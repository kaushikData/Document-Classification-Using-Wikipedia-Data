<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>2-functor</title>
    <ns>0</ns>
    <id>47489599</id>
    <revision>
      <id>845947473</id>
      <parentid>845806711</parentid>
      <timestamp>2018-06-15T06:50:37Z</timestamp>
      <contributor>
        <username>MitchB</username>
        <id>2181606</id>
      </contributor>
      <comment>Attempted to make opening paragraph a bit more detailed and direct</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1281">{{refimprove|date=December 2017}}
In [[mathematics]], a 2-functor is a morphism between [[2-category|2-categories]]&lt;ref&gt;{{cite journal |last1=Kelly |first1=G.M. |last2=Street |first2=R. |date=1974 |title=Review of the elements of 2-categories |journal=Category Seminar |volume=420 |pages= 75--103 }} &lt;/ref&gt;. They may be defined formally using [[Enriched category|enrichment]] by saying that a 2-category is exactly a ''Cat''-enriched category and a 2-functor is a ''Cat''-functor &lt;ref&gt; G. M. Kelly. Basic concepts of enriched category theory. Reprints in Theory and Applications of Categories, (10), 2005. &lt;/ref&gt;.

Explicitly, if ''C'' and ''D'' are 2-categories then a 2-functor &lt;math&gt;F\colon C\to D&lt;/math&gt; consists of
* a function &lt;math&gt;F\colon \text{Ob} C\to \text{Ob} D&lt;/math&gt;, and
* for each pair of objects &lt;math&gt;c,c'\in C&lt;/math&gt; a functor &lt;math&gt;F_{c,c'}\colon \text{Hom}_{C}(c,c')\to\text{Hom}_D(Fc,Fc')&lt;/math&gt; 
such that each &lt;math&gt;F_{c,c}&lt;/math&gt; strictly preserves identity objects and they commute with horizontal composition in ''C'' and ''D''.

See &lt;ref&gt;{{nlab|id=2-functor}}&lt;/ref&gt; for more details and for [[lax functor|lax versions]].

==References==
{{Reflist}}

{{Category theory}}

[[Category:Functors]]
[[Category:Higher category theory]]

{{categorytheory-stub}}</text>
      <sha1>rk73dlqdiv9fhkb4n06yk6k4pqjmxol</sha1>
    </revision>
  </page>
  <page>
    <title>Arbitrary-precision arithmetic</title>
    <ns>0</ns>
    <id>600892</id>
    <revision>
      <id>868901915</id>
      <parentid>862863788</parentid>
      <timestamp>2018-11-15T04:34:32Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Example */ italicize comments, {{mvar}}, {{sup}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23207">{{More citations needed|date=July 2007}}
In [[computer science]], '''arbitrary-precision arithmetic''', also called '''bignum arithmetic''', multiple-precision arithmetic, or sometimes '''infinite-precision arithmetic''', indicates that [[calculation]]s are performed on numbers whose [[numerical digit|digits]] of [[precision (arithmetic)|precision]] are limited only by the available [[memory (computers)|memory]] of the host system.  This contrasts with the faster fixed-precision arithmetic found in most [[arithmetic logic unit]] (ALU) hardware, which typically offers between 8 and 64 [[bit]]s of precision.

Several modern [[programming language]]s have built-in support for bignums, and others have libraries available for arbitrary-precision [[integer]] and [[floating-point]] math.  Rather than store values as a fixed number of binary [[bit]]s related to the size of the [[processor register]], these implementations typically use variable-length [[array data structure|arrays]] of digits.

Arbitrary precision is used in applications where the speed of [[arithmetic]] is not a limiting factor, or where [[Floating point error mitigation|precise results]] with very large numbers are required.  It should not be confused with the [[symbolic computation]] provided by many [[computer algebra system]]s, which represent numbers by expressions such as {{math|''π''·sin(2)}}, and can thus ''represent'' any [[computable number]] with infinite precision.

==Applications==

A common application is [[public-key cryptography]], whose algorithms commonly employ arithmetic with integers having hundreds of digits.&lt;ref&gt;{{cite web |url=https://arstechnica.com/news.ars/post/20070523-researchers-307-digit-key-crack-endangers-1024-bit-rsa.html |title=Researchers: 307-digit key crack endangers 1024-bit RSA |author=Jacqui Cheng |date=May 23, 2007}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.rsa.com/rsalabs/node.asp?id%3D2218 |title=Archived copy |accessdate=2012-03-31 |deadurl=yes |archiveurl=https://web.archive.org/web/20120401144624/http://www.rsa.com/rsalabs/node.asp?id=2218 |archivedate=2012-04-01 |df= }} recommends important RSA keys be 2048 bits (roughly 600 digits).&lt;/ref&gt;  Another is in situations where artificial limits and [[arithmetic overflow|overflows]] would be inappropriate.  It is also useful for checking the results of fixed-precision calculations, and for determining the optimum value for coefficients needed in formulae, for example the {{radic|1/3}} that appears in [[Gaussian integration]].

Arbitrary precision arithmetic is also used to compute fundamental [[mathematical constant]]s such as [[pi|π]] to millions or more digits and to analyze the properties of the digit strings&lt;ref&gt;{{cite journal |author=R. K. Pathria |authorlink=Raj Pathria |title=A Statistical Study of the Randomness Among the First 10,000 Digits of Pi |year=1962 |journal=Mathematics of Computation |volume=16 |issue=78 |pages=188–197 |url=http://www.ams.org/journals/mcom/1962-16-078/S0025-5718-1962-0144443-7/ |accessdate=2014-01-10 |doi=10.1090/s0025-5718-1962-0144443-7}} A quote example from this article: "Such an extreme pattern is dangerous even if diluted by one of its neighbouring blocks"; this was the occurrence of the sequence 77 twenty-eight times in one block of a thousand digits.&lt;/ref&gt; or more generally to investigate the precise behaviour of functions such as the [[Riemann zeta function]] where certain questions are difficult to explore via analytical methods. Another example is in rendering [[fractal]] images with an extremely high magnification, such as those found in the [[Mandelbrot set]].

Arbitrary-precision arithmetic can also be used to avoid [[arithmetic overflow|overflow]], which is an inherent limitation of fixed-precision arithmetic.  Similar to a 5-digit [[odometer]]'s display which changes from 99999 to 00000, a fixed-precision integer may exhibit ''wraparound'' if numbers grow too large to represent at the fixed level of precision.  Some processors can instead deal with overflow by ''[[saturation arithmetic|saturation]],'' which means that if a result would be unrepresentable, it is replaced with the nearest representable value.  (With 16-bit unsigned saturation, adding any positive amount to 65535 would yield 65535.)  Some processors can generate an [[exception handling|exception]] if an arithmetic result exceeds the available precision. Where necessary, the exception can be caught and recovered from—for instance, the operation could be restarted in software using arbitrary-precision arithmetic.

In many cases, the task or the programmer can guarantee that the integer values in a specific application will not grow large enough to cause an overflow. Such guarantees may be based on pragmatic limits: a school attendance program may have a task limit of 4,000 students. A programmer may design the computation so that intermediate results stay within specified precision boundaries.

Some programming languages such as [[Lisp (programming language)|Lisp]], [[Python (programming language)|Python]], [[Perl]], [[Haskell (programming language)|Haskell]] and [[Ruby (programming language)|Ruby]] use, or have an option to use, arbitrary-precision numbers for ''all'' integer arithmetic.  Although this reduces performance, it eliminates the possibility of incorrect results (or exceptions) due to simple overflow.  It also makes it possible to guarantee that arithmetic results will be the same on all machines, regardless of any particular machine's [[Word (data type)|word size]].  The exclusive use of arbitrary-precision numbers in a programming language also simplifies the language, because ''a number is a number'' and there is no need for multiple types to represent different levels of precision.

==Implementation issues==

Arbitrary-precision arithmetic is considerably slower than arithmetic using numbers that fit entirely within processor registers, since the latter are usually implemented in [[Arithmetic logic unit|hardware arithmetic]] whereas the former must be implemented in software.  Even if the [[computer]] lacks hardware for certain operations (such as integer division, or all floating-point operations) and software is provided instead, it will use number sizes closely related to the available hardware registers: one or two words only and definitely not N words.    There are exceptions, as certain ''[[variable word length machine|variable word length]]'' machines of the 1950s and 1960s, notably the [[IBM 1620]], [[IBM 1401]] and the Honeywell ''Liberator'' series, could manipulate numbers bound only by available storage, with an extra bit that delimited the value.

Numbers can be stored in a [[fixed-point arithmetic|fixed-point]] format, or in a [[floating-point]] format as a [[significand]] multiplied by an arbitrary exponent.  However, since division almost immediately introduces infinitely repeating sequences of digits (such as 4/7 in decimal, or 1/10 in binary), should this possibility arise then either the representation would be truncated at some satisfactory size or else rational numbers would be used: a large integer for the [[numerator]] and for the [[denominator]]. But even with the [[greatest common divisor]] divided out, arithmetic with rational numbers can become unwieldy very quickly: 1/99 − 1/100 = 1/9900, and if 1/101 is then added, the result is 10001/999900.

The size of arbitrary-precision numbers is limited in practice by the total storage available, the variables used to index the digit strings, and computation time. A 32-bit operating system may limit available storage to less than 4&amp;nbsp;GB.&lt;!-- could make thrashing statement for numbers larger than physical RAM --&gt; A programming language using 32-bit integers can only index 4&amp;nbsp;GB. If multiplication is done with an {{math|[[Big O notation|O]](''N''&lt;sup&gt;2&lt;/sup&gt;)}} algorithm, it would take on [[Order of approximation|the order of]] {{math|10&lt;sup&gt;12&lt;/sup&gt;}} steps to multiply two one-million-word numbers.

Numerous [[algorithms]] have been developed to efficiently perform arithmetic operations on numbers stored with arbitrary precision.  In particular, supposing that {{math|''N''}} digits are employed, algorithms have been designed to minimize the asymptotic [[Computational complexity theory|complexity]] for large {{math|''N''}}.

The simplest algorithms are for [[addition]] and [[subtraction]], where one simply adds or subtracts the digits in sequence, carrying as necessary, which yields an {{math|O(''N'')}} algorithm (see [[big O notation]]).

[[Comparison (computer programming)|Comparison]] is also very simple. Compare the high-order digits (or machine words) until a difference is found. Comparing the rest of the digits/words is not necessary. The worst case is {{math|O(''N'')}}, but usually it will go much faster.

For [[multiplication]], the most straightforward algorithms used for multiplying numbers by hand (as taught in primary school) require {{math|O(''N''&lt;sup&gt;2&lt;/sup&gt;)}} operations, but [[multiplication algorithm]]s that achieve {{math|O(''N''&amp;nbsp;log(''N'')&amp;nbsp;log(log(''N'')))}} complexity have been devised, such as the [[Schönhage–Strassen algorithm]], based on [[fast Fourier transform]]s, and there are also algorithms with slightly worse complexity but with sometimes superior real-world performance for smaller {{math|''N''}}. The [[Karatsuba algorithm|Karatsuba]] multiplication is such an algorithm.

For [[Division (mathematics)|division]], see [[division algorithm]].

For a list of algorithms along with complexity estimates, see [[computational complexity of mathematical operations]].

For examples in [[x86]] assembly, see [[#External links|external links]].

==Pre-set precision==
In some languages such as [[REXX]], the precision of all calculations must be set before doing a calculation. Other languages, such as [[Python (programming language)|Python]] and [[Ruby (programming language)|Ruby]] extend the precision automatically to prevent overflow.

==Example==
The calculation of [[factorial]]s can easily produce very large numbers. This is not a problem for their usage in many formulae (such as [[Taylor series]]) because they appear along with other terms, so that—given careful attention to the order of evaluation—intermediate calculation values are not troublesome. If approximate values of factorial numbers are desired, [[Stirling's approximation]] gives good results using floating-point arithmetic. The largest representable value for a fixed-size integer variable may be exceeded even for relatively small arguments as shown in the table below. Even floating-point numbers are soon outranged, so it may help to recast the calculations in terms of the [[logarithm]] of the number.

But if exact values for large factorials are desired, then special software is required, as in the pseudocode that follows, which implements the classic algorithm to calculate 1, 1×2, 1×2×3, 1×2×3×4, etc. the successive factorial numbers.

 Constant Limit = 1000;            ''% Sufficient digits.''
 Constant Base = 10;               ''% The base of the simulated arithmetic.''
 Constant FactorialLimit = 365;    ''% Target number to solve, 365!''
 Array digit[1:Limit] of integer;  ''% The big number.''
 Integer carry,d;                  ''% Assistants during multiplication.''
 Integer last,i;                   ''% Indices to the big number's digits.''
 Array text[1:Limit] of character; ''% Scratchpad for the output.''
 Constant tdigit[0:9] of character = ["0","1","2","3","4","5","6","7","8","9"];
 '''BEGIN'''
  digit:=0;                        ''% Clear the whole array.''
  digit[1]:=1;                     ''% The big number starts with 1,''
  last:=1;                         ''% Its highest-order digit is number 1.''
  '''for''' n:=1 '''to''' FactorialLimit '''do'''    ''% Step through producing 1!, 2!, 3!, 4!, etc. ''
   carry:=0;                       ''% Start a multiply by n.''
   '''for''' i:=1 '''to''' last '''do'''             ''% Step along every digit.''
    d:=digit[i]*n + carry;         ''% The classic multiply.''
    digit[i]:=d '''mod''' Base;          ''% The low-order digit of the result.''
    carry:=d '''div''' Base;             ''% The carry to the next digit.''
   '''next''' i;
   '''while''' carry &gt; 0                 ''% Store the carry in the big number.            ''
    '''if''' last &gt;= Limit '''then''' croak("Overflow!");  ''% If possible!''
    last:=last + 1;                ''% One more digit.''
    digit[last]:=carry '''mod''' Base;   ''% Placed.''
    carry:=carry '''div''' Base;         ''% The carry reduced.''
   '''Wend'''                            ''% With n &gt; Base, maybe &gt; 1 digit extra.''
   text:=" ";                      ''% Now prepare the output.''
   '''for''' i:=1 '''to''' last '''do'''             ''% Translate from binary to text.''
    text[Limit - i + 1]:=tdigit[digit[i]];  ''% Reversing the order.''
   '''next''' i;                         ''% Arabic numerals put the low order last.''
   '''Print''' text," = ",n,"!";         ''% Print the result!''
  '''next''' n;                          ''% On to the next factorial up.''
 '''END''';

With the example in view, a number of details can be discussed. The most important is the choice of the representation of the big number. In this case, only integer values are required for digits, so an array of fixed-width integers is adequate. It is convenient to have successive elements of the array represent higher powers of the base.

The second most important decision is in the choice of the base of arithmetic, here ten. There are many considerations. The scratchpad variable {{mvar|d}} must be able to hold the result of a single-digit multiply ''plus the carry'' from the prior digit's multiply. In base ten, a sixteen-bit integer is certainly adequate as it allows up to 32767. However, this example cheats, in that the value of {{mvar|n}} is not itself limited to a single digit. This has the consequence that the method will fail for {{math|''n'' &gt; 3200}} or so. In a more general implementation, {{mvar|n}} would also use a multi-digit representation. A second consequence of the shortcut is that after the multi-digit multiply has been completed, the last value of ''carry'' may need to be carried into multiple higher-order digits, not just one.

There is also the issue of printing the result in base ten, for human consideration. Because the base is already ten, the result could be shown simply by printing the successive digits of array ''digit'', but they would appear with the highest-order digit last (so that 123 would appear as "321"). The whole array could be printed in reverse order, but that would present the number with leading zeroes ("00000...000123") which may not be appreciated, so we decided to build the representation in a space-padded text variable and then print that. The first few results (with spacing every fifth digit and annotation added here) are:

{| style="text-align: right; white-space: nowrap; line-height: 80%"
! colspan=2 style="text-align: center" | Factorial numbers
! colspan=2 style="text-align: center" | Reach of computer integers
|-
|                                                 1 = ||  1!
|-
|                                                 2 = ||  2!
|-
|                                                 6 = ||  3!
|-
|                                                24 = ||  4!
|-
|                                               120 = ||  5!
| 8-bit || style="text-align: left" | 255
|-
|                                               720 = ||  6!
|-
|                                              5040 = ||  7!
|-
|                                             40320 = ||  8!
| 16-bit || style="text-align: left" | 65535
|-
|                                           3 62880 = ||  9!   
|-
|                                          36 28800 = || 10!   
|-
|                                         399 16800 = || 11!
|-
|                                        4790 01600 = || 12!
| 32-bit || style="text-align: left" | 42949 67295
|-
|                                       62270 20800 = || 13!   
|-
|                                     8 71782 91200 = || 14!   
|-
|                                   130 76743 68000 = || 15!   
|-
|                                  2092 27898 88000 = || 16!   
|-
|                                 35568 74280 96000 = || 17!   
|-
|                               6 40237 37057 28000 = || 18!   
|-
|                             121 64510 04088 32000 = || 19!   
|-
|                            2432 90200 81766 40000 = || 20!
| 64-bit || style="text-align: left" | 18446 74407 37095 51615
|-
|                           51090 94217 17094 40000 = || 21!   
|-
|                        11 24000 72777 76076 80000 = || 22!   
|-
|                       258 52016 73888 49766 40000 = || 23!   
|-
|                      6204 48401 73323 94393 60000 = || 24!   
|-
|                   1 55112 10043 33098 59840 00000 = || 25!   
|-
|                  40 32914 61126 60563 55840 00000 = || 26!   
|-
|                1088 88694 50418 35216 07680 00000 = || 27!   
|-
|               30488 83446 11713 86050 15040 00000 = || 28!   
|-
|             8 84176 19937 39701 95454 36160 00000 = || 29!   
|-
|           265 25285 98121 91058 63630 84800 00000 = || 30!   
|-
|          8222 83865 41779 22817 72556 28800 00000 = || 31!
|-
|       2 63130 83693 36935 30167 21801 21600 00000 = || 32!
|-
|      86 83317 61881 18864 95518 19440 12800 00000 = || 33!
|-
|    2952 32799 03960 41408 47618 60964 35200 00000 = || 34!
| 128-bit || style="text-align: left" | 3402 82366 92093 84634 63374 60743 17682 11455
|-
| 1 03331 47966 38614 49296 66651 33752 32000 00000 = || 35! 
|}

We could try to use the available arithmetic of the computer more efficiently. A simple escalation would be to use base 100 (with corresponding changes to the translation process for output), or, with sufficiently wide computer variables (such as 32-bit integers) we could use larger bases, such as 10,000. Working in a power-of-2 base closer to the computer's built-in integer operations offers advantages, although conversion to a decimal base for output becomes more difficult. On typical modern computers, additions and multiplications take constant time independent of the values of the operands (so long as the operands fit in single machine words), so there are large gains in packing as much of a bignumber as possible into each element of the digit array. The computer may also offer facilities for splitting a product into a digit and carry without requiring the two operations of ''mod'' and ''div'' as in the example, and nearly all arithmetic units provide a ''[[carry flag]]'' which can be exploited in multiple-precision addition and subtraction. This sort of detail is the grist of machine-code programmers, and a suitable assembly-language bignumber routine can run much faster than the result of the compilation of a high-level language, which does not provide access to such facilities.

For a single-digit multiply the working variables must be able to hold the value (base-1){{sup|2}} + carry, where the maximum value of the carry is (base-1). Similarly, the variables used to index the digit array are themselves limited in width. A simple way to extend the indices would be to deal with the bignumber's digits in blocks of some convenient size so that the addressing would be via (block ''i'', digit ''j'') where ''i'' and ''j'' would be small integers, or, one could escalate to employing bignumber techniques for the indexing variables. Ultimately, machine storage capacity and execution time impose limits on the problem size.

==History==
IBM's first business computer, the [[IBM 702]] (a [[vacuum-tube]] machine) of the mid-1950s, implemented integer arithmetic ''entirely in hardware'' on digit strings of any length from 1 to 511 digits.  The earliest widespread software implementation of arbitrary-precision arithmetic was probably that in [[Maclisp]].  Later, around 1980, the [[operating system]]s [[VAX/VMS]] and [[VM/CMS]] offered bignum facilities as a collection of [[literal string|string]] [[subprogram|functions]] in the one case and in the languages [[EXEC 2]] and [[REXX]] in the other.

An early widespread implementation was available via the [[IBM 1620]] of 1959–1970.  The 1620 was a decimal-digit machine which used discrete transistors, yet it had hardware (that used [[lookup table]]s) to perform integer arithmetic on digit strings of a length that could be from two to whatever memory was available.  For floating-point arithmetic, the mantissa was restricted to a hundred digits or fewer, and the exponent was restricted to two digits only.  The largest memory supplied offered 60 000 digits, however [[Fortran]] compilers for the 1620 settled on fixed sizes such as 10, though it could be specified on a control card if the default was not satisfactory.

==Software libraries==
{{See also|List of arbitrary-precision arithmetic software}}

Arbitrary-precision arithmetic in most computer software is implemented by calling an external [[library (computer science)|library]] that provides [[data type]]s and [[subroutine]]s to store numbers with the requested precision and to perform computations.

Different libraries have different ways of representing arbitrary-precision numbers, some libraries work only with integer numbers, others store [[floating point]] numbers in a variety of bases (decimal or binary powers). Rather than representing a number as single value, some store numbers as a numerator/denominator pair ([[rational number|rationals]]) and some can fully represent [[computable number]]s, though only up to some storage limit. Fundamentally, [[Turing machine]]s cannot represent all [[real number]]s, as the [[cardinality]] of {{math|'''ℝ'''}} exceeds the cardinality of {{math|'''ℤ'''}}.

== See also ==

* [[Karatsuba algorithm]]
* [[Toom–Cook multiplication]]
* [[Schönhage–Strassen algorithm]]
* [[Fürer's algorithm]]
* [[List of arbitrary-precision arithmetic software]]

== References ==

{{reflist}}
* {{Cite book|last=Knuth |first=Donald |authorlink=Donald Knuth |title=Seminumerical Algorithms |series=[[The Art of Computer Programming]] |volume=2 |year=2008 |edition=3rd |publisher=Addison-Wesley |isbn=0-201-89684-2|postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;&amp;#123;&amp;#123;inconsistent citations&amp;#125;&amp;#125; }}, Section 4.3.1: The Classical Algorithms

== External links ==
* [http://oopweb.com/Assembly/Documents/ArtOfAssembly/Volume/Chapter_9/CH09-3.html#HEADING3-1 Chapter 9.3 of ''The Art of Assembly''] by [[Randall Hyde]] discusses multiprecision arithmetic, with examples in [[x86]]-assembly.
* Rosetta Code task [http://rosettacode.org/wiki/Arbitrary-precision_integers_%28included%29 Arbitrary-precision integers] Case studies in the style in which over 47 programming languages compute the value of 5**4**3**2 using arbitrary precision arithmetic.

{{data types}}

[[Category:Computer arithmetic]]
[[Category:Computer arithmetic algorithms]]</text>
      <sha1>smis9nvfc5g386rw1bmcvyx5vlgubkb</sha1>
    </revision>
  </page>
  <page>
    <title>Architectural drawing</title>
    <ns>0</ns>
    <id>21482414</id>
    <revision>
      <id>868506489</id>
      <parentid>848884756</parentid>
      <timestamp>2018-11-12T17:07:13Z</timestamp>
      <contributor>
        <username>Mtpanchal</username>
        <id>25337644</id>
      </contributor>
      <comment>/* CGI and computer-aided design */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35450">{{Refimprove|date=August 2013}}

[[File:Plan Port-Royal-des-Champs.jpg|thumb|upright=1.25|18th century axonometric plan, [[Port-Royal-des-Champs]].]]

An '''architectural drawing''' or '''architect's drawing''' is a [[technical drawing]] of a building (or building project) that falls within the definition of [[architecture]]. Architectural drawings are used by [[architect]]s and others for a number of purposes: to develop a design idea into a coherent proposal, to communicate ideas and concepts, to convince clients of the merits of a design, to enable a [[building contractor]] to construct it, as a record of the completed work, and to make a record of a building that already exists.

Architectural drawings are made according to a set of [[Convention (norm)|conventions]], which include particular views (floor plan, section etc.), sheet sizes, units of measurement and scales, annotation and cross referencing. Conventionally, drawings were made in ink on paper or a similar material, and any copies required had to be laboriously made by hand. The twentieth century saw a shift to drawing on tracing paper, so that mechanical copies could be run off efficiently.

The development of the [[computer]] had a major impact on the methods used to design and create technical drawings,&lt;ref name="Bert02"&gt;Gary R. Bertoline et al. (2002) ''Technical Graphics Communication''. p.12.&lt;/ref&gt; making manual drawing almost obsolete, and opening up new possibilities of form using organic shapes and complex geometry. Today the vast majority of drawings are created using [[Computer-aided design|CAD]] software.&lt;ref&gt;[http://www.wisegeek.com/what-are-cad-drawings.htm Wisegeek, basic definition of the scope of CAD drawings.]

&lt;/ref&gt;

==Size and scale==
{{main|Paper size|Engineer's scale|Architect's scale|Metric scale}}
The size of drawings reflects the materials available and the size that is convenient to transport – rolled up or folded, laid out on a table, or pinned up on a wall. The draughting process may impose limitations on the size that is realistically workable. Sizes are determined by a consistent [[paper size]] system, according to local usage. Normally the largest [[paper size]] used in modern architectural practice is ISO A0 ({{convert|841|×|1189|mm|in|1|abbr=on|disp=or}}) or in the USA Arch E ({{convert|762|×|1067|mm|in|0|abbr=on|disp=or}}) or Large E size ({{convert|915|×|1220|mm|in|0|abbr=on|disp=or}}).&lt;ref name=Dummies&gt;David Byrnes, AutoCAD 2008 For Dummies. Publisher: John Wiley &amp; Sons; illustrated edition (4 May 2007). {{ISBN|0-470-11650-1}}&lt;/ref&gt;

Architectural drawings are drawn to scale, so that relative sizes are correctly represented. The scale is chosen both to ensure the whole building will fit on the chosen sheet size, and to show the required amount of detail. At the scale of one eighth of an inch to one foot (1:96) or the metric equivalent 1 to 100, walls are typically shown as simple outlines corresponding to the overall thickness. At a larger scale, half an inch to one foot (1:24) or the nearest common metric equivalent 1 to 20, the layers of different materials that make up the wall construction are shown. Construction details are drawn to a larger scale, in some cases full size (1 to 1 scale).

Scale drawings enable dimensions to be "read" off the drawing, i.e. measured directly. [[Imperial units|Imperial]] scales (feet and inches) are equally readable using an ordinary ruler. On a one-eighth inch to one foot scale drawing, the one-eighth divisions on the ruler can be read off as feet. Architects normally use a [[scale ruler]] with different scales marked on each edge. A third method, used by builders in estimating, is to measure directly off the drawing and multiply by the scale factor.

Dimensions can be measured off drawings made on a stable medium such as vellum. All processes of reproduction introduce small errors, especially now that different copying methods mean that the same drawing may be re-copied, or copies made in several different ways. Consequently, dimensions need to be written ("figured") on the drawing. The disclaimer "Do not scale off dimensions" is commonly inscribed on architects drawings, to guard against errors arising in the copying process.

[[File:Architectural drawing 001.png|thumb|left|Standard views used in architects' drawings.]]
[[Image:Panopticon.jpg|thumb|left|Architectural drawing combining elevation, section and plan: drawings by [[Willey Reveley]] of [[Jeremy Bentham]]'s proposal for a [[Panopticon]] prison, 1791.]]

==Standard views used in architectural drawing==
''This section deals with the conventional views used to represent a building or structure. See the [[#Types of architectural drawing|Types of architectural drawing]] section below for drawings classified according to their purpose.''

[[File:Queen's House plan.jpg|thumb|right|Principal floor plans of the [[Queen's House]], Greenwich (UK).]]

===Floor plan===
A [[floor plan]] is the most fundamental architectural [[diagram]], a view from above showing the arrangement of spaces in building in the same way as a [[map]], but showing the arrangement at a particular level of a building. Technically it is a horizontal section cut through a building (conventionally at four feet / one metre and twenty centimetres above floor level), showing walls, windows and door openings and other features at that level. The plan view includes anything that could be seen below that level: the floor, stairs (but only up to the plan level), fittings and sometimes furniture. Objects above the plan level (e.g. beams overhead) can be indicated as dashed lines.

Geometrically, [[plan view]] is defined as a vertical [[orthographic projection]] of an object on to a horizontal plane, with the horizontal plane cutting through the building.



===Site plan===
A [[site plan]] is a specific type of plan, showing the whole context of a building or group of buildings. A site plan shows property boundaries and means of access to the site, and nearby structures if they are relevant to the design. For a [[Real estate development|development]] on an urban site, the site plan may need to show adjoining streets to demonstrate how the design fits into the urban fabric. Within the site boundary, the site plan gives an overview of the entire scope of work. It shows the buildings (if any) already existing and those that are proposed, usually as a building footprint; roads, parking lots, footpaths, [[hardscape|hard landscaping]], trees and planting. For a construction project, the site plan also needs to show all the services connections: drainage and sewer lines, water supply, electrical and communications cables, exterior lighting etc.

Site plans are commonly used to [[Representation (arts)|represent]] a building proposal prior to detailed design: drawing up a site plan is a tool for deciding both the site layout and the size and orientation of proposed new buildings. A site plan is used to verify that a proposal complies with local development codes, including restrictions on historical sites. In this context the site plan forms part of a legal agreement, and there may be a requirement for it to be drawn up by a licensed professional: architect, engineer, landscape architect or land surveyor.&lt;ref&gt;[http://ottawa.ca/en/homeowners-guide-small-projects-1/how-detailed-should-your-plans-be City of Ottawa, specific requirements for drawings to be submitted for a building permit] {{webarchive |url=https://web.archive.org/web/20140102192756/http://ottawa.ca/en/homeowners-guide-small-projects-1/how-detailed-should-your-plans-be |date=January 2, 2014 }}. Local authorities worldwide publish similar information.&lt;/ref&gt;

[[File:Panthéon Soufflot - élevation principale.png| thumb|right|Elevation of the principal façade of the [[Panthéon, Paris]]]]

===Elevation===
An elevation is a view of a building seen from one side, a flat representation of one [[façade]]. This is the most common view used to describe the external appearance of a building. Each elevation is labelled in relation to the compass direction it faces, e.g. looking toward the north you would be seeing the southern elevation of the building.&lt;ref&gt;{{Citation | first = Frank| last = Ching| author-link = | title = Architectural Graphics – Second Edition | place = New York | publisher = Van Norstrand Reinhold | year = 1985 | isbn = 0-442-21862-1 }}&lt;/ref&gt; Buildings are rarely a simple rectangular shape in plan, so a typical elevation may show all the parts of the building that are seen from a particular direction.

Geometrically, an elevation is a horizontal orthographic projection a building on to a vertical plane, the vertical plane normally being parallel to one side of the building.

Architects also use the word elevation as a [[synonym]] for [[façade]], so the north elevation is literally the north-facing wall of the building.

[[File:L-Observatorium.png|thumb|Section drawing of the [[Astrophysical Institute Potsdam|Observatorium]] at Potsdam.]]

===Cross section===
A [[Cross section (geometry)|cross section]], also simply called a section, represents a vertical plane cut through the object, in the same way as a [[floor plan]] is a horizontal section viewed from the top. In the section view, everything cut by the section plane is shown as a bold line, often with a solid fill to show objects that are cut through, and anything seen beyond generally shown in a thinner line. Sections are used to describe the relationship between different levels of a building. In the Observatorium drawing illustrated here, the section shows the dome which can be seen from the outside, a second dome that can only be seen inside the building, and the way the space between the two accommodates a large astronomical telescope: relationships that would be difficult to understand from plans alone.

A sectional elevation is a combination of a cross section, with elevations of other parts of the building seen beyond the section plane.

Geometrically, a cross section is a horizontal orthographic projection of a building on to a vertical plane, with the vertical plane cutting through the building.

===Isometric and axonometric projections===
Isometric and axonometric projections are a simple way of representing a three dimensional object, keeping the elements to scale and showing the relationship between several sides of the same object, so that the complexities of a shape can be clearly understood.

There is some confusion about the terms isometric and axonometric. “Axonometric is a word that has been used by architects for hundreds of years. Engineers use the word axonometric as a generic term to include isometric, diametric and trimetric drawings.”&lt;ref name=Piper&gt;Alan Piper, ''Drawing for Designers''. Laurence King Publishing 2007. {{ISBN|978-1-85669-533-6}} Page 57, definition of axonometric drawing&lt;/ref&gt; This article uses the terms in the architecture-specific sense.

Despite fairly complex geometrical explanations, for the purposes of practical draughting the difference between isometric and axonometric is simple (see diagram above). In both, the plan is drawn on a skewed or rotated grid, and the verticals are projected vertically on the page. All lines are drawn to scale so that relationships between elements are accurate. In many cases a different scale is required for different [[Cartesian coordinate system|axes]], and again this can be calculated but in practice was often simply estimated by eye.
* An [[Isometric projection|isometric]] uses a plan grid at 30 degrees from the horizontal in both directions, which distorts the plan shape. Isometric graph paper can be used to construct this kind of drawing. This view is useful to explain construction details (e.g. three dimensional joints in joinery). The isometric was the standard view until the mid twentieth century, remaining popular until the 1970s, especially for textbook diagrams and illustrations.&lt;ref name=McKay&gt;W. B. McKay: McKay's Building Construction. Donhead Publishing 2005. {{ISBN|978-1-873394-72-4}} A new reprint of the combined three volumes that McKay published between 1938 and 1944. Heavily illustrated textbook of architectural detailing.&lt;/ref&gt;&lt;ref&gt;[http://www.donhead.com/Look%20Inside/Mckay2.pdf Sample pages of isometric drawings from McKay's Building Construction] {{webarchive |url=https://web.archive.org/web/20110710144037/http://www.donhead.com/Look%20Inside/Mckay2.pdf |date=July 10, 2011 }}&lt;/ref&gt;
* [[Cabinet projection]] is similar, but only one axis is skewed, the others being horizontal and vertical. Originally used in cabinet making, the advantage is that a principal side (e.g. a cabinet front) is displayed without distortion, so only the less important sides are skewed. The lines leading away from the eye are drawn at a reduced scale to lessen the degree of distortion. The cabinet projection is seen in Victorian engraved advertisements and architectural textbooks,&lt;ref name=McKay/&gt; but has virtually disappeared from general use.
* An [[Axonometric projection|axonometric]] uses a 45 degree plan grid, which keeps the original orthogonal geometry of the plan. The great advantage of this view for architecture is that the draughtsman can work directly from a plan, without having to reconstruct it on a skewed grid. In theory the plan should be set at 45 degrees, but this introduces confusing coincidences where opposite corners align. Unwanted effects can be avoided by rotating the plan while still projecting vertically. This is sometimes called a planometric or plan oblique view,&lt;ref name=Thompson/&gt; and allows freedom to choose any suitable angle to present the most useful view of an object.

Traditional draughting techniques used 30–60 and 45 degree [[set square]]s, and that determined the angles used in these views. Once the adjustable square became common those limitations were lifted.

The axonometric gained in popularity in the twentieth century, not just as a convenient diagram but as a formal presentation technique, adopted in particular by the [[Modern Movement]].&lt;ref name=Piper/&gt; Axonometric drawings feature prominently in the influential 1970's drawings of [[Michael Graves]], [[James Stirling (architect)|James Stirling]] and others, using not only straightforward views but worms-eye view, unusually and exaggerated rotations of the plan, and exploded elements.&lt;ref&gt;Thomas W Schaller, Architecture in Watercolour. Van Nostrand Re9inhold, New York 1990. {{ISBN|0-442-23484-8}}&lt;/ref&gt;

The axonometric view is not readily generated by CAD programmes which create views from a three dimensional model. Consequently, it is now rarely used.

===Detail drawings===
Detail drawings show a small part of the construction at a larger scale, to show how the component parts fit together. They are also used to show small surface details, for example decorative elements. Section drawings at large scale are a standard way of showing building construction details, typically showing complex junctions (such as floor to wall junction, window openings, eaves and roof apex) that cannot be clearly shown on a drawing that includes the full height of the building. A full set of construction details needs to show plan details as well as vertical section details. One detail is seldom produced in isolation: a set of details shows the information needed to understand the construction in three dimensions. Typical scales for details are 1/10, 1/5 and full size.

In traditional construction, many details were so fully standardised, that few detail drawings were required to construct a building. For example, the construction of a [[sash window]] would be left to the carpenter, who would fully understand what was required, but unique decorative details of the facade would be drawn up in detail. In contrast, modern buildings need to be fully detailed because of the proliferation of different products, methods and possible solutions.

==Architectural perspective==
[[File:La renaissance du treillage, 1977.jpg|thumb|Perspective in the manner of the classic ''Ideal city'' by [[Jean-Max Albert]],1977.]]
[[File:Dercy House drawing-room1777.jpg|thumb|right|Two point perspective, interior of Dercy House by [[Robert Adam]], 1777.]]
[[Perspective (graphical)|Perspective]] in drawing is an approximate representation on a flat surface of an image as it is perceived by the eye. The key concepts here are:
* Perspective is the view from a particular fixed viewpoint.
* Horizontal and vertical edges in the object are represented by horizontals and verticals in the drawing.
* Lines leading away into the distance appear to converge at a [[vanishing point]].
* All horizontals converge to a point on the [[horizon]], which is a horizontal line at eye level.
* Verticals converge to a point either above or below the horizon.

The basic categorization of artificial perspective is by the number of vanishing points:
* [[One-point perspective]] where objects facing the viewer are orthogonal, and receding lines converge to a single vanishing point.
* [[Two-point perspective]] reduces distortion by viewing objects at an angle, with all the horizontal lines receding to one of two vanishing points, both located on the horizon.
* [[Three-point perspective]] introduces additional realism by making the verticals recede to a third vanishing point, which is above or below depending upon whether the view is seen from above or below.

The normal convention in architectural perspective is to use two-point perspective, with all the verticals drawn as verticals on the page.

Three-point perspective gives a casual, photographic snapshot effect. In professional [[architectural photography]], conversely, a [[view camera]] or a [[perspective control lens]] is used to eliminate the third vanishing point, so that all the verticals are vertical on the photograph, as with the perspective convention. This can also be done by digital manipulation of a photograph taken with a standard lens.

[[Aerial perspective]] is a technique in painting, for indicating distance by approximating the effect of the atmosphere on distant objects. In daylight, as an ordinary object gets further from the eye, its contrast with the background is reduced, its colour saturation is reduced, and its colour becomes more blue. Not to be confused with [[aerial view]] or bird's eye view, which is the view as seen (or imagined) from a high vantage point. In J M Gandy's perspective of the Bank of England (see illustration at the beginning of this article), Gandy portrayed the building as a picturesque ruin in order to show the internal plan arrangement, a precursor of the cutaway view.&lt;ref name=Stamp&gt;The Great Perspectivists, by Gavin Stamp. RIBA Drawings Series, published by Trefoil Books London 1982. {{ISBN|0-86294-002-8}}&lt;/ref&gt;

A [[wikt:montage|montage]] image is produced by superimposing a perspective image of a building on to a photographic background. Care is needed to record the position from which the photograph was taken, and to generate the perspective using the same viewpoint. This technique is popular in computer visualisation, where the building can be [[photorealism|photorealistically]] rendered, and the final image is intended to be almost indistinguishable from a photograph.

==Sketches and diagrams==
[[File:Y-blokken som plassvegg.jpg|thumb|right|Architect's early concept sketches.]]
A [[Sketch (drawing)|sketch]] is a rapidly executed freehand drawing, a quick way to record and develop an idea, not intended as a finished work. A [[diagram]] could also be drawn freehand but deals with symbols, to develop the logic of a design. Both can be worked up into a more presentable form and used to communicate the principles of a design.{{fact|date=February 2018}}

In architecture, the finished work is expensive and time consuming, so it is important to resolve the design as fully as possible before construction work begins. Complex modern buildings involve a large team of different specialist disciplines, and communication at the early design stages is essential to keep the design moving towards a coordinated outcome.&lt;ref name="BoCo04"&gt;Richard Boland and Fred Collopy (2004). ''Managing as designing''. p.69.&lt;/ref&gt; Architects (and other designers) start investigating a new design with sketches and diagrams, to develop a rough design that provides an adequate response to the particular design problems.{{fact|date=February 2018}}

There are two basic elements to a building design, the aesthetic and the practical. The aesthetic element includes the layout and visual appearance, the anticipated feel of the materials, and cultural references that will influence the way people perceive the building. Practical concerns include space allocated for different activities, how people enter and move around the building, daylight and artificial lighting, acoustics, traffic noise, legal matters and building codes, and many other issues. While both aspects are partly a matter of customary practice, every site is different. Many architects actively seek innovation, thereby increasing the number of problems to be resolved.{{fact|date=February 2018}}

Architectural [[legend]] often refers to designs made on the back of an envelope/napkin/cigarette packet/bubblegum wrapper.&lt;ref&gt;https://www.theguardian.com/artanddesign/2009/mar/08/architecture-exhibition|Le Corbusier's sketch design for his Cabanon&lt;/ref&gt; Initial thoughts are important, even if they have to be discarded along the way, because they provide the central idea around which the design can develop.&lt;ref name=Yee&gt;Rendow Yee (2002). ''Architectural Drawing: A Visual Compendium of Types and Methods''. 2nd Edition. Wiley, 2002.&lt;/ref&gt; Although a sketch is inaccurate, it is disposable and allows for freedom of thought, for trying different ideas quickly. Choice becomes sharply reduced once the design is committed to a scale drawing, and the sketch stage is almost always essential.{{fact|date=February 2018}}

Diagrams are mainly used to resolve practical matters. In the early phases of the design architects use diagrams to develop, explore, and communicate ideas and solutions. They are essential tools for thinking, problem solving, and communication in the design disciplines. Diagrams can be used to resolve spatial relationships, but they can also represent forces and flows, e.g. the forces of sun and wind, or the flows of people and materials through a building.&lt;ref name="YiGr01"&gt;Ellen Yi-Luen Do†&amp; Mark D. Gross (2001). [http://depts.washington.edu/redline1/AIRE264.pdf "Thinking with diagrams in architectural design"]. In: ''Artificial Intelligence Review'' 15: 135–149, 2001.&lt;/ref&gt;

An [[Exploded view drawing|exploded view]] diagram shows component parts dis-assembled in some way, so that each can be seen on its own. These views are common in technical manuals, but are also used in architecture, either in conceptual diagrams or to illustrate technical details. In a [[Cutaway (3D graphics)|cutaway view]] parts of the exterior are omitted to show the interior, or details of internal construction.&lt;ref&gt;Andreas C. Papadakis (1988). ''Deconstruction in Architecture: In Architecture and Urbanism''. p.65.&lt;/ref&gt; Although common in technical illustration, including many building products and systems, the cutaway is in fact little-used in architectural drawing.{{fact|date=February 2018}}

==Types==
Architectural drawings are produced for a specific purpose, and can be classified accordingly. Several elements are often included on the same sheet, for example a sheet showing a plan together with the principal façade.

===Presentation drawings===
Drawings intended to explain a scheme and to promote its merits. Working drawings may include tones or [[hatching|hatches]] to emphasise different materials, but they are diagrams, not intended to appear realistic. Basic presentation drawings typically include people, vehicles and trees, taken from a library of such images, and are otherwise very similar in style to working drawings. [[Artistic rendering|Rendering]] is the art of adding surface textures and shadows to show the visual qualities of a building more realistically. An [[architectural illustrator]] or [[graphic designer]] may be employed to prepare specialist presentation images, usually perspectives or highly finished site plans, floor plans and elevations etc.

===Survey drawings===
Measured drawings of existing land, structures and buildings. Architects need an accurate set of survey drawings as a basis for their working drawings, to establish exact dimensions for the construction work. Surveys are usually measured and drawn up by specialist [[Surveying|land surveyors]].

===Record drawings===
Historically, architects have made record drawings in order to understand and emulate the great architecture known to them. In the Renaissance, architects from all over Europe studied and recorded the remains of the Roman and Greek civilizations, and used these influences to develop the architecture of the period. Records are made both individually, for local purposes, and on a large scale for publication. Historic surveys worth referring to include:
* [[Colen Campbell]]'s ''Vitruvius Brittanicus'', illustrations of English buildings by [[Inigo Jones]] and [[Sir Christopher Wren]], as well as Campbell himself and other prominent architects of the era.
* The [[Survey of London]], founded in 1894 by [[Charles Robert Ashbee]] and now available through [[English Heritage]]. A record of notable streets and individual buildings in the former County of London.
* [[Historic American Buildings Survey]], records of notable buildings drawn up during the 1930s [[Great Depression|Depression]], this collection is held by the Library of Congress and is available copyright-free on the internet.

Record drawings are also used in construction projects, where "as-built" drawings of the completed building take account of all the variations made during the course of construction.

===Working drawings===
A comprehensive set of drawings used in a building construction project: these will include not only architect's drawings but structural and services engineer's drawings etc. Working drawings logically subdivide into location, assembly and component drawings.&lt;ref name=Thompson&gt;Arthur Thompson, Architectural Design Procedures, Second Edition. Architectural Press: Elsevier 2007. {{ISBN|978-0-340-71941-1}}&lt;/ref&gt;
* Location drawings, also called general arrangement drawings, include floor plans, sections and elevations: they show where the construction elements are located.
* Assembly drawings show how the different parts are put together. For example, a wall detail will show the layers that make up the construction, how they are fixed to structural elements, how to finish the edges of openings, and how prefabricated components are to be fitted.
* Component drawings enable self-contained elements e.g. windows and doorsets, to be fabricated in a workshop, and delivered to site complete and ready for installation. Larger components may include roof trusses, cladding panels, cupboards and kitchens. Complete rooms, especially hotel bedrooms and bathrooms, may be made as prefabricated pods complete with internal decorations and fittings.
Traditionally, working drawings would typically combine plans, sections, elevations and some details to provide a complete explanation of a building on one sheet. That was possible because little detail was included, the building techniques involved being common knowledge amongst building professionals. Modern working drawings are much more detailed and it is standard practice to isolate each view on a separate sheet. Notes included on drawings are brief, referring to standardised specification documents for more information. Understanding the layout and construction of a modern building involves studying an often-sizeable set of drawings and documents.

==Drafting==
[[File:Architect.png|thumb|right|Architect at his drawing board (1893).]]
Until the latter part of the [[20th century]], all architectural drawings were manually produced, if not by the architects, then by trained (but less skilled) [[draughtsman|draughtsmen]] (or [[drafter]]s), who did not generate the design, but did make many of the less important decisions. This system has continued with CAD draughting: many design architects have little or no knowledge of CAD software programmes, relying upon others to take their designs beyond the sketch stage. Draughtsmen often specialize in a type of structure, such as residential or commercial, or in a type of construction: timber frame, reinforced concrete, prefabrication, etc.&lt;ref name="BLC07"&gt;[[Bureau of Labor Statistics]]. [http://www.bls.gov/oco/ocos111.htm ''Occupational Outlook Handbook, 2008–09 Edition: Drafters''] dated: 18 December 2007. accessed: 24 September 2008.&lt;/ref&gt;

The traditional tools of the architect were the [[drawing board]] or draughting table, [[T-square]] and [[set square]]s, [[protractor]], [[Compass (drafting)|compasses]], [[pencil]], and [[technical pen|drawing pens]] of different types.&lt;ref name="Yee"/&gt; Drawings were made on [[vellum]], coated [[linen]], and [[tracing paper]]. [[Technical lettering|Lettering]] would either be done by hand, mechanically using a [[stencil]], or a combination of the two. Ink lines were drawn with a [[ruling pen]], a relatively sophisticated device similar to a dip-in pen, but with adjustable line width, capable of producing a very fine controlled line width. Ink pens had to be dipped into ink frequently. Draughtsmen worked standing up, keeping the ink on a separate table to avoid spilling ink on the drawing.{{Citation needed|reason=article|date=July 2009}}

Developments in the 20th century included the [[parallel motion]] drawing board, as well as more complex improvements on the basic T-square. The development of reliable [[Technical pen|technical drawing pens]] allowed for faster draughting and stencilled lettering. [[Letraset]] dry transfer lettering and half-tone sheets were popular from the 1970s until{{when|date=February 2018}} computers made those processes obsolete.{{fact|date=February 2018}}

===CGI and computer-aided design===
[[File:Campus-SKOLKOVO.jpg|thumb|280px|right|Computer generated perspective of the Moscow School of Management, by David Adjaye.]]
[[Computer-aided design]] is the use of computer software to create drawings. Today the vast majority of technical drawings of all kinds are made using CAD. Instead of drawing lines on paper, the computer records equivalent information electronically. There are many advantages to this system: repetition is reduced because complex elements can be copied, duplicated and stored for re-use. Errors can be deleted, and the speed of draughting allows many permutations to be tried before the design is finalised. On the other hand, CAD drawing encourages a proliferation of detail and increased expectations of accuracy, aspects which reduce the efficiency originally expected from the move to computerisation.{{fact|date=February 2018}}
[[File:Construction drawing autocad.jpg|thumb|right|An example of a drawing drafted in [[AutoCAD]]]]
Professional CAD software such as [[AutoCAD]] is complex and requires both training and experience before the operator becomes fully productive. Consequently, skilled CAD operators are often divorced from the design process. Simpler software such as [[SketchUp]] and Vectorworks allows for more intuitive drawing and is intended as a design tool.{{fact|date=February 2018}}

CAD is used to create all kinds of drawings, from working drawings to [[photorealistic]] perspective views. [[Architectural rendering]]s (also called visualisations) are made by creating a three-dimensional model using CAD. The model can be viewed from any direction to find the most useful viewpoints. Different software (for example [[Autodesk 3ds Max]]) is then used to apply colour and texture to surfaces, and to represent shadows and reflections. The result can be accurately combined with photographic elements: people, cars, background landscape.{{fact|date=February 2018}}

[[Building information modeling]] (BIM) is the logical development of CAD drawing, a relatively new technology but fast becoming mainstream. The design team collaborates to create a three-dimensional computer model, and all plans and other two-dimensional views are generated directly from the model, ensuring spatial consistency. The key innovation here is to share the model via the internet, so that all the design functions (site survey, architecture, structure and services) can be integrated into a single model, or as a series of models associated with each specialism that are shared throughout the design development process. Some form of management, not necessarily by the architect, needs to be in place to resolve conflicting priorities. The starting point of BIM is spatial design, but it also enables components to be quantified and scheduled directly from the information embedded in the model.{{fact|date=February 2018}}

An [[architectural animation]] is a short film showing how a proposed building will look: the moving image makes three-dimensional forms much easier to understand. An animation is generated from a series of hundreds or even thousands of still images, each made in the same way as an architectural visualisation. A computer-generated building is created using a CAD programme, and that is used to create more or less realistic views from a sequence of viewpoints. The simplest animations use a moving viewpoint, while more complex animations can include moving objects: people, vehicles, and so on.{{fact|date=February 2018}}

==Architectural reprographics==
{{Main|Architectural reprography}}
[[File:Architectural Drawing of "The House of Tomorrow".JPG|thumb|right|Blueprint]]
Reprographics or reprography covers a variety of technologies, media, and support services used to make multiple copies of original drawings. Prints of architectural drawings are still sometimes called [[blueprint]]s, after one of the early processes which produced a white line on blue paper. The process was superseded by the dye-line print system which prints black on white coated paper ([[Whiteprint]]). The standard modern processes are the [[ink-jet printer]], [[laser printer]] and [[photocopier]], of which the ink-jet and laser printers are commonly used for large-format printing. Although colour printing is now commonplace, it remains expensive above A3 size, and architect's working drawings still tend to adhere to the black and white / greyscale aesthetic.

==See also==
{{Commons category|Architectural drawings}}
{{div col|colwidth=30em}}
* [[Architectural model]]
* [[Copyright in architecture in the United States]]
* [[Drawing]]
* [[Engineering drawing]]
* [[ISO 13567#List of layers in a standard architectural drawing|Layers in a standard architectural drawing]]
* [[Linear scale]]
* [[List of museums with major collections of European prints and drawings]]
* [[Museum for Architectural Drawing]], Berlin, Germany
* [[Multiview orthographic projection]]
* [[Preservation: Library and Archival Science]]
* [[Technical drawing]]
{{div col end}}

==References==
{{reflist|2}}

{{Visualization}}
{{Portal bar|Architecture}}

{{DEFAULTSORT:Architectural Drawing}}
[[Category:Architecture|Drawing]]
[[Category:Technical drawing]]</text>
      <sha1>qdo92dl4llpmmkep0ijm63tb24jq9j3</sha1>
    </revision>
  </page>
  <page>
    <title>Atle Selberg</title>
    <ns>0</ns>
    <id>2021</id>
    <revision>
      <id>845749605</id>
      <parentid>805427708</parentid>
      <timestamp>2018-06-13T21:28:38Z</timestamp>
      <contributor>
        <username>Alaney2k</username>
        <id>209266</id>
      </contributor>
      <minor/>
      <comment>/* Institute for Advanced Study */is "The New York Times"; publisher=&gt;work, replaced: [[New York Times → [[The New York Times, publisher=[[The New York Times]] → work=[[The New York Times]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10389">{{Use dmy dates|date=April 2017}}
{{Infobox scientist
| name = Atle Selberg
| image = Atle Selberg.jpg
| image_size = 
| birth_date = {{Birth date|1917|6|14|df=y}}
| birth_place = [[Langesund]], Norway
| death_date = {{Death date and age|2007|8|6|1917|6|14|df=y}}
| death_place = [[Princeton, New Jersey|Princeton]], [[New Jersey]], United States
| residence =
| nationality = Norwegian
| field = [[Mathematician|Mathematics]]
| alma_mater = [[University of Oslo]]
| academic_advisors = 
| known_for = [[Chowla–Selberg formula]] &lt;br /&gt; [[Critical line theorem]] &lt;br /&gt; [[Maass–Selberg relations]] &lt;br /&gt; [[Selberg class]] &lt;br /&gt; [[Selberg's conjecture]] &lt;br /&gt; [[Selberg integral]] &lt;br /&gt; [[Selberg trace formula]] &lt;br /&gt; [[Selberg zeta function]] &lt;br /&gt; [[Selberg sieve]]
| awards = [[Abel Prize]] (honorary) (2002)&lt;br /&gt; [[Fields Medal]] (1950)&lt;br /&gt; [[Wolf Prize]] (1986)&lt;br /&gt; [[Gunnerus Medal]] (2002)
| influences = [[Srinivasa Ramanujan]]
| spouse = Hedvig Liebermann
}}
'''Atle Selberg''' (14 June 1917 – 6 August 2007) was a Norwegian [[mathematician]] known for his work in [[analytic number theory]], and in the theory of [[automorphic form]]s, in particular bringing them into relation with [[spectral theory]]. He was awarded the [[Fields Medal]] in 1950.

== Early years ==
Selberg was born in [[Langesund]], Norway, the son of teacher Anna Kristina Selberg and mathematician [[Ole Michael Ludvigsen Selberg]]. Two of his brothers also went on to become mathematicians as well, and the remaining one became a professor of engineering. 
&lt;!-- There seems to be no source for the following anecdote, and the reference given does not mention Selberg:
His first result came at age 14 when he found[[Johann Bernoulli]]'s  remarkable 1697 formula
:&lt;math&gt;\sum_{n=1}^\infty n^{-n} = \int_0^1 x^{-x} dx\quad\quad(=1.291285997...)&lt;/math&gt;
which he published as a problem in the book ''Problems and Theorems in Analysis'' (part I, problem 160) by [[Pólya]] and [[Gábor Szegö]].
--&gt;
While he was still at school he was influenced by the work of [[Srinivasa Ramanujan]] and he found an exact analytical formula for the [[Partition (number theory)#Partition function|partition function]] as suggested by the works of Ramanujan; however, this result was first published by [[Hans Rademacher]]. During the war he fought against the German invasion of Norway, and was imprisoned several times. 
He studied at the [[University of Oslo]] and completed his [[Ph.D.]] in 1943.

== World War II ==
During [[World War II]], Selberg worked in isolation due to the [[German occupation of Norway]]. After the war his accomplishments became known, including a proof that a positive proportion of the zeros of the [[Riemann zeta function]] lie on the line &lt;math&gt;\Re(s)=\tfrac{1}{2}&lt;/math&gt;. 
 
After the war, he turned to [[sieve theory]], a previously neglected topic which Selberg's work brought into prominence. In a 1947 paper he introduced the [[Selberg sieve]], a method well adapted in particular to providing auxiliary upper bounds, and which contributed to [[Chen's theorem]], among other important results.

In 1948 Selberg submitted two papers in ''[[Annals of Mathematics]]'' in which he proved by elementary means the theorems for [[primes in arithmetic progression]] and the [[prime number theorem|density of primes]].&lt;ref&gt;{{cite journal|jstor=1969455|
 title=An Elementary Proof of the Prime-Number Theorem| url=https://www.math.lsu.edu/~mahlburg/teaching/handouts/2014-7230/Selberg-ElemPNT1949.pdf| 
 first=Atle|
 last=Selberg|
 journal=Annals of Mathematics|
 year=April 1949|
 pages=305–313|
volume=50|
doi=10.2307/1969455
}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal|jstor= 1969454| 
 title=An Elementary Proof of Dirichlet's Theorem About Primes in Arithmetic Progression|
 first=Atle|
 last=Selbert|
 journal=Annals of Mathematics|
 year=April 1949|
 pages=297–304|
volume=50|
doi=10.2307/1969454 }}&lt;/ref&gt; This challenged the widely held view of his time that certain theorems are only obtainable with the advanced methods of [[complex analysis]]. Both results were based on his work on the asymptotic formula
:&lt;math&gt;\vartheta \left( x \right)\log \left( x \right) + \sum\limits_{p \le x} {\log \left( p \right)} \vartheta \left( {\frac{x}{p}} \right) = 2x\log \left( x \right) + O\left( x \right)&lt;/math&gt;
where
:&lt;math&gt;\vartheta \left( x \right) = \sum\limits_{p \le x} {\log \left( p \right)}&lt;/math&gt;
for primes &lt;math&gt;p&lt;/math&gt;. He established this result by elementary means in March 1948, and by July of that year, Selberg and [[Paul Erdős]] each obtained [[elementary proof]]s of the [[prime number theorem]], both using the asymptotic formula above as a starting point.&lt;ref&gt;{{cite journal|author=Spencer, Joel|author2=Graham, Ronald|title=The Elementary Proof of the Prime Number Theorem|journal=The Mathematical Intelligencer|year=2009|volume=31|issue=3|pages=18–23|url=http://www.cs.nyu.edu/spencer/erdosselberg.pdf|doi=10.1007/s00283-009-9063-9}}&lt;/ref&gt; Circumstances leading up to the proofs, as well as publication disagreements, led to a bitter dispute between the two mathematicians.&lt;ref name=goldfeld&gt;{{Cite journal | last = Goldfeld | first = Dorian | year = 2003 | title = The Elementary Proof of the Prime Number Theorem: an Historical Perspective | journal = Number Theory: New York Seminar | pages = 179–192}}&lt;/ref&gt;&lt;ref name=interview&gt;{{Cite journal|url=http://www.ams.org/bull/2008-45-04/S0273-0979-08-01223-8/S0273-0979-08-01223-8.pdf |first=Nils A.|last= Baas|first2= Christian F.|last2= Skau |journal= Bull. Amer. Math. Soc. |volume=45 |year=2008|pages= 617–649 |title=The lord of the numbers, Atle Selberg. On his life and mathematics|doi=10.1090/S0273-0979-08-01223-8|issue=4}}&lt;/ref&gt;

For his fundamental accomplishments during the 1940s, Selberg received the 1950 [[Fields Medal]].

== Institute for Advanced Study ==
Selberg moved to the United States and settled at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]] in the 1950s where he remained until his death. During the 1950s he worked on introducing [[spectral theory]] into [[number theory]], culminating in his development of the [[Selberg trace formula]], the most famous and influential of his results. In its simplest form, this establishes a duality between the lengths of [[closed geodesic]]s on a [[compact Riemann surface]] and the [[eigenvalue]]s of the [[Laplace-Beltrami operator|Laplacian]], which is analogous to the duality between the [[prime number]]s and the zeros of the zeta function.

He was awarded the 1986 [[Wolf Prize in Mathematics]]. He was also awarded an honorary [[Abel Prize]] in 2002, its founding year, before the awarding of the regular prizes began.

Selberg received many distinctions for his work in addition to the [[Fields Medal]], the [[Wolf Prize]] and the [[Gunnerus Medal]]. He was elected to the [[Norwegian Academy of Science and Letters]], the [[Royal Danish Academy of Sciences and Letters]] and the [[American Academy of Arts and Sciences]].

In 1972 he was awarded an [[honorary degree]], doctor philos. honoris causa, at the [[Norwegian Institute of Technology]], later part of [[Norwegian University of Science and Technology]].&lt;ref&gt;{{cite web |url=http://www.ntnu.edu/phd/honorary-doctors|title=Honorary doctors at NTNU|publisher=Norwegian University of Science and Technology}}&lt;/ref&gt;

Selberg had two children, Ingrid Selberg and Lars Selberg. Ingrid Selberg is married to playwright [[Mustapha Matura]].

He died at home in Princeton on 6 August 2007 of heart failure.&lt;ref&gt;{{cite news |first= |last= |authorlink= |coauthors= |title=Atle Selberg, 90, Lauded Mathematician, Dies |work=[[The New York Times]] |date=17 August 2007|url=https://www.nytimes.com/2007/08/17/nyregion/17selberg.html}}&lt;/ref&gt;

== Selected publications ==
* ''Atle Selberg Collected Papers: 1'' (Springer-Verlag, Heidelberg), {{isbn|0-387-18389-2}}
* ''Collected Papers'' (Springer-Verlag, Heidelberg Mai 1998), {{isbn|3-540-50626-8}}

== References ==
{{reflist}}

==Further reading==
* Albers, Donald J. and [[Gerald L. Alexanderson|Alexanderson, Gerald L.]] (2011), ''Fascinating Mathematical People: interviews and memoirs'', "Atle Selberg", pp 254–73, [[Princeton University Press]], {{isbn|978-0-691-14829-8}}.
* {{Cite journal|url=http://www.ams.org/bull/2008-45-04/S0273-0979-08-01223-8/
|first=Nils A.|last= Baas|first2= Christian F.|last2= Skau
|journal= Bull. Amer. Math. Soc. |volume=45 |year=2008|pages= 617–649
|title=The lord of the numbers, Atle Selberg. On his life and mathematics|doi=10.1090/S0273-0979-08-01223-8|issue=4}} Interview with Selberg
*{{Cite journal | author = [[Dennis Hejhal|Hejhal, Dennis]] |date=June–July 2009 | title = Remembering Atle Selberg, 1917–2007 | journal = [[Notices of the American Mathematical Society]] | volume = 56
  | issue = 6 | pages = 692–710 | url = http://www.ams.org/notices/200906/rtx090600692p-corrected.pdf
  | format = PDF}}
* {{Cite web|last=Selberg |url=http://www.ias.ac.in/resonance/Dec1996/pdf/Dec1996Reflections.pdf |title=Reflections Around the Ramanujan Centenary|year=1996}}

==External links==
{{Commons category|Atle Selberg}}
* {{MathGenealogy|id=121277}}
* {{Britannica|533117}}
* {{MacTutor Biography|id=Selberg}}
* [http://publications.ias.edu/selberg  Atle Selberg Archive webpage]
* [http://www.ias.edu/news/press-releases/2009-30 Obituary at IAS]
* [http://www.timesonline.co.uk/tol/comment/obituaries/article2477242.ece Obituary in ''The Times'']
* [http://arkivportalen.no/side/arkiv/detaljer?arkivId=no-NTNU_arkiv000000008702 Atle Selbergs private archive] exists at NTNU University Library [https://www.ntnu.no/ub/bibliotek/dora Dorabiblioteket]

{{Fields medalists}}
{{Wolf Prize in Mathematics}}

{{Authority control}}

{{DEFAULTSORT:Selberg, Atle}}
[[Category:1917 births]]
[[Category:2007 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Fields Medalists]]
[[Category:Institute for Advanced Study faculty]]
[[Category:Members of the Royal Danish Academy of Sciences and Letters]]
[[Category:Members of the Norwegian Academy of Science and Letters]]
[[Category:Norwegian emigrants to the United States]]
[[Category:Norwegian mathematicians]]
[[Category:Number theorists]]
[[Category:People from Bamble]]
[[Category:University of Oslo alumni]]
[[Category:Wolf Prize in Mathematics laureates]]</text>
      <sha1>dfqwne5tk0k7ml7vklf1dmkmtuqoo0m</sha1>
    </revision>
  </page>
  <page>
    <title>Borel determinacy theorem</title>
    <ns>0</ns>
    <id>15483838</id>
    <revision>
      <id>814727948</id>
      <parentid>814727887</parentid>
      <timestamp>2017-12-10T15:33:43Z</timestamp>
      <contributor>
        <username>Gaiacarra</username>
        <id>536057</id>
      </contributor>
      <comment>/* Gale&amp;ndash;Stewart games */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12597">In [[descriptive set theory]], the '''Borel determinacy theorem''' states that any Gale–Stewart game whose payoff set is a [[Borel set]] is [[Determinacy|determined]], meaning that one of the two players will have a winning [[strategy]] for the game.

The theory was proved by [[Donald A. Martin]] in 1975, and is being applied in descriptive [[set theory]] to show that Borel sets in [[Polish space]]s have regularity properties such as the [[perfect set property]] and the [[property of Baire]].

The theorem is also known for its [[metamathematics|metamathematical]] properties. In 1971, before the theorem was proved, [[Harvey Friedman]] showed that any proof of the theorem in [[Zermelo–Fraenkel set theory]] must make repeated use of the [[axiom of replacement]]. Later results showed that stronger determinacy theorems cannot be proven in Zermelo–Fraenkel set theory, although they are relatively [[consistent]] with it, if certain [[large cardinals]] are consistent.

== Background ==

=== Gale&amp;ndash;Stewart games ===
{{main|Determinacy}}

A '''Gale&amp;ndash;Stewart''' game is a two-player game of perfect information. The game is defined using a set ''A'', and is denoted ''G''&lt;sub&gt;''A''&lt;/sub&gt;. The two players alternate turns, and each player is aware of all moves before making the next one. On each turn, each player chooses a single element of ''A'' to play. The same element may be chosen more than once without restriction. The game can be visualized through the following diagram, in which the moves are made from left to right, with the moves of player I above and the moves of player II below.

&lt;center&gt;
&lt;math&gt;
\begin{matrix}
\mathrm{I} &amp;  a_1 &amp; \quad &amp; a_3 &amp; \quad &amp; a_5 &amp; \quad &amp; \cdots\\
\mathrm{II} &amp;  \quad &amp; a_2 &amp; \quad &amp; a_4 &amp; \quad &amp; a_6 &amp; \cdots
\end{matrix}
&lt;/math&gt;
&lt;/center&gt;

The play continues without end, so that a single play of the game determines an infinite sequence &lt;math&gt;\langle a_1,a_2,a_3\ldots\rangle&lt;/math&gt; of elements of ''A''. The set of all such sequences is denoted ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt;.    The players are aware, from the beginning of the game, of a fixed '''payoff set''' (a.k.a. ''winning set'') that will determine who wins.   The payoff set is a [[subset]] of ''A''&lt;sup&gt;ω&lt;/sup&gt;. If the infinite sequence created by a play of the game is in the payoff set, then player I wins. Otherwise, player II wins; there are no ties.

This definition initially does not seem to include traditional perfect information games such as chess, since the set of moves available in such games changes every turn. However, this sort of case can be handled by declaring that a player who makes an illegal move loses immediately, so that the Gale-Stewart notion of a game does in fact generalize the concept of a game defined by a [[game tree]].

=== Winning strategies ===
A '''winning strategy''' for a player is a function that tells the player what move to make from any position in the game, such that if the player follows the function he or she will surely win.  More specifically, a winning strategy for player I is a function ''f'' that takes as input sequences of elements of A of even length and returns an element of ''A'', such that player I will win every play of the form
&lt;center&gt;
&lt;math&gt;
\begin{matrix}
\mathrm{I} &amp;  a_1 = f(\langle \rangle) &amp; \quad &amp; a_3 = f(\langle a_1, a_2\rangle)&amp; \quad &amp; a_5 = f(\langle a_1, a_2, a_3, a_4\rangle) &amp; \quad &amp; \cdots\\
\mathrm{II} &amp;  \quad &amp; a_2 &amp; \quad &amp; a_4 &amp; \quad &amp; a_6 &amp; \cdots.
\end{matrix}
&lt;/math&gt;
&lt;/center&gt;
A winning strategy for player II is a function ''g'' that takes odd-length sequences of elements of ''A'' and returns elements of ''A'', such that player II will win every play of the form
&lt;center&gt;
&lt;math&gt;
\begin{matrix}
\mathrm{I} &amp;  a_1 &amp; \quad &amp; a_3 &amp; \quad &amp; a_5 &amp; \quad &amp; \cdots\\
\mathrm{II} &amp;  \quad &amp; a_2 = g(\langle a_1\rangle)&amp; \quad &amp; a_4  = g(\langle a_1,a_2,a_3\rangle) &amp; \quad &amp; a_6 = g(\langle a_1,a_2,a_3,a_4,a_5\rangle) &amp; \cdots .
\end{matrix}
&lt;/math&gt;
&lt;/center&gt;

At most one player can have a winning strategy; if both players had winning strategies, and played the strategies against each other, only one of the two strategies could win that play of the game.   If one of the players has a winning strategy for a particular payoff set, that payoff set is said to be '''determined'''.

=== Topology ===
For a given set ''A'', whether a subset of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; will be determined depends to some extent on its topological structure. For the purposes of Gale&amp;ndash;Stewart games, the set ''A'' is endowed with the [[discrete topology|discrete]] [[topology]], and ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; endowed with the resulting [[product topology]], where ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; is viewed as a [[countably infinite]] [[topological product]] of ''A'' with itself.  In particular, when ''A'' is the set {0,1}, the topology defined on ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; is exactly the ordinary topology on [[Cantor space]], and when ''A'' is the set of natural numbers, it is the ordinary topology on [[Baire space]].

The set ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; can be viewed as the set of paths through a certain [[Tree (descriptive set theory)|tree]], which leads to a second characterization of its topology. The tree consists of all finite sequences of elements of ''A'', and the children of a particular node &amp;sigma; of the tree are exactly the sequences that extend &amp;sigma; by one element. Thus if ''A'' = { 0, 1 }, the first level of the tree consists of the sequences &amp;lang; 0 &amp;rang; and &amp;lang; 1 &amp;rang;; the second level consists of the four sequences &amp;lang; 0, 0 &amp;rang;, &amp;lang; 0, 1 &amp;rang;, &amp;lang; 1, 0 &amp;rang;, &amp;lang; 1, 1 &amp;rang;; and so on.  For each of the finite sequences &amp;sigma; in the tree, the set of all elements of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; that begin with &amp;sigma; is a [[basis (topology)|basic open set]] in the topology on ''A''. The [[open set]]s of ''A''&lt;sup&gt;ω&lt;/sup&gt; are precisely the sets expressible as unions of these basic open sets. The [[closed set]]s, as usual, are those whose complement is open.

The [[Borel set]]s of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; are the smallest class of subsets of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; that includes the open sets and is closed under complement and countable union. That is, the Borel sets are the smallest [[sigma-algebra|&amp;sigma;-algebra]] of subsets of ''A''&lt;sup&gt;ω&lt;/sup&gt; containing all the open sets. The Borel sets are classified in the [[Borel hierarchy]] based on how many times the operations of complement and countable union are required to produce them from open sets.

== Previous results ==
Gale and Stewart (1953) proved that if the payoff set is an [[open set|open]] or [[closed set|closed]] subset of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; then the Gale&amp;ndash;Stewart game with that payoff set is always determined. Over the next twenty years, this was extended to slightly higher levels of the [[Borel hierarchy]] through ever more complicated proofs.  This led to the question of whether the game must be determined whenever the payoff set is a [[Borel set|Borel subset]] of ''A''&lt;sup&gt;ω&lt;/sup&gt;.  It was known that, using the [[axiom of choice]], it is possible to construct a subset of {0,1}&lt;sup&gt;ω&lt;/sup&gt; that is not determined (Kechris 1995, p.&amp;nbsp;139).

[[Harvey Friedman]] (1971) proved that any proof that all Borel subsets of Cantor space ({0,1}&lt;sup&gt;ω&lt;/sup&gt; ) were determined would require repeated use of the [[axiom of replacement]], an axiom not typically required to prove theorems about "small" objects such as Cantor space.

== Borel determinacy ==
[[Donald A. Martin]] (1975) proved that for any set ''A'', all Borel subsets of ''A''&lt;sup&gt;ω&lt;/sup&gt; are determined. Because the original proof was quite complicated, Martin published a shorter proof in 1982 that did not require as much technical machinery. In his review of Martin's paper, Drake describes the second proof as "surprisingly straightforward."

The field of [[descriptive set theory]] studies properties of [[Polish space]]s (essentially, complete separable metric spaces). The Borel determinacy theorem has been used to establish many properties of Borel subsets of these spaces. For example, all Borel subsets of Polish spaces have the [[perfect set property]] and the [[property of Baire]].

== Set-theoretic aspects ==
The Borel determinacy theorem is of interest for its [[metamathematics|metamethematical]] properties as well as its consequences in descriptive set theory.

Determinacy of closed sets of ''A''&lt;sup&gt;&amp;omega;&lt;/sup&gt; for arbitrary ''A'' is equivalent to the [[axiom of choice]] over [[Zermelo-Fraenkel set theory|ZF]] (Kechris 1995, p.&amp;nbsp;139). When working in  set-theoretical systems where the axiom of choice is not assumed, this can be circumvented by considering generalized strategies known as '''quasistrategies''' (Kechris 1995, p.&amp;nbsp;139) or by only considering games where ''A'' is the set of natural numbers, as in the [[axiom of determinacy]].

'''Zermelo set theory''' (Z) is [[Zermelo–Fraenkel set theory]] without the axiom of replacement. It differs from ZF in that Z does not prove that the [[power set]] operation can be iterated uncountably many times beginning with an arbitrary set.  In particular, ''V''&lt;sub&gt;&amp;omega; + &amp;omega;&lt;/sub&gt;, a particular countable level of the [[cumulative hierarchy]], is a model of Zermelo set theory.  The axiom of replacement, on the other hand, is only satisfied by ''V''&lt;sub&gt;κ&lt;/sub&gt; for significantly larger values of κ, such as when κ is a [[strongly inaccessible cardinal]]. Friedman's theorem of 1971 showed that there is a model of Zermelo set theory (with the axiom of choice) in which Borel determinacy fails, and thus Zermelo set theory cannot prove the Borel determinacy theorem.

== Stronger forms of determinacy ==
{{Main|Determinacy}}
Several set-theoretic principles about determinacy stronger than Borel determinacy are studied in descriptive set theory. They are closely related to [[large cardinal axiom]]s.

The [[axiom of projective determinacy]] states that all [[projective set|projective]] subsets of a Polish space are determined. It is known to be unprovable in ZFC but relatively consistent with it and implied by certain [[large cardinal]] axioms. The existence of a [[measurable cardinal]] is enough to imply over ZFC that all [[analytic set|analytic subsets]] of Polish spaces are determined.

The [[axiom of determinacy]] states that all subsets of all Polish spaces are determined. It is inconsistent with ZFC but in ZF + DC (Zermelo-Fraenkel set theory plus the [[axiom of dependent choice]]) it is equiconsistent with certain large cardinal axioms.

== References ==
* {{cite journal
  | first = Harvey
  | last = Friedman
  | title = Higher set theory and mathematical practice
  | journal = Annals of Mathematical Logic
  | volume=2
  | year=1971
  | pages=325&amp;ndash;357
  | doi = 10.1016/0003-4843(71)90018-0
  | issue = 3
}}
** L. Bukovský, reviewer, [[Mathematical Reviews]], {{MR|284327}}.
* {{cite book
  | author= Gale, D. and F. M. Stewart
  | chapter=Infinite games with perfect information
  | title=Contributions to the theory of games, vol. 2
  | year=1953
  | series=Annals of Mathematical Studies, vol. 28
  | volume=28 
  | pages=245&amp;ndash;266
  | publisher=Princeton University Press
}}
** S. Sherman, reviewer, [[Mathematical Reviews]], {{MR|54922}}.
*{{cite book
 | author = Alexander Kechris
 | authorlink = Alexander S. Kechris
 | title = Classical descriptive set theory
 | series = [[Graduate Texts in Mathematics]]
 | volume = 156
 | year = 1995
 | isbn = 0-387-94374-9
}}
* {{cite journal
 | author=Martin, Donald A.
 | title=Borel determinacy
 | journal=[[Annals of Mathematics]] |series=Second Series
 | volume=102 
 | issue=2
 | pages=363–371
 | year=1975
 | doi=10.2307/1971035
}}
** John Burgess, reviewer. [[Mathematical Reviews]], {{MR|403976}}.
* {{cite book
 | first= Donald A. 
 | last=Martin 
 | chapter=A purely inductive proof of Borel determinacy
 | title= Recursion theory
 | pages=303&amp;ndash;308 
 | publisher= 
 | date= 1982
 | series=Proc. Sympos. Pure Math
 | edition=Proceedings of the AMS&amp;ndash;ASL summer institute held in Ithaca, New York 
}}
**F. R. Drake, reviewer, [[Mathematical Reviews]], {{MR|791065}}.

== External links ==
* ''[http://www.cas.unt.edu/~rdb0003/thesis/thesis.pdf Borel determinacy and metamathematics]''. Ross Bryant. Master's thesis, University of North Texas, 2001.
* [http://plato.stanford.edu/entries/large-cardinals-determinacy/ "Large Cardinals and Determinacy"] at the [[Stanford Encyclopedia of Philosophy]]

[[Category:Determinacy]]
[[Category:Theorems in the foundations of mathematics]]</text>
      <sha1>pgaezeivfsbvct57002s8sok66375az</sha1>
    </revision>
  </page>
  <page>
    <title>Bowen ratio</title>
    <ns>0</ns>
    <id>224300</id>
    <revision>
      <id>853677253</id>
      <parentid>792048035</parentid>
      <timestamp>2018-08-06T08:43:38Z</timestamp>
      <contributor>
        <username>JeopardyTempest</username>
        <id>3220485</id>
      </contributor>
      <comment>I believe this definition would be better for including the meteorology side of it, as I believe the Bowen ratio is used for land surfaces as well, and so the words water body may confuse?  Please do correct me if I'm wrong, I am not 100% certain, it's been a while.  And if there's a better word to convey both applications, please do feel free to change!</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3333">In [[meteorology]] and [[hydrology]], the '''Bowen ratio''' is used to describe the type of [[heat transfer]] for a surface that has moisture.  Heat transfer can either occur as [[sensible heat]] (differences in temperature without [[evapotranspiration]]) or [[latent heat]] (the energy required during a change of state, without a change in temperature).  The Bowen ratio is the mathematical method generally used to calculate heat lost (or gained) in a substance; it is the ratio of energy fluxes from one state to another by [[sensible heat]] and latent heating respectively. It is calculated by the equation: 

: &lt;math&gt;B = {\frac{Q_h}{Q_e}}&lt;/math&gt;,

where &lt;math&gt;Q_h&lt;/math&gt; is sensible heating and &lt;math&gt;Q_e&lt;/math&gt; is latent heating.  The quantity was named by [[Harald Sverdrup (oceanographer)|Harald Sverdrup]] after [[Ira Sprague Bowen]] (1898–1973), an [[Astrophysics|astrophysicist]] whose theoretical work on evaporation to air from water bodies made first use of it, and it is used most commonly in [[meteorology]] and [[hydrology]].  In this context, when the magnitude of &lt;math&gt;B&lt;/math&gt; is less than one, a greater proportion of the available energy at the surface is passed to the atmosphere as latent heat than as sensible heat, and the converse is true for values of &lt;math&gt;B&lt;/math&gt; greater than one.  As &lt;math&gt;{Q_e \rightarrow 0}&lt;/math&gt;, however, &lt;math&gt;B&lt;/math&gt; becomes unbounded making the Bowen ratio a poor choice of variable for use in formulae, especially for arid surfaces.  For this reason the [[evaporative fraction]] is sometimes a more appropriate choice of variable representing the relative contributions of the turbulent energy fluxes to the surface energy budget.

The Bowen ratio is related to the evaporative fraction, &lt;math&gt;EF&lt;/math&gt;, through the equation,

: &lt;math&gt;{EF = \frac{Q_e}{Q_e + Q_h} = \frac{1}{1+B}}&lt;/math&gt;.

The Bowen ratio is an indicator of the type of surface. The Bowen ratio, &lt;math&gt;{B}&lt;/math&gt;, is less than one over surfaces with abundant water supplies.

{| class="wikitable"
|-
! Type of surface !! Range of Bowen ratios
|-
| Deserts || &gt;10.0
|-
| Semi-arid landscapes || 2.0-6.0
|-
| Temperate forests and grasslands || 0.4-0.8
|-
| Tropical rainforests || 0.1-0.3
|-
| Tropical oceans || &lt;0.1
|}


==See also==
*[[Meteorology]]
*[[Hydrology]]
*[[Latent heat]]
*[[Sensible heat]]

==References==
* Bowen, I.S., 1926: The ratio of heat losses by conduction and by evaporation from any water surface.  ''[[Physical Review]]'', 27, pp 779–787.
* Lewis, J.M., 1995: The Story behind the Bowen Ratio. ''[[Bulletin of the American Meteorological Society]]'', 76, pp 2433–2443. [http://ams.allenpress.com/amsonline/?request=get-abstract&amp;issn=1520-0477&amp;volume=076&amp;issue=12&amp;page=2433]
* Sturman, A.P., &amp; Tapper, N.J., 1996: ''[[The Weather and Climate of Australia and New Zealand]]'', pp 309-310.

==External links==
* [https://web.archive.org/web/20030327074553/http://www.nsdl.arm.gov/Library/glossary.shtml#bowen_ratio National Science Digital Library - Bowen Ratio]
* [ftp://195.37.229.5/pub/outgoing/jwinder/BowenRatioLiterature/Lewis_BullAmeriMeteoSoc_1995.pdf The Story behind the Bowen Ratio]{{dead link|date=November 2016 |bot=InternetArchiveBot |fix-attempted=yes }}

[[Category:Ratios]]
[[Category:Thermodynamics]]
[[Category:Atmospheric thermodynamics]]

{{physics-stub}}</text>
      <sha1>1cvbti05r7a3yvliovjfjlcxstqatow</sha1>
    </revision>
  </page>
  <page>
    <title>Buffon's noodle</title>
    <ns>0</ns>
    <id>12784536</id>
    <revision>
      <id>801258196</id>
      <parentid>740777744</parentid>
      <timestamp>2017-09-18T16:55:56Z</timestamp>
      <contributor>
        <username>Shaded0</username>
        <id>5264861</id>
      </contributor>
      <minor/>
      <comment>/* Bending the needle */clean up and formatting, [[WP:AWB/T|typo(s) fixed]]: Therefore → Therefore, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3559">In [[geometric probability]], the problem of '''Buffon's noodle''' is a variation on the well-known problem of [[Buffon's needle]], named after [[Georges-Louis Leclerc, Comte de Buffon]] who lived in the 18th century. That problem solved by Buffon was the earliest geometric probability problem to be solved.

==Buffon's needle==
{{main|Buffon's needle}}
Suppose there exist an infinite number of equally spaced parallel lines, and we were to randomly toss a needle whose length is less than or equal to the distance between adjacent lines. What is the probability that the needle will cross a line?  The formula is &lt;math&gt;P = 2 L / \pi D&lt;/math&gt;, where ''D'' is the distance between two adjacent lines, and ''L'' is the length of the needle.

==Bending the needle==

The interesting thing about the formula is that it stays the same even when you bend the needle in any way you want (subject to the constraint that it must lie in a plane), making it a "noodle"—a rigid [[plane curve]]. We drop the assumption that the length of the noodle is no more than the distance between the parallel lines.

The [[probability distribution]] of the number of crossings depends on the shape of the noodle, but the [[expected value|expected number]] of crossings does not; it depends only on the length ''L'' of the noodle and the distance ''D'' between the parallel lines (observe that a curved noodle may cross a single line multiple times).

This fact may be proved as follows (see Klain and Rota). First suppose the noodle is [[piecewise linear curve|piecewise linear]], i.e. consists of ''n'' straight pieces. Let ''X''&lt;sub&gt;''i''&lt;/sub&gt; be the number of times the ''i''th piece crosses one of the parallel lines. These random variables are not [[statistical independence|independent]], but the expectations are still additive due to the [[Expected value#Linearity|linearity of expectation]]:

:&lt;math&gt; E(X_1+\cdots+X_n) = E(X_1)+\cdots+E(X_n). &lt;/math&gt;

Regarding a curved noodle as the limit of a sequence of piecewise linear noodles, we conclude that the expected number of crossings per toss is proportional to the length; it is some constant times the length ''L''. Then the problem is to find the constant. In case the noodle is a circle of diameter equal to the distance ''D'' between the parallel lines, then ''L'' = π''D'' and the number of crossings is exactly 2, with probability 1. So when ''L'' = π''D'' then the expected number of crossings is 2. Therefore, the expected number of crossings must be 2''L''/(π''D'').

There is one more surprising consequence. In case the noodle is any closed [[curve of constant width]] D the number of crossings is also exactly 2. This implies [[Barbier's theorem]] asserting that the perimeter is the same as that of a circle.

== References ==
* {{Cite journal
| doi = 10.2307/2317945
| issn = 0002-9890
| volume = 76
| issue = 8, October 1969
| pages = 916–918
| last = Ramaley
| first = J. F.
| title = Buffon's Noodle Problem
| journal = [[The American Mathematical Monthly]]
| year = 1969
| publisher = Mathematical Association of America
| jstor = 2317945
}}
* {{Cite book | year=1997 | title = Introduction to geometric probability | author1=Daniel A. Klain | author2=Gian-Carlo Rota | publisher=[[Cambridge University Press]] | isbn=978-0-521-59654-1 | url=https://books.google.com/books?id=Q1ytkNM6BtAC&amp;pg=PA1 | authorlink2=Gian-Carlo Rota | postscript=&lt;!--None--&gt;}}

==External links==
* [http://www.cut-the-knot.org/Curriculum/Probability/Buffon.shtml Interactive math page]

[[Category:Integral geometry]]</text>
      <sha1>akn4sivnwxeunr2ac7r3rejinkwalqi</sha1>
    </revision>
  </page>
  <page>
    <title>CDMF</title>
    <ns>0</ns>
    <id>10605858</id>
    <revision>
      <id>772049493</id>
      <parentid>722521468</parentid>
      <timestamp>2017-03-25T01:14:07Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* References */convert deprecated magic links to template usage, update CS1 params in templates - [[WP:Bots/Requests for approval/PrimeBOT 13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2339">In [[cryptography]], '''CDMF''' ('''Commercial Data Masking Facility''') is an algorithm developed at [[IBM]] in 1992 to reduce the security strength of the [[56-bit encryption|56-bit]] [[Data Encryption Standard|DES]] cipher to that of [[40-bit encryption]], at the time a requirement of U.S. restrictions on [[export of cryptography]]. Rather than a separate cipher from DES, CDMF constitutes a [[key generation]] algorithm, called ''key shortening''. It is one of the cryptographic algorithms supported by [[S-HTTP]].

==Algorithm==
Like DES, CDMF accepts a 64-bit input [[key (cryptography)|key]], but not all bits are used.
The algorithm consists of the following steps:

#Clear bits 8, 16, 24, 32, 40, 48, 56, 64 (ignoring these bits as DES does).
#[[XOR]] the result with its encryption under DES using the key 0xC408B0540BA1E0AE.
#Clear bits 1, 2, 3, 4, 8, 16, 17, 18, 19, 20, 24, 32, 33, 34, 35, 36, 40, 48, 49, 50, 51, 52, 56, 64.
#Encrypt the result under DES using the key 0xEF2C041CE6382FE6.

The resulting 64-bit data is to be used as a DES key. Due to step 3, a [[brute force attack]] needs to test only 2&lt;sup&gt;40&lt;/sup&gt; possible keys.

==References==
* {{cite journal
    |author1=D.B. Johnson |author2=S.M. Matyas |author3=A.V. Le |author4=J.D. Wilkins | title = The Commercial Data Masking Facility (CDMF) data privacy algorithm
    | journal = IBM Journal of Research and Development
    | volume = 38
    | issue = 2
    | pages = 217&amp;ndash;226
    | publisher = IBM
    | date = March 1994
    | url = http://domino.watson.ibm.com/tchjr/journalindex.nsf/0/a453914c765e690085256bfa0067f9f4?OpenDocument
    | format = [[PDF]]
    | accessdate = April 11, 2007
    | doi = 10.1147/rd.382.0217 }}
* {{US patent|5323464}}, IBM's patent on CDMF
* [http://www.isg.rhul.ac.uk/~cjm/ISO-register/0005.pdf ISO/IEC9979-0005 Register Entry (PDF)], registered October 29, 1994
* {{cite book
    | last = Schneier
    | first = Bruce
    | authorlink = Bruce Schneier
    | title = Applied Cryptography
    | edition = 2nd
    | publisher = [[John Wiley &amp; Sons]]
    | date = 1996
    | page = 366
    | isbn = 0-471-11709-9 }}
* {{IETF RFC|2660}}, defines S-HTTP

{{DEFAULTSORT:Cdmf}}
[[Category:Cryptographic algorithms]]
[[Category:Data Encryption Standard]]
[[Category:Key management]]
[[Category:Block ciphers]]


{{crypto-stub}}</text>
      <sha1>4koptsr1j5boq9f41r3n999362ndur3</sha1>
    </revision>
  </page>
  <page>
    <title>Constant (mathematics)</title>
    <ns>0</ns>
    <id>24758132</id>
    <revision>
      <id>871180483</id>
      <parentid>871180347</parentid>
      <timestamp>2018-11-29T13:40:18Z</timestamp>
      <contributor>
        <ip>134.100.120.181</ip>
      </contributor>
      <comment>/* Constant function */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6183">{{refimprove|date=August 2012}}
{{for|a narrower treatment related to this subject|Mathematical constant}}
In [[mathematics]], the adjective '''constant''' means non-varying. The noun '''constant''' may have two different meanings. It may refer to a fixed and well-defined number or other [[mathematical object]]. The term [[mathematical constant]] (and also [[physical constant]]) is sometimes used to distinguish this meaning from the other one.  A '''constant''' may also refer to a [[constant function]] or its [[value (mathematics)|value]] (it is a common usage to identify them). Such a constant is commonly represented by a [[variable (mathematics)|variable]] which does not depend on the main variable(s) of the studied problem. This is the case, for example, for a [[constant of integration]] which is an arbitrary constant function (not depending on the variable of integration) added to a particular [[antiderivative]] to get all the antiderivatives of the given function.

For example, a general quadratic function is commonly written as:

:&lt;math&gt;a x^2 + b x + c\, ,&lt;/math&gt;

where ''a'', ''b'' and ''c'' are constants (or parameters), while ''x'' is the variable, a placeholder for the argument of the function being studied. A more explicit way to denote this function is

:&lt;math&gt;x\mapsto a x^2 + b x + c \, ,&lt;/math&gt;

which makes the function-argument status of ''x'' clear, and thereby implicitly the constant status of ''a'', ''b'' and ''c''. In this example ''a'', ''b'' and ''c'' are [[coefficient]]s of the polynomial. Since ''c'' occurs in a term that does not involve ''x'', it is called the [[Constant term|constant term of the polynomial]] and can be thought of as the coefficient of ''x''&lt;sup&gt;0&lt;/sup&gt;; any polynomial term or expression of [[Degree of a polynomial|degree]] zero is a constant.&lt;ref&gt;{{cite book | last = Foerster | first = Paul A. | title = Algebra and Trigonometry: Functions and Applications, Teacher's Edition | edition = Classics | year = 2006 | isbn = 0-13-165711-9 | publisher = [[Prentice Hall]] | location = Upper Saddle River, NJ}}&lt;/ref&gt;{{rp|18}}

== Constant function ==
{{Main|Constant function|Nullary}}

A constant may be used to define a [[constant function]] that ignores its arguments and always gives the same value. A constant function of a single variable, such as &lt;math&gt;f(x)=5&lt;/math&gt;, has a [[graph of a function|graph]] that is a horizontal straight line, parallel to the ''x''-axis. Such a function always takes the same value (in this case, 5) because its argument does not appear in the expression defining the function.

== Context-dependence ==

The context-dependent nature of the concept of "constant" can be seen in this example from elementary calculus:

:&lt;math&gt;\begin{align}
\frac{d}{dx} 2^x  &amp; = \lim_{h\to 0} \frac{2^{x+h} - 2^x} h = \lim_{h\to 0} 2^x\frac{2^h - 1} h \\[8pt]
&amp; = 2^x \lim_{h\to 0} \frac{2^h - 1} h &amp; &amp; \text{since } x \text{ is constant (i.e. does not depend on } h\text{)} \\[8pt]
 &amp; = 2^x \cdot\mathbf{constant,} &amp; &amp; \text{where }\mathbf{constant}\text{ means not depending on } x.
\end{align}&lt;/math&gt;
"Constant" means not depending on some variable; not changing as that variable changes. In the first case above, it means not depending on&amp;nbsp;''h''; in the second, it means not depending on&amp;nbsp;''x''.

==Notable mathematical constants==
{{main|Mathematical constant}}
Some values occur frequently in mathematics and are conventionally denoted by a specific symbol. These standard symbols and their values are called mathematical constants. Examples include:
* 0 ([[zero]]).
* 1 ([[one]]), the [[natural number]] after zero.
* {{pi}} ([[pi]]), the constant representing the [[ratio]] of a circle's circumference to its diameter, approximately equal to 3.141592653589793238462643...&lt;ref&gt;{{cite book | last = Arndt | first = Jörg | last2 = Haenel | first2 = Christoph | title = Pi – Unleashed | page = 240 | year = 2001 | publisher = Springer | isbn = 978-3540665724}}&lt;/ref&gt;
* ''[[e (mathematical constant)|e]]'', approximately equal to 2.718281828459045235360287...
* ''i'', the [[imaginary unit]] such that ''i''&lt;sup&gt;2&lt;/sup&gt; = −1.
* &lt;math alt="Square root of 2"&gt;\sqrt{2}&lt;/math&gt; ([[square root of 2]]), the length of the diagonal of a square with unit sides, approximately equal to 1.414213562373095048801688.
* ''φ'' ([[golden ratio]]), approximately equal to 1.618033988749894848204586, or algebraically, &lt;math&gt;1+ \sqrt{5} \over 2&lt;/math&gt;.

==Constants in calculus==
In [[calculus]], constants are treated in several different ways depending on the operation. For example, the [[derivative]] of a constant function is zero. This is because the derivative measures the rate of change of a function with respect to a variable, and since constants, by definition, do not change, their derivative is therefore zero. Conversely, when [[Antiderivative|integrating]] a constant function, the constant is multiplied by the variable of integration. During the evaluation of a [[limit (mathematics)|limit]], the constant remains the same as it was before and after evaluation.

Integration of a function of one variable often involves a [[constant of integration]]. This arises because of the integral operator's nature as the inverse of the [[derivative|differential operator]], meaning the aim of integration is to recover the original function before differentiation. The differential of a constant function is zero, as noted above, and the differential operator is a linear operator, so functions that only differ by a constant term have the same derivative. To acknowledge this, a constant of integration is added to an [[indefinite integral]]; this ensures that all possible solutions are included. The constant of integration is generally written as 'c' and represents a constant with a fixed but undefined value.

===Examples===
If {{math|''f''}} is the constant function such that &lt;math&gt;f(x)=72&lt;/math&gt; for every {{math|''x''}} then
:&lt;math&gt; f'(x)=0&lt;/math&gt;
:&lt;math&gt;\int f(x) \,dx = 72x+c&lt;/math&gt;

==See also==
*[[Expression (mathematics)|Expression]]
*[[Physical constant]]
*[[Constant (disambiguation)]]

==References==
{{reflist}}

[[Category:Algebra]]
[[Category:Elementary mathematics]]</text>
      <sha1>jrff2z3457eixvk9fgc2zztggx91f3f</sha1>
    </revision>
  </page>
  <page>
    <title>Content (measure theory)</title>
    <ns>0</ns>
    <id>9999200</id>
    <revision>
      <id>850978757</id>
      <parentid>850918546</parentid>
      <timestamp>2018-07-19T07:46:33Z</timestamp>
      <contributor>
        <ip>80.187.107.159</ip>
      </contributor>
      <comment>/* Examples */confusing formulation corrected</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6923">In [[mathematics]], a '''content''' is a set function like a [[measure (mathematics)|measure]] but a content need not be countably additive, but must only be finitely additive. A content is a [[real function]] &lt;math&gt;\mu&lt;/math&gt; defined on a [[field of sets]] &lt;math&gt;\mathcal{A}&lt;/math&gt; such that
# &lt;math&gt;\mu(A)\in\ [0, \infty] \text{ whenever } A \in \mathcal{A}.&lt;/math&gt;
# &lt;math&gt;\mu(\varnothing) = 0. &lt;/math&gt;
# &lt;math&gt;\mu(A_1 \cup A_2) = \mu(A_1) + \mu(A_2) \text{ whenever } A_1,A_2 \in \mathcal{A} \text{ and } A_1 \cap A_2 = \varnothing.&lt;/math&gt;

An example of a content is a [[measure (mathematics)|measure]], which is a [[sigma additivity|''σ''-additive]] ''content'' defined on a [[Sigma field|''σ''-field]]. Every (real-valued) measure is a content, but not vice versa. Contents give a good notion of integrating bounded functions on a space but can behave badly when integrating unbounded functions, while measures give a good notion of integrating unbounded functions.

==Examples==

An example of a content that is not a measure on a σ-algebra is the content on all subsets of the positive integers that has value 1/2&lt;sup&gt;''n''&lt;/sup&gt; on any integer ''n'' and is infinite on any infinite subset.

An example of a content on the positive integers that is always finite but is not a measure can be given as follows. Take a positive linear functional on the bounded sequences that is 0 if the sequence has only a finite number of nonzero elements and takes value 1 on the sequence 1, 1, 1, ...., so the functional in some sense gives an "average value" of any bounded sequence. (Such a functional cannot be constructed explicitly, but exists by the [[Hahn–Banach theorem]].) Then the content of a set of positive integers is the average value of the sequence that is 1 on this set and 0 elsewhere. Informally, one can think  of the content of a subset of integers as the "chance" that a randomly chosen integer lies in this subset (though this is not compatible with the usual definitions of chance in probability theory, which assume countable additivity).

==Integration of bounded functions==

In general integration of functions with respect to a content does not behave well. However there is a well-behaved notion of integration provided that the function is bounded and the total content of the space is finite, given as follows.

Suppose that the total content of a space is finite. 
If ''f'' is a bounded function on the space such that the inverse image of any open subset of the reals has a content, then we can define the integral of ''f'' with respect to the content as
:&lt;math&gt;\int f \, d\lambda = \lim \sum_{i=1}^n f(\alpha_i)\lambda (f^{-1}(A_i))&lt;/math&gt;
where the ''A''&lt;sub&gt;''i''&lt;/sub&gt; form a finite collections of disjoint half-open sets  whose union covers the range of ''f'', and α&lt;sub&gt;''i''&lt;/sub&gt; is any element of ''A''&lt;sub&gt;''i''&lt;/sub&gt;, and where the limit is taken as the diameters of the sets ''A''&lt;sub&gt;''i''&lt;/sub&gt; tend to 0.

==Duals of spaces of bounded functions==

Suppose that μ is a measure on some space ''X''. The bounded measurable functions on ''X'' form a Banach space with respect to the supremum norm. The positive elements of the dual of this space correspond to bounded contents λ  ''Χ'', with the value of λ on ''f'' given by the integral &lt;math&gt;\int f \, d\lambda&lt;/math&gt;. Similarly one can form the space of essentially bounded functions, with the norm given by the essential supremum, and the positive elements of the dual of this space are given by bounded contents that vanish on sets of measure 0.

==Construction of a measure from a content==

There are several ways to construct a measure μ from a content λ on a topological space. This section gives one such method for locally compact Hausdorff spaces such that the content is defined on all compact subsets. In general the measure is not an extension of the content, as the content may fail to be countably additive, and the measure may even be identically zero even if the content is not.

First restrict the content to compact sets. This gives a function λ of compact sets ''C'' with the following properties:
# &lt;math&gt;\lambda(C)\in\ [0, \infty]&lt;/math&gt; for all compact sets ''C''
# &lt;math&gt;\lambda(\varnothing) = 0. &lt;/math&gt;
# &lt;math&gt;\lambda(C_1 ) \le \lambda(C_2) \text{ whenever } C_1\subset C_2&lt;/math&gt;
# &lt;math&gt;\lambda(C_1 \cup C_2) \le \lambda(C_1) + \lambda(C_2)&lt;/math&gt; for all pairs of compact sets
# &lt;math&gt;\lambda(C_1 \cup C_2) = \lambda(C_1) + \lambda(C_2) &lt;/math&gt; for all pairs of disjoint compact sets.

There are also examples of functions λ as above not constructed from contents. 
An example is given by the construction of [[Haar measure]] on a locally compact group. One method of constructing such a Haar measure is to produce a left-invariant function λ as above on the compact subsets of the group, which can then be extended to a left-invariant measure.

===Definition on open sets===

Given λ as above, we define a function μ on all open sets by 
:&lt;math&gt;\mu(U ) = \sup_{C\subset U}\lambda (C)&lt;/math&gt;.
This has the following properties: 
# &lt;math&gt;\mu(U)\in\ [0, \infty] &lt;/math&gt;
# &lt;math&gt;\mu(\varnothing) = 0. &lt;/math&gt;
# &lt;math&gt;\mu(U_1 ) \le \mu(U_2) \text{ whenever } U_1\subset U_2&lt;/math&gt;
# &lt;math&gt;\mu(\bigcup_nU_n ) \le \bigoplus_n\lambda(U_n)&lt;/math&gt; for any collection of open sets.
# &lt;math&gt; \mu(\bigcup_nU_n ) = \bigoplus_n\lambda(U_n)&lt;/math&gt; for any collection of disjoint open sets

===Definition on all sets===

Given μ as above, we extend the  function μ to all subsets of the topological space by 
:&lt;math&gt;\mu(A ) = \inf_{A\subset U}\mu (U).&lt;/math&gt;
This is an [[outer measure]], in other words it has the following properties: 
# &lt;math&gt;\mu(A)\in\ [0, \infty] &lt;/math&gt;
# &lt;math&gt;\mu(\varnothing) = 0. &lt;/math&gt;
# &lt;math&gt;\mu(A_1 ) \le \mu(A_2) \text{ whenever } A_1\subset A_2&lt;/math&gt;
# &lt;math&gt;\mu(\bigcup_nA_n ) \le \bigoplus_n\lambda(A_n)&lt;/math&gt; for any countable collection of sets.

===Construction of a measure===

The function μ above is an [[outer measure]] on the family of all subsets. Therefore it becomes a measure when restricted to the measurable subsets for the outer measure, which are the subsets ''E'' such that μ(''X'') = μ(''X''&amp;cap;''E'') + μ(''X''\''E'') for all subsets ''X''. If the space is locally compact then every open set is measurable for this measure.

The measure μ does not necessarily coincide with the content λ on compact sets, However it does if λ is regular in the sense that 
for any compact ''C'', λ(''C'') is the inf of λ(''D'') for compact sets ''D'' containing ''C'' in their interiors.
==See also==
* [[Minkowski content]]
==References==
*{{citation|first=Paul|last=Halmos|authorlink=Paul Halmos|year=1950|title=Measure Theory|publisher=Van Nostrand and Co.}}
*{{citation|mr=0053185|last=Mayrhofer|first=Karl|title=Inhalt und Mass (Content and measure)|publisher=Springer-Verlag|year=1952}}

[[Category:Measure theory]]
[[Category:Set families]]</text>
      <sha1>psjl2d4bvrgp8emgbkr0onocowh0grt</sha1>
    </revision>
  </page>
  <page>
    <title>Cytoscape</title>
    <ns>0</ns>
    <id>10921962</id>
    <revision>
      <id>869591948</id>
      <parentid>840000075</parentid>
      <timestamp>2018-11-19T16:09:07Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>/* top */Fixing [[Wikipedia:Disambiguation pages with links|links to disambiguation pages]], replaced: [[open source]] → [[Open-source software|open source]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8347">{{Infobox software
| name                   = Cytoscape
| title                  = 
| logo                   = &lt;!-- [[File: ]] --&gt;
| logo caption           = 
| screenshot             = CytoscapeHome.png
| screenshot size        = 200px
| caption                = Cytoscape home page
| collapsible            = 
| author                 = [http://www.systemsbiology.org/ Institute for Systems Biology]
| developer              = 
| released               = July 2002&lt;!-- {{Start date|YYYY|MM|DD|df=yes/no}} --&gt;
| discontinued           = 
| latest release version = 3.5.1
| latest release date    = {{Start date and age|2017|04|26|df=yes/no}}
| latest preview version = 
| latest preview date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| status                 = 
| programming language   = [[Java platform|Java]]
| operating system       = Any ([[Java platform|Java]]-based)
| platform               = 
| size                   = 
| language               = 
| language count         = &lt;!-- DO NOT include this parameter unless you know what it does --&gt;
| language footnote      = 
| genre                  = [[Image processing]]
| license                = [[LGPL]]
| alexa                  = 
| website                = {{URL|http://www.cytoscape.org/}}
| standard               = 
| AsOf                   = 
}}
'''Cytoscape''' is an [[Open-source software|open source]] [[bioinformatics]] [[software platform]] for [[Visualization (graphic)|visualizing]] [[Metabolic network modelling|molecular interaction networks]] and integrating with [[gene expression]] profiles and other state data. Additional features are available as [[plugins]]. Plugins are available for network and molecular profiling analyses, new layouts, additional file format support and connection with databases and searching in large networks. Plugins may be developed using the Cytoscape open [[Java (programming language)|Java]] software architecture by anyone and plugin  community development is encouraged.&lt;ref&gt;{{cite journal |vauthors=Shannon P, Markiel A, Ozier O |title=Cytoscape: a software environment for integrated models of biomolecular interaction networks |journal=Genome Res. |volume=13 |issue=11 |pages=2498–504 |year=2003 |pmid=14597658 |doi=10.1101/gr.1239303 |url=http://www.genome.org/cgi/content/full/13/11/2498 |pmc=403769|display-authors=etal}}
&lt;/ref&gt;&lt;ref&gt;{{cite journal |vauthors=Bell GW, Lewitter F |title=Visualizing networks |journal=Meth. Enzymol. |volume=411 |issue= |pages=408–21 |year=2006 |pmid=16939803 |doi=10.1016/S0076-6879(06)11022-8}}&lt;/ref&gt;  Cytoscape also has a [[JavaScript]]-centric sister project named [http://js.cytoscape.org Cytoscape.js] that can be used to analyse and visualise graphs in JavaScript environments, like a browser.

== History ==
Cytoscape was originally created at the Institute of Systems Biology in Seattle in 2002.  Now, it is developed by an international consortium of open source developers. Cytoscape was initially made public in July, 2002 (v0.8); the second release (v0.9) was in November, 2002, and v1.0 was released in March 2003.  Version 1.1.1 is the last stable release for the 1.0 series. Version 2.0 was initially released in 2004; Cytoscape 2.83, the final 2.xx version, was released in May 2012. Version 3.0 was released Feb 1, 2013, and the latest version, 3.4.0, was released in May 2016.

== Development ==
The Cytoscape core developer team continues to work on this project and released Cytoscape 3.0 in 2013. This represented a major change in the Cytoscape architecture; it is a more modularized, expandable and maintainable version of the software.&lt;ref&gt;[http://cytoscape.wodaklab.org/wiki/Cytoscape_3/ developer's wiki page].&lt;/ref&gt;

== Usage ==
[[Image:Cytoscape network visualization1.png|thumb|450px|Yeast Protein–protein/Protein–DNA interaction network visualized by Cytoscape. Node degree is mapped to node size]]

While Cytoscape is most commonly used for biological research applications, it is agnostic in terms of usage.  Cytoscape can be used to visualize and analyze network graphs of any kind involving nodes and edges (e.g., social networks). A key aspect of the software architecture of Cytoscape is the use of plugins for specialized features. Plugins are developed by core developers and the greater user community.

== Features ==
'''Input'''
* Input and construct molecular interaction networks from raw interaction files (SIF format) containing lists of protein–protein and/or protein–DNA interaction pairs.  For yeast and other model organisms, large sources of pairwise interactions are available through the BIND and [[TRANSFAC]] databases. User-defined interaction types are also supported.
* Load and save previously-constructed interaction networks in [[Graph Modelling Language|GML]] format (Graph Modelling Language).
* Load and save networks and node/edge attributes in an XML document format called [[XGMML]] (eXtensible Graph Markup and Modeling Language).
* Input mRNA expression profiles from tab- or space-delimited text files.
* Load and save arbitrary attributes on nodes and edges. For example, input a set of custom annotation terms for your proteins, create a set of confidence values for your protein–protein interactions.
* Import gene functional annotations from the [[Gene Ontology]] (GO) and [[KEGG]] databases.
* Directly import GO terms and annotations from OBO and Gene Association files.
* Load and save state of the cytoscape session in a cytoscape session (.cys) file. Cytoscape session file includes networks, attributes (for node/edge/network), desktop states (selected/hidden nodes and edges, window sizes), properties, and visual styles.

'''Visualization'''
* Customize network data display using powerful visual styles.
* View a superposition of gene expression ratios and p-values on the network.  Expression data can be mapped to node color, label, border thickness, or border color, etc. according to user-configurable colors and visualization schemes.
* Layout networks in two dimensions.  A variety of layout algorithms are available, including cyclic and [[Force-based algorithms (graph drawing)|spring-embedded layouts]].
* Zoom in/out and pan for browsing the network.
* Use the network manager to easily organize multiple networks. And this structure can be saved in a session file.
* Use the bird's eye view to easily navigate large networks.
* Easily navigate large networks (100,000+ nodes and edges) by efficient rendering engine.

'''Analysis'''
* Plugins available for network and molecular profile analysis. For example:
** Filter the network to select subsets of nodes and/or interactions based on the current data.  For instance, users may select nodes involved in a threshold number of interactions, nodes that share a particular GO annotation, or nodes whose gene expression levels change significantly in one or more conditions according to p-values loaded with the gene expression data.
** Find active subnetworks/pathway modules. The network is screened against gene expression data to identify connected sets of interactions, i.e. interaction subnetworks, whose genes show particularly high levels of differential expression.  The interactions contained in each subnetwork provide hypotheses for the regulatory and signaling interactions in control of the observed expression changes.
** Find clusters (highly interconnected regions) in any network loaded into Cytoscape. Depending on the type of network, clusters may mean different things. For instance, clusters in a protein–protein interaction network have been shown to be protein complexes and parts of pathways. Clusters in a protein similarity network represent protein families.

== See also ==
* [[Computational genomics]]
* [[Metabolic network modelling]]
* [[Protein–protein interaction prediction]]
* [[Graph drawing]]

== References ==
{{Reflist}}

== External links ==
* {{Official website|http://www.cytoscape.org/}}
* [http://wiki.cytoscape.org/ Cytoscape wiki]
* [https://omictools.com/cytoscape-tool Cytoscape omictools webpage]

{{genomics-footer}}
{{Graph Analysis Software}}

[[Category:Bioinformatics software]]
[[Category:Systems biology]]
[[Category:Mathematical and theoretical biology]]
[[Category:Graph drawing software]]
[[Category:Cross-platform software]]
[[Category:Java platform software]]</text>
      <sha1>41ysf17tw8qtjww5sgsg1h6kupviq0w</sha1>
    </revision>
  </page>
  <page>
    <title>D'Alembert operator</title>
    <ns>0</ns>
    <id>293511</id>
    <revision>
      <id>857282389</id>
      <parentid>857172768</parentid>
      <timestamp>2018-08-30T18:47:00Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* top */ ² → &lt;sup&gt;2&lt;/sup&gt;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4879">{{DISPLAYTITLE:d'Alembert operator}}
In [[special relativity]], [[electromagnetism]] and [[Wave|wave theory]], the '''d'Alembert operator''' (denoted by a box: &lt;math&gt;\Box&lt;/math&gt;), also called the '''d'Alembertian''', '''wave operator''', or '''box operator''' is the [[Laplace operator]] of [[Minkowski space]]. The operator is named after French mathematician and physicist [[Jean le Rond d'Alembert]].

In Minkowski space, in standard coordinates {{math|(''t'', ''x'', ''y'', ''z'')}}, it has the form
: &lt;math&gt;
\begin{align}
\Box &amp; = \partial^\mu \partial_\mu = g^{\mu\nu} \partial_\nu \partial_\mu = \frac{1}{c^{2}} \frac{\partial^2}{\partial t^2} - \frac{\partial^2}{\partial x^2} - \frac{\partial^2}{\partial y^2} - \frac{\partial^2}{\partial z^2} \\
&amp; = \frac{1}{c^2} {\partial^2 \over \partial t^2} - \nabla^2 = \frac{1}{c^2}{\partial^2 \over \partial t^2} - \Delta ~~.
\end{align}
&lt;/math&gt;

Here  ∇&lt;sup&gt;2&lt;/sup&gt; is the 3-dimensional [[Laplace operator|Laplacian]] and {{math|''g&lt;sup&gt;μν&lt;/sup&gt;''}}  is the inverse [[Minkowski metric]] with 
:&lt;math&gt;g_{00} = 1&lt;/math&gt;, &lt;math&gt;g_{11} = g_{22} = g_{33} = -1&lt;/math&gt;, &lt;math&gt;g_{\mu\nu} = 0&lt;/math&gt; for &lt;math&gt;\mu \neq \nu&lt;/math&gt;.
Note that the {{math|''μ''}} and {{math|''ν''}} summation indices range from 0 to 3: see [[Einstein notation]]. We have assumed units such that the speed of light {{mvar|c}} = 1.

Some authors also use the negative [[metric signature]] of {{nowrap|(− + + +)}}, with &lt;math&gt;g_{00} = -1,\; g_{11} = g_{22} = g_{33} = 1&lt;/math&gt;.

[[Lorentz transformation]]s leave the [[Minkowski metric]] invariant, so the d'Alembertian yields a [[Lorentz scalar]]. The above coordinate expressions remain valid for the standard coordinates in every inertial frame.

==Alternate notations==
There are a variety of notations for the d'Alembertian. The most common is the symbol &lt;math&gt;\Box&lt;/math&gt; ([[Unicode]]: {{unichar|2610|ballot box}}): the four sides of the box representing the four dimensions of space-time and the &lt;math&gt;\Box^2&lt;/math&gt; which emphasizes the scalar property through the squared term (much like the [[Laplacian]]). This symbol is sometimes called the '''quabla''' (''cf''. [[nabla symbol]]). In keeping with the triangular notation for the [[Laplacian]], sometimes  &lt;math&gt;\Delta_M&lt;/math&gt; is used.

Another way to write the d'Alembertian in flat standard coordinates is  &lt;math&gt;\partial^2&lt;/math&gt;. This notation is used extensively in [[quantum field theory]], where partial derivatives are usually indexed, so the lack of an index with the squared partial derivative signals the presence of the d'Alembertian.

Sometimes &lt;math&gt;\Box&lt;/math&gt; is used to represent the four-dimensional Levi-Civita [[covariant derivative]]. The symbol &lt;math&gt;\nabla&lt;/math&gt; is then used to represent the space derivatives, but this is [[coordinate chart]] dependent.

==Applications==
The [[wave equation]] for small vibrations is of the form
:&lt;math&gt; \Box_{c} u\left(x,t\right) \equiv u_{tt} - c^2u_{xx} = 0~,&lt;/math&gt;
where {{math| ''u''(''x,t'')}} is the displacement.

The [[wave equation]] for the electromagnetic field in vacuum is
:&lt;math&gt; \Box A^{\mu} = 0 &lt;/math&gt;
where {{math|''A&lt;sup&gt;μ&lt;/sup&gt;''}}  is the [[electromagnetic four-potential]].

The [[Klein–Gordon equation]] has the form
:&lt;math&gt; (\Box + m^2) \psi = 0~.&lt;/math&gt;

==Green's function==
The [[Green's function]], &lt;math&gt;G\left(\tilde{x} - \tilde{x}'\right)&lt;/math&gt;, for the d'Alembertian is defined by the equation
:&lt;math&gt; \Box G\left(\tilde{x} - \tilde{x}'\right) = \delta\left(\tilde{x} - \tilde{x}'\right)&lt;/math&gt;

where &lt;math&gt;\delta\left(\tilde{x} - \tilde{x}'\right)&lt;/math&gt; is the multidimensional [[Dirac delta function]] and  &lt;math&gt;\tilde{x}&lt;/math&gt; and  &lt;math&gt;\tilde{x}'&lt;/math&gt; are two points in Minkowski space.

A special solution is given by the ''retarded Green's function'' which corresponds to signal [[propagator|propagation]] only forward in time
:&lt;math&gt;G\left(\vec{r}, t\right) = \frac{1}{4\pi r} \Theta(t) \delta\left(t - \frac{r}{c}\right)~~~&lt;/math&gt;&lt;ref&gt;{{cite web|author=S. Siklos|title=The causal Green’s function for the wave equation|url=http://www.damtp.cam.ac.uk/user/stcs/courses/fcm/handouts/wave_equation.pdf|accessdate=2 January 2013}}&lt;/ref&gt;

where &lt;math&gt;\Theta&lt;/math&gt; is the [[Heaviside step function]].

==See also==
*[[4-gradient]]
*[[d'Alembert's formula]]
*[[Klein–Gordon equation]]
*[[Relativistic heat conduction]]
*[[Ricci calculus]]

==References==
{{Reflist}}

==External links==
* {{springer|title=D'Alembert operator|id=p/d030080}}
* {{Cite wikisource
 | title = Translation:On the Dynamics of the Electron (July)
 | last  = Poincaré
 | first = Henri
 | year  = 1906
}}, originally printed in [[Rendiconti del Circolo Matematico di Palermo]].
* {{MathWorld | urlname=dAlembertian | title=d'Alembertian}}

{{physics operators}}

[[Category:Differential operators]]
[[Category:Hyperbolic partial differential equations]]</text>
      <sha1>al73auix5h6f96hkc4t8x8s1v38vc06</sha1>
    </revision>
  </page>
  <page>
    <title>David Conlon</title>
    <ns>0</ns>
    <id>36837348</id>
    <revision>
      <id>839446939</id>
      <parentid>839438801</parentid>
      <timestamp>2018-05-03T13:51:49Z</timestamp>
      <contributor>
        <username>Wilson1923</username>
        <id>20164019</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3743">{{Infobox scientist
| name              = David Conlon
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| caption           = 
| birth_date        = {{Birth year and age|1982}}
| birth_place       = [[Ireland]]
| death_date        = 
| death_place       = 
| nationality       = [[Ireland|Irish]]
| fields            = [[Mathematics]]
| workplaces        = [[University of Oxford]]
| alma_mater        = [[University of Cambridge]]&lt;br&gt;[[Trinity College Dublin]]
| doctoral_advisor  = [[Timothy Gowers]]
| doctoral_students = 
| known_for         =
| awards            = [[European Prize in Combinatorics]] (2011)
}}
'''David Conlon''' (born 1982) is an [[Ireland|Irish]] [[mathematician]]. He represented Ireland in the [[International Mathematical Olympiad]] in 1998 and 1999.&lt;ref&gt;{{cite web|title=International Mathematical Olympiad Results for Ireland|url=https://www.imo-official.org/country_individual_r.aspx?code=IRL|accessdate=7 July 2017}}&lt;/ref&gt; He was an undergraduate in [[Trinity College Dublin]], where he was [[List of Scholars of Trinity College, Dublin|elected a Scholar]] in 2001&lt;ref name="TCD Scholars"&gt;{{cite web|title=TCD Scholars Since 1925|url=http://www.tcdlife.ie/scholars/scholar/about-list.php|accessdate=7 July 2017}}&lt;/ref&gt; and graduated in 2003. He earned a Ph.D. from [[Cambridge University]] in 2009.&lt;ref&gt;{{MathGenealogy |id=138270 }}&lt;/ref&gt;  He is a fellow of [[Wadham College, Oxford]] and is a Professor of Discrete Mathematics in the Mathematics Institute at the University of Oxford.  His research interests are in Hungarian-style [[combinatorics]], particularly [[Ramsey theory]], [[extremal graph theory]], [[combinatorial number theory]], and probabilistic methods in combinatorics.&lt;ref name="David Conlon's Oxford Contact Page"&gt;{{cite web|title=Prof. David Conlon|url=http://www.maths.ox.ac.uk/people/profiles/david.conlon|work=University of Oxford|publisher=University of Oxford|accessdate=28 March 2018}}&lt;/ref&gt; 

Conlon has worked in [[Ramsey theory]]. In particular, he proved the first superpolynomial improvement on the [[Erdős–Szekeres bound]] on diagonal [[Ramsey number]]s.&lt;ref name="Paper on Ramsey Numbers"&gt;{{cite web|last=Conlon|first=David|title=A New Upper Bound for Diagonal Ramsey Numbers|url=https://www.dpmms.cam.ac.uk/~dc340/RamseyUpper.pdf|work=www.dpmms.cam.ac.uk|publisher=University of Cambridge|accessdate=25 April 2014}}&lt;/ref&gt; 

He won the [[European Prize in Combinatorics]] in 2011, for his work in Ramsey theory and for his progress on Sidorenko's conjecture that, for any [[bipartite graph]] ''H'', random bipartite graphs have the fewest [[subgraph isomorphism|subgraphs isomorphic to ''H'']].&lt;ref&gt;{{citation|url=http://mta.hu/matematika_hirek/a-kombinatorika-kivalosagai-az-akademian-128508|title=A kombinatorika kiválóságai az Akadémián|publisher=[[Hungarian Academy of Sciences]]|language=Hungarian|date=September 1, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20131106013006/http://mta.hu/matematika_hirek/a-kombinatorika-kivalosagai-az-akademian-128508|archivedate=November 6, 2013|df=}}.&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
*{{MathGenealogy |id=138270 }}
*[http://www.maths.ox.ac.uk/contact/details/conlond Home page] at Oxford
*[https://scholar.google.com/citations?user=Br__ds4AAAAJ Google scholar profile]
*{{IMO results |id=5361 }}

{{authority control}}
{{DEFAULTSORT:Conlon, David}}
[[Category:1982 births]]
[[Category:Living people]]
[[Category:Irish mathematicians]]
[[Category:Combinatorialists]]
[[Category:International Mathematical Olympiad participants]]
[[Category:Alumni of Trinity College, Dublin]]
[[Category:Scholars of Trinity College, Dublin]]
[[Category:Alumni of the University of Cambridge]]</text>
      <sha1>3yjnr1gx3q4cdpg8fitaquj3zrp0cae</sha1>
    </revision>
  </page>
  <page>
    <title>Degeneracy (graph theory)</title>
    <ns>0</ns>
    <id>27545816</id>
    <revision>
      <id>860270084</id>
      <parentid>860270035</parentid>
      <timestamp>2018-09-19T14:22:09Z</timestamp>
      <contributor>
        <ip>130.206.68.4</ip>
      </contributor>
      <comment>/* k-Cores */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31050">:''"K-core" redirects here. The [[core (graph theory)|core]] of a graph is a different concept.''
[[File:2-degenerate graph 2-core.svg|thumb|400px|A 2-degenerate graph: each vertex has at most two neighbors to its left, so the rightmost vertex of any subgraph has degree at most two. Its 2-core, the subgraph remaining after repeatedly deleting vertices of degree less than two, is shaded.]]
In [[graph theory]], a '''''k''-degenerate graph''' is an [[undirected graph]] in which every subgraph has a vertex of [[degree (graph theory)|degree]] at most ''k'': that is, some vertex in the subgraph touches ''k'' or fewer of the subgraph's edges. The '''degeneracy''' of a graph is the smallest value of ''k'' for which it is ''k''-degenerate. The degeneracy of a graph is a measure of how [[dense graph|sparse]] it is, and is within a constant factor of other sparsity measures such as the [[arboricity]] of a graph.

Degeneracy is also known as the  '''''k''-core number''',&lt;ref name="bh03"&gt;{{harvtxt|Bader|Hogue|2003}}.&lt;/ref&gt; '''width''',&lt;ref&gt;{{harvtxt|Freuder|1982}}.&lt;/ref&gt; and '''linkage''',&lt;ref&gt;{{harvtxt|Kirousis|Thilikos|1996}}.&lt;/ref&gt; and is essentially the same as the '''coloring number'''&lt;ref&gt;{{harvtxt|Erdős|Hajnal|1966}}.&lt;/ref&gt; or '''Szekeres-Wilf number''' (named after {{harvs|last1=Szekeres|author1-link=George Szekeres|last2=Wilf|author2-link=Herbert Wilf|year=1968|txt}}). ''k''-degenerate graphs have also been called '''''k''-inductive graphs'''.&lt;ref&gt;{{harvtxt|Irani|1994}}.&lt;/ref&gt; The degeneracy of a graph may be computed in [[linear time]] by an algorithm that repeatedly removes minimum-degree vertices.&lt;ref&gt;{{harvtxt|Matula|Beck|1983}}&lt;/ref&gt; The [[Connected component (graph theory)|connected components]] that are left after all vertices of degree less than ''k'' have been removed are called the '''''k''-cores''' of the graph and the degeneracy of a graph is the largest value ''k'' such that it has a ''k''-core.

==Examples==
Every finite [[tree (graph theory)|forest]] has either an isolated vertex (incident to no edges) or a leaf vertex (incident to exactly one edge); therefore, trees and forests are 1-degenerate graphs. Every 1-degenerate graph is a forest.

Every finite [[planar graph]] has a vertex of degree five or less; therefore, every planar graph is 5-degenerate, and the degeneracy of any planar graph is at most five. Similarly, every [[outerplanar graph]] has degeneracy at most two,&lt;ref&gt;{{harvtxt|Lick|White|1970}}.&lt;/ref&gt; and the [[Apollonian network]]s have degeneracy three.

The [[Barabási–Albert model]] for generating [[random graph|random]] [[scale-free networks]]&lt;ref&gt;{{harvtxt|Barabási|Albert|1999}}.&lt;/ref&gt; is parameterized by a number ''m'' such that each vertex that is added to the graph has ''m'' previously-added vertices. It follows that any subgraph of a network formed in this way has a vertex of degree at most ''m'' (the last vertex in the subgraph to have been added to the graph) and Barabási–Albert networks are automatically ''m''-degenerate.

Every ''k''-regular graph has degeneracy exactly&amp;nbsp;''k''. More strongly, the degeneracy of a graph equals its maximum vertex degree if and only if at least one of the [[connected component (graph theory)|connected components]] of the graph is regular of maximum degree. For all other graphs, the degeneracy is strictly less than the maximum degree.&lt;ref&gt;{{harvtxt|Jensen|Toft|2011}}, [https://books.google.com/books?id=leL0Y5N0bFoC&amp;pg=PA78 p.&amp;nbsp;78]: "It is easy to see that col(''G'')&amp;nbsp;=&amp;nbsp;&amp;Delta;(''G'')&amp;nbsp;+&amp;nbsp;1 if and only if ''G'' has a &amp;Delta;(''G'')-regular component." In the notation used by Jensen and Toft, col(''G'') is the degeneracy plus one, and &amp;Delta;(''G'') is the maximum vertex degree.&lt;/ref&gt;

==Definitions and equivalences==
The coloring number of a graph ''G'' was defined by {{harvtxt|Erdős|Hajnal|1966}} to be the least &amp;kappa; for which there exists an ordering of the vertices of ''G'' in which each vertex has fewer than &amp;kappa; neighbors that are earlier in the ordering. It should be distinguished from the [[chromatic number]] of ''G'', the minimum number of colors needed to color the vertices so that no two adjacent vertices have the same color; the ordering which determines the coloring number provides an order to color the vertices of G with the coloring number, but in general the chromatic number may be smaller.

The degeneracy of a graph ''G'' was defined by {{harvtxt|Lick|White|1970}} as the least ''k'' such that every [[induced subgraph]] of ''G'' contains a vertex with ''k'' or fewer neighbors. The definition would be the same if arbitrary subgraphs are allowed in place of induced subgraphs, as a non-induced subgraph can only have vertex degrees that are smaller than or equal to the vertex degrees in the subgraph induced by the same vertex set.

The two concepts of coloring number and degeneracy are equivalent: in any finite graph the degeneracy is just one less than the coloring number.&lt;ref&gt;{{harvtxt|Matula|1968}}; {{harvtxt|Lick|White|1970}}, Proposition 1, page 1084.&lt;/ref&gt; For, if a graph has an ordering with coloring number κ then in each subgraph ''H'' the vertex that belongs to ''H'' and is last in the ordering has at most &amp;kappa;&amp;nbsp;&amp;minus;&amp;nbsp;1 neighbors in ''H''. In the other direction, if ''G'' is ''k''-degenerate, then an ordering with coloring number ''k''&amp;nbsp;+&amp;nbsp;1 can be obtained by repeatedly finding a vertex ''v'' with at most ''k'' neighbors, removing ''v'' from the graph, ordering the remaining vertices, and adding ''v'' to the end of the order.

A third, equivalent formulation is that ''G'' is ''k''-degenerate (or has coloring number at most ''k''&amp;nbsp;+&amp;nbsp;1) if and only if the edges of ''G'' can be oriented to form a [[directed acyclic graph]] with [[Degree (graph theory)|outdegree]] at most ''k''.&lt;ref&gt;{{harvtxt|Chrobak|Eppstein|1991}}.&lt;/ref&gt; Such an orientation can be formed by orienting each edge towards the earlier of its two endpoints in a coloring number ordering. In the other direction, if an orientation with outdegree ''k'' is given, an ordering with coloring number ''k''&amp;nbsp;+&amp;nbsp;1 can be obtained as a [[topological ordering]] of the resulting directed acyclic graph.

==''k''-Cores==
A ''k''-core of a graph ''G'' is a [[maximal element|maximal]] subgraph of ''G'' in which all vertices have degree at least ''k''. Equivalently, it is one of the [[Connected component (graph theory)|connected components]] of the subgraph of ''G'' formed by repeatedly deleting all vertices of degree less than ''k''. If a non-empty ''k''-core exists, then, clearly, ''G'' has degeneracy at least ''k'', and the degeneracy of ''G'' is the largest ''k'' for which ''G'' has a ''k''-core.

A vertex &lt;math&gt;u&lt;/math&gt; has ''coreness'' &lt;math&gt;c&lt;/math&gt; if it belongs to a
&lt;math&gt;c&lt;/math&gt;-core but not to any &lt;math&gt;(c+1)&lt;/math&gt;-core.

The concept of a ''k''-core was introduced to study the clustering structure of [[social network]]s&lt;ref&gt;{{harvtxt|Seidman|1983}}.&lt;/ref&gt; and to describe the evolution of [[random graph]]s;&lt;ref&gt;{{harvtxt|Bollobás|1984}}; {{harvtxt|Łuczak|1991}};{{harvtxt|Dorogovtsev|Goltsev|Mendes|2006}}.&lt;/ref&gt; it has also been applied in [[bioinformatics]],&lt;ref name="bh03"/&gt;&lt;ref&gt;{{harvtxt|Altaf-Ul-Amin|Nishikata|Koma|Miyasato|2003}}; {{harvtxt|Wuchty|Almaas|2005}}.&lt;/ref&gt; [[graph drawing|network visualization]],&lt;ref&gt;{{harvtxt|Gaertler|Patrignani|2004}}; {{harvtxt|Alvarez-Hamelin|Dall'Asta|Barrat|Vespignani|2005}}.&lt;/ref&gt; Internet structure,&lt;ref name="CarmiHavlin2007"&gt;{{cite journal|last1=Carmi|first1=S.|last2=Havlin|first2=S.|last3=Kirkpatrick|first3=S.|last4=Shavitt|first4=Y.|last5=Shir|first5=E.|title=A model of Internet topology using k-shell decomposition|journal=Proceedings of the National Academy of Sciences|volume=104|issue=27|year=2007|pages=11150–11154|issn=0027-8424|doi=10.1073/pnas.0701175104|pmc=1896135|arxiv=cs/0607080|bibcode=2007PNAS..10411150C}}&lt;/ref&gt; spreading of economic crises,&lt;ref name="GarasArgyrakis2010"&gt;{{cite journal|last1=Garas|first1=Antonios|last2=Argyrakis|first2=Panos|last3=Rozenblat|first3=Céline|last4=Tomassini|first4=Marco|last5=Havlin|first5=Shlomo|title=Worldwide spreading of economic crisis|journal=New Journal of Physics|volume=12|issue=11|year=2010|pages=113043|issn=1367-2630|doi=10.1088/1367-2630/12/11/113043|bibcode=2010NJPh...12k3043G}}&lt;/ref&gt; identifying influential spreaders&lt;ref&gt;{{Cite journal|last=Kitsak|first=Maksim|last2=Gallos|first2=Lazaros K.|last3=Havlin|first3=Shlomo|last4=Liljeros|first4=Fredrik|last5=Muchnik|first5=Lev|last6=Stanley|first6=H. Eugene|last7=Makse|first7=Hernán A.|date=2010-08-29|title=Identification of influential spreaders in complex networks|url=https://www.nature.com/articles/nphys1746|journal=Nature Physics|language=En|volume=6|issue=11|pages=888–893|doi=10.1038/nphys1746|issn=1745-2473|arxiv=1001.5285|bibcode=2010NatPh...6..888K}}&lt;/ref&gt;, brain cortex structure&lt;ref name="LahavKsherim2016"&gt;{{cite journal|last1=Lahav|first1=Nir|last2=Ksherim|first2=Baruch|last3=Ben-Simon|first3=Eti|last4=Maron-Katz|first4=Adi|last5=Cohen|first5=Reuven|last6=Havlin|first6=Shlomo|title=K-shell decomposition reveals hierarchical cortical organization of the human brain|journal=New Journal of Physics|volume=18|issue=8|year=2016|pages=083013|issn=1367-2630|doi=10.1088/1367-2630/18/8/083013|arxiv=1803.03742|bibcode=2016NJPh...18h3013L}}&lt;/ref&gt; or relisience of networks in [[Ecology]]. &lt;ref name="Garcia-Algarra2017"&gt;{{cite journal|last1=Garcia-Algarra|first1=Javier|last2=Pastor|first2=Juan Manuel|last3=Iriondo|first3=Jose Maria|last4=Galeano|first4=Javier|title=Ranking of critical species to preserve the functionality of mutualistic networks using the k-core decomposition|journal=PeerJ|volume=5|year=2017|pages=e3321|issn=2167-8359|doi=10.7717/peerj.3321}}&lt;/ref&gt;
A method to identify k-core structure in a weighted network was also developed.&lt;ref name="GarasSchweitzer2012"&gt;{{cite journal|last1=Garas|first1=Antonios|last2=Schweitzer|first2=Frank|last3=Havlin|first3=Shlomo|title=Ak-shell decomposition method for weighted networks|journal=New Journal of Physics|volume=14|issue=8|year=2012|pages=083030|issn=1367-2630|doi=10.1088/1367-2630/14/8/083030|arxiv=1205.3720|bibcode=2012NJPh...14h3030G}}&lt;/ref&gt;

== ''k''-Core percolation ==
''K''-core percolation (called also bootstrap percolation) theory was developed by Dorogovtsev et al^&lt;ref&gt;{{Cite journal|last=Dorogovtsev|first=S.N.|last2=Goltsev|first2=A.V.|last3=Mendes|first3=J.F.F.|date=2006|title=k-Core Organization of Complex Networks|url=|journal=Phys. Rev. Lett.|volume=96|issue=4|pages=040601|via=|doi=10.1103/physrevlett.96.040601|pmid=16486798|arxiv=cond-mat/0509102|bibcode=2006PhRvL..96d0601D}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Goltsev|first=A.V.|last2=Dorogovtsev|first2=S.N.|last3=Mendes|first3=J.F.F.|date=2006|title=k-core (bootstrap) percolation on complex networks: Critical phenomena and nonlocal effects|url=|journal=Phys. Rev. E|volume=73|issue=5|pages=056101|via=|doi=10.1103/physreve.73.056101|arxiv=cond-mat/0602611|bibcode=2006PhRvE..73e6101G}}&lt;/ref&gt; on random networks. They find a hybrid phase transition with a jump emergence of the ''k''-core as in a first order phase transition as well as a singularity as in a continuous transition. The model shows cascading failure processes.&lt;ref&gt;{{Cite journal|last=Watts|first=D.J.|date=2002|title=A Simple Model of Global Cascades on Random Networks|url=|journal=Proceedings of the National Academy of Sciences|volume=99|issue=9|pages=5766|via=|doi=10.1073/pnas.082090499|bibcode=2002PNAS...99.5766W|pmc=122850}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Gleeson|first=James P.|last2=Cahalane|first2=Diarmuid J.|date=2007-05-03|title=Seed size strongly affects cascades on random networks|url=https://link.aps.org/doi/10.1103/PhysRevE.75.056103|journal=Physical Review E|volume=75|issue=5|pages=056103|doi=10.1103/PhysRevE.75.056103|bibcode=2007PhRvE..75e6103G}}&lt;/ref&gt;

A model combining cascading failures from ''k''-core and from interdependent networks was recently developed and analyzed.&lt;ref&gt;{{Cite journal|last=Panduranga|first=Nagendra K.|last2=Gao|first2=Jianxi|last3=Yuan|first3=Xin|last4=Stanley|first4=H. Eugene|last5=Havlin|first5=Shlomo|date=2017-09-28|title=Generalized model for k-core percolation and interdependent networks|url=https://link.aps.org/doi/10.1103/PhysRevE.96.032317|journal=Physical Review E|volume=96|issue=3|pages=032317|doi=10.1103/PhysRevE.96.032317|via=|arxiv=1703.02158|bibcode=2017PhRvE..96c2317P}}&lt;/ref&gt; It is found that the phase diagram of the combined processes is very rich and includes novel features that do not appear in each of the processes separately.

==Algorithms==
As {{harvtxt|Matula|Beck|1983}} describe, it is possible to find a vertex ordering of a finite graph ''G'' that optimizes the coloring number of the ordering, in [[linear time]], by using a [[bucket queue]] to repeatedly find and  remove the vertex of smallest degree. The degeneracy is then the highest degree of any vertex at the moment it is removed.

In more detail, the algorithm proceeds as follows:
*Initialize an output list ''L''.
*Compute a number ''d&lt;sub&gt;v&lt;/sub&gt;'' for each vertex ''v'' in ''G'', the number of neighbors of ''v'' that are not already in ''L''. Initially, these numbers are just the degrees of the vertices.
*Initialize an array ''D'' such that ''D''[''i''] contains a list of the vertices ''v'' that are not already in ''L'' for which ''d&lt;sub&gt;v&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;''i''.
*Initialize ''k'' to 0.
*Repeat ''n'' times:
**Scan the array cells ''D''[0], ''D''[1], ... until finding an ''i'' for which ''D''[''i''] is nonempty.
**Set ''k'' to max(''k'',''i'')
**Select a vertex ''v'' from ''D''[''i'']. Add ''v'' to the beginning of ''L'' and remove it from ''D[''i''].
**For each neighbor ''w'' of ''v'' not already in ''L'', subtract one from ''d&lt;sub&gt;w&lt;/sub&gt;'' and move ''w'' to the cell of D corresponding to the new value of  ''d&lt;sub&gt;w&lt;/sub&gt;''.

At the end of the algorithm, ''k'' contains the degeneracy of ''G'' and ''L'' contains a list of vertices in an optimal ordering for the coloring number. The ''i''-cores of ''G'' are the prefixes of ''L'' consisting of the vertices added to ''L'' after ''k'' first takes a value greater than or equal to&amp;nbsp;''i''.

Initializing the variables ''L'', ''d&lt;sub&gt;v&lt;/sub&gt;'', ''D'', and ''k'' can easily be done in linear time. Finding each successively removed vertex ''v'' and adjusting the cells of ''D'' containing the neighbors of ''v'' take time proportional to the value of ''d&lt;sub&gt;v&lt;/sub&gt;'' at that step; but the sum of these values is the number of edges of the graph (each edge contributes to the term in the sum for the later of its two endpoints) so the total time is linear.

==Relation to other graph parameters==
If a graph ''G'' is oriented acyclically with outdegree ''k'', then its edges may be partitioned into ''k'' [[tree (graph theory)|forests]] by choosing one forest for each outgoing edge of each node. Thus, the [[arboricity]] of ''G'' is at most equal to its degeneracy. In the other direction, an ''n''-vertex graph that can be partitioned into ''k'' forests has at most ''k''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1) edges and therefore has a vertex of degree at most 2''k''&amp;minus;&amp;nbsp;1 – thus, the degeneracy is less than twice the arboricity. One may also compute in polynomial time an orientation of a graph that minimizes the outdegree but is not required to be acyclic. The edges of a graph with such an orientation may be partitioned in the same way into ''k'' [[pseudoforest]]s, and conversely any partition of a graph's edges into ''k'' pseudoforests leads to an outdegree-''k'' orientation (by choosing an outdegree-1 orientation for each pseudoforest), so the minimum outdegree of such an orientation is the [[pseudoarboricity]], which again is at most equal to the degeneracy.&lt;ref&gt;{{harvtxt|Chrobak|Eppstein|1991}}; {{harvtxt|Gabow|Westermann|1992}}; {{harvtxt|Venkateswaran|2004}}; {{harvtxt|Asahiro|Miyano|Ono|Zenmyo|2006}}; {{harvtxt|Kowalik|2006}}.&lt;/ref&gt; The [[Thickness (graph theory)|thickness]] is also within a constant factor of the arboricity, and therefore also of the degeneracy.{{sfnp|Dean|Hutchinson|Scheinerman|1991}}

A ''k''-degenerate graph has chromatic number at most ''k''&amp;nbsp;+&amp;nbsp;1; this is proved by a simple induction on the number of vertices
which is exactly like the proof of the six-color theorem for planar graphs.  Since chromatic number is an upper bound on the order of
the [[maximum clique]], the latter invariant is also at most degeneracy plus one. By using a [[greedy coloring]] algorithm on an ordering with optimal coloring number, one can [[graph color]] a ''k''-degenerate graph using at most ''k''&amp;nbsp;+&amp;nbsp;1 colors.&lt;ref&gt;{{harvtxt|Erdős|Hajnal|1966}}; {{harvtxt|Szekeres|Wilf|1968}}.&lt;/ref&gt;

A [[K-vertex-connected graph|''k''-vertex-connected graph]] is a graph that cannot be partitioned into more than one component by the removal of fewer than ''k'' vertices, or equivalently a graph in which each pair of vertices can be connected by ''k'' vertex-disjoint paths. Since these paths must leave the two vertices of the pair via disjoint edges, a ''k''-vertex-connected graph must have degeneracy at least ''k''. Concepts related to ''k''-cores but based on vertex connectivity have been studied in social network theory under the name of [[structural cohesion]].&lt;ref&gt;{{harvtxt|Moody|White|2003}}.&lt;/ref&gt;

If a graph has [[treewidth]] or [[pathwidth]] at most ''k'', then it is a subgraph of a [[chordal graph]] which has a [[perfect elimination ordering]] in which each vertex has at most ''k'' earlier neighbors. Therefore, the degeneracy is at most equal to the treewidth and at most equal to the pathwidth.  However, there exist graphs with bounded degeneracy and unbounded treewidth, such as the [[grid graph]]s.&lt;ref&gt;{{harvtxt|Robertson|Seymour|1984}}.&lt;/ref&gt;

The [[Erdős–Burr conjecture]] relates the degeneracy of a graph ''G'' to the [[Ramsey theory|Ramsey number]] of ''G'', the largest ''n'' such that any two-edge-coloring of an ''n''-vertex [[complete graph]] must contain a monochromatic copy of ''G''. Specifically, the conjecture is that for any fixed value of ''k'', the Ramsey number of ''k''-degenerate graphs grows linearly in the number of vertices of the graphs.&lt;ref&gt;{{harvtxt|Burr|Erdős|1975}}.&lt;/ref&gt; The conjecture was proven by {{harvtxt|Lee|2017}}.

==Infinite graphs==
Although concepts of degeneracy and coloring number are frequently considered in the context of finite graphs, the original motivation for {{harvtxt|Erdős|Hajnal|1966}} was the theory of infinite graphs. For an infinite graph ''G'', one may define the coloring number analogously to the definition for finite graphs, as the smallest [[cardinal number]] &amp;alpha; such that there exists a [[well-ordering]] of the vertices of ''G'' in which each vertex has fewer than α neighbors that are earlier in the ordering. The inequality between coloring and chromatic numbers holds also in this infinite setting; {{harvtxt|Erdős|Hajnal|1966}} state that, at the time of publication of their paper, it was already well known.

The degeneracy of random subsets of infinite [[Lattice (group)|lattices]] has been studied under the name of [[bootstrap percolation]].

== See also ==
* [[Graph theory]]
* [[Network science]]
* [[Percolation theory|Percolation Theory]]

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
*{{citation
 |last1=Altaf-Ul-Amin 
 |first1=M. 
 |last2=Nishikata 
 |first2=K. 
 |last3=Koma 
 |first3=T. 
 |last4=Miyasato 
 |first4=T. 
 |last5=Shinbo 
 |first5=Y. 
 |last6=Arifuzzaman 
 |first6=M. 
 |last7=Wada 
 |first7=C. 
 |last8=Maeda 
 |first8=M. 
 |last9=Oshima 
 |first9=T. 
 |journal=Genome Informatics 
 |pages=498–499 
 |title=Prediction of protein functions based on {{mvar|k}}-cores of protein-protein interaction networks and amino acid sequences 
 |url=http://www.jsbi.org/journal/GIW03/GIW03P158.pdf 
 |volume=14 
 |year=2003 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20070927200153/http://www.jsbi.org/journal/GIW03/GIW03P158.pdf 
 |archivedate=2007-09-27 
 |df= 
}}.
*{{citation
 | last1 = Alvarez-Hamelin | first1 = José Ignacio
 | last2 = Dall'Asta | first2 = Luca
 | last3 = Barrat | first3 = Alain
 | last4 = Vespignani | first4 = Alessandro
 | arxiv = cs/0504107
 | chapter= {{mvar|k}}-core decomposition: a tool for the visualization of large scale networks
 | year = 2006
 | bibcode = 2005cs........4107A
 | editor1-last=Weiss |editor1-first=Yair

 | editor2-last=Schölkopf |editor2-first=Bernhard

 | editor3-last=Platt |editor3-first=John
 | title=Advances in Neural Information Processing Systems 18: Proceedings of the 2005 Conference
 | volume=18 |page=41
 | publisher=The MIT Press
 | isbn=0262232537
}}.
*{{citation
 | last1 = Asahiro | first1 = Yuichi
 | last2 = Miyano | first2 = Eiji
 | last3 = Ono | first3 = Hirotaka
 | last4 = Zenmyo | first4 = Kouhei
 | contribution = Graph orientation algorithms to minimize the maximum outdegree
 | isbn = 1-920682-33-3
 | location = Darlinghurst, Australia, Australia
 | pages = 11–20
 | publisher = Australian Computer Society, Inc.
 | title = CATS '06: Proceedings of the 12th Computing: The Australasian Theory Symposium
 | year = 2006}}.
*{{citation
 | last1 = Bader | first1 = Gary D.
 | last2 = Hogue | first2 = Christopher W. V.
 | doi = 10.1186/1471-2105-4-2
 | issue = 1
 | journal = [[BMC Bioinformatics]]
 | page = 2
 | pmid = 12525261
 | title = An automated method for finding molecular complexes in large protein interaction networks
 | volume = 4
 | year = 2003
 | pmc = 149346}}.
*{{citation
 |last1        = Barabási
 |first1       = Albert-László
 |author1-link = Albert-László Barabási
 |last2        = Albert
 |first2       = Réka
 |author2-link = Réka Albert
 |doi          = 10.1126/science.286.5439.509
 |journal      = [[Science (journal)|Science]]
 |pages        = 509–512
 |title        = Emergence of scaling in random networks
 |url          = http://www.nd.edu/~networks/Publication%20Categories/03%20Journal%20Articles/Physics/EmergenceRandom_Science%20286,%20509-512%20(1999).pdf
 |volume       = 286
 |year         = 1999
 |issue        = 5439
 |pmid         = 10521342
 |deadurl      = yes
 |archiveurl   = https://web.archive.org/web/20061111032123/http://www.nd.edu/~networks/Publication%20Categories/03%20Journal%20Articles/Physics/EmergenceRandom_Science%20286%2C%20509-512%20%281999%29.pdf
 |archivedate  = 2006-11-11
 |df           = 
|arxiv= cond-mat/9910332
 |bibcode= 1999Sci...286..509B
 }}.
*{{citation
 | last = Bollobás | first = Béla | author-link = Béla Bollobás
 | contribution = The evolution of sparse graphs
 | pages = 35–57
 | publisher = Academic Press
 | title = Graph Theory and Combinatorics, Proc. Cambridge Combinatorial Conf. in honor of Paul Erdős
 | year = 1984}}.
*{{citation
 | last1 = Burr | first1 = Stefan A. | author1-link = Stefan Burr
 | last2 = Erdős | first2 = Paul | author2-link = Paul Erdős
 | contribution = On the magnitude of generalized Ramsey numbers for graphs
 | mr = 0371701
 | location = Amsterdam
 | pages = 214–240
 | publisher = North-Holland
 | series = Colloq. Math. Soc. János Bolyai
 | title = Infinite and finite sets (Colloq., Keszthely, 1973; dedicated to P. Erdős on his 60th birthday), Vol. 1
 | url = http://www.renyi.hu/~p_erdos/1975-26.pdf
 | volume = 10
 | year = 1975}}.
*{{citation
 | last1 = Chrobak | first1 = Marek
 | last2 = Eppstein | first2 = David | author2-link = David Eppstein
 | doi = 10.1016/0304-3975(91)90020-3
 | issue = 2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | pages = 243–266
 | title = Planar orientations with low out-degree and compaction of adjacency matrices
 | url = http://www.ics.uci.edu/~eppstein/pubs/ChrEpp-TCS-91.pdf
 | volume = 86
 | year = 1991}}.
*{{citation
 | last1 = Dean | first1 = Alice M.
 | last2 = Hutchinson | first2 = Joan P. | author2-link = Joan Hutchinson
 | last3 = Scheinerman | first3 = Edward R. | author3-link = Ed Scheinerman
 | doi = 10.1016/0095-8956(91)90100-X
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1109429
 | pages = 147–151
 | series = Series B
 | title = On the thickness and arboricity of a graph
 | volume = 52
 | year = 1991}}.
*{{citation
 | last1 = Dorogovtsev | first1 = S. N. 
 | last2 = Goltsev | first2 = A. V.
 | last3 = Mendes | first3 = J. F. F.
 | doi = 10.1103/PhysRevLett.96.040601
 | journal = [[Physical Review Letters]]
 | pages = 040601 
 | title = {{mvar|k}}-core organization of complex networks
 | arxiv = cond-mat/0509102
 | volume = 96
 | year = 2006
 | pmid = 16486798
 | issue = 4| bibcode = 2006PhRvL..96d0601D}}.
*{{citation
 | last1 = Erdős | first1 = Paul | author1-link = Paul Erdős
 | last2 = Hajnal | first2 = András | author2-link = András Hajnal
 | doi = 10.1007/BF02020444
 | mr = 0193025
 | issue = 1–2
 | journal = Acta Mathematica Hungarica
 | pages = 61–99
 | title = On chromatic number of graphs and set-systems
 | url = http://www.renyi.hu/~p_erdos/1966-07.pdf
 | volume = 17
 | year = 1966}}.
*{{citation
 | last = Freuder | first = Eugene C.
 | doi = 10.1145/322290.322292
 | issue = 1
 | journal = [[Journal of the ACM]]
 | pages = 24–32
 | title = A sufficient condition for backtrack-free search
 | volume = 29
 | year = 1982}}.
*{{citation
 | last1 = Gabow | first1 = H. N.
 | last2 = Westermann | first2 = H. H.
 | doi = 10.1007/BF01758774
 | issue = 1
 | journal = [[Algorithmica]]
 | pages = 465–497
 | title = Forests, frames, and games: algorithms for matroid sums and applications
 | volume = 7
 | year = 1992}}.
*{{citation
 |last1=Gaertler 
 |first1=Marco 
 |last2=Patrignani 
 |first2=Maurizio 
 |contribution=Dynamic analysis of the autonomous system graph 
 |pages=13–24 
 |title=Proc. 2nd International Workshop on Inter-Domain Performance and Simulation (IPS 2004) 
 |url=http://www.dia.uniroma3.it/~patrigna/papers/files/ASGraphDynamicAnalysis.pdf 
 |year=2004 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20110722065122/http://www.dia.uniroma3.it/~patrigna/papers/files/ASGraphDynamicAnalysis.pdf 
 |archivedate=2011-07-22 
 |df= 
}}.
*{{citation
 | last = Irani | first = Sandy
 | doi = 10.1007/BF01294263
 | issue = 1
 | journal = [[Algorithmica]]
 | pages = 53–72
 | title = Coloring inductive graphs on-line
 | volume = 11
 | year = 1994}}.
*{{citation
 | last1 = Jensen | first1 = Tommy R.
 | last2 = Toft | first2 = Bjarne
 | isbn = 9781118030745
 | publisher = John Wiley &amp; Sons
 | series = Wiley Series in Discrete Mathematics and Optimization
 | title = Graph Coloring Problems
 | volume = 39
 | year = 2011}}.
*{{citation
 |last1=Kirousis 
 |first1=L. M. 
 |last2=Thilikos 
 |first2=D. M. 
 |doi=10.1137/S0097539793255709 
 |issue=3 
 |journal=[[SIAM Journal on Computing]] 
 |pages=626–647 
 |title=The linkage of a graph 
 |url=http://lca.ceid.upatras.gr/~kirousis/publications/j19.pdf 
 |volume=25 
 |year=1996 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20110721084143/http://lca.ceid.upatras.gr/~kirousis/publications/j19.pdf 
 |archivedate=2011-07-21 
 |df= 
}}.
*{{citation
 | last = Kowalik | first = Łukasz
 | doi = 10.1007/11940128_56
 | journal = Proceedings of the 17th International Symposium on Algorithms and Computation (ISAAC 2006)
 | pages = 557–566
 | publisher = Springer-Verlag
 | title = Approximation scheme for lowest outdegree orientation and graph density measures
 | volume = 4288
 | year = 2006| series = Lecture Notes in Computer Science
 | isbn = 978-3-540-49694-6
 }}.
*{{citation|year=2017|title=Ramsey numbers of degenerate graphs|first=Choongbum|last=Lee|doi = 10.4007/annals.2017.185.3.2 | issue = 3 | journal = Annals of Mathematics | pages = 791–829 | volume = 185 |arxiv=1505.04773}}.
*{{citation
 | last1 = Lick | first1 = Don R.
 | last2 = White | first2 = Arthur T.
 | journal = [[Canadian Journal of Mathematics]]
 | pages = 1082–1096
 | title = {{mvar|k}}-degenerate graphs
 | url = http://www.smc.math.ca/cjm/v22/p1082
 | volume = 22
 | year = 1970
 | doi = 10.4153/CJM-1970-125-1}}.
*{{citation
 | last = Łuczak | first = Tomasz
 | doi = 10.1016/0012-365X(91)90162-U
 | issue = 1
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 61–68
 | title = Size and connectivity of the {{mvar|k}}-core of a random graph
 | url = http://mathcs.emory.edu/~tomasz/papers/core.ps
 | volume = 91
 | year = 1991}}.
*{{citation
 | last = Matula | first = David W.
 | doi = 10.1137/1010115
 | journal = [[SIAM Review]]
 | pages = 481–482
 | title = A min-max theorem for graphs with application to graph coloring
 | department = SIAM 1968 National Meeting
 | volume = 10
 | year = 1968
 | issue = 4}}.
*{{citation
 | last1 = Matula | first1 = David W.
 | last2 = Beck | first2 = L. L. 
 | doi = 10.1145/2402.322385
 | journal = [[Journal of the ACM]]
 | volume = 30
 | mr = 0709826
 | number = 3
 | pages = 417–427
 | title = Smallest-last ordering and clustering and graph coloring algorithms
 | year = 1983}}.
*{{citation
 | last1 = Moody | first1 = James
 | last2 = White | first2 = Douglas R. | author2-link = Douglas R. White
 | issue = 1
 | journal = [[American Sociological Review]]
 | pages = 1–25
 | title = Structural cohesion and embeddedness: a hierarchical conception of social groups
 | volume = 68
 | year = 2003
 | doi=10.2307/3088904}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/0095-8956(84)90013-3
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 49–64
 | title = Graph minors. III. Planar tree-width
 | volume = 36
 | year = 1984}}.
*{{citation
 | last = Seidman | first = Stephen B.
 | doi = 10.1016/0378-8733(83)90028-X
 | issue = 3
 | journal = [[Social Networks (journal)|Social Networks]]
 | pages = 269–287
 | title = Network structure and minimum degree
 | volume = 5
 | year = 1983}}.
*{{citation
 | last1 = Szekeres | first1 = George | author1-link = George Szekeres
 | last2 = Wilf | first2 = Herbert S. | author2-link = Herbert Wilf
 | doi = 10.1016/S0021-9800(68)80081-X
 | journal = [[Journal of Combinatorial Theory]]
 | title = An inequality for the chromatic number of a graph
 | year = 1968
 | volume = 4
 | pages = 1–3}}.
*{{citation
 | last = Venkateswaran | first = V.
 | doi = 10.1016/j.dam.2003.07.007
 | issue = 1–3
 | journal = [[Discrete Applied Mathematics]]
 | pages = 374–378
 | title = Minimizing maximum indegree
 | volume = 143
 | year = 2004}}.
*{{citation
 | last1 = Wuchty | first1 = S.
 | last2 = Almaas | first2 = E.
 | doi = 10.1002/pmic.200400962
 | issue = 2
 | journal = [[Proteomics (journal)|Proteomics]]
 | pages = 444–449
 | pmid = 15627958
 | title = Peeling the yeast protein network
 | volume = 5
 | year = 2005}}.
{{refend}}

[[Category:Graph invariants]]
[[Category:Graph algorithms]]</text>
      <sha1>obzkhemsuu7aaawdln8l13n4jhfl847</sha1>
    </revision>
  </page>
  <page>
    <title>Divisibility sequence</title>
    <ns>0</ns>
    <id>29875125</id>
    <revision>
      <id>856609226</id>
      <parentid>856609206</parentid>
      <timestamp>2018-08-26T12:28:16Z</timestamp>
      <contributor>
        <username>Maxal</username>
        <id>237258</id>
      </contributor>
      <minor/>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3333">In mathematics, a '''divisibility sequence''' is an [[integer sequence]] &lt;math&gt;(a_n)&lt;/math&gt; indexed by [[positive integer]]s ''n'' such that

:&lt;math&gt;\text{if }m\mid n\text{ then }a_m\mid a_n&lt;/math&gt;

for all&amp;nbsp;''m'',&amp;nbsp;''n''.  That is, whenever one index is a multiple of another one, then the corresponding term also is a multiple of the other term.  The concept can be generalized to sequences with values in any [[ring (mathematics)|ring]] where the concept of [[divisibility]] is defined.

A '''strong divisibility sequence''' is an integer sequence &lt;math&gt;(a_n)&lt;/math&gt; such that for all positive integers&amp;nbsp;''m'',&amp;nbsp;''n'',

:&lt;math&gt;\gcd(a_m,a_n) = a_{\gcd(m,n)}.&lt;/math&gt;

Every strong divisibility sequence is a divisibility sequence: if &lt;math&gt;m\mid n&lt;/math&gt; then &lt;math&gt;\gcd(m,n) = m&lt;/math&gt;. Then by the strong divisibility property, &lt;math&gt;\gcd(a_m,a_n) = a_m&lt;/math&gt; and therefore &lt;math&gt;a_m\mid a_n&lt;/math&gt;.

==Examples==
* Any constant sequence is a strong divisibility sequence.
* Every sequence of the form &lt;math&gt;a_n = kn&lt;/math&gt;, for some nonzero integer ''k'', is a divisibility sequence.
* Every sequence of the form &lt;math&gt;a_n = A^n - B^n&lt;/math&gt; for integers &lt;math&gt;A&gt;B&gt;0&lt;/math&gt; is  a divisibility sequence.
* The [[Fibonacci numbers]] {{math|''F''&lt;sub&gt;''n''&lt;/sub&gt;}} form a strong divisibility sequence.
* More generally, any [[Lucas sequence]] of the first kind {{math|''U''&lt;sub&gt;''n''&lt;/sub&gt;(''P'',''Q'')}} is a divisibility sequence. Moreover, it is a strong divisibility sequence when {{math|1=gcd(''P'',''Q'')=1}}.
* [[Elliptic divisibility sequence]]s are another class of such sequences.

==References==
* {{cite book
|first1=Graham
|last1=Everest
|first2=Alf
|last2=van der Poorten
|first3=Igor
|last3=Shparlinski
|first4=Thomas
|last4=Ward
|title=Recurrence Sequences
|publisher=American Mathematical Society
|year=2003
|isbn=978-0-8218-3387-2
}}
* {{cite journal
|first1=Marshall
|last1=Hall
|title=Divisibility sequences of third order
|journal=Am. J. Math.
|year=1936
|pages=577–584
|volume=58
|jstor = 2370976
}}
* {{cite journal
|first1=Morgan
|last1=Ward
|title=A note on divisibility sequences
|journal=Bull. Amer. Math. Soc.
|volume=45
|issue=4
|year=1939
|pages=334–336
|url=http://projecteuclid.org/euclid.bams/1183501776
|doi=10.1090/s0002-9904-1939-06980-2
}}
* {{cite journal
|first1=V. E.
|last1=Hoggatt, Jr.
|first2=C. T.
|last2=Long
|title=Divisibility properties of generalized Fibonacci polynomials
|year=1973
|page=113
|url=http://www.fq.math.ca/Scanned/12-2/hoggatt1.pdf
|journal=Fibonacci Quarterly
}}
* {{cite journal
|first1=J.-P.
|last1=Bézivin
|first2=A.
|last2=Pethö
|first3=A. J.
|last3=van der Porten
|journal=Am. J. Math.
|volume=112
|issue=6
|year=1990
|pages=985–1001
|title=A full characterization of divisibility sequences
| jstor = 2374733
}}
* {{citation | editor1=Dorian Goldfeld | editor2=Jay Jorgenson | editor3=Peter Jones | editor4=Dinakar Ramakrishnan | editor5=Kenneth A. Ribet | editor6=John Tate | title=Number Theory, Analysis and Geometry. In Memory of [[Serge Lang]] | publisher=Springer | year=2012 | isbn=978-1-4614-1259-5 | author1=P. Ingram | author2=J. H. Silverman | chapter=Primitive divisors in elliptic divisibility sequences | pages=243–271 }}

[[Category:Sequences and series]]
[[Category:Integer sequences]]
[[Category:Arithmetic functions]]</text>
      <sha1>5brbbvsvm3enbbzugx1e47c2n28zrb3</sha1>
    </revision>
  </page>
  <page>
    <title>Double-star snark</title>
    <ns>0</ns>
    <id>24093107</id>
    <revision>
      <id>852405308</id>
      <parentid>852405083</parentid>
      <timestamp>2018-07-28T19:29:33Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Graphs of radius 4 per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 July 21]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2256">{{infobox graph
 | name = Double-star snark
 | image = [[Image:Double-star snark.svg|220px]]
 | image_caption = The Double-star snark
 | namesake =
 | vertices = 30
 | edges = 45
 | diameter = 4
 | radius = 4
 | girth = 6
 | automorphisms = 80
 | chromatic_number = 3
 | chromatic_index = 4
 | properties = [[Snark (graph theory)|Snark]]&lt;br&gt;[[hypohamiltonian graph|Hypohamiltonian]]
|book thickness=3|queue number=2}}

In the [[mathematics|mathematical]] field of [[graph theory]], the '''double-star snark''' is a [[snark (graph theory)|snark]] with 30 [[vertex (graph theory)|vertices]] and 45 edges.&lt;ref&gt;{{MathWorld|title=Double Star Snark|urlname=DoubleStarSnark}}&lt;/ref&gt;

In 1975, [[ Rufus Isaacs (game theorist) | Rufus Isaacs]] introduced two infinite families of snarks—the [[flower snark]] and the [[BDS snark]], a family that includes the two [[Blanuša snarks]], the [[Descartes snark]] and the [[Szekeres snark]] (BDS stands for Blanuša Descartes Szekeres).&lt;ref&gt;{{Citation | first=R.|last= Isaacs| title=Infinite families of non-trivial trivalent graphs which are not Tait-colorable| journal=[[American Mathematical Monthly]]| volume=82| year=1975| pages=221&amp;ndash;239| doi=10.2307/2319844 | issue=3 | publisher=Mathematical Association of America | jstor=2319844}}&lt;/ref&gt; Isaacs also discovered one 30-vertex snark that does not belongs to the BDS family and that is not a flower snark — the double-star snark.

As a snark, the double-star graph is a connected, bridgeless [[cubic graph]] with [[chromatic index]] equal to 4. The double-star snark is [[planar graph|non-planar]] and [[hamiltonian graph|non-hamiltonian]] but is [[hypohamiltonian graph|hypohamiltonian]].&lt;ref&gt;{{MathWorld|title=Hypohamiltonian Graph|urlname=HypohamiltonianGraph}}&lt;/ref&gt; It has [[book thickness]] 3 and [[queue number]] 2.&lt;ref&gt;Wolz, Jessica; ''Engineering Linear Layouts with SAT.'' Master Thesis, University of Tübingen, 2018&lt;/ref&gt;

==Gallery==
&lt;gallery&gt;
Image:Double-star snark 3COL.svg|The [[chromatic number]] of the double-star snark is 3.
Image:Double-star snark 4color edge.svg|The [[chromatic index]] of the double-star snark is 4.
&lt;/gallery&gt;

== References ==
{{reflist}}

[[Category:Individual graphs]]
[[Category:Regular graphs]]


{{combin-stub}}</text>
      <sha1>j12kjj93xqb2oow4zifz6nshh9uxwj3</sha1>
    </revision>
  </page>
  <page>
    <title>Dual basis in a field extension</title>
    <ns>0</ns>
    <id>1182975</id>
    <revision>
      <id>734108869</id>
      <parentid>644686663</parentid>
      <timestamp>2016-08-12T05:49:14Z</timestamp>
      <contributor>
        <username>Chempencil</username>
        <id>28932601</id>
      </contributor>
      <minor/>
      <comment>Minor grammatical change</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1944">{{Unreferenced|date=December 2009}}
In [[mathematics]], the [[linear algebra]] concept of [[dual basis]] can be applied in the context of a [[finite extension]] ''L''/''K'', by using the [[field trace]]. This requires the property that the field trace ''Tr''&lt;sub&gt;''L''/''K''&lt;/sub&gt;  provides a [[non-degenerate]] [[quadratic form]] over ''K''. This can be guaranteed if the extension is [[separable extension|separable]]; it is automatically true if ''K'' is a [[perfect field]], and hence in the cases where ''K'' is finite, or of characteristic zero.

A '''dual basis''' is not a concrete [[basis (linear algebra)|basis]] like the [[polynomial basis]] or the [[normal basis]]; rather it provides a way of using a second basis for computations.  

Consider two bases for elements in a [[finite field]], GF(''p''&lt;sup&gt;''m''&lt;/sup&gt;):

:&lt;math&gt;B_1 = {\alpha_0, \alpha_1, \ldots, \alpha_{m-1}}&lt;/math&gt;

and

:&lt;math&gt;B_2 = {\gamma_0, \gamma_1, \ldots, \gamma_{m-1}}&lt;/math&gt;

then ''B''&lt;sub&gt;2&lt;/sub&gt; can be considered a dual basis of ''B''&lt;sub&gt;1&lt;/sub&gt; provided

:&lt;math&gt;\operatorname{Tr}(\alpha_i\cdot \gamma_j) = \left\{\begin{matrix} 0, &amp; \operatorname{if}\ i \neq j\\ 1, &amp; \operatorname{otherwise} \end{matrix}\right. &lt;/math&gt;

Here the [[field trace|trace]] of a value in GF(''p''&lt;sup&gt;''m''&lt;/sup&gt;) can be calculated as follows:

:&lt;math&gt;\operatorname{Tr}(\beta ) = \sum_{i=0}^{m-1} \beta^{p^i}&lt;/math&gt;

Using a dual basis can provide a way to easily communicate between devices that use different bases, rather than having to explicitly convert between bases using the [[change of basis|change of bases]] formula.  Furthermore, if a dual basis is implemented then conversion from an element in the original basis to the dual basis can be accomplished with multiplication by the multiplicative identity (usually 1).

{{DEFAULTSORT:Dual Basis In A Field Extension}}
[[Category:Linear algebra]]
[[Category:Field extensions]]
[[Category:Theory of cryptography]]</text>
      <sha1>sq8mi0da5v4hz74e6nf4bfscac4ovto</sha1>
    </revision>
  </page>
  <page>
    <title>Edwin E. Moise</title>
    <ns>0</ns>
    <id>19236494</id>
    <revision>
      <id>827842057</id>
      <parentid>781263508</parentid>
      <timestamp>2018-02-27T01:43:39Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>copy-edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8072">{{redirect|Edwin Moise|the American physician and Confederate judge|Edwin Warren Moïse}}
{{Infobox scientist
|name              = Edwin Evariste Moise
|image = Edwin Moise Headshot.jpg
|image_size = 150px
|caption           = 
|birth_date        = {{birth date|1918|12|22}}
|birth_place       = [[New Orleans]], [[Louisiana]]
|death_date        = {{dda|1998|12|18|1918|12|22}}
|death_place       = [[New York City|New York]], [[New York (state)|New York]]
|fields            = Mathematician
|workplaces        = [[University of Michigan]]&lt;br&gt;[[Institute for Advanced Study]]&lt;br&gt;[[Harvard University]]&lt;br&gt;[[Queens College, City University of New York|Queens College]]
|alma_mater        = [[University of Texas]]
|doctoral_advisor  = [[Robert Lee Moore]]
|doctoral_students = [[James Munkres]]&lt;br&gt;[[Peter Shalen]]
|known_for         = [[3-manifolds]]&lt;br&gt;[[School Mathematics Study Group|SMSG]]
|footnotes         = 
}}

'''Edwin Evariste Moise''' ({{IPAc-en|m|oʊ|ˈ|iː|z}};&lt;ref name="NYT obit" /&gt; December 22, 1918 – December 18, 1998)&lt;ref name="NYT obit"&gt;{{cite news |first=Wolfgang |last=Saxon |title=Edwin Evariste Moise, 79, Mathematics Scholar |url=https://query.nytimes.com/gst/fullpage.html?res=9D07E2DF143FF93BA15751C1A96E958260 |work=New York Times |issn=0362-4331 |date=2008-12-28 |accessdate=2008-09-07 }}
&lt;/ref&gt;&lt;ref name="RootsWeb SSDI"&gt;
{{cite web |url=http://ssdi.rootsweb.ancestry.com/cgi-bin/ssdi.cgi |title=Social Security Death Index Interactive Search |accessdate=2008-09-14 |publisher=RootsWeb (based on Social Security Administration records)|quote= search for Moise, Edwin E}}
&lt;/ref&gt;
was an American mathematician and mathematics education reformer. After his retirement from mathematics he became a [[literary critic]] of 19th-century [[English poetry]] and had several notes published in that field.&lt;ref name="NYT obit" /&gt;&lt;ref name="Anderson Fitzpatrick interview"&gt;
{{cite web |url=http://at.yorku.ca/t/o/p/c/94.htm |title=An Interview of Edwin Moise |accessdate=2008-09-08 |last=Anderson |first=Richard D. |author2=Ben Fitzpatrick, Jr |date=1998-06-29 |work=Topology Atlas |publisher=York University}}
&lt;/ref&gt;

==Early life and education==

Edwin E. Moise was born December 22, 1918 in [[New Orleans]], [[Louisiana]].&lt;ref name="RootsWeb SSDI" /&gt;&lt;ref name="Notices obit"&gt;
{{cite journal |date=May 1999 |title=Mathematics People |journal=[[Notices of the American Mathematical Society]] |volume=46 |issue=5 |pages=573–575 |url=http://www.ams.org/notices/199905/people.pdf |accessdate=2008-09-06 |quote=incorrectly gives December 25 as death date |issn=0002-9920}}&lt;/ref&gt;
He graduated from [[Tulane University]] in 1940.&lt;ref name="NYT obit" /&gt; He worked as a [[cryptanalyst]] and Japanese translator for the [[Office of the Chief of Naval Operations]] during [[World War II]].&lt;ref name="NYT obit" /&gt;&lt;ref name="ICMI profile"&gt;
{{cite web |url=http://www.icmihistory.unito.it/portrait/moise.php |title=History of the International Commission on Mathematical Instruction - Profile of Edwin Evariste Moise |accessdate=2008-09-08 |last=Kilpatrick |first=Jeremy |date=2007-11-27 |publisher=University of Turin}}
&lt;/ref&gt;

He received his [[Ph.D.]] degree in mathematics from the [[University of Texas]] in 1947.&lt;ref name="NYT obit" /&gt; His dissertation was titled "An indecomposable continuum which is homeomorphic to each of its nondegenerate subcontinua," a topic in [[continuum theory]], and was written under the direction of [[Robert Lee Moore]]. In his dissertation Moise coined the term [[pseudo-arc]].&lt;ref name="ICMI profile" /&gt;&lt;ref name="Students of Moore"&gt;
{{cite web |url=http://www.discovery.utexas.edu/rlm/reference/fitzpatrick.html |title=The Students of R.L. Moore |accessdate=2008-09-08 |last=Fitzpatrick, Jr. |first=Ben |date=July 2005 |work=Legacy of R. L. Moore |publisher=University of Texas}}
&lt;/ref&gt;

==Career==

Moise taught at the [[University of Michigan]] from 1947 to 1960. He was James B. Conant Professor of education and mathematics at [[Harvard University]]  from 1960 to 1971. He held a Distinguished Professorship at [[Queens College, City University of New York]] from 1971 to 1987.&lt;ref name="NYT obit" /&gt;&lt;ref name="ICMI profile" /&gt;

Moise started working on the topology of [[3-manifold]]s while at the [[University of Michigan]]. During 1949–1951 he held an appointment at the [[Institute for Advanced Study]] during which he proved [[Moise's theorem]] that every 3-manifold can be [[triangulation (topology)|triangulated]] in an essentially unique way.&lt;ref name="ICMI profile" /&gt;

Moise joined the [[School Mathematics Study Group]] when it started in 1958, as a member of the geometry writing team. The team produced several course outlines and sample pages for a 10th grade [[geometry]] course, and then Moise and Floyd L. Downs wrote a geometry textbook, based on the team's approach, that was published in 1964. The textbook used metric postulates instead of [[Euclidean geometry#Axioms|Euclid's postulates]], a controversial approach supported by some mathematicians such as [[Saunders Mac Lane]] but opposed by others such as Alexander Wittenberg and [[Morris Kline]].&lt;ref name="ICMI profile" /&gt;

Moise was a president of the [[Mathematical Association of America]], a vice-president of the [[American Mathematical Society]], a Fellow of the [[American Academy of Arts and Sciences]], and was on the Executive Committee of the [[International Commission on Mathematical Instruction]].&lt;ref name="NYT obit" /&gt;&lt;ref name="ICMI profile" /&gt;

Moise retired from Queens College in 1987 and started a second career studying 19th century [[English poetry]].&lt;ref name="NYT obit" /&gt; He had six short notes of [[literary criticism]] published.&lt;ref name="Anderson Fitzpatrick interview" /&gt;

In the middle and late 1960s, Moise was among the few members of the senior faculty at Harvard University who strongly and publicly opposed the [[Vietnam War]].

Moise died in [[New York City]] on December 18, 1998, aged 79.&lt;ref name="NYT obit" /&gt;&lt;ref name="RootsWeb SSDI" /&gt;

==See also==
* [[Moise's theorem]]

==Selected publications==

* {{cite book | last = Moise | first = Edwin E. | title = Elementary Geometry from an Advanced Standpoint |edition=3rd | publisher = Addison-Wesley | location = Boston | year = 1990 |origyear=1963| isbn = 978-0-201-50867-3 }}
* {{cite book | last = Moise | first = Edwin E. |author2=Floyd L. Downs | title = Geometry | publisher = Addison Wesley Publishing Company | location = Reading, MA | year = 1991 |origyear=1964| isbn = 978-0-201-25335-1 }}
* {{cite book |title=The Number Systems of Elementary Mathematics; Counting, Measurement, and Coordinates |last=Moise |first=Edwin E. |year=1966 |publisher=Addison-Wesley |location=Reading, MA |oclc=359171}}
* {{cite book |title=Calculus |edition = 2nd |last=Moise |first=Edwin E.|year=1972 |origyear=1967|publisher=Addison-Wesley |location=Reading, MA |oclc=363809 }}
* {{cite book | last = Moise | first = Edwin E. | title = Geometric Topology in Dimensions 2 and 3 | publisher = New York : Springer-Verlag | location = New York | year = 1977 | isbn = 978-0-387-90220-3 }}
* {{cite book | last = Moise | first = Edwin E. | title = Introductory Problem Courses in Analysis and Topology | publisher = Springer-Verlag | location = Berlin | year = 1982 | isbn = 978-0-387-90701-7 }}

==Notes==
&lt;references /&gt;

==External links==
*{{MathGenealogy|id=306}}
*[http://www.maa.org/history/presidents/moise.html MAA presidents: Edwin Evariste Moise]

{{Authority control}}

{{DEFAULTSORT:Moise, Edwin Evariste}}
[[Category:1918 births]]
[[Category:1998 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Queens College, City University of New York faculty]]
[[Category:Geometers]]
[[Category:Harvard University faculty]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Presidents of the Mathematical Association of America]]
[[Category:Topologists]]
[[Category:Tulane University alumni]]
[[Category:University of Michigan faculty]]
[[Category:University of Texas at Austin alumni]]
[[Category:Guggenheim Fellows]]</text>
      <sha1>fbf3wvpukkq79mm4ec2ixc6d2cl8u6g</sha1>
    </revision>
  </page>
  <page>
    <title>External (mathematics)</title>
    <ns>0</ns>
    <id>13933682</id>
    <revision>
      <id>712564492</id>
      <parentid>678511403</parentid>
      <timestamp>2016-03-29T20:57:50Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6525">{{unreferenced|date=December 2007}}
The term '''external''' is useful for describing certain algebraic structures. The term comes from the concept of an [[Binary operation#External binary operations|external binary operation]] which is a binary operation that draws from some ''external set''. To be more specific, a '''left external binary operation''' on ''S'' over ''R'' is a function &lt;math&gt;f : R \times S \rightarrow S&lt;/math&gt; and a '''right external binary operation''' on ''S'' over ''R'' is a function &lt;math&gt;f : S \times R \rightarrow S&lt;/math&gt; where ''S'' is the set the operation is defined on, and ''R'' is the external set (the set the operation is defined ''over'').

== Generalizations ==

The ''external'' concept is a generalization rather than a specialization, and as such, it is different from many terms in mathematics. A similar but opposite concept is that of an ''internal binary function'' from ''R'' to ''S'', defined as a function &lt;math&gt;f : R \times R \rightarrow S&lt;/math&gt;. Internal binary functions are like binary functions, but are a form of specialization, so they only accept a subset of the domains of binary functions. Here we list these terms with the [[Function (mathematics)|function]] [[Method signature|signatures]] they imply, along with some examples:

* &lt;math&gt;f : Q \times R \rightarrow S&lt;/math&gt; ([[binary function]])
** Example:  [[exponentiation]] (&lt;math&gt;z^q : \Bbb{Z} \times \Bbb{Q} \rightarrow \Bbb{C}&lt;/math&gt; as in &lt;math&gt;{(-1)}^{1/2} = i&lt;/math&gt;), 
** Example: [[element (mathematics)|set membership]] (&lt;math&gt;(\in) : S \times \mathbf{Set} \rightarrow \Bbb{B}&lt;/math&gt; where &lt;math&gt; \mathbf{Set} &lt;/math&gt; is the [[category of sets]])
** Examples: [[matrix multiplication]], the [[tensor product]], and the [[Cartesian product]]
* &lt;math&gt;f : R \times R \rightarrow S&lt;/math&gt; (internal binary function)
** Example: internal [[binary relations]] (&lt;math&gt;(\le) : R \times R \rightarrow \Bbb{B}&lt;/math&gt;)
** Examples: the [[dot product]], the [[inner product space|inner product]], and [[metric (mathematics)|metrics]].
* &lt;math&gt;f : R \times S \rightarrow S&lt;/math&gt; ([[Binary operation#External binary operations|external binary operation]])
** Examples: [[dynamical system]] [[flow (mathematics)|flows]], [[group action]]s, [[projection (set theory)|projection maps]], and [[scalar multiplication]].
* &lt;math&gt;f : S \times S \rightarrow S&lt;/math&gt; ([[binary operation]]).
** Examples: [[addition]], [[multiplication]],  [[permutation]]s, and the [[cross product]].

== External monoids ==

Since [[monoid]]s are defined in terms of [[binary operations]], we can define an ''external monoid'' in terms of ''external binary operations''. For the sake of simplicity, unless otherwise specified, a ''left'' external binary operation is implied. Using the term ''external'', we can make the generalizations:

* An '''external [[magma (mathematics)|magma]]''' &lt;math&gt;(S, \times)&lt;/math&gt; over ''R'' is a set ''S'' with an external binary operation. This satisfies &lt;math&gt;r \times s \in S&lt;/math&gt; for all &lt;math&gt;s \in S, r \in R&lt;/math&gt; (external [[closure (mathematics)|closure]]). 
* An '''external [[semigroup]]''' &lt;math&gt;(S, \times)&lt;/math&gt; over &lt;math&gt;(R, \cdot)&lt;/math&gt; is an external magma that satisfies &lt;math&gt;(r_1 \cdot r_2) \times s = r_1 \times (r_2 \times s)&lt;/math&gt; for all &lt;math&gt;s \in S, r_1, r_2 \in R&lt;/math&gt; (externally [[associative]]). 
* An '''external [[monoid]]''' &lt;math&gt;(S, \times)&lt;/math&gt; over &lt;math&gt;(R, \cdot)&lt;/math&gt; is an external semigroup in which there exists &lt;math&gt;1 \in R&lt;/math&gt; such that &lt;math&gt;1 \times s = s&lt;/math&gt; for all &lt;math&gt;s \in S&lt;/math&gt; (has external [[identity element]]).

== Modules as external rings ==

Much of the machinery of [[module (mathematics)|modules]] and [[vector spaces]] are fairly straightforward, or discussed above. The only thing not covered yet is their distribution axioms. The external ring multiplication &lt;math&gt;\otimes&lt;/math&gt; is externally [[Distributive property|distributive]] in &lt;math&gt;(S, \oplus, \otimes)&lt;/math&gt; over the [[ring (mathematics)|ring]] &lt;math&gt;(R, +, \cdot)&lt;/math&gt; [[iff]]:
* &lt;math&gt;r \otimes (s_1 \oplus s_2) = (r \otimes s_1) \oplus (r \otimes s_2)&lt;/math&gt; for all &lt;math&gt;s_1,s_2 \in S, r \in R&lt;/math&gt; and: 
* &lt;math&gt;(r_1 + r_2) \otimes s = (r_1 \otimes s) \oplus (r_2 \otimes s)&lt;/math&gt; for all &lt;math&gt;s \in S, r_1,r_2 \in R&lt;/math&gt;

Using these terminology we can make the following local generalizations:
* An '''external semiring''' &lt;math&gt;(S, \oplus, \otimes)&lt;/math&gt; over the [[semiring]] &lt;math&gt;(R, +, \cdot)&lt;/math&gt; is a [[commutative]] [[monoid]] &lt;math&gt;(S, \oplus)&lt;/math&gt; and an external monoid &lt;math&gt;(S, \otimes)&lt;/math&gt; where &lt;math&gt;\otimes&lt;/math&gt; is externally [[Distributive property|distributive]] in &lt;math&gt;(S, \oplus, \otimes)&lt;/math&gt; over the [[semiring]] &lt;math&gt;(R, +, \cdot)&lt;/math&gt;. 
* An '''external ring''' &lt;math&gt;(S, \oplus, \otimes)&lt;/math&gt; over the [[ring (mathematics)|ring]] &lt;math&gt;(R, +, \cdot)&lt;/math&gt; is an [[abelian group]] &lt;math&gt;(S, \oplus)&lt;/math&gt; and an external monoid &lt;math&gt;(S, \otimes)&lt;/math&gt; where &lt;math&gt;\otimes&lt;/math&gt; is externally [[Distributive property|distributive]] in &lt;math&gt;(S, \oplus, \otimes)&lt;/math&gt; over the [[ring (mathematics)|ring]] &lt;math&gt;(R, +, \cdot)&lt;/math&gt;.

== Other examples ==

Now that we have all the terminology we need, we can make simple connections between various structures:
* Complex exponentiation forms an external [[monoid]] &lt;math&gt;(\Bbb{C}, \uparrow)&lt;/math&gt; over the [[abelian group]] &lt;math&gt;(\Bbb{C}, \cdot)&lt;/math&gt;.
* Prime factorization forests form an external [[semiring]] &lt;math&gt;(\Bbb{N}, \cdot, \uparrow)&lt;/math&gt; over the [[semiring]] &lt;math&gt;(\Bbb{N}, +, \cdot)&lt;/math&gt;.
* A [[dynamical system (definition)|dynamical system]] &lt;math&gt;(T, S, \Phi)&lt;/math&gt; is an '''external monoid''' &lt;math&gt;(S, \Phi)&lt;/math&gt; over the [[monoid]] &lt;math&gt;(T, {+})&lt;/math&gt;.
* A [[semimodule]] is an '''external semiring''' over a [[semiring]].
* A [[module (mathematics)|module]] is an '''external ring''' over a [[ring (mathematics)|ring]].
* A [[vector space]] is an '''external ring''' over a [[field (mathematics)|field]].

== Usefulness ==

It could be argued that we already have terms for the concepts described here, like [[dynamical systems]], [[group actions]], [[module (mathematics)|modules]], and [[vector spaces]]. However, there is still no other terminology available for an '''external monoid''' for which this terminology gives us a concise expression. Above all else, this is a reason this term should be of use in the mathematical community.

[[Category:Abstract algebra]]
[[Category:Binary operations]]</text>
      <sha1>9kcir5pv8ca0znvsvhwj8f2vr4x1fpu</sha1>
    </revision>
  </page>
  <page>
    <title>Farey sequence</title>
    <ns>0</ns>
    <id>350164</id>
    <revision>
      <id>870943926</id>
      <parentid>870221010</parentid>
      <timestamp>2018-11-27T23:20:25Z</timestamp>
      <contributor>
        <username>Sapphorain</username>
        <id>12923157</id>
      </contributor>
      <comment>Alternate definition; citation needed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23561">[[Image:Farey diagram horizontal arc 9.svg|thumb|300px|[[Farey diagram]] to ''F''&lt;sub&gt;9&lt;/sub&gt; represented with circular arcs. In [http://upload.wikimedia.org/wikipedia/commons/9/91/Farey_diagram_horizontal_arc_9.svg the SVG image], hover over a curve to highlight it and its terms.]]
[[Image:Farey diagram square 9.svg|thumb|Farey diagram to ''F''&lt;sub&gt;9&lt;/sub&gt;.]]
[[Image:Farey sequence denominators 9.svg|thumb|Symmetrical pattern made by the denominators of the Farey sequence, ''F''&lt;sub&gt;9&lt;/sub&gt;.]]
[[Image:Farey sequence denominators 25.svg|thumb|Symmetrical pattern made by the denominators of the Farey sequence, ''F''&lt;sub&gt;25&lt;/sub&gt;.]]

In [[mathematics]], the '''Farey sequence''' of order ''n'' is the [[sequence]] of completely reduced [[vulgar fraction|fraction]]s, either between 0 and 1, or without this restriction,&lt;ref&gt;[[Ivan M. Niven]] and Herbert S. Zuckerman, ''An Introduction to the theory of numbers'', third edition, John Wiley and Sons 1972, Definition 6.1. ''"The sequence of all reduced fractions with denominators not exceeding n, listed in order of their size, is called the Farey sequence of order n."'' With the comment: ''"This definition of the Farey sequences seems to be the most convenient. However, some authors prefer to restrict the fractions to the interval from 0 to 1."''&lt;/ref&gt; which when [[in lowest terms]] have [[denominator]]s less than or equal to ''n'', arranged in order of increasing size.

With the restricted definition, each Farey sequence starts with the value 0, denoted by the fraction &lt;sup&gt;0&lt;/sup&gt;⁄&lt;sub&gt;1&lt;/sub&gt;, and ends with the value 1, denoted by the fraction &lt;sup&gt;1&lt;/sup&gt;⁄&lt;sub&gt;1&lt;/sub&gt; (although some authors omit these terms).

A Farey sequence is sometimes called a Farey [[series (mathematics)|series]],{{citation needed|date=November 2018}} which is not strictly correct, because the terms are not summed. 

==Examples==
The Farey sequences of orders 1 to 8 are :
:''F''&lt;sub&gt;1&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;2&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;3&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;4&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;5&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;6&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;7&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|6|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
:''F''&lt;sub&gt;8&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|6|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|7|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }

{| class="toccolours" style="text-align:center; margin-top:1em"
! Centered
|-
| ''F''&lt;sub&gt;1&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;2&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;3&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;4&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;5&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;6&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;7&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|6|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|-
|''F''&lt;sub&gt;8&lt;/sub&gt; = { {{sfrac|0|1}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|2}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|2|3}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|3|4}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|4|5}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|5|6}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|6|7}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|7|8}}&lt;sub&gt;,&lt;/sub&gt; {{sfrac|1|1}} }
|}
{| class="toccolours" style="margin-top:1em"
! Sorted
|-
|&lt;pre style="background:transparent; border:none; font-size:88%;"&gt;
 F1 = {0/1,                                                                                                          1/1}
 F2 = {0/1,                                                   1/2,                                                   1/1}
 F3 = {0/1,                               1/3,                1/2,                2/3,                               1/1}
 F4 = {0/1,                     1/4,      1/3,                1/2,                2/3,      3/4,                     1/1}
 F5 = {0/1,                1/5, 1/4,      1/3,      2/5,      1/2,      3/5,      2/3,      3/4, 4/5,                1/1}
 F6 = {0/1,           1/6, 1/5, 1/4,      1/3,      2/5,      1/2,      3/5,      2/3,      3/4, 4/5, 5/6,           1/1}
 F7 = {0/1,      1/7, 1/6, 1/5, 1/4, 2/7, 1/3,      2/5, 3/7, 1/2, 4/7, 3/5,      2/3, 5/7, 3/4, 4/5, 5/6, 6/7,      1/1}
 F8 = {0/1, 1/8, 1/7, 1/6, 1/5, 1/4, 2/7, 1/3, 3/8, 2/5, 3/7, 1/2, 4/7, 3/5, 5/8, 2/3, 5/7, 3/4, 4/5, 5/6, 6/7, 7/8, 1/1}
&lt;/pre&gt;
|}

==History==
:''The history of 'Farey series' is very curious'' &amp;mdash; Hardy &amp; Wright (1979) Chapter III&lt;ref&gt;[[G. H. Hardy|Hardy, G.H.]] &amp; [[E. M. Wright|Wright, E.M.]] (1979) ''An Introduction to the Theory of Numbers'' (Fifth Edition). Oxford University Press. {{ISBN|0-19-853171-0}}&lt;/ref&gt;

:''... once again the man whose name was given to a mathematical relation was not the original discoverer so far as the records go.'' &amp;mdash; Beiler (1964) Chapter XVI&lt;ref name=Beiler&gt;Beiler, Albert H. (1964) ''Recreations in the Theory of Numbers'' (Second Edition). Dover. {{ISBN|0-486-21096-0}}. Cited in [http://www.cut-the-knot.org/blue/FareyHistory.shtml Farey Series, A Story] at [[Cut-the-Knot]]&lt;/ref&gt;

Farey sequences are named after the [[United Kingdom|British]] [[geologist]] [[John Farey, Sr.]], whose letter about these sequences was published in the ''[[Philosophical Magazine]]'' in 1816. Farey conjectured, without offering proof, that each new term in a Farey sequence expansion is the [[mediant (mathematics)|mediant]] of its neighbours. Farey's letter was read by [[Cauchy]], who provided a proof in his ''Exercices de mathématique'', and attributed this result to Farey. In fact, another mathematician, [[Charles Haros]], had published similar results in 1802 which were not known either to Farey or to Cauchy.&lt;ref name=Beiler/&gt; Thus it was a historical accident that linked Farey's name with these sequences. This is an example of [[Stigler's law of eponymy]].

==Properties==
[[File:Farey diagram circle packing 5.png|thumb]]
===Sequence length and index of a fraction===
The Farey sequence of order ''n'' contains all of the members of the Farey sequences of lower orders. In particular ''F&lt;sub&gt;n&lt;/sub&gt;'' contains all of the members of ''F''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt; and also contains an additional fraction for each number that is less than ''n'' and [[coprime]] to ''n''. Thus ''F''&lt;sub&gt;6&lt;/sub&gt; consists of ''F''&lt;sub&gt;5&lt;/sub&gt; together with the fractions {{sfrac|1|6}} and {{sfrac|5|6}}. 

The middle term of a Farey sequence ''F''&lt;sub&gt;''n''&lt;/sub&gt; is always {{sfrac|1|2}}, 
for ''n'' &gt; 1. From this, we can relate the lengths of ''F&lt;sub&gt;n&lt;/sub&gt;'' and ''F''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt; using [[Euler's totient function]] &lt;math&gt;\varphi(n)&lt;/math&gt; :

:&lt;math&gt;|F_n| = |F_{n-1}| + \varphi(n).&lt;/math&gt;

Using the fact that |''F''&lt;sub&gt;1&lt;/sub&gt;| = 2, we can derive an expression for the length of ''F&lt;sub&gt;n&lt;/sub&gt;''&lt;ref&gt;{{Cite OEIS|A005728}}&lt;/ref&gt;:

:&lt;math&gt;|F_n| = 1 + \sum_{m=1}^n \varphi(m).&lt;/math&gt;

We also have :

:&lt;math&gt;|F_n| = \frac{1}{2}\left(3+\sum_{d=1}^n\mu(d)\left\lfloor\tfrac{n}{d}\right\rfloor^2\right),&lt;/math&gt;
and by a [[Möbius inversion formula]] : 
:&lt;math&gt;|F_n| = \frac{1}{2}(n+3)n-\sum_{d=2}^n|F_{\lfloor n/d\rfloor}|,&lt;/math&gt;
where µ(''d'') is the number-theoretic [[Möbius function]], and  &lt;math&gt;\lfloor \tfrac{n}{d} \rfloor &lt;/math&gt; is the [[Floor and ceiling functions|floor function]]. 

The asymptotic behaviour of |''F&lt;sub&gt;n&lt;/sub&gt;''| is :

:&lt;math&gt;|F_n| \sim \frac {3n^2}{\pi^2}.&lt;/math&gt;

The index &lt;math&gt;I_n(a_{k,n})=k&lt;/math&gt; of a fraction &lt;math&gt;a_{k,n}&lt;/math&gt; in the Farey sequence &lt;math&gt;F_n=\{a_{k,n} : k = 0, 1, \ldots, m_n\}&lt;/math&gt; is simply the position that &lt;math&gt;a_{k,n}&lt;/math&gt;  occupies in the sequence. This is of special relevance as it is used in an alternative formulation of the [[Riemann hypothesis]], see [[#Riemann_hypothesis|below]]. Various useful properties follow:

:&lt;math&gt;I_n(0/1) = 0,&lt;/math&gt;
:&lt;math&gt;I_n(1/n) = 1,&lt;/math&gt;
:&lt;math&gt;I_n(1/2) = (|F_n|-1)/2,&lt;/math&gt;
:&lt;math&gt;I_n(1/1) = |F_n|-1 ,&lt;/math&gt;
:&lt;math&gt;I_n(h/k) = |F_n|-1-I_n((k-h)/k).&lt;/math&gt;

The index of &lt;math&gt;1/k&lt;/math&gt; where &lt;math&gt;n/(i+1) &lt; k \leq n/i &lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; is the [[least common multiple]] of the first &lt;math&gt;i&lt;/math&gt; numbers, &lt;math&gt;n={\rm lcm}([2,i]) &lt;/math&gt;, is given by&lt;ref&gt;{{cite arXiv |last=Tomas |first=Rogelio |eprint=1802.07792 |title=Partial Franel sums |class=math.NT |date=2018}} Accessed: November 18, 2018.&lt;/ref&gt;:

:&lt;math&gt;I_n(1/k) = 1 + n \sum_{j=1}^{i} \frac{\varphi(j)}{j} - k\Phi(i).&lt;/math&gt;

===Farey neighbours&lt;!-- This section is linked from [[Farey pair]] --&gt;===
Fractions which are neighbouring terms in any Farey sequence are known as a ''Farey pair'' and have the following properties.

If {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} are neighbours in a Farey sequence, with {{sfrac|''a''|''b''}}&amp;nbsp;&lt;&amp;nbsp;{{sfrac|''c''|''d''}}, then their difference {{sfrac|''c''|''d''}}&amp;nbsp;&amp;minus;&amp;nbsp;{{sfrac|''a''|''b''}} is equal to {{sfrac|1|''bd''}}.{{why|date=May 2018}} Since 

:&lt;math&gt;\frac{c}{d} - \frac{a}{b} = \frac{bc - ad}{bd},&lt;/math&gt;

this is equivalent to saying that 

:&lt;math&gt;bc - ad = 1&lt;/math&gt;.

Thus {{sfrac|1|3}} and {{sfrac|2|5}} are neighbours in ''F''&lt;sub&gt;5&lt;/sub&gt;, and their difference is {{sfrac|1|15}}.

The converse is also true. If 

:&lt;math&gt;bc - ad = 1&lt;/math&gt;

for positive integers ''a'',''b'',''c'' and ''d'' with ''a'' &lt; ''b'' and ''c'' &lt; ''d'' then {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} will be neighbours in the Farey sequence of order max(''b,d'').

If {{sfrac|''p''|''q''}} has neighbours {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} in some Farey sequence, with 

:&lt;math&gt;\frac{a}{b} &lt; \frac{p}{q} &lt; \frac{c}{d} &lt;/math&gt;

then {{sfrac|''p''|''q''}} is the [[mediant (mathematics)|mediant]] of {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} &amp;ndash; in other words, 

:&lt;math&gt;\frac{p}{q} = \frac{a + c}{b + d}.&lt;/math&gt;

This follows easily from the previous property, since if {{nowrap|1=''bp'' – ''aq'' = ''qc'' – ''pd'' = 1}}, then {{nowrap|1=''bp'' + ''pd'' = ''qc'' + ''aq''}}, {{nowrap|1=''p''(''b'' + ''d'') = ''q''(''a'' + ''c'')}}, {{nowrap|1={{sfrac|''p''|''q''}} = {{sfrac|''a'' + ''c''|''b'' + ''d''}}}}.

It follows that if {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} are neighbours in a Farey sequence then the first term that appears between them as the order of the Farey sequence is incremented is 

:&lt;math&gt;\frac{a+c}{b+d},&lt;/math&gt;

which first appears in the Farey sequence of order {{nowrap|''b'' + ''d''}}.

Thus the first term to appear between {{sfrac|1|3}} and {{sfrac|2|5}} is {{sfrac|3|8}}, which appears in ''F''&lt;sub&gt;8&lt;/sub&gt;.

The ''[[Stern–Brocot tree]]'' is a data structure showing how the sequence is built up from 0 (= {{sfrac|0|1}}) and 1 (= {{sfrac|1|1}}), by taking successive mediants.

Fractions that appear as neighbours in a Farey sequence have closely related [[continued fraction]] expansions. Every fraction has two continued fraction expansions &amp;mdash; in one the final term is 1; in the other the final term is greater than 1. If {{sfrac|''p''|''q''}}, which first appears in Farey sequence ''F&lt;sub&gt;q&lt;/sub&gt;'', has continued fraction expansions

:[0; ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n'' &amp;minus; 1&lt;/sub&gt;, ''a''&lt;sub&gt;''n''&lt;/sub&gt;, 1]
:[0; ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n'' &amp;minus; 1&lt;/sub&gt;, ''a''&lt;sub&gt;''n''&lt;/sub&gt; + 1]

then the nearest neighbour of {{sfrac|''p''|''q''}} in ''F&lt;sub&gt;q&lt;/sub&gt;'' (which will be its neighbour with the larger denominator) has a continued fraction expansion

:[0; ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n''&lt;/sub&gt;]

and its other neighbour has a continued fraction expansion 

:[0; ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''n'' &amp;minus; 1&lt;/sub&gt;]

For example, {{sfrac|3|8}} has the two continued fraction expansions {{nowrap|[0; 2, 1, 1, 1]}} and {{nowrap|[0; 2, 1, 2]}}, and its neighbours in ''F''&lt;sub&gt;8&lt;/sub&gt; are {{sfrac|2|5}}, which can be expanded as {{nowrap|[0; 2, 1, 1]}}; and {{sfrac|1|3}}, which can be expanded as {{nowrap|[0; 2, 1]}}.

===Applications===
Farey sequences are very useful to find rational approximations of irrational numbers.&lt;ref&gt;"[http://nrich.maths.org/6596 Farey Approximation]", ''NRICH.maths.org''. Accessed: 18 November 2018.&lt;/ref&gt;

In physics systems featuring resonance phenomena Farey sequences provide a very elegant and efficient method to compute resonance locations in 1D&lt;ref&gt;*{{cite arXiv |last1=Zhenhua Li |first1=A. |last2=Harter |first2=W.G. |eprint=1308.4470v1 |title=Quantum Revivals of Morse Oscillators and Farey-Ford Geometry |class=quant-ph |date=2013}} Accessed: November 18, 2018.&lt;/ref&gt; and 2D.&lt;ref&gt;Tomas, R. (2014). "[http://prst-ab.aps.org/abstract/PRSTAB/v17/i1/e014001 From Farey sequences to resonance diagrams]", ''prst-ab.aps.org''. Accessed: 18 November 2018.&lt;/ref&gt;

===Ford circles===
[[File:Comparison_Ford_circles_Farey_diagram.svg|thumb|250px|Comparison of Ford circles and a Farey diagram with circular arcs for ''n'' from 1 to 9. Note that each arc intersects its corresponding circles at right angles. In [http://upload.wikimedia.org/wikipedia/commons/0/0f/Comparison_Ford_circles_Farey_diagram.svg the SVG image], hover over a circle or curve to highlight it and its terms.]]

There is a connection between Farey sequence and [[Ford circle]]s.

For every fraction ''p''/''q'' (in its lowest terms) there is a Ford circle C[''p''/''q''], which is the circle with radius 1/(2''q''&lt;sup&gt;2&lt;/sup&gt;) and centre at (''p''/''q'', 1/(2''q''&lt;sup&gt;2&lt;/sup&gt;)). Two Ford circles for different fractions are either [[Disjoint sets|disjoint]] or they are [[tangent]] to one another—two Ford circles never intersect. If 0 &lt; ''p''/''q'' &lt; 1 then the Ford circles that are tangent to C[''p''/''q''] are precisely the Ford circles for fractions that are neighbours of ''p''/''q'' in some Farey sequence.

Thus ''C''[2/5] is tangent to ''C''[1/2], ''C''[1/3], ''C''[3/7], ''C''[3/8] etc.

===Riemann hypothesis===
Farey sequences are used in two equivalent formulations of the [[Riemann hypothesis]]. Suppose the terms of &lt;math&gt;F_n&lt;/math&gt; are &lt;math&gt;\{a_{k,n} : k = 0, 1, \ldots, m_n\}&lt;/math&gt;. Define &lt;math&gt;d_{k,n} = a_{k,n} - k/m_n&lt;/math&gt;, in other words &lt;math&gt;d_{k,n}&lt;/math&gt; is the difference between the ''k''th term of the ''n''th Farey sequence, and the ''k''th member of a set of the same number of points, distributed evenly on the unit interval. In 1924 [[Jérôme Franel]]&lt;ref&gt;"[http://www.digizeitschriften.de/dms/resolveppn/?PID=GDZPPN00250653X Les suites de Farey et le problème des nombres premiers]", ''Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse'' 1924, 198-201. {{fr icon}}&lt;/ref&gt; proved that the statement

: &lt;math&gt;\sum_{k=1}^{m_n} d_{k,n}^2 = O (n^r)\quad\forall r&gt;-1&lt;/math&gt;

is equivalent to the Riemann hypothesis, and then [[Edmund Landau]]&lt;ref&gt;"[http://www.digizeitschriften.de/dms/resolveppn/?PID=GDZPPN002506548 Bemerkungen zu der vorstehenden Abhandlung von Herrn Franel]", ''Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse'' 1924, 202-206. {{de icon}}&lt;/ref&gt; remarked (just after Franel's paper) that the statement

: &lt;math&gt;\sum_{k=1}^{m_n} |d_{k,n}| = O (n^r)\quad\forall r&gt;1/2&lt;/math&gt;

is also equivalent to the Riemann hypothesis.

==Next term==

A surprisingly simple algorithm exists to generate the terms of ''F&lt;sub&gt;n&lt;/sub&gt;'' in either traditional order (ascending) or non-traditional order (descending). The algorithm computes each successive entry in terms of the previous two entries using the mediant property given above. If {{sfrac|''a''|''b''}} and {{sfrac|''c''|''d''}} are the two given entries, and {{sfrac|''p''|''q''}} is the unknown next entry, then {{sfrac|''c''|''d''}}&amp;nbsp;=&amp;nbsp;{{sfrac|''a''&amp;nbsp;+&amp;nbsp;''p''|''b''&amp;nbsp;+&amp;nbsp;''q''}}. Since {{sfrac|''c''|''d''}} is in lowest terms,  there must be an integer ''k'' such that ''kc''&amp;nbsp;=&amp;nbsp;''a''&amp;nbsp;+&amp;nbsp;''p'' and ''kd''&amp;nbsp;=&amp;nbsp;''b''&amp;nbsp;+&amp;nbsp;''q'', giving ''p''&amp;nbsp;=&amp;nbsp;''kc''&amp;nbsp;&amp;minus;&amp;nbsp;''a'' and ''q''&amp;nbsp;=&amp;nbsp;''kd''&amp;nbsp;&amp;minus;&amp;nbsp;''b''. If we consider ''p'' and ''q'' to be functions of ''k'', then
:&lt;math&gt; \frac{p(k)}{q(k)}- \frac{c}{d} = \frac{cb - da}{d(kd - b)}&lt;/math&gt;
so the larger ''k'' gets, the closer {{sfrac|''p''|''q''}} gets to {{sfrac|''c''|''d''}}.

To give the next term in the sequence ''k'' must be as large as possible, subject to ''kd''&amp;nbsp;&amp;minus;&amp;nbsp;''b''&amp;nbsp;≤&amp;nbsp;''n'' (as we are only considering numbers with denominators not greater than ''n''), so ''k'' is the greatest integer&amp;nbsp;≤&amp;nbsp;{{sfrac|''n''&amp;nbsp;+&amp;nbsp;''b''|''d''}}. Putting this value of ''k'' back into the equations for ''p'' and ''q'' gives
:&lt;math&gt; p = \left\lfloor\frac{n+b}{d}\right\rfloor c - a&lt;/math&gt;
:&lt;math&gt; q = \left\lfloor\frac{n+b}{d}\right\rfloor d - b&lt;/math&gt;

This is implemented in [[Python (programming language)|Python]] as:
&lt;source lang="python"&gt;
def farey_function(n, descending=False):
    """Print the nth Farey sequence, either ascending or descending."""
    a, b, c, d = 0, 1, 1, n
    if descending: 
        a, c = 1, n-1
    print "%d/%d" % (a,b)
    while (c &lt;= n and not descending) or (a &gt; 0 and descending):
        k = int((n + b) / d)
        a, b, c, d = c, d, (k*c-a), (k*d-b)
        print "%d/%d" % (a,b)
&lt;/source&gt;

Brute-force searches for solutions to [[Diophantine equation]]s in rationals can often take advantage of the Farey series (to search only reduced forms).  The lines marked (*) can also be modified to include any two adjacent terms so as to generate terms only larger (or smaller) than a given term.&lt;ref&gt;Norman Routledge, "Computing Farey Series," ''[[The Mathematical Gazette]]'', Vol. ''' 92 ''' (No. 523), 55&amp;ndash;62 (March 2008).&lt;/ref&gt;

==See also==
* [[ABACABA pattern]]
* [[Stern–Brocot tree]]
* [[Euler's totient function]]

==References==
&lt;references/&gt;

==Further reading==
* [[Allen Hatcher]], [http://pi.math.cornell.edu/~hatcher/TN/TNpage.html Topology of Numbers]
* [[Ronald L. Graham]], [[Donald E. Knuth]], and [[Oren Patashnik]], ''Concrete Mathematics: A Foundation for Computer Science'', 2nd Edition (Addison-Wesley, Boston, 1989); in particular, Sec. 4.5 (pp. 115&amp;ndash;123), Bonus Problem 4.61 (pp. 150, 523&amp;ndash;524), Sec. 4.9 (pp. 133&amp;ndash;139), Sec. 9.3, Problem 9.3.6 (pp. 462&amp;ndash;463).  {{ISBN|0-201-55802-5}}.
* Linas Vepstas. ''The Minkowski Question Mark, GL(2,Z), and the Modular Group.'' http://linas.org/math/chap-minkowski.pdf reviews the isomorphisms of the Stern-Brocot Tree.
* Linas Vepstas. ''Symmetries of Period-Doubling Maps.'' http://linas.org/math/chap-takagi.pdf reviews connections between Farey Fractions and Fractals.
* Scott B. Guthery, ''A Motif of Mathematics: History and Application of the Mediant and the Farey Sequence'', (Docent Press, Boston, 2010). {{ISBN|1-4538-1057-9}}.
* Cristian Cobeli and Alexandru Zaharescu, ''The Haros-Farey Sequence at Two Hundred Years. A Survey'', Acta Univ. Apulensis Math. Inform. no. 5 (2003) 1–38, [http://www.emis.de/journals/AUA/acta5/survey3.ps_pages1-20.pdf pp. 1&amp;ndash;20] [http://www.emis.de/journals/AUA/acta5/survey3.ps_pages21-38.pdf pp. 21&amp;ndash;38]
* Andrey O. Matveev, ''Farey Sequences: Duality and Maps Between Subsequences'', (De Gruyter, Berlin, 2017). {{ISBN|978-3-11-054662-0}}.

==External links==
* [[Alexander Bogomolny]]. [http://www.cut-the-knot.org/blue/Farey.shtml Farey series] and [http://www.cut-the-knot.org/blue/Stern.shtml Stern-Brocot Tree] at [[Cut-the-Knot]] 
* Ettore Pennestri'. [https://www.researchgate.net/publication/297000899_Kinematic_synthesis_of_gear_trains_A_Brocot_table_of_base_120 A Brocot table of base 120]
* {{springer|title=Farey series|id=p/f038230}}
* {{MathWorld | urlname=Stern-BrocotTree | title=Stern-Brocot Tree}}
* {{OEIS el|1=A005728|2=Number of fractions in Farey series of order n}}
* {{OEIS el|1=A006842|2=Numerators of Farey series of order n}}
* {{OEIS el|1=A006843|2=Denominators of Farey series of order n}}
* {{cite web|last1=Bonahon|first1=Francis|authorlink=Francis Bonahon|title=Funny Fractions and Ford Circles|url=https://www.youtube.com/watch?v=0hlvhQZIOQw|publisher=[[Brady Haran]]|accessdate=9 June 2015|format=YouTube video}}

{{Authority control}}
[[Category:Fractions (mathematics)]]
[[Category:Number theory]]
[[Category:Sequences and series]]</text>
      <sha1>55gji6m666an0m94e4f2z67jzyg1s62</sha1>
    </revision>
  </page>
  <page>
    <title>Graeme Milton</title>
    <ns>0</ns>
    <id>53143101</id>
    <revision>
      <id>836135093</id>
      <parentid>789696145</parentid>
      <timestamp>2018-04-12T21:32:51Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>Birth/death year categories, [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3852">{{Infobox scientist
|name              = Graeme Milton
|image             = 
|caption           = 
|birth_date        = {{b-da|1956}}
|birth_place       = [[Sydney, Australia]]
|death_date        = 
|death_place       = 
|residence         = [[Salt Lake City, Utah]]
|citizenship       = 
|nationality       = 
|ethnicity         = 
|field             = [[applied mathematics]]&lt;br&gt;[[metamaterials]]&lt;br&gt;[[nonlinear dynamics]]
|work_institutions = [[Caltech]]&lt;br&gt;[[Courant Institute of Mathematical Sciences]]&lt;br&gt;[[MSRI]]&lt;br&gt;[[KAIST]]&lt;br&gt;[[University of Utah]]
|alma_mater        = [[University of Sydney]]&lt;br&gt;[[Cornell University]]
|doctoral_advisor  = [[Michael Fisher]]
|thesis_title = Some exotic models in statistical physics
|thesis_year = 1985
|thesis_url = http://adsabs.harvard.edu/abs/1985PhDT........75M
|doctoral_students = 
|known_for         = 
|influences        = 
|influenced        = 
|awards            = {{Plainlist|
* [[Alfred P. Sloan Fellowship]] &lt;small&gt;(1988)&lt;/small&gt;
* [[David and Lucile Packard Foundation#Conservation and science|Packard Fellowship]]&lt;small&gt;(1988)&lt;/small&gt;
* [[Society for Industrial and Applied Mathematics#SIAM Fellows|SIAM Fellow]] &lt;small&gt;(2009)&lt;/small&gt;
* 2012 Rolf Landauer International ETOPIM Association Medal
}}
}}
'''Graeme Milton''' is an American mathematician, currently Distinguished Professor at [[University of Utah]] and also previously the Eisenbud Professor at [[Mathematical Sciences Research Institute]] in 2010 and also a Full Professor at [[Courant Institute of Mathematical Sciences]].&lt;ref&gt;{{Cite web |url=https://faculty.utah.edu/u0028185-GRAEME_W_MILTON/teaching/index.hml |title=Graeme W. Milton |publisher=utah.edu |accessdate=February 9, 2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.math.utah.edu/~milton/ |title=Graeme Milton |publisher=utah.edu |accessdate=February 9, 2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://faculty.utah.edu/bytes/curriculumVitae.hml?id=u0028185 |title=CV |publisher=utah.edu |accessdate=February 9, 2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.worldcat.org/identities/lccn-n89610653/ |title=Milton, Graeme |publisher=worldcat.org |accessdate=February 9, 2017}}&lt;/ref&gt;

==Biography==
Graeme W. Milton received B.Sc. and M.Sc degrees in Physics from the [[University of Sydney]] in 1980 and 1982 respectively. He received a Ph.D degree in Physics from [[Cornell University]] in 1985, after which he joined the [[Caltech]] Physics Department as a Weingart Fellow from 1984 to 1986. He then joined the [[Courant Institute of Mathematical Sciences]] where he stayed until 1994 when he joined the faculty at the University of Utah as a full professor. He has received numerous honors and awards, including a [[Alfred P. Sloan Fellowship]] and a [[David and Lucile Packard Foundation#Conservation and science|Packard Fellowship]], both in 1988. He was an Invited Speaker for the 1998 [[International Congress of Mathematicians]]. He was awarded the Ralph E. Kleinman Prize in 2003 by the [[Society for Industrial and Applied Mathematics]] for “his many deep contributions to the modeling and analysis of composite materials.”&lt;ref&gt;{{cite web|title=Department of Mathematics Distinguished Lecturer Graeme Milton|url=https://ps.uci.edu/events/7565|website=UC Irvine School of Physical Sciences|accessdate=19 March 2017|language=en}}&lt;/ref&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Milton, Graeme}}
[[Category:Living people]]
[[Category:University of Utah faculty]]
[[Category:American mathematicians]]
[[Category:Cornell University alumni]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Applied mathematicians]]
[[Category:Sloan Research Fellows]]
[[Category:Courant Institute of Mathematical Sciences faculty]]
[[Category:University of Sydney alumni]]
[[Category:1956 births]]


{{US-mathematician-stub}}</text>
      <sha1>kqgj1f93gmvblcfopl81nudp06zvzux</sha1>
    </revision>
  </page>
  <page>
    <title>Henda Swart</title>
    <ns>0</ns>
    <id>45093024</id>
    <revision>
      <id>859169614</id>
      <parentid>839421086</parentid>
      <timestamp>2018-09-12T06:07:07Z</timestamp>
      <contributor>
        <ip>197.245.179.195</ip>
      </contributor>
      <comment>/* Career */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4357">{{Infobox academic
| honorific_prefix   = &lt;!-- see [[MOS:HONOURIFIC]] --&gt;
| name               = Henda Swart
| honorific_suffix   = 
| image              = Henda_Swart.jpg
| image_size         = 
| alt                = 
| caption            = 
| native_name        = 
| native_name_lang   = 
| birth_name         = Hendrika Cornelia Scott Henda
| birth_date         = 1939 &lt;!-- {{birth date and age|YYYY|MM|DD}}  --&gt;
| birth_place        = 
| death_date         = February 2016 &lt;!-- {{death date and age|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) --&gt;
| death_place        = 
| death_cause        = 
| region             = 
| nationality        = 
| citizenship        = 
| residence          = 
| other_names        = 
| occupation         = 
| period             = 
| known_for          = 
| title              = 
| boards             = &lt;!--board or similar positions extraneous to main occupation--&gt;
| spouse             = 
| children           = 
| awards             = Fellow Royal Society of South Africa
| website            = 
| education          = 
| alma_mater         = Stellenbosch University
| thesis_title       = Sesquilinear Curves in Desarguesian Planes 
| thesis_url         = 
| thesis_year        = 
| school_tradition   = 
| doctoral_advisor   =  Kurt-Rüdiger Kannenberg
| academic_advisors  = 
| influences         = &lt;!--must be referenced from a third party source--&gt;
| era                = 
| discipline         = Mathematics
| sub_discipline     = graph theory
| workplaces         = University of KwaZulu-Natal, &lt;br&gt; University of Cape Town
| doctoral_students  = &lt;!--only those with WP articles--&gt;
| notable_students   = &lt;!--only those with WP articles--&gt;
| main_interests     = 
| notable_works      = 
| notable_ideas      = 
| influenced         = &lt;!--must be referenced from a third party source--&gt;
| signature          = 
| signature_alt      = 
| signature_size     = 
| footnotes          = 
}}
'''Hendrika Cornelia Scott (Henda) Swart''' &lt;small&gt;[[Royal Society of South Africa|FRSSAf]]&lt;/small&gt; (born 1939, died February 2016 [age 77-78])&lt;ref&gt;{{Cite web |url=https://www.royalsocietysa.org.za/?page_id=759 |title=Fellows (FRSSAf) |date=December 2016 |website=Royal Society of South Africa |access-date=2017-11-29}}&lt;/ref&gt; was a South African mathematician, a professor emeritus of mathematics at the [[University of KwaZulu-Natal]] and a professor at the [[University of Cape Town]]&lt;ref name="rssa"&gt;[http://www.royalsocietysa.org.za/wp-content/uploads/2013/01/HendaSwart.pdf Fellow citation], [[Royal Society of South Africa]], 1996, retrieved 2015-01-17.&lt;/ref&gt;&lt;ref name="marching"&gt;{{citation|title=Women Marching Into the 21st Century: Wathint' Abafazi, Wathint' Imbokodo|author=Group Democracy and Governance, Human Sciences Research Council|publisher=HSRC Press|year=2000|isbn=9780796919663|contribution=Swart, Henda|pages=192–193|url=https://books.google.com/books?id=YgzGqNhLY1UC&amp;pg=PA192}}.&lt;/ref&gt;

== Career ==
Swart began teaching at the University of Natal in 1962.&lt;ref name="marching"/&gt; She was the first person to earn a doctorate in mathematics from [[Stellenbosch University]],&lt;ref name="marching"/&gt; in 1971, with a dissertation on the geometry of [[projective plane]]s supervised by Kurt-Rüdiger Kannenberg.&lt;ref&gt;{{mathgenealogy|id=72354}}&lt;/ref&gt; In 1977, her research interests shifted from geometry to [[graph theory]], which she continued to publish in for the rest of her career.&lt;ref name="marching"/&gt;

She was the editor-in-chief of the journal ''Utilitas Mathematica'',&lt;ref name="rssa"/&gt;&lt;ref name="marching"/&gt;&lt;ref&gt;[http://bkocay.cs.umanitoba.ca/utilitas/index.html ''Utilitas Mathematica'' home page], retrieved 2015-01-17.&lt;/ref&gt; and was vice president of the [[Institute of Combinatorics and its Applications]].&lt;ref name="rssa"/&gt;&lt;ref name="marching"/&gt; In 1996 she became a [[fellow]] of the [[Royal Society of South Africa]].&lt;ref name="rssa"/&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Swart, Hendrika Cornelia Scott}}
[[Category:1939 births]]
[[Category:2016 deaths]]
[[Category:20th-century South African mathematicians]]
[[Category:South African mathematicians]]
[[Category:Women mathematicians]]
[[Category:Graph theorists]]
[[Category:Stellenbosch University alumni]]
[[Category:University of KwaZulu-Natal]]
[[Category:21st-century South African mathematicians]]</text>
      <sha1>5454ibrzipj2lu9dih1m19ub15hcuqq</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert's sixteenth problem</title>
    <ns>0</ns>
    <id>381750</id>
    <revision>
      <id>866979398</id>
      <parentid>843951156</parentid>
      <timestamp>2018-11-02T20:48:43Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>convert HTML entities</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7461">'''Hilbert's 16th problem''' was posed by [[David Hilbert]] at the [[Paris]] conference of the [[International Congress of Mathematicians]] in 1900, as part of [[Hilbert's problems|his list of 23 problems in mathematics]].&lt;ref name="ParisConf1"&gt;
{{cite web
 |url=http://aleph0.clarku.edu/~djoyce/hilbert/problems.html
 |title=Mathematical Problems
 |author=David Hilbert (translated by Mary Winton Newson)
}}&lt;/ref&gt;

The original problem was posed as the ''Problem of the topology of algebraic curves and surfaces'' (''Problem der Topologie algebraischer Kurven und Flächen'').

Actually the problem consists of two similar problems in different branches of mathematics:
* An investigation of the relative positions of the branches of real [[algebraic curve]]s of degree ''n'' (and similarly for [[algebraic surface]]s).
* The determination of the upper bound for the number of [[limit cycle]]s in two-dimensional [[polynomial vector field]]s of degree ''n'' and an investigation of their relative positions.

The first problem is yet unsolved for ''n''&amp;nbsp;=&amp;nbsp;8. Therefore, this problem is what usually is meant when talking about Hilbert's sixteenth problem in [[real algebraic geometry]]. The second problem also remains unsolved: no upper bound for the number of limit cycles is known for any ''n''&amp;nbsp;&gt;&amp;nbsp;1, and this is what usually is meant by Hilbert's sixteenth problem in the field of [[dynamical system]]s.

== The first part of Hilbert's 16th problem ==
In 1876 [[Carl Gustav Axel Harnack|Harnack]] investigated [[algebraic curve]]s in the [[real projective plane]] and found that curves of degree ''n'' could have no more than

:&lt;math&gt; {n^2-3n+4 \over 2} &lt;/math&gt;

separate [[Locally connected space|connected components]]. Furthermore, he showed how to construct curves that attained that upper bound, and thus that it was the best possible bound. Curves with that number of components are called [[Harnack's curve theorem|M-curve]]s.

Hilbert had investigated the M-curves of degree 6, and found that the 11 components always were grouped in a certain way. His challenge to the mathematical community now was to completely investigate the possible configurations of the components of the M-curves.

Furthermore, he requested a generalization of Harnack's Theorem to [[algebraic surface]]s and a similar investigation of surfaces with the maximum number of components.

== The second part of Hilbert's 16th problem ==

Here we are going to consider [[polynomial vector field]]s in the [[real number|real]] plane, that is a system of differential equations of the form:

:&lt;math&gt; {dx \over dt}=P(x,y), \qquad {dy \over dt}=Q(x,y) &lt;/math&gt;

where both ''P'' and ''Q'' are real polynomials of degree ''n''.

These polynomial vector fields were studied by [[Henri Poincaré|Poincaré]], who had the idea of abandoning the search for finding exact solutions to the system, and instead attempted to study the qualitative features of the collection of all possible solutions.

Among many important discoveries, he found that the limit sets of such solutions need not be a [[stationary point]], but could rather be a periodic solution. Such solutions are called [[limit cycle]]s.

The second part of Hilbert's 16th problem is to decide an upper bound for the number of limit cycles in polynomial vector fields of degree ''n'' and, similar to the first part, investigate their relative positions.

===Results===
It was shown in 1991/1992 by [[Yulii Ilyashenko]] and [[Jean Écalle]] that every polynomial vector field in the plane has only finitely many limit cycles (a 1923 article by [[Henri Dulac]] claiming a proof of this statement had been shown to contain a gap in 1981). This statement is not obvious, since it is easy to construct smooth (C&lt;sup&gt;&amp;infin;&lt;/sup&gt;) vector fields in the plane with infinitely many concentric limit cycles.&lt;ref name=ilu&gt;{{cite journal|author=Yu. Ilyashenko|title=Centennial History of Hilbert's 16th problem|journal=Bulletin of the AMS|year=2002|volume=39|number=3|pages=301–354|pmid=|url=http://www.ams.org/journals/bull/2002-39-03/S0273-0979-02-00946-1/S0273-0979-02-00946-1.pdf|doi=10.1090/s0273-0979-02-00946-1}}&lt;/ref&gt;

The question whether there exists a finite upper bound ''H''(''n'') for the number of limit cycles of planar polynomial vector fields of degree ''n'' remains unsolved for any ''n''&amp;nbsp;&gt;&amp;nbsp;1. (''H''(1)&amp;nbsp;=&amp;nbsp;0 since linear vector fields do not have limit cycles.) [[Evgenii Landis]] and [[Ivan Petrovsky]] claimed a solution in the 1950s, but it was shown wrong in the early 1960s. Quadratic plane vector fields with four limit cycles are known.&lt;ref name=ilu/&gt;

== The original formulation of the problems ==

In his speech, Hilbert presented the problems as:&lt;ref name="ParisConf2"&gt;{{cite web
 |url=http://aleph0.clarku.edu/~djoyce/hilbert/problems.html#16
 |title=Mathematical Problems # 16
 |author=David Hilbert (translated by Maby Winton Newson)
}}&lt;/ref&gt;

{{cquote|The upper bound of closed and separate branches of an algebraic curve of degree ''n'' was decided by Harnack (Mathematische Annalen, 10); from this arises the further question as of the relative positions of the branches in the plane.
As of the curves of degree 6, I have – admittedly in a rather elaborate way – convinced myself that the 11 branches, that they can have according to Harnack, never all can be separate, rather there must exist one branch, which have another branch running in its interior and nine branches running in its exterior, or opposite. It seems to me that a thorough investigation of the relative positions of the upper bound for separate branches is of great interest, and similarly the corresponding investigation of the number, shape and position of the sheets of an algebraic surface in space – it is not yet even known, how many sheets a surface of degree 4 in three-dimensional space can maximally have. (cf. Rohn, Flächen vierter Ordnung, Preissschriften der Fürstlich Jablonowskischen Gesellschaft, Leipzig 1886)}}

Hilbert continues:&lt;ref name="ParisConf2"/&gt;

{{cquote|
Following this purely algebraic problem I would like to raise a question that, it seems to me, can be attacked by the same method of continuous coefficient changing, and whose answer is of similar importance to the topology of the families of curves defined by differential equations – that is the question of the upper bound and position of the Poincaré boundary cycles (cycles limites) for a differential equation of first order of the form: 

:&lt;math&gt; {dy \over dx} = {Y \over X} &lt;/math&gt;

where ''X'', ''Y'' are integer, rational functions of ''n''th degree in resp. ''x'', ''y'', or written homogeneously:

:&lt;math&gt;
X \left( y {dz \over dt} - z {dy \over dt} \right)
 + Y\left(z {dx \over dt} - x {dz \over dt} \right)
 + Z\left(x {dy \over dt} - y {dx \over dt} \right) 
 = 0
&lt;/math&gt;

where ''X'', ''Y'', ''Z'' means integral, rational, homogenic functions of ''n''th degree in ''x'', ''y'', ''z'' and the latter are to be considered function of the parameter&amp;nbsp;''t''.}}

== References ==
&lt;references/&gt;

== External Links ==
*[http://www.math.spbu.ru/user/nk/PDF/Limit_cycles_Focus_values.pdf 16th Hilbert problem: computation of Lyapunov quantities and limit cycles in two-dimensional dynamical systems]
{{Hilbert's problems}}

[[Category:Hilbert's problems|#16]]
[[Category:Unsolved problems in mathematics|Hilbert#16]]
[[Category:Real algebraic geometry]]
[[Category:Dynamical systems]]</text>
      <sha1>hgxryjl4to4bqos9j5v6mdwh54v2tky</sha1>
    </revision>
  </page>
  <page>
    <title>IDEA NXT</title>
    <ns>0</ns>
    <id>2067069</id>
    <revision>
      <id>788488509</id>
      <parentid>752220324</parentid>
      <timestamp>2017-07-01T18:21:30Z</timestamp>
      <contributor>
        <ip>174.118.63.84</ip>
      </contributor>
      <comment>fix comma splice</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3067">{{Infobox block cipher
| name          = IDEA NXT (FOX)
| image         = [[Image:Foxround.png|280px|center]]
| caption       = Round function of 
| designers     = Pascal Junod, [[Serge Vaudenay]]
| publish date  = 2003
| derived from  = [[International Data Encryption Algorithm|IDEA]]
| derived to    = 
| key size      = 0-256 bits
| block size    = 64 or 128 bits
| structure     = [[Lai-Massey scheme]]
| rounds        = 16
| cryptanalysis = [[Integral attack]] on 7 round NXT64 with time complexity of 2&lt;sup&gt;237.4&lt;/sup&gt; and on 5 round NXT128 with time complexity of 2&lt;sup&gt;205.6&lt;/sup&gt; by Wu Wenling, Zhang Wentao, and Feng Dengguo.&lt;ref&gt;{{cite journal |author1=Wu Wenling |author2=Zhang Wentao |author3=Feng Dengguo |date={{date|2005-08-25}} |title=Improved Integral Cryptanalysis of FOX Block Cipher |url=https://eprint.iacr.org/2005/292 }}&lt;/ref&gt;
}}

In [[cryptography]], the '''IDEA NXT''' algorithm (previously known as '''FOX''') is a [[block cipher]] designed by Pascal Junod and [[Serge Vaudenay]] of [[EPFL]] ([[Lausanne]], [[Switzerland]]). It was conceived between 2001 and 2003.  The project was originally named FOX and was published in 2003. In May 2005 it was announced by MediaCrypt under the name '''IDEA NXT'''. IDEA NXT is the successor to the [[International Data Encryption Algorithm]] (IDEA) and also uses the [[Lai-Massey scheme]].&lt;ref&gt;{{cite journal |title=IDEA NXT Technical Description |publisher=MediaCrypt |url=http://www.mediacrypt.com/_pdf/NXT_Technical_Description_0406.pdf |archiveurl=https://web.archive.org/web/20070928014200/http://www.mediacrypt.com/_pdf/NXT_Technical_Description_0406.pdf |archivedate={{date|2007-09-28}} }}&lt;/ref&gt; MediaCrypt AG holds patents on elements of IDEA{{cn|date=November 2016}} and IDEA NXT. The cipher is specified in two configurations: NXT64 (with block of 64 bits, key of 128 bits, 16 rounds) and NXT128 (with block of 128 bits, key of 256 bits, 16 rounds).

==References==
{{Reflist}}

==External links==
* [http://crypto.junod.info/fox_spec_v1.2.pdf FOX Specifications Version 1.2]
* [http://embeddedsw.net/Cipher_Reference_Home.html 256bit Ciphers - IDEANXT Reference implementation and derived code]
* [http://www.mediacrypt.com/ Mediacrypt homepage] &amp;mdash; IDEA licensor
* [http://crypto.junod.info/sac04a.pdf FOX: a new family of block ciphers]
* [http://eprint.iacr.org/2005/157.pdf FOX algorithm implementation - a hardware design approach]
* [http://www.ouah.org/ogay/idea_nxt/ BSD licensed C Software implementation of IDEA NXT]
* [http://appft1.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=%2220040247117%22.PGNR.&amp;OS=DN/20040247117&amp;RS=DN/20040247117 U.S. Patent Application Pub. No. 2004/0247117]
* [http://appft1.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=1&amp;f=G&amp;l=50&amp;s1=%2220050053233%22.PGNR.&amp;OS=DN/20050053233&amp;RS=DN/20050053233  U.S. Patent Application Pub. No. 2005/0053233]

{{Cryptography navbox | block}}

[[Category:Block ciphers]]


{{crypto-stub}}</text>
      <sha1>kwhwu4858g0a6f4qgzrhj1blpwsd0md</sha1>
    </revision>
  </page>
  <page>
    <title>Institut de Mathématiques de Toulouse</title>
    <ns>0</ns>
    <id>20908760</id>
    <revision>
      <id>783100711</id>
      <parentid>751705680</parentid>
      <timestamp>2017-05-31T04:02:21Z</timestamp>
      <contributor>
        <username>JackofOz</username>
        <id>33566</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1545">{{unreferenced|date=August 2012}}
The '''Institut de Mathématiques de Toulouse''' (IMT) is the Toulouse Mathematics Institute, a [[CNRS]] Research Laboratory which federates the [[mathematics]] community of the [[Toulouse]] area in [[France]]. The IMT is constituted by three main teams (in 2008):

* [[Partial differential equations]], [[numerical analysis]], [[Optimization (mathematics)|optimization]] (formerly MIP)
* [[Pure mathematics]] (formerly Laboratoire Émile Picard)
* [[Statistics]] &amp; [[Probability]] (formerly LSP)

The IMT is one of the largest French research centers in mathematics, and its scientific activities cover almost all domains of mathematics. It comprises approximately 180 permanent [[researcher]]s and 100 [[PhD student]]s (in 2008), belonging to various institutions of the [[University of Toulouse]].

The main buildings of the IMT are located on the [[Paul Sabatier University]] campus.

The IMT is responsible for the [[Fermat Prize]] and the [[Annales de la Faculté des Sciences de Toulouse]].

== External links ==
* [http://www.math.univ-toulouse.fr/ Institut de Mathématiques de Toulouse]
* [http://wikimapia.org/11065463/Toulouse-Mathematics-Institute Geographic location with Wikimapia]
* [http://hal.archives-ouvertes.fr/lab/IMT/ IMT scientific production] on [[Hyper Articles en Ligne|HAL]]

{{coord missing|France}}

{{DEFAULTSORT:Institut de Mathematiques de Toulouse}}
[[Category:Mathematical institutes]]
[[Category:French National Centre for Scientific Research]]

{{math-stub}}
{{France-stub}}</text>
      <sha1>htu0dnj80woyga88xie7lls6lzqjwoa</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Combinatorial Theory</title>
    <ns>0</ns>
    <id>15094960</id>
    <revision>
      <id>842870575</id>
      <parentid>841461307</parentid>
      <timestamp>2018-05-25T06:59:53Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Category:Combinatorics journals]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4073">{{Infobox journal
| title         = Journal of Combinatorial Theory
| cover         = 
| caption       = 
| former_name   = &lt;!-- or |former_names= --&gt;
| abbreviation  = J. Comb. Theory
| mathscinet    = J. Combin. Theory
| discipline    = Mathematics
| peer-reviewed = 
| language      = English
| editor        = &lt;!-- or |editors= --&gt;
| publisher     = [[Elsevier]]
| country       = 
| history       = 1966-present
| frequency     = Monthly
| openaccess    = 
| license       = 
| impact        = 
| impact-year   = 
 | ISSNlabel = Series A
 | ISSN = 0097-3165
 | eISSN = 
 | ISSN2label = Series B
 | ISSN2 = 0095-8956
 | eISSN2 = 
| CODEN         =
| JSTOR         = 
| LCCN          = 
| OCLC          =
| website       =
| link1         = http://www.journals.elsevier.com/journal-of-combinatorial-theory-series-a/
| link1-name    = Series A website
| link2         = http://www.journals.elsevier.com/journal-of-combinatorial-theory-series-b/
| link2-name    = Series B website
| boxwidth      = 
}}
The '''''Journal of Combinatorial Theory''''', '''Series A'''&lt;ref&gt;[http://www.elsevier.com/wps/find/journaldescription.cws_home/622862/description Journal of Combinatorial Theory, Series A - Elsevier&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; and '''Series B''',&lt;ref&gt;[http://www.elsevier.com/wps/find/journaldescription.cws_home/622863/description Journal of Combinatorial Theory, Series B - Elsevier&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; are [[mathematical journal]]s specializing in [[combinatorics]] and related areas. They are  published by [[Elsevier]]. ''Series A'' is concerned primarily with [[Mathematical structure|structure]]s, [[block design|design]]s, and applications of combinatorics. ''Series B'' is concerned primarily with [[graph theory|graph]] and [[matroid theory]]. The two series are two of the leading journals in the field and are widely known as ''JCTA'' and ''JCTB''.{{Citation needed|date=February 2010}}

The journal was founded in 1966 by [[Frank Harary]] and [[Gian-Carlo Rota]].&lt;ref name=sigact&gt;They are acknowledged on the journals' title pages and Web sites.  See [http://www.elsevier.com/wps/find/journaleditorialboard.cws_home/622862/editorialboard Editorial board of JCTA]; [http://www.elsevier.com/wps/find/journaleditorialboard.cws_home/622863/editorialboard Editorial board of JCTB].&lt;/ref&gt; Originally there was only one journal, which was split into two parts in 1971 as the field grew rapidly.

==Influential articles==
Influential articles that appeared in the journal include [[Gyula O. H. Katona|Katona]]'s elegant proof of the [[Erdős–Ko–Rado theorem]] and a series of papers spanning over 500 pages, appearing from 1983 to 2004, by [[Neil Robertson (mathematician)|Neil Robertson]] and [[Paul Seymour (mathematician)|Paul D. Seymour]] on the topic of [[minor (graph theory)|graph minors]], which together constitute the proof of the [[graph minor theorem]].

A selection of a few influential articles is listed below.

&lt;!--Don't change the title of the following paper!  mis-spelling "Erdös" is how it appeared.--&gt;
* {{cite journal
  | first = G.O.H.
  | last = Katona
  | authorlink = Gyula O. H. Katona
  | title = A simple proof of the Erdös-Chao Ko-Rado theorem
  | journal = Journal of Combinatorial Theory, Series B
  | volume = 13
  | year = 1972
  | issue = 2
  | pages = 183–184
  | doi = 10.1016/0095-8956(72)90054-8
}}
*{{cite journal
| first=Neil
| last=Robertson
|author2=P.D. Seymour
| title=Graph Minors. I. Excluding a forest
| journal=Journal of Combinatorial Theory, Series B
| volume=35
| issue=1
| year=1983
| pages=39–61
| doi=10.1016/0095-8956(83)90079-5
}}
*{{cite journal
| first=Neil
| last=Robertson
|author2=P.D. Seymour
| title=Graph Minors. XX. Wagner's conjecture
| journal=Journal of Combinatorial Theory, Series B
| volume=92
| issue=2
| year=2004
| pages=325–357
| doi=10.1016/j.jctb.2004.08.001
}}

==References==
{{reflist}}

[[Category:Combinatorics journals]]
[[Category:Publications established in 1966]]
[[Category:Elsevier academic journals]]
[[Category:English-language journals]]</text>
      <sha1>pkgoydgdf4rv0h9fc1end49c0tf8pva</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Computational and Applied Mathematics</title>
    <ns>0</ns>
    <id>58977389</id>
    <revision>
      <id>867488953</id>
      <parentid>867488916</parentid>
      <timestamp>2018-11-06T01:37:36Z</timestamp>
      <contributor>
        <username>IntoThinAir</username>
        <id>18336458</id>
      </contributor>
      <comment>added [[Category:Computational mathematics]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2743">{{Infobox journal
| title         = Journal of Computational and Applied Mathematics
| image         =  &lt;!-- or |cover= --&gt;
| image_size    = 
| alt           = 
| caption       = 
| former_name   = &lt;!-- or |former_names= --&gt;
| abbreviation  = J. Comput. Appl. Math
| bluebook      = &lt;!-- For law journals only --&gt;
| mathscinet    = &lt;!-- For the MathSciNet abbreviation IF different from ISO 4 abbreviation--&gt;
| nlm           = &lt;!-- For the NLM abbreviation IF different from ISO 4 abbreviation--&gt;
| discipline    = [[Computational mathematics]]
| peer-reviewed = 
| language      = English
| editor        = Yalchin Efendiev, Taketomo Mitsui, Michael Kwok-Po Ng, Fatih Tank, Luc Wuytack
| publisher     = [[Elsevier]]
| country       = 
| history       = 1975–present
| frequency     = Biweekly
| openaccess    = 
| license       = 
| impact        = 1.632
| impact-year   = 2017
| ISSNlabel     = 
| ISSN          = 0377-0427
| eISSN         = 1879-1778
| CODEN         = JCAMDI
| JSTOR         = 
| LCCN          = 2003233964
| OCLC          = 57049116
| website       = https://www.journals.elsevier.com/journal-of-computational-and-applied-mathematics
| link1         = https://www.sciencedirect.com/journal/journal-of-computational-and-applied-mathematics
| link1-name    = Online access
| link2         = https://www.sciencedirect.com/journal/journal-of-computational-and-applied-mathematics/issues
| link2-name    = Online archive
| boxwidth      = 
}}
The '''''Journal of Computational and Applied Mathematics''''' is a [[peer-review]]ed [[scientific journal]] covering [[computational mathematics|computational]] and [[applied mathematics]]. It was established in 1975 and is published biweekly by [[Elsevier]]. The [[editors-in-chief]] are Yalchin Efendiev ([[Texas A&amp;M University]]), Taketomo Mitsui ([[Nagoya University]]), Michael Kwok-Po Ng ([[Hong Kong Baptist University]]), Fatih Tank ([[Ankara University]]), and Luc Wuytack ([[University of Antwerp]]). According to the ''[[Journal Citation Reports]]'', the journal has a 2017 [[impact factor]] of 1.632.&lt;ref name=WoS&gt;{{cite book |year=2018 |chapter=Journal of Computational and Applied Mathematics |title=2017 [[Journal Citation Reports]] |publisher=[[Clarivate Analytics]] |edition=Science |series=[[Web of Science]]}}&lt;/ref&gt; 

==References==
{{Reflist}}
==External links==
*{{Official website|https://www.journals.elsevier.com/journal-of-computational-and-applied-mathematics}}
{{Mathematics-journal-stub}}

[[Category:Biweekly journals]]
[[Category:Applied mathematics]]
[[Category:Mathematics journals]]
[[Category:Elsevier academic journals]]
[[Category:Publications established in 1975]]
[[Category:English-language journals]]
[[Category:Computational mathematics]]</text>
      <sha1>5zq17r81yu3x6oc5sxuz2rdzg0jpmx3</sha1>
    </revision>
  </page>
  <page>
    <title>Katugampola fractional operators</title>
    <ns>0</ns>
    <id>48977562</id>
    <revision>
      <id>855536820</id>
      <parentid>846651248</parentid>
      <timestamp>2018-08-19T01:24:36Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted the phrasing 'it is interesting to note that' - see [[Wikipedia:Manual_of_Style/Words_to_watch#Editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18127">In [[mathematics]], '''Katugampola fractional operators''' are [[integral operators]] that generalize the ''Riemann–Liouville'' and the ''Hadamard'' fractional operators into a unique form.&lt;ref name="Integral"&gt;{{cite journal|doi=10.1016/j.amc.2011.03.062|pages=860–865|title=New approach to a generalized fractional integral|journal=Applied Mathematics and Computation|volume=218|issue=3|year=2011|last1=Katugampola|first1=Udita N.|arxiv=1010.0742}}&lt;/ref&gt;&lt;ref name="dist"&gt;Katugampola, Udita N. (2011).  [http://opensiuc.lib.siu.edu/dissertations/387/ On Generalized Fractional Integrals and Derivatives], Ph.D. Dissertation, Southern Illinois University, Carbondale, August, 2011.&lt;/ref&gt;&lt;ref name="derivative" /&gt;&lt;ref name="tran" /&gt; The '''Katugampola fractional integral''' generalizes both the [[Fractional calculus#Riemann Liouville fractional integral|Riemann–Liouville fractional integral]] and the [[Fractional calculus#Hadamard fractional integral|Hadamard fractional integral]] into a single form and It is also closely related to the [[Erdelyi–Kober operator|Erdelyi–Kober]] &lt;ref name="erdelyi"&gt;{{cite journal | last= Erdélyi | first= Arthur | authorlink= Arthur Erdélyi | title= On some functional transformations | journal= Rendiconti del Seminario Matematico dell'Università e del Politecnico di Torino | volume= 10 | pages= 217–234 | year= 1950–51 | mr=  0047818| ref= harv}}&lt;/ref&gt;&lt;ref name="Kober"&gt;{{cite journal | last= Kober | first= Hermann | title= On fractional integrals and derivatives | journal= The Quarterly Journal of Mathematics (Oxford Series) | volume= 11 | issue= 1 | pages= 193–211 | year= 1940 | doi= 10.1093/qmath/os-11.1.193 | ref= harv| bibcode= 1940QJMat..11..193K }}&lt;/ref&gt;&lt;ref name="Samko"&gt;''Fractional Integrals and Derivatives: Theory and Applications'', by Samko, S.; Kilbas, A.A.; and Marichev, O. Hardcover: 1006 pages. Publisher: Taylor &amp; Francis Books. {{ISBN|2-88124-864-0}}&lt;/ref&gt;&lt;ref name="KilSri"&gt;''Theory and Applications of Fractional Differential Equations'', by Kilbas, A. A.; Srivastava, H. M.; and Trujillo, J. J. Amsterdam, Netherlands, Elsevier, February 2006. {{ISBN|0-444-51832-0}}&lt;/ref&gt; operator that generalizes the Riemann–Liouville fractional integral. '''Katugampola fractional derivative'''&lt;ref name="dist" /&gt;&lt;ref name="derivative" /&gt;&lt;ref name="tran" /&gt; has been defined using the [[Fractional calculus#Further generalizations|Katugampola fractional integral]] &lt;ref name="derivative" /&gt; and as with any other [[fractional calculus|fractional differential operator]], it also extends the possibility of taking [[real number]] powers or [[complex number]] powers of the integral and [[derivative|differential operators]].

== Definitions ==
These operators have been defined on the following extended-Lebesgue space.

Let &lt;math&gt;\textit{X}^p_c(a,b), \; c\in \mathbb{R}, \, 1 \leq p \leq \infty &lt;/math&gt; be the space of those Lebesgue measurable functions &lt;math&gt; f &lt;/math&gt; on &lt;math&gt; [a, b] &lt;/math&gt; for which &lt;math&gt;\|f\|_{\textit{X}^p_c} &lt; \infty &lt;/math&gt;, where the norm is defined by &lt;ref name="Integral" /&gt;
&amp;nbsp;
::&lt;math&gt;
\begin{align}
\|f\|_{\textit{X}^p_c} =\Big(\int^b_a |t^c f(t)|^p \frac{dt}{t}\Big)^{1/p} &lt; \infty,
\end{align}
&lt;/math&gt;
&amp;nbsp;
for &lt;math&gt; 1 \leq p &lt; \infty,\, c \in \mathbb{R} &lt;/math&gt; and for the case &lt;math&gt; p=\infty &lt;/math&gt;
&amp;nbsp;
::&lt;math&gt;
\begin{align}
\|f\|_{\textit{X}^\infty_c} = \text{ess sup}_{a \leq t \leq b} [t^c|f(t)|],  \quad ( c \in \mathbb{R}).
\end{align}
&lt;/math&gt;

== Katugampola fractional integral ==
It is defined via the following integrals &lt;ref name="Integral" /&gt;&lt;ref name="dist" /&gt;&lt;ref name="langevin"&gt;{{cite journal|doi=10.1186/s13662-015-0712-3|title=On the nonlocal Katugampola fractional integral conditions for fractional Langevin equation|journal=Advances in Difference Equations|volume=2015|year=2015|last1=Thaiprayoon|first1=Chatthai|last2=Ntouyas|first2=Sotiris K|last3=Tariboon|first3=Jessada}}&lt;/ref&gt;&lt;ref name="appro "&gt;{{cite journal|arxiv=1512.03791|title=An approximation formula for the Katugampola integral|journal= J. Math. Anal. |volume=7|issue=1|pages= 23–30 |year=2016|last1=Almeida|first1=R.|last2=Bastos|first2=N. |url=https://dl.dropboxusercontent.com/u/1639385/JMA7-1/JMA7-1-4.pdf|bibcode=2015arXiv151203791A}}&lt;/ref&gt;&lt;ref name="googlesite"&gt;{{cite journal|first=Udita|last=Katugampola|title=Google Site|url=https://sites.google.com/site/uditanalin/research-1|access-date=11 November 2017}}&lt;/ref&gt;
{{NumBlk|:|&lt;math&gt; ({}^\rho \mathcal{I}^\alpha_{a+}f)(x) = \frac{\rho^{1- \alpha }}{\Gamma(\alpha)} \int^x_a \frac{\tau^{\rho-1} f(\tau) }{(x^\rho - \tau^\rho)^{1-\alpha}}\, d\tau, &lt;/math&gt;|{{EquationRef|1}}}}
&amp;nbsp;
for &lt;math&gt; x &gt; a &lt;/math&gt; and &lt;math&gt; \operatorname{Re}(\alpha) &gt; 0. &lt;/math&gt; This integral is called the ''left-sided'' fractional integral. Similarly, the ''right-sided'' fractional integral is defined by,
&amp;nbsp;
{{NumBlk|:|&lt;math&gt; ({}^\rho \mathcal{I}^\alpha_{b-}f)(x) = \frac{\rho^{1- \alpha }}{\Gamma({\alpha})} \int^b_x \frac{\tau^{\rho-1} f(\tau) }{(\tau^\rho - x^\rho)^{1-\alpha}}\, d\tau. &lt;/math&gt;|{{EquationRef|2}}}}
&amp;nbsp;
for &lt;math&gt;\textstyle x &lt; b&lt;/math&gt; and &lt;math&gt;\textstyle\operatorname{Re}(\alpha) &gt; 0&lt;/math&gt;.

These are the fractional generalizations of the &lt;math&gt;n&lt;/math&gt;-fold left- and right-integrals of the form

: &lt;math&gt; \int_a^x t_1^{\rho-1} \, dt_1 \int_a^{t_1} t_2^{\rho-1} \,dt_2 \cdots \int_a^{t_{n -1}} t_n^{\rho-1} f(t_n)\,dt_n&lt;/math&gt;

and

: &lt;math&gt; \int_x^b t_1^{\rho-1} \,dt_1 \int^b_{t_1} t_2^{\rho-1} \,dt_2 \cdots \int^b_{t_{n -1}} t_n^{\rho-1} f(t_n) \, dt_n&lt;/math&gt; for &lt;math&gt;\textstyle n \in \mathbb{N},&lt;/math&gt;

respectively. Even though the integral operators in question are close resemblance of the famous [[Erdélyi–Kober operator]], it is not possible to obtain the Hadamard fractional integrals as a direct consequence of the Erdélyi–Kober operators. Also, there is a corresponding fractional derivative, which generalizes the ''Riemann–Liouville'' and the ''Hadamard fractional derivatives''. As with the case of fractional integrals, the same is not true for the Erdélyi–Kober operator.

== Katugampola fractional derivative ==
As with the case of other fractional derivatives, it is defined via the Katugampola fractional integral.&lt;ref name="derivative"&gt;{{citation | last= Katugampola |first=Udita N.| title= ''New Approach to Generalized Fractional Derivatives'' | journal= Bull. Math. Anal. App.| volume= 6|issue =4 | pages= 1–15| year= 2014| mr= 3298307 |url=http://www.emis.de/journals/BMAA/repository/docs/BMAA6-4-1.pdf}}&lt;/ref&gt;&lt;ref name="langevin" /&gt;&lt;ref name="appro " /&gt;&lt;ref name="googlesite"/&gt;

Let &lt;math&gt;\alpha \in \mathbb{C},\ \operatorname{Re}(\alpha) \geq 0, n=[\operatorname{Re}(\alpha)]+1&lt;/math&gt; and &lt;math&gt;\rho &gt;0.&lt;/math&gt; The generalized fractional derivatives, corresponding to the generalized fractional integrals ({{EquationNote|1}}) and ({{EquationNote|2}}) are defined, respectively, for &lt;math&gt; 0 \leq a &lt; x &lt; b \leq \infty &lt;/math&gt;, by
[[File:Fig1-Katugampola.jpg|right|thumb|320px|The half-derivative of the function &lt;math&gt; f(x) = x^{0.5}&lt;/math&gt; for the Katugampola fractional derivative.]]
[[File:Fig2-Katugampola.jpg|right|thumb|320px|The half derivative of the function &lt;math&gt; f(x) = x^\nu&lt;/math&gt; for the Katugampola fractional derivative for &lt;math&gt;\alpha = 0.5&lt;/math&gt; and &lt;math&gt;\rho = 2&lt;/math&gt;.]]
:&lt;math&gt;\begin{align}
\big({}^\rho \mathcal{D}^\alpha_{a+}f\big)(x)&amp;= \bigg(x^{1-\rho} \,\frac{d}{dx}\bigg)^n\,\, \big({}^\rho \mathcal{I}^{n-\alpha}_{a+}f\big)(x)\\
 &amp;= \frac{\rho^{\alpha-n+1 }}{\Gamma({n-\alpha})} \, \bigg(x^{1-\rho} \,\frac{d}{dx}\bigg)^n \int^x_a \frac{\tau^{\rho-1} f(\tau) }{(x^\rho - \tau^\rho)^{\alpha-n+1}}\, d\tau,
\end{align}&lt;/math&gt;
and
:&lt;math&gt;\begin{align}
\big({}^\rho \mathcal{D}^\alpha_{b-}f\big)(x) &amp;= \bigg(-x^{1-\rho} \,\frac{d}{dx}\bigg)^n\,\, \big({}^\rho \mathcal{I}^{n-\alpha}_{b-}f\big)(x)\\
 &amp;= \frac{\rho^{\alpha-n+1 }}{\Gamma({n-\alpha})}\bigg(-x^{1-\rho}\frac{d}{dx}\bigg)^n \int^b_x\frac{\tau^{\rho-1} f(\tau) }{(\tau^\rho - x^\rho)^{\alpha-n+1}}\, d\tau,
\end{align}&lt;/math&gt;
respectively, if the integrals exist.

These operators generalize the Riemann–Liouville and Hadamard fractional derivatives into a single form, while the Erdelyi–Kober fractional is a generalization of the Riemann–Liouville fractional derivative.&lt;ref name="derivative" /&gt; When, &lt;math&gt; b=\infty &lt;/math&gt;, the fractional derivatives are referred to as [[weyl integral|Weyl-type]] derivatives.

=== Caputo–Katugampola fractional derivative ===
There is a Caputo-type modification of the Katugampola derivative that is now known as the Caputo–Katugampola fractional derivative.&lt;ref&gt;{{cite journal|doi=10.1007/s10957-016-0883-4|arxiv=1601.07376|title=Variational Problems Involving a Caputo-Type Fractional Derivative|journal=Journal of Optimization Theory and Applications|volume=174|issue=1|pages=276–294|year=2017|last=Almeida|first=Ricardo}}&lt;/ref&gt;&lt;ref name="maxi"&gt;{{cite journal|doi=10.22436/jnsa.010.04.75|title=Maximum principles for time-fractional Caputo-Katugampola diffusion equations|journal=Journal of Nonlinear Sciences and Applications|volume=10|pages=2257–2267|year=2017|last1=Cao|first1=Liang|last2=Kong|first2=Hua|last3=Zeng|first3=Sheng-Da}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|doi=10.1016/j.amc.2017.07.003|title=Fractional differential equations of Caputo–Katugampola type and numerical solutions|journal=Applied Mathematics and Computations|volume=315|pages=549–554|year=2017|last1=Zeng|first1=Sheng-Da|last2=Baleanu|first2=Dumitru|last3=Bai|first3=Yunru|first4=Guocheng|last4=Wu}}&lt;/ref&gt;
Let &lt;math&gt; f \in L^1[a, b], \alpha \in (0, 1]&lt;/math&gt; and &lt;math&gt; \rho &lt;/math&gt;. The C-K fractional derivative of order &lt;math&gt; \alpha &lt;/math&gt; of the function &lt;math&gt; f:[a,b] \rightarrow \mathbb{R},&lt;/math&gt; with respect to parameter &lt;math&gt; \rho &lt;/math&gt; can be expressed as

:&lt;math&gt; {}^C\mathcal{D}^{\alpha, \rho}_{a+}f(t)=\frac{\rho^\alpha t^{1-\alpha}}{\Gamma(1-\alpha)}\frac{d}{dt}\int^t_a\frac{s^{\rho-1}}{(t^\rho-s^\rho)^\alpha}\big[f(s)-f(a)\big]\,ds. &lt;/math&gt;

It satisfies the following result. Assume that &lt;math&gt; f \in C^1[a, b]  &lt;/math&gt;, then the C-K derivative has the following equivalent form &lt;ref name="maxi"/&gt;
::&lt;math&gt;
{}^C\mathcal{D}^{\alpha, \rho}_{a+}f(t)=\frac{\rho^\alpha }{\Gamma(1-\alpha)}\int^t_a \frac{f^\prime(s)}{(t^\rho-s^\rho)^\alpha}ds.
&lt;/math&gt;

=== Hilfer–Katugampola fractional derivative ===
Another recent generalization is the ''Hilfer-Katugampola'' fractional derivative.&lt;ref&gt;{{cite journal|arxiv=1705.07733|title=Hilfer-Katugampola fractional derivative|year=2017|last1=Oliveira|first1=D.S.|first2=E.|last2=Capelas de Oliveira|bibcode=2017arXiv170507733O}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|arxiv=1709.08838|title=Existence and Stability of Fractional Differential Equations Involving Generalized Katugampola Derivative|year=2017|last1=Bhairat|first1=Sandeep P.|first2=D.B.|last2=Dhaigude|bibcode=2017arXiv170908838B}}&lt;/ref&gt; Let order &lt;math&gt;0&lt;\alpha&lt;1&lt;/math&gt; and type &lt;math&gt;0\leq{\beta}\leq{1}&lt;/math&gt;. The fractional derivative (left-sided/right-sided),
with respect to &lt;math&gt;x&lt;/math&gt;, with &lt;math&gt;\rho&gt;0&lt;/math&gt;, is defined by

:&lt;math&gt;\begin{align}
({^{\rho}\mathcal{D}^{\alpha,\beta}_{a\pm}}\varphi)(x)&amp;=\left(\pm\,{^{\rho}\mathcal{J}_{a\pm}^{\beta(1-\alpha)}}\left(t^{\rho-1}\frac{d}{dt}\right){^{\rho}\mathcal{J}_{a\pm}^{(1-\beta)(1-\alpha)}}\varphi\right)(x)\\
&amp;=\left(\pm\,{^{\rho}\mathcal{J}_{a\pm}^{\beta(1-\alpha)}}\delta_{\rho}\,{^{\rho}\mathcal{J}_{a\pm}^{(1-\beta)(1-\alpha)}}\varphi\right)(x),
\end{align}
&lt;/math&gt;
where &lt;math&gt;\delta_{\rho}= t^{\rho-1}\frac{d}{dt}&lt;/math&gt;, for functions &lt;math&gt; \varphi &lt;/math&gt; in which the expression on the right hand side 
exists, where &lt;math&gt;\mathcal{J}&lt;/math&gt; is the generalized fractional integral 
given in ({{EquationNote|1}}).

== Mellin transform ==
As in the case of [[Laplace transform]]s, [[Mellin transform]]s will be used specially when solving [[differential equation]]s. The Mellin transforms of the ''left-sided'' and ''right-sided'' versions of Katugampola Integral operators are given by &lt;ref name="dist" /&gt;&lt;ref name="tran"&gt;{{cite journal|pages=566–580|arxiv=1112.6031|doi=10.1016/j.amc.2014.12.067|title=Mellin transforms of generalized fractional integrals and derivatives|journal=Applied Mathematics and Computation|volume=257|year=2015|last1=Katugampola|first1=Udita N.}}&lt;/ref&gt;

=== Theorem ===
Let &lt;math&gt;\alpha \in \mathcal{C},\  \operatorname{Re}(\alpha) &gt; 0,&lt;/math&gt; and &lt;math&gt;\rho &gt;0.&lt;/math&gt; Then,
::&lt;math&gt;
\begin{align}
 &amp; \mathcal{M}\bigg({}^\rho \mathcal{I}^\alpha_{a+}f\bigg)(s) = \frac{\Gamma\big(1-\frac{s}{\rho}-\alpha\big)}{\Gamma\big(1-\frac{s}{\rho}\big)\,\rho^\alpha}\, \mathcal{M}f(s + \alpha\rho), \quad \operatorname{Re}(s/\rho + \alpha) &lt; 1, \, x &gt; a,    \\
 &amp; \mathcal{M}\bigg({}^\rho \mathcal{I}^\alpha_{b-}f\bigg)(s) = \frac{\Gamma\big(\frac{s}{\rho}\big)}{\Gamma\big(\frac{s}{\rho} + \alpha\big)\,\rho^\alpha}\, \mathcal{M}f(s + \alpha\rho), \quad \operatorname{Re}(s/\rho) &gt; 0, \, x &lt; b, \\
\end{align}
&lt;/math&gt;

for &lt;math&gt;f \in \textit{X}^1_{s + \alpha\rho}(\mathbb{R^+})&lt;/math&gt;, if &lt;math&gt;\mathcal{M}f(s + \alpha\rho)&lt;/math&gt; exists for &lt;math&gt; s\in \mathbb{C}&lt;/math&gt;.

==Hermite-Hadamard type inequalities==
Katugampola operators satisfy the following Hermite-Hadamard type inequalities:&lt;ref name="H-H"&gt;{{cite journal|title =On Hermite-Hadamard Type Inequalities via Generalized Fractional Integrals| last1=M. Jleli |last2=D. O'Regan |last3=B. Samet | journal=Turkish Journal of Mathematics |year =2016|volume = 40|pages = 1221–1230|url=http://journals.tubitak.gov.tr/math/issues/mat-16-40-6/mat-40-6-4-1507-79.pdf}}&lt;/ref&gt;

=== Theorem ===
Let &lt;math&gt;\alpha &gt; 0 &lt;/math&gt; and &lt;math&gt;\rho &gt;0.&lt;/math&gt;. If &lt;math&gt; f &lt;/math&gt; is a convex function on &lt;math&gt; [a, b] &lt;/math&gt;, then 
::&lt;math&gt;
f\left(\frac{a+b}{2}\right) \leq \frac{\rho^\alpha\Gamma(\alpha +1)}{4(b^\alpha -a^\alpha)^\alpha}\left[{}^\rho \mathcal{I}^\alpha_{a+}F(b)+{}^\rho \mathcal{I}^\alpha_{b-}F(a)\right] \leq \frac{f(a)+f(b)}{2},
&lt;/math&gt;
where &lt;math&gt; F(x) = f(x) + f(a+b-x), \; x \in [a, b]. &lt;/math&gt;.

When &lt;math&gt; \rho \rightarrow 0^+ &lt;/math&gt;, in the above result, the following Hadamard type inequality holds:&lt;ref name="H-H" /&gt;

===Corollary===
Let &lt;math&gt;\alpha &gt; 0 &lt;/math&gt;. If &lt;math&gt; f &lt;/math&gt; is a convex function on &lt;math&gt; [a, b] &lt;/math&gt;, then 
::&lt;math&gt;
f\left(\frac{a+b}{2}\right) \leq \frac{\Gamma(\alpha +1)}{4\left(\ln \frac{b}{a}\right)^\alpha}\left[ \mathbf{I}^\alpha_{a+}F(b)+ \mathbf{I}^\alpha_{b-}F(a)\right] \leq \frac{f(a)+f(b)}{2},
&lt;/math&gt;
where &lt;math&gt; \mathbf{I}^\alpha_{a+}&lt;/math&gt; and &lt;math&gt; \mathbf{I}^\alpha_{b-}&lt;/math&gt; are left- and right-sided [[Fractional calculus#Hadamard fractional integral|Hadamard fractional integrals]].

== Recent Development ==
These operators have been mentioned in the following works:
# ''Fractional Calculus. An Introduction for Physicists'', by Richard Herrmann &lt;ref&gt;''Fractional Calculus. An Introduction for Physicists'', by Richard Herrmann. Hardcover. Publisher: World Scientific, Singapore; (February 2011) {{isbn|978-981-4340-24-3}}&lt;/ref&gt;
# ''Fractional Calculus of Variations in Terms of a Generalized Fractional Integral with Applications to Physics'', Tatiana Odzijewicz,  Agnieszka B. Malinowska and Delfim F. M. Torres, Abstract and Applied Analysis, Vol 2012 (2012), Article ID 871912, 24 pages'' &lt;ref&gt;{{cite journal|doi=10.1155/2012/871912|title=Fractional Calculus of Variations in Terms of a Generalized Fractional Integral with Applications to Physics|journal=Abstract and Applied Analysis|volume=2012|pages=1|year=2012|last1=Odzijewicz|first1=Tatiana|last2=Malinowska|first2=Agnieszka B.|last3=Torres|first3=Delfim F. M.}}&lt;/ref&gt;
# ''[https://books.google.com/books?id=0sD_ugAACAAJ Introduction to the Fractional Calculus of Variations]'', Agnieszka B Malinowska and Delfim F. M. Torres, Imperial College Press, 2015
# ''[https://books.google.com/books?id=QkOMBgAAQBAJ Advanced Methods in the Fractional Calculus of Variations]'', Malinowska, Agnieszka B., Odzijewicz, Tatiana, Torres, Delfim F.M., Springer, 2015
# ''Expansion formulas in terms of integer-order derivatives for the Hadamard fractional integral and derivative'', Shakoor Pooseh, Ricardo Almeida, and Delfim F. M. Torres, Numerical Functional Analysis and Optimization, Vol 33, Issue 3, 2012, pp 301–319.&lt;ref&gt;{{cite journal|doi= 10.1080/01630563.2011.647197|title= Expansion Formulas in Terms of Integer-Order Derivatives for the Hadamard Fractional Integral and Derivative|journal= Numerical Functional Analysis and Optimization|volume= 33|issue= 3|pages= 301|year= 2012|last1= Pooseh|first1= Shakoor|last2= Almeida|first2= Ricardo|last3= Torres|first3= Delfim F. M.|arxiv= 1112.0693}}&lt;/ref&gt;

== References ==
{{reflist}}

== Further reading ==
* ''An Introduction to the Fractional Calculus and Fractional Differential Equations'', by Kenneth S. Miller, Bertram Ross (Editor). Hardcover: 384 pages. Publisher: John Wiley &amp; Sons; 1 edition (May 19, 1993). {{ISBN|0-471-58884-9}}
* ''The Fractional Calculus; Theory and Applications of Differentiation and Integration to Arbitrary Order (Mathematics in Science and Engineering, V)'', by Keith B. Oldham, Jerome Spanier. Hardcover. Publisher: Academic Press; (November 1974). {{ISBN|0-12-525550-0}}
* ''Fractional Differential Equations. An Introduction to Fractional Derivatives, Fractional Differential Equations, Some Methods of Their Solution and Some of Their Applications.'', (Mathematics in Science and Engineering, vol. 198), by Igor Podlubny. Hardcover. Publisher: Academic Press; (October 1998) {{ISBN|0-12-558840-2}}
* ''Fractional Calculus. An Introduction for Physicists'', by Richard Herrmann. Hardcover. Publisher: World Scientific, Singapore; (February 2011) {{ISBN|978-981-4340-24-3}}
* [http://mechatronics.ece.usu.edu/foc/wcica2010tw/Recent%20History%20of%20Fractional%20Calculus-typeset.pdf Recent history of fractional calculus] by J.T. Machado, V. Kiryakova, F. Mainardi,

== Notes ==
The CRONE (R) Toolbox, a Matlab and Simulink Toolbox dedicated to fractional calculus, can be downloaded at http://cronetoolbox.ims-bordeaux.fr

[[Category:Fractional calculus| ]]
[[Category:Riemannian theory]]</text>
      <sha1>amq2n2sy6idpmx06swcfpp2sl0vywr1</sha1>
    </revision>
  </page>
  <page>
    <title>Key checksum value</title>
    <ns>0</ns>
    <id>43094970</id>
    <revision>
      <id>801721443</id>
      <parentid>731467721</parentid>
      <timestamp>2017-09-21T12:30:55Z</timestamp>
      <contributor>
        <username>Zyxw</username>
        <id>473593</id>
      </contributor>
      <minor/>
      <comment>add missing heading for references using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="470">{{Orphan|date=July 2016}}

In [[cryptography]], a '''Key [[Checksum]] Value''' (KCV) is checksum of the key value used to compare keys without knowing their actual values.

A KCV normally consists of a zero-block encrypted with the key, or a cryptographically secure hash over the key (also called a fingerprint)&lt;ref&gt;https://stackoverflow.com/questions/12228250/detecting-incorrect-key-using-aes-gcm-in-java&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Cryptography]]</text>
      <sha1>f50unq9xuh8a0yny1mhb1gqokewjzmq</sha1>
    </revision>
  </page>
  <page>
    <title>Klein–Gordon equation</title>
    <ns>0</ns>
    <id>209627</id>
    <revision>
      <id>871433869</id>
      <parentid>871335114</parentid>
      <timestamp>2018-12-01T01:18:53Z</timestamp>
      <contributor>
        <username>JRSpriggs</username>
        <id>1026643</id>
      </contributor>
      <comment>Undid revision 871335114 by [[Special:Contributions/2A02:C7D:3230:C000:ACBF:6B7F:6D78:FC11|2A02:C7D:3230:C000:ACBF:6B7F:6D78:FC11]] ([[User talk:2A02:C7D:3230:C000:ACBF:6B7F:6D78:FC11|talk]]) wrong</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22378">{{Quantum mechanics|cTopic=Equations}}
The '''Klein–Gordon equation''' ('''Klein–Fock–Gordon equation''' or sometimes '''Klein–Gordon–Fock equation''') is a [[relativistic wave equation]], related to the [[Schrödinger equation]]. It is second order in space and time and manifestly [[Lorentz covariance|Lorentz covariant]]. It is a quantized version of the relativistic [[energy–momentum relation]]. Its solutions include a [[quantum field theory|quantum scalar or pseudoscalar field]], a field whose quanta are spinless particles. Its theoretical relevance is similar to that of the [[Dirac equation]].&lt;ref&gt;{{harvnb|Gross|1993}}&lt;/ref&gt; Electromagnetic interactions can be incorporated, forming the topic of [[scalar electrodynamics]], but because common spinless particles like the [[pi meson]]s are unstable and also experience the strong interaction (with unknown interaction term in the [[Hamiltonian (quantum mechanics)|Hamiltonian]]&lt;ref&gt;{{harvnb|Greiner|Müller|1994}}&lt;/ref&gt;), the practical utility is limited.

The equation can be put into the form of a Schrödinger equation. In this form it is expressed as two coupled differential equations, each of first order in time.&lt;ref name=":0" /&gt; The solutions have two components, reflecting the charge degree of freedom in relativity.&lt;ref name=":0"&gt;{{harvnb|Greiner|2000|loc=Ch. 1}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Feshbach|Villars|1958}}&lt;/ref&gt; It admits a conserved quantity, but this is not positive definite. The wave function cannot therefore be interpreted as a [[probability amplitude]]. The conserved quantity is instead interpreted as [[electric charge]] and the norm squared of the wave function is interpreted as a [[charge density]]. The equation describes all spinless particles with positive, negative as well as zero charge. 

Any solution of the free Dirac equation is, component-wise, a solution of the free Klein–Gordon equation.

The equation does not form the basis of a consistent quantum relativistic ''one-particle'' theory. There is no known such theory for particles of any spin. For full reconciliation of quantum mechanics with special relativity [[quantum field theory]] is needed, in which the Klein&amp;ndash;Gordon equation reemerges as the equation obeyed by the components of all free quantum fields.&lt;ref group=nb&gt;[[Steven Weinberg]] makes a point about this. He leaves out the treatment of relativistic wave mechanics altogether in his otherwise complete introduction to modern applications of quantum mechanics, explaining "It seems to me that the way this is usually presented in books on quantum mechanics is profoundly misleading." (From the preface in ''Lectures on Quantum Mechanics'', referring to treatments of the Dirac equation in its original flavor.)&lt;br&gt;&lt;br&gt; Others, like [[Walter Greiner]] does in his series on theoretical physics, give a full account of the historical development and view of [[relativistic quantum mechanics]] before they get to the modern interpretation, with the rationale that it is highly desirable or even necessary from a pedagogical point of view to take the long route.&lt;/ref&gt; In quantum field theory, the solutions of the free (noninteracting) versions of the original equations still play a role. They are needed to build the Hilbert space ([[Fock space]]) and to express quantum field by using complete sets (spanning sets of Hilbert space) of wave functions.

==Statement==
The Klein–Gordon equation with mass parameter &lt;math&gt;m&lt;/math&gt; is
:&lt;math&gt; \frac {1}{c^2} \frac{\partial^2}{\partial t^2} \psi - \nabla^2 \psi + \frac {m^2 c^2}{\hbar^2} \psi = 0. &lt;/math&gt;
Solutions of the equation are complex-valued functions &lt;math&gt;\psi(t,\mathbf{x})&lt;/math&gt; of the time variable &lt;math&gt;t&lt;/math&gt; and space variables &lt;math&gt;\mathbf{x}&lt;/math&gt;; the [[Laplace operator|Laplacian]] &lt;math&gt;\nabla^2&lt;/math&gt; acts on the space variables only.

The equation is often abbreviated as
:&lt;math&gt;(\Box + \mu^2) \psi = 0,&lt;/math&gt;

where {{math|''&amp;mu; {{=}} {{sfrac|mc|ħ}}''}} and {{math|&amp;#x25A1;}} is the [[d'Alembert operator]], defined by
:&lt;math&gt; \Box = -\eta^{\mu\nu} \partial_\mu \, \partial_\nu = \frac{1}{c^2}\frac{\partial^2}{\partial t^2} - \nabla^2.&lt;/math&gt;

(We are using the (−, +, +, +) [[metric signature]].)

The Klein–Gordon equation is often written in [[natural units]]:
:&lt;math&gt; - \partial_t^2 \psi + \nabla^2 \psi = m^2 \psi&lt;/math&gt;

The form of the Klein–Gordon equation is derived by requiring that [[plane wave]] solutions of the equation:
:&lt;math&gt;\psi = e^{-i\omega t + i k\cdot x } = e^{i k_\mu x^\mu}&lt;/math&gt;

obey the energy momentum relation of special relativity:
:&lt;math&gt; -p_\mu p^\mu = E^2 - P^2 = \omega^2 - k^2 = - k_\mu k^\mu = m^2&lt;/math&gt;

Unlike the Schrödinger equation, the Klein–Gordon equation admits two values of {{math|''ω''}} for each {{math|''k''}}, one positive and one negative. Only by separating out the positive and negative frequency parts does one obtain an equation describing a relativistic wavefunction.  For the time-independent case, the Klein–Gordon equation becomes
:&lt;math&gt;\left[ \nabla^2 - \frac {m^2 c^2}{\hbar^2} \right] \psi(\mathbf{r}) = 0&lt;/math&gt;

which is formally the same as the homogeneous [[screened Poisson equation]].

==History==
The equation was named after the physicists [[Oskar Klein]] and [[Walter Gordon (physicist)|Walter Gordon]], who in 1926 proposed that it describes relativistic electrons. Other authors making similar claims in that same year were [[Vladimir Fock]], Johann Kudar, [[Théophile de Donder]] and [[Frans-H. van den Dungen]], and [[Louis de Broglie]]. Although it turned out that modeling the electron's spin required the [[Dirac equation]], the Klein–Gordon equation correctly describes the spinless relativisitic [[composite particle]]s, like the [[pion]]. On July 4, 2012, European Organization for Nuclear Research [[CERN]] announced the discovery of the [[Higgs boson]]. Since the [[Higgs boson]] is a spin-zero particle, it is the first observed ostensibly  [[elementary particle]] to be described by the Klein–Gordon equation. Further experimentation and analysis is required to discern whether the [[Higgs boson]] observed is that of the [[Standard Model]], or a more exotic, possibly composite, form. 

The Klein–Gordon equation was first considered as a quantum wave equation by [[Erwin Schrödinger|Schrödinger]] in his search for an equation describing de Broglie waves. The equation is found in his notebooks from late 1925, and he appears to have prepared a manuscript applying it to the hydrogen atom. Yet, because it fails to take into account the electron's spin, the equation predicts the hydrogen atom's fine structure incorrectly, including overestimating the overall magnitude of the splitting pattern by a factor of {{math|{{sfrac|4''n''|2''n'' &amp;minus; 1}}}} for the {{math|''n''}}-th energy level. The Dirac equation relativistic spectrum is, however, easily recovered if the orbital momentum quantum number {{math|''&amp;#x2113;''}} is replaced by total angular momentum quantum number {{math|''j''}}.&lt;ref name="Itzykson&amp;Zuber"&gt;See C Itzykson and J-B Zuber, Quantum Field Theory, McGraw-Hill Co., 1985, pp. 73–74. Eq. 2.87 is identical to eq. 2.86 except that it features {{math|''j''}} instead of {{math|&amp;#x2113;}}.&lt;/ref&gt; In January 1926, Schrödinger submitted for publication instead ''his'' equation, a non-relativistic approximation that predicts the Bohr energy levels of hydrogen without [[fine structure]].

In 1926, soon after the Schrödinger equation was introduced, [[Vladimir Fock]] wrote an article about its generalization for the case of [[magnetic field]]s, where [[force]]s were dependent on [[velocity]], and independently derived this equation. Both Klein and Fock used Kaluza and Klein's method. Fock also determined the [[gauge theory]] for the [[wave equation]]. The Klein–Gordon equation for a [[free particle]] has a simple [[plane wave]] solution.

==Derivation==
The non-relativistic equation for the energy of a free particle is
:&lt;math&gt;\frac{\mathbf{p}^2}{2 m} = E.&lt;/math&gt;

By quantizing this, we get the non-relativistic Schrödinger equation for a free particle,
:&lt;math&gt;\frac{\mathbf{\hat{p}}^2}{2m} \psi = \hat{E}\psi&lt;/math&gt;
where 
:&lt;math&gt;\mathbf{\hat{p}} =-i \hbar \mathbf{\nabla}&lt;/math&gt;

is the [[momentum operator]] ({{math|∇}} being the [[del|del operator]]), and 
:&lt;math&gt;\hat{E}=i \hbar \frac{\partial}{\partial t}&lt;/math&gt;

is the [[energy operator]].

The Schrödinger equation suffers from not being [[Poincaré group|relativistically invariant]], meaning that it is inconsistent with [[special relativity]].

It is natural to try to use the identity from special relativity describing the energy:

:&lt;math&gt;\sqrt{\mathbf{p}^2 c^2 + m^2 c^4} = E&lt;/math&gt;

Then, just inserting the quantum mechanical operators for momentum and energy yields the equation

:&lt;math&gt; \sqrt{(-i\hbar\mathbf{\nabla})^2 c^2 + m^2 c^4} \, \psi = i \hbar \frac{\partial}{\partial t}\psi. &lt;/math&gt;

The square root of a differential operator can be defined with the help of Fourier transformations, but due to the asymmetry of space and time derivatives, Dirac found it impossible to include external electromagnetic fields in a relativistically invariant way. So he looked for another equation that can be modified in order to describe the action of electromagnetic forces. In addition, this equation, as it stands, is [[Action at a distance|nonlocal]] (see also [http://www.ma.utexas.edu/mediawiki/index.php/Introduction_to_nonlocal_equations Introduction to nonlocal equations]).

Klein and Gordon instead began with the square of the above identity, i.e.
:&lt;math&gt;\mathbf{p}^2 c^2 + m^2 c^4 = E^2&lt;/math&gt;

which, when quantized, gives
:&lt;math&gt; \left ((-i\hbar\mathbf{\nabla})^2 c^2 + m^2 c^4 \right ) \psi = \left(i \hbar \frac{\partial}{\partial t} \right)^2 \psi &lt;/math&gt;

which simplifies to
:&lt;math&gt; - \hbar^2 c^2 \mathbf{\nabla}^2 \psi + m^2 c^4 \psi = - \hbar^2 \frac{\partial^2}{\partial t^2} \psi. &lt;/math&gt;

Rearranging terms yields
:&lt;math&gt; \frac {1}{c^2} \frac{\partial^2}{\partial t^2} \psi - \mathbf{\nabla}^2 \psi + \frac {m^2 c^2}{\hbar^2} \psi = 0. &lt;/math&gt;

Since all reference to imaginary numbers has been eliminated from this equation, it can be applied to fields that are [[real number|real]] valued as well as those that have [[complex number|complex]] values.

Rewriting the first two terms using the inverse of the [[Minkowski metric]] {{math|diag(−''c''&lt;sup&gt;2&lt;/sup&gt;, 1, 1, 1)}}, and writing the Einstein summation convention explicitly we get
:&lt;math&gt; - \eta^{\mu \nu} \partial_\mu \, \partial_\nu \psi \equiv \sum_{\mu=0}^{\mu = 3} \sum_{\nu=0}^{\nu=3}-\eta^{\mu\nu} \partial_\mu \, \partial_\nu \psi = \frac 1 {c^2} \partial_0^2 \psi - \sum_{\nu = 1}^{\nu =3} \partial_\nu \, \partial_\nu\psi =  \frac {1}{c^2} \frac{\partial^2}{\partial t^2} \psi - \mathbf{\nabla}^2 \psi.&lt;/math&gt; 

Thus the Klein–Gordon equation can be written in a covariant notation. This often means an abbreviation in the form of

:&lt;math&gt;(\Box + \mu^2) \psi = 0,&lt;/math&gt;

where

:&lt;math&gt; \mu = \frac{mc}{\hbar}&lt;/math&gt;

and

:&lt;math&gt; \Box = \frac{1}{c^2}\frac{\partial^2}{\partial t^2} - \nabla^2.&lt;/math&gt;

This operator is called the [[d'Alembert operator]].

Today this form is interpreted as the relativistic [[field equation]] for [[spin (physics)|spin]]-0 particles.&lt;ref name=":0"/&gt;  Furthermore, any ''component'' of any solution to the free [[Dirac equation]] (for a spin-one-half particle) is automatically a solution to the free Klein–Gordon equation. This generalizes to particles of any spin due extension to the [[Bargmann&amp;ndash;Wigner equations]]. Furthermore, in [[quantum field theory]], every component of every quantum field must satisfy the free Klein–Gordon equation,&lt;ref&gt;{{harvnb|Weinberg|2002|loc=Ch. 5}}&lt;/ref&gt; making the equation a generic expression of quantum fields.

=== Klein–Gordon equation in a potential ===

The Klein–Gordon equation can be generalized to describe a field in some potential {{math|''V''(''&amp;psi;'')}} as:&lt;ref&gt;David Tong, [http://www.damtp.cam.ac.uk/user/tong/qft.html Lectures on Quantum Field Theory], Lecture 1, Section 1.1.1&lt;/ref&gt;

:&lt;math&gt;\Box \psi + \frac{\partial V}{\partial \psi} = 0&lt;/math&gt;

==Conserved current==
The conserved current associated to the U(1) symmetry of a complex field &lt;math&gt;\varphi(x) \in \mathbb{C}&lt;/math&gt; satisfying the Klein–Gordon equation reads

: &lt;math&gt; \partial_\mu J^\mu(x) = 0, \qquad J^\mu(x) \equiv \varphi^*(x) \partial^\mu\varphi(x) - \varphi(x)\partial^\mu \varphi^*(x). &lt;/math&gt;

The form of the conserved current can be derived systematically by applying [[Noether's theorem]] to the U(1) symmetry. We will not do so here, but simply give a proof that this conserved current is correct.

&lt;div style="clear:both;width:65%;" class="NavFrame collapsed"&gt;
&lt;div class="NavHead" style="background-color:#CCCCFF; text-align:left; font-size:larger;"&gt;Proof using algebraic manipulations from the KG equation&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;"&gt;
From the Klein–Gordon equation for a complex field &lt;math&gt;\varphi(x)&lt;/math&gt; of mass &lt;math&gt;m&lt;/math&gt; written in covariant notation

:&lt;math&gt; (\square + m^2) \varphi(x) = 0, &lt;/math&gt;

and its complex conjugate

:&lt;math&gt; (\square + m^2) \varphi^*(x) = 0, &lt;/math&gt;

we have, multiplying by the left respectively by &lt;math&gt;\varphi^*(x)&lt;/math&gt; and &lt;math&gt;\varphi(x)&lt;/math&gt; (and omitting for brevity the explicit &lt;math&gt;x&lt;/math&gt; dependence),

:&lt;math&gt; \varphi^* (\square + m^2) \varphi = 0, &lt;/math&gt;
:&lt;math&gt; \varphi (\square + m^2) \varphi^* = 0 .&lt;/math&gt;

Subtracting the former from the latter we obtain

:&lt;math&gt; \varphi^* \square  \varphi - \varphi \square \varphi^* = 0 &lt;/math&gt;

from which we obtain the conservation law for the Klein–Gordon field:

:&lt;math&gt; \partial_\mu J^\mu(x) = 0, \qquad J^\mu(x) \equiv \varphi^*(x) \partial^\mu\varphi(x) - \varphi(x)\partial^\mu \varphi^*(x). &lt;/math&gt;

&lt;/div&gt;
&lt;/div&gt;

== Relativistic free particle solution ==

The Klein–Gordon equation for a free particle can be written as

:&lt;math&gt;\mathbf{\nabla}^2\psi-\frac{1}{c^2}\frac{\partial^2}{\partial t^2}\psi = \frac{m^2c^2}{\hbar^2}\psi&lt;/math&gt;

We look for plane wave solutions of the form

:&lt;math&gt;\psi(\mathbf{r}, t) = e^{i(\mathbf{k}\cdot\mathbf{r}-\omega t)}&lt;/math&gt;

for some constant [[angular frequency]] {{math|''&amp;omega;'' ∈ ℝ}} and [[wave number]] {{math|'''k''' ∈ ℝ&lt;sup&gt;3&lt;/sup&gt;}}. Substitution gives the ''dispersion relation'':

:&lt;math&gt;-|\mathbf{k}|^2+\frac{\omega^2}{c^2}=\frac{m^2c^2}{\hbar^2}.&lt;/math&gt;

Energy and momentum are seen to be proportional to {{math|''ω''}} and {{math|'''k'''}}:

:&lt;math&gt;\langle\mathbf{p}\rangle=\left\langle \psi \left|-i\hbar\mathbf{\nabla}\right|\psi\right\rangle = \hbar\mathbf{k},&lt;/math&gt;
:&lt;math&gt;\langle E\rangle=\left\langle \psi \left|i\hbar\frac{\partial}{\partial t} \right| \psi\right\rangle = \hbar\omega.&lt;/math&gt;

So the dispersion relation is just the classic relativistic equation:

:&lt;math&gt;\langle E \rangle^2=m^2c^4+\langle \mathbf{p} \rangle^2c^2.&lt;/math&gt;

For massless particles, we may set {{math|''m'' {{=}} 0}}, recovering the relationship between energy and momentum for massless particles:

:&lt;math&gt;\langle E \rangle=|\langle \mathbf{p} \rangle| c.&lt;/math&gt;

==Action==
The Klein–Gordon equation can also be derived via a [[calculus of variations|variational]] method by considering the action:

:&lt;math&gt;\mathcal{S} = \int \left( - \frac{\hbar^2}{m} \eta^{\mu \nu} \partial_\mu\bar\psi \,\partial_\nu \psi - m c^2 \bar\psi \psi \right) \mathrm{d}^4 x &lt;/math&gt;

where {{math|''&amp;psi;''}} is the Klein–Gordon field and {{math|''m''}} is its mass. The [[complex conjugate]] of {{math|''&amp;psi;''}} is written {{math|{{overbar|''&amp;psi;''}}}}. If the scalar field is taken to be real-valued, then {{math|{{overbar|''&amp;psi;''}} {{=}} ''&amp;psi;''}} and it is customary to introduce a factor of {{sfrac|1|2}} for both terms.

Applying the formula for the [[stress–energy tensor#Hilbert stress–energy tensor|Hilbert stress–energy tensor]] to the Lagrangian density (the quantity inside the integral), we can derive the [[stress–energy tensor]] of the scalar field. It is

: &lt;math&gt;T^{\mu\nu} = \frac{\hbar^2}{m} \left (\eta^{\mu \alpha} \eta^{\nu \beta} + \eta^{\mu \beta} \eta^{\nu \alpha} - \eta^{\mu\nu} \eta^{\alpha \beta} \right ) \partial_\alpha \bar\psi \, \partial_\beta \psi - \eta^{\mu\nu} m c^2 \bar\psi \psi .&lt;/math&gt;

By integration of the time–time component {{math|''T''&lt;sup&gt;00&lt;/sup&gt;}} over all space, one may show that both the positive and negative frequency plane wave solutions can be physically associated with particles with ''positive'' energy. This is not the case for the Dirac equation and its energy–momentum tensor.&lt;ref name=":0"/&gt;

==Electromagnetic interaction==
There is a simple way to make any field interact with electromagnetism in a [[gauge theory|gauge invariant]] way: replace the derivative operators with the gauge covariant derivative operators. This is because to maintain symmetry of the physical equations for the wavefunction &lt;math&gt;\varphi&lt;/math&gt; under a local ''U''(1) gauge transformation &lt;math&gt;\varphi \rightarrow \varphi' = \exp(i\theta)\varphi&lt;/math&gt; where &lt;math&gt;\theta(t,\textbf{x})&lt;/math&gt; is a locally variable phase angle, which transformation redirects the wavefunction in the complex phase space defined by &lt;math&gt;\exp(i\theta)=\cos\theta + i\sin \theta&lt;/math&gt;, it is required that ordinary derivatives &lt;math&gt;\partial_\mu&lt;/math&gt; be replaced by gauge-covariant derivatives &lt;math&gt;D_\mu=\partial_\mu-ieA_\mu&lt;/math&gt; while the gauge fields transform as &lt;math&gt;eA_\mu\rightarrow eA'_\mu=eA_\mu+\partial_\mu\theta&lt;/math&gt;.  The Klein–Gordon equation therefore becomes:

:&lt;math&gt;D_\mu D^\mu \varphi = -(\partial_t - ie A_0)^2 \varphi + (\partial_i - ie A_i)^2 \varphi = m^2 \varphi&lt;/math&gt;

in [[natural units]], where {{math|''A''}} is the vector potential. While it is possible to add many higher order terms, for example,

:&lt;math&gt;D_\mu D^\mu\varphi + A F^{\mu\nu} D_\mu \varphi D_\nu (D_\alpha D^\alpha \varphi) =0&lt;/math&gt;
these terms are not [[renormalization|renormalizable]] in 3&amp;nbsp;+&amp;nbsp;1 dimensions.

The field equation for a charged scalar field multiplies by {{math|''i''}},{{what|reason=Does this change it? Sounds equivalent.|date=October 2016}} which means the field must be complex. In order for a field to be charged, it must have two components that can rotate into each other, the real and imaginary parts.

The action for a charged scalar is the covariant version of the uncharged action:

:&lt;math&gt;S= \int_x \left (\partial_\mu \varphi^* + ie A_\mu \varphi^* \right ) \left (\partial_\nu \varphi - ie A_\nu\varphi \right )\eta^{\mu\nu} = \int_x |D \varphi|^2&lt;/math&gt;

==Gravitational interaction==
In [[general relativity]], we include the effect of gravity by replacing partial with covariant derivatives and the Klein–Gordon equation becomes (in the [[Metric signature|mostly pluses signature]])&lt;ref&gt;S.A. Fulling, Aspects of Quantum Field Theory in Curved Space–Time, Cambridge University Press, 1996, p. 117&lt;/ref&gt;

:&lt;math&gt;\begin{align}
0 &amp; = - g^{\mu \nu} \nabla_{\mu} \nabla_{\nu} \psi + \dfrac {m^2 c^2}{\hbar^2} \psi = - g^{\mu \nu} \nabla_{\mu} (\partial_\nu \psi) + \dfrac {m^2 c^2}{\hbar^2} \psi \\
&amp; = - g^{\mu \nu} \partial_\mu \partial_\nu \psi + g^{\mu \nu} \Gamma^{\sigma}{}_{\mu \nu} \partial_\sigma \psi + \dfrac {m^2 c^2}{\hbar^2} \psi
\end{align}&lt;/math&gt;

or equivalently

:&lt;math&gt;\frac{-1}{\sqrt{-g}} \partial_\mu \left ( g^{\mu \nu} \sqrt{-g} \partial_\nu \psi \right ) + \frac {m^2 c^2}{\hbar^2} \psi = 0&lt;/math&gt;

where ''g''{{math|''&lt;sup&gt;αβ&lt;/sup&gt;''}} is the inverse of the [[metric tensor]] that is the gravitational potential field, ''g'' is the [[determinant]] of the metric tensor, {{math|∇&lt;sub&gt;''μ''&lt;/sub&gt;}} is the [[covariant derivative]] and {{math|Γ''&lt;sup&gt;σ&lt;/sup&gt;&lt;sub&gt;μν&lt;/sub&gt;''}} is the [[Christoffel symbol]] that is the gravitational [[force field (physics)|force field]].

==See also==
*[[Relativistic wave equations]]
*[[Dirac equation]]
*[[Rarita–Schwinger equation]]
*[[Quantum field theory]]
*[[Scalar field theory]]
*[[Sine–Gordon equation]]

==Remarks==
{{reflist|group=nb}}

==Notes==
&lt;references/&gt;

==References==
*{{cite book  |ref=harv|  author= Davydov, A.S. |  title= Quantum Mechanics, 2nd Edition | publisher=[[Pergamon Press]] | year=1976 | isbn=0-08-020437-6}}
*{{cite journal|ref=harv|last1=Feshbach|first1=H.|last2=Villars|first2=F.|title=Elementary relativistic wave mechanics of spin 0 and spin 1/2 particles|journal=Rev. Mod. Phys.|volume=30|issue=1|year=1958|doi=10.1103/RevModPhys.30.24|bibcode = 1958RvMP...30...24F }}
*{{cite book|ref=harv| first = W.|last=Greiner|year = 2000 |edition=3rd|title = Relativistic Quantum Mechanics. Wave Equations|volume= |publisher= [[Springer Verlag]]| isbn = 3-5406-74578|url=https://books.google.com/books?id=2DAInxwvlHYC&amp;pg=PA1&amp;dq=Relativistic+quantum+mechanics|authorlink=Walter Greiner}}
*{{cite book|ref=harv|last1=Greiner|first=W.|last2=Müller|first2=B.|title=Quantum Mechanics: Symmetries|year=1994|edition=2nd|isbn=978-3540580805|publisher=Springer}}
*{{cite book|ref = harv|last=Gross|first=F.|title=Relativistic Quantum Mechanics and Field Theory|year=1993|edition=1st|publisher=[[Wiley-VCH]]|isbn=978-0471591139}}
*{{cite book|ref=harv|last=Sakurai|first=J. J.|title=Advanced Quantum Mechanics|publisher=[[Addison Wesley]]|year=1967|isbn=0-201-06710-2}}
*{{cite book|ref=harv|last=Weinberg|first=S.|year=2002|title=The Quantum Theory of Fields|volume=I|isbn=0-521-55001-7|authorlink=Steven Weinberg|publisher=[[Cambridge University Press]]}}

==External links==
* {{springer|title=Klein–Gordon equation|id=p/k055480}}
* {{MathWorld| urlname=Klein-GordonEquation | urltitle=Klein–Gordon equation}}
* [http://eqworld.ipmnet.ru/en/solutions/lpde/lpde203.pdf Linear Klein–Gordon Equation] at EqWorld: The World of Mathematical Equations.
* [http://eqworld.ipmnet.ru/en/solutions/npde/npde2107.pdf Nonlinear Klein–Gordon Equation] at EqWorld: The World of Mathematical Equations.
* [http://www.ma.utexas.edu/mediawiki/index.php/Introduction_to_nonlocal_equations Introduction to nonlocal equations].

{{Quantum mechanics topics|state=collapsed}}

{{DEFAULTSORT:Klein-Gordon equation}}
[[Category:Partial differential equations]]
[[Category:Special relativity]]
[[Category:Waves]]
[[Category:Quantum field theory]]
[[Category:Equations of physics]]
[[Category:Mathematical physics]]</text>
      <sha1>fupkkt66x9xwnwtdkz5beh2b273mbub</sha1>
    </revision>
  </page>
  <page>
    <title>Krylov–Bogoliubov averaging method</title>
    <ns>0</ns>
    <id>21291593</id>
    <revision>
      <id>842321976</id>
      <parentid>809437467</parentid>
      <timestamp>2018-05-21T18:10:49Z</timestamp>
      <contributor>
        <ip>216.165.117.64</ip>
      </contributor>
      <comment>/* Derivation */ Corrected size of paranthesis</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5048">The '''Krylov–Bogolyubov averaging method''' ('''Krylov–Bogolyubov method of averaging''') is a mathematical method for approximate analysis of oscillating processes in non-linear mechanics.&lt;ref&gt;[http://eom.springer.de/K/k055940.htm Krylov–Bogolyubov method of averaging] at Springer Encyclopaedia of Mathematics&lt;/ref&gt; The method is based on the averaging principle when the exact differential equation of the motion is replaced by its averaged version. The method is named after [[Nikolay Mitrofanovich Krylov|Nikolay Krylov]] and [[Nikolay Bogoliubov]].

Various averaging schemes for studying problems of celestial mechanics were used since works of [[Carl Friedrich Gauss|Gauss]], [[Pierre Fatou|Fatou]], [[Boris Delaunay|Delone]], [[George William Hill|Hill]]. The importance of the contribution of Krylov and Bogoliubov is that they developed a general averaging approach and proved that the solution of the averaged system approximates the exact dynamics.&lt;ref&gt;{{cite book |title=Methodes approchees de la mecanique non-lineaire dans leurs application a l'Aeetude de la perturbation des mouvements periodiques de divers phenomenes de resonance s'y rapportant|last=N. M. Krylov|authorlink=|author2=N. N. Bogolyubov |year=1935|publisher=Académie des Sciences d'Ukraine|location=Kiev|isbn=|pages=|language=French}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Introduction to non-linear mechanics|last= N. M. Krylov|authorlink= |author2=N. N. Bogolyubov |year=1937|language=Russian |publisher=Izd-vo AN SSSR|location=Kiev|isbn=|pages=}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Introduction to non-linear mechanics|last= N. M. Krylov|authorlink= |author2=N. N. Bogolyubov |year=1947 |publisher=Princeton Univ. Press|location=Princeton|isbn=9780691079851|pages=|language=English}}&lt;/ref&gt;

==Background==
Krylov–Bogoliubov averaging can be used to approximate oscillatory problems when a classical perturbation expansion fails. That is [[singular perturbation]] problems of oscillatory type, for example Einstein's correction to the [[Two-body problem in general relativity|perihelion precession of Mercury]].&lt;ref name="Smith"&gt;{{cite book | last = Smith | first = Donald | title = Singular-Perturbation Theory | publisher = Cambridge University Press | location = Cambridge | year = 1985 | isbn = 0-521-30042-8 }}&lt;/ref&gt;

==Derivation==
The method deals with differential equations in the form

:&lt;math&gt;
\frac{d^2u}{dt^2} + k^2 u = a + \varepsilon f\left(u,\frac{du}{dt}\right)
&lt;/math&gt;
for a smooth function ''f'' along with appropriate initial conditions. The parameter ''ε'' is assumed to satisfy

:&lt;math&gt;
0 &lt; \varepsilon \ll k.
&lt;/math&gt;
If ''ε''&amp;nbsp;=&amp;nbsp;0 then the equation becomes that of the simple harmonic oscillator with constant forcing, and the general solution is

:&lt;math&gt;
u(t) = \frac{a}{k^2} + A \sin (kt + B),
&lt;/math&gt;
where ''A'' and ''B'' are chosen to match the initial conditions. The solution to the perturbed equation (when ''ε''&amp;nbsp;≠&amp;nbsp;0) is assumed to take the same
form, but now ''A'' and ''B'' are allowed to vary with ''t'' (and&amp;nbsp;''ε'').  If it is also assumed that 
:&lt;math&gt;
\frac{du}{dt} = kA(t) \cos (kt + B(t)),
&lt;/math&gt;
then it can be shown that ''A'' and ''B'' satisfy the differential equation:&lt;ref name="Smith" /&gt;
:&lt;math&gt;
\frac{d}{dt} \begin{bmatrix} A \\ B \end{bmatrix}  = \frac{\varepsilon}{k} f\left( \frac{a}{k^2} + A \sin (\phi), kA \cos (\phi)\right) \begin{bmatrix} \cos(\phi)  \\ - \frac{1}{A} \sin(\phi)  \end{bmatrix},
&lt;/math&gt;
where &lt;math&gt; \phi = kt + B &lt;/math&gt;. Note that this equation is still exact — no approximation has been made as yet. The method of Krylov and Bogolyubov is to note that the functions A and B vary slowly
with time (in proportion to ε), so their dependence on &amp;phi; can be (approximately) removed by averaging on the right hand side of the previous equation:
:&lt;math&gt;
\frac{d}{dt} \begin{bmatrix} A_0 \\ B_0 \end{bmatrix}  = \frac{\varepsilon}{2\pi k} \int_0^{2 \pi} f\left( \frac{a}{k^2} + A \sin (\theta), kA \cos (\theta)\right) \begin{bmatrix} \cos(\theta)  \\ - \frac{1}{A_0} \sin(\theta)  \end{bmatrix} d\theta,
&lt;/math&gt;
where &lt;math&gt;A_0&lt;/math&gt; and &lt;math&gt;B_0&lt;/math&gt; are held fixed during the integration. After solving this (possibly) simpler set of differential equations, the Krylov–Bogolyubov averaged approximation for the original function is then given by
:&lt;math&gt;
u_0(t,\varepsilon) := \frac{a}{k^2} + A_0(t,\varepsilon) \sin (kt + B_0(t,\varepsilon)).
&lt;/math&gt;
This approximation has been shown to satisfy &lt;ref&gt;{{cite book | last = Bogoliubov | first = N. | title = Asymptotic Methods in the Theory of Non-Linear Oscillations | publisher = Gordon &amp; Breach | location = Paris | year = 1961 | isbn = 978-0-677-20050-7 }}&lt;/ref&gt;
:&lt;math&gt;
\left| u(t,\varepsilon) - u_0(t,\varepsilon) \right| \le C_1 \varepsilon,
&lt;/math&gt;
where t satisfies
:&lt;math&gt;
0 \le t \le \frac{C_2}{\varepsilon}
&lt;/math&gt;
for some constants &lt;math&gt;C_1&lt;/math&gt; and &lt;math&gt;C_2&lt;/math&gt;, independent of ε.

==References==
{{reflist}}

{{DEFAULTSORT:Krylov-Bogoliubov averaging method}}
[[Category:Dynamical systems]]</text>
      <sha1>9e6i2is6zhqoy946g5w1jbft9h3ph9p</sha1>
    </revision>
  </page>
  <page>
    <title>Limited principle of omniscience</title>
    <ns>0</ns>
    <id>37440876</id>
    <revision>
      <id>840421861</id>
      <parentid>839795603</parentid>
      <timestamp>2018-05-09T19:51:21Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <minor/>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2856">In [[constructive mathematics]], the '''limited principle of omniscience''' ('''LPO''') and the '''lesser limited principle of omniscience''' ('''LLPO''') are axioms that are nonconstructive but are weaker than the full [[law of the excluded middle]] {{harv|Bridges|Richman|1987}}. The LPO and LLPO axioms are used to gauge the amount of nonconstructivity required for an argument, as in [[constructive reverse mathematics]]. They are also related to [[weak counterexample]]s in the sense of Brouwer. 

== Definitions ==

The limited principle of omniscience states {{harv|Bridges|Richman|1987|p=3}}:
:'''LPO''': For any sequence ''a''&lt;sub&gt;0&lt;/sub&gt;, ''a''&lt;sub&gt;1&lt;/sub&gt;, ... such that each ''a''&lt;sub&gt;''i''&lt;/sub&gt; is either 0 or 1, the following holds: either ''a''&lt;sub&gt;''i''&lt;/sub&gt; = 0 for all ''i'', or there is a ''k'' with ''a''&lt;sub&gt;''k''&lt;/sub&gt; = 1.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/16832703|title=A course in constructive algebra|last=Mines|first=Ray|date=|publisher=Springer-Verlag|others=Richman, Fred and Ruitenburg, Wim|year=1988|isbn=0387966404|location=New York|pages=4-5|oclc=16832703}}&lt;/ref&gt;

The lesser limited principle of omniscience states:
:'''LLPO''': For any sequence ''a''&lt;sub&gt;0&lt;/sub&gt;, ''a''&lt;sub&gt;1&lt;/sub&gt;, ... such that each ''a''&lt;sub&gt;''i''&lt;/sub&gt; is either 0 or 1, and such that at most one ''a''&lt;sub&gt;''i''&lt;/sub&gt; is nonzero, the following holds: either ''a''&lt;sub&gt;2''i''&lt;/sub&gt; = 0 for all ''i'', or ''a''&lt;sub&gt;2''i''+1&lt;/sub&gt; = 0 for all ''i'', where ''a''&lt;sub&gt;2''i''&lt;/sub&gt; and  ''a''&lt;sub&gt;2''i''+1&lt;/sub&gt; are entries with even and odd index respectively. 

It can be proved constructively that the law of the excluded middle implies LPO, and LPO implies LLPO. However, none of these implications can be reversed in typical systems of constructive mathematics. 

The term "omniscience" comes from a thought experiment regarding how a mathematician might tell which of the two cases in the conclusion of LPO holds for a given sequence (''a''&lt;sub&gt;''i''&lt;/sub&gt;). Answering the question "is there a ''k'' with ''a''&lt;sub&gt;''k''&lt;/sub&gt; = 1?" negatively, assuming the answer is negative, seems to require surveying the entire sequence. Because this would require the examination of infinitely many terms, the axiom stating it is possible to make this determination was dubbed an "omniscience principle" by {{harvtxt|Bishop|1967}}.

== References ==
&lt;references /&gt;
* {{cite book |last=Bishop |first=Errett |authorlink=Errett Bishop |date=1967 |title=Foundations of Constructive Analysis |isbn=4-87187-714-0 |ref=harv}}
* {{cite book |last1=Bridges |first1=Douglas |last2=Richman |first2=Fred |date=1987 |title=Varieties of Constructive Mathematics |isbn=0-521-31802-5 |ref=harv}}

== External links ==

* {{SEP|mathematics-constructive|Constructive Mathematics|Douglas Bridges}}

[[Category:Constructivism (mathematics)]]

{{mathlogic-stub}}</text>
      <sha1>22c1xn9hf17u0ycn0shcrb5gq17lzls</sha1>
    </revision>
  </page>
  <page>
    <title>Magic hypercube</title>
    <ns>0</ns>
    <id>372467</id>
    <revision>
      <id>855565416</id>
      <parentid>843392201</parentid>
      <timestamp>2018-08-19T07:37:40Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[Wikipedia:Bots/Requests for approval/Texvc2LaTeXBot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18711">{{multiple issues|
{{technical|date=October 2010}}
{{Refimprove|date=October 2010}}
{{Cleanup|reason=the mathematical expressions [[Help:Displaying a formula|need to be rewritten in AMS-LaTeX markup]]|date=March 2014}}
{{one source|date=March 2014}}
{{essay-like|date=October 2017}}
}}
In [[mathematics]], a '''magic hypercube''' is the [[dimension|''k''-dimensional]] generalization of [[magic square]]s, [[magic cube]]s and '''magic tesseracts'''; that is, a number of [[integers]] arranged in an ''n'' × ''n'' × ''n'' × ... × ''n'' pattern such that the sum of the numbers on each pillar (along any axis) as well as the main [[space diagonal]]s is equal to a single number, the so-called [[magic constant]] of the [[hypercube]], denoted ''M''&lt;sub&gt;''k''&lt;/sub&gt;(''n''). It can be shown that if a magic hypercube consists of the numbers 1, 2, ..., ''n''&lt;sup&gt;''k''&lt;/sup&gt;, then it has magic number

:&lt;math&gt;M_k(n) = \frac{n(n^k+1)}{2}&lt;/math&gt;

For ''n'' = 4, this sequence is {{OEIS2C|id=A021003}}.

Four-, five-, six-, seven- and eight-dimensional magic hypercubes of order three have been constructed by [[J. R. Hendricks]].

Marian Trenkler proved the following theorem:
A ''p''-dimensional magic hypercube of order ''n'' exists if and only if
''p'' &gt; 1  and ''n'' is different from 2  or ''p'' = 1.  A construction of a magic hypercube follows from the proof.

The [[R (programming language)|R programming language]] includes a module, &lt;tt&gt; library(magic)&lt;/tt&gt;, that will create magic hypercubes of any dimension (with ''n'' a multiple of 4).

Change to more modern conventions here-after (basically k ==&gt; n and n ==&gt; m)

==Conventions==

It is customary to denote the [[dimension]] with the letter 'n' and the [[cardinality|order]] of a hypercube with the letter 'm'.

*'''(''n'') Dimension''' :  the number of directions within a hypercube.
*'''(''m'') Order''' : the number of numbers along a direction.

Further: In this article the analytical number range [0..m&lt;sup&gt;n&lt;/sup&gt;-1] is being used. For the regular number range [1..m&lt;sup&gt;n&lt;/sup&gt;] you can add 1 to each number. This has absolutely no effect on the properties of the hypercube.

==Perfect and Nasik magic hypercubes==
{{main article|Nasik magic hypercube}}
If, in addition, the numbers on every [[cross section (geometry)|cross section]] diagonal also sum up to the hypercube's magic number, the hypercube is called a [[perfect magic hypercube]]; otherwise, it is called a [[semiperfect magic hypercube]]. The number ''n'' is called the order of the magic hypercube.

The above definition of "perfect" assumes that one of the older definitions for perfect magic cubes is used. See [[Magic Cube Classes]].
The '''''Universal Classification System for Hypercubes''''' (John R. Hendricks) requires that for any dimension hypercube, ''all'' possible lines sum correctly for the hypercube to be considered ''perfect'' magic. Because of the confusion with the term ''perfect'', '''''nasik''''' is now the preferred term   for ''any'' magic hypercube where '''''all''''' possible lines sum to ''S''. Nasik was defined in this manner by C. Planck in 1905. A nasik magic hypercube has {{sfrac|2}}(3&lt;sup&gt;''n''&lt;/sup&gt; &amp;minus; 1) lines of ''m'' numbers passing through each of the ''m''&lt;sup&gt;''n''&lt;/sup&gt; cells.

==Notations==

in order to keep things in hand a special notation was developed:
*&lt;math&gt;\left[ {}_{k} i;\ k\in\{0,\cdots,n-1\};\ i\in\{0,\cdots,m-1\}\right]&lt;/math&gt;: positions within the hypercube
*&lt;math&gt;\left\langle {}_{k} i;\ k\in\{0,\cdots,n-1\};\ i\in\{0,\cdots,m-1\}\right\rangle&lt;/math&gt;: vector through the hypercube

Note: The notation for position can also be used for the value on that position. Then, where it is appropriate, dimension and order can be added to it, thus forming: &lt;sup&gt;n&lt;/sup&gt;[&lt;sub&gt;k&lt;/sub&gt;i]&lt;sub&gt;m&lt;/sub&gt;

As is indicated 'k' runs through the dimensions, while the coordinate 'i' runs through all possible values, when values 'i' are outside the range it is simply moved back into the range by adding or subtracting appropriate multiples of m, as the magic hypercube resides in n-dimensional modular space.

There can be multiple 'k' between bracket, these can't have the same value, though in undetermined order, which explains the equality of:

&lt;math&gt;\left[ {}_{1}i, {}_{k}j \right]=\left[ {}_{k}j, {}_{1}i \right]&lt;/math&gt;

Of course given 'k' also one value 'i' is referred to.&lt;br /&gt;
When a specific coordinate value is mentioned the other values can be taken as 0, which is especially the case when the amount of 'k's are limited using pe. #k=1 as in:

&lt;math&gt;
\left[ {}_{k}1;\ \#k=1 \right] = \left[ {}_{k}1\ \ {}_{j}0\ ; \ \#k=1;\ \#j=n-1 \right] 
&lt;/math&gt;
("axial"-neighbor of &lt;math&gt;\left[ {}_{k}0 \right]&lt;/math&gt; )

(#j=n-1 can be left unspecified) j now runs through all the values in [0..k-1,k+1..n-1].

Further: without restrictions specified 'k' as well as 'i' run through all possible values, in combinations same letters assume same values. Thus makes it possible to specify a particular line within the hypercube (see r-agonal in pathfinder section)

Note: as far as I know this notation is not in general use yet(?), Hypercubes are not generally analyzed in this particular manner.

Further: "'''perm(0..n-1)'''" specifies a [[permutation]] of the n numbers 0..n-1.

==Construction==

Besides more specific constructions two more general construction method are noticeable:

===KnightJump construction===
This construction generalizes the movement of the chessboard horses (vectors &lt;math&gt;\langle 1,2 \rangle, \langle 1,-2 \rangle, \langle -1,2 \rangle, \langle -1,-2 \rangle &lt;/math&gt;) to more general movements (vectors &lt;math&gt;\langle {}_k i \rangle&lt;/math&gt;). The method starts at the position P&lt;sub&gt;0&lt;/sub&gt; and further numbers are sequentially placed at positions &lt;math&gt;V_0&lt;/math&gt; further until (after m steps) a position is reached that is already occupied, a further vector is needed to find the next free position. Thus the method is specified by the n by n+1 matrix:
:&lt;math&gt;[P_0, V_0 \dots V_{n-1}]&lt;/math&gt;
This positions the number 'k' at position:
:&lt;math&gt;P_k = P_0 + \sum_{l=0}^{n-1}((k\backslash m^l)\ \%\ m) V_l;\quad k = 0 \dots m^n-1.&lt;/math&gt;
'''C. Planck''' gives in his 1905 article [http://www.magichypercubes.com/Encyclopedia/k/PathNasiks.zip "'''The theory of Path Nasiks'''"] conditions to create with this method "Path Nasik" (or modern {perfect}) hypercubes.

===Latin prescription construction===
(modular equations).
This method is also specified by an n by n+1 matrix. However this time it multiplies the n+1 vector  [x&lt;sub&gt;0&lt;/sub&gt;,..,x&lt;sub&gt;n-1&lt;/sub&gt;,1], After this multiplication the result is taken modulus m to achieve the n (Latin) hypercubes:
 LP&lt;sub&gt;k&lt;/sub&gt; = ( &lt;sub&gt;l=0&lt;/sub&gt;∑&lt;sup&gt;n-1&lt;/sup&gt; LP&lt;sub&gt;k,l&lt;/sub&gt; x&lt;sub&gt;l&lt;/sub&gt; + LP&lt;sub&gt;k,n&lt;/sub&gt; ) % m
of radix m numbers (also called "'''digits'''"). On these LP&lt;sub&gt;k&lt;/sub&gt;'s "'''digit changing'''" (?i.e. Basic manipulation) are generally applied before these LP&lt;sub&gt;k&lt;/sub&gt;'s are combined into the hypercube:
 &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;/sub&gt; = &lt;sub&gt;k=0&lt;/sub&gt;∑&lt;sup&gt;n-1&lt;/sup&gt; LP&lt;sub&gt;k&lt;/sub&gt; m&lt;sup&gt;k&lt;/sup&gt;

'''J.R.Hendricks''' often uses modular equation, conditions to make hypercubes of various quality can be found on [http://www.magichypercubes.com/Encyclopedia http://www.magichypercubes.com/Encyclopedia] at several places (especially p-section)

Both methods fill the hypercube with numbers, the knight-jump guarantees (given appropriate vectors) that every number is present. The Latin prescription only if the components are orthogonal (no two digits occupying the same position)

===Multiplication===
Amongst the various ways of compounding, the multiplication&lt;ref&gt;this is a n-dimensional version of (pe.): [http://mathforum.org/alejandre/magic.square/adler/product.html Alan Adler magic square multiplication]&lt;/ref&gt; can be considered as the most basic of these methods. The '''basic multiplication''' is given by:
 &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; * &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt; : &lt;sup&gt;n&lt;/sup&gt;[&lt;sub&gt;k&lt;/sub&gt;i]&lt;sub&gt;m&lt;sub&gt;1&lt;/sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt; = &lt;sup&gt;n&lt;/sup&gt;[ [&lt;nowiki&gt;[&lt;/nowiki&gt;&lt;sub&gt;k&lt;/sub&gt;i \ m&lt;sub&gt;2&lt;/sub&gt;]&lt;sub&gt;m&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;m&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;n&lt;/sup&gt;]&lt;sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt; + [&lt;sub&gt;k&lt;/sub&gt;i % m&lt;sub&gt;2&lt;/sub&gt;]&lt;sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;]&lt;sub&gt;m&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;&lt;sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;

Most compounding methods can be viewed as variations of the above, As most qualifiers are invariant under multiplication one can for example place any aspectial variant of &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt; in the above equation, besides that on the result one can apply a manipulation to improve quality. Thus one can specify pe the  J. R. Hendricks / M. Trenklar doubling. These things go beyond the scope of this article.

==Aspects==
A hypercube knows '''n! 2&lt;sup&gt;n&lt;/sup&gt;''' Aspectial variants, which are obtained by coordinate reflection ([&lt;sub&gt;k&lt;/sub&gt;i] --&amp;gt; [&lt;sub&gt;k&lt;/sub&gt;(-i)]) and coordinate permutations ([&lt;sub&gt;k&lt;/sub&gt;i] --&amp;gt; [&lt;sub&gt;perm[k]&lt;/sub&gt;i]) effectively giving the Aspectial variant:
 &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;/sub&gt;&lt;sup&gt;~R perm(0..n-1)&lt;/sup&gt;; R = &lt;sub&gt;k=0&lt;/sub&gt;∑&lt;sup&gt;n-1&lt;/sup&gt; ((reflect(k)) ? 2&lt;sup&gt;k&lt;/sup&gt; : 0) ; perm(0..n-1) a permutation of 0..n-1
Where reflect(k) true iff coordinate k is being reflected, only then 2&lt;sup&gt;k&lt;/sup&gt; is added to R.
As is easy to see, only n coordinates can be reflected explaining 2&lt;sup&gt;n&lt;/sup&gt;, the n! permutation of n coordinates explains the other factor to the total amount of "Aspectial variants"!

Aspectial variants are generally seen as being equal. Thus any hypercube can be represented shown in '''"normal position"''' by:
 [&lt;sub&gt;k&lt;/sub&gt;0] = min([&lt;sub&gt;k&lt;/sub&gt;θ ; θ ε {-1,0}]) (by reflection)
 [&lt;sub&gt;k&lt;/sub&gt;1 ; #k=1] &amp;lt; [&lt;sub&gt;k+1&lt;/sub&gt;1 ; #k=1] ; k = 0..n-2 (by coordinate permutation)
(explicitly stated here: [&lt;sub&gt;k&lt;/sub&gt;0] the minimum of all corner points. The axial neighbour sequentially based on axial number)

==Basic manipulations==

Besides more specific manipulations, the following are of more general nature

*'''#[perm(0..n-1)]''' : component permutation
*'''^[perm(0..n-1)]''' : coordinate permutation (n == 2: transpose)
*'''_2&lt;sup&gt;axis&lt;/sup&gt;[perm(0..m-1)]''' : monagonal permutation (axis ε [0..n-1])
*'''=[perm(0..m-1)]''' : digit change

Note: &lt;nowiki&gt;'#'&lt;/nowiki&gt;, '^', '_' and '=' are essential part of the notation and used as manipulation selectors.

===Component permutation===
Defined as the exchange of components, thus varying the factor m&lt;sup&gt;'''k'''&lt;/sup&gt; in m&lt;sup&gt;'''perm(k)'''&lt;/sup&gt;, because there are n component hypercubes the permutation is over these n  components

===Coordinate permutation===
The exchange of coordinate [&lt;sub&gt;'''k'''&lt;/sub&gt;i] into [&lt;sub&gt;'''perm(k)'''&lt;/sub&gt;i], because of n coordinates a permutation over these n directions is required.&lt;br /&gt;
The term '''transpose''' (usually denoted by &lt;sup&gt;t&lt;/sup&gt;) is used with two dimensional matrices, in general though perhaps "coordinate permutation" might be preferable.

===Monagonal permutation===
Defined as the change of [&lt;sub&gt;k&lt;/sub&gt;'''i'''] into [&lt;sub&gt;k&lt;/sub&gt;'''perm(i)'''] alongside the given "axial"-direction. Equal permutation along various axes can be combined by adding the factors 2&lt;sup&gt;axis&lt;/sup&gt;. Thus defining all kinds of r-agonal permutations for any r. Easy to see that all possibilities are given by the corresponding permutation of m numbers.

Noted be that '''reflection''' is the special case:
 ~R = _R[n-1,..,0]
Further when all the axes undergo the same ;permutation (R = 2&lt;sup&gt;n&lt;/sup&gt;-1) an '''n-agonal permutation''' is achieved, In this special case the 'R' is usually omitted so:
 _[perm(0..n-1)] = _(2&lt;sup&gt;n&lt;/sup&gt;-1)[perm(0..n-1)]

===Digitchanging===
Usually being applied at component level and can be seen as given by '''[&lt;sub&gt;k&lt;/sub&gt;i]''' in '''perm([&lt;sub&gt;k&lt;/sub&gt;i]''') since a component is filled with radix m digits, a permutation over m numbers is an appropriate manner to denote these.

==Pathfinders==
J. R. Hendricks called the directions within a hypercubes "'''pathfinders'''", these directions are simplest denoted in a ternary number system as:
 Pf&lt;sub&gt;p&lt;/sub&gt; where: p = &lt;sub&gt;k=0&lt;/sub&gt;∑&lt;sup&gt;n-1&lt;/sup&gt; (&lt;sub&gt;k&lt;/sub&gt;i + 1) 3&lt;sup&gt;k&lt;/sup&gt; &amp;lt;==&amp;gt; &amp;lt;&lt;sub&gt;k&lt;/sub&gt;i&amp;gt; ; i ε {-1,0,1}

This gives 3&lt;sup&gt;n&lt;/sup&gt; directions. since every direction is traversed both ways one can limit to the upper half [(3&lt;sup&gt;n&lt;/sup&gt;-1)/2,..,3&lt;sup&gt;n&lt;/sup&gt;-1)] of the full range.

With these pathfinders any line to be summed over (or r-agonal) can be specified:
 [ &lt;sub&gt;j&lt;/sub&gt;0 &lt;sub&gt;k&lt;/sub&gt;p &lt;sub&gt;l&lt;/sub&gt;q ; #j=1 #k=r-1 ; k &gt; j ] &amp;lt; &lt;sub&gt;j&lt;/sub&gt;1 &lt;sub&gt;k&lt;/sub&gt;θ &lt;sub&gt;l&lt;/sub&gt;0 ; θ ε {-1,1} &amp;gt;  ; p,q ε [0,..,m-1]

which specifies all (broken) r-agonals, p and q ranges could be omitted from this description. The main (unbroken) r-agonals are thus given by the slight modification of the above:
 [ &lt;sub&gt;j&lt;/sub&gt;0 &lt;sub&gt;k&lt;/sub&gt;0 &lt;sub&gt;l&lt;/sub&gt;-1 &lt;sub&gt;s&lt;/sub&gt;p ; #j=1 #k+#l=r-1 ; k,l &gt; j ] &amp;lt; &lt;sub&gt;j&lt;/sub&gt;1 &lt;sub&gt;k&lt;/sub&gt;1 &lt;sub&gt;l&lt;/sub&gt;-1 &lt;sub&gt;s&lt;/sub&gt;0 &amp;gt;

==Qualifications==

A hypercube &lt;sup&gt;n&lt;/sup&gt;H&lt;sub&gt;m&lt;/sub&gt; with numbers in the analytical numberrange [0..m&lt;sup&gt;n&lt;/sup&gt;-1] has the magic sum:
 &lt;sup&gt;n&lt;/sup&gt;S&lt;sub&gt;m&lt;/sub&gt; = m (m&lt;sup&gt;n&lt;/sup&gt; - 1) / 2.

Besides more specific qualifications the following are the most important, "summing" of course stands for "summing correctly to the magic sum"

*{'''r-agonal'''} : all main (unbroken) r-agonals are summing.
*{'''pan r-agonal'''} : all (unbroken and broken) r-agonals are summing.
*{'''magic'''} : {1-agonal n-agonal}
*{'''perfect'''} : {pan r-agonal; r = 1..n}

Note: This series doesn't start with 0 since a nill-agonal doesn't exist, the numbers correspond with the usual name-calling: 1-agonal = monagonal, 2-agonal = diagonal, 3-agonal = triagonal etc.. Aside from this the number correspond to the amount of "-1" and "1" in the corresponding pathfinder.

In case the hypercube also sum when all the numbers are raised to the power p one gets p-multimagic hypercubes. The above qualifiers are simply prepended onto the p-multimagic qualifier. This defines qualifications as {r-agonal 2-magic}. Here also "2-" is usually replaced by "bi",  "3-" by "tri" etc. ("1-magic" would be "monomagic" but "mono" is usually omitted). The sum for p-Multimagic hypercubes can be found by using [[Faulhaber's formula]] and divide it by m&lt;sup&gt;n-1&lt;/sup&gt;.

Also "magic" (i.e. {1-agonal n-agonal}) is usually assumed, the [[perfect magic cube|Trump/Boyer {diagonal} cube]] is technically seen {1-agonal 2-agonal 3-agonal}.

[[Nasik magic hypercube]] gives arguments for using {'''nasik'''} as synonymous to {'''perfect'''}. The strange generalization of square 'perfect' to using it synonymous to {diagonal} in cubes is however also resolve by putting curly brackets around qualifiers, so {'''perfect'''} means {pan r-agonal; r = 1..n} (as mentioned above).

some minor qualifications are:
*{'''&lt;sup&gt;n&lt;/sup&gt;compact'''} : {all order 2 subhyper cubes sum to 2&lt;sup&gt;n&lt;/sup&gt; &lt;sup&gt;n&lt;/sup&gt;S&lt;sub&gt;m&lt;/sub&gt; / m}
*{'''&lt;sup&gt;n&lt;/sup&gt;complete'''} : {all pairs halve an n-agonal apart sum equal (to (m&lt;sup&gt;n&lt;/sup&gt; - 1)}

{'''&lt;sup&gt;n&lt;/sup&gt;compact'''} might be put in notation as : '''&lt;sub&gt;(k)&lt;/sub&gt;∑ [&lt;sub&gt;j&lt;/sub&gt;i + &lt;sub&gt;k&lt;/sub&gt;1] = 2&lt;sup&gt;n&lt;/sup&gt; &lt;sup&gt;n&lt;/sup&gt;S&lt;sub&gt;m&lt;/sub&gt; / m'''.&lt;br /&gt;
{'''&lt;sup&gt;n&lt;/sup&gt;complete'''} can simply be written as: '''[&lt;sub&gt;j&lt;/sub&gt;i] + [&lt;sub&gt;j&lt;/sub&gt;i + &lt;sub&gt;k&lt;/sub&gt;(m/2) ; #k=n ] = m&lt;sup&gt;n&lt;/sup&gt; - 1'''.&lt;br /&gt;
Where:&lt;br /&gt;
&lt;sub&gt;(k)&lt;/sub&gt;∑ is symbolic for summing all possible k's, there are 2&lt;sup&gt;n&lt;/sup&gt; possibilities for &lt;sub&gt;k&lt;/sub&gt;1.&lt;br /&gt;
[&lt;sub&gt;j&lt;/sub&gt;i + &lt;sub&gt;k&lt;/sub&gt;1] expresses [&lt;sub&gt;j&lt;/sub&gt;i] and all its r-agonal neighbors.&lt;br /&gt;
for {complete} the complement of [&lt;sub&gt;j&lt;/sub&gt;i] is at position [&lt;sub&gt;j&lt;/sub&gt;i + &lt;sub&gt;k&lt;/sub&gt;(m/2) ; #k=n ].

for squares: {'''&lt;sup&gt;2&lt;/sup&gt;compact &lt;sup&gt;2&lt;/sup&gt;complete'''} is the "modern/alternative qualification" of what Dame [[Kathleen Ollerenshaw]] called [[most-perfect magic square]], {&lt;sup&gt;n&lt;/sup&gt;compact &lt;sup&gt;n&lt;/sup&gt;complete} is the qualifier for the feature in more than 2 dimensions&lt;br /&gt;
Caution: some people seems to equate {compact} with {&lt;sup&gt;2&lt;/sup&gt;compact} instead of {&lt;sup&gt;n&lt;/sup&gt;compact}. Since this introductory article is not the place to discuss these kind of issues I put in the dimensional pre-superscript &lt;sup&gt;n&lt;/sup&gt; to both these qualifiers (which are defined as shown) &lt;br /&gt;
consequences of {&lt;sup&gt;n&lt;/sup&gt;compact} is that several figures also sum since they can be formed by adding/subtracting order 2 sub-hyper cubes. Issues like these go beyond this articles scope.

==Special hypercubes==
The following hypercubes serve special purposes;

===The "normal hypercube"===
 &lt;sup&gt;n&lt;/sup&gt;N&lt;sub&gt;m&lt;/sub&gt; : [&lt;sub&gt;k&lt;/sub&gt;i] = &lt;sub&gt;k=0&lt;/sub&gt;∑&lt;sup&gt;n-1&lt;/sup&gt; &lt;sub&gt;k&lt;/sub&gt;i m&lt;sup&gt;k&lt;/sup&gt;
This hypercube can be seen as the source of all numbers. A procedure called [http://www.magichypercubes.com/Encyclopedia/d/DynamicNumbering.html "Dynamic numbering"] makes use of the  [[isomorphism]] of every hypercube with this normal, changing the source, changes the hypercube. Usually these sources are limited to direct products of normal hypercubes or normal [[Magic hyperbeam|hyperbeams]] (defined as having possibly other orders along the various directions).

===The "constant 1"===
 &lt;sup&gt;n&lt;/sup&gt;1&lt;sub&gt;m&lt;/sub&gt; : [&lt;sub&gt;k&lt;/sub&gt;i] = 1
The hypercube that is usually added to change the here used "analytic" number range into the "regular" number range. Other constant hypercubes are of course multiples of this one.

==File format==
Based on [[XML]], the file format [http://www.magichypercubes.com/Encyclopedia/x/XmlHypercubes.html Xml-Hypercubes] is developed to describe various hypercubes to ensure human readability as well as programmatical usability. Besides full listings the format offers the ability to invoke mentioned constructions (amongst others)

== See also ==
*[[John R. Hendricks]]
*[[Magic hyperbeam]]
*[[Space diagonal]]

== References ==
{{reflist}}

==Further reading==

* J.R.Hendricks: Magic Squares to Tesseract by Computer, Self-published, 1998, 0-9684700-0-9
* Planck, C., M.A.,M.R.C.S., The Theory of Paths Nasik, 1905, printed for private circulation. Introductory letter to the paper

== External links ==
* [http://www.magichypercubes.com/Encyclopedia/index.html The Magic Encyclopedia] Articles by Aale de Winkel
* [http://math.ku.sk/~trenkler/Cube-Ref.html Magic Cubes and Hypercubes - References] Collected by Marian Trenkler
** [http://math.ku.sk/~trenkler/05-MagicCube.pdf An algorithm for making magic cubes] by Marian Trenkler
* [http://www.multimagie.com/ multimagie.com] Articles by Christian Boyer
* [http://www.magichypercube.com magichypercube.com] A magic cube generator
{{Magic polygons}}

{{DEFAULTSORT:Magic Hypercube}}
[[Category:Recreational mathematics]]
[[Category:Magic squares]]</text>
      <sha1>3wrott3u4v26fw7hbi5dcgjx06pls9y</sha1>
    </revision>
  </page>
  <page>
    <title>Mara Neusel</title>
    <ns>0</ns>
    <id>44752364</id>
    <revision>
      <id>859425800</id>
      <parentid>842419874</parentid>
      <timestamp>2018-09-14T00:07:47Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:Women mathematicians]] (parent category) using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6933">{{Infobox scientist
|name              = Mara Dicle Neusel
|birth_date        = {{Birth date|1964|05|14}}
|birth_place       = [[Stuttgart]], [[Germany]]
|death_date        = {{Death date and age|2014|09|05|1964|05|14}} 
|alma_mater        = [[University of Göttingen]]
|doctoral_advisor  = [[:de:Tammo tom Dieck|Tammo tom Dieck]]
|thesis_title      = Konfigurationen von Geraden und einer Quadrik mit Baumauflösungen (Configurations of straight line and a quadric with tree resolutions)
|thesis_year      = 1992
|known_for        = Invariant Theory
}}
[[File:Mara Neusel - Alter Luisenstädtischer Friedhof (2).jpg|thumb|Grave of Mara Neusel in Berlin]]
'''Mara Dicle Neusel''' (May 14, 1964 – September 5, 2014) was a mathematician, author, teacher and an advocate for [[women in mathematics]]. The focus of her mathematical work was on [[invariant theory]], which can be briefly described at the study of [[group action]]s and their [[fixed point (mathematics)|fixed point]]s.

== Life and education ==

Mara Neusel was born in [[Stuttgart, Germany]], one of two children of Günter and Aylâ (Helvacioglu) Neusel. In 2001 she became the fourth woman to earn the advanced degree ''venia legendi'' ([[Habilitation]]) in mathematics from the [[University of Göttingen]], following in the footsteps of the first woman mathematician to be awarded the venia legend from Göttingen in 1919, [[Emmy Noether]].&lt;ref name="Vitulli, p. 21"&gt;[[Marie A. Vitulli|Marie Vitulli]], ''In Memoriam: Mara Dicle Neusel'' AWM Newsletter, November–December 2014, vol. 44 no. 6, p. 21: https://www.dropbox.com/s/dcwn31w7v2q63lf/AWM%20News%20Nov%20Dec%202014.pdf?dl=0&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Bessenrodt|first1=Christine|title=Habilitationen von Frauen|url=https://dmv.mathematik.de/index.php/all-docman-categories/stellungnahmen/stellungnahmen-der-dmv/439-sn-tuc-habilitationfrauen-2000/file|website=dmv.mathematik.de/index.php/all-docman-categories/stellungnahmen/stellungnahmen-der-dmv/439-sn-tuc-habilitationfrauen-2000/file|publisher=DeutscheMathimatikerVereingigung|accessdate=12 March 2015}}&lt;/ref&gt;

== Career ==

Professor Neusel was the author of a research monograph, an advanced undergraduate text, and a memoir for the [[American Mathematical Society]]: ''Invariant Theory and Finite Groups'',&lt;ref name="Monograph2002"&gt;{{cite book|last1=Neusel|first1=Mara D.|last2=Smith|first2=Larry|title=Invariant Theory of Finite Groups|date= 2002|series=Mathematical Surveys and Monographs|volume=94|publisher=American Mathematical Society|location=Providence, R.I.|mr=1869812|isbn=978-0-8218-4981-1|url=http://www.ams.org/bookstore-getitem/item=SURV-94-S|accessdate=10 March 2015}}&lt;/ref&gt;''Invariant Theory'',&lt;ref name="Monograph2007"&gt;{{cite book|last1=Neusel|first1=Mara D.|title=Invariant Theory |date= 2007|series=Student Mathematical Library|volume=36|publisher=American Mathematical Society|location=Providence, R.I.|mr=2280491|zbl=1110.13001|isbn=978-0-8218-4132-7|url=http://www.ams.org/bookstore-getitem/item=STML-36|accessdate=10 March 2015}}&lt;/ref&gt; and ''Inverse Invariant Theory and Steenrod Operations''.&lt;ref name="Memoir2000"&gt;{{cite book|last1=Neusel|first1=Mara D.|title=Inverse Invariant Theory and Steenrod Operations |date= 2007|series=Memoirs of the American Mathematical Society|volume=146|publisher=American Mathematical Society|location=Providence, R.I.|mr=1693799 |isbn=978-0-8218-2091-9|url=http://www.ams.org/bookstore-getitem/item=MEMO-146-692|accessdate=10 March 2015}}&lt;/ref&gt;    The exposition in the text ''Invariant Theory'' "stands out by its masterly clarity, comprehensiveness, profundity, and didactical disposition."&lt;ref&gt;{{cite web|last1=Kleinert|first1=Werner|title=Review of Invariant Theory|url=https://zbmath.org/?format=complete&amp;q=an:1110.13001|publisher=FIZ Karlsruhe GmbH|accessdate=12 March 2015}}&lt;/ref&gt; Neusel served on the editorial boards of ''Advances in Pure Mathematics'' and the ''International Journal of Mathematics and Applied Statistics''.  A tireless advocate for girls and women in mathematics, Dr. Neusel established  ''Emmy Noether High School Mathematics Days'' in May 2003&lt;ref&gt;{{cite journal|last1=Neusel|first1=Mara D.|title=The Noether Days at Texas Tech University|journal=Newsletter of the Association for Women in Mathematics|date=2004|volume=34|issue=5|pages=20–21|url=http://www.drivehq.com/file/df.aspx/isGallarytrue/shareID8755087/fileID748809056?1=1|accessdate=10 March 2015}}&lt;/ref&gt; which continues to be celebrated with workshops and mathematical competitions.&lt;ref&gt;{{cite web|title=Emmy Noether High School Mathematics Days|url=http://www.math.ttu.edu/~enoether/|website=www.math.ttu.edu/~enoether/|publisher=Texas Tech University|accessdate=10 March 2015}}&lt;/ref&gt;  She co-founded the Young Women in Mathematics group at Texas Tech and received a diversity grant to support the group.

Dr. Neusel began her career at  [[Texas Tech University]] in 2002 as an associate professor and was promoted to full professor in 2009.&lt;ref name="Lubbock Avalanche Journal"&gt;''Obituary'' Lubbock Avalanche-Journal, Sept. 10, 2014: http://www.legacy.com/obituaries/lubbockonline/obituary.aspx?pid=172415148&lt;/ref&gt; She also held visiting appointments at [[Yale University]], the [[University of Minnesota]], and the [[University of Notre Dame]].

Professor Neusel was had long term memberships in the [[American Mathematical Society]] &lt;ref&gt;{{cite journal|title=Deaths of AMS Members|journal=Notices of the American Mathematical Society|date=2015|volume=62|issue=3|pages=281–282|url=http://www.ams.org/notices/201503/rnoti-p281.pdf|accessdate=12 March 2015}}&lt;/ref&gt; and the [[Association for Women in Mathematics]].&lt;ref name="Vitulli, p. 21" /&gt; Neusel co-organized a special session on "[[Homological Algebra]] and Its Applications" at the 2005 Meeting of the American Mathematical Society in Lubbock, Texas&lt;ref&gt;{{cite journal|title=Program of Sessions: Lubbock, Texas, April 8 - 10, 2005|journal=Notices of the American Mathematical Society|date=2005|volume=52|issue=4|pages=Appendix 14–27|url=http://www.ams.org/notices/200504/lubbock-prog.pdf|accessdate=12 March 2015}}&lt;/ref&gt; as well as a special session on "Commutative Algebra and Algebraic Geometry" at the 40th Anniversary Celebration of the Association for Women in Mathematics at Brown University in 2011.&lt;ref&gt;{{cite web|title=AWM Anniversary Conference at Brown University (September 17-18, 2011)|url=http://icerm.brown.edu/awm-anniversary-2011/|accessdate=12 March 2015}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

{{Portal | Mathematics | United States}}
{{Authority control}}

{{DEFAULTSORT:Neusel, Mara}}
[[Category:1964 births]]
[[Category:2014 deaths]]
[[Category:German mathematicians]]
[[Category:American women mathematicians]]
[[Category:University of Göttingen alumni]]
[[Category:Texas Tech University faculty]]
[[Category:20th-century women scientists]]
[[Category:20th-century American scientists]]


{{mathematician-stub}}</text>
      <sha1>27p3ysrgxyr22pysuacz4rke7z5q0cg</sha1>
    </revision>
  </page>
  <page>
    <title>Negacyclic convolution</title>
    <ns>0</ns>
    <id>15743680</id>
    <revision>
      <id>576252894</id>
      <parentid>576079399</parentid>
      <timestamp>2013-10-08T06:59:58Z</timestamp>
      <contributor>
        <username>Anomalocaris</username>
        <id>299039</id>
      </contributor>
      <minor/>
      <comment>{{Mathanalysis-stub}}; wikilinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="567">In mathematics, '''negacyclic convolution''' is a [[convolution]] between two vectors ''a'' and ''b''.

It is also called skew [[circular convolution]] or wrapped convolution. It results from multiplication of a skew circulant matrix, generated by vector ''a'', with vector ''b''.

== See also ==
*[[Discrete_Fourier_transform#Circular_convolution_theorem_and_cross-correlation_theorem|Circular convolution theorem]]

[[Category:Bilinear operators]]
[[Category:Binary operations]]
[[Category:Functional analysis]]
[[Category:Image processing]]


{{Mathanalysis-stub}}</text>
      <sha1>4l722ueqizwcilutmy2o7hif0a63rdo</sha1>
    </revision>
  </page>
  <page>
    <title>Persistence of a number</title>
    <ns>0</ns>
    <id>624708</id>
    <revision>
      <id>832585386</id>
      <parentid>818829188</parentid>
      <timestamp>2018-03-26T21:23:42Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>save text from invisible. replace SloanesRef: use {{Cite OEIS}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4006">In [[mathematics]], the '''persistence of a number''' is the number of times one must apply a given operation to an integer before reaching a [[Fixed point (mathematics)|fixed point]] at which the operation no longer alters the number.

Usually, this involves additive or multiplicative persistence of an integer, which is how often one has to replace the number by the sum or product of its digits until one reaches a single digit. Because the numbers are broken down into their digits, the additive or multiplicative persistence depends on the [[radix]]. In the remainder of this article, base ten is assumed.

The single-digit final state reached in the process of calculating an integer's additive persistence is its [[digital root]]. Put another way, a number's additive persistence counts how many times we must [[digit sum|sum its digits]] to arrive at its digital root.

== Examples ==
The additive persistence of 2718 is 2: first we find that 2&amp;nbsp;+&amp;nbsp;7&amp;nbsp;+&amp;nbsp;1&amp;nbsp;+&amp;nbsp;8&amp;nbsp;=&amp;nbsp;18, and then that&amp;nbsp;1&amp;nbsp;+&amp;nbsp;8&amp;nbsp;=&amp;nbsp;9. The multiplicative persistence of 39 is 3, because it takes three steps to reduce 39 to a single digit: 39&amp;nbsp;→&amp;nbsp;27&amp;nbsp;→&amp;nbsp;14&amp;nbsp;→&amp;nbsp;4. Also, 39 is the smallest number of multiplicative persistence&amp;nbsp;3.

== Smallest numbers of a given persistence ==
For a [[radix]] of 10, there is thought to be no number with a multiplicative persistence &gt; 11: this is known to be true for numbers up to 10&lt;sup&gt;233&lt;/sup&gt;.&lt;ref&gt;{{cite web|url=http://mathworld.wolfram.com/MultiplicativePersistence.html|title=Multiplicative Persistence|first=Weisstein, Eric|last=W.|website=mathworld.wolfram.com}}&lt;/ref&gt; The smallest numbers with persistence 0, 1, ... are:
:0, 10, 25, 39, 77, 679, 6788, 68889, 2677889, 26888999, 3778888999, 277777788888899. {{OEIS|A003001}}
The search for these numbers can be sped up by using additional properties of the decimal digits of these record-breaking numbers. These digits must be sorted, and except for the first two digits, all digits must be 7, 8, or 9. There are also additional restrictions on the first two digits.
Based on these restrictions, the number of candidates for ''n''-digit numbers with record-breaking persistence is only proportional to the square of ''n'', a tiny fraction of all ''n''-digit numbers. However, any number that is missing from the sequence above would have multiplicative persistence &gt; 11; such numbers are believed not to exist, and would need to have over 200 digits if they do exist.&lt;ref&gt;{{Cite OEIS|A003001}}&lt;/ref&gt;

The additive persistence of a number, however, can become arbitrarily large (proof: For a given number &lt;math&gt;n&lt;/math&gt;, the persistence of the number consisting of &lt;math&gt;n&lt;/math&gt; repetitions of the digit 1 is 1 higher than that of &lt;math&gt;n&lt;/math&gt;). The smallest numbers of additive persistence 0, 1, ... are:
:0, 10, 19, 199, 19999999999999999999999, ... {{OEIS|A006050}}
The next number in the sequence (the smallest number of additive persistence 5) is 2&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;2×(10&lt;sup&gt;22&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1)/9&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 (that is, 1 followed by 2222222222222222222222 9's). For any fixed base, the sum of the digits of a number is proportional to its [[logarithm]]; therefore, the additive persistence is proportional to the [[iterated logarithm]]. More about the additive persistence of a number can be found [https://www.academia.edu/11654065/On_the_additive_persistence_of_a_number_in_base_p here].

==References==
{{Reflist}}

== Literature ==
* {{cite book |last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved problems in number theory | publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=978-0-387-20860-2 | zbl=1058.11001 | pages=398–399 }}
* {{cite book |last=Meimaris | first=Antonios | title=On the additive persistence of a number in base p| publisher=Preprint | year=2015| url=https://www.academia.edu/11654065/On_the_additive_persistence_of_a_number_in_base_p}}

[[Category:Number theory]]</text>
      <sha1>83hascfdbqx8r7ia88nenp4p45huhyu</sha1>
    </revision>
  </page>
  <page>
    <title>Pointwise</title>
    <ns>0</ns>
    <id>4786797</id>
    <revision>
      <id>870262080</id>
      <parentid>866208424</parentid>
      <timestamp>2018-11-23T15:57:30Z</timestamp>
      <contributor>
        <username>Just a guy from the KP</username>
        <id>9994896</id>
      </contributor>
      <minor/>
      <comment>/* Componentwise operations */ Typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4145">In [[mathematics]], the qualifier '''pointwise''' is used to indicate that a certain property is defined by considering each value &lt;math&gt;f(x)&lt;/math&gt; of some function &lt;math&gt;f.&lt;/math&gt; An important class of pointwise concepts are the ''pointwise operations'' &amp;ndash; operations defined on functions by applying the operations to function values separately for each point in the [[domain (mathematics)|domain]] of definition. Important [[Theory of relations|relations]] can also be defined pointwise.

== Pointwise operations ==
Examples include

: &lt;math&gt;
\begin{align}
(f+g)(x) &amp; = f(x)+g(x) &amp; \text{(pointwise addition)} \\
(f\cdot g)(x) &amp; = f(x) \cdot g(x) &amp; \text{(pointwise multiplication)} \\
(\lambda f)(x) &amp; = \lambda \cdot f(x) &amp; \text{(pointwise multiplication by a scalar)}
\end{align}
&lt;/math&gt;
where &lt;math&gt;f,g:X\to R&lt;/math&gt;.

See [[pointwise product]], [[scalar (mathematics)|scalar]].

Pointwise operations inherit such properties as [[associativity]], [[commutativity]] and [[distributivity]] from corresponding operations on the [[codomain]]. An example of an operation on functions which is ''not'' pointwise is [[convolution]].

By taking some [[algebraic structure]] &lt;math&gt;A&lt;/math&gt; in the place of &lt;math&gt;R&lt;/math&gt;, we can turn the set of all functions &lt;math&gt;X&lt;/math&gt; to the [[carrier set]] of &lt;math&gt;A&lt;/math&gt; into an algebraic structure of the same type in an analogous way.

== Componentwise operations ==
Componentwise operations are usually defined on vectors, where vectors are elements of the set &lt;math&gt;K^n&lt;/math&gt; for some [[natural number]] &lt;math&gt;n&lt;/math&gt; and some [[Field (mathematics)|field]] &lt;math&gt;K&lt;/math&gt;. If we denote the &lt;math&gt;i&lt;/math&gt;-th component of any vector &lt;math&gt;v&lt;/math&gt; as &lt;math&gt;v_i&lt;/math&gt;, then componentwise addition is &lt;math&gt;(u+v)_i = u_i+v_i&lt;/math&gt;.

Componentwise operations can be defined on matrices. Matrix addition, where &lt;math&gt;(A + B)_{ij} = A_{ij} + B_{ij}&lt;/math&gt; is a componentwise operation while [[matrix multiplication]] is not.

A [[Tuple#Tuples as functions|tuple]] can be regarded as a function, and a vector is a tuple. Therefore, any vector &lt;math&gt;v&lt;/math&gt; corresponds to the function &lt;math&gt;f:n\to K&lt;/math&gt; such that &lt;math&gt;f(i)=v_i&lt;/math&gt;, and any componentwise operation on vectors is the pointwise operation on functions corresponding to those vectors.

== Pointwise relations ==
In [[order theory]] it is common to define a pointwise [[partial order]] on functions. With ''A'', ''B'' [[partially ordered sets|posets]], the set of functions ''A'' → ''B'' can be ordered by ''f'' ≤ ''g'' if and only if (∀''x'' ∈ A) ''f''(''x'') ≤ ''g''(''x''). Pointwise orders also inherit some properties of the underlying posets. For instance if A and B are [[continuous lattice]]s, then so is the set of functions ''A'' → ''B'' with pointwise order.&lt;ref&gt;Gierz, p. xxxiii&lt;/ref&gt; Using the pointwise order on functions one can concisely define other important notions, for instance:&lt;ref&gt;Gierz, p. 26&lt;/ref&gt;

* A [[closure operator]] ''c'' on a poset ''P'' is a [[monotonic function|monotone]] and [[idempotent]] self-map on ''P'' (i.e. a [[projection (order)|projection operator]]) with the additional property that id&lt;sub&gt;''A''&lt;/sub&gt; ≤ ''c'', where id is the [[identity function]].
* Similarly, a projection operator ''k'' is called a [[kernel operator]] if and only if ''k'' ≤ id&lt;sub&gt;''A''&lt;/sub&gt;.

An example of [[infinitary]] pointwise relation is [[pointwise convergence]] of functions &amp;mdash; a [[sequence]] of functions 
:&lt;math&gt;\{f_n\}_{n=1}^\infty&lt;/math&gt;
with
:&lt;math&gt;f_n:X \longrightarrow Y&lt;/math&gt;
[[limit of a sequence|converges]] pointwise to a function &lt;math&gt;f&lt;/math&gt; if for each &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;X&lt;/math&gt;
:&lt;math&gt;\lim_{n \rightarrow \infty} f_n(x) = f(x).&lt;/math&gt;

== Notes ==
{{reflist}}

== References ==
''For order theory examples:''
* T.S. Blyth, ''Lattices and Ordered Algebraic Structures'', Springer, 2005, {{isbn|1-85233-905-5}}.
* G. Gierz, K. H. Hofmann, K. Keimel, J. D. Lawson, M. Mislove, D. S. Scott: ''Continuous Lattices and Domains'', Cambridge University Press, 2003.

{{PlanetMath attribution|id=7260|title=Pointwise}}

[[Category:Mathematical terminology]]</text>
      <sha1>78qy4qwbvouphbe0903904xgxr7b2ii</sha1>
    </revision>
  </page>
  <page>
    <title>Quantitative analysis (finance)</title>
    <ns>0</ns>
    <id>29295573</id>
    <revision>
      <id>869557177</id>
      <parentid>869545142</parentid>
      <timestamp>2018-11-19T10:18:56Z</timestamp>
      <contributor>
        <username>Limit-theorem</username>
        <id>17495744</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1248">{{Merge from|Quantitative analyst|date=November 2018}}
{{unreferenced|date=May 2016}}
'''Quantitative analysis''' is the use of models, or algorithms, to model risks in general, or to evaluate assets for investment. The process usually consists of searching vast databases for patterns, such as correlations among liquid assets or price-movement patterns ([[trend following]] or [[Mean reversion (finance)|mean reversion]]). The resulting strategies may involve [[high-frequency trading]].

Some of the larger investment managers using quantitative analysis include [[Renaissance Technologies]], [[Winton Group]], [[D. E. Shaw &amp; Co.]], [[AQR Capital Management]], and [[Two Sigma Investments]].
== See also ==
* [[Black–Scholes equation]]
* [[Financial signal processing]]
* [[Quantitative analyst]]
* [[Technical analysis]]

==References==
&lt;references/&gt;
* [https://books.google.com.vn/books?hl=en&amp;lr=&amp;id=FV2mBgAAQBAJ&amp;oi=fnd&amp;pg=PT13&amp;dq=%22what+is+Quantitative+analysis%22&amp;ots=LCnNueZDHt&amp;sig=7bbyR8R0p8ojcBCHGNct7MqgnZ8&amp;redir_esc=y#v=onepage&amp;q=%22what%20is%20Quantitative%20analysis%22&amp;f=false Analysing Quantitative Data for Business and Management Students]

[[Category:Valuation (finance)]]
[[Category:Mathematical finance]]
{{investment-stub}}</text>
      <sha1>avai8xeojdufl7zagq30phoc2qzawad</sha1>
    </revision>
  </page>
  <page>
    <title>Reduced residue system</title>
    <ns>0</ns>
    <id>10299080</id>
    <revision>
      <id>833411227</id>
      <parentid>815831659</parentid>
      <timestamp>2018-03-31T11:06:26Z</timestamp>
      <contributor>
        <username>Alpha-Gamma</username>
        <id>30330458</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2339">Any subset ''R'' of the integers is called a '''reduced residue system''' modulo ''n'' if:

#gcd(''r'', ''n'') = 1 for each ''r'' contained in ''R'';
#''R'' contains φ(''n'') elements;
#no two elements of ''R'' are congruent modulo ''n''.&lt;ref&gt;{{harvtxt|Long|1972|p=85}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Pettofrezzo|Byrkit|1970|p=104}}&lt;/ref&gt;

Here &lt;math&gt;\varphi&lt;/math&gt; denotes [[Euler's totient function]].

A reduced residue system modulo ''n'' can be formed from a [[complete residue system modulo m|complete residue system]] modulo ''n'' by removing all integers not relatively prime to ''n''. For example, a complete residue system modulo 12 is {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}. The so-called [[totative]]s 1, 5, 7 and 11 are the only integers in this set which are relatively prime to 12, and so the corresponding reduced residue system modulo 12 is {1,5,7,11}. The [[cardinality]] of this set can be calculated with the totient function: &lt;math&gt;\varphi(12) = 4&lt;/math&gt;. Some other reduced residue systems modulo 12 are:

*{13,17,19,23}
*{−11,−7,−5,−1}
*{−7,−13,13,31}
*{35,43,53,61}

==Facts==
*If {{math|{''r''&lt;sub&gt;1&lt;/sub&gt;, ''r''&lt;sub&gt;2&lt;/sub&gt;, ... , ''r''&lt;sub&gt;φ(''n'')&lt;/sub&gt;} }} is a reduced residue system with ''n'' &gt; 2, then &lt;math&gt;\sum r_i \equiv 0 \pmod n&lt;/math&gt;.
*Every number in a reduced residue system mod ''n'' is a generator for the additive group of integers modulo n.

==See also==
*[[Complete residue system modulo m]]
*[[Congruence relation]]
*[[Euler's totient function]]
*[[Greatest common divisor]]
*[[Least residue system modulo m]]
*[[Modular arithmetic]]
*[[Number theory]]
*[[Residue number system]]

== Notes ==
&lt;references/&gt;

== References ==
* {{citation |last=Long |first=Calvin T. |year=1972 |title=Elementary Introduction to Number Theory |edition=2nd |publisher=[[D. C. Heath and Company]] |location=Lexington |lccn=77171950}}
* {{citation |last1=Pettofrezzo |first1=Anthony J. |last2=Byrkit |first2=Donald R. |year=1970 |title=Elements of Number Theory |publisher=[[Prentice Hall]] |location=Englewood Cliffs |lccn=71081766}}

==External links==
*[http://planetmath.org/ResidueSystems Residue systems] at PlanetMath
*[http://mathworld.wolfram.com/ReducedResidueSystem.html Reduced residue system] at MathWorld

[[Category:Modular arithmetic]]
[[Category:Elementary_number_theory]]

{{numtheory-stub}}</text>
      <sha1>hon6jvn1naciai5wa0hyqa3d1x6p3ab</sha1>
    </revision>
  </page>
  <page>
    <title>Relevance logic</title>
    <ns>0</ns>
    <id>185076</id>
    <revision>
      <id>870794162</id>
      <parentid>836099696</parentid>
      <timestamp>2018-11-27T01:25:06Z</timestamp>
      <contributor>
        <username>Chris James Hall</username>
        <id>28834157</id>
      </contributor>
      <comment>adding mergefrom tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19349">{{mergefrom|Strict_logic|discuss=Talk:Relevance_logic#Merger proposal|date=November 2018}}

'''Relevance logic''', also called '''relevant logic''', is a kind of non-[[classical logic]] requiring the [[Antecedent (logic)|antecedent]] and [[consequent]] of [[Entailment|implications]] to be relevantly related. They may be viewed as a family of [[substructural logic|substructural]] or [[modal logic|modal]] logics. (It is generally, but not universally, called ''relevant logic'' by Australian [[logician]]s, and ''relevance logic'' by other English-speaking logicians.)

Relevance logic aims to capture aspects of implication that are ignored by the "[[material conditional|material implication]]" operator in classical [[truth-functional logic]], namely the notion of relevance between antecedent and conditional of a true implication.  This idea is not new: [[C. I. Lewis]] was led to invent modal logic, and specifically [[strict implication]], on the grounds that classical logic grants [[paradoxes of material implication]] such as the principle that [[Vacuous truth|a falsehood implies any proposition]].  Hence "if I'm a donkey, then two and two is four" is true when translated as a material implication, yet it seems intuitively false since a true implication must tie the antecedent and consequent together by some notion of relevance. And whether or not I'm a donkey seems in no way relevant to whether two and two is four.

How does relevance logic formally capture a notion of relevance? In terms of a syntactical constraint for a [[propositional calculus]], it is necessary, but not sufficient, that premises and conclusion share [[atomic formula]]e (formulae that do not contain any [[logical connective]]s). In a [[predicate calculus]], relevance requires sharing of variables and constants between premises and conclusion. This can be ensured (along with stronger conditions) by, e.g., placing certain restrictions on the rules of a natural deduction system. In particular, a Fitch-style [[natural deduction]] can be adapted to accommodate relevance by introducing tags at the end of each line of an application of an inference indicating the premises relevant to the conclusion of the inference.  [[Gentzen]]-style [[sequent calculus|sequent calculi]] can be modified by removing the weakening rules that allow for the introduction of arbitrary formulae on the right or left side of the [[sequent]]s.

A notable feature of relevance logics is that they are [[paraconsistent logic]]s: the existence of a contradiction will not cause "[[principle of explosion|explosion]]". This follows from the fact that a conditional with a contradictory antecedent that does not share any propositional or predicate letters with the consequent cannot be true (or derivable).

==History==

Relevance logic was proposed in 1928 by Russian Soviet philosopher [[Ivan E. Orlov]] (1886–circa 1936) in his strictly mathematical paper "The Logic of Compatibility of Propositions" published in Matematicheskii Sbornik.
The basic idea of relevant implication appears in medieval logic, and some pioneering work was done by [[Wilhelm Ackermann|Ackermann]],&lt;ref&gt;
{{Citation
 | title = Begründung einer strengen Implikation
 | jstor = 2268750
 | year = 1956
 | first = W. | last =  Ackermann | authorlink = Wilhelm Ackermann
 | journal = [[Journal of Symbolic Logic]]
 | pages = 113–128 | volume = 21 | issue = 2}}
&lt;/ref&gt;
[[Moh Shaw-Kwei|Moh]],&lt;ref&gt;{{Citation
 | title = The Deduction Theorems and Two New Logical Systems
 | year = 1950
 | last = Moh  | first = Shaw-kwei
 | journal = Methodos
 | pages = 56–75 | volume = 2
}}
Moh Shaw-Kwei, 1950, "," Methodos 2 56-75.
&lt;/ref&gt;
and [[Alonzo Church|Church]]&lt;ref&gt;{{Citation
 | title = The Weak Theory of Implication
 | year = 1951
 | last = Church |first= A.
}} in ''Kontroliertes Denken: Untersuchungen zum Logikkalkül und zur Logik der Einzelwissenschaften'', Kommissions-Verlag Karl Alber, edited by A. Menne, A. Wilhelmy and H. Angsil, pp.22-37.
&lt;/ref&gt;
in the 1950s.  Drawing on them, [[Nuel Belnap]] and [[Alan Ross Anderson]] (with others) wrote the ''magnum opus'' of the subject, ''Entailment: The Logic of Relevance and Necessity'' in the 1970s (the second volume being published in the nineties). They focused on both systems of [[entailment]] and systems of relevance, where implications of the former kinds are supposed to be both relevant and necessary.

==Axioms==
The early developments in relevance logic focused on the stronger systems. The development of the Routley-Meyer semantics brought out a range of weaker logics. The weakest of these logics is the relevance logic B. It is axiomatized with the following axioms and rules.
# &lt;math&gt;A\to A&lt;/math&gt;
# &lt;math&gt;A\land B\to A&lt;/math&gt;
# &lt;math&gt;A\land B\to B&lt;/math&gt;
# &lt;math&gt;(A\to B)\land(A\to C)\to (A\to B\land C)&lt;/math&gt;
# &lt;math&gt;A\to A\lor B&lt;/math&gt;
# &lt;math&gt;B\to A\lor B&lt;/math&gt;
# &lt;math&gt;(A\to C)\land(B\to C)\to (A\lor B\to C)&lt;/math&gt;
# &lt;math&gt;A\land(B\lor C)\to (A\land B)\lor(A\land C)&lt;/math&gt;
# &lt;math&gt;\lnot\lnot A\to A&lt;/math&gt;
The rules are the following.
# &lt;math&gt;A, A\to B\vdash B&lt;/math&gt;
# &lt;math&gt;A, B\vdash A\land B&lt;/math&gt;
# &lt;math&gt;A\to B\vdash (C\to A)\to(C\to B)&lt;/math&gt;
# &lt;math&gt;A\to B\vdash (B\to C)\to(A\to C)&lt;/math&gt;
# &lt;math&gt;A\to B\vdash \lnot B\to\lnot A&lt;/math&gt;
Stronger logics can be obtained by adding any of the following axioms.
# &lt;math&gt;(A\to B)\to (\lnot B\to\lnot A)&lt;/math&gt;
# &lt;math&gt;(A\to B)\land(B\to C)\to (A\to C)&lt;/math&gt;
# &lt;math&gt;(A\to B)\to((B\to C)\to(A\to C))&lt;/math&gt;
# &lt;math&gt;(A\to B)\to((C\to A)\to(C\to B))&lt;/math&gt;
# &lt;math&gt;(A\to(A\to B))\to(A\to B)&lt;/math&gt;
# &lt;math&gt;(A\land (A\to B))\to B&lt;/math&gt;
# &lt;math&gt;(A\to\lnot A)\to\lnot A&lt;/math&gt;
# &lt;math&gt;(A\to (B\to C))\to(B\to(A\to C))&lt;/math&gt;
# &lt;math&gt;A\to((A\to B)\to B)&lt;/math&gt;
# &lt;math&gt;((A\to A)\to B)\to B&lt;/math&gt;
# &lt;math&gt;A\lor\lnot A&lt;/math&gt;
# &lt;math&gt;A\to(A\to A)&lt;/math&gt;
There are some notable logics stronger than B that can be obtained by adding axioms to B as follows.
* For DW, add axiom 1.
* For DJ, add axioms 1, 2.
* For TW, add axioms 1, 2, 3, 4.
* For RW, add axioms 1, 2, 3, 4, 8, 9.
* For T, add axioms 1, 2, 3, 4, 5, 6, 7, 11.
* For R, add axioms 1-11.
* For E, add axioms 1-7, 10, 11, &lt;math&gt;((A\to A)\land(B\to B)\to C)\to C&lt;/math&gt;, and &lt;math&gt;\Box A\land \Box B\to \Box (A\land B)&lt;/math&gt;, where &lt;math&gt;\Box A&lt;/math&gt; is defined as &lt;math&gt;(A\to A)\to A&lt;/math&gt;.
* For RM, add all the additional axioms.

==Models==
===Routley-Meyer models===
The standard model theory for relevance logics is the Routley-Meyer ternary-relational semantics developed by [[Richard Sylvan|Richard Routley]] and [[Bob_Meyer_(logician)|Robert Meyer]]. A Routley-Meyer frame F for a propositional language is a quadruple (W,R,*,0), where W is a non-empty set, R is a ternary relation on W, and * is a function from W to W, and &lt;math&gt;0\in W&lt;/math&gt;. A Routley-Meyer model M is a Routley-Meyer frame F together with a valuation, &lt;math&gt;\Vdash&lt;/math&gt;, that assigns a truth value to each atomic proposition relative to each point &lt;math&gt;a\in W&lt;/math&gt;. There are some conditions placed on Routley-Meyer frames. Define &lt;math&gt;a\leq b&lt;/math&gt; as &lt;math&gt;R0ab&lt;/math&gt;.
* &lt;math&gt;a\leq a&lt;/math&gt;.
* If &lt;math&gt;a\leq b&lt;/math&gt;  and &lt;math&gt;b\leq c&lt;/math&gt;, then &lt;math&gt;a\leq c&lt;/math&gt;.
* If &lt;math&gt;d\leq a&lt;/math&gt; and &lt;math&gt;Rabc&lt;/math&gt;, then &lt;math&gt;Rdbc&lt;/math&gt;.
* &lt;math&gt;a^{**}=a&lt;/math&gt;.
* If &lt;math&gt;a\leq b&lt;/math&gt;, then &lt;math&gt;b^*\leq a^*&lt;/math&gt;.
Write &lt;math&gt;M,a\Vdash A&lt;/math&gt; and &lt;math&gt;M,a\nVdash A&lt;/math&gt; to indicate that the formula &lt;math&gt;A&lt;/math&gt; is true, or not true, respectively, at point &lt;math&gt;a&lt;/math&gt; in &lt;math&gt;M&lt;/math&gt;. 
One final condition on Routley-Meyer models is the hereditariness condition.
* If &lt;math&gt;M,a\Vdash p&lt;/math&gt; and &lt;math&gt;a\leq b&lt;/math&gt;, then &lt;math&gt;M,b\Vdash p&lt;/math&gt;, for all atomic propositions &lt;math&gt;p&lt;/math&gt;.
By an inductive argument, hereditariness can be shown to extend to complex formulas, using the truth conditions below.
* If &lt;math&gt;M,a\Vdash A&lt;/math&gt; and &lt;math&gt;a\leq b&lt;/math&gt;, then &lt;math&gt;M,b\Vdash A&lt;/math&gt;, for all formulas &lt;math&gt;A&lt;/math&gt;.

The truth conditions for complex formulas are as follows.
* &lt;math&gt;M,a\Vdash A\land B \iff M, a\Vdash A&lt;/math&gt; and &lt;math&gt;M,a\Vdash B&lt;/math&gt;
* &lt;math&gt;M,a\Vdash A\lor B \iff M, a\Vdash A&lt;/math&gt; or &lt;math&gt;M,a\Vdash B&lt;/math&gt;
* &lt;math&gt;M,a\Vdash A\to B\iff \forall b,c((Rabc\land M,b\Vdash A)\Rightarrow M,c\Vdash B)&lt;/math&gt;
* &lt;math&gt;M,a\Vdash\lnot A\iff M,a^*\nVdash A&lt;/math&gt;

A formula &lt;math&gt;A&lt;/math&gt; holds in a model &lt;math&gt;M&lt;/math&gt; just in case &lt;math&gt;M,0\Vdash A&lt;/math&gt;. A formula &lt;math&gt;A&lt;/math&gt; holds on a frame &lt;math&gt;F&lt;/math&gt; iff A holds in every model &lt;math&gt;(F,\Vdash)&lt;/math&gt;. A formula &lt;math&gt;A&lt;/math&gt; is valid in a class of frames iff A holds on every frame in that class. 
The class of all Routley-Meyer frames satisfying the above conditions validates that relevance logic B. One can obtain Routley-Meyer frames for other relevance logics by placing appropriate restrictions on R and on *. These conditions are easier to state using some standard definitions. Let &lt;math&gt;Rabcd&lt;/math&gt; be defined as &lt;math&gt;\exists x(Rabx \land Rxcd)&lt;/math&gt;, and let &lt;math&gt;Ra(bc)d&lt;/math&gt; be defined as &lt;math&gt;\exists x(Rbcx \land Raxd)&lt;/math&gt;. Some of the frame conditions and the axioms they validate are the following.
{| class="wikitable"
! Name !! Frame condition !! Axiom
|-
! Pseudo-modus ponens 
| &lt;math&gt;Raaa&lt;/math&gt;
| &lt;math&gt;(A\land (A\to B))\to B&lt;/math&gt;
|-
! Prefixing 
| &lt;math&gt;Rabcd\Rightarrow Ra(bc)d&lt;/math&gt;
| &lt;math&gt;(A\to B)\to((C\to A)\to(C\to B))&lt;/math&gt;
|-
! Suffixing 
| &lt;math&gt;Rabcd\Rightarrow Rb(ac)d&lt;/math&gt;
| &lt;math&gt;(A\to B)\to((B\to C)\to(A\to C))&lt;/math&gt;
|-
! Contraction
| &lt;math&gt;Rabc\Rightarrow Rabbc&lt;/math&gt;
| &lt;math&gt;(A\to(A\to B))\to(A\to B)&lt;/math&gt;
|-
! Conjunctive syllogism 
| &lt;math&gt;Rabc\Rightarrow Ra(ab)c&lt;/math&gt;
| &lt;math&gt;(A\to B)\land(B\to C)\to (A\to C)&lt;/math&gt;
|-
! Assertion 
| &lt;math&gt;Rabc\Rightarrow Rbac&lt;/math&gt;
| &lt;math&gt;A\to((A\to B)\to B)&lt;/math&gt;
|-
! E axiom 
| &lt;math&gt;Ra0a&lt;/math&gt;
| &lt;math&gt;((A\to A)\to B)\to B&lt;/math&gt;
|-
! Mingle axiom
| &lt;math&gt;Rabc\Rightarrow a\leq c&lt;/math&gt; or &lt;math&gt;b\leq c&lt;/math&gt;
| &lt;math&gt;A\to(A\to A)&lt;/math&gt;
|-
! Reductio
| &lt;math&gt;Raa^*a&lt;/math&gt;
| &lt;math&gt;(A\to\lnot A)\to\lnot A&lt;/math&gt;
|-
! Contraposition
| &lt;math&gt;Rabc\Rightarrow Rac^*b^*&lt;/math&gt;
| &lt;math&gt;(A\to B)\to (\lnot B\to\lnot A)&lt;/math&gt;
|-
! Excluded middle
| &lt;math&gt;0^*\leq 0&lt;/math&gt;
| &lt;math&gt;A\lor\lnot A&lt;/math&gt;
|-
! Strict implication weakening
| &lt;math&gt;0\leq a&lt;/math&gt;
| &lt;math&gt;A\to(B\to B)&lt;/math&gt;
|-
! Weakening
| &lt;math&gt;Rabc\Rightarrow b\leq c&lt;/math&gt;
| &lt;math&gt;A\to(B\to A)&lt;/math&gt;
|}
The last two conditions validate forms of weakening that relevance logics were originally developed to avoid. They are included to show the flexibility of the Routley-Meyer models.

===Operational models===
Operational models for negation-free fragments of relevance logics were developed by [[Alasdair Urquhart]] in his PhD thesis and in subsequent work. The intuitive idea behind the operational models is that points in a model are pieces of information, and combining information supporting a conditional with the information supporting its antecedent yields some information that supports the consequent. Since the operational models do not generally interpret negation, this section will consider only languages with a conditional, conjunction, and disjunction.

An operational frame &lt;math&gt;F&lt;/math&gt; is a triple &lt;math&gt;(K,\cdot,0)&lt;/math&gt;, where  &lt;math&gt;K&lt;/math&gt; is a non-empty set, &lt;math&gt;0\in K&lt;/math&gt;, and &lt;math&gt;\cdot&lt;/math&gt; is a binary operation on &lt;math&gt;K&lt;/math&gt;. Frames have conditions, some of which may be dropped to model different logics. The conditions Urquhart proposed to model the conditional of the relevance logic R are the following.
* &lt;math&gt;x\cdot x=x&lt;/math&gt;
* &lt;math&gt;(x\cdot y)\cdot z=x\cdot(y\cdot z)&lt;/math&gt;
* &lt;math&gt;x\cdot y=y\cdot x&lt;/math&gt;
* &lt;math&gt;0\cdot x=x&lt;/math&gt;
Under these conditions, the operational frame is a join semilattice.

An operational model &lt;math&gt;M&lt;/math&gt; is a frame &lt;math&gt;F&lt;/math&gt; with a valuation &lt;math&gt;V&lt;/math&gt; that maps pairs of points and atomic propositions to truth values, T or F. &lt;math&gt;V&lt;/math&gt; can be extended to a valuation &lt;math&gt;\Vdash&lt;/math&gt; on complex formulas as follows.
* &lt;math&gt;M,a\Vdash p \iff V(a,p)=T&lt;/math&gt;, for atomic propositions
* &lt;math&gt;M,a\Vdash A\land B \iff M, a\Vdash A&lt;/math&gt; and &lt;math&gt;M,a\Vdash B&lt;/math&gt;
* &lt;math&gt;M,a\Vdash A\lor B \iff M, a\Vdash A&lt;/math&gt; or &lt;math&gt;M,a\Vdash B&lt;/math&gt;
* &lt;math&gt;M,a\Vdash A\to B\iff \forall b(M,b\Vdash A\Rightarrow M,a\cdot b\Vdash B)&lt;/math&gt;

A formula &lt;math&gt;A&lt;/math&gt; holds in a model &lt;math&gt;M&lt;/math&gt; iff &lt;math&gt;M,0\Vdash A&lt;/math&gt;. A formula &lt;math&gt;A&lt;/math&gt; is valid in a class of models &lt;math&gt;C&lt;/math&gt; iff it holds in each model &lt;math&gt;M\in C&lt;/math&gt;. 

The conditional fragment of R is sound and complete with respect to the class of semilattice models. The logic with conjunction and disjunction is properly stronger than the conditional, conjunction, disjunction fragment of R. In particular, the formula &lt;math&gt;(A\to(B\lor C))\land(B\to C)\to (A\to C)&lt;/math&gt; is valid for the operational models but it is invalid in R. The logic generated by the operational models for R has a complete axiomatic proof system, due [[Kit Fine]] and to Gerald Charlwood. Charlwood also provided a natural deduction system for the logic, which he proved equivalent to the axiomatic system. Charlwood showed that his natural deduction system is equivalent to a system provided by [[Dag Prawitz]].

The operational semantics can be adapted to model the conditional of E by adding a non-empty set of worlds &lt;math&gt;W&lt;/math&gt; and an accessibility relation &lt;math&gt;\leq&lt;/math&gt; on &lt;math&gt;W\times W&lt;/math&gt; to the frames. The accessibility relation is required to be reflexive and transitive, to capture the idea that E's conditional has an S4 necessity. The valuations then map triples of atomic propositions, points, and worlds to truth values. The truth condition for the conditional is changed to the following. 
* &lt;math&gt;M,a, w\Vdash A\to B\iff \forall b, \forall w'\geq w(M,b, w'\Vdash A\Rightarrow M,a\cdot b,w'\Vdash B)&lt;/math&gt;

The operational semantics can be adapted to model the conditional of T by adding a relation &lt;math&gt;\leq&lt;/math&gt; on &lt;math&gt;K\times K&lt;/math&gt;. The relation is required to obey the following conditions.
* &lt;math&gt;0\leq x&lt;/math&gt;
* If &lt;math&gt;x\leq y&lt;/math&gt; and &lt;math&gt;y\leq z&lt;/math&gt;, then &lt;math&gt;x\leq z&lt;/math&gt;
* If &lt;math&gt;x\leq y&lt;/math&gt;, then &lt;math&gt;x\cdot z\leq y\cdot z&lt;/math&gt;
The truth condition for the conditional is changed to the following.
* &lt;math&gt;M,a\Vdash A\to B\iff \forall b((a\leq b\land M,b\Vdash A)\Rightarrow M,a\cdot b\Vdash B)&lt;/math&gt;

There are two ways to model the contraction-less relevance logics TW and RW  with the operational models. The first way is to drop the condition that &lt;math&gt;x\cdot x=x&lt;/math&gt;. The second way is to keep the semilattice conditions on frames and add a binary relation, &lt;math&gt;J&lt;/math&gt;, of disjointness to the frame. For these models, the truth conditions for the conditional is changed to the following, with the addition of the ordering in the case of TW.
* &lt;math&gt;M,a\Vdash A\to B\iff \forall b((Jab \land M,b\Vdash A)\Rightarrow M,a\cdot b\Vdash B)&lt;/math&gt;

Urquhart showed that the semilattice logic for R is properly stronger than the positive fragment of R. Lloyd Humberstone provided an enrichment of the operational models that permitted a different truth condition for disjunction. The resulting class of models generates exactly the positive fragment of R.

===Algebraic models===
Some relevance logics can be given algebraic models, such as the logic R. The algebraic structures for R are [[De_Morgan_algebra|de Morgan monoids]], which are sextuples &lt;math&gt;(D,\land,\lor,\lnot,\circ,e)&lt;/math&gt; where
* &lt;math&gt;(D,\land,\lor,\lnot)&lt;/math&gt; is a distributive [[Lattice_(order)|lattice]] with a unary operation, &lt;math&gt;\lnot&lt;/math&gt; obeying the laws &lt;math&gt;\lnot\lnot x=x&lt;/math&gt; and if &lt;math&gt;x\leq y&lt;/math&gt; then &lt;math&gt;\lnot y\leq \lnot x&lt;/math&gt;;
* &lt;math&gt;e\in D&lt;/math&gt;, the binary operation &lt;math&gt;\circ&lt;/math&gt; is [[Commutative_property|commutative]] (&lt;math&gt;x\circ y=y\circ x&lt;/math&gt;) and [[Associative_property|associative]] (&lt;math&gt;(x\circ y)\circ z=x\circ (y\circ z)&lt;/math&gt;), and &lt;math&gt;e\circ x=x&lt;/math&gt;, i.e. &lt;math&gt;(D,\circ,e)&lt;/math&gt; is an [[Monoid#Commutative_monoid|Abelian monoid]] with [[Identity_element|identity]] &lt;math&gt;e&lt;/math&gt;;
* the monoid is lattice-ordered and satisfies &lt;math&gt;x\circ(y\lor z)=(x\circ y)\lor(x\circ z)&lt;/math&gt;;
* &lt;math&gt;x\leq x\circ x&lt;/math&gt;; and 
* if &lt;math&gt;x\circ y\leq z&lt;/math&gt;, then &lt;math&gt;x\circ\lnot z\leq \lnot y&lt;/math&gt;.
The operation &lt;math&gt;x\to y&lt;/math&gt; interpreting the conditional of R is defined as &lt;math&gt;\lnot(x\circ\lnot y)&lt;/math&gt;. 
A de Morgan monoid is a [[residuated lattice]], obeying the following residuation condition. 
: &lt;math&gt;x \circ y\leq z \iff x\leq y\to z&lt;/math&gt;

An interpretation &lt;math&gt;v&lt;/math&gt; is a [[homomorphism]] from the propositional language to a de Morgan monoid &lt;math&gt;M&lt;/math&gt; such that 
* &lt;math&gt;v(p)\in D&lt;/math&gt; for all atomic propositions, 
* &lt;math&gt;v(\lnot A)=\lnot v(A)&lt;/math&gt;
* &lt;math&gt;v(A\lor B)=v(A)\lor v(B)&lt;/math&gt;
* &lt;math&gt;v(A\land B)=v(A)\land v(B)&lt;/math&gt;
* &lt;math&gt;v(A\to B)=v(A)\to v(B)&lt;/math&gt;

Given a de Morgan monoid &lt;math&gt;M&lt;/math&gt; and an interpretation &lt;math&gt;v&lt;/math&gt;, one can say that formula &lt;math&gt;A&lt;/math&gt; holds on &lt;math&gt;v&lt;/math&gt; just in case &lt;math&gt;e\leq v(A)&lt;/math&gt;. A formula &lt;math&gt;A&lt;/math&gt; is valid just in case it holds on all interpretations on all de Morgan monoids. The logic R is sound and complete for de Morgan monoids.

==See also==
{{Portal|Logic}}
* [[Non sequitur (logic)]]
* [[Relevant type system]], a [[substructural type system]]

==References==
&lt;references/&gt;

==Bibliography==
* [[Alan Ross Anderson]] and [[Nuel Belnap]], 1975.  ''Entailment: the logic of relevance and necessity, vol. I''.  Princeton University Press. {{isbn|0-691-07192-6}}
* ------- and J. M. Dunn, 1992.  ''Entailment: the logic of relevance and necessity, vol. II'', Princeton University Press.
* Mares, Edwin, and Meyer, R. K., 2001, "Relevant Logics," in Goble, Lou, ed., ''The Blackwell Guide to Philosophical Logic''. Blackwell.
* Richard Routley, Val Plumwood, Robert K. Meyer, and Ross T. Brady. ''Relevant Logics and their Rivals''. Ridgeview, 1982.
* R. Brady (ed.), ''Relevant Logics and their Rivals (Volume II)'', Aldershot: Ashgate, 2003.
* Alasdair Urquhart. Semantics for relevant logics. ''Journal of Symbolic Logic'', 37:159–169, 1972.
* Alasdair Urquhart. ''The Semantics of Entailment''. PhD thesis, University of Pittsburgh, 1972.
* Katalin Bimbó, Relevance logics, in ''Philosophy of Logic'', D. Jacquette (ed.), (volume 5 of ''Handbook of the Philosophy of Science'', D. Gabbay, P. Thagard, J. Woods (eds.)), Elsevier (North-Holland), 2006, pp. 723–789.
* J. Michael Dunn and Greg Restall. Relevance logic. In ''Handbook of Philosophical Logic'', Volume 6, F. Guenthner and D. Gabbay (eds.), Dordrecht: Kluwer, 2002, pp. 1–136.
* Stephen Read, ''Relevant Logic'', Oxford: Blackwell, 1988.

==External links==
*[[Stanford Encyclopaedia of Philosophy]]:  "[http://plato.stanford.edu/entries/logic-relevance/ Relevance logic]" -- by Edwin Mares.
*"[http://consequently.org/papers/rle.pdf Relevance logic]" -- by J. Michael Dunn and Greg Restall
*''[https://www.st-andrews.ac.uk/~slr/Relevant_Logic.pdf Relevant Logic]'' -- by Stephen Read
{{Non-classical logic}}

{{DEFAULTSORT:Relevance Logic}}
[[Category:Substructural logic]]
[[Category:Non-classical logic]]
[[Category:Paraconsistent logic]]</text>
      <sha1>m5z2t0neuyp2gq36iv5rxj7v9bve4k9</sha1>
    </revision>
  </page>
  <page>
    <title>Rigidity matroid</title>
    <ns>0</ns>
    <id>36758654</id>
    <revision>
      <id>846748251</id>
      <parentid>841568464</parentid>
      <timestamp>2018-06-20T17:13:29Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15831">In the mathematics of [[structural rigidity]], a '''rigidity matroid''' is a [[matroid]] that describes the number of [[Degrees of freedom (mechanics)|degrees of freedom]] of an [[undirected graph]] with rigid edges of fixed lengths, embedded into [[Euclidean space]]. In a rigidity matroid for a graph with ''n'' vertices in ''d''-dimensional space, a set of edges that defines a subgraph with ''k'' degrees of freedom has [[matroid rank]] ''dn''&amp;nbsp;&amp;minus;&amp;nbsp;''k''. A set of edges is independent if and only if, for every edge in the set, removing the edge would increase the number of degrees of freedom of the remaining subgraph.&lt;ref name="graver"&gt;{{citation
 | last = Graver | first = Jack E.
 | doi = 10.1137/0404032
 | issue = 3
 | journal = SIAM Journal on Discrete Mathematics
 | mr = 1105942
 | pages = 355–368
 | title = Rigidity matroids
 | volume = 4
 | year = 1991}}.&lt;/ref&gt;&lt;ref name="w92"&gt;{{citation
 | last = Whiteley | first = Walter | authorlink = Walter Whiteley
 | contribution = Matroids and rigid structures
 | doi = 10.1017/CBO9780511662041.002
 | location = Cambridge
 | mr = 1165538
 | pages = 1–53
 | publisher = Cambridge Univ. Press
 | series = Encyclopedia of Mathematics and its Applications
 | title = Matroid Applications
 | volume = 40
 | year = 1992}}.&lt;/ref&gt;&lt;ref name="whiteley"&gt;{{citation
 | last = Whiteley | first = Walter | authorlink = Walter Whiteley
 | contribution = Some matroids from discrete applied geometry
 | doi = 10.1090/conm/197/02540
 | location = Providence, RI
 | mr = 1411692
 | pages = 171–311
 | publisher = American Mathematical Society
 | series = Contemporary Mathematics
 | title = Matroid theory (Seattle, WA, 1995)
 | volume = 197
 | year = 1996}}.&lt;/ref&gt;

==Definition==
A ''framework'' is an [[undirected graph]], embedded into ''d''-dimensional Euclidean space by providing a ''d''-tuple of [[Cartesian coordinate]]s for each vertex of the graph. From a framework with ''n'' vertices and ''m'' edges, one can define a matrix with ''m'' rows and ''nd'' columns, an expanded version of the [[incidence matrix]] of the graph called the ''rigidity matrix''. In this matrix, the entry in row ''e'' and column (''v'',''i'') is zero if ''v'' is not an endpoint of edge ''e''. If, on the other hand, edge ''e'' has vertices ''u'' and ''v'' as endpoints, then the value of the entry is the difference between the ''i''th coordinates of ''v'' and ''u''.&lt;ref name="graver"/&gt;&lt;ref name="whiteley"/&gt;

The rigidity matroid of the given framework is a [[linear matroid]] that has as its elements the edges of the graph. A set of edges is independent, in the matroid, if it corresponds to a set of rows of the rigidity matrix that is [[linear independence|linearly independent]]. A framework is called ''generic'' if the coordinates of its vertices are [[algebraic independence|algebraically independent]] real numbers. Any two generic frameworks on the same graph ''G'' determine the same rigidity matroid, regardless of their specific coordinates. This is the (''d''-dimensional) rigidity matroid of ''G''.&lt;ref name="graver"/&gt;&lt;ref name="whiteley"/&gt;

==Statics==
A ''load'' on a framework is a system of forces on the vertices (represented as vectors). A ''stress'' is a special case of a load, in which equal and opposite forces are applied to the two endpoints of each edge (which may be imagined as a spring) and the forces formed in this way are added at each vertex. Every stress is an ''equilibrium load'', a load that does not impose any translational force on the whole system (the sum of its force vectors is zero) nor any rotational force. A linear dependence among the rows of the rigidity matrix may be represented as a ''self-stress'', an assignment of equal and opposite forces to the endpoints of each edge that is not identically zero but that adds to zero at every vertex. Thus, a set of edges forms an independent set in the rigidity matroid if and only if it has no self-stress.&lt;ref name="whiteley"/&gt;

The vector space of all possible loads, on a system of ''n'' vertices, has dimension ''dn'', among which the equilibrium loads form a subspace of dimension
&lt;math&gt;dn-\binom{d+1}{2}&lt;/math&gt;. An independent set in the rigidity matroid has a system of equilibrium loads whose dimension equals the cardinality of the set, so the maximum rank that any set in the matroid can have is &lt;math&gt;dn-\binom{d+1}{2}&lt;/math&gt;. If a set has this rank, it follows that its set of stresses is the same as the space of equilibrium loads. Alternatively and equivalently, in this case every equilibrium load on the framework may be ''resolved'' by a stress that generates an equal and opposite set of forces, and the framework is said to be statically rigid.&lt;ref name="whiteley"/&gt;

==Kinematics==
If the vertices of a framework are in a motion, then that motion may be described over small scales of distance by its [[gradient]], a vector for each vertex specifying its speed and direction. The gradient describes a linearized approximation to the actual motion of the points, in which each point moves at constant velocity in a straight line. The gradient may be described as a row vector that has one real number coordinate for each pair &lt;math&gt;(v,i)&lt;/math&gt; where &lt;math&gt;v&lt;/math&gt; is a vertex of the framework and &lt;math&gt;i&lt;/math&gt; is the index of one of the Cartesian coordinates of &lt;math&gt;d&lt;/math&gt;-dimensional space; that is, the dimension of the gradient is the same as the width of the rigidity matrix.&lt;ref name="graver"/&gt;&lt;ref name="whiteley"/&gt;

If the edges of the framework are assumed to be rigid bars that can neither expand nor contract (but can freely rotate) then any motion respecting this rigidity must preserve the lengths of the edges: the derivative of length, as a function of the time over which the motion occurs, must remain zero. This condition may be expressed in linear algebra as a constraint that the gradient vector of the motion of the vertices must have zero [[inner product]] with the row of the rigidity matrix that represents the given edge. Thus, the family of gradients of (infinitesimally) rigid motions is given by the [[nullspace]] of the rigidity matrix.&lt;ref name="graver"/&gt;&lt;ref name="whiteley"/&gt; For frameworks that are not in generic position, it is possible that some infinitesimally rigid motions (vectors in the nullspace of the rigidity matrix) are not the gradients of any continuous motion, but this cannot happen for generic frameworks.&lt;ref name="w92"/&gt;

A rigid motion of the framework is a motion such that, at each point in time, the framework is [[congruence (geometry)|congruent]] to its original configuration. Rigid motions include translations and rotations of Euclidean space; the gradients of rigid motions form a linear space having the translations and rotations as bases, of dimension &lt;math&gt;\binom{d+1}{2}&lt;/math&gt;, which must always be a subspace of the nullspace of the rigidity matrix.
Because the nullspace always has at least this dimension, the rigidity matroid can have rank at most &lt;math&gt;dn-\binom{d+1}{2}&lt;/math&gt;, and when it does have this rank the only motions that preserve the lengths of the edges of the framework are the rigid motions. In this case the framework is said to be first-order (or infinitesimally) rigid.&lt;ref name="graver"/&gt;&lt;ref name="whiteley"/&gt; More generally, an edge &lt;math&gt;e&lt;/math&gt; belongs to the matroid closure operation of a set &lt;math&gt;S&lt;/math&gt; if and only if there does not exist a continuous motion of the framework that changes the length of &lt;math&gt;e&lt;/math&gt; but leaves the lengths of the edges in &lt;math&gt;S&lt;/math&gt; unchanged.&lt;ref name="graver"/&gt;

Although defined in different terms (column vectors versus row vectors, or forces versus motions) static rigidity and first-order rigidity reduce to the same properties of the underlying matrix and therefore coincide with each other. In two dimensions, the generic rigidity matroid also describes the number of degrees of freedom of a different kind of motion, in which each edge is constrained to stay parallel to its original position rather than being constrained to maintain the same length; however, the equivalence between rigidity and parallel motion breaks down in higher dimensions.&lt;ref name="whiteley"/&gt;

==Unique realization==
[[File:Diamond graph.svg|thumb|The [[diamond graph]], generically rigid but not uniquely realizable]]
A framework has a ''unique realization'' in ''d''-dimensional space if every placement of the same graph with the same edge lengths is congruent to it. Such a framework must necessarily be rigid, because otherwise there exists a continuous motion bringing it to a non-congruent placement with the same edge lengths, but unique realizability is stronger than rigidity. For instance, the [[diamond graph]] (two triangles sharing an edge) is rigid in two dimensions, but it is not uniquely realizable because it has two different realizations, one in which the triangles are on opposite sides of the shared edge and one in which they are both on the same side. Uniquely realizable graphs are important in applications that involve reconstruction of shapes from distances, such as [[triangulation]] in land surveying,&lt;ref name="molecule"&gt;{{citation
 | last = Hendrickson | first = Bruce
 | doi = 10.1137/0805040
 | issue = 4
 | journal = SIAM Journal on Optimization
 | mr = 1358807
 | pages = 835–857
 | title = The molecule problem: exploiting structure in global optimization
 | volume = 5
 | year = 1995| citeseerx = 10.1.1.55.2335
 }}.&lt;/ref&gt; the determination of the positions of the nodes in a [[wireless sensor network]],&lt;ref&gt;{{citation
 | last1 = Eren | first1 = T.
 | last2 = Goldenberg | first2 = O.K.
 | last3 = Whiteley | first3 = W.
 | last4 = Yang | first4 = Y.R.
 | last5 = Morse | first5 = A.S.
 | last6 = Anderson | first6 = B.D.O.
 | last7 = Belhumeur | first7 = P.N.
 | contribution = Rigidity, computation, and randomization in network localization
 | doi = 10.1109/INFCOM.2004.1354686
 | pages = 2673–2684
 | title = Proc. Twenty-third Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM 2004)
 | volume = 4
 | year = 2004}}.&lt;/ref&gt; and the reconstruction of conformations of molecules via [[nuclear magnetic resonance spectroscopy]].&lt;ref name="molecule"/&gt;

Bruce Hendrickson defined a graph to be ''redundantly rigid'' if it remains rigid after removing any one of its edges. In matroidal terms, this means that the rigidity matroid has the full rank &lt;math&gt;dn-\binom{d+1}{2}&lt;/math&gt; and that the matroid does not have any coloops. Hendrickson
proved that every uniquely realizable framework (with generic edge lengths) is either a [[complete graph]] or a &lt;math&gt;(d+1)&lt;/math&gt;-[[k-vertex-connected graph|vertex-connected]], redundantly rigid graph, and he conjectured that this is an exact characterization of the uniquely realizable frameworks.&lt;ref&gt;{{citation
 | last = Hendrickson | first = Bruce
 | doi = 10.1137/0221008
 | issue = 1
 | journal = SIAM Journal on Computing
 | mr = 1148818
 | pages = 65–84
 | title = Conditions for unique graph realizations
 | volume = 21
 | year = 1992}}.&lt;/ref&gt; The conjecture is true for one and two dimensions; in the one-dimensional case, for instance, a graph is uniquely realizable if and only if it is connected and [[Bridge (graph theory)|bridgeless]].&lt;ref&gt;{{citation
 | last1 = Jackson | first1 = Bill
 | last2 = Jordán | first2 = Tibor
 | doi = 10.1016/j.jctb.2004.11.002
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2130278
 | pages = 1–29
 | series = Series B
 | title = Connected rigidity matroids and unique realizations of graphs
 | volume = 94
 | year = 2005}}.&lt;/ref&gt; However, Henrickson's conjecture is false for three or more dimensions.&lt;ref&gt;{{citation
 | last = Connelly | first = Robert | authorlink = Robert Connelly
 | contribution = On generic global rigidity
 | location = Providence, RI
 | mr = 1116345
 | pages = 147–155
 | publisher = American Mathematical Society
 | series = DIMACS Series on Discrete Mathematics and Theoretical Computer Science
 | title = Applied Geometry and Discrete Mathematics
 | volume = 4
 | year = 1991}}.&lt;/ref&gt; For frameworks that are not generic, it is NP-hard to determine whether a given framework is uniquely realizable.&lt;ref&gt;{{citation
 | last = Saxe | first = J. B. | authorlink = James B. Saxe
 | location = Pittsburgh, PA
 | publisher = Computer Science Department, Carnegie-Mellon University
 | series = Technical Report
 | title = Embeddability of weighted graphs in ''k''-space is strongly NP-hard
 | year = 1979}}. As cited by {{harvtxt|Jackson|Jordán|2005}}.&lt;/ref&gt;

==Relation to sparsity==
{{harvtxt|Streinu|Theran|2009}} define a graph as being &lt;math&gt;(k,l)&lt;/math&gt;-sparse if every nonempty subgraph with &lt;math&gt;n&lt;/math&gt; vertices has at most &lt;math&gt;kn-l&lt;/math&gt; edges, and &lt;math&gt;(k,l)&lt;/math&gt;-tight if it is &lt;math&gt;(k,l)&lt;/math&gt;-sparse and has exactly &lt;math&gt;kn-l&lt;/math&gt; edges.&lt;ref&gt;{{citation
 | last1 = Streinu | first1 = I. | author1-link = Ileana Streinu
 | last2 = Theran | first2 = L.
 | arxiv = math/0703921
 | doi = 10.1016/j.ejc.2008.12.018
 | issue = 8
 | journal = [[European Journal of Combinatorics]]
 | pages = 1944–1964
 | title = Sparse hypergraphs and pebble game algorithms
 | volume = 30
 | year = 2009}}.&lt;/ref&gt; From the consideration of loads and stresses it can be seen that a set of edges that is independent in the rigidity matroid forms a &lt;math&gt;(d,\binom{d+1}{2})&lt;/math&gt;-sparse graph, for if not there would exist a subgraph whose number of edges would exceed the dimension of its space of equilibrium loads, from which it follows that it would have a self-stress.
By similar reasoning, a set of edges that is both independent and rigid forms a &lt;math&gt;(d,\binom{d+1}{2})&lt;/math&gt;-tight graph. For instance, in one dimension, the independent sets form the edge sets of forests, (1,1)-sparse graphs, and the independent rigid sets form the edge sets of trees, (1,1)-tight graphs. In this case the rigidity matroid of a framework is the same as the [[graphic matroid]] of the corresponding graph.&lt;ref name="w92"/&gt;

In two dimensions, {{harvtxt|Laman|1970}} showed that the same characterization is true: the independent sets form the edge sets of (2,3)-sparse graphs and the independent rigid sets form the edge sets of (2,3)-tight graphs.&lt;ref&gt;{{citation
 | last = Laman | first = G. | authorlink = Gerard Laman
 | doi = 10.1007/BF01534980
 | issue = 4
 | journal = J. Engineering Mathematics
 | mr = 0269535
 | pages = 331–340
 | title = On graphs and the rigidity of plane skeletal structures
 | volume = 4
 | year = 1970| bibcode = 1970JEnMa...4..331L}}.&lt;/ref&gt; Based on this work the (2,3)-tight graphs (the graphs of minimally rigid generic frameworks in two dimensions) have come to be known as [[Laman graph]]s. The family of Laman graphs on a fixed set of &lt;math&gt;n&lt;/math&gt; vertices forms the set of bases of the rigidity matroid of a [[complete graph]], and more generally for every graph &lt;math&gt;G&lt;/math&gt; that forms a rigid framework in two dimensions, the spanning Laman subgraphs of &lt;math&gt;G&lt;/math&gt; are the bases of the rigidity matroid of &lt;math&gt;G&lt;/math&gt;.

However, in higher dimensions not every &lt;math&gt;(d,\binom{d+1}{2})&lt;/math&gt;-tight graph is minimally rigid, and characterizing the minimally rigid graphs (the bases of the rigidity matroid of the complete graph) is an important open problem.&lt;ref&gt;{{citation
 | last1 = Jackson | first1 = Bill
 | last2 = Jordán | first2 = Tibor
 | doi = 10.1142/S0218195906002117
 | issue = 5-6
 | journal = International Journal of Computational Geometry &amp; Applications
 | mr = 2269396
 | pages = 415–429
 | title = On the rank function of the 3-dimensional rigidity matroid
 | url = http://web.cs.elte.hu/egres/tr/egres-05-09.pdf
 | volume = 16
 | year = 2006}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Mathematics of rigidity]]
[[Category:Matroid theory]]</text>
      <sha1>dejc12nqlheft45c0cwueh8ink9ojwn</sha1>
    </revision>
  </page>
  <page>
    <title>Saturation (graph theory)</title>
    <ns>0</ns>
    <id>2547402</id>
    <revision>
      <id>702638784</id>
      <parentid>702590347</parentid>
      <timestamp>2016-01-31T20:31:24Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>Fixing [[Wikipedia:Disambiguation pages with links|links to disambiguation pages]], replaced: [[Graph (mathematics)|graph]]{{dn|date=January 2016}} → [[Graph (discrete mathematics)|graph]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="668">Let &lt;math&gt;G(V,E)&lt;/math&gt; be a [[Graph (discrete mathematics)|graph]] and &lt;math&gt;M&lt;/math&gt; a [[Matching (graph theory)|matching]] in &lt;math&gt;G&lt;/math&gt;. A vertex &lt;math&gt;v\in V(G)&lt;/math&gt; is said to be '''saturated''' by &lt;math&gt;M&lt;/math&gt; if there is an edge in &lt;math&gt;M&lt;/math&gt; incident to &lt;math&gt;v&lt;/math&gt;. A vertex &lt;math&gt;v\in V(G)&lt;/math&gt; with no such edge is said to be '''unsaturated''' by &lt;math&gt;M&lt;/math&gt;. We also say that &lt;math&gt;M&lt;/math&gt; '''saturates''' &lt;math&gt;v&lt;/math&gt;.&lt;ref&gt;[http://planetmath.org/?op=getobj&amp;from=objects&amp;id=4735 Saturate]. [[PlanetMath]].&lt;/ref&gt;

==See also==
* [[Hall's marriage theorem]]
* [[Bipartite matching]]

==References==
{{reflist}}


[[Category:Matching]]</text>
      <sha1>6rj6h7mw76lt08a82mhknrcjioov1jt</sha1>
    </revision>
  </page>
  <page>
    <title>Self-dissimilarity</title>
    <ns>0</ns>
    <id>24824751</id>
    <revision>
      <id>754890153</id>
      <parentid>723876679</parentid>
      <timestamp>2016-12-15T01:59:15Z</timestamp>
      <contributor>
        <username>RJFJR</username>
        <id>141808</id>
      </contributor>
      <comment>remove {{multiple issues| {{notability|date=October 2010}} {{Context|date=January 2010}} }}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1440">
'''Self-dissimilarity''' is a measure of [[complexity]] defined in a series of papers by [[David Wolpert]] and [[William G. Macready]].&lt;ref&gt;{{cite book|title=International Conference on Complex Systems|year=2004|editor=Y. Bar-Yam|publisher=Perseus books, in press|chapter=Self-dissimilarity as a high dimensional complexity measure|first1=David H. |last1=Wolpert|first2=William|last2=Macready|url=http://ti.arc.nasa.gov/m/pub-archive/935h/0935%20(Wolpert).pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author1=Wolpert, D.H. |author2=Macready, W.G. |lastauthoramp=yes |chapter=Self-Dissimilarity: An Empirically Observable Measure of Complexity|title=Unifying Themes in Complex Systems|editor=Y. Bar-Yam|publisher=Perseus books|year=2000|url=http://ti.arc.nasa.gov/m/profile/dhw/papers/84.pdf}}&lt;/ref&gt;
The degrees of self-dissimilarity between the [[pattern recognition|patterns]] of a [[system theory|system]] observed at various [[scale factor|scale]]s (e.g. the average [[matter density]] of a physical body for [[volume]]s at different [[orders of magnitude]]) constitute a complexity "signature" of that system.

== See also ==
*[[Diversity index]]
*[[Index of dissimilarity]]
*[[Jensen–Shannon divergence]]
*[[Self-similarity]]
*[[Similarity measure]]
*[[Variance]]

== References ==
{{reflist}}

{{DEFAULTSORT:Self-Dissimilarity}}
[[Category:Information theory]]
[[Category:Complex systems theory]]
[[Category:Measures of complexity]]


{{math-stub}}</text>
      <sha1>4vdqgqnsikkxh5s2ahxbv2paj3i55mp</sha1>
    </revision>
  </page>
  <page>
    <title>Space-filling polyhedron</title>
    <ns>0</ns>
    <id>58607583</id>
    <revision>
      <id>871708276</id>
      <parentid>870627789</parentid>
      <timestamp>2018-12-02T23:01:06Z</timestamp>
      <contributor>
        <username>Katharineamy</username>
        <id>2590656</id>
      </contributor>
      <comment>added [[Category:Polyhedra]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="734">A '''space-filling polyhedron''' is a [[polyhedron]] that can be used to fill all of three-dimensional space via translations, rotations and/or reflections. Any periodic tiling or [[Honeycomb (geometry)|honeycomb]] of three-space can in fact be generated by translating a [[primitive cell]] polyhedron.

==References==
* [http://mathworld.wolfram.com/Space-FillingPolyhedron.html Space-Filling Polyhedron], MathWorld
* {{cite book |author1=Arthur L. Loeb |authorlink1=Arthur Lee Loeb |title=Space Structures |date=1991 |publisher=Birkhäuser |location=Boston, MA |isbn=978-1-4612-0437-4 |pages=127–132 |url=https://doi.org/10.1007/978-1-4612-0437-4_16 |chapter=Space-filling Polyhedra}}


{{geometry-stub}}



[[Category:Polyhedra]]</text>
      <sha1>5831codghwrwa8h2knyicafkkxhab10</sha1>
    </revision>
  </page>
  <page>
    <title>System U</title>
    <ns>0</ns>
    <id>49481270</id>
    <revision>
      <id>868096938</id>
      <parentid>767894888</parentid>
      <timestamp>2018-11-10T00:01:05Z</timestamp>
      <contributor>
        <ip>80.5.152.81</ip>
      </contributor>
      <comment>Fixed link (case-sensitive fragment)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5201">In [[mathematical logic]], '''System U''' and '''System U&lt;sup&gt;−&lt;/sup&gt;''' are [[pure type system]]s, i.e. special forms of a [[typed lambda calculus]] with an arbitrary number of [[Structure (mathematical logic)#Many-sorted_structures|sorts]], axioms and rules (or dependencies between the sorts). They were both proved inconsistent by [[Jean-Yves Girard]] in 1972.&lt;ref name=Girard1972&gt;{{cite paper |first=Jean-Yves |last=Girard |title=Interprétation fonctionnelle et Élimination des coupure de l'arithmétique d'ordre supérieur |year=1972 |url=https://www.cs.cmu.edu/~kw/scans/girard72thesis.pdf }}&lt;/ref&gt; This result led to the realization that [[Per Martin-Löf|Martin-Löf]]'s original [[intuitionistic type theory#Martin-Löf type theories|1971 type theory]] was inconsistent as it allowed the same "Type in Type" behaviour that Girard's paradox exploits.

== Formal definition ==
System U is defined&lt;ref name=SoerensenUrzyczyn2006&gt;{{cite book |first=Morten Heine |last=Sørensen |first2=Paweł |last2=Urzyczyn |title=Lectures on the Curry–Howard isomorphism |location= |publisher=Elsevier |year=2006 |isbn=0-444-52077-5 |chapter=Pure type systems and the lambda cube }}&lt;/ref&gt;{{rp|352}} as a pure type system with
* three [[Many-sorted logic|sorts]] &lt;math&gt;\{\ast, \square, \triangle\}&lt;/math&gt;;
* two axioms &lt;math&gt;\{\ast:\square, \square:\triangle\}&lt;/math&gt;; and
* five rules &lt;math&gt;\{(\ast,\ast), (\square,\ast), (\square,\square), (\triangle,\ast), (\triangle,\square)\}&lt;/math&gt;.

System U&lt;sup&gt;−&lt;/sup&gt; is defined the same with the exception of the &lt;math&gt;(\triangle, \ast)&lt;/math&gt; rule.

The sorts &lt;math&gt;\ast&lt;/math&gt; and &lt;math&gt;\square&lt;/math&gt; are conventionally called “Type” and “[[kind (type theory)|Kind]]”, respectively; the sort &lt;math&gt;\triangle&lt;/math&gt; doesn't have a specific name. The two axioms describe the containment of types in kinds (&lt;math&gt;\ast:\square&lt;/math&gt;) and kinds in &lt;math&gt;\triangle&lt;/math&gt; (&lt;math&gt;\square:\triangle&lt;/math&gt;). Intuitively, the sorts describe a hierarchy in the ''nature'' of the terms.
#   All values have a ''type'', such as a base type (''e.g.'' &lt;math&gt;b : \mathrm{Bool}&lt;/math&gt; is read as “{{math|''b''}} is a boolean”) or a (dependent) function type (''e.g.'' &lt;math&gt;f : \mathrm{Nat} \to \mathrm{Bool}&lt;/math&gt; is read as “{{math|''f''}} is a function from natural numbers to booleans”).
#   &lt;math&gt;\ast&lt;/math&gt; is the sort of all such types (&lt;math&gt;t : \ast&lt;/math&gt; is read as “{{math|''t''}} is a type”). From &lt;math&gt;\ast&lt;/math&gt; we can build more terms, such as &lt;math&gt;\ast \to \ast&lt;/math&gt; which is the ''kind'' of unary type-level operators (''e.g.'' &lt;math&gt;\mathrm{List} : \ast \to \ast&lt;/math&gt; is read as “{{math|List}} is a function from types to types”, that is, a polymorphic type). The rules restrict how we can form new kinds.
#   &lt;math&gt;\square&lt;/math&gt; is the sort of all such kinds (&lt;math&gt;k : \square&lt;/math&gt; is read as “{{math|''k''}} is a kind”). Similarly we can build related terms, according to what the rules allow.
#   &lt;math&gt;\triangle&lt;/math&gt; is the sort of all such terms.

The rules govern the dependencies between the sorts: &lt;math&gt;(\ast,\ast)&lt;/math&gt; says that values may depend on values ([[first-class function|functions]]), &lt;math&gt;(\square,\ast)&lt;/math&gt; allows values to depend on types ([[parametric polymorphism|polymorphism]]), &lt;math&gt;(\square,\square)&lt;/math&gt; allows types to depend on types ([[type constructor|type operators]]), and so on.

== Girard's paradox&lt;!--'Girard's paradox' redirects here--&gt; ==
The definitions of System U and U&lt;sup&gt;−&lt;/sup&gt; allow the assignment of [[parametric polymorphism|polymorphic]] [[kind (type theory)|kind]]s to ''generic constructors'' in analogy to polymorphic types of terms in classical polymorphic lambda calculi, such as [[System F]]. An example of such a generic constructor might be{{r|SoerensenUrzyczyn2006|page=353}} (where ''k'' denotes a kind variable)

:&lt;math&gt;\lambda k^\square \lambda\alpha^{k \to k} \lambda\beta^k\!. \alpha (\alpha \beta) \;:\; \Pi k : \square((k \to k) \to k \to k)&lt;/math&gt;.

This mechanism is sufficient to construct a term with the type &lt;math&gt;(\forall p:\ast, p) = \bot&lt;/math&gt;, which implies that every type is [[type inhabitation|inhabited]]. By the [[Curry–Howard correspondence]], this is equivalent to all logical propositions being provable, which makes the system inconsistent.

'''Girard's paradox'''&lt;!--boldface per WP:R#PLA--&gt; is the [[type theory|type-theoretic]] analogue of [[Russell's paradox]] in [[naive set theory|set theory]].

== References ==
{{reflist}}

== Further reading ==
* {{cite book |editors=S. Abramsky, D. Gabbay and T. Maibaum |first=Henk |last=Barendregt |authorlink=Henk Barendregt |chapter=Lambda calculi with types |title=Handbook of Logic in Computer Science |pages=117–309 |publisher=[[Oxford University Press|Oxford Science Publications]] |year=1992 |chapterurl=ftp://ftp.cs.ru.nl/pub/CompMath.Found/HBK.ps }}
* {{cite book |first=Thierry |last=Coquand |authorlink=Thierry Coquand |chapter=An analysis of Girard's paradox |title=Logic in Computer Science |pages=227–236 |publisher=[[IEEE Computer Society]] Press |year=1986 }}

[[Category:Lambda calculus]]
[[Category:Proof theory]]
[[Category:Type theory]]</text>
      <sha1>8pxjsu07e7eywfblfdjiagt9v02jrnl</sha1>
    </revision>
  </page>
  <page>
    <title>Systems of Logic Based on Ordinals</title>
    <ns>0</ns>
    <id>32122937</id>
    <revision>
      <id>869166640</id>
      <parentid>842308485</parentid>
      <timestamp>2018-11-16T20:54:22Z</timestamp>
      <contributor>
        <ip>2A02:C7F:8E85:7600:CC27:7E27:164E:297E</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3204">{{DISPLAYTITLE:''Systems of Logic Based on Ordinals''}}
'''''Systems of Logic Based on Ordinals''''' was the PhD dissertation of the [[mathematician]] [[Alan Turing]].&lt;ref name="turingphd"&gt;{{TuringPhD}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Turing | first1 = A. M. | authorlink = Alan Turing| title = Systems of Logic Based on Ordinals | doi = 10.1112/plms/s2-45.1.161 | journal = Proceedings of the London Mathematical Society | pages = 161–228 | year = 1939 | pmid =  | pmc = }}&lt;/ref&gt;

Turing’s thesis is not about a new type of formal logic, nor was he interested in so-called ‘ranked logic’ systems derived from ordinal or relative numbering, in which comparisons can be made between truth-states on the basis of relative veracity. Instead, Turing investigated the possibility of resolving the Godelian incompleteness condition using Cantor’s method of infinites. This condition can be stated thus- in all systems with finite sets of axioms, an exclusive-or condition applies to expressive power and provability; ie one can have power and no proof, or proof and no power, but not both.

The thesis is an exploration of formal mathematical systems after [[Gödel's incompleteness theorems|Gödel's theorem]].  Gödel showed for that any formal system S powerful enough to represent arithmetic, there is a theorem G which is true but the system is unable to prove.  G could be added as an additional axiom to the system in place of a proof.  However this would create a new system S' with its own unprovable true theorem G', and so on.  Turing's thesis considers iterating the process to infinity, creating a system with an infinite set of axioms.

The thesis was completed at Princeton under [[Alonzo Church]] and was a classic work in mathematics which introduced the concept of [[ordinal logic]].&lt;ref&gt;Solomon Feferman, ''Turing in the Land of O(z)'' in "The universal Turing machine: a half-century survey" by Rolf Herken 1995 {{isbn|3-211-82637-8}} page 111&lt;/ref&gt; 

[[Martin Davis]] states that although Turing's use of a [[Oracle machine|computing oracle]] is not a major focus of the dissertation, it has proven to be highly influential in [[theoretical computer science]], e.g. in the [[polynomial time hierarchy]].&lt;ref&gt;[[Martin Davis]] "Computability, Computation and the Real World", in ''Imagination and Rigor'' edited by Settimo Termini 2006 {{isbn|88-470-0320-2}} pages 63-66 [https://books.google.com/books?id=K3xBKR2HiT8C&amp;pg=PA65&amp;dq=oracle+hypercomputation+copeland&amp;hl=en&amp;sa=X&amp;ei=CNWeT6ShF4LrOY3IgPsB&amp;redir_esc=y#v=onepage&amp;q=oracle%20hypercomputation%20copeland&amp;f=false]&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* {{cite web | url=http://www.princeton.edu/turing/alan/dissertation/ | title=Turing's Princeton Dissertation | publisher=Princeton University Press | accessdate=January 10, 2012}} 
* {{cite | url=http://math.stanford.edu/~feferman/papers/turingnotices.pdf | title=Turing's Thesis
 | author = Solomon Feferman | journal = Notices of the AMS | volume=53 | issue=10 | date = November 2006 }}

[[Category:History of logic]]
[[Category:Systems of formal logic]]
[[Category:Alan Turing]]
[[Category:Ordinal numbers]]

{{mathlogic-stub}}
{{mathematics-lit-stub}}</text>
      <sha1>e5wu7pfn3ysc6y9sb582c4dt72p1m9r</sha1>
    </revision>
  </page>
  <page>
    <title>The Princeton Companion to Mathematics</title>
    <ns>0</ns>
    <id>20240388</id>
    <revision>
      <id>865959384</id>
      <parentid>841492692</parentid>
      <timestamp>2018-10-27T09:08:45Z</timestamp>
      <contributor>
        <username>Pirhayati</username>
        <id>16750284</id>
      </contributor>
      <comment>added [[Category:Edited volumes]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10723">{{Italic title}}
'''''The Princeton Companion to Mathematics''''' is a book, edited by [[Timothy Gowers]] with associate editors June Barrow-Green and [[Imre Leader]], and published in 2008 by [[Princeton University Press]] ({{ISBN|978-0-691-11880-2}}). It provides an extensive overview of [[mathematics]], and is noted for the high caliber of the contributors. The book was a 2011 winner of the [[Euler Book Prize]] of the [[Mathematical Association of America]], given annually to "an outstanding book about mathematics".&lt;ref name="euler"/&gt;&lt;ref name="times"&gt;{{citation|journal=[[The Times]]|first=Ian|last=Stewart|authorlink=Ian Stewart (mathematician)|title=The Princeton Companion to Mathematics and The Numerati: How They'll Get My Number and Yours|date=November 21, 2008|url=http://entertainment.timesonline.co.uk/tol/arts_and_entertainment/books/non-fiction/article5205503.ece}}.&lt;/ref&gt;&lt;ref name="scinews"&gt;{{citation|journal=[[Science News]]|first=Tom|last=Siegfried|title=Book Review: The Princeton Companion to Mathematics, Timothy Gowers, ed|date=November 7, 2008|url=http://www.sciencenews.org/view/generic/id/38362/title/Book_Review__Book_Review_The_Princeton_Companion_to_Mathematics,_Timothy_Gowers,_ed_}}.&lt;/ref&gt;&lt;ref name="sigact"&gt;{{citation|journal=[[ACM SIGACT|ACM SIGACT News]]|title=Review of The Princeton Companion to Mathematics|volume=41|issue=1|year=2010|pages=31–33|url=http://www.cs.umd.edu/~gasarch/bookrev/41-1.pdf|first=Haris|last=Aziz|doi=10.1145/1753171.1753183}}.&lt;/ref&gt;&lt;ref name="hist"&gt;{{citation|journal=[[Historia Mathematica]]|volume=37|issue=1|year=2010|pages=110–112|doi=10.1016/j.hm.2009.08.001|title=Book Review: The Princeton Companion to Mathematics|first=Craig G.|last=Fraser}}.&lt;/ref&gt;&lt;ref name="nams"&gt;{{citation|last1=Birch|first1=Bryan|author1-link=Bryan John Birch|last2=Donaldson|first2=Simon|author2-link=Simon Donaldson|last3=Kalai|first3=Gil|author3-link=Gil Kalai|last4=Kenyon|first4=Richard|last5=Macintyre|first5=Angus|author5-link=Angus Macintyre|title=The Princeton companion to mathematics|journal=[[Notices of the American Mathematical Society]]|volume=56|year=2009|issue=10|pages=1276–1281|mr=2572756|url=http://www.ams.org/notices/200910/rtx091001276p.pdf}}.&lt;/ref&gt;&lt;ref name="siam"&gt;{{citation|mr=2573944|last=Borwein|first=Jonathan M.|authorlink=Jonathan Borwein|title=The Princeton companion to mathematics|journal=[[SIAM Review]]|volume=51|year=2009|issue=4|pages=790–794|url=http://docserver.carma.newcastle.edu.au/id/eprint/392}}.&lt;/ref&gt;&lt;ref name="bsl"&gt;{{citation|mr=2723560|last=Kennedy|first=Juliette|title=The Princeton companion to mathematics|journal=[[Bulletin of Symbolic Logic]]|volume=15|year=2009|issue=4|pages=431–436|url=http://www.math.ucla.edu/~asl/bsl/1504/1504-003.ps|doi=10.1017/S1079898600008374}}.&lt;/ref&gt;&lt;ref name="mr"&gt;{{citation|first=Terence|last=Tao|authorlink=Terence Tao|mr=2467561|title=The Princeton companion to mathematics|journal=[[Mathematical Reviews]]|year=2009}}.&lt;/ref&gt;&lt;ref name="lms"&gt;{{citation|journal=[[London Mathematical Society|London Mathematical Society Newsletter]]|url=http://old.lms.ac.uk/newsletter/378/378_10.html|first=Robin|last=Wilson|authorlink=Robin Wilson (mathematician)|title=The Princeton Companion to Mathematics|volume=378|year=2009}}.&lt;/ref&gt;

==Topics and organization==
The book concentrates primarily on modern [[pure mathematics]] rather than [[applied mathematics]], although it does also cover both applications of mathematics and the mathematics that relates to those applications;
it provides a broad overview of the significant ideas and developments in research mathematics.&lt;ref name="times"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="siam"/&gt; It is organized into eight parts:&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;&lt;ref name="nams"/&gt;&lt;ref name="siam"/&gt;&lt;ref name="lms"/&gt;
*An introduction to mathematics, outlining the major areas of study, key definitions, and the goals and purposes of mathematical research.&lt;ref name="times"/&gt;&lt;ref name="sigact"/&gt;
*An overview of the history of mathematics, in seven chapters including the development of important concepts such as number, geometry, mathematical proof, and the axiomatic approach to the foundations of mathematics.&lt;ref name="scinews"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;&lt;ref name="siam"/&gt; A chronology of significant events in mathematical history is also provided later in the book.&lt;ref name="hist"/&gt;
*Three core sections, totalling approximately 600 pages. The first of these sections provides an alphabetized set of articles on 99 specific mathematical concepts such as the [[axiom of choice]], [[expander graph]]s, and [[Hilbert space]]. The second core section includes long surveys of 26 branches of research mathematics such as [[algebraic geometry]] and [[combinatorial group theory]]. The third describes 38 important mathematical problems and theorems such as the [[four color theorem]], the [[Birch and Swinnerton-Dyer conjecture]], and the [[Halting problem]].&lt;ref name="times"/&gt;&lt;ref name="scinews"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;&lt;ref name="nams"/&gt;&lt;ref name="mr"/&gt;
*A collection of biographies of nearly 100 famous deceased mathematicians, arranged chronologically,&lt;ref name="times"/&gt;&lt;ref name="scinews"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;&lt;ref name="siam"/&gt;&lt;ref name="mr"/&gt; also including a history of [[Nicolas Bourbaki]]'s pseudonymous collaboration.&lt;ref name="nams"/&gt;&lt;ref name="mr"/&gt;
*Essays describing the influences and applications of mathematics in the sciences, technology, business, medicine, and the fine arts.&lt;ref name="times"/&gt;&lt;ref name="scinews"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;
*A section of perspectives on the future of mathematics, problem solving techniques, the ubiquity of mathematics, and advice to young mathematicians.&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;
Despite its length, the range of topics included is selective rather than comprehensive: some important established topics such as [[diophantine approximation]] are omitted, [[transcendental number theory]], [[differential geometry]], and [[cohomology]] get short shrift, and the most recent frontiers of research are also generally not included.&lt;ref name="nams"/&gt;

==Target audience==
The book's authors have attempted to keep their work accessible by forgoing abstraction and technical nomenclature as much as possible and by making heavy use of concrete examples and illustrations.&lt;ref name="times"/&gt; Compared to the concise and factual coverage of mathematics in sources such as [[Wikipedia]] and [[MathWorld]], the articles in the ''Princeton Companion'' are intended to be more reflective and discursive,&lt;ref name="hist"/&gt; and to convey the beauty and depth of modern mathematics.&lt;ref name="bsl"/&gt; Quoting a passage from [[Bertrand Russell]] that "Pure Mathematics is the class of all propositions of the form ''p'' implies ''q''", the editor of the ''Companion'' states that it "is about everything that Russell’s definition leaves out."&lt;ref name="siam"/&gt;&lt;ref name="bsl"/&gt;

The core sections of the ''Companion'' are aimed primarily at readers who are already familiar with mathematics at the undergraduate level.&lt;ref name="times"/&gt;&lt;ref name="hist"/&gt; Much of the rest of the book, such as its collection of biographies, would be accessible to a mathematically inclined high school student,&lt;ref name="times"/&gt;&lt;ref name="scinews"/&gt;&lt;ref name="nams"/&gt; and there is enough depth of coverage in the book to interest even professional research mathematicians.&lt;ref name="sigact"/&gt;&lt;ref name="nams"/&gt; Reviewer [[Jonathan Borwein]] summarizes the audience for this book broadly:&lt;ref name="siam"/&gt;&lt;ref&gt;In his review, [[Robin Wilson (mathematician)|Robin Wilson]] expresses very similar sentiments: "Once in a while a book comes along that should be on every mathematician’s bookshelf. This is such a book."&lt;/ref&gt;
{{cquote|Every research mathematician, every  university student of mathematics, and every serious amateur of mathematical science should own at least one copy of ''the Companion''.}}

==Contributors==
The contributors to ''The Princeton Companion to Mathematics'' consist of 133 of the world's best mathematicians.&lt;ref name="euler"/&gt;&lt;ref name="times"/&gt;&lt;ref name="mr"/&gt; Timothy Gowers, its editor, is the recipient of the [[Fields Medal]], considered to be the top honor in mathematics.&lt;ref name="times"/&gt;&lt;ref name="sigact"/&gt; Other contributors include Fields medalists [[Michael Atiyah]], [[Alain Connes]], [[Charles Fefferman]], and [[Terence Tao]], and well-known mathematicians [[Noga Alon]], [[George Andrews (mathematician)|George Andrews]], [[Béla Bollobás]], [[John P. Burgess]], [[Clifford Cocks]], [[Ingrid Daubechies]], [[Persi Diaconis]], [[Jordan Ellenberg]], [[Oded Goldreich]], [[Andrew Granville]], [[Jeremy Gray]], [[Frank Kelly (mathematician)|Frank Kelly]], [[Sergiu Klainerman]], [[Jon Kleinberg]], [[János Kollár]], [[Peter Lax]], [[Dusa McDuff]], [[Barry Mazur]], [[Carl Pomerance]], [[Eleanor Robson]], [[Peter Sarnak]], [[Madhu Sudan]], [[Clifford Taubes]], and [[Avi Wigderson]]. Among the historians who contributed to it are [[Charles Coulston Gillispie|Charles C. Gillispie]], [[Ivor Grattan-Guinness]], [[Jeremy Gray]], [[Niccolò Guicciardini]], [[:de:Ulf Hashagen|Ulf Hashagen]], [[Eberhard Knobloch]], [[Karen Hunger Parshall]], [[Eleanor Robson]], and [[:de:Erhard Scholz|Erhard Scholz]].&lt;ref name="euler"/&gt;&lt;ref name="sigact"/&gt;&lt;ref name="hist"/&gt;&lt;ref name="nams"/&gt;&lt;ref name="siam"/&gt;

==Awards==
Gowers and the ''Princeton Companion'' were the 2011 winners of the [[Euler Book Prize]] of the [[Mathematical Association of America]], given annually to "an outstanding book about mathematics".&lt;ref name="euler"&gt;[http://www.ams.org/profession/prize-booklet-2011.pdf January 2011 Prizes and Awards], [[American Mathematical Society]], retrieved 2011-02-01.&lt;/ref&gt;

The ''Princeton Companion'' was also listed as an outstanding title by ''[[Choice: Current Reviews for Academic Libraries|Choice Magazine]]'', a publication of the [[American Library Association]], in 2009.&lt;ref&gt;[http://www.cro2.org/default.aspx?page=reviewdisplay&amp;pid=3439943 Review by S. J. Colley], 2009, Choice Reviews Online, retrieved 2011-02-01.&lt;/ref&gt;

==References==
{{reflist|colwidth=30em}}

==See also==
* ''The Princeton Companion to Applied Mathematics'', published 2015 and edited by Nicholas Higham

==External links==
* [http://press.princeton.edu/titles/8350.html Book homepage] at Princeton University Press; contains several sample chapters
* [http://gowers.wordpress.com/category/princeton-companion-to-mathematics/ Princeton Companion To Mathematics category] in Gowers's blog

{{DEFAULTSORT:Princeton Companion to Mathematics}}
[[Category:Mathematics books]]
[[Category:2008 books]]
[[Category:Edited volumes]]</text>
      <sha1>4mfzfvfjrkkvbqojyprhis1ksme3uhq</sha1>
    </revision>
  </page>
  <page>
    <title>Uniform norm</title>
    <ns>0</ns>
    <id>349755</id>
    <revision>
      <id>849319083</id>
      <parentid>849261490</parentid>
      <timestamp>2018-07-08T05:04:51Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <comment>Undid revision 849261490 by [[Special:Contributions/2A01:119F:21E:4D00:E93E:7C2B:D141:DF31|2A01:119F:21E:4D00:E93E:7C2B:D141:DF31]] ([[User talk:2A01:119F:21E:4D00:E93E:7C2B:D141:DF31|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3751">{{About|the function space norm|the finite-dimensional vector space distance|Chebyshev distance|the uniformity norm in additive combinatorics|Gowers norm}}
{{Refimprove|date=December 2009}}
[[Image:Vector norm sup.svg|frame|right|The perimeter of the square is the set of points in '''R'''&lt;sup&gt;2&lt;/sup&gt; where the sup norm equals a fixed positive constant.]]

In [[mathematical analysis]], the '''uniform [[norm (mathematics)|norm]]''' (or '''sup norm''') assigns to [[real number|real-]] or [[complex number|complex]]-valued bounded functions ''f'' defined on a set ''S'' the non-negative number

:&lt;math&gt;\|f\|_\infty=\|f\|_{\infty,S}=\sup\left\{\,\left|f(x)\right|:x\in S\,\right\}.&lt;/math&gt;

This norm is also called the '''[[supremum]] norm,''' the '''Chebyshev norm,''' or the '''infinity norm.''' The name "uniform norm" derives from the fact that a sequence of functions &lt;math&gt;\{f_n\}&lt;/math&gt; converges to f under the metric derived from the uniform norm if and only if &lt;math&gt;f_n&lt;/math&gt; converges to &lt;math&gt;f&lt;/math&gt; [[uniform convergence|uniformly]].&lt;ref&gt;{{cite book|last=Rudin|first=Walter|title=Principles of Mathematical Analysis|year=1964|publisher=McGraw-Hill|location=New York|isbn=0-07-054235-X|pages=151}}&lt;/ref&gt;

If we allow unbounded functions, this formula does not yield a norm or [[metric (mathematics)|metric]] in a strict sense, although the obtained so-called [[metric (mathematics)#Generalized metrics|extended metric]] still allows one to define a topology on the function space in question.

If ''f'' is a [[continuous function]] on a [[closed interval]], or more generally a [[compact space|compact]] set, then it is bounded and the [[supremum]] in the above definition is attained by the Weierstrass [[extreme value theorem]], so we can replace the supremum by the maximum. In this case, the norm is also called the '''maximum norm'''.
In particular, for the case of a vector &lt;math&gt;x=(x_1,\dots,x_n)&lt;/math&gt; in [[finite set|finite]] [[dimension]]al [[coordinate space]], it takes the form

:&lt;math&gt;\|x\|_\infty=\max\{ |x_1|, \dots, |x_n| \}.&lt;/math&gt;&lt;!-- avoiding "\," should allow HTML display --&gt;

The reason for the subscript "∞" is that whenever ''f'' is continuous

:&lt;math&gt;\lim_{p\rightarrow\infty}\|f\|_p=\|f\|_\infty,&lt;/math&gt;

where

:&lt;math&gt;\|f\|_p=\left(\int_D \left|f\right|^p\,d\mu\right)^{1/p}&lt;/math&gt;

where ''D'' is the domain of ''f'' (and the integral amounts to a sum if ''D'' is a [[discrete set]]).

The binary function

:&lt;math&gt;d(f,g)=\|f-g\|_\infty&lt;/math&gt;

is then a [[metric (mathematics)|metric]] on the space of all bounded functions (and, obviously, any of its subsets) on a particular domain. A sequence { ''f''&lt;sub&gt;''n''&lt;/sub&gt; : ''n'' = 1, 2, 3, ... } [[uniform convergence|converges uniformly]] to a function ''f'' if and only if

:&lt;math&gt;\lim_{n\rightarrow\infty}\|f_n-f\|_\infty=0.\,&lt;/math&gt;

We can define closed sets and closures of sets with respect to this metric topology; closed sets in the uniform norm are sometimes called ''uniformly closed'' and closures ''uniform closures''. The uniform closure of a set of functions A is the space of all functions that can be approximated by a sequence of uniformly-converging functions on A. For instance, one restatement of the [[Stone–Weierstrass theorem]] is that the set of all continuous functions on &lt;math&gt;[a,b]&lt;/math&gt; is the uniform closure of the set of polynomials on &lt;math&gt;[a,b]&lt;/math&gt;.

For [[complex number|complex]] [[continuity (topology)|continuous]] functions over a [[compact space]], this turns it into a [[C-star algebra|C* algebra]].

==See also==
*[[Chebyshev distance]]
*[[Uniform continuity]]
*[[Uniform space]]

==References==

{{Reflist}}

{{DEFAULTSORT:Uniform Norm}}
[[Category:Functional analysis]]
[[Category:Norms (mathematics)]]</text>
      <sha1>5rkt980r87cshn20p78f8ygk03lb57j</sha1>
    </revision>
  </page>
  <page>
    <title>Weyl distance function</title>
    <ns>0</ns>
    <id>46578848</id>
    <revision>
      <id>663415822</id>
      <parentid>660441515</parentid>
      <timestamp>2015-05-21T15:19:23Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>/* Abstract characterization of buildings */Typo fixing, replaced: the the → the using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5815">In [[combinatorial geometry]], the '''Weyl distance function''' is a function that behaves in some ways like the [[distance function]] of a [[metric space]], but instead of taking values in the positive real numbers, it takes values in a [[group (mathematics)|group]] of [[reflection (mathematics)|reflections]], called the [[Weyl group]] (named for [[Hermann Weyl]]).  This distance function is defined on the collection of chambers in a mathematical structure known as a [[building (mathematics)|building]], and its value on a pair of chambers a minimal sequence of reflections (in the Weyl group) to go from one chamber to the other.  An adjacent sequence of chambers in a building is known as a gallery, so the Weyl distance function is a way of encoding the information of a minimal gallery between two chambers.  In particular, the number of reflections to go from one chamber to another coincides with the length of the minimal gallery between the two chambers, and so gives a natural metric (the gallery metric) on the building.  According to {{harvtxt|Abramenko|Brown|2008}}, the Weyl distance function is something like a [[geometric vector]]: it encodes both the magnitude (distance) between two chambers of a building, as well as the direction between them.

==Definitions==
We record here definitions from {{harvtxt|Abramenko|Brown|2008}}.  Let {{math|&amp;Sigma;(''W'',''S'')}} be the [[Coxeter complex]] associated to a group ''W'' generated by a set of reflections ''S''.  The vertices of {{math|&amp;Sigma;(''W'',''S'')}} are the elements of ''W'', and the chambers of the complex are the cosets of ''S'' in ''W''.  The vertices of each chamber can be ''colored'' in a one-to-one manner by the elements of ''S'' so that no adjacent vertices of the complex receive the same color.  This coloring, although essentially canonical, is not quite unique.  The coloring of a given chamber is not uniquely determined by its realization as a coset of ''S''.  But once the coloring of a single chamber has been fixed, the rest of the Coxeter complex is uniquely colorable.  Fix such a coloring of the complex.

A gallery is a sequence of adjacent chambers
:&lt;math&gt;C_0,C_1,\dots,C_n.&lt;/math&gt;
Because these chambers are adjacent, any consecutive pair &lt;math&gt;C_{i-1},C_i&lt;/math&gt; of chambers share all but one vertex.  Denote the color of this vertex by &lt;math&gt;s_i&lt;/math&gt;.  The Weyl distance function between &lt;math&gt;C_0&lt;/math&gt; and &lt;math&gt;C_n&lt;/math&gt; is defined by
:&lt;math&gt;\delta(C_0,C_n) = s_1s_2\cdots s_n.&lt;/math&gt;
It can be shown that this does not depend on the choice of gallery connecting &lt;math&gt;C_0&lt;/math&gt; and &lt;math&gt;C_n&lt;/math&gt;.

Now, a building is a simplicial complex that is organized into apartments, each of which is a Coxeter complex (satisfying some coherence axioms).  Buildings are colorable, since the Coxeter complexes that make them up are colorable.  A coloring of a building is associated with a uniform choice of Weyl group for the Coxeter complexes that make it up, allowing it to be regarded as a collection of words on the set of colors with relations.  Now, if &lt;math&gt;C_0,\dots,C_n&lt;/math&gt; is a gallery in a building, then define the Weyl distance between &lt;math&gt;C_0&lt;/math&gt; and &lt;math&gt;C_n&lt;/math&gt; by
:&lt;math&gt;\delta(C_0,C_n) = s_1s_2\cdots s_n&lt;/math&gt;
where the &lt;math&gt;s_i&lt;/math&gt; are as above.  As in the case of Coxeter complexes, this does not depend on the choice of gallery connecting the chambers &lt;math&gt;C_0&lt;/math&gt; and &lt;math&gt;C_n&lt;/math&gt;.

The gallery distance &lt;math&gt;d(C_0,C_n)&lt;/math&gt; is defined as the minimal word length needed to express &lt;math&gt;\delta(C_0,C_n)&lt;/math&gt; in the Weyl group.  Symbolically, &lt;math&gt;d(C_0,C_n)=\ell(\delta(C_0,C_n))&lt;/math&gt;.

==Properties==
The Weyl distance function satisfies several properties that parallel those of distance functions in metric spaces:
* &lt;math&gt;\delta(C,D) = 1&lt;/math&gt; if and only if &lt;math&gt;C=D&lt;/math&gt; (the group element 1 corresponds to the [[empty product|empty word]] on ''S'').  This corresponds to the property &lt;math&gt;d(C,D)=0&lt;/math&gt; if and only if &lt;math&gt;C=D&lt;/math&gt; of the gallery metric {{harv|Abramenko|Brown|2008|p=199}}:
* &lt;math&gt;\delta(C,D)=\delta(D,C)^{-1}&lt;/math&gt; (inversion corresponds to reversal of words in the alphabet ''S'').  This corresponds to symmetry &lt;math&gt;d(C,D)=d(D,C)&lt;/math&gt; of the gallery metric.
* If &lt;math&gt;\delta(C',C)=s\in S&lt;/math&gt; and &lt;math&gt;\delta(C,D)=w&lt;/math&gt;, then &lt;math&gt;\delta(C',D)&lt;/math&gt; is either ''w'' or ''sw''.  Moreover, if &lt;math&gt;\ell(sw)=\ell(w)+1&lt;/math&gt;, then &lt;math&gt;\delta(C',D)=sw&lt;/math&gt;.  This corresponds to the triangle inequality.

==Abstract characterization of buildings==
In addition to the properties listed above, the Weyl distance function satisfies the following property:
* If &lt;math&gt;\delta(C,D)=w&lt;/math&gt;, then for any &lt;math&gt;s\in S&lt;/math&gt; there is a chamber &lt;math&gt;C'&lt;/math&gt;, such that &lt;math&gt;\delta(C',C)=s&lt;/math&gt; and &lt;math&gt;\delta(C',D)=sw&lt;/math&gt;.

In fact, this property together with the two listed in the "Properties" section furnishes an abstract "metrical" characterization of buildings, as follows.  Suppose that (''W'',''S'') is a Coxeter system consisting of a Weyl group ''W'' generated by reflections belonging to the subset ''S''.  A building of type (''W'',''S'') is a pair consisting of a set ''C'' of ''chambers'' and a function:
:&lt;math&gt;\delta:C\times C\to W&lt;/math&gt;
such that the three properties listed above are satisfied.  Then ''C'' carries the canonical structure of a building, in which {{math|''&amp;delta;''}} is the Weyl distance function.

==References==
* {{citation|last1=Abramenko|first1=P.|last2=Brown|first2=K.|title=Buildings: Theory and applications|publisher=Springer|year=2008}}

==External links==
* Mike Davis, [http://www.math.cornell.edu/~vogtmann/MSRI/MDavis.pdf Cohomology of Coxeter groups and buildings], MSRI 2007.

[[Category:Geometric group theory]]
[[Category:Metric geometry]]</text>
      <sha1>sk3dgs8k1vgdsz5bxmxagkg13ps7jbe</sha1>
    </revision>
  </page>
  <page>
    <title>Ω-consistent theory</title>
    <ns>0</ns>
    <id>4066001</id>
    <revision>
      <id>799603635</id>
      <parentid>797626902</parentid>
      <timestamp>2017-09-08T18:38:30Z</timestamp>
      <contributor>
        <username>RJGray</username>
        <id>8268674</id>
      </contributor>
      <comment>/* ω-logic */ link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12504">{{lowercase|ω-consistent theory}}
In [[mathematical logic]], an '''ω-consistent''' (or '''omega-consistent''', also called '''numerically segregative''')&lt;ref name="quine"&gt;[[W.V.O. Quine]] (1971), ''Set Theory and its Logic''.&lt;/ref&gt; '''theory''' is a [[theory (mathematical logic)|theory]] (collection of [[sentence (mathematical logic)|sentences]]) that is not only (syntactically) [[Theory (mathematical logic)#Consistency and completeness|consistent]] (that is, does not prove a [[contradiction]]), but also avoids proving certain infinite combinations of sentences that are intuitively contradictory. The name is due to [[Kurt Gödel]], who introduced the concept in the course of proving the [[Gödel's incompleteness theorems|incompleteness theorem]].&lt;ref&gt;Smorynski, "The incompleteness theorems", ''Handbook of Mathematical Logic'', 1977, p.&amp;nbsp;851.&lt;/ref&gt;

== Definition ==

A theory ''T'' is said to [[Interpretability|interpret]] the language of arithmetic if there is a translation of formulas of arithmetic into the language of ''T'' so that ''T'' is able to prove the basic axioms of the natural numbers under this translation.

A ''T'' that interprets arithmetic is '''ω-inconsistent''' if, for some property ''P'' of natural numbers (defined by a formula in the language of ''T''), ''T'' proves ''P''(0), ''P''(1), ''P''(2), and so on (that is, for every standard natural number ''n'', ''T'' proves that ''P''(''n'') holds), but ''T'' also proves that there is some natural number ''n'' (necessarily nonstandard) such that ''P''(''n'') ''fails''. This may not generate a contradiction within ''T'' because ''T'' may not be able to prove for any ''specific'' value of ''n'' that ''P''(''n'') fails, only that there ''is'' such an ''n''.

''T'' is '''ω-consistent''' if it is ''not'' ω-inconsistent.

There is a weaker but closely related property of Σ&lt;sub&gt;1&lt;/sub&gt;-soundness. A theory ''T'' is '''Σ&lt;sub&gt;1&lt;/sub&gt;-sound''' (or '''1-consistent''', in another terminology) if every Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left: -0.5em"&gt;1&lt;/sub&gt;-sentence&lt;ref&gt;The definition of this symbolism can be found at [[arithmetical hierarchy]].&lt;/ref&gt; provable in ''T'' is true in the standard model of arithmetic '''N''' (i.e., the structure of the usual natural numbers with addition and multiplication).
If ''T'' is strong enough to formalize a reasonable model of [[theory of computation|computation]], Σ&lt;sub&gt;1&lt;/sub&gt;-soundness is equivalent to demanding that whenever ''T'' proves that a computer program{{huh|where do now a comp and its programme come from?|date=July 2017}} ''C'' halts, then ''C'' actually halts. Every ω-consistent theory is Σ&lt;sub&gt;1&lt;/sub&gt;-sound, but not vice versa.

More generally, we can define an analogous concept for higher levels of the [[arithmetical hierarchy]]. If Γ is a set of arithmetical sentences (typically Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left: -0.5em"&gt;''n''&lt;/sub&gt; for some ''n''), a theory ''T'' is '''Γ-sound''' if every Γ-sentence provable in ''T'' is true in the standard model. When Γ is the set of all arithmetical formulas, Γ-soundness is called just (arithmetical) soundness.
If the language of ''T'' consists ''only'' of the language of arithmetic (as opposed to, for example, set theory), then a sound system is one whose model can be thought of as the set ω, the usual set of mathematical natural numbers. The case of general ''T'' is different, see [[#ω-logic|ω-logic]] below.

Σ&lt;sub&gt;''n''&lt;/sub&gt;-soundness has the following computational interpretation: if the theory proves that a program ''C'' using a Σ&lt;sub&gt;''n''−1&lt;/sub&gt;-[[oracle machine|oracle]] halts, then ''C'' actually halts.

== Examples ==

=== Consistent, &amp;omega;-inconsistent theories ===
Write PA for the theory [[Peano axioms|Peano arithmetic]], and Con(PA) for the statement of arithmetic that formalizes the claim "PA is consistent". Con(PA) could be of the form "For every natural number ''n'', ''n'' is not the [[Gödel number]] of a proof from PA that 0=1". (This formulation uses 0=1 instead of a direct contradiction; that gives the same result, because PA certainly proves ¬0=1, so if it proved 0=1 as well we would have a contradiction, and on the other hand, if PA proves a contradiction, [[Principle of explosion|then it proves anything]], including 0=1.)

Now, assuming PA is really consistent, it follows that PA&amp;nbsp;+&amp;nbsp;¬Con(PA) is also consistent, for if it were not, then PA would prove Con(PA) (since an inconsistent theory proves every sentence), contradicting [[Gödel's second incompleteness theorem]]. However, PA&amp;nbsp;+&amp;nbsp;¬Con(PA) is ''not'' ω-consistent. This is because, for any particular natural number ''n'', PA&amp;nbsp;+&amp;nbsp;¬Con(PA) proves that ''n'' is not the Gödel number of a proof that 0=1 (PA itself proves that fact; the extra assumption ¬Con(PA) is not needed). However, PA&amp;nbsp;+&amp;nbsp;¬Con(PA) proves that, for ''some'' natural number ''n'', ''n'' ''is'' the Gödel number of such a proof (this is just a direct restatement of the claim ¬Con(PA) ).

In this example, the axiom ¬Con(PA) is Σ&lt;sub&gt;1&lt;/sub&gt;, hence the system PA&amp;nbsp;+&amp;nbsp;¬Con(PA) is in fact Σ&lt;sub&gt;1&lt;/sub&gt;-unsound, not just ω-inconsistent.

=== Arithmetically sound, &amp;omega;-inconsistent theories ===

Let ''T'' be PA together with the axioms ''c''&amp;nbsp;≠&amp;nbsp;''n'' for each natural number ''n'', where ''c'' is a new constant added to the language. Then ''T'' is arithmetically sound (as any nonstandard model of PA can be expanded to a model of ''T''), but ω-inconsistent (as it proves &lt;math&gt;\exists x\,c=x&lt;/math&gt;, and ''c''&amp;nbsp;≠&amp;nbsp;''n'' for every number ''n'').

Σ&lt;sub&gt;1&lt;/sub&gt;-sound ω-inconsistent theories using only the language of arithmetic can be constructed as follows. Let ''I''Σ&lt;sub&gt;''n''&lt;/sub&gt; be the subtheory of PA with the induction schema restricted to Σ&lt;sub&gt;''n''&lt;/sub&gt;-formulas, for any ''n''&amp;nbsp;&gt;&amp;nbsp;0. The theory ''I''Σ&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt; is finitely axiomatizable, let thus ''A'' be its single axiom, and consider the theory ''T''&amp;nbsp;=&amp;nbsp;''I''Σ&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;¬''A''. We can assume that ''A'' is an instance of the induction schema, which has the form
::&lt;math&gt;\forall w\,[B(0,w)\land\forall x\,(B(x,w)\to B(x+1,w))\to\forall x\,B(x,w)].&lt;/math&gt;
If we denote the formula
::&lt;math&gt;\forall w\,[B(0,w)\land\forall x\,(B(x,w)\to B(x+1,w))\to B(n,w)]&lt;/math&gt;
by ''P''(''n''), then for every natural number ''n'', the theory ''T'' (actually, even the pure predicate calculus) proves ''P''(''n''). On the other hand, ''T'' proves the formula &lt;math&gt;\exists x\,\neg P(x)&lt;/math&gt;, because it is [[Logical equivalence|logically equivalent]] to the axiom ¬''A''. Therefore, ''T'' is ω-inconsistent.

It is possible to show that ''T'' is Π&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;3&lt;/sub&gt;-sound. In fact, it is Π&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;3&lt;/sub&gt;-[[conservative extension|conservative]] over the (obviously sound) theory ''I''Σ&lt;sub&gt;''n''&lt;/sub&gt;. The argument is more complicated (it relies on the provability of the Σ&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;2&lt;/sub&gt;-reflection principle for ''I''Σ&lt;sub&gt;''n''&lt;/sub&gt; in ''I''Σ&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt;).

=== Arithmetically unsound, &amp;omega;-consistent theories ===

Let ω-Con(PA) be the arithmetical sentence formalizing the statement "PA is ω-consistent". Then the theory PA&amp;nbsp;+&amp;nbsp;¬ω-Con(PA) is unsound (Σ&lt;sub&gt;3&lt;/sub&gt;-unsound, to be precise), but ω-consistent. The argument is similar to the first example: a suitable version of the Hilbert-Bernays-Löb derivability conditions holds for the "provability predicate" ω-Prov(''A'')&amp;nbsp;=&amp;nbsp;¬ω-Con(PA&amp;nbsp;+&amp;nbsp;¬''A''), hence it satisfies an analogue of Gödel's second incompleteness theorem.

== ω-logic ==
{{distinguish|Ω-logic}}
The concept of theories of arithmetic whose integers are the true mathematical integers is captured by '''ω-logic'''.&lt;ref&gt;[[Jon Barwise|J. Barwise]] (ed.), ''Handbook of Mathematical Logic'', North-Holland, Amsterdam, 1977.&lt;/ref&gt; Let ''T'' be a theory in a countable language which includes a unary predicate symbol ''N'' intended to hold just of the natural numbers, as well as specified names 0, 1, 2, …, one for each (standard) natural number (which may be separate constants, or constant terms such as 0, 1, 1+1, 1+1+1, …, etc.).  Note that ''T'' itself could be referring to more general objects, such as real numbers or sets; thus in a model of ''T'' the objects satisfying ''N''(''x'') are those that ''T'' interprets as natural numbers, not all of which need be named by one of the specified names.

The system of ω-logic includes all axioms and rules of the usual first-order predicate logic, together with, for each ''T''-formula ''P''(''x'') with a specified free variable ''x'', an [[infinitary logic|infinitary]] '''ω-rule''' of the form:
:From &lt;math&gt;P(0),P(1),P(2),\ldots&lt;/math&gt; infer &lt;math&gt;\forall x\,(N(x)\to P(x))&lt;/math&gt;.

That is, if the theory asserts (i.e. proves) ''P''(''n'') separately for each natural number ''n'' given by its specified name, then it also asserts ''P'' collectively for all natural numbers at once via the evident finite universally quantified counterpart of the infinitely many antecedents of the rule.  For a theory of arithmetic, meaning one with intended domain the natural numbers such as [[Peano arithmetic]], the predicate ''N'' is redundant and may be omitted from the language, with the consequent of the rule for each ''P'' simplifying to &lt;math&gt;\forall x\,P(x)&lt;/math&gt;.

An ω-model of ''T'' is a model of ''T'' whose domain includes the natural numbers and whose specified names and symbol ''N'' are standardly interpreted, respectively as those numbers and the predicate having just those numbers as its domain (whence there are no nonstandard numbers). If ''N'' is absent from the language then what would have been the domain of ''N'' is required to be that of the model, i.e. the model contains only the natural numbers.  (Other models of ''T'' may interpret these symbols nonstandardly; the domain of ''N'' need not even be countable, for example.)  These requirements make the ω-rule sound in every ω-model. As a corollary to the [[omitting types theorem]], the converse also holds: the theory ''T'' has an ω-model if and only if it is consistent in ω-logic.

There is a close connection of ω-logic to ω-consistency. A theory consistent in ω-logic is also ω-consistent (and arithmetically sound). The converse is false, as consistency in ω-logic is a much stronger notion than ω-consistency. However, the following characterization holds: a theory is ω-consistent if and only if its closure under ''unnested'' applications of the ω-rule is consistent.

== Relation to other consistency principles ==

If the theory ''T'' is [[recursively enumerable|recursively axiomatizable]], ω-consistency has the following characterization, due to [[Craig Smoryński|C. Smoryński]]:&lt;ref&gt;{{cite book|last=Smoryński|first=Craig|url=https://books.google.com/?id=7waFAAAAIAAJ&amp;q=978-0387962092&amp;dq=978-0387962092 |isbn=978-0-387-96209-2|title=Self-reference and modal logic|publisher=Springer|location= Berlin|year= 1985}} Reviewed in {{Cite journal | doi = 10.2307/2274450| jstor = 2274450| title = Self-Reference and Modal Logic| journal = The Journal of Symbolic Logic| volume = 53| pages = 306| year = 1988| last1 = Boolos | first1 = G. | last2 = Smorynski | first2 = C.}}&lt;/ref&gt;
:''T'' is &amp;omega;-consistent if and only if &lt;math&gt;T+\mathrm{RFN}_T+\mathrm{Th}_{\Pi^0_2}(\mathbb N)&lt;/math&gt; is consistent.
Here, &lt;math&gt;\mathrm{Th}_{\Pi^0_2}(\mathbb N)&lt;/math&gt; is the set of all Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left: -0.5em"&gt;2&lt;/sub&gt;-sentences valid in the standard model of arithmetic, and &lt;math&gt;\mathrm{RFN}_T&lt;/math&gt; is the [[reflection principle|uniform reflection principle]] for ''T'', which consists of the axioms
:&lt;math&gt;\forall x\,(\mathrm{Prov}_T(\ulcorner\varphi(\dot x)\urcorner)\to\varphi(x))&lt;/math&gt;
for every formula &lt;math&gt;\varphi&lt;/math&gt; with one free variable. In particular, a finitely axiomatizable theory ''T'' in the language of arithmetic is ω-consistent if and only if ''T''&amp;nbsp;+&amp;nbsp;PA is &lt;math&gt;\Sigma^0_2&lt;/math&gt;-sound.

== Notes ==
&lt;references/&gt;

== Bibliography ==
* Kurt Gödel (1931).  'Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I'.  In ''Monatshefte für Mathematik''.  Translated into English as [[On Formally Undecidable Propositions of Principia Mathematica and Related Systems]].

{{DEFAULTSORT:Omega consistent theory}}
[[Category:Proof theory]]</text>
      <sha1>4c437bgq06irfr1jm56hon85sy1e9nw</sha1>
    </revision>
  </page>
</mediawiki>
