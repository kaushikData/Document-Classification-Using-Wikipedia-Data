<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Abstract cell complex</title>
    <ns>0</ns>
    <id>35238282</id>
    <revision>
      <id>789921282</id>
      <parentid>782003135</parentid>
      <timestamp>2017-07-10T13:42:49Z</timestamp>
      <contributor>
        <ip>122.61.146.101</ip>
      </contributor>
      <comment>Spelling and consistency</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8362">In mathematics, an '''abstract cell complex''' is an abstract set with [[Alexandrov topology]] in which a non-negative integer number called [[dimension]] is assigned to each point. The complex is called “abstract” since its points, which are called “cells”, are not subsets of a [[Hausdorff space]] as it is the case in Euclidean and [[CW complex]]. Abstract cell complexes play an important role in [[image analysis]] and [[computer graphics]].

==History==
The idea of abstract cell complexes &lt;ref&gt;Reinhard Klette: Cell complexes through time. http://spie.org/Publications/Proceedings/Paper/10.1117/12.404813&lt;/ref&gt; (also named abstract cellular complexes) relates to [[Johann Benedict Listing|J. Listing]] (1862) &lt;ref&gt;Listing J.: "Der Census räumlicher Complexe". ''Abhandlungen der Königlichen Gesellschaft der Wissenschaften zu Göttingen'', v. 10, Göttingen, 1862, 97–182.&lt;/ref&gt; und [[Ernst Steinitz|E. Steinitz]] (1908).&lt;ref&gt;Steinitz E.: "Beiträge zur Analysis". ''Sitzungsbericht Berliner Mathematischen Gesellschaft'', Band. 7, 1908, 29–49.&lt;/ref&gt; Also A.W Tucker (1933),&lt;ref&gt;Tucker A.W.: "An abstract approach to manifolds", Annals Mathematics, v. 34, 1933, 191-243.&lt;/ref&gt; K. Reidemeister (1938),&lt;ref&gt;Reidemeister K.: "Topologie der Polyeder und kombinatorische Topologie der Komplexe". Akademische Verlagsgesellschaft Geest &amp; Portig, Leipzig, 1938 (second edition 1953)&lt;/ref&gt; P.S. Aleksandrov (1956) &lt;ref&gt;Aleksandrov P.S.: Combinatorial Topology, Graylock Press, Rochester, 1956,&lt;/ref&gt;  as well as R. Klette und A. Rosenfeld (2004) &lt;ref&gt;Klette R. und Rosenfeld. A.: "Digital Geometry", Elsevier, 2004.&lt;/ref&gt; have described abstract cell complexes. E. Steinitz has defined an abstract cell complex as &lt;math&gt; C=(E,B,dim)&lt;/math&gt; where ''E'' is an '''abstract''' set, ''B'' is an asymmetric, irreflexive and transitive binary relation called the '''bounding relation''' among the elements of ''E'' and ''dim'' is a function assigning a non-negative integer to each element of ''E'' in such a way that if &lt;math&gt;B(a, b)&lt;/math&gt;, then &lt;math&gt;dim(a)&lt;dim(b)&lt;/math&gt;. 
V. Kovalevsky (1989) &lt;ref&gt;Kovalevsky, V.: "Finite Topology as Applied to Image Analysis", ''Computer Vision, Graphics and Image Processing'', v. 45, No. 2, 1989, 141–161.&lt;/ref&gt; described abstract cell complexes for 3D and higher dimensions. He also suggested numerous applications to image analysis. In his book (2008) &lt;ref&gt;http://www.geometry.kovalevsky.de.&lt;/ref&gt; he has suggested an axiomatic theory of locally finite [[topological spaces]] which are generalization of abstract cell complexes. The book contains among others new definitions of topological balls and spheres independent of [[metric (mathematics)|metric]], a new definition of [[combinatorial manifold]]s and many algorithms useful for image analysis.

==Basic results==
The topology of abstract cell complexes is based on a [[partial order]] in the set of its points or cells. 

The notion of the abstract cell complex defined by E. Steinitz is related to the notion of an [[abstract simplicial complex]] and it differs from a [[simplicial complex]] by the property that its elements are no [[simplex|simplices]]: An ''n''-dimensional element of an abstract complexes must not have ''n''+1 zero-dimensional sides, and not each subset of the set of zero-dimensional sides of a cell is a cell. This is important since the notion of an abstract cell complexes can be applied to the two- and three-dimensional grids used in image processing, which is not true for simplicial complexes. A non-simplicial complex is a generalization which makes the introduction of cell coordinates possible: There are non-simplicial complexes which are Cartesian products of such "linear" one-dimensional complexes where each zero-dimensional cell, besides two of them, bounds exactly two one-dimensional cells. Only such Cartesian complexes make it possible to introduce such coordinates that each cell has a set of coordinates and any two different cells have different coordinate sets. The coordinate set can serve as a name of each cell of the complex which is important for processing complexes. 

Abstract complexes allow the introduction of classical topology (Alexandrov-topology) in grids being the basis of digital image processing. This possibility defines the great advantage of abstract cell complexes: It becomes possible to exactly define the notions of connectivity and of the boundary of subsets. The definition of dimension of cells and of complexes is in the general case different from that of simplicial complexes (see below).

The notion of an abstract cell complex differs essentially from that of a CW-complex because an abstract cell complex is no [[Hausdorff space]]. This is important from the point of view of computer science since it is impossible to explicitly represent a non-discrete Hausdorff space in a computer. (The neighborhood of each point in such a space must have infinitely many points). 

The book by V. Kovalevsky &lt;ref&gt;V. Kovalevsky: "Geometry of Locally Finite Spaces". Editing house Dr. Bärbel Kovalevski, Berlin 2008. {{ISBN|978-3-9812252-0-4}}.&lt;/ref&gt; contains the description of the theory of [[locally finite space]]s which are a generalization of abstract cell complexes. A locally finite space ''S'' is a set of points where a subset of ''S'' is defined for each point ''P'' of ''S''. This subset containing a limited number of points is called the '''smallest neighborhood''' of ''P''. A binary neighborhood relation is defined in the set of points of the locally finite space ''S'': The element (point) ''b'' is in the neighborhood relation with the element ''a'' if ''b'' belongs to the smallest neighborhood of the element ''a''. New axioms of a locally finite space have been formulated, and it was proven that the space ''S'' is in accordance with the axioms only if the neighborhood relation is anti-symmetric and transitive. The neighborhood relation is the reflexive hull of the inverse bounding relation. It was shown that classical axioms of the topology can be deduced as theorems from the new axioms. Therefore, a locally finite space satisfying the new axioms is a particular case of a classical topological space. Its topology is a [[poset topology]] or [[Alexandrov topology]].
An abstract cell complex is a particular case of a locally finite space in which the dimension is defined for each point. It was demonstrated that the dimension of a cell ''c'' of an abstract cell complex is equal to the length (number of cells minus 1) of the maximum bounding path leading from any cell of the complex to the cell ''c''. The bounding path is a sequence of cells in which each cell bounds the next one. The book contains the theory of digital straight segments in 2D complexes, numerous algorithms for tracing boundaries in 2D and 3D, for economically encoding the boundaries and for exactly reconstructing a subset from the code of its boundary.

==Abstract Cell Complex Digital Image Representation==
[[File:Digital Image ACC Decomposition.PNG|thumb|A 3x4 digital image decomposed into its Abstract Cell Complex dimensional constituents.]]
A digital image may be represented by a 2D Abstract Cell Complex (ACC) by decomposing the image into its ACC dimensional constituents: points (0-cell), cracks/edges (1-cell), and pixels/faces (2-cell).

[[File:Digital Image ACC Coordinate Assignment.PNG|thumb|Digital Image ACC Coordinate Assignment]]
This decomposition together with a coordinate assignment rule to unambiguously assign coordinates from the image pixels to the dimensional constituents permit certain image analysis operations to be carried out on the image with elegant algorithms such as crack [[boundary tracing]], [[digital straight segment]] subdivision, etc. One such rule maps the points, cracks, and faces to the top left coordinate of the pixel. It should be noted that these dimensional constituents require no explicit translation into their own data structures but may be implicitly understood and related to the 2D array which is the usual data structure representation of a digital image. This coordinate assignment rule and the renderings of each cell incident to this image is depicted in the image at right.

== References ==
{{Reflist}}

== External links ==
* [http://www.kovalevsky.de Prof. Dr. Vladimir Kovalevsky]

[[Category:Topology]]</text>
      <sha1>96g713iyk6muae5tle61l2d75njibwq</sha1>
    </revision>
  </page>
  <page>
    <title>Abū Kāmil Shujāʿ ibn Aslam</title>
    <ns>0</ns>
    <id>2479369</id>
    <revision>
      <id>869457731</id>
      <parentid>868149057</parentid>
      <timestamp>2018-11-18T19:05:34Z</timestamp>
      <contributor>
        <username>Arjayay</username>
        <id>5718152</id>
      </contributor>
      <comment>Duplicate word removed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17198">{{Infobox scholar
| name             = Abū Kāmil
| other_names      = al-ḥāsib al-miṣrī
| birth_date       = c. 850
| birth_place      =
| death_date       = c. 930
| death_place      =
| era              = [[Islamic Golden Age]]
| region           = [[Egypt]]

| school_tradition =
| main_interests   = [[Algebra]], [[geometry]]
| notable_ideas    = {{Unbulleted list|Use of irrational numbers as solutions and coefficients to equations}}
| major_works      = ''The Book of Algebra''
| influences       = [[Al-Khwarizmi]]
| influenced       = [[Al-Karaji]], [[Fibonacci]]
}}
'''{{transl|ar|ALA|Abū Kāmil, Shujāʿ ibn Aslam ibn Muḥammad Ibn Shujāʿ}}''' ([[Latinization (literature)|Latinized]] as '''Auoquamel''',&lt;ref&gt;{{Cite book| publisher = Routledge| isbn = 978-0-415-12411-9| last = Rāshid| first = Rushdī|author2= Régis Morelon| title = Encyclopedia of the history of Arabic science| year = 1996| page=240| volume=2}}&lt;/ref&gt; {{lang-ar|أبو كامل شجاع بن أسلم بن محمد بن شجاع}}, also known as '''al-ḥāsib al-miṣrī'''&amp;mdash;lit. "the Egyptian reckoner") (c. 850 – c. 930) was an [[Egyptians|Egyptian]] [[Muslim]] mathematician during the [[Islamic Golden Age]]. He is considered the first mathematician to systematically use and accept [[irrational number]]s as solutions and [[coefficients]] to equations.&lt;ref name="Sesiano" /&gt; His mathematical techniques were later adopted by [[Fibonacci]], thus allowing Abu Kamil an important part in introducing algebra to Europe.&lt;ref name=MacTutor /&gt;

Abu Kamil made important contributions to [[algebra]] and [[geometry]].&lt;ref name="EI2" /&gt; He was the first [[Islamic mathematician]] to work easily with algebraic equations with powers higher than &lt;math&gt;x^2&lt;/math&gt; (up to &lt;math&gt;x^8&lt;/math&gt;),&lt;ref name=MacTutor /&gt;&lt;ref name="Levey2008" /&gt; and solved sets of non-linear [[simultaneous equations]] with three unknown [[Variable (mathematics)|variables]].&lt;ref name="Berggren"&gt;{{cite book | first=J. Lennart | last=Berggren | title=The Mathematics of Egypt, Mesopotamia, China, India, and Islam: A Sourcebook | chapter=Mathematics in Medieval Islam | publisher=Princeton University Press | year=2007 | isbn=978-0-691-11485-9 | pages=518, 550 |url=https://books.google.com/books?id=3ullzl036UEC&amp;lpg=PP1&amp;dq=The%20Mathematics%20of%20Egypt%2C%20Mesopotamia%2C%20China%2C%20India%2C%20and%20Islam&amp;pg=PA518#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;  He wrote all problems rhetorically, and some of his books lacked any [[mathematical notation]] beside those of integers. For example, he uses the Arabic expression "māl māl shayʾ" ("square-square-thing") for &lt;math&gt;x^5&lt;/math&gt; (i.e., &lt;math&gt;x^2\cdot x^2\cdot x&lt;/math&gt;).&lt;ref name="MacTutor" /&gt;&lt;ref&gt;{{Cite book| publisher = Cambridge University Press| isbn = 978-0-88385-329-0| last = Bashmakova| first = Izabella Grigorʹevna|author1-link= Isabella Bashmakova |author2= Galina S. Smirnova| title = The beginnings and evolution of algebra| date = 2000-01-15| page=52}}&lt;/ref&gt;

The muslim encyclopedist [[Ibn Khaldūn]] classified Abū Kāmil as the second greatest algebraist chronologically after [[al-Khwarizmi]].&lt;ref&gt;{{cite journal |last1=Sesiano |first1=Jacques |title=Abū Kāmil |journal=Encyclopaedia of the History of Science, Technology, and Medicine in Non-Western Cultures |date=2008 |pages=7–8 |doi=10.1007/978-1-4020-4425-0_9198 |url=https://doi.org/10.1007/978-1-4020-4425-0_9198 |publisher=Springer Netherlands |language=en}}&lt;/ref&gt;

== Life ==

Almost nothing is known about the life and career of Abu Kamil except that he was a successor of [[al-Khwarizmi]], whom he never personally met.&lt;ref name=MacTutor&gt;{{MacTutor Biography|id=Abu_Kamil}}&lt;/ref&gt;

==Works==

=== ''Book of Algebra (Kitāb fī al-jabr wa al-muqābala)'' ===

The ''Algebra'' is perhaps Abu Kamil's most influential work, which he intended to supersede and expand upon that of [[Al-Khwarizmi]].&lt;ref name="Sesiano" /&gt;&lt;ref name="Sesiano09" /&gt; Whereas the [[The Compendious Book on Calculation by Completion and Balancing|''Algebra'' of al-Khwarizmi]] was geared towards the general public, Abu Kamil was addressing other mathematicians, or readers familiar with [[Euclid]]'s ''Elements''.&lt;ref name="Sesiano09" /&gt;  In this book Abu Kamil solves systems of [[equation]]s whose solutions are [[Natural number|whole numbers]] and [[fractions]], and accepted [[irrational numbers]] (in the form of a [[square root]] or [[Nth root|fourth root]]) as solutions and [[coefficient]]s to [[quadratic equation]]s.&lt;ref name="Sesiano"&gt;Jacques Sesiano, "Islamic mathematics", p. 148, in {{Cite book|title=Mathematics Across Cultures: The History of Non-Western Mathematics|editor1-first=Helaine|editor1-last=Selin|editor1-link=Helaine Selin|editor2-first=Ubiratàn|editor2-last=D'Ambrosio|editor2-link=Ubiratàn D'Ambrosio|year=2000|publisher=Springer|isbn=1-4020-0260-2|url=https://books.google.com/books?id=2hTyfurOH8AC&amp;lpg=PP1&amp;dq=Mathematics%20Across%20Cultures%3A%20The%20History%20of%20Non-Western%20Mathematics&amp;pg=PA148#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;

The first chapter teaches algebra by solving problems of application to geometry, often involving an unknown variable and square roots. The second chapter deals with the [[The Compendious Book on Calculation by Completion and Balancing#The book|six types of problems]] found in Al-Khwarizmi's book,&lt;ref name="HSTM" /&gt; but some of which, especially those of &lt;math&gt;x^2&lt;/math&gt;, were now worked out directly instead of first solving for &lt;math&gt;x&lt;/math&gt; and accompanied with geometrical illustrations and proofs.&lt;ref name="Levey2008" /&gt;&lt;ref name="HSTM" /&gt; The third chapter contains examples of [[quadratic irrationalities]] as solutions and coefficients.&lt;ref name="HSTM" /&gt; The fourth chapter shows how these irrationalities are used to solve problems involving [[polygons]]. The rest of the book contains solutions for sets of [[indeterminate equation]]s, problems of application in realistic situations, and problems involving unrealistic situations intended for [[recreational mathematics]].&lt;ref name="HSTM"/&gt;

A number of Islamic mathematicians wrote commentaries on this work, including al-Iṣṭakhrī al-Ḥāsib and ʿAli ibn Aḥmad al-ʿImrānī (d. 955-6),&lt;ref&gt;{{Cite book| publisher = Macmillan Co.| last = Louis Charles Karpinski| title = Robert of Chester's Latin Translation of the Algebra of Al-Khowarizmi, with an Introduction, Critical Notes and an English Version| year = 1915}}&lt;/ref&gt; but both commentaries are now lost.&lt;ref name="EI2" /&gt;

In Europe, similar material to this book is found in the writings of [[Fibonacci]], and some sections were incorporated and improved upon in the Latin work of [[John of Seville]], ''Liber mahameleth''.&lt;ref name="HSTM" /&gt; A partial translation to Latin was done in the 14th century by William of Luna, and in the 15th century the whole work also appeared in a Hebrew translation by Mordekhai Finzi.&lt;ref name="HSTM" /&gt;

=== ''Book of Rare Things in the Art of Calculation (Kitāb al-ṭarā’if fi’l-ḥisāb)'' ===

Abu Kamil describes a number of systematic procedures for finding [[integral|integral solutions]] for [[indeterminate equation]]s.&lt;ref name="EI2"&gt;{{Cite encyclopedia | edition = 2nd| publisher = Brill Academic Publishers| volume = 1| pages = 132–3| last = Hartner| first = W.| title = ABŪ KĀMIL SHUDJĀʿ | encyclopedia = [[Encyclopaedia of Islam]]| year = 1960 |isbn = 90-04-08114-3}}&lt;/ref&gt; It is also the earliest known Arabic work where solutions are sought to the type of indeterminate equations found in [[Diophantus]]'s ''[[Arithmetica]]''. However, Abu Kamil explains certain methods not found in any extant copy of the ''Arithmetica''.&lt;ref name="MacTutor" /&gt; He also describes one problem for which he found 2,678 solutions.&lt;ref name="Livio" /&gt;

=== ''On the Pentagon and Decagon (Kitāb al-mukhammas wa’al-mu‘ashshar)''  ===

In this treatise algebraic methods are used to solve geometrical problems.&lt;ref name="EI2" /&gt; Abu Kamil uses the equation &lt;math&gt;x^4 + 3125 = 125x^2&lt;/math&gt; to calculate a numerical approximation for the side of a regular [[pentagon]] in a circle of diameter 10.&lt;ref&gt;{{Cite book| publisher = BRILL| isbn = 978-90-04-10119-7| last = Ragep| first = F. J.|author2=Sally P. Ragep|author3=Steven John Livesey| title = Tradition, transmission, transformation: proceedings of two conferences on pre-modern science held at the University of Oklahoma| year = 1996 |page=48}}&lt;/ref&gt; He also uses the [[golden ratio]] in some of his calculations.&lt;ref name="Livio"&gt;{{cite book | last = Livio | first = Mario | title = The Golden Ratio | publisher = Broadway | location = New York | year = 2003 | isbn = 0-7679-0816-3 | pages=89–90, 92, 96}}&lt;/ref&gt; [[Fibonacci]] knew about this treatise and made extensive use of it in his ''Practica geometriae''.&lt;ref name="EI2" /&gt;

=== ''Book of Birds (Kitāb al-ṭair)'' ===

A small treatise teaching how to solve indeterminate [[linear system]]s with positive [[integral|integral solutions]].&lt;ref name="Sesiano09" /&gt; The title is derived from a type of problems known in the east which involve the purchase of different species of birds. Abu Kamil wrote in the introduction:

&lt;blockquote&gt;I found myself before a problem that I solved and for which I discovered a great many solutions; looking deeper for its solutions, I obtained two thousand six hundred and seventy-six correct ones. My astonishment about that was great, but I found out that, when I recounted this discovery, those who did not know me were arrogant, shocked, and suspicious of me. I thus decided to write a book on this kind of calculations, with the purpose of facilitating its treatment and making it more accessible.&lt;ref name="Sesiano09"&gt;{{Cite book| publisher = AMS Bookstore| isbn = 978-0-8218-4473-1| last = Sesiano| first = Jacques| title = An introduction to the history of algebra: solving equations from Mesopotamian times to the Renaissance| date = 2009-07-09}}&lt;/ref&gt;&lt;/blockquote&gt;

According to Jacques Sesiano, Abu Kamil remained seemingly unparalleled throughout the Middle Ages in trying to find all the possible solutions to some of his problems.&lt;ref name="HSTM"&gt;{{Cite encyclopedia | publisher = Springer|  pages = 4–5| last = Sesiano| first = Jacques| title = Abū Kāmil | encyclopedia = Encyclopaedia of the history of science, technology, and medicine in non-western cultures| date = 1997-07-31}}&lt;/ref&gt;

=== ''On Measurement and Geometry (Kitāb al-misāḥa wa al-handasa)'' ===

A manual of [[geometry]] for non-mathematicians, like land surveyors and other government officials, which presents a set of rules for calculating the volume and surface area of solids (mainly rectangular [[parallelepiped]]s, right circular [[prism (geometry)|prism]]s, [[square pyramid]]s, and circular [[cone (geometry)|cones]]). The first few chapters contain rules for determining the [[area]], [[diagonal]], [[perimeter]], and other parameters for different types of triangles, rectangles and squares.&lt;ref name="MacTutor" /&gt;

=== Lost works ===

Some of Abu Kamil's lost works include:

* A treatise on the use of double [[false position]], known as the ''Book of the Two Errors'' (''Kitāb al-khaṭaʾayn'').&lt;ref&gt;{{Cite conference| conference = Eighth North African Meeting on the History of Arab Mathematics| last = Schwartz| first = R. K| title =Issues in the Origin and Development of Hisab al-Khata’ayn (Calculation by Double False Position)| location = Radès, Tunisia| date = 2004}} Available online at:  http://facstaff.uindy.edu/~oaks/Biblio/COMHISMA8paper.doc and {{cite web|url=http://www.ub.edu/islamsci/Schwartz.pdf |title=Archived copy |accessdate=2012-06-08 |deadurl=yes |archiveurl=https://web.archive.org/web/20140516012137/http://www.ub.edu/islamsci/Schwartz.pdf |archivedate=2014-05-16 }}&lt;/ref&gt;
* ''Book on Augmentation and Diminution'' (''Kitāb al-jamʿ wa al-tafrīq''), which gained more attention after historian [[Franz Woepcke]] linked it with an anonymous Latin work, ''Liber augmenti et diminutionis''.&lt;ref name="EI2" /&gt;
* ''Book of Estate Sharing using Algebra'' (''Kitāb al-waṣāyā bi al-jabr wa al-muqābala''), which contains algebraic solutions for problems of [[Islamic inheritance jurisprudence|Islamic inheritance]] and discusses the opinions of known [[Islamic jurisprudence|jurists]].&lt;ref name="HSTM" /&gt;

[[Ibn al-Nadim]] in his ''[[Fihrist]]'' listed the following additional titles: ''Book of Fortune'' (''Kitāb al-falāḥ''), ''Book of the Key to Fortune'' (''Kitāb miftāḥ al-falāḥ''), ''Book of the Adequate'' (''Kitāb al-kifāya''), and ''Book of the Kernel'' (''Kitāb al-ʿasīr'').&lt;ref name="Levey2008" /&gt;

== Legacy ==

The works of Abu Kamil influenced other mathematicians, like [[al-Karaji]] and [[Fibonacci]], and as such had a lasting impact on the development of algebra.&lt;ref name="Levey2008"&gt;{{cite encyclopedia| last = Levey| first = Martin| title = Abū Kāmil Shujāʿ ibn Aslam ibn Muḥammad ibn Shujāʿ| url = http://www.encyclopedia.com/doc/1G2-2830900029.html| encyclopedia = [[Dictionary of Scientific Biography]]| volume = 1| pages = 30–32| publisher = Charles Scribner's Sons| location = New York| year = 1970| isbn = 0-684-10114-9}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi = 10.2307/2972073| issn = 0002-9890| volume = 21| issue = 2| pages = 37–48| last = Karpinski| first = L. C.| title = The Algebra of Abu Kamil| journal = The American Mathematical Monthly| date = 1914-02-01| jstor = 2972073}}&lt;/ref&gt; Many of his examples and algebraic techniques were later copied by Fibonacci in his ''Practica geometriae'' and other works.&lt;ref name="Levey2008" /&gt;&lt;ref name="Livio" /&gt; Unmistakable borrowings, but without Abu Kamil being explicitly mentioned and perhaps mediated by lost treatises, are also found in Fibonacci's ''[[Liber Abaci]]''.&lt;ref&gt;{{Cite conference| publisher = Max Planck Institute for the History of Science| volume = 390| last = Høyrup| first = J.| title = Hesitating progress-the slow development toward algebraic symbolization in abbacus-and related manuscripts, c. 1300 to c. 1550: Contribution to the conference" Philosophical Aspects of Symbolic Reasoning in Early Modern Science and Mathematics", Ghent, 27–29 August 2009| location = Berlin| series = Preprints| date = 2009}}&lt;/ref&gt;

==On al-Khwarizmi==

Abu Kamil was one of the earliest mathematicians to recognize [[al-Khwarizmi]]'s contributions to [[algebra]], defending him against Ibn Barza who attributed the authority and precedent in algebra to his grandfather, [['Abd al-Hamīd ibn Turk]].&lt;ref name="MacTutor" /&gt; Abu Kamil wrote in the introduction of his ''Algebra'':

&lt;blockquote&gt;I have studied with great attention the writings of the mathematicians, examined their assertions, and scrutinized what they explain in their works; I thus observed that the book by Muḥammad ibn Mūsā al-Khwārizmī known as ''Algebra'' is superior in the accuracy of its principle and the exactness of its argumentation. It thus behooves us, the community of mathematicians, to recognize his priority and to admit his knowledge and his superiority, as in writing his book on algebra he was an initiator and the discoverer of its principles, ...&lt;ref name="Sesiano09" /&gt;&lt;/blockquote&gt;

==Notes==
{{reflist|2}}

==References==
* {{Cite book| publisher = AMS Bookstore| isbn = 978-0-8218-4473-1| last = Sesiano| first = Jacques| title = An introduction to the history of algebra: solving equations from Mesopotamian times to the Renaissance| date = 2009-07-09}}
* {{cite encyclopedia
| last = Levey
| first = Martin
| title = Abū Kāmil Shujāʿ ibn Aslam ibn Muḥammad ibn Shujāʿ
| url = http://www.encyclopedia.com/doc/1G2-2830900029.html
| encyclopedia = [[Dictionary of Scientific Biography]]
| volume = 1
| pages = 30–32
| publisher = Charles Scribner's Sons
| location = New York
| year = 1970
| isbn = 0-684-10114-9
}}
* {{MacTutor Biography|id=Abu_Kamil}}

==Further reading==
* {{Cite journal| issn = 0021-1753| volume = 69| issue = 2| pages = 259–262| last = Yadegari| first = Mohammad| title = The Use of Mathematical Induction by Abū Kāmil Shujā' Ibn Aslam (850-930)| journal = Isis| date = 1978-06-01| jstor = 230435| doi=10.1086/352009}}
* {{Cite journal| doi = 10.2307/2972073| issn = 0002-9890| volume = 21| issue = 2| pages = 37–48| last = Karpinski| first = L. C.| title = The Algebra of Abu Kamil| journal = The American Mathematical Monthly| date = 1914-02-01| jstor = 2972073}}
* {{Cite book| publisher = Wilfrid Laurier Univ Pr| isbn = 0-88920-152-8| last = Herz-Fischler| first = Roger| title = A Mathematical History of Division in Extreme and Mean Ratio| date = June 1987}}
* Djebbar, Ahmed. ''Une histoire de la science arabe'': Entretiens avec Jean Rosmorduc. Seuil (2001)

{{Islamic mathematics}}

{{Authority control}}

{{DEFAULTSORT:Abu Kamil}}
[[Category:Mathematicians of medieval Islam]]
[[Category:Medieval Arab mathematicians]]
[[Category:9th-century mathematicians]]
[[Category:10th-century mathematicians]]
[[Category:Algebraists]]
[[Category:850 births]]
[[Category:930 deaths]]
[[Category:Egyptian Muslims]]
[[Category:Egyptian scientists]]
[[Category:Medieval Egyptian mathematicians]]
[[Category:Mathematicians who worked on Islamic inheritance]]</text>
      <sha1>ch11jpvlli1xfp6cvtskytuz0r7253k</sha1>
    </revision>
  </page>
  <page>
    <title>Adjoint filter</title>
    <ns>0</ns>
    <id>7869295</id>
    <revision>
      <id>799761628</id>
      <parentid>797858639</parentid>
      <timestamp>2017-09-09T18:01:57Z</timestamp>
      <contributor>
        <username>Edgar181</username>
        <id>491706</id>
      </contributor>
      <comment>[[Wikipedia:Articles for deletion/Adjoint filter]] closed as keep</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1954">In [[signal processing]], the '''adjoint filter mask''' &lt;math&gt;h^*&lt;/math&gt; of a [[linear filter|filter mask]] &lt;math&gt;h&lt;/math&gt; is reversed in time and the elements are [[complex conjugate]]d.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=PLcC2gmtv3kC|title=Discrete Fourier Analysis and Wavelets: Applications to Signal and Image Processing|last=Broughton|first=S. Allen|last2=Bryan|first2=Kurt M.|date=2011-10-13|publisher=John Wiley &amp; Sons|year=|isbn=9781118211007|location=|pages=141|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=VQa3CgAAQBAJ|title=Wavelets: An Elementary Treatment of Theory and Applications|last=Koornwinder|first=Tom H.|date=1993-06-24|publisher=World Scientific|year=|isbn=9789814590976|location=|pages=70|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=bcJJAAAAQBAJ|title=Excursions in Harmonic Analysis, Volume 2: The February Fourier Talks at the Norbert Wiener Center|last=Andrews|first=Travis D.|last2=Balan|first2=Radu|last3=Benedetto|first3=John J.|last4=Czaja|first4=Wojciech|last5=Okoudjou|first5=Kasso A.|date=2013-01-04|publisher=Springer Science &amp; Business Media|year=|isbn=9780817683795|location=|pages=174|language=en}}&lt;/ref&gt;
:&lt;math&gt;(h^*)_k = \overline{h_{-k}}&lt;/math&gt;

Its name is derived from the fact that the convolution with the adjoint filter is the [[adjoint of an operator|adjoint operator]] of the original filter, with respect to the [[Hilbert space]] &lt;math&gt;\ell_2&lt;/math&gt; of the [[sequence]]s in which the inner product is the [[Euclidean norm]].
:&lt;math&gt;\langle h*x, y \rangle = \langle x, h^* * y \rangle&lt;/math&gt;

The [[autocorrelation]] of a signal &lt;math&gt;x&lt;/math&gt; can be written as &lt;math&gt;x^* * x&lt;/math&gt;.

==Properties==
* &lt;math&gt;{h^*}^* = h&lt;/math&gt;
* &lt;math&gt;(h*g)^* = h^* * g^*&lt;/math&gt;
* &lt;math&gt;(h\leftarrow k)^* = h^* \rightarrow k&lt;/math&gt;

== References ==
{{Reflist}}{{Math-stub}}

{{DEFAULTSORT:Adjoint Filter}}
[[Category:Digital signal processing]]</text>
      <sha1>hhmckmhqytkxva6cazzhgld0w5c3iky</sha1>
    </revision>
  </page>
  <page>
    <title>Algebraic enumeration</title>
    <ns>0</ns>
    <id>212117</id>
    <revision>
      <id>646270450</id>
      <parentid>508857014</parentid>
      <timestamp>2015-02-09T01:10:43Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>rm orphan tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="775">'''Algebraic enumeration''' is a subfield of [[enumeration]] that deals with finding exact formulas for the number of [[combinatorics|combinatorial objects]] of a given type, rather than estimating this number [[asymptotic analysis|asymptotically]]. Methods of finding these formulas include [[generating function]]s and the solution of [[recurrence relation]]s.&lt;ref&gt;{{citation
 | last1 = Gessel | first1 = Ira M.
 | last2 = Stanley | first2 = Richard P. | author2-link = Richard P. Stanley
 | contribution = Algebraic enumeration
 | location = Amsterdam
 | mr = 1373677
 | pages = 1021–1061
 | publisher = Elsevier
 | title = Handbook of combinatorics, Vol. 1, 2
 | year = 1995}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Enumerative combinatorics]]


{{combin-stub}}</text>
      <sha1>e9predo9h23ndr6kgxjneonwka99301</sha1>
    </revision>
  </page>
  <page>
    <title>B-convex space</title>
    <ns>0</ns>
    <id>21600196</id>
    <revision>
      <id>753815879</id>
      <parentid>448309601</parentid>
      <timestamp>2016-12-09T10:20:23Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Probability theory]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2085">In [[functional analysis]], the class of '''''B''-convex spaces''' is a class of [[Banach space]].  The concept of ''B''-convexity was defined and used to characterize Banach spaces that have the [[strong law of large numbers]] by Anatole Beck in 1962;  accordingly, "B-convexity" is understood as an abbreviation of '''Beck convexity'''.  Beck proved the following theorem: A Banach space is ''B''-convex [[if and only if]] every sequence of [[statistical independence|independent]], symmetric, uniformly bounded and [[Radon random variable]]s in that space satisfies the strong law of large numbers.

Let ''X'' be a Banach space with [[norm (mathematics)|norm]] ||&amp;nbsp;||.  ''X'' is said to be '''''B''-convex''' if for some ''ε''&amp;nbsp;&amp;gt;&amp;nbsp;0 and some [[natural number]] ''n'', it holds true that whenever ''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt; are elements of the [[closed unit ball]] of ''X'', there is a choice of signs ''α''&lt;sub&gt;1&lt;/sub&gt;, ..., ''α''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;{&amp;minus;1,&amp;nbsp;+1} such that

:&lt;math&gt;\left\| \sum_{i = 1}^{n} \alpha_{i} x_{i} \right\| \leq (1 - \varepsilon) n.&lt;/math&gt;

Later authors have shown that B-convexity is equivalent to a number of other important properties in the theory of Banach spaces.  Being '''B-convex''' and having '''Rademacher type''' &lt;math&gt;p&gt;1&lt;/math&gt; were shown to be equivalent Banach-space properties by [[Gilles Pisier]].

==References==

* {{cite journal
| doi = 10.1090/S0002-9939-1962-0133857-9
| last = Beck
| first = Anatole
| title = A convexity condition in Banach spaces and the strong law of large numbers
| journal = Proc. Amer. Math. Soc.
| volume = 13
| issue = 2
| year = 1962
| pages = 329&amp;ndash;334
| issn = 0002-9939
| mr = 0133857
}}
* {{ cite book
| last1 = Ledoux
| first1 = Michel
| last2 = Talagrand | first2 = Michel | author2-link = Michel Talagrand
| title = Probability in Banach spaces
| publisher = Springer-Verlag
| location = Berlin
| year = 1991
| pages = xii+480
| isbn = 3-540-52013-9
| mr = 1102015
}} (See chapter 9)

[[Category:Banach spaces]]
[[Category:Convex geometry]]</text>
      <sha1>ghcrzas122pq478o1kmb92dsl4on1uc</sha1>
    </revision>
  </page>
  <page>
    <title>Babuška–Lax–Milgram theorem</title>
    <ns>0</ns>
    <id>13502744</id>
    <revision>
      <id>790660039</id>
      <parentid>729208719</parentid>
      <timestamp>2017-07-15T06:05:57Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Background */LaTeX spacing clean up, replaced: \ &lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5579">In [[mathematics]], the '''Babuška–Lax–Milgram theorem''' is a generalization of the famous [[Lax–Milgram theorem]], which gives conditions under which a [[bilinear form]] can be "inverted" to show the existence and uniqueness of a [[weak solution]] to a given [[boundary value problem]].  The result is named after the [[mathematician]]s [[Ivo Babuška]], [[Peter Lax]] and [[Arthur Milgram]].

==Background==
In the modern, [[functional analysis|functional-analytic]] approach to the study of [[partial differential equations]], one does not attempt to solve a given partial differential equation directly, but by using the structure of the [[vector space]] of possible solutions, e.g. a [[Sobolev space]] ''W''&lt;sup&gt;''k'',''p''&lt;/sup&gt;.  Abstractly, consider two [[real number|real]] [[normed space]]s ''U'' and ''V'' with their [[continuous dual space]]s ''U''&lt;sup&gt;∗&lt;/sup&gt; and ''V''&lt;sup&gt;∗&lt;/sup&gt; respectively.  In many applications, ''U'' is the space of possible solutions; given some [[partial differential operator]] Λ&amp;nbsp;:&amp;nbsp;''U''&amp;nbsp;→&amp;nbsp;''V''&lt;sup&gt;∗&lt;/sup&gt; and a specified element ''f''&amp;nbsp;∈&amp;nbsp;''V''&lt;sup&gt;∗&lt;/sup&gt;, the objective is to find a ''u''&amp;nbsp;∈&amp;nbsp;''U'' such that

:&lt;math&gt;\Lambda u = f.&lt;/math&gt;

However, in the [[weak formulation]], this equation is only required to hold when "tested" against all other possible elements of ''V''.  This "testing" is accomplished by means of a bilinear function ''B''&amp;nbsp;:&amp;nbsp;''U''&amp;nbsp;&amp;times;&amp;nbsp;''V''&amp;nbsp;→&amp;nbsp;'''R''' which encodes the differential operator Λ; a ''weak solution'' to the problem is to find a ''u''&amp;nbsp;∈&amp;nbsp;''U'' such that

:&lt;math&gt;B(u, v) = \langle f, v \rangle \mbox{ for all } v \in V.&lt;/math&gt;

The achievement of Lax and Milgram in their 1954 result was to specify sufficient conditions for this weak formulation to have a unique solution that depends [[continuous function|continuously]] upon the specified datum ''f''&amp;nbsp;∈&amp;nbsp;''V''&lt;sup&gt;∗&lt;/sup&gt;: it suffices that ''U''&amp;nbsp;=&amp;nbsp;''V'' is a [[Hilbert space]], that ''B'' is continuous, and that ''B'' is strongly [[coercive function|coercive]], i.e.

:&lt;math&gt;| B(u, u) | \geq c \| u \|^{2}&lt;/math&gt;

for some constant ''c''&amp;nbsp;&amp;gt;&amp;nbsp;0 and all ''u''&amp;nbsp;∈&amp;nbsp;''U''.

For example, in the solution of the [[Poisson equation]] on a [[bounded set|bounded]], [[open set|open]] domain Ω&amp;nbsp;⊂&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;,

:&lt;math&gt;\begin{cases} - \Delta u(x) = f(x), &amp; x \in \Omega; \\ u(x) = 0, &amp; x \in \partial \Omega; \end{cases}&lt;/math&gt;

the space ''U'' could be taken to be the Sobolev space ''H''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;1&lt;/sup&gt;(Ω) with dual ''H''&lt;sup&gt;&amp;minus;1&lt;/sup&gt;(Ω); the former is a subspace of the [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; space]] ''V''&amp;nbsp;=&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;(Ω); the bilinear form ''B'' associated to &amp;minus;Δ is the ''L''&lt;sup&gt;2&lt;/sup&gt;(Ω) [[inner product]] of the derivatives:

:&lt;math&gt;B(u, v) = \int_{\Omega} \nabla u(x) \cdot \nabla v(x) \, \mathrm{d} x.&lt;/math&gt;

Hence, the weak formulation of the Poisson equation, given ''f''&amp;nbsp;∈&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;(Ω), is to find ''u''&lt;sub&gt;''f''&lt;/sub&gt; such that

:&lt;math&gt;\int_{\Omega} \nabla u_{f}(x) \cdot \nabla v(x) \, \mathrm{d} x = \int_{\Omega} f(x) v(x) \, \mathrm{d} x \mbox{ for all } v \in H_{0}^{1} (\Omega).&lt;/math&gt;

==Statement of the theorem==

In 1971, Babuška provided the following generalization of Lax and Milgram's earlier result, which begins by dispensing with the requirement that ''U'' and ''V'' be the same space.  Let ''U'' and ''V'' be two real Hilbert spaces and let ''B''&amp;nbsp;:&amp;nbsp;''U''&amp;nbsp;&amp;times;&amp;nbsp;''V''&amp;nbsp;→&amp;nbsp;'''R''' be a continuous bilinear functional.  Suppose also that ''B'' is weakly coercive: for some constant ''c''&amp;nbsp;&amp;gt;&amp;nbsp;0 and all ''u''&amp;nbsp;∈&amp;nbsp;''U'',

:&lt;math&gt;\sup_{\| v \| = 1} | B(u, v) | \geq c \| u \|&lt;/math&gt;

and, for all 0&amp;nbsp;≠&amp;nbsp;''v''&amp;nbsp;∈&amp;nbsp;''V'', 

:&lt;math&gt;\sup_{\| u \| = 1} | B(u, v) | &gt; 0&lt;/math&gt;

Then, for all ''f''&amp;nbsp;∈&amp;nbsp;''V''&lt;sup&gt;∗&lt;/sup&gt;, there exists a unique solution ''u''&amp;nbsp;=&amp;nbsp;''u''&lt;sub&gt;''f''&lt;/sub&gt;&amp;nbsp;∈&amp;nbsp;''U'' to the weak problem

:&lt;math&gt;B(u_{f}, v) = \langle f, v \rangle \mbox{ for all } v \in V.&lt;/math&gt;

Moreover, the solution depends continuously on the given datum:

:&lt;math&gt;\| u_{f} \| \leq \frac{1}{c} \| f \|.&lt;/math&gt;

==See also==

* [[Lions–Lax–Milgram theorem]]

==References==

*{{cite journal
|last = Babuška
|first = Ivo
|author-link = Ivo Babuška
|title = Error-bounds for finite element method
|journal = [[Numerische Mathematik]]
|volume = 16
|year = 1970–1971
|pages = 322–333
|url=https://eudml.org/doc/132037
|issn = 0029-599X
|doi = 10.1007/BF02165003
|mr = 0288971
|zbl=0214.42001
}}
*{{citation
|last = Lax
|first = Peter D.
|author-link = Peter Lax
|last2 = Milgram
|first2 = Arthur N.
|author2-link = Arthur Milgram
|chapter = Parabolic equations
|title = Contributions to the theory of partial differential equations
|series = Annals of Mathematics Studies
|volume= 33
|pages = 167–190
|chapter-url=https://www.degruyter.com/view/books/9781400882182/9781400882182-010/9781400882182-010.xml
|url=https://www.degruyter.com/viewbooktoc/product/474533
|publisher = [[Princeton University Press]]
|place = [[Princeton, N. J.]]
|year = 1954
|mr=0067317
|zbl=0058.08703
|via = [[De Gruyter]]
|subscription=yes}}

==External links==
* {{springer
 | title = Babuška–Lax–Milgram theorem
 | id = B/b110020
 | last = Roşca
 | first = Ioan
}}

{{DEFAULTSORT:Babuska-Lax-Milgram theorem}}
[[Category:Theorems in analysis]]
[[Category:Partial differential equations]]</text>
      <sha1>ekpk6rgsdxhtx1tqpm4m9srmastvovk</sha1>
    </revision>
  </page>
  <page>
    <title>Burnside category</title>
    <ns>0</ns>
    <id>41144473</id>
    <revision>
      <id>726617820</id>
      <parentid>726530170</parentid>
      <timestamp>2016-06-23T08:19:27Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes using [[Project:AWB|AWB]] (12033)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2905">In [[category theory]] and [[homotopy theory]] the '''Burnside category''' of a [[finite group]] ''G'' is a category whose objects are finite [[G-set|''G''-sets]] and whose morphisms are (equivalence classes of) [[Span (category theory)|spans]] of ''G''-equivariant maps. It is a categorification of the [[Burnside ring]] of ''G''.

==Definitions==
Let ''G'' be a finite group (in fact everything will work verbatim for a [[profinite group]]). Then for any two finite ''G''-sets ''X'' and ''Y'' we can define an equivalence relation among spans of [[G-set|''G''-sets]] of the form &lt;math&gt;X\leftarrow U \rightarrow Y&lt;/math&gt; where two spans &lt;math&gt;X\leftarrow U \rightarrow Y&lt;/math&gt; and &lt;math&gt;X\leftarrow W \rightarrow Y&lt;/math&gt;are equivalent if and only if there is a ''G''-equivariant bijection of ''U'' and ''W'' commuting with the projection maps to ''X'' and ''Y''. This set of equivalence classes form naturally a monoid under disjoint union; we indicate with &lt;math&gt;A(G)(X,Y)&lt;/math&gt; the [[Grothendieck group|group completion]] of that monoid. Taking pullbacks induces natural maps &lt;math&gt;A(G)(X,Y)\times A(G)(Y,Z)\rightarrow A(G)(X,Z)&lt;/math&gt;.

Finally we can define the '''Burnside category''' ''A(G)'' of ''G'' as the category whose objects are finite ''G''-sets and the morphisms spaces are the groups &lt;math&gt;A(G)(X,Y)&lt;/math&gt;.

==Properties==
* ''A(G)'' is an [[additive category]] with direct sums given by the disjoint union of ''G''-sets and zero object given by the empty ''G''-set;
* The product of two ''G''-sets induces a symmetric monoidal structure on ''A(G)'';
* The endomorphism ring of the point (that is the ''G''-set with only one element) is the [[Burnside ring]] of ''G'';
* ''A(G)'' is equivalent to the full subcategory of the homotopy category of genuine ''G''-spectra spanned by the suspension spectra of finite ''G''-sets.

==Mackey functors==
If ''C'' is an [[additive category]], then a ''C''-valued '''Mackey functor''' is an additive functor from ''A(G)'' to ''C''. Mackey functors are important in representation theory and stable equivariant homotopy theory.
* To every ''G''-representation ''V'' we can associate a Mackey functor in vector spaces sending every finite ''G''-set ''U'' to the vector space of ''G''-equivariant maps from ''U'' to ''V''. 
* The homotopy groups of a [[equivariant homotopy theory|genuine ''G''-spectrum]] form a Mackey functor. In fact genuine ''G''-spectra can be seen as additive functor on an appropriately higher categorical version of the Burnside category.

== References ==
* {{cite arXiv | last1=Guillou | first1=Bertrand | last2=May | first2=J.P.| title=Models of G-spectra as presheaves of spectra | eprint=1110.3571}}
* {{cite arXiv | last=Barwick | first=Clark | title=Spectral Mackey functors and equivariant algebraic K-theory (I) | eprint=1404.0108}}

[[Category:Category theory]]
[[Category:Group theory]]


{{categorytheory-stub}}</text>
      <sha1>i11sxjvdhfdx4yyyy58wc4rbato85xz</sha1>
    </revision>
  </page>
  <page>
    <title>Canonical Huffman code</title>
    <ns>0</ns>
    <id>6946171</id>
    <revision>
      <id>761085587</id>
      <parentid>747382242</parentid>
      <timestamp>2017-01-20T20:08:36Z</timestamp>
      <contributor>
        <ip>129.34.20.23</ip>
      </contributor>
      <comment>Kraft inequality is misstated;  The sum is less than **or equal** to 1.  As a matter of fact gzip will reject a huffman tree whose sum is not 1</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9056">{{Multiple issues|
{{no footnotes|date=March 2014}}
{{technical|date=June 2011}}
{{context|date=June 2011}}
}}
A '''canonical Huffman code''' is a particular type of [[Huffman code]] with unique properties which allow it to be described in a very compact manner.

[[Data compression|Data compressor]]s generally work in one of two ways. Either the decompressor can infer what [[codebook]] the compressor has used from previous context, or the compressor must tell the decompressor what the codebook is. Since a canonical Huffman codebook can be stored especially efficiently, most compressors start by generating a "normal" Huffman codebook, and then convert it to canonical Huffman before using it.

In order for a [[symbol code]] scheme such as the [[Huffman code]] to be decompressed, the same model that the encoding algorithm used to compress the source data must be provided to the decoding algorithm so that it can use it to decompress the encoded data.  In standard Huffman coding this model takes the form of a tree of variable-length codes, with the most frequent symbols located at the top of the structure and being represented by the fewest number of bits.

However, this code tree introduces two critical inefficiencies into an implementation of the coding scheme.  Firstly, each node of the tree must store either references to its child nodes or the symbol that it represents.  This is expensive in memory usage and if there is a high proportion of unique symbols in the source data then the size of the code tree can account for a significant amount of the overall encoded data.  Secondly, traversing the tree is computationally costly, since it requires the algorithm to jump randomly through the structure in memory as each bit in the encoded data is read in.

Canonical Huffman codes address these two issues by generating the codes in a clear standardized format; all the codes for a given length are assigned their values sequentially.  This means that instead of storing the structure of the code tree for decompression only the lengths of the codes are required, reducing the size of the encoded data.  Additionally, because the codes are sequential, the decoding algorithm can be dramatically simplified so that it is computationally efficient.

==Algorithm==
The normal Huffman coding [[algorithm]] assigns a variable length code to every symbol in the alphabet.  More frequently used symbols will be assigned a shorter code.  For example, suppose we have the following ''non''-canonical codebook:

 A = 11
 B = 0
 C = 101
 D = 100

Here the letter A has been assigned 2 [[bit]]s, B has 1 bit, and C and D both have 3 bits.  To make the code a ''canonical'' Huffman code, the codes are renumbered.  The bit lengths stay the same with the code book being sorted ''first'' by codeword length and ''secondly'' by [[alphabetical]] [[Value (computer science)|value]]:

 B = 0
 A = 11
 C = 101
 D = 100

Each of the existing codes are replaced with a new one of the same length, using the following algorithm:

* The ''first'' symbol in the list gets assigned a codeword which is the same length as the symbol's original codeword but all zeros.  This will often be a single zero ('0').
* Each subsequent symbol is assigned the next [[Binary numeral system|binary]] number in sequence, ensuring that following codes are always higher in value.
* When you reach a longer codeword, then ''after'' incrementing, append zeros until the length of the new codeword is equal to the length of the old codeword. This can be thought of as a [[Logical shift|left shift]].

By following these three rules, the ''canonical'' version of the code book produced will be:

 B = 0
 A = 10
 C = 110
 D = 111

===As a fractional binary number===

Another perspective on the canonical codewords is that they are the digits past the [[radix point]] (binary decimal point) in a binary representation of a certain series.  Specifically, suppose the lengths of the codewords are ''l''&lt;sub&gt;1&lt;/sub&gt; ... ''l''&lt;sub&gt;n&lt;/sub&gt;.  Then the canonical codeword for symbol ''i'' is the first ''l''&lt;sub&gt;i&lt;/sub&gt; binary digits past the radix point in the binary representation of

&lt;math&gt;\sum_{j = 1}^{i - 1} 2^{-l_j}.&lt;/math&gt;

This perspective is particularly useful in light of [[Kraft's inequality]], which says that the sum above will always be less than or equal to 1 (since the lengths come from a prefix free code).  This shows that adding one in the algorithm above never overflows and creates a codeword that is longer than intended.

==Encoding the codebook==
The whole advantage of a canonical Huffman tree is that one can encode the description (the codebook) in fewer bits than a fully described tree.

Let us take our original Huffman codebook:

 A = 11
 B = 0
 C = 101
 D = 100

There are several ways we could encode this Huffman tree.  For example, we could write each '''symbol''' followed by the '''number of bits''' and '''code''':

 ('A',2,11), ('B',1,0), ('C',3,101), ('D',3,100)

Since we are listing the symbols in sequential alphabetical order, we can omit the symbols themselves, listing just the '''number of bits''' and '''code''':

 (2,11), (1,0), (3,101), (3,100)

With our ''canonical'' version we have the knowledge that the symbols are in sequential alphabetical order ''and'' that a later code will always be higher in value than an earlier one.  The only parts left to transmit are the [[bit-length]]s ('''number of bits''') for each symbol.  Note that our canonical Huffman tree always has higher values for longer bit lengths and that any symbols of the same bit length (''C'' and ''D'') have higher code values for higher symbols:

 A = 10    (code value: 2 decimal, bits: '''2''')
 B = 0     (code value: 0 decimal, bits: '''1''')
 C = 110   (code value: 6 decimal, bits: '''3''')
 D = 111   (code value: 7 decimal, bits: '''3''')

Since two-thirds of the constraints are known, only the '''number of bits''' for each symbol need be transmitted:

 2, 1, 3, 3

With knowledge of the canonical Huffman algorithm, it is then possible to recreate the entire table (symbol and code values) from just the bit-lengths.  Unused symbols are normally transmitted as having zero bit length.

Another efficient way representing the codebook is to list all symbols in increasing order by their bit-lengths, and record the number of symbols for each bit-length.  For the example mentioned above, the encoding becomes:

 (1,1,2), ('B','A','C','D')

This means that the first symbol ''B'' is of length 1, then the ''A'' of length 2, and remains of 3.  Since the symbols are sorted by bit-length, we can efficiently reconstruct the codebook.  A [[pseudo code]] describing the reconstruction is introduced on the next section.

This type of encoding is advantageous when only a few symbols in the alphabet are being compressed. For example, suppose the codebook contains only 4 letters ''C'', ''O'', ''D'' and ''E'', each of length 2. To represent the letter ''O'' using the previous method, we need to either add a lot of zeros:

 0, 0, 2, 2, 2, 0, ... , 2, ...

or record which 4 letters we have used. Each way makes the description longer than:

 (0,4), ('C','O','D','E')

The [[JPEG File Interchange Format]] uses this  method of encoding, because at most only 162 symbols out of the [[8-bit]] alphabet, which has size 256, will be in the codebook.

==Pseudo code==
Given a list of symbols sorted by bit-length, the following [[pseudo code]] will print a canonical Huffman code book:

 code = 0
 while more symbols:
     print symbol, code
     code = (code + 1) &lt;&lt; ((bit length of the next symbol) - (current bit length))

==Algorithm==

The algorithm described in:
"A Method for the Construction of Minimum-Redundancy Codes"
David A. Huffman, Proceedings of the I.R.E.
is:

 compute huffman code:
  input:   message ensemble (set of (message, probability)).
           base D.
  output:  code ensemble (set of (message, code)).
  algorithm:
    1- sort the message ensemble by decreasing probability.
    2- N is the cardinal of the message ensemble (number of different
       messages).
    3- compute the integer n_0 such as 2&lt;=n_0&lt;=D and (N-n_0)/(D-1) is integer.
    4- select the n_0 least probable messages, and assign them each a
       digit code.
    5- substitute the selected messages by a composite message summing
       their probability, and re-order it.
    6- while there remains more than one message, do steps thru 8.
    7-    select D least probable messages, and assign them each a
          digit code.
    8-    substitute the selected messages by a composite message
          summing their probability, and re-order it.
    9- the code of each message is given by the concatenation of the
       code digits of the aggregate they've been put in.

References: 
1. [http://ww2.cs.mu.oz.au/mg/ Managing Gigabytes]: book with an implementation of canonical huffman codes for word dictionaries. 
{{Compression methods}}

{{DEFAULTSORT:Canonical Huffman Code}}
[[Category:Lossless compression algorithms]]
[[Category:Coding theory]]</text>
      <sha1>lgj2djt9jghoakeq2agrmh2709v7z20</sha1>
    </revision>
  </page>
  <page>
    <title>Closure operator</title>
    <ns>0</ns>
    <id>483120</id>
    <revision>
      <id>861654283</id>
      <parentid>815504810</parentid>
      <timestamp>2018-09-29T00:54:27Z</timestamp>
      <contributor>
        <username>Ketiltrout</username>
        <id>202276</id>
      </contributor>
      <minor/>
      <comment>dab</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16180">In [[mathematics]], a '''closure operator''' on a [[Set (mathematics)|set]] ''S'' is a [[Function (mathematics)|function]] &lt;math&gt;\operatorname{cl}: \mathcal{P}(S)\rightarrow \mathcal{P}(S)&lt;/math&gt; from the [[power set]] of ''S'' to itself which satisfies the following conditions for all sets &lt;math&gt;X,Y\subseteq S&lt;/math&gt;
:{| border="0"
|-
| &lt;math&gt;X \subseteq \operatorname{cl}(X)&lt;/math&gt;
| (cl is ''extensive'')
|-
| &lt;math&gt;X\subseteq Y \Rightarrow \operatorname{cl}(X) \subseteq \operatorname{cl}(Y)&lt;/math&gt;
| (cl is ''increasing'')
|-
| &lt;math&gt; \operatorname{cl}(\operatorname{cl}(X))=\operatorname{cl}(X)&lt;/math&gt;
| (cl is ''idempotent'')
|}

Closure operators are determined by their '''closed sets''', i.e., by the sets of the form cl(''X''), since the '''closure''' cl(''X'') of a set ''X'' is the smallest closed set containing ''X''. Such families of "closed sets" are sometimes called "'''Moore families'''", in honor of [[E. H. Moore]] who studied closure operators in his 1910 ''Introduction to a form of general analysis'', whereas the concept of the closure of a subset originated in the work of [[Frigyes Riesz]] in connection with topological spaces.&lt;ref&gt;Blyth p.11&lt;/ref&gt;

Closure operators are also called "'''hull operators'''", which prevents confusion with the "closure operators" studied in [[point-set topology|topology]]. A set together with a closure operator on it is sometimes called a '''closure space'''.

== Applications ==

Closure operators have many applications: 

In topology, the closure operators are [[Kuratowski closure axioms|''topological'' closure operator]]s, which must satisfy

: &lt;math&gt;\operatorname{cl}(X_1 \cup\dots\cup X_n) = \operatorname{cl}(X_1)\cup\dots\cup \operatorname{cl}(X_n)&lt;/math&gt;

for all &lt;math&gt;n\in\N&lt;/math&gt; (Note that for &lt;math&gt;n=0&lt;/math&gt; this gives &lt;math&gt;\operatorname{cl}(\varnothing)=\varnothing&lt;/math&gt;). 

In [[algebra]] and [[logic]], many closure operators are '''finitary closure operators''', i.e. they satisfy

: &lt;math&gt;\operatorname{cl}(X) = \bigcup\left\{\operatorname{cl}(Y) : Y\subseteq X \text{ and } Y \text{ finite} \right\}.&lt;/math&gt;

In [[universal logic]], closure operators are also known as '''consequence operators'''. 

In the theory of [[partially ordered set]]s, which are important in [[theoretical computer science]], closure operators have an alternative definition.

== Closure operators in topology ==
{{main|Kuratowski closure axioms}}
The [[topological closure]] of a subset ''X'' of a [[topological space]] consists of all points ''y'' of the space, such that every [[neighbourhood (mathematics)|neighbourhood]] of ''y'' contains a point of ''X''. The function that associates to every subset ''X'' its closure is a topological closure operator. Conversely, every topological closure operator on a set gives rise to a topological space whose closed sets are exactly the closed sets with respect to the closure operator.

For topological closure operators the second closure axiom (being increasing) is redundant.

== Closure operators in algebra ==
Finitary closure operators play a relatively prominent role in [[universal algebra]], and in this context they are traditionally called ''algebraic closure operators''. Every subset of an [[structure (mathematical logic)|algebra]] ''generates'' a [[substructure (mathematics)|subalgebra]]: the smallest subalgebra containing the set. This gives rise to a finitary closure operator.

Perhaps the best known example for this is the function that associates to every subset of a given [[vector space]] its [[linear span]]. Similarly, the function that associates to every subset of a given [[group (mathematics)|group]] the [[subgroup]] generated by it, and similarly for [[field (mathematics)|field]]s and all other types of [[algebraic structure]]s.

The linear span in a vector space and the similar algebraic closure in a field both satisfy the ''exchange property:'' If ''x'' is in the closure of the union of ''A'' and {''y''} but not in the closure of ''A'', then ''y'' is in the closure of the union of ''A'' and {''x''}. A finitary closure operator with this property is called a [[matroid]]. The [[dimension (vector space)|dimension]] of a vector space, or the [[transcendence degree]] of a field (over its [[prime field]]) is exactly the rank of the corresponding matroid.

The function that maps every subset of a given [[field (mathematics)|field]] to its [[algebraic closure]] is also a finitary closure operator, and in general it is different from the operator mentioned before. Finitary closure operators that generalize these two operators are studied in [[model theory]] as dcl (for ''definable closure'') and acl (for ''algebraic closure'').

The [[convex hull]] in ''n''-dimensional [[Euclidean space]] is another example of a finitary closure operator. It satisfies the ''anti-exchange property:'' If ''x'' is not contained in the union of ''A'' and {''y''}, but in its closure, then ''y'' is not contained in the closure of the union of ''A'' and {''x''}. Finitary closure operators with this property give rise to [[antimatroid]]s.

== Closure operators in logic ==
Suppose you have some [[mathematical logic|logical formalism]] that contains certain rules allowing you to derive new formulas from given ones. Consider the set ''F'' of all possible formulas, and let ''P'' be the [[power set]] of ''F'', ordered by ⊆. For a set ''X'' of formulas, let cl(''X'') be the set of all formulas that can be derived from ''X''. Then cl is a closure operator on ''P''. More precisely, we can obtain cl as follows. Call "continuous" an operator ''J'' such that, for every directed class ''T'',
	
:''J''(''lim T'')= ''lim J''(''T'').	

This continuity condition is on the basis of a fixed point theorem for ''J''. Consider the one-step operator ''J'' of a monotone logic. This is the operator associating any set ''X'' of formulas with the set ''J(X)'' of formulas which are either logical axioms or are obtained by an inference rule from formulas in ''X'' or are in ''X''. Then such an operator is continuous and we can define cl(''X'') as the least fixed point for ''J'' greater or equal to ''X''. In accordance with such a point of view, Tarski, Brown, Suszko and other authors proposed a general approach to logic based on closure operator theory. Also, such an idea is proposed in programming logic (see Lloyd 1987) and in fuzzy logic (see Gerla 2000).

=== Consequence operators ===
Around 1930, [[Alfred Tarski]] developed an abstract theory of logical deductions which models some properties of logical calculi. Mathematically, what he described is just a finitary closure operator on a set (the set of ''sentences'').  In [[universal logic]], finitary closure operators are still studied under the name ''consequence operator'', which was coined by Tarski. The set ''S'' represents a set of sentences, a subset ''T'' of ''S'' a theory, and cl(''T'') is the set of all sentences that follow from the theory. Nowadays the term can refer to closure operators which need not be finitary; finitary closure operators are then sometimes called '''finite consequence operators'''.

== Closed and pseudo-closed sets ==
The closed sets with respect to a closure operator on ''S'' form a subset ''C'' of the power set '''''P'''''(''S''). Any intersection of sets in ''C'' is again in ''C''. In other words, ''C'' is a complete meet-subsemilattice of '''''P'''''(''S''). Conversely, if ''C'' ⊆ '''''P'''''(''S'') is closed under arbitrary intersections, then the function that associates to every subset ''X'' of ''S'' the smallest set ''Y'' ∈ ''C'' such that ''X'' ⊆ ''Y'' is a closure operator.

There is a simple and fast algorithm for generating all closed sets of a given closure operator&lt;ref&gt; Ganter, Algorithm 1&lt;/ref&gt;.

A closure operator on a set is topological if and only if the set of closed sets is closed under finite unions, i.e., ''C'' is a meet-complete sublattice of '''''P'''''(''S''). Even for non-topological closure operators, ''C'' can be seen as having the structure of a lattice. (The join of two sets ''X'',''Y'' ⊆ '''''P'''''(''S'') being cl(''X'' &lt;math&gt;\cup&lt;/math&gt; ''Y'').) But then ''C'' is not a [[sublattice]] of the lattice '''''P'''''(''S'').

Given a finitary closure operator on a set, the closures of finite sets are exactly the [[compact element]]s of the set ''C'' of closed sets. It follows that ''C'' is an [[algebraic poset]].
Since ''C'' is also a lattice, it is often referred to as an algebraic lattice in this context. Conversely, if ''C'' is an algebraic poset, then the closure operator is finitary.

Each closure operator on a finite set ''S'' is uniquely determined by its images of its ''pseudo-closed'' sets&lt;ref&gt; Ganter, Section 3.2&lt;/ref&gt;.
These are recursively defined: A set is '''pseudo-closed''' if it is not closed and contains the closure of each of its pseudo-closed proper subsets. Formally: ''P''&amp;sube;''S'' is pseudo-closed if and only if
* ''P''&amp;ne;cl(''P'') and 
* if ''Q''&amp;sub;''P'' is pseudo-closed, then cl(''Q'')&amp;sube;''P''.

== Closure operators on partially ordered sets ==
A [[partially ordered set]] (poset) is a set together with a ''partial order'' ≤, i.e. a binary relation which is reflexive ({{nowrap|''a'' ≤ ''a''}}), transitive ({{nowrap|''a'' ≤ ''b'' ≤ ''c''}} implies {{nowrap|''a'' ≤ ''c''}}) and antisymmetric ({{nowrap|''a'' ≤ ''b'' ≤ ''a''}} implies ''a''&amp;nbsp;=&amp;nbsp;''b''). Every [[power set]] '''P'''(''S'') together with inclusion ⊆ is a partially ordered set.

A function cl: ''P'' → ''P'' from a partial order ''P'' to itself is called a closure operator if it satisfies the following axioms for all elements ''x'', ''y'' in ''P''.
:{| border="0"
|-
| ''x'' ≤ cl(''x'')
| (cl is ''extensive'')
|-
| ''x'' ≤ ''y'' implies cl(''x'') ≤ cl(''y'')&amp;nbsp;&amp;nbsp;
| (cl is [[increasing]])
|-
| cl(cl(''x'')) = cl(''x'')
| (cl is [[idempotent]])
|}

More succinct alternatives are available: the definition above is equivalent to the single axiom

:''x'' ≤ cl(''y'') if and only if cl(''x'') ≤ cl(''y'')

for all ''x'', ''y'' in ''P''.

Using the [[pointwise order]] on functions between posets, one may alternatively write the extensiveness property as id&lt;sub&gt;''P''&lt;/sub&gt; ≤ cl, where id is the [[identity function]]. A self-map ''k'' that is increasing and idempotent, but satisfies the [[Duality (order theory)|dual]] of the extensiveness property, i.e. ''k'' ≤ id&lt;sub&gt;''P''&lt;/sub&gt; is called a '''kernel operator''',&lt;ref&gt;Giertz, p. 26&lt;/ref&gt; '''interior operator''',&lt;ref&gt;Erné, p. 2, uses closure (resp. interior) operation&lt;/ref&gt; or '''dual closure'''.&lt;ref&gt;Blyth, p. 10&lt;/ref&gt; As examples, if ''A'' is a subset of a set ''B'', then the self-map on the powerset of ''B'' given by ''μ&lt;sub&gt;A&lt;/sub&gt;''(''X'') = ''A'' ∪ ''X'' is a closure operator, whereas ''λ&lt;sub&gt;A&lt;/sub&gt;''(''X'') = ''A'' ∩ ''X'' is a kernel operator. The [[ceiling function]] from the [[real number]]s to the real numbers, which assigns to every real ''x'' the smallest [[integer]] not smaller than ''x'', is another example of a closure operator.

A [[fixpoint]] of the function cl, i.e. an element ''c'' of ''P'' that satisfies cl(''c'')&amp;nbsp;=&amp;nbsp;''c'', is called a '''closed element'''. A closure operator on a partially ordered set is determined by its closed elements. If ''c'' is a closed element, then ''x'' ≤ ''c'' and cl(''x'') ≤ ''c'' are equivalent conditions.

Every [[Galois connection]] (or [[residuated mapping]]) gives rise to a closure operator (as is explained in that article). In fact, ''every'' closure operator arises in this way from a suitable Galois connection.&lt;ref&gt;Blyth, p. 10&lt;/ref&gt; The Galois connection is not uniquely determined by the closure operator. One Galois connection that gives rise to the closure operator cl can be described as follows: if ''A'' is the set of closed elements with respect to cl, then cl: ''P'' → ''A'' is the lower adjoint of a Galois connection between ''P'' and ''A'', with the upper adjoint being the embedding of ''A'' into ''P''. Furthermore, every lower adjoint of an embedding of some subset into ''P'' is a closure operator. "Closure operators are lower adjoints of embeddings." Note however that not every embedding has a lower adjoint.

Any partially ordered set ''P'' can be viewed as a [[category theory|category]], with a single morphism from ''x'' to ''y'' if and only if ''x'' ≤ ''y''. The closure operators on the partially ordered set ''P'' are then nothing but the [[monad (category theory)|monad]]s on the category ''P''. Equivalently, a closure operator can be viewed as an endofunctor on the category of partially ordered sets that has the additional ''idempotent'' and ''extensive'' properties.

If ''P'' is a [[complete lattice]], then a subset ''A'' of ''P'' is the set of closed elements for some closure operator on ''P'' if and only if ''A'' is a '''Moore family''' on ''P'', i.e. the largest element of ''P'' is in ''A'', and the [[infimum]] (meet) of any non-empty subset of ''A'' is again in ''A''. Any such set ''A'' is itself a complete lattice with the order inherited from ''P'' (but the [[supremum]] (join) operation might differ from that of ''P''). When ''P'' is the [[powerset]] Boolean algebra of a set ''X'', then a Moore family on ''P'' is called a '''closure system''' on ''X''.

The closure operators on ''P'' form themselves a complete lattice; the order on closure operators is defined by cl&lt;sub&gt;1&lt;/sub&gt; ≤ cl&lt;sub&gt;2&lt;/sub&gt; [[iff]] cl&lt;sub&gt;1&lt;/sub&gt;(''x'') ≤ cl&lt;sub&gt;2&lt;/sub&gt;(''x'') for all ''x'' in ''P''.

==See also==
*[[Čech closure operator]]
*[[Galois connection]]
*[[Interior algebra]]
*[[Kuratowski closure axioms]]
*[[Closure (topology)]] and [[Interior (topology)]]

== Notes ==
{{reflist|3}}

== References ==
* [[Garrett Birkhoff]]. 1967 (1940). ''Lattice Theory, 3rd ed''. American Mathematical Society.
* Burris, Stanley N., and H.P. Sankappanavar (1981) [http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra]  Springer-Verlag. {{ISBN|3-540-90578-2}} ''Free online edition''.
* Brown, D.J. and Suszko, R. (1973) "Abstract Logics," [[Dissertationes Mathematicae]] 102- 9-42.
* Castellini, G. (2003) ''Categorical closure operators''. Boston MA: Birkhaeuser.
* Edelman, Paul H. (1980) ''Meet-distributive lattices and the anti-exchange closure,'' [[Algebra Universalis]] 10: 290-299.
* Ganter, Bernhard and Obiedkov, Sergei (2016) ''Conceptual Exploration''. Springer, {{ISBN|978-3-662-49290-1}}.
* Gerla, G. (2000) ''Fuzzy Logic: Mathematical Tools for Approximate Reasoning''. [[Kluwer Academic Publishers]].
* Lloyd, J.W. (1987) ''Foundations of Logic Programming''. [[Springer-Verlag]].
* [[Alfred Tarski|Tarski, Alfred]] (1983) "Fundamental concepts of the methodology of deductive sciences" in ''Logic, Semantics, Metamathematics''. Hackett (1956 ed., [[Oxford University Press]]).
* [[Alfred Tarski]] (1956) ''Logic, semantics and metamathematics''. [[Oxford University Press]].
* [[Morgan Ward|Ward, Morgan]] (1942) "The closure operators of a lattice," [[Annals of Mathematics]] 43: 191-96.
* G. Gierz, K. H. Hofmann, K. Keimel, J. D. Lawson, M. Mislove, D. S. Scott: ''Continuous Lattices and Domains'', Cambridge University Press, 2003
* T.S. Blyth, ''Lattices and Ordered Algebraic Structures'', Springer, 2005, {{ISBN|1-85233-905-5}}.
* M. Erné, J. Koslowski, A. Melton, G. E. Strecker, ''A primer on Galois connections'', in: Proceedings of the 1991 Summer Conference on General Topology and Applications in Honor of Mary Ellen Rudin and Her Work, Annals of the New York Academy of Sciences, Vol. 704, 1993, pp.&amp;nbsp;103–125. Available online in various file formats: [https://web.archive.org/web/20060108063506/http://www.iti.cs.tu-bs.de/TI-INFO/koslowj/RESEARCH/gal_bw.ps.gz PS.GZ] [http://www.math.ksu.edu/~strecker/primer.ps PS]

==External links==
*[[Stanford Encyclopedia of Philosophy]]: "[http://plato.stanford.edu/entries/consequence-algebraic/ Propositional Consequence Relations and Algebraic Logic]" -- by Ramon Jansana.

{{DEFAULTSORT:Closure Operator}}
[[Category:Closure operators|*]]
[[Category:Universal algebra]]
[[Category:Order theory]]

[[pl:Operator konsekwencji]]</text>
      <sha1>nah8wp577laaw7acun7o9wqfb5bbex9</sha1>
    </revision>
  </page>
  <page>
    <title>Count data</title>
    <ns>0</ns>
    <id>15690807</id>
    <revision>
      <id>857915533</id>
      <parentid>828122233</parentid>
      <timestamp>2018-09-03T21:31:45Z</timestamp>
      <contributor>
        <username>Smasongarrison</username>
        <id>16185737</id>
      </contributor>
      <comment>/* top */copy editing, applying [[Wikipedia:AutoWikiBrowser/General_fixes|General fixes]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3801">{{More citations needed|date=August 2009}}

In [[statistics]], '''count data''' is a [[statistical data type]], a type of [[data]] in which the observations can take only the non-negative [[integer]] values {0, 1, 2, 3, ...}, and where these integers arise from [[counting]] rather than [[ranking]].  The statistical treatment of count data is distinct from that of [[binary data]], in which the observations can take only two values, usually represented by 0 and 1, and from [[ordinal data]], which may also consist of integers but where the individual values fall on an arbitrary scale and only the relative ranking is important.

Statistical analyses involving count data includes simple counts, such as the number of occurrences of thunderstorms in a calendar year, and [[categorical data]] in which the counts represent the numbers of items falling into each of several categories.

==Count variables==
An individual piece of count data is often termed a '''count variable'''.  When such a variable is treated as a [[random variable]], the [[Poisson distribution|Poisson]], [[binomial distribution|binomial]] and [[negative binomial distribution|negative binomial]] distributions are commonly used to represent its distribution.

==Graphical examination==
Graphical examination of count data may be aided by the use of [[data transformation (statistics)|data transformation]]s chosen to have the property of stabilising the sample variance. In particular, the [[square root]] transformation might be used when data can be approximated by a [[Poisson distribution]] (although other transformation have modestly improved properties), while an inverse sine transformation is available when a [[binomial distribution]] is preferred.

==Relating count data to other variables==
Here the count variable would be treated as a [[dependent variable]]. Statistical methods such as [[least squares]] and [[analysis of variance]] are designed to deal with continuous dependent variables. These can be adapted to deal with count data by using [[data transformation (statistics)|data transformation]]s such as the [[square root]] transformation, but such methods have several drawbacks; they are approximate at best and estimate [[parameter]]s that are often hard to interpret.

The [[Poisson distribution]] can form the basis for some analyses of count data and in this case [[Poisson regression]] may be used. This is a special case of the class of [[generalized linear model]]s which also contains specific forms of model capable of using the [[binomial distribution]] ([[binomial regression]], [[logistic regression]]) or the [[negative binomial distribution]] where the assumptions of the Poisson model are violated, in particular when the range of count values is limited or when [[overdispersion]] is present.

==See also==
* [[Index of dispersion]]
* [[Empirical distribution function]]
* [[Frequency distribution]]

==Further reading==
{{No footnotes|date=November 2009}}
* {{cite book |last=Cameron |first=A. C. |authorlink=A. Colin Cameron |first2=P. K. |last2=Trivedi |title=Regression Analysis of Count Data Book |location= |publisher=Cambridge University Press |edition=Second |year=2013 |isbn=978-1-107-66727-3 |url=https://books.google.com/books?id=qVEwBQAAQBAJ }}
* {{cite book |last=Hilbe |first=Joseph M. |year=2011 |title=Negative Binomial Regression |edition=Second |publisher=Cambridge University Press |isbn=978-0-521-19815-8 |url=https://books.google.com/books?id=0Q_ijxOEBjMC }}
* {{cite book |title=Econometric Analysis of Count Data |first=Rainer |last=Winkelmann | publisher=Springer |edition=Fifth |year=2008 |isbn=978-3-540-77648-2 |doi=10.1007/978-3-540-78389-3 }}

{{DEFAULTSORT:Count Data}}
[[Category:Statistical data types]]
[[Category:Quantity]]
[[Category:Units of amount]]</text>
      <sha1>752awku0tylc99ya3wx8n7rh0gr74ua</sha1>
    </revision>
  </page>
  <page>
    <title>Cut rule</title>
    <ns>0</ns>
    <id>1038753</id>
    <revision>
      <id>867480599</id>
      <parentid>791881930</parentid>
      <timestamp>2018-11-06T00:16:03Z</timestamp>
      <contributor>
        <ip>81.158.102.144</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1123">{{unreferenced|date=July 2017}}
In [[mathematical logic]], the '''cut rule''' is an [[inference rule]] of [[sequent calculus]]. It is a generalisation of the classical [[modus ponens]] inference rule.  Its meaning is that, if a formula ''A'' appears as a conclusion in one proof and a hypothesis in another, then another proof in which the formula ''A'' does not appear can be deduced.  In the particular case of the modus ponens, for example occurrences of ''man'' are eliminated of ''Every man is mortal, Socrates is a man'' to deduce ''Socrates is mortal''.

== Formal notation ==
Formal notation in sequent calculus notation :
;cut:
: &lt;math&gt;
\cfrac{\Gamma \vdash A, \Delta \qquad \Gamma', A \vdash \Delta'} {\Gamma, \Gamma' \vdash \Delta, \Delta'} &lt;/math&gt;

== Elimination ==
The cut rule is the subject of an important theorem, the [[cut elimination theorem]]. It states that any judgement that possesses a proof in the sequent calculus that makes use of the cut rule also possesses a cut-free proof, that is, a proof that does not make use of the cut rule.

[[Category:Rules of inference]]
[[Category:Logical calculi]]</text>
      <sha1>bkqhdny5amc0ge0dmroi119kdvu981t</sha1>
    </revision>
  </page>
  <page>
    <title>Cutting sequence</title>
    <ns>0</ns>
    <id>33509133</id>
    <revision>
      <id>824983982</id>
      <parentid>678468455</parentid>
      <timestamp>2018-02-10T19:58:49Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* References */ [[Valérie Berthé]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1488">[[File:Fibonacci word cutting sequence.png|thumb|350px|The [[Fibonacci word]] is an example of a [[Sturmian word]]. The start of the cutting sequence shown here illustrates the start of the word 0100101001.]]
In [[digital geometry]], a '''cutting sequence''' is a [[sequence]] of symbols whose elements correspond to the individual grid lines crossed ("cut") as a [[curve]] crosses a [[square grid]].&lt;ref&gt;{{Cite journal | last1 = Monteil | first1 = T. | doi = 10.4204/EPTCS.63.21 | title = The complexity of tangent words | journal = Electronic Proceedings in Theoretical Computer Science | volume = 63 | pages = 152 | year = 2011 | pmid =  | pmc = }}&lt;/ref&gt;

[[Sturmian word]]s are a special case of cutting sequences where the curves are [[straight line]]s of [[irrational number|irrational]] slope.&lt;ref name=PF152&gt;Pytheas Fogg (2002) p.152&lt;/ref&gt;

== References ==
{{reflist}}
* {{cite book | last=Pytheas Fogg | first=N. | editor1-first=Valérie | editor1-last = Berthé |editor1-link = Valérie Berthé| editor2-last = Ferenczi | editor2-first= Sébastien | editor3-last= Mauduit | editor3-first= Christian | editor4-last= Siegel | editor4-first= A. | title=Substitutions in dynamics, arithmetics and combinatorics | series=Lecture Notes in Mathematics | volume=1794 | location=Berlin | publisher=[[Springer-Verlag]] | year=2002 | isbn=3-540-44141-7 | zbl=1014.11015 }}

{{combin-stub}}

[[Category:Discrete mathematics]]
[[Category:Digital geometry]]
[[Category:Sequences and series]]</text>
      <sha1>dnjf3qm5ssk7eyq1vuqwmsw6u8bzu1k</sha1>
    </revision>
  </page>
  <page>
    <title>Deviant logic</title>
    <ns>0</ns>
    <id>4135768</id>
    <revision>
      <id>868872596</id>
      <parentid>822109929</parentid>
      <timestamp>2018-11-15T00:05:23Z</timestamp>
      <contributor>
        <username>Trade</username>
        <id>30525710</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3899">{{Tone|date=March 2011}}

Philosopher [[Susan Haack]]&lt;ref&gt;{{cite book |last= Haack |first=Susan |authorlink=Susan Haack |date=1996 |title= '''Deviant Logic, Fuzzy Logic: Beyond the Formalism''' |publisher=Chicago: The University of Chicago Pres |page=xxvi-291 |isbn=9780226311340}} (First appeared in 1974 as ''Deviant Logic'', published by Cambridge University Press. The 1996 edition includes some additional essays published between 1973 and 1980, particularly on fuzzy logic.)&lt;/ref&gt; uses the term "'''deviant logic'''" to describe certain [[non-classical logic|non-classical]] [[systems of logic]]. In these logics,

* the [[Set (mathematics)|set]] of [[well-formed formula]]s generated equals the set of well-formed formulas generated by classical logic.
* the set of [[theorem]]s generated is different from the set of theorems generated by classical logic.

The set of theorems of a deviant logic can differ in any possible way from classical logic's set of theorems: as a proper [[subset]], superset, or fully exclusive set. A notable example of this is the trivalent logic developed by [[Poles|Polish]] [[logician]] and [[mathematician]] [[Jan Łukasiewicz]]. Under this system, any theorem necessarily dependent on classical logic's [[principle of bivalence]] would fail to be valid.  The term first appears in Chapter 6 of [[Willard Van Orman Quine]]'s ''Philosophy of Logic'', New Jersey: Prentice Hall (1970), which is cited by Haack on p.&amp;nbsp;15 of her book.

==Quasi-deviant and extended logics==
Haack also described what she calls a ''quasi''-deviant logic. These logics are different from pure deviant logics in that:

* the set of well-formed formulas generated is a proper superset of the set of well-formed formulas generated by classical logic.
* the set of theorems generated is a proper superset of the set of theorems generated by classical logic, both in that the quasi-deviant logic generates novel theorems using well-formed formulas held in common with classical logic, as well as novel theorems using novel well-formed formulas.

Finally, Haack defined a class of merely ''extended'' logics. In these,

* the set of well-formed formulas generated is a proper superset of the set of well-formed formulas generated by classical logic.
* the set of theorems generated is a proper superset of the set of theorems generated by classical logic, but only in that the novel theorems generated by the extended logic are only a result of novel well-formed formulas.

Some systems of [[modal logic]] meet this definition. In such systems, any novel theorem would not parse in classical logic due to modal operators. While deviant and quasi-deviant logics are typically proposed as rivals to classical logic, the impetus behind extended logics is normally only to provide a supplement to it.

== Two decades later ==
[[Achille Varzi (philosopher)|Achille Varzi]] in his review&lt;ref&gt;{{cite journal |last=Varzi |first=Achille |journal=[[The Philosophical Review]] |volume=107 |issue=3 |page=468-471 |url=http://www.columbia.edu/~av72/papers/PhilReview(Review)_1998.pdf |title=Review |access-date=2011-04-10 |archive-url=https://web.archive.org/web/20160304064005/http://www.columbia.edu/~av72/papers/PhilReview(Review)_1998.pdf# |archive-date=2016-03-04 |dead-url=no |df= }}&lt;/ref&gt; of the 1996 edition of Haack's book writes that the survey did not stand well the test of time, particularly with the "extraordinary proliferation of nonclassical logics in the past two decades—paraconsistent logics, linear logics, substructural logics, nonmonotonic logics, innumerable other logics for AI and computer science." He also finds that Haack's account of [[vagueness]] "is now seriously defective." He concedes however that "as a defense of a philosophical position, ''Deviant Logic'' retains its significance."

==References==
{{Reflist|colwidth=30em}}

[[Category:Non-classical logic]]</text>
      <sha1>e80notxd88bh5i5cus4s0t3xy3spg54</sha1>
    </revision>
  </page>
  <page>
    <title>Euler Book Prize</title>
    <ns>0</ns>
    <id>30721658</id>
    <revision>
      <id>829155183</id>
      <parentid>824518459</parentid>
      <timestamp>2018-03-06T23:54:57Z</timestamp>
      <contributor>
        <username>Apokrif</username>
        <id>173030</id>
      </contributor>
      <minor/>
      <comment>/* Winners */ Magical Mathematics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5430">The '''Euler Book Prize''' is an award named after Swiss mathematician and physicist [[Leonhard Euler]] (1707-1783) and given annually at the [[Joint Mathematics Meetings]] by the [[Mathematical Association of America]] to an outstanding book in [[mathematics]] that is likely to improve the public view of the field.&lt;ref name="maa"&gt;[https://www.maa.org/programs-and-communities/member-communities/maa-awards/writing-awards/euler-book-prize Euler Book Prize].&lt;/ref&gt;

The prize was founded in 2005 with funds provided by mathematician [[Paul Halmos]] (1916–2006) and his wife Virginia. It was first given in 2007; this date was chosen to honor the 300th anniversary of Euler's birth, as part of the MAA "Year of Euler" celebration.&lt;ref name="maa"/&gt;&lt;ref name="jmm07"&gt;{{citation|title=JMM 2007: Report of the MAA Secretary|journal=Focus|publisher=[[Mathematical Association of America]]|url=http://www.maa.org/pubs/february07web.pdf|first=Martha J.|last=Siegel|authorlink=Martha Siegel|date=February 2007|pages=8–10}}.&lt;/ref&gt;

==Winners==
*2007: [[John Derbyshire]], ''[[Prime Obsession|Prime Obsession: Bernhard Riemann and the Greatest Unsolved Problem in Mathematics]]'' (Joseph Henry Press, 2003).&lt;ref name="maa"/&gt;&lt;ref name="jmm07"/&gt; The main subject of this popular-audience book is the [[Riemann hypothesis]], concerning the location of the zeros of the [[Riemann zeta function]], and its application to the distribution of [[prime number]]s.&lt;ref&gt;{{citation|first=Timothy|last=Gowers|authorlink=Timothy Gowers|journal=[[Nature (journal)|Nature]]|title=Prime time for mathematics|date=October 9, 2003|volume=425|issue=562|doi=10.1038/425562a}}.&lt;/ref&gt;&lt;ref&gt;[http://www.maa.org/news/AwardsJMM07-Citations.html Euler Prize citation], MAA, 2007, retrieved 2011-02-01.&lt;/ref&gt; Due to a miscommunication, Derbyshire missed the award ceremony.&lt;ref&gt;{{citation| title=Big Easy| journal=[[National Review]]| date=January 8, 2007| first=John| last=Derbyshire| authorlink=John Derbyshire |url=http://www.nationalreview.com/articles/219661/big-easy/john-derbyshire}}.&lt;/ref&gt;
*2008: Benjamin Yandell, ''The Honors Class: Hilbert's Problems and Their Solvers'' (AK Peters, 2002).&lt;ref name="maa"/&gt; This book intertwines the stories of the solutions to [[Hilbert's problems]] with the biographies of its solvers. The award was given posthumously to Yandell, who died in 2004.&lt;ref&gt;[http://www.maa.org/news/h-MAA-Euler08.pdf Euler prize citation for Yandell], MAA, 2008, retrieved 2011-02-01.&lt;/ref&gt;
*2009: [[Siobhan Roberts]], ''King of Infinite Space: Donald Coxeter, the Man Who Saved Geometry'' (Walker and Company, 2006).&lt;ref name="maa"/&gt; This biography of [[Harold Scott MacDonald Coxeter]] also describes the history of geometry and Coxeter's contributions to the field.&lt;ref&gt;{{citation|url=https://www.washingtonpost.com/wp-dyn/content/article/2006/09/05/AR2006090501286.html|journal=[[Washington Post]]|title=Symmetry in Motion|first=Jordan|last=Ellenberg|date=September 6, 2006}}.&lt;/ref&gt;&lt;ref&gt;[http://www.maa.org/awards/jmm09PB.pdf January 2009 Prizes and Award], [[Mathematical Association of America]], retrieved 2011-02-01.&lt;/ref&gt;
*2010: David S. Richeson, ''Euler’s Gem: The Polyhedron Formula and the Birth of Topology'' (Princeton University Press, 2008).&lt;ref name="maa"/&gt; Richeson relates the history of [[Euler characteristic|Euler's formula]] {{math|1=''V'' &amp;minus; ''E'' + ''F'' = 2}} connecting the numbers of vertices, edges, and faces of a [[convex polyhedron]]. The story leads from Euler's first observation in 1750 to modern [[topology]] and the mathematics of [[William Thurston]] and [[Grigori Perelman]].&lt;ref&gt;[http://www.ams.org/ams/prizebooklet-2010.pdf January 2010 Prizes and Awards], [[American Mathematical Society]], retrieved 2011-02-01.&lt;/ref&gt;
*2011: [[Timothy Gowers]], ''[[The Princeton Companion to Mathematics]]'' (Princeton University Press, 2008). This book provides an overview of modern research mathematics; Gowers edited the contributions of 133 distinguished mathematicians as well as writing many of the entries in it himself.&lt;ref&gt;[http://www.ams.org/profession/prize-booklet-2011.pdf January 2011 Prizes and Awards], [[American Mathematical Society]], retrieved 2011-02-01.&lt;/ref&gt;
*2012: [[Daina Taimina]], ''Crocheting Adventures with hyperbolic planes'', A. K. Peters 2009
*2013: [[Persi Diaconis]], [[Ronald Graham]], ''Magical Mathematics . The mathematical ideas that animate great magic tricks'', Princeton University Press 2011
*2014: [[Steven Strogatz]], ''The Joy of x: A Guided Tour of Math, from One to Infinity'', Houghton Mifflin Harcourt, 2012
*2015: [[Edward Frenkel]], ''Love and Math: The Heart of Hidden Reality'', Basic Books, 2013
*2016: [[Jordan Ellenberg]], ''How Not to Be Wrong: The Power of Mathematical Thinking'', Penguin Press, 2014
*2017: [[Ian Stewart (mathematician)|Ian Stewart]], ''In Pursuit of the Unknown: 17 Equations That Changed the World'', Basic Books, New York, 2012 &lt;ref&gt;[http://www.ams.org/profession/prizes-awards/PrizeBooklet-2017.pdf?_ga=1.147771504.675213196.1483718656 Prize Booklet 2017, page 10]&lt;/ref&gt; &lt;ref&gt;[http://jointmathematicsmeetings.org/meetings/national/jmm2017/2180_prizes-all Laureate 2017]&lt;/ref&gt;
*2018: [[Matt Parker]], ''Things to Make and Do in the Fourth Dimension'', Farrar, Straus and Giroux (2014)

==References==
{{reflist|colwidth=30em}}

[[Category:Mathematics awards]]
[[Category:Awards of the Mathematical Association of America]]</text>
      <sha1>r8j5zihbk5rsu5hpf95qv8vgsn16vhv</sha1>
    </revision>
  </page>
  <page>
    <title>FastICA</title>
    <ns>0</ns>
    <id>1977119</id>
    <revision>
      <id>864056938</id>
      <parentid>864056291</parentid>
      <timestamp>2018-10-14T20:34:10Z</timestamp>
      <contributor>
        <username>DWHChemE</username>
        <id>28233782</id>
      </contributor>
      <minor/>
      <comment>improved readability of product wp'*wj*wj by wp'*wj*wj = (wp'*wj)*wj</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7781">{{one source|date=April 2013}}
'''FastICA''' is an efficient and popular algorithm for [[independent component analysis]] invented by Aapo Hyvärinen at [[Helsinki University of Technology]].&lt;ref name = "Hyvarinen"&gt;{{Cite journal | last1 = Hyvärinen | first1 = A. | last2 = Oja | first2 = E. | doi = 10.1016/S0893-6080(00)00026-5 | title = Independent component analysis: Algorithms and applications | journal = Neural Networks | volume = 13 | issue = 4–5 | pages = 411–430 | year = 2000 | pmid =  10946390| url = http://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf| pmc = }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Hyvarinen | first1 = A. | title = Fast and robust fixed-point algorithms for independent component analysis | doi = 10.1109/72.761722 | journal = IEEE Transactions on Neural Networks | volume = 10 | issue = 3 | pages = 626–634 | year = 1999 | pmid =  18252563| url = http://www.cs.helsinki.fi/u/ahyvarin/papers/TNN99new.pdf| pmc = }}&lt;/ref&gt; Like most ICA algorithms, FastICA seeks an orthogonal rotation of [[FastICA#Prewhitening the data|prewhitened]] data, through a fixed-point [[iterative method|iteration scheme]], that maximizes a measure of [[non-Gaussianity]] of the rotated components. Non-gaussianity serves as a proxy for [[statistical independence]], which is a very strong condition and requires infinite data to verify. FastICA can also be alternatively derived as an approximative Newton iteration.

== Algorithm ==

=== ''Prewhitening'' the data ===
Let the &lt;math&gt;\mathbf{X} := (x_{ij}) \in \mathbb{R}^{N \times M}&lt;/math&gt; denote the input data matrix, &lt;math&gt;M&lt;/math&gt; the number of columns corresponding with the number of samples of mixed signals and &lt;math&gt;N&lt;/math&gt; the number of rows corresponding with the number of independent source signals. The input data matrix &lt;math&gt;\mathbf{X}&lt;/math&gt; must be ''prewhitened'', or centered and whitened, before applying the FastICA algorithm to it.

*Centering the data entails demeaning each component of the input data &lt;math&gt;\mathbf{X}&lt;/math&gt;, that is,
&lt;center&gt;&lt;math&gt; x_{ij} \leftarrow x_{ij} - \frac{1}{M} \sum_{j^{\prime}} x_{ij^{\prime}}&lt;/math&gt; &lt;/center&gt;
:for each &lt;math&gt;i =1,\ldots,N&lt;/math&gt; and &lt;math&gt;j = 1, \ldots, M &lt;/math&gt;. After centering, each row of &lt;math&gt;\mathbf{X}&lt;/math&gt; has an [[expected value]] of &lt;math&gt;0&lt;/math&gt;.
*''Whitening'' the data requires a [[linear transformation]]  &lt;math&gt;\mathbf{L}: \mathbb{R}^{N \times M} \to \mathbb{R}^{N \times M}&lt;/math&gt; of the centered data so that the components of &lt;math&gt;\mathbf{L}(\mathbf{X})&lt;/math&gt; are uncorrelated and have variance one. More precisely, if &lt;math&gt;\mathbf{X}&lt;/math&gt; is a centered data matrix, the covariance of &lt;math&gt;\mathbf{L}_{\mathbf{x}} := \mathbf{L}(\mathbf{X})&lt;/math&gt; is the &lt;math&gt;(N \times N)&lt;/math&gt;-dimensional identity matrix, that is,
&lt;center&gt;&lt;math&gt; \mathrm{E}\left \{ \mathbf{L}_{\mathbf{x}} \mathbf{L}_{\mathbf{x}}^{T} \right \} = \mathbf{I}_N&lt;/math&gt;&lt;/center&gt;
: A common method for whitening is by performing an [[eigenvalue decomposition]] on the [[covariance matrix]] of the centered data &lt;math&gt;\mathbf{X}&lt;/math&gt;, &lt;math&gt; E\left \{  \mathbf{X} \mathbf{X}^{T} \right \} = \mathbf{E}\mathbf{D}\mathbf{E}^T&lt;/math&gt;, where &lt;math&gt;\mathbf{E}&lt;/math&gt; is the matrix of eigenvectors and &lt;math&gt;\mathbf{D}&lt;/math&gt; is the diagonal matrix of eigenvalues. The whitened data matrix is defined thus by
&lt;center&gt;&lt;math&gt; \mathbf{X} \leftarrow \mathbf{E}\mathbf{D}^{-1/2}\mathbf{E}^T\mathbf{X}. &lt;/math&gt;&lt;/center&gt;

=== Single component extraction ===

The iterative algorithm finds the direction for the weight vector &lt;math&gt;\mathbf{w} \in \mathbb{R}^N&lt;/math&gt;
that maximizes a measure of non-Gaussianity of the projection &lt;math&gt;\mathbf{w}^T \mathbf{X}&lt;/math&gt;, 
with &lt;math&gt;\mathbf{X} \in \mathbb{R}^{N \times M}&lt;/math&gt; denoting a [[FastICA#Prewhitening the data|prewhitened]] data matrix as described above.
Note that &lt;math&gt;\mathbf{w}&lt;/math&gt; is a column vector. To measure non-Gaussianity, FastICA relies on a nonquadratic [[nonlinear]] [[function (mathematics)|function]] &lt;math&gt;f(u)&lt;/math&gt;, its first derivative &lt;math&gt;g(u)&lt;/math&gt;, and its second derivative &lt;math&gt;g^{\prime}(u)&lt;/math&gt;. Hyvärinen states that the functions 
&lt;center&gt;&lt;math&gt;
f(u) = \log \cosh (u), \quad  g(u) = \tanh (u), \quad \text{and} \quad {g}'(u) = 1-\tanh^2(u), 
&lt;/math&gt;&lt;/center&gt;
are useful for general purposes, while 
&lt;center&gt;&lt;math&gt;
f(u) = -e^{-u^2/2}, \quad g(u) = u e^{-u^2/2}, \quad \text{and} \quad {g}'(u) = (1-u^2) e^{-u^2/2}
&lt;/math&gt;&lt;/center&gt; 
may be highly robust.&lt;ref name ="Hyvarinen" /&gt; The steps for extracting the weight vector &lt;math&gt;\mathbf{w}&lt;/math&gt; for single component in FastICA are the following: 
# Randomize the initial weight vector &lt;math&gt;\mathbf{w}&lt;/math&gt;
# Let &lt;math&gt; 
   \mathbf{w}^+ \leftarrow E\left\{\mathbf{X} g(\mathbf{w}^T \mathbf{X})^T\right\} - 
                  E\left\{g'(\mathbf{w}^T \mathbf{X})\right\}\mathbf{w} 
      &lt;/math&gt;, where &lt;math&gt;E\left\{...\right\}&lt;/math&gt; means averaging over all column-vectors of matrix &lt;math&gt;\mathbf{X}&lt;/math&gt;
# Let &lt;math&gt; \mathbf{w} \leftarrow \mathbf{w}^+ / \|\mathbf{w}^+\| &lt;/math&gt;
# If not converged, go back to 2

=== Multiple component extraction ===

The single unit iterative algorithm estimates only one weight vector which extracts a single component. Estimating additional components that are mutually "independent" requires repeating the algorithm to obtain linearly independent projection vectors - note that the notion of  [[Independence (probability theory)|independence]] here refers to maximizing non-Gaussianity in the estimated components. Hyvärinen provides several ways of extracting multiple components with the simplest being the following. Here, &lt;math&gt;\mathbf{1}&lt;/math&gt; is a column vector of 1's of dimension &lt;math&gt;M&lt;/math&gt;.

'''Algorithm''' FastICA
:'''Input:''' &lt;math&gt; C &lt;/math&gt; Number of desired components
:'''Input:''' &lt;math&gt; \mathbf{X} \in \mathbb{R}^{N \times M} &lt;/math&gt; Prewhitened matrix, where each column represents an &lt;math&gt;N&lt;/math&gt;-dimensional sample, where &lt;math&gt; C &lt;= N &lt;/math&gt;
:'''Output:''' &lt;math&gt; \mathbf{W} \in \mathbb{R}^{N \times C} &lt;/math&gt; Un-mixing matrix where each column projects &lt;math&gt; \mathbf{X} &lt;/math&gt; onto independent component. 
:'''Output:''' &lt;math&gt; \mathbf{S} \in \mathbb{R}^{C \times M} &lt;/math&gt; Independent components matrix, with &lt;math&gt;M&lt;/math&gt; columns representing a sample with &lt;math&gt; C &lt;/math&gt;  dimensions.
 
  '''for''' p '''in''' 1 to C:
     ''&lt;math&gt;\mathbf{w_p} \leftarrow&lt;/math&gt; Random vector of length N
     '''while''' &lt;math&gt;\mathbf{w_p}&lt;/math&gt; changes
         ''&lt;math&gt;\mathbf{w_p} \leftarrow \frac{1}{M}\mathbf{X} g(\mathbf{w_p}^T \mathbf{X})^T - \frac{1}{M}g'(\mathbf{w_p}^T\mathbf{X})\mathbf{1} \mathbf{w_p}&lt;/math&gt;
         ''&lt;math&gt;\mathbf{w_p} \leftarrow \mathbf{w_p} - \sum_{j = 1}^{p-1} (\mathbf{w_p}^T\mathbf{w_j})\mathbf{w_j}&lt;/math&gt;''
         ''&lt;math&gt;\mathbf{w_p} \leftarrow \frac{\mathbf{w_p}}{\|\mathbf{w_p}\|}&lt;/math&gt;

 
 
  '''Output:''' &lt;math&gt; \mathbf{W} = \begin{bmatrix} \mathbf{w_1},  \dots,  \mathbf{w_C} \end{bmatrix}
             &lt;/math&gt;&lt;br&gt;
  
  '''Output:''' &lt;math&gt; 
             \mathbf{S} = \mathbf{W^T}\mathbf{X}&lt;/math&gt;

== See also ==

* [[Unsupervised learning]]
* [[Machine learning]]
* The [[IT++]] library features a FastICA implementation in [[C++]]
* [[Infomax]]

==References==

{{Reflist}}

==External links==
* [http://www.cis.hut.fi/projects/ica/fastica/ FastICA package for Matlab or Octave]
* [https://cran.r-project.org/web/packages/fastICA/index.html fastICA package] in [[R programming language]]
* [http://sourceforge.net/projects/fastica FastICA in Java] on [[SourceForge]]
* [http://rapid-i.com/wiki/index.php?title=Independent_Component_Analysis FastICA in Java] in [[RapidMiner]].

[[Category:Factor analysis]]
[[Category:Computational statistics]]
[[Category:Machine learning algorithms]]</text>
      <sha1>ocvmgwjppvzwlhydvlwbfoqskintnan</sha1>
    </revision>
  </page>
  <page>
    <title>Fixed-point space</title>
    <ns>0</ns>
    <id>1461517</id>
    <revision>
      <id>849172621</id>
      <parentid>784640285</parentid>
      <timestamp>2018-07-07T02:00:35Z</timestamp>
      <contributor>
        <username>محمد عصام</username>
        <id>19379913</id>
      </contributor>
      <comment>Added {{[[:Template:no footnotes|no footnotes]]}} tag to article ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1314">{{no footnotes|date=July 2018}}
In [[mathematics]], a [[Hausdorff space]] ''X'' is called a '''fixed-point space''' if every [[continuous function]]  &lt;math&gt;f:X\rightarrow X&lt;/math&gt; has a [[fixed point (mathematics)|fixed point]].

For example, any closed interval [a,b] in &lt;math&gt;\mathbb R&lt;/math&gt; is a fixed point space, and it can be proved from the intermediate value property of real continuous function. The [[open interval]] (''a'',&amp;nbsp;''b''), however, is not a fixed point space. To see it, consider the function 
&lt;math&gt;f(x) = a + \frac{1}{b-a}\cdot(x-a)^2&lt;/math&gt;, for example. 

Any [[linearly ordered]] space that is connected and has a top and a bottom element is a fixed point space. 

Note that, in the definition, we could easily have disposed of the condition that the space is Hausdorff.

==References==
* Vasile I. Istratescu, ''Fixed Point Theory, An Introduction'', D. Reidel, the Netherlands (1981).  {{ISBN|90-277-1224-7}}
* Andrzej Granas and [[James Dugundji]], ''Fixed Point Theory'' (2003) Springer-Verlag, New York, {{ISBN|0-387-00173-5}}
* William A. Kirk and Brailey Sims, ''Handbook of Metric Fixed Point Theory'' (2001), Kluwer Academic, London {{ISBN|0-7923-7073-2}}

[[Category:Fixed points (mathematics)]]
[[Category:Topology]]
[[Category:Topological spaces]]


{{mathanalysis-stub}}</text>
      <sha1>l70umsxvynwv50trfigs9re4qrncatn</sha1>
    </revision>
  </page>
  <page>
    <title>Fulkerson–Chen–Anstee theorem</title>
    <ns>0</ns>
    <id>43198751</id>
    <revision>
      <id>814890750</id>
      <parentid>781788160</parentid>
      <timestamp>2017-12-11T14:53:54Z</timestamp>
      <contributor>
        <username>7heRolf</username>
        <id>27778502</id>
      </contributor>
      <minor/>
      <comment>/* Other notations */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4601">The '''Fulkerson–Chen–Anstee theorem''' is a result in [[graph theory]], a branch of [[combinatorics]]. It provides one of two known approaches solving the [[digraph realization problem]], i.e. it gives a necessary and sufficient condition for pairs of nonnegative [[integer]]s &lt;math&gt;((a_1,b_1),\ldots,(a_n,b_n))&lt;/math&gt; to be the [[directed graph|indegree]]-[[directed graph|outdegree]] pairs of a [[directed graph|simple directed graph]]; a sequence obeying these conditions is called "digraphic". [[D. R. Fulkerson]] &lt;ref name="Fulkerson"&gt;D.R. Fulkerson: ''Zero-one matrices with zero trace.'' In: ''Pacific J. Math.'' No. 12, 1960, pp. 831–836&lt;/ref&gt; (1960) obtained a characterization analogous to the classical [[Erdős–Gallai theorem]] for graphs, but in contrast to this solution with exponentially many inequalities. In 1966 Chen &lt;ref name="Chen"&gt;Wai-Kai Chen: ''On the realization of a (''p'',''s'')-digraph with prescribed degrees .'' In: ''Journal of the Franklin Institute'' No. 6, 1966, pp. 406–422&lt;/ref&gt; improved this result in demanding the additional constraint that the integer pairs must be sorted in non-increasing lexicographical order leading to n inequalities. Anstee &lt;ref name="Anstee"&gt;Richard Anstee: ''Properties of a class of (0,1)-matrices covering a given matrix.'' In: ''Can. J. Math.'', 1982, pp. 438–453&lt;/ref&gt; (1982) observed in a different context that it is suffient to have &lt;math&gt;a_1\geq\cdots\geq a_n&lt;/math&gt;. Berger &lt;ref name="Berger"&gt;Annabell Berger: ''A Note on the Characterization of Digraphic Sequences'' In: ''Discrete Mathematics'', 2014, pp. 38–41&lt;/ref&gt; reinvented this result and gives a direct proof.

==Theorem statement==
A sequence &lt;math&gt;((a_1,b_1 ),\ldots,(a_n,b_n))&lt;/math&gt; of nonnegative integer pairs with &lt;math&gt;a_1\geq\cdots\geq a_n&lt;/math&gt; is digraphic if and only if &lt;math&gt;\sum_{i=1}^{n}a_i=\sum_{i=1}^{n}b_i&lt;/math&gt; and the following inequality holds for ''k'' such that &lt;math&gt;1 \leq  k \leq n&lt;/math&gt;:

: &lt;math&gt;
\sum^k_{i=1} a_i\leq \sum^k_{i=1} \min(b_i,k-1)+ \sum^n_{i=k+1} \min(b_i,k)
&lt;/math&gt;

==Stronger versions==
Berger &lt;ref name="Berger" /&gt; proved that it suffices to consider the &lt;math&gt;k&lt;/math&gt;th inequality such that &lt;math&gt;1 \leq k &lt; n&lt;/math&gt; with &lt;math&gt;a_k &gt; a_{k+1}&lt;/math&gt; and for &lt;math&gt;k = n&lt;/math&gt;.

==Other notations==
The theorem can also be stated in terms of zero-one [[matrix (mathematics)|matrices]]. The connection can be seen if one realizes that each [[directed graph]] has an [[adjacency matrix]] where the column sums and row sums correspond to &lt;math&gt;(a_1,\ldots,a_n)&lt;/math&gt; and &lt;math&gt;(b_1,\ldots,b_n)&lt;/math&gt;. Note that the diagonal of the matrix only contains zeros. There is a connection to the relation [[majorization]]. We define a sequence &lt;math&gt;(a^*_1,\ldots,a^*_n)&lt;/math&gt; with &lt;math&gt;a^*_k:=|\{b_i|i&gt;k, b_i \geq k\}| + |\{b_i|i \leq k, b_i \geq k-1\}|&lt;/math&gt;. Sequence &lt;math&gt;(a^*_1,\ldots,a^*_n)&lt;/math&gt; can also be determined by a [[corrected Ferrers diagram]]. Consider sequences &lt;math&gt;(a_1,\ldots,a_n)&lt;/math&gt;, &lt;math&gt;(b_1,\ldots,b_n)&lt;/math&gt; and &lt;math&gt;(a^*_1,\ldots,a^*_n)&lt;/math&gt; as &lt;math&gt;n&lt;/math&gt;-dimensional vectors &lt;math&gt;a&lt;/math&gt;, &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;a^*&lt;/math&gt;. Since &lt;math&gt;\sum_{i=1}^k a^*_i = \sum^k_{i=1} \min(b_i,k-1)+ \sum^n_{i=k+1} \min(b_i,k)&lt;/math&gt; by applying the principle of [[double counting (proof technique)|double counting]], the theorem above states that a pair of nonnegative integer sequences &lt;math&gt;(a,b)&lt;/math&gt; with nonincreasing &lt;math&gt;a&lt;/math&gt; is digraphic if and only if vector &lt;math&gt;a^*&lt;/math&gt; majorizes &lt;math&gt;a&lt;/math&gt;.

==Generalization==
A sequence &lt;math&gt;((a_1,b_1 ),\ldots,(a_n,b_n))&lt;/math&gt; of nonnegative integer pairs with &lt;math&gt;a_1\geq\cdots\geq a_n&lt;/math&gt; is digraphic if and only if &lt;math&gt;\sum_{i=1}^{n}a_i=\sum_{i=1}^{n}b_i&lt;/math&gt; and there exists a sequence &lt;math&gt;c&lt;/math&gt; such that the pair &lt;math&gt;(c,b)&lt;/math&gt; is digraphic and &lt;math&gt;c&lt;/math&gt; majorizes &lt;math&gt;a&lt;/math&gt;.&lt;ref name="Berger2"&gt;Annabell Berger: ''The connection between the number of realizations for degree sequences and majorization'' In: ''arXiv1212.5443'', 2012&lt;/ref&gt;

==Characterizations for similar problems==
Similar theorems describe the degree sequences of simple graphs, simple directed graphs with loops, and simple bipartite graphs. The first problem is characterized by the [[Erdős–Gallai theorem]]. The latter two cases, which are equivalent see Berger,&lt;ref name="Berger" /&gt; are characterized by the [[Gale–Ryser theorem]].

==See also==
*[[Kleitman–Wang algorithms]]

==References==
&lt;references /&gt;

{{DEFAULTSORT:Fulkerson-Chen-Anstee theorem}}
[[Category:Theorems in graph theory]]</text>
      <sha1>5stylyavvg1mlo4yk0x9q857f0vp2hi</sha1>
    </revision>
  </page>
  <page>
    <title>General elephant</title>
    <ns>0</ns>
    <id>22955929</id>
    <revision>
      <id>765761424</id>
      <parentid>657048226</parentid>
      <timestamp>2017-02-16T08:34:12Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>{{algebraic-geometry-stub}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="815">{{Orphan|date=December 2012}}

In [[algebraic geometry]], '''''general elephant''''' is an idiosyncratic name for a general element of the anticanonical system of a variety, introduced by {{harvtxt|Reid|1987}}. For 3-folds the '''general elephant problem''' (or conjecture) asks whether general elephants have at most [[du Val singularities]]; this has been proved in several cases.

==References==
*{{Citation | last1=Reid | first1=Miles | author1-link=Miles Reid | title=Algebraic geometry, Bowdoin, 1985 (Brunswick, Maine, 1985) | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Proc. Sympos. Pure Math. |mr=927963 | year=1987 | volume=46 | chapter=Young person's guide to canonical singularities | pages=345–414}}

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>0zjv47xjebkwwv85at7eoco8ytjh10x</sha1>
    </revision>
  </page>
  <page>
    <title>Generality of algebra</title>
    <ns>0</ns>
    <id>31628660</id>
    <revision>
      <id>690695919</id>
      <parentid>645522513</parentid>
      <timestamp>2015-11-15T01:37:22Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>clean up; http-&gt;https (see [[WP:VPR/Archive 127#RfC: Should we convert existing Google and Internet Archive links to HTTPS?|this RfC]]) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2235">In the history of mathematics, the '''generality of algebra''' was a phrase used by [[Augustin-Louis Cauchy]] to describe a method of argument that was used in the 18th century by mathematicians such as [[Leonhard Euler]] and [[Joseph-Louis Lagrange]],&lt;ref name=Jahnke&gt;{{citation|title=A history of analysis|first=Hans Niels|last=Jahnke|publisher=American Mathematical Society|year=2003|isbn=978-0-8218-2623-2|page=131|url=https://books.google.com/books?id=CVRZEXFVsZkC&amp;pg=PA131 }}.&lt;/ref&gt; particularly in manipulating infinite series. According to Koetsier,&lt;ref name=Koetsier&gt;{{citation|first=Teun|last=Koetsier|title=Lakatos' philosophy of mathematics: A historical approach|publisher=North-Holland|year=1991|pages=206&amp;ndash;210}}.&lt;/ref&gt; the generality of algebra principle assumed, roughly, that the algebraic rules that hold for a certain class of expressions can be extended to hold more generally on a larger class of objects, even if the rules are no longer obviously valid.  As a consequence, 18th century mathematicians believed that they could derive meaningful results by applying the usual rules of algebra and calculus that hold for finite expansions even when manipulating infinite expansions.  In works such as ''[[Cours d'Analyse]]'', Cauchy rejected the use of "generality of algebra" methods and sought a more rigorous foundation for [[mathematical analysis]].

An example&lt;ref name=Koetsier/&gt; is Euler's derivation of the series
{{NumBlk|:|&lt;math&gt;\frac{\pi - x}{2} = \sin x + \frac{1}{2}\sin 2x + \frac{1}{3}\sin 3x+\cdots&lt;/math&gt;|{{EquationRef|1}}}}
for &lt;math&gt;0&lt;x&lt;\pi&lt;/math&gt;.  He first evaluated the identity
{{NumBlk|:|&lt;math&gt;\frac{1-r\cos x}{1-2r\cos x + r^2} = 1 + r\cos x + r^2\cos2x+r^3\cos 3x+\cdots&lt;/math&gt;|{{EquationRef|2}}}}
at &lt;math&gt;r=1&lt;/math&gt; to obtain
{{NumBlk|:|&lt;math&gt;0 = \frac{1}{2} + \cos x + \cos 2x + \cos 3x + \cdots.&lt;/math&gt;|{{EquationRef|3}}}}
The infinite series on the right hand side of ({{EquationNote|3}}) diverges for all real &lt;math&gt;x&lt;/math&gt;.  But nevertheless integrating this term-by-term gives ({{EquationNote|1}}), an identity which is known to be true by modern methods.

==References==
{{reflist}}

[[Category:Mathematical analysis]]
[[Category:History of calculus]]


{{mathanalysis-stub}}</text>
      <sha1>t5j87ezw5cj56l34jahblnibqv60qqn</sha1>
    </revision>
  </page>
  <page>
    <title>Irregularity of distributions</title>
    <ns>0</ns>
    <id>10782668</id>
    <revision>
      <id>633317672</id>
      <parentid>626907375</parentid>
      <timestamp>2014-11-11T01:36:29Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Fractions to [[:Category:Fractions (mathematics)]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2958">The '''irregularity of distributions''' problem, stated first by [[Hugo Steinhaus]], is a numerical problem with a surprising result. The problem is to find ''N'' numbers, &lt;math&gt;x_1,\ldots,x_N&lt;/math&gt;, all between 0 and 1, for which the following conditions hold:

* The first two numbers must be in different halves (one less than 1/2, one greater than 1/2).
* The first 3 numbers must be in different thirds (one less than 1/3, one between 1/3 and 2/3, one greater than 2/3).
* The first 4 numbers must be in different fourths.
* The first 5 numbers must be in different fifths.
* etc.

Mathematically, we are looking for a sequence of [[real number]]s

:&lt;math&gt;x_1,\ldots,x_N&lt;/math&gt;

such that for every ''n''&amp;nbsp;&amp;isin;&amp;nbsp;{1,&amp;nbsp;...,&amp;nbsp;''N''} and every ''k''&amp;nbsp;&amp;isin;&amp;nbsp;{1,&amp;nbsp;...,&amp;nbsp;''n''} there is some ''i''&amp;nbsp;&amp;isin;&amp;nbsp;{1,&amp;nbsp;...,&amp;nbsp;''n''} such that

:&lt;math&gt;\frac{k-1}{n} \leq x_i &lt; \frac{k}{n}.&lt;/math&gt;

== Solution ==

The surprising result is that there is a solution up to ''N''&amp;nbsp;=&amp;nbsp;17, but starting at ''N''&amp;nbsp;=&amp;nbsp;18 and above it is impossible.  A possible solution for ''N''&amp;nbsp;≤&amp;nbsp;17 is shown diagrammatically on the right; numerically it is as follows:

[[Image:Irregularity of distributions.png|thumb|right|400px|A possible solution for ''N''&amp;nbsp;=&amp;nbsp;17 shown diagrammatically. In each row ''n'', there are ''n'' “vines” which are all in different ''n''&lt;sup&gt;th&lt;/sup&gt;s. For example, looking at row 5, it can be seen that 0&amp;nbsp;&lt;&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;1/5&amp;nbsp;&lt;&amp;nbsp;''x''&lt;sub&gt;5&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;2/5&amp;nbsp;&lt;&amp;nbsp;''x''&lt;sub&gt;3&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;3/5&amp;nbsp;&lt;&amp;nbsp;''x''&lt;sub&gt;4&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;4/5&amp;nbsp;&lt;&amp;nbsp;''x''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;1.  The numerical values are printed in the article text.]]

: &lt;math&gt;
\begin{align}
x_{1} &amp; = 0.029 \\
x_{2} &amp; = 0.971 \\
x_{3} &amp; = 0.423 \\
x_{4} &amp; = 0.71 \\
x_{5} &amp; = 0.27 \\
x_{6} &amp; = 0.542 \\
x_{7} &amp; = 0.852 \\
x_{8} &amp; = 0.172 \\
x_{9} &amp; = 0.62 \\
x_{10} &amp; = 0.355 \\
x_{11} &amp; = 0.774 \\
x_{12} &amp; = 0.114 \\
x_{13} &amp; = 0.485 \\
x_{14} &amp; = 0.926 \\
x_{15} &amp; = 0.207 \\
x_{16} &amp; = 0.677 \\
x_{17} &amp; = 0.297
\end{align}
&lt;/math&gt;

In this example, considering for instance the first 5 numbers, we have

: &lt;math&gt;0 &lt; x_1 &lt; \frac{1}{5} &lt; x_5 &lt; \frac{2}{5} &lt; x_3 &lt; \frac{3}{5} &lt; x_4 &lt; \frac{4}{5} &lt; x_2 &lt; 1.&lt;/math&gt;

==References==
* H. Steinhaus, ''One hundred problems in elementary mathematics'', [[Basic Books]], New York, 1964, page&amp;nbsp;12
*{{cite journal|author=[[Elwyn Berlekamp|Berlekamp, E. R.]]; [[Ronald L. Graham|Graham, R. L.]]|title=Irregularities in the distributions of finite sequences
 | journal = [[Journal of Number Theory]]|volume=2|year=1970|pages=152–161|mr=0269605|doi=10.1016/0022-314X(70)90015-6}}
* M. Warmus, "A Supplementary Note on the Irregularities of Distributions", ''[[Journal of Number Theory]]'' 8, 260&amp;ndash;263, 1976.

{{DEFAULTSORT:Irregularity Of Distributions}}
[[Category:Fractions (mathematics)]]</text>
      <sha1>euem67wwcxymtow8n58iw5exk83eils</sha1>
    </revision>
  </page>
  <page>
    <title>Join and meet</title>
    <ns>0</ns>
    <id>3956618</id>
    <revision>
      <id>843761256</id>
      <parentid>822334462</parentid>
      <timestamp>2018-05-31T08:38:11Z</timestamp>
      <contributor>
        <username>Church of emacs</username>
        <id>2208837</id>
      </contributor>
      <comment>{{Duplication|dupe=Infimum and supremum}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8095">{{Duplication|dupe=Infimum and supremum}}
[[File:Join and meet.svg|thumb|This [[Hasse diagram]] depicts a partially ordered set with four elements - '''a''', '''b''', the [[maximal element]] equal to the join of '''a''' and '''b''' ('''a''' &amp;or; '''b''') and the [[minimal element]] equal to the meet of '''a''' and '''b''' ('''a''' &amp;and; '''b'''). The join/meet of a maximal/minimal element and another element is the maximal/minimal element and conversely the meet/join of a maximal/minimal element with another element is the other element. Thus every pair in this poset has both a meet and a join and the poset can be classified as a [[lattice (order theory)]].]]

In a [[partially ordered set]] ''P'', the '''join''' and '''meet''' of a [[subset]] ''S'' are respectively the [[supremum]] (least upper bound) of ''S'', denoted &amp;#8897;''S'', and [[infimum]] (greatest lower bound) of ''S'', denoted &amp;#8896;''S''. In general, the join and meet of a subset of a partially ordered set need not exist; when they do exist, they are elements of ''P''. 

Join and meet can also be defined as a [[commutative]], [[associative]] and [[idempotent]] [[Partial function|partial]] [[binary operation]] on pairs of elements from ''P''. If '''a''' and '''b''' are elements from ''P'', the join is denoted as '''a''' &amp;or; '''b''' and the meet is denoted '''a''' &amp;and; '''b'''. 

Join and meet are symmetric [[duality (order theory)|dual]]s with respect to order inversion.  The join/meet of a subset of a [[total order|totally ordered set]] is simply its maximal/minimal element, if such an element exists.

A partially ordered set in which all pairs have a join is a [[join-semilattice]].  Dually, a partially ordered set in which all pairs have a meet is a [[meet-semilattice]].  A partially ordered set that is both a join-semilattice and a meet-semilattice is a [[lattice (order)|lattice]].  A lattice in which every subset, not just every pair, possesses a meet and a join is  a [[complete lattice]].  It is also possible to define a [[partial lattice]], in which not all pairs have a meet or join but the operations (when defined) satisfy certain axioms.{{sfn|Grätzer|1996|p=[https://books.google.com/books?id=SoGLVCPuOz0C&amp;pg=PA52 52]}}

==Partial order approach==
Let ''A'' be a set with a [[partial order]] ≤, and let ''x'' and ''y'' be two elements in ''A''.  An element ''z'' of ''A'' is the meet (or greatest lower bound or infimum) of ''x'' and ''y'', if the following two conditions are satisfied:
# ''z'' ≤ ''x'' and ''z'' ≤ ''y'' (i.e., ''z'' is a lower bound of ''x'' and ''y'').
# For any ''w'' in ''A'', such that {{Nowrap|''w'' ≤ ''x''}} and {{Nowrap|''w'' ≤ ''y''}}, we have {{Nowrap|''w'' ≤ ''z''}} (i.e., ''z'' is greater than or equal to any other lower bound of ''x'' and ''y'').
If there is a meet of ''x'' and ''y'', then it is unique, since if both ''z'' and ''z''&amp;prime; are greatest lower bounds of ''x'' and ''y'', then {{Nowrap|''z'' ≤ ''z''&amp;prime;}} and {{Nowrap|''z''&amp;prime; ≤ ''z''}}, and thus {{Nowrap begin}}''z'' = ''z''&amp;prime;{{Nowrap end}}.  If the meet does exist, it is denoted {{Nowrap|''x'' &amp;and; ''y''}}.
Some pairs of elements in ''A'' may lack a meet, either since they have no lower bound at all, or since none of their lower bounds is greater than all the others.  If all pairs of elements have meets, then the meet is a binary operation on ''A'', and it is easy to see that this operation fulfills the following three conditions: For any elements ''x'', ''y'', and ''z'' in ''A'',
:'''a.'''  ''x'' ∧ ''y'' = ''y'' ∧ ''x'' ([[commutativity]]),
:'''b.'''  ''x'' ∧ (''y'' ∧ ''z'') = (''x'' ∧ ''y'') ∧ ''z'' ([[associativity]]), and
:'''c.'''  ''x'' ∧ ''x'' = ''x'' ([[idempotency]]).

==Universal algebra approach==
By definition, a [[binary operation]] ∧ on a set ''A'' is a ''meet'', if it satisfies the three conditions '''a''', '''b''', and '''c'''.  The pair (''A'',∧) then is a [[meet-semilattice]].  Moreover, we then may define a [[binary relation]] ≤ on ''A'', by stating that {{Nowrap|''x'' ≤ ''y''}} if and only if {{Nowrap begin}}''x'' ∧ ''y'' = ''x''{{Nowrap end}}.  In fact, this relation is a [[partial order]] on ''A''.  Indeed, for any elements ''x'', ''y'', and ''z'' in ''A'',
* ''x'' ≤ ''x'', since ''x'' ∧ ''x'' = ''x'' by '''c''';
* if ''x'' ≤ ''y'' and ''y'' ≤ ''x'', then {{Nowrap begin}}''x'' = ''x'' ∧ ''y'' = ''y'' ∧ ''x'' = ''y''{{Nowrap end}} by '''a'''; and
* if ''x'' ≤ ''y'' and ''y'' ≤ ''z'', then ''x'' ≤ ''z'', since then ''x'' ∧ ''z'' = (''x'' ∧ ''y'') ∧ ''z'' = ''x'' ∧ (''y'' ∧ ''z'') = ''x'' ∧ ''y'' = ''x'' by '''b'''.

Note that both meets and joins equally satisfy this definition: a couple of associated meet and join operations yield partial orders which are the reverse of each other. When choosing one of these orders as the main ones, one also fixes which operation is considered a meet (the one giving the same order) and which is considered a join (the other one).

==Equivalence of approaches==
If (''A'',≤) is a [[partially ordered set]], such that each pair of elements in ''A'' has a meet, then indeed {{Nowrap begin}}''x'' ∧ ''y'' = ''x''{{Nowrap end}} if and only if {{Nowrap|''x'' ≤ ''y''}}, since in the latter case indeed ''x'' is a lower bound of ''x'' and ''y'', and since clearly ''x'' is the ''greatest'' lower bound if and only if it is a lower bound.  Thus, the partial order defined by the meet in the universal algebra approach coincides with the original partial order.

Conversely, if (''A'',∧) is a [[meet-semilattice]], and the partial order ≤ is defined as in the universal algebra approach, and {{Nowrap begin}}''z'' = ''x'' ∧ ''y''{{Nowrap end}} for some elements ''x'' and ''y'' in ''A'', then ''z'' is the greatest lower bound of ''x'' and ''y'' with respect to ≤, since
:''z'' ∧ ''x'' = ''x'' ∧ ''z'' = ''x'' ∧ (''x'' ∧ ''y'') = (''x'' ∧ ''x'') ∧ ''y'' = ''x'' ∧ ''y'' = ''z''
and therefore {{Nowrap|''z'' ≤ ''x''}}. Similarly, {{Nowrap|''z'' ≤ ''y''}}, and if ''w'' is another lower bound of ''x'' and ''y'', then {{Nowrap begin}}''w'' ∧ ''x'' = ''w'' ∧ ''y'' = w{{Nowrap end}}, whence
:''w'' ∧ ''z'' = ''w'' ∧ (''x'' ∧ ''y'') = (''w'' ∧ ''x'') ∧ ''y'' = ''w'' ∧ ''y'' = ''w''.
Thus, there is a meet defined by the partial order defined by the original meet, and the two meets coincide.

In other words, the two approaches yield essentially equivalent concepts, a set equipped with both a binary relation and a binary operation, such that each one of these structures determines the other, and fulfil the conditions for partial orders or meets, respectively.

==Meets of general subsets==
If (''A'',∧) is a meet-semilattice, then the meet may be extended to a well-defined meet of any non-empty finite set, by the technique described in [[iterated binary operation]]s.  Alternatively, if the meet defines or is defined by a partial order, some subsets of ''A'' indeed have [[Infimum#Infima in partially ordered sets|infima]] with respect to this, and it is reasonable to consider such an infimum as the meet of the subset.  For non-empty finite subsets, the two approaches yield the same result, whence either may be taken as a definition of meet.  In the case where ''each'' subset of ''A'' has a meet, in fact (''A'',≤) is a [[complete lattice]]; for details, see [[completeness (order theory)]].

==Notes==
{{reflist}}

==References==
{{refbegin}}
*{{cite book | zbl=1002.06001 | last1=Davey | first1=B.A. | last2=Priestley | first2=H.A. | title=Introduction to Lattices and Order | edition=2nd | location=Cambridge | publisher=[[Cambridge University Press]] | year=2002 | isbn=0-521-78451-4 }}
*{{cite book | first=Steven | last=Vickers | authorlink=Steve Vickers (computer scientist) | title=Topology via Logic | series=Cambridge Tracts in Theoretic Computer Science | volume=5 | isbn=0-521-36062-5 | year=1989 | zbl=0668.54001 }}
{{refend}}

{{DEFAULTSORT:Join And Meet}}
[[Category:Binary operations]]
[[Category:Lattice theory]]
[[Category:Order theory]]</text>
      <sha1>4yim2zc61xmkw10sdem749t5barw9le</sha1>
    </revision>
  </page>
  <page>
    <title>Karl Küpfmüller</title>
    <ns>0</ns>
    <id>5647048</id>
    <revision>
      <id>816727596</id>
      <parentid>786447251</parentid>
      <timestamp>2017-12-23T07:28:46Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1) ([[User:Balon Greyjoy|Balon Greyjoy]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5775">{{Infobox scientist
|name              = Karl Küpfmüller
|birth_date        = {{birth date|1897|10|df=y|6}}
|birth_place       = [[Nuremberg]], [[German Empire]]
|death_date        = {{death date and age|1977|12|26|1897|10|6|df=y}}
|death_place       = [[Darmstadt]], [[Germany]]
|residence         = 
|citizenship       = 
|nationality       = German
|ethnicity         = 
|fields            = [[Electronic engineering]]
|workplaces        = [[Siemens]], &lt;br&gt;[[Gdańsk University of Technology|Danzig Institute of Technology]],&lt;br&gt;
[[Technische Universität Berlin|Berlin Institute of Technology]]
|alma_mater        = Ohm-Polytechnikum (today called: Georg-Simon-Ohm-Hochschule Nürnberg)
|doctoral_advisor  = 
|academic_advisors = 
|doctoral_students = 
|notable_students  = 
|known_for         = [[Küpfmüller's uncertainty principle]] (1924)&lt;br&gt;
[[Nyquist–Shannon sampling theorem]]
|influences        = 
|influenced        = 
|awards            = [[Werner von Siemens Ring]] (1968)
}}

'''Karl Küpfmüller''' (6 October 1897 – 26 December 1977) was a [[Germany|German]] electrical engineer, who was prolific in the areas of communications technology, measurement and control engineering, acoustics, communication theory and theoretical electro-technology.

==Biography==
Küpfmüller was born in [[Nuremberg]], where he studied at the Ohm-Polytechnikum. After returning from military service in [[World War I]], he worked at the telegraph research division of the German Post in Berlin as a co-worker of [[Karl Willy Wagner]], and, from 1921, he was lead engineer at the central laboratory of [[Siemens AG|Siemens &amp; Halske AG]] in the same city.

In 1928 he became full professor of general and theoretical electrical engineering at the ''[[Gdańsk University of Technology|Technische Hochschule]]'' in [[Danzig]], and later held the same position in Berlin. Küpfmüller joined the [[National Socialist Motor Corps]] in 1933. In the following year he also joined the [[Sturmabteilung|SA]]. In 1937 Küpfmüller joined the [[NSDAP]] and became a member of the [[Schutzstaffel|SS]], where he reached the rank of [[Obersturmbannführer]].&lt;ref&gt;Prof. Helmut Maier: ''Forschung als Waffe. Rüstungsforschung in der Kaiser-Wilhelm-Gesellschaft und das Kaiser-Wilhelm-Institut für Metallforschung 1900-1945/48''. Wallstein Verlag, Göttingen 2007, {{ISBN|978-3-8353-0109-2}}, p. 710.&lt;/ref&gt;

Küpfmüller was appointed as director of communication technology Research &amp; Development at the [[Siemens]]-Wernerwerk for telegraphy. In 1941–1945 he was director of the central R&amp;D division at Siemens &amp; Halske in 1937.

Later he was honorary professor at the ''Technische Hochschule Berlin''. In 1968, he received the [[Werner von Siemens Ring]] for his contributions to the theory of [[telecommunication]]s and other electro-technology.

He died at [[Darmstadt]].

==Studies in communication theory==
About 1928, he did the same analysis that [[Harry Nyquist]] did, to show that not more than 2B independent pulses per second could be put through a channel of bandwidth B.  He did this by quantifying the time-bandwidth product ''k'' of various communication signal types, and showing that ''k'' could never be less than 1/2.&lt;ref&gt;K. Küpfmüller, "Über die Dynamik der selbsttätigen Verstärkungsregler", ''Elektrische Nachrichtentechnik'', vol. 5, no. 11, pp. 459-467, 1928. (German) [http://ict.open.ac.uk/classics/2.pdf On the dynamics of automatic gain controllers], (English translation)&lt;/ref&gt;  From his 1931 paper (rough translation from Swedish):&lt;ref&gt;Karl Küpfmüller, "Utjämningsförlopp inom Telegraf- och Telefontekniken", ("Transients in telegraph and telephone engineering"), ''[[Teknisk Tidskrift]]'', no. 9 pp.153-160 and 10 pp.178-182, 1931. (Swedish) [http://runeberg.org/tektid/1931e/0157.html] [http://runeberg.org/tektid/1931e/0182.html]
&lt;/ref&gt;

:"The time law allows comparison of the capacity of each transfer method with various known methods. On the other hand it indicates the limits that the development of technology must stay within. One interesting question for example is where the lower limit for ''k'' lies. The answer is acquired by at least one power change being needed to achieve one signal. So the frequency range must be at least so wide that the settling time becomes less than the duration of a signal, and from this comes ''k''=1/2. So we can never get below this value, no matter how technology develops."

==Textbooks by Küpfmüller==

* K. Küpfmüller, ''Einführung in die theoretische Elektrotechnik'' [Introduction to the theory of electrical engineering]. Berlin: Julius Springer, 1932.
* K. Küpfmüller (revised and extended by W. Mathis and A. Reibiger), ''Theoretische Elektrotechnik: Eine Einführung'' [Theory of electrical engineering: An introduction], 19th ed. New York: Springer-Verlag, 2013.

==References==

{{Reflist}}

==Further reading==

* Bissell, C.C. (2006) [http://oro.open.ac.uk/5575/1/01636314.pdf  ''Karl Küpfmüller, 1928: An early time-domain, closed-loop, stability criterion.''] Historic Perspective. IEEE Control Systems Magazine, 26 (3). 115-116, 126. ISSN 0272-1708 
* [https://web.archive.org/web/20070524181615/http://www.tet.uni-hannover.de/kuepfmueller/Lebenslauf/lebenslauf.htm Kupfmüller biography at the University of Hannover] (German)

{{Authority control}}

{{DEFAULTSORT:Kupfmuller, Karl}}
[[Category:1897 births]]
[[Category:1977 deaths]]
[[Category:People from Nuremberg]]
[[Category:Information theory]]
[[Category:Sturmabteilung personnel]]
[[Category:SS-Obersturmbannführer]]
[[Category:German electrical engineers]]
[[Category:Werner von Siemens Ring laureates]]
[[Category:Communication theorists]]
[[Category:Recipients of the Knights Cross of the War Merit Cross]]</text>
      <sha1>lyihyh2naqvo8bi4cktql0bn74lwbx4</sha1>
    </revision>
  </page>
  <page>
    <title>Knuth's Simpath algorithm</title>
    <ns>0</ns>
    <id>43278241</id>
    <revision>
      <id>801248211</id>
      <parentid>793181687</parentid>
      <timestamp>2017-09-18T15:51:12Z</timestamp>
      <contributor>
        <username>A3nm</username>
        <id>2049718</id>
      </contributor>
      <comment>/* External links */ fix link formatting</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1146">'''Simpath''' is an [[algorithm]] introduced by [[Donald Knuth]] that constructs a [[zero-suppressed decision diagram]] (ZDD) representing all simple paths between two vertices in a given graph.&lt;ref&gt;{{cite book|last1=Knuth|first1=Donald|title=The Art of Computer Programming, Volume 4A|date=2011|publisher=Addison-Wesley Professional: Boston, MA, USA|page=254,275}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Finding All Solutions and Instances of Numberlink and Slitherlink by ZDDs|journal=Algorithms|date=2012|volume=5|pages=176–213|doi=10.3390/a5020176}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
{{Wikiquote}}
{{Commons category|Donald Ervin Knuth}}
* [https://github.com/takemaru/graphillion Graphillion library] which implements the algorithm for manipulating large sets of paths and other structures.
* [http://www-cs-faculty.stanford.edu/~knuth/programs.html#simpath], A CWEB implementation by Donald Knuth.


{{Donald Knuth navbox}}


[[Category:Computer arithmetic algorithms]]
[[Category:Donald Knuth]]
[[Category:Graph algorithms]]
[[Category:Mathematical logic]]
[[Category:Theoretical computer science]]


{{-}}
{{algorithm-stub}}</text>
      <sha1>cugx1nw44r45fxp0atuzrc5slakux64</sha1>
    </revision>
  </page>
  <page>
    <title>Laplace transform</title>
    <ns>0</ns>
    <id>18610</id>
    <revision>
      <id>870981003</id>
      <parentid>869421525</parentid>
      <timestamp>2018-11-28T04:49:35Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <minor/>
      <comment>/* Statistical mechanics */ typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="63028">{{redirect|ℒ|the Lagrangian|Lagrangian mechanics}}
In [[mathematics]], the '''Laplace transform''' is an [[integral transform]] named after its discoverer [[Pierre-Simon Laplace]] ({{IPAc-en|l|ə|ˈ|p|l|ɑ:|s}}).  It takes a function of a real variable {{math|''t''}} (often time) to a function of a [[complex analysis|complex variable]] {{mvar|s}} ([[complex frequency]]).

The Laplace transform is very similar to the [[Fourier transform]].  While the Fourier transform of a function is a [[complex function]] of a ''real'' variable (frequency), the Laplace transform of a function is a complex function of a ''complex variable''.  Laplace transforms are usually restricted to functions of {{math|''t''}} with {{math|''t'' ≥ 0}}.  A consequence of this restriction is that the Laplace transform of a function is a [[holomorphic function]] of the variable {{math|''s''}}.  Unlike the Fourier transform, the Laplace transform of a [[distribution (mathematics)|distribution]] is generally a [[well-behaved]] function.  Techniques of complex variables can also be used to  directly study Laplace transforms.  As a holomorphic function, the Laplace transform has a power series representation.  This power series expresses a function as a linear superposition of [[moment (mathematics)|moments]] of the function.  This perspective has applications in [[probability theory]].

The Laplace transform is invertible on a large class of functions.  The inverse Laplace transform takes a function of a complex variable ''s'' (often frequency) and yields a function of a real variable ''t'' (time).  Given a simple mathematical or functional description of an input or output to a [[system]], the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.&lt;ref&gt;{{harvnb|Korn|Korn|1967|loc=§8.1}}&lt;/ref&gt;  So, for example, Laplace transformation from the [[time domain]] to the [[frequency domain]] transforms differential equations into algebraic equations and [[convolution]] into multiplication.  It has many applications in the sciences and technology.

== History ==
The Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory.&lt;ref&gt;{{citation |url=https://archive.org/details/thorieanalytiqu01laplgoog |title=Théorie analytique des Probabilités |location=Paris |date=1814 |edition=2nd |at=chap.I sect.2-20 |chapter=Des Fonctions génératrices |trans-title=Analytical Probability Theory |trans-chapter=On generating functions |language=fr}}&lt;/ref&gt; Laplace's use of generating functions was similar to what is now known as the z-transform and he gave little attention to the continuous variable case which was discussed by [[Niels Henrik Abel|Abel]].&lt;ref&gt;{{citation |first=N. H. |last=Abel |chapter=Sur les fonctions génératrices et leurs déterminantes |date=1820 |title=Œuvres Complètes |language=fr |publication-date=1839 |volume=II |pages=77–88}} [https://books.google.com/books?id=6FtDAQAAMAAJ&amp;pg=RA2-PA67&amp;lpg=RA2-PA67 1881 edition]&lt;/ref&gt; The theory was further developed in the 19th and early 20th centuries by [[Mathias Lerch|Lerch]],&lt;ref&gt;{{citation |first=M. |last=Lerch |author-link=Mathias Lerch |title=Sur un point de la théorie des fonctions génératrices d'Abel |journal=Acta Math. |volume=27 |date=1903 |pages=339–351 |url=https://projecteuclid.org/euclid.acta/1485882168 |doi=10.1007/BF02421315 |trans-title=Proof of the inversion formula |language=fr}}&lt;/ref&gt; [[Oliver Heaviside|Heaviside]],&lt;ref&gt;{{citation |first=O. |last=Heaviside |author-link=Oliver Heaviside |chapter=The solution of definite integrals by differential transformation |title=Electromagnetic Theory |location=London |at=section 526 |volume=III |chapter-url=https://books.google.com/books?id=y9auR0L6ZRcC&amp;pg=PA234&amp;lpg=PA234|isbn=9781605206189 |date=January 2008 }}&lt;/ref&gt; and [[Thomas John I'Anson Bromwich|Bromwich]].&lt;ref&gt;{{citation |first=T. J. |last=Bromwich |author-link=Thomas John I'Anson Bromwich |title=Normal coordinates in dynamical systems |journal=Proc. London Math. Soc. |volume=15 |pages=401–448 |date=1916 |doi=10.1112/plms/s2-15.1.401}}&lt;/ref&gt; The current widespread use of the transform (mainly in engineering) came about during and soon after World War II&lt;ref&gt;An influential book was: {{citation |first=M. F. |last=Gardner |first2=J. L. |last2=Barnes |title=Transients in Linear Systems studied by the Laplace Transform |date=1942 |location=New York |publisher=Wiley}}&lt;/ref&gt; replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by Doetsch&lt;ref&gt;{{citation |first=G. |last=Doetsch |title=Theorie und Anwendung der Laplacesche Transformation |location=Berlin |date=1937 |publisher=Springer |language=de |trans-title=Theory and Application of the Laplace Transform}} translation 1943&lt;/ref&gt; to whom the name Laplace Transform is apparently due.  

The early history of methods having some similarity to Laplace transform is as follows. From 1744, [[Leonhard Euler]] investigated integrals of the form
: &lt;math&gt; z = \int X(x) e^{ax}\, dx \quad\text{ and }\quad z = \int X(x) x^A \, dx&lt;/math&gt;
as solutions of [[Laplace transform applied to differential equations|differential equations]] but did not pursue the matter very far.&lt;ref&gt;{{harvnb|Euler|1744}}, {{harvnb|Euler|1753}}, {{harvnb|Euler|1769}}&lt;/ref&gt;

[[Joseph Louis Lagrange]] was an admirer of Euler and, in his work on integrating [[probability density function]]s, investigated expressions of the form
: &lt;math&gt; \int X(x) e^{- a x } a^x\, dx,&lt;/math&gt;
which some modern historians have interpreted within modern Laplace transform theory.&lt;ref&gt;{{harvnb|Lagrange|1773}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Grattan-Guinness| 1997|p=260}}&lt;/ref&gt;{{Clarify|date=May 2010}}

These types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations.&lt;ref&gt;{{harvnb|Grattan-Guinness|1997|p=261}}&lt;/ref&gt; However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form
: &lt;math&gt; \int x^s \varphi (x)\, dx,&lt;/math&gt;
akin to a [[Mellin transform]], to transform the whole of a [[difference equation]], in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.&lt;ref&gt;{{harvnb|Grattan-Guinness|1997|pp=261&amp;ndash;262}}&lt;/ref&gt;

Laplace also recognised that [[Joseph Fourier]]'s method of [[Fourier series]] for solving the [[diffusion equation]] could only apply to a limited region of space because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.&lt;ref&gt;{{harvnb|Grattan-Guinness|1997|pp=262&amp;ndash;266}}&lt;/ref&gt;

== Formal definition ==
The Laplace transform of a [[function (mathematics)|function]] {{math|''f''(''t'')}}, defined for all [[real number]]s {{math|''t'' ≥ 0}}, is the function {{math|''F''(''s'')}}, which is a unilateral transform defined by
: &lt;math&gt;F(s) =\int_0^\infty f(t)e^{-st} \, dt&lt;/math&gt;
where ''s'' is a [[complex number]] frequency parameter
: &lt;math&gt;s = \sigma + i \omega&lt;/math&gt;, with real numbers {{math|''σ''}} and {{math|''ω''}}.

An alternate notation for the Laplace transform is &lt;math&gt;\mathcal{L}\{f\}&lt;/math&gt; instead of {{math|''F''}}.

The meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that {{math|''f''}} must be [[locally integrable]] on {{closed-open|0, ∞}}.  For locally integrable functions that decay at infinity or are of [[exponential type]], the integral can be understood to be a (proper) [[Lebesgue integral]]. However, for many applications it is necessary to regard it as a [[conditionally convergent]] [[improper integral]] at {{math|∞}}.  Still more generally, the integral can be understood in a [[distribution (mathematics)|weak sense]], and this is dealt with below.

One can define the Laplace transform of a finite [[Borel measure]] {{math|''μ''}} by the [[Lebesgue integral]]&lt;ref&gt;{{harvnb|Feller|1971|loc=§XIII.1}}&lt;/ref&gt;
: &lt;math&gt;\mathcal{L}\{\mu\}(s) = \int_{[0,\infty)} e^{-st}\, d\mu(t).&lt;/math&gt;

An important special case is where {{math|''μ''}} is a [[probability measure]], for example, the [[Dirac delta function]]. In [[operational calculus]], the Laplace transform of a measure is often treated as though the measure came from a [[probability density function]] {{math|''f''}}.  In that case, to avoid potential confusion, one often writes
: &lt;math&gt;\mathcal{L}\{f\}(s) = \int_{0^-}^\infty f(t)e^{-st} \, dt,&lt;/math&gt;
where the lower limit of {{math|0&lt;sup&gt;−&lt;/sup&gt;}} is shorthand notation for
: &lt;math&gt;\lim_{\varepsilon\rightarrow 0}\int_{-\varepsilon}^\infty.&lt;/math&gt;

This limit emphasizes that any point mass located at {{math|0}} is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the [[Laplace–Stieltjes transform]].

=== Probability theory ===
In [[probability theory|pure]] and [[applied probability]], the Laplace transform is defined as an [[expected value]]. If {{math|''X''}} is a [[random variable]] with [[probability density function]] {{math|''f''}}, then the Laplace transform of {{math|''f''}} is given by the expectation
: &lt;math&gt;\mathcal{L}\{f\}(s) = E\! \left[e^{-sX} \right]\! .&lt;/math&gt;

By [[abuse of notation|convention]], this is referred to as the Laplace transform of the random variable {{math|''X''}} itself. Replacing {{math|''s''}} by {{math|−''t''}} gives the [[moment generating function]] of {{math|''X''}}. The Laplace transform has applications throughout probability theory, including [[first passage time]]s of [[stochastic processes]] such as [[Markov chain]]s, and [[renewal theory]].

Of particular use is the ability to recover the [[cumulative distribution function]] of a continuous random variable {{math|''X''}} by means of the Laplace transform as follows&lt;ref&gt;The cumulative distribution function is the integral of the probability density function.&lt;/ref&gt;
: &lt;math&gt;F_X(x) = \mathcal{L}^{-1}\! \left\{\frac{1}{s}E\left[e^{-sX}\right]\right\}\! (x) = \mathcal{L}^{-1}\! \left\{\frac{1}{s}\mathcal{L}\{f\}(s)\right\}\! (x).&lt;/math&gt;

=== Bilateral Laplace transform ===
{{Main article|Two-sided Laplace transform}}

When one says "the Laplace transform" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the ''bilateral Laplace transform'' or [[two-sided Laplace transform]] by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the [[Heaviside step function]].

The bilateral Laplace transform is defined as follows,
: &lt;math&gt;\mathcal{B}\{f\}(s) = \int_{-\infty}^\infty e^{-st} f(t)\, dt.&lt;/math&gt;

=== Inverse Laplace transform ===
{{Main article|Inverse Laplace transform}}
Two integrable functions have the same Laplace transform only if they differ on a set of [[Lebesgue measure]] zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a [[one-to-one function|one-to-one]] mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space [[Lp space|{{math|''L''&lt;sup&gt;&amp;infin;&lt;/sup&gt;(0, &amp;infin;)}}]], or more generally [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distributions]] (that is, functions of at worst polynomial growth) on {{open-open|0, &amp;infin;}}.  The Laplace transform is also defined and injective for suitable spaces of [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distribution]]s.

In these cases, the image of the Laplace transform lives in a space of [[analytic function]]s in the [[#Region of convergence|region of convergence]].  The [[inverse Laplace transform]] is given by the following [[complex number|complex]] integral, which is known by various names (the '''Bromwich integral''', the '''Fourier–Mellin integral''', and '''Mellin's inverse formula'''):
: &lt;math&gt;f(t) = \mathcal{L}^{-1}\{F\}(t) = \frac{1}{2 \pi i} \lim_{T\to\infty}\int_{\gamma - i T}^{\gamma + i T} e^{st} F(s)\, ds,&lt;/math&gt;
where {{math|''γ''}} is a real number so that the contour path of integration is in the region of convergence of {{math|''F''(''s'')}}. An alternative formula for the inverse Laplace transform is given by [[Post's inversion formula]]. The limit here is interpreted in the weak-* topology.

In practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.

== Region of convergence ==
If {{math|''f''}} is a [[locally integrable]] function (or more generally a Borel measure locally of bounded variation), then the Laplace transform {{math|''F''(''s'')}} of {{math|''f''}} converges provided that the limit
: &lt;math&gt;\lim_{R\to\infty}\int_0^R f(t)e^{-st}\,dt&lt;/math&gt;
exists.

The Laplace transform converges absolutely if the integral
: &lt;math&gt;\int_0^\infty \left|f(t)e^{-st}\right|\,dt&lt;/math&gt;
exists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.

The set of values for which {{math|''F''(''s'')}} converges absolutely is either of the form {{math|Re(''s'') &gt; ''a''}} or else {{math|Re(''s'') ≥ ''a''}}, where {{math|''a''}} is an [[extended real number|extended real constant]], {{math|−∞ ≤ ''a'' ≤ ∞}}.  (This follows from the [[dominated convergence theorem]].) The constant {{math|''a''}} is known as the abscissa of absolute convergence, and depends on the growth behavior of {{math|''f''(''t'')}}.&lt;ref&gt;{{harvnb|Widder|1941|loc=Chapter II, §1}}&lt;/ref&gt; Analogously, the two-sided transform converges absolutely in a strip of the form  {{math|''a'' &lt; Re(''s'') &lt; ''b''}}, and possibly including the lines {{math|1=Re(''s'') = ''a''}} or {{math|1=Re(''s'') = ''b''}}.&lt;ref&gt;{{harvnb|Widder|1941|loc=Chapter VI, §2}}&lt;/ref&gt;  The subset of values of {{math|''s''}} for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is [[analytic function|analytic]] in the region of absolute convergence: this is a consequence of [[Fubini's theorem]] and [[Morera's theorem]]. 

Similarly, the set of values for which {{math|''F''(''s'')}} converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the '''[[region of convergence]]''' (ROC).  If the Laplace transform converges (conditionally) at {{math|1=''s'' = ''s''&lt;sub&gt;0&lt;/sub&gt;}}, then it automatically converges for all {{math|''s''}} with {{math|Re(''s'') &gt; Re(''s''&lt;sub&gt;0&lt;/sub&gt;)}}.  Therefore, the region of convergence is a half-plane of the form {{math|Re(''s'') &gt; ''a''}}, possibly including some points of the boundary line {{math|1=Re(''s'') = ''a''}}.

In the region of convergence {{math|Re(''s'') &gt; Re(''s''&lt;sub&gt;0&lt;/sub&gt;)}}, the Laplace transform of {{math|''f''}} can be expressed by [[integration by parts|integrating by parts]] as the integral
: &lt;math&gt;F(s) = (s-s_0)\int_0^\infty e^{-(s-s_0)t}\beta(t)\,dt,\quad \beta(u) = \int_0^u e^{-s_0t}f(t)\,dt.&lt;/math&gt;

That is, in the region of convergence {{math|''F''(''s'')}} can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.

There are several [[Paley–Wiener theorem]]s concerning the relationship between the decay properties of {{math|''f''}} and the properties of the Laplace transform within the region of convergence.

In engineering applications, a function corresponding to a [[LTI system|linear time-invariant (LTI) system]] is ''stable'' if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region {{math|Re(''s'') ≥ 0}}.  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.

This ROC is used in knowing about the causality and stability of a system.

== Properties and theorems ==
The Laplace transform has a number of properties that make it useful for analyzing linear [[dynamical system]]s. The most significant advantage is that [[derivative|differentiation]] and [[integral|integration]] become multiplication and division, respectively, by  {{math|''s''}} (similarly to [[logarithm]]s changing multiplication of numbers to addition of their logarithms).

Because of this property, the Laplace variable {{math|''s''}} is also known as ''operator variable'' in the {{math|''L''}} domain: either ''derivative operator'' or (for {{math|''s''&lt;sup&gt;−1&lt;/sup&gt;)}} ''integration operator''. The transform turns [[integral equation]]s and [[differential equation]]s to [[polynomial equation]]s, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the time domain.

Given the functions {{math|''f''(''t'')}} and {{math|''g''(''t'')}}, and their respective Laplace transforms {{math|''F''(''s'')}} and {{math|''G''(''s'')}},
: &lt;math&gt;\begin{align}
f(t) &amp;= \mathcal{L}^{-1}\{F(s)\},\\
g(t) &amp;= \mathcal{L}^{-1}\{G(s)\},
\end{align}&lt;/math&gt;

The following '''table''' is a list of properties of unilateral Laplace transform:&lt;ref&gt;{{harvnb|Korn|Korn|1967|pp=226&amp;ndash;227}}&lt;/ref&gt;

{| class="wikitable" id="291017_tableid"
|+ Properties of the unilateral Laplace transform
|-
 !
 ! Time domain
 ! {{math|''s''}} domain
 ! Comment
|-
 ! [[Linearity]]
 | &lt;math&gt; a f(t) + b g(t) \ &lt;/math&gt;
 | &lt;math&gt; a F(s) + b G(s) \ &lt;/math&gt;
 | Can be proved using basic rules of integration.
|-
 ! Frequency-domain derivative
 | &lt;math&gt; t f(t) \ &lt;/math&gt;
 | &lt;math&gt; -F'(s) \ &lt;/math&gt;
 | {{math|''F''′}} is the first [[derivative]] of {{math|''F''}} with respect to {{math|''s''}}.
|-
 ! Frequency-domain general derivative
 | &lt;math&gt; t^{n} f(t) \ &lt;/math&gt;
 | &lt;math&gt; (-1)^{n} F^{(n)}(s) \ &lt;/math&gt;
 | More general form, {{math|''n''}}th derivative of {{math|''F''(''s'')}}.
|-
 ! [[Derivative]]
 | &lt;math&gt; f'(t) \ &lt;/math&gt;
 | &lt;math&gt; s F(s) - f(0^{+}) \ &lt;/math&gt;
 | {{math|''f''}} is assumed to be a [[differentiable function]], and its derivative is assumed to be of [[exponential type]].  This can then be obtained by [[integration by parts]]
|-
 ! Second derivative
 | &lt;math&gt; f''(t) \ &lt;/math&gt;
 | &lt;math&gt; s^2 F(s) - s f(0^{+}) - f'(0^{+}) \ &lt;/math&gt;
 | {{math|''f''}} is assumed twice differentiable and the second derivative to be of exponential type. Follows by applying the Differentiation property to {{math|''f''′(''t'')}}.
|-
 ! General derivative
 | &lt;math&gt; f^{(n)}(t)  \ &lt;/math&gt;
 | &lt;math&gt; s^n F(s) - \sum_{k=1}^{n} s^{n-k} f^{(k-1)}(0^{+}) \ &lt;/math&gt;
 | {{math|''f''}} is assumed to be {{math|''n''}}-times differentiable, with {{math|''n''}}th derivative of exponential type.  Follows by [[mathematical induction]].
|-
 ! [[Frequency|Frequency-domain integration]]
 | &lt;math&gt; \frac{1}{t}f(t)  \ &lt;/math&gt;
 | &lt;math&gt; \int_s^\infty F(\sigma)\, d\sigma \ &lt;/math&gt;
 | This is deduced using the nature of frequency differentiation and conditional convergence.
|-
 ! Time-domain [[integral|integration]]
 | &lt;math&gt; \int_0^t f(\tau)\, d\tau  =  (u * f)(t)&lt;/math&gt;
 | &lt;math&gt; {1 \over s} F(s) &lt;/math&gt;
 | {{math|''u''(''t'')}} is the [[Heaviside step function]] and {{math|(''u''&amp;nbsp;∗&amp;nbsp;''f'')(''t'')}} is the [[convolution]] of {{math|''u''(''t'')}} and {{math|''f''(''t'')}}.
|-
 ! Frequency shifting
 | &lt;math&gt; e^{at} f(t)  \ &lt;/math&gt;
 | &lt;math&gt; F(s - a) \ &lt;/math&gt;
 |
|-
 ! Time shifting
 | &lt;math&gt; f(t - a) u(t - a) \ &lt;/math&gt;
 | &lt;math&gt; e^{-as} F(s) \ &lt;/math&gt;
 | {{math|''u''(''t'')}} is the [[Heaviside step function]]
|-
 ! Time scaling
 | &lt;math&gt;f(at)&lt;/math&gt;
 | &lt;math&gt; \frac{1}{a} F \left ( {s \over a} \right )&lt;/math&gt;
 | &lt;math&gt; a &gt; 0 \ &lt;/math&gt;
|-
 ! [[Multiplication]]
 | &lt;math&gt;f(t)g(t)&lt;/math&gt;
 | &lt;math&gt; \frac{1}{2\pi i}\lim_{T\to\infty}\int_{c - iT}^{c + iT}F(\sigma)G(s - \sigma)\,d\sigma \ &lt;/math&gt;
 | The integration is done along the vertical line {{nowrap|1=Re(''σ'') = ''c''}} that lies entirely within the region of convergence of {{math|''F''}}.&lt;ref&gt;{{harvnb|Bracewell|2000|loc=Table 14.1, p. 385}}&lt;/ref&gt;
|-
 ! [[Convolution]]
 | &lt;math&gt; (f * g)(t) = \int_{0}^{t} f(\tau)g(t - \tau)\,d\tau&lt;/math&gt;
 | &lt;math&gt; F(s) \cdot G(s) \ &lt;/math&gt;
 | 
|-
 ! [[Complex conjugation]]
 | &lt;math&gt; f^*(t) &lt;/math&gt;
 | &lt;math&gt; F^*(s^*) &lt;/math&gt;
 |
|-
 ! [[Cross-correlation]]
 | &lt;math&gt; f(t)\star g(t) &lt;/math&gt;
 | &lt;math&gt; F^*(-s^*)\cdot G(s) &lt;/math&gt;
 |
|-
 ! [[Periodic function]]
 | &lt;math&gt;f(t)&lt;/math&gt;
 | &lt;math&gt;{1 \over 1 - e^{-Ts}} \int_0^T e^{-st} f(t)\,dt &lt;/math&gt;
 | {{math|''f''(''t'')}} is a periodic function of [[periodic function|period]] {{math|''T''}} so that {{math|1=''f''(''t'') = ''f''(''t'' + ''T'')}}, for all {{math|''t'' ≥ 0}}. This is the result of the time shifting property and the [[geometric series]].
|}

* '''[[Initial value theorem]]''':
: &lt;math&gt;f(0^+)=\lim_{s\to \infty}{sF(s)}.&lt;/math&gt;
* '''[[Final value theorem]]''':
: &lt;math&gt;f(\infty)=\lim_{s\to 0}{sF(s)}&lt;/math&gt;, if all [[Pole (complex analysis)|poles]] of ''sF''(''s'') are in the left half-plane.
: The final value theorem is useful because it gives the long-term behaviour without having to perform [[partial fraction]] decompositions or other difficult algebra. If {{math|''F''(''s'')}} has a pole in the right-hand plane or poles on the imaginary axis (e.g., if &lt;math&gt;f(t) = e^t&lt;/math&gt; or &lt;math&gt;f(t) = \sin(t)&lt;/math&gt;), the behaviour of this formula is undefined.

=== Relation to power series ===
The Laplace transform can be viewed as a [[continuous function|continuous]] analogue of a [[power series]]. If  {{math|''a''(''n'')}} is a discrete function of a positive integer {{math|''n''}}, then the power series associated to  {{math|''a''(''n'')}} is the series
:&lt;math&gt;\sum_{n=0}^{\infty} a(n) x^n&lt;/math&gt;
where  {{math|''x''}} is a real variable (see [[Z transform]]). Replacing summation over {{math|''n''}} with integration over  {{math|''t''}}, a continuous version of the power series becomes
:&lt;math&gt;\int_{0}^{\infty} f(t) x^t\, dt&lt;/math&gt;
where the discrete function {{math|''a''(''n'')}} is replaced by the continuous one {{math|''f''(''t'')}}. 

Changing the base of the power from {{math|''x''}} to {{math|''e''}} gives
:&lt;math&gt;\int_{0}^{\infty} f(t) \left(e^{\ln{x}}\right)^t\, dt&lt;/math&gt;

For this to converge for, say, all bounded functions {{math|''f''}}, it is necessary to require that {{math|ln ''x'' &lt; 0}}. Making the substitution {{math|1=&amp;minus;''s'' = ln ''x''}} gives just the Laplace transform:
:&lt;math&gt;\int_{0}^{\infty} f(t) e^{-st}\, dt&lt;/math&gt;

In other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter {{math|''n''}} is replaced by the continuous parameter {{math|''t''}}, and {{math|''x''}} is replaced by {{math|''e''&lt;sup&gt;&amp;minus;''s''&lt;/sup&gt;}}.

=== Relation to moments ===
{{main article|Moment generating function}}
The quantities
:&lt;math&gt;\mu_n = \int_0^\infty t^nf(t)\, dt&lt;/math&gt;

are the ''moments'' of the function {{math|''f''}}.  If the first {{math|''n''}} moments of {{math|''f''}} converge absolutely, then by repeated [[differentiation under the integral]], 
:&lt;math&gt;(-1)^n(\mathcal L f)^{(n)}(0) = \mu_n .&lt;/math&gt;
This is of special significance in probability theory, where the moments of a random variable {{math|''X''}} are given by the expectation values &lt;math&gt;\mu_n=E[X^n]&lt;/math&gt;.  Then, the relation holds
:&lt;math&gt;\mu_n = (-1)^n\frac{d^n}{ds^n}E\left[e^{-sX}\right](0).&lt;/math&gt;

=== Proof of the Laplace transform of a function's derivative ===
It is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:

: &lt;math&gt;\begin{align}
  \mathcal{L} \left\{f(t)\right\} &amp;= \int_{0^-}^\infty e^{-st} f(t)\, dt \\[6pt]
                                  &amp;= \left[\frac{f(t)e^{-st}}{-s} \right]_{0^-}^\infty -
                                       \int_{0^-}^\infty \frac{e^{-st}}{-s} f'(t) \, dt\quad \text{(by parts)} \\[6pt]
                                  &amp;= \left[-\frac{f(0^-)}{-s}\right] + \frac 1 s \mathcal{L} \left\{f'(t)\right\},
\end{align}&lt;/math&gt;

yielding

: &lt;math&gt;\mathcal{L} \{ f'(t) \} = s\cdot\mathcal{L} \{ f(t) \}-f(0^-), &lt;/math&gt;

and in the bilateral case,

: &lt;math&gt; \mathcal{L} \{ f'(t) \} = s \int_{-\infty}^\infty e^{-st} f(t)\,dt  = s \cdot \mathcal{L} \{ f(t) \}. &lt;/math&gt;

The general result

: &lt;math&gt;\mathcal{L} \left\{ f^{(n)}(t) \right\} = s^n \cdot \mathcal{L} \{ f(t) \} - s^{n - 1} f(0^-) - \cdots - f^{(n - 1)}(0^-),&lt;/math&gt;

where {{math|''f''&lt;sup&gt;(''n'')&lt;/sup&gt;}} denotes the {{math|''n''}}th derivative of {{math|''f''}}, can then be established with an [[mathematical induction|inductive]] argument.

=== Evaluating integrals over the positive real axis ===
A useful property of the Laplace transform is the following:

: &lt;math&gt;\int_0^\infty f(x)g(x)\,dx = \int_0^\infty(\mathcal{L} f)(s)\cdot(\mathcal{L}^{-1}g)(s)\,ds &lt;/math&gt;

under suitable assumptions on the behaviour of &lt;math&gt;f,g&lt;/math&gt; in a right neighbourhood of &lt;math&gt;0&lt;/math&gt; and on the decay rate of &lt;math&gt;f,g&lt;/math&gt; in a left neighbourhood of &lt;math&gt;\infty&lt;/math&gt;. The above formula is a variation of [[integration by parts]], with the operators 
&lt;math&gt;\frac{d}{dx}&lt;/math&gt; and &lt;math&gt;\int \,dx&lt;/math&gt; being replaced by &lt;math&gt;\mathcal{L}&lt;/math&gt; and &lt;math&gt;\mathcal{L}^{-1}&lt;/math&gt;. Let us prove the equivalent formulation:

: &lt;math&gt;\int_0^\infty(\mathcal{L} f)(x)g(x)\,dx = \int_0^\infty f(s)(\mathcal{L}g)(s)\,ds. &lt;/math&gt;

By plugging in &lt;math&gt;(\mathcal{L}f)(x)=\int_0^\infty f(s)e^{-sx}\,ds&lt;/math&gt; the left-hand side turns into:

: &lt;math&gt;\int_0^\infty\int_0^\infty f(s)g(x) e^{-sx}\,ds\,dx, &lt;/math&gt;

but assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.

=== Evaluating improper integrals ===
Let &lt;math&gt;\mathcal{L}\left\{f(t)\right\} = F(s)&lt;/math&gt;, then (see the table above)

: &lt;math&gt;\mathcal{L} \left\{\frac{f(t)} t \right\} = \int_s^\infty F(p)\, dp,&lt;/math&gt;

or

: &lt;math&gt;\int_0^\infty \frac{f(t)}{t}e^{-st}\, dt = \int_s^\infty F(p)\, dp.&lt;/math&gt;

Letting {{math|''s'' → 0}}, gives one the identity

: &lt;math&gt;\int_0^\infty \frac{f(t)} t \, dt = \int_0^\infty F(p)\, dp.&lt;/math&gt;

provided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, proceeding formally one has

:&lt;math&gt;
\begin{align}
&amp; \int_0^\infty \frac 1 t ( \cos(at) - \cos(bt) )\, dt =
  \int_0^\infty \left(\frac p {p^2 + a^2} - \frac{p}{p^2 + b^2}\right)\, dp \\[6pt]
= {} &amp; \frac 1 2 \left. \ln\frac{p^2 + a^2}{p^2 + b^2} \right|_{p\,:=\,0}^\infty = \ln b - \ln a.
\end{align}
&lt;/math&gt;

The validity of this identity can be proved by other means. It is an example of a [[Frullani integral]].

Another example is [[Dirichlet integral]].

=== Relationship to other transforms ===

==== Laplace–Stieltjes transform ====
The (unilateral) [[Laplace–Stieltjes transform]] of a function {{math|''g'' : '''R''' → '''R'''}} is defined by the [[Lebesgue–Stieltjes integral]]

: &lt;math&gt;\{\mathcal{L}^*g\}(s) = \int_0^\infty e^{-st} \, dg(t).&lt;/math&gt;

The function {{math|''g''}} is assumed to be of [[bounded variation]].  If {{math|''g''}} is the [[antiderivative]] of {{math|''f''}}:

: &lt;math&gt;g(x) = \int_0^x f(t)\,dt&lt;/math&gt;

then the Laplace–Stieltjes transform of {{math|''g''}} and the Laplace transform of {{math|''f''}} coincide.  In general, the Laplace–Stieltjes transform is the Laplace transform of the [[Stieltjes measure]] associated to {{math|''g''}}.  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace–Stieltjes transform is thought of as operating on its [[cumulative distribution function]].&lt;ref&gt;{{harvnb|Feller|1971|p=432}}&lt;/ref&gt;

==== Fourier transform ====
The [[continuous Fourier transform]] is equivalent to evaluating the bilateral Laplace transform with imaginary argument {{math|1=''s'' = ''iω''}} or {{math|1=''s'' = 2''πfi''}}&lt;ref&gt;{{harvnb|Takacs|1953|p=93}}&lt;/ref&gt; when the condition explained below is fulfilled, 
:&lt;math&gt;\begin{align}
  \hat{f}(\omega) &amp;= \mathcal{F}\{f(t)\} \\[4pt]
                  &amp;= \mathcal{L}\{f(t)\}|_{s = i\omega}  =  F(s)|_{s = i \omega} \\[4pt]
                  &amp;= \int_{-\infty}^\infty e^{-i \omega t} f(t)\,dt~.
\end{align}&lt;/math&gt;

This definition of the Fourier transform requires a prefactor of 1/2 {{math|''π''}} on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the [[frequency spectrum]] of a [[signal (information theory)|signal]] or [[dynamical system]].

The above relation is valid as stated if and only if the region of convergence (ROC) of  {{math|''F''(''s'')}} contains the imaginary axis,  {{math|1=''σ'' = 0}}.

For example, the function {{math|1=''f''(''t'') = cos(''ω''&lt;sub&gt;0&lt;/sub&gt;''t'')}} has a Laplace transform  {{math|1=''F''(''s'') =  ''s''/(''s''&lt;sup&gt;2&lt;/sup&gt; + ''ω''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;)}} whose ROC is {{math|Re(''s'') &gt; 0}}. As {{math|1=''s'' = ''iω''}} is a pole of  {{math|''F''(''s'')}}, substituting  {{math|1=''s'' = ''iω''}} in {{math|''F''(''s'')}} does not yield the Fourier transform of  {{math|''f''(''t'')''u''(''t'')}}, which is proportional to the [[Dirac delta-function]] {{math|''δ''(''ω'' − ''ω''&lt;sub&gt;0&lt;/sub&gt;)}}.

However, a relation of the form
: &lt;math&gt;\lim_{\sigma\to 0^+} F(\sigma+i\omega) = \hat{f}(\omega)&lt;/math&gt;
holds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a [[weak limit]] of measures (see [[vague topology]]).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of [[Paley–Wiener theorem]]s.

==== Mellin transform ====
The [[Mellin transform]] and its inverse are related to the two-sided Laplace transform by a simple change of variables.

If in the Mellin transform
: &lt;math&gt;G(s) = \mathcal{M}\{g(\theta)\} = \int_0^\infty \theta^s g(\theta) \, \frac{d\theta} \theta &lt;/math&gt;
we set {{math|1=''θ'' = ''e''&lt;sup&gt;−''t''&lt;/sup&gt;}} we get a two-sided Laplace transform.

==== Z-transform ====
The unilateral or one-sided [[Z-transform]] is simply the Laplace transform of an ideally sampled signal with the substitution of
: &lt;math&gt; z \stackrel{\mathrm{def}}{{}={}} e^{sT} ,&lt;/math&gt;
where {{math|1=''T'' = 1/''f&lt;sub&gt;s&lt;/sub&gt;''}} is the [[Sampling theorem|sampling]] period (in units of time e.g., seconds) and  {{math|''f&lt;sub&gt;s&lt;/sub&gt;''}} is the [[sampling rate]] (in [[sample (signal)|samples per second]] or [[hertz]]).

Let
: &lt;math&gt; \Delta_T(t) \ \stackrel{\mathrm{def}}{=}\  \sum_{n=0}^{\infty}  \delta(t - n T) &lt;/math&gt;
be a sampling impulse train (also called a [[Dirac comb]]) and
:&lt;math&gt;\begin{align}
  x_q(t) \  &amp;\stackrel{\mathrm{def}}{=}\  x(t) \Delta_T(t) = x(t) \sum_{n=0}^{\infty}  \delta(t - n T) \\
            &amp;= \sum_{n=0}^{\infty} x(n T) \delta(t - n T) = \sum_{n=0}^{\infty} x[n] \delta(t - n T)
\end{align}&lt;/math&gt;
be the sampled representation of the continuous-time {{math|''x''(''t'')}}
: &lt;math&gt; x[n] \stackrel{\mathrm{def}}{{}={}}  x(nT) ~.&lt;/math&gt;

The Laplace transform of the sampled signal {{math|''x''&lt;sub&gt;''q''(''t'')&lt;/sub&gt;}} is
: &lt;math&gt;\begin{align}
  X_q(s) &amp;= \int_{0^-}^\infty x_q(t) e^{-s t} \,dt \\
         &amp;= \int_{0^-}^\infty \sum_{n=0}^\infty x[n] \delta(t - n T) e^{-s t} \, dt \\
         &amp;= \sum_{n=0}^\infty x[n] \int_{0^-}^\infty \delta(t - n T) e^{-s t} \, dt \\
         &amp;= \sum_{n=0}^\infty x[n] e^{-n s T}~.
\end{align}&lt;/math&gt;

This is the precise definition of the unilateral [[Z-transform]] of the discrete function {{math|''x''[''n'']}}

: &lt;math&gt; X(z) = \sum_{n=0}^{\infty} x[n] z^{-n} &lt;/math&gt;
with the substitution of {{math|''z'' → e&lt;sup&gt;''sT''&lt;/sup&gt;}}.

Comparing the last two equations, we find the relationship between the unilateral [[Z-transform]] and the Laplace transform of the sampled signal,
: &lt;math&gt;X_q(s) =  X(z) \Big|_{z=e^{sT}}.&lt;/math&gt;

The similarity between the {{math|''Z''}} and Laplace transforms is expanded upon in the theory of [[time scale calculus]].

==== Borel transform ====
The integral form of the [[Borel summation|Borel transform]]

: &lt;math&gt;F(s) = \int_0^\infty f(z)e^{-sz}\, dz&lt;/math&gt;

is a special case of the Laplace transform for {{math|''f''}} an [[entire function]] of [[exponential type]], meaning that

: &lt;math&gt;|f(z)|\le Ae^{B|z|}&lt;/math&gt;

for some constants {{math|''A''}} and {{math|''B''}}.  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. [[Nachbin's theorem]] gives necessary and sufficient conditions for the Borel transform to be well defined.

==== Fundamental relationships ====
Since an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.

== Table of selected Laplace transforms ==
{{main article|List of Laplace transforms}}

The following table provides Laplace transforms for many common functions of a single variable.&lt;ref&gt;{{Citation |edition=3rd |page=455 |first1=K. F. |last1=Riley |first2=M. P. |last2=Hobson |first3=S. J. |last3=Bence |title=Mathematical methods for physics and engineering |publisher=Cambridge University Press |year=2010 |isbn=978-0-521-86153-3}}&lt;/ref&gt;&lt;ref&gt;{{Citation |first1=J. J. |last1=Distefano |first2=A. R. |last2=Stubberud |first3=I. J. |last3=Williams |page=78 |title=Feedback systems and control |edition=2nd |publisher=McGraw-Hill |series=Schaum's outlines |year=1995 |isbn=978-0-07-017052-0}}&lt;/ref&gt; For definitions and explanations, see the ''Explanatory Notes'' at the end of the table.

Because the Laplace transform is a linear operator,

* The Laplace transform of a sum is the sum of Laplace transforms of each term.

:: &lt;math&gt;\mathcal{L}\{f(t) + g(t)\}  = \mathcal{L}\{f(t)\} + \mathcal{L}\{ g(t)\}  &lt;/math&gt;

* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.

:: &lt;math&gt;\mathcal{L}\{a f(t)\}  = a \mathcal{L}\{ f(t)\}&lt;/math&gt;

Using this [[linearity]], and various [[List of trigonometric identities|trigonometric]], [[Hyperbolic function|hyperbolic]], and [[complex number]] (etc.) properties and/or identities, some Laplace transforms can be obtained from others more quickly than by using the definition directly.

The unilateral Laplace transform takes as input a function whose time domain is the [[non-negative]] reals, which is why all of the time domain functions in the table below are multiples of the [[Heaviside step function]], {{math|''u''(''t'')}}.

The entries of the table that involve a time delay {{math|''τ''}} are required to be [[causal system|causal]] (meaning that {{math|''τ'' &gt; 0}}).  A causal system is a system where the [[impulse response]] {{math|''h''(''t'')}} is zero for all time {{mvar|t}} prior to {{math|1=''t'' = 0}}. In general, the region of convergence for causal systems is not the same as that of [[anticausal system]]s.

{| class="wikitable"
|-
! Function
! Time domain &lt;br&gt; &lt;math&gt;f(t) = \mathcal{L}^{-1}\{F(s)\}&lt;/math&gt; 
! Laplace {{math|s}}-domain &lt;br&gt; &lt;math&gt;F(s) = \mathcal{L}\{f(t)\}&lt;/math&gt; 
! Region of convergence 
! Reference

|- style="text-align:center;"
| [[Dirac delta function|unit impulse]] 
|| &lt;math&gt; \delta(t) \ &lt;/math&gt; 
|| &lt;math&gt; 1  &lt;/math&gt; 
|| all {{math|''s''}}
|| inspection

|- style="text-align:center;"
| delayed impulse 
|| &lt;math&gt; \delta(t - \tau) \ &lt;/math&gt; 
|| &lt;math&gt; e^{-\tau s} \ &lt;/math&gt; 
|| 
|| time shift of&lt;br&gt;unit impulse

|- style="text-align:center;"
| [[Heaviside step function|unit step]] 
|| &lt;math&gt; u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { 1 \over s } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| integrate unit impulse

|- style="text-align:center;"
| delayed unit step 
|| &lt;math&gt; u(t - \tau) \ &lt;/math&gt; 
|| &lt;math&gt; \frac 1 s e^{-\tau s} &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}} 
|| time shift of&lt;br&gt;unit step

|- style="text-align:center;"
| [[ramp function|ramp]] 
|| &lt;math&gt; t \cdot u(t)\ &lt;/math&gt; 
|| &lt;math&gt;\frac 1 {s^2}&lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| integrate unit&lt;br&gt;impulse twice

|- style="text-align:center;"
| {{math|''n''}}th power &lt;br /&gt; (for integer {{math|''n''}}) 
|| &lt;math&gt; t^n \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt; { n! \over s^{n + 1} } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}   &lt;br /&gt; ({{math|''n'' &gt; −1}})
|| Integrate unit&lt;br&gt;step {{math|''n''}} times

|- style="text-align:center;"
| {{math|''q''}}th power &lt;br /&gt; (for complex {{math|''q''}}) 
|| &lt;math&gt; t^q \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt; { \Gamma(q + 1) \over s^{q + 1} } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}} &lt;br /&gt; {{math|Re(''q'') &gt; −1}} 
||&lt;ref&gt;{{citation |title=Mathematical Handbook of Formulas and Tables |edition=3rd |first1=S. |last1=Lipschutz |first2=M. R. |last2=Spiegel |first3=J. |last3=Liu |series=Schaum's Outline Series |publisher=McGraw-Hill |page=183 |year=2009 |isbn=978-0-07-154855-7}} – provides the case for real {{math|''q''}}.&lt;/ref&gt;&lt;ref&gt;http://mathworld.wolfram.com/LaplaceTransform.html – Wolfram Mathword provides case for complex {{math|''q''}}&lt;/ref&gt;

|- style="text-align:center;"
| {{math|''n''}}th root 
|| &lt;math&gt; \sqrt[n]{t} \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt; { 1 \over s^{\frac 1 n + 1} } \Gamma\left(\frac 1 n + 1\right) &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}} 
|| Set {{math|1=''q'' = 1/''n''}} above.

|- style="text-align:center;"
| {{math|''n''}}th power with frequency shift 
|| &lt;math&gt;t^{n} e^{-\alpha t} \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt;\frac{n!}{(s+\alpha)^{n+1}}&lt;/math&gt; 
|| {{math|Re(''s'') &gt; −''α''}}
|| Integrate unit step,&lt;br&gt;apply frequency shift

|- style="text-align:center;"
| delayed {{math|''n''}}th power &lt;br /&gt; with frequency shift 
|| &lt;math&gt;(t-\tau)^n e^{-\alpha (t-\tau)} \cdot u(t-\tau) &lt;/math&gt; 
|| &lt;math&gt; \frac{n! \cdot e^{-\tau s}}{(s+\alpha)^{n+1}} &lt;/math&gt;
|| {{math|Re(''s'') &gt; −''α''}} 
|| Integrate unit step,&lt;br&gt;apply frequency shift,&lt;br&gt;apply time shift

|- style="text-align:center;"
| [[exponential decay]] 
|| &lt;math&gt; e^{-\alpha t} \cdot u(t)   &lt;/math&gt; 
|| &lt;math&gt; { 1 \over s+\alpha } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; −''α''}}
|| Frequency shift of&lt;br&gt;unit step

|- style="text-align:center;"
| [[Two-sided Laplace transform|two-sided]] exponential decay &lt;br&gt;(only for bilateral transform)
|| &lt;math&gt; e^{-\alpha|t|}  \ &lt;/math&gt; 
|| &lt;math&gt; { 2\alpha \over \alpha^2 - s^2 } &lt;/math&gt; 
|| {{math|−''α'' &lt; Re(''s'') &lt; ''α''}} 
|| Frequency shift of&lt;br&gt;unit step

|- style="text-align:center;"
| exponential approach 
|| &lt;math&gt;( 1-e^{-\alpha t})  \cdot u(t)  \ &lt;/math&gt; 
|| &lt;math&gt;\frac{\alpha}{s(s+\alpha)} &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| Unit step minus&lt;br&gt;exponential decay

|- style="text-align:center;"
| [[sine]] 
|| &lt;math&gt; \sin(\omega t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { \omega \over s^2 + \omega^2  } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| {{Harvnb|Bracewell|1978|p=227}}

|- style="text-align:center;"
| [[cosine]] 
|| &lt;math&gt; \cos(\omega t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { s \over s^2 + \omega^2  } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| {{Harvnb|Bracewell|1978|p=227}}

|- style="text-align:center;"
| [[hyperbolic sine]] 
|| &lt;math&gt; \sinh(\alpha t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { \alpha \over s^2 - \alpha^2 } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; {{abs|''α''}}}} 
|| {{Harvnb|Williams|1973|p=88}}

|- style="text-align:center;"
| [[hyperbolic cosine]] 
|| &lt;math&gt; \cosh(\alpha t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { s \over s^2 - \alpha^2  } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; {{abs|''α''}}}}
|| {{Harvnb|Williams|1973|p=88}}

|- style="text-align:center;"
| exponentially decaying &lt;br /&gt; sine wave 
|| &lt;math&gt;e^{-\alpha t}  \sin(\omega t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { \omega \over (s+\alpha )^2 + \omega^2  } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; −''α''}} 
|| {{Harvnb|Bracewell|1978|p=227}}

|- style="text-align:center;"
| exponentially decaying &lt;br /&gt; cosine wave 
|| &lt;math&gt;e^{-\alpha t}  \cos(\omega t) \cdot u(t) \ &lt;/math&gt; 
|| &lt;math&gt; { s+\alpha \over (s+\alpha )^2 + \omega^2  } &lt;/math&gt; 
|| {{math|Re(''s'') &gt; −''α''}}
|| {{Harvnb|Bracewell|1978|p=227}}

|- style="text-align:center;"
| [[natural logarithm]] 
|| &lt;math&gt; \ln (t) \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt; - { 1 \over s}\, \left[ \ln(s)+\gamma \right] &lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}} 
|| {{Harvnb|Williams|1973|p=88}}

|- style="text-align:center;"
| [[Bessel function]] &lt;br&gt; of the first kind, &lt;br /&gt; of order ''n'' 
|| &lt;math&gt; J_n( \omega t) \cdot u(t)&lt;/math&gt; 
|| &lt;math&gt;\frac{ \left(\sqrt{s^2+ \omega^2}-s\right)^n}{\omega^n \sqrt{s^2 + \omega^2}}&lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}   &lt;br /&gt; ({{math|''n'' &gt; −1}}) 
|| {{Harvnb|Williams|1973|p=89}}

|- style="text-align:center;"
| [[Error function]] 
|| &lt;math&gt; \operatorname{erf}(t) \cdot u(t) &lt;/math&gt; 
|| &lt;math&gt; \frac 1 s e^{(1/4)s^2} \left(1 - \operatorname{erf} \frac s 2 \right)&lt;/math&gt; 
|| {{math|Re(''s'') &gt; 0}}
|| {{Harvnb|Williams|1973|p=89}}

|-
| colspan=5|'''Explanatory notes:'''
{{col-begin}}
{{col-break}}

* {{math|''u''(''t'')}} represents the [[Heaviside step function]].
* {{math|''δ''}}  represents the [[Dirac delta function]].
* {{math|Γ(''z'')}} represents the [[Gamma function]].
* {{math|''γ''}} is the [[Euler&amp;ndash;Mascheroni constant]].

{{col-break}}

*  {{math|''t''}}, a real number, typically represents ''time'', &lt;br /&gt;although it can represent ''any'' independent dimension.
*  {{math|''s''}} is the [[complex number|complex]] frequency domain parameter, and  {{math|Re(''s'')}} is its [[real part]].
*  {{math|''α'', ''β'', ''τ,'' and ''ω''}} are [[real numbers]].
*  {{math|''n''}} is an [[integer]].

{{col-end}}
|}

== ''s''-domain equivalent circuits and impedances ==
The Laplace transform is often used in circuit analysis, and simple conversions to the {{math|''s''}}-domain of circuit elements can be made. Circuit elements can be transformed into [[Electrical impedance|impedance]]s, very similar to [[Phasor (sine waves)|phasor]] impedances.

Here is a summary of equivalents:

: [[File:S-Domain circuit equivalents.svg|alt={{math|''s''}}-domain equivalent circuits|centre|frameless|400x400px|{{math|''s''}}-domain equivalent circuits]]

Note that the resistor is exactly the same in the time domain and the {{math|''s''}}-domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the {{math|''s''}}-domain account for that.

The equivalents for current and voltage sources are simply derived from the transformations in the table above.

== Examples and applications ==
&lt;!--A few worked examples are provided here to enable the reader to assess comprehension of the factual presentation.  Elaboration beyond the role of supporting factual comprehension belongs at [[v:|Wikiversity]] or [[b:|Wikibooks]].--&gt;

The Laplace transform is used frequently in [[engineering]] and [[physics]]; the output of a [[linear time-invariant]] system can be calculated by convolving its unit [[impulse response]] with the input signal. Performing this calculation in Laplace space turns the [[convolution]] into a [[multiplication]]; the latter being easier to solve because of its algebraic form. For more information, see [[control theory]].

The Laplace transform can also be used to [[Laplace transform applied to differential equations|solve differential equations]] and is used extensively in [[mechanical engineering]] and [[electrical engineering]].  The Laplace transform reduces a linear [[differential equation]] to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer [[Oliver Heaviside]] first proposed a similar scheme, although without using the Laplace transform; and the resulting [[operational calculus]] is credited as the Heaviside calculus.

=== Nuclear physics ===
In [[nuclear physics]], the following fundamental relationship governs [[radioactive decay]]: the number of radioactive atoms {{math|''N''}} in a sample of a radioactive [[isotope]] decays at a rate proportional to {{math|''N''}}.  This leads to the first order linear differential equation

: &lt;math&gt;\frac{dN}{dt} = -\lambda N,&lt;/math&gt;

where {{math|''λ''}} is the [[decay constant]]. The Laplace transform can be used to solve this equation.

Rearranging the equation to one side, we have

: &lt;math&gt;\frac{dN}{dt} + \lambda N = 0.&lt;/math&gt;

Next, we take the Laplace transform of both sides of the equation:

: &lt;math&gt;\left( s \tilde{N}(s) - N_0 \right) + \lambda \tilde{N}(s) = 0,&lt;/math&gt;

where

: &lt;math&gt;\tilde{N}(s) = \mathcal{L}\{N(t)\}&lt;/math&gt;

and

: &lt;math&gt;N_0 = N(0).&lt;/math&gt;

Solving, we find

: &lt;math&gt;\tilde{N}(s) = \frac{N_0}{s + \lambda}.&lt;/math&gt;

Finally, we take the inverse Laplace transform to find the general solution

: &lt;math&gt;\begin{align}
  N(t) &amp;= \mathcal{L}^{-1} \{\tilde{N}(s)\} = \mathcal{L}^{-1}\! \left\{ \frac{N_0}{s + \lambda} \right\}\\
       &amp;= \ N_0 e^{-\lambda t},
\end{align}&lt;/math&gt;

which is indeed the correct form for radioactive decay.

=== Complex impedance of a capacitor ===
In the theory of [[electrical circuit]]s, the current flow in a [[capacitor]] is proportional to the capacitance and rate of change in the electrical potential (in [[International System of Units|SI]] units). Symbolically, this is expressed by the differential equation

: &lt;math&gt;i = C { dv \over dt} ,&lt;/math&gt;

where {{math|''C''}} is the capacitance (in [[farad]]s) of the capacitor, {{math|1=''i'' = ''i''(''t'')}} is the [[electric current]] (in [[ampere]]s) through the capacitor as a function of time, and {{math|1=''v'' = ''v''(''t'')}} is the [[electrostatic potential|voltage]] (in [[volt]]s) across the terminals of the capacitor, also as a function of time.

Taking the Laplace transform of this equation, we obtain

: &lt;math&gt;I(s) = C(s V(s) - V_0),&lt;/math&gt;

where

: &lt;math&gt;\begin{align}
  I(s) &amp;= \mathcal{L} \{ i(t) \},\\
  V(s) &amp;= \mathcal{L} \{ v(t) \},
\end{align}&lt;/math&gt;

and

: &lt;math&gt;V_0 = v(t)\Big|_{t=0}. \, &lt;/math&gt;

Solving for {{math|''V''(''s'')}} we have

: &lt;math&gt;V(s) = { I(s) \over sC } + { V_0 \over s }.&lt;/math&gt;

The definition of the [[complex number|complex]] [[Electrical impedance|impedance]] {{math|''Z''}} (in [[ohm]]s) is the ratio of the complex voltage {{math|''V''}} divided by the complex current {{math|''I''}} while holding the initial state {{math|''V''&lt;sub&gt;0&lt;/sub&gt;}} at zero:

: &lt;math&gt;Z(s) = \left. { V(s) \over I(s) } \right|_{V_0 = 0}.&lt;/math&gt;

Using this definition and the previous equation, we find:

: &lt;math&gt;Z(s) = \frac{1}{sC}, &lt;/math&gt;

which is the correct expression for the complex impedance of a capacitor. 
In addition, the Laplace transform has large applications in control theory.

=== Partial fraction expansion ===
&lt;!-- [[Partial fractions in Laplace transforms]] redirect here --&gt;
Consider a linear time-invariant system with [[transfer function]]
: &lt;math&gt;H(s) = \frac{1}{(s + \alpha)(s + \beta)}.&lt;/math&gt;

The [[impulse response]] is simply the inverse Laplace transform of this transfer function:
: &lt;math&gt;h(t) = \mathcal{L}^{-1}\{H(s)\}.&lt;/math&gt;

To evaluate this inverse transform, we begin by expanding {{math|''H''(''s'')}} using the method of [[partial fraction]] expansion,
: &lt;math&gt;\frac{1}{(s + \alpha)(s + \beta)} = { P \over s + \alpha } + { R \over s+\beta }.&lt;/math&gt;

The unknown constants {{math|''P''}} and {{math|''R''}} are the [[residue (complex analysis)|residue]]s located at the corresponding [[pole (complex analysis)|pole]]s of the transfer function. Each residue represents the relative contribution of that [[mathematical singularity|singularity]] to the transfer function's overall shape.

By the [[residue theorem]], the inverse Laplace transform depends only upon the poles and their residues. To find the residue {{math|''P''}}, we multiply both sides of the equation by {{math|''s'' + ''α''}} to get
: &lt;math&gt;\frac{1}{s + \beta} = P  + { R (s + \alpha) \over s + \beta }.&lt;/math&gt;

Then by letting {{math|1=''s'' = −''α''}}, the contribution from {{math|''R''}} vanishes and all that is left is
: &lt;math&gt;P = \left.{1 \over s+\beta}\right|_{s=-\alpha} = {1 \over \beta - \alpha}.&lt;/math&gt;

Similarly, the residue {{math|''R''}} is given by
: &lt;math&gt;R = \left.{1 \over s + \alpha}\right|_{s=-\beta} = {1 \over \alpha - \beta}.&lt;/math&gt;

Note that
: &lt;math&gt;R = {-1 \over \beta - \alpha} = - P&lt;/math&gt;
and so the substitution of {{math|''R''}} and {{math|''P''}} into the expanded expression for {{math|''H''(''s'')}} gives
: &lt;math&gt;H(s)  = \left( \frac{1}{\beta - \alpha} \right) \cdot \left(  { 1 \over s + \alpha } - { 1  \over s + \beta }  \right).&lt;/math&gt;

Finally, using the linearity property and the known transform for exponential decay (see ''Item'' #''3'' in the ''Table of Laplace Transforms'', above), we can take the inverse Laplace transform of {{math|''H''(''s'')}} to obtain
: &lt;math&gt;h(t) = \mathcal{L}^{-1}\{H(s)\} = \frac{1}{\beta - \alpha}\left(e^{-\alpha t} - e^{-\beta t}\right),&lt;/math&gt;
which is the impulse response of the system.

;Convolution
The same result can be achieved using the [[Convolution theorem|convolution property]] as if the system is a series of filters with transfer functions of {{math|1/(''s'' + ''a'')}} and {{math|1/(''s'' + ''b'')}}. That is, the inverse of

: &lt;math&gt;H(s) = \frac{1}{(s + a)(s + b)} = \frac{1}{s+a} \cdot \frac{1}{s + b}&lt;/math&gt;

is

: &lt;math&gt; \mathcal{L}^{-1}\! \left\{ \frac{1}{s + a} \right\} * \mathcal{L}^{-1}\! \left\{\frac{1}{s + b} \right\} = e^{-at} * e^{-bt} = \int_0^t e^{-ax}e^{-b(t - x)}\, dx = \frac{e^{-a t}-e^{-b t}}{b - a}.&lt;/math&gt;

=== Phase delay ===
{| class="wikitable"
|-
! Time function
! Laplace transform
|-
| &lt;math&gt;\sin{(\omega t + \varphi)}&lt;/math&gt;
| &lt;math&gt;\frac{s\sin(\varphi) + \omega \cos(\varphi)}{s^2 + \omega^2}&lt;/math&gt;
|-
| &lt;math&gt;\cos{(\omega t + \varphi)}&lt;/math&gt;
| &lt;math&gt;\frac{s\cos(\varphi) - \omega \sin(\varphi)}{s^2 + \omega^2}.&lt;/math&gt;
|}

Starting with the Laplace transform,

: &lt;math&gt;X(s) = \frac{s\sin(\varphi) + \omega \cos(\varphi)}{s^2 + \omega^2}&lt;/math&gt;

we find the inverse by first rearranging terms in the fraction:

: &lt;math&gt;\begin{align}
  X(s) &amp;= \frac{s \sin(\varphi)}{s^2 + \omega^2} + \frac{\omega \cos(\varphi)}{s^2 + \omega^2} \\
       &amp;= \sin(\varphi) \left(\frac{s}{s^2 + \omega^2} \right) + \cos(\varphi) \left(\frac{\omega}{s^2 + \omega^2} \right).
\end{align}&lt;/math&gt;

We are now able to take the inverse Laplace transform of our terms:

: &lt;math&gt;\begin{align}
  x(t) &amp;= \sin(\varphi) \mathcal{L}^{-1}\left\{\frac{s}{s^2 + \omega^2} \right\} + \cos(\varphi) \mathcal{L}^{-1}\left\{\frac{\omega}{s^2 + \omega^2} \right\} \\
       &amp;= \sin(\varphi)\cos(\omega t) + \sin(\omega t)\cos(\varphi).
\end{align}&lt;/math&gt;

This is just the [[Trigonometric identity#Angle sum and difference identities|sine of the sum]] of the arguments, yielding:

:&lt;math&gt;x(t) = \sin (\omega t + \varphi).&lt;/math&gt;

We can apply similar logic to find that

: &lt;math&gt;\mathcal{L}^{-1} \left\{ \frac{s\cos\varphi - \omega \sin\varphi}{s^2 + \omega^2} \right\} = \cos{(\omega t + \varphi)}.&lt;/math&gt;

=== {{Anchor|Inferring spatial structure from spectrum}}Determining structure of astronomical object from spectrum ===
The wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the ''spatial distribution'' of matter of an [[Astronomy|astronomical]] source of [[Radio frequency|radio-frequency]] [[thermal radiation]] too distant to [[Angular resolution|resolve]] as more than a point, given its [[flux density]] [[spectrum]], rather than relating the ''time'' domain with the spectrum (frequency domain).

Assuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible [[Mathematical model|model]] of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum.&lt;ref&gt;{{citation |first1=M. |last1=Salem |first2=M. J. |last2=Seaton |year=1974 |url=http://adsabs.harvard.edu/cgi-bin/nph-data_query?bibcode=1974MNRAS.167..493S&amp;link_type=ARTICLE&amp;db_key=AST&amp;high= |title=I. Continuum spectra and brightness contours |journal=[[Monthly Notices of the Royal Astronomical Society]] |volume=167 |issue=3 |pages=493–510 |doi=10.1093/mnras/167.3.493 |bibcode=1974MNRAS.167..493S}}, and&lt;br/&gt;{{citation |first1=M. |last1=Salem |year=1974 |url=http://adsabs.harvard.edu/cgi-bin/nph-data_query?bibcode=1974MNRAS.167..511S&amp;link_type=ARTICLE&amp;db_key=AST&amp;high= |title=II. Three-dimensional models |journal=Monthly Notices of the Royal Astronomical Society |volume=167 |issue=3 |pages=511–516 |doi=10.1093/mnras/167.3.511 |bibcode=1974MNRAS.167..511S}}&lt;/ref&gt; When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.

=== Statistical mechanics ===
In [[statistical mechanics]], the Laplace transform of the density of states &lt;math&gt;g(E)dE&lt;/math&gt; defines the [[partition function (statistical mechanics)|partition function]].&lt;ref&gt;{{cite book|author1=RK Pathria|author2=Paul Beal|title=Statistical mechanics|edition=2nd|publisher=Butterworth-Heinemann|year=1996|page=56}}&lt;/ref&gt; That is, the partition function &lt;math&gt;Z(\beta)&lt;/math&gt; is given by
:&lt;math&gt; Z(\beta) = \int_0^\infty e^{-\beta E}g(E)dE&lt;/math&gt;
and the inverse is given by
:&lt;math&gt; g(E) = \frac{1}{2\pi i} \int_{\beta_0-i\infty}^{\beta_0+i\infty} e^{\beta E}Z(\beta) d\beta&lt;/math&gt;

== See also ==
{{div col}}
* [[Analog signal processing]]
* [[Bernstein's theorem on monotone functions]]
* [[Continuous-repayment mortgage#Mortgage difference and differential equation|Continuous-repayment mortgage]]
* [[Fourier transform]]
* [[Hamburger moment problem]]
* [[Hardy–Littlewood tauberian theorem]]
* [[Moment-generating function]]
* [[Pierre-Simon Laplace]]
* [[Post's inversion formula]]
* [[Signal-flow graph]]
* [[Laplace–Carson transform]]
* [[Symbolic integration]]
* [[Transfer function]]
* [[Z-transform]] (discrete equivalent of the Laplace transform)
{{div col end}}

== Notes ==
{{Reflist|30em}}

== References ==

=== Modern ===
* {{Citation |last=Bracewell |first=Ronald N. |title=The Fourier Transform and its Applications |edition=2nd |year=1978 |publisher=McGraw-Hill Kogakusha |isbn=978-0-07-007013-4 }}&lt;!-- This edition is used for pinpoint citations in the transform table. --&gt;
* {{citation|first=R. N.|last=Bracewell|title=The Fourier Transform and Its Applications|edition=3rd|location=Boston|publisher=McGraw-Hill|year=2000|isbn=978-0-07-116043-8}}
* {{Citation | last1=Feller | first1=William | author1-link=William Feller | title=An introduction to probability theory and its applications. Vol. II. | publisher=[[John Wiley &amp; Sons]] | location=New York | series=Second edition | mr=0270403  | year=1971}}
* {{citation |first1=G. A. |last1=Korn |first2=T. M. |last2=Korn |title=Mathematical Handbook for Scientists and Engineers |publisher=McGraw-Hill Companies |edition=2nd |year=1967 |isbn=978-0-07-035370-1 }}
* {{Citation | last1=Widder | first1=David Vernon | title=The Laplace Transform | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series, v. 6 | mr=0005923  | year=1941}}
* {{Citation | last=Williams |first=J. |title=Laplace Transforms |series=Problem Solvers |volume= |publisher=George Allen &amp; Unwin |year=1973 |isbn= 978-0-04-512021-5 }}
* {{Citation | last=Takacs | first= J.|title=Fourier amplitudok meghatarozasa operatorszamitassal | year=1953 | journal=Magyar Hiradastechnika | volume=IV | issue=7–8|pages=93–96 |language=Hungarian }}

=== Historical ===
&lt;!-- Citations to Opera omnia [The Complete Works] are wrong. Opera omnia was published 1911 and after, so the citations should be |origyear=17xx |year=1992... Handling of Euler's volume number and Opera omnia volume is problematic --&gt;
* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1744 |title=De constructione aequationum |trans-title=The Construction of Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=150–161}}
* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1753 |title=Methodus aequationes differentiales |trans-title=A Method for Solving Differential Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=181–213}}
* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |origyear=1769 |title=Institutiones calculi integralis, Volume 2 |trans-title=Institutions of Integral Calculus |language=la |journal=Opera Omnia |series=1st series |volume=12 |year=1992 |location=Basel |publisher=Birkhäuser |isbn=978-3764314743 &lt;!-- isbn for the entire first series--&gt;}}, Chapters 3–5
* {{citation |last=Euler |first=Leonhard |authorlink=Leonhard Euler |year=1769 |title=Institutiones calculi integralis |trans-title=Institutions of Integral Calculus |language=la |volume=II &lt;!--Secundum--&gt; |at=ch. 3–5, pp. 57–153 |location=Paris |publisher=Petropoli |url=https://books.google.com/books?id=BFqWNwpfqo8C }}
* {{citation|last=Grattan-Guinness|first=I|authorlink=Ivor Grattan-Guinness|year=1997|contribution=Laplace's integral solutions to partial differential equations|editor=Gillispie, C. C.|title=Pierre Simon Laplace 1749–1827: A Life in Exact Science|location=Princeton|publisher=Princeton University Press|isbn=978-0-691-01185-1}}
* {{citation|last=Lagrange|first=J. L.|authorlink=Joseph Louis Lagrange|year=1773|title=Mémoire sur l'utilité de la méthode|series=Œuvres de Lagrange|volume=2|pages=171–234}}

==Further reading==
* {{citation|first1=Wolfgang|last1=Arendt|first2=Charles J.K.|last2=Batty|first3=Matthias|last3=Hieber|first4=Frank|last4=Neubrander|title=Vector-Valued Laplace Transforms and Cauchy Problems|publisher=Birkhäuser Basel|year=2002|isbn=978-3-7643-6549-3 |ref=none}}.
* {{citation|last=Davies|first=Brian|title=Integral transforms and their applications|edition=Third|publisher=Springer|location=New York|year=2002|isbn= 978-0-387-95314-4 |ref=none}}
* {{citation | last=Deakin|first= M. A. B. | year=1981 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=25 | pages=343–390 | doi=10.1007/BF01395660 | issue=4 |ref=none}}
* {{citation | last=Deakin|first= M. A. B. | year=1982 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=26 | pages=351–381 | doi=10.1007/BF00418754 | issue=4 |ref=none}}
* {{citation |last=Doetsch |first=Gustav |authorlink=Gustav Doetsch |date=1974 |title=Introduction to the Theory and Application of the Laplace Transformation |publisher=Springer |isbn=978-0-387-06407-9 |ref=none}}
* Mathews, Jon; Walker, Robert L. (1970), ''Mathematical methods of physics'' (2nd ed.), New York: W. A. Benjamin, {{isbn|0-8053-7002-1}}
* {{citation|first1=A. D.|last1=Polyanin|first2=A. V.|last2=Manzhirov|title=Handbook of Integral Equations|publisher=CRC Press|location=Boca Raton|year=1998|isbn=978-0-8493-2876-3 |ref=none}}
* {{Citation | last1=Schwartz | first1=Laurent | author-link=Laurent Schwartz | title=Transformation de Laplace des distributions | mr=0052555  | year=1952 | journal=Comm. Sém. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.] | volume=1952 | pages=196–206 |language=French |ref=none}}
* {{Citation |last=Schwartz |first=Laurent |author-link=Laurent Schwartz |year=2008 |origyear=1966 |title=Mathematics for the Physical Sciences |publisher=Dover Publications |location=New York |series=Dover Books on Mathematics |pages=215–241 |isbn=978-0-486-46662-0 |url={{Google books|-_AuDQAAQBAJ|Mathematics for the Physical Sciences|page=215|plainurl=yes}} |ref=none}} - See Chapter VI. The Laplace transform.
* {{citation|first=William McC.|last=Siebert|title=Circuits, Signals, and Systems|publisher=MIT Press|location=Cambridge, Massachusetts|year=1986|isbn=978-0-262-19229-3 |ref=none}}
* {{Citation | last1=Widder | first1=David Vernon | title=What is the Laplace transform? | mr=0013447  | year=1945 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 |volume=52 |issue=8 | pages=419–425 | doi=10.2307/2305640 | jstor=2305640 |ref=none}}

== External links ==
{{wikiquote}}
{{commons category|Laplace transformation}}
* {{springer|title=Laplace transform|id=p/l057540}}
* [http://wims.unice.fr/wims/wims.cgi?lang=en&amp;+module=tool%2Fanalysis%2Ffourierlaplace Online Computation] of the transform or inverse transform, wims.unice.fr
* [http://eqworld.ipmnet.ru/en/auxiliary/aux-inttrans.htm Tables of Integral Transforms] at EqWorld: The World of Mathematical Equations.
* {{MathWorld|title=Laplace Transform|urlname=LaplaceTransform}}
* [http://fourier.eng.hmc.edu/e102/lectures/Laplace_Transform/ Good explanations of the initial and final value theorems]
* [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at MathPages
* [http://www.wolframalpha.com/input/?i=laplace+transform+example Computational Knowledge Engine] allows to easily calculate Laplace Transforms and its inverse Transform.
* [http://www.laplacetransformcalculator.com/easy-laplace-transform-calculator/ Laplace Calculator] to calculate Laplace Transform online easily.

{{Authority control}}

{{DEFAULTSORT:Laplace Transform}}
[[Category:Laplace transforms| ]]
[[Category:Differential equations]]
[[Category:Fourier analysis]]
[[Category:Mathematical physics]]</text>
      <sha1>09audan2zvn0il4z307qx2vpr20cjg6</sha1>
    </revision>
  </page>
  <page>
    <title>Late fee</title>
    <ns>0</ns>
    <id>2236984</id>
    <revision>
      <id>866834094</id>
      <parentid>866831456</parentid>
      <timestamp>2018-11-01T21:16:11Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Mergefrom}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2287">{{mergefrom|library fine|date=November 2018}}
{{Refimprove|date=April 2010}}
A '''late fee''', also known as an ''overdue fine'', ''late fine'', or ''past due fee'', is a charge fined against a client by a company or organization for not paying a bill or returning a rented or borrowed item by its due date. Its use is most commonly associated with businesses like creditors, video rental outlets and [[library|libraries]]. Late fees are generally calculated on a per day, per item basis.

Organizations encourage the payment of late fees by suspending a client's borrowing or rental privileges until accumulated fees are paid, sometimes after these fees have exceeded a certain level.

Late fees are widely regarded as an [[annoyance]]. In 2005, video rental chain [[Blockbuster Video]] capitalized on this perception with a major [[advertising campaign]] that touted a revision of its rental policy as "The End of Late Fees".

More recently, in 2006, [[Rogers Video]] has used the same technique, except only for movies, and without any [[restocking fee]] (due to movies costing much less than video games).

Late fees charged by banks, landlords, and utilities have been heavily criticized as a penalty against the poor, and attempts have been made in some places to outlaw them completely or place caps on them. The argument against them is that the poor will inevitably be forced to pay them as they cannot earn the money to pay their bills by the due date. These people will be forced to pay even higher fees for the same services, and will find making future timely payments to their creditors even more difficult.

Late fees are issued to people who do not pay on time and don't honor a lease or obligation that they are responsible for.

A special use of the term late fee is additional postage that was once required by Post Offices to allow inclusion of a letter or package in the outgoing mail dispatch although having been posted later than the normal closing time for mail. Often a special Late Fee Box was provided.

== See also ==
*[[Grace period]]
*[[Turn-off notice]]

== External links ==
* {{LISWiki_link|Late fees}}

[[Category:Renting]]
[[Category:Mathematical finance]]
[[Category:Credit]]
[[Category:Personal financial problems]]
[[Category:Time]]


{{econ-stub}}</text>
      <sha1>j9fe7nsxue1xg0tz5lswrfk5qn6k5ei</sha1>
    </revision>
  </page>
  <page>
    <title>Linear transport theory</title>
    <ns>0</ns>
    <id>33278970</id>
    <revision>
      <id>765883648</id>
      <parentid>765373798</parentid>
      <timestamp>2017-02-16T23:42:37Z</timestamp>
      <contributor>
        <username>Primefac</username>
        <id>11508456</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/Fmadd|Fmadd]] ([[User talk:Fmadd|talk]]) to last version by SchreiberBike</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1713">In [[mathematical physics]] '''Linear transport theory''' is the study of equations describing the migration of [[particles]] or [[energy]] within a host medium when such migration involves random absorption, [[Emission spectrum|emission]] and [[scattering]] events.  Subject to certain simplifying assumptions, this is a common and useful framework for describing the scattering of [[light]] ([[radiative transfer]]) or [[neutrons]] ([[neutron transport]]).

Given the laws of individual collision events (in the form of absorption coefficients and scattering kernels/phase functions) the problem of linear transport theory is then to determine the result of a large number of random collisions governed by these laws.  This involves computing exact or approximate solutions of the transport equation, and there are various forms of the transport equation that have been studied.  Common varieties include steady-state vs time-dependent, scalar vs vector (the latter including polarization), and monoenergetic vs multi-energy (multi-group).

== See also ==
* [[Radiative transfer]]
* [[Neutron transport]]

==References==
* {{Citation | last1=Case | first1=Kenneth | last2=Zweifel | first2=Paul | title=Linear Transport Theory | publisher=[[Addison-Wesley]] | year=1967}}
* {{Citation | last1=Davison | first1=Boris | author1-link=Boris Davison | title=Neutron Transport Theory | publisher=[[Oxford University Press]] | edition=1st | isbn=978-0-19-851207-3 | year=1957}}
* {{Citation | last1=Kaper | last2=Lekkerkerker | last3=Hejtmanek | title=Spectral Methods In Linear Transport Theory | publisher=[[Birkhäuser Basel]] | edition=1st | isbn=978-3-7643-1372-2 | year=1982}}



[[Category:Mathematical physics]]</text>
      <sha1>qq6r8b96c8nj739bg4mb4ufv9j2go3b</sha1>
    </revision>
  </page>
  <page>
    <title>Main effect</title>
    <ns>0</ns>
    <id>7042478</id>
    <revision>
      <id>739355192</id>
      <parentid>739307219</parentid>
      <timestamp>2016-09-14T05:54:14Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1435">In the [[design of experiments]] and [[analysis of variance]], a '''main effect''' is the effect of an independent variable on a dependent variable averaging across the levels of any other independent variables.  The term is frequently used in the context of [[factorial design]]s and [[regression analysis|regression models]] to distinguish main effects from [[interaction (statistics)|interaction]] effects.

Relative to a factorial design, under an analysis of variance, a main effect test will test the hypotheses expected such as H&lt;sub&gt;0&lt;/sub&gt;, the null hypothesis. Running a hypothesis for a main effect will test whether there is evidence of an effect of different treatments. However a main effect test is nonspecific and will not allow for a localization of specific mean pairwise comparisons (simple effects). A main effect test will merely look at whether overall there is something about a particular factor that is making a difference. In other words a test examining differences amongst the levels of a single factor (averaging over the other factor and/or factors). Main effects are essentially the overall effect of a factor.

== References ==

* McBurney, D.M., White, T.L. (2004). ''Research Methods''. CA: Wadsworth Learning.
* Mook, Douglas G. (2001). ''Psychological Research: The Ideas Behind the Methods''. NY: W. W. Norton &amp; Company.

{{statistics-stub}}

[[Category:Research]]
[[Category:Analysis of variance]]</text>
      <sha1>27ndhlac5k4p8ph2e3pip2pit9lx55p</sha1>
    </revision>
  </page>
  <page>
    <title>Measure space</title>
    <ns>0</ns>
    <id>45270</id>
    <revision>
      <id>860052906</id>
      <parentid>833381875</parentid>
      <timestamp>2018-09-18T00:48:23Z</timestamp>
      <contributor>
        <ip>89.107.5.192</ip>
      </contributor>
      <comment>/* Example */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3509">A '''measure space''' is a basic object of [[measure theory]], a branch of mathematics  that studies generalized notions of volumes. Measure spaces contain information about the underlying set, the subsets of said set that are feasible for measuring (the [[sigma-algebra|&lt;math&gt; \sigma&lt;/math&gt;-algebra]]) and the method that is used for measuring (the [[measure (mathematics)|measure]]). One important  example of a measure space is a [[probability space]].

Measure space should not be confused with the related [[measurable space]]s.

== Definition ==
A measure space is a triple &lt;math&gt; (X, \mathcal A, \mu) &lt;/math&gt; , where&lt;ref name="Kosorok83"/&gt;&lt;ref name="Klenke18" /&gt;
* &lt;math&gt; X &lt;/math&gt; is a (nonempty) set
* &lt;math&gt; \mathcal A &lt;/math&gt; is a [[sigma-algebra|&lt;math&gt; \sigma&lt;/math&gt;-algebra]] on the set &lt;math&gt; X &lt;/math&gt;
* &lt;math&gt; \mu &lt;/math&gt; is a [[measure (mathematics)|measure]] on &lt;math&gt; (X, \mathcal A) &lt;/math&gt;

== Example ==
Set
:&lt;math&gt;X = \{0, 1\}&lt;/math&gt;

The &lt;math display="inline"&gt;\sigma&lt;/math&gt;-algebra on finite sets such as the one above is usually the [[power set]], which is the set of all subsets (of a given set) and is denoted by &lt;math display="inline"&gt;\mathcal{P}(\cdot)&lt;/math&gt;. Sticking with  this convention, we set
:&lt;math&gt;\mathcal{A} = \mathcal{P}(X)&lt;/math&gt;

In this simple case, the power set can be written down explicitly:
:&lt;math&gt;\mathcal{P}(X) = \{\emptyset, \{0\}, \{1\}, X\}.&lt;/math&gt;

As measure, define &lt;math display="inline"&gt;\mu&lt;/math&gt; by 
:&lt;math&gt;\mu(\{0\}) = \mu(\{1\}) = \frac{1}{2},&lt;/math&gt;

so &lt;math display="inline"&gt;\mu(X) = 1&lt;/math&gt; (by additivity of measures) and &lt;math display="inline"&gt;\mu(\emptyset) = 0&lt;/math&gt; (by definition of measures).

This leads to the measure space &lt;math display="inline"&gt;(X, \mathcal{P}(X), \mu)&lt;/math&gt;. It is a [[probability space]], since &lt;math display="inline"&gt;\mu(X) = 1&lt;/math&gt;. The measure &lt;math display="inline"&gt;\mu&lt;/math&gt; corresponds to the [[Bernoulli distribution]] with &lt;math display="inline"&gt;p = \frac{1}{2}&lt;/math&gt;, which is for example used to model a fair coin flip.

== Important classes of measure spaces ==
Most important classes of measure spaces are defined by the properties of their associated measures. This includes
* [[Probability space]]s, a measure space where the measure is a [[probability measure]]&lt;ref name="Kosorok83"/&gt;
* Finite measure spaces, where the measure is a [[finite measure]]&lt;ref name="eommeasurespace"/&gt;
* &lt;math&gt; \sigma&lt;/math&gt;-finite measure spaces, where the measure is a [[sigma-finite measure|&lt;math&gt; \sigma &lt;/math&gt;-finite measure]]&lt;ref name="eommeasurespace"/&gt;

Another class of measure spaces are the [[complete measure space]]s.&lt;ref name="Klenke33" /&gt;

== References ==
&lt;references&gt;
&lt;ref name="Kosorok83" &gt;{{cite book |last1=Kosorok |first1=Michael R. |year=2008  |title=Introduction to Empirical Processes and Semiparametric Inference |location=New York |publisher=Springer |page=83|isbn=978-0-387-74977-8 }}&lt;/ref&gt;
&lt;ref name="Klenke18" &gt;{{cite book |last1=Klenke |first1=Achim |year=2008  |title=Probability Theory |location=Berlin |publisher=Springer |doi=10.1007/978-1-84800-048-3 |isbn=978-1-84800-047-6 |page=18}}&lt;/ref&gt;
&lt;ref name="Klenke33" &gt;{{cite book |last1=Klenke |first1=Achim |year=2008  |title=Probability Theory |location=Berlin |publisher=Springer |doi=10.1007/978-1-84800-048-3 |isbn=978-1-84800-047-6 |page=33}}&lt;/ref&gt;
&lt;ref name="eommeasurespace"&gt;{{SpringerEOM |title=Measure space |id=Measure_space  |author-last1=Anosov |author-first1=D.V.}}&lt;/ref&gt;
&lt;/references&gt;

[[Category:Measure theory]]</text>
      <sha1>p4nqnwxhvzk7ddw7lylnvqxf8g4lgoc</sha1>
    </revision>
  </page>
  <page>
    <title>Method of Four Russians</title>
    <ns>0</ns>
    <id>31812917</id>
    <revision>
      <id>862032562</id>
      <parentid>862032424</parentid>
      <timestamp>2018-10-01T18:41:11Z</timestamp>
      <contributor>
        <username>Mhym</username>
        <id>635181</id>
      </contributor>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3593">In [[computer science]], the '''Method of Four Russians''' is a technique for speeding up [[algorithm]]s involving [[Boolean matrix|Boolean matrices]], or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values.

== Idea ==

The main idea of the method is to partition the matrix into small square blocks of size {{math|''t'' &amp;times; ''t''}} for some parameter {{mvar|t}}, and to use a [[lookup table]] to perform the algorithm quickly within each block. The index into the lookup table encodes the values of the matrix cells on the upper left of the block boundary prior to some operation of the algorithm, and the result of the lookup table encodes the values of the boundary cells on the lower right of the block after the operation. Thus, the overall algorithm may be performed by operating on only {{math|(''n''/''t'')&lt;sup&gt;2&lt;/sup&gt;}} blocks instead of on {{math|''n''&lt;sup&gt;2&lt;/sup&gt;}} matrix cells, where {{mvar|n}} is the side length of the matrix. In order to keep the size of the lookup tables (and the time needed to initialize them) sufficiently small, {{mvar|t}} is typically chosen to be {{math|''O''(log ''n'')}}.

== Applications ==

Algorithms to which the Method of Four Russians may be applied include:
* computing the [[transitive closure]] of a graph, 
* Boolean [[matrix multiplication]], 
* [[edit distance]] calculation,
* [[sequence alignment]],
* index calculation for [[binary jumbled pattern matching]].
In each of these cases it speeds up the algorithm by one or two [[logarithm]]ic factors.

The Method of Four Russians matrix inversion algorithm published by Bard is implemented in M4RI library for fast arithmetic with dense matrices over ''F''&lt;sub&gt;2&lt;/sub&gt;. M4RI is used by [[SageMath]] and the PolyBoRi library.&lt;ref&gt;[https://malb.bitbucket.io/m4ri/ M4RI - Main Page]&lt;/ref&gt;

== History ==

The algorithm was introduced by [[Vladimir Arlazarov|V. L. Arlazarov]], E. A. Dinic, [[Alexander Kronrod|M. A. Kronrod]], and I. A. Faradžev in 1970.{{sfn|Arlazarov|Dinic|Kronrod|Faradzev|1970}} The origin of the name is unknown; {{Harvtxt|Aho|Hopcroft|Ullman|1974}} explain:
:The second method, often called the "Four Russians'" algorithm, after the cardinality and nationality of its inventors, is somewhat more "practical" than the algorithm in Theorem 6.9.{{sfn|Aho|Hopcraft|Ullman|1974|p=243}}
All four authors worked in [[Moscow|Moscow, Russia]] at the time.&lt;ref&gt;[http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=dan&amp;paperid=35675&amp;option_lang=eng Author affiliations] on MathNet.ru.&lt;/ref&gt;

==Notes==
{{Reflist}}

==References==
*{{Citation |first=V. |last=Arlazarov |authorlink=Vladimir Arlazarov |first2=E. |last2=Dinic |first3=M. |last3=Kronrod |first4=I. |last4=Faradžev |year=1970 |title=On economical construction of the transitive closure of a directed graph |journal=Dokl. Akad. Nauk SSSR |volume=194 |issue=11 }}. Original title: "Об экономном построении транзитивного замыкания ориентированного графа", published in ''[[Proceedings of the USSR Academy of Sciences|Доклады Академии Наук СССР]]'' '''134''' (3), 1970.
*{{Citation |first=Alfred V. |last=Aho |first2=John E. |last2=Hopcroft |first3=Jeffrey D. |last3=Ullman |year=1974 |title=The design and analysis of computer algorithms |publisher=Addison-Wesley}}
*{{Citation |last=Bard |first=Gregory V. |year=2009 |title=Algebraic Cryptanalysis |publisher=Springer |isbn=978-0-387-88756-2}}

[[Category:Numerical linear algebra]]


{{mathapplied-stub}}</text>
      <sha1>c793194pr3qqxkpaf49kn8ykpcyhkj2</sha1>
    </revision>
  </page>
  <page>
    <title>Misère</title>
    <ns>0</ns>
    <id>212453</id>
    <revision>
      <id>866820091</id>
      <parentid>864153188</parentid>
      <timestamp>2018-11-01T19:29:51Z</timestamp>
      <contributor>
        <username>Erel Segal</username>
        <id>7637243</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4167">'''Misere''', '''misère''', '''bettel''' or '''bettler''' ([[French language|French]] for "destitution"; equivalent terms in other languages include ''contrabola'', ''devole'', ''pobre'') is a [[bidding|bid]] in various [[card game]]s, and the player who bids misere undertakes to win no [[Trick-taking game|tricks]] or as few as possible, usually at no trump, in the round to be played. This does not allow sufficient variety to constitute a game in its own right, but it is the basis of such trick-avoidance games as [[Hearts (card game)|Hearts]], and provides an optional contract for most games involving an auction.&lt;ref&gt;Parlett, David (1996). ''Oxford Dictionary of card Games'', [[Oxford University Press]], pg. 162. {{ISBN|0-19-869173-4}}&lt;/ref&gt;

A misere bid usually indicates an extremely poor hand, hence the name. An '''open''' or '''lay down misere''', or '''misere ouvert''' is a [[500 (card game)|500]] bid where the player is so sure of losing every trick that they undertake to do so with their cards placed face-up on the table.  Consequently, 'lay down misere' is [[Australian and New Zealand punting glossary|Australian gambling slang]] for a predicted easy victory. 

In [[Skat (card game)|Skat]], the bidding can result in a '''null game''', where the bidder wins only if they lose every trick. (Conversely, the opponents win by forcing the bidder to take a trick.)

The word is first recorded in this sense in the rules for the game "[[Boston whist|Boston]]" in the late 18th century.&lt;ref&gt;[[Oxford English Dictionary]]&lt;/ref&gt; Cannot be played in 6 hand 500.

== Misère game ==
A '''''misère game''''' or '''''bettel game''''' is a game that is played according to its conventional rules, except that it is "played to lose"; that is, the winner is the one who loses according to the normal game rules. Such games generally have rulesets that normally encourage players to win; for example, most variations of [[draughts]] (known as "checkers" in the [[United States]]) require players to make a capture move if it is available; thus, in the misère variation, players can force their opponents to take numerous checkers through intentionally "poor" play.

In [[combinatorial game theory]], a misère game is one played according to the "misère play condition"; that is, a player unable to move wins.&lt;ref&gt;{{cite book
  | last=Berlekamp
  | first=Elwyn R.
  | authorlink=Elwyn Berlekamp
  |author2=John H. Conway |author3=Richard K. Guy
   | title=[[Winning Ways for your Mathematical Plays]]
  | publisher=Academic Press
  | year=1982
  | isbn=0-12-091102-7}} Revised and reprinted as: {{cite book
  | author= –
  | title=Winning Ways for your Mathematical Plays (2nd ed.)
  | publisher=A K Peters Ltd
  | date=2001–2004
  | isbn=1-56881-144-6}}&lt;/ref&gt;&lt;ref&gt;{{cite book
  | last = Conway
  | first = John Horton
  | authorlink = John Horton Conway
  | title = [[On numbers and games]]
  | publisher = [[Academic Press]]
  | year = 1976
  | isbn = 0-12-186350-6}}&lt;br /&gt; Revised and reprinted as: {{cite book
  | last = –
  | authorlink = John Horton Conway
  | title = [[On numbers and games]]
  | publisher = A K Peters Ltd
  | year = 2000
  | isbn = 1-56881-127-6}}&lt;/ref&gt; (This is opposed to the "normal play condition" in which a player unable to move loses.) For most games this is the same as the ordinary use of the word, but a very few games are actually misère games according to their standard rules, for example [[Sylver coinage]].

== Other uses ==
* The game of [[Nim]] is often played using the misère play condition, as in the film ''[[Last Year at Marienbad]]''.
* Perhaps the only misère [[Combinatorial game theory|combinatorial]] game played competitively in an organized forum is ''[[Sprouts (game)|sprouts]]''.
* [[Lowball (poker)|Lowball]] is a form of [[poker]] in which the lowest-scoring hand wins.

== See also ==
{{Wiktionary|misère}}
* [[Miser]]
* [[Notakto]]
*[[Avoider-Enforcer game]]

== References ==
{{reflist}}

{{DEFAULTSORT:Misere}}
[[Category:Board game gameplay and terminology]]
[[Category:Card game terminology]]
[[Category:Combinatorial game theory]]
[[Category:Trick-avoidance card games|*Misere]]</text>
      <sha1>p7ytjqcsx66hhrdewbj6vnqh8z3aqhu</sha1>
    </revision>
  </page>
  <page>
    <title>Monic polynomial</title>
    <ns>0</ns>
    <id>314730</id>
    <revision>
      <id>843681049</id>
      <parentid>833310469</parentid>
      <timestamp>2018-05-30T18:52:42Z</timestamp>
      <contributor>
        <ip>2605:E000:35C9:2C00:40A8:322B:F1E4:3E99</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8207">{{refimprove|date=January 2013}}
In [[algebra]], a '''monic polynomial''' is a single-variable polynomial (that is, a [[univariate polynomial]]) in which the [[leading coefficient]] (the nonzero coefficient of highest degree) is equal to&amp;nbsp;1. Therefore, a monic polynomial has the form

:&lt;math&gt;x^n+c_{n-1}x^{n-1}+\cdots+c_2x^2+c_1x+c_0&lt;/math&gt;

== Univariate polynomials ==
If a [[polynomial]] has only one [[indeterminate (variable)|indeterminate]] ([[univariate polynomial]]), then the terms are usually written either from highest degree to lowest degree ("descending powers") or from lowest degree to highest degree ("ascending powers").  A univariate polynomial in ''x'' of degree ''n'' then takes the general form displayed above, where

: ''c''&lt;sub&gt;''n''&lt;/sub&gt; ≠ 0, ''c''&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt;, ..., ''c''&lt;sub&gt;2&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt; and ''c''&lt;sub&gt;0&lt;/sub&gt;

are constants, the coefficients of the polynomial.

Here the term ''c''&lt;sub&gt;''n''&lt;/sub&gt;''x''&lt;sup&gt;''n''&lt;/sup&gt; is called the ''leading term'', and its coefficient ''c''&lt;sub&gt;''n''&lt;/sub&gt; the ''leading coefficient''; if the leading coefficient {{nowrap|is 1}}, the univariate polynomial is called '''monic'''.

===Examples===
* [[Complex quadratic polynomial]]s

=== Properties ===

====Multiplicatively closed====
The set of all monic polynomials (over a given (unitary) [[ring (mathematics)|ring]] ''A'' and for a given variable ''x'') is closed under multiplication, since the product of the leading terms of two monic polynomials is the leading term of their product. Thus, the monic polynomials form a multiplicative [[semigroup]] of the [[polynomial ring]] ''A''[''x''].  Actually, since the [[constant polynomial]] 1 is monic, this semigroup is even a [[monoid]].

====Partially ordered====
The restriction of the [[divisibility (ring theory)|divisibility]] relation to the set of all monic polynomials (over the given ring) is a [[partial order]], and thus makes this set to a [[poset]].  The reason is that if ''p''(''x'') divides ''q''(''x'') and ''q''(''x'') divides ''p''(''x'') for two monic polynomials ''p'' and ''q'', then ''p'' and ''q'' must be equal.  The corresponding property is not true for polynomials in general, if the ring contains [[invertible element]]s other than 1.

====Polynomial equation solutions====
In other respects, the properties of monic polynomials and of their corresponding monic [[polynomial equation]]s depend crucially on the coefficient ring ''A''. If ''A'' is a [[field (algebra)|field]], then every non-zero polynomial ''p'' has exactly one [[associated element|associated]] monic polynomial ''q''; actually, ''q'' is ''p'' divided with its leading coefficient. In this manner, then, any non-trivial polynomial equation ''p''(''x'')&amp;nbsp;=&amp;nbsp;0 may be replaced by an equivalent monic equation ''q''(''x'')&amp;nbsp;=&amp;nbsp;0. E.g., the general real second degree equation
:&lt;math&gt;\ ax^2+bx+c = 0&lt;/math&gt; (where &lt;math&gt; a \neq 0&lt;/math&gt;)
may be replaced by
:&lt;math&gt;\ x^2+px+q = 0&lt;/math&gt;,
by putting &amp;nbsp;''p''&amp;nbsp;=&amp;nbsp;''b''/''a''&amp;nbsp; and &amp;nbsp;''q''&amp;nbsp;=&amp;nbsp;''c''/''a''. Thus, the equation
:&lt;math&gt;2x^2+3x+1 = 0&lt;/math&gt;
is equivalent to the monic equation
:&lt;math&gt;x^2+\frac{3}{2}x+\frac{1}{2}=0.&lt;/math&gt;

The general quadratic solution formula is then the slightly more simplified form of:
:&lt;math&gt;x = \frac{1}{2} \left( -p \pm \sqrt{p^2 - 4q} \right).&lt;/math&gt;

=====Integrality=====
On the other hand, if the coefficient ring is not a field, there are more essential differences.  E.g., a monic polynomial equation with [[integer]] coefficients cannot have other [[Rational number|rational]] solutions than integer solutions.  Thus, the equation
:&lt;math&gt;\ 2x^2+3x+1 = 0&lt;/math&gt;
possibly might have some rational root, which is not an integer, (and incidentally it does have ''inter alia'' the root &amp;minus;1/2); while the equations
:&lt;math&gt;\ x^2+5x+6 = 0&lt;/math&gt;
and
:&lt;math&gt;\ x^2+7x+8 = 0&lt;/math&gt;
only may have integer solutions or [[irrational number|irrational]] solutions.

The roots of monic polynomial with integer coefficients are called [[algebraic integer]]s.

The solutions to monic polynomial equations over an [[integral domain]] are important in the theory of [[integral extension]]s and [[integrally closed domain]]s, and hence for [[algebraic number theory]].  In general, assume that ''A'' is an integral domain, and also a subring of the integral domain ''B''.  Consider the subset ''C'' of ''B'', consisting of those ''B'' elements, which satisfy monic polynomial equations over ''A'':
:&lt;math&gt; C := \{b \in B : \exists\, p(x) \in A[x]\,, \hbox{ which is monic and such that } p(b) = 0\}\,.&lt;/math&gt;
The set ''C'' contains ''A'', since any ''a''&amp;nbsp;∈&amp;nbsp;''A'' satisfies the equation ''x''&amp;nbsp;−&amp;nbsp;''a''&amp;nbsp;=&amp;nbsp;0. Moreover, it is possible to prove that ''C'' is closed under addition and multiplication.  Thus, ''C'' is a subring of ''B''.  The ring ''C'' is called the ''integral closure'' of ''A'' in ''B''; or just the integral closure of ''A'', if ''B'' is the [[fraction field]] of ''A''; and the elements of ''C'' are said to be ''[[integrality|integral]]'' over ''A''.  If here &lt;math&gt;A=\mathbb{Z}&lt;/math&gt; (the ring of [[integer]]s) and &lt;math&gt;B=\mathbb{C}&lt;/math&gt; (the field of [[complex number]]s), then ''C'' is the ring of ''[[algebraic integers]]''.

====Irreduciblity ====
If {{mvar|p}} is a [[prime number]], the number of monic [[irreducible polynomial]]s of degree {{mvar|n}} over a [[finite field]] &lt;math&gt;GF(p)&lt;/math&gt; with {{mvar|p}} elements is equal to the [[Necklace (combinatorics)|necklace counting function]] {{tmath|N_p(n)}}.{{cn|date=February 2018}} 

If one removes the constraint of being monic, this number becomes {{tmath|(p-1)N_p(n)}}. 

The total number of roots of these monic irreducible polynomials is {{tmath|nN_p(n)}}. This is the number of elements of the field {{tmath|GF(p^n)}} (with {{tmath|p^n}} elements) that do not belong to any smaller field.

For {{math|1=''p'' = 2}}, such polynomials are commonly used to generate [[pseudorandom binary sequence]]s.{{cn|date=February 2018}}

== Multivariate polynomials ==
Ordinarily, the term ''monic'' is not employed for polynomials of several variables.  However, a polynomial in several variables may be regarded as a polynomial in only "the last" variable, but with coefficients being polynomials in the others.  This may be done in several ways, depending on which one of the variables is chosen as "the last one". E.g., the real polynomial
:&lt;math&gt;\ p(x,y) = 2xy^2+x^2-y^2+3x+5y-8&lt;/math&gt;
is monic, considered as an element in '''R'''[''y''][''x''], i.e., as a univariate polynomial in the variable ''x'', with coefficients which themselves are univariate polynomials in ''y'':
:&lt;math&gt;p(x,y) = 1\cdot x^2 + (2y^2+3) \cdot x + (-y^2+5y-8)&lt;/math&gt;;
but ''p''(''x'',''y'') is not monic as an element in  '''R'''[''x''][''y''], since then the highest degree coefficient (i.e., the ''y''&lt;sup&gt;2&lt;/sup&gt; coefficient) is &amp;nbsp;2''x''&amp;nbsp;&amp;minus;&amp;nbsp;1.

There is an alternative convention, which may be useful e.g. in [[Gröbner basis]] contexts: a polynomial is called monic, if its leading coefficient (as a multivariate polynomial) is 1.  In other words, assume that ''p = p''(''x''&lt;sub&gt;1&lt;/sub&gt;'',...,x&lt;sub&gt;n&lt;/sub&gt;'') is a non-zero polynomial in ''n'' variables, and that there is a given [[monomial order]] on the set of all ("monic") monomials in these variables, i.e., a total order of the free commutative [[monoid]] generated by ''x''&lt;sub&gt;1&lt;/sub&gt;'',...,x&lt;sub&gt;n&lt;/sub&gt;'', with the unit as lowest element, and respecting multiplication.  In that case, this order defines a highest non-vanishing term in ''p'', and ''p'' may be called monic, if that term has coefficient one.

"Monic multivariate polynomials" according to either definition share some properties with the "ordinary" (univariate) monic polynomials.  Notably, the product of monic polynomials again is monic.

== References ==
* {{cite book |last=Pinter |first=Charles C. |title=A Book of Abstract Algebra |year=2010 |origyear=Unabridged republication of the 1990 second edition of the work originally published in 1982 by the McGraw–Hill Publishing Company |publisher=Dover |isbn=978-0486474175}}

[[Category:Polynomials]]</text>
      <sha1>h9eslnysvk7yrelj0le9man03lgtegp</sha1>
    </revision>
  </page>
  <page>
    <title>Neugebauer equations</title>
    <ns>0</ns>
    <id>4637146</id>
    <revision>
      <id>828144506</id>
      <parentid>827974521</parentid>
      <timestamp>2018-02-28T20:39:39Z</timestamp>
      <contributor>
        <username>Lam-ang</username>
        <id>8509776</id>
      </contributor>
      <minor/>
      <comment>fixed reflist</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3098">The '''Neugebauer equations''' are a set of equations used to model [[color printing]] systems, developed by [[Hans E. J. Neugebauer]].&lt;ref name=original&gt;{{cite journal|first=H. E. J. |last=Neugebauer |title=Die theoretischen Grundlagen des Mehrfarbenbuchdrucks |trans-title=The theoretical foundations of multicolor printing |journal=Zeitschrift für wissenschaftliche Photographie Photophysik und Photochemie |volume=36 |issue=4 |date=1937 |page=73–89}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Color Technology for Electronic Imaging Devices|first=Henry R.|last=Kang|publisher=SPIE Press|year=1997|isbn=978-0-8194-2108-1}}&lt;/ref&gt; They were intended to predict the color produced by a combination of [[halftone]]s printed in [[CMYK|cyan, magenta, and yellow inks]].

The equations estimate the [[reflectance]] (in [[CIE XYZ]] coordinates or as a function of wavelength) as a function of the reflectance of the 8 possible combinations of CMY inks (or the 16 combinations of CMYK inks), weighted by the area they take up on the paper. In wavelength form:&lt;ref name=original /&gt;
:&lt;math&gt;R(\lambda) = \sum_{i=1}^{16} w_i R_i(\lambda)&lt;/math&gt;
where ''R&lt;sub&gt;i&lt;/sub&gt;''(''λ'') is the reflectance of ink combination ''i'', and ''w&lt;sub&gt;i&lt;/sub&gt;'' is the relative proportions of the 16 colors in a uniformly colored patch. The weights are dependent on the halftone pattern and possibly subject to various forms of [[dot gain]].&lt;ref&gt;{{cite journal|first=Raja |last=Balasubramanian |title=A spectral Neugebauer model for dot-on-dot printers |journal=Proc. SPIE |volume=2413 |date=1995 |url=http://chester.xerox.com/~raja/papers/EI95.pdf}}&lt;/ref&gt;

Light can interact with the paper and ink in more complex ways. The [[Yule-Nielsen effect|Yule–Nielsen]] correction takes into account light entering through blank regions and re-emerging through ink:&lt;ref&gt;{{cite journal|first=J. A. C. |last=Yule |first2=W. J. |last2=Neilsen |date=1951 |title=The Penetration of light into Paper and its Effect on Halftone Reproduction |volume=1951 |journal=TAGA Proceedings |page=65–76}}&lt;/ref&gt;
:&lt;math&gt;R(\lambda) = \left ( \sum_{i=1}^{16} w_i R_i(\lambda)^\frac{1}{n} \right )^n&lt;/math&gt;
The factor ''n'' would be 2 for a perfectly-diffusing [[Lambertian reflectance|Lambertian]] paper substrate, but can be adjusted based on empirical measurements. Further considerations of the optics, such as multiple internal reflections, can be added at the price of additional complexity. 

In order to achieve a desired reflectance these equations have to be inverted to produce the actual dot areas or digital values sent to the printer, a nontrivial operation that may have multiple solutions.&lt;ref&gt;{{cite journal|first=Marc F. |last=Mahy |date=1998 |title=Insight into the solutions of the Neugebauer equations |journal=Electronic Imaging: SPIE/IS&amp;T International Technical Group Newsletter |issue=Jan 1999 |page=7, 11  |url=http://www.inventoland.net/pdf/Reports/ei_newsletter99ocr.pdf}}&lt;/ref&gt;

==See also==
* [[CMYK color model]]

==References==
{{reflist|30em}}

[[Category:Equations]]
[[Category:Color]]
[[Category:Printing]]

{{mathapplied-stub}}</text>
      <sha1>mvrv17n9fx66umza1hav7rc7qovo3e4</sha1>
    </revision>
  </page>
  <page>
    <title>Newton's theorem about ovals</title>
    <ns>0</ns>
    <id>29224388</id>
    <revision>
      <id>862710055</id>
      <parentid>852416284</parentid>
      <timestamp>2018-10-06T05:25:47Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5409">In mathematics, '''Newton's theorem about ovals''' states that the area cut off by a [[secant line|secant]] of a smooth [[Convex set|convex]] oval is not an [[algebraic function]] of the secant.

[[Isaac Newton]] stated it as lemma&amp;nbsp;28 of section&amp;nbsp;VI of book&amp;nbsp;1 of Newton's ''[[Philosophiæ Naturalis Principia Mathematica|Principia]]'', and used it to show that the position of a planet moving in an orbit is not an algebraic function of time.  There has been some controversy about whether or not this theorem is correct because Newton did not state exactly what he meant by an oval, and for some interpretations of the word oval the theorem is correct, while for others it is false.  If "oval" means "continuous convex curve", then there are counterexamples, such as triangles or one of the lobes of [[Huygens lemniscate]] ''y''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''x''&lt;sup&gt;4&lt;/sup&gt;, while {{harvtxt|Arnold|1989}} pointed that if "oval" means "infinitely differentiable convex curve" then Newton's claim is correct and his argument has the essential steps of a rigorous proof.

{{harvtxt|Vassiliev|2002}} generalized Newton's theorem to higher dimensions.

==Statement==
[[File:Lemniscate-of-Gerono.svg|thumb|The lemniscate of Gerono or Huygens; the area cut off by a secant is algebraic, but the lemniscate is not smooth at the origin]]
An English translation Newton's original statement {{harv|Newton|1966|loc=lemma 28 section 6 book I}} is:

: "There is no oval figure whose area, cut off by right lines at pleasure, can be universally found by means of equations of any number of finite terms and dimensions."

In modern mathematical language, Newton essentially proved the following theorem:

: There is no convex smooth (meaning infinitely differentiable)  curve such that the area cut off by a line ''ax''&amp;nbsp;+&amp;nbsp;''by''&amp;nbsp;=&amp;nbsp;''c'' is an algebraic function of ''a'', ''b'', and&amp;nbsp;''c''.

In other words, "oval" in Newton's statement should mean "convex smooth curve". The infinite differentiability at all points is necessary: For any positive integer ''n'' there are algebraic curves that are smooth at all but one point and differentiable ''n'' times at the remaining point for which the area cut off by a secant is algebraic.

Newton observed that a similar argument shows that the arclength of a (smooth convex) oval between two points is not given by an algebraic function of the points.

==Newton's proof==
[[File:Spiral of Archimedes.svg|thumb|left|If the oval is a circle centered at the origin, then the spiral constructed by Newton is an [[Archimedean spiral]].]]
Newton took the origin ''P'' inside the oval, and considered the spiral of points (''r'',&amp;nbsp;''θ'') in polar coordinates whose distance ''r'' from ''P'' is the area cut off by the lines from ''P'' with angles 0 and&amp;nbsp;''θ''. He then observed that this spiral cannot be algebraic as it has an infinite number of intersections with a line through ''P'', so the area cut off by a secant cannot be an algebraic function of the secant.

This proof requires that the oval and therefore the spiral be smooth; otherwise the spiral might be an infinite union of pieces of different algebraic curves. This is what happens in the various "counterexamples" to Newton's theorem for non-smooth ovals.
{{Clear}}

==References==

*{{Citation | last1=Arnold | first1=V. I. | author1-link=Vladimir Arnold | title=Topological proof of the transcendence of the abelian integrals in Newton's Principia | date=1989 | journal=Istoriko-Matematicheskie Issledovaniya | issn=0136-0949 | issue=31 | pages=7–17|mr=0993175 }}
*{{Citation | last1=Arnold | first1=V. I. | author1-link=Vladimir Arnold | last2=Vasilev | first2=V. A. | title=Newton's Principia read 300 years later | date=1989 | journal=[[Notices of the American Mathematical Society]] | issn=0002-9920 | volume=36 | issue=9 | pages=1148–1154|mr=1024727}}
*{{citation| author-link = Isaac Newton|last=Newton |first=I.| date = 1966| title = [[Philosophiæ Naturalis Principia Mathematica|Principia Vol. I The Motion of Bodies]]| edition = based on Newton's 2nd edition (1713)| translator=Andrew Motte (1729)| others = Revised by [[Florian Cajori]] (1934)| publisher = University of California Press| location = Berkeley, CA| isbn = 978-0-520-00928-8}} Alternative translation of earlier (2nd) edition of Newton's ''Principia''.
*{{Citation | last1=Pesic | first1=Peter | title=The validity of Newton's Lemma 28 | doi=10.1006/hmat.2001.2321 | mr=1849799 | date=2001 | journal=[[Historia Mathematica]] | issn=0315-0860 | volume=28 | issue=3 | pages=215–219}}
*{{Citation | last1=Pourciau | first1=Bruce | title=The integrability of ovals: Newton's Lemma 28 and its counterexamples | doi=10.1007/s004070000034 | mr=1827869 | date=2001 | journal=[[Archive for History of Exact Sciences]] | issn=0003-9519 | volume=55 | issue=5 | pages=479–499}}
*{{Citation | last1=Vassiliev | first1=V. A. | title=Applied Picard-Lefschetz theory | url=https://books.google.com/books?isbn=0821829483 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Mathematical Surveys and Monographs | isbn=978-0-8218-2948-6 | mr=1930577 | date=2002 | volume=97 | doi=10.1090/surv/097}}

{{Isaac Newton}}

{{DEFAULTSORT:Newton's Theorem About Ovals}}
[[Category:Curves]]
[[Category:Isaac Newton]]
[[Category:Theorems in geometry]]</text>
      <sha1>siq8dw5h4s43u1peptogofx0fvfjuzm</sha1>
    </revision>
  </page>
  <page>
    <title>Nicolai V. Krylov</title>
    <ns>0</ns>
    <id>35252798</id>
    <revision>
      <id>806667302</id>
      <parentid>779623147</parentid>
      <timestamp>2017-10-23T13:02:00Z</timestamp>
      <contributor>
        <username>Melcous</username>
        <id>20472590</id>
      </contributor>
      <comment>per [[Template:Infobox academic]] , only for those notable enough for their own wiki article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3752">{{Infobox scientist
| name = Nicolai Vladimirovich Krylov
| image = 
| birth_date = {{Birth date and age|1941|06|05|df=y}}
| birth_place =[[Sudogda]], [[Russian SFSR]]
| residence = [[Minnesota]], [[United States]]
| citizenship = [[Russians|Russian]]
| field = [[Mathematics]]
| work_institution = [[University of Minnesota]]
| alma_mater = [[Moscow State University]]
| doctoral_advisor = [[Eugene Dynkin]]
| doctoral_students =[[Istvan Gyongy]]
| known_for =
| prizes = [[Leroy P. Steele Prize]] for Seminal Contribution to Research (2004)
}}

'''Nicolai Vladimirovich Krylov''' ({{lang-ru|Никола́й Влади́мирович Крыло́в}}; born 5 June 1941) is a Russian mathematician specializing in [[partial differential equation]]s, particularly [[stochastic partial differential equation]]s and [[diffusion process]]es. Krylov studied at [[Lomonosov University]], where he in 1966 under [[Eugene Dynkin|E. B. Dynkin]] attained a doctoral candidate title (similar to a PhD) and in 1973 a Russian doctoral degree (somewhat more prestigious than a PhD). He taught from 1966 to 1990 at the Lomonosov University and is since 1990 a professor at the [[University of Minnesota]]. At the beginning  of his career (starting from 1963) he, in collaboration with Dynkin, worked on nonlinear stochastic [[control theory]], making advances in the study of convex,&lt;ref&gt;The non-linearity can be modeled by a convex function.&lt;/ref&gt; nonlinear partial equations of 2nd order (''i.e.'' [[Richard Bellman|Bellman]] equations), which were examined with stochastic methods. This led to the Evans-Krylov theory,&lt;ref&gt;{{cite journal|author=Krylov|title=Boundedly inhomogeneous elliptic and parabolic equations|journal=Izvestiya Akad. Nauk SSSR, ser. mat.|volume=46|year=1982|number=3|pages=487–523}}&lt;/ref&gt; for which he received with [[Lawrence C. Evans]] in 2004 the [[Leroy P. Steele Prize]]&lt;ref&gt;{{cite journal|journal=Notices of the AMS|title=2004 Steele Prize|year=2004|volume=51|number=4|url=http://www.ams.org/notices/200404/comm-steele.pdf}}&lt;/ref&gt; of the [[American Mathematical Society]] (for work done simultaneously and independently by both Krylov and Evans). They proved the second order differentiability ([[Hölder continuity]] of the second derivative) of the solutions of convex, completely nonlinear, second order elliptical partial differential equations and thus the existence of "classical solutions" (Theorem of Evans-Krylov). He was in 1978 at [[Helsinki]] and in 1986 at [[Berkeley, California|Berkeley]] an Invited Speaker for the [[International Congress of Mathematicians|ICM]]. He received the Humboldt Research Award in 2001. In 1993 he was elected a member of the [[American Academy of Arts and Sciences]] (1993). He should not be confused with the mathematician [[Nikolay Mitrofanovich Krylov|Nikolay M. Krylov]].

==Works==
*Controlled diffusion processes, Springer 1980
*Introduction to the theory of diffusion processes, AMS 1995
*Nonlinear elliptic and parabolic equations of the second order, Dordrecht, Reidel 1987
*Lectures on elliptic and parabolic equations in Hölder Spaces, AMS 1996
*Introduction to the theory of random processes, AMS 2002
*Lectures on Elliptic and Parabolic Equations in Sobolev Spaces, AMS 2008

==References==
&lt;references /&gt;

{{Authority control}}

==External links==
*[http://www.math.umn.edu/~krylov/ Homepage]
*{{MathGenealogy|id=15024}}

{{DEFAULTSORT:Krylov, Nicolai Vladimirovich}}
[[Category:Russian mathematicians]]
[[Category:Soviet mathematicians]]
[[Category:1941 births]]
[[Category:Living people]]
[[Category:Mathematical analysts]]
[[Category:21st-century mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:Fellows of the American Academy of Arts and Sciences]]</text>
      <sha1>ix1xssl7r69rc8psibjplgg9wr8loz8</sha1>
    </revision>
  </page>
  <page>
    <title>North east down</title>
    <ns>0</ns>
    <id>5644212</id>
    <revision>
      <id>861181879</id>
      <parentid>795989002</parentid>
      <timestamp>2018-09-25T17:30:41Z</timestamp>
      <contributor>
        <ip>134.223.230.152</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2721">[[File:ECEF ENU Longitude Latitude relationships.svg|thumb|The east north up (ENU) local tangent plane is similar to NED, except for swapping 'down' for 'up' and x for y.]]
'''North east down''' ('''NED'''), also known as '''local tangent plane''' ('''LTP'''), is a geographical coordinate system for representing [[State vector (geographical)|state vectors]] that is commonly used in [[aviation]].  It consists of three numbers: one represents the position along the northern axis, one along the eastern axis, and one represents vertical position.  Down is chosen as opposed to up in order to comply with the [[right-hand rule]].  The origin of this coordinate system is usually chosen to be a point on the surface of the geoid below the aircraft's center of gravity. However, care must be taken since, if the aircraft is accelerating (turning or accelerating linearly), then the NED coordinates are no longer inertial coordinates.&lt;ref&gt;{{Cite book|title = Unmanned Rotorcraft Systems|last = Cai|first = Guowei|publisher = Springer|year = 2011|isbn = 978-0-85729-634-4|location = |pages = 27|last2 = Chen|first2 = Ben M.|last3 = Lee|first3 = Tong Heng}}&lt;/ref&gt;

NED coordinates are similar to [[ECEF]] in that they're Cartesian, however they can be more convenient due to the relatively small numbers involved, and also because of the intuitive axes. NED and ECEF coordinates can be related with the following formula:&lt;ref&gt;{{Cite book|title = Unmanned Rotorcraft Systems|last = Cai|first = Guowei|publisher = Springer|year = 2011|isbn = 978-0-85729-634-4|location = |pages = 32|last2 = Chen|first2 = Ben M.|last3 = Lee|first3 = Tong Heng}}&lt;/ref&gt;

:&lt;math&gt;
   \mathbf p_{\mathrm{NED}} = R^T (\mathbf p_{\mathrm{ECEF}} - \mathbf p_{\mathrm{Ref}})
&lt;/math&gt;

where &lt;math&gt;\mathbf p_{\mathrm{NED}}&lt;/math&gt; is a 3D position in a NED system, &lt;math&gt;\mathbf p_{\mathrm{ECEF}}&lt;/math&gt; is the corresponding ECEF position, &lt;math&gt;\mathbf p_{\mathrm{Ref}}&lt;/math&gt; is the reference ECEF position (where the local tangent plane originates), and &lt;math&gt;R&lt;/math&gt; is a [[rotation matrix]] whose columns are the north, east, and down axes. &lt;math&gt;R&lt;/math&gt; may be defined conveniently from the latitude &lt;math&gt;\phi&lt;/math&gt; and longitude &lt;math&gt;\lambda&lt;/math&gt; corresponding to &lt;math&gt;\mathbf p_{\mathrm{Ref}}&lt;/math&gt;:

:&lt;math&gt;
   R = \begin{bmatrix}
      -\sin(\phi) \cos(\lambda) &amp; -\sin(\lambda) &amp; -\cos(\phi) \cos(\lambda) \\
      -\sin(\phi) \sin(\lambda) &amp;  \cos(\lambda) &amp; -\cos(\phi) \sin(\lambda) \\
      \cos(\phi) &amp; 0 &amp; -\sin(\phi)
   \end{bmatrix}
&lt;/math&gt;

==See also==
* [[East north up]]
* [[Axes conventions]]
* [[Geodetic system]]

== References ==
&lt;references /&gt;

[[Category:Aerospace]]
[[Category:Coordinate systems]]


{{Aviation-stub}}</text>
      <sha1>rnaskzzw6run9o5irfk7qn8ldjqcvlv</sha1>
    </revision>
  </page>
  <page>
    <title>Orientation of churches</title>
    <ns>0</ns>
    <id>13294412</id>
    <revision>
      <id>871634101</id>
      <parentid>871634029</parentid>
      <timestamp>2018-12-02T12:47:33Z</timestamp>
      <contributor>
        <username>Wham2001</username>
        <id>915833</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/178.193.214.42|178.193.214.42]] ([[User talk:178.193.214.42|talk]]) to last revision by Bealtainemí. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14039">[[File:Cathedral.svg|thumb|300px|Cathedral oriented to the east. The arrow indicates the west front entrance.]]
Within [[church architecture]], '''orientation''' is an arrangement by which the point of main interest in the interior is towards the east ({{lang-la|oriens}}). The east end is where the [[altar]] is placed, often within an [[apse]]. The [[façade]] and main entrance are accordingly at the west end.

The opposite arrangement, in which the church is entered from the east and the sanctuary is at the other end, is called occidentation.&lt;ref&gt;[https://books.google.com/books?id=dQFbDwAAQBAJ&amp;pg=PA28&amp;dq=%22was+occidented%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwin96_xiJLdAhWLKsAKHf90DEoQ6AEIKTAA#v=onepage&amp;q=%22was%20occidented%22&amp;f=false Thomas Coomans, ''Life Inside the Cloister'' (Leuven University Press 2018), p. 28]&lt;/ref&gt;&lt;ref&gt;[https://books.google.ie/books?id=cfRTip1qBJcC&amp;pg=PA290&amp;dq=%22was+occidented%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwin96_xiJLdAhWLKsAKHf90DEoQ6AEINDAC#v=onepage&amp;q=%22was%20occidented%22&amp;f=false Noel Lenski, ''The Cambridge Companion to the Age of Constantine'' (Cambridge University Press 2006), p. 290]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=90daDwAAQBAJ&amp;pg=PT82&amp;dq=%22was+occidented%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwin96_xiJLdAhWLKsAKHf90DEoQ6AEIOTAD#v=onepage&amp;q=%22was%20occidented%22&amp;f=false Marilyn Stokstad, ''Medieval Art'' (Routledge 2018)]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=nSCoDQAAQBAJ&amp;pg=PT165&amp;dq=%22is+occidented%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwieuvfWg5LdAhUpIMAKHRtPDXkQ6AEILzAB#v=onepage&amp;q=%22is%20occidented%22&amp;f=false Éamonn Ó Carragáin, Carol Neuman de Vegvar, ''Roma Felix – Formation and Reflections of Medieval Rome'' (Routledge 2016)]&lt;/ref&gt;

Since the eighth century most churches are oriented. Hence, even in the many churches where the altar end is not actually to the east, terms such as "east end", "west door", "north aisle" are commonly used as if the church were oriented, treating the altar end as the [[liturgical east and west|liturgical east]].&lt;ref&gt;"East" in Curl, James Stephens, ''Encyclopaedia of Architectural Terms'', 1993, Donhead Publishing, {{ISBN|1873394047}}, 9781873394045&lt;/ref&gt; 

== History ==

The first Christians faced east when praying, for which various explanations have been offered. In a tradition well established by the time of Christ, Jews in the diaspora would pray facing [[Jerusalem]], which in most of the [[Roman Empire]] would have been to the east. Another explanation is that Christ's [[Second Coming]] would be on the clouds coming from the East: "For as the lightning cometh out of the east, and shineth even unto the west; so shall also the coming of the Son of man be." ([[Matthew 24]]:27). Due to this eastward posture of prayer, [[Tertullian]] (c. 160 — c. 220) says that some non-Christians thought they worshipped the sun.&lt;ref&gt;[http://www.tertullian.org/latin/apologeticus.htm Tertuliano, ''Apologeticus'', 16.9–10]; [http://www.newadvent.org/fathers/0301.htm translation]&lt;/ref&gt; [[Origen]] (c. 185 — 253) says: "The fact that [...] of all the quarters of the heavens, the east is the only direction we turn to when we pour out prayer, the reasons for this, I think, are not easily discovered by anyone."&lt;ref&gt;"quod ex omnibus coeli plagis ad solam orientis partem conversi orationem fundimus, non facile cuiquam puto ratione compertum" ([https://books.google.com/books?id=GakNAAAAYAAJ&amp;pg=PA40&amp;dq=%22ex+omnibus+coeli+plagis+ad+solam+orientis+partem+conversi+orationem+fundimus%22&amp;hl=en&amp;sa=X&amp;ved=0CEoQ6AEwCWoVChMI_4_QzvycyAIVTHY-Ch0oUAdU#v=onepage&amp;q=%22ex%20omnibus%20coeli%20plagis%20ad%20solam%20orientis%20partem%20conversi%20orationem%20fundimus%22&amp;f=false ''Origenis in Numeros homiliae'', Homilia V, 1]; [https://books.google.com/books?id=P4pPyRXeWkUC&amp;pg=PA17&amp;dq=Origen+%22only+direction%22&amp;hl=en&amp;sa=X&amp;redir_esc=y#v=onepage&amp;q=Origen%20%22only%20direction%22&amp;f=false translation]&lt;/ref&gt; Later on, various [[Fathers of the Church]] advanced mystical reasons for the custom.

At first, the orientation of the building in which Christians met was unimportant, but after the [[legalization of Christianity in Rome|legalization of the religion]] in the fourth century, customs developed in this regard.&lt;ref name=ODCAA&gt;[https://books.google.com/books?id=Te2dAAAAQBAJ&amp;pg=PA117&amp;dq=Oxford+Dictionary+%22orientation+of+churches%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjqp8vY0OXLAhVDvA8KHYnAAgAQ6AEIKTAC#v=onepage&amp;q=Oxford%20Dictionary%20%22orientation%20of%20churches%22&amp;f=false ''The Oxford Dictionary of Christian Art and Architecture'' (2013] {{ISBN|978-0-19968027-6}}), p. 117&lt;/ref&gt; These differed in [[eastern Christianity|eastern]] and [[western Christianity]].

The ''[[Apostolic Constitutions]]'', a work of [[eastern Christianity]] written between 375 and 380 AD, gave it as a rule that churches should have the [[chancel|sanctuary]] (with [[apse]] and [[sacristy|sacristies]]) at the east end, to enable Christians to pray eastward in church as in private or in small groups. In the middle of the sanctuary was the [[altar]], behind which was the [[bishop]]'s throne, flanked by the seats of the [[presbyter]]s, while the [[laity]] were on the opposite side. However, even in the East there were churches (for example, in [[Tyre, Lebanon]]) that had the entrance at the east end, and the sanctuary at the west end. During the readings all looked towards the readers, the bishop and presbyters looking westward, the people eastward. The ''Apostolic Constitutions'', like the other documents that speak of the custom of praying towards the east, do not indicate on which side of the altar the bishop stood for "the sacrifice".&lt;ref&gt;[https://books.google.com/books?id=Dr4CAAAAQAAJ&amp;printsec=frontcover&amp;dq=%22Constitutiones+Apostolorum%22&amp;hl=en&amp;sa=X&amp;redir_esc=y#v=onepage&amp;q=%22Constitutiones%20Apostolorum%22&amp;f=false ''Constitutiones Apostolorum'' II, 57}: Ὁ οἶκος ἕστω ἐπιμήκης, κατὰ ἀνατολὰς ἐπιτραμμένος, ἐξ ἑκατέρων τῶν μερῶν ἔχων τὰ παστοροφορεῖα πρὸς ἀνατολήν [...] κείσθω δὲ μέσος ὁ τοῦ ἐπισκόπου θρόνος, παρ' ἑκατέρου δὲ αὐτοῦ καθεζέσθωσαν τὸ πρεσβυτέριον [...] εἰς τὸ ἕτερον μέρος οἱ λαΐκοὶ καθεζέσθωσαν [...] μετὰ δὲ ταῦτα γινέσθω ἡ θυσία, ἑστῶτος παντὸς τοῦ λαοῦ ([http://www.newadvent.org/fathers/07152.htm translation])&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=B6slCgAAQBAJ&amp;pg=PT371&amp;dq=%22Apostolic+Constitutions%22+oblong&amp;hl=en&amp;sa=X&amp;redir_esc=y#v=onepage&amp;q=%22Apostolic%20Constitutions%22%20oblong&amp;f=false William E. Addis, ''A Catholic Dictionary'' (Aeterna Press 1961), article "Church: place of Christian assembly"]&lt;/ref&gt;

The earliest Christian churches in [[Rome]] were all built with the entrance to the east, like the Jewish [[temple in Jerusalem]].&lt;ref name=Dietz&gt;[http://www.sacredarchitecture.org/articles/the_eschatological_dimension_of_church_architecture Helen Dietz, "The Eschatological Dimension of Church Architecture"]&lt;/ref&gt; Only in the 8th or 9th century did Rome accept the orientation that had become obligatory in the [[Byzantine Empire]] and was also generally adopted in the [[Frankish Empire]] and elsewhere in northern Europe.&lt;ref name=ODCAA/&gt;&lt;ref name=Dietz/&gt;&lt;ref&gt;[https://books.google.com/books?id=fUqcAQAAQBAJ&amp;pg=PA525&amp;dq=%22Empire+in+the+8th+or%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiN_JufhubLAhVFeQ8KHWTKDhIQ6AEIKTAA#v=onepage&amp;q=%22Empire%20in%20the%208th%20or%22&amp;f=false ''Oxford Dictionary of the Christian Church'' (2005] {{ISBN|978-0-19280290-3}}), p. 525&lt;/ref&gt; The original [[Constantine the Great|Constantinian]] [[Church of the Holy Sepulchre]] in [[Jerusalem]] also had the altar in the west end.&lt;ref&gt;[[D. Fairchild Ruggles]], [https://books.google.com/books?id=1W8XWWOxGgoC&amp;pg=PA134&amp;dq=%22Sepulchre+reconstructed+plan%22&amp;hl=en&amp;sa=X&amp;ved=0CCEQ6AEwAGoVChMI3Pew-ZKfyAIVymsUCh1BHg73#v=onepage&amp;q=%22Sepulchre%20reconstructed%20plan%22&amp;f=false ''On Location: Heritage Cities and Sites''] (Springer 2011 {{ISBN|978-1-46141108-6}}), p. 134&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=oFl6GaXH5DsC&amp;pg=PA208&amp;dq=Holy+Sepulchre+basilica+orientation&amp;hl=en&amp;sa=X&amp;redir_esc=y#v=onepage&amp;q=Holy%20Sepulchre%20basilica%20orientation&amp;f=false Lawrence Cunningham, John Reich, Lois Fichner-Rathus, ''Culture and Values: A Survey of the Humanities'', Volume 1 |(Cengage Learning 2013] {{ISBN|978-1-13395244-2}}), pp. 208–210&lt;/ref&gt;

The old Roman custom of having the altar at the west end and the entrance at the east was sometimes followed as late as the 11th century even in areas under Frankish rule, as seen in [[Petershausen (Constance)]], [[Bamberg Cathedral]], [[Augsburg Cathedral]], [[Regensburg Cathedral]], and [[Hildesheim Cathedral]] (all in present-day Germany).&lt;ref&gt;[https://books.google.com/books?id=sX8w667tblMC&amp;pg=PA12&amp;dq=%22XI+Jahrh+fortgedauert%22&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwir9NbtjObLAhWHDg8KHUFVA8kQ6AEIHDAA#v=onepage&amp;q=%22XI%20Jahrh%20fortgedauert%22&amp;f=false Heinrich Otte, ''Handbuch der kirchlichen Kunst-Archäologie des deutschen Mittelalters'' (Leipzig 1868), p. 12]&lt;/ref&gt;

The importance attached to orientation of churches declined after the 15th century.&lt;ref name=Harvard/&gt; In his instructions on the building and arrangement of churches, [[Charles Borromeo]], [[archbishop]] of [[Milan]] from 1560 to 1584, expressed a preference for having the apse point exactly east, but accepted that, where that is impractical, a church could be built even on a north-south axis, preferably with the façade at the southern end. He stated that the altar can also be at the west end, where "in accordance with the rite of the Church it is customary for [[Mass (liturgy)|Mass]] to be celebrated at the main altar by a priest facing the people".&lt;ref&gt;[http://www.memofonte.it/home/files/pdf/scritti_borromeo.pdf Carlo Borromeo, ''Instructiones fabricae et suppellectilis ecclesiasticae'' (Fondazione Memofonte onlus. Studio per l'elaborazione informatica delle fonti storico-artistiche), liber I, cap. X. ''De cappella maiori'' (pp. 18–19)]&lt;/ref&gt;

The medieval [[mendicant orders]] generally built their churches inside towns and had to fit them into the town plans, regardless of orientation. Later, in the [[Spanish colonial empire|Spanish]] and [[Portuguese colonial empire]]s they made no attempt to observe orientation, as is seen in [[San Francisco de Asis Mission Church]] near [[Taos, New Mexico]]. Today in the West, orientation is little observed in building churches.

== Inexactitude of orientation ==
[[File:Plan de la cathédrale de Quimper.png|thumb|300px|Plan of [[Quimper Cathedral]]]]
Charles Borromeo stated that churches ought to be oriented exactly east, in line with the rising sun at the [[equinoxes]], not at the [[solstices]], but some churches seem to be oriented to sunrise on the [[feast day]] of their patron saint. Thus [[St. Stephen's Cathedral, Vienna]] is oriented in line with sunrise on [[St. Stephen's Day]], 26 December, in [[Julian calendar]] 1137, when it began to be built. However, a survey of old English churches published in 2006 showed practically no relationship with the feast days of the saints to whom they are dedicated. The results also did not conform to a theory that compass readings could have caused the variants. Taken as a body, those churches can only be said to have been oriented approximately but not exactly to the geographical east.&lt;ref&gt;[http://www.archaeologyuk.org/ba/ba94/feat2.shtml Ian Hinton, "Churches face East, don't they?" in ''British Archaeology''] {{webarchive|url=https://web.archive.org/web/20160311151757/http://archaeologyuk.org/ba/ba94/feat2.shtml |date=2016-03-11 }}&lt;/ref&gt;

Another survey of a smaller number of English churches examined other possible alignments also and found that, if sunset as well as sunrise is taken into account, the saint's day hypothesis covered 43% of the cases considered, and that there was a significant correspondence also with sunrise on [[Easter]] morning of the year of foundation. The results provided no support for the compass readings hypothesis.&lt;ref&gt;[https://www.academia.edu/3876168/The_orientation_of_churches_Some_new_evidence Jason R. Ali, Peter Cunich, "The orientation of churches: Some new evidence" in ''The Antiquaries Journal'']&lt;/ref&gt;

Yet another study of English churches found that a significant proportion of churches that showed a considerable deviation from true east were constrained by neighbouring buildings in town and perhaps by site [[topography]] in rural areas.&lt;ref&gt;[http://his.library.nenu.edu.cn/upload/soft/haoli/115/455.pdf Peter G. Hoare and Caroline S. Sweet, "The orientation of early medieval churches in England" in ''Journal of Historical Geography'' 26, 2 (2000) 162–173] {{webarchive|url=https://web.archive.org/web/20160304001902/http://his.library.nenu.edu.cn/upload/soft/haoli/115/455.pdf |date=2016-03-04 }}&lt;/ref&gt;

Similarly, a survey of a total of 32 medieval churches with reliable [[metadata]] in [[Lower Austria]] and [[northern Germany]] discovered only a few aligned in accordance with the saint's feast, with no general trend. There was no evidence of the use of compasses; and there was a preferred alignment towards true east, with variations due to town and natural topography.&lt;ref name=Harvard&gt;[http://adsabs.harvard.edu/abs/2014GeoJI.198....1A Patrick Arneitz, Andrea Draxler, Roman Rauch, Roman Leonhardt, "Orientation of churches by magnetic compasses?" in ''Geophysical Journal'', Volume 198, Issue 1, p.1-7]&lt;/ref&gt;

A notable example of an (approximately) oriented church building that – to match the contours of its location and to avoid an area that was swampy at the time of its construction – bends slightly in the middle is [[Quimper Cathedral]] in [[Brittany]].

== See also ==
{{Portal|Architecture|Christianity}}
* ''[[Ad orientem]]''

==References==
{{reflist}}

[[Category:Church architecture]]
[[Category:Orientation (geometry)]]

[[de:Ostung]]</text>
      <sha1>dmdo19q38c2wt4fhsqjh0am6m24f14k</sha1>
    </revision>
  </page>
  <page>
    <title>Parametric oscillator</title>
    <ns>0</ns>
    <id>4902017</id>
    <revision>
      <id>865741212</id>
      <parentid>865308817</parentid>
      <timestamp>2018-10-25T20:56:28Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>v2.0b - [[WP:WCW]] project (Unicode control characters)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28528">[[File:Varactor parametric amplifier 1958.jpg|thumb|One of the first varactor parametric amplifiers, invented at [[Bell Labs]] around 1958.  This 4 stage amplifier achieved 10 dB gain at 400 MHz. Parametric amplifiers are used in applications requiring extremely low noise.]]

A '''parametric oscillator''' is a driven [[harmonic oscillator]] in which the oscillations are driven by varying some parameter of the system at some frequency, typically different from the natural frequency of the oscillator.  A simple example of a parametric oscillator is a child pumping a swing by periodically standing and squatting to increase the size of the swing's oscillations.&lt;ref name=Case&gt;{{cite web |title=Two ways of driving a child's swing |url=http://www.grinnell.edu/academic/physics/faculty/case/swing/ |first=William |last=Case |accessdate=27 November 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20111209230414/http://www.grinnell.edu/academic/physics/faculty/case/swing |archivedate=9 December 2011 |df= }} Note: In real-life playgrounds, swings are predominantly driven, not parametric, oscillators.&lt;/ref&gt;&lt;ref name=Case96&gt;{{cite journal |last=Case |first=W. B. |year=1996 |title=The pumping of a swing from the standing position |journal=American Journal of Physics |volume=64 |pages=215–220 |doi=10.1119/1.18209|bibcode = 1996AmJPh..64..215C }}&lt;/ref&gt;&lt;ref name=Roura&gt;{{cite journal |last1=Roura |first1=P. |last2=Gonzalez |first2=J.A. |year=2010 |title=Towards a more realistic description of swing pumping due to the exchange of angular momentum |journal=European Journal of Physics |volume=31 |pages=1195–1207 |doi=10.1088/0143-0807/31/5/020|bibcode = 2010EJPh...31.1195R }}&lt;/ref&gt;  The child's motions vary the moment of inertia of the swing as a pendulum.  The "pump" motions of the child must be at twice the frequency of the swing's oscillations.  Examples of parameters that may be varied are the oscillator's resonance frequency &lt;math&gt;\omega&lt;/math&gt; and damping &lt;math&gt;\beta&lt;/math&gt;.

Parametric oscillators are used in several areas of physics.  The classical [[varactor]] parametric oscillator consists of a semiconductor [[varactor diode]] connected to a [[resonant circuit]] or [[cavity resonator]].  It is driven by varying the diode's capacitance by applying a varying bias voltage.  The circuit that varies the diode's capacitance is called the "pump" or "driver".   In microwave electronics, [[waveguide (electromagnetism)|waveguide]]/[[Yttrium aluminum garnet|YAG]] based parametric oscillators operate in the same fashion.  Another important example is the [[optical parametric oscillator]], which converts an input [[laser]] light wave into two output waves of lower frequency (&lt;math&gt;\omega_s, \omega_i&lt;/math&gt;)

When operated at pump levels below oscillation, the parametric oscillator can [[amplifier|amplify]] a signal, becoming a '''parametric amplifier''' ('''paramp''').    [[Varactor]] parametric amplifiers have been developed as low-noise amplifiers in the radio and microwave frequency range.  The advantage of a parametric amplifier is that it has much lower noise than an ordinary amplifier based on a gain device like a [[transistor]] or vacuum tube.  This is because in the parametric amplifier a [[Electrical reactance|reactance]] is varied instead of a (noise-producing) [[electrical resistance|resistance]].  They have been used in very low noise radio receivers in [[radio telescope]]s and [[spacecraft communication]] antennas.

Parametric resonance occurs in a mechanical system when a system is parametrically excited and oscillates at one of its resonant frequencies. Parametric excitation differs from forcing since the action appears as a time varying modification on a system parameter.

==History==
Parametric oscillations were first noticed in mechanics.  [[Michael Faraday]] (1831) was the first to notice oscillations of one frequency being excited by forces of double the frequency, in the crispations (ruffled surface waves) observed in a wine glass excited to "sing".&lt;ref&gt;Faraday, M. (1831) [https://books.google.com/books?id=3U5FAAAAcAAJl&amp;pg=PA299#v=onepage&amp;q&amp;f=false "On a peculiar class of acoustical figures; and on certain forms assumed by a group of particles upon vibrating elastic surfaces",]{{dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes }} ''Philosophical Transactions of the Royal Society (London)'', '''121''' : 299-318.&lt;/ref&gt; [[Franz Melde]] (1860) generated parametric oscillations in a string by employing a tuning fork to periodically vary the tension at twice the resonance frequency of the string.&lt;ref&gt;Melde, F. (1860) [https://babel.hathitrust.org/cgi/pt?id=umn.31951d00326548g;view=1up;seq=209 "Über Erregung stehender Wellen eines fadenförmigen Körpers"]{{dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes }} [On the excitation of standing waves on a string], ''Annalen der Physik und Chemie'' (2nd series), '''109''' : 193-215.&lt;/ref&gt;  Parametric oscillation was first treated as a general phenomenon by [[John Strutt, 3rd Baron Rayleigh|Rayleigh]] (1883,1887).&lt;ref&gt;Strutt, J.W. (Lord Rayleigh) (1883) [https://books.google.ca/books?id=EZAOAAAAIAAJ&amp;pg=PA229#v=onepage&amp;q&amp;f=false "On maintained vibrations",] {{webarchive |url=https://web.archive.org/web/20160813023848/https://books.google.ca/books?id=EZAOAAAAIAAJ&amp;pg=PA229#v=onepage&amp;q&amp;f=false |date=August 13, 2016 }} ''Philosophical Magazine'', 5th series, '''15''' : 229-235.&lt;/ref&gt;&lt;ref&gt;Strutt, J.W. (Lord Rayleigh) (1887) [https://books.google.com/books?id=tn47AQAAMAAJ&amp;pg=PA145#v=onepage&amp;q&amp;f=false "On the maintenance of vibrations by forces of double frequency, and on the propagation of waves through a medium endowed with periodic structure",]{{dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes }} ''Philosophical Magazine'', 5th series, '''24''' : 145-159.&lt;/ref&gt;&lt;ref&gt;Strutt, J.W. (Lord Rayleigh) ''The Theory of Sound'', 2nd. ed. (N.Y., N.Y.: Dover, 1945), vol. 1, pages 81-85.&lt;/ref&gt;

One of the first to apply the concept to electric circuits was [[George Francis FitzGerald]], who in 1892 tried to excite oscillations in an [[LC circuit]] by pumping it with a varying inductance provided by a dynamo.&lt;ref&gt;See:
*  FitzGerald, George F. (29 January 1892) [https://books.google.com/books?id=85cvAAAAYAAJ&amp;pg=PA329#v=onepage&amp;q&amp;f=false "On the driving of electromagnetic vibrations by electro-magnetic and electrostatic engines,"]{{dead link|date=October 2017|bot=medic}}{{cbignore|bot=medic}} ''The Electrician'', '''28''' :  329-330.
*  Reprinted: George Francis Fitzgerald with Joseph Larmor, ed., ''The Scientific Writings of the Late George Francis Fitzgerald'' (London, England:  Longmans, Green, &amp; Co., 1902 ; Dublin, Ireland:  Hodges, Figgis, &amp; Co., 1902), [https://books.google.com/books?id=G0bPAAAAMAAJ&amp;pg=PA277#v=onepage&amp;q&amp;f=false pp. 277–281.] {{webarchive |url=https://web.archive.org/web/20140707134922/https://books.google.com/books?id=G0bPAAAAMAAJ&amp;pg=PA277#v=onepage&amp;q&amp;f=false |date=July 7, 2014 }}
*  Reprinted:  (Anon.) (11 February 1892) [https://archive.org/stream/nature03grougoog#page/n398/mode/2up "Physical Society, January 22,"] {{webarchive |url=https://web.archive.org/web/20110712170842/https://archive.org/stream/nature03grougoog#page/n398/mode/2up |date=July 12, 2011 }} ''Nature'', '''45''' : 358-359.&lt;/ref&gt;
&lt;ref name="Hong"&gt;{{cite book   
  | last = Hong
  | first = Sungook Hong
  | authorlink = 
  | coauthors = 
  | title = Wireless: From Marconi's Black-Box to the Audion
  | publisher = MIT Press
  | date = 201
  | location = 
  | pages = 158–161
  | url = https://books.google.com/books?id=UjXGQSPXvIcC&amp;pg=PA165&amp;lpg=PA164&amp;dq=%22negative+resistance%22+ayrton+%22continuous+waves%22#v=onepage&amp;q=%22negative%20resistance%22%20ayrton%20%22continuous%20waves%22&amp;f=false
  | doi = 
  | id = 
  | isbn = 0262082985}}&lt;/ref&gt;  Parametric amplifiers ('''paramps''') were first used in 1913-1915 for radio telephony from Berlin to Vienna and Moscow, and were predicted to have a useful future ([[Ernst Alexanderson]], 1916).&lt;ref&gt;Alexanderson, Ernst F.W. (April 1916) [https://books.google.com/books?id=o0ASAAAAIAAJ&amp;pg=PA101#v=onepage&amp;q&amp;f=false "A magnetic amplifier for audio telephony"]{{dead link|date=December 2016 |bot=InternetArchiveBot |fix-attempted=yes }} ''Proceedings of the Institute of Radio Engineers'', '''4''' : 101-149.&lt;/ref&gt;  These early parametric amplifiers used the nonlinearity of an iron-core [[inductor]], so they could only function at low frequencies.

In 1948 [[Aldert van der Ziel]] pointed out a major advantage of the parametric amplifier: because it used a variable reactance instead of a resistance for amplification it had inherently low noise.&lt;ref name="Roer" /&gt;  A parametric amplifier used as the [[RF front end|front end]] of a [[radio receiver]] could amplify a weak signal while introducing very little noise.  In 1952 Harrison Rowe at [[Bell Labs]] extended some 1934 mathematical work on pumped oscillations by Jack Manley and published the modern mathematical theory of parametric oscillations, the [[Manley-Rowe relations]].&lt;ref name="Roer" /&gt; 

The [[varactor diode]] invented in 1956 had a nonlinear capacitance that was usable into microwave frequencies.  The varactor parametric amplifier was developed by Marion Hines in 1956 at [[Western Electric]].&lt;ref name="Roer"&gt;{{cite book
 | last1  = Roer
 | first1 = T.G. 
 | title  = Microwave Electronic Devices
 | publisher = Springer Science and Business Media 
 | date   = 2012
 | pages  = 7
 | url    = https://books.google.com/books?id=deDvBwAAQBAJ&amp;pg=PA7&amp;dq=%22parametric+amplifier%22+Manley+Rowe+varactor
 | doi    = 
 | id     = 
 | isbn   = 1461525004
 }}&lt;/ref&gt;  At the time it was invented microwaves were just being exploited, and the varactor amplifier was the first semiconductor amplifier at microwave frequencies.&lt;ref name="Roer" /&gt;  It was applied to low noise radio receivers in many areas, and has been widely used in [[radio telescope]]s, [[satellite ground station]]s, and long range [[radar]].  It is the main type of parametric amplifier used today.   Since that time parametric amplifiers have been built with other nonlinear active devices such as [[Josephson junction]]s.  The technique has been extended to optical frequencies in [[optical parametric oscillator]]s and amplifiers which use [[nonlinear optics|nonlinear crystals]] as the active element.

==Mathematical analysis==
A parametric oscillator is a [[harmonic oscillator]] whose physical properties vary with time.  The equation of such an oscillator is
:&lt;math&gt;
\frac{d^{2}x}{dt^{2}} + \beta(t) \frac{dx}{dt} + \omega^{2}(t) x = 0
&lt;/math&gt;
This equation is linear in &lt;math&gt;x(t)&lt;/math&gt;.  By assumption, the parameters 
&lt;math&gt;\omega^{2}&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; depend only on time and do ''not'' depend on the state of the oscillator.  In general, &lt;math&gt;\beta(t)&lt;/math&gt; and/or &lt;math&gt;\omega^{2}(t)&lt;/math&gt; are assumed to vary periodically, with the same period &lt;math&gt;T&lt;/math&gt;.

If the parameters vary at roughly ''twice'' the [[natural frequency]] of the oscillator (defined below), the oscillator phase-locks to the parametric variation and absorbs energy at a rate proportional to the energy it already has.  Without a compensating energy-loss mechanism provided by &lt;math&gt;\beta&lt;/math&gt;, the oscillation amplitude grows exponentially. (This phenomenon is called '''parametric excitation''', '''parametric resonance''' or '''parametric pumping'''.)  However, if the initial amplitude is zero, it will remain so; this distinguishes it from the non-parametric resonance of driven simple [[harmonic oscillator]]s, in which the amplitude grows linearly in time regardless of the initial state.

A familiar experience of both parametric and driven oscillation is playing on a swing.&lt;ref name=Case/&gt;&lt;ref name=Case96/&gt;&lt;ref name=Roura/&gt; Rocking back and forth pumps the swing as a [[Harmonic oscillator#Driven harmonic oscillators|driven harmonic oscillator]], but once moving, the swing can also be parametrically driven by alternately standing and squatting at key points in the swing arc. This changes moment of inertia of the swing and hence the resonance frequency, and children can quickly reach large amplitudes provided that they have some amplitude to start with (e.g., get a push).  Standing and squatting at rest, however, leads nowhere.

===Transformation of the equation===

We begin by making a change of variables

:&lt;math&gt;
q(t) \ \stackrel{\mathrm{def}}{=}\   e^{D(t)} x(t)
&lt;/math&gt;

where &lt;math&gt;D(t)&lt;/math&gt; is a time integral of the damping

:&lt;math&gt;
D(t) \ \stackrel{\mathrm{def}}{=}\   \frac{1}{2} \int^{t} d\tau \ \beta(\tau).
&lt;/math&gt;

This change of variables eliminates the damping term

:&lt;math&gt;
\frac{d^{2}q}{dt^{2}} + \Omega^{2}(t) q = 0
&lt;/math&gt;
 
where the transformed frequency is defined

:&lt;math&gt;
\Omega^{2}(t) = \omega^{2}(t) - 
\frac{1}{2} \left( \frac{d\beta}{dt} \right) - \frac{1}{4} \beta^{2}.
&lt;/math&gt;

In general, the variations in damping and frequency are relatively small perturbations

:&lt;math&gt;
\beta(t) = \omega_{0} \left[b + g(t) \right]
&lt;/math&gt;

:&lt;math&gt;
\omega^{2}(t) = \omega_{0}^{2} \left[1 + h(t) \right]
&lt;/math&gt;

where &lt;math&gt;\omega_{0}&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt; are constants, namely, the time-averaged oscillator frequency and damping, respectively.  The transformed frequency can be written in a similar way:

:&lt;math&gt;
\Omega^{2}(t) = \omega_{n}^{2} \left[1 + f(t) \right],
&lt;/math&gt;

where &lt;math&gt;\omega_{n}&lt;/math&gt; is the [[natural frequency]] of the damped harmonic oscillator

:&lt;math&gt;
\omega_{n}^{2} \ \stackrel{\mathrm{def}}{=}\   \omega_{0}^{2} \left( 1 - \frac{b^{2}}{4} \right)
&lt;/math&gt;

and

:&lt;math&gt;
\omega_{n}^{2} f(t) \ \stackrel{\mathrm{def}}{=}\   \omega_{0}^{2} \left\{h(t) - 
\frac{1}{2\omega_{0}} \left( \frac{dg}{dt} \right)
- \frac{b}{2} g(t) - \frac{1}{4} g^{2}(t)\right\}.
&lt;/math&gt;

Thus, our transformed equation can be written

:&lt;math&gt;
\frac{d^{2}q}{dt^{2}} + \omega_{n}^{2} \left[1 + f(t) \right] q = 0.
&lt;/math&gt;

The independent variations &lt;math&gt;g(t)&lt;/math&gt; and &lt;math&gt;h(t)&lt;/math&gt; in the oscillator damping and resonance frequency, respectively, can be combined into a single pumping function &lt;math&gt;f(t)&lt;/math&gt;.  The converse conclusion is that any form of parametric excitation can be accomplished by varying either the resonance frequency or the damping, or both.

===Solution of the transformed equation===

Let us assume that &lt;math&gt;f(t)&lt;/math&gt; is sinusoidal, specifically

:&lt;math&gt;
f(t) = f_{0} \sin 2\omega_{p}t
&lt;/math&gt;

where the pumping frequency &lt;math&gt;\omega_{p} \approx \omega_{n}&lt;/math&gt; but need not equal &lt;math&gt;\omega_{n}&lt;/math&gt; exactly.  The solution &lt;math&gt;q(t)&lt;/math&gt; of our transformed equation may be written

:&lt;math&gt;
q(t) = A(t) \cos \omega_{p}t + B(t) \sin \omega_{p}t
&lt;/math&gt;

where the rapidly varying components have been factored out(&lt;math&gt;\cos \omega_{p}t&lt;/math&gt; and &lt;math&gt;\sin \omega_{p}t&lt;/math&gt;) to isolate the slowly varying amplitudes &lt;math&gt;A(t)&lt;/math&gt; and &lt;math&gt;B(t)&lt;/math&gt;.  This corresponds to Laplace's variation of parameters method.

Substituting this solution into the transformed equation and retaining only the terms first-order in &lt;math&gt;f_{0} \ll 1&lt;/math&gt; yields two coupled equations

:&lt;math&gt;
2\omega_{p} \frac{dA}{dt} = 
\left( \frac{f_{0}}{2} \right) \omega_{n}^{2} A - 
\left( \omega_{p}^{2} - \omega_{n}^{2} \right) B
&lt;/math&gt;

:&lt;math&gt;
2\omega_{p} \frac{dB}{dt} = 
-\left( \frac{f_{0}}{2} \right) \omega_{n}^{2} B + 
\left( \omega_{p}^{2} - \omega_{n}^{2} \right) A
&lt;/math&gt;

These equations may be decoupled and solved by making another change of variables

:&lt;math&gt;
A(t) \ \stackrel{\mathrm{def}}{=}\   r(t) \cos \theta(t)
&lt;/math&gt;

:&lt;math&gt;
B(t) \ \stackrel{\mathrm{def}}{=}\   r(t) \sin \theta(t)
&lt;/math&gt;

which yields the equations

:&lt;math&gt;
\frac{dr}{dt} = \left( \alpha_{\mathrm{max}} \cos 2\theta \right) r
&lt;/math&gt;

:&lt;math&gt;
\frac{d\theta}{dt} = -\alpha_{\mathrm{max}} 
\left[\sin 2\theta - \sin 2\theta_{\mathrm{eq}} \right]
&lt;/math&gt;

where for brevity the following are defined

:&lt;math&gt;
\alpha_{\mathrm{max}} \ \stackrel{\mathrm{def}}{=}\   \frac{f_{0} \omega_{n}^{2}}{4\omega_{p}}
&lt;/math&gt;

:&lt;math&gt;
\sin 2\theta_{\mathrm{eq}} \ \stackrel{\mathrm{def}}{=}\   \left( \frac{2}{f_{0}} \right) \epsilon
&lt;/math&gt;

and the detuning

:&lt;math&gt;
\epsilon \ \stackrel{\mathrm{def}}{=}\   \frac{\omega_{p}^{2} - \omega_{n}^{2}}{\omega_{n}^{2}}
&lt;/math&gt;

The &lt;math&gt;\theta&lt;/math&gt; equation does not depend on &lt;math&gt;r&lt;/math&gt;, and linearization near its equilibrium position &lt;math&gt;\theta_{\mathrm{eq}}&lt;/math&gt; shows that &lt;math&gt;\theta&lt;/math&gt; decays exponentially to its equilibrium

:&lt;math&gt;
\theta(t) = \theta_{\mathrm{eq}} + 
\left( \theta_{0} - \theta_{\mathrm{eq}} \right) e^{-2\alpha t}
&lt;/math&gt;

where the decay constant

&lt;math&gt;\alpha \ \stackrel{\mathrm{def}}{=}\   \alpha_{\mathrm{max}} \cos 2\theta_{\mathrm{eq}}&lt;/math&gt;.

In other words, the parametric oscillator phase-locks to the pumping signal &lt;math&gt;f(t)&lt;/math&gt;.

Taking &lt;math&gt;\theta(t) = \theta_{\mathrm{eq}}&lt;/math&gt; (i.e., assuming that the phase has locked), the &lt;math&gt;r&lt;/math&gt; equation becomes

:&lt;math&gt;
\frac{dr}{dt} = \alpha r
&lt;/math&gt;

whose solution is &lt;math&gt;r(t) = r_{0} e^{\alpha t}&lt;/math&gt;; the amplitude of the &lt;math&gt;q(t)&lt;/math&gt; oscillation diverges exponentially.  However, the corresponding amplitude &lt;math&gt;R(t)&lt;/math&gt; of the ''untransformed'' variable &lt;math&gt;x \ \stackrel{\mathrm{def}}{=}\   q e^{-D(t)}&lt;/math&gt; need not diverge

:&lt;math&gt;
R(t) = r(t) e^{-D(t)} = r_{0} e^{\alpha t - D(t)}
&lt;/math&gt;

The amplitude &lt;math&gt;R(t)&lt;/math&gt; diverges, decays or stays constant, depending on whether &lt;math&gt;\alpha t&lt;/math&gt; is greater than, less than, or equal to &lt;math&gt;D(t)&lt;/math&gt;, respectively.

The maximum growth rate of the amplitude occurs when &lt;math&gt;\omega_{p} = \omega_{n}&lt;/math&gt;.  At that frequency, the equilibrium phase &lt;math&gt;\theta_{\mathrm{eq}}&lt;/math&gt; is zero, implying that &lt;math&gt;\cos 2\theta_{\mathrm{eq}}=1&lt;/math&gt; and &lt;math&gt;\alpha = \alpha_{\mathrm{max}}&lt;/math&gt;.  As &lt;math&gt;\omega_{p}&lt;/math&gt; is varied from &lt;math&gt;\omega_{n}&lt;/math&gt;, &lt;math&gt;\theta_{\mathrm{eq}}&lt;/math&gt; moves away from zero and &lt;math&gt;\alpha &lt; \alpha_{\mathrm{max}}&lt;/math&gt;, i.e., the amplitude grows more slowly.  For sufficiently large deviations of &lt;math&gt;\omega_{p}&lt;/math&gt;, the decay constant &lt;math&gt;\alpha&lt;/math&gt; can become purely imaginary since

:&lt;math&gt;
\alpha = \alpha_{\mathrm{max}} 
\sqrt{1- \left( \frac{2}{f_{0}} \right)^{2} \epsilon^{2}}
&lt;/math&gt;

If the detuning &lt;math&gt;\epsilon&lt;/math&gt; exceeds &lt;math&gt;f_{0}/2&lt;/math&gt;, &lt;math&gt;\alpha&lt;/math&gt; becomes purely imaginary and &lt;math&gt;q(t)&lt;/math&gt; varies sinusoidally.  Using the definition of the detuning &lt;math&gt;\epsilon&lt;/math&gt;, the pumping frequency &lt;math&gt;2\omega_{p}&lt;/math&gt; must lie between &lt;math&gt;2\omega_{n} \sqrt{1 - \frac{f_{0}}{2}}&lt;/math&gt; and &lt;math&gt;2\omega_{n} \sqrt{1 + \frac{f_{0}}{2}}&lt;/math&gt; in order to achieve exponential growth in &lt;math&gt;q&lt;/math&gt;.  Expanding the square roots in a binomial series shows that the spread in pumping frequencies that result in exponentially growing &lt;math&gt;q&lt;/math&gt; is approximately &lt;math&gt;\omega_{n} f_{0}&lt;/math&gt;.

===Intuitive derivation of parametric excitation===

The above derivation may seem like a mathematical sleight-of-hand, so it may be helpful to give an intuitive derivation.  The &lt;math&gt;q&lt;/math&gt; equation may be written in the form

:&lt;math&gt;
\frac{d^{2}q}{dt^{2}} + \omega_{n}^{2} q = -\omega_{n}^{2} f(t) q
&lt;/math&gt;

which represents a simple harmonic oscillator (or, alternatively, a [[bandpass filter]]) being driven by a signal &lt;math&gt;-\omega_{n}^{2} f(t) q&lt;/math&gt; that is proportional to its response &lt;math&gt;q&lt;/math&gt;.

Assume that &lt;math&gt;q(t) = A \cos \omega_{p} t&lt;/math&gt; already has an oscillation at frequency &lt;math&gt;\omega_{p}&lt;/math&gt; and that the pumping &lt;math&gt;f(t) = f_{0} \sin 2\omega_{p}t&lt;/math&gt; has double the frequency and a small amplitude &lt;math&gt;f_{0} \ll 1&lt;/math&gt;.  Applying a [[trigonometry|trigonometric identity]] for products of sinusoids, their product &lt;math&gt;q(t)f(t)&lt;/math&gt; produces two driving signals,
one at frequency &lt;math&gt;\omega_{p}&lt;/math&gt; and the other at frequency &lt;math&gt;3 \omega_{p}&lt;/math&gt;

:&lt;math&gt;
f(t)q(t) = \frac{f_{0}}{2} A 
\left( \sin \omega_{p} t + \sin 3\omega_{p} t \right)
&lt;/math&gt;

Being off-resonance, the &lt;math&gt;3\omega_{p}&lt;/math&gt; signal is attenuated and can be neglected initially.  By contrast, the &lt;math&gt;\omega_{p}&lt;/math&gt; signal is on resonance, serves to amplify &lt;math&gt;q&lt;/math&gt;, and is proportional to the amplitude 
&lt;math&gt;A&lt;/math&gt;.  Hence, the amplitude of &lt;math&gt;q&lt;/math&gt; grows exponentially unless it is initially zero.

Expressed in Fourier space, the multiplication &lt;math&gt;f(t)q(t)&lt;/math&gt; is a convolution of their Fourier transforms &lt;math&gt;\tilde{F}(\omega)&lt;/math&gt; and &lt;math&gt;\tilde{Q}(\omega)&lt;/math&gt;.  The positive feedback arises because the &lt;math&gt;+2\omega_{p}&lt;/math&gt; component of &lt;math&gt;f(t)&lt;/math&gt; converts the &lt;math&gt;-\omega_{p}&lt;/math&gt; component of &lt;math&gt;q(t)&lt;/math&gt; into a driving signal at 
&lt;math&gt;+\omega_{p}&lt;/math&gt;, and vice versa (reverse the signs).  This explains why the pumping frequency must be near &lt;math&gt;2\omega_{n}&lt;/math&gt;, twice the natural frequency of the oscillator.  Pumping at a grossly different frequency would not couple (i.e., provide mutual positive feedback) between the &lt;math&gt;-\omega_{p}&lt;/math&gt; and &lt;math&gt;+\omega_{p}&lt;/math&gt; components of &lt;math&gt;q(t)&lt;/math&gt;.

== Parametric resonance ==

'''Parametric resonance''' is the [[Parameter|parametric]]al [[resonance]] [[phenomenon]] of mechanical perturbation and [[oscillation]] at certain [[frequency|frequenc]]ies (and the associated [[harmonic]]s). This effect is different from regular resonance because it exhibits the [[instability]] phenomenon.

Parametric resonance occurs in a mechanical system when a system is parametrically excited and oscillates at one of its resonant frequencies. Parametric resonance takes place when the external excitation frequency equals twice the natural frequency of the system. Parametric excitation differs from forcing since the action appears as a time varying modification on a system parameter. The classical example of parametric resonance is that of the vertically forced pendulum.

For small amplitudes and by linearising, the stability of the periodic solution is given by [[Mathieu function#Mathieu equation|Mathieu's equation]]:

&lt;math&gt;\ddot{u} + (a + B \cos t)u =0 &lt;/math&gt;

where &lt;math&gt;u&lt;/math&gt; is some perturbation from the periodic solution. Here the &lt;math&gt;B\ \cos(t)&lt;/math&gt; term acts as an ‘energy’ source and is said to parametrically excite the system. The Mathieu equation describes many other physical systems to a sinusoidal parametric excitation such as an LC Circuit where the capacitor plates move sinusoidally.

==Parametric amplifiers==

===Introduction===
A parametric amplifier is implemented as a [[frequency mixer|mixer]]. The mixer's gain shows up in the output as amplifier gain. The input weak signal is mixed with a strong local oscillator signal, and the resultant strong output is used in the ensuing receiver stages.

Parametric amplifiers also operate by changing a parameter of the amplifier. 
Intuitively, this can be understood as follows, for a variable capacitor based amplifier.

Q [charge in a capacitor] =  C x V&lt;br&gt;
therefore  &lt;br&gt;
V [voltage across a capacitor] = Q/C

Knowing the above, if a capacitor is charged until its voltage equals the sampled voltage of an incoming weak signal, and if the capacitor's capacitance is then reduced (say, by manually moving the plates further apart), then the voltage across the capacitor will increase. In this way, the voltage of the weak signal is amplified.

If the capacitor is a [[varicap diode]], then the 'moving the plates' can be done simply by applying time-varying DC voltage to the varicap diode. This driving voltage usually comes from another oscillator — sometimes called a "pump".

The resulting output signal contains frequencies that are the sum and difference of the input signal (f1) and the pump signal (f2): (f1 +  f2) and (f1 - f2).

A practical parametric oscillator needs the following connections: one for the "common" or "[[ground (electrical)|ground]]", one to feed the pump, one to retrieve the output, and maybe a fourth one for biasing. A parametric amplifier needs a fifth port to input the signal being amplified. Since a varactor diode has only two connections, it can only be a part of an LC network with four [[eigenvector]]s with nodes at the connections. This can be implemented as a [[transimpedance amplifier]], a [[Traveling wave tube amplifier|traveling wave amplifier]] or by means of a [[circulator]].

===Mathematical equation===
The parametric oscillator equation can be extended by adding an external driving force &lt;math&gt;E(t)&lt;/math&gt;:

:&lt;math&gt;
\frac{d^{2}x}{dt^{2}} + \beta(t) \frac{dx}{dt} + \omega^{2}(t) x = E(t).
&lt;/math&gt;

We assume that the damping &lt;math&gt;D&lt;/math&gt; is sufficiently strong that, in the absence of the driving force &lt;math&gt;E&lt;/math&gt;, the amplitude of the parametric oscillations does not diverge, i.e., that &lt;math&gt;\alpha t &lt; D&lt;/math&gt;.  In this situation, the parametric pumping acts to lower the effective damping in the system.  For illustration, let the damping be constant &lt;math&gt;\beta(t) = \omega_{0} b&lt;/math&gt; and assume that the external driving force is at the mean resonance frequency &lt;math&gt;\omega_{0}&lt;/math&gt;, i.e., &lt;math&gt;E(t) = E_{0} \sin \omega_{0} t&lt;/math&gt;.  The equation becomes

:&lt;math&gt;
\frac{d^{2}x}{dt^{2}} + b \omega_{0} \frac{dx}{dt} + 
\omega_{0}^{2} \left[1 + h_{0} \sin 2\omega_{0} t \right] x = 
E_{0} \sin \omega_{0} t
&lt;/math&gt;

whose solution is roughly

:&lt;math&gt;
x(t) = \frac{2E_{0}}{\omega_{0}^{2} \left( 2b - h_{0} \right)} \cos \omega_{0} t.
&lt;/math&gt;

As &lt;math&gt;h_{0}&lt;/math&gt; approaches the threshold &lt;math&gt;2b&lt;/math&gt;, the amplitude diverges.  When &lt;math&gt;h \geq 2b&lt;/math&gt;, the system enters parametric resonance and the amplitude begins to grow exponentially, even in the absence of a driving force &lt;math&gt;E(t)&lt;/math&gt;.

===Advantages===
'''1''':It is highly sensitive

'''2''':low noise level amplifier for ultra high frequency and microwave radio signal

'''3''':The unique capability to operate as a wireless powered amplifier that doesn't require internal power source&lt;ref&gt;{{cite journal|doi=10.1002/mrm.23274 | volume=68 | title=Sensitivity enhancement of remotely coupled NMR detectors using wirelessly powered parametric amplification | year=2012 | journal=Magnetic Resonance in Medicine | pages=989–996 | last1 = Qian | first1 = Chunqi| pmc=3330139 }}&lt;/ref&gt;

===Other relevant mathematical results===

If the parameters of any second-order linear differential equation are varied periodically, [[Floquet analysis]] shows that the solutions must vary either sinusoidally or exponentially.

The &lt;math&gt;q&lt;/math&gt; equation above with periodically varying &lt;math&gt;f(t)&lt;/math&gt; is an example of a [[Hill differential equation|Hill equation]].  If &lt;math&gt;f(t)&lt;/math&gt; is a simple sinusoid, the equation is called a [[Mathieu equation]].

==See also==
* [[Harmonic oscillator]]
* [[Optical parametric oscillator]]
* [[Optical parametric amplifier]]
* [[Mathieu equation]]

==References==

{{reflist}}

{{Refimprove|date=May 2008}}

==Further reading ==

* Kühn L. (1914) ''Elektrotech. Z.'', '''35''', 816-819.
* {{cite journal | last1 = Mumford | first1 = WW | year = 1960 | title = Some Notes on the History of Parametric Transducers | url = | journal = Proceedings of the Institute of Radio Engineers | volume = 48 | issue = | pages = 848–853 | doi=10.1109/jrproc.1960.287620}}
* Pungs L. DRGM Nr. 588 822 (24 October 1913); DRP Nr. 281440 (1913); ''Elektrotech. Z.'', '''44''', 78-81 (1923?); ''Proc. IRE'', '''49''', 378 (1961).

==External articles==
* Elmer, Franz-Josef, "''[https://elmer.unibas.ch/pendulum/parres.htm Parametric Resonance Pendulum Lab University of Basel]''". unibas.ch, July 20, 1998.
* Cooper, Jeffery, "''[https://dx.doi.org/10.1137/S0036141098340703 Parametric Resonance in Wave Equations with a Time-Periodic Potential]''". SIAM Journal on Mathematical Analysis, Volume 31, Number 4, pp.&amp;nbsp;821–835. Society for Industrial and Applied Mathematics, 2000 .
* "''[https://web.archive.org/web/20060303175343/http://bednorzmuller87.phys.cmu.edu/demonstrations/oscillationsandwaves/drivenoscillations/demo223.html Driven Pendulum: Parametric Resonance]''". phys.cmu.edu (Demonstration of physical mechanics or classical mechanics.  Resonance oscillations set up in a simple pendulum via periodically varying pendulum length.)

[[Category:Electronic oscillators]]
[[Category:Amplifiers]]
[[Category:Dynamical systems]]
[[Category:Ordinary differential equations]]</text>
      <sha1>jein9fc6owbt84yzfd8vlg0znc6lapu</sha1>
    </revision>
  </page>
  <page>
    <title>Polyphase quadrature filter</title>
    <ns>0</ns>
    <id>237147</id>
    <revision>
      <id>819782509</id>
      <parentid>819780168</parentid>
      <timestamp>2018-01-11T07:01:13Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Technical}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2320">{{technical|date=January 2018}}
A '''polyphase quadrature filter''', or '''PQF''', is a [[filter bank]] which splits an input signal into a given number N (mostly a power of 2) of equidistant [[sub-band]]s. These sub-bands are subsampled by a factor of N, so they are critically [[sample (signal)|sampled]].&lt;ref&gt;{{Cite journal|last=Rothweiler|first=J.|date=April 1983|title=Polyphase quadrature filters–A new subband coding technique|url=http://ieeexplore.ieee.org/abstract/document/1172005/|journal=ICASSP '83. IEEE International Conference on Acoustics, Speech, and Signal Processing|volume=8|pages=1280–1283|doi=10.1109/ICASSP.1983.1172005}}&lt;/ref&gt;

This critical sampling introduces [[aliasing]]. Similar to the [[Modified discrete cosine transform|MDCT]] [[time domain alias cancellation]] the aliasing of polyphase quadrature filters is canceled by neighbouring sub-bands, i.e. signals are typically stored in two sub-bands.

Note that signal in odd subbands is stored [[frequency inverted]].

PQF filters are used in [[MPEG-1 Audio Layer I]] and [[MPEG-1 Audio Layer II|II]], [[Musepack]] (which was based on MPEG-1 layer II), in [[MP3|MPEG-1 Layer III]] with an additional MDCT, in [[MPEG-4 AAC-SSR]] for the 4 band PQF bank, in [[Spectral Band Replication|MPEG-4 V3 SBR]]
for the analysis of the upper spectral replicated band, and in [[Digital Theatre System|DTS]].

PQF has an advantage over the very similar stacked [[quadrature mirror filter]] (QMF). [[Propagation delay|Delay]] and computational effort are much lower.

A PQF filter bank is constructed using a base filter, which is a [[low-pass filter|low-pass]] at fs/4N. This lowpass is modulated by N [[cosine]] functions and converted to N [[band-pass filter|band-passes]] with a [[Bandwidth (signal processing)|bandwidth]] of fs/2N.

The base lowpass is typically a&lt;!--n?--&gt; [[finite impulse response|FIR]] filter with a length of 10*N ... 24*N taps. Note that it is also possible to build PQF filters using recursive [[infinite impulse response|IIR]] filters.

==Computation==

There are different formulas possible. Most of them are based on the [[modified discrete cosine transform|MDCT]] but are slightly modified.


==References==
&lt;references /&gt;

[[Category:Digital signal processing]]
[[Category:Linear filters]]


{{signal-processing-stub}}</text>
      <sha1>10jncicujvda70g0lq3o1g62jatsgnr</sha1>
    </revision>
  </page>
  <page>
    <title>Proof-carrying code</title>
    <ns>0</ns>
    <id>3929020</id>
    <revision>
      <id>794500027</id>
      <parentid>788977933</parentid>
      <timestamp>2017-08-08T12:09:02Z</timestamp>
      <contributor>
        <username>Sjcjoosten</username>
        <id>9228791</id>
      </contributor>
      <comment>/* Packet filter example */ Removing 'or certifying compiler': a certifying compiler does not help in this part of the story, since it does not talk about compilation at all (it talks about machine code in the previous section)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3319">'''Proof-carrying code''' ('''PCC''') is a software mechanism that allows a host system to verify properties about an application via a [[formal proof]] that accompanies the application's executable code.  The host system can quickly verify the validity of the proof, and it can compare the conclusions of the proof to its own [[security policy]] to determine whether the application is safe to execute.  This can be particularly useful in ensuring [[memory safety]] (i.e. preventing issues like [[buffer overflows]]).

Proof-carrying code was originally described in 1996 by [[George Necula]] and [[Peter Lee (computer scientist)|Peter Lee]].

==Packet filter example==
The original publication on proof-carrying code in 1996&lt;ref&gt;Necula, G. C. and Lee, P. 1996. Safe kernel extensions without run-time checking. SIGOPS Operating Systems Review 30, SI (Oct. 1996), 229–243.&lt;/ref&gt; used [[packet filter]]s as an example: a user-mode application hands a function written in machine code to the kernel that determines whether or not an application is interested in processing a particular network packet. Because the packet filter runs in [[kernel mode]], it could compromise the integrity of the system if it contains malicious code that writes to kernel data structures. Traditional approaches to this problem include interpreting a [[domain specific language]] for packet filtering, inserting checks on each memory access ([[software fault isolation]]), and writing the filter in a high-level language which is compiled by the kernel before it is run. These approaches all have severe performance disadvantages for code as frequently run as a packet filter.

With proof-carrying code, the kernel publishes a security policy specifying properties that any packet filter must obey: for example, will not access memory outside of the packet and its scratch memory area. A [[Automated theorem prover|theorem prover]] is used to show that the machine code satisfies this policy. The steps of this proof are recorded and attached to the machine code which is given to the kernel program loader. The program loader can then rapidly validate the proof, allowing it to thereafter run the machine code without any additional checks. If a malicious party modifies either the machine code or the proof, the resulting proof-carrying code is either invalid or harmless (still satisfies the security policy).

==See also==
* [[Typed assembly language]]
* [[Program derivation]]
* [[Formal verification]]

==References==
&lt;references /&gt;
* George C. Necula and Peter Lee. [http://www.eecs.berkeley.edu/~necula/Papers/tr96-165.ps.gz ''Proof-Carrying Code''].  Technical Report CMU-CS-96-165, November 1996. (62 pages)
* George C. Necula and Peter Lee.  [http://www.cs.berkeley.edu/~necula/Papers/pcc_lncs98.ps ''Safe, Untrusted Agents Using Proof-Carrying Code''].  Mobile Agents and Security, Giovanni Vigna (Ed.), Lecture Notes in Computer Science, Vol. 1419, Springer-Verlag, Berlin, {{ISBN|3-540-64792-9}}, 1998.
* George C. Necula. ''[http://www.cs.berkeley.edu/~necula/Papers/thesis.pdf Compiling with Proofs]''. PhD thesis, School of Computer Science, Carnegie Mellon Univ., Sept. 1998.

[[Category:Computer security]]
[[Category:Dependently typed programming]]
[[Category:Formal methods]]
[[Category:Programming language theory]]</text>
      <sha1>j5tfue1kh70kt588bzu3tejn0zyq0zj</sha1>
    </revision>
  </page>
  <page>
    <title>Proof-theoretic semantics</title>
    <ns>0</ns>
    <id>910505</id>
    <revision>
      <id>833753088</id>
      <parentid>799574515</parentid>
      <timestamp>2018-04-02T07:35:21Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2900">'''Proof-theoretic semantics''' is an approach to the [[Formal semantics (logic)|semantics of logic]] that attempts to locate the meaning of propositions and [[logical connective]]s not in terms of [[interpretation (logic)|interpretation]]s, as in [[Alfred Tarski|Tarski]]an approaches to semantics, but in the role that the proposition or logical connective plays within the [[Formal system|system of inference]].

[[Gerhard Gentzen]] is the founder of proof-theoretic semantics, providing the formal basis for it in his account of [[cut-elimination]] for the [[sequent calculus]], and some provocative philosophical remarks about locating the meaning of logical connectives in their introduction rules within [[natural deduction]]. The history of proof-theoretic semantics since then has been devoted to exploring the consequences of these ideas.{{Citation needed|date=December 2014}}

[[Dag Prawitz]] extended Gentzen's notion of [[analytic proof]] to [[natural deduction]], and suggested that the value of a proof in natural deduction may be understood as its normal form.  This idea lies at the basis of the [[Curry&amp;ndash;Howard isomorphism]], and of [[intuitionistic type theory]].  His [[inversion principle]] lies at the heart of most modern accounts of proof-theoretic semantics.

[[Michael Dummett]] introduced the very fundamental idea of [[logical harmony]], building on a suggestion of [[Nuel Belnap]].  In brief, a language, which is understood to be associated with certain patterns of inference, has logical harmony if it is always possible to recover analytic proofs from arbitrary demonstrations, as can be shown for the sequent calculus by means of cut-elimination theorems and for natural deduction by means of normalisation theorems.  A language that lacks logical harmony will suffer from the existence of incoherent forms of inference: it will likely be inconsistent.

==See also==
* [[Inferential role semantics]]
* [[Truth-conditional semantics]]

==References==
*[http://plato.stanford.edu/entries/proof-theoretic-semantics/ Proof-Theoretic Semantics], at the [[Stanford Encyclopedia of Philosophy]]
*[http://www.iep.utm.edu/l/logcon-d.htm Logical Consequence, Deductive-Theoretic Conceptions], at the [[Internet Encyclopedia of Philosophy]].
* Nissim Francez, "On a Distinction of Two Facets of Meaning and its Role in Proof-theoretic Semantics", ''[[Logica Universalis]]'' 9, 2015. {{doi|10.1007/s11787-015-0118-8}}
*  Thomas Piecha, Peter Schroeder-Heister (eds), [https://link.springer.com/book/10.1007%2F978-3-319-22686-6 "Advances in Proof-Theoretic Semantics"], Trends in Logic 43, Springer, 2016.

==External links==

*[https://web.archive.org/web/20090415110223/http://arche-wiki.st-and.ac.uk/~ahwiki/bin/view/Arche/ProofTheoreticSemantics Arché Bibliography on Proof-Theoretic Semantics.]

{{logic-stub}}
[[Category:Philosophical logic]]
[[Category:Proof theory]]</text>
      <sha1>5wo1s4jaj9wg7snxlso9oofc6wdf3pn</sha1>
    </revision>
  </page>
  <page>
    <title>Rarita–Schwinger equation</title>
    <ns>0</ns>
    <id>1531781</id>
    <revision>
      <id>855441512</id>
      <parentid>815637165</parentid>
      <timestamp>2018-08-18T09:27:30Z</timestamp>
      <contributor>
        <ip>5.170.243.96</ip>
      </contributor>
      <comment>specified that the local fermionic symmetry for the massless R-S is local supersymmetry and this implies supergravity.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6505">In [[theoretical physics]], the '''Rarita–Schwinger equation''' is the
[[theory of relativity|relativistic]] [[field equation]] of [[spin (physics)|spin]]-3/2 [[fermion]]s. It is similar to the [[Dirac equation]] for spin-1/2 fermions. This equation was first introduced by [[William Rarita]] and [[Julian Schwinger]] in 1941. 

In modern notation it can be written as:&lt;ref&gt;S. Weinberg, "The quantum theory of fields", Vol. 3, Cambridge p. 335&lt;/ref&gt;
:&lt;math&gt; \left ( \epsilon^{\mu \kappa \rho \nu} \gamma_5 \gamma_\kappa \partial_\rho - i m \sigma^{\mu \nu} \right)\psi_\nu = 0 &lt;/math&gt;
where &lt;math&gt;\epsilon^{\mu\kappa\rho\nu}&lt;/math&gt; is the [[Levi-Civita symbol]],
&lt;math&gt;\gamma_5&lt;/math&gt; and &lt;math&gt;\gamma_\nu&lt;/math&gt; are [[Dirac matrices]],
&lt;math&gt;m&lt;/math&gt; is the mass,
&lt;math&gt;\sigma^{\mu\nu} \equiv \frac{i}{2} [\gamma^\mu,\gamma^\nu] &lt;/math&gt;,
and &lt;math&gt;\psi_\nu&lt;/math&gt; is a vector-valued [[spinor]] with additional components compared to the four component spinor in the Dirac equation. It corresponds to the {{math|({{sfrac|1|2}}, {{sfrac|1|2}}) ⊗ (({{sfrac|1|2}}, 0) ⊕ (0, {{sfrac|1|2}}))}} [[Representations of the Lorentz group|representation of the Lorentz group]], or rather, its {{math|(1, {{sfrac|1|2}}) ⊕ ({{sfrac|1|2}}, 1)}} part.&lt;ref&gt;S. Weinberg, "The quantum theory of fields", Vol. 1, Cambridge p. 232&lt;/ref&gt;


This field equation can be derived as the [[Euler&amp;ndash;Lagrange equation]] corresponding to the Rarita–Schwinger [[Lagrangian (field theory)|Lagrangian]]:&lt;ref&gt;S. Weinberg, "The quantum theory of fields", Vol. 3, Cambridge p. 335&lt;/ref&gt;
:&lt;math&gt;\mathcal{L}=-\tfrac{1}{2}\;\bar{\psi}_\mu \left ( \epsilon^{\mu \kappa \rho \nu} \gamma_5 \gamma_\kappa \partial_\rho - i m \sigma^{\mu \nu} \right)\psi_\nu&lt;/math&gt;
where the bar above &lt;math&gt;\psi_\mu&lt;/math&gt; denotes the [[Dirac adjoint]].

This equation controls the propagation of the [[wave function]] of composite objects such as the [[delta baryon]]s ({{SubatomicParticle|Delta}}) or for the  conjectural [[gravitino]]. So far, no [[elementary particle]] with spin 3/2 has been found experimentally.  

The massless Rarita–Schwinger equation has a fermionic gauge symmetry: is invariant under the gauge transformation &lt;math&gt;\psi_\mu \rightarrow \psi_\mu + \partial_\mu \epsilon&lt;/math&gt;, where &lt;math&gt;\epsilon\equiv \epsilon_\alpha&lt;/math&gt;  is an arbitrary spinor field. This is simply the local [[supersymmetry]] of [[supergravity]], and the field must be a gravitino.

"Weyl" and "Majorana" versions of the Rarita–Schwinger equation also exist.

==Equations of motion in the massless case==
Consider a massless Rarita-Schwinger field described by the Lagrangian density
:&lt;math&gt; \mathcal L_{RS} = \bar \psi_\mu \gamma^{\mu\nu\rho} \partial_\nu \psi_\rho,&lt;/math&gt;
where the sum over spin indices is implicit, &lt;math&gt;\psi_\mu&lt;/math&gt; are Majorana spinors, and
:&lt;math&gt; \gamma^{\mu\nu\rho} \equiv \frac{1}{3!} \gamma^{[\mu}\gamma^\nu \gamma^{\rho]}. &lt;/math&gt;

To obtain the equations of motion we vary the Lagrangian with respect to the fields &lt;math&gt;\psi_\mu&lt;/math&gt;, obtaining:
:&lt;math&gt; \delta \mathcal L_{RS} =
    \delta \bar \psi_\mu \gamma^{\mu\nu\rho} \partial_\nu \psi_\rho
    + \bar \psi_\mu \gamma^{\mu\nu\rho} \partial_\nu \delta \psi_\rho
    = \delta \bar \psi_\mu \gamma^{\mu\nu\rho} \partial_\nu \psi_\rho
    - \partial_\nu \bar \psi_\mu \gamma^{\mu\nu\rho} \delta \psi_\rho
    + \text{ boundary terms}
&lt;/math&gt;
using the Majorana flip properties&lt;ref&gt;Pierre Ramond - Field theory, a Modern Primer - p.40&lt;/ref&gt;
we see that the second and first terms on the RHS are equal, concluding that
:&lt;math&gt; \delta \mathcal L_{RS} = 2 \delta \bar \psi_\mu \gamma^{\mu\nu\rho} \partial_\nu \psi_\rho, &lt;/math&gt;
plus unimportant boundary terms.
Imposing &lt;math&gt; \delta \mathcal L_{RS} = 0&lt;/math&gt; we thus see that the equation of motion for a massless Majorana Rarita-Schwinger spinor reads:
:&lt;math&gt; \gamma^{\mu\nu\rho} \partial_\nu \psi_\rho = 0. &lt;/math&gt;

==Drawbacks of the equation==
The current description of massive, higher spin fields through either Rarita–Schwinger or [[Fierz–Pauli equation|Fierz–Pauli]] formalisms is afflicted with several maladies.

===Superluminal propagation===

As in the case of the Dirac equation, electromagnetic interaction can be added by promoting the partial derivative to [[gauge covariant derivative]]:
:&lt;math&gt;\partial_\mu \rightarrow D_\mu = \partial_\mu - i e A_\mu &lt;/math&gt;.
In 1969, Velo and Zwanziger showed that the Rarita–Schwinger Lagrangian coupled to [[electromagnetism]] leads to equation with solutions representing wavefronts, some of which propagate faster than light. In other words, 
the field then suffers from acausal, superluminal propagation; consequently, the [[Quantization (physics)|quantization]] in interaction with electromagnetism is essentially flawed{{why|date=February 2016}}. In extended supergravity, though, Das and Freedman&lt;ref&gt;{{Cite journal | doi = 10.1016/0550-3213(76)90589-7| title = Gauge quantization for spin-3/2 fields| journal = Nuclear Physics B| volume = 114| issue = 2| pages = 271| year = 1976| last1 = Das | first1 = A. | last2 = Freedman | first2 = D. Z. |bibcode = 1976NuPhB.114..271D }}; {{Cite journal | doi = 10.1016/0550-3213(77)90041-4| title = Gauge internal symmetry in extended supergravity| journal = Nuclear Physics B| volume = 120| issue = 2| pages = 221| year = 1977| last1 = Freedman | first1 = D. Z. | last2 = Das | first2 = A. |bibcode = 1977NuPhB.120..221F }}&lt;/ref&gt; have shown that local supersymmetry solves this problem{{how|date=February 2016}}.

==References==
&lt;references/&gt;

==Sources==
* W. Rarita and J. Schwinger, ''[http://prola.aps.org/abstract/PR/v60/i1/p61_1 On a Theory of Particles with Half-Integral Spin] Phys. Rev. 60, 61 (1941).
* Collins P.D.B., Martin A.D., Squires E.J., ''Particle physics and cosmology'' (1989) Wiley, ''Section 1.6''.
* G. Velo, D. Zwanziger, ''Propagation and Quantization of Rarita–Schwinger Waves in an External Electromagnetic Potential'', Phys. Rev. 186, 1337 (1969).
* G. Velo, D. Zwanziger, ''Noncausality and Other Defects of Interaction Lagrangians for Particles with Spin One and Higher'', Phys. Rev. 188, 2218 (1969).
* M. Kobayashi, A. Shamaly, ''Minimal Electromagnetic coupling for massive spin-two fields'', Phys. Rev. D 17,8, 2179 (1978).

{{DEFAULTSORT:Rarita-Schwinger equation}}
[[Category:Quantum field theory]]
[[Category:Spinors]]
[[Category:Partial differential equations]]
[[Category:Fermions]]
[[Category:Equations of physics]]
[[Category:Mathematical physics]]</text>
      <sha1>f7lhg422cy7p354nznal6g9it1kheju</sha1>
    </revision>
  </page>
  <page>
    <title>Sergei Natanovich Bernstein</title>
    <ns>0</ns>
    <id>976516</id>
    <revision>
      <id>842799379</id>
      <parentid>842752898</parentid>
      <timestamp>2018-05-24T18:51:15Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove [[:Category:Jewish mathematicians]]. [[WP:G4]] per [[:WP:Categories for discussion/Log/2007 May 14#Category:Jewish_mathematicians]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6602">{{Infobox scientist
| name = Sergei Natanovich Bernstein
| image = Snbernstein.jpg
| image_size = 200px
| caption = Sergei Natanovich Bernstein
| birth_date = {{birth date|1880|3|5|df=y}}
| birth_place = [[Odessa]], [[Kherson Governorate]], [[Russian Empire]]
| death_date = {{death date and age|1968|10|26|1880|3|5|df=y}}
| death_place = [[Moscow]], [[Soviet Union]]
| nationality = Soviet
| residence = [[Russian Empire]], [[Soviet Union]]
| field = [[Mathematics]]
| work_institution = [[University of Paris]]&lt;br /&gt; [[University of Goettingen]]&lt;br /&gt; [[University of Kharkiv]]&lt;br /&gt; [[Saint Petersburg State University|Leningrad University]]&lt;br /&gt;[[Steklov Institute of Mathematics]]
| alma_mater = [[University of Paris]]
| doctoral_advisor = [[Charles Émile Picard]]&lt;br&gt;[[David Hilbert]]
| doctoral_students =[[Yakov Geronimus]]&lt;br&gt;[[Sergey Stechkin]] 
| known_for  = [[Bernstein's inequality (mathematical analysis)|Bernstein's inequality]] in analysis &lt;br&gt; [[Bernstein inequalities in probability theory]] &lt;br&gt; [[Bernstein polynomial]] &lt;br&gt; [[Bernstein's theorem (approximation theory)]] &lt;br&gt; [[Bernstein's theorem on monotone functions]] &lt;br&gt; [[Bernstein problem in mathematical genetics]]
| prizes = 
| religion = 
| footnotes = 
}}

'''Sergei Natanovich Bernstein''' ({{lang-ru|Серге́й Ната́нович Бернште́йн}}, sometimes Romanized as {{lang|ru-Latn|Bernshtein}}; 5 March 1880 – 26 October 1968) was a [[Russian Empire|Russia]]n and [[USSR|Soviet]] [[mathematician]] of Jewish origin known for contributions to [[partial differential equations]], [[differential geometry]], [[probability theory]], and [[approximation theory]].&lt;ref&gt;{{cite book|first=A. P.|last= Youschkevitch|chapter = BERNSTEIN, SERGEY NATANOVICH|title=Dictionary of Scientific Biography|url=
http://www.encyclopedia.com/doc/1G2-2830904824.html}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|first=S. M. |last=Lozinskii|year=1983|title=On the hundredth anniversary of the birth of S. N. Bernstein|journal=Russ. Math. Surv.|volume=38|page=163|doi=10.1070/RM1983v038n03ABEH003497}}&lt;/ref&gt;

==Work==

===Partial differential equations===

In his doctoral dissertation, submitted in 1904 to the [[University of Paris|Sorbonne]], Bernstein solved [[Hilbert's nineteenth problem]] on the analytic solution of elliptic differential equations.&lt;ref&gt;{{cite journal|first1=N.I.|last1=Akhiezer|author1-link=Naum Akhiezer|first2=I.G.|last2=Petrovskii|author2-link=Ivan Petrovsky|title=S. N. Bernshtein's contribution to the theory of partial differential equations|year=1961|journal=Russ. Math. Surv.|volume= 16|url=http://iopscience.iop.org/0036-0279/16/2/A01}}&lt;/ref&gt; His later work was devoted to Dirichlet's boundary problem for non-linear equations of elliptic type, where, in particular, he introduced [[a priori estimate]]s.

===Probability theory===

In 1917, Bernstein suggested the first axiomatic foundation of probability theory, based on the underlying algebraic structure.&lt;ref&gt;{{cite journal|mr=0130818|last=Linnik|first=Ju. V.|author-link=Yuri Linnik|title=The contribution of S. N. Bernšteĭn to the theory of probability|journal=Russ. Math. Surv.|year=1961|volume=16|issue=2|pages=21&amp;ndash;22|doi=10.1070/rm1961v016n02abeh004103}}&lt;/ref&gt; It was later superseded by the [[measure theory|measure-theoretic]] approach of [[Kolmogorov]].

In the 1920s, he introduced a method for proving [[central limit theorem|limit theorems]] for sums of dependent [[random variable]]s.

===Approximation theory===
Through his application of [[Bernstein polynomial]]s, he laid the foundations of [[constructive function theory]], a field studying the connection between smoothness properties of a function and its approximations by polynomials.&lt;ref&gt;{{cite journal|first=V. S.|last=Videnskii|year=1961|journal=Russ. Math. Surv.|volume=16|page=17|title=Sergei Natanovich Bernshtein &amp;mdash; founder of the constructive theory of functions|doi=10.1070/RM1961v016n02ABEH004102}}&lt;/ref&gt; In particular, he proved 
the [[Stone–Weierstrass theorem|Weierstrass approximation theorem]]&lt;ref&gt;S. Bernstein (1912–13) "Démonstration du théroème de Weierstrass, fondeé sur le calcul des probabilités, ''Commun. Soc. Math. Kharkow'' (2) 13: 1-2&lt;/ref&gt;&lt;ref&gt;Kenneth M. Lavasseur (1984) [https://www.jstor.org/stable/2322960 A Probabilistic Proof of the Weierstrass Theorem], [[American Mathematical Monthly]] 91(4): 249,50&lt;/ref&gt; and [[Bernstein's theorem (approximation theory)]].

==Publications==
* S. N. Bernstein, ''Collected Works'' (Russian):
** vol. 1, ''The Constructive Theory of Functions'' (1905–1930), translated: Atomic Energy Commission, Springfield, Va, 1958
** vol. 2, ''The Constructive Theory of Functions'' (1931–1953)
** vol. 3, ''Differential equations, calculus of variations and geometry'' (1903–1947)
** vol. 4, ''Theory of Probability. Mathematical statistics'' (1911–1946)
* S. N. Bernstein, ''The Theory of Probabilities'' (Russian), Moscow, Leningrad, 1946

==See also==
*[[A priori estimate]]
*[[Bernstein algebra]]
*[[Bernstein's inequality (mathematical analysis)]]
*[[Bernstein inequalities in probability theory]]
*[[Bernstein polynomial]]
*[[Bernstein's problem]]
*[[Bernstein's theorem (approximation theory)]]
*[[Bernstein's theorem on monotone functions]]
*[[Bernstein–von Mises theorem]]
*[[Stone–Weierstrass theorem]]

==Notes==
{{Reflist}}

==References==

*{{MacTutor|id=Bernstein_Sergi}}

==External links==
*{{MathGenealogy |id=53459}}
*[http://www.math.technion.ac.il/hat/people/bernstein.html Sergei Natanovich Bernstein] and history of approximation theory from [[Technion — Israel Institute of Technology]]
*[https://zbmath.org/authors/?q=ai:author_id Author profile] in the database [[Zentralblatt MATH|zbMATH]]

{{Authority control}}

{{DEFAULTSORT:Bernstein, Sergei Natanovich}}
[[Category:1880 births]]
[[Category:1968 deaths]]
[[Category:People from Odessa]]
[[Category:People from Kherson Governorate]]
[[Category:Ukrainian Jews]]
[[Category:Approximation theorists]]
[[Category:Probability theorists]]
[[Category:19th-century mathematicians]]
[[Category:20th-century Ukrainian mathematicians]]
[[Category:Soviet mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Ukrainian mathematicians]]
[[Category:PDE theorists]]
[[Category:University of Paris alumni]]
[[Category:University of Kharkiv faculty]]
[[Category:Corresponding Members of the Russian Academy of Sciences (1917–25)]]
[[Category:Full Members of the USSR Academy of Sciences]]
[[Category:Stalin Prize winners]]
[[Category:Recipients of the Order of Lenin]]
[[Category:Moscow State University faculty]]</text>
      <sha1>7gpoqm4s98afwwq9iyorr6vj6ated8i</sha1>
    </revision>
  </page>
  <page>
    <title>Snedecor Award</title>
    <ns>0</ns>
    <id>47945620</id>
    <revision>
      <id>847901518</id>
      <parentid>822138176</parentid>
      <timestamp>2018-06-28T15:18:06Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Div col]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1259">{{unreferenced|date=September 2015}}
The '''Snedecor Award''', named after [[George W. Snedecor]], is given by the [[Committee of Presidents of Statistical Societies]] to a [[statistician]] for contribution to [[biometry]].

==Winners==
{{Div col|colwidth=20em}}
* 1977: [[Philip Dawid|A. P. Dawid]]
* 1978: [[Bruce W. Turnbull]]
* 1979: [[Ethel S. Gilbert]]
* 1981: [[Barry H. Margolin]]
* 1982: [[Byron J. T. Morgan]]
* 1983: [[D. S. Robson]]
* 1984: [[Stuart H. Hurlbert]]
* 1985: [[Mitchell H. Gail]]
* 1986: [[Scott L. Zeger]]
* 1987: [[George E. Bonney]]
* 1988: [[Cyrus R. Mehta]]
* 1989: [[Barry I. Graubard]]
* 1990: [[Kenneth H. Pollock]]
* 1993: [[Kenneth L. Lange]]
* 1995: [[Norman Breslow|Norman E. Breslow]]
* 1997: [[Michael A. Newton]]
* 1999: [[Daniel Scharfstein]]
* 2001: [[Patrick J. Heagerty]]
* 2003: [[Paul R. Rosenbaum]]
* 2005: [[Nicholas P. Jewell]]
* 2007: [[Donald Rubin]]
* 2009: [[Marie Davidian]]
* 2011: [[Nilanjan Chatterjee]]
* 2013: [[Jack Kalbfleisch]]
* 2015: [[Danyu Lin]]
* 2017: [[Aurore Delaigle]]
{{div col end}}

== External links ==
* [http://community.amstat.org/copss/awards/snedecor Snedecor Award website]

[[Category:Statistical awards]]
[[Category:Mathematics awards]]
[[Category:Awards established in 1976]]</text>
      <sha1>o32ia9m4800qydrs9pqst5z4zxilmgl</sha1>
    </revision>
  </page>
  <page>
    <title>Time delay neural network</title>
    <ns>0</ns>
    <id>23594537</id>
    <revision>
      <id>866178689</id>
      <parentid>846736072</parentid>
      <timestamp>2018-10-28T19:49:17Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: IEEE Transactions on Acoustics, Speech and Signal Processing → IEEE Transactions on Acoustics, Speech, and Signal Processing (2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14181">[[File:TDNN Diagram.png|thumb|right|TDNN Diagram]]

'''Time delay neural network''' ('''TDNN''') &lt;ref name="phoneme detection"&gt;[[Alex Waibel|Alexander Waibel]], Tashiyuki Hanazawa, [[Geoffrey Hinton]], Kiyohito Shikano, Kevin J. Lang, ''Phoneme Recognition Using Time-Delay Neural Networks'', IEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. - 339 March 1989.&lt;/ref&gt; is a multilayer [[artificial neural network]] architecture whose purpose is to 1) classify patterns with shift-invariance, and 2) model context at each layer of the network.

Shift-invariant classification means that the classifier does not require explicit segmentation prior to classification. For the classification of a temporal pattern (such as speech), the TDNN thus avoids having to determine the beginning and end points of sounds before classifying them.

For contextual modelling in a TDNN, each neural unit at each layer receives input not only from activations/features at the layer below, but from a pattern of unit output and its context.  For time signals each unit receives as input the activation patterns over time from units below.  Applied to two-dimensional classification (images, time-frequency patterns), the TDNN can be trained with shift-invariance in the coordinate space and avoids precise segmentation in the coordinate space.

== History ==
The TDNN was first proposed to classify [[phonemes]] in speech signals for automatic [[speech recognition]], where the automatic determination of precise segments or feature boundaries is difficult or impossible. Because the TDNN recognizes phonemes and their underlying acoustic/phonetic features, independent of position in time, it improved performance over static classification.&lt;ref name="phoneme detection" /&gt;&lt;ref name=":0"&gt;Alexander Waibel, ''Phoneme Recognition Using Time-Delay Neural Networks'', SP87-100, Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE), December, 1987,Tokyo, Japan.&lt;/ref&gt; It was also applied to two-dimensional signals (time-frequency patterns in speech,&lt;ref name=":1"&gt;John B. Hampshire and Alexander Waibel, ''Connectionist Architectures for Multi-Speaker Phoneme Recognition'',  Advances in Neural Information Processing Systems, 1990, Morgan Kaufmann.&lt;/ref&gt; and coordinate space pattern in OCR.&lt;ref name=":2"&gt;Stefan Jaeger, Stefan Manke, Juergen Reichert, Alexander Waibel, ''Online handwriting recognition: the NPen++recognizer'', International Journal on Document Analysis and Recognition Vol. 3, Issue 3, March 2001&lt;/ref&gt;

==Overview==
The Time Delay Neural Network, like other neural networks, operates with multiple interconnected layers of [[perceptron]]s, and is implemented as a  [[feedforward neural network]]. All neurons (at each layer) of a TDNN receive inputs from the outputs of neurons at the layer below but with two differences:

# Unlike regular [[Multilayer perceptron|Multi-Layer perceptrons]], all units in a TDNN, at each layer, obtain inputs from a contextual ''window'' of outputs from the layer below.  For time varying signals (e.g. speech), each unit has connections to the output from units below but also to the time-delayed (past) outputs from these same units. This models the units' temporal pattern/trajectory.  For two-dimensional signals (e.g. time-frequency patterns or images), a 2-D context window is observed at each layer.  Higher layers have inputs from widening context windows than lower layers and thus generally model coarser levels of abstraction.
# Shift-invariance is achieved by explicitly removing position dependence during [[backpropagation]] training.  This is done by making time-shifted copies of a network across the dimension of invariance (here: time). The error gradient is then computed by backpropagation through all these networks from an overall target vector, but before performing the weight update, the error gradients associated with shifted copies are averaged and thus shared and constraint to be equal. Thus, all position dependence from backpropagation training through the shifted copies is removed and the copied networks learn the most salient hidden features shift-invariantly, i.e. independent of their precise position in the input data.  Shift-invariance is also readily extended to multiple dimensions by imposing similar weight-sharing across copies that are shifted along multiple dimensions.&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;

=== Example ===

In the case of a speech signal, inputs are spectral coefficients over time.

In order to learn critical acoustic-phonetic features (for example formant transitions, bursts, frication, etc.) without first requiring precise localization, the TDNN is trained time-shift-invariantly. Time-shift invariance is achieved through weight sharing across time during training:  Time shifted copies of the TDNN are made over the input range (from left to right in Fig.1).  Backpropagation is then performed from an overall classification target vector (see TDNN diagram, three phoneme class targets (/b/, /d/, /g/) are shown in the output layer), resulting in gradients that will generally vary for each of the time-shifted network copies.  Since such time-shifted networks are only copies, however, the position dependence is removed by weight sharing.  In this example, this is done by averaging the gradients from each time-shifted copy before performing the weight update.  In speech, time-shift invariant training was shown to learn weight matrices that are independent of precise positioning of the input. The weight matrices could also be shown to detect important acoustic-phonetic features that are known to be important for human speech perception, such as formant transitions, bursts, etc.&lt;ref name="phoneme detection" /&gt; TDNN’s could also be combined or grown by way of pre-training.&lt;ref name=":3"&gt;Alexander Waibel, Hidefumi Sawai, Kiyohiro Shikano, ''Modularity and Scaling in Large Phonemic Neural Networks'',  IEEE Transactions on Acoustics, Speech, and Signal Processing, December, December 1989.&lt;/ref&gt;

=== Implementation ===

The precise architecture of TDNNs (time-delays, number of layers) is mostly determined by the designer depending on the classification problem and the most useful context sizes.  The delays or context windows are chosen specific to each application.  Work has also been done to create adaptable time-delay TDNNs &lt;ref&gt;Christian Koehler and Joachim K. Anlauf, ''An adaptable time-delay neural-network algorithm for image sequence analysis'', IEEE Transactions on Neural Networks 10.6 (1999): 1531-1536&lt;/ref&gt; where this manual tuning is eliminated.

=== State of the Art ===

TDNN based phoneme recognizers compared favourably in early comparisons with HMM based phone models.&lt;ref name="phoneme detection" /&gt;&lt;ref name=":3" /&gt;  Modern deep TDNN architectures include many more hidden layers and sub-sample or pool connections over broader contexts at higher layers.  They achieve up to 50% word error reduction over [[Mixture model|GMM]] based acoustic models.&lt;ref name=":4"&gt;Vijayaditya Peddinti, Daniel Povey, Sanjeev Khudanpur, ''A time delay neural network architecture for efficient modeling of long temporal contexts'', Proceedings of Interspeech 2015&lt;/ref&gt;&lt;ref name=":5"&gt;David Snyder, Daniel Garcia-Romero, Daniel Povey, ''A Time-Delay Deep Neural Network-Based Universal Background Models for Speaker Recognition'', Proceedings of  ASRU 2015.&lt;/ref&gt;  While the different layers of TDNN’s are intended to learn features of increasing context width, they do model local contexts.  When longer distance relationships and pattern sequences have to be processed, learning states and state-sequences is important and TDNNs can be combined with other modelling techniques &lt;ref name=":6"&gt;Patrick Haffner, Alexander Waibel, ''Multi-State Time Delay Neural Networks for Continuous Speech Recognition'', Advances in Neural Information Processing Systems, 1992, Morgan Kaufmann.&lt;/ref&gt;&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;

==Applications==

=== Speech Recognition ===

TDNNs used to solve problems in speech recognition that were introduced in 1987 &lt;ref name=":0" /&gt; and initially focused on shift-invariant phoneme recognition.  Speech lends itself nicely to TDNNs as spoken sounds are rarely of uniform length and precise segmentation is difficult or impossible.  By scanning a sound over past and future, the TDNN is able to construct a model for the key elements of that sound in a time-shift invariant manner.  This is particularly useful as sounds are smeared out through reverberation.&lt;ref name=":4" /&gt;&lt;ref name=":5" /&gt;  Large phonetic TDNN’s can be constructed modularly through pre-training and combining smaller networks.&lt;ref name=":3" /&gt;

=== Large Vocabulary Speech Recognition ===

Large vocabulary speech recognition requires recognizing sequences of phonemes that make up words subject to the constraints of a large pronunciation vocabulary.  Integration of TDNNs into large vocabulary speech recognizers is possible by introducing state transitions and search between phonemes that make up a word.  The resulting Multi-State Time-Delay Neural Network (MS-TDNN) can be trained discriminative from the word level, thereby optimizing the entire arrangement toward word recognition instead of phoneme classification.&lt;ref name=":6" /&gt;&lt;ref name=":7"&gt;Christoph Bregler, Hermann Hild, Stefan Manke, Alexander Waibel, ''Improving Connected Letter Recognition by Lipreading'', IEEE Proceedings International Conference on Acoustics, Speech, and Signal Processing, Minneapolis, 1993.&lt;/ref&gt;&lt;ref name=":2" /&gt;

=== Speaker Independence ===

Two-dimensional variants of the TDNN’s were proposed for speaker independence.&lt;ref name=":1" /&gt; Here, shift-invariance is applied to the time ''as well as'' to the frequency axis in order to learn hidden features that are independent of precise location in time and in frequency (the latter being due to speaker variability).

=== Reverberation ===

One of the persistent problems in speech recognition is recognizing speech when it is corrupted by echo and reverberation (as is the case in large rooms and distant microphones).  Reverberation can be viewed as corrupting speech with delayed versions of itself.  In general, it is difficult, however, to de-reverberate a signal as the impulse response function (and thus the convolutional noise experienced by the signal) is not known for any arbitrary space.  The TDNN was shown to be effective to recognize speech robustly despite different levels of reverberation.&lt;ref name=":4" /&gt;&lt;ref name=":5" /&gt;

=== Lip-reading – Audio-Visual Speech ===

TDNNs were also successfully used in early demonstrations of audio-visual speech, where the sounds of speech are complemented by visually reading lip movement.&lt;ref name=":7" /&gt;  Here, TDNN based recognizers used visual and acoustic features jointly to achieve improved recognition accuracy, particularly in the presence of noise, where complementary information from an alternate modality could be fused nicely in a neural net.

=== Handwriting Recognition ===

TDNNs have been used effectively in compact and high-performance handwriting recognition systems. Shift-invariance was also adapted to spatial patterns (x/y-axes) in image offline handwriting recognition.&lt;ref name=":2" /&gt;

=== Video Analysis ===

Video has a temporal dimension that makes a TDNN an ideal solution to analysing motion patterns. An example of this analysis is a combination of vehicle detection and recognizing pedestrians.&lt;ref&gt;Christian Woehler and Joachim K. Anlauf, Real-time object recognition on image sequences with the adaptable time delay neural network algorithm—applications for autonomous vehicles." Image and Vision Computing 19.9 (2001): 593-618.&lt;/ref&gt; When examining videos, subsequent images are fed into the TDNN as input where each image is the next frame in the video. The strength of the TDNN comes from its ability to examine objects shifted in time forward and backward to define an object detectable as the time is altered. If an object can be recognized in this manner, an application can plan on that object to be found in the future and perform an optimal action.

=== Image Recognition ===

Two-dimensional TDNNs were later applied to other image recognition tasks under the name of “[[Convolutional neural network|Convolutional Neural Networks]]”, where shift-invariant training is applied to the x/y axes of an image.

=== Common Libraries ===

*TDNNs can be implemented in virtually all machine learning frameworks using one dimensional [[convolutional neural network]]s, due to the equivalence of the methods. 
*[[Matlab]]: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function. The default training algorithm is a Supervised Learning back-propagation algorithm that updates filter weights based on the Levenberg-Marquardt optimizations. The function is timedelaynet(delays, hidden_layers, train_fnc) and returns a time-delay neural network architecture that a user can train and provide inputs to.&lt;ref&gt;''"Time Series and Dynamic Systems - MATLAB &amp; Simulink".'' mathworks.com. Retrieved 21 June 2016.&lt;/ref&gt;
*The [[Kaldi (software)|Kaldi ASR Toolkit]] has an implementation of TDNNs with several optimizations for speech recognition &lt;ref&gt;Vijayaditya Peddinti, Guoguo Chen, Vimal Manohar, Tom Ko, Daniel Povey, Sanjeev Khudanpur, ''JHU ASpIRE system: Robust LVCSR with TDNNs i-vector Adaptation and RNN-LMs'', Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop, 2015.&lt;/ref&gt;

==See also==

* [[Convolutional neural network]] - a convolutional neural net where the convolution is performed along the time axis of the data is very similar to a TDNN.
* [[Recurrent neural networks]] - a recurrent neural network also handles temporal data, albeit in a different manner. Instead of a time-varied input, RNNs maintain internal hidden layers to keep track of past (and in the case of Bi-directional RNNs, future) inputs.

==References==
{{reflist}}

[[Category:Artificial neural networks]]</text>
      <sha1>q5wm72xc6lf9sb4y4sglfwjiye6k98f</sha1>
    </revision>
  </page>
  <page>
    <title>TopFIND</title>
    <ns>0</ns>
    <id>33178845</id>
    <revision>
      <id>836050636</id>
      <parentid>832596684</parentid>
      <timestamp>2018-04-12T11:39:44Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Background */[[User:JCW-CleanerBot#Logic|task]], replaced: Molecular &amp; cellular proteomics : MCP →  	Molecular &amp; Cellular Proteomics using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10316">{{infobox biodatabase
|title = TopFIND
|description = '''TopFIND''' is the '''T'''ermini '''o'''riented '''p'''rotein '''F'''unction '''I'''nferred '''D'''atabase, a central resource of [[protein]] data integrated with knowledge on [[protein]] termini, proteolytic processing by [[protease]]s, terminal amino acid modifications and inferred functional implications created by combining community contributions with the [[UniProt]] and [[MEROPS]] [[database]]s.
|scope = Protein annotation
|organism = H. sapiens, M. musculus, A. thaliana, S. cerevisiae, E. coli
|center = [[University of British Columbia]] (UBC), Canada
|laboratory = Christopher Overall
|author = Philipp F. Lange
|citation = TopFIND 2.0--linking protein termini with proteolytic processing and modifications altering protein function&lt;ref name="pmid22102574"&gt;{{Cite journal 
| last1 = Lange | first1 = P. F. 
| last2 = Huesgen | first2 = P. F. 
| last3 = Overall | first3 = C. M. 
| doi = 10.1093/nar/gkr1025 
| title = TopFIND 2.0--linking protein termini with proteolytic processing and modifications altering protein function 
| journal = Nucleic Acids Research 
| volume = 40 
| issue = Database issue 
| pages = D351–D361 
| year = 2011 
| pmid = 22102574 
| pmc =3244998 
}}&lt;/ref&gt;
|released = 2011
|standard =
|format = Custom comma separated file, [[SQL]], [[XML]].
|url = {{URL|clipserve.clip.ubc.ca/topfind}}
|license = [[Creative Commons]] Attribution-NoDerivs
|curation = Yes - manual and automatic. Rules for automatic annotation generated by Database Curators and computational algorithms.
}}

'''TopFIND''' is the '''T'''ermini '''o'''riented '''p'''rotein '''F'''unction '''I'''nferred '''D'''atabase ('''TopFIND''') is an integrated [[knowledgebase]] focused on [[protein]] termini, their formation by [[protease]]s and functional implications. It contains information about the processing and the processing state of proteins and functional implications thereof derived from research literature, contributions by the scientific community and biological [[database]]s.&lt;ref name="pmid21822272"&gt;{{Cite journal
 | last1 = Lange | first1 = P. F.
 | last2 = Overall | first2 = C. M.
 | doi = 10.1038/nmeth.1669
 | title = TopFIND, a knowledgebase linking protein termini with function
 | journal = Nature Methods
 | volume = 8
 | issue = 9
 | pages = 703–704
 | year = 2011
 | pmid = 21822272
}}&lt;/ref&gt;

==Background==
Among the most fundamental characteristics of a [[protein]] are the N- and C-termini defining the start and end of the [[peptide|polypeptide chain]]. While genetically encoded, protein termini isoforms are also often generated during [[translation (biology)|translation]], following which, termini are highly dynamic, being frequently trimmed at their ends by a large array of exopeptidases. Neo-termini can also be generated by endopeptidases after precise and limited proteolysis, termed processing. Necessary for the maturation of many proteins, processing can also occur afterwards, often resulting in dramatic functional consequences. Aberrant proteolysis can cause wide range of diseases like arthritis&lt;ref name="pmid21120997"&gt;{{cite journal |author= Cox JH, Starr AE, Kappelhoff R, Yan R, Roberts CR, Overall CM|title=Matrix metalloproteinase 8 deficiency in mice exacerbates inflammatory arthritis through delayed neutrophil apoptosis and reduced caspase 11 expression |journal=Arthritis &amp; Rheumatism |volume=62 |issue=12 |pages=3645–3655 |date=December 2010 |pmid=21120997 |doi=10.1002/art.27757 |url=}}&lt;/ref&gt; or cancer.&lt;ref name="pmid16498445"&gt;{{cite journal |author= Overall CM, Kleifeld O|title=Tumour microenvironment - opinion: validating matrix metalloproteinases as drug targets and anti-targets for cancer therapy |journal=Nature Reviews Cancer |volume=6 |issue=3 |pages=227–239 |date=March 2006 |pmid=16498445 |url= |doi=10.1038/nrc1821}}&lt;/ref&gt; Hence, proteolytic generation of pleiotrophic stable forms of proteins, the universal susceptibility of proteins to proteolysis, and its irreversibility, distinguishes proteolysis from many highly studied posttranslational modifications. Proteases are tightly interconnected in the protease web&lt;ref&gt;{{Cite journal
 | author = [[Nikolaus Fortelny]], [[Jennifer H. Cox]], [[Reinhild Kappelhoff]], [[Amanda E. Starr]], [[Philipp F. Lange]], [[Paul Pavlidis]] &amp; [[Christopher M. Overall]]
 | title = Network analyses reveal pervasive functional regulation between proteases in the human protease web
 | journal = [[PLOS Biology]]
 | volume = 12
 | issue = 5
 | pages = e1001869
 | year = 2014
 | doi = 10.1371/journal.pbio.1001869
 | pmid = 24865846
 | pmc=4035269
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | author = [[Nikolaus Fortelny]], [[Georgina S. Butler]], [[Christopher M. Overall]] &amp; [[Paul Pavlidis]]
 | title = Protease-Inhibitor Interaction Predictions: Lessons on the Complexity of Protein-Protein Interactions
 | journal = [[Molecular &amp; Cellular Proteomics]]
 | volume = 16
 | issue = 6
 | pages = 1038–1051
 | year = 2017
 | doi = 10.1074/mcp.M116.065706
 | pmid = 28385878
 | pmc=5461536
}}&lt;/ref&gt; and their aberrant activity in disease can lead to diagnostic fragment profiles with characteristic protein termini.&lt;ref&gt;{{Cite journal
 | author = [[Pitter F. Huesgen]], [[Philipp F. Lange]] &amp; [[Christopher M. Overall]]
 | title = Ensembles of protein termini and specific proteolytic signatures as candidate biomarkers of disease
 | journal = [[Proteomics: Clinical Applications]]
 | volume = 8
 | issue = 5–6
 | pages = 338–350
 | year = 2014
 | doi = 10.1002/prca.201300104
 | pmid = 24497460
}}&lt;/ref&gt; Following proteolysis, the newly formed protein termini can be further modified,&lt;ref&gt;{{Cite journal
 | author = [[Philipp F. Lange]] &amp; [[Christopher M. Overall]]
 | title = Protein TAILS: when termini tell tales of proteolysis and function
 | journal = [[Current Opinion in Chemical Biology]]
 | volume = 17
 | issue = 1
 | pages = 73–82
 | year = 2013
 | doi = 10.1016/j.cbpa.2012.11.025
 | pmid = 23298954
}}&lt;/ref&gt; a process that affects protein function and stability.&lt;ref&gt;{{Cite journal
 | author = [[Philipp F. Lange]], [[Pitter F. Huesgen]], [[Karen Nguyen]] &amp; [[Christopher M. Overall]]
 | title = Annotating N termini for the human proteome project: N termini and Nalpha-acetylation status differentiate stable cleaved protein species from degradation remnants in the human erythrocyte proteome
 | journal = [[Journal of Proteome Research]]
 | volume = 13
 | issue = 4
 | pages = 2028–2044
 | year = 2014
 | doi = 10.1021/pr401191w
 | pmid = 24555563
 | pmc=3979129
}}&lt;/ref&gt;

==Knowledgebase content==
TopFIND is a resource for comprehensive coverage of protein N- and C-termini discovered by all available in silico, in vitro as well as in vivo methodologies. It makes use of existing knowledge by seamless integration of data from [[UniProt]] and [[MEROPS]] and provides access to new data from community submission and manual literature curating. It renders modifications of [[protein]] termini, such as acetylation and citrullination, easily accessible and searchable and provides the means to identify and analyse extend and distribution of terminal modifications across a protein. Since its inception TopFIND has been expanded to further species.&lt;ref name="pmid22102574" /&gt;

==Data access==
The data is presented to the user with a strong emphasis on the relation to curated background information and underlying evidence that led to the observation of a terminus, its modification or proteolytic cleavage. In brief the [[protein]] information, its domain structure, protein termini, terminus modifications and proteolytic processing of and by other proteins is listed. All information is accompanied by [[metadata]] like its original source, method of identification, confidence measurement or related publication. A positional cross correlation evaluation matches termini and cleavage sites with protein features (such as amino acid variants) and domains to highlight potential effects and dependencies in a unique way. Also, a network view of all proteins showing their functional dependency as [[protease]], [[Enzyme substrate (biology)|substrate]] or [[Protease inhibitor (biology)|protease inhibitor]] tied in with [[Protein–protein interaction|protein interactions]] is provided for the easy evaluation of network wide effects. A powerful yet user friendly filtering mechanism allows the presented data to be filtered based on parameters like methodology used, in vivo relevance, confidence or data source (e.g. limited to a single laboratory or publication). This provides means to assess physiological relevant data and to deduce functional information and hypotheses relevant to the bench scientist.  In a later release analysis tools for the evaluation of proteolytic pathways in experimental data have been added.&lt;ref name="pmid25332401"&gt;{{Cite journal
 | author = [[Nikolaus Fortelny]], [[Sharon Yang]], [[Paul Pavlidis]], [[Philipp F. Lange]] &amp; [[Christopher M. Overall]]
 | title = Proteome TopFIND 3.0 with TopFINDer and PathFINDer: database and analysis tools for the association of protein termini to pre- and post-translational events
 | journal = [[Nucleic Acids Research]]
 | volume = 43
 | issue = Database issue
 | pages = D290–D297
 | year = 2015
 | doi = 10.1093/nar/gku1012
 | pmid = 25332401
 | pmc=4383881
}}&lt;/ref&gt;

==See also==
* [[MEROPS]]
* [[UniProt]]
* [[Cytoscape]]
* [[Computational genomics]]
* [[Metabolic network modelling]]
* [[Protein-protein interaction prediction]]

==References==
{{reflist}}

==External links==
* [http://clipserve.clip.ubc.ca/topfind/ TopFIND - main website and web interface]
* [https://www.ubc.ca/ Host institution website]
* [http://langelab.med.ubc.ca Research group of Philipp Lange - inventor &amp; core developer] 
* [http://clip.ubc.ca Research Group of Christopher Overall - home of TopFIND] 
* [http://merops.sanger.ac.uk/ Merops - the peptidase database]
* [https://www.uniprot.org/ UniProt]
* {{MeshName|Proteases}}

{{genomics-footer}}
{{Enzymes}}
{{Proteases}}

[[Category:Molecular biology]]
[[Category:Biological databases]]
[[Category:Bioinformatics software]]
[[Category:Systems biology]]
[[Category:Mathematical and theoretical biology]]
[[Category:Protein domains]]
[[Category:Protein families]]
[[Category:Posttranslational modification]]</text>
      <sha1>5l8w3727dm85lcpu2odbl3e1xvnlp84</sha1>
    </revision>
  </page>
  <page>
    <title>Transparency (data compression)</title>
    <ns>0</ns>
    <id>1190670</id>
    <revision>
      <id>841018228</id>
      <parentid>837112040</parentid>
      <timestamp>2018-05-13T15:19:56Z</timestamp>
      <contributor>
        <username>Kvng</username>
        <id>910180</id>
      </contributor>
      <comment>simplify and clarify</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3741">In [[data compression]] and [[psychoacoustics]], '''transparency''' is the result of [[lossy data compression]] accurate enough that the compressed result is [[perception|perceptually]] indistinguishable from the uncompressed input. In other words, transparent compression has no perceptible [[compression artifact]]s.

A '''transparency threshold''' is a given value at which transparency is reached. It is commonly used to describe compressed data bitrates. For example, the transparency threshold for MP3 to Linear PCM audio is said to be between 175 and 245&amp;nbsp;kbit/s, at [[44.1 kHz|44.1&amp;nbsp;kHz]], when encoded as [[Variable_bitrate|VBR]] MP3 (corresponding to the -V3 and -V0 settings of the highly popular [[LAME]] MP3 encoder).&lt;ref name="LAME Recommended Encoder Settings"&gt;{{citation
  | title = LAME Recommended Encoder Settings | date = 
  | publisher = hydrogenaudio | format = 
  | url = http://wiki.hydrogenaud.io/index.php?title=LAME | accessdate = }}&lt;/ref&gt; This means that when an MP3 that was encoded at those bitrates is being played back, it is indistinguishable from the original PCM, and the compression is transparent to the listener.

Transparency, like sound or video quality, is subjective. It depends most on the listener's familiarity with digital artifacts, their awareness that artifacts may in fact be present, and to a lesser extent, the compression method, [[bit-rate]] used, input characteristics, and the listening/viewing conditions and equipment. Despite this, sometimes general consensus is formed for what compression options "should" provide transparent results for most people on most equipment. Due to the subjectivity and the changing nature of compression, recording, and playback technology, such opinions should be considered only as rough estimates rather than established fact.

Judging transparency can be difficult, due to [[Observer-expectancy effect|observer bias]], in which subjective like/dislike of a certain compression methodology emotionally influences their judgment. This bias is commonly referred to as ''[[placebo]]'', although this use is slightly different from the medical use of the term.

To scientifically prove that a compression method is ''not'' transparent, [[double-blind]] tests may be useful. The [[ABX test|ABX method]] is normally used, with a [[null hypothesis]] that the samples tested are the same and with an [[alternative hypothesis]] that the samples are in fact different.

All lossless data compression methods are transparent, by nature. However, a double-blind comparison could still yield claims of perceived differences and thus lack of transparency, even though such claims would be in error.

==See also==
*[[Codec listening test]]
*{{Section link|High fidelity|Listening tests}}

==References==
{{reflist}}
* Bosi, Marina; Richard E. Goldberg. ''Introduction to digital audio coding and standards''. Springer, 2003. {{ISBN|1-4020-7357-7}}
* Cvejic, Nedeljko; Tapio Seppänen. ''Digital audio watermarking techniques and technologies: applications and benchmarks''. Idea Group Inc (IGI), 2007. {{ISBN|1-59904-513-3}}
* Pohlmann, Ken C. ''Principles of digital audio''. McGraw-Hill Professional, 2005. {{ISBN|0-07-144156-5}}
* Spanias, Andreas; Ted Painter; Venkatraman Atti. ''Audio signal processing and coding''. Wiley-Interscience, 2007. {{ISBN|0-471-79147-4}}
* Syed, Mahbubur Rahman. ''Multimedia technologies: concepts, methodologies, tools, and applications, Volume 3''. Idea Group Inc (IGI), 2008. {{ISBN|1-59904-953-8}}

==External links==
*[http://wiki.hydrogenaud.io/index.php?title=Transparent "Transparency"], Hydrogen Audio Wiki

[[Category:Data compression]]
[[Category:Audio codecs]]


{{signal-processing-stub}}
{{Sound-tech-stub}}</text>
      <sha1>m6jx39bnogaqxffii8hlgmubojgnhgv</sha1>
    </revision>
  </page>
  <page>
    <title>Treviso Arithmetic</title>
    <ns>0</ns>
    <id>8272539</id>
    <revision>
      <id>869422090</id>
      <parentid>837046365</parentid>
      <timestamp>2018-11-18T14:29:44Z</timestamp>
      <contributor>
        <username>TiltuM</username>
        <id>25848390</id>
      </contributor>
      <comment>added [[Category:15th-century Italian mathematicians]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4825">{{italic title}}
The '''''Treviso Arithmetic''''', or '''''Arte dell'Abbaco''''', is an anonymous textbook in commercial arithmetic written in vernacular [[Venetian language|Venetian]] and published in [[Treviso]], Italy in 1478.

The author explains the motivation for writing this textbook:&lt;ref&gt;David Eugene Smith "The First Printed Arithmetic (Treviso, 1478)," ''Isis'', 6 (1924): 311–331,  at p. 314&lt;/ref&gt;
{{Blockquote|I have often been asked by certain youths in whom I have much interest, and who look forward to mercantile pursuits, to put into writing the fundamental principles of arithmetic, commonly called abacus.}}

The ''Treviso Arithmetic'' is the earliest known printed mathematics book in the West, and one of the first printed European textbooks dealing with a science.

==The ''Arithmetic'' as an early printed book==

There appears to have been only one edition of the work. [[David Eugene Smith]] translated parts of the'' Treviso Arithmetic'' for educational purposes in 1907. [[Frank J. Swetz]] translated the complete work using Smith's notes in 1987 in his ''Capitalism &amp; Arithmetic: The New Math of the 15th Century''. Swetz used a copy of the ''Treviso'' housed in the Manuscript Library at Columbia University. The volume found its way to this collection via a curious route. [[Maffeo Pinelli]] (1785), an Italian bibliophile, is the first known owner. After his death his library was purchased by a London book dealer and sold at auction on February 6, 1790. The book was obtained for ''three shillings'' by Mr. Wodhull.&lt;ref&gt;Swetz, Frank, J. 1987. ''Capitalism and Arithmetic''. La Salle: Open Court.
&lt;/ref&gt; About 100 years later the ''Arithmetic'' appeared in the library of Brayton Ives, a New York lawyer. When Ives sold the collection of books at auction, [[George Arthur Plimpton]], a New York publisher, acquired the ''Treviso'' and made it an acquisition to his extensive collection of early scientific texts. Plimpton donated his library to [[Columbia University]] in 1936.&lt;ref&gt;Swetz, 34&lt;/ref&gt; Original copies of the ''Treviso Arithmetic'' are extremely rare.

There are 123 pages of text with 32 lines of print to a page. The pages are unnumbered, untrimmed and have wide margins. Some of the margins contain written notes. The size of the book is 14.5&amp;nbsp;cm by 20.6&amp;nbsp;cm.

The book included information taken from the 1202 ''[[Liber Abaci]]'', such as [[lattice multiplication]]. George G. Joseph, "Crest of the Peacock' suggests that Napier read this book to create [[Napier's bones]], or [[Napier's rods]].

==Reasons for publication==
The ''Treviso Arithmetic'' is a practical book intended for self study and for use in Venetian trade. It is written in vernacular Venetian and communicated knowledge to a large population.

It helped to end the monopoly on mathematical knowledge and gave important information to the middle class. It was not written for a large audience, but was intended to teach mathematics of everyday currency.

The ''Treviso'' became one of the first mathematics books written for the expansion of human knowledge. It provided an opportunity for the common person, rather than only a privileged few, to learn the art of computation. The ''Treviso Arithmetic'' provided an early example of the Hindu–[[Arabic numeral]] system computational algorithms.&lt;ref&gt;Swetz, 26&lt;/ref&gt;

==See also==
*[[Ars Magna (Gerolamo Cardano)]] (1510)
*''[[Trigonometria]]'' (1595)

==Notes==
{{reflist}}

==References==
*[[Carl Benjamin Boyer|Boyer, Carl]]. 1991. ''A History of Mathematics''. New York City: Wiley.
*{{cite journal|jstor=1343930|title=Envisioning Capital: Political Economy on Display|first=Susan|last=Buck-Morss|date=1 January 1995|publisher=|journal=Critical Inquiry|volume=21|issue=2|pages=434–467}}
*Carter, Baker.  2006. ''The Role of the History of Mathematics in Middle School''. Presentation at East Tennessee University, August 28.
*Gazale, Midhat, J. 2000. ''Number''. Princeton: Princeton University Press.
*Newman, J, R. 1956. ''The World of Mathematics''. New York City: Simon &amp; Schuster.
*Peterson, Ivars. 1996. ''Old and New Arithmetic''. Mathematical Association of America. http://www.maa.org/mathland/mathland_8_5.html (accessed October 11, 2006).
*Swetz, Frank, J. 1987. ''Capitalism and Arithmetic''. La Salle: Open Court.

==External links==
*[https://web.archive.org/web/20120206013105/http://www.republicaveneta.com/doc/abaco.pdf Full text of the ''Treviso Arithmetic'']
*[http://www.columbia.edu/cu/lweb/eresources/exhibitions/treasures/html/160.html ''Treviso Arithmetic'' at Columbia University]
{{authority control}}
[[Category:1478 books]]
[[Category:Mathematics books]]
[[Category:15th century in science]]
[[Category:Venetian language]]
[[Category:Works published anonymously]]
[[Category:15th-century Italian mathematicians]]</text>
      <sha1>r5268suvt4ndqn4gg4i9l9ut6tbasvl</sha1>
    </revision>
  </page>
  <page>
    <title>Unified Modeling Language for Interactive Systems</title>
    <ns>0</ns>
    <id>38693595</id>
    <revision>
      <id>557911377</id>
      <parentid>550789876</parentid>
      <timestamp>2013-06-02T02:06:23Z</timestamp>
      <contributor>
        <username>Ad Orientem</username>
        <id>13259281</id>
      </contributor>
      <comment>Added tags to the page using [[Wikipedia:Page Curation|Page Curation]] (technical)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="969">{{technical|date=June 2013}}

The '''Unified Modeling Language for Interactive Systems''' (UMLi)&lt;ref&gt;Paulo Pinheiro da Silva and Norman W. Paton. User Interface Modeling in UMLi. IEEE Software, Vol.20 No. 4, July/August 2003, pages 62-69.&lt;/ref&gt; is a conservative extension of the [[Unified Modeling Language]] for user interface design. UMLi was developed in the period between 1998 and 2002 as part of [[Paulo Pinheiro]]'s Ph.D. Thesis at the University of Manchester.&lt;ref&gt;Paulo Pinheiro da Silva. Object Modelling of Interactive Systems: The UMLi Approach. PhD's thesis, Department of Computer Science, University of Manchester, United Kingdom, 2002.&lt;/ref&gt; UMLi is based on [[model-based user interface development environments]] (MB-UIDEs), which provide the capability to design and implement user interfaces in a declarative and systematic way.

==References==
{{Reflist}}

==External links==
* http://trust.utep.edu/umli/



[[Category:Unified Modeling Language]]</text>
      <sha1>tfcn59sm56qvcu5msc9bpiiop9nyvmr</sha1>
    </revision>
  </page>
  <page>
    <title>Wojciech Rytter</title>
    <ns>0</ns>
    <id>38237389</id>
    <revision>
      <id>861261537</id>
      <parentid>772208326</parentid>
      <timestamp>2018-09-26T05:56:13Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2474">'''Wojciech Rytter''' is a [[Polish people|Polish]] [[computer scientist]], a professor of computer science at the [[University of Warsaw]]. His research focuses on the design and analysis of [[algorithm]]s, and in particular on [[stringology]].

==Professional career==
Rytter earned a master's degree in 1971 and a Ph.D. in 1975 from Warsaw University, and earned his [[habilitation]] in 1985.&lt;ref name="cv"&gt;[http://www.mimuw.edu.pl/~rytter/rytter_cv.html Curriculum vitae], retrieved 2013-01-15.&lt;/ref&gt; He has been on the faculty of Warsaw University since 1971, and is now a full professor there.&lt;ref name="ae"&gt;[http://www.ae-info.org/ae/User/Rytter_Wojciech Wojciech Rytter] at the [[Academia Europaea]], retrieved 2013-01-15.&lt;/ref&gt; He has also held long-term visiting positions at the [[New Jersey Institute of Technology]], [[Liverpool University]], [[Bonn University]], the [[University of California, Riverside]], [[Warwick University]], and the University of Mexico.&lt;ref name="cv"/&gt;&lt;ref name="ae"/&gt;

==Books==
Rytter is the author or co-author of:&lt;ref&gt;As listed in [[Worldcat]], retrieved 2013-01-15.&lt;/ref&gt;
*''Zagadnienie stabilności automatów skończonych Stochastycznych'' (in Polish, PKiN, 1972)
*''Automaty funkcyjne'' (in Polish, Centrum Obliczeniowe Polskiej Akademii Nauk, 1976)
*''Złożność czasowa dwukierunkowych automatów stosowych i programów rekurencyjnych'' (in Polish, 1983)
*''Efficient parallel algorithms'' (with [[Alan Gibbons]], Cambridge University Press, 1988)
*''Analysis of algorithms and data structures'' (with Lech Banachowski and Antoni Kreczmar, Addison-Wesley, 1991)
*''Text algorithms'' (with [[Maxime Crochemore]], Oxford University Press, 1994)
*''Fast parallel algorithms for graph matching problems'' (with [[Marek Karpinski]], Clarendon Press, 1998)
*''Jewels of stringology: text algorithms'' (with Maxime Crochemore, World Scientific, 2002)

==Awards and honors==
Rytter is a member of the [[Academia Europaea]].&lt;ref name="ae"/&gt;

==References==
{{reflist}}

==External links==
*{{Official website}}
*{{DBLP |name=Wojciech Rytter}}
*{{Google Scholar id |name=Wojciech Rytter}}

{{authority control}}

{{DEFAULTSORT:Rytter, Wojciech}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Polish computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:University of Warsaw alumni]]
[[Category:University of Warsaw faculty]]
[[Category:Members of Academia Europaea]]</text>
      <sha1>1bzxgyo1todbutdmbp1l972fkcxupr3</sha1>
    </revision>
  </page>
  <page>
    <title>Z-channel (information theory)</title>
    <ns>0</ns>
    <id>8396078</id>
    <revision>
      <id>846589163</id>
      <parentid>794187586</parentid>
      <timestamp>2018-06-19T18:09:28Z</timestamp>
      <contributor>
        <ip>50.205.66.30</ip>
      </contributor>
      <comment>/* Capacity */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4727">A '''Z-channel''' is a [[communications channel]] used in [[coding theory]] and [[information theory]] to model the behaviour of some data storage systems.

== Definition ==
A ''Z-channel'' (or a ''binary asymmetric channel'') is a channel with binary input and binary output where the crossover 1 → 0 occurs with nonnegative probability ''p'', whereas the crossover 0 → 1 never occurs. In other words, if ''X'' and ''Y'' are the [[random variable]]s describing the probability distributions of the input and the output of the channel, respectively, then the crossovers of the channel are characterized by the [[conditional probability|conditional probabilities]]
: Prob{''Y'' = 0 | ''X'' = 0} = 1
: Prob{''Y'' = 0 | ''X'' = 1} = ''p''
: Prob{''Y'' = 1 | ''X'' = 0} = 0
: Prob{''Y'' = 1 | ''X'' = 1} = 1&amp;minus;''p''

== Capacity ==
The [[channel capacity|capacity]] &lt;math&gt;\mathsf{cap}(\mathbb{Z})&lt;/math&gt; of the Z-channel &lt;math&gt;\mathbb{Z}&lt;/math&gt; with the crossover 1 → 0 probability ''p'', when the input random variable ''X'' is distributed according to the [[Bernoulli distribution]] with probability ''&lt;math&gt;\alpha&lt;/math&gt;'' for the occurrence of 0, is calculated as follows.
:&lt;math&gt;\mathsf{cap}(\mathbb{Z}) = 
\max_\alpha\{\mathsf{H}(Y) - \mathsf{H}(Y \mid X)\} = \max_\alpha\Bigl\{\mathsf{H}(Y) - \sum_{x \in \{0,1\}}\mathsf{H}(Y \mid X = x) \mathsf{Prob}\{X = x\}\Bigr\} &lt;/math&gt;
::::&lt;math&gt;=\max_\alpha\{\mathsf{H}((1-\alpha)(1-p)) - \mathsf{H}(Y \mid X = 1) \mathsf{Prob}\{X = 1\} \}&lt;/math&gt;
::::&lt;math&gt;=\max_\alpha\{\mathsf{H}((1-\alpha)(1-p)) - (1-\alpha)\mathsf{H}(p) \},&lt;/math&gt;
where &lt;math&gt;\mathsf{H}(\cdot)&lt;/math&gt; is the [[binary entropy function]].

The maximum is attained for
:&lt;math&gt;\alpha = 1 - \frac{1}{(1-p)(1+2^{\mathsf{H}(p)/(1-p)})},&lt;/math&gt;
yielding the following value of &lt;math&gt;\mathsf{cap}(\mathbb{Z})&lt;/math&gt; as a function of ''p''
:&lt;math&gt;\mathsf{cap}(\mathbb{Z}) = \mathsf{H}\left(\frac{1}{1+2^{\mathsf{s}(p)}}\right) - \frac{\mathsf{s}(p)}{1+2^{\mathsf{s}(p)}} = \log_2(1{+}2^{-\mathsf{s}(p)}) = \log_2\left(1+(1-p) p^{p/(1-p)}\right) \; \textrm{ where } \; \mathsf{s}(p) = \frac{\mathsf{H}(p)}{1-p}.&lt;/math&gt;

For small ''p'', the capacity is approximated by

:&lt;math&gt; \mathsf{cap}(\mathbb{Z}) \approx 1- 0.5 \mathsf{H}(p) &lt;/math&gt;
as compared to the capacity &lt;math&gt;1{-}\mathsf{H}(p)&lt;/math&gt; of the [[binary symmetric channel]] with crossover probability ''p''.

== Bounds on the size of an asymmetric-error-correcting code ==
Define the following distance function &lt;math&gt;\mathsf{d}_A(\mathbf{x}, \mathbf{y})&lt;/math&gt; on the words &lt;math&gt;\mathbf{x}, \mathbf{y} \in \{0,1\}^n&lt;/math&gt; of length ''n'' transmitted via a Z-channel
:&lt;math&gt;\mathsf{d}_A(\mathbf{x}, \mathbf{y}) \stackrel{\vartriangle}{=} \max\left\{ \big|\{i \mid x_i = 0, y_i = 1\}\big| , \big|\{i \mid x_i = 1, y_i = 0\}\big| \right\}.&lt;/math&gt;
Define the sphere &lt;math&gt;V_t(\mathbf{x})&lt;/math&gt; of radius ''t'' around a word &lt;math&gt;\mathbf{x} \in \{0,1\}^n&lt;/math&gt; of length ''n'' as the set of all the words at distance ''t'' or less from &lt;math&gt;\mathbf{x}&lt;/math&gt;, in other words,
:&lt;math&gt;V_t(\mathbf{x}) = \{\mathbf{y} \in \{0, 1\}^n \mid \mathsf{d}_A(\mathbf{x}, \mathbf{y}) \leq t\}.&lt;/math&gt;
A [[code]] &lt;math&gt;\mathcal{C}&lt;/math&gt; of length ''n'' is said to be ''t''-asymmetric-error-correcting if for any two codewords &lt;math&gt;\mathbf{c}\ne \mathbf{c}' \in \{0,1\}^n&lt;/math&gt;, one has &lt;math&gt;V_t(\mathbf{c}) \cap V_t(\mathbf{c}') = \emptyset&lt;/math&gt;. Denote by &lt;math&gt;M(n,t)&lt;/math&gt; the maximum number of codewords in a ''t''-asymmetric-error-correcting code of length ''n''.

'''The Varshamov bound'''.
For ''n''≥1 and ''t''≥1,
:&lt;math&gt;M(n,t) \leq \frac{2^{n+1}}{\sum_{j = 0}^t{\left( \binom{\lfloor n/2\rfloor}{j}+\binom{\lceil n/2\rceil}{j}\right)}}.&lt;/math&gt;

'''The constant-weight{{what|date=November 2014}} code bound'''.
For ''n &gt; 2t ≥ 2'', let the sequence ''B&lt;sub&gt;0&lt;/sub&gt;, B&lt;sub&gt;1&lt;/sub&gt;, ..., B&lt;sub&gt;n-2t-1&lt;/sub&gt;'' be defined as
:&lt;math&gt;B_0 = 2, \quad B_i = \min_{0 \leq j &lt; i}\{ B_j + A(n{+}t{+}i{-}j{-}1, 2t{+}2, t{+}i)\}&lt;/math&gt; for &lt;math&gt;i &gt; 0&lt;/math&gt;.
Then &lt;math&gt;M(n,t) \leq B_{n-2t-1}.&lt;/math&gt;

== References ==
* {{Smallcaps|T. Kløve,}} Error correcting codes for the asymmetric channel, ''Technical Report 18–09–07–81,'' Department of Informatics, University of Bergen, Norway, 1981.
* {{Smallcaps|S. Verdú,}} Channel Capacity, in ''The electrical engineering handbook,'' 2nd ed., IEEE Press and CRC Press, 1997, ch. 73.5, pp. 1671-1678. 
* {{Smallcaps|L.G. Tallini, S. Al-Bassam, B. Bose,}} On the capacity and codes for the Z-channel, ''Proceedings of the IEEE International Symposium on Information Theory,'' Lausanne, Switzerland, 2002, p.&amp;nbsp;422.

[[Category:Coding theory]]
[[Category:Information theory]]
[[Category:Inequalities]]</text>
      <sha1>mh7t620jvjbxknoh5s9tnwwfdly8cyo</sha1>
    </revision>
  </page>
</mediawiki>
