<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>16 (number)</title>
    <ns>0</ns>
    <id>208254</id>
    <revision>
      <id>867077682</id>
      <parentid>866194075</parentid>
      <timestamp>2018-11-03T14:11:10Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Circular link (to DAB page) removed. ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11953">{{Redirect|XVI||16 (disambiguation)}}
{{Example farm|date=March 2010}}
{{Infobox number
| number =  16
| numeral = [[hexadecimal]]
| divisor = 1, 2, 4, 8, 16
| lang1 = [[Hebrew (language)|Hebrew]]
| lang1 symbol = &lt;span style="font-size:150%;"&gt;ט"ז&lt;/span&gt; (Tet Zayin)
}}
'''16''' ('''sixteen''') is the [[natural number]] following [[15 (number)|15]] and preceding [[17 (number)|17]]. 16 is a [[composite number]], and a [[square number]], being [[4 (number)|4]]&lt;sup&gt;2&lt;/sup&gt; = 4 × 4. It is the smallest number with exactly five [[divisor]]s, its proper divisors being {{num|1}}, {{num|2}}, {{num|4}} and {{num|8}}.

In English speech, the numbers 16 and 60 are sometimes confused, as they sound very similar.

Sixteen is the fourth [[power of two]]. For this reason, 16 was used in weighing light objects in several cultures. The British have 16 ounces in one pound; the Chinese used to have 16 ''liangs'' in one ''jin''. In old days, weighing was done with a beam balance to make equal splits. It would be easier to split a heap of grains into sixteen equal parts through successive divisions than to split into ten parts. Chinese Taoists did finger computation on the trigrams and hexagrams by counting the finger tips and joints of the fingers with the tip of the thumb. Each hand can count up to 16 in such manner. The Chinese abacus uses two upper beads to represent the 5s and 5 lower beads to represent the 1s, the 7 beads can represent a hexadecimal digit from 0 to 15 in each column.

== Mathematics ==
Sixteen is an [[Parity (mathematics)|even]] number and a square number.

Sixteen is the fourth power of two.

Sixteen is the only integer that [[Equation xʸ=yˣ|equals ''m''&lt;sup&gt;''n''&lt;/sup&gt; and ''n''&lt;sup&gt;''m''&lt;/sup&gt;, for some unequal integers ''m'' and ''n'']] (''m''&amp;nbsp;=&amp;nbsp;4, ''n''&amp;nbsp;=&amp;nbsp;2, or vice versa).&lt;ref&gt;{{cite book
 |author = David Wells
 |title = The Penguin Dictionary of Curious and Interesting Numbers
 |publisher = Penguin Books
 |year = 1987
 |page = 93
}}&lt;/ref&gt; It has this property because 2&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;2&amp;nbsp;×&amp;nbsp;2. It is also equal to &lt;sup&gt;3&lt;/sup&gt;2 (see [[tetration]]).

16 is the base of the [[hexadecimal]] number system, which is used extensively in [[computer science]].

==Science==
* The [[atomic number]] of [[sulfur]]
* [[Group (periodic table)|Group 16]] of the [[periodic table]] are the [[chalcogens]]

==Religion==
====Hinduism====
*Saint [[Markandeya]] is said to have been granted to live to 16 years of age. When he turned sixteen,the goddess of death, [[Yama]], came to look for him and fastened a noose around the saint. The saint hugged the idol of lord [[Shiva]] that he worshipped(which can be still found in the [[Amritaghateswarar-Abirami Temple,Thirukkadaiyur|Amritaghateswarar-Abirami Temple]] in [[Thirukkadaiyur]], [[Tamil Nadu]], [[India]]. As the noose was sprung round the saint together with lord Shiva, this made the lord angry and he appeared in his fierce form and vanquished the lord of death, causing a brief catastrophe in the world where no one died. Eventually, lord Yama was revived and the saint [[Markandeya]] was made immortal to be of age sixteen forever.

==Languages==

===Grammar===

In Spanish and Portuguese, 16 is the first compound number (Spanish: ''dieciséis'', European Portuguese: ''dez'''a'''sseis'', Brazilian Portuguese: ''dez'''e'''sseis''); the numbers 11 (Spanish: ''once'', Portuguese: ''onze'') through 15 (Spanish: ''quince'', Portuguese: ''quinze'') have their own names.

==Age 16==
{{globalize|dat16
e=October 2014|date=September 2016}}
* Sixteen is the minimum age for being allowed an official beginner's [[driver's license]] with parental consent in many [[United States|U.S.]] states and in [[Canada]]. In [[Australia]], [[Iceland]], [[New Zealand]], [[Norway]], [[South Africa]], and the [[Isle of Man]], it is the age one can begin to get a learner's [[license]]
* A "[[sweet sixteen (birthday)|sweet sixteen]]" is celebrated by many sixteen-year-old girls in the [[United States]]. It is a [[coming of age]] celebration that traditionally marks a girl's transition into womanhood. For its significance in popular culture, this "coming of age" has inspired the titles of many songs, such as "''[[Happy Birthday Sweet Sixteen]]''", "''[[You're Sixteen]]''", "''[[Sweet Sixteen (Hilary Duff song)|Sweet Sixteen]]''", "''[[U16 Girls]]''"  "''[[Sweet Little Sixteen]]''" and "''[[The Crests|Sixteen Candles]]''"
* Sixteen is the minimum age that one can leave school in many states of the United States and Canada (however, restrictions apply and vary depending on state or province)&lt;ref name="ECS"&gt;{{cite web|first=Marga|last=Mikulecky|publisher=Education Commission of the States|title=Compulsory School Age Requirements|url=http://www.ecs.org/clearinghouse/01/07/03/10703.pdf|date=April 2013|accessdate=January 8, 2015}}&lt;/ref&gt;
* In the United States, sixteen-year-old girls earn the right to privacy laws surrounding [[Obstetrics and gynaecology|OBGYN]] practices
* In [[Belgium]], it is the legal minimum age for a person to purchase any tobacco product.
* In the United States and Canada, 16 is the most common [[age of consent|age of sexual consent]], as well as the age in the United Kingdom.&lt;ref&gt;{{cite web|url=http://www.age-of-consent.info/|archive-url=https://web.archive.org/web/20110417024317/http://www.age-of-consent.info/|dead-url=yes|archive-date=2011-04-17|title=Age Of Consent By State|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.avert.org/age-of-consent.htm|title=Age of consent for sexual intercourse|publisher=}}&lt;/ref&gt;
* Sixteen is the minimum age to get married, with parental consent in many countries, and without parental consent in [[Scotland]].
* Sixteen is the [[legal drinking age]] in [[Germany]], [[Belgium]], [[Switzerland]], [[Austria]] and [[Portugal]].
* Minimum age at which one can buy, rent, purchase, buy tickets to, or view a 16+ rated film in the Canadian province of Quebec. It is also the minimum age at which one can accompany a minor under-13 while buying, renting, or purchasing tickets to a 13+ rated movie in the province of Quebec.
* Minimum age at which one can donate blood (with parental consent) in many U.S. states
* Minimum age at which one can obtain an adult passport (which lasts ten years) in the United States, United Kingdom, and Australia.
* Minimum age at which one can join the [[British Armed Forces|Armed Forces]] in the [[United Kingdom]] (deployment is only allowed at age 18)
* Sixteen is the voting age in [[Argentina]], [[Austria]], [[Brazil]], [[Cuba]], [[Ecuador]], the [[Isle of Man]], and [[Nicaragua]].
* Sixteen is the [[age of majority]] in [[Cambodia]], [[Cuba]], [[Kyrgyzstan]], and [[Vietnam]].

==In sports==

Many leagues and tournaments have 16 teams, for example:
* [[FIFA World Cup]] finals from 1934 through 1978 (although for various reasons, only 15 competed in the 1938 and 1950 finals)
* [[FIFA Women's World Cup]] finals from 1999 through 2011
* The season-ending [[NASCAR playoffs|playoffs]] in the [[Monster Energy NASCAR Cup Series|NASCAR Cup Series]]
* The [[National League]] of [[Major League Baseball]] from 1998 to 2012

In both the [[NBA]] and [[NHL]], 16 teams qualify for the respective league playoffs; it is also the number of wins needed to win the title (both leagues have four playoff rounds, with four wins in seven games needed to win each round).

The regular season of the [[National Football League]] currently consists of 16 games.

In [[AFL Women's]], the top-level league of [[Women's Australian rules football|women's]] [[Australian rules football]], each team has 16 players on the field at any given time (as opposed to the 18 of almost all other competitions in the sport, most notably the parent [[Australian Football League]] for men).

==In other fields==
{{See also|List of highways numbered 16}}
* 16 steps make up the average bar of music in a 4/4 musical arrangement. The [[Roland TR-808]], for instance, has 16 buttons that light up representing 16 16th notes making up a drum pattern.
*[[Sixteen, Kentucky]], a community in the United States
* King of France (August 1754 – 21 January 1793) [[Louis XVI of France]]
* There are 16 [[ounce]]s in an [[avoirdupois]] pound
* There are 16 [[Pawn (chess)|pawns]] in a [[chess]] set and each player in a [[chess]] game starts with sixteen pieces
[[Image:Muybridge race horse animated.gif|thumb|right|300px|Sixteen frames of images]]
* "[[The Sixteen]]" is an English choir performing early religious music
* [[Sixteen (band)|Sixteen]] is a Polish band that represented [[Poland]] in the [[1998 Eurovision Song Contest]]
* The [[Cadillac Sixteen]]
* There are 16 different personality types in the [[Myers-Briggs]] classification system
* A note played for one-sixteenth the duration of a [[whole note]] is called a [[sixteenth note]] or a semiquaver
* In the [[16-bit era]], [[16-bit]] microprocessor ran [[16-bit application]]s
* [[Sixteen Kingdoms]], part of [[Chinese history]]
* The fighter jet, the [[F-16 Fighting Falcon]]
* [[16 mm]] film was originally an amateur [[movie]] format, but is now used by professionals
* "[[16 (Green Day song)|16]]" is a song by American band [[Green Day]]
* The [[M16 rifle]]
* The number 16 is the symbol of the [[A Day of Solidarity with Belarus|Day of solidarity with political prisoners and victims of the Lukashenka regime in Belarus]], which is commemorated on 16th of every months by demonstrations and flash mobs worldwide{{cn|date=May 2018}}
* A sixteen is a slang term for a verse in a hip hop song, which are often written in 16-[[Bar (music)|bar]] [[stanza]]s.&lt;ref&gt;{{cite web|url=http://artsedge.kennedy-center.org/content/3656/|title=ARTSEDGE: The Poetics of Hip-Hop|first=The Kennedy Center|last=ArtsEdge|date=|website=artsedge.kennedy-center.org|accessdate=21 March 2018}}&lt;/ref&gt;
* [[List of Dragon Ball characters#Android #16|Android 16]], a fictional character in the ''Dragon Ball'' manga series
* The amount of waking hours in a day in an "8 hours of sleep" schedule
* In the story of the [[Sleeping Beauty]], a spell is placed on the princess that when she reaches her 16th birthday, she will "prick her finger on the spindle of a spinning wheel and die"
* 16 is the number of the French department [[Charente]]
* Many [[bank card number]]s are 16 digits long
* There is a [[No Doubt]] song titled "Sixteen" on the album [[Tragic Kingdom]]
* The [[metalcore]]  band [[Demon Hunter]] has a song titled "Sixteen" on their [[Storm the Gates of Hell]] album
* In [[Belgium]], 16 is colloquially used to refer to the Belgian government or Prime Minister, especially in media, because of the official seat of the Belgian federal government being located on 16, rue de la Loi in Brussels. The full address is also sometimes used, in a similar way as 10, Downing Street in England.&lt;ref&gt;{{cite web |url=http://chancellerie.belgium.be/fr/content/le-16 |title=Archived copy |access-date=9 June 2015 |archive-url=https://web.archive.org/web/20150704060938/http://chancellerie.belgium.be/fr/content/le-16 |archive-date=4 July 2015 |dead-url=yes |df=dmy-all }}&lt;/ref&gt;{{failed verification|reason=That shows the building is referred to as "the 16", not the government|date=July 2015}}
* The number of rays in the [[Vergina Sun]], symbol by Philip's Argead dynasty, possible religious symbol representing the Olympian gods.
* There are sixteen petals on the [[Imperial Seal of Japan]].
* There were sixteen lands created by Ahura Mazda, according to [[Avestan geography]], which were then followed by sixteen negative counter-creations of Angra Mainyu.

==References==
{{reflist}}

==External links==
{{Wiktionary|sixteen}}
* {{cite web|title=16 x&lt;sup&gt;y&lt;/sup&gt;=y&lt;sup&gt;x&lt;/sup&gt; Sweet Sixteen|url=http://www.numberphile.com/videos/16.html|work=Numberphile|publisher=[[Brady Haran]]|author=Symonds, Ria|author2=Parker, Matt}}

{{Use dmy dates|date=September 2011}}

{{Integers|zero}}

[[Category:Integers]]</text>
      <sha1>frnyo37it44q091whyfitpsxmo19x3k</sha1>
    </revision>
  </page>
  <page>
    <title>2-4-2-1 code</title>
    <ns>0</ns>
    <id>56334866</id>
    <redirect title="Aiken code" />
    <revision>
      <id>821031853</id>
      <parentid>821025979</parentid>
      <timestamp>2018-01-18T01:02:01Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+rcats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="115">#redirect [[Aiken code]] {{R from alternative name}}

[[Category:Computer arithmetic]]
[[Category:Numeral systems]]</text>
      <sha1>3ntl93o58yxu5wtrn4q9ipt4n8gtsw5</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithmic paradigm</title>
    <ns>0</ns>
    <id>51411922</id>
    <revision>
      <id>736065537</id>
      <parentid>736064186</parentid>
      <timestamp>2016-08-24T23:01:37Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Randomized algorithm#Randomized incremental constructions in geometry|randomized incremental construction]] and [[rotating calipers]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1127">An '''algorithmic paradigm''', '''algorithm design paradigm''', '''algorithmic technique''', or '''algorithmic strategy''' is a generic method or approach which underlies the design of a class of [[algorithm]]s. It is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a [[computer program]].  &lt;ref&gt;[https://books.google.com/books?id=M2viBQAAQBAJ&amp;pg=PA702 p. 702]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=McPJt_eBgnoC&amp;pg=SA1-PA9 p. 9]&lt;/ref&gt; Examples of algorithmic paradigms include the [[greedy algorithm]]  in [[optimization problem]]s,  [[dynamic programming]], [[prune and search]], and [[divide and conquer algorithms]]. More specialized algorithmic paradigms used in [[parameterized complexity]] include [[kernelization]] and [[iterative compression]]. In [[computational geometry]], additional algorithmic paradigms include [[sweep line algorithm]]s, [[rotating calipers]], and [[Randomized algorithm#Randomized incremental constructions in geometry|randomized incremental construction]].

==References==
{{reflist}}

[[Category:Algorithms]]

{{algorithm-stub}}</text>
      <sha1>7ve5y3dhw1r1m79fvx3bktx8ojxzrzy</sha1>
    </revision>
  </page>
  <page>
    <title>Alspach's conjecture</title>
    <ns>0</ns>
    <id>55964224</id>
    <revision>
      <id>843601766</id>
      <parentid>816190364</parentid>
      <timestamp>2018-05-30T06:23:52Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4128">'''Alspach's conjecture''' is a [[Theorem|mathematical theorem]] that characterizes the [[Edge cycle cover|disjoint cycle cover]]s of [[complete graph]]s with prescribed cycle lengths. It is named after [[Brian Alspach]], who posed it as a research problem in 1981. A proof was published by {{harvs|first1=Darryn|last1=Bryant|first2=Daniel|last2=Horsley|first3=William|last3=Pettersson|year=2014|txt}}.

==Formulation==
In this context, a disjoint cycle cover is a set of simple cycles, no two of which use the same edge, that include all of the edges of a graph. For a disjoint cycle cover to exist, it is necessary for every vertex to have even [[degree (graph theory)|degree]], because the degree of each vertex is two times the number of cycles that include that vertex, an even number. And for the cycles in a disjoint cycle cover to have a given collection of lengths,
it is also necessary for the sum of the given cycle lengths to equal the total number of edges in the given graph. Alspach conjectured that, for complete graphs, these two necessary conditions are also sufficient: if &lt;math&gt;n&lt;/math&gt; is odd (so that the degrees are even) and a given list of cycle lengths (all at most &lt;math&gt;n&lt;/math&gt;) adds to &lt;math&gt;\tbinom{n}{2}&lt;/math&gt; (the number of edges in the complete graph) then the complete graph &lt;math&gt;K_n&lt;/math&gt; can always be decomposed into cycles of the given length. It is this statement that Bryant, Horsley, and Pettersson proved.

==Generalization to even numbers of vertices==
For complete graphs &lt;math&gt;K_n&lt;/math&gt; whose number &lt;math&gt;n&lt;/math&gt; of vertices is even, Alspach conjectured that it is always possible to decompose the graph into a [[perfect matching]] and a collection of cycles of prescribed lengths summing to &lt;math&gt;\tbinom{n}{2}-n/2&lt;/math&gt;. In this case the matching eliminates the odd degree at each vertex, leaving a subgraph of even degree, and the remaining condition is again that the sum of the cycle lengths equals the number of edges to be covered. This variant of the conjecture was also proven by Bryant, Horsley, and Pettersson.

==Related problems==
The [[Oberwolfach problem]] on decompositions of complete graphs into copies of a given 2-regular graph is related, but neither is a special case of the other.
If &lt;math&gt;G&lt;/math&gt; is a 2-regular graph, with &lt;math&gt;n&lt;/math&gt; vertices, formed from a disjoint union of cycles of certain lengths, then a solution to the Oberwolfach problem for &lt;math&gt;G&lt;/math&gt; would also provide a decomposition of the complete graph into &lt;math&gt;(n-1)/2&lt;/math&gt; copies of each of the cycles of &lt;math&gt;G&lt;/math&gt;. However, not every decomposition of &lt;math&gt;K_n&lt;/math&gt; into this many cycles of each size can be grouped into disjoint cycles that form copies of &lt;math&gt;G&lt;/math&gt;, and on the other hand not every instance of Alspach's conjecture involves sets of cycles that have &lt;math&gt;(n-1)/2&lt;/math&gt; copies of each cycle.

==References==
*{{citation
 | last = Alspach | first = B. | authorlink = Brian Alspach
 | department = Research problems
 | doi = 10.1016/s0012-365x(81)80029-5
 | issue = 3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | page = 333
 | title = Problem 3
 | volume = 36
 | year = 1981}}
*{{citation
 | last1 = Bryant | first1 = Darryn
 | last2 = Horsley | first2 = Daniel
 | last3 = Pettersson | first3 = William
 | doi = 10.1112/plms/pdt051
 | issue = 5
 | journal = Proceedings of the London Mathematical Society
 | mr = 3214677
 | pages = 1153–1192
 | series = Third Series
 | title = Cycle decompositions V: Complete graphs into cycles of arbitrary lengths
 | volume = 108
 | year = 2014}}
*{{citation
 | last1 = Chartrand | first1 = Gary | author1-link = Gary Chartrand
 | last2 = Lesniak | first2 = Linda
 | last3 = Zhang | first3 = Ping | author3-link = Ping Zhang (graph theorist)
 | contribution = Alspach's conjecture
 | contribution-url = https://books.google.com/books?id=Cjw0CwAAQBAJ&amp;pg=PA349
 | edition = 6th
 | isbn = 9781498735803
 | page = 349
 | publisher = CRC Press
 | series = Textbooks in Mathematics
 | title = Graphs &amp; Digraphs
 | volume = 39
 | year = 2015}}

[[Category:Theorems in graph theory]]</text>
      <sha1>9u6vokgcv8sbp01ggsszu9ct3kffhts</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic rope</title>
    <ns>0</ns>
    <id>10324074</id>
    <revision>
      <id>836621792</id>
      <parentid>789708417</parentid>
      <timestamp>2018-04-15T21:59:51Z</timestamp>
      <contributor>
        <username>Adavidb</username>
        <id>2413055</id>
      </contributor>
      <minor/>
      <comment>/* top */clean up, added [[CAT:O|orphan]] tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3186">{{Orphan|date=April 2018}}

[[Image:Hortus Deliciarum - Arithmetik.gif|thumb|[[Allegory]] of the Arithmetic with knotted rope (taken from the [[Hortus deliciarum]] (around 1180)]]
The '''arithmetic rope''', or '''knotted rope''', was a widely used [[arithmetic tool]] in the [[Middle Ages]] that could be used to solve many [[mathematical]] and [[geometry|geometrical]] problems.

An arithmetic rope generally has at least 13 knots—therefore, it is often called '''thirteen-knot-rope'''—placed at equal intervals. More knots were beneficial, especially for [[multiplication]] and [[Division (mathematics)|division]].

In [[medieval architecture]], the knotted rope was indispensable for architects, because it allowed the construction of [[equilateral triangle|equilateral]] and [[right-angled triangle]]s, as well as [[circle]]s.

In the depiction of the [[liberal arts]] in [[Hortus deliciarum]], the [[allegory]] of arithmetics is a female figure with a knotted rope.

{{Clear}}

==Arithmetic functions==
{| class="wikitable"
| bgcolor="#FFDEAD" colspan="4"|'''Arithmetics'''
|-
| '''[[Addition]]'''
|X + Y = Z
|X knots are counted, then another Y. The total number of counted knots is Z.
|&lt;small&gt;e.g.: 5 + 4 = 9&lt;/small&gt;&lt;br&gt;[[Image:13knoten_add.png]]
|-
|'''[[Subtraction]]'''
|X - Y = Z
|X knots are counted, then Y knots are 'uncounted'. The total number of knots remaining counted is Z.
|&lt;small&gt;e.g.: 9 - 4 = 5&lt;/small&gt;&lt;br&gt;[[Image:13knoten_sub.png]]
|-
|'''[[Multiplication]]'''
|X * Y = Z
|X knots are counted, and the resulting distance is put together Y times. The total number of counted knots is Z.
|&lt;small&gt;e.g.: 4 * 3 = 12&lt;/small&gt;&lt;br&gt;[[Image:13knoten mul.gif]]
|-
|'''[[Division (mathematics)|Division]]'''
| nowrap|X / Y = Z (remainder Q)
|X knots are counted. From these knots, Y knots are taken and grouped together until all are used up. The number of groups is Z; the number of remaining knots represents the [[remainder]], Q.
|&lt;small&gt;e.g.: 12 / 4 = 3&lt;/small&gt;&lt;br&gt;[[Image:13knoten_div.png]]
|-
| bgcolor="#FFDEAD" colspan="4"|'''Geometrics'''
|-
| colspan="2" |'''[[Right angle]]'''
|The two ends of the knotted rope are nailed together, and 5 knots are counted for the base. For the perpendicular side, 4 knots are required. The right-angled triangle is generated by pulling the sides taut.
|[[Image:13knoten_rw.png]]
|-
| colspan="2" | '''[[Equilateral triangle]]'''
|The two ends of the knotted rope are nailed together, and 5 knots are counted for each side. The sides are tautened to create an equilateral triangle.
|[[Image:13knoten_gs.png]]
|-
| colspan="2" |'''[[Circle]]'''
|One end is nailed down, and a [[stylus]] is attached at the desired distance. With the rope pulled taut, the stylus is moved around, forming a circle.
|
|}

==External links==
* [https://web.archive.org/web/20070926220246/http://www.zdf.de/ZDFmt/mediathek/ZDFmt_video_cont/0%2C3498%2CMT-2172487--MD-1000051-vi-1-47%2C00.html ZDF Mediathek - Video showing the application of the arithmetic rope] (''in German'')
* http://turba-delirantium.skyrocket.de/wissenschaft/rechenseil.htm (''in German'')

{{DEFAULTSORT:Arithmetic Rope}}
[[Category:Mathematical tools]]
[[Category:Arithmetic]]</text>
      <sha1>s6wesnoomfe2xrgf3ucs3jy03tu5uga</sha1>
    </revision>
  </page>
  <page>
    <title>Banach–Alaoglu theorem</title>
    <ns>0</ns>
    <id>577366</id>
    <revision>
      <id>868847520</id>
      <parentid>865286248</parentid>
      <timestamp>2018-11-14T20:53:41Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10206">In [[functional analysis]] and related branches of [[mathematics]], the '''Banach–Alaoglu theorem''' (also known as '''Alaoglu's theorem''') states that the [[closed set|closed]] [[ball (mathematics)|unit ball]] of the [[dual space]] of a [[normed vector space]] is [[compact space|compact]] in the [[weak topology|weak* topology]].&lt;ref&gt;{{harvnb|Rudin|1991}}, section 3.15.&lt;/ref&gt;  A common proof identifies the unit ball with the weak* topology as a closed subset of a [[cartesian product|product]] of compact sets with the [[product topology]].  As a consequence of [[Tychonoff's theorem]], this product, and hence the unit ball within, is compact.

A proof of this theorem for [[separable space|separable]] normed vector spaces was published in 1932 by [[Stefan Banach]], and the first proof for the general case was published in 1940 by the mathematician [[Leonidas Alaoglu]].

Since the Banach–Alaoglu theorem is proven via [[Tychonoff's theorem]], it relies on the [[Zermelo–Fraenkel set theory|ZFC]] axiomatic framework, in particular the [[axiom of choice]].  Most mainstream functional analysis also relies on ZFC. However, the theorem does ''not'' rely upon the axiom of choice in the separable case (see below): in this case one actually has a constructive proof.

This theorem has applications in physics when one describes the set of states of an algebra of observables, namely that any states can be written as a convex linear combination of so-called pure states.

==The theorem==
Let X be a normed space, the dual X* is hence also a normed space (with the operator norm).

The closed unit ball of X* is compact with respect to the [[Ultraweak topology|weak* topology]]. (cf. also section "dual" in the article "topological vector space")

This is a motivation for having different topologies on a same space since in contrast the unit ball in the norm topology is compact if and only if the space is finite-dimensional, cf. [[Riesz lemma]].

==Sequential Banach–Alaoglu theorem==
A special case of the Banach–Alaoglu theorem is the sequential version of the theorem, which asserts that the closed unit ball of the dual space of a [[separable metric space|separable]] normed vector space is [[sequentially compact]] in the weak* topology.  In fact, the weak* topology on the closed unit ball of the dual of a separable space is [[metrizable]], and thus compactness and sequential compactness are equivalent.

Specifically, let ''X'' be a separable normed space and ''B'' the closed unit ball in ''X''&lt;sup&gt;&amp;lowast;&lt;/sup&gt;.  Since ''X'' is separable, let {''x''&lt;sub&gt;''n''&lt;/sub&gt;} be a countable dense subset.  Then the following defines a metric for ''x'',&amp;nbsp;''y''&amp;nbsp;&amp;isin;&amp;nbsp;''B''

:&lt;math&gt;\rho(x,y)=\sum_{n=1}^\infty \, 2^{-n} \, \frac{\left|\langle x-y, x_n\rangle\right|}{1 + \left|\langle x-y, x_n\rangle\right|}&lt;/math&gt;

in which &lt;math&gt;\langle\cdot,\cdot\rangle&lt;/math&gt; denotes the duality pairing of ''X''&lt;sup&gt;&amp;lowast;&lt;/sup&gt; with ''X''.  Sequential compactness of ''B'' in this metric can be shown by a [[diagonalization argument]] similar to the one employed in the proof of the [[Arzelà–Ascoli theorem]].

Due to the constructive nature of its proof (as opposed to the general case, which is based on the axiom of choice), the sequential Banach–Alaoglu theorem is often used in the field of [[partial differential equations]] to construct solutions to PDE or [[calculus of variations|variational problems]].  For instance, if one wants to minimize a functional&amp;thinsp; &lt;math&gt;F: X^* \to {\mathbb R}&lt;/math&gt;&amp;thinsp; on the dual of a separable normed vector space ''X'', one common strategy is to first construct a minimizing sequence&amp;thinsp; &lt;math&gt;x_1, x_2, \ldots \in X^*&lt;/math&gt;&amp;thinsp; which approaches the infimum of ''F'', use the sequential Banach–Alaoglu theorem to extract a subsequence that converges in the weak* topology to a limit ''x'', and then establish that ''x'' is a minimizer of ''F''.  The last step often requires ''F'' to obey a (sequential) [[Semi-continuity|lower semi-continuity]] property in the weak* topology.

When ''X''&lt;sup&gt;&amp;lowast;&lt;/sup&gt; is the space of finite Radon measures on the real line (so that&amp;thinsp; &lt;math&gt;X = C_0({\mathbb R})&lt;/math&gt;&amp;thinsp; is the space of continuous functions vanishing at infinity, by the [[Riesz–Markov–Kakutani representation theorem|Riesz representation theorem]]), the sequential Banach–Alaoglu theorem is equivalent to the [[Helly selection theorem]].

==Generalization: Bourbaki–Alaoglu theorem==

The '''Bourbaki–Alaoglu theorem''' is a generalization&lt;ref&gt;{{harvnb|Köthe|1969}}, Theorem (4) in §20.9.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Meise|Vogt|1997}}, Theorem 23.5.&lt;/ref&gt; by [[Nicolas Bourbaki|Bourbaki]] to [[dual topology|dual topologies]] on [[locally convex space]]s.

Given a separated [[locally convex space]] ''X'' with [[continuous dual]] ''X''&amp;nbsp;' then the [[polar set|polar]] ''U''&lt;sup&gt;0&lt;/sup&gt; of any [[neighbourhood (topology)|neighbourhood]] ''U'' in ''X'' is compact in the [[weak topology (polar topology)|weak topology]] σ(''X''&amp;nbsp;',''X'') on ''X''&amp;nbsp;'.

In the case of a normed vector space, the polar of a neighbourhood is closed and norm-bounded in the dual space.  For example, the polar of the unit ball is the closed unit ball in the dual.  Consequently, for normed vector space (and hence Banach spaces) the Bourbaki–Alaoglu theorem is equivalent to the Banach–Alaoglu theorem.

==Proof==

For any ''x'' in ''X'', let

:&lt;math&gt;D_x=\{z\in\Complex: \left|z\right|\leq \|x\|\},&lt;/math&gt;

and

:&lt;math&gt;D=\prod_{x\in X} D_x.&lt;/math&gt;

Since each ''D&lt;sub&gt;x&lt;/sub&gt;'' is a compact subset  of the complex plane, ''D'' is also compact in the [[product topology]] by [[Tychonoff theorem]].

We can identify the closed unit ball in ''X*'', ''B''&lt;sub&gt;1&lt;/sub&gt;(''X*''), as a subset of ''D'' in a natural way:

:&lt;math&gt; f \in B_1\left(X^*\right) \mapsto (f(x))_{x \in X} \in D.&lt;/math&gt;
 
This map is injective and continuous, with ''B''&lt;sub&gt;1&lt;/sub&gt;(''X*'') having the weak-* topology and ''D'' the product topology. Its inverse, defined on its range, is also continuous.

The theorem will be proved if the range of the above map is closed. But this is also clear. If one has a net

:&lt;math&gt;(f_{\alpha}(x))_{x \in X} \to (\lambda_x)_{x \in X}&lt;/math&gt;

in ''D'', then the functional defined by

:&lt;math&gt;g(x) = \lambda_x &lt;/math&gt;

lies in ''B''&lt;sub&gt;1&lt;/sub&gt;(''X*'').

==Consequences==
* In a Hilbert space, every bounded and closed set is weakly relatively compact, hence every bounded net has a weakly convergent subnet (Hilbert spaces are [[reflexive space|reflexive]]).
* As norm-closed, convex sets are weakly closed ([[Hahn–Banach theorem]]), norm-closures of convex bounded sets in Hilbert spaces or reflexive Banach spaces are weakly compact.
* Closed and bounded sets in ''B(H)'' are precompact with respect to the [[weak operator topology]] (the weak operator topology is weaker than the [[ultraweak topology]] which is in turn the weak-*-topology with respect to the predual of ''B(H)'', the [[trace class]] operators.) Hence bounded sequences of operators have a weak accumulation point. 
As a consequence, ''B(H)'' has the [[Heine–Borel theorem|Heine–Borel property]], if equipped with either the weak operator or the ultraweak topology.
* If ''X'' is a [[reflexive Banach space]], then every bounded sequence in ''X'' has a weakly convergent subsequence.  (This follows by applying the Banach–Alaoglu theorem to a weakly metrizable subspace of ''X''; or, more succinctly, by applying the [[Eberlein–Šmulian theorem]].) For example, suppose that ''X''=[[Lp space|''L''&lt;sup&gt;p&lt;/sup&gt;(&amp;mu;)]], 1&lt;''p''&lt;∞.  Let ''f''&lt;sub&gt;n&lt;/sub&gt; be a bounded sequence of functions in ''X''. Then there exists a subsequence ''f''&lt;sub&gt;n&lt;sub&gt;k&lt;/sub&gt;&lt;/sub&gt; and an ''f'' &amp;isin; ''X'' such that

::&lt;math&gt;\int f_{n_k} g\,d\mu \to \int f g\,d\mu&lt;/math&gt;

:for all ''g'' &amp;isin; ''L''&lt;sup&gt;q&lt;/sup&gt;(&amp;mu;) = ''X''* (where 1/''p''+1/''q''=1).  The corresponding result for ''p''=1 is not true, as ''L''&lt;sup&gt;1&lt;/sup&gt;(&amp;mu;) is not reflexive.

It should be cautioned that despite appearances, the Banach–Alaoglu theorem does ''not'' imply that the weak-* topology is locally compact.  This is because the closed unit ball is only a neighborhood of the origin in the [[strong topology]], but is usually not a neighbourhood of the origin in the weak-* topology, as it has empty interior in the weak* topology, unless the space is finite-dimensional.  In fact, it is a result of [[André Weil|Weil]] that all [[locally compact]] [[Hausdorff space|Hausdorff]] topological vector spaces must be finite-dimensional.

==See also==
*[[Bishop–Phelps theorem]]
*[[Banach–Mazur theorem]]
*[[Eberlein–Šmulian theorem]]
*[[Goldstine theorem]]
*[[James' theorem]]
*[[Mazur's lemma]]
*[[Krein-Milman theorem]]
* [[Delta-convergence|Delta-compactness theorem]]

==Notes==
{{reflist}}

==References==
* {{Cite book  |ref=harv
  | last = Rudin
  | first = W.
  | authorlink=Walter Rudin 
  | title = Functional Analysis
  | place = Boston, MA
  | publisher = McGraw-Hill
  | isbn = 0-07-054236-8
  | edition = 2nd
  | year = 1991
  | postscript = &lt;!--None--&gt; }} See section 3.15, p.&amp;nbsp;68.
* {{cite book
  | last1=Meise
  | first1=Reinhold
  | last2=Vogt
  | first2=Dietmar
  | title=Introduction to Functional Analysis
  | publisher=Clarendon Press
  | location=Oxford
  | year=1997
  | isbn=0-19-851485-9
  | ref=harv}} See Theorem 23.5, p.&amp;nbsp;264.
* {{cite book|last1=Köthe|first1=Gottfried|title=Topological Vector Spaces I|date=1969|publisher=Springer-Verlag|location=New York|ref=harv}} See §20.9.

==Further reading==
* {{cite book | author = John B. Conway|authorlink=John B. Conway | title = A course in functional analysis | publisher = Springer-Verlag | location = Berlin | year = 1994 | edition = 2nd | isbn = 0-387-97245-5}} See Chapter 5, section 3.
* {{cite book | author = Peter B. Lax 
|authorlink=Peter Lax 
| title = Functional Analysis 
| publisher = Wiley-Interscience | year = 2002 
|pages=120–121| isbn = 0-471-55604-1}}

{{Functional Analysis}}

{{DEFAULTSORT:Banach-Alaoglu theorem}}
[[Category:Functional analysis]]
[[Category:Articles containing proofs]]
[[Category:Compactness theorems]]</text>
      <sha1>nk9iqh6cbw7y7srmff1xlm3b4f3b5qx</sha1>
    </revision>
  </page>
  <page>
    <title>Bell number</title>
    <ns>0</ns>
    <id>201022</id>
    <revision>
      <id>860278212</id>
      <parentid>858941895</parentid>
      <timestamp>2018-09-19T15:30:49Z</timestamp>
      <contributor>
        <username>Maxal</username>
        <id>237258</id>
      </contributor>
      <comment>/* Bell primes */ asof update</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28669">In [[combinatorics|combinatorial mathematics]], the '''Bell numbers''' count the possible [[partition of a set|partitions of a set]]. These numbers have been studied by mathematicians since the 19th century, and their roots go back to medieval Japan, but they are named after [[Eric Temple Bell]], who wrote about them in the 1930s.

Starting with ''B''&lt;sub&gt;0&lt;/sub&gt; = ''B''&lt;sub&gt;1&lt;/sub&gt; = 1, the first few Bell numbers are:
:1, [[1 (number)|1]], [[2 (number)|2]], [[5 (number)|5]], [[15 (number)|15]], [[52 (number)|52]], [[203 (number)|203]], 877, 4140, 21147, 115975, 678570, 4213597, 27644437, 190899322, 1382958545, 10480142147, 82864869804, 682076806159, 5832742205057, ... {{OEIS|id=A000110}}.

The ''n''th of these numbers, ''B&lt;sub&gt;n&lt;/sub&gt;'', counts the number of different ways to partition a set that has exactly ''n'' elements, or equivalently, the number of [[equivalence relation]]s on it. 
Outside of mathematics, the same number also counts the number of different [[rhyme scheme]]s for ''n''-line poems.{{sfn|Gardner|1978}}

As well as appearing in counting problems, these numbers have a different interpretation, as [[moment (mathematics)|moments]] of [[probability distribution]]s. In particular, ''B&lt;sub&gt;n&lt;/sub&gt;'' is the ''n''th moment of a [[Poisson distribution]] with [[mean]] 1.

==Counting==

===Set partitions===
{{main article|Partition of a set}}
[[File:Bell numbers subset partial order.svg|thumb|right|Partitions of sets can be arranged in a partial order, showing that each partition of a set of size n "uses" one of the partitions of a set of size n-1.]]
[[File:Set partitions 5; circles.svg|thumb|The 52 partitions of a set with 5 elements]]
In general, ''B''&lt;sub&gt;''n''&lt;/sub&gt; is the number of [[partition of a set|partitions]] of a set of size ''n''. A partition of a set ''S'' is defined as a set of nonempty, pairwise disjoint subsets of ''S'' whose union is ''S''. For example, ''B''&lt;sub&gt;3&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;5 because the 3-element set {''a'',&amp;nbsp;''b'',&amp;nbsp;''c''} can be partitioned in 5 distinct ways:

:{ {''a''}, {''b''}, {''c''} }
:{ {''a''}, {''b'', ''c''} }
:{ {''b''}, {''a'', ''c''} }
:{ {''c''}, {''a'', ''b''} }
:{ {''a'', ''b'', ''c''} }.

''B''&lt;sub&gt;0&lt;/sub&gt; is 1 because there is exactly one partition of the [[empty set]]. Every member of the empty set is a nonempty set (that is [[vacuous truth|vacuously true]]), and their union is the empty set.  Therefore, the empty set is the only partition of itself. As suggested by the set notation above, we consider neither the order of the partitions nor the order of elements within each partition. This means that the following partitionings are all considered identical:
:{ {''b''}, {''a'', ''c''} }
:{ {''a'', ''c''}, {''b''} }
:{ {''b''}, {''c'', ''a''} }
:{ {''c'', ''a''}, {''b''} }.
If, instead, different orderings of the sets are considered to be different partitions, then the number of these [[Weak ordering|ordered partitions]] is given by the [[ordered Bell number]]s.

===Factorizations===
If a number ''N'' is a [[squarefree]] positive [[integer]] (meaning that it is the product of some number ''n'' of distinct [[prime number]]s), then ''B&lt;sub&gt;n&lt;/sub&gt;'' gives the number of different [[multiplicative partition]]s of ''N''. These are [[factorization]]s of ''N'' into numbers greater than one, treating two factorizations as the same if they have the same factors in a different order.&lt;ref&gt;{{harvnb|Williams|1945}} credits this observation to Silvio Minetola's ''Principii di Analisi Combinatoria'' (1909).&lt;/ref&gt; For instance, 30 is the product of the three primes 2, 3, and&amp;nbsp;5, and has ''B''&lt;sub&gt;3&lt;/sub&gt; = 5 factorizations:
:&lt;math&gt;30 = 2\times 15=3\times 10=5\times 6=2\times 3\times 5&lt;/math&gt;

===Rhyme schemes===
The Bell numbers also count the [[rhyme scheme]]s of an ''n''-line [[poem]] or [[stanza]]. A rhyme scheme describes which lines rhyme with each other, and so may be interpreted as a partition of the set of lines into rhyming subsets. Rhyme schemes are usually written as a sequence of Roman letters, one per line, with rhyming lines given the same letter as each other, and with the first lines in each rhyming set labeled in alphabetical order. Thus, the 15 possible four-line rhyme schemes are AAAA, AAAB, AABA, AABB, AABC, ABAA, ABAB, ABAC, ABBA, ABBB, ABBC, ABCA, ABCB, ABCC, and ABCD.{{sfn|Gardner|1978}}

===Permutations===
The Bell numbers come up in a card [[shuffling]] problem mentioned in the addendum to {{harvtxt|Gardner|1978}}. If a deck of ''n'' cards is shuffled by repeatedly removing the top card and reinserting it anywhere in the deck (including its original position at the top of the deck), with exactly ''n'' repetitions of this operation, then there are ''n''&lt;sup&gt;''n''&lt;/sup&gt; different shuffles that can be performed. Of these, the number that return the deck to its original sorted order is exactly ''B&lt;sub&gt;n&lt;/sub&gt;''. Thus, the probability that the deck is in its original order after shuffling it in this way is ''B&lt;sub&gt;n&lt;/sub&gt;''/''n''&lt;sup&gt;''n''&lt;/sup&gt;, which is significantly larger than the 1/''n''! probability that would describe a uniformly random permutation of the deck.

Related to card shuffling are several other problems of counting special kinds of [[permutation]]s that are also answered by the Bell numbers. For instance, the ''n''th Bell number equals number of permutations on ''n'' items in which no three values that are in sorted order have the last two of these three consecutive. In a notation for generalized [[permutation pattern]]s where values that must be consecutive are written adjacent to each other, and values that can appear non-consecutively are separated by a dash, these permutations can be described as the permutations that avoid the pattern 1-23. The permutations that avoid the generalized patterns 12-3, 32-1, 3-21, 1-32, 3-12, 21-3, and 23-1 are also counted by the Bell numbers.{{sfnp|Claesson|2001}} The permutations in which every 321 pattern (without restriction on consecutive values) can be extended to a 3241 pattern are also counted by the Bell numbers.{{sfnp|Callan|2006}} However, the Bell numbers grow too quickly to count the permutations that avoid a pattern that has not been generalized in this way: by the (now proven) [[Stanley–Wilf conjecture]], the number of such permutations is singly exponential, and the Bell numbers have a higher asymptotic growth rate than that.

==Triangle scheme for calculations==
{{main article|Bell triangle}}
[[Image:BellNumberAnimated.gif|right|thumb|The triangular array whose right-hand diagonal sequence consists of Bell numbers]]
The Bell numbers can easily be calculated by creating the so-called [[Bell triangle]], also called '''Aitken's array''' or the '''Peirce triangle''' after [[Alexander Aitken]] and [[Charles Sanders Peirce]].&lt;ref&gt;{{Cite OEIS|A011971|name=Aitken's array}}&lt;/ref&gt;

# Start with the number one.  Put this on a row by itself. (&lt;math&gt; x_{0,1} = 1 &lt;/math&gt;)
# Start a new row with the rightmost element from the previous row as the leftmost number (&lt;math&gt;x_{i,1} \leftarrow x_{i-1, r}&lt;/math&gt; where ''r'' is the last element of (''i''-1)-th row)
# Determine the numbers not on the left column by taking the sum of the number to the left and the number above the number to the left, that is, the number diagonally up and left of the number we are calculating &lt;math&gt;( x_{i,j} \leftarrow x_{i,j-1} + x_{i-1,j-1} )&lt;/math&gt; 
# Repeat step three until there is a new row with one more number than the previous row (do step 3 until &lt;math&gt; j = r + 1 &lt;/math&gt;)
# The number on the left hand side of a given row is the ''Bell number'' for that row. (&lt;math&gt;B_i \leftarrow x_{i,1}&lt;/math&gt;)

Here are the first five rows of the triangle constructed by these rules:

  1
  1   2
  2   3   5
  5   7  10  15
 15  20  27  37  52

The Bell numbers appear on both the left and right sides of the triangle.

==Properties==

===Summation formulas===
The Bell numbers satisfy a [[recurrence relation]] involving [[binomial coefficient]]s:{{sfn|Wilf|1994|p=23}}
:&lt;math&gt;B_{n+1}=\sum_{k=0}^{n} \binom{n}{k} B_k.&lt;/math&gt;
It can be explained by observing that, from an arbitrary partition of ''n''&amp;nbsp;+&amp;nbsp;1 items, removing the set containing the first item leaves a partition of a smaller set of ''k'' items for some number ''k'' that may range from 0 to ''n''. There are &lt;math&gt;\tbinom{n}{k}&lt;/math&gt; choices for the ''k'' items that remain after one set is removed, and ''B&lt;sub&gt;k&lt;/sub&gt;'' choices of how to partition them.

A different summation formula represents  each Bell number as a sum of [[Stirling numbers of the second kind]]
:&lt;math&gt;B_n=\sum_{k=0}^n \left\{{n\atop k}\right\}.&lt;/math&gt;
The Stirling number &lt;math&gt;\left\{{n\atop k}\right\}&lt;/math&gt; is the number of ways to partition a set of cardinality ''n'' into exactly ''k'' nonempty subsets. Thus, in the equation relating the Bell numbers to the Stirling numbers, each partition counted on the left hand side of the equation is counted in exactly one of the terms of the sum on the right hand side, the one for which ''k'' is the number of sets in the partition.{{sfnp|Conway|Guy|1996}}

{{harvtxt|Spivey|2008}} has given a formula that combines both of these summations:
:&lt;math&gt;B_{n+m} = \sum_{k=0}^n \sum_{j=0}^m \left\{{m\atop j}\right\} {n \choose k} j^{n-k} B_k.&lt;/math&gt;

===Generating function===
The [[generating function|exponential generating function]] of the Bell numbers is
:&lt;math&gt;B(x) = \sum_{n=0}^\infty \frac{B_n}{n!} x^n = e^{e^x-1}.&lt;/math&gt;
In this formula, the summation in the middle is the general form used to define the exponential generating function for any sequence of numbers, and the formula on the right is the result of performing the summation in the specific case of the Bell numbers.

One way to derive this result uses [[analytic combinatorics]], a style of mathematical reasoning in which sets of mathematical objects are described by formulas explaining their construction from simpler objects, and then those formulas are manipulated to derive the combinatorial properties of the objects. In the language of analytic combinatorics, a set partition may be described as a set of nonempty [[Urn problem|urns]] into which elements labelled from 1 to ''n'' have been distributed, and the [[combinatorial class]] of all partitions (for all ''n'') may be expressed by the notation
:&lt;math&gt;\mathrm{S\scriptstyle ET}(\mathrm{S\scriptstyle ET}_{\ge 1}(\mathcal{Z})).&lt;/math&gt;
Here, &lt;math&gt;\mathcal{Z}&lt;/math&gt; is a combinatorial class with only a single member of size one, an element that can be placed into an urn. The inner &lt;math&gt;\mathrm{S\scriptstyle ET}_{\ge 1}&lt;/math&gt; operator describes a set or urn that contains one or more labelled elements, and the outer
&lt;math&gt;\mathrm{S\scriptstyle ET}&lt;/math&gt; describes the overall partition as a set of these urns. The exponential generating function may then be read off from this notation by translating the &lt;math&gt;\mathrm{S\scriptstyle ET}&lt;/math&gt; operator into the exponential function and the nonemptiness constraint ≥1 into subtraction by one.{{sfn|Flajolet|Sedgewick|2009}}

An alternative method for deriving the same generating function uses the recurrence relation for the Bell numbers in terms of binomial coefficients to show that the exponential generating function satisfies the [[differential equation]] &lt;math&gt;B'(x) = e^{x}B(x)&lt;/math&gt;. The function itself can be found by solving this equation.{{sfn|Rota|1964}}{{sfn|Wilf|1994|pp=20-23}}{{sfn|Bender|Williamson|2006}}

===Moments of probability distributions===
The Bell numbers satisfy [[Dobinski's formula]]{{sfn|Dobiński|1877}}{{sfn|Rota|1964}}{{sfn|Bender|Williamson|2006}}
:&lt;math&gt;B_n=\frac{1}{e}\sum_{k=0}^\infty \frac{k^n}{k!}.&lt;/math&gt;
This formula can be derived by expanding the exponential generating function using the [[Taylor series]] for the exponential function, and then collecting terms with the same exponent.{{sfn|Flajolet|Sedgewick|2009}}
It allows ''B&lt;sub&gt;n&lt;/sub&gt;'' to be interpreted as the ''n''th [[moment (mathematics)|moment]] of a [[Poisson distribution]] with [[expected value]] 1.

The ''n''th Bell number is also the sum of the coefficients in the ''n''th [[Bell polynomial|complete Bell polynomial]], which expresses the ''n''th [[moment (mathematics)|moment]] of any [[probability distribution]] as a function of the first ''n'' [[cumulant]]s.

===Modular arithmetic===
The Bell numbers obey [[Touchard's congruence]]: If ''p'' is any [[prime number]] then{{sfnp|Becker|Riordan|1948}}
:&lt;math&gt;B_{p+n} \equiv B_n+B_{n+1} \pmod p&lt;/math&gt;
or, generalizing{{sfnp|Hurst|Schultz|2009}}
:&lt;math&gt;B_{p^m+n} \equiv mB_n+B_{n+1} \pmod p.&lt;/math&gt;

Because of Touchard's congruence, the Bell numbers are periodic modulo ''p'', for every prime number ''p''; for instance, for ''p''&amp;nbsp;=&amp;nbsp;2, the Bell numbers repeat the pattern odd-odd-even with period three. The period of this repetition, for an arbitrary prime number ''p'', must be a divisor of
:&lt;math&gt;\frac{p^p-1}{p-1}&lt;/math&gt;
and for all prime ''p'' ≤ 101 and ''p'' = 113, 163, 167, or 173 it is exactly this number {{OEIS|id=A001039}}.{{sfn|Williams|1945}}{{sfn|Wagstaff|1996}}

The period of the Bell numbers to modulo ''n'' are
:1, 3, 13, 12, 781, 39, 137257, 24, 39, 2343, 28531167061, 156, 25239592216021, 411771, 10153, 48, 51702516367896047761, 39, 109912203092239643840221, 9372, 1784341, 85593501183, 949112181811268728834319677753, 312, 3905, 75718776648063, 117, 1647084, 91703076898614683377208150526107718802981, 30459, 568972471024107865287021434301977158534824481, 96, 370905171793, 155107549103688143283, 107197717, 156, ... {{OEIS|id=A054767}}

===Integral representation===
An application of [[Cauchy's integral formula]] to the exponential generating function yields the complex integral representation
: &lt;math&gt; B_n = \frac{n!}{2 \pi i e} \int_{\gamma} \frac{e^{e^z}}{z^{n+1}} \, dz. &lt;/math&gt;

Some asymptotic representations can then be derived by a standard application of the [[method of steepest descent]].&lt;ref&gt;{{cite book|title=Complex Analysis|first=Barry|last=Simon|year=2010|contribution=Example 15.4.6 (Asymptotics of Bell Numbers)|pages=772–774|url=http://www.math.caltech.edu/~2010-11/2term/ma111b/CA-Sec15-4_march2.pdf}}&lt;/ref&gt;

===Log-concavity===
The Bell numbers form a [[logarithmically concave sequence|logarithmically convex sequence]]. Dividing them by the factorials, ''B''&lt;sub&gt;''n''&lt;/sub&gt;/''n''!, gives a logarithmically concave sequence.{{sfn|Engel|1994}}{{sfn|Canfield|1995}}{{sfn|Asai|Kubo|Kuo|2000}}

===Growth rate===
Several [[Asymptotic analysis|asymptotic]] formulas for the Bell numbers are known.  In {{harvtxt|Berend|Tassa|2010}} the following bounds were established:
:&lt;math&gt; B_n &lt; \left( \frac{0.792 n}{\ln( n+1)} \right)^n &lt;/math&gt; for all positive integers &lt;math&gt;n&lt;/math&gt;;
moreover, if &lt;math&gt; \varepsilon&gt;0 &lt;/math&gt; then for all &lt;math&gt; n &gt; n_0(\varepsilon) &lt;/math&gt;,
:&lt;math&gt; B_n &lt; \left( \frac{e^{-0.6 + \varepsilon} n}{\ln(n+1)}\right)^n &lt;/math&gt;
where   &lt;math&gt; ~n_0(\varepsilon) = \max\left\{e^4,d^{-1}(\varepsilon) \right\}~ &lt;/math&gt;   and
&lt;math&gt; ~d(x):= \ln \ln (x+1) - \ln \ln x + \frac{1+e^{-1}}{\ln x}\,.
&lt;/math&gt;
The Bell numbers can also be approximated using the [[Lambert W function]], a function with the same growth rate as the logarithm, as {{sfnp|Lovász|1993}}
:&lt;math&gt;B_n  \sim \frac{1}{\sqrt{n}} \left( \frac{n}{W(n)} \right)^{n + \frac{1}{2}} \exp\left(\frac{n}{W(n)} - n - 1\right). &lt;/math&gt;

{{harvtxt|Moser|Wyman|1955}} established the expansion
:&lt;math&gt;B_{n+h} = \frac{(n+h)!}{W(n)^{n+h}} \times \frac{\exp(e^{W(n)} - 1)}{(2\pi B)^{1/2}} \times \left( 1 + \frac{P_0 + hP_1 + h^2P_2}{e^{W(n)}} + \frac{Q_0 + hQ_1 + h^2Q_2 + h^3Q_3 + h^4Q_4}{e^{2W(n)}} + O(e^{-3W(n)}) \right)&lt;/math&gt;
uniformly for &lt;math&gt;h = O(\ln(n))&lt;/math&gt; as &lt;math&gt;n \rightarrow \infty&lt;/math&gt;, where &lt;math&gt;B&lt;/math&gt; and each &lt;math&gt;P_i&lt;/math&gt; and &lt;math&gt;Q_i&lt;/math&gt; are known expressions in &lt;math&gt;W(n)&lt;/math&gt;.&lt;ref&gt;{{cite web|url=http://www.austinmohr.com/Work_files/bellMoser.pdf|title=The Moser-Wyman expansion of the Bell numbers|first=Rod|last=Canfield|date=July 1994|accessdate=2013-10-24}}&lt;/ref&gt;

The asymptotic expression

:&lt;math&gt;
\begin{align}
\frac{\ln B_n}{n} &amp; = \ln n - \ln \ln n - 1 + \frac{\ln \ln n}{\ln n} + \frac{1}{\ln n} + \frac{1}{2}\left(\frac{\ln \ln n}{\ln n}\right)^2 + O\left(\frac{\ln \ln n}{(\ln n)^2} \right) \\
&amp; {} \qquad \text{as }n\to\infty
\end{align}
&lt;/math&gt;

was established by {{harvtxt|de Bruijn|1981}}.

==Bell primes==
{{harvtxt|Gardner|1978}} raised the question of whether infinitely many Bell numbers are also [[prime number]]s. The first few Bell numbers that are prime are:
:2, 5, 877, 27644437, 35742549198872617291353508656626642567, 359334085968622831041960188598043661065388726959079837 {{OEIS|id=A051131}}
corresponding to the indices 2, 3, 7, 13, 42 and 55 {{OEIS|id=A051130}}.

The next '''Bell prime''' is ''B''&lt;sub&gt;2841&lt;/sub&gt;, which is approximately 9.30740105 &amp;times; 10&lt;sup&gt;6538&lt;/sup&gt;.&lt;ref&gt;{{cite web|url=http://primes.utm.edu/primes/page.php?id=68825|title=93074010508593618333...83885253703080601131|work=5000 Largest Known Primes, The Prime Database|accessdate=2013-10-24}}&lt;/ref&gt; {{As of|2018}}, it is the largest known prime Bell number.  [[Phil Carmody]] showed it was a [[probable prime]] in 2002. After 17 months of computation with Marcel Martin's [[Elliptic curve primality proving|ECPP]] program Primo, Ignacio Larrosa Cañestro proved it to be prime in 2004. He ruled out any other possible primes below ''B''&lt;sub&gt;6000&lt;/sub&gt;, later extended to ''B''&lt;sub&gt;30447&lt;/sub&gt; by [[Eric Weisstein]].&lt;ref&gt;{{mathworld|title=Integer Sequence Primes|id=IntegerSequencePrimes}}&lt;/ref&gt;

==History==
The Bell numbers are named after [[Eric Temple Bell]], who wrote about them in 1938, following up a 1934 paper in which he studied the [[Bell polynomials]].{{sfn|Bell|1934}}{{sfn|Bell|1938}} Bell did not claim to have discovered these numbers; in his 1938 paper, he wrote that the Bell numbers "have been frequently investigated" and "have been rediscovered many times". Bell cites several earlier publications on these numbers, beginning with {{harvtxt|Dobiński|1877}} which gives [[Dobinski's formula]] for the Bell numbers. Bell called these numbers "exponential numbers"; the name "Bell numbers" and the notation ''B&lt;sub&gt;n&lt;/sub&gt;'' for these numbers was given to them by {{harvtxt|Becker|Riordan|1948}}.&lt;ref&gt;{{harvnb|Rota|1964}}. However, Rota gives an incorrect date, 1934, for {{harvnb|Becker|Riordan|1948}}.&lt;/ref&gt;

The first exhaustive enumeration of set partitions appears to have occurred in medieval Japan, where (inspired by the popularity of the book ''[[The Tale of Genji]]'') a parlor game called ''genji-ko'' sprang up,
in which guests were given five packets of incense to smell and were asked to guess which ones were the same as each other and which were different. The 52 possible solutions, counted by the Bell number ''B''&lt;sub&gt;5&lt;/sub&gt;, were recorded by 52 different diagrams, which were printed above the chapter headings in some editions of The Tale of Genji.{{sfn|Knuth|2013}}&lt;ref&gt;{{harvnb|Gardner|1978}} and {{harvnb|Berndt|2011}} also mention the connection between Bell numbers and The Tale of Genji, in less detail.&lt;/ref&gt;

In [[Srinivasa Ramanujan]]'s second notebook, he investigated both Bell polynomials and Bell numbers.{{sfn|Berndt|2011}}
Early references for the [[Bell triangle]], which has the Bell numbers on both of its sides, include {{harvtxt|Peirce|1880}} and {{harvtxt|Aitken|1933}}.

==See also==
* [[Touchard polynomials]]

==Notes==
{{Reflist|30em}}

==References==
{{refbegin|30em}}
*{{cite journal
 | last1 = Asai | first1 = Nobuhiro
 | last2 = Kubo | first2 = Izumi
 | last3 = Kuo | first3 = Hui-Hsiung
 | arxiv = math/0104137
 | doi = 10.1023/A:1010738827855
 | issue = 1-3
 | journal = Acta Applicandae Mathematicae
 | mr = 1831247
 | pages = 79–87
 | title = Bell numbers, log-concavity, and log-convexity
 | volume = 63
 | year = 2000
 | ref = harv}}
*{{cite journal
 | last = Aitken | first = A. C. | author-link = Alexander Aitken
 | doi = 10.1017/S1757748900002334
 | journal = [[Edinburgh Mathematical Notes|Mathematical Notes]]
 | pages = 18–23
 | title = A problem in combinations
 | volume = 28
 | year = 1933|ref=harv }}
*{{cite journal|ref=harv|first1=H. W.|last1=Becker|first2=John|last2=Riordan|author2-link=John Riordan (mathematician)|title=The arithmetic of Bell and Stirling numbers|journal=American Journal of Mathematics|volume=70|year=1948|pages=385–394|jstor= 2372336|doi=10.2307/2372336}}.
*{{cite journal|first=E. T.|last=Bell|authorlink=Eric Temple Bell|title= Exponential polynomials|journal=Annals of Mathematics|volume=35|year=1934|pages=258–277|ref=harv|jstor=1968431|doi=10.2307/1968431}}.
*{{cite journal|first=E. T.|last=Bell|authorlink=Eric Temple Bell|title= The iterated exponential integers|journal=Annals of Mathematics|volume=39|year=1938|pages=539–557|ref=harv|jstor=1968633|doi=10.2307/1968633}}.
*{{cite book
 | last1 = Bender | first1 = Edward A.
 | last2 = Williamson | first2 = S. Gill
 | contribution = Example 11.7, Set Partitions
 | isbn = 0-486-44603-4
 | pages = 319–320
 | publisher = Dover
 | title = Foundations of Combinatorics with Applications
 | url = http://www.math.ucsd.edu/~ebender/CombText/ch-11.pdf
 | year = 2006
 | ref = harv}}
*{{cite journal
 | last1 = Berend | first1 = D.
 | last2 = Tassa | first2 = T.
 | issue = 2
 | journal = Probability and Mathematical Statistics
 | pages = 185–205
 | title = Improved bounds on Bell numbers and on moments of sums of random variables
 | volume = 30
 | year = 2010
 | ref = harv}}
*{{cite journal
 | last = Berndt | first = Bruce C.
 | issue = 2
 | journal = Asia Pacific Mathematics Newsletter
 | pages = 8–13
 | title = Ramanujan Reaches His Hand From His Grave To Snatch Your Theorems From You
 | url = http://www.asiapacific-mathnews.com/01/0102/0008_0013.pdf
 | volume = 1
 | year = 2011
 | ref = harv}}
*{{cite book
 | last = de Bruijn | first = N.G. | author-link = Nicolaas_Govert_de_Bruijn
 | page = 108
 | title = Asymptotic methods in analysis
 | publisher = Dover
 | edition = 3rd
 | year = 1981
 | ref = harv}}
*{{cite journal
 | last = Callan | first = David
 | arxiv = math/0507169
 | issue = 1
 | journal = Journal of Integer Sequences
 | mr = 2193154
 | page = 06.1.4
 | title = A combinatorial interpretation of the eigensequence for composition
 | url = https://eudml.org/doc/52955
 | volume = 9
 | year = 2006
 | ref = harv|bibcode = 2005math......7169C}}
*{{cite journal
 | last = Canfield | first = E. Rodney
 | doi = 10.1016/0097-3165(95)90033-0
 | issue = 1
 | journal = Journal of Combinatorial Theory
 | mr = 1354972
 | pages = 184–187
 | series = Series A
 | title = Engel's inequality for Bell numbers
 | volume = 72
 | year = 1995
 | ref = harv}}
*{{cite journal
 | last = Claesson | first = Anders
 | doi = 10.1006/eujc.2001.0515
 | issue = 7
 | journal = European Journal of Combinatorics
 | mr = 1857258
 | pages = 961–971
 | title = Generalized pattern avoidance
 | volume = 22
 | year = 2001
 | ref = harv}}
*{{cite book|last1=Conway|first1=John Horton|author1-link=John Horton Conway|last2=Guy|first2=Richard K.|author2-link=Richard K. Guy|title=The Book of Numbers|series=Copernicus Series|publisher=Springer|year=1996|isbn=9780387979939|contribution=Famous Families of Numbers: Bell Numbers and Stirling Numbers|pages=91–94|ref=harv}}
*{{cite journal|first=G.|last=Dobiński|title=Summirung&lt;!-- "Summirung" is an archaic spelling, and it is the spelling that was used in this title. --&gt; der Reihe &lt;math&gt;\textstyle\sum\frac{n^m}{n!}&lt;/math&gt; für ''m''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;4,&amp;nbsp;5,&amp;nbsp;…|journal=Grunert's Archiv|volume=61|year=1877|pages=333–336|url=https://archive.org/stream/archivdermathem88unkngoog#page/n346|ref=harv}}
*{{cite journal
 | last = Engel | first = Konrad
 | doi = 10.1016/0097-3165(94)90038-8
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1255264
 | pages = 67–78
 | series = Series A
 | title = On the average rank of an element in a filter of the partition lattice
 | volume = 65
 | year = 1994
 | ref = harv}}
*{{cite book
 | last1 = Flajolet | first1 = Philippe | author1-link = Philippe Flajolet
 | last2 = Sedgewick | first2 = Robert | author2-link = Robert Sedgewick (computer scientist)
 | contribution = II.3 Surjections, set partitions, and words
 | pages = 106–119
 | publisher = Cambridge University Press
 | title = Analytic Combinatorics
 | url = http://algo.inria.fr/flajolet/Publications/book.pdf
 | year = 2009
 | ref = harv}}
*{{cite journal
 | last = Gardner | first = Martin | author-link = Martin Gardner
 | doi = 10.1038/scientificamerican0578-24
 | journal = [[Scientific American]]
 | pages = 24–30
 | title = The Bells: versatile numbers that can count partitions of a set, primes and even rhymes
 | volume = 238
 | year = 1978|ref=harv| bibcode = 1978SciAm.238e..24G}} Reprinted with an addendum as "The Tinkly Temple Bells", Chapter 2 of ''Fractal Music, Hypercards, and more ... Mathematical Recreations from Scientific American'', W. H. Freeman, 1992, pp.&amp;nbsp;24–38
* {{springer|title=Bell numbers|id=p/b110240}}
*{{cite arXiv|title=An elementary (number theory) proof of Touchard's congruence|first1=Greg|last1=Hurst|first2=Andrew|last2=Schultz|eprint=0906.0696|year=2009|class=math.CO|ref=harv}}
* {{cite book|contribution=Two thousand years of combinatorics|first=Donald E.|last=Knuth|authorlink=Donald Knuth|pages=7–37|title=Combinatorics: Ancient and Modern|publisher=Oxford University Press|year=2013|editor1-first=Robin|editor1-last=Wilson|editor2-first=John J.|editor2-last=Watkins|ref=harv}}
*{{Cite book |authorlink=László Lovász| last=Lovász | first=L. |title=Combinatorial Problems and Exercises |edition=2nd |place=Amsterdam, Netherlands |publisher=North-Holland |year=1993|zbl=0785.05001|contribution=Section 1.14, Problem 9|page=17|url=https://books.google.com/books?id=e99fXXYx9zcC&amp;pg=PA17|ref=harv}}
*{{cite journal
 | last1 = Moser | first1 = Leo | author1-link = Leo Moser
 | last2 = Wyman | first2 = Max
 | journal = Transactions of the Royal Society of Canada, Section III
 | mr = 0078489
 | pages = 49–54
 | title = An asymptotic formula for the Bell numbers
 | volume = 49
 | year = 1955
 | ref = harv}}
*{{cite journal
 | last = Peirce | first = C. S. | author-link = Charles Sanders Peirce
 | issue = 1
 | journal = [[American Journal of Mathematics]]
 | jstor = 2369442
 | pages = 15–57
 | title = On the algebra of logic
 | volume = 3
 | year = 1880|ref=harv | doi=10.2307/2369442}}. 
*{{citation
 | last = Rota | first = Gian-Carlo | author-link = Gian-Carlo Rota
 | doi = 10.2307/2312585
 | issue = 5
 | journal = [[American Mathematical Monthly]]
 | mr = 0161805
 | pages = 498–504
 | title = The number of partitions of a set
 | volume = 71
 | year = 1964
 | ref = harv}}
*{{cite journal
 | last = Spivey | first = Michael Z.
 | issue = 2
 | journal = Journal of Integer Sequences
 | mr = 2420912
 | page = Article 08.2.5, 3
 | title = A generalized recurrence for Bell numbers
 | url = http://www.cs.uwaterloo.ca/journals/JIS/VOL11/Spivey/spivey25.pdf
 | volume = 11
 | year = 2008
 | ref = harv}}
*{{cite journal
 | last = Wagstaff | first = Samuel S. | author-link = Sam Wagstaff
 | bibcode = 1996MaCom..65..383W
 | doi = 10.1090/S0025-5718-96-00683-7
 | issue = 213
 | journal = [[Mathematics of Computation]]
 | mr = 1325876
 | pages = 383–391
 | title = Aurifeuillian factorizations and the period of the Bell numbers modulo a prime
 | url = http://homes.cerias.purdue.edu/~ssw/bell/bell.ps
 | volume = 65
 | year = 1996
 | ref = harv}}
* {{cite book | last=Wilf | first=Herbert S. | authorlink=Herbert Wilf | title=Generatingfunctionology | edition=2nd | location=Boston, MA | publisher=Academic Press | year=1994 | isbn=0-12-751956-4 | zbl=0831.05001 |ref=harv | url = https://www.math.upenn.edu/~wilf/gfology2.pdf
}}
*{{cite journal
 | last = Williams | first = G. T.
 | journal = [[American Mathematical Monthly]]
 | jstor = 2305292
 | doi = 10.2307/2305292
 | mr = 0012612
 | pages = 323–327
 | title = Numbers generated by the function ''e''&lt;sup&gt;''e''&lt;sup&gt;''x''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1&lt;/sup&gt;
  | volume = 52
 | year = 1945
 | ref = harv}}
{{refend}}

==External links==
* {{Cite web
|author=Robert Dickau
|url=http://mathforum.org/advanced/robertd/bell.html
|title=Diagrams of Bell numbers
}}
* {{MathWorld|urlname=BellNumber|title=Bell Number
}}
* {{Cite web
|author=Gottfried Helms
|url=http://go.helms-net.de/math/binomial/04_5_SummingBellStirling.pdf
|title=Further properties &amp; Generalization of Bell-Numbers
}}

{{Classes of natural numbers}}

{{DEFAULTSORT:Bell Number}}
[[Category:Integer sequences]]</text>
      <sha1>313p4qr58sc2tzftyayuwvzisrflgxv</sha1>
    </revision>
  </page>
  <page>
    <title>Bernoulli polynomials</title>
    <ns>0</ns>
    <id>228161</id>
    <revision>
      <id>862795375</id>
      <parentid>862708297</parentid>
      <timestamp>2018-10-06T18:51:48Z</timestamp>
      <contributor>
        <ip>185.61.186.146</ip>
      </contributor>
      <comment>Undid revision 862526690 by [[Special:Contributions/Deacon Vorbis|Deacon Vorbis]] ([[User talk:Deacon Vorbis|talk]]) The page in question has been created</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15097">In [[mathematics]], the '''Bernoulli polynomials''', named after [[Jacob Bernoulli]], occur in the study of many [[special functions]] and, in particular the [[Riemann zeta function]] and the [[Hurwitz zeta function]].  This is in large part because they are an [[Appell sequence]] (i.e. a [[Sheffer sequence]] for the ordinary [[derivative]] operator). Unlike [[orthogonal polynomials]], the Bernoulli polynomials are remarkable in that the number of crossings of the ''x''-axis in the [[unit interval]] does not go up as the degree of the polynomials goes up. In the limit of large degree, the Bernoulli polynomials, appropriately scaled, approach the [[trigonometric function|sine and cosine functions]].
[[Image:Bernoulli polynomials.svg|thumb|right|Bernoulli polynomials]]

A similar set of polynomials, based on a similar generating function, is the family of '''Euler polynomials'''.

==Representations==

The Bernoulli polynomials ''B''&lt;sub&gt;''n''&lt;/sub&gt; admit a variety of different [[representation (mathematics)|representations]].  Which among them should be taken to be the definition may depend on one's purposes.

===Explicit formula===

:&lt;math&gt;B_n(x) = \sum_{k=0}^n {n \choose k} b_{n-k} x^k,&lt;/math&gt;

for ''n'' ≥ 0, where ''b''&lt;sub&gt;''k''&lt;/sub&gt; are the [[Bernoulli number]]s.

===Generating functions===
The [[generating function]] for the Bernoulli polynomials is

:&lt;math&gt;\frac{t e^{xt}}{e^t-1}= \sum_{n=0}^\infty B_n(x) \frac{t^n}{n!}.&lt;/math&gt;

The generating function for the Euler polynomials is
:&lt;math&gt;\frac{2 e^{xt}}{e^t+1}= \sum_{n=0}^\infty E_n(x) \frac{t^n}{n!}.&lt;/math&gt;

===Representation by a differential operator===

The Bernoulli polynomials are also given by

:&lt;math&gt;B_n(x)={D \over e^D -1} x^n&lt;/math&gt;

where ''D'' = ''d''/''dx'' is differentiation with respect to ''x'' and the fraction is expanded as a [[formal power series]]. It follows that 
:&lt;math&gt;\int _a^x  B_n (u) ~du = \frac{B_{n+1}(x) - B_{n+1}(a)}{n+1}   ~.&lt;/math&gt;
cf. [[#Integrals|integrals below]].

===Representation by an integral operator===

The Bernoulli polynomials are the unique polynomials determined by

:&lt;math&gt;\int_x^{x+1} B_n(u)\,du = x^n.&lt;/math&gt;

The [[integral transform]]

:&lt;math&gt;(Tf)(x) = \int_x^{x+1} f(u)\,du&lt;/math&gt;

on polynomials ''f'', simply amounts to 
:&lt;math&gt;
\begin{align}
(Tf)(x) = {e^D - 1 \over D}f(x) &amp; {} = \sum_{n=0}^\infty {D^n \over (n+1)!}f(x) \\
&amp; {} = f(x) + {f'(x) \over 2} + {f''(x) \over 6} + {f'''(x) \over 24} + \cdots  ~.
\end{align}
&lt;/math&gt;
This can be used to produce the [[#Inversion|inversion formulae below]].

==Another explicit formula==

An explicit formula for the Bernoulli polynomials is given by

:&lt;math&gt;B_m(x)=
\sum_{n=0}^m \frac{1}{n+1}
\sum_{k=0}^n (-1)^k {n \choose k} (x+k)^m.&lt;/math&gt;

Note the remarkable similarity to the globally convergent series expression for the [[Hurwitz zeta function]]. Indeed, one has

:&lt;math&gt;B_n(x) = -n \zeta(1-n,x)&lt;/math&gt;

where ''ζ''(''s'',&amp;nbsp;''q'') is the Hurwitz zeta; thus, in a certain sense, the Hurwitz zeta generalizes the Bernoulli polynomials to non-integer values of&amp;nbsp;''n''.

The inner sum may be understood to be the ''n''th [[forward difference]] of ''x''&lt;sup&gt;''m''&lt;/sup&gt;; that is,

:&lt;math&gt;\Delta^n x^m = \sum_{k=0}^n (-1)^{n-k} {n \choose k} (x+k)^m&lt;/math&gt;

where Δ is the [[forward difference operator]]. Thus, one may write

:&lt;math&gt;B_m(x)= \sum_{n=0}^m \frac{(-1)^n}{n+1} \Delta^n x^m. &lt;/math&gt;

This formula may be derived from an identity appearing above as follows. Since the forward difference operator Δ equals
:&lt;math&gt;\Delta = e^D - 1&lt;/math&gt;
where ''D'' is differentiation with respect to ''x'', we have, from the [[Mercator series]]

:&lt;math&gt;{D \over e^D - 1} = {\log(\Delta + 1) \over \Delta} = \sum_{n=0}^\infty {(-\Delta)^n \over n+1}.&lt;/math&gt;

As long as this operates on an ''m''th-degree polynomial such as ''x''&lt;sup&gt;''m''&lt;/sup&gt;, one may let ''n'' go from 0 only up to&amp;nbsp;''m''.

An integral representation for the Bernoulli polynomials is given by the [[Nörlund&amp;ndash;Rice integral]], which follows from the expression as a finite difference.

An explicit formula for the Euler polynomials is given by

:&lt;math&gt;E_m(x)=
\sum_{n=0}^m \frac{1}{2^n}
\sum_{k=0}^n (-1)^k {n \choose k} (x+k)^m\,.&lt;/math&gt;

This may also be written in terms of the [[Euler number]]s ''E''&lt;sub&gt;''k''&lt;/sub&gt; as

:&lt;math&gt;E_m(x)=
\sum_{k=0}^m {m \choose k} \frac{E_k}{2^k}
\left(x-\frac{1}{2}\right)^{m-k} \,.&lt;/math&gt;

==Sums of ''p''th powers==

We have

:&lt;math&gt;\sum_{k=0}^x k^p = \frac{B_{p+1}(x+1)-B_{p+1}(0)}{p+1}&lt;/math&gt;

(assuming 0&lt;sup&gt;0&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;1). See [[Faulhaber's formula]] for more on this.

==The Bernoulli and Euler numbers==
The [[Bernoulli number]]s are given by &lt;math&gt;\textstyle B_n=B_n(0).&lt;/math&gt;

This definition gives &lt;math&gt;\textstyle \zeta(-n) = -\frac{1}{n+1}B_{n+1} &lt;/math&gt; for &lt;math&gt;\textstyle n=0, 1, 2, \ldots&lt;/math&gt;.

An alternate convention defines the Bernoulli numbers as &lt;math&gt;\textstyle B_n=B_n(1).&lt;/math&gt;

The two conventions differ only for &lt;math&gt;n=1&lt;/math&gt; since &lt;math&gt;B_1(1)= \tfrac{1}{2} = -B_1(0)&lt;/math&gt;.

The [[Euler number]]s are given by &lt;math&gt;E_n=2^nE_n(\tfrac{1}{2}).&lt;/math&gt;

==Explicit expressions for low degrees==
The first few Bernoulli polynomials are:

: &lt;math&gt;
\begin{align}
B_0(x) &amp; =1 \\[8pt]
B_1(x) &amp; =x-\frac{1}{2} \\[8pt]
B_2(x) &amp; =x^2-x+\frac{1}{6} \\[8pt]
B_3(x) &amp; =x^3-\frac{3}{2}x^2+\frac{1}{2}x \\[8pt]
B_4(x) &amp; =x^4-2x^3+x^2-\frac{1}{30} \\[8pt]
B_5(x) &amp; =x^5-\frac{5}{2}x^4+\frac{5}{3}x^3-\frac{1}{6}x \\[8pt]
B_6(x) &amp; =x^6-3x^5+\frac{5}{2}x^4-\frac{1}{2}x^2+\frac{1}{42}.
\end{align}
&lt;/math&gt;

The first few Euler polynomials are:

: &lt;math&gt;
\begin{align}
E_0(x) &amp; =1 \\[8pt]
E_1(x) &amp; =x-\frac{1}{2} \\[8pt]
E_2(x) &amp; =x^2-x \\[8pt]
E_3(x) &amp; =x^3-\frac{3}{2}x^2+\frac{1}{4} \\[8pt]
E_4(x) &amp; =x^4-2x^3+x \\[8pt]
E_5(x) &amp; =x^5-\frac{5}{2}x^4+\frac{5}{2}x^2-\frac{1}{2} \\[8pt]
E_6(x) &amp; =x^6-3x^5+5x^3-3x.
\end{align}
&lt;/math&gt;

==Maximum and minimum==

At higher ''n'', the amount of variation in ''B''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') between ''x''&amp;nbsp;=&amp;nbsp;0 and ''x''&amp;nbsp;=&amp;nbsp;1 gets large. For instance,

:&lt;math&gt;B_{16}(x)=x^{16}-8x^{15}+20x^{14}-\frac{182}{3}x^{12}+\frac{572}{3}x^{10}-429x^8+\frac{1820}{3}x^6
-\frac{1382}{3}x^4+140x^2-\frac{3617}{510}&lt;/math&gt;

which shows that the value at ''x''&amp;nbsp;=&amp;nbsp;0 (and at ''x''&amp;nbsp;=&amp;nbsp;1) is −3617/510 ≈&amp;nbsp;−7.09, while at ''x''&amp;nbsp;=&amp;nbsp;1/2, the value is 118518239/3342336 ≈&amp;nbsp;+7.09. [[D.H. Lehmer]]&lt;ref&gt;D.H. Lehmer, "On the Maxima and Minima of Bernoulli Polynomials", ''[[American Mathematical Monthly]]'', volume 47, pages 533–538 (1940)&lt;/ref&gt; showed that the maximum value of ''B''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') between 0 and 1 obeys

:&lt;math&gt;M_n &lt; \frac{2n!}{(2\pi)^n}&lt;/math&gt;

unless ''n'' is 2 modulo 4, in which case

:&lt;math&gt;M_n = \frac{2\zeta(n)n!}{(2\pi)^n}&lt;/math&gt;

(where &lt;math&gt;\zeta(x)&lt;/math&gt; is the [[Riemann zeta function]]), while the minimum obeys

:&lt;math&gt;m_n &gt; \frac{-2n!}{(2\pi)^n}&lt;/math&gt;

unless ''n'' is 0 modulo 4, in which case

:&lt;math&gt;m_n = \frac{-2\zeta(n)n!}{(2\pi)^n}.&lt;/math&gt;

These limits are quite close to the actual maximum and minimum, and Lehmer gives more accurate limits as well.

==Differences and derivatives==

The Bernoulli and Euler polynomials obey many relations from [[umbral calculus]]:

:&lt;math&gt;\Delta B_n(x) = B_n(x+1)-B_n(x)=nx^{n-1},&lt;/math&gt;

:&lt;math&gt;\Delta E_n(x) = E_n(x+1)-E_n(x)=2(x^n-E_n(x)).&lt;/math&gt;

(Δ is the [[forward difference operator]]).

These [[polynomial sequence]]s are [[Appell sequence]]s:

:&lt;math&gt;B_n'(x)=nB_{n-1}(x),&lt;/math&gt;

:&lt;math&gt;E_n'(x)=nE_{n-1}(x).&lt;/math&gt;

===Translations===

:&lt;math&gt;B_n(x+y)=\sum_{k=0}^n {n \choose k} B_k(x) y^{n-k}&lt;/math&gt;

:&lt;math&gt;E_n(x+y)=\sum_{k=0}^n {n \choose k} E_k(x) y^{n-k}&lt;/math&gt;

These identities are also equivalent to saying that these polynomial sequences are [[Appell sequence]]s.  ([[Hermite polynomials]] are another example.)

===Symmetries===

:&lt;math&gt;B_n(1-x)=(-1)^nB_n(x),\quad n \ge 0,&lt;/math&gt;

:&lt;math&gt;E_n(1-x)=(-1)^n E_n(x)&lt;/math&gt;

:&lt;math&gt;(-1)^n B_n(-x) = B_n(x) + nx^{n-1}&lt;/math&gt;

:&lt;math&gt;(-1)^n E_n(-x) = -E_n(x) + 2x^n&lt;/math&gt;

:&lt;math&gt;B_n\left(\frac{1}{2}\right) = \left(\frac{1}{2^{n-1}}-1\right) B_n, \quad n \geq 0\text{ from the multiplication theorems below.} &lt;/math&gt;

[[Zhi-Wei Sun]] and Hao Pan &lt;ref&gt;{{cite journal |author1=Zhi-Wei Sun |author2=Hao Pan |journal=Acta Arithmetica |volume=125 |year=2006 |pages=21–39 |title=Identities concerning Bernoulli and Euler polynomials  |arxiv=math/0409035 |doi=10.4064/aa125-1-3|bibcode=2006AcAri.125...21S }}&lt;/ref&gt; established the following surprising symmetry relation: If {{math| ''r'' + ''s'' + ''t'' {{=}} ''n''}} and {{math| ''x'' + ''y'' + ''z'' {{=}} 1}}, then

:&lt;math&gt;r[s,t;x,y]_n+s[t,r;y,z]_n+t[r,s;z,x]_n=0,&lt;/math&gt;

where

:&lt;math&gt;[s,t;x,y]_n=\sum_{k=0}^n(-1)^k{s \choose k}{t\choose {n-k}}
B_{n-k}(x)B_k(y).&lt;/math&gt;

==Fourier series==

The [[Fourier series]] of the Bernoulli polynomials is also a [[Dirichlet series]], given by the expansion

:&lt;math&gt;B_n(x) = -\frac{n!}{(2\pi i)^n}\sum_{k\not=0 }\frac{e^{2\pi ikx}}{k^n}= -2 n! \sum_{k=1}^{\infty} \frac{\cos\left(2 k \pi x- \frac{n \pi} 2 \right)}{(2 k \pi)^n}.&lt;/math&gt;
Note the simple large ''n'' limit to suitably scaled trigonometric functions.

This is a special case of the analogous form for the [[Hurwitz zeta function]]

:&lt;math&gt;B_n(x) = -\Gamma(n+1) \sum_{k=1}^\infty
\frac{ \exp (2\pi ikx) + e^{i\pi n} \exp (2\pi ik(1-x)) } { (2\pi ik)^n }. &lt;/math&gt;

This expansion is valid only for 0&amp;nbsp;≤&amp;nbsp;''x''&amp;nbsp;≤&amp;nbsp;1 when ''n''&amp;nbsp;≥&amp;nbsp;2 and is valid for 0&amp;nbsp;&lt;&amp;nbsp;''x''&amp;nbsp;&lt;&amp;nbsp;1 when ''n''&amp;nbsp;=&amp;nbsp;1.

The Fourier series of the Euler polynomials may also be calculated.  Defining the functions

:&lt;math&gt;C_\nu(x) = \sum_{k=0}^\infty
\frac {\cos((2k+1)\pi x)} {(2k+1)^\nu}&lt;/math&gt;

and

:&lt;math&gt;S_\nu(x) = \sum_{k=0}^\infty
\frac {\sin((2k+1)\pi x)} {(2k+1)^\nu}&lt;/math&gt;

for &lt;math&gt;\nu &gt; 1&lt;/math&gt;, the Euler polynomial has the Fourier series

:&lt;math&gt;C_{2n}(x) = \frac{(-1)^n}{4(2n-1)!}
\pi^{2n} E_{2n-1} (x)&lt;/math&gt;

and

:&lt;math&gt;S_{2n+1}(x) = \frac{(-1)^n}{4(2n)!}
\pi^{2n+1} E_{2n} (x).&lt;/math&gt;

Note that the &lt;math&gt;C_\nu&lt;/math&gt; and &lt;math&gt;S_\nu&lt;/math&gt; are odd and even, respectively:

:&lt;math&gt;C_\nu(x) = -C_\nu(1-x)&lt;/math&gt;

and

:&lt;math&gt;S_\nu(x) = S_\nu(1-x).&lt;/math&gt;

They are related to the [[Legendre chi function]] &lt;math&gt;\chi_\nu&lt;/math&gt; as

:&lt;math&gt;C_\nu(x) = \mbox{Re} \chi_\nu (e^{ix})&lt;/math&gt;

and

:&lt;math&gt;S_\nu(x) = \mbox{Im} \chi_\nu (e^{ix}).&lt;/math&gt;

==Inversion==
The Bernoulli and Euler polynomials may be inverted to express the [[monomial]] in terms of the polynomials.

Specifically, evidently from the above section on [[#Representation by an integral operator]], it follows that  
:&lt;math&gt;x^n = \frac {1}{n+1}
\sum_{k=0}^n {n+1 \choose k} B_k (x)
&lt;/math&gt;

and

:&lt;math&gt;x^n = E_n (x) + \frac {1}{2}
\sum_{k=0}^{n-1} {n \choose k} E_k (x).
&lt;/math&gt;

==Relation to falling factorial==
The Bernoulli polynomials may be expanded in terms of the [[falling factorial]] &lt;math&gt;(x)_k&lt;/math&gt; as

:&lt;math&gt;B_{n+1}(x) =  B_{n+1} + \sum_{k=0}^n
\frac{n+1}{k+1}
\left\{ \begin{matrix} n \\ k \end{matrix} \right\}
(x)_{k+1} &lt;/math&gt;
where &lt;math&gt;B_n=B_n(0)&lt;/math&gt; and

:&lt;math&gt;\left\{ \begin{matrix} n \\ k \end{matrix} \right\} = S(n,k)&lt;/math&gt;

denotes the [[Stirling number of the second kind]]. The above may be inverted to express the falling factorial in terms of the Bernoulli polynomials:

:&lt;math&gt;(x)_{n+1} = \sum_{k=0}^n
\frac{n+1}{k+1}
\left[ \begin{matrix} n \\ k \end{matrix} \right]
\left(B_{k+1}(x) - B_{k+1} \right) &lt;/math&gt;

where
:&lt;math&gt;\left[ \begin{matrix} n \\ k \end{matrix} \right] = s(n,k)&lt;/math&gt;

denotes the [[Stirling number of the first kind]].

==Multiplication theorems==
The [[multiplication theorem]]s were given by [[Joseph Ludwig Raabe]] in 1851:

For a natural number {{math|''m''&amp;ge;1}},

:&lt;math&gt;B_n(mx)= m^{n-1} \sum_{k=0}^{m-1} B_n \left(x+\frac{k}{m}\right)&lt;/math&gt;

:&lt;math&gt;E_n(mx)= m^n \sum_{k=0}^{m-1}
(-1)^k E_n \left(x+\frac{k}{m}\right)
\quad \mbox{ for } m=1,3,\dots&lt;/math&gt;

:&lt;math&gt;E_n(mx)= \frac{-2}{n+1} m^n \sum_{k=0}^{m-1}
(-1)^k B_{n+1} \left(x+\frac{k}{m}\right)
\quad \mbox{ for } m=2,4,\dots&lt;/math&gt;

==Integrals==
Indefinite integrals
:&lt;math&gt;\int_a^x B_n(t)\,dt =
\frac{B_{n+1}(x)-B_{n+1}(a)}{n+1}&lt;/math&gt;

:&lt;math&gt;\int_a^x E_n(t)\,dt =
\frac{E_{n+1}(x)-E_{n+1}(a)}{n+1}&lt;/math&gt;

Definite integrals
:&lt;math&gt;\int_0^1 B_n(t) B_m(t)\,dt =
(-1)^{n-1} \frac{m! n!}{(m+n)!} B_{n+m}
\quad \mbox { for } m,n \ge 1 &lt;/math&gt;

:&lt;math&gt;\int_0^1 E_n(t) E_m(t)\,dt =
(-1)^{n} 4 (2^{m+n+2}-1)\frac{m! n!}{(m+n+2)!} B_{n+m+2}&lt;/math&gt;

==Periodic Bernoulli polynomials==
A '''periodic Bernoulli polynomial''' {{math|''P''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')}} is a Bernoulli polynomial evaluated at the [[fractional part]] of the argument {{math|''x''}}.  These functions are used to provide the [[remainder term]] in the [[Euler–Maclaurin formula]] relating sums to integrals.  The first polynomial is a [[Sawtooth wave|sawtooth function]].

Strictly these functions are not polynomials at all and more properly should be termed the periodic Bernoulli functions.

The following properties are of interest, valid for all &lt;math&gt; x &lt;/math&gt;:

:&lt;math&gt;
\begin{align}
&amp;P_k(x) \text{ is continuous for all } k \neq 1 \\
&amp;P_k'(x) \text{ exists and is continuous for } k=0, k \geq 3 \\
&amp;P'_k(x) = kP_{k-1}(x), k \geq 3
\end{align}
&lt;/math&gt;

==See also==
* [[Bernoulli numbers]]
* [[Bernoulli polynomials of the second kind]]
* [[Stirling polynomial]]

==References==
&lt;references /&gt;
* Milton Abramowitz and Irene A. Stegun, eds. ''[[Abramowitz and Stegun|Handbook of Mathematical Functions]] with Formulas, Graphs, and Mathematical Tables'', (1972) Dover, New York. ''(See  [http://www.math.sfu.ca/~cbm/aands/page_804.htm Chapter 23])''
* {{Apostol IANT}} ''(See chapter 12.11)''
*{{dlmf|first=K. |last=Dilcher|id=24|title=Bernoulli and Euler Polynomials}}
* {{Cite journal | last1 = Cvijović | first1 = Djurdje | last2 = Klinowski | first2 = Jacek | year = 1995 | title = New formulae for the Bernoulli and Euler polynomials at rational arguments | url = | journal = Proceedings of the American Mathematical Society | volume = 123 | issue = | pages = 1527–1535 | doi=10.2307/2161144}}
* {{Cite journal | doi = 10.1007/s11139-007-9102-0 | last1 = Guillera | first1 = Jesus | last2 = Sondow | first2 = Jonathan | year = 2008 | title = Double integrals and infinite products for some classical constants via analytic continuations of Lerch's transcendent | arxiv = math.NT/0506319 | journal = The Ramanujan Journal | volume = 16 | issue = 3| pages = 247–270 }} ''(Reviews relationship to the Hurwitz zeta function and Lerch transcendent.)''
* {{cite book | author=Hugh L. Montgomery | authorlink=Hugh Montgomery (mathematician) |author2=Robert C. Vaughan |authorlink2=Robert Charles Vaughan (mathematician)  | title=Multiplicative number theory I. Classical theory | series=Cambridge tracts in advanced mathematics | volume=97 | year=2007 | isbn=0-521-84903-9 | pages=495–519 | publisher=Cambridge Univ. Press | location=Cambridge }}

{{authority control}}
[[Category:Special functions]]
[[Category:Number theory]]
[[Category:Polynomials]]</text>
      <sha1>3vuhgpapv6anstwb19n47aezbhlia5y</sha1>
    </revision>
  </page>
  <page>
    <title>Boolean-valued model</title>
    <ns>0</ns>
    <id>2732301</id>
    <revision>
      <id>826842128</id>
      <parentid>782969282</parentid>
      <timestamp>2018-02-21T08:39:15Z</timestamp>
      <contributor>
        <username>Trovatore</username>
        <id>310173</id>
      </contributor>
      <comment>{{short description}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16859">{{short description|set theory concept}}
In [[mathematical logic]], a '''Boolean-valued model''' is a generalization of the ordinary [[Alfred Tarski|Tarskian]] notion of [[structure (mathematical logic)|structure]] from [[model theory]]. In a Boolean-valued model, the [[truth value]]s of [[proposition]]s are not limited to "true" and "false", but instead take values in some fixed [[complete Boolean algebra]].

Boolean-valued models were introduced by [[Dana Scott]], [[Robert M. Solovay]], and [[Petr Vopěnka]] in the 1960s in order to help understand [[Paul Cohen (mathematician)|Paul Cohen]]'s method of [[forcing (mathematics)|forcing]]. They are also related to [[Heyting algebra]] semantics in [[intuitionistic logic]].

==Definition==

Fix a complete Boolean algebra ''B''&lt;ref name="trivial_ba"&gt;''B'' here is assumed to be ''nondegenerate''; that is, 0 and 1 must be distinct elements of ''B''. Authors writing on Boolean-valued models typically take this requirement to be part of the definition of "Boolean algebra", but authors writing on Boolean algebras in general often do not.&lt;/ref&gt; and a [[first-order language]] ''L''; the [[signature (mathematical logic)|signature]] of ''L'' will consist of a collection of constant symbols, function symbols, and relation symbols.

A Boolean-valued model for the language ''L'' consists of a universe ''M'', which is a set of elements (or '''''names'''''), together with interpretations for the symbols. Specifically, the model must assign to each constant symbol of ''L'' an element of ''M'', and to each ''n''-ary function symbol ''f'' of ''L'' and each ''n''-tuple &amp;lt;a&lt;sub&gt;0&lt;/sub&gt;,...,a&lt;sub&gt;''n''-1&lt;/sub&gt;&amp;gt; of elements of ''M'', the model must assign an element of ''M'' to the term ''f''(a&lt;sub&gt;0&lt;/sub&gt;,...,a&lt;sub&gt;''n''-1&lt;/sub&gt;).

Interpretation of the [[atomic formula]]s of ''L'' is more complicated. To each pair ''a'' and ''b'' of elements of ''M'', the model must assign a truth value ||''a''=''b''|| to the expression ''a''=''b''; this truth value is taken from the Boolean algebra ''B''. Similarly, for each ''n''-ary relation symbol ''R'' of ''L'' and each ''n''-tuple &amp;lt;a&lt;sub&gt;0&lt;/sub&gt;,...,a&lt;sub&gt;''n''-1&lt;/sub&gt;&amp;gt; of elements of ''M'', the model must assign an element of ''B'' to be the truth value ||''R''(a&lt;sub&gt;0&lt;/sub&gt;,...,a&lt;sub&gt;''n''-1&lt;/sub&gt;)||.

==Interpretation of other formulas and sentences==

The truth values of the atomic formulas can be used to reconstruct the truth values of more complicated formulas, using the structure of the Boolean algebra. For propositional connectives, this is easy; one simply applies the corresponding Boolean operators to the truth values of the subformulae. For example, if φ(''x'') and ψ(''y'',''z'') are formulas with one and two [[free variable]]s, respectively, and if ''a'', ''b'', ''c'' are elements of the model's universe to be substituted for ''x'', ''y'', and ''z'', then the truth value of
: &lt;math&gt;\phi(a)\land\psi(b,c)&lt;/math&gt;
is simply
: &lt;math&gt;\|\phi(a)\land\psi(b,c)\|=\|\phi(a)\|\ \land\ \|\psi(b,c)\| &lt;/math&gt;

The completeness of the Boolean algebra is required to define truth values for quantified formulas. If φ(''x'') is a formula with free variable ''x'' (and possibly other free variables that are suppressed), then
: &lt;math&gt;\|\exists x\phi(x)\|=\bigvee_{a\in M}\|\phi(a)\|,&lt;/math&gt;
where the right-hand side is to be understood as the [[supremum]] in ''B'' of the set of all truth values ||φ(''a'')|| as ''a'' ranges over ''M''.

The truth value of a formula is sometimes referred to as its [[probability]]. However, these are not probabilities in the ordinary sense, because they are not [[real number]]s, but rather elements of the complete Boolean algebra ''B''.

==Boolean-valued models of set theory==
Given a complete Boolean algebra ''B''&lt;ref name="trivial_ba"/&gt; there is a Boolean-valued model denoted by ''V&lt;sup&gt;B&lt;/sup&gt;'', which is the Boolean-valued analogue of the [[von Neumann universe]] ''V''. (Strictly speaking, ''V&lt;sup&gt;B&lt;/sup&gt;'' is a [[proper class]], so we need to reinterpret what it means to be a [[model theory|model]] appropriately.) Informally, the elements of ''V&lt;sup&gt;B&lt;/sup&gt;'' are "Boolean-valued sets". Given an ordinary set ''A'', every set either is or is not a member; but given a Boolean-valued set, every set has a certain, fixed "probability" of being a member of ''A''. Again, the "probability" is an element of ''B'', not a real number. The concept of Boolean-valued sets resembles, but is not the same as, the notion of a [[fuzzy set]].

The ("probabilistic") elements of the Boolean-valued set, in turn, are also Boolean-valued sets, whose elements are also Boolean-valued sets, and so on. In order to obtain a non-circular definition of Boolean-valued set, they are defined inductively in a hierarchy similar to the [[cumulative hierarchy]]. For each ordinal α of ''V'', the set ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;'' is defined as follows. 
* ''V''&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;0&lt;/sub&gt; is the empty set. 
*''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α+1&lt;/sub&gt;'' is the set of all functions from ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;'' to ''B''. (Such a function represents a "probabilistic" [[subset]] of ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;''; if ''f'' is such a function, then for any ''x''∈''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;'', ''f''(''x'') is the probability that ''x'' is in the set.)
* If α is a limit ordinal, ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;'' is the union of ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;β&lt;/sub&gt;'' for β&amp;lt;α 
The class ''V&lt;sup&gt;B&lt;/sup&gt;'' is defined to be the union of all sets ''V&lt;sup&gt;B&lt;/sup&gt;&lt;sub&gt;α&lt;/sub&gt;''.

It is also possible to relativize this entire construction to some transitive model ''M'' of [[Zermelo-Fraenkel set theory|ZF]] (or sometimes a fragment thereof). The Boolean-valued model ''M''&lt;sup&gt;''B''&lt;/sup&gt; is obtained by applying the above construction ''inside'' ''M''. The restriction to transitive models is not serious, as the [[Mostowski collapse|Mostowski collapsing theorem]] implies that every "reasonable" (well-founded, extensional) model is isomorphic to a transitive one. (If the model ''M'' is not transitive things get messier, as ''M'''s interpretation of what it means to be a "function" or an "ordinal" may differ from  the "external" interpretation.)

Once the elements of ''V''&lt;sup&gt;B&lt;/sup&gt; have been defined as above, it is necessary to define ''B''-valued  relations of equality and membership on ''V&lt;sup&gt;B&lt;/sup&gt;''. Here a ''B''-valued relation on ''V&lt;sup&gt;B&lt;/sup&gt;'' is a function from ''V&lt;sup&gt;B&lt;/sup&gt;''&amp;times;''V&lt;sup&gt;B&lt;/sup&gt;'' to ''B''. To avoid confusion with the usual equality and membership, these are denoted by ||''x''=''y''|| and ||''x''∈''y''||  for ''x'' and ''y'' in ''V&lt;sup&gt;B&lt;/sup&gt;''. They are defined as follows:
:||''x''∈''y''|| is defined to be ∑&lt;sub&gt;''t''∈Dom(''y'')&lt;/sub&gt; ||''x''=''t''|| ∧ ''y''(''t'')   ("''x'' is in ''y'' if it is equal to something in ''y''").
:||''x''=''y''|| is defined to be ||''x''⊆''y''||∧||y⊆''x''||   ("''x'' equals ''y'' if ''x'' and ''y'' are both subsets of each other"), where
:||''x''⊆''y''|| is defined to be ∏&lt;sub&gt;''t''∈Dom(''x'')&lt;/sub&gt; ''x''(''t'')⇒||''t''∈''y''||   ("''x'' is a subset of ''y'' if all elements of ''x'' are in ''y''")

The symbols ∑ and ∏ denote the least upper bound and greatest lower bound operations, respectively, in the complete Boolean algebra ''B''. At first sight the definitions above appear to be circular: ||&amp;nbsp; ∈&amp;nbsp;|| depends on ||&amp;nbsp;=&amp;nbsp;||, which depends on ||&amp;nbsp;⊆&amp;nbsp;||, which depends on ||&amp;nbsp;∈&amp;nbsp;||. However, a close examination shows that the definition of ||&amp;nbsp;∈&amp;nbsp;|| only depends on ||&amp;nbsp;∈&amp;nbsp;|| for elements of smaller rank, so ||&amp;nbsp;∈&amp;nbsp;|| and ||&amp;nbsp; =&amp;nbsp;|| are well defined functions from ''V&lt;sup&gt;B&lt;/sup&gt;''&amp;times;''V&lt;sup&gt;B&lt;/sup&gt;'' to ''B''.

It can be shown that the ''B''-valued  relations ||&amp;nbsp;∈&amp;nbsp;|| and ||&amp;nbsp;=&amp;nbsp;|| on ''V&lt;sup&gt;B&lt;/sup&gt;'' make ''V&lt;sup&gt;B&lt;/sup&gt;'' into a Boolean-valued model of set theory. Each sentence of first order set theory with no free variables has a truth value in ''B''; it must be shown that the axioms for equality and all the axioms of ZF set theory (written without free variables) have truth value 1 (the largest element of ''B''). This proof is straightforward, but it is long because there are many different axioms that need to be checked.

==Relationship to forcing==
Set theorists use a technique called [[forcing (mathematics)|forcing]]
to obtain [[independence (mathematical logic)|independence results]] and to construct models of set theory for other purposes. The method was originally developed by [[Paul Cohen (mathematician)|Paul Cohen]] but has been greatly extended since then. In one form, forcing "adds to the universe" a [[generic filter|generic]] subset of a [[poset]], the poset being designed to impose interesting properties on the newly added object. The wrinkle is that (for interesting posets) it can be proved that there simply ''is'' no such generic subset of the poset. There are three usual ways of dealing with this:
* '''syntactic forcing''' A ''forcing relation'' &lt;math&gt; p\Vdash\phi&lt;/math&gt; is defined between elements ''p'' of the poset and formulas φ of the ''forcing language''. This relation is defined syntactically and has no semantics; that is, no model is ever produced. Rather, starting with the assumption that ZFC (or some other axiomatization of set theory) proves the independent statement, one shows that ZFC must also be able to prove a contradiction. However, the forcing is "over ''V''"; that is, it is not necessary to start with a countable transitive model. See Kunen (1980) for an exposition of this method. 
* '''countable transitive models''' One starts with a [[countable set|countable]] [[transitive set|transitive]] model ''M'' of as much of set theory as is needed for the desired purpose, and that contains the poset. Then there ''do'' exist filters on the poset that are generic ''over M''; that is, that meet all dense open subsets of the poset that happen also to be elements of ''M''. 
* '''fictional generic objects''' Commonly, set theorists will simply ''pretend'' that the poset has a subset that is generic over all of ''V''. This generic object, in nontrivial cases, cannot be an element of ''V'', and therefore "does not really exist". (Of course, it is a point of philosophical contention whether ''any'' sets "really exist", but that is outside the scope of the current discussion.) Perhaps surprisingly, with a little practice this method is useful and reliable, but it can be philosophically unsatisfying.

===Boolean-valued models and syntactic forcing===
Boolean-valued models can be used to give semantics to syntactic forcing; the price paid is that the semantics is not 2-valued ("true or false"), but assigns truth values from some complete Boolean algebra. Given a forcing poset ''P'', there is a corresponding complete Boolean algebra ''B'', often obtained as the collection of [[regular open set|regular open subsets]] of ''P'', where the [[topology]] on ''P'' is defined by declaring all [[lower set]]s open (and all [[upper set]]s closed). (Other approaches to constructing ''B'' are discussed below.)

Now the order on ''B'' (after removing the zero element) can replace ''P'' for forcing purposes, and the forcing relation can be interpreted semantically by saying that, for ''p'' an element of ''B'' and φ a formula of the forcing language,
:&lt;math&gt;p\Vdash\phi\iff p\leq||\phi||&lt;/math&gt;
where ||φ|| is the truth value of φ in ''V''&lt;sup&gt;''B''&lt;/sup&gt;.

This approach succeeds in assigning a semantics to forcing over ''V'' without resorting to fictional generic objects. The disadvantages are that the semantics is not 2-valued, and that the combinatorics of ''B'' are often more complicated than those of the underlying poset ''P''.

===Boolean-valued models and generic objects over countable transitive models===
One interpretation of forcing starts with a countable transitive model ''M'' of ZF set theory, a partially ordered set ''P'', and a "generic" subset ''G'' of ''P'', and constructs a new model of ZF set theory from these objects. (The conditions that the model be countable and transitive simplify some technical problems, but are not essential.) Cohen's construction can be carried out using Boolean-valued models as follows. 
* Construct a complete Boolean algebra ''B'' as the complete Boolean algebra "generated by" the poset ''P''. 
* Construct an ultrafilter ''U'' on ''B'' (or equivalently a homomorphism from ''B'' to the Boolean algebra {true, false}) from the generic subset ''G'' of ''P''.
* Use the homomorphism  from ''B'' to {true, false} to turn the Boolean-valued model ''M&lt;sup&gt;B&lt;/sup&gt;'' of the section above into an ordinary model of ZF.

We now explain these steps in more detail.

For any poset ''P'' there is a complete Boolean algebra ''B'' and a map ''e'' from ''P'' to ''B''&lt;sup&gt;+&lt;/sup&gt; (the non-zero elements of ''B'') such that the image is dense, ''e''(''p'')≤''e''(''q'') whenever ''p''≤''q'', and ''e''(''p'')''e''(''q'')=0 whenever ''p'' and ''q'' are incompatible. This Boolean algebra is unique up to isomorphism. It can be constructed as the algebra of regular open sets in the topological space of ''P'' (with underlying set ''P'', and a base given by the sets ''U''&lt;sub&gt;''p''&lt;/sub&gt; of elements ''q'' with ''q''≤''p'').

The map from the poset ''P'' to the complete Boolean algebra ''B'' is not injective in general. The map is injective if and only if ''P'' has the following property: if every ''r''≤''p'' is compatible with ''q'', then ''p''≤''q''.

The ultrafilter ''U'' on ''B'' is defined to be  the set of elements ''b'' of ''B'' that are greater than some element of (the image of) ''G''. Given an ultrafilter ''U'' on a Boolean algebra, we get a homomorphism to {true, false}
by mapping ''U'' to true and its complement to false. Conversely, given such a homomorphism, the inverse image of true is an ultrafilter, so ultrafilters are essentially the same as homomorphisms to {true, false}. (Algebraists might prefer to use maximal ideals instead of ultrafilters: the complement of an ultrafilter is a maximal ideal, and conversely the complement of a maximal ideal is an ultrafilter.)

If ''g'' is a homomorphism from a Boolean algebra ''B'' to a Boolean algebra ''C'' and ''M&lt;sup&gt;B&lt;/sup&gt;'' is any 
''B''-valued model of ZF (or of any other theory for that matter) we can turn ''M&lt;sup&gt;B&lt;/sup&gt;''  into a ''C'' -valued model by applying the homomorphism ''g'' to the value of all formulas. In particular if ''C'' is {true, false} we get a {true, false}-valued model. This is almost the same as an ordinary model: in fact we get an ordinary model on the set of equivalence classes under ||&amp;nbsp;=&amp;nbsp;|| of a {true, false}-valued model. So we get an ordinary model of ZF set theory by starting from ''M'', a Boolean algebra ''B'', and an ultrafilter ''U'' on ''B''.
(The model of ZF constructed like this is not transitive. In practice one  applies the [[Mostowski collapse|Mostowski collapsing theorem]] to turn this into a transitive model.)

We have seen that forcing can be done using Boolean-valued models, by constructing a Boolean algebra with ultrafilter from a poset with a generic subset. It is also possible to go back the other way: given a Boolean algebra ''B'', we can form a poset ''P'' of all the nonzero elements of ''B'', and a generic ultrafilter on ''B'' restricts to a generic set on ''P''. So the techniques of forcing and Boolean-valued models are essentially equivalent.

==Notes==
&lt;references/&gt;

==References==
* Bell, J. L. (1985) ''Boolean-Valued Models and Independence Proofs in Set Theory'', Oxford. {{ISBN|0-19-853241-5}}
*{{springer|id=b/b016990|first=V.N.|last= Grishin}}
* {{cite book|authorlink=Thomas Jech|author=Jech, Thomas|title=Set theory, third millennium edition (revised and expanded)|publisher=Springer|year=2002|isbn=3-540-44085-2|oclc=174929965}}
* {{cite book|title=Set Theory: An Introduction to Independence Proofs|author=Kunen, Kenneth|publisher=North-Holland|year=1980|isbn=0-444-85401-0|oclc=12808956}}
* {{cite book|author=Kusraev, A. G. and  [[S. S. Kutateladze]]|title=Boolean Valued Analysis|
publisher=Kluwer Academic Publishers|year=1999|isbn=0-7923-5921-6|oclc=41967176}} Contains an account of Boolean-valued models and applications to Riesz spaces, Banach spaces and algebras. 
* {{cite book|author=Manin, Yu. I.|title=A Course in Mathematical Logic|publisher=Springer|year=1977|isbn=0-387-90243-0|oclc=2797938}} Contains an account of forcing and Boolean-valued models written for mathematicians who are not set theorists.
* {{cite book|author=Rosser, J. Barkley|title=Simplified Independence Proofs, Boolean valued models of set theory|publisher=Academic Press|year=1969}}

[[Category:Model theory]]
[[Category:Boolean algebra]]
[[Category:Forcing (mathematics)]]</text>
      <sha1>3ooi7riu3qtqbqg5iem2fzxfz7b8qkk</sha1>
    </revision>
  </page>
  <page>
    <title>Communicating finite-state machine</title>
    <ns>0</ns>
    <id>38734569</id>
    <revision>
      <id>590770636</id>
      <parentid>585046660</parentid>
      <timestamp>2014-01-15T04:30:17Z</timestamp>
      <contributor>
        <username>Pandorabox722</username>
        <id>20216339</id>
      </contributor>
      <comment>Typos in the reference section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4147">In [[computer science]], a '''communicating finite-state machine''' is a [[finite state machine]] labeled with "receive" and "send" operations over some alphabet of channels. They were introduced by Brand and Zafiropulo,&lt;ref&gt;D. Brand and P. Zafiropulo. On communicating finite-state machines. Journal of the ACM, 30(2):323-342, 1983.&lt;/ref&gt; and can be used as a model of [[concurrency (computer science)|concurrent]] processes like [[Petri nets]]. Communicating finite state machines are used frequently for modeling a communication protocol since they make it possible to detect major protocol design errors, including boundedness, deadlocks, and unspecified receptions.&lt;ref&gt;Rosier, Louis E; Gouda, Mohamed G. Deciding Progress for a Class of Communicating Finite State Machines. Austin: University of Texas at Austin, 1983.&lt;/ref&gt;

The advantage of communicating finite state machines is that they make it possible to decide many properties in communication protocols, beyond the level of just detecting such properties. This advantage rules out the need for human assistance or restriction in generality.&lt;ref&gt;D. Brand and P. Zafiropulo. On communicating finite-state machines. Journal of the ACM, 30(2):323-342, 1983.&lt;/ref&gt;

It has been proved with the introduction of the concept itself that when two finite state machines communicate with only one type of messages, boundedness, deadlocks, and unspecified reception state can be decided and identified while such is not the case when the machines communicate with two or more types of messages. Later, it has been further proved that when only one finite state machine communicates with single type of message while the communication of its partner is unconstrained, we can still decide and identify boundedness, deadlocks, and unspecified reception state.&lt;ref&gt;Rosier, Louis E; Gouda, Mohamed G. Deciding Progress for a Class of Communicating Finite State Machines. Austin: University of Texas at Austin, 1983.&lt;/ref&gt;

It has been further proved that when the message priority relation is empty, boundedness, deadlocks and unspecified reception state can be decided even under the condition in which there are two or more types of messages in the communication between finite state machines.&lt;ref&gt;Gouda, Mohamed G; Rosier, Louis E. "Communicating finite state machines with priority channels," Automata, Languages and Programming. Antwerp: ICALP, 1984&lt;/ref&gt;

Boundedness, deadlocks, and unspecified reception state are all decidable in polynomial time (which means that a particular problem can be solved in tractable, not infinite, amount of time) since the decision problems regarding them are nondeterministic logspace complete.&lt;ref&gt;Rosier, Louis E; Gouda, Mohamed G. Deciding Progress for a Class of Communicating Finite State Machines. Austin: University of Texas at Austin, 1983.&lt;/ref&gt;

Communicating finite state machines can be the most powerful in situations where the propagation delay is not negligible (so that several messages can be in transit at one time) and in situations where it is natural to describe the protocol parties and the communication medium as separate entities.&lt;ref&gt;D. Brand and P. Zafiropulo. On communicating finite-state machines. Journal of the ACM, 30(2):323-342, 1983.&lt;/ref&gt;

==Communicating Hierarchical State Machine==

Hierarchical state machines are finite state machines whose states themselves can be other machines. Since a communicating finite state machine is characterized by concurrency, the most notable trait in a '''communicating hierarchical state machine''' is the coexistence of hierarchy and concurrency. This had been considered highly suitable as it signifies stronger interaction inside the machine. 

However, it was proved that the coexistence of hierarchy and concurrency intrinsically costs language inclusion, language equivalence, and all of universality.&lt;ref&gt;Alur, Rajeev; Kannan, Sampath; Yannakakis, Mihalis. "Communicating hierarchical state machines," Automata, Languages and Programming. Prague: ICALP, 1999&lt;/ref&gt;

== References ==
&lt;references /&gt;

[[Category:Concurrency (computer science)]]
[[Category:Models of computation]]</text>
      <sha1>nhx6jvk4mv2bqr0u2qrnfkj4pbu2vru</sha1>
    </revision>
  </page>
  <page>
    <title>Constraint counting</title>
    <ns>0</ns>
    <id>2471934</id>
    <revision>
      <id>848067521</id>
      <parentid>673726926</parentid>
      <timestamp>2018-06-29T15:50:43Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Class. Quant. Grav. → Class. Quantum Grav. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6654">In [[mathematics]], '''constraint counting''' is counting the number of [[constraint (mathematics)|constraints]] in order to compare it with the number of [[variable (mathematics)|variables]], [[parameter#Mathematical functions|parameters]], etc. that are free to be determined, the idea being that in most cases the number of independent choices that can be made is the excess of the latter over the former.

For example, in [[linear algebra]] if the number of constraints (independent equations) in a [[system of linear equations]] equals the number of unknowns then precisely one solution exists; if there are fewer independent equations than unknowns, an infinite number of solutions exist; and if the number of independent equations exceeds the number of unknowns, then no solutions exist.

In the context of [[partial differential equation]]s, constraint counting is a crude but often useful way of counting the number of ''free functions'' needed to specify a solution to a [[partial differential equation]].

==Partial differential equations==

Consider a second order partial differential equation in three variables, such as the two-dimensional [[wave equation]]
:&lt;math&gt; u_{tt} = u_{xx} + u_{yy}. &lt;/math&gt;
It is often profitable to think of such an equation as a ''rewrite rule'' allowing us to rewrite arbitrary partial derivatives of the function &lt;math&gt;u(t,x,y)&lt;/math&gt; using fewer partials than would be needed for an arbitrary function.  For example, if &lt;math&gt;u&lt;/math&gt; satisfies the wave equation, we can rewrite 
:&lt;math&gt; u_{tyt} = u_{tty} = u_{xxy} + u_{yyy} &lt;/math&gt;
where in the first equality, we appealed to the fact that ''partial derivatives commute''.

===Linear equations===

To answer this in the important special case of a [[linear]] partial differential equation, Einstein asked: how many of the partial derivatives of a solution can be [[linearly independent]]?  It is convenient to record his answer using an [[ordinary generating function]]
:&lt;math&gt;s(\xi) = \sum_{k=0}^\infty s_k \xi^k &lt;/math&gt;
where &lt;math&gt;s_k&lt;/math&gt; is a natural number counting the number of linearly independent partial derivatives (of order k) of an arbitrary function in the solution space of the equation in question.

Whenever a function satisfies some partial differential equation, we can use the corresponding rewrite rule to eliminate some of them, because ''further mixed partials have necessarily become linearly dependent''.  Specifically, the power series counting the variety of ''arbitrary'' functions of three variables (no constraints) is
:&lt;math&gt;f(\xi) =  \frac{1}{(1-\xi)^3} = 1 + 3 \xi + 6 \xi^2 + 10 \xi^3 + \dots&lt;/math&gt;
but the power series counting those in the solution space of some second order p.d.e. is
:&lt;math&gt;g(\xi) = \frac{1-\xi^2}{(1-\xi)^3} = 1 + 2 \xi + 5 \xi^2 + 7 \xi^3 + \dots &lt;/math&gt;
which records that we can eliminate ''one'' second order partial &lt;math&gt;u_{tt}&lt;/math&gt;, ''three'' third order partials &lt;math&gt;u_{ttt}, \, u_{ttx}, \, u_{tty} &lt;/math&gt;, and so forth.

More generally, the o.g.f. for an arbitrary function of n variables is
:&lt;math&gt;s[n](\xi) = 1/(1-\xi)^n = 1 + n \, \xi + \left( \begin{matrix} n \\ 2 \end{matrix} \right) \, \xi^2 + \left( \begin{matrix} n+1 \\ 3 \end{matrix} \right) \, \xi^3 + \dots &lt;/math&gt;
where the coefficients of the infinite [[power series]] of the generating function are constructed using an appropriate infinite sequence of [[binomial coefficient]]s, and the power series for a function required to satisfy a linear m-th order equation is
:&lt;math&gt;g(\xi) = \frac{1-\xi^m}{(1-\xi)^n} &lt;/math&gt;

Next,
:&lt;math&gt; \frac{1-\xi^2}{(1-\xi)^3} = \frac{1 + \xi}{(1-\xi)^2}&lt;/math&gt;
which can be interpreted to predict that a solution to a second order linear p.d.e. in ''three'' variables is expressible by two ''freely chosen'' functions of ''two'' variables, one of which is used immediately, and the second, only after taking a ''first derivative'', in order to express the solution.

===General solution of initial value problem===

To verify this prediction, recall the solution of the [[initial value problem]]
:&lt;math&gt;u_{tt} = u_{xx} + u_{yy}, \; u(0,x,y) = p(x,y), \; u_t(0,x,y) = q(x,y) &lt;/math&gt;
Applying the [[Laplace transform]] &lt;math&gt;u(t,x,y) \mapsto [Lu](\omega,x,y)&lt;/math&gt; gives
:&lt;math&gt; -\omega^2 \, [Lu] + \omega \, p(x,y) + q(x,y) + [Lu]_x + [Lu]_y&lt;/math&gt;
Applying the [[Fourier transform]] &lt;math&gt;[Lu](\omega,x,y) \mapsto [FLU](\omega,m,n)&lt;/math&gt; to the two spatial variables gives
:&lt;math&gt; -\omega^2 \, [FLu] + \omega \, [Fp] + [Fq] - (m^2+n^2) \, [FLu]&lt;/math&gt;
or
:&lt;math&gt;[FLu](\omega,m,n) = \frac{ \omega \, [Fp](m,n) + [Fq](m,n)}{\omega^2 + m^2 + n^2}&lt;/math&gt;
Applying the inverse Laplace transform gives
:&lt;math&gt; [Fu](t,m,n) = [Fp](m,n) \, \cos( \sqrt{m^2+n^2} \, t ) + \frac{ [Fq](m,n) \, \sin (\sqrt{m^2+n^2} \, t) }{\sqrt{m^2+n^2}} &lt;/math&gt;
Applying the inverse Fourier transform gives
:&lt;math&gt;u(t,x,y) = Q(t,x,y) + P_t(t,x,y)&lt;/math&gt;
where
:&lt;math&gt;P(t,x,y) = \frac{1}{2\pi} \, \int_{(x-x')^2 + (y-y')^2 &lt; t^2} \frac{p(x',y') \, dx' dy'}{ \left[ t^2-(x-x')^2-(y-y')^2 \right]^{1/2}} &lt;/math&gt;
:&lt;math&gt;Q(t,x,y) = \frac{1}{2\pi} \, \int_{(x-x')^2 + (y-y')^2 &lt; t^2} \frac{q(x',y') \, dx' dy'}{ \left[ t^2-(x-x')^2-(y-y')^2 \right]^{1/2}} &lt;/math&gt;
Here, p,q are arbitrary (sufficiently smooth) functions of two variables, so (due their modest time dependence) the integrals P,Q also count as "freely chosen" functions of two variables; as promised, one of them is differentiated once before adding to the other to express the general solution of the initial value problem for the two dimensional wave equation.

===Quasilinear equations===

In the case of a nonlinear equation, it will only rarely be possible to obtain the general solution in closed form.  However, if the equation is ''quasilinear'' (linear in the highest order derivatives), then we can still obtain approximate information similar to the above: specifying a member of the solution space will be "modulo nonlinear quibbles" equivalent to specifying a certain number of functions in a smaller number of variables.  The number of these functions is the ''Einstein strength'' of the p.d.e.  In the simple example above,  the strength is two, although in this case we were able to obtain more precise information.

==References==

*{{cite journal | author=Siklos, S. T. C. | title=Counting solutions of Einstein's equation | journal=Class. Quantum Grav. | year=1996 | volume=13 | pages=1931–1948 | doi=10.1088/0264-9381/13/7/021 | issue=7}}  Application of constraint counting to Riemannian geometry and to general relativity.

[[Category:Combinatorics]]
[[Category:Partial differential equations]]
[[Category:Riemannian geometry]]</text>
      <sha1>2mrgek0rnccutbz5cmao0acampl98pz</sha1>
    </revision>
  </page>
  <page>
    <title>Convergence (logic)</title>
    <ns>0</ns>
    <id>32106812</id>
    <revision>
      <id>627004384</id>
      <parentid>617168787</parentid>
      <timestamp>2014-09-25T09:05:51Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* top */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="935">In [[mathematics]], [[computer science]] and [[logic]], '''convergence''' refers to the idea that different sequences of transformations come to a conclusion in a finite amount of time (the transformations are [[Newman's lemma|terminating]]), and that the conclusion reached is independent of the path taken to get to it (they are [[Confluence (abstract rewriting)|confluent]]).

More formally, a [[preorder]]ed set of [[term rewriting]] transformations are said to be '''convergent''' if they are [[Confluence (abstract rewriting)|confluent]] and [[Newman's lemma|terminating]].&lt;ref&gt;{{cite book|author1=[[Franz Baader]]|author2=[[Tobias Nipkow]]|title=Term Rewriting and All That|year=1998|publisher=Cambridge University Press|isbn=0-521-77920-0}}&lt;/ref&gt;

==See also==
*[[Logical equality]]
*[[Logical equivalence]]
*[[Rule of replacement]]

==References==
&lt;references /&gt;

[[Category:Rewriting systems]]

{{comp-sci-stub}}
{{plt-stub}}</text>
      <sha1>shynlzx9ezt9670myk6osb1i1z7k7h2</sha1>
    </revision>
  </page>
  <page>
    <title>DONE</title>
    <ns>0</ns>
    <id>51017812</id>
    <revision>
      <id>819039061</id>
      <parentid>737198131</parentid>
      <timestamp>2018-01-07T01:47:33Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding links to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1890">The Data-based Online Nonlinear Extremumseeker (DONE) algorithm is a black-box [[optimization]] algorithm.
DONE models the unknown cost function and attempts to find an optimum of the underlying function.
The DONE algorithm is suitable for optimizing costly and noisy functions and does not require derivatives.
An advantage of DONE over similar algorithms, such as [[Bayesian Optimization]], is that the [[computational cost]] per iteration is independent of the number of function evaluations.

==Methods==

The DONE algorithm was first proposed by Hans Verstraete and Sander Wahls.&lt;ref&gt;Hans R. G. W. Verstraete, Sander Wahls, Jeroen Kalkman, Michel Verhaegen: [https://www.osapublishing.org/abstract.cfm?uri=ol-40-24-5722 Model-based sensor-less wavefront aberration correction in optical coherence tomography], Opt. Lett. 40, 5722-5725 (2015)&lt;/ref&gt; The algorithm fits a [[surrogate model]] based on random Fourier features&lt;ref&gt;Ali Rahimi, Benjamin Recht: [http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf Random features for large-scale kernel machines], Advances in neural information processing systems, pp. 1177-1184 (2007)&lt;/ref&gt; and then uses a well-known [[L-BFGS]] algorithm to find an optimum of the surrogate model.

==Applications==
DONE was first demonstrated for maximizing the signal in [[optical coherence tomography]] measurements, but has since then been applied to various other applications. For example, it was used to help extending the field of view in [[light sheet fluorescence microscopy]].&lt;ref&gt;Dean Wilding, Paolo Pozzi, Oleg Soloviev, Gleb Vdovin, Colin J. Sheppard,  Michel Verhaegen: [http://www.dcsc.tudelft.nl/~mverhaegen/papers/PupilFilters.pdf Pupil filters for extending the field-of-view in light-sheet microscopy], Optics letters 41, no. 6 (2016): 1205-1208&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Algorithms]]</text>
      <sha1>izid0h0yxna4t78atf5uh18i1rf5iz4</sha1>
    </revision>
  </page>
  <page>
    <title>Delta invariant</title>
    <ns>0</ns>
    <id>13374894</id>
    <revision>
      <id>721416010</id>
      <parentid>496667613</parentid>
      <timestamp>2016-05-21T18:24:48Z</timestamp>
      <contributor>
        <username>Laurusnobilis</username>
        <id>2514565</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="567">In [[mathematics]], in the theory of [[algebraic curve]]s, a '''delta invariant''' measures the number of [[double point]]s concentrated at a point.&lt;ref name=milnor&gt;[[John Milnor]], ''Singular Points of Hypersurfaces'', p. 85&lt;/ref&gt;   It is a non-negative integer.


Delta invariants are discussed in the "Classification of singularities" section of the [[algebraic curve#Classification of singularities|algebraic curve]] article.

==References==
{{Reflist}}

{{Algebraic curves navbox}}

[[Category:Algebraic curves]]
[[Category:Singularity theory]]

{{algebra-stub}}</text>
      <sha1>npudmv1rxmliwpkwn0ioscai6a198bk</sha1>
    </revision>
  </page>
  <page>
    <title>Folded-t and half-t distributions</title>
    <ns>0</ns>
    <id>51410046</id>
    <revision>
      <id>802063593</id>
      <parentid>780123517</parentid>
      <timestamp>2017-09-23T19:26:44Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <comment>/* Further reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4805">{{DISPLAYTITLE:Folded-''t'' and half-''t'' distributions}}
In statistics, the '''folded-''t''''' and '''half-''t'' distributions''' are derived from [[Student's t-distribution|Student's ''t''-distribution]] by taking the [[absolute value]]s of variates. This is analogous to the [[folded normal distribution|folded-normal]] and the [[half-normal distribution|half-normal]] [[statistical distribution]]s being derived from the [[normal distribution]].

==Definition==
The '''folded non-standardized ''t'' distribution''' is the distribution of the absolute value of the non-standardized ''t'' distribution with &lt;math&gt;\nu&lt;/math&gt; degrees of freedom; its [[probability density function]] is given by:{{cn|date=November 2016}}
:&lt;math&gt;g\left(x\right)\;=\;\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\sqrt{\nu\pi\sigma^2}}\left\lbrace
\left[1+\frac{1}{\nu}\frac{\left(x-\mu\right)^2}{\sigma^2}\right]^{-\frac{\nu+1}{2}}+\left[1+\frac{1}{\nu}\frac{\left(x+\mu\right)^2}{\sigma^2}\right]^{-\frac{\nu+1}{2}} \right\rbrace \qquad(\mbox{for}\quad x \geq 0)&lt;/math&gt;.
The '''half-''t'' distribution''' results as the special case of &lt;math&gt;\mu=0&lt;/math&gt;, and the '''standardized''' version as the special case of &lt;math&gt;\sigma=1&lt;/math&gt;.

== Relation to normal and Cauchy distributions==
Folded-''t'' and half-''t'' generalize the '''[[folded normal distribution|folded normal]]''' and '''[[half-normal distribution|half-normal distributions]]''' by allowing for finite [[degrees of freedom (statistics)|degrees-of-freedom]] (the [[normal distribution|normal]] analogues constitute the limiting cases of infinite degrees-of-freedom). Since the [[Cauchy distribution]] constitutes the special case of a [[Student-t distribution|Student-''t'' distribution]] with one degree of freedom, the families of folded and half-''t'' distributions include the '''folded Cauchy''' and '''half-Cauchy distributions''' for &lt;math&gt;\nu=1&lt;/math&gt;.

==The half-''t'' distribution==
If &lt;math&gt;\mu=0&lt;/math&gt;, the folded-''t'' distribution reduces to the special case of the half-''t'' distribution. Its [[probability density function]] then simplifies to
:&lt;math&gt;g\left(x\right)\;=\;\frac{2\;\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\sqrt{\nu\pi\sigma^2}}
\left(1+\frac{1}{\nu}\frac{x^2}{\sigma^2}\right)^{-\frac{\nu+1}{2}} \qquad(\mbox{for}\quad x \geq 0)&lt;/math&gt;.
The half-''t'' distribution's first two [[moment (mathematics)|moment]]s ([[expected value|expectation]] and [[variance]]) are given by:&lt;ref&gt;{{citation|last1=Psarakis|first1=S.|last2=Panaretos|first2=J.|title=The folded t distribution|journal=Communications in Statistics - Theory and Methods|volume=19|issue=7|year=1990|pages=2717-2734|doi=10.1080/03610929008830342}}&lt;/ref&gt;
:&lt;math&gt;\operatorname{E}[X]\;=\;2\sigma\sqrt{\frac{\nu}{\pi}}\frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\,(\nu-1)} \qquad\mbox{for}\quad \nu &gt; 1&lt;/math&gt;,
and
:&lt;math&gt;\operatorname{Var}(X)\;=\;\sigma^2\frac{\nu}{\nu-2}\frac{4\nu}{\pi(\nu-1)^2}\left(\frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})}\right)^2 \qquad\mbox{for}\quad \nu &gt; 2&lt;/math&gt;.

==See also==
* [[Student-t distribution|Student-''t'' distribution]]
* [[half-normal distribution]]
* [[folded normal distribution]]
* [[normal distribution]]
* [[Cauchy distribution]]

== References ==
{{Reflist}}

==Further reading==
* {{cite journal |last1=Psarakis|first1=S.|last2=Panaretos|first2=J.|title=The folded t distribution|journal=Communications in Statistics - Theory and Methods|volume=19|issue=7|year=1990|pages=2717-2734|doi=10.1080/03610929008830342}}
* {{cite journal |last1=Gelman|first1=A.|title=Prior distributions for variance parameters in hierarchical models|journal=Bayesian Analysis|volume=1|number=3|pages=515-534|year=2006|url=http://projecteuclid.org/euclid.ba/1340371048}}
* {{cite journal |first=M. P. |last=Wiper |first2=F. J. |last2=Girón |first3=Arthur |last3=Pewsey |title=Objective Bayesian Inference for the Half-Normal and Half-t Distributions |journal=Communications in Statistics - Theory and Methods |volume=37 |year=2008 |issue=20 |pages=3165–3185 |doi=10.1080/03610920802105184 }}
* {{cite journal |last1=Tancredi |first1=A. |year=2002 |title=Accounting for heavy tails in stochastic frontier models |url=http://paduaresearch.cab.unipd.it/7325/ |institution=Università degli Studi di Padova |number=7325 |series=Working paper}}

==External links==
* Functions to evaluate half-''t'' distributions are available in several [[R (programming language)|R]] packages, e.g. [https://rdrr.io/cran/LaplacesDemon/man/dist.Halft.html] [https://rdrr.io/cran/bayesmeta/man/dhalfnormal.html] [https://rdrr.io/cran/extraDistr/man/HalfT.html].

{{stats-stub|date=August 2016}}

{{ProbDistributions|continuous-semi-infinite}}

[[Category:Continuous distributions]]</text>
      <sha1>ofxx1eu8epp23fm27lz8zkafk9plv3g</sha1>
    </revision>
  </page>
  <page>
    <title>Free logic</title>
    <ns>0</ns>
    <id>1635110</id>
    <revision>
      <id>799119096</id>
      <parentid>783783888</parentid>
      <timestamp>2017-09-05T19:12:04Z</timestamp>
      <contributor>
        <username>Biogeographist</username>
        <id>18201938</id>
      </contributor>
      <comment>removed red links ([[WP:WTAF|write the article first]]); added [[Template:Full citation needed]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6420">A '''free logic''' is a [[logic]] with fewer [[existential clause|existential]] presuppositions than classical logic. Free logics may allow for [[Term (first-order logic)|terms]] that do not denote any object. Free logics may also allow [[structure (mathematical logic)|models]] that have an [[empty domain]]. A free logic with the latter property is an '''inclusive logic'''.

== Explanation ==

In [[classical logic]] there are theorems that clearly presuppose that there is something in the [[domain of discourse]]. Consider the following classically valid theorems.

:1. &lt;math&gt; \forall xA \rightarrow \exists xA&lt;/math&gt;
:2. &lt;math&gt; \forall xA \rightarrow A(r/x)&lt;/math&gt; (where r does not occur free for x in A and A(r/x) is the result of substituting r for all free occurrences of x in A)
:3. &lt;math&gt; Ar \rightarrow \exists xAx&lt;/math&gt; (where r does not occur free for x in A)

A valid scheme in the theory of [[First-order logic#Equality and its axioms|equality]] which exhibits the same feature is

:4. &lt;math&gt; \forall x(Fx \rightarrow Gx) \land \exists xFx \rightarrow \exists x(Fx \land Gx)&lt;/math&gt;

Informally, if F is '=y', G is 'is Pegasus', and we substitute 'Pegasus' for y, then (4) appears to allow us to infer from 'everything identical with Pegasus is Pegasus' that something is identical with Pegasus. The problem comes from substituting nondesignating constants for variables:  in fact, we cannot do this in standard formulations of [[first-order logic]], since there are no nondesignating constants.  Classically, ∃x(x=y) is deducible from the open equality axiom y=y by particularization (i.e. (3) above).

In free logic, (1) is replaced with

:1b. &lt;math&gt; \forall xA \land E!t \rightarrow \exists xA&lt;/math&gt;, where E! is an existence predicate (in some but not all formulations of free logic, E!t can be defined as &amp;exist;y(y=t))&lt;ref&gt;{{cite book|url=https://plato.stanford.edu/archives/win2016/entries/nonexistent-objects/|title=The Stanford Encyclopedia of Philosophy|first=Maria|last=Reicher|editor-first=Edward N.|editor-last=Zalta|date=1 January 2016|publisher=Metaphysics Research Lab, Stanford University|via=Stanford Encyclopedia of Philosophy}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Parsons, Terence|authorlink=Terence Parsons|year=1980|title=Nonexistent Objects|publisher=New Haven: Yale University Press}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Zalta, Edward N.|authorlink=Edward N. Zalta|year=1983|title=Abstract Objects. An Introduction to Axiomatic Metaphysics|publisher=Dordrecht: Reidel}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Jacquette, Dale|year=1996|title=Meinongian Logic. The Semantics of Existence and Nonexistence|series=Perspectives in Analytical Philosophy 11|publisher=Berlin–New York: de Gruyter.}}&lt;/ref&gt;

Similar modifications are made to other theorems with existential import (e.g. the Rule of Particularization becomes (Ar → (E!r → ∃xAx)).

[[Axiom]]atizations of free-logic are given by Theodore Hailperin (1957),{{Full citation needed|date=September 2017}} [[Jaakko Hintikka]] (1959),&lt;ref&gt;Jaako Hintikka (1959). Existential Presuppositions and Existential Commitments. Journal of Philosophy 56 (3):125-137.&lt;/ref&gt; [[Karel Lambert]] (1967),&lt;ref name="Lambert"/&gt; and Richard L. Mendelsohn (1989).{{Full citation needed|date=September 2017}}

==Interpretation==

[[Karel Lambert]] wrote in 1967:&lt;ref name="Lambert"&gt;''Free Logic and the Concept of Existence'' by Karel Lambert, Notre Dame Journal of Formal Logic, V.III, numbers 1 and 2, April 1967&lt;/ref&gt; "In fact, one may regard free logic... literally as a theory about singular existence, in the sense that it lays down certain minimum conditions for that concept."  The question that concerned the rest of his paper was then a description of the theory, and to inquire whether it gives a necessary and sufficient condition for existence statements.

Lambert notes the irony in that [[Willard Van Orman Quine]] so vigorously defended a form of logic that only accommodates his famous dictum, "To be is to be the value of a variable," when the logic is supplemented with [[Bertrand Russell|Russellian]] assumptions of [[Theory of Descriptions|description theory]].  He criticizes this approach because it puts too much ideology into a logic, which is supposed to be philosophically neutral.  Rather, he points out, not only does free logic provide for Quine's criterion—it even proves it!  This is done by brute force, though, since he takes as axioms &lt;math&gt; \exists xFx \rightarrow (\exists x(E!Fx))&lt;/math&gt; and &lt;math&gt;Fy \rightarrow (E!y \rightarrow \exists xFx)&lt;/math&gt;, which neatly formalizes Quine's dictum.  So, Lambert argues, to reject his construction of free logic requires you to reject Quine's philosophy, which requires some argument and also means that whatever logic you develop is always accompanied by the stipulation that you must reject Quine to accept the logic.  Likewise, if you reject Quine then you must reject free logic.  This amounts to the contribution that free logic makes to ontology.

The point of free logic, though, is to have a formalism that implies no particular ontology, but that merely makes an interpretation of Quine both formally possible and simple.  An advantage of this is that formalizing theories of singular existence in free logic brings out their implications for easy analysis.  Lambert takes the example of the theory proposed by [[Wesley C. Salmon]] and George Nahknikian,&lt;ref&gt;George Nahknikian and Wesley C. Salmon, "'Exists' as a Predicate" ''Philosophical Review'' Vol. 66: 1957 pp. 535-542&lt;/ref&gt; which is that to exist is to be self-identical.

==See also==
* [[Square of opposition]]
* [[Table of logic symbols]]

==Notes==
{{reflist}}

==References==
* {{cite book|author=Lambert, Karel|authorlink=Karel Lambert|year=2003|title=Free logic: Selected essays|publisher=Cambridge Univ. Press|isbn=9780511039195}}
* ———, 2001, "Free Logics," in Goble, Lou, ed., ''The Blackwell Guide to Philosophical Logic''. Blackwell.
* ———, 1997. ''Free logics: Their foundations, character, and some applications thereof.'' Sankt Augustin: Academia.
* ———, ed. 1991. ''Philosophical applications of free logic.'' Oxford Univ. Press.
* Morscher, Edgar, and Hieke, Alexander, 2001. ''New essays in free logic.'' Dordrecht: Kluwer.

== External links ==
*{{cite SEP |url-id=logic-free |title=Free logic |last=Nolt |first=John}}

{{DEFAULTSORT:Free Logic}}
[[Category:Non-classical logic]]</text>
      <sha1>5u6sslnp0f0es5482d6hi44wfjzutt6</sha1>
    </revision>
  </page>
  <page>
    <title>GReAT</title>
    <ns>0</ns>
    <id>4774780</id>
    <revision>
      <id>746007688</id>
      <parentid>551591450</parentid>
      <timestamp>2016-10-24T18:38:39Z</timestamp>
      <contributor>
        <ip>2A01:CB08:8658:2900:B9F2:660B:E782:AD48</ip>
      </contributor>
      <comment>Alert on broken links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1731">'''Graph Rewriting and Transformation''' ('''GReAT''') is a  [[Model Transformation Language]] (MTL) for [[Model Integrated Computing]] available in the [[Generic Modeling Environment|GME]] environment. GReAT has a rich pattern specification sublanguage, a [[graph transformation]] sublanguage and a high level control-flow sublanguage. It has been designed to address the specific needs of the model transformation area. The GME environment is an example of a [[Model Driven Engineering]] (MDE) framework.

==See also==
* [[ATLAS Transformation Language]]
* [[CoSMIC]]
* [[Domain Specific Language]] (DSL)
* [[Domain-specific modelling]] (DSM)
* [[Model-based testing]] (MBT)
* [[Meta-Object Facility]]
* [[Meta-modeling]]
* [[VIATRA]]
* [[XML Metadata Interchange|XMI]]
* [[Object Constraint Language|OCL]]
* [[QVT]]

==References==
* [http://ase.informatik.uni-essen.de/ase/past/ase2003/demos/agrawal.pdf GReAT  ref 1]
* [http://www.omg.org/news/meetings/workshops/MIC_2004_Manual/07-1_Vizhanyo.pdf GReAT  ref 2]
* [http://tfs.cs.tu-berlin.de/grabats/Final04/agrawal.pdf GReAT  ref 3] [broken link]
* [http://www.isis.vanderbilt.edu/publications/archive/Karsai_G_0_0_2003_On_the_Use.pdf  GReAT   ref 4 ] [broken link]
* [http://www.swen.uwaterloo.ca/~kczarnec/ECE750T7/Model_To_Model_Transformations4.pdf GReAT   ref 5] [broken link]
* [http://www.metamodel.com/wisme-2003/13.pdf  GReAT   ref 6] [broken link]
* [http://www.softmetaware.com/oopsla2005/vizhanyo.pdf  GReAT   ref 7]
* [http://www.lore.ua.ac.be/refactoringProject/publications/Mens2004MtransTaxoGT.pdf GReAT   ref 8]
* [http://www.isis.vanderbilt.edu/publications/archive/Agrawal_A_0_0_2005_The_Design.pdf GReAT   ref 9] [broken link]

[[Category:Graph rewriting]]</text>
      <sha1>8ip2jeb477h5wak82g8lehdkr0x28h7</sha1>
    </revision>
  </page>
  <page>
    <title>Harold Edwards (mathematician)</title>
    <ns>0</ns>
    <id>26012311</id>
    <revision>
      <id>833055768</id>
      <parentid>806905034</parentid>
      <timestamp>2018-03-29T12:36:24Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>add +[[Category:People from Champaign, Illinois]]; +[[Category:Mathematicians from Illinois]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10502">{{Infobox scientist
|name              = Harold Mortimer Edwards, Jr.
|image             = 
|image_size        = 
|caption           = 
|birth_date        = {{birth date and age|1936|8|6|mf=y}}
|birth_place       = [[Champaign, Illinois]]&lt;ref name="cv"&gt;[http://www.math.nyu.edu/faculty/edwardsd/vita.htm Curriculum vitae] from Edwards' web site at NYU, retrieved 2010-01-30.&lt;/ref&gt; 
|death_date        = 
|death_place       = 
|nationality       = American
|ethnicity         = 
|field             = [[Mathematics]]
|work_institutions = [[New York University]]
|alma_mater        = [[Harvard University]]
|doctoral_advisor  = [[Raoul Bott]]
|doctoral_students = 
|known_for         =  
|prizes            = [[Leroy P. Steele Prize]]
}}

'''Harold Mortimer Edwards, Jr.''' (born August 6, 1936) is an American mathematician working in [[number theory]], [[abstract algebra|algebra]], and the history and philosophy of mathematics.

He was one of the co-founding editors, with Bruce Chandler, of ''[[The Mathematical Intelligencer]]''.&lt;ref name="cv"/&gt;
He is the author of expository books on the [[Riemann zeta function]], on [[Galois theory]], and on [[Fermat's Last Theorem]].  He wrote a book on [[Leopold Kronecker]]'s work on [[divisor theory]] providing a systematic exposition of that work—a task that Kronecker never completed.  He has written textbooks on [[linear algebra]], [[calculus]], and number theory.  He also wrote a book of essays on [[constructive mathematics]].

==Biography==
Edwards received his Ph.D. in 1961 from [[Harvard University]], under the supervision of [[Raoul Bott]].&lt;ref&gt;{{mathgenealogy|name=Harold Mortimer Edwards, Jr. |id=54164}}.&lt;/ref&gt;
He has taught at Harvard and [[Columbia University]]; he joined the faculty at [[New York University]] in 1966, and has been an [[emeritus professor]] since 2002.&lt;ref name="cv"/&gt;

In 1980, Edwards won the [[Leroy P. Steele Prize]] for Mathematical Exposition of the [[American Mathematical Society]], for his books on the Riemann zeta function and Fermat's Last Theorem.&lt;ref&gt;[http://www.ams.org/prizes/steele-prize.html Leroy P. Steel Prizes], [[American Mathematical Society]], retrieved 2010-01-31.&lt;/ref&gt; For his contribution in the field of the history of mathematics he was awarded the [[Albert Leon Whiteman Memorial Prize]] by the AMS in 2005.&lt;ref name="whiteman"&gt;{{citation
 | date = April 2005
 | issue = 4
 | journal = Notices of the [[American Mathematical Society|AMS]]
 | title = 2005 Whiteman Prize
 | url = http://www.ams.org/notices/200504/comm-whiteman.pdf
 | volume = 52}}.&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-12-02.&lt;/ref&gt;

Edwards is married to [[Betty Rollin]], a former [[NBC News]] correspondent, author, and [[breast cancer]] [[Cancer survivor|survivor]].&lt;ref&gt;{{citation|url=https://www.nytimes.com/1985/09/09/style/daughter-s-story-aiding-mother-s-suicide.html|title=Daughter's Story: Aiding Mother's Suicide|journal=[[New York Times]]|first=Judy|last=Klemesrud|date=September 9, 1985}}.&lt;/ref&gt;

==Books==
* ''Higher Arithmetic: An Algorithmic Introduction to Number Theory'' (2008)&lt;ref&gt;[[American Mathematical Society]], 2008, {{ISBN|978-0-8218-4439-7}}.&lt;/ref&gt;&lt;br&gt;An extension of Edwards' work in ''Essays in Constructive Mathematics'', this textbook covers the material of a typical undergraduate [[number theory]] course,&lt;ref name="wag"&gt;Review by [[Samuel S. Wagstaff, Jr.]] (2009), ''[[Mathematical Reviews]]'', {{MR|2392541}}.&lt;/ref&gt; but follows a [[Constructivism (mathematics)|constructivist]] viewpoint in focusing on [[algorithm]]s for solving problems rather than allowing purely existential solutions.&lt;ref name="wag"/&gt;&lt;ref name="lhdf"/&gt; The constructions are intended to be simple and straightforward, rather than efficient, so, unlike works on [[Computational number theory|
algorithmic number theory]], there is no analysis of how efficient they are in terms of their [[running time]].&lt;ref name="lhdf"&gt;[http://www.maa.org/maa%20reviews/HA.html Review] by Luiz Henrique de Figueiredo, [[Mathematical Association of America]], April 26, 2008.&lt;/ref&gt;
* ''Essays in Constructive Mathematics'' (2005)&lt;ref&gt;Springer-Verlag, 2005, {{ISBN|0-387-21978-1}}.&lt;/ref&gt;&lt;br&gt;Although motivated in part by the history and philosophy of mathematics, the main goal of this book is to show that advanced mathematics such as the [[fundamental theorem of algebra]], the theory of [[binary quadratic form]]s, and the [[Riemann–Roch theorem]] can be handled in a constructivist framework.&lt;ref&gt;{{citation|url=http://www.maa.org/reviews/constructiveessays.html|contribution=Essays in Constructive Mathematics by Harold M. Edwards|title=Read This! The MAA Online book review column|publisher=[[Mathematical Association of America]]|first=Bonnie|last=Schulman|date=February 22, 2005}}.&lt;/ref&gt;&lt;ref&gt;Review by Edward J. Barbeau (2005), ''[[Mathematical Reviews]]'', {{MR|2104015}}.&lt;/ref&gt;&lt;ref&gt;Review by S. C. Coutinho (2010), ''[[SIGACT|SIGACT News]]'' '''41''' (2): 33–36, {{doi|10.1145/1814370.1814372}}.&lt;/ref&gt;
* ''Linear Algebra'', Birkhäuser, (1995)
* ''Divisor Theory'' (1990)&lt;ref&gt;Birkhäuser, 1990, {{ISBN|0-8176-3448-7}}.&lt;/ref&gt;&lt;br&gt;[[Algebraic divisors]] were introduced by Kronecker as an alternative to the theory of [[Ideal (ring theory)|ideals]].&lt;ref&gt;Review by D. Ştefănescu (1993), ''[[Mathematical Reviews]]'', {{MR|1200892}}.&lt;/ref&gt; According to the citation for Edwards' Whiteman Prize, this book completes the work of Kronecker by providing "the sort of systematic and coherent exposition of divisor theory that Kronecker himself was never able to achieve."&lt;ref name="whiteman"/&gt;
* ''Galois Theory'' (1984)&lt;ref&gt;Graduate Texts in Mathematics 101, Springer-Verlag, 1984, {{ISBN|0-387-90980-X}}.&lt;/ref&gt;&lt;br&gt;[[Galois theory]] is the study of the [[Root of a function|solutions]] of [[polynomial|polynomial equations]] using abstract [[symmetry group]]s. This book puts the origins of the theory into their proper historical perspective, and carefully explains the mathematics in [[Évariste Galois]]' original manuscript (reproduced in translation).&lt;ref&gt;Review by B. Heinrich Matzat (1987), ''[[Mathematical Reviews]]'', {{MR|0743418}}.&lt;/ref&gt;&lt;ref&gt;[http://www.maa.org/programs/maa-awards/writing-awards/book-review-of-galois-theory-by-harold-m-edwards Review] by [[Peter M. Neumann]] (1987), ''[[American Mathematical Monthly]]'' '''93''': 407–411.&lt;/ref&gt;&lt;br&gt;Mathematician [[Peter M. Neumann]] won the [[Lester R. Ford]] Award of the [[Mathematical Association of America]] in 1987 for his review of this book.&lt;ref&gt;[http://www.maa.org/awards/ford.html The Lester R. Ford Award], MAA, retrieved 2010-02-01.&lt;/ref&gt;
* ''Fermat's Last Theorem: A Genetic Introduction to Algebraic Number Theory'' (1977)&lt;ref&gt;Graduate Texts in Mathematics 50, Springer-Verlag, New York, 1977, {{ISBN|0-387-90230-9}}. Reprinted with corrections, 1996, {{ISBN|978-0-387-95002-0}}, {{MR|1416327}}. Russian translation by V. L. Kalinin and A. I. Skopin. Mir, Moscow, 1980, {{MR|0616636}}.&lt;/ref&gt;&lt;br&gt;As the word "genetic" in the title implies, this book on [[Fermat's Last Theorem]] is organized in terms of the origins and historical development of the subject. It was written some years prior to [[Wiles' proof of Fermat's Last Theorem|Wiles' proof]] of the theorem, and covers research related to the theorem only up to the work of [[Ernst Kummer]], who used [[p-adic number]]s and [[Ideal (ring theory)|ideal theory]] to prove the theorem for a large class of exponents, the [[regular prime]]s.&lt;ref&gt;[http://projecteuclid.org/euclid.bams/1183548007 Review] by Charles J. Parry (1981), ''Bulletin of the AMS'' '''4''' (2): 218–222.&lt;/ref&gt;&lt;ref&gt;Review by [[William C. Waterhouse]] (1983), ''[[Mathematical Reviews]]'', {{MR|0616635}}.&lt;/ref&gt;
* ''Riemann's Zeta Function'' (1974)&lt;ref&gt;Pure and Applied Mathematics 58, Academic Press, 1974. Republished by Dover Publications, 2001, {{ISBN|978-0-486-41740-0}}.&lt;/ref&gt;&lt;br&gt;This book concerns the [[Riemann zeta function]] and the [[Riemann hypothesis]] on the location of the zeros of this function. It includes a translation of Riemann's original paper on these subjects, and analyzes this paper in depth; it also covers methods of computing the function such as [[Euler–Maclaurin summation]] and the [[Riemann–Siegel formula]]. However, it omits related research on other [[Riemann zeta function|zeta function]]s with analogous properties to Riemann's function, as well as more recent work on the [[large sieve]] and density estimates.&lt;ref&gt;Review by Harvey Cohn (1975), ''SIAM Review'' '''17''' (4): 697–699, {{doi|10.1137/1017086}}.&lt;/ref&gt;&lt;ref&gt;Review by Robert Spira (1976), ''Historia Mathematica'' '''3''' (4): 489–490, {{doi|10.1016/0315-0860(76)90087-2}}.&lt;/ref&gt;&lt;ref&gt;Review by [[Bruce C. Berndt]], ''[[Mathematical Reviews]]'', {{MR|0466039}}.&lt;/ref&gt;
* ''Advanced Calculus: A Differential Forms Approach'' (1969)&lt;ref&gt;Houghton–Mifflin, 1969. Reprinted with corrections by Krieger Publishing, 1980. Republished again by Birkhäuser, 1993, {{ISBN|0-8176-3707-9}}.&lt;/ref&gt;&lt;br&gt;This textbook uses [[differential form]]s as a unifying approach to [[multivariate calculus]]. Most chapters are self-contained. As an aid to learning the material, several important tools such as the [[implicit function theorem]] are described first in the simplified setting of [[affine map]]s before being extended to [[differentiable map]]s.&lt;ref&gt;Review by Nick Lord (1996), ''The Mathematical Gazette'' '''80''' (489): 629–630, {{doi|10.2307/3618555}}.&lt;/ref&gt;&lt;ref&gt;Review by R. S. Booth (1982), ''[[Mathematical Reviews]]'', {{MR|0587115}}.&lt;/ref&gt;

==See also==
*[[Edwards curve]] and [[Twisted Edwards curve]]

==References==
{{reflist|30em}}

==External links==
* [http://www.math.nyu.edu/faculty/edwardsd Web page at New York University]

{{Authority control}}

{{DEFAULTSORT:Edwards, Harold M.}}
[[Category:1936 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Number theorists]]
[[Category:Harvard University alumni]]
[[Category:Columbia University faculty]]
[[Category:Harvard University faculty]]
[[Category:New York University faculty]]
[[Category:Historians of mathematics]]
[[Category:Guggenheim Fellows]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:People from Champaign, Illinois]]
[[Category:Mathematicians from Illinois]]</text>
      <sha1>9ej5e5v0yx019pab7lecm2x2hnvg99i</sha1>
    </revision>
  </page>
  <page>
    <title>Identity theorem</title>
    <ns>0</ns>
    <id>3553654</id>
    <revision>
      <id>871411588</id>
      <parentid>865709286</parentid>
      <timestamp>2018-11-30T21:47:26Z</timestamp>
      <contributor>
        <ip>205.175.106.125</ip>
      </contributor>
      <comment>/* Proof */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4134">In [[complex analysis]], a branch of [[mathematics]], the '''identity theorem''' for [[holomorphic function]]s states: given functions ''f'' and ''g'' holomorphic on a [[Domain (mathematical analysis)|domain]] ''D'' (open and connected subset), if ''f'' = ''g'' on some &lt;math&gt;S \subseteq D&lt;/math&gt;, &lt;math&gt;S &lt;/math&gt; having an [[Limit point|accumulation point]], then ''f'' = ''g'' on ''D''. 

Thus a holomorphic function is completely determined by its values on a (possibly quite small) neighborhood in ''D''. This is not true for real-differentiable functions. In comparison, holomorphy, or complex-differentiability, is a much more rigid notion. Informally, one sometimes summarizes the theorem by saying holomorphic functions are "hard" (as opposed to, say, continuous functions which are "soft").

The underpinning fact from which the theorem is established is the [[Analyticity of holomorphic functions|developability of a holomorphic function into its Taylor series]].

The connectedness assumption on the domain ''D'' is necessary. For example, if ''D'' consists of two disjoint [[open sets|open set]], &lt;math&gt;f&lt;/math&gt; can be &lt;math&gt;0&lt;/math&gt; on one open set, and &lt;math&gt;1&lt;/math&gt; on another, while &lt;math&gt;g&lt;/math&gt; is &lt;math&gt;0&lt;/math&gt; on one, and &lt;math&gt;2&lt;/math&gt; on another.

== Lemma ==

If two holomorphic functions ''f'' and ''g'' on a domain ''D'' agree on a set S which has an accumulation point ''c'' in ''D'', then ''f = g'' on a disk in &lt;math&gt;D&lt;/math&gt; centered at &lt;math&gt;c&lt;/math&gt;.

To prove this, it is enough to show that &lt;math&gt;f^{(n)}(c)= g^{(n)}(c)&lt;/math&gt; for all &lt;math&gt;n\geq 0&lt;/math&gt;. 

If this is not the case, let ''m'' be the smallest nonnegative integer with &lt;math&gt;f^{(m)}(c)\ne g^{(m)}(c)&lt;/math&gt;. By holomorphy, we have the following Taylor series representation in some open neighborhood U of ''c'':

:&lt;math&gt;
\begin{align}
(f - g)(z) &amp;{}=(z - c)^m  \cdot \left[\frac{(f - g)^{(m)}(c)}{m!} + \frac{(z - c) \cdot (f - g)^{(m+1)}(c)}{(m+1)!} + \cdots  \right]  \\[6pt]  
           &amp;{}=(z - c)^m  \cdot h(z)
\end{align}
&lt;/math&gt;

By continuity, ''h'' is non-zero in some small open disk ''B'' around ''c''. But then ''f''&amp;nbsp;&amp;minus;&amp;nbsp;''g''&amp;nbsp;≠&amp;nbsp;0 on the punctured set ''B''&amp;nbsp;&amp;minus;&amp;nbsp;{''c''}. This contradicts the assumption that ''c'' is an accumulation point of {''f = g''}.

This lemma shows that for a complex number ''a'', the [[fiber (mathematics)|fiber]] ''f''&lt;sup&gt;&amp;minus;1&lt;/sup&gt;(''a'') is a discrete (and therefore countable) set, unless ''f'' = ''a''.

== Proof ==

Define the set on which &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; have the same Taylor expansion:

:&lt;math&gt;S = \{ z \in D \mid f^{(k)}(z) = g^{(k)}(z) \text{ for all } k  \geq 0\}=\bigcap_{k=0}^\infty \{ z \in D \mid (f^{(k)}- g^{(k)})(z)=0\}.&lt;/math&gt;

We'll show &lt;math&gt;S&lt;/math&gt; is nonempty, open, and closed. Then by connectedness of &lt;math&gt;D&lt;/math&gt;, &lt;math&gt;S&lt;/math&gt; must be all of &lt;math&gt;D&lt;/math&gt;, which implies &lt;math&gt;f=g&lt;/math&gt; on &lt;math&gt;S=D&lt;/math&gt;.

By the lemma, &lt;math&gt;f = g&lt;/math&gt; in a disk centered on a disk in &lt;math&gt;D&lt;/math&gt; centered at &lt;math&gt;c&lt;/math&gt;, they have the same Taylor series at &lt;math&gt;c&lt;/math&gt;, so &lt;math&gt;c\in S&lt;/math&gt;, &lt;math&gt;S&lt;/math&gt; is nonempty.

As &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are holomorphic on &lt;math&gt;D&lt;/math&gt;, &lt;math&gt;\forall w\in S&lt;/math&gt;, the Taylor series of &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; at &lt;math&gt;w&lt;/math&gt; have non-zero [[radius of convergence]]. Therefore, the open disk &lt;math&gt;B_r(w)&lt;/math&gt; also lies in ''S'' for some ''r''. So ''S'' is open.

By holomorphy of &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt;, they have holomorphic derivatives, so all &lt;math&gt;f^{(n)}, g^{(n)}&lt;/math&gt; are continuous. This means that &lt;math&gt; \{z \in D \mid (f^{(k)} - g^{(k)})(z) = 0\}&lt;/math&gt; is closed for all &lt;math&gt;k&lt;/math&gt;. &lt;math&gt;S&lt;/math&gt; is an intersection of closed sets, so it's closed

==References==
*{{cite book |author1=Ablowitz, Mark J. |author2=Fokas A. S. |title=Complex variables: Introduction and applications |publisher=Cambridge University Press |location=Cambridge, UK |year=1997 |isbn=0-521-48058-2 |oclc= |doi= |accessdate= |page=122}}

[[Category:Theorems in complex analysis]]
[[Category:Articles containing proofs]]</text>
      <sha1>ko6n01j6prvvj3kg1qxhpt5aapfnqg6</sha1>
    </revision>
  </page>
  <page>
    <title>Integrated information theory</title>
    <ns>0</ns>
    <id>27453461</id>
    <revision>
      <id>846640266</id>
      <parentid>843887221</parentid>
      <timestamp>2018-06-20T01:08:35Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 6 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38702">[[File:Phi-iit-symbol.svg|frame|[[Phi]], the symbol for integrated information.]]
'''Integrated information theory''' ('''IIT''') attempts to explain what [[consciousness]] is and why it might be associated with certain physical systems. Given any such system, the theory predicts whether that system is conscious, to what degree it is conscious, and what particular experience it is having (see [[#Central Identity|Central identity]]). According to IIT, a system's consciousness is determined by its [[Causality|causal]] properties and is therefore an intrinsic, fundamental property of any physical system.&lt;ref name=Tononi2016&gt;{{Cite journal|last=Tononi|first=Giulio|last2=Boly|first2=Melanie|last3=Massimini|first3=Marcello|last4=Koch|first4=Christof|title=Integrated information theory: from consciousness to its physical substrate|url=http://www.nature.com/doifinder/10.1038/nrn.2016.44|journal=Nature Reviews Neuroscience|volume=17|issue=7|pages=450–461|doi=10.1038/nrn.2016.44|pmid=27225071}}&lt;/ref&gt;

IIT was proposed by neuroscientist [[Giulio Tononi]] in 2004, and has been continuously developed over the past decade. The latest version of the theory, labeled ''IIT 3.0'', was published in 2014.&lt;ref name=":2"&gt;{{Cite journal|title = From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0|url = https://dx.doi.org/10.1371/journal.pcbi.1003588|journal = PLoS Comput Biol|date = 2014-05-08|pmc = 4014402|pmid = 24811198|pages = e1003588|volume = 10|issue = 5|doi = 10.1371/journal.pcbi.1003588|first = Masafumi|last = Oizumi|first2 = Larissa|last2 = Albantakis|first3 = Giulio|last3 = Tononi|bibcode = 2014PLSCB..10E3588O}}&lt;/ref&gt;&lt;ref name="Scholarpedia"&gt;{{Cite web|title = Integrated information theory - Scholarpedia|url = http://www.scholarpedia.org/article/Integrated_information_theory|website = www.scholarpedia.org|accessdate = 2015-11-23}}&lt;/ref&gt;

== Overview ==

=== Relationship to the "hard problem of consciousness" ===
[[David Chalmers]] has argued that any attempt to explain consciousness in purely physical terms (i.e. to start with the laws of physics as they are currently formulated and derive the necessary and inevitable existence of consciousness) eventually runs into the so-called "[[hard problem of consciousness|hard problem]]". Rather than try to start from physical principles and arrive at consciousness, IIT "starts with consciousness" (accepts the existence of consciousness as certain) and reasons about the properties that a postulated physical substrate would have to have in order to account for it. The ability to perform this jump from [[phenomenology (philosophy)|phenomenology]] to mechanism rests on IIT's assumption that if a conscious experience can be fully accounted for by an underlying physical system, then the properties of the physical system must be constrained by the properties of the experience.

Specifically, IIT moves from phenomenology to mechanism by attempting to identify the essential properties of conscious experience (dubbed "axioms") and, from there, the essential properties of conscious physical systems (dubbed "postulates").

=== Axioms: essential properties of experience ===
[[File:Axioms and postulates of integrated information theory.jpg|thumb|Axioms and postulates of integrated information theory.]]
The axioms are intended to capture the essential aspects of every conscious experience. Every axiom should apply to every possible experience.

The wording of the axioms has changed slightly as the theory has developed, and the most recent and complete statement of the axioms is as follows: 
{{Pull quote| 
* '''Intrinsic existence:''' Consciousness ''exists'': each experience is ''actual''—indeed, that my experience here and now exists (it is real) is the only fact I can be sure of immediately and absolutely. Moreover, my experience exists from its own ''intrinsic'' perspective, independent of external observers (it is intrinsically real or actual).  
* '''Composition:''' Consciousness is ''structured'': each experience is composed of multiple ''phenomenological distinctions'', elementary or higher-order. For example, within one experience I may distinguish a book, a blue color, a blue book, the left side, a blue book on the left, and so on.  
* '''Information:''' Consciousness is ''specific'': each experience is the ''particular way it is''—being composed of a specific set of specific phenomenal distinctions—thereby differing from other possible experiences (''differentiation''). For example, an experience may include phenomenal distinctions specifying a large number of spatial locations, several positive concepts, such as a bedroom (as opposed to no bedroom), a bed (as opposed to no bed), a book (as opposed to no book), a blue color (as opposed to no blue), higher-order "bindings" of first-order distinctions, such as a blue book (as opposed to no blue book), as well as many negative concepts, such as no bird (as opposed to a bird), no bicycle (as opposed to a bicycle), no bush (as opposed to a bush), and so on. Similarly, an experience of pure darkness and silence is the particular way it is—it has the specific quality it has (no bedroom, no bed, no book, no blue, nor any other object, color, sound, thought, and so on). And being that way, it necessarily differs from a large number of alternative experiences I could have had but I am not actually having.  
* '''Integration:''' Consciousness is ''unified'': each experience is ''irreducible'' to non-interdependent, disjoint subsets of phenomenal distinctions. Thus, I experience a whole visual scene, not the left side of the visual field independent of the right side (and vice versa). For example, the experience of seeing the word "BECAUSE" written in the middle of a blank page is irreducible to an experience of seeing "BE" on the left plus an experience of seeing "CAUSE" on the right. Similarly, seeing a blue book is irreducible to seeing a book without the color blue, plus the color blue without the book. 
* '''Exclusion:''' Consciousness is ''definite'', in content and spatio-temporal grain: each experience has the set of phenomenal distinctions it has, neither less (a subset) nor more (a superset), and it flows at the speed it flows, neither faster nor slower. For example, the experience I am having is of seeing a body on a bed in a bedroom, a bookcase with books, one of which is a blue book, but I am not having an experience with less content—say, one lacking the phenomenal distinction blue/not blue, or colored/not colored; or with more content—say, one endowed with the additional phenomenal distinction high/low blood pressure. Moreover, my experience flows at a particular speed—each experience encompassing say a hundred milliseconds or so—but I am not having an experience that encompasses just a few milliseconds or instead minutes or hours.
|author=[[Giulio Tononi|Dr. Giulio Tononi]]|title=''Integrated information theory''|source=Scholarpedia&lt;ref name="Scholarpedia" /&gt;}}

=== Postulates: properties required of the physical substrate ===
The axioms describe regularities in conscious experience, and IIT seeks to explain these regularities. What could account for the fact that every experience exists, is structured, is differentiated, is unified, and is definite? IIT argues that the existence of an underlying causal system with these same properties offers the most parsimonious explanation. Thus a physical system, if conscious, is so by virtue of its causal properties.

The properties required of a conscious physical substrate are called the "postulates," since the existence of the physical substrate is itself only postulated (remember, IIT maintains that the only thing one can be sure of is the existence of one's own consciousness). In what follows, a "physical system" is taken to be a set of elements, each with two or more internal states, inputs that influence that state, and outputs that are influenced by that state (neurons or logic gates are the natural examples). Given this definition of "physical system", the postulates are:
{{Pull quote|
* '''Intrinsic existence:''' To account for the intrinsic existence of experience, a system constituted of elements in a state must exist intrinsically (be actual): specifically, in order to exist, it must have cause-effect power, as there is no point in assuming that something exists if nothing can make a difference to it, or if it cannot make a difference to anything. Moreover, to exist from its own intrinsic perspective, independent of external observers, a system of elements in a state must have cause-effect power upon itself, independent of extrinsic factors. Cause-effect power can be established by considering a [[#Cause-effect space|cause-effect space]] with an axis for every possible state of the system in the past (causes) and future (effects). Within this space, it is enough to show that an "intervention" that sets the system in some initial state (cause), keeping the state of the elements outside the system fixed (background conditions), can lead with probability different from chance to its present state; conversely, setting the system to its present state leads with probability above chance to some other state (effect).
* '''Composition:''' The system must be structured: subsets of the elements constituting the system, composed in various combinations, also have cause-effect power within the system. Thus, if a system '''ABC''' is constituted of elements '''A''', '''B''', and '''C''', any subset of elements (its power set), including '''A''', '''B''', '''C''', '''AB''', '''AC''', '''BC''', as well as the entire system, '''ABC''', can compose a mechanism having cause-effect power. Composition allows for elementary (first-order) elements to form distinct higher-order mechanisms, and for multiple mechanisms to form a structure.    
* '''Information:''' The system must specify a [[#CEStruct|cause-effect structure]] that is the particular way it is: a specific set of specific [[#CER|cause-effect repertoires]]—thereby differing from other possible ones (differentiation). A cause-effect repertoire characterizes in full the cause-effect power of a mechanism within a system by making explicit all its cause-effect properties. It can be determined by perturbing the system in all possible ways to assess how a mechanism in its present state makes a difference to the probability of the past and future states of the system. Together, the cause-effect repertoires specified by each composition of elements within a system specify a cause-effect structure. ...
* '''Integration:''' The cause-effect structure specified by the system must be unified: it must be intrinsically irreducible to that specified by non-interdependent sub-systems obtained by [[#unipartition|unidirectional partitions]]. Partitions are taken unidirectionally to ensure that cause-effect power is intrinsically irreducible—from the system's intrinsic perspective—which implies that every part of the system must be able to both affect and be affected by the rest of the system. Intrinsic irreducibility can be measured as integrated information ([[#bigphi|"big phi"]] or &lt;math display="inline"&gt;\Phi&lt;/math&gt;, a non-negative number), which quantifies to what extent the cause-effect structure specified by a system's elements changes if the system is partitioned (cut or reduced) along its [[#SysMIP|minimum partition]] (the one that makes the least difference). By contrast, if a partition of the system makes no difference to its cause-effect structure, then the whole is reducible to those parts. If a whole has no cause-effect power above and beyond its parts, then there is no point in assuming that the whole exists in and of itself: thus, having irreducible cause-effect power is a further prerequisite for existence. This postulate also applies to individual mechanisms: a subset of elements can contribute a specific aspect of experience only if their combined cause-effect repertoire is irreducible by a minimum partition of the mechanism ([[#smallphi|"small phi"]] or &lt;math display="inline"&gt;\varphi&lt;/math&gt;).
* '''Exclusion:''' The cause-effect structure specified by the system must be definite: it is specified over a single set of elements—neither less nor more—the one over which it is maximally irreducible from its intrinsic perspective ([[#phimax|&lt;math display="inline"&gt;\Phi^{\textrm{Max}}&lt;/math&gt;]]), thus laying maximal claim to intrinsic existence. ... With respect to causation, this has the consequence that the "winning" cause-effect structure excludes alternative cause-effect structures specified over overlapping elements, otherwise there would be causal overdetermination. ... The exclusion postulate can be said to enforce Occam's razor (entities should not be multiplied beyond necessity): it is more parsimonious to postulate the existence of a single cause-effect structure over a system of elements—the one that is maximally irreducible from the system's intrinsic perspective—than a multitude of overlapping cause-effect structures whose existence would make no further difference. The exclusion postulate also applies to individual mechanisms: a subset of elements in a state specifies the cause-effect repertoire that is maximally irreducible ([[#MICE|MICE]]) within the system (&lt;math display="inline"&gt;\Phi^{\textrm{Max}}&lt;/math&gt;), called a core concept, or [[#Concept|concept]] for short. Again, it cannot additionally specify a cause-effect repertoire overlapping over the same elements, because otherwise the difference a mechanism makes would be counted multiple times. ... Finally, the exclusion postulate also applies to spatio-temporal grains, implying that a conceptual structure is specified over a definite grain size in space (either quarks, atoms, neurons, neuronal groups, brain areas, and so on) and time (either microseconds, milliseconds, seconds, minutes, and so on), the one at which &lt;math display="inline"&gt;\Phi&lt;/math&gt; reaches a maximum. ... Once more, this implies that a mechanism cannot specify a cause-effect repertoire at a particular temporal grain, and additional effects at a finer or coarser grain, otherwise the differences a mechanism makes would be counted multiple times.
|author=[[Giulio Tononi|Dr. Giulio Tononi]]|title=''Integrated information theory''|source=Scholarpedia&lt;ref name="Scholarpedia" /&gt;}}

=== Mathematics: formalization of the postulates ===
For a complete and thorough account of the mathematical formalization of IIT, see reference.&lt;ref name=":2" /&gt; What follows is intended as a brief summary, adapted from,&lt;ref&gt;{{Cite journal|title = The Intrinsic Cause-Effect Power of Discrete Dynamical Systems—From Elementary Cellular Automata to Adapting Animats|url = http://www.mdpi.com/1099-4300/17/8/5472|journal = Entropy|date = 2015-07-31|pages = 5472–5502|volume = 17|issue = 8|doi = 10.3390/e17085472|language = en|first = Larissa|last = Albantakis|first2 = Giulio|last2 = Tononi|bibcode = 2015Entrp..17.5472A}}&lt;/ref&gt; of the most important quantities involved. Pseudocode for the algorithms used to calculate these quantities can be found at reference.&lt;ref name=":3"&gt;{{Cite web|title = CSC-UW/iit-pseudocode|url = https://github.com/CSC-UW/iit-pseudocode|website = GitHub|access-date = 2016-01-29}}&lt;/ref&gt;

A '''system''' refers to a set of elements, each with two or more internal states, inputs that influence that state, and outputs that are influenced by that state. A '''mechanism''' refers to a subset of system elements. The mechanism-level quantities below are used to assess the integration of any given mechanism, and the system-level quantities are used to assess the integration of sets of mechanisms ("sets of sets").

In order to apply the IIT formalism to a system, its full transition probability matrix (TPM) must be known. The TPM specifies the probability with which any state of a system transitions to any other system state. Each of the following quantities is calculated in a bottom-up manner from the system's TPM.

{|class="wikitable"
|-
! scope="col" | Mechanism-level quantities
|- id=CER
| A '''cause-effect repertoire''' &lt;math display="inline"&gt;\textrm{CER}(m_t,\, Z_{t\pm1})=\{p_{\textrm{cause}}(z_{t-1}|m_t),\, p_{\textrm{effect}}(z_{t+1}|m_t)\}&lt;/math&gt; is a set of two probability distributions, describing how the mechanism &lt;math display="inline"&gt;M_t&lt;/math&gt; in its current state &lt;math display="inline"&gt;m_t&lt;/math&gt; constrains the past and future states of the sets of system elements &lt;math display="inline"&gt;Z_{t-1}&lt;/math&gt; and &lt;math display="inline"&gt;Z_{t+1}&lt;/math&gt;, respectively. 
Note that &lt;math display="inline"&gt;Z_{t-1}&lt;/math&gt; may be different from &lt;math display="inline"&gt;Z_{t+1}&lt;/math&gt;, since the elements that a mechanism affects may be different from the elements that affect it.  
|- id=Partition
|  A '''partition''' &lt;math display="inline"&gt;P = \{M_1, Z_1;M_2,Z_2\}&lt;/math&gt; is a grouping of system elements, where the connections between the parts &lt;math display="inline"&gt;\{M_1,Z_1\}&lt;/math&gt; and &lt;math display="inline"&gt;\{M_2,Z_2\}&lt;/math&gt; are injected with independent noise. For a simple binary element &lt;math display="inline"&gt;A&lt;/math&gt; which outputs to a simple binary element &lt;math display="inline"&gt;B&lt;/math&gt;, injecting the connection &lt;math display="inline"&gt;A \to B&lt;/math&gt; with independent noise means that the input value which &lt;math display="inline"&gt;A&lt;/math&gt; receives, &lt;math display="inline"&gt;0&lt;/math&gt; or &lt;math display="inline"&gt;1&lt;/math&gt;, is entirely independent of the actual state of &lt;math display="inline"&gt;B&lt;/math&gt;, thus rendering &lt;math display="inline"&gt;B&lt;/math&gt; causally ineffective. 
&lt;math display="inline"&gt;P_{t\pm1}&lt;/math&gt; denotes a pair of partitions, one of which is considered when looking at a mechanism's causes, and the other of which is considered when looking at its effects.
|- id=EMD
| The '''[[earth mover's distance]]''' &lt;math display="inline"&gt;\textrm{EMD}(p_1,\, p_2)&lt;/math&gt; is used to measure distances between probability distributions &lt;math display="inline"&gt;p_1&lt;/math&gt; and &lt;math display="inline"&gt;p_2&lt;/math&gt;. The EMD depends on the user's choice of ground distance between points in the metric space over which the probability distributions are measured, which in IIT is the system's state space. When computing the EMD with a system of simple binary elements, the ground distance between system states is chosen to be their [[Hamming distance]]. 
|- id=Smallphi
| '''Integrated information''' &lt;math display="inline"&gt;\varphi&lt;/math&gt; measures the irreducibility of a cause-effect repertoire with respect to partition &lt;math display="inline"&gt;P_{t\pm1}&lt;/math&gt;, obtained by combining the irreducibility of its constituent cause and effect repertoires with respect to the same partitioning. 
The irreducibility of the cause repertoire with respect to &lt;math display="inline"&gt;P_{t-1}&lt;/math&gt; is given by &lt;math display="inline"&gt;\varphi_{\textrm{cause}}(m_t,\, Z_{t-1},\, P_{t-1}) = \textrm{EMD}(p_{\textrm{cause}}(z_{t-1}|m_t),\, p_{\textrm{cause}}(z_{1,t-1}|m_{1,t}) \times p_{\textrm{cause}}(z_{2,t-1}|m_{2,t}))&lt;/math&gt;, and similarly for the effect repertoire.

Combined, &lt;math display="inline"&gt;\varphi_{\textrm{cause}}&lt;/math&gt; and &lt;math display="inline"&gt;\varphi_{\textrm{effect}}&lt;/math&gt; yield the irreducibility of the &lt;math display="inline"&gt;\textrm{CER}&lt;/math&gt; as a whole: &lt;math display="inline"&gt;\varphi(m_t,\, Z_{t\pm1},\, P_{t\pm1}) = \min(\varphi_{\textrm{cause}}(m_t,\, Z_{t-1},\, P_{t-1}), \varphi_{\textrm{effect}}(m_t,\, Z_{t+1},\, P_{t+1})).&lt;/math&gt;. 
|- id=MechMIP
| The '''minimum-information partition''' of a mechanism and its purview is given by &lt;math display="inline"&gt;\textrm{MIP}(m_t,\, Z_{t\pm1})=\operatorname*{\arg\,\min}_{P_{t\pm1}} \, (\varphi(m_t,\, Z_{t\pm1},\, P_{t\pm1}))&lt;/math&gt;. The minimum-information partition is the partitioning that least affects a cause-effect repertoire. For this reason, it is sometimes called the '''minimum-difference partition'''. 
Note that the minimum-information "partition", despite its name, is really a ''pair'' of partitions. We call these partitions &lt;math display="inline"&gt;\textrm{MIP}_{\textrm{cause}}&lt;/math&gt; and &lt;math display="inline"&gt;\textrm{MIP}_{\textrm{effect}}&lt;/math&gt;.
|- id=MICE
| There is at least one choice of elements over which a mechanism's cause-effect repertoire is maximally irreducible (in other words, over which its &lt;math display="inline"&gt;\varphi&lt;/math&gt; is highest). We call this choice of elements &lt;math display="inline"&gt;Z^*_{t\pm1}=\{Z^*_{t-1},\, Z^*_{t+1}\}&lt;/math&gt;, and say that this choice specifies a '''maximally irreducible cause-effect repertoire'''. 
Formally, &lt;math display="inline"&gt; Z^*_{t-1} = \{\operatorname*{\arg\,\max}_{Z_{t-1}} \, (\varphi_{\textrm{cause}}(m_t,\, Z_{t-1},\, \textrm{MIP}_{\textrm{cause}}))\}&lt;/math&gt; and &lt;math display="inline"&gt; Z^*_{t+1} = \{\operatorname*{\arg\,\max}_{Z_{t+1}} \, (\varphi_{\textrm{effect}}(m_t,\, Z_{t+1},\, \textrm{MIP}_{\textrm{effect}}))\}&lt;/math&gt;.
|- id=Concept
| The '''concept''' &lt;math display="inline"&gt;\textrm{CER}(m_t,\, Z^*_{t\pm1})=\{p_{\textrm{cause}}(z^*_{t-1}|m_t),\, p_{\textrm{effect}}(z^*_{t+1}|m_t)\}&lt;/math&gt; is the maximally irreducible cause-effect repertoire of mechanism&lt;math display="inline"&gt;M_t&lt;/math&gt; in its current state &lt;math display="inline"&gt;m_t&lt;/math&gt; over &lt;math display="inline"&gt;Z^*_{t\pm1}&lt;/math&gt;, and describes the causal role of &lt;math display="inline"&gt;M_t&lt;/math&gt; within the system. Informally, &lt;math display="inline"&gt;Z^*_{t\pm1}&lt;/math&gt; is the concept's '''purview''', and specifies what the concept "is about". 
The '''intrinsic cause-effect power''' of &lt;math display="inline"&gt;m_t&lt;/math&gt; is the concept's strength, and is given by:
&lt;math display="inline"&gt;\varphi^{\textrm{Max}}(m_t) = \varphi(m_t,\, Z^*_{t\pm1},\, \textrm{MIP}) = \min(\varphi_{\textrm{cause}}(m_t,\, Z^*_{t-1},\, \textrm{MIP}_{\textrm{cause}}),\, \varphi_{\textrm{effect}}(m_t,\, Z^*_{t+1},\, \textrm{MIP}_{\textrm{effect}}))&lt;/math&gt;
|-
|}

{|class="wikitable"
|-
! scope="col" | System-level quantities
|- id=CEStruct
| A '''cause-effect structure''' &lt;math display="inline"&gt;C(s_t)&lt;/math&gt; is the set of concepts specified by all mechanisms with &lt;math display="inline"&gt;\varphi^{\textrm{Max}}(m_t) &gt; 0&lt;/math&gt; within the system &lt;math display="inline"&gt;S_t&lt;/math&gt; in its current state &lt;math display="inline"&gt;s_t&lt;/math&gt;. If a system turns out to be conscious, its cause-effect structure is often referred to as a '''conceptual''' '''structure'''. 
|- id=unipartition
| A '''unidirectional partition''' &lt;math display="inline"&gt;P_{\to} = \{S_1,S_2\}&lt;/math&gt; is a grouping of system elements where the connections from the set of elements &lt;math display="inline&gt;S_1&lt;/math&gt; to &lt;math display="inline"&gt;S_2&lt;/math&gt; are injected with independent noise.
|- id=XEMD
| The '''extended earth mover's distance''' &lt;math display="inline"&gt;\textrm{XEMD}(C_1,\, C_2)&lt;/math&gt; is used to measure the minimal cost of transforming cause-effect structure &lt;math display="inline"&gt;C_1&lt;/math&gt; into structure &lt;math display="inline"&gt;C_2&lt;/math&gt;. Informally, one can say that–whereas the EMD transports the probability of a system state over the distance between two system states–the XEMD transports the strength of a concept over the distance between two concepts. 
In the XEMD, the "earth" to be transported is intrinsic cause-effect power (&lt;math display="inline"&gt;\varphi^{\textrm{Max}}&lt;/math&gt;), and the ground distance between concepts &lt;math display="inline"&gt;A&lt;/math&gt; and &lt;math display="inline"&gt;B&lt;/math&gt; with cause repertoires &lt;math display="inline"&gt;A_{\textrm{cause}}&lt;/math&gt; and &lt;math display="inline"&gt;B_{\textrm{cause}}&lt;/math&gt; and effect repertoires &lt;math display="inline"&gt;A_{\textrm{effect}}&lt;/math&gt; and &lt;math display="inline"&gt;B_{\textrm{effect}}&lt;/math&gt; is given by &lt;math display="inline"&gt;\textrm{EMD}(A_{\textrm{cause}},\, B_{\textrm{cause}}) + \textrm{EMD}(A_{\textrm{effect}},\, B_{\textrm{effect}})&lt;/math&gt;. 
|- id=Bigphi
| '''Integrated (conceptual) information''' &lt;math display="inline"&gt;\Phi(s_t,\, P_{\to}) = \textrm{XEMD}(C(s_t)|C(s_t,\, P_{\to}))&lt;/math&gt; measures the irreducibility of a cause-effect structure with respect to a unidirectional partition. &lt;math display="inline"&gt;\Phi&lt;/math&gt; captures how much the cause-effect repertoires of the system's mechanisms are altered and how much intrinsic cause effect power (&lt;math display="inline"&gt;\varphi^{\textrm{Max}}&lt;/math&gt;) is lost due to partition &lt;math display="inline"&gt;P_{\to}&lt;/math&gt;.
|- id=SysMIP
| The '''minimum-information partition''' of a set of elements in a state is given by &lt;math display="inline"&gt;\textrm{MIP}(s_t)=\operatorname*{\arg\,\min}_{P_\to} \, (\Phi(s_t,\, \,P_{\to}))&lt;/math&gt;. The minimum-information partition is the unidirectional partition that least affects a cause-effect structure &lt;math display="inline"&gt;C(s_t)&lt;/math&gt;.
|- id=phimax
| The '''intrinsic cause-effect power''' of a set of elements in a state is given by &lt;math display="inline"&gt;\Phi^{\textrm{Max}}(s^*_t) = \Phi(s^*_t,\, \textrm{MIP}(s^*_t)) &lt;/math&gt;, such that for any other &lt;math display="inline"&gt;S_t&lt;/math&gt; with &lt;math display="inline"&gt;(S_t \cap S^*_t) \neq \emptyset&lt;/math&gt;, &lt;math display="inline"&gt;\Phi(s_t) \leq \Phi(s^*_t)&lt;/math&gt;. According to IIT, a system's &lt;math display="inline"&gt;\Phi^{\textrm{Max}}&lt;/math&gt; is the degree to which it can be said to exist. 
|- id="MICS"
| A '''complex''' is a set of elements &lt;math display="inline"&gt;S^*_t&lt;/math&gt; with &lt;math display="inline"&gt;\Phi^{\textrm{Max}} = \Phi(s^*_t) &gt; 0&lt;/math&gt;, and thus specifies a '''maximally irreducible cause-effect structure''', also called a '''conceptual structure'''. According to IIT, complexes are conscious entities.  
|-
|}

==== Cause-effect space ====
For a system of &lt;math&gt;N&lt;/math&gt; simple binary elements, '''cause-effect space''' is formed by &lt;math&gt;2\times2^N&lt;/math&gt; axes, one for each possible past and future state of the system. Any cause-effect repertoire &lt;math&gt;R&lt;/math&gt;, which specifies the probability of each possible past and future state of the system, can be easily plotted as a point in this high-dimensional space: The position of this point along each axis is given by the probability of that state as specified by &lt;math&gt;R&lt;/math&gt;. If a point is also taken to have a scalar magnitude (which can be informally thought of as the point's "size", for example), then it can easily represent a concept: The concept's cause-effect repertoire specifies the location of the point in cause-effect space, and the concept's &lt;math&gt;\varphi^{\textrm{Max}}&lt;/math&gt; value specifies that point's magnitude.

In this way, a conceptual structure &lt;math&gt;C&lt;/math&gt; can be plotted as a '''constellation''' of points in cause-effect space. Each point is called a '''star''', and each star's magnitude (&lt;math&gt;\varphi^{\textrm{Max}}&lt;/math&gt;) is its '''size'''.

=== Central identity ===
IIT addresses the [[Mind–body problem|mind-body problem]] by proposing an identity between phenomenological properties of experience and causal properties of physical systems: ''The conceptual structure specified by a complex of elements in a state is identical to its experience.''

Specifically, the form of the conceptual structure in cause-effect space completely specifies the quality of the experience, while the irreducibility &lt;math&gt;\Phi^{\textrm{Max}} &lt;/math&gt; of the conceptual structure specifies the level to which it exists (i.e., the complex's level of consciousness).  The maximally irreducible cause-effect repertoire of each concept within a conceptual structure specifies what the concept contributes to the quality of the experience, while its irreducibility &lt;math&gt;\varphi^{\textrm{Max}} &lt;/math&gt; specifies how much the concept is present in the experience.

According to IIT, an experience is thus an intrinsic property of a complex of mechanisms in a state.

== Extensions ==
The calculation of even a modestly-sized system's &lt;math&gt;\Phi^{\textrm{Max}}&lt;/math&gt; is often computationally intractable, so efforts have been made to develop heuristic or proxy measures of integrated information. For example, Masafumi Oizumi has developed &lt;math&gt;\Phi^*&lt;/math&gt;, a practical approximation for integrated information that solves the theoretical shortcomings of previously proposed proxy measures,&lt;ref&gt;{{Cite journal|title = Measuring integrated information from the decoding perspective|arxiv = 1505.04368|date = 2015-05-17|first = Masafumi|last = Oizumi|first2 = Shun-ichi|last2 = Amari|first3 = Toru|last3 = Yanagawa|first4 = Naotaka|last4 = Fujii|first5 = Naotsugu|last5 = Tsuchiya|doi=10.1371/journal.pcbi.1004654|volume=12|issue=1|journal=PLOS Computational Biology|page=e1004654|bibcode=2016PLSCB..12E4654O}}&lt;/ref&gt; such as the one proposed by Adam Barrett.&lt;ref&gt;{{cite journal | last1 = Barrett | first1 = A.B. | last2 = Seth | first2 = A.K. | year = 2011 | title = Practical measures of integrated information for time-series data | url = | journal = PLoS Comput. Biol. | volume = 7 | issue = 1| page = e1001052 | doi=10.1371/journal.pcbi.1001052| bibcode = 2011PLSCB...7E1052B }}&lt;/ref&gt;

A significant computational challenge in calculating integrated information is finding the [[Minimum-information partition|Minimum Information Partition]] of a neural system, which requires iterating through all possible network partitions. To solve this problem, Daniel Toker has suggested using the most modular decomposition of a network as an extremely quick proxy for the Minimum Information Partition.&lt;ref&gt;{{Cite arXiv|title =Moving Past the Minimum Information Partition: How to Quickly and Accurately Calculate Integrated Information|arxiv = 1605.01096|date = 2016-05-03|first = Daniel|last = Toker|first2 = Friedrich|last2 = Sommer}}&lt;/ref&gt;

== Related experimental work ==
While the algorithm&lt;ref name=":3" /&gt; for assessing a system's &lt;math&gt;\Phi^{\textrm{Max}}&lt;/math&gt; and conceptual structure is relatively straightforward, its high [[time complexity]] makes it computationally intractable for many systems of interest. Heuristics and approximations can sometimes be used to provide ballpark estimates of a complex system's integrated information, but precise calculations are often impossible. These computational challenges, combined with the already difficult task of reliably and accurately assessing consciousness under experimental conditions, make testing many of the theory's predictions difficult.

Despite these challenges, researchers have attempted to use measures of information integration and differentiation to assess levels of consciousness in a variety of subjects.&lt;ref&gt;{{Cite journal|title = Cortical reactivity and effective connectivity during REM sleep in humans|journal = Cognitive Neuroscience|date = 2010-09-01|issn = 1758-8936|pmc = 2930263|pmid = 20823938|pages = 176–183|volume = 1|issue = 3|doi = 10.1080/17588921003731578|first = M.|last = Massimini|first2 = F.|last2 = Ferrarelli|first3 = Mj|last3 = Murphy|first4 = R.|last4 = Huber|first5 = Ba|last5 = Riedner|first6 = S.|last6 = Casarotto|first7 = G.|last7 = Tononi}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|title = Breakdown in cortical effective connectivity during midazolam-induced loss of consciousness|journal = Proceedings of the National Academy of Sciences of the United States of America|date = 2010-02-09|issn = 1091-6490|pmc = 2823915|pmid = 20133802|pages = 2681–2686|volume = 107|issue = 6|doi = 10.1073/pnas.0913008107|first = Fabio|last = Ferrarelli|first2 = Marcello|last2 = Massimini|first3 = Simone|last3 = Sarasso|first4 = Adenauer|last4 = Casali|first5 = Brady A.|last5 = Riedner|first6 = Giuditta|last6 = Angelini|first7 = Giulio|last7 = Tononi|first8 = Robert A.|last8 = Pearce|bibcode = 2010PNAS..107.2681F}}&lt;/ref&gt; For instance, a recent study using a less computationally-intensive proxy for &lt;math&gt;\Phi^{\textrm{Max}}&lt;/math&gt; was able to reliably discriminate between varying levels of consciousness in wakeful, sleeping (dreaming vs. non-dreaming), anesthetized, and comatose (vegetative vs. minimally-conscious vs. locked-in) individuals.&lt;ref&gt;{{Cite journal|title = A Theoretically Based Index of Consciousness Independent of Sensory Processing and Behavior|url = http://stm.sciencemag.org/content/5/198/198ra105|journal = Science Translational Medicine|date = 2013-08-14|issn = 1946-6234|pmid = 23946194|pages = 198ra105–198ra105|volume = 5|issue = 198|doi = 10.1126/scitranslmed.3006294|language = en|first = Adenauer G.|last = Casali|first2 = Olivia|last2 = Gosseries|first3 = Mario|last3 = Rosanova|first4 = Mélanie|last4 = Boly|first5 = Simone|last5 = Sarasso|first6 = Karina R.|last6 = Casali|first7 = Silvia|last7 = Casarotto|first8 = Marie-Aurélie|last8 = Bruno|first9 = Steven|last9 = Laureys|first10 = Marcello|last10 = Massimini}}&lt;/ref&gt;

IIT also makes several predictions which fit well with existing experimental evidence, and can be used to explain some counterintuitive findings in consciousness research.&lt;ref&gt;{{Cite web|title = Integrated information theory - Scholarpedia|url = http://www.scholarpedia.org/article/Integrated_information_theory#Predictions_and_explanations|website = www.scholarpedia.org|access-date = 2016-01-28}}&lt;/ref&gt;  For example, IIT can be used to explain why some brain regions, such as the [[cerebellum]] do not appear to contribute to consciousness, despite their size and/or functional importance.

== Reception ==
{{expand section|date=May 2016}}
Integrated Information Theory has received both broad criticism and support.

=== Support ===
Neuroscientist [[Christof Koch]], who has helped to develop the theory, has called IIT "the only really promising fundamental theory of consciousness".&lt;ref&gt;{{Cite news|title = Sizing Up Consciousness by Its Bits|url = https://www.nytimes.com/2010/09/21/science/21consciousness.html|newspaper = The New York Times|date = 2010-09-20|access-date = 2015-11-23|issn = 0362-4331|first = Carl|last = Zimmer}}&lt;/ref&gt;  Technologist [[Virgil Griffith]] says "IIT is currently the leading theory of consciousness."&lt;ref&gt;{{Cite news|title=How valid is Giulio Tononi's mathematical formula for consciousness?|url=https://www.quora.com/How-valid-is-Giulio-Tononis-mathematical-formula-for-consciousness/answer/Virgil-Griffith-1}}&lt;/ref&gt;

=== Criticism ===
Challenges to IIT:
* IIT proposes conditions which are necessary for consciousness, but are not entirely sufficient.&lt;ref name=":0"&gt;{{Cite web|title = Shtetl-Optimized  » Blog Archive » Why I Am Not An Integrated Information Theorist (or, The Unconscious Expander)|url = http://www.scottaaronson.com/blog/?p=1799|website = www.ScottAaronson.com|access-date = 23 November 2015}}&lt;/ref&gt; 
* IIT claims that all of its axioms are self-evident.&lt;ref name=":1"&gt;{{cite journal|last1 = Cerullo|first1 = Michael A.|last2 = Kording|first2 = Konrad P.|authorlink2=Konrad Kording|title = The Problem with Phi: A Critique of Integrated Information Theory|journal = PLOS Computational Biology|date = 17 September 2015|volume = 11|issue = 9|pages = e1004286|doi = 10.1371/journal.pcbi.1004286|bibcode = 2015PLSCB..11E4286C}}&lt;/ref&gt; 
* Since IIT is not a [[Functionalism (philosophy of mind)|functionalist]] theory of consciousness, criticisms of non-functionalism have been levied against it.&lt;ref name=":1" /&gt; 
* The limits of IIT's definition of consciousness have led to criticism.&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt;

== See also ==
{{div col|colwidth=30em}}
* [[Causality]]
* [[Consciousness]]
* [[Hard problem of consciousness]]
* [[Mind–body problem]]
* [[Neural correlates of consciousness]]
* [[Phenomenology (philosophy)]]
* [[Phenomenology (psychology)]]
* [[Philosophy of mind]]
* [[Qualia]]
* [[Sentience]]
{{div col end}}

== References ==
{{Reflist}}

== External links ==
{{Commons category}}

=== Related papers ===
* [http://www.nature.com/nrn/journal/v17/n7/full/nrn.2016.44.html Integrated information theory: from consciousness to its physical substrate]
* [http://www.scholarpedia.org/article/Integrated_information_theory Integrated information theory (Scholarpedia)]
* [http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1003588 From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0]
* [http://www.architalbiol.org/aib/article/viewFile/15056/23165867 Integrated Information Theory: An Updated Account (2012) (First presentation of IIT 3.0)]
* [[doi:10.2307/25470707|Integrated Information Theory: A Provisional Manifesto (2008) (IIT 2.0)]]
* [http://www.biomedcentral.com/1471-2202/5/42 An Information Integration Theory of Consciousness (2004) (IIT 1.0)]

=== Websites ===
* [http://integratedinformationtheory.org/ IntegratedInformationTheory.org]: resource for learning about IIT; features a graphical user interface to [https://github.com/wmayner/pyphi PyPhi].
*{{IEP|int-info|Integrated Information Theory of Consciousness}}

=== Software ===
* [https://github.com/wmayner/pyphi PyPhi]: an open-source Python library for calculating integrated information and related quantities. 
** [http://integratedinformationtheory.org/calculate.html Graphical user interface]
** [https://pyphi.readthedocs.io/en/stable/ Documentation]

=== Books ===
* [http://amzn.com/030790721X Phi: A Voyage from the Brain to the Soul]

=== News articles ===
* Nautilus (2017): [http://nautil.us/issue/47/consciousness/is-matter-conscious Is Matter Conscious?]
* Aeon (2016): [https://aeon.co/essays/could-machines-have-become-self-aware-without-our-knowing-it Consciousness creep]
* MIT Technology Review (2014): [http://www.technologyreview.com/news/531146/what-it-will-take-for-computers-to-be-conscious/ What It Will Take for Computers to Be Conscious]
* Wired (2013): [https://www.wired.com/2013/11/christof-koch-panpsychism-consciousness/ A Neuroscientist's Radical Theory of How Networks Become Conscious]
* The New Yorker (2013): [http://www.newyorker.com/tech/elements/how-much-consciousness-does-an-iphone-have How Much Consciousness Does an iPhone Have?]
* New York Times (2010): [https://www.nytimes.com/2010/09/21/science/21consciousness.html?pagewanted=2&amp;_r=1&amp;sq=integrated%20information%20theory&amp;st=nyt&amp;scp=1 Sizing Up Consciousness by Its Bits]
*  Scientific American (2009): [http://www.scientificamerican.com/article.cfm?id=a-theory-of-consciousness A "Complex" Theory of Consciousness]
* IEEE Spectrum (2008): [http://spectrum.ieee.org/computing/hardware/a-bit-of-theory-consciousness-as-integrated-information A Bit of Theory: Consciousness as Integrated Information Theory]

=== Talks ===
* David Chalmers (2014): [https://www.ted.com/talks/david_chalmers_how_do_you_explain_consciousness How do you explain consciousness?]
* Christof Koch (2014): [https://www.youtube.com/watch?v=LGd8p-GSLgY The Integrated Information Theory of Consciousness]


{{Consciousness}}

[[Category:Consciousness studies]]
[[Category:Information theory]]</text>
      <sha1>9qado4e887rjc64xjejlpnrlt55c5os</sha1>
    </revision>
  </page>
  <page>
    <title>International Society for Mathematical Sciences</title>
    <ns>0</ns>
    <id>4703917</id>
    <revision>
      <id>809106547</id>
      <parentid>807652340</parentid>
      <timestamp>2017-11-07T04:29:36Z</timestamp>
      <contributor>
        <username>NihlusBOT</username>
        <id>31996569</id>
      </contributor>
      <minor/>
      <comment>Bot: removed invalid image syntax from file parameters ([[Wikipedia:Bots/Requests for approval/NihlusBOT 7|Task 7]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1998">{{Infobox Organization
| name         = International Society for Mathematical Sciences
| image        = International Society for Mathematical Sciences (emblem).png
| image_border = 
| size         = 20x190
| caption      = 
| formation    = 1922
| type         = 
| headquarters = [[Osaka, Chine|2-1-18 Minami Hanadaguchi-cho, Sakai-ku, Sakai, Osaka 590-0075, Japan]]
| location     = 
| membership   =  
| language     = Japanese, Russian
| leader_title = Rapretator
| leader_name  = [[Lluís Ginel]]
| key_people   = Robert and Mitch
| num_staff    = 
| budget       = 
| website      = http://www.jams.or.jp/
}}
The '''International Society for Mathematical Sciences''' is a mathematics society, primarily based in [[Japan]]. It was formerly known as the [[Japanese Association of Mathematical Sciences]], and was founded in 1948 by Tatsujiro Shimizu.&lt;ref&gt;[http://www-groups.dcs.st-and.ac.uk/~history/Societies/JAMS.html The Japanese Association of Mathematical Sciences], MacTutor history of mathematics archive.&lt;/ref&gt;&lt;ref&gt;Hiroshi Sugiyama, [http://www.jams.or.jp/shimizu/shimizu.html Biographical sketch of Shimizu from the ISMS web site], reprinted from ''Mathematica Japonica'' '''40'''(1): 2.&lt;/ref&gt;

The ISMS publishes a bimonthly scientific journal, [http://www.jams.or.jp/notice/scmj/smj.html ''Scientiae Mathematicae Japonicae''] ({{ISSN|1346-0447}}), which was formed in 2001 from the merger of two journals previously published by the same society, [http://www.jams.or.jp/notice/mj/mj.html ''Mathematica Japonica''], founded in 1948, and ''Scientiae Mathematicae'', which published nine issues over three volumes in 1998, 1999, and 2000. In addition the ISMS holds an annual meeting and publishes a [[Japanese language]] mathematics magazine, ''Kaiho'', and a monthly newsletter, ''Notices from the ISMS''.

==References==
{{reflist}}

==External links==

* [http://www.jams.or.jp/ International Society for Mathematical Sciences] 

{{math-stub}}

[[Category:Mathematical societies]]</text>
      <sha1>7bqih7yyecyjt18c49wxr2ut2uhggb5</sha1>
    </revision>
  </page>
  <page>
    <title>Invariant differential operator</title>
    <ns>0</ns>
    <id>6935363</id>
    <revision>
      <id>846641402</id>
      <parentid>736335501</parentid>
      <timestamp>2018-06-20T01:19:44Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 3 [[bibcode|bibcode(s)]] and 1 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8584">In [[mathematics]] and [[theoretical physics]], an '''invariant differential operator''' is a kind of [[Map (mathematics)|mathematical map]] from some objects to an object of similar type. These objects are typically [[Function (mathematics)|functions]] on &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, functions on a [[manifold]], [[vector (geometric)|vector]] valued functions, [[vector field]]s, or, more generally, [[Section (category theory)|sections]] of a [[vector bundle]].

In an invariant differential operator &lt;math&gt;D&lt;/math&gt;, the term ''[[differential operator]]'' indicates that the value &lt;math&gt;Df&lt;/math&gt; of the map depends only on &lt;math&gt;f(x)&lt;/math&gt; and the [[derivative]]s of &lt;math&gt;f&lt;/math&gt; in &lt;math&gt;x&lt;/math&gt;. The word ''[[Invariant (mathematics)|invariant]]'' indicates that the operator contains some [[Symmetry in mathematics|symmetry]]. This means that there is a [[Group (mathematics)|group]] &lt;math&gt;G&lt;/math&gt; with a [[group action]] on the functions (or other objects in question) and this action is preserved by the operator:

:&lt;math&gt;D(g\cdot f)=g\cdot (Df).&lt;/math&gt;

Usually, the action of the group has the meaning of a [[change of coordinates]] (change of observer) and the invariance means that the operator has the same expression in all admissible coordinates.

==Invariance on homogeneous spaces==
Let ''M''&amp;nbsp;=&amp;nbsp;''G''/''H'' be a [[homogeneous space]] for a [[Lie group]] G and a Lie subgroup H. Every [[Representation (mathematics)|representation]] &lt;math&gt;\rho:H\rightarrow\mathrm{Aut}(\mathbb{V})&lt;/math&gt; gives rise to a [[vector bundle]]

:&lt;math&gt;V=G\times_{H}\mathbb{V}\;\text{where}\;(gh,v)\sim(g,\rho(h)v)\;\forall\;g\in G,\;h\in H\;\text{and}\;v\in\mathbb{V}.&lt;/math&gt;

Sections &lt;math&gt;\varphi\in\Gamma(V)&lt;/math&gt; can be identified with

:&lt;math&gt;\Gamma(V)=\{\varphi:G\rightarrow\mathbb{V}\;:\;\varphi(gh)=\rho(h^{-1})\varphi(g)\;\forall\;g\in G,\; h\in H\}.&lt;/math&gt;

In this form the group ''G'' acts on sections via

:&lt;math&gt;(\ell_g \varphi)(g')=\varphi(g^{-1}g').&lt;/math&gt;

Now let ''V'' and ''W'' be two [[vector bundle]]s over ''M''. Then a differential operator

:&lt;math&gt;d:\Gamma(V)\rightarrow\Gamma(W)&lt;/math&gt;

that maps sections of ''V'' to sections of ''W'' is called invariant if

:&lt;math&gt;d(\ell_g \varphi) = \ell_g (d\varphi).&lt;/math&gt;

for all sections &lt;math&gt;\varphi&lt;/math&gt; in &lt;math&gt;\Gamma(V)&lt;/math&gt; and elements ''g'' in ''G''.  All linear invariant differential operators on homogeneous [[parabolic geometry (differential geometry)|parabolic geometries]], i.e. when ''G'' is semi-simple and ''H'' is a parabolic subgroup, are given dually by homomorphisms of [[generalized Verma module]]s.

==Invariance in terms of abstract indices==
Given two [[Connection (mathematics)|connections]] &lt;math&gt;\nabla&lt;/math&gt; and &lt;math&gt;\hat{\nabla}&lt;/math&gt; and a one form &lt;math&gt;\omega&lt;/math&gt;, we have
:&lt;math&gt;\nabla_{a}\omega_{b}=\hat{\nabla}_{a}\omega_{b}-Q_{ab}{}^{c}\omega_{c}&lt;/math&gt;
for some tensor &lt;math&gt;Q_{ab}{}^{c}&lt;/math&gt;.&lt;ref&gt;{{cite book|author=Penrose and Rindler|title=Spinors and Space Time|publisher=Cambridge Monographs on Mathematical Physics|year=1987}}&lt;/ref&gt;  Given an equivalence class of connections &lt;math&gt;[\nabla]&lt;/math&gt;, we say that an operator is invariant if the form of the operator does not change when we change from one connection in the equivalence class to another. For example, if we consider the equivalence class of all [[torsion tensor|torsion free]] connections, then the tensor Q is symmetric in its lower indices, i.e. &lt;math&gt;Q_{ab}{}^{c}=Q_{(ab)}{}^{c}&lt;/math&gt;. Therefore we can compute
:&lt;math&gt;\nabla_{[a}\omega_{b]}=\hat{\nabla}_{[a}\omega_{b]},&lt;/math&gt;
where brackets denote skew symmetrization. This shows the invariance of the exterior derivative when acting on one forms.
Equivalence classes of connections arise naturally in differential geometry, for example:

* in [[conformal geometry]] an equivalence class of connections is given by the Levi Civita connections of all [[Metric (mathematics)|metrics]] in the conformal class;
*  in [[projective geometry]] an equivalence class of connection is given by all connections that have the same [[geodesics]];
* in [[CR geometry]] an equivalence class of connections is given by the Tanaka-Webster connections for each choice of pseudohermitian structure

==Examples==
# The usual [[gradient]] operator &lt;math&gt;\nabla&lt;/math&gt; acting on real valued functions on [[Euclidean space]] is invariant with respect to all [[Euclidean transformation]]s.
# The [[exterior derivative|differential]] acting on functions on a manifold with values in [[one-form#Differential one-forms|1-form]]s (its expression is &lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;d=\sum_j \partial_j \, dx_j&lt;/math&gt; &lt;br&gt;in any local coordinates) is invariant with respect to all smooth transformations of the manifold (the action of the transformation on [[differential form]]s is just the [[pullback (differential geometry)|pullback]]).
# More generally, the [[exterior derivative]] &lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;d:\Omega^n(M)\rightarrow\Omega^{n+1}(M)&lt;/math&gt; &lt;br&gt;that acts on ''n''-forms of any smooth manifold M is invariant with respect to all smooth transformations. It can be shown that the exterior derivative is the only linear invariant differential operator between those bundles.
# The [[Dirac operator]] in physics is invariant with respect to the [[Poincaré group]] (if we choose the proper [[group action|action]] of the [[Poincaré group]] on spinor valued functions. This is, however, a subtle question and if we want to make this mathematically rigorous, we should say that it is invariant with respect to a group which is a [[Double covering group|double cover]] of the Poincaré group)
# The [[conformal Killing equation]] &lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;X^a \mapsto \nabla_{(a}X_{b)}-\frac{1}{n}\nabla_c X^c g_{ab}&lt;/math&gt;&lt;br&gt; is a conformally invariant linear differential operator between vector fields and symmetric trace-free tensors.

==Conformal invariance==
&lt;gallery&gt;
Image:conformalsphere.jpg| The sphere (here shown as a red circle) as a conformal homogeneous manifold.
&lt;/gallery&gt;
Given a metric 
:&lt;math&gt;g(x,y)=x_{1}y_{n+2}+x_{n+2}y_{1}+\sum_{i=2}^{n+1}x_{i}y_{i}&lt;/math&gt;

on &lt;math&gt;\mathbb{R}^{n+2}&lt;/math&gt;, we can write the [[sphere]] &lt;math&gt;S^{n}&lt;/math&gt; as the space of generators of the [[Null cone|nil cone]]

:&lt;math&gt;S^{n}=\{[x]\in\mathbb{RP}_{n+1}\; :\; g(x,x)=0 \}.&lt;/math&gt;

In this way, the flat model of [[conformal geometry]] is the sphere &lt;math&gt;S^{n}=G/P&lt;/math&gt; with &lt;math&gt;G=SO_{0}(n+1,1)&lt;/math&gt; and P the stabilizer of a point in &lt;math&gt;\mathbb{R}^{n+2}&lt;/math&gt;. A classification of all linear conformally invariant differential operators on the sphere is known (Eastwood and Rice, 1987).&lt;ref&gt;{{cite journal|last=M.G. Eastwood and J.W. Rice|title=Conformally invariant differential operators on Minkowski space and their curved analogues|journal=Commun. Math. Phys. |volume=109 |year=1987 |issue=2 |pages=207–228}}&lt;/ref&gt;

==See also==
*[[Differential operator]]s
*[[Laplace invariant]]
*[[Invariant factorization of LPDOs]]

==Notes==
&lt;references /&gt;

&lt;ref&gt;{{cite journal|last1=Dobrev|first1=Vladimir|title=Canonical construction of intertwining differential operators associated with representations of real semisimple Lie groups|journal=Rept. Math. Phys.|date=1988|volume=25|issue=2|pages=159–181|doi=10.1016/0034-4877(88)90050-X|url=http://www.journals.elsevier.com/reports-on-mathematical-physics/|bibcode=1988RpMP...25..159D}}&lt;/ref&gt;

==References==
*{{cite book|last=Slovák|first=Jan|title=[ftp://www.math.muni.cz/pub/math/people/Slovak/papers/vienna.ps Invariant Operators on Conformal Manifolds]|year=1993|publisher=Research Lecture Notes, University of Vienna (Dissertation)}}
*{{cite book|last1 = Kolář|first1=Ivan|last2=Michor|first2=Peter|last3=Slovák|first3=Jan|url=http://www.emis.de/monographs/KSM/kmsbookh.pdf|format=PDF|title=Natural operators in differential geometry|year = 1993|publisher = Springer-Verlag, Berlin, Heidelberg, New York}}
*{{cite journal|last1=Eastwood|first1=M. G.|last2=Rice|first2=J. W.|title=Conformally invariant differential operators on Minkowski space and their curved analogues|journal=Commun. Math. Phys. |volume=109 |year=1987 |issue=2 |pages=207–228|bibcode=1987CMaPh.109..207E|doi=10.1007/BF01215221}}
*{{cite journal|last=Kroeske|first=Jens|title=Invariant bilinear differential pairings on parabolic geometries |year=2008|journal=Phd thesis from the University of Adelaide|arxiv=0904.3311|bibcode=2009PhDT.......274K}}

{{DEFAULTSORT:Invariant Differential Operator}}
[[Category:Differential geometry]]
[[Category:Differential operators]]</text>
      <sha1>fk8of2soopzb8tygokjdujbrny20vpr</sha1>
    </revision>
  </page>
  <page>
    <title>Jacob Fox</title>
    <ns>0</ns>
    <id>34422078</id>
    <revision>
      <id>865267046</id>
      <parentid>861310479</parentid>
      <timestamp>2018-10-22T20:35:11Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/Am149072|Am149072]] ([[User talk:Am149072|talk]]) to last version by Tom.Reding</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4948">{{for|the baseball player|Jacob Fox (baseball)}}
{{Infobox scientist
| name              = Jacob Fox
| image             = Jacob fox (cropped).jpg
| image_size        = 
| caption           = Fox at [[Mathematical Research Institute of Oberwolfach|Oberwolfach]] in 2016
| birth_date        = {{Birth year and age|1984}}
| birth_place       = 
| death_date        = 
| death_place       = 
| nationality       = [[United States|American]]
| fields            = [[Mathematics]]
| workplaces        = [[Stanford University]]
| alma_mater        = [[Princeton University]]&lt;br /&gt;[[Massachusetts Institute of Technology|MIT]]
| doctoral_advisor  = [[Benny Sudakov]]
| doctoral_students = 
| known_for         = 
| awards            = {{plainlist|1=
*[[Morgan Prize]] (2006)
*Dénes Kőnig Prize (2010)
*[[Mathematical Research Institute of Oberwolfach#Oberwolfach Prize|Oberwolfach Prize]] (2016)
}}                                     
}}
'''Jacob Fox''' (born '''Jacob Licht''' in 1984) is an [[United States|American]] [[mathematician]]. He is a professor at [[Stanford University]]. His research interests are in Hungarian-style [[combinatorics]], particularly [[Ramsey theory]], [[extremal graph theory]], [[combinatorial number theory]], and probabilistic methods in combinatorics.

Fox grew up in [[West Hartford, Connecticut]] and attended [[Hall High School (Connecticut)|Hall High School]]. As a senior he won second place overall and first place in his category in the annual [[Regeneron Science Talent Search|Intel Science Talent Search]],&lt;ref&gt;{{citation|url=https://student.societyforscience.org/intel-sts-2002|title=Intel STS 2002|accessdate=2017-12-09}}&lt;/ref&gt;
also winning the Karl Menger Memorial Prize of the [[American Mathematical Society]] for his project. The project was titled "Rainbow Ramsey Theory: Rainbow Arithmetic Progressions and Anti-Ramsey Results"&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200208/people.pdf|department=Mathematics People|title=AMS Menger Prizes at the 2002 ISEF|first=Gisele|last=Goldstein|journal=Notices of the American Mathematical Society|page=940|volume=49|issue=8|date=September 2002}}&lt;/ref&gt;
and was based on a research project he did at a six-week summer camp in mathematics at the [[Massachusetts Institute of Technology]] (MIT);&lt;ref&gt;{{citation|url=http://news.mit.edu/2001/siemans-1107|title=High-schoolers face off in national sci-tech contest at MIT|magazine=MIT News|date=November 7, 2001|publisher=Massachusetts Institute of Technology}}&lt;/ref&gt;
he also participated in an earlier high school mathematics program at [[Ohio State University]].&lt;ref name=morgan/&gt;

Fox became an undergraduate at MIT, and was awarded the 2006 [[Morgan Prize]] for several research publications in combinatorics.&lt;ref name=morgan&gt;{{citation|url=http://www.ams.org/notices/200604/comm-morgan.pdf|journal=Notices of the American Mathematical Society|title=2005 Morgan Prize|pages=479–480|volume=53|issue=4|date=April 2006}}&lt;/ref&gt;
Fox completed his [[Ph.D.]] in 2010 from [[Princeton University]]; his dissertation, supervised by [[Benny Sudakov]], was titled ''Ramsey Numbers''.&lt;ref&gt;{{MathGenealogy |id=151144}}&lt;/ref&gt;
After working in the mathematics department at MIT from 2010 to 2014, he joined the faculty of [[Stanford University]] in 2015.&lt;ref&gt;{{citation|url=http://math.mit.edu/~fox/jacobfoxcv15.pdf|title=Curriculum vitae|date=February 2015|accessdate=2017-12-09}}&lt;/ref&gt;

In 2010, Fox was awarded the Dénes Kőnig Prize, an early-career award of the [[Society for Industrial and Applied Mathematics]] Activity Group on Discrete Mathematics.&lt;ref name=s4s&gt;{{citation|url=https://www.societyforscience.org/content/ssp-blog/alumnus-jacob-fox-wins-konig-prize|title=Alumnus Jacob Fox Wins the Konig Prize|publisher=Society for Science &amp; the Public|date=August 23, 2010|accessdate=2017-12-09}}&lt;/ref&gt;
He was an invited speaker at the [[International Congress of Mathematicians]] in 2014.&lt;ref&gt;{{citation|url=http://www.icm2014.org/en/program/scientific/section.html|title=Invited section lectures, ICM 2014|accessdate=2017-12-09}}&lt;/ref&gt;  He was awarded the [[Mathematical Research Institute of Oberwolfach#Oberwolfach Prize|Oberwolfach Prize]] in 2016.&lt;ref&gt;{{citation|url=https://www.mfo.de/math-in-public/prizes/oberwolfach-prize/|title=Oberwolfach Prize 2016 for Junior Mathematicians|accessdate=2018-02-11}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

==External links==
*[http://stanford.edu/~jacobfox/ Home page]

{{Authority control}}

{{DEFAULTSORT:Fox, Jacob}}
[[Category:1984 births]]
[[Category:Living people]]
[[Category:21st-century American mathematicians]]
[[Category:Combinatorialists]]
[[Category:Princeton University alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:Stanford University faculty]]
[[Category:People from West Hartford, Connecticut]]
[[Category:Morgan Prize winners]]


{{US-mathematician-stub}}</text>
      <sha1>dnzebpbckjd0f04j96ogoztmf5fcjle</sha1>
    </revision>
  </page>
  <page>
    <title>James Challis</title>
    <ns>0</ns>
    <id>457816</id>
    <revision>
      <id>853301290</id>
      <parentid>811272089</parentid>
      <timestamp>2018-08-03T19:45:41Z</timestamp>
      <contributor>
        <username>Reyk</username>
        <id>378651</id>
      </contributor>
      <minor/>
      <comment>/* Physicist */ -typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12276">{{EngvarB|date=August 2014}}
{{Use dmy dates|date=August 2014}}
{{Infobox scientist
|name              = James Challis
|image             = James Challis.jpg
|birth_date        = {{Birth date|df=yes|1803|12|12}}
|birth_place       = [[Braintree, Essex]]
|death_date        = {{death date and age|df=yes|1882|12|3|1803|12|12}}
|death_place       = [[Cambridge]]
|residence         =
|citizenship       =
|nationality       = English
|ethnicity         =
|field             = [[Astronomy]]
|work_institutions = [[Cambridge Observatory]]
|alma_mater        =
|doctoral_advisor  =
|doctoral_students =
|known_for         = [[Discovery of Neptune|Not discovering Neptune]]
|influences        =
|influenced        =
|prizes            =
|religion          =
}}
'''James Challis''' [[Fellow of the Royal Society|FRS]] (12 December 1803&amp;nbsp;– 3 December 1882) was an English clergyman, [[physicist]] and [[astronomer]]. [[Plumian Professor of Astronomy and Experimental Philosophy]] and the director of the [[Cambridge Observatory]], he investigated a wide range of physical phenomena though made few lasting contributions outside [[astronomy]]. He is best remembered for his missed opportunity to discover the [[planet]] [[Neptune]] in 1846.

==Early life==
Challis was born in [[Braintree, Essex]] where his father, John Challis, was a [[stonemason]]. After attending various local schools, he graduated from [[Trinity College, Cambridge]] in 1825 as [[Senior Wrangler]] and first [[Smith's prize]]man.&lt;ref&gt;{{acad|CHLS821J|James Challis}}&lt;/ref&gt; He was elected a [[Fellow#Oxford, Cambridge and Dublin|fellow]] of Trinity in 1826 and was [[ordination|ordained]] in 1830. He held the [[benefice]] of [[Papworth Everard]], Cambridgeshire from the college until 1852. In 1831 Challis married Sarah Copsey, ''née'' Chandler, a widow, and consequently resigned his Trinity fellowship. The couple had a son and a daughter.&lt;ref name="ODNB"&gt;Clerke (2006)&lt;/ref&gt;

==Plumian professor==
In 1836, he became director of the Cambridge Observatory and Plumian Professor, holding the latter post until his death. He lectured in all areas of [[physics]]. As examiner for the Smith's prize, he appraised the early work of [[G. G. Stokes]], [[Arthur Cayley]], [[John Couch Adams]], [[William Thomson, 1st Baron Kelvin|William Thomson]] (later Lord Kelvin), [[Peter Guthrie Tait]] and [[James Clerk Maxwell]]. For over a decade, in correspondence and publications, Challis repeatedly disagreed with Stokes's conclusions from his research.&lt;ref&gt;David B. Wilson, '[[Stokes, Sir George Gabriel, first baronet (1819–1903)|Stokes, Sir George Gabriel, first baronet]]', Oxford Dictionary of National Biography, Oxford University Press, 2004&lt;/ref&gt;

Challis was referee for Thomson and for Stokes in their respective applications for chairs at the [[University of Glasgow]], and for Maxwell at [[University of Aberdeen|Aberdeen]]. He and Thomson together set and examined the [[Adams prize]] topic on [[Saturn's rings]], won by Maxwell in 1857.

==Cambridge Observatory==
Challis succeeded [[George Biddell Airy]] at the observatory and gradually improved the instrumentation and [[accuracy and precision|accuracy]] of observations. He made some early observations of the fracture of [[comet]] [[3D/Biela]] into two pieces on 15 January 1846 and re-observed both fragments in 1852. He published over 60 [[scientific paper]]s recording other observations of comets and [[asteroid]]s. He invented the [[meteoroscope]] (1848) and the [[transit-reducer]] (1849). Challis published twelve volumes of ''Astronomical Observations Made at the Observatory of Cambridge''.&lt;ref name="ODNB"/&gt;

He and his wife lived at the observatory as genial hosts for 25 years, though Challis once left his wife to guard an intruder while he summoned assistance. Challis eventually resigned the observatory post because of the [[chronic stress]] that his inability to keep up with processing new astronomical observations was causing him. His predecessor Airy had taken a more relaxed attitude. He was succeeded by Adams though he maintained his professorship until his death.&lt;ref name="ODNB"/&gt;

==The search for the eighth planet==
{{main|Discovery of Neptune}}
In 1846, Airy finally persuaded a skeptical Challis to join in the search for an eighth planet in the [[solar system]]. Adams had predicted the location of such a planet as early as 1844, based on irregularities in the orbit of [[Uranus]]. Adams failed to promote his prediction successfully and there was little enthusiasm for a systematic search of the heavens until Airy's intervention. Challis finally began his, somewhat reluctant, search in July 1846, unaware that Frenchman [[Urbain Le Verrier]] had independently made an identical prediction. German astronomer [[Johann Gottfried Galle]], assisted by [[Heinrich Louis d'Arrest]], finally confirmed Le Verrier's prediction on 23 September. The planet was named "Neptune". It soon became apparent from Challis's notebooks that he had observed Neptune twice, a month earlier, failing to make the identification through lack of diligence and a current star chart.&lt;ref name="ODNB"/&gt;

Challis was full of remorse but blamed his neglect on the pressing business of catching up on the backlog of astronomical observations from the observatory. As he reflected in a letter to Airy of 12 October 1846:&lt;ref&gt;Eggen (1970–1981) ''p.''187&lt;/ref&gt;

{{ quotation | I have been greatly mortified to find that my observations would have shewn me the planet in the early part of August if I had only discussed them. ... I delayed doing this ... chiefly because I was making a grand effort to reduce the vast numbers of comet observations which I have accumulated and this occupied the whole of my time. }}

==Physicist==
Challis also worked in [[hydrodynamics]] and in [[optics]] where he supported the [[Light#Wave theory|wave theory of light]] and advanced the theory of a [[luminiferous ether]] as a medium for its propagation. However, he rejected the idea that the ether was an [[Elasticity (physics)|elastic solid]], insisting that it was a [[fluid]], bringing him into conflict with Airy and Stokes. Driven by Sir [[Isaac Newton]]'s somewhat obscure assertion of "a certain most subtle spirit which pervades and lies hid in all gross bodies",&lt;ref&gt;''[[Philosophiae Naturalis Principia Mathematica]]'', 2.547&lt;/ref&gt; Challis was driven to attempt to derive all physical phenomena from a model of inert [[sphere|spherical]] [[atom]]s embedded in an elastic fluid ether,&lt;ref&gt;Challis (1869)&lt;/ref&gt; an enterprise described as an attempt at a "[[Victorian era|Victorian]] [[unified field theory]]".&lt;ref name="ODNB"/&gt; His work included a [[Mechanical explanations of gravitation|mechanical explanation of gravitation]].&lt;ref&gt;Taylor, W. B. (1876), "Kinetic Theories of Gravitation", ''Smithsonian Report'', 205–282&lt;/ref&gt; His ideas won few supporters.&lt;ref name="ODNB"/&gt;

==Theological views==
Challis took issue with [[Charles Wycliffe Goodwin]]'s views on [[Book of Genesis|Genesis]] expressed in ''[[Essays and Reviews]]'' (1860). Challis saw Genesis as an "antecedent plan" for creation, rather than a literal chronology, and argued that the [[Bible|biblical]] account could be reconciled with the [[Geologic time scale|geological record]].&lt;ref&gt;Challis (1861)&lt;/ref&gt; He went on to interpret the word "law", as used in a [[spirituality|spiritual]] sense by [[Paul the Apostle|Saint Paul]], in the sense of [[scientific law]].&lt;ref name="ODNB"/&gt;&lt;ref&gt;Challis (1871)&lt;/ref&gt;

==Assessment==
Challis published 225 papers in mathematics, physics and astronomy.&lt;ref name="eb"&gt;[Anon.] (2001)&lt;/ref&gt; He was re-elected fellow of Trinity in 1870. He died in [[Cambridge]] and was buried beside his wife in [[Mill Road Cemetery, Cambridge]]. His wealth when he died was £781 ({{Inflation|UK|781|1882|fmt=eq|cursign=£|r=-2}}).&lt;ref name="ODNB"/&gt;

Despite the embarrassment over Neptune, Challis did make genuine contributions to astronomy. His blend of theology and science was in the spirit of Stokes, and his search for a unified theory akin to the endeavours of Thomson and Maxwell. However, despite his tenacity in advocating his physical and theological theories, they had little impact,&lt;ref name="ODNB"/&gt; and in fact [[Richard Christopher Carrington|Richard Carrington]] credited him as his professor with inspiring his decision to pursue astronomy rather than become a clergyman.&lt;ref&gt;{{Citation | author1=Stuart Clark | title=The Sun Kings The Unexpected Tragedy of Richard Carrington and the Tale of How Modern Astronomy Began | publication-date=2007 | publisher=[[Princeton University Press]] | page=62| isbn=978-0-691-12660-9 }}&lt;/ref&gt; [[Olin J. Eggen]] claimed that "At a later time, or under less amiable circumstances, he would have been branded a charlatan. He would now be as forgotten as his peculiar ideas had not the events surrounding the discovery of Neptune in 1845 given him a genuine opportunity for scientific immortality. But he fumbled it."&lt;ref&gt;Eggen (1970–1981) ''p.''186&lt;/ref&gt;

==Honours and memorials==
*Fellow of the [[Royal Astronomical Society]], (1836);&lt;ref name="ODNB"/&gt;
*[[Fellow of the Royal Society]], (1848);&lt;ref name="ODNB"/&gt;
*Bronze medal at [[The Great Exhibition]] for his transit-reducer, (1851).&lt;ref name="ODNB"/&gt;
*The [[distributed.net]] UK team, originally Cambridge University and [[CIX]] based, is named "Prof. James Challis' Most Excellent UK Team" in his honour [https://web.archive.org/web/20070909023322/http://www.winwaed.com/comp/challis/climateprediction.shtml].
*[[Lunar crater]] [[Challis (crater)|Challis]] is named after him.&lt;ref&gt;{{cite book |author1=Cocks, E. E. |author2=Cocks, J. C. | date=1995 | title=Who's Who on the Moon: A Biographical Dictionary of Lunar Nomenclature | publisher=Tudor Publishers | isbn=0-936389-27-3 }}&lt;/ref&gt;

==References==
{{Reflist}}

==Bibliography==

===By Challis===
*Challis, J. (1861) ''Creation in Plan and Progress''
*{{ cite book | author=— | date=1869 | title=Notes on the Principles of Pure and Applied Calculation; and Applications of Mathematical Principles to Theories of the Physical Forces | location=Cambridge | publisher=Deighton, Bell and Co. | url=https://archive.org/details/notesonprinciple00chalrich }}
*— (1871) ''A Translation of the Epistle of the Apostle Paul to the Romans''
*— (1873) ''An Essay on the Mathematical Principles of Physics''
*— (1875) ''Remarks on the Cambridge Mathematical Studies''
*— (1880) ''Essay on the Scriptural Doctrine of Immortality''

===Obituary===
*[[James Whitbread Lee Glaisher|J. W. L. G.]] (1882–83) "[http://cdsads.u-strasbg.fr//full/seri/MNRAS/0043//0000160.000.html James Challis]" ''[[Monthly Notices of the Royal Astronomical Society]]'', '''43''': 160–79

===About Challis===
*[Anon.] (2001) "Challis, James", ''[[Encyclopædia Britannica]]'', CDROM Deluxe edition
*Clerke, A. M. (2006) "[http://www.oxforddnb.com/view/article/5024 Challis, James (1803–1882)]", rev. David B. Wilson, ''[[Oxford Dictionary of National Biography]]'', Oxford University Press, online edn, Oct 2006, accessed 17 September 2007 {{ODNBsub}}
*[[Olin J. Eggen|Eggen, O. J.]] (1970–1981) "Challis, James" in {{cite book | author=Gillespie, C.C. (ed.) | location=New York | title=Dictionary of Scientific Biography | publisher=Charles Screibner's Sons | isbn=0-684-16970-3 | pages=186–187 }}
*{{ cite book | author=Standage, T | date=2000 | title=The Neptune File: Planet Detectives and the Discovery of Worlds Unseen | isbn=0-7139-9472-X | location=London | publisher=[[Allen Lane]] }}

==External links==
* {{Gutenberg author | id=Challis,+James | name=James Challis}}
* {{Internet Archive author |sname=James Challis}}

{{Authority control}}

{{DEFAULTSORT:Challis, James}}
[[Category:1803 births]]
[[Category:1882 deaths]]
[[Category:People from Braintree, Essex]]
[[Category:English astronomers]]
[[Category:English physicists]]
[[Category:19th-century astronomers]]
[[Category:19th-century English Anglican priests]]
[[Category:People educated at Mill Hill School]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:Senior Wranglers]]
[[Category:Fellows of the Royal Society]]
[[Category:Fellows of the Royal Astronomical Society]]</text>
      <sha1>ogudc0ejm91o2812urs3xdcvwn8rqv8</sha1>
    </revision>
  </page>
  <page>
    <title>Jeffery–Williams Prize</title>
    <ns>0</ns>
    <id>18739069</id>
    <revision>
      <id>866339359</id>
      <parentid>866274835</parentid>
      <timestamp>2018-10-29T19:19:13Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>/* Recipients of the Jeffery&amp;ndash;Williams Prize */ added wikipedia links for Speicher, Halperin &amp; Lancaster</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2561">The '''Jeffery&amp;ndash;Williams Prize''' is a mathematics award presented annually by the [[Canadian Mathematical Society]].  The award is presented to individuals  in recognition of outstanding contributions to mathematical research. The first award was presented in 1968. The prize was named in honor of the mathematicians [[Ralph Lent Jeffery]] and [[Lloyd Williams (mathematician)|Lloyd Williams]].

==Recipients of the Jeffery&amp;ndash;Williams Prize==
Source: [http://cms.math.ca/Prizes/info/jw.html Canadian Mathematical Society]
{{columns-list|colwidth=30em|
* 2018 [[Gordon Douglas Slade|Gordon Slade]]
* 2017 [[Robert McCann (mathematician)|Robert McCann]]
*2016 [[Daniel Wise (mathematician)|Daniel Wise]]
*2015 [[Alejandro Adem]]
*2014 [[Askold Khovanskii]]
*2013 [[Zinovy Reichstein]]
*2012 [[Roland Speicher]]
*2011   [[Kai Behrend]]
*2010   [[Mikhail Lyubich]]
*2009   [[Stephen S. Kudla]]
*2008  	[[Martin T. Barlow|Martin Barlow]]
*2007 	[[Nassif Ghoussoub]]
*2006 	[[Andrew Granville]]
*2005 	[[Pierre Milman]]
*2005 	[[Edward Bierstone]]
*2004 	[[Joel Feldman]]
*2003 	[[M. Ram Murty]] 	
*2002 	[[Ed Perkins|Edwin Perkins]]
*2001 	[[David William Boyd|David Boyd]]
*2000  	Not Awarded
*1999 	[[John Friedlander]] 	
*1998 	[[George A. Elliott|George Elliott]]
*1997 	[[Stephen Halperin]]
*1996 	[[Mark Goresky]]
*1995 	[[Robert Moody|R. V. Moody]]
*1994  	[[Donald A. Dawson|D. Dawson]]
*1993 	[[James Arthur (mathematician)|James Arthur]]
*1992 	[[Israel Michael Sigal|I. M. Sigal]]
*1991 	[[Peter Lancaster]]
*1990 	[[Robert Steinberg]]
*1989 	[[Eric Charles Milner|E. C. Milner]]
*1988 	[[Joachim Lambek]]
*1987 	[[Louis Nirenberg]]
*1986  	[[Carl S. Herz|C. Herz]]
*1985 	[[Laurent C. Siebenmann]]
*1984 	[[Cathleen Synge Morawetz]]
*1983 	[[Raoul Bott]]
*1982 	[[Joseph Lipman]]
*1981 	[[Jerrold E. Marsden]]
*1980 	[[Robert Langlands]]
*1979 	[[Israel Halperin]]
*1978   [[George Grätzer|G. Gratzer]]
*1977   [[George F. D. Duff]]
*1976   [[Max Wyman]]
*1975   [[Nathan Saul Mendelsohn]]
*1974   [[Hans Zassenhaus|Hans J. Zassenhaus]]
*1973   [[Harold Scott MacDonald Coxeter]]
*1972   [[Philip J. Davis]]
*1971   [[W. T. Tutte]]
*1970   [[Wilhelmus Luxemburg|W. A. J. Luxemburg]]
*1969   R. Pyke
*1968   [[Irving Kaplansky]]
}}

==References==
{{Reflist}}

==External links==
* [http://www.cms.math.ca/ Canadian Mathematical Society]

{{DEFAULTSORT:Jeffery-Williams Prize}}
[[Category:Mathematics awards]]
[[Category:Awards established in 1968]]
[[Category:Canadian science and technology awards]]
[[Category:1968 establishments in Canada]]</text>
      <sha1>bnyabrgv6em3ysk6hxuyx3ac8nx0vn2</sha1>
    </revision>
  </page>
  <page>
    <title>Lattice path</title>
    <ns>0</ns>
    <id>42123338</id>
    <revision>
      <id>720953903</id>
      <parentid>686125403</parentid>
      <timestamp>2016-05-18T22:54:08Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7223">[[File:Lattice Path in Z2.svg|thumb|285px|Lattice path of length 5 in &lt;math&gt; \mathbb{Z}^2 &lt;/math&gt; with 
&lt;math&gt; S = \left\{ (2,0), (1,1), (0,-1) \right\}&lt;/math&gt;.|right]]

In [[combinatorics]], a '''lattice path''' &lt;math&gt;L&lt;/math&gt; in &lt;math&gt;\mathbb{Z}^d&lt;/math&gt; of length &lt;math&gt; k &lt;/math&gt; with steps in &lt;math&gt; S &lt;/math&gt;  is a sequence &lt;math&gt;v_0, v_1, \ldots, v_k \in \mathbb{Z}^d &lt;/math&gt; such that each consecutive difference &lt;math&gt; v_i - v_{i-1} &lt;/math&gt; lies in &lt;math&gt; S&lt;/math&gt;.&lt;ref name=EC1&gt;{{cite book|last=Stanley|first=Richard|title=Enumerative Combinatorics, Volume 1|date=2012|publisher=Cambridge University Press|isbn=978-1-107-60262-5|pages=21|edition=2}}&lt;/ref&gt; 
A lattice path may lie in any [[Lattice graph|lattice]] in &lt;math&gt; \mathbb{R}^d &lt;/math&gt;,&lt;ref name=EC1 /&gt; but the integer lattice &lt;math&gt;\mathbb{Z}^d&lt;/math&gt; is most commonly used.

An example of a lattice path in &lt;math&gt; \mathbb{Z}^2 &lt;/math&gt; of length 5 with steps in &lt;math&gt; S = \lbrace (2,0), (1,1), (0,-1) \rbrace &lt;/math&gt;
is &lt;math&gt; L = \lbrace (-1,-2), (0,-1), (2,-1), (2,-2), (2,-3), (4,-3) \rbrace &lt;/math&gt;.

==North-East lattice paths==
A '''North-East (NE) lattice path''' is a lattice path in &lt;math&gt; \mathbb{Z}^2 &lt;/math&gt; with steps in &lt;math&gt; S = \lbrace (0,1), (1,0) \rbrace &lt;/math&gt;. The &lt;math&gt; (0,1) &lt;/math&gt; steps are called North steps and denoted by &lt;math&gt; N &lt;/math&gt;'s;
the &lt;math&gt; (1,0) &lt;/math&gt; steps are called East steps and denoted by &lt;math&gt; E &lt;/math&gt;'s.

NE lattice paths most commonly begin at the origin. This convention allows us to encode all the information about a NE lattice path &lt;math&gt; L &lt;/math&gt;
in a single [[permutation pattern|permutation word]]. The length of the word gives us the number of steps of the lattice path, &lt;math&gt; k &lt;/math&gt;. The order of the &lt;math&gt; N &lt;/math&gt;'s and &lt;math&gt; E &lt;/math&gt;'s communicates the sequence of &lt;math&gt; L &lt;/math&gt;. Furthermore, the number of &lt;math&gt; N &lt;/math&gt;'s and the number of &lt;math&gt; E &lt;/math&gt;'s in the word determines the end point of &lt;math&gt; L &lt;/math&gt;.

If the permutation word for a NE lattice path contains &lt;math&gt; n &lt;/math&gt; &lt;math&gt; N &lt;/math&gt;steps and &lt;math&gt; e &lt;/math&gt; 
&lt;math&gt; E &lt;/math&gt; steps, and if the path begins at the origin, then the path necessarily ends at &lt;math&gt; (e,n) &lt;/math&gt;. This follows because you have "walked" exactly &lt;math&gt; n &lt;/math&gt; steps North and &lt;math&gt; e &lt;/math&gt; steps East from &lt;math&gt; (0,0) &lt;/math&gt;.

[[File:1N3E SVG.svg|thumb|500px|NE lattice paths starting from &lt;math&gt;(0,0)&lt;/math&gt; with exactly one &lt;math&gt;N&lt;/math&gt; and three &lt;math&gt;E&lt;/math&gt;'s. The endpoint is necessarily at &lt;math&gt;(3,1)&lt;/math&gt;.|center]]

==Counting lattice paths==
Lattice paths are often used to count other combinatorial objects. Similarly, there are many combinatorial objects that count the number of lattice paths of a certain kind. This occurs when the lattice paths are in [[bijection]] with the object in question. For example,

* [[Catalan number#Applications in combinatorics|Dyck paths]] are counted by the &lt;math&gt; n^{\text{th}} &lt;/math&gt; [[Catalan number]] &lt;math&gt; C_n &lt;/math&gt;. A '''Dyck path''' is a lattice path in &lt;math&gt;\mathbb{Z}^2&lt;/math&gt; from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (2n,0) &lt;/math&gt; with steps in &lt;math&gt; S = \lbrace (1,1), (1,-1) \rbrace &lt;/math&gt; that never passes below the &lt;math&gt;x&lt;/math&gt;-axis.&lt;ref name=EC2&gt;{{cite book|last=Stanley|first=Richard|title=Enumerative Combinatorics, Volume 2|date=2001|publisher=Cambridge University Press|isbn=978-0-521-78987-5|pages=173, 239}}&lt;/ref&gt; Equivalently, a Dyck path is a NE lattice path from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (n,n) &lt;/math&gt; that lies strictly below (but may touch) the diagonal &lt;math&gt; y=x &lt;/math&gt;.&lt;ref name=EC2 /&gt;&lt;ref name=Wolfram_Dyck&gt;{{cite web|title=Wolfram MathWorld|url=http://mathworld.wolfram.com/DyckPath.html|accessdate=6 March 2014}}&lt;/ref&gt;
* The [[Schröder number]]s count the number of lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (n,n) &lt;/math&gt; with steps in &lt;math&gt; (1,0), (0,1) &lt;/math&gt; and &lt;math&gt; (1,1) &lt;/math&gt; that never rise above the diagonal &lt;math&gt; y=x &lt;/math&gt;.&lt;ref name=EC2 /&gt;
* The number of NE lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (a,b) &lt;/math&gt; counts the number of [[combination]]s of &lt;math&gt; a &lt;/math&gt; objects out of a set of &lt;math&gt; a + b &lt;/math&gt; objects.

==Combinations and NE lattice paths==
NE lattice paths have close connections to the number of [[combination]]s, which are counted by the [[binomial coefficient]], and arranged in [[Pascal's triangle]]. The diagram below demonstrates some of these connections.

[[File:Walking on Pascal's Triangle SVG.svg|thumb|300px|The number of lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (2,3) &lt;/math&gt; is equal to &lt;math&gt; \binom{2+3}{2} =\binom{5}{2} = 10 &lt;/math&gt;.|center]]

The number of lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (n,k) &lt;/math&gt; is equal to the [[binomial coefficient]] &lt;math&gt; \binom{n+k}{n} &lt;/math&gt;. The diagram shows this for &lt;math&gt; 0 \leq k \leq n =4 &lt;/math&gt;. If one rotates the diagram 135° clockwise about the origin and extend it to include all &lt;math&gt; n,k \in \mathbb{N} \cup \lbrace 0 \rbrace &lt;/math&gt;, one obtains Pascal's triangle. This result is no surprise, because the &lt;math&gt; k^{\text{th}} &lt;/math&gt; entry of the &lt;math&gt; n^{\text{th}} &lt;/math&gt; row of Pascal's Triangle is the binomial coefficient 
&lt;math&gt; \binom{n}{k} &lt;/math&gt;.

===Problems and proofs===
The graphical representation of NE lattice paths lends itself to many [[bijective]] proofs involving combinations. Here are a few examples.

* &lt;math&gt; \sum_{k=0}^n \binom{n}{k} ^2 = \binom{2n}{n} &lt;/math&gt;.

''Proof'': The right-hand side is equal to the number of NE lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (n,n) &lt;/math&gt;. Each of these NE lattice paths intersects exactly one of the lattice points in the rectangular array with coordinates &lt;math&gt; (x, n-x) &lt;/math&gt; for &lt;math&gt; x \in \lbrace 0, 1, \ldots, n \rbrace &lt;/math&gt;. This is shown in the figure below for &lt;math&gt; n=4 &lt;/math&gt;: Every NE lattice path from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (4,4) &lt;/math&gt; intersects exactly one of the colored nodes.

[[Image:NE nodes SVG.svg|thumb|Each NE lattice path passes through exactly one colored node.|center]]

On the left-hand side, the [[binomial coefficient]] squared, &lt;math&gt; \binom{n}{k}^2&lt;/math&gt;, represents two copies of the set of NE lattice paths from
&lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (k,n-k) &lt;/math&gt; attached endpoint to start point. Rotate the second copy 90° clockwise. This does not change the combinatorics of the object: &lt;math&gt; \binom{n}{k} = \binom{n}{n-k} &lt;/math&gt;. So the total number of lattice paths remains the same.

[[Image:Squared.png|thumb|500px|Sets of NE lattice paths squared, with the second copy rotated 90° clockwise.|center]]

Superimpose the NE lattice paths squared onto the same rectangular array, as seen in the figure below. We see that all NE lattice paths from &lt;math&gt; (0,0) &lt;/math&gt; to &lt;math&gt; (n,n) &lt;/math&gt; are accounted for. In particular, notice that any lattice path passing through the red lattice point (for example) is counted by the squared set of lattice paths (also shown in red). &lt;math&gt; \Box &lt;/math&gt;

[[File:Superimposed lattice paths squared.jpg|thumb|200px|Superimposed sets of NE lattice paths squared. All NE lattice paths are accounted for.|center]]

==References==
{{Reflist}}

[[Category:Enumerative combinatorics]]</text>
      <sha1>cpd5ji1ao0w95a63eo67ye9p5nslq9t</sha1>
    </revision>
  </page>
  <page>
    <title>Line–line intersection</title>
    <ns>0</ns>
    <id>8240558</id>
    <revision>
      <id>857265238</id>
      <parentid>857264821</parentid>
      <timestamp>2018-08-30T16:26:59Z</timestamp>
      <contributor>
        <username>Eric Wieser</username>
        <id>13669091</id>
      </contributor>
      <comment>Fix broken ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14604">[[Image:Line-Line Intersection.png|400px|thumb|right|The intersection of lines.]]
In [[Euclidean geometry]], the [[intersection]] of a [[line (mathematics)|line]] and a line can be the [[empty set]], a [[point (geometry)|point]], or a line. Distinguishing these cases and finding the intersection point have use, for example, in [[computer graphics]], [[motion planning]], and [[collision detection]].

In [[three-dimensional]] Euclidean geometry, if two lines are not in the same [[plane (geometry)|plane]] they are called [[skew lines]] and have no point of intersection. If they are in the same plane there are three possibilities: if they coincide (are not distinct lines) they have an [[infinitude]] of points in common (namely all of the points on either of them); if they are distinct but have the same slope they are said to be [[parallel (geometry)|parallel]] and have no points in common; otherwise they have a single point of intersection.

The distinguishing features of [[non-Euclidean geometry]] are the number and locations of possible intersections between two lines and the number of possible lines with no intersections (parallel lines) with a given line.

== Intersection of two lines ==

A [[necessary condition]] for two lines to intersect is that they are in the same plane&amp;mdash;that is, are not skew lines. Satisfaction of this condition is equivalent to the [[tetrahedron]] with vertices at two of the points on one line and two of the points on the other line being [[degeneracy (mathematics)|degenerate]] in the sense of having zero [[volume]]. For the algebraic form of this condition, see {{slink|Skew lines|Testing for skewness}}.

===Given two points on each line===

First we consider the intersection of two lines &lt;math&gt;L_1\,&lt;/math&gt; and &lt;math&gt;L_2\,&lt;/math&gt; in 2-dimensional space, with line &lt;math&gt;L_1\,&lt;/math&gt; being defined by two distinct points &lt;math&gt;(x_1,y_1)\,&lt;/math&gt; and &lt;math&gt;(x_2,y_2)\,&lt;/math&gt;, and line &lt;math&gt;L_2\,&lt;/math&gt; being defined by two distinct points &lt;math&gt;(x_3,y_3)\,&lt;/math&gt; and &lt;math&gt;(x_4,y_4)\,&lt;/math&gt;.&lt;ref name="Wolfram"&gt;
{{cite web | title=Weisstein, Eric W. "Line-Line Intersection." From MathWorld | work=A Wolfram Web Resource | url=http://mathworld.wolfram.com/Line-LineIntersection.html| accessdate=2008-01-10}}
&lt;/ref&gt;

The intersection &lt;math&gt;P\,&lt;/math&gt; of line &lt;math&gt;L_1\,&lt;/math&gt; and &lt;math&gt;L_2\,&lt;/math&gt; can be defined using [[determinant]]s.

:&lt;math&gt;
P_x = \frac{\begin{vmatrix} \begin{vmatrix} x_1 &amp; y_1\\x_2 &amp; y_2\end{vmatrix} &amp;  \begin{vmatrix} x_1 &amp; 1\\x_2 &amp; 1\end{vmatrix} \\\\ \begin{vmatrix} x_3 &amp; y_3\\x_4 &amp; y_4\end{vmatrix} &amp; \begin{vmatrix} x_3 &amp; 1\\x_4 &amp; 1\end{vmatrix} \end{vmatrix} }
{\begin{vmatrix} \begin{vmatrix} x_1 &amp; 1\\x_2 &amp; 1\end{vmatrix} &amp;  \begin{vmatrix} y_1 &amp; 1\\y_2 &amp; 1\end{vmatrix} \\\\ \begin{vmatrix} x_3 &amp; 1\\x_4 &amp; 1\end{vmatrix} &amp; \begin{vmatrix} y_3 &amp; 1\\y_4 &amp; 1\end{vmatrix} \end{vmatrix}}\,\!
\qquad
P_y = \frac{\begin{vmatrix} \begin{vmatrix} x_1 &amp; y_1\\x_2 &amp; y_2\end{vmatrix} &amp;  \begin{vmatrix} y_1 &amp; 1\\y_2 &amp; 1\end{vmatrix} \\\\ \begin{vmatrix} x_3 &amp; y_3\\x_4 &amp; y_4\end{vmatrix} &amp; \begin{vmatrix} y_3 &amp; 1\\y_4 &amp; 1\end{vmatrix} \end{vmatrix} }
{\begin{vmatrix} \begin{vmatrix} x_1 &amp; 1\\x_2 &amp; 1\end{vmatrix} &amp;  \begin{vmatrix} y_1 &amp; 1\\y_2 &amp; 1\end{vmatrix} \\\\ \begin{vmatrix} x_3 &amp; 1\\x_4 &amp; 1\end{vmatrix} &amp; \begin{vmatrix} y_3 &amp; 1\\y_4 &amp; 1\end{vmatrix} \end{vmatrix}}\,\!
&lt;/math&gt;

The determinants can be written out as:

: &lt;math&gt;
\begin{align}
(P_x, P_y)= \bigg(&amp;\frac{(x_1 y_2-y_1 x_2)(x_3-x_4)-(x_1-x_2)(x_3 y_4-y_3 x_4)}{(x_1-x_2)(y_3-y_4)-(y_1-y_2)(x_3-x_4)}, \\
         &amp;\frac{(x_1 y_2-y_1 x_2)(y_3-y_4)-(y_1-y_2)(x_3 y_4-y_3 x_4)}{(x_1-x_2)(y_3-y_4)-(y_1-y_2)(x_3-x_4)}\bigg)
\end{align}
&lt;/math&gt;

Note that the intersection point is for the infinitely long lines defined by the points, rather than the [[line segment]]s between the points, and can produce an intersection point beyond the lengths of the line segments. In order to find the position of the intersection in respect to the line segments, we can define lines &lt;math&gt;L_1\,&lt;/math&gt; and &lt;math&gt;L_2\,&lt;/math&gt; in terms of first degree [[Bézier curve#Linear curves|Bézier]] parameters:

: &lt;math&gt;
L_1 = {x_1\choose y_1} + t {x_2-x_1 \choose y_2-y_1},
\qquad
L_2 = {x_3\choose y_3} + u {x_4-x_3 \choose y_4-y_3}
&lt;/math&gt;

(where ''t'' and ''u'' are real numbers). Then the intersection point is found with one of the following values of ''t'' or ''u'':

: &lt;math&gt;
t = \frac{\begin{vmatrix} x_1-x_3 &amp; x_3-x_4\\y_1-y_3 &amp; y_3-y_4\end{vmatrix}}{\begin{vmatrix} x_1-x_2 &amp; x_3-x_4\\y_1-y_2 &amp; y_3-y_4\end{vmatrix}} = \frac{(x_1 - x_3)(y_3-y_4)-(y_1-y_3)(x_3-x_4)}{(x_1-x_2)(y_3-y_4)-(y_1-y_2)(x_3-x_4)},
\qquad
u = -\frac{\begin{vmatrix} x_1-x_2 &amp; x_1-x_3\\y_1-y_2 &amp; y_1-y_3\end{vmatrix}}{\begin{vmatrix} x_1-x_2 &amp; x_3-x_4\\y_1-y_2 &amp; y_3-y_4\end{vmatrix}} = -\frac{(x_1 - x_2)(y_1-y_3)-(y_1-y_2)(x_1-x_3)}{(x_1-x_2)(y_3-y_4)-(y_1-y_2)(x_3-x_4)}
&lt;/math&gt;
with:
: &lt;math&gt;
(P_x, P_y)= (x_1 + t (x_2-x_1),\; y_1 + t (y_2-y_1)) \quad \mathrm{or} \quad (P_x, P_y) = (x_3 + u (x_4-x_3),\; y_3 + u (y_4-y_3))
&lt;/math&gt;

Subsequently, one can check if the intersection points falls within the first line segment by testing if 0.0&amp;nbsp;≤&amp;nbsp;''t''&amp;nbsp;≤&amp;nbsp;1.0, and check if it falls within the second line segment by testing if 0.0&amp;nbsp;≤&amp;nbsp;''u''&amp;nbsp;≤&amp;nbsp;1.0.


When the two lines are parallel or coincident the denominator is zero:

: &lt;math&gt;
(x_1-x_2)(y_3-y_4)-(y_1-y_2)(x_3-x_4)=0.
&lt;/math&gt;

If the lines are almost parallel, then a computer solution might encounter numeric problems implementing the solution described above: the recognition of this condition might require an approximate test in a practical application. An alternate approach might be to rotate the line segments so that one of them is horizontal, whence the solution of the rotated parametric form of the second line is easily obtained. Careful discussion of the special cases is required (parallel lines/coincident lines, overlapping/non-overlapping intervals).

===Given the equations of the lines===
The &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; coordinates of the point of intersection of two non-vertical lines can easily be found using the following substitutions and rearrangements.

Suppose that two lines have the equations &lt;math&gt;y=ax+c&lt;/math&gt; and &lt;math&gt;y=bx+d&lt;/math&gt; where &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt; are the [[slope]]s (gradients) of the lines and where &lt;math&gt;c&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; are the ''y''-intercepts of the lines. At the point where the two lines intersect (if they do), both &lt;math&gt;y&lt;/math&gt; coordinates will be the same, hence the following equality:

:&lt;math&gt;ax+c=bx+d&lt;/math&gt;.

We can rearrange this expression in order to extract the value of &lt;math&gt;x&lt;/math&gt;,

:&lt;math&gt;ax-bx=d-c&lt;/math&gt;,
and so, 
:&lt;math&gt;x=\frac{d-c}{a-b}&lt;/math&gt;.

To find the ''y'' coordinate, all we need to do is substitute the value of ''x'' into either one of the two line equations, for example, into the first:

:&lt;math&gt;y=a\frac{d-c}{a-b}+c&lt;/math&gt;.

Hence, the point of intersection is 
:&lt;math&gt;P\left( \frac{d-c}{a-b}, a\frac{d-c}{a-b}+c \right) = P\left( \frac{d-c}{a-b}, \frac{ad - bc}{a-b} \right)&lt;/math&gt;. 
Note if ''a'' = ''b'' then the two lines are [[parallel (geometry)|parallel]]. If ''c'' ≠ ''d'' as well, the lines are different and there is no intersection, otherwise the two lines are identical.

=== Using homogeneous coordinates  ===

By using [[homogeneous coordinates]], the intersection point of two implicitly defined lines can be determined quite easily. In 2D, every point can be defined as a projection of a 3D point, given as the ordered triple &lt;math&gt;(x, y, w)&lt;/math&gt;. The mapping from 3D to 2D coordinates is &lt;math&gt;(x', y') = (x/w, y/w)&lt;/math&gt;. We can convert 2D points to homogeneous coordinates by defining them as &lt;math&gt;(x, y, 1)&lt;/math&gt;.

Assume that we want to find intersection of two infinite lines in 2-dimensional space, defined as &lt;math&gt;a_1x + b_1y + c_1 = 0&lt;/math&gt; and &lt;math&gt;a_2x + b_2y + c_2 = 0&lt;/math&gt;. We can represent these two lines in [[line coordinates]] as  &lt;math&gt;U_1 = (a_1, b_1, c_1)&lt;/math&gt; and &lt;math&gt;U_2 = (a_2, b_2, c_2)&lt;/math&gt;,

The intersection &lt;math&gt;P'&lt;/math&gt; of two lines is then simply given by,&lt;ref&gt;{{Cite web|title = Homogeneous coordinates|url = http://robotics.stanford.edu/~birch/projective/node4.html|website = robotics.stanford.edu|accessdate = 2015-08-18}}&lt;/ref&gt;

&lt;math&gt;P' = (a_p, b_p, c_p) = U_1 \times U_2 = (b_1 c_2 - b_2 c_1, a_2 c_1-a_1 c_2, a_1 b_2 - a_2 b_1)&lt;/math&gt;

If &lt;math&gt;c_p = 0&lt;/math&gt; the lines do not intersect.

== ''n''-line intersection ==

===Existence of and expression for the intersection===

====In two dimensions====

In two dimensions, more than two lines [[almost certainly]] do not intersect at a single point. To determine if they do and, if so, to find the intersection point, write the ''i''-th equation (''i'' = 1, ...,''n'') as &lt;math&gt;(a_{i1} \quad a_{i2})(x \quad y)^T=b_i,&lt;/math&gt; and stack these equations into matrix form as

:&lt;math&gt;Aw=b,&lt;/math&gt;

where the ''i''-th row of the ''n'' × 2 matrix ''A'' is &lt;math&gt;(a_{i1},  a_{i2})&lt;/math&gt;, ''w'' is the 2 × 1 vector (''x, y'')&lt;sup&gt;T&lt;/sup&gt;, and the ''i''-th element of the column vector ''b'' is ''b''&lt;sub&gt;''i''&lt;/sub&gt;. If ''A'' has independent columns, its [[matrix rank|rank]] is 2.  Then if and only if the rank of the [[augmented matrix]] [''A'' | ''b'' ] is also 2, there exists a solution of the matrix equation and thus an intersection point of the ''n'' lines. The intersection point, if it exists, is given by

:&lt;math&gt;w=A^gb=(A^TA)^{-1}A^Tb,&lt;/math&gt;

where &lt;math&gt;A^g&lt;/math&gt; is the [[Moore-Penrose generalized inverse]] of &lt;math&gt;A&lt;/math&gt; (which has the form shown because ''A'' has full column rank). Alternatively, the solution can be found by jointly solving any two independent equations. But if the rank of ''A'' is only 1, then if the rank of the augmented matrix is 2 there is no solution but if its rank is 1 then all of the lines coincide with each other.

====In three dimensions====

The above approach can be readily extended to three dimensions. In three or more dimensions, even two lines almost certainly do not intersect; pairs of non-parallel lines that do not intersect are called [[skew lines]].  But if an intersection does exist it can be found, as follows.

In three dimensions a line is represented by the intersection of two planes, each of which has an equation of the form &lt;math&gt;(a_{i1} \quad a_{i2} \quad a_{i3})(x \quad y \quad z)^T=b_i.&lt;/math&gt; Thus a set of ''n'' lines can be represented by 2''n'' equations in the 3-dimensional coordinate vector ''w'' = (''x'', ''y'', ''z'')&lt;sup&gt;T&lt;/sup&gt;:

:&lt;math&gt;Aw=b&lt;/math&gt;

where now ''A'' is 2''n'' × 3 and ''b'' is 2''n'' × 1. As before there is a unique intersection point if and only if ''A'' has full column rank and the augmented matrix [''A'' | ''b'' ] does not, and the unique intersection if it exists is given by

:&lt;math&gt;w = (A^TA)^{-1}A^Tb.&lt;/math&gt;

===Nearest point to non-intersecting lines===

In two or more dimensions, we can usually find a point that is mutually closest to two or more lines in a [[least-squares]] sense.

====In two dimensions====

In the two-dimensional case, first, represent line ''i'' as a point, &lt;math&gt;p_i&lt;/math&gt;, on the line and a [[unit vector|unit]] [[normal vector]], &lt;math&gt;\hat n_i&lt;/math&gt;, perpendicular to that line. That is, if &lt;math&gt;x_1&lt;/math&gt; and &lt;math&gt;x_2&lt;/math&gt; are points on line 1, then let &lt;math&gt;p_1 = x_1&lt;/math&gt; and let

:&lt;math&gt;\hat n_1:= \begin{bmatrix}0&amp;-1\\1&amp;0\end{bmatrix} (x_2-x_1) / \|x_2-x_1\|&lt;/math&gt;

which is the unit vector along the line, rotated by 90 degrees.

Note that the distance from a point, ''x'' to the line &lt;math&gt;(p, \hat n)&lt;/math&gt; is given by

:&lt;math&gt;d(x,(p,n))=\|(x-p)\cdot \hat n\| = \|(x-p)^\top \hat n\| = \sqrt{(x-p)^\top \hat n \hat n^\top (x-p)}.&lt;/math&gt;

And so the squared distance from a point, ''x'', to a line is

:&lt;math&gt;d(x,(p,n))^2=(x-p)^\top (\hat n \hat n^\top) (x-p).&lt;/math&gt;

The sum of squared distances to many lines is the [[Loss function|cost function]]:

:&lt;math&gt;E(x) = \sum_i (x-p_i)^\top (\hat n_i \hat n_i^\top) (x-p_i).&lt;/math&gt;

This can be rearranged:

:&lt;math&gt;
\begin{align}
E(x) &amp; = \sum_i x^\top \hat n_i \hat n_i^\top x - x^\top \hat n_i \hat n_i^\top p_i - p_i^\top \hat n_i \hat n_i^\top x + p_i^\top \hat n_i \hat n_i^\top p_i \\
&amp; = x^\top \left(\sum_i \hat n_i \hat n_i^\top\right) x - 2 x^\top \left(\sum_i \hat n_i \hat n_i^\top p_i\right) + \sum_i p_i^\top \hat n_i \hat n_i^\top p_i.
\end{align}
&lt;/math&gt;

To find the minimum, we differentiate with respect to ''x'' and set the result equal to the zero vector:

:&lt;math&gt;\frac{\partial E(x)}{\partial x} = 0 = 2 \left(\sum_i \hat n_i \hat n_i^\top\right) x - 2 \left(\sum_i \hat n_i \hat n_i^\top p_i\right) &lt;/math&gt;

so

:&lt;math&gt;\left(\sum_i \hat n_i \hat n_i^\top\right) x = \sum_i \hat n_i \hat n_i^\top p_i&lt;/math&gt;

and so

:&lt;math&gt;x = \left(\sum_i \hat n_i \hat n_i^\top\right)^{-1}\left(\sum_i \hat n_i \hat n_i^\top p_i\right).&lt;/math&gt;

====In three dimensions====

While &lt;math&gt;\hat n_i&lt;/math&gt; is not well-defined in more than two dimensions, this can be generalized to any number of dimensions by noting that &lt;math&gt;\hat n_i \hat n_i^\top&lt;/math&gt; is simply the (symmetric) matrix with all eigenvalues unity except for a zero eigenvalue in the direction along the line providing a [[seminorm]] on the distance between &lt;math&gt;p_i&lt;/math&gt; and another point giving the distance to the line. In any number of dimensions, if &lt;math&gt;\hat v_i&lt;/math&gt; is a unit vector ''along'' the ''i''-th line, then

: &lt;math&gt;\hat n_i \hat n_i^\top&lt;/math&gt; becomes &lt;math&gt;I - \hat v_i \hat v_i^\top&lt;/math&gt;

where ''I'' is the identity matrix, and so&lt;ref&gt;{{cite web |last1=Traa |first1=Johannes |title=Least-Squares Intersection of Lines |url=http://cal.cs.illinois.edu/~johannes/research/LS_line_intersect.pdf |accessdate=30 August 2018}}&lt;/ref&gt;


: &lt;math&gt; x= \left(\sum_i I-\hat v_i \hat v_i^\top\right)^{-1} \left(\sum_i (I-\hat v_i \hat v_i^\top) p_i\right).&lt;/math&gt; 


==See also==
*[[Line segment intersection]]
*[[Projective plane#Lines joining points and intersection of lines .28using duality.29|Line intersection in projective space]]
*[[Distance from a point to a line]]
*[[Parallel postulate]]
*{{slink|Intersection (Euclidean geometry)|Two line segments}}

== References ==
&lt;references/&gt;

== External links ==
* [http://softsurfer.com/Archive/algorithm_0106/algorithm_0106.htm Distance between Lines and Segments with their Closest Point of Approach], applicable to two, three, or more dimensions.

{{DEFAULTSORT:Line-line intersection}}
[[Category:Euclidean geometry]]
[[Category:Linear algebra]]
[[Category:Geometric algorithms]]</text>
      <sha1>ixd28mk9tsm7txuw1va8t381aggk4m0</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematics education journals</title>
    <ns>0</ns>
    <id>20745603</id>
    <revision>
      <id>869120998</id>
      <parentid>869119664</parentid>
      <timestamp>2018-11-16T15:18:27Z</timestamp>
      <contributor>
        <ip>130.117.124.10</ip>
      </contributor>
      <comment>/* R */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1539">This is a list of notable [[academic journal]]s in the field of [[mathematics education]].

==C==
*''[[College Mathematics Journal]]''

==E==
*''[[Educational Studies in Mathematics]]''

==F==
*''[http://flm-journal.org For the Learning of Mathematics]''

==I==
*''[[International Journal of Science and Mathematics Education]]''
*''[[Investigations in Mathematics Learning]]''

==J==
*''[[Journal for Research in Mathematics Education]]''
*''[[Journal of Mathematics Teacher Education]]''

==M==
*''[[The Mathematics Educator]]''
*''[[The Mathematics Enthusiast]]''
*''[[Mathematics Teacher]]''
*''[[Mathematics Teaching]]''

==P==
*''[[Philosophy of Mathematics Education Journal]]''
*''[[PRIMUS (journal)|Problems, Resources, and Issues in Mathematics Undergraduate Studies]]''

==R==

*''[https://www.tandfonline.com/rrme Research in Mathematics Education]''

==S==
*''[[Science &amp; Education]]''

==T==
*''[[Teaching Mathematics and Its Applications]]''

==See also==
*[[List of probability journals]]
*[[List of statistics journals]]
*[[List of mathematics journals]]

==External links==
*[http://mathedjournals.wikispaces.com Wikispaces list of journals and conferences in mathematics education]
*[https://web.archive.org/web/20090206021327/http://www.crme.soton.ac.uk/links/journals.html Online list of some journals in mathematics education]

{{DEFAULTSORT:List Of Mathematics Education Journals}}
[[Category:Mathematics journals|*]]
[[Category:Lists of academic journals|Mathematics education]]
[[Category:Mathematics education|*]]</text>
      <sha1>sm77etauy9dqo1ei8o32rp4v8dd06wy</sha1>
    </revision>
  </page>
  <page>
    <title>Long code (mathematics)</title>
    <ns>0</ns>
    <id>22354099</id>
    <revision>
      <id>822472702</id>
      <parentid>774932065</parentid>
      <timestamp>2018-01-26T15:42:59Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2598">{{infobox code
 | name           = Math logic 
 | image          =
 | image_caption  =
 | namesake       =
 | type           = [[Block code]]
 | block_length   = &lt;math&gt;2^{n}&lt;/math&gt; for some &lt;math&gt;n\in\N&lt;/math&gt;
 | message_length = &lt;math&gt;\log n&lt;/math&gt;
 | rate           =
 | distance       =
 | alphabet_size  = &lt;math&gt;2&lt;/math&gt;
 | notation       = &lt;math&gt;(2^{n},\log n)_2&lt;/math&gt;-code
}}

In [[theoretical computer science]] and [[coding theory]], the '''long code''' is an [[error detection and correction|error-correcting code]] that is [[locally decodable code|locally decodable]]. Long codes have an extremely poor rate, but play a fundamental role in the theory of [[hardness of approximation]].

==Definition==
Let &lt;math&gt;f_1,\dots,f_{2^n} : \{0,1\}^k\to \{0,1\}&lt;/math&gt; for &lt;math&gt;k=\log n&lt;/math&gt; be the list of ''all'' functions from &lt;math&gt;\{0,1\}^k\to\{0,1\}&lt;/math&gt;.
Then the long code encoding of a message &lt;math&gt;x\in\{0,1\}^k&lt;/math&gt; is the string &lt;math&gt;f_1(x)\circ f_2(x)\circ\dots\circ f_{2^n}(x)&lt;/math&gt; where &lt;math&gt;\circ&lt;/math&gt; denotes concatenation of strings.
This string has length &lt;math&gt;2^n=2^{2^k}&lt;/math&gt;.

The [[Walsh-Hadamard code]] is a subcode of the long code, and can be obtained by only using functions &lt;math&gt;f_i&lt;/math&gt; that are [[linear function]]s when interpreted as functions &lt;math&gt;\mathbb F_2^k\to\mathbb F_2&lt;/math&gt; on the [[finite field]] with two elements. Since there are only &lt;math&gt;2^k&lt;/math&gt; such functions, the block length of the Walsh-Hadamard code is &lt;math&gt;2^k&lt;/math&gt;.

An equivalent definition of the long code is as follows:
The Long code encoding of &lt;math&gt;j\in[n]&lt;/math&gt; is defined to be the truth table of the Boolean dictatorship function on the &lt;math&gt;j&lt;/math&gt;th coordinate, i.e., the truth table of &lt;math&gt;f:\{0,1\}^n\to\{0,1\}&lt;/math&gt; with &lt;math&gt;f(x_1,\dots,x_n)=x_j&lt;/math&gt;.&lt;ref&gt;Definition 7.3.1 in [https://arxiv.org/abs/1002.3864  Limits of Approximation Algorithms: PCPs and Unique Games (DIMACS Tutorial Lecture Notes)]&lt;/ref&gt;
Thus, the Long code encodes a &lt;math&gt;(\log n)&lt;/math&gt;-bit string as a &lt;math&gt;2^n&lt;/math&gt;-bit string.

==Properties==
The long code does not contain repetitions, in the sense that the function &lt;math&gt;f_i&lt;/math&gt; computing the &lt;math&gt;i&lt;/math&gt;th bit of the output is different from any function &lt;math&gt;f_j&lt;/math&gt; computing the &lt;math&gt;j&lt;/math&gt;th bit of the output for &lt;math&gt;j\neq i&lt;/math&gt;.
Among all codes that do not contain repetitions, the long code has the longest possible output.
Moreover, it contains all non-repeating codes as a subcode.

==References==
{{reflist}}

[[Category:Coding theory]]
[[Category:Error detection and correction]]</text>
      <sha1>ta122bissjn1cl4x66oatk6kddnpntn</sha1>
    </revision>
  </page>
  <page>
    <title>Maximum common induced subgraph</title>
    <ns>0</ns>
    <id>4288963</id>
    <revision>
      <id>749430208</id>
      <parentid>749430174</parentid>
      <timestamp>2016-11-14T08:02:52Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>more like start class now</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3649">In [[graph theory]] and [[theoretical computer science]], a '''maximum common induced subgraph''' of two graphs ''G'' and ''H'' is a graph that is an [[induced subgraph]] of both ''G'' and ''H'',
and that has as many vertices as possible.

Finding this graph is [[NP-hard]].
In the associated [[decision problem]], the input is two graphs ''G'' and ''H'' and a number ''k''. The problem is to decide whether ''G'' and ''H'' have a common induced subgraph with at least ''k'' vertices. This problem is [[NP-complete]].&lt;ref&gt;{{citation|author = [[Michael R. Garey]] and [[David S. Johnson]] | year = 1979 | title = [[Computers and Intractability: A Guide to the Theory of NP-Completeness]] | publisher = W.H. Freeman | isbn = 0-7167-1045-5}} A1.4: GT48, pg.202.&lt;/ref&gt; It is a generalization of the induced [[subgraph isomorphism problem]], which arises when ''k'' equals the number of vertices in the smaller of ''G'' and ''H'', so that this entire graph must appear as an induced subgraph of the other graph.

Based on [[hardness of approximation]] results for the [[maximum independent set]] problem, the maximum common induced subgraph problem is also hard to approximate.&lt;ref&gt;{{citation
 | last = Kann | first = Viggo
 | contribution = On the approximability of the maximum common subgraph problem
 | doi = 10.1007/3-540-55210-3_198
 | pages = 375–388
 | publisher = Springer Science $\mathplus$ Business Media
 | series = Lecture Notes in Computer Science
 | title = STACS 92: 9th Annual Symposium on Theoretical Aspects of Computer Science Cachan, France, February 13–15, 1992, Proceedings
 | volume = 577
 | year = 1992}}.&lt;/ref&gt; This implies that, unless [[P = NP]], there is no [[approximation algorithm]] that, in [[polynomial time]] on &lt;math&gt;n&lt;/math&gt;-vertex graphs, always finds a solution within a factor of &lt;math&gt;n^{1-\epsilon}&lt;/math&gt; of optimal, for any &lt;math&gt;\epsilon &gt; 0&lt;/math&gt;.&lt;ref&gt;{{citation |first=D. |last=Zuckerman |title=[[Symposium on Theory of Computing|Proc. 38th ACM Symp. Theory of Computing]] |pages=681–690 |year=2006 |doi=10.1145/1132516.1132612 |id={{ECCC|2005|05|100}}|chapter=Linear degree extractors and the inapproximability of max clique and chromatic number |isbn=1-59593-134-1}}.&lt;/ref&gt;

One possible solution for this problem is to build a [[Modular product of graphs|modular product graph]] of ''G'' and ''H''.
In this graph, the largest [[Clique (graph theory)|clique]] corresponds to a maximum common induced subgraph of ''G'' and ''H''. Therefore, [[clique problem|algorithms for finding maximum cliques]] can be used to find the maximum common induced subgraph.&lt;ref&gt;{{citation
 | last1 = Barrow | first1 = H.
 | last2 = Burstall | first2 = R. | author2-link = Rod Burstall
 | doi = 10.1016/0020-0190(76)90049-1
 | issue = 4
 | journal = Information Processing Letters
 | pages = 83–84
 | title = Subgraph isomorphism, matching relational structures and maximal cliques
 | volume = 4
 | year = 1976}}.&lt;/ref&gt;

Maximum common induced subgraph algorithms have a long tradition in [[cheminformatics]] and [[Pharmacophore|pharmacophore mapping]].&lt;ref&gt;{{citation
 | last1 = Raymond | first1 = John W.
 | last2 = Willett | first2 = Peter
 | doi = 10.1023/A:1021271615909
 | issue = 7
 | journal = Journal of Computer-Aided Molecular Design
 | pages = 521–533
 | title = Maximum common subgraph isomorphism algorithms for the matching of chemical structures
 | volume = 16
 | year = 2002}}.&lt;/ref&gt;

==See also==
*[[Molecule mining]]
*[[Maximum common edge subgraph]]

==References==
{{reflist}}

[[Category:NP-complete problems]]
[[Category:Cheminformatics]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>p6quwe5bgvgtw4vm7kk6o73vg2ycnvc</sha1>
    </revision>
  </page>
  <page>
    <title>Michael Somos</title>
    <ns>0</ns>
    <id>24464863</id>
    <revision>
      <id>863878463</id>
      <parentid>775270038</parentid>
      <timestamp>2018-10-13T17:32:43Z</timestamp>
      <contributor>
        <ip>141.161.13.187</ip>
      </contributor>
      <comment>/* External links */ Update home page. Old one unavailable.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1351">'''Michael Somos''' is an [[United States|American]] [[mathematician]], who was a visiting scholar in the [[Georgetown University]] Mathematics and Statistics department for four years and is currently an affiliate researcher in that department. In the late eighties he proposed a conjecture about certain [[polynomial recurrence]]s, now called [[Somos sequence]]s,&lt;ref&gt;{{cite web|url=http://faculty.uml.edu/jpropp/somos.html|title=The Somos Sequence Site |publisher= [[University of Massachusetts Lowell]]|author =[[Jim Propp]]|date=2006-08-08 |accessdate=2009-10-13}}&lt;/ref&gt; that surprisingly in some cases contain only integers. [[Somos' quadratic recurrence constant]] is also named after him.

== Notes ==
{{Reflist}}

== References ==
* Michael Somos and Robert Haas, "A Linked Pair of Sequences Implies the Primes Are Infinite", ''[[The American Mathematical Monthly]]'', volume 110, number 6 (June &amp;ndash; July, 2003), pp.&amp;nbsp;539&amp;ndash;540

== External links ==
* [http://grail.eecs.csuohio.edu/~somos/home.html  Michael Somos's homepage]
* [http://mathworld.wolfram.com/SomosSequence.html  Somos sequence in mathworld]

{{Authority control}}

{{DEFAULTSORT:Somos, Michael}}
[[Category:Living people]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Combinatorialists]]


{{US-mathematician-stub}}</text>
      <sha1>gjjnujak8t33q127033lq48b1ftalrn</sha1>
    </revision>
  </page>
  <page>
    <title>Missing square puzzle</title>
    <ns>0</ns>
    <id>365627</id>
    <revision>
      <id>862828195</id>
      <parentid>862828154</parentid>
      <timestamp>2018-10-06T23:38:14Z</timestamp>
      <contributor>
        <username>BrayLockBoy</username>
        <id>20908161</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6418">[[File:Missing Square Animation.gif|thumb|right|300px|Missing square puzzle animation, like a "magician presentation."]]
[[File:Missing_square_puzzle-AB.png|thumb|right|Both "total triangles" are in a perfect 13×5 grid; and both the "component triangles", the blue in a 5×2 grid and the red in an 8×3 grid.]]
The '''missing square puzzle''' is an [[optical illusion]] used in [[mathematics]] classes to help students reason about geometrical figures; or rather to teach them not to reason using figures, but to use only textual descriptions and the axioms of geometry. It depicts two arrangements made of similar shapes in slightly different configurations. Each apparently forms a 13×5 right-angled [[triangle]], but one has a 1×1 hole in it.

==Solution==
[[File:Missing-square-puzzle,showPart.png|thumb|What the "magician presentation" does not show. The angles of the hypotenuses aren't the same: they are not [[Similarity (geometry)#Similar triangles|similar triangles]].]]
[[File:Paradoja del cuadrado perdido, area.png|thumb|Splitting the ''thin parallelogram'' area (yellow) into little parts, and building a single unit square with them.]]

The key to the puzzle is the fact that neither of the 13×5 "triangles" is truly a triangle, because what appears to be the [[hypotenuse]] is bent. In other words, the "hypotenuse" does not maintain a consistent [[slope]], even though it may appear that way to the human eye. 

[[File:Paradoja_del_cuadrado_perdido_10,AB.png|center|520px|There are two distinct and "false hypotenuses" for the total triangle.]]
A true 13×5 triangle cannot be created from the given component parts. The four figures (the yellow, red, blue and green shapes) total 32 units of area. The apparent triangles formed from the figures are 13 units wide and 5 units tall, so it appears that the area should be &lt;math&gt;\textstyle{S=\frac{13 \times 5}{2}=32.5}&lt;/math&gt; units. However, the blue triangle has a ratio of 5:2 (=2.5), while the red triangle has the ratio 8:3 (≈2.667), so the apparent combined [[hypotenuse]] in each figure is actually bent. With the bent hypotenuse, the first figure actually occupies a combined 32 units, while the second figure occupies 33, including the "missing" square.

The amount of bending is approximately 1/28th of a unit (1.245364267°), which is difficult to see on the diagram of the puzzle, and was illustrated as a graphic. Note the grid point where the red and blue triangles in the lower image meet (5 squares to the right and two units up from the lower left corner of the combined figure), and compare it to the same point on the other figure; the edge is slightly under the mark in the upper image, but goes through it in the lower. Overlaying the hypotenuses from both figures results in a very ''thin [[parallelogram]]'' (represented with the four red dots) with an area of exactly one grid square, so the "missing" area.

===Principle===
According to [[Martin Gardner]],&lt;ref&gt;
{{cite book 
|last= Martin 
|first= Gardner 
|title= Mathematics Magic and magic 
|year= 1956 
|publisher= Dover 
|pages= 139–150
|isbn= 9780486203355
}}&lt;/ref&gt; this particular puzzle was invented by a [[New York City]] amateur magician, [[Paul Curry]], in 1953. However, the principle of a dissection paradox has been known since the start of the 16th century. 

The integer dimensions of the parts of the puzzle (2, 3, 5, 8, 13) are successive [[Fibonacci numbers]], which leads to the exact unit area in the ''thin parallelogram''.
Many other geometric [[dissection puzzle]]s are based on a few simple properties of the Fibonacci sequence.&lt;ref&gt;{{cite web |publisher=Math World |last=Weisstein |first=Eric |title=Cassini's Identity |url=http://mathworld.wolfram.com/CassinisIdentity.html}}&lt;/ref&gt;

==Similar puzzles==
[[File:Loyd64-65-dis b.svg|thumb|right|200px|[[Sam Loyd]]'s paradoxical dissection]]
[[Sam Loyd]]'s paradoxical dissection demonstrates two rearrangements of an 8×8 square. In the "larger" rearrangement (the 5×13 rectangle in the image to the right), the gaps between the figures have a combined unit square more area than their square gaps counterparts, creating an illusion that the figures there take up more space than those in the original square figure.&lt;ref&gt;{{Cite news|url=https://mathblag.wordpress.com/2011/08/28/a-paradoxical-dissection/|title=A Paradoxical Dissection|date=2011-08-28|work=mathblag|access-date=2018-04-19|language=en-US}}&lt;/ref&gt; In the "smaller" rearrangement (the shape below the 5×13 rectangle), each quadrilateral needs to overlap the triangle by an area of half a unit for its top/bottom edge to align with a grid line, resulting overall loss in one unit square area.

Mitsunobu Matsuyama's "Paradox" uses four congruent [[quadrilateral]]s and a small square, which form a larger square. When the quadrilaterals are rotated about their centers they fill the space of the small square, although the total area of the figure seems unchanged. The apparent paradox is explained by the fact that the side of the new large square is a little smaller than the original one. If ''θ'' is the angle between two opposing sides in each quadrilateral, then the quotient between the two areas is given by sec&lt;sup&gt;2&lt;/sup&gt;''θ''{{Explain|date=November 2017}}. For ''θ'' = 5°, this is approximately 1.00765, which corresponds to a difference of about 0.8%.
[[File:Missing square edit.gif|thumb|left|150px|A variant of Mitsunobu Matsuyama's "Paradox"]]

{{-}}

== See also ==
* [[Einstellung effect]]
* [[Missing dollar riddle]]

==References==
{{Reflist}}

==External links==
{{Commons category|Missing square puzzle}}
*A printable [http://www.archimedes-lab.org/workshop13skulls.html Missing Square variant] with a video demonstration.
*[http://www.cut-the-knot.org/Curriculum/Fallacies/CurryParadox.shtml Curry's Paradox: How Is It Possible?] at [[cut-the-knot]]
*[http://www.mathematik.uni-bielefeld.de/~sillke/PUZZLES/jigsaw-paradox.html Jigsaw Paradox]
*[http://www.slideshare.net/sualeh/the-eleven-holes-puzzle The Eleven Holes Puzzle]
*[https://www.youtube.com/watch?v=dmBsPgPu0Wc "Infinite chocolate trick"], a demonstration of the missing square puzzle utilising a 4×6 [[chocolate bar]]
{{DEFAULTSORT:Missing Square Puzzle}}
[[Category:Optical illusions]]
[[Category:Fibonacci numbers]]
[[Category:Elementary mathematics]]
[[Category:Mathematics paradoxes]]
[[Category:Puzzles]]
[[Category:Geometric dissection]]</text>
      <sha1>d7q921joarc9f0te4evgrgjwu38ki0k</sha1>
    </revision>
  </page>
  <page>
    <title>Partial differential equation</title>
    <ns>0</ns>
    <id>52564</id>
    <revision>
      <id>871180475</id>
      <parentid>869919578</parentid>
      <timestamp>2018-11-29T13:40:14Z</timestamp>
      <contributor>
        <username>Thatsme314</username>
        <id>31364895</id>
      </contributor>
      <minor/>
      <comment>/* Classification */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35066">[[File:Heat.gif|thumb|right|A visualisation of a solution to the two-dimensional [[heat equation]] with temperature represented by the third dimension]]
In [[mathematics]], a '''partial differential equation''' ('''PDE''') is a [[differential equation]] that contains beforehand unknown [[Multivariable calculus|multivariable functions]] and their [[partial derivative]]s. PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a [[computer model]]. A special case is [[ordinary differential equation]]s (ODEs), which deal with [[function (mathematics)|functions]] of a single variable and their [[derivative]]s.

PDEs can be used to describe a wide variety of phenomena such as [[sound]], [[heat]], [[diffusion]], [[electrostatics]], [[electrodynamics]], [[fluid dynamics]], [[Elasticity (physics)|elasticity]], or [[quantum mechanics]]. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional [[dynamical system]]s, partial differential equations often model [[multidimensional system]]s. PDEs find their generalisation in [[stochastic partial differential equation]]s.

== Introduction ==
Partial differential equations (PDEs) are equations that involve rates of change with respect to [[continuous variables]]. The position of a [[rigid body]] is specified by six parameters,&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=v9PLbcYd9aUC&amp;pg=PA32|title=Modelling and Control of Robot Manipulators|last=Sciavicco|first=Lorenzo|last2=Siciliano|first2=Bruno|date=2001-02-19|publisher=Springer Science &amp; Business Media|isbn=9781852332211|language=en}}&lt;/ref&gt; but the configuration of a [[fluid]] is given by the [[continuous distribution]] of several parameters, such as the [[temperature]], [[pressure]], and so forth. The dynamics for the rigid body take place in a finite-dimensional [[Configuration space (physics)|configuration space]]; the dynamics for the fluid occur in an infinite-dimensional configuration space. This distinction usually makes PDEs much harder to solve than ordinary differential equations (ODEs), but here again, there will be simple solutions for linear problems. Classic domains where PDEs are used include [[acoustics]], [[fluid dynamics]], [[electrodynamics]], and [[heat transfer]].

A partial differential equation (PDE) for the function {{math|''u''(''x''&lt;sub&gt;1&lt;/sub&gt;,… ''x&lt;sub&gt;n&lt;/sub&gt;'')}} is an equation of the form

: &lt;math&gt;f \left (x_1, \ldots x_n; u, \frac{\partial u}{\partial x_1}, \ldots \frac{\partial u}{\partial x_n}; \frac{\partial^2 u}{\partial x_1 \partial x_1}, \ldots \frac{\partial^2 u}{\partial x_1 \partial x_n}; \ldots \right) = 0.&lt;/math&gt;

If {{mvar|f}} is a [[linear function]] of {{mvar|u}} and its derivatives, then the PDE is called linear. Common examples of linear PDEs include the [[heat equation]], the [[wave equation]], [[Laplace's equation]], [[Helmholtz equation]], [[Klein–Gordon equation]], and [[Poisson's equation]].

A relatively simple PDE is

: &lt;math&gt;\frac{\partial u}{\partial x}(x,y) = 0.&lt;/math&gt;

This relation [[Logical implication|implies]] that the function {{math|''u''(''x'',''y'')}} is independent of {{mvar|x}}. However, the equation gives no information on the function's dependence on the variable {{mvar|y}}. Hence the general solution of this equation is

: &lt;math&gt;u(x,y) = f(y),&lt;/math&gt;

where {{mvar|f}} is an arbitrary function of {{mvar|y}}. The analogous ordinary differential equation is

: &lt;math&gt;\frac{\mathrm{d} u}{\mathrm{d} x}(x) = 0,&lt;/math&gt;

which has the solution

: &lt;math&gt;u(x) = c,&lt;/math&gt;

where {{mvar|c}} is any [[Constant (mathematics)|constant]] value. These two examples illustrate that general solutions of ordinary differential equations (ODEs) involve arbitrary constants, but solutions of PDEs involve arbitrary functions. A solution of a PDE is generally not [[Uniqueness quantification|unique]]; additional conditions must generally be specified on the [[Boundary (topology)|boundary]] of the region where the solution is defined. For instance, in the simple example above, the function {{math|''f''(''y'')}} can be determined if {{mvar|u}} is specified on the line {{math|''x'' {{=}} 0}}.

== Existence and uniqueness ==
Although the issue of existence and uniqueness of solutions of ordinary differential equations has a very satisfactory answer with the [[Picard–Lindelöf theorem]], that is far from the case for partial differential equations. The [[Cauchy–Kowalevski theorem]] states that the [[Cauchy problem]] for any partial differential equation whose coefficients are [[Analytic function|analytic]] in the unknown function and its derivatives, has a locally unique analytic solution. Although this result might appear to settle the existence and uniqueness of solutions, there are examples of linear partial differential equations whose coefficients have derivatives of all orders (which are nevertheless not analytic) but which have no solutions at all: see [[Lewy's example|Lewy (1957)]]. Even if the solution of a partial differential equation exists and is unique, it may nevertheless have undesirable properties.  The mathematical study of these questions is usually in the more powerful context of [[weak solution]]s.

An example of pathological behavior is the sequence (depending upon {{mvar|n}}) of [[Cauchy problem]]s for the [[Laplace equation]]

: &lt;math&gt;\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}=0,&lt;/math&gt;

with [[boundary condition]]s

: &lt;math&gt;\begin{align} u(x,0) &amp;= 0, \\ \frac{\partial u}{\partial y}(x,0) &amp;= \frac{\sin nx}{n}, \end{align}&lt;/math&gt;

where {{mvar|n}} is an integer. The derivative of {{mvar|u}} with respect to {{mvar|y}} approaches zero [[uniform convergence|uniformly]] in {{mvar|x}} as {{mvar|n}} increases, but the solution is

: &lt;math&gt;u(x,y) = \frac{\sinh ny \sin nx}{n^2}.&lt;/math&gt;

This solution approaches infinity if {{mvar|nx}} is not an integer multiple of {{pi}} for any non-zero value of {{mvar|y}}. The Cauchy problem for the Laplace equation is called ''ill-posed'' or ''not [[Well-posed problem|well-posed]]'', since the solution does not continuously depend on the data of the problem. Such ill-posed problems are not usually satisfactory for physical applications.

The existence of solutions for the [[Navier–Stokes equations]], a partial differential equation, is part of one of the [[Millennium Prize Problems]].

== Notation ==
In PDEs, it is common to denote partial derivatives using subscripts. That is:

: &lt;math&gt;u_x = \frac{\partial u}{\partial x}&lt;/math&gt;
: &lt;math&gt;u_{xx} = \frac{\partial^2 u}{\partial x^2} &lt;/math&gt;
: &lt;math&gt;u_{xy} = \frac{\partial^2 u}{\partial y\, \partial x} = \frac{\partial}{\partial y } \left(\frac{\partial u}{\partial x}\right). &lt;/math&gt;

Especially in physics, [[del]] or nabla ({{math|∇}}) is often used to denote spatial derivatives, and {{math|''u&amp;#x307;'', ''ü''}} for time derivatives. For example, the [[wave equation]] (described below) can be written as

:&lt;math&gt;\ddot u=c^2\nabla^2u&lt;/math&gt;

or

:&lt;math&gt;\ddot u=c^2\Delta u&lt;/math&gt;

where {{math|Δ}} is the [[Laplace operator]].

== Classification ==
Some linear, second-order partial differential equations can be classified as [[parabolic partial differential equation|parabolic]], [[hyperbolic partial differential equation|hyperbolic]] and [[elliptic partial differential equation|elliptic]]. Others, such as the [[Euler–Tricomi equation]], have different types in different regions. The classification provides a guide to appropriate initial and boundary conditions and to the smoothness of the solutions.

=== Equations of first order ===

{{main|First-order partial differential equation}}

=== Linear equations of second order ===
Assuming {{math|''u&lt;sub&gt;xy&lt;/sub&gt;'' {{=}} ''u&lt;sub&gt;yx&lt;/sub&gt;''}}, the general linear second-order PDE in two independent variables has the form

: &lt;math&gt;Au_{xx} + 2Bu_{xy} + Cu_{yy} + \cdots \mbox{(lower order terms)} = 0,&lt;/math&gt;

where the coefficients {{mvar|A}}, {{mvar|B}}, {{mvar|C}}... may depend upon {{mvar|x}} and {{mvar|y}}. If {{math|''A''&lt;sup&gt;2&lt;/sup&gt; + ''B''&lt;sup&gt;2&lt;/sup&gt; + ''C''&lt;sup&gt;2&lt;/sup&gt; &gt; 0}} over a region of the {{mvar|xy}}-plane, the PDE is second-order in that region. This form is analogous to the equation for a conic section:

: &lt;math&gt;Ax^2 + 2Bxy + Cy^2 + \cdots = 0.&lt;/math&gt;
More precisely, replacing {{math|∂&lt;sub&gt;''x''&lt;/sub&gt;}} by {{mvar|X}}, and likewise for other variables (formally this is done by a [[Fourier transform]]), converts a constant-coefficient PDE into a polynomial of the same degree, with the top degree (a [[homogeneous polynomial]], here a [[quadratic form]]) being most significant for the classification.

Just as one classifies [[conic section]]s and quadratic forms into parabolic, hyperbolic, and elliptic based on the [[discriminant]] {{math|''B''&lt;sup&gt;2&lt;/sup&gt; − 4''AC''}}, the same can be done for a second-order PDE at a given point.  However, the [[discriminant]] in a PDE is given by {{math|''B''&lt;sup&gt;2&lt;/sup&gt; − ''AC''}} due to the convention of the {{mvar|xy}} term being {{math|2''B''}} rather than {{mvar|B}}; formally, the discriminant (of the associated quadratic form) is {{math|(2''B'')&lt;sup&gt;2&lt;/sup&gt; − 4''AC'' {{=}} 4(''B''&lt;sup&gt;2&lt;/sup&gt; − ''AC'')}}, with the factor of 4 dropped for simplicity.

# {{math|''B''&lt;sup&gt;2&lt;/sup&gt; − ''AC'' &lt; 0}} (''[[elliptic partial differential equation]]''): Solutions of [[elliptic partial differential equation|elliptic PDEs]] are as smooth as the coefficients allow, within the interior of the region where the equation and solutions are defined. For example, solutions of Laplace's equation are analytic within the domain where they are defined, but solutions may assume boundary values that are not smooth. The motion of a fluid at subsonic speeds can be approximated with elliptic PDEs, and the Euler–Tricomi equation is elliptic where {{math|''x'' &lt; 0}}.
# {{math|''B''&lt;sup&gt;2&lt;/sup&gt; − ''AC'' {{=}} 0}} (''[[parabolic partial differential equation]]''): Equations that are [[parabolic partial differential equation|parabolic]] at every point can be transformed into a form analogous to the [[heat equation]] by a change of independent variables. Solutions smooth out as the transformed time variable increases. The Euler–Tricomi equation has parabolic type on the line where {{math|''x'' {{=}} 0}}.
# {{math|''B''&lt;sup&gt;2&lt;/sup&gt; − ''AC'' &gt; 0}} (''[[hyperbolic partial differential equation]]''): [[hyperbolic partial differential equation|hyperbolic]] equations retain any discontinuities of functions or derivatives in the initial data. An example is the wave equation. The motion of a fluid at supersonic speeds can be approximated with hyperbolic PDEs, and the Euler–Tricomi equation is hyperbolic where {{math|''x'' &gt; 0}}.

If there are {{mvar|n}} independent variables {{math|''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2 &lt;/sub&gt;,… ''x''&lt;sub&gt;''n''&lt;/sub&gt;}}, a general linear partial differential equation of second order has the form

: &lt;math&gt;L u =\sum_{i=1}^n\sum_{j=1}^n a_{i,j} \frac{\partial^2 u}{\partial x_i \partial x_j} \quad \text{ plus lower-order terms} =0.&lt;/math&gt;

The classification depends upon the signature of the eigenvalues of the coefficient matrix {{math|''a''&lt;sub&gt;''i'',''j''&lt;/sub&gt;}}.

# Elliptic: the eigenvalues are all positive or all negative.
# Parabolic: the eigenvalues are all positive or all negative, save one that is zero.
# Hyperbolic: there is only one negative eigenvalue and all the rest are positive, or there is only one positive eigenvalue and all the rest are negative.
# Ultrahyperbolic: there is more than one positive eigenvalue and more than one negative eigenvalue, and there are no zero eigenvalues. There is only a limited theory for ultrahyperbolic equations (Courant and Hilbert, 1962).

=== Systems of first-order equations and characteristic surfaces ===
The classification of partial differential equations can be extended to systems of first-order equations, where the unknown {{mvar|u}} is now a [[Euclidean vector|vector]] with {{mvar|m}} components, and the coefficient matrices {{mvar|A&lt;sub&gt;ν&lt;/sub&gt;}} are {{mvar|m}} by {{mvar|m}} matrices for {{math|''ν'' {{=}} 1, 2,… ''n''}}. The partial differential equation takes the form

: &lt;math&gt;Lu = \sum_{\nu=1}^{n} A_\nu \frac{\partial u}{\partial x_\nu} + B=0,&lt;/math&gt;

where the coefficient matrices {{mvar|A&lt;sub&gt;ν&lt;/sub&gt;}} and the vector {{mvar|B}} may depend upon {{mvar|x}} and {{mvar|u}}. If a [[hypersurface]] {{mvar|S}} is given in the implicit form

: &lt;math&gt;\varphi(x_1, x_2, \ldots x_n)=0,&lt;/math&gt;

where {{mvar|φ}} has a non-zero gradient, then {{mvar|S}} is a '''characteristic surface''' for the operator {{mvar|L}} at a given point if the characteristic form vanishes:

: &lt;math&gt;Q\left(\frac{\partial\varphi}{\partial x_1}, \ldots\frac{\partial\varphi}{\partial x_n}\right) =\det\left[\sum_{\nu=1}^nA_\nu \frac{\partial \varphi}{\partial x_\nu}\right]=0.\,&lt;/math&gt;

The geometric interpretation of this condition is as follows: if data for {{mvar|u}} are prescribed on the surface {{mvar|S}}, then it may be possible to determine the normal derivative of {{mvar|u}} on {{mvar|S}} from the differential equation. If the data on {{mvar|S}} and the differential equation determine the normal derivative of {{mvar|u}} on {{mvar|S}}, then {{mvar|S}} is non-characteristic. If the data on {{mvar|S}} and the differential equation ''do not'' determine the normal derivative of {{mvar|u}} on {{mvar|S}}, then the surface is '''characteristic''', and the differential equation restricts the data on {{mvar|S}}: the differential equation is ''internal'' to {{mvar|S}}.

# A first-order system {{math|''Lu'' {{=}} 0}} is ''elliptic'' if no surface is characteristic for {{mvar|L}}: the values of {{mvar|u}} on {{mvar|S}} and the differential equation always determine the normal derivative of {{mvar|u}} on {{mvar|S}}.
# A first-order system is ''hyperbolic'' at a point if there is a '''spacelike''' surface {{mvar|S}} with normal {{mvar|ξ}} at that point. This means that, given any non-trivial vector {{mvar|η}} orthogonal to {{mvar|ξ}}, and a scalar multiplier {{mvar|λ}}, the equation {{math|''Q''(''λξ'' + ''η'') {{=}} 0}} has {{mvar|m}} real roots {{math|''λ''&lt;sub&gt;1&lt;/sub&gt;, ''λ''&lt;sub&gt;2&lt;/sub&gt;,… ''λ''&lt;sub&gt;''m''&lt;/sub&gt;}}. The system is '''strictly hyperbolic''' if these roots are always distinct. The geometrical interpretation of this condition is as follows: the characteristic form {{math|''Q''(''ζ'') {{=}} 0}} defines a cone (the normal cone) with homogeneous coordinates ζ. In the hyperbolic case, this cone has {{mvar|m}} sheets, and the axis {{math|''ζ'' {{=}} ''λξ''}} runs inside these sheets: it does not intersect any of them. But when displaced from the origin by η, this axis intersects every sheet. In the elliptic case, the normal cone has no real sheets.

=== Equations of mixed type ===
If a PDE has coefficients that are not constant, it is possible that it will not belong to any of these categories but rather be of '''mixed type'''. A simple but important example is the [[Euler–Tricomi equation]]

: &lt;math&gt;u_{xx} = xu_{yy},&lt;/math&gt;

which is called '''elliptic-hyperbolic''' because it is elliptic in the region {{math|''x'' &lt; 0}}, hyperbolic in the region {{math|''x'' &gt; 0}}, and degenerate parabolic on the line {{math|''x'' {{=}} 0}}.
&lt;!--
''fill in: Dirichlet and Neumann boundaries, hyperbolic/parabolic/elliptic separation of variables, [[Fourier analysis]], [[Green's function]]s ...--&gt;

=== Infinite-order PDEs in quantum mechanics ===
In the [[phase space formulation]] of quantum mechanics,  one may consider the [[Method of quantum characteristics|quantum Hamilton's equations]] for trajectories of quantum particles. These equations are infinite-order PDEs. However, in the semiclassical expansion, one has a finite system of ODEs at any fixed order of [[Dirac constant|{{mvar|ħ}}]].  The evolution equation of the [[Wigner quasi-probability distribution|Wigner function]] is also an infinite-order PDE. The quantum trajectories are [[Method of quantum characteristics|quantum characteristics]], with the use of which one could calculate the evolution of the Wigner function.

== Analytical solutions ==

===Separation of variables===
{{main|Separable partial differential equation}}
Linear PDEs can be reduced to systems of ordinary differential equations by the important technique of separation of variables. This technique rests on a characteristic of solutions to differential equations: if one can find any solution that solves the equation and satisfies the boundary conditions, then it is ''the'' solution (this also applies to ODEs). We assume as an [[ansatz]] that the dependence of a solution on the parameters space and time can be written as a product of terms that each depend on a single parameter, and then see if this can be made to solve the problem.&lt;ref&gt;{{cite book|last1=Gershenfeld|first1=Neil|title=The nature of mathematical modeling|date=2000|publisher=Cambridge Univ. Press|location=Cambridge|isbn=0521570956|page=27|edition=Reprinted (with corr.)}}&lt;/ref&gt;

In the method of separation of variables, one reduces a PDE to a PDE in fewer variables, which is an ordinary differential equation if in one variable – these are in turn easier to solve.

This is possible for simple PDEs, which are called [[separable partial differential equation]]s, and the domain is generally a rectangle (a product of intervals). Separable PDEs correspond to [[diagonal matrices]] – thinking of "the value for fixed {{mvar|x}}" as a coordinate, each coordinate can be understood separately.

This generalizes to the [[method of characteristics]], and is also used in [[integral transform]]s.

===Method of characteristics===
{{main|Method of characteristics}}
In special cases, one can find characteristic curves on which the equation reduces to an ODE – changing coordinates in the domain to straighten these curves allows separation of variables, and is called the [[method of characteristics]].

More generally, one may find characteristic surfaces.

===Integral transform===
An [[integral transform]] may transform the PDE to a simpler one, in particular, a separable PDE. This corresponds to diagonalizing an operator.

An important example of this is [[Fourier analysis]], which diagonalizes the heat equation using the [[eigenbasis]] of sinusoidal waves.

If the domain is finite or periodic, an infinite sum of solutions such as a [[Fourier series]] is appropriate, but an integral of solutions such as a [[Fourier integral]] is generally required for infinite domains. The solution for a point source for the heat equation given above is an example of the use of a Fourier integral.

===Change of variables===

Often a PDE can be reduced to a simpler form with a known solution by a suitable [[Change of variables (PDE)|change of variables]].  For example, the [[Black–Scholes equation#Derivation|Black–Scholes]] PDE

:&lt;math&gt; \frac{\partial V}{\partial t} + \tfrac{1}{2}\sigma^2 S^2\frac{\partial^2 V}{\partial S^2} + rS\frac{\partial V}{\partial S} - rV = 0 &lt;/math&gt;

is reducible to the [[heat equation]]

:&lt;math&gt; \frac{\partial u}{\partial \tau} = \frac{\partial^2 u}{\partial x^2}&lt;/math&gt;

by the change of variables (for complete details see {{webarchive |url=https://web.archive.org/web/20080411030405/http://www.math.unl.edu/~sdunbar1/Teaching/MathematicalFinance/Lessons/BlackScholes/Solution/solution.shtml |date=April 11, 2008 |title=Solution of the Black Scholes Equation }})

:&lt;math&gt;\begin{align}
V(S,t) &amp;= K v(x,\tau),\\[5px]
x &amp;= \ln\left(\tfrac{S}{K} \right),\\[5px]
\tau &amp;= \tfrac{1}{2} \sigma^2 (T - t),\\[5px]
v(x,\tau)&amp;=e^{-\alpha x-\beta\tau} u(x,\tau).
\end{align}&lt;/math&gt;

===Fundamental solution===
{{main|Fundamental solution}}
Inhomogeneous equations can often be solved (for constant coefficient PDEs, always be solved) by finding the [[fundamental solution]] (the solution for a point source), then taking the [[convolution]] with the boundary conditions to get the solution.

This is analogous in [[signal processing]] to understanding a filter by its [[impulse response]].

===Superposition principle===
{{further| Superposition principle }}
The superposition principle applies to any linear system, including linear systems of PDEs. A common visualization of this concept is the interaction of two waves in phase being combined to result in a greater amplitude, for example {{math|sin ''x'' + sin ''x'' {{=}} 2 sin ''x''}}. The same principle can be observed in PDEs where the solutions may be real or complex and additive. [[Superposition principle|superposition]]
If {{math|''u''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''u''&lt;sub&gt;2&lt;/sub&gt;}} are solutions of linear PDE in some function space {{mvar|R}}, then {{math|''u'' {{=}} ''c''&lt;sub&gt;1&lt;/sub&gt;''u''&lt;sub&gt;1&lt;/sub&gt; + ''c''&lt;sub&gt;2&lt;/sub&gt;''u''&lt;sub&gt;2&lt;/sub&gt;}} with any constants {{math|''c''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''c''&lt;sub&gt;2&lt;/sub&gt;}} are also a solution of that PDE in the same function space.

===Methods for non-linear equations===
{{see also|nonlinear partial differential equation}}

There are no generally applicable methods to solve nonlinear PDEs. Still, existence and uniqueness results (such as the [[Cauchy–Kowalevski theorem]]) are often possible, as are proofs of important qualitative and quantitative properties of solutions (getting these results is a major part of [[mathematical analysis|analysis]]). Computational solution to the nonlinear PDEs, the [[split-step method]], exist for specific equations like [[nonlinear Schrödinger equation]].

Nevertheless, some techniques can be used for several types of equations. The [[h-principle|{{mvar|h}}-principle]] is the most powerful method to solve [[Underdetermined system|underdetermined]] equations. The [[Riquier–Janet theory]] is an effective method for obtaining information about many analytic [[Overdetermined system|overdetermined]] systems.

The [[method of characteristics]] ([[similarity transformation method]]) can be used in some very special cases to solve partial differential equations.

In some cases, a PDE can be solved via [[perturbation analysis]] in which the solution is considered to be a correction to an equation with a known solution. Alternatives are [[numerical analysis]] techniques from simple [[finite difference]] schemes to the more mature [[multigrid]] and [[finite element method]]s. Many interesting problems in science and engineering are solved in this way using [[computer]]s, sometimes high performance [[supercomputer]]s.

===Lie group method===
From 1870 [[Sophus Lie]]'s work put the theory of differential equations on a more satisfactory foundation. He showed that the integration theories of the older mathematicians can, by the introduction of what are now called [[Lie group]]s, be referred to a common source; and that ordinary differential equations which admit the same [[infinitesimal transformation]]s present comparable difficulties of integration. He also emphasized the subject of [[contact transformation|transformations of contact]].

A general approach to solving PDEs uses the symmetry property of differential equations, the continuous [[infinitesimal transformation]]s of solutions to solutions ([[Lie theory]]). Continuous [[group theory]], [[Lie algebras]] and [[differential geometry]] are used to understand the structure of linear and nonlinear partial differential equations for generating integrable equations, to find its [[Lax pair]]s, recursion operators, [[Bäcklund transform]] and finally finding exact analytic solutions to the PDE.

Symmetry methods have been recognized to study differential equations arising in mathematics, physics, engineering, and many other disciplines.

===Semianalytical methods===
The [[adomian decomposition method]], the [[Aleksandr Lyapunov|Lyapunov]] artificial small parameter method, and He's [[homotopy perturbation method]] are all special cases of the more general [[homotopy analysis method]]. These are series expansion methods, and except for the Lyapunov method, are independent of small physical parameters as compared to the well known [[perturbation theory]], thus giving these methods greater flexibility and solution generality.

== Numerical solutions ==
The three most widely used numerical methods to solve PDEs are the [[finite element analysis|finite element method]] (FEM), [[finite volume method]]s (FVM) and [[finite difference method]]s (FDM), as well other kind of methods called [[Meshfree methods]], which were made to solve problems where the before mentioned methods are limited. The FEM has a prominent position among these methods and especially its exceptionally efficient higher-order version [[hp-FEM]]. Other hybrid versions of FEM and Meshfree methods include the generalized finite element method (GFEM), [[extended finite element method]] (XFEM), [[Spectral element method|spectral finite element method]] (SFEM), [[Meshfree methods|meshfree finite element method]], [[Discontinuous Galerkin Method|discontinuous Galerkin finite element method]] (DGFEM), [[Element-Free Galerkin Method]] (EFGM), [[Interpolating Element-Free Galerkin Method]] (IEFGM), etc.

=== Finite element method ===
{{main|Finite element method}}
The finite element method (FEM) (its practical application often known as finite element analysis (FEA)) is a numerical technique for finding approximate solutions of partial differential equations (PDE) as well as of integral equations. The solution approach is based either on eliminating the differential equation completely (steady state problems), or rendering the PDE into an approximating system of ordinary differential equations, which are then numerically integrated using standard techniques such as Euler's method, Runge–Kutta, etc.

===Finite difference method===
{{main|Finite difference method}}
Finite-difference methods are numerical methods for approximating the solutions to differential equations using [[finite difference]] equations to approximate derivatives.

=== Finite volume method ===
{{main|Finite volume method}}
Similar to the finite difference method or finite element method, values are calculated at discrete places on a meshed geometry. "Finite volume" refers to the small volume surrounding each node point on a mesh. In the finite volume method, surface integrals in a partial differential equation that contain a divergence term are converted to volume integrals, using the [[divergence theorem]]. These terms are then evaluated as fluxes at the surfaces of each finite volume. Because the flux entering a given volume is identical to that leaving the adjacent volume, these methods conserve mass by design.

==See also==
* [[Dirichlet boundary condition]]
* [[Jet bundle]]
* [[Laplace transform applied to differential equations]]
* [[List of dynamical systems and differential equations topics]]
* [[Matrix differential equation]]
* [[Neumann boundary condition]]
* [[Numerical partial differential equations]]
* [[Partial differential algebraic equation]]
* [[Recurrence relation]]
* [[Robin boundary condition]]
* [[Stochastic processes and boundary value problems]]

==Notes==
{{Reflist}}

== References ==
{{refbegin|2}}
* {{cite book |title=Solving Frontier problems of Physics: The decomposition method
|first=G.|last=Adomian|publisher=Kluwer Academic Publishers|year=1994|isbn=|page=}}
* {{Citation |first=R. |last=Courant |lastauthoramp=yes |first2=D. |last2=Hilbert |title=Methods of Mathematical Physics |volume=II |publisher=Wiley-Interscience |location=New York |year=1962 }}.
* {{Citation |authorlink=Lawrence C. Evans |first=L. C. |last=Evans |title=Partial Differential Equations |publisher=American Mathematical Society |location=Providence |year=1998 |isbn=0-8218-0772-2 }}.
* {{cite book|last1=Holubová|first1=Pavel Drábek ; Gabriela|title=Elements of partial differential equations|date=2007|publisher=de Gruyter|location=Berlin|isbn=9783110191240|edition=[Online-Ausg.].}}
* {{Citation |first=Nail H |last=Ibragimov |title=CRC Handbook of Lie Group Analysis of Differential Equations Vol. 1-3 |publisher=CRC-Press |location=Providence |year=1993 |isbn=0-8493-4488-3 }}.
* {{Citation |authorlink=Fritz John |first=F. |last=John |title=Partial Differential Equations |location=New York |publisher=Springer-Verlag |year=1982 |edition=4th |isbn=0-387-90609-6 }}.
* {{Citation |first=J. |last=Jost |title=Partial Differential Equations |publisher=Springer-Verlag |location=New York |year=2002 |isbn=0-387-95428-7 }}.
* {{Citation |first=Hans |last=Lewy |year=1957 |title=An example of a smooth linear partial differential equation without solution |journal=Annals of Mathematics |series=Second Series |volume=66 |issue=1 |pages=155–158 |doi= 10.2307/1970121}}.
* {{Citation | last=Liao | first=S.J. |authorlink=Liao Shijun| title=Beyond Perturbation: Introduction to the Homotopy Analysis Method | publisher=Chapman &amp; Hall/ CRC Press | location=Boca Raton  | year=2003 | isbn=1-58488-407-X }}
* {{Citation |first=P.J. |last=Olver |author-link=Peter J. Olver |year=1995 |title=Equivalence, Invariants and Symmetry |publisher=Cambridge Press }}.
* {{Citation |authorlink=Ivan Petrovsky |first=I. G. |last=Petrovskii |title=Partial Differential Equations |publisher=W. B. Saunders Co. |location=Philadelphia |year=1967 }}.
* {{Citation |first=Y. |last=Pinchover |lastauthoramp=yes |first2=J. |last2=Rubinstein |title=An Introduction to Partial Differential Equations |publisher=Cambridge University Press |location=New York |year=2005 |isbn=0-521-84886-5 }}.
* {{Citation |first=A. D. |last=Polyanin |title=Handbook of Linear Partial Differential Equations for Engineers and Scientists |publisher=Chapman &amp; Hall/CRC Press |location=Boca Raton |year=2002 |isbn=1-58488-299-9 }}.
* {{Citation |first=A. D. |last=Polyanin |lastauthoramp=yes |first2=V. F. |last2=Zaitsev |title=Handbook of Nonlinear Partial Differential Equations |publisher=Chapman &amp; Hall/CRC Press |location=Boca Raton |year=2004 |isbn=1-58488-355-3 }}.
* {{Citation |first=A. D. |last=Polyanin |first2=V. F. |last2=Zaitsev |lastauthoramp=yes |first3=A. |last3=Moussiaux |title=Handbook of First Order Partial Differential Equations |publisher=Taylor &amp; Francis |location=London |year=2002 |isbn=0-415-27267-X }}.
* {{citation|mr=3014456|last=Roubíček|first= T.|title=Nonlinear Partial Differential Equations with Applications|publisher= Birkhäuser|place= Basel, Boston, Berlin|edition=2nd|year= 2013|ISBN= 978-3-0348-0512-4|doi=10.1007/978-3-0348-0513-1}}
* {{Citation |first=P. |last=Solin |title=Partial Differential Equations and the Finite Element Method |publisher=J. Wiley &amp; Sons |location=Hoboken, NJ |year=2005 |isbn=0-471-72070-4 }}.
* {{Citation |first=P. |last=Solin |first2=K. |last2=Segeth |lastauthoramp=yes |first3=I. |last3=Dolezel |title=Higher-Order Finite Element Methods |publisher=Chapman &amp; Hall/CRC Press |location=Boca Raton |year=2003 |isbn=1-58488-438-X }}.
* {{Citation |first=H. |last=Stephani |year=1989 |title=Differential Equations: Their Solution Using Symmetries. Edited by M. MacCallum |publisher=Cambridge University Press }}.
* {{cite book |title=Partial Differential Equations and Solitary Waves Theory
|first=Abdul-Majid|last=Wazwaz|publisher=Higher Education Press|year=2009|isbn=978-3-642-00251-9|page=}}
* {{cite book |title=Partial Differential Equations Methods and Applications
|first=Abdul-Majid|last=Wazwaz|publisher=A.A. Balkema|year=2002|isbn=90-5809-369-7|page=}}
* {{Citation |first=D. |last=Zwillinger |title=Handbook of Differential Equations |publisher=Academic Press |location=Boston |year=1997 |edition=3rd |isbn=0-12-784395-7 }}.
* {{Citation |authorlink=Neil Gershenfeld |first=N. |last=Gershenfeld |title=The Nature of Mathematical Modeling |location=New York |publisher=Cambridge University Press, New York, NY, USA |year=1999 |edition=1st |isbn=0-521-57095-6 }}.
* {{Citation |first=I.S. |last=Krasil'shchik |lastauthoramp=yes |first2=A.M., Eds. |last2=Vinogradov |title=Symmetries and Conserwation Laws for Differential Equations of Mathematical Physics |publisher=American Mathematical Society, Providence, Rhode Island, USA |year=1999 |isbn=0-8218-0958-X }}.
* {{Citation |first=I.S. |last=Krasil'shchik |first2=V.V. |last2=Lychagin|lastauthoramp=yes |first3=A.M. |last3=Vinogradov |title=Geometry of Jet Spaces and Nonlinear Partial Differential Equations |publisher=Gordon and Breach Science Publishers, New York, London, Paris, Montreux, Tokyo |year=1986 |isbn=2-88124-051-8 }}.
* {{Citation |first=A.M. |last=Vinogradov |title=Cohomological Analysis of Partial Differential Equations and Secondary Calculus |publisher=American Mathematical Society, Providence, Rhode Island, USA |year=2001 |isbn=0-8218-2922-X }}.
{{refend}}

== Further reading ==
* {{Cite journal|last=Cajori|first=Florian|authorlink=Florian Cajori|year=1928|title=The Early History of Partial Differential Equations and of Partial Differentiation and Integration|url=http://www.math.harvard.edu/archive/21a_fall_14/exhibits/cajori/cajori.pdf|journal=The American Mathematical Monthly|volume=35|issue=9|pages=459–467|doi=10.2307/2298771}}

== External links ==
{{Sister project links| wikt=no | commons=Category:Solutions of PDE | b=Partial Differential Equations | n=no | q=Partial differential equation | s=no | v=no | voy=no | species=no | d=no}}
* {{springer|title=Differential equation, partial|id=p/d031920}}
* [http://eqworld.ipmnet.ru/en/pde-en.htm Partial Differential Equations: Exact Solutions] at EqWorld: The World of Mathematical Equations.
* [http://eqworld.ipmnet.ru/en/solutions/eqindex/eqindex-pde.htm Partial Differential Equations: Index] at EqWorld: The World of Mathematical Equations.
* [http://eqworld.ipmnet.ru/en/methods/meth-pde.htm Partial Differential Equations: Methods] at EqWorld: The World of Mathematical Equations.
* [http://www.exampleproblems.com/wiki/index.php?title=Partial_Differential_Equations Example problems with solutions] at exampleproblems.com
* [http://mathworld.wolfram.com/PartialDifferentialEquation.html Partial Differential Equations] at mathworld.wolfram.com
* [https://reference.wolfram.com/language/FEMDocumentation/tutorial/SolvingPDEwithFEM.html Partial Differential Equations] with Mathematica
* [http://www.mathworks.com/moler/pdes.pdf Partial Differential Equations] in Cleve Moler: Numerical Computing with MATLAB
* [http://www.nag.com/numeric/fl/nagdoc_fl24/html/D03/d03intro.html Partial Differential Equations] at nag.com
* [https://web.archive.org/web/20060812140140/http://tosio.math.toronto.edu/wiki/index.php/Main_Page Dispersive PDE Wiki]
* [http://www.primat.mephi.ru/wiki/ NEQwiki, the nonlinear equations encyclopedia]
* [http://www.scholarpedia.org/article/Partial_differential_equation Partial differential equation | Scholarpedia]

{{Differential equations topics}}
{{Authority control}}

[[Category:Multivariable calculus]]
[[Category:Differential equations]]
[[Category:Partial differential equations|*]]
[[Category:Concepts in physics]]</text>
      <sha1>llvh7mvmrw0f23jsmpwcoi3biffrara</sha1>
    </revision>
  </page>
  <page>
    <title>Power of two</title>
    <ns>0</ns>
    <id>376948</id>
    <revision>
      <id>870601234</id>
      <parentid>870161684</parentid>
      <timestamp>2018-11-25T22:01:57Z</timestamp>
      <contributor>
        <username>ComplexRational</username>
        <id>34997143</id>
      </contributor>
      <comment>removed section 'expressions and notations' per [[WP:NOTDIR]]; this does not belong here (maybe in [[exponentiation#History of the notation]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33608">{{multiple issues|
{{refimprove|date=June 2018}}
{{tone|date=June 2018}}
{{original research|date=June 2018}}
{{trivia|date=June 2018}}
}}
{{Other uses}}
[[Image:Ten octaves visualization.svg|thumb|Visualization of powers of two from 1 to 1024 (2&lt;sup&gt;0&lt;/sup&gt; to 2&lt;sup&gt;10&lt;/sup&gt;).]]

In [[mathematics]], a '''power of two''' is a number of the form {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}} where {{mvar|n}} is an [[integer]], i.e. the result of [[exponentiation]] with number [[2|two]] as the [[Base (exponentiation)|base]] and integer&amp;nbsp;{{mvar|n}} as the [[exponent]].

In a context where only integers are considered, {{mvar|n}} is restricted to non-negative values,&lt;ref&gt;{{cite book |title=Schaum's Outline of Theory and Problems of Essential Computer Mathematics |first=Seymour |last=Lipschutz |year=1982 |isbn=0-07-037990-4 |page=3 |publisher=McGraw-Hill |location=New York}}&lt;/ref&gt; so we have 1, 2, and 2 [[multiplication|multiplied]] by itself a certain number of times.&lt;ref&gt;{{cite book |title=Mathematics Masterclasses |first=Michael J. |last=Sewell |year=1997 |isbn=0-19-851494-8 |page=78 |publisher=Oxford University Press |location=Oxford}}&lt;/ref&gt;

Because two is the base of the [[Binary number|binary numeral system]], powers of two are common in [[computer science]]. Written in binary, a power of two always has the form 100…000 or 0.00…001, just like a [[power of ten]] in the [[decimal]] system.

== Computer science ==
Two to the power of {{mvar|n}}, written as {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}, is the number of ways the [[bit]]s in a [[binary numeral system|binary]] word of length {{mvar|n}} can be arranged. A word, interpreted as an unsigned [[integer (computer science)|integer]], can represent values from 0&amp;nbsp;({{math|000…000&lt;sub&gt;2&lt;/sub&gt;}}) to {{math|2&lt;sup&gt;''n''&lt;/sup&gt; − 1}}&amp;nbsp;({{math|111…111&lt;sub&gt;2&lt;/sub&gt;}}) inclusively. Corresponding [[signedness|signed]] integer values can be positive, negative and zero; see [[signed number representations]]. Either way, one less than a power of two is often the upper bound of an integer in binary computers. As a consequence, numbers of this form show up frequently in computer software. As an example, a [[video game]] running on an 8-bit system might limit the score or the number of items the player can hold to 255—the result of using a [[byte]], which is [[octet (computing)|8 bits long]], to store the number, giving a maximum value of {{math|1=2&lt;sup&gt;8&lt;/sup&gt; − 1 = 255}}.  For example, in the original ''[[The Legend of Zelda (video game)|Legend of Zelda]]'' the main character was limited to carrying 255&amp;nbsp;rupees (the currency of the game) at any given time, and the video game [[Pac-Man]] famously shuts down at level&amp;nbsp;255.

Powers of two are often used to measure computer memory.  A byte is now considered eight bits (an [[octet (computing)|octet]], resulting in the possibility of 256 values (2&lt;sup&gt;8&lt;/sup&gt;).  (The term ''byte'' once meant (and in some cases, still means) a [[bit#More than one bit|collection of bits]], typically of 5 to 32 bits, rather than only an 8-bit unit.)  The prefix ''kilo'', in conjunction with ''byte'', may be, and has traditionally been, used, to mean 1,024 (2&lt;sup&gt;10&lt;/sup&gt;). However, in general, the term ''kilo'' has been used in the [[International System of Units]] to mean 1,000 (10&lt;sup&gt;3&lt;/sup&gt;). [[Binary prefixes]] have been standardized, such as ''kibi''&amp;nbsp;(Ki) meaning 1,024. Nearly all [[processor register]]s have sizes that are powers of two, 32 or 64 being most common.

Powers of two occur in a range of other places as well. For many [[disk drive]]s, at least one of the sector size, number of sectors per track, and number of tracks per surface is a power of two. The logical block size is almost always a power of two.

Numbers that are not powers of two occur in a number of situations, such as video resolutions, but they are often the sum or product of only two or three powers of two, or powers of two minus one. For example, {{math|1=640 = 32 × 20  }}, and {{math|1=480 = 32 × 15}}. Put another way, they have fairly regular bit patterns.

== Mersenne and Fermat primes ==
A [[prime number]] that is one less than a power of two is called a [[Mersenne prime]]. For example, the prime number [[thirty-one|31]] is a Mersenne prime because it is 1 less than 32 (2&lt;sup&gt;5&lt;/sup&gt;). Similarly, a prime number (like [[257 (number)|257]]) that is one more than a positive power of two is called a [[Fermat prime]]—the exponent  itself is a power of two.  A [[fraction (mathematics)|fraction]] that has a power of two as its [[denominator]] is called a [[dyadic rational]]. The numbers that can be represented as sums of consecutive positive integers are called [[polite number]]s; they are exactly the numbers that are not powers of two.

== Euclid's ''Elements'', Book IX ==
The geometric progression 1, 2, 4, 8, 16, 32, … (or, in the [[binary numeral system]], 1, 10, 100, 1000, 10000, 100000, … ) is important in [[number theory]]. Book&amp;nbsp;IX, Proposition&amp;nbsp;36 of [[Euclid's Elements|''Elements'']] proves that if the sum of the first {{mvar|n}} terms of this progression is a prime number (and thus is a Mersenne prime as mentioned above), then this sum times the {{mvar|n}}th term is a [[perfect number]]. For example, the sum of the first 5 terms of the series 1 + 2 + 4 + 8 + 16 = 31, which is a prime number. The sum 31 multiplied by 16 (the 5th term in the series) equals 496, which is a perfect number.

Book&amp;nbsp;IX, Proposition&amp;nbsp;35, proves that in a geometric series if the first term is subtracted from the second and last term in the sequence, then as the excess of the second is to the first—so is the excess of the last to all those before it. (This is a restatement of our formula for geometric series from above.) Applying this to the geometric progression 31, 62, 124, 248, 496 (which results from 1, 2, 4, 8, 16 by multiplying all terms by 31), we see that 62 minus 31 is to 31 as 496 minus 31 is to the sum of 31, 62, 124, 248. Therefore, the numbers 1, 2, 4, 8, 16, 31, 62, 124 and 248 add up to 496 and further these are all the numbers that [[divisor|divide]] 496. For suppose that {{mvar|p}} divides 496 and it is not amongst these numbers. Assume {{math|''p q''}} is equal to {{math|16 × 31}}, or 31 is to {{mvar|q}} as {{mvar|p}} is to 16. Now {{mvar|p}} cannot divide 16 or it would be amongst the numbers 1, 2, 4, 8 or 16.
Therefore, 31 cannot divide {{mvar|q}}. And since 31 does not divide {{mvar|q}} and {{mvar|q}} measures 496, the [[fundamental theorem of arithmetic]] implies that {{mvar|q}} must divide 16 and be amongst the numbers 1, 2, 4, 8 or 16. Let {{mvar|q}} be 4, then {{mvar|p}} must be 124, which is impossible since by hypothesis {{mvar|p}} is not amongst the numbers 1, 2, 4, 8, 16, 31, 62, 124 or 248.

== The 0th through 95th powers of two ==
{{Anchor|List of powers of two}}
{{OEIS|id=A000079}}

&lt;div style="overflow:auto"&gt;
{| class="wikitable" style="text-align:center"
|- style="background:#e9e9e9;" 
|'''2&lt;sup&gt;0&lt;/sup&gt;'''  || '''=''' ||align="right"| '''[[1 (number)|1]]'''
|bgcolor="white" rowspan=16|
|'''2&lt;sup&gt;16&lt;/sup&gt;''' || '''=''' ||align="right"| '''[[65536 (number)|65,536]]'''
|bgcolor="white" rowspan=16|
|'''2&lt;sup&gt;32&lt;/sup&gt;''' || '''=''' ||align="right"| '''4,294,967,296'''
|bgcolor="white" rowspan=16|
|'''2&lt;sup&gt;48&lt;/sup&gt;''' || '''=''' ||align="right"| '''281,474,976,710,656'''
|bgcolor="white" rowspan=16|
|'''2&lt;sup&gt;64&lt;/sup&gt;''' || '''=''' ||align="right"| '''18,446,744,073,709,551,616'''
|bgcolor="white" rowspan=16|
|'''2&lt;sup&gt;80&lt;/sup&gt;''' || '''=''' ||align="right"| '''1,208,925,819,614,629,174,706,176'''
|-----
|2&lt;sup&gt;1&lt;/sup&gt;  || = ||align="right"| [[2 (number)|2]]
|2&lt;sup&gt;17&lt;/sup&gt; || = ||align="right"| 131,072
|2&lt;sup&gt;33&lt;/sup&gt; || = ||align="right"| 8,589,934,592
|2&lt;sup&gt;49&lt;/sup&gt; || = ||align="right"| 562,949,953,421,312
|2&lt;sup&gt;65&lt;/sup&gt; || = ||align="right"| 36,893,488,147,419,103,232
|2&lt;sup&gt;81&lt;/sup&gt; || = ||align="right"| 2,417,851,639,229,258,349,412,352
|-----
|2&lt;sup&gt;2&lt;/sup&gt;  || = ||align="right"| [[4 (number)|4]]
|2&lt;sup&gt;18&lt;/sup&gt; || = ||align="right"| 262,144
|2&lt;sup&gt;34&lt;/sup&gt; || = ||align="right"| 17,179,869,184
|2&lt;sup&gt;50&lt;/sup&gt; || = ||align="right"| 1,125,899,906,842,624
|2&lt;sup&gt;66&lt;/sup&gt; || = ||align="right"| 73,786,976,294,838,206,464
|2&lt;sup&gt;82&lt;/sup&gt; || = ||align="right"| 4,835,703,278,458,516,698,824,704
|-----
|2&lt;sup&gt;3&lt;/sup&gt;  || = ||align="right"| [[8 (number)|8]]
|2&lt;sup&gt;19&lt;/sup&gt; || = ||align="right"| 524,288
|2&lt;sup&gt;35&lt;/sup&gt; || = ||align="right"| 34,359,738,368
|2&lt;sup&gt;51&lt;/sup&gt; || = ||align="right"| 2,251,799,813,685,248
|2&lt;sup&gt;67&lt;/sup&gt; || = ||align="right"| 147,573,952,589,676,412,928
|2&lt;sup&gt;83&lt;/sup&gt; || = ||align="right"| 9,671,406,556,917,033,397,649,408
|-----
|'''2&lt;sup&gt;4&lt;/sup&gt;'''  || '''=''' ||align="right"| '''[[16 (number)|16]]'''
|'''2&lt;sup&gt;20&lt;/sup&gt;''' || '''=''' ||align="right"| '''1,048,576'''
|'''2&lt;sup&gt;36&lt;/sup&gt;''' || '''=''' ||align="right"| '''68,719,476,736'''
|'''2&lt;sup&gt;52&lt;/sup&gt;''' || '''=''' ||align="right"| '''4,503,599,627,370,496'''
|'''2&lt;sup&gt;68&lt;/sup&gt;''' || '''=''' ||align="right"| '''295,147,905,179,352,825,856'''
|'''2&lt;sup&gt;84&lt;/sup&gt;''' || '''=''' ||align="right"| '''19,342,813,113,834,066,795,298,816'''
|-----
|2&lt;sup&gt;5&lt;/sup&gt;  || = ||align="right"| [[32 (number)|32]]
|2&lt;sup&gt;21&lt;/sup&gt; || = ||align="right"| 2,097,152
|2&lt;sup&gt;37&lt;/sup&gt; || = ||align="right"| 137,438,953,472
|2&lt;sup&gt;53&lt;/sup&gt; || = ||align="right"| 9,007,199,254,740,992
|2&lt;sup&gt;69&lt;/sup&gt; || = ||align="right"| 590,295,810,358,705,651,712
|2&lt;sup&gt;85&lt;/sup&gt; || = ||align="right"| 38,685,626,227,668,133,590,597,632
|-----
|2&lt;sup&gt;6&lt;/sup&gt;  || = ||align="right"| [[64 (number)|64]]
|2&lt;sup&gt;22&lt;/sup&gt; || = ||align="right"| 4,194,304
|2&lt;sup&gt;38&lt;/sup&gt; || = ||align="right"| 274,877,906,944
|2&lt;sup&gt;54&lt;/sup&gt; || = ||align="right"| 18,014,398,509,481,984
|2&lt;sup&gt;70&lt;/sup&gt; || = ||align="right"| 1,180,591,620,717,411,303,424
|2&lt;sup&gt;86&lt;/sup&gt; || = ||align="right"| 77,371,252,455,336,267,181,195,264
|-----
|2&lt;sup&gt;7&lt;/sup&gt;  || = ||align="right"| [[128 (number)|128]]
|2&lt;sup&gt;23&lt;/sup&gt; || = ||align="right"| 8,388,608
|2&lt;sup&gt;39&lt;/sup&gt; || = ||align="right"| 549,755,813,888
|2&lt;sup&gt;55&lt;/sup&gt; || = ||align="right"| 36,028,797,018,963,968
|2&lt;sup&gt;71&lt;/sup&gt; || = ||align="right"| 2,361,183,241,434,822,606,848
|2&lt;sup&gt;87&lt;/sup&gt; || = ||align="right"| 154,742,504,910,672,534,362,390,528
|-----
|- style="background:#e9e9e9;" 
|'''2&lt;sup&gt;8&lt;/sup&gt;'''  || '''=''' ||align="right"| '''[[256 (number)|256]]'''
|'''2&lt;sup&gt;24&lt;/sup&gt;''' || '''=''' ||align="right"| '''16,777,216'''
|'''2&lt;sup&gt;40&lt;/sup&gt;''' || '''=''' ||align="right"| '''1,099,511,627,776'''
|'''2&lt;sup&gt;56&lt;/sup&gt;''' || '''=''' ||align="right"| '''72,057,594,037,927,936'''
|'''2&lt;sup&gt;72&lt;/sup&gt;''' || '''=''' ||align="right"| '''4,722,366,482,869,645,213,696'''
|'''2&lt;sup&gt;88&lt;/sup&gt;''' || '''=''' ||align="right"| '''309,485,009,821,345,068,724,781,056'''
|-----
|2&lt;sup&gt;9&lt;/sup&gt;  || = ||align="right"| [[512 (number)|512]]
|2&lt;sup&gt;25&lt;/sup&gt; || = ||align="right"| 33,554,432
|2&lt;sup&gt;41&lt;/sup&gt; || = ||align="right"| 2,199,023,255,552
|2&lt;sup&gt;57&lt;/sup&gt; || = ||align="right"| 144,115,188,075,855,872
|2&lt;sup&gt;73&lt;/sup&gt; || = ||align="right"| 9,444,732,965,739,290,427,392
|2&lt;sup&gt;89&lt;/sup&gt; || = ||align="right"| 618,970,019,642,690,137,449,562,112
|-----
|2&lt;sup&gt;10&lt;/sup&gt; || = ||align="right"|[[1024 (number)|1,024]]
|2&lt;sup&gt;26&lt;/sup&gt; || = ||align="right"| 67,108,864
|2&lt;sup&gt;42&lt;/sup&gt; || = ||align="right"| 4,398,046,511,104
|2&lt;sup&gt;58&lt;/sup&gt; || = ||align="right"| 288,230,376,151,711,744
|2&lt;sup&gt;74&lt;/sup&gt; || = ||align="right"| 18,889,465,931,478,580,854,784
|2&lt;sup&gt;90&lt;/sup&gt; || = ||align="right"| 1,237,940,039,285,380,274,899,124,224
|-----
|2&lt;sup&gt;11&lt;/sup&gt; || = ||align="right"| 2,048
|2&lt;sup&gt;27&lt;/sup&gt; || = ||align="right"| 134,217,728
|2&lt;sup&gt;43&lt;/sup&gt; || = ||align="right"| 8,796,093,022,208
|2&lt;sup&gt;59&lt;/sup&gt; || = ||align="right"| 576,460,752,303,423,488
|2&lt;sup&gt;75&lt;/sup&gt; || = ||align="right"| 37,778,931,862,957,161,709,568
|2&lt;sup&gt;91&lt;/sup&gt; || = ||align="right"| 2,475,880,078,570,760,549,798,248,448
|-----
|'''2&lt;sup&gt;12&lt;/sup&gt;''' || '''=''' ||align="right"| '''4,096'''
|'''2&lt;sup&gt;28&lt;/sup&gt;''' || '''=''' ||align="right"| '''268,435,456'''
|'''2&lt;sup&gt;44&lt;/sup&gt;''' || '''=''' ||align="right"| '''17,592,186,044,416'''
|'''2&lt;sup&gt;60&lt;/sup&gt;''' || '''=''' ||align="right"| '''1,152,921,504,606,846,976'''
|'''2&lt;sup&gt;76&lt;/sup&gt;''' || '''=''' ||align="right"| '''75,557,863,725,914,323,419,136'''
|'''2&lt;sup&gt;92&lt;/sup&gt;''' || '''=''' ||align="right"| '''4,951,760,157,141,521,099,596,496,896'''
|-----
|2&lt;sup&gt;13&lt;/sup&gt; || = ||align="right"| 8,192
|2&lt;sup&gt;29&lt;/sup&gt; || = ||align="right"| 536,870,912
|2&lt;sup&gt;45&lt;/sup&gt; || = ||align="right"| 35,184,372,088,832
|2&lt;sup&gt;61&lt;/sup&gt; || = ||align="right"| 2,305,843,009,213,693,952
|2&lt;sup&gt;77&lt;/sup&gt; || = ||align="right"| 151,115,727,451,828,646,838,272
|2&lt;sup&gt;93&lt;/sup&gt; || = ||align="right"| 9,903,520,314,283,042,199,192,993,792
|-----
|2&lt;sup&gt;14&lt;/sup&gt; || = ||align="right"| 16,384
|2&lt;sup&gt;30&lt;/sup&gt; || = ||align="right"| 1,073,741,824
|2&lt;sup&gt;46&lt;/sup&gt; || = ||align="right"| 70,368,744,177,664
|2&lt;sup&gt;62&lt;/sup&gt; || = ||align="right"| 4,611,686,018,427,387,904
|2&lt;sup&gt;78&lt;/sup&gt; || = ||align="right"| 302,231,454,903,657,293,676,544
|2&lt;sup&gt;94&lt;/sup&gt; || = ||align="right"| 19,807,040,628,566,084,398,385,987,584
|-----
|2&lt;sup&gt;15&lt;/sup&gt; || = ||align="right"| 32,768
|2&lt;sup&gt;31&lt;/sup&gt; || = ||align="right"| 2,147,483,648
|2&lt;sup&gt;47&lt;/sup&gt; || = ||align="right"| 140,737,488,355,328
|2&lt;sup&gt;63&lt;/sup&gt; || = ||align="right"| 9,223,372,036,854,775,808
|2&lt;sup&gt;79&lt;/sup&gt; || = ||align="right"| 604,462,909,807,314,587,353,088
|2&lt;sup&gt;95&lt;/sup&gt; || = ||align="right"| 39,614,081,257,132,168,796,771,975,168
|}
&lt;/div&gt;
Starting with&amp;nbsp;2 the last digit is periodic with period&amp;nbsp;4, with the cycle 2–4–8–6–, and starting with&amp;nbsp;4 the last two digits are periodic with period&amp;nbsp;20. These patterns are generally true of any power, with respect to any [[radix|base]]. The pattern continues, of course, where each pattern has starting point {{math|2&lt;sup&gt;''k''&lt;/sup&gt;}}, and the period is the [[multiplicative order]] of 2&amp;nbsp;modulo&amp;nbsp;{{math|5&lt;sup&gt;''k''&lt;/sup&gt;}}, which is {{math|&amp;phi;(5&lt;sup&gt;''k''&lt;/sup&gt;)}}&amp;nbsp;=&amp;nbsp;4&amp;nbsp;&amp;times;&amp;nbsp;{{math|5&lt;sup&gt;''k''&amp;minus;1&lt;/sup&gt;}} (see [[Multiplicative group of integers modulo n]]).{{cn|date=June 2018}}

==  Powers of 1024  ==
{{OEIS|id=A140300}}

The first few powers of 2&lt;sup&gt;10&lt;/sup&gt; are slightly larger than those same powers of 1000:
{|
|2&lt;sup&gt;0&lt;/sup&gt;||=||align="left"|1||= 1000&lt;sup&gt;0&lt;/sup&gt;||align="right"|(0% deviation)
|-
|2&lt;sup&gt;10&lt;/sup&gt;||=||align="left"|1&amp;nbsp;024||≈ 1000&lt;sup&gt;1&lt;/sup&gt;||align="right"|(2.4% deviation)
|-
|2&lt;sup&gt;20&lt;/sup&gt;||=||align="left"|1&amp;nbsp;048&amp;nbsp;576||≈ 1000&lt;sup&gt;2&lt;/sup&gt;||align="right"|(4.9% deviation)
|-
|2&lt;sup&gt;30&lt;/sup&gt;||=||align="left"|1&amp;nbsp;073&amp;nbsp;741&amp;nbsp;824||≈ 1000&lt;sup&gt;3&lt;/sup&gt;||align="right"|(7.4% deviation)
|-
|2&lt;sup&gt;40&lt;/sup&gt;||=||align="left"|1&amp;nbsp;099&amp;nbsp;511&amp;nbsp;627&amp;nbsp;776||≈ 1000&lt;sup&gt;4&lt;/sup&gt;||align="right"|(10% deviation)
|-
|2&lt;sup&gt;50&lt;/sup&gt;||=||align="left"|1&amp;nbsp;125&amp;nbsp;899&amp;nbsp;906&amp;nbsp;842&amp;nbsp;624||≈ 1000&lt;sup&gt;5&lt;/sup&gt;||align="right"|(12.6% deviation)
|-
|2&lt;sup&gt;60&lt;/sup&gt;||=||align="left"|1&amp;nbsp;152&amp;nbsp;921&amp;nbsp;504&amp;nbsp;606&amp;nbsp;846&amp;nbsp;976||≈ 1000&lt;sup&gt;6&lt;/sup&gt;||align="right"|(15.3% deviation)
|-
|2&lt;sup&gt;70&lt;/sup&gt;||=||align="left"|1&amp;nbsp;180&amp;nbsp;591&amp;nbsp;620&amp;nbsp;717&amp;nbsp;411&amp;nbsp;303&amp;nbsp;424||≈ 1000&lt;sup&gt;7&lt;/sup&gt;||align="right"|(18.1% deviation)
|-
|2&lt;sup&gt;80&lt;/sup&gt;||=||align="left"|1&amp;nbsp;208&amp;nbsp;925&amp;nbsp;819&amp;nbsp;614&amp;nbsp;629&amp;nbsp;174&amp;nbsp;706&amp;nbsp;176||≈ 1000&lt;sup&gt;8&lt;/sup&gt;||align="right"|(20.9% deviation)
|-
|2&lt;sup&gt;90&lt;/sup&gt;||=||align="left"|1&amp;nbsp;237&amp;nbsp;940&amp;nbsp;039&amp;nbsp;285&amp;nbsp;380&amp;nbsp;274&amp;nbsp;899&amp;nbsp;124&amp;nbsp;224||≈  1000&lt;sup&gt;9&lt;/sup&gt;||align="right"|(23.8% deviation)
|-
|2&lt;sup&gt;100&lt;/sup&gt;||=||align="left"|1&amp;nbsp;267&amp;nbsp;650&amp;nbsp;600&amp;nbsp;228&amp;nbsp;229&amp;nbsp;401&amp;nbsp;496&amp;nbsp;703&amp;nbsp;205&amp;nbsp;376||≈ 1000&lt;sup&gt;10&lt;/sup&gt;||align="right"|(26.8% deviation)
|-
|2&lt;sup&gt;110&lt;/sup&gt;||=||align="left"|1&amp;nbsp;298&amp;nbsp;074&amp;nbsp;214&amp;nbsp;633&amp;nbsp;706&amp;nbsp;907&amp;nbsp;132&amp;nbsp;624&amp;nbsp;082&amp;nbsp;305&amp;nbsp;024||≈ 1000&lt;sup&gt;11&lt;/sup&gt;||align="right"|(29.8% deviation)
|-
|2&lt;sup&gt;120&lt;/sup&gt;||=||align="left|1&amp;nbsp;329&amp;nbsp;227&amp;nbsp;995&amp;nbsp;784&amp;nbsp;915&amp;nbsp;872&amp;nbsp;903&amp;nbsp;807&amp;nbsp;060&amp;nbsp;280&amp;nbsp;344&amp;nbsp;576||≈ 1000&lt;sup&gt;12&lt;/sup&gt;||align="right"|(32.9% deviation)
|-
|2&lt;sup&gt;130&lt;/sup&gt;||=||align="left|1&amp;nbsp;361&amp;nbsp;129&amp;nbsp;467&amp;nbsp;683&amp;nbsp;753&amp;nbsp;853&amp;nbsp;853&amp;nbsp;498&amp;nbsp;429&amp;nbsp;727&amp;nbsp;072&amp;nbsp;845&amp;nbsp;824||≈ 1000&lt;sup&gt;13&lt;/sup&gt;||align="right"|(36.1% deviation)
|-
|2&lt;sup&gt;140&lt;/sup&gt;||=||align="left|1&amp;nbsp;393&amp;nbsp;796&amp;nbsp;574&amp;nbsp;908&amp;nbsp;163&amp;nbsp;946&amp;nbsp;345&amp;nbsp;982&amp;nbsp;392&amp;nbsp;040&amp;nbsp;522&amp;nbsp;594&amp;nbsp;123&amp;nbsp;776||≈ 1000&lt;sup&gt;14&lt;/sup&gt;||align="right"|(39.4% deviation)
|-
|2&lt;sup&gt;150&lt;/sup&gt;||=||align="left|1&amp;nbsp;427&amp;nbsp;247&amp;nbsp;692&amp;nbsp;705&amp;nbsp;959&amp;nbsp;881&amp;nbsp;058&amp;nbsp;285&amp;nbsp;969&amp;nbsp;449&amp;nbsp;495&amp;nbsp;136&amp;nbsp;382&amp;nbsp;746&amp;nbsp;624||≈ 1000&lt;sup&gt;15&lt;/sup&gt;||align="right"|(42.7% deviation)
|}
{{See also|Binary prefixes|IEEE 1541-2002}}

== Powers of two whose exponents are powers of two ==
Because data (specifically integers) and the addresses of data are stored using the same hardware, and the data is stored in one or more octets ({{math|2&lt;sup&gt;3&lt;/sup&gt;}}), [[double exponential function|double exponential]]s of two are common. For example,

{{OEIS|id=A001146}}

: 2&lt;sup&gt;1&lt;/sup&gt; = [[2 (number)|2]]
: 2&lt;sup&gt;2&lt;/sup&gt; = [[4 (number)|4]]
: 2&lt;sup&gt;4&lt;/sup&gt; = [[16 (number)|16]]
: 2&lt;sup&gt;8&lt;/sup&gt; = [[256 (number)|256]]
: 2&lt;sup&gt;16&lt;/sup&gt; = [[65536 (number)|65,536]]
: 2&lt;sup&gt;32&lt;/sup&gt; = 4,294,967,296
: 2&lt;sup&gt;64&lt;/sup&gt; = 18,446,744,073,709,551,616 (20 digits)
: 2&lt;sup&gt;128&lt;/sup&gt; = 340,282,366,920,938,463,463,374,607,431,768,211,456 (39 digits)
: 2&lt;sup&gt;256&lt;/sup&gt; = &lt;br&gt;115,792,089,237,316,195,423,570,985,008,687,907,853,269,984,665,640,564,039,457,584,007,913,129,&lt;br&gt;639,936 (78 digits)
: 2&lt;sup&gt;512&lt;/sup&gt; = &lt;br&gt;13,407,807,929,942,597,099,574,024,998,205,846,127,479,365,820,592,393,377,723,561,443,721,764,0&lt;br&gt;30,073,546,976,801,874,298,166,903,427,690,031,858,186,486,050,853,753,882,811,946,569,946,433,6&lt;br&gt;49,006,084,096 (155 digits)
: 2&lt;sup&gt;1,024&lt;/sup&gt; = 179,769,313,486,231,590,772,930,...,304,835,356,329,624,224,137,216 (309 digits)
: 2&lt;sup&gt;2,048&lt;/sup&gt; = 32,317,006,071,311,007,300,714,8...,193,555,853,611,059,596,230,656 (617 digits)
: 2&lt;sup&gt;4,096&lt;/sup&gt; = 1,044,388,881,413,152,506,691,75...,243,804,708,340,403,154,190,336 (1,234 digits)
: 2&lt;sup&gt;8,192&lt;/sup&gt; = 1,090,748,135,619,415,929,462,98...,997,186,505,665,475,715,792,896 (2,467 digits)
: 2&lt;sup&gt;16,384&lt;/sup&gt; = 1,189,731,495,357,231,765,085,75...,460,447,027,290,669,964,066,816 (4,933 digits)
: 2&lt;sup&gt;32,768&lt;/sup&gt; = 1,415,461,031,044,954,789,001,55...,541,122,668,104,633,712,377,856 (9,865 digits)
: 2&lt;sup&gt;65,536&lt;/sup&gt; = 2,003,529,930,406,846,464,979,07...,339,445,587,895,905,719,156,736 (19,729 digits)
: 2&lt;sup&gt;131,072&lt;/sup&gt; = 4,014,132,182,036,063,039,166,06...,850,665,812,318,570,934,173,696 (39,457 digits)
: 2&lt;sup&gt;262,144&lt;/sup&gt; = 16,113,257,174,857,604,736,195,7...,753,862,605,349,934,298,300,416 (78,914 digits)

Several of these numbers represent the number of values representable using common [[data type|computer data types]]. For example, a 32-bit word consisting of 4&amp;nbsp;bytes can represent {{math|2&lt;sup&gt;32&lt;/sup&gt;}} distinct values, which can either be regarded as mere bit-patterns, or are more commonly interpreted as the unsigned numbers from 0 to {{math|2&lt;sup&gt;32&lt;/sup&gt; − 1}}, or as the range of signed numbers between {{math|−2&lt;sup&gt;31&lt;/sup&gt;}} and {{math|2&lt;sup&gt;31&lt;/sup&gt; − 1}}. Also see [[tetration]] and [[hyperoperation#Lower hyperoperations|lower hyperoperations]]. For more about representing signed numbers see [[two's complement]].

In a connection with [[nimber]]s these numbers are often called ''[[Pierre de Fermat|Fermat]] 2-powers''.

The numbers &lt;math&gt;2^{2^n}&lt;/math&gt; form an [[irrationality sequence]]: for every sequence &lt;math&gt;x_i&lt;/math&gt; of [[positive integer]]s, the [[series (mathematics)|series]]
:&lt;math&gt;\sum_{i=0}^{\infty} \frac{1}{2^{2^i} x_i}  = \frac{1}{2x_0}+\frac{1}{4x_1}+\frac{1}{16x_2}+\cdots&lt;/math&gt;
converges to an [[irrational number]]. Despite the rapid growth of this sequence, it is the slowest-growing irrationality sequence known.&lt;ref&gt;{{citation | last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved problems in number theory | publisher=[[Springer-Verlag]] | edition=3rd | year=2004 | isbn=0-387-20860-7 | zbl=1058.11001 | contribution=E24 Irrationality sequences | page=346 | url=https://books.google.com/books?id=1AP2CEGxTkgC&amp;pg=PA346 | deadurl=no | archiveurl=https://web.archive.org/web/20160428053544/https://books.google.com/books?id=1AP2CEGxTkgC&amp;pg=PA346 | archivedate=2016-04-28 | df= }}.&lt;/ref&gt;

== Some selected powers of two ==
; 2&lt;sup&gt;8&lt;/sup&gt; = 256
:The number of values represented by the 8 [[bit]]s in a [[byte]], more specifically termed as an [[octet (computing)|octet]].  (The term [[byte]] is often defined as a [[bit#More than one bit|collection of bits]] rather than the strict definition of an 8-bit quantity, as demonstrated by the term [[kilobyte]].)
; 2&lt;sup&gt;10&lt;/sup&gt; = 1,024
: The binary approximation of the [[kilo-]], or 1,000 multiplier, which causes a change of prefix. For example: 1,024&amp;nbsp;[[byte]]s = 1&amp;nbsp;[[kilobyte]] (or [[kibibyte]]).
: This number has no special significance to computers, but is important to humans because we make use of powers of ten.
; 2&lt;sup&gt;12&lt;/sup&gt; = 4,096
: The hardware [[Page (computing)|page]] size of [[Intel x86]] processor.
; 2&lt;sup&gt;15&lt;/sup&gt; = 32,768
: The number of non-negative values for a ''signed'' 16-bit integer.
; 2&lt;sup&gt;16&lt;/sup&gt; = 65,536
: The number of distinct values representable in a single [[Word (data type)|word]] on a [[16-bit]] processor, such as the original [[x86]] processors.&lt;ref name="iword"&gt;Though they vary in word size, all x86 processors use the term "word" to mean 16&amp;nbsp;bits; thus, a 32-bit x86 processor refers to its native wordsize as a dword&lt;/ref&gt;
: The maximum range of a [[short integer]] variable in the [[C Sharp (programming language)|C#]], and [[Java (programming language)|Java]] programming languages. The maximum range of a '''Word''' or '''Smallint''' variable in the [[Pascal (programming language)|Pascal]] programming language.
: The number of [[binary relation]]s on a 4-element set.
; 2&lt;sup&gt;20&lt;/sup&gt; = 1,048,576
: The binary approximation of the [[mega-]], or 1,000,000 multiplier, which causes a change of prefix. For example: 1,048,576&amp;nbsp;[[byte]]s = 1&amp;nbsp;[[megabyte]] (or [[mibibyte]]).
: This number has no special significance to computers, but is important to humans because we make use of powers of ten.
; 2&lt;sup&gt;24&lt;/sup&gt; = 16,777,216
: The number of unique [[color]]s that can be displayed in [[True Color|truecolor]], which is used by common [[computer monitor]]s.
: This number is the result of using the three-channel [[RGB]] system, with 8&amp;nbsp;bits for each channel, or 24&amp;nbsp;bits in total.
: The size of the largest unsigned integer or address in computers with [[24-bit]] registers or data buses.
; 2&lt;sup&gt;29&lt;/sup&gt; = 536,870,912
: The largest power of two with distinct digits in base ten.&lt;ref&gt;Prime Curios!: 536870912 {{cite web |url=https://primes.utm.edu/curios/page.php/536870912.html |title=Archived copy |accessdate=2017-09-05 |deadurl=no |archiveurl=https://web.archive.org/web/20170905231159/https://primes.utm.edu/curios/page.php/536870912.html |archivedate=2017-09-05 |df= }}&lt;/ref&gt;
; 2&lt;sup&gt;30&lt;/sup&gt; = 1,073,741,824
: The binary approximation of the [[giga-]], or 1,000,000,000 multiplier, which causes a change of prefix. For example, 1,073,741,824 [[byte]]s = 1&amp;nbsp;[[gigabyte]] (or [[gibibyte]]).
: This number has no special significance to computers, but is important to humans because we make use of powers of ten.
; 2&lt;sup&gt;31&lt;/sup&gt; = 2,147,483,648
: The number of non-negative values for a ''signed'' 32-bit integer. Since [[Unix time]] is measured in seconds since January 1, 1970, it will run out at 2,147,483,647 seconds or 03:14:07 UTC on Tuesday, 19 January 2038 on 32-bit computers running Unix, a problem known as the [[year 2038 problem]].
; 2&lt;sup&gt;32&lt;/sup&gt; = 4,294,967,296
: The number of distinct values representable in a single [[Word (data type)|word]] on a [[32-bit]] processor.&lt;ref&gt;[http://www.vaughns-1-pagers.com/computer/powers-of-2.htm Powers of 2 by Vaughn Aubuchon] {{webarchive|url=https://web.archive.org/web/20150812072147/http://www.vaughns-1-pagers.com/computer/powers-of-2.htm |date=2015-08-12 }}&lt;/ref&gt; Or, the number of values representable in a [[Word (data type)#Size families|doubleword]] on a [[16-bit]] processor, such as the original [[x86]] processors.&lt;ref name="iword"/&gt;
: The range of an &lt;code&gt;[[integer (computer science)|int]]&lt;/code&gt; variable in the [[Java (programming language)|Java]] and [[C Sharp (programming language)|C#]] programming languages.
: The range of a &lt;code&gt;Cardinal&lt;/code&gt; or &lt;code&gt;Integer&lt;/code&gt; variable in the [[Pascal (programming language)|Pascal]] programming language.
: The minimum range of a [[long integer]] variable in the [[C (programming language)|C]] and [[C++]] programming languages.
: The total number of [[IP address]]es under [[IPv4]]. Although this is a seemingly large number, [[IPv4 address exhaustion]] is imminent.
: The number of [[binary operation]]s with domain equal to any 4-element set, such as [[Galois field|GF]](4).
; 2&lt;sup&gt;40&lt;/sup&gt; = 1,099,511,627,776
: The binary approximation of the [[tera-]], or 1,000,000,000,000 multiplier, which causes a change of prefix. For example, 1,099,511,627,776 [[byte]]s = 1 [[terabyte]] (or [[tebibyte]]).
: This number has no special significance to computers, but is important to humans because we make use of powers of ten.
; 2&lt;sup&gt;50&lt;/sup&gt; = 1,125,899,906,842,624
: The binary approximation of the [[peta-]], or 1,000,000,000,000,000 multiplier. 1,125,899,906,842,624 [[byte]]s = 1 [[petabyte]] (or [[pebibyte]]).
; 2&lt;sup&gt;53&lt;/sup&gt; = 9,007,199,254,740,992
: The number until which all integer values can exactly be represented in IEEE [[double precision floating-point format]].
; 2&lt;sup&gt;56&lt;/sup&gt; = 72,057,594,037,927,936
: The number of different possible keys in the obsolete 56 bit [[Data Encryption Standard|DES]] symmetric cipher.
; 2&lt;sup&gt;60&lt;/sup&gt; = 1,152,921,504,606,846,976
: The binary approximation of the [[exa-]], or 1,000,000,000,000,000,000 multiplier.  1,152,921,504,606,846,976 [[byte]]s = 1 [[exabyte]] (or [[exbibyte]]).
; 2&lt;sup&gt;63&lt;/sup&gt; = 9,223,372,036,854,775,808
: The number of non-negative values for a ''signed'' 64-bit integer.
; 2&lt;sup&gt;64&lt;/sup&gt; = 18,446,744,073,709,551,616
: The number of distinct values representable in a single [[Word (data type)|word]] on a [[64-bit]] processor. Or, the number of values representable in a [[Word (data type)#Size families|doubleword]] on a [[32-bit]] processor. Or, the number of values representable in a [[Word (data type)#Size families|quadword]] on a [[16-bit]] processor, such as the original [[x86]] processors.&lt;ref name="iword"/&gt;
: The range of a [[long integer|long]] variable in the [[Java (programming language)|Java]] and [[C Sharp (programming language)|C#]] programming languages.
: The range of a '''Int64''' or '''QWord''' variable in the [[Pascal (programming language)|Pascal]] programming language.
: The total number of [[IPv6 address]]es generally given to a single LAN or subnet.
: One more than the number of grains of rice on a chessboard, [[Wheat and chessboard problem|according to the old story]], where the first square contains one grain of rice and each succeeding square twice as many as the previous square. For this reason the number 2&lt;sup&gt;64&lt;/sup&gt; – 1 is known as the "chess number".
: 2&lt;sup&gt;64&lt;/sup&gt; – 1 is also the numbers of moves required to complete the legendary 64-disk version of the [[Tower of Hanoi#Origins|Tower of Hanoi]].
; 2&lt;sup&gt;68&lt;/sup&gt; = 295,147,905,179,352,825,856
: The first power of 2 to contain all decimal digits. {{OEIS|id=A137214}}
; 2&lt;sup&gt;70&lt;/sup&gt; = 1,180,591,620,717,411,303,424
: The binary approximation of the [[zetta-]], or 1,000,000,000,000,000,000,000 multiplier. 1,180,591,620,717,411,303,424 [[byte]]s = 1 [[zettabyte]] (or [[zebibyte]]).
; 2&lt;sup&gt;80&lt;/sup&gt; = 1,208,925,819,614,629,174,706,176
: The binary approximation of the [[yotta-]], or 1,000,000,000,000,000,000,000,000 multiplier. 1,208,925,819,614,629,174,706,176 [[byte]]s = 1 [[yottabyte]] (or [[yobibyte]]).
; 2&lt;sup&gt;86&lt;/sup&gt; = 77,371,252,455,336,267,181,195,264
: 2&lt;sup&gt;86&lt;/sup&gt; is conjectured to be the largest power of two not containing a zero in decimal.&lt;ref&gt;Weisstein, Eric W. "Zero." From MathWorld--A Wolfram Web Resource. {{cite web |url=http://mathworld.wolfram.com/Zero.html |title=Archived copy |accessdate=2013-05-29 |deadurl=no |archiveurl=https://web.archive.org/web/20130601190920/http://mathworld.wolfram.com/Zero.html |archivedate=2013-06-01 |df= }}&lt;/ref&gt;
; 2&lt;sup&gt;96&lt;/sup&gt; = 79,228,162,514,264,337,593,543,950,336
: The total number of [[IPv6 address]]es generally given to a [[local Internet registry]]. In [[CIDR]] notation, ISPs are given a {{IPaddr||32}}, which means that 128-32=96 bits are available for addresses (as opposed to network designation). Thus, 2&lt;sup&gt;96&lt;/sup&gt; addresses.
; 2&lt;sup&gt;128&lt;/sup&gt; = 340,282,366,920,938,463,463,374,607,431,768,211,456
: The total number of [[IPv6 address|IP addresses]] available under [[IPv6]]. Also the number of distinct [[Universally unique identifier|universally unique identifiers (UUIDs)]].
; 2&lt;sup&gt;168&lt;/sup&gt; = 374,144,419,156,711,147,060,143,317,175,368,453,031,918,731,001,856
: The largest known power of 2 not containing all decimal digits (the digit 2 is missing in this case). {{OEIS|id=A137214}}
; 2&lt;sup&gt;192&lt;/sup&gt; = 6,277,101,735,386,680,763,835,789,423,207,666,416,102,355,444,464,034,512,896
: The total number of different possible keys in the [[Advanced Encryption Standard|AES]] 192-bit [[key space (cryptography)|key space]] (symmetric cipher).
; 2&lt;sup&gt;256&lt;/sup&gt; = &lt;br&gt;115,792,089,237,316,195,423,570,985,008,687,907,853,269,984,665,640,564,039,457,584,007,913,129,&lt;br&gt;639,936
: The total number of different possible keys in the [[Advanced Encryption Standard|AES]] 256-bit [[key space (cryptography)|key space]] (symmetric cipher).
; 2&lt;sup&gt;333&lt;/sup&gt; = &lt;br&gt;17,498,005,798,264,095,394,980,017,816,940,970,922,825,355,447,145,699,491,406,164,851,279,623,9&lt;br&gt;93,595,007,385,788,105,416,184,430,592
: The smallest power of 2 greater than a [[googol]] (10&lt;sup&gt;100&lt;/sup&gt;).
; 2&lt;sup&gt;1024&lt;/sup&gt; = 179,769,313,486,231,590,772,931,...,304,835,356,329,624,224,137,216
: The maximum number that can fit in an IEEE [[double-precision floating-point format]], and hence the maximum number that can be represented by many programs, for example [[Microsoft Excel]].
; 2&lt;sup&gt;77,232,917&lt;/sup&gt; = 467,333,183,359,231,099,988,335,...,136,582,730,618,069,762,179,072
: One more than the [[largest known prime number]] {{As of|2018|lc=on}}. It has more than 23 million digits.&lt;ref&gt;https://www.mersenne.org/primes/?press=M77232917&lt;/ref&gt;

==Other properties==
The sum of all {{mvar|n}}-choose [[binomial coefficient]]s is equal to {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}. Consider the set of all {{mvar|n}}-digit binary integers. Its [[cardinality]] is {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}. It is also the sums of the cardinalities of certain subsets: the subset of integers with no 1s (consisting of a single number, written as {{mvar|n}} 0s), the subset with a single 1, the subset with two 1s, and so on up to the subset with {{mvar|n}} 1s (consisting of the number written as {{mvar|n}} 1s). Each of these is in turn equal to the binomial coefficient indexed by {{mvar|n}} and the number of 1s being considered (e.g., there are 10-choose-3 binary numbers with ten digits that include exactly three 1s).

The number of [[vertex (geometry)|vertices]] of an {{mvar|n}}-dimensional [[hypercube]] is {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}. Similarly, the number of {{math|(''n'' − 1)}}-faces of an {{mvar|n}}-dimensional [[cross-polytope]] is also {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}} and the formula for the number of {{mvar|x}}-faces an {{mvar|n}}-dimensional cross-polytope has is &lt;math&gt;\scriptstyle 2^x{n\choose x}&lt;/math&gt;.

The [[1/2 + 1/4 + 1/8 + 1/16 + · · ·|sum of the reciprocals of the powers of two]] is [[1 (number)|1]]. The [[1/4 + 1/16 + 1/64 + 1/256 + · · ·|sum of the reciprocals of the squared powers of two]] is 1/3.

The smallest natural power of two whose [[Decimal|decimal representation]] begins with 7 is&lt;ref name="o_potegach_dwojki"&gt;{{cite web
 |url         = http://www.deltami.edu.pl/temat/matematyka/teoria_liczb/2011/03/07/O_potegach_dwojki/
 |title       = O potęgach dwójki (About powers of two)
 |author      = Paweł Strzelecki
 |language    = pl
 |year        = 1994
 |publisher   = Delta
 |deadurl     = no
 |archiveurl  = https://web.archive.org/web/20160509191813/http://www.deltami.edu.pl/temat/matematyka/teoria_liczb/2011/03/07/O_potegach_dwojki/
 |archivedate = 2016-05-09
 |df          = 
}}&lt;/ref&gt;
: &lt;math&gt;2^{46} = 70\ 368\ 744\ 177\ 664.&lt;/math&gt;

==See also==
* [[Binary number]]
* [[Geometric progression]]
* [[Gould's sequence]]
* [[Binary logarithm#Integer|Integer binary logarithm]]
* [[Inchworm Song]]
* [[Octave (electronics)]]
* [[Sum-free sequence]]

==References==
{{reflist}}

== External links ==
* {{OEIS el |sequencenumber = A000079 |name = 2&lt;sup&gt;n&lt;/sup&gt; |formalname = Powers of 2: a(n) = 2^n}} (Powers of two)
* {{OEIS el |sequencenumber = A001146 |name = 2&lt;sup&gt;(2&lt;sup&gt;n&lt;/sup&gt;)&lt;/sup&gt; |formalname = a(n) = 2^(2^n) }} (Powers of two whose exponents are powers of two)

{{-}}
{{Series (mathematics)}}
{{Classes of natural numbers}}
{{Large numbers}}

{{DEFAULTSORT:Power Of Two}}
[[Category:Binary arithmetic]]
[[Category:Integer sequences]]
[[Category:Integers]]</text>
      <sha1>6ffic9i2r2u90dxo211y45w1gcr8wf2</sha1>
    </revision>
  </page>
  <page>
    <title>Process performance qualification protocol</title>
    <ns>0</ns>
    <id>44740826</id>
    <revision>
      <id>861752622</id>
      <parentid>826548063</parentid>
      <timestamp>2018-09-29T19:19:03Z</timestamp>
      <contributor>
        <ip>223.24.170.178</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2754">'''H'''

&lt;ref name=":0" /&gt;'''Process performance qualification protocol''' is a component of [[process validation]]: [[process qualification]]. This step is vital in maintaining ongoing production quality by recording and having available for review essential conditions, &lt;u&gt;controls, testing, and expected manufacturing outcome&lt;/u&gt; of a production process. The [[Food and Drug Administration]] recommends the following criteria be included in a PPQ protocol:&lt;ref name=":0"&gt;{{cite web|title=Guidance for Industry Process Validation: General Principles and Practices|url=http://www.fda.gov/downloads/Drugs/Guidances/UCM070336.pdf|publisher=Food and Drug Administration|accessdate=16 December 2014}}&lt;/ref&gt;

*Manufacturing conditions: Operating parameters, equipment limits, and component inputs
*What data should be recorded and analyzed
*What tests should be performed to ensure quality at each production step
*A sampling plan to outline sampling methods both during and between production batches
*Analysis methodology that allows for data scientific and risk oriented decision making based on statistical data. Variability limits should be defined and contingencies in the event of non-conforming data established
*Approval of PPQ protocol from relevant departments
Deviations from the standard operation procedures should be made within the framework of the protocol and at the approval of relevant [[quality control]] departments.&lt;ref&gt;{{cite web|title=Process Performance Qualification|url=http://www.atris-systems.com/222.0.html|publisher=Atris Information Systems|accessdate=16 December 2014}}&lt;/ref&gt; The protocol should cover all aspects of production including: equipment, personnel, raw materials, and operating environment. The FDA further recommends a documentation of the protocol be published internally. The report should include:
*A summation of relevant data and analysis from the protocol
*An explanation of unexpected data and any other results not mandated by the protocol and its effects on production quality
*Identify correlating effects and suggest changes to existing processes
*Conclude if the process performance is adequately qualified to meet performance standards. Should production standards not be met appropriate changes should be outlined

==References==
{{Reflist}}

==External links==
{{Commons category|HTML}}
* [http://c.ymcdn.com/sites/www.casss.org/resource/resmgr/CMC_No_Am_Jan_Spkr_Slds/2013_CMCJ_LambertWendy.pdf casss.org]
* [http://www.fda.gov/OHRMS/DOCKETS/98fr/04d-0001-bkg0001-10-sg3_n99-10_edition2.pdf Process Validation Guidance]

[[Category:Formal methods]]
[[Category:Enterprise modelling]]
[[Category:Business process management]]
[[Category:Validity (statistics)]]
[[Category:Pharmaceutical industry]]</text>
      <sha1>ruumg7vw5up8xma5o0nbadc4ropwdwb</sha1>
    </revision>
  </page>
  <page>
    <title>Proof theory</title>
    <ns>0</ns>
    <id>183478</id>
    <revision>
      <id>850197678</id>
      <parentid>821949059</parentid>
      <timestamp>2018-07-14T09:50:45Z</timestamp>
      <contributor>
        <ip>47.187.206.244</ip>
      </contributor>
      <comment>/* Ordinal analysis */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18553">'''Proof theory''' is a major branch&lt;ref name=wang&gt;According to Wang (1981), pp. 3–4, proof theory is one of four domains mathematical logic, together with [[model theory]], [[axiomatic set theory]], and [[recursion theory]]. [[Jon Barwise|Barwise]] (1978) consists of four corresponding parts, with part D being about "Proof Theory and Contstructive Mathematics".&lt;/ref&gt; of [[mathematical logic]] that represents [[Mathematical proof|proof]]s as formal [[mathematical object]]s, facilitating their analysis by mathematical techniques.  Proofs are typically presented as inductively-defined [[data structures]] such as plain lists, boxed lists, or [[Tree_(data_structure)|tree]]s, which are constructed according to the [[axiom]]s and [[rule of inference|rules of inference]] of the logical system.  As such, proof theory is [[syntax (logic)|syntactic]] in nature, in contrast to [[model theory]], which is [[Formal semantics (logic)|semantic]] in nature.

Some of the major areas of proof theory include [[structural proof theory]], [[ordinal analysis]], [[provability logic]], [[reverse mathematics]], [[proof mining]], [[automated theorem proving]], and [[proof complexity]]. Much research also focuses on applications in computer science, linguistics, and philosophy.

==History==
Although the formalisation of logic was much advanced by the work of such figures as [[Gottlob Frege]], [[Giuseppe Peano]], [[Bertrand Russell]], and [[Richard Dedekind]], the story of modern proof theory is often seen as being established by [[David Hilbert]], who initiated what is called [[Hilbert's program]] in the [[foundations of mathematics]]. The central idea of this program was that if we could give [[finitary]] proofs of consistency for all the sophisticated formal theories needed by mathematicians, then we could ground these theories by means of a metamathematical argument, which shows that all of their purely universal assertions (more technically their provable [[arithmetical hierarchy|&lt;math&gt;\Pi^0_1&lt;/math&gt; sentences]]) are finitarily true; once so grounded we do not care about the non-finitary meaning of their existential theorems, regarding these as pseudo-meaningful stipulations of the existence of ideal entities.

The failure of the program was induced by [[Kurt Gödel]]'s [[Gödel's incompleteness theorems|incompleteness theorems]], which showed that any [[ω-consistent theory]] that is sufficiently strong to express certain simple arithmetic truths, cannot prove its own consistency, which on Gödel's formulation is a &lt;math&gt;\Pi^0_1&lt;/math&gt;  sentence. However, modified versions of Hilbert's program emerged and research has been carried out on related topics. This has led, in particular, to:
*Refinement of Gödel's result, particularly [[J. Barkley Rosser]]'s refinement, weakening the above requirement of ω-consistency to simple consistency;
*Axiomatisation of the core of Gödel's result in terms of a modal language, [[provability logic]];
*Transfinite iteration of theories, due to [[Alan Turing]] and [[Solomon Feferman]];
*The discovery of [[self-verifying theories]], systems strong enough to talk about themselves, but too weak to carry out the [[diagonal lemma|diagonal argument]] that is the key to Gödel's unprovability argument.

In parallel to the rise and fall of Hilbert's program, the foundations of [[structural proof theory]] were being founded.  [[Jan Łukasiewicz]]  suggested in 1926 that one could improve on [[Hilbert system]]s as a basis for the axiomatic presentation of logic if one  allowed the drawing of conclusions from assumptions in the inference rules of the logic.  In response to this  [[Stanisław Jaśkowski]] (1929) and [[Gerhard Gentzen]] (1934) independently provided such systems, called calculi of [[natural deduction]], with Gentzen's approach introducing the idea of symmetry between the grounds for asserting propositions, expressed in [[introduction rule]]s, and the consequences of accepting propositions in the [[elimination rule]]s, an idea that has proved very important in proof theory.&lt;ref&gt;{{harvtxt|Prawitz|2006|p=98}}.&lt;/ref&gt;  Gentzen (1934) further introduced the idea of the [[sequent calculus]], a calculus advanced in a similar spirit that better expressed the duality of the logical connectives,&lt;ref&gt;Girard, Lafont, and Taylor (1988).&lt;/ref&gt; and went on to make fundamental advances in the formalisation of intuitionistic logic,  and provide the first [[combinatorial proof]] of the consistency of [[Peano arithmetic]].  Together, the presentation of natural deduction and the sequent calculus introduced the fundamental idea of [[analytic proof]] to proof theory.

==Structural proof theory==
{{Main article|Structural proof theory}}

Structural proof theory is the subdiscipline of proof theory that studies the specifics of [[proof calculi]]. The three most well-known styles of proof calculi are:
*The [[Hilbert system|Hilbert calculi]]
*The [[natural deduction calculus|natural deduction calculi]]
*The [[sequent calculus|sequent calculi]]

Each of these can give a complete and axiomatic formalization of [[propositional logic|propositional]] or [[predicate logic]] of either the [[classical logic|classical]] or [[intuitionistic logic|intuitionistic]] flavour, almost any [[modal logic]], and many [[substructural logic]]s, such as [[relevance logic]] or [[linear logic]].  Indeed, it is unusual to find a logic that resists being represented in one of these calculi.

Proof theorists are typically interested in proof calculi that support a notion of [[analytic proof]].  The notion of analytic proof was introduced by Gentzen for the sequent calculus; there the analytic proofs are those that are [[cut-elimination theorem|cut-free]]. Much of the interest in cut-free proofs comes from the subformula property: every formula in the end sequent of a cut-free proof is a subformula of one of the premises. This allows one to show consistency of the sequent calculus easily; if the empty sequent were derivable it would have to be a subformula of some premise, which it is not. Gentzen's midsequent theorem, the Craig interpolation theorem, and Herbrand's theorem also follow as corollaries of the cut-elimination theorem.

Gentzen's natural deduction calculus also supports a notion of analytic proof, as shown by [[Dag Prawitz]]. The definition is slightly more complex: we say the analytic proofs are the [[Natural deduction#Consistency.2C completeness.2C and normal forms|normal forms]], which are related to the notion of normal form in term rewriting.  More exotic proof calculi such as [[Jean-Yves Girard]]'s [[proof net]]s also support a notion of analytic proof.

Structural proof theory is connected to [[type theory]] by means of the [[Curry-Howard correspondence]], which observes a structural analogy between the process of normalisation in the natural deduction calculus and beta reduction in the [[typed lambda calculus]].  This provides the foundation for the [[intuitionistic type theory]] developed by [[Per Martin-Löf]], and is often extended to a three way correspondence, the third leg of which are the [[cartesian closed category|cartesian closed categories]].

Other research topics in structural theory include analytic tableau, which apply the central idea of analytic proof from structural proof theory to provide decision procedures and semi-decision procedures for a wide range of logics, and the proof theory of substructural logics.

==Ordinal analysis==
{{Main article|Ordinal analysis}}

Ordinal analysis is a powerful technique for providing combinatorial consistency proofs for subsystems of arithmetic, analysis, and set theory. [[Gödel's second incompleteness theorem]] is often interpreted as demonstrating that finitistic consistency proofs are impossible for theories of sufficient strength. Ordinal analysis allows one to measure precisely the infinitary content of the consistency of theories. For a consistent recursively axiomatized theory T, one can prove in finitistic arithmetic that the well-foundedness of a certain transfinite ordinal implies the consistency of T. Gödel's second incompleteness theorem implies that the well-foundedness of such an ordinal cannot be proved in the theory T.

Consequences of ordinal analysis include (1) consistency of subsystems of classical second order arithmetic and set theory relative to constructive theories, (2) combinatorial independence results, and (3) classifications of provably total recursive functions and provably well-founded ordinals.

Ordinal analysis was originated by Gentzen, who proved the consistency of Peano Arithmetic using [[transfinite induction]] up to ordinal ε&lt;sub&gt;0&lt;/sub&gt;. Ordinal analysis has been extended to many fragments of first and second order arithmetic and set theory. One major challenge has been the ordinal analysis of impredicative theories. The first breakthrough in this direction was Takeuti's proof of the consistency of Π{{su|p=1|b=1}}-CA&lt;sub&gt;0&lt;/sub&gt; using the method of ordinal diagrams.

==Provability logic==
{{Main article|Provability logic}}

''Provability logic'' is a [[modal logic]], in which the box operator is interpreted as 'it is provable that'. The point is to capture the notion of a proof predicate of a reasonably rich [[theory (mathematical logic)|formal theory]]. As basic axioms of the provability logic GL ([[Kurt Gödel|Gödel]]-[[Martin Hugo Löb|Löb]]), which captures provable in [[Peano Arithmetic]], one takes modal analogues of the Hilbert-Bernays derivability conditions and Löb's theorem (if it is provable that the provability of A implies A, then A is provable).

Some of the basic results concerning the incompleteness of Peano Arithmetic and related theories have analogues in provability logic. For example, it is a theorem in GL that if a contradiction is not provable then it is not provable that a contradiction is not provable (Gödel's second incompleteness theorem). There are also modal analogues of the fixed-point theorem. [[Robert Solovay]] proved that the modal logic GL is complete with respect to Peano Arithmetic. That is, the propositional theory of provability in Peano Arithmetic is completely represented by the modal logic GL. This straightforwardly implies that propositional reasoning about provability in Peano Arithmetic is complete and decidable.

Other research in provability logic has focused on first-order provability logic, [[Japaridze's polymodal logic|polymodal provability logic]] (with one modality representing provability in the object theory and another representing provability in the meta-theory), and [[Interpretability logic|interpretability logics]] intended to capture the interaction between provability and interpretability. Some very recent research has involved applications of graded provability algebras to the ordinal analysis of arithmetical theories.

==Reverse mathematics==
{{Main article|Reverse mathematics}}

'''Reverse mathematics''' is a program in [[mathematical logic]] that seeks to determine which axioms are required to prove theorems of mathematics.&lt;ref&gt;Simpson 2010&lt;/ref&gt; The field was founded by [[Harvey Friedman]]. Its defining method can be described as "going backwards from the [[theorem]]s to the [[axiom]]s", in contrast to the ordinary mathematical practice of deriving theorems from axioms. The reverse mathematics program was foreshadowed by results in set theory such as the classical theorem that the [[axiom of choice]] and [[Zorn's lemma]] are equivalent over [[ZF set theory]]. The goal of reverse mathematics, however, is to study possible axioms of ordinary theorems of mathematics rather than possible axioms for set theory.

In reverse mathematics, one starts with a framework language and a base theory—a core axiom system—that is too weak to prove most of the theorems one might be interested in, but still powerful enough to develop the definitions necessary to state these theorems.  For example, to study the theorem "Every bounded sequence of [[real number]]s has a [[supremum]]" it is necessary to use a base system that can speak of real numbers and sequences of real numbers.

For each theorem that can be stated in the base system but is not provable in the base system, the goal is to determine the particular axiom system (stronger than the base system) that is necessary to prove that theorem. To show that a system ''S'' is required to prove a theorem ''T'', two proofs are required. The first proof shows ''T'' is provable from ''S''; this is an ordinary mathematical proof along with a justification that it can be carried out in the system ''S''. The second proof, known as a '''reversal''', shows that ''T'' itself implies ''S''; this proof is carried out in the base system. The reversal establishes that no axiom system ''S&amp;prime;'' that extends the base system can be weaker than ''S'' while still proving&amp;nbsp;''T''.

One striking phenomenon in reverse mathematics is the robustness of the ''Big Five'' axiom systems. In order of increasing strength, these systems are named by the initialisms RCA&lt;sub&gt;0&lt;/sub&gt;, WKL&lt;sub&gt;0&lt;/sub&gt;, ACA&lt;sub&gt;0&lt;/sub&gt;, ATR&lt;sub&gt;0&lt;/sub&gt;, and Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub &gt;1&lt;/sub&gt;-CA&lt;sub&gt;0&lt;/sub&gt;. Nearly every theorem of ordinary mathematics that has been reverse mathematically analyzed has been proven equivalent to one of these five systems. Much recent research has focused on combinatorial principles that do not fit neatly into this framework, like RT&lt;sup&gt;2&lt;/sup&gt;&lt;sub &gt;2&lt;/sub&gt; (Ramsey's theorem for pairs).

Research in reverse mathematics often incorporates methods and techniques from [[recursion theory]] as well as proof theory.

==Functional interpretations==
Functional interpretations are interpretations of non-constructive theories in functional ones. Functional interpretations usually proceed in two stages. First, one "reduces" a classical theory C to an intuitionistic one I. That is, one provides a constructive mapping that translates the theorems of C to the theorems of I. Second, one reduces the intuitionistic theory I to a quantifier free theory of functionals F. These interpretations contribute to a form of Hilbert's program, since they prove the consistency of classical theories relative to constructive ones. Successful functional interpretations have yielded reductions of infinitary theories to finitary theories and impredicative theories to predicative ones.

Functional interpretations also provide a way to extract constructive information from proofs in the reduced theory. As a direct consequence of the interpretation one usually obtains the result that any recursive function whose totality can be proven either in I or in C is represented by a term of F. If one can provide an additional interpretation of F in I, which is sometimes possible, this characterization is in fact usually shown to be exact. It often turns out that the terms of F coincide with a natural class of functions, such as the primitive recursive or polynomial-time computable functions. Functional interpretations have also been used to provide ordinal analyses of theories and classify their provably recursive functions.

The study of functional interpretations began with Kurt Gödel's interpretation of intuitionistic arithmetic in a quantifier-free theory of functionals finite type. This interpretation is commonly known as the Dialectica interpretation. Together with the double-negation interpretation of classical logic in intuitionistic logic, it provides a reduction of classical arithmetic to intuitionistic arithmetic.

==Formal and informal proof==&lt;!-- This section is linked from [[Black–Scholes]] and [[Mathematical proof]]--&gt;
{{Main article |Formal proof}}

The ''informal'' proofs of everyday mathematical practice are unlike the ''formal'' proofs of proof theory. They are rather like high-level sketches that would allow an expert to reconstruct a formal proof at least in principle, given enough time and patience. For most mathematicians, writing a fully formal proof is too pedantic and long-winded to be in common use.

Formal proofs are constructed with the help of computers in [[interactive theorem proving]]. 
Significantly, these proofs can be checked automatically, also by computer. Checking formal proofs is usually simple, whereas ''finding'' proofs ([[automated theorem proving]]) is generally hard. An informal proof in the mathematics literature, by contrast, requires weeks of [[peer review]] to be checked, and may still contain errors.

==Proof-theoretic semantics==
{{Main article|proof-theoretic semantics|logical harmony}}

In [[linguistics]], [[type-logical grammar]], [[categorial grammar]] and [[Montague grammar]] apply formalisms based on structural proof theory to give a formal [[natural language semantics]].

==See also==
{{Portal|Logic}}
* [[Intermediate logic]]
* [[Model theory]]
* [[Proof (truth)]]
* [[Proof techniques]]

==Notes==
&lt;references/&gt;

==References==
* J. Avigad and E.H. Reck (2001). [http://www.andrew.cmu.edu/user/avigad/Papers/infinite.pdf "'Clarifying the nature of the infinite': the development of metamathematics and proof theory]".  Carnegie-Mellon Technical Report CMU-PHIL-120.
* [[Jon Barwise|J. Barwise]], ed. (1978). ''Handbook of Mathematical Logic''. North-Holland.
* S. Buss, ed. (1998) ''Handbook of Proof Theory.'' Elsevier.
* [[A. S. Troelstra]] and H. Schwichtenberg (1996). ''Basic Proof Theory'', Cambridge Tracts in Theoretical Computer Science, Cambridge University Press, {{isbn|0-521-77911-1}}.
* G. Gentzen (1935/1969).  "Investigations into logical deduction". In M. E. Szabo, ed. ''Collected Papers of Gerhard Gentzen''. North-Holland.  Translated by Szabo from "Untersuchungen über das logische Schliessen", ''Mathematisches Zeitschrift'' v. 39, pp.&amp;nbsp;176–210, 405&amp;nbsp;431.
* [[Dag Prawitz|D. Prawitz]] (1965). ''Natural deduction: A proof-theoretical study'', Dover Publications, {{isbn|978-0-486-44655-4}}
* S.G. Simpson (2010). ''Subsystems of Second-order Arithmetic'', second edition. Cambridge University Press, {{isbn|978-0521150149}}.
* [[Hao Wang (academic)|H. Wang]] (1981). ''Popular Lectures on Mathematical Logic'', [[Van Nostrand|Van Nostrand Reinhold Company]], {{isbn|0-442-23109-1}}.

== External links ==
*{{Springer |title=Proof theory |id=p/p075430}}
*J. von Plato (2008). [http://plato.stanford.edu/entries/proof-theory-development/ The Development of Proof Theory].  [[Stanford Encyclopedia of Philosophy]].

{{Mathematical logic}}

[[Category:Proof theory| ]]
[[Category:Mathematical logic| P]]
[[Category:Metalogic]]</text>
      <sha1>caqg8qrz49fwutxigefhaib74yeethe</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum energy teleportation</title>
    <ns>0</ns>
    <id>30408239</id>
    <revision>
      <id>797572994</id>
      <parentid>793582992</parentid>
      <timestamp>2017-08-27T23:27:10Z</timestamp>
      <contributor>
        <username>Auric</username>
        <id>31706</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/117.226.200.224|117.226.200.224]] ([[User talk:117.226.200.224|talk]]) to last revision by Davy2016. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7402">{{main|Teleportation}}

'''Quantum energy teleportation,'''  a hypothesis first put forward  by Japanese physicist [[Masahiro Hotta]] of [[Tohoku University]], proposes that it may be possible to teleport energy by exploiting quantum energy fluctuations of an entangled vacuum state of a quantum field.&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =A PROTOCOL FOR QUANTUM ENERGY DISTRIBUTION| work = Phys. Lett. A 372  5671 (2008)}}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =QUANTUM MEASUREMENT INFORMATION AS A KEY TO ENERGY EXTRACTION FROM LOCAL VACUUMS| work = Phys. Rev. D 78 045006 (2008)}}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =QUANTUM ENERGY TELEPORTATION IN SPIN CHAIN SYSTEMS| work = J. Phys. Soc. Jap. 78 034001 (2009) }}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =QUANTUM ENERGY TELEPORTATION WITH TRAPPED IONS| work = Phys. Rev. A 80 042323 (2009) }}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =QUANTUM ENERGY TELEPORTATION WITH AN ELECTROMAGNETIC FIELD: DISCRETE VS. CONTINUOUS VARIABLES| work = J. Phys. A: Math. Theor. 43 105305 (2010)}}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Masahiro | last = Hotta | title =CONTROLLED HAWKING PROCESS BY QUANTUM ENERGY TELEPORTATION| work = Phys. Rev. D 81 044025 (2010) }}&lt;/ref&gt;&lt;ref&gt;{{cite journal| first = Masahiro | last = Hotta | title =Energy Entanglement Relation for Quantum Energy Teleportation |arxiv=1002.0200 |journal=Phys. Lett. A |volume=374 |pages=3416 |year=2010|bibcode = 2010PhLA..374.3416H |doi = 10.1016/j.physleta.2010.06.058 }}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Yasusada| last = Nambu  | title =QUANTUM ENERGY TELEPORTATION WITH A LINEAR HARMONIC CHAIN| work = Phys. Rev. A 82 042329 (2010)|display-authors=etal}}&lt;/ref&gt;&lt;ref&gt;{{cite news |first= Axel|last=Tillemans| date = January 17, 2009 | title = Japaner wollen Energie teleportieren|work=Wissenschaft.de|url=http://www.wissenschaft.de/wissenschaft/hintergrund/298859.html }}&lt;/ref&gt;&lt;ref&gt;{{cite news |last=KFC| date = February 3, 2010 | title = Physicist Discovers How to Teleport Energy|work = Technology Review published by MIT | url = http://www.technologyreview.com/blog/arxiv/24759/ }}&lt;/ref&gt;&lt;ref&gt;{{cite news |first=Jennifer|last=Ouellette|date=February 4, 2010 |work=Discovery News| title = Teleporting Energy| url = http://news.discovery.com/space/teleporting-energy.html }}&lt;/ref&gt;&lt;ref&gt;{{cite news |first=Mathew |last=Klie-Cribb|date=February 17, 2010|work=Canadian Geographic Compass Blog| title = New Teleportation Technique Helps Physicists Understand the Universe| url = http://www.canadiangeographic.ca/blog/posting.asp?ID=220}}&lt;/ref&gt;  The hypothesis proposes that energy may be injected into a zero-point fluctuation of the field at one place, and extracted from a fluctuation at another place. Even for interstellar distance energy transfer, the amount of teleported energy is nonzero,&lt;ref&gt;{{cite news | first = Stuart | last = Fox | title = Physicists Prove Teleportation of Energy Is Possible | date = February 4, 2010 | url = http://www.popsci.com/science/article/2010-02/physicists-prove-teleportation-energy-theoretically-possible | work = Popular Science | accessdate = 2011-01-13}}&lt;/ref&gt; but negligibly small. In contrast, the teleportation protocol will be effective in small quantum worlds of nanoscale devices like [[quantum computers]].

The idea is a continuation of work by computer scientist Charles H. Bennett on [[quantum teleportation]] [[C.H. Bennett]], ''et al.'' in 1993&lt;ref&gt;{{cite news | first = Charles H.| last = Bennett | work = Phys. Rev. Lett. 70 1895 (1993)|display-authors=etal}}&lt;/ref&gt; and experimentally confirmed by various experiments in the following years.&lt;ref&gt;{{cite news | first = Dirk| last = Bouwmeester | work = Nature 390 575 (1997)|display-authors=etal}}&lt;/ref&gt;&lt;ref&gt;{{cite news | first = Akira| last = Furusawa | work = Science 282 706 (1998)|display-authors=etal}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Jin |first1=Xian-Min |last2=Ren |first2=Ji-Gang |last3=Yang |first3=Bin |last4=Yi |first4=Zhen-Huan |last5=Zhou |first5=Fei |last6=Xu |first6=Xiao-Fan |last7=Wang |first7=Shao-Kai |last8=Yang |first8=Dong |last9=Hu |first9=Yuan-Feng |displayauthors=8|title=Experimental free-space quantum teleportation |journal=Nature Photonics |volume=4 |issue=6 |pages=376–381 |year=2010 |doi=10.1038/nphoton.2010.87|bibcode = 2010NaPho...4..376J }}&lt;/ref&gt; Protocols of the quantum teleportation transfer quantum information, but cannot teleport energy itself.

==Description==
{{confusing|date=November 2013}}
Quantum energy teleportation is a quantum protocol which transfers locally available energy, in an operational sense, from one subsystem of a many-body system to another in an entangled [[ground state]] by using local operations and classical communication ([[LOCC]]). The locally available energy indicates the energy which can be extracted from a subsystem by local operations and harnessed for any purpose. The transfer speed can be much faster than the velocity of energy diffusion of the system. It does not allow energy transportation at [[superluminal]] (faster than light) speed, nor does it increase total energy itself contained in a distant place. Though [[zero-point energy]] of the ground state exists everywhere in the system and contributes to the amount of the total energy, it is not available by use of ordinary local operations. However, if information about a local zero-point fluctuation, which carries a portion of the zero-point energy, is obtained by a measurement of a distant subsystem via ground-state [[Quantum entanglement|entanglement]], the energy becomes available, and can be extracted by a local operation dependent on the information. The extraction of the energy is accompanied by generation of negative energy density, which is allowed in quantum physics of many-body systems including quantum fields, and retains the local energy conservation law. The remote measurement, which provides the information for energy extraction, injects energy into the measured subsystem. A portion of the injected energy, which amount is larger than that of the energy extracted from the zero-point fluctuation, becomes unavailable because of entanglement breaking by the measurement, and cannot be retrieved by local operations in the measurement region. Thus, during the protocol, the amount of locally available energy decreases in the measurement region, and it increases in the energy extraction region. The injected energy is the input of this teleportation protocol, and the extracted energy is the output.
 
The details can be found in a review article written by Hotta.&lt;ref&gt;{{cite news |last=Masahiro |first=Hotta| title = Quantum Energy Teleportation: An Introductory Review |url = http://www.tuhep.phys.tohoku.ac.jp/~hotta/extended-version-qet-review.pdf }}&lt;/ref&gt;

==Experiments==
Experimental verification of the teleportation has not been achieved yet. A realistic experimental proposal is provided using a semiconductor exhibiting the [[quantum Hall effect]].&lt;ref&gt;{{cite news |author1=Go Yusa|author2=Wataru Izumida| author3 = Masahiro Hotta | title =Quantum energy teleportation in a quantum Hall system| work = Phys. Rev. A 84, 032336 (2011) }}&lt;/ref&gt;

==References==
&lt;references/&gt;

{{DEFAULTSORT:Quantum Energy Teleportation}}
[[Category:Theoretical physics]]
[[Category:Quantum information science]]</text>
      <sha1>8ikp1ihvhfe08nx5scwu55tu3w826pi</sha1>
    </revision>
  </page>
  <page>
    <title>Reeb foliation</title>
    <ns>0</ns>
    <id>2604269</id>
    <revision>
      <id>865742664</id>
      <parentid>703712695</parentid>
      <timestamp>2018-10-25T21:07:05Z</timestamp>
      <contributor>
        <ip>199.91.249.134</ip>
      </contributor>
      <comment>Corrected death year of Georges Reeb to be consistent with the death year on the page dedicated to Georges Reeb.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1559">In [[mathematics]], the '''Reeb foliation''' is a particular [[foliation]] of the [[3-sphere]], introduced by the French mathematician [[Georges Reeb]] (1920–1993).

It is based on dividing the sphere into two [[solid tori]], along a 2-[[torus]]: see [[Clifford torus]]. Each of the solid tori is then foliated internally, in [[codimension]] 1, and the dividing torus surface forms one more leaf.

By [[Novikov's compact leaf theorem]], every smooth foliation of the 3-sphere includes a compact torus leaf, bounding a solid torus foliated in the same way.

== Illustrations ==
{|
| [[File:Reebfoliation-ring-2d-2.svg|300px|thumb|2-dimensional section of Reeb foliation]]
| [[File:Reeb foliation half-torus POV-Ray.png|350px|thumb|3-dimensional model of Reeb foliation]]
|}

==References==
* {{cite book | author=G. Reeb | title=Sur certaines propriétés topologiques des variétés feuillétées | series=Actualités Sci. Indust. | volume=1183 | publisher=Hermann | location=Paris | year=1952 }} 
* {{cite book | title=Foliations | author=Alberto Candel |author2=Lawrence Conlon  | publisher=[[American Mathematical Society]] | year=2000 | isbn=0-8218-0809-5 | page=93 }}
* {{cite book | title=Introduction to Foliations and Lie Groupoids | author=Ieke Moerdijk |author2=J. Mrčun  | series=Cambridge studies in advanced mathematics | volume=91 | publisher=[[Cambridge University Press]] | year=2003 | isbn=0-521-83197-0 | page=8 }}

==External links== 
* {{MathWorld|urlname=ReebFoliation|title=Reeb Foliation}}

{{topology-stub}}

[[Category:Foliations]]</text>
      <sha1>hxfn0rpr2mrlk2wppeb474hn26j9k1b</sha1>
    </revision>
  </page>
  <page>
    <title>Rosalind Tanner</title>
    <ns>0</ns>
    <id>37409519</id>
    <revision>
      <id>828495706</id>
      <parentid>788262924</parentid>
      <timestamp>2018-03-02T22:22:05Z</timestamp>
      <contributor>
        <username>I dream of horses</username>
        <id>9676078</id>
      </contributor>
      <minor/>
      <comment>Cleaning up a [[WP:RANPP|randomly generated list]], [[WP:AWB/T|typo(s) fixed]]: Bachelor's degree → bachelor's degree using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3516">{{Infobox person
|image         = Young Skewes Schieldrop Tricomi Cartwright Zurich1932.tif
|caption       = Mrs. R. C. H. Young (left, upper) at the [[International Congress of Mathematicians|ICM]] 1932
|name          = Rosalind Tanner
|birth_name    = Rosalind Cecilia Hildegard Young
|birth_date    = {{birth date|1900|2|5|df=y}}
|birth_place   = [[Göttingen]], [[Germany]]
|death_date    = {{death date and age|1992|11|24|1900|2|5|df=y}}
|death_place   = 
|occupation = Mathematician, historian
|spouse = William Tanner
|nationality   = 
|other_names   =
|known_for     = Mathematics, history of mathematics
}}
'''Rosalind Cecilia Hildegard Tanner''' (née Young) (5 February 1900 – 24 November 1992) was a mathematician and historian of mathematics.&lt;ref&gt;{{cite web|title=Rosalind Cecilia Hildegard Tanner|first=Neumann|url=http://www.oxforddnb.com/index/54/101054645/|work=ODNB|accessdate=22 October 2012}}&lt;/ref&gt; She was the eldest daughter of the mathematicians [[Grace Young|Grace]] and [[William Henry Young|William Young]]. She was born and lived in [[Göttingen]] in Germany (where her parents worked at the university) until 1908.&lt;ref&gt;{{cite web|title=Biography of Grace Young|url=http://www-history.mcs.st-and.ac.uk/Biographies/Chisholm_Young.html|work=The MacTutor History of Mathematics archive|accessdate=22 October 2012|author=J J O'Connor and E F Robertson}}&lt;/ref&gt; During her life she used the name Cecily.&lt;ref name=ArchivesHub&gt;{{cite web|title=Paper of Rosalind Cecilia Hildegard Tanner|url=http://archiveshub.ac.uk/data/gb141unistafftanner|work=Archives Hub|accessdate=22 October 2012}}&lt;/ref&gt;

Rosalind joined the [[University of Lausanne]] in 1917. She also helped her father's research between 1919 and 1921 at the [[Aberystwyth University|University College Wales]] in Aberystwyth, and worked with [[Edward Collingwood]], also of Aberystwyth, on a translation of Georges Valiron's course on Integral Functions.&lt;ref name=ArchivesHub /&gt; She received a L-És-sc (a bachelor's degree) from Lausanne in 1925.&lt;ref&gt;{{cite web |title=Rosalind Young|url=http://www-history.mcs.st-and.ac.uk/Davis/Names/Young_Rosalind.html|work=The MacTutor History of Mathematics archive}}&lt;/ref&gt;

She then studied at [[Girton College, Cambridge]], gaining a PhD in 1929 under the supervision of Professor [[E. W. Hobson]]&lt;ref&gt;{{cite web|title=RCH Tanner|url=http://genealogy.math.ndsu.nodak.edu/id.php?id=18551|work=Mathematics Genealogy Project|accessdate=22 October 2012}}&lt;/ref&gt; for research on [[Riemann–Stieltjes integral|Stieltjes integration]]. She accepted a teaching post at [[Imperial College, London]] where she worked until 1967.&lt;ref name=ArchivesHub /&gt;

After 1936, most of her research was in the [[history of mathematics]], and she had a particular interest in [[Thomas Harriot]], an Elizabethan mathematician. She set up the Harriot Seminars in Oxford and Durham. Rosalind married William Tanner in 1953; however, he died a few months after their marriage. Her interest in sixteenth and seventeenth century mathematics continued after her retirement, and she died on 24 November 1992.&lt;ref name=ArchivesHub /&gt;

==References==
{{commons category|Rosalind Cecilia Hildegard Tanner (mathematician)}}
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Tanner, Rosalind}}
[[Category:1900 births]]
[[Category:1992 deaths]]
[[Category:Women mathematicians]]
[[Category:Historians of mathematics]]
[[Category:German mathematicians]]
[[Category:20th-century historians]]
[[Category:20th-century mathematicians]]</text>
      <sha1>qj27cm493gk8e6hxeu0td5pnjeqkwuc</sha1>
    </revision>
  </page>
  <page>
    <title>Semicircle</title>
    <ns>0</ns>
    <id>617831</id>
    <revision>
      <id>807119179</id>
      <parentid>807115247</parentid>
      <timestamp>2017-10-26T01:05:23Z</timestamp>
      <contributor>
        <username>Bamyers99</username>
        <id>12311825</id>
      </contributor>
      <comment>Undid revision 807115247 by [[Special:Contributions/2605:E000:2F5F:CE00:494C:B6D9:2926:AADB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3376">[[Image:semicircle.svg|frame|A '''semicircle''' of radius ''r''.]]

In [[mathematics]] (and more specifically [[geometry]]), a '''semicircle''' is a one-dimensional [[Locus (mathematics)|locus]] of points that forms half of a [[circle]]. The full [[Arc (geometry)|arc]] of a semicircle always measures 180° (equivalently, {{pi}} [[radians]], or a [[turn (geometry)#Subdivision of turns|half-turn]]). It has only one line of symmetry ([[reflection symmetry]]). In non-technical usage, the term "semicircle" is sometimes used to refer to a half-[[Disc (geometry)|disk]], which is a two-dimensional [[geometric shape]] that also includes the diameter segment from one end of the arc to the other as well as all the interior points.

By [[Thales' theorem]], any [[triangle]] [[Inscribed figure|inscribed]] in a semicircle with a [[vertex (geometry)|vertex]] at each of the endpoints of the semicircle and the third vertex elsewhere on the semicircle is a [[right triangle]], with [[right angle]] at the third vertex. 

All lines intersecting the semicircle [[perpendicular]]ly are [[concurrent lines|concurrent]] at the center of the circle containing the given semicircle.

==Uses==
[[Image:SemicircleMeans.svg|right|thumb|300px|A '''semicircle''' with arithmetic and geometric means of ''a'' and ''b'']]
A semicircle can be used to [[Compass and straightedge constructions|construct]] the [[arithmetic mean|arithmetic]] and [[geometric mean|geometric]] means of two lengths using straight-edge and compass. If we make a semicircle with a diameter of ''a''+''b'', then the length of its radius is the arithmetic mean of ''a'' and ''b'' (since the radius is half of the diameter). The geometric mean can be found by dividing the diameter into two segments of lengths ''a'' and ''b'', and then connecting their common endpoint to the semicircle with a segment perpendicular to the diameter. The length of the resulting segment is the geometric mean,&lt;ref&gt;[http://aleph0.clarku.edu/~djoyce/java/elements/bookVI/propVI13.html Euclid's Elements, Book VI, Proposition 13]&lt;/ref&gt; which can be proved using the [[Pythagorean theorem]]. This can
be used to accomplish [[Quadrature (mathematics)|quadrature]] of a rectangle (since a square whose sides are equal to the geometric mean of the sides of a rectangle has the same [[area]] as the rectangle), and thus of any figure for which we can construct a rectangle of equal area, such as any [[polygon]] (but not a circle).

==Equation==

The equation of a semicircle with midpoint &lt;math&gt;(x_0,y_0)&lt;/math&gt; on the diameter between its endpoints and which is entirely concave from below is

:&lt;math&gt;y=y_0+\sqrt{r^2-(x-x_0)^2}.&lt;/math&gt;

If it is entirely concave from above, the equation is

:&lt;math&gt;y=y_0-\sqrt{r^2-(x-x_0)^2}.&lt;/math&gt;

==Arbelos==
[[Image:Arbelos.svg|right|thumb|300px|An '''arbelos''' (grey region)]]
An [[arbelos]] is a region in the [[plane (geometry)|plane]]  bounded by three semicircles connected at the corners, all on the same side of a [[straight line]] (the ''baseline'') that contains their [[diameter]]s.

==See also==

*[[Amphitheater]]
*[[Archimedes' twin circles]]
*[[Archimedes' quadruplets]]
*[[Salinon]]
*[[Wigner semicircle distribution]]

==References==
{{reflist}}

==External links==
*[http://mathworld.wolfram.com/Semicircle.html Semicircle - Mathworld]

[[Category:Elementary geometry]]
[[es:Semicírculo]]</text>
      <sha1>ifdq98hvb3xso2c5igvlgb8qt6bmfo9</sha1>
    </revision>
  </page>
  <page>
    <title>Stanko Bilinski</title>
    <ns>0</ns>
    <id>44812552</id>
    <revision>
      <id>829880983</id>
      <parentid>816661571</parentid>
      <timestamp>2018-03-11T10:51:21Z</timestamp>
      <contributor>
        <username>GregorB</username>
        <id>179697</id>
      </contributor>
      <comment>added [[Category:Geometers]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2610">'''Stanko Bilinski''' (22 April 1909 in [[Našice]] – 6 April 1998 in [[Zagreb]]) was a Croatian mathematician and academician. He was a professor at the [[University of Zagreb]] and a [[fellow]] of the [[Croatian Academy of Sciences and Arts]]&lt;ref&gt;{{citation|url=http://info.hazu.hr/en/member_of_academy/personal_pages/sbilinski_en|title=Stanko Bilinski, F.C.A., Mathematician|publisher= [[Croatian Academy of Sciences and Arts]]|accessdate=2016-05-26}}&lt;/ref&gt;

In 1960 he discovered a [[rhombic dodecahedron]] of the second kind,  the [[Bilinski dodecahedron]]. Like the standard rhombic dodecahedron, this convex polyhedron has 12 congruent [[rhombus]] sides, but they are differently shaped and arranged. Bilinski's discovery corrected a 75-year-old omission in [[Evgraf Fedorov]]'s classification of convex polyhedra with congruent rhombic faces.&lt;ref&gt;{{citation
 |last        = Grünbaum
 |first       = Branko
 |authorlink  = Branko Grünbaum
 |doi         = 10.1007/s00283-010-9138-7
 |issue       = 4
 |journal     = [[The Mathematical Intelligencer]]
 |mr          = 2747698
 |pages       = 5–15
 |title       = The Bilinski dodecahedron and assorted parallelohedra, zonohedra, monohedra, isozonohedra, and otherhedra
 |url         = https://dlib.lib.washington.edu/researchworks/bitstream/handle/1773/15593/Bilinski_dodecahedron.pdf
 |volume      = 32
 |year        = 2010
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20150402132516/https://dlib.lib.washington.edu/researchworks/bitstream/handle/1773/15593/Bilinski_dodecahedron.pdf
 |archivedate = 2015-04-02
 |df          = 
}}.&lt;/ref&gt;

==References==
{{reflist}}

==Further reading==
* {{cite journal | url=http://web.math.hr/glasnik/33.2/33214.pdf | title=In memoriam: Stanko Bilinski (22.4.1909.–6.4.1998.) | journal=Glasnik Matematički | volume=33 | issue=2 |date=December 1998 | pages=323–333 | publisher=Croatian Mathematical Society | language=Croatian | format=PDF | accessdate=21 April 2011}}
* {{cite magazine | url= http://mis.element.hr/fajli/902/50-12.pdf | title=Stanko Bilinski (1909. – 2009.) | magazine = miš – matematika i škola | accessdate=2015-05-31 | language=Croatian | format=PDF}}

{{authority control}}

{{DEFAULTSORT:Bilinski, Stanko}}
[[Category:1909 births]]
[[Category:1998 deaths]]
[[Category:Croatian mathematicians]]
[[Category:University of Zagreb faculty]]
[[Category:Members of the Croatian Academy of Sciences and Arts]]
[[Category:20th-century Croatian mathematicians]]
[[Category:People from Našice]]
[[Category:Geometers]]


{{Croatia-bio-stub}}
{{Europe-mathematician-stub}}</text>
      <sha1>4uusoetgk62gaunv2llc2fpshg2si8m</sha1>
    </revision>
  </page>
  <page>
    <title>Stephen Yablo</title>
    <ns>0</ns>
    <id>17689596</id>
    <revision>
      <id>859154118</id>
      <parentid>858754910</parentid>
      <timestamp>2018-09-12T02:50:30Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>add spouse</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3026">{{Infobox philosopher
| region           = [[Western philosophy]]
| era              = [[Contemporary philosophy]]
| image            = SteveYablo.jpg
| caption          = 
| name             = Stephen Yablo
| education        = [[University of Toronto]] &lt;small&gt;([[Bachelor of Science|B.Sc.]])&lt;/small&gt;&lt;br&gt;[[University of California, Berkeley]] &lt;small&gt;([[Ph.D.]])
| school_tradition = [[Analytic philosophy|Analytic]]
| notable_ideas    = [[Yablo's paradox]]
| spouse           = [[Sally Haslanger]]
| main_interests   = [[Philosophical logic]]
| institutions     =
}}

'''Stephen Yablo''' is an American philosopher. He is David W. Skinner Professor of Philosophy at the [[Massachusetts Institute of Technology]] (MIT), and taught previously at the [[University of Michigan, Ann Arbor]].&lt;ref&gt;http://www.mit.edu/~yablo/cv.pdf&lt;/ref&gt; He specializes in the [[philosophy of logic]], [[philosophy of mind]], [[metaphysics]], and [[philosophy of language]].

He is married to fellow MIT philosopher [[Sally Haslanger]].

==Education and career==
His Ph.D. is from [[University of California, Berkeley]], where he worked with [[Donald Davidson (philosopher)|Donald Davidson]] and [[George Myro]].  In 2012, he was elected a Fellow of the [[American Academy of Arts and Sciences]].

He was born in Toronto, ON to a Polish father and Romanian-Canadian mother.

==Work==
In 1993, he published a short paper showing that a [[Yablo's paradox|liar-like paradox]] can be generated without [[self-reference]]. He has published a number of influential papers in philosophy of mind, philosophy of language, and metaphysics, and gave the [[John Locke Lectures]] at Oxford in 2012, which formed the basis for his book ''Aboutness'', which one reviewer described as "an important and far-reaching book that philosophers will be discussing for a long time."&lt;ref&gt;https://ndpr.nd.edu/news/50261-aboutness/&lt;/ref&gt;

==Books==
*''Thoughts (Philosophical Papers, volume 1)'' (Oxford University Press, 2009)
*''Things (Philosophical Papers, volume 2)'' (Oxford University Press, 2010)
*''Aboutness'' (Princeton University Press, 2014).

==References==
{{Reflist}}

==External links==
*[http://www.mit.edu/~yablo/pwsr.pdf "Paradox Without Self-Reference"] - ''Analysis'', vol. 53 (1993), pp.&amp;nbsp;251–52
*[http://www.mit.edu/~yablo/mc.pdf "Mental Causation"] - ''The Philosophical Review'', vol. 101, issue 2 (1992), pp.&amp;nbsp;245–280
*[http://www.mit.edu/%7Eyablo/gf.pdf "Go Figure: A Path Through Fictionalism"]
*[https://www.3ammagazine.com/3am//about-aboutness/ Interview at [[3:AM Magazine]]]

{{Philosophy of language}}
{{Authority control}}

{{DEFAULTSORT:Yablo, Stephen}}
[[Category:Analytic philosophers]]
[[Category:American logicians]]
[[Category:Philosophers of mathematics]]
[[Category:Philosophers of mind]]
[[Category:Philosophers of language]]
[[Category:Living people]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Guggenheim Fellows]]
[[Category:University of Michigan faculty]]


{{US-philosopher-stub}}</text>
      <sha1>hm8fklvw9bn4m3zu1y6oyvo88zvjnej</sha1>
    </revision>
  </page>
  <page>
    <title>Survival function</title>
    <ns>0</ns>
    <id>30876757</id>
    <revision>
      <id>851547338</id>
      <parentid>851546996</parentid>
      <timestamp>2018-07-23T01:56:00Z</timestamp>
      <contributor>
        <username>Donner60</username>
        <id>12744454</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/207.119.63.202|207.119.63.202]] ([[User talk:207.119.63.202|talk]]): unexplained content removal ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13796">The '''survival function''' is a [[function (mathematics)|function]] that gives the [[probability]] that a patient, device, or other object of interest will [[survival analysis|survive]] beyond any given specified time.&lt;ref name="KleinbaumKlein2012"&gt;{{Citation
|last1=Kleinbaum
|first1=David G.
|last2=Klein
|first2= Mitchel
|title= Survival analysis: A Self-learning text
|edition=Third
|year=2012
|publisher= Springer
|isbn= 978-1441966452
}}
&lt;/ref&gt;

The survival function is also known as the '''survivor function'''&lt;ref name="TablemanKim2003"&gt;{{Citation
|last1= Tableman
|first1= Mara
|last2= Kim
|first2= Jong Sung
|title= Survival Analysis Using S
|edition=First
|year=2003
|publisher= Chapman and Hall/CRC
|isbn= 978-1584884088
}}
&lt;/ref&gt; or '''reliability function'''.&lt;ref name="Ebeling2010"&gt;{{Citation
|last1= Ebeling
|first1= Charles
|title= An Introduction to Reliability and Maintainability Engineering
|edition=Second
|year=2010
|publisher= Waveland Press
|isbn= 978-1577666257
}}
&lt;/ref&gt;

The term ''reliability function'' is common in [[engineering]] while the term ''survival function'' is used in a broader range of applications, including human mortality. Another name for the survival function is the '''complementary cumulative distribution function'''.

==Definition==

Let ''T'' be a continuous random variable with [[cumulative distribution function]] ''F''(''t'') on the interval &lt;nowiki&gt;[0,∞)&lt;/nowiki&gt;. Its ''survival function'' or ''reliability function'' is:

:&lt;math&gt;S(t) = P(\{T &gt; t\}) = \int_t^{\infty} f(u)\,du = 1-F(t).&lt;/math&gt;

== Examples of survival functions ==

The graphs below show examples of hypothetical survival functions. The x-axis is time. The y-axis is the proportion of subjects surviving. The graphs show the probability that a subject will survive beyond time t.

[[File:Four survival functions.svg|600px|Four survival functions]]

For example, for survival function 1, the probability of surviving longer than t = 2 months is 0.37. That is, 37% of subjects survive more than 2 months.

[[File:Survival function 1.svg|400px|Survival function 1]]

For survival function 2, the probability of surviving longer than t = 2 months is 0.97. That is, 97% of subjects survive more than 2 months.

[[File:Survival function 2.svg|400px|Survival function 2]]

Median survival may be determined from the survival function. For example, for survival function 2, 50% of the subjects survive 3.72 months. Median survival is thus 3.72 months.

[[File:Survival function 2 median survival.svg|400px|Survival function median survival]]

In some cases, median survival cannot be determined from the graph. For example, for survival function 4, more than 50% of the subjects survive longer than the observation period of 10 months.

[[File:Median survival greater than 10 months.svg|400px|Median survival greater than 10 months]]

The survival function is one of several ways to describe and display survival data. Another useful way to display data is a graph showing the distribution of survival times of subjects. Olkin,&lt;ref name="OlkinGleserDerman1994"&gt;{{Citation
|last1=Olkin
|first1=Ingram
|last2=Gleser
|first2= Leon
|last3=Derman
|first3= Cyrus
|title= Probability Models and Applications
|edition=Second	
|year=1994
|publisher= Macmillan
|isbn= 0-02-389220-X
}}
&lt;/ref&gt; page 426, gives the following example of survival data. The number of hours between successive failures of an air-conditioning system were recorded. The time between successive failures are 1, 3, 5, 7, 11, 11, 11, 12, 14, 14, 14, 16, 16, 20, 21, 23, 42, 47, 52, 62, 71, 71, 87, 90, 95, 120, 120, 225, 246, and 261 hours. The mean time between failures is 59.6. This mean value will be used shortly to fit a theoretical curve to the data. The figure below shows the distribution of the time between failures. The blue tick marks beneath the graph are the actual hours between successive failures.

[[File:Distribution of AC failure times.svg|400px|Distribution of AC failure times]]

The distribution of failure times is over-laid with a curve representing an exponential distribution. For this example, the [[exponential distribution]] approximates the distribution of failure times. The exponential curve is a theoretical distribution fitted to the actual failure times. This particular exponential curve is specified by the parameter lambda, λ= 1/(mean time between failures) = 1/59.6 = 0.0168. The distribution of failure times is called the probability density function (pdf), if time can take any positive value. In equations, the pdf is specified as f(t). If time can only take discrete values (such as 1 day, 2 days, and so on), the distribution of failure times is called the probability mass function (pmf). Most survival analysis methods assume that time can take any positive value, and f(t) is the pdf. If the time between observed air conditioner failures is approximated using the exponential function, then the exponential curve gives the probability density function, f(t), for air conditioner failure times.

Another useful way to display the survival data is a graph showing the cumulative failures up to each time point. These data may be displayed as either the cumulative number or the cumulative proportion of failures up to each time. The graph below shows the cumulative probability (or proportion) of failures at each time for the air conditioning system. The stairstep line in black shows the cumulative proportion of failures. For each step there is a blue tick at the bottom of the graph indicating an observed failure time. The smooth red line represents the exponential curve fitted to the observed data.

[[File:CDF for AC failures.svg|400px|CDF for AC failures]]

A graph of the cumulative probability of failures up to each time point is called the [[cumulative distribution function]], or CDF. In survival analysis, the cumulative distribution function gives the probability that the survival time is less than or equal to a specific time, t.

Let T be survival time, which is any positive number. A particular time is designated by the lower case letter t. The cumulative distribution function of ''T'' is the function

:&lt;math&gt;F(t) = \operatorname{P}(T\leq t),&lt;/math&gt;

where the right-hand side represents the [[probability]] that the random variable ''T'' is less than or equal to ''t''. If time can take on any positive value, then the cumulative distribution function F(t) is the integral of the probability density function f(t).

For the air conditioning example, the graph of the CDF below illustrates that the probability that the time to failure is less than or equal to 100 hours is 0.81, as estimated using the exponential curve fit to the data.

[[File:AC Time to failure LT 100 hours.svg|400px|AC Time to failure LT 100 hours]]

An alternative to graphing the probability that the failure time is ''less'' than or equal to 100 hours is to graph the probability that the failure time is ''greater'' than 100 hours. The probability that the failure time is greater than 100 hours must be 1 minus the probability that the failure time is less than or equal to 100 hours, because total probability must sum to 1.

This gives

P(failure time &gt; 100 hours)  = 1 - P(failure time &lt; 100 hours) = 1 – 0.81 = 0.19.

This relationship generalizes to all failure times:

P(T &gt; t)  = 1 - P(T &lt; t) = 1 – cumulative distribution function.

This relationship is shown on the graphs below. The graph on the left is the cumulative distribution function, which is P(T &lt; t). The graph on the right is P(T &gt; t)  = 1 - P(T &lt; t). The graph on the right is the survival function, S(t). The fact that the S(t) = 1 – CDF is the reason that another name for the survival function is the complementary cumulative distribution function.

[[File:Survival function is 1 - CDF.svg|400px|Survival function is 1 - CDF]]

==Parametric survival functions==

In some cases, such as the air conditioner example, the distribution of survival times may be approximated well by a function such as the exponential distribution. Several distributions are commonly used in survival analysis, including the exponential, Weibull, gamma, normal, log-normal, and log-logistic.&lt;ref name="Ebeling2010" /&gt;&lt;ref name="Klein2005"&gt;{{Citation
|last1= Klein
|first1= John
|last2= Moeschberger  
|first2= Melvin
|title= Survival Analysis: Techniques for Censored and Truncated Data 
|edition= Second
|year=2005
|publisher= Springer
|isbn= 978-0387953991 
}}
&lt;/ref&gt; These distributions are defined by parameters. The normal (Gaussian) distribution, for example, is defined by the two parameters mean and standard deviation. Survival functions that are defined by parameters are said to be parametric.

In the four survival function graphs shown above, the shape of the survival function is defined by a particular probability distribution: survival function 1 is defined by an exponential distribution, 2 is defined by a Weibull distribution, 3 is defined by a log-logistic distribution, and 4 is defined by another Weibull distribution.

===Exponential survival function===

For an exponential survival distribution, the probability of failure is the same in every time interval, no matter the age of the individual or device. This fact leads to the "memoryless" property of the exponential survival distribution:  the age of a subject has no effect on the probability of failure in the next time interval. The exponential may be a good model for the lifetime of a system where parts are replaced as they fail.&lt;ref name="Mendenhall2007"&gt;{{Citation
|last1= Mendenhall
|first1= William
|last2= Terry
|first2= Sincich
|title= Statistics for Engineering and the Sciences
|edition=Fifth
|year=2007
|publisher= Pearson / Prentice Hall
|isbn= 978-0131877061
}}
&lt;/ref&gt; It may also be useful for modeling survival of living organisms over short intervals. It is not likely to be a good model of the complete lifespan of a living organism.&lt;ref name="Brostrom2012"&gt;{{Citation
|last1= Brostrom
|first1= Göran
|title= Event History Analysis with R
|edition=First
|year=2012
|publisher= Chapman &amp; Hall/CRC
|isbn= 978-1439831649
}}
&lt;/ref&gt; As Efron and Hastie &lt;ref name="EfronHastie2016"&gt;{{Citation
|last1= Efron
|first1= Bradley
|last2= Hastie
|first2= Trevor
|title= Computer Age Statistical Inference: Algorithms, Evidence, and Data Science
|edition= First
|year=2016
|publisher= Cambridge University Press
|isbn= 978-1107149892
}}
&lt;/ref&gt;
(p.&amp;nbsp;134) note, "If human lifetimes were exponential there wouldn't be old or young people, just lucky or unlucky ones".

===Weibull survival function===

A key assumption of the exponential survival function is that the hazard rate is constant. In an example given above, the proportion of men dying each year was constant at 10%, meaning that the hazard rate was constant. The assumption of constant hazard may not be appropriate. For example, among most living organisms, the risk of death is greater in old age than in middle age – that is, the hazard rate increases with time. For some diseases, such as breast cancer, the risk of recurrence is lower after 5 years – that is, the hazard rate decreases with time. The [[Weibull distribution]] extends the exponential distribution to allow constant, increasing, or decreasing hazard rates.

=== Other parametric survival functions===

There are several other parametric survival functions that may provide a better fit to a particular data set, including normal, lognormal, log-logistic, and gamma. The choice of parametric distribution for a particular application can be made using graphical methods or using formal tests of fit.
These distributions and tests are described in textbooks on survival analysis.&lt;ref name="KleinbaumKlein2012" /&gt;&lt;ref name="Ebeling2010" /&gt; Lawless &lt;ref name=" Lawless2002"&gt;{{Citation
|last1= Lawless
|first1= Jerald 
|title= Statistical Models and Methods for Lifetime Data 
|edition=Second
|year=2002
|publisher= Wiley
|isbn= 978-0471372158
}}
&lt;/ref&gt;
has extensive coverage of parametric models.

Parametric survival functions are commonly used in manufacturing applications, in part because they enable estimation of the survival function beyond the observation period. However, appropriate use of parametric functions requires that data are well modeled by the chosen distribution. If an appropriate distribution is not available, or cannot be specified before a clinical trial or experiment, then non-parametric survival functions offer a useful alternative.

==Non-parametric survival functions==

A parametric model of survival may not be possible or desirable. In these situations, the most common method to model the survival function is the non-parametric [[Kaplan–Meier estimator]].

==Properties==

Every survival function ''S''(''t'') is [[monotonic function|monotonically decreasing]], i.e. &lt;math&gt;S(u) \le S(t)&lt;/math&gt; for all &lt;math&gt;u &gt; t&lt;/math&gt;.

It is a property of a [[random variable]] that maps a set of events, usually associated with mortality or failure of some system, onto [[time]].

The [[time]], ''t'' = 0, represents some origin, typically the beginning of a study or the start of operation of some system. ''S''(0) is commonly unity but can be less to represent the [[probability]] that the system fails immediately upon operation.

Since the CDF is a [[right-continuous]] function, the survival function &lt;math&gt;S(t) = 1-F(t)&lt;/math&gt; is also right-continuous.

==See also==
{{Portal|Statistics}}
*[[Failure rate]]
*[[Frequency of exceedance]]
*[[Kaplan–Meier estimator]]
*[[Mean time to failure]]
*[[Residence time (statistics)]]
*[[Survivorship curve]]

==References==
{{Reflist}}

{{Statistics|analysis}}

{{DEFAULTSORT:Survival Function}}
[[Category:Survival analysis]]
[[Category:Applied probability]]

[[fr:Analyse de survie#Fonction de survie]]</text>
      <sha1>64ahgm8ah033a3spvc09ettzceesyok</sha1>
    </revision>
  </page>
  <page>
    <title>Sylvester's sequence</title>
    <ns>0</ns>
    <id>4535485</id>
    <revision>
      <id>860783715</id>
      <parentid>845147777</parentid>
      <timestamp>2018-09-23T01:31:49Z</timestamp>
      <contributor>
        <username>VladimirReshetnikov</username>
        <id>8541403</id>
      </contributor>
      <comment>/* Closed form formula and asymptotics */ The last listed digit 2 was incorrect, see https://oeis.org/A076393</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20938">[[Image:Sylvester-square.svg|thumb|300px|Graphical demonstration of the convergence of the sum 1/2 + 1/3 + 1/7 + 1/43 + ... to 1. Each row of ''k'' squares of side length 1/''k'' has total area 1/''k'', and all the squares together exactly cover a larger square with area 1. Squares with side lengths 1/1807 or smaller are too small to see in the figure and are not shown.]]
In [[number theory]], '''Sylvester's sequence''' is an [[integer sequence]] in which each member of the sequence is the product of the previous members, plus one. The first few terms of the sequence are:
:2, 3, 7, 43, 1807, 3263443, 10650056950807, 113423713055421844361000443 {{OEIS|id=A000058}}.

Sylvester's sequence is named after [[James Joseph Sylvester]], who first investigated it in 1880. Its values grow [[Double exponential function|doubly exponentially]], and the sum of its [[Reciprocal (mathematics)|reciprocal]]s forms a [[Series (mathematics)|series]] of [[unit fraction]]s that converges to 1 more rapidly than any other series of unit fractions with the same number of terms. The [[recurrence relation|recurrence]] by which it is defined allows the numbers in the sequence to be [[integer factorization|factored]] more easily than other numbers of the same magnitude, but, due to the rapid growth of the sequence, complete [[prime factor]]izations are known only for a few of its members. Values derived from this sequence have also been used to construct finite [[Egyptian fraction]] representations of 1, [[Sasakian manifold|Sasakian]] [[Einstein manifold]]s, and hard instances for [[online algorithm]]s.

== Formal definitions ==
Formally, Sylvester's sequence can be defined by the formula
:&lt;math&gt;s_n = 1 + \prod_{i = 0}^{n - 1} s_i.&lt;/math&gt;
The [[empty product|product of an empty set]] is 1, so ''s''&lt;sub&gt;0&lt;/sub&gt; = 2.

Alternatively, one may define the sequence by the [[recurrence relation|recurrence]]
:&lt;math&gt;\displaystyle s_i = s_{i-1}(s_{i-1}-1)+1,&lt;/math&gt; with ''s''&lt;sub&gt;0&lt;/sub&gt; = 2.
It is straightforward to show by induction that this is equivalent to the other definition.

== Closed form formula and asymptotics ==
The Sylvester numbers grow [[double exponential function|doubly exponentially]] as a function of ''n''. Specifically, it can be shown that

:&lt;math&gt;s_n = \left\lfloor E^{2^{n+1}}+\frac12 \right\rfloor,&lt;/math&gt;

for a number ''E'' that is approximately 1.26408473530530...&lt;ref&gt;{{harvtxt|Graham|Knuth|Patashnik|1989}} set this as an exercise; see also {{harvtxt|Golomb|1963}}.&lt;/ref&gt; This formula has the effect of the following [[algorithm]]:
:s&lt;sub&gt;0&lt;/sub&gt; is the nearest integer to E&lt;sup&gt;2&lt;/sup&gt;; s&lt;sub&gt;1&lt;/sub&gt; is the nearest integer to E&lt;sup&gt;4&lt;/sup&gt;; s&lt;sub&gt;2&lt;/sub&gt; is the nearest integer to E&lt;sup&gt;8&lt;/sup&gt;; for  s&lt;sub&gt;''n''&lt;/sub&gt;, take E&lt;sup&gt;2&lt;/sup&gt;, square it ''n'' more times, and take the nearest integer.
This would only be a practical algorithm if we had a better way of calculating E to the requisite number of places than calculating s&lt;sub&gt;''n''&lt;/sub&gt; and taking its repeated square root.

The double-exponential growth of the Sylvester sequence is unsurprising if one compares it to the sequence of [[Fermat number]]s ''F''&lt;sub&gt;''n''&lt;/sub&gt;; the Fermat numbers are usually defined by a doubly exponential formula, &lt;math&gt;2^{2^n}+1&lt;/math&gt;, but they can also be defined by a product formula very similar to that defining Sylvester's sequence:

:&lt;math&gt;F_n = 2 + \prod_{i = 0}^{n - 1} F_i.&lt;/math&gt;

== Connection with Egyptian fractions ==
The [[unit fraction]]s formed by the [[Multiplicative inverse|reciprocals]] of the values in Sylvester's sequence generate an [[Series (mathematics)|infinite series]]:
:&lt;math&gt;\sum_{i=0}^{\infty} \frac1{s_i} = \frac12 + \frac13 + \frac17 + \frac1{43} + \frac1{1807} + \cdots.&lt;/math&gt;
The partial sums of this series have a simple form,
:&lt;math&gt;\sum_{i=0}^{j-1} \frac1{s_i} = 1 - \frac{1}{s_j-1} = \frac{s_j-2}{s_j-1}.&lt;/math&gt;
This may be proved by induction, or more directly by noting that the recursion implies that
:&lt;math&gt;\frac{1}{s_i-1}-\frac{1}{s_{i+1}-1}=\frac{1}{s_i},&lt;/math&gt;
so the sum [[Telescoping series|telescopes]]
:&lt;math&gt;\sum_{i=0}^{j-1} \frac{1}{s_i} = \sum_{i=0}^{j-1} \left( \frac{1}{s_i-1}-\frac{1}{s_{i+1}-1} \right) = \frac{1}{s_0-1} - \frac{1}{s_j-1} = 1 - \frac{1}{s_j-1}.&lt;/math&gt;
Since this sequence of partial sums (''s''&lt;sub&gt;''j''&lt;/sub&gt;-2)/(''s''&lt;sub&gt;''j''&lt;/sub&gt;-1) converges to one, the overall series forms an infinite [[Egyptian fraction]] representation of the number one:
:&lt;math&gt;1 = \frac12 + \frac13 + \frac17 + \frac1{43} + \frac1{1807} + \cdots.&lt;/math&gt;
One can find finite Egyptian fraction representations of one, of any length, by truncating this series and subtracting one from the last denominator:
:&lt;math&gt;1 = \tfrac12 + \tfrac13 + \tfrac16, \quad 1 = \tfrac12 + \tfrac13 + \tfrac17 + \tfrac1{42}, \quad 1 = \tfrac12 + \tfrac13 + \tfrac17 + \tfrac1{43} + \tfrac1{1806},\quad \dots.&lt;/math&gt;
The sum of the first ''k'' terms of the infinite series provides the closest possible underestimate of 1 by any ''k''-term Egyptian fraction.&lt;ref&gt;This claim is commonly attributed to {{harvtxt|Curtiss|1922}}, but {{harvtxt|Miller|1919}} appears to be making the same statement in an earlier paper. See also {{harvtxt|Rosenman|Underwood|1933}}, {{harvtxt|Salzer|1947}}, and {{harvtxt|Soundararajan|2005}}.&lt;/ref&gt; For example, the first four terms add to 1805/1806, and therefore any Egyptian fraction for a number in the open interval (1805/1806,1) requires at least five terms.

It is possible to interpret the Sylvester sequence as the result of a [[greedy algorithm for Egyptian fractions]], that at each step chooses the smallest possible denominator that makes the partial sum of the series be less than one. Alternatively, the terms of the sequence after the first can be viewed as the denominators of the [[odd greedy expansion]] of 1/2.

== Uniqueness of quickly growing series with rational sums ==
As Sylvester himself observed, Sylvester's sequence seems to be unique in having such quickly growing values, while simultaneously having a series of reciprocals that converges to a rational number. This sequence provides an example showing that double-exponential growth is not enough to cause an integer sequence to be an [[irrationality sequence]].{{sfnp|Guy|2004}}

To make this more precise, it follows from results of {{harvtxt|Badea|1993}} that, if a sequence of integers &lt;math&gt;a_n&lt;/math&gt; grows quickly enough that
:&lt;math&gt;a_n\ge a_{n-1}^2-a_{n-1}+1,&lt;/math&gt;
and if the series
:&lt;math&gt;A=\sum\frac1{a_i}&lt;/math&gt;
converges to a rational number ''A'', then, for all  ''n'' after some point, this sequence must be defined by the same recurrence
:&lt;math&gt;a_n= a_{n-1}^2-a_{n-1}+1&lt;/math&gt;
that can be used to define Sylvester's sequence.

{{harvtxt|Erdős|Graham|1980}} [[Erdős conjecture|conjectured]] that, in results of this type, the inequality bounding the growth of the sequence could be replaced by a weaker condition,
:&lt;math&gt;\lim_{n\rightarrow\infty} \frac{a_n}{a_{n-1}^2}=1.&lt;/math&gt;
{{harvtxt|Badea|1995}} surveys progress related to this conjecture; see also {{harvtxt|Brown|1979}}.

== Divisibility and factorizations ==
If ''i'' &lt; ''j'', it follows from the definition that ''s''&lt;sub&gt;''j''&lt;/sub&gt; ≡ 1 (mod ''s''&lt;sub&gt;''i''&lt;/sub&gt;). Therefore, every two numbers in Sylvester's sequence are [[relatively prime]]. The sequence can be used to prove that there are infinitely many [[prime number]]s, as any prime can divide at most one number in the sequence. More strongly, no prime factor of a number in the sequence can be congruent to 5 (mod 6), and the sequence can be used to prove that there are infinitely many primes congruent to 7 (mod 12).{{sfnp|Guy|Nowakowski|1975}}

{{unsolved|mathematics|Are all the terms in Sylvester's sequence squarefree?}}
Much remains unknown about the factorization of the numbers in the Sylvester's sequence. For instance, it is not known if all numbers in the sequence are [[Square-free integer|squarefree]], although all the known terms are.

As {{harvtxt|Vardi|1991}} describes, it is easy to determine which Sylvester number (if any) a given prime ''p'' divides: simply compute the recurrence defining the numbers modulo ''p'' until finding either a number that is congruent to zero (mod ''p'') or finding a repeated modulus.  Via this technique he found that 1166 out of the first three million primes are divisors of Sylvester numbers,&lt;ref&gt;This appears to be a typo, as Andersen finds 1167 prime divisors in this range.&lt;/ref&gt; and that none of these primes has a square that divides a Sylvester number. 
The set of primes which can occur as factors of Sylvester numbers is of density zero in the set of all primes:{{sfnp|Jones|2006}} indeed, the number of such primes less than ''x'' is &lt;math&gt;O(\pi(x) / \log\log\log x)&lt;/math&gt;.{{sfnp|Odoni|1985}}

The following table shows known factorizations of these numbers, (except the first four, which are all prime):&lt;ref&gt;All prime factors ''p'' of Sylvester numbers ''s''&lt;sub&gt;''n''&lt;/sub&gt; with ''p'' &amp;lt; 5{{e|7}} and ''n'' ≤ 200 are listed by Vardi. Ken Takusagawa lists the [http://kenta.blogspot.com/2006/01/factoring-sylvesters-sequence.html factorizations up to ''s''&lt;sub&gt;9&lt;/sub&gt;] and the [http://kenta.blogspot.com/2006/04/sylvester-10th-factored.html factorization of ''s''&lt;sub&gt;10&lt;/sub&gt;]. The remaining factorizations are from [http://primerecords.dk/sylvester-factors.htm a list of factorizations of Sylvester's sequence] maintained by Jens Kruse Andersen. Retrieved 2014-06-13.&lt;/ref&gt;

{| class="wikitable"
|-
! ''n''
! Factors of ''s''&lt;sub&gt;''n''&lt;/sub&gt;
|-
|4
|13 × 139
|-
|5
|3263443, which is prime
|-
|6
|547 × 607 × 1033 × 31051
|-
|7
|29881 × 67003 × 9119521 × 6212157481
|-
|8
|5295435634831 × 31401519357481261 × 77366930214021991992277
|-
|9
|[[181 (number)|181]] × 1987 × 112374829138729 × 114152531605972711 × 35874380272246624152764569191134894955972560447869169859142453622851
|-
|10
|2287 × 2271427 × 21430986826194127130578627950810640891005487 × P156
|-
|11
|[[73 (number)|73]] × C416
|-
|12
|2589377038614498251653 × 2872413602289671035947763837 × C785
|-
|13
|52387 × 5020387 × 5783021473 × 401472621488821859737 × 287001545675964617409598279 × C1600
|-
|14
|13999 × 74203 × 9638659 × 57218683 × 10861631274478494529 × C3293
|-
|15
|17881 × 97822786011310111 × 54062008753544850522999875710411 × C6618
|-
|16
|128551 × C13335
|-
|17
|635263 × 1286773 × 21269959 × C26661
|-
|18
|50201023123 × 139263586549 × 60466397701555612333765567 × C53313 
|-
|19
|775608719589345260583891023073879169 × C106685
|-
|20
|352867 × 6210298470888313 × C213419
|-
|21
|387347773 × 1620516511 × C426863
|-
|22
|91798039513 × C853750
|}

As is customary, P''n'' and C''n'' denote prime and [[composite numbers]] ''n'' digits long.

== Applications ==
{{harvtxt|Boyer|Galicki|Kollár|2005}} use the properties of Sylvester's sequence to define large numbers of [[Sasakian manifold|Sasakian]] [[Einstein manifold]]s having the [[differential topology]] of odd-dimensional [[hypersphere|spheres]] or [[exotic sphere]]s. They show that the number of distinct Sasakian Einstein [[Riemannian metric|metrics]] on a [[topological sphere]] of dimension 2''n'' &amp;minus; 1 is at least proportional to ''s''&lt;sub&gt;''n''&lt;/sub&gt; and hence has double exponential growth with ''n''.

As {{harvtxt|Galambos|Woeginger|1995}} describe, {{harvtxt|Brown|1979}} and {{harvtxt|Liang|1980}} used values derived from Sylvester's sequence to construct lower bound examples for [[online algorithm|online]] [[bin packing]] [[algorithm]]s. {{harvtxt|Seiden|Woeginger|2005}} similarly use the sequence to lower bound the performance of a two-dimensional cutting stock algorithm.&lt;ref&gt;In their work, Seiden and Woeginger refer to Sylvester's sequence as "Salzer's sequence" after the work of {{harvtxt|Salzer|1947}} on closest approximation.&lt;/ref&gt;

[[Znám's problem]] concerns sets of numbers such that each number in the set divides but is not equal to the product of all the other numbers, plus one. Without the inequality requirement, the values in Sylvester's sequence would solve the problem; with that requirement, it has other solutions derived from recurrences similar to the one defining Sylvester's sequence. Solutions to Znám's problem have applications to the classification of surface singularities (Brenton and Hill 1988) and to the theory of [[nondeterministic finite automata]].{{sfnp|Domaratzki|Ellul|Shallit|Wang|2005}}

{{harvs|first=D. R.|last=Curtiss|authorlink=David Raymond Curtiss|year=1922|txt}} describes an application of the closest approximations to one by ''k''-term sums of unit fractions, in lower-bounding the number of divisors of any [[perfect number]], and {{harvtxt|Miller|1919}} uses the same property to [[upper bound]] the size of certain [[Group (mathematics)|groups]].

== See also ==
* [[Cahen's constant]]
* [[Primary pseudoperfect number]]

== Notes ==
{{reflist|30em}}

== References ==
{{refbegin|30em}}
* {{cite journal
  | last = Badea | first = Catalin
  | title = A theorem on irrationality of infinite series and applications
  | year = 1993
  | journal = [[Acta Arithmetica]]
  | volume = 63
  | pages = 313–323
  | mr = 1218459
  | ref = harv}}
* {{cite web
 |last        = Badea
 |first       = Catalin
 |title       = On some criteria for irrationality for series of positive rationals: a survey
 |year        = 1995
 |url         = http://www.lacim.uqam.ca/~plouffe/OEIS/citations/caen.pdf
 |ref         = harv
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20080911223925/http://www.lacim.uqam.ca/~plouffe/OEIS/citations/caen.pdf
 |archivedate = 2008-09-11
 |df          = 
}}
*{{cite journal
  | last1 = Boyer | first1 = Charles P.
  | last2 = Galicki | first2 = Krzysztof
  | last3 = Kollár | first3 = János
  | title = Einstein metrics on spheres
  | journal = [[Annals of Mathematics]]
  | volume = 162
  | issue = 1
  | year = 2005
  | pages = 557–580
  | arxiv = math.DG/0309408 | mr = 2178969
  | doi = 10.4007/annals.2005.162.557
  | ref = harv}}
* {{cite journal
  | last1 = Brenton | first1 = Lawrence | last2 = Hill | first2 = Richard
  | title = On the Diophantine equation 1=&amp;Sigma;1/''n''&lt;sub&gt;''i''&lt;/sub&gt; + 1/&amp;Pi;''n''&lt;sub&gt;''i''&lt;/sub&gt; and a class of homologically trivial complex surface singularities
  | journal = [[Pacific Journal of Mathematics]]
  | url = http://projecteuclid.org/euclid.pjm/1102689567
  | volume = 133
  | issue = 1
  | year = 1988
  | pages = 41–67
  | mr = 0936356 | doi=10.2140/pjm.1988.133.41
  | ref = harv}}
* {{cite journal
  | last = Brown | first = D. J.
  | title = A lower bound for on-line one-dimensional bin packing algorithms
  | version = Tech. Rep. R-864
  | year = 1979
  | publisher = Coordinated Science Lab., Univ. of Illinois, Urbana-Champaign
  | ref = harv}}
* {{cite journal
  | last = Curtiss | first = D. R. | authorlink = David Raymond Curtiss| title = On Kellogg's diophantine problem
  | journal = [[American Mathematical Monthly]]
  | jstor = 2299023
  | volume = 29
  | year = 1922
  | issue = 10
  | pages = 380–387
  | doi = 10.2307/2299023
  | ref = harv}}
* {{cite journal
  | last1 = Domaratzki | first1 = Michael
  | last2 = Ellul | first2 = Keith
  | author3-link = Jeffrey Shallit | last3 = Shallit | first3 = Jeffrey
  | last4 = Wang | first4 = Ming-Wei
  | title = Non-uniqueness and radius of cyclic unary NFAs
  | journal = International Journal of Foundations of Computer Science
  | volume = 16
  | issue = 5
  | pages = 883–896
  | year = 2005
  | url = http://www.cs.umanitoba.ca/~mdomarat/pubs/DESW_dcfs.ps 
  | mr = 2174328
  | doi = 10.1142/S0129054105003352
  | ref = harv}}
* {{cite book
  | author1-link = Paul Erdős | last1 = Erdős | first1 = Paul
  | author2-link = Ronald Graham | last2 = Graham | first2 = Ronald L.
  | year = 1980
  | title = Old and new problems and results in combinatorial number theory
  | publisher = Monographies de L'Enseignement Mathématique, No. 28, Univ. de Genève
  | mr = 0592420
  | ref = harv}}
* {{cite journal
  | last1 = Galambos | first1 = Gábor | last2 = Woeginger | first2 = Gerhard J. | author2-link = Gerhard J. Woeginger
  | title = On-line bin packing — A restricted survey
  | journal = Mathematical Methods of Operations Research
  | volume = 42
  | issue = 1
  | year = 1995
  | doi = 10.1007/BF01415672
  | mr = 1346486
  | pages = 25
  | ref = harv}}
* {{cite journal
  | last1 = Golomb | first1 = Solomon W.
  | authorlink = Solomon Golomb
  | title = On certain nonlinear recurring sequences
  | year = 1963
  | journal = American Mathematical Monthly
  | volume = 70
  | issue = 4
  | pages = 403–405
  | jstor = 2311857
  | mr = 0148605
  | doi = 10.2307/2311857
  | ref = harv}}
* {{cite book
  | author1-link = Ronald Graham| last1 = Graham | first1 = R.
  | author2-link = Donald Knuth | last2 = Knuth | first2 = D. E.
  | last3 = Patashnik | first3 = O.
  | title = Concrete Mathematics
  | edition = 2nd
  | year = 1989
  | publisher = Addison-Wesley
  | at = Exercise 4.37
  | isbn = 0-201-55802-5
  | ref = harv}}
*{{cite book |last=Guy | first=Richard K. | authorlink=Richard K. Guy | title=Unsolved Problems in Number Theory | publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=0-387-20860-7 | zbl=1058.11001 | contribution=E24 Irrationality sequences|page=346|url=https://books.google.com/books?id=1AP2CEGxTkgC&amp;pg=PA346 |ref=harv}}
*{{cite journal
 | last1 = Guy | first1 = Richard
 | last2 = Nowakowski | first2 = Richard
 | issue = 2
 | journal = Delta (Waukesha)
 | mr = 0384675
 | pages = 49–63
 | title = Discovering primes with Euclid
 | volume = 5
 | year = 1975
  | ref = harv}}
*{{cite journal  | last = Jones | first = Rafe  | title = The density of prime divisors in the arithmetic dynamics of quadratic polynomials
  | year = 2006
  | arxiv = math.NT/0612415|ref=harv | doi=10.1112/jlms/jdn034 | volume=78 | journal=Journal of the London Mathematical Society | pages=523–544}}
* {{cite journal
  | last = Liang | first = Frank M.
  | title = A lower bound for on-line bin packing
  | year = 1980
  | journal = Information Processing Letters
  | volume = 10
  | issue = 2
  | pages = 76–79
  | mr = 0564503
  | doi = 10.1016/S0020-0190(80)90077-0
  | ref = harv}}
* {{cite journal
  | last = Miller | first = G. A.
  | title = Groups possessing a small number of sets of conjugate operators
  | journal = [[Transactions of the American Mathematical Society]]
  | year = 1919
  | volume = 20
  | issue = 3
  | pages = 260–270
  | jstor = 1988867
  | doi = 10.2307/1988867
  | ref = harv}}
*{{cite journal | last=Odoni | first=R. W. K. | title=On the prime divisors of the sequence w&lt;sub&gt;n+1&lt;/sub&gt; =1+w&lt;sub&gt;1&lt;/sub&gt;⋯w&lt;sub&gt;n&lt;/sub&gt; | zbl=0574.10020 | journal=J. Lond. Math. Soc., II. Ser. | volume=32 | pages=1–11 | year=1985|ref=harv }}
* {{cite journal
  | last = Rosenman | first = Martin
  | last2 = Underwood | first2 = F.
  | title = Problem 3536
  | journal = American Mathematical Monthly
  | volume = 40
  | issue = 3
  | year = 1933
  | jstor = 2301036
  | pages = 180–181
  | doi = 10.2307/2301036
  | ref = harv}}
* {{cite journal
  | last = Salzer | first = H. E.
  | journal = American Mathematical Monthly
  | year = 1947
  | title = The approximation of numbers as sums of reciprocals
  | volume = 54
  | issue = 3
  | pages = 135–142
  | jstor = 2305906
  | mr = 0020339
  | doi = 10.2307/2305906
  | ref = harv}}
* {{cite journal
  | last1 = Seiden | first1 = Steven S. | last2 = Woeginger | first2 = Gerhard J. | author2-link = Gerhard J. Woeginger
  | title = The two-dimensional cutting stock problem revisited
  | journal = Mathematical Programming
  | volume = 102
  | issue = 3
  | year = 2005
  | pages = 519–530
  | doi = 10.1007/s10107-004-0548-1
  | mr = 2136225
  | ref = harv}}
* {{cite journal
  | last = Soundararajan | first = K.
  | year = 2005
  | title = Approximating 1 from below using ''n'' Egyptian fractions
  | arxiv = math.CA/0502247
  | ref = harv}}
* {{cite journal
  | last = Sylvester | first = J. J.
  | authorlink = J. J. Sylvester
  | title = On a point in the theory of vulgar fractions
  | jstor = 2369261
  | journal = [[American Journal of Mathematics]]
  | volume = 3
  | issue = 4
  | year = 1880
  | pages = 332–335
  | doi = 10.2307/2369261
  | ref = harv}}
* {{cite book
  | last = Vardi | first = Ilan
  | title = Computational Recreations in Mathematica
  | year = 1991
  | publisher = Addison-Wesley
  | pages = 82–89
  | isbn = 0-201-52989-0
  | ref = harv}}
{{refend}}

== External links ==
* [https://web.archive.org/web/20000516205029/http://mathpages.com/home/kmath455.htm Irrationality of Quadratic Sums], from K. S. Brown's MathPages.
* {{mathworld | title = Sylvester's Sequence | urlname = SylvestersSequence}}

{{good article}}

[[Category:Egyptian fractions]]
[[Category:Integer sequences]]
[[Category:Mathematical series]]
[[Category:Number theory]]
[[Category:Recurrence relations]]</text>
      <sha1>cklqo8z5x04250d0bl828dh5fybf6dn</sha1>
    </revision>
  </page>
  <page>
    <title>Systematic code</title>
    <ns>0</ns>
    <id>8722775</id>
    <revision>
      <id>723919740</id>
      <parentid>634828261</parentid>
      <timestamp>2016-06-06T02:06:57Z</timestamp>
      <contributor>
        <username>Dcirovic</username>
        <id>11795905</id>
      </contributor>
      <minor/>
      <comment>refs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4018">In [[coding theory]], a '''systematic code''' is any [[error-correcting code]] in which the input data is embedded in the encoded output. Conversely, in a '''non-systematic code''' the output does not contain the input symbols.

Systematic codes have the advantage that the parity data can simply be appended to the source block, and receivers do not need to recover the original source symbols if received correctly &amp;ndash; this is useful for example if error-correction coding is combined with a hash function for quickly determining the correctness of the received source symbols, or in cases where errors occur in [[Erasure channel (disambiguation)|erasures]] and a received symbol is thus always correct. Furthermore, for engineering purposes such as synchronization and monitoring, it is desirable to get reasonable good estimates of the received source symbols without going through the lengthy decoding process which may be carried out at a remote site at a later time.&lt;ref name="nonsystematic"&gt;{{cite journal|author=[[James L. Massey]], [[Daniel J. Costello, Jr.]]|title=Nonsystematic convolutional codes for sequential decoding in space applications|journal=[[IEEE]] Transactions on Communication Technology|volume=19|issue=5|year=1971|doi=10.1109/TCOM.1971.1090720}}&lt;/ref&gt;

==Properties==
Every non-systematic linear code can be transformed into a systematic code with essentially the same properties (i.e., minimum distance).&lt;ref name="nonsystematic"/&gt;&lt;ref name=" Richard_Blahut"&gt;{{cite book|title=Algebraic codes for data transmission|author=Richard E. Blahut|pages=53–54|year=2003|publisher=Cambridge. Univ. Press|isbn=978-0-521-55374-2|edition = 2nd}}&lt;/ref&gt;
Because of the advantages cited above, [[linear code|linear]] error-correcting codes are therefore generally implemented as systematic codes. However, for certain decoding algorithms such as sequential decoding or maximum-likelihood decoding, a non-systematic structure can increase performance in terms of undetected decoding error probability when the minimum ''free'' distance of the code is larger.&lt;ref name="nonsystematic"/&gt;&lt;ref&gt;{{cite book |author1=Shu Lin |author2=Daniel J. Costello, Jr. | title=Error Control Coding: Fundamentals and Applications | publisher=[[Prentice Hall]] | year=1983 | isbn=0-13-283796-X | pages=278–280}}&lt;/ref&gt;

For a systematic [[linear code]], the [[generator matrix]], &lt;math&gt;G&lt;/math&gt;, can always be written as &lt;math&gt;G = [ I_k | P ]&lt;/math&gt;, where &lt;math&gt;I_k&lt;/math&gt; is the [[identity matrix]] of size &lt;math&gt;k&lt;/math&gt;.

==Examples==
* [[Checksum]]s and [[hash function]]s, combined with the input data, can be viewed as systematic error-detecting codes.
* Linear codes are usually implemented as systematic error-correcting codes (e.g., Reed-Solomon codes in [[Compact Disc|CDs]]).
* [[Convolutional code]]s are implemented as either systematic or non-systematic codes. Non-systematic convolutional codes can provide better performance under maximum-likelihood ([[Viterbi decoder|Viterbi]]) decoding.
* In [[DVB-H]], for additional error protection and power efficiency for mobile receivers, a systematic [[Reed–Solomon error correction|Reed-Solomon code]] is employed as an erasure code over packets within a [[burst transmission|data burst]], where each packet is protected with a [[Cyclic redundancy check|CRC]]: data in verified packets count as correctly received symbols, and if all are received correctly, evaluation of the additional parity data can be omitted, and receiver devices can switch off reception until the start of the next burst.
* [[Fountain code]]s may be either systematic or non-systematic: as they do not exhibit a fixed [[code rate]], the set of source symbols is diminishing among the possible output set.

==Notes==
&lt;references/&gt;

==References==
* {{cite book |author1=Shu Lin |author2=Daniel J. Costello, Jr. | title=Error Control Coding: Fundamentals and Applications | publisher=[[Prentice Hall]] | year=1983 | isbn=0-13-283796-X | pages=278–280}}

[[Category:Coding theory]]</text>
      <sha1>8nm1elhr03skk4wwoglrx848z94hto8</sha1>
    </revision>
  </page>
  <page>
    <title>Turing's proof</title>
    <ns>0</ns>
    <id>3739933</id>
    <revision>
      <id>867638909</id>
      <parentid>867493649</parentid>
      <timestamp>2018-11-07T01:13:30Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>[[WP:AWB/T|All typo fixes]] on, [[WP:AWB/T|typo(s) fixed]]: … → ..., Godel’s → Godel's (20)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42985">'''Turing's proof''' is a proof by [[Alan Turing]], first published in January 1937 with the title '''On Computable Numbers, with an Application to the [[Entscheidungsproblem]]'''.&lt;!--boldface per WP:R#PLA--&gt; It  was the second proof of the assertion ([[Alonzo Church]]'s proof was first) that some [[decision problem]]s are "[[undecidable problem|undecidable]]": there is no single algorithm that infallibly gives a correct "yes" or "no" answer to each instance of the problem. In his own words:
"...what I shall prove is quite different from the well-known results of Gödel ... I shall now show that there is no general method which tells whether a given formula '''U''' is provable in '''K''' [''[[Principia Mathematica]]'']..." (''Undecidable'', p.&amp;nbsp;145).

Turing preceded this proof with two others. The second and third both rely on the first. All rely on his development of type-writer-like "computing machines" that obey a simple set of rules and his subsequent development of a "universal computing machine".

==Richard's paradox==
In 1905, Jules Richard presented this profound paradox. Alan Turing's first proof constructs this paradox with his so-called computing machine and proves that this machine cannot answer a simple question: will this machine be able to determine if ''any'' computing machine (including itself) will become trapped in an unproductive "infinite loop" (i.e. it fails to continue its computation of the diagonal number).

A succinct definition of [[Richard's paradox]] is found in Whitehead and Russell's ''Principia Mathematica'':

:Richard's paradox is as follows. Consider all decimals that can be defined by means of a finite number of words; let E be the class of such decimals. Then E has [aleph-sub-zero — an infinity of] terms; hence its members can be ordered as the 1st, 2nd, 3rd, ... Let N be a number defined as follows [Whitehead &amp; Russell now employ the [[Cantor diagonal method]]]; if the nth figure in the nth decimal is p, let the nth figure in N be p+1 (or 0, if p = 9). Then N is different from all the members of E, since, whatever finite value n may have, the nth figure in N is different from the nth figure in the nth of the decimals composing E, and therefore N is different from the nth decimal. Nevertheless, we have defined N in a finite number of words [i.e. this very word-definition just above!] and therefore N ought to be a member of E. Thus N both is and is not a member of E (''Principia Mathematica'', 2nd edition 1927, p. 61).

==Complications==
Turing's proof is complicated by a large number of definitions, and confounded with what [[Martin Davis]] called "petty technical details" and "...technical details [that] are incorrect as given" (Davis's commentary in ''Undecidable'', p.&amp;nbsp;115). Turing himself published "A correction" in 1937: "The author is indebted to [[P. Bernays]] for pointing out these errors" (''Undecidable'', p.&amp;nbsp;152).

Specifically, in its original form the third proof is badly marred by technical errors. And even after Bernays' suggestions and Turing's corrections, errors remained in the description of the [[universal machine]]. And confusingly, since Turing was unable to correct his original paper, some text within the body harks to Turing's flawed first effort.

Bernays' corrections may be found in ''Undecidable'', pp.&amp;nbsp;152–154; the original is to be found as:
:"On Computable Numbers, with an Application to the Entscheidungsproblem. A Correction," ''Proceedings of the London Mathematical Society'' (2), 43 (1936–37), 544-546.''

The on-line version of Turing's paper has these corrections in an addendum; however, corrections to the Universal Machine must be found in an analysis provided by [[Emil Post]].

At first, the only mathematician to pay close attention to the details of the proof was Post (cf. Hodges p.&amp;nbsp;125) — mainly because he had arrived simultaneously at a similar reduction of "algorithm" to primitive machine-like actions, so he took a personal interest in the proof. Strangely (perhaps World War II intervened) it took Post some ten years to dissect it in the ''Appendix'' to his paper ''Recursive Unsolvability of a Problem of Thue'', 1947 (reprinted in ''Undecidable'', p.&amp;nbsp;293).

''Before readers tackle "Proof #3" they are advised to place those corrections on their copy of the proof.''

Other problems present themselves: In his ''Appendix'' Post commented indirectly on the paper's difficulty and directly on its "outline nature" (Post in ''Undecidable'', p.&amp;nbsp;299) and "intuitive form" of the proofs (''ibid''.). Post had to infer various points:

:"If our critique is correct, a machine is said to be circle-free if it is a Turing computing ... machine which prints an infinite number of 0s and 1s. And the two theorems of Turing's in question are really the following. There is no Turing ... machine which, when supplied with an arbitrary positive integer n, will determine whether n is the D.N of a Turing computing ... machine that is circle-free. [Secondly], There is no Turing convention-machine which, when supplied with an arbitrary positive integer n, will determine whether n is the D.N of a Turing computing ... machine that ever prints a given symbol (0 say)" (Post in ''Undecidable'', p. 300)

Anyone who has ever tried to read the paper will understand Hodges' complaint:

:"The paper started attractively, but soon plunged (in typical Turing manner) into a thicket of obscure German Gothic type in order to develop his instruction table for the universal machine. The last people to give it a glance would be the applied mathematicians who had to resort to practical computation..." (Hodges p. 124)

==Summary of the proofs==
In his proof that the Entscheidungsproblem can have no solution, Turing proceeded from two proofs that were to lead to his final proof. His first theorem is most relevant to the [[halting problem]], the second is more relevant to [[Rice's theorem]].

'''First proof''': that no "computing machine" exists that can decide whether or not an arbitrary "computing machine" (as represented by an integer 1, 2, 3, . . .) is "circle-free" (i.e. goes on printing its number in binary ad infinitum): "...we have no general process for doing this in a finite number of steps" (p.&amp;nbsp;132, ''ibid''.). Turing's proof, although it seems to use the "diagonal process", in fact shows that his machine (called H) cannot calculate its own number, let alone the entire diagonal number ([[Cantor's diagonal argument]]): "The fallacy in the argument lies in the assumption that B [the diagonal number] is computable" (''Undecidable'', p.&amp;nbsp;132). The proof does not require much mathematics.

'''Second proof''': This one is perhaps more familiar to readers as [[Rice's theorem]]: "We can show further that ''there can be no machine E which, when supplied with the S.D ["program"] of an arbitrary machine M, will determine whether M ever prints a given symbol (0 say)''" (his italics, ''Undecidable'', p. 134).

'''Third proof''': "Corresponding to each computing machine M we construct a formula Un(M) and we show that, if there is a general method for determining whether Un(M) is provable, then there is a general method for determining whether M ever prints 0" (''Undecidable'', p. 145)

[Readers who brave Proof #3 should come equipped with a solid background in (i) logic (ii) the paper of [[Kurt Gödel]] ''On Formally Undecidable Propositions of Principia Mathematica and Related Systems'' (reprinted in ''Undecidable'', p. 5). For assistance with Gödel's paper they should consult e.g. [[Ernest Nagel]] and [[James R. Newman]], ''Godel's Proof'', New York University Press, 1958.]

This proof requires the use of formal logic to prove a first lemma, followed by a brief word-proof of the second:
:"Lemma 1: If S1 [symbol "0"] appears on the tape in some complete configuration of M, then Un(M) is provable" (''Undecidable'', p. 147)

:"Lemma 2: [The converse] If Un(M) is provable then S1 [symbol "0"] appears on the tape in some complete configuration of M" (''Undecidable'', p. 148)

Finally, in only 64 words and symbols Turing proves by ''[[reductio ad absurdum]]'' that "the Hilbert Entscheidungsproblem can have no solution" (''Undecidable'', p. 145).

===Summary of the first proof===
Turing created a thicket of abbreviations; see the glossary at the end of this for help.

Some key clarifications:
:Turing's machine H is attempting to print a diagonal number of 0s and 1s
::This diagonal number is created when H actually "simulates" each "successful" machine under evaluation and prints the R-th "figure" (1 or 0) of the R-th "successful" machine
* Turing spent much of his paper actually "constructing" his machines to convince us of their truth. This was required by his use of the ''reductio ad absurdum'' form of proof.
* We must emphasize the "constructive" nature of this proof. Turing describes what could be a real machine, really buildable. The only questionable element is the existence of machine D, which this proof will eventually show to be impossible.

Turing begins the proof with the assertion of the existence of a “decision/determination” machine D. When fed any S.D (string of symbols A, C, D, L, R, N, semicolon “;”) it will determine if this S.D (symbol string) represents a "computing machine" that is either "circular" — and therefore "un-satisfactory u" —  or "circle-free" — and therefore "satisfactory s".

:Turing has previously demonstrated in his commentary that all "computing machines'' — machines that compute a number as 1s and 0s forever — can be written as an S.D on the tape of the “universal machine” U. Most of his work leading up to his first proof is spent demonstrating that a universal machine truly exists, i.e.
::There truly exists a universal machine U
::For each number N, there truly exists a unique S.D,
::Every Turing machine has an S.D
::Every S.D on U’s tape can be “run” by U and will produce the same “output” (figures 1, 0) as the original machine.

Turing makes no comment about how machine D goes about its work. For sake of argument, we suppose that D would first look to see if the string of symbols is "well-formed" (i.e. in the form of an algorithm and not just a scramble of symbols), and if not then discard it. Then it would go “circle-hunting”. To do this perhaps it would use “heuristics” (tricks: taught or learned). For purposes of the proof, these details are not important.

Turing then describes (rather loosely) the algorithm (method) to be followed by a machine he calls H. Machine H contains within it the decision-machine D (thus D is a “subroutine” of H). Machine H’s algorithm is expressed in H’s table of instructions, or perhaps in H’s Standard Description on tape and united with the universal machine U; Turing does not specify this.

:In the course of describing universal machine U, Turing has demonstrated that a machine’s S.D (string of letters similar to a “program”) can be converted to an integer (base 8) and vice versa. Any number N (in base 8) can be converted to an S.D with the following replacements: 1 by A, 2 by C, 3 by D, 4 by L, 5 by R, 6 by N, 7 by semicolon ";".

::As it turns out, machine H's unique number (D.N) is the number "K". We can infer that K is some hugely long number, maybe tens-of-thousands of digits long. But this is not important to what follows.

Machine H is responsible for converting ''any'' number N into an equivalent S.D symbol string for sub-machine D to test.  (In programming parlance: H passes an arbitrary "S.D” to D, and D returns “satisfactory” or “unsatisfactory”.) Machine H is also responsible for keeping a tally R (“Record”?) of successful numbers (we suppose that the number of “successful” S.D's, i.e. R, is much less than the number of S.D's tested, i.e. N). Finally, H prints on a section of its tape a diagonal number “beta-primed” B’. H creates this B’ by “simulating” (in the computer-sense) the “motions” of each “satisfactory” machine/number; eventually this machine/number under test will arrive at its Rth “figure” (1 or 0), and H will print it. H then is responsible for “cleaning up the mess” left by the simulation, incrementing N and proceeding onward with its tests, ''ad infinitum''.

:Note: All these machines that H is hunting for are what Turing called "computing machines". These compute binary-decimal-numbers in an endless stream of what Turing called "figures": only the symbols 1 and 0.

An example: Suppose machine H has tested 13472 numbers and produced 5 satisfactory numbers, i.e. H has converted the numbers 1 through 13472 into S.D’s (symbol strings) and passed them to D for test. As a consequence H has tallied 5 satisfactory numbers and run the first one to its 1st “figure”, the second to its  2nd figure, the third to its 3rd figure, the fourth to its 4th figure, and the fifth to its 5th figure. The count now stands at N = 13472, R = 5, and B’ = “.10011” (for example). H cleans up the mess on its tape, and proceeds:

''H'' increments ''N'' = 13473 and converts "13473" to symbol string ADRLD. If sub-machine D deems ADLRD unsatisfactory, then H leaves the tally-record R at 5. H will increment the number N to 13474 and proceed onward. On the other hand, if D deems  ADRLD satisfactory then H will increment R to 6. H will convert N (again) into ADLRD [this is just an example, ADLRD is probably useless] and “run” it using the universal machine U until this machine-under-test (U "running" ADRLD) prints its 6th “figure” i.e. 1 or 0. H will print this 6th number (e.g. “0”) in the “output” region of its tape (e.g. B’ = “.100110”).

H cleans up the mess, and then increments the number ''N'' to 13474.

The whole process unravels when H arrives at its own number K. We will proceed with our example. Suppose the successful-tally/record R stands at 12. H finally arrives at its own number minus 1, i.e. N = K-1 = 4335...321'''4''', and this number is unsuccessful. Then H increments N to produce K = 4355...321'''5''', i.e. its own number. H converts this to “LDDR...DCAR” and passes it to decision-machine D. Decision-machine D must return “satisfactory” (that is: H must ''by definition'' go on and on testing, ''ad infinitum'', because it is "circle-free"). So H now increments tally R from 12 to 13 and then re-converts the number-under-test K into its S.D and uses U to simulate it. But this means that H will be simulating its own motions. What is the first thing the simulation will do? This simulation K-aka-H either creates a new N or “resets” the “old” N to 1. This "K-aka-H" either creates a new R or “resets” the “old” R to 0. Old-H “runs” new "K-aka-H" until it arrives at its 12th figure.

But it never makes it to the 13th figure; K-aka-H eventually arrives at 4355...321'''5''', again, and ''K-aka-H'' must repeat the test. ''K-aka-H'' will never reach the 13th figure. The H-machine probably just prints copies of itself ''ad infinitum'' across blank tape. But this contradicts the premise that H is a satisfactory, non-circular computing machine that goes on printing the diagonal numbers's 1's and 0's forever. (We will see the same thing if N is reset to 1 and R is reset to 0.)

If the reader does not believe this, they can write a "stub" for decision-machine D (stub "D" will return "satisfactory") and then see for themselves what happens at the instant machine H encounters its own number.

===Summary of the second proof===
Less than one page long, the passage from premises to conclusion is obscure.

Turing proceeds by ''reductio ad absurdum''. He asserts the existence of a machine E, which when given the S.D (Standard Description, i.e. "program") of an arbitrary machine M, will determine whether M ever prints a given symbol (0 say). He does not assert that this M is a "computing machine".

Given the existence of machine E, Turing proceeds as follows:
# If machine E exists then a machine G exists that determines if M prints 0 infinitely often, AND
# If E exists then another process exits [we can call the process/machine G' for reference] that determines if M prints 1 infinitely often, THEREFORE
# When we combine G with G' we have a process that determines if M prints an infinity of figures, AND
# IF the process "G with G'" determines M prints an infinity of figures, THEN "G with G'" has determined that M is circle-free, BUT
# This process "G with G'" that determine if M is circle-free, by proof 1, cannot exist, THEREFORE
# Machine E does not exist.

===Details of second proof===
The difficulty in the proof is step 1. The reader will be helped by realizing that Turing is not explaining his subtle handiwork. (In a nutshell: he is using certain equivalencies between the “existential-“ and “universal-operators” together with their equivalent expressions written with logical operators.)

Here's an example: Suppose we see before us a parking lot full of hundreds of cars. We decide to go around the entire lot looking for: “Cars with flat (bad) tires”. After an hour or so we have found two “cars with bad tires.” We can now say with certainty that “Some cars have bad tires”. Or we could say: “It’s not true that ‘All the cars have good tires’”. Or: “It is true that: ‘not all the cars have good tires”. Let us go to another lot. Here we discover that “All the cars have good tires.” We might say, “There’s not a single instance of a car having a bad tire.”  Thus we see that, if we can say something about each car separately then we can say something about ALL of them collectively.

This is what Turing does:
From ''M'' he creates a collection of machines {''M''1, ''M''2, ''M''3, ''M''4, ..., ''Mn''} and about each he writes a sentence: “''X'' prints at least one 0” and allows only two “[[truth value]]s”, True = blank or False = :0:. One by one he determines the truth value of the sentence for each machine and makes a string of blanks or :0:, or some combination of these. We might get something like this: “''M''1 prints a 0” = True AND “''M''2 prints a 0” = True AND “''M''3 prints a 0” = True AND “''M''4 prints a 0” = False, ... AND “''Mn'' prints a 0” = False. He gets the string
:BBB:0::0::0: ... :0: ... ad infinitum
if there are an infinite number of machines ''Mn''. If on the other hand if every machine had produced a "True" then the expression on the tape would be
:BBBBB....BBBB ... ad infinitum

Thus Turing has converted statements about each machine considered separately into a single "statement" (string) about all of them. Given the machine (he calls it G) that created this expression, he can test it with his machine E and determine if it ever produces a 0. In our first example above we see that indeed it does, so we know that not all the M's in our sequence print 0s. But the second example shows that, since the string is blanks then every Mn in our sequence has produced a 0.

All that remains for Turing to do is create a process to create the sequence of Mn's from a single M.

Suppose ''M'' prints this pattern:

:''M'' =&gt; ...AB01AB0010AB…

Turing creates another machine F that takes M and crunches out a sequence of Mn's that successively convert the first n 0's to “0-bar” ('''0'''):
:M1 = ...AB'''0'''1AB0010AB...
:M2 = ...AB'''0'''1AB'''0'''010AB...
:M3 = ...AB'''0'''1AB'''00'''10AB...
:M4 = ...AB'''0'''1AB'''00'''1'''0'''AB...
He claims, without showing details, that this machine F is truly build-able. We can see that one of a couple things could happen. F may run out of machines that have 0's, or it may have to go on ''ad infinitum'' creating machines to “cancel the zeros”.

Turing now combines machines E and F into a composite machine G. G starts with the original M, then uses F to create all the successor-machines M1, M2,. . ., Mn. Then G uses E to test each machine starting with M. If E detects that a machine never prints a zero, G prints :0: for that machine. If E detects that a machine does print a 0 (we assume, Turing doesn’t say) then G prints :: or just skips this entry, leaving the squares blank. We can see that a couple things can happen.
:G will print no 0’s, ever, if all the Mn’s print 0’s, OR,
:G will print ad infinitum 0’s if all the M’s print no 0’s, OR,
:G will print 0’s for a while and then stop.

Now, what happens when we apply E to G itself?
:If E(G) determines that G never prints a 0 then we know that all the Mn’s have printed 0’s. And this means that, because all the Mn came from M, that M itself prints 0’s ''ad infinitum'', OR
:If E(G) determines that G does print a 0 then we know that not all the Mn’s print 0’s; therefore M does not print 0’s ''ad infinitum''.

As we can apply the same process for determining if M prints 1 infinitely often. When we combine these processes, we can determine that M does, or does not, go on printing 1's and 0's ''ad infinitum''. Thus we have a method for determining if M is circle-free. By Proof 1 this is impossible. So the first assertion that E exists, is wrong: E does not exist.

===Summary of the third proof===
Here Turing proves "that the [[David Hilbert|Hilbert]] [[Entscheidungsproblem]] can have no solution" (''Undecidable'', p.&amp;nbsp;145). Here he
:“…show(s) that there can be no general process for determining whether a given formula U of the functional calculus K is provable.” (''ibid''.)

* Both Lemmas #1 and #2 are required to form the necessary "IF AND ONLY IF" (i.e. [[logical equivalence]]) required by the proof:

:"A set E is computably decidable if and only if both E and its complement are computably enumerable" (Frankél, p. 67)

;Summary of the proof

Turing demonstrates the existence of a formula '''Un'''(M) which says, in effect, that "in some complete configuration of M, '''0''' appears on the tape" (p.&amp;nbsp;146). This formula is TRUE, that is, it is "constructible", and he shows how to go about this.

Then Turing proves two Lemmas, the first requiring all the hard work. (The second is the converse of the first.) Then he uses ''reductio ad absurdum'' to prove his final result:

# There exists a formula '''Un'''(M). This formula is TRUE, AND
# If the ''Entscheidungsproblem'' can be solved THEN a mechanical process exists for determining whether '''Un'''(M) is ''provable'' (derivable), AND
# By Lemmas 1 and 2: '''Un'''(M) is ''provable'' IF AND ONLY IF '''0''' appears in some "complete configuration" of M, AND
# IF '''0''' appears in some "complete configuration" of M THEN a mechanical process exists that will determine whether arbitrary M ever prints '''0''', AND
# By Proof 2 no mechanical process exists that will determine whether arbitrary M ever prints '''0''', THEREFORE
# '''Un'''(M) is not '''provable''' (it is TRUE, but not ''provable'') which means that the ''Entscheidungsproblem'' is unsolvable.

;Discussion of the third proof

''If readers intend to study the proof in detail they should correct their copies of the pages of the third proof with the corrections that Turing supplied''.

To (even attempt to) follow the technical details, the reader will need to understand the definition of "provable" and be aware of important "clues".

"Provable" means, in the sense of Gödel, that (i) the axiom system itself is powerful enough to produce (express) the sentence "This sentence is provable", and (ii) that in any arbitrary "well-formed" proof the symbols lead by axioms, definitions, and substitution to the symbols of the conclusion.

First clue: "Let us put the description of M into the first standard form of §6". Section 6 describes the very specific "encoding" of machine M on the tape of a "universal machine" U. This requires the reader to know some idiosyncrasies of Turing's universal machine U and the encoding scheme.

(i) The universal machine is a set of "universal" instructions that reside in an "instruction table". Separate from this, on U's tape, a "computing machine" M will reside as "M-code". The universal table of instructions can print on the tape the symbols '''A, C, D, 0, 1, u, v, w, x, y, z, :''' . The various machines M can print these symbols only indirectly by commanding U to print them.

(ii) The "machine code" of M consists of only a few letters and the semicolon, i.e. '''D, C, A, R, L, N, ;''' . Nowhere within the "code" of M will the numerical "figures" (symbols) '''1''' and '''0''' ever appear. If M wants U to print a symbol from the collection '''blank, 0,  1''' then it uses one of the following codes to tell U to print them. To make things more confusing, Turing calls these symbols S0, S1, and S2, i.e.
:'''blank''' = S0 = '''D'''
:'''0''' = S1 = '''DC'''
:'''1''' = S2 = '''DCC'''

(iii) A "computing machine", whether it is built directly into a table (as his first examples show), or as machine-code M on universal-machine U's tape, prints its number on blank tape (to the right of M-code, if there is one) as '''1'''s and '''0'''s forever proceeding to the right.

(iv) If a "computing machine" is U+"M-code", then "M-code" appears first on the tape; the tape has a left end and the "M-code" starts there and proceeds to the right on alternate squares. When the M-code comes to an end (and it must, because of the assumption that these M-codes are finite algorithms), the "figures" will begin as '''1'''s and '''0'''s on alternate squares, proceeding to the right forever. Turing uses the (blank) alternate squares (called "E"- "eraseable"- squares) to help U+"M-code" keep track of where the calculations are, both in the M-code and in the "figures" that the machine is printing.

(v) A "complete configuration" is a printing of all symbols on the tape, including M-code [?] and "figures" up to that point, together with the figure currently being scanned (with a pointer-character printed to the left of the scanned symbol ?). If we have interpreted Turing's meaning correctly, this will be a hugely long set of symbols. But whether the entire M-code must be repeated is unclear; only a printing of the current M-code instruction is necessary plus the printing of all figures with a figure-marker).

(vi) Turing reduced the vast possible number of instructions in "M-code" (again: the code of M to appear on the tape) to a small canonical set, one of three similar to this: {qi Sj Sk R ql} e.g. ''If machine is executing instruction #qi and symbol Sj is on the square being scanned, then Print symbol Sk and go Right and then go to instruction ql'': The other instructions are similar, encoding for "Left" L and "No motion" N. It is this set that is encoded by the string of symbols qi = DA...A, Sj = DC...C, Sk = DC...C, R, ql = DA....A. Each instruction is separated from another one by the semicolon. For example, {q5, S1 S0 L q3} means: Instruction #5: If scanned symbol is '''0''' then print '''blank''', go Left, then go to instruction #3. It is encoded as follows
: ; D A A A A A D C D L D A A A

Second clue: Turing is using ideas introduced in Gödel's paper, that is, the "Gödelization" of (at least part of) the formula for '''Un'''(M). This clue appears only as a footnote on page 138 (''Undecidable''): "A sequence of r primes is denoted by [[Exponentiation|^]](r)" (''ibid''.) [Here, r inside parentheses is "raised".] This "sequence of primes" appears in a formula called F^(n).

Third clue: This reinforces the second clue. Turing's original attempt at the proof uses the expression
:(Eu)N(u) &amp; (x)( ... etc. ...) (''Undecidable'', p. 146)
Earlier in the paper Turing had previously used this expression (p.&amp;nbsp;138) and defined N(u) to mean "u is a non-negative integer" (''ibid''.) (i.e. a Gödel number). But, with the Bernays corrections, Turing abandoned this approach (i.e. the use of N(u)) and the only place where "the Gödel number" appears explicitly is where he uses F^(n).

What does this mean for the proof? The first clue means that a simple examination of the M-code on the tape will not reveal if a symbol '''0''' is ever printed by U+"M-code". A testing-machine might look for the appearance of '''DC''' in one of the strings of symbols that represent an instruction. But will this instruction ever be "executed?" Something has to "run the code" to find out. This something can be a machine, or it can be lines in a formal proof, i.e. Lemma #1.

The second and third clues mean that, as its foundation is Gödel's paper,  the proof is difficult.

===Details of the third proof===
* In the example below we will actually construct a simple "theorem"—a little [[Post–Turing machine]] program "run it". We will see just how mechanical a properly designed theorem can be. A proof, we will see, is just that, a "test" of the theorem that we do by inserting a "proof example" into the beginning and see what pops out at the end.
* Both Lemmas #1 and #2 are required to form the necessary "IF AND ONLY IF" (i.e. logical equivalence) required by the proof:

:"A set E is computably decidable if and only if both E and its complement are computably enumerable" (Frankél, p. 67)

* To quote Frankel:
:"A sentence A is said to be decidable in a [[formal system]] S if either A or its negation is provable in S" (Frankél, p. 65)

Frankel has defined "provable" earlier in his book:
:"A formal system is a system of ''axioms'' (expressed in some formally defined language) and ''rules of reasoning'' (also called inference rules), used to derive the ''theorems'' of the system. A ''theorem'' is any statement in the language of the system obtainable by a series of applications of the rules of reasoning, starting from the axioms. A ''proof'' is a finite sequence of such applications, leading to a theorem as its conclusion" (ibid p. 17).

Thus a "sentence" is a string of symbols, and a theorem is a string of strings of symbols.

Turing is confronted with the following tasks:
* to convert a [[Universal Turing machine]] "program", and the numerical symbols on the tape (Turing's "figures", symbols "1" and "0"), into a "theorem"—that is, a (monstrously long) ''string of sentences'' that define the successive actions of the machine, (all) the figures of the tape, and the location of the "tape head".

Thus the "string of sentences" will be strings of strings of symbols. The only allowed individual symbols will come from Godel's symbols defined in his paper.(In the following example we use the "&lt;" and "&gt;" around a "figure" to indicate that the "figure" is the symbol being scanned by the machine).

===An example of what "complete configuration" means===
In the following, we have to remind ourselves that every one of Turing's “computing machines” is a binary-number generator/creator that begins work on “blank tape”. Properly constructed, it always cranks away ad infinitum, but its instructions are always finite. In Turing's proofs, Turing's tape had a “left end” but extended right ad infinitum. For sake of example below we will assume that the “machine” is not a Universal machine, but rather the simpler “dedicated machine” with the instructions in the Table.

Our example is based on a ''modified'' [[Post–Turing machine]] model of a Turing Machine. This model prints only the symbols 0 and 1. The blank tape is considered to be all b's. Our modified model requires us to add two more instructions to the 7 Post–Turing instructions. The abbreviations that we will use are:
: R, RIGHT: look to the right and move tape to left, or move tape head right
: L, LEFT : look to the left and to move tape right, or move tape head left
: E, ERASE scanned square (e.g. make square blank)
: P0,: PRINT 0 in scanned square
: P1,: PRINT 1 in scanned square
: Jb_n, JUMP-IF-blank-to-instruction_#n,
: J0_n, JUMP-IF-0-to-instruction_#n,
: J1_n, JUMP-IF-1-to-instrucntion_#n,
: HALT.
In the cases of R, L, E, P0, and P1 after doing its task the machine continues on to the next instruction in numerical sequence; ditto for the jumps if their tests fail.

But, for brevity, our examples will only use three squares. And these will always start as there blanks with the scanned square on the left: i.e. bbb. With two symbols 1, 0 and blank we can have 27 distinct configurations:

: bbb, bb0, bb1, b0b, b00, b01, b1b, b10, b11, 0bb, 0b0, 0b1, 00b, 000, 001, 01b, 010, 011, 1bb, 1b0, 1b1, 10b, 100, 101, 11b, 110, 111

We must be careful here, because it is quite possible that an algorithm will (temporarily) leave blanks in between figures, then come back and fill something in. More likely, an algorithm may do this intentionally. In fact, Turing's machine does this—it prints on alternate squares, leaving blanks between figures so it can print locator symbols.

Turing always left alternate squares blank so his machine could place a symbol to the left of a figure (or a letter if the machine is the universal machine and the scanned square is actually in the “program”). In our little example we will forego this and just put symbols ( ) around the scanned symbol, as follows:

: b(b)0 this means, “Tape is blanks-to-the-left of left blank but left blank is “in play”, the scanned-square-is-blank, “0”, blanks-to-right”
: 1(0)1 this means, “Tape is blanks-to-the-left, then 1, scanned square is “0”

Let us write a simple program:
: start: P1, R, P1, R, P1, H

Remember that we always start with blank tape. The complete configuration prints the symbols on the tape followed by the next instruction:
: start config: (b) P1,
: config #1: (1) R,
: config #2: 1(b) P1,
: config #3: 1(1) R,
: config #4: 11(b) P1,
: config #5: 11(1) H

Let us add “jump” into the formula. When we do this we discover why the complete configuration must include the tape symbols. (Actually, we see this better, below.) This little program prints three “1”s to the right, reverses direction and moves left printing 0’s until it hits a blank. We will print all the symbols that our machine uses:
: start: P1, R, P1, R, P1, P0, L, J1_7, H
: (b)bb P1,
: (1)bb R,
: 1(b)b P1,
: 1(1)b R,
: 11(b) P1,
: 11(1) P0,
: 11(0) L,
: 1(1)0 J1_7
: 1(1)0 L
: (1)10 J0_7
: (1)10 L
: (b)110 J0_7
: (b)110 H
Here at the end we find that a blank on the left has “come into play” so we leave it as part of the total configuration.

Given that we have done our job correctly, we add the starting conditions and see “where the theorem goes”. The resulting configuration—the number 110—is the PROOF.

* Turing's first task had to write a generalized expression using logic symbols to express exactly what his Un(M) would do.
* Turing's second task is to "Godelize" this hugely long string-of-string-of-symbols using Godel's technique of assigning primes to the symbols and raising the primes to prime-powers, per Godel's method.

==Glossary of terms used by Turing==
1 '''computable number''' — a number whose decimal is computable by a machine, i.e. by finite means (e.g. an algorithm)

2 '''M''' — a machine with a finite instruction table and a scanning/printing head. M moves an infinite tape divided into squares each “capable of bearing a symbol”. The machine-instructions are only the following: move one square left, move one square right, on the scanned square print symbol p, erase the scanned square, if the symbol is p then do instruction aaa, if the scanned symbol is not p then do instruction aaa, if the scanned symbol is none then do instruction aaa, if the scanned symbol is any do instruction aaa [where “aaa” is an instruction-identifier].

3 '''computing machine''' — an M that prints two kinds of symbols, symbols of the first type are called “figures” and are only binary symbols 1 and 0; symbols of the second type are any other symbols.

4 '''figures''' — symbols '''1''' and '''0''', a.k.a. “symbols of the first kind”

5 '''m-configuration''' — the instruction-identifier, either a symbol in the instruction table, or a string of symbols representing the instruction- number on the tape of the universal machine (e.g. "DAAAAA = #5")

6 '''symbols of the second kind''' — any symbols other than '''1''' and '''0'''

7 '''circular''' — an unsuccessful computating machine. It fails to print, ad infinitum, the figures '''0''' or '''1''' that represent in binary the number it computes

8 '''circle-free''' — a successful computating machine. It prints, ad infinitum, the figures '''0''' or '''1''' that represent in binary the number it computes

9 '''sequence''' — as in “sequence computed by the machine”: symbols of the first kind a.k.a. figures a.k.a. symbols 0 and 1.

10  '''computable sequence''' — can be computed by a circle-free machine

11 '''S.D''' – Standard Description: a sequence of symbols A, C, D, L, R, N, “;” on a Turing machine tape

12 '''D.N''' — Description Number: an S.D converted to a number: 1=A, 2=C, 3 =D, 4=L, 5=R, 6=N, 7=;

13 '''M(n)''' — a machine whose D.N is number “n”

14 '''satisfactory''' — a S.D or D.N that represents a circle-free machine

15 '''U''' — a machine equipped with a “universal” table of instructions. If U is “supplied with a tape on the beginning of which is written the S.D of some computing machine M, U will compute the same sequence as M.”

16 '''β’'''—“beta-primed”: A so-called “diagonal number” made up of the n-th figure (i.e. 0 or 1) of the n-th computable sequence [also: the computable number of H, see below]

17 '''u''' — an unsatisfactory, i.e. circular, S.D

18 '''s''' — satisfactory, i.e. circle-free S.D

19 '''D''' — a machine contained in H (see below). When supplied with the S.D of any computing machine M, D will test M's S.D and if circular mark it with “u” and if circle-free mark it with “s”

20 '''H''' — a computing machine. H computes B’, maintains R and N. H contains D and U and an unspecified machine (or process) that maintains N and R and provides D with the equivalent S.D of N. E also computes the figures of B’ and assembles the figures of B’.

21 '''R''' — a record, or tally, of the quantity of successful (circle-free) S.D tested by D

22 '''N''' — a number, starting with 1, to be converted into an S.D by machine E. E maintains N.

23 '''K''' — a number. The D.N of H.

;Required for Proof #3

5 '''m-configuration''' — the instruction-identifier, either a symbol in the instruction table, or a string of symbols representing the instruction's number on the tape of the universal machine (e.g. "DAAAAA = instruction #5"). In Turing's S.D the m-configuration appears twice in each instruction, the left-most string is the "current instruction"; the right-most string is the next instruction.

24 '''complete configuration''' — the number (figure '''1''' or '''0''') of the scanned square, the complete sequence of all symbols on the tape, and the m-configuration (the instruction-identifier, either a symbol or a string of symbols representing a number, e.g. "instruction DAAAA = #5")

25 '''RSi(x, y)''' — "in the complete configuration x of M the symbol on square y is Si. "complete configuration" is definition #5,

26 '''I(x, y)''' — "in the complete configuration x of M the square y is scanned"

27 '''Kqm(x)''' — "in the complete configuration x of M the machine-configuration (instruction number) is qm"

28 '''F(x,y)''' — "y is the ''immediate'' successor of x" (follows Gödel's use of "f" as the successor-function).

29 '''G(x,y)''' — "x precedes y", not necessarily immediately

30 '''Inst{qi, Sj Sk L ql}''' is an abbreviation, as are Inst{qi, Sj Sk R ql}, and Inst{qi, Sj Sk N ql}. See below.

Turing reduces his instruction set to three “canonical forms” – one for Left, Right, and No-movement. Si and Sk are symbols on the tape.
: 		tape				Final
: m-config	Symbol	Operations	m-config
:  qi		Si		PSk, L		qm
:  qi		Si		PSk, R		qm
:  qi		Si		PSk, N		qm
For example, the operations in the first line are PSk = PRINT symbol Sk from the collection '''A, C, D, 0, 1, u, v, w, x, y, z, :''', then move tape LEFT.

These he further abbreviated as:
(N1)	qi Sj Sk L qm
(N2)	qi Sj Sk R qm
(N3)	qi Sj Sk N qm

In Proof #3 he calls the first of these “Inst{qi Sj Sk L ql}”, and he shows how to write the entire machine S.D  as the logical conjunction (logical OR): this string is called “Des(M)”, as in “Description-of-M”.
i.e. if the machine prints 0 then 1's and 0's on alternate squares to the right ad infinitum it might have the table (a similar example appears on page 119):
: q1, blank, P0, R, q2
: q2, blank, P-blank, R, q3
: q3, blank, P1, R, q4
: q4, blank, P-blank, R, q1
(This has been reduced to canonical form with the “p-blank” instructions so it differs a bit from Turing's example.)
If put them into the “ Inst( ) form” the instructions will be the following (remembering: S0 is blank, S1 = 0, S2 = 1):
: Inst {q1 S0 S1 R q2}
: Inst {q2 S0 S0 R q3}
: Inst {q3 S0 S2 R q4}
: Inst {q4 S0 S0 R q1}
The reduction to the Standard Description (S.D) will be:
: ; D A D D C R D A A ; D A A D D R D A A A ; D A A A D D C C R D A A A A ; D A A A A D D R D A ;
This agrees with his example in the book (there will be a blank between each letter and number). Universal machine U uses the alternate blank squares as places to put "pointers".

==References==
*  {{Citation | last= Turing | first= A.M. | publication-date = 1937 | year = 1936 | title = On Computable Numbers, with an Application to the Entscheidungsproblem | periodical = Proceedings of the London Mathematical Society | series = 2 | volume = 42 | issue= 1 | pages = 230–65 | doi= 10.1112/plms/s2-42.1.230 }} (and {{Citation | last = Turing | first = A.M. | publication-date = 1937 | title = On Computable Numbers, with an Application to the Entscheidungsproblem: A correction | periodical = Proceedings of the London Mathematical Society | series = 2 | volume = 43 | issue = 6 | pages = 544–6 | doi = 10.1112/plms/s2-43.6.544 | year = 1938 }}). ([http://www.turingarchive.org/browse.php/B/12 Online version].) This is the epochal paper where Turing defines [[Turing machine]]s, shows that the [[Entscheidungsproblem]] is unsolvable.
* [[Martin Davis]], ''The Undecidable, Basic Papers on Undecidable Propositions, Unsolvable Problems and Computable Functions'', Raven Press, New York, 1965. The two papers of Post referenced above are included in this volume. Other papers include those by Godel, Church, Rosser, and Kleene.
* [[Andrew Hodges]], ''[[Alan Turing: The Enigma]]'', [[Simon and Schuster]], New York. Cf. Chapter "The Spirit of Truth" for a history leading to, and a discussion of, his proof.
* [[Hans Reichenbach]], ''Elements of Symbolic Logic'', Dover Publications, Inc., New York, 1947.

[[Category:1937 in mathematics]]
[[Category:Theory of computation]]
[[Category:Mathematical logic]]
[[Category:Articles containing proofs]]
[[Category:Mathematical proofs]]
[[Category:Alan Turing]]</text>
      <sha1>ahzermbjxztgf8lpydjvr4xd0bcb34c</sha1>
    </revision>
  </page>
  <page>
    <title>Two ears theorem</title>
    <ns>0</ns>
    <id>48898634</id>
    <revision>
      <id>733403472</id>
      <parentid>708947653</parentid>
      <timestamp>2016-08-07T15:40:13Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* History and proof */Journal cites, Added 1 doi to a journal cite using [[Project:AWB|AWB]] (12066)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5224">[[File:Triangulation 3-coloring.svg|thumb|A triangulated polygon. The two vertices at the ends of the chain of triangles form ears. However, this polygon also has other ears that are not evident in this triangulation.]]
In [[geometry]], the '''two ears theorem''' states that every [[simple polygon]] with more than three vertices has at least two [[Ear (mathematics)|ears]], vertices that can be removed from the polygon without introducing any crossings. The two ears theorem is equivalent to the existence of [[polygon triangulation]]s. It is frequently attributed to Gary H. Meisters, but was proved earlier by [[Max Dehn]].

==Statement of the theorem==
An ear of a polygon is defined as a [[vertex (geometry)|vertex]] {{mvar|v}} such that the line segment between the two neighbors of {{mvar|v}} lies entirely in the interior of the polygon. The two ears theorem states that every simple polygon has at least two ears.

==Ears from triangulations==
An ear and its two neighbors form a [[triangle]] within the polygon that is not crossed by any other part of the polygon. Removing a triangle of this type produces a polygon with fewer sides, and repeatedly removing ears allows any simple polygon to be [[polygon triangulation|triangulated]].

Conversely, if a polygon is triangulated, the [[Dual graph|weak dual]] of the triangulation (a graph with one vertex per triangle and one edge per pair of adjacent triangles) will be a [[tree (mathematics)|tree]] and each leaf of the tree will form an ear. Since every tree with more than one vertex has at least two leaves, every triangulated polygon with more than one triangle has at least two ears. Thus, the two ears theorem is equivalent to the fact that every simple polygon has a triangulation.&lt;ref&gt;{{citation
 | last = O'Rourke | first = Joseph | authorlink = Joseph O'Rourke (professor)
 | isbn = 0-19-503965-3
 | mr = 921437
 | publisher = Oxford University Press
 | series = International Series of Monographs on Computer Science
 | title = Art Gallery Theorems and Algorithms
 | year = 1987}}.&lt;/ref&gt;

==Related types of vertex==
An ear is called ''exposed'' when it forms a vertex of the [[convex hull]] of the polygon. However, it is possible for a polygon to have no exposed ears.&lt;ref&gt;{{citation
 | last = Meisters | first = G. H.
 | doi = 10.2307/2321563
 | issue = 4
 | journal = [[American Mathematical Monthly]]
 | mr = 567710
 | pages = 284–285
 | title = Principal vertices, exposed points, and ears
 | volume = 87
 | year = 1980}}.&lt;/ref&gt;

Ears are a special case of a ''principal vertex'', a vertex such that the line segment connecting the vertex's neighbors does not cross the polygon or touch any other vertex of it. A principal vertex for which this line segment lies outside the polygon is called a ''mouth''. Analogously to the two ears theorem, every non-convex simple polygon has at least one mouth. Polygons with the minimum  number of principal vertices of both types, two ears and a mouth, are called [[anthropomorphic polygon]]s.&lt;ref&gt;{{citation
 | last = Toussaint | first = Godfried | authorlink = Godfried Toussaint
 | doi = 10.2307/2324033
 | issue = 1
 | journal = [[American Mathematical Monthly]]
 | mr = 1083611
 | pages = 31–35
 | title = Anthropomorphic polygons
 | volume = 98
 | year = 1991}}.&lt;/ref&gt;

==History and proof==
The two ears theorem is often attributed to a 1975 paper by Gary H. Meisters, from which the "ear" terminology originated.&lt;ref&gt;{{citation
 | last = Meisters | first = G. H.
 | journal = [[American Mathematical Monthly]]
 | mr = 0367792
 | pages = 648–651
 | title = Polygons have ears
 | volume = 82
 | year = 1975
 | doi=10.2307/2319703}}.&lt;/ref&gt; However, the theorem was proved earlier by [[Max Dehn]] (circa 1899) as part of a proof of the [[Jordan curve theorem]]. To prove the theorem, Dehn observes that every polygon has at least three convex vertices. If one of these vertices, {{mvar|v}}, is not an ear, then it can be connected by a diagonal to another vertex {{mvar|x}} inside the triangle {{mvar|uvw}} formed by {{mvar|v}} and its two neighbors; {{mvar|x}} can be chosen to be the vertex within this triangle that is farthest from line {{mvar|uw}}. This diagonal decomposes the polygon into two smaller polygons, and repeated decomposition by ears and diagonals eventually produces a triangulation of the whole polygon, from which an ear can be found as a leaf of the dual tree.&lt;ref&gt;{{citation
 | last = Guggenheimer | first = H. | authorlink = Heinrich Guggenheimer
 | doi = 10.1007/BF02464980
 | issue = 2
 | journal = [[Archive for History of Exact Sciences]]
 | jstor = 41133486
 | mr = 0532231
 | pages = 193–200
 | title = The Jordan curve theorem and an unpublished manuscript by Max Dehn
 | url = http://www.maths.ed.ac.uk/~aar/jordan/guggenheim.pdf
 | volume = 17
 | year = 1977}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://www.cut-the-knot.org/pigeonhole/PolygonalEars.shtml Meisters' Two Ears Theorem], [[Cut-the-Knot]]
*[http://cgm.cs.mcgill.ca/~godfried/teaching/cg-projects/97/Ian/twoears.html The Two-Ears Theorem], [[Godfried Toussaint]]
*{{mathworld|id=Two-EarsTheorem|title=Two-Ears Theorem}}

[[Category:Polygons]]
[[Category:Theorems in geometry]]</text>
      <sha1>c4p4s38lz5nu483fvatxdna89bru9wb</sha1>
    </revision>
  </page>
  <page>
    <title>Vivid designator</title>
    <ns>0</ns>
    <id>34608521</id>
    <revision>
      <id>842510234</id>
      <parentid>836250546</parentid>
      <timestamp>2018-05-22T22:41:38Z</timestamp>
      <contributor>
        <username>Biogeographist</username>
        <id>18201938</id>
      </contributor>
      <comment>removed inappropriate [[Category:Reference]], which is for the [[library]]-related meaning of [[reference]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1709">In [[modal logic]] and the [[philosophy of language]], a '''vivid designator''' is a term which is ''believed'' to designate the same thing in all [[possible world]]s&lt;ref name="quine"&gt;Quine, W.V.O., ''Quintessence: Reference and Modality'', 2004, pp. 356–357&lt;/ref&gt; and nothing else where such an object does not exist in a possible world. It is the analogue, in the sense of believing, of a [[rigid designator]],&lt;ref&gt;D. Kaplan, ''Quantifying In'', 1969&lt;/ref&gt; which ''is'' ([[Reference|refers to]]) the same in all possible worlds, rather than is just ''believed'' to be so.

== Willard Van Orman Quine ==
[[Willard Van Orman Quine]] credits [[David Kaplan (philosopher)|David Kaplan]] (who in turn [[Montgomery Furth]]) for the term "vivid designator" in his 1953 paper "Reference and Modality". He examines the separation between [[De dicto and de re|''de re'' and ''de dicto'']] and does away with ''de re'' statements, because ''de re'' statements can only work for names that are used [[Reference|referentially]].&lt;ref&gt;Andrea Bonomi, ''On Quine: Transparency and Specificity in Intentional Contexts'', 1995, p. 183.&lt;/ref&gt; In fact, both [[rigid designators]] and vivid designators are similarly dependent on context and empty otherwise.  The same is true of the whole [[Quantification (logic)|quantified]] [[modal logic]] of necessity because it collapses if [[essence]] is withdrawn.&lt;ref&gt;Quine, W.V.O., ''Quintessence: Reference and Modality'', 2004, pp. 356–357.&lt;/ref&gt;

== See also ==
*''[[Naming and Necessity]]''
*[[Rigid designator]]
*[[Non-rigid designator]]
*[[Scientific essentialism]]

== References ==
&lt;references/&gt;

[[Category:Modal logic]]
[[Category:Philosophy of language]]


{{ling-stub}}</text>
      <sha1>qh4ilyz0lylf3713h8b9r91ws9uqujt</sha1>
    </revision>
  </page>
  <page>
    <title>W. W. Rouse Ball</title>
    <ns>0</ns>
    <id>308290</id>
    <revision>
      <id>864540033</id>
      <parentid>847780343</parentid>
      <timestamp>2018-10-17T21:44:18Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>add IPAc-en</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5520">{{Use dmy dates|date=May 2012}}
{{Use British English|date=May 2012}}
{{Infobox scientist
| name = Walter William Rouse Ball
| image = wwrouseball.jpg
| birth_date = {{Birth date|1850|8|14|df=y}}
| birth_place = [[Hampstead]], [[London]], [[England]]
| residence = [[United Kingdom]]
| nationality = [[United Kingdom|British]]
| death_date = {{death date and age|1925|4|4|1850|8|14|df=y}}
| death_place = Elmside, [[Cambridge]], [[England]]
| field = [[Mathematician]]
| work_university = [[University of Cambridge]]
| alma_mater = [[University College London]]&lt;br /&gt;[[University of Cambridge]]
| doctoral_advisor =
| doctoral_students = [[Ernest Barnes]]
| known_for  = [[Tessellation]]s, [[magic squares]], [[history of mathematics]]
| prizes =[[Smith's Prize]] &lt;small&gt;(1874)&lt;/small&gt;
| religion =
| footnotes =
}}

'''Walter William Rouse Ball''', known as '''W. W. Rouse Ball''' ({{IPAc-en|r|aʊ|s}}; 14 August 1850&amp;nbsp;– 4 April 1925), was a [[United Kingdom|British]] [[mathematician]], lawyer, and fellow at [[Trinity College, Cambridge]] from 1878 to 1905. He was also a keen amateur magician, and the founding president of the Cambridge [[Pentacle Club]] in 1919, one of the world's oldest magic societies.&lt;ref&gt;http://geniimagazine.com/wiki/index.php?title=Pentacle_Club&amp;redirect=no&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Whittaker |first1=E.T. | author-link1 =E. T. Whittaker |date=October 1925 |title=Obituary: W. W. Rouse Ball |jstor=3604492 |journal=[[The Mathematical Gazette]] |volume=12 |issue=178 |pages=449–454 |doi= }}&lt;/ref&gt;

==Life==
Ball was the son and heir of Walter Frederick Ball, of 3, St John's Park Villas, South Hampstead, London. Educated at [[University College School]], he entered [[Trinity College, Cambridge]] in 1870, became a scholar and first [[Smith's Prize]]man, and gained his BA in 1874 as second [[Wrangler (University of Cambridge)|Wrangler]]. He became a Fellow of Trinity in 1875, and remained one for the rest of his life.&lt;ref&gt;{{acad|id=BL870WW|name=Ball, Walter William Rouse}}&lt;/ref&gt;

He is buried at the [[Ascension Parish Burial Ground, Cambridge|Parish of the Ascension Burial Ground]] in Cambridge.&lt;ref&gt;{{harvnb|Singmaster|2005}}, p. 658&lt;/ref&gt;

He is commemorated in the naming of the small pavilion, now used as changing rooms and toilets, on [[Jesus Green]] in Cambridge.

==Books==
*''A History of the Study of Mathematics at Cambridge''; [[Cambridge University Press]], 1889 (reissued by the publisher, 2009, {{ISBN|978-1-108-00207-3}})
{{gutenberg|no=31246 |name=A Short Account of the History of Mathematics}} (1st ed. 1888 and later editions). Dover 1960 republication of fourth edition: [http://www.gutenberg.org/files/31246/31246-pdf.pdf].
{{gutenberg|no=26839 |name=Mathematical Recreations and Essays}} (1st ed. 1892;&lt;ref&gt;{{cite journal|author=Oliver, J. E.|title=Review: ''Mathematical Recreations and Essays'' by W. W. Rouse Ball|journal=Bull. Amer. Math. Soc.|year=1892|volume=2|issue=3|pages=37–46|url=http://www.ams.org/journals/bull/1892-02-03/S0002-9904-1892-00105-X/S0002-9904-1892-00105-X.pdf|doi=10.1090/S0002-9904-1892-00105-X }}&lt;/ref&gt; later editions with [[H.S.M. Coxeter]])&lt;ref&gt;{{cite journal|author=Frame, J. S.|title=Review: ''Mathematical Recreations and Essays, 11th edition, by W. W. Rouse Ball; revised by H. S. M. Coxeter|journal=Bull. Amer. Math. Soc.|year=1940|volume=45|issue=3|pages=211–213|url=http://www.ams.org/journals/bull/1940-46-03/S0002-9904-1940-07170-8/S0002-9904-1940-07170-8.pdf|doi=10.1090/S0002-9904-1940-07170-8}}&lt;/ref&gt;
*''A History of the First Trinity Boat Club'' (1908)
{{gutenberg|no=54023 |name=Cambridge Papers}} (1st ed. 1918). Macmillan and Co., Limited 1918: [http://www.gutenberg.org/ebooks/54023].
*''String Figures''; Cambridge, W. Heffer &amp; Sons (1st ed. 1920, 2nd ed. 1921, 3rd ed. 1929, reprinted with supplements as ''Fun with String Figures'' by [[Dover Publications]], 1971, {{ISBN|0-486-22809-6}})

==See also==
*[[Rouse Ball Professor of Mathematics]]
*[[Rouse Ball Professor of English Law]]
*[[Martin Gardner]]: another author of recreational mathematics.

==Notes==
{{Reflist}}

==References==
*{{Citation
| last=Singmaster
| first=David
| chapter=1892 Walter William Rouse Ball, Mathematical recreations and problems of past and present times
| pages=653–663
| editor-last=Grattan-Guinness
| editor-first=I.
| title=Landmark Writings in Western Mathematics 1640-1940
| year=2005
| publisher=Elsevier
| isbn=978-0-444-50871-3
}}

==External links==
{{wikisource}}
{{Wikiquote}}
{{wikiquote|A Short Account of the History of Mathematics}}
* {{Gutenberg author | id=Ball,+W.+W.+Rouse+(Walter+William+Rouse)}}
* {{Internet Archive author |search=("Ball, W. W. Rouse" OR "W. W. Rouse Ball" OR "Walter William Rouse Ball" OR "Ball, Walter William Rouse")}}
* {{Librivox author |id=6113}}
* {{MacTutor Biography|id= Ball}}
* {{MathGenealogy |id=27230}}
* {{Find a Grave|5935598}}

{{Authority control}}

{{DEFAULTSORT:Rouse Ball, W. W.}}
[[Category:1850 births]]
[[Category:1925 deaths]]
[[Category:19th-century English mathematicians]]
[[Category:20th-century English mathematicians]]
[[Category:Historians of mathematics]]
[[Category:Recreational mathematicians]]
[[Category:Mathematics popularizers]]
[[Category:Alumni of University College London]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:Magic squares]]
[[Category:People educated at University College School]]
[[Category:Second Wranglers]]
[[Category:British magicians]]</text>
      <sha1>ncoan25u01uqes7umb00mz73go6srbu</sha1>
    </revision>
  </page>
  <page>
    <title>Wilson's model of information behavior</title>
    <ns>0</ns>
    <id>40882433</id>
    <revision>
      <id>805932752</id>
      <parentid>784819056</parentid>
      <timestamp>2017-10-18T15:34:46Z</timestamp>
      <contributor>
        <username>Dpleibovitz</username>
        <id>3747202</id>
      </contributor>
      <minor/>
      <comment>+hyperlink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7235">{{Underlinked|date=January 2014}}
{{primary sources|date=June 2017}}


'''Wilson's model of information seeking behaviour''' was born out of a need to focus the field of [[information and library science]] on human [[information seeking behavior|use of information]], rather than the use of information systems and sources.&lt;ref name="Wilson 2000"&gt;Wilson (2000)&lt;/ref&gt; Previous studies undertaken in the field were primarily concerned with systems, specifically, how an individual uses a system.&lt;ref name="Wilson 2000"/&gt; Very little had been written that examined an individual's information needs, or how information seeking behaviour related to other task-oriented behaviours.&lt;ref name="Wilson 2000"/&gt; [[Thomas D. Wilson]]'s first model had its origins in a presentation at the University of Maryland in 1971 when "an attempt was made to map the processes involved in what was known at the time as "user need research".&lt;ref name="Wilson 2005"&gt;Wilson (2005)&lt;/ref&gt;{{rp|31}}

==Wilson's first model==

Published in 1981, Wilson's first model outlined the factors leading to information seeking, and the barriers inhibiting action.&lt;ref name="Wilson 2005"/&gt; It stated that information-seeking was prompted by an individual's physiological, cognitive, or affective needs, which have their roots in personal factors, role demands, or environmental context.&lt;ref name="Wilson 2000"/&gt; In order to satisfy these needs, an individual makes demands upon a system by acting as an intermediary, or through the use of technology.&lt;ref name="Wilson 1981"&gt;Wilson (1981)&lt;/ref&gt; The information provided by the system is then evaluated to determine if it satisfies the individual's needs.&lt;ref name="Wilson 1981"/&gt; This first model was based on an understanding of human information seeking behaviors that are best understood as three interwoven frameworks: The user, the information system, and the information resource.&lt;ref name="Wilson 1981"/&gt;

===First revision in 1994===
Wilson later built upon his original model in order to understand the personal circumstance, social role, and environmental context in which an information need is created.&lt;ref name="Wilson 2005"/&gt; This new model, altered in 1994 incorporated Ellis' stages of information-seeking: starting, browsing, differentiating, monitoring, extracting, verifying and ending.&lt;ref&gt;Wilson (1994)&lt;/ref&gt; It also displayed the physiological, affective, and cognitive needs that give rise to information seeking behaviour.&lt;ref name="Wilson 2005"/&gt; The model recognized that an information need is not a need in and of itself, but rather one that stems from a previous psychological need. These needs are generated by the interplay of personal habits and political, economic, and technological factors in an individual's environmental.&lt;ref&gt;Wilson (1991)&lt;/ref&gt; The factors that drive needs can also obstruct an individual's search for information.

===Second revision in 1996===
In 1996 Wilson proposed a third model that built upon the previous two. This model incorporated several new elements that helped to demonstrate the stages experienced by the 'person in context', or searcher, when looking for information. These included an intermediate stage between the acknowledgement of a need and the initiation of action,&lt;ref name="Wilson 1997"&gt;Wilson (1997)&lt;/ref&gt; a redefining of the barriers he proposed in his second model as "intervening variables"&lt;ref name="Wilson 1999"&gt;Wilson (1999)&lt;/ref&gt; to show that factors can be supportive or preventative&lt;ref name="Wilson 1999"/&gt; a feedback loop, and an "activating mechanism" stage.&lt;ref name="Wilson 1997"/&gt; 'Activating mechanisms' identify relevant impetus that prompt a decision to seek information, and integrate behavioural theories such as 'stress/coping theory', 'risk/reward theory' and 'social learning theory'.

==Development of a general model==

In 1999, Wilson developed a general model that brought together different areas of research in the study of information behavior.&lt;ref name="Wilson 1999"/&gt;&lt;ref&gt;Bawden (2006)&lt;/ref&gt; The model represented research topics as a series of nested fields, with information behavior as the general area of investigation, information-seeking behavior as its sub-set, and information searching behavior as a further sub-set.&lt;ref name="Wilson 1999"/&gt;

==An evolving model==

Wilson's model has changed over time, and will continue to evolve as technology and the nature of information changes.&lt;ref name=Wilson/&gt; The model has been cited and discussed by leaders in the information science field, and can be integrated with other significant theories of information behaviour.&lt;ref name="Wilson 2005"/&gt;{{rp|35}} Wilson describes the model diagrams as elaborating on one another, saying "no one model stands alone and in using the model to guide the development of research ideas, it is necessary to examine and reflect upon all of the diagrams".&lt;ref name="Wilson 2005"/&gt;{{rp|35}}

Recently, there has been a shift from theorizing on research already conducted on information behaviour, to pursuing "research within specific theoretical contexts".&lt;ref name=Wilson/&gt; Wilson's Model is "aimed at linking theories to action";&lt;ref name="Wilson 2005"/&gt;{{rp|35}} however, it is this move from theory to action that is proving slow. Through numerous qualitative studies, "we now have many in depth investigations into the information seeking behavior of small samples of people".&lt;ref name=Wilson/&gt; Despite these studies, there have not been many links made between this research and changes in policy or practice.&lt;ref name=Wilson&gt;Wilson (2010)&lt;/ref&gt;

==Footnotes==
&lt;references /&gt;

==References==

&lt;!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. ---&gt;

*Bawden, D. (2006). Users, user studies and human information behaviour: a three decade perspective on Tom Wilson's "On user studies and information needs". ''Journal of Documentation'', 62(6), 671-179.
*Case, D. O. (2012). ''Looking for information: A survey of research on information seeking, needs, and behavior'' (3rd ed.). Bingley, UK: [[Emerald Group Publishing Limited]].
*Wilson, T. D. (1981). On user studies and information needs. ''[[Journal of Documentation]]'', 37(1), 3-15.
*Wilson, T. D. (1994). Information needs and uses: fifty years of progress? In B. C. Vickory (Ed.), ''Fifty years of information progress: A Journal of Documentation review'' (pp.&amp;nbsp;15–51). London: Aslib.
*Wilson, T. D. (1997). Information behaviour: an interdisciplinary perspective. ''[[Information Processing and Management]]'', 33(4), 551-572.
*Wilson, T. D. (1999). Models of information behaviour research. ''Journal of Documentation'', 55(3), 249-270.
*Wilson, T. D. (2000). Human information behavior. ''Informing Science'', 3(2), 49-55.
*Wilson, T. D. (2005). Evolution in information behaviour modeling: Wilson's model. In K. Fisher, S. Erdelez, &amp; L. McKechnie (Eds.), ''Theories of information behavior'' (pp.&amp;nbsp;31–39). Medford, New Jersey: Information Today.
*Wilson, T.D. (2010). Fifty Years of Information Behaviour Research. ''Bulletin'', 36(3), 27-34.

[[Category:Information theory]]</text>
      <sha1>n84ecdr0djhq4h5qbguv4wbr2aqmh15</sha1>
    </revision>
  </page>
</mediawiki>
