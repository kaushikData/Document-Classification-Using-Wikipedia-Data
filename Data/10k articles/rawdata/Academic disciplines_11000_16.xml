<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Automation</title>
    <ns>0</ns>
    <id>173354</id>
    <revision>
      <id>870447393</id>
      <parentid>870227457</parentid>
      <timestamp>2018-11-24T21:44:05Z</timestamp>
      <contributor>
        <ip>164.11.76.14</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="89449">{{About||a hierarchical presentation of automation topics|Outline of automation|other uses|Automation (disambiguation)}}
{{Distinguish|automaton}}
{{Use dmy dates|date=January 2018}}
{{Automation}}

'''Automation''' is the technology  by which a process  or procedure is performed with minimum human assistance.&lt;ref&gt;{{cite book
|title= Fundamentals of Modern Manufacturing: Materials, Processes, and Systems|last=Groover|first= Mikell|year=2014}}&lt;/ref&gt; Automation &lt;ref name="Rifkin 1995" /&gt; or automatic control is the use of various [[control system]]s for operating equipment such as machinery, processes in factories, boilers and heat treating ovens, switching on telephone networks, steering and stabilization of ships, aircraft and other applications and vehicles with minimal or reduced human intervention.  Some processes have been completely automated.

Automation covers applications ranging from a household [[thermostat]] controlling a boiler, to a large industrial control system with tens of thousands of input measurements and output control signals. In control complexity it can range from simple on-off control to multi-variable high level algorithms.

In the simplest type of an automatic [[control loop]], a [[Controller (control theory)|controller]] compares a measured value of a process with a desired set value, and processes the resulting error signal to change some input to the process, in such a way that the process stays at its set point despite disturbances. This closed-loop control is an application of negative feedback to a system. The mathematical basis of [[control theory]] was begun in the 18th century, and advanced rapidly in the 20th.

Automation has been achieved by various means including mechanical, [[Hydraulics|hydraulic]], [[Pneumatics|pneumatic]], electrical, electronic devices and [[computer]]s, usually in combination. Complicated systems, such as modern factories, [[airplane]]s and [[ship]]s typically use all these combined techniques. The benefit of automation include labor savings, savings in [[Electricity|electricity costs]], savings in material costs, and improvements to quality, accuracy and precision.

The [[World Bank]]'s [[World Development Report]] 2019 shows evidence that while automation displaces workers, innovation creates new industries and jobs.&lt;ref&gt;{{cite web|url=http://www.worldbank.org/en/publication/wdr2019|title=The Changing Nature of Work|access-date=8 October 2018}}&lt;/ref&gt;

The term ''automation'', inspired by the earlier word ''automatic'' (coming from ''[[automaton]]''), was not widely used before 1947, when Ford established an automation department.&lt;ref name="Rifkin 1995"&gt;{{cite book| author = Rifkin, Jeremy | title = The End of Work: The Decline of the Global Labor Force and the Dawn of the Post-Market Era | publisher = Putnam Publishing Group | year = 1995 | isbn = 0-87477-779-8|pages=66, 75}}&lt;/ref&gt; It was during this time that industry was rapidly adopting [[PID controller|feedback controllers]], which were introduced in the 1930s.&lt;ref&gt;{{cite book
|title=A History of Control Engineering 1930-1955
 |last=Bennett
 |first= S. 
|year=1993 |publisher =Peter Peregrinus Ltd. On behalf of the Institution of Electrical Engineers
|location= London
|isbn= 0-86341-280-7|pages=
| postscript = &lt;!--None--&gt;}}&lt;/ref&gt;

[[File:Control room pt tupper.jpg|thumb|Minimum human intervention is required to control many large facilities such as this electrical generating station.]]

==Open-loop and closed-loop (feedback) control==
Fundamentally, there are two types of control loop; open loop control, and closed loop [[feedback]] control.

In open loop control, the control action from the controller is independent of the "process output" (or "controlled process variable"). A good example of this is a central heating boiler controlled only by a timer, so that heat is applied for a constant time, regardless of the temperature of the building. (The control action is the switching on/off of the boiler. The process output is the building temperature).

In closed loop control, the control action from the controller is dependent on the process output. In the case of the boiler analogy this would include a thermostat to monitor the building temperature, and thereby feed back a signal to ensure the controller maintains the building at the temperature set on the thermostat. A closed loop controller therefore has a feedback loop which ensures the controller exerts a control action to give a process output the same as the "Reference input" or "set point". For this reason, closed loop controllers are also called feedback controllers.&lt;ref&gt;"Feedback and control systems" - JJ Di Steffano, AR Stubberud, IJ Williams. Schaums outline series, McGraw-Hill 1967&lt;/ref&gt;

The definition of a closed loop control system according to the British Standard Institution is 'a control system possessing monitoring feedback, the deviation signal formed as a result of this feedback being used to control the action of a final control element in such a way as to tend to reduce the deviation to zero.' &lt;ref name = mayr&gt;{{cite book|title= The Origins of Feedback Control|last=Mayr|first= Otto| author-link= Otto Mayr |year= 1970
|publisher =The Colonial Press, Inc.|location= Clinton, MA USA|isbn= |pages=|url=https://archive.org/details/TheOriginsOfFeedbackControlOttoMayr }}&lt;/ref&gt;

Likewise, a ''Feedback Control System'' is a system which tends to maintain a prescribed relationship of one system variable to another by comparing functions of these variables and using the difference as a means of control.&lt;ref name = mayr/&gt;
The advanced type of automation that revolutionized manufacturing, aircraft, communications and other industries, is feedback control, which is usually ''continuous'' and involves taking measurements using a [[sensor]] and making calculated adjustments to keep the measured variable within a set range.&lt;ref name="Bennett 1993"/&gt;&lt;ref&gt;Bennett, Stuart (1992). A history of control engineering, 1930-1955. IET. p. 48. {{ISBN|978-0-86341-299-8}}.&lt;/ref&gt; The theoretical basis of closed loop automation is [[control theory]].
[[File:Centrifugal flyball governor.jpg|thumb|right| A [[flyball governor]] is an early example of a feedback control system.  An increase in speed would make the counterweights move outward, sliding a linkage that tended to close the valve supplying steam, and so slowing the engine. ]]

==Control actions==
{{Main|Control system}}

=== Discrete control (on/off) ===
One of the simplest types of control is ''on-off'' control. An example is the thermostat used on household appliances which either opens or closes an electrical contact. (Thermostats were originally developed as true feedback-control mechanisms rather than the on-off common household appliance thermostat.)

Sequence control, in which a programmed sequence of ''discrete'' operations is performed, often based on system logic that involves system states. An elevator control system is an example of sequence control.

===PID controller===
[[File:PID en.svg|right|thumb|400x400px|A [[block diagram]] of a PID controller in a feedback loop, r(''t'') is the desired process value or "set point", and y(''t'') is the measured process value.]]
{{main |PID Controller}}
A '''proportional–integral–derivative controller''' ('''PID controller''') is a [[control loop]] [[feedback mechanism]] ([[controller (control theory)|controller]]) widely used in [[industrial control system]]s.

In a [[PID loop]], the controller continuously calculates an ''error value'' &lt;math&gt;e(t)&lt;/math&gt; as the difference between a desired [[Setpoint (control system)|setpoint]] and a measured [[process variable]] and applies a correction based on [[Proportional control|proportional]], [[integral]], and [[derivative]] terms, respectively (sometimes denoted ''P'', ''I'', and ''D'') which give their name to the controller type.

The theoretical understanding and application dates from the 1920s, and they are implemented in nearly all analogue control systems; originally in mechanical controllers, and then using discrete electronics and latterly in industrial process computers.

===Sequential control and logical sequence or system state control===
{{main| Programmable logic controller}}
Sequential control may be either to a fixed sequence or to a logical one that will perform different actions depending on various system states. An example of an adjustable but otherwise fixed sequence is a timer on a lawn sprinkler.
{|align=right
|-
! style="color:#black; background:#d3d3d3; font-size:100%; text-align:center;" colspan="2"|State Abstraction
|-
|[[Image:Finite state machine example with comments.svg|thumb|center|This state diagram shows how [[Unified modeling language|UML]] can be used for designing a door system that can only be opened and closed]]
|}
States refer to the various conditions that can occur in a use or sequence scenario of the system. An example is an elevator, which uses logic based on the system state to perform certain actions in response to its state and operator input. For example, if the operator presses the floor n button, the system will respond depending on whether the elevator is stopped or moving, going up or down, or if the door is open or closed, and other conditions.&lt;ref&gt;The elevator example is commonly used in programming texts, such as [[Unified modeling language]]&lt;/ref&gt;

An early development of sequential control was [[relay logic]], by which electrical relays engage electrical contacts which either start or interrupt power to a device. Relays were first used in telegraph networks before being developed for controlling other devices, such as when starting and stopping industrial-sized electric motors or opening and closing solenoid valves. Using relays for control purposes allowed event-driven control, where actions could be triggered out of sequence, in response to external events. These were more flexible in their response than the rigid single-sequence cam timers. More complicated examples involved maintaining safe sequences for devices such as swing bridge controls, where a lock bolt needed to be disengaged before the bridge could be moved, and the lock bolt could not be released until the safety gates had already been closed.

The total number of relays, cam timers and drum sequencers can number into the hundreds or even thousands in some factories. Early [[computer programming|programming]] techniques and languages were needed to make such systems manageable, one of the first being [[ladder logic]], where diagrams of the interconnected relays resembled the rungs of a ladder. Special computers called [[programmable logic controllers]] were later designed to replace these collections of hardware with a single, more easily re-programmed unit. 
  
In a typical hard wired motor start and stop circuit (called a ''control circuit'') a motor is started by pushing a "Start" or "Run" button that activates a pair of electrical relays. The "lock-in" relay locks in contacts that keep the control circuit energized when the push button is released. (The start button is a normally open contact and the stop button is normally closed contact.) Another relay energizes a switch that powers the device that throws the motor starter switch (three sets of contacts for three phase industrial power) in the main power circuit. Large motors use high voltage and experience high in-rush current, making speed important in making and breaking contact. This can be dangerous for personnel and property with manual switches. The "lock in" contacts in the start circuit and the main power contacts for the motor are held engaged by their respective electromagnets until a "stop" or "off" button is pressed, which de-energizes the lock in relay.&lt;ref&gt;{{cite web|url=http://www.exman.com/mshoass.html|title=MOTOR STARTERS START STOPS HAND OFF AUTO|publisher=}}&lt;/ref&gt;

Commonly [[interlock (engineering)|interlock]]s are added to a control circuit. Suppose that the motor in the example is powering machinery that has a critical need for lubrication. In this case an interlock could be added to insure that the oil pump is running before the motor starts. Timers, limit switches and electric eyes are other common elements in control circuits.

[[Solenoid valve]]s are widely used on compressed air or hydraulic fluid for powering [[actuator]]s on mechanical components. While motors are used to supply continuous rotary motion, actuators are typically a better choice for intermittently creating a limited range of movement for a mechanical component, such as moving various mechanical arms, opening or closing valves, raising heavy press rolls, applying pressure to presses.

===Computer control===
Computers can perform both sequential control and feedback control, and typically a single computer will do both in an industrial application. [[Programmable logic controller]]s (PLCs) are a type of special purpose microprocessor that replaced many hardware components such as timers and drum sequencers used in [[relay logic]] type systems. General purpose process control computers have increasingly replaced stand alone controllers, with a single computer able to perform the operations of hundreds of controllers. Process control computers can process data from a network of PLCs, instruments and controllers in order to implement typical (such as [[PID controller|PID]]) control of many individual variables or, in some cases, to implement complex control [[algorithm]]s using multiple inputs and mathematical manipulations. They can also analyze data and create real time graphical displays for operators and run reports for operators, engineers and management.

Control of an [[automated teller machine]] (ATM) is an example of an interactive process in which a computer will perform a logic derived response to a user selection based on information retrieved from a networked database. The ATM process has similarities with other online transaction processes. The different logical responses are called ''scenarios''. Such processes are typically designed with the aid of [[use case]]s and [[flowchart]]s, which guide the writing of the software code.The earliest feedback control mechanism was the water clock invented by Greek engineer Ctesibius (285–222 BC)

==History==

===Early history===

[[Image:Clepsydra-Diagram-Fancy.jpeg|thumb|180px|Ctesibius's clepsydra (3rd century BC).]]
It was a preoccupation of the Greeks and Arabs (in the period between about 300 BC and about 1200 AD) to keep accurate track of time. In [[Ptolemaic Egypt]], about 270 BC, [[Ctesibius]] described a float regulator for a [[water clock]], a device not unlike the ball and cock in a modern flush toilet. This was the earliest feedback controlled  mechanism.&lt;ref&gt;{{Cite journal|last=Guarnieri|first=M.|date=2010|title=The Roots of Automation Before Mechatronics|journal=IEEE Ind. Electron. M. |volume=4| issue=2| pages=42–43 |doi=10.1109/MIE.2010.936772 |ref=harv}}&lt;/ref&gt;  The appearance of the mechanical clock in the 14th century made the water clock and its feedback control system obsolete.

The [[History of Iran|Persian]] [[Banū Mūsā]] brothers, in their ''[[Book of Ingenious Devices]]'' (850 AD), described a number of automatic controls.&lt;ref name=Hassan&gt;[[Ahmad Y Hassan]], [http://www.history-science-technology.com/Articles/articles%2071.htm Transfer Of Islamic Technology To The West, Part II: Transmission Of Islamic Engineering] {{webarchive|url=https://web.archive.org/web/20080218171021/http://www.history-science-technology.com/Articles/articles%2071.htm |date=2008-02-18 }}&lt;/ref&gt; Two-step level controls for fluids, a form of discontinuous [[variable structure control]]s, was developed by the Banu Musa brothers.&lt;ref&gt;{{citation|title=Soft variable-structure controls: a survey|author=J. Adamy &amp; A. Flemming|journal=Automatica|volume=40|issue=11|date=November 2004|publisher=[[Elsevier]]|pages=1821–1844|doi=10.1016/j.automatica.2004.05.017}}&lt;/ref&gt; They also described a [[Control theory|feedback controller]].&lt;ref name=Mayr&gt;[[Otto Mayr]] (1970). ''The Origins of Feedback Control'', [[MIT Press]].&lt;/ref&gt;&lt;ref name=Hill&gt;[[Donald Routledge Hill]], "Mechanical Engineering in the Medieval Near East", ''Scientific American'', May 1991, p. 64-69.&lt;/ref&gt;

===Industrial Revolution in Europe===
The introduction of [[Engine|prime movers]], or self-driven machines advanced grain mills, furnaces, boilers, and the [[steam engine]] created a new requirement for automatic control systems including [[thermostat|temperature regulator]]s (invented in 1624 (see [[Cornelius Drebbel]])), [[pressure regulator]]s (1681), [[float regulator]]s (1700) and [[speed control]] devices. Another control mechanism was used to tent the sails of windmills. It was patented by Edmund Lee in 1745.&lt;ref name="Bennett 1979 pp"/&gt; Also in 1745, [[Jacques de Vaucanson]] invented the first automated loom. The design of feedback control systems up through the Industrial Revolution was by trial-and-error, together with a great deal of engineering intuition. Thus, it was more of an art than a science. In the mid-19th century mathematics was first used to analyze the stability of feedback control systems. Since mathematics is the formal language of automatic control theory, we could call the period before this time the prehistory of control theory.

In 1771 [[Richard Arkwright]] invented the first fully automated spinning mill driven by water power, known at the time as the [[water frame]].&lt;ref&gt;{{cite book|first=Tessie P.|last=Liu|title=The Weaver's Knot: The Contradictions of Class Struggle and Family Solidarity in Western France, 1750–1914|url=https://books.google.com/books?id=ZBcSaBxNP_4C&amp;pg=PA91|year=1994|publisher=Cornell University Press|isbn=0-8014-8019-1|pages=91–}}&lt;/ref&gt; An automatic flour mill was developed by [[Oliver Evans]] in 1785, making it the first completely automated industrial process.&lt;ref&gt;{{cite book|last=Jacobson|first=Howard B.|title=Automation and Society|year=1959|publisher=Philosophical Library|location=New York, NY|page=8|author2=Joseph S. Roueek}}&lt;/ref&gt;&lt;ref&gt;{{Hounshell1984}}&lt;/ref&gt;

[[File:Tower bridge steam engine.jpg|thumb|[[Steam engine]]s are a technology created during the 1700s used to promote automation.]]
The [[centrifugal governor]], which was invented by [[Christian Huygens]] in the seventeenth century, was used to adjust the gap between [[millstone]]s.&lt;ref&gt;{{cite web|url=http://www.princeton.edu/~hos/Mahoney/clarklec.html|title=Charting the Globe and Tracking the Heavens|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://books.google.com/books?id=iwbWCgAAQBAJ&amp;pg=PA36|title=Adaptive Control Processes: A Guided Tour|first=Richard E.|last=Bellman|date=8 December 2015|publisher=Princeton University Press}}&lt;/ref&gt;&lt;ref&gt;{{cite book
|title=A History of Control Engineering 1800–1930
 |last1=Bennett
 |first1= S.  
|year=1979 |publisher =Peter Peregrinus Ltd.
|location= London
|isbn= 0-86341-047-2|pages=47, 266
| postscript = &lt;!--None--&gt;}}
&lt;/ref&gt; Another centrifugal governor was used by a Mr. Bunce of England in 1784 as part of a model [[steam crane]].&lt;ref&gt;{{cite web|url=https://books.google.com/books?id=1DNWAAAAcAAJ&amp;pg=PA29-IA1|title=A course of lectures on the Steam Engine, delivered before the Members of the London Mechanics' Institution ... To which is subjoined, a copy of the rare ... work on Steam Navigation, originally published by J. Hulls in 1737. Illustrated by ... engravings|first=Charles Frederick|last=Partington|date=1 January 1826}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://books.google.com/books?id=-xJFAQAAMAAJ&amp;pg=PA296|title=Transactions of the Society Instituted at London for the Encouragement of Arts, Manufactures, and Commerce|first=Society for the Encouragement of Arts, Manufactures, and Commerce (Great|last=Britain)|date=1 January 1814}}&lt;/ref&gt; The centrifugal governor was adopted by James Watt for use on a steam engine in 1788 after Watt’s partner Boulton saw one at a flour mill [[Boulton &amp; Watt]] were building.&lt;ref name="Bennett 1979 pp"&gt;{{Harvnb|Bennett|1979|pp=}}&lt;/ref&gt;

The governor could not actually hold a set speed; the engine would assume a new constant speed in response to load changes. The governor was able to handle smaller variations such as those caused by fluctuating heat load to the boiler. Also, there was a tendency for oscillation whenever there was a speed change. As a consequence, engines equipped with this governor were not suitable for operations requiring constant speed, such as cotton spinning.&lt;ref name="Bennett 1979 pp"/&gt;

Several improvements to the governor, plus improvements to valve cut-off timing on the steam engine, made the engine suitable for most industrial uses before the end of the 19th century. Advances in the steam engine stayed well ahead of science, both thermodynamics and [[control theory]].&lt;ref name="Bennett 1979 pp"/&gt;

The governor received relatively little scientific attention until [[James Clerk Maxwell]] published a paper that established the beginning of a theoretical basis for understanding control theory. Development of the electronic amplifier during the 1920s, which was important for long distance telephony, required a higher signal to noise ratio, which was solved by negative feedback noise cancellation. This and other telephony applications contributed to control theory. In the 1940s and 1950s, German mathematician [[Irmgard Flugge-Lotz]] developed the theory of discontinuous automatic controls, which found military applications during the [[Second World War]] to [[fire control system]]s and aircraft [[navigation system]]s.&lt;ref name="Bennett 1993"&gt;{{Harvnb|Bennett|1993|pp=}}&lt;/ref&gt;

=== 20th century ===
[[Relay logic]] was introduced with factory [[electrification]], which underwent rapid adaption from 1900 though the 1920s. Central electric power stations were also undergoing rapid growth and operation of new high pressure boilers, steam turbines and electrical substations created a large demand for instruments and controls. Central control rooms became common in the 1920s, but as late as the early 1930s, most process control was on-off. Operators typically monitored charts drawn by recorders that plotted data from instruments. To make corrections, operators manually opened or closed valves or turned switches on or off. Control rooms also used color coded lights to send signals to workers in the plant to manually make certain changes.&lt;ref&gt;{{Harvnb|Bennett|1993|pp=31}}&lt;/ref&gt;

Controllers, which were able to make calculated changes in response to deviations from a set point rather than on-off control, began being introduced the 1930s. Controllers allowed manufacturing to continue showing productivity gains to offset the declining influence of factory electrification.&lt;ref name="Field_2011"&gt;
{{cite book
|title=A Great Leap Forward: 1930s Depression and U.S. Economic Growth
 |last=Field
 |first= Alexander J.
|year= 2011 |publisher =Yale University Press
|location= New Haven, London
|isbn=978-0-300-15109-1 |pages=
}}&lt;/ref&gt;

Factory productivity was greatly increased by electrification in the 1920s. U. S. manufacturing productivity growth fell from 5.2%/yr 1919-29 to 2.76%/yr 1929-41.  Alexander Field notes that spending on non-medical instruments increased significantly from 1929–33 and remained strong thereafter.&lt;ref name="Field_2011"/&gt;

The First and Second World Wars saw major advancements in the field of [[mass communication]] and [[signal processing]]. Other key advances in automatic controls include [[differential equation]]s, [[stability theory]] and [[system theory]] (1938), [[Frequency response|frequency domain analysis]] (1940), [[Motion control|ship control]] (1950), and [[stochastic analysis]] (1941).

Starting in 1958, various systems based on [[solid-state (electronics)|solid-state]]&lt;ref name="Wireless-World_1960"/&gt;&lt;ref name="MBLE_1962_Norbit"/&gt; [[digital electronics|digital logic]] modules for hard-wired programmed logic controllers (the predecessors of [[programmable logic controller]]s (PLC)) emerged to replace electro-mechanical relay logic in [[industrial control system]]s for [[process control]] and automation, including early [[Telefunken]]/[[AEG]] [[Logistat]], [[Siemens]] {{ill|Simatic|de}}, [[Philips]]/[[Mullard]]/{{ill|Valvo (company){{!}}Valvo|de|Valvo}} [[Norbit module|Norbit]], [[BBC]] [[Sigmatronic]], [[ACEC (company)|ACEC]] [[Logacec]], {{ill|Akkord-Radio{{!}}Akkord|de|Akkord-Radio}} [[Estacord]], Krone&lt;!-- AG --&gt; Mibakron, Bistat, Datapac, Norlog, SSR, or &lt;!-- ABB --&gt;Procontic systems.&lt;ref name="Wireless-World_1960"/&gt;&lt;ref name="Akkord_Estacord"/&gt;&lt;ref name="Klingelnberg_1967"/&gt;&lt;ref name="Parr_1993"/&gt;&lt;ref name="Weissel_1995"/&gt;&lt;ref name="Walker_2012"/&gt;

In 1959 Texaco's Port Arthur refinery became the first chemical plant to use [[digital control]].&lt;ref&gt;{{Harvnb|Rifkin|1995|pp=}}&lt;/ref&gt;
Conversion of factories to digital control began to spread rapidly in the 1970s as the price of computer hardware fell.

===Significant applications===
The automatic telephone switchboard was introduced in 1892 along with dial telephones.&lt;ref name="Jerome 1934"&gt;{{Cite book
 | last1 = Jerome
 | first1 = Harry
 | title = Mechanization in Industry, National Bureau of Economic Research
 | year = 1934
 | url = https://www.nber.org/chapters/c5238.pdf
 |page=158
 | postscript = &lt;!--None--&gt;}}&lt;/ref&gt; By 1929, 31.9% of the Bell system was automatic. Automatic telephone switching originally used vacuum tube amplifiers and electro-mechanical switches, which consumed a large amount of electricity. Call volume eventually grew so fast that it was feared the telephone system would consume all electricity production, prompting [[Bell Labs]] to begin research on the [[transistor]].&lt;ref&gt;{{cite book |title=A Century of Innovation: Twenty Engineering Achievements That Transformed Our Lives
|last=Constable |first=George
|authorlink= |author2=Somerville, Bob |year=1964 |publisher=Joseph Henry Press|location= |isbn= 0309089085 |pages= |url= }}&lt;/ref&gt;

The logic performed by telephone switching relays was the inspiration for the digital computer.
The first commercially successful glass bottle blowing machine was an automatic model introduced in 1905.&lt;ref&gt;{{ Cite web
 |title        = The American Society of Mechanical Engineers Designates the Owens "AR" Bottle Machine as an International Historic Engineering Landmark
 |year         = 1983
 |url          = https://www.asme.org/getmedia/a9e54878-05b1-4a91-a027-fe3b7e08699e/86-Owens-AR-Bottle-Machine.aspx
 |postscript   = &lt;!--None--&gt;
 |access-date  = 7 March 2017
 |archive-url  = https://web.archive.org/web/20171018180627/https://www.asme.org/getmedia/a9e54878-05b1-4a91-a027-fe3b7e08699e/86-Owens-AR-Bottle-Machine.aspx
 |archive-date = 18 October 2017
 |dead-url     = yes
 |df           = dmy-all
}}&lt;/ref&gt; The machine, operated by a two-man crew working 12-hour shifts, could produce 17,280 bottles in 24 hours, compared to 2,880 bottles made by a crew of six men and boys working in a shop for a day. The cost of making bottles by machine was 10 to 12 cents per gross compared to $1.80 per gross by the manual glassblowers and helpers.

Sectional electric drives were developed using control theory. Sectional electric drives are used on different sections of a machine where a precise differential must be maintained between the sections. In steel rolling, the metal elongates as it passes through pairs of rollers, which must run at successively faster speeds. In paper making the paper sheet shrinks as it passes around steam heated drying arranged in groups, which must run at successively slower speeds. The first application of a sectional electric drive was on a paper machine in 1919.&lt;ref&gt;{{Harvnb|Bennett|1993|pp=7}}&lt;/ref&gt; One of the most important developments in the steel industry during the 20th century was continuous wide strip rolling, developed by Armco in 1928.&lt;ref&gt;
{{cite book
|title=The Unbound Prometheus: Technological Change and Industrial Development in Western Europe from 1750 to the Present
 |last=Landes	
 |first= David.  S.
|year= 1969|publisher =Press Syndicate of the University of Cambridge
|location= Cambridge, New York
|isbn=  0-521-09418-6|pages=475
| postscript = &lt;!--None--&gt;}}
&lt;/ref&gt;
[[File:Automated liquid oral dose.jpg|thumb|Automated pharmacology production]]
Before automation many chemicals were made in batches. In 1930, with the widespread use of instruments and the emerging use of controllers, the founder of Dow Chemical Co. was advocating [[continuous production]].&lt;ref&gt;{{Harvnb|Bennett|1993|pp=65}}Note 1&lt;/ref&gt;

Self-acting machine tools that displaced hand dexterity so they could be operated by boys and unskilled laborers were developed by [[James Nasmyth]] in the 1840s.&lt;ref&gt;
{{cite book
|title=Science and Technology in the Industrial Revolution
 |last=Musson 
|author2=Robinson
|year=1969 |publisher =University of Toronto Press
|location= 
|isbn= |page=}}
&lt;/ref&gt; [[Machine tools]] were automated with [[Numerical control]] (NC) using punched paper tape in the 1950s. This soon evolved into computerized numerical control (CNC).

Today extensive automation is practiced in practically every type of manufacturing and assembly process. Some of the larger processes include electrical power generation, oil refining, chemicals, steel mills, plastics, cement plants, fertilizer plants, pulp and paper mills, automobile and truck assembly, aircraft production, glass manufacturing, natural gas separation plants, food and beverage processing, canning and bottling and manufacture of various kinds of parts. Robots are especially useful in hazardous applications like automobile spray painting. Robots are also used to assemble electronic circuit boards. Automotive welding is done with robots and automatic welders are used in applications like pipelines.

===Space/computer age===

With the advent of the space age in 1957, controls design, particularly in the United States, turned away from the frequency-domain techniques of classical control theory and backed into the differential equation techniques of the late 19th century, which were couched in the time domain. During the 1940s and 1950s, German mathematician [[Irmgard Flugge-Lotz]] developed the theory of discontinuous automatic control, which became widely used in [[bang-bang control|hysteresis control systems]] such as [[navigation system]]s, [[fire-control system]]s, and [[electronics]]. Through Flugge-Lotz and others, the modern era saw time-domain design for [[nonlinear systems]] (1961), [[navigation]] (1960), [[optimal control]] and [[estimation theory]] (1962), [[nonlinear control theory]] (1969), [[digital control]] and [[Filtration (mathematics)|filtering theory]] (1974), and the [[personal computer]] (1983).

== Advantages and disadvantages ==

Perhaps the most cited advantage of automation in industry is that it is associated with faster production and cheaper labor costs. Another benefit could be that it replaces hard, physical, or monotonous work.&lt;ref&gt;{{Cite book|title = Industrial Automation: Hands on|last = Lamb|first = Frank|publisher = |year = 2013|isbn = |location = |pages = 1–4}}&lt;/ref&gt; Additionally, tasks that take place in hazardous environments or that are otherwise beyond human capabilities can be done by machines, as machines can operate even under extreme temperatures or in atmospheres that are radioactive or toxic. They can also be maintained with simple quality checks. However, at the time being, not all tasks can be automated, and some tasks are more expensive to automate than others. Initial costs of installing the machinery in factory settings are high, and failure to maintain a system could result in the loss of the product itself. Moreover, some studies seem to indicate that industrial automation could impose ill effects beyond operational concerns, including worker displacement due to systemic loss of employment and compounded environmental damage; however, these findings are both convoluted and controversial in nature, and could potentially be circumvented.&lt;ref&gt;{{Cite_news|url=https://search.proquest.com/docview/1790436902?pq-origsite=gscholar|title=The Risk of Automation for Jobs in OECD Countries: A COMPARATIVE ANALYSIS|last=Arnzt|first=Melanie|date=14 May 2016}}&lt;/ref&gt;

The main advantages of automation are:
*Increased throughput or productivity.
*Improved quality or increased predictability of quality.
*Improved robustness (consistency), of processes or product.
*Increased consistency of output.
*Reduced direct human labor costs and expenses.
*Installation in operations reduces cycle time. 
*Can complete tasks where a high degree of accuracy is required.
*Replaces human operators in tasks that involve hard physical or monotonous work (e.g., using one forklift with a single driver instead of a team of multiple workers to lift a heavy object)&lt;ref&gt;[http://www.bma-automation.com/Prozessautomatisierung.2102.0.html?id=2102&amp;L=1 Process automation, retrieved on 20.02.2010] {{webarchive |url=https://web.archive.org/web/20130517174600/http://www.bma-automation.com/Prozessautomatisierung.2102.0.html?id=2102&amp;L=1 |date=17 May 2013 }}&lt;/ref&gt;
*Reduces some occupational injuries (e.g., fewer strained backs from lifting heavy objects)
*Replaces humans in tasks done in dangerous environments (i.e. fire, space, volcanoes, nuclear facilities, underwater, etc.)
*Performs tasks that are beyond human capabilities of size, weight, speed, endurance, etc.
*Reduces operation time and work handling time significantly.
*Frees up workers to take on other roles.
*Provides higher level jobs in the development, deployment, maintenance and running of the automated processes.

The main disadvantages of automation are:

*Possible security threats/vulnerability due to increased relative susceptibility for committing errors.
*Unpredictable or excessive development costs.
*High initial cost.
*Displaces workers due to job replacement.
*Leads to further environmental damage and could compound climate change.&lt;ref&gt;{{cite book|author1=Rainer Walz|author2=Joachim Schleich|title=The Economics of Climate Change Policies: Macroeconomic Effects, Structural Adjustments and Technological Change|url=https://books.google.com/books?id=3ai2XlE2qRwC&amp;pg=PA157|date=September 27, 2008|publisher=Springer Science &amp; Business Media|isbn=978-3-7908-2078-2|page=157}}&lt;/ref&gt;

==Societal impact==
{{Original research section|date=March 2018}}

Increased automation can often cause workers to feel anxious about losing their jobs as technology renders their skills or experience unnecessary. Early in the [[Industrial Revolution]], when inventions like the [[steam engine]] were making some job categories expendable, workers forcefully resisted these changes. [[Luddites]], for instance, were English textile workers who protested the introduction of weaving machines by destroying them.&lt;ref&gt;{{cite web|url=https://www.britannica.com/event/Luddite|title=Luddite|website=Encyclopedia Britannica|access-date=28 December 2017}}&lt;/ref&gt; Similar movements have sprung up periodically ever since. For most of the nineteenth and twentieth centuries, the most influential of these movements were led by [[organized labor]], which advocated for the retraining of workers whose jobs were rendered redundant by machines.

Currently, the relative anxiety about automation reflected in opinion polls seems to correlate closely with the strength of organized labor in that region or nation. For example, while a recent study by the [[Pew Research Center]] indicated that 72% of Americans are worried about increasing automation in the workplace, 80% of Swedes see automation and [[artificial intelligence]] as a good thing, due to the country’s still-powerful unions and a more robust national safety net.&lt;ref&gt;{{cite news|url=https://www.nytimes.com/2017/12/27/business/the-robots-are-coming-and-sweden-is-fine.html?hp&amp;action=click&amp;pgtype=Homepage&amp;clickSource=story-heading&amp;module=photo-spot-region&amp;region=top-news&amp;WT.nav=top-news|title=The Robots are Coming, and Sweden is Fine|last=Goodman|first=Peter S.|work=The New York Times|date=27 December 2017|access-date=28 December 2017}}&lt;/ref&gt;

Automation is already contributing significantly to unemployment, particularly in nations where the government does not proactively seek to diminish its impact. In the United States, 47% of all current jobs have the potential to be fully automated by 2033, according to the research of experts [[Carl Frey|Carl Benedikt Frey]] and Michael Osborne. Furthermore, wages and educational attainment appear to be strongly negatively correlated with an occupation’s risk of being automated.&lt;ref&gt;{{cite news|url=http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf|title=THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION?|last=Frey|first=C. B.|last2=Osborne|first2=M.A.|date=17 September 2013|access-date=1 March 2017}}
&lt;/ref&gt; Prospects are particularly bleak for occupations that do not presently require a university degree, such as truck driving.&lt;ref&gt;{{cite web|url= https://www.rollingstone.com/politics/features/death-of-the-american-trucker-w514802 |title=Death of the American Trucker}}&lt;/ref&gt; Even in high-tech corridors like [[Silicon Valley]], concern is spreading about a future in which a sizable percentage of adults have little chance of sustaining gainful employment.&lt;ref&gt;{{cite web|url= https://mashable.com/2017/08/06/silicon-valley-automation-apocalypse-jamie-bartlett/#raCswumsKsqa |title=Silicon Valley luminaries are busily preparing for when robots take over}}&lt;/ref&gt; As the example of Sweden suggests, however, the transition to a more automated future need not inspire panic, if there is sufficient political will to promote the retraining of workers whose positions are being rendered obsolete.

==Lights out manufacturing==

{{Main|Lights out (manufacturing)}}
Lights out manufacturing is a production system with no human workers, to eliminate labor costs.

Lights Out Manufacturing grew in popularity in the U.S. when General Motors in 1982 implemented humans “hands-off” manufacturing in order to “replace risk-averse bureaucracy with automation and robots”. However, the factory never reached full “lights out” status.&lt;ref name="RCR Wireless News"&gt;{{Cite news|url=https://www.rcrwireless.com/20160810/internet-of-things/lights-out-manufacturing-tag31-tag99|title=Lights out manufacturing and its impact on society|date=2016-08-10|work=RCR Wireless News|access-date=2018-02-28|language=en-US}}&lt;/ref&gt;

The expansion of Lights Out Manufacturing requires:&lt;ref&gt;{{Cite news|url=https://cnc-machine-tools.com/checklist-for-lights-out-manufacturing/|title=Checklist for Lights-Out Manufacturing|date=2017-09-04|work=CNC machine tools|access-date=2018-02-28|language=en-US}}&lt;/ref&gt;
* Reliability of equipment
* Long term mechanic capabilities
* Planned preventative maintenance
* Commitment from the staff

==Health and environment==
{{Original research section|date=March 2018}}

The costs of automation to the environment are different depending on the technology, product or engine automated. There are automated engines that consume more energy resources from the Earth in comparison with previous engines and vice versa.{{citation needed|date=October 2013}} Hazardous operations, such as [[oil refining]], the manufacturing of [[Chemical industry|industrial chemicals]], and all forms of [[metal working]], were always early contenders for automation.{{dubious|date=October 2013}}{{citation needed|date=October 2013}}

The automation of vehicles could prove to have a substantial impact on the environment, although the nature of this impact could be beneficial or harmful depending on several factors. Because [[automated vehicle]]s are much less likely to get into accidents compared to human-driven vehicles, some precautions built into current models (such as [[anti-lock brake]]s or [[laminated glass]]) would not be required for self-driving versions. Removing these safety features would also significantly reduce the weight of the vehicle, thus increasing [[fuel economy in automobiles|fuel economy]] and reducing emissions per mile. Self-driving vehicles are also more precise with regard to acceleration and breaking, and this could contribute to reduced emissions. Self-driving cars could also potentially utilize fuel-efficient features such as route mapping that is able to calculate and take the most efficient routes. Despite this potential to reduce emissions, some researchers theorize that an increase of production of self-driving cars could lead to a boom of vehicle ownership and use. This boom could potentially negate any environmental benefits of self-driving cars if a large enough number of people begin driving personal vehicles more frequently.&lt;ref&gt;{{cite web|url=http://time.com/4476614/self-driving-cars-environment/ |title=Self-Driving Cars Could Help Save the Environment—Or Ruin It. It Depends on Us|publisher=}}&lt;/ref&gt;

Automation of homes and home appliances is also thought to impact the environment, but the benefits of these features are also questioned. A study of energy consumption of automated homes in Finland showed that [[smart home]]s could reduce energy consumption by monitoring levels of consumption in different areas of the home and adjusting consumption to reduce energy leaks (such as automatically reducing consumption during the nighttime when activity is low). This study, along with others, indicated that the smart home’s ability to monitor and adjust consumption levels would reduce unnecessary energy usage. However, new research suggests that smart homes might not be as efficient as non-automated homes. A more recent study has indicated that, while monitoring and adjusting consumption levels does decrease unnecessary energy use, this process requires monitoring systems that also consume a significant amount of energy. This study suggested that the energy required to run these systems is so much so that it negates any benefits of the systems themselves, resulting in little to no ecological benefit.&lt;ref&gt;{{cite journal |url=https://www.sciencedirect.com/science/article/pii/S2405896315001597 |title=Environmental Impacts and Benefits of Smart Home Automation: Life Cycle Assessment of Home Energy Management System|journal=IFAC-Papers ''On'' ''Line''|volume=48|pages=880|doi=10.1016/j.ifacol.2015.05.158|year=2015|last1=Louis|first1=Jean-Nicolas|last2=Calo|first2=Antonio|last3=Leiviskä|first3=Kauko|last4=Pongrácz|first4=Eva}}&lt;/ref&gt;

==Convertibility and [[turnaround time]]==

Another major shift in automation is the increased demand for flexibility and convertibility in manufacturing processes. Manufacturers are increasingly demanding the ability to easily switch from manufacturing Product A to manufacturing Product B without having to completely rebuild the [[production line]]s. Flexibility and distributed processes have led to the introduction of [[Automated Guided Vehicle]]s with Natural Features Navigation.

Digital electronics helped too. Former analogue-based instrumentation was replaced by digital equivalents which can be more accurate and flexible, and offer greater scope for more sophisticated configuration, parametrization and operation. This was accompanied by the [[fieldbus]] revolution which provided a networked (i.e. a single cable) means of communicating between control systems and field level instrumentation, eliminating hard-wiring.

[[Discrete manufacturing]] plants adopted these technologies fast. The more conservative process industries with their longer plant life cycles have been slower to adopt and analogue-based measurement and control still dominates. The growing use of [[Industrial Ethernet]] on the factory floor is pushing these trends still further, enabling manufacturing plants to be integrated more tightly within the enterprise, via the internet if necessary. Global competition has also increased demand for [[Reconfigurable Manufacturing System]]s.

==Automation tools==
Engineers can now have [[numerical control]] over automated devices. The result has been a rapidly expanding range of applications and human activities. [[Computer-aided technologies]] (or CAx) now serve as the basis for mathematical and organizational tools used to create complex systems. Notable examples of CAx include [[Computer-aided design]] (CAD software) and [[Computer-aided manufacturing]] (CAM software). The improved design, analysis, and manufacture of products enabled by CAx has been beneficial for industry.&lt;ref&gt;{{cite journal |url=http://www.sciencedirect.com/science/article/pii/S0010448504000491 |title=Engineers' CAx education—it's not only CAD |journal=Computer-Aided Design |volume=36 |issue=14 |pages=1439 |doi=10.1016/j.cad.2004.02.011|year=2004 |last1=Werner Dankwort |first1=C |last2=Weidlich |first2=Roland |last3=Guenther |first3=Birgit |last4=Blaurock |first4=Joerg E }}&lt;/ref&gt;

[[Information technology]], together with [[industry|industrial]] [[machinery]] and [[industrial process|process]]es, can assist in the design, implementation, and monitoring of control systems. One example of an [[industrial control systems|industrial control system]] is a [[programmable logic controller]] (PLC). PLCs are specialized hardened computers which are frequently used to synchronize the flow of inputs from (physical) [[sensor]]s and events with the flow of outputs to actuators and events.&lt;ref name="Reference.com"&gt;
{{cite web|url=http://dictionary.reference.com/browse/Automation|title=Automation - Definitions from Dictionary.com|publisher=dictionary.reference.com|accessdate=2008-04-22| archiveurl= https://web.archive.org/web/20080429002933/http://dictionary.reference.com/browse/automation| archivedate= 29 April 2008 | deadurl= no}}&lt;/ref&gt;

[[File:Automated online assistant.png|thumb|An [[automated online assistant]] on a website, with an [[avatar (computing)|avatar]] for enhanced [[human–computer interaction]].]]
[[Human-computer interaction|Human-machine interface]]s (HMI) or [[Human–computer interaction|computer human interfaces]] (CHI), formerly known as ''man-machine interfaces'', are usually employed to communicate with PLCs and other computers. Service personnel who monitor and control through HMIs can be called by different names. In industrial process and manufacturing environments, they are called operators or something similar. In boiler houses and central utilities departments they are called stationary engineers.&lt;ref&gt;{{cite web|url=http://www.bls.gov/oco/ocos228.htm|title=Stationary Engineers and Boiler Operators&lt;!-- Bot generated title --&gt;|publisher=}}&lt;/ref&gt;

Different types of automation tools exist:
* ANN – [[Artificial Neural Network]]
* DCS – [[Distributed Control System]]
* HMI – [[Human Machine Interface]]
* SCADA – [[Supervisory Control and Data Acquisition]]
* PLC – [[Programmable Logic Controller]]
* [[Instrumentation]]
* [[Motion control]]
* [[Robotics]]

When it comes to factory automation, Host Simulation Software (HSS) is a commonly used testing tool that is used to test the equipment software. HSS is used to test equipment performance with respect to Factory Automation standards (timeouts, response time, processing time).&lt;ref&gt;http://www.hcltech.com/sites/default/files/effective_host_simulation.pdf&lt;/ref&gt;

===Limitations to automation===
*Current technology is unable to automate all the desired tasks.
*Many operations using automation have large amounts of invested capital and produce high volumes of product, making malfunctions extremely costly and potentially hazardous. Therefore, some personnel are needed to ensure that the entire system functions properly and that safety and product quality are maintained.
*As a process becomes increasingly automated, there is less and less labor to be saved or quality improvement to be gained. This is an example of both [[diminishing returns]] and the [[logistic function]].
*As more and more processes become automated, there are fewer remaining non-automated processes. This is an example of exhaustion of opportunities. New technological paradigms may however set new limits that surpass the previous limits.

===Current limitations===
Many roles for humans in industrial processes presently lie beyond the scope of automation. Human-level [[pattern recognition]], [[language comprehension]], and language production ability are well beyond the capabilities of modern mechanical and computer systems (but see [[Watson (computer)]]). Tasks requiring subjective assessment or synthesis of complex sensory data, such as scents and sounds, as well as high-level tasks such as strategic planning, currently require human expertise. In many cases, the use of humans is more cost-effective than mechanical approaches even where automation of industrial tasks is possible. Overcoming these obstacles is a theorized path to [[post-scarcity]] economics.

==== Paradox of automation ====

The [[paradox]] of automation says that the more efficient the automated system, the more crucial the human contribution of the operators. Humans are less involved, but their involvement becomes more critical.

If an automated system has an error, it will multiply that error until it’s fixed or shut down. This is where human operators come in.&lt;ref&gt;{{cite web|url=http://personalmba.com/paradox-of-automation/|title=Paradox of Automation – The Personal MBA|first=Josh|last=Kaufman|publisher=}}&lt;/ref&gt;

A fatal example of this was [[Air France Flight 447]], where a failure of automation put the pilots into a manual situation they were not prepared for.&lt;ref&gt;{{cite web|url=http://99percentinvisible.org/episode/children-of-the-magenta-automation-paradox-pt-1/|title=Children of the Magenta (Automation Paradox, pt. 1) – 99% Invisible|publisher=}}&lt;/ref&gt;

== Cognitive automation ==
Cognitive automation, as a subset of [[artificial intelligence]],&lt;ref&gt;{{Cite journal|last=Guhathakurta|first=Rahul|date=|year=2018|title=Cognitive Automation — Going beyond Rule-based RPA|url=https://www.indrastra.com/2018/09/Cognitive-Automation-004-09-2018-0006.html|journal=IndraStra Global|publication-place=New York|volume=004|pages=0006|issn=2381-3652|via=}}&lt;/ref&gt; is an emerging genus of automation enabled by [[cognitive computing]]. Its primary concern is the automation of clerical tasks and workflows that consist of structuring [[unstructured data]].&lt;ref&gt;{{Cite web|url=http://thesiliconreview.com/magazines/automate-complex-workflows-using-tactical-cognitive-computing-coseer/|title=Automate Complex Workflows Using Tactical Cognitive Computing: Coseer|website=thesiliconreview.com|access-date=2017-07-30}}&lt;/ref&gt;

Cognitive automation relies on multiple disciplines: natural language processing, real-time computing, machine learning algorithms, big data analytics and evidence-based learning. According to [[Deloitte]], cognitive automation enables the replication of human tasks and judgment “at rapid speeds and considerable scale.”&lt;ref&gt;{{Cite web|url=https://www2.deloitte.com/us/en/pages/deloitte-analytics/articles/cognitive-automation.html|title=Cognitive automation: Streamlining knowledge processes {{!}} Deloitte US|website=Deloitte United States|language=en|access-date=2017-07-30}}&lt;/ref&gt;

Such tasks include:
* Document redaction
* Data extraction and document synthesis / reporting
* Contract management
* Natural language search
* Customer, employee, and stakeholder onboarding
* Manual activities and verifications
* Follow up and email communications

==Recent and emerging applications==
{{Main|Emerging technologies}}
[[File:Factory Automation Robotics Palettizing Bread.jpg|thumb|[[KUKA]] [[industrial robot]]s being used at a bakery for food production]]

===Automated retail===

'''Food and drink'''
{{Main|Automated restaurant}}
The food retail industry has started to apply automation to the ordering process; [[McDonald's]] has introduced touch screen ordering and payment systems in many of its restaurants, reducing the need for as many cashier employees.&lt;ref&gt;[https://web.archive.org/web/20130919201318/http://www.itbusiness.ca/blog/mcdonalds-automation-a-sign-of-declining-service-sector-employment/20398] &lt;/ref&gt; [[The University of Texas at Austin]] has introduced fully automated cafe retail locations.&lt;ref&gt;[http://singularityhub.com/2012/05/09/automation-comes-to-the-coffeehouse-with-robotic-baristas/ Automation Comes To The Coffeehouse With Robotic Baristas]. Singularity Hub. Retrieved on 2013-07-12.&lt;/ref&gt; Some Cafes and restaurants have utilized mobile and tablet "[[Mobile app|apps]]" to make the ordering process more efficient by customers ordering and paying on their device.&lt;ref&gt;[http://www.bighospitality.co.uk/Business/New-Pizza-Express-app-lets-diners-pay-bill-using-iPhone New Pizza Express app lets diners pay bill using iPhone]. Bighospitality.co.uk. Retrieved on 2013-07-12.&lt;/ref&gt; Some restaurants have automated food delivery to customers tables using a [[Conveyor belt sushi|Conveyor belt system]]. The use of [[robots]] is sometimes employed to replace [[waiting staff]].&lt;ref&gt;[https://techcrunch.com/2010/03/12/wheelie-toshibas-new-robot-is-cute-autonomous-and-maybe-even-useful-video/ Wheelie: Toshiba's new robot is cute, autonomous and maybe even useful (video)]. TechCrunch (12 March 2010). Retrieved on 2013-07-12.&lt;/ref&gt;

'''Stores'''
{{Main|Automated retail}}
Many [[supermarkets]] and even smaller stores are rapidly introducing [[Self checkout]] systems reducing the need for employing checkout workers. In the United States, the retail industry employs 15.9 million people as of 2017 (around 1 in 9 Americans in the workforce). Globally, an estimated 192 million workers could be affected by automation according to research by [[Eurasia Group]].&lt;ref name=":0"&gt;{{Cite web|url=https://www.economist.com/news/briefing/21721900-love-affair-shopping-has-gone-online-decline-established-american-retailing|title=The decline of established American retailing threatens jobs|website=The Economist|access-date=2017-05-28}}&lt;/ref&gt;

[[Online shopping]] could be considered a form of automated retail as the payment and checkout are through an automated [[Online transaction processing]] system, with the share of online retail accounting jumping from 5.1% in 2011 to 8.3% in 2016 {{Citation needed|date=September 2017}}. However, two-thirds of books, music and films are now purchased online. In addition, automation and online shopping could reduce demands for shopping malls, and retail property, which in America is currently estimated to account for 31% of all commercial property or around 7 billion square feet. Amazon has gained much of the growth in recent years for online shopping, accounting for half of the growth in online retail in 2016.&lt;ref name=":0" /&gt; Other forms of automation can also be an integral part of online shopping, for example the deployment of automated warehouse robotics such as that applied by [[Amazon.com|Amazon]] using [[Kiva Systems]].

===Automated mining===
{{main|Automated mining}} Automated mining involves the removal of human labor from the [[mining]] process.&lt;ref&gt;[http://www.theaustralian.com.au/business/mining-energy/rio-to-trial-automated-mining/story-e6frg9df-1111115351260 ''Rio to trial automated mining''] at The Australian&lt;/ref&gt; The [[Mining#Mining industry|mining industry]] is currently in the transition towards automation. Currently it can still require a large amount of [[human capital]], particularly in the [[third world]] where labor costs are low so there is less incentive for increasing efficiency through automation.

===Automated video surveillance===

The Defense Advanced Research Projects Agency ([[DARPA]]) started the research and development of automated visual [[surveillance]] and monitoring (VSAM) program, between 1997 and 1999, and airborne video surveillance (AVS) programs, from 1998 to 2002. Currently, there is a major effort underway in the vision community to develop a fully automated [[Space Tracking and Surveillance System|tracking surveillance]] system. Automated video surveillance monitors people and vehicles in real time within a busy environment. Existing automated surveillance systems are based on the environment they are primarily designed to observe, i.e., indoor, outdoor or airborne, the amount of sensors that the automated system can handle and the mobility of sensor, i.e., stationary camera vs. mobile camera. The purpose of a surveillance system is to record properties and trajectories of objects in a given area, generate warnings or notify designated authority in case of occurrence of particular events.&lt;ref&gt;Javed, O, &amp; Shah, M. (2008). [https://books.google.com/books?id=UVcVLjtst74C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Automated multi-camera surveillance]. City of Publication: Springer-Verlag New York Inc.&lt;/ref&gt;

===Automated highway systems===
{{main|Automated highway systems}}

As demands for safety and mobility have grown and technological possibilities have multiplied, interest in automation has grown. Seeking to accelerate the development and introduction of fully automated vehicles and highways, the [[United States Congress]] authorized more than $650 million over six years for [[intelligent transport system]]s (ITS) and demonstration projects in the 1991 [[Intermodal Surface Transportation Efficiency Act]] (ISTEA). Congress legislated in ISTEA that "the [[United States Secretary of Transportation|Secretary of Transportation]] shall develop an automated highway and vehicle prototype from which future fully automated intelligent vehicle-highway systems can be developed. Such development shall include research in human factors to ensure the success of the man-machine relationship. The goal of this program is to have the first fully automated highway roadway or an automated test track in operation by 1997. This system shall accommodate installation of equipment in new and existing motor vehicles." [ISTEA 1991, part B, Section 6054(b)].

Full automation commonly defined as requiring no control or very limited control by the driver; such automation would be accomplished through a combination of sensor, computer, and communications systems in vehicles and along the roadway. Fully automated driving would, in theory, allow closer vehicle spacing and higher speeds, which could enhance traffic capacity in places where additional road building is physically impossible, politically unacceptable, or prohibitively expensive. Automated controls also might enhance road safety by reducing the opportunity for driver error, which causes a large share of motor vehicle crashes. Other potential benefits include improved air quality (as a result of more-efficient traffic flows), increased fuel economy, and spin-off technologies generated during research and development related to automated highway systems.&lt;ref&gt;Menzies, Thomas. R. [https://books.google.com/books?id=pj4XHb_x1wYC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false National Automated Highway System Research Program A review]. 253. Washington D.C.: Transportation Research Board, 1998. 2–50.&lt;/ref&gt;

===Automated waste management===
[[File:Automated side loader operation.webm|thumb|Automated side loader operation]]
Automated waste collection trucks prevent the need for as many workers as well as easing the level of labor required to provide the service.&lt;ref&gt;Hepker, Aaron. (27 November 2012) [http://www.kcrg.com/news/local/Automated-Garbage-Trucks-Hitting-Cedar-Rapids-Streets-181070351.html Automated Garbage Trucks Hitting Cedar Rapids Streets | KCRG-TV9 | Cedar Rapids, Iowa News, Sports, and Weather | Local News] {{webarchive |url=https://web.archive.org/web/20130116072459/http://www.kcrg.com/news/local/Automated-Garbage-Trucks-Hitting-Cedar-Rapids-Streets-181070351.html |date=16 January 2013 }}. Kcrg.com. Retrieved on 2013-07-12.&lt;/ref&gt;

===Business process automation===
{{main article|Business process automation}}
Business process automation (BPA) is the technology-enabled automation of complex&lt;ref&gt;[https://www.gartner.com/it-glossary/bpa-business-process-automation https://www.gartner.com/it-glossary/bpa-business-process-automation] Published by Gartner&lt;/ref&gt; [[business process]]es. It can help to streamline a business for simplicity, achieve digital transformation, increase service quality, improve service delivery or contain costs. BPA consists of integrating applications, restructuring labor resources and using software applications throughout the organization. Robotic process automation is an emerging field within BPA and uses [[artificial intelligence]]. BPAs can be implemented in a number of business areas including [[marketing]],&lt;ref&gt;[https://www.smartsheet.com/understanding-evolution-and-importance-business-process-automation Understanding the Evolution and Importance of Business Process Automation] Published by smartsheet.com, retrieved August 13, 2018&lt;/ref&gt; [[sales]]&lt;ref&gt;[https://www.tebillion.com/en/blog/111-three-reasons-why-your-business-needs-to-automate-its-sales-process Three Reasons Why Your Business Needs To Automate Its Sales Process] Published by tebillion.com June 27, 2018, retrieved August 13, 2018&lt;/ref&gt; and [[workflow]].&lt;ref&gt;[http://www.docuvantage.com/what-are-business-process-management-and-workflow Business Process Management] Published by docuvantage.com, retrieved August 13, 2018&lt;/ref&gt;

===Home automation===
{{main|Home automation}}
Home automation (also called [[domotics]]) designates an emerging practice of increased automation of household appliances and features in residential dwellings, particularly through electronic means that allow for things impracticable, overly expensive or simply not possible in recent past decades. The rise in the usage of home automation solutions has taken a turn reflecting the increased dependency of people on such automation solutions. However, the increased comfort that gets added through these automation solutions is remarkable.&lt;ref&gt;{{Cite web|url=http://www.domautics.com/home-automation-system|title=Smart &amp; Intelligent Home Automation Solutions|last=|first=|date=2018-05-15|website=|access-date=}}&lt;/ref&gt;

===Laboratory automation===
{{Main|Laboratory automation}}[[File:GammaGIF.gif|link=https://en.wikipedia.org/wiki/File:GammaGIF.gif|alt=Automated laboratory instrument|thumb|Automated laboratory instrument]]Automation is essential for many scientific and clinical applications.&lt;ref&gt;{{Cite book|title=Practical Laboratory Automation: Made Easy with AutoIt|last=Carvalho|first=Matheus|publisher=Wiley VCH|year=2017|isbn=978-3-527-34158-0|location=|pages=|quote=|via=}}&lt;/ref&gt; Therefore, automation has been extensively employed in laboratories. From as early as 1980 fully automated laboratories have already been working.&lt;ref&gt;{{Cite journal|last=Boyd|first=James|date=18 January 2002|title=Robotic Laboratory Automation|url=http://science.sciencemag.org/content/295/5554/517|journal=Science|language=en|volume=295|issue=5554|pages=517–518|doi=10.1126/science.295.5554.517|issn=0036-8075|pmid=11799250}}&lt;/ref&gt; However, automation has not become widespread in laboratories due to its high cost. This may change with the ability of integrating low-cost devices with standard laboratory equipment.&lt;ref&gt;{{Cite journal|last=Carvalho|first=Matheus C.|date=1 August 2013|title=Integration of Analytical Instruments with Computer Scripting|url=http://jla.sagepub.com/content/18/4/328|archive-url=https://archive.is/20161027100231/http://jla.sagepub.com/content/18/4/328|dead-url=yes|archive-date=27 October 2016|journal=Journal of Laboratory Automation|language=en|volume=18|issue=4|pages=328–333|doi=10.1177/2211068213476288|issn=2211-0682|pmid=23413273}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=http://www.sciencedirect.com/science/article/pii/B9780124104624000019|title=Chapter 1 - Introduction to Open-Source Hardware for Science|last=Pearce|first=Joshua M.|date=1 January 2014|publisher=Elsevier|isbn=9780124104624|location=Boston|pages=1–11|doi=10.1016/b978-0-12-410462-4.00001-9}}&lt;/ref&gt; [[Autosampler]]s are common devices used in laboratory automation.

===Logistics automation===
{{main|Logistics automation}}

===Industrial automation===
Industrial automation deals primarily with the automation of manufacturing, quality control and material handling processes. General purpose controllers for industrial processes include Programmable logic controllers, stand-alone I/O modules, and computers. Industrial automation is to replace the decision making of humans and manual command-response activities with the use of mechanised equipment and logical programming commands. One trend is increased use of [[Machine vision]] to provide automatic inspection and robot guidance functions, another is a continuing increase in the use of robots. Industrial automation is simply require in industries.

The integration of control and information across the enterprise enables industries to optimise [https://digitalcontrols.org industrial process] operations.

Energy efficiency in industrial processes has become a higher priority. Semiconductor companies like Infineon Technologies are offering 8-bit micro-controller applications for example found in motor controls, general purpose pumps, fans, and ebikes to reduce energy consumption and thus increase efficiency.

{{see also|Building automation|Laboratory automation}}

====Industrial Automation and Industry 4.0====
The rise of industrial automation is directly tied to the “fourth industrial revolution”, which is better known now as Industry 4.0. Originating from Germany, Industry 4.0 encompasses numerous devises, concepts, and machines.&lt;ref name="doi.org"&gt;{{Cite journal | doi=10.11113/jt.v78.9285|title = Industry 4.0: A Review on Industrial Automation and Robotic| journal=Jurnal Teknologi| volume=78| issue=6–13|year = 2016|last1 = Kamarul Bahrin|first1 = Mohd Aiman| last2=Othman| first2=Mohd Fauzi| last3=Nor Azli| first3=Nor Hayati| last4=Talib| first4=Muhamad Farihin}}&lt;/ref&gt; It, along with the advancement of the Industrial Internet of Things (formally known as the IoT or IIoT) which is “Internet of Things is a seamless integration of diverse physical objects in the Internet through a virtual representation”.&lt;ref&gt;{{Cite book | doi=10.1109/IMIS.2012.134|chapter = Integrating Building Automation Systems and IPv6 in the Internet of Things|title = 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing| pages=683–688|year = 2012|last1 = Jung|first1 = Markus| last2=Reinisch| first2=Christian| last3=Kastner| first3=Wolfgang| isbn=978-1-4673-1328-5}}&lt;/ref&gt; These new revolutionary advancements have drawn attention to the world of automation in an entirely new light and shown ways for it to grow to increase productivity and efficiency in machinery and manufacturing facilities. Industry 4.0 works with the IIoT and software/hardware to connect in a way that (through communication technologies) add enhancements and improve manufacturing processes. Being able to create smarter, safer, and more advanced manufacturing is now possible with these new technologies. It opens up a manufacturing platform that is more reliable, consistent, and efficient that before. Implementation of systems such as [[SCADA]] are an example of software that take place in Industrial Automation today. SCADA is a supervisory data collection software, just one of the many used in Industrial Automation.&lt;ref&gt;{{Cite journal | doi=10.18845/tm.v28i4.2438|title = Los sistemas SCADA en la automatización industrial| journal=Revista Tecnología en Marcha| volume=28| issue=4| pages=3|year = 2015|last1 = Pérez-López|first1 = Esteban}}&lt;/ref&gt; Industry 4.0 vastly covers many areas in manufacturing and will continue to do so as time goes on.&lt;ref name="doi.org" /&gt;

====Industrial Robotics====
[[File:Workmaster.jpg|alt=Large automated milling machines inside a big warehouse-style lab room|thumb|Automated milling machines]]
[[Industrial robotics]] is a sub-branch in the industrial automation that aids in various manufacturing processes. Such manufacturing processes include; machining, welding, painting, assembling and material handling to name a few.&lt;ref&gt;{{cite book|last1=Shell|first1=Richard|title=Handbook of Industrial Automation|date=2000|page=46}}&lt;/ref&gt; Industrial robots utilizes various mechanical, electrical as well as software systems to allow for high precision, accuracy and speed that far exceeds any human performance. The birth of industrial robot came shortly after World War II as United States saw the need for a quicker way to produce industrial and consumer goods.&lt;ref&gt;{{cite book|last1=Kurfess|first1=Thomas|title=Robotics and Automation Handbook|date=2005|page=5}}&lt;/ref&gt; Servos, digital logic and solid state electronics allowed engineers to build better and faster systems and overtime these systems were improved and revised to the point where a single robot is capable of running 24 hours a day with little or no maintenance. In 1997, there were 700,000 industrial robots in use, the number has risen to 1.8M in 2017&lt;ref&gt;{{Cite news|url=https://www.pwc.com/gx/en/ceo-agenda/ceosurvey/2017/gx/talent.html|title=Managing man and machine|last=PricewaterhouseCoopers|work=PwC|access-date=2017-12-04|language=en}}&lt;/ref&gt; In recent years, [[artificial intelligence]] (AI) with [[robotics]] are also used in creating an automatic labelling solution, using robotic arms as the automatic label applicator, and AI for learning and detecting the products to be labelled. &lt;ref&gt; {{Cite web|url= https://milliontech.com/solutions/label-printing/irls-intelligent-robotics-labeling-system|title=AI Automatic Label Applicator &amp; Labelling System
|publisher=Milliontech|access-date=2018-11-16}}&lt;/ref&gt;

====Programmable Logic Controllers====
Industrial automation incorporates programmable logic controllers in the manufacturing process. Programmable logic controllers (PLCs) use a processing system which allows for variation of controls of inputs and outputs using simple programming. PLCs make use of programmable memory, storing instructions and functions like logic, sequencing, timing, counting, etc. Using a logic based language, a PLC can receive a variety of inputs and return a variety of logical outputs, the input devices being sensors and output devices being motors, valves, etc. PLCs are similar to computers, however, while computers are optimized for calculations, PLCs are optimized for control task and use in industrial environments. They are built so that only basic logic-based programming knowledge is needed and to handle vibrations, high temperatures, humidity and noise. The greatest advantage PLCs offer is their flexibility. With the same basic controllers, a PLC can operate a range of different control systems. PLCs make it unnecessary to rewire a system to change the control system. This flexibility leads to a cost-effective system for complex and varied control systems.&lt;ref&gt;{{cite book|last1=Bolten|first1=William|title=Programmable Logic Controllers (5th Edition)|date=2009|page=3}}&lt;/ref&gt;

[[Image:Siemens Simatic S7-416-3.jpg|thumb|Siemens Simatic S7-400 system in a rack, left-to-right: power supply unit (PSU), CPU, interface module (IM) and communication processor (CP).]]
PLCs can range from small "building brick" devices with tens of I/O in a housing integral with the processor, to large rack-mounted modular devices with a count of thousands of I/O, and which are often networked to other PLC and [[SCADA]] systems.

They can be designed for multiple arrangements of digital and analog inputs and outputs (I/O), extended temperature ranges, immunity to [[noise (electronics)|electrical noise]], and resistance to vibration and impact. Programs to control machine operation are typically stored in battery-backed-up or [[non-volatile memory]].

It was from the automotive industry in the USA that the PLC was born. Before the PLC, control, sequencing, and safety interlock logic for manufacturing automobiles was mainly composed of [[relay]]s, [[cam timer]]s, [[drum sequencer (controller)|drum sequencer]]s, and dedicated closed-loop controllers. Since these could number in the hundreds or even thousands, the process for updating such facilities for the yearly model [[changeover|change-over]] was very time consuming and expensive, as [[electrician]]s needed to individually rewire the relays to change their operational characteristics.

When digital computers became available, being general-purpose programmable devices, they were soon applied to control sequential and combinatorial logic in industrial processes. However these early computers required specialist programmers and stringent operating environmental control for temperature, cleanliness, and power quality. To meet these challenges this the PLC was developed with several key attributes. It would tolerate the shop-floor environment, it would support discrete (bit-form) input and output in an easily extensible manner, it would not require years of training to use, and it would permit its operation to be monitored. Since many industrial processes have timescales easily addressed by millisecond response times, modern (fast, small, reliable) electronics greatly facilitate building reliable controllers, and performance could be traded off for reliability.&lt;ref name=Parr00&gt;E. A. Parr, ''Industrial Control Handbook'', Industrial Press Inc., 1999 {{ISBN|0-8311-3085-7}}&lt;/ref&gt;

====Agent-assisted automation====
{{main|Agent-assisted automation}}
Agent-assisted automation refers to automation used by call center agents to handle customer inquiries. There are two basic types: desktop automation and automated voice solutions. Desktop automation refers to software programming that makes it easier for the call center agent to work across multiple desktop tools. The automation would take the information entered into one tool and populate it across the others so it did not have to be entered more than once, for example. Automated voice solutions allow the agents to remain on the line while disclosures and other important information is provided to customers in the form of pre-recorded audio files. Specialized applications of these automated voice solutions enable the agents to process credit cards without ever seeing or hearing the credit card numbers or CVV codes&lt;ref name="adsit"&gt;{{cite news | last=Adsit | first=Dennis| url= http://www.isixsigma.com/index.php?option=com_k2&amp;view=item&amp;id=1854&amp;Itemid=1&amp;Itemid=1| title= Error-proofing strategies for managing call center fraud | work= isixsigma.com |date= 21 February 2011}}&lt;/ref&gt;

The key benefit of agent-assisted automation is compliance and error-proofing. Agents are sometimes not fully trained or they forget or ignore key steps in the process. The use of automation ensures that what is supposed to happen on the call actually does, every time.

==Relationship to unemployment==
{{main|Technological unemployment}}
Research by  [[Carl Benedikt Frey]] and Michael Osborne of the [[Oxford Martin School]] argued that employees engaged in "tasks following well-defined procedures that can easily be performed by sophisticated algorithms" are at risk of displacement, and 47 per cent of jobs in the US were at risk. The study, released as a working paper in 2013 and published in 2017, predicted that automation would put low-paid physical occupations most at risk, by surveying a group of colleagues on their opinions.&lt;ref name=OMS913&gt;{{cite web|author1=Carl Benedikt Frey  |author2=Michael Osborne|title=The Future of Employment: How susceptible are jobs to computerisation?|url=http://www.oxfordmartin.ox.ac.uk/publications/view/1314|publisher=[[Oxford Martin School]]|accessdate=7 November 2015|format=publication|date=September 2013}}&lt;/ref&gt; However, according to a study published in [[McKinsey Quarterly]]&lt;ref name=MKQ1115&gt;{{cite web|author1=Michael Chui |author2=James Manyika |author3=Mehdi Miremadi |title=Four fundamentals of workplace automation As the automation of physical and knowledge work advances, many jobs will be redefined rather than eliminated—at least in the short term.|url=http://www.mckinsey.com//Insights/Business_Technology/Four_fundamentals_of_workplace_automation|publisher=[[McKinsey Quarterly]]|accessdate=7 November 2015|date=November 2015|quote=Very few occupations will be automated in their entirety in the near or medium term. Rather, certain activities are more likely to be automated....}}&lt;/ref&gt; in 2015 the impact of computerization in most cases is not replacement of employees but automation of portions of the tasks they perform.&lt;ref name=NYT11615&gt;{{cite news|author1=Steve Lohr|title=Automation Will Change Jobs More Than Kill Them|url=http://bits.blogs.nytimes.com/2015/11/06/automation-will-change-jobs-more-than-kill-them/|accessdate=7 November 2015|work=The New York Times|date=6 November 2015|quote=technology-driven automation will affect most every occupation and can change work, according to new research from McKinsey}}&lt;/ref&gt; The methodology of the McKinsey study has been heavily criticized for being intransparent and relying on subjective assessments.&lt;ref&gt;{{Cite journal|last=Arntz er al|first=|date=Summer 2017|title=Future of work|url=|journal=Economic Lettets|volume=|pages=|via=}}&lt;/ref&gt; The methodology of Frey and Osborne has been subjected to criticism, as lacking evidence, historical awareness, or credible methodology.&lt;ref&gt;DH Autor, ‘[http://pubs.aeaweb.org/doi/pdf/10.1257%2Fjep.29.3.3 Why Are There Still So Many Jobs? The History and Future of Workplace Automation]’ (2015) 29(3) Journal of Economic Perspectives 3.&lt;/ref&gt;&lt;ref&gt;E McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2018) [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3044448 SSRN, part 2(3), 15–16]&lt;/ref&gt; In addition the OCED, found that  across the 21 OECD countries, 9% of jobs are automatable.&lt;ref&gt;Arntz, M., T. Gregory and U. Zierahn (2016), "[https://futuroexponencial.com/wp-content/uploads/2018/02/OECD.pdf The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis]", ''OECD Social, Employment and Migration Working Papers'', No. 189, OECD Publishing, Paris, &lt;nowiki&gt;http://dx.doi.org.mutex.gmu.edu/10.1787/5jlz9h56dvq7-en&lt;/nowiki&gt;.&lt;/ref&gt;

The Obama White House has pointed out that every 3 months "about 6 percent of jobs in the economy are destroyed by shrinking or closing businesses, while a slightly larger percentage of jobs are added".&lt;ref&gt;Executive Office of the President, Artificial Intelligence, Automation and the Economy ([https://www.whitehouse.gov/sites/whitehouse.gov/files/images/EMBARGOED%20AI%20Economy%20Report.pdf December 2016]) 2 and 13–19.&lt;/ref&gt; A recent MIT economics study of automation in the United States from 1990 to 2007 found that there may be a negative impact on employment and wages when robots are introduced to an industry. When one robot is added per one thousand workers, the employment to population ratio decreases between 0.18–0.34 percentages and wages are reduced by 0.25–0.5 percentage points. During the time period studied, the US did not have many robots in the economy which restricts the impact of automation. However, automation is expected to triple (conservative estimate) or quadruple (generous estimate) leading these numbers to become substantially higher.&lt;ref&gt;{{cite web|last1=Acemoglu|first1=Daron|last2=Restrepo|first2=Pascual|title=Robots and Jobs: Evidence from US Labor Markets|url=https://economics.mit.edu/files/12763|accessdate=February 20, 2018|archive-url=https://web.archive.org/web/20180403004714/https://economics.mit.edu/files/12763|archive-date=3 April 2018|dead-url=yes|df=dmy-all}}&lt;/ref&gt;

Based on a formula by [[Gilles Saint-Paul]], an economist at Toulouse 1 University, the demand for unskilled human capital declines at a slower rate than the demand for skilled human capital increases.&lt;ref&gt;Saint-Paul, G. (2008). Innovation and inequality:How does technical progress affect workers? Princeton, New Jersey: Princeton University Press.&lt;/ref&gt; In the long run and for society as a whole it has led to cheaper products, [[Working time#Gradual decrease in working hours|lower average work hours]], and new industries forming (i.e., robotics industries, computer industries, design industries). These new industries provide many high salary skill based jobs to the economy. By 2030, between 3 and 14 percent of the global workforce will be forced to switch job categories due to automation eliminating jobs in an entire sector. While the number of jobs lost to automation are often offset by jobs gained from technological advances, the same type of job lost is not the same one replaced and that leading to increasing unemployment in the lower-middle class. This occurs largely in the US and developed countries where technological advances contribute to higher demand for high skilled labor but demand for middle wage labor continues to fall. Economists call this trend “income polarization” where unskilled labor wages are driven down and skilled labor is driven up and it is predicted to continue in developed economies.&lt;ref&gt;{{cite book|author=McKinsey Global Institute|title=Jobs Lost, Jobs Gained: Workforce Transitions in a Time of Automation|date=December 2017|publisher=Mckinsey &amp; Company|pages=1–20|url=https://www.mckinsey.com/~/media/McKinsey/Global%20Themes/Future%20of%20Organizations/What%20the%20future%20of%20work%20will%20mean%20for%20jobs%20skills%20and%20wages/MGI-Jobs-Lost-Jobs-Gained-Report-December-6-2017.ashx|accessdate=February 20, 2018}}&lt;/ref&gt;

==See also==
{{Portal|Robotics|Electronics}}
{{div col|colwidth=20em}}
* [[Automated storage and retrieval system]]
* [[Automation technician]]
* [[Cognitive computing]]
* [[Cybernetics]]
* [[Futures studies]]
* [[Machine to machine]]
* [[Mobile manipulator]]
* [[Multi-agent system]]
* [[Process control]]
* [[Productivity improving technologies]]
* [[Robotic process automation]]
* [[Control engineering]]
* [[Feedforward control]]
* [[Data-driven control system]]
* [[Technological unemployment]]{{div col end}}

==Notes==
{{Reflist|refs=
&lt;ref name="MBLE_1962_Norbit"&gt;{{cite journal |title=les relais statiques Norbit |language=French |date=September 1962&lt;!-- or 1961? --&gt; |journal=[[Revue MBLE]] |publisher=[[Philips Research Laboratory]], {{lang|fr|Manufacture Belge de Lampes et de Materiel Electronique}} (MBLE Research Laboratory) |location=Brussels, Belgium |url=http://www.radiocollection.be/images/mble_img/mble_auto17.jpg |access-date=2018-06-18 |dead-url=no |archive-url=https://web.archive.org/web/20180618235651/http://www.radiocollection.be/images/mble_img/mble_auto17.jpg |archive-date=2018-06-18}} [https://web.archive.org/web/20180619105935/http://www.radiocollection.be/images/mble_img/mble_auto10.jpg]
[https://web.archive.org/web/20180619105944/http://www.radiocollection.be/images/mble_img/mble_auto11.jpg]
[https://web.archive.org/web/20180619110132/http://www.radiocollection.be/images/mble_img/mble_auto12.jpg]
[https://web.archive.org/web/20180619110140/http://www.radiocollection.be/images/mble_img/mble_auto13.jpg]
[https://web.archive.org/web/20180619110249/http://www.radiocollection.be/images/mble_img/mble_auto14.jpg]
[https://web.archive.org/web/20180619110302/http://www.radiocollection.be/images/mble_img/mble_auto15.jpg]
[https://web.archive.org/web/20180619110254/http://www.radiocollection.be/images/mble_img/mble_auto16.jpg]&lt;/ref&gt;
&lt;ref name="Walker_2012"&gt;{{cite book |title=The Programmable Logic Controller: its prehistory, emergence and application |author-first=Mark John |author-last=Walker |date=2012-09-08 |type=PhD thesis |location=Department of Communication and Systems Faculty of Mathematics, Computing and Technology |publisher=[[The Open University]] |pages=223, 269, 308 |url=http://oro.open.ac.uk/54687/1/594090.pdf |access-date=2018-06-20 |dead-url=no |archive-url=https://web.archive.org/web/20180620115412/http://oro.open.ac.uk/54687/1/594090.pdf |archive-date=2018-06-20}}&lt;/ref&gt;
&lt;ref name="Wireless-World_1960"&gt;{{cite journal |title=INTERKAMA 1960 - Dusseldorf Exhibition of Automation and Instruments |date=December 1960 |volume=66 |number=12 |journal=[[Wireless World]] |pages=588–589 |url=https://www.americanradiohistory.com/Archive-Wireless-World/60s/Wireless-World-1960-12.pdf |access-date=2018-06-18 |quote=[…] Another point noticed was the widespread use of small-package [[solid-state (electronics)|solid-state]] [[digital logic|logic]] (such as "[[Logical AND|and]]," "[[Logical OR|or]]," "[[Logical NOT|not]]") and [[instrumentation]] (timers, amplifiers, etc.) units. There would seem to be a good case here for the various manufacturers to standardise practical details such as mounting, connections and power supplies so that a [[Siemens]] "{{ill|Simatic|de}}," say, is directly interchangeable with an [[Ateliers des Constructions Electronique de Charleroi]] "[[Logacec]]," a [[Telefunken]] "[[Logistat]]," or a [[Mullard]] "[[Norbit module|Norbit]]" or "[[Combi-element]]." […]}}&lt;/ref&gt;
&lt;ref name="Akkord_Estacord"&gt;{{cite book |publisher={{ill|Akkord-Radio{{!}}Akkord-Radio GmbH|de|Akkord-Radio}} |location=Herxheim/Pfalz, Germany |title=Estacord - Das universelle Bausteinsystem für kontaktlose Steuerungen |language=German |date=&lt;!-- ca. 1960-1962? --&gt; |type=Catalog}}&lt;/ref&gt;
&lt;ref name="Klingelnberg_1967"&gt;{{cite book |title=Technisches Hilfsbuch |language=German |author-first=W. Ferdinand |author-last=Klingelnberg 
|editor-first1=Fritz |editor-last1=Pohl |editor-first2=Rudolf |editor-last2=Reindl |edition=softcover reprint of 15th hardcover |publisher=[[Springer-Verlag]] |date=2013 |orig-year=1967, 1960, 1939&lt;!-- 1940, 1942, 1944, 1953 --&gt; |isbn=978-3-64288368-2 |id=0512 |lccn=67-23459 |doi=10.1007/978-3-642-88367-5 |page=135 |url=https://books.google.com/books?id=_zymBgAAQBAJ&amp;pg=PA135}}&lt;/ref&gt;
&lt;ref name="Weissel_1995"&gt;{{cite book |title=Digitale Schaltungstechnik |chapter=4.1. Grundschaltungen mit Bipolar- und Feldeffekttransistoren |language=German |author-first1=Ralph |author-last1=Weißel |author-first2=Franz |author-last2=Schubert |publisher=[[Springer-Verlag]] |date=2013-03-07 |orig-year=1995, 1990 |isbn=978-3-540-57012-7 |doi=10.1007/978-3-642-78387-6 |edition=reprint of 2nd |page=116 |url=https://books.google.com/books?id=h3DRBgAAQBAJ&amp;pg=PA116&amp;lpg=PA116}}&lt;/ref&gt;
&lt;ref name="Parr_1993"&gt;{{cite book |title=Logic Designer's Handbook: Circuits and Systems |author-first=E. Andrew |author-last=Parr |edition=revised 2nd |publisher=B.H. Newnes / Butterworth-Heinemann Ltd. / Reed International Books |date=1993 |orig-year=1984 |isbn=0-7506-0535-9 |pages=45–46 |url=https://books.google.com/books?id=Yk8vBQAAQBAJ&amp;pg=PA482&amp;lpg=PA482 |access-date=2018-06-25}}&lt;/ref&gt;
}}

==References==
* {{cite journal |first=David H. |last=Autor |title=Why Are There Still So Many Jobs? The History and Future of Workplace Automation |year=2015 |volume=29 |page=3 |number=3 |journal=Journal of Economic Perspectives |url=https://economics.mit.edu/files/11563 |access-date=16 January 2018 |doi=10.1257/jep.29.3.3}}
* {{cite book|title=A History of Control Engineering 1930-1955 |last=Bennett |first= S. |year=1993 |publisher =Peter Peregrinus Ltd. On behalf of the Institution of Electrical Engineers
|location= London|isbn= 0-86341-280-7|pages=| postscript = &lt;!--None--&gt;}}
* {{Citation | last = Dunlop | first = John T. (ed.) | year = 1962 | title = Automation and Technological Change: Report of the Twenty-first American Assembly | publisher = Prentice-Hall | location = Englewood Cliffs, NJ, USA | url =  | doi =  | isbn =  | id =  | postscript =. }}* {{Citation | last = Dunlop | first = John T. (ed.) | year = 1962 | title = Automation and Technological Change: Report of the Twenty-first American Assembly | publisher = Prentice-Hall | location = Englewood Cliffs, NJ, USA | url =  | doi =  | isbn =  | id =  | postscript =. }}
*E McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2018) [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3044448 SSRN, part 2(3)]
* {{Citation | last = Ouellette | first = Robert | year = 1983 | title = Automation Impacts on Industry | publisher = Ann Arbor Science Publishers | location = Ann Arbor, MI, USA | url =  | doi =  | isbn = 978-0-250-40609-8 | id =  | postscript =. }}
* {{Citation|last=Trevathan |first=Vernon L. (ed.) |year=2006 |title=A Guide to the Automation Body of Knowledge |edition=2nd |publisher=International Society of Automation |location=Research Triangle Park, NC, USA |url=http://www.isa.org/autobok/ |doi= |isbn=978-1-55617-984-6 |id= |postscript=. |deadurl=yes |archiveurl=https://web.archive.org/web/20080704074027/http://www.isa.org/autobok |archivedate=4 July 2008 |df= }}
* {{Citation | last = Frohm | first = Jorgen| year = 2008 | title = Levels of Automation in Production Systems | publisher = Chalmers University of Technology| url = http://publications.lib.chalmers.se | doi =  | isbn = 978-91-7385-055-1 | id =  | postscript =. }}
* Executive Office of the President, Artificial Intelligence, Automation and the Economy ([https://www.whitehouse.gov/sites/whitehouse.gov/files/images/EMBARGOED%20AI%20Economy%20Report.pdf December 2016])

{{Sister project links|wikt=automation|commons=Category:Automation|n=no|s=no|b=no}}

{{Robotics}}

[[Category:Automation| ]]
[[Category:Articles containing video clips]]</text>
      <sha1>hs7e2j9lig4j7s6kzw1it13h16o74os</sha1>
    </revision>
  </page>
  <page>
    <title>Bearing surface</title>
    <ns>0</ns>
    <id>23438467</id>
    <revision>
      <id>863571833</id>
      <parentid>849071580</parentid>
      <timestamp>2018-10-11T16:46:27Z</timestamp>
      <contributor>
        <username>Volunteer1234</username>
        <id>30845620</id>
      </contributor>
      <comment>is</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2078">A '''bearing surface''' in [[mechanical engineering]] is the [[area]] of contact between two objects. It usually is used in reference to [[bolted joint]]s and [[bearing (mechanical)|bearings]], but can be applied to a wide variety of engineering applications. 

On a [[screw]] the bearing area loosely refers to the underside of the head.&lt;ref&gt;{{harvnb|Smith|1990|p=38}}.&lt;/ref&gt; Strictly speaking, the bearing area refers to the area of the screw head that directly bears on the part being fastened.&lt;ref&gt;{{Citation | title = Fastener terms | url = http://www.canadianstainless.ca/page9.html | accessdate = 2009-06-29}}.&lt;/ref&gt; 

For a cylindrical bearing it is the [[projected area]] perpendicular to the applied force.&lt;ref&gt;{{harvnb|Low|Bevis|1908|p=115}}.&lt;/ref&gt;

On a [[spring (device)|spring]] the bearing area refers to the amount of area on the top or bottom surface of the spring in contact with the constraining part.&lt;ref&gt;{{Citation | title = Helical Compression Spring Terminology | url = http://www.masterspring.com/technical_resources/helical_compression_spring_terminology/default.html | accessdate = 2009-06-29}}.&lt;/ref&gt;

The ways of [[machine tool]]s, such as dovetail slides, box ways, prismatic ways, and other types of machine slides are also bearing surfaces. 

==See also==
*[[Babbitt (metal)|Babbitt]], an alloy that covers a bearing surface
*[[Bridge bearing]]

==References==
{{Reflist}}

===Bibliography===
*{{Citation | last = Low | first = David Allan | last2 = Bevis | first2 = Alfred William | title = Manual of machine drawing and design | publisher = Longmans, Green, and co | year = 1908 | edition = Revised | url = https://books.google.com/books?id=acYJAAAAIAAJ}}.
*{{Citation | last = Smith | first = Carroll | author-link = Carroll Smith | title = Carroll Smith's Nuts, Bolts, Fasteners, and Plumbing Handbook | publisher = MotorBooks/MBI Publishing Company | year = 1990 | url = https://books.google.com/books?id=A81HmmRCN7YC | isbn = 0-87938-406-9}}.

[[Category:Bearings_(mechanical)]]
[[Category:Mechanical engineering]]

{{mech-engineering-stub}}</text>
      <sha1>5rcicxlszigcvnj1pqekz6ly2uzp7d3</sha1>
    </revision>
  </page>
  <page>
    <title>Biodemography of human longevity</title>
    <ns>0</ns>
    <id>4140679</id>
    <revision>
      <id>815579495</id>
      <parentid>776509238</parentid>
      <timestamp>2017-12-15T18:25:45Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>/* Theory */Typo fixing, replaced: biodemograhic → biodemographic using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4492">{{refimprove|date=October 2009}}
[[File:Nursing home.JPG|thumb|350px|Old man at a [[nursing home]] in [[Norway]].]]
Biodemography is a multidisciplinary approach, integrating biological knowledge (studies on human biology and animal models) with demographic research on human longevity and survival. Biodemographic studies are important for understanding the driving forces of the current longevity revolution (dramatic increase in human life expectancy), forecasting the future of human longevity, and identification of new strategies for further increase in healthy and productive life span.

==Theory==
Biodemographic studies found a remarkable similarity in survival dynamics between humans and laboratory animals. Specifically, three general biodemographic laws of survival are found:

# [[Gompertz–Makeham law of mortality]]
# [[Compensation law of mortality]]
# [[Late-life mortality deceleration]].

The [[Gompertz–Makeham law of mortality|Gompertz–Makeham law]] states that death rate is a sum of age-independent component ([[Makeham term]]) and age-dependent component ([[Gompertz function]]), which increases exponentially with age.

The [[compensation law of mortality]] (late-life mortality convergence) states that the relative differences in death rates between different populations of the same biological species are decreasing with age, because the higher initial death rates are compensated by lower pace of their increase with age.

The [[Late-life mortality deceleration]] law states that death rates stop increasing exponentially at advanced ages and level-off to the [[late-life mortality plateau]]. An immediate consequence from this observation is that there is no fixed upper limit to human longevity &amp;mdash; there is no special fixed number, which separates possible and impossible values of lifespan. This challenges the common belief&lt;ref&gt;Gavrilov, L.A., Gavrilova, N.S. Common sense and the limits to life. Int. J. Geriatric Psychiatry, 1993, 8(8): 695–695.&lt;/ref&gt;&lt;ref&gt;Gavrilov L.A. Does a limit of the life span really exist? Biophysics [Biofizika], 1984, 29(5): 908–911.&lt;/ref&gt; in existence of a fixed maximal human life span.

Biodemographic studies found that even genetically identical laboratory animals kept in constant environment have very different lengths of life, suggesting a crucial role of chance and early-life developmental noise in longevity determination. This leads to new approaches in understanding causes of exceptional human longevity.

As for the future of human longevity, biodemographic studies found that evolution of human lifespan had two very distinct stages – the initial stage of mortality decline at younger ages is now replaced by a new trend of preferential improvement of the oldest-old survival. This phenomenon invalidates methods of longevity forecasting based on extrapolation of long-term historical trends.

A general explanation of these biodemographic laws of aging and longevity has been suggested based on system [[reliability theory of aging and longevity|reliability theory]].

==See also==
* [[Demography]]
* [[Biodemography]]
* [[Longevity]]
* [[Life extension]]
* [[List of life extension-related topics]]
* [[Reliability theory of aging and longevity]]

==References==
{{Reflist}}

==Further reading==
* {{Cite book |author=Leonid A. Gavrilov |author2=Natalia S. Gavrilova |last-author-amp=yes |year=1991 |title=The Biology of Life Span: A Quantitative Approach |location=New York |publisher=Harwood Academic Publisher |isbn=3-7186-4983-7}}
* {{cite journal |vauthors=Gavrilov LA, Gavrilova NS, Olshansky SJ, Carnes BA |year=2002 |title=Genealogical data and biodemography of human longevity |journal=Social Biology |volume=49 |issue=3-4 |pages=160–173 |doi=10.1080/19485565.2002.9989056}}
* {{cite journal |vauthors=Gavrilov LA, Gavrilova NS |year=2001 |title=Biodemographic study of familial determinants of human longevity |journal=Population: An English Selection |volume=13 |issue=1 |pages=197–222}}

==External links==
*[http://longevity-science.org/Biodemography.html Biodemography of Human Longevity] &amp;mdash; abstract of keynote lecture, p.&amp;nbsp;42. In: Inaugural International Conference on Longevity. Final Programme and Abstracts. Sydney Convention &amp; Exhibition Centre. Sydney, Australia, March 5–7, 2004, 94 pp

{{Longevity}}

{{DEFAULTSORT:Biodemography Of Human Longevity}}
[[Category:Ageing]]
[[Category:Gerontology]]
[[Category:Medical aspects of death]]
[[Category:Population]]</text>
      <sha1>j7uyq5pd8uh4mtptiobsvy4fu4efcl8</sha1>
    </revision>
  </page>
  <page>
    <title>Chloracne</title>
    <ns>0</ns>
    <id>767305</id>
    <revision>
      <id>864814849</id>
      <parentid>862645038</parentid>
      <timestamp>2018-10-19T17:05:33Z</timestamp>
      <contributor>
        <ip>2001:56A:F347:0:3862:F3E4:E856:F291</ip>
      </contributor>
      <comment>/* Treatment */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9296">{{Infobox medical condition (new)
| name            = Chloracne
| synonyms        = 
| image           = Chloracne-in-herbicide-worker.png
| caption         = Chloracne in this [[herbicide]] production worker involved almost every follicular orifice on his face and neck with [[comedones]], [[papules]] and cystlike lesions.
| pronounce       = 
| field           = 
| symptoms        = 
| complications   = 
| onset           = 
| duration        = 
| types           = 
| causes          = 
| risks           = 
| diagnosis       = 
| differential    = 
| prevention      = 
| treatment       = 
| medication      = 
| prognosis       = 
| frequency       = 
| deaths          = 
}}

'''Chloracne''' is an [[Acne vulgaris|acne]]-like eruption of [[blackhead]]s, [[cyst]]s, and [[pustule]]s associated with over-exposure to certain [[halogen]]ated [[aromatic compound]]s, such as chlorinated [[Polychlorinated dibenzodioxins|dioxins]] and [[Polychlorinated dibenzofurans|dibenzofurans]]. The [[lesion]]s are most frequently found on the cheeks, behind the ears, in the armpits and groin region.

The condition was first described in German industrial workers in 1897 by Siegfried Bettmann,&lt;ref&gt;Siegfried Bettmann (1869–1939), University of Heidelberg&lt;/ref&gt; and was initially believed to be caused by exposure to [[chlorine]] (hence the name "chloracne"). It was only in the mid-1950s that chloracne was associated with aromatic hydrocarbons.&lt;ref name="ref1"&gt;{{cite web |vauthors=Williams DE, Wolfe WH, Lustik MB |year=1995 |title=An Epidemiologic Investigation of Health Effects in Air Force Personnel Following Exposure to Herbicides |volume=4 |page=427 |publisher= |id=A313403 |url=http://www.stormingmedia.us/31/3134/A313403.html |display-authors=etal}}&lt;/ref&gt; The substances that may cause chloracne are now collectively known as '''chloracnegens'''.

Chloracne is particularly linked to toxic exposure to [[Polychlorinated dibenzodioxins|dioxin]]s ([[byproduct]]s of many [[chemical process]]es, including the manufacture of [[herbicides]] such as [[Agent Orange]])&amp;mdash;so much so that it is considered a clinical sign of dioxin exposure. The severity and onset of chloracne may follow a typical [[asymptotic]] [[dose-response relationship]] [[curve]].

==Cause==
Chloracne normally results from direct skin contact with chloracnegens, although ingestion and [[inhalation]] are also possible causative routes.

Chloracnegens are [[fat-soluble]], meaning they persist in the body fat for a very long period following exposure. Chloracne is a chronic [[inflammation|inflammatory]] condition that results from this persistence, in combination with the toxin's chemical properties. It is believed, at least from [[rodent]] models, that the [[toxin]] activates a series of [[receptor (biochemistry)|receptors]] promoting [[macrophage]] proliferation, inducing [[neutrophilia]] and leading to a generalised inflammatory response in the skin. This process may also be augmented by induction of excess [[Tumor necrosis factors|tumor necrosis factor]] in the [[blood]] [[blood plasma|serum]].

The inflammatory processes lead to the formation of [[keratin]]ous plugs in skin pores, forming yellowish [[cyst]]s and dark [[pustule]]s. The associated [[pus]] is usually a color of green approximating that of a tennis ball. The skin lesions occur mainly in the face, but in more severe cases they involve the shoulders and chest, the back, and the abdomen. In advanced cases, the lesions appear also on the arms, neck, thighs, legs, hands and feet.

In some instances, chloracne may not appear for three to four weeks after toxic exposure; however, in other cases&amp;mdash;particularly in events of massive exposure&amp;mdash;the symptoms may appear within days.&lt;ref name="ref1"/&gt;&lt;ref name="ref2"&gt;{{cite journal |vauthors=De Marchia B, Ravetzb JR |title=Risk management and governance: a post-normal science approach |journal=Futures |volume=31 |issue=7 |pages=743–57 |year=1999 |doi=10.1016/S0016-3287(99)00030-0}}&lt;/ref&gt;

==Treatment==
Once chloracne has been identified, the primary action is to remove the patient and all other individuals from the source of contamination. Further treatment is [[symptomatic]].

Secondary infections on severe or persistent lesions may need to be treated with oral [[antibiotics]] or [[isotretinoin]]. However, chloracne itself can be highly resistant to any treatment.

The course of the disease is highly variable. In some cases the lesions may disappear within two years or so; however, in other cases the lesions may be effectively permanent (mean duration of lesions in one 1984 study was 26 years, with some workers remaining disfigured over three decades after exposure).&lt;ref name="ref3"&gt;{{cite journal |vauthors=Moses M, Lilis R, Crow KD |title=Health status of workers with past exposure to 2,3,7,8-tetrachlorodibenzo-p-dioxin in the manufacture of 2,4,5-trichlorophenoxyacetic acid: comparison of findings with and without chloracne |journal=Am. J. Ind. Med. |volume=5 |issue=3 |pages=161–82 |year=1984 |pmid=6142642 |doi= 10.1002/ajim.4700050303|url=|display-authors=etal}}&lt;/ref&gt;

==Related conditions==
Chloracne is very often seen in combination with [[hyperhidrosis]] (clammy, sweaty skin) and [[porphyria cutanea tarda]] (a skin condition of increased pigmentation, hair coarsening and blistering).

==Notable cases==
[[File:Viktor Yuschenko.jpg|thumb|200px|[[Viktor Yushchenko]] at the [[University of Amsterdam]], with chloracne from [[2,3,7,8-Tetrachlorodibenzodioxin|TCDD]] [[Polychlorinated dibenzodioxins|dioxin]] poisoning (2006)]]
* In 1949, 226 workers became ill after a container of [[herbicide]] exploded at a [[Monsanto Company]] plant in [[Nitro, West Virginia]].&lt;ref name="nitro"&gt;{{cite journal |vauthors=Barlett DL, Steele JB |title=Monsanto's Harvest Of Fear |journal=Vanity Fair |volume= |issue=May |pages= |year=2008 |url=http://www.vanityfair.com/politics/features/2008/05/monsanto200805?currentPage=4}}&lt;/ref&gt; Many were diagnosed with chloracne; a medical report at the time described "systemic intoxication in the workers involving most major organ systems."{{citation needed|date = August 2012}}
* 193 cases of chloracne occurred in [[Seveso]], [[Italy]] in 1976 following an [[Seveso disaster|industrial accident]] in which up to a few kilograms of [[Polychlorinated dibenzodioxins|TCDD]] were released into the atmosphere.&lt;ref&gt;{{Cite journal|title = Long-term effects of chemical disasters. Lessons and results from Seveso|journal = The Science of the Total Environment|date = 1991-07-01|issn = 0048-9697|pmid = 1835132|pages = 5–20|volume = 106|issue = 1-2|first = P. A.|last = Bertazzi|doi=10.1016/0048-9697(91)90016-8}}&lt;/ref&gt;
* Thousands of individuals were exposed at [[Fort McClellan]], Alabama, when a chemical weapons training center and a nearby [[Monsanto]] factory disposed of chemicals into a creek over several decades.&lt;ref&gt;{{cite web|url=http://www.commondreams.org/headlines02/0101-02.htm |title=Corporate Giant Monsanto Hid Decades Of Pollution |publisher=Commondreams.org |date=2002-01-01 |accessdate=2013-09-08}}&lt;/ref&gt; Many individuals {{how many?|date=December 2017}} settled out of court, but a class-action suit is still ongoing.&lt;ref&gt;{{cite web |url=http://www.catastrophemap.com/anniston.html |archive-url=https://web.archive.org/web/20090323120422/http://catastrophemap.com/anniston.html |dead-url=yes |archive-date=23 March 2009 |title=Monsanto creek contaminated |publisher=CatastropheMap, Ltd. |accessdate=10 April 2014 |df= }}&lt;/ref&gt; Although the incineration of the chemical weapons at Fort McClellan ended in 2011, areas of the base remain closed or off-limits due to the residual contamination.
* In 1968, almost 2,000 individuals in northern [[Kyūshū]], Japan suffered chloracne, among other symptoms, after chronic exposure to cooking oils contaminated with [[Polychlorinated biphenyl|PCB]]s and [[PCDF]]s. The syndrome came to be called ''[[Yushō disease]]'' or "Rice Oil" disease.
* In 1979, a similar case of mass contamination of cooking oil was reported in central [[Taiwan]]. Over 2,000 individuals were affected by what came to be called ''Yu-Cheng''.&lt;ref&gt;{{cite journal |author=Aoki Y |title=Polychlorinated biphenyls, polychlorinated dibenzo-p-dioxins, and polychlorinated dibenzofurans as endocrine disrupters--what we have learned from Yusho disease |journal=Environ. Res. |volume=86 |issue=1 |pages=2–11 |year=2001 |pmid=11386736 |doi=10.1006/enrs.2001.4244 |url=}}&lt;/ref&gt;
* Ukrainian President [[Viktor Yushchenko]] suffered from prominent facial chloracne and was diagnosed with dioxin poisoning in late 2004.&lt;ref&gt;{{cite web|url=http://news.bbc.co.uk/2/hi/health/4041321.stm|title=BBC NEWS - Health - Yushchenko and the poison theory|publisher=bbc.co.uk|accessdate=2014-12-08}}&lt;/ref&gt;

==References==
{{Reflist}}

== External links ==
{{Medical resources
|  DiseasesDB     = 31706 
|  ICD10          = {{ICD10|L|70|8|l|60}} 
|  ICD9           =  
|  ICDO           =  
|  OMIM           =  
|  MedlinePlus    =  
|  eMedicineSubj  = topic 
|  eMedicineTopic = 620 
|  eMedicine_mult = &lt;br&gt;(Acneiform Eruptions) 
|  MeshID         = D054506
}}
{{commonscatinline}}

{{Disorders of skin appendages}}

[[Category:Acneiform eruptions]]
[[Category:Toxicology]]
[[Category:Chlorine]]</text>
      <sha1>90ojygr7vxtjuut11npr4hd64rmfybd</sha1>
    </revision>
  </page>
  <page>
    <title>DNA sequencing</title>
    <ns>0</ns>
    <id>1158125</id>
    <revision>
      <id>871755206</id>
      <parentid>871755135</parentid>
      <timestamp>2018-12-03T06:00:20Z</timestamp>
      <contributor>
        <username>Kiko Garcia 1</username>
        <id>35250467</id>
      </contributor>
      <minor/>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="108040">{{pp-move-indef|small=yes}}
{{Use dmy dates|date=April 2011}}
{{Genetics sidebar}}

'''DNA sequencing''' is the process of determining the order of [[nucleotides]] in [[DNA]]. It includes any method or technology that is used to determine the order of the four bases: [[adenine]], [[guanine]], [[cytosine]], and [[thymine]]. The advent of rapid DNA sequencing methods has greatly accelerated biological and medical research and discovery.&lt;ref&gt;{{cite web|url=https://theconversation.com/introducing-dark-dna-the-phenomenon-that-could-change-how-we-think-about-evolution-82867|title=Introducing ‘dark DNA’ – the phenomenon that could change how we think about evolution}}&lt;/ref&gt;

Knowledge of DNA sequences has become indispensable for basic biological research, and in numerous applied fields such as [[medical diagnosis]], [[biotechnology]], [[forensic biology]], [[virology]] and biological [[systematics]]. The rapid speed of sequencing attained with modern DNA sequencing technology has been instrumental in the sequencing of complete DNA sequences, or [[genomes]], of numerous types and species of life, including the [[human genome]] and other complete DNA sequences of many animal, plant, and microbial species.
[[File:Radioactive Fluorescent Seq.jpg|thumbnail|An example of the results of automated chain-termination DNA sequencing.]]

The first DNA sequences were obtained in the early 1970s by academic researchers using laborious methods based on [[two-dimensional chromatography]]. Following the development of [[fluorescence]]-based sequencing methods with a [[DNA sequencer]],&lt;ref name=olsvik1993&gt;{{cite journal | vauthors = Olsvik O, Wahlberg J, Petterson B, Uhlén M, Popovic T, Wachsmuth IK, Fields PI | title = Use of automated sequencing of polymerase chain reaction-generated amplicons to identify three types of cholera toxin subunit B in Vibrio cholerae O1 strains | journal = [[J. Clin. Microbiol.]] | volume = 31 | issue = 1 | pages = 22–25 | date = January 1993 | pmid = 7678018 | pmc = 262614 | url = http://jcm.asm.org/cgi/pmidlookup?view=long&amp;pmid=7678018 }}{{open access}}&lt;/ref&gt; DNA sequencing has become easier and orders of magnitude faster.&lt;ref name="pmid18992322"&gt;{{cite journal | vauthors = Pettersson E, Lundeberg J, Ahmadian A | title = Generations of sequencing technologies | journal = Genomics | volume = 93 | issue = 2 | pages = 105–11 | date = February 2009 | pmid = 18992322 | doi = 10.1016/j.ygeno.2008.10.003 }}&lt;/ref&gt;

== Applications ==
DNA sequencing may be used to determine the sequence of individual [[gene]]s, larger genetic regions (i.e. clusters of genes or [[operons]]), full chromosomes, or [[Whole genome sequencing|entire genomes]] of any organism.  DNA sequencing is also the most efficient way to indirectly sequence [[RNA]] or [[protein]]s (via their [[open reading frame]]s). In fact, DNA sequencing has become a key technology in many areas of biology and other sciences such as medicine, [[forensics]], and [[anthropology]].

=== Molecular biology ===
Sequencing is used in [[molecular biology]] to study genomes and the proteins they encode. Information obtained using sequencing allows researchers to identify changes in genes, associations with diseases and phenotypes, and identify potential drug targets.

=== Evolutionary biology ===
Since DNA is an informative macromolecule in terms of transmission from one generation to another, DNA sequencing is used in [[evolutionary biology]] to study how different organisms are related and how they evolved.

=== Metagenomics ===
{{Main|Metagenomics}}
The field of [[metagenomics]] involves identification of organisms present in a body of water, [[sewage]], dirt, debris filtered from the air, or swab samples from organisms. Knowing which organisms are present in a particular environment is critical to research in [[ecology]], [[epidemiology]], [[microbiology]], and other fields. Sequencing enables researchers to determine which types of microbes may be present in a [[microbiome]], for example.

=== Medicine ===
Medical technicians may sequence genes (or, theoretically, full genomes) from patients to determine if there is risk of genetic diseases. This is a form of [[genetic testing]], though some genetic tests may not involve DNA sequencing.

=== Forensics ===
DNA sequencing may be used along with [[DNA profiling]] methods for [[forensic identification]]&lt;ref&gt;{{Cite news|url=https://theconversation.com/from-the-crime-scene-to-the-courtroom-the-journey-of-a-dna-sample-82250|title=From the crime scene to the courtroom: the journey of a DNA sample|last=Curtis|first=Caitlin|date=29 August 2017|work=The Conversation|access-date=|archive-url=|archive-date=|dead-url=|last2=Hereward|first2=James}}&lt;/ref&gt; and [[DNA paternity testing|paternity testing]]. DNA testing has evolved tremendously in the last few decades to ultimately link a DNA print to what is under investigation. The DNA patterns in fingerprint, saliva, hair follicles, etc. uniquely separate each living organism from another. Testing DNA is a technique which can detect specific genomes in a DNA strand to produce a unique and individualized pattern. Every living organism ever created has a one of a kind DNA pattern, which can be determined through DNA testing. It is extremely rare that two people have exactly the same DNA pattern, therefore DNA testing is highly successful.

== The four canonical bases ==
{{Main|Nucleotide}}
The canonical structure of DNA has four bases: [[thymine]] (T), [[adenine]] (A), [[cytosine]] (C), and [[guanine]] (G). DNA sequencing is the determination of the physical order of these bases in a molecule of DNA. However, there are many other bases that may be present in a molecule. In some viruses (specifically, [[bacteriophage]]), cytosine may be replaced by hydroxy methyl or hydroxy methyl glucose cytosine.&lt;ref&gt;{{cite journal|last1=Moréra|first1=Solange|last2=Larivière|first2=Laurent|last3=Kurzeck|first3=Jürgen|last4=Aschke-Sonnenborn|first4=Ursula|last5=Freemont|first5=Paul S|last6=Janin|first6=Joël|last7=Rüger|first7=Wolfgang|title=High resolution crystal structures of T4 phage β-glucosyltransferase: induced fit and effect of substrate and metal binding|journal=Journal of Molecular Biology|date=August 2001|volume=311|issue=3|pages=569–77|doi=10.1006/jmbi.2001.4905|pmid=11493010}}&lt;/ref&gt; In mammalian DNA, variant bases with [[methyl]] groups or phosphosulfate may be found.&lt;ref&gt;{{cite journal|last1=Ehrlich|first1=Melanie|last2=Gama-Sosa|first2=Miguel A.|last3=Huang|first3=Lan-Hsiang|last4=Midgett|first4=Rose Marie|last5=Kuo|first5=Kenneth C.|last6=McCune|first6=Roy A.|last7=Gehrke|first7=Charles|title=Amount and distribution of 5-methylcytosine in human DNA from different types of tissues or cells|journal=Nucleic Acids Research|date=1982|volume=10|issue=8|pages=2709–21|doi=10.1093/nar/10.8.2709|pmid=7079182|pmc=320645}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Ehrlich|first1=M|last2=Wang|first2=R.|title=5-Methylcytosine in eukaryotic DNA|journal=Science|date=19 June 1981|volume=212|issue=4501|pages=1350–57|doi=10.1126/science.6262918|pmid=6262918|bibcode = 1981Sci...212.1350E }}&lt;/ref&gt; Depending on the sequencing technique, a particular modification, e.g., the 5mC ([[5 methyl cytosine]]) common in humans, may or may not be detected.&lt;ref&gt;{{cite journal|last1=Song|first1=Chun-Xiao|last2=Clark|first2=Tyson A|last3=Lu|first3=Xing-Yu|last4=Kislyuk|first4=Andrey|last5=Dai|first5=Qing|last6=Turner|first6=Stephen W|last7=He|first7=Chuan|last8=Korlach|first8=Jonas|title=Sensitive and specific single-molecule sequencing of 5-hydroxymethylcytosine|journal=Nature Methods|date=20 November 2011|volume=9|issue=1|pages=75–77|doi=10.1038/nmeth.1779|pmid=22101853|pmc=3646335}}&lt;/ref&gt;

==History==
=== Discovery of DNA structure and function ===
Deoxyribonucleic acid ([[DNA]]) was first discovered and isolated by [[Friedrich Miescher]] in 1869, but it remained understudied for many decades because proteins, rather than DNA, were thought to hold the genetic blueprint to life. This situation changed after 1944 as a result of some experiments by [[Oswald Avery]], [[Colin Munro MacLeod|Colin MacLeod]], and [[Maclyn McCarty]] demonstrating that purified DNA could change one strain of bacteria into another. This was the first time that DNA was shown capable of transforming the properties of cells.

In 1953, [[James Watson]] and [[Francis Crick]] put forward their [[double-helix]] model of DNA, based on [[X-ray crystallography|crystallized X-ray]] structures being studied by [[Rosalind Franklin]] – and without crediting her. According to the model, DNA is composed of two strands of nucleotides coiled around each other, linked together by hydrogen bonds and running in opposite directions. Each strand is composed of four complementary nucleotides – adenine (A), cytosine (C), guanine (G) and thymine (T) – with an A on one strand always paired with T on the other, and C always paired with G. They proposed such a structure allowed each strand to be used to reconstruct the other, an idea central to the passing on of hereditary information between generations.&lt;ref name="pmid13168976"&gt;{{cite journal | vauthors = Watson JD, Crick FH | title = The structure of DNA | journal = Cold Spring Harb. Symp. Quant. Biol. | volume = 18 | issue =  | pages = 123–31 | year = 1953 | pmid = 13168976 | doi = 10.1101/SQB.1953.018.01.020 }}&lt;/ref&gt;
[[File:Frederick Sanger2.jpg|thumb|[[Frederick Sanger]], a pioneer of sequencing. Sanger is one of the few scientists who was awarded two Nobel prizes, one for the [[Protein sequencing|sequencing of proteins]], and the other for the sequencing of DNA.]]
The foundation for sequencing proteins was first laid by the work of [[Frederick Sanger]] who by 1955 had completed the sequence of all the amino acids in [[insulin]], a small protein secreted by the pancreas. This provided the first conclusive evidence that proteins were chemical entities with a specific molecular pattern rather than a random mixture of material suspended in fluid. Sanger's success in sequencing insulin greatly electrified x-ray crystallographers, including Watson and Crick who by now were trying to understand how DNA directed the formation of proteins within a cell. Soon after attending a series of lectures given by Frederick Sanger in October 1954, Crick began to develop a theory which argued that the arrangement of nucleotides in DNA determined the sequence of amino acids in proteins which in turn helped determine the function of a protein. He published this theory in 1958.&lt;ref&gt;[http://www.whatisbiotechnology.org/exhibitions/sanger/path Marks, L, The path to DNA sequencing: The life and work of Frederick Sanger].&lt;/ref&gt;

===RNA sequencing===
[[RNA sequencing]] was one of the earliest forms of nucleotide sequencing. The major landmark of RNA sequencing is the sequence of the first complete gene and the complete genome of [[Bacteriophage MS2]], identified and published by [[Walter Fiers]] and his coworkers at the [[University of Ghent]] ([[Ghent]], [[Belgium]]), in 1972&lt;ref&gt;{{cite journal | vauthors = Min Jou W, Haegeman G, Ysebaert M, Fiers W | title = Nucleotide sequence of the gene coding for the bacteriophage MS2 coat protein | journal = Nature | volume = 237 | issue = 5350 | pages = 82–8 | date = May 1972 | pmid = 4555447 | doi = 10.1038/237082a0 | bibcode = 1972Natur.237...82J }}&lt;/ref&gt; and 1976.&lt;ref&gt;{{cite journal | vauthors = Fiers W, Contreras R, Duerinck F, Haegeman G, Iserentant D, Merregaert J, Min Jou W, Molemans F, Raeymaekers A, Van den Berghe A, Volckaert G, Ysebaert M | title = Complete nucleotide sequence of bacteriophage MS2 RNA: primary and secondary structure of the replicase gene | journal = Nature | volume = 260 | issue = 5551 | pages = 500–7 | date = April 1976 | pmid = 1264203 | doi = 10.1038/260500a0 | bibcode = 1976Natur.260..500F }}&lt;/ref&gt; Traditional RNA sequencing methods require the creation of a [[Complementary DNA|cDNA]] molecule which must be sequenced.&lt;ref&gt;{{Cite journal|last=Ozsolak|first=Fatih|last2=Milos|first2=Patrice M.|date=2011-02-01|title=RNA sequencing: advances, challenges and opportunities|url=http://www.nature.com/nrg/journal/v12/n2/full/nrg2934.html|journal=Nature Reviews Genetics|language=en|volume=12|issue=2|pages=87–98|doi=10.1038/nrg2934|issn=1471-0056|pmc=3031867|pmid=21191423}}&lt;/ref&gt;

===Early DNA sequencing methods===
The first method for determining DNA sequences involved a location-specific primer extension strategy established by [[Ray Wu]] at [[Cornell University]] in 1970.&lt;ref&gt;{{cite web|url=http://www.mbg.cornell.edu/faculty-staff/faculty/wu.cfm|title=Ray Wu Faculty Profile|archiveurl=https://web.archive.org/web/20090304121126/http://www.mbg.cornell.edu/faculty-staff/faculty/wu.cfm|archivedate=2009-03-04|publisher=Cornell University}}&lt;/ref&gt; DNA polymerase catalysis and specific nucleotide labeling, both of which figure prominently in current sequencing schemes, were used to sequence the cohesive ends of lambda phage DNA.&lt;ref&gt;{{cite journal|last=Padmanabhan|first=R|author2=Ray Wu |author3=Ernest Jay |title=Chemical Synthesis of a Primer and Its Use in the Sequence Analysis of the Lysozyme Gene of Bacteriophage T4|journal=Proceedings of the National Academy of Sciences|date=June 1974|volume=71|issue=6|pages=2510–14|doi=10.1073/pnas.71.6.2510|bibcode=1974PNAS...71.2510P|pmc=388489}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Onaga LA | title = Ray Wu as Fifth Business: Demonstrating Collective Memory in the History of DNA Sequencing | journal = Studies in the History and Philosophy of Science | volume = 46 | pages = 1–14 | date = June 2014 | pmid = 24565976 | doi = 10.1016/j.shpsc.2013.12.006 | series = Part C }}&lt;/ref&gt;&lt;ref name="pmid4553110"&gt;{{cite journal | vauthors = Wu R | title = Nucleotide sequence analysis of DNA | journal = Nature New Biology | volume = 236 | issue = 68 | pages = 198–200 | year = 1972 | pmid = 4553110 | doi = 10.1038/newbio236198a0 }}&lt;/ref&gt;  Between 1970 and 1973, Wu, R Padmanabhan and colleagues demonstrated that this method can be employed to determine any DNA sequence using synthetic location-specific primers.&lt;ref name="pmid4560009"&gt;{{cite journal | vauthors = Padmanabhan R, Wu R | title = Nucleotide sequence analysis of DNA. IX. Use of oligonucleotides of defined sequence as primers in DNA sequence analysis | journal = Biochem. Biophys. Res. Commun. | volume = 48 | issue = 5 | pages = 1295–302 | year = 1972 | pmid = 4560009 | doi = 10.1016/0006-291X(72)90852-2| url = }}&lt;/ref&gt;&lt;ref name="pmid4358929"&gt;{{cite journal | vauthors = Wu R, Tu CD, Padmanabhan R | title = Nucleotide sequence analysis of DNA. XII. The chemical synthesis and sequence analysis of a dodecadeoxynucleotide which binds to the endolysin gene of bacteriophage lambda | journal = Biochem. Biophys. Res. Commun. | volume = 55 | issue = 4 | pages = 1092–99 | year = 1973 | pmid = 4358929 | doi = 10.1016/S0006-291X(73)80007-5}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Jay E, Bambara R, Padmanabhan R, Wu R | title = DNA sequence analysis: a general, simple and rapid method for sequencing large oligodeoxyribonucleotide fragments by mapping | journal = Nucleic Acids Research | volume = 1 | issue = 3 | pages = 331–53 | date = March 1974 | pmid = 10793670 | pmc = 344020 | doi = 10.1093/nar/1.3.331 }}&lt;/ref&gt; [[Frederick Sanger]] then adopted this primer-extension strategy to develop more rapid DNA sequencing methods at the [[Medical Research Council (United Kingdom)|MRC Centre]], [[Cambridge]], UK and published a method for "DNA sequencing with chain-terminating inhibitors" in 1977.&lt;ref name="Sanger1977" /&gt; [[Walter Gilbert]] and [[Allan Maxam]] at [[Harvard University|Harvard]] also developed sequencing methods, including one for "DNA sequencing by chemical degradation".&lt;ref name=Maxam77/&gt;&lt;ref&gt;Gilbert, W. [http://nobelprize.org/nobel_prizes/chemistry/laureates/1980/gilbert-lecture.pdf DNA sequencing and gene structure]. Nobel lecture, 8 December 1980.&lt;/ref&gt; In 1973, Gilbert and Maxam reported the sequence of 24 basepairs using a method known as wandering-spot analysis.&lt;ref&gt;{{cite journal | vauthors = Gilbert W, Maxam A | title = The Nucleotide Sequence of the lac Operator | journal = Proc. Natl. Acad. Sci. U.S.A. | volume = 70 | issue = 12 | pages = 3581–84 | date = December 1973 | pmid = 4587255 | pmc = 427284 | doi = 10.1073/pnas.70.12.3581 | bibcode = 1973PNAS...70.3581G }}&lt;/ref&gt; Advancements in sequencing were aided by the concurrent development of [[recombinant DNA]] technology, allowing DNA samples to be isolated from sources other than viruses.

=== Sequencing of full genomes ===
[[File:Genome map of the bacteriophage ΦX174 showing overlapping genes.svg|thumb|300px|Right|The 5,386 bp genome of [[bacteriophage φX174]]. Each coloured block represents a gene.]]
The first full DNA genome to be sequenced was that of [[bacteriophage φX174]] in 1977.&lt;ref&gt;{{cite journal | vauthors = Sanger F, Air GM, Barrell BG, Brown NL, Coulson AR, Fiddes CA, Hutchison CA, Slocombe PM, Smith M | title = Nucleotide sequence of bacteriophage phi X174 DNA | journal = Nature | volume = 265 | issue = 5596 | pages = 687–95 | date = February 1977 | pmid = 870828 | doi = 10.1038/265687a0 | bibcode = 1977Natur.265..687S }}&lt;/ref&gt; [[Medical Research Council (UK)|Medical Research Council]] scientists deciphered the complete DNA sequence of the [[Epstein-Barr virus]] in 1984, finding it contained 172,282 nucleotides. Completion of the sequence marked a significant turning point in DNA sequencing because it was achieved with no prior genetic profile knowledge of the virus.&lt;ref&gt;[http://www.whatisbiotechnology.org/exhibitions/sanger/sequencing "The Next Frontier: Human Viruses"] , whatisbiotechnology.org, Retrieved 3 May 2017&lt;/ref&gt;

A non-radioactive method for transferring the DNA molecules of sequencing reaction mixtures onto an immobilizing matrix during electrophoresis was developed by Pohl and co-workers in the early 1980s.&lt;ref&gt;{{cite journal | vauthors = Beck S, Pohl FM | title = DNA sequencing with direct blotting electrophoresis | journal = EMBO J | volume = 3 | issue = 12 | pages = 2905–09 | year = 1984 | pmid = 6396083 | pmc = 557787 }}&lt;/ref&gt;&lt;ref&gt;United States Patent 4,631,122 (1986)&lt;/ref&gt; Followed by the commercialization of the DNA sequencer "Direct-Blotting-Electrophoresis-System GATC 1500" by [[GATC Biotech]], which was intensively used in the framework of the EU genome-sequencing programme, the complete DNA sequence of the yeast ''[[Saccharomyces cerevisiae]]'' chromosome II.&lt;ref name = "Feldmann_1994"/&gt; [[Leroy E. Hood]]'s laboratory at the [[California Institute of Technology]] announced the first semi-automated DNA sequencing machine in 1986.&lt;ref&gt;{{cite journal | vauthors = Smith LM, Sanders JZ, Kaiser RJ, Hughes P, Dodd C, Connell CR, Heiner C, Kent SB, Hood LE | title = Fluorescence Detection in Automated DNA Sequence Analysis | journal = Nature | volume = 321 | issue = 6071 | pages = 674–79 | date = 12 June 1986 | pmid = 3713851 | doi = 10.1038/321674a0 | bibcode = 1986Natur.321..674S }}&lt;/ref&gt; This was followed by [[Applied Biosystems]]' marketing of the first fully automated sequencing machine, the ABI 370, in 1987 and by Dupont's Genesis 2000&lt;ref&gt;{{cite journal | vauthors = Prober JM, Trainor GL, Dam RJ, Hobbs FW, Robertson CW, Zagursky RJ, Cocuzza AJ, Jensen MA, Baumeister K | title = A system for rapid DNA sequencing with fluorescent chain-terminating dideoxynucleotides | journal = Science | volume = 238 | issue = 4825 | pages = 336–41 | date = 16 Oct 1987 | pmid = 2443975 | doi = 10.1126/science.2443975 | bibcode = 1987Sci...238..336P }}&lt;/ref&gt;  which used a novel fluorescent labeling technique enabling all four dideoxynucleotides to be identified in a single lane. By 1990, the U.S. [[National Institutes of Health]] (NIH) had begun large-scale sequencing trials on ''[[Mycoplasma capricolum]]'', ''[[Escherichia coli]]'', ''[[Caenorhabditis elegans]]'', and ''[[Saccharomyces cerevisiae]]'' at a cost of US$0.75 per base. Meanwhile, sequencing of human [[cDNA]] sequences called [[expressed sequence tag]]s began in [[Craig Venter]]'s lab, an attempt to capture the coding fraction of the [[human genome]].&lt;ref name="pmid2047873"&gt;{{cite journal | vauthors = Adams MD, Kelley JM, Gocayne JD, Dubnick M, Polymeropoulos MH, Xiao H, Merril CR, Wu A, Olde B, Moreno RF | title = Complementary DNA sequencing: expressed sequence tags and human genome project | journal = Science | volume = 252 | issue = 5013 | pages = 1651–56 | date = June 1991 | pmid = 2047873 | doi = 10.1126/science.2047873 | bibcode = 1991Sci...252.1651A }}&lt;/ref&gt; In 1995, Venter, [[Hamilton O. Smith|Hamilton Smith]], and colleagues at [[The Institute for Genomic Research]] (TIGR) published the first complete genome of a free-living organism, the bacterium ''[[Haemophilus influenzae]]''.  The circular chromosome contains 1,830,137 bases and its publication in the journal Science&lt;ref&gt;{{cite journal | vauthors = Fleischmann RD, Adams MD, White O, Clayton RA, Kirkness EF, Kerlavage AR, Bult CJ, Tomb JF, Dougherty BA, Merrick JM | title = Whole-genome random sequencing and assembly of ''Haemophilus influenzae Rd'' | journal = Science | volume = 269 | issue = 5223 | pages = 496–512 | date = July 1995 | pmid = 7542800 | doi = 10.1126/science.7542800 | bibcode = 1995Sci...269..496F }}&lt;/ref&gt; marked the first published use of whole-genome shotgun sequencing, eliminating the need for initial mapping efforts.

By 2001, shotgun sequencing methods had been used to produce a draft sequence of the human genome.&lt;ref name="Lander_2001"/&gt;&lt;ref name="Venter_2001"/&gt;

=== High-throughput sequencing (HTS) methods ===
Several new methods for DNA sequencing were developed in the mid to late 1990s and were implemented in commercial [[DNA sequencers]] by the year 2000. Together these were called the "next-generation" or "second-generation" sequencing (NGS) methods, in order to distinguish them from the aforementioned earlier methods, like Sanger Sequencing. In contrast to the first generation of sequencing, NGS technology is typically characterized by being highly scalable, allowing the entire genome to be sequenced at once. Usually, this is accomplished by fragmenting the genome into small pieces, randomly sampling for a fragment, and sequencing it using one of a variety of technologies, such as those described below. An entire genome is possible because multiple fragments are sequenced at once (giving it the name "massively parallel" sequencing) in an automated process.

NGS technology has tremendously empowered researchers to look for insights into health, anthropologists to investigate human origins, and is catalyzing the "[[Personalized medicine|Personalized Medicine]]" movement. However, it has also opened the door to more room for error. There are many software tools to carry out the computational analysis of NGS data, each with its own algorithm. Even the parameters within one software package can change the outcome of the analysis. In addition, the large quantities of data produced by DNA sequencing have also required development of new methods and programs for sequence analysis. Several efforts to develop standards in the NGS field have been attempted to address these challenges, most of which have been small-scale efforts arising from individual labs. Most recently, a large, organized, FDA-funded effort has culminated in the [[BioCompute Object|BioCompute]] standard.

On 26 October 1990, [[Roger Tsien]], Pepi Ross, Margaret Fahnestock and Allan J Johnston filed a patent describing stepwise ("base-by-base") sequencing with removable 3' blockers on DNA arrays (blots and single DNA molecules).&lt;ref name=TsienPatent&gt;{{cite web|url=http://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=19910516&amp;DB=EPODOC&amp;locale=en_EP&amp;CC=WO&amp;NR=9106678A1&amp;KC=A1&amp;ND=4|title=Espacenet – Bibliographic data|website=worldwide.espacenet.com}}&lt;/ref&gt;
In 1996, [[Pål Nyrén]] and his student [[Mostafa Ronaghi]] at the Royal Institute of Technology in [[Stockholm]] published their method of [[pyrosequencing]].&lt;ref name=Ronaghi&gt;{{cite journal | vauthors = Ronaghi M, Karamohamed S, Pettersson B, Uhlén M, Nyrén P | title = Real-time DNA sequencing using detection of pyrophosphate release | journal = Analytical Biochemistry | volume = 242 | issue = 1 | pages = 84–89 | year = 1996 | pmid = 8923969 | doi = 10.1006/abio.1996.0432 }}&lt;/ref&gt;

On 1 April 1997, Pascal Mayer and Laurent Farinelli submitted patents to the World Intellectual Property Organization describing DNA colony sequencing.&lt;ref name=DNA_colony_patents&gt;{{cite web| last = Kawashima | first = Eric H. | author2 = Laurent Farinelli | author3 = Pascal Mayer | title = Patent: Method of nucleic acid amplification | accessdate = 2012-12-22 | date = 2005-05-12 | url = http://www.patentlens.net/patentlens/patent/WO_1998_044151_A1/en/
| postscript = }}&lt;/ref&gt; The DNA sample preparation and random surface-PCR arraying methods described in this patent, coupled to Roger Tsien et al.'s "base-by-base" sequencing method, is now implemented in [[Illumina (company)|Illumina]]'s Hi-Seq genome sequencers.

In 1998, Phil Green and Brent Ewing of the University of Washington described their [[phred quality score]] for sequencer data analysis,&lt;ref&gt;{{cite journal|vauthors=Ewing B, Green P|date=March 1998|title=Base-calling of automated sequencer traces using phred. II. Error probabilities|url=http://www.genome.org/cgi/pmidlookup?view=long&amp;pmid=9521922|journal=Genome Res.|volume=8|issue=3|pages=186–94|doi=10.1101/gr.8.3.186|pmid=9521922}}&lt;/ref&gt; a landmark analysis technique that gained widespread adoption, and which is still the most common metric for assessing the accuracy of a sequencing platform.&lt;ref&gt;{{cite web|url=https://www.illumina.com/documents/products/technotes/technote_Q-Scores.pdf|title=Quality Scores for Next-Generation Sequencing|last=|first=|date=31 October 2011|website=Illumina|access-date=8 May 2018}}&lt;/ref&gt;

Lynx Therapeutics published and marketed [[Massively parallel signature sequencing]] (MPSS), in 2000. This method incorporated a parallelized, adapter/ligation-mediated, bead-based sequencing technology and served as the first commercially available "next-generation" sequencing method, though no [[DNA sequencers]] were sold to independent laboratories.&lt;ref name="Brenner_2000"&gt;{{cite journal | vauthors = Brenner S, Johnson M, Bridgham J, Golda G, Lloyd DH, Johnson D, Luo S, McCurdy S, Foy M, Ewan M, Roth R, George D, Eletr S, Albrecht G, Vermaas E, Williams SR, Moon K, Burcham T, Pallas M, DuBridge RB, Kirchner J, Fearon K, Mao J, Corcoran K | title = Gene expression analysis by massively parallel signature sequencing (MPSS) on microbead arrays | journal = Nature Biotechnology | volume = 18 | issue = 6 | pages = 630–34 | year = 2000 | pmid = 10835600 | doi = 10.1038/76469 }}&lt;/ref&gt;

== Basic methods ==

=== Maxam-Gilbert sequencing ===
{{Main|Maxam-Gilbert sequencing}}
[[Allan Maxam]] and [[Walter Gilbert]] published a DNA sequencing method in 1977 based on chemical modification of DNA and subsequent cleavage at specific bases.&lt;ref name=Maxam77&gt;{{cite journal | vauthors = Maxam AM, Gilbert W | title = A new method for sequencing DNA | journal = Proc. Natl. Acad. Sci. USA | volume = 74 | issue = 2 | pages = 560–64 | date = February 1977 | pmid = 265521 | pmc = 392330 | doi = 10.1073/pnas.74.2.560 | bibcode = 1977PNAS...74..560M }}&lt;/ref&gt;  Also known as chemical sequencing, this method allowed purified samples of double-stranded DNA to be used without further cloning.  This method's use of radioactive labeling and its technical complexity discouraged extensive use after refinements in the Sanger methods had been made.

Maxam-Gilbert sequencing requires radioactive labeling at one 5' end of the DNA and purification of the DNA fragment to be sequenced. Chemical treatment then generates breaks at a small proportion of one or two of the four nucleotide bases in each of four reactions (G, A+G, C, C+T). The concentration of the modifying chemicals is controlled to introduce on average one modification per DNA molecule. Thus a series of labeled fragments is generated, from the radiolabeled end to the first "cut" site in each molecule. The fragments in the four reactions are electrophoresed side by side in denaturing acrylamide gels for size separation. To visualize the fragments, the gel is exposed to X-ray film for autoradiography, yielding a series of dark bands each corresponding to a radiolabeled DNA fragment, from which the sequence may be inferred.&lt;ref name=Maxam77 /&gt;

=== Chain-termination methods ===
{{Main|Sanger sequencing}}
The [[Sanger sequencing|chain-termination method]] developed by [[Frederick Sanger]] and coworkers in 1977 soon became the method of choice, owing to its relative ease and reliability.&lt;ref name="Sanger1977"&gt;{{cite journal | vauthors = Sanger F, Nicklen S, Coulson AR | title = DNA sequencing with chain-terminating inhibitors | journal = Proc. Natl. Acad. Sci. USA | volume = 74 | issue = 12 | pages = 5463–77 | date = December 1977 | pmid = 271968 | pmc = 431765 | doi = 10.1073/pnas.74.12.5463 | bibcode = 1977PNAS...74.5463S }}&lt;/ref&gt;&lt;ref name=Sanger75&gt;{{cite journal | vauthors = Sanger F, Coulson AR | title = A rapid method for determining sequences in DNA by primed synthesis with DNA polymerase | journal = J. Mol. Biol. | volume = 94 | issue = 3 | pages = 441–48 | date = May 1975 | pmid = 1100841 | doi = 10.1016/0022-2836(75)90213-2 }}&lt;/ref&gt; When invented, the chain-terminator method used fewer toxic chemicals and lower amounts of radioactivity than the Maxam and Gilbert method.  Because of its comparative ease, the Sanger method was soon automated and was the method used in the first generation of [[DNA sequencer]]s.

Sanger sequencing is the method which prevailed from the 1980s until the mid-2000s. Over that period, great advances were made in the technique, such as fluorescent labelling, capillary electrophoresis, and general automation. These developments allowed much more efficient sequencing, leading to lower costs. The Sanger method, in mass production form, is the technology which produced the [[Human Genome Project|first human genome]] in 2001, ushering in the age of [[genomics]]. However, later in the decade, radically different approaches reached the market, bringing the cost per genome down from $100 million in 2001 to $10,000 in 2011.&lt;ref&gt;{{cite web |last=Wetterstrand |first=Kris |title=DNA Sequencing Costs: Data from the NHGRI Genome Sequencing Program (GSP) |publisher=[[National Human Genome Research Institute]] |accessdate=30 May 2013 |url=https://www.genome.gov/sequencingcosts }}&lt;/ref&gt;

== Advanced methods and ''de novo'' sequencing ==
[[File:DNA Sequencing gDNA libraries.jpg|thumb|right|Genomic DNA is fragmented into random pieces and cloned as a bacterial library. DNA from individual bacterial clones is sequenced and the sequence is assembled by using overlapping DNA regions.(click to expand)]] Large-scale sequencing often aims at sequencing very long DNA pieces, such as whole [[chromosome]]s, although large-scale sequencing can also be used to generate very large numbers of short sequences, such as found in [[phage display]]. For longer targets such as chromosomes, common approaches consist of cutting (with [[restriction enzyme]]s) or shearing (with mechanical forces) large DNA fragments into shorter DNA fragments. The fragmented DNA may then be [[clone (genetics)|cloned]] into a [[Vector DNA|DNA vector]] and amplified in a bacterial host such as ''[[Escherichia coli]]''. Short DNA fragments purified from individual bacterial colonies are individually sequenced and [[sequence assembly|assembled electronically]] into one long, contiguous sequence. Studies have shown that adding a size selection step to collect DNA fragments of uniform size can improve sequencing efficiency and accuracy of the genome assembly. In these studies, automated sizing has proven to be more reproducible and precise than manual gel sizing.&lt;ref name="pmid23147856"&gt;{{cite journal | vauthors = Quail MA, Gu Y, Swerdlow H, Mayho M | title = Evaluation and optimisation of preparative semi-automated electrophoresis systems for Illumina library preparation | journal = Electrophoresis | volume = 33 | issue = 23 | pages = 3521–28 | year = 2012 | pmid = 23147856 | doi = 10.1002/elps.201200128 }}&lt;/ref&gt;&lt;ref name="pmid22713159"&gt;{{cite journal | vauthors = Duhaime MB, Deng L, Poulos BT, Sullivan MB | title = Towards quantitative metagenomics of wild viruses and other ultra-low concentration DNA samples: a rigorous assessment and optimization of the linker amplification method | journal = Environ. Microbiol. | volume = 14 | issue = 9 | pages = 2526–37 | year = 2012 | pmid = 22713159 | pmc = 3466414 | doi = 10.1111/j.1462-2920.2012.02791.x }}&lt;/ref&gt;&lt;ref name="pmid22675423"&gt;{{cite journal | vauthors = Peterson BK, Weber JN, Kay EH, Fisher HS, Hoekstra HE | title = Double digest RADseq: an inexpensive method for de novo SNP discovery and genotyping in model and non-model species | journal = PLoS ONE | volume = 7 | issue = 5 | pages = e37135 | year = 2012 | pmid = 22675423 | pmc = 3365034 | doi = 10.1371/journal.pone.0037135 |bibcode = 2012PLoSO...737135P }}&lt;/ref&gt;

The term "''de novo'' sequencing" specifically refers to methods used to determine the sequence of DNA with no previously known sequence. ''De novo'' translates from Latin as "from the beginning". Gaps in the assembled sequence may be filled by [[primer walking]]. The different strategies have different tradeoffs in speed and accuracy; [[shotgun sequencing|shotgun methods]] are often used for sequencing large genomes, but its assembly is complex and difficult, particularly with [[Microsatellite (genetics)|sequence repeat]]s often causing gaps in genome assembly.

Most sequencing approaches use an ''in vitro'' cloning step to amplify individual DNA molecules, because their molecular detection methods are not sensitive enough for single molecule sequencing. Emulsion PCR&lt;ref name=Williams2006ePCR&gt;{{cite journal | vauthors = Williams R, Peisajovich SG, Miller OJ, Magdassi S, Tawfik DS, Griffiths AD | title = Amplification of complex gene libraries by emulsion PCR | journal = Nature Methods | volume = 3 | issue = 7 | pages = 545–50 | year = 2006 | pmid = 16791213 | doi = 10.1038/nmeth896 }}&lt;/ref&gt; isolates individual DNA molecules along with primer-coated beads in aqueous droplets within an oil phase. A [[polymerase chain reaction]] (PCR) then coats each bead with clonal copies of the DNA molecule followed by immobilization for later sequencing. Emulsion PCR is used in the methods developed by Marguilis et al. (commercialized by [[454 Life Sciences]]), Shendure and Porreca et al. (also known as "[[Polony (biology)|Polony sequencing]]") and [[ABI Solid Sequencing|SOLiD sequencing]], (developed by [[Agencourt]], later [[Applied Biosystems]], now [[Life Technologies (Thermo Fisher Scientific)|Life Technologies]]).&lt;ref name="Margulies_2005"/&gt;&lt;ref name=polony_sequencing&gt;{{cite journal | vauthors = Shendure J, Porreca GJ, Reppas NB, Lin X, McCutcheon JP, Rosenbaum AM, Wang MD, Zhang K, Mitra RD, Church GM | title = Accurate Multiplex Polony Sequencing of an Evolved Bacterial Genome | journal = Science | volume = 309 | issue = 5741 | pages = 1728–32 | year = 2005 | pmid = 16081699 | doi = 10.1126/science.1117389 | bibcode = 2005Sci...309.1728S }}&lt;/ref&gt;&lt;ref name=solid_sequencing&gt;{{cite web|url=http://solid.appliedbiosystems.com/|archiveurl=https://web.archive.org/web/20080516181322/http://solid.appliedbiosystems.com/|archivedate=2008-05-16|title=Applied Biosystems – File Not Found (404 Error)|date=16 May 2008|publisher=}}&lt;/ref&gt; Emulsion PCR is also used in the GemCode and Chromium platforms developed by 10x Genomics.&lt;ref name="10x-epcr"&gt;{{cite journal|last1=Goodwin|first1=Sara|last2=McPherson|first2=John D.|last3=McCombie|first3=W. Richard|title=Coming of age: ten years of next-generation sequencing technologies|journal=Nature Reviews Genetics|date=17 May 2016|volume=17|issue=6|pages=333–51|doi=10.1038/nrg.2016.49|pmid=27184599}}&lt;/ref&gt;

=== Shotgun sequencing ===
{{Main|Shotgun sequencing}}
Shotgun sequencing is a sequencing method designed for analysis of DNA sequences longer than 1000 base pairs, up to and including entire chromosomes.  This method requires the target DNA to be broken into random fragments.  After sequencing individual fragments, the sequences can be reassembled on the basis of their overlapping regions.&lt;ref&gt;{{cite journal | vauthors = Staden R | title = A strategy of DNA sequencing employing computer programs. | journal = Nucleic Acids Research | volume = 6 | issue = 7 | pages = 2601–10 | date = 11 Jun 1979 | pmid = 461197 | pmc = 327874 | doi = 10.1093/nar/6.7.2601 }}&lt;/ref&gt;

=== Bridge PCR ===
Another method for ''[[in vitro]]'' clonal amplification is bridge PCR, in which fragments are amplified upon primers attached to a solid surface&lt;ref name=DNA_colony_patents /&gt;&lt;ref name=DNA_colony_presentation&gt;P. Mayer,L. Farinelli, G. Matton, C. Adessi, G. Turcatti, J. J. Mermod, E. Kawashima.[http://www.slideshare.net/pascalmayer/dna-colony-massively-parrallel-sequencing-ams98-presentation DNA colony massively parallel sequencing ams98 presentation]&lt;/ref&gt;&lt;ref name=Mosaic_patent&gt;{{US patent|5641658}}&lt;/ref&gt; and form "[[#subsection Illumina (Solexa) sequencing|DNA colonies]]" or "DNA clusters". This method is used in the [[Illumina (company)|Illumina]] Genome Analyzer [[#subsection Illumina (Solexa) sequencing|sequencers]]. Single-molecule methods, such as that developed by [[Stephen Quake]]'s laboratory (later commercialized by [[Helicos Biosciences|Helicos]]) are an exception:  they use bright fluorophores and laser excitation to detect base addition events from individual DNA molecules fixed to a surface, eliminating the need for molecular amplification.&lt;ref&gt;{{cite journal | vauthors = Braslavsky I, Hebert B, Kartalov E, Quake SR | title = Sequence information can be obtained from single DNA molecules | journal = Proc. Natl. Acad. Sci. USA | volume = 100 | issue = 7 | pages = 3960–64 | date = April 2003 | pmid = 12651960 | pmc = 153030 | doi = 10.1073/pnas.0230489100 | bibcode = 2003PNAS..100.3960B }}&lt;/ref&gt;

== High-throughput methods ==
{{Anchor|Next-generation methods}} &lt;!-- NB. Next-generation sequencing redirects to this section --&gt;
[[File:Mapping Reads.png|thumb|right|Multiple, fragmented sequence reads must be assembled together on the basis of their overlapping areas.]]
High-throughput (formerly "next-generation") sequencing applies to genome sequencing, genome resequencing, [[transcriptome]] profiling ([[RNA-Seq]]), DNA-protein interactions ([[ChIP-sequencing]]), and [[epigenome]] characterization.&lt;ref name="pmid19900591"&gt;{{cite journal | vauthors = de Magalhães JP, Finch CE, Janssens G | title = Next-generation sequencing in aging research: emerging applications, problems, pitfalls and possible solutions | journal = [[Ageing Research Reviews]] | volume = 9 | issue = 3 | pages = 315–23 | year = 2010 | pmid = 19900591 | pmc = 2878865 | doi = 10.1016/j.arr.2009.10.006 }}&lt;/ref&gt; Resequencing is necessary, because the genome of a single individual of a species will not indicate all of the genome variations among other individuals of the same species.

The high demand for low-cost sequencing has driven the development of high-throughput sequencing technologies that [[multiplex (assay)|parallelize]] the sequencing process, producing thousands or millions of sequences concurrently.&lt;ref name="pmid23856935"&gt;{{cite journal | vauthors = Grada A | title = Next-generation sequencing: methodology and application | journal = J Invest Dermatol | volume = 133 | issue = 8 | pages = 1–4 | date = August 2013 | pmid = 23856935 | doi = 10.1038/jid.2013.248 }}&lt;/ref&gt;&lt;ref name=hall2007&gt;{{cite journal | vauthors = Hall N | title = Advanced sequencing technologies and their wider impact in microbiology | journal = [[J. Exp. Biol.]] | volume =  210| issue = Pt 9 | pages = 1518–25 | date = May 2007 | pmid = 17449817 | doi = 10.1242/jeb.001370 }}{{open access}}&lt;/ref&gt;&lt;ref name=church2006&gt;{{cite journal | vauthors = Church GM | title = Genomes for all | journal = [[Sci. Am.]] | volume = 294 | issue = 1 | pages = 46–54 | date = January 2006 | pmid = 16468433 | doi = 10.1038/scientificamerican0106-46 | authorlink1 = George M. Church | bibcode = 2006SciAm.294a..46C }}{{subscription required}}&lt;/ref&gt;  High-throughput sequencing technologies are intended to lower the cost of DNA sequencing beyond what is possible with standard dye-terminator methods.&lt;ref name="pmid18165802"&gt;{{cite journal | vauthors = Schuster SC | title = Next-generation sequencing transforms today's biology | journal = Nat. Methods | volume = 5 | issue = 1 | pages = 16–18 | date = January 2008 | pmid = 18165802 | doi = 10.1038/nmeth1156 }}&lt;/ref&gt;  In ultra-high-throughput sequencing as many as 500,000 sequencing-by-synthesis operations may be run in parallel.&lt;ref name=kalb1992&gt;{{cite book | title = Massively Parallel, Optical, and Neural Computing in the United States | first1 = Gilbert | last1 = Kalb | first2 = Robert | last2 = Moxley | publisher = [[IOS Press]] | year = 1992 | isbn = 978-90-5199-097-3 }}{{Page needed|date=June 2013}}&lt;/ref&gt;&lt;ref name=tenBosch2008&gt;{{cite journal | vauthors = ten Bosch JR, Grody WW | title = Keeping Up with the Next Generation | journal = The Journal of Molecular Diagnostics | volume = 10 | issue = 6 | pages = 484–92 | year = 2008 | pmid = 18832462 | pmc = 2570630 | doi = 10.2353/jmoldx.2008.080027 }}{{open access}}&lt;/ref&gt;&lt;ref name=Tucker2009&gt;{{cite journal | vauthors = Tucker T, Marra M, Friedman JM | title = Massively Parallel Sequencing: The Next Big Thing in Genetic Medicine | journal = The American Journal of Human Genetics | volume = 85 | issue = 2 | pages = 142–54 | year = 2009 | pmid = 19679224 | pmc = 2725244 | doi = 10.1016/j.ajhg.2009.06.022 }}{{open access}}&lt;/ref&gt;

{| class="wikitable" style="font-size:0.9em;"
|+ Comparison of high-throughput sequencing methods&lt;ref name=quail2012&gt;{{cite journal | vauthors = Quail MA, Smith M, Coupland P, Otto TD, Harris SR, Connor TR, Bertoni A, Swerdlow HP, Gu Y | title = A tale of three next generation sequencing platforms: comparison of Ion Torrent, Pacific Biosciences and illumina MiSeq sequencers | journal = [[BMC Genomics]] | volume = 13 | issue = 1 | page = 341 | date = 1 January 2012 | pmid = 22827831 | pmc = 3431227 | doi = 10.1186/1471-2164-13-341 }}{{open access}}&lt;/ref&gt;&lt;ref name=lin2012&gt;{{cite journal | vauthors = Liu L, Li Y, Li S, Hu N, He Y, Pong R, Lin D, Lu L, Law M | title = Comparison of Next-Generation Sequencing Systems | journal = Journal of Biomedicine and Biotechnology | volume = 2012 | pages = 1–11 | date = 1 January 2012 | pmid = 22829749 | doi = 10.1155/2012/251364 | pmc=3398667}}{{open access}}&lt;/ref&gt;
! Method !! '''Read length''' !! '''Accuracy (single read not consensus)''' !! '''Reads per run''' !! '''Time per run''' !! '''Cost per 1 million bases (in US$)''' !! '''Advantages''' !! '''Disadvantages''' 
|-
| '''Single-molecule real-time sequencing (Pacific Biosciences)''' ||30,000 bp ([[N50 statistic|N50]]);
maximum read length &gt;100,000 bases&lt;ref name="sequel21"&gt;{{cite web|url=https://www.pacb.com/blog/new-software-polymerase-sequel-system-boost-throughput-affordability/|title=New Software, Polymerase for Sequel System Boost Throughput and Affordability – PacBio|date=7 March 2018|publisher=}}&lt;/ref&gt;&lt;ref name="autogenerated1"&gt;{{cite web |url=http://www.genomeweb.com/sequencing/after-year-testing-two-early-pacbio-customers-expect-more-routine-use-rs-sequenc |title=After a Year of Testing, Two Early PacBio Customers Expect More Routine Use of RS Sequencer in 2012 |author=&lt;!--Staff writer(s); no by-line.--&gt; |date=10 January 2012 |publisher=GenomeWeb }}{{registration required}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://globenewswire.com/news-release/2013/10/03/577891/10051072/en/Pacific-Biosciences-Introduces-New-Chemistry-With-Longer-Read-Lengths-to-Detect-Novel-Features-in-DNA-Sequence-and-Advance-Genome-Studies-of-Large-Organisms.html|title=Pacific Biosciences Introduces New Chemistry With Longer Read Lengths to Detect Novel Features in DNA Sequence and Advance Genome Studies of Large Organisms|first=Pacific Biosciences,|last=Inc.|publisher=}}&lt;/ref&gt;
| 87% raw-read accuracy&lt;ref name="pmid23644548"&gt;{{cite journal | vauthors = Chin CS, Alexander DH, Marks P, Klammer AA, Drake J, Heiner C, Clum A, Copeland A, Huddleston J, Eichler EE, Turner SW, Korlach J | title = Nonhybrid, finished microbial genome assemblies from long-read SMRT sequencing data | journal = Nat. Methods | volume = 10 | issue = 6 | pages = 563–69 | year = 2013 | pmid = 23644548 | doi = 10.1038/nmeth.2474 }}&lt;/ref&gt;|| 500,000 per Sequel SMRT cell, 10–20 gigabases&lt;ref name="sequel21" /&gt;&lt;ref name="flxlexblog.wordpress.com"&gt;{{cite web|url=http://flxlexblog.wordpress.com/2013/07/05/de-novo-bacterial-genome-assembly-a-solved-problem/|title=De novo bacterial genome assembly: a solved problem?|date=5 July 2013|publisher=}}&lt;/ref&gt;&lt;ref name=rasko2011&gt;{{cite journal | vauthors = Rasko DA, Webster DR, Sahl JW, Bashir A, Boisen N, Scheutz F, Paxinos EE, Sebra R, Chin CS, Iliopoulos D, Klammer A, Peluso P, Lee L, Kislyuk AO, Bullard J, Kasarskis A, Wang S, Eid J, Rank D, Redman JC, Steyert SR, Frimodt-Møller J, Struve C, Petersen AM, Krogfelt KA, Nataro JP, Schadt EE, Waldor MK | title = Origins of the Strain Causing an Outbreak of Hemolytic–Uremic Syndrome in Germany | journal = [[N Engl J Med]] | volume = 365 | issue = 8 | pages = 709–17 | date = 25 August 2011 | pmid = 21793740 | doi = 10.1056/NEJMoa1106920 | pmc=3168948}}{{open access}}&lt;/ref&gt; || 30 minutes to 20 hours&lt;ref name="sequel21"/&gt;&lt;ref name=tran2012&gt;{{cite journal | vauthors = Tran B, Brown AM, Bedard PL, Winquist E, Goss GD, Hotte SJ, Welch SA, Hirte HW, Zhang T, Stein LD, Ferretti V, Watt S, Jiao W, Ng K, Ghai S, Shaw P, Petrocelli T, Hudson TJ, Neel BG, Onetto N, Siu LL, McPherson JD, Kamel-Reid S, Dancey JE | title = Feasibility of real time next generation sequencing of cancer genes linked to drug response: Results from a clinical trial | journal = [[Int. J. Cancer]] | volume = 132 | issue = 7 | pages = 1547–55 | date = 1 January 2012 | pmid = 22948899 | doi = 10.1002/ijc.27817 | authorlink18 = Thomas J. Hudson | authorlink10 = Lincoln Stein }}{{subscription required}}&lt;/ref&gt; || $0.05–$0.08 || Fast. Detects 4mC, 5mC, 6mA.&lt;ref&gt;{{cite journal | vauthors = Murray IA, Clark TA, Morgan RD, Boitano M, Anton BP, Luong K, Fomenkov A, Turner SW, Korlach J, Roberts RJ | title = The methylomes of six bacteria | journal = Nucleic Acids Research | volume = 40 | issue = 22 | pages = 11450–62 | date = 2 October 2012 | pmid = 23034806 | pmc = 3526280 | doi = 10.1093/nar/gks891 }}&lt;/ref&gt; || Moderate throughput. Equipment can be very expensive.
|-
| '''Ion semiconductor (Ion Torrent sequencing)''' || up to 600 bp&lt;ref&gt;{{cite web|url=https://www.thermofisher.com/order/catalog/product/A30670|title=Ion 520 &amp; Ion 530 ExT Kit-Chef – Thermo Fisher Scientific|website=www.thermofisher.com}}&lt;/ref&gt; || 99.6%&lt;ref&gt;[http://129.130.90.13/ion-docs/GUID-C6419130-57D8-4DE2-BCF8-47157CB3C9A2.html ]{{dead link|date=September 2018}}&lt;/ref&gt; || up to 80 million || 2 hours || $1 || Less expensive equipment. Fast. || Homopolymer errors.

|-
| '''Pyrosequencing (454)''' || 700 bp || 99.9% || 1 million || 24 hours || $10 || Long read size. Fast. || Runs are expensive. Homopolymer errors.

|-
| '''Sequencing by synthesis (Illumina)''' ||MiniSeq, NextSeq: 75–300 bp;
MiSeq: 50–600 bp;

HiSeq 2500: 50–500 bp;

HiSeq 3/4000: 50–300 bp;

HiSeq X: 300 bp
| 99.9% (Phred30) || MiniSeq/MiSeq: 1–25 Million;
NextSeq: 130-00 Million;

HiSeq 2500: 300 million – 2 billion;

HiSeq 3/4000 2.5 billion;

HiSeq X: 3 billion
| 1 to 11 days, depending upon sequencer and specified read length&lt;ref name=vliet2010&gt;{{cite journal | vauthors = van Vliet AH | title = Next generation sequencing of microbial transcriptomes: challenges and opportunities | journal = [[FEMS Microbiology Letters]] | volume = 302 | issue = 1 | pages = 1–7 | date = 1 January 2010 | pmid = 19735299 | doi = 10.1111/j.1574-6968.2009.01767.x }}{{open access}}&lt;/ref&gt; || $0.05 to $0.15 || Potential for high sequence yield, depending upon sequencer model and desired application. || Equipment can be very expensive. Requires high concentrations of DNA.
|-
|'''Combinatorial probe anchor synthesis (cPAS-  BGI/MGI)'''
|BGISEQ-50: 35-50bp;
MGISEQ 200: 50-200bp;

BGISEQ-500, MGISEQ-2000: 50-300bp&lt;ref&gt;{{cite web|url=http://en.mgitech.cn/product/30.html|title=BGI and MGISEQ|last=|first=|date=|website=en.mgitech.cn|archive-url=|archive-date=|dead-url=|access-date=2018-07-05}}&lt;/ref&gt;
|99.9% (Phred30)
|BGISEQ-50: 160M;
MGISEQ 200: 300M;

BGISEQ-500: 1300M per flow cell;

MGISEQ-2000: 375M FCS flow cell, 1500M FCL flow cell per flow cell.
|1 to 9 days depending on instrument, read length and number of flow cells run at a time.
|$0.035- $0.12
|
|
|-
| '''Sequencing by ligation (SOLiD sequencing)''' || 50+35 or 50+50 bp || 99.9% || 1.2 to 1.4 billion || 1 to 2 weeks || $0.13 || Low cost per base. || Slower than other methods. Has issues sequencing palindromic sequences.&lt;ref name="Yu-Feng Huang, Sheng-Chung Chen, Yih-Shien Chiang, Tzu-Han Chen &amp; Kuo-Ping Chiu 2012 S10"&gt;{{cite journal | vauthors = Huang YF, Chen SC, Chiang YS, Chen TH, Chiu KP | title = Palindromic sequence impedes sequencing-by-ligation mechanism | journal = [[BMC Systems Biology]] | volume = 6 Suppl 2 | pages = S10 | year = 2012 | pmid = 23281822 | doi = 10.1186/1752-0509-6-S2-S10 | pmc=3521181}}&lt;/ref&gt;
|-
| '''Nanopore Sequencing''' || Dependent on library prep, not the device, so user chooses read length. (up to 500 kb reported)  || ~92–97% single read || dependent on read length selected by user || data streamed in real time. Choose 1 min to 48 hrs || $500–999 per Flow Cell, base cost dependent on expt || Longest individual reads. Accessible user community. Portable (Palm sized).  || Lower throughput than other machines, Single read accuracy in 90s. 
|-
| '''Chain termination (Sanger sequencing)''' || 400 to 900 bp || 99.9% || N/A || 20 minutes to 3 hours || $2400 || Useful for many applications. || More expensive and impractical for larger sequencing projects. This method also requires the time consuming step of plasmid cloning or PCR.

|}

=== Massively parallel signature sequencing (MPSS) ===
The first of the high-throughput sequencing technologies, [[massively parallel signature sequencing]] (or MPSS), was developed in the 1990s at Lynx Therapeutics, a company founded in 1992 by [[Sydney Brenner]] and [[Applied Biosystems#History|Sam Eletr]]. MPSS was a bead-based method that used a complex approach of adapter ligation followed by adapter decoding, reading the sequence in increments of four nucleotides. This method made it susceptible to sequence-specific bias or loss of specific sequences. Because the technology was so complex, MPSS was only performed 'in-house' by Lynx Therapeutics and no DNA sequencing machines were sold to independent laboratories. Lynx Therapeutics merged with Solexa (later acquired by [[Illumina (company)|Illumina]]) in 2004, leading to the development of sequencing-by-synthesis, a simpler approach acquired from [[Manteia Predictive Medicine]], which rendered MPSS obsolete. However, the essential properties of the MPSS output were typical of later high-throughput data types, including hundreds of thousands of short DNA sequences. In the case of MPSS, these were typically used for sequencing [[cDNA]] for measurements of [[gene expression]] levels.&lt;ref name="Brenner_2000"/&gt;

=== Polony sequencing ===
{{Main|Polony sequencing}}
The [[Polony sequencing]] method, developed in the laboratory of [[George M. Church]] at Harvard, was among the first high-throughput sequencing systems and was used to sequence a full ''[[E. coli]]'' genome in 2005.&lt;ref name=Shendure2005&gt;{{cite journal | vauthors = Shendure J, Porreca GJ, Reppas NB, Lin X, McCutcheon JP, Rosenbaum AM, Wang MD, Zhang K, Mitra RD, Church GM | title = Accurate multiplex polony sequencing of an evolved bacterial genome. | journal = Science | volume = 309 | issue = 5741 | pages = 1728–32 | date = 9 Sep 2005 | pmid = 16081699 | doi = 10.1126/science.1117389 | bibcode = 2005Sci...309.1728S }}&lt;/ref&gt; It combined an in vitro paired-tag library with emulsion PCR, an automated microscope, and ligation-based sequencing chemistry to sequence an ''E. coli'' genome at an accuracy of &gt;99.9999% and a cost approximately 1/9 that of Sanger sequencing.&lt;ref name=Shendure2005 /&gt; The technology was licensed to Agencourt Biosciences, subsequently spun out into Agencourt Personal Genomics, and eventually incorporated into the [[Applied Biosystems]] SOLiD platform. Applied Biosystems was later acquired by [[Life Technologies (Thermo Fisher Scientific)|Life Technologies]], now part of [[Thermo Fisher Scientific]].

=== 454 pyrosequencing ===
{{Main|454 Life Sciences#Technology}}
A parallelized version of [[pyrosequencing]] was developed by [[454 Life Sciences]], which has since been acquired by [[Roche Diagnostics]]. The method amplifies DNA inside water droplets in an oil solution (emulsion PCR), with each droplet containing a single DNA template attached to a single primer-coated bead that then forms a clonal colony. The sequencing machine contains many [[picoliter]]-volume wells each containing a single bead and sequencing enzymes. Pyrosequencing uses [[luciferase]] to generate light for detection of the individual nucleotides added to the nascent DNA, and the combined data are used to generate sequence [[read (biology)|reads]].&lt;ref name="Margulies_2005"/&gt; This technology provides intermediate read length and price per base compared to Sanger sequencing on one end and Solexa and SOLiD on the other.&lt;ref name="pmid18165802"/&gt;

=== Illumina (Solexa) sequencing ===
{{Main|Illumina dye sequencing}}
[[Solexa]], now part of [[Illumina (company)|Illumina]], was founded by [[Shankar Balasubramanian]] and [[David Klenerman]] in 1998, and developed a sequencing method based on reversible dye-terminators technology, and engineered polymerases.&lt;ref name = "Bentley_2008"/&gt; The reversible terminated chemistry concept was invented by Bruno Canard and Simon Sarfati at the Pasteur Institute in Paris.&lt;ref&gt;{{Citation|last=Canard|first=Bruno|title=Novel derivatives usable for the sequencing of nucleic acids|date=13 Oct 1994|url=http://www.google.ge/patents/CA2158975A1|last2=Sarfati|first2=Simon|accessdate=2016-03-09}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Canard|first=Bruno|last2=Sarfati|first2=Robert S.|date=1994-10-11|title=DNA polymerase fluorescent substrates with reversible 3′-tags|url=http://www.sciencedirect.com/science/article/pii/0378111994902267|journal=Gene|volume=148|issue=1|pages=1–6|doi=10.1016/0378-1119(94)90226-7|pmid=7523248}}&lt;/ref&gt; It was developed internally at Solexa by those named on the relevant patents. In 2004, Solexa acquired the company [[Manteia Predictive Medicine]] in order to gain a massively parallel sequencing technology invented in 1997 by Pascal Mayer and Laurent Farinelli.&lt;ref name=DNA_colony_patents /&gt; It is based on "DNA Clusters" or "DNA colonies", which involves the clonal amplification of DNA on a surface. The cluster technology was co-acquired with Lynx Therapeutics of California. Solexa Ltd. later merged with Lynx to form Solexa Inc.

[[File:Illumina HiSeq 2500.jpg|thumb|An Illumina HiSeq 2500 sequencer]]

In this method, DNA molecules and primers are first attached on a slide or flow cell and amplified with [[polymerase]] so that local clonal DNA colonies, later coined "DNA clusters", are formed. To determine the sequence, four types of reversible terminator bases (RT-bases) are added and non-incorporated nucleotides are washed away. A camera takes images of the [[Fluorescent labeling|fluorescently labeled]] nucleotides. Then the dye, along with the terminal 3' blocker, is chemically removed from the DNA, allowing for the next cycle to begin. Unlike pyrosequencing, the DNA chains are extended one nucleotide at a time and image acquisition can be performed at a delayed moment, allowing for very large arrays of DNA colonies to be captured by sequential images taken from a single camera.

[[File:Illumina MiSeq sequencer.jpg|thumb|An Illumina MiSeq sequencer]]

Decoupling the enzymatic reaction and the image capture allows for optimal throughput and theoretically unlimited sequencing capacity.  With an optimal configuration, the ultimately reachable instrument throughput is thus dictated solely by the analog-to-digital conversion rate of the camera, multiplied by the number of cameras and divided by the number of pixels per DNA colony required for visualizing them optimally (approximately 10 pixels/colony). In 2012, with cameras operating at more than 10&amp;nbsp;MHz A/D conversion rates and available optics, fluidics and enzymatics, throughput can be multiples of 1 million nucleotides/second, corresponding roughly to 1 human genome equivalent at 1x [[Coverage (genetics)|coverage]] per hour per instrument, and 1 human genome re-sequenced (at approx. 30x) per day per instrument (equipped with a single camera).&lt;ref name="pmid18576944"&gt;{{cite journal | vauthors = Mardis ER | title = Next-generation DNA sequencing methods | journal = Annu Rev Genom Hum Genet | volume = 9 | issue =  | pages = 387–402 | year = 2008 | pmid = 18576944 | doi = 10.1146/annurev.genom.9.081307.164359 }}&lt;/ref&gt;

===Combinatorial probe anchor synthesis (cPAS)===

This method is an upgraded modification to combinatorial probe anchor ligation technology (cPAL) described by [[Complete Genomics]]&lt;ref name=":0"&gt;{{Cite journal|last=Drmanac|first=Radoje|last2=Sparks|first2=Andrew B.|last3=Callow|first3=Matthew J.|last4=Halpern|first4=Aaron L.|last5=Burns|first5=Norman L.|last6=Kermani|first6=Bahram G.|last7=Carnevali|first7=Paolo|last8=Nazarenko|first8=Igor|last9=Nilsen|first9=Geoffrey B.|date=2010-01-01|title=Human Genome Sequencing Using Unchained Base Reads on Self-Assembling DNA Nanoarrays|url=http://science.sciencemag.org/content/327/5961/78|journal=Science|language=en|volume=327|issue=5961|pages=78–81|doi=10.1126/science.1181498|issn=0036-8075|pmid=19892942|bibcode=2010Sci...327...78D}}&lt;/ref&gt; which has since become part of Chinese genomics company [[Beijing Genomics Institute|BGI]] in 2013.&lt;ref&gt;{{cite web|url=http://www.completegenomics.com/|title=About Us - Complete Genomics|last=brandonvd|website=Complete Genomics|language=en-US|access-date=2018-07-02}}&lt;/ref&gt; The two companies have refined the technology to allow for longer read lengths, reaction time reductions and faster time to results. In addition, data are now generated as contiguous full-length reads in the standard FASTQ file format and can be used as-is in most short-read-based bioinformatics analysis pipelines.&lt;ref name=":1"&gt;{{Cite journal|last=Huang|first=Jie|last2=Liang|first2=Xinming|last3=Xuan|first3=Yuankai|last4=Geng|first4=Chunyu|last5=Li|first5=Yuxiang|last6=Lu|first6=Haorong|last7=Qu|first7=Shoufang|last8=Mei|first8=Xianglin|last9=Chen|first9=Hongbo|date=2017-05-01|title=A reference human genome dataset of the BGISEQ-500 sequencer|url=https://academic.oup.com/gigascience/article/6/5/1/3098240|journal=GigaScience|language=en|volume=6|issue=5|pages=1–9|doi=10.1093/gigascience/gix024|pmc=5467036|pmid=28379488}}&lt;/ref&gt;{{citation needed|date=July 2018}}

The two technologies that form the basis for this high-throughput sequencing technology are [[DNA nanoball sequencing|DNA nanoballs]] (DNB) and patterned arrays for nanoball attachment to a solid surface.&lt;ref name=":0" /&gt; DNA nanoballs are simply formed by denaturing double stranded, adapter ligated libraries and ligating the forward strand only to a splint oligonucleotide to form a ssDNA circle. Faithful copies of the circles containing the DNA insert are produced utilizing Rolling Circle Amplification that generates approximately 300–500 copies. The long strand of ssDNA folds upon itself to produce a three-dimensional nanoball structure that is approximately 220 nm in diameter. Making DNBs replaces the need to generate PCR copies of the library on the flow cell and as such can remove large proportions of duplicate reads, adapter-adapter ligations and PCR induced errors.&lt;ref name=":1" /&gt;{{citation needed|date=July 2018}}
[[File:MGISEQ-2000RS.jpg|thumb|A BGI MGISEQ-2000RS sequencer]]
The patterned array of positively charged spots is fabricated through photolithography and etching techniques followed by chemical modification to generate a sequencing flow cell.  Each spot on the flow cell is approximately 250 nm in diameter, are separated by 700 nm  (centre to centre) and allows easy attachment of a single negatively charged DNB to the flow cell and thus reducing under or over-clustering on the flow cell.&lt;ref name=":0" /&gt;{{citation needed|date=July 2018}}

Sequencing is then performed by addition of an oligonucleotide probe that attaches in combination to specific sites within the DNB. The probe acts as an anchor that then allows one of four single reversibly inactivated, labelled nucleotides to bind after flowing across the flow cell. Unbound nucleotides are washed away before laser excitation of the attached labels then emit fluorescence and signal is captured by cameras that is converted to a digital output for base calling. The attached base has its terminator and label chemically cleaved at completion of the cycle. The cycle is repeated with another flow of free, labelled nucleotides across the flow cell to allow the next nucleotide to bind and have its signal captured. This process is completed a number of times (usually 50 to 300 times) to determine the sequence of the inserted piece of DNA at a rate of approximately 40 million nucleotides per second as of 2018.{{citation needed|date=July 2018}}

=== SOLiD sequencing ===
[[File:Library preparation for the SOLiD platform.svg|right|thumb|Library preparation for the SOLiD platform]]
{{Main|2 base encoding}}
[[Applied Biosystems]]' (now a [[Life Technologies (Thermo Fisher Scientific)|Life Technologies]] brand) SOLiD technology employs [[sequencing by ligation]]. Here, a pool of all possible oligonucleotides of a fixed length are labeled according to the sequenced position. Oligonucleotides are annealed and ligated; the preferential ligation by [[DNA ligase]] for matching sequences results in a signal informative of the nucleotide at that position. Before sequencing, the DNA is amplified by emulsion PCR. The resulting beads, each containing single copies of the same DNA molecule, are deposited on a glass slide.&lt;ref name="pmid18477713"&gt;{{cite journal | vauthors = Valouev A, Ichikawa J, Tonthat T, Stuart J, Ranade S, Peckham H, Zeng K, Malek JA, Costa G, McKernan K, Sidow A, Fire A, Johnson SM | title = A high-resolution, nucleosome position map of C. elegans reveals a lack of universal sequence-dictated positioning | journal = Genome Res. | volume = 18 | issue = 7 | pages = 1051–63 | date = July 2008 | pmid = 18477713 | pmc = 2493394 | doi = 10.1101/gr.076463.108 }}&lt;/ref&gt; The result is sequences of quantities and lengths comparable to Illumina sequencing.&lt;ref name="pmid18165802"/&gt; This [[sequencing by ligation]] method has been reported to have some issue sequencing palindromic sequences.&lt;ref name="Yu-Feng Huang, Sheng-Chung Chen, Yih-Shien Chiang, Tzu-Han Chen &amp; Kuo-Ping Chiu 2012 S10"/&gt;

=== Ion Torrent semiconductor sequencing ===
{{Main|Ion semiconductor sequencing}}
Ion Torrent Systems Inc. (now owned by [[Life Technologies (Thermo Fisher Scientific)|Life Technologies]]) developed a system based on using standard sequencing chemistry, but with a novel, semiconductor-based detection system. This method of sequencing is based on the detection of [[hydrogen ion]]s that are released during the [[DNA polymerase|polymerisation]] of [[DNA]], as opposed to the optical methods used in other sequencing systems. A microwell containing a template DNA strand to be sequenced is flooded with a single type of [[nucleotide]]. If the introduced nucleotide is [[complementarity (molecular biology)|complementary]] to the leading template nucleotide it is incorporated into the growing complementary strand. This causes the release of a hydrogen ion that triggers a hypersensitive ion sensor, which indicates that a reaction has occurred. If [[homopolymer]] repeats are present in the template sequence, multiple nucleotides will be incorporated in a single cycle. This leads to a corresponding number of released hydrogens and a proportionally higher electronic signal.&lt;ref name="rusk"&gt;{{cite journal | vauthors = Rusk N | year = 2011 | title = Torrents of sequence | url = | journal = Nat Methods | volume = 8 | issue = 1| page = 44 | doi=10.1038/nmeth.f.330}}&lt;/ref&gt;

[[File:From second to fourth-generation sequencing, illustration on TAGGCT template.svg|thumb|right| Sequencing of the TAGGCT template with IonTorrent, PacBioRS and GridION]]

=== DNA nanoball sequencing ===
{{Main|DNA nanoball sequencing}}
[[DNA nanoball sequencing]] is a type of high throughput sequencing technology used to determine the entire [[genomic sequence]] of an organism.  The company [[Complete Genomics]] uses this technology to sequence samples submitted by independent researchers.  The method uses [[rolling circle replication]] to amplify small fragments of genomic DNA into DNA nanoballs.  Unchained sequencing by ligation is then used to determine the nucleotide sequence.&lt;ref name = "Drmanac_2010" /&gt;  This method of DNA sequencing allows large numbers of DNA nanoballs to be sequenced per run and at low [[reagent]] costs compared to other high-throughput sequencing platforms.&lt;ref&gt;{{cite journal | vauthors = Porreca GJ | title = Genome Sequencing on Nanoballs | journal = Nature Biotechnology | volume = 28 | issue = 1 | pages = 43–44 | year = 2010 | pmid = 20062041 | doi = 10.1038/nbt0110-43 }}&lt;/ref&gt;  However, only short sequences of DNA are determined from each DNA nanoball which makes mapping the short reads to a [[reference genome]] difficult.&lt;ref name = "Drmanac_2010"/&gt; This technology has been used for multiple genome sequencing projects and is scheduled to be used for more.&lt;ref&gt;[https://web.archive.org/web/20100825003320/http://www.completegenomics.com/news-events/press-releases/ Complete Genomics] Press release, 2010&lt;/ref&gt;

=== Heliscope single molecule sequencing ===
{{Main|Helicos single molecule fluorescent sequencing}}
Heliscope sequencing is a method of single-molecule sequencing developed by [[Helicos Biosciences]]. It uses DNA fragments with added poly-A tail adapters which are attached to the flow cell surface. The next steps involve extension-based sequencing with cyclic washes of the flow cell with fluorescently labeled nucleotides (one nucleotide type at a time, as with the Sanger method). The reads are performed by the Heliscope sequencer.&lt;ref&gt;{{cite web|url=http://www.helicosbio.com/Products/HelicosregGeneticAnalysisSystem/HeliScopetradeSequencer/tabid/87/Default.aspx|archiveurl=https://web.archive.org/web/20091102041828/http://www.helicosbio.com/Products/HelicosregGeneticAnalysisSystem/HeliScopetradeSequencer/tabid/87/Default.aspx|archivedate=2009-11-02|title=HeliScope Gene Sequencing / Genetic Analyzer System : Helicos BioSciences|date=2 November 2009|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Thompson JF, Steinmann KE | title = Single molecule sequencing with a HeliScope genetic analysis system | journal = Current Protocols in Molecular Biology | volume = Chapter 7 | pages = Unit7.10 | date = October 2010 | pmid = 20890904 | pmc = 2954431 | doi = 10.1002/0471142727.mb0710s92 | isbn = 978-0471142720 }}&lt;/ref&gt; The reads are short, averaging 35 bp.&lt;ref&gt;{{cite web |url=http://seqll.com/technical-description/ |archive-url=https://web.archive.org/web/20140808055229/http://seqll.com/technical-description/ |dead-url=yes |archive-date=8 August 2014 |publisher=SeqLL |accessdate=9 Aug 2015 |title=tSMS SeqLL Technical Explanation}}&lt;/ref&gt; In 2009 a human genome was sequenced using the Heliscope, however in 2012 the company went bankrupt.&lt;ref&gt;{{cite book|url=https://link.springer.com/chapter/10.1007/978-1-4939-0715-1_6 |author1=Sara El-Metwally |title=Next Generation Sequencing Technologies and Challenges in Sequence Assembly |volume=7 |author2=Osama M. Ouda |author3=Mohamed Helmy |work=Next Generation Sequencing Technologies and Challenges in Sequence Assembly, Springer Briefs in Systems Biology Volume 7 |year=2014 |pages=51–59|doi=10.1007/978-1-4939-0715-1_6 |chapter=New Horizons in Next-Generation Sequencing |series=SpringerBriefs in Systems Biology |isbn=978-1-4939-0714-4 }}&lt;/ref&gt;

=== Single molecule real time (SMRT) sequencing ===
{{Main|Single molecule real time sequencing}}
SMRT sequencing is based on the sequencing by synthesis approach. The DNA is synthesized in zero-mode wave-guides (ZMWs)&amp;nbsp;– small well-like containers with the capturing tools located at the bottom of the well. The sequencing is performed with use of unmodified polymerase (attached to the ZMW bottom) and fluorescently labelled nucleotides flowing freely in the solution. The wells are constructed in a way that only the fluorescence occurring by the bottom of the well is detected. The fluorescent label is detached from the nucleotide upon its incorporation into the DNA strand, leaving an unmodified DNA strand. According to [[Pacific Biosciences]] (PacBio), the SMRT technology developer, this methodology allows detection of nucleotide modifications (such as cytosine methylation). This happens through the observation of polymerase kinetics. This approach allows reads of 20,000 nucleotides or more, with average read lengths of 5 kilobases.&lt;ref name="flxlexblog.wordpress.com"/&gt;&lt;ref&gt;{{cite web|url=http://www.genomeweb.com/sequencing/pacbio-sales-start-pick-company-delivers-product-enhancements|title=PacBio Sales Start to Pick Up as Company Delivers on Product Enhancements|publisher=}}&lt;/ref&gt; In 2015, Pacific Biosciences announced the launch of a new sequencing instrument called the Sequel System, with 1 million ZMWs compared to 150,000 ZMWs in the PacBio RS II instrument.&lt;ref&gt;{{cite web|url=http://www.bio-itworld.com/2015/9/30/pacbio-announces-sequel-sequencing-system.aspx|title=Bio-IT World|website=www.bio-itworld.com}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.genomeweb.com/business-news/pacbio-launches-higher-throughput-lower-cost-single-molecule-sequencing-system|title=PacBio Launches Higher-Throughput, Lower-Cost Single-Molecule Sequencing System|publisher=}}&lt;/ref&gt; SMRT sequencing is referred to as "[[Third-generation sequencing|third-generation]]" or "long-read" sequencing.

=== Nanopore DNA sequencing ===
{{Main|Nanopore sequencing}}
The DNA passing through the nanopore changes its ion current. This change is dependent on the shape, size and length of the DNA sequence. Each type of the nucleotide blocks the ion flow through the pore for a different period of time. The method does not require modified nucleotides and is performed in real time. Nanopore sequencing is referred to as "[[Third-generation sequencing|third-generation]]" or "long-read" sequencing, along with SMRT sequencing.

Early industrial research into this method was based on a technique called 'Exonuclease sequencing', where the readout of electrical signals occurring at nucleotides passing by [[hemolysin|alpha(α)-hemolysin]] pores covalently bound with [[cyclodextrin]].&lt;ref&gt;{{Cite journal|last=Clarke|first=James|last2=Wu|first2=Hai-Chen|last3=Jayasinghe|first3=Lakmal|last4=Patel|first4=Alpesh|last5=Reid|first5=Stuart|last6=Bayley|first6=Hagan|date=2009-04-01|title=Continuous base identification for single-molecule nanopore DNA sequencing|url=http://www.nature.com/nnano/journal/v4/n4/full/nnano.2009.12.html|journal=Nature Nanotechnology|language=en|volume=4|issue=4|pages=265–70|doi=10.1038/nnano.2009.12|issn=1748-3387|pmid=19350039|bibcode=2009NatNa...4..265C}}&lt;/ref&gt; However the subsequently commercial method, 'strand sequencing' sequencing DNA bases in an intact strand.

Two main areas of nanopore sequencing in development are solid state nanopore sequencing, and protein based nanopore sequencing. Protein nanopore sequencing utilizes membrane protein complexes such as α-hemolysin, MspA (''[[Mycobacterium smegmatis]]'' Porin A) or CssG, which show great promise given their ability to distinguish between individual and groups of nucleotides.&lt;ref name="Torre 2012"&gt;{{cite journal|year=2012|title=Fabrication and characterization of solid-state nanopore arrays for high-throughput DNA sequencing|journal=Nanotechnology|volume=23|issue=38|page=385308|bibcode=2012Nanot..23L5308D|doi=10.1088/0957-4484/23/38/385308|pmc=3557807|pmid=22948520|vauthors=dela Torre R, Larkin J, Singer A, Meller A}}&lt;/ref&gt; In contrast, solid-state nanopore sequencing utilizes synthetic materials such as silicon nitride and aluminum oxide and it is preferred for its superior mechanical ability and thermal and chemical stability.&lt;ref name="Pathak 2012"&gt;{{cite journal|year=2012|title=Double-functionalized nanopore-embedded gold electrodes for rapid DNA sequencing|url=|journal=Applied Physics Letters|volume=100|issue=2|page=023701|doi=10.1063/1.3673335|vauthors=Pathak B, Lofas H, Prasongkit J, Grigoriev A, Ahuja R, Scheicher RH|bibcode=2012ApPhL.100b3701P}}&lt;/ref&gt; The fabrication method is essential for this type of sequencing given that the nanopore array can contain hundreds of pores with diameters smaller than eight nanometers.&lt;ref name="Torre 2012" /&gt;

The concept originated from the idea that single stranded DNA or RNA molecules can be electrophoretically driven in a strict linear sequence through a biological pore that can be less than eight nanometers, and can be detected given that the molecules release an ionic current while moving through the pore.  The pore contains a detection region capable of recognizing different bases, with each base generating various time specific signals corresponding to the sequence of bases as they cross the pore which are then evaluated.&lt;ref name="Pathak 2012" /&gt; Precise control over the DNA transport through the pore is crucial for success. Various enzymes such as exonucleases and polymerases have been used to moderate this process by positioning them near the pore’s entrance.&lt;ref name="Korlach 2008"&gt;{{cite journal|year=2008|title=Selective aluminum passivation for targeted immobilization of single DNA polymerase molecules in zero-mode waveguide nanostructures|journal=Proceedings of the National Academy of Sciences|volume=105|issue=4|pages=1176–81|bibcode=2008PNAS..105.1176K|doi=10.1073/pnas.0710982105|pmc=2234111|pmid=18216253|vauthors=Korlach J, Marks PJ, Cicero RL, Gray JJ, Murphy DL, Roitman DB, Pham TT, Otto GA, Foquet M, Turner SW}}&lt;/ref&gt;

== Methods in development ==
DNA sequencing methods currently under development include reading the sequence as a DNA strand transits through [[nanopore sequencing|nanopores]] (a method that is now commercial but subsequent generations such as solid-state nanopores are still in development),&lt;ref&gt;{{cite web |url=http://mcb.harvard.edu/branton/index.htm |archive-url=https://web.archive.org/web/20020221002907/http://mcb.harvard.edu/branton/index.htm |dead-url=yes |archive-date=21 February 2002 |title=The Harvard Nanopore Group |publisher=Mcb.harvard.edu |accessdate=2009-11-15 |df=dmy-all }}&lt;/ref&gt;&lt;ref name="Physorg"&gt;{{cite web |url=http://www.physorg.com/news157378086.html |title=Nanopore Sequencing Could Slash DNA Analysis Costs |accessdate=}}&lt;/ref&gt; and microscopy-based techniques, such as [[Atomic force microscope|atomic force microscopy]] or [[Transmission electron microscopy DNA sequencing|transmission electron microscopy]] that are used to identify the positions of individual nucleotides within long DNA fragments (&amp;gt;5,000 bp) by nucleotide labeling with heavier elements (e.g., halogens) for visual detection and recording.&lt;ref&gt;{{US patent reference
|number=20060029957
|y=2005
|m=07
|d=14 |inventor=ZS Genetics
|title=Systems and methods of analyzing nucleic acid polymers and related components
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Xu M, Fujita D, Hanagata N | title = Perspectives and challenges of emerging single-molecule DNA sequencing technologies | journal = Small | volume = 5 | issue = 23 | pages = 2638–49 | date = December 2009 | pmid = 19904762 | doi = 10.1002/smll.200900976 }}&lt;/ref&gt;
[[Third-generation sequencing|Third generation technologies]] aim to increase throughput and decrease the time to result and cost by eliminating the need for excessive reagents and harnessing the processivity of DNA polymerase.&lt;ref&gt;{{cite journal | vauthors = Schadt EE, Turner S, Kasarskis A | title = A window into third-generation sequencing | journal = Human Molecular Genetics | volume = 19 | issue = R2 | pages = R227–40 | year = 2010 | pmid = 20858600 | doi = 10.1093/hmg/ddq416 }}&lt;/ref&gt;

=== Tunnelling currents DNA sequencing ===
Another approach uses measurements of the electrical tunnelling currents across single-strand DNA as it moves through a channel. Depending on its electronic structure, each base affects the tunnelling current differently,&lt;ref&gt;{{cite journal | vauthors = Xu M, Endres RG, Arakawa Y  | title = The electronic properties of DNA bases | journal = Small | volume = 3 | issue = 9 | pages = 1539–43 | year = 2007 | pmid = 17786897 | doi = 10.1002/smll.200600732}}&lt;/ref&gt; allowing differentiation between different bases.&lt;ref&gt;{{cite journal | vauthors = Di Ventra M | title = Fast DNA sequencing by electrical means inches closer | journal = Nanotechnology | volume = 24 | issue = 34 | page = 342501 | year = 2013 | pmid = 23899780 | doi = 10.1088/0957-4484/24/34/342501 | bibcode = 2013Nanot..24H2501D }}&lt;/ref&gt;

The use of tunnelling currents has the potential to sequence orders of magnitude faster than ionic current methods and the sequencing of several DNA oligomers and micro-RNA has already been achieved.&lt;ref name="pmid22787559"&gt;{{cite journal | vauthors = Ohshiro T, Matsubara K, Tsutsui M, Furuhashi M, Taniguchi M, Kawai T | title = Single-molecule electrical random resequencing of DNA and RNA | journal = Sci Rep | volume = 2 | issue = | page = 501 | year = 2012 | pmid = 22787559 | pmc = 3392642 | doi = 10.1038/srep00501 |bibcode = 2012NatSR...2E.501O }}&lt;/ref&gt;

=== Sequencing by hybridization ===
''[[Sequencing by hybridization]]'' is a non-enzymatic method that uses a [[DNA microarray]]. A single pool of DNA whose sequence is to be determined is fluorescently labeled and hybridized to an array containing known sequences. Strong hybridization signals from a given spot on the array identifies its sequence in the DNA being sequenced.&lt;ref&gt;{{cite journal | vauthors = Hanna GJ, Johnson VA, Kuritzkes DR, Richman DD, Martinez-Picado J, Sutton L, Hazelwood JD, D'Aquila RT | title = Comparison of Sequencing by Hybridization and Cycle Sequencing for Genotyping of Human Immunodeficiency Virus Type 1 Reverse Transcriptase | journal = J. Clin. Microbiol. | volume = 38 | issue = 7 | pages = 2715–21 | date = 1 July 2000 | pmid = 10878069 | pmc = 87006 | url = http://jcm.asm.org/cgi/pmidlookup?view=long&amp;pmid=10878069 }}&lt;/ref&gt;

This method of sequencing utilizes binding characteristics of a library of short single stranded DNA molecules (oligonucleotides), also called DNA probes, to reconstruct a target DNA sequence. Non-specific hybrids are removed by washing and the target DNA is eluted.&lt;ref name="Morey"&gt;{{cite journal | vauthors = Morey M, Fernández-Marmiesse A, Castiñeiras D, Fraga JM, Couce ML, Cocho JA | title = A glimpse into past, present, and future DNA sequencing | journal = Molecular Genetics and Metabolism | volume = 110 | issue = 1–2 | pages = 3–24 | year = 2013 | pmid = 23742747 | pmc =  | doi = 10.1016/j.ymgme.2013.04.024 }}&lt;/ref&gt; Hybrids are re-arranged such that the DNA sequence can be reconstructed. The benefit of this sequencing type is its ability to capture a large number of targets with a homogenous coverage.&lt;ref name="Qin"&gt;{{cite journal | vauthors = Qin Y, Schneider TM, Brenner MP | title = Sequencing by Hybridization of Long Targets | journal = PLoS ONE | volume = 7 | issue = 5 | pages = e35819 | year = 2012 | pmid = 22574124 | pmc = 3344849 | doi = 10.1371/journal.pone.0035819 | editor1-last = Gibas | bibcode = 2012PLoSO...735819Q | editor1-first = Cynthia }}&lt;/ref&gt; A large number of chemicals and starting DNA is usually required. However, with the advent of solution-based hybridization, much less equipment and chemicals are necessary.&lt;ref name="Morey"/&gt;

=== Sequencing with mass spectrometry ===
[[Mass spectrometry]] may be used to determine DNA sequences. Matrix-assisted laser desorption ionization time-of-flight mass spectrometry, or [[Matrix-assisted laser desorption/ionization|MALDI-TOF MS]], has specifically been investigated as an alternative method to gel electrophoresis for visualizing DNA fragments. With this method, DNA fragments generated by chain-termination sequencing reactions are compared by mass rather than by size. The mass of each nucleotide is different from the others and this difference is detectable by mass spectrometry. Single-nucleotide mutations in a fragment can be more easily detected with MS than by gel electrophoresis alone. MALDI-TOF MS can more easily detect differences between RNA fragments, so researchers may indirectly sequence DNA with MS-based methods by converting it to RNA first.&lt;ref&gt;{{cite journal | vauthors = Edwards JR, Ruparel H, Ju J | title = Mass-spectrometry DNA sequencing | journal = Mutation Research | volume = 573 | issue = 1–2 | pages = 3–12 | year = 2005 | pmid = 15829234 | doi = 10.1016/j.mrfmmm.2004.07.021 }}&lt;/ref&gt;

The higher resolution of DNA fragments permitted by MS-based methods is of special interest to researchers in forensic science, as they may wish to find [[single-nucleotide polymorphisms]] in human DNA samples to identify individuals. These samples may be highly degraded so forensic researchers often prefer [[mitochondrial DNA]] for its higher stability and applications for lineage studies. MS-based sequencing methods have been used to compare the sequences of human mitochondrial DNA from samples in a [[Federal Bureau of Investigation]] database&lt;ref&gt;{{cite journal | vauthors = Hall TA, Budowle B, Jiang Y, Blyn L, Eshoo M, Sannes-Lowery KA, Sampath R, Drader JJ, Hannis JC, Harrell P, Samant V, White N, Ecker DJ, Hofstadler SA | title = Base composition analysis of human mitochondrial DNA using electrospray ionization mass spectrometry: A novel tool for the identification and differentiation of humans | journal = Analytical Biochemistry | volume = 344 | issue = 1 | pages = 53–69 | year = 2005 | pmid = 16054106 | doi = 10.1016/j.ab.2005.05.028 }}&lt;/ref&gt; and from bones found in mass graves of World War I soldiers.&lt;ref&gt;{{cite journal | vauthors = Howard R, Encheva V, Thomson J, Bache K, Chan YT, Cowen S, Debenham P, Dixon A, Krause JU, Krishan E, Moore D, Moore V, Ojo M, Rodrigues S, Stokes P, Walker J, Zimmermann W, Barallon R | title = Comparative analysis of human mitochondrial DNA from World War I bone samples by DNA sequencing and ESI-TOF mass spectrometry | journal = Forensic Science International: Genetics | volume = 7 | issue = 1 | pages = 1–9 | date = 15 Jun 2011 | pmid = 21683667 | doi = 10.1016/j.fsigen.2011.05.009 }}&lt;/ref&gt;

Early chain-termination and TOF MS methods demonstrated read lengths of up to 100 base pairs.&lt;ref&gt;{{cite journal | vauthors = Monforte JA, Becker CH | title = High-throughput DNA analysis by time-of-flight mass spectrometry | journal = Nature Medicine | volume = 3 | issue = 3 | pages = 360–62 | date = 1 March 1997 | pmid = 9055869 | doi = 10.1038/nm0397-360 }}&lt;/ref&gt; Researchers have been unable to exceed this average read size; like chain-termination sequencing alone, MS-based DNA sequencing may not be suitable for large ''de novo'' sequencing projects. Even so, a recent study did use the short sequence reads and mass spectroscopy to compare single-nucleotide polymorphisms in pathogenic ''[[Streptococcus]]'' strains.&lt;ref&gt;{{cite journal | vauthors = Beres SB, Carroll RK, Shea PR, Sitkiewicz I, Martinez-Gutierrez JC, Low DE, McGeer A, Willey BM, Green K, Tyrrell GJ, Goldman TD, Feldgarden M, Birren BW, Fofanov Y, Boos J, Wheaton WD, Honisch C, Musser JM | title = Molecular complexity of successive bacterial epidemics deconvoluted by comparative pathogenomics | journal = Proceedings of the National Academy of Sciences | volume = 107 | issue = 9 | pages = 4371–76 | date = 8 February 2010 | pmid = 20142485 | pmc = 2840111 | doi = 10.1073/pnas.0911295107 | bibcode = 2010PNAS..107.4371B }}&lt;/ref&gt;

=== Microfluidic Sanger sequencing ===
{{Main|Sanger sequencing}}
In microfluidic Sanger sequencing the entire thermocycling amplification of DNA fragments as well as their separation by electrophoresis is done on a single glass wafer (approximately 10&amp;nbsp;cm in diameter) thus reducing the reagent usage as well as cost.&lt;ref&gt;{{cite journal | vauthors = Kan CW, Fredlake CP, Doherty EA, Barron AE | title = DNA sequencing and genotyping in miniaturized electrophoresis systems | journal = Electrophoresis | volume = 25 | issue = 21–22 | pages = 3564–88 | date = 1 November 2004 | pmid = 15565709 | doi = 10.1002/elps.200406161 }}&lt;/ref&gt; In some instances researchers have shown that they can increase the throughput of conventional sequencing through the use of microchips.&lt;ref&gt;{{cite journal | vauthors = Chen YJ, Roller EE, Huang X | title = DNA sequencing by denaturation: experimental proof of concept with an integrated fluidic device | journal = Lab on a Chip | volume = 10 | issue = 9 | pages = 1153–59 | year = 2010 | pmid = 20390134 | pmc = 2881221 | doi = 10.1039/b921417h }}&lt;/ref&gt; Research will still need to be done in order to make this use of technology effective.

=== Microscopy-based techniques ===
{{Main|Transmission electron microscopy DNA sequencing}}
This approach directly visualizes the sequence of DNA molecules using electron microscopy. The first identification of DNA base pairs within intact DNA molecules by enzymatically incorporating modified bases, which contain atoms of increased atomic number, direct visualization and identification of individually labeled bases within a synthetic 3,272 base-pair DNA molecule and a 7,249 base-pair viral genome has been demonstrated.&lt;ref&gt;{{cite journal | vauthors = Bell DC, Thomas WK, Murtagh KM, Dionne CA, Graham AC, Anderson JE, Glover WR | title = DNA Base Identification by Electron Microscopy | journal = Microscopy and Microanalysis : The Official Journal of Microscopy Society of America, Microbeam Analysis Society, Microscopical Society of Canada | volume = 18 | issue = 5 | pages = 1–5 | date = 9 Oct 2012 | pmid = 23046798 | doi = 10.1017/S1431927612012615 | bibcode = 2012MiMic..18.1049B }}&lt;/ref&gt;

=== RNAP sequencing ===
This method is based on use of [[RNA polymerase]] (RNAP), which is attached to a [[polystyrene]] bead. One end of DNA to be sequenced is attached to another bead, with both beads being placed in optical traps. RNAP motion during transcription brings the beads in closer and their relative distance changes, which can then be recorded at a single nucleotide resolution. The sequence is deduced based on the four readouts with lowered concentrations of each of the four nucleotide types, similarly to the Sanger method.&lt;ref&gt;{{cite journal | vauthors = Pareek CS, Smoczynski R, Tretyn A | title = Sequencing technologies and genome sequencing | journal = Journal of Applied Genetics | volume = 52 | issue = 4 | pages = 413–35 | date = November 2011 | pmid = 21698376 | pmc = 3189340 | doi = 10.1007/s13353-011-0057-x }}&lt;/ref&gt; A comparison is made between regions and sequence information is deduced by comparing the known sequence regions to the unknown sequence regions.&lt;ref name="Pareek CS"&gt;{{cite journal | vauthors = Pareek CS, Smoczynski R, Tretyn A | title = Sequencing technologies and genome sequencing | journal = Journal of Applied Genetics | volume = 52 | issue = 4 | pages = 413–35 | year = 2011 | pmid = 21698376 | pmc = 3189340 | doi = 10.1007/s13353-011-0057-x }}&lt;/ref&gt;

=== ''In vitro'' virus high-throughput sequencing ===
A method has been developed to analyze full sets of [[Interactome|protein interactions]] using a combination of 454 pyrosequencing and an  ''in vitro'' virus [[mRNA display]] method. Specifically, this method covalently links proteins of interest to the mRNAs encoding them, then detects the mRNA pieces using reverse transcription [[Polymerase chain reaction|PCR]]s. The mRNA may then be amplified and sequenced. The combined method was titled IVV-HiTSeq and can be performed under cell-free conditions, though its results may not be representative of ''in vivo'' conditions.&lt;ref&gt;{{cite journal | vauthors = Fujimori S, Hirai N, Ohashi H, Masuoka K, Nishikimi A, Fukui Y, Washio T, Oshikubo T, Yamashita T, Miyamoto-Sato E | title = Next-generation sequencing coupled with a cell-free display technology for high-throughput production of reliable interactome data | journal = Scientific Reports | volume = 2 | page = 691 | year = 2012 | pmid = 23056904 | pmc = 3466446 | doi = 10.1038/srep00691 | bibcode = 2012NatSR...2E.691F }}&lt;/ref&gt;

== Sample preparation ==
The success of any DNA sequencing protocol relies upon the DNA or RNA sample extraction and preparation from the biological material of interest.
* A successful DNA extraction will yield a DNA sample with long, non-degraded strands. 
* A successful RNA extraction will yield a RNA sample that should be converted to complementary DNA (cDNA) using reverse transcriptase—a DNA polymerase that synthesizes a complementary DNA based on existing strands of RNA in a PCR-like manner.&lt;ref&gt;{{cite journal | vauthors = Harbers M | year = 2008 | title = The Current Status of cDNA Cloning | url = | journal = Genomics | volume = 91 | issue = 3| pages = 232–42 | doi = 10.1016/j.ygeno.2007.11.004 | pmid = 18222633 }}&lt;/ref&gt; Complementary DNA can then be processed the same way as genomic DNA.

According to the sequencing technology to be used, the samples resulting from either the DNA or the RNA extraction require further preparation.  For Sanger sequencing, either cloning procedures or PCR are required prior to sequencing. In the case of next-generation sequencing methods, library preparation is required before processing.&lt;ref&gt;{{cite journal |vauthors=Alberti A, Belser C, Engelen S, Bertrand L, Orvain C, Brinas L, Cruaud C, etal | year = 2014 | title = Comparison of Library Preparation Methods Reveals Their Impact on Interpretation of Metatranscriptomic Data | journal = BMC Genomics | volume = 15 | issue = | pages = 912–12 | doi = 10.1186/1471-2164-15-912 | pmid=25331572 | pmc=4213505}}&lt;/ref&gt; Assessing the quality and quantity of nucleic acids both after extraction and after library preparation identifies degraded, fragmented, and low-purity samples and yields high-quality sequencing data.&lt;ref&gt;{{cite web| url= https://www.illumina.com/content/dam/illumina-marketing/documents/products/appnotes/library-qc-fragment-analyzer-application-note-770-2017-002.pdf|title=Scalable Nucleic Acid Quality Assessments for Illumina Next-Generation Sequencing Library Prep|accessdate=2017-12-27}}&lt;/ref&gt;

== Development initiatives ==
[[File:Historic cost of sequencing a human genome.svg|thumb|280px|Total cost of sequencing a human genome over time as calculated by the [[National Human Genome Research Institute|NHGRI]].]]
In October 2006, the [[X Prize Foundation]] established an initiative to promote the development of [[full genome sequencing]] technologies, called the [[Archon X Prize]], intending to award $10 million to "the first Team that can build a device and use it to sequence 100 human genomes within 10 days or less, with an accuracy of no more than one error in every 100,000 bases sequenced, with sequences accurately covering at least 98% of the genome, and at a recurring cost of no more than $10,000 (US) per genome."&lt;ref&gt;{{cite web|url=http://genomics.xprize.org/|title=Archon Genomics XPRIZE|website=Archon Genomics XPRIZE}}&lt;/ref&gt;

Each year the [[National Human Genome Research Institute]], or NHGRI, promotes grants for new research and developments in [[genomics]]. 2010 grants and 2011 candidates include continuing work in microfluidic, polony and base-heavy sequencing methodologies.&lt;ref&gt;{{cite web|url=http://www.genome.gov/10000004|title=Grant Information|website=National Human Genome Research Institute (NHGRI)}}&lt;/ref&gt;

== Computational challenges ==
The sequencing technologies described here produce raw data that needs to be assembled into longer sequences such as complete genomes ([[sequence assembly]]). There are many computational challenges to achieve this, such as the evaluation of the raw sequence data which is done by programs and algorithms such as [[Phred base calling|Phred]] and [[Phrap]]. Other challenges have to deal with [[Repetitive DNA|repetitive]] sequences that often prevent complete genome assemblies because they occur in many places of the genome. As a consequence, many sequences may not be assigned to particular [[chromosome]]s. The production of raw sequence data is only the beginning of its detailed [[Bioinformatics|bioinformatical]] analysis.&lt;ref name="pmid24727769"&gt;{{cite journal | vauthors = Severin J, Lizio M, Harshbarger J, Kawaji H, Daub CO, Hayashizaki Y, Bertin N, Forrest AR | title = Interactive visualization and analysis of large-scale sequencing datasets using ZENBU | journal = Nat. Biotechnol. | volume = 32 | issue = 3 | pages = 217–19 | year = 2014 | pmid = 24727769 | doi = 10.1038/nbt.2840 }}&lt;/ref&gt; Yet new methods for sequencing and correcting sequencing errors were developed.&lt;ref&gt;{{cite journal |vauthors=Shmilovici A, Ben-Gal I | title = Using a VOM model for reconstructing potential coding regions in EST sequences|journal=Computational Statistics | year = 2007 | volume = 22 | issue = 1 | pages = 49–69 | doi = 10.1007/s00180-007-0021-8 | url = http://www.eng.tau.ac.il/~bengal/VOM_EST.pdf }}&lt;/ref&gt;

=== Read trimming ===
Sometimes, the raw reads produced by the sequencer are correct and precise only in a fraction of their length. Using the entire read may introduce artifacts in the downstream analyses like genome assembly, snp calling, or gene expression estimation. Two classes of trimming programs have been introduced, based on the window-based or the running-sum classes of algorithms.&lt;ref&gt;{{cite journal | vauthors = Del Fabbro C, Scalabrin S, Morgante M, Giorgi FM | title = An Extensive Evaluation of Read Trimming Effects on Illumina NGS Data Analysis | journal = PLoS ONE | volume = 8 | issue = 12 | pages = e85024 | year = 2013 | pmid = 24376861 | pmc = 3871669 | doi = 10.1371/journal.pone.0085024 | bibcode = 2013PLoSO...885024D }}&lt;/ref&gt; This is a partial list of the trimming algorithms currently available, specifying the algorithm class they belong to:

{| class="wikitable"
|+ Read Trimming Algorithms
! Name of algorithm !! Type of algorithm !! Link
|-
| Cutadapt&lt;ref name=cutadapt&gt;{{cite journal|last1=Martin|first1=Marcel|title=Cutadapt removes adapter sequences from high-throughput sequencing reads|journal=EMBnet.journal|date=2 May 2011|volume=17|issue=1|page=10|doi=10.14806/ej.17.1.200}}&lt;/ref&gt; || Running sum || [https://code.google.com/p/cutadapt/ Cutadapt]
|-
| ConDeTri&lt;ref name=condetri&gt;{{cite journal|last1=Smeds|first1=Linnéa|last2=Künstner|first2=Axel|last3=Donlin|first3=Maureen J.|title=ConDeTri - A Content Dependent Read Trimmer for Illumina Data|journal=PLoS ONE|date=19 October 2011|volume=6|issue=10|pages=e26314|doi=10.1371/journal.pone.0026314|bibcode = 2011PLoSO...626314S|pmid=22039460|pmc=3198461}}&lt;/ref&gt; || Window based || [https://code.google.com/p/condetri/ ConDeTri]
|-
| ERNE-FILTER&lt;ref name="erne-bs5"&gt;{{cite journal|last1=Spandow|first1=O|last2=Hellström|first2=S|last3=Schmidt|first3=SH|last4=De Paoli|first4=Emanuale|last5=Policriti|first5=Alberto|title=ERNE-BS5: Aligning BS-treated Sequences by Multiple Hits on a 5-letters Alphabet|journal=Proceedings of the ACM Conference on Bioinformatics, Computational Biology and Biomedicine|date=2012|volume=12|pages=12–19|doi=10.1145/2382936.2382938|isbn=9781450316705}}&lt;/ref&gt; || Running sum || [http://erne.sourceforge.net/ ERNE-FILTER]
|-
| FASTX quality trimmer || Window based || [http://hannonlab.cshl.edu/fastx_toolkit/download.html FASTX quality trimmer]
|-
| PRINSEQ&lt;ref name=prinseq&gt;{{cite journal|last1=Schmieder|first1=R.|last2=Edwards|first2=R.|title=Quality control and preprocessing of metagenomic datasets|journal=Bioinformatics|date=28 January 2011|volume=27|issue=6|pages=863–64|doi=10.1093/bioinformatics/btr026|pmid=21278185|pmc=3051327}}&lt;/ref&gt; || Window based || [http://sourceforge.net/projects/prinseq/files/ PRINSEQ]
|-
| Trimmomatic&lt;ref name=trimmomatic&gt;{{cite journal|last1=Bolger|first1=A. M.|last2=Lohse|first2=M.|last3=Usadel|first3=B.|title=Trimmomatic: a flexible trimmer for Illumina sequence data|journal=Bioinformatics|date=1 April 2014|volume=30|issue=15|pages=2114–20|doi=10.1093/bioinformatics/btu170|pmid=24695404}}&lt;/ref&gt; || Window based || [http://www.usadellab.org/cms/index.php?page=trimmomatic Trimmomatic]
|-
| SolexaQA&lt;ref name=solexaqa&gt;{{cite journal|last1=Cox|first1=Murray P|last2=Peterson|first2=Daniel A|last3=Biggs|first3=Patrick J|title=SolexaQA: At-a-glance quality assessment of Illumina second-generation sequencing data|journal=BMC Bioinformatics|date=2010|volume=11|issue=1|page=485|doi=10.1186/1471-2105-11-485|pmid=20875133|pmc=2956736}}&lt;/ref&gt; || Window based || [http://sourceforge.net/projects/solexaqa/files/ SolexaQA]
|-
| SolexaQA-BWA || Running sum || [http://sourceforge.net/projects/solexaqa/files/ SolexaQA-BWA]
|-
| Sickle || Window based || [https://github.com/najoshi/sickle Sickle]
|}

== Ethical issues ==
{{Expand section|date=May 2015}}
{{Further|Bioethics}}
Human genetics have been included within the field of [[bioethics]] since the early 1970s&lt;ref name="ethics-murray"&gt;{{cite journal|last1=Murray|first1=TH|title=Ethical issues in human genome research.|journal=FASEB Journal|date=January 1991|volume=5|issue=1|pages=55–60|pmid=1825074}}&lt;/ref&gt; and the growth in the use of DNA sequencing (particularly high-throughput sequencing) has introduced a number of ethical issues. One key issue is the ownership of an individual's DNA and the data produced when that DNA is sequenced.&lt;ref name="usd1000-genome-ethics"&gt;{{cite journal|last1=Robertson|first1=John A.|title=The $1000 Genome: Ethical and Legal Issues in Whole Genome Sequencing of Individuals|journal=The American Journal of Bioethics|date=August 2003|volume=3|issue=3|pages=35–42|doi=10.1162/152651603322874762|pmid=14735880}}&lt;!--|accessdate=20 May 2015--&gt;&lt;/ref&gt; Regarding the DNA molecule itself, the leading legal case on this topic, ''[[Moore v. Regents of the University of California]]'' (1990) ruled that individuals have no property rights to discarded cells or any profits made using these cells (for instance, as a patented [[cell line]]). However, individuals have a right to informed consent regarding removal and use of cells. Regarding the data produced through DNA sequencing, ''Moore'' gives the individual no rights to the information derived from their DNA.&lt;ref name="usd1000-genome-ethics" /&gt;

As DNA sequencing becomes more widespread, the storage, security and sharing of genomic data has also become more important.&lt;ref name="usd1000-genome-ethics" /&gt;&lt;ref name="guardian-ethics"&gt;{{cite web|last1=Henderson|first1=Mark|title=Human genome sequencing: the real ethical dilemmas|url=https://www.theguardian.com/science/2013/sep/09/genetics-ethics-human-gene-sequencing|website=The Guardian|accessdate=20 May 2015}}&lt;/ref&gt; For instance, one concern is that insurers may use an individual's genomic data to modify their quote, depending on the perceived future health of the individual based on their DNA.&lt;ref name="guardian-ethics" /&gt;&lt;ref name="ny-times-insurance-ethics"&gt;{{cite news|last1=Harmon|first1=Amy|title=Insurance Fears Lead Many to Shun DNA Tests|url=https://www.nytimes.com/2008/02/24/health/24dna.html?pagewanted=all&amp;_r=0|website=The New York Times|accessdate=20 May 2015|date=24 February 2008}}&lt;/ref&gt; In May 2008, the [[Genetic Information Nondiscrimination Act]] (GINA) was signed in the United States, prohibiting discrimination on the basis of genetic information with respect to health insurance and employment.&lt;ref name="OMB support"&gt;[http://www.genome.gov/Pages/PolicyEthics/GeneticDiscrimination/SAPonHR493.pdf Statement of Administration policy], Executive Office of the President, Office of Management and Budget, 27 April 2007&lt;/ref&gt;&lt;ref name="Signing"&gt;{{cite news |url=http://www.genome.gov/27026050|title=President Bush Signs the Genetic Information Nondiscrimination Act of 2008|author=National Human Genome Research Institute|date=21 May 2008| accessdate=17 Feb 2014}}&lt;/ref&gt; In 2012, the US [[Presidential Commission for the Study of Bioethical Issues]] reported that existing privacy legislation for DNA sequencing data such as GINA and the [[Health Insurance Portability and Accountability Act]] were insufficient, noting that whole-genome sequencing data was particularly sensitive, as it could be used to identify not only the individual from which the data was created, but also their relatives.&lt;ref name="nature-ethics"&gt;{{cite web|last1=Baker|first1=Monya|title=US ethics panel reports on DNA sequencing and privacy|url=http://blogs.nature.com/news/2012/10/us-ethics-panel-reports-on-dna-sequencing-and-privacy.html|website=Nature New Blog|accessdate=20 May 2015}}&lt;/ref&gt;&lt;ref name="privacy-progress-report"&gt;{{cite web|title=Privacy and Progress in Whole Genome Sequencing|url=http://bioethics.gov/sites/default/files/PrivacyProgress508_1.pdf|publisher=Presidential Commission for the Study of Bioethical Issues|accessdate=20 May 2015}}&lt;/ref&gt;

Ethical issues have also been raised by the increasing use of genetic variation screening, both in newborns, and in adults by companies such as [[23andMe]].&lt;ref name="ethics-newborns"&gt;{{cite journal|last1=Goldenberg|first1=Aaron J.|last2=Sharp|first2=Richard R.|title=The Ethical Hazards and Programmatic Challenges of Genomic Newborn Screening|journal=[[JAMA (journal)|JAMA]]|date=1 February 2012|volume=307|issue=5|pages=461–2|doi=10.1001/jama.2012.68|pmid=22298675|pmc=3868436}}&lt;/ref&gt;&lt;ref name="ethics-hughes"&gt;{{cite web|last1=Hughes|first1=Virginia|title=It’s Time To Stop Obsessing About the Dangers of Genetic Information|url=http://www.slate.com/articles/health_and_science/medical_examiner/2013/01/ethics_of_genetic_information_whole_genome_sequencing_is_here_and_we_need.html|website=Slate Magazine|accessdate=22 May 2015}}&lt;/ref&gt; It has been asserted that screening for genetic variations can be harmful, increasing [[anxiety]] in individuals who have been found to have an increased risk of disease.&lt;ref name="ethics-bloss"&gt;{{cite journal|last1=Bloss|first1=Cinnamon S.|last2=Schork|first2=Nicholas J.|last3=Topol|first3=Eric J.|title=Effect of Direct-to-Consumer Genomewide Profiling to Assess Disease Risk|journal=New England Journal of Medicine|date=10 February 2011|volume=364|issue=6|pages=524–34|doi=10.1056/NEJMoa1011893|pmid=21226570|pmc=3786730}}&lt;/ref&gt; For example, in one case noted in ''[[Time (magazine)|Time]]'', doctors screening an ill baby for genetic variants chose not to inform the parents of an unrelated variant linked to [[dementia]] due to the harm it would cause to the parents.&lt;ref name="ethics-time"&gt;{{cite news|last1=Rochman|first1=Bonnie|title=What Your Doctor Isn’t Telling You About Your DNA|url=http://healthland.time.com/2012/10/25/what-your-doctor-isnt-telling-you-about-your-dna/|website=Time.com|accessdate=22 May 2015|date=25 October 2012}}&lt;/ref&gt; However, a 2011 study in ''[[The New England Journal of Medicine]]'' has shown that individuals undergoing disease risk profiling did not show increased levels of anxiety.&lt;ref name="ethics-bloss" /&gt;

== See also ==
{{col-begin}}
{{col-2}}
* [[Bioinformatics]]
* [[Cancer genome sequencing]]
* [[DNA computing]]
* [[DNA field-effect transistor]]
* [[DNA sequencing theory]]
* [[DNA sequencer]]
* [[Genome project]]
* [[Jumping library]]
{{col-2}}
* [[Nucleic acid sequence]]
* [[Multiplex ligation-dependent probe amplification]]
* [[Personalized medicine]]
* [[Protein sequencing]]
* [[Sequence mining]]
* [[Sequence profiling tool]]
* [[Transmission electron microscopy DNA sequencing]]
{{col-end}}

== References ==
{{reflist|refs=

&lt;ref name = "Bentley_2008"&gt;{{cite journal | vauthors = Bentley DR, Balasubramanian S, ''et al.'' | title = Accurate whole human genome sequencing using reversible terminator chemistry | journal = Nature | volume = 456 | issue = 7218 | pages = 53–59 | year = 2008 | pmid = 18987734 | pmc = 2581791 | doi = 10.1038/nature07517 |bibcode = 2008Natur.456...53B }}&lt;/ref&gt;

&lt;ref name = "Drmanac_2010" &gt;{{cite journal | vauthors = Drmanac R, Sparks AB, ''et al.'' | title = Human Genome Sequencing Using Unchained Base Reads in Self-Assembling DNA Nanoarrays | journal = Science | volume = 327 | issue = 5961 | pages = 78–81 | year = 2010 | pmid = 19892942 | doi = 10.1126/science.1181498 | bibcode = 2010Sci...327...78D }}&lt;/ref&gt;

&lt;ref name="Feldmann_1994"&gt;{{cite journal | vauthors = Feldmann H, ''et al.'' | title = Complete DNA sequence of yeast chromosome II | journal = EMBO J. | volume = 13 | issue = 24 | pages = 5795–809 | year = 1994 | pmid = 7813418 | pmc = 395553 }}&lt;/ref&gt;

&lt;ref name="Lander_2001"&gt;{{cite journal | vauthors = Lander ES, Linton LM, Birren B, Nusbaum C, Zody MC, ''et al.'' | title = Initial sequencing and analysis of the human genome | journal = Nature | volume = 409 | issue = 6822 | pages = 860–921 | date = February 2001 | pmid = 11237011 | doi = 10.1038/35057062 | bibcode = 2001Natur.409..860L | url = https://deepblue.lib.umich.edu/bitstream/2027.42/62798/1/409860a0.pdf }}&lt;/ref&gt;

&lt;ref name="Margulies_2005"&gt;{{cite journal | vauthors = Margulies M, Egholm M, ''et al.'' | title = Genome Sequencing in Open Microfabricated High Density Picoliter Reactors | journal = Nature | volume = 437 | issue = 7057 | pages = 376–80 | date = September 2005 | pmid = 16056220 | pmc = 1464427 | doi = 10.1038/nature03959 | bibcode = 2005Natur.437..376M }}&lt;/ref&gt;

&lt;ref name="Venter_2001"&gt;{{cite journal | vauthors = Venter JC, Adams MD, ''et al.'' | title = The sequence of the human genome | journal = Science | volume = 291 | issue = 5507 | pages = 1304–51 | date = February 2001 | pmid = 11181995 | doi = 10.1126/science.1058040 | bibcode = 2001Sci...291.1304V }}&lt;/ref&gt;

}}

== External links ==
{{Library resources box
 |onlinebooks=no
 |by=no}}
{{wikibooks
 |1= Next Generation Sequencing (NGS)
}}
* A [[Wikibooks:Next Generation Sequencing (NGS)|wikibook on next generation sequencing]]
* A [http://omictools.com/ free didactic directory for DNA sequencing analysis.]
* A [http://www.whatisbiotechnology.org/exhibitions/sanger The path to DNA sequencing: The life and work of Fred Sanger]
* A [https://map.meenta.io/ US Map of New Generation Sequencers]
* A [https://www.cd-genomics.com/blog/the-brief-introduction-of-sequencing-history-sequencing-in-20th-century/Brief Introduction of Sequencing History: Sequencing in 20th Century]

{{Portal bar|Molecular and cellular biology}}

{{DEFAULTSORT:Dna Sequencing}}
[[Category:DNA sequencing| ]]
[[Category:Biotechnology]]
[[Category:DNA]]
[[Category:Genetic mapping]]
[[Category:Molecular biology]]
[[Category:Molecular biology techniques]]
[[Category:1970 introductions]]
[[Category:1970 in biology]]
[[Category:1970 in biotechnology]]
[[Category:1970 in science]]
[[Category:1998 in technology]]</text>
      <sha1>1buru1q0wbed9vjmuqstqqw8ztmqk64</sha1>
    </revision>
  </page>
  <page>
    <title>Deprivation index</title>
    <ns>0</ns>
    <id>5266824</id>
    <revision>
      <id>791765932</id>
      <parentid>791734887</parentid>
      <timestamp>2017-07-22T10:33:22Z</timestamp>
      <contributor>
        <username>Alexf</username>
        <id>55327</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/Trutz Haase|Trutz Haase]] ([[User talk:Trutz Haase|talk]]) to last version by Maralia</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="440">'''Deprivation indices''' are a measure of the level of [[poverty|deprivation]] in an area.

Examples include:

*[[Indices of deprivation 2004]] (ID2004)
*[[Indices of deprivation 2007]] (ID2007)
*[[Underprivileged area score]]
*[[Carstairs index]]
*[[Department of Environment Index]]

{{Indices of Deprivation}}

[[Category:Medical statistics]]
[[Category:Epidemiology]]
[[Category:Human geography]]

{{Economics-stub}}
{{Sociology-stub}}</text>
      <sha1>ju0d4hrtca6fdo59cmws7cta2vmrz70</sha1>
    </revision>
  </page>
  <page>
    <title>Dimensionless momentum-depth relationship in open-channel flow</title>
    <ns>0</ns>
    <id>29491804</id>
    <revision>
      <id>809042665</id>
      <parentid>809042566</parentid>
      <timestamp>2017-11-06T20:06:20Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18028">== Momentum in open channel flow ==

=== What is momentum?===
[[Momentum]] for one-dimensional flow in a channel can be given by the expression:&lt;br /&gt;
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;M=\frac{Q^2}{gA}+\overline yA&lt;/math&gt; 
|}
:{|
|where:	
* M is the momentum [L&lt;sup&gt;3&lt;/sup&gt;]
* Q is the rate of flow [L&lt;sup&gt;3&lt;/sup&gt;/s]
* g is the acceleration due to gravity [L/T&lt;sup&gt;2&lt;/sup&gt;]
* A is the cross sectional area of flow [L&lt;sup&gt;2&lt;/sup&gt;]
* ȳ is the distance from the centroid of A to the water surface [L]
|}

For [[open channel flow]] calculations where momentum can be assumed to be [[Momentum–depth relationship in a rectangular channel#Conservation of Momentum|conserved]], such as in a hydraulic jump, we can equate the Momentum at an upstream location,''M''&lt;sub&gt;1&lt;/sub&gt;, to that at a downstream location, ''M''&lt;sub&gt;2&lt;/sub&gt;, such that:  
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;M_1=\frac{Q^2}{gA_1}+\overline y_1A_1=\frac{Q^2}{gA_2}+\overline y_2A_2=M_2&lt;/math&gt;
|}

=== Momentum in a rectangular channel ===
In the unique circumstance where the flow is in a rectangular channel (such as a laboratory flume), we can describe this relationship as [[momentum–depth relationship in a rectangular channel#The momentum equation for horizontal, rectangular channels|unit momentum]], by dividing both sides of the equation by the width of the channel.  This produces &lt;sub&gt;u&lt;/sub&gt;M in terms of ft&lt;sup&gt;2&lt;/sup&gt;, and is given by the equation: &lt;br /&gt;
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;{_uM_1}=\frac{q^2}{gy_1}+ \frac{y_1^2}{2} =\frac{q^2}{gy_2}+ \frac{y_2^2}{2}={_uM_2}&lt;/math&gt;
|}
:{|
|where:	
* &lt;sub&gt;u&lt;/sub&gt;M is M/b [L&lt;sup&gt;2&lt;/sup&gt;]
* q is Q/b [L&lt;sup&gt;2&lt;/sup&gt;/T]
* b is the base width of the rectangular channel [L]
|}

=== Why is momentum important? ===
Momentum is one of the most important basic definitions in [[Fluid mechanics|Fluid Mechanics]]. The conservation of momentum is one of the three fundamental physical principles in both Fluid Mechanics and [Open-channel flow | open channel flow] (the other two are mass conservation and energy conservation). This principle leads to the momentum equation set in three dimensions (x, y and z). With different assumptions, these momentum equations can be simplified to several widely applied forms:

With Newton’s second law, [[Newtonian fluids]] assumption and Stokes hypothesis, the original fluid momentum equations are derived as the [[Navier–Stokes equations]]. These equations are classic in Fluid Mechanics, but the nonlinearity in these partial differential equations make them difficult to solve mathematically. As a result, analytical solutions for the Navier–Stokes equations still remain a tough research topic.

For high Reynolds number flow, the effects of viscosity are negligible. In these cases, with the inviscid assumption, [[Navier–Stokes equations]] can be derived as [[Euler equations (fluid dynamics)|Euler equations]]. Though they are still nonlinear partial differential equations, the elimination of viscous terms simplifies the problem.

In some applications, when viscosity, [[Conservative vector field|rotationality]] and [[incompressible flow|compressibility]] of the fluid can be neglected, the Navier–Stokes equations can be further simplified to the Laplace equation form, which is referred as [[potential flow]].

In [[computational fluid dynamics]], solving the partial differential momentum equations mentioned above with discretized algebraic equations is the most important procedure to study flow characteristics in different applications.

Momentum also allows us to describe the characteristics of flow when energy is not conserved. [[HEC-RAS]], a widely used computer model developed by the US Army Corps of Engineers for calculating water surface profiles, considers that when flow passes through critical depth, the basic assumption of gradually varied flow required for the Energy Equation is not applicable. Locations where flow may make such a transition include: significant changes in slope, channel geometry (e.g. bridge sections), grade control structures, and the confluence of water bodies. In these instances, HEC-RAS will use a form of the momentum equation to solve for the water surface elevation at an unknown location.

In addition, momentum flux is one of the parameters to estimate fluid impact on offshore structures. Analysis of momentum flux in coastal regions can provide advisable infrastructure layout planning to minimize the potential hazards from extreme events such as storm surge, hurricane and tsunami (e.g. (Park et al. 2013), (Yeh 2006), (Guard et al. 2005) and (Chanson et al. 2002)).

=== What are the characteristics of momentum? ===
For discussion, we will consider an ideal, frictionless, [[Momentum-depth relationship in a rectangular channel|rectangular channel]].  For each value of q, a [[momentum–depth relationship in a rectangular rhannel#The M-y Diagram|unique curve]] can be produced where ''M'' is shown as a function of depth.  As is the case for specific energy, the minimum value of &lt;sub&gt;u&lt;/sub&gt;M, &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;min&lt;/sub&gt;, corresponds to [[momentum–depth relationship in a rectangular channel#Critical flow|critical depth]].  For each value of &lt;sub&gt;u&lt;/sub&gt;M greater than &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;min&lt;/sub&gt;, there are two depths that can occur.  These are called conjugate depths, and represent supercritical and subcritical alternatives for flow of a given &lt;sub&gt;u&lt;/sub&gt;M.  Since [[Hydraulic Jumps in Rectangular Channels|hydraulic jumps]] conserve momentum, if the depth at the upstream or downstream end of a hydraulic jump is known, we can determine the unknown depth by drawing a vertical line through the known depth and reading its conjugate. The M-y diagram below shows three M-y curves with unit discharge 10, 15
and 20&amp;nbsp;ft&lt;sup&gt;2&lt;/sup&gt;/s. It can be observed that the M-y curves shift in positive M axis as the q value increases. From the M-y equation mentioned earlier, as y increases to infinity, the q&lt;sup&gt;2&lt;/sup&gt; / gy&lt;sub&gt;1&lt;/sub&gt; term would be negligible, and the M value will converge to 0.5y&lt;sup&gt;2&lt;/sup&gt; (shown as the black dashed curve in M-y diagram). By taking the derivative dM / dy = 0, we can also obtain the equation of minimum M with different q values:&lt;br /&gt;
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;\frac{dM}{dy} = y_c - \frac{q^2}{gy_c^2} &lt;/math&gt;
|}

By eliminating the term of q in the equation above with the relationship between q and y&lt;sub&gt;c&lt;/sub&gt; (y&lt;sub&gt;c&lt;/sub&gt; = ( q&lt;sup&gt;2&lt;/sup&gt; / g )&lt;sup&gt;1/3&lt;/sup&gt; ), and put the resulting equation of y into the original M-y ccg3 c
equation, we can obtain the characteristic curve of critical M and y (shown as the red dashed curve in M-y diagram):
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;y_c = \frac{2}{3}\sqrt{M_c} &lt;/math&gt;
|}

{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
|
[[File:M-y Diagram with different q.pdf|thumb|M-y Diagram for open channel flow|1000px]]
|}

== Dimensionless M’-y’ diagram ==

=== Why do we need dimensionless momentum–depth relationship? ===
Conjugate depths can be determined from curves like the one above.  However, since this curve is unique for q = 20&amp;nbsp;ft&lt;sup&gt;2&lt;/sup&gt;/s, we would have to develop a new curve for each rectangular channel of a given base width (or discharge).  If we can establish a dimensionless relationship, we can apply the curve to any problem in which the cross-section is rectangular in shape.  To create a dimensionless momentum–depth relationship, we will divide both sides by a normalizing value that will allow us to use a dimensionless relationship between Momentum and Depth for all values of ''q''.

=== Derivation of the dimensionless momentum–depth relationship ===
Given that:  
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;{_uM_1}=\frac{q^2}{gy_1}+ \frac{y_1^2}{2} =\frac{q^2}{gy_2}+ \frac{y_2^2}{2}={_uM_2}&lt;/math&gt;
|}
and that:  
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;{q^2}={gy_c^3}&lt;/math&gt; 
|}
according to the [[Buckingham pi theorem|Buckingham {{pi}} theorem]], with dimensional analysis, we can normalize the relationship between depth and Momentum by dividing both by the value of the critical depth squared and substituting for q&lt;sup&gt;2&lt;/sup&gt; to yield:
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;\frac{_uM}{y_c^2} = \frac{gy_c^3}{gyy_c^2} + \frac{y^2}{2y_c^2}&lt;/math&gt; 
|}
:{|
|where:	
* y&lt;sub&gt;c&lt;/sub&gt; is the critical depth.
|}&lt;br /&gt;
If we let M’ = &lt;sub&gt;u&lt;/sub&gt;M/y&lt;sub&gt;c&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;, and y’ = y/y&lt;sub&gt;c&lt;/sub&gt;, this equation becomes: 
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| &lt;math&gt;M'= \frac{1}{y'} + \frac{y'^2}{2}&lt;/math&gt;  
|}

=== The dimensionless momentum–depth diagram ===
By applying the conversion to dimensionless units described above, the dimensionless momentum–depth diagram is produced below.
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| [[File:Dimensionless M-y.png|400px]]
|}

=== What is the relationship between the dimensionless momentum–depth diagram and the dimensionless energy–depth diagram? ===
By close inspection of the [[Dimensionless Specific Energy Diagrams for Open Channel Flow|dimensionless dnergy–depth]] diagram, an interesting conclusion can be drawn, which is that M’ is the same function of y’ as E’ is of 1/y’, and vice versa.  This is demonstrated in the following chart that compares favorably to the chart of the [[Dimensionless Specific Energy Diagrams for Open Channel Flow|Dimensionless Energy-Depth]] Diagram.  Note that the only difference between the chart above and the one below is the values of the y-axis are the reciprocal of one another and that the scale has been changed to be consistent with the scale found in the discussion of [[Dimensionless Specific Energy Diagrams for Open Channel Flow|Dimensionless Energy-Depth]]. &lt;br /&gt;
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| [[File:Dimensionless M v y-inverse.png|400px]]
|}
Because Energy and Momentum have this reciprocal relationship (found also in the non-dimensionless forms of these relationships), we can use a Dimensionless Energy-Depth Diagram to create a dimensionless momentum–depth diagram, and vice versa.

== Solution of simple version of hydraulic jump with dimensionless diagram ==
To demonstrate the use of a dimensionless momentum–depth diagram in the solution of a simple [[hydraulic jumps in rectangular hcannels|hydraulic jump]] problem (hydraulic jump is also very common in other situations. Let’s consider a rectangular channel with a base width of 10&amp;nbsp;ft, and a flow rate of 100&amp;nbsp;ft&lt;sup&gt;3&lt;/sup&gt;/s, with a tailwater induced downstream depth of 6&amp;nbsp;ft.  What is the depth of flow at the upstream end of the hydraulic jump?

'''Step 1''' – Calculate q: 
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;q=\frac{Q}{b}&lt;/math&gt;
|-
| &lt;math&gt;q=\frac{100 ft^3/s}{10 ft}=10ft^2/s&lt;/math&gt;
|}
'''Step 2''' – Calculate y&lt;sub&gt;c&lt;/sub&gt;:
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;y_c=\sqrt[3]{q^2 \over g}&lt;/math&gt;
|-
| &lt;math&gt;y_c=\sqrt[3]{{(10 ft^2/s)}^2 \over 32.2 ft/s^2}=1.459 ft&lt;/math&gt;
|-
| (note-calculations are displayed to 3 decimal places to reduce rounding errors in '''Step 6''')
|}

'''Step 3''' – Calculate y’ for the downstream depth:
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;y'=\frac{y_d}{y_c}&lt;/math&gt;
|-
| &lt;math&gt;y'=\frac{6 ft}{1.46 ft}=4.112&lt;/math&gt;
|}
'''Step 4''' – Determine Conjugate Dimensionless Depth from Chart:

Using the Dimensionless Chart presented above, plot y’ = 4.11 over to its intersection with the M’ curve.  Read down the chart to find the conjugate depth and determine the new y’ from the left axis.
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| [[File:Solution plot.png|400px|Solution plot]]
|}
'''Step 5''' – Calculate the upstream (conjugate) depth to  6&amp;nbsp;ft by converting y’ = 0.115 to its actual depth:
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;y'=\frac{y_u}{y_c}&lt;/math&gt;
|-
| &lt;math&gt;{y_u}={y'}{y_c}=0.115(1.459ft)=0.168 ft&lt;/math&gt;
|}
'''Step 6''' – Validation:
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;{_uM_u}=\frac{q^2}{gy_1}+ \frac{y_1^2}{2}&lt;/math&gt;
|-
| &lt;math&gt;{_uM_u}=\frac{10^2}{(32.2)0.168}+ \frac{0.168^2}{2}=18.500ft^2&lt;/math&gt;
|}
and
{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;{_uM_d}=\frac{q^2}{gy_2}+ \frac{y_2^2}{2}&lt;/math&gt;
|-
| &lt;math&gt;{_uM_d}=\frac{10^2}{(32.2)6}+ \frac{6^2}{2}=18.518ft^2&lt;/math&gt;
|}
The difference between &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;u&lt;/sub&gt; and &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;d&lt;/sub&gt; is shown as 0.18&amp;nbsp;ft&lt;sup&gt;2&lt;/sup&gt; due to rounding errors.  Therefore, &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;u&lt;/sub&gt; and &lt;sub&gt;u&lt;/sub&gt;M&lt;sub&gt;d&lt;/sub&gt; are shown to represent the same unit momentum across the jump and momentum is conserved, validating the calculations using the Dimensionless Chart above.

This topic contribution was made in partial fulfillment of the requirements for Virginia Tech, Department of Civil and Environmental Engineering course: CEE 5984 – Open Channel Flow during the Fall 2010 semester.

== Solution of hydraulic jump with sluice gate ==
The following example of a hydraulic jump at a [[Sluice|sluice gate]] outlet will give a clear idea about how conservation of energy and conservation of momentum apply in open channel flow.

As shown in the middle panel in schematic plot, in a rectangular channel, deep upstream flow (position 1) encounters a sluice gate in front of position 2. A sluice gate imposes adecrease in flow depth at position 2, and a hydraulic jump is formed between position 2 and far downstream where the flow depth increases again (position 3). The left panel in Figure 2 shows the M-y diagram of these 3 positions (momentum is also referred to as other definitions in different references, e.g. “Specific Force” in (Chaudhry 2008)), while the right panel in schematic plot shows the [[Energy–depth relationship in a rectangular channel|E-y]] diagram for these 3 positions. Energy loss can be neglected between position 1 and 2 (e.g. assuming conservation of energy), but the external thrust on the gate causes significant momentum loss. By contrast, between positions 2 and 3, turbulence in the hydraulic jump dissipates energy, while the momentum can be assumed to be conserved. If we know the unit discharge as q = 10&amp;nbsp;ft&lt;sup&gt;2&lt;/sup&gt;/s and the flow depth at position 1 as y&lt;sub&gt;1&lt;/sub&gt; = 8.0&amp;nbsp;ft, by applying energy conservation between position 1 &amp; 2 and momentum conservation between 2 &amp; 3, the flow depths at position 2 (y&lt;sub&gt;2&lt;/sub&gt;) and 3 (y&lt;sub&gt;3&lt;/sub&gt;) can be computed.

Applying [[Energy–depth relationship in a rectangular channel|conservation of energy]] between position 1 &amp; 2:

{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;E_1 = E_2&lt;/math&gt;
|-
| &lt;math&gt;y_1 + \frac{q^2}{2gy_1} = y_2 + \frac{q^2}{2gy_2} = 8.02 ft&lt;/math&gt;
|-
| &lt;math&gt;y_2 = \frac{2y_1}{-1 + \sqrt{1+8\frac{gy_1^3}{q^2}}} =0.45 ft&lt;/math&gt;
|}

Applying conservation of momentum between position 2 &amp; 3:

{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;M_2 = M_3&lt;/math&gt;
|-
| &lt;math&gt;\frac{y_2}{2} + \frac{q^2}{gy_2} = \frac{y_3}{2} + \frac{q^2}{gy_3} = 32.4 ft&lt;/math&gt;
|-
| &lt;math&gt;y_3 = \frac{y_2}{2}(-1 + \sqrt{1+8\frac{q^2}{gy_2^3}}) = 3.46 ft&lt;/math&gt;
|}

In addition, we can obtain the thrust on the sluice gate as well:

{| style="border:0px solid #ddd; text-align:center; margin:auto" cellspacing="20"
| &lt;math&gt;\triangle{M} = M_1 - M_2 = 25.5&lt;/math&gt;
|-
| &lt;math&gt;Thrust = \gamma \triangle{M} = \rho g \triangle{M} = 1590 lbs/ff&lt;/math&gt;
|}

(The example above comes from Dr. Moglen’s “Open Channel Flow” course (CEE5384) in Virginia Tech, U.S.)

&lt;br /&gt;
{| style="border:0px solid #ddd; text-align:left; margin:auto" cellspacing="20"
| [[File:Hydraulic Jump with Sluice Gate.png|thumb|Hydraulic Jump with Sluice Gate|600px]]
|}

==References==
* Brunner, G.W., HEC-RAS, River Analysis System Hydraulic Reference Manual (CPD-69), US Army Corps of Engineers, Hydrologic Engineering Center, 2010.
* Chanson, H., Aoki, S.-i. &amp; Maruyama, M. (2002), ‘An experimental study of tsunami runup on dry and wet horizontal coastlines’, Science of Tsunami Hazards 20(5), 278–293.
* Chaudhry, M.H., Open-Channel Flow (second edition), Springer Science+Business Media, llc, 2008.
* French, R.H., Open-Channel Hydraulics, McGraw-Hill, Inc., 1985.
* Guard, P., Baldock, T. &amp; Nielsen, P. (2005), General solutions for the initial run-up of a breaking tsunami front, in ‘International Symposium Disaster Reduction on Coasts’, Monash University, pp.&amp;nbsp;1–8.
* Henderson, F.M., Open Channel Flow, Prentice-Hall, 1966.
* Janna, W.S., Introduction to Fluid Mechanics, PWS-Kent Publishing Company, 1993.
* Linsey, R.K., Franzini, J.B., Freyberg, D.L., Tchobanoglous, G., Water-Resources Engineering (fourth edition), McGraw-Hill, Inc., 1992.
* Park, H., Cox, D. T., Lynett, P. J., Wiebe, D. M. &amp; Shin, S. (2013), ‘Tsunami inunda- tion modeling in constructed environments: A physical and numerical comparison of free-surface elevation, velocity, and momentum flux’, Coastal Engineering 79, 9– 21.
* Yeh, H. (2006), ‘Maximum fluid forces in the tsunami runup zone’, Journal of water- way, port, coastal, and ocean engineering 132(6), 496–500.

[[Category:Hydraulics]]
[[Category:Fluid mechanics]]
[[Category:Hydraulic engineering]]
[[Category:Environmental engineering]]</text>
      <sha1>cvnrblgkjf9c8gcb12j075ftuxoeyuh</sha1>
    </revision>
  </page>
  <page>
    <title>Directory-based cache coherence</title>
    <ns>0</ns>
    <id>51518781</id>
    <revision>
      <id>834253470</id>
      <parentid>813162694</parentid>
      <timestamp>2018-04-04T18:49:35Z</timestamp>
      <contributor>
        <username>LilHelpa</username>
        <id>8024439</id>
      </contributor>
      <minor/>
      <comment>it's → its</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7975">In [[computer engineering]], '''directory-based cache coherence''' is a type of [[Cache coherence#Coherence mechanisms|cache coherence mechanism]], where directories are used to manage caches in place of snoopy methods due to their scalability. [[bus snooping|Snoopy bus-based methods]] scale poorly due to the use of [[Broadcasting (networking)|broadcasting]]. These methods can be used to target both [[Computer performance|performance]] and [[scalability]] of directory systems.&lt;ref name=CMPAMDUWPaper&gt;{{Cite journal|last=Reihnhart|first=Steven|last2=Basu|first2=Arkaprava|last3=Beckmann|first3=Bradford|last4=Hill|first4=Mark|date=2013-07-11|title="CMP Directory Coherence: One Granularity Does Not Fit All"|url=http://research.cs.wisc.edu/multifacet/papers/tr1798_region_coherence.pdf}}&lt;/ref&gt;

== Full bit vector format ==
[[File:Full bit vector format diagram.jpg|thumb|Diagram of full bit vector directory format, where E=Exclusive, S=Shared, M=Modified, and U=Uncached]]
In the full bit vector format, for each possible [[cache line]] in [[Computer_memory|memory]], a [[bit]] is used to track whether every individual [[Central processing unit|processor]] has that line stored in its [[cache (computing)|cache]].&lt;ref name=SolihinBook2015&gt;{{Cite book|title=Fundamentals of Parallel Multicore Architecture|last=Solihin|first=Yan|publisher=Solihin Publishing and Consulting, LLC|date=2015-10-09|isbn=978-1-4822-1118-4|location=Raleigh, North Carolina|pages=331–335|quote=|via=}}&lt;/ref&gt; The full bit vector format is the simplest structure to implement, but the least scalable.&lt;ref name=CMPAMDUWPaper/&gt; The [[SGI Origin 2000]] uses a combination of full bit vector and coarse bit vector depending on the number of processors.&lt;ref name="SGI2000OriginPaper"&gt;{{Cite conference|last=Laudon|first=James|last2=Lenoski|first2=Daniel|date=1997-06-01|title=The SGI Origin: a ccNUMA highly scalable serve|url=http://dl.acm.org/citation.cfm?id=264206|conference=Proceedings of the 24th annual international symposium on Computer architecture}}&lt;/ref&gt;

Each directory entry must have 1 bit stored per processor per cache line, along with bits for tracking the state of the directory. This leads to the total size required being ''(number of processors)×number of cache lines'', having a storage [[Overhead (computing)|overhead]] ratio of ''(number of processors)/(cache block size×8)''.

It can be observed that directory overhead scales linearly with the number of processors. While this may be fine for a small number of processors, when implemented in large systems the size requirements for the directory becomes excessive. For example, with a block size of 32 bytes and 1024 processors, the storage overhead ratio becomes 1024/(32×8) = 400%.&lt;ref name=SolihinBook2015/&gt;

== Coarse bit vector format ==
[[File:Coarse bit vector format diagram.jpg|thumb|Diagram of coarse bit vector directory format]]
The coarse bit vector format has a similar structure to the full bit vector format, though rather than tracking one bit per processor for every cache line, the directory groups several processors into [[Node_(computer_science)|nodes]], storing whether a cache line is stored in a node rather than a line. This improves size requirements at the expense of [[Bus (computing)|bus]] traffic saving (processors per node)×(total lines) bits of space.&lt;ref name="SGI2000OriginPaper"/&gt; Thus the ratio overhead is the same, just replacing number of processors with number of processor groups. When a bus request is made for a cache line that one processor in the group has, the directory broadcasts the signal into every processor in the node rather than just the caches that contain it, leading to unnecessary traffic to nodes that don't have the data cached.&lt;ref name=SolihinBook2015/&gt;

In this case the directory entry uses 1 bit for a group of processors for each cache line. For the same example as Full Bit Vector format if we consider 1 bit for 8 processors as a group, then the storage overhead will be 128/(32×8)=50%. This is a significant improvement over the Full Bit Vector format.

==Sparse directory format== 
A cache only stores a small subset of blocks in main memory at a particular time. Hence most of the entries in the directory will belong to uncached blocks. In the sparse directory format the wastage is reduced by storing only the cached blocks in the directory.&lt;ref name=SolihinBook2015/&gt;Consider a processor with a cache size of 64KB with a block size of 32 bytes and the main memory size to be 4MB. The maximum number of entries that the directory can have in the sparse directory format is 2048. If the directory has an entry for all the blocks in the memory the number of entries in the directory will be 131072. Thus it is evident that the storage improvement provided by sparse directory format is very significant.

==Number-balanced binary tree format==
In this format the directory is decentralised and distributed among the caches that share a memory block. Different caches that share a memory block are arranged in the form of a [[binary tree]]. The cache that accesses a memory block first is the [[Tree (data structure)|root node]]. Each memory block has the root node information (HEAD) and Sharing counter field (SC). The SC field has the number of caches that share the block. Each cache entry has [[Pointer (computer programming)|pointers]] to the next sharing caches known as L-CHD and R-CHD.  A condition for this directory is that the binary tree should be number balanced, i.e the number of nodes in the left sub tree must be equal to or one greater than the number of nodes in the right subtree. All the subtrees should also be number balanced.&lt;ref&gt;{{Cite journal|last=Seo|first=Dae-Wha|last2=Cho|first2=Jung Wan|date=1993-01-01|title=Directory-based cache coherence scheme using number-balanced binary tree|url=http://www.sciencedirect.com/science/article/pii/0165607493900119|journal=Microprocessing and Microprogramming|volume=37|issue=1|pages=37–40|doi=10.1016/0165-6074(93)90011-9}}&lt;/ref&gt;

==Chained directory format== 
In this format the memory holds the directory pointer to the latest cache that accessed the block and each cache has the pointer to the previous cache that accessed the block. So when a processor sends a write request to a block in memory, the processor sends [[Cache invalidation|invalidations]] down the chain of pointers.  In this directory when a cache block is replaced we need to [[Graph_traversal|traverse]] the [[Linked list|list]] in order to change the directory which increases [[Latency_(engineering)#Computer_hardware_and_operating_system_latency|latency]]. In order to prevent this [[doubly linked list]]s are widely used now in which each cached copy has pointers to previous and the next cache that accesses the block.&lt;ref&gt;{{Cite journal|last=Chaiken|first=D.|last2=Fields|first2=C.|last3=Kurihara|first3=K.|last4=Agarwal|first4=A.|date=1990-06-01|title=Directory-based cache coherence in large-scale multiprocessors|url=http://ieeexplore.ieee.org/document/55500/|journal=Computer|volume=23|issue=6|pages=49–58|doi=10.1109/2.55500|issn=0018-9162}}&lt;/ref&gt;

== Limited pointer format ==
The limited pointer format uses a set number of pointers to track the processors that are caching the data. When a new processor caches a block, a free pointer is chosen from a pool to point to that processor. There are a few options for handling cases when the number of sharers exceeds the number of free pointers. One method is to invalidate one of the sharers, using its pointer for the new requestor, though this can be costly in cases where a block has a large number of readers, such as a lock. Another method is to have a separate pool of free pointers available to all the blocks. This method is usually effective as the number of blocks shared by a large number of processors is not normally very large.&lt;ref name=SolihinBook2015/&gt;

== References ==
{{Reflist}}


[[Category:Computer architecture]]</text>
      <sha1>ah2isjwbc3cise33p5uo66rpcfqesm0</sha1>
    </revision>
  </page>
  <page>
    <title>Ecdysis</title>
    <ns>0</ns>
    <id>10340</id>
    <revision>
      <id>858197291</id>
      <parentid>858177987</parentid>
      <timestamp>2018-09-05T18:04:58Z</timestamp>
      <contributor>
        <username>Velella</username>
        <id>136926</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2600:1702:4C0:21E0:88B6:29E6:9942:C918|2600:1702:4C0:21E0:88B6:29E6:9942:C918]] ([[User talk:2600:1702:4C0:21E0:88B6:29E6:9942:C918|talk]]) to last version by Edit-pi</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10336">{{other uses}}
[[File:Cicada molting animated-2.gif|thumb|right|Process of ecdysis of a [[cicada]].]]

'''Ecdysis''' is the [[moulting]] of the [[cuticle]] in many invertebrates of the clade [[Ecdysozoa]]. Since the cuticle of these animals typically forms a largely inelastic [[exoskeleton]], it is shed during growth and a new, larger covering is formed.&lt;ref name="Ewer"&gt;{{cite journal |author=John Ewer |year=2005 |title=How the ecdysozoan changed its coat |journal=[[PLoS Biology]] |volume=3 |issue=10 |page=e349 |doi=10.1371/journal.pbio.0030349 |pmid=16207077 |pmc=1250302}}&lt;/ref&gt; The remnants of the old, empty exoskeleton are called [[exuvia]]e.&lt;ref name="Tetlie"&gt;{{cite journal |author=O. Erik Tetlie, Danita S. Brandt &amp; Derek E. G. Briggs |year=2008 |title=Ecdysis in sea scorpions (Chelicerata: Eurypterida) |journal=[[Palaeogeography, Palaeoclimatology, Palaeoecology]] |volume=265 |issue=3–4 |pages=182–194 |doi=10.1016/j.palaeo.2008.05.008}}&lt;/ref&gt;

After moulting, an arthropod is described as ''teneral'', a ''callow''; it is "fresh", pale and soft-bodied. Within one or two hours, the cuticle hardens and darkens following a [[Tanning (leather)|tanning]] process analogous to the production of [[leather]].&lt;ref name="mcgraw-hill"&gt;{{cite book |author=Russell Jurenka |chapter=Insect physiology |title=[[McGraw-Hill Encyclopedia of Science &amp; Technology]] |volume=9 |page=323 |year=2007 |isbn=978-0-07-144143-8 |edition=10th |editor=Sybil P. Parker}}&lt;/ref&gt; During this short phase the animal expands, since growth is otherwise constrained by the rigidity of the exoskeleton. Growth of the limbs and other parts normally covered by hard exoskeleton is achieved by transfer of body fluids from soft parts before the new skin hardens. A spider with a small abdomen may be undernourished but more probably has recently undergone ecdysis. Some arthropods, especially large insects with tracheal respiration, expand their new exoskeleton by swallowing or otherwise taking in air. The maturation of the structure and [[animal coloration|colouration]] of the new exoskeleton might take days or weeks in a long-lived insect; this can make it difficult to identify an individual if it has recently undergone ecdysis.

Ecdysis allows damaged tissue and missing limbs to be [[regeneration (biology)|regenerated]] or substantially re-formed. Complete regeneration may require a series of moults, the stump becoming a little larger with each moult until it is a normal, or near normal, size.&lt;ref&gt;{{cite journal |author=Penny M. Hopkins |year=2001 |title=Limb regeneration in the fiddler crab, ''Uca pugilator'': hormonal and growth factor control |journal=[[American Zoologist]] |volume=41 |issue=3 |pages=389–398 |doi=10.1093/icb/41.3.389}}&lt;/ref&gt;

==Etymology==

The term ''ecdysis'' comes from {{lang-grc|ἐκδύω}} (''{{lang|grc|ekduo}}''), "to take off, strip off".&lt;ref&gt;{{cite book |author=Liddell &amp; Scott |year=1889 |title=An Intermediate Greek-English Lexicon |location=Oxford |publisher=[[Clarendon Press]] |url=http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0058%3Aentry%3De)kdu%2Fw}}&lt;/ref&gt;

==Process==

In preparation for ecdysis, the arthropod becomes inactive for a period of time, undergoing [[apolysis]] or separation of the old exoskeleton from the underlying epidermal cells. For most organisms, the resting period is a stage of preparation during which the secretion of fluid from the moulting glands of the epidermal layer and the loosening of the underpart of the cuticle occur.
Once the old cuticle has separated from the epidermis, a digesting fluid is secreted into the space between them. However, this fluid remains inactive until the upper part of the new cuticle has been formed. Then, by crawling movements, the organism pushes forward in the old [[Integumentary system|integumentary shell]], which splits down the back allowing the animal to emerge. Often, this initial crack is caused by a combination of movement and increase in blood pressure within the body, forcing an expansion across its [[exoskeleton]], leading to an eventual crack that allows for certain organisms such as [[spider]]s to extricate themselves.
While the old cuticle is being digested, the new layer is secreted. All cuticular structures are shed at ecdysis, including the inner parts of the exoskeleton, which includes terminal linings of the [[alimentary tract]] and of the [[invertebrate trachea|trachea]]e if they are present.
{{Multiple image
| header = Physiology of ecdysis
| direction = horizontal
| align = center
| width = 240
| image1 = The-arthropods-moulting-1.gif
| alt1 = The process of moulting in insects begins with the separation of the cuticle from the underlying epidermal cells.
| image2 = The-arthropods-moulting-2.gif
| alt2 = After the separation, moulting fluid is secreted into the space between the old cuticle and the epidermis (the exuvial space); this contains inactive enzymes which are activated only after the new epicuticle is secreted.
| image3 = The-arthropods-moulting-3.gif
| alt3 = The lower regions of the old cuticle are then digested by the enzymes and subsequently absorbed. The process of moulting can start.
}}

==Insects==
{{wide image|Aeshna cyanea freshly slipped L2.jpg|1200px|Moulting (ecdysis) in [[southern hawker]], ''Aeshna cyanea''}}

Each stage of development between moults for insects in the taxon [[endopterygota]] is called an [[instar]], or stadium, and each stage between moults of insects in the [[Exopterygota]] is called a nymph: there may be up to 15 nymphal stages. [[Endopterygota]] tend to have only four or five instars. Endopterygotes have more alternatives to moulting, such as expansion of the cuticle and collapse of air sacs to allow growth of internal organs.

The process of moulting in insects begins with the separation of the cuticle from the underlying epidermal cells (apolysis) and ends with the shedding of the old cuticle (ecdysis). In many species it is initiated by an increase in the [[hormone]] [[ecdysone]]. This hormone causes:
* apolysis – the separation of the cuticle from the [[Squamous epithelium|epidermis]]
* [[secretion]] of new cuticle materials beneath the old
* degradation of the old cuticle

After apolysis the insect is known as a [[pharate]]. Moulting fluid is then secreted into the exuvial space between the old cuticle and the epidermis, this contains inactive enzymes which are activated only after the new [[epicuticle]] is secreted. This prevents the new [[procuticle]] from getting digested as it is laid down. The lower regions of the old cuticle, the [[endocuticle]] and [[mesocuticle]], are then digested by the enzymes and subsequently absorbed. The [[exocuticle]] and epicuticle resist digestion and are hence shed at ecdysis.

==Spiders==
[[File:Crab spider female in ecdysis; Genus Synema, Family Thomisidae 5725s.jpg|left|thumb|Female [[crab spider]] ''[[Synema decens]]'', teneral after final ecdysis, still dangling from drop line, about to be mated, [[opisthosoma]] still shrunken]]

Spiders generally change their skin for the first time while still inside the egg sac, and the spiderling that emerges broadly resembles the adult. The number of moults varies, both between species and genders, but generally will be between five times and nine times before the spider reaches maturity. Not surprisingly, since males are generally smaller than females, the males of many species mature faster and do not undergo ecdysis as many times as the females before maturing.
Members of the [[Mygalomorphae]] are very long-lived, sometimes 20 years or more; they moult annually even after they mature.

Spiders stop feeding at some time before moulting, usually for several days. The physiological processes of releasing the old exoskeleton from the tissues beneath typically cause various colour changes, such as darkening. If the old exoskeleton is not too thick it may be possible to see new structures, such as [[seta]]e, from outside. However, contact between the nerves and the old exoskeleton is maintained until a very late stage in the process.

The new, teneral exoskeleton has to accommodate a larger frame than the previous [[instar]], while the spider has had to fit into the previous exoskeleton until it has been shed. This means the spider does not fill out the new exoskeleton completely, so it commonly appears somewhat wrinkled.

Most species of spiders hang from silk during the entire process, either dangling from a drop line, or fastening their claws into webbed fibres attached to a suitable base. The discarded, dried exoskeleton typically remains hanging where it was abandoned once the spider has left.

To open the old exoskeleton, the spider generally contracts its abdomen ([[opisthosoma]]) to supply enough fluid to pump into the [[Cephalothorax|prosoma]] with sufficient pressure to crack it open along its lines of weakness. The [[carapace]] lifts off from the front, like a helmet, as its surrounding skin ruptures, but it remains attached at the back. Now the spider works its limbs free and typically winds up dangling by a new thread of silk attached to its own exuviae, which in turn hang from the original silk attachment.

At this point the spider is a callow; it is teneral and vulnerable. As it dangles, its exoskeleton hardens and takes shape. The process may take minutes in small spiders, or some hours in the larger Mygalomorphs. Some spiders, such as some ''[[Synema (spider)|Synema]]'' species, members of the [[Thomisidae]] (crab spiders), mate while the female is still callow, during which time she is unable to eat the male.&lt;ref&gt;{{cite book |author=Erik Holm &amp; Anna Sophia Dippenaar-Schoeman |title=Goggo Guide: the Arthropods of Southern Africa |publisher=LAPA |year=2010 |isbn=978-0-7993-4689-3}}&lt;/ref&gt;

==Eurypterids==
[[Eurypterid]]s are a group of [[chelicerates]] that became [[extinction|extinct]] in the late [[Permian]]. They underwent ecdysis similarly to extant chelicerates, and most fossils are thought to be of exuviae, rather than cadavers.&lt;ref name="Tetlie"/&gt;

==See also==
*[[Ecdysteroid]]

==References==
{{reflist|32em}}

==External links==
*{{Commons category-inline}}

[[Category:Animal developmental biology]]
[[Category:Protostome anatomy]]
[[Category:Ethology]]

[[es:Muda (biología)]]
[[it:Muta (biologia)]]</text>
      <sha1>daojk1uewdjqdpo05isvkx3p9kohiye</sha1>
    </revision>
  </page>
  <page>
    <title>Encyclopedia of Buddhist Arts</title>
    <ns>0</ns>
    <id>55311718</id>
    <revision>
      <id>805685975</id>
      <parentid>805669240</parentid>
      <timestamp>2017-10-17T00:08:05Z</timestamp>
      <contributor>
        <username>Johnbod</username>
        <id>2563820</id>
      </contributor>
      <comment>added [[Category:Art history books]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3693">{{Infobox Book 
| name                 = Encyclopedia of Buddhist Arts 
| image                =
| image_caption        = 
| author               = Venerable Master [[Hsing Yun]], Editor 
| title_orig           = 
| translator           = 
| illustrator          =
| country              = Taiwan
| language             = Traditional Chinese
| series               = 20 books
| subject              = Encyclopedia of Buddhist Arts 
| genre                = 
| publisher            = Fo Guang Shan 
| release_date         = March 2013
| chinese_release_date = 
| media_type           = Hardcover, full-color printing
| pages                = Each book has 384-400 pages
| format               =
| isbn                 = 978-986-5844-00-4
| preceded_by          = 
| followed_by          = 
}}

'''Encyclopedia of Buddhist Arts''' ({{Lang-zh|t=世界佛教美術圖說大辭典|p=Shìjiè fójiào měishù túshuō dà cídiǎn}}) is a set of books that was started by the founder of [[Fo Guang Shan]], Venerable Master Hsing Yun. The project started in 2001 and was completed in March 2013. There are 20 volumes in total and the artwork spans all 5 continents with information from more than 30 countries. The project was made possible with the help of numerous scholars and volunteers, 300 monastics, 140 scholars from 16 different countries, and more than 400 volunteers. Fo Guang Shan has donated copies of the encyclopedia to libraries and academic institutions across the world.&lt;ref&gt;{{cite web |url= https://www.soas.ac.uk/news/newsitem113315.html |title=SOAS Library receives 20-volume Encyclopedia of Buddhist Arts donated by Fo Guang Shan Monastery |last= |first= |date=7 July 2016 |website= [[SOAS, University of London|School of Oriental and African Studies]] |publisher=[[University of London]] |access-date=17 October 2017 |quote=}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url= https://www.soas.ac.uk/news/newsitem113315.html |title=Fo Guang Shan Temple presents Encyclopedia of Buddhist Arts to the Lusi Wong Library
 |last= |first= |date=9 January 2017 |website= Renison University College|publisher=[[University of Waterloo]] |access-date=17 October 2017 |quote=}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.hsilai.org/en/eNews/2015/04082015A.php |title=Fo Guang Shan Donates Encyclopedia of Buddhist Arts to UC Berkeley |last= |first= |date=8 April 2015 |website=[[Hsi Lai Temple]] |publisher= |access-date= 17 October 2017 |quote=}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.alestlelive.com/news/article_60474068-ad4b-11e7-8408-47d43cf07024.html |title=Buddhist temple donates encyclopedias to Lovejoy Library|last=Jordan |first=Corinthia |date=9 October 2017 |website=AlestleLive |publisher= |access-date= 17 October 2017 |quote=}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.lib.ncsu.edu/news/staff-news/libraries-accepts-donation-of-buddhist-encyclopedia |title=Libraries accepts donation of Buddhist encyclopedia |last= |first= |date=23 March 2017 |website=NCSU Libraries |publisher=[[North Carolina State University]] |access-date= 17 October 2017 |quote=}}&lt;/ref&gt;

The volumes are divided into 8 categories: 
* Architecture - 4 volumes
* Caves - 5 volumes
* Sculpture - 4 volumes
* Paintings - 3 volumes
* Calligraphy and engravings - 1 volume
* Artifacts - 1 volume
* People  - 1 volume
* Index - 1 volume
The volumes are printed in color with over 9000 articles, 4 million words, and 15,000 pictures in total.

==References==
{{reflist}}

[[Category:Fo Guang Shan]]
[[Category:Books about Buddhism]]
[[Category:Asian encyclopedias]]
[[Category:21st-century encyclopedias]]
[[Category:Encyclopedias of religion]]
[[Category:Buddhist art]]
[[Category:2013 non-fiction books]]
[[Category:Art history books]]</text>
      <sha1>sap0glvslhlzkkl1gj7r2qe3lcqtzyx</sha1>
    </revision>
  </page>
  <page>
    <title>Entertainment management</title>
    <ns>0</ns>
    <id>8957966</id>
    <revision>
      <id>822673799</id>
      <parentid>822673773</parentid>
      <timestamp>2018-01-27T20:55:58Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>added [[Category:Entertainment]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1986">{{Multiple issues|
{{refimprove|date=September 2014}}
{{peacock|date=September 2011}}
{{advert|date=September 2011}}
}}

'''Entertainment management''' is a relatively new [[business management]] discipline that is increasingly being taught as a [[Bachelor of Arts degree]]. Entertainment management courses aim to provide graduates with appropriate knowledge and skills to progress into management careers within the [[show business|entertainment sector]], managing facilities such as sport events, theme parks, theaters, cinemas, live music venues, museums, art galleries, broadcast media companies and night clubs.{{citation needed|date=September 2011}}

The [[Lubin School of Business]] at [[Pace University]] offers a [[Bachelor of Business Administration|BBA]] degree in [[management]] with a concentration in arts and entertainment.&lt;ref&gt;http://www.pace.edu/lubin/arts-and-entertainment-bba&lt;/ref&gt;

A number of master's-level programs have emerged recently, including [[Carnegie Mellon University|Carnegie Mellon University's]] [[Heinz College|Master of Entertainment Industry Management]] – which offers students with undergraduate degrees in the film and television the opportunity to refocus their education on the management dimension of the work, or Northwestern University's [http://www.creative.northwestern.edu Master of Science in Leadership for Creative Enterprises] program, which offers students with backgrounds in visual, performing, or interactive arts with management and entrepreneurial skills.

Growth in these courses has been linked with growth in both the creative and cultural industries. This growth is linked to increased [[consumer expenditure]] on recreation and entertainment activities. The result is a population assigning greater importance to the free time they have and a consequential willingness to spend more of their income on the 'experience' economy.

==References==
&lt;references /&gt;

[[Category:Management by type]]
[[Category:Entertainment]]</text>
      <sha1>02rcobi0tiethu4eqte5f6cqur7i633</sha1>
    </revision>
  </page>
  <page>
    <title>Euxinia</title>
    <ns>0</ns>
    <id>53489192</id>
    <revision>
      <id>855475921</id>
      <parentid>842500116</parentid>
      <timestamp>2018-08-18T15:53:57Z</timestamp>
      <contributor>
        <username>Pbsouthwood</username>
        <id>10044298</id>
      </contributor>
      <comment>Adding local [[Wikipedia:Short description|short description]]: "Condition when water is both anoxic and sulfidic" ([[User:Galobtter/Shortdesc helper.js|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54459">{{short description|Condition when water is both anoxic and sulfidic}}
'''Euxinia''' or '''euxinic conditions''' occur when water is both [[Anoxic event|anoxic]] and sulfidic. This means that there is no [[oxygen]] (O&lt;sub&gt;2&lt;/sub&gt;) and a raised level of free [[hydrogen sulfide]] (H&lt;sub&gt;2&lt;/sub&gt;S). Euxinic bodies of water are frequently strongly stratified, have an oxic, highly productive, thin surface layer, and have anoxic, sulfidic bottom water.  The word euxinia is derived from the Greek name for the Black Sea- Εὔξεινος Πόντος (''Euxeinos Pontos)''- which translates to "hospitable sea".&lt;ref name=":1"&gt;{{Cite journal|last=Meyer|first=Katja M.|last2=Kump|first2=Lee R.|date=2008-04-29|title=Oceanic Euxinia in Earth History: Causes and Consequences|url=http://www.annualreviews.org/doi/10.1146/annurev.earth.36.031207.124256|journal=Annual Review of Earth and Planetary Sciences|language=en|volume=36|issue=1|pages=251–288|doi=10.1146/annurev.earth.36.031207.124256}}&lt;/ref&gt; Euxinic deep water is a key component of the [[Canfield ocean]], a model of oceans during the Proterozoic known as the [[Boring Billion]] proposed by [[Donald Canfield]], an American geologist, in 1998.&lt;ref name=":0" /&gt; There is still debate within the scientific community on both the duration and frequency of euxinic conditions in the ancient oceans.&lt;ref name=":17"&gt;{{Cite journal|last=Lyons|first=Timothy W.|date=2008-08-15|title=Ironing Out Ocean Chemistry at the Dawn of Animal Life|url=http://science.sciencemag.org/content/321/5891/923|journal=Science|language=en|volume=321|issue=5891|pages=923–924|doi=10.1126/science.1162870|issn=0036-8075|pmid=18703731}}&lt;/ref&gt; Euxinia is relatively rare in modern bodies of water, but does still happen in places like the Black Sea and certain fjords.

== Background ==
Euxinia most frequently occurred in the Earth's ancient oceans, but its distribution and frequency of occurrence are still under debate.&lt;ref name=":2"&gt;{{Cite journal|last=Lyons|first=Timothy W.|last2=Anbar|first2=Ariel D.|last3=Severmann|first3=Silke|last4=Scott|first4=Clint|last5=Gill|first5=Benjamin C.|date=2009-04-27|title=Tracking Euxinia in the Ancient Ocean: A Multiproxy Perspective and Proterozoic Case Study|url=http://www.annualreviews.org/doi/10.1146/annurev.earth.36.031207.124233|journal=Annual Review of Earth and Planetary Sciences|language=en|volume=37|issue=1|pages=507–534|doi=10.1146/annurev.earth.36.031207.124233}}&lt;/ref&gt; The original model was that it was quite constant for approximately a billion years.&lt;ref name=":0" /&gt; Some meta-analyses have questioned how persistent euxinic conditions were based on relatively small [[black shale]] deposits in a period when the ocean should have theoretically been preserving more organic matter.&lt;ref name=":1" /&gt;

Before the [[Great Oxygenation Event]] happened approximately 2.3 billion years ago, there was little free oxygen in either the atmosphere or the ocean.&lt;ref&gt;{{Cite book|url=https://link.springer.com/chapter/10.1007/978-3-319-12415-5_1|title=Sustaining Life on Planet Earth: Metalloenzymes Mastering Dioxygen and Other Chewy Gases|last=Torres|first=Martha E. Sosa|last2=Saucedo-Vázquez|first2=Juan P.|last3=Kroneck|first3=Peter M. H.|date=2015-01-01|publisher=Springer International Publishing|isbn=9783319124148|editor-last=Kroneck|editor-first=Peter M. H.|series=Metal Ions in Life Sciences|pages=1–12|language=en|doi=10.1007/978-3-319-12415-5_1|editor-last2=Torres|editor-first2=Martha E. Sosa}}&lt;/ref&gt; It was originally thought that the ocean accumulated oxygen soon after the atmosphere did, but this idea was challenged by Canfield in 1998 when he proposed that instead of the deep ocean becoming oxidizing, it became sulfidic.&lt;ref name=":0"&gt;{{Cite journal|last=Canfield|first=D. E.|year=|title=A new model for Proterozoic ocean chemistry|url=http://www.nature.com/doifinder/10.1038/24839|journal=Nature|volume=396|issue=6710|pages=450–453|doi=10.1038/24839|via=}}&lt;/ref&gt; This hypothesis is partially based on the disappearance of [[banded iron formation]]&lt;nowiki/&gt;s from the geological records 1.8 billion years ago. Canfield argued that although enough oxygen entered the atmosphere to erode sulfides in continental rocks, there was not enough oxygen to mix into the deep ocean.&lt;ref name=":0" /&gt; This would result in an anoxic deep ocean with an increased flux of sulfur from the continents. The sulfur would strip iron ions from the sea water, resulting in [[iron sulfide]] (pyrite), a portion of which was eventually buried. When sulfide became the major oceanic [[oxidant]] instead of iron, the deep water became euxinic.&lt;ref name=":1" /&gt; This has become what is known as the [[Canfield ocean]], a model backed by the increase in presence of δ&lt;sup&gt;34&lt;/sup&gt;S in sedimentary [[pyrite]]&lt;ref name=":0" /&gt; and the discovery of evidence of the first sulfate [[evaporite]]&lt;nowiki/&gt;s.&lt;ref name=":14"&gt;{{Cite journal|last=Melezhik|first=Victor A.|last2=Fallick|first2=Anthony E.|last3=Rychanchik|first3=Dmitry V.|last4=Kuznetsov|first4=Anton B.|date=2005-04-01|title=Palaeoproterozoic evaporites in Fennoscandia: implications for seawater sulphate, the rise of atmospheric oxygen and local amplification of the δ13C excursion|url=http://onlinelibrary.wiley.com/doi/10.1111/j.1365-3121.2005.00600.x/abstract|journal=Terra Nova|language=en|volume=17|issue=2|pages=141–148|doi=10.1111/j.1365-3121.2005.00600.x|issn=1365-3121}}&lt;/ref&gt;

[[Anoxic event|Anoxia]] and sulfidic conditions often occur together. In anoxic conditions anaerobic, sulfate reducing bacteria convert sulfate into sulfide, creating sulfidic conditions.&lt;ref name=":2" /&gt; The emergence of this metabolic pathway was very important in the pre-oxygenated oceans because adaptations to otherwise inhabitable or "toxic" environments like this may have played a role in the diversification of early eukaryotes and protozoa in the pre-Phanerozoic.&lt;ref name=":2" /&gt;

Euxinia still occurs occasionally today, mostly in [[meromictic lakes]] and silled basins such as the [[Black Sea]] and some fjords.&lt;ref name=":1" /&gt; It is rare in modern times; less than 0.5% of today's sea floor is euxinic.&lt;ref name=":2" /&gt;

== Causes ==
[[File:How oceans become euxinic.png|thumb|600x600px|Diagram of mechanisms of euxinia in the Canfield Ocean]]
The basic requirements for the formation of euxinic conditions are the absence of [[oxygen]] (O&lt;sub&gt;2&lt;/sub&gt;), and the presence of [[Sulfate|sulfate ions]] (SO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2−&lt;/sup&gt;), organic matter (CH&lt;sub&gt;2&lt;/sub&gt;O), and [[Sulfate-reducing bacteria|bacteria]] capable of reducing sulfate to [[hydrogen sulfide]] (H&lt;sub&gt;2&lt;/sub&gt;S).&lt;ref name=":1" /&gt; The bacteria utilize the [[redox]] potential of sulfate as an [[Oxidizing agent|oxidant]] and organic matter as a [[Reducing agent|reductant]] to generate chemical energy through [[Anaerobic respiration|cellular respiration]]. The chemical species of interest can be represented via the reaction:

2CH&lt;sub&gt;2&lt;/sub&gt;O + SO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2−&lt;/sup&gt; → H&lt;sub&gt;2&lt;/sub&gt;S + 2HCO&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;

In the reaction above the sulfur has been reduced to form the [[By-product|byproduct]] hydrogen sulfide, the characteristic compound present in water under euxinic conditions. Although sulfate reduction occurs in waters throughout the world, most modern-day aquatic habitats are oxygenated due to [[photosynthesis|photosynthetic]] production of oxygen and [[gas exchange]] between the atmosphere and surface water. Sulfate reduction in these environments is often limited to occurring in [[seabed]] [[sediment]]s that have a strong [[redox gradient]] and become [[Anoxic waters|anoxic]] at some depth below the [[Sediment–water interface|sediment-water interface]]. In the ocean the [[Reaction rate|rate]] of these reactions is not [https://online.science.psu.edu/biol011_active002/node/4343 limited] by sulfate, which has been present in large quantities throughout the oceans for the past 2.1 billion years.&lt;ref name=":14" /&gt; The [[Great Oxygenation Event]] increased atmospheric oxygen concentrations such that oxidative [[weathering]] of [[Sulfide minerals|sulfides]] became a major source of sulfate to the ocean.&lt;ref&gt;{{Cite journal|last=Cameron|first=E. M.|year=1982|title=Sulphate and sulphate reduction in early Precambrian oceans|url=http://www.nature.com/nature/journal/v296/n5853/pdf/296145a0.pdf|journal=Nature|volume=296|pages=145–148|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Canfield|first=Donald E.|last2=Farquhar|first2=James|date=2009-05-19|year=|title=Animal evolution, bioturbation, and the sulfate concentration of the oceans|url=http://www.pnas.org/content/106/20/8123|journal=Proceedings of the National Academy of Sciences|language=en|volume=106|issue=20|pages=8123–8127|doi=10.1073/pnas.0902037106|issn=0027-8424|pmc=2688866|pmid=19451639|via=}}&lt;/ref&gt; Despite plentiful sulfate ions being present in solution, they are not preferentially used by most bacteria. The reduction of sulfate does not give as much energy to an organism as reduction of oxygen or [[nitrate]], so the concentrations of these other elements must be nearly zero for sulfate-reducing bacteria to out-compete [[Aerobic organism|aerobic]] and [[denitrifying bacteria]]. In most modern settings these conditions only occur in a small portion of sediments, resulting in insufficient concentrations of hydrogen sulfide to form euxinic waters.&lt;ref name=":2" /&gt;

Conditions required for the formation of persistent euxinia include [[anoxic waters]], high [[nutrient]] levels, and a [[Stratification (water)|stratified]] water column.&lt;ref name=":1" /&gt; These conditions are not all-inclusive and are based largely on modern observations of euxinia. Conditions leading up to and triggering large-scale euxinic events, such as the [[Canfield ocean]], are likely the result of multiple interlinking factors, many of which have been inferred through studies of the [[geologic record]] at relevant locations.&lt;ref name=":9" /&gt;&lt;ref name=":10" /&gt;&lt;ref name=":11" /&gt;&lt;ref name=":12" /&gt; The formation of stratified anoxic waters with high nutrient levels is influenced by a variety of global and local-scale phenomena such as the presence of nutrient traps and a warming climate.&lt;ref name=":1" /&gt;

=== Nutrient traps ===
In order for euxinic conditions to persist, a positive feedback loop must exist that perpetuates organic matter export to bottom waters and reduction of sulfate under anoxic conditions. Organic matter export is driven by high levels of primary production in the [[photic zone]], supported by a continual supply of nutrients to the oxic surface waters. A natural source of nutrients, such as phosphate ({{chem|PO|4|3−}}), comes from [[weathering]] of rocks and subsequent transport of these dissolved nutrients via rivers.&lt;ref&gt;{{Cite journal|last=Moore|first=C. M.|last2=Mills|first2=M. M.|last3=Arrigo|first3=K. R.|last4=Berman-Frank|first4=I.|last5=Bopp|first5=L.|last6=Boyd|first6=P. W.|last7=Galbraith|first7=E. D.|last8=Geider|first8=R. J.|last9=Guieu|first9=C.|title=Processes and patterns of oceanic nutrient limitation|url=http://www.nature.com/doifinder/10.1038/ngeo1765|journal=Nature Geoscience|volume=6|issue=9|pages=701–710|doi=10.1038/ngeo1765}}&lt;/ref&gt; In a nutrient trap, increased input of phosphate from rivers, high rates of recycling of phosphate from sediments, and slow vertical mixing in the water column allow for euxinic conditions to persist.&lt;ref name=":8" /&gt;

==== Geography ====
[[File:FjordCirculation.JPG|thumb|399x399px|A simplified model of estuarine circulation in a silled basin. Depicted here is a three-layered body of water which has been further simplified in the article by combining the intermediate and deep layers.]]
The arrangement of the continents has changed over time due to [[plate tectonics]], resulting in the [[bathymetry]] of ocean basins also changing over time. The shape and size of the basins influences the circulation patterns and concentration of nutrients within them. [[Computer simulation|Numerical models]] simulating past arrangements of continents have shown that nutrient traps can form in certain scenarios, increasing local concentrations of phosphate and setting up potential euxinic conditions.&lt;ref name=":1" /&gt; On a smaller scale, silled basins often act as nutrient traps due to their typical [[Estuarine water circulation|estuarine circulation]].&lt;ref name=":8" /&gt; Estuarine circulation occurs where surface water is replenished from river input and precipitation, causing an outflow of surface waters from the basin, while deep water flows into the basin over the sill. This type of circulation allows for anoxic, high nutrient bottom water to develop within the basin.&lt;ref name=":1" /&gt;

==== Stratification ====
Stratified waters, in combination with slow vertical mixing, are essential to maintaining euxinic conditions.&lt;ref name=":1" /&gt; Stratification occurs when two or more water masses with different densities occupy the same basin. While the less dense surface water can exchange gas with the oxygen-rich atmosphere, the denser bottom waters maintain low oxygen content. In the modern oceans, [[thermohaline circulation]] and [[upwelling]] prevent the oceans from maintaining anoxic bottom waters. In a silled basin, the stable stratified layers only allow surface water to flow out of the basin while the deep water remains anoxic and relatively unmixed. During an intrusion of dense saltwater however, the nutrient-rich bottom water upwells, causing increased [[Primary production|productivity]] in the surface, further enhancing the nutrient trap due to [[biological pump]]ing. Rising sea level can exacerbate this process by increasing the amount of deep water entering a silled basin and enhancing estuarine circulation.&lt;ref&gt;{{Cite journal|last=Middelburg|first=J. J.|last2=Calvert|first2=S. E.|last3=Karlin|first3=R.|date=1991-07-01|title=Organic-rich transitional facies in silled basins: Response to sea-level change|url=http://geology.gsapubs.org/content/19/7/679|journal=Geology|language=en|volume=19|issue=7|pages=679–682|doi=10.1130/0091-7613(1991)0192.3.CO;2|issn=0091-7613}}&lt;/ref&gt;&lt;ref name=":15"&gt;{{Cite journal|last=Arthur|first=M.A.|last2=Sageman|first2=B.B.|year=2005|title=Sea Level Control on Source Rock Development: Perspectives from the Holocene Black Sea, the mid-Cretaceous Western Interior Basin of North America, and the Late Devonian Appalachian Basin|url=http://www.earth.northwestern.edu/research/sageman/PDF/05.Arthur&amp;Sageman.pdf|journal=SEPM|volume=82|pages=35–59|via=}}&lt;/ref&gt;

=== Warming climate ===
A warming climate increases surface temperatures of waters which effects multiple aspects of euxinic water formation. As waters warm, the [[solubility]] of [[Ocean deoxygenation|oxygen decreases]], allowing for deep anoxic waters to form more readily.&lt;ref&gt;{{Cite journal|last=Hotinski|first=Roberta M.|year=2001|title=Ocean stagnation and end-Permian anoxia|url=https://www.researchgate.net/publication/235451836_Ocean_Stagnation_and_end_Permian_anoxia|journal=Geology|volume=29|pages=7–10|via=}}&lt;/ref&gt; Additionally, the warmer water causes increased respiration of organic matter leading to further oxygen depletion. Higher temperatures enhance the hydrologic cycle, increasing evaporation from bodies of water, resulting in increased precipitation. This causes higher rates of weathering of rocks and therefore higher nutrient concentrations in river outflows. The nutrients allow for more productivity resulting in more [[marine snow]] and subsequently lower oxygen in deep waters due to increased respiration.&lt;ref name=":1" /&gt;

Volcanism has also been proposed to be a factor in creating euxinic conditions. The [[Carbon dioxide in Earth's atmosphere|carbon dioxide]] (CO&lt;sub&gt;2&lt;/sub&gt;) released during [[Volcanism|volcanic]] outgassing causes [[global warming]] which has cascading effects on the formation of euxinic conditions.&lt;ref name=":1" /&gt;&lt;ref name=":15" /&gt;

== Evidence for euxinic events ==

=== Black shale ===
[[File:Black shale, Kansas City MO - panoramio.jpg|thumb|Black shale is one of the preliminary indicators of anoxia and perhaps euxinia]]
Black shales are organic rich, microlaminated sedimentary rocks often associated with bottom water anoxia. This is because anoxia slows the degradation of organic matter, allowing for greater burial in the sediments. Other evidence for anoxic burial of black shale includes the lack of [[bioturbation]], meaning that there were no organisms burrowing into the sediment because there was no oxygen for respiration.&lt;ref name=":2" /&gt; There must also be a source of organic matter for burial, generally from production near the oxic surface. Many papers discussing ancient euxinic events use the presence of black shale as a preliminary proxy for anoxic bottom waters, but it should be noted that their presence does not in and of itself indicate euxinia or even strong anoxia. Generally geochemical testing is needed to provide better evidence for conditions.&lt;ref name=":2" /&gt;

=== Geochemistry ===
Some researchers study the occurrence of euxinia in ancient oceans because it was more prevalent then than it is today. Since ancient oceans cannot be directly observed, scientists use geology and chemistry to find evidence in [[sedimentary rock]] created under euxinic conditions. Some of these techniques come from studying modern examples of euxinia, while others are derived from geochemistry. Though modern euxinic environments have geochemical properties in common with ancient euxinic oceans, the physical processes causing euxinia most likely vary between the two.&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;

==== Isotopes ====
[[Stable isotope ratio]]&lt;nowiki/&gt;s can be used to infer the environmental conditions during the formation of sedimentary rock. Using [[stoichiometry]] and knowledge of [[redox]] pathways, paleogeologists can use [[isotope]]&lt;nowiki/&gt;s ratios of elements to determine the chemical composition of the water and sediments when burial occurred.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/945435170|title=Stable isotope geochemistry|last=Jochen.|first=Hoefs,|date=2015-01-01|publisher=Springer|isbn=9783319197159|oclc=945435170}}&lt;/ref&gt;

Sulfur isotopes are frequently used to look for evidence of ancient euxinia. Low δ&lt;sup&gt;34&lt;/sup&gt;S in black shales and sedimentary rocks provides positive evidence for euxinic formation conditions. The pyrite (FeS&lt;sub&gt;2&lt;/sub&gt;) in euxinic basins typically has higher concentrations of light sulfur isotopes than pyrite in the modern ocean.&lt;ref name=":1" /&gt; The reduction of sulfate to sulfide favors the lighter sulfur isotopes (&lt;sup&gt;32&lt;/sup&gt;S) and becomes depleted in the heavier isotopes (&lt;sup&gt;34&lt;/sup&gt;S). This lighter sulfide then bonds with Fe&lt;sup&gt;2+&lt;/sup&gt; to form FeS&lt;sub&gt;2&lt;/sub&gt; which is then partially preserved in the sediments. In most modern systems, sulfate eventually becomes limiting, and the isotopic weights of sulfur in both sulfate and sulfide (preserved as FeS&lt;sub&gt;2&lt;/sub&gt;) become equal.&lt;ref name=":1" /&gt;

Molybdenum (Mo), the most common transition metal ion in modern seawater, is also used to look for evidence for euxinia.&lt;ref name=":2" /&gt; Weathering of rocks provides an input of MoO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2–&lt;/sup&gt; into oceans. Under oxic conditions, MoO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2–&lt;/sup&gt;  is very unreactive, but in modern euxinic environments such as the [[Black Sea]], molybdenum precipitates out as oxythiomolybdate (MoO&lt;sub&gt;4−x&lt;/sub&gt;S&lt;sub&gt;x&lt;/sub&gt;&lt;sup&gt;2–&lt;/sup&gt; ).&lt;ref name=":16"&gt;{{Cite journal|last=Arnold|first=G. L.|last2=Anbar|first2=A. D.|last3=Barling|first3=J.|last4=Lyons|first4=T. W.|date=2004-04-02|title=Molybdenum Isotope Evidence for Widespread Anoxia in Mid-Proterozoic Oceans|url=http://science.sciencemag.org/content/304/5667/87|journal=Science|language=en|volume=304|issue=5667|pages=87–90|doi=10.1126/science.1091785|issn=0036-8075|pmid=15066776}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Anbar|first=Ariel D.|last2=Duan|first2=Yun|last3=Lyons|first3=Timothy W.|last4=Arnold|first4=Gail L.|last5=Kendall|first5=Brian|last6=Creaser|first6=Robert A.|last7=Kaufman|first7=Alan J.|last8=Gordon|first8=Gwyneth W.|last9=Scott|first9=Clinton|date=2007-09-28|title=A Whiff of Oxygen Before the Great Oxidation Event?|url=http://science.sciencemag.org/content/317/5846/1903|journal=Science|language=en|volume=317|issue=5846|pages=1903–1906|doi=10.1126/science.1140325|issn=0036-8075|pmid=17901330}}&lt;/ref&gt; The isotope ratio for Molybdenum (δ&lt;sup&gt;97/95&lt;/sup&gt; Mo) in euxinic sediments appears to be higher than in oxic conditions.&lt;ref name=":16" /&gt; Additionally, the concentration of molybdenum is frequently correlated with the concentration of organic matter in euxinic sediments.&lt;ref name=":2" /&gt; The use of Mo to indicate euxinia is still under debate.&lt;ref name=":2" /&gt;

==== Trace-element enrichment ====
Under euxinic conditions, some trace elements such as Mo, U, V, Cd, Cu, Tl, Ni, Sb, and Zn, become insoluble.&lt;ref&gt;{{Cite journal|last=Algeo|first=Thomas J|last2=Maynard|first2=J. Barry|date=2004-06-16|title=Trace-element behavior and redox facies in core shales of Upper Pennsylvanian Kansas-type cyclothems|url=http://www.sciencedirect.com/science/article/pii/S0009254103003930|journal=Chemical Geology|series=Geochemistry of Organic-Rich Shales: New Perspectives|volume=206|issue=3–4|pages=289–318|doi=10.1016/j.chemgeo.2003.12.009}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Brumsack|first=Hans-J.|date=2006-03-22|title=The trace metal content of recent organic carbon-rich sediments: Implications for Cretaceous black shale formation|url=http://www.sciencedirect.com/science/article/pii/S0031018205002737|journal=Palaeogeography, Palaeoclimatology, Palaeoecology|volume=232|issue=2–4|pages=344–361|doi=10.1016/j.palaeo.2005.05.011}}&lt;/ref&gt;  This means that euxinic sediments would contain more of the solid form of these elements than the background seawater.&lt;ref name=":1" /&gt;  For example, Molybdenum and other trace metals become insoluble in anoxic and sulfidic conditions, so over time the seawater becomes depleted of trace metals under conditions of persistent euxinia, and preserved sediments are relatively enriched with molybdenum and other trace elements.&lt;ref&gt;{{Cite journal|last=Algeo|first=Thomas J.|date=2004-12-01|title=Can marine anoxic events draw down the trace element inventory of seawater?|url=http://geology.gsapubs.org/content/32/12/1057|journal=Geology|language=en|volume=32|issue=12|pages=1057–1060|doi=10.1130/G20896.1|issn=0091-7613}}&lt;/ref&gt;

==== Organic biomarkers ====
[[File:Purple and Green Sulfur Bacteria and Their Biomarkers.png|thumb|440x440px|Pigments from purple and green sulfur reducing bacteria are strong evidence for euxinic conditions]]
Bacteria such as [[green sulfur bacteria]] (GSB) and [[purple sulfur bacteria]] (PSB), which exist where the photic zone overlaps with euxinic water masses, leave pigments behind in sediments.  These pigments can be used to identify past euxinic conditions.&lt;ref name=":1" /&gt; The pigments used to identify past presesnce of GSB are [[chlorobactane]] and [[isorenieratene]].&lt;ref name=":18"&gt;{{Cite journal|last=Overmann|first=Jörg|last2=Cypionka|first2=Heribert|last3=Pfennig|first3=Norbert|date=1992-01-01|title=An extremely low-light adapted phototrophic sulfur bacterium from the Black Sea|url=http://onlinelibrary.wiley.com/doi/10.4319/lo.1992.37.1.0150/abstract|journal=Limnology and Oceanography|language=en|volume=37|issue=1|pages=150–155|doi=10.4319/lo.1992.37.1.0150|issn=1939-5590}}&lt;/ref&gt; The pigments used to identify past presence of PSB is [[okenane]].&lt;ref&gt;{{Cite journal|last=Overmann|first=Jörg|last2=Sandmann|first2=Gerhard|last3=Hall|first3=Ken J.|last4=Northcote|first4=Tom G.|date=1993-03-01|title=Fossil carotenoids and paleolimnology of meromictic Mahoney Lake, British Columbia, Canada|url=https://link.springer.com/article/10.1007/BF00877257|journal=Aquatic Sciences|language=en|volume=55|issue=1|pages=31–39|doi=10.1007/BF00877257|issn=1015-1621}}&lt;/ref&gt;

==== Iron geochemistry ====
[[Pyrite]] (FeS&lt;sub&gt;2&lt;/sub&gt;) is a mineral formed by the reaction of hydrogen sulfide (H&lt;sub&gt;2&lt;/sub&gt;S) and bioreactive iron (Fe&lt;sup&gt;2+&lt;/sup&gt;). In oxic bottom waters pyrite can only form in sediments where H&lt;sub&gt;2&lt;/sub&gt;S is present. However, in iron-rich euxinic environments, pyrite formation can occur at higher rates in both the water column and in sediments due to higher concentrations of H&lt;sub&gt;2&lt;/sub&gt;S.&lt;ref name=":8" /&gt; Threfore the presence of euxinic conditions can be inferred by the ratio of pyrite-bound iron to the total iron in sediments. High ratios of pyrite-bound iron can be used as an indicator of past euxinic conditions.&lt;ref name=":9"&gt;{{Cite journal|last=Lyons|first=Timothy|last2=Severmann|first2=Silke|year=2006|title=A critical look at iron paleoredox proxies: New insights from modern euxinic marine basins|url=|journal=Geochimica et Cosmochimica Acta|volume=70|pages=5698–5722|via=Elsevier Science Direct}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Raiswell|first=R.|last2=Newton|first2=R.|last3=Wignall|first3=P. B.|date=2001-03-01|title=An Indicator of Water-Column Anoxia: Resolution of Biofacies Variations in the Kimmeridge Clay (Upper Jurassic, U.K.)|url=http://jsedres.geoscienceworld.org/content/71/2/286|journal=Journal of Sedimentary Research|language=en|volume=71|issue=2|pages=286–294|doi=10.1306/070300710286|issn=1527-1404}}&lt;/ref&gt; Similarly, if &gt;45% of the bioreactive iron in sediments is pyrite-bound, then anoxic or euxinic conditions can be inferred.&lt;ref name=":8" /&gt; While useful, these methods do not provide definitive proof of euxinia because not all euxinic waters have the same concentrations of bioreactive iron available.&lt;ref name=":8" /&gt; These relationships have been found to be present in the modern euxinic Black Sea.&lt;ref name=":10"&gt;{{Cite journal|last=Lyons|first=Timothy|year=1997|title=Sulfur isotopic trends and pathways of iron sulfide formation in upper Holocene sediments of the anoxic Black Sea|url=|journal=Geochimica et Cosmochimica Acta|volume=61|pages=3367–3382|via=Elsevier Science Direct}}&lt;/ref&gt;

== Euxinic events in Earth's history ==

  [[File:Timeline of euxinia in ancient oceans.png|thumb|660x660px|Presence of euxinia in the world's ancient deep oceans. According to Canfield, the deep ocean became sulfitic around 1.8 billion years ago and stayed that way for much of the boring billion. Periodic euxinia dominated through the Late Devonian Kelwasser events, and then most likely disappeared during the Carboniferous. Euxinia reemerged at the Permian-Triassic Boundary, and may have been present during the Ocean Anoxia Events of the Mesozoic. Euxinia is rare in Cenozoic oceans. Adapted from Lyons, 2008&lt;ref name=":17"/&gt;]]

=== Proterozoic ===
The Proterozoic is the transition era between anoxic and oxygenated oceans. The classic model is that the end of the [[Banded iron formation]]&lt;nowiki/&gt;s (BIFs) was due to the injection of oxygen into the deep ocean, an approximately 0.6 billion year lag behind the [[Great Oxygenation Event]].&lt;ref name=":4"&gt;{{Cite journal|last=Holland|first=Heinrich D.|date=2006-06-29|year=|title=The oxygenation of the atmosphere and oceans|url=http://rstb.royalsocietypublishing.org/content/361/1470/903|journal=Philosophical Transactions of the Royal Society B: Biological Sciences|language=en|volume=361|issue=1470|pages=903–915|doi=10.1098/rstb.2006.1838|issn=0962-8436|pmid=16754606|via=|pmc=1578726}}&lt;/ref&gt; Canfield, however, argued that anoxia lasted much longer, and the end of the banded iron formations was due to the introduction of sulfide.&lt;ref name=":0" /&gt; Supporting Canfield's original hypothesis, 1.84 billion year old sedimentary records have been found in the Animike group in Canada that exhibit close to full pyritization on top of the last of the banded iron formations, showing evidence of a transition to euxinic conditions in that basin.&lt;ref name=":3"&gt;{{Cite journal|last=Poulton|first=Simon W.|last2=Fralick|first2=Philip W.|last3=Canfield|first3=Donald E.|date=2004-09-09|title=The transition to a sulphidic ocean {{!}}[sim]{{!}} 1.84 billion years ago|url=http://www.nature.com/nature/journal/v431/n7005/full/nature02912.html|journal=Nature|language=en|volume=431|issue=7005|pages=173–177|doi=10.1038/nature02912|issn=0028-0836}}&lt;/ref&gt;   In order for full pyritization to happen, nearly all of the sulfate in the water was reduced to sulfide, which stripped the iron from the water, forming pyrite. Because this basin was open to the ocean, deep euxinia was interpreted as being a widespread phenomena.&lt;ref name=":3" /&gt; This euxinia is hypothesized to have lasted until about 0.8 billion years ago, making basin bottom euxinia a potentially widespread feature throughout the [[Boring Billion]].&lt;ref name=":3" /&gt;

Further evidence for euxinia was discovered in the McArthur Basin in Australia, where similar iron chemistry was found. The degree of pyritization and the δ&lt;sup&gt;34&lt;/sup&gt;S were both high, supporting the presence of anoxia and sulfide, as well as the depletion of sulfate.&lt;ref name=":8"&gt;{{Cite journal|last=Shen|first=Yanan|last2=Canfield|first2=Donald E.|last3=Knoll|first3=Andrew H.|date=2002-02-01|title=Middle Proterozoic ocean chemistry: Evidence from the McArthur Basin, northern Australia|url=http://www.ajsonline.org/content/302/2/81|journal=American Journal of Science|language=en|volume=302|issue=2|pages=81–109|doi=10.2475/ajs.302.2.81|issn=0002-9599}}&lt;/ref&gt; A different study found biomarkers for [[green sulfur bacteria]] and [[purple sulfur bacteria]] in the same area, providing further evidence for the reduction of sulfate to hydrogen sulfide.&lt;ref&gt;{{Cite journal|last=Brocks|first=Jochen J.|last2=Love|first2=Gordon D.|last3=Summons|first3=Roger E.|last4=Knoll|first4=Andrew H.|last5=Logan|first5=Graham A.|last6=Bowden|first6=Stephen A.|date=2005-10-06|title=Biomarker evidence for green and purple sulphur bacteria in a stratified Palaeoproterozoic sea|url=http://www.nature.com/nature/journal/v437/n7060/abs/nature04068.html|journal=Nature|language=en|volume=437|issue=7060|pages=866–870|doi=10.1038/nature04068|issn=0028-0836}}&lt;/ref&gt;

Molybdenum isotopes have been used to examine the distribution of euxinia in the Proterozoic eon, and suggest that perhaps euxinia was not as widespread as Canfield initially postulated. Bottom waters may have been more widely suboxic than anoxic, and there could have been negative feedback between euxinia and the high levels of surface primary production needed to sustain euxinic conditions.&lt;ref&gt;{{Cite journal|last=Scott|first=C.|last2=Lyons|first2=T. W.|last3=Bekker|first3=A.|last4=Shen|first4=Y.|last5=Poulton|first5=S. W.|last6=Chu|first6=X.|last7=Anbar|first7=A. D.|date=2008-03-27|title=Tracing the stepwise oxygenation of the Proterozoic ocean|url=http://www.nature.com/nature/journal/v452/n7186/abs/nature06811.html|journal=Nature|language=en|volume=452|issue=7186|pages=456–459|doi=10.1038/nature06811|issn=0028-0836}}&lt;/ref&gt; Further work has suggested that from 700 million years ago (late Proterozoic) and onward, the deep oceans may have actually been anoxic and iron rich with conditions similar to those during the formation of BIFs.&lt;ref name=":17" /&gt;&lt;ref&gt;{{Cite journal|last=Canfield|first=Donald E.|last2=Poulton|first2=Simon W.|last3=Knoll|first3=Andrew H.|last4=Narbonne|first4=Guy M.|last5=Ross|first5=Gerry|last6=Goldberg|first6=Tatiana|last7=Strauss|first7=Harald|date=2008-08-15|title=Ferruginous Conditions Dominated Later Neoproterozoic Deep-Water Chemistry|url=http://science.sciencemag.org/content/321/5891/949|journal=Science|language=en|volume=321|issue=5891|pages=949–952|doi=10.1126/science.1154499|issn=0036-8075|pmid=18635761}}&lt;/ref&gt;

=== Phanerozoic ===
There is evidence for multiple euxinic events during the Phanerozoic. It is most likely that euxinia was periodic during the Paleozoic and Mesozoic, but geologic data is too sparse to draw any large scale conclusions. In this eon, there is some evidence that euxinic events are potentially linked with mass extinction events including the [[Late Devonian extinction|Late Devonian]] and [[Permian–Triassic extinction event|Permian–Triassic]].&lt;ref name=":1" /&gt;

==== Paleozoic ====

The periodic presence of euxinic conditions in the Lower Cambrian has been supported by evidence found on the Yangtze platform in South China. Sulfur isotopes during the transition from Proterozoic to Phanerozoic give evidence for widespread euxinia, perhaps lasting throughout the Cambrian period.&lt;ref&gt;Gill, Benjamin C, Timothy W Lyons, Seth a Young, Lee R Kump, Andrew H Knoll, and Matthew R Saltzman. 2010. “Geochemical Evidence for Widespread Euxinia in the Later Cambrian Ocean.” ''Nature'' 469 (7328): 80–83. doi:10.1038/nature09700.&lt;/ref&gt;  Towards the end of the Lower Cambrian, the euxinic chemocline grew deeper until euxinia was present only in the sediments, and once sulfate became limiting, conditions became anoxic instead of euxinic. Some areas eventually became oxic, while others eventually returned to euxinic for some time.&lt;ref&gt;{{Cite journal|last=Goldberg|first=Tatiana|last2=Strauss|first2=Harald|last3=Guo|first3=Qingjun|last4=Liu|first4=Congqiang|date=2007-10-08|title=Reconstructing marine redox conditions for the Early Cambrian Yangtze Platform: Evidence from biogenic sulphur and organic carbon isotopes|url=http://www.sciencedirect.com/science/article/pii/S0031018207001800|journal=Palaeogeography, Palaeoclimatology, Palaeoecology|series=From Snowball Earth to the Cambrian bioradiation: calibration of Ediacaran-Cambrian history in South China|volume=254|issue=1–2|pages=175–193|doi=10.1016/j.palaeo.2007.03.015}}&lt;/ref&gt;

Geological records from the paleozoic in the Selwyn Basin in Northern Canada have also shown evidence for episodic stratification and mixing, where, using δ&lt;sup&gt;34&lt;/sup&gt;S, it was determined that hydrogen sulfide was more prevalent than [[sulfate]].&lt;ref&gt;{{Cite journal|last=Goodfellow|first=Wayne D|last2=Jonasson|first2=Ian R|year=1984|title=Data from ocean stagnation and ventilation defined by secular trends in pyrite and baritye, Selwyn Basin, Yukon|url=|journal=Geology|volume=12|pages=583–586|via=}}&lt;/ref&gt; Although this was not originally attributed to euxinia, further studies found that seawater in that time likely had low concentrations of sulfate, meaning that the sulfur in the water was primarily in the form of sulfide. This combined with organic-rich black shale provide strong evidence for euxinia.&lt;ref&gt;{{Cite journal|last=Lowenstein|first=Tim K.|last2=Hardie|first2=Lawrence A.|last3=Timofeeff|first3=Michael N.|last4=Demicco|first4=Robert V.|title=Secular variation in seawater chemistry and the origin of calcium chloride basinal brines|url=http://mr.crossref.org/iPage?doi=10.1130%2FG19728R.1|journal=Geology|volume=31|issue=10|doi=10.1130/g19728r.1}}&lt;/ref&gt;

There is similar evidence in the black shales in the mid-continent North America from the Devonian and early Mississippian periods. [[Isorenieratene]], a pigment known as a proxy for an anoxic photic zone, has been found in the geological record in Illinois and Michigan.&lt;ref name=":11"&gt;{{Cite journal|last=Brown|first=Todd C.|last2=Kenig|first2=Fabien|date=2004-12-02|title=Water column structure during deposition of Middle Devonian–Lower Mississippian black and green/gray shales of the Illinois and Michigan Basins: a biomarker approach|url=http://www.sciencedirect.com/science/article/pii/S0031018204004523|journal=Palaeogeography, Palaeoclimatology, Palaeoecology|volume=215|issue=1–2|pages=59–85|doi=10.1016/j.palaeo.2004.08.004}}&lt;/ref&gt; Although present, these events were probably ephemeral and did not last for longer periods of time.&lt;ref&gt;{{Cite journal|last=Shultz|first=Richard B|year=2006|title=Geochemical relationships of Late Paleozoic carbon-rich shales of the Midcontinent, USA: a compendium of results advocating changeable geochemical conditions|url=|journal=Chemical Geology|volume=206|pages=347–372|via=}}&lt;/ref&gt; Similar periodic evidence of euxinia can also be found in the Sunbury shales of Kentucky.&lt;ref name=":12"&gt;{{Cite journal|last=Rimmer|first=Susan M.|date=2004-06-16|title=Geochemical paleoredox indicators in Devonian–Mississippian black shales, Central Appalachian Basin (USA)|url=http://www.sciencedirect.com/science/article/pii/S0009254104000191|journal=Chemical Geology|series=Geochemistry of Organic-Rich Shales: New Perspectives|volume=206|issue=3–4|pages=373–391|doi=10.1016/j.chemgeo.2003.12.029}}&lt;/ref&gt;

Evidence for euxinia has also been tied to the [[Kellwasser event]]&lt;nowiki/&gt;s of the Late Devonian Extinction event. Euxinia in basinal waters in what is now central Europe (Germany, Poland, and France) persisted for part of the late Devonian, and may have spread up into shallow waters, contributing to the extinction event.&lt;ref&gt;{{Cite journal|last=Bond|first=David|last2=Wignall|first2=Paul B.|last3=Racki|first3=Grzegorz|date=2004-03-01|title=Extent and duration of marine anoxia during the Frasnian–Famennian (Late Devonian) mass extinction in Poland, Germany, Austria and France|url=https://www.cambridge.org/core/journals/geological-magazine/article/div-classtitleextent-and-duration-of-marine-anoxia-during-the-frasnianfamennian-late-devonian-mass-extinction-in-poland-germany-austria-and-francediv/E23779056D0B8D8520D5A7E04FFF5B1D|journal=Geological Magazine|volume=141|issue=2|pages=173–193|doi=10.1017/S0016756804008866|issn=1469-5081}}&lt;/ref&gt;

There was perhaps a period of oxygenation of bottom waters during the [[Carboniferous]], most likely between the Late Devonian Extinction and the Permian-Triassic Extinction, at which point euxinia would be very rare in the paleo oceans.&lt;ref name=":4" /&gt;

The [[Permian–Triassic extinction event]] may also have some ties to euxinia, with hypercapnia and hydrogen sulfide toxicity killing off many species.&lt;ref&gt;{{Cite journal|last=Meyer|first=K. M.|last2=Kump|first2=L. R.|last3=Ridgwell|first3=A.|date=2008-09-01|title=Biogeochemical controls on photic-zone euxinia during the end-Permian mass extinction|url=http://geology.gsapubs.org/content/36/9/747|journal=Geology|language=en|volume=36|issue=9|pages=747–750|doi=10.1130/G24618A.1|issn=0091-7613}}&lt;/ref&gt; Presence of a biomarker for anaerobic photosynthesis by green sulfur bacteria has been found spanning from the Permian to early Triassic in sedimentary rock in both Australia and China, meaning that euxinic conditions extended up quite shallow in the water column, contributing to the extinctions and perhaps even slowed the recovery.&lt;ref&gt;{{Cite journal|last=Grice|first=Kliti|last2=Cao|first2=Changqun|last3=Love|first3=Gordon D.|last4=Böttcher|first4=Michael E.|last5=Twitchett|first5=Richard J.|last6=Grosjean|first6=Emmanuelle|last7=Summons|first7=Roger E.|last8=Turgeon|first8=Steven C.|last9=Dunning|first9=William|date=2005-02-04|title=Photic Zone Euxinia During the Permian-Triassic Superanoxic Event|url=http://science.sciencemag.org/content/307/5710/706|journal=Science|language=en|volume=307|issue=5710|pages=706–709|doi=10.1126/science.1104323|issn=0036-8075|pmid=15661975}}&lt;/ref&gt; It is uncertain, however, just how widespread photic zone euxinia was during this period. Modelers have hypothesized that due to environmental conditions anoxia and sulfide may have been brought up from a deep, vast euxinic reservoir in [[upwelling]] areas, but stable, gyre-like areas remained oxic.&lt;ref&gt;{{Cite journal|last=Kump|first=Lee R.|last2=Pavlov|first2=Alexander|last3=Arthur|first3=Michael A.|date=2005-05-01|title=Massive release of hydrogen sulfide to the surface ocean and atmosphere during intervals of oceanic anoxia|url=http://geology.gsapubs.org/content/33/5/397|journal=Geology|language=en|volume=33|issue=5|pages=397–400|doi=10.1130/G21295.1|issn=0091-7613}}&lt;/ref&gt;

==== Mesozoic ====

The Mesozoic is well known for its distinct [[Ocean anoxic event|Ocean Anoxic Event]]&lt;nowiki/&gt;s (OAEs) which resulted in the burial of layers of black shale. Although these OAEs are not stand alone evidence for euxinia, many do contain biomarkers which support euxinic formation.&lt;ref name=":1" /&gt; Again, evidence is not universal. OAEs may have spurred the spread of existing euxinia, especially in upwelling regions or semi-restricted basins, but photic zone euxinia did not happen everywhere.&lt;ref name=":1" /&gt;

==== Cenozoic ====
Few episodes of euxinia are evident in the sedimentary record during the Cenozoic.&lt;ref name=":1" /&gt; Since the end of the Cretaceous OAEs, it is most likely that the oceanic bottom waters have stayed oxic.&lt;ref name=":4" /&gt;

== Modern euxinia ==
 
Euxinic conditions have nearly vanished from Earth's open-ocean environments, but a few small scale examples still exist today. Many of these locations share common biogeochemical characteristics.&lt;ref name=":1" /&gt; For example, low rates of overturning and vertical mixing of the total water column is common in euxinic bodies of water.&lt;ref name=":1" /&gt; Small surface area to depth ratios allow multiple stable layers to form while limiting wind-driven overturning and thermohaline circulation.&lt;ref name=":1" /&gt; Furthermore, restricted mixing enhances stratified layers of high nutrient density which are reinforced by biological recycling.&lt;ref name=":1" /&gt; Within the chemocline, highly specialized organisms, such as green sulfur bacteria (GSB) take advantage of the strong redox potential gradient and minimal sunlight.&lt;ref name=":1" /&gt;

=== The Black Sea ===
[[File:Black Sea Catchment Map.svg|thumb|Map of the Black Sea showing the many rivers that supply the basin with low-density fresh water, along with the narrow Bosphorus Strait to the southwest that supplies the basin with high-density salt water. This assists in the stratification and euxinia that exists in the modern Black Sea.]]
The Black Sea is a commonly used modern model for understanding biogeochemical processes that occur under euxinic conditions.&lt;ref name=":5"&gt;{{Cite journal|last=Nägler|first=T. F.|last2=Neubert|first2=N.|last3=Böttcher|first3=M. E.|last4=Dellwig|first4=O.|last5=Schnetger|first5=B.|date=2011-10-07|title=Molybdenum isotope fractionation in pelagic euxinia: Evidence from the modern Black and Baltic Seas|url=http://www.sciencedirect.com/science/article/pii/S0009254111002750|journal=Chemical Geology|volume=289|issue=1–2|pages=1–11|doi=10.1016/j.chemgeo.2011.07.001}}&lt;/ref&gt; It is thought to represent the conditions of Earth's proto-oceans and thus assists in the interpretation of oceanic proxies.&lt;ref name=":5" /&gt; Black Sea sediment contains redox reactions to depths of tens of meters, compared to single centimeters in the open ocean.&lt;ref name=":6" /&gt; This unique feature is important for understanding the behavior of the redox cascade under euxinic conditions.&lt;ref name=":6"&gt;Stewart, Keith, et al. "Oxic, suboxic, and anoxic conditions in the Black Sea." ''The Black Sea Flood Question: Changes in Coastline, Climate, and Human Settlement''. Springer Netherlands, 2007. 1-21.&lt;/ref&gt;

The only connection between the open ocean and the Black Sea is the [[Bosphorus|Bosphorus Strait]], through which dense Mediterranean waters are imported.&lt;ref name=":6" /&gt; Subsequently, numerous rivers, such as the [[Danube]], [[Don River (Russia)|Don]], [[Dnieper]], and [[Dniester]], drain fresh water into the Black Sea, which floats on top of the more dense Mediterranean water, causing a strong, stratified water column.&lt;ref name=":5" /&gt; This stratification is maintained by a strong [[pycnocline]] which restricts ventilation of deep waters and results in an intermediate layer called the [[chemocline]], a sharp boundary separating oxic surface waters from anoxic bottom waters usually between 50m and 100m depth,&lt;ref&gt;{{Cite journal|last=Murray|first=J. W.|last2=Jannasch|first2=H. W.|last3=Honjo|first3=S.|last4=Anderson|first4=R. F.|last5=Reeburgh|first5=W. S.|last6=Top|first6=Z.|last7=Friederich|first7=G. E.|last8=Codispoti|first8=L. A.|last9=Izdar|first9=E.|date=1989-03-30|title=Unexpected changes in the oxic/anoxic interface in the Black Sea|url=http://www.nature.com/nature/journal/v338/n6214/abs/338411a0.html|journal=Nature|language=en|volume=338|issue=6214|pages=411–413|doi=10.1038/338411a0}}&lt;/ref&gt; with interannual variation attributed to large scale changes in temperature.&lt;ref name=":6" /&gt; Well-mixed, oxic conditions exist above the chemocline and sulfidic conditions are dominant below.&lt;ref name=":6" /&gt; Surface oxygen and deep water sulfide do not overlap via vertical mixing,&lt;ref&gt;{{Cite journal|last=Yakushev|first=E. V.|last2=Chasovnikov|first2=V. K.|last3=Debolskaya|first3=E. I.|last4=Egorov|first4=A. V.|last5=Makkaveev|first5=P. N.|last6=Pakhomova|first6=S. V.|last7=Podymov|first7=O. I.|last8=Yakubenko|first8=V. G.|date=2006-08-01|title=The northeastern Black Sea redox zone: Hydrochemical structure and its temporal variability|url=http://www.sciencedirect.com/science/article/pii/S0967064506001469|journal=Deep Sea Research Part II: Topical Studies in Oceanography|series=Black Sea Oceanography|volume=53|issue=17–19|pages=1769–1786|doi=10.1016/j.dsr2.2006.05.019}}&lt;/ref&gt; but horizontal entrainment of oxygenated waters and vertical mixing of oxidized manganese into sulfidic waters may occur near the Bosphorus Strait inlet.&lt;ref name=":6" /&gt; Manganese and iron oxides likely oxidize hydrogen sulfide near the chemocline, resulting in the decrease in H&lt;sub&gt;2&lt;/sub&gt;S concentrations as one approaches the chemocline from below.

=== Meromictic lakes ===
[[Meromictic lake]]s are poorly mixed and anoxic bodies of water with strong vertical stratification.&lt;ref name=":1" /&gt; While meromictic lakes are frequently categorized as bodies of water with the potential for euxinic conditions, many do not exhibit euxinia. Meromictic lakes are infamous for [[limnic eruption]]s.&lt;ref name=":20" /&gt; These events usually coincide with nearby tectonic or volcanic activity that disturbs the otherwise stable stratification of meromictic lakes.&lt;ref&gt;{{Cite book|url=https://link.springer.com/chapter/10.1007/978-3-663-05239-5_10|title=Natural Hazards in West and Central Africa|last=Tietze|first=Klaus|date=1992-01-01|publisher=Vieweg+Teubner Verlag|isbn=9783663052418|editor-last=Freeth|editor-first=Samuel J.|series=International Monograph Series|pages=97–107|language=en|doi=10.1007/978-3-663-05239-5_10|editor-last2=Ofoegbu|editor-first2=Charles O.|editor-last3=Onuoha|editor-first3=K. Mosto}}&lt;/ref&gt; This can result in the release of immense concentrations of stored toxic gasses from the anoxic bottom waters, such as CO&lt;sub&gt;2&lt;/sub&gt;&lt;ref name=":20"&gt;{{Cite journal|last=Zhang|first=Youxue|year=1996|title=Dynamic of CO2-driven lake eruptions|url=https://deepblue.lib.umich.edu/bitstream/handle/2027.42/62537/379057a0.pdf?sequence=1&amp;isAllowed=y|journal=Nature|volume=379|pages=57–59|via=}}&lt;/ref&gt; and H&lt;sub&gt;2&lt;/sub&gt;S, especially from euxinic meromictic lakes. In high enough concentration, these limnic explosions can be deadly to humans and animals, such as the [[Lake Nyos disaster]] in 1986.&lt;ref&gt;{{Cite journal|last=Kling|first=George W.|last2=Clark|first2=Michael A.|last3=Compton|first3=Harry R.|last4=Devine|first4=Joseph D.|last5=Evans|first5=William C.|last6=Humphrey|first6=Alan M.|last7=Koenigsberg|first7=Edward J.|last8=Lockwood|first8=John P.|last9=Tuttle|first9=Michele L.|date=1987-04-10|title=The 1986 Lake Nyos gas disaster in Cameroon, West Africa|url=http://go.galegroup.com/ps/anonymous?id=GALE%7CA4785733&amp;sid=googleScholar&amp;v=2.1&amp;it=r&amp;linkaccess=fulltext&amp;issn=00368075&amp;p=AONE&amp;sw=w&amp;authCount=1&amp;isAnonymousEntry=true|journal=Science|language=English|volume=236}}&lt;/ref&gt;
[[File:Mariager fjord vinter.jpg|thumb|Mariager fjord often produces a "rotten egg" smell in the summer due to sulfur content.]]

=== North Sea fjords ===
Some [[fjord]]s develop euxinia if the connection to the open ocean is constricted, similar to the case of the Black Sea. This constriction prohibits relatively dense, oxygen-rich oceanic water from mixing with the bottom water of the fjord, which leads to stable stratified layers in the fjord.&lt;ref name=":1" /&gt; Low salinity melt water forms a lens of fresh, low density water on top of a more dense mass of bottom water.  Ground sources of sulfur are also an important cause for euxinia in fjords.&lt;ref name=":19"&gt;{{Cite journal|last=Sørensen|first=Ketil B|last2=Canfield|first2=Donald E|date=2004-02-01|title=Annual fluctuations in sulfur isotope fractionation in the water column of a euxinic marine basin 1|url=http://www.sciencedirect.com/science/article/pii/S0016703703003879|journal=Geochimica et Cosmochimica Acta|volume=68|issue=3|pages=503–515|doi=10.1016/S0016-7037(03)00387-9}}&lt;/ref&gt;

==== Framvaren Fjord ====

This fjord was born as a glacial lake that was separated from the open ocean (the North Sea) when it was lifted during glacial rebound.&lt;ref name=":1" /&gt; A shallow channel (2m deep) was dug in 1850, providing a marginal connection to the North Sea.&lt;ref name=":1" /&gt; A strong pycnocline separates fresh surface water from dense, saline bottom water, and this pycnolcine reduces mixing between the layers. Anoxic conditions persist below the chemocline at 20m, and the fjord has the highest levels of hydrogen sulfide in the anoxic marine world.&lt;ref&gt;{{Cite journal|last=Millero|first=Frank J.|date=1991-07-01|title=The oxidation of H2S in Framvaren Fjord|url=http://onlinelibrary.wiley.com/doi/10.4319/lo.1991.36.5.1007/abstract|journal=Limnology and Oceanography|language=en|volume=36|issue=5|pages=1007–1014|doi=10.4319/lo.1991.36.5.1007|issn=1939-5590}}&lt;/ref&gt;&lt;ref name=":1" /&gt; Like the Black Sea, vertical overlap of oxygen and sulfur is limited, but the decline of H&lt;sub&gt;2&lt;/sub&gt;S approaching the chemocline from below is indicative of oxidation of H&lt;sub&gt;2&lt;/sub&gt;S, which has been attributed to manganese and iron oxides, photo-autotrophic bacteria, and entrainment of oxygen horizontally from the boundaries of the fjord.&lt;ref&gt;{{Cite journal|last=Yao|first=Wensheng|last2=Millero|first2=Frank J.|title=The chemistry of the anoxic waters in the Framvaren Fjord, Norway|url=https://link.springer.com/article/10.1007/BF01025231|journal=Aquatic Geochemistry|language=en|volume=1|issue=1|pages=53–88|doi=10.1007/BF01025231|issn=1380-6165}}&lt;/ref&gt; These oxidation processes are similar to those present in the Black Sea.

Two strong seawater intrusion events have occurred through the channel in recent history (1902 and 1942).&lt;ref name=":1" /&gt; Seawater intrusions to fjords force dense, salty, oxygen-rich water into the typically anoxic, sulfidic bottom waters of euxinic fjords.&lt;ref name=":7"&gt;{{Cite journal|last=Pakhomova|first=Svetlana|last2=Braaten|first2=Hans Fredrik|last3=Yakushev|first3=Evgeniy|last4=Skei|first4=Jens|date=2014-04-28|year=|title=Biogeochemical consequences of an oxygenated intrusion into an anoxic fjord|url=http://www.geochemicaltransactions.com/content/15/1/5|journal=Geochemical Transactions|language=En|volume=15|issue=1|pages=|doi=10.1186/1467-4866-15-5|issn=1467-4866|pmid=24872727|via=}}&lt;/ref&gt; These events result in a temporary disturbance to the chemocline, raising the depth at which H&lt;sub&gt;2&lt;/sub&gt;S is detected. The breakdown of the chemocline causes H&lt;sub&gt;2&lt;/sub&gt;S to react with dissolved oxygen in a redox reaction.&lt;ref name=":7" /&gt; This decreases the concentration of dissolved oxygen in the biologically active photic zone which can result in basin-scale fish die-offs.&lt;ref name=":7" /&gt; The 1942 event, in particular, was strong enough to chemically reduce the vast majority of oxygen and elevate the chemocline to the air-water interface.&lt;ref name=":7" /&gt; This caused a temporary state of total anoxia in the fjord, and resulted in dramatic fish mortality.&lt;ref name=":7" /&gt;

==== Mariager Fjord ====

This fjord is marked by a highly mobile chemocline with a depth that is thought to be related to temperature effects.&lt;ref name=":2" /&gt; Local reports of strong rotten egg smell- the smell of sulfur- during numerous summers around the fjord provide evidence that, like the Framvaren fjord, the chemocline has breached the surface of the fjord at least 5 times in the last century.&lt;ref name=":2" /&gt; Sediments export during these events increased the concentrations of dissolved phosphates, inorganic bioavailable nitrogen, and other nutrients, resulting in a [[harmful algal bloom]].&lt;ref name=":19" /&gt;

=== Cariaco Basin ===
The [[Cariaco Basin]] in Venezuela has been used to study the cycle of organic material in euxinic marine environments.&lt;ref name=":13"&gt;{{Cite journal|last=Werne|first=Josef P.|last2=Lyons|first2=Timothy W.|last3=Hollander|first3=David J.|last4=Formolo|first4=Michael J.|last5=Sinninghe Damsté|first5=Jaap S.|date=2003-04-15|title=Reduced sulfur in euxinic sediments of the Cariaco Basin: sulfur isotope constraints on organic sulfur formation|url=http://www.sciencedirect.com/science/article/pii/S0009254102003935|journal=Chemical Geology|series=Isotopic records of microbially mediated processes|volume=195|issue=1–4|pages=159–179|doi=10.1016/S0009-2541(02)00393-5}}&lt;/ref&gt; An increase in productivity coincident with post glacial nutrient loading probably caused a transition from oxic to anoxic and subsequently euxinic conditions around 14.5 thousand years ago.&lt;ref&gt;{{Cite journal|last=Lyons|first=Timothy W|last2=Werne|first2=Josef P|last3=Hollander|first3=David J|last4=Murray|first4=R. W|date=2003-04-15|title=Contrasting sulfur geochemistry and Fe/Al and Mo/Al ratios across the last oxic-to-anoxic transition in the Cariaco Basin, Venezuela|url=http://www.sciencedirect.com/science/article/pii/S0009254102003923|journal=Chemical Geology|series=Isotopic records of microbially mediated processes|volume=195|issue=1–4|pages=131–157|doi=10.1016/S0009-2541(02)00392-3}}&lt;/ref&gt; High productivity at the surface produces a rain of particulate organic matter to the sub surface where anoxic, sulfidic conditions persist.&lt;ref name=":13" /&gt; The organic matter in this region is oxidized with sulfate, producing reduced sulfur (H&lt;sub&gt;2&lt;/sub&gt;S) as a waste product. Free sulfur exists deep in the water column and up to 6m in depth in the sediment.&lt;ref name=":13" /&gt;

== See also ==
* [[Anoxic event]]
* [[Canfield ocean]]
* [[Redox]]
* [[Boring Billion]]

== References ==
{{reflist}}

[[Category:Environmental science]]
[[Category:Environmental chemistry]]
[[Category:Oceanography]]
[[Category:Chemical oceanography]]
[[Category:Bioindicators]]
[[Category:Aquatic ecology]]
[[Category:Water quality indicators]]</text>
      <sha1>75959agy9lvqu3n4s0boc1xthdvwx68</sha1>
    </revision>
  </page>
  <page>
    <title>Expectation confirmation theory</title>
    <ns>0</ns>
    <id>42363753</id>
    <revision>
      <id>842968652</id>
      <parentid>842968634</parentid>
      <timestamp>2018-05-25T22:44:17Z</timestamp>
      <contributor>
        <username>Aamri2</username>
        <id>26461452</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/49.150.44.156|49.150.44.156]] ([[User talk:49.150.44.156|talk]]) to last revision by Omnipaedista. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3906">[[Image:Expectation confirmation theory.png|thumb|420px|right|A model of expectation confirmation theory.]]
'''Expectation confirmation theory''' (alternatively '''ECT''' or '''expectation disconfirmation theory''') is a [[Cognitive psychology|cognitive theory]] which seeks to explain post-purchase or post-adoption [[Contentment|satisfaction]] as a function of expectations, perceived performance, and disconfirmation of beliefs. The structure of the theory was developed in a series of two papers written by Richard L. Oliver in 1977&lt;ref&gt;Oliver R. L, 1977, "Effect of Expectation and Disconfirmation on Postexposure Product Evaluations - an Alternative Interpretation," Journal of Applied Psychology, 62(4), p. 480.&lt;/ref&gt; and 1980.&lt;ref&gt;Oliver R. L, 1980, "A Cognitive Model of the Antecedents and Consequences of Satisfaction Decisions," Journal of Marketing Research, 17(4), p. 460.&lt;/ref&gt; Although the theory originally appeared in the [[psychology]] and [[marketing]] literatures, it has since been adopted in several other scientific fields, notably including [[consumer research]] and [[information systems]], among others.

==Theoretical constructs==
Expectation confirmation theory involves four primary constructs: expectations, perceived performance, disconfirmation of beliefs, and satisfaction.

===Expectations===
''Expectations'' refer to the attributes or characteristics that a person anticipates or predicts will be associated with an entity such as a product, service, or technology artifact. Expectations are posited to directly influence both perceptions of performance and disconfirmation of beliefs, and are posited to indirectly influence post-purchase or post-adoption satisfaction by way of a [[Mediation (statistics)|mediational relationship]] through the disconfirmation construct. Pre-purchase or pre-adoption expectations form the basis of comparison against which the product, service, or technology artifact is ultimately judged.

=== Perceived performance===
''Perceived performance'' refers to a person’s perceptions of the actual performance of a product, service, or technology artifact. According to expectation confirmation theory, perceptions of performance are directly influenced by pre-purchase or pre-adoption expectations, and in turn directly influence disconfirmation of beliefs and post-purchase or post-adoption satisfaction. Perceived performance is also posited to indirectly influence post-purchase or post-adoption satisfaction by way of a mediational relationship through the disconfirmation construct.

=== Disconfirmation of beliefs===
''Disconfirmation of beliefs'' refers to the judgments or evaluations that a person makes with respect to a product, service, or technology artifact. These evaluations or judgments are made in comparison to the person’s original expectations. When a product, service, or technology artifact outperforms the person’s original expectations, the disconfirmation is positive, which is posited to increase post-purchase or post-adoption satisfaction. When a product, service, or technology artifact underperforms the person’s original expectations, the disconfirmation is negative, which is posited to decrease post-purchase or post-adoption satisfaction (i.e., to increase dissatisfaction).

===Satisfaction===
Post-purchase or post-adoption ''satisfaction'' refers to the extent to which a person is pleased or contented with a product, service, or technology artifact after having gained direct experience with the product, service, or artifact. Expectation confirmation theory posits that satisfaction is directly influenced by disconfirmation of beliefs and perceived performance, and is indirectly influenced by both expectations and perceived performance by means of a mediational relationship which passes through the disconfirmation construct.

==References==
{{reflist}}

[[Category:Cognitive science]]</text>
      <sha1>fqorz3uve9xmszod860qzlx55vaukql</sha1>
    </revision>
  </page>
  <page>
    <title>External wall insulation</title>
    <ns>0</ns>
    <id>16761344</id>
    <revision>
      <id>871048063</id>
      <parentid>871048007</parentid>
      <timestamp>2018-11-28T16:17:22Z</timestamp>
      <contributor>
        <ip>81.143.226.222</ip>
      </contributor>
      <comment>/* Further reading */ Adding Bulletpoint formatting</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11756">{{for|the analogous North American class of non-load bearing building cladding systems|Exterior insulation finishing system}}
[[Image:EWIS.jpg|thumb|right|Types of External cromatic 
 wall insulation systems (EWI Systems pictured above)]]

An '''external wall insulation''' system (or EWIS) is a thermally insulated, protective, decorative exterior [[cladding (construction)|cladding]] procedure involving the use of expanded [[polystyrene]], [[mineral wool]], polyurethane foam or phenolic foam, topped off with a reinforced cement based, mineral or synthetic finish and [[plaster]].&lt;ref&gt;{{Cite journal|url = http://www.maloneassociatesltd.co.uk/wp-content/uploads/2015/05/The-Risky-Business-of-Covering-Up.pdf|title = The risky business of covering up|last = Malone|first = Joe|date = 1 December 2013|journal = Construction, Research and Innovation Journal|doi = |pmid = |access-date = 5 December 2015}}&lt;/ref&gt;

The thickness of thermal insulation is dependent on whatever type is required in order to create a partition with a heat [[transmission factor]] of U=0.25-0.3 W/m2K. When calculating the actual insulation requirements, consideration must be given to current Building Regulation standards. Consideration must also be given to exposure and durability, and whether the structure might be subjected to vandalism etc. In many older properties, special attention is required for concrete beams or lintels which act as [[thermal bridges]] providing poor insulation.

==Types==

External wall insulation systems generally comprise firstly an insulation layer (an element which helps to achieve the requisite thermal performance); and secondly,a protected weatherproof finish (usually a [[Stucco|render]], although brick slips, tiles, and decorative boards can also be used). Insulating render can also be an advantage in certain locations. Choice of types and sizes will depend on the substrate and design exposure requirements.

Dry finishes are usually fixed to the substrate by means of timber [[batten]]s independently fixed to the substrate.

Any system selected and installed, should be certified by a notified body.

===Traditional finishes===

A selection of traditional finishes is currently utilised within the external wall insulation industry. Dry-dash render is a traditional render application commonly used. By this method, dry dashing aggregate is thrown onto the wet render to create a natural aggregate finish. Available in a wide variety of colours, sizes and textures, the practice is relatively cheap. Manufactured aggregates such as ceramics and glass can be used for more specialised projects, but the costs will be greater than for projects using natural aggregates.

Scratch plaster render is a coloured cementitious render scratched while the surface is still workable, but after the initial setting has taken place. The surface of the render is removed by the action of the scratching tool, and approximately {{convert|2|to|3|mm}} of render are removed exposing the open matrix of the aggregate mix. The true colour of the render is exposed with a light even texture.

Rough-cast render consists of a top-coat render and aggregate mix thrown onto a backing coat in a [[slurry]] form, the aggregate being totally encapsulated within the cementitious slurry. The aggregate may be any hard stone of an equal graded size to suit the particular application and creates a “lumpy texture” finish. This method is traditionally widely used in Scotland.

An innovation is the inclusion of [[silicone]] water-proofers in pre-blended and pre-packed proprietary renders. This development increases the specification and capabilities of polymer renders, particularly for exposed or coastal areas. It is applied in the conventional manner and is now readily available in all the usual colours.

Tyrolean finishes are sprayed cementitious mixes, pre-coloured and applied by a hand-held machine. This finish is widely used throughout the UK as an economical, easily applied colourful finish for all forms of building type. It has medium-term durability under average conditions.{{vague|date=May 2011}}

Smooth/painted finishes consist of masonry paint, and are applied to a good rendered surface to give a smooth coloured effect, free of the imperfections that the more natural aggregate finishes can sometimes deliver. A very wide selection of light colours are available.

Textured coatings are applied by roller or trowel to an approximate thickness of {{convert|1.5|to|3|mm}}, and are usually [[Acrylate polymer|acrylic]] or silicone-based for waterproofing and long term durability. They produce an even, flat-textured, finish.

Acrylic variants are easily applied, and are considered “high performance” finishes. Some cheaper variants might result in the loss [[opacity (optics)|opacity]] of surface brightness over a relatively short life span. High quality acrylics can provide a longer term durability, colour stability, and crack resistance compared to polymer cement finishes. Acrylic variants are available in a very wide range of colours.

Silicone variants are more resistant to marine environments than acrylics, as they have superior water resistance, but they can be more costly, and come in a smaller range of colours.

Brick slips are a thin facing applied over an insulant to provide a traditional “brick” wall finish. Slips can either be manufactured by [[extrusion]] or cut from real bricks. Specialist waterproof coloured pointing mortars are used to complete the effect. Commercially available brick slip systems have been developed to include support for the brick slip finish, certified by [[BBA/BRE]]. The brick slips usually have a size of about 210-240 x 50-71 x 20&amp;nbsp;mm (length x height x width).&lt;ref&gt;Klinkerriemchen / The size from Brick slips [http://www.renowall.de/klinkerriemchen.php "Klinkerriemchen / Brick slips"]&lt;/ref&gt;

Simulated brick renders can also be replicated in coloured polymer to a high standard. Two coloured layers of polymer-modified external cementitious render are applied in {{convert|3|to|4|mm}} layers onto a coloured backing. The “brick” pattern is cut into the top layer, exposing an under-layer of differing colour representing the cement joints.

Simulated stone renders are made from coloured [[polymer]]. Two coloured layers of polymer-modified external cementitious render are applied in {{convert|3|to|4|mm}} layers onto a specified backing. The “stone” pattern is cut into the top layer exposing an under-layer of differing colour to represent the cement joints.

[[Terracotta]] tiles are usually of clay burnt material imported from Europe. These proprietary systems are secured by a system of extruded aluminium rail systems fixed securely to the substrate with insulation material inserted within the void. Special pressed metal profiles and [[Lock (water transport)#Cill|cills]] are added to make them waterproof.

Timber boards, aluminium or [[PVC]] “sidings” can be installed over insulation to provide additional alternatives to the traditional render and applied finishes. The boards are usually of [[shiplap]] profile, and either [[cedar wood|cedar]] or treated [[softwood]]. Aluminium or PVC systems are also available as alternatives.

Traditional tile hanging finishes can be applied onto conventional timber support structures and insulated with the required type and thickness of insulation. Suitable consideration has to be given to ventilation passages to avoid [[interstitial condensation]].

==Reducing Carbon Emissions==
With the UK aiming to reduce its carbon emissions by 80% by the year 2050,&lt;ref&gt;{{cite web|title=Reducing the UK’s greenhouse gas emissions by 80% by 2050|url=https://www.gov.uk/government/policies/reducing-the-uk-s-greenhouse-gas-emissions-by-80-by-2050|website=Gov.uk|accessdate=19 July 2014}}&lt;/ref&gt; the British government has offered up to £6,000 cashback to homeowners who install EWI at their solid wall property.&lt;ref&gt;{{cite web|title=Green Deal: energy saving for your home|url=https://www.gov.uk/green-deal-energy-saving-measures/get-money-back-from-the-green-deal-home-improvement-fund|website=Department of Energy and Climate Change|accessdate=19 July 2014}}&lt;/ref&gt; South Wales, where the housing stock is in particular need of being updated to become energy efficient, has seen a surge in applications for this scheme.&lt;ref&gt;{{cite web|last1=Dobson|first1=Ben|title=High take up of external wall insulation in Swansea|url=http://www.sbmenergyservices.co.uk/blog/high-take-up-of-external-wall-insulation-in-swansea|website=SBM Energy Services|accessdate=19 July 2014}}&lt;/ref&gt;

External wall insulation is a great and confirmed way to reduce energy usage needed to heat up the building. Installing it is a part of and [[eco home]] or [[carbon neutral home]] idea.&lt;ref&gt;http://blog.kanler.com/2015/03/13/going-green-easy-on-the-planet-and-your-wallet/&lt;/ref&gt;

==Product Requirements==
Particular product requirements need to be met such as the external wall insulation product reaching a particular u-value in order to make the building sufficiently thermally insulated and therefore be used for a green deal project.&lt;ref&gt;{{cite web|title=Alumasc Exterior Building Products Product Datasheets|url=http://www.alumascfacades.co.uk/downloads/product-datasheets/|website=Alumasc Facades|accessdate=July 2014}}&lt;/ref&gt;

==Dampness==
The application of External Wall Insulation can help to deal with rain penetration problems through solid walls by blocking wind-driven rain. However, it can also make the problem worse if poor detailing (e.g. around eaves) allows water to pass behind the external wall insulation where it can become trapped. A high standard of design and installation should therefore be insisted upon. The dangers of not adequately designing and specifying these systems is dealt with in a research paper written by Joe Malone and published in the CIOB's Construction, Research and Innovation Journal (Volume 4, Issue 4, Dec 2013 The Risky Business of Covering Up)

External Wall Insulation should only be applied to walls that do not suffer from [[Damp (structural)|pre-existing dampness problems]]. The Energy Saving Trust give the following advice.&lt;ref name="Choosing external wall insulation"&gt;{{cite web|url=http://www.energysavingtrust.org.uk/Insulation/Solid-wall-insulation/Choosing-external-wall-insulation|website=energysavingtrust.org.uk|publisher=Energy Saving Trust|accessdate=22 September 2014}}&lt;/ref&gt;

''"The main damp issue to be avoided with external wall insulation is rising damp. If you already have a problem with this, then it will have to be fixed before the insulation is fitted, otherwise you run the risk of trapping the damp inside the wall structure and so making the problem worse."''

==See also==
*[[Exterior insulation finishing system]]
*[[Building insulation]]
*[[Building insulation materials]]
*[[Thermal insulation]]

==Further reading==
*National Building Specification Section M21 Insulation with rendered finish
*BSI British Standards and Code of Practice
*BRE Report 135: EWI, Fire performance for multi-storey buildings
*BRE Report 262: Thermal insulation avoiding the risks
*INCA Insulated render and cladding Specifiers/property owners briefing
*Technical Drawings: Weber UK EWI Systems
*''The Complete Guide to External Wall Insulation'' by C J Pearson
*CIOB's Construction, Research &amp; Innovation Journal: "The Risky Business of Covering Up" by Joe Malone
*[https://gaffneyandguinan.co.uk/services-products/external-wall-insulation-coventry/ A Guide to External Wall Insulation (2018).] Retrieved November 28, 2018, from Gaffney &amp; Guinan

==References==
{{Reflist}}

{{Authority control}}

[[Category:Construction]]
[[Category:Building engineering]]</text>
      <sha1>3ttb0n0zgmxawbmtqlf2gzjsea8rn0s</sha1>
    </revision>
  </page>
  <page>
    <title>Feminist geography</title>
    <ns>0</ns>
    <id>850705</id>
    <revision>
      <id>866911144</id>
      <parentid>864927434</parentid>
      <timestamp>2018-11-02T11:00:41Z</timestamp>
      <contributor>
        <username>Oliverlikes</username>
        <id>34707482</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22845">{{copy edit|for=remove wordiness. Fix bad use of quote marks. Explain murky concepts. |date=October 2018}}
{{short description|An approach in human geography which applies the theories, methods and critiques of feminism}}
{{Feminism sidebar |expanded=Feminist critiques}}

'''[[Feminist]] geography''' is an approach in [[human geography]] which applies the theories, methods and critiques of [[feminism]] to the study of the human environment, society and geographical space.&lt;ref name=rose&gt;{{cite book|last1=Rose|first1=Gillian|authorlink1=Gillian Rose (geographer)|title=Feminism &amp; Geography: The Limits of Geographical Knowledge|date=1993|publisher=[[University of Minnesota Press]]|location=Minneapolis, MN|isbn=9780816624188|url=https://books.google.com/books/about/Feminism_Geography.html?id=ut9_Af4oyGkC}}&lt;/ref&gt; The field of feminist geography, which uses a multidisciplinary approach, emerged in the 1970s out of the women’s movement's call on the academy to better incorporate women into academia both as producers and subjects&lt;ref name=":0" /&gt;. Feminist geography is a process of situating geographical research on an [[Intersectionality|intersectional]] foundation thereby examining axes beyond gender to incorporate positions of race, class, ability, sexuality, etc. Through this practice, feminist geography prioritizes [[Praxis (process)|praxis]] within the field as established in feminist epistemology.&lt;ref name=":1" /&gt; The discipline has been subject to several controversies.&lt;ref name=":2"&gt;{{Cite news|url=https://areomagazine.com/2018/10/02/academic-grievance-studies-and-the-corruption-of-scholarship/|title=Academic Grievance Studies and the Corruption of Scholarship - Areo|date=2018-10-03|work=Areo|access-date=2018-10-13|language=en-US}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.washingtontimes.com/news/2017/jul/13/feminist-geographers-dont-cite-research-white-men/|title=Feminist geographers encourage colleagues not to cite research of white men|last=http://www.washingtontimes.com|first=The Washington Times|work=The Washington Times|access-date=2018-10-13|language=en-US}}&lt;/ref&gt; 

==The geography of women== 
The geography of women focuses upon description of the effects on [[gender inequality]]. Its theoretical influences focus on welfare geography and [[liberal feminism]]. Geographically, feminist geographers emphasize on constraints of distance and spatial separation. As Seager et al. argues, gender is only the narrow-minded approach when understanding the oppression of women throughout the decades of colonial history. In such, understanding the geography of women would mean taking a critical approach in questioning the dimensions of age, class, ethnicity, orientation and other socio-economic factors (2004).&lt;ref name=":0"&gt;Seager, J., &amp; Nelson, L. (Eds.). (2004). Companion to Feminist Geography. Williston, VT, USA: Blackwell Publishing.&lt;/ref&gt; An early reproach of geography of women approach was that gender roles were mainly explained as gender inequality, such as housewives and mothers, in combination with the some concept of spatial constraint. However, Foord and Gregson (1986) argued that the concept of [[gender role]]s narrows the focus to women, emerges from a static [[social theory]], and presents women as victims. Furthermore, it gives a narrow reading of distance even though the geography of women displays how spatial constraint and separation enter into the construction of women’s position. Theorist Edward Said critiques the idea of geographical spaces in such a context where our actions on gendered practices of representation are fabricated through dominant ideological beliefs (2004).&lt;ref&gt;Gregory, D. (2004). The colonial present. (pp. 18-19). Victoria: Blackwell Publishing.&lt;/ref&gt; In relation to the misrepresentation of gender roles and taken-for-granted movements on feminine rights, we see that the challenges of the colonial present lies within the confinement of women in limited spatial opportunities. Hence, feminist geographies should consider and trace the inter-connections in all aspects of daily life; in other words, gender should be applied and developed in terms of space.&lt;ref&gt;{{cite book|last=Massey|first=Doreen|title=Space, Place, and Gender|year=1990|publisher=University of Minnesota Press Minneapolis}}&lt;/ref&gt;

==Socialist feminist geography==
[[Socialist feminist]] geography seeks to explain inequality and the relationship between [[capitalism]] and [[patriarchy]]. It uses [[Marxism]] and [[Socialist feminism]] to explain the interdependence of geography, gender relations and economic development under capitalism. Socialist feminist geography revolved around the questions of how to reduce gender inequality based on patriarchy and capitalism. It has theoretical influences on Marxism, socialist feminism. The geographical focus is on spatial separation, gender place, and localities. One of the key theoretical debates within socialist feminist geography revolved around the question of how best to articulate gender and [[class (social)|class]] analysis. For instance, drawing on of married mainland Chinese immigrant women living in New York City. While women remain the primary object of analysis, and gender remains the primary social relation, Zhou is intensely aware that many other factors, such as class, also affect women’s post-migration experiences and circumstances.&lt;ref name="Longhurt 2002"&gt;{{cite journal|last=Longhurt|first=Robyn|title=Geography and gender: a 'critical' time?|year=2002}}&lt;/ref&gt;

There are two scales that socialist feminist geographers first worked primarily. First, at the urban scale, Anglo-American feminist geographers focused on the social and spatial separation of suburban homes from paid employment; this was seen as vital to the day-to-day and generational reproduction of workers and the development and maintenance of traditional gender relations in capitalist societies.&lt;ref&gt;{{cite book|title=Industrial change, the domestic economy and home life|last=MaccKenzie|first=S.|author2=Rose, D.|publisher=|year=1983|isbn=|location=|pages=}}&lt;/ref&gt;

Socialist feminist geographers widely attending to the ways that gender relations differ from place to place not only reflect, but also partly determine local economic changes. Judith Butler’s idea of citationality expands on the concept of the lack of agency to facilitate the presence of women within the discipline of geography. In such, we come to the awareness that whenever performative measures are taken to diminish women’s rights in geographical space, the conventions around it adapt around this context to make it seem as the norm.&lt;ref&gt;McKenzie, J. (2001). Perform or Else : From Discipline to Performance. London, GBR: Routledge.&lt;/ref&gt; Likewise, feminist geographers are also drawing on a broader range of social, and particularly cultural theory, including [[psychoanalysis]] and [[post-structuralism]], in order to develop a fuller understanding of how gender relations and identities are shaped and assumed. This has led to fundamental rethinking of the category gender, and the contradictions and possibilities presented by the seeming instability and insistent repetitions of [[gender norm]]s in practice. The focus on multiple identifications and the influence of post-structuralist and psychoanalytic theories has brought feminist geographers into dialogue with other strands of critical geography. But another consequence is that theoretical differences among feminist geographers are more obvious than in the past, but according to Monk 1994 the national differences between America and British geographers may be diminishing as both parties pursue new directions.

==Feminist geographies of difference==
Feminist geographies of difference concentrate upon the construction of gendered identities, differences among women, gender and constructions of nature by using cultural, post-structural, [[postcolonial]] and psychoanalytic theories, which writings of [[women of color]], [[lesbian]] women, gay men and women from [[third world]] countries. In terms of geography, feminist geographers emphasize on micro-geographies of body, mobile identities, distance, separation and place, [[imagined geographies]], [[colonialism]] and post-colonialism, and environment or [[nature]].

Since the late 1980s, many feminist geographers have moved on to three new research areas:

First, feminist geographers contest and expand the category of genders between men and women. The difference in the construction of gender relations across race, ethnicity, age, religion, sexuality and nationality, becomes interesting for feminist geographers. Additionally, feminist geographers are also increasingly attentive to women who are positioned in various ways along the multiple axis of difference.

Second, in order to get better understanding of how gender relations and identities are formed and assumed, a broader extent of social theory, particular culture, are drawn by feminist geographers. Feminist geographers are more able to discuss and debate after the focus on multiple identifications and the influence of post-structuralist and psychoanalytic theories.&lt;ref&gt;{{cite book|last=Monk|first=J.|title=On not excluding the other half from human geography|year=1982}}&lt;/ref&gt;

Third, a key area of discussion is about the difference between [[relativism]] and [[situated knowledge]], and ways to reconcile partial perspectives with commitment to political action and social change.

==Critical human geography==
Critical human geography is defined as “a diverse and rapidly changing set of ideas and practices within human geography linked by a share commitment to [[emancipatory politics]] within and beyond the discipline, to the promotion of progressive social change and to the development of a broad range of critical theories and their application in geographical research and political practice.” (Johnston 2000).&lt;ref name="Longhurt 2002"/&gt;

Critical human geography comes from Anglophonic geography in the mid-1990s. It presents a broad alliance of progressive approaches to the discipline. Critical human geographers draw on theoretical approaches such as [[anarchism]], [[anti-colonialism]], [[critical race theory]], [[environmentalism]], [[feminism]], [[Marxism]], nonrepresentational theory, [[post-Marxism]], post-colonialism, post-structuralism, [[psychoanalysis]], [[queer theory]], [[situationism]], and [[socialism]]. Much of the focus is on some of the key publications marking different eras in critical geography.

Critical human geography must be understood as multiple, dynamic, and contested.&lt;ref&gt;{{cite book|last=Warf|first=Barney|title=Encyclopedia of Geography Critical Human Geography|year=2010|publisher=University British Columbia-vancouve}}&lt;/ref&gt;

Rather than a specific sub-discipline of [[geography]], feminist geography is often considered part of a broader [[postmodern]], [[critical theory]] approach, often drawing from the theories of [[Michel Foucault]], [[Jacques Derrida]], and [[Judith Butler]] among others. More recent influences include critiques of feminism from [[post-colonial]] theorists. Feminist geographers often focus on the lived experiences of individuals and groups in their own localities, upon the geographies that they live in within their own communities, rather than theoretical development without [[empirical]] work.&lt;ref name=rose/&gt;

Many feminist geographers study the same subjects as other geographers, but often with a focus on [[gender]] divisions.&lt;ref name=mcdowell&gt;McDowell, Linda (1993) "Space, place and gender relations" in ''Progress in Human Geography'' 17(2)&lt;/ref&gt; This concern has developed into a concern with wider issues of gender, family, sexuality, race, and class. Examples of areas of focus include:
* Geographic differences in [[gender]] relations and [[gender equality]]
* The geography of [[women]]: spatial constraints, welfare geography
* The construction of [[gender identity]] through the use and nature of spaces and [[Location (geography)|places]]
* Geographies of [[Sexuality and space|sexuality]] ([[queer theory]])
* [[Children's geographies]]

Feminist geographers are also deeply impacted and responding to contemporary globalization and neoliberal discourses that are manifested as being both transnational and translocal. &lt;ref name=":0" /&gt; 

In addition to societal studies, Feminist Geography also critiques [[Human Geography]] and other academic disciplines,  arguing that academic structures have been traditionally characterized by a [[patriarchal]] perspective, and that contemporary studies which do not confront the nature of previous work reinforce the [[masculine]] bias of academic study.&lt;ref name="Moss"&gt;Moss, Pamela, 2007 ''Feminisms in Geography: Rethinking Space, Place, and Knowledges'' Rowman &amp; Littlefield Publishers {{ISBN|978-0-7425-3829-0}}&lt;/ref&gt; The British Geographer [[Gillian Rose (geographer)|Gillian Rose's]] ''Feminism and Geography''&lt;ref name="rose" /&gt; is one such sustained criticism, focused on Human Geography in Britain as being historically [[masculinist]] in its approach. This includes the writing of landscape as feminine (and thus as subordinate to male geographers), assuming a separation between mind and body.  The following is referenced from Johnston &amp; Sidaway (2004),&lt;ref name="johnston"&gt;Johnston, R.J. &amp; J.&amp;nbsp;D. Sidaway.  (2004). ''Geography and Geographers.'' London: Arnold, p. 312.&lt;/ref&gt; and further describes such a separation and its influence on geography:

{{Quotation|"'[[Cartesian dualism]] underlines our thinking in a myriad of ways, not least in the divergence of the social sciences from the natural sciences, and in a geography which is based on the separation of people from their environments.  Thus while geography is unusual in its spanning of the natural and social sciences and in focusing on the interrelations between people and their environments, it is still assumed that the two are distinct and one acts on the other. Geography, like all of the social sciences, has been built upon a particular conception of mind and body which sees them as separate, apart and acting on each other (Johnston, 1989, cited in Longhurst, 1997, p. 492)' 
Thus, too, feminist work has sought to transform approaches to the study of landscape by relating it to the way that it is represented ('appreciated' so to speak), in ways that are analogous to the heterosexual male gaze directed towards the female body (Nash 1996). Both of these concerns (and others)- about the body as a contested site and for the Cartesian distinction between mind and body - have been challenged in [[postmodern]] and [[poststructuralist]] feminist geographies."}}

Other feminist geographers have interrogated the ways in which the discipline of geography itself represents and reproduces the heterosexual male gaze. Feminist geographers such as [[Katherine McKittrick]] have asserted pointed critiques of the ways in which we see and understand space are fundamentally bound up in how we understand the hegemonic presence of the white male subject in history, geography and in the materiality of everyday space. Building off of [[Sylvia Wynter]]'s theories of the racialized production of public and private space, McKittrick challenges “social landscapes that presume [[subaltern]] populations have no relationship to the production of space” &lt;ref name=mckittrick&gt;McKittrick, Katherine. ''Demonic Grounds: Black Women and the Cartographies of Struggle''. Minneapolis, MN: University of Minnesota Press, 2006. p. 92&lt;/ref&gt; and writes to document black female geographies in order to "allow us to engage with a narrative that locates and draws on black histories and black subjects in order to make visible social lives which are often displaced, rendered ungeographic.”&lt;ref&gt;McKittrick, x.&lt;/ref&gt; McKittrick stakes claim in the co-articulation of race and gender as they articulate space and she writes, “I am emphasizing here that racism and sexism are not simply bodily or identity based; racism and sexism are also spatial acts and illustrate black women’s geographic experiences and knowledges as they are made possible through domination.”&lt;ref&gt;McKittrick, xviii&lt;/ref&gt; Moreover, many feminist geographers have critiqued human geography for its centering of masculine knowledge and its emphasis on “objective” knowledge arguing instead for a use of situated knowledge which understands both observation and analysis as being rooted in partial objectivity.&lt;ref name=":1"&gt;{{Cite journal|last=Coddington|first=Kate|date=2015|title=Feminist Geographies “Beyond” Gender: de-Coupling Feminist Research and the Gendered Subject|url=|journal=Geography Compass|volume=9|pages=214-224|via=}}&lt;/ref&gt;

== Challenges of feminist geography ==
Linda McDowell and Joanne P. Sharp, both foundational feminist geographers and scholars, describe the struggle of gaining recognition in academia, “[It has been] ‘a long struggle to gain recognition within geography as a discipline that gender relations are a central organizing feature both of the material and symbolic worlds and of the theoretical basis of the discipline.’’&lt;ref&gt;{{Cite book|title=Space, gender, knowledge: Feminist readings|last=McDowell|first=Linda|last2=Sharp|first2=Joanne|publisher=|year=1997|isbn=|location=|pages=}}&lt;/ref&gt;  Feminist geographers struggle in academia in a variety of ways. Firstly, ideas that originate from feminist discourse are often seen as common sense once the wider field accepts them thereby invisibilizing geography that is explicitly feminist. Furthermore, feminist geography is understood to be the only subfield of geography where gender is explicitly addressed permitting the wider disciple to disengage from feminist challenges. Finally, within the field, some geographers believe that feminist practice has been fully integrated into the academy making feminist geography obsolete.

Challenges of feminist geography are also embedded in the subfield itself. The epistemology of feminist geography argues that the positionality and lived experience of the geographers are as central to scholarship as what is being researched. In this way, feminist geographers must maintain diverse identities to fully engage with the disciple. Linda Peake and Gill Valentine point out that while feminist geography has addressed gender issues in more than twenty-five countries across the world, this scholarship is conducted by white female scholars from institutions in the Global North.&lt;ref&gt;{{Cite journal|last=Peake|first=Linda|last2=Valentine|first2=Gill|date=2003|title=Editorial|url=|journal=Gender, Place and Culture|volume=10(2)|pages=107-09|via=}}&lt;/ref&gt; In this way, feminist geography faces not only barriers rooted in the academy but a lack of diversity in its own field. &lt;ref&gt;{{Cite journal|last=Dias|first=Karen|last2=Blecha|first2=Jennifer|date=2007|title=Feminism and Social Theory in Geography: An Introduction*|url=|journal=Professional Geographer|volume=59(1)|pages=1-9|via=}}&lt;/ref&gt;

== Controversies surrounding feminist geography ==
In 2018, a leading journal in feminist geography, Gender, Place and Culture, was subject to a [[Scholarly publishing hoax|scholarly publishing hoax.]] Helen Pluckrose, James A. Lindsay and [[Peter Boghossian]] submitted a paper titled "Human Reactions to Rape Culture and Queer Performativity in Urban Dog Parks in Portland, Oregon".&lt;ref name=":2" /&gt; The paper proposed that dog parks are “rape-condoning spaces”, and a place of rampant canine rape culture and systemic oppression against “the oppressed dog” through which human attitudes to both problems can be measured and analyzed by applying [[black feminist criminology]]. The paper suggested that this could provide insight into training men out of the sexual violence and bigotry. The paper has since been retracted.&lt;ref&gt;{{Cite journal|last=Wilson|first=Helen|date=2018-10-05|title=Retracted article: Human reactions to rape culture and queer performativity at urban dog parks in Portland, Oregon|url=https://www.tandfonline.com/doi/abs/10.1080/0966369X.2018.1475346|journal=Gender, Place &amp; Culture|language=en|pages=1–20|doi=10.1080/0966369x.2018.1475346|issn=0966-369X}}&lt;/ref&gt; The hoax has been criticized as unethical and mean-spirited, and critics of the hoax have suggested that the hoaxers do not understand the process of peer review.&lt;ref&gt;{{Cite news|url=https://www.chronicle.com/article/What-the-Grievance/244753|title=What the ‘Grievance Studies’ Hoax Means|date=2018-10-09|work=The Chronicle of Higher Education|access-date=2018-10-13}}&lt;/ref&gt; 

==List of related geographers==
{{Columns-list|colwidth=22em|
*[[Dolores Hayden]]
*[[Rosalyn Deutsche]]
*[[Sarah Holloway]]
*[[Cindi Katz]]
*[[Doreen Massey (geographer)|Doreen Massey]]
*[[Linda McDowell]]
*[[Gillian Rose (geographer)|Gillian Rose]]
*[[Lynn Staeheli]] 
*[[Evelyn Stokes]]
*[[Gill Valentine]]
*[[Samantha Fletcher]]
*[[Geraldine Pratt]]
*[[Kirsten Simonsen]]
*[[Susan Hanson (geographer)|Susan Hanson]] 
}}

==See also==
*  [[History of geography]]
*  [[Critical geography]]
*  [[Cultural geography]]

==References==
{{reflist|30em}}

==Further reading==
*McKittrick, Katherine. Demonic Grounds: Black Women and the Cartographies of Struggle. Minneapolis, MN: University of Minnesota Press, 2006.
*McDowell, Linda (1992) ''Doing gender: feminisms, feminists and research methods in human geography''. Transactions of the Institute of British Geographers 17, 399-416.
*McDowell, Linda; and Sharp, Joanne P. (eds). (1999). ''A Feminist Glossary of Human Geography.'' London: Arnold.
*McDowell, Linda. (1999) ''Gender, Identity and Place: understanding feminist geographies.'' Cambridge : Polity Press, 1999
*Pratt, Geraldine. (2004) "Working Feminism." Philadelphia: Temple University Press.
*[[Gillian Rose (geographer)|Gillian Rose]] (1993) ''Feminism and Geography: The Limits of Geographical Knowledge'' Univ. of Minnesota Press
*Seager, Joni and Nelson, Lise. (eds) (2004) ''Companion to Feminist Geography (Blackwell Companions to Geography).'' Blackwell Publishers, {{ISBN|1-4051-0186-5}}
*Valentine, Gill. (2004) ''Public Space and the Culture of Childhood.'' London:Ashgate
*Johnston, R.J. &amp; J.D. Sidaway.  (2004).  ''Geography and Geographers.'' London: Arnold.  Chapter 8: Feminist geographies.
*Simonsen, Kirsten. (2007). "Practice, spatiality and embodied emotions: an outline of a geography of practice". Human Affairs, 17(2), 168-181.

===Scientific journals===
*[http://www.tandf.co.uk/journals/titles/0966369X.asp ''Gender, Place and Culture - A Journal of Feminist Geography''] Routledge ISSN 0966-369X Online ISSN 1360-0524

{{Human geography}}
{{Feminist theory}}

{{DEFAULTSORT:Feminist Geography}}
[[Category:Human geography]]
[[Category:Feminism and education]]
[[Category:Feminism and society]]</text>
      <sha1>7otxlkudpben1s5ldasznmldqxcklup</sha1>
    </revision>
  </page>
  <page>
    <title>Frequency (gene)</title>
    <ns>0</ns>
    <id>39055192</id>
    <revision>
      <id>853913324</id>
      <parentid>846911533</parentid>
      <timestamp>2018-08-07T19:42:38Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted 'interestingly' - see [[Wikipedia:Manual_of_Style/Words_to_watch#Editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36590">{{Pfam_box 
| Symbol = FRQ 
| Name = Frequency clock protein 
| image = 
| width = 
| caption = 
| Pfam = PF09421
| InterPro = IPR018554
| SMART= 
| Prosite = 
| SCOP =  
| TCDB = 
| OPM family= 
| OPM protein= 
| PDB= 
}}

The '''frequency''' (''frq'') [[gene]] encodes the protein frequency (FRQ) that functions in the ''Neurospora crassa'' circadian clock. The FRQ protein plays a key role in circadian oscillator, serving to nucleate the negative element complex in the auto regulatory transcription-translation negative feedback-loop (TTFL) that is responsible for [[circadian rhythm]]s in ''N. crassa''.&lt;ref&gt;{{cite journal | vauthors = Baker CL, Loros JJ, Dunlap JC | title = The circadian clock of Neurospora crassa | journal = FEMS Microbiology Reviews | volume = 36 | issue = 1 | pages = 95–110 | date = January 2012 | pmid = 21707668 | pmc = 3203324 | doi = 10.1111/j.1574-6976.2011.00288.x }}&lt;/ref&gt;  Similar rhythms are found in mammals, Drosophila and cyanobacteria.  Recently, FRQ [[Homology (biology)|homologs]] have been identified in several other species of fungi.&lt;ref name="Montenegro-Montero_2015"&gt;{{cite journal | vauthors = Montenegro-Montero A, Canessa P, Larrondo LF | title = Around the Fungal Clock: Recent Advances in the Molecular Study of Circadian Clocks in Neurospora and Other Fungi | journal = Advances in Genetics | volume = 92 | pages = 107–84 | date = 2015-01-01 | pmid = 26639917 | doi = 10.1016/bs.adgen.2015.09.003 }}&lt;/ref&gt;  Expression of frq is controlled by the two [[transcription factors]] [[White Collar-1|white collar-1]] (WC-1) and white collar-2 (WC-2) that act together as the White Collar Complex (WCC) and serve as the positive element in the TTFL.  Expression of frq can also be induced through light exposure in a WCC dependent manner. [[Forward genetics]] has generated many alleles of ''frq'' resulting in strains whose circadian clocks vary in period length.

== Discovery ==

The ''frq'' locus was discovered by Jerry F. Feldman.  Feldman had been a graduate student with Colin Pittendrigh at Princeton and went to CalTech in 1967 to begin genetic screens for circadian clock mutants. The screening was aided by recent work that improved the expression of the rhythm in ''Neurospora''.
[[Colin Pittendrigh ]]&lt;nowiki/&gt;and his colleagues had confirmed in 1959 that the daily cycle of asexual development, described  in ''[[Neurospora crassa]]'' earlier by Brandt,&lt;ref name = "Brandt_1953"&gt;{{cite journal | vauthors = Brandt WH | title = Zonation in a prolinelcss strain of Neurospora | journal = Mycologia | volume = 45 | pages = 194–209 | date = 1953 | jstor = 4547688 }}&lt;/ref&gt; was in fact due to regulation by a [[circadian clock]].&lt;ref&gt;{{cite journal | title = Growth Patterns in Neurospora: A Biological Clock in Neurospora | journal = Nature | date = July 18, 1959 | pages = 169–170 | volume = 184 | issue = 4681 | doi = 10.1038/184169a0 | first = C. S. | last = Pittendrigh | first2 = V. G. | last2 = Bruce | first3 = N. S. | last3 = Rosensweig | first4 = M. L. | last4 = Rubin | name-list-format = vanc }}&lt;/ref&gt; In work published not long before Feldman arrived at CalTech, Malcolm L. Sargent, Winslow R. Briggs and Dow O. Woodward at [[Stanford University]] reported that overt expression of the developmental rhythm in [[conidiation]] was enhanced in a strain of ''Neurospora'' called ''Timex.''&lt;ref name="pmid5978549"&gt;{{cite journal | vauthors = Sargent ML, Briggs WR, Woodward DO | title = Circadian nature of a rhythm expressed by an invertaseless strain of Neurospora crassa | journal = Plant Physiology | volume = 41 | issue = 8 | pages = 1343–9 | date = October 1966 | pmid = 5978549 | pmc = 550529 | doi = 10.1104/pp.41.8.1343 }}&lt;/ref&gt;'' ''(This strain contained a [[mutation]] in the locus ''band (bd)'', later shown to encode a mildly hyperactive allele of ''ras-1'' so strains are now known as ''ras-1[bd]''.&lt;ref name="Belden_2007"&gt;{{cite journal | vauthors = Belden WJ, Larrondo LF, Froehlich AC, Shi M, Chen CH, Loros JJ, Dunlap JC | title = The band mutation in Neurospora crassa is a dominant allele of ras-1 implicating RAS signaling in circadian output | journal = Genes &amp; Development | volume = 21 | issue = 12 | pages = 1494–505 | date = June 2007 | pmid = 17575051 | doi = 10.1101/gad.1551707 | pmc=1891427}}&lt;/ref&gt; Because rhythms in strains that include ''ras-1[bd]'' are easier to detect,  ''ras-1[bd]'' is often incorporated into strains used for studies of circadian biology in ''Neurospora''.&lt;ref name="Belden_2007" /&gt;).  Outputs of the ''Neurospora'' circadian clock include [[carotenoid]] synthesis as well as the asexual [[spore]] formation seen on race tubes, and recent evidence suggests that thousands of genes are under circadian control.&lt;ref name="Diernfellner_2007" /&gt;&lt;ref name="Montenegro-Montero_2015" /&gt;

Feldman used nitrosoguanidine as a mutagen and used race tubes to screen individual strains surviving the mutagenesis for their circadian period length. Race tubes are long hollow glass tubes bent at either end to hold an agar growth medium. When ''Neurospora'' is inoculated at one end of a tube it will grow to the other end, and in constant darkness the daily circadian cycle of growth and development is manifest.&lt;ref name="Nakashima_Onai_1996"&gt;{{cite journal |vauthors=Nakashima H, Onai K | title = The circadian conidiation rhythm in Neurospora crassa | journal = Seminars in Cell &amp; Developmental Biology |date=December 1996 | volume = 7 | issue = 6 | pages = 765–774 | doi = 10.1006/scdb.1996.0094 }}&lt;/ref&gt;  Although Feldman's screens were successful he was slow to publish so the identity of mutant genes ''frq''[1], ''frq''[2], and ''frq''[3] were not reported until 1973.&lt;ref name="pmid4273217"&gt;{{cite journal | vauthors = Feldman JF, Hoyle MN | title = Isolation of circadian clock mutants of Neurospora crassa | journal = Genetics | volume = 75 | issue = 4 | pages = 605–13 | date = December 1973 | pmid = 4273217 | pmc = 1213033 | doi =  }}&lt;/ref&gt;  In 1986, ''frq'' was cloned by [[Jay Dunlap]] and his colleagues using a strategy that involved a long chromosome walk and successful application of the then-untried strategy of rescuing an arrhythmic behavioral mutant through transformation of exogenous DNA arising from the chromosome walk. The success of this strategy and of the cloning of a clock gene sparked interest in further research and understanding of the ''[[Neurospora crassa|N. crassa]] ''circadian clock.&lt;ref name="pmid2525233"&gt;{{cite journal | vauthors = McClung CR, Fox BA, Dunlap JC | title = The Neurospora clock gene frequency shares a sequence element with the Drosophila clock gene period | journal = Nature | volume = 339 | issue = 6225 | pages = 558–62 | date = June 1989 | pmid = 2525233 | doi = 10.1038/339558a0 }}&lt;/ref&gt;  The expression of ''frq'' was later shown to rhythmically cycle; furthermore, when strains of ''Neurospora'' were engineered in which ''frq'' expression could be driven from a region distinct from the resident [[wild type]] gene,  it was found that FRQ repressed its own expression and that no level of constant expression could support a circadian clock.&lt;ref name = "Aronson_1994"&gt;{{cite journal | vauthors = Aronson BD, Johnson KA, Loros JJ, Dunlap JC | title = Negative feedback defining a circadian clock: autoregulation of the clock gene frequency | journal = Science | volume = 263 | issue = 5153 | pages = 1578–84 | date = March 1994 | pmid = 8128244 | doi = 10.1126/science.8128244 }}&lt;/ref&gt; These experiments were the first to manipulate the expression of a clock gene through means that did not themselves affect the clock and established that autoregulatory negative feedback giving rise to cyclical clock gene expression lay at the core of the circadian oscillator.

== Structure and Function ==
[[File:Simplified Representation of Neurospora Circadian Clock.jpg|thumbnail|Simplified Representation of ''Neurospora'' Circadian Clock&lt;ref name="Tseng_2012"&gt;{{cite journal | vauthors = Tseng YY, Hunt SM, Heintzen C, Crosthwaite SK, Schwartz JM | title = Comprehensive modelling of the Neurospora circadian clock and its temperature compensation | journal = PLoS Computational Biology | volume = 8 | issue = 3 | pages = e1002437 | year = 2012 | pmid = 22496627 | pmc = 3320131 | doi = 10.1371/journal.pcbi.1002437 }}&lt;/ref&gt;]]

Reflecting its role as a core clock protein, deletion of the ''frq'' gene results in arrhythmicity, and in ''Neurospora'', the only function of FRQ is in the circadian clock. The ''frq'' gene can be activated from two distinct cis-acting sequences in its promoter, a distal site, the clock-box, used in the context of circadian regulation, and a site close to the principal transcription start site that is used for light-induced expression (the proximal light-regulatory element or PLRE). These ''frq'' transcripts both have capacity to encode two FRQ proteins, a long form of 989 [[amino acid]]s (lFRQ) and a short form of 890 [[amino acid]]s (sFRQ); both lFRQ and sFRQ are required for strong rhythmicity although the clock is able to persist at certain temperatures, albeit with a weaker rhythmicity, with just one of the proteins present.&lt;ref name="pmid9150147"&gt;{{cite journal | vauthors = Liu Y, Garceau NY, Loros JJ, Dunlap JC | title = Thermally regulated translational control of FRQ mediates aspects of temperature responses in the neurospora circadian clock | journal = Cell | volume = 89 | issue = 3 | pages = 477–86 | date = May 1997 | pmid = 9150147 | doi = 10.1016/S0092-8674(00)80228-7 }}&lt;/ref&gt; The choice of which protein is made is the result of temperature-dependent splicing of the primary transcript such that it includes or excludes the ATG start codon for lFRQ.&lt;ref name="Colot_2005"&gt;{{cite journal | vauthors = Colot HV, Loros JJ, Dunlap JC | title = Temperature-modulated alternative splicing and promoter use in the Circadian clock gene frequency | journal = Molecular Biology of the Cell | volume = 16 | issue = 12 | pages = 5563–71 | year = 2005 | pmid = 16195340 | pmc = 1289402 | doi = 10.1091/mbc.E05-08-0756 | url = }}&lt;/ref&gt; The two forms of FRQ provide the ''Neurospora'' clock a greater range of temperatures over which it can operate optimally. An increase in temperature leads to increased expression of lFRQ, while sFRQ is unaffected. Warmer temperatures induce more efficient [[alternative splicing|splicing]] of an [[intron]] in the translation start site.&lt;ref name="Diernfellner_2007"&gt;{{cite journal | vauthors = Diernfellner A, Colot HV, Dintsis O, Loros JJ, Dunlap JC, Brunner M | title = Long and short isoforms of Neurospora clock protein FRQ support temperature-compensated circadian rhythms | journal = FEBS Letters | volume = 581 | issue = 30 | pages = 5759–64 | date = December 2007 | pmid = 18037381 | pmc = 2704016 | doi = 10.1016/j.febslet.2007.11.043 }}&lt;/ref&gt; Because sFRQ favors a longer period than lFRQ, free running rhythms in wild type ''Neurospora'' are somewhat decreased with increased temperature.&lt;ref name="Diernfellner_2007" /&gt;

FRQ has also been shown to interact with several other proteins.  It interacts at all times with FRH (FRQ-interacting RNA [[helicase]]; an essential [[DEAD box]]-containing RNA helicase in ''Neurospora'') to form a FRQ/FRH complex (FFC).&lt;ref name="Cheng_2005"&gt;{{cite journal | vauthors = Cheng P, He Q, He Q, Wang L, Liu Y | title = Regulation of the Neurospora circadian clock by an RNA helicase | journal = Genes &amp; Development | volume = 19 | issue = 2 | pages = 234–41 | date = January 2005 | pmid = 15625191 | pmc = 545885 | doi = 10.1101/gad.1266805 }}&lt;/ref&gt;&lt;ref name = "Baker_2009"&gt;{{cite journal | vauthors = Baker CL, Kettenbach AN, Loros JJ, Gerber SA, Dunlap JC | title = Quantitative proteomics reveals a dynamic interactome and phase-specific phosphorylation in the Neurospora circadian clock | journal = Molecular Cell | volume = 34 | issue = 3 | pages = 354–63 | year = 2009 | pmid = 19450533 | pmc = 2711022 | doi = 10.1016/j.molcel.2009.04.023 }}&lt;/ref&gt; FRQ also stably interacts with [[casein kinase 1]] (CK1) although the strength of the interaction changes with time of day. Additional interactions with other kinases including PRD-4 (CHK2)&lt;ref name = "Pregueiro_2006"&gt;{{cite journal | vauthors = Pregueiro AM, Liu Q, Baker CL, Dunlap JC, Loros JJ | title = The Neurospora checkpoint kinase 2: a regulatory link between the circadian and cell cycles | journal = Science | volume = 313 | issue = 5787 | pages = 644–9 | year = 2006 | pmid = 16809488 | doi = 10.1126/science.1121716 }}&lt;/ref&gt; and [[casein kinase 2]] (CKII) are known.

Structural prediction programs suggest that only a few regions of FRQ are likely to fold into stable structures, and consistent with this a variety of experimental data indicate that FRQ is an [[Intrinsically disordered proteins|Intrinsically Disordered Protein]].&lt;ref name = "Hurley_2013"&gt;{{cite journal | vauthors = Hurley JM, Larrondo LF, Loros JJ, Dunlap JC | title = Conserved RNA helicase FRH acts nonenzymatically to support the intrinsically disordered Neurospora clock protein FRQ | journal = Molecular Cell | volume = 52 | issue = 6 | pages = 832–43 | date = December 2013 | pmid = 24316221 | doi = 10.1016/j.molcel.2013.11.005 | pmc=3900029}}&lt;/ref&gt; In the absence of its partner FRH, FRQ is very unstable. The myriad time-of-day specific phosphorylation that characterize FRQ are predicted to provide structure to this otherwise disordered protein. There is no known domain structure to FRQ because of its highly disordered structure.

Typically, proteins show a codon usage bias where they are more likely to choose synonymous codons that are more available in their [[Transfer RNA|tRNA]] pool. ''Neurospora crassa'' has a relatively strong codon usage bias compared to ''[[Saccharomyces cerevisiae|S. cerevisiae]]'', a commonly used organism for codon-optimization analysis. However, because FRQ is an Intrinsically Disordered Protein, it does not have demonstrate codon usage bias. In fact, when its codons are optimized, the protein loses its function and the clock is disturbed. This is not the case for [[cyanobacteria]]l clock genes, kaiB and [[kaiC]], which both led to more robust clock function.&lt;ref&gt;{{Cite journal|last=Zhou|first=Mian|last2=Wang|first2=Tao|last3=Fu|first3=Jingjing|last4=Xiao|first4=Guanghua|last5=Liu|first5=Yi|date=2017-04-27|title=Non-optimal codon usage influences protein structure in intrinsically disordered regions|journal=Molecular Microbiology|volume=97|issue=5|pages=974–987|doi=10.1111/mmi.13079|issn=0950-382X|pmc=4636118|pmid=26032251}}&lt;/ref&gt;

== Regulation ==
[[File:Frq, FRQ and WC1 peaks.jpg|thumb|388x388px|Relative peaks of ''frq'' mRNA, FRQ protein and WC-1 protein.&lt;ref&gt;{{cite journal | vauthors = Dunlap JC, Loros JJ, Colot HV, Mehra A, Belden WJ, Shi M, Hong CI, Larrondo LF, Baker CL, Chen CH, Schwerdtfeger C, Collopy PD, Gamsby JJ, Lambreghts R | title = A circadian clock in Neurospora: how genes and proteins cooperate to produce a sustained, entrainable, and compensated biological oscillator with a period of about a day | journal = Cold Spring Harbor Symposia on Quantitative Biology | volume = 72 | pages = 57–68 | pmid = 18522516 | doi = 10.1101/sqb.2007.72.072 | pmc=3683860 | year=2007}}&lt;/ref&gt; Demonstrates how WC-1 activates subsequent transcription of ''frq.'']]
A description of the regulation of ''frq'' and FRQ requires a description of the clock cycle. The molecular basis of the circadian oscillator in ''Neurospora'' begins with two protein complexes. One is the FFC, the negative element complex composed of two copies of FRQ, FRH, and Casein kinase 1 as well as, probably, other less strongly bound proteins.&lt;ref name = "Baker_2009" /&gt;  The other complex which acts as the positive element in the feedback loop includes WC-1 and WC-2; they are [[GATA transcription factor]]s that, together, form the heterodimeric WCC via their [[PAS domain]]s.&lt;ref&gt;{{cite journal | vauthors = Talora C, Franchi L, Linden H, Ballario P, Macino G | title = Role of a white collar-1-white collar-2 complex in blue-light signal transduction | journal = The EMBO Journal | volume = 18 | issue = 18 | pages = 4961–8 | date = September 1999 | pmid = 10487748 | pmc = 1171567 | doi = 10.1093/emboj/18.18.4961 }}&lt;/ref&gt; When WCC is released from the FFC negative element complex during subjective night, it binds to the clock-box within frequency (''frq'') gene [[promoter (genetics)|promoter]] and activates ''frq'' [[Transcription (genetics)|transcription]].&lt;ref name="Froehlich_2002"&gt;{{cite journal | vauthors = Froehlich AC, Liu Y, Loros JJ, Dunlap JC | title = White Collar-1, a circadian blue light photoreceptor, binding to the frequency promoter | journal = Science | volume = 297 | issue = 5582 | pages = 815–9 | year = 2002 | pmid = 12098706 | doi = 10.1126/science.1073681 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Denault DL, Loros JJ, Dunlap JC | title = WC-2 mediates WC-1-FRQ interaction within the PAS protein-linked circadian feedback loop of Neurospora | journal = The EMBO Journal | volume = 20 | issue = 1–2 | pages = 109–17 | date = January 2001 | pmid = 11226161 | pmc = 140181 | doi = 10.1093/emboj/20.1.109 }}&lt;/ref&gt; It has recently been shown that the Histone H3 Lysine 36 [[Methyltransferase]], SET-2, is responsible for methylation of the ''frq'' gene to establish a chromatin state that will allow for transcription of ''frq'' by the WCC.&lt;ref&gt;{{cite journal | vauthors = Sun G, Zhou Z, Liu X, Gai K, Liu Q, Cha J, Kaleri FN, Wang Y, He Q | title = Suppression of WHITE COLLAR-independent frequency Transcription by Histone H3 Lysine 36 Methyltransferase SET-2 Is Necessary for Clock Function in Neurospora | journal = The Journal of Biological Chemistry | volume = 291 | issue = 21 | pages = 11055–63 | date = May 2016 | pmid = 27002152 | pmc = 4900255 | doi = 10.1074/jbc.M115.711333 }}&lt;/ref&gt;

The frequency (FRQ) protein accumulates and is progressively phosphorylated by CKI, CKII, and a [[CAMK1|calcium/calmodulin-dependent kinase]] (CAMK-1), and additional kinases, reaching its peak around mid-subjective day.&lt;ref name="Garceau_1997"&gt;{{cite journal | vauthors = Garceau NY, Liu Y, Loros JJ, Dunlap JC | title = Alternative initiation of translation and time-specific phosphorylation yield multiple forms of the essential clock protein FREQUENCY | journal = Cell | volume = 89 | issue = 3 | pages = 469–76 | year = 1997 | pmid = 9150146 | doi = 10.1016/S0092-8674(00)80227-5 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Heintzen C, Liu Y | title = The Neurospora crassa circadian clock | journal = Advances in Genetics | volume = 58 | issue =  | pages = 25–66 | year = 2007 | pmid = 17452245 | doi = 10.1016/s0065-2660(06)58002-2 }}&lt;/ref&gt;&lt;ref name="Cha_2015"&gt;{{cite journal | vauthors = Cha J, Zhou M, Liu Y | title = Mechanism of the Neurospora circadian clock, a FREQUENCY-centric view | journal = Biochemistry | volume = 54 | issue = 2 | pages = 150–6 | date = January 2015 | pmid = 25302868 | pmc = 4303299 | doi = 10.1021/bi5005624 }}&lt;/ref&gt; Kinase inhibitors reduce degradation of FRQ by preventing phosphorylation.&lt;ref&gt;{{cite journal | vauthors = Liu Y, Loros J, Dunlap JC | title = Phosphorylation of the Neurospora clock protein FREQUENCY determines its degradation rate and strongly influences the period length of the circadian clock | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 97 | issue = 1 | pages = 234–9 | date = January 2000 | pmid = 10618401 | pmc = 26646 | doi = 10.1073/pnas.97.1.234 }}&lt;/ref&gt; FRQ is phosphorylated at more than 100 sites based on ''in vitro'' analyses using mass spectrometry of lFRQ peptides. These sites appear within the protein in a highly reproducible manner indicating that the timing of the phosphorylations is important. Moreover, mutation of the sites shows that they work in domains, with some phosphorylations serving to lengthen period and others to shorten period.&lt;ref name = "Baker_2009" /&gt;

FRQ recruits [[kinase]]s such as [[casein kinase 1]]a (CK-1a) that [[phosphorylates|phosphorylate]] WCC, although the function of these phosphorylations is unclear as hyperphosphorylated WCC remains active. Eventually, repression is relieved when FRQ becomes so highly phosphorylated that the FFC no longer interacts with the WCC. This process occurs with a periodicity of around 22 hours in constant conditions.&lt;ref&gt;{{cite journal | vauthors = Larrondo LF, Olivares-Yañez C, Baker CL, Loros JJ, Dunlap JC | title = Circadian rhythms. Decoupling circadian clock protein turnover from circadian period determination | journal = Science | volume = 347 | issue = 6221 | pages = 1257277 | date = January 2015 | pmid = 25635104 | pmc = 4432837 | doi = 10.1126/science.1257277 }}&lt;/ref&gt; At a later time, and with kinetics that do not influence the circadian cycle, this hyperphosphorylated FRQ is degraded through the ubiquitin/proteasome pathway. Heavily phosphorylated FRQ undergoes a conformational change that is detected by the FWD-1 protein, which is part of the SCF type E3 ligase.&lt;ref name="He_2003"&gt;{{cite journal | vauthors = He Q, Cheng P, Yang Y, He Q, Yu H, Liu Y | title = FWD1-mediated degradation of FREQUENCY in Neurospora establishes a conserved mechanism for circadian clock regulation | journal = The EMBO Journal | volume = 22 | issue = 17 | pages = 4421–30 | date = September 2003 | pmid = 12941694 | pmc = 202367 | doi = 10.1093/emboj/cdg425 }}&lt;/ref&gt;

FRQ forms a homodimer via its coiled-coil domain located near the N-terminus. This dimerization is required for FRQ to interact with the WCC and repress its own expression.&lt;ref name="Cheng_2001"/&gt; Deletion of the WCC leads to an inability to form the homodimer, which causes ''frq'' to no longer be negatively regulated by FRQ concentration.&lt;ref name="Cheng_2001"&gt;{{cite journal | vauthors = Cheng P, Yang Y, Heintzen C, Liu Y | title = Coiled-coil domain-mediated FRQ-FRQ interaction is essential for its circadian clock function in Neurospora | journal = The EMBO Journal | volume = 20 | issue = 1–2 | pages = 101–8 | date = January 2001 | pmid = 11226160 | pmc = 140186 | doi = 10.1093/emboj/20.1.101 }}&lt;/ref&gt; This leads to arrhythmicity.&lt;ref name="Cheng_2001" /&gt;

A positive feedback loop between FRQ and WCC has been proposed but details are not yet known. It is believed that WCC is degraded when it is transcriptionally active, and that prevention of this caused by the FFC allows for an accumulation of WCC.&lt;ref name = "Shi_2010"&gt;{{cite journal | vauthors = Shi M, Collett M, Loros JJ, Dunlap JC | title = FRQ-interacting RNA helicase mediates negative and positive feedback in the Neurospora circadian clock | journal = Genetics | volume = 184 | issue = 2 | pages = 351–61 | year = 2010 | pmid = 19948888 | pmc = 2828717 | doi = 10.1534/genetics.109.111393 }}&lt;/ref&gt; This proposed mechanism has been shown to possibly be more complex in that FRQ may regulate WC-1 and WC-2 independently.&lt;ref name="Lakin-Thomas_2011"&gt;{{cite journal | vauthors = Lakin-Thomas PL, Bell-Pedersen D, Brody S | title = The genetics of circadian rhythms in Neurospora | journal = Advances in Genetics | volume = 74 | pages = 55–103 | date = 2011-01-01 | pmid = 21924975 | doi = 10.1016/b978-0-12-387690-4.00003-9 | series = The Genetics of Circadian Rhythms | editor-first = Stuart | editor-last = Brody | name-list-format = vanc | pmc=5027897}}&lt;/ref&gt; Recently the transcription factor ADV-1 was identified as a necessary transducer of clock outputs, including circadian rhythmicity in genes critical to [[somatic cell]] fusion.&lt;ref&gt;{{Cite journal|last=Dekhang|first=Rigzin|last2=Wu|first2=Cheng|last3=Smith|first3=Kristina M.|last4=Lamb|first4=Teresa M.|last5=Peterson|first5=Matthew|last6=Bredeweg|first6=Erin L.|last7=Ibarra|first7=Oneida|last8=Emerson|first8=Jillian M.|last9=Karunarathna|first9=Nirmala|date=2017-01-05|title=The Neurospora Transcription Factor ADV-1 Transduces Light Signals and Temporal Information to Control Rhythmic Expression of Genes Involved in Cell Fusion|journal=G3 (Bethesda, Md.)|volume=7|issue=1|pages=129–142|doi=10.1534/g3.116.034298|issn=2160-1836|pmc=5217103|pmid=27856696}}&lt;/ref&gt;

The ''frq'' gene is strongly induced by short duration exposure to light. Because the core of the clock is based on rhythmic expression of ''frq'', acute light-induction provides a straightforward way to reset the clock.&lt;ref name = "Crosthwaite_1995"&gt;{{cite journal | vauthors = Crosthwaite SK, Loros JJ, Dunlap JC | title = Light-induced resetting of a circadian clock is mediated by a rapid increase in frequency transcript | journal = Cell | volume = 81 | issue = 7 | pages = 1003–12 | year = 1995 | pmid = 7600569 | doi = 10.1016/S0092-8674(05)80005-4 }}&lt;/ref&gt; Mammalian clocks are reset by light by a nearly identical mechanism, with ''mPer1'' transcripts being induced by short flashes of light outside of the subjective day. The ''mPer1'' mechanism in the mammalian clock draws closer similarities to the mechanism in ''Neurospora'' than to the mechanism of its homolog in [[Drosophila]], [[Period (gene)|''per'']].&lt;ref&gt;{{cite journal | vauthors = Shigeyoshi Y, Taguchi K, Yamamoto S, Takekida S, Yan L, Tei H, Moriya T, Shibata S, Loros JJ, Dunlap JC, Okamura H | title = Light-induced resetting of a mammalian circadian clock is associated with rapid induction of the mPer1 transcript | journal = Cell | volume = 91 | issue = 7 | pages = 1043–53 | date = December 1997 | pmid = 9428526 | doi = 10.1016/s0092-8674(00)80494-8 }}&lt;/ref&gt;

== Mutations ==

[[Forward genetics]] has been used to create ''Neurospora'' clock mutants with varied periods of [[conidiation]]. Although nine alleles have been described as having come from forward genetics, sequence analysis subsequent to the cloning of ''frq'' showed that ''frq''[2] ,''frq''[4], and ''frq''[6]  shared the same single base change, and likewise ''frq''[7]  and ''frq''[8]  had the same single base change, so the redundant alleles have been dropped.&lt;ref name="Aronson_1994b"&gt;{{cite journal | vauthors = Aronson BD, Johnson KA, Dunlap JC | title = Circadian clock locus frequency: protein encoded by a single open reading frame defines period length and temperature compensation | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 91 | issue = 16 | pages = 7683–7 | year = 1994 | pmid = 8052643 | pmc = 44466 | doi = 10.1073/pnas.91.16.7683| url = }}&lt;/ref&gt;   The periods of various ''frq'' mutants that arose from forward screens are as follows when measured at 25&lt;sup&gt;o&lt;/sup&gt;C, although it should be noted that because ''frq''[3] and ''frq''[7] result in clocks with altered temperature compensation, periods will be different at other temperatures: 
[[File:Importance-of-MAP-Kinases-during-Protoperithecial-Morphogenesis-in-Neurospora-crassa-pone.0042565.s006.ogv|thumb|224x224px|''Neurospora crassa, ''organism used to study the FRQ/WCC oscillator]]
{| class="wikitable"
|+Period of ''frq'' mutants at 25˚C
|Mutant
|''frq''[1]
|''frq''[2]
|''frq''[3
|''frq''[7]
|''frq''[9]
|-
|Period (hr)
|16.5
|19.3
|24.0
|29.0
|Arrhythmic
|}

== FRQ-less Oscillator (FLO) ==

A number of identifiably distinct oscillators outside of the FRQ/WCC system have been discovered; however, none of these FRQ-less oscillations (FLOs) satisfy the characteristics to be classified as [[circadian]] oscillators.&lt;ref name="Shi_2007"&gt;{{cite journal | vauthors = Shi M, Larrondo LF, Loros JJ, Dunlap JC | title = A developmental cycle masks output from the circadian oscillator under conditions of choline deficiency in Neurospora | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 104 | issue = 50 | pages = 20102–7 | date = December 2007 | pmid = 18056807 | pmc = 2148429 | doi = 10.1073/pnas.0706631104 }}&lt;/ref&gt; The circadian FRQ-WCC Oscillator (FWO) has been shown, via [[luciferase]] reporting, to continue running even when a FLO (the CDO or choline deficiency oscillator that controls conidiation under conditions of choline limitation) controls conidiation.&lt;ref name="Shi_2007" /&gt;  In the ''frq[9]'' mutant ''Neurospora crassa'', a non-temperature compensated rhythm of conidiospore development was still observed in constant darkness (DD).&lt;ref&gt;{{cite journal | vauthors = Loros JJ, Richman A, Feldman JF | title = A recessive circadian clock mutation at the frq locus of Neurospora crassa | journal = Genetics | volume = 114 | issue = 4 | pages = 1095–110 | date = December 1986 | pmid = 2948874 | pmc = 1203030 }}&lt;/ref&gt; The period for ''frq'' null mutants varied from 12 to 35 hours but could be stabilized by the addition of [[farnesol]] or [[geraniol]]. However, this mechanism is not well understood.&lt;ref name="Bell-Pedersen_2005"&gt;{{cite journal | vauthors = Bell-Pedersen D, Cassone VM, Earnest DJ, Golden SS, Hardin PE, Thomas TL, Zoran MJ | title = Circadian rhythms from multiple oscillators: lessons from diverse organisms | journal = Nature Reviews Genetics | volume = 6 | issue = 7 | pages = 544–56 | date = July 2005 | pmid = 15951747 | pmc = 2735866 | doi = 10.1038/nrg1633 }}&lt;/ref&gt; Although this FRQ-less rhythm lost certain clock characteristics such as temperature compensation, temperature pulses were sufficient to reset the clock.&lt;ref name="pmid12932081"&gt;{{cite journal | vauthors = Granshaw T, Tsukamoto M, Brody S | title = Circadian rhythms in Neurospora crassa: farnesol or geraniol allow expression of rhythmicity in the otherwise arrhythmic strains frq10, wc-1, and wc-2 | journal = Journal of Biological Rhythms | volume = 18 | issue = 4 | pages = 287–96 | date = August 2003 | pmid = 12932081 | doi = 10.1177/0748730403255934 }}&lt;/ref&gt; Another FLO is the NRO or Nitrate Reductase Oscillator that appears under conditions of nitrate starvation and is thought to arise from feedback loops within the nitrate assimilation pathway; it has a period length of about 24 hours but is not temperature compensated.&lt;ref name="Christensen_2004"&gt;{{cite journal | vauthors = Christensen MK, Falkeid G, Loros JJ, Dunlap JC, Lillo C, Ruoff P | title = A nitrate-induced frq-less oscillator in Neurospora crassa | journal = Journal of Biological Rhythms | volume = 19 | issue = 4 | pages = 280–6 | year = 2004 | pmid = 15245647 | doi = 10.1177/0748730404265532 | url = }}&lt;/ref&gt;  In short, there is much evidence to support FRQ-less oscillators in ''Neurospora crassa. ''One way to rationalize this is to assume that many are "slaves" to the frequency/white collar oscillator; they do not possess all of the characteristics of a circadian clock on their own because this is supplied by the FWO.&lt;ref name="Bell-Pedersen_2005" /&gt;  However, rhythms in clock-controlled gene-16 (ccg-16) are coupled to the FWO but function autonomously, demonstrating that ''Neurospora crassa'' contains at least 2 potential pacemakers, but only one that can be reset by light and temperature while maintaining temperature compensation.&lt;ref name="Bell-Pedersen_2005" /&gt;&lt;ref name="Dunlap_2004"&gt;{{cite journal | vauthors = Dunlap JC, Loros JJ | title = The neurospora circadian system | journal = Journal of Biological Rhythms | volume = 19 | issue = 5 | pages = 414–24 | date = October 2004 | pmid = 15534321 | doi = 10.1177/0748730404269116 }}&lt;/ref&gt; The FRQ-less oscillator has never been proven to affect the true circadian clock.&lt;ref name="Dunlap_2004" /&gt; The mechanism and significance for FRQ-less oscillators (FLO) are still under research.

== Evolution ==

The FRQ protein is conserved within the ''Sordariacea'' but diverges outside of this group.&lt;ref name="Montenegro-Montero_2015"/&gt;&lt;ref name="Salichos_2010"&gt;{{cite journal | vauthors = Salichos L, Rokas A | title = The diversity and evolution of circadian clock proteins in fungi | journal = Mycologia | volume = 102 | issue = 2 | pages = 269–78 | year = 2010 | pmid = 20361495 | doi = 10.3852/09-073| jstor = 27811038 }}&lt;/ref&gt;  Nonetheless bona fide FRQ-based circadian cocks have been found in organisms other than ''Neurospora'' both within the ''Sordariacea'', for instance, in the salient fungal pathogen Botrytis,&lt;ref name="pmid26124115"&gt;{{cite journal | vauthors = Hevia MA, Canessa P, Müller-Esparza H, Larrondo LF | title = A circadian oscillator in the fungus Botrytis cinerea regulates virulence when infecting Arabidopsis thaliana | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 112 | issue = 28 | pages = 8744–9 | year = 2015 | pmid = 26124115 | pmc = 4507220 | doi = 10.1073/pnas.1508432112 }}&lt;/ref&gt; and also as far afield as Pyronema&lt;ref name="Traeger_2015"&gt;{{cite journal | vauthors = Traeger S, Nowrousian M | title = Analysis of Circadian Rhythms in the Basal Filamentous Ascomycete Pyronema confluens | journal = G3 (Bethesda, Md.) | volume = 5 | issue = 10 | pages = 2061–71 | year = 2015 | pmid = 26254031 | pmc = 4592989 | doi = 10.1534/g3.115.020461 }}&lt;/ref&gt; within the Pezizomycetes, an early-diverging lineage of filamentous ascomycetes. ''Frq'' was even found in non-Dikarya group of fungi. The finding of ''frq'' and conserved circadian clock mechanism inside non-Dikarya, Arbuscular Mycorrhizal Fungi expanded the evolutionary history of this gene in Fungal kingdom &lt;ref&gt;Lee, SJ., Kong, M., Morse, D. Hijri, M. (2018) Expression of putative circadian clock components in the arbuscular mycorrhizal fungus Rhizoglomus irregulare. Mycorrhiza. https://doi.org/10.1007/s00572-018-0843-y&lt;/ref&gt;. ''frq'' seems to diverge very quickly during its evolution. A part of the reason why the FRQ primary amino acid sequence diverges so quickly may be because it is an Intrinsically Disordered Protein and as a result lacks the structural constraints that limit sequence changes.&lt;ref name="Dunlap_2006"&gt;{{cite journal | vauthors = Dunlap JC, Loros JJ | title = How fungi keep time: circadian system in Neurospora and other fungi | journal = Current Opinion in Microbiology | volume = 9 | issue = 6 | pages = 579–87 | date = December 2006 | pmid = 17064954 | doi = 10.1016/j.mib.2006.10.008 }}&lt;/ref&gt;&lt;ref name = "Hurley_2013" /&gt;  Since [[codon]] optimization of the ''frq'' [[gene]] results in impaired circadian [[feedback|feedback loop]] function, ''frq'' displays non-optimal [[codon usage bias]] across its [[open reading frame]] in contrast to most other genes.&lt;ref name="pmid23417067"&gt;{{cite journal | vauthors = Zhou M, Guo J, Cha J, Chae M, Chen S, Barral JM, Sachs MS, Liu Y | title = Non-optimal codon usage affects expression, structure and function of clock protein FRQ | journal = Nature | volume = 495 | issue = 7439 | pages = 111–5 | date = March 2013 | pmid = 23417067 | pmc = 3629845 | doi = 10.1038/nature11833 }}&lt;/ref&gt; FRQ is an intrinsically disordered protein that is not well conserved, even across fungi.&lt;ref&gt;{{cite journal | vauthors = Hurley JM, Larrondo LF, Loros JJ, Dunlap JC | title = Conserved RNA helicase FRH acts nonenzymatically to support the intrinsically disordered neurospora clock protein FRQ | journal = Molecular Cell | volume = 52 | issue = 6 | pages = 832–43 | date = December 2013 | pmid = 24316221 | doi = 10.1016/j.molcel.2013.11.005 | pmc=3900029}}&lt;/ref&gt; Unlike FRQ, however, WC-1 is very well conserved. It is the founding member of the family of blue light photoreceptors used in the entire Kingdom of fungi. Moreover, it is similar in structure and function to [[ARNTL|BMAL1]]. [[Casein kinase 2]] is conserved in the circadian oscillators of plants ([[Arabidopsis]]) and flies ([[Drosophila]]).&lt;ref name="He_2003" /&gt; A similar form of [[casein kinase 1|CKI]] is necessary for the degradation of [[Period (gene)|period]] (PER) proteins in ''Drosophila'' and mammals.&lt;ref name="He_2003" /&gt; The Drosophila gene ''slimb'' is orthologous to [[F-box protein|FWD1]] in ''Neurospora'', both of which are crucial for clock protein degradation.&lt;ref name="He_2003" /&gt; In general, the TTFLs found in fungi and animals share a similar regulatory architecture, with a single step negative feedback loop, PAS-PAS heterodimeric activators that are conserved, and negative element proteins that largely lack structure and are much less well conserved. A similar palette of kinases modifies the clock proteins in all cases.

== See also ==
*[[White Collar-1]]
*[[Colin Pittendrigh]]
*[[Period (gene)]]
*[[Casein kinase 1]]
*''[[Neurospora crassa]]''
*[[Negative feedback]]

== References ==
{{reflist|33em}}

[[Category:Chronobiology]]
[[Category:Circadian rhythm]]
[[Category:Fungal proteins]]
[[Category:Sordariales]]
[[Category:Fungus genes]]
[[Category:Articles containing video clips]]</text>
      <sha1>lttx885nocucw3seehcwn5iwpi91qgq</sha1>
    </revision>
  </page>
  <page>
    <title>Gerontogens</title>
    <ns>0</ns>
    <id>47987393</id>
    <revision>
      <id>684155034</id>
      <parentid>684154975</parentid>
      <timestamp>2015-10-04T22:46:21Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1713">{{Orphan|date=October 2015}}

'''Gerontogens''' are environmental agents that can accelerate aging in some animals, including humans. Gerontogens are typically toxic chemical agents, such as those found in cigarette smoke. However, many other things can act as gerontogens, including [[Ultraviolet|ultraviolet radiation]], [[chemotherapy]] treatment, and [[arsenic]].&lt;ref&gt;{{Cite web|title = Toxins in the Environment Further Age Humanity|url = http://www.natureworldnews.com/articles/7278/20140528/toxins-environment-further-age-humanity.htm|accessdate = 2015-10-01}}&lt;/ref&gt;

Gerontogens work in two different ways. They can shorten [[telomere]]s, repetitive [[Nucleic acid sequence|nucleotide sequences]] at the end of [[chromosome]]s, which accelerates cell desctruction. Gerontogens can also accelerate the rate of [[Senescence|cellular senescence]], where normal diploid cells cease to divide. This can be measured using the body's levels of the protein [[p16]].&lt;ref name="MyUser_News.nationalgeographic.com_September_30_2015c"&gt;{{cite web |url=http://news.nationalgeographic.com/news/2014/05/140528-gerontogens-chemicals-toxins-environment-study-aging-science/ |title=Scientists Urge Study of Environmental Factors That May Speed Aging |newspaper=News.nationalgeographic.com |date=  |author= |accessdate= September 30, 2015}}&lt;/ref&gt;&lt;ref name="MyUser_Eurekalert.org_September_30_2015c"&gt;{{cite web |url=http://www.eurekalert.org/pub_releases/2014-05/cp-tit052014.php |title=Toxins in the environment might make you older than your years |newspaper=Eurekalert.org |date=  |author= |accessdate= September 30, 2015}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Ageing]]
[[Category:Toxicology]]


{{med-toxic-stub}}</text>
      <sha1>03qkwqzefuud999tnm7jjai6a9n18az</sha1>
    </revision>
  </page>
  <page>
    <title>Global South Development Magazine</title>
    <ns>0</ns>
    <id>33225681</id>
    <revision>
      <id>828010094</id>
      <parentid>827890523</parentid>
      <timestamp>2018-02-28T01:05:22Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>Fix [[:Category:Pages using deprecated image syntax]]; [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5653">{{Infobox newspaper
| title = Global South Development Magazine&lt;!--"Global South Development Magazine" per [[WP:MOSTM]]--&gt;
| logo = Global south development magazine Nov 2015.png
| logo_size = 290px
| image = &lt;!-- Deleted image removed: [[File:GSDM Jan 2011 little poster.jpg|170px|border]] --&gt;
| caption = The front cover of ''GSDM'' &lt;br /&gt;in January 2011, reporting on microfinance
| type = Quarterly
| format = Magazine
| foundation = 2009
| ceased publication = 
| political = 
| price = Free
| owners = Silcreation, Finland (2009-2017)
Global South Media Action (2018-)
| editor = [[Manoj Kr. Bhusal]]
| staff = More than 60 global volunteers
| circulation = 
| Language = English
| ISSN = 1799-0769
| website = {{URL|http://www.gsdmagazine.org/}}
}}

'''''Global South Development Magazine''''' ('''''GSDM''''') is an online magazine of international development issues. The magazine is inspired by the idea of citizen journalism and primarily covers developmental issues of [[developing countries]]. From 2010 to 2015, ''GSDM'' was a quarterly magazine published by a [[Finland|Finnish]] [[non-profit]] development media organisation [http://www.silcreation.org Silver Lining Creation ry]. As of 2018, the magazine is published by Helsinki-based media organization, Global South Media Action.

==History==
The first issue of the quarterly magazine was published in March 2010 dedicating its first cover issue to the Copenhagen Climate Change Summit.&lt;ref&gt;GSDM documents archive: http://www.silcreation.org/apps/documents/&lt;/ref&gt; Since then subsequent issues were published and were made available  online. On 11 September 2011, the magazine team was expanded with an Assistant Editor and a number of other [[special correspondents]]&lt;ref&gt;GSDM expands its team: http://www.silcreation.org/apps/blog/show/9033667-gsdm-expands-its-global-team-fenton-assistant-editor-new-special-correspondents-for-south-to-south-cooperation-development-aid-conflict-states-&lt;/ref&gt;  The magazine team claimed that within relatively short period of its inception, their publication had been received very well and still has an influential global readership. ''GSDM's'' distribution was free of charge. In 2012, the [[magazine]] launched a separate [http://gsdmagazine.org website] to archive its published articles and special reports.&lt;ref&gt;Global South Development Magazine: http://www.silcreation.org/globalsouthdevelopmentmag.htm&lt;/ref&gt; In 2013, ''GSDM'' introduced the concept of Development Reporters as an effort to encourage students of development studies and community activists to write about global development issues.&lt;ref&gt;http://gsdmagazine.org/developmentreporter/&lt;/ref&gt;

==The Team==
''Global South Development Magazine'' has been run by its [http://www.silcreation.org/globalteamgsdm.htm global editorial team] which by June 2012 consisted 40 professional volunteers from different parts of the world. The magazine has an executive editorial team, five regional editors, a group of special correspondents and numerous country reporters.&lt;ref&gt;Global South Development Magazine Global Editorial team: http://www.gsdmagazine.org/editorial-team/&lt;/ref&gt;

== Covered issues ==
[[Image:Global South Development Magazine April 2012.jpg|thumb|right|April 2012 issue of Global South Development Magazine featuring conflict in [[the Democratic Republic of the Congo]].]]

''GSDM'' has covered many issues that range from development aid to environmental sustainability. On its October 2011 edition, the magazine criticised [[Apple Inc.]] for their poor philanthropy records.&lt;ref&gt;Apple, Steve Jobs and the Developing World: http://www.manojbhusal.net/apps/blog/show/9447989-steve-jobs-apple-and-the-developing-world&lt;/ref&gt; The magazine's April 2012 edition was dedicated to [[the Democratic Republic of the Congo]] with an in-depth report on the humanitarian situation in the country.&lt;ref&gt;DRC Diary: Reflections from the field: http://gsdmagazine.org/2012/06/06/drc-diary-a-reflection-from-the-field/&lt;/ref&gt;

==Special correspondents==
As of April 2014, 10 special correspondents reported on 10 different development themes prioritised by the magazine.&lt;ref&gt;Global Team, GSDM: http://www.gsdmagazine.org/editorial-team/&lt;/ref&gt; Namely the themes were: 
*Women’s issues in Africa
*Global environmental issues
*Climate change
*Global Health
*Livelihood &amp; Global Economic Affairs
*Global Education
*Development Aid 
*Global Peace &amp; Security Issues 
*South-to-South Development Cooperation
*Development &amp; Democracy in Africa
*Food Sovereignty and Rural Livelihoods

==Environmental concerns==
Despite its "print-like" content and popularity, ''GSDM'', reportedly, is not planning to issue the magazine's paper version mostly due to their commitment to environmentally friendly activities and concerns.

&lt;!-- Deleted image removed: [[Image:Global South Development Magazine April 2015 cover.jpeg|thumb|right|April 2015 issue of Global South Development Magazine featuring [[South Sudan]].]] --&gt;

==See also==
* [[Global South]]
* [[Development journalism]]
* [[Developing countries]]
* [[Voluntarism (action)|Voluntarism]]

== References ==
{{Reflist}}

==External links==
* [http://www.gsdmagazine.org Official website]
* [http://www.gsdmagazine.org/editorial-team/ GSDM Global Team]
* [http://www.gsdmagazine.org GSDM featured articles]
* [http://www.gsdmagazine.org/category/editor/ Editor's blog]

[[Category:2009 establishments in Finland]]
[[Category:Development studies]]
[[Category:Free magazines]]
[[Category:Finnish magazines]]
[[Category:Magazines established in 2009]]
[[Category:Quarterly magazines]]
[[Category:Online magazines]]
[[Category:Environmental magazines]]</text>
      <sha1>7twx4y9su1z7xngo5e2hebw7jfv2hec</sha1>
    </revision>
  </page>
  <page>
    <title>Government Accountability Office</title>
    <ns>0</ns>
    <id>199096</id>
    <revision>
      <id>868842736</id>
      <parentid>868662770</parentid>
      <timestamp>2018-11-14T20:16:11Z</timestamp>
      <contributor>
        <username>PoliceSheep99</username>
        <id>33521564</id>
      </contributor>
      <comment>/* Core values */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27033">{{Redirect|GAO||Gao (disambiguation)}}
{{Use mdy dates|date=August 2015}}
{{advert section|date=November 2018}}
{{Infobox Government agency
|agency_name     = Government Accountability Office
|abbreviation    = GAO
|logo            = US-GovernmentAccountabilityOffice-Logo.svg
|logo_width      = 200px
|logo_caption    = Logo of the Government Accountability Office
|seal            = US-GovernmentAccountabilityOffice-Seal.svg
|seal_width      = 140px
|seal_caption    = Seal of the Government Accountability Office
|picture         = Flag of the United States General Accounting Office.svg
|picture_caption = Flag of the Government Accountability Office
|formed          = {{start date and age|1921|7|1}}
|date1           =
|date1_name      =
|date2           =
|date2_name      =
|preceding1      =
|preceding2      =
|dissolved       =
|superseding     =
|jurisdiction    =
|headquarters    = 441 G St., NW&lt;br&gt;Washington, D.C., U.S. 20548
|employees       = 3,350 (2010)
|budget          = $557 million (2011)
|chief1_name     = [[Eugene Louis Dodaro]]
|chief1_position = [[Comptroller General of the United States]]
|chief2_name     =
|chief2_position =
|parent_agency   =
|child1_agency   =
|child2_agency   =
|website         = [http://www.gao.gov gao.gov]
|footnotes       =Measurable benefits of GAO work total $49.9 billion, a return of $87 for every dollar invested; at the end of FY 2010, over 80% of the GAO recommendations made in FY 2006 had been implemented.&lt;ref&gt;{{cite web |url=http://www.gao.gov/about/gglance.html |title=GAO at a Glance |publisher=Government Accountability Office |accessdate=January 27, 2011}}&lt;/ref&gt;
}}
The '''Government Accountability Office''' ('''GAO''') is a [[legislative branch]]  government agency that provides [[audit]]ing, [[evaluation]], and investigative services for the [[United States Congress]].&lt;ref&gt;{{cite web|url=https://www.gao.gov/about/workforce/ocg.html|title=Office of the Comptroller General|publisher=United States Government Accountability Office}}&lt;/ref&gt; It is the [[supreme audit institution]] of the [[federal government of the United States]].

Mission of GAO is to:
* investigate how the federal government spends taxpayer dollars
* support the Congress in meeting its constitutional responsibilities
* help improve the performance
* ensure the accountability of the federal government for people
* provide Congress with timely information

==Core values==
{{advert section|date=July 2018}}
[[File:Gao core values chart.gif|thumb|GAO’s Core Values encompass mission values (Accountability, Integrity, Reliability) and people values (Valued, Respected, Treated Fairly)]]
* Accountability:  GAO helps the Congress oversee federal programs and operations to ensure accountability to the American people. GAO's analysts, auditors, lawyers, economists, information technology specialists, investigators, and other multidisciplinary professionals seek to enhance the economy, efficiency, effectiveness, and credibility of the federal government both in fact and in the eyes of the American people. GAO accomplishes its mission through a variety of activities, including financial audits, program reviews, investigations, legal support, and policy analyses.
* Integrity:  GAO takes a professional, objective, fact-based, nonpartisan, nonideological, fair, and balanced approach to all of its activities and sets high standards for itself and its work. Integrity is the foundation of reputation, and GAO's approach to its work assures both.
* Reliability:  GAO produces high quality reports, testimony, briefings, legal opinions, and other products and services that are timely, accurate, useful, clear, and candid.
* Valued:  GAO seeks out and appreciates each person’s perspectives by seeing everyone as an individual and tapping into everyone’s skills, talents, and life experiences.
* Respected:  GAO strives to treat everyone with dignity by listening, hearing, and acknowledging everyone’s viewpoints, keeping an open mind, and embracing differences.
* Treated Fairly:  GAO fosters a work environment that provides opportunities for all staff to excel by acting with honesty and integrity, treating all equitably, checking for bias, supporting equal access to opportunities, and trusting others to do their part.

==Powers of GAO==
Work of GAO is done at the request of congressional committees or subcommittees or is mandated by public laws or committee reports. It also undertakes research under the authority of the Comptroller General. It supports congressional oversight by:
* auditing agency operations to determine whether federal funds are being spent efficiently and effectively;
* investigating allegations of illegal and improper activities;
* reporting on how well government programs and policies are meeting their objectives;
* performing policy analyses and outlining options for congressional consideration;
* issuing legal decisions and opinions;
* advising Congress and the heads of executive agencies about ways to make government more efficient and effective.

==Products of GAO==
[[File:LocalGao.png|thumb|GAO local offices]]

Products of GAO includes the following:
* reports and written correspondence;
* testimonies and statements for the record, where the former are delivered orally by one or more of GAO senior executives at a congressional hearing and the latter are provided for inclusion in the congressional record;
* briefings, which are usually given directly to congressional staff members;
* legal decisions and opinions resolving bid protests and addressing issues of appropriations law as well as opinions on the scope and excrcise of authority of federal officers.
GAO also produce special publications on specific issues of general interest to many Americans, such as its report on the fiscal future of the United States, GAO’s role in the federal bid protest process, and critical issues for congressional consideration related to improving the nation's image abroad.

==History==
The GAO was established as the '''General Accounting Office''' by the [[Budget and Accounting Act]] of 1921. The act required the head of the GAO to "investigate, at the seat of government or elsewhere, all matters relating to the receipt, disbursement, and application of public funds, and shall make to the President ... and to Congress ... reports [and] recommendations looking to greater economy or efficiency in public expenditures".&lt;ref&gt;[[Budget and Accounting Act of 1921]], Sec. 312(a), {{USStat|42|25}}&lt;/ref&gt; According to the GAO's current mission statement, the agency exists to support the Congress in meeting its [[United States Constitution|constitutional]] responsibilities and to help improve the [[performance]] and ensure the [[accountability]] of the federal government for the benefit of the American people.

The name was changed in 2004 to Government Accountability Office by the [[GAO Human Capital Reform Act]] to better reflect the mission of the office.&lt;ref&gt;{{cite news|title=GAO Answers the Question: What’s in a Name?|last=Walker|first=David M.|authorlink=David M. Walker (U.S. Comptroller General)|date=July 19, 2004|work=[[Roll Call]]|url=http://www.gao.gov/about/rollcall07192004.pdf}}&lt;/ref&gt;&lt;ref&gt;Section 8, GAO Human Capital Reform Act of 2004, Pub. L. No. 108-271, 118 Stat. 811, 814 (July 7, 2004).&lt;/ref&gt; While most other countries have government entities similar to the GAO, their focus (with the exceptions of the [[Taiwan]]ese [[Control Yuan]] and the [[Israel]]i [[State Comptroller of Israel|State Comptroller]]) is primarily on conducting financial audits.{{Citation needed|date=September 2015}} The GAO's auditors conduct not only financial audits, but also engage in a wide assortment of performance audits.

Over the years, the GAO has been referred to as "The Congressional Watchdog" and "The Taxpayers' Best Friend" for its frequent audits and investigative reports that have uncovered waste and inefficiency in government. News media often draw attention to the GAO's work by publishing stories on the findings, conclusions and recommendations of its reports. Members of Congress also frequently cite the GAO's work in statements to the press, congressional hearings, and floor debates on proposed legislation.  In 2007 the Partnership for Public Service ranked the GAO second on its list of the best places to work in the federal government and [[Washingtonian (magazine)|''Washingtonian'']] magazine included the GAO on its 2007 list of great places to work in Washington, a list that encompasses the public, private, and non-profit sectors.

The GAO is headed by the [[Comptroller General of the United States|comptroller general of the U.S.]], a professional and non-partisan position in the U.S. government.  The comptroller general is appointed by the [[President of the United States|president]], by and with the [[advice and consent#United States|advice and consent]] of the [[United States Senate|Senate]], for a 15-year, non-renewable term.  The president selects a nominee from a list of at least three individuals recommended by an eight-member bipartisan, bicameral commission of congressional leaders. During such term, the comptroller general has standing to pursue litigation to compel access to federal agency information. The comptroller general may not be removed by the president, but only by Congress through impeachment or joint resolution for specific reasons.&lt;ref&gt;''See [[Bowsher v. Synar]]'', 478 U.S. 714 (1986)&lt;/ref&gt;  Since 1921, there have been only seven comptrollers general, and no formal attempt has ever been made to remove a comptroller general.

Labor-management relations became fractious during the 9-year tenure of the 7th comptroller general, [[David M. Walker (U.S. Comptroller General)|David M. Walker]].  On September 19, 2007, GAO analysts voted by a margin of two to one (897–445), in a 75% turnout, to establish the first union in the GAO's 86-year history.  The analysts voted to affiliate with the [[International Federation of Professional and Technical Engineers]] (IFPTE), a member union of the [[AFL-CIO]]. There are more than 1,800 analysts in the GAO analysts bargaining unit; the local voted to name itself IFPTE Local 1921, in honor of the date of the GAO's establishment. On February 14, 2008, the GAO analysts' union approved its first-ever negotiated pay contract with management; of just over 1,200 votes, 98 percent were in favor of the contract.

[[Image:US-GeneralAccountingOffice-Seal.svg|thumb|140px|Seal of the General Accounting Office, from 1921 until being renamed in 2004.]]
The GAO also establishes standards for audits of government organizations, programs, activities, and functions, and of government assistance received by contractors, nonprofit organizations, and other nongovernmental organizations. These standards, often referred to as [[Government Auditing Standards (Yellow Book)|Generally Accepted Government Auditing Standards]] (GAGAS), are to be followed by auditors and audit organizations when required by law, regulation, agreement, contract, or policy. These standards pertain to auditors' professional qualifications, the quality of audit effort, and the characteristics of professional and meaningful audit reports.

In 1992 the GAO hosted XIV [[International Congress of Supreme Audit Institutions|INCOSAI]], the fourteenth triennial convention of the [[International Organization of Supreme Audit Institutions]] (INTOSAI).&lt;ref&gt;{{citation
 | title = [[:File:INTOSAI 50 Years.pdf|INTOSAI: 50 Years (1953-2003)]]
 | publisher = [[International Organization of Supreme Audit Institutions]]
 | year = 2004
 | location = [[Vienna, Austria|Vienna]]
 | page = 67}}&lt;/ref&gt;

==Reports==
[[File:General Accounting Office Building.jpg|thumb|right|[[US General Accounting Office Building|GAO headquarters]] in [[Washington, D.C.]]]]
GAO is a United States government electronic data provider, as all of its reports are available on its [http://www.gao.gov/browse/date/week website], except for certain reports whose distribution is limited to official use in order to protect national and homeland security.{{Citation needed|date=March 2014}} The variety of topics reported on range from Federal Budget and Fiscal Issues to Financial Management, Education, Retirement Issues, Defense, Homeland Security, Administration of Justice, Health Care, Information Management and Technology, Natural Resources, Environment, International Affairs, Trade, Financial Markets, Housing, Government Management and Human Capital. GAO often produces highlights of its reports that serve as a [[Congressional Record#Overview|statement for the record]] for various subcommittees of the United States Congress.

Most GAO studies and reports are initiated by requests from members of Congress, including requests mandated in statute, and so reflect concerns of current political import, for example to study the impact of a government-wide hiring freeze.&lt;ref name="GAO_1982"&gt;{{cite report |author=[[Comptroller General of the United States]] |accessdate=January 24, 2017 |url=http://www.gao.gov/assets/140/137055.pdf |format=PDF |title=Recent Government-Wide Hiring Freeze Prove Ineffective In Managing Federal Employment  |number=FPCD-82-21 |date=March 10, 1982 |publisher=Government Accountability Office (GOA)}} requested sent to  [[Charles A. Bowsher]] by [[Geraldine A. Ferraro]] Chairwoman, Subcommittee on Human Resources Committee on Post Office and Civil Service House of Representatives&lt;/ref&gt; Many reports are issued periodically and take a long view of U.S. agencies' operations.{{Citation needed|date=July 2007}} GAO also produces [http://www.gao.gov/key_issues/overview#t=3 annual reports on key issues] such as [http://www.gao.gov/duplication/overview#t=0 Duplication and Cost savings] and [http://www.gao.gov/highrisk/overview High-Risk Update].

The GAO prepares some 900 reports annually. GAO publishes reports and information relating to, [[Inter alia#inter alia|''inter alia'']]:

===Financial Statements of the U.S. government===
Each year the GAO issues an audit report on the financial statements of the United States Government. The '''2010 Financial Report of the United States Government''' was released on December 21, 2010.&lt;ref name="GaO 2010"&gt;{{cite web |url=http://www.gao.gov/press/financial_report_2010dec21.html |title=Press Release |publisher=US Government Accountability Office |accessdate=January 8, 2011}}&lt;/ref&gt; The accompanying press release states that the GAO 'cannot render an [[audit opinion|opinion]] on the [[2010 United States federal budget|2010 consolidated financial statements of the federal government]], because of widespread [[materiality (auditing)|material]] internal control weaknesses, significant uncertainties, and other limitations'.&lt;ref name="GaO 2010"/&gt;

===U.S. Public Debt===
As part of its initiative to advocate [[sustainability]], the GAO publishes a Federal Fiscal Outlook Report,&lt;ref&gt;{{cite web |url=http://www.gao.gov/special.pubs/longterm/fed/recent.html |title=Most Recent Federal Fiscal Outlook Report |publisher=Government Accountability Office |accessdate=January 27, 2011}}&lt;/ref&gt; as well as data relating to the [[US public debt|deficit]].&lt;ref name="deficit"&gt;{{cite web |url=http://www.gao.gov/special.pubs/longterm/deficit/ |title=Measuring the Deficit: Cash vs. Accrual |publisher=Government Accountability Office |accessdate=January 19, 2011}}&lt;/ref&gt; The US deficit is presented on a [[Comparison of Cash Method and Accrual Method of accounting|cash]] rather than [[accruals]] basis, although the GAO notes that the accrual deficit 'provides more information on the longer-term implications of the government's annual operations'.&lt;ref name="deficit"/&gt;
In [[Fiscal year|FY]] 2010, the [[Federal government of the United States|US federal government]] had a net operating cost of $2,080 billion, although since this includes accounting [[Provision (accounting)|provisions]] (estimates of future liabilities), the cash deficit is $1,294 billion.&lt;ref&gt;{{cite web |url=http://www.gao.gov/financial/fy2010/10frusg.pdf |title=2010 Financial Report of the United States Government (''vid.'' pp.v, 43) |publisher=Government Accountability Office |accessdate=January 7, 2011}}&lt;/ref&gt;

===Quinquennial Strategic Plan===
The most recent GAO plan, for 2010-2015, sets out four goals, namely to address: (1) Current and Emerging Challenges to the Well-being and Financial Security of the American People; (2) Changing Security Threats and the Challenges of Global Interdependence; (3) Transformation of the Federal Government to Address National Challenges; (4) Maximization of the Value of the GAO.&lt;ref&gt;{{cite web |url=http://www.gao.gov/new.items/d10559sp.pdf |title=Strategic Plan: Serving the Congress and the Nation, 2010 –2015 |publisher=Government Accountability Office |accessdate=January 27, 2011}}&lt;/ref&gt;

Forensic Audits and Investigative Service (FAIS)

The Forensic Audits and Investigative Service (FAIS) team provides Congress with high-quality forensic audits and investigations of fraud, waste, and abuse; other special investigations; and security and vulnerability assessments. Its work cuts across a diverse array of government programs administered by IRS, the Centers for Medicare and Medicaid Services, the Department of Veterans Affairs, and the Department of Homeland Security, among others.

==GAO and Technology Assessment==

After the closing of the Office of Technology Assessment (OTA) in 1995, Congress directed GAO to conduct a [[technology assessment]] (TA) pilot program. Between 2002 and 2006, four reports were completed– use of biometrics for border security, cyber security for [[critical infrastructure protection]], technologies for protecting structures in wildland fires, and cargo container security technologies. In the first report, GAO found that while biometrics technologies could be used to secure the border, they had limitations in fingerprinting and facial recognition systems. An immediate impact of the report was a congressional testimony on the use of biometrics which, in turn, helped to inform U.S. national security reform efforts. GAO reports, which are made available to the public, have become essential vehicles for understanding science and technology (S&amp;T) implications of policies considered by the Congress.

Since 2007, Congress has established a permanent TA function within GAO. This new operational role augments GAO’s performance audits related to S&amp;T issues, including effectiveness and efficiency of U.S. federal programs. In 2010, GAO joined [[European Parliamentary Technology Assessment]] (EPTA) as an associate member. In the last three years, GAO has completed TA reports on three topics, the most recent one being released in 2011 – rail security, climate engineering, and alternate neutron detectors. In the climate engineering report, Congress requested GAO to examine three areas: the current S&amp;T state of climate engineering, views of experts on the future of climate engineering research, and potential public responses to climate engineering. When the GAO receives a request to conduct TA, it follows five phases: Acceptance, Planning, Data Gathering and Analysis, Product development and Distribution and Results. Phases one and two include selecting the topic and initiating the TA plan while the other ones are respectively: conducting TA, followed by developing the report and ensuring its accuracy and integrity, and finally receiving feedback from Congress and developing lessons learned to enhance the TA process.

The GAO describes the TA as providing "thorough and balanced analysis of critical technological innovations that affect our society, the environment, and the economy" explaining "the consequences that each featured technology will have on federal agencies and departments, and their wider impacts on American society".&lt;ref&gt;[http://www.gao.gov/technology_assessment U.S. GAO - Technology Assessment]. Gao.gov. Retrieved on July 19, 2013.&lt;/ref&gt; This broad working definition enables GAO analysts to utilize TA as a tool for policy analysis. Technology assessments at GAO are conducted in accordance with GAO’s quality assurance framework.  GAO initiates technology assessments through congressional mandates, requests from congressional leaders, and through the authority of U.S. Comptroller General.

The Technology Assessment section of GAO's website &lt;ref&gt;[http://www.gao.gov/technology_assessment GAO-TA]&lt;/ref&gt; offers the latest TA reports and videos.

==Protocols==
* USDA Should Take Further Action to Reduce Pathogens in Meat and Poultry Products. Why GAO Did This StudyThe U.S. food supply is generally considered safe, but the Centers for Disease Control and Prevention (CDC) estimate that Salmonella and Campylobacter in food cause about 2 million human illnesses per year in the United States. GAO was asked to review USDA’s approach to reducing pathogens in meat and poultry products. This report examines (1) the extent to which USDA has developed standards for meat and poultry products and (2) any additional steps USDA has taken to address challenges GAO identified in 2014. GAO reviewed relevant regulations, documents, and data and interviewed officials from USDA and CDC, as well as 17 stakeholders representing industry, consumer groups, and researchers selected based on their knowledge of USDA’s meat and poultry slaughter inspections and food safety.What GAO RecommendsGAO is making three recommendations, including that USDA document its process for deciding which products to consider for new standards and that it include information on the effectiveness of on-farm practices in its guidelines for Salmonella control in hogs. USDA agreed with GAO's recommendations and described actions it will take to implement them.
* CRITICAL INFRASTRUCTURE PROTECTION Additional Actions Are Essential for Assessing Cybersecurity Framework Adoption. Why GAO Did This Study Our nation’s critical infrastructure includes the public and private systems and assets vital to national security, economic stability, and public health and safety. Federal policy identifies 16 critical infrastructure sectors, including the financial services, energy, transportation, and communications sectors. To better address cyber- related risks to critical infrastructure, in 2014, NIST developed, as called for by federal law and policy, the Framework for Improving Critical Infrastructure Cybersecurity, a voluntary framework of cybersecurity standards and procedures for industry to adopt.The Cybersecurity Enhancement Act of 2014 included provisions for GAO to review aspects of the cybersecurity standards and procedures in the framework developed by NIST. GAO’s objective was to assess what is known about the extent to which critical infrastructure sectors have adopted the framework. To do so, GAO analyzed documentation, such as sector-specific guidance and tools to facilitate implementation, and interviewed relevant federal and nonfederal officials from the 16 critical infrastructure sectors.What GAO RecommendsGAO is making nine recommendations that methods be developed for determining framework adoption by the sector-specific agencies across their respective sectors, in consultation with their respective sector partner(s), such as the sector coordinating councils, the Department of Homeland Security, and NIST, as appropriate. Five agencies agreed with the recommendations, while four others neither agreed nor disagreed.
* Homeland defenceurgent Need for DOD and FAA to Address Risks and Improve Planning for Technology That Tracks Military Aircraft. Why GAO Did This StudyDOD has until January 1, 2020, to equip its aircraft with ADS-B Out technology that would provide DOD, FAA, and private citizens the ability to track their flights in real-time and track flight patterns over time. This technology is a component of NextGen, a broader FAA initiative that seeks to modernize the current radar- driven, ground-based air transportation system into a satellite-driven space- based system.What GAO RecommendsGAO is recommending that DOD and FAA approve one or more solutions to address ADS-B -related security risks; and that DOD implement key tasks to facilitate consistent, long-term planning and implementation of NextGen. DOD and the Department of Transportation generally concurred and described planned actions to implement the recommendations.

==See also==
{{div col|colwidth=30em}}
* [[Title 4 of the Code of Federal Regulations]]

;Offices
* [[Comptroller and Auditor General]]
* [[Comptroller]]
* [[Inspector General]]
* [[Comptroller General of the United States|Auditor general]]
* [[Director of audit]]
* [[Treasurer]]
* [[Corporate title]]

;Non-governmental organizations ([[Non-governmental organizations|NGOs]])
* [[Government Accountability Project]]
* [[Project On Government Oversight]]

;Audit
* [[Auditor independence]]
* [[Negative assurance]]
* [[Positive assurance]]

;International
* [[Australia]]: [[Australian National Audit Office]]
* [[Brazil]]: [[Tribunal de Contas da União|Court of Accounts of the Union]]
* [[Botswana]]: Office of the Auditor General Botswana&lt;ref&gt;[http://www.oag.org.bw OAG.org.bw] {{webarchive|url=https://web.archive.org/web/20110706162807/http://www.oag.org.bw/ |date=July 6, 2011 }}&lt;/ref&gt;
* [[Canada]]: [[Auditor General of Canada]]
* [[European Union]]: [[Court of Auditors]]
* [[Hong Kong]]: [[Director of Audit (Hong Kong)|Director of Audit of Hong Kong]]
* [[India]]: [[Comptroller and Auditor General of India]]
* [[Mexico]]: Auditoría Superior de la Federación&lt;ref&gt;[http://www.asf.gob.mx Auditoria Superior de la Federación]. ASF. Retrieved on July 19, 2013.&lt;/ref&gt;
* [[Philippines]]: [[Commission on Audit (Philippines)|Commission on Audit]]&lt;ref&gt;[http://coa.gov.ph/ COA.gov.ph/]&lt;/ref&gt;
* [[Republic of China]] ([[Taiwan]]): [[Control Yuan]]
* [[United Kingdom]]: [[National Audit Office (United Kingdom)|National Audit Office]]
{{div col end}}

==References==
{{reflist|30em}}
* {{cite book|last1=United States Congress. Senate Committee on Homeland Security and Governmental Affairs|title=Government Accountability Office Improvement Act|date=December 17, 2013|publisher=Washington, D.C. : U.S. Government Printing Office, 2013.|pages=113–128}} Retrieved on September 28, 2015

==External links==
{{Commons category}}
* [http://www.gao.gov/ GAO homepage]
* [http://www.gao.gov/about/namechange.html GAO name change]
* [https://web.archive.org/web/20151121082115/http://fas.org/document.htm General Accounting Office Reports], on the website of the [[Federation of American Scientists]]

{{USCongress}}

[[Category:Government agencies established in 1921]]
[[Category:Open government in the United States]]
[[Category:Government audit]]
[[Category:Government Accountability Office| ]]
[[Category:Technology assessment]]
[[Category:Agencies of the United States Congress]]
[[Category:1921 establishments in Washington, D.C.]]
[[Category:Auditing in the United States]]</text>
      <sha1>45ppr8mil1xodtzr3mickk30b4cvu5q</sha1>
    </revision>
  </page>
  <page>
    <title>Grave goods</title>
    <ns>0</ns>
    <id>723048</id>
    <revision>
      <id>850658012</id>
      <parentid>824015445</parentid>
      <timestamp>2018-07-17T07:30:35Z</timestamp>
      <contributor>
        <username>Chiswick Chap</username>
        <id>2666701</id>
      </contributor>
      <comment>/* Famous grave sites */ img of 5th dynasty bread</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8434">{{refimprove|date=February 2008}}
[[Image:Tutanchamon (js) 3.jpg|thumb|The [[gilding|gilded]] [[throne]] of [[Pharaoh]] [[Tutankhamun]] is but one of the treasures found within his tomb.]]
'''Grave goods''', in [[archaeology]] and [[anthropology]], are the items buried along with the body.

They are usually personal possessions, supplies to smooth the deceased's journey into the afterlife or offerings to the gods. Grave goods may be classed as a type of [[votive deposit]]. Most grave goods recovered by archaeologists consist of inorganic objects such as pottery and stone and metal tools but organic objects that have since decayed were also placed in ancient tombs.&lt;ref&gt;[[Ian Morris (historian)|Ian Morris]], ''Death-Ritual and Social Structure in Classical Antiquity'' (Cambridge, 1992; {{ISBN|0-521-37611-4}})&lt;/ref&gt;   [[Funerary art]] is a broad term but generally means artworks made specifically to decorate a burial place, such as miniature models of possessions including slaves or servants for "use" in the afterlife.

Where grave goods appear, [[grave robbery]] is a potential problem.  [[Etruscans]] would scratch the word ''śuθina'', [[Etruscan language|Etruscan]] for "from a tomb", on grave goods buried with the dead to discourage their reuse by the living.&lt;ref&gt;[[Giuliano Bonfante]] and [[Larissa Bonfante]] ''The Etruscan Language: an Introduction'' (Univ. Manchester Press, 2002. {{ISBN|0-7190-5540-7}}); several examples collected&lt;/ref&gt;  The tomb of [[pharaoh]] [[Tutankhamun]] is famous  because it was one of the few [[Egyptian tombs]] that was not thoroughly looted in ancient times.

Grave goods can be regarded as a [[sacrifice]] intended for the benefit of the deceased in the [[afterlife]]. Closely related are customs of [[ancestor worship]] and offerings to the dead, in modern western culture related to [[All Souls' Day]] ([[Day of the Dead]]), in East Asia the  "[[hell bank note]]" and related customs.
Also closely related is the custom of [[retainer sacrifice]], where servants or wives of a deceased chieftain are interred with the body.
As the inclusion of expensive grave goods and of slaves or retainers became a sign of high status in the [[Bronze Age]], the prohibitive cost led to the development of "fake" grave goods, where artwork meant to ''depict'' grave goods or retainers is produced for the burial and deposited in the grave in place of the actual sacrifice.

==History==

[[File:Urnenbestattung HH-Marmstorf Grab 216 Modell.jpg|thumb|150px|Warrior's burial from Hamburg-Marmstorf Grave]]
There are disputed claims of [[Paleolithic burial|intentional burial]] of [[Neanderthal]]s as old as 130,000 years. Similar claims have been made for early [[anatomically modern humans]] as old as 100,000 years. The earliest undisputed cases of burials are found in modern human sites of the Upper Palaeolithic.

Beads made of [[basalt]] deposited in graves in the [[Fertile Crescent]]
date to the end of the [[Upper Paleolithic]], beginning in about the 12th to 11th millennium BC.&lt;ref&gt;The Earliest Beads, muma.org{{Clarify|date=October 2011}}&lt;/ref&gt;

The distribution of grave goods are a potential indicator of the [[social stratification]] of a society. Thus, early [[Neolithic]] graves tend to show equal distribution of goods, suggesting a more or less [[classless society]], while in [[Chalcolithic]] and [[Bronze Age]] burials, rich grave goods are concentrated in "[[chieftain]]" graves ([[Tumulus|barrows]]), indicating social stratification.&lt;ref&gt;see e.g. William A. Haviland, Harald E. L. Prins, Dana Walrath, Bunny McBride, ''Anthropology: The Human Challenge, Cengage Learning, 2010 {{ISBN|978-0-495-81084-1}}, p. 268.&lt;/ref&gt; It is also possible that burial goods indicate a level of concern and consciousness in regard to an [[afterlife]] and related sense of [[spirituality]].

==Famous grave sites==
[[File:Conical loaves of bread, Gebelein, 5th Dynasty c 2400 BC.jpg|thumb|left|[[History of bread|Conical loaves of bread]] as grave goods exactly as laid out in the Great Tomb, North Necropolis, [[Gebelein]], [[5th Dynasty]] (Old Kingdom), 2435-2305 BC. Excavations by [[Ernesto Schiaparelli]], 1911. Egyptian Museum, Turin, S. 14051-14055]]

The expression of social status in rich graves is taken to extremes in the royal graves of the Bronze Age. In the [[Theban Necropolis]] in [[Ancient Egypt]], the [[pyramids]] and the royal graves in the [[Valley of the Kings]] are among the most elaborate burials in human history. This trend is continued into the [[Iron Age]]. An example of an extremely rich royal grave of the Iron Age is the [[Terracotta Army]] of [[Qin Shi Huang]].{{Citation needed|date = March 2017}}

In the sphere of the [[Roman Empire]], [[early Christianity|early Christian]] graves lack grave goods, and grave goods tend to disappear with the [[decline of Greco-Roman polytheism]] in the 5th and 6th centuries. Similarly, the presence of grave goods in the [[Early Middle Ages]] in Europe has often been taken as evidence of [[paganism]], although during the period of conversion in [[Anglo-Saxon England]] and the [[Frankish Empire]] (7th century), the situation may be more complicated.&lt;ref&gt;Helen Geake, ''The use of grave-goods in conversion-period England, c.600-c.850'', British Archaeological Reports, 1997, {{ISBN|978-0-86054-917-8}}&lt;/ref&gt;
In the Christian Middle Ages, high-status graves are marked on the exterior, with [[tomb effigy|tomb effigies]] or expensive tomb stones rather than by the presence of grave goods.{{Citation needed|date = March 2017}}

The practice of placing grave goods with the dead body has thus an uninterrupted history beginning in the [[Upper Paleolithic]], if not the [[Middle Paleolithic]], upheld until comparatively recent times, in many regions of the world ceasing only with [[Christianization]].{{Citation needed|date = March 2017}}

==Role in archaeology==
[[File:Copper age grave group stone wristguard copper dagger bone belt fitting sittingbourne british museum.JPG|thumb|right|A [[Copper Age]] grave group including a stone wristguard, copper dagger and bone belt fitting found at [[Sittingbourne]]]]
The importance of grave goods, from the simple behavioural and technical to the metaphysical,  in [[archaeology]] cannot be overestimated.
Because of their almost ubiquitous presence throughout the world and throughout prehistory, in many cases the excavation of every-day items placed in burials is the main source of such artifacts in a given prehistoric culture. 
However, care must be taken to avoid naive interpretation of grave goods as an objective sample of artifacts in use in a culture. Because of their ritual context, grave goods may represent a special class of artifacts, in some instances produced especially for burial. 
Artwork produced for the burial itself is known as [[funerary art]], while grave goods in the narrow sense are items produced for actual use that are placed in the grave, but in practice the two categories overlap.

Grave goods in Bronze Age and Iron Age cemeteries are a good indicator of relative [[social status]]; 
in a 2001 study on an [[Iron Age Italy|Iron Age]] cemetery in [[Pontecagnano Faiano]], Italy, a correlation was found between the quality of grave goods and  [[Forensic science|Forensic]] indicators on the skeletons, showing that skeletons in wealthy tombs tended to show substantially less evidence of biological stress during adulthood, with fewer broken bones or signs of hard labor.&lt;ref&gt;{{cite journal |first=John |last=Robb |first2=Renzo |last2=Bigazzi |first3=Luca |last3=Lazzarini |first4=Caterina |last4=Scarsini |first5=Fiorenza |last5=Sonego |title=Social status and biological status: A comparison of grave goods and skeletal indicators from Pontecagnano |journal=[[American Journal of Physical Anthropology]] |volume=115 |issue=3 |pages=213–222 |year=2001 |doi=10.1002/ajpa.1076 }}&lt;/ref&gt;

==See also==
*[[Burial]]
*[[Grave field]]
*[[Necropolis]]
*''[[Mingqi]]'', the traditional Chinese burial goods

== References ==
{{Reflist}}

==External links==
*[http://www.mama.org/exhibits/ancient/ ''The Earliest Beads'', Treasures From the Ancient World, Museum of Ancient and Modern Art, at muma.org]

{{Prehistoric technology|state=expanded}}

{{Authority control}}

{{DEFAULTSORT:Grave Goods}}
[[Category:Archaeological artefact types]]
[[Category:Anthropology]]
[[Category:Death customs]]
[[Category:Sacrifice]]
[[Category:Afterlife]]</text>
      <sha1>4f7ffl75ozj76tj7y0oqi5r0k6feecc</sha1>
    </revision>
  </page>
  <page>
    <title>Haskins Laboratories</title>
    <ns>0</ns>
    <id>6202324</id>
    <revision>
      <id>855319044</id>
      <parentid>838168660</parentid>
      <timestamp>2018-08-17T12:47:48Z</timestamp>
      <contributor>
        <username>Certes</username>
        <id>5984052</id>
      </contributor>
      <minor/>
      <comment>Fix links to [[President]] (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23394">{{External links|date=February 2014}}

{{Infobox non-profit
| name            = Haskins Laboratories
| image           = HaskinsLabs.jpg
| caption         = Haskins Laboratories
| type            = Non-profit Organization
| purpose         = 
| tax_id          = 13-1628174
| registration_id =
| founded_date    = 1935
| founder         = [[Caryl Haskins]]&lt;br /&gt; [[Franklin S. Cooper]]
| dissolved       = &lt;!-- {{End date|YYYY|MM|DD}} --&gt;
| location        = 300 George St #900, [[New Haven, Connecticut]] 06511
| coordinates     = &lt;!-- {{Coord|LAT|LON|display=inline,title}} --&gt;
| origins         = 
| key_people      = [[Kenneth Pugh]], [[President (corporate title)|President]] &lt;br /&gt; [[Douglas Whalen]], [[VP]]&lt;br /&gt; [[Vincent Gracco]], [[VP]]&lt;br /&gt;[[Joseph Cardone]], [[CFO]] &lt;br /&gt; [[Carol Fowler]], [[Senior Advisor]]&lt;br /&gt; [[Philip Rubin]], [[Senior Advisor]]
| area_served     = 
| products        = Research and Analysis
| services        =
| focus           = [[Speech]], [[Language]], [[Literacy]], [[Education]]
| mission         = 
| method          = 
| revenue         = $7,009,532 (2015) [http://www.guidestar.org/profile/13-1628174]
| disbursed       =  
| expenses        = $7,253,369 (2015) [http://www.guidestar.org/profile/13-1628174]
| endowment       = 
| num_volunteers  = 
| num_employees   = 96 (2015) [http://www.guidestar.org/profile/13-1628174]
| num_members     = 
| subsid          = 
| owner           = 
| motto           = 
| former name     =
| homepage        = {{URL|www.haskinslabs.org}}
| footnotes       = 
}}

'''Haskins Laboratories'''&lt;ref&gt;http://www.haskins.yale.edu&lt;/ref&gt; is an independent [[501(c) organization|501(c) non-profit corporation]], founded in 1935 and located in [[New Haven, Connecticut]], since 1970. It is a [[interdisciplinary|multidisciplinary]] and international community of researchers which conducts basic [[research]] on [[Speech communication|spoken]] and [[reading (activity)|written]] [[language]]. A guiding perspective of their research is to view speech and language as biological processes. The Laboratories has a long history of [[technology|technological]] and [[theory|theoretical]] innovation, from creating the rules for [[speech synthesis]] and the first working prototype of a [[reading machine]] for the [[blindness|blind]] to developing the landmark concept of [[phonemic awareness]] as the critical preparation for learning to read.

==Research tools and facilities==
Haskins Laboratories is equipped, in-house, with a comprehensive suite of tools and capabilities to advance its mission of research into language and literacy. These include (as of 2014):
* [[Anechoic chamber]]
* [[Electroencephalography]]
** [http://www.biosemi.com/ BioSemi] 264 electrode, 24 bit [http://www.biosemi.com/products.htm Active Two System]
** [http://www.egi.com/ EGI] 128 electrode, [http://www.egi.com/research-division-research-products/eeg-systems Geodesic EEG System 300]
* [[Electromagnetic articulography]] (EMMA)
** [http://www.articulograph.de/?page_id=711 Carstens AG501]
** NDI WAVE 
* [[Eye Tracking]]: HL is equipped with 3 [http://www.sr-research.com/ SR Research] eye-trackers.
** 2 Model [http://www.sr-research.com/EL_1000.html Eyelink 1000] systems.
** 1 Model [http://www.sr-research.com/eyelink1000plus.html Eyelink 1000plus] system.
* [[Magnetic Resonance Imaging]]: Haskins has access to MRI scanners through agreements with the [[University of Connecticut]] and the [[Yale School of Medicine]]. On-site, HL has a [[GNU]]-Linux computer cluster dedicated to analysis of MRI data.
* [[Motion Capture]]: HL is equipped with a [http://www.vicon.com/ Vicon] motion capture system with one Basler high-speed digital camera, six Vicon MX T-20 cameras and a Vicon MX Giganet for synching camera data and connecting cameras to the data capture computer.
* [[Near Infrared Spectroscopy]]: HL has a [http://www.nirsoptix.com TechEn] CW6 8x8 system (four emitters; eight detectors). 
* [[Medical ultrasonography|Ultrasound sonogram]]

==History==
Scores of researchers have contributed to scientific breakthroughs at Haskins Laboratories since its founding. All of them are indebted to the pioneering work and leadership of [[Caryl Parker Haskins]], [[Franklin S. Cooper]], [[Alvin Liberman]], [[Seymour Hutner]] and [[Luigi Provasoli]]. This history focuses on the research program of the main division of Haskins Laboratories that, since the 1940s, has been most well known for its work in the areas of speech, language and reading.&lt;ref&gt;[http://www.haskins.yale.edu/sciencespoken.html Haskins Laboratories, ''The Science of the Spoken and Written Word''.]&lt;/ref&gt;

===1930s===
[[Caryl Haskins]] and [[Franklin S. Cooper]] established Haskins Laboratories in 1935. It was originally affiliated with [[Harvard University]], [[MIT]], and [[Union College]] in Schenectady, NY. Caryl Haskins conducted research in [[microbiology]], [[radiation]] [[physics]], and other fields in Cambridge, MA and Schenectady. In 1939 the Laboratories moved its center to [[New York City]]. Seymour Hutner joined the staff to set up a research program in [[microbiology]], [[genetics]], and [[nutrition]]. The descendant of this program [http://appserv.pace.edu/execute/page.cfm?doc_id=18327] is now part of [[Pace University]] in New York.

===1940s===
The U. S. [[Office of Scientific Research and Development]], under [[Vannevar Bush]] asked Haskins Laboratories to evaluate and develop technologies for assisting blinded [[World War II]] veterans. Experimental psychologist [[Alvin Liberman]] joined the Laboratories to assist in developing a "sound alphabet" to represent the letters in a text for use in a reading machine for the blind. Luigi Provasoli joined the Laboratories to set up a research program in [[marine biology]]. The program in marine biology moved to [[Yale University]] in 1970 and disbanded with Provasoli's retirement in 1978.

===1950s===
[[Franklin S. Cooper]] invented the [[pattern playback]][http://cobweb.ecn.purdue.edu/~malcolm/interval/1994-036/][http://www.haskins.yale.edu/featured/patplay.html], a machine that converts pictures of the acoustic patterns of speech back into sound. With this device, [[Alvin Liberman]], Cooper, and Pierre Delattre (and later joined by [[Katherine Safford Harris]], [[Leigh Lisker]], Arthur Abramson,  and others), discovered the acoustic cues for the perception of phonetic segments (consonants and vowels). Liberman and colleagues proposed a [[motor theory of speech perception]] to resolve the acoustic complexity: they hypothesized that we perceive speech by tapping into a biological specialization, a speech module, that contains knowledge of the acoustic consequences of articulation. Liberman, aided by Frances Ingemann [http://linguistlist.org/people/personal/get-personal-page2.cfm?PersonID=4996] and others, organized the results of the work on speech cues into a groundbreaking set of rules for [[speech synthesis]] by the Pattern Playback [http://www.haskins.yale.edu/featured/patplay.html].

===1960s===
[[Franklin S. Cooper]] and [[Katherine Safford Harris]], working with Peter MacNeilage, were the first researchers in the U.S. to use [[electromyography|electromyographic]] techniques, pioneered at the [[University of Tokyo]], to study the neuromuscular organization of speech. [[Leigh Lisker]] and [[Arthur S. Abramson|Arthur Abramson]] looked for simplification at the level of articulatory action in the voicing of certain contrasting consonants. They showed that many acoustic properties of voicing contrasts arise from variations in [[voice onset time]], the relative phasing of the onset of [[vocal cord]] vibration and the end of a consonant. Their work has been widely replicated and elaborated, here and abroad, over the following decades. [[Donald Shankweiler]] and [[Michael Studdert-Kennedy]] used a [[dichotic listening]] technique (presenting different nonsense syllables simultaneously to opposite ears) to demonstrate the dissociation of [[phonetic]] (speech) and [[Hearing (sense)|auditory]] (nonspeech) perception by finding that phonetic structure devoid of meaning is an integral part of language, typically processed in the left [[cerebral hemisphere]]. Liberman, Cooper, Shankweiler, and Studdert-Kennedy summarized and interpreted fifteen years of research in "Perception of the Speech Code," still among the most cited papers in the speech literature. It set the agenda for many years of research at Haskins and elsewhere by describing speech as a code in which speakers overlap (or coarticulate) segments to form syllables. Researchers at Haskins connected their first computer to a speech synthesizer designed by the Laboratories' engineers. [[Ignatius Mattingly]], with British collaborators, John N. Holmes [https://www.amazon.co.uk/dp/0748408576] and J.N. Shearme [http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&amp;id=JASMAN000035000011001911000004&amp;idtype=cvips&amp;gifs=yes], adapted the [[Pattern playback]] rules to write the first computer program for synthesizing continuous speech from a phonetically spelled input. A further step toward a [[reading machine]] for the blind combined Mattingly's program with an automatic look-up procedure for converting alphabetic text into strings of [[phonetic]] symbols.

===1970s===
In 1970 Haskins Laboratories moved to [[New Haven, Connecticut]], and entered into affiliation agreements with [[Yale University]] and the [[University of Connecticut]]. [[Isabelle Liberman]], Donald Shankweiler, and [[Alvin Liberman]] teamed up with [[Ignatius Mattingly]] to study the relationship between speech perception and reading, a topic implicit in the Laboratories' research program since its inception. They developed the concept of [[phonemic awareness]], the knowledge that would-be readers must be aware of the phonemic structure of their language in order to be able to read. [[Leonard Katz]] related the work to contemporary cognitive theory and provided expertise in experimental design and data analysis. Under the broad rubric of the "[[alphabetic principle]]," this is the core of the Laboratories' present program of reading pedagogy. Patrick Nye [http://www.haskins.yale.edu/staff/nye.html] joined the Laboratories to lead a team working on the [[reading machine]] for the blind. The project culminated when the addition of an [[optical character recognition|optical character recognizer]] allowed investigators to assemble the first automatic text-to-speech reading machine. By the end of the decade this technology had advanced to the point where commercial concerns assumed the task of designing and manufacturing reading machines for the blind [http://www.kurzweiltech.com/kesi.html].

In 1973 [[Franklin S. Cooper]] was selected to form a panel of six experts&lt;ref&gt;Time Magazine (1973). "The Secretary and the Tape Tangle." ''Time Magazine'', Dec. 10, 1973.&lt;/ref&gt; charged with investigating the famous 18-minute gap in the [[Watergate tapes|White House office tapes]] of President [[Richard Nixon]] related to the [[Watergate scandal]] [http://www.paloaltoonline.com/weekly/morgue/community_pulse/1999_Mar_10.LEADOBIT.html]

Building on earlier work, [[Philip Rubin]] developed the [[sinewave synthesis]] program, which was then used by [[Robert Remez]], Rubin,  and colleagues to show that listeners can perceive continuous speech without traditional speech cues from a pattern of sinewaves that track the changing resonances of the [[vocal tract]]. This paved the way for a view of speech as a dynamic pattern of trajectories through articulatory-acoustic space. [[Philip Rubin]] and colleagues developed Paul Mermelstein's anatomically simplified [[vocal tract]] model [http://www.mindspring.com/~ssshp/ssshp_cd/ss_btl2.htm], originally worked on at [[Bell Laboratories]], into the first articulatory synthesizer [http://www.haskins.yale.edu/facilities/asy.html] that can be controlled in a physically meaningful way and used for interactive experiments.

===1980s===
Studies of different [[writing]] systems supported the controversial hypothesis that all reading necessarily activates the [[phonological]] form of a word before, or at the same time, as its meaning. Work included experiments by Georgije Lukatela [http://www.haskins.yale.edu/STAFF/lukatela.html], [[Michael Turvey]], [[Leonard Katz]], [[Ram Frost]] [https://scholars.huji.ac.il/ramfrost], Laurie Feldman [http://www.albany.edu/psy/feldman.html], and [[Shlomo Bentin]], in a variety of languages. Cross-language work on reading, including investigations of the brain process involved, remains a large part of the Laboratories' program today.

Various researchers developed compatible theoretical accounts of [[speech production]],&lt;ref&gt;Gloria J. Borden and Katherine S. Harris. Speech Science Primer: Physiology, acoustics, and perception of speech. Second Edition. Williams &amp; Williams, Baltimore, MD, 1984&lt;/ref&gt; [[speech perception]] and [[phonological]] knowledge. [[Carol Fowler]] proposed a [[direct realism]] theory of speech perception: listeners perceive gestures not by means of a specialized decoder, as in the motor theory, but because information in the acoustic signal specifies the gestures that form it. [[J. A. Scott Kelso]] and colleagues demonstrated functional synergies in speech gestures experimentally. Elliot Saltzman [http://www.haskins.yale.edu/staff/saltzman.html] developed a [[dynamical systems]] theory of [[Synergetics (Haken)|synergetic]] action and implemented the theory as a working model of speech production. [[linguistics|Linguists]] [[Catherine Browman]] and [[Louis M. Goldstein|Louis Goldstein]] developed the theory of [[articulatory phonology]] [http://www.haskins.yale.edu/research/gestural.html], in which gestures are the basic units of both [[phonetic]] action and [[phonological]] knowledge. Articulatory phonology, the task dynamic model, and the articulatory synthesis model are combined into a gestural computational model of speech production [http://www.haskins.yale.edu/research/gestural.html].

===1990s===
[[Katherine Safford Harris]],&lt;ref&gt;Frederica Bell-Berti. ''Producing Speech: Contemporary Issues, for Katherine Safford Harris''. Springer, 1995.&lt;/ref&gt; Frederica Bell-Berti [https://web.archive.org/web/20070927223034/http://www.stjohns.edu/academics/graduate/liberalarts/departments/speech] and colleagues studied the phasing and cohesion of articulatory speech gestures. [[Kenneth Pugh]] was among the first scientists to use [[functional magnetic resonance imaging]] (fMRI) to reveal brain activity associated with reading and reading disabilities. Pugh, [[Donald Shankweiler]], Weija Ni [http://www.csr.nih.gov/photodisplay/finalinter.aspx?id=1258&amp;orgid=340010003&amp;other=0], Einar Mencl [http://www.haskins.yale.edu/staff/mencl.html], and colleagues developed novel applications of [[neuroimaging]] to measure brain activity associated with understanding sentences. [[Philip Rubin]], [[Louis M. Goldstein|Louis Goldstein]] and Mark Tiede [http://www.haskins.yale.edu/staff/tiede.html] designed a radical revision of the articulatory synthesis model, known as CASY [http://www.haskins.yale.edu/facilities/casy.html], the configurable articulatory synthesizer. This 3-dimensional model of the [[vocal tract]] permits researchers to replicate [[MRI]] images of actual speakers. [[Douglas Whalen]], Goldstein, Rubin and colleagues extended this work to study the relation between speech production and perception. [http://www.haskins.yale.edu/newsrelease/A93-2006.html] [[Donald Shankweiler]], [[Susan Brady (psychologist)|Susan Brady]],  Anne Fowler [http://www.haskins.yale.edu/staff/fowlera.html], and others explored whether weak [[memory]] and [[perception]] in poor readers are tied specifically to [[phonological]] deficits. Evidence rejected broader cognitive deficits underlying reading difficulties and raised questions about impaired phonological representations in disabled readers.

===2000s===
Anne Fowler [http://www.haskins.yale.edu/staff/fowlera.html] and [[Susan Brady (psychologist)|Susan Brady]] launched the Early Reading Success (ERS) program [http://www.haskins.yale.edu/ers/], part of the Haskins Literacy Initiative [http://www.haskins.yale.edu/hli.html] which promotes the science of teaching reading. The ERS program was a demonstration project examining the efficacy of [[professional development]] in [[reading (activity)|reading]] instruction for teachers of children in kindergarten through second grade. The Mastering Reading Instruction program [http://www.haskins.yale.edu/mrin.html], which combines professional development with Haskins-trained mentors, was a continuation of ERS. [[David Ostry]] and colleagues explored the neurological underpinning of [[motor control]] using a robot arm to influence [[jaw]] movement. [[Douglas Whalen]] and Khalil Iskarous [http://www.haskins.yale.edu/staff/iskarous.html] pioneered the pairing of [[ultrasound]], used here to monitor articulators that cannot be seen, and [[Optotrak]][http://www.ndigital.com/certus.php], an opto-electronic position-tracking device, used here to monitor visible articulators. Christine Shadle  [http://haskinslabs.org/people/christine-shadle] joined Haskins in 2004 to head up a project investigating the [[speech production]] goals for [[fricatives]][https://projectreporter.nih.gov/project_info_description.cfm?aid=6768145&amp;icde=32362515&amp;ddparam=&amp;ddvalue=&amp;ddsub=&amp;cr=5&amp;csb=default&amp;cs=ASC&amp;pball=]. [[Donald Shankweiler]] and David Braze [http://www.haskins.yale.edu/staff/braze.html] developed an [[Eye movement (sensory)|eye movement]] laboratory that combines [[eye tracking]] data with brain activity measures for investigating [[reading (activity)|reading]] processes in normal and disabled readers. [[Laura L. Koenig|Laura Koenig]] and [[Jorge C. Lucero]] [http://www.cic.unb.br/~lucero/index_en.html] studied the development of laryngeal and aerodynamic control in children's speech. In March 2005 Haskins Laboratories moved to a new state-of-the-art facility on George Street in [[New Haven]]. In 2008 [[Ken Pugh]] of [[Yale University]] was named President and Director of Research, succeeding [[Carol Fowler]] who remains at Haskins as a Senior Advisor. In 2009 Haskins released its new Strategic Plan [http://www.haskins.yale.edu/StrategicPlan.html], which features new ''Birth-to-Five'' and [[Bilingualism]] initiatives.

===2010s===
The [http://www.haskins.yale.edu/hti/ Haskins Training Institute] was established in 2011 to provide direct educational opportunities in Haskins Laboratories' core areas of research ([[language]], [[speech perception]], [[speech production]], [[literacy]]). The Training Institute serves to communicate this knowledge to the public through accessible seminars, small conferences, and intern and training positions.

Capabilities in the [[eye movement]] labs is expanded to include 3 [[eye tracker]]s, including one with the ability to capture synchronous gaze and [[EEG]] data, and another able to capture synchronous gaze and [[speech]] signals.

In December 2015, Haskins Laboratories convened a [http://www.haskins.yale.edu/hgs/ Global Literacy Summit]. This was a three-day meeting of scientists and representatives from governmental and non-governmental organizations around the globe, who are working with programs in the developing world to support literacy and education in disadvantaged populations.

== See also (people) ==
* [[Arthur S. Abramson]]
* [[Shlomo Bentin]]
* [[Susan Brady (psychologist)|Susan Brady]]
* [http://www.haskins.yale.edu/staff/braze.html David Braze]
* [[Catherine Browman]]
* [[Franklin S. Cooper]]
* [http://www.haskins.yale.edu/staff/fowlera.html Anne E. Fowler]
* [[Carol Fowler]]
* [[Louis M. Goldstein]]
* [[Katherine Safford Harris]]
* [[Caryl Parker Haskins]]
* [[Leonard Katz]]
* [[J. A. Scott Kelso]]
* [[Laura L. Koenig|Laura Koenig]]
* [[Alvin Liberman]]
* [[Isabelle Liberman]]
* [[Philip Lieberman]]
* [[Leigh Lisker]]
* [[Ignatius Mattingly]]
* [[David Ostry]]
* [[Ken Pugh]]
* [[Robert Remez]]
* [[Philip Rubin]]
* [[Elliot Saltzman]]
* [[Hollis Scarborough]]
* [[Donald Shankweiler]]
* [[Michael Studdert-Kennedy]]
* [[Michael Turvey]]
* [[Douglas Whalen]]
* [[Ram Frost]]

== See also (topics) ==
* [[alphabetic principle]]
* [[articulatory phonology]]
* [[articulatory synthesis]]
* [[categorical perception]]
* [[coarticulation]]
* [[cognitive science]]
* [[cognitive neuroscience]]
* [[dichotic listening]]
* [[direct realism]]
* [[experimental psychology]]
* [[eye tracking]]
* [[linguistics]]
* [[motor theory of speech perception]]
* [[orthographic depth]]
* [[Pattern playback]]
* [[phonemic awareness]]
* [[phonological awareness]]
* [[psycholinguistics]]
* [[reading (activity)|reading]]
* [[reading disability]]
* [[reading machine]]
* [[sinewave synthesis]]
* [[speech perception]]
* [[speech synthesis]]
* [[visual word form area]]
* [[voice onset time]]
* [[Watergate tapes]]

==References==
{{refbegin}}
* Frederica Bell-Berti. ''Producing Speech: Contemporary Issues, for Katherine Safford Harris''. Springer, 1995. 
* Gloria J. Borden and Katherine S. Harris. ''Speech Science Primer: Physiology, acoustics, and perception of speech. Second Edition''. Williams &amp; Williams, Baltimore, MD, 1984.
* Alice B. Dadourian. ''A Bio-Biography of Caryl Parker Haskins''. Yvonix, New Haven, Connecticut, 2000.
* Haskins Laboratories. ''The Science of the Spoken and Written Word''. Haskins Laboratories, New Haven, CT, 2005.
* James F. Kavanagh and Ignatius G. Mattingly (eds.), ''Language by Ear and by Eye: The Relationships between Speech and Reading''. The MIT Press, Cambridge, MA: 1972. (Paperback edition, 1974, {{ISBN|0-262-61015-9}}).
* Alvin M. Liberman. ''Speech: a special code''. The MIT Press, Cambridge, MA: 1996.
* A. M. Liberman, F. S. Cooper, D. S. Shankweiler, and M. Studdert-Kennedy. Perception of the speech code. ''Psychological Review'', 74, 1967, 431-461.
* A. M., Liberman, A. M., K. S. Harris, H. S. Hoffman &amp; B. C. Griffith. The discrimination of speech sounds within and across phoneme boundaries. ''Journal of Experimental Psychology'', 54, 358 - 368, 1957.
* Ignatius G. Mattingly &amp; Michael Studdert-Kennedy (Eds.), ''Modularity and the Motor Theory of Speech Perception'': Proceedings of a Conference to Honor Alvin M. Liberman. Hillsdale, NJ: Lawrence Erlbaum: 1991. (Paperback, {{ISBN|0-8058-0331-9}})
* Patrick W. Nye, Smithsonian Speech Synthesis History Project, August 1, 1989 [https://web.archive.org/web/20070108175035/http://www.mindspring.com/~ssshp/ssshp_cd/ss_hask.htm]
* [[Malcolm Slaney]]. Pattern playback from 1950 to 1995. ''Proceedings of the 1995 IEEE Systems, Man and Cybernetics Conference'', October 22–25, 1995, Vancouver, Canada. Copyright 1995, IEEE. [http://cobweb.ecn.purdue.edu/~malcolm/interval/1994-036/]
{{refend}}

==Notes==
{{reflist}}

[[Category:Cognitive science research institutes]]
[[Category:Research institutes in the United States]]
[[Category:Biological research institutes]]
[[Category:Linguistics organizations]]
[[Category:Organizations established in 1935]]
[[Category:Phonetics]]
[[Category:Phonology]]
[[Category:Speech recognition]]
[[Category:Speech synthesis]]
[[Category:Yale University]]
[[Category:University of Connecticut]]
[[Category:Non-profit organizations based in Connecticut]]
[[Category:501(c)(3) nonprofit organizations]]</text>
      <sha1>qxbtwujpq5f4fvwoivc9kriz13ijzzr</sha1>
    </revision>
  </page>
  <page>
    <title>Heinrich Hübsch</title>
    <ns>0</ns>
    <id>9955665</id>
    <revision>
      <id>869045360</id>
      <parentid>845286725</parentid>
      <timestamp>2018-11-16T01:47:08Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2478">[[Image:Frontalsicht Dom Speyer.jpg|thumb|West facade of the [[Speyer Cathedral]] rebuilt by Heinrich Hübsch]]
[[Image:Baden-Baden 10-2015 img37 Pump house.jpg|thumb|Trinkhalle (pump room) in [[Baden-Baden]]]]
'''Heinrich Hübsch''' (9 February 1795 – 3 April 1863) was a [[Germans|German]] architect.  After studies in [[Ruprecht Karl University of Heidelberg|Heidelberg]] (1813–15) and at [[Friedrich Weinbrenner]]'s school of architecture in [[Karlsruhe]] (1815–17) he traveled extensively in [[Greece]] and [[Italy]] (1817–24).  In 1831 he was appointed Oberbaurat (inspector of buildings) at Karlsruhe.  He designed many churches and other public buildings, mainly in the [[Grand Duchy of Baden]], and is also known for his writings.

In his book ''In welchem Style sollen wir bauen?'' (''In which style should we build?'', 1828) he distanced himself from Weinbrenner's [[Neoclassical architecture|neoclassical style]]. ''Die altchristlichen Kirchen'' (Karlsruhe, 1862) is a work on basilican architecture, published also in [[French language|French]] as ''Monuments de l'architecture chrétienne''.

Hübsch is credited with creating the [[Rundbogenstil]] architectural style.&lt;ref&gt;Bergdoll, Barry, European Architecture, 1750-1890,  Oxford, 2000, pp. 184-9&lt;/ref&gt;

==Publications==
([[s:de:Heinrich Hübsch]])

==Buildings==

* [[Karlsruhe Institute of Technology|Polytechnical School]], main building, [[Karlsruhe]], 1833–1835
* [[Staatliche Kunsthalle Karlsruhe]], 1836–1846
* [[Kassel Synagogue]], 1839
* [[Trinkhalle (Baden-Baden)|Trinkhalle]], [[Baden-Baden]], 1839–1842
* [[Bruchsal]] penitentiary, 1841–1848
* [[Botanischer Garten Karlsruhe|Karlsruhe Botanical Garden]], plant houses, 1853–1857
* [[Speyer Cathedral]] westwerk, 1854–1858

== External links ==
* [http://www.rz.uni-karlsruhe.de/~saai/bestaende_huebsch_heinrich.html Heinrich Hübsch at the SAAI]
{{Commons category}}

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Hubsch, Heinrich}}
[[Category:German architecture writers]]
[[Category:1795 births]]
[[Category:1863 deaths]]
[[Category:19th-century German architects]]
[[Category:Architecture educators]]
[[Category:Architectural theoreticians]]
[[Category:German non-fiction writers]]
[[Category:People from Weinheim]]
[[Category:People from the Grand Duchy of Baden]]
[[Category:Heidelberg University alumni]]
[[Category:Karlsruhe Institute of Technology faculty]]
[[Category:German male non-fiction writers]]</text>
      <sha1>2i33g9gcwnalxnyywbbzjobp2f0cc5g</sha1>
    </revision>
  </page>
  <page>
    <title>IAR Graduate Conference</title>
    <ns>0</ns>
    <id>25908518</id>
    <revision>
      <id>845686899</id>
      <parentid>693759794</parentid>
      <timestamp>2018-06-13T13:16:55Z</timestamp>
      <contributor>
        <username>PKT</username>
        <id>1382933</id>
      </contributor>
      <comment>+coords</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6122">{{Infobox organization
| name                = Institute of Asian Research (IAR) Graduate Conference
| native_name         = 
| native_name_lang    = 
| named_after         = 
| image               = 
| image_size          = 
| alt                 = 
| caption             = 
| map                 = 
| map_size            = 
| map_alt             = 
| map_caption         = 
| map2                = 
| map2_size           = 
| map2_alt            = 
| map2_caption        = 
| abbreviation        = 
| motto               = 
| predecessor         = 
| merged              = 
| successor           = 
| formation           = &lt;!-- use {{start date|YYYY|MM|DD|df=y}} --&gt;
| founder             = 
| founding_location   = 
| extinction          = &lt;!-- use {{end date and age|YYYY|MM|DD}} --&gt;
| merger              = 
| type                = 
| tax_id              = &lt;!-- or | vat_id = (for European organizations) --&gt;
| registration_id     = &lt;!-- for non-profit org --&gt;
| status              = 
| purpose             = understanding between students of Asia Pacific policy and makers of Asia Pacific policy 
| headquarters        = 
| location            = 
| coords              = &lt;!-- {{coord|LAT|LON|display=inline,title}} --&gt;
| region              = 
| services            = 
| products            = 
| methods             = 
| fields              = 
| membership          = 
| membership_year     = 
| language            = 
| owner               = &lt;!-- or | owners = --&gt;
| sec_gen             = 
| leader_title        = 
| leader_name         = 
| leader_title2       = 
| leader_name2        = 
| leader_title3       = 
| leader_name3        = 
| leader_title4       = 
| leader_name4        = 
| board_of_directors  = 
| key_people          = 
| main_organ          = 
| parent_organization = [[University of British Columbia]] 
| subsidiaries        = ''Journal of the College for Interdisciplinary Studies''
| secessions          = 
| affiliations        = 
| budget              = 
| budget_year         = 
| revenue             = 
| revenue_year        = 
| disbursements       = 
| expenses            = 
| expenses_year       = 
| endowment           = 
| staff               = 
| staff_year          = 
| volunteers          = 
| volunteers_year     = 
| slogan              = 
| mission             = 
| website             = &lt;!-- {{URL|example.com}} --&gt;
| remarks             = 
| formerly            = 
| footnotes           = 
}}



The '''Institute of Asian Research (IAR) Graduate Conference''' at the [[University of British Columbia]] is an annual graduate conference organized by the IAR Conference Committee, and co-hosted by the University's [[Institute of Asian Research]]. The symposium is a forum for interdisciplinary discussion on Asia Pacific policy-relevant issues, where students in all fields are encouraged to demonstrate the policy significance of their work. The IAR Conference Committee, under its collaboration with the College for Interdisciplinary Studies ([http://www.cfis.ubc.ca/ CFIS]) at UBC, publishes the proceedings of the conference in the ''Journal of the College for Interdisciplinary Studies'', as well as the possibility of publication in the Asia Pacific Memo.

== Mandate ==
The mandate of the symposium, as stated by its organizer (IAR Conference Committee), is "to promote academic awareness towards the salience of policy-relevant issues in the Asia Pacific and its surrounding regions. The IAR Conference Committee, backed by its belief of academic research as a necessary precursor to sound policy-making and the interdisciplinary nature of such, strives to create a community of understanding between students of Asia Pacific policy and makers of Asia Pacific policy by providing a dynamic forum for the exchange of ideas".[http://www.iar.ubc.ca/mapps/mappssaconference.aspx]

== Chronology of Conference Themes ==
*2010, ''Conceiving Asia Pacific: The Policy Kaleidoscope''
*2011, ''Transnational Policy: Connecting the Asia Pacific''

== Topics ==
Areas of discussion include, but are not limited to:
*Trade, Infrastructure, Gateway Initiatives
*Environment and Policy
*Technology and New Media
*Traditional and Economic Security
*[[Urbanism]] and the Rise of Cities
*Democratization
*Human Rights and Governance
*Non-Traditional Security
*Social Change, Development
*Public and Health Policy
*Ethics and Morality
*Education
*Energy and Resource Management
*Ethnicity and Nationalism
*Social Work

== 2011 Conference Schedule ==
'''Thursday, March 17/2011'''
{| class="wikitable"
|-
! '''TIME''' !! '''ACTIVITY''' !! '''PRESENTER''' !! '''ROOM'''
|-
| 11:30 - 12:30 || REGISTRATION || NA || C.K. Choi Lounge
|-
| 12:30 – 13:30 || KEYNOTE SPEECH || Joseph Caron || Liu Institute Multipurpose Room 
|-
| 13:40 - 14:45 || ROUNDTABLES SESSION #1 || Multiple(4-6) || C.K. Choi Boardrooms
|-
| 15:15 - 16:45 || PANEL SESSION #1 GLOBALIZATION || Multiple(2) || C.K. Choi Room 120
|-
| 17:00 - 18:00 || PRESENTATION || Victor Radujko || C.K. Choi Room 120
|}

'''Friday, March 18/2011'''
{| class="wikitable"
|-
! '''TIME''' !! '''ACTIVITY''' !! '''PRESENTER''' !! '''ROOM'''
|-
| 10:30 - 12:00 || PANEL SESSION #2 MIGRATION || Multiple(3) || C.K. Choi Room 120
|-
| 13:40 – 14:45 || ROUNDTABLES SESSION #2 || Multiple(4-6) || C.K. Choi Boardrooms 
|-
| 15:15 - 16:45 || PANEL SESSION #3 ECONOMIC TRADE &amp; DEVELOPMENT || Multiple(3) || C.K. Choi Room 120
|-
| 16:45 - 17:00 || CLOSING CEREMONY || NA || C.K. Choi Lounge
|}

== References ==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [http://www.iar.ubc.ca/mapps/mappssaconference.aspx IAR Graduate Conference]
* [http://mapps.iar.ubc.ca/ Master of Asia Pacific Policy Studies at UBC]
* [http://www.iar.ubc.ca/ Institute of Asian Research]

{{coord |49.2668|N|123.2587|W|display=title}}

[[Category:Conferences]]
[[Category:Academic conferences]]
[[Category:Research institutes of international relations]]
[[Category:University of British Columbia]]
[[Category:Research institutes in Canada]]</text>
      <sha1>csqesqpg14inihsrn67lbxr6kkn1xsk</sha1>
    </revision>
  </page>
  <page>
    <title>Immunopathology</title>
    <ns>0</ns>
    <id>2405284</id>
    <revision>
      <id>840769799</id>
      <parentid>835859453</parentid>
      <timestamp>2018-05-12T01:45:33Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5379">
'''Immunopathology''' is a branch of medicine that deals with immune responses associated with disease.  It includes the study of the pathology of an [[organism]], [[organ system]], or disease with respect to the [[immune system]], immunity, and immune responses. In biology, it refers to damage caused to an organism by its own immune response, as a result of an infection. It could be due to mismatch between pathogen and host species, and often occurs when an animal pathogen infects a human (e.g. [[avian flu]] leads to a [[cytokine storm]] which contributes to the increased mortality rate).&lt;ref&gt;{{cite journal|last1=Us|first1=Dürdal|title=[Cytokine storm in avian influenza]|journal=Mikrobiyoloji Bulteni|date=1 April 2008|volume=42|issue=2|pages=365–380|issn=0374-9096|pmid=18697437}}&lt;/ref&gt; 

When a foreign antigen enters the body, there is either an antigen specific or nonspecific response to it. These responses are the immune system fighting off the foreign antigens, whether they are deadly or not. Immunopathology could refer to how the foreign antigens cause the immune system to have a response or problems that can arise from an organism’s own immune response on itself. There are certain problems or faults in the immune system that can lead to more serious illness or disease. These diseases can come from one of the following problems. The first would be Hypersensitivity reactions, where there would be a stronger immune response than normal. There are four different types (type one, two, three and four), all with varying types and degrees of an immune response. The problems that arise from each type vary from small allergic reactions to more serious illnesses such as tuberculosis or arthritis. The second kind of complication in the immune system is Autoimmunity, where the immune system would attack itself rather than the antigen. Inflammation is a prime example of autoimmunity, as the immune cells used are self-reactive. A few examples of autoimmune diseases are Type 1 diabetes, Addison’s disease and Celiac disease. The third and final type of complication with the immune system is Immunodeficiency, where the immune system lacks the ability to fight off a certain disease. The immune system’s ability to combat it is either hindered or completely absent. The two types are Primary Immunodeficiency, where the immune system is either missing a key component or does not function properly, and Secondary Immunodeficiency, where disease is obtained from an outside source, like radiation or heat, and therefore cannot function properly. Diseases that can cause immunodeficiency include HIV, AIDS and leukemia.&lt;ref&gt;{{cite journal|url=https://dx.doi.org/10.1186/1710-1492-7-S1-S1|title=An introduction to immunology and immunopathology|first1=Richard|last1=Warrington|first2=Wade|last2=Watson|first3=Harold L.|last3=Kim|first4=Francesca Romana|last4=Antonetti|date=1 January 2011|publisher=|journal=Allergy, Asthma &amp; Clinical Immunology|volume=7|issue=1|pages=S1|via=BioMed Central|doi=10.1186/1710-1492-7-S1-S1|pmid=22165815|pmc=3245432}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Warrington|first1=Richard|title=An introduction to immunology and immunopathology|url=http://aacijournal.biomedcentral.com/articles/10.1186/1710-1492-7-S1-S1|website=BioMed Central|publisher=Warrington et al; licensee BioMed Central Ltd.}}&lt;/ref&gt; 

In all vertebrates, there are two different kinds of immune responses: Innate and Adaptive immunity. Innate immunity is used to fight off non-changing antigens and is therefore considered nonspecific. It is usually a more immediate response than the adaptive immune system, usually responding within minutes to hours.&lt;ref&gt;Warrington, Richard''. [http://aacijournal.biomedcentral.com/articles/10.1186/1710-1492-7-S1-S1 "An introduction to immunology and immunopathology"].'' BioMed Central. Warrington et al; licensee BioMed Central Ltd.&lt;/ref&gt; It is composed of physical blockades such as the skin, but also contains nonspecific immune cells such as dendritic cells, macrophages, T Cells, and basophils. The second for of immunity is Adaptive immunity. This form of immunity requires recognition of the foreign antigen before a response is produced. Once the antigen is recognized, a specific response is produced in order to destroy the specific antigen. Because of this idea, adaptive immunity is considered to be specific immunity. A key part of adaptive immunity that separates it from innate is the use of memory to combat the antigen in the future. When the antigen is originally introduced, the organism does not have any receptors for the antigen so it must generate them from the first time the antigen is present. The immune system then builds a memory of that antigen, which enables it to recognize the antigen quicker in the future and be able to combat it quicker and more efficiently. The more the system is exposed to the antigen, the quicker it will build up its responsiveness.&lt;ref&gt;{{cite journal | author = Iwasaki A., Medzhitov R. | year = 2010 | title = Regulation of Adaptive Immunity by the Innate Immune System | url = | journal = Science | volume = 327 | issue = 5963| pages = 291–95 | doi=10.1126/science.1183021| pmc = 3645875}}&lt;/ref&gt;

==References ==
{{reflist|30em}}

{{Pathology}}

[[Category:Clinical pathology]]
[[Category:Pathology]]
[[Category:Branches of immunology]]


{{pathology-stub}}</text>
      <sha1>i74r7w316hp6cbpxc56zvgwtfw2lt76</sha1>
    </revision>
  </page>
  <page>
    <title>Institute of Mathematics of National Academy of Sciences of Armenia</title>
    <ns>0</ns>
    <id>14073367</id>
    <revision>
      <id>845129404</id>
      <parentid>824668279</parentid>
      <timestamp>2018-06-09T16:03:26Z</timestamp>
      <contributor>
        <username>ԱշոտՏՆՂ</username>
        <id>20919629</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5485">{{primary sources|date=February 2015}}
{{Infobox university
| name           = Institute of Mathematics of National Academy of Sciences of Armenia
| image        = Logo IM NAS.png
| established  = 01.07.1971
| free_label   = Director
| free         = [[Rafayel Barkhudaryan]]
| coor         = {{coord|40|11|33.26 |N|44|30|29|E|}}
| city         = [[Yerevan]]
| country      = [[Armenia]]
| website      = http://math.sci.am
}}

The '''Institute of Mathematics''' ([[Armenian language|Armenian]]: {{lang|hy|Մաթեմատիկայի Ինստիտուտ}}) is owned and operated by the [[Armenian Academy of Sciences]], located in [[Yerevan]].

==History==
The '''Institute of Mathematics of National Academy of Sciences of Armenia''' originated as the Section for Mathematics and Mechanics, created within the newly formed [[Armenian Academy of Sciences]] in 1944.  The section later developed into an Institute of Mathematics and Mechanics of Armenian Academy of Sciences, whose first Director was academician [[Artashes Shahinian]], known for his results in [[complex analysis]]. The Institute of Mathematics of Armenian Academy of Sciences separated from the latter Institute in 1971. The bearer of the office of the Director of Institute has been academician [[Mkhitar Djrbashian]] (1971-1989, 1989-1994 Honorary Director).

The academicians [[Sergey Mergelyan]], [[Norair Arakelian]], [[Alexandr Talalyan]], [[Raphayel Alexandrian]], [[Rouben V. Ambartzumian]] and [[Anry Nersesyan]] also have greatly influenced the formation of the scientific profile of the Institute and largely contributed to mathematics in general. In particular [[Rouben V. Ambartzumian]]&lt;ref&gt;{{cite journal |url= https://link.springer.com/article/10.3103/S1068362313010019?no-access=true |doi= 10.3103/S1068362313010019 |volume=48 |title= Academician R. V. Ambartzumian |journal= Journal of Contemporary Mathematical Analysis |pages= 1–3}}&lt;/ref&gt; is famous for his work in [[Stochastic geometry|Stochastic Geometry]] and [[Integral geometry|Integral Geometry]], where he created a new branch called Combinatorial Integral Geometry.&lt;ref&gt;1982 – R.V. Ambartzumian. ''Combinatorial Integral Geometry with Applications to Mathematical [[Stereology]]'', John Wiley, Chichester, NY&lt;/ref&gt; He has provided solutions to a number of classical problems in particular the solution to the Buffon Sylvester problem as well as the [[Hilbert's fourth problem#cite note-5|Hilbert's fourth problem]] in dimensions 2&lt;ref&gt;R. V. Ambartzumian. "A note on pseudo-metrics on the plane". ''Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete''. 1976, Volume 37, Issue 2, pp. 145-155&lt;/ref&gt; and 3.&lt;ref&gt;R. V. Ambartzumian. "Remarks on Combinatorics of Planes in Euclidean Three Dimensions". ''SOP Transactions on Applied Mathematics''. Volume 1, Number 2, pp. 29-43. 2014&lt;/ref&gt;

In the early years, the investigations carried out in the Institute concentrated on [[complex analysis|Function Theory]]. Gradually the sphere of investigations expanded and now includes [[differential equations|Differential]] and [[integral equation|Integral]] Equations, [[Functional Analysis]], [[Probability Theory]] and [[Mathematical Statistics]].

==Journals==
The institute has a journal, ''[[Izvestia NAS RA Matematika]]''. The founder and the first Editor in Chief (1971–1990) of the journal was [[Mkhitar Djrbashian]]; under [[Rouben V. Ambartzumian]] Editor in Chief (1990 - 2010) the journal obtained international recognition and obtained an English version, ''[[Journal of Contemporary Mathematical Analysis]]'', published initially by Allerton Press, Inc. New York and later by [[Springer Science+Business Media]]. Journal covers a host of topics including: [[real analysis]] and [[complex analysis]]; [[approximation theory]], [[boundary value problem]]s; [[integral geometry]] and [[stochastic geometry]]; [[differential equations]]; [[probability]] and [[statistics]]; [[integral equations]]; [[algebra]].

==Directors, faculty and members==
At present the Institute has about 30 main researchers as well as a number of associate researchers from [[Yerevan State University]].

[[Norair Arakelian]] in 1970 (Nice) and [[Mkhitar Djrbashian]], [[Rouben V. Ambartzumian]] in 1974 (Vancouver) were invited speakers at the 
[[International Congresses of Mathematicians]].

{| class="wikitable"
|-
! colspan="2" | Directors of the IM NAS
|-
! Name
! Term
|-
| ''[[Mkhitar Djrbashian]]'' || 1971-1989
|-
| ''[[Norair Arakelian]]'' || 1989-1991
|-
| ''[[Alexandr Talalyan]]'' || 1991-1997
|-
| ''[[Norair Arakelian]]'' ||  1997-2006
|-
| ''[[Bagrat Batikyan]]'' ||  2006-2010
|-
| ''[[Valeri Martirosyan]]'' ||  2011-2012
|-
| ''[[Rafayel Barkhudaryan]]'' || 2012–present
|-
|}

==See also==
* [[Armenian National Academy of Sciences]]
* [[Byurakan Observatory]]
* [[Mikael Ter-Mikaelian Institute for Physical Research]]
* [[List of International Congresses of Mathematicians Plenary and Invited Speakers]]
* [[USSR State Prize]]
* [[Rollo Davidson Prize]]

==References==
{{reflist}}

==External links==
* [http://math.sci.am/ Institute of Mathematics of National Academy of Sciences of Armenia official site]
* [http://www.sci.am/resorgs.php?oid=2&amp;langid=1 National Academy of Sciences of Armenia]

{{Yerevan landmarks}}

[[Category:1944 establishments in Armenia]]
[[Category:Science and technology in Armenia]]
[[Category:Research institutes in Armenia]]
[[Category:Mathematical institutes]]
[[Category:Integral geometry]]</text>
      <sha1>itxw13cmdbmm9wins6rzq3a39qph6kx</sha1>
    </revision>
  </page>
  <page>
    <title>Jerzy Adam Kowalski</title>
    <ns>0</ns>
    <id>47480337</id>
    <revision>
      <id>821843524</id>
      <parentid>798396191</parentid>
      <timestamp>2018-01-22T23:22:04Z</timestamp>
      <contributor>
        <username>Andrew J.Kurbiko</username>
        <id>20106661</id>
      </contributor>
      <comment>added [[Category:SWPS University faculty]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2692">'''Jerzy Adam Kowalski''' (born 1958) is a Polish [[researcher]] and [[popular science]] author in the field of [[human sexuality]].

==Biography==
He is a graduate of the [[Warsaw University]], where from 1977 to 1984 he studied [[political science]], [[journalism]] and [[psychology]]. He was a journalist, publisher and editor. From 2008 he is a scientific worker in the [[Institute of Sex Research in Opole, Poland]]&lt;ref&gt;[http://homo-eroticus.ibs.opole.pl/about-the-author.html "About the Author"] at the book "Homo eroticus" website.&lt;/ref&gt; and the chairman of board of the foundation for the Institute.&lt;ref&gt;[http://www.ibs.opole.pl/index.php/en/administration "Administration"] at the Institute of Sex Research in Opole Website.&lt;/ref&gt; He is PhD Cand. in The Institute of Culture Science, [[University of Social Sciences and Humanities]] in Warsaw.

==Selected publications==
* Jerzy A. Kowalski, ''Homo eroticus'', Wydawnictwo IBS, Opole 2011, Serie: Eros i logos. {{ISBN|978-83-931776-0-8}} [In Polish].
* Jerzy A. Kowalski, ''Homo eroticus. Jak narodziła się ludzka seksualność'' (e-book), Wydawnictwo IBS, Opole 2011, {{ISBN|978-83-931776-4-6}} [In Polish][Homo eroticus: How human sexuality has been arising].
*Jerzy A. Kowalski, ''The origins of homosexuality emancipation'', Serie: Following Bronislaw Malinowski, [https://www.amazon.com/homosexuality-emancipation-Following-Bronislaw-Malinowski-ebook/dp/B011543AU6 An Amazon Kindle edition]. The Institute of Sex Research in Opole Press, Opole 2015, {{ISBN|978-83-931776-3-9}}.
* Jerzy A. Kowalski, ''Sexual partner roles in homoerotic relations: An attempt of classification,''  [[Journal of Homosexuality]]'','' Latest articles: {{doi|10.1080/00918369.2015.1078639}}

==Other notes==
He published in 2011 the book "Homo eroticus", devoted to the evolution of human sexuality. It discusses inter alia certain famous theories in the field and proposes interesting new explanations for this problems, e.g., the fur losing by humans, ovulation veiling in women, two type of woman sexual receptivity, the origination of intimacy, marriage, love, and initiation and circumcision rites. The book was highly praised by specialists and recommended as a reading for university students in Cracow, Poland.&lt;ref&gt;[http://homo-eroticus.ibs.opole.pl/reviews.html "Reviews"] at the book "Homo eroticus" website.&lt;/ref&gt;

== References ==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Kowalski, Jerzy Adam}}
[[Category:1958 births]]
[[Category:Sexologists]]
[[Category:Polish psychologists]]
[[Category:Sexual orientation and science]]
[[Category:Living people]]
[[Category:University of Warsaw alumni]]
[[Category:SWPS University faculty]]</text>
      <sha1>840haxqgqu879q9tmaybyr7q7d3bgid</sha1>
    </revision>
  </page>
  <page>
    <title>John H. Chapman Space Centre</title>
    <ns>0</ns>
    <id>653126</id>
    <revision>
      <id>856770833</id>
      <parentid>839697448</parentid>
      <timestamp>2018-08-27T12:29:23Z</timestamp>
      <contributor>
        <username>Deor</username>
        <id>3022076</id>
      </contributor>
      <comment>{{coord}} tweaks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4477">{{Infobox government agency
| agency_name     = John H. Chapman Space Centre
| type            = 
| nativename      = 
| nativename_a    = 
| nativename_r    = 
| seal            = 
| seal_width      = 100px
| seal_caption    = 
| logo            = 
| logo_width      = 
| logo_caption    = 
| picture         =
| picture_width   = 
| picture_caption = 
| formed          = 1992
| preceding1      = 
| preceding2      = &lt;!-- up to |preceding6= --&gt;
| dissolved       = 
| superseding1    = 
| superseding2    = &lt;!-- up to |superseding6= --&gt;
| agency_type     = Research and Technological Development
| jurisdiction    = [[Government of Canada]]
| headquarters    = [[Longueuil, Quebec]]
| coordinates     = {{coord|45.5198|-73.3936|type:landmark_region:CA-QC|display=inline, title}}
| motto           = 
| employees       = &lt; 600
| budget          = 
| minister1_name  = 
| minister1_pfo   = 
| minister2_name  = 
| minister2_pfo   = &lt;!-- up to |minister7_name= --&gt;
| deputyminister1_name = 
| deputyminister1_pfo  = 
| deputyminister2_name = 
| deputyminister2_pfo  = &lt;!-- up to |deputyminister7_name= --&gt;
| chief1_name     = 
| chief1_position = 
| chief2_name     = 
| chief2_position = &lt;!-- up to |chief9_name= --&gt;
| public_protector =
| deputy          =
| parent_department = 
| parent_agency   = [[Canadian Space Agency|CSA]]
| child1_agency   = 
| child2_agency   = &lt;!-- up to |child25_agency= --&gt;
| keydocument1    = &lt;!-- up to |keydocument6= --&gt;
| website         = {{URL|http://www.asc-csa.gc.ca/eng/default.asp}}
| map             = 
| map_width       = 
| map_caption     = 
| footnotes       = 
| embed           =
}}

The '''John H. Chapman Space Centre''' is the [[headquarters]] of the [[Canadian Space Agency]]. It is located in [[Longueuil]], [[Quebec]], Canada, in the borough of [[Saint-Hubert, Quebec|Saint-Hubert]].

==Location and name==

The centre has a total surface area of 41 hectares (101 acres)&lt;ref&gt;[http://www.tbs-sct.gc.ca/dfrp-rbif/pn-nb/11818-eng.aspx John H. Chapman Space Center].  Treasury Board of Canada Secretariat. Retrieved on April 2016.&lt;/ref&gt; located on the border of the [[Montréal/St-Hubert Airport|Saint Hubert airport]], a [[general aviation]] facility. The building is supposed to look somewhat like a [[space station]]. When seen from above however, it bears no resemblance to real stations like the [[International Space Station|ISS]] or to famous fictional ones.&lt;ref&gt;Canadian Space Agency headquarters photo.  ''[http://www.thespacereview.com/article/674/1 Can we finally reach for the stars?]'', "The Space Review".  Retrieved on 2008-01-10&lt;/ref&gt;

The building was finished in 1992 and named Canadian Space Agency Headquarters, and in 1996, it was renamed the John H. Chapman Space Centre in honour of [[John H. Chapman|John Chapman]] for his accomplishments in the [[Canadian Space Program]] and because of his role in the [[Alouette 1]] program.&lt;ref&gt;[http://www.science.ca/scientists/scientistprofile.php?pID=135 John Herbert Chapman - Builder of the Canadian space program]. ''Science Canada''. Retrieved on April 15, 2016.&lt;/ref&gt;

==Programs==

The centre houses the Canadian [[astronaut]] office and most of the administrative and technical units supporting Canada's programs in space sciences and technology. This includes satellite control rooms, the Protein Crystal Growth Mission Support Centre, and simulators for the [[Canadarm2]], the [[Mobile Servicing System]], and the [[Advanced Space Vision System]].  It also houses the Mission Operations Centre (MOC) that includes the Remote Multi-Purpose Support Room (RMPSR) that is used to operate the [[Mobile Servicing System|MSS]] on-orbit in conjunction with the flight control and mission evaluation rooms at the [[Lyndon B. Johnson Space Center|Johnson Space Center]] as well as the Operations and Engineering Centre (OEC) which supports the flight controllers at [[Lyndon B. Johnson Space Center|JSC]]. As the headquarters for the space agency, it also houses many offices for general administrative functions or for specific programs such as exchange activities with [[NASA]], [[ESA]], [[ISRO]] and other [[national space agencies]].

==References==
{{reflist}}

{{Canadian Space Agency}}

{{Use Canadian English|date=January 2014}}

[[Category:Science and technology in Canada]]
[[Category:Space program of Canada]]
[[Category:Space technology research institutes]]
[[Category:Research institutes in Canada]]
[[Category:Buildings and structures in Longueuil]]</text>
      <sha1>198aysx30h1om07778ui9d0i4mahc79</sha1>
    </revision>
  </page>
  <page>
    <title>Licensed behavior analyst</title>
    <ns>0</ns>
    <id>28066214</id>
    <revision>
      <id>820974918</id>
      <parentid>807569404</parentid>
      <timestamp>2018-01-17T18:18:09Z</timestamp>
      <contributor>
        <ip>73.123.199.155</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14180">{{over-coverage|date=July 2010}}
A '''licensed behavior analyst''' is a type of [[behavioral health]] [[professional]] in the United States. They have at least a master's degree, and sometimes a doctorate, in [[behavior analysis]] or a related field.&lt;ref name="baojournal.com"&gt;{{cite journal|authors=Cautilli, J.D., &amp; Dziewolska, H.|year=2008|title=Licensing behavior analysts: General historical issues and why people oppose them|journal=International Journal of Behavioral Consultation and Therapy|volume=4|issue=1|pages=1–13|url=http://psycnet.apa.org/journals/bct/4/1/1.pdf&amp;productCode=pa|format=PDF|doi=10.1037/h0100827}}&lt;/ref&gt; Behavior analysts apply [[radical behaviorism]] to people by performing [[applied behavior analysis]].&lt;ref name="baojournal.com"/&gt;

== Defining the scope of practice ==
The Behavior Analyst Certification Board (BACB) defines behavior analysis as follows:&lt;ref&gt;[http://www.bacb.com BACB]&lt;/ref&gt;

&lt;blockquote&gt;"The field of behavior analysis grew out of the scientific study of principles of learning and behavior. It has two main branches: experimental and applied behavior analysis. The experimental analysis of behavior (EAB) is the basic science of this field and has over many decades accumulated a substantial and well-respected research literature. This literature provides the scientific foundation for applied behavior analysis (ABA), which is both an applied science that develops methods of changing behavior and a profession that provides services to meet diverse behavioral needs. Briefly, professionals in applied behavior analysis engage in the specific and comprehensive use of principles of learning, including [[operant]] and respondent learning, in order to address behavioral needs of widely varying individuals in diverse settings. Examples of these applications include: building the skills and achievements of children in school settings; enhancing the development, abilities, and choices of children and adults with different kinds of disabilities; and augmenting the performance and satisfaction of employees in organizations and businesses."&lt;/blockquote&gt;

As the above suggests, [[behavior analysis]] is based on the principles of [[operant]] and [[respondent conditioning]]. This places [[behavior analysis]] as one of the dominant models of [[behavior management]], [[behavioral engineering]] and [[behavior therapy]].  Behavior analysis is an active, environmental based approach and some behavior analytic procedures are considered highly restrictive (see [[least restrictive environment]]). For example, these service may make access to preferred items contingent on performance. This has led to abuses in the past, in particular where punishment programs have been involved.&lt;ref name=Cautilli/&gt; In addition, failure to be an independent profession often leads behavior analysts and other behavior modifiers to have their ethical codes supplanted by those of other professions.&lt;ref&gt;{{cite journal|authors=Cautilli, J.D. &amp; Weinberg, M.|year=2007|title=Editorial – Beholden To Other Professions|journal=The Behavior Analyst Today|volume=8|issue=2|pages=111–113|url=http://www.baojournal.com/|doi=10.1037/h0100606}}&lt;/ref&gt; For example, a behavior analyst working in the hospital setting might design a [[token economy]], a form of [[contingency management]]. He may desire to meet his ethical obligation to make the program habilitative and in the clients' best long-term interest. The physicians and nurses in the hospital who supervise him may decide that the [[token economy]] should instead create order in the nursing routines so clients get their medication quickly and efficiently. Instead of the ethical code of the Behavior Analysis Certification Board and the [[Association for Behavior Analysis]] International's position that those receiving treatment have a right to effective treatment&lt;ref name=ABA&gt;{{cite web|url=https://apps.abainternational.org/ABA/statements/treatment.asp|archiveurl=https://web.archive.org/web/20081119073107/http://apps.abainternational.org/ABA/statements/treatment.asp|archivedate=November 19, 2008|deadurl=yes|title=Statement on the Right to Effective Behavioral Treatment, 1989}}&lt;/ref&gt; and a right to effective education.&lt;ref name=ABA/&gt; In addition, failure on the part of a behavior analyst to adequately supervise his or her workers could lead to abuse.&lt;ref&gt;{{cite journal|authors=Bassett, J. E., &amp; Blanchard, E. B.|year=1977|title=The effect of the absence of close supervision on the use of response cost in a prison token economy|journal=Journal of Applied Behavior Analysis|volume=10|pages=375–380|doi=10.1901/jaba.1977.10-375|pmc=1311200|pmid=924912}}&lt;/ref&gt; Finally, misrepresentations of the field and historical problems between academics has led to frequent calls to professionalize behavior analysis.&lt;ref&gt;{{cite journal|authors=Cautilli, J. D. &amp; Rosenwasser, B.J.|year=2001|title=The Editors speak out on intellectual bigotry: Why We Need To Become A Profession|journal=The Behavior Analyst Today|volume=2|issue=1|pages=2–4|url=http://psycnet.apa.org/journals/bar/2/1/2.pdf&amp;productCode=pa|format=PDF}}&lt;/ref&gt;

In general, there is wide support within the profession for licensure.&lt;ref name="baojournal.com"/&gt;

===Range of populations worked with===
{{Main article|Professional practice of behavior analysis}}

The professional practice of behavior analysis ranges from treatment of individuals with autism and developmental disabilities to behavioral coaching and behavioral psychotherapy. In addition to treatment of [[mental health]] problems and corrections,&lt;ref&gt;{{cite journal|authors=Bednar, R. L., Zelhart, P. F., Greathouse, L., &amp; Weinberg, S.|year=1970|title=Operant conditioning principles in the treatment of learning and behavior problems with delinquent boys|journal=Journal of Counseling Psychology|volume=17|pages=492–497|doi=10.1037/h0029884}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|authors=Braukmann, C. J., Fixsen, D. L., Phillips, E. L., &amp; Wolf, M. M.|year=1975|title=Behavioral approaches to treatment in the crime and delinquency field|journal=Criminology|volume=13|pages=299–331|doi=10.1111/j.1745-9125.1975.tb00672.x}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=McGuffin, P.W.|year=1991|title=The effect of timeout duration on frequency of aggression in hospitalized children with conduct disorders|journal=Behavioral Interventions|volume=6|issue=4|pages=279–288|url=http://onlinelibrary.wiley.com/doi/10.1002/bin.2360060405/abstract|doi=10.1002/bin.2360060405}}&lt;/ref&gt; the professional practice of behavior analysis includes organizational behavioral management, behavioral safety and even maintaining the behavioral health of astronauts while within and beyond earth's orbit.&lt;ref&gt;{{cite journal|authors=Emurian, H.H. &amp; Brady, J.V.|year=2007|title=Behavioral Health Management of Space Dwelling Groups: Safe Passage Beyond Earth Orbit|journal=The Behavior Analyst Today|volume=8|issue=3|pages=113–135|url=http://psycnet.apa.org/journals/bar/8/2/113.html}}&lt;/ref&gt;

===Certification===
The Behavior Analyst Certification Board (BACB) offers a technical [[Professional certification|certificate]] in behavior analysis. This certification is internationally recognized. This certification states the level of training and requires an exam to show a minimum level of [[competence (human resources)|competence]] to call oneself a board certified behavior analyst (BCBA). Certification came about because of many ethical issues with behavioral interventions being delivered including the use of aversive and humiliating treatments in the name of [[behavior modification]].&lt;ref&gt;{{cite book|authors=Bailey, J.S. &amp; Burch, M.R.|year=2005|title=Ethics for Behavior Analysts: A Practical Guide to the Behavior Analyst Certification Board Guidelines for Responsible Conduct|publisher=Lawrence Erlbaum Associates, Publishers|isbn=9780805851175 }}&lt;/ref&gt; American psychological association offers a diplomate (post Ph.D. and licensed certification) in behavioral psychology.&lt;ref&gt;{{cite web|authors=Dowd, E.T.|year=2001|title=Board Certification (Diplomate) in Behavioral Psychology|journal=The Behavior Analyst Today|volume=2|issue=1|pages=l5–28|url=http://www.personal.kent.edu/~edowd/ABPP/diplomate.htm}}&lt;/ref&gt;

===The meaning of certification===
BACB is a private non-profit organization without governmental powers to regulate behavior analytic practice. While the BACB certification means that candidates have satisfied entry-level requirements in behavior analytic training, certificants may require a government license for independent practice when treating behavioral health or medical problems. Licensed certificants must operate within the scope of their license and must practice within their areas of expertise. Where the government regulates behavior analytic services unlicensed certificants must be supervised by a licensed professional and operate within the scope of their supervisor’s license when treating disorders. Unlicensed certificants who provide behavior analytic training for educational or optimal performance purposes do not require licensed supervision. Where the government does not regulate the treatment of medical or psychological disorders certificants should practice in accord with the laws of their state, province, or country. All certificants must practice within their personal areas of expertise.

===Licensure===
Recently, a move has occurred to license behavior analysts.&lt;ref name=Cautilli&gt;{{cite journal|authors=Cautilli, J.D., &amp; Weinberg, M.|year=2007|title=Editorial: To license or not to license? That is the question:  Or, if we make a profession, will they come?|journal=The Behavior Analyst Today|volume=8|issue=1|pages=1–8.[http://www.baojournal.com/]|doi=10.1037/h0100100}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.abapracticesig.org/pr01.htm|title=Proposed Regulation: Model Licensing Act for Behavior Analysts|year=2008|archiveurl=https://web.archive.org/web/20080905130810/http://www.abapracticesig.org/pr01.htm|deadurl=yes|archivedate= September 5, 2008}}&lt;/ref&gt; Licensure's purpose is to protect the public from employing unqualified practitioners.&lt;ref name=Hassert&gt;{{cite journal|authors=Hassert, D.L, Kelly, A.N., Pritchard, J.K. &amp; Cautilli, J.D.|year=2008|title=The Licensing of Behavior Analysts: Protecting the profession and the public|journal=Journal of Early and Intensive Behavior Intervention|volume=5|issue=2|pages=8–19|url=http://psycnet.apa.org/journals/eib/5/2/8.pdf&amp;productCode=pa|doi=10.1037/h0100415}}&lt;/ref&gt;

The model licensing act states that a person is a behavior analyst by training and experience.  The person seeking licensure must have mastered behavior analysis by achieving a master's degree in behavior analysis or related subject matter. Like all other master level licensed professions (see [[counseling]] and [[licensed professional counselor]]) the model act sets the standard for a master's degree. This requirement states that the person has achieved textbook knowledge of behavior analysis which can be then tested through the exam offered by the Behavior Analyst Certification Board or the one offered by the World Center for Behavior Analysis. It also requires an internship in which a behavior analysts works under another master or Ph.D. level behavior analyst for a period of one year (750 hours) with at least two hours/week of supervision. Finally, those 750 hours are considered tutelage time. After that, the behavior analyst must engage in supervised practice under a behavior analyst for a period of another 2 years (2,000 hours).

Once this process is complete, the person applies to a state board who ensures that he or she has indeed met the above conditions.  Once the person is licensed public protection is still monitored by the licensing board, which makes sure that the person receives sufficient ongoing education, and the licensing board investigates ethical complaints. A licensed behavior analyst would have equal training, knowledge, skills and abilities in their discipline as would a [[mental health counselor]] or [[marriage and family therapist]] in their discipline. In February 2008, [[Indiana]], [[Arizona]], [[Massachusetts]], [[Vermont]], [[Oklahoma]] and other states now have legislation pending to create licensure for behavior analysts. [[Pennsylvania]] was the first state in 2008 to license "behavior specialists" to cover behavior analysts. Arizona, less than three weeks later, became the first state to license "behavior analysts." Other states such as [[Nevada]] and [[Wisconsin]] also have passed behavior analytic licensure.

==Other countries==
Recently{{when|date=October 2013}} licensure efforts have occurred in [[Canada]] for behavior analysts.

==Professional organizations==
The [[Association for Behavior Analysis]] International has a special interest group for practitioner issues, which focuses on key issues related to licensing behavior analysts. In addition, they have a practice board and a policy board to handle legislative issues [http://www.abainternational.org/ ABA:I]. Finally, the association has recently put out its own model licensing act for behavior analysts.

Association for behavior analysis international serves as the core intellectual home for behavior analysts.&lt;ref name=Hassert/&gt;&lt;ref&gt;{{cite journal|authors=Twyman, J.S.|year=2007|title=A new era of science and practice in behavior analysis|journal=Association for Behavior Analysis International: Newsletter|volume=30|issue=3|pages=1–4}}&lt;/ref&gt; The Association for Behavior Analysis International sponsors 2 conferences per year – one in the U.S. and one international.

==See also==
* [[Professional practice of behavior analysis]]

==References==
{{Reflist}}

{{DEFAULTSORT:Licensed Behavior Analysts}}
[[Category:Mental health professionals]]
[[Category:Mental health in the United States]]
[[Category:Psychiatry-related fields]]
[[Category:Applied psychology]]
[[Category:Behavior modification|*]]
[[Category:Cognitive behavioral therapy]]
[[Category:Clinical psychology]]
[[Category:Behaviorism]]

[[de:Applied Behavior Analysis]]
[[fr:Analyse du comportement appliquée]]
[[nl:Toegepaste gedragsanalyse]]
[[pt:Profissional de saúde mental]]</text>
      <sha1>j82j8crzxriubsxjalkl0qmgc8qn6j5</sha1>
    </revision>
  </page>
  <page>
    <title>Marchetti's constant</title>
    <ns>0</ns>
    <id>7803002</id>
    <revision>
      <id>843534630</id>
      <parentid>841634551</parentid>
      <timestamp>2018-05-29T19:32:37Z</timestamp>
      <contributor>
        <username>FrescoBot</username>
        <id>9021902</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:FrescoBot/Links|link syntax]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3703">'''Marchetti's constant''' is the average time spent by a person for [[commuting]] each day, which is approximately one hour. The term is a misnomer, because [[Italian people|Italian]] [[physicist]] Cesare Marchetti himself attributes the "one hour" finding to transportation analyst and engineer Yacov Zahavi.&lt;ref name="mar94"&gt;[http://www.cesaremarchetti.org/archive/electronic/basic_instincts.pdf Marchetti, C., 1994: Anthropological Invariants in Travel Behavior, Technological Forecasting and Social Change , 47 :75–88, Internal Publication, International Institute for Applied Systems Analysis, Laxenburg, Austria]&lt;/ref&gt;

Marchetti posits that although forms of [[urban planning]] and [[transport]] may change, and although some live in villages and others in cities, people gradually adjust their lives to their conditions (including location of their homes relative to their workplace) such that the average travel time stays approximately constant.&lt;ref name="mar94"/&gt;&lt;ref name="Ausubel1998"&gt;[http://phe.rockefeller.edu/green_mobility/ Toward green mobility: the evolution of transport], Jesse H. Ausubel, Cesare Marchetti and Perrin Meyer, 1998 (accessed Nov 6, 2006); [http://phe.rockefeller.edu/TIP_transport/ The Evolution of Transport], April/May 2001, Jesse H. Ausubel and Cesare Marchetti. Includes observations on historical cities.&lt;/ref&gt; Ever since [[Neolithic]] times, people have kept the average time spent per day for travel the same, even though the distance may increase due to the advancements in the means of transportation.

A related concept is that of Zahavi, who also noticed that people seem to have a constant "travel time budget", that is, "a stable daily amount of time that people make available for travel."&lt;ref&gt;Metz, David, 2008: The Limits to Travel: How Far Will You Go?, 8, Earthscan, London&lt;/ref&gt; David Metz, former chief scientist at the Department of Transport, UK, cites data of average travel time in Britain drawn from the British National Travel Survey in support of Marchetti's and Zahavi's conclusions.&lt;ref&gt;Ibid.&lt;/ref&gt; The work casts doubt on the contention that investment in [[infrastructure]] saves travel time. Instead, it appears from Metz's figures that people invest travel time saved in travelling a longer distance,&lt;ref&gt;The point is also made in a 2009 paper by Yves Crozet: 'Economic Development and the Role of Travel time: The key concept of accessibility' published in Commissioned Papers for the 4th International Future Urban Transport Conference of the Volvo Research and Educational Foundations, Gothenburg, Sweden, April 19–21, 2009.&lt;/ref&gt; a particular example of [[Jevons paradox]] described by the [[Lewis–Mogridge position]]. Because of the constancy of travel times as well as induced travel, [[Robert Cervero]] has argued that the World Bank and other international aid agencies evaluate transportation investment proposals in developing and rapidly motorizing cities less on the basis of potential travel-time savings and more on the accessibility benefits they confer.&lt;ref&gt;Cervero, Robert, 2011: Beyond Travel-Time Savings: An Expanded Framework for Evaluating Urban Transport Projects, The International Bank for Reconstruction and Development/The World Bank, Department for International Development, Transport Research Support Program.[http://documents.worldbank.org/curated/en/466801468178764085/pdf/702060ESW0P1200s0in0Urban0Transport.pdf]&lt;/ref&gt;

==See also==
*[[Braess' paradox]]

==References==
{{Reflist|refs=}}

[[Category:Urban planning]]
[[Category:Urban geography]]
[[Category:Commuting]]
[[Category:Transport economics]]
[[Category:Transportation planning]]
[[Category:Sustainable transport]]


{{Planning-stub}}</text>
      <sha1>i2cdiuvlazmi4k9dmmuqu8o092sigq0</sha1>
    </revision>
  </page>
  <page>
    <title>Michelson stellar interferometer</title>
    <ns>0</ns>
    <id>7986136</id>
    <revision>
      <id>733525075</id>
      <parentid>613034228</parentid>
      <timestamp>2016-08-08T12:15:19Z</timestamp>
      <contributor>
        <username>Iridescent</username>
        <id>937705</id>
      </contributor>
      <minor/>
      <comment>/* top */[[WP:AWB/T|Typo fixing]], [[WP:AWB/T|typo(s) fixed]]: 100 inch → 100-inch using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1321">[[Image:Michelson stellar interferometer.svg|thumb|right|Scheme of the Michelson stellar interferometer]]
[[Image:Hooker interferometer.jpg|right|thumb|300px|A 20-foot (~6&amp;nbsp;meters) Michelson interferometer mounted on the frame of the 100-inch (~250&amp;nbsp;cm) [[Hooker Telescope]], 1920.]]

The '''Michelson stellar interferometer''' is one of the earliest [[astronomical interferometer]]s built and used. The interferometer was proposed by [[Albert A. Michelson]] in 1890, following a suggestion by [[Hippolyte Fizeau]].

The first such interferometer built was at the [[Mount Wilson observatory]], making use of its 100-inch (~250&amp;nbsp;centimeters) mirror.  It was used to make the first-ever measurement of a stellar diameter, by Michelson and [[Francis G. Pease]], when the diameter of [[Betelgeuse]] was measured in December 1920. The diameter was found to be 240&amp;nbsp;million&amp;nbsp;miles (~380&amp;nbsp;million&amp;nbsp;kilometers), about the size of the [[orbit]] of [[Mars]], or about 300 times larger than the [[Sun]].

==See also==
* [[History of astronomical interferometry]]
* [[Fizeau interferometer]]
* [[Michelson interferometer]]

==References==
* Michelson, A. A., and Pease, F. G. (1921). ''Astrophys. J.'' '''53''', 249–259.

{{optics-stub}}
[[Category:Observational astronomy]]
[[Category:Interferometers]]</text>
      <sha1>qa8s92phe9m4xc4h1ddf3ogyvpwt2q8</sha1>
    </revision>
  </page>
  <page>
    <title>Montreal Laboratory</title>
    <ns>0</ns>
    <id>16266461</id>
    <revision>
      <id>858893591</id>
      <parentid>843092062</parentid>
      <timestamp>2018-09-10T10:07:11Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9) ([[User:FA RotBot|FA RotBot]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36940">{{featured article}}

[[File:Canadian Prime Minister Mackenzie King, with President Franklin D Roosevelt, and Winston Churchill during the Quebec Conference, 18 August 1943. H32129.jpg|thumb|right|Canadian Prime Minister [[Mackenzie King]] with U. S. President [[Franklin D Roosevelt]] and British Prime Minister [[Winston Churchill]] during the [[Quebec Conference, 1943|Quebec Conference]], 18 August 1943, at which the mechanism for cooperation on [[Tube Alloys]] was agreed upon]]
The '''Montreal Laboratory''' in [[Montreal|Montreal, Quebec]], Canada, was established by the [[National Research Council (Canada)|National Research Council]] of Canada during [[World War II]] to undertake [[nuclear technology|nuclear research]] in collaboration with the [[Nuclear weapons and the United Kingdom|United Kingdom]], and to absorb some of the scientists and work of the [[Tube Alloys]] nuclear project in Britain. It became part of the [[Manhattan Project]], and designed and built some of the world's first [[nuclear reactor]]s.

After the [[Fall of France]], some French scientists escaped to Britain with their stock of [[heavy water]]. They were temporarily installed in the [[Cavendish Laboratory]] at the [[University of Cambridge]], where they worked on reactor design. The [[MAUD Committee]] was uncertain whether this was relevant to the main task of Tube Alloys, that of building an [[atomic bomb]], although there remained a possibility that a reactor could be used to breed [[plutonium]], which might be used in one. It therefore recommended that they be relocated to the United States, and co-located with the Manhattan Project's reactor effort. Due to American concerns about security (many of the scientists were foreign nationals) and patent claims by the French scientists and [[Imperial Chemical Industries]] (ICI), it was decided to relocate them to Canada instead.

The Canadian government agreed to the proposal, and the Montreal Laboratory was established in a house belonging to [[McGill University]]; it moved to permanent accommodation at the [[Université de Montréal]] in March 1943. The first eight laboratory staff arrived in Montreal at the end of 1942. These were [[Bertrand Goldschmidt]] and [[Pierre Auger]] from France, [[George Placzek]] from [[Czechoslovakia]], S. G. Bauer from Switzerland, [[Friedrich Paneth]] and [[Hans von Halban]] from Austria, and R. E. Newell and F. R. Jackson from Britain. The Canadian contingent included [[George Volkoff]], [[Bernice Weldon Sargent]] and [[George Laurence]], and promising young Canadian scientists such as [[J. Carson Mark]], [[P. R. Wallace|Phil Wallace]] and [[Leo Yaffe]].

Although Canada was a major source of [[uranium ore]] and heavy water, these were controlled by the Americans. Anglo-American cooperation broke down, denying the Montreal Laboratory scientists access to the materials they needed to build a reactor. In 1943, the [[Quebec Agreement]] merged Tube Alloys with the American Manhattan Project. The Americans agreed to help build the reactor. Scientists who were not British subjects left, and [[John Cockcroft]] became the new director of the Montreal Laboratory in May 1944. The [[Chalk River Laboratories]] opened in 1944, and the Montreal Laboratory was closed in July 1946. Two reactors were built at Chalk River. The small [[ZEEP]] went critical on 5 September 1945, and the larger [[NRX]] on 21 July 1947. NRX was for a time the most powerful [[research reactor]] in the world.

==Early nuclear research in Canada==
[[File:C.D. Howe, wartime.jpg|thumb|right|alt=Head and shoulders of a man in a suit and tie|[[C. D. Howe]], [[Minister of Munitions and Supply]]]]
Canada has a long history of involvement with nuclear research, dating back to the pioneering work of [[Ernest Rutherford]] at [[McGill University]] in 1899.&lt;ref name="Canada's role"&gt;{{cite press release |url=https://www.cns-snc.ca//media/history/1945Aug13PressReleasePart1.pdf |accessdate=19 May 2016 |title=Canada's Role in Atomic Bomb Drama |author=Department of Reconstruction |date=13 August 1945 }}&lt;/ref&gt; In 1940, [[George Laurence]] of the [[National Research Council (Canada)|National Research Council]] (NRC) began experiments in [[Ottawa]] to measure [[neutron capture]] and [[nuclear fission]] in [[uranium]] to demonstrate the feasibility of a [[nuclear reactor]]. For that purpose, he obtained {{convert|450|kg}} of [[uranium dioxide]] in paper bags from the [[Eldorado Mine (Northwest Territories)|Eldorado Mine]] at [[Port Radium]] in the [[Northwest Territories]]. For a [[neutron moderator]], he used [[carbon]] in the form of [[petroleum coke]]. This was placed with the bags of uranium oxide in a large wooden bin lined with [[paraffin wax]], another neutron moderator. A neutron source was added, and a [[Geiger counter]] used to measure [[radioactivity]].&lt;ref name="Early Years"&gt;{{cite web |url=https://www.ieee.ca/millennium/nuclear_power/NuclEnerg.PDF |title=Early Years of Nuclear Energy Research in Canada |first=George C. |last=Laurence |authorlink=George C. Laurence  |publisher=IEEE Canada |accessdate=19 May 2016 }}&lt;/ref&gt;

The experiments continued in 1942, but were ultimately unsuccessful; the problems posed by impurities in the coke and uranium oxide had not been fully appreciated, and as a result too many neutrons were captured. But Laurence's efforts attracted some attention, and in the summer of 1940 he was visited by [[Ralph H. Fowler|R. H. Fowler]],&lt;ref name="Early Years" /&gt; the British scientific liaison officer in Canada.{{sfn|Hewlett|Anderson|1962|p=33}} This was followed by a visit from [[John Cockcroft]] of the British [[Tizard Mission]] to the United States in the autumn. They brought news of the similar research being carried out under the supervision of the [[MAUD Committee]] in Britain and the [[National Defense Research Committee]] (NDRC) in the United States.&lt;ref name="Early Years" /&gt;{{sfn|Gowing|1964|pp=64–65}}

Fowler became the channel of communication between the NDRC and its counterparts in Britain and Canada.{{sfn|Hewlett|Anderson|1962|p=257}} Through him, Laurence obtained an introduction to [[Lyman J. Briggs]], the chairman of the NDRC's [[S-1 Uranium Committee]], who supplied copies of American studies.&lt;ref name="Early Years" /&gt;{{sfn|Gowing|1964|pp=64–65}} On returning to England, Cockcroft arranged through [[Henry Mond, 2nd Baron Melchett|Lord Melchett]] for Laurence to receive a $5,000 grant to continue his research. This payment was made by [[Imperial Chemical Industries]] (ICI) through a Canadian subsidiary. It had the desired side effect of impressing the Canadian authorities with the importance of Laurence's work.{{sfn|Gowing|1964|p=67}}

==French connection==
Laurence had chosen to use carbon instead of [[heavy water]] because it was cheaper and more readily available.&lt;ref name="Early Years" /&gt; A team of scientists in France that included [[Hans von Halban]], [[Lew Kowarski]], and [[Francis Perrin]] had been conducting similar experiments since 1939. By 1940, they had decided to use heavy water as a moderator, and through the French [[Minister of Armaments (France)|Minister of Armaments]] obtained about {{convert|185|kg}} from the [[Norsk Hydro]] hydroelectric station at [[Vemork]] in Norway. After the [[Fall of France]], they had escaped to Britain with their stock of heavy water. They were temporarily installed in the [[Cavendish Laboratory]] at the [[University of Cambridge]] but, believing that Britain would soon fall as well, were eager to relocate to the United States or Canada.{{sfn|Gowing|1964|pp=49–51}}&lt;ref name="The Role of the French Scientists"&gt;{{cite web |url=https://cns-snc.ca/media/history/fifty_years/goldschmidt.html |title=How it All Began in Canada – The Role of the French Scientists |first=Bertrand |last=Goldschmidt |authorlink=Bertrand Goldschmidt |publisher=[[Canadian Nuclear Society]] |accessdate=6 May 2016 }}&lt;/ref&gt;

Canada was an alternative source of heavy water. [[Cominco]] had been involved in heavy water research since 1934, and produced it at its smelting plant in [[Trail, British Columbia]]. On 26 February 1941, the NRC inquired about its ability to produce heavy water. This was followed on 23 July by a letter from [[Hugh Stott Taylor|Hugh Taylor]], a British-born scientist working at [[Princeton University]], on behalf of the [[Office of Scientific Research and Development]] (OSRD). Taylor offered a NDRC contract to produce {{convert|2000|lb}}, for which the NDRC was prepared to pay $5 per pound for low-grade and $10 for high-grade heavy water. At the time it was selling for up to $1,130 per pound.&lt;ref name="Cominco" /&gt;

Cominco's president, [[Selwyn G. Blaylock]], was cautious. There might be no post-war demand for heavy water, and the [[patent]] on the process was held by Albert Edgar Knowles, so a profit-sharing agreement would be required. In response, Taylor offered $20,000 for plant modifications.&lt;ref name="Cominco"&gt;{{cite journal |title=Cominco and the Manhattan Project |first=C. D. |last=Andrews |pp=51–62|journal=BC Studies |issn=0005-2949 |issue=11 |date=Fall 1971 |url=http://ojs.library.ubc.ca/index.php/bcstudies/article/viewFile/710/756 |accessdate=21 May 2016 }}&lt;/ref&gt;&lt;ref&gt;{{US patent|2044704}}&lt;/ref&gt; There the matter rested until 6 December, when Blaylock had a meeting with the British physicist G. I. Higson, who informed him that Taylor had become discouraged with Cominco, and had decided to find another source of heavy water. Blaylock invited Taylor to visit Trail, which he did from 5 to 8 January 1942. The two soon found common ground. Blaylock agreed to produce heavy water at Trail, and quickly secured approval from the Chairman of the Board, Sir [[Edward Wentworth Beatty|Edward Beatty]]. A contract was signed on 1 August 1942. The heavy water project became known as the [[P-9 Project]] in October 1942.&lt;ref name="Cominco" /&gt;

The French scientists made good progress on the design of an [[aqueous homogeneous reactor]], but there were doubts that their work was relevant to the main task of the British [[Tube Alloys]] project, that of building an [[atomic bomb]], and resources were tightly controlled in wartime Britain. There was a possibility that a reactor could be used to breed [[plutonium]], but its use in a bomb seemed a remote possibility.{{sfn|Gowing|1964|pp=71–75}} The MAUD Committee therefore felt that they should relocate to America. It made sense to pool resources, and America had advantages, notably access to materials such as heavy water. American scientists such as [[Henry D. Smyth]], Harold Urey and Hugh Taylor urged that the Cambridge team be sent to America. On the other hand, American officials had concerns about security, since only one of the six senior scientists in the Cambridge group was British, and about French patent claims.{{sfn|Gowing|1964|pp=134–135}}&lt;ref&gt;{{cite web |url=http://blog.nuclearsecrecy.com/2012/03/05/70-years-ago-vannevar-bush-worries-about-french-patents/ |title=70 years ago: Vannevar Bush worries about French Patents |publisher=Restricted Data |first=Alex |last=Wellerstein |date=5 March 2012 |accessdate=22 July 2016 }}&lt;/ref&gt; These included patents on controlling nuclear chain reactions, enriching uranium, and using [[deuterium]] as a neutron moderator. There were also two patent applications in conjunction with [[Egon Bretscher]] and [[Norman Feather]] on the production and use of plutonium.{{sfn|Gowing|1964|pp=74–75}} [[George Paget Thomson|George Thomson]], the chairman of the MAUD Committee, suggested a compromise: relocating the team to Canada.{{sfn|Gowing|1964|pp=134–135}}

==Establishment==
The next step was to broach the matter with the Canadians. The [[Lord President of the Council|Lord President]], Sir [[John Anderson, 1st Viscount Waverley|John Anderson]], as the [[Minister (government)|minister]] responsible for Tube Alloys, wrote to the British [[High Commissioner (Commonwealth)|High Commissioner]] to Canada, [[Malcolm MacDonald]], who had been involved in Tube Alloys negotiations with Canada regarding [[Eldorado Mining and Refining|Eldorado]]'s uranium mine at Port Radium and its refinery in [[Port Hope, Ontario]].{{sfn|Gowing|1964|pp=187–188}} On 19 February 1942, MacDonald, Thomson and Wallace Akers, the director of Tube Alloys, met with [[Jack Mackenzie|C. J. Mackenzie]], the president of the NRC, who enthusiastically supported the proposal. The following day he took them to see [[C. D. Howe]], the [[Minister of Munitions and Supply]].&lt;ref name="Early Years" /&gt;

[[File:Montreal Group.jpg|thumb|left|Montreal Laboratory staff in 1944]]
Howe cabled Anderson expressing the Canadian government's agreement in principle, but requesting a more detailed appraisal of the cost of the proposed laboratory. Sir John Anderson replied that he envisaged a laboratory with about 30 scientists and 25 laboratory assistants, of whom 22 scientists and 6 laboratory assistants would be sent from Britain. The estimated running cost was £60,000 per annum. He agreed that the costs and salaries would be divided between the British and Canadian governments, but the British share would come from a billion-dollar war gift from Canada. The Canadians found this acceptable. Howe and Mackenzie then travelled to London to finalise arrangements for the laboratory's governance. It was agreed that it would be run by a Policy Committee consisting of Howe and MacDonald and be administered by and funded through the NRC, with research directed by a Technical Committee chaired by Halban.{{sfn|Gowing|1964|pp=187–188}}

The Canadians decided that the new laboratory should be located in Montreal, where housing accommodation was easier to find than in wartime Ottawa. They hoped to have everything ready by 1 January 1943, but negotiations for laboratory space fell through.{{sfn|Gowing|1964|p=190}} A search then commenced for an alternative location. [[Bertrand Goldschmidt]], a French scientist who was already in Canada, ran into [[Henri Laugier]], a French biologist who had been president of the ''[[Centre national de la recherche scientifique]]'' before the Fall of France, when he had escaped to Canada. Laugier suggested that they acquire some unused wings of a new building at the [[Université de Montréal]], where he was now teaching. These had been earmarked for a medical school, but had never been equipped due to a lack of funds.&lt;ref name="The Role of the French Scientists" /&gt; The {{convert|200|m2|adj=on}} space was acquired, but considerable work was required to convert it into a laboratory, and it could not be made ready before mid-February 1943.{{sfn|Gowing|1964|p=190}} [[Ernest Cormier]], the university architect, drew up the plans.&lt;ref name="The Role of the French Scientists" /&gt;

The first eight staff arrived in Montreal at the end of 1942. These were Goldschmidt and [[Pierre Auger]] from France, [[George Placzek]] from [[Czechoslovakia]], S. G. Bauer from Switzerland, [[Friedrich Paneth]] and Halban from Austria, and R. E. Newell and F. R. Jackson from Britain. The [[Battle of the Atlantic]] was still raging, and men and equipment, which travelled separately, were at risk from German [[U-boat]]s. The scientists occupied a house at 3470 Simpson Street in downtown Montreal that belonged to McGill University.&lt;ref name="Early Years" /&gt; This soon became so crowded that bathrooms were used for offices, with the bath tubs used to store papers and books.{{sfn|Gowing|1964|p=190}} They were relieved to move to the more spacious accommodation at the Université de Montréal in March.{{sfn|Gowing|1964|p=190}} The laboratory grew to over 300 staff, about half of whom were Canadians recruited by Laurence.&lt;ref name="Early Years" /&gt;

Placzek became head of the theoretical physics division. Kowarski was designated to be the head of the experimental physics division, but there was a personality clash with Halban, and Kowarski did not wish to accept what he saw as a subordinate position under Halban. At this point, many other scientists said that they would not go without Kowarski, but Sir [[Edward Victor Appleton|Edward Appleton]], the [[permanent secretary]] of the British [[Department of Scientific and Industrial Research (United Kingdom)|Department of Scientific and Industrial Research]], of which the Tube Alloys was a part, managed to persuade them to go. Kowarski remained at Cambridge, where he worked for [[James Chadwick]]. Auger became head of the experimental physics division instead.&lt;ref name="The Role of the French Scientists" /&gt;{{sfn|Gowing|1964|p=191}} Paneth became head of the chemistry division. Two other scientists that had escaped from France joined the laboratory: the French chemist [[Jules Guéron]], who had been working for [[Free France]] at Cambridge,{{sfn|Gowing|1964|p=190}} and [[Bruno Pontecorvo]], an Italian scientist who had worked with [[Enrico Fermi]] in Italy before the war.{{sfn|Rhodes|1995|pp=128–129}}

For the Canadian contingent, Laurence and Mackenzie set out to recruit some top nuclear physicists, of whom there were few in Canada. The first was [[George Volkoff]] at the [[University of British Columbia]], who had worked with [[Robert Oppenheimer]] on the physics of [[neutron star]]s. They also tried to recruit [[Harry Thode]] from [[McMaster University]], but found that Harold Urey from the [[Manhattan Project]]'s [[SAM Laboratories]] was also interested in Thode's expertise in testing heavy water with [[mass spectrography]], and had made a more attractive offer. A compromise was reached whereby Thode did work for the Montreal Laboratory, but remained at McMaster University. Promising young Canadian scientists were also recruited, including [[J. Carson Mark]], [[P. R. Wallace|Phil Wallace]] and [[Leo Yaffe]].&lt;ref name="Early Years" /&gt;{{sfn|Avery|1998|pp=183–184}}

==Research==
[[File:ZEEP1945.jpg|thumb|right|[[ZEEP]] building at the [[Chalk River Laboratories]] c. 1945]]
The Montreal Laboratory investigated multiple avenues of reactor development. One was a homogeneous reactor, in which a uranium compound was dissolved in heavy water to form a [[slurry]], or a "mayonnaise" as the Montreal team called it. This offered various advantages for cooling, control and the ability to draw off plutonium that was produced. Paneth, Goldschmidt and others experimented with methods of preparing such a uranium compound, but none could be found with the required density. They considered using [[enriched uranium]], but it was unavailable. Attention then turned to a heterogeneous reactor, in which a lattice of uranium metal rods were immersed in heavy water. While much less heavy water would be required, there was a danger that the water would decompose into deuterium and oxygen—a potentially explosive combination. There was great interest in [[breeder reactor]]s, which could breed plutonium from uranium or [[uranium-233]] from [[thorium]], as it was believed that uranium was scarce. A process was devised for separating the uranium from thorium.&lt;ref name="Early Years" /&gt;

To build a working nuclear reactor, the Montreal Laboratory depended on the Americans for heavy water from Trail, which was under American contract, but this was not forthcoming. An American request for Halban to come to New York to discuss heavy water with Fermi and Urey was turned down by the British, and the Americans brought cooperation to a standstill.{{sfn|Jones|1985|p=235}} By June 1943 work at the Montreal Lab had come to a halt. Morale was low and the Canadian Government proposed cancelling the project.&lt;ref name="Early Years" /&gt; The British government seriously considered going it alone on developing nuclear weapons, despite the cost and the expected length of the project.{{sfn|Howard|1972|pp=589–592}} In August 1943, Canadian Prime Minister [[Mackenzie King]] hosted the [[Quebec Conference, 1943|Quebec Conference]], at which [[Winston Churchill]] and [[Franklin D. Roosevelt]] came together, and agreed to resume cooperation. The [[Quebec Agreement]] subsumed Tube Alloys into the Manhattan Project, and established the [[Combined Policy Committee]], on which Canada was represented by Howe, to control the Manhattan Project.{{sfn|Hewlett|Anderson|1962|pp=277–280}}

While some aspects of cooperation resumed quickly, it took longer to finalize the details with respect to the Montreal Laboratory. [[Brigadier General (United States)|Brigadier General]] [[Leslie Groves]] (the director of the Manhattan Project), Chadwick (now the head of the [[British contribution to the Manhattan Project|British Mission to the Manhattan Project]]), and Mackenzie negotiated recommendations, which were approved by the Combined Policy Committee on 13 April 1944. A final agreement was spelt out on 20 May. Under it, the Americans would assist with the construction of a heavy water reactor in Canada, and would provide technical assistance with matters such as corrosion and the effects of radiation on materials. They would not provide details about plutonium or plutonium chemistry, although irradiated uranium slugs would be made available for the British to work it out for themselves.{{sfn|Hewlett|Anderson|1962|pp=281–284}} The Americans had already built their own heavy water reactor, [[Chicago Pile-3]], which went critical in May 1944.{{sfn|Hewlett|Anderson|1962|pp=306–307}} The September 1944 [[Quebec Agreement#Background and negotiations|Hyde Park Agreement]] extended both commercial and military cooperation into the post-war period.{{sfn|Gowing|1964|pp=340–342}}

Hans von Halban had proved to be an unfortunate choice as he was a poor administrator, and did not work well with Mackenzie or the NRC.{{sfn|Avery|1998|pp=184–185}} The Americans saw him as a security risk, and objected to the French atomic patents claimed by the Paris Group (in association with ICI).{{sfn|Gowing|1964|pp=206–207, 209–214}} In April 1944 a Combined Policy Committee meeting at Washington agreed that Canada would build a heavy water reactor. Scientists who were not British subjects would leave, and Cockcroft became the new director of the Montreal Laboratory in May 1944.&lt;ref name="The Role of the French Scientists" /&gt; [[Edgar William Richard Steacie|E. W. R. Steacie]] became assistant director and head of the Chemistry division when Paneth left. Volkoff eventually succeeded Placzek as head of the Theoretical Physics division. Halban remained as head of the nuclear physics division.&lt;ref name="Early Years" /&gt;

[[File:NRX_Pile_Building_and_ZEEP_Building-_Cooling_Tanks_1945.jpg|thumb|left|[[NRX]] and [[ZEEP]] buildings at the [[Chalk River Laboratories]]]]
After the [[Liberation of Paris]] in August 1944, the French scientists wanted to go home. Auger had already returned to London to join the French Scientific Mission in April 1944. Halban returned on a visit to London and Paris in November 1944, where he saw [[Frédéric Joliot-Curie]] for the first time since leaving France. While he maintained that he did not divulge any nuclear secrets to his previous boss (although he had discussed patent rights), Halban was not allowed to work or to leave North America for a year, although he left the Montreal Laboratory in April 1945. In 1946 he settled in England.{{sfn|Gowing|1964|pp=292–296}} [[Bernice Weldon Sargent|B. W. Sargent]] then became Head of the nuclear physics division.&lt;ref name="Early Years" /&gt; Cockcroft arranged for Goldschmidt, Guéron and Kowarski to remain until June 1945, later extended until the end of 1945. Goldschmidt was willing to stay longer, and Cockcroft wanted to keep him, but Groves insisted that he should go, and, in the interest of Allied harmony, he did. All the French scientists had left by January 1946.{{sfn|Gowing|1964|pp=292–296}}

On 24 August 1944, the decision was taken to build a small reactor to test the group's calculations relating to such matters as lattice dimensions, sheathing materials, and [[control rod]]s, before proceeding with the full-scale [[NRX]] reactor.&lt;ref name="Early Years" /&gt; With Halban gone, Kowarski joined the Laboratory, and was given responsibility for the small reactor,{{sfn|Close|2015|pp=102–104}}{{sfn|Hewlett|Anderson|1962|pp=282–284}} which he named [[ZEEP]], for Zero Energy Experimental Pile. He was assisted in the design by Charles Watson-Munro from New Zealand, and [[George Klein (inventor)|George Klein]] and Don Nazzer from Canada.&lt;ref name="Early Years" /&gt; Building reactors in downtown Montreal was out of the question; the Canadians selected, and Groves approved, a site at [[Chalk River]], Ontario, on the south bank of the [[Ottawa River]] some {{convert|110|mi}} northwest of Ottawa.{{sfn|Jones|1985|pp=246–247}}

The Americans fully supported the reactor project with information and visits.{{sfn|Avery|1998|p=200}} Groves loaned the Montreal Laboratory {{convert|19|ST}} of heavy water and {{convert|5|ST}} of pure uranium metal for the reactor, and samples of pure and irradiated uranium and thorium to develop the extraction process. The irradiated materials came from the Manhattan Project's [[X-10 Graphite Reactor]] at the [[Clinton Engineer Works]] at Oak Ridge, Tennessee. Some {{convert|10|ST}} of machined pure uranium rods was sold outright to Canada. He also supplied instruments, drawings and technical information, provided expertise from American scientists,{{sfn|Manhattan District|1947|p=9.5}} and opened a liaison office in Montreal headed by Major H. S. Benbow. The American physicist [[William Weldon Watson]] from the [[Metallurgical Laboratory]] and chemist John R. Huffman from the SAM Laboratories were assigned to it.{{sfn|Hewlett|Anderson|1962|pp=282–284}}{{sfn|Manhattan District|1947|p=9.6}} They were succeeded by [[George Weil]] in November 1945.{{sfn|Avery|1998|p=200}}{{sfn|Manhattan District|1947|p=9.6}}&lt;ref name="New York Times"&gt;{{cite news |newspaper=[[The New York Times]] |url=https://www.nytimes.com/1995/07/06/obituaries/george-leon-weil-87-physicist-who-helped-make-atomic-bomb.html |title=George Leon Weil, 87, Physicist Who Helped Make Atomic Bomb |first=Wolfgang |last=Saxon |date=6 July 1995 |accessdate=8 March 2015 }}&lt;/ref&gt; Benbow was succeeded by Major P. Firmin in December 1945, who in turn was replaced by Colonel A. W. Nielson in February 1946.{{sfn|Manhattan District|1947|p=9.7}}

The [[Chalk River Laboratories]] opened in 1944, and the Montreal Laboratory was closed in July 1946.&lt;ref name="Early Years" /&gt; ZEEP went critical on 5 September 1945,{{sfn|Close|2015|pp=102–104}} becoming the first operating nuclear reactor outside the United States. Using {{convert|5|ST}} of heavy water and {{convert|3.5|ST}} of uranium metal, it could operate continuously at 3.5 W, or for brief periods at 30 to 50 W.{{sfn|Manhattan District|1947|p=9.23}} The larger NRX followed on 21 July 1947.{{sfn|Close|2015|pp=102–104}} With five times the [[neutron flux]] of any other reactor, it was the most powerful [[research reactor]] in the world.&lt;ref name="Fidecaro"&gt;{{cite web |url=http://www.df.unipi.it/~rossi/PONTE_5.pdf |date=4 December 1996 |title=Bruno Pontecorvo: From Rome To Dubna (personal recollections) |first=Giuseppe |last=Fidecaro |publisher=[[Università di Pisa]] |accessdate=15 April 2016 }}&lt;/ref&gt; Originally designed in July 1944 with an output of 8 MW, the power was raised to 10 MW through design changes such as replacing uranium rods clad in stainless steel and cooled by heavy water with aluminium-clad rods cooled by light water.{{sfn|Manhattan District|1947|pp=9.9–9.10}}

By the end of 1946, the Montreal Laboratory was estimated to have cost US$22,232,000, excluding the cost of the heavy water. The NRX reactor provided Britain, the United States and Canada with a source of fissile plutonium and uranium-233. It also provided a means of efficiently producing medical isotopes like [[phosphorus-32]], research facilities that for a time were superior to those in the United States, and a wealth of technical information related to reactor design and operation.{{sfn|Manhattan District|1947|pp=9.26–9.28}} With the passage of the Canadian Atomic Energy Act of 1946, the responsibility for the Chalk River Laboratories passed to the [[Atomic Energy Control Board]].{{sfn|Manhattan District|1947|p=9.7}}

==Atomic spies==
On 5 September 1945, [[Igor Gouzenko]], a [[cipher|cypher]] clerk at the [[Soviet Union]]'s embassy in Ottawa, and his family [[defection|defected]] to Canada. He brought with him copies of cables detailing [[GRU|Soviet intelligence]] (GRU) espionage activities in Canada. Agents included Alan Nunn May, who secretly supplied tiny samples of uranium-233 and [[uranium-235]] to GRU agent Pavel Angelov in July 1945; [[Fred Rose (politician)|Fred Rose]], a [[Parliament of Canada|member of parliament]]; and NRC scientists [[Israel Halperin]], Edward Mazerall and Durnford Smith.{{sfn|Rhodes|1995|pp=183–187}}{{sfn|Close|2015|p=136}} Pontecorvo, who defected to the Soviet Union in 1950, has long been suspected of having been involved in espionage. No evidence that he was a Soviet agent has ever been established,{{sfn|Close|2015|pp=308–309}} but the GRU obtained samples of uranium and blueprints of the NRX, for which Nunn May could not have been the source, and Pontecorvo remains the prime suspect.{{sfn|Close|2015|pp=143–143}} When the spy ring became public knowledge in February 1946, the Americans became more cautious about sharing information with Britain and Canada.{{sfn|Gowing|Arnold|1974|p=98}}

==Cooperation ends==
[[File:TrumanAttleeKing1945.jpg|thumb|right|President [[Harry Truman]] and prime ministers [[Clement Attlee]] and [[Mackenzie King]] boarding {{USS|Sequoia|presidential yacht|6}} for discussions about nuclear weapons, November 1945]]
The Montreal Laboratory had been a fruitful and successful international venture, although the Canadians had on occasion been resentful of British actions that were perceived as high-handed and insensitive. One such action came in November 1945 when the British government suddenly announced that Cockcroft had been appointed the head of the new [[Atomic Energy Research Establishment]] in Britain without any prior consultation and at a time when the NRX reactor was still under construction. Cockcroft did not depart Canada until September 1946, but it was a sure sign of waning British interest in collaboration with Canada. The British suggested he be replaced by the British physicist [[Bennett Lewis]], who was eventually appointed, but only after the Canadian-born [[Walter Zinn]] turned the job down.{{sfn|Gowing|Arnold|1974|pp=131–146}}

Anglo-American cooperation did not long survive the war. Roosevelt died on 12 April 1945, and the Hyde Park Agreement was not binding on subsequent administrations.{{sfn|Paul|2000|pp=72–73}} The [[Special Relationship]] between Britain and the United States "became very much less special".{{sfn|Gowing|Arnold|1974|p=93}} The British government had trusted that America would share nuclear technology, which the British considered a joint discovery. On 9 November 1945, Mackenzie King and British Prime Minister [[Clement Attlee]] went to Washington, D.C. to confer with President [[Harry Truman]] about future cooperation in nuclear weapons and nuclear power.{{sfn|Gowing|Arnold|1974|pp=73–77}} A Memorandum of Intention that replaced the Quebec Agreement made Canada a full partner.{{sfn|Hewlett|Anderson|1962|p=468}} The three leaders agreed that there would be full and effective cooperation, but British hopes for a resumption of cooperation on nuclear weapons were in vain.{{sfn|Gowing|Arnold|1974|p=92}} The Americans soon made it clear that cooperation was restricted to basic scientific research.{{sfn|Paul|2000|pp=80–83}}

At the Combined Policy Committee meeting in February 1946, without prior consultation with Canada, the British announced their intention to build a [[GLEEP|graphite-moderated nuclear reactor]] in the United Kingdom. An outraged Howe told Canadian ambassador [[Lester B. Pearson]] to inform the Committee that nuclear cooperation between Britain and Canada was at an end. The Canadians had been given what they deemed assurances that the Chalk River Laboratories would be a joint enterprise, and regarded the British decision as a breach of faith. Anglo-American cooperation largely ended in April 1946 when Truman declared that the United States would not assist Britain in the design, construction or operation of a plutonium production reactor. The Americans had agreed that such a facility could be built in Canada, but the British were not willing to be dependent on Canada for the supply of [[fissile]] material.{{sfn|Gowing|Arnold|1974|pp=131–146}} 
{{clear}}

==Notes==
{{reflist|30em}}

==References==
* {{cite book |last=Avery |first=Donald |year=1998 |title=The Science of War: Canadian Scientists and Allied Military Technology |location=Toronto |publisher=University of Toronto Press  |isbn=978-0-8020-5996-3 |oclc=38885226 |ref=harv }}
* {{cite book |last=Close |first=Frank |authorlink=Frank Close |year=2015 |title=Half-Life: The Divided Life of Bruno Pontecorvo, Physicist or Spy |publisher=Basic Books  |location=New York |isbn=978-0-465-06998-9 |oclc=897001600 |ref=harv}}
* {{cite book |last=Gowing |first=Margaret |authorlink=Margaret Gowing  |year=1964 |title=Britain and Atomic Energy 1939–1945  |publisher=Macmillan |location=London |oclc=3195209 |ref=harv }}
* {{cite book | last1 = Gowing | first1 = Margaret | first2 = Lorna | last2 = Arnold | authorlink2=Lorna Arnold | year = 1974 | title=Independence and Deterrence: Britain and Atomic Energy, 1945–1952, Volume 1, Policy Making | publisher= Macmillan| location = London | isbn = 0-333-15781-8 | oclc = 611555258 | ref=harv }}
* {{cite book |last=Hewlett |first=Richard G. |authorlink=Richard G. Hewlett |last2=Anderson |first2=Oscar E.  |year=1962 |title=The New World, 1939–1946 |publisher=Pennsylvania State University Press|isbn=0-520-07186-7 |location=University Park |url=https://www.governmentattic.org/5docs/TheNewWorld1939-1946.pdf |accessdate=26 March 2013|oclc=637004643 |ref=harv  }}
* {{cite book |last=Howard |first=Michael |authorlink=Michael Howard (historian) |title=Grand Strategy, IV, August 1942 – September 1943 |year=1972 |location=London |publisher=HMSO |isbn=978-0-11-630075-1 |oclc=24415425 |ref=harv }}
* {{cite book |last=Jones |first=Vincent |title=Manhattan: The Army and the Atomic Bomb  |year=1985 |publisher=United States Army Center of Military History |location=Washington, D.C.|url=http://www.history.army.mil/html/books/011/11-10/CMH_Pub_11-10.pdf |accessdate=25 August 2013 |oclc=10913875 |ref=harv }}
* {{cite book |url=http://www.osti.gov/includes/opennet/includes/MED_scans/Book%20I%20-%20General%20-%20Vol.%204-Chapters%209-10.pdf |author=Manhattan District |title=Manhattan District History, Book I, Volume 4, Chapter 9 – Assistance to the Canadian Pile Project |publisher=Manhattan District |year=1947 |location=Washington, D.C. |oclc=889323140 |ref=harv}}
* {{cite book |last=Paul |first=Septimus H. |year=2000 |title=Nuclear Rivals: Anglo-American Atomic Relations, 1941–1952 |location=Columbus, Ohio |publisher=Ohio State University Press |isbn= 978-0-8142-0852-6 |oclc=43615254 |ref = harv }}
* {{cite book |last = Rhodes |first = Richard |authorlink = Richard Rhodes | year = 1995 | title = Dark Sun: The Making of the Hydrogen Bomb | publisher = Simon &amp; Schuster | location = New York | isbn = 0-684-80400-X |oclc=32509950 |ref=harv}}

==External links==
* {{cite web |url=http://avalon.law.yale.edu/wwii/q002.asp |title=The Quebec Conference: Agreement Relating to Atomic Energy |publisher=[[Yale University]] |accessdate=9 December 2016 }}
* {{cite web |url=http://www.oecd-nea.org/dbprog/mmrw/index.html |title=Canadian and British Early Atomic Energy Reports (1940–1946) |publisher=[[Nuclear Energy Agency]] |accessdate=24 May 2016 |archive-url=https://web.archive.org/web/20160921080944/http://www.oecd-nea.org/dbprog/mmrw/index.html |archive-date=21 September 2016 |dead-url=yes |df=dmy-all }}
{{Manhattan Project}}
{{UdeM}}

{{portal bar|Canada|History of Science|Nuclear technology|United Kingdom|World War II}}
{{Coord|45|30|17|N|73|36|46|W|display=title|type:edu}}
{{Use dmy dates|date=May 2016}}

[[Category:National Research Council of Canada]]
[[Category:Nuclear research institutes]]
[[Category:Research institutes in Canada]]
[[Category:Nuclear history of the United Kingdom]]
[[Category:History of the Manhattan Project]]
[[Category:Nuclear technology in Canada]]
[[Category:Université de Montréal]]
[[Category:History of Montreal]]
[[Category:Canada in World War II]]
[[Category:1942 establishments in Canada]]
[[Category:1946 disestablishments in Canada]]
[[Category:United Kingdom–United States relations]]
[[Category:Canada–United Kingdom relations]]
[[Category:Canada–United States relations]]</text>
      <sha1>ar4h77cbrxyytjbzu92z5x7cds9ipx3</sha1>
    </revision>
  </page>
  <page>
    <title>Neomodern</title>
    <ns>0</ns>
    <id>1430291</id>
    <revision>
      <id>867589821</id>
      <parentid>867589817</parentid>
      <timestamp>2018-11-06T18:25:29Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/96.85.143.11|96.85.143.11]] to version by 95.253.203.9. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3534167) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3121">{{About|the architectural movement|the philosophical movement|Neomodernism}}
[[File:Bay Adelaide first tower nearing completion - cropped.jpg|right|thumb|200px|The [[Bay Adelaide Centre]] in Toronto. When first proposed in the 1980s the building had a strongly postmodernist design. The final design, completed in 2009, adopted the neomodern style.]]
[[File:Neomodernist facade in Pretoria.JPG|right|thumb|200px|Building in [[Pretoria]] with a neomodern architectural design.]]
'''Neomodern''' or '''neomodernist''' art is a reaction to the complexity of [[postmodern architecture]] and [[eclecticism]], seeking greater simplicity.

==Architecture==
Neomodern architecture continues [[Modern architecture|modernism]] as a dominant form of architecture in the 20th and 21st centuries, especially in corporate offices. It tends to be used for certain segments of buildings. Many residential houses tend to embrace [[Postmodern architecture|postmodern]], [[New Classical Architecture|new classical]] and [[neo-eclectic]] styles, for instance, and major monuments today most often opt for [[starchitect]] inspired uniqueness. 
Neomodern architecture shares many of the basic characteristics of modernism. Both reject classical ornamentation, decorations, and deliberate ambitions to continue pre-modernist traditions. Neomodernist buildings, like modernist ones, are designed to be largely monolithic and functional.

==Artist group==
The neomodern artist group was founded in 1997 by [[Guy Denning]]&lt;ref name=sherwin&gt;Sherwin, Brian. [http://www.myartspace.com/blog/2006/11/art-space-talk-guy-denning.html "Art Space Talk: Guy Denning"], myartspace.com, 14 November 2006. Retrieved 31 May 2008.&lt;/ref&gt; on the premise that the diversity of contemporary art was being stifled by the state supported art institutions and organisations. The group have no common style or media but there is a bias towards figurative painting. Original artists listed: [[James Butler (artist)|Jim Butler]], [[David Cobley]], [[Emily Cole]], [[Mark Demsteader]], [[Guy Denning]], [[Ian Francis]], [[Juno Doran]], [[Ghislaine Howard]], [[David Jamin (artist)|Jamin]], [[Maya Kulenovic]], [[Mark Stephen Meadows]], [[Antony Micallef]], [[Motorboy]], [[Carol Peace]], [[Graeme Robbins]], [[Harry Simmonds]], [[Tom Wilmott]], [[Franklin Torres]], [[Kit Wise]] and [[Claire Zakiewicz]].

==See also==
* [[Metamodernism]]
* [[Remodernism]]
* [[Vancouverism]]

==Notes and references==
{{reflist}}

==External links==
* [https://web.archive.org/web/20070930093518/http://guydenning.org/neomodern/a_new_critical_aesthetic.htm Neomodern group manifesto] 
* [http://www.stuckism.com/remod.html Remodernist Manifesto] 

{{-}}
{{Criticism of postmodernism}}
{{Modern architecture}}


[[Category:Neomodern architecture| ]]
[[Category:Remodernism|*]]
[[Category:Metamodernism|*]]
[[Category:Architectural styles]]
[[Category:Art movements]]
[[Category:Modernism]]
[[Category:Modernist architecture|+]]
[[Category:Postmodernism|+]]
[[Category:Postmodern architecture|+]]
[[Category:20th-century architectural styles]]
[[Category:21st-century architectural styles]]</text>
      <sha1>157ni3lcm5pzlxkzgxqitwbsapt2r1n</sha1>
    </revision>
  </page>
  <page>
    <title>Network analyzer (AC power)</title>
    <ns>0</ns>
    <id>38433617</id>
    <revision>
      <id>823221880</id>
      <parentid>802546610</parentid>
      <timestamp>2018-01-30T23:42:01Z</timestamp>
      <contributor>
        <username>Wtshymanski</username>
        <id>139104</id>
      </contributor>
      <comment>sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24323">{{distinguish|Network analyzer (electrical)}}
From 1929&lt;ref&gt;Thomas Parke Hughes ''Networks of power: electrification in Western society, 1880-1930'' JHU Press, 1993 {{ISBN|0-8018-4614-5}} page 376&lt;/ref&gt; to the late 1960s, large [[alternating current]] power systems were modelled and studied on '''AC network analyzers''' (also called '''alternating current network calculators''' or '''AC calculating boards''')  or '''transient network analyzers'''. These special-purpose [[analog computer]]s were an outgrowth of the DC calculating boards used in the very earliest power system analysis. By the middle of the 1950s, fifty network analyzers were in operation.&lt;ref&gt;Charles Eames, Ray Eames ''A Computer Perspective: Background to the Computer Age'',Harvard University Press, 1990 0674156269, page 117&lt;/ref&gt; AC network analyzers were much used for [[Power flow study|power flow studies]], short circuit calculations, and system stability studies, but were ultimately replaced by numerical solutions running on digital computers. While the analyzers could provide real-time simulation of events, with no concerns about numeric stability of algorithms, the analyzers were costly, inflexible, and limited in the number of buses and lines that could be simulated.&lt;ref&gt;M.A. Laughton, D.F Warne (ed),''Electrical Engineer's Reference Book (16th Edition)'', Elsevier, 2003 {{ISBN|978-1-60119-452-7}} pages 368-369&lt;/ref&gt;  Eventually powerful digital computers replaced analog network analyzers for practical calculations, but analog physical models for studying electrical transients are still in use.

== Calculating methods ==
As AC power systems became larger at the start of the 20th century, with more interconnected devices, the problem of calculating the expected behavior of the systems became more difficult. Manual methods were only practical for systems of a few sources and nodes. The complexity of practical problems made manual calculation techniques too laborious or inaccurate to be useful. Many mechanical aids to calculation were developed to solve problems relating to network power systems.

DC calculating boards used resistors and DC sources to represent an AC network. A resistor was used to model the inductive reactance of a circuit, while the actual series resistance of the circuit was neglected. The principle disadvantage was the inability to model complex impedances. However, for short-circuit fault studies, the effect of the resistance component was usually small. DC boards served to produce results accurate to around 20% error, sufficient for some purposes.

Artificial lines were used to analyze transmission lines. These carefully constructed replicas of the distributed inductance, capacitance and resistance of a full-size line were used to investigate propagation of impulses in lines and to validate theoretical calculations of transmission line properties. An artificial line was made by winding layers of wire around a glass cylinder, with interleaved sheets of tin foil, to give the model proportionally the same distributed inductance and capacitance as the full-size line.  Later, lumped-element approximations of transmission lines were found to give adequate precision for many calculations.

Laboratory investigations of the stability of multiple-machine systems were constrained by the use of direct-operated indicating instruments (voltmeters, ammeters, and wattmeters). To ensure that the instruments negligibly loaded the model system, the machine power level used was substantial. Some workers in the 1920s used three-phase model generators rated up to 600 kVA and 2300 volts to represent a power system. General Electric developed model systems using generators rated at 3.75 kVA.&lt;ref&gt;H.P. Kuehni, R.G. Lorraine, ''A New A-C Network Analyzer'', ''Transactions AIEE'', February 1938 volume 57 page 67&lt;/ref&gt; It was difficult to keep multiple generators in synchronism, and the size and cost of the units was a constraint.  While transmission lines and loads could be accurately scaled down to laboratory representations, rotating machines could not be accurately miniaturized and keep the same dynamic characteristics as full-sized prototypes; the ratio of machine inertia to machine frictional loss did not scale.&lt;ref&gt;David A. Mindell, ''Between Human and Machine: Feedback, Control and Computing Before Cybernetics'', JHU Press, 2004 {{ISBN|0801880572}}
 pp.149-150&lt;/ref&gt;

==Scale model==
A network analyzer system was essentially a [[scale model]] of the electrical properties of a specific power system. Generators, transmission lines, and loads were represented by miniature electrical components with scale values in proportion to the modeled system.&lt;ref&gt;[[Edward Kimbark|Edward Wilson Kimbark]], ''Power System Stability'',Wiley-IEEE ,1948, {{ISBN|0-7803-1135-3}} page 64 and following&lt;/ref&gt; Model components were interconnected with flexible cords to represent the [[schematic|schematic diagram]] of the modeled system.

Instead of using miniature rotating machines, accurately calibrated phase-shifting transformers were built to simulate electrical machines.  These were all energized by the same source (at local power frequency or from a motor-generator set) and so inherently maintained synchronism. The phase angle and terminal voltage of each simulated generator could be set using rotary scales on each phase-shifting transformer unit. Using the [[per-unit system]] allowed values to be conveniently interpreted without additional calculation.

To reduce the size of the model components, the network analyzer often was energized at a higher frequency than the 50&amp;nbsp;Hz or 60&amp;nbsp;Hz [[utility frequency]]. The operating frequency was chosen to be high enough to allow high-quality inductors and capacitors to be made, and to be compatible with the available indicating instruments, but not so high that stray capacitance would affect results. Many systems used either 440&amp;nbsp;Hz, or 480&amp;nbsp;Hz, provided by a motor-generator set, to reduce size of model components. Some systems used 10&amp;nbsp;kHz, using capacitors and inductors similar to those used in radio electronics.

Model circuits were energized at relatively low voltages to allow for safe measurement with adequate precision. The model base quantities varied by manufacturer and date of design; as amplified indicating instruments became more common, lower base quantities were feasible.  Model voltages and currents started off around 200 volts and 0.5 amperes in the MIT analyzer, which still allowed directly driven (but especially sensitive) instruments to be used to measure model parameters. The later machines used as little as 50 volts and 50 mA, used with amplified indicating instruments. By use of the [[per-unit system]], model quantities could be readily transformed into the actual system quantities of voltage, current, power or impedance. A watt measured in the model might correspond to hundreds of kilowatts or megawatts in the modeled system. One hundred volts measured on the model might correspond to one per-unit, which could represent, say, 230,000 volts on a transmission line or 11,000 volts in a distribution system.  Typically, results accurate to around 2% of measurement could be obtained.&lt;ref&gt;Institution of Engineering and Technology , ''Power System Protection, Volumes 1-4'',  1995 {{ISBN|978-1-60119-889-1}} pages 216-220&lt;/ref&gt; Model components were single-phase devices, but using the [[symmetrical components]] method, unbalanced three-phase systems could be studied as well.

A complete network analyzer was a system that filled a large room; one model was described as four bays of equipment, spanning a U-shaped arrangement 26 feet (8 metres) across. Companies such as [[General Electric]] and [[Westinghouse Electric (1886)|Westinghouse]] could provide consulting services based on their analyzers; but some large electrical utilities operated their own analyzers. The use of network analyzers allowed quick solutions to difficult calculation problems, and allowed problems to be analyzed that would otherwise be uneconomic to compute using manual calculations. Although expensive to build and operate, network analyzers often repaid their costs in reduced calculation time and expedited project schedules.&lt;ref&gt;Aad Blok, Greg Downey (ed) ''Uncovering Labour in Information Revolutions, 1750-2000'', Cambridge University Press, 2003 {{ISBN|0521543533}}, pp. 76-80&lt;/ref&gt; For example, a stability study might indicate if a transmission line should have larger or differently spaced conductors to preserve stability margin during system faults; potentially saving many miles of cable and thousands of insulators.

Network analyzers did not directly simulate the dynamic effects of load application to machine dynamics (torque angle, and others).  Instead, the analyzer would be used to solve dynamic problems in a stepwise fashion, first calculating a load flow, then adjusting the phase angle of the machine in response to its power flow, and re-calculating the power flow.

In use, the system to be modelled would be represented as a [[One-line diagram|single line diagram]] and all the impedances of lines and machines would be scaled to model values on the analyzer. A plugging diagram would be prepared to show the interconnections to be made between the model elements. The circuit elements would be interconnected by patch cables. The model system would be energized, and measurements taken at the points of interest in the model; these could be scaled up to the values in the full-scale system.&lt;ref name=HarderGHN&gt;http://www.ieeeghn.org/wiki/images/e/ec/Chapter_6-Calculating_Power_(Edwin_L._Harder).pdf Calculating Power, retrieved 2013 Feb 26&lt;/ref&gt;

==The MIT network analyzer==
The network analyzer installed at [[Massachusetts Institute of Technology]] (MIT) grew out of a 1924 thesis project by Hugh H. Spencer and [[Harold Locke Hazen]], investigating a power system modelling concept proposed by [[Vannevar Bush]]. Instead of miniature rotating machines, each generator was represented by a transformer with adjustable voltage and phase, all fed from a common source. This eliminated the poor accuracy of models with miniature machines.  The 1925 publication of this thesis attracted the attention at General Electric, where [[Robert Doherty (college president)|Robert Doherty]] was interested in modelling problems of system stability. He asked Hazen to verify that the model could accurately reproduce the behavior of machines during load changes.

Design and construction was carried out jointly by General Electric and MIT. When first demonstrated in June 1929, the system had eight phase-shifting transformers to represent synchronous machines. Other elements included 100 variable line resistors, 100 variable reactors, 32 fixed capacitors, and 40 adjustable load units. The analyzer was described in a 1930 paper by H.L Hazen, O.R. Schurig and M.F. Gardner. The base quantities for the analyzer were 200 volts, and 0.5 amperes. Sensitive portable thermocouple-type instruments were used for measurement.&lt;ref&gt;H.L Hazen, O.R. Schurig and M.F. Gardner. ''The M.I.T. Network Analyzer Design and Application to Power System Problems'', ''Transactions AIEEE'', July 1930 pp.1102-1113&lt;/ref&gt; The analyzer occupied four large panels, arranged in a U-shape, with tables in front of each section to hold measuring instruments. While primarily conceived as an educational tool, the analyzer saw considerable use by outside firms, who would pay to use the device.  [[American Gas and Electric Company]], the [[Tennessee Valley Authority]], and many other organizations studied problems on the MIT analyzer in its first decade of operation.  In 1940 the system was moved and expanded to handle more complex systems.

By 1953 the MIT analyzer was beginning to fall behind the state of the art.  Digital computers were first used on power system problems as early as "[[Whirlwind I|Whirlwind]]" in 1949. Unlike most of the forty other analyzers in service by that point, the MIT instrument was energized at 60&amp;nbsp;Hz, not 440 or 480&amp;nbsp;Hz, making its components large, and expansion to new types of problems difficult. Many utility customers had bought their own network analyzers. The MIT system was dismantled and sold to the [[Puerto Rico Electric Power Authority|Puerto Rico Water Resources Authority]] in 1954.&lt;ref&gt;Karl L. Wildes, Nilo A. Lindgren  ''A Century of Electrical Engineering and Computer Science at MIT, 1882-1982'' MIT Press 1985 {{ISBN|0262231190}}, pp. 100-104&lt;/ref&gt;

== Commercial manufacturers ==

By 1947, fourteen network analyzers had been built at a total cost of about two million US dollars. General Electric built two full-scale network analyzers for its own work and for services to its clients. Westinghouse built systems for their internal use and provided more than 20 analyzers to utility and university clients. After the Second World War analyzers were known to be in use in France, the UK, Australia, Japan, and the Soviet Union. Later models had improvements such as centralized control of switching, central measurement bays, and chart recorders to automatically provide permanent records of results.

General Electric's Model 307 was a miniaturized AC network analyzer with four generator units and a single electronically amplified metering unit. It was targeted at utility companies to solve problems too large for hand computation but not worth the expense of renting time on a full size analyzer.  Like the Iowa State College analyzer, it used a system frequency of 10&amp;nbsp;kHz instead of 60&amp;nbsp;Hz or 480&amp;nbsp;Hz, allowing much smaller radio-style capacitor and inductors to be used to model power system components. The 307 was cataloged from 1957 and had a list of about 20 utility, educational and government customers. In 1959 its list price was $8,590.&lt;ref&gt;http://ed-thelen.org/comp-hist/GE-Computer_Department_Data_Book_1960.pdf ''GE-Computer_Department_Data_Book_1960'', page 150-152, retrieved 2013 Feb 7&lt;/ref&gt;

In 1953, the [[Metropolitan Edison Company]] and a group of six other electrical companies purchased a new Westinghouse AC network analyzer for installation at the [[Franklin Institute]] in Philadelphia.  The system, described as the largest ever built,  cost $400,000.&lt;ref&gt;https://news.google.com/newspapers?nid=2202&amp;dat=19530204&amp;id=RVMmAAAAIBAJ&amp;sjid=nf8FAAAAIBAJ&amp;pg=830,3636416 Gettysburg Times ''7 firms will put analyzer in institute'', February 4, 1953&lt;/ref&gt;

In Japan, network analyzers were installed starting in 1951. The [[Yokogawa Electric]] company introduced a model energized at 3980&amp;nbsp;Hz starting in 1956.&lt;ref&gt;http://www2.iee.or.jp/ver2/honbu/14-magazine/log/2004/2004_08a_03.pdf Historical Trends and Interactive Relationship in Establishment of the
of Symmetrical Coordinates and AC Network Analyzer retrieved 2013 Feb 26&lt;/ref&gt;

{|  class="wikitable"
|+ '''AC Network Analyzers '''&lt;ref name=AIEE49&gt;W. A. Morgan, F. S. Rothe, J.J. Winsness ''An Improved A-C Network Analyzer'', ''AIEE Transactions'', Volume 68, 1949 pp. 891-896&lt;/ref&gt;
|-
!  Owner
!  Year
!  Frequency
!  Generator Units
!  Total circuits
!  Remarks
|-
| [[Massachusetts Institute of Technology|MIT]]
| 1929
| 60
| 16
| 209
| First system in commercial use
|-
| [[Purdue University]]
| 1942
| 440
| 16
| 383
| Reconstructed after 1929 initial installation
|-
| [[Pennsylvania Railroad]]
| 1932
| 440
| 6
| 296
| 
|-
| [[Commonwealth Edison Company]]
| 1932
| 440
| 6
| 186
|
|-
| General Electric Company
| 1937
| 480
| 12
| 313
| 
|-
| Public Service Electric and Gas Co of New Jersey
| 1938
| 480
| 8
| 163
| 
|-
| [[Tennessee Valley Authority]]
| 1938
| 440
| 18
| 270
| 
|-
| [[Bonneville Power Administration]]
| 1939
| 480
| 18
| 326
| 
|-
| [[São Paulo Tramway, Light and Power Company]]
| 1940
| 440
| 6
| 98
| Brazil
|-
| [[Potomac Electric Power Company]]
| 1941
| 440
| 6
| 120
| 
|-
| [[Ontario Hydro|Hydro Electric Power Commission]]
| 1941
| 440
| 15
| 259
| Ontario, Canada
|-
| Public Service Co. of Oklahoma
| 1941
|  60
|   7
| 185
| 
|-
| [[Westinghouse Electric Corporation]]
| 1942
| 440
|  22
| 384
| 
|-
| [[Illinois Institute of Technology]]
| 1945
| 440
|  12
| 236
| Cost $90,000, sponsored by 17 electrical utilities&lt;ref&gt;http://fultonhistory.com/newspaper%202/Auburn%20NY%20Citizen%20Advertiser/Auburn%20NY%20Citizen%20Advertiser%201945.pdf/Newspaper%20Auburn%20NY%20Citizen%20Advertiser%201945%20-%200253.PDF  "$90,000 Electric Brain Installed at Illinois Tech"&lt;/ref&gt;
|-
| [[Iowa State College]]
| 1946
| 10,000
|  4
| 64
| Continued in commercial use until the early 1970s.
|-
| [[Texas A&amp;M University|Texas A and M College]]
| 1947
| 440
|  18
| 344
| Operated until 1971 when it was sold to [[Lower Colorado Power Authority]]
|-
| City of [[Los Angeles]]
| 1947
| 440
|  18
| 266
|
|-
| [[University of Kansas]]
| 1947
|  60
|  8
| 133
|
|-
| [[Associated Electrical Industries|Associated Electrical Industries, Ltd.]]
| 1947
| 500
|  12
| 274
| United Kingdom
|-
| [[Georgia School of Technology]]
| 1948
| 440
|  14
| 322
| Donated by Georgia Power Corp, cost $300,000&lt;ref&gt;http://www.gtri.gatech.edu/history/our-forefathers/gerald-rosselot retrieved 2013 Feb 26&lt;/ref&gt;
|-
| [[Pacific Gas and Electric Company]]
| 1948
| 440
|  14
| 324
|
|-
| [[Constellation Energy|Consolidated Gas, Electric Light and Power Co. of Baltimore]]
| 1948
| 440
|  16
| 240
|
|-
| [[United States Bureau of Reclamation]]
| 1948
| 480
|  12
| 240
|
|-
| General Electric Company (No. 2)
| 1949
| 480
|  12
| 392
|
|-
| [[University of California]]
| 1949
| 480
|  6
| 113
|
|-
| [[Indian Institute of Science]]
| 1949
| 480
|  16
| 338
|
|-
| [[State Electricity Commission of Victoria]]
| 1950
| 450
| 12 
| --
| Westinghouse make, in utility service to 1967, 10 kW motor generator input, &lt;ref&gt; https://collections.museumvictoria.com.au/articles/10180 Bonwick, B. (2011) ''The Network Analyser - a detailed description in Museums Victoria Collections'' Accessed 04 August 2017 &lt;/ref&gt;
|-
| [[Franklin Institute]]
| 1953
| 440
|  --
| ---
| Westinghouse make, largest system delivered to that date, cost $400,000 in 1953 dollars
|-
| [[Cornell University]]
| 1953
| 440
|  18
| ---
|Decommissioned mid 1960's&lt;ref&gt;http://www2.cit.cornell.edu/computer/history/Linke.html Cornell computing histories, retrieved 2013 Feb 26&lt;/ref&gt;
|}

==Other applications==

===Transient analyzer===
A "transient network analyzer" was an analog model of a transmission system especially adapted to study high-frequency transient surges (such as those due to lightning or switching), instead of AC power frequency currents. Similarly to an AC network analyzer, they represented apparatus and lines with scaled inductances and resistances. A synchronously driven switch repeatedly applied a transient impulse to the model system, and the response at any point could be observed on an [[oscilloscope]] or recorded on an oscillograph. Some transient analyzers are still in use for research and education, sometimes combined with digital [[protective relay]]s or recording instruments.&lt;ref&gt;http://www.cpri.in/about-us/departmentsunits/power-system-division-psd/transient-network-analyser.html
TNA at Central Power Research Institute, India retrieved 2013 Feb 26&lt;/ref&gt;

===Anacom===
The Westinghouse ''Anacom'' was an AC-energized electrical analog computer system used extensively for problems in mechanical design, structural elements, lubrication oil flow, and various transient problems including those due to lightning surges in electric power transmission systems. The excitation frequency of the computer could be varied. The Westinghouse Anacom constructed in 1948 was used up to the early 1990s for engineering calculations; its original cost was $500,000. The system was periodically updated and expanded; by the 1980s the Anacom could be run through many simulation cases unattended, under the control of a digital computer that automatically set up initial conditions and recorded the results. Westinghouse built a replica Anacom for [[Northwestern University]], sold an Anacom to [[ABB Group|ABB]], and twenty or thirty similar computers by other makers were used around the world.&lt;ref name=HarderGHN/&gt;

===Physics and chemistry===
Since the multiple elements of the AC network analyzer formed a powerful analog computer, occasionally problems in physics and chemistry were modeled (by such researchers as [[Gabriel Kron]] of [[General Electric]]), in the late 1940s prior to the ready availability of general-purpose digital computers.&lt;ref&gt;http://www.metaphorik.de/12/tympasdalouka.pdf retrieved 2008 Jan 26&lt;/ref&gt; Another application was water flow in water distribution systems. The forces and displacements of a mechanical system could be readily modelled with the voltages and currents of a network analyzer, which allowed easy adjustment of properties such as the stiffness of a spring by, for example, changing the value of a capacitor. &lt;ref name=JS13/&gt;

===Structures===
The [[David Taylor Model Basin]] operated an AC network analyzer from the late 1950s until the mid-1960s. The system was used on problems in ship design. An electrical analog of the structural properties of a proposed ship, shaft, or other structure could be built, and tested for its vibrational modes.  Unlike AC analyzers used for power systems work, the exciting frequency was made continuously variable so that mechanical resonance effects could be investigated.

==Decline and obsolescence==
Even during the Depression and the Second World War, many network analyzers were constructed because of their great value in solving calculations related to electric power transmission. By the mid 1950s, about thirty analyzers were available in the United States, representing an oversupply.  Institutions such as MIT could no longer justify operating analyzers as paying clients barely covered operating expenses. &lt;ref name=JS13&gt; James S. Small, ''The Analogue Alternative: The Electronic Analogue Computer in Britain and the USA, 1930-1975'', Routledge, 2013, {{ISBN|1134699026}}, pages 35-40&lt;/ref&gt;  

Once digital computers of adequate performance became available, the solution methods developed on analog network analyzers were migrated to the digital realm, where plugboards, switches and meter pointers were replaced with punch cards and printouts. The same general-purpose digital computer hardware that ran network studies could easily be dual-tasked with business functions such as payroll. Analog network analyzers faded from general use for load-flow and fault studies, although some persisted in transient studies for a while longer. Analog analyzers were dismantled and either sold off to other utilities, donated to engineering schools, or scrapped.

The fate of a few analyzers illustrates the trend. The analyzer purchased by [[American Electric Power]] was replaced by digital systems in 1961, and donated to [[Virginia Tech]]. The Westinghouse network analyzer purchased by the [[State Electricity Commission of Victoria]], Australia in 1950 was taken out of utility service in 1967 and donated to the Engineering department at [[Monash University]]; but by 1985, even instructional use of the analyzer was no longer practical and the system was finally dismantled.&lt;ref&gt;https://collections.museumvictoria.com.au/items/1763754 Photograph of part of a Westinghouse network analyzer, retrieved 2017 Aug 3&lt;/ref&gt;

One factor contributing to the obsolescence of analog models was the increasing complexity of interconnected power systems. Even a large analyzer could only represent a few machines, and perhaps a few score lines and busses. Digital computers routinely handled systems with thousands of busses and transmission lines.

==See also==
* [[Network analyzer (electrical)]]
* [[Power system protection]]
* [[Differential analyser]]
* [[Prospective short-circuit current]]

==References==
&lt;references/&gt;

==External links==
*[http://etd.nd.edu/ETD-db/theses/available/etd-11172011-202226/unrestricted/MayoLA112011D.pdf] Lee Allen Mayo, thesis ''Simulation without replication'', University of Notre Dame 2011, pp.&amp;nbsp;52–101 discusses use of network analyzers for theoretical calculations

[[Category:Computer-related introductions in 1929]]
[[Category:Electrical engineering]]
[[Category:Analog computers]]</text>
      <sha1>hn2izcte5hmvnelwzfi55xm22ztl9f7</sha1>
    </revision>
  </page>
  <page>
    <title>Oil platform</title>
    <ns>0</ns>
    <id>163806</id>
    <revision>
      <id>871519306</id>
      <parentid>870814372</parentid>
      <timestamp>2018-12-01T17:10:34Z</timestamp>
      <contributor>
        <username>Xanzzibar</username>
        <id>35592</id>
      </contributor>
      <comment>image formatting, cut dead/spammy/less-useful external links, organize see also items</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40113">{{short description|Large offshore structure with oil drilling and related facilities}}
{{more citations needed|date=July 2013}}
[[File:Off_Shore_Drilling_Rig,_Santa_Barbara,_CA,_6_December,_2011.JPG|thumb|An oil drilling platform off the coast of Santa Barbara, CA - 6 December 2011]]
[[File:Oil platform P-51 (Brazil).jpg|thumb|Oil platform P-51 off the [[Brazil]]ian coast is a [[semi-submersible platform]].]] 
[[File:11-09-fotofluege-cux-allg-25a.jpg|thumb|Oil platform [[Mittelplate]] in the North Sea]]

An '''oil platform''', '''offshore platform''', or '''offshore drilling rig''' is a large structure with facilities for [[well drilling]] to explore, extract, store, process [[petroleum]] and [[natural gas]] which lies in rock formations beneath the seabed. In many cases, the platform contains facilities to house the workforce as well.

Most commonly, oil platforms engage in activities on the [[continental shelf]], though they can also be used in lakes, inshore waters and inland seas.

Depending on the circumstances,&lt;ref&gt;{{Cite journal|last=Ronalds|first=BF|year=2005|title=Applicability ranges for offshore oil and gas production facilities|url=http://www.sciencedirect.com/science/article/pii/S095183390500050X|journal=Marine Structures|volume=18 |issue=3|pages=251–263|via=Elsevier ScienceDirect|doi=10.1016/j.marstruc.2005.06.001}}&lt;/ref&gt; the platform may be [[Fixed Platform|fixed]] to the ocean floor, may consist of an [[artificial island]], or may [[Floating oil production system|float]]. Remote [[subsea]] wells may also be connected to a platform by flow lines and by [[Umbilical cable|umbilical]] connections. These sub-sea solutions may consist of one or more subsea wells, or of one or more manifold centres for multiple wells.

Offshore drilling presents environmental challenges, both from the produced hydrocarbons and the materials used during the drilling operation. Controversies include the ongoing [[US offshore drilling debate|U.S. offshore drilling debate]].&lt;ref&gt;Compton, Glenn, "[http://thebradentontimes.com/reasons-not-to-drill-for-oil-offshore-of-florida-p19415-137.htm 10 Reasons Not to Drill for Oil Offshore of Florida]", ''The Bradenton Times'', Sunday, January 14, 2018&lt;/ref&gt;

There are many different types of facilities from which offshore drilling operations take place. These include bottom founded drilling rigs ([[Jackup rig|jackup barges]] and swamp barges), combined drilling and production facilities either bottom founded or floating platforms, and deepwater mobile offshore drilling units (MODU) including semi-submersibles and drillships.  These are capable of operating in water depths up to {{convert|3000|m|ft}}. In shallower waters the mobile units are anchored to the seabed, however in deeper water (more than {{convert|1500|m|ft}}) the [[semisubmersible]]s or [[drillship]]s are maintained at the required drilling location using [[dynamic positioning]].

==History==
[[File:Gulf Offshore Platform.jpg|thumb|upright|Offshore platform, [[Gulf of Mexico]]]]
Around 1891, the first submerged oil wells were drilled from platforms built on piles in the fresh waters of the [[Grand Lake St. Marys]] (a.k.a. Mercer County Reservoir) in [[Ohio]]. The wide but shallow reservoir was built from 1837 to 1845 to provide water to the [[Miami and Erie Canal]].

Around 1896, the first submerged oil wells in salt water were drilled in the portion of the [[Summerland Oil Field|Summerland field]] extending under the [[Santa Barbara Channel]] in [[California]]. The wells were drilled from piers extending from land out into the channel.

Other notable early submerged drilling activities occurred on the Canadian side of [[Lake Erie]] since 1913  and [[Caddo Lake]] in [[Louisiana]] in the 1910s. Shortly thereafter, wells were drilled in tidal zones along the [[Gulf Coast of the United States|Gulf Coast]] of [[Texas]] and Louisiana. The [[Goose Creek Oil Field|Goose Creek field]] near [[Baytown, Texas]] is one such example. In the 1920s, drilling was done from concrete platforms in [[Lake Maracaibo]], [[Venezuela]].

The oldest offshore well recorded in Infield's offshore database is the [[Bibiheybət|Bibi Eibat]] well which came on stream in 1923 in [[Azerbaijan]].&lt;ref&gt;{{cite web|url=http://www.members.tripod.com/azmsa/oil.html|title=Oil in Azerbaijan|publisher=|accessdate=20 April 2015}}&lt;/ref&gt; Landfill was used to raise shallow portions of the [[Caspian Sea]].

In the early 1930s, [[Texaco|the Texas Company]] developed the first mobile steel barges for drilling in the brackish coastal areas of the gulf.

In 1937, [[Pure Oil Company]] (now [[Chevron Corporation]]) and its partner [[Superior Oil Company]] (now part of [[ExxonMobil Corporation]]) used a fixed platform to develop a field in {{convert|14|ft|m}} of water, one mile (1.6&amp;nbsp;km) offshore of [[Calcasieu Parish, Louisiana]].

In 1938, Humble Oil built  a mile-long wooden trestle with railway tracks into the sea at McFadden Beach on the Gulf of Mexico, placing a derrick at its end - this was later destroyed by a hurricane.&lt;ref&gt;{{cite journal|last1=Morton|first1=Michael Quentin|date=June 2016|title=Beyond Sight of Land: A History of Oil Exploration in the Gulf of Mexico|url=https://www.academia.edu/25960555/Beyond_Sight_of_Land_Oil_A_History_of_Oil_Exploration_in_the_Gulf_of_Mexico_2016_|journal=GeoExpro|volume=30|issue=3|pages=60–63|accessdate=8 November 2016}}&lt;/ref&gt;

In 1945, concern for American control of its offshore oil reserves caused President [[Harry Truman]] to issue an Executive Order unilaterally extending American territory to the edge of its continental shelf, an act that effectively ended the [[3-mile limit]] "[[freedom of the seas]]" regime.

In 1946, Magnolia Petroleum (now [[ExxonMobil]]) drilled at a site {{convert|18|mi|km}} off the coast, erecting a platform in {{convert|18|ft|m}} of water off [[St. Mary Parish, Louisiana]].

In early 1947, Superior Oil erected a drilling/production platform in {{convert|20|ft|m|abbr=on}} of water some 18 miles{{vague|which miles?|date=February 2010}} off [[Vermilion Parish, Louisiana]]. But it was [[Kerr-McGee]] Oil Industries (now [[Anadarko Petroleum Corporation]]), as operator for partners [[Phillips Petroleum]] ([[ConocoPhillips]]) and [[Stanolind Oil &amp; Gas]] ([[BP]]), that completed its historic Ship Shoal Block 32 well in October 1947, months before Superior actually drilled a discovery from their Vermilion platform farther offshore. In any case, that made Kerr-McGee's well the first oil discovery drilled out of sight of land.&lt;ref&gt;Ref accessed 02-12-89 by technical aspects and coast mapping. [[Kerr-McGee]]&lt;/ref&gt;&lt;ref name="project-redsand"&gt;[http://www.project-redsand.com/ Project Redsand&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

The British [[Maunsell Forts]] constructed during [[World War II]] are considered the direct predecessors of modern offshore platforms. Having been pre-constructed in a very short time, they were then floated to their location and placed on the shallow bottom of the [[Thames]] and the [[Mersey]] estuary.&lt;ref name="project-redsand" /&gt;&lt;ref&gt;[http://www.azer.com/aiweb/categories/magazine/ai112_folder/112_articles/112_chronology.html 11.2 Azerbaijan's Oil History Brief Oil Chronology since 1920  Part 2 by Mir-Yusif Mir-Babayev&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

In 1954, the first [[jackup rig|jackup oil rig]] was ordered by [[Zapata Oil]]. It was designed by [[R. G. LeTourneau]] and featured three electro-mechanically-operated lattice type legs. Built on the shores of the [[Mississippi river]] by the LeTourneau Company, it was launched in December 1955, and christened 'Scorpion'. The Scorpion was put into operation in May 1956 off [[Port Aransas]], Texas. It was lost in 1969.&lt;ref&gt;http://iadc.org/dcpi/dc-septoct05/Sept05-anniversary.pdf&lt;/ref&gt;&lt;ref&gt;http://petrowiki.org/History_of_offshore_drilling_units&lt;/ref&gt;&lt;ref&gt;https://www.youtube.com/watch?v=4ibvuWmF7Dc&lt;/ref&gt;

When offshore drilling moved into deeper waters of up to {{convert|30|m|ft}}, fixed platform rigs were built, until demands for drilling equipment was needed in the {{convert|100|ft|m}} to {{convert|120|m|ft}} depth of the Gulf of Mexico, the first [[Jackup rig|jack-up rigs]] began appearing from specialized offshore drilling contractors such as forerunners of ENSCO International.

The first [[semi-submersible]] resulted from an unexpected observation in 1961. [[Blue Water Drilling Company]] owned and operated the four-column submersible Blue Water Rig No.1 in the Gulf of Mexico for [[Shell Oil Company]]. As the pontoons were not sufficiently buoyant to support the weight of the rig and its consumables, it was towed between locations at a draught midway between the top of the pontoons and the underside of the deck. It was noticed that the motions at this draught were very small, and Blue Water Drilling and Shell jointly decided to try operating the rig in the floating mode. The concept of an anchored, stable floating deep-sea platform had been designed and tested back in the 1920s by [[Edward Robert Armstrong]] for the purpose of operating aircraft with an invention known as the 'seadrome'. The first purpose-built drilling [[semi-submersible]] ''Ocean Driller'' was launched in 1963. Since then, many semi-submersibles have been purpose-designed for the drilling industry mobile offshore fleet.

The first offshore [[drillship]] was the ''CUSS 1'' developed for the [[Mohole]] project to drill into the Earth's crust.

As of June, 2010, there were over 620 mobile offshore drilling rigs (Jackups, semisubs, drillships, barges) available for service in the competitive rig fleet.&lt;ref&gt;{{cite web|url=http://www.rigzone.com/data/|title=RIGZONE - Offshore Rig Data, Onshore Fleet Analysis|publisher=|accessdate=20 April 2015}}&lt;/ref&gt;

One of the world's deepest hubs is currently the [[Perdido oil platform|Perdido]] in the Gulf of Mexico, floating in 2,438 meters of water. It is operated by [[Royal Dutch Shell]] and was built at a cost of $3 billion.&lt;ref&gt;{{cite web|url=https://www.reuters.com/article/idUSN3123683920100331|title=UPDATE 1-Shell starts production at Perdido|work=Reuters|accessdate=20 April 2015}}&lt;/ref&gt; The deepest operational platform is the Petrobras America Cascade FPSO in the Walker Ridge 249 field in 2,600 meters of water.

== Main offshore fields ==
Notable offshore fields include:
* the [[North Sea]]
* the [[Offshore oil and gas in the US Gulf of Mexico|Gulf of Mexico]] (offshore [[Texas]], [[Louisiana]], [[Mississippi]], and [[Alabama]])
* [[Offshore oil and gas in California|California]] (in the [[Los Angeles Basin]] and [[Santa Barbara Channel]], part of the Ventura Basin)
* the Caspian Sea (notably some major fields offshore [[Azerbaijan]])
* the [[Campos Basin|Campos]] and [[Santos Basin]]s off the coasts of [[Brazil]]
* [[Newfoundland and Labrador|Newfoundland]] and [[Nova Scotia]] ([[Atlantic Canada]])
* several fields off [[West Africa]] most notably west of [[Nigeria]] and [[Angola]]
* offshore fields in [[South East Asia]] and [[Sakhalin]], Russia
* major offshore oil fields are located in the [[Persian Gulf]] such as Safaniya, Manifa and Marjan which belong to Saudi Arabia and are developed by Saudi Aramco.&lt;ref&gt;{{cite web|url=http://www.highbeam.com/doc/1G1-12308981.html|title=Archived copy|archiveurl=https://web.archive.org/web/20121105163103/http://www.highbeam.com/doc/1G1-12308981.html|archivedate=2012-11-05|deadurl=yes|accessdate=2011-02-26|df=}}&lt;/ref&gt;
* fields in [[India]] (Mumbai High, K G Basin-East Coast Of India, Tapti Field, [[Gujarat]], India)
* the [[Taranaki Basin]] in [[New Zealand]]
* the [[East-Prinovozemelsky field|Kara Sea]] north of Siberia&lt;ref&gt;{{cite news|url=https://www.platts.com/latest-news/oil/moscow/russian-rosneft-announces-major-oil-gas-discovery-21300064|title=Russian Rosneft announces major oil, gas discovery in Arctic Kara Sea|accessdate=2017-08-18|publisher=Platts}}&lt;/ref&gt;
* the [[Arctic Ocean]] off the coasts of [[Alaska]] and Canada's [[Northwest Territories]]&lt;ref&gt;{{cite web|url=https://www.boem.gov/uploadedFiles/BOEM/Oil_and_Gas_Energy_Program/Resource_Evaluation/Resource_Assessment/2006AlaskaUndiscoveredOilandGasResources.pdf|title=Year 2006 National Assessment - Alaska Outer Continental Shelf|publisher=Dept Interior BEOM|accessdate=2017-08-18}}&lt;/ref&gt;

==Types==
Larger lake- and sea-based offshore platforms and [[drilling rig]] for oil. 
 
[[File:Types of offshore oil and gas structures.jpg|thumb|600px|center|1, 2) conventional fixed platforms; 3) compliant tower; 4, 5) vertically moored tension leg and mini-tension leg platform; 6) spar; 7, 8) semi-submersibles; 9) floating production, storage, and offloading facility; 10) sub-sea completion and tie-back to host facility.&lt;ref&gt;{{cite web | author=Office of Ocean Exploration and Research | title=Types of Offshore Oil and Gas Structures | department=NOAA Ocean Explorer: Expedition to the Deep Slope | url=http://oceanexplorer.noaa.gov/explorations/06mexico/background/oil/media/types_600.html | publisher=National Oceanic and Atmospheric Administration | date=15 December 2008 | accessdate=23 May 2010}}&lt;/ref&gt;]]

~fixed are those platforms which are fixed at a particular place and cannot be changed.

===Compliant towers===
{{Main article|Compliant Tower}}
These platforms consist of slender, flexible towers and a pile foundation supporting a conventional deck for drilling and production operations. Compliant towers are designed to sustain significant lateral deflections and forces, and are typically used in water depths ranging from {{convert|370|to|910|m}}.

===Semi-submersible platform===
{{Main article|Semi-submersible}}
These platforms have hulls (columns and pontoons) of sufficient [[buoyancy]] to cause the structure to float, but of weight sufficient to keep the structure upright. Semi-submersible platforms can be moved from place to place and can be ballasted up or down by altering the amount of flooding in buoyancy tanks. They are generally anchored by combinations of chain, wire rope or polyester rope, or both, during drilling and/or production operations, though they can also be kept in place by the use of [[dynamic positioning]]. Semi-submersibles can be used in water depths from {{convert|60|to|6000|m|sigfig=1}}.

===Jack-up drilling rigs===
[[File:Jackrigkachbay.jpg|thumb|{{convert|400|ft}} tall jackup rig being towed by tugboats, [[Kachemak Bay, Alaska]]]]
{{Main article|Jackup rig}}
Jack-up Mobile Drilling Units (or jack-ups), as the name suggests, are rigs that can be jacked up above the sea using legs that can be lowered, much like [[Jack (device)|jacks]]. These MODUs (Mobile Offshore Drilling Units) are typically used in water depths up to {{convert|120|m|ft}}, although some designs can go to {{convert|170|m|abbr=on}} depth. They are designed to move from place to place, and then anchor themselves by deploying their legs to the ocean bottom using a [[rack and pinion]] gear system on each leg.

===Drillships===
{{Main article|Drillship}}
A drillship is a maritime vessel that has been fitted with drilling apparatus. It is most often used for exploratory drilling of new oil or gas wells in deep water but can also be used for scientific drilling. Early versions were built on a modified tanker hull, but purpose-built designs are used today. Most drillships are outfitted with a [[dynamic positioning]] system to maintain position over the well. They can drill in water depths up to {{convert|3700|m|abbr=on}}.&lt;ref&gt;{{cite news |url=http://www.chevron.com/news/press/release/?id=2010-03-11 |title=Chevron Drillship |accessdate=2010-05-24 |date=2010-03-11 |deadurl=yes |archiveurl=https://web.archive.org/web/20100530044448/http://www.chevron.com/news/press/release/?id=2010-03-11 |archivedate=2010-05-30 |df= }}&lt;/ref&gt;

===Floating production systems===
[[File:View of the Port of Las Palmas from the dock of La Esfinge (3).jpg|View of the Port of Las Palmas from the dock of La Esfinge|thumb]]
{{Main article|Floating production, storage and offloading}}
The main types of floating production systems are [[Floating Production Storage and Offloading|FPSO (floating production, storage, and offloading system)]]. FPSOs consist of large monohull structures, generally (but not always) shipshaped, equipped with processing facilities. These platforms are moored to a location for extended periods, and do not actually drill for oil or gas. Some variants of these applications, called [[Floating storage and offloading unit|FSO (floating storage and offloading system)]] or FSU (floating storage unit), are used exclusively for storage purposes, and host very little process equipment. This is one of the best sources for having floating production.

The world's first [[FLNG|floating liquefied natural gas (FLNG)]] facility is currently under development. See the section on [[Oil platform#Particularly large examples|particularly large examples]] below.

===Tension-leg platform===
{{Main article|Tension-leg platform}}
TLPs are floating platforms tethered to the seabed in a manner that eliminates most vertical movement of the structure. TLPs are used in water depths up to about {{convert|2,000|m|ft|abbr=off|sp=us}}. The "conventional" TLP is a 4-column design which looks similar to a semisubmersible. Proprietary versions include the Seastar and MOSES mini TLPs; they are relatively low cost, used in water depths between {{convert|180|and|1300|m}}. Mini TLPs can also be used as utility, satellite or early production platforms for larger deepwater discoveries.

===Gravity-based structure===
{{Main article|Gravity-based structure}}
A GBS can either be steel or concrete and is usually anchored directly onto the seabed. Steel GBS are predominantly used when there is no or limited availability of crane barges to install a conventional fixed offshore platform, for example in the Caspian Sea. There are several steel GBS in the world today (e.g. offshore Turkmenistan Waters (Caspian Sea) and offshore New Zealand). Steel GBS do not usually provide [[hydrocarbon]] storage capability. It is mainly installed by pulling it off the yard, by either wet-tow or/and dry-tow, and self-installing by controlled ballasting of the compartments with sea water. To position the GBS during installation, the GBS may be connected to either a transportation barge or any other barge (provided it is large enough to support the GBS) using strand jacks. The jacks shall be released gradually whilst the GBS is ballasted to ensure that the GBS does not sway too much from target location.

===Spar platforms===
[[File:Devils tower 2004.JPG|thumb|upright|Devil's Tower spar platform]]
{{Main article|Spar (platform)}}
Spars are moored to the seabed like TLPs, but whereas a TLP has vertical tension tethers, a spar has more conventional mooring lines. Spars have to-date been designed in three configurations: the "conventional" one-piece cylindrical hull; the "truss spar", in which the midsection is composed of truss elements connecting the upper buoyant hull (called a hard tank) with the bottom soft tank containing permanent ballast; and the "cell spar", which is built from multiple vertical cylinders. The spar has more inherent stability than a TLP since it has a large counterweight at the bottom and does not depend on the mooring to hold it upright. It also has the ability, by adjusting the mooring line tensions (using chain-jacks attached to the mooring lines), to move horizontally and to position itself over wells at some distance from the main platform location. The first production spar was [[Kerr-McGee Corporation|Kerr-McGee's]] Neptune, anchored in {{convert|590|m|abbr=on}} in the Gulf of Mexico; however, spars (such as [[Brent Spar]]) were previously used as FSOs.

[[Eni]]'s [[Devil's Tower (oil platform)|Devil's Tower]] located in {{convert|1710|m|abbr=on}} of water in the Gulf of Mexico, was the world's deepest spar until 2010. The world's deepest platform is currently the [[Perdido oil platform|Perdido]] spar in the Gulf of Mexico, floating in 2,438 metres of water. It is operated by [[Royal Dutch Shell]] and was built at a cost of $3 billion.&lt;ref&gt;[https://www.reuters.com/article/idUSN3123683920100331 Shell starts production at Perdido]&lt;/ref&gt;&lt;ref&gt;Fahey, Jonathan, [[Associated Press]], "[http://www.msnbc.msn.com/id/45825598/ns/us_news-environment/t/deep-gulf-drilling-thrives-mos-after-bp-spill/ Deep Gulf drilling thrives 18 mos. after BP spill]", ''[[Japan Times]]'', 4 January 2012, p. 11; "[https://www.google.com/hostednews/ap/article/ALeqM5gz-JrDDvRM0_zBWa3CWjEGhvB0xw?docId=7c57a1cc233d4a2d9ee7d047ef6d32cc The offshore drilling life: cramped and dangerous]", 1 January 2012.&lt;/ref&gt;

The first truss spars were Kerr-McGee's Boomvang and Nansen.{{Citation needed|date=November 2010}}
The first (and only) cell spar is Kerr-McGee's Red Hawk.&lt;ref&gt;{{cite news |url=http://www.fmctechnologies.com/en/SubseaSystems/GlobalProjects/NorthAmerica/US/KMGRedHawk.aspx?tab=%7BB01D40AB-5E2F-4710-9543-19C658AF29F5%7D |title=First Cell Spar |accessdate=2010-05-24}}&lt;/ref&gt;

===Normally unmanned installations (NUI)===
{{Main article|Normally unmanned installation}}
These installations, sometimes called toadstools, are small platforms, consisting of little more than a [[well bay]], [[helipad]] and emergency shelter. They are designed to be operated remotely under normal conditions, only to be visited occasionally for routine maintenance or [[well work]].

===Conductor support systems===
{{Main article|Conductor Support Systems}}
These installations, also known as '''satellite platforms''', are small unmanned platforms consisting of little more than a [[well bay]] and a small [[process plant]]. They are designed to operate in conjunction with a static production platform which is connected to the platform by flow lines or by [[umbilical cable]], or both.

==Particularly large examples==
[[File:Oil platform Norway.jpg|thumb|upright|[[Troll A platform|Troll A]] [[natural gas]] platform, a [[gravity-based structure]], under construction in [[Norway]]. Almost all of the 600KT structure will end up submerged.]]

The [[Petronius Platform]] is a compliant tower in the [[Gulf of Mexico]] modeled after the Hess Baldpate platform, which stands {{convert|2000|ft|m}} above the ocean floor. It is one of the [[world's tallest structures]].&lt;ref&gt;{{cite web | title=What is the World's Tallest Building? | url=http://www.allaboutskyscrapers.com/tallest_building.htm | work=All About Skyscrapers | year=2009 | accessdate=23 May 2010 | deadurl=yes | archiveurl=https://web.archive.org/web/20110205082042/http://www.allaboutskyscrapers.com/tallest_building.htm | archivedate=5 February 2011 | df= }}&lt;/ref&gt;

The [[Hibernia Gravity Base Structure|Hibernia]] platform in [[Canada]] is the world's largest (in terms of weight) offshore platform, located on the [[Jeanne D'Arc Basin]], in the [[Atlantic Ocean]] off the coast of [[Newfoundland and Labrador|Newfoundland]]. This ''[[gravity base structure]]'' (GBS), which sits on the ocean floor, is {{convert|111|m|ft}} high and has storage capacity for {{convert|1.3|Moilbbl|m3}} of crude oil in its {{convert|85|m|ft|adj=on}} high caisson. The platform acts as a small concrete island with serrated outer edges designed to withstand the impact of an [[iceberg]]. The GBS contains production storage tanks and the remainder of the void space is filled with ballast with the entire structure weighing in at 1.2 million [[ton]]s.

[[Royal Dutch Shell]] is currently developing the first [[FLNG|Floating Liquefied Natural Gas (FLNG)]] facility, which will be situated approximately 200&amp;nbsp;km off the coast of [[Western Australia]] and is due for completion around 2017.&lt;ref&gt;http://www.ft.com/cms/s/0/9ccaed4a-82ba-11e0-b97c-00144feabdc0.html#axzz1NADgzzOH&lt;/ref&gt; When finished, it will be the largest floating offshore facility. It is expected to be approximately 488m long and 74m wide with [[Displacement (ship)|displacement]] of around 600,000t when fully ballasted.&lt;ref&gt;http://gastoday.com.au/news/flng_gets_serious/042981/&lt;/ref&gt;

==Maintenance and supply==
A typical oil production platform is self-sufficient in energy and water needs, housing electrical generation, water desalinators and all of the equipment necessary to process oil and gas such that it can be either delivered directly onshore by pipeline or to a [[Floating production storage and offloading|floating platform]] or tanker loading facility, or both. Elements in the oil/gas production process include [[wellhead]], [[production manifold]], [[production separator]], [[glycol]] process to dry gas, [[gas compressor]]s, [[Water injection (oil production)|water injection pumps]], [[oil/gas export metering]] and [[main oil line]] pumps.

Larger platforms assisted by smaller ESVs (emergency support vessels) like the [[United Kingdom|British]] [[Iolair]] that are summoned when something has gone wrong, ''e.g.'' when a [[search and rescue]] operation is required. During normal operations, [[platform supply vessel|PSVs]] (platform supply vessels) keep the platforms provisioned and supplied, and [[anchor handling tug supply vessel|AHTS vessels]] can also supply them, as well as tow them to location and serve as standby rescue and firefighting vessels.

==Crew==

===Essential personnel===
Not all of the following personnel are present on every platform. On smaller platforms, one worker can perform a number of different jobs. The following also are not names officially recognized in the industry:

*[[OIM (offshore installation manager)]] who is the ultimate authority during his/her shift and makes the essential decisions regarding the operation of the platform;
*operations team leader (OTL);
*Offshore Methods Engineer (OME) who defines the installation methodology of the platform;
*offshore operations engineer (OOE) who is the senior technical authority on the platform;
*PSTL or operations coordinator for managing crew changes;
*dynamic positioning operator, navigation, ship or vessel maneuvering (MODU), station keeping, fire and gas systems operations in the event of incident;
*automation systems specialist, to configure, maintain and troubleshoot the process control systems (PCS), process safety systems, emergency support systems and vessel management systems;
*second mate to meet manning requirements of flag state, operates fast rescue craft, cargo operations, fire team leader;
*third mate to meet manning requirements of flag state, operate fast rescue craft, cargo operations, fire team leader;
*ballast control operator to operate fire and gas systems;
*crane operators to operate the cranes for lifting cargo around the platform and between boats;
*scaffolders to rig up scaffolding for when it is required for workers to work at height;
*coxswains to maintain the lifeboats and manning them if necessary;
*control room operators, especially FPSO or production platforms;
*catering crew, including people tasked with performing essential functions such as cooking, laundry and cleaning the accommodation;
*production techs to run the production plant;
*[[helicopter]] [[Aviator|pilot]](s) living on some platforms that have a helicopter based offshore and transporting workers to other platforms or to shore on crew changes;
*maintenance technicians (instrument, electrical or mechanical).
*Fully qualified medic.
*Radio operator to operate all radio communications.
*Store Keeper, keeping the inventory well supplied

===Incidental personnel===
Drill crew will be on board if the installation is performing drilling operations. A drill crew will normally comprise:
* [[Toolpusher]]
* [[Driller (oil)|Driller]]
* [[Roughneck]]s
* [[Roustabout]]s
* [[Company man]]
* [[Mud engineer]]
* [[Motorman]]
* [[Derrickhand]]
* [[Geologist]]
* [[Welders]] and Welder Helpers
[[Well services]] crew will be on board for [[well work]]. The crew will normally comprise:
* Well services supervisor
* Wireline or coiled tubing operators
* Pump operator
* Pump hanger and ranger

==Drawbacks==
{{For|fuller discussion|United States offshore drilling debate}}

===Risks===
The nature of their operation—extraction of volatile substances sometimes under extreme pressure in a hostile environment—means risk; accidents and tragedies occur regularly. The U.S. [[Minerals Management Service]] reported 69 offshore deaths, 1,349 injuries, and 858 fires and explosions on offshore rigs in the Gulf of Mexico from 2001 to 2010.&lt;ref&gt;{{cite news | title = Potential for big spill after oil rig sinks | date = 2010-04-22 | url = http://www.msnbc.msn.com/id/36683314/ns/us_news-life/ | work = MSNBC | accessdate = 2010-06-04}}&lt;/ref&gt; On July 6, 1988, 167 people died when [[Occidental Petroleum]]'s [[Piper Alpha]] offshore production platform, on the Piper field in the UK sector of the [[North Sea]], exploded after a gas leak. The resulting investigation conducted by Lord Cullen and publicized in the first [[Cullen Report]] was highly critical of a number of areas, including, but not limited to, management within the company, the design of the structure, and the Permit to Work System. The report was commissioned in 1988, and was delivered November 1990.&lt;ref&gt;http://www.oilandgas.org.uk/issues/piperalpha/v0000864.cfm{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; The accident greatly accelerated the practice of providing living accommodations on separate platforms, away from those used for extraction.

The offshore can be in itself a hazardous environment. In March 1980, the '[[flotel]]' (floating hotel) platform ''[[Alexander L. Kielland (platform)|Alexander L. Kielland]]'' capsized in a storm in the [[North Sea]] with the loss of 123 lives.&lt;ref&gt;{{cite news |url=http://news.bbc.co.uk/onthisday/hi/dates/stories/march/27/newsid_2531000/2531091.stm |title=North Sea platform collapses  | work=BBC News | accessdate=2008-06-19 | date=1980-03-27}}&lt;/ref&gt;

In 2001, ''[[Petrobras 36]]'' in [[Brazil]] exploded and sank five days later, killing 11 people.

Given the number of grievances and conspiracy theories that involve the oil business, and the importance of gas/oil platforms to the economy, platforms in the United States are believed to be potential terrorist targets.{{citation needed|date = March 2014}} Agencies and military units responsible for maritime counter-terrorism in the US ([[United States Coast Guard|Coast Guard]], [[Navy SEALs]], [[United States Marine Corps Force Reconnaissance|Marine Recon]]) often train for platform raids.{{citation needed|date = March 2014}}

On April 21, 2010, the ''[[Deepwater Horizon]]'' platform, 52 [[nautical mile|miles]] off-shore of [[Venice, Louisiana]], (property of [[Transocean]] and leased to [[BP]]) [[Deepwater Horizon oil spill|exploded]], killing 11 people, and sank two days later. The resulting undersea gusher, conservatively estimated to exceed {{convert|20|e6USgal|m3}} as of early June, 2010, became the worst oil spill in US history, eclipsing the [[Exxon Valdez oil spill]].

===Ecological effects===
[[File:Gulf Coast Platforms.jpg|thumb|250px|right|NOAA map of the 3,858 oil and gas platforms extant in the Gulf of Mexico in 2006]]
In British waters, the cost of removing all platform rig structures entirely was estimated in 2013 at £30 billion.&lt;ref&gt;http://www.raeng.org.uk/publications/reports/decommissioning-in-the-north-sea.&lt;/ref&gt;

Aquatic organisms invariably attach themselves to the undersea portions of oil platforms, turning them into artificial reefs. In the Gulf of Mexico and offshore California, the waters around oil platforms are popular destinations for sports and commercial fishermen, because of the greater numbers of fish near the platforms. The [[United States]] and [[Brunei]] have active [[Rigs-to-Reefs]] programs, in which former oil platforms are left in the sea, either in place or towed to new locations, as permanent artificial reefs. In the US [[Gulf of Mexico]], as of September 2012, 420 former oil platforms, about 10 percent of decommissioned platforms, have been converted to permanent reefs.&lt;ref&gt;National Oceanic and Atmospheric Administration, [http://sero.nmfs.noaa.gov/habitat_conservation/documents/pdfs/efh/gulf_decommissioning_and_rigs_to_reefs_faqs_final.pdf Gulf decomissioning and Rigs-to-Reefs, FAQs] {{webarchive|url=https://web.archive.org/web/20131109224846/http://sero.nmfs.noaa.gov/habitat_conservation/documents/pdfs/efh/gulf_decommissioning_and_rigs_to_reefs_faqs_final.pdf |date=2013-11-09 }}, 2012.&lt;/ref&gt;

On the US Pacific coast, [[marine biologist]] Milton Love has proposed that oil platforms off California be retained as [[artificial reef]]s, instead of being dismantled (at great cost), because he has found them to be havens for many of the species of fish which are otherwise declining in the region, in the course of 11 years of research.&lt;ref&gt;{{cite web |vauthors=Page M, Dugan J, Love M, Lenihan H |title=Ecological Performance and Trophic Links: Comparisons Among Platforms And Natural Reefs For Selected Fish And Their Prey |url=http://www.coastalresearchcenter.ucsb.edu/cmi/ecoperformance.html |publisher=University of California, Santa Barbara |accessdate=2008-06-27 }}&lt;/ref&gt; Love is funded mainly by government agencies, but also in small part by the [[California Artificial Reef Enhancement Program]]. [[Professional diving#Scientific diving|Divers]] have been used to assess the [[fish]] populations surrounding the platforms.&lt;ref&gt;{{cite journal |author1=SA Cox |author2=CR Beaver |author3=QR Dokken |author4=JR Rooker.  |last-author-amp=yes |title=Diver-based under water survey techniques used to assess fish populations and fouling community development on offshore oil and gas platform structures |journal=In: MA Lang, CC Baldwin (Eds.) the Diving for Science...1996, "Methods and Techniques of Underwater Research". |volume=Proceedings of the American Academy of Underwater Sciences |issue=16th Annual Scientific Diving Symposium |year=1996 |url=http://archive.rubicon-foundation.org/4689 |accessdate=2008-06-27 }}&lt;/ref&gt;

== Challenges ==
Offshore oil and gas production is more challenging than land-based installations due to the remote and harsher environment. Much of the innovation in the offshore petroleum sector concerns overcoming these challenges, including the need to provide very large production facilities. Production and drilling facilities may be very large and a large investment, such as the [[Troll A platform]] standing on a depth of 300 meters.

Another type of offshore platform may float with a mooring system to maintain it on location. While a floating system may be lower cost in deeper waters than a fixed platform, the dynamic nature of the platforms introduces many challenges for the drilling and production facilities.

The ocean can add several thousand meters or more to the [[fluid column]]. The addition increases the equivalent circulating density and downhole pressures in drilling wells, as well as the energy needed to lift produced fluids for separation on the platform.

The trend today is to conduct more of the production operations [[subsea]], by separating water from oil and re-injecting it rather than pumping it up to a platform, or by flowing to onshore, with no installations visible above the sea. Subsea installations help to exploit resources at progressively deeper waters—locations which had been inaccessible—and overcome challenges posed by sea ice such as in the [[Barents Sea]]. One such challenge in shallower environments is [[Seabed gouging by ice|seabed gouging by drifting ice features]] (means of protecting offshore installations against ice action includes burial in the seabed).

Offshore manned facilities also present logistics and human resources challenges. An offshore oil platform is a small community in itself with cafeteria, sleeping quarters, management and other support functions. In the North Sea, staff members are transported by helicopter for a two-week shift. They usually receive higher salary than onshore workers do. Supplies and waste are transported by ship, and the supply deliveries need to be carefully planned because storage space on the platform is limited. Today, much effort goes into relocating as many of the personnel as possible onshore, where management and technical experts are in touch with the platform by video conferencing. An onshore job is also more attractive for the aging workforce in the [[petroleum industry]], at least in the western world. These efforts among others are contained in the established term [[integrated operations]]. The increased use of subsea facilities helps achieve the objective of keeping more workers onshore. Subsea facilities are also easier to expand, with new separators or different modules for different oil types, and are not limited by the fixed floor space of an above-water installation.

== Effects on the environment ==
Offshore oil production involves environmental risks, most notably [[oil spill]]s from oil tankers or pipelines transporting oil from the platform to onshore facilities, and from leaks and accidents on the platform.&lt;ref&gt;{{cite video|title=Debate Over Offshore Drilling|medium=internet video|publisher=''[[CBS News]]''|date=2008|url=http://www.webcastr.com/videos/news/debate-over-offshore-drilling.html|accessdate=2008-09-27|archive-url=https://web.archive.org/web/20080824002817/http://www.webcastr.com/videos/news/debate-over-offshore-drilling.html|archive-date=2008-08-24|dead-url=yes|df=}}&lt;/ref&gt; [[Produced water]] is also generated, which is water brought to the surface along with the oil and gas; it is usually highly saline and may include dissolved or unseparated hydrocarbons.

==Deepest oil platforms==
The world's deepest oil platform is the floating [[Perdido (oil platform)|Perdido]], which is a [[Spar (platform)|spar platform]] in the Gulf of Mexico in a water depth of {{convert|2438|m}}.

Non-floating compliant towers and fixed platforms, by water depth:

* [[Petronius Platform]], {{convert|535|m|abbr=on}}
* [[Baldpate Platform]], {{convert|502|m|abbr=on}}
* [[Troll A|Troll A Platform]], {{convert|472|m|abbr=on}}
* [[Bullwinkle Platform]], {{convert|413|m|abbr=on}}
* [[Pompano Platform]], {{convert|393|m|abbr=on}}
* [[Benguela-Belize Lobito-Tomboco Platform]], {{convert|390|m|abbr=on}}
* [[Gullfaks C|Gulfaks C Platform]], {{convert|380|m|abbr=on}}
* [[Tombua Landana Platform]], {{convert|366|m|abbr=on}}
* [[Harmony Platform]], {{convert|366|m|abbr=on}}

==See also==
{{div col|colwidth=40em}}
* [[Accommodation platform]]
* [[Chukchi Cap]]
* [[Conductor support system]]
* [[Deep sea mining]]
* [[Deepwater drilling]]
* [[Drillship]]
* [[Jackup barge]]
* [[North Sea oil]]
* [[Offshore concrete structure]]
* [[Offshore geotechnical engineering]]
* [[Offshore oil and gas in the United States]]
* [[Oil drilling]]
* [[Protocol for the Suppression of Unlawful Acts against the Safety of Fixed Platforms Located on the Continental Shelf]]
* [[Rigs-to-Reefs]]
* [[SAR201]]
* [[Semi-submersible]]
* [[Shallow water drilling]]
* [[Submarine pipeline]]
* [[Subsea]]
* [[TEMPSC]]
* [[Texas Towers]]
* [[United States offshore drilling debate]]
{{div col end}}

==References==
{{Reflist|30em}}

==External links==
{{Commons|Oil platform}}
* [http://www.oilrigdisasters.co.uk Oil Rig Disasters] Listing of oil rig accidents
* [http://www.oilrig-photos.com Oil Rig Photos] Collection of pictures of drilling rigs and production platforms
* [https://web.archive.org/web/20071020233211/http://divinglore.com/Offshore_Platforms.htm An independent review of offshore platforms in the North Sea]
* [https://web.archive.org/web/20080101062156/http://www.vulcanhammer.info/off/conventional.php Overview of Conventional Platforms] Pictorial treatment on the installation of platforms which extend from the seabed to the ocean surface

{{Tallest buildings and structures}}
{{DEFAULTSORT:Oil Platform}}
[[Category:Oil platforms| ]]
[[Category:Offshore engineering]]
[[Category:Petroleum production]]
[[Category:Drilling technology]]
[[Category:Natural gas technology]]
[[Category:Structural engineering]]</text>
      <sha1>dzuilm7f4g8o1k5tnf7mpp6amjij83t</sha1>
    </revision>
  </page>
  <page>
    <title>Particle (ecology)</title>
    <ns>0</ns>
    <id>1109435</id>
    <revision>
      <id>860619555</id>
      <parentid>860617638</parentid>
      <timestamp>2018-09-21T22:48:12Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Unreferenced}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3879">{{Other uses|Particle (disambiguation)}}

{{unreferenced|date=September 2018}}
In marine and freshwater [[ecology]], a '''particle''' is a small object. Particles can remain in suspension in the ocean or freshwater. However, they eventually settle (rate determined by [[Stokes' law]]) and accumulate as sediment. Some can enter the [[Earth's atmosphere|atmosphere]] through wave action where they can act as [[cloud condensation nuclei]] (CCN). Many organisms [[filter (chemistry)|filter]] particles out of the water with unique filtration mechanisms ([[filter feeder]]s).  Particles are often associated with high loads of [[toxin]]s which attach to the surface.  As these toxins are passed up the food chain they accumulate in fatty tissue and become increasingly concentrated in predators (see [[bioaccumulation]]).  Very little is known about the dynamics of particles, especially when they are re-suspended by [[dredging]]. They can remain floating in the water and drift over long distances.  The decomposition of some particles by bacteria consumes a lot of [[oxygen]] and can cause the water to become [[hypoxia (environmental)|hypoxic]].

==Particle analysis==
Particle levels in water (or air) can be measured with a [[turbidity]] meter and analyzed with a [[particle counter]]. They can also be scanned with an underwater microscope, such as [[ecoSCOPE]].

[[Image:Particlekils.gif|thumb|Particles scanned with the [[ecoSCOPE]] microscope. The blue frame is a 1 mm contrast grid.]]

==Contaminant kinetics==
{{main article|Marine pollution}}
It takes a few days until [[plankton]] organisms have filtered the particles and incorporated the toxins into their body fat and [[Biological tissue|tissue]]: In the southwards flow of the waters of the Hudson off the coast of [[New Jersey]], the highest levels of mercury in [[copepod]]s have not been found directly in front of the river off [[New York (state)|New York]] but 150&amp;nbsp;km south, off [[Atlantic City]].

Many copepods are then captured by [[mysidae]], [[krill]] and smallest [[fish]] like the juveniles of [[atlantic herring]] - and in each step of the [[foodchain]] the toxin concentrations increase by the factor of 10. The milk of mothers (''Homo sapiens'') consuming fish and related products like margarine and eggs in such areas have so high toxin levels that it would be impossible to sell such milk on markets - their babies have much more birth-defects and/or retarded brains and have later difficulties to learn and/or reproduce. Many die at an early age.
{{clear}} &lt;!-- force image to begin on new line --&gt;

[[Image:Krillfilter2kils.jpg|thumb|Filter of krill]]
Filter of [[krill]]: The first degree [[filter setae]] carry in v-form two rows of second degree [[setae]], pointing towards the inside of the [[feeding basket]]. The purple ball is one micrometer in size. To display the total area of this fascinating particle filtration structure one would have to [http://www.ecoscope.com/krill/filter/filter7/index.htm tile] 7500 times this image.
{{clear}} &lt;!-- force image to begin on new line --&gt;

[[Image:Mysis2kils.jpg|thumb|Filter basket of a mysid.]]
[[Filter basket]] of a mysid. These 3&amp;nbsp;cm long animals live close to shore and hover above the sea floor, constantly collecting particles. Mysids are an important food source for [[atlantic herring|herring]], [[cod]], [[flounder]], [[striped bass]]. In polluted areas they have high toxin levels in their tissue but they are very robust and take a lot of poison before they die. Such [[filter feeding|filter-feeding]] organisms are the reason that much of the materials we throw in the oceans comes back to us in our food.{{Citation needed|date=May 2007}}
{{clear}} &lt;!-- force image to begin on new line --&gt;

{{aquatic ecosystem topics|state=expanded}}
{{marine pollution}}

[[Category:Environmental chemistry]]
[[Category:Bioindicators]]</text>
      <sha1>torqew5c67gnhzkrz5kd65yvbwctdg9</sha1>
    </revision>
  </page>
  <page>
    <title>Patchwork religion</title>
    <ns>0</ns>
    <id>48950353</id>
    <revision>
      <id>705458824</id>
      <parentid>702946175</parentid>
      <timestamp>2016-02-17T16:34:38Z</timestamp>
      <contributor>
        <username>AManWithNoPlan</username>
        <id>12416903</id>
      </contributor>
      <minor/>
      <comment>Cleaned up using [[WP:AutoEd|AutoEd]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4173">{{Orphan|date=December 2015}}

'''Рatchwork religion''' — term in the [[sociology of religion]] for indicating situations, when individual or religious movement forms its own world view from different elements, which were taken from different existing religions or own [[religious experience]]. Collected from these elements religious world view reminds of a patchwork quilt with a unique pattern. Term has common features with social concepts like [[syncretism]], [[bricolage]], [[sheilaism]].

== History ==
Use of term patchwork concerning religion was for the first time suggested by an American sociologist [[Robert Wuthnow]]. Wutthow studies aspects of American religiosity, believing that its patchwork and avoidance of keeping to strictly defined forms are its essential features. Thus he writes:  &lt;blockquote&gt;“Now, at the end of the twentieth century, growing numbers of Americans piece together their faith like a patchwork quilt. Spirituality has become a vastly complex quest in which each person seeks in his or her own way”.&lt;ref&gt;Wuthnow R. After Heaven: Spirituality in America Since the 1950s / Robert Wuthnow. — Berkeley: University of California Press, 1998. — Р. 2.&lt;/ref&gt; &lt;/blockquote&gt;At the same time patchwork of individual religiosity, as Wuthnow states, doesn’t contradict loyalty of individual to church’s official position, in which it must be. In his other book Wuthnow connects patchwork with a feature of American religiosity called The Shopping Mentality. Bearers of such mentality mostly admit the existence of God or some kind of mystical force, but believe that none of religions is able to explain exhaustively this mystery to people. At the same time within the framework of each religion good examples of penetration into mysterious spheres of divine can be found, which means that a person can take some elements from each religion in order to gather them into a general picture of individual religiosity.  &lt;blockquote&gt;“When God is ultimately a mystery, it is easy to assume that all religions contain insights about God but no religion provides a complete understanding of God, and thus one way to increase one`s understanding of God is by gleaning ideas from many different religious traditions”.&lt;ref&gt;Wuthnow R. America and the Challenges of Religious Diversity / Robert Wuthnow. — Princeton: Princeton University Press, 2007. — Р. 120.&lt;/ref&gt;&lt;/blockquote&gt;Wuthnow writes about spiritual shoppers as about people, who  &lt;blockquote&gt;“Having learned to be open-minded and to patch together ideas from many different sources”.&lt;ref&gt;Wuthnow R. America and the Challenges of Religious Diversity / Robert Wuthnow. — Princeton: Princeton University Press, 2007. — Р. 122.&lt;/ref&gt;&lt;/blockquote&gt;

== Patchwork religion in collective consciousness ==
Nevertheless the fact that originally patchwork religion was applied to individual religiosity, it’s also being used in description of public worldview features. Patchwork is inherent in religious traditions, when their representatives include in original teaching or practice not originally inherent elements, for example which were characteristic for other religion, which was dominant among these representatives before. This explains dual faith, superstitions, which can be characterized as interpolations, brought not by an individual believer, but during a historical process. Some scientists think that each religious tradition has its people’s version, which includes such kinds of interpolations (for example, people’s Catholicism, people’s Buddhism etc.).&lt;ref&gt;«Denz H.» Religion, Popular Piety, Patchwork Religion / Hermann Denz // Church and Religion in Contemporary Europe: Results from Empirical and Comparative Research. — Wiesbaden: VS Verlag für Sozialwissenschaften | GWV Fachverlage GmbH, 2009. — P. 183.&lt;/ref&gt; Collective form of patchwork religion, as well as an individual, is an evidence of a conjunction to religious tradition of elements, which were not inherent before, or of a refusal to admit elements, which are inherent in it.

== Notes ==
{{reflist}}

[[Category:Sociological terminology]]
[[Category:Sociology of religion]]</text>
      <sha1>dt2qbfpthx0kpiz4zchzb48sesh1u5m</sha1>
    </revision>
  </page>
  <page>
    <title>Planning permission</title>
    <ns>0</ns>
    <id>53226889</id>
    <revision>
      <id>832304636</id>
      <parentid>831804709</parentid>
      <timestamp>2018-03-25T03:59:45Z</timestamp>
      <contributor>
        <ip>2605:6000:F500:7C00:B448:AD51:2BF2:C470</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5110">{{For|planning permission laws in the UK|Planning permission in the United Kingdom}}

[[File:One57 under construction 3 November 2012.jpeg|thumb|A skyscraper under construction. Such a development would have gone through stringent checks against the local building code before planning permission was granted.]]
'''Planning permission''' or '''developmental approval''' refers to the approval needed for construction or expansion (including significant [[renovation]]) in some jurisdictions.&lt;ref&gt;{{cite book|last1=Harwood|first1=Richard|title=Planning Permission|publisher=International Specialized Book Services|isbn=9781780434919|url=https://books.google.com.au/books?id=q0X0nQEACAAJ|accessdate=5 March 2017|language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Planning permission - GOV.UK|url=https://www.gov.uk/planning-permission-england-wales/when-you-need-it|website=www.gov.uk|publisher=UK Government|accessdate=18 February 2017|language=en}}&lt;/ref&gt; It is usually given in the form of a '''building permit''' (or '''construction permit'''). Generally, the new construction must be [[Building inspection|inspected]] during construction and after completion to ensure compliance with national, regional, and local [[building code]]s. Planning is also dependent on the site's zone – for example, one cannot obtain permission to build a nightclub in an area where it is inappropriate such as a high-density suburb.&lt;ref&gt;{{cite web|title=How Do I Get Planning Permission in NSW? - The Design Partnership|url=http://thedesignpartnership.com.au/planning-permission-nsw/|website=thedesignpartnership.com.au|accessdate=18 February 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Planning permissions and liquor licences|url=http://www.vcglr.vic.gov.au/home/liquor/new+applicants/licence+application+requirements/planning+permissions+and+liquor+licences/|website=www.vcglr.vic.gov.au|accessdate=18 February 2017|language=en-au}}&lt;/ref&gt; Failure to obtain a permit can result in [[Fine (penalty)|fines]], [[Sanctions (law)|penalties]], and [[demolition]] of unauthorized construction if it cannot be made to meet code. House building permits, for example, are subject to [[List of housing statutes|local housing statutes]]. The criteria for planning permission are a part of [[urban planning]] and [[construction law]], and are usually managed by [[town planner]]s employed by [[local government]]s.&lt;ref&gt;{{cite web|last1=Portal|first1=Planning|title=Do you need permission? {{!}} Planning Portal|url=https://www.planningportal.co.uk/info/200125/do_you_need_permission|website=www.planningportal.co.uk|accessdate=18 February 2017|language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Planning|first1=Department of Environment, Land, Water and|title=Planning applications|url=http://www.dtpli.vic.gov.au/planning/planning-applications|website=www.dtpli.vic.gov.au|accessdate=18 February 2017|language=en}}&lt;/ref&gt; Since building permits usually precede outlays for construction, employment, financing and furnishings, they are often used as a [[economic indicator|leading indicator]] for developments in other areas of the economy.

==In specific industries==
===Broadcasting===
As part of [[broadcast law]], the term is also used in [[broadcasting]], where individual [[radio station|radio]] and [[television station]]s typically must apply for and receive permission to construct [[Radio masts and towers|radio tower]]s and [[radio antenna]]s.  This type of permit is issued by a national broadcasting authority, but does ''not'' imply [[zoning]] any other permission that must be given by [[local government]].  The permit itself also does not necessarily imply permission to operate the station once constructed. In the U.S., a construction permit is valid for three years. Afterwards, the station must receive a full license to operate, which is good for seven years.&lt;ref&gt;[http://radio-locator.com/cgi-bin/help?topic=cp Construction Permits] Radio-Locator.com&lt;/ref&gt;  This is provided by a separate [[broadcast license]], also called a "license to cover" by the [[Federal Communications Commission]] (FCC) in the United States.  Further permission or registration for [[tower]]s may be needed from [[aviation]] authorities.

In the U.S., construction permits for commercial stations are now assigned by auction, rather than the former process of determining who would serve the [[community of license]] best.  If the given [[frequency allocation]] is sought by at least one [[non-commercial educational]] (NCE) applicant, or is on an NCE-reserved TV channel or in the [[FM broadcasting|FM]] reserved band, the comparative process still takes place, though the FCC refuses to consider which [[radio format]] the applicants propose.

In Canada, the [[Canadian Radio-television and Telecommunications Commission]] maintains a comparative process in issuing permits, ensuring that a variety of programming is available in each area, and that as many groups as possible have access to [[free speech]] over [[radio waves]].

==References==
{{reflist|30em}}

{{Land-use planning}}

[[Category:Urban planning]]
[[Category:Building]]
[[Category:Construction law]]</text>
      <sha1>0g36auz4f05fyvaqzsgkdqa5ufgufym</sha1>
    </revision>
  </page>
  <page>
    <title>Plastochron</title>
    <ns>0</ns>
    <id>2897809</id>
    <revision>
      <id>750418943</id>
      <parentid>750416092</parentid>
      <timestamp>2016-11-19T16:54:12Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1959">As the tip of a plant [[shoot]] grows, new leaves are produced at regular time intervals if temperature is held constant. This time interval is termed the '''plastochron''' (or '''plastochrone''').&lt;ref name="Silk"&gt;{{cite journal | last=Silk | first=Wendy Kuhn | last2=Erickson | first2=Ralph O. | title=Kinematics of plant growth | journal=Journal of Theoretical Biology| volume=76 | issue=4 | year=1979 | pages=481–501 | doi=10.1016/0022-5193(79)90014-6}}&lt;/ref&gt; The '''plastochrone index''' and the [[leaf plastochron index]] are ways of measuring the age of a plant dependent on morphological traits rather than on chronological age.{{clarify|date=November 2016}} Use of these indices removes differences caused by germination, developmental differences and exponential growth.

==Definitions==
The spatial pattern of the arrangement of leaves is called [[phyllotaxis|phyllotaxy]] whereas the time between successive leaf initiation events is called the plastochron and the rate of emergence from the [[Bud#Types_of_buds|apical bud]] is the [[phyllochron]].

==Plastochron ratio==
In 1951, F. J. Richards introduced the idea of the plastochron ratio and developed a system of equations to describe mathematically a centric representation using three parameters: plastochron ratio, divergence angle, and the angle of the cone tangential to the apex in the area being considered.&lt;ref&gt;FJ Richards, Philos. Trans. R. Soc. London, Ser. B 235, 509 (1951).&lt;/ref&gt;&lt;ref&gt;[http://aob.oxfordjournals.org/content/39/3/455.short Orthostichy, Parastichy and Plastochrone Ratio in a Central Theory of Phyllotaxis]&lt;/ref&gt;

Emerging [[Petiole (botany)|phyllodes]] or leaf variants experience a sudden change from a high [[humidity]] environment to a more [[arid]] one. There are other changes they encounter such as variations in light level, [[Photoperiodism|photoperiod]] and the gaseous content of the air.

==References==
{{reflist}}

{{botany-stub}}

[[Category:Botany]]</text>
      <sha1>k7fmwey8dgqrw4erbpsk826l5i1wiiy</sha1>
    </revision>
  </page>
  <page>
    <title>Problem picture</title>
    <ns>0</ns>
    <id>2776504</id>
    <revision>
      <id>833601887</id>
      <parentid>711459501</parentid>
      <timestamp>2018-04-01T15:08:39Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3967">[[File:Defendant and Counsel by WF Yeames.jpg|thumb|250px|right| ''Defendant and Counsel'' (1895), by Yeames, an example of the problem picture, which invites the viewer to speculate on the woman's alleged crime and on whether or not she may be guilty.]]A '''problem picture''' is a [[genre]] of art popular in late [[Victorian painting]], characterised by the deliberately ambiguous depiction of a key moment in a narrative that can be interpreted in several different ways, or which portrays an unresolved dilemma. It has some relation to the [[problem play]]. The viewer of the picture is invited to speculate about several different possible explanations of the scene.  The genre has much in common with that of [[book illustration]], then at its most popular, but with the text belonging to the illustration omitted.&lt;ref&gt;See David Skilton,“The Centrality of Literary Illustration in Victorian Visual Culture: the example of Millais and Trollope from 1860 to 1864.” Journal of Illustration Studies (December 2007). 14 May 2014. &lt;http://jois.uia.no/articles.php?article=30&gt;&lt;/ref&gt;  

The genre began to emerge in the second half of the nineteenth century, along with the development of book illustrations that depicted "pregnant" moments in a narrative. One of the earliest problem pictures is [[John Everett Millais]]' ''Trust Me'', which depicts an older man demanding that a young woman hand him a letter she has received. Either character might be uttering the words. The significance and content of the letter is left to the imagination.  Their relationship is also unclear; in view of their ages, they might be a married couple, or a father and daughter. 

Other artists who worked in the genre included [[William Frederick Yeames]], whose ''"[[And When Did You Last See Your Father? (picture)|And when did you last see your father?]]"'' became the most famous example of the genre. It depicts a young boy of the [[English civil war]] period being gently interrogated by [[Oliver Cromwell|Cromwellian]] troops who are looking for his Royalist father. It is implied that they are asking a trick question designed to discover his location. The painting is poised at the moment the child is about to answer. Yeames painted many other works of this type, including ''Amy Robsart'' and ''Defendant and Counsel''. When the latter was exhibited a newspaper ran a competition for readers to guess what crime the woman was accused of.&lt;ref&gt;[http://www.victorianartinbritain.co.uk/biog/yeames.htm Obituary of Yeames] {{webarchive|url=https://web.archive.org/web/20060822202258/http://www.victorianartinbritain.co.uk/biog/yeames.htm |date=2006-08-22 }}&lt;/ref&gt;

[[File:Sickert.jpg|left|thumb|250px|Walter Sickert, ''The Camden Town Murder'', originally titled, ''What Shall We Do for the Rent?'' or ''What Shall We Do to Pay the Rent'' 1908]]
Some [[avant garde]] artists also experimented with the genre, notably [[Edgar Degas]] and his follower [[Walter Sickert]]. Degas's [[Interior (Degas)|''Interior'']] (1869) depicts an ambiguous scene suggestive of sexual transgression and violence (hence the alternative title of "the Rape"). Similar ambiguity is found in Sickert's ''[[The Camden Town Murder]]'' (1908), in which the two figures can be interpreted as a couple, or a killer and his victim.

The genre continued to be popular into the early twentieth century, but was by this time increasingly seen as old fashioned and as over-literary, against the emphasis on pictorial style and form characteristic of [[impressionism]] and [[post-impressionism]].

==References==
&lt;!--See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the &lt;ref(erences/)&gt; tags--&gt;
&lt;div style="font-size:90%"&gt;&lt;references/&gt;&lt;/div&gt;

==Reading==
Pamela Fletcher, ''Narrating Modernity: The British Problem Picture, 1895-1914'' (Ashgate, 2003).

[[Category:Painting]]
[[Category:Art genres]]
[[Category:English art]]
[[Category:Iconography]]</text>
      <sha1>i657m0bqce66gj0e08oqbqdhn01yarp</sha1>
    </revision>
  </page>
  <page>
    <title>Resource efficiency</title>
    <ns>0</ns>
    <id>36804997</id>
    <revision>
      <id>778785663</id>
      <parentid>778785459</parentid>
      <timestamp>2017-05-05T06:34:35Z</timestamp>
      <contributor>
        <username>Mild Bill Hiccup</username>
        <id>5202324</id>
      </contributor>
      <comment>/* top */ Fixing style/layout errors</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6955">'''Resource efficiency''' is the maximising of the supply of money, materials, staff, and other assets that can be drawn on by a person or organization in order to function effectively, with minimum [[waste]]d ([[natural resource|natural]]) [[Resource intensity|resource expenses]]. It means using the Earth's [[Non-renewable resource|limited resources]] in a [[sustainable]] manner while minimising [[environmental impact]].

==Motivation==
A 2014 report by [[The Carbon Trust]] suggested that resource challenges are intensifying rapidly – for example, there could be a 40% gap between available water supplies and water needs by 2030, and some critical materials could be in short supply as soon as 2016.{{Update inline|date=May 2017}} These challenges could lead to disruptions to supply, growing regulatory requirements, volatile fluctuation of prices, and may ultimately threaten the viability of existing [[business model]]s.&lt;ref&gt;{{cite web |url=http://www.carbontrust.com/resources/reports/advice/opportunities-in-a-resource-constrained-world |title=Opportunities in a resource constrained world: How business is rising to the challenge|publisher=The Carbon Trust |date=February 2014|access-date=22 July 2014 }}&lt;/ref&gt;

==Related concepts==
Resource efficiency measures, methods, and aims are quite similar to those of [[resource productivity]]/[[resource intensity]] and of the slightly more environment-inclined concept of [[ecological efficiency]]/[[eco-efficiency]]. {{see also|Sustainability measurement}}

==Energy efficiency==
{{main|Efficient energy use}}

==Possible approaches==
To achieve and optimize natural resource and energy efficiency, several [[Sustainable development|sustainable economical or production schemes]] have been proposed over the course of the last 50 years:{{When|date=May 2017}} [[circular economy]], [[cradle-to-cradle]]- or [[regenerative design]], as well as [[biomimetics]] principles, just to name a few. Common to all of them is built-in sustainability, in which ([[non-renewable]]) resource-wasting is ruled out by design. They are generally built to be [[holistic]], robustly [[self-sustaining]] and respecting the [[carrying capacity]] of the economic or [[ecosystem|ecological]] system.

==Resource use measurement and identification of hotspots==
A key tool in resource efficiency is measuring different aspects of resource use (e.g. [[carbon footprint]], [[water footprint]], [[land footprint]] or [[Material flow accounting|material use]]), then identifying 'hot spots' where the most resources are used or where there are the best opportunities to reduce this resource use. For example, [[Waste &amp; Resources Action Programme|WRAP]] has published information on hotspots for 50 grocery products likely to contribute most to the [[environmental impact]]s associated with UK [[household consumption]]. &lt;ref&gt;{{cite web|url=http://www.wrap.org.uk/content/hotspot-data-50-grocery-products|title=Hotspot data for 50 grocery products|publisher=}}&lt;/ref&gt;
WRAP have created a range of tools and guides to help improve business resource efficiency.&lt;ref&gt;{{cite web|url=http://www.wrap.org.uk/content/business-resource-efficiency-hub|title=Business Resource Efficiency Hub|publisher=}}&lt;/ref&gt;

==Initiatives and programmes==

===UNEP===
[[UNEP]] works to promote resource efficiency and ''[[sustainable consumption]] and [[sustainable production|production]]'' (SCP) in both developed and [[developing countries]]. The focus is on achieving increased understanding and implementation by public and private decision makers, as well as civil society, of policies and actions for resource efficiency and SCP. This includes the promotion of sustainable [[resource management]] in a [[Product life cycle|life cycle]] perspective for goods and services.&lt;ref&gt;{{cite web|url=http://www.unep.org/resourceefficiency/|title=Welcome to Resource Efficiency - Resource Efficiency|author=|date=|website=www.UNEP.org|access-date=5 May 2017}}&lt;/ref&gt;

===Europe 2020===
The resource-efficient Europe flagship initiative is part of the [[Europe 2020]] Strategy, the EU's growth strategy for a smart, inclusive and [[sustainable economy]]. It supports the shift towards [[sustainable growth]] via a resource-efficient, [[low-carbon economy]].&lt;ref&gt;{{cite web|url=http://ec.europa.eu/environment/resource_efficiency/|title=Resource Efficiency - Environment - European Commission|author=|date=|website=EC.Europa.eu|access-date=5 May 2017}}&lt;/ref&gt;

===Tomsk Polytechnic University===
In October 2012 [[Tomsk Polytechnic University]] (TPU) launched the Development Program of Resource Efficient Technologies for the period 2013–2018.&lt;ref&gt;{{cite web|url=http://res-eff.tpu.ru/en/|title=Resource Effisient Technologies Center of Exellence - Home|author=|date=|website=res-eff.TPU.ru|access-date=5 May 2017}}&lt;/ref&gt; That program was presented by TPU in 2009 at the Russian federal competition  "National Research University". A key point of the program of TPU was announced the formation of high school as a world-class university-based staffing and development of technologies for resource-efficient economy.

TPU developed educational module "Resource Efficiency", prepared and published a textbook "Principals of resource efficiency", optional subject matter of the same name introduced in the curriculum (for all disciplines and areas of undergraduate).

TPU envisages university development in the field of resource-efficient technologies that unites six research and educational clusters:
#Safe Environment
##Non-destructive testing and diagnostics
##Materials for extreme conditions
##Domestic and industrial [[waste recycling]]
#[[Sustainable Energy]]
##[[High-temperature superconductivity]] technologies for [[energy production]]
##Nuclear and hydrogen fuel of the new generation
##[[Hybrid simulation]] in energy production
##Resource-efficient generation
#[[Medical Engineering]]
##[[Bioengineering]] materials and technologies
##Radiation technologies in bioengineering
##Electrophysical biomedical complexes
#Planet Resources
##Resource-efficient use of mineral resources
##Clear water
##[[Green chemistry]]
#Cognitive Systems and Telecommunications
##[[Cognitive software]] and hardware systems
##[[Wireless telecommunication]] systems and technologies
#Social Science and Humanities in Engineering
##Social science and humanities component of engineering
##Mechanisms of technical innovations initiation and engineering forethought

===Resource Efficient Scotland===
''Resource Efficient Scotland'' is a Scottish government-funded programme that helps businesses and the public and third sectors save money by using resources more efficiently.&lt;ref&gt;{{cite web|url=http://www.resourceefficientscotland.com/|title=Resource Efficient Scotland|work=Resource Efficient Scotland}}&lt;/ref&gt;

==See also==
* [[Scarcity]]
* [[Natural resource management]]

==References==
{{reflist}}


[[Category:Resources]]
[[Category:Waste minimisation]]</text>
      <sha1>958q238ars6ht7rx2izi6l8unfq2fp4</sha1>
    </revision>
  </page>
  <page>
    <title>School for Advanced Research</title>
    <ns>0</ns>
    <id>19864705</id>
    <revision>
      <id>848893162</id>
      <parentid>842670649</parentid>
      <timestamp>2018-07-05T02:32:09Z</timestamp>
      <contributor>
        <username>FrescoBot</username>
        <id>9021902</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:FrescoBot/Links|link syntax]] and minor changes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13705">{{Infobox university
| name              = School for Advanced Research
| image_name        = 
| image_size        = 
| image_alt         = 
| latin_name        = 
| motto             = 
| mottoeng          = 
| established       = 
| founder           = [[Alice Cunningham Fletcher]]
| type              = Private
| affiliation       = 
| endowment         = 
| budget            = 
| officer_in_charge = 
| chairman          = 
| chancellor        = 
| president         = Michael F. Brown
| vice-president    = 
| superintendent    = 
| provost           = 
| vice_chancellor   = 
| rector            = 
| principal         = 
| dean              = 
| director          = 
| head_label        = 
| head              = 
| academic_staff    = 
| administrative_staff  = 
| students          = 
| doctoral          = 
| other             = 
| city              = [[Santa Fe, New Mexico|Santa Fe]]
| state             = [[New Mexico]]
| province          = 
| country           = U.S.
| coor              = 
| campus            = 
| former_names      = School of American Archaeology, School of American Research
| free_label        = 
| free              = 
| affiliations      = 
| website           = {{URL|http://sarweb.org}}
| logo              = 
| footnotes         = 
}}

[[File:SAR ordaz 01.jpg|thumb|Spiral at the School for Advanced Research, May 2007.]]

The '''School for Advanced Research (SAR)''', until 2007 known as the '''School of American Research''' and founded in 1907 as the '''School for American Archaeology''' (SAA), is an advanced [[research center]] located in [[Santa Fe, New Mexico]], USA. Since 1967, the scope of the school's activities has embraced a global perspective through programs to encourage advanced scholarship in [[anthropology]] and related [[social science]] disciplines and the [[humanities]], and to facilitate the work of [[Native Americans in the United States|Native American]] scholars and artists. SAR offers residential fellowships for artists and scholars, and it publishes academic and popular non-fiction books through SAR Press.

== Foundation ==
[[File:Edgar lee hewett1.jpg|thumb|[[Edgar Lee Hewett]], president of [[New Mexico Highlands University|New Mexico Normal University]] in 1898]]
In the early years of the 20th century, [[archaeology]] was a young discipline with roots in historical studies of [[Old World]] antiquities. In 1906 [[Alice Cunningham Fletcher]], an anthropologist and ethnographer of [[Plains Indian]] groups, was on the American Committee of the [[Archaeological Institute of America]]. The AIA, founded in Boston in 1879, had schools in [[Athens]], [[Rome]], and [[Palestine (region)|Palestine]] that sponsored research on classical civilization and promoted professional standards in archaeology. Fletcher wanted to establish an "Americanist" center to train students in the profession of archaeology, to engage in anthropological research in the Americas, and to preserve and study the unique cultural heritage of the [[American Southwest]]. 

Her goals coincided with those of [[Edgar Lee Hewett]], an educator and amateur archaeologist whom she met in [[Mexico]] in 1906.&lt;ref&gt;''A Peculiar Alchemy: A Centennial History of SAR,'' Nancy Owen Lewis and Kay Leigh Hagan, SAR Press, 2007&lt;/ref&gt;&lt;ref&gt;''The School of American Research: A History,'' Malinda Elliott, SAR Press, 1987&lt;/ref&gt;
Nicknamed "El Toro" (the bull), Hewett was a controversial figure.&lt;!-- Why? Don't say "controversial" if you don't intend to explain--&gt; He served as president of New Mexico Normal School in [[Las Vegas, New Mexico|Las Vegas]] (now [[New Mexico Highlands University]]) from 1898 to 1903, where he taught some of the first anthropology courses to be offered at any U.S. college. His work lobbying for the protection of archaeological sites led to the creation of [[Mesa Verde National Park]] and the passage of the U.S. [[Antiquities Act]] of 1906.

In December 1907, the American Committee of the AIA accepted Fletcher's plan to establish the School of American Archaeology. It appointed Hewett as director and Fletcher as the first chairperson of the School's managing committee.

== Early years ==
Santa Fe, then the capital of [[New Mexico Territory]], was chosen as the School of American Archaeology's headquarters in part because the territorial government offered the historic [[Palace of the Governors]] as a permanent home. In 1909, the legislature established the [[Museum of New Mexico]] as an agency of the School, creating a relationship that would continue for the next 50 years. Hewett became director of both the Museum and the School.&lt;ref&gt;''A Laboratory for Anthropology: Science and Romanticism in the American Southwest, 1846–1930,'' Don D. Fowler, UNM Press, 2000&lt;/ref&gt; In 1917, the School of American Archaeology changed its name to the School of American Research to reflect a broader mission:
&lt;blockquote&gt;
"to promote and carry on research in Archaeology and related branches of the Science of Man; to foster Art in all its branches through exhibitions and by other means which may from time to time be desirable". (Articles of Incorporation 1917)
&lt;/blockquote&gt;
[[File:Ordaz Chaco Canyon.jpg|thumb|250px|right|Pueblo del Arroyo, [[Chaco Canyon]], New Mexico.]]
Midway through its first year of operations, the school was immersed in excavating Pueblo ruins on the eastern edge of the Pajarito Plateau, west of Santa Fe, and conducting the first of its field programs. Many legendary archaeologists, among them [[Neil Judd]], [[Alfred V. Kidder]], and [[Sylvanus Morley]], were trained at SAR field labs at Tyuonyi Ruin on El Rito de los Frijoles (now part of [[Bandelier National Monument]]), [[Chaco Canyon]], [[Puye Cliff Dwellings]], and other sites. The school also sponsored excavations in Mexico, Guatemala, and South America, and led the effort to preserve 22 Spanish missions in New Mexico. While directing the school, Hewett founded departments of anthropology at the [[University of Southern California]] and the [[University of New Mexico]].

Through the Museum of New Mexico, the school took an early interest in promoting and preserving the artistic traditions of Southwestern Indians. Indian workers assisted at the School's excavations on the Pajarito Plateau, and their interactions with Hewett, [[Kenneth M. Chapman]], and other archaeologists led to a recognition of individual talents and traditional aesthetics. Hewett and Chapman, an artist hired by Hewett to head the art department at New Mexico Normal School, and later one of the first employees of the School of American Archaeology, provided extensive support for Indian artists.  They offered studio facilities, as well as collecting and exhibiting their work. Early Native artists promoted by SAR included [[Maria Martinez]], Crescencio Martinez, [[Awa Tsireh]], and [[Fred Kabotie]], among many others.&lt;ref&gt;''Kenneth Chapman's Santa Fe: Artists and Archaeologists, 1907–1931,'' edited by Marit K. Munson, SAR Press, 2008&lt;/ref&gt; In 1922, the school sponsored the first Southwest Indian Fair, precursor of today's world-renowned [[Santa Fe Indian Market]].

Hewett led the school and museum until his death in 1946 at age 82. A 20-year period of relative inactivity followed. The School continued to pursue archaeological research projects on a modest scale.  It was headed, successively, by Sylvanus Morley, Boaz Long, Wayne L. Mauzy, Edward Weyer, Jr., and Eugene McCluney. This transition period ended in 1959, when the State Legislature formally separated the [[Museum of New Mexico]] from the School. The School of American Research was gutted, left with a staff of two and an uncertain future.

== Rebuilding the school ==
In 1967, [[Douglas W. Schwartz]], a young professor of anthropology from the [[University of Kentucky]], became the new director of the School of American Research.  Schwartz broadened the school's focus to embrace advanced scholarship in anthropology and the humanities worldwide; and to promote the study, preservation, and creation of Southwest Indian art. Schwartz also continued the school's archaeological research with field excavations in the [[Grand Canyon]] in the late 1960s and, in the 1970s, the excavations of [[Arroyo Hondo Pueblo]].&lt;ref name="Arroyo Hondo Pueblo Project"&gt;http://www.arroyohondo.org&lt;/ref&gt;&lt;ref name="Conrad et al. 2016"&gt;{{cite journal|last1 = Conrad | first1 = Cyler | last2=Jones |first2=Emily Lena | last3=Newsome |first3=Seth D. |last4=Schwartz |first4=Douglas W. | year= 2016 | title=Bone isotopes, eggshell and turkey husbandry at Arroyo Hondo Pueblo | url=http://www.sciencedirect.com/science/article/pii/S2352409X1630267X | journal= Journal of Archaeological Science: Reports | doi=10.1016/j.jasrep.2016.06.016}}&lt;/ref&gt;

Over the years, SAR's offices had relocated from the Palace of the Governors to the Hewett House on Lincoln Street. In 1973, the school moved into an old adobe estate on Santa Fe's east side. ''El Delirio'' had been the home of Martha Root White and Amelia Elizabeth White. Built in the 1920s by [[William Penhallow Henderson]], the estate was a popular gathering place for Santa Fe artists, writers, and intellectuals—among them Hewett, Morley, and others associated with the school. The White sisters were avid promoters of Indian art, and together they opened the first Native American art gallery in New York City. Elizabeth also was a founding member of the [[Indian Arts Fund]] (IAF) in Santa Fe and sat on SAR's Board of Managers for 25 years. When Elizabeth died in 1972 at age 94, she left El Delirio and other Santa Fe properties to the School. In that same year, the IAF disbanded and deeded its collections of Southwest Indian art to the School.

The new campus, with its many buildings, permitted the realization of Schwartz's vision for the school. The Advanced Seminar Program was inaugurated in 1968, and has since sponsored more than 120 seminars, the results of which are published by the school's SAR Press. The Resident Scholar Program, launched in 1972, has provided over 180 scholars with residential fellowships.

The construction of the Indian Arts Research Center in 1978 gave the collections inherited from the IAF a suitable home. In 1988, the J. I. Staley Prize was established to recognize books by living authors that exemplify outstanding research in anthropology. Over the succeeding two decades, several residential fellowships for Native artists were also established.

== New century, new directions ==
In 2001, SAR was under a new president, Richard M. Leventhal, an archaeologist from UCLA who assumed leadership of the school on the retirement of Dr. Schwartz. During his three-year tenure at the School, Dr. Leventhal worked to revitalize SAR’s core programs and extend greater opportunities for scholars and visiting Native artists. Dr. Leventhal was succeeded in 2005 by Dr. James F. Brooks, formerly director of SAR Press. His term coincided with the school’s centennial in 2007, when SAR changed its name from the School of American Research to the School for Advanced Research, to better reflect the global reach of its support for scholarship in the social sciences and humanities. Some of the highlights of Brooks’s tenure include new initiatives such as the Campbell Program for Women Scholar Practitioners—which has supported women from Morocco, Ethiopia, and Kenya in developing strategies for women’s economic and social empowerment—and an emphasis on collaborative research and exhibition projects with Native peoples; monthly Sparks Talks on local history and culture; and a field trip program serving more than two hundred participants annually, visiting locations as near as Pecos National Monument and as far as the borderlands of southeastern Turkey.

When Brooks resigned his post in June 2013, SAR’s Board of Directors appointed Dr. David E. Stuart, an anthropologist and long-time teacher and senior administrator at the University of New Mexico, as interim president. In June 2014, Michael F. Brown assumed SAR’s presidency after shifting to emeritus status at Williams College, on whose faculty he had long served. Brown, a cultural anthropologist familiar with SAR from participation in two advanced seminars and a term as resident scholar, has published extensively on new religious movements, the indigenous peoples of South America, and global efforts to protect indigenous cultural property from appropriation and misuse.

== Current programs ==
The School for Advanced Research offers residential fellowships for scholars and Native artists, and internships are provided for Native students pursuing academic careers or professional careers in museums. The School also sponsors scholarly seminars through its Advanced Seminar and Short Seminar programs. The results of many of these programs are published through SAR Press.  The school recognizes outstanding books in anthropology with the annual [[J. I. Staley Prize]]. Public outreach includes membership, lecture, and tour and field trip programs.  SAR has created an educational website for New Mexico grade-school students.

== References ==
{{reflist}}

== External links ==
*[http://www.sarweb.org/ Official site of the School for Advanced Research]
*[http://www.southwestcrossroads.org/ Southwest Crossroads website for New Mexico grade-school students]
{{coord missing|New Mexico}}

[[Category:Anthropological research institutes]]
[[Category:Art in New Mexico]]
[[Category:Research institutes in the United States]]
[[Category:Pre-Columbian studies]]
[[Category:Mesoamerican studies]]
[[Category:Educational institutions established in 1907]]
[[Category:1907 establishments in New Mexico Territory]]</text>
      <sha1>rv7vx9s4wo43nwu0ytzgw1mp0ioqhqs</sha1>
    </revision>
  </page>
  <page>
    <title>Significance analysis of microarrays</title>
    <ns>0</ns>
    <id>16022328</id>
    <revision>
      <id>841770701</id>
      <parentid>782127390</parentid>
      <timestamp>2018-05-17T23:17:07Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9288">{{Merge|Microarray analysis techniques|Gene chip analysis|discuss=talk:Microarray analysis techniques#Merger proposal|date=May 2017}}
{{Howto|date=May 2009}}
{{Expert needed|date=May 2009}}
[[Image:SAM.png|thumb|right]]
'''Significance analysis of microarrays (SAM)''' is a [[statistics|statistical technique]], established in 2001 by Virginia Tusher, [[Robert Tibshirani]] and [[Gilbert Chu]], for determining whether changes in [[gene expression]] are statistically significant. With the advent of [[DNA microarray]]s, it is now possible to measure the expression of thousands of genes in a single hybridization experiment.  The data generated is considerable, and a method for sorting out what is significant and what isn't is essential. SAM is distributed by [[Stanford University]] in an [[R (programming language)|R-package]].

SAM identifies statistically significant genes by carrying out gene specific [[Student's t-test|t-tests]] and computes a statistic ''d&lt;sub&gt;j&lt;/sub&gt;'' for each gene ''j'', which measures the strength of the relationship between gene expression and a response variable.&lt;ref name="R1"/&gt;&lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt; This analysis uses [[non-parametric statistics]], since the data may not follow a [[normal distribution]]. The response variable describes and groups the data based on experimental conditions. In this method, repeated [[permutations]] of the data are used to determine if the expression of any gene is significant related to the response.  The use of permutation-based analysis accounts for correlations in genes and avoids [[wikt:Special:Search/parametric|parametric]] assumptions about the distribution of individual genes.  This is an advantage over other techniques (e.g., [[ANOVA]] and [[Bonferroni]]), which assume equal variance and/or independence of genes.&lt;ref name="R6"/&gt;

==Basic protocol==
*Perform [[microarray]] experiments &amp;mdash; DNA microarray with oligo and cDNA primers, SNP arrays, protein arrays, etc.
*Input Expression Analysis in Microsoft Excel &amp;mdash; see below
*Run SAM as a Microsoft Excel   Add-Ins
*Adjust the Delta  tuning parameter  to get a significant # of genes along with an acceptable false discovery rate (FDR)) and Assess Sample Size by calculating the mean difference in expression in the SAM Plot Controller
*List Differentially Expressed Genes (Positively and Negatively Expressed Genes)

==Running SAM==
*SAM is available for download online at http://www-stat.stanford.edu/~tibs/SAM/ for academic and non-academic users after completion of a registration step.
*SAM is run as an Excel Add-In, and the  SAM Plot Controller allows Customization of the False Discovery Rate and Delta, while the  SAM Plot and SAM Output functionality generate a List of Significant Genes, Delta Table, and Assessment of Sample Sizes
*[[Permutations]] are calculated based on the number of samples
*Block Permutations
**Blocks are batches of microarrays; for example for eight samples split into two groups (control and affected) there are 4!=24 permutations for each block and the total number of permutations is (24)(24)= 576.  A minimum of 1000 permutations are recommended;&lt;ref name="R1"/&gt;&lt;ref name="R2"/&gt;&lt;ref name="R3"/&gt;
the number of permutations is set by the user when imputing correct values for the data set to run SAM

===Response formats&lt;ref name="R1"/&gt;===
'''Types'''
:*'''Quantitative''' &amp;mdash; real-valued (such as heart rate)
:*'''One class''' &amp;mdash; tests whether the mean gene expression differs from zero
:*'''Two class''' &amp;mdash; two sets of measurements
::*'''Unpaired''' &amp;mdash; measurement units are different in the two groups; e.g. control and treatment groups with samples from different patients
::*'''Paired''' &amp;mdash; same experimental units are measured in the two groups; e.g. samples before and after treatment from the same patients
:*'''Multiclass''' &amp;mdash; more than two groups with each containing different experimental units; generalization of two class unpaired type
:*'''Survival''' &amp;mdash; data of a time until an event (for example death or relapse)
:*'''Time course''' &amp;mdash; each experimental units is measured at more than one time point; experimental units fall into a one or two class design
:*'''Pattern discovery''' &amp;mdash; no explicit response parameter is specified; the user specifies eigengene (principal component) of the expression data and treats it as a quantitative response

==Algorithm==
SAM calculates a test statistic for relative difference in gene expression based on permutation analysis of expression data and calculates a false discovery rate.  The principal calculations of the program are illustrated below.&lt;ref name="R1"/&gt;&lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;

[[Image:Samcalc.jpg]] [[Image:RandS.jpg]]

The ''s''&lt;sub&gt;o&lt;/sub&gt; constant is chosen to minimize the coefficient of variation of ''d&lt;sub&gt;i&lt;/sub&gt;''.  r&lt;sub&gt;''i''&lt;/sub&gt; is equal to the expression levels (x) for gene ''i'' under y experimental conditions.

&lt;math&gt;\mathrm{False \ discovery \ rate \ (FDR) = \frac{Median \ (or \ 90^{th} \ percentile) \ of \ \# \ of \ falsely \ called \ genes}{Number \ of \ genes \ called \ significant}}&lt;/math&gt;

'''Fold changes''' (t) are specified to guarantee genes called significant change at least a pre-specified amount.  This means that the absolute value of the average expression levels of a gene under each of two conditions must be greater than the fold change (t) to be called positive and less than the inverse of the fold change (t) to be called negative.

The SAM algorithm can be stated as:
#Order test statistics according to magnitude &lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;
#For each permutation compute the ordered null (unaffected) scores &lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;
#Plot the ordered test statistic against the expected null scores &lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;
#Call each gene significant if the absolute value of the test statistic for that gene minus the mean test statistic for that gene is greater than a stated threshold &lt;ref name="R8"/&gt;
#Estimate the false discovery rate based on expected versus observed values &lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;

===Output===
*Significant gene sets
**Positive gene set &amp;mdash; higher expression of most genes in the gene set correlates with higher values of the phenotype y
**Negative gene set &amp;mdash; lower expression of most genes in the gene set correlates with higher values of the phenotype y

==SAM features==
*Data from Oligo or cDNA arrays, SNP array, protein arrays,etc. can be utilized in SAM&lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;
*Correlates expression data to clinical parameters&lt;ref name="R6"/&gt;
*Correlates expression data with time&lt;ref name="R1"/&gt;
*Uses data permutation to estimates False Discovery Rate for multiple testing&lt;ref name="R7"/&gt;&lt;ref name="R8"/&gt;&lt;ref name="R6"/&gt;&lt;ref name="R5"/&gt;
*Reports local false discovery rate (the FDR for genes having a similar d&lt;sub&gt;i&lt;/sub&gt; as that gene)&lt;ref name="R1"/&gt; and miss rates &lt;ref name="R1"/&gt;&lt;ref name="R7"/&gt;
*Can work with blocked design for when treatments are applied within different batches of arrays&lt;ref name="R1"/&gt;
*Can adjust threshold determining number of gene called significant&lt;ref name="R1"/&gt;

==See also==
* [[Microarray analysis techniques]]
* [[Microarray|Microarrays]]

==References==
{{reflist|refs=
&lt;ref name="R1"&gt;Chu, G., Narasimhan, B, Tibshirani, R, Tusher, V.  "SAM "Significance Analysis of Microarrays" Users Guide and technical document."    [http://www-stat.stanford.edu/~tibs/SAM/sam.pdf]&lt;/ref&gt;
&lt;ref name="R2"&gt;Dinu, I. P., JD; Mueller, T; Liu, Q; Adewale, AJ; Jhangri, GS; Einecke, G; Famulski, KS; Halloran, P; Yasui, Y. (2007). "Improving gene set analysis of microarray data by SAM-GS." BMC Bioinformatics 8: 242.&lt;/ref&gt;
&lt;ref name="R3"&gt;Jeffery, I. H., DG; Culhane, AC. (2006). "Comparison and evaluation of methods for generating differentially expressed gene lists from microarray data." BMC Bioinformatics 7: 359.&lt;/ref&gt;
&lt;ref name="R5"&gt;Larsson, O. W., C; Timmons, JA. (2005). "Considerations when using the significance analysis of microarrays (SAM) algorithm." BMC Bioinformatics 6: 129.&lt;/ref&gt;
&lt;ref name="R6"&gt;Tusher, V. G., R. Tibshirani, et al. (2001). "Significance analysis of microarrays applied to the ionizing radiation response." Proceedings of the National Academy of Sciences 98(9): 5116&amp;ndash;5121. [http://www-stat.stanford.edu/~tibs/SAM/pnassam.pdf]&lt;/ref&gt;
&lt;ref name="R7"&gt;Zang, S., R. Guo, et al. (2007). "Integration of statistical inference methods and a novel control measure to improve sensitivity and specificity of data analysis in expression profiling studies." Journal of Biomedical Informatics 40(5): 552&amp;ndash;560&lt;/ref&gt;
&lt;ref name="R8"&gt;Zhang, S. (2007). "A comprehensive evaluation of SAM, the SAM R-package and a simple modification to improve its performance." BMC Bioinformatics 8: 230.&lt;/ref&gt;
}}
{{refbegin}}
*Kooperberg, C., S. Sipione, et al. (2002). "Evaluating test statistics to select interesting genes in microarray experiments." Hum. Mol. Genet. 11(19): 2223&amp;ndash;2232.
{{refend}}

==External links==
* [https://web.archive.org/web/20090615060922/http://www-stat-class.stanford.edu/~tibs/clickwrap/sam.html   SAM download instructions]

{{DEFAULTSORT:Significance Analysis Of Microarrays}}
[[Category:Statistical genetics]]
[[Category:Gene expression]]
[[Category:Microarrays]]</text>
      <sha1>1rrqu02gnqh01b3vpa5cmnfsqpelgtq</sha1>
    </revision>
  </page>
  <page>
    <title>Society for Developmental Biology</title>
    <ns>0</ns>
    <id>13690160</id>
    <revision>
      <id>850501114</id>
      <parentid>658811177</parentid>
      <timestamp>2018-07-16T07:59:24Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <comment>removed [[Category:Scientific societies]]; added [[Category:American scientific societies]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3253">{{Other uses2|SDB}}

The '''Society for Developmental Biology''' ('''SDB''') is a professional society for basic scientists and physicians around the world whose [[research]] is focused on the study of the [[developmental biology]] and [[embryology]].

== History ==
The Society for Developmental Biology (SDB) was founded in 1939 to promote the field of developmental biology and to advance the understanding of developmental biology at all levels. SDB is a non-profit professional society dedicated to advancement of the field of developmental biology. Over recent decades, the SDB has grown  to nearly 2000 members, and has evolved to provide an international forum for research, education and career development in developmental biology.

The stated [[mission statement|mission]] of the society is to:
#Foster excellence in research and education in developmental biology.
#Provide advice and resources on careers in developmental biology.
#Provide information for the public on relevant topics in developmental biology.
#Provide a communication hub for all developmental biologists.

The Society is associated with the monthly [[peer review]]ed [[Scientific journal|journal]], ''[[Developmental Biology]]''.

== Awards ==
The Society for Developmental Biology inaugurated the [[Edwin Grant Conklin Medal]] in 1995 to honor the biologist [[Edwin Conklin]].&lt;ref name = "EGC medal"&gt;{{cite web |url = http://www.sdbonline.org/index.php?option=content&amp;task=view&amp;id=8 |title = Edwin Grant Conklin Medal |publisher = Society for Developmental Biology}}&lt;/ref&gt;

An annual [[Lifetime Achievement Award]] was begun in 2000. &lt;ref&gt;{{cite web|title=Society for Developmental Biology Lifetime Achievement Award|url=http://www.sdbonline.org/index.php?option=com_content&amp;task=view&amp;id=10&amp;Itemid=50|accessdate=April 2, 2013}}&lt;/ref&gt;

== Annual Meeting ==
The Society holds an annual meeting that is attended by scientists from around the world. The 68th annual meeting in 2009 will be held in [[San Francisco, CA]]. In addition to the annual meetings, specific regions around the U.S. hold regional meetings.

=== Past Meetings ===
The first symposium on Development and Growth was sponsored by the editors of [[Growth (magazine)|Growth]], and it was held in August 1939, at North Truro. Subsequent meetings have been held in a variety of cities throughout the world. A selection of recent meetings are summarized in the table. More information about future and past annual meetings are posted on the Society's official website [http://www.sdbonline.org/].
{| class="wikitable"
! Year
! Dates
! Venue
! Presiding President
|-
| 2006
| unk
| [[San Francisco, CA]]
| Michael Crow
|-
| 2007
| June
| [[Cancun, Mexico]]
| [[Gail R. Martin]]
|-
| 2008
| date TBA
| [[Philadelphia, PA]]
| [[Eric F. Wieschaus]]
|-
| 2009
| July 23–27
| [[San Francisco, CA]]
| Marianne Bronner-Fraser
|}

== References ==
{{reflist}}

== External links ==
*[http://www.sdbonline.org/ Society for Developmental Biology home page]
*[http://www.elsevier.com/wps/find/journaldescription.cws_home/622816/description#description Developmental Biology journal home page]

[[Category:Developmental biology]]
[[Category:American scientific societies]]
[[Category:Organizations established in 1939]]</text>
      <sha1>aswp5jc3eo2lqgphkmdvt6ar8zejbo4</sha1>
    </revision>
  </page>
  <page>
    <title>Stratigraphic paleobiology</title>
    <ns>0</ns>
    <id>58600218</id>
    <revision>
      <id>865586210</id>
      <parentid>861586594</parentid>
      <timestamp>2018-10-24T20:55:58Z</timestamp>
      <contributor>
        <username>NikelsenH</username>
        <id>18120325</id>
      </contributor>
      <minor/>
      <comment>/* Topic and key concepts */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2476">'''Stratigraphic paleobiology''' is a branch of [[geology]] that is closely related to [[paleobiology]], [[sequence stratigraphy]] and [[sedimentology]]. Stratigraphic paleobiology studies how the [[fossil record]] is altered by sedimentological processes and how this affects [[biostratigraphy]] and paleobiological interpretations of the fossil record.&lt;ref name="scarponi2008"/&gt;

== Topic and key concepts ==
Holland and Patzkowsky (2012) define stratigraphic paleobiology as follows:&lt;ref name="hollandpatzkowsky2"/&gt;

"[Stratigraphic paleobiology] is built on the premise that the distribution of fossil taxa in time and space is controlled not only by processes of evolution, ecology, and environmental change, but also by the stratigraphic processes that govern where and when sediment that might contain fossils is deposited and preserved. Teasing apart the effects of these two suites of processes to understand the history of life on Earth is the essence of stratigraphic paleobiology."

Large parts of stratigraphic paleobiology rely on [[sequence stratigraphy]]. This is since within a sequence, many parameters such as depositional conditions, (non)preservation, and [[facies]] change deterministically. This sequence stratigraphic background alone, without any changes in ecology or any evolutionary processes, creates a baseline of constant change in the number of fossils and taxa that are preserved. One example for this are [[maximum flooding surface]]s, which commonly display large accumulations of shells and an increased number of first fossil occurrences and last fossil occurrences. This is however not necessary linked to any change in ecology or an extinction event, but can be generated by the low deposition rates during the maximum flooding surface alone.

== See also ==
* [[Range offset]]
* [[Depositional resolution]]

== References ==
&lt;references&gt;
&lt;ref name="hollandpatzkowsky2"&gt;{{cite book |last1=Patzkowsky |first1= Mark E. |first2=Steven M. |last2=Holland|year= 2012|title=Stratigraphic Paleobiology |location=Chicago |publisher=University of Chicago University Press|pages=2}} &lt;/ref&gt;
&lt;ref name="scarponi2008"&gt;{{cite journal |last1=Scarponi |first1=Daniele |last2=Angeletti |first2=Lorenzo |year=2008 | title= Integration of palaeontological patterns in the sequence stratigraphy paradigm: a case study from Holocene deposits of the Po Plain (Italy) |journal= GeoActa}} &lt;/ref&gt;
&lt;/references&gt;

[[Category:Paleobiology]]
[[Category:Stratigraphy]]</text>
      <sha1>8td7ypz3xu9ffi72yno5bclrjek75xx</sha1>
    </revision>
  </page>
  <page>
    <title>The lamb and lion</title>
    <ns>0</ns>
    <id>55184452</id>
    <revision>
      <id>862134636</id>
      <parentid>841126864</parentid>
      <timestamp>2018-10-02T11:48:13Z</timestamp>
      <contributor>
        <username>Pa2rick</username>
        <id>19130881</id>
      </contributor>
      <minor/>
      <comment>Spelling correction, "Restoraionist" &gt;&gt; "Restorationist"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7248">{{About|heraldry||Lamb and lion (disambiguation)}}
[[File:The sign for the Lamb and Lion, Bath - geograph.org.uk - 987958.jpg|thumb|The lamb and the lion as they appear on an establishment's signboard in [[Bath, England]]]]
[[File:Knesset Menorah Isaiah P5200011.JPG|thumb|Part of the [[Knesset Menorah]] includes relief of a lamb, lion, various other animals, and a little child under a representation of Isaiah.]]
[[File:William Strutt Peace 1896.jpg|thumb|"Peace," etching by the Australian artist [[William Strutt]], 1896]]
[[File:Edward Hicks - Peaceable Kingdom.jpg|thumb|[[Edward Hicks]], "Peaceable Kingdom," c. 1834]]
'''"The lamb with the lion"''' &amp;ndash; often a paraphrase from Isaiah, and more closely quoted as "the '''wolf and lamb'''", "a '''child will lead them'''", and the like &amp;ndash; are an artistic and symbolic device, most generally related to peace.

The symbol is used in both Christianity and Judaism to represent the [[Messianic Age]].&lt;ref&gt;{{cite book|url = https://books.google.com/books?id=gbkRAAAAQBAJ&amp;pg=PA25&amp;dq|page = 25|title = Judaism in America|author = Marc Lee Raphael|publisher = [[Columbia University Press]]|year = 2012}}&lt;/ref&gt; In addition, in Christianity, according to a sermon by [[Augustine]], [[Lion (heraldry)|the lion]] stands for Christ resurrected, [[Lamb of God|the lamb]] for Christ's sacrifice ("He endured death as a lamb; he devoured it as a lion."&amp;mdash;Augustine, Sermon 375A).&lt;ref&gt;{{cite book|url = https://books.google.com/books?id=egKpDgAAQBAJ&amp;pg=PT17&amp;dq#v=onepage&amp;q&amp;f=false|title = Saint Augustine on the Resurrection of Christ: Teaching, Rhetoric, and Reception|author = Gerald O'Collins|publisher = [[Oxford University Press]]|year = 2017|isbn = 9780192520173}}&lt;/ref&gt;

Although [[Isaiah]] 35:2 casts a lion metaphorically as forbidden in the future paradise ("No lion shall be there, nor any ravenous beast shall go up thereon, it shall not be found there; but the redeemed shall walk there"); in [[Isaiah 11:6|11:6]],7, Isaiah references such formerly ravenous beasts as become peaceable: "The wolf will live with the lamb, the leopard will lie down with the goat, the calf and the lion and the yearling together; and a little child will lead them. The cow will feed with the bear, their young will lie down together, and the lion will eat straw like the ox."&lt;ref&gt;{{cite web|author = Pini Dunner|date = July 14, 2017|url=https://www.algemeiner.com/2017/07/14/the-state-of-israel-is-the-first-stage-of-the-messianic-era/|title=The State of Israel Is the First Stage of the Messianic Era|publisher=[[The Algemeiner]]}}&lt;/ref&gt;

'''"In like a lion, out like a lamb"''' is a proverb having to do with March weather. It has been speculated that its origin is from [[Astrology|astrological]] [[Leo (astrology)|Leo]] (lion) being followed by [[Aries (astrology)|Aries]] ([kid] goat).&lt;ref&gt;{{cite web|url=https://www.theparisreview.org/blog/2015/03/02/folk-wisdom/ |title=Where Does "In Like a Lion, Out Like a Lamb" Originate? |publisher=Theparisreview.org |date= |accessdate=2017-09-12}}&lt;/ref&gt;

==Examples==

In the 1830s, American [[Quaker]] artist Edward Hicks began painting a series of paintings on the theme of the [[Peaceable Kingdom (theology)|Peaceable Kingdom]].

The kingdom-of-peace motif has been popular among various so-called Christian [[Restorationism|"Restorationist"]] groups. For example:
* The lamb and lion have been used informally in [[Community of Christ]] since the [[Church of Christ (Latter Day Saints)|Latter Day Saints' "Kirtland" period]].{{#tag:ref|The [[Latter Day Saint movement]]'s founder, Joseph Smith, Jr. ([[Joseph Smith III]]'s father), related during the [[Zion's Camp]] expedition: "In pitching my tent we found three massasaugas or prairie rattlesnakes, which the brethren were about to kill, but I said, Let them alone &amp;ndash; don't hurt them! How will the serpent ever lose his venom, while the servants of God possess the same disposition, and continue to make war upon it? Men must become harmless, before the brute creation; and when men lose their vicious dispositions and cease to destroy the animal race, the lion and the lamb can dwell together, and the sucking child can play with the serpent in safety." &amp;mdash;[[Joseph Smith, Jr.]], 1834&lt;ref&gt;{{cite book|url = https://books.google.com/books?id=eIOs5efUfuoC&amp;q=lamb#v=snippet&amp;q=%22lion%20and%20the%20lamb%22&amp;f=false|page = 293|title = Prophecies of Joseph Smith|author = [[Duane S. Crowther]]|publisher = Cedar Fort|year = 2008|isbn = 9780882908427}}&lt;/ref&gt;|group="nb"}} Its original formal iteration, prominently featuring the lion, the lamb, and child, along with the motto ''Peace'', was designed by [[Joseph Smith III]], [[Jason W. Briggs]], and Elijah Banta, and approved in the denomination's General Conference in 1874.&lt;ref&gt;{{cite journal|author = Lawrence W. Tyree|title = Impressions with a Purpose: Omissions, Myths, and the Real Origins of the Church Seal|journal = [[Restoration Studies]]|volume = 12|year = 2011}}&lt;/ref&gt;
[[File:CoC Seal.jpg|thumb|Seal of the Community of Christ (c. 1950s; since the 1960s it has been simplified, e.g.,  braiding around circumference removed)]]

* The [[Worldwide Church of God]] (now [[Grace Communion International]]) had used a seal depicting the lamb, the lion and a child.&lt;ref&gt;{{cite web|url=http://asecondlook.info/000glendora/articles/2003/2003lamb.htm |title=Why Not the Lion and the Lamb? |publisher=Asecondlook.info |date= |accessdate=2017-09-12}}&lt;/ref&gt;

A number of "peace" gardens or fountains at Jewsish, Catholic, and Protestant places of worship contain statuary containing the lamb and lion. In 1987, the Lion &amp; Lamb Peace Arts Center was established at [[Mennonite]] [[Bluffton University]].&lt;ref&gt;{{cite web|url=http://www.blufftonicon.com/news/2017/04/25/planting-seeds-peace-30-years |title=Planting seeds of peace for 30 years |publisher=The Bluffton Icon |date=2017-04-25 |accessdate=2017-09-12}}&lt;/ref&gt;

Humorist [[Josh Billings]] (1818–1885): "The lion and the lamb may possibly sometimes lie down together; but if you'll notice carefully, when the lion gets up, the lamb is generally missing."&lt;ref&gt;{{cite book|url = https://books.google.com/books?id=uk1EAQAAMAAJ&amp;pg=PA19&amp;l#v=onepage&amp;q&amp;f=false|page = 19|author = [[Josh Billings]]|publisher = [[Shore Printing Company]]|year = 1913|title = Wit and Wisdom of Josh Billings}}&lt;/ref&gt; Attributed to [[Woody Allen]]: "I've always liked, someday the lamb will lay by the lion ... but it won't get much sleep."&lt;ref&gt;{{cite web|url=http://www.morefamousquotes.com/topics/quotes-about-the-lion-and-the-lamb/ |title=Quotes About The Lion And The Lamb: top 42 The Lion And The Lamb quotes from famous authors |publisher=Morefamousquotes.com |date= |accessdate=2017-09-12}}&lt;/ref&gt;

==See also==
* [[Peaceable Kingdom (disambiguation)|Peaceable Kingdom]]
* [[The Wolf and the Lamb]]
* [[Hosanna to God and the Lamb]]
* [[Snake handling]]
* [[Coat of arms of the London Borough of Barnet]]

== Notes ==
{{reflist|group="nb"}}
{{clear}}

== Citations ==
{{Commons category|Kingdom of peace}}
{{reflist}}

{{DEFAULTSORT:Lion and the lamb, The}}
[[Category:Peace symbols]]
[[Category:Symbols of Abrahamic religions]]
[[Category:Iconography]]
[[Category:Heraldry]]
[[Category:Lions in heraldry]]</text>
      <sha1>j44wv7as3kndiyoyn9shir1r1qi7wz5</sha1>
    </revision>
  </page>
  <page>
    <title>Tokamak à configuration variable</title>
    <ns>0</ns>
    <id>7255094</id>
    <revision>
      <id>865016946</id>
      <parentid>865016912</parentid>
      <timestamp>2018-10-21T04:13:32Z</timestamp>
      <contributor>
        <username>Minerman30</username>
        <id>30071999</id>
      </contributor>
      <comment>Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3638">{{refimprove|date=March 2016}}
{{Fusion devices
|name         = TCV
|image        = TCV-sup.jpg
|type         = [[Tokamak]]
|operation    = 1992–
|major radius = 0.88 m
|minor radius = 0.25 m
|field        = 1.43 [[Tesla (unit)|T]]
|heating      = 4.5 [[Megawatt|MW]]
|current      = 1.2 [[Megaampere|MA]]
|location     = [[Lausanne]], [[Switzerland]]
}}
[[File:Tcv int.jpg|thumb|Tokamak à Configuration Variable (TCV): inner view, with the graphite-clad torus. Courtesy of CRPP-EPFL, Association Suisse-Euratom]]
[[File:03 Toakamakclaudeseul.jpg|thumb|Tokamak à Configuration Variable (TCV): general view of the setup. Courtesy of CRPP-EPFL, Association Suisse-Euratom]]

The '''''Tokamak à configuration variable''''' ('''''TCV''''', literally "variable configuration [[tokamak]]") is a [[Switzerland|Swiss]] research [[nuclear fusion|fusion]] reactor of the [[École polytechnique fédérale de Lausanne]]. Its distinguishing feature over other tokamaks is that its torus section is three times higher than wide. This allows studying several shapes of plasmas, which is particularly relevant since the shape of the plasma has links to the performance of the reactor. The TCV was set up in November 1992.

== Characteristics ==
* Plasma height: 1.40 metres
* Minor radius: 0.25 metre
* Major radius: 0.88 metre
* Plasma current: 1.2 megaamperes
* Plasma life span: 2 seconds maximum
* Toroidal magnetic field: 1.43 teslas
* Additional heating power: 4.5 megawatts

== Main studies ==
* Confinement studies
** confinement as a function of the shape of the plasma (triangular, square or elongated)
** Improvement of the confinement of the core
* Studies on vertically elongated plasmas 
* Studies with ECRH and ECCD ([[electron cyclotron resonance heating]] and [[electron cyclotron current drive]])&lt;ref&gt;[http://spc.epfl.ch/research_TCV_Heating TCV Auxiliary Heating.]&lt;/ref&gt;

By 2012 it had 16 poloidal plasma shaping coils and could achieve a variety of field configurations and plasma shapes.&lt;ref&gt;[http://spc.epfl.ch/TCV-new-shapes TCV - Development of new plasma shapes. May 2012]&lt;/ref&gt;&lt;ref&gt;[http://spc.epfl.ch/research_TCV_Tokamak ] diagram shows 16 shaping coils and 7 other poloidal coils&lt;/ref&gt;

== History ==
* 1976: First proposal for an elongated tokamak by the "New Swiss Association"
* 1985: Second proposal, with a more elongated tokamak
* 1986: Acceptance of the TCV proposal (Tokamak à Configuration Variable)
* 1992: First plasma discharge
* 1997: World record of plasma elongation (see [[plasma shaping]])
* by August 2015 it has had a 19-month shutdown/upgrade to install its first [[neutral beam injector]].&lt;ref&gt;[https://www.euro-fusion.org/newsletter/keeping-fusion-research-on-the-boil-three-tokamaks-and-one-stellarator/ Keeping fusion research on the boil: Three tokamaks and one stellarator. August 2015]&lt;/ref&gt;
* by 2016 it was upgraded/enhanced to run with a 'snowflake' [[divertor]]&lt;ref&gt;[https://www.euro-fusion.org/newsletter/divertor-concepts/ Snowflake and the multiple divertor concepts. March 2016]&lt;/ref&gt;

==References==
{{reflist}}

== External links ==
{{Commons|Tokamak à Configuration Variable}}
* [http://crpp.epfl.ch/research_TCV TCV official site]
** [http://spc.epfl.ch/TCV-technical-data TCV Technical data] as of Oct 2012

{{Fusion experiments}}
{{Portal bar|Energy|Switzerland}}

{{DEFAULTSORT:Tokamak a configuration variable}}
[[Category:École Polytechnique Fédérale de Lausanne]]
[[Category:Fusion power]]
[[Category:Fusion reactors]]
[[Category:Nuclear fusion]]
[[Category:Nuclear research institutes]]
[[Category:Plasma physics]]
[[Category:Research projects]]
[[Category:Tokamaks]]</text>
      <sha1>ni00n05po0ok9fmmsbzpnmpb9sg74x0</sha1>
    </revision>
  </page>
  <page>
    <title>Uncertainty theory</title>
    <ns>0</ns>
    <id>25075497</id>
    <revision>
      <id>843321242</id>
      <parentid>843319332</parentid>
      <timestamp>2018-05-28T10:52:50Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{More footnotes}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18346">{{distinguish|Uncertainty principle}}
{{multiple issues|
{{more footnotes|date=May 2018}}
{{technical|date=December 2009}}
{{howto|date=December 2009}}
{{citation style|date=December 2009}}
{{misleading|date=December 2009}}
}}

'''Uncertainty theory''' is a branch of [[mathematics]] based on normality, monotonicity, self-duality, countable subadditivity, and product measure axioms.{{Clarify|date=December 2009}} It was founded by Baoding Liu &lt;ref&gt;Baoding Liu, Uncertainty Theory, 2nd ed., Springer-Verlag, Berlin, 2007.&lt;/ref&gt; in 2007 and refined in 2009.&lt;ref&gt;Baoding Liu, Uncertainty Theory, 4th ed., http://orsc.edu.cn/liu/ut.pdf.&lt;/ref&gt;

Mathematical measures of the likelihood of an event being true include [[probability theory]], capacity, [[fuzzy logic]], possibility, and credibility, as well as uncertainty.

==Four axioms==
'''Axiom 1.''' (Normality Axiom) &lt;math&gt;\mathcal{M}\{\Gamma\}=1\text{ for the universal set }\Gamma&lt;/math&gt;.

'''Axiom 2.''' (Self-Duality Axiom) &lt;Math&gt;\mathcal{M}\{\Lambda\}+\mathcal{M}\{\Lambda^c\}=1\text{ for any event }\Lambda&lt;/math&gt;.

'''Axiom 3.''' (Countable Subadditivity Axiom) For every countable sequence of events &amp;Lambda;&lt;sub&gt;1&lt;/sub&gt;, &amp;Lambda;&lt;sub&gt;2&lt;/sub&gt;, ..., we have
::&lt;math&gt;\mathcal{M}\left\{\bigcup_{i=1}^\infty\Lambda_i\right\}\le\sum_{i=1}^\infty\mathcal{M}\{\Lambda_i\}&lt;/math&gt;.

'''Axiom 4.''' (Product Measure Axiom) Let &lt;math&gt;(\Gamma_k,\mathcal{L}_k,\mathcal{M}_k)&lt;/math&gt; be uncertainty spaces for &lt;math&gt;k=1,2,\cdots,n&lt;/math&gt;. Then the product uncertain measure &lt;math&gt;\mathcal{M}&lt;/math&gt; is an uncertain measure on the product &amp;sigma;-algebra satisfying
::&lt;math&gt;\mathcal{M}\left\{\prod_{i=1}^n\Lambda_i\right\}=\underset{1\le i\le n}{\operatorname{min} }\mathcal{M}_i\{\Lambda_i\}&lt;/math&gt;.

'''Principle.''' (Maximum Uncertainty Principle) For any event, if there are multiple reasonable values that an uncertain measure may take, then the value as close to 0.5 as possible is assigned to the event.

==Uncertain variables==
An uncertain variable is a [[measurable function]] ξ from an uncertainty space &lt;math&gt;(\Gamma,L,M)&lt;/math&gt; to the [[set (mathematics)|set]] of [[real numbers]], i.e., for any [[Borel set]] '''B''' of [[real numbers]], the set 
&lt;math&gt;\{\xi\in B\}=\{\gamma \in \Gamma|\xi(\gamma)\in B\}&lt;/math&gt; is an event.

==Uncertainty distribution==
Uncertainty distribution is inducted to describe uncertain variables.

'''Definition''':The '''uncertainty distribution''' &lt;math&gt;\Phi(x):R \rightarrow [0,1]&lt;/math&gt; of an uncertain variable ξ is defined by &lt;math&gt;\Phi(x)=M\{\xi\leq x\}&lt;/math&gt;.

'''Theorem'''(Peng and Iwamura, ''Sufficient and Necessary Condition for Uncertainty Distribution'') A function &lt;math&gt;\Phi(x):R \rightarrow [0,1]&lt;/math&gt; is an uncertain distribution if and only if it is an increasing function except &lt;math&gt;\Phi (x) \equiv 0&lt;/math&gt; and &lt;math&gt;\Phi (x)\equiv 1&lt;/math&gt;.

==Independence==
'''Definition''': The uncertain variables &lt;math&gt;\xi_1,\xi_2,\ldots,\xi_m&lt;/math&gt; are said to be independent if 
:&lt;math&gt;M\{\cap_{i=1}^m(\xi \in B_i)\}=\mbox{min}_{1\leq i \leq m}M\{\xi_i \in B_i\} &lt;/math&gt;
for any Borel sets &lt;math&gt;B_1,B_2,\ldots,B_m&lt;/math&gt; of real numbers.

'''Theorem 1''': The uncertain variables &lt;math&gt;\xi_1,\xi_2,\ldots,\xi_m&lt;/math&gt; are independent if 
:&lt;math&gt;M\{\cup_{i=1}^m(\xi \in B_i)\}=\mbox{max}_{1\leq i \leq m}M\{\xi_i \in B_i\} &lt;/math&gt;
for any Borel sets &lt;math&gt;B_1,B_2,\ldots,B_m&lt;/math&gt; of real numbers.

'''Theorem 2''': Let &lt;math&gt;\xi_1,\xi_2,\ldots,\xi_m&lt;/math&gt; be independent uncertain variables, and &lt;math&gt;f_1,f_2,\ldots,f_m&lt;/math&gt; measurable functions. Then &lt;math&gt;f_1(\xi_1),f_2(\xi_2),\ldots,f_m(\xi_m)&lt;/math&gt; are independent uncertain variables.

'''Theorem 3''': Let &lt;math&gt;\Phi_i&lt;/math&gt; be uncertainty distributions of independent uncertain variables &lt;math&gt;\xi_i,\quad i=1,2,\ldots,m&lt;/math&gt; respectively, and &lt;math&gt;\Phi&lt;/math&gt; the joint uncertainty distribution of uncertain vector &lt;math&gt;(\xi_1,\xi_2,\ldots,\xi_m)&lt;/math&gt;. If &lt;math&gt;\xi_1,\xi_2,\ldots,\xi_m&lt;/math&gt; are independent, then we have 
:&lt;math&gt;\Phi(x_1, x_2, \ldots, x_m)=\mbox{min}_{1\leq i \leq m}\Phi_i(x_i)&lt;/math&gt;
for any real numbers &lt;math&gt;x_1, x_2, \ldots, x_m&lt;/math&gt;.

==Operational law==
'''Theorem''': Let &lt;math&gt;\xi_1,\xi_2,\ldots,\xi_m&lt;/math&gt; be independent uncertain variables, and &lt;math&gt;f: R^n \rightarrow R&lt;/math&gt; a measurable function. Then &lt;math&gt;\xi=f(\xi_1,\xi_2,\ldots,\xi_m)&lt;/math&gt; is an uncertain variable such that
::&lt;math&gt;\mathcal{M}\{\xi\in B\}=\begin{cases} \underset{f(B_1,B_2,\cdots,B_n)\subset B}{\operatorname{sup} }\;\underset{1\le k\le n}{\operatorname{min} }\mathcal{M}_k\{\xi_k\in B_k\}, &amp; \text{if } \underset{f(B_1,B_2,\cdots,B_n)\subset B}{\operatorname{sup} }\;\underset{1\le k\le n}{\operatorname{min} }\mathcal{M}_k\{\xi_k\in B_k\} &gt; 0.5 \\ 1-\underset{f(B_1,B_2,\cdots,B_n)\subset B^c}{\operatorname{sup} }\;\underset{1\le k\le n}{\operatorname{min} }\mathcal{M}_k\{\xi_k\in B_k\}, &amp; \text{if } \underset{f(B_1,B_2,\cdots,B_n)\subset B^c}{\operatorname{sup} }\;\underset{1\le k\le n}{\operatorname{min} }\mathcal{M}_k\{\xi_k\in B_k\} &gt; 0.5 \\ 0.5, &amp; \text{otherwise} \end{cases}&lt;/math&gt;
where &lt;math&gt;B, B_1, B_2, \ldots, B_m&lt;/math&gt; are Borel sets, and &lt;math&gt;f( B_1, B_2, \ldots, B_m)\subset B&lt;/math&gt; means&lt;math&gt;f(x_1, x_2, \ldots, x_m) \in B&lt;/math&gt; for any&lt;math&gt;x_1 \in B_1, x_2 \in B_2, \ldots,x_m \in B_m&lt;/math&gt;.

==Expected Value==
'''Definition''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable. Then the expected value of &lt;math&gt;\xi&lt;/math&gt; is defined by 
:::&lt;math&gt;E[\xi]=\int_0^{+\infty}M\{\xi\geq r\}dr-\int_{-\infty}^0M\{\xi\leq r\}dr&lt;/math&gt;
provided that at least one of the two integrals is finite.

'''Theorem 1''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with uncertainty distribution &lt;math&gt;\Phi&lt;/math&gt;. If the expected value exists, then 
:::&lt;math&gt;E[\xi]=\int_0^{+\infty}(1-\Phi(x))dx-\int_{-\infty}^0\Phi(x)dx&lt;/math&gt;.

[[File:Uncertain expected value.jpg|300px|center]]

'''Theorem 2''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with regular uncertainty distribution &lt;math&gt;\Phi&lt;/math&gt;. If the expected value exists, then 
:::&lt;math&gt;E[\xi]=\int_0^1\Phi^{-1}(\alpha)d\alpha&lt;/math&gt;.

'''Theorem 3''': Let &lt;math&gt;\xi&lt;/math&gt; and &lt;math&gt;\eta&lt;/math&gt; be independent uncertain variables with finite expected values. Then for any real numbers &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt;, we have
:::&lt;math&gt;E[a\xi+b\eta]=aE[\xi]+b[\eta]&lt;/math&gt;.

==Variance==
'''Definition''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with finite expected value &lt;math&gt;e&lt;/math&gt;. Then the variance of &lt;math&gt;\xi&lt;/math&gt; is defined by 
:::&lt;math&gt;V[\xi]=E[(\xi-e)^2]&lt;/math&gt;.

'''Theorem''': If &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with finite expected value, &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt; are real numbers, then
:::&lt;math&gt;V[a\xi+b]=a^2V[\xi]&lt;/math&gt;.

==Critical value==
'''Definition''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable, and &lt;math&gt;\alpha\in(0,1]&lt;/math&gt;. Then
:&lt;math&gt;\xi_{sup}(\alpha)=\mbox{sup}\{r|M\{\xi\geq r\}\geq\alpha\}&lt;/math&gt;
is called the α-[[optimistic]] value to &lt;math&gt;\xi&lt;/math&gt;, and 
:&lt;math&gt;\xi_{inf}(\alpha)=\mbox{inf}\{r|M\{\xi\leq r\}\geq\alpha\}&lt;/math&gt;
is called the α-[[pessimistic]] value to &lt;math&gt;\xi&lt;/math&gt;.

'''Theorem 1''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with regular uncertainty distribution &lt;math&gt;\Phi&lt;/math&gt;. Then its α-[[optimistic]] value and α-[[pessimistic]] value are 
::&lt;math&gt;\xi_{sup}(\alpha)=\Phi^{-1}(1-\alpha)&lt;/math&gt;,
::&lt;math&gt;\xi_{inf}(\alpha)=\Phi^{-1}(\alpha)&lt;/math&gt;.

'''Theorem 2''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable, and &lt;math&gt;\alpha\in(0,1]&lt;/math&gt;. Then we have
* if &lt;math&gt;\alpha&gt;0.5&lt;/math&gt;, then &lt;math&gt;\xi_{inf}(\alpha)\geq \xi_{sup}(\alpha)&lt;/math&gt;;
* if &lt;math&gt;\alpha\leq 0.5&lt;/math&gt;, then &lt;math&gt;\xi_{inf}(\alpha)\leq \xi_{sup}(\alpha)&lt;/math&gt;.

'''Theorem 3''': Suppose that &lt;math&gt;\xi&lt;/math&gt; and &lt;math&gt;\eta&lt;/math&gt; are independent uncertain variables, and &lt;math&gt;\alpha\in(0,1]&lt;/math&gt;. Then we have

&lt;math&gt;(\xi + \eta)_{sup}(\alpha)=\xi_{sup}(\alpha)+\eta_{sup}{\alpha}&lt;/math&gt;,

&lt;math&gt;(\xi + \eta)_{inf}(\alpha)=\xi_{inf}(\alpha)+\eta_{inf}{\alpha}&lt;/math&gt;,

&lt;math&gt;(\xi \vee \eta)_{sup}(\alpha)=\xi_{sup}(\alpha)\vee\eta_{sup}{\alpha}&lt;/math&gt;,

&lt;math&gt;(\xi \vee \eta)_{inf}(\alpha)=\xi_{inf}(\alpha)\vee\eta_{inf}{\alpha}&lt;/math&gt;,

&lt;math&gt;(\xi \wedge \eta)_{sup}(\alpha)=\xi_{sup}(\alpha)\wedge\eta_{sup}{\alpha}&lt;/math&gt;,

&lt;math&gt;(\xi \wedge \eta)_{inf}(\alpha)=\xi_{inf}(\alpha)\wedge\eta_{inf}{\alpha}&lt;/math&gt;.

==Entropy==
'''Definition''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with uncertainty distribution &lt;math&gt;\Phi&lt;/math&gt;. Then its entropy is defined by
::&lt;math&gt;H[\xi]=\int_{-\infty}^{+\infty}S(\Phi(x))dx&lt;/math&gt;
where &lt;math&gt;S(x)=-t\mbox{ln}(t)-(1-t)\mbox{ln}(1-t)&lt;/math&gt;.

'''Theorem 1'''(''Dai and Chen''): Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with regular uncertainty distribution &lt;math&gt;\Phi&lt;/math&gt;. Then
::&lt;math&gt;H[\xi]=\int_0^1\Phi^{-1}(\alpha)\mbox{ln}\frac{\alpha}{1-\alpha}d\alpha&lt;/math&gt;.

'''Theorem 2''': Let &lt;math&gt;\xi&lt;/math&gt; and &lt;math&gt;\eta&lt;/math&gt; be independent uncertain variables. Then for any real numbers &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt;, we have
::&lt;math&gt;H[a\xi+b\eta]=|a|E[\xi]+|b|E[\eta]&lt;/math&gt;.

'''Theorem 3''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable whose uncertainty distribution is arbitrary but the expected value &lt;math&gt;e&lt;/math&gt; and variance &lt;math&gt;\sigma^2&lt;/math&gt;. Then
::&lt;math&gt;H[\xi]\leq\frac{\pi\sigma}{\sqrt{3}}&lt;/math&gt;.

==Inequalities==
'''Theorem 1'''(''Liu'', Markov Inequality): Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable. Then for any given numbers &lt;math&gt;t &gt; 0&lt;/math&gt; and &lt;math&gt;p &gt; 0&lt;/math&gt;, we have
::&lt;math&gt;M\{|\xi|\geq t\}\leq \frac{E[|\xi|^p]}{t^p}&lt;/math&gt;.

'''Theorem 2''' (''Liu'', Chebyshev Inequality) Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable whose variance &lt;math&gt;V[\xi]&lt;/math&gt; exists. Then for any given number&lt;math&gt; t &gt; 0&lt;/math&gt;, we have
::&lt;math&gt;M\{|\xi-E[\xi]|\geq t\}\leq \frac{V[\xi]}{t^2}&lt;/math&gt;.

'''Theorem 3''' (''Liu'', Holder’s Inequality) Let &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; be positive numbers with &lt;math&gt;1/p + 1/q = 1&lt;/math&gt;, and let &lt;math&gt;\xi&lt;/math&gt; and &lt;math&gt;\eta&lt;/math&gt; be independent uncertain variables with &lt;math&gt;E[|\xi|^p]&lt; \infty&lt;/math&gt; and &lt;math&gt;E[|\eta|^q] &lt; \infty&lt;/math&gt;. Then we have
::&lt;math&gt;E[|\xi\eta|]\leq \sqrt[p]{E[|\xi|^p]} \sqrt[p]{E[\eta|^p]}&lt;/math&gt;.

'''Theorem 4''':(Liu [127], Minkowski Inequality) Let &lt;math&gt;p&lt;/math&gt; be a real number with &lt;math&gt;p\leq 1&lt;/math&gt;, and let &lt;math&gt;\xi&lt;/math&gt; and &lt;math&gt;\eta&lt;/math&gt; be independent uncertain variables with &lt;math&gt;E[|\xi|^p]&lt; \infty&lt;/math&gt; and &lt;math&gt;E[|\eta|^q] &lt; \infty&lt;/math&gt;. Then we have
::&lt;math&gt;\sqrt[p]{E[|\xi+\eta|^p]}\leq \sqrt[p]{E[|\xi|^p]}+\sqrt[p]{E[\eta|^p]}&lt;/math&gt;.

==Convergence concept==
'''Definition 1''': Suppose that &lt;math&gt;\xi,\xi_1,\xi_2,\ldots&lt;/math&gt; are uncertain variables defined on the uncertainty space &lt;math&gt;(\Gamma,L,M)&lt;/math&gt;. The sequence &lt;math&gt;\{\xi_i\}&lt;/math&gt; is said to be convergent a.s. to &lt;math&gt;\xi&lt;/math&gt; if there exists an event &lt;math&gt;\Lambda&lt;/math&gt; with &lt;math&gt;M\{\Lambda\} = 1&lt;/math&gt; such that
::&lt;math&gt;\mbox{lim}_{i\rightarrow\infty}|\xi_i(\gamma)-\xi(\gamma)|=0&lt;/math&gt;
for every &lt;math&gt;\gamma\in\Lambda&lt;/math&gt;. In that case we write &lt;math&gt;\xi_i\rightarrow \xi&lt;/math&gt;,a.s.

'''Definition 2''': Suppose that &lt;math&gt;\xi,\xi_1,\xi_2,\ldots&lt;/math&gt; are uncertain variables. We say that the sequence &lt;math&gt;\{\xi_i\}&lt;/math&gt; converges in measure to &lt;math&gt;\xi&lt;/math&gt; if
::&lt;math&gt;\mbox{lim}_{i\rightarrow\infty}M\{|\xi_i-\xi|\leq \varepsilon \}=0&lt;/math&gt;
for every &lt;math&gt;\varepsilon&gt;0&lt;/math&gt;.

'''Definition 3''': Suppose that &lt;math&gt;\xi,\xi_1,\xi_2,\ldots&lt;/math&gt; are uncertain variables with finite expected values. We say that the sequence &lt;math&gt;\{\xi_i\}&lt;/math&gt; converges in mean to &lt;math&gt;\xi&lt;/math&gt; if
::&lt;math&gt;\mbox{lim}_{i\rightarrow\infty}E[|\xi_i-\xi|]=0&lt;/math&gt;.

'''Definition 4''': Suppose that &lt;math&gt;\Phi,\phi_1,\Phi_2,\ldots&lt;/math&gt; are uncertainty distributions of uncertain variables &lt;math&gt;\xi,\xi_1,\xi_2,\ldots&lt;/math&gt;, respectively. We say that the sequence &lt;math&gt;\{\xi_i\}&lt;/math&gt; converges in distribution to &lt;math&gt;\xi&lt;/math&gt; if &lt;math&gt;\Phi_i\rightarrow\Phi&lt;/math&gt; at any continuity point of &lt;math&gt;\Phi&lt;/math&gt;.

'''Theorem 1''': Convergence in Mean &lt;math&gt;\Rightarrow&lt;/math&gt; Convergence in Measure &lt;math&gt;\Rightarrow&lt;/math&gt; Convergence in Distribution. 
However, Convergence in Mean &lt;math&gt;\nLeftrightarrow&lt;/math&gt; Convergence Almost Surely &lt;math&gt;\nLeftrightarrow&lt;/math&gt; Convergence in Distribution.

==Conditional uncertainty==
'''Definition 1''': Let &lt;math&gt;(\Gamma,L,M)&lt;/math&gt; be an uncertainty space, and &lt;math&gt;A,B\in L&lt;/math&gt;. Then the conditional uncertain measure of A given B is defined by

::&lt;math&gt;\mathcal{M}\{A\vert B\}=\begin{cases} \displaystyle\frac{\mathcal{M}\{A\cap B\} }{\mathcal{M}\{B\} }, &amp;\displaystyle\text{if }\frac{\mathcal{M}\{A\cap B\} }{\mathcal{M}\{B\} }&lt;0.5 \\ \displaystyle 1 - \frac{\mathcal{M}\{A^c\cap B\} }{\mathcal{M}\{B\} }, &amp;\displaystyle\text{if } \frac{\mathcal{M}\{A^c\cap B\} }{\mathcal{M}\{B\} }&lt;0.5 \\ 0.5, &amp; \text{otherwise} \end{cases}&lt;/math&gt;
::&lt;math&gt;\text{provided that } \mathcal{M}\{B\}&gt;0&lt;/math&gt;

'''Theorem 1''': Let &lt;math&gt;(\Gamma,L,M)&lt;/math&gt; be an uncertainty space, and B an event with &lt;math&gt;M\{B\} &gt; 0&lt;/math&gt;. Then M{·|B} defined by Definition 1 is an uncertain measure, and &lt;math&gt;(\Gamma,L,M\{\mbox{·}|B\})&lt;/math&gt;is an uncertainty space.

'''Definition 2''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable on &lt;math&gt;(\Gamma,L,M)&lt;/math&gt;. A conditional uncertain variable of &lt;math&gt;\xi&lt;/math&gt; given B is a measurable function &lt;math&gt;\xi|_B&lt;/math&gt; from the conditional uncertainty space &lt;math&gt;(\Gamma,L,M\{\mbox{·}|_B\})&lt;/math&gt; to the set of real numbers such that
::&lt;math&gt;\xi|_B(\gamma)=\xi(\gamma),\forall \gamma \in \Gamma&lt;/math&gt;.

'''Definition 3''': The conditional uncertainty distribution &lt;math&gt;\Phi\rightarrow[0, 1]&lt;/math&gt; of an uncertain variable &lt;math&gt;\xi&lt;/math&gt; given B is defined by
::&lt;math&gt;\Phi(x|B)=M\{\xi\leq x|B\}&lt;/math&gt;
provided that &lt;math&gt;M\{B\}&gt;0&lt;/math&gt;.

'''Theorem 2''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with regular uncertainty distribution &lt;math&gt;\Phi(x)&lt;/math&gt;, and &lt;math&gt;t&lt;/math&gt; a real number with &lt;math&gt;\Phi(t) &lt; 1&lt;/math&gt;. Then the conditional uncertainty distribution of &lt;math&gt;\xi&lt;/math&gt; given &lt;math&gt;\xi&gt; t&lt;/math&gt; is
::&lt;math&gt;\Phi(x\vert(t,+\infty))=\begin{cases} 0, &amp; \text{if }\Phi(x)\le\Phi(t)\\ \displaystyle\frac{\Phi(x)}{1-\Phi(t)}\and 0.5, &amp; \text{if }\Phi(t)&lt;\Phi(x)\le(1+\Phi(t))/2 \\ \displaystyle\frac{\Phi(x)-\Phi(t)}{1-\Phi(t)}, &amp; \text{if }(1+\Phi(t))/2\le\Phi(x) \end{cases}&lt;/math&gt;

'''Theorem 3''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable with regular uncertainty distribution &lt;math&gt;\Phi(x)&lt;/math&gt;, and &lt;math&gt;t&lt;/math&gt; a real number with &lt;math&gt;\Phi(t)&gt;0&lt;/math&gt;. Then the conditional uncertainty distribution of &lt;math&gt;\xi&lt;/math&gt; given &lt;math&gt;\xi\leq t&lt;/math&gt; is
::&lt;math&gt;\Phi(x\vert(-\infty,t])=\begin{cases} \displaystyle\frac{\Phi(x)}{\Phi(t)}, &amp; \text{if }\Phi(x)\le\Phi(t)/2 \\ \displaystyle\frac{\Phi(x)+\Phi(t)-1}{\Phi(t)}\or 0.5, &amp; \text{if }\Phi(t)/2\le\Phi(x)&lt;\Phi(t) \\ 1, &amp; \text{if }\Phi(t)\le\Phi(x) \end{cases}&lt;/math&gt;

'''Definition 4''': Let &lt;math&gt;\xi&lt;/math&gt; be an uncertain variable. Then the conditional expected value of &lt;math&gt;\xi&lt;/math&gt; given B is defined by
::&lt;math&gt;E[\xi|B]=\int_0^{+\infty}M\{\xi\geq r|B\}dr-\int_{-\infty}^0M\{\xi\leq r|B\}dr&lt;/math&gt;
provided that at least one of the two integrals is finite.

==References==
{{commons category|Uncertainty Theory}}
{{Reflist}}

==Sources==
* Xin Gao, Some Properties of Continuous Uncertain Measure, ''[[International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems]]'', Vol.17, No.3, 419-426, 2009.
* Cuilian You, Some Convergence Theorems of Uncertain Sequences, ''Mathematical and Computer Modelling'', Vol.49, Nos.3-4, 482-487, 2009.
* Yuhan Liu, How to Generate Uncertain Measures, ''Proceedings of Tenth National Youth Conference on Information and Management Sciences'', August 3–7, 2008, Luoyang, pp.&amp;nbsp;23–26.
* Baoding Liu, Some Research Problems in Uncertainty Theory, ''Journal of Uncertain Systems'', Vol.3, No.1, 3-10, 2009.
* Yang Zuo, Xiaoyu Ji, Theoretical Foundation of Uncertain Dominance, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;827–832.
* Yuhan Liu and Minghu Ha, Expected Value of Function of Uncertain Variables, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;779–781.
* Zhongfeng Qin, On Lognormal Uncertain Variable, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;753–755.
* Jin Peng, Value at Risk and Tail Value at Risk in Uncertain Environment, ''Proceedings of the Eighth International Conference on Information and Management Sciences, Kunming, China'', July 20–28, 2009, pp.&amp;nbsp;787–793.
* Yi Peng, U-Curve and U-Coefficient in Uncertain Environment, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;815–820.
* Wei Liu, Jiuping Xu, Some Properties on Expected Value Operator for Uncertain Variables, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;808–811.
* Xiaohu Yang, Moments and Tails Inequality within the Framework of Uncertainty Theory, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;812–814.
* Yuan Gao, Analysis of k-out-of-n System with Uncertain Lifetimes, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;794–797.
* Xin Gao, Shuzhen Sun, Variance Formula for Trapezoidal Uncertain Variables, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;853–855.
* Zixiong Peng, A Sufficient and Necessary Condition of Product Uncertain Null Set, ''Proceedings of the Eighth International Conference on Information and Management Sciences'', Kunming, China, July 20–28, 2009, pp.&amp;nbsp;798–801.

{{DEFAULTSORT:Uncertainty Theory}}
[[Category:Probability theory]]
[[Category:Fuzzy logic]]</text>
      <sha1>0h8ys8cy5piomdvi9ts5zuajvmuo291</sha1>
    </revision>
  </page>
  <page>
    <title>Vanitas</title>
    <ns>0</ns>
    <id>285031</id>
    <revision>
      <id>871646209</id>
      <parentid>861726987</parentid>
      <timestamp>2018-12-02T14:48:01Z</timestamp>
      <contributor>
        <username>Archaeodontosaurus</username>
        <id>9237608</id>
      </contributor>
      <comment>/* In modern times */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8154">{{About|the style of artwork}}
{{refimprove|date=December 2011}}
[[File:Antonio de Pereda - Allegory of Vanity - Google Art Project.jpg|thumb|333px|''Vanitas'' by [[Antonio de Pereda y Salgado]] ]]
 
A '''vanitas''' is a symbolic work of art showing the transience of life, the futility of pleasure, and the certainty of death, often contrasting symbols of wealth and symbols of ephemerality and death. Best-known are ''vanitas'' [[still life]]s, a common genre in [[Netherlandish art]] of the 16th and 17th centuries; they have also been created at other times and in other [[medium (art)|media]] and [[Genre#Visual arts|genres]].&lt;ref&gt;Search for 'vanitas' at Harvard Art Museums: [https://www.harvardartmuseums.org/?q=vanitas]&lt;/ref&gt;

==Etymology==

The [[Latin]] noun [[wikt:vanitas#Latin|''vanitas'']] (from the Latin adjective ''vanus'' 'empty') means 'emptiness', 'futility', or 'worthlessness', the traditional Christian view being that earthly goods and pursuits are transient and worthless.&lt;ref&gt;Charlton T. Lewis, Charles Short, ''A Latin Dictionary'', [http://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.04.0059:entry=vanitas ''s.v.'']&lt;/ref&gt; It alludes to [[Ecclesiastes]] {{bibleref2-nb|Eccl.|1:2; 12:8|VULGATE}}, where ''vanitas'' translates the Hebrew word ''hevel'', which also includes the concept of transitoriness.&lt;ref&gt;Daniel C. Fredericks, ''Coping with Transience: Ecclesiastes on Brevity in Life'', p. 15 and ''passim''&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Oxford Treasury of Sayings and Quotations |url=https://books.google.com/books?id=IYOcAQAAQBAJ&amp;printsec=frontcover |first=Susan |last=Ratcliffe |date=October 13, 2011 |publisher=[[Oxford University Press|OUP]] |location=[[Oxford]] |id={{ISBN|0-19960912-8}} |isbn=978-0-199-60912-3 |page=[https://books.google.com/books?id=IYOcAQAAQBAJ&amp;pg=PA127&amp;dq=%226+Vanitas+vanitatum%22+futility 127]}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=From Bonbon to Cha-cha. Oxford Dictionary of Foreign Words and Phrases|url=https://books.google.com/books?id=Nvu17oLIQNgC&amp;printsec=frontcover |first=Andrew |last=Delahunty |date=October 23, 2008 |publisher=OUP |location=Oxford |id={{ISBN|0-19954369-0}} |isbn=978-0-199-54369-4 |page=[https://books.google.com/books?id=Nvu17oLIQNgC&amp;pg=PA360&amp;dq=%22Vanitas+vanitatum%22+futility 360]}}&lt;/ref&gt;

==Themes==
[[File:Pier Francesco Cittadini Vanitas-Stillleben.jpg|thumb|245px|[[Pier Francesco Cittadini]] from 17th century school]]

Vanitas themes were common in medieval funerary art, with most surviving examples in sculpture. By the 15th century, these could be extremely morbid and explicit, reflecting an increased obsession with death and decay also seen in the ''[[Ars moriendi]],'' the ''[[Danse Macabre]]'', and the overlapping motif of the ''[[Memento mori]].''  From the Renaissance such motifs gradually became more indirect and, as the still-life genre became popular, found a home there.  Paintings executed in the vanitas style were meant to remind viewers of the transience of life, the futility of pleasure, and the certainty of death. They also provided a moral justification for painting attractive objects
.

==Motifs==
[[File:Harmen Steenwijck - Vanitas.JPG|245px|thumb|left|''Vanitas'' by [[Harmen Steenwijck]]]]

Common vanitas symbols include skulls, which are a reminder of the certainty of death; rotten fruit (decay); bubbles (the brevity of life and suddenness of death); smoke, watches, and hourglasses (the brevity of life); and musical instruments (brevity and the ephemeral nature of life). Fruit, flowers and butterflies can be interpreted in the same way, and a peeled lemon was, like life, attractive to look at but bitter to taste. Art historians debate how much, and how seriously, the vanitas theme is implied in still-life paintings without explicit imagery such as a skull. As in much moralistic genre painting, the enjoyment evoked by the sensuous depiction of the subject is in a certain conflict with the moralistic message.&lt;ref&gt;For more on this topic, see [https://books.google.it/books?id=QkeBswEACAAJ&amp;dq=the+living+dead+ecclesiastes+through+art&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiYx7rVrrDdAhXIKewKHZ9oB1MQ6AEIKTAA ''The Living Dead: Ecclesiastes through Art''], exh. cat. edited by Corinna Ricasoli, Paderborn: Ferdinand Schöningh 2018, and the bibliography therein.&lt;/ref&gt;

''Composition of flowers'' is a  less obvious style of Vanitas by [[Abraham Mignon]] in the [[National Museum, Warsaw]]. Barely visible amid vivid and perilous nature (snakes, poisonous mushrooms), a bird skeleton is a symbol of vanity and shortness of life.
[[File:Lille Hemessen vanitas.JPG|thumb|''Vanitas'' by [[Jan Sanders van Hemessen]]]]

==Outside visual art==
*The first movement in composer [[Robert Schumann]]'s ''5 Pieces in a Folk Style, for Cello and Piano, Op. 102'' is entitled ''Vanitas vanitatum: Mit Humor.''  
*''Vanitas vanitatum'' is the title of an [[oratorio]] written by an Italian Baroque composer [[Giacomo Carissimi]] (1604/1605 -1674).
*Composer [[Richard Barrett (composer)|Richard Barrett]]'s ''[[Vanity]]'', for orchestra, is greatly inspired by this movement.
*[[Vanitas (Anaal Nathrakh album)|Vanitas]] is the seventh album by British [[Extreme Metal]] band [[Anaal Nathrakh]].

==In modern times==
*[[C. Allan Gilbert]], ''All Is Vanity'', drawing, 1892.
*[[Jana Sterbak]], ''[[Vanitas: Flesh Dress for an Albino Anorectic]]'', artwork, 1987.
*[[Alexander de Cadenet]], ''Skull Portraits,'' various subjects, 1996 – present.
*[[:fr:Philippe Pasqua|Philippe Pasqua]], series of skulls, sculpture, 1990s – present.
*[[Damien Hirst]], ''[[For the Love of God]],'' sculpture (A diamond skull), 2007.
*[[Anne de Carbuccia]], ''[[One Planet One Future]],'' various subjects, 2013 – present.

{{Clear}}
&lt;gallery widths="200px" heights="200px" caption="Vanitas"&gt;
File:1628 Claesz Vanitas-Stillleben mit Selbstbildnis anagoria.JPG|''Vanitas Still Life with Self-Portrait'', [[Pieter Claesz]], 1628
File:Vanitas painting, selfportrait most probably Clara Peeters.jpg|Vanitas painting, self-portrait, most probably by [[Clara Peeters]]
File:A Vanitas) by Edward Collier.jpg|''Vanitas' by [[Edwaert Collier|Edward Collier]]
File:Vanitas-Still Life, Oosterwijck.jpg|''Vanitas-Still Life'', [[Maria van Oosterwijck]] (1630–1693)

File:Abraham Mignon - The Nature as a Symbol of Vanitas - WGA15668.jpg|''Vanitas,'' by [[Abraham Mignon]]
Beaux-Arts de Pau - Vanité au buste - Johann de Cordua 1665.jpg|''Vanitas with bust,'' [[Joannes de Cordua]] (1630–1702)
File:Allegory of Charles I of England and Henrietta of France in a Vanitas Still Life.jpg|''Allegory of Charles I of England and Henrietta of France in a Vanitas Still Life'' by [[Carstian Luyckx]],
File:Adriaen van Utrecht- Vanitas - Still Life with Bouquet and Skull.JPG|Adriaen van Utrecht - ''Vanitas,'' composition with flowers and skull

&lt;/gallery&gt;

== See also ==
*[[Emptiness]]
*''[[Memento mori]]''
*[[Mortality salience]]
*''[[Sic transit gloria mundi]]''
*''[[Ubi sunt]]''

== References==
{{reflist}}

== External links ==
{{Commons category|Vanitas}}
{{wiktionary}}
*[http://www.vmfa.museum/Visit/Library/Research/Exhibition_History/Exhibitions_-_2000s.aspx Vanitas in contemporary art]{{deadurl|date=September 2018}} An exhibition at the [[Virginia Museum of Fine Arts]]
*[https://web.archive.org/web/20110610235349/http://www.nationalgallery.org.uk/server.php?search_word=vanitas&amp;change=SearchResults&amp;changeNav=1 Vanitas] in the [[London National Gallery]]
*[http://www.museemaillol.com/ Vanités] An exhibition at [[Musée Maillol]], Paris
*[http://www.britannica.com/EBchecked/topic/623056/vanitas vanitas (art)] - ''[[Encyclopædia Britannica]]''
*[http://www.melaniesherman.com/dt_gallery/momento-mori/ Vanitas concept expressed in ceramic compositions]
*"[https://www.google.com/culturalinstitute/beta/usergallery/oAKis1oFVGZ1KA An Exploration of Vanitas: The 17th Century and the Present]", online exhibit at Google Arts &amp; Culture
{{Death and mortality in art}}

[[Category:Christian art about death]]
[[Category:Art genres]]
[[Category:Iconography]]
[[Category:Art of the Dutch Golden Age]]
[[Category:Memento mori]]
[[Category:Netherlandish art]]</text>
      <sha1>ax3ow3obfpqmr71bde8mnw4r10kkhhv</sha1>
    </revision>
  </page>
  <page>
    <title>Vietnam National University of Forestry</title>
    <ns>0</ns>
    <id>51055433</id>
    <revision>
      <id>801668870</id>
      <parentid>801668705</parentid>
      <timestamp>2017-09-21T02:53:31Z</timestamp>
      <contributor>
        <username>Biencuong502</username>
        <id>28746294</id>
      </contributor>
      <minor/>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3630">{{unreferenced|date=July 2016}}

'''Vietnam National University of Forestry''' (VNUF) was established according to the Decision No.127/CP dated on August 19, 1964 by the [[Prime Minister of Vietnam]].

Currently, there are over 16.000 students, including undergraduate and graduate, following 22 disciplines of undergraduate level, 6 majors of master level, and 4 majors of doctorate level.
The main campus of VNUF is located in Xuan Mai Town, [[Chương_Mỹ_District|Chuong My District]], [[Hanoi_Capital_Region|Hanoi Capital]]. The second campus (established in 01/2008) is located in [[Trảng_Bom_District|Trang Bom Town]], [[Đồng_Nai_Province|Dong Nai Province]].

==History==
Historical background:
Vietnam National University of Forestry (VNUF) was established according to the Decision No.127/CP dated on August 19, 1964 by the Prime Minister of Vietnam, and was separated from the Forestry Department - [[Vietnam_National_University_of_Agriculture|Hanoi University of Agriculture]].
From 1964 to 1984: The first campus of VNUF was located in the evacuated area of [[Đông_Triều_District|Dong Trieu] district], [[Quảng_Ninh_Province|Quang Ninh province]]. The task of VNUF was to train and provide human resources of undergraduate with three academic faculties and four majors of forestry.
From 1984 until now: The main campus was located at Xuan Mai town, Chuong My district, Hanoi, becoming a university with diversified training and education activities to meet social needs and to fulfill the duty of national scientific technology
The second campus (established in 01/2008) is located in Trang Bong Town, Dong Nai province, [[Vietnam]] that was upgraded from the Forestry College 2 - [[Ministry_of_Agriculture_and_Rural_Development_(Vietnam)|Ministry of Agriculture and Rural Development]] to meet the demand for human resources in forestry for the southern provinces of the country.
Today VNUF activities expanded to five Academic Faculties with hundreds departments, 36 major subjects.
Over the years, more than 1,000 masters, 150 doctors, over 10,000 undergraduate students, and 500 trainees with intermediate and primary level have graduated from VNUF. 
Likewise, the VNUF has helped establish more than 30 universities, training and research institutions in different countries, as well as international organizations.

==Facilities==

VNUF has 160 hectares in the main campus and 20 hectares in the second branch for serving its training and science research purposes.
6 experimental centers with 58 labs for testing and practice,
10,800 m2 of classrooms,
A library of 3,000 m2 with 150,000 books/textbooks and other electronic sources for reference.
Nearly 100 ha of experimental forests for training and science research.
16 high buildings which provide accommodation with self-contained rooms for nearly 8,000 students.
The sport areas and recreation centers including gymnasiums, outdoor swimming pool, sport ground, house of culture, etc., have the area of 20,000 m2.

==Organization Structure==

The Vietnam National University of Forestry has 3 organizational levels: a) Board of Leaders, b) Faculties &amp; Administrative Divisions, and c) Organizations.

07 Faculties/Colleges
09 Administrative Divisions.
05 Research &amp; Production Units.
01 Company of Consulting, Investment &amp; Forestry Development (CIFOD).

==References==
{{Reflist}}

==External links==
* {{Official website|http://en.vnuf.edu.vn/home}}

[[Category:Universities and colleges in Vietnam by type]]
[[Category:Forestry education]]
[[Category:1964 establishments in Vietnam]]
[[Category:Educational institutions established in 1964]]</text>
      <sha1>878gqhepwx4xnq88jh0i645f8tm9nid</sha1>
    </revision>
  </page>
  <page>
    <title>Zentrum für Europäische Wirtschaftsforschung</title>
    <ns>0</ns>
    <id>25033120</id>
    <revision>
      <id>835115318</id>
      <parentid>750065530</parentid>
      <timestamp>2018-04-06T17:08:28Z</timestamp>
      <contributor>
        <ip>193.196.11.188</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4883">{{One source|section|date=March 2012}}[[image:ZEW Mannheim.jpg|thumb|ZEW headquarters in Mannheim]]
The '''Centre for European Economic Research (ZEW)''' in [[Mannheim]] is an economic research institute and a member of the [[Gottfried Wilhelm Leibniz Scientific Community]]. Under the leadership of Prof. Achim Wambach, PhD, president of the Institute, and Thomas Kohl, director of business and administration, ZEW employs a staff of about 186.&lt;ref&gt;{{Cite web|url=http://www.zew.de/en/das-zew/ueber-das-zew/|title=About the Centre for European Economic Research|website=www.zew.de|access-date=2016-04-29}}&lt;/ref&gt; ZEW is one of Europe’s leading economic research institutes.

ZEW is subdivided into the six research fields:
*Labour Markets, Human Resources and Social Policy
*Economics of Innovation and Industrial Dynamics
*Digital Economy
*International Finance and Financial Management
*Environmental and Resource Economics, Environmental Management
*Corporate Taxation and Public Finance;

and three research groups:
*International Distribution and Redistribution
*Market Design&lt;ref&gt;{{Cite web|url=http://www.zew.de/PM4464-1|title=Article ZEW - New ZEW Research Group "Market Design" Takes up Work|website=zew.de|access-date=2016-06-02}}&lt;/ref&gt;
*Competition and Regulation &lt;ref&gt;{{Cite web|url=http://www.zew.de/en/das-zew/forschungseinheiten/|title=ZEW Research Departments|website=www.zew.de|access-date=2016-04-29}}&lt;/ref&gt;

ZEW’s guiding mission is to study the optimal performance of markets and institutions in [[Europe]]. ZEW’s expertise lies particularly in the area of applied micro[[econometrics]] and in [[computable general equilibrium]] models. Research findings are presented at conferences and published in scientific journals. ZEW also contributes to current political and economic discussions by issuing a variety of its own publications. Furthermore, it is offering seminars.&lt;ref name=ZEW01/&gt;

Special attention is paid to the monthly published ZEW Indicator of Economic Sentiment. It is a leading indicator for the German economy. The survey also asks for the expectations for the [[Eurozone]], Japan, Great Britain, Italy, France and the US.

ZEW is funded in part by the Federal State of [[Baden-Württemberg]]. Since 2005, the Institute has also received basic funding from a partnership between the German federal and state governments. More than 40 per cent of the Institute’s financial resources are obtained from research contracts for third parties, including the [[European Commission]], ministries, and institutions of the federal and state governments, as well as companies, associations, and local authorities. As a member of the Leibniz Scientific Community, also known as the Leibniz Association, ZEW gained recognition from the [http://www.leibniz-gemeinschaft.de/?nid=sen&amp;nidap=&amp;print=0 association's Senate] on the basis of a strong 2009 evaluation.&lt;ref name=ZEW01&gt;[http://www.zew.de/en/daszew/daszew.php3?mi=ZEW "ZEW Profile"] {{webarchive |url=https://web.archive.org/web/20120327174415/http://www.zew.de/en/daszew/daszew.php3?mi=ZEW |date=March 27, 2012 }}, Centre webpage (English language). Retrieved 2012-03-13.&lt;/ref&gt;

==Attention to indicators==
The March, 2012, edition of the Indicator of Economic Sentiment, which compiled survey results from 285 analysts,&lt;ref name=ZEW02&gt;[http://download.zew.de/e_03_2012_table.pdf "Financial Market Survey: Results March 2012"] and [http://www.zew.de/en/presse/1949 "ZEW Indicator of Economic Sentiment - Positive Outlook Confirmed"], press release March 13, 2012; Centre webpages. Inflation not mentioned in press release. Retrieved 2012-03-13.&lt;/ref&gt; found a notable increase in German sentiment.&lt;ref name=MW01&gt;Watts, William L., [http://www.marketwatch.com/story/german-march-zew-index-jumps-to-223-2012-03-13 "German March ZEW index jumps to 22.3"], ''[[MarketWatch]]'', March 13, 2012. Retrieved 2012-03-13.&lt;/ref&gt; Another of the several measures in the survey—of the "Current economic situation"—showed little change in the month,&lt;ref name=MW01/&gt; while inflation expectations rose sharply.&lt;ref name=ZEW02/&gt; The indicator showed an "unexpected rise in April [2012] for a fifth straight monthly gain. The indicator rose to 23.4 from 22.3 in March, against expectations for a decline to 20.0", a result which upon release was cited relative to gains in European stock markets in mid-month.&lt;ref&gt;Kollmeyer, Barbara, [http://www.marketwatch.com/story/europe-stocks-extend-gains-after-german-zew-2012-04-17?dist=beforebell "Europe stocks extend gains after German ZEW"], ''[[MarketWatch]]'', April 17, 2012. Retrieved 2012-04-17.&lt;/ref&gt;

==References==
{{reflist}}

{{Authority control}}

{{coord|49.4819|N|8.4658|E|source:wikidata|display=title}}

{{DEFAULTSORT:Zentrum fur Europaische Wirtschaftsforschung}}
[[Category:Economic research institutes]]
[[Category:Research institutes in Germany]]</text>
      <sha1>k1kkggwu6q4svwgh8a1yayajn395eyb</sha1>
    </revision>
  </page>
</mediawiki>
