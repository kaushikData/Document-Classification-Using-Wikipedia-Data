<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Aleksandr Lyapunov</title>
    <ns>0</ns>
    <id>65425</id>
    <revision>
      <id>862716951</id>
      <parentid>860839454</parentid>
      <timestamp>2018-10-06T06:30:15Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Lyapunov family per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 23]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13863">{{Infobox scientist
| name = Aleksandr Mikhailovich Lyapunov
| image = Alexander Ljapunow jung.jpg
| caption =
| birth_date = {{birth date|1857|06|06|mf=y}}
| birth_place = [[Yaroslavl]], [[Russian Empire]]
| death_date = {{death date and age|1918|11|03|1857|06|06|mf=y}}
| death_place = [[Odessa]], [[Ukrainian People's Republic]]
| nationality = Russian
| fields = [[Applied mathematics]]
| workplaces = [[Saint Petersburg State University]]&lt;br&gt;[[Russian Academy of Sciences]]&lt;br&gt;[[Kharkov University]]
| alma_mater = [[Saint Petersburg State University]]
| doctoral_advisor = [[Pafnuty Chebyshev]]
| doctoral_students = [[Nikola Saltikov]]&lt;br&gt;[[Vladimir Steklov (mathematician)|Vladimir Steklov]]
| known_for = [[Lyapunov function]]&lt;br&gt;[[Lyapunov stability]]&lt;br&gt;[[Lyapunov exponent]]&lt;br&gt;[[Central limit theorem#Lyapunov CLT|Lyapunov Central Limit Theorem]]&lt;br&gt;[[Lyapunov vector]]
| awards =
}}
'''Aleksandr Mikhailovich Lyapunov''' ({{lang-ru|Алекса́ндр Миха́йлович Ляпуно́в}}, {{IPA-ru|ɐlʲɪkˈsandr mʲɪˈxajɫəvʲɪtɕ lʲɪpʊˈnof|pron}}; {{OldStyleDate|June 6|1857|May 25}} – November 3, 1918) was a [[Russians|Russian]] [[mathematician]], [[mechanician]] and [[physicist]]. His surname is sometimes [[Romanization of Russian|romanized]] as '''Ljapunov''', '''Liapunov''', '''Liapounoff''' or '''Ljapunow'''. He was the son of astronomer [[Mikhail Lyapunov]] and the brother of pianist and composer [[Sergei Lyapunov]].

Lyapunov is known for his development of the [[stability theory]] of a [[dynamical system]], as well as for his many contributions to [[mathematical physics]] and [[probability theory]].

== Biography ==

=== Early life ===
Lyapunov was born in [[Yaroslavl]], [[Russian Empire]]. His father [[Mikhail Lyapunov|Mikhail Vasilyevich Lyapunov]] (1820–1868) was an [[astronomer]] employed by the [[Demidov Lyceum]]. His brother, [[Sergei Lyapunov]], was a gifted composer and pianist. In 1863, M. V. Lyapunov retired from his scientific career and relocated his family to his wife's estate at Bolobonov, in the Simbirsk province (now [[Ulyanovsk Oblast]]). After the death of his father in 1868, Aleksandr Lyapunov was educated by his uncle R. M. Sechenov, brother of the [[physiologist]] [[Ivan Mikhailovich Sechenov]]. At his uncle's family, Lyapunov studied with his distant cousin Natalia Rafailovna, who became his wife in 1886. In 1870, his mother moved with her sons to [[Nizhny Novgorod]], where he started the third class of the [[gymnasium (school)|gymnasium]]. He graduated from the gymnasium with distinction in 1876.{{sfn|Smirnov|1992}}

=== Education ===

In 1876, Lyapunov entered the Physico-Mathematical department at the [[Saint Petersburg State University|University of Saint Petersburg]], but after one month he transferred to the Mathematics department of the university.

Among the Saint Petersburg professors of mathematics were [[Pafnuty Chebyshev|Chebyshev]] and his students [[Aleksandr Korkin|Aleksandr Nikolaevich Korkin]] and [[Yegor Ivanovich Zolotarev]]. Lyapunov wrote his first independent scientific works under the guidance of the professor of mechanics, D. K. Bobylev. In 1880 Lyapunov received a gold medal for a work on [[hydrostatics]]. This was the basis for his first published scientific works ''On the equilibrium of a heavy body in a heavy fluid contained in a vessel of a fixed form'' and ''On the potential of hydrostatic pressure''. Lyapunov completed his university course in 1880, two years after [[Andrey Markov]] who had also graduated at Saint Petersburg University. Lyapunov would maintain a scientific contact with Markov during all his life.

=== Teaching and research ===
A major theme in Lyapunov's research was the stability of a rotating fluid mass with possible astronomical application. This subject was proposed to Lyapunov by [[Pafnuty Chebyshev|Chebyshev]] as a topic for his masters thesis which he submitted in 1884 with the title ''On the stability of ellipsoidal forms of rotating fluids''. 
 
In 1885, Lyapunov became [[privatdozent]] and was proposed to accept the chair of mechanics at [[Kharkov University]], where he went the same year. About the initial stay at [[Kharkov]], Smirnov writes in his biography of Lyapunov:

{{quote|text=Here at first, the research activity of Lyapunov was cut short. It was necessary to work out courses and put together notes for students, which took up much time.{{sfn|Smirnov|1992}}}}

His student and collaborator, [[Vladimir Steklov (mathematician)|Vladimir Steklov]], recalled his first lecture in the following way: "A handsome young man, almost of the age of the other students, came before the audience, where there was also the old Dean, professor Levakovsky, who was respected by all students. After the Dean had left, the young man with a trembled voice started to lecture a course on the dynamics of material points, instead of a course on [[dynamical system]]s. This subject was already known to the students from the lectures of professor Delarue. But what Lyapunov taught us was new to me and I had never seen this material in any textbook. All antipathy to the course was immediately blown to dust. From that day students would show Lyapunov a special respect."{{sfn|Smirnov|1992}}

The main contribution was published in the celebrated  monograph  'A.M. Lyapunov, The general problem of the stability of motion. 1892. Kharkov Mathematical Society, Kharkov, 251p. (in Russian)'. 
This led on to his 1892 doctoral thesis ''The general problem of the stability of motion''.{{sfn|Lyapunov|1992}} The thesis was defended in Moscow University on September 12, 1892, with [[Nikolay Yegorovich Zhukovsky|Nikolai Zhukovsky]] and V. B. Mlodzeevski as opponents. In 1908, the Kharkov edition was translated to French.
Republished by the University of Toulouse: 'Probleme General de la Stabilite du Mouvement, Par M.A. Liapounoff. Traduit du russe par M.Edouard Davaux'. 

=== Later years ===
Lyapunov returned to Saint Petersburg in 1902, after being elected acting member of the Academy of Science as well as ordinary professor in the Faculty of Applied Mathematics of the university. The position had been left vacant by the death of his former teacher, [[Pafnuty Chebyshev|Chebyshev]]. Not having any teaching obligations, this allowed Lyapunov to focus on his studies and in particular he was able to bring to a conclusion the work on the problem of Chebyshev with which he started his scientific career.

In 1908, he took part to the Fourth [[International Congress of Mathematicians|International Mathematical Congress]] in Rome. He also participated in the publication of Euler's selected works: he was an editor of the volumes 18 and 19.{{sfn|Smirnov|1992}}

=== Death ===

By the end of June 1917, Lyapunov traveled with his wife to his brother's place in [[Odessa]]. Lyapunov's wife was suffering from tuberculosis so they moved following her doctor's orders. She died on October 31, 1918. The same day, Lyapunov shot himself in the head, and three days later he died.{{sfn|Shcherbakov|1992}} By that time, he was going blind from [[cataracts]].{{sfn|Smirnov|1992}}

== Work ==
[[Image:Aleksander Lyapunov in 1876.png|thumb|right|Aleksandr Lyapunov in 1876]]
Lyapunov contributed to several fields, including [[differential equation]]s, [[potential theory]], [[dynamical system]]s and [[probability theory]]. His main preoccupations were the stability of equilibria and the motion of mechanical systems, and the study of particles under the influence of gravity. His work in the field of [[mathematical physics]] regarded the boundary value problem of the [[Laplace's equation|equation of Laplace]]. In the theory of potential, his work from 1897 ''On some questions connected with [[Peter Gustav Lejeune Dirichlet|Dirichlet's]] problem'' clarified several important aspects of the theory. His work in this field is in close connection with the work of Steklov. Lyapunov developed many important approximation methods. His methods, which he developed in 1899, make it possible to define the stability of sets of ordinary differential equations. He created the modern theory of the stability of a dynamic system. In the theory of probability, he generalised the works of Chebyshev and Markov, and proved the [[Central Limit Theorem]] under more general conditions than his predecessors. The method of characteristic functions he used for the proof later found widespread use in probability theory.{{sfn|Smirnov|1992}}

Like many mathematicians, Lyapunov preferred to work alone and communicated mainly with few colleagues and close relatives. He usually worked late, four to five hours at night, sometimes the whole night. Once or twice a year he visited the theatre, or went to some concert. He had many students. He was an honorary member of many universities, an honorary member of the Academy in Rome and a corresponding member of the [[Académie des Sciences|Academy of Sciences]] in [[Paris, France|Paris]].{{sfn|Smirnov|1992}}

Lyapunov's impact was significant, and a number of different mathematical concepts therefore bear his name: 
* [[Lyapunov equation]]
* [[Lyapunov exponent]]
* [[Lyapunov function]]
* [[Lyapunov fractal]]
* [[Lyapunov stability]]
* [[Lyapunov's central limit theorem]]
* [[Lyapunov vector]]

== Selected publications ==
* 1884, ''On the stability of ellipsoidal figures of equilibrium of a rotating fluid'' (in Russian) Published in ''Bulletin Astronomique'' 1885
* 1892, ''A.M. Lyapunov, The general problem of the stability of motion. 1892. Kharkov Mathematical Society, Kharkov, 251p.'' (in Russian)
* 1897, ''Sur certaines questions qui se rattachent au problème de Dirichlet''
* 1901, ''Nouvelle forme du théorème sur la limite de probabilité''
* 1901, ''Sur un théorème du calcul des probabilités''
* 1902, ''Sur une série dans la théorie des équations différentielles linéaires du second ordre à coefficients périodiques''
* 1903, ''Recherches dans la théorie de la figure des corps célestes''
* 1904, ''Sur l'équation de Clairaut et les équations plus générales de la théorie de la figure des planètes''

== See also ==
{{div col|colwidth=20em}}
* [[Lyapunov equation]]
* [[Lyapunov exponent]]
* [[Lyapunov fractal]]
* [[Lyapunov function]]
* [[Lyapunov stability]]
* [[Lyapunov time]]
* [[Lyapunov's central limit theorem]]
* [[Central limit theorem#Lyapunov condition|Lyapunov's condition]]
* [[Lyapunov–Malkin theorem]]
* [[Lyapunov–Schmidt reduction]]
{{div col end}}

== Notes ==
{{reflist}}

== References ==
{{refbegin}}
*{{Citation
|last=Lyapunov
|first=A. M.
|year=1992
|title=The general problem of the stability of motion
|location=London
|publisher=Taylor &amp; Francis
|isbn=978-0-7484-0062-1
|ref=harv
|translator=A. T. Fuller
}} Reviewed in detail by M. C. Smith: Automatica 1995 vol.3(2), pp.&amp;nbsp;353–356 
*{{Citation
|last=Parks
|first=Patrick C.
|year=1992
|title=A. M. Lyapunov's stability theory – 100 years on
|journal=IMA Journal of Mathematical Control &amp; Information
|volume=9
|pages=275–303
|doi=10.1093/imamci/9.4.275
|url=http://imamci.oxfordjournals.org/cgi/reprint/9/4/275.pdf
|ref=harv
|issue=4
}}
*{{Citation
|last=Shcherbakov
|first=Pavel S.
|year=1992
|title=Alexander Mikhailovitch Lyapunov: On the centenary of his doctoral dissertation on stability of motion
|journal=Automatica
|volume=28
|issue=5
|pages=865–871
|doi=10.1016/0005-1098(92)90140-B
|ref=harv
}}
*{{Citation
|last=Smirnov
|first=Vladimir Ivanovich
|year=1992
|title=Biography of A. M. Lyapunov
|journal=International Journal of Control
|volume=55
|issue=3
|pages=775–784
|doi=10.1080/00207179208934258
|url=http://www.ingelec.uns.edu.ar/asnl/Materiales/Cap05Extras/LyapBio/lyapbio.pdf
|ref=harv
}}
*{{Citation
|last=Barrett
|first=J. F.
|year=1992
|title=Bibliography of A. M. Lyapunov's work
|journal=International Journal of Control
|volume=55
|issue=3
|pages=785–790
|doi=10.1080/00207179208934259
|ref=harv
}}
*{{Citation
|last=Sinai
|first=Yakov
|year=2004
|title=Russian Mathematicians in the 20th Century
|publisher=World Scientific
|isbn=978-981-238-385-3
|ref=harv
}}
{{refend}}

== External links ==
{{commons category|Aleksandr Lyapunov}}
* {{MacTutor Biography|id=Lyapunov}}
* {{MathGenealogy |id=31015}}
* [http://www.mathsoc.spb.ru/pantheon/lyapunov/b-e.html Ляпунов Александр Михайлович&lt;!-- bot-generated title --&gt;] at www. mathsoc.spb. ru (in Russian)
* [http://www.spbu.ru/History/275/Chronicle/spbu/Persons/L_yapunov.html Ляпунов Александр Михайлович (1857-1918)&lt;!-- bot-generated title --&gt;] at www.spbu. ru (in Russian)
* [https://web.archive.org/web/20020909205413/http://www-mechmath.univer.kharkov.ua/theormech/lapunov.html Ляпунов Александр Михайлович&lt;!-- bot-generated title --&gt;] at www-mechmath. univer. kharkov. ua (in Russian)

* [https://scholar.google.com/citations?user=8Rj2u78AAAAJ&amp;hl=en ] Aleksandr M. Lyapunov = Ляпунов Александр Михайлович  alive at scholar.google.com (live citations)

{{chaos theory}}
{{Authority control}}

{{DEFAULTSORT:Lyapunov, Aleksandr}}
[[Category:1857 births]]
[[Category:1918 deaths]]
[[Category:19th-century Russian mathematicians]]
[[Category:Ukrainian mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:Chaos theorists]]
[[Category:Control theorists]]
[[Category:Full Members of the Russian Academy of Sciences (1917–25)]]
[[Category:Full Members of the St Petersburg Academy of Sciences]]
[[Category:Mathematicians who committed suicide]]
[[Category:People from Yaroslavl]]
[[Category:Russian mathematicians]]
[[Category:Saint Petersburg State University alumni]]
[[Category:Suicides by firearm in the Soviet Union]]
[[Category:Suicides by firearm in Ukraine]]
[[Category:Rurikids]]
[[Category:Untitled Rurikids]]</text>
      <sha1>hhefhycdp7jitmt4m1kqmq478gzxwpj</sha1>
    </revision>
  </page>
  <page>
    <title>André plane</title>
    <ns>0</ns>
    <id>21121170</id>
    <revision>
      <id>569346256</id>
      <parentid>469796577</parentid>
      <timestamp>2013-08-20T07:24:17Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>/* References */[[WP:CHECKWIKI]] error fixes / special characters in sortkey fixed using [[Project:AWB|AWB]] (9427)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="806">In mathematics, '''André planes''' are  [[non-Desarguesian plane]]s with [[transitive group action|transitive]] [[automorphism group]]s found by {{harvtxt|André|1954}}.

==References==
*{{Citation | last1=André | first1=Johannes | title=Über nicht-Desarguessche Ebenen mit transitiver Translationsgruppe | url=http://resolver.sub.uni-goettingen.de/purl?GDZPPN002384345 | doi=10.1007/BF01187370 | mr=0063056 | year=1954 | journal=[[Mathematische Zeitschrift]] | issn=0025-5874 | volume=60 | pages=156–186}}
*{{Citation | last1=Weibel | first1=Charles | title=Survey of Non-Desarguesian Planes  | url=http://www.ams.org/notices/200710/ | year=2007 | journal= Notices of the AMS  | volume= 54 | issue=10 | pages=1294–1303}}

{{DEFAULTSORT:Andre plane}}
[[Category:Finite geometry]]


{{geometry-stub}}</text>
      <sha1>ileys2a3w0mtxc3gez782v7k7eu8f32</sha1>
    </revision>
  </page>
  <page>
    <title>Ball (mathematics)</title>
    <ns>0</ns>
    <id>160556</id>
    <revision>
      <id>865484001</id>
      <parentid>865398597</parentid>
      <timestamp>2018-10-24T07:19:38Z</timestamp>
      <contributor>
        <username>Purgy Purgatorio</username>
        <id>22035051</id>
      </contributor>
      <comment>/* {{mvar|p}}-norm */ sorry ...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10459">{{more footnotes|date=March 2013}}
[[File:Sphere wireframe.svg|thumb|In [[Euclidean space]], a '''ball''' is the volume bounded by a sphere]]

In [[mathematics]], a '''ball''' is the space bounded by a [[sphere]]. It may be a '''closed ball''' (including the [[boundary points]] that constitute the sphere) or an '''open ball''' (excluding them).

These concepts are defined not only in three-dimensional [[Euclidean space]] but also for lower and higher dimensions, and for [[metric space]]s in general. A ''ball'' or '''hyperball''' in {{mvar|n}} dimensions is called an '''{{mvar|n}}-ball''' and is bounded by an [[N-sphere|'''({{math|''n'' − 1}})-sphere''']]. Thus, for example, a ball in the [[Euclidean plane]] is the same thing as a [[disk (mathematics)|disk]], the area bounded by a [[circle]]. In [[Euclidean space|Euclidean 3-space]], a ball is taken to be the [[volume]] bounded by a [[2-sphere|2-dimensional sphere]]. In a [[one-dimensional space]], a ball is a [[line segment]].

In other contexts, such as in [[Euclidean geometry]] and informal use, ''sphere'' is sometimes used to mean ''ball''.

==Balls in Euclidean space==
In Euclidean {{mvar|n}}-space, an (open) {{mvar|n}}-ball of radius {{mvar|r}} and center {{mvar|x}} is the set of all points of distance less than {{mvar|r}} from {{mvar|x}}. A closed {{mvar|n}}-ball of radius {{mvar|r}} is the set of all points of distance less than or equal to {{mvar|r}} away from {{mvar|x}}.

In Euclidean {{mvar|n}}-space, every ball is bounded by a [[hypersphere]].  The ball is a bounded [[Interval (mathematics)|interval]] when {{math|1=''n'' = 1}}, is a '''[[Disk (mathematics)|disk]]''' bounded by a [[circle]] when {{math|1=''n'' = 2}}, and is bounded by a [[sphere]] when {{math|1=''n'' = 3}}.

=== Volume ===
{{main article|Volume of an n-ball|l1=Volume of an {{mvar|n}}-ball}}
The {{mvar|n}}-dimensional volume of a Euclidean ball of radius {{mvar|R}} in {{mvar|n}}-dimensional Euclidean space is:&lt;ref&gt;Equation 5.19.4, ''NIST Digital Library of Mathematical Functions.'' http://dlmf.nist.gov/,{{dead link|date=July 2016 |bot=InternetArchiveBot |fix-attempted=yes }} Release 1.0.6 of 2013-05-06.&lt;/ref&gt;
:&lt;math&gt;V_n(R) = \frac{\pi^\frac{n}{2}}{\Gamma\left(\frac{n}{2} + 1\right)}R^n,&lt;/math&gt;
where&amp;nbsp;{{math|Γ}} is [[Leonhard Euler]]'s [[gamma function]] (which can be thought of as an extension of the [[factorial]] function to fractional arguments). Using explicit formulas for [[particular values of the gamma function]] at the integers and half integers gives formulas for the volume of a Euclidean ball that do not require an evaluation of the gamma function. These are:
:&lt;math&gt;\begin{align}V_{2k}(R) &amp;= \frac{\pi^k}{k!}R^{2k}\,,\\
V_{2k+1}(R) &amp;= \frac{2^{k+1}\pi^k}{(2k+1)!!}R^{2k+1} = \frac{2(k!)(4\pi)^k}{(2k+1)!}R^{2k+1}\,.\end{align}&lt;/math&gt;
In the formula for odd-dimensional volumes, the [[double factorial]] {{math|(2''k'' + 1)!!}} is defined for odd integers {{math|2''k'' + 1}} as {{math|1=(2''k'' + 1)!! = 1 · 3 · 5 · … · (2''k'' − 1) · (2''k'' + 1)}}.

==Balls in general metric spaces==
Let {{math|(''M'', ''d'')}} be a [[metric space]], namely a set {{mvar|M}} with a [[Metric (mathematics)|metric]] (distance function) {{mvar|d}}. The open (metric) '''ball of radius''' {{math|''r'' &gt; 0}} centered at a point {{mvar|p}} in {{mvar|M}}, usually denoted by {{math|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'')}} or {{math|''B''(''p''; ''r'')}}, is defined by

:&lt;math&gt;B_r(p) = \{ x \in M \mid d(x,p) &lt; r \},&lt;/math&gt;

The closed (metric) ball, which may be denoted by {{math|''B&lt;sub&gt;r&lt;/sub&gt;''[''p'']}} or {{math|''B''[''p''; ''r'']}}, is defined by

:&lt;math&gt;B_r[p] = \{ x \in M \mid d(x,p) \le r \}.&lt;/math&gt;

Note in particular that a ball (open or closed) always includes {{mvar|p}} itself, since the definition requires {{math|''r'' &gt; 0}}.

The [[closure (mathematics)|closure]] of the open ball {{math|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'')}} is usually denoted {{math|{{overline|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'')}}}}. While it is always the case that {{math|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'') ⊆ {{overline|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'')}} ⊆ ''B&lt;sub&gt;r&lt;/sub&gt;''[''p'']}}, it is {{em|not}} always the case that {{math|{{overline|''B&lt;sub&gt;r&lt;/sub&gt;''(''p'')}} {{=}} ''B&lt;sub&gt;r&lt;/sub&gt;''[''p'']}}. For example, in a metric space {{mvar|X}} with the [[discrete metric]], one has {{math|{{overline|''B''&lt;sub&gt;1&lt;/sub&gt;(''p'')}} {{=}} {p&lt;nowiki&gt;}&lt;/nowiki&gt;}} and {{math|''B''&lt;sub&gt;1&lt;/sub&gt;[''p''] {{=}} ''X''}}, for any {{math|''p'' ∈ ''X''}}.

A '''[[unit ball]]''' (open or closed) is a ball of radius 1.

A subset of a metric space is [[bounded set|bounded]] if it is contained in some ball. A set is [[totally bounded]] if, given any positive radius, it is covered by finitely many balls of that radius.

The open balls of a [[metric space]] can serve as a [[base (topology)|base]], giving this space a [[topological space|topology]], the open sets of which are all possible [[union (set theory)|union]]s of open balls. This topology on a metric space is called the '''topology induced by''' the metric {{mvar|d}}.

==Balls in normed vector spaces==
Any [[normed vector space]] {{mvar|V}} with norm &lt;math&gt;\|\cdot\|&lt;/math&gt; is also a metric space with the metric &lt;math&gt;d (x,y)= \|x-y\|.&lt;/math&gt;  In such spaces, an arbitrary ball &lt;math&gt;B_r(y)&lt;/math&gt; of points &lt;math&gt;x&lt;/math&gt; around a point &lt;math&gt;y&lt;/math&gt; with a distance of less than &lt;math&gt;r&lt;/math&gt; may be viewed as a scaled (by &lt;math&gt;r&lt;/math&gt;) and translated (by &lt;math&gt;y&lt;/math&gt;) copy of a ''unit ball'' &lt;math&gt;B_1(0).&lt;/math&gt; Such "centered" balls with &lt;math&gt;y=0&lt;/math&gt; are denoted with &lt;math&gt;B(r).&lt;/math&gt;

The Euclidean balls discussed earlier are an example of balls in a normed vector space.

==={{mvar|p}}-norm===
In a [[Cartesian space]] {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} with the [[p-norm|{{mvar|p}}-norm]] {{mvar|L&lt;sub&gt;p&lt;/sub&gt;}}, that is

:&lt;math&gt;\left\| x \right\| _p = \left( |x_1|^p + |x_2|^p + \dotsb + |x_n|^p \right) ^{1/p},&lt;/math&gt;

an open ball around the origin with radius &lt;math&gt;r&lt;/math&gt; is given by the set

:&lt;math&gt; B(r) = \left\{ x \in \R^n \,:\left\| x \right\| _p = \left( |x_1|^p + |x_2|^p + \dotsb + |x_n|^p \right) ^{1/p} &lt; r \right\}.&lt;/math&gt;

For {{math|1=''n'' = 2}}, in a 2-dimensional plane &lt;math&gt;\mathbb R^2&lt;/math&gt;, "balls" according to the {{math|''L''&lt;sub&gt;1&lt;/sub&gt;}}-norm (often called the ''[[Taxicab geometry|taxicab]]'' or ''Manhattan'' metric) are bounded by squares with their ''diagonals'' parallel to the coordinate axes; those according to the {{math|''L''&lt;sub&gt;∞&lt;/sub&gt;}}-norm, also called the [[Chebyshev distance|Chebyshev]] metric, have squares with their ''sides'' parallel to the coordinate axes as their boundaries. The {{math|''L''&lt;sub&gt;2&lt;/sub&gt;}}-norm, known as the Euclidean metric, generates the well known discs within circles, and for other values of {{mvar|p}}, the corresponding balls are areas bounded by [[Lamé curve]]s (hypoellipses or hyperellipses).

For {{math|1=''n'' = 3}}, the {{math|''L''&lt;sub&gt;1&lt;/sub&gt;}}- balls are within octahedra with axes-aligned ''body diagonals'', the {{math|''L''&lt;sub&gt;∞&lt;/sub&gt;}}-balls are within cubes with axes-aligned ''edges'', and the boundaries of balls for {{mvar|L&lt;sub&gt;p&lt;/sub&gt;}} with {{math|''p'' &gt; 2}} are [[superegg|superellipsoids]]. Obviously, {{math|''p'' {{=}} 2}} generates the inner of usual spheres.

===General convex norm===
More generally, given any [[central symmetry|centrally symmetric]], [[bounded set|bounded]], [[open set|open]], and [[convex set|convex]] subset {{mvar|X}} of {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}, one can define a [[Norm (mathematics)|norm]] on {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} where the balls are all translated and uniformly scaled copies of&amp;nbsp;{{mvar|X}}. Note this theorem does not hold if "open" subset is replaced by "closed" subset, because the origin point qualifies but does not define a norm on&amp;nbsp;{{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}.

==Topological balls==

One may talk about balls in any [[topological space]] {{mvar|X}}, not necessarily induced by a metric. An (open or closed) {{mvar|n}}-dimensional '''topological ball''' of {{mvar|X}} is any subset of {{mvar|X}} which is [[homeomorphic]] to an (open or closed) Euclidean {{mvar|n}}-ball. Topological {{mvar|n}}-balls are important in [[combinatorial topology]], as the building blocks of [[cell complex]]es.

Any open topological {{mvar|n}}-ball is homeomorphic to the Cartesian space {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} and to the open [[hypercube|unit {{mvar|n}}-cube]] (hypercube) {{math|(0, 1)&lt;sup&gt;''n''&lt;/sup&gt; ⊆ ℝ&lt;sup&gt;''n''&lt;/sup&gt;}}. Any closed topological {{mvar|n}}-ball is homeomorphic to the closed {{mvar|n}}-cube {{math|[0, 1]&lt;sup&gt;''n''&lt;/sup&gt;}}.

An {{mvar|n}}-ball is homeomorphic to an {{mvar|m}}-ball if and only if {{math|1=''n'' = ''m''}}. The homeomorphisms between an open {{mvar|n}}-ball {{mvar|B}} and {{math|ℝ&lt;sup&gt;''n''&lt;/sup&gt;}} can be classified in two classes, that can be identified with the two possible [[orientation (mathematics)|topological orientation]]s of&amp;nbsp;{{mvar|B}}.

A topological {{mvar|n}}-ball need not be [[differentiable manifold|smooth]]; if it is smooth, it need not be [[diffeomorphic]] to a Euclidean {{mvar|n}}-ball.

==See also==
{{Div col|colwidth=20em}}
*[[Ball]] – ordinary meaning
*[[Disk (mathematics)]]
*[[Formal ball]], an extension to negative radii
*[[Neighbourhood (mathematics)]]
*[[3-sphere]]
*[[n-sphere|{{mvar|n}}-sphere]], or hypersphere
*[[Alexander horned sphere]]
*[[Manifold]]
*[[Volume of an n-ball|Volume of an {{mvar|n}}-ball]]
*[[Octahedron]] – a 3-ball in the {{math|''l''&lt;sub&gt;1&lt;/sub&gt;}} metric.
*[[Spherical shell]]
{{div col end}}

==References==
{{Expand section|date=December 2009}}
{{Reflist}}
* {{cite journal |first=D. J. |last=Smith |first2=M. K. |last2=Vamanamurthy |title=How small is a unit ball? |journal=[[Mathematics Magazine]] |volume=62 |year=1989 |issue=2 |pages=101–107 |jstor=2690391 }}
* {{cite journal |title=Robin Conditions on the Euclidean ball |first=J. S. |last=Dowker |journal=[[Classical and Quantum Gravity]] |year=1996 |volume=13 |issue=4 |pages=585–610 |doi=10.1088/0264-9381/13/4/003 |arxiv=hep-th/9506042 |bibcode=1996CQGra..13..585D }}
* {{cite journal |first=Peter M. |last=Gruber |title=Isometries of the space of convex bodies contained in a Euclidean ball |journal=[[Israel Journal of Mathematics]] |year=1982 |volume=42 |issue=4 |pages=277–283 |doi=10.1007/BF02761407 }}

{{DEFAULTSORT:Ball (Mathematics)}}
[[Category:Balls]]
[[Category:Metric geometry]]
[[Category:Spheres]]
[[Category:Topology]]</text>
      <sha1>mtrblgya6z5ya7xr80qqlp2cy34ahgt</sha1>
    </revision>
  </page>
  <page>
    <title>Bisection (software engineering)</title>
    <ns>0</ns>
    <id>36033877</id>
    <revision>
      <id>826405304</id>
      <parentid>826243295</parentid>
      <timestamp>2018-02-18T22:54:39Z</timestamp>
      <contributor>
        <username>Mrwojo</username>
        <id>4135</id>
      </contributor>
      <comment>what it mean for version control to "support" bisection, generalize sections to be about automation potential, added a new ref (Zeller)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5111">{{Other uses|Bisect (disambiguation){{!}}Bisect}}
'''Bisection''' is a method used in [[software development]] to identify [[Patch (computing)|change sets]] that result in a specific behavior change. It is mostly employed for finding the patch that introduced a [[software bug|bug]]. Another application area is finding the patch that indirectly fixed a bug.

==Overview==
The process of locating the [[changeset]] that introduced a specific [[software regression|regression]] was described as "source change isolation" in 1997 by Brian Ness and Viet Ngo of [[Cray Research]]. [[Regression testing]] was performed on Cray's [[compiler]]s in editions comprising one or more changesets. Editions with known regressions could not be validated until developers addressed the problem. Source change isolation narrowed the cause to a single changeset that could then be excluded from editions, unblocking them with respect to this problem, while the author of the change worked on a fix. Ness and Ngo outlined [[linear search]] and [[binary search]] methods of performing this isolation.&lt;ref name="Ness 97"&gt;{{cite conference |title=Regression containment through source change isolation |last=Ness |first=Brian |last2=Ngo |first2=Viet |date=1997 |conference=Computer Software and Applications Conference |doi=10.1109/CMPSAC.1997.625082 |publisher=IEEE}}&lt;/ref&gt;

Code bisection has the goal of minimizing the effort to find a specific change set.
It employs a [[divide and conquer algorithm]] that
depends on having access to the code history which is usually preserved by
[[revision control]] in a [[Repository (version control)|code repository]].

==Bisection method==
===Code bisection algorithm===
Code history has the structure of a [[directed acyclic graph]] which can be [[Topological ordering|topologically sorted]]. This makes it possible to use a divide and conquer search algorithm which:
* splits up the [[Computational geometry#Geometric query problems|search space]] of candidate revisions
* tests for the behavior in question
* reduces the search space depending on the test result
* re-iterates the steps above until a range with at most one bisectable [[Candidate solution|patch candidate]] remains

===Algorithmic complexity===
Bisection is in [[L (complexity)|LSPACE]] having an [[Analysis of algorithms|algorithmic complexity]] of &lt;math&gt;O(\log N)&lt;/math&gt; with &lt;math&gt;N&lt;/math&gt; denoting the number of revisions in the search space, and is similar to a [[binary search]].

===Desirable repository properties===
For code bisection it is desirable that each revision in the search space can be built and tested independently.

==Automation support==
Although the bisection method can be completed manually, one of its main advantages is that it can be easily automated.&lt;ref name="Ness 97" /&gt; It can thus fit into existing [[test automation]] processes: failures in exhaustive automated regression tests can trigger automated bisection to localize faults. Ness and Ngo focused on its potential in Cray's [[continuous delivery]]-style environment in which the automatically-isolated bad changeset could be automatically excluded from builds.&lt;ref name="Zeller 99"&gt;{{cite conference |first=Andreas |last=Zeller |title=Yesterday, my program worked. Today, it does not. Why? |date=1999 |conference=European Software Engineering Conference |location=Toulouse, France |doi=10.1145/318774.318946}}&lt;/ref&gt;

The revision control systems [[Git (software)|Git]] and [[Mercurial]] have built-in functionality for code bisection.&lt;ref&gt;{{cite web|url=https://git-scm.com/docs/git-bisect |title=git-bisect(1) |website=git-scm.com |accessdate=2017-08-05}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.selenic.com/mercurial/hg.1.html#bisect |title=hg |website=Selenic.com |date= |accessdate=2017-01-09}}&lt;/ref&gt; The user can start a bisection session with a specified range of revisions from which the revision control system proposes a revision to test, the user tells the system whether the revision tested as "good" or "bad", and the process repeats until the specific "bad" revision has been identified. Other revision control systems, such as [[Bazaar (software)|Bazaar]] or [[Apache Subversion|Subversion]], support bisection through plugins&lt;ref&gt;{{cite web|url=http://doc.bazaar.canonical.com/plugins/en/bisect-plugin.html |title=bisect - Find the revision introducing a bug using a binary search — Bazaar 2.8.0dev1 documentation |website=Doc.bazaar.canonical.com |date= |accessdate=2017-01-09}}&lt;/ref&gt; or external scripts.&lt;ref&gt;{{cite web|url=https://metacpan.org/module/INFINOID/App-SVN-Bisect-1.1/bin/svn-bisect |title=svn-bisect |website=Metacpan.org |date= |accessdate=2017-01-09}}&lt;/ref&gt;

[[Phoronix Test Suite]] can do bisection automatically to find performance regressions.

==See also==
* [[Delta debugging]] (generalization of finding a minimal cause of a bug) 
* {{section link|Annotation|Source control}} (determining changesets that edited a line in a file)

==References==
{{Reflist}}

[[Category:Version control]]
[[Category:Version control systems]]
[[Category:Software development process]]
[[Category:Algorithms]]</text>
      <sha1>ezrdyd0azruvhit4yul8t6e9slajj3a</sha1>
    </revision>
  </page>
  <page>
    <title>Campbell's theorem (probability)</title>
    <ns>0</ns>
    <id>34929672</id>
    <revision>
      <id>851514722</id>
      <parentid>851514630</parentid>
      <timestamp>2018-07-22T20:49:30Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>sizes of delimiters</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14598">{{about|random point processes||Campbell's theorem (geometry)}}

In [[probability theory]] and [[statistics]], '''Campbell's theorem''' or the '''Campbell–Hardy theorem''' is either a particular [[equation]] or set of results relating to the [[Expected value|expectation]] of a [[Function (mathematics)|function]] summed over a [[point process]] to an [[integral]] involving the [[Moment measure#First moment measure|mean measure]] of the point process, which allows for the calculation of [[expected value]] and [[variance]] of the [[random]] [[summation|sum]]. One version of the theorem,&lt;ref name="stoyan1995stochastic"&gt;D. Stoyan, W. S. Kendall, J. Mecke. ''Stochastic geometry and its applications'', volume 2. Wiley Chichester, 1995.&lt;/ref&gt; also known as '''Campbell's formula''',&lt;ref name="baddeley2007spatial"&gt;{{Cite book | doi = 10.1007/978-3-540-38175-4_1 | first1 = A. | last1 = Baddeley | first2 = I. | last2 = Barany | first3 = R. | last3 = Schneider | first4 = W. | last4 = Weil| chapter = Spatial Point Processes and their Applications | title = Stochastic Geometry | series = Lecture Notes in Mathematics | volume = 1892 | pages = 1 | year = 2007 | isbn = 978-3-540-38174-7 | pmid =  | pmc = }}&lt;/ref&gt;{{rp|28}} entails an integral equation for the aforementioned sum over a general point process, and not necessarily  a Poisson point process.&lt;ref name="baddeley2007spatial"/&gt; There also exist equations involving  [[moment measure]]s and [[factorial moment measure]]s that are considered versions of Campbell's formula. All these results are employed in  probability and statistics with a particular importance in the theory of [[point process]]es&lt;ref name="daleyPPI2003"&gt;{{Cite journal | doi = 10.1007/b97277 | first1 = D. J. | last1 = Daley | first2 = D. | last2 = Vere-Jones| title = An Introduction to the Theory of Point Processes | series = Probability and its Applications | year = 2003 | isbn = 0-387-95541-0 | pmid =  | pmc = }}&lt;/ref&gt; and [[queueing theory]]&lt;ref name="baccelli2002elements"&gt;{{cite book|title=Elements of queueing theory: Palm Martingale calculus and stochastic recurrences|page=18,195 |first=Pierre|last=Brémaud|first2=François|last2=Baccelli|publisher=Springer Science &amp; Business Media|year=2002|isbn=978-3-642-08537-6}}&lt;/ref&gt;  as well as the related fields [[stochastic geometry]],&lt;ref name="stoyan1995stochastic"/&gt; [[continuum percolation theory]],&lt;ref name="meester1996continuum"&gt;R. Meester and R. Roy. Continuum percolation, volume 119 of Cambridge tracts in mathematics, 1996.&lt;/ref&gt; and [[spatial statistics]].&lt;ref name="baddeley2007spatial"/&gt;&lt;ref name="moller2003statistical"&gt;{{Cite journal | last1 = Moller | first1 = J. | last2 = Plenge Waagepetersen | first2 = R. | doi = 10.1201/9780203496930 | title = Statistical Inference and Simulation for Spatial Point Processes | series = C&amp;H/CRC Monographs on Statistics &amp; Applied Probability | volume = 100 | year = 2003 | isbn = 978-1-58488-265-7 | pmid =  | pmc = }}&lt;/ref&gt;

Another result by the name of Campbell's theorem&lt;ref name="kingman1992poisson"&gt;{{cite book|title=Poisson Processes|page=28|first=John|last=Kingman|authorlink=John Kingman|publisher=Oxford Science Publications|year=1993|isbn=0-19-853693-3}}&lt;/ref&gt; is specifically for the [[Poisson point process]] and gives a method for calculating [[Moment (mathematics)|moments]] as well as the [[Laplace functional]] of a Poisson point process.

The name of both theorems stems from the work&lt;ref name="campbell1909study"&gt;{{Cite journal|last=Campbell|first= N.| authorlink=Norman Robert Campbell |year=1909|journal= Proc. Camb. Phil. Soc. |volume=15 |title=The study of discontinuous phenomena|pages= 117–136|url=https://archive.org/details/proceedingsofcam15190810camb}}&lt;/ref&gt;&lt;ref name="campbell1909discontinuities"&gt;{{cite journal|last=Campbell|first= N.| authorlink = Norman Robert Campbell |year=1910|journal= Proc. Camb. Phil. Soc. |volume=15 |title=Discontinuities in light emission
|pages=310–328|url=https://archive.org/details/proceedingsofcam15190810camb}}&lt;/ref&gt; by [[Norman Robert Campbell|Norman R. Campbell]] on [[Thermionic emission|thermionic]] noise, also known as [[shot noise]], in [[vacuum tubes]],&lt;ref name="daleyPPI2003"/&gt;&lt;ref name="stirzaker2000advice"&gt;{{cite journal | last1 = Stirzaker | first1 = David | year = 2000 | title = Advice to Hedgehogs, or, Constants Can Vary | journal = The Mathematical Gazette | volume = 84 | issue = 500 | pages = 197–210 | publisher = 197–210 | jstor = 3621649 | url =  | format =  | accessdate = }}&lt;/ref&gt;  which was partly inspired by the work of [[Ernest Rutherford]] and [[Hans Geiger]] on [[alpha particle]] detection, where the [[Poisson point process]] arose as a solution to a family of differential equations by [[Harry Bateman]].&lt;ref name="stirzaker2000advice"/&gt;  In Campbell's work, he presents the moments and [[Moment-generating function|generating functions]] of the random sum of a Poisson process on the real line, but remarks that the main mathematical argument was due to [[G. H. Hardy]], which has inspired the result to be sometimes called the '''Campbell–Hardy theorem'''.&lt;ref name="stirzaker2000advice"/&gt;&lt;ref&gt;{{cite book|last=Grimmett G. and  Stirzaker D.|title=Probability and random processes|year=2001|publisher=Oxford University Press|pages=290}}&lt;/ref&gt;

==Background==

For a point process &lt;math&gt;N&lt;/math&gt; defined on ''d''-dimensional [[Euclidean space]] &lt;math&gt;\textbf{R}^d &lt;/math&gt;,{{efn|It can be defined on a more general mathematical space than Euclidean space, but often this space is used for models.&lt;ref name="daleyPPI2003"/&gt;}} Campbell's theorem offers a way to calculate expectations of a real-valued function &lt;math&gt;f&lt;/math&gt;   defined also on &lt;math&gt;\textbf{R}^d &lt;/math&gt; and summed over &lt;math&gt;N&lt;/math&gt;, namely:

:&lt;math&gt; \operatorname E\left[ \sum_{x\in N}f(x)\right], &lt;/math&gt;

where &lt;math&gt;E &lt;/math&gt; denotes the expectation and set notation is used such that &lt;math&gt;N&lt;/math&gt; is considered as a random set (see [[Point process notation]]). For a point process  &lt;math&gt;N&lt;/math&gt;, Campbell's theorem relates the above expectation with  the intensity measure&amp;nbsp;Λ. In relation to a [[Borel set]] ''B'' the intensity measure of &lt;math&gt;N&lt;/math&gt; is defined as:

:&lt;math&gt;\Lambda(B)=\operatorname E[N(B)],&lt;/math&gt;

where the [[Measure (mathematics)|measure]] notation is used such that &lt;math&gt;N&lt;/math&gt; is considered a random [[counting measure]]. The quantity  Λ(''B'') can be interpreted as the average number of points of  &lt;math&gt;N&lt;/math&gt;  located in the set ''B''.

==First definition: general point process==

One version of Campbell's theorem is for a general (not necessarily simple) point process &lt;math&gt;N&lt;/math&gt; with intensity measure:

:&lt;math&gt; \Lambda (B)=\operatorname E[N(B)], &lt;/math&gt;

is known as '''Campbell's formula'''&lt;ref name="baddeley2007spatial"/&gt; or '''Campbell's theorem''',&lt;ref name="stoyan1995stochastic"/&gt;&lt;ref name="daleyPPII2008"&gt;{{Cite journal | last1 = Daley | first1 = D. J. | last2 = Vere-Jones | first2 = D. | doi = 10.1007/978-0-387-49835-5 | title = An Introduction to the Theory of Point Processes | series = Probability and Its Applications | year = 2008 | isbn = 978-0-387-21337-8 | pmid =  | pmc = }}&lt;/ref&gt;&lt;ref name="bremaud2014fourier"&gt;P. Brémaud. ''Fourier Analysis of Stochastic Processes''. Springer, 2014.&lt;/ref&gt; which gives a method for calculating expectations of sums of [[measurable function]]s &lt;math&gt; f&lt;/math&gt; with [[Range (mathematics)|ranges]] on the [[real line]]. More specifically, for a point process &lt;math&gt;N&lt;/math&gt; and a measurable function &lt;math&gt; f: \textbf{R}^d\rightarrow \textbf{R}&lt;/math&gt;, the sum of &lt;math&gt; f&lt;/math&gt; over the point process is given by the equation:

:&lt;math&gt; E\left[\sum_{x\in N}f(x)\right]=\int_{\textbf{R}^d} f(x)\Lambda (dx), &lt;/math&gt;

where if one side of the equation is finite, then so is the other side.&lt;ref name="baddeley1999crash"&gt;A. Baddeley. A crash course in stochastic geometry. ''Stochastic Geometry: Likelihood and Computation Eds OE Barndorff-Nielsen, WS Kendall, HNN van Lieshout (London: Chapman and Hall) pp'', pages 1–35, 1999.

&lt;/ref&gt; This equation is essentially an application of [[Fubini's theorem]]&lt;ref name="stoyan1995stochastic"/&gt; and it holds for a wide class of point processes, simple or not.&lt;ref name="baddeley2007spatial"/&gt; Depending on the integral notation,{{efn|As discussed in Chapter 1 of Stoyan, Kendall and Mecke,&lt;ref name="stoyan1995stochastic"/&gt; which applies to all other integrals presented here and elsewhere due to varying integral notation.}} this  integral may also be written as:&lt;ref name="baddeley1999crash"/&gt;

:&lt;math&gt; \operatorname E\left[\sum_{x\in N}f(x)\right]=\int_{\textbf{R}^d} f \, d\Lambda , &lt;/math&gt;

If the intensity measure &lt;math&gt; \Lambda&lt;/math&gt; of a point process &lt;math&gt;N&lt;/math&gt; has a density &lt;math&gt; \lambda(x) &lt;/math&gt;, then Campbell's formula becomes:

:&lt;math&gt; \operatorname E\left[\sum_{x\in N}f(x)\right]= \int_{\textbf{R}^d} f(x)\lambda(x) \, dx &lt;/math&gt;

===Stationary point process===

For a stationary point process &lt;math&gt;N&lt;/math&gt; with constant density &lt;math&gt; \lambda&gt;0&lt;/math&gt;, '''Campbell's theorem''' or '''formula''' reduces to a volume integral:

: &lt;math&gt; \operatorname E\left[\sum_{x\in N}f(x)\right]=\lambda \int_{\textbf{R}^d} f(x) \, dx &lt;/math&gt;

This equation naturally holds for the homogeneous Poisson point processes, which is an example of a [[stationary stochastic process]].&lt;ref name="stoyan1995stochastic"/&gt;

==Applications: Random sums==
Campbell's theorem for general point processes gives a method for calculating the expectation of a function of a point (of a point process) summed over all the points in the point process. These random sums over point processes have applications in many areas where they are used as mathematical models.

===Shot noise===
Campbell originally studied a problem of random sums motivated by understanding thermionic noise in valves, which is also known as shot-noise. Consequently, the study of random sums of functions over point processes is known as shot noise in probability and, particularly, point process theory.

===Interference in wireless networks===
In wireless network communication, when a transmitter is trying to send a signal to a receiver, all the other transmitters in the network can be considered as interference, which poses a similar problem as noise does in traditional wired telecommunication networks in terms of the ability to send data based on information theory. If the positioning of the interfering transmitters are assumed to form some point process, then shot noise can be used to model the sum of their interfering signals, which has led to stochastic geometry models of wireless networks.&lt;ref name="BB1"/&gt;

==Generalizations==
For general point processes, other more general versions of Campbell's theorem exist depending on the nature of the random sum and in particular the function being summed over the point process.

===Functions of multiple points===
If the function is a function of more than one point of the point process, the [[moment measure]]s or [[factorial moment measure]]s of the point process are needed, which can be compared to moments and factorial of random variables. The type of measure needed depends on whether the points of the point process in the random sum are need to be distinct or may repeat.

====Repeating points====
Moment measures are used when points are allowed to repeat.

====Distinct points====
Factorial moment measures are used when points are not allowed to repeat, hence points are distinct.

===Functions of points and the point process===

For general point processes, Campbell's theorem is only for sums of functions of a single point of the point process. To calculate the sum of a function of a single point as well as the entire point process, then generalized Campbell's theorems are required using the Palm distribution of the point process, which is based on the branch of probability known as Palm theory or [[Palm calculus]].

==Second definition: Poisson point process==

Another version of Campbell's theorem&lt;ref name="kingman1992poisson"/&gt; says that for a Poisson point process &lt;math&gt;N&lt;/math&gt; with intensity measure &lt;math&gt; \Lambda&lt;/math&gt; and a measurable function &lt;math&gt; f:\textbf{R}^d\rightarrow \textbf{R}&lt;/math&gt;, the random sum

:&lt;math&gt; S =\sum_{x\in N}f(x) &lt;/math&gt;

is [[absolutely convergent]] with [[Almost surely|probability one]] [[if and only if]] the integral

:&lt;math&gt; \int_{\textbf{R}^d} \min(|f(x)|,1)\Lambda (dx) &lt; \infty. &lt;/math&gt;

Provided that this integral is finite, then the theorem further asserts that for any [[Complex Number|complex]] value &lt;math&gt;\theta&lt;/math&gt; the equation

:&lt;math&gt; E(e^{\theta S})=\exp \left(\int_{\textbf{R}^d} [e^{\theta f(x)}-1]\Lambda (dx) \right), &lt;/math&gt;

holds if the integral on the right-hand side [[convergence (mathematics)|converges]], which is the case for purely [[Imaginary number|imaginary]] &lt;math&gt;\theta&lt;/math&gt;. Moreover,

:&lt;math&gt; E(S)=\int_{\textbf{R}^d} f(x)\Lambda (dx), &lt;/math&gt;

and if this integral converges, then

:&lt;math&gt; \operatorname{Var}(S)=\int_{\textbf{R}^d} f(x)^2\Lambda (dx), &lt;/math&gt;

where &lt;math&gt; \text{Var}(S)&lt;/math&gt; denotes the [[variance]] of the random sum &lt;math&gt;S&lt;/math&gt;.

From this theorem some expectation results for the [[Poisson point process]] follow, including its  [[Laplace functional]].&lt;ref name="kingman1992poisson"/&gt; {{efn|Kingman&lt;ref name="kingman1992poisson"/&gt; calls it a "characteristic functional" but Daley and Vere-Jones&lt;ref name="daleyPPI2003"/&gt; and others call it a "Laplace functional",&lt;ref name="stoyan1995stochastic"/&gt;&lt;ref name="BB1"&gt;{{Cite journal | last1 = Baccelli | first1 = F. O. | title = Stochastic Geometry and Wireless Networks: Volume I Theory | doi = 10.1561/1300000006 | journal = Foundations and Trends in Networking | volume = 3 | issue = 3–4 | pages = 249–449 | year = 2009 | pmid =  | pmc = }}&lt;/ref&gt; reserving the term "characteristic functional" for when &lt;math&gt; \theta&lt;/math&gt; is imaginary.}}

===Application: Laplace functional===

For a Poisson point process &lt;math&gt; N&lt;/math&gt; with intensity measure &lt;math&gt; \Lambda&lt;/math&gt;, the [[Laplace functional]] is a consequence of the above version of Campbell's theorem&lt;ref name="kingman1992poisson"/&gt; and is given by:&lt;ref name="BB1"/&gt;

:&lt;math&gt; \mathcal{L}_N(sf) := E\bigl[ e^{-s \sum_{x \in N} f(x) } \bigr] =\exp \Bigl[-\int_{\textbf{R}^d} (1-e^{-sf(x)})\Lambda(dx) \Bigr], &lt;/math&gt;

which for the homogeneous case is:

:&lt;math&gt; \mathcal{L}_N(sf)=\exp\Bigl[-\lambda\int_{\textbf{R}^d}(1-e^{-sf(x)}) \, dx \Bigr]. &lt;/math&gt;

==Notes==
{{notelist}}

==References==
{{reflist|29em}}

[[Category:Probability theorems]]</text>
      <sha1>iu9p3iawht54t21f1dn1k5qj3uz6yup</sha1>
    </revision>
  </page>
  <page>
    <title>Classical orthogonal polynomials</title>
    <ns>0</ns>
    <id>336568</id>
    <revision>
      <id>823972253</id>
      <parentid>823972129</parentid>
      <timestamp>2018-02-04T15:36:36Z</timestamp>
      <contributor>
        <username>Physicist137</username>
        <id>30460241</id>
      </contributor>
      <minor/>
      <comment>Fixing pontuation on the first paragraph.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="35643">In mathematics, the '''classical orthogonal polynomials''' are the most widely used [[orthogonal polynomials]]: the [[Hermite polynomials]], [[Laguerre polynomials]], [[Jacobi polynomials]] (including as a special case the [[Gegenbauer polynomials]], [[Chebyshev polynomials]], and [[Legendre polynomials]]&lt;ref&gt;See {{harvtxt|Suetin|2001}}&lt;/ref&gt;).

They have many important applications in such areas as mathematical physics (in particular, the theory of [[random matrices]]), [[approximation theory]], [[numerical analysis]], and many others.

Classical orthogonal polynomials appeared in the early 19th century in the works of [[Adrien-Marie Legendre]],  who introduced the Legendre polynomials. In the late 19th century, the study of [[continued fraction]]s to solve the [[moment problem]] by [[Pafnuty Chebyshev|P. L. Chebyshev]] and then [[Andrey Markov|A.A. Markov]] and [[Thomas Joannes Stieltjes|T.J. Stieltjes]] led to the general notion of orthogonal polynomials.

For given [[polynomial]]s &lt;math&gt;Q, L: \R \to \R&lt;/math&gt; and &lt;math&gt;\forall\,n \in \N_0&lt;/math&gt; the classical orthogonal polynomials &lt;math&gt;f_n:\R \to \R&lt;/math&gt; are characterized by being solutions of the differential equation 
:&lt;math&gt;Q(x) \, f_n^{\prime\prime} +  L(x)\,f_n^{\prime} + \lambda_n  f_n = 0&lt;/math&gt;
with to be determined constants &lt;math&gt;\lambda_n \in \R&lt;/math&gt;.

There are several more general definitions of orthogonal classical polynomials; for example, {{harvtxt|Andrews|Askey|1985}} use the term for all polynomials in the [[Askey scheme]].

== Definition ==

In general, the orthogonal polynomials &lt;math&gt;P_n&lt;/math&gt; with respect to a weight &lt;math&gt;W:\mathbb R \rightarrow \mathbb R^+ &lt;/math&gt;

:&lt;math&gt;\begin{align}
&amp;\deg P_n = n~, \quad n = 0,1,2,\ldots\\
&amp;\int P_m(x) \, P_n(x) \, W(x)\,dx = 0~, \quad m \neq n~.
\end{align}&lt;/math&gt;

The relations above define &lt;math&gt;P_n&lt;/math&gt; up to multiplication by a number. Various normalisations are used to fix the constant, e.g.

:&lt;math&gt; \int P_n(x)^2 W(x)\,dx = 1~.&lt;/math&gt;

The classical orthogonal polynomials correspond to the three families of weights:

:&lt;math&gt;\begin{align}
\text{(Jacobi)}\quad &amp;W(x) = \begin{cases} 
  (1 - x)^\alpha (1+x)^\beta~, &amp; -1 \leq x \leq 1 \\
  0~, &amp;\text{otherwise}
\end{cases}  \\
\text{(Hermite)}\quad  &amp;W(x) = \exp(- x^2) \\
\text{(Laguerre)}\quad &amp;W(x) = \begin{cases}
  x^\alpha \exp(- x)~, &amp; x \geq 0 \\
  0~, &amp; \text{otherwise}
\end{cases}      
\end{align}&lt;/math&gt;

The standard normalisation (also called ''standardization'') is detailed below.

===Jacobi polynomials===
{{main article|Jacobi polynomials}}

For &lt;math&gt;\alpha,\,\beta&gt;-1&lt;/math&gt; the Jacobi polynomials are given by the formula

:&lt;math&gt;P_n^{(\alpha,\beta)} (z)
= \frac{(-1)^n}{2^n n!} (1-z)^{-\alpha} (1+z)^{-\beta}
\frac{d^n}{dz^n} \left\{ (1-z)^\alpha (1+z)^\beta (1 - z^2)^n \right\}~. &lt;/math&gt;

They are normalised (standardized) by

:&lt;math&gt;P_n^{(\alpha, \beta)} (1) = {n+\alpha\choose n},&lt;/math&gt;

and satisfy the orthogonality condition

:&lt;math&gt;\begin{align}
&amp;\int_{-1}^1 (1-x)^{\alpha} (1+x)^{\beta} 
P_m^{(\alpha,\beta)} (x)P_n^{(\alpha,\beta)} (x) \; dx \\
= {} &amp;
\frac{2^{\alpha+\beta+1}}{2n+\alpha+\beta+1}
\frac{\Gamma(n+\alpha+1)\Gamma(n+\beta+1)}{\Gamma(n+\alpha+\beta+1)n!} \delta_{nm}.
\end{align}
&lt;/math&gt;

The Jacobi polynomials are solutions to the differential equation

:&lt;math&gt;
(1-x^2)y'' + ( \beta-\alpha - (\alpha + \beta + 2)x )y'+ n(n+\alpha+\beta+1) y = 0~.
&lt;/math&gt;

==== Important special cases ====

The Jacobi polynomials with &lt;math&gt;\alpha=\beta&lt;/math&gt; are called the [[Gegenbauer polynomials]] (with parameter &lt;math&gt;\gamma = \alpha+1/2&lt;/math&gt;)

For &lt;math&gt;\alpha=\beta=0&lt;/math&gt;, these are called the [[Legendre polynomials]] (for which the interval of orthogonality is [&amp;minus;1,&amp;nbsp;1] and the weight function is simply 1):

:&lt;math&gt;
P_0(x) = 1,\, P_1(x) = x,\,P_2(x) = \frac{3x^2-1}{2},\,
P_3(x) = \frac{5x^3-3x}{2},\ldots&lt;/math&gt;

For &lt;math&gt;\alpha=\beta=\pm 1/2&lt;/math&gt;, one obtains the [[Chebyshev polynomials]] (of the second and first kind, respectively).

===Hermite polynomials===
{{main article|Hermite polynomials}}

The Hermite polynomials are defined by&lt;ref&gt;other conventions are also used; see [[Hermite polynomials]].&lt;/ref&gt;

:&lt;math&gt; H_n(x)=(-1)^n e^{x^2}\frac{d^n}{dx^n}e^{-x^2}=e^{x^2/2}\bigg (x-\frac{d}{dx} \bigg )^n e^{-x^2/2}&lt;/math&gt;

They satisfy the orthogonality condition

:&lt;math&gt; \int_{-\infty}^\infty H_n(x) H_m(x) e^{-x^2} \, dx = \sqrt{\pi} 2^n n! \delta_{mn}~, &lt;/math&gt;

and the differential equation

:&lt;math&gt;y'' - 2xy' + 2n\,y = 0~.&lt;/math&gt;

===Laguerre polynomials===
{{main article|Laguerre polynomials}}

The generalised Laguerre polynomials are defined by

: &lt;math&gt;L_n^{(\alpha)}(x)=
{x^{-\alpha} e^x \over n!}{d^n \over dx^n} \left(e^{-x} x^{n+\alpha}\right)&lt;/math&gt;

(the classical Laguerre polynomials correspond to &lt;math&gt;\alpha=0&lt;/math&gt;.)

They satisfy the orthogonality relation

: &lt;math&gt;\int_0^\infty x^\alpha e^{-x} L_n^{(\alpha)}(x)L_m^{(\alpha)}(x) \, dx=\frac{\Gamma(n+\alpha+1)}{n!}\delta_{n,m}~,&lt;/math&gt;

and the differential equation

:&lt;math&gt;
x\,y'' + (\alpha +1 - x)\,y' + n\,y = 0~.&lt;/math&gt;

== Differential equation ==

The classical orthogonal polynomials arise from a differential equation of the form

:&lt;math&gt; Q(x) \, f'' +  L(x)\,f' + \lambda  f = 0 &lt;/math&gt;

where ''Q'' is a given quadratic (at most) polynomial, and ''L'' is a given linear polynomial.  The function ''f'', and the constant ''λ'', are to be found.

:(Note that it makes sense for such an equation to have a polynomial solution.
:Each term in the equation is a polynomial, and the degrees are consistent.)

This is a [[Sturm–Liouville theory|Sturm–Liouville]] type of equation.  Such equations generally have singularities in their solution functions f except for particular values of ''λ''.  They can be thought of an [[eigenvalue|eigenvector/eigenvalue]] problems:  Letting ''D'' be the [[differential operator]], &lt;math&gt;D(f) = Q f'' + L f'&lt;/math&gt;, and changing the sign of ''λ'', the problem is to find the eigenvectors (eigenfunctions) f, and the
corresponding eigenvalues ''λ'', such that f does not have singularities and ''D''(''f'') = ''λf''.

The solutions of this differential equation have singularities unless ''λ'' takes on
specific values.  There is a series of numbers ''&amp;lambda;''&lt;sub&gt;0&lt;/sub&gt;, ''&amp;lambda;''&lt;sub&gt;1&lt;/sub&gt;, ''&amp;lambda;''&lt;sub&gt;2&lt;/sub&gt;, ... that led to a series of polynomial solutions ''P''&lt;sub&gt;0&lt;/sub&gt;, ''P''&lt;sub&gt;1&lt;/sub&gt;, ''P''&lt;sub&gt;2&lt;/sub&gt;, ... if one of the following sets of conditions are met:

# ''Q'' is actually quadratic, ''L'' is linear, ''Q'' has two distinct real roots, the root of ''L'' lies strictly between the roots of ''Q'', and the leading terms of ''Q'' and ''L'' have the same sign.
# ''Q'' is not actually quadratic, but is linear, ''L'' is linear, the roots of ''Q'' and ''L'' are different, and the leading terms of ''Q'' and ''L'' have the same sign if the root of ''L'' is less than the root of ''Q'', or vice versa.
# ''Q'' is just a nonzero constant, ''L'' is linear, and the leading term of ''L'' has the opposite sign of ''Q''.

These three cases lead to the '''Jacobi-like''', '''Laguerre-like''', and '''Hermite-like''' polynomials, respectively.

In each of these three cases, we have the following:

* The solutions are a series of polynomials ''P''&lt;sub&gt;0&lt;/sub&gt;, ''P''&lt;sub&gt;1&lt;/sub&gt;, ''P''&lt;sub&gt;2&lt;/sub&gt;, ..., each ''P''&lt;sub&gt;''n''&lt;/sub&gt; having degree ''n'', and corresponding to a number &amp;lambda;&lt;sub&gt;''n''&lt;/sub&gt;.
* The interval of orthogonality is bounded by whatever roots ''Q'' has.
* The root of ''L'' is inside the interval of orthogonality.
* Letting &lt;math&gt;R(x) = e^{\int \frac{L(x)}{Q(x)}\,dx}&lt;/math&gt;, the polynomials are orthogonal under the weight function &lt;math&gt;W(x) =\frac{R(x)}{Q(x)}&lt;/math&gt;
* ''W''(''x'') has no zeros or infinities inside the interval, though it may have zeros or infinities at the end points.
* ''W''(''x'') gives a finite inner product to any polynomials.
* ''W''(''x'') can be made to be greater than 0 in the interval.  (Negate the entire differential equation if necessary so that ''Q''(''x'') &gt; 0 inside the interval.)

Because of the constant of integration, the quantity ''R''(''x'') is determined only up to an arbitrary positive multiplicative constant.  It will be used only in homogeneous differential equations
(where this doesn't matter) and in the definition of the weight function (which can also be
indeterminate.)  The tables below will give the "official" values of ''R''(''x'') and ''W''(''x'').

=== Rodrigues' formula  ===

{{main article|Rodrigues' formula}}
Under the assumptions of the preceding section,
''P''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') is proportional to &lt;math&gt;\frac{1}{W(x)} \  \frac{d^n}{dx^n}\left(W(x)[Q(x)]^n\right).&lt;/math&gt;

This is known as [[Rodrigues' formula]], after [[Olinde Rodrigues]].  It is often written

:&lt;math&gt;P_n(x) = \frac{1}{{e_n}W(x)} \  \frac{d^n}{dx^n}\left(W(x)[Q(x)]^n\right)&lt;/math&gt;

where the numbers ''e''&lt;sub&gt;''n''&lt;/sub&gt; depend on the standardization.  The standard values of ''e''&lt;sub&gt;''n''&lt;/sub&gt; will be given in the tables below.

===The numbers ''λ''&lt;sub&gt;''n''&lt;/sub&gt;===
Under the assumptions of the preceding section, we have

:&lt;math&gt;\lambda_n = - n \left( \frac{n-1}{2} Q'' + L' \right).&lt;/math&gt;

(Since ''Q'' is quadratic and ''L'' is linear, &lt;math&gt;Q''&lt;/math&gt; and &lt;math&gt;L'&lt;/math&gt; are constants, so these are just numbers.)

=== Second form for the differential equation ===
Let

:&lt;math&gt;R(x) = e^{\int \frac{L(x)}{Q(x)}\,dx}.&lt;/math&gt;

Then

:&lt;math&gt;(Ry')' = R\,y'' + R'\,y' = R\,y'' + \frac{R\,L}{Q}\,y'.&lt;/math&gt;

Now multiply the differential equation

:&lt;math&gt;Q\,y'' + L\,y' + \lambda y = 0&lt;/math&gt;

by ''R''/''Q'', getting

:&lt;math&gt;R\,y'' + \frac{R\,L}{Q}\,y' + \frac{R\,\lambda}{Q}\,y = 0&lt;/math&gt;

or

:&lt;math&gt;(Ry')' + \frac{R\,\lambda}{Q}\,y = 0.&lt;/math&gt;

This is the standard Sturm–Liouville form for the equation.

===Third form for the differential equation===
Let &lt;math&gt;S(x) = \sqrt{R(x)} = e^{\int \frac{L(x)}{2\,Q(x)}\,dx}.&lt;/math&gt;

Then

:&lt;math&gt;S' = \frac{S\,L}{2\,Q}.&lt;/math&gt;

Now multiply the differential equation

:&lt;math&gt;Q\,y'' + L \,y' + \lambda y = 0&lt;/math&gt;

by ''S''/''Q'', getting

:&lt;math&gt;S\,y'' + \frac{S\,L} Q \,y' + \frac{S\,\lambda} Q \,y = 0&lt;/math&gt;

or

:&lt;math&gt;S\,y'' + 2\,S'\,y' + \frac{S\,\lambda} Q \,y = 0&lt;/math&gt;

But &lt;math&gt;(S\,y)'' = S\,y'' + 2\,S'\,y' + S''\,y&lt;/math&gt;, so

:&lt;math&gt;(S\,y)'' + \left(\frac{S\,\lambda} Q - S''\right)\,y = 0,&lt;/math&gt;

or, letting ''u'' = ''Sy'',

:&lt;math&gt;u'' + \left(\frac \lambda Q - \frac{S''} S \right)\,u = 0.&lt;/math&gt;

=== Formulas involving derivatives ===
Under the assumptions of the preceding section, let ''P''{{su|b=''n''|p=[''r'']}} denote the ''r''-th derivative of ''P''&lt;sub&gt;''n''&lt;/sub&gt;.
(We put the "r" in brackets to avoid confusion with an exponent.)
''P''{{su|b=''n''|p=[''r'']}} is a polynomial of degree ''n''&amp;nbsp;&amp;minus;&amp;nbsp;''r''.  Then we have the following:

* (orthogonality) For fixed r, the polynomial sequence ''P''{{su|b=''r''|p=[''r'']}}, ''P''{{su|b=''r'' + 1|p=[''r'']}}, ''P''{{su|b=''r'' + 2|p=[''r'']}}, ... are orthogonal, weighted by &lt;math&gt;WQ^r&lt;/math&gt;.
* (generalized [[Olinde Rodrigues|Rodrigues']] formula) ''P''{{su|b=''n''|p=[''r'']}} is proportional to &lt;math&gt;\frac{1}{W(x)[Q(x)]^r} \  \frac{d^{n-r}}{dx^{n-r}}\left(W(x)[Q(x)]^n\right).&lt;/math&gt;
* (differential equation) ''P''{{su|b=''n''|p=[''r'']}} is a solution of &lt;math&gt;{Q}\,y'' + (rQ'+L)\,y' + [\lambda_n-\lambda_r]\,y = 0&lt;/math&gt;, where &amp;lambda;&lt;sub&gt;''r''&lt;/sub&gt; is the same function as &amp;lambda;&lt;sub&gt;''n''&lt;/sub&gt;, that is, &lt;math&gt;\lambda_r = - r \left( \frac{r-1}{2} Q'' + L' \right)&lt;/math&gt;
* (differential equation, second form) ''P''{{su|b=''n''|p=[''r'']}} is a solution of &lt;math&gt;(RQ^{r}y')' + [\lambda_n-\lambda_r]RQ^{r-1}\,y = 0&lt;/math&gt;

There are also some mixed recurrences.  In each of these, the numbers ''a'', ''b'', and ''c'' depend on ''n''
and ''r'', and are unrelated in the various formulas.

* &lt;math&gt;P_n^{[r]} = aP_{n+1}^{[r+1]} + bP_n^{[r+1]} + cP_{n-1}^{[r+1]}&lt;/math&gt;
* &lt;math&gt;P_n^{[r]} = (ax+b)P_n^{[r+1]} + cP_{n-1}^{[r+1]}&lt;/math&gt;
* &lt;math&gt;QP_n^{[r+1]} = (ax+b)P_n^{[r]} + cP_{n-1}^{[r]}&lt;/math&gt;

There are an enormous number of other formulas involving orthogonal polynomials
in various ways.  Here is a tiny sample of them, relating to the Chebyshev,
associated Laguerre, and Hermite polynomials:

* &lt;math&gt;2\,T_{m}(x)\,T_{n}(x) = T_{m+n}(x) + T_{m-n}(x)&lt;/math&gt;
* &lt;math&gt;H_{2n}(x) = (-4)^{n}\,n!\,L_{n}^{(-1/2)}(x^2)&lt;/math&gt;
* &lt;math&gt;H_{2n+1}(x) = 2(-4)^{n}\,n!\,x\,L_{n}^{(1/2)}(x^2)&lt;/math&gt;

=== Orthogonality ===

The differential equation for a particular ''λ'' may be written (omitting explicit dependence on x)

:&lt;math&gt;Q\ddot{f}_n+L\dot{f}_n+\lambda_nf_n=0&lt;/math&gt;

multiplying by &lt;math&gt;(R/Q)f_m&lt;/math&gt; yields

:&lt;math&gt;Rf_m\ddot{f}_n+\frac{R}{Q}Lf_m\dot{f}_n+\frac{R}{Q}\lambda_nf_mf_n=0&lt;/math&gt;

and reversing the subscripts yields

:&lt;math&gt;Rf_n\ddot{f}_m+\frac{R}{Q}Lf_n\dot{f}_m+\frac{R}{Q}\lambda_mf_nf_m=0&lt;/math&gt;

subtracting and integrating:

:&lt;math&gt;
\int_a^b \left[R(f_m\ddot{f}_n-f_n\ddot{f}_m)+
\frac{R}{Q}L(f_m\dot{f}_n-f_n\dot{f}_m)\right] \, dx
+(\lambda_n-\lambda_m)\int_a^b \frac{R}{Q}f_mf_n \, dx = 0
&lt;/math&gt;

but it can be seen that

:&lt;math&gt;
\frac{d}{dx}\left[R(f_m\dot{f}_n-f_n\dot{f}_m)\right]=
R(f_m\ddot{f}_n-f_n\ddot{f}_m)\,\,+\,\,R\frac{L}{Q}(f_m\dot{f}_n-f_n\dot{f}_m)
&lt;/math&gt;

so that:

:&lt;math&gt;\left[R(f_m\dot{f}_n-f_n\dot{f}_m)\right]_a^b\,\,+\,\,(\lambda_n-\lambda_m)\int_a^b \frac{R}{Q}f_mf_n \, dx=0&lt;/math&gt;

If the polynomials ''f'' are such that the term on the left is zero, and &lt;math&gt;\lambda_m \ne \lambda_n&lt;/math&gt; for &lt;math&gt;m \ne n&lt;/math&gt;, then the orthogonality relationship will hold:

:&lt;math&gt;\int_a^b \frac{R}{Q}f_mf_n \, dx=0&lt;/math&gt;

for &lt;math&gt;m \ne n&lt;/math&gt;.

== Derivation from differential equation ==

All of the polynomial sequences arising from the differential equation above are equivalent, under scaling and/or shifting of the domain, and standardizing of the polynomials, to more restricted classes.  Those restricted classes are exactly "classical orthogonal polynomials".

* Every Jacobi-like polynomial sequence can have its domain shifted and/or scaled so that its interval of orthogonality is [&amp;minus;1,&amp;nbsp;1], and has ''Q'' = 1&amp;nbsp;&amp;minus;&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;.  They can then be standardized into the '''Jacobi polynomials''' &lt;math&gt;P_n^{(\alpha, \beta)}&lt;/math&gt;.  There are several important subclasses of these: '''Gegenbauer''', '''Legendre''', and two types of '''Chebyshev'''.
* Every Laguerre-like polynomial sequence can have its domain shifted, scaled, and/or reflected so that its interval of orthogonality is &lt;math&gt;[0, \infty)&lt;/math&gt;, and has ''Q'' = ''x''.  They can then be standardized into the '''Associated Laguerre polynomials''' &lt;math&gt;L_n^{(\alpha)}&lt;/math&gt;.  The plain '''Laguerre polynomials''' &lt;math&gt;\ L_n&lt;/math&gt; are a subclass of these.
* Every Hermite-like polynomial sequence can have its domain shifted and/or scaled so that its interval of orthogonality is &lt;math&gt;(-\infty, \infty)&lt;/math&gt;, and has Q = 1 and L(0) = 0.  They can then be standardized into the '''Hermite polynomials''' &lt;math&gt;H_n&lt;/math&gt;.

Because all polynomial sequences arising from a differential equation in the manner
described above are trivially equivalent to the classical polynomials, the actual classical
polynomials are always used.

=== Jacobi polynomial ===
The Jacobi-like polynomials, once they have had their domain shifted and scaled so that
the interval of orthogonality is [&amp;minus;1,&amp;nbsp;1], still have two parameters to be determined.
They are &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; in the Jacobi polynomials,
written &lt;math&gt;P_n^{(\alpha, \beta)}&lt;/math&gt;.  We have &lt;math&gt;Q(x) = 1-x^2&lt;/math&gt; and
&lt;math&gt;L(x) = \beta-\alpha-(\alpha+\beta+2)\, x&lt;/math&gt;.
Both &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; are required to be greater than &amp;minus;1.
(This puts the root of L inside the interval of orthogonality.)

When &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; are not equal, these polynomials
are not symmetrical about ''x'' = 0.

The differential equation

:&lt;math&gt;(1-x^2)\,y'' + (\beta-\alpha-[\alpha+\beta+2]\,x)\,y' + \lambda \,y = 0\qquad \text{with}\qquad\lambda = n(n+1+\alpha+\beta)&lt;/math&gt;

is '''Jacobi's equation'''.

For further details, see [[Jacobi polynomials]].

=== Gegenbauer polynomials ===
When one sets the parameters &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; in the Jacobi polynomials equal to each other, one obtains the '''Gegenbauer''' or '''ultraspherical''' polynomials.  They are written &lt;math&gt;C_n^{(\alpha)}&lt;/math&gt;, and defined as

:&lt;math&gt;C_n^{(\alpha)}(x) = \frac{\Gamma(2\alpha\!+\!n)\,\Gamma(\alpha\!+\!1/2)}{\Gamma(2\alpha) \,\Gamma(\alpha\!+\!n\!+\!1/2)}\! \  P_n^{(\alpha-1/2, \alpha-1/2)}(x).&lt;/math&gt;

We have &lt;math&gt;Q(x) = 1-x^2&lt;/math&gt; and
&lt;math&gt;L(x) = -(2\alpha+1)\, x&lt;/math&gt;.
The parameter &lt;math&gt;\alpha&lt;/math&gt; is required to be greater than&amp;nbsp;&amp;minus;1/2.

(Incidentally, the standardization given in the table below would make no sense for ''α'' = 0 and ''n'' ≠ 0, because it would set the polynomials to zero.  In that case, the accepted standardization sets &lt;math&gt;C_n^{(0)}(1) = \frac{2}{n}&lt;/math&gt; instead of the value given in the table.)

Ignoring the above considerations, the parameter &lt;math&gt;\alpha&lt;/math&gt; is closely related to the derivatives of &lt;math&gt;C_n^{(\alpha)}&lt;/math&gt;:

:&lt;math&gt;C_n^{(\alpha+1)}(x) = \frac{1}{2\alpha}\! \  \frac{d}{dx}C_{n+1}^{(\alpha)}(x)&lt;/math&gt;

or, more generally:

:&lt;math&gt;C_n^{(\alpha+m)}(x) = \frac{\Gamma(\alpha)}{2^m\Gamma(\alpha+m)}\! \  C_{n+m}^{(\alpha)[m]}(x).&lt;/math&gt;

All the other classical Jacobi-like polynomials (Legendre, etc.) are special cases of the Gegenbauer polynomials, obtained by choosing a value of &lt;math&gt;\alpha&lt;/math&gt; and choosing a standardization.

For further details, see [[Gegenbauer polynomials]].

=== Legendre polynomials ===
The differential equation is

:&lt;math&gt;(1-x^2)\,y'' - 2x\,y' + \lambda \,y = 0\qquad \text{with}\qquad\lambda = n(n+1).&lt;/math&gt;

This is '''Legendre's equation'''.

The second form of the differential equation is:

:&lt;math&gt;\frac{d}{dx}[(1-x^2)\,y'] + \lambda\,y = 0.&lt;/math&gt;

The [[recurrence relation]] is

:&lt;math&gt;(n+1)\,P_{n+1}(x) = (2n+1)x\,P_n(x) - n\,P_{n-1}(x).&lt;/math&gt;

A mixed recurrence is

:&lt;math&gt;P_{n+1}^{[r+1]}(x) = P_{n-1}^{[r+1]}(x) + (2n+1)\,P_n^{[r]}(x).&lt;/math&gt;

Rodrigues' formula is

:&lt;math&gt;P_n(x) = \,\frac{1}{2^n n!} \  \frac{d^n}{dx^n}\left([x^2-1]^n\right).&lt;/math&gt;

For further details, see [[Legendre polynomials]].

==== Associated Legendre polynomials ====
The [[Associated Legendre polynomials]], denoted
&lt;math&gt;P_\ell^{(m)}(x)&lt;/math&gt; where &lt;math&gt;\ell&lt;/math&gt; and &lt;math&gt;m&lt;/math&gt; are integers with &lt;math&gt;0 \leqslant m  \leqslant \ell&lt;/math&gt;, are defined as

:&lt;math&gt;P_\ell^{(m)}(x) = (-1)^m\,(1-x^2)^{m/2}\ P_\ell^{[m]}(x).&lt;/math&gt;

The ''m'' in parentheses (to avoid confusion with an exponent) is a parameter.  The ''m'' in brackets denotes the ''m''-th derivative of the Legendre polynomial.

These "polynomials" are misnamed—they are not polynomials when ''m'' is odd.

They have a recurrence relation:

:&lt;math&gt;(\ell+1-m)\,P_{\ell+1}^{(m)}(x) = (2\ell+1)x\,P_\ell^{(m)}(x) - (\ell+m)\,P_{\ell-1}^{(m)}(x).&lt;/math&gt;

For fixed ''m'', the sequence &lt;math&gt;P_m^{(m)}, P_{m+1}^{(m)}, P_{m+2}^{(m)}, \dots&lt;/math&gt; are orthogonal over [&amp;minus;1,&amp;nbsp;1], with weight&amp;nbsp;1.

For given ''m'', &lt;math&gt;P_\ell^{(m)}(x)&lt;/math&gt; are the solutions of

:&lt;math&gt;(1-x^2)\,y'' -2xy' + \left[\lambda - \frac{m^2}{1-x^2}\right]\,y = 0\qquad \text{ with }\qquad\lambda = \ell(\ell+1).&lt;/math&gt;

=== Chebyshev polynomials ===
The differential equation is

:&lt;math&gt;(1-x^2)\,y'' - x\,y' + \lambda \,y = 0\qquad \text{with}\qquad\lambda = n^2.&lt;/math&gt;

This is '''[[Chebyshev equation|Chebyshev's equation]]'''.

The recurrence relation is

:&lt;math&gt;T_{n+1}(x) = 2x\,T_n(x) - T_{n-1}(x).&lt;/math&gt;

Rodrigues' formula is

:&lt;math&gt;T_n(x) = \frac{\Gamma(1/2)\sqrt{1-x^2}}{(-2)^n\,\Gamma(n+1/2)} \  \frac{d^n}{dx^n}\left([1-x^2]^{n-1/2}\right).&lt;/math&gt;

These polynomials have the property that, in the interval of orthogonality,

:&lt;math&gt;T_n(x) = \cos(n\,\arccos(x)).&lt;/math&gt;

(To prove it, use the recurrence formula.)

This means that all their local minima and maxima have values of &amp;minus;1 and +1, that is, the polynomials are "level".  Because of this, expansion of functions in terms of Chebyshev polynomials is sometimes used for [[approximation theory|polynomial approximations]] in computer math libraries.

Some authors use versions of these polynomials that have been shifted so that the interval of orthogonality is [0,&amp;nbsp;1] or [&amp;minus;2,&amp;nbsp;2].

There are also '''Chebyshev polynomials of the second kind''', denoted &lt;math&gt;U_n&lt;/math&gt;

We have:

:&lt;math&gt;U_n = \frac{1}{n+1}\,T_{n+1}'.&lt;/math&gt;

For further details, including the expressions for the first few
polynomials, see [[Chebyshev polynomials]].

=== Laguerre polynomials ===
The most general Laguerre-like polynomials, after the domain has been shifted and scaled, are the Associated Laguerre polynomials (also called generalized Laguerre polynomials), denoted &lt;math&gt;L_n^{(\alpha)}&lt;/math&gt;.  There is a parameter &lt;math&gt;\alpha&lt;/math&gt;, which can be any real number strictly greater than &amp;minus;1.  The parameter is put in parentheses to avoid confusion with an exponent.  The plain Laguerre polynomials are simply the &lt;math&gt;\alpha = 0&lt;/math&gt; version of these:

:&lt;math&gt;L_n(x) = L_n^{(0)}(x).&lt;/math&gt;

The differential equation is

:&lt;math&gt;x\,y'' + (\alpha + 1-x)\,y' + \lambda \,y = 0\text{ with }\lambda = n.&lt;/math&gt;

This is '''Laguerre's equation'''.

The second form of the differential equation is

:&lt;math&gt;(x^{\alpha+1}\,e^{-x}\, y')' + \lambda \,x^\alpha \,e^{-x}\,y = 0.&lt;/math&gt;

The recurrence relation is

:&lt;math&gt;(n+1)\,L_{n+1}^{(\alpha)}(x) = (2n+1+\alpha-x)\,L_n^{(\alpha)}(x) - (n+\alpha)\,L_{n-1}^{(\alpha)}(x).&lt;/math&gt;

Rodrigues' formula is

:&lt;math&gt;L_n^{(\alpha)}(x) = \frac{x^{-\alpha}e^x}{n!} \  \frac{d^n}{dx^n}\left(x^{n+\alpha}\,e^{-x}\right).&lt;/math&gt;

The parameter &lt;math&gt;\alpha&lt;/math&gt; is closely related to the derivatives of &lt;math&gt;L_n^{(\alpha)}&lt;/math&gt;:

:&lt;math&gt;L_n^{(\alpha+1)}(x) = - \frac{d}{dx}L_{n+1}^{(\alpha)}(x)&lt;/math&gt;

or, more generally:

:&lt;math&gt;L_n^{(\alpha+m)}(x) = (-1)^m L_{n+m}^{(\alpha)[m]}(x).&lt;/math&gt;

Laguerre's equation can be manipulated into a form that is more useful in applications:

:&lt;math&gt;u = x^{\frac{\alpha-1}{2}}e^{-x/2}L_n^{(\alpha)}(x)&lt;/math&gt;

is a solution of

:&lt;math&gt;u'' + \frac{2}{x}\,u' + \left[\frac \lambda x - \frac{1}{4} - \frac{\alpha^2-1}{4x^2}\right]\,u = 0\text{ with } \lambda = n+\frac{\alpha+1}{2}. &lt;/math&gt;

This can be further manipulated.  When &lt;math&gt;\ell = \frac{\alpha-1}{2}&lt;/math&gt; is an integer, and &lt;math&gt;n \ge \ell+1&lt;/math&gt;:

:&lt;math&gt;u = x^\ell e^{-x/2} L_{n-\ell-1}^{(2\ell+1)}(x)&lt;/math&gt;

is a solution of

:&lt;math&gt;u'' + \frac{2}{x}\,u' + \left[\frac \lambda x - \frac{1}{4} - \frac{\ell(\ell+1)}{x^2}\right]\,u = 0\text{ with }\lambda = n.&lt;/math&gt;

The solution is often expressed in terms of derivatives instead of associated Laguerre polynomials:

:&lt;math&gt;u = x^{\ell}e^{-x/2}L_{n+\ell}^{[2\ell+1]}(x).&lt;/math&gt;

This equation arises in quantum mechanics, in the radial part of the solution of the [[Schrödinger equation]] for a one-electron atom.

Physicists often use a definition for the Laguerre polynomials that is larger, by a factor of &lt;math&gt;(n!)&lt;/math&gt;, than the definition used here.

For further details, including the expressions for the first few polynomials, see [[Laguerre polynomials]].

=== Hermite polynomials ===

The differential equation is

:&lt;math&gt;y'' - 2xy' + \lambda \,y = 0,\qquad \text{with}\qquad\lambda = 2n.&lt;/math&gt;

This is '''Hermite's equation'''.

The second form of the differential equation is

:&lt;math&gt;(e^{-x^2}\,y')' + e^{-x^2}\,\lambda\,y = 0.&lt;/math&gt;

The third form is

:&lt;math&gt;(e^{-x^2/2}\,y)'' + (\lambda +1-x^2)(e^{-x^2/2}\,y) = 0.&lt;/math&gt;

The recurrence relation is

:&lt;math&gt;H_{n+1}(x) = 2x\,H_n(x) - 2n\,H_{n-1}(x).&lt;/math&gt;

Rodrigues' formula is

:&lt;math&gt;H_n(x) = (-1)^n\,e^{x^2} \  \frac{d^n}{dx^n}\left(e^{-x^2}\right).&lt;/math&gt;

The first few Hermite polynomials are

:&lt;math&gt;H_0(x) = 1&lt;/math&gt;

:&lt;math&gt;H_1(x) = 2x&lt;/math&gt;

:&lt;math&gt;H_2(x) = 4x^2-2&lt;/math&gt;

:&lt;math&gt;H_3(x) = 8x^3-12x&lt;/math&gt;

:&lt;math&gt;H_4(x) = 16x^4-48x^2+12&lt;/math&gt;

One can define the '''associated Hermite functions'''

: &lt;math&gt; \psi_n(x) = (h_n)^{-1/2}\,e^{-x^2/2}H_n(x).&lt;/math&gt;

Because the multiplier is proportional to the square root of the weight function, these functions
are orthogonal over &lt;math&gt;(-\infty, \infty)&lt;/math&gt; with no weight function.

The third form of the differential equation above, for the associated Hermite functions, is

:&lt;math&gt;\psi'' + (\lambda +1-x^2)\psi = 0.&lt;/math&gt;

The associated Hermite functions arise in many areas of mathematics and physics.
In quantum mechanics, they are the solutions of Schrödinger's equation for the harmonic oscillator.
They are also eigenfunctions (with eigenvalue (&amp;minus;''i'')&lt;sup&gt;''n''&lt;/sup&gt;) of the [[continuous Fourier transform]].

Many authors, particularly probabilists, use an alternate definition of the Hermite polynomials, with a weight function of &lt;math&gt;e^{-x^2/2}&lt;/math&gt; instead of &lt;math&gt;e^{-x^2}&lt;/math&gt;.  If the notation ''He'' is used for these Hermite polynomials, and ''H'' for those above, then these may be characterized by

:&lt;math&gt;He_n(x) = 2^{-n/2}\,H_n\left(\frac{x}{\sqrt{2}}\right).&lt;/math&gt;

For further details, see [[Hermite polynomials]].

==Characterizations of classical orthogonal polynomials==

There are several conditions that single out the classical orthogonal polynomials from the others.

The first condition was found by Sonine (and later by Hahn), who showed that (up to linear changes of variable) the classical orthogonal polynomials are the only ones such that their derivatives are also orthogonal polynomials.

Bochner characterized classical orthogonal polynomials in terms of their recurrence relations.

Tricomi characterized classical orthogonal polynomials as those that have a certain analogue of the [[Rodrigues formula]].

== Table of classical orthogonal polynomials ==

The following table summarises the properties of the classical orthogonal polynomials.&lt;ref&gt;See {{harvtxt|Abramowitz|Stegun|1965}}&lt;/ref&gt;

&lt;center&gt;

{| border="1" cellspacing="0" cellpadding="5"
|-----
! Name, and conventional symbol
! [[Chebyshev polynomials|Chebyshev]], &lt;math&gt;\ T_n&lt;/math&gt;
! [[Chebyshev polynomials|Chebyshev]]&lt;br&gt;(second kind), &lt;math&gt;\ U_n&lt;/math&gt;
! [[Legendre polynomials|Legendre]], &lt;math&gt;\ P_n&lt;/math&gt;
! [[Hermite polynomials|Hermite]], &lt;math&gt;\ H_n&lt;/math&gt;
|-----
| Limits of orthogonality&lt;ref&gt;i.e. the edges of the support of the weight ''W''.&lt;/ref&gt;
| &lt;math&gt;-1, 1&lt;/math&gt;
| &lt;math&gt;-1, 1&lt;/math&gt;
| &lt;math&gt;-1, 1&lt;/math&gt; 
| &lt;math&gt;-\infty, \infty&lt;/math&gt;
|-----
| Weight, &lt;math&gt;W(x)&lt;/math&gt; 
| &lt;math&gt;(1-x^2)^{-1/2}&lt;/math&gt;
| &lt;math&gt;(1-x^2)^{1/2}&lt;/math&gt;
| &lt;math&gt;1&lt;/math&gt; 
| &lt;math&gt;e^{-x^2}&lt;/math&gt;
|-----
| Standardization 
| &lt;math&gt;T_n(1)=1&lt;/math&gt;
| &lt;math&gt;U_n(1)=n+1&lt;/math&gt;
| &lt;math&gt;P_n(1)=1&lt;/math&gt; 
| Lead term &lt;math&gt;=2^n&lt;/math&gt;
|-----
| Square of norm &lt;ref&gt;&lt;math&gt;h_n = \int P_n^2(x) W(x) \, dx&lt;/math&gt;&lt;/ref&gt;
| &lt;math&gt;\left\{
\begin{matrix}
\pi   &amp;:~n=0 \\
\pi/2 &amp;:~n\ne 0
\end{matrix}\right.
&lt;/math&gt;
| &lt;math&gt;\pi/2&lt;/math&gt; 
| &lt;math&gt;\frac{2}{2n+1}&lt;/math&gt;
| &lt;math&gt;2^n\,n!\,\sqrt{\pi}&lt;/math&gt;
|-----
| Leading term &lt;ref&gt;The leading coefficient ''k''&lt;sub&gt;''n''&lt;/sub&gt; of &lt;math&gt; P_n(x) = k_n x^n + k'_n x^{n-1} + \cdots + k^{(n)} &lt;/math&gt;&lt;/ref&gt;
| &lt;math&gt;2^{n-1}&lt;/math&gt;
| &lt;math&gt;2^n&lt;/math&gt;
| &lt;math&gt;\frac{(2n)!}{2^n\,(n!)^2}&lt;/math&gt;
| &lt;math&gt;2^n&lt;/math&gt;
|-----
| Second term, &lt;math&gt;k'_n&lt;/math&gt; 
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt; 
| &lt;math&gt;0&lt;/math&gt;
|-----
| &lt;math&gt;Q&lt;/math&gt; 
| &lt;math&gt;1-x^2&lt;/math&gt;
| &lt;math&gt;1-x^2&lt;/math&gt;
| &lt;math&gt;1-x^2&lt;/math&gt; 
| &lt;math&gt;1&lt;/math&gt;
|-----
| &lt;math&gt;L&lt;/math&gt; 
| &lt;math&gt;-x&lt;/math&gt;
| &lt;math&gt;-3x&lt;/math&gt;
| &lt;math&gt;-2x&lt;/math&gt; 
| &lt;math&gt;-2x&lt;/math&gt;
|-----
| &lt;math&gt;R(x) =e^{\int \frac{L(x)}{Q(x)}\,dx}&lt;/math&gt;
| &lt;math&gt;(1-x^2)^{1/2}&lt;/math&gt; 
| &lt;math&gt;(1-x^2)^{3/2}&lt;/math&gt;
| &lt;math&gt;1-x^2&lt;/math&gt; 
| &lt;math&gt;e^{-x^2}&lt;/math&gt;
|-----
| Constant in diff. equation, &lt;math&gt;\lambda_n&lt;/math&gt;
| &lt;math&gt;n^2&lt;/math&gt; 
| &lt;math&gt;n(n+2)&lt;/math&gt;
| &lt;math&gt;n(n+1)&lt;/math&gt; 
| &lt;math&gt;2n&lt;/math&gt;
|-----
| Constant in Rodrigues' formula, &lt;math&gt;e_n&lt;/math&gt;
| &lt;math&gt;(-2)^n\,\frac{\Gamma(n+1/2)}{\sqrt{\pi}}&lt;/math&gt;
| &lt;math&gt;2(-2)^n\,\frac{\Gamma(n+3/2)}{(n+1)\,\sqrt{\pi}}&lt;/math&gt;
| &lt;math&gt;(-2)^n\,n!&lt;/math&gt; 
| &lt;math&gt;(-1)^n&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;a_n&lt;/math&gt;
| &lt;math&gt;2&lt;/math&gt; 
| &lt;math&gt;2&lt;/math&gt;
| &lt;math&gt;\frac{2n+1}{n+1}&lt;/math&gt; 
| &lt;math&gt;2&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;b_n&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt; 
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt; 
| &lt;math&gt;0&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;c_n&lt;/math&gt;
| &lt;math&gt;1&lt;/math&gt; 
| &lt;math&gt;1&lt;/math&gt;
| &lt;math&gt;\frac{n}{n+1}&lt;/math&gt; 
| &lt;math&gt;2n&lt;/math&gt;
|}
&lt;/center&gt;

&lt;center&gt;

{| border="1" cellspacing="0" cellpadding="5"
|-----
! Name, and conventional symbol
! [[Laguerre polynomials|Associated Laguerre]], &lt;math&gt;L_n^{(\alpha)}&lt;/math&gt;
! [[Laguerre polynomials|Laguerre]], &lt;math&gt;\ L_n&lt;/math&gt;
|-----
| Limits of orthogonality 
| &lt;math&gt;0, \infty&lt;/math&gt;
| &lt;math&gt;0, \infty&lt;/math&gt;
|-----
| Weight, &lt;math&gt;W(x)&lt;/math&gt; 
| &lt;math&gt;x^{\alpha}e^{-x}&lt;/math&gt;
| &lt;math&gt;e^{-x}&lt;/math&gt;
|-----
| Standardization
| Lead term &lt;math&gt;=\frac{(-1)^n}{n!}&lt;/math&gt;
| Lead term &lt;math&gt;=\frac{(-1)^n}{n!}&lt;/math&gt;
|-----
| Square of norm, &lt;math&gt;h_n&lt;/math&gt;
| &lt;math&gt;\frac{\Gamma(n+\alpha+1)}{n!}&lt;/math&gt;
| &lt;math&gt;1&lt;/math&gt;
|-----
| Leading term, &lt;math&gt;k_n&lt;/math&gt; 
| &lt;math&gt;\frac{(-1)^n}{n!}&lt;/math&gt;
| &lt;math&gt;\frac{(-1)^n}{n!}&lt;/math&gt;
|-----
| Second term, &lt;math&gt;k'_n&lt;/math&gt;
| &lt;math&gt;\frac{(-1)^{n+1}(n+\alpha)}{(n-1)!}&lt;/math&gt;
| &lt;math&gt;\frac{(-1)^{n+1}n}{(n-1)!}&lt;/math&gt;
|-----
| &lt;math&gt;Q&lt;/math&gt; 
| &lt;math&gt;x&lt;/math&gt;
| &lt;math&gt;x&lt;/math&gt;
|-----
| &lt;math&gt;L&lt;/math&gt; 
| &lt;math&gt;\alpha+1-x&lt;/math&gt;
| &lt;math&gt;1-x&lt;/math&gt;
|-----
| &lt;math&gt;R(x) =e^{\int \frac{L(x)}{Q(x)}\,dx}&lt;/math&gt;
| &lt;math&gt;x^{\alpha+1}\,e^{-x}&lt;/math&gt; 
| &lt;math&gt;x\,e^{-x}&lt;/math&gt;
|-----
| Constant in diff. equation, &lt;math&gt;\lambda_n&lt;/math&gt;
| &lt;math&gt;n&lt;/math&gt; 
| &lt;math&gt;n&lt;/math&gt;
|-----
| Constant in Rodrigues' formula, &lt;math&gt;e_n&lt;/math&gt;
| &lt;math&gt;n!&lt;/math&gt; 
| &lt;math&gt;n!&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;a_n&lt;/math&gt;
| &lt;math&gt;\frac{-1}{n+1}&lt;/math&gt; 
| &lt;math&gt;\frac{-1}{n+1}&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;b_n&lt;/math&gt;
| &lt;math&gt;\frac{2n+1+\alpha}{n+1}&lt;/math&gt;
| &lt;math&gt;\frac{2n+1}{n+1}&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;c_n&lt;/math&gt;
| &lt;math&gt;\frac{n+\alpha}{n+1}&lt;/math&gt; 
| &lt;math&gt;\frac{n}{n+1}&lt;/math&gt;
|}
&lt;/center&gt;

&lt;center&gt;

{| border="1" cellspacing="0" cellpadding="5"
|-----
! Name, and conventional symbol
! [[Gegenbauer polynomials|Gegenbauer]], &lt;math&gt;C_n^{(\alpha)}&lt;/math&gt;
! [[Jacobi polynomials|Jacobi]], &lt;math&gt;P_n^{(\alpha, \beta)}&lt;/math&gt;
|-----
| Limits of orthogonality 
| &lt;math&gt;-1, 1&lt;/math&gt;
| &lt;math&gt;-1, 1&lt;/math&gt;
|-----
| Weight, &lt;math&gt;W(x)&lt;/math&gt; 
| &lt;math&gt;(1-x^2)^{\alpha-1/2}&lt;/math&gt;
| &lt;math&gt;(1-x)^\alpha(1+x)^\beta&lt;/math&gt;
|-----
| Standardization
| &lt;math&gt;C_n^{(\alpha)}(1)=\frac{\Gamma(n+2\alpha)}{n!\,\Gamma(2\alpha)}&lt;/math&gt; if &lt;math&gt;\alpha\ne0&lt;/math&gt;
| &lt;math&gt;P_n^{(\alpha, \beta)}(1)=\frac{\Gamma(n+1+\alpha)}{n!\,\Gamma(1+\alpha)}&lt;/math&gt;
|-----
| Square of norm, &lt;math&gt;h_n&lt;/math&gt;
| &lt;math&gt;\frac{\pi\,2^{1-2\alpha}\Gamma(n+2\alpha)}{n!(n+\alpha)(\Gamma(\alpha))^2}&lt;/math&gt;
| &lt;math&gt;\frac{2^{\alpha+\beta+1}\,\Gamma(n\!+\!\alpha\!+\!1)\,\Gamma(n\!+\!\beta\!+\!1)}
{n!(2n\!+\!\alpha\!+\!\beta\!+\!1)\Gamma(n\!+\!\alpha\!+\!\beta\!+\!1)}&lt;/math&gt;
|-----
| Leading term, &lt;math&gt;k_n&lt;/math&gt;
| &lt;math&gt;\frac{\Gamma(2n+2\alpha)\Gamma(1/2+\alpha)}{n!\,2^n\,\Gamma(2\alpha)\Gamma(n+1/2+\alpha)}&lt;/math&gt;
| &lt;math&gt;\frac{\Gamma(2n+1+\alpha+\beta)}{n!\,2^n\,\Gamma(n+1+\alpha+\beta)}&lt;/math&gt;
|-----
| Second term, &lt;math&gt;k'_n&lt;/math&gt; 
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;\frac{(\alpha-\beta)\,\Gamma(2n+\alpha+\beta)}{(n-1)!\,2^n\,\Gamma(n+1+\alpha+\beta)}&lt;/math&gt;
|-----
| &lt;math&gt;Q&lt;/math&gt; 
| &lt;math&gt;1-x^2&lt;/math&gt;
| &lt;math&gt;1-x^2&lt;/math&gt;
|-----
| &lt;math&gt;L&lt;/math&gt; 
| &lt;math&gt;-(2\alpha+1)\,x&lt;/math&gt;
| &lt;math&gt;\beta-\alpha-(\alpha+\beta+2)\,x&lt;/math&gt;
|-----
| &lt;math&gt;R(x) =e^{\int \frac{L(x)}{Q(x)}\,dx}&lt;/math&gt;
| &lt;math&gt;(1-x^2)^{\alpha+1/2}&lt;/math&gt;
| &lt;math&gt;(1-x)^{\alpha+1}(1+x)^{\beta+1}&lt;/math&gt;
|-----
| Constant in diff. equation, &lt;math&gt;\lambda_n&lt;/math&gt;
| &lt;math&gt;n(n+2\alpha)&lt;/math&gt; 
| &lt;math&gt;n(n+1+\alpha+\beta)&lt;/math&gt;
|-----
| Constant in Rodrigues' formula, &lt;math&gt;e_n&lt;/math&gt;
| &lt;math&gt;\frac{(-2)^n\,n!\,\Gamma(2\alpha)\,\Gamma(n\!+\!1/2\!+\!\alpha)}
{\Gamma(n\!+\!2\alpha)\Gamma(\alpha\!+\!1/2)}&lt;/math&gt;
| &lt;math&gt;(-2)^n\,n!&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;a_n&lt;/math&gt;
| &lt;math&gt;\frac{2(n+\alpha)}{n+1}&lt;/math&gt;
| &lt;math&gt;\frac{(2n+1+\alpha+\beta)(2n+2+\alpha+\beta)}{2(n+1)(n+1+\alpha+\beta)}&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;b_n&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;\frac{({\alpha}^2-{\beta}^2)(2n+1+\alpha+\beta)}{2(n+1)(2n+\alpha+\beta)(n+1+\alpha+\beta)}&lt;/math&gt;
|-----
| Recurrence relation, &lt;math&gt;c_n&lt;/math&gt;
| &lt;math&gt;\frac{n+2{\alpha}-1}{n+1}&lt;/math&gt;
| &lt;math&gt;\frac{(n+\alpha)(n+\beta)(2n+2+\alpha+\beta)}{(n+1)(n+1+\alpha+\beta)(2n+\alpha+\beta)}&lt;/math&gt;
|}
&lt;/center&gt;

== See also ==

* [[Appell sequence]]
* [[Askey scheme]] of hypergeometric orthogonal polynomials
* [[Binomial type|Polynomial sequences of binomial type]]
* [[Biorthogonal polynomials]]
* [[Generalized Fourier series]]
* [[Secondary measure]]
* [[Sheffer sequence]]
* [[Umbral calculus]]

==Notes==
{{Reflist}}

== References ==

* {{Abramowitz_Stegun_ref|22|773}}
*{{Cite book | last1=Andrews | first1=George E. | last2=Askey | first2=Richard | editor1-last=Brezinski | editor1-first=C. | editor2-last=Draux | editor2-first=A. | editor3-last=Magnus | editor3-first=Alphonse P. | editor4-last=Maroni | editor4-first=Pascal | editor5-last=Ronveaux | editor5-first=A. | title=Polynômes orthogonaux et applications.  Proceedings of the Laguerre symposium held at Bar-le-Duc, October 15–18, 1984.  | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Math. | isbn=978-3-540-16059-5  | mr=838970 | year=1985 | volume=1171 | chapter=Classical orthogonal polynomials | doi=10.1007/BFb0076530 | pages=36–62 | ref=harv | postscript=.}}
* {{cite book | first=Theodore Seio|last= Chihara | title= An Introduction to Orthogonal Polynomials | publisher= Gordon and Breach, New York | year=1978 | isbn = 0-677-04150-0|ref=harv}}
*{{Cite journal | last1=Foncannon | first1=J. J. | title=Review of ''Classical and quantum orthogonal polynomials in one variable'' by Mourad Ismail | publisher=Springer New York | doi=10.1007/BF02985757 | year=2008 | journal=[[The Mathematical Intelligencer]] | issn=0343-6993 | volume=30 | pages=54–60 | last2=Foncannon | first2=J. J. | last3=Pekonen | first3=Osmo | ref=harv | postscript=.}}
*{{cite book | last=Ismail|first=Mourad E. H. | title=Classical and Quantum Orthogonal Polynomials in One Variable | year=2005 | isbn=0-521-78201-5 | url = http://www.cambridge.org/us/catalogue/catalogue.asp?isbn=9780521782012 | publisher=Cambridge Univ. Press | location=Cambridge|ref=harv}}
* {{cite book | first=Dunham |last=Jackson | title= Fourier Series and Orthogonal Polynomials | location= New York | publisher=Dover | origyear=1941|year= 2004 | isbn = 0-486-43808-2|ref=harv}}
*{{dlmf|id=18|title=Orthogonal Polynomials|first=Tom H. |last=Koornwinder|first2=Roderick S. C.|last2= Wong|first3=Roelof |last3=Koekoek||first4=René F. |last4=Swarttouw}}
*{{eom|id=Classical_orthogonal_polynomials|first=P. K.|last=Suetin}}
*{{Cite book | last1=Szegő | first1=Gábor | title=Orthogonal Polynomials | url=https://books.google.com/books?id=3hcW8HBh7gsC | publisher= American Mathematical Society | series=Colloquium Publications | isbn=978-0-8218-1023-1 | mr=0372517 | year=1939 | volume=XXIII | postscript=.|ref=harv}}

[[Category:Articles containing proofs]]
[[Category:Orthogonal polynomials]]
[[Category:Special hypergeometric functions]]

[[zh:正交多項式]]</text>
      <sha1>1dscaw70tpt2fx67go4fi7cbat3p6bq</sha1>
    </revision>
  </page>
  <page>
    <title>Complete set of invariants</title>
    <ns>0</ns>
    <id>9903220</id>
    <revision>
      <id>830957109</id>
      <parentid>790698029</parentid>
      <timestamp>2018-03-17T22:43:03Z</timestamp>
      <contributor>
        <username>Rich Farmbrough</username>
        <id>82835</id>
      </contributor>
      <minor/>
      <comment>/* top */Spell out American postal abbreviations (Florida) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2329">In [[mathematics]], a complete set of [[Invariant (mathematics)|invariant]]s for a [[classification theorems|classification problem]] is a collection of maps
:&lt;math&gt;f_i : X \to Y_i &lt;/math&gt;
(where ''X'' is the collection of objects being classified, up to some equivalence relation, and the &lt;math&gt;Y_i&lt;/math&gt; are some sets), such that &lt;math&gt;x \sim x'&lt;/math&gt; if and only if &lt;math&gt;f_i(x) = f_i(x')&lt;/math&gt; for all ''i''. In words, such that two objects are equivalent if and only if all invariants are equal.&lt;ref&gt;{{citation
 | last = Faticoni | first = Theodore G.
 | contribution = Modules and point set topological spaces
 | doi = 10.1201/9781420010763.ch10
 | mr = 2229105
 | pages = 87–105
 | publisher = Chapman &amp; Hall/CRC, Boca Raton, Florida
 | series = Lect. Notes Pure Appl. Math.
 | title = Abelian groups, rings, modules, and homological algebra
 | volume = 249
 | year = 2006}}. See in particular [https://books.google.com/books?id=VOlZoLXQ92kC&amp;pg=PA97 p.&amp;nbsp;97].&lt;/ref&gt;

Symbolically, a complete set of invariants is a collection of maps such that
:&lt;math&gt;\prod f_i : (X/\sim) \to \prod Y_i&lt;/math&gt;
is [[injective]].

As invariants are, by definition, equal on equivalent objects, equality of invariants is a ''necessary'' condition for equivalence; a ''complete'' set of invariants is a set such that equality of these is ''sufficient'' for equivalence. In the context of a group action, this may be stated as: invariants are functions of [[coinvariant]]s (equivalence classes, orbits), and a complete set of invariants characterizes the coinvariants (is a set of defining equations for the coinvariants).

==Examples==
* In the [[classification of two-dimensional closed manifolds]], [[Euler characteristic]] (or [[Genus (mathematics)|genus]]) and [[orientability]] are a complete set of invariants.
* [[Jordan normal form]] of a matrix is a complete invariant for matrices up to conjugation, but [[eigenvalue]]s (with multiplicities) are not.

==Realizability of invariants==
A complete set of invariants does not immediately yield a [[classification theorem]]: not all combinations of invariants may be realized. Symbolically, one must also determine the image of
:&lt;math&gt;\prod f_i : X \to \prod Y_i.&lt;/math&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Complete Set Of Invariants}}
[[Category:Mathematical terminology]]</text>
      <sha1>eipkcuubw4b8602o3y3vcg53ip343y1</sha1>
    </revision>
  </page>
  <page>
    <title>Decimal128 floating-point format</title>
    <ns>0</ns>
    <id>23558705</id>
    <revision>
      <id>855595837</id>
      <parentid>852197739</parentid>
      <timestamp>2018-08-19T13:17:10Z</timestamp>
      <contributor>
        <username>Graeme Bartlett</username>
        <id>38427</id>
      </contributor>
      <minor/>
      <comment>marking structured text with code</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11707">{{lowercase}}
{{floating-point}}
In [[computing]], '''decimal128''' is a [[decimal floating-point]] [[computer numbering format]] that occupies 16 bytes (128 bits) in computer memory.
It is intended for applications where it is necessary to emulate decimal rounding exactly, such as financial and tax computations.

Decimal128 supports 34 [[decimal digit]]s of [[significand]] and  an [[exponent]] range of −6143 to +6144, i.e. {{gaps|±0.000|000|000|000|000|000|000|000|000|000|000|e=-6143}} to {{gaps|±9.999|999|999|999|999|999|999|999|999|999|999|e=6144}}.  (Equivalently, {{gaps|±0|000|000|000|000|000|000|000|000|000|000|000|e=-6176}} to {{gaps|±9|999|999|999|999|999|999|999|999|999|999|999|e=6111}}.) Therefore, decimal128 has the greatest range of values compared with other IEEE basic floating point formats. Because the significand is not normalized, most values with less than 34 [[significant digits]] have multiple possible representations; {{gaps|1×10&lt;sup&gt;2&lt;/sup&gt;|&amp;#61;|0.1×10&lt;sup&gt;3&lt;/sup&gt;|&amp;#61;|0.01×10&lt;sup&gt;4&lt;/sup&gt;}}, etc.  Zero has {{gaps|12|288}} possible representations ({{gaps|24|576}} if you include both [[signed zero]]s).

Decimal128 floating point is a relatively new decimal floating-point format, formally introduced in the [[IEEE 754-2008|2008 version]]&lt;ref name="IEEE-754_2008"&gt;{{cite journal |title=IEEE Standard for Floating-Point Arithmetic |author=IEEE Computer Society |date=2008-08-29 |publisher=[[IEEE]] |id=IEEE Std 754-2008 |doi=10.1109/IEEESTD.2008.4610935 |ref=CITEREFIEEE_7542008 |isbn=978-0-7381-5753-5 |url=http://ieeexplore.ieee.org/servlet/opac?punumber=4610933 |access-date=2016-02-08}}&lt;/ref&gt; of [[IEEE 754]] as well as with [[ISO/IEC/IEEE 60559:2011]].&lt;ref name="ISO-60559_2011"&gt;{{cite journal |title=ISO/IEC/IEEE 60559:2011 |url=http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=57469 |date=2011 |access-date=2016-02-08}}&lt;/ref&gt;

== Representation of decimal128 values ==

{| class="wikitable"
|-
! Sign !! Combination !! Significand continuation
|-
! 1 bit !! 17 bits !! 110 bits
|-
| s || mmmmmmmmmmmmmmmmm || cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc
|}

[[IEEE 754]] allows two alternative representation methods for decimal128 values.
The standard does not specify how to signify which representation is used,
for instance in a situation where decimal128 values are communicated between systems.

In one representation method, based on [[binary integer decimal]] (BID),
the significand is represented as binary coded positive integer.

The other, alternative, representation method is based on
[[densely packed decimal]] (DPD) for most of the
significand (except the most significant digit).

Both alternatives provide exactly the same range of representable numbers: 34 digits of significand and 3×2&lt;sup&gt;12&lt;/sup&gt; = {{gaps|12|288}} possible exponent values.

In both cases, the most significant 4 bits of the significand (which actually only have 10 possible values) are combined with the most significant 2 bits of the exponent (3 possible values) to use 30 of the 32 possible values of 5 bits in the combination field.  The remaining combinations encode [[infinity|infinities]] and [[NaN]]s.

{| class="wikitable"
|-
! Combination field !! Exponent !! Significand Msbits !! Other
|-
| 00mmmmmmmmmmmmmmm || 00xxxxxxxxxxxx || 0ccc || —
|-
| 01mmmmmmmmmmmmmmm || 01xxxxxxxxxxxx || 0ccc || —
|-
| 10mmmmmmmmmmmmmmm || 10xxxxxxxxxxxx || 0ccc || —
|-
| 1100mmmmmmmmmmmmm || 00xxxxxxxxxxxx || 100c || —
|-
| 1101mmmmmmmmmmmmm || 01xxxxxxxxxxxx || 100c || —
|-
| 1110mmmmmmmmmmmmm || 10xxxxxxxxxxxx || 100c || —
|-
| 11110mmmmmmmmmmmm || — || — || ±Infinity
|-
| 11111mmmmmmmmmmmm || — || — || NaN. Sign bit ignored. Sixth bit of the combination field determines if the NaN is signaling.
|}

In the case of Infinity and NaN, all other bits of the encoding are ignored.  Thus, it is possible to initialize an array to Infinities or NaNs by filling it with a single byte value.

=== Binary integer significand field ===
This format uses a binary significand from 0 to 10&lt;sup&gt;34&lt;/sup&gt;−1 = {{gaps|9|999|999|999|999|999|999|999|999|999|999|999}} = 1ED09BEAD87C0378D8E63FFFFFFFF&lt;sub&gt;16&lt;/sub&gt; = 
{{gaps|0111|1011010000|1001101111|1010101101|1000011111|0000000011|0111100011|0110001110|0110001111|1111111111|1111111111|1111111111&lt;sub&gt;2&lt;/sub&gt;}}.
The encoding can represent binary significands up to 10×2&lt;sup&gt;110&lt;/sup&gt;−1 = {{gaps|12|980|742|146|337|069|071|326|240|823|050|239}} but values larger than 10&lt;sup&gt;34&lt;/sup&gt;−1 are illegal (and the standard requires implementations to treat them as 0, if encountered on input).

As described above, the encoding varies depending on whether the most significant 4 bits of the significand are in the range 0 to 7 (0000&lt;sub&gt;2&lt;/sub&gt; to 0111&lt;sub&gt;2&lt;/sub&gt;), or higher (1000&lt;sub&gt;2&lt;/sub&gt; or 1001&lt;sub&gt;2&lt;/sub&gt;).

If the 2 bits after the sign bit are "00", "01", or "10", then the 
exponent field consists of the 14 bits following the sign bit, and the
significand is the remaining 113 bits, with an implicit leading 0 bit:

 &lt;code&gt; s 00eeeeeeeeeeee   (0)ttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;
 &lt;code&gt; s 01eeeeeeeeeeee   (0)ttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;
 &lt;code&gt; s 10eeeeeeeeeeee   (0)ttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;  

This includes [[subnormal numbers]] where the leading significand digit is 0.

If the 2 bits after the sign bit are "11", then the 14-bit exponent field is shifted 2 bits to the right (after both the sign bit and the "11" bits thereafter), and the represented significand is in the remaining 111 bits. In this case there is an implicit (that is, not stored) leading 3-bit sequence "100" in the true significand.

 &lt;code&gt; s 1100eeeeeeeeeeee (100)t tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;
 &lt;code&gt; s 1101eeeeeeeeeeee (100)t tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;
 &lt;code&gt; s 1110eeeeeeeeeeee (100)t tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt tttttttttt&lt;/code&gt;

The "11" 2-bit sequence after the sign bit indicates that there is an ''implicit'' "100" 3-bit
prefix to the significand. Compare having an implicit 1 in the significand of normal
values for the binary formats. Note also that the "00", "01", or "10" bits are part of the exponent field.

For the decimal128 format, all of these significands are out of the valid range (they begin with 2^113 &gt; 1.038×10&lt;sup&gt;34&lt;/sup&gt;), and are thus decoded as zero, but the pattern is same as [[decimal32]] and [[decimal64]].

In the above cases, the value represented is

: (−1)&lt;sup&gt;sign&lt;/sup&gt; × 10&lt;sup&gt;exponent−6176&lt;/sup&gt; × significand &lt;!-- Remember, significand is defined as an integer: 0 &lt;= significand &lt; 10^34 --&gt;

If the four bits after the sign bit are "1111" then the value is an infinity or a NaN, as described above:

 s 11110 xx...x    ±infinity
 s 11111 0x...x    a quiet NaN
 s 11111 1x...x    a signalling NaN

=== Densely packed decimal significand field ===
In this version, the significand is stored as a series of decimal digits.  The leading digit is between 0 and 9 (3 or 4 binary bits), and the rest of the significand uses the [[densely packed decimal]] (DPD) encoding.

Unlike the binary integer significand version, where the exponent changed position and came before the significand, this encoding combines the leading 2 bits of the exponent and the leading digit (3 or 4 bits) of the significand into the five bits that follow the sign bit.

This twelve bits after that are the exponent continuation field, providing the less-significant bits of the exponent.

The last 110 bits are the significand continuation field, consisting of eleven 10-bit ''[[declet (computing)|declet]]s''.&lt;ref name="Muller_2010"&gt;{{cite book |author-last1=Muller |author-first1=Jean-Michel |author-last2=Brisebarre |author-first2=Nicolas |author-last3=de Dinechin |author-first3=Florent |author-last4=Jeannerod |author-first4=Claude-Pierre |author-last5=Lefèvre |author-first5=Vincent |author-last6=Melquiond |author-first6=Guillaume |author-last7=Revol |author-first7=Nathalie |author-last8=Stehlé |author-first8=Damien |author-last9=Torres |author-first9=Serge |title=Handbook of Floating-Point Arithmetic |year=2010 |publisher=[[Birkhäuser]] |edition=1 |isbn=978-0-8176-4704-9&lt;!-- print --&gt; |doi=10.1007/978-0-8176-4705-6 |lccn=2009939668&lt;!-- |isbn=978-0-8176-4705-6 (online), ISBN 0-8176-4704-X (print) --&gt;}}&lt;/ref&gt; Each declet encodes three decimal digits&lt;ref name="Muller_2010"/&gt; using the DPD encoding.

If the first two bits after the sign bit are "00", "01", or "10", then those are
the leading bits of the exponent, and the three bits after that are interpreted as
the leading decimal digit (0 to 7):

 &lt;code&gt; s 00 TTT (00)eeeeeeeeeeee (0TTT)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 &lt;code&gt; s 01 TTT (01)eeeeeeeeeeee (0TTT)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 &lt;code&gt; s 10 TTT (10)eeeeeeeeeeee (0TTT)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 
If the first two bits after the sign bit are "11", then the 
second two bits are the leading bits of the exponent, and the last bit is
prefixed with "100" to form the leading decimal digit (8 or 9):

 &lt;code&gt; s 1100 T (00)eeeeeeeeeeee (100T)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 &lt;code&gt; s 1101 T (01)eeeeeeeeeeee (100T)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 &lt;code&gt; s 1110 T (10)eeeeeeeeeeee (100T)[tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt][tttttttttt]&lt;/code&gt;
 
The remaining two combinations (11110 and 11111) of the 5-bit field
are used to represent ±infinity and NaNs, respectively.

The DPD/3BCD transcoding for the declets is given by the following table.
b9...b0 are the bits of the DPD, and d2...d0 are the three BCD digits.

{{Densely packed decimal}}

The 8 decimal values whose digits are all 8s or 9s have four codings each.
The bits marked x in the table above are ignored on input, but will always be 0 in computed results.
(The 8×3 = 24 non-standard encodings fill in the gap between 10&lt;sup&gt;3&lt;/sup&gt;=1000 and 2&lt;sup&gt;10&lt;/sup&gt;=1024.)

In the above cases, with the ''true significand'' as the sequence of decimal digits decoded, the value represented is

:&lt;math&gt;(-1)^\text{signbit}\times 10^{\text{exponentbits}_2-6176_{10}}\times \text{truesignificand}_{10}&lt;/math&gt;

== See also ==
* [[decimal32 floating-point format|Decimal32]]
* [[decimal64 floating-point format|Decimal64]]
* [[IEEE 754-2008|IEEE Standard for Floating-Point Arithmetic (IEEE 754)]]
* [[ISO/IEC 10967]], Language Independent Arithmetic
* [[Primitive data type]]

== References ==
{{reflist}}

[[Category:Computer arithmetic]]
[[Category:Data types]]
[[Category:Floating point types]]</text>
      <sha1>7ddnhg4f6rwc4vrrzg2gi7g77z9d7oe</sha1>
    </revision>
  </page>
  <page>
    <title>Decomposition method (queueing theory)</title>
    <ns>0</ns>
    <id>39645680</id>
    <revision>
      <id>679316285</id>
      <parentid>678493670</parentid>
      <timestamp>2015-09-03T20:25:21Z</timestamp>
      <contributor>
        <username>Dexbot</username>
        <id>16752040</id>
      </contributor>
      <minor/>
      <comment>Bot: Deprecating [[Template:Cite doi]] and some minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1230">In [[queueing theory]], a discipline within the mathematical [[probability theory|theory of probability]], the '''decomposition method''' is an approximate method for the analysis of queueing networks where the network is broken into subsystems which are independently analyzed.&lt;ref&gt;{{Cite journal | last1 = Kuehn | first1 = P. | doi = 10.1109/TCOM.1979.1094270 | title = Approximate Analysis of General Queuing Networks by Decomposition | journal = IEEE Transactions on Communications | volume = 27 | pages = 113–126 | year = 1979 | pmid =  | pmc = }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Caldentey | first1 = R. | title = Approximations for Multi-Class Departure Processes| journal = Queueing Systems | volume = 38 | issue = 2 | pages = 205–212 | doi = 10.1023/A:1010910531975 | year = 2001 | pmid =  | pmc = | url = http://people.stern.nyu.edu/rcaldent/papers/QuestaApprox.pdf}}&lt;/ref&gt;

The individual queueing nodes are considered to be independent [[G/G/1 queue]]s where arrivals are governed by a [[renewal process]] and both service time and arrival distributions are parametrised to match the first two moments of data.

==References==

{{Reflist}}

{{Queueing theory}}

{{probability-stub}}

[[Category:Queueing theory]]</text>
      <sha1>4qqhws3n3s40o24nixa6i9thm0l37d2</sha1>
    </revision>
  </page>
  <page>
    <title>Deferred Measurement Principle</title>
    <ns>0</ns>
    <id>42726919</id>
    <revision>
      <id>829100028</id>
      <parentid>794073517</parentid>
      <timestamp>2018-03-06T17:09:58Z</timestamp>
      <contributor>
        <username>Jmertel23</username>
        <id>32942831</id>
      </contributor>
      <minor/>
      <comment>added wikilinks and removed "underlinked" tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1928">
{{Orphan|date=August 2017}}


[[File:MeasurementCommutesWithControls.png|thumb|Two equivalent quantum logic circuits. One where measurement happens first, and one where an operation conditioned on the to-be-measured qubit happens first.]]

The '''Deferred Measurement Principle''' is a result in [[quantum computing]] which states that delaying measurements until the end of a quantum computation doesn't affect the [[probability distribution]] of outcomes.&lt;ref name="NielsenChuang2010"&gt;{{cite book|author1=Michael A. Nielsen|author2=Isaac L. Chuang|title=Quantum Computation and Quantum Information: 10th Anniversary Edition|url=https://books.google.com/books?id=-s4DEy7o-a0C|date=9 December 2010|publisher=Cambridge University Press|isbn=978-1-139-49548-6 |page=186 |section=4.4 Measurement}}&lt;/ref&gt;&lt;ref name="Cross2012"&gt;{{cite book|author=Odel A. Cross|title=Topics in Quantum Computing|url=https://books.google.com/books?id=b_D9flK2h8QC&amp;pg=PA348|date=5 November 2012|publisher=O. A. Cross|isbn=978-1-4800-2749-7|page=348 |section=5.2.2 Deferred Measurement}}&lt;/ref&gt;

A consequence of the deferred measurement principle is that measuring commutes with conditioning.
The choice of whether to measure a [[qubit]] before, after, or during an operation conditioned on that qubit will have no observable effect on a circuit's final expected results.

Thanks to the deferred measurement principle, measurements in a [[quantum circuit]] can often be shifted around so they happen at better times.
For example, measuring qubits as early as possible can reduce the maximum number of simultaneously stored qubits; potentially enabling an algorithm to be run on a smaller quantum computer or to be simulated more efficiently.
Alternatively, deferring all measurements until the end of circuits allows them to be analyzed using only [[pure state]]s.

==References==
{{reflist}}

[[Category:Quantum information science]]


{{quantum-stub}}</text>
      <sha1>7s2x42p9rwa6t4xsx4j4vsjpz5rke5c</sha1>
    </revision>
  </page>
  <page>
    <title>Delta operator</title>
    <ns>0</ns>
    <id>229528</id>
    <revision>
      <id>871281911</id>
      <parentid>871281901</parentid>
      <timestamp>2018-11-30T01:17:39Z</timestamp>
      <contributor>
        <username>Ifnord</username>
        <id>470876</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/107.3.3.24|107.3.3.24]] ([[User talk:107.3.3.24|talk]]) to last revision by BG19bot. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3601">In [[mathematics]], a '''delta operator''' is a shift-equivariant [[linear transformation|linear]] operator ''&lt;math&gt;Q\colon\mathbb{K}[x] \longrightarrow \mathbb{K}[x]&lt;/math&gt;'' on the [[vector space]] of [[polynomial]]s in a variable &lt;math&gt;x&lt;/math&gt; over a [[field (mathematics)|field]] &lt;math&gt;\mathbb{K}&lt;/math&gt; that reduces degrees by one.

To say that &lt;math&gt;Q&lt;/math&gt; is '''shift-equivariant''' means that if &lt;math&gt;g(x) = f(x + a)&lt;/math&gt;, then

:&lt;math&gt;{ (Qg)(x) = (Qf)(x + a)}.\,&lt;/math&gt;

In other words, if ''&lt;math&gt;f&lt;/math&gt;'' is a "'''shift'''" of ''&lt;math&gt;g&lt;/math&gt;'', then ''&lt;math&gt;Qf&lt;/math&gt;'' is also a shift of ''&lt;math&gt;Qg&lt;/math&gt;'', and has the same "'''shifting vector'''" ''&lt;math&gt;a&lt;/math&gt;''.

To say that ''an operator reduces degree by one'' means that if ''&lt;math&gt;f&lt;/math&gt;'' is a polynomial of degree ''&lt;math&gt;n&lt;/math&gt;'', then ''&lt;math&gt;Qf&lt;/math&gt;'' is either a polynomial of degree &lt;math&gt;n-1&lt;/math&gt;, or, in case &lt;math&gt;n = 0&lt;/math&gt;, ''&lt;math&gt;Qf&lt;/math&gt;'' is 0.

Sometimes a ''delta operator'' is defined to be a shift-equivariant linear transformation on polynomials in ''&lt;math&gt;x&lt;/math&gt;'' that maps ''&lt;math&gt;x&lt;/math&gt;'' to a nonzero constant.  Seemingly weaker than the definition given above, this latter characterization can be shown to be equivalent to the stated definition, since shift-equivariance is a fairly strong condition.

==Examples==

* The forward [[difference operator]]

:: &lt;math&gt; (\Delta f)(x) = f(x + 1) - f(x)\, &lt;/math&gt;

:is a delta operator.

* [[Derivative|Differentiation]] with respect to ''x'', written as ''D'', is also a delta operator.
* Any operator of the form
::&lt;math&gt;\sum_{k=1}^\infty c_k D^k&lt;/math&gt;
: (where ''D''&lt;sup&gt;''n''&lt;/sup&gt;(&amp;fnof;) = &amp;fnof;&lt;sup&gt;(''n'')&lt;/sup&gt; is the ''n''&lt;sup&gt;th&lt;/sup&gt; derivative) with &lt;math&gt;c_1\neq0&lt;/math&gt; is a delta operator.  It can be shown that all delta operators can be written in this form.  For example, the difference operator given above can be expanded as
::&lt;math&gt;\Delta=e^D-1=\sum_{k=1}^\infty \frac{D^k}{k!}.&lt;/math&gt;

* The generalized derivative of [[time scale calculus]] which unifies the forward difference operator with the derivative of standard [[calculus]] is a delta operator.
* In [[computer science]] and [[cybernetics]], the term "discrete-time delta operator" (&amp;delta;) is generally taken to mean a difference operator

:: &lt;math&gt;{(\delta f)(x) = {{ f(x+\Delta t) - f(x) }  \over {\Delta t} }}, &lt;/math&gt;

: the [[Euler approximation]] of the usual derivative with a discrete sample time &lt;math&gt;\Delta t&lt;/math&gt;. The delta-formulation obtains a significant number of numerical advantages compared to the shift-operator at fast sampling.

==Basic polynomials==

Every delta operator ''&lt;math&gt;Q&lt;/math&gt;'' has a unique sequence of "basic polynomials", a [[polynomial sequence]] defined by three conditions:

* &lt;math&gt;p_0(x)=1 ;&lt;/math&gt;
* &lt;math&gt;p_{n}(0)=0;&lt;/math&gt;
* &lt;math&gt;(Qp_n)(x)=np_{n-1}(x), \; \forall n \in \mathbb N.&lt;/math&gt;

Such a sequence of basic polynomials is always of [[binomial type]], and it can be shown that no other sequences of binomial type exist.  If the first two conditions above are dropped, then the third condition says this polynomial sequence is a [[Sheffer sequence]]—a more general concept.

== See also ==

* [[Pincherle derivative]]
* [[Shift operator]]
* [[Umbral calculus]]

== References ==
* {{Citation | last1=Nikol'Skii | first1=Nikolai Kapitonovich | title=Treatise on the shift operator: spectral function theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-0-387-15021-5 | year=1986}}

[[Category:Linear algebra]]
[[Category:Polynomials]]
[[Category:Finite differences]]</text>
      <sha1>kcnjo93snheipxjhs8hymq8u9r2s8ky</sha1>
    </revision>
  </page>
  <page>
    <title>Distance (graph theory)</title>
    <ns>0</ns>
    <id>1020021</id>
    <revision>
      <id>846760600</id>
      <parentid>831270123</parentid>
      <timestamp>2018-06-20T18:43:22Z</timestamp>
      <contributor>
        <ip>69.166.46.149</ip>
      </contributor>
      <comment>/* Algorithm for finding pseudo-peripheral vertices */  I could be wrong but returning v instead of u gives a sub-optimal vertex.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5896">{{Redirect|Geodesic distance|distances on the surface of a sphere|Great-circle distance|distances on the surface of the Earth|Geodesics on an ellipsoid}}

In the [[mathematics|mathematical]] field of [[graph theory]], the '''distance''' between two [[vertex (graph theory)|vertices]] in a [[Graph (discrete mathematics)|graph]] is the number of edges in a [[shortest path problem|shortest path]] (also called a '''graph geodesic''') connecting them.  This is also known as the '''geodesic distance'''.&lt;ref&gt;{{cite journal |last=Bouttier  |first=Jérémie |author2=Di Francesco,P. |author3=Guitter, E. |date=July 2003  
|title=Geodesic distance in planar graphs |journal= Nuclear Physics B|volume=663 |issue=3 |pages=535–567 |url=http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6TVC-48KW72R-1&amp;_user=3742306&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_acct=C000061256&amp;_version=1&amp;_urlVersion=0&amp;_userid=3742306&amp;md5=86dd4de63373a7e72d23d16840947661
|accessdate= 2008-04-23 |quote=By distance we mean here geodesic distance along the graph, namely the length of any shortest path between say two given faces  
|doi=10.1016/S0550-3213(03)00355-9}}&lt;/ref&gt; Notice that there may be more than one shortest path between two vertices.&lt;ref&gt;
{{cite web |url=http://mathworld.wolfram.com/GraphGeodesic.html |title=Graph Geodesic |accessdate= 2008-04-23
|last=Weisstein |first=Eric W. |authorlink=Eric W. Weisstein |work=MathWorld--A Wolfram Web Resource 
|publisher= Wolfram Research 
|quote=The length of the graph geodesic between these points d(u,v) is called the graph distance between u and v }}
&lt;/ref&gt;  If there is no path connecting the two vertices, i.e., if they belong to different [[connected component (graph theory)|connected component]]s, then conventionally the distance is defined as infinite.

In the case of a [[directed graph]] the distance &lt;math&gt;d(u,v)&lt;/math&gt; between two vertices &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; is defined as the length of a shortest directed path from &lt;math&gt;u&lt;/math&gt; to &lt;math&gt;v&lt;/math&gt; consisting of arcs, provided at least one such path exists.&lt;ref&gt;F. Harary, Graph Theory, Addison-Wesley, 1969, p.199.&lt;/ref&gt; Notice that, in contrast with the case of undirected graphs, &lt;math&gt;d(u,v)&lt;/math&gt; does not necessarily coincide with &lt;math&gt;d(v,u)&lt;/math&gt;, and it might be the case that one is defined while the other is not.

==Related concepts==
A [[metric space]] defined over a set of points in terms of distances in a graph defined over the set is called a '''graph metric'''.
The vertex set (of an undirected graph) and the distance function form a metric space, if and only if the graph is [[connected (graph theory)|connected]].

The '''eccentricity''' &lt;math&gt;\epsilon(v)&lt;/math&gt; of a vertex &lt;math&gt;v&lt;/math&gt; is the greatest geodesic distance between &lt;math&gt;v&lt;/math&gt; and any other vertex. It can be thought of as how far a node is from the node most distant from it in the graph.

The '''radius''' &lt;math&gt;r&lt;/math&gt; of a graph is the minimum eccentricity of any vertex or, in symbols, &lt;math&gt;r = \min_{v \in V} \epsilon(v)&lt;/math&gt;.

The '''diameter''' &lt;math&gt;d&lt;/math&gt; of a graph is the maximum eccentricity of any vertex in the graph.  That is, &lt;math&gt;d&lt;/math&gt; is the greatest distance between any pair of vertices or, alternatively, &lt;math&gt;d = \max_{v \in V}\epsilon(v)&lt;/math&gt;. To find the diameter of a graph, first find the [[Shortest path problem|shortest path]] between each pair of [[vertex (graph theory)|vertices]]. The greatest length of any of these paths is the diameter of the graph. 

A '''central vertex''' in a graph of radius &lt;math&gt;r&lt;/math&gt; is one whose eccentricity is &lt;math&gt;r&lt;/math&gt;&amp;mdash;that is, a vertex that achieves the radius or, equivalently, a vertex &lt;math&gt;v&lt;/math&gt; such that &lt;math&gt;\epsilon(v) = r&lt;/math&gt;.

A '''peripheral vertex''' in a graph of diameter &lt;math&gt;d&lt;/math&gt; is one that is distance &lt;math&gt;d&lt;/math&gt; from some other vertex&amp;mdash;that is, a vertex that achieves the diameter. Formally, &lt;math&gt;v&lt;/math&gt; is peripheral if &lt;math&gt;\epsilon(v) = d&lt;/math&gt;.

A '''pseudo-peripheral vertex''' &lt;math&gt;v&lt;/math&gt; has the property that for any vertex &lt;math&gt;u&lt;/math&gt;, if &lt;math&gt;v&lt;/math&gt; is as far away from &lt;math&gt;u&lt;/math&gt; as possible, then &lt;math&gt;u&lt;/math&gt; is as far away from &lt;math&gt;v&lt;/math&gt; as possible.  Formally, a vertex ''u'' is pseudo-peripheral, 
if for each vertex ''v'' with &lt;math&gt;d(u,v) = \epsilon(u)&lt;/math&gt; holds &lt;math&gt;\epsilon(u)=\epsilon(v)&lt;/math&gt;.

The [[partition of a set|partition]] of a graph's vertices into subsets by their distances from a given starting vertex is called the [[level structure]] of the graph.

A graph such that for every pair of vertices there is a unique shortest path connecting them is called a '''geodetic graph'''. For example, all [[Tree (graph theory)|trees]] are geodetic.&lt;ref&gt;[[Øystein Ore]], Theory of graphs [3rd ed., 1967], Colloquium Publications, American Mathematical Society,  	p. 104&lt;/ref&gt;

==Algorithm for finding pseudo-peripheral vertices==
Often peripheral [[sparse matrix]] algorithms need a starting vertex with a high eccentricity. A peripheral vertex would be perfect, but is often hard to calculate. In most circumstances a pseudo-peripheral vertex can be used.  A pseudo-peripheral vertex can easily be found with the following algorithm:

# Choose a vertex &lt;math&gt;u&lt;/math&gt;.
# Among all the vertices that are as far from &lt;math&gt;u&lt;/math&gt; as possible, let &lt;math&gt;v&lt;/math&gt; be one with minimal [[degree (graph theory)|degree]].
# If &lt;math&gt;\epsilon(v) &gt; \epsilon(u)&lt;/math&gt; then set &lt;math&gt;u=v&lt;/math&gt; and repeat with step 2, else &lt;math&gt;u&lt;/math&gt; is a pseudo-peripheral vertex.

==See also==
* [[Distance matrix]]
* [[Resistance distance]]
* [[Betweenness centrality]]
* [[Centrality]]
* [[Closeness (graph theory)|Closeness]]
* [[Degree diameter problem]] for [[Graph (discrete mathematics)|graph]]s and [[digraph (mathematics)|digraph]]s
* [[Metric graph]]

==Notes==
{{reflist}}

[[Category:Graph theory]]</text>
      <sha1>nc1c07a0vqxhmgd3jnjoacfp2aa7z05</sha1>
    </revision>
  </page>
  <page>
    <title>Domain relational calculus</title>
    <ns>0</ns>
    <id>217680</id>
    <revision>
      <id>758478608</id>
      <parentid>758477750</parentid>
      <timestamp>2017-01-05T17:55:49Z</timestamp>
      <contributor>
        <ip>128.189.133.101</ip>
      </contributor>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3550">In [[computer science]], '''domain relational calculus''' ('''DRC''') is a calculus that was introduced by Michel Lacroix and [[Alain Pirotte]] as a [[declarative programming|declarative]] [[query language|database query language]] for the [[relational model|relational data model]].&lt;ref name="LP77"&gt;Michel Lacroix, Alain Pirotte: Domain-Oriented Relational Languages. VLDB 1977: 370-378&lt;/ref&gt;

In DRC, ''queries'' have the form:

:&lt;math&gt; \{\langle X_1, X_2, ...., X_n \rangle \mid p(\langle X_1, X_2, ...., X_n\rangle) \} &lt;/math&gt;

where each X&lt;sub&gt;i&lt;/sub&gt; is either a domain variable or constant, and &lt;math&gt;p(\langle X_1, X_2, ...., X_n \rangle)&lt;/math&gt; denotes a DRC ''formula''.  The result of the query is the set of tuples X&lt;sub&gt;1&lt;/sub&gt; to X&lt;sub&gt;n&lt;/sub&gt; that make the DRC formula true.

This language uses the same operators as [[tuple calculus]],
the logical connectives &amp;and; (and), &amp;or; (or) and &amp;not; (not). The [[existential quantification|existential quantifier]] (&amp;exist;) and the [[universal quantification|universal quantifier]] (&amp;forall;) can be used to bind the variables.

Its computational expressiveness is equivalent to that of [[Relational algebra]].&lt;ref name="Codd72a"&gt;[[E. F. Codd]]: Relational Completeness of Data Base Sub-languages. In R. Rustin, editor, Data Base Systems. Prentice Hall, 1972&lt;/ref&gt;

==Examples==
Let (A, B, C) mean (Rank, Name, ID) in the Enterprise relation

and let (D, E, F) mean (Name, DeptName, ID) in the Department relation

Find all captains of the starship [[USS Enterprise (NCC-1701)|USS Enterprise]]:

&lt;math&gt;\left\{ \ {\left\langle A, B, C \right\rangle} \mid {\left\langle A, B, C \right\rangle \in \mathrm{Enterprise} \ \land \ A = \mathrm{'Captain'} } \ \right\}&lt;/math&gt;

In this example, A, B, C denotes both the result set and a set in the table Enterprise.

Find names of Enterprise crew members who are in Stellar Cartography:

&lt;math&gt;\begin{align}
\{ {\left\langle B \right\rangle} &amp; \mid {\exists A, C \ \left\langle A, B, C \right\rangle \in \mathrm{Enterprise} } \\
                               &amp; \land \ {\exists D, E, F \ \left\langle D, E, F \right\rangle \in \mathrm{Departments} } \\
                               &amp; \land \ F = C \ \land \ E = \mathrm{'Stellar\ Cartography'} \} \\
\end{align}&lt;/math&gt;

In this example, we're only looking for the name, and that's B.  The condition F = C is a requirement because we need to find Enterprise crew members AND they are in the Stellar Cartography Department.

An alternate representation of the previous example would be:

&lt;math&gt;\left\{ \ {\left\langle B \right\rangle} \mid {\exists A, C \ \left\langle A, B, C \right\rangle \in \mathrm{Enterprise} } \ \land \ {\exists D \ \left\langle D, \mathrm{'Stellar\ Cartography'}, C \right\rangle \in \mathrm{Departments} } \ \right\}&lt;/math&gt;

In this example, the value of the requested F domain is directly placed in the formula and the C domain variable is re-used in the query for the existence of a department, since it already holds a crew member's ID.

== Systems ==

* [http://des.sourceforge.net DES – An educational tool for working with Domain Relational Calculus and other formal languages]
* [http://www.eas.asu.edu/~winrdbi/ WinRDBI – An educational tool for working with Domain Relational Calculus and other formal languages]

== See also ==
*[[Relational algebra]]
*[[Relational calculus]]
**[[Tuple relational calculus]] (TRC)
* [[Aldat Relational Algebra]]
* [[Domain algebra]]

== References ==

&lt;references/&gt;

[[Category:Relational model]]
[[Category:Logical calculi]]</text>
      <sha1>dnz48w8kge47io3tfcnzyki3xseq971</sha1>
    </revision>
  </page>
  <page>
    <title>Dynamic Data Driven Applications Systems</title>
    <ns>0</ns>
    <id>3434148</id>
    <revision>
      <id>834493063</id>
      <parentid>768757715</parentid>
      <timestamp>2018-04-06T00:55:18Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */HTTP→HTTPS for [[National Science Foundation]], replaced: http://www.nsf.gov/ → https://www.nsf.gov/ using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3049">'''Dynamic Data Driven Applications Systems''' ('''DDDAS''') is a new paradigm whereby the computation and instrumentation aspects of an application system are dynamically integrated in a feed-back control loop, in the sense that instrumentation data can be dynamically incorporated into the executing model of the application, and in reverse the executing model can control the instrumentation.  Such approaches have been shown that can enable more accurate and faster modeling and analysis of the characteristics and behaviors of a system and can exploit data in intelligent ways to convert them to new capabilities, including decision support systems with the accuracy of full scale modeling, efficient data collection, management, and data mining. The DDDAS concept - and the term - was proposed by [[Frederica Darema]] for the [https://www.nsf.gov/cise/cns/darema/dd_das/index_wkshp.jsp National Science Foundation (NSF) workshop in March 2000].

There are several affiliated annual meetings and conferences, including:

* DDDAS workshop at ICCS (since 2003)
*[http://dydess.mit.edu/ DyDESS] conference and workshop at MIT organized by Sai Ravela and Adrian Sandu
* DDDAS special session at the ACC organized by Puneet Singla and Dennis Bernstein and Sai Ravela
* DDDAS Special Session [http://fusion2015.org/ Information Fusion]
== References ==
#F. Darema, “Dynamic Data Driven Applications Systems: A New Paradigm for Application Simulations and Measurements. Computational Science.” Int’l Conf. on Computational Science (ICCS), LNCS, 3038, 662–669, 2004.
#F. Darema, “Grid Computing and Beyond: The Context of Dynamic Data Driven Applications Systems,” Proceedings IEEE, 93(3), p. 692-697, 2005.
#G. Allen, “Building a Dynamic Data Driven Application System for Hurricane Forecasting,” Int’l Conf. on Computational Science (ICCS), LNCS, vol. 4487, p. 1034–1041. Springer, Heidelberg, 2007.
#M. Denham, A. Cortes, T. Margalef, E. Luque, “Applying a Dynamic Data Driven Genetic Algorithm to Improve Forest Fire Spread Prediction,”  M. Bubak et al. (Eds.): ICCS 2008, LNCS 5103, pp. 36–45, 2008.
#E. Blasch, Y. Al-Nashif, and S. Hariri, “Static versus Dynamic Data Information Fusion analysis using DDDAS for Cyber Trust,” Procedia Computer Science, Vol. 29, pp. 1299-1313, 2014.
#X. Shi, H. Damgacioglu,  N. Celik, “A Dynamic Data Driven Approach for Operation Planning of Microgrids,” Procedia Computer Science, 2015.
&lt;references /&gt;

== External links ==
*[http://www.1dddas.org/ 1DDDAS.org] Has a list of active projects and slides from the current DDDAS program and past contributions from [[National Science Foundation|NSF]].
*[http://caos.mit.edu CAOS] Cooperative Autonomous Observing Systems for Mapping and Monitoring the Atmosphere @ MIT, jointly between EAPS and Aero-Astro
*[http://www.firegrid.org/ FireGrid] FireGrid is a previous example for Emergency Systems.

== See also ==
*[[Data assimilation]]
*[[Control systems]]
*[[Uncertainty Quantification]]
[[Category:Theoretical computer science]]</text>
      <sha1>k2cwukd32sxdwsa2iyd6z9qg8xhq706</sha1>
    </revision>
  </page>
  <page>
    <title>Euler–Lagrange equation</title>
    <ns>0</ns>
    <id>294995</id>
    <revision>
      <id>865845353</id>
      <parentid>863678260</parentid>
      <timestamp>2018-10-26T15:14:19Z</timestamp>
      <contributor>
        <ip>18.40.122.104</ip>
      </contributor>
      <comment>Added missing term in summation at end of "Several functions of several variables with higher derivatives"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22707">In the [[calculus of variations]], the '''Euler–Lagrange equation''', '''Euler's equation''',&lt;ref&gt;{{cite book|first=Charles|last=Fox|title=An introduction to the calculus of variations|publisher=Courier Dover Publications|year=1987|isbn=978-0-486-65499-7}}&lt;/ref&gt; or '''Lagrange's equation''' (although the latter name is ambiguous—see [[Lagrange's formula (disambiguation)|disambiguation page]]), is a second-order [[partial differential equation]] whose solutions are the [[function (mathematics)|function]]s for which a given [[functional (mathematics)|functional]] is [[stationary point|stationary]]. It was developed by Swiss mathematician [[Leonhard Euler]] and Italian-French mathematician [[Joseph-Louis Lagrange]] in the 1750s.

Because a differentiable functional is stationary at its local [[maxima and minima]], the Euler–Lagrange equation is useful for solving [[optimization (mathematics)|optimization]] problems in which, given some functional, one seeks the function minimizing or maximizing it. This is analogous to [[Fermat's theorem (stationary points)|Fermat's theorem]] in [[calculus]], stating that at any point where a differentiable function attains a local extremum its [[derivative (mathematics)|derivative]] is zero.

In [[Lagrangian mechanics]], because of [[Hamilton's principle]] of stationary action, the evolution of a physical system is described by the solutions to the Euler–Lagrange equation for the [[action (physics)#Action (functional)|action]] of the system. In [[classical mechanics]], it is equivalent to [[Newton's laws of motion]], but it has the advantage that it takes the same form in any system of [[generalized coordinate]]s, and it is better suited to generalizations. In [[classical field theory]] there is an [[classical field theory#Lagrangian dynamics|analogous equation]] to calculate the dynamics of a [[field (physics)|field]].

==History==
The Euler–Lagrange equation was developed in the 1750s by Euler and Lagrange in connection with their studies of the  [[tautochrone]] problem. This is the problem of determining a curve on which a weighted particle will fall to a fixed point in a fixed amount of time, independent of the starting point.

Lagrange solved this problem in 1755  and sent the solution to Euler. Both further developed Lagrange's method and applied it to [[mechanics]], which led to the formulation of [[Lagrangian mechanics]]. Their correspondence ultimately led to the [[calculus of variations]], a term coined by Euler himself in 1766.&lt;ref&gt;[http://numericalmethods.eng.usf.edu/anecdotes/lagrange.pdf A short biography of Lagrange] {{webarchive|url=https://web.archive.org/web/20070714022022/http://numericalmethods.eng.usf.edu/anecdotes/lagrange.pdf |date=2007-07-14 }}&lt;/ref&gt;

==Statement==
The Euler–Lagrange equation is an equation satisfied by a function  '''''q'''''
of a [[real number|real]] argument ''t'', which is a stationary point of the [[functional (mathematics)|functional]]

:&lt;math&gt;\displaystyle S(\boldsymbol q) = \int_a^b L(t,\boldsymbol q(t),\boldsymbol \dot{q}(t))\, \mathrm{d}t&lt;/math&gt;

where:
*&lt;math&gt;\boldsymbol q&lt;/math&gt; is the function to be found:
:&lt;math&gt;\begin{align}
\boldsymbol q \colon [a, b] \subset \mathbb{R} &amp; \to     X \\
                                 t &amp; \mapsto x = \boldsymbol q(t)
\end{align}&lt;/math&gt;
:such that &lt;math&gt;\boldsymbol q&lt;/math&gt; is differentiable, &lt;math&gt;\boldsymbol q(a) = \boldsymbol x_a&lt;/math&gt;, and &lt;math&gt;\boldsymbol q(b) = \boldsymbol x_{b} &lt;/math&gt;;
*&lt;math&gt;\boldsymbol \dot{q} &lt;/math&gt;; is the derivative of &lt;math&gt;\boldsymbol q&lt;/math&gt;:
*:&lt;math&gt;\begin{align}
\dot{q}\colon [a, b] &amp; \to     T_{q(t)}X \\
               t &amp; \mapsto v = \dot{q}(t)
\end{align}&lt;/math&gt;
:&lt;math&gt; T_{q(t)} X&lt;/math&gt; denotes the [[tangent space]] to &lt;math&gt; X &lt;/math&gt; at the point &lt;math&gt; q(t) &lt;/math&gt;.
* &lt;math&gt;L&lt;/math&gt; is a real-valued function with [[continuous function|continuous]] first [[partial derivatives]]:
*:&lt;math&gt;\begin{align}
L \colon [a, b] \times TX &amp; \to     \mathbb{R} \\
                         (t, x, v) &amp; \mapsto L(t, x, v).
\end{align}&lt;/math&gt;
:&lt;math&gt;TX&lt;/math&gt; being the [[tangent bundle]] of &lt;math&gt;X&lt;/math&gt; defined by 
: &lt;math&gt; TX = \bigcup_{x \in X} \{ x \} \times T_{x}X &lt;/math&gt; ;

The Euler–Lagrange equation, then, is given by
{{Equation box 1
|indent =:
|equation = &lt;math&gt;L_x(t,q(t),\dot{q}(t))-\frac{\mathrm{d}}{\mathrm{d}t}L_v(t,q(t),\dot{q}(t)) = 0.&lt;/math&gt;
|border colour = #50C878
|background colour = #ECFCF4}} 
where &lt;math&gt;L_x&lt;/math&gt; and &lt;math&gt;L_v&lt;/math&gt; denote the partial derivatives of &lt;math&gt;L&lt;/math&gt; with respect to the second and third arguments, respectively.

If the dimension of the space &lt;math&gt;X&lt;/math&gt; is greater than 1, this is a system of differential equations, one for each component:
:&lt;math&gt;\frac{\partial L}{\partial q_i}(t,\boldsymbol q(t),\boldsymbol \dot{q}(t))-\frac{\mathrm{d}}{\mathrm{d}t}\frac{\partial L}{\partial \dot q_i}(t,\boldsymbol q(t),\boldsymbol \dot{q}(t)) = 0
\quad \text{for } i = 1, \dots, n.&lt;/math&gt;

:{| class="toccolours collapsible collapsed" width="60%" style="text-align:left"
!Derivation of one-dimensional Euler–Lagrange equation
|-
|
The derivation of the one-dimensional Euler–Lagrange equation is one of the classic proofs in [[mathematics]]. It relies on the [[fundamental lemma of calculus of variations]].

We wish to find a function &lt;math&gt;f&lt;/math&gt; which satisfies the boundary conditions &lt;math&gt;f(a) = A&lt;/math&gt;, &lt;math&gt;f(b) = B&lt;/math&gt;, and which extremizes the functional

: &lt;math&gt; J = \int_a^b F(x,f(x),f'(x))\, \mathrm{d}x\ . &lt;/math&gt;

We assume that &lt;math&gt;F&lt;/math&gt; is twice continuously differentiable.&lt;ref name='CourantP184'&gt;{{harvnb|Courant|Hilbert|1953|p=184}}&lt;/ref&gt; A weaker assumption can be used, but the proof becomes more difficult.{{Cn|date=September 2013}}

If &lt;math&gt;f&lt;/math&gt; extremizes the functional subject to the boundary conditions, then any slight perturbation of &lt;math&gt;f&lt;/math&gt; that preserves the boundary values must either increase &lt;math&gt;J&lt;/math&gt; (if &lt;math&gt;f&lt;/math&gt; is a minimizer) or decrease &lt;math&gt;J&lt;/math&gt; (if &lt;math&gt;f&lt;/math&gt; is a maximizer).

Let &lt;math&gt;g_{\varepsilon} (x) = f (x) + \varepsilon \eta (x)&lt;/math&gt; be the result of such a perturbation &lt;math&gt;\varepsilon \eta (x)&lt;/math&gt; of &lt;math&gt;f&lt;/math&gt;, where &lt;math&gt;\varepsilon&lt;/math&gt; is small and &lt;math&gt;\eta (x)&lt;/math&gt; is a differentiable function satisfying &lt;math&gt;\eta (a) = \eta (b) = 0&lt;/math&gt;. Then define

: &lt;math&gt; J_\varepsilon = \int_a^b F(x,g_\varepsilon(x), g_\varepsilon'(x) ) \, \mathrm{d}x = \int_a^b F_\varepsilon\, \mathrm{d}x  &lt;/math&gt;

where &lt;math&gt; F_\varepsilon = F(x, \, g_\varepsilon (x), \, g_\varepsilon' (x) ) &lt;/math&gt; .

We now wish to calculate the [[total derivative]] of &lt;math&gt; J_\varepsilon&lt;/math&gt; with respect to ''ε''.

: &lt;math&gt; \frac{\mathrm{d} J_\varepsilon}{\mathrm{d} \varepsilon} = \frac{\mathrm d}{\mathrm d\varepsilon}\int_a^b F_\varepsilon\, \mathrm{d}x = \int_a^b \frac{\mathrm{d} F_\varepsilon}{\mathrm{d}\varepsilon} \, \mathrm{d}x &lt;/math&gt;

It follows from the total derivative that

:&lt;math&gt; 
\begin{align}
\frac{\mathrm d F_\varepsilon}{\mathrm d\varepsilon} &amp; =\frac{\mathrm d x}{\mathrm d\varepsilon}\frac{\partial F_\varepsilon}{\partial x} + \frac{\mathrm d g_\varepsilon}{\mathrm d\varepsilon}\frac{\partial F_\varepsilon}{\partial g_\varepsilon} + \frac{\mathrm d g_\varepsilon'}{\mathrm d\varepsilon}\frac{\partial F_\varepsilon}{\partial g_\varepsilon'} \\
&amp; = \frac{\mathrm d g_\varepsilon}{\mathrm d\varepsilon}\frac{\partial F_\varepsilon}{\partial g_\varepsilon}+\frac{\mathrm d g'_\varepsilon}{\mathrm d\varepsilon}\frac{\partial F_\varepsilon}{\partial g'_\varepsilon} \\
&amp; = \eta(x) \frac{\partial F_\varepsilon}{\partial g_\varepsilon} + \eta'(x) \frac{\partial F_\varepsilon}{\partial g_\varepsilon'} \ . \\
\end{align}
&lt;/math&gt;

So

: &lt;math&gt; \frac{\mathrm{d} J_\varepsilon}{\mathrm{d} \varepsilon} = \int_a^b \left[\eta(x) \frac{\partial F_\varepsilon}{\partial g_\varepsilon} + \eta'(x) \frac{\partial F_\varepsilon}{\partial g_\varepsilon'} \, \right]\,\mathrm{d}x \ . &lt;/math&gt;

When ''ε'' = 0 we have ''g''&lt;sub&gt;''ε''&lt;/sub&gt; = ''f'', ''F&lt;sub&gt;ε&lt;/sub&gt; =  F(x, f(x), f'(x))''   and ''J&lt;sub&gt;ε&lt;/sub&gt;''&amp;nbsp; has an [[extremum]] value, so that

: &lt;math&gt; \frac{\mathrm d J_\varepsilon}{\mathrm d\varepsilon}\bigg|_{\varepsilon=0}  = \int_a^b \left[ \eta(x) \frac{\partial F}{\partial f} + \eta'(x) \frac{\partial F}{\partial f'} \,\right]\,\mathrm{d}x = 0 \ .&lt;/math&gt;

The next step is to use [[integration by parts]] on the second term of the integrand, yielding

: &lt;math&gt; \int_a^b \left[ \frac{\partial F}{\partial f} - \frac{\mathrm{d}}{\mathrm{d}x} \frac{\partial F}{\partial f'} \right] \eta(x)\,\mathrm{d}x + \left[ \eta(x) \frac{\partial F}{\partial f'} \right]_a^b = 0 \ . &lt;/math&gt;

Using the boundary conditions &lt;math&gt;\eta (a) = \eta (b) = 0&lt;/math&gt;,

: &lt;math&gt; \int_a^b \left[ \frac{\partial F}{\partial f} - \frac{\mathrm{d}}{\mathrm{d}x} \frac{\partial F}{\partial f'} \right] \eta(x)\,\mathrm{d}x = 0  \ . &lt;/math&gt;

Applying the [[fundamental lemma of calculus of variations]] now yields the Euler–Lagrange equation

: &lt;math&gt; \frac{\partial F}{\partial f} - \frac{\mathrm{d}}{\mathrm{d}x} \frac{\partial F}{\partial f'} = 0 \ . &lt;/math&gt;
|}

:{| class="toccolours collapsible collapsed" width="60%" style="text-align:left"
!Alternate derivation of one-dimensional Euler–Lagrange equation
|-
|
Given a functional

:&lt;math&gt;J = \int^b_aF(t, y(t), y'(t))\,\mathrm{d}t&lt;/math&gt;

on &lt;math&gt;C^1([a, b])&lt;/math&gt; with the boundary conditions &lt;math&gt;y(a) = A&lt;/math&gt; and &lt;math&gt;y(b) = B&lt;/math&gt;, we proceed by approximating the extremal curve by a polygonal line with &lt;math&gt;n&lt;/math&gt; segments and passing to the limit as the number of segments grows arbitrarily large.

Divide the interval &lt;math&gt;[a, b]&lt;/math&gt; into &lt;math&gt;n&lt;/math&gt; equal segments with endpoints &lt;math&gt;t_0 = a, t_1, t_2, \ldots, t_n = b&lt;/math&gt; and let &lt;math&gt;\Delta t = t_k - t_{k - 1}&lt;/math&gt;. Rather than a smooth function &lt;math&gt;y(t)&lt;/math&gt; we consider the polygonal line with vertices &lt;math&gt;(t_0, y_0),\ldots,(t_n, y_n)&lt;/math&gt;, where &lt;math&gt;y_0 = A&lt;/math&gt; and &lt;math&gt;y_n = B&lt;/math&gt;. Accordingly, our functional becomes a real function of &lt;math&gt;n - 1&lt;/math&gt; variables given by

:&lt;math&gt;J(y_1, \ldots, y_{n - 1}) \approx \sum^{n - 1}_{k = 0}F\left(t_k, y_k, \frac{y_{k + 1} - y_k}{\Delta t}\right)\Delta t.&lt;/math&gt;

Extremals of this new functional defined on the discrete points &lt;math&gt;t_0,\ldots,t_n&lt;/math&gt; correspond to points where

:&lt;math&gt;\frac{\partial J(y_1,\ldots,y_n)}{\partial y_m} = 0.&lt;/math&gt;

Evaluating this partial derivative gives

:&lt;math&gt;\frac{\partial J}{\partial y_m} = F_y\left(t_m, y_m, \frac{y_{m + 1} - y_m}{\Delta t}\right)\Delta t + F_{y'}\left(t_{m - 1}, y_{m - 1}, \frac{y_m - y_{m - 1}}{\Delta t}\right) - F_{y'}\left(t_m, y_m, \frac{y_{m + 1} - y_m}{\Delta t}\right).&lt;/math&gt;

Dividing the above equation by &lt;math&gt;\Delta t&lt;/math&gt; gives

:&lt;math&gt;\frac{\partial J}{\partial y_m \Delta t} = F_y\left(t_m, y_m, \frac{y_{m + 1} - y_m}{\Delta t}\right) - \frac{1}{\Delta t}\left[F_{y'}\left(t_m, y_m, \frac{y_{m + 1} - y_m}{\Delta t}\right) - F_{y'}\left(t_{m - 1}, y_{m - 1}, \frac{y_m - y_{m - 1}}{\Delta t}\right)\right],&lt;/math&gt;

and taking the limit as &lt;math&gt;\Delta t \to 0&lt;/math&gt; of the right-hand side of this expression yields

:&lt;math&gt;F_y - \frac{\mathrm{d}}{\mathrm{d}t}F_{y'} = 0.&lt;/math&gt;

The left hand side of the previous equation is the [[functional derivative]] &lt;math&gt;\delta J/\delta y&lt;/math&gt; of the functional &lt;math&gt;J&lt;/math&gt;. A necessary condition for a differentiable functional to have an extremum on some function is that its functional derivative at that function vanishes, which is granted by the last equation.
|}

==Examples==
A standard example is finding the real-valued function ''f'' on the interval [''a'', ''b''], such that ''f''(''a'') = ''c'' and ''f''(''b'') = ''d'', for which the  [[path (topology) | path]]  [[arc length|length]] along the [[Curve#length of a curve|curve]] traced by ''f'' is as short as possible. 
:&lt;math&gt; \text{s} = \int_{a}^{b} \sqrt{1+y'^2}\,\mathrm{d}x,&lt;/math&gt;
the integrand function being {{nowrap|1=''L''(''x'', ''y'', ''y''′) = {{radic|1 + ''y''′ ²}}}} .

The partial derivatives of ''L'' are:
:&lt;math&gt;\frac{\partial L(x, y, y')}{\partial y'} = \frac{y'}{\sqrt{1 + y'^2}} \quad \text{and} \quad
\frac{\partial L(x, y, y')}{\partial y} = 0.&lt;/math&gt;
By substituting these into the Euler–Lagrange equation, we obtain
:&lt;math&gt; 
\begin{align}
\frac{\mathrm{d}}{\mathrm{d}x} \frac{y'(x)}{\sqrt{1 + (y'(x))^2}} &amp;= 0 \\ 
\frac{y'(x)}{\sqrt{1 + (y'(x))^2}} &amp;= C = \text{constant} \\
\Rightarrow y'(x)&amp;= \frac{C}{\sqrt{1-C^2}} := A \\
\Rightarrow y(x) &amp;= Ax + B
\end{align}
&lt;/math&gt;
that is, the function must have constant first derivative, and thus its [[graph of a function|graph]] is a [[straight line]].

==Generalizations for several functions, several variables, and higher derivatives==

===Single function of single variable with higher derivatives===
The stationary values of the functional
:&lt;math&gt;
   I[f] = \int_{x_0}^{x_1} \mathcal{L}(x, f, f', f'', \dots, f^{(k)})~\mathrm{d}x ~;~~ 
     f' := \cfrac{\mathrm{d}f}{\mathrm{d}x}, ~f'' := \cfrac{\mathrm{d}^2f}{\mathrm{d}x^2}, ~
     f^{(k)} := \cfrac{\mathrm{d}^kf}{\mathrm{d}x^k}
 &lt;/math&gt;
can be obtained from the Euler–Lagrange equation&lt;ref name=Courant&gt;{{cite book | last1=Courant | first1=R | authorlink1=Richard Courant | last2=Hilbert | first2=D | authorlink2=David Hilbert | title = Methods of Mathematical Physics | volume = Vol. I | edition = First English | ref=harv | publisher = Interscience Publishers, Inc | year = 1953 | location = New York | isbn = 978-0471504474}}&lt;/ref&gt; 
:&lt;math&gt;
   \cfrac{\partial \mathcal{L}}{\partial f} - \cfrac{\mathrm{d}}{\mathrm{d} x}\left(\cfrac{\partial \mathcal{L}}{\partial f'}\right) + \cfrac{\mathrm{d}^2}{\mathrm{d} x^2}\left(\cfrac{\partial \mathcal{L}}{\partial f''}\right) - \dots +
  (-1)^k \cfrac{\mathrm{d}^k}{\mathrm{d} x^k}\left(\cfrac{\partial \mathcal{L}}{\partial f^{(k)}}\right)  = 0 
 &lt;/math&gt;
under fixed boundary conditions for the function itself as well as for the first &lt;math&gt;k-1&lt;/math&gt; derivatives (i.e. for all &lt;math&gt;f^{(i)}, i \in \{0, ..., k-1\}&lt;/math&gt;). The endpoint values of the highest derivative &lt;math&gt;f^{(k)}&lt;/math&gt; remain flexible.

===Several functions of single variable with single derivative===
If the problem involves finding several functions (&lt;math&gt;f_1, f_2, \dots, f_m&lt;/math&gt;) of a single independent variable (&lt;math&gt;x&lt;/math&gt;) that define an extremum of the functional
:&lt;math&gt;
    I[f_1,f_2, \dots, f_m] = \int_{x_0}^{x_1} \mathcal{L}(x, f_1, f_2, \dots, f_m, f_1', f_2', \dots, f_m')~\mathrm{d}x
    ~;~~ f_i' := \cfrac{\mathrm{d}f_i}{\mathrm{d}x}
 &lt;/math&gt;
then the corresponding Euler–Lagrange equations are&lt;ref name=Weinstock&gt;{{cite book |last=Weinstock |first=R. |year=1952 |title=Calculus of Variations with Applications to Physics and Engineering |publisher=McGraw-Hill |location=New York }}&lt;/ref&gt;
:&lt;math&gt;
   \begin{align}
     \frac{\partial \mathcal{L}}{\partial f_i} - \frac{\mathrm{d}}{\mathrm{d}x}\left(\frac{\partial \mathcal{L}}{\partial f_i'}\right) = 0_i 
   \end{align}
&lt;/math&gt;

===Single function of several variables with single derivative===
A multi-dimensional generalization comes from considering a function on n variables. If &lt;math&gt;\Omega&lt;/math&gt; is some surface, then

: &lt;math&gt; 
   I[f] = \int_{\Omega} \mathcal{L}(x_1, \dots , x_n, f, f_{, 1}, \dots , f_{, n})\, \mathrm{d}\mathbf{x}\,\! ~;~~
      f_{, j} := \cfrac{\partial f}{\partial x_j}
&lt;/math&gt;

is extremized only if ''f'' satisfies the [[partial differential equation]]

: &lt;math&gt; \frac{\partial \mathcal{L}}{\partial f} - \sum_{j=1}^{n} \frac{\partial}{\partial x_j}\left(\frac{\partial \mathcal{L}}{\partial f_{, j}}\right) = 0. &lt;/math&gt;

When ''n'' = 2 and functional &lt;math&gt;\mathcal I&lt;/math&gt; is the [[energy functional]], this leads to the soap-film [[minimal surface]] problem.

===Several functions of several variables with single derivative===
If there are several unknown functions to be determined and several variables such that
: &lt;math&gt; 
   I[f_1,f_2,\dots,f_m] = \int_{\Omega} \mathcal{L}(x_1, \dots , x_n, f_1, \dots, f_m, f_{1,1}, \dots , f_{1,n},  \dots, f_{m,1}, \dots, f_{m,n}) \, \mathrm{d}\mathbf{x}\,\! ~;~~
      f_{i,j} := \cfrac{\partial f_i}{\partial x_j}
&lt;/math&gt;
the system of Euler–Lagrange equations is&lt;ref name=Courant/&gt;
: &lt;math&gt; 
  \begin{align}
    \frac{\partial \mathcal{L}}{\partial f_1} - \sum_{j=1}^{n} \frac{\partial}{\partial x_j}\left(\frac{\partial \mathcal{L}}{\partial f_{1,j}}\right) &amp;= 0_1 \\
    \frac{\partial \mathcal{L}}{\partial f_2} - \sum_{j=1}^{n} \frac{\partial}{\partial x_j}\left(\frac{\partial \mathcal{L}}{\partial f_{2,j}}\right) &amp;= 0_2 \\
    \vdots \qquad \vdots \qquad &amp;\quad \vdots  \\
    \frac{\partial \mathcal{L}}{\partial f_m} - \sum_{j=1}^{n} \frac{\partial}{\partial x_j}\left(\frac{\partial \mathcal{L}}{\partial f_{m,j}}\right) &amp;= 0_m.
  \end{align}
 &lt;/math&gt;

===Single function of two variables with higher derivatives===
If there is a single unknown function ''f'' to be determined that is dependent on two variables ''x''&lt;sub&gt;1&lt;/sub&gt; and ''x''&lt;sub&gt;2&lt;/sub&gt; and if the functional depends on higher derivatives of ''f'' up to ''n''-th order such that
: &lt;math&gt;
   \begin{align}
     I[f] &amp; = \int_{\Omega} \mathcal{L}(x_1, x_2, f, f_{,1}, f_{,2}, f_{,11}, f_{,12}, f_{,22},
                                        \dots, f_{,22\dots 2})\, \mathrm{d}\mathbf{x} \\
     &amp; \qquad \quad
        f_{,i} := \cfrac{\partial f}{\partial x_i} \; , \quad
        f_{,ij} := \cfrac{\partial^2 f}{\partial x_i\partial x_j} \; , \;\; \dots
   \end{align}
&lt;/math&gt;
then the Euler–Lagrange equation is&lt;ref name=Courant/&gt;
:&lt;math&gt;
  \begin{align}
    \frac{\partial \mathcal{L}}{\partial f}
    &amp; - \frac{\partial}{\partial x_1}\left(\frac{\partial \mathcal{L}}{\partial f_{,1}}\right)
      - \frac{\partial}{\partial x_2}\left(\frac{\partial \mathcal{L}}{\partial f_{,2}}\right) 
      + \frac{\partial^2}{\partial x_1^2}\left(\frac{\partial \mathcal{L}}{\partial f_{,11}}\right)
      + \frac{\partial^2}{\partial x_1\partial x_2}\left(\frac{\partial \mathcal{L}}{\partial f_{,12}}\right)
      + \frac{\partial^2}{\partial x_2^2}\left(\frac{\partial \mathcal{L}}{\partial f_{,22}}\right) \\
    &amp; - \dots
      + (-1)^k \frac{\partial^k}{\partial x_2^k}\left(\frac{\partial \mathcal{L}}{\partial f_{,22\dots 2}}\right) = 0
  \end{align}
 &lt;/math&gt;
which can be represented shortly as:
:&lt;math&gt;
    \frac{\partial \mathcal{L}}{\partial f} +\sum_{j=1}^n \sum_{\mu_1 \leq \ldots \leq \mu_j} (-1)^j \frac{\partial^j}{\partial x_{\mu_{1}}\dots \partial x_{\mu_{j}}} \left( \frac{\partial \mathcal{L} }{\partial f_{,\mu_1\dots\mu_j}}\right)=0
 &lt;/math&gt;
wherein &lt;math&gt;\mu_1 \dots \mu_j&lt;/math&gt; are indices that span the number of variables, that is, here they go from 1 to 2. Here summation over the &lt;math&gt;\mu_1 \dots \mu_j&lt;/math&gt; indices is only over &lt;math&gt;\mu_1 \leq \mu_2 \leq \ldots \leq \mu_j&lt;/math&gt; in order to avoid counting the same partial derivative multiple times, for example &lt;math&gt;f_{,12} = f_{,21}&lt;/math&gt; appears only once in the previous equation.

===Several functions of several variables with higher derivatives===
If there are ''p'' unknown functions ''f''&lt;sub&gt;i&lt;/sub&gt; to be determined that are dependent on ''m'' variables ''x''&lt;sub&gt;1&lt;/sub&gt; ... ''x''&lt;sub&gt;m&lt;/sub&gt; and if the functional depends on higher derivatives of the ''f''&lt;sub&gt;i&lt;/sub&gt; up to ''n''-th order such that
:&lt;math&gt;
   \begin{align}
     I[f_1,\ldots,f_p] &amp; = \int_{\Omega} \mathcal{L}(x_1, \ldots, x_n; f_1,\ldots,f_p; f_{1,1},\ldots,
     f_{p,m}; f_{1,11},\ldots, f_{p,mm};\ldots; f_{p,m\ldots m})\, \mathrm{d}\mathbf{x} \\
     &amp; \qquad \quad
        f_{i,\mu} := \cfrac{\partial f_i}{\partial x_\mu} \; , \quad
        f_{i,\mu_1\mu_2} := \cfrac{\partial^2 f_i}{\partial x_{\mu_1}\partial x_{\mu_2}} \; , \;\; \dots
   \end{align}
&lt;/math&gt;

where &lt;math&gt;\mu_1 \dots \mu_j&lt;/math&gt; are indices that span the number of variables, that is they go from 1 to m. Then the Euler–Lagrange equation is

:&lt;math&gt;
    \frac{\partial \mathcal{L}}{\partial f_i} +\sum_{j=1}^n \sum_{\mu_1 \leq \ldots \leq \mu_j} (-1)^j \frac{\partial^j}{\partial x_{\mu_{1}}\dots \partial x_{\mu_{j}}} \left( \frac{\partial \mathcal{L} }{\partial f_{i,\mu_1\dots\mu_j}}\right)=0
 &lt;/math&gt;

where the summation over the &lt;math&gt;\mu_1 \dots \mu_j&lt;/math&gt; is avoiding counting the same derivative &lt;math&gt; f_{i,\mu_1\mu_2} = f_{i,\mu_2\mu_1}&lt;/math&gt; several times, just as in the previous subsection. This can be expressed more compactly as

:&lt;math&gt;
\sum_{j=0}^n \sum_{\mu_1 \leq \ldots \leq \mu_j} (-1)^j \partial_{ \mu_{1}\ldots \mu_{j} }^j \left( \frac{\partial \mathcal{L} }{\partial f_{i,\mu_1\dots\mu_j}}\right)=0
 &lt;/math&gt;

==Generalization to manifolds==
Let &lt;math&gt;M&lt;/math&gt; be a [[smooth manifold]], and let &lt;math&gt;C^\infty([a,b])&lt;/math&gt; denote the space of [[smooth functions]] &lt;math&gt;f:[a,b]\to M&lt;/math&gt;. Then, for functionals &lt;math&gt;S:C^\infty ([a,b])\to \mathbb{R}&lt;/math&gt; of the form
:&lt;math&gt;
S[f]=\int_a^b (L\circ\dot{f})(t)\,\mathrm{d} t
&lt;/math&gt;
where &lt;math&gt;L:TM\to\mathbb{R}&lt;/math&gt; is the Lagrangian, the statement &lt;math&gt;\mathrm{d} S_f=0&lt;/math&gt; is equivalent to the statement that, for all &lt;math&gt;t\in [a,b]&lt;/math&gt;, each coordinate frame [[fiber bundle|trivialization]] &lt;math&gt;(x^i,X^i)&lt;/math&gt; of a neighborhood of &lt;math&gt;\dot{f}(t)&lt;/math&gt; yields the following &lt;math&gt;\dim M&lt;/math&gt; equations:
:&lt;math&gt;
\forall i:\frac{\mathrm{d}}{\mathrm{d}t}\frac{\partial F}{\partial X^i}\bigg|_{\dot{f}(t)}=\frac{\partial F}{\partial x^i}\bigg|_{\dot{f}(t)}
&lt;/math&gt;

==See also==
{{Wiktionary|Euler–Lagrange equation}}
*[[Lagrangian mechanics]]
*[[Hamiltonian mechanics]]
*[[Analytical mechanics]]
*[[Beltrami identity]]
*[[Functional derivative]]

==Notes==
{{reflist}}

==References==
* {{springer|title=Lagrange equations (in mechanics)|id=p/l057150}}
* {{mathworld|urlname=Euler-LagrangeDifferentialEquation|title=Euler-Lagrange Differential Equation}}
* {{planetmathref |id=1995|title=Calculus of Variations}}
* {{cite book |last=Gelfand |first=Izrail Moiseevich |authorlink=Israel Gelfand |title=Calculus of Variations |publisher=Dover |year=1963 |isbn=0-486-41448-5}}
* Roubicek, T.: ''[http://www.wiley-vch.de/books/sample/3527411887_c17.pdf Calculus of variations]. Chap.17 in: [http://www.wiley-vch.de/publish/en/books/forthcomingTitles/MA00/3-527-41188-7/?sID=nrgsqk516u2v9ffab8u7io1dq4 Mathematical Tools for Physicists]. (Ed. M. Grinfeld) J. Wiley, Weinheim, 2014, {{ISBN|978-3-527-41188-7}}, pp.551-588.

{{DEFAULTSORT:Euler-Lagrange Equation}}
[[Category:Ordinary differential equations]]
[[Category:Partial differential equations]]
[[Category:Calculus of variations]]
[[Category:Articles containing proofs]]
[[Category:Leonhard Euler]]</text>
      <sha1>5nl0cz56c1xo7rqbrh8xityipr16toi</sha1>
    </revision>
  </page>
  <page>
    <title>Foundations of Differential Geometry</title>
    <ns>0</ns>
    <id>36727478</id>
    <revision>
      <id>832424524</id>
      <parentid>784716809</parentid>
      <timestamp>2018-03-25T22:55:16Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>copyedit, add wikilinks</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2615">{{italic title}}
'''''Foundations of Differential Geometry''''' is an influential 2-volume mathematics book on [[differential geometry]] written by [[Shoshichi Kobayashi]] and [[Katsumi Nomizu]]. The first volume was published in 1963 and the second in 1969, by Interscience Publishers. Both were published again in 1996 as Wiley Classics Library.

The first volume considers [[manifold]]s, [[fiber bundle]]s, [[tensor analysis]], [[connection (mathematics)|connections in bundles]], and the role of [[Lie group]]s. It also covers [[holonomy]], the [[de Rham decomposition theorem]] and the [[Hopf–Rinow theorem]]. According to the review of [[James Eells]], it has a "fine expositional style" and consists of a "special blend of algebraic, analytic, and geometric concepts". Eells says it is "essentially a [[textbook]] (even though there are no [[exercise (mathematics)|exercise]]s)". An advanced text, it has a "pace geared to a [one] term graduate course".

The second volume considers [[submanifold]]s of [[Riemannian manifold]]s, the [[Gauss map]], and the [[second fundamental form]]. It continues with [[geodesic]]s on Riemannian manifolds, [[Jacobi field]]s, the [[Morse index]], the [[Rauch comparison theorem]]s, and the [[Cartan–Hadamard theorem]]. Then it ascends to [[complex manifold]]s, [[Kähler manifold]]s, [[homogeneous space]]s, and [[symmetric space]]s. In a discussion of [[Riemann curvature tensor|curvature]]  representation of [[characteristic class]]es of [[principal bundle]]s ([[Chern–Weil theory]]), it covers [[Euler class]]es, [[Chern class]]es, and [[Pontryagin class]]es. The second volume also received a favorable review by J. Eells in ''Mathematical Reviews''.

== References ==
*S. Kobayashi, K. Nomizu. ''Foundations of Differential Geometry'' (Wiley Classics Library) Volume 1.
*S. Kobayashi, K. Nomizu. ''Foundations of Differential Geometry'' (Wiley Classics Library) Volume 2, {{ISBN|0-470-49648-7}}
*J. Eells (1963) [http://www.ams.org/mathscinet/pdf/0152974.pdf Review of Volume 1] from [[Mathematical Reviews]]
*{{cite journal|author=Hermann, Robert|authorlink=Robert Hermann (mathematician)|title=Review: ''Foundations of differential geometry'', Volume 1|journal=[[Bulletin of the American Mathematical Society]]|year=1964|volume=70|issue=2|pages=232–235|url=http://www.ams.org/journals/bull/1964-70-02/S0002-9904-1964-11094-6/|doi=10.1090/s0002-9904-1964-11094-6}}
*J. Eells (1969) [http://www.ams.org/mathscinet/pdf/0238225.pdf Review of Volume 2] from Mathematical Reviews

[[Category:Mathematics textbooks]]
[[Category:1963 books]]
[[Category:1969 books]]</text>
      <sha1>cnapxg6msq4eisq0zi6h1f37yemfz1j</sha1>
    </revision>
  </page>
  <page>
    <title>Geometry of roots of real polynomials</title>
    <ns>0</ns>
    <id>23574973</id>
    <revision>
      <id>777723804</id>
      <parentid>777719941</parentid>
      <timestamp>2017-04-28T21:21:07Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/BigJohnHenry|BigJohnHenry]] ([[User talk:BigJohnHenry|talk]]): Per [[WP:ELNO]]. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6644">{{Orphan|date=May 2014}}

[[Image:Polynomialdeg5.png|thumb|right|300px|Polynomial of degree 5:&lt;br&gt;{{nowrap|''ƒ''(''x'') {{=}} 1/20 (''x'' + 4)(''x'' + 2)·}} {{nowrap|·(''x'' + 1)(''x'' − 1)(''x'' − 3) + 2}}]]

[[Graph of a function|Graphical]] [[List of graphical methods|method]]s provide a means of determining or approximating the [[root of a function|roots]] of a [[polynomial]]—the values that make the polynomial equal to zero.&lt;ref&gt;{{citation| title=Graphical Representation of Complex Roots |author=James A. Ward |journal=National Mathematics Magazine |volume=11 |date=April 1937 |pages=297–303 |issue=7| doi=10.2307/3028785}}&lt;/ref&gt; Practical tools for performing these include [[graph paper]], [[graphical calculator]]s and [[computer graphics]].&lt;ref&gt;{{citation |title=Determining Roots of Complex Functions with Computer Graphics |author=Robert Kowalski, Helen Skala |journal=Coll. Micro. |year=1990 |volume=VIII |pages=51–54 |issue=1}}&lt;/ref&gt;

The [[fundamental theorem of algebra]] states that a ''n''th-degree polynomial with complex coefficients (including real coefficients) has ''n'' complex roots (not necessarily real even if the coefficients are real), although its roots may not all be different from each other.  If the polynomial has real coefficients, its roots are either real, or else occur as [[complex conjugate]]s.  Suppose a polynomial ''P''(''x'') is graphed as ''y'' =&amp;nbsp;''P''(''x'').  At a real root, the graph of the polynomial crosses the ''x''-axis.  Thus, the real roots of a polynomial can be demonstrated graphically.&lt;ref&gt;{{citation |title=A graphical approach to understanding the fundamental theorem of algebra |author=Sudhir Kumar Goel, Denise T. Reid. |journal=Mathematics Teacher |date=December 2001 |volume=94 |issue=9 |page=749}}&lt;/ref&gt;

For some kinds of polynomials, all the roots, including the complex roots, can  be found graphically. Polynomial equations up to the fifth degree may be solved graphically.&lt;ref&gt;Henriquez, Garcia, "The graphical interpretation of the complex roots of cubic equations," ''[[American Mathematical Monthly]]'' 42(6), June–July 1935, 383-384.&lt;/ref&gt;&lt;ref name=Yanosik&gt;{{citation| title=Graphical Solutions for Complex Roots of Quadratics, Cubics and Quartics |author=George A. Yanosik |journal=National Mathematics Magazine |volume=17 |date=January 1943 |pages=147–150 |issue=4| doi=10.2307/3028335}}&lt;/ref&gt;&lt;ref&gt;{{citation |journal=The Quarterly Journal of Mathematics |year=1934 |doi=10.1093/qmath/os-5.1.10 |publisher=Oxford University Press |title=On the number of real roots of a quintic equation |author=T.W.Chaundy |volume=os-5 |pages=10–22}}&lt;/ref&gt;

The [[geometry|geometrical]] methods of [[compass and straightedge constructions|ruler and compass]] may be used to solve any [[linear equation|linear]] or [[quadratic equation]].  [[Descartes]] showed that the constructions of [[Euclid]] were equivalent to the [[algebra]]ic solution of quadratics.&lt;ref&gt;{{citation |pages=120 et seq. |title= Geometry: Euclid and beyond |author=[[Robin Hartshorne]] |url=https://books.google.com/books?id=EJCSL9S6la0C |isbn= 978-0-387-98650-0 |year=2000}}&lt;/ref&gt;

[[Cubic equations]] may be solved by [[solid geometry]].  [[Archimedes]]' work ''On the Sphere and the Cylinder'' provided solutions of some cubics and [[Omar Khayyam]] systematised this to provide geometrical solutions of all quadratics and cubics.&lt;ref&gt;{{citation |url=https://books.google.co.uk/books?id=4miP1_qN7aoC |chapter=ch. III Latency |title=The emergence of number |author=John N. Crossley |isbn=978-9971-5-0414-4 |year=1987}}&lt;/ref&gt;

==Complex roots of quadratic polynomials==
For polynomials with real coefficients, a local minimum point above the ''x''-axis or a local maximum point below the ''x''-axis indicates the existence of two non-real [[complex number|complex]] roots, which are each other's complex conjugates.&lt;ref&gt;{{citation|title=From Cardano's Great Art to Lagrange's Reflections: Filling a Gap in the History of Algebra|series=Heritage of European mathematics|first=Jacqueline A.|last=Stedall|publisher=European Mathematical Society|year=2011|isbn=9783037190920|page=97|url=https://books.google.com/books?id=VQ-eI3EHBD4C&amp;pg=PA97}}.&lt;/ref&gt; The converse, however, is not true; for example, the cubic polynomial ''x''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''x'' has two complex roots, but its graph has no local minima or maxima.

The simplest such case involves parabolas.

[[Image:Visual.complex.root.finding.png|300px|right|thumb|A second-degree polynomial function whose ''x'' intercepts are not real: {{nowrap|''y'' {{=}} (''x'' − 5)&lt;sup&gt;2&lt;/sup&gt; + 9}}. The "3" is the imaginary part of the ''x''-intercept. The real part is the ''x''-coordinate of the vertex. Thus the roots are {{nowrap|5 ± 3''i''}}.]]

If a parabola has a global minimum point above the ''x''-axis, or a global maximum point below the ''x''-axis, then its ''x'' intercepts are not real.  For

: &lt;math&gt; y = a(x - h)^2 + k, \, &lt;/math&gt;

if ''a'' and ''k'' are positive, then the roots are non-real complex numbers.  The number&amp;nbsp;''k'' is then the height of the vertex above the ''x''-axis.  In the example in the illustration, we have&amp;nbsp;''k''&amp;nbsp;=&amp;nbsp;9.  Suppose one goes ''k''&amp;nbsp;units in the opposite direction from the vertex, i.e. away from the ''x''-axis, then horizontally as far as it takes to reach the curve (in the example, that distance is&amp;nbsp;3.  The horizontal distance from that point to the curve is the absolute value of the imaginary part of the root.&lt;ref name = "Norton1984"&gt;{{citation |title=Complex Roots Made Visible |author=Alec Norton, Benjamin Lotto |journal=The College Mathematics Journal |volume=15 |date=June 1984 |pages=248–249 |issue=3 |doi=10.2307/2686333}}&lt;/ref&gt;  The ''x''-coordinate of the vertex is the real part.&lt;ref name = "Norton1984"/&gt; Thus, in the example, the roots are&lt;ref name = "Norton1984"/&gt;
: &lt;math&gt; 5 \pm 3i. \, &lt;/math&gt;

This method is specific to quadratics and does not generalise to higher-degree polynomial equations.

==See also==

[[Cubic function#Geometric interpretation of the roots]]

==References==
{{reflist}}

==External links==
* [http://www.math.hmc.edu/funfacts/ffiles/10005.1.shtml ''Complex roots made visible'' at Mudd Math Fun Facts]
* [http://www.nctm.org/eresources/view_article.asp?article_id=6168 ''Connecting complex roots to a parabola's graph'' at ON-Math]
* [http://mathforum.org/library/drmath/view/53808.html ''Complex Roots'' at Dr. Math]. With comments by [[John Horton Conway|John Conway]]

{{DEFAULTSORT:Graphical Methods Of Finding Polynomial Roots}}
[[Category:Elementary algebra]]
[[Category:Root-finding algorithms]]</text>
      <sha1>c4exd5v8j4rhd54h7f8yrafnhi0vdmq</sha1>
    </revision>
  </page>
  <page>
    <title>Gibbons–Hawking ansatz</title>
    <ns>0</ns>
    <id>35132005</id>
    <revision>
      <id>797753663</id>
      <parentid>750176421</parentid>
      <timestamp>2017-08-29T00:04:01Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[Wikipedia:Bots/Requests for approval/KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1768">{{Technical|date=December 2012}}
In mathematics, the '''Gibbons–Hawking ansatz''' is a method of constructing [[gravitational instanton]]s introduced by {{harvs|txt|last=Gibbons|first=Gary|author1-link=Gary Gibbons|first2=Stephen|last2=Hawking|author2-link=Stephen Hawking|year1=1978|year2=1979}}. It gives examples of [[hyperkähler manifold]]s in dimension 4 that are invariant under a [[circle action]].

== See also ==
* [[Gibbons–Hawking space]]

==References==
* {{Citation | last1=Gibbons | first1=G.W. | last2=Hawking | first2=S. W. | author2-link=Stephen Hawking | title=Gravitational multi-instantons     | doi=10.1016/0370-2693(78)90478-1 | year=1978 | journal=Physics Letters B | issn=0370-2693 | volume=78 | issue=4 | pages=430–432|bibcode = 1978PhLB...78..430G }}
* {{Citation | last1=Gibbons | first1=G. W. | last2=Hawking | first2=S. W. | author2-link=Stephen Hawking | title=Classification of gravitational instanton symmetries | url=http://projecteuclid.org/getRecord?id=euclid.cmp/1103905051 |mr=535152 | year=1979 | journal=Communications in Mathematical Physics | issn=0010-3616 | volume=66 | issue=3 | pages=291–310 | doi=10.1007/bf01197189|bibcode = 1979CMaPh..66..291G }}
* {{Citation | last1=Gonzalo Pérez | first1=Jesús | last2=Geiges | first2=Hansjörg | title=A homogeneous Gibbons–Hawking ansatz and Blaschke products | url=https://dx.doi.org/10.1016/j.aim.2010.05.006 | doi=10.1016/j.aim.2010.05.006 |mr=2680177 | year=2010 | journal=Advances in Mathematics | issn=0001-8708 | volume=225 | issue=5 | pages=2598–2615}}

{{Stephen Hawking}}

{{DEFAULTSORT:Gibbons-Hawking ansatz}}
[[Category:1978 introductions]]
[[Category:Differential geometry]]
[[Category:General relativity]]
[[Category:Stephen Hawking]]

{{physics-stub}}</text>
      <sha1>edb9b0mv4vzk7zmm9wq8y4qc6r6i0hc</sha1>
    </revision>
  </page>
  <page>
    <title>Graph algebra (social sciences)</title>
    <ns>0</ns>
    <id>27145862</id>
    <revision>
      <id>798580472</id>
      <parentid>657002180</parentid>
      <timestamp>2017-09-02T18:42:22Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>adding a link using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="827">'''Graph algebra''' is [[systems-centric]] modeling tool for the [[social sciences]].&lt;ref&gt;{{citation|title=Graph Algebra: Mathematical Modeling With a Systems Approach|volume=151|series=Quantitative Applications in the Social Sciences|first=Courtney|last=Brown|publisher=SAGE|year=2008|isbn=9781412941099|url=https://books.google.com/books?id=pLuuYWK5V4oC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false}}.&lt;/ref&gt;  It was first developed by Sprague, Pzeworski, and Cortes&lt;ref&gt;Cortés, Fernando, Adam Przeworski, and John Sprague. 1974. Systems Analysis for Social Scientists. New York: John Wiley &amp; Sons.&lt;/ref&gt; as a hybridized version of engineering plots to describe social phenomena.

== Notes and references ==

{{Reflist}}

{{DEFAULTSORT:Graph Algebra (Social Sciences)}}
[[Category:Algebra]]
[[Category:Social science methodology]]</text>
      <sha1>rbixckwbs0wqzunivujt72oot9yurtp</sha1>
    </revision>
  </page>
  <page>
    <title>Graph operations</title>
    <ns>0</ns>
    <id>9938244</id>
    <revision>
      <id>841550729</id>
      <parentid>841493172</parentid>
      <timestamp>2018-05-16T14:37:36Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4551">'''Graph operations''' produce new [[Graph (discrete mathematics)|graph]]s from initial ones. They may be separated into the following major categories.  

==Unary operations==
Unary operations create a new graph from one initial one.

===Elementary operations===
Elementary operations or editing operations create a new graph from one initial one by a simple local change, such as addition or deletion of a vertex or of an edge, merging and splitting of vertices, [[edge contraction]], etc.
The [[graph edit distance]] between a pair of graphs is the minimum number of elementary operations required to transform one graph into the other.

===Advanced operations===
Advanced operations create a new graph from one initial one by a complex changes, such as:
* [[transpose graph]];
* [[complement graph]];
* [[line graph]];
* [[graph minor]];
* [[graph rewriting]];
* [[power of graph]];
* [[dual graph]];
* [[medial graph]];
* [[quotient graph]];
* [[Y-Δ transform]];
* [[Mycielskian]].

==Binary operations==
Binary operations create a new graph from two initial ones {{nobreak|1=''G''&lt;sub&gt;1&lt;/sub&gt; = (''V''&lt;sub&gt;1&lt;/sub&gt;, ''E''&lt;sub&gt;1&lt;/sub&gt;)}} and {{nobreak|1=''G''&lt;sub&gt;2&lt;/sub&gt; = (''V''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;2&lt;/sub&gt;)}}, such as:
* graph union: {{nobreak|1=''G''&lt;sub&gt;1&lt;/sub&gt; ∪ ''G''&lt;sub&gt;2&lt;/sub&gt;}}.  There are two definitions.  In the most common one, the [[disjoint union of graphs]], the union is assumed to be disjoint.  Less commonly (though more consistent with the general definition of [[union (set theory)|union]] in mathematics) the union of two graphs is defined as the graph {{nobreak|(''V''&lt;sub&gt;1&lt;/sub&gt; ∪ ''V''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;1&lt;/sub&gt; ∪ ''E''&lt;sub&gt;2&lt;/sub&gt;)}}.

* graph intersection: {{nobreak|1=''G''&lt;sub&gt;1&lt;/sub&gt; ∩ ''G''&lt;sub&gt;2&lt;/sub&gt; = (''V''&lt;sub&gt;1&lt;/sub&gt; ∩ ''V''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;1&lt;/sub&gt; ∩ ''E''&lt;sub&gt;2&lt;/sub&gt;)}};&lt;ref name=bondy_murty&gt;{{cite book
 | last1 = Bondy | first1 = J. A.
 | last2 = Murty | first2 = U. S. R.
 | title = Graph Theory
 | publisher = Springer
 | series = Graduate Texts in Mathematics
 | date = 2008
 | pages = 29
 | isbn = 978-1-84628-969-9}}&lt;/ref&gt;
* graph join: graph with all the edges that connect the vertices of the first graph with the vertices of the second graph. It is a commutative operation (for unlabelled graphs);&lt;ref name=harary/&gt;
* [[graph products]] based on the [[cartesian product]] of the vertex sets:
** [[Cartesian product of graphs|cartesian graph product]]: it is a commutative and associative operation (for unlabelled graphs),&lt;ref name=harary&gt;[[Frank Harary|Harary, F]]. ''Graph Theory''. Reading, MA: Addison-Wesley, 1994.&lt;/ref&gt;
** [[Lexicographic product of graphs|lexicographic graph product]] (or graph composition): it is an associative (for unlabelled graphs) and non-commutative operation,&lt;ref name=harary/&gt;
** [[Strong product of graphs|strong graph product]]: it is a commutative and associative operation (for unlabelled graphs),
** [[Tensor product of graphs|tensor graph product]] (or direct graph product, categorical graph product, cardinal graph product, Kronecker graph product): it is a commutative and associative operation (for unlabelled graphs),
** [[Zig-zag product of graphs|zig-zag graph product]];&lt;ref&gt;{{cite journal
 |author1=Reingold, O. |author2=Vadhan, S. |author3=Wigderson, A. | title = Entropy waves, the zig-zag graph product, and new constant-degree expanders
 | journal = [[Annals of Mathematics]]
 | volume = 155
 | issue = 1
 | year = 2002
 | pages = 157–187
 |mr=1888797
 | doi = 10.2307/3062153
 | jstor = 3062153|arxiv=math/0406038}}&lt;/ref&gt;
* graph product based on other products:
** [[Rooted product of graphs|rooted graph product]]: it is an associative operation (for unlabelled but rooted graphs),
** [[Corona product of graphs|corona graph product]]: it is a non-commutative operation;&lt;ref&gt;{{cite journal | last1 = Frucht | first1 = Robert | authorlink = Robert Frucht | authorlink2 = Frank Harary | last2 = Harary | first2 = Frank | year = 1970 | title = On the corona of two graphs | url = | journal = [[Aequationes Mathematicae]] | volume = 4 | issue = | pages = 322–324 | doi=10.1007/bf01844162}}&lt;/ref&gt;
* [[Series-parallel graph|series-parallel graph composition]]:
** parallel graph composition: it is a commutative operation (for unlabelled graphs),
** series graph composition: it is a non-commutative operation,
** source graph composition: it is a commutative operation (for unlabelled graphs);
* [[Hajós construction]].

==Notes==
&lt;references/&gt;

{{DEFAULTSORT:Graph Operations}}
[[Category:Graph operations|*]]</text>
      <sha1>1ezxx47o14xvsd26lrsefa0w95jxvnu</sha1>
    </revision>
  </page>
  <page>
    <title>Group key</title>
    <ns>0</ns>
    <id>6763077</id>
    <revision>
      <id>791518370</id>
      <parentid>791445934</parentid>
      <timestamp>2017-07-20T20:03:26Z</timestamp>
      <contributor>
        <username>Onel5969</username>
        <id>10951369</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Classical education]] (link changed to [[Classics]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1900">{{Orphan|date=February 2009}}
In [[cryptography]], a '''group key''' is a [[cryptographic key]] that is shared between a group of users. Typically, group keys are distributed by sending them to individual users, either physically, or encrypted individually for each user using either that user's pre-distributed private key.

A common use of group keys is to allow a group of users to decrypt a broadcast message that is intended for that entire group of users, and no-one else. 

For example, in the [[Second World War]], group keys (known as "iodoforms", a term invented by a [[Classics|classically educated]] non-chemist, and nothing to do with the [[iodoform|chemical of the same name]]&lt;ref name="chempdf"&gt;Richard Clayton, ''Hiding: Anonymity Systems'', http://www.cl.cam.ac.uk/~rnc1/notes/AT02_hiding.pdf, lecture notes, 2002.&lt;/ref&gt;) were sent to groups of agents by the [[Special Operations Executive]]. These group keys allowed all the agents in a particular group to receive a single coded message.
&lt;ref name="marks"&gt;''Between Silk and Cyanide – a Codemaker’s War 1941-1945'', [[Leo Marks]], HarperCollins 1998.
&lt;/ref&gt;
&lt;ref name="rja14"&gt;Ross Anderson, ''Security Engineering: A Guide to Building Dependable Distributed Systems'', chapter 20, page 428, Wiley 2001, {{ISBN|0-471-38922-6}} (paperback, 641pp.) Available online at http://www.cl.cam.ac.uk/~rja14/book.html&lt;/ref&gt;

In present-day applications, group keys are commonly used in [[conditional access]] systems, where the key is the common key used to decrypt the broadcast signal, and the group in question is the group of all paying subscribers. In this case, the group key is typically distributed to the subscribers' receivers using a combination of a physically distributed [[secure cryptoprocessor]] in the form of a [[smartcard]] and encrypted over-the-air messages.

== References ==
&lt;references/&gt;

[[Category:Cryptography]]</text>
      <sha1>b0esnhvxd8bbtt609plgmm8x5896bf9</sha1>
    </revision>
  </page>
  <page>
    <title>Gödel's completeness theorem</title>
    <ns>0</ns>
    <id>12450</id>
    <revision>
      <id>864239384</id>
      <parentid>863781394</parentid>
      <timestamp>2018-10-16T00:33:17Z</timestamp>
      <contributor>
        <username>Tim Smith</username>
        <id>107315</id>
      </contributor>
      <minor/>
      <comment>/* Relationship to the compactness theorem */ "deductive system" for consistency with rest of article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14479">[[File:Completude̠ logique premier ordre.png|thumb|400px|The formula ([[Universal quantification|∀]]''x''. ''R''(''x'',''x'')) [[Material conditional|→]] (∀''x''[[Existential quantification|∃]]''y''. ''R''(''x'',''y'')) holds in all [[Structure (mathematical logic)|structures]] (only the simplest 8 are shown left). By G&amp;ouml;del's completeness result, it must hence have a [[natural deduction]] proof (shown right).]]
'''Gödel's completeness theorem''' is a fundamental theorem in [[mathematical logic]] that establishes a correspondence between [[semantics|semantic]] truth and syntactic [[Provability logic|provability]] in [[first-order logic]]. It makes a close link between [[model theory]] that deals with what is true in different models, and [[proof theory]] that studies what can be formally proven in particular [[formal system]]s.

It was first proved by [[Kurt Gödel]] in 1929. It was then simplified in 1947, when [[Leon Henkin]] observed in his [[Ph.D.]] [[thesis]] that the hard part of the proof can be presented as the Model Existence Theorem (published in 1949). Henkin's proof was simplified by [[Gisbert Hasenjaeger]] in 1953.

==Preliminaries==
There are numerous [[deductive system]]s for first-order logic, including systems of [[natural deduction]] and [[Hilbert-style deduction system|Hilbert-style systems]]. Common to all deductive systems is the notion of a '''formal deduction'''. This is a sequence (or, in some cases, a finite [[tree structure|tree]]) of formulas with a specially-designated '''conclusion'''. The definition of a deduction is such that it is finite and that it is possible to verify [[algorithm]]ically (by a [[computer]], for example, or by hand) that a given sequence (or tree) of formulas is indeed a deduction.

A first-order formula is called '''[[Validity (logic)|logically valid]]''' if it is true in every [[structure (mathematical logic)|structure]] for the language of the formula (i.e. for any assignment of values to the variables of the formula). To formally state, and then prove, the completeness theorem, it is necessary to also define a deductive system. A deductive system is called '''complete''' if every logically valid formula is the conclusion of some formal deduction, and the completeness theorem for a particular deductive system is the theorem that it is complete in this sense. Thus, in a sense, there is a different completeness theorem for each deductive system. A converse to completeness is '''[[soundness theorem|soundness]],''' the fact that only logically valid formulas are provable in the deductive system.

If some specific deductive system of first-order logic is sound and complete, then it is "perfect" (a formula is provable if and only if it is logically valid), thus equivalent to any other deductive system with the same quality (any proof in one system can be converted into the other).

==Statement of the theorem==

We first fix a deductive system of first-order predicate calculus, choosing any of the well-known equivalent systems.  Gödel's original proof assumed the Hilbert-Ackermann proof system.

===Gödel's original formulation===

The completeness theorem says that if a formula is logically valid then there is a finite deduction (a formal proof) of the formula.

Thus, the deductive system is "complete" in the sense that no additional inference rules are required to prove all the logically valid formulas. A converse to completeness is '''[[soundness theorem|soundness]],''' the fact that only logically valid formulas are provable in the deductive system. Together with soundness (whose verification is easy), this theorem implies that a formula is logically valid [[if and only if]] it is the conclusion of a formal deduction.

===More general form===

The theorem can be expressed more generally in terms of [[logical consequence]].  We say that a sentence ''s'' is a '''syntactic consequence''' of a theory ''T'', denoted &lt;math&gt;T\vdash s&lt;/math&gt;, if ''s'' is provable from ''T'' in our deductive system.  We say that ''s'' is a '''semantic consequence''' of ''T'', denoted &lt;math&gt;T\models s&lt;/math&gt;, if ''s'' holds in every [[model (mathematical logic)|model]] of ''T''.  The completeness theorem then says that for any first-order theory ''T'' with a [[well-order]]able language, and any sentence ''s'' in the language of ''T'',

:if &lt;math&gt;T\models s&lt;/math&gt;, then &lt;math&gt;T\vdash s&lt;/math&gt;.

Since the converse (soundness) also holds, it follows that &lt;math&gt;T\models s&lt;/math&gt; iff &lt;math&gt;T\vdash s&lt;/math&gt;, and thus that syntactic and semantic consequence are equivalent for first-order logic.

This more general theorem is used implicitly, for example, when a sentence is shown to be provable from the axioms of [[group theory]] by considering an arbitrary group and showing that the sentence is satisfied by that group.

Gödel's original formulation is deduced by taking the particular case of a theory without any axiom.

===Model existence theorem===

The completeness theorem can also be understood in terms of [[consistency]], as a consequence of Henkin's [[Consistency#Henkin.27s_theorem|model existence theorem]].  We say that a theory ''T'' is '''syntactically consistent''' if there is no sentence ''s'' such that both ''s'' and its negation ¬''s'' are provable from ''T'' in our deductive system.  The model existence theorem says that for any first-order theory ''T'' with a well-orderable language,

:if &lt;math&gt;T&lt;/math&gt; is syntactically consistent, then &lt;math&gt;T&lt;/math&gt; has a model.

Another version, with connections to the [[Löwenheim–Skolem theorem]], says:

:Every syntactically consistent, [[countable]] first-order theory has a finite or countable model.

Given Henkin's theorem, the completeness theorem can be proved as follows: If &lt;math&gt;T \models s&lt;/math&gt;, then &lt;math&gt;T\cup\lnot s&lt;/math&gt; does not have models. By the contrapositive of Henkin's, then &lt;math&gt;T\cup\lnot s&lt;/math&gt; is syntactically inconsistent. So a contradiction (&lt;math&gt;\bot&lt;/math&gt;) is provable from &lt;math&gt;T\cup\lnot s&lt;/math&gt; in the deductive system. Hence &lt;math&gt;(T\cup\lnot s) \vdash \bot&lt;/math&gt;, and then by the properties of the deductive system, &lt;math&gt;T\vdash s&lt;/math&gt;.

===As a theorem of arithmetic===

The Model Existence Theorem and its proof can be formalized in the framework of [[Peano arithmetic]]. Precisely, we can systematically define a model of any consistent effective first-order theory ''T'' in Peano arithmetic by interpreting each symbol of ''T'' by an arithmetical formula whose free variables are the arguments of the symbol. However, the definition expressed by this formula is not recursive.

==Consequences==
An important consequence of the completeness theorem is that it is possible to [[enumerable set|recursively enumerate]] the semantic consequences of any [[effectively computable|effective]] first-order theory, by enumerating all the possible formal deductions from the axioms of the theory, and use this to produce an enumeration of their conclusions. 

This comes in contrast with the direct meaning of the notion of semantic consequence, that quantifies over all structures in a particular language, which is clearly not a recursive definition.

Also, it makes the concept of "provability," and thus of "theorem," a clear concept that only depends on the chosen system of axioms of the theory, and not on the choice of a proof system.

==Relationship to the incompleteness theorem==

[[Gödel's incompleteness theorem]], another celebrated result, shows that there are inherent limitations in what can be achieved with formal proofs in mathematics. The name for the incompleteness theorem refers to another meaning of ''complete'' (see [[Model theory#Using the compactness and completeness theorems|model theory – Using the compactness and completeness theorems]]).

It shows that in any [[consistent]] [[effectively computable|effective]] theory ''T'' containing [[Peano arithmetic]] (PA), the formula ''C&lt;sub&gt;T&lt;/sub&gt;'' expressing the consistency of ''T'' cannot be proven within ''T''.

Applying the completeness theorem to this result, gives the existence of a model of ''T'' where the formula ''C&lt;sub&gt;T&lt;/sub&gt;'' is false. Such a model (precisely, the set of "natural numbers" it contains) is necessarily [[Non-standard model of arithmetic|non-standard]], as it contains the code number of a proof of a contradiction of ''T''.
But ''T'' is consistent when viewed from the outside. Thus this code number of a proof of contradiction of ''T'' must be a non-standard number.

In fact, the model of ''any'' theory containing PA obtained by the systematic construction of the arithmetical model existence theorem, is ''always'' non-standard with a non-equivalent provability predicate and a non-equivalent way to interpret its own construction, so that this construction is non-recursive (as recursive definitions would be unambiguous).

Also, [[Tennenbaum's theorem|there is no recursive non-standard model of PA]].

==Relationship to the compactness theorem==
The completeness theorem and the [[compactness theorem]] are two cornerstones of first-order logic. While neither of these theorems can be proven in a completely [[effectively computable|effective]] manner, each one can be effectively obtained from the other.

The compactness theorem says that if a formula φ is a logical consequence of a (possibly infinite) set of formulas Γ then it is a logical consequence of a finite subset of Γ. This is an immediate consequence of the completeness theorem, because only a finite number of axioms from Γ can be mentioned in a formal deduction of φ, and the soundness of the deductive system then implies φ is a logical consequence of this finite set. This proof of the compactness theorem is originally due to Gödel.

Conversely, for many deductive systems, it is possible to prove the completeness theorem as an effective consequence of the compactness theorem.

The ineffectiveness of the completeness theorem can be measured along the lines of [[reverse mathematics]]. When considered over a countable language, the completeness and compactness theorems are equivalent to each other and equivalent to a weak form of choice known as [[weak König's lemma]], with the equivalence provable in RCA&lt;sub&gt;0&lt;/sub&gt; (a second-order variant of [[Peano arithmetic]] restricted to induction over  Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;1&lt;/sub&gt; formulas). Weak König's lemma is provable in ZF, the system of [[Zermelo–Fraenkel set theory]] without axiom of choice, and thus the completeness and compactness theorems for countable languages are provable in ZF. However the situation is different when the language is of arbitrary large cardinality since then, though the completeness and compactness theorems remain provably equivalent to each other in ZF, they are also provably equivalent to a weak form of the [[axiom of choice]] known as [[Boolean prime ideal theorem#The ultrafilter lemma|the ultrafilter lemma]]. In particular, no theory extending ZF can prove either the completeness or compactness theorems over arbitrary (possibly uncountable) languages without also proving the ultrafilter lemma on a set of same cardinality, knowing that on countable sets, the ultrafilter lemma becomes equivalent to weak König's lemma.

==Completeness in other logics==
The completeness theorem is a central property of [[first-order logic]] that does not hold for all logics. [[Second-order logic]], for example, does not have a completeness theorem for its standard semantics (but does have the completeness property for [[Henkin semantics]]), and the set of logically-valid formulas in second-order logic is not recursively enumerable. The same is true of all higher-order logics. It is possible to produce sound deductive systems for higher-order logics, but no such system can be complete.

[[Lindström's theorem]] states that first-order logic is the strongest (subject to certain constraints) logic satisfying both compactness and completeness.

A completeness theorem can be proved for [[modal logic]] or [[intuitionistic logic]] with respect to [[Kripke semantics]].

==Proofs==
Gödel's [[Original proof of Gödel's completeness theorem|original proof of the theorem]] proceeded by reducing the problem to a special case for formulas in a certain syntactic form, and then handling this form with an ''ad hoc'' argument.

In modern logic texts, Gödel's completeness theorem is usually proved with [[Leon Henkin|Henkin]]'s proof, rather than with Gödel's original proof. Henkin's proof directly constructs a [[term model]] for any consistent first-order theory. James Margetson (2004) developed a computerized formal proof using the [[Isabelle (theorem prover)|Isabelle]] theorem prover.&lt;ref&gt;{{cite report | url=http://afp.sourceforge.net/entries/Completeness-paper.pdf | author=James Margetson | title=Proving the Completeness Theorem within Isabelle/HOL | institution= | type=Technical Report | number= | date=Sep 2004 }}&lt;/ref&gt; Other proofs are also known.

==See also==
* [[Gödel's incompleteness theorems]]
* [[Original proof of Gödel's completeness theorem]]

==Further reading==
* {{cite journal
 |last=Gödel |first=K |authorlink=Kurt Gödel
 |year=1929
 |title=Über die Vollständigkeit des Logikkalküls
 |url=http://ubdata.univie.ac.at/AC05181322
 |version=Doctoral dissertation |publisher=University Of Vienna.
}} The first proof of the completeness theorem.
* {{cite journal
 |last=Gödel |first=K |authorlink=Kurt Gödel
 |title=Die Vollständigkeit der Axiome des logischen Funktionenkalküls
 |language=German
 |journal=[[Monatshefte für Mathematik]]
 |volume=37
 |issue=1 |pages=349&amp;ndash;360 |year=1930
 |doi=10.1007/BF01696781
 |jfm=56.0046.04
}} The same material as the dissertation, except with briefer proofs, more succinct explanations, and omitting the lengthy introduction.
{{reflist}}

==External links==
*[[Stanford Encyclopedia of Philosophy]]: "[http://plato.stanford.edu/entries/goedel/ Kurt Gödel]"—by Juliette Kennedy.
*MacTutor biography: [http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Godel.html Kurt Gödel.]
* Detlovs, Vilnis, and Podnieks, Karlis, "[http://www.ltn.lv/~podnieks/ Introduction to mathematical logic.]"

{{Metalogic}}

{{DEFAULTSORT:Godels Completeness Theorem}}
[[Category:Theorems in the foundations of mathematics]]
[[Category:Metatheorems]]
[[Category:Model theory]]
[[Category:Proof theory]]
[[Category:Works by Kurt Gödel|Completeness theorem]]</text>
      <sha1>n7f97a7d8iz26xtg9xlq9im11q28fo3</sha1>
    </revision>
  </page>
  <page>
    <title>Hamiltonian coloring</title>
    <ns>0</ns>
    <id>47650504</id>
    <revision>
      <id>843601649</id>
      <parentid>712733392</parentid>
      <timestamp>2018-05-30T06:22:13Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1171">'''Hamiltonian coloring''' is a type of [[graph coloring]].  Hamiltonian coloring uses a concept called detour distance between two [[vertex (graph theory)|vertices]] of the graph.&lt;ref name="e01"&gt;{{cite book |last1=Chartrand |first1=Gary |last2=Zhang |first2=Ping|author2-link=Ping Zhang (graph theorist) |authorlink1=Gary Chartrand |title=Chromatic Graph Theory |year=2009 |publisher=CRC Press |chapter=14. Colorings, Distance, and Domination |pages=397–438}}&lt;/ref&gt; It has many applications in different areas of science and technology.

==Terminologies==
[[File:Detour distance in C5.png|thumb|right|The detour distance between u and v in ''C&lt;sub&gt;5&lt;/sub&gt;'' is 4]]

===Detour distance===
The distance between two vertices in a graph is defined as the minimum of lengths of [[Path (graph theory)|paths]] connecting those vertices. The '''detour distance''' between two vertices, say, u and v is defined as the length of the longest u-v path in the graph.&lt;ref name="e01" /&gt; In the case of a tree the detour distance between any two vertices is same as the distance between the two vertices.

==References==
&lt;references /&gt;

[[Category:Graph coloring]]


{{topology-stub}}</text>
      <sha1>moclwvgdmj0lgq8llwlw8wkpye9bvcu</sha1>
    </revision>
  </page>
  <page>
    <title>Hankel contour</title>
    <ns>0</ns>
    <id>1268560</id>
    <revision>
      <id>829300184</id>
      <parentid>829282510</parentid>
      <timestamp>2018-03-07T20:14:22Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1209">[[Image:Hankel contour.png|right]]

In [[mathematics]], a '''Hankel contour''' is a path in the [[complex plane]] which extends from 
[∞,δ], around the origin [[counter clockwise]] and back to
[∞,&amp;minus;δ]{{clarify|date=March 2018}}, where δ is an arbitrarily small positive number. The contour thus remains arbitrarily close to the [[real axis]] but without crossing the real axis except for negative values of ''x''.

Use of Hankel contours is one of the [[methods of contour integration]]. This type of path for [[contour integral]]s was first used by [[Hermann Hankel]] in his investigations of the [[Gamma function]].

The [[mirror image]] extending from &amp;minus;∞, circling the origin [[clockwise]], and returning
to &amp;minus;∞ is also called a Hankel contour.

==References==
* {{cite book | author=Hugh L. Montgomery | authorlink=Hugh Montgomery (mathematician) |author2=Robert C. Vaughan |authorlink2=Robert Charles Vaughan (mathematician)  | title=Multiplicative number theory I. Classical theory | series=Cambridge tracts in advanced mathematics | volume=97 | year=2007 | isbn=0-521-84903-9 | page=515 }}

[[Category:Complex analysis]]
[[Category:Special functions]]


{{Mathanalysis-stub}}</text>
      <sha1>tk6mxzrukxg50xzrnh3of69n658bmsu</sha1>
    </revision>
  </page>
  <page>
    <title>Herz–Schur multiplier</title>
    <ns>0</ns>
    <id>22616744</id>
    <revision>
      <id>619095636</id>
      <parentid>601823074</parentid>
      <timestamp>2014-07-30T07:41:27Z</timestamp>
      <contributor>
        <username>Magioladitis</username>
        <id>1862829</id>
      </contributor>
      <minor/>
      <comment>/* Definition */Replace unicode entity nbsp for character [NBSP] (or space)  per [[WP:NBSP]] + other fixes, replaced: →   (3) using [[Project:AWB|AWB]] (10331)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1910">In the [[mathematics|mathematical]] field of [[representation theory]], a '''Herz–Schur multiplier''' (named after [[Carl S. Herz]] and [[Issai Schur]]) is a special kind of mapping from a [[group (mathematics)|group]] to the [[field (mathematics)|field]] of [[complex number]]s.

==Definition==
Let Ψ be a mapping of a group ''G'' to the complex numbers. It is a Herz–Schur multiplier if the induced map Ψ: ''N''(''G'') → ''N''(''G'') is a [[completely positive map]], where ''N''(''G'') is the closure of the span ''M'' of the image of λ in ''B''(''ℓ''&lt;sup&gt;&amp;nbsp;2&lt;/sup&gt;(''G'')) with respect to the [[weak topology]], λ is the left [[regular representation]] of ''G'' and Ψ is on ''M'' defined as

:&lt;math&gt;\Psi:~\sum\limits_{g\in G}\mu_g\lambda_g\mapsto\sum\limits_{g\in G}\psi(g)\mu_g\lambda_g.&lt;/math&gt;

==See also==
* [[Figà-Talamanca–Herz algebra]]
* [[Fourier algebra]]

==References==
{{refimprove|date=June 2009}}
&lt;references /&gt;
* {{Citation | last1=Pisier | first1=Gilles | authorlink=Gilles Pisier | title=Multipliers and lacunary sets in non-amenable groups | doi=10.2307/2374918 | mr=1323679 |arxiv=math/9212207 | year=1995 | journal=[[American Journal of Mathematics]] | issn=0002-9327 | volume=117 | issue=2 | pages=337–376 | publisher=The Johns Hopkins University Press | jstor=2374918}}
* {{Citation | last1=Figà-Talamanca | first1=Alessandro | last2=Picardello | first2=Massimo A. | title=Harmonic analysis on free groups | publisher=Marcel Dekker Inc. | location=New York | series=Lecture Notes in Pure and Applied Mathematics | isbn=978-0-8247-7042-6 | mr=710827 | year=1983 | volume=87}}
*Carl S. Herz. Une généralisation de la notion de transformée de Fourier-Stieltjes. Annales de l'institut Fourier, tome 24, no 3 (1974), p.&amp;nbsp;145-157.

{{DEFAULTSORT:Herz-Schur Multiplier}}
[[Category:Representation theory]]
[[Category:Harmonic analysis]]


{{mathanalysis-stub}}</text>
      <sha1>i944x4ab5qliyp8mhsuf11w0osziw17</sha1>
    </revision>
  </page>
  <page>
    <title>Idempotent matrix</title>
    <ns>0</ns>
    <id>2974863</id>
    <revision>
      <id>864738351</id>
      <parentid>864724590</parentid>
      <timestamp>2018-10-19T04:09:20Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Undid revision 864724590 by [[Special:Contributions/80.65.246.237|80.65.246.237]] ([[User talk:80.65.246.237|talk]]) List format was better</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6744">In [[linear algebra]], an '''idempotent matrix''' is a [[matrix (mathematics)|matrix]] which, when multiplied by itself, yields itself.&lt;ref&gt;{{cite book |last=Chiang |first=Alpha C. |title=Fundamental Methods of Mathematical Economics |publisher=McGraw–Hill |edition=3rd |year=1984 |page=80 |location=New York |isbn=0070108137 }}&lt;/ref&gt;&lt;ref name=Greene&gt;{{cite book |last=Greene |first=William H. |title=Econometric Analysis |publisher=Prentice–Hall |location=Upper Saddle River, NJ |edition=5th |year=2003 |pages=808–809 |isbn=0130661899 }}&lt;/ref&gt; That is, the matrix ''M'' is idempotent if and only if ''MM''&amp;nbsp;=&amp;nbsp;''M''. For this product ''MM'' to be [[matrix multiplication|defined]], ''M'' must necessarily be a [[square matrix]]. Viewed this way, idempotent matrices are [[idempotent element (ring theory)|idempotent element]]s of [[matrix ring]]s.

==Example==
Examples of a &lt;math&gt;2 \times 2&lt;/math&gt; and a &lt;math&gt;3 \times 3&lt;/math&gt; idempotent matrix are &lt;math&gt;\begin{bmatrix}1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}&lt;/math&gt; and &lt;math&gt;\begin{bmatrix}2 &amp; -2 &amp; -4 \\ -1 &amp; 3 &amp; 4 \\ 1 &amp; -2 &amp; -3 \end{bmatrix}&lt;/math&gt;, respectively.

==Real 2 × 2 case==
If a matrix &lt;math&gt;\begin{pmatrix}a &amp; b \\ c &amp; d \end{pmatrix}&lt;/math&gt; is idempotent, then
* &lt;math&gt;a = a^2 + bc,&lt;/math&gt;
* &lt;math&gt;b = ab + bd,&lt;/math&gt; implying &lt;math&gt;b(1 - a - d) = 0&lt;/math&gt; so &lt;math&gt;b = 0&lt;/math&gt; or &lt;math&gt;d = 1 - a,&lt;/math&gt;
* &lt;math&gt;c = ca + cd,&lt;/math&gt; implying &lt;math&gt;c(1 - a - d) = 0&lt;/math&gt; so &lt;math&gt;c = 0&lt;/math&gt; or &lt;math&gt;d = 1 - a,&lt;/math&gt;
* &lt;math&gt;d = bc + d^2.&lt;/math&gt;

Thus a necessary condition for a 2 × 2 matrix to be idempotent is that either it is [[diagonal matrix|diagonal]] or its [[trace (linear algebra)|trace]] equals 1.
Notice that, for idempotent diagonal matrices, &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; must be either 1 or 0.

If ''b'' = ''c'', the matrix &lt;math&gt;\begin{pmatrix}a &amp; b \\ b &amp; 1 - a \end{pmatrix}&lt;/math&gt; will be idempotent provided &lt;math&gt;a^2 + b^2 = a ,&lt;/math&gt; so ''a'' satisfies the [[quadratic equation]]
:&lt;math&gt;a^2 - a + b^2 = 0 ,&lt;/math&gt; or &lt;math&gt;\left(a - \frac{1}{2}\right)^2 + b^2 = \frac{1}{4}&lt;/math&gt;

which is a [[circle]] with center (1/2, 0) and radius 1/2. In terms of an angle &amp;theta;,
:&lt;math&gt;M = \frac{1}{2}\begin{pmatrix}1 - \cos\theta &amp; \sin\theta \\ \sin\theta &amp; 1 + \cos\theta \end{pmatrix}&lt;/math&gt; is idempotent.

However, ''b'' = ''c'' is not a necessary condition: any matrix
:&lt;math&gt;\begin{pmatrix}a &amp; b \\ c &amp; 1 - a\end{pmatrix}&lt;/math&gt; with &lt;math&gt;a^2 + bc = a&lt;/math&gt; is idempotent.

==Properties==
With the exception of the [[identity matrix]], an idempotent matrix is [[singular matrix|singular]]; that is, its number of independent rows (and columns) is less than its number of rows (and columns).  This can be seen from writing &lt;math&gt;MM = M&lt;/math&gt;, assuming that {{mvar|M}} has full rank (is non-singular), and pre-multiplying by &lt;math&gt;M^{-1}&lt;/math&gt; to obtain &lt;math&gt;M = IM = M^{-1}MM = M^{-1}M = I&lt;/math&gt;.

When an idempotent matrix is subtracted from the identity matrix, the result is also idempotent. This holds since 
: {{math|1=[''I''&amp;nbsp;−&amp;nbsp;''M''][''I''&amp;nbsp;−&amp;nbsp;''M''] =&amp;nbsp;''I''&amp;nbsp;−&amp;nbsp;''M''&amp;nbsp;−&amp;nbsp;''M''&amp;nbsp;+&amp;nbsp;''M''&lt;sup&gt;2&lt;/sup&gt; =&amp;nbsp;''I''&amp;nbsp;−&amp;nbsp;''M''&amp;nbsp;−&amp;nbsp;''M''&amp;nbsp;+&amp;nbsp;''M'' =&amp;nbsp;''I''&amp;nbsp;−&amp;nbsp;''M''}}.

A matrix {{mvar|A}} is idempotent if and only if for all positive integers n, &lt;math&gt;A^n = A&lt;/math&gt;. The 'if' direction trivially follows by taking &lt;math&gt;n=2&lt;/math&gt;. The 'only if' part can be shown using proof by induction. Clearly we have the result for &lt;math&gt;n = 1&lt;/math&gt;, as &lt;math&gt;A^1 = A&lt;/math&gt;. Suppose that &lt;math&gt;A^{k-1} = A&lt;/math&gt;. Then, &lt;math&gt;A^k = A^{k-1}A = AA = A&lt;/math&gt;, as required. Hence by the principle of induction, the result follows.

An idempotent matrix is always [[diagonalizable]] and its [[eigenvalue]]s are either 0 or 1.&lt;ref&gt;{{cite book |first=Roger A. |last=Horn |first2=Charles R. |last2=Johnson |title=Matrix analysis |publisher=Cambridge University Press |year=1990 |page=[{{Google books|plainurl=y|id=PlYQN0ypTwEC|page=148|text=every idempotent matrix is diagonalizable}} p. 148] |isbn=0521386322 }}&lt;/ref&gt; The [[trace (linear algebra)|trace]] of an idempotent matrix — the sum of the elements on its main diagonal — equals the [[rank (linear algebra)|rank]] of the matrix and thus is always an integer. This provides an easy way of computing the rank, or alternatively an easy way of determining the trace of a matrix whose elements are not specifically known (which is helpful in [[statistics]], for example, in establishing the degree of [[bias (statistics)|bias]] in using a [[variance|sample variance]] as an estimate of a [[variance|population variance]]).

==Applications==
Idempotent matrices arise frequently in [[regression analysis]] and [[econometrics]]. For example, in [[ordinary least squares]], the regression problem is to choose a vector {{mvar|&amp;beta;}} of coefficient estimates so as to minimize the sum of squared residuals (mispredictions) ''e''&lt;sub&gt;''i''&lt;/sub&gt;: in matrix form,
: Minimize &lt;math&gt;(y - X\beta)^\textsf{T}(y - X\beta) &lt;/math&gt;

where ''y'' is a vector of [[Dependent and independent variables#Statistics|dependent variable]] observations, and ''X'' is a matrix each of whose columns is a column of observations on one of the [[Dependent and independent variables#Statistics|independent variables]]. The resulting estimator is

:&lt;math&gt;\hat\beta = \left(X^\textsf{T}X\right)^{-1}X^\textsf{T}y &lt;/math&gt;

where superscript ''T'' indicates a [[transpose]], and the vector of residuals is&lt;ref name=Greene/&gt;

:&lt;math&gt;
  \hat{e} = y - X \hat\beta
          = y - X\left(X^\textsf{T}X\right)^{-1}X^\textsf{T}y
          = \left[I - X\left(X^\textsf{T}X\right)^{-1}X^\textsf{T}\right]y
          = My.
&lt;/math&gt;

Here both ''M'' and &lt;math&gt;X\left(X^\textsf{T}X\right)^{-1}X^\textsf{T}&lt;/math&gt;(the latter being known as the [[hat matrix]]) are idempotent and symmetric matrices, a fact which allows simplification when the sum of squared residuals is computed:

:&lt;math&gt;\hat{e}^\textsf{T}\hat{e} = (My)^\textsf{T}(My) = y^\textsf{T}M^\textsf{T}My = y^\textsf{T}MMy = y^\textsf{T}My.&lt;/math&gt;

The idempotency of ''M'' plays a role in other calculations as well, such as in determining the variance of the estimator &lt;math&gt;\hat{\beta}&lt;/math&gt;.

An idempotent linear operator ''P'' is a projection operator on the [[column space|range space]] {{tmath|R(P)}} along its [[null space]] {{tmath|N(P)}}. ''P'' is an [[orthogonal projection]] operator if and only if it is idempotent and [[Symmetric matrix|symmetric]].

==See also==
* [[Idempotence]]
* [[Nilpotent]]
* [[Projection (linear algebra)]]
* [[Hat matrix]]

==References==
{{reflist}}

[[Category:Algebra]]
[[Category:Regression analysis]]
[[Category:Matrices]]</text>
      <sha1>e8ia74ao9rh7i5f9qjg1jr62oaxxtdq</sha1>
    </revision>
  </page>
  <page>
    <title>International Conference on Software Engineering and Formal Methods</title>
    <ns>0</ns>
    <id>20787202</id>
    <revision>
      <id>798315902</id>
      <parentid>769829614</parentid>
      <timestamp>2017-09-01T05:44:08Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[Wikipedia:Bots/Requests for approval/KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3561">{{third-party|date=August 2013}}
{{primary sources|date=August 2013}}
The '''''International Conference on Software Engineering and Formal Methods''''' ('''SEFM''') is an international academic conference in the field of [[software engineering]].&lt;ref&gt;[http://sefm.iist.unu.edu/history.html SEFM history], [[UNU-IIST]], [[United Nations University]], Macau.&lt;/ref&gt;

==History ==
Until 2002, SEFM was a workshop; it then became a full international conference. It is sponsored by the [[IEEE Computer Society]]. The ''1st IEEE International Conferences on         Software Engineering and Formal Methods''  (SEFM 2003) was  held at [[Brisbane]], [[Australia]] in September 2003.&lt;ref&gt;[http://sefm.iist.unu.edu/SEFM2003/ SEFM 2003], Brisbane, Australia, 2003.&lt;/ref&gt; Submissions originated from 22 different countries. As well as IEEE-CS, supporters for SEFM 2003 included the  [[Australian Computer Society]] (ACS), [[Boeing Australia]], and the [[Italy|Italian]] Embassy in [[Canberra]].

The proceedings for the conference are published by the [[Springer Science+Business Media]] in [[LNCS]] since 2011.&lt;ref&gt;[https://link.springer.com/search?query=SEFM&amp;facet-content-type=%22Book%22 SEFM Proceedings], [[SpringerLink]], 2005.&lt;/ref&gt; Previously, the proceedings were published by [[IEEE]].&lt;ref&gt;[http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=10529 SEFM 2005 Proceedings], [[IEEE Xplore]], 2005.&lt;/ref&gt;

==Aims==
SEFM aims to bring together practitioners and researchers from academia, industry, and government, to advance the state of the art in [[formal methods]], to help in their large-scale application in the software industry, and to encourage their integration with other practical [[software engineering]] methods.

The conferences are often held in the [[Asia]] and [[Pacific]] regions and specifically in developing countries. An important aim of the SEFM conferences is to encourage research cooperation between developing countries and industrialized countries. SEFM 2010 was in [[Pisa]], [[Italy]].&lt;ref&gt;[http://www.sefm2010.isti.cnr.it/ SEFM 2010], [[Consiglio Nazionale delle Ricerche|CNR]], Italy.&lt;/ref&gt; SEFM 2013 was in [[Madrid]], [[Spain]].&lt;ref&gt;{{cite web| url=http://antares.sip.ucm.es/sefm2013/ | title=SEFM 2013 | publisher=[[Universidad Complutense]] | location=Madrid, Spain | accessdate=4 March 2013 }}&lt;/ref&gt; SEFM 2014 takes place in Grenoble, France &lt;ref&gt;{{cite web|title=SEFM 2014|url=http://sefm2014.inria.fr/|accessdate=15 January 2014}}&lt;/ref&gt;

The SEFM conference series is included on the [[DBLP]] online publications database.&lt;ref&gt;[http://www.informatik.uni-trier.de/~ley/db/conf/sefm/ Conference on Software Engineering and Formal Methods (SEFM)], [[DBLP]].&lt;/ref&gt; Revised selected papers sometimes appear as special journal issues.&lt;ref&gt;{{cite journal| doi=10.1007/s00165-013-0281-8 | first1=Jonathan P. | last1=Bowen | authorlink1=Jonathan Bowen | first2=Michael | last2=Butler | authorlink2=Michael Butler (computer scientist) | first3=Steve | last3=Reeves | authorlink3=Steve Reeves (computer scientist) | first4=Mike | last4=Hinchey | authorlink4=Michael Hinchey | title=Editorial | journal=[[Formal Aspects of Computing]] | volume=5 | page=343 | year=2013 }}&lt;!--| accessdate=3 June 2013--&gt;&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* [http://sefm.iist.unu.edu/ SEFM website]
{{IEEE conferences}}
{{formalmethods-stub}}

[[Category:Recurring events established in 2003]]
[[Category:Software engineering conferences]]
[[Category:Formal methods]]
[[Category:IEEE conferences]]
[[Category:September events]]</text>
      <sha1>hhufk3jm4dzbsocpxwq90a60ja9flzi</sha1>
    </revision>
  </page>
  <page>
    <title>International Institute for Advanced Studies in Systems Research and Cybernetics</title>
    <ns>0</ns>
    <id>31640999</id>
    <revision>
      <id>472562696</id>
      <parentid>461319575</parentid>
      <timestamp>2012-01-22T05:46:33Z</timestamp>
      <contributor>
        <username>BattyBot</username>
        <id>15996738</id>
      </contributor>
      <comment>changed {{Unreferenced}} to {{Refimprove}} &amp; [[WP:AWB/GF|general fixes]], removed wikify tag using [[Project:AWB|AWB]] (7916)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="971">{{refimprove|date=May 2011}}

The International Institute for Advanced Studies is a [[Non-profit organization|non-profit]] [[educational organization]] committed to the development and promotion of [[Cybernetics]] and [[Systems research|Systems Research]] and the advancement of interdisciplinary studies in the [[sciences]], [[engineering]], [[arts]] and [[humanities]].&lt;ref&gt;[http://www.iias.edu/iias_leaflet.html IIAS Overview]&lt;/ref&gt;

IIAS hosts an annual [[symposium]] in [[Baden-Baden]], [[Germany]], where researchers from around the world submit and share their papers on topics ranging from [[artificial intelligence]] and [[nanotechnology]] to [[Risk analysis (engineering)|risk analysis]].

==External links==
*[http://www.iias.edu/ ''The International Institute for Advanced Studies in Systems Research and Cybernetics '' homepage]

== References ==
&lt;references/&gt;

[[Category:Information systems]]
[[Category:Computer science journals]]
[[Category:Cybernetics]]</text>
      <sha1>cnk8xly92ka67frpyt4t4rujbn0m4or</sha1>
    </revision>
  </page>
  <page>
    <title>Joseph Liouville</title>
    <ns>0</ns>
    <id>341810</id>
    <revision>
      <id>840055251</id>
      <parentid>839953477</parentid>
      <timestamp>2018-05-07T12:42:26Z</timestamp>
      <contributor>
        <username>PIerre.Lescanne</username>
        <id>18880395</id>
      </contributor>
      <comment>correction of a mistake</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6316">{{Infobox scientist
|name              = Joseph Liouville
|image             = Joseph liouville.jpeg
|image_size       = 150px
|caption           = Joseph Liouville 
|birth_date        = {{birth date|1809|03|24|df=y}}
|birth_place       = [[Saint-Omer]], [[France]]
|death_date        = {{death date and age|1882|09|08|1809|03|24|df=y}}
|death_place       = [[Paris]], France
|nationality       = French
|alma_mater        = [[École Polytechnique]]
|doctoral_advisor  = [[Siméon Denis Poisson|Siméon Poisson]]&lt;br&gt;[[Louis Jacques Thénard]]
|doctoral_students = [[Eugène Charles Catalan]]&lt;br&gt;[[Nikolai Bugaev]]
|known_for         = [[Liouville's equation]]
|field             = Mathematics
|work_institutions =[[École Centrale Paris]]&lt;br&gt;[[École Polytechnique]] 
|prizes            = 
}}
'''Joseph Liouville''' [[Royal Society of London|FRS]] [[FRSE]] [[French Academy of Sciences|FAS]] ({{IPAc-en|ˌ|l|i:|u:|ˈ|v|ɪ|l}}; {{IPA-fr|ʒɔzɛf ljuvil|lang}}; 24 March 1809 – 8 September 1882)&lt;ref&gt;His death is registered the 9th of Septembre [http://archives.paris.fr/arkotheque/visionneuse/visionneuse.php?arko=YTo2OntzOjQ6ImRhdGUiO3M6MTA6IjIwMTgtMDUtMDYiO3M6MTA6InR5cGVfZm9uZHMiO3M6MTE6ImFya29fc2VyaWVsIjtzOjQ6InJlZjEiO2k6NztzOjQ6InJlZjIiO2k6MzYxNDtzOjE2OiJ2aXNpb25uZXVzZV9odG1sIjtiOjE7czoyMToidmlzaW9ubmV1c2VfaHRtbF9tb2RlIjtzOjQ6InByb2QiO30=#uielem_move=1%2C-812&amp;uielem_islocked=0&amp;uielem_zoom=132&amp;uielem_brightness=0&amp;uielem_contrast=0&amp;uielem_isinverted=0&amp;uielem_rotate=F Etat civil de la ville de Paris, 6ème arrondissement].&lt;/ref&gt;{{,}}&lt;ref&gt;[http://gallica.bnf.fr/ark:/12148/bpt6k278320w/f1.item.r=Liouville.zoom Figaro du 10 décembre 1882]&lt;/ref&gt; was a French mathematician.

== Life and work ==

[[File:Journal math liouville.jpg|thumb|right|Title page of the first volume of ''Journal de Mathématiques Pures et Appliquées'' in 1836.]]
He was born in [[Saint-Omer]] in France on 24 March 1809.&lt;ref&gt;{{cite book|title=Biographical Index of Former Fellows of the Royal Society of Edinburgh 1783–2002|date=July 2006|publisher=The Royal Society of Edinburgh|isbn=0 902 198 84 X|url=https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp2.pdf}}&lt;/ref&gt;

Liouville graduated from the [[École Polytechnique]] in 1827. After some years as an assistant at various institutions including the [[École Centrale Paris]], he was appointed as professor at the École Polytechnique in 1838. He obtained a chair in mathematics at the [[Collège de France]] in 1850 and a chair in mechanics at the Faculté des Sciences in 1857.

Besides his academic achievements, he was very talented in organisational matters. Liouville founded the ''[[Journal de Mathématiques Pures et Appliquées]]'' which retains its high reputation up to today, in order to promote other mathematicians' work. He was the first to read, and to recognize the importance of, the unpublished work of [[Évariste Galois]] which appeared in his journal in 1846. Liouville was also involved in politics for some time, and he became a member of the [[National Assembly of France|Constituting Assembly]] in 1848. However, after his defeat in the legislative elections in 1849, he turned away from politics.

Liouville worked in a number of different fields in mathematics, including [[number theory]], [[complex analysis]], [[differential geometry and topology]], but also [[mathematical physics]] and even [[astronomy]]. He is remembered particularly for [[Liouville's theorem (complex analysis)|Liouville's theorem]]. In number theory, he was the first to prove the existence of [[transcendental number]]s by a construction using [[continued fraction]]s ([[Liouville number]]s). In mathematical physics, Liouville made two fundamental contributions: the [[Sturm–Liouville theory]], which was joint work with [[Charles François Sturm]], and is now a standard procedure to solve certain types of [[integral equation]]s by developing into eigenfunctions, and the fact (also known as [[Liouville's theorem (Hamiltonian)|Liouville's theorem]]) that time evolution is measure preserving for a [[Hamiltonian mechanics|Hamiltonian]] system. In Hamiltonian dynamics, Liouville also introduced the notion of [[action-angle variables]] as a description of completely [[integrable systems]]. The modern formulation of this is sometimes called the '''Liouville–Arnold theorem''', and the underlying concept of integrability is referred to as '''Liouville integrability'''.

In 1851, he was elected a foreign member of the [[Royal Swedish Academy of Sciences]].

The crater [[Liouville (crater)|Liouville]] on the [[Moon]] is named after him. So is the [[Liouville function]], an important function in number theory.

==See also==
*[[List of things named after Joseph Liouville]]
* [[Liouville's theorem (disambiguation)]]

==Notes==
{{reflist}}

==References==
* {{MacTutor Biography|id=Liouville}}
* {{Citation|last = Lützen|first = Jesper|year = 1990|title = Joseph Liouville 1809–1882: Master of Pure and Applied Mathematics|series = Studies in the History of Mathematics and Physical Sciences|volume = 15|publisher = Springer-Verlag|isbn = 3-540-97180-7}}
* Lutzen J., "Liouville's differential calculus of arbitrary order and its electrodynamical  origin",in  {\it Proc. 19th  Nordic  Congress Mathematicians}. 1985. Icelandic Mathematical Society, Reykjavik, pp.&amp;nbsp;149–160.

==Further reading==
* {{citation | last=Williams | first=Kenneth S. | title=Number theory in the spirit of Liouville | zbl=1227.11002 | series=London Mathematical Society Student Texts | volume=76 | location=Cambridge | publisher=[[Cambridge University Press]] | isbn=978-0-521-17562-3 | year=2011 }}

==External links==
* {{Gutenberg author | id=Liouville,+Joseph | name=Joseph Liouville}}
* {{Internet Archive author |sname=Joseph Liouville}}
* {{MathGenealogy|id=55185}}

{{Authority control}}

{{DEFAULTSORT:Liouville, Joseph}}
[[Category:École Polytechnique alumni]]
[[Category:École des Ponts ParisTech alumni]]
[[Category:Corps des ponts]]
[[Category:1809 births]]
[[Category:1882 deaths]]
[[Category:19th-century French mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Members of the French Academy of Sciences]]
[[Category:Members of the Royal Swedish Academy of Sciences]]
[[Category:Foreign Members of the Royal Society]]</text>
      <sha1>dho164qel9t8a65cacs362b3h45tazk</sha1>
    </revision>
  </page>
  <page>
    <title>Kantorovich inequality</title>
    <ns>0</ns>
    <id>929502</id>
    <revision>
      <id>842028712</id>
      <parentid>804403122</parentid>
      <timestamp>2018-05-19T18:54:33Z</timestamp>
      <contributor>
        <ip>2607:FEA8:1D5F:FA33:81D9:1E45:AC61:1C62</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2656">In [[mathematics]], the '''Kantorovich inequality''' is a particular case of the [[Cauchy–Schwarz inequality]], which is itself a generalization of the [[triangle inequality]].

The triangle inequality states that the length of two sides of any triangle, added together, will be equal to or greater than the length of the third side.  In simplest terms, the Kantorovich inequality translates the basic idea of the triangle inequality into the terms and notational conventions of [[linear programming]]. (See [[vector space]], [[inner product]], and [[normed vector space]] for other examples of how the basic ideas inherent in the triangle inequality—line segment and distance—can be generalized into a broader context.)

More formally, the Kantorovich inequality can be expressed this way:

:Let

:: &lt;math&gt;p_i \geq 0,\quad 0 &lt; a \leq x_i \leq b\text{ for }i=1, \dots ,n.&lt;/math&gt; 
 
:Let &lt;math&gt;A_n=\{1,2,\dots ,n\}.&lt;/math&gt; 
 
:Then 
 
:: &lt;math&gt;
\begin{align}
&amp; {} \qquad \left( \sum_{i=1}^n p_ix_i \right ) \left (\sum_{i=1}^n \frac{p_i}{x_i} \right) \\
&amp; \leq \frac{(a+b)^2}{4ab} \left (\sum_{i=1}^n p_i \right )^2
-\frac{(a-b)^2}{4ab} \cdot \min \left\{ \left (\sum_{i \in X}p_i-\sum_{j \in Y}p_j \right )^2\,:\, {X \cup Y=A_n},{X \cap Y=\varnothing} \right\}.
\end{align}
&lt;/math&gt;

The Kantorovich inequality is used in [[convergence analysis]]; it bounds the convergence rate of Cauchy's [[steepest descent]].

Equivalents of the Kantorovich inequality have arisen in a number of different fields.  For instance, the [[Cauchy&amp;ndash;Schwarz&amp;ndash;Bunyakovsky inequality]] and the [[Wielandt inequality]] are equivalent to the Kantorovich inequality and all of these are, in turn, special cases of the [[Hölder inequality]].

The Kantorovich inequality is named after Soviet economist, mathematician, and [[Nobel Prize]] winner [[Leonid Kantorovich]], a pioneer in the field of [[linear programming]].

There is also Matrix version of the Kantrovich inequality due to Marshall and Olkin.

==References==
* {{MathWorld|urlname=KantorovichInequality|title=Kantorovich Inequality}}
* {{PlanetMath|urlname=KantorovichInequality|title=Cauchy-Schwarz inequality}}
* [http://carbon.cudenver.edu/~hgreenbe/glossary/index.php?page=K.html Mathematical Programming Glossary entry on "Kantorovich inequality"]
* MARSHALL A. W. and OLKIN, I., Matrix  versions  of the  Cauchy and Kantorovieh inequatities. [[Aequationes Mathematicae]] 40 (1990), pp. 89–93.

==External links==
*[http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Kantorovich.html Biography of Leonid Vitalyevich Kantorovich]

[[Category:Theorems in analysis]]
[[Category:Inequalities]]</text>
      <sha1>8qmyd2osiktcg00uokcr0m87a3t34wo</sha1>
    </revision>
  </page>
  <page>
    <title>Kuiper's theorem</title>
    <ns>0</ns>
    <id>2993692</id>
    <revision>
      <id>831366555</id>
      <parentid>822446924</parentid>
      <timestamp>2018-03-20T06:25:37Z</timestamp>
      <contributor>
        <ip>42.244.62.219</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7663">In [[mathematics]], '''Kuiper's theorem''' (after [[Nicolaas Kuiper]]) is a result on the topology of operators on an infinite-dimensional, complex [[Hilbert space]]&amp;nbsp;''H''. It states that the [[topological space|space]] GL(''H'') of [[invertible]] [[bounded operator|bounded]] [[linear operator|endomorphisms]] of ''H'' is such that all maps from any [[CW complex|finite complex]] ''Y'' to GL(''H'') are [[homotopic]] to a constant, for the [[norm topology]] on operators.

A significant corollary, also referred to as ''Kuiper's theorem'', is that this group is [[weakly contractible]], ''ie.'' all its [[homotopy group]]s are trivial. This result has important uses in [[topological K-theory]].

==General topology of the general linear group==

For finite dimensional ''H'', this group would be a complex [[general linear group]] and not at all contractible. In fact it is homotopy equivalent to its [[maximal compact subgroup]], the [[unitary group]] ''U'' of ''H''. The proof that the complex general linear group and unitary group have the same [[homotopy type]] is by the [[Gram-Schmidt process]], or through the [[matrix polar decomposition]], and carries over to the infinite-dimensional case of [[separable Hilbert space]], basically because the space of [[upper triangular matrices]] is contractible as can be seen quite explicitly. The underlying phenomenon is that passing to infinitely many dimensions causes much of the topological complexity of the unitary groups to vanish; but see the section on Bott's unitary group, where the passage to infinity is more constrained, and the resulting group has non-trivial homotopy groups.

==Historical context and topology of spheres==
It is a surprising fact that the [[unit sphere]], sometimes denoted ''S''&lt;sup&gt;∞&lt;/sup&gt;, in infinite-dimensional [[Hilbert space]] ''H'' is a [[contractible space]], while no finite-dimensional spheres are contractible. This result, certainly known decades before Kuiper's, may have the status of [[mathematical folklore]], but it is quite often cited.&lt;ref&gt;[[John Baez]], "This Week's Finds in Mathematical Physics, Week 151", [http://www.math.ucr.edu/home/baez/week151.html]&lt;/ref&gt;&lt;ref&gt;Dave Rusin, newsgroup posting http://www.math.niu.edu/~rusin/known-math/93_back/s-infty&lt;/ref&gt; In fact more is true: ''S''&lt;sup&gt;∞&lt;/sup&gt; is [[diffeomorphic]] to ''H'', which is certainly contractible by its convexity.&lt;ref&gt;С. Bessaga, ''Every infinite-dimensional Hilbert space is diffeomorphic with its unit sphere''. Bull. Acad. Polon. Sci. Sér. Sci. Math. 14 (1966), 2731.&lt;/ref&gt; One consequence is that there are smooth counterexamples to an extension of the [[Brouwer fixed-point theorem]] to the unit ball in ''H''.&lt;ref&gt;Andrzej Granas, [[James Dugundji]], ''Fixed point theory'' (2003), pp. 82-3.&lt;/ref&gt; The existence of such counter-examples that are [[homeomorphism]]s was shown in 1943 by [[Shizuo Kakutani]], who may have first written down a proof of the contractibility of the unit sphere.&lt;ref&gt;S. Kakutani, ''Topological properties of the unit sphere in Hilbert space'', Proc. Imp. Acad. Tokyo 19 (1943), 269–271.&lt;/ref&gt; But the result was anyway essentially known (in 1935 [[Andrey Nikolayevich Tychonoff]] showed that the unit sphere was a retract of the unit ball).&lt;ref&gt;Andrzej Granas, James Dugundji, p. 108.&lt;/ref&gt;

The result on the group of bounded operators was proved by the Dutch mathematician [[Nicolaas Kuiper]], for the case of a separable Hilbert space; the restriction of separability was later lifted.&lt;ref&gt;[[Luc Illusie]], ''Contractibilité du groupe linéaire des espaces de Hilbert de dimension infinie'', [[Séminaire Bourbaki]] 1964, Exp. No. 284.&lt;/ref&gt; The same result, but for the [[strong operator topology]] rather than the norm topology, was published in 1963 by [[Jacques Dixmier]] and [[Adrien Douady]].&lt;ref&gt;Lemme 3 on p. 26, [http://archive.numdam.org/ARCHIVE/BSMF/BSMF_1963__91_/BSMF_1963__91__227_0/BSMF_1963__91__227_0.pdf ''Champs continus d’espaces hilbertiens'' (PDF)], Bulletin de la Société Mathématique de France, 91 (1963), p. 227-284.&lt;/ref&gt; The geometric relationship of the sphere and group of operators is that the unit sphere is a [[homogeneous space]] for the unitary group ''U''. The stabiliser of a single vector ''v'' of the unit sphere is the unitary group of the orthogonal complement of ''v''; therefore the [[homotopy long exact sequence]] predicts that all the homotopy groups of the unit sphere will be trivial. This shows the close topological relationship, but is not in itself quite enough, since the inclusion of a point will be a [[weak homotopy equivalence]] only, and that implies contractibility directly only for a [[CW complex]]. In a paper published two years after Kuiper's,&lt;ref&gt;Richard Palais, ''Homotopy Theory of Infinite Dimensional Manifolds'', Topology, vol. 5, pp.1-16 (1966).&lt;/ref&gt; Richard Palais provided technical results on infinite-dimensional manifolds sufficient to resolve this issue.&lt;ref&gt;E.g. http://math.leetspeak.org/GN/homotopy_groups_of_operator_groups.pdf&lt;/ref&gt;

==Bott's unitary group==

There is another infinite-dimensional unitary group, of major significance in [[homotopy theory]], that to which the [[Bott periodicity theorem]] applies. It is certainly not contractible. The difference from Kuiper's group can be explained: Bott's group is the subgroup in which a given operator acts non-trivially only on a subspace spanned by the first ''N'' of a fixed orthonormal basis {''e''&lt;sub&gt;''i''&lt;/sub&gt;}, for some ''N'', being the identity on the remaining basis vectors.

==Applications==
An immediate consequence, given the general theory of [[fibre bundle]]s, is that every [[Hilbert bundle]] is a [[trivial bundle]].&lt;ref&gt;Booss and Bleecker, ''Topology and Analysis'' (1985), p. 67.&lt;/ref&gt;

The result on the contractibility of ''S''&lt;sup&gt;∞&lt;/sup&gt; gives a geometric construction of [[classifying space]]s for certain groups that act freely it, such as the cyclic group with two elements and the [[circle group]]. The unitary group ''U'' in Bott's sense has a classifying space ''BU'' for complex [[vector bundle]]s (see [[Classifying space for U(n)]]). A deeper application coming from Kuiper's theorem is the proof of the '''Atiyah–Jänich theorem''' (after [[Klaus Jänich]] and [[Michael Atiyah]]), stating that the space of [[Fredholm operator]]s on ''H'', with the norm topology, represents the functor ''K''(.) of topological (complex) K-theory, in the sense of homotopy theory. This is given by Atiyah.&lt;ref&gt;[[Michael Atiyah]], ''K-theory'' p. 153 and p. 162-3, ''Collected Works'' volume 2, pp. 590-600.&lt;/ref&gt;

==Case of Banach spaces==
The same question may be posed about invertible operators on any [[Banach space]] of infinite dimension. Here there are only partial results. Some classical sequence spaces have the same property, namely that the group of invertible operators is contractible. On the other hand, there are examples known where it fails to be a [[connected space]].&lt;ref&gt;Herbert Schröder, [https://arxiv.org/PS_cache/math/pdf/9810/9810069v1.pdf ''On the topology of the group of invertible elements'' (PDF), preprint survey].&lt;/ref&gt; Where all homotopy groups are known to be trivial, the contractibility in some cases may remain unknown.

==References==
{{reflist}}
* {{cite journal| last=Kuiper | first=N. | title=The homotopy type of the unitary group of Hilbert space | journal=[[Topology (journal)|Topology]] | volume=3 | year=1965| issue=1 | pages=19&amp;ndash;30 | doi=10.1016/0040-9383(65)90067-4}}

[[Category:K-theory]]
[[Category:Operator theory]]
[[Category:Hilbert space]]
[[Category:Theorems in topology]]
[[Category:Topology of Lie groups]]</text>
      <sha1>1p6b8u7yaltuqwlutkcrr8yan811zz3</sha1>
    </revision>
  </page>
  <page>
    <title>Maass–Selberg relations</title>
    <ns>0</ns>
    <id>33188525</id>
    <revision>
      <id>814475009</id>
      <parentid>749358293</parentid>
      <timestamp>2017-12-09T01:21:41Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=[[Annals of Mathematics|Annals of Mathematics. Second Series]] → journal=[[Annals of Mathematics]] |series=Second Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3915">In mathematics, the '''Maass–Selberg relations''' are some relations describing the inner products of truncated [[real analytic Eisenstein series]], that in some sense say that distinct Eisenstein series are orthogonal. {{harvs|txt|last=Maass|authorlink=Hans Maass|year=1949|loc=p.169–170|year2=1964|loc2=p. 195–215}} introduced the Maass–Selberg relations for the case of real analytic Eisenstein series on the upper half plane.  {{harvs|txt|last=Selberg|authorlink=Atle Selberg|year=1963|loc=p.183–184}} extended the relations to symmetric spaces of rank 1. {{harvtxt|Harish-Chandra|1968|loc=p.75}} generalized the Maass–Selberg relations to Eisenstein series of higher rank semisimple group (and named the relations after Maass and Selberg).   {{harvs|txt|last=Harish-Chandra|year1=1972|year2=1976}} found some analogous relations between [[Eisenstein integral]]s, that he also called Maass–Selberg relations.

Informally, the Maass–Selberg relations say that the inner product of two distinct Eisenstein series is zero. However the integral defining the inner product does not converge, so the Eisenstein series first have to be truncated. The Maass–Selberg relations then say that the inner product of two truncated Eisenstein series is given by a finite sum of elementary factors that depend on the truncation chosen, whose [[Hadamard's finite part|finite part]] tends to zero as the truncation is removed.

==References==

*{{Citation | last1=Harish-Chandra | editor1-last=Mars | editor1-first=J. G. M. | title=Automorphic forms on semisimple Lie groups | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | isbn=978-3-540-04232-7 | doi=10.1007/BFb0098434 |mr=0232893 | year=1968 | volume=62}}
*{{Citation | last1=Harish-Chandra | editor1-last=Gulick | editor1-first=Denny | editor2-last=Lipsman | editor2-first=Ronald L. | title=Conference on Harmonic Analysis (Univ. Maryland, College Park, Md., 1971) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series= Lecture Notes in Mathematics | isbn=978-3-540-05856-4 | doi=10.1007/BFb0059640 |mr=0399355 | year=1972 | volume=266 | chapter=On the theory of the Eisenstein integral | pages=123–149}}
*{{Citation | last1=Harish-Chandra | title=Harmonic analysis on real reductive groups. III. The Maass-Selberg relations and the Plancherel formula | jstor=1971058 |mr=0439994 | year=1976 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=104 | issue=1 | pages=117–201 | doi=10.2307/1971058}}
*{{Citation | last1=Kubota | first1=Tomio | title=Elementary theory of Eisenstein series | url=https://books.google.com/books?id=7TbvAAAAMAAJ | publisher=Kodansha Ltd. | location=Tokyo | isbn=978-0-470-50920-3 |mr=0429749 | year=1973}}
*{{Citation | last1=Maass | first1=Hans | title=Über eine neue Art von nichtanalytischen automorphen Funktionen und die Bestimmung Dirichletscher Reihen durch Funktionalgleichungen | doi=10.1007/BF01329622 |mr=0031519 | year=1949 | journal=[[Mathematische Annalen]] | issn=0025-5831 | volume=121 | pages=141–183}}
*{{Citation | last1=Maass | first1=Hans | editor1-last=Lal | editor1-first=Sunder | title=Lectures on modular functions of one complex variable | url=http://www.math.tifr.res.in/~publ/ln/tifr29.pdf | publisher=Tata Institute of Fundamental Research | location=Bombay | series=Tata Institute of Fundamental Research Lectures on Mathematics | isbn=978-3-540-12874-8 |mr=0218305 | year=1964 | volume=29}}
*{{Citation | last1=Selberg | first1=Atle | title=Proc. Internat. Congr. Mathematicians (Stockholm, 1962) | url=http://mathunion.org/ICM/ICM1962.1/ | publisher=Inst. Mittag-Leffler | location=Djursholm |mr=0176097 | year=1963 | chapter=Discontinuous groups and harmonic analysis | pages=177–189}}

{{DEFAULTSORT:Maass-Selberg relations}}
[[Category:Modular forms]]
[[Category:Representation theory]]</text>
      <sha1>3bzvgnzrytdat9ycchtwd7cecu3z5ld</sha1>
    </revision>
  </page>
  <page>
    <title>Mikhail Atallah</title>
    <ns>0</ns>
    <id>33253916</id>
    <revision>
      <id>860560412</id>
      <parentid>841574732</parentid>
      <timestamp>2018-09-21T14:15:11Z</timestamp>
      <contributor>
        <ip>155.178.180.12</ip>
      </contributor>
      <comment>/* Biography */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6632">{{Infobox scientist
| boxwidth          =
| name              = Mikhail Atallah
| image             = 
| image_size        = 
| alt               =
| caption           = 
| birth_date        = 
| birth_place       = 
| residence         = 
| nationality       = 
| fields            = [[Computer Science]]
| workplaces        = [[Purdue University]]
| alma_mater        = [[Johns Hopkins University]]
| doctoral_advisor  = [[S. Rao Kosaraju]]
| academic_advisors = 
| doctoral_students =  
| notable_students  =
| known_for         = 
| awards            = 
}}
'''Mikhail Jibrayil (Mike) Atallah''' is a [[Lebanese American]] [[computer scientist]], a distinguished professor of computer science at [[Purdue University]].

==Biography==
Atallah received his bachelor's degree from the [[American University of Beirut]] in 1975. He then moved to [[Johns Hopkins University]] for his graduate studies, earning a master's degree in 1980 and a Ph.D. in 1982 under the supervision of [[S. Rao Kosaraju]]. Since that time he has been a member of the Purdue University faculty.&lt;ref name="purdue-cs"&gt;[http://www.cs.purdue.edu/people/faculty/mja/ Department faculty profile], Purdue University, retrieved 2011-09-29.&lt;/ref&gt;&lt;ref name="mg"&gt;{{mathgenealogy|name=Mikhail Jibrayil Atallah|id=47076}}&lt;/ref&gt;

In 2001, Atallah co-founded Arxan Technologies, Inc., a provider of internet anti-piracy and anti-tampering software, and in 2007, he became its chief technology officer.&lt;ref name="arxan"&gt;[http://www.arxan.com/company/press-releases/mikhail-j-atallah-CTO-6-21-07.php Arxan Appoints Dr. Mikhail J. Atallah as Chief Technology Officer] {{webarchive|url=https://web.archive.org/web/20120129115257/http://www.arxan.com/company/press-releases/mikhail-j-atallah-CTO-6-21-07.php |date=2012-01-29 }}, Arxan Technologies, retrieved 2011-09-29.&lt;/ref&gt;

==Research==
Atallah has published over 200 papers on topics in [[algorithm]]s and [[computer security]].&lt;ref&gt;[http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Atallah:Mikhail_J=.html DBLP listing of Atallah's publications], retrieved 2011-09-29.&lt;/ref&gt;

Atallah's thesis work was on the subject of [[parallel algorithm]]s,&lt;ref name="mg"/&gt; and he continued working in that area as a faculty member.
Algorithmic research by Atallah includes papers on [[parallel computation|parallel]]  and [[dynamic problem (algorithms)|dynamic]] [[computational geometry]],&lt;ref&gt;{{citation
 | last = Atallah | first = Mikhail J.
 | doi = 10.1016/0898-1221(85)90105-1
 | issue = 12
 | journal = Computers &amp; Mathematics with Applications
 | mr = 822083
 | pages = 1171–1181
 | title = Some dynamic computational geometry problems
 | volume = 11
 | year = 1985}}. {{citation
 | last1 = Atallah | first1 = Mikhail J.
 | last2 = Goodrich | first2 = Michael T. | author2-link = Michael T. Goodrich
 | doi = 10.1016/0743-7315(86)90011-0
 | issue = 4
 | journal = J. Parallel Distrib. Comput.
 | pages = 492–507
 | title = Efficient parallel solutions to some geometric problems
 | volume = 3
 | year = 1986}}.&lt;/ref&gt; finding the [[symmetry|symmetries]] of geometric figures,&lt;ref&gt;{{citation
 | last = Atallah | first = Mikhail J.
 | doi = 10.1109/TC.1985.1676605
 | issue = 7
 | journal = IEEE Transactions on Computers
 | mr = 800338
 | pages = 663–666
 | title = On symmetry detection
 | volume = 34
 | year = 1985}}.&lt;/ref&gt; [[divide and conquer algorithm]]s,&lt;ref&gt;{{citation
 | last1 = Atallah | first1 = Mikhail J.
 | last2 = Cole | first2 = Richard
 | last3 = Goodrich | first3 = Michael T. | author3-link = Michael T. Goodrich
 | doi = 10.1137/0218035
 | issue = 3
 | journal = SIAM Journal on Computing
 | mr = 996833
 | pages = 499–532
 | title = Cascading divide-and-conquer: a technique for designing parallel algorithms
 | volume = 18
 | year = 1989}}.&lt;/ref&gt; and efficient parallel computations of the [[Levenshtein distance]] between pairs of strings.&lt;ref&gt;{{citation
 | last1 = Apostolico | first1 = Alberto
 | last2 = Atallah | first2 = Mikhail J.
 | last3 = Larmore | first3 = Lawrence L. | author3-link = Lawrence L. Larmore
 | last4 = McFaddin | first4 = Scott
 | doi = 10.1137/0219066
 | issue = 5
 | journal = SIAM Journal on Computing
 | mr = 1059665
 | pages = 968–988
 | title = Efficient parallel algorithms for string editing and related problems
 | volume = 19
 | year = 1990| citeseerx = 10.1.1.100.9057}}.&lt;/ref&gt; With his student Marina Blanton, Atallah is the editor of the ''Algorithms and Theory of Computation Handbook'' (CRC Press, 2nd ed., 2009, {{ISBN|978-1-58488-818-5}}).

Atallah's more recent research has been in the area of [[computer security]]. His work in this area has included techniques for text-based [[digital watermarking]].&lt;ref&gt;{{citation|url=http://www.timeshighereducation.co.uk/story.asp?storyCode=159577&amp;sectioncode=26|title=Word order may stump hackers|journal=[[Times Higher Education]]|date=May 4, 2001}}.&lt;/ref&gt;&lt;ref&gt;{{citation|url=https://www.sciencedaily.com/releases/2001/04/010427071702.htm|title=Purdue Team Develops Watermark To Protect Electronic Documents|journal=ScienceDaily|date=April 27, 2001}}&lt;/ref&gt; and the addition of multiple guard points within software as an anti-piracy measure.&lt;ref&gt;{{citation|title=Multiple "guards" foil hackers|journal=USA Today Magazine|date=June 1, 2003}}.&lt;/ref&gt;

==Awards and honors==
In 2006, Atallah was elected as a [[fellow]] of the [[Association for Computing Machinery]] for his "contributions to parallel and distributed computation".&lt;ref&gt;[http://fellows.acm.org/fellow_citation.cfm?id=1978675&amp;srt=all [[List of Fellows of the Association for Computing Machinery|ACM Fellow]] award citation], retrieved 2011-09-29.&lt;/ref&gt; He has also been a fellow of the [[IEEE]] since 1997.&lt;ref name="purdue-cs"/&gt;&lt;ref&gt;[http://www.ieee.org/membership_services/membership/fellows/regional/region_four.html Fellows in Region 4] {{webarchive|url=https://web.archive.org/web/20110805000048/http://www.ieee.org/membership_services/membership/fellows/regional/region_four.html |date=2011-08-05 }}, IEEE, retrieved 2011-09-29.&lt;/ref&gt;

==References==
{{Reflist|colwidth=30em}}

{{Authority control}}

{{DEFAULTSORT:Atallah, Mikhail J.}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Researchers in geometric algorithms]]
[[Category:Computer security academics]]
[[Category:American University of Beirut alumni]]
[[Category:Johns Hopkins University alumni]]
[[Category:Purdue University faculty]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Fellow Members of the IEEE]]</text>
      <sha1>pm5cuxen47hfk09liyarvuools85xc3</sha1>
    </revision>
  </page>
  <page>
    <title>Miklós Simonovits</title>
    <ns>0</ns>
    <id>31394970</id>
    <revision>
      <id>855333957</id>
      <parentid>855201850</parentid>
      <timestamp>2018-08-17T15:00:44Z</timestamp>
      <contributor>
        <username>Tudor987</username>
        <id>19636086</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5464">{{eastern name order|Simonovits Miklós}}{{Infobox person
| name = Miklós Simonovits
| birth_date = 4 September 1943
| birth_place = [[Budapest]]
| nationality = [[Hungary|Hungarian]]
| education = [[PhD.]] [[Eotvos Lorand University]], 1971
| occupation = [[Mathematician]]
| organization = [[Alfréd Rényi Institute of Mathematics]], [[Budapest]]
| known_for = [[Extremal Graph Theory]] [[Extremal Combinatorics]]
| awards = [[Szele Tibor-emlékérem]] (1989)
[[Akadémiai Díj]] (1993)
[[Széchenyi Prize]] (2014)
| website = http://www.renyi.hu/~miki/
}}
'''Miklós Simonovits''' (4 September 1943 in Budapest) is a [[Hungarian people|Hungarian]] mathematician who currently works at the [[Alfréd Rényi Institute of Mathematics|Rényi Institute of Mathematics]] in [[Budapest]] and is a member of the [[Hungarian Academy of Sciences]]. He is on the advisory board of the journal [[Combinatorica]]. He is best known for his work in [[extremal graph theory]] and was awarded [[Széchenyi Prize]] in 2014. Among other things, he discovered the method of progressive induction which he used to describe graphs which do not contain a predetermined graph and the number of edges is close to maximal. With [[László Lovász|Lovász]], he gave a [[randomized algorithm]] using ''O''(''n''&lt;sup&gt;7&lt;/sup&gt; log&lt;sup&gt;2&lt;/sup&gt; ''n'')
separation calls to approximate the volume of a convex body within a fixed relative error.

Simonovits was also one of the most frequent collaborators with [[Paul Erdős]], co-authoring 21 papers with him.&lt;ref&gt;{{Cite web| title = Papers of Paul Erdős | url = http://www.renyi.hu/~p_erdos/}}&lt;/ref&gt;

== Career ==
He began his university studies at the Mathematics department of '''[[Eötvös Loránd University]]''' in 1962, after winning a [https://www.imo-official.org/participant_r.aspx?id=9817 silver and bronze medal] at the International Mathematics Olympiad in 1961 and 1962 respectively. He got his diploma in mathematics from the university in 1967 and defended his PhD under [[Vera T. Sós]] in 1971. He taught as an assistant professor and then associate professor at Eotvos Lorand, from 1971 to 1979, mainly combinatorics and analysis. He joined Alfréd Rényi Institute of Mathematics in 1979. In the coming years, he was appointed as the professor in Discrete mathematics. He was also a visiting professor at a number of foreign institutions in US and Canada. He was also a visiting researcher at Moscow State University, Charles University, Prague, Warsaw University, Denmark and various institutions in India. He was elected as a corresponding member at the Hungarian Academy of Sciences in 2001 and full membership was awarded in 2008.

== Academic work ==
His main research interests are Combinatorics, Extremal Graph Theory, Theoretical Computer Science and Random Graphs.

He discovered the method of progressive induction which he used to describe graphs which do not contain a predetermined graph and the number of edges is close to maximal. With [[László Lovász|Laszlo Lovász]], he gave a [[randomized algorithm]] using ''O''(''n''&lt;sup&gt;7&lt;/sup&gt; log&lt;sup&gt;2&lt;/sup&gt; ''n'')
separation calls to approximate the volume of a convex body within a fixed relative error.

He is a long-time collaborator of [[Endre Szemerédi|Endre Szemeredi]] and worked with him closely.

Simonovits was also one of the most frequent collaborators with [[Paul Erdős]], co-authoring 21 papers with him.

== Family ==
His father Simonovits István (1907–1985) was a doctor and a hematologist. He was a member of the Hungarian Academy of Sciences. Beke Anna, his mother, was a mathematics and physics teacher, who also worked in a book publishing company.

== Awards ==
* [[:hu:Szele Tibor-emlékérem|Tibor Szele-Medal]] (1989)
* [[:hu:Akadémiai Díj|Academy Award]] (1993)
* [[:hu:Széchenyi-díj|Széchenyi-Prize]] (2014)

== Key publications ==
* ''A limit theorem in graph theory'' (Erdős Pállal, 1966)
* ''Anti-Ramsey theorems'' (társszerző, 1973)
* ''On the Structure of Edge Graphs-2'' (társszerző, 1976)
* ''Spanning Retracts of a Partially Ordered Set'' (társszerző, 1980)
* ''Compactness Results in Extremal Graph-Theory'' (Erdős Pállal, 1982)
* ''Supersaturated Graphs and Hypergraphs'' (Erdős Pállal, 1983)
* ''On Restricted Colorings of K_n'' ([[:hu:T. Sós Vera|T. Sós Verával]], 1984)
* ''Szemerédi Partition And Quasi-Randomness'' (T. Sós Verával, 1991)
* ''Random Walks in a Convex Body and an Improved Volume Algorithm'' ([[:hu:Lovász László (matematikus)|Lovász Lászlóval]], 1993)
* ''Isoperimetric Problems for Convex Bodies and a Localization Lemma'' (társszerző, 1995)
* ''Szemerédi's Regularity Lemma and its Applications in Graph Theory'' (Komlós Jánossal, 1996)
* ''The Regularity Lemma and its applications in graph theory'' (társszerző, 2002)
* ''Determinisztikus és véletlen struktúrák az extrém gráfelméletben'' (2002)
* ''Triple Systems not Containing a Fano Configuration'' ([[:hu:Füredi Zoltán|Füredi Zoltánnal]], 2005)
* ''Stabilitási módszerek alkalmazása a gráfelméletben'' (2008)

==References==
&lt;references/&gt;

==External links==
* [http://www.renyi.hu/~miki/ Miklós Simonovits' home page]

{{Authority control}}

{{DEFAULTSORT:Simonovits, Miklos}}
[[Category:Living people]]
[[Category:Combinatorialists]]
[[Category:Members of the Hungarian Academy of Sciences]]
[[Category:Hungarian mathematicians]]
[[Category:Hungarian people]]
[[Category:1943 births]]</text>
      <sha1>kryscxgooinburckwi4obhzjx44obrb</sha1>
    </revision>
  </page>
  <page>
    <title>Mlecchita vikalpa</title>
    <ns>0</ns>
    <id>48725243</id>
    <revision>
      <id>840196867</id>
      <parentid>787128289</parentid>
      <timestamp>2018-05-08T10:02:37Z</timestamp>
      <contributor>
        <ip>2405:204:A507:CDD2:C84E:C3C:E258:B3E9</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6827">'''Mlecchita Vikalpa''' is one of the 64 arts  listed in [[Vatsyayana]]'s [[Kamasutra]]. The list appears in Chapter 3 of Part I of Kamasutra and Mlecchita Vikalpa appears as the 44th item in the list. The term Mlecchita Vikalapa has been translated into English as "the art of understanding writing in cypher, and the writing of words in a peculiar way".&lt;ref name="translation"&gt;{{cite book|last1=Translators: Richard Burton, Bhagavanlal Indrajit, Shivaram Parashuram Bhide|title=The Kama Sutra of Vatsyayana (Translated From The Sanscrit In Seven Parts With Preface,Introduction and Concluding Remarks)|date=January 18, 2009|publisher=The Project Gutenberg|url=http://www.gutenberg.org/files/27827/27827-h/27827-h.htm|accessdate=3 December 2015}}&lt;/ref&gt;

Mlecchita Vikalpa is the art of secret writing and secret communications. In ''[[The Codebreakers]]'', a 1967 book by [[David Kahn (writer)|David Kahn]] about the history of [[cryptography]], the reference to Mlecchita Vikalpa in Kamasutra is cited as proof of the prevalence of cryptographic methods in [[ancient India]]. Though Kamasutra does not have details of the methods by which people of that time practiced this particular form of art, later commentators of Kamasutra have described several methods. For example, Yasodhara in his Jayamangala commentary on Kamasutra&lt;ref name=Kahn&gt;{{cite book|last1=David Kahn|title=The Codebreakers|date=December 1996|publisher=Simon and Schuster|isbn=9781439103555|page=74|url=https://books.google.co.in/books?id=SEH_rHkgaogC&amp;pg=PA1000&amp;lpg=PA1000&amp;dq=chinese+cryptography+history&amp;source=bl&amp;ots=_2hrl9t0B1&amp;sig=2LAjURo7zlj5YBoExJjZXbjDhNU&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiAidiN_KvJAhUUVI4KHfl9DA44ChDoAQgwMAQ#v=onepage&amp;q=chinese%20cryptography%20history&amp;f=false|accessdate=25 November 2015}}&lt;/ref&gt; gives descriptions of methods known by the names ''Kautilya'' and ''Muladeviya''. The ciphers described in the Jayamangala commentary are substitution ciphers: in Kautiliyam the letter substitutions are based on phonetic relations, and Muladeviya is a simplified version of Kautiliyam. There are also references to other methods for secret communications like  Gudhayojya, Gudhapada and  Gudhavarna. Some modern writers on cryptography have christened the ciphers alluded to in the Kamasutra as ''Kamasutra cipher'' or ''Vatsyayana cipher''.&lt;ref&gt;{{cite web|last1=Simon Singh|title=The Black Chamber|url=http://www.simonsingh.net/The_Black_Chamber/kamasutra.html|accessdate=4 December 2015}}&lt;/ref&gt;

The exact date of the composition of Kamasutra has not been fixed. It is supposed that Vatsyayana must have lived between the sixth and first century BC. However, the date of the Jayamangla commentary has been fixed as between the tenth and thirteenth centuries CE.&lt;ref name="translation"/&gt;

==Kautiliya==
This is a Mlecchita named after Kautilya, the author of the  ancient Indian political treatise, the [[Arthashastra]]. In this system, the short and long vowels, the anusvara and the spirants are interchanged for the consonants and the conjuncts. The following table shows the substitutions used in the Kautiliyam cipher. The characters not listed in the table are left unchanged.&lt;ref name=FineArts&gt;{{cite book|last1=Anil Baran Ganguly|title=Fine Arts of Ancient India|date=1979|publisher=Abhinav Publications|pages=1678 - 170|url=https://books.google.co.in/books?id=dw7NhcImr1oC&amp;pg=PA169&amp;lpg=PA169&amp;dq=muladeviya&amp;source=bl&amp;ots=CqJoSWHMuW&amp;sig=hdc94H8NrGqGBOSWuPbAzRg3JFk&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwja98vlg8HJAhWUwY4KHUe9DxYQ6AEIHTAA#v=onepage&amp;q=muladeviya&amp;f=false|accessdate=4 December 2015}}&lt;/ref&gt;

::{| class="wikitable"
|-
|a || ā || i || ī || u || ū || ṛ ||  	ṝ || ḷ || ḹ|| e || ai || o || au ||  	ṃ|| ḩ || ñ|| ś || ṣ || s || i || r || l || u
|-
| kh || g || gh ||ṅ || ch || j || jh || ñ  || ṭh || ḍ || ḍh || ṇ || th || d || dh || n || ph || b || bh || m || y || r || l || v 
|}

There is a simplified form of this scheme known by the name ''Durbodha''.

==Muladeviya==
Another form of secret writing mentioned in Yasodhara's commentary on Kamasutra is known by the name ''Muladeviya''. This existed both in the spoken form and in the written form. In the written form it is called ''Gudhalekhya''. This form of secret communications were used by kings' spies as well as traders in various geographical locations in India. Also this form of secret communications has been popular among thieves and robbers.&lt;ref name="FineArts"/&gt; However, there were variations in the actual scheme across the various geographical areas. For example, in the erstwhile Travancore Kingdom, spread over a part of present-day Kerala State in India, it was practiced under the name [[Mulabhadra]] with some changes from the schemes described by Yashodhara.

The cipher alphabet of Muladeviya consists of the reciprocal one specified in the table below.&lt;ref name="FineArts"/&gt;&lt;ref&gt;{{cite book|last1=Friedrich L Brauer|title=Decrypted Secrets: Methods and Maxims of Cryptology|date=2007|publisher=Springer|isbn=978-3-540-24502-5|pages=47}}&lt;/ref&gt;
 
::{| class="wikitable"
|-
| a || kh || gh || c || t || ñ || n || r || l || y
|-
| k || g || ṅ || ṭ || p || ṇ || m || ṣ || s || ś  
|}

The great Indian epic Mahabharata contains an incident involving the use of this type of secret talking.&lt;ref&gt;{{cite book|last1=Anil Baran Ganguly|title=Fine Arts in Ancient India|date=1979|publisher=Abhinav Publications|page=169|url=https://books.google.co.in/books?id=dw7NhcImr1oC&amp;pg=PA169&amp;lpg=PA169&amp;dq=muladeviya&amp;source=bl&amp;ots=CqJnVWPJCW&amp;sig=6R3BjnVtmeg2bJnwvdos4qKPxT4&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjG7KGJ8azJAhXEBY4KHWwPAjUQ6AEIHjAA#v=onepage&amp;q=muladeviya&amp;f=false|accessdate=26 November 2015}}&lt;/ref&gt; Duryodhana was planning to burn Pandavas alive and had made arrangements to send Pandavas to Varanavata. Vidura resorted to secret talk to warn Yudhishthira about the dangers in front of everybody present. Only Yudhishthira could understand the secret message. None others even suspected that it was a warning.

==Gudhayojya==
This is an elementary and trivial method for obscuring the true content of spoken messages and it is popular as a game among children. The idea is to add some unnecessary letters chosen randomly to the beginning or to the end of every word in a sentence. For example, to obscure the sentence "will visit you tonight" one may add the letters  "dis" at the beginning of every word and convey the message as "diswill disvisit disyou distonight" the real content of which may not be intelligible to the uninitiated  if pronounced rapidly.&lt;ref name="FineArts"/&gt;

==See also==
*[[Mulabhadra]]
*[[Pig Latin]]

==References==
{{reflist}}

{{Cryptography navbox | classical}}

[[Category:Cryptography]]
[[Category:History of cryptography]]
[[Category:Military communications]]
[[Category:Classical ciphers]]
[[Category:Kamashastra]]</text>
      <sha1>lhgi6jvfh0y4nbp16gpws8a1i1y4b3n</sha1>
    </revision>
  </page>
  <page>
    <title>Node influence metric</title>
    <ns>0</ns>
    <id>43679237</id>
    <revision>
      <id>846699139</id>
      <parentid>846304759</parentid>
      <timestamp>2018-06-20T10:51:32Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 1 [[arXiv|arxiv eprint(s)]], 7 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11260">In [[graph theory]] and [[network theory|network analysis]], '''node influence metrics''' are measures that rank or quantify the influence of every [[vertex (graph theory)|node]] (also called vertex) within a graph. They are related to [[Centrality| centrality indices]]. Applications include measuring the influence of each person in a [[social network]], understanding the role of infrastructure nodes in [[Transport network|transportation networks]], the [[Internet]], or [[urban network]]s, and the participation of a given node in disease dynamics.

== Origin and development ==
The traditional approach to understanding node importance is via [[Centrality | centrality indicators]]. Centrality indices are designed to produce a ranking which accurately identifies the most influential nodes. Since the mid 2000s, however, social scientists and  network physicists have begun to question the suitability of centrality indices for understanding node influence. Centralities may indicate the most influential nodes, but they are rather less informative for the vast majority of nodes which are not highly influential.

Borgatti and Everett's 2006 review article&lt;ref name="Borgatti2006"&gt;
{{cite journal | last1=Borgatti | first1=Steve |last2=Everett|first2=Martin|title=A graph-theoretic perspective on centrality|journal=Social Networks| year=2006|volume=28|pages=466–484 | doi=10.1016/j.socnet.2005.11.005}}
&lt;/ref&gt;
showed that the accuracy of centrality indices is highly dependent on network topology.
This finding has been repeatedly observed since then. (e.g.&lt;ref name="daSilva2012"&gt;{{cite journal | last1=da Silva|first1=Renato |last2=Viana|first2=Matheus|last3=da F. Costa |first3=Luciano| title=Predicting epidemic outbreak from individual features of the spreaders| journal=J. Stat Mech Theor Exp | year=2012|volume=2012|pages=P07005|number=07 | doi=10.1088/1742-5468/2012/07/p07005|arxiv=1202.0024|bibcode=2012JSMTE..07..005A}}&lt;/ref&gt;&lt;ref name="Lawyer2015"&gt;
{{cite journal |last1= Lawyer |first1= Glenn |year= 2015 |title= Understanding the spreading power of all nodes in a network: a continuous-time perspective |journal=Sci Rep |volume=5|pages=8665|doi=10.1038/srep08665 |pmid=25727453 |pmc=4345333|arxiv=1405.6707|bibcode=2015NatSR...5E8665L}}&lt;/ref&gt;).
In 2012, Bauer and colleagues reminded us that centrality indices only rank nodes but do not quantify the difference between them.&lt;ref name="Bauer2012"&gt;
{{cite journal | last1=Bauer|first1=Frank | last2=Lizier|first2=Joseph|title=Identifying influential spreaders and efficiently estimating infection  numbers in epidemic models: A walk counting approach| journal=Europhys Lett | year=2012| volume=99| pages=68007|number=6 | doi=10.1209/0295-5075/99/68007|arxiv=1203.0502|bibcode=2012EL.....9968007B}}
&lt;/ref&gt;
In 2013, Sikic and colleagues presented strong evidence that centrality indices considerably underestimate the power of non-hub nodes.&lt;ref name="Sikic2013"&gt;
{{ cite journal| last1= Sikic| first1=Mile|last2=Lancic|first2=Alen|last3=Antulov-Fantulin|first3=Nino|last4=Stefanic|first4=Hrvoje| title = Epidemic centrality -- is there an underestimated epidemic impact  of network peripheral nodes? |journal = The European Physical Journal B |volume=86 |number=10 |pages=1–13 |year=2013 | doi=10.1140/epjb/e2013-31025-5|arxiv=1110.2558}}
&lt;/ref&gt;
The reason is quite clear. The accuracy of a centrality measure depends on network topology, but complex networks have heterogenous topology. Hence a centrality measure which is appropriate for identifying highly influential nodes will most likely be inappropriate for the remainder of the network.&lt;ref name="Lawyer2015"/&gt;

This has inspired the development of novel methods designed to measure the influence of all network nodes. The most general of these are
the '''accessibility''', which  uses the diversity of random walks to measure how accessible the rest of the network is from a given start node,&lt;ref name="Travencolo2008"&gt;{{ cite journal| last1=Travencolo|first1=B. a. N.|last2=da F. Costa| first2 =Luciano| title=Accessibility in complex networks| journal=Phys Lett A| year=2008|volume=373|number=1|pages=89–95| doi=10.1016/j.physleta.2008.10.069}}&lt;/ref&gt;
and the '''expected force''',  derived from the expected value of the [[force of infection]] generated by a node.&lt;ref name="Lawyer2015"/&gt;
Both of these measures can be meaningfully computed from the structure of the network alone.

== Accessibility ==
The '''Accessibility''' is derived from the theory of random walks. It measures the diversity of [[self-avoiding walk]]s which start from a given node. A walk on a network is a sequence of adjacent vertices; a self-avoiding walk lists visits each vertex at most once. 
The original work used simulated walks of length 60 to characterize the network of urban streets in a Brazilian city.&lt;ref name="Travencolo2008"/&gt;
It was later formalized as a modified form of hierarchical degree which controls for both transmission probabilities and the diversity of walks of a given fixed length.&lt;ref name='Viana2012'&gt;{{ cite journal| last1=Viana|first1=Matheus|last2=Batista|first2=Joao| last3=da F. Costa|first3=Luciano| title=Effective number of accessed nodes in complex networks | journal =Phys Rev E|year=2012 | volume=85| number = 3 pt 2|pages=036105}}
&lt;/ref&gt;

=== Definition ===
The hierarchical degree measures the number of nodes reachable from a start node by performing walks of length &lt;math&gt;h&lt;/math&gt;. For a fixed &lt;math&gt;h&lt;/math&gt; and walk type, each of these neighbors is reached with a (potentially different) probability &lt;math&gt;p_j^{(h)}&lt;/math&gt;. 
Given a vector of such probabilities, the accessibility of node &lt;math&gt;i&lt;/math&gt; at scale &lt;math&gt;h&lt;/math&gt; is defined

:&lt;math&gt;\kappa_i^{(h)} = \exp \left( - \sum_j p_j^{(h)} \log p_j^{(h)} \right) &lt;/math&gt;

The probabilities can be based on uniform-probability random walks, or additionally modulated by edge weights and/or explicit (per edge) transmission probabilities.&lt;ref name='Viana2012'/&gt;

=== Applications ===
The accessibility has been shown to reveal community structure in urban networks,&lt;ref name="Travencolo2008"/&gt; corresponds to the number of nodes which can be visited in a defined time period,&lt;ref name="Viana2012"/&gt; and is predictive of the outcome of [[Compartmental models in epidemiology|epidemiological SIR model]] spreading processes on networks with large [[Network science#Diameter of a network|diameter]] and low [[Network science#Density|density]].&lt;ref name="daSilva2012"/&gt;

== Expected force ==

The '''expected force''' measures node influence from an epidemiological perspective. It is the [[expected value]] of the [[force of infection]] generated by the node after two transmissions.

=== Definition ===

The expected force of a node  &lt;math&gt;i&lt;/math&gt; is given by

:&lt;math&gt;\kappa_i = - \sum_{j=1}^J d_j \log(d_j)&lt;/math&gt;

where the sum is taken over the set &lt;math&gt;J&lt;/math&gt; of all possible transmission clusters resulting from two transmissions starting from &lt;math&gt;i&lt;/math&gt;, and &lt;math&gt;d_j&lt;/math&gt; is the normalized cluster degree of cluster &lt;math&gt;j \in J&lt;/math&gt;.

The definition naturally extends to directed networks by limiting the enumeration &lt;math&gt;J&lt;/math&gt; by edge direction.
Likewise, extension to weighted networks, or networks with heterogeneous transmission probabilities, is a matter of adjusting the normalization of &lt;math&gt;d_j&lt;/math&gt; to include the probability that that cluster forms. 
It is also possible to use more than two transmissions to define the set &lt;math&gt;J&lt;/math&gt;.&lt;ref name="Lawyer2015"/&gt;

=== Applications ===

The expected force has been shown to strongly correlate with SI, SIS, and SIR epidemic outcomes over a broad range of network topologies, both simulated and empirical.&lt;ref name="Lawyer2015"/&gt;&lt;ref name="Lawyer2014tr"&gt;{{cite journal |last1= Lawyer |first1= Glenn |year= 2014 |title= Technical Report: Performance of the Expected Force on AS-level Internet topologies | arxiv=1406.4785 |bibcode= 2014arXiv1406.4785L }}&lt;/ref&gt;
It has also been used to measure the pandemic potential of world airports,&lt;ref&gt;{{cite journal|last1=Lawyer|first1=Glenn|title=Measuring the potential of individual airports for pandemic spread over the world airline network|journal=BMC Infectious Diseases|date=2016|volume=16|page=70|doi=10.1186/s12879-016-1350-4|pmid=26861206|url=https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-016-1350-4|pmc=4746766}}&lt;/ref&gt; and mentioned in the context of 
digital payments,&lt;ref&gt;{{cite journal|last1=Milkau|first1=Udo|last2=Bott|first2=Jürgen|title=Digitalisation in payments: From interoperability to centralised models?|journal=Journal of Payments Strategy &amp; Systems|date=2015|volume=9|issue=3|url=http://www.ingentaconnect.com/content/hsp/jpss/2015/00000009/00000003/art00008}}&lt;/ref&gt;
ecology,&lt;ref&gt;{{cite journal|last1=Jordan|first1=Lyndon|last2=Maguire|first2=Sean|last3=Hofmann|first3=Hans|last4=Kohda|first4=Masanori|title=The social and ecological costs of an ‘over-extended' phenotype|journal=Proceedings of the Royal Society B|date=2016|volume=283|issue=1822|doi=10.1098/rspb.2015.2359|pmid=26740619|pmc=4721094|pages=20152359}}&lt;/ref&gt; 
fitness,&lt;ref&gt;{{cite journal|last1=Pereira|first1=Vanessa|last2=Gama|first2=Maria|last3=Sousa|first3=Filipe|last4=Lewis|first4=Theodore|last5=Gobatto|first5=Claudio|last6=Manchado-Gobatto|first6=Fúlvia|title=Complex network models reveal correlations among network metrics, exercise intensity and role of body changes in the fatigue process|journal=Scientific Reports|date=2015|volume=5|page=10489|doi=10.1038/srep10489|pmid=25994386|pmc=4440209|bibcode=2015NatSR...510489P}}&lt;/ref&gt;
and project management.&lt;ref&gt;{{cite journal|last1=Ellinas|first1=Christos|last2=Allan|first2=Neil|last3=Durugbo|first3=Christopher|last4=Johansson|first4=Anders|title=How Robust Is Your Project? From Local Failures to Global Catastrophes: A Complex Networks Approach to Project Systemic Risk|journal=PLoS One|date=2015|doi=10.1371/journal.pone.0142469|pmid=26606518|url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142469|volume=10|pmc=4659599|pages=e0142469|bibcode=2015PLoSO..1042469E}}&lt;/ref&gt;

== Other approaches ==

Others suggest metrics which explicitly encode the dynamics of a specified process unfolding on the network.
The  '''dynamic influence''' is the proportion of infinite walks starting from each node, where walk steps are scaled such that the linear dynamics of the system are expected to converge to a non-null steady state.&lt;ref name="Klemm2012"&gt;
{{cite journal | last1=Klemm|first1=Konstantin|last2=Serrano|first2=M Angeles|last3=Eguiluz|first3=Victor|last4=Miguel|first4=Maxi San |title= A measure of individual role in collective dynamics| journal =Sci Rep|year=2012|volume=2|pages=292|doi=10.1038/srep00292|bibcode=2012NatSR...2E.292K}}&lt;/ref&gt; The '''Impact''' sums, over increasing walk lengths, the probability of transmission to the end node of the walk and that the end node has not  been previously visited by a shorter walk.&lt;ref name="Bauer2012"/&gt;
While both measures well predict the outcome of the dynamical systems they encode, in each case the authors admit that results from one dynamic do not translate to other dynamics.

==References==
{{reflist}}

*
*
*
*

[[Category:Network analysis]]
[[Category:Graph theory]]</text>
      <sha1>661oz3r6ca2u37dvi0o2s56qrpnirv4</sha1>
    </revision>
  </page>
  <page>
    <title>Nonlinear system identification</title>
    <ns>0</ns>
    <id>40158142</id>
    <revision>
      <id>869640362</id>
      <parentid>851958023</parentid>
      <timestamp>2018-11-19T21:24:02Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding link to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21833">[[System identification]] is a method of identifying or measuring the [[mathematical model]] of a [[system]] from measurements of the system inputs and outputs. The applications of system identification include any system where the inputs and outputs can be measured and include [[industrial process]]es, [[control system]]s, [[economic data]], [[biology]] and the [[life sciences]], [[medicine]], [[social system]]s and many more.

A [[nonlinear system]] is defined as any system that is not linear, that is any system that does not satisfy the [[superposition principle]]. This negative definition tends to obscure that there are very many different types of nonlinear systems. Historically, system identification for nonlinear systems&lt;ref name="Nelles"&gt;Nelles O. "Nonlinear System Identification: From Classical Approaches to Neural Networks". Springer Verlag,2001&lt;/ref&gt;&lt;ref name="SAB1"&gt;Billings S.A. "Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains". Wiley, 2013&lt;/ref&gt; has developed by focusing on specific classes of system and can be broadly categorised into five basic approaches, each defined by a model class:
# [[Volterra series]] models,
# block structured models,
# [[neural network]] models,
# NARMAX models, and
# [[State-space representation|State-space]] models.

There are four steps to be followed for system identification: data gathering, model postulate, parameter identification and model validation. Data gathering is considered as the first and essential part in identification terminology, used as the input for the model which is prepared later. It consists of selecting an appropriate data set, pre-processing and processing. It involves the implementation of the known algorithms together with the transcription of flight tapes, data storage and data management, calibration, processing, analysis and presentation. Moreover, model validation is necessary to gain confidence in, or reject, a particular model. In particular, the parameter estimation and the model validation are integral parts of the system identification. Validation refers to the process of confirming the conceptual model and demonstrating an adequate correspondence between the computational results of the model and the actual data.&lt;ref&gt;{{Cite book|title = Data Processing Consideration and Model Validation in Flight Vehicle System Identification|url = https://link.springer.com/chapter/10.1007/978-3-642-32573-1_46|publisher = Springer Berlin Heidelberg|date = 2011-12-01|isbn = 978-3-642-32572-4|pages = 269–274|series = Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering|doi = 10.1007/978-3-642-32573-1_46|first = Sepehr|last = Nesaei|first2 = Kamran|last2 = Raissi|editor-first = Vinu V.|editor-last = Das|editor-first2 = Ezendu|editor-last2 = Ariwa|editor-first3 = Syarifah Bahiyah|editor-last3 = Rahayu}}&lt;/ref&gt;

== Volterra series methods ==

The early work was dominated by methods based on the [[Volterra series]], which in the discrete time case can be expressed as

: &lt;math&gt;\begin{align}
y(k)&amp; = h_0+\sum\limits_{m_1=1}^M h_1(m_1)u(k-m_1) + \sum\limits_{m_1=1}^M \sum\limits_{m_2=1}^M h_2(m_1,m_2)u(k-m_1)u(k-m_2) \\
&amp; {}\quad{}+\sum\limits_{m_1=1}^M \sum\limits_{m_2=1}^M \sum\limits_{m_3=1}^M h_3(m_1,m_2,m_3)u(k-m_1)u(k-m_2)u(k-m_3) + \cdots
\end{align}&lt;/math&gt;

where ''u''(''k''), ''y''(''k''); ''k'' = 1, 2, 3, … are the measured input and output respectively and &lt;math&gt;h_\ell(m_1,\ldots ,m_\ell)&lt;/math&gt; is the ''l''th-order Volterra kernel, or ''l''th-order nonlinear impulse response. The Volterra series is an extension of the linear [[convolution]] integral. Most of the earlier identification algorithms assumed that just the first two, linear and quadratic, Volterra kernels are present and used special inputs such as Gaussian white noise and correlation methods to identify the two Volterra kernels. In most of these methods the input has to be Gaussian and white which is a severe restriction for many real processes. These results were later extended to include the first three Volterra kernels, to allow different inputs, and other related developments including the [[Wiener series]]. A very important body of work was developed by Wiener, Lee, Bose and colleagues at MIT from the 1940s to the 1960s including the famous Lee and Schetzen method.&lt;ref&gt;Schetzen M. "The Volterra and Wiener Theories of Nonlinear Systems". Wiley, 1980&lt;/ref&gt;&lt;ref&gt;Rugh W.J. "Nonlinear System Theory – The Volterra Wiener Approach". Johns Hopkins University Press,1981&lt;/ref&gt; While these methods are still actively studied today there are several basic restrictions. These include the necessity of knowing the number of Volterra series terms a priori, the use of special inputs, and the large number of estimates that have to be identified. For example for a system where the first order Volterra kernel   is described by say 30 samples, 30x30 points will be required for the second order kernel, 30x30x30 for the third order   and so on and hence the amount of data required to provide good estimates becomes excessively large.&lt;ref name="SAB2"&gt;Billings S.A. "[http://eprints.whiterose.ac.uk/75753/1/report%20112.pdf Identification of Nonlinear Systems: A Survey]". IEE Proceedings Part D 127(6), 272–285,1980&lt;/ref&gt; These numbers can be reduced by exploiting certain symmetries but the requirements are still excessive irrespective of what algorithm is used for the identification.

== Block-structured systems ==

Because of the problems of identifying Volterra models other model forms were investigated as a basis for system identification for nonlinear systems. Various forms of block structured nonlinear models have been introduced or re-introduced.&lt;ref name="SAB2" /&gt;&lt;ref&gt;Haber R., Keviczky L "Nonlinear System Identification-Input Output Modeling Approach". Vols I &amp; II, Kluwer,1980&lt;/ref&gt; The Hammerstein model consists of a static single valued nonlinear element followed by a linear dynamic element. The Wiener model is the reverse of this combination so that the linear element occurs before the static nonlinear characteristic. The Wiener-Hammerstein model consists of a static nonlinear element sandwiched between two dynamic linear elements, and several other model forms are available. All these models can be represented by a Volterra series but in this case the Volterra kernels take on a special form in each case. Identification consists of correlation based and parameter estimation methods. The correlation methods exploit certain properties of these systems, which means that if specific inputs are used, often white Gaussian noise, the individual elements can be identified one at a time. This results in manageable data requirements and the individual blocks can sometimes be related to components in the system under study.

More recent results are based on parameter estimation and neural network based solutions. Many results have been introduced and these systems continue to be studied in depth. One problem is that these methods are only applicable to a very special form of model in each case and usually this model form has to be known prior to identification.

== Neural networks ==

[[Artificial neural networks]] try loosely to imitate the network of neurons in the brain where computation takes place through a large number of simple processing elements. A typical neural network consists of a number of simple processing units interconnected to form a complex network. Layers of such units are arranged so that data is entered at the input layer and passes through either one or several intermediate layers before reaching the output layer. In [[supervised learning]] the network is trained by operating on the difference between the actual output and the desired output of the network, the prediction error, to change the connection strengths between the nodes. By iterating the weights are modified until the output error reaches an acceptable level. This process is called machine learning because the network adjusts the weights so that the output pattern is reproduced.
Neural networks have been extensively studied and there are many excellent textbooks devoted to this topic in general,&lt;ref name="Nelles" /&gt;&lt;ref&gt;Haykin S. "Neural Networks: A Comprehensive Foundation". McMillan,1999&lt;/ref&gt; and more focussed textbooks which emphasise control and systems applications,.&lt;ref name="Nelles" /&gt;&lt;ref&gt;Warwick K, Irwin G.W., Hunt K.J. "Neural Networks for Control and Systems". Peter Peregrinus, 1992&lt;/ref&gt;
There are two main problem types that can be studied using neural networks: static problems, and dynamic problems. Static problems include [[pattern recognition]], [[class (set theory)|class]]ification, and [[approximation]]. Dynamic problems involve lagged variables and are more appropriate for system identification and related applications. Depending on the architecture of the network the training problem can be either nonlinear-in-the-parameters which involves optimisation or linear-in-the-parameters which can be solved using classical approaches. The training algorithms can be categorised into supervised, unsupervised, or reinforcement learning. Neural networks have excellent approximation properties but these are usually based on standard function approximation results using for example the [[Weierstrass]] Theorem that applies equally well to polynomials, rational functions, and other well-known models. 
Neural networks have been applied extensively to system identification problems which involve nonlinear and dynamic relationships. However, classical neural networks are purely gross static approximating machines. There is no dynamics within the network. Hence when fitting dynamic models all the dynamics arise by allocating lagged inputs and outputs to the input layer of the network. The training procedure then produces the best static approximation that relates the lagged variables assigned to the input nodes to the output. There are more complex network architectures, including recurrent networks,&lt;ref name="Nelles" /&gt; that produce dynamics by introducing increasing orders of lagged variables to the input nodes. But in these cases it is very easy to over specify the lags and this can lead to over fitting and poor generalisation properties. 
Neural networks have several advantages; they are conceptually simple, easy to train and to use, have excellent approximation properties, the concept of local and parallel processing is important and this provides integrity and fault tolerant behaviour. The biggest criticism of the classical neural network models is that the models produced are completely opaque and usually cannot be written down or analysed. It is therefore very difficult to know what is causing what, to analyse the model, or to compute dynamic characteristics from the model. Some of these points will not be relevant to all applications but they are for dynamic modelling.

== NARMAX methods ==

The '''n'''onlinear '''a'''uto'''r'''egressive '''m'''oving '''a'''verage model with e'''x'''ogenous inputs (NARMAX model) can represent a wide class of nonlinear systems,&lt;ref name="SAB1" /&gt; and is defined as

: &lt;math&gt;\begin{align}
y(k) &amp; =F[y(k-1),y(k-2),\ldots ,y(k-n_y),u(k-d),u(k-d-1),\ldots ,u(k-d-n_u), \\ 
&amp; {}\quad e(k-1),e(k-2),\ldots ,e(k-n_e)]+e(k)
\end{align}&lt;/math&gt;
 
where ''y''(''k''), ''u''(''k'') and ''e''(''k'') are the system output, input, and noise sequences respectively; &lt;math&gt;n_y&lt;/math&gt;, &lt;math&gt;n_u&lt;/math&gt;, and &lt;math&gt;n_e&lt;/math&gt; are the maximum lags for the system output, input and noise; F[•] is some nonlinear function, d is a time delay typically set to ''d''&amp;nbsp;=&amp;nbsp;1.The model is essentially an expansion of past inputs, outputs and noise terms. Because the [[noise]] is modelled explicitly, unbiased estimates of the system model can be obtained in the presence of unobserved highly correlated and nonlinear noise.
The Volterra, the block structured models and many neural network architectures can all be considered as subsets of the NARMAX model. Since NARMAX was introduced, by proving what class of nonlinear systems can be represented by this model, many results and algorithms have been derived based around this description. Most of the early work was based on polynomial expansions of the NARMAX model. These are still the most popular methods today but other more complex forms based on [[wavelets]] and other expansions have been introduced to represent severely nonlinear and highly complex nonlinear systems. A significant proportion of nonlinear systems can be represented by a NARMAX model including systems with exotic behaviours such as [[chaos theory|chaos]], [[bifurcation theory|bifurcations]], and [[subharmonics]].
While NARMAX started as the name of a model it has now developed into a philosophy of nonlinear system identification,.&lt;ref name="SAB1" /&gt; The NARMAX approach consists of several steps:

* Structure detection: which terms are in the model
* Parameter estimation: determine the model coefficients
* Model validation: is the model unbiased and correct
* Prediction: what is the output at some future time
* Analysis: what are the dynamical properties of the system

Structure detection forms the most fundamental part of NARMAX. For example a NARMAX model which consists of one lagged input and one lagged output term, three lagged noise terms, expanded as a cubic polynomial would consist of fifty six possible candidate terms. This number of candidate terms arises because the expansion by definition includes all possible combinations within the cubic expansion. Naively proceeding to estimate a model which includes all these terms and then pruning will cause numerical and computational problems and should always be avoided. However, only a few terms are often important in the model. Structure detection, which aims to select terms one at a time, is therefore critically important. These objectives can easily be achieved by using the Orthogonal Least Squares &lt;ref name="SAB1" /&gt;  algorithm and its derivatives to select the NARMAX model terms one at a time. These ideas can also be adapted for [[pattern recognition]] and [[feature selection]] and provide an alternative to [[principal component analysis]] but with the advantage that the features are revealed as basis functions that are easily related back to the original problem. &lt;br /&gt;
NARMAX methods are designed to do far more than to just find the best approximating model. System identification can be divided into two aims. The first involves approximation where the key aim is to develop a model that approximates the data set such that good predictions can be made. There are many applications where this approach is appropriate, for example in time series prediction of the weather, stock prices, speech, target tracking, pattern classification etc. In such applications the form of the model is not that important. The objective is to find an approximation scheme which produces the minimum prediction errors. A second objective of system identification, which includes the first objective as a subset, involves much more than just finding a model to achieve the best mean squared errors. This second aim is why the NARMAX philosophy was developed and is linked to the idea of finding the simplest model structure. The aim here is to develop models that reproduce the dynamic characteristics of the underlying system, to find the simplest possible model, and if possible to relate this to components and behaviours of the system under study. The core aim of this second approach to identification is therefore to identify and reveal the rule that represents the system. These objectives are relevant to model simulation and control systems design, but increasingly to applications in medicine, neuro science, and the life sciences. Here the aim is to identify models, often nonlinear, that can be used to understand the basic mechanisms of how these systems operate and behave so that we can manipulate and utilise these. NARMAX methods have also been developed in the frequency and spatio-temporal domains.

== Stochastic nonlinear models ==
In a general situation, it might be the case that some exogenous uncertain disturbance passes through the nonlinear dynamics and influence the outputs. A model class that is general enough to capture this situation is the class of stochastic nonlinear [[State-space representation|state-space models]]. A state-space model is usually obtained using first principle laws,&lt;ref name=":0"&gt;{{Cite book|url=https://www.worldcat.org/oclc/38884169|title=System identification : theory for the user|last=Lennart.|first=Ljung,|date=1999|publisher=Prentice Hall PTR|isbn=0136566952|edition=2nd|location=Upper Saddle River, NJ|oclc=38884169}}&lt;/ref&gt; such as mechanical, electrical, or thermodynamic physical laws, and the parameters to be identified usually have some physical meaning or significance.

A discrete-time state-space model may be defined by the difference equations:

:&lt;math&gt;
\begin{aligned}
x_{t+1} &amp;= f(x_t, u_t, w_t; \theta),\\
y_t &amp;= g(x_t, u_t, v_t; \theta), \quad t =1,2, \dots
\end{aligned}
&lt;/math&gt;

in which &lt;math&gt;t&lt;/math&gt; is a positive integer referring to time.  The functions &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are general nonlinear functions. The first equation is known as the state equation and the second is known as the output equation. All the signals are modeled uing [[stochastic process]]es. The process &lt;math&gt;x_t&lt;/math&gt; is known as the state process,  &lt;math&gt;w_t&lt;/math&gt; and &lt;math&gt;v_t&lt;/math&gt; are usually assumed [[Independence (probability theory)|independent]] and mutually independent such that &lt;math&gt;w_t \sim p(w; \theta),\; v_t \sim p(v; \theta)&lt;/math&gt;. The parameter &lt;math&gt;\theta&lt;/math&gt; is usually a finite-dimensional (real) parameter to be estimated (using experimental data). Observe that the state process does not have to be a physical signal, and it is normally unobserved (not measured). The data set is given as a set of input-output pairs &lt;math&gt;(y_t, u_t)&lt;/math&gt; for &lt;math&gt;t = 1, \dots, N&lt;/math&gt; for some finite positive integer value &lt;math&gt;N&lt;/math&gt;.

Unfortunately, due to the nonlinear transformation of unobserved random variables, the [[likelihood function]] of the outputs is analytically intractable; it is given in terms of a multidimensional marginalization integral. Consequently, commonly used parameter estimation methods such as the [[Maximum likelihood estimation|Maximum Likelihood Method]] or the Prediction Error Method based on the optimal one-step ahead predictor&lt;ref name=":0" /&gt; are analytically intractable.  Recently, algorithms based on [[Particle filter|sequential Monte Carlo]] methods have been used  to approximate the conditional mean of the outputs or, in conjunction with the [[Expectation–maximization algorithm|Expectation-Maximization]] algorithm, to approximate the maximum likelihood estimator.&lt;ref&gt;{{Cite journal|last=Schön|first=Thomas B.|last2=Lindsten|first2=Fredrik|last3=Dahlin|first3=Johan|last4=Wågberg|first4=Johan|last5=Naesseth|first5=Christian A.|last6=Svensson|first6=Andreas|last7=Dai|first7=Liang|title=Sequential Monte Carlo Methods for System Identification**This work was supported by the projects Learning of complex dynamical systems (Contract number: 637-2014-466) and Probabilistic modeling of dynamical systems (Contract number: 621-2013-5524), both funded by the Swedish Research Council.|url=http://linkinghub.elsevier.com/retrieve/pii/S2405896315028487|journal=IFAC-PapersOnLine|volume=48|issue=28|pages=775–786|doi=10.1016/j.ifacol.2015.12.224}}&lt;/ref&gt;  These methods, albeit asymptotically optimal, are computationally demanding and their use is limited to specific cases where the fundamental limitations of the employed particle filters can be avoided. An alternative solution is to apply the prediction error method using a sub-optimal predictor.&lt;ref&gt;M. Abdalmoaty, [http://urn.kb.se/resolve?urn=urn%3Anbn%3Ase%3Akth%3Adiva-218100 ‘Learning Stochastic Nonlinear Dynamical Systems Using Non-stationary Linear Predictors’], Licentiate dissertation, Stockholm, Sweden, 2017. [http://urn.kb.se/resolve?urn=urn%3Anbn%3Ase%3Akth%3Adiva-218100 Urn:nbn:se:kth:diva-218100]&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Abdalmoaty|first=Mohamed Rasheed|last2=Hjalmarsson|first2=Håkan|title=Simulated Pseudo Maximum Likelihood Identification of Nonlinear Models|url=http://linkinghub.elsevier.com/retrieve/pii/S2405896317324655|journal=IFAC-PapersOnLine|volume=50|issue=1|pages=14058–14063|doi=10.1016/j.ifacol.2017.08.1841}}&lt;/ref&gt; The resulting estimator can be shown to be strongly consistent and asymptotically normal and can be evaluated using relatively simple algorithms.

== See also ==
{{Portal|Mathematics}}
* [[Grey box model]]
* [[Statistical Model]]

==References==
{{reflist}}

==Further reading==
* Lennart Ljung: System Identification — Theory For the User, 2nd ed, PTR Prentice Hall, Upper Saddle River, N. J., 1999.
* R. Pintelon, J. Schoukens, System Identification: A Frequency Domain Approach, IEEE Press, New York, 2001. {{ISBN|978-0-7803-6000-6}}
* T. Söderström, P. Stoica, System Identification, Prentice Hall, Upper Saddle River, N.J., 1989. {{ISBN|0-13-881236-5}}
* R. K. Pearson:  [https://books.google.com/books?id=Os7nCwAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Discrete-Time Dynamic Models]. Oxford University Press, 1999.
* P. Marmarelis, V. Marmarelis, V. [https://books.google.com/books?id=1O7lBwAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Analysis of Physiological Systems], Plenum, 1978.
* K. Worden, G. R. Tomlinson, Nonlinearity in Structural Dynamics, Institute of Physics Publishing, 2001.

{{DEFAULTSORT:Nonlinear system identification}}
[[Category:Nonlinear systems| ]]
[[Category:Dynamical systems]]</text>
      <sha1>nck9bha3x8ki344l04g0y56i5u0tsmz</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical analysis</title>
    <ns>0</ns>
    <id>21506</id>
    <revision>
      <id>865558984</id>
      <parentid>865555834</parentid>
      <timestamp>2018-10-24T17:29:28Z</timestamp>
      <contributor>
        <username>Anita5192</username>
        <id>13220696</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/43.242.123.166|43.242.123.166]] ([[User talk:43.242.123.166|talk]]) to last version by OlaniyiMoses2008</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31146">{{more footnotes|date=November 2013}}
{{Use dmy dates|date=July 2012}}
[[Image:Ybc7289-bw.jpg|thumb|250px|right|Babylonian clay tablet [[YBC 7289]] (c. 1800–1600 BC) with annotations. The approximation of the [[square root of 2]] is four [[sexagesimal]] figures, which is about six [[decimal]] figures. 1 + 24/60 + 51/60&lt;sup&gt;2&lt;/sup&gt; + 10/60&lt;sup&gt;3&lt;/sup&gt; = 1.41421296...&lt;ref&gt;[http://it.stlawu.edu/%7Edmelvill/mesomath/tablets/YBC7289.html Photograph, illustration, and description of the ''root(2)'' tablet from the Yale Babylonian Collection]&lt;/ref&gt;]]
'''Numerical analysis''' is the study of [[algorithm]]s that use numerical [[approximation]] (as opposed to general [[symbolic computation|symbolic manipulations]]) for the problems of [[mathematical analysis]] (as distinguished from [[discrete mathematics]]). Numerical analysis naturally finds application in all fields of engineering and the physical sciences, but in the 21st&amp;nbsp;century also the life sciences, social sciences, medicine, business and even the arts have adopted elements of scientific computations. As an aspect of mathematics and [[computer science]] that generates, analyzes, and implements algorithms, the growth in power and the revolution in computing has raised the use of realistic mathematical models in science and engineering, and complex numerical analysis is required to provide solutions to these more involved models of the world. [[Ordinary differential equation]]s appear in [[celestial mechanics]] (planets, stars and galaxies); [[numerical linear algebra]] is important for data analysis; [[stochastic differential equation]]s and [[Markov chain]]s are essential in simulating living cells for medicine and biology.

Before the advent of modern computers, [[numerical method]]s often depended on hand [[interpolation]] in large printed tables. Since the mid 20th century, computers calculate the required functions instead. These same interpolation formulas nevertheless continue to be used as part of the software algorithms for solving [[differential equation]]s.

One of the earliest mathematical writings is a Babylonian tablet from the [[Yale Babylonian Collection]] ([[YBC 7289]]), which gives a [[sexagesimal]] numerical approximation of the [[square root of 2]], the length of the [[diagonal]] in a [[unit square]]. Being able to compute the sides of a triangle (and hence, being able to compute [[square root]]s) is extremely important, for instance, in [[astronomy]], [[carpentry]] and [[construction]].&lt;ref&gt;The New Zealand Qualification authority specifically mentions this skill in document 13004 version 2, dated 17 October 2003 titled [http://www.nzqa.govt.nz/nqfdocs/units/pdf/13004.pdf CARPENTRY THEORY: Demonstrate knowledge of setting out a building]&lt;/ref&gt;

Numerical analysis continues this long tradition of practical mathematical calculations. Much like the [[Babylonian mathematics|Babylonian]] approximation of the square root of 2, modern numerical analysis does not seek exact answers, because exact answers are often impossible to obtain in practice. Instead, much of numerical analysis is concerned with obtaining approximate solutions while maintaining reasonable bounds on errors.

==General introduction==
The overall goal of the field of numerical analysis is the design and analysis of techniques to give approximate but accurate solutions to hard problems, the variety of which is suggested by the following:

* Advanced numerical methods are essential in making [[numerical weather prediction]] feasible.
* Computing the trajectory of a spacecraft requires the accurate numerical solution of a system of [[ordinary differential equation]]s.
* Car companies can improve the crash safety of their vehicles by using computer simulations of car crashes. Such simulations essentially consist of solving [[partial differential equation]]s numerically.
* [[Hedge fund]]s (private investment funds) use tools from all fields of numerical analysis to attempt to calculate the value of stocks and derivatives more precisely than other market participants.
* Airlines use sophisticated optimization algorithms to decide ticket prices, airplane and crew assignments and fuel needs. Historically, such algorithms were developed within the overlapping field of [[operations research]].
* Insurance companies use numerical programs for [[Actuary|actuarial]] analysis.

The rest of this section outlines several important themes of numerical analysis.

===History===

The field of numerical analysis predates the invention of modern computers by many centuries. [[Linear interpolation]] was already in use more than 2000 years ago. Many great mathematicians of the past were preoccupied by numerical analysis, as is obvious from the names of important algorithms like [[Newton's method]], [[Lagrange polynomial|Lagrange interpolation polynomial]], [[Gaussian elimination]], or [[Euler's method]].

To facilitate computations by hand, large books were produced with formulas and tables of data such as interpolation points and function coefficients.  Using these tables, often calculated out to 16 decimal places or more for some functions, one could look up values to plug into the formulas given and achieve very good numerical estimates of some functions.  The canonical work in the field is the [[NIST]] publication edited by [[Abramowitz and Stegun]], a 1000-plus page book of a very large number of commonly used formulas and functions and their values at many points.  The function values are no longer very useful when a computer is available, but the large listing of formulas can still be very handy.

The [[mechanical calculator]] was also developed as a tool for hand computation. These calculators evolved into electronic computers in the 1940s, and it was then found that these computers were also useful for administrative purposes. But the invention of the computer also influenced the field of numerical analysis, since now longer and more complicated calculations could be done.

===Direct and iterative methods===

{| class="wikitable" style="float: right; width: 250px; margin-left: 1em;"
 |-
 |
'''Direct vs iterative methods'''

Consider the problem of solving

:3''x''&lt;sup&gt;3&lt;/sup&gt; + 4 = 28

for the unknown quantity ''x''.

{| style="margin:auto; text-align:right"
 |+ Direct method
 |-
 |  || 3''x''&lt;sup&gt;3&lt;/sup&gt; + 4 = 28.
 |-
 | ''Subtract 4'' || 3''x''&lt;sup&gt;3&lt;/sup&gt; = 24.
 |-
 | ''Divide by 3'' || ''x''&lt;sup&gt;3&lt;/sup&gt; = &amp;nbsp;8.
 |-
 | ''Take cube roots'' || ''x'' = &amp;nbsp;2.
 |}

For the iterative method, apply the [[bisection method]] to ''f''(''x'') = 3''x''&lt;sup&gt;3&lt;/sup&gt; &amp;minus; 24. The initial values are ''a'' = 0, ''b'' = 3, ''f''(''a'') = &amp;minus;24, ''f''(''b'') = 57.

{| style="margin:auto;" class="wikitable"
 |+ Iterative method
 |-
 ! ''a'' !! ''b'' !! mid !! ''f''(mid)
 |-
 | 0 || 3 || 1.5 || &amp;minus;13.875
 |-
 | 1.5 || 3 || 2.25 || 10.17...
 |-
 | 1.5 || 2.25 || 1.875 || &amp;minus;4.22...
 |-
 | 1.875 || 2.25 || 2.0625 || 2.32...
 |}

We conclude from this table that the solution is between 1.875 and 2.0625. The algorithm might return any number in that range with an error less than 0.2.

==== Discretization and numerical integration ====

[[Image:Schumacher (Ferrari) in practice at USGP 2005.jpg|right|125px]]
In a two-hour race, we have measured the speed of the car at three instants and recorded them in the following table.

{| style="margin:auto;" class="wikitable"
! Time
| 0:20 || 1:00 || 1:40
|-
! km/h
| 140  || 150  || 180
|}

A '''discretization''' would be to say that the speed of the car was constant from 0:00 to 0:40, then from 0:40 to 1:20 and finally from 1:20 to 2:00. For instance, the total distance traveled in the first 40 minutes is approximately {{math|size=100%|1=({{val|2|/|3|u=h}}&amp;nbsp;&amp;times;&amp;nbsp;{{val|140|u=km/h}})&amp;nbsp;=&amp;nbsp;{{val|93.3|u=km}}}}. This would allow us to estimate the total distance traveled as {{val|93.3|u=km}} + {{val|100|u=km}} + {{val|120|u=km}} = {{val|313.3|u=km}}, which is an example of '''numerical integration''' (see below) using a [[Riemann sum]], because displacement is the [[integral]] of velocity.

'''Ill-conditioned problem''': Take the function {{math|size=100%|1=''f''(''x'') = 1/(''x''&amp;nbsp;&amp;minus;&amp;nbsp;1)}}. Note that ''f''(1.1) = 10 and ''f''(1.001) = 1000: a change in ''x'' of less than 0.1 turns into a change in ''f''(''x'') of nearly 1000. Evaluating ''f''(''x'') near ''x'' = 1 is an ill-conditioned problem.

'''Well-conditioned problem''': By contrast, evaluating the same function {{math|size=100%|1=''f''(''x'') = 1/(''x''&amp;nbsp;&amp;minus;&amp;nbsp;1)}} near ''x'' = 10 is a well-conditioned problem. For instance, ''f''(10) = 1/9 ≈ 0.111 and ''f''(11) = 0.1: a modest change in ''x'' leads to a modest change in ''f''(''x'').
|}

Direct methods compute the solution to a problem in a finite number of steps. These methods would give the precise answer if they were performed in [[Computer numbering formats|infinite precision arithmetic]]. Examples include [[Gaussian elimination]], the [[QR decomposition|QR factorization]] method for solving [[system of linear equations|systems of linear equations]], and the [[simplex method]] of [[linear programming]]. In practice, [[Floating point|finite precision]] is used and the result is an approximation of the true solution (assuming [[Numerically stable|stability]]).

In contrast to direct methods, [[iterative method]]s are not expected to terminate in a finite number of steps. Starting from an initial guess, iterative methods form successive approximations that [[Limit of a sequence|converge]] to the exact solution only in the limit. A convergence test, often involving [[Residual (numerical analysis)|the residual]], is specified in order to decide when a sufficiently accurate solution has (hopefully) been found. Even using infinite precision arithmetic these methods would not reach the solution within a finite number of steps (in general). Examples include [[Newton's method]], the [[bisection method]], and [[Jacobi iteration]]. In computational matrix algebra, iterative methods are generally needed for large problems.

Iterative methods are more common than direct methods in numerical analysis. Some methods are direct in principle but are usually used as though they were not, e.g. [[GMRES]] and the [[conjugate gradient method]]. For these methods the number of steps needed to obtain the exact solution is so large that an approximation is accepted in the same manner as for an iterative method.

===Discretization===

Furthermore, continuous problems must sometimes be replaced by a discrete problem whose solution is known to approximate that of the continuous problem; this process is called ''[[discretization]]''. For example, the solution of a [[differential equation]] is a [[function (mathematics)|function]]. This function must be represented by a finite amount of data, for instance by its value at a finite number of points at its domain, even though this domain is a [[Continuum (set theory)|continuum]].

==Generation and propagation of errors==
The study of errors forms an important part of numerical analysis. There are several ways in which error can be introduced in the solution of the problem.

===Round-off===

[[Round-off error]]s arise because it is impossible to represent all [[real number]]s exactly on a machine with finite memory (which is what all practical [[digital computer]]s are).

===Truncation and discretization error===

[[Truncation error]]s are committed when an iterative method is terminated or a mathematical procedure is approximated, and the approximate solution differs from the exact solution. Similarly, discretization induces a [[discretization error]] because the solution of the discrete problem does not coincide with the solution of the continuous problem. For instance, in the iteration in the sidebar to compute the solution of &lt;math&gt;3x^3+4=28&lt;/math&gt;, after 10 or so iterations, we conclude that the root is roughly 1.99 (for example). We therefore have a truncation error of 0.01.

Once an error is generated, it will generally propagate through the calculation. For instance, we have already noted that the operation + on a calculator (or a computer) is inexact. It follows that a calculation of the type {{tmath|a+b+c+d+e}} is even more inexact.

What does it mean when we say that the truncation error is created when we approximate a mathematical procedure?  We know that to integrate a function exactly requires one to find the sum of infinite trapezoids.  But numerically one can find the sum of only finite trapezoids, and hence the approximation of the mathematical procedure.  Similarly, to differentiate a function, the differential element approaches zero but numerically we can only choose a finite value of the differential element.

===Numerical stability and well-posed problems===

[[Numerical stability]] is an important notion in numerical analysis. An algorithm is called ''numerically stable'' if an error, whatever its cause, does not grow to be much larger during the calculation. This happens if the problem is ''[[condition number|well-conditioned]]'', meaning that the solution changes by only a small amount if the problem data are changed by a small amount. To the contrary, if a problem is ''ill-conditioned'', then any small error in the data will grow to be a large error.

Both the original problem and the algorithm used to solve that problem can be ''well-conditioned'' and/or ''ill-conditioned'', and any combination is possible.

So an algorithm that solves a well-conditioned problem may be either numerically stable or numerically unstable. An art of numerical analysis is to find a stable algorithm for solving a well-posed mathematical problem. For instance, computing the square root of 2 (which is roughly 1.41421) is a well-posed problem. Many algorithms solve this problem by starting with an initial approximation ''x''&lt;sub&gt;0&lt;/sub&gt; to &lt;math&gt;\sqrt{2}&lt;/math&gt;, for instance ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.4, and then computing improved guesses ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, etc. One such method is the famous [[Babylonian method]], which is given by ''x''&lt;sub&gt;''k''+1&lt;/sub&gt; = ''x&lt;sub&gt;k&lt;/sub&gt;''/2 + 1/''x&lt;sub&gt;k&lt;/sub&gt;''. Another method, which we will call Method X, is given by ''x''&lt;sub&gt;''k''+1&lt;/sub&gt; = (''x''&lt;sub&gt;''k''&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; − 2)&lt;sup&gt;2&lt;/sup&gt; + ''x''&lt;sub&gt;''k''&lt;/sub&gt;.&lt;ref&gt;This is a [[fixed point iteration]] for the equation &lt;math&gt;x=(x^2-2)^2+x=f(x)&lt;/math&gt;, whose solutions include &lt;math&gt;\sqrt{2}&lt;/math&gt;. The iterates always move to the right since &lt;math&gt;f(x)\geq x&lt;/math&gt;. Hence &lt;math&gt;x_1=1.4&lt;\sqrt{2}&lt;/math&gt; converges and &lt;math&gt;x_1=1.42&gt;\sqrt{2}&lt;/math&gt; diverges.&lt;/ref&gt; We have calculated a few iterations of each scheme in table form below, with initial guesses ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.4 and ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.42.

{| class="wikitable"
 |-
! Babylonian
! Babylonian
! Method X
! Method X
 |-
 | ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.4
 | ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.42
 | ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.4
 | ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.42
 |-
 | ''x''&lt;sub&gt;1&lt;/sub&gt; = 1.4142857...
 | ''x''&lt;sub&gt;1&lt;/sub&gt; = 1.41422535...
 | ''x''&lt;sub&gt;1&lt;/sub&gt; = 1.4016
 | ''x''&lt;sub&gt;1&lt;/sub&gt; = 1.42026896
 |-
 | ''x''&lt;sub&gt;2&lt;/sub&gt; = 1.414213564...
 | ''x''&lt;sub&gt;2&lt;/sub&gt; = 1.41421356242...
 | ''x''&lt;sub&gt;2&lt;/sub&gt; = 1.4028614...
 | ''x''&lt;sub&gt;2&lt;/sub&gt; = 1.42056...
 |-
 |
 |
 | ...
 | ...
 |-
 |
 |
 | ''x''&lt;sub&gt;1000000&lt;/sub&gt; = 1.41421...
 | ''x''&lt;sub&gt;27&lt;/sub&gt; = 7280.2284...
 |}

Observe that the Babylonian method converges quickly regardless of the initial guess, whereas Method X converges extremely slowly with initial guess ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.4 and diverges for initial guess ''x''&lt;sub&gt;0&lt;/sub&gt; = 1.42. Hence, the Babylonian method is numerically stable, while Method X is numerically unstable.
:'''Numerical stability''' is affected by the number of the significant digits the machine keeps on, if we use a machine that keeps only the four most significant decimal digits, a good example on loss of significance is given by these two equivalent functions
:&lt;math&gt; 
f(x)=x\left(\sqrt{x+1}-\sqrt{x}\right)
\text{ and } g(x)=\frac{x}{\sqrt{x+1}+\sqrt{x}}.
&lt;/math&gt;
:If we compare the results of
:: &lt;math&gt; f(500)=500 \left(\sqrt{501}-\sqrt{500} \right)=500 \left(22.38-22.36 \right)=500(0.02)=10&lt;/math&gt;
:and
:&lt;math&gt;
\begin{alignat}{3}g(500)&amp;=\frac{500}{\sqrt{501}+\sqrt{500}}\\
      &amp;=\frac{500}{22.38+22.36}\\
      &amp;=\frac{500}{44.74}=11.17
\end{alignat}
&lt;/math&gt;
: by looking to the two results above, we realize that '''[[loss of significance]]''' (caused here by '''catastrophic cancelation''') has a huge effect on the results, even though both functions are equivalent, as shown below
:: &lt;math&gt; \begin{alignat}{4}
f(x)&amp;=x \left(\sqrt{x+1}-\sqrt{x} \right)\\
    &amp;=x \left(\sqrt{x+1}-\sqrt{x} \right)\frac{\sqrt{x+1}+\sqrt{x}}{\sqrt{x+1}+\sqrt{x}}\\
    &amp;=x\frac{(\sqrt{x+1})^2-(\sqrt{x})^2}{\sqrt{x+1}+\sqrt{x}}\\
    &amp;=x\frac{x+1-x}{\sqrt{x+1}+\sqrt{x}}  \\
    &amp;=x\frac{1}{\sqrt{x+1}+\sqrt{x}}  \\
    &amp;=\frac {x}{\sqrt{x+1}+\sqrt{x}}  \\
    &amp;=g(x)
\end{alignat}&lt;/math&gt;

:The desired value, computed using infinite precision, is 11.174755...
*The example is a modification of one taken from Mathew; Numerical methods using Matlab, 3rd ed.

==Areas of study==

The field of numerical analysis includes many sub-disciplines. Some of the major ones are:

===Computing values of functions===

{| class="wikitable" style="float: right; width: 250px; clear: right; margin-left: 1em;"
 |
'''Interpolation''': We have observed the temperature to vary from 20 degrees Celsius at 1:00 to 14 degrees at 3:00. A linear interpolation of this data would conclude that it was 17 degrees at 2:00 and 18.5 degrees at 1:30pm.

'''Extrapolation''': If the [[gross domestic product]] of a country has been growing an average of 5% per year and was 100 billion dollars last year, we might extrapolate that it will be 105 billion dollars this year.

[[Image:Linear-regression.svg|right|100px|A line through 20 points]]

'''Regression''': In linear regression, given ''n'' points, we compute a line that passes as close as possible to those ''n'' points.

[[Image:LemonadeJuly2006.JPG|right|100px|How much for a glass of lemonade?]]

'''Optimization''': Say you sell lemonade at a [[lemonade stand]], and notice that at $1, you can sell 197 glasses of lemonade per day, and that for each increase of $0.01, you will sell one glass of lemonade less per day. If you could charge $1.485, you would maximize your profit, but due to the constraint of having to charge a whole cent amount, charging $1.48 or $1.49 per glass will both yield the maximum income of $220.52 per day.

[[Image:Wind-particle.png|right|Wind direction in blue, true trajectory in black, Euler method in red.]]

'''Differential equation''': If you set up 100 fans to blow air from one end of the room to the other and then you drop a feather into the wind, what happens? The feather will follow the air currents, which may be very complex. One approximation is to measure the speed at which the air is blowing near the feather every second, and advance the simulated feather as if it were moving in a straight line at that same speed for one second, before measuring the wind speed again. This is called the [[Euler method]] for solving an ordinary differential equation.
|}

One of the simplest problems is the evaluation of a function at a given point. The most straightforward approach, of just plugging in the number in the formula is sometimes not very efficient. For polynomials, a better approach is using the [[Horner scheme]], since it reduces the necessary number of multiplications and additions. Generally, it is important to estimate and control [[round-off error]]s arising from the use of [[floating point]] arithmetic.

===Interpolation, extrapolation, and regression===

[[Interpolation]] solves the following problem: given the value of some unknown function at a number of points, what value does that function have at some other point between the given points?

[[Extrapolation]] is very similar to interpolation, except that now we want to find the value of the unknown function at a point which is outside the given points.

[[Regression analysis|Regression]] is also similar, but it takes into account that the data is imprecise. Given some points, and a measurement of the value of some function at these points (with an error), we want to determine the unknown function. The [[numerical methods for linear least squares|least squares]]-method is one popular way to achieve this.

===Solving equations and systems of equations===

Another fundamental problem is computing the solution of some given equation. Two cases are commonly distinguished, depending on whether the equation is linear or not. For instance, the equation &lt;math&gt;2x+5=3&lt;/math&gt; is linear while &lt;math&gt;2x^2+5=3&lt;/math&gt; is not.

Much effort has been put in the development of methods for solving [[systems of linear equations]]. Standard direct methods, i.e., methods that use some [[matrix decomposition]] are [[Gaussian elimination]], [[LU decomposition]], [[Cholesky decomposition]] for [[symmetric matrix|symmetric]] (or [[hermitian matrix|hermitian]]) and [[positive-definite matrix]], and [[QR decomposition]] for non-square matrices. [[Iterative method]]s such as the [[Jacobi method]], [[Gauss–Seidel method]], [[successive over-relaxation]] and [[conjugate gradient method]] are usually preferred for large systems. General iterative methods can be developed using a [[matrix splitting]].

[[Root-finding algorithm]]s are used to solve nonlinear equations (they are so named since a root of a function is an argument for which the function yields zero). If the function is [[derivative|differentiable]] and the derivative is known, then [[Newton's method]] is a popular choice. [[Linearization]] is another technique for solving nonlinear equations.

===Solving eigenvalue or singular value problems===
Several important problems can be phrased in terms of [[eigenvalue decomposition]]s or [[singular value decomposition]]s. For instance, the [[image compression|spectral image compression]] algorithm&lt;ref&gt;[http://online.redwoods.cc.ca.us/instruct/darnold/maw/single.htm The Singular Value Decomposition and Its Applications in Image Compression] {{webarchive|url=https://web.archive.org/web/20061004041704/http://online.redwoods.cc.ca.us/instruct/darnold/maw/single.htm |date=4 October 2006 }}&lt;/ref&gt; is based on the singular value decomposition. The corresponding tool in statistics is called [[principal component analysis]].

===Optimization===
{{Main|Mathematical optimization}}

Optimization problems ask for the point at which a given function is maximized (or minimized). Often, the point also has to satisfy some [[Constraint (mathematics)|constraint]]s.

The field of optimization is further split in several subfields, depending on the form of the objective function and the constraint. For instance, [[linear programming]] deals with the case that both the objective function and the constraints are linear. A famous method in linear programming is the [[simplex method]].

The method of [[Lagrange multipliers]] can be used to reduce optimization problems with constraints to unconstrained optimization problems.

===Evaluating integrals===
{{Main|Numerical integration}}

Numerical integration, in some instances also known as numerical [[quadrature (mathematics)|quadrature]], asks for the value of a definite [[integral]]. Popular methods use one of the [[Newton–Cotes formulas]] (like the midpoint rule or [[Simpson's rule]]) or [[Gaussian quadrature]]. These methods rely on a "divide and conquer" strategy, whereby an integral on a relatively large set is broken down into integrals on smaller sets. In higher dimensions, where these methods become prohibitively expensive in terms of computational effort, one may use [[Monte Carlo method|Monte Carlo]] or [[quasi-Monte Carlo method]]s (see [[Monte Carlo integration]]), or, in modestly large dimensions, the method of [[sparse grid]]s.

===Differential equations===
{{main|Numerical ordinary differential equations|Numerical partial differential equations}}

Numerical analysis is also concerned with computing (in an approximate way) the solution of [[differential equation]]s, both ordinary differential equations and [[partial differential equation]]s.

Partial differential equations are solved by first discretizing the equation, bringing it into a finite-dimensional subspace. This can be done by a [[finite element method]], a [[finite difference]] method, or (particularly in engineering) a [[finite volume method]]. The theoretical justification of these methods often involves theorems from [[functional analysis]]. This reduces the problem to the solution of an algebraic equation.

==Software==
{{main|List of numerical analysis software|Comparison of numerical analysis software}}

Since the late twentieth century, most algorithms are implemented in a variety of programming languages. The [[Netlib]] repository contains various collections of software routines for numerical problems, mostly in [[Fortran]] and [[C (programming language)|C]]. Commercial products implementing many different numerical algorithms include the [[IMSL Numerical Libraries|IMSL]] and [[Numerical Algorithms Group|NAG]] libraries; a [[free software|free-software]] alternative is the [[GNU Scientific Library]].

There are several popular numerical computing applications such as [[MATLAB]], [[TK Solver]], [[S-PLUS]], and [[IDL (programming language)|IDL]] as well as free and open source alternatives such as [[FreeMat]], [[Scilab]], [[GNU Octave]] (similar to Matlab), and [[IT++]] (a C++ library). There are also programming languages such as [[R (programming language)|R]] (similar to S-PLUS) and [[Python (programming language)|Python]] with libraries such as [[NumPy]], [[SciPy]] and [[SymPy]]. Performance varies widely: while vector and matrix operations are usually fast, scalar loops may vary in speed by more than an order of magnitude.&lt;ref&gt;[http://www.sciviews.org/benchmark/ Speed comparison of various number crunching packages] {{webarchive|url=https://web.archive.org/web/20061005024002/http://www.sciviews.org/benchmark/ |date=5 October 2006 }}&lt;/ref&gt;&lt;ref&gt;[http://www.scientificweb.com/ncrunch/ncrunch5.pdf Comparison of mathematical programs for data analysis] Stefan Steinhaus, ScientificWeb.com&lt;/ref&gt;

Many [[computer algebra system]]s such as [[Mathematica]] also benefit from the availability of [[arbitrary precision arithmetic]] which can provide more accurate results.

Also, any [[spreadsheet]] [[software]] can be used to solve simple problems relating to numerical analysis.

==See also==
*[[Analysis of algorithms]]
*[[Computational science]]
*[[Interval arithmetic]]
*[[List of numerical analysis topics]]
*[[Numerical differentiation]]
*''[[Numerical Recipes]]''
*[[Symbolic-numeric computation]]

==Notes==
&lt;references/&gt;

==References==
&lt;!--
This template can be used for additional references.
*{{cite book |last= |first= |authorlink= |coauthors= |title= |year= |publisher= |location= |id= }}
--&gt;
*{{cite book|author=[[Gene H. Golub|Golub, Gene H.]] and [[Charles F. Van Loan]]|title=Matrix Computations|edition=third|publisher=Johns Hopkins University Press|ISBN=0-8018-5413-X|year=1986}}
*{{cite book |first=Nicholas J.|last=Higham | authorlink=Nicholas Higham|title=Accuracy and Stability of Numerical Algorithms|publisher=Society for Industrial and Applied Mathematics|ISBN=0-89871-355-2|year=1996}}
*{{cite book |last=Hildebrand |first=F. B. | authorlink=Francis B. Hildebrand | title=Introduction to Numerical Analysis | edition=2nd |year=1974 |publisher=McGraw-Hill |location= |isbn= 0-07-028761-9}}
*{{cite book |last=Leader |first=Jeffery J. | authorlink=Jeffery J. Leader|title=Numerical Analysis and Scientific Computation |year=2004 |publisher=Addison Wesley |location= |isbn= 0-201-73499-0 }}
*{{cite book|last= Wilkinson |first =J.H.| authorlink=James H. Wilkinson| title=The Algebraic Eigenvalue Problem (Clarendon Press)|year=1965}}
*{{cite journal | author=Kahan, W. | authorlink= William Kahan| title= "A survey of error-analysis," in Info. Processing 71 (Proc. IFIP Congress 71 in Ljubljana), vol. 2, pp. 1214–39, North-Holland Publishing, Amsterdam|year=1972}} (examples of the importance of accurate arithmetic).
* [[Lloyd N. Trefethen|Trefethen, Lloyd N.]] (2006). [http://people.maths.ox.ac.uk/trefethen/NAessay.pdf "Numerical analysis"], 20 pages. In: Timothy Gowers and June Barrow-Green (editors), ''Princeton Companion of Mathematics'', Princeton University Press.

== External links ==
{{Sister project links| wikt=no | b=Numerical Methods | n=no | q=Numerical analysis | s=no | v=no | voy=no | species=no | d=no}}

'''Journals'''
*[http://www-gdz.sub.uni-goettingen.de/cgi-bin/digbib.cgi?PPN362160546 Numerische Mathematik], volumes 1-66, Springer, 1959-1994 (searchable; pages are images). {{en icon}} {{de icon}}
*[http://www.springerlink.com/content/0029-599X Numerische Mathematik at SpringerLink], volumes 1-112, Springer, 1959–2009
*[http://siamdl.aip.org/dbt/dbt.jsp?KEY=SJNAAM SIAM Journal on Numerical Analysis], volumes 1-47, SIAM, 1964–2009

'''Online texts'''
*{{springer|title=Numerical analysis|id=p/n120130}}
*[http://www.nr.com/oldverswitcher.html ''Numerical Recipes''], William H. Press (free, downloadable previous editions)
*[https://web.archive.org/web/20120225082123/http://kr.cs.ait.ac.th/~radok/math/mat7/stepsa.htm ''First Steps in Numerical Analysis''] ([[Internet Archive|archived]]), R.J.Hosking, S.Joe, D.C.Joyce, and J.C.Turner
*[http://www.phy.ornl.gov/csep/CSEP/TEXTOC.html ''CSEP'' (Computational Science Education Project)], [[U.S. Department of Energy]]

'''Online course material'''
*[http://www.damtp.cam.ac.uk/user/fdl/people/sd103/lectures/nummeth98/index.htm#L_1_Title_Page Numerical Methods], Stuart Dalziel [[University of Cambridge]]
*[http://www.math.upenn.edu/~wilf/DeturckWilf.pdf Lectures on Numerical Analysis], Dennis Deturck and Herbert S. Wilf [[University of Pennsylvania]]
*[http://johndfenton.com/Lectures/Numerical-Methods/Numerical-Methods.pdf Numerical methods], John D. Fenton [[University of Karlsruhe]]
*[http://www-teaching.physics.ox.ac.uk/computing/NumericalMethods/NMfP.pdf Numerical Methods for Physicists], Anthony O’Hare [[Oxford University]]
*[https://web.archive.org/web/20120225082123/http://kr.cs.ait.ac.th/~radok/math/mat7/stepsa.htm Lectures in Numerical Analysis] ([[Internet Archive|archived]]), R. Radok [[Mahidol University]]
*[http://ocw.mit.edu/courses/mechanical-engineering/2-993j-introduction-to-numerical-analysis-for-engineering-13-002j-spring-2005/ Introduction to Numerical Analysis for Engineering], Henrik Schmidt [[Massachusetts Institute of Technology]]
*[http://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/ ''Numerical Analysis for Engineering''], D. W. Harder [[University of Waterloo]]

{{Areas of mathematics}}
{{Branches of physics}}
{{Computer science}}

{{Authority control}}

{{DEFAULTSORT:Numerical Analysis}}
[[Category:Numerical analysis| ]]
[[Category:Mathematical physics]]
[[Category:Computational science]]</text>
      <sha1>m4jaev8tjpkkkm5k9pfe5vabeb5tq2a</sha1>
    </revision>
  </page>
  <page>
    <title>Octal</title>
    <ns>0</ns>
    <id>22330</id>
    <revision>
      <id>862649931</id>
      <parentid>862642250</parentid>
      <timestamp>2018-10-05T19:24:49Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>Undid revision 862642250 by [[Special:Contributions/WATSUPPP1235|WATSUPPP1235]] ([[User talk:WATSUPPP1235|talk]]) undid vandalism</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34829">{{Table Numeral Systems}}
The '''octal''' [[numeral system]], or '''oct''' for short, is the [[radix|base]]-8 number system, and uses the digits 0 to 7. Octal numerals can be made from [[Binary numeral system|binary]] numerals by grouping consecutive binary digits into groups of three (starting from the right). For example, the binary representation for decimal 74 is 1001010.  Two zeroes can be added at the left:  {{nowrap|(00)1 001 010}}, corresponding the octal digits {{nowrap|1 1 2}}, yielding the octal representation 112.

In the decimal system each decimal place is a power of ten. For example:
: &lt;math&gt;\mathbf{74}_{10} = \mathbf{7} \times 10^1 + \mathbf{4} \times  10^0&lt;/math&gt;
In the octal system each place is a power of eight. For example:
: &lt;math&gt;\mathbf{112}_8 = \mathbf{1} \times  8^2 + \mathbf{1} \times  8^1 + \mathbf{2} \times  8^0 &lt;/math&gt;
By performing the calculation above in the familiar decimal system we see why 112 in octal is equal to 64+8+2 = 74 in decimal.

{| class="wikitable" style="float:right; text-align:center"
|+ The octal [[multiplication table]]
|-
| × || '''1''' || '''2''' || '''3''' || '''4''' || '''5''' || '''6''' || '''7''' || '''10''' 
|-
| '''1''' || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 10
|-
| '''2''' || 2 || 4 || 6 || 10 || 12 || 14 || 16 || 20
|-
| '''3''' || 3 || 6 || 11 || 14 || 17 || 22 || 25 || 30
|-
| '''4''' || 4 || 10 || 14 || 20 || 24 || 30 || 34 || 40
|-
| '''5''' || 5 || 12 || 17 || 24 || 31 || 36 || 43 || 50
|-
| '''6''' || 6 || 14 || 22 || 30 || 36 || 44 || 52 || 60
|-
| '''7''' || 7 || 16 || 25 || 34 || 43 || 52 || 61 || 70
|-
| '''10''' || 10 || 20 || 30 || 40 || 50 || 60 || 70 || 100
|}

==Usage==

===By Native Americans===
The [[Yuki language]] in [[California]] and the [[Pame language|Pamean languages]]&lt;ref&gt;{{Cite journal
 | last=Avelino
 | first=Heriberto
 | title=The typology of Pame number systems and the limits of Mesoamerica as a linguistic area
 | journal=Linguistic Typology
 | year=2006
 | volume=10
 | issue=1
 | pages=41–60
 | url=http://linguistics.berkeley.edu/~avelino/Avelino_2006.pdf
 | doi=10.1515/LINGTY.2006.002
 | postscript=&lt;!--None--&gt;
}}&lt;/ref&gt; in [[Mexico]] have octal systems because the speakers count using the spaces between their fingers rather than the fingers themselves.&lt;ref&gt;{{cite journal|jstor=2686959|title=Ethnomathematics: A Multicultural View of Mathematical Ideas|author=Marcia Ascher|publisher=The College Mathematics Journal}}&lt;/ref&gt;

===By Europeans===

*It has been suggested that the reconstructed [[Proto-Indo-European]] word for "nine" might be related to the PIE word for "new".  Based on this, some have speculated that proto-Indo-Europeans used an octal number system, though the evidence supporting this is slim.&lt;ref&gt;{{cite book 
 |last= Winter
 |first= Werner
 |chapter= Some thoughts about Indo-European numerals
 |title= Indo-European numerals
 |series= Trends in Linguistics
 |volume= 57
 |editor1-last= Gvozdanović
 |editor1-first= Jadranka
 |year= 1991
 |publisher= Mouton de Gruyter
 |location= Berlin
 |isbn= 3-11-011322-8
 |pages= 13–14
 |url= https://books.google.com/books?id=S-hmNOLuDGsC&amp;lpg=PA170&amp;pg=PA13#v=onepage&amp;q&amp;f=false
 |accessdate= 2013-06-09
}}&lt;/ref&gt;
*In 1668 [[John Wilkins]] in ''[[An Essay towards a Real Character, and a Philosophical Language]]'' proposed use of base 8 instead of 10 "because the way of Dichotomy or Bipartition being the most natural and easie kind of Division, that Number is capable of this down to an Unite".&lt;ref&gt;{{cite book 
 |last= Wilkins
 |first= John
 |title= An Essay Towards a Real Character and a Philosophical Language
 |year= 1668
 |publisher= 
 |location= London
 |pages= 190
 |url= https://books.google.com/books?id=BCCtZjBtiEYC&amp;pg=PA190&amp;cad=3#v=onepage&amp;q&amp;f=false
 |accessdate= 2015-02-08
}}&lt;/ref&gt;
*In 1716 King [[Charles XII of Sweden]] asked [[Emanuel Swedenborg]] to elaborate a number system based on 64 instead of 10. Swedenborg however argued that for people with less intelligence than the king such a big base would be too difficult and instead proposed 8 as the base. In 1718 Swedenborg wrote (but did not publish) a manuscript: "En ny rekenkonst som om vexlas wid Thalet 8 i stelle then wanliga wid Thalet 10" ("A new arithmetic (or art of counting) which changes at the Number 8 instead of the usual at the Number 10"). The numbers 1-7 are there denoted by the consonants l, s, n, m, t, f, u (v) and zero by the vowel o. Thus 8 = "lo", 16 = "so", 24 = "no", 64 = "loo", 512 = "looo" etc. Numbers with consecutive consonants are pronounced with vowel sounds between in accordance with a special rule.&lt;ref&gt;[[Donald Knuth]], ''[[The Art of Computer Programming]]''&lt;/ref&gt;
*Writing under the pseudonym "Hirossa Ap-Iccim" in ''[[The Gentleman's Magazine]]'', (London) July 1745, [[Hugh Jones (reverend)|Hugh Jones]] proposed an octal system for British coins, weights and measures. "Whereas reason and convenience indicate to us an uniform standard for all quantities; which I shall call the ''Georgian standard''; and that is only to divide every integer in each ''species'' into eight equal parts, and every part again into 8 real or imaginary particles, as far as is necessary. For tho' all nations count universally by ''tens'' (originally occasioned by the number of digits on both hands) yet 8 is a far more complete and commodious number; since it is divisible into halves, quarters, and half quarters (or units) without a fraction, of which subdivision ''ten'' is uncapable...." In a later treatise on [[Hugh Jones (reverend)#Publications|Octave computation]] (1753) Jones concluded: "Arithmetic by ''Octaves'' seems most agreeable to the Nature of Things, and therefore may be called Natural Arithmetic in Opposition to that now in Use, by Decades; which may be esteemed Artificial Arithmetic."&lt;ref&gt;See H.R. Phalen, "Hugh Jones and Octave Computation," ''The American Mathematical Monthly'' 56 (August–September 1949): 461-65.&lt;/ref&gt; 
*In 1801, [[James Anderson of Hermiston|James Anderson]] criticized the French for basing the Metric system on decimal arithmetic.  He suggested base 8, for which he coined the term ''octal''.  His work was intended as recreational mathematics, but he suggested a purely octal system of weights and measures and observed that the existing system of [[English units]] was already, to a remarkable extent, an octal system.&lt;ref&gt;James Anderson, On Octal Arithmetic [title appears only in page headers], [https://books.google.com/books?id=olhHAAAAYAAJ&amp;pg=PA437 Recreations in Agriculture, Natural-History, Arts, and Miscellaneous Literature], Vol. IV, No. 6 (Feb. 1801), T. Bensley, London; pages 437-448.&lt;/ref&gt;
*In the mid 19th century, Alfred B. Taylor concluded that "Our octonary [base 8] radix is, therefore, beyond all comparison the "''best possible one''" for an arithmetical system." The proposal included a graphical notation for the digits and new names for the numbers, suggesting that we should count "''un'', ''du'', ''the'', ''fo'', ''pa'', ''se'', ''ki'', ''unty'', ''unty-un'', ''unty-du''" and so on, with successive multiples of eight named "''unty'', ''duty'', ''thety'', ''foty'', ''paty'', ''sety'', ''kity'' and ''under''." So, for example, the number 65 (101 in octal) would be spoken in octonary as ''under-un''.&lt;ref&gt;A.B. Taylor, [https://books.google.com/books?id=X7wLAAAAYAAJ&amp;pg=PP5 Report on Weights and Measures], Pharmaceutical Association, 8th Annual Session, Boston, Sept. 15, 1859.  See pages and 48 and 53.&lt;/ref&gt;&lt;ref&gt;Alfred B. Taylor, Octonary numeration and its application to a system of weights and measures, [https://books.google.com/books?id=KsAUAAAAYAAJ&amp;pg=PA296 Proc. Amer. Phil. Soc. Vol XXIV], Philadelphia, 1887; pages 296-366.  See pages 327 and 330.&lt;/ref&gt;  Taylor also republished some of Swedenborg's work on octonary as an appendix to the above-cited publications.

==={{anchor|\nnn}}In computers===
Octal became widely used in computing when systems such as the [[PDP-8]], [[ICT 1900 series|ICL 1900]] and [[IBM mainframe]]s employed [[12-bit]], [[24-bit]] or [[36-bit]] words.  Octal was an ideal abbreviation of binary for these machines because their word size is divisible by three (each octal digit represents three binary digits). So four, eight or twelve digits could concisely display an entire [[Word (computer architecture)|machine word]]. It also cut costs by allowing [[Nixie tube]]s, [[seven-segment display]]s, and [[calculator]]s to be used for the operator consoles, where binary displays were too complex to use, decimal displays needed complex hardware to convert radices, and [[hexadecimal]] displays needed to display more numerals.

All modern computing platforms, however, use [[word (computer architecture)|16-, 32-, or 64-bit words]], further divided into [[octet (computing)|eight-bit bytes]].  On such systems three octal digits per byte would be required, with the most significant octal digit representing two binary digits (plus one bit of the next significant byte, if any). Octal representation of a 16-bit word requires 6&amp;nbsp;digits, but the most significant octal digit represents (quite inelegantly) only one bit (0 or 1). This representation offers no way to easily read the most significant byte, because it's smeared over four octal digits. Therefore, hexadecimal is more commonly used in programming languages today, since two hexadecimal digits exactly specify one byte.  Some platforms with a power-of-two word size still have instruction subwords that are more easily understood if displayed in octal; this includes the [[PDP-11]] and [[Motorola 68000 family]].  The modern-day ubiquitous [[x86 architecture]] belongs to this category as well, but octal is rarely used on this platform, although certain properties of the binary encoding of opcodes become more readily apparent when displayed in octal, e.g. the ModRM byte, which is divided into fields of 2, 3, and 3 bits, so octal can be useful in describing these encodings.

Octal is sometimes used in computing instead of hexadecimal, perhaps most often in modern times in conjunction with [[file permissions]] under [[Unix]] systems (see [[chmod]]). It has the advantage of not requiring any extra symbols as digits (the hexadecimal system is base-16 and therefore needs six additional symbols beyond 0–9). It is also used for digital displays.

In programming languages, octal [[Literal (computer programming)|literals]] are typically identified with a variety of [[prefix]]es, including the digit &lt;tt&gt;0&lt;/tt&gt;, the letters &lt;tt&gt;o&lt;/tt&gt; or &lt;tt&gt;q&lt;/tt&gt;, the digit–letter combination &lt;tt&gt;0o&lt;/tt&gt;, or the symbol &lt;tt&gt;&amp;&lt;/tt&gt;&lt;ref&gt;{{cite book |chapter=Constants, Variables, Expressions and Operators |author=Microsoft Corporation |year=1987 |access-date=2015-12-12 |chapter-url=http://www.antonis.de/qbebooks/gwbasman/chapter%206.html |title=GW-BASIC User's Manual |url=http://www.antonis.de/qbebooks/gwbasman/ }}&lt;/ref&gt; or &lt;tt&gt;$&lt;/tt&gt;.  In ''Motorola convention'', octal numbers are prefixed with &lt;tt&gt;@&lt;/tt&gt;, whereas a small letter &lt;tt&gt;o&lt;/tt&gt; is added as a [[suffix|postfix]] following the ''Intel convention''.&lt;ref name="Kueveler-Schwoch_1996"&gt;{{cite book|title=Arbeitsbuch Informatik - eine praxisorientierte Einführung in die Datenverarbeitung mit Projektaufgabe|language=German|first1=Gerd|last1=Küveler|first2=Dietrich|last2=Schwoch|date=2013|orig-year=1996|publisher=Vieweg-Verlag, reprint: Springer-Verlag|isbn=978-3-528-04952-2|id=9783322929075|doi=10.1007/978-3-322-92907-5|url=https://books.google.com/books?id=b8-dBgAAQBAJ|accessdate=2015-08-05}}&lt;/ref&gt;&lt;ref name="Kueveler-Schwoch_2007"&gt;{{cite book|title=Informatik für Ingenieure und Naturwissenschaftler: PC- und Mikrocomputertechnik, Rechnernetze|language=German|first1=Gerd|last1=Küveler|first2=Dietrich|last2=Schwoch|date=2007-10-04|publisher=Vieweg, reprint: Springer-Verlag|edition=5|volume=2|isbn=3834891916|id=9783834891914|url=https://books.google.com/books?id=xQbvPYxceY0C|accessdate=2015-08-05}}&lt;/ref&gt; In [[DR-DOS]] and [[Multiuser DOS]] various [[environment variable]]s like [[%$CLS%|$CLS]], [[%$ON%|$ON]], [[%$OFF%|$OFF]], [[%$HEADER%|$HEADER]] or [[%$FOOTER%|$FOOTER]] support an &lt;tt&gt;\nnn&lt;/tt&gt; octal number notation,&lt;ref name="Paul_1997_NWDOSTIP"/&gt;&lt;ref name="Paul_2002_CLS"/&gt;&lt;ref name="CCI_1997_HELP"/&gt; and DR-DOS [[DEBUG]] utilizes &lt;tt&gt;\&lt;/tt&gt; to prefix octal numbers as well.

For example, the literal 73 (base 8) might be represented as &lt;tt&gt;073&lt;/tt&gt;, &lt;tt&gt;o73&lt;/tt&gt;, &lt;tt&gt;q73&lt;/tt&gt;, &lt;tt&gt;0o73&lt;/tt&gt;, &lt;tt&gt;\73&lt;/tt&gt;, &lt;tt&gt;@73&lt;/tt&gt;, &lt;tt&gt;&amp;73&lt;/tt&gt;, &lt;tt&gt;$73&lt;/tt&gt; or &lt;tt&gt;73o&lt;/tt&gt; in various languages.

Newer languages have been abandoning the prefix &lt;tt&gt;0&lt;/tt&gt;, as decimal numbers are often represented with leading zeroes.  The prefix &lt;tt&gt;q&lt;/tt&gt; was introduced to avoid the prefix &lt;tt&gt;o&lt;/tt&gt; being mistaken for a zero, while the prefix &lt;tt&gt;0o&lt;/tt&gt; was introduced to avoid starting a numerical literal with an alphabetic character (like &lt;tt&gt;o&lt;/tt&gt; or &lt;tt&gt;q&lt;/tt&gt;), since these might cause the literal to be confused with a variable name.  The prefix &lt;tt&gt;0o&lt;/tt&gt; also follows the model set by the prefix &lt;tt&gt;0x&lt;/tt&gt; used for hexadecimal literals in the [[C (programming language)|C language]]; it is supported by [[Haskell (programming language)|Haskell]],&lt;ref&gt;Haskell: http://www.haskell.org/onlinereport/lexemes.html#sect2.5&lt;/ref&gt; [[OCaml]],&lt;ref&gt;OCaml: http://caml.inria.fr/pub/docs/manual-ocaml/lex.html&lt;/ref&gt; [[Perl 6]],&lt;ref&gt;Perl 6: http://perlcabal.org/syn/S02.html#Radix_markers&lt;/ref&gt; [[Python (programming language)|Python]] as of version 3.0,&lt;ref&gt;Python 3: https://docs.python.org/3.1/reference/lexical_analysis.html#integer-literals&lt;/ref&gt; [[Ruby (programming language)|Ruby]],&lt;ref&gt;RubySpec: https://github.com/kostya/rubyspec/blob/master/core/string/to_i_spec.rb&lt;/ref&gt; [[Tcl]] as of version 9,&lt;ref&gt;Tcl: http://wiki.tcl.tk/498&lt;/ref&gt; and it is intended to be supported by [[ECMAScript]] 6&lt;ref&gt;ECMAScript 6th Edition draft: https://people.mozilla.org/~jorendorff/es6-draft.html#sec-literals-numeric-literals&lt;/ref&gt; (the prefix &lt;tt&gt;0&lt;/tt&gt; has been discouraged in ECMAScript 3 and dropped in ECMAScript 5&lt;ref&gt;Mozilla Developer Network: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseInt&lt;/ref&gt;).

Octal numbers that are used in some programming languages (C, [[Perl]], [[PostScript]]…) for textual/graphical representations of byte strings when some byte values (unrepresented in a code page, non-graphical, having special meaning in current context or otherwise undesired) have to be to [[escape character|escaped]] as &lt;tt&gt;\nnn&lt;/tt&gt;. Octal representation may be particularly handy with non-ASCII bytes of [[UTF-8]], which encodes groups of 6 bits, and where any start byte has octal value &lt;tt&gt;\3nn&lt;/tt&gt; and any continuation byte has octal value &lt;tt&gt;\2nn&lt;/tt&gt;.

=== In aviation ===
[[Transponder (aeronautics)|Transponders]] in aircraft transmit a [[Transponder (aeronautics)#Transponder codes|code]], expressed as a four-octal-digit number, when interrogated by ground radar. This code is used to distinguish different aircraft on the radar screen.

==Conversion between bases==

===Decimal to octal conversion===

====Method of successive Euclidean division by 8====
To convert integer decimals to octal, [[Euclidean division|divide]] the original number by the largest possible power of 8 and divide the remainders by successively smaller powers of 8 until the power is 1.  The octal representation is formed by the quotients, written in the order generated by the algorithm.
For example, to convert 125&lt;sub&gt;10&lt;/sub&gt; to octal:
:125 = 8&lt;sup&gt;2&lt;/sup&gt; × '''1''' + 61
:61 = 8&lt;sup&gt;1&lt;/sup&gt; × '''7''' + 5
:5 = 8&lt;sup&gt;0&lt;/sup&gt; × '''5''' + 0
Therefore, 125&lt;sub&gt;10&lt;/sub&gt; = 175&lt;sub&gt;8&lt;/sub&gt;.

Another example:
:900 = 8&lt;sup&gt;3&lt;/sup&gt; × '''1''' + 388
:388 = 8&lt;sup&gt;2&lt;/sup&gt; × '''6''' + 4
:4 = 8&lt;sup&gt;1&lt;/sup&gt; × '''0''' + 4
:4 = 8&lt;sup&gt;0&lt;/sup&gt; × '''4''' + 0
Therefore, 900&lt;sub&gt;10&lt;/sub&gt; = 1604&lt;sub&gt;8&lt;/sub&gt;.

====Method of successive multiplication by 8====
To convert a decimal fraction to octal, multiply by 8; the integer part of the result is the first digit of the octal fraction. Repeat the process with the fractional part of the result, until it is null or within acceptable error bounds.

Example: Convert 0.1640625 to octal:
:0.1640625 × 8 = 1.3125 = '''1''' + 0.3125
:0.3125 × 8 = 2.5 = '''2''' + 0.5
:0.5 × 8 = 4.0 = '''4''' + 0
Therefore, 0.1640625&lt;sub&gt;10&lt;/sub&gt; = 0.124&lt;sub&gt;8&lt;/sub&gt;.

These two methods can be combined to handle decimal numbers with both integer and fractional parts, using the first on the integer part and the second on the fractional part.

====Method of successive duplication====
To convert integer decimals to octal, prefix the number with "0.". Perform the following steps for as long as digits remain on the right side of the radix:
Double the value to the left side of the radix, using ''octal'' rules, move the radix point one digit rightward, and then place the doubled value underneath the current value so that the radix points align. If the moved radix point crosses over a digit that is 8 or 9, convert it to 0 or 1 and add the carry to the next leftward digit of the current value. ''Add'' ''octally'' those digits to the left of the radix and simply drop down those digits to the right, without modification.

Example:
&lt;pre&gt;
 0.4 9 1 8 decimal value
  +0
 ---------
   4.9 1 8
  +1 0
  --------
   6 1.1 8
  +1 4 2
  --------
   7 5 3.8
  +1 7 2 6
  --------
 1 1 4 6 6. octal value
&lt;/pre&gt;

===Octal to decimal conversion===
To convert a number {{mvar|k}} to decimal, use the formula that defines its base-8 representation:
:&lt;math&gt;k = \sum_{i=0}^n \left( a_i\times 8^i \right)&lt;/math&gt;

In this formula, {{math|''a''&lt;sub&gt;''i''&lt;/sub&gt;}} is an individual octal digit being converted, where {{mvar|i}} is the position of the digit (counting from 0 for the right-most digit).

Example: Convert 764&lt;sub&gt;8&lt;/sub&gt; to decimal:
 
:764&lt;sub&gt;8&lt;/sub&gt; = 7 × 8&lt;sup&gt;2&lt;/sup&gt; + 6 × 8&lt;sup&gt;1&lt;/sup&gt; + 4 × 8&lt;sup&gt;0&lt;/sup&gt;  = 448 + 48 + 4 = 500&lt;sub&gt;10&lt;/sub&gt;

For double-digit octal numbers this method amounts to multiplying the lead digit by 8 and adding the second digit to get the total.

Example: 65&lt;sub&gt;8&lt;/sub&gt; = 6 × 8 + 5 = 53&lt;sub&gt;10&lt;/sub&gt;

====Method of successive duplication====
To convert octals to decimals, prefix the number with "0.". Perform the following steps for as long as digits remain on the right side of the radix: Double the value to the left side of the radix, using ''decimal'' rules, move the radix point one digit rightward, and then place the doubled value underneath the current value so that the radix points align. ''Subtract'' ''decimally'' those digits to the left of the radix and simply drop down those digits to the right, without modification.

Example:
&lt;pre&gt;
 0.1 1 4 6 6  octal value
  -0
 -----------
   1.1 4 6 6
  -  2
  ----------
     9.4 6 6
  -  1 8
  ----------
     7 6.6 6
  -  1 5 2
  ----------
     6 1 4.6
  -  1 2 2 8
  ----------
     4 9 1 8. decimal value
&lt;/pre&gt;

===Octal to binary conversion===
To convert octal to binary, replace each octal digit by its binary representation.
	
Example: Convert 51&lt;sub&gt;8&lt;/sub&gt; to binary:
:5&lt;sub&gt;8&lt;/sub&gt; = 101&lt;sub&gt;2&lt;/sub&gt;
:1&lt;sub&gt;8&lt;/sub&gt; = 001&lt;sub&gt;2&lt;/sub&gt;
Therefore, 51&lt;sub&gt;8&lt;/sub&gt; = 101 001&lt;sub&gt;2&lt;/sub&gt;.

===Binary to octal conversion===
The process is the reverse of the previous algorithm. The binary digits are grouped by threes, starting from the least significant bit and proceeding to the left and to the right.  Add leading zeroes (or trailing zeroes to the right of decimal point) to fill out the last group of three if necessary.  Then replace each trio with the equivalent octal digit.

For instance, convert binary 1010111100 to octal:

:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
| 001 || 010 || 111 || 100
|- align="center"
| 1 || 2 || 7 || 4
|}

Therefore, 1010111100&lt;sub&gt;2&lt;/sub&gt; = 1274&lt;sub&gt;8&lt;/sub&gt;.

Convert binary 11100.01001 to octal:

:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
|  011 || 100|| &amp;nbsp;.&amp;nbsp; || 010 || 010
|- align="center"
| 3 || 4 || &amp;nbsp;.&amp;nbsp; || 2 || 2 
|}

Therefore, 11100.01001&lt;sub&gt;2&lt;/sub&gt; = 34.22&lt;sub&gt;8&lt;/sub&gt;.

===Octal to hexadecimal conversion===
The conversion is made in two steps using binary as an intermediate base. Octal is converted to binary and then binary to hexadecimal, grouping digits by fours, which correspond each to a hexadecimal digit.

For instance, convert octal 1057 to hexadecimal:

:To binary:
:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
| 1 || 0 || 5 || 7
|- align="center"
| 001 || 000 || 101 || 111
|}

:then to hexadecimal:
:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
| 0010 || 0010 || 1111
|- align="center"
| 2 || 2 || F
|}

Therefore, 1057&lt;sub&gt;8&lt;/sub&gt; = 22F&lt;sub&gt;16&lt;/sub&gt;.

===Hexadecimal to octal conversion===
Hexadecimal to octal conversion proceeds by first converting the hexadecimal digits to 4-bit binary values, then regrouping the binary bits into 3-bit octal digits.

For example, to convert 3FA5&lt;sub&gt;16&lt;/sub&gt;:

:To binary:
:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
| 3 || F || A || 5
|- align="center"
| 0011 || 1111 || 1010 || 0101
|}

:then to octal:
:{| border="1" cellspacing="0" cellpadding="4"
|- align="center"
| 0 || 011 || 111 || 110 || 100 || 101
|- align="center"
| 0 || 3 || 7 || 6 || 4 || 5
|}

Therefore, 3FA5&lt;sub&gt;16&lt;/sub&gt; = 37645&lt;sub&gt;8&lt;/sub&gt;.

==Real numbers==
===Fractions===
Due to having only factors of two, many octal fractions have repeating digits, although these tend to be fairly simple:

{|class="wikitable"

| colspan="3" align="center" | Decimal base&lt;br&gt;&lt;SMALL&gt;Prime factors of the base: &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Prime factors of one below the base: &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Prime factors of one above the base: &lt;span style="color:Orange"&gt;'''11'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Other Prime factors: &lt;span style="color:Red"&gt;'''7 13 17 19 23 29 31'''&lt;/span&gt;&lt;/SMALL&gt;
| colspan="3" align="center" | '''Octal base'''&lt;br&gt;&lt;SMALL&gt;Prime factors of the base: &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Prime factors of one below the base: &lt;span style="color:Blue"&gt;'''7'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Prime factors of one above the base: &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;&lt;/SMALL&gt;&lt;br&gt;&lt;SMALL&gt;Other Prime factors: &lt;span style="color:Red"&gt;'''5 13 15 21 23 27 35 37'''&lt;/span&gt;&lt;/SMALL&gt;
|-
| align="center" | Fraction
| align="center" | &lt;SMALL&gt;Prime factors&lt;br&gt;of the denominator&lt;/SMALL&gt;
| align="center" | Positional representation
| align="center" | Positional representation
| align="center" | &lt;SMALL&gt;Prime factors&lt;br&gt;of the denominator&lt;/SMALL&gt;
| align="center" | Fraction
|-
| align="center" | 1/2
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| '''0.5'''
| '''0.4'''
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| align="center" | 1/2
|-
| align="center" | 1/3
| align="center" | &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''3333... = '''0.'''{{overline|3}}
| bgcolor=#c0c0c0 | '''0.'''2525... = '''0.'''{{overline|25}}
| align="center" | &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/3
|-
| align="center" | 1/4
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| '''0.25'''
| '''0.2'''
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| align="center" | 1/4
|-
| align="center" | 1/5
| align="center" | &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| '''0.2'''
| bgcolor=#c0c0c0 | '''0.'''{{overline|1463}}
| align="center" | &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/5
|-
| align="center" | 1/6
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.1'''{{overline|6}}
| bgcolor=#c0c0c0 | '''0.1'''{{overline|25}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/6
|-
| align="center" | 1/7
| align="center" | &lt;span style="color:Red"&gt;'''7'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|142857}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|1}}
| align="center" | &lt;span style="color:Blue"&gt;'''7'''&lt;/span&gt;
| align="center" | 1/7
|-
| align="center" | 1/8
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| '''0.125'''
| '''0.1'''
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| align="center" | 1/10
|-
| align="center" | 1/9
| align="center" | &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|1}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|07}}
| align="center" | &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/11
|-
| align="center" | 1/10
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| '''0.1'''
| bgcolor=#c0c0c0 | '''0.0'''{{overline|6314}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/12
|-
| align="center" | 1/11
| align="center" | &lt;span style="color:Orange"&gt;'''11'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|09}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|0564272135}}
| align="center" | &lt;span style="color:Red"&gt;'''13'''&lt;/span&gt;
| align="center" | 1/13
|-
| align="center" | 1/12
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.08'''{{overline|3}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|52}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/14
|-
| align="center" | 1/13
| align="center" | &lt;span style="color:Red"&gt;'''13'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|076923}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|0473}}
| align="center" | &lt;span style="color:Red"&gt;'''15'''&lt;/span&gt;
| align="center" | 1/15
|-
| align="center" | 1/14
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''7'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|714285}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|4}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''7'''&lt;/span&gt;
| align="center" | 1/16
|-
| align="center" | 1/15
| align="center" | &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|6}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|0421}}
| align="center" | &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/17
|-
| align="center" | 1/16
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| '''0.0625'''
| '''0.04'''
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| align="center" | 1/20
|-
| align="center" | 1/17
| align="center" | &lt;span style="color:Red"&gt;'''17'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|0588235294117647}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|03607417}}
| align="center" | &lt;span style="color:Red"&gt;'''21'''&lt;/span&gt;
| align="center" | 1/21
|-
| align="center" | 1/18
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|5}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|34}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/22
|-
| align="center" | 1/19
| align="center" | &lt;span style="color:Red"&gt;'''19'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|052631578947368421}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|032745}}
| align="center" | &lt;span style="color:Red"&gt;'''23'''&lt;/span&gt;
| align="center" | 1/23
|-
| align="center" | 1/20
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| '''0.05'''
| bgcolor=#c0c0c0 | '''0.0'''{{overline|3146}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/24
|-
| align="center" | 1/21
| align="center" | &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''7'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|047619}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|03}}
| align="center" | &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''7'''&lt;/span&gt;
| align="center" | 1/25
|-
| align="center" | 1/22
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''11'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|45}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|2721350564}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''13'''&lt;/span&gt;
| align="center" | 1/26
|-
| align="center" | 1/23
| align="center" | &lt;span style="color:Red"&gt;'''23'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|0434782608695652173913}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|02620544131}}
| align="center" | &lt;span style="color:Red"&gt;'''27'''&lt;/span&gt;
| align="center" | 1/27
|-
| align="center" | 1/24
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.041'''{{overline|6}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|25}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/30
|-
| align="center" | 1/25
| align="center" | &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| '''0.04'''
| bgcolor=#c0c0c0 | '''0.'''{{overline|02436560507534121727}}
| align="center" | &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/31
|-
| align="center" | 1/26
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''13'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|384615}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|2354}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''15'''&lt;/span&gt;
| align="center" | 1/32
|-
| align="center" | 1/27
| align="center" | &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|037}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|022755}}
| align="center" | &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;
| align="center" | 1/33
|-
| align="center" | 1/28
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''7'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.03'''{{overline|571428}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|2}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''7'''&lt;/span&gt;
| align="center" | 1/34
|-
| align="center" | 1/29
| align="center" | &lt;span style="color:Red"&gt;'''29'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|0344827586206896551724137931}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|0215173454106475626043236713}}
| align="center" | &lt;span style="color:Red"&gt;'''35'''&lt;/span&gt;
| align="center" | 1/35
|-
| align="center" | 1/30
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Blue"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Green"&gt;'''5'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.0'''{{overline|3}}
| bgcolor=#c0c0c0 | '''0.0'''{{overline|2104}}
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;, &lt;span style="color:Orange"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:Red"&gt;'''5'''&lt;/span&gt;
| align="center" | 1/36
|-
| align="center" | 1/31
| align="center" | &lt;span style="color:Red"&gt;'''31'''&lt;/span&gt;
| bgcolor=#c0c0c0 | '''0.'''{{overline|032258064516129}}
| bgcolor=#c0c0c0 | '''0.'''{{overline|02041}}
| align="center" | &lt;span style="color:Red"&gt;'''37'''&lt;/span&gt;
| align="center" | 1/37
|-
| align="center" | 1/32
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| '''0.03125'''
| '''0.02'''
| align="center" | &lt;span style="color:Green"&gt;'''2'''&lt;/span&gt;
| align="center" | 1/40
|}

===Irrational numbers===
The table below gives the expansions of some common [[irrational number]]s in decimal and octal.
{| class="wikitable"
! rowspan=2 | Number
! colspan=2 | Positional representation
|-
! Decimal
! Octal
|-
| [[Square root of 2|{{sqrt|2}}]] {{small|(the length of the [[diagonal]] of a unit [[Square (geometry)|square]])}}
| {{val|1.414213562373095048}}...
| 1.3240 4746 3177 1674...
|-
| [[Square root of 3|{{sqrt|3}}]] {{small|(the length of the diagonal of a unit [[cube]])}}
| {{val|1.732050807568877293}}...
| 1.5666 3656 4130 2312...
|-
| [[Square root of 5|{{sqrt|5}}]] {{small|(the length of the [[diagonal]] of a 1×2 [[rectangle]])}}
| {{val|2.236067977499789696}}...
| 2.1706 7363 3457 7224...
|-
| [[Golden ratio|{{mvar|φ}}]] {{small|1=(phi, the [[golden ratio]] = {{math|(1+{{radical|5}})/2}})}}
| {{val|1.618033988749894848}}...
| 1.4743 3571 5627 7512...
|-
| [[Pi|{{mvar|π}}]] {{small|(pi, the ratio of [[circumference]] to [[diameter]] of a circle)}}
| {{val|3.141592653589793238462643}}&lt;br&gt;{{val|383279502884197169399375105}}...
| 3.1103 7552 4210 2643...
|-
| [[E (mathematical constant)|{{mvar|e}}]] {{small|(the base of the [[natural logarithm]])}}
| {{val|2.718281828459045235}}...
| 2.5576 0521 3050 5355...
|}

==See also==
* [[Computer numbering formats]]
* [[Octal games]], a game numbering system used in [[combinatorial game theory]]
* [[Syllabic octal]], a specific octal representation of 8-bit syllables
* [[Squawk code]], an octal representation of [[Gillham code]]

==References==
{{reflist|refs=
&lt;ref name="Paul_1997_NWDOSTIP"&gt;{{cite book |title=NWDOS-TIPs&amp;nbsp;— Tips &amp;amp; Tricks rund um Novell DOS 7, mit Blick auf undokumentierte Details, Bugs und Workarounds |work=MPDOSTIP |author-first=Matthias |author-last=Paul |date=1997-07-30 |edition=3, release 157 |language=German |format=e-book |url=http://www.antonis.de/dos/dos-tuts/mpdostip/html/nwdostip.htm |access-date=2014-08-06 |dead-url=no |archive-url=https://web.archive.org/web/20161104235829/http://www.antonis.de/dos/dos-tuts/mpdostip/html/nwdostip.htm |archive-date=2016-11-04}} (NB. NWDOSTIP.TXT is a comprehensive work on Novell DOS 7 and OpenDOS 7.01, including the description of many undocumented features and internals. It is part of the author's yet larger &lt;code&gt;MPDOSTIP.ZIP&lt;/code&gt; collection maintained up to 2001 and distributed on many sites at the time. The provided link points to a HTML-converted older version of the &lt;code&gt;NWDOSTIP.TXT&lt;/code&gt; file.)&lt;/ref&gt;
&lt;ref name="Paul_2002_CLS"&gt;{{cite web |title=Updated CLS posted |author-first=Matthias |author-last=Paul |date=2002-03-26 |url=http://marc.info/?l=freedos-dev&amp;m=101717593306186&amp;w=2 |publisher=freedos-dev mailing list |access-date=2014-08-06}}&lt;/ref&gt;
&lt;ref name="CCI_1997_HELP"&gt;{{cite book |title=CCI Multiuser DOS 7.22 GOLD Online Documentation |id=HELP.HLP |date=1997-02-10 |publisher=[[Concurrent Controls, Inc.]] (CCI)}}&lt;/ref&gt;
}}

==External links==
* [http://www.octomatics.org Octomatics] is a [[numeral system]] enabling simple visual calculation in octal.

[[Category:Binary arithmetic]]
[[Category:Positional numeral systems]]</text>
      <sha1>fdbx9wuph9d26umujwitjuf3hmvqcvd</sha1>
    </revision>
  </page>
  <page>
    <title>Opposite group</title>
    <ns>0</ns>
    <id>31366779</id>
    <revision>
      <id>854415994</id>
      <parentid>816350165</parentid>
      <timestamp>2018-08-11T05:35:18Z</timestamp>
      <contributor>
        <ip>82.136.67.75</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2361">{{Unreferenced|date=December 2017}}

[[File:Opposite_group_nature.svg|thumbnail|This is a [[natural transformation]] of binary operation from a group to its opposite. &lt;''g''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt;&gt; denotes the [[ordered pair]] of the two group elements. *' can be viewed as the naturally induced addition of +.]]
In [[group theory]], a branch of [[mathematics]], an '''opposite group''' is a way to construct a [[group (mathematics)|group]] from another group that allows one to define [[Group action|right action]] as a special case of [[Group action|left action]].

[[Monoid|Monoids]], groups, [[Ring (mathematics)|rings]], and [[Algebra over a ring|algebras]] can be viewed as [[Category (mathematics)|categories]] with a single object. The construction of the [[opposite category]] generalizes the opposite group, [[opposite ring]], etc.

== Definition ==
Let &lt;math&gt;G&lt;/math&gt; be a group under the operation &lt;math&gt;*&lt;/math&gt;. The opposite group of &lt;math&gt;G&lt;/math&gt;, denoted &lt;math&gt;G^{\mathrm{op}}&lt;/math&gt;, has the same underlying set as &lt;math&gt;G&lt;/math&gt;, and its group operation &lt;math&gt;\mathbin{\ast'}&lt;/math&gt; is defined by &lt;math&gt;g_1 \mathbin{\ast'} g_2 = g_2 * g_1&lt;/math&gt;.

If &lt;math&gt;G&lt;/math&gt; is [[abelian group|abelian]], then it is equal to its opposite group. Also, every group &lt;math&gt;G&lt;/math&gt; (not necessarily abelian) is [[naturally isomorphic]] to its opposite group: An isomorphism &lt;math&gt;\varphi: G \to G^{\mathrm{op}}&lt;/math&gt; is given by &lt;math&gt;\varphi(x) = x^{-1}&lt;/math&gt;. More generally, any [[antiautomorphism]] &lt;math&gt;\psi: G \to G&lt;/math&gt; gives rise to a corresponding isomorphism &lt;math&gt;\psi': G \to G^{\mathrm{op}}&lt;/math&gt; via &lt;math&gt;\psi'(g)=\psi(g)&lt;/math&gt;, since
: &lt;math&gt;\psi'(g * h) = \psi(g * h) = \psi(h) * \psi(g) = \psi(g) \mathbin{\ast'} \psi(h)=\psi'(g) \mathbin{\ast'} \psi'(h).&lt;/math&gt;

== Group action ==
Let &lt;math&gt;X&lt;/math&gt; be an object in some category, and &lt;math&gt;\rho: G \to \mathrm{Aut}(X)&lt;/math&gt; be a [[Group action|right action]]. Then &lt;math&gt;\rho^{\mathrm{op}}: G^{\mathrm{op}} \to \mathrm{Aut}(X)&lt;/math&gt; is a left action defined by &lt;math&gt;\rho^{\mathrm{op}}(g)x = x\rho(g)&lt;/math&gt;, or &lt;math&gt;g^{\mathrm{op}}x = xg&lt;/math&gt;.

== See also ==
* [[Opposite ring]]
* [[Opposite category]]

== External links ==
* [http://planetmath.org/oppositegroup http://planetmath.org/oppositegroup]

[[Category:Group theory]]
[[Category:Representation theory]]</text>
      <sha1>fspgqoowp285trbeghocu46g0o2g206</sha1>
    </revision>
  </page>
  <page>
    <title>Owen's T function</title>
    <ns>0</ns>
    <id>26297589</id>
    <revision>
      <id>751688966</id>
      <parentid>735051220</parentid>
      <timestamp>2016-11-27T08:07:58Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Multivariate statistics]]; added [[Category:Normal distribution]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3691">In mathematics, '''Owen's T function''' ''T''(''h'',&amp;nbsp;''a''), named after [[statistician]] Donald Bruce Owen, is defined by

:&lt;math&gt;
 T(h,a)=\frac{1}{2\pi}\int_{0}^{a} \frac{e^{-\frac{1}{2} h^2 (1+x^2)}}{1+x^2}  dx \quad \left(-\infty &lt; h, a &lt; +\infty\right).
&lt;/math&gt;

The function was first introduced by Owen in 1956.&lt;ref&gt;Owen, D B (1956). "Tables for computing bivariate normal probabilities". ''Annals of Mathematical Statistics'',
27, 1075&amp;ndash;1090.&lt;/ref&gt;

==Applications==
The function ''T''(''h'',&amp;nbsp;''a'') gives the probability of the event (''X&gt;h'' and 0''&lt;Y&lt;a*X'') where ''X'' and ''Y'' are [[statistically independent|independent]] [[standard normal distribution|standard normal]] [[random variable]]s.
 
This function can be used to calculate [[bivariate normal distribution]] probabilities&lt;ref&gt;Sowden, R R and Ashford, J R (1969). "Computation of the bivariate normal integral". ''Applied Statististics'', 18, 169&amp;ndash;180.&lt;/ref&gt;&lt;ref&gt;Donelly, T G (1973). "Algorithm 462. Bivariate normal distribution". ''Commun. Ass. Comput.Mach.'', 16, 638.&lt;/ref&gt; and, from there, in the calculation of [[multivariate normal distribution]] probabilities.&lt;ref&gt;Schervish, M H (1984). "Multivariate normal probabilities with [[error bound]]". ''Applied Statistics'', 33, 81&amp;ndash;94.&lt;/ref&gt;
It also frequently appears in [[List of integrals of Gaussian functions|various integrals involving Gaussian functions]].

Computer algorithms for the accurate calculation of this function are available;&lt;ref&gt;Patefield, M. and Tandy, D.  (2000) "[http://www.jstatsoft.org/v05/i05/paper Fast and accurate Calculation of Owen’s T-Function]", ''Journal of Statistical Software'', 5 (5), 1&amp;ndash;25. &lt;/ref&gt; [[Gaussian quadrature|quadrature]] having been employed since the 1970s. &lt;ref&gt;[http://people.sc.fsu.edu/~jburkardt/m_src/asa076/tfn.m JC Young and Christoph Minder. Algorithm AS 76] &lt;/ref&gt;

==Properties==
: &lt;math&gt; T(h,0) = 0 &lt;/math&gt;
: &lt;math&gt; T(0,a) = \frac{1}{2\pi} \arctan(a) &lt;/math&gt;
: &lt;math&gt; T(-h,a) = T(h,a) &lt;/math&gt;
: &lt;math&gt; T(h,-a) = -T(h,a) &lt;/math&gt;
: &lt;math&gt; T(h,a) + T(ah,\frac{1}{a}) = \frac{1}{2} \left(\Phi(h) + \Phi(ah)\right) - \Phi(h)\Phi(ah) \quad \mbox{if} \quad a \geq 0 &lt;/math&gt;
: &lt;math&gt; T(h,a) + T(ah,\frac{1}{a}) = \frac{1}{2} \left(\Phi(h) + \Phi(ah)\right) - \Phi(h)\Phi(ah) - \frac{1}{2} \quad \mbox{if} \quad a &lt; 0 &lt;/math&gt;
: &lt;math&gt; T(h, 1) = \frac{1}{2} \Phi(h) \left(1 - \Phi(h)\right) &lt;/math&gt;
: &lt;math&gt; \int T(0,x) \mathrm{d}x = x T(0,x) - \frac{1}{4 \pi} \ln(1+x^2) + C &lt;/math&gt;
Here ''Φ(x)'' is the [[Normal distribution|standard normal cumulative density function]]
: &lt;math&gt; \Phi(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x \exp\left(-t^2 / 2\right) \mathrm{d}t &lt;/math&gt;
More properties can be found in the literature.&lt;ref&gt;{{harvtxt|Owen|1980}}&lt;/ref&gt;

==References==
{{reflist}}

* {{cite journal
  | last1 = Owen | first1 = D.
  | year = 1980
  | title = A table of normal integrals
  | journal = Communications in Statistics: Simulation and Computation
  | pages = 389–419
  | volume = B9
  | ref = harv
  }}

==Software==
* [http://people.sc.fsu.edu/~burkardt/f_src/owens/owens.html Owen's T function] (user web site) - offers C++, FORTRAN77, FORTRAN90, and MATLAB libraries released under the LGPL license [[LGPL]]
* Owen's T-function is implemented in [[Mathematica]] since version 8, as [http://reference.wolfram.com/mathematica/ref/OwenT.html OwenT].

==External links==
* [http://blog.wolfram.com/2010/10/07/why-you-should-care-about-the-obscure/ Why You Should Care about the Obscure] (Wolfram blog post)

[[Category:Normal distribution]]
[[Category:Computational statistics]]
[[Category:Functions related to probability distributions]]


{{statistics-stub}}</text>
      <sha1>s8lmz26uykrcsnbr2asj8oibhgn2z1x</sha1>
    </revision>
  </page>
  <page>
    <title>Paden–Kahan subproblems</title>
    <ns>0</ns>
    <id>56625736</id>
    <revision>
      <id>865405597</id>
      <parentid>865286438</parentid>
      <timestamp>2018-10-23T19:08:54Z</timestamp>
      <contributor>
        <ip>23.28.182.213</ip>
      </contributor>
      <comment>Added atan2 to the theta equation for subproblem 3</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14108">'''Paden–Kahan subproblems''' are a set of solved geometric problems which occur frequently in [[inverse kinematics]] of common robotic manipulators.&lt;ref&gt;{{cite web|last1=Paden|first1=Bradley Evan|title=Kinematics and Control of Robot Manipulators|bibcode=1985PhDT........94P|website=Ph.D. Thesis|accessdate=18 February 2018|date=1985}}&lt;/ref&gt; Although the set of problems is not exhaustive, it may be used to simplify inverse kinematic analysis for many industrial robots.&lt;ref&gt;{{cite book|last1=Sastry|first1=Richard M. Murray ; Zexiang Li ; S. Shankar|title=A mathematical introduction to robotic manipulation|date=1994|publisher=CRC Press|location=Boca Raton, Fla.|isbn=9780849379819|edition=1. [Dr.]|url=http://www.cds.caltech.edu/~murray/books/MLS/pdf/mls94-complete.pdf}}&lt;/ref&gt;

== Simplification strategies ==

For a structure equation defined by the [[Product of exponentials formula|product of exponentials]] method, Paden–Kahan subproblems may be used to simplify and solve the inverse kinematics problem. Notably, the matrix exponentials are non-[[Commutative property|commutative]].

Generally, subproblems are applied to solve for particular points in the inverse kinematics problem (e.g., the intersection of joint axes) in order to solve for joint angles.

=== Eliminating revolute joints ===

Simplification is accomplished by the principle that a rotation has no effect on a point lying on its axis. For example, if the point &lt;math display="inline"&gt;p&lt;/math&gt; is on the axis of a revolute twist &lt;math display="inline"&gt;\xi&lt;/math&gt;, its position is unaffected by the actuation of the twist. To wit:&lt;math display="block"&gt;e^{\widehat{\xi}\theta}p=p&lt;/math&gt;

Thus, for a structure equation&lt;math display="block"&gt;e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}e^{\widehat{\xi}_3\theta_3}=g&lt;/math&gt;where &lt;math display="inline"&gt;\xi_1&lt;/math&gt;, &lt;math display="inline"&gt;\xi_2&lt;/math&gt; and &lt;math display="inline"&gt;\xi_3&lt;/math&gt; are all zero-pitch twists, applying both sides of the equation to a point &lt;math display="inline"&gt;p&lt;/math&gt; which is on the axis of &lt;math display="inline"&gt;\xi_3&lt;/math&gt; (but not on the axes of &lt;math display="inline"&gt;\xi_1&lt;/math&gt; or &lt;math display="inline"&gt;\xi_2&lt;/math&gt;) yields&lt;math display="block"&gt;e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}e^{\widehat{\xi}_3\theta_3}p=gp&lt;/math&gt;By the cancellation of &lt;math display="inline"&gt;\xi_3&lt;/math&gt;, this yields&lt;math display="block"&gt;e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}p=gp&lt;/math&gt;which, if &lt;math display="inline"&gt;\xi_1&lt;/math&gt; and &lt;math display="inline"&gt;\xi_2&lt;/math&gt; intersect, may be solved by Subproblem 2.

=== Norm ===

In some cases, the problem may also be simplified by subtracting a point from both sides of the equation and taking the norm of the result.

For example, to solve&lt;math display="block"&gt;e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}e^{\widehat{\xi}_3\theta_3}=g&lt;/math&gt;for &lt;math display="inline"&gt;\xi_3&lt;/math&gt;, where &lt;math display="inline"&gt;\xi_1&lt;/math&gt; and &lt;math display="inline"&gt;\xi_2&lt;/math&gt; intersect at the point &lt;math display="inline"&gt;q&lt;/math&gt;, both sides of the equation may be applied to a point &lt;math display="inline"&gt;p&lt;/math&gt; that is not on the axis of &lt;math display="inline"&gt;\xi_3&lt;/math&gt;. Subtracting &lt;math display="inline"&gt;q&lt;/math&gt; and taking the norm of both sides yields&lt;math display="block"&gt;\begin{aligned}
\delta_i = \|gp-q\| = \|e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}e^{\widehat{\xi}_3\theta_3}p-q\|
 = \|e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}(e^{\widehat{\xi}_3\theta_3}p-q)\|
 = \|e^{\widehat{\xi}_3\theta_3}p-q\|
 \end{aligned}&lt;/math&gt; 
This may be solved using Subproblem 3.

== List of subproblems ==
Each subproblem is presented as an algorithm based on a geometric proof. Code to solve a given subproblem, which should be written to account for cases with multiple solutions or no solution, may be integrated into inverse kinematics algorithms for a wide range of robots.

== Subproblem 1: Rotation about a single axis ==
:[[File:Paden-Kahan Subproblem 1.png|thumb|An illustration of the first Paden–Kahan subproblem.]]'''Let &lt;math display="inline"&gt;\xi&lt;/math&gt; be a zero-pitch twist with unit magnitude and &lt;math display="inline"&gt;p, q \in \R^3&lt;/math&gt; be two points. Find &lt;math display="inline"&gt;\theta&lt;/math&gt; such that '''&lt;math display="block"&gt;e^{\widehat{\xi}\theta}p=q.&lt;/math&gt;
In this subproblem, a point &lt;math display="inline"&gt;p&lt;/math&gt; is rotated around a given axis &lt;math display="inline"&gt;\xi&lt;/math&gt; such that it coincides with a second point &lt;math display="inline"&gt;q&lt;/math&gt;.[[File:Paden-Kahan Subproblem 1 (projected circle).png|thumb|An illustration of the projected circle in the first Paden–Kahan subproblem.]]

=== Solution ===
Let &lt;math display="inline"&gt;r&lt;/math&gt; be a point on the axis of &lt;math display="inline"&gt;\xi&lt;/math&gt;. Define the vectors &lt;math display="inline"&gt;u=(p-r)&lt;/math&gt; and &lt;math display="inline"&gt;v=(q-r)&lt;/math&gt;. Since &lt;math display="inline"&gt;r&lt;/math&gt; is on the axis of &lt;math display="inline"&gt;\xi&lt;/math&gt;, &lt;math display="inline"&gt;e^{\widehat{\xi}\theta}r=r.&lt;/math&gt; Therefore, &lt;math display="inline"&gt;e^{\widehat{\omega}\theta}u=v.&lt;/math&gt;

Next, the vectors &lt;math display="inline"&gt;u'&lt;/math&gt; and &lt;math display="inline"&gt;v'&lt;/math&gt; are defined to be the projections of &lt;math display="inline"&gt;u&lt;/math&gt; and &lt;math display="inline"&gt;v&lt;/math&gt; onto the plane perpendicular to the axis of &lt;math display="inline"&gt;\xi&lt;/math&gt;. For a vector &lt;math display="inline"&gt;\omega \in \R&lt;/math&gt; in the direction of the axis of &lt;math display="inline"&gt;\xi&lt;/math&gt;,&lt;math display="block"&gt;u'=u-\omega\omega^Tu&lt;/math&gt;and&lt;math display="block"&gt;v'=v-\omega\omega^Tv.&lt;/math&gt;In the event that &lt;math display="inline"&gt;u'=0&lt;/math&gt;, &lt;math display="inline"&gt;p=q&lt;/math&gt; and both points lie on the axis of rotation. The subproblem therefore yields an infinite number of possible solutions in that case.

In order for the problem to have a solution, it is necessary that the projections of &lt;math display="inline"&gt;u&lt;/math&gt; and &lt;math display="inline"&gt;v&lt;/math&gt; onto the &lt;math display="inline"&gt;\omega&lt;/math&gt; axis and onto the plane perpendicular to &lt;math display="inline"&gt;\omega&lt;/math&gt; have equal lengths. It is necessary to check, to wit, that:&lt;math display="block"&gt;\omega^Tu=\omega^Tv&lt;/math&gt;and that&lt;math display="block"&gt;\|u'\|=\|v'\|&lt;/math&gt;

If these equations are satisfied, the value of the joint angle &lt;math display="inline"&gt;\theta&lt;/math&gt; may be found using the [[atan2]] function:&lt;math display="block"&gt;\theta=\mathrm{atan2}(\omega^T(u'\times v'), u'^Tv').&lt;/math&gt;Provided that &lt;math display="inline"&gt;u'\neq 0&lt;/math&gt;, this subproblem should yield one solution for &lt;math display="inline"&gt;\theta&lt;/math&gt;.

== Subproblem 2: Rotation about two subsequent axes ==

:[[File:Paden-Kahan Subproblem 2.png|thumb|Illustration of Paden–Kahan Subproblem 2. The subproblem yields two solutions in the event that the circles intersect at two points; one solution if the circles are tangential; and no solution if the circles fail to intersect.]]'''Let &lt;math display="inline"&gt;\xi_1&lt;/math&gt; and &lt;math display="inline"&gt;\xi_2&lt;/math&gt; be two zero-pitch twists with unit magnitude and intersecting axes. Let &lt;math display="inline"&gt;p, q \in \R^3&lt;/math&gt; be two points. Find &lt;math display="inline"&gt;\theta_1&lt;/math&gt; and &lt;math display="inline"&gt;\theta_2&lt;/math&gt; such that &lt;math display="block"&gt;e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}p=q.&lt;/math&gt;'''
This problem corresponds to rotating &lt;math display="inline"&gt;p&lt;/math&gt; around the axis of &lt;math display="inline"&gt;\xi_2&lt;/math&gt; by &lt;math display="inline"&gt;\theta_2&lt;/math&gt;, then rotating it around the axis of &lt;math display="inline"&gt;\xi_1&lt;/math&gt; by &lt;math display="inline"&gt;\theta_1&lt;/math&gt;, so that the final location of &lt;math display="inline"&gt;p&lt;/math&gt; is coincident with &lt;math display="inline"&gt;q&lt;/math&gt;. (If the axes of &lt;math display="inline"&gt;\xi_1&lt;/math&gt; and &lt;math display="inline"&gt;\xi_2&lt;/math&gt; are coincident, then this problem reduces to Subproblem 1, admitting all solutions such that &lt;math display="inline"&gt;\theta_1+\theta_2=\theta&lt;/math&gt;.)

=== Solution ===

Provided that the two axes are not parallel (i.e., &lt;math display="inline"&gt;\omega_1 \neq \omega_2&lt;/math&gt;), let &lt;math display="inline"&gt;c&lt;/math&gt; be a point such that &lt;math display="block"&gt;e^{\widehat{\xi}_2\theta_2} p=c=e^{-\widehat{\xi}_1\theta_1}q.&lt;/math&gt; In other words, &lt;math display="inline"&gt;c&lt;/math&gt; represents the point to which &lt;math display="inline"&gt;p&lt;/math&gt; is rotated around one axis before it is rotated around the other axis to be coincident with &lt;math display="inline"&gt;q&lt;/math&gt;. Each individual rotation is equivalent to Subproblem 1, but it’s necessary to identify one or more valid solutions for &lt;math display="inline"&gt;c&lt;/math&gt; in order to solve for the rotations.

Let &lt;math display="inline"&gt;r&lt;/math&gt; be the point of intersection of the two axes:&lt;math display="block"&gt;e^{\widehat{\xi}_2\theta_2}(p-r)=c-r=e^{-\widehat{\xi}_1\theta_1}(q-r).&lt;/math&gt;[[File:Paden-Kahan Subproblem 2 Tangential Case.png|thumb|An illustration of Paden–Kahan subproblem 2, showing the tangential case in which the subproblem yields only one solution.]]Define the vectors &lt;math display="inline"&gt;u=(p-r)&lt;/math&gt;, &lt;math display="inline"&gt;v=(q-r)&lt;/math&gt; and &lt;math display="inline"&gt;z=(c-r)&lt;/math&gt;. Therefore,&lt;math display="block"&gt;e^{\widehat{\xi}_2\theta_2}u=z=e^{-\widehat{\xi}_1\theta_1}v.&lt;/math&gt;

This implies that &lt;math display="inline"&gt;\omega^T_2u=\omega^T_2z&lt;/math&gt;, &lt;math display="inline"&gt;\omega^T_1 v=\omega^T_1z&lt;/math&gt;, and &lt;math display="inline"&gt;\|u\|^2=\|z\|^2=\|v\|^2&lt;/math&gt;. Since &lt;math display="inline"&gt;\omega_1&lt;/math&gt;, &lt;math display="inline"&gt;\omega_2&lt;/math&gt; and &lt;math display="inline"&gt;\omega_1 \times \omega_2&lt;/math&gt; are linearly independent, &lt;math display="inline"&gt;z&lt;/math&gt; can be written as&lt;math display="block"&gt;z=\alpha \omega_1 + \beta\omega_2 + \gamma(\omega_1 \times \omega_2).&lt;/math&gt;

The values of the coefficients may be solved thus:[[File:Paden-Kahan Subproblem 2 - 2 soln case.png|thumb|An illustration of Paden–Kahan subproblem 2, showing a case with two intersecting circles and therefore two solutions. Both solutions (c, c2) are highlighted.]]&lt;math display="block"&gt;\alpha = \frac{(\omega^T_1 \omega_2)\omega^T_2u-\omega^T_1v}{(\omega^T_1\omega_2)^2 - 1}&lt;/math&gt;&lt;math display="block"&gt;\beta = \frac{(\omega^T_1 \omega_2)\omega^T_1v-\omega^T_2u}{(\omega^T_1\omega_2)^2 - 1}&lt;/math&gt;, and&lt;math display="block"&gt;\gamma^2=\frac{\|u\|^2-\alpha^2-\beta^2-2\alpha\beta\omega^T_1 \omega_2}{\|\omega_1 \times \omega_2\|^2.}&lt;/math&gt;The subproblem yields two solutions in the event that the circles intersect at two points; one solution if the circles are tangential; and no solution if the circles fail to intersect.

== Subproblem 3: Rotation to a given distance ==

:'''Let &lt;math display="inline"&gt;\xi&lt;/math&gt; be a zero-pitch twist with unit magnitude; let &lt;math display="inline"&gt;p, q \in \R^3&lt;/math&gt; be two points; and let &lt;math display="inline"&gt;\delta&lt;/math&gt; be a real number greater than 0. Find &lt;math display="inline"&gt;\theta&lt;/math&gt; such that &lt;math display="block"&gt;\|q-e^{\widehat{\xi} \theta}p\| = \delta.&lt;/math&gt;'''

In this problem, a point &lt;math display="inline"&gt;p&lt;/math&gt; is rotated about an axis &lt;math display="inline"&gt;\xi&lt;/math&gt; until the point is a distance &lt;math display="inline"&gt;\delta&lt;/math&gt; from a point &lt;math display="inline"&gt;q&lt;/math&gt;. In order for a solution to exist, the circle defined by rotating &lt;math display="inline"&gt;p&lt;/math&gt; around &lt;math display="inline"&gt;\xi&lt;/math&gt; must have a sphere of radius &lt;math display="inline"&gt;\delta&lt;/math&gt; centered at &lt;math display="inline"&gt;q&lt;/math&gt;.

=== Solution ===

Let &lt;math display="inline"&gt;r&lt;/math&gt; be a point on the axis of &lt;math display="inline"&gt;\xi&lt;/math&gt;. The vectors &lt;math display="inline"&gt;u=(p-r)&lt;/math&gt; and &lt;math display="inline"&gt;v=(q-r)&lt;/math&gt; are defined so that&lt;math display="block"&gt;\|v-e^{\widehat{\xi}\theta}u\|^2=\delta^2.&lt;/math&gt;

The projections of &lt;math display="inline"&gt;u&lt;/math&gt; and &lt;math display="inline"&gt;v&lt;/math&gt; are &lt;math display="inline"&gt;u'=u-\omega\omega^Tu&lt;/math&gt; and &lt;math display="inline"&gt;v'=v-\omega\omega^Tv.&lt;/math&gt; The “projection” of the line segment defined by &lt;math display="inline"&gt;\delta&lt;/math&gt; is found by subtracting the component of &lt;math display="inline"&gt;p-q&lt;/math&gt; in the &lt;math display="inline"&gt;\omega&lt;/math&gt; direction:&lt;math display="block"&gt;\delta'^2 = \delta^2 - |\omega^T(p-q)|^2.&lt;/math&gt;The angle &lt;math display="inline"&gt;\theta_0&lt;/math&gt; between the vectors &lt;math display="inline"&gt;u'&lt;/math&gt; and &lt;math display="inline"&gt;v'&lt;/math&gt; is found using the [[atan2]] function:&lt;math display="block"&gt;\theta_0 = atan2(\omega^T(u'\times v'), u'^Tv').&lt;/math&gt;The joint angle &lt;math display="inline"&gt;\theta&lt;/math&gt; is found by the formula&lt;math display="block"&gt;\theta=\theta_0 \pm \cos^{-1} \left( \frac{\|u'\|^2 + \|v'\|^2 - \delta'^2}{2\|u'\| \|v'\|} \right).&lt;/math&gt;This subproblem may yield zero, one, or two solutions, depending on the number of points at which the circle of radius &lt;math display="inline"&gt;\|u'\|&lt;/math&gt; intersects the circle of radius &lt;math display="inline"&gt;\delta'&lt;/math&gt;.

== Subproblem 4: Rotation about two axes to a given distance ==

:'''Let &lt;math display="inline"&gt;\xi_1&lt;/math&gt; and &lt;math display="inline"&gt;\xi_2&lt;/math&gt; be two zero-pitch twists with unit magnitude and intersecting axes. Let &lt;math display="inline"&gt;p, q_1, q_2 \in \R^3&lt;/math&gt; be points. Find &lt;math display="inline"&gt;\theta_1&lt;/math&gt; and &lt;math display="inline"&gt;\theta_2&lt;/math&gt; such that &lt;math display="block"&gt;\|e^{\widehat{\xi}_1\theta_1}e^{\widehat{\xi}_2\theta_2}p-q_1\|=\delta_1.&lt;/math&gt;'''

This problem is analogous to Subproblem 2, except that the final point is constrained by distances to two known points.

== Subproblem 5: Translation to a given distance ==

:'''Let &lt;math display="inline"&gt;\xi&lt;/math&gt; be an infinite-pitch unit magnitude twist; &lt;math display="inline"&gt;p, q \in \R^3&lt;/math&gt; two points; and &lt;math display="inline"&gt;\delta&lt;/math&gt; a real number greater than 0. Find &lt;math display="inline"&gt;\theta&lt;/math&gt; such that &lt;math display="block"&gt;\|q-e^{\widehat{\xi}\theta}p\|=\delta.&lt;/math&gt;'''

==References==
{{Reflist}}



[[Category:Computational geometry]]
[[Category:Robotic manipulation]]</text>
      <sha1>9jif05bsmzgv5ch1gb1un4exkl3hwo7</sha1>
    </revision>
  </page>
  <page>
    <title>Phyloscan</title>
    <ns>0</ns>
    <id>25958537</id>
    <revision>
      <id>870955478</id>
      <parentid>727541635</parentid>
      <timestamp>2018-11-28T01:06:21Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Bioinformatics]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4011">{{Infobox Software
| name                   = Phyloscan
| developer              = Wadsworth Center, New York State Department of Health
| released               = {{release date|2005|03|14}}
| latest release version = 2.2
| latest release date    = {{release date|2010|01|28}}
| platform               = web service
| language               = [[English language|English]]
| genre                  = [[Bioinformatics]] tool
| website                = http://ccmbweb.ccv.brown.edu/cgi-bin/phyloscanV2.pl
}}

'''Phyloscan'''&lt;ref&gt;{{cite journal |last1=Palumbo |first1=MJ |last2=Newberg |first2=LA |title=Phyloscan: locating transcription-regulating binding sites in mixed aligned and unaligned sequence data |journal=Nucleic Acids Research |volume=38 |issue=Web server issue |pages=W268&amp;ndash;W274 |date=July 1, 2010|url=http://nar.oxfordjournals.org/cgi/content/abstract/38/suppl_2/W268 |doi=10.1093/nar/gkq330 |pmc=2896078 |pmid=20435683}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Carmack |first1=CS |last2=McCue |first2=LA |last3=Newberg |first3=LA |last4=Lawrence |first4=CE |title=PhyloScan: identification of transcription factor binding sites using cross-species evidence |journal=Algorithms for Molecular Biology |volume=2 |issue=1 |pages=article 1 |date=January 23, 2007|url=http://www.almob.org/content/2/1/1 |doi=10.1186/1748-7188-2-1 |pmid=17244358 |pmc=1794230}}&lt;/ref&gt; is a web service for DNA [[sequence analysis]] that is free and open to all users (without login requirement).  For locating matches to a user-specified [[sequence motif]] for a regulatory [[DNA binding site|binding site]], Phyloscan provides a [[sensitivity and specificity|statistically sensitive]] scan of user-supplied mixed [[sequence alignment|aligned]] and unaligned DNA sequence data.  Phyloscan's strength is that it brings together 
* the Staden method&lt;ref&gt;{{cite journal |last1=Staden |first1=R |title=Methods for calculating the probabilities of finding patterns in sequences |journal=Computer Applications in the Biosciences |volume=5 |issue=2 |pages=89&amp;ndash;96 |date=April 1989 |url=http://bioinformatics.oxfordjournals.org/cgi/content/abstract/5/2/89 |doi=10.1093/bioinformatics/5.2.89 |pmid=2720468}}&lt;/ref&gt; for computing [[statistical significance]],
* the "phylogenetic motif model" scanning functionality of the MONKEY software&lt;ref&gt;{{cite journal |last1=Moses |first1=AM |last2=Chiang |first2=DY |last3=Pollard |first3=DA |last4=Iyer |first4=VN |last5=Eisen |first5=MB |title=MONKEY: identifying conserved transcription-factor binding sites in multiple alignments using a binding site-specific evolutionary model |journal=Genome Biology |volume=5 |issue=12 |pages=R98 |date=November 30, 2004|url=http://genomebiology.com/2004/5/12/R98 |doi=10.1186/gb-2004-5-12-r98 |pmid=15575972 |pmc=545801}}&lt;/ref&gt; that models evolutionary relationships among aligned sequences,
* the use of the Bailey &amp; Gribskov method&lt;ref&gt;{{cite journal |last1=Bailey |first1=TL |last2=Gribskov |first2=M |title=Methods and statistics for combining motif match scores |journal=Journal of Computational Biology |volume=5 |issue=2 |pages=211&amp;ndash;221 |date=Summer 1998 |doi=10.1089/cmb.1998.5.211 |pmid=9672829}}&lt;/ref&gt; for combining statistics across non-aligned sequence data, and
* the Neuwald &amp; Green technique&lt;ref&gt;{{cite journal |last1=Neuwald |first1=AF |last2=Green |first2=P |title=Detecting patterns in protein sequences |journal=Journal of Molecular Biology |volume=239 |issue=5 |pages=698&amp;ndash;712 |date=June 24, 1994 |url=http://www.sciencedirect.com/science/article/B6WK7-45NSJRT-BC/2/21eaf0a0831a83996e53fd380cd03c61 |doi=10.1006/jmbi.1994.1407 |pmid=8014990}}&lt;/ref&gt; for combining statistics across multiple binding sites found within a single gene promoter region.

==References==
{{reflist}}

==External links==
*[http://ccmbweb.ccv.brown.edu/cgi-bin/phyloscanV2.pl Phyloscan homepage] at [[Brown University]]

{{DEFAULTSORT:Phyloscan}}
[[Category:Bioinformatics]]
[[Category:Bioinformatics software]]
[[Category:Computational science]]</text>
      <sha1>497ymhoch7hsd7fhh4w0g5dwtwp9cen</sha1>
    </revision>
  </page>
  <page>
    <title>Ptolemy's table of chords</title>
    <ns>0</ns>
    <id>30684123</id>
    <revision>
      <id>870814124</id>
      <parentid>864728413</parentid>
      <timestamp>2018-11-27T04:37:21Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* The chord function and the table */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13897">The '''table of chords''', created by the astronomer, geometer, and geographer [[Ptolemy]] in [[Egypt]] during the 2nd century AD, is a [[trigonometric table]] in Book&amp;nbsp;I, chapter&amp;nbsp;11 of Ptolemy's ''[[Almagest]]'',&lt;ref name=toomer&gt;{{Citation|title=Ptolemy's Almagest|last1=Toomer|first1=G. J.|authorlink=Gerald J. Toomer|publisher=[[Princeton University Press]]|year= 1998|ISBN =0-691-00260-6}}&lt;/ref&gt; a treatise on [[mathematical astronomy]].  It is essentially equivalent to a table of values of the [[sine]] function.  It was the earliest trigonometric table extensive enough for many practical purposes, including those of astronomy (an earlier table of chords by [[Hipparchus]] gave chords only for arcs that were multiples of {{nowrap|{{sfrac|7|1|2}}° {{=}} {{sfrac|{{pi}}|24}} radians}}).&lt;ref&gt;Thurston, [https://books.google.com/books?id=rNpHjqxQQ9oC&amp;pg=PA235 pp. 235&amp;ndash;236].&lt;/ref&gt;  Centuries passed before more extensive trigonometric tables were created. One such table is the ''[[Canon Sinuum (Bürgi)|Canon Sinuum]]'' created at the end of the 16th century.

== The chord function and the table ==

[[File:Chords.svg|thumb|right|350px|Example: The length of the chord subtending a {{sfrac|109|1|2}} arc is approximately&amp;nbsp;98.]]

A [[chord (geometry)|chord]] of a [[circle]] is a line segment whose endpoints are on the circle.  Ptolemy used a circle whose diameter is&amp;nbsp;120.  He tabulated the length of a chord whose endpoints are separated by an arc of ''n''&amp;nbsp;degrees, for ''n'' ranging from {{sfrac|1|2}} to 180 by increments of&amp;nbsp;{{sfrac|1|2}}.  In modern notation, the length of the chord corresponding to an arc of ''θ''&amp;nbsp;degrees is

: &lt;math&gt;
\begin{align}
&amp; \operatorname{chord} \theta = 120 \, \sin\left(\frac{\theta^\circ} 2 \right) \\
= {} &amp; 60 \cdot \left( 2 \, \sin\left(\frac{\pi\theta}{360} \text{ radians} \right) \right).
\end{align}
&lt;/math&gt;

As ''θ'' goes from 0 to 180, the chord of a ''θ''° arc goes from 0 to&amp;nbsp;120.  For tiny arcs, the chord is to the arc angle in degrees as {{pi}} is to&amp;nbsp;3, or more precisely, the ratio can be made as close as desired to {{sfrac|{{pi}}|3}}&amp;nbsp;≈&amp;nbsp;{{val|1.04719755}} by making ''θ'' small enough.  Thus, for the arc of {{sfrac|1|2}}°, the chord length is slightly more than the arc angle in degrees.  As the arc increases, the ratio of the chord to the arc decreases.  When the arc reaches 60°, the chord length is exactly equal to the number of degrees in the arc, i.e. chord&amp;nbsp;60°&amp;nbsp;=&amp;nbsp;60.  For arcs of more than 60°, the chord is less than the arc, until an arc of 180° is reached, when the chord is only&amp;nbsp;120.

The fractional parts of chord lengths were expressed in [[sexagesimal]] (base 60) numerals.  For example, where the length of a chord subtended by a 112° arc is reported to be 99&amp;nbsp;29&amp;nbsp;5, it has a length of

: &lt;math&gt; 99 + \frac{29}{60} + \frac{5}{60^2} = 99.4847\overline{2}, &lt;/math&gt;

rounded to the nearest&amp;nbsp;{{sfrac|1|60&lt;sup&gt;2&lt;/sup&gt;}}.&lt;ref name=toomer /&gt;

After the columns for the arc and the chord, a third column is labeled "sixtieths".  For an arc of&amp;nbsp;''θ''°, the entry in the "sixtieths" column is

: &lt;math&gt; \frac{\operatorname{chord} \left(\theta + \tfrac12 \right)^\circ - \operatorname{chord} \left( \theta^\circ\right)}{30}. &lt;/math&gt;

This is the average number of sixtieths of a unit that must be added to chord(''θ''°) each time the angle increases by one minute of arc, between the entry for&amp;nbsp;''θ''° and that for&amp;nbsp;(''θ''&amp;nbsp;+&amp;nbsp;{{sfrac|1|2}})°. Thus, it is used for [[linear interpolation]].  Glowatzki and Göttsche showed that Ptolemy must have calculated chords to five sexigesimal places in order to achieve the degree of accuracy found in the "sixtieths" column.&lt;ref&gt;Ernst Glowatzki and Helmut Göttsche, ''Die Sehnentafel des Klaudios Ptolemaios.  Nach den historischen Formelplänen neuberechnet.'', München, 1976.&lt;/ref&gt;

: &lt;math&gt;
\begin{array}{|l|rrr|rrr|}
\hline
\text{arc} &amp; \text{chord} &amp; &amp; &amp; \text{sixtieths} &amp; &amp; \\
\hline
{}\,\,\,\,\,\,\,\,\,\, \tfrac12 &amp;  0 &amp; 31 &amp; 25 &amp; 0 \quad 1 &amp; 2 &amp; 50 \\
{}\,\,\,\,\,\,\, 1 &amp; 1 &amp; 2 &amp; 50 &amp; 0 \quad 1 &amp; 2 &amp; 50 \\
{}\,\,\,\,\,\,\, 1\tfrac12 &amp; 1 &amp; 34 &amp; 15 &amp; 0 \quad 1 &amp; 2 &amp; 50 \\
{}\,\,\,\,\,\,\, \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
109 &amp; 97 &amp; 41 &amp; 38 &amp; 0 \quad 0 &amp; 36 &amp; 23 \\
109\tfrac12 &amp; 97 &amp; 59 &amp; 49 &amp; 0 \quad 0 &amp; 36 &amp; 9 \\
110 &amp; 98 &amp; 17 &amp; 54 &amp; 0 \quad 0 &amp; 35 &amp; 56 \\
110\tfrac12 &amp; 98 &amp; 35 &amp; 52 &amp; 0 \quad 0 &amp; 35 &amp; 42\\
111 &amp; 98 &amp; 53 &amp; 43 &amp; 0 \quad 0 &amp; 35 &amp; 29 \\
111\tfrac12 &amp; 99 &amp; 11 &amp; 27 &amp; 0 \quad 0 &amp; 35 &amp; 15 \\
112 &amp; 99 &amp; 29 &amp; 5 &amp; 0 \quad 0 &amp; 35 &amp; 1\\
112\tfrac12 &amp; 99 &amp; 46 &amp; 35 &amp; 0 \quad 0 &amp; 34 &amp; 48 \\
113 &amp; 100 &amp; 3 &amp; 59 &amp; 0 \quad 0 &amp; 34 &amp; 34 \\
{}\,\,\,\,\,\,\, \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
179 &amp; 119 &amp; 59 &amp; 44 &amp; 0 \quad 0 &amp; 0 &amp; 25 \\
179\frac12 &amp; 119 &amp; 59 &amp; 56 &amp; 0 \quad 0 &amp; 0 &amp; 9 \\
180 &amp; 120 &amp; 0 &amp; 0 &amp; 0 \quad 0 &amp; 0 &amp; 0 \\
\hline
\end{array}
&lt;/math&gt;

== How Ptolemy computed chords ==

Chapter 10 of Book&amp;nbsp;I of the ''Almagest'' presents [[Euclidean geometry|geometric]] theorems used for computing chords.  Ptolemy used geometric reasoning based on Proposition&amp;nbsp;10 of Book&amp;nbsp;XIII of [[Euclid|Euclid's]] ''[[Euclid's Elements|Elements]]'' to find the chords of 72° and&amp;nbsp;36°.  That Proposition states that if an equilateral [[pentagon]] is inscribed in a circle, then the area of the square on the side of the pentagon equals the sum of the areas of the squares on the sides of the [[hexagon]] and the [[decagon]] inscribed in the same circle.

He used [[Ptolemy's theorem]] on quadrilaterals inscribed in a circle to derive formulas for the chord of a half-arc, the chord of the sum of two arcs, and the chord of a difference of two arcs.  The theorem states that for a [[quadrilateral]] inscribed in a [[circle]], the product of the lengths of the diagonals equals the sum of the products of the two pairs of lengths of opposite sides.  The derivations of trigonometric identities rely on a [[cyclic quadrilateral]] in which one side is a diameter of the circle.

To find the chords of arcs of 1° and {{sfrac|1|2}}° he used approximations based on [[Aristarchus's inequality]].  The inequality states that for arcs ''α'' and ''β'', if 0&amp;nbsp;&lt;&amp;nbsp;''β''&amp;nbsp;&lt;&amp;nbsp;''α''&amp;nbsp;&lt;&amp;nbsp;90°, then

: &lt;math&gt; \frac{\sin \alpha}{\sin \beta} &lt; \frac\alpha\beta &lt; \frac{\tan\alpha}{\tan\beta}.&lt;/math&gt;

Ptolemy showed that for arcs of 1° and {{sfrac|1|2}}°, the approximations correctly give the first two sexigesimal places after the integer part.

== The numeral system and the appearance of the untranslated table ==

{{main|Greek numerals}}

Lengths of arcs of the circle, in degrees, and the integer parts of chord lengths, were expressed in a [[base 10]] [[numeral system]] that used 21 of the letters of the [[Greek alphabet]] with the meanings given in the following table, and a symbol, "∠′&amp;thinsp;", that means {{sfrac|1|2}} and a raised circle "○" that fills a blank space (effectively representing zero). Two of the letters, labeled "archaic" in the table below, had not been in use in the Greek language for some centuries before the ''Almagest'' was written, but were still in use as numerals and [[Ancient Greek music|musical notes]].
: &lt;math&gt;
\begin{array}{|rlr|rlr|rlr|}
\hline
\alpha &amp; \mathrm{alpha} &amp;  1 &amp; \iota &amp; \mathrm{iota} &amp; 10 &amp; \rho &amp; \mathrm{rho} &amp; 100 \\  \beta &amp; \mathrm{beta} &amp; 2 &amp; \kappa &amp; \mathrm{kappa} &amp; 20 &amp; \vdots  &amp; \vdots &amp; \vdots \\  \gamma &amp; \mathrm{gamma} &amp; 3 &amp; \lambda &amp; \mathrm{lambda} &amp; 30 &amp; &amp; &amp; \\  \delta &amp; \mathrm{delta} &amp; 4 &amp; \mu &amp; \mathrm{mu} &amp; 40 &amp; &amp; &amp; \\  \varepsilon &amp; \mathrm{epsilon} &amp; 5 &amp; \nu &amp; \mathrm{nu} &amp; 50 &amp; &amp; &amp; \\  \stigma &amp; \mathrm{stigma\ (archaic)} &amp; 6 &amp; \xi &amp; \mathrm{xi} &amp; 60 &amp; &amp; &amp; \\  \zeta &amp; \mathrm{zeta} &amp; 7 &amp; \omicron &amp; \mathrm{omicron} &amp; 70 &amp; &amp; &amp; \\  \eta &amp; \mathrm{eta} &amp; 8 &amp; \pi &amp; \mathrm{pi} &amp; 80 &amp; &amp; &amp; \\  \theta &amp; \mathrm{theta} &amp; 9 &amp; \koppa &amp; \mathrm{koppa\ (archaic)} &amp; 90 &amp; &amp; &amp; \\  \hline
\end{array}
&lt;/math&gt;
Thus, for example, an arc of {{sfrac|143|1|2}}° is expressed as ''ρμγ''∠′. (As the table only reaches 180°, the Greek numerals for 200 and above are not used.)

The fractional parts of chord lengths required great accuracy, and were given in two columns in the table: The first column gives an integer multiple of {{sfrac|1|60}}, in the range 0–59, the second an integer multiple of {{sfrac|1|60&lt;sup&gt;2&lt;/sup&gt;}}&amp;nbsp;=&amp;nbsp;{{sfrac|1|3600}}, also in the range 0–59.

Thus in  Heiberg's [http://www.wilbourhall.org/pdfs/HeibergAlmagestComplete.pdf edition of the ''Almagest'' with the table of chords on pages 48–63], the beginning of the table, corresponding to arcs from {{sfrac|1|2}}° to {{sfrac|7|1|2}}°, looks like this:
: &lt;math&gt;
\begin{array}{ccc} \pi\varepsilon\rho\iota\varphi\varepsilon\rho\varepsilon\iota\tilde\omega\nu &amp; \varepsilon\overset{\text{'}}\nu\theta\varepsilon\iota\tilde\omega\nu &amp; \overset{\text{`}}\varepsilon\xi\eta\kappa\omicron\sigma\tau\tilde\omega\nu \\
\begin{array}{|l|} \hline \quad \angle' \\ \alpha \\  \alpha\;\angle' \\  \hline\beta \\  \beta\;\angle' \\  \gamma \\  \hline\gamma\;\angle' \\  \delta \\  \delta\;\angle' \\  \hline\varepsilon \\  \varepsilon\;\angle' \\  \stigma \\  \hline\stigma\;\angle' \\  \zeta \\  \zeta\;\angle' \\  \hline \end{array} &amp; \begin{array}{|r|r|r|} \hline\circ &amp; \lambda\alpha &amp; \kappa\varepsilon \\  \alpha &amp; \beta &amp; \nu \\  \alpha &amp; \lambda\delta &amp; \iota\varepsilon \\  \hline \beta &amp; \varepsilon &amp; \mu \\  \beta &amp; \lambda\zeta &amp; \delta \\  \gamma &amp; \eta &amp; \kappa\eta \\  \hline \gamma &amp; \lambda\theta &amp; \nu\beta \\  \delta &amp; \iota\alpha &amp; \iota\stigma \\  \delta &amp; \mu\beta &amp; \mu \\  \hline \varepsilon &amp; \iota\delta &amp; \delta \\  \varepsilon &amp; \mu\varepsilon &amp; \kappa\zeta \\  \stigma &amp; \iota\stigma &amp; \mu\theta \\  \hline \stigma &amp; \mu\eta &amp; \iota\alpha \\  \zeta &amp; \iota\theta &amp; \lambda\gamma \\  \zeta &amp; \nu &amp; \nu\delta \\  \hline \end{array} &amp; \begin{array}{|r|r|r|r|} \hline \circ &amp; \alpha &amp; \beta &amp; \nu \\  \circ &amp; \alpha &amp; \beta &amp; \nu \\  \circ &amp; \alpha &amp; \beta &amp; \nu \\  \hline \circ &amp; \alpha &amp; \beta &amp; \nu \\  \circ &amp; \alpha &amp; \beta &amp; \mu\eta \\  \circ &amp; \alpha &amp; \beta &amp; \mu\eta \\  \hline\circ &amp; \alpha &amp; \beta &amp; \mu\eta \\  \circ &amp; \alpha &amp; \beta &amp; \mu\zeta \\  \circ &amp; \alpha &amp; \beta &amp; \mu\zeta \\  \hline \circ &amp; \alpha &amp; \beta &amp; \mu\stigma \\  \circ &amp; \alpha &amp; \beta &amp; \mu\varepsilon \\  \circ &amp; \alpha &amp; \beta &amp; \mu\delta \\  \hline \circ &amp; \alpha &amp; \beta &amp; \mu\gamma \\  \circ &amp; \alpha &amp; \beta &amp; \mu\beta \\  \circ &amp; \alpha &amp; \beta &amp; \mu\alpha \\  \hline \end{array}
\end{array}
&lt;/math&gt;

Later in the table, one can see the base-10 nature of the numerals expressing the integer parts of the arc and the chord length.  Thus an arc of 85° is written as ''πε'' (''π'' for 80 and ''ε'' for 5) and not broken down into 60&amp;nbsp;+&amp;nbsp;25. The corresponding chord length is 81 plus a fractional part. The integer part begins with ''πα'', likewise not broken into 60&amp;nbsp;+&amp;nbsp;21. But the fractional part, {{sfrac|4|60}}&amp;nbsp;+&amp;nbsp;{{sfrac|15|60&lt;sup&gt;2&lt;/sup&gt;}}, is written as ''δ'', for 4, in the {{sfrac|1|60}} column, followed by ''ιε'', for 15, in the {{sfrac|1|60&lt;sup&gt;2&lt;/sup&gt;}} column.
: &lt;math&gt;
\begin{array}{ccc} \pi\varepsilon\rho\iota\varphi\varepsilon\rho\varepsilon\iota\tilde\omega\nu &amp; \varepsilon\overset{\text{'}}\nu\theta\varepsilon\iota\tilde\omega\nu &amp; \overset{\text{`}}\varepsilon\xi\eta\kappa\omicron\sigma\tau\tilde\omega\nu \\
\begin{array}{|l|} \hline \pi\delta\angle' \\  \pi\varepsilon \\  \pi\varepsilon\angle' \\  \hline  \pi\stigma \\  \pi\stigma\angle' \\  \pi\zeta \\  \hline \end{array} &amp; \begin{array}{|r|r|r|} \hline \pi &amp; \mu\alpha &amp; \gamma \\  \pi\alpha &amp; \delta &amp; \iota\varepsilon \\  \pi\alpha &amp; \kappa\zeta &amp; \kappa\beta \\  \hline \pi\alpha &amp; \nu &amp; \kappa\delta \\  \pi\beta &amp; \iota\gamma &amp; \iota\theta \\  \pi\beta &amp; \lambda\stigma &amp; \theta \\  \hline \end{array} &amp; \begin{array}{|r|r|r|r|} \hline \circ &amp; \circ &amp; \mu\stigma &amp; \kappa\varepsilon \\  \circ &amp; \circ &amp; \mu\stigma &amp; \iota\delta \\  \circ &amp; \circ &amp; \mu\stigma &amp; \gamma \\  \hline \circ &amp; \circ &amp; \mu\varepsilon &amp; \nu\beta \\  \circ &amp; \circ &amp; \mu\varepsilon &amp; \mu \\  \circ &amp; \circ &amp; \mu\varepsilon &amp; \kappa\theta \\  \hline \end{array}
\end{array}
&lt;/math&gt;
The table has 45&amp;nbsp;lines on each of eight pages, for a total of 360&amp;nbsp;lines.

== See also ==
* [[Exsecant]]
* ''[[Fundamentum Astronomiae]]'', a book setting forth an algorithm for precise computation of sines, published in the late 1500s
* [[Scale of chords]]
* [[Versine]]

== References ==
{{Reflist}}

* {{Citation|title=Episodes from the Early History of Mathematics|last1=Aaboe|first1=Asger|authorlink=Asger Aaboe|publisher=Mathematical Association of America|year= 1997|ISBN =978-0-88385-613-0}}
* {{Citation|title=Greek Science in Antiquity|last1=Clagett|first1=Marshall|authorlink=Marshall Clagett |publisher=Courier Dover Publications|year=2002|ISBN =978-0-8369-2150-2}}
* {{Citation|title=A History of Ancient Mathematical Astronomy|last1=Neugebauer|first1=Otto|authorlink=Otto Neugebauer|publisher=Springer-Verlag|year= 1975|ISBN =978-0-387-06995-1}}
* [[Olaf Pedersen]] (1974) ''A Survey of the Almagest'', [[Odense University Press]] {{ISBN|87-7492-087-1}}
* {{Citation|title=Early Astronomy|last1=Thurston|first1=Hugh|authorlink=Hugh Thurston |publisher=Springer|year=1996|ISBN =978-0-387-94822-5}}

== External links ==
* [[Johan Ludvig Heiberg (historian)|J. L. Heiberg]] [http://www.wilbourhall.org/pdfs/HeibergAlmagestComplete.pdf ''Almagest''], Table of chords on pages 48–63.
* Glenn Elert [https://hypertextbook.com/eworld/chords/ Ptolemy's Table of Chords: Trigonometry in the Second Century]

[[Category:Trigonometry]]
[[Category:History of mathematics|Trigonometry]]
[[Category:History of astronomy]]
[[Category:Elementary special functions]]
[[Category:Ptolemy]]</text>
      <sha1>8p1qieekycszr8d48bkr13p8ojh1yp5</sha1>
    </revision>
  </page>
  <page>
    <title>QAMA Calculator</title>
    <ns>0</ns>
    <id>58209457</id>
    <revision>
      <id>871700124</id>
      <parentid>870623294</parentid>
      <timestamp>2018-12-02T21:56:28Z</timestamp>
      <contributor>
        <username>Katharineamy</username>
        <id>2590656</id>
      </contributor>
      <comment>added [[Category:Calculators]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1873">The '''QAMA Calculator''' is a [[calculator]] that requires users to provide a reasonable estimate of the answer before the precise answer is delivered.&lt;ref&gt;{{cite web|url=http://qamacalculator.com/|title=Introducing QAMA Calculator|website=qamacalculator.com}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.forbes.com/sites/alexknapp/2012/07/09/qama-the-calculator-that-makes-you-better-at-math/#32d3b4a16a91|title=QAMA: The Calculator That Makes You Better At Math|first=Alex|last=Knapp|publisher=}}&lt;/ref&gt; QAMA stands for Quick Approximate Mental Arithmetic.

Invented by Ilan Samson, it aims to get users to think first by estimating before they get the correct answer.&lt;ref&gt;{{Cite news|url=http://ideas.time.com/2012/11/29/how-to-use-technology-to-make-you-smarter/?iid=op-main-lead|title=How to Use Technology to Make You Smarter|last=Paul|first=Annie Murphy|work=Time|access-date=2018-08-23|language=en-US|issn=0040-781X}}&lt;/ref&gt; Estimation is seen by many as an essential part of mathematics, and some believe that the presence and popularity of calculators could inhibit the use of estimation skills.&lt;ref&gt;{{cite web|url=https://www.goodreads.com/quotes/846896-when-an-official-report-in-the-uk-was-commissioned-to|title=A quote from What's Math Got to Do with It?|website=www.goodreads.com}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://munews.missouri.edu/news-releases/2008/0528-reys-lifetime-award-release.php|title=Power of Estimation Takes Math Beyond Classroom - MU News Bureau|website=munews.missouri.edu}}&lt;/ref&gt;

A physical version of the calculator was released for sale in 2014, with apps for smartphones and tablets developed in 2016.

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}


{{computing-stub}}



[[Category:Calculators]]</text>
      <sha1>s3b117jz0soic3649j7ih35n1fopx16</sha1>
    </revision>
  </page>
  <page>
    <title>Simplicial presheaf</title>
    <ns>0</ns>
    <id>39611193</id>
    <revision>
      <id>846595270</id>
      <parentid>841927268</parentid>
      <timestamp>2018-06-19T18:55:36Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5669">In mathematics, more specifically in [[homotopy theory]], a '''simplicial presheaf''' is a [[presheaf]] on a [[Site (mathematics)|site]] (e.g., the [[Category theory|category]] of [[topological space]]s) taking values in [[simplicial set]]s (i.e., a [[contravariant functor]] from the site to the category of simplicial sets). Equivalently, a simplicial presheaf is a simplicial object in the category of presheaves on a site. The notion was introduced by A. Joyal in the 1970s.&lt;ref&gt;http://ncatlab.org/nlab/files/ToenStacksNAC.pdf&lt;/ref&gt; Similarly, a '''simplicial sheaf''' on a site is a [[simplicial object]] in the category of [[Sheaf (mathematics)|sheaves]] on the site.&lt;ref&gt;{{harvnb|Jardine|2007|loc=§1}}&lt;/ref&gt;

Example: Let us consider, say, the [[étale site]] of a scheme ''S''. Each ''U'' in the site represents the presheaf &lt;math&gt;\operatorname{Hom}(-, U)&lt;/math&gt;. Thus, a '''simplicial scheme''', a simplicial object in the site, represents a simplicial presheaf (in fact, often a simplicial sheaf).

Example: Let ''G'' be a presheaf of groupoids. Then taking [[nerve (category theory)|nerve]]s section-wise, one obtains a simplicial presheaf &lt;math&gt;BG&lt;/math&gt;. For example, one might set &lt;math&gt;B\operatorname{GL} = \varinjlim B\operatorname{GL_n}&lt;/math&gt;. These types of examples appear in K-theory.&lt;!--Example: Let a presheaf of groups ''G'' act on a presheaf ''X''; i.e., there are [[group actions]] &lt;math&gt;G(U) \times X(U) \to X(U)&lt;/math&gt; for each ''U'' in the site. One then obtains the category &lt;math&gt;EG&lt;/math&gt;--&gt;

If &lt;math&gt;f: X \to Y&lt;/math&gt; is a local weak equivalence of simplicial presheaves, then the induced map &lt;math&gt;\mathbb{Z} f: \mathbb{Z} X \to \mathbb{Z} Y&lt;/math&gt; is also a local weak equivalence.

== Homotopy sheaves of a simplicial presheaf ==
Let ''F'' be a simplicial presheaf on a site. The '''homotopy sheaves''' &lt;math&gt;\pi_* F&lt;/math&gt; of ''F'' is defined as follows. For any &lt;math&gt;f:X \to Y&lt;/math&gt; in the site and a 0-simplex ''s'' in ''F''(''X''), set &lt;math&gt;(\pi_0^\text{pr} F)(X) = \pi_0 (F(X))&lt;/math&gt; and &lt;math&gt;(\pi_i^\text{pr} (F, s))(f) = \pi_i (F(Y), f^*(s))&lt;/math&gt;. We then set &lt;math&gt;\pi_i F&lt;/math&gt; to be the sheaf associated with the pre-sheaf &lt;math&gt;\pi_i^\text{pr} F&lt;/math&gt;.&lt;!-- discuss hypercovering business --&gt;

== Model structures ==
The category of simplicial presheaves on a site admits many different [[model category|model structure]]s.&lt;!--A map of simplicial presheaves with "local right lifting property" is called a '''hypercover'''.&lt;ref&gt;{{harvnb|Jardine|2007|loc=§ 2}}&lt;/ref&gt; (see loc. cit. for the precise definition.)--&gt;

Some of them are obtained by viewing simplicial presheaves as functors 
:&lt;math&gt;S^{op} \to \Delta^{op} Sets&lt;/math&gt;
The category of such functors is endowed with (at least) three model structures, namely the projective, the Reedy, and the injective model structure. The weak equivalences / fibrations in the first are maps
:&lt;math&gt;\mathcal F \to \mathcal G&lt;/math&gt;
such that 
:&lt;math&gt;\mathcal F(U) \to \mathcal G(U)&lt;/math&gt;
is a weak equivalence / fibration of simplicial sets, for all ''U'' in the site ''S''. The injective model structure is similar, but with weak equivalences and cofibrations instead.

== Stack ==
{{main|Stack (mathematics)}}

A simplicial presheaf ''F'' on a site is called a stack if, for any ''X'' and any [[hypercovering]] ''H'' →''X'', the canonical map
:&lt;math&gt;F(X) \to \operatorname{holim} F(H_n)&lt;/math&gt;
is a [[weak equivalence (homotopy theory)|weak equivalence]] as simplicial sets, where the right is the [[homotopy limit]] of
:&lt;math&gt;[n] = \{ 0, 1, \dots, n \} \mapsto F(H_n)&lt;/math&gt;.

Any sheaf ''F'' on the site can be considered as a stack by viewing &lt;math&gt;F(X)&lt;/math&gt; as a constant simplicial set; this way, the category of sheaves on the site is included as a subcategory to the homotopy category of simplicial presheaves on the site. The inclusion functor has a left adjoint and that is exactly &lt;math&gt;F \mapsto \pi_0 F&lt;/math&gt;.

If ''A'' is a sheaf of abelian group (on the same site), then we define &lt;math&gt;K(A, 1)&lt;/math&gt; by doing classifying space construction levelwise (the notion comes from the [[obstruction theory]])  and set &lt;math&gt;K(A, i) = K(K(A, i-1), 1)&lt;/math&gt;. One can show (by induction): for any ''X'' in the site,
:&lt;math&gt;\operatorname{H}^i(X; A) = [X, K(A, i)]&lt;/math&gt;
where the left denotes a sheaf cohomology and the right the homotopy class of maps.&lt;!-- A semidirect product of &lt;math&gt;K(A, i)&lt;/math&gt;. ....    is called a ''i''-[[gerbe]] with coefficients in ''A''.--&gt;

== See also ==
*[[cubical set]]

== Notes ==
{{reflist}}

== Further reading ==
*Konrad Voelkel, [http://blog.konradvoelkel.de/2012/11/simplicial-presheaves-model/ Model structures on simplicial presheaves]

== References ==
* {{cite book | last=Jardine | first=J.F. | chapter=Generalised sheaf cohomology theories | pages=29–68 | editor1-last=Greenlees | editor1-first=J. P. C. | title=Axiomatic, enriched and motivic homotopy theory. Proceedings of the NATO Advanced Study Institute, Cambridge, UK, 9--20 September 2002 | location=Dordrecht | publisher=Kluwer Academic | series=NATO Science Series II: Mathematics, Physics and Chemistry | volume=131 | year=2004 | isbn=1-4020-1833-9 | zbl=1063.55004 }}
* {{cite web | first=J.F. | last=Jardine | year=2007 | url=http://www.math.uwo.ca/~jardine/papers/Fields-01.pdf | title=Simplicial presheaves }}
*B. Toën, [https://wayback.archive-it.org/all/20090625184038/http://www.math.univ-toulouse.fr/~toen/crm-2008.pdf Simplicial presheaves and derived algebraic geometry]

== External links ==
*[http://www.math.uwo.ca/~jardine/ J.F. Jardine's homepage]

[[Category:Homotopy theory]]
[[Category:Simplicial sets]]
[[Category:Functors]]</text>
      <sha1>51s3x7yzycp8rynuj7bed0fx1lz0rid</sha1>
    </revision>
  </page>
  <page>
    <title>Svetlana Gannushkina</title>
    <ns>0</ns>
    <id>26507256</id>
    <revision>
      <id>846944996</id>
      <parentid>844857818</parentid>
      <timestamp>2018-06-21T21:27:37Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v485)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3346">[[File:Reunión con Svetlana Gannúshkina.jpg|thumb|Svetlana Gannushkina in 2009]]
'''Svetlana Alekseevna Gannushkina''' ({{lang-ru|Светла́на Алексе́евна Га́ннушкина}}, born 6 March 1942) is a mathematician and [[human rights]] activist in [[Russia]] who was reported to have been a serious contender for the 2010 [[Nobel Peace Prize]].&lt;ref&gt;{{cite web |url=http://news.bbc.co.uk/2/hi/technology/8560469.stm |title=
Internet 'in running' for Nobel Peace Prize |author= |date=10 March 2010 |work= |publisher=[[BBC News]] |accessdate=19 January 2012}}&lt;/ref&gt;

==Biography==
Gannushkina worked for many years as a professor of mathematics at a [[Moscow]] university. In 1990, she helped to found the group Citizen’s Assistance (''Grazhdanskoe Sodeistvie''), an NGO which campaigns for human rights, particularly with regard to immigrants and refugees in Russian society.&lt;ref name="bbcG61016"/&gt; Since 2015 the organization is labelled a "[[Russian foreign agent law|foreign agent]]" by the [[Russian government]].&lt;ref name="bbcG61016"&gt;[https://www.bbc.com/news/world-37558076 The Nobel Peace Prize: Who will win this year?], [[BBC News]] (6 October 2016)&lt;/ref&gt;

Gannushkina is a member of the [[Presidential Council for Civil Society and Human Rights]].&lt;ref name=AI&gt;{{cite web |url=https://www.amnesty.org/en/news-and-updates/feature-stories/human-rights-defender-russia-svetlana-alekseevna-gannushkina-20081209 |title=Human Rights Defender in Russia: Svetlana Alekseevna Gannushkina |author= |date=9 December 2008 |work= |publisher=[[Amnesty International]] |accessdate=19 January 2012}}&lt;/ref&gt; She is also on the council of [[Memorial (society)|Memorial]], a society dedicated to the remembrance of victims of Soviet repression.

In 2006, she was awarded the [[Homo Homini Award]] for human rights activism by the Czech group [[People in Need (Czech Republic)|People in Need]].&lt;ref&gt;{{cite web|url=http://www.clovekvtisni.cz/index2en.php?id=549|title=Previous Recipients of the Homo Homini Award|author=|date=|work=|publisher=[[People In Need (Czech Republic)|People in Need]]|accessdate=17 April 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20110501192644/http://www.clovekvtisni.cz/index2en.php?id=549|archivedate=1 May 2011|df=}}&lt;/ref&gt;

In 2016, Gannushkina received the [[Right Livelihood Award]], often referred to as "Alternative Nobel Prize", Stockholm, Sweden, "''for her decades-long commitment to promoting human rights and justice for refugees and forced migrants, and tolerance among different ethnic groups"''&lt;ref&gt;{{Cite web|url=http://www.rightlivelihoodaward.org/laureates/svetlana-gannushkina/|title=Svetlana Gannushkina {{!}} The Right Livelihood Award|website=www.rightlivelihoodaward.org|language=en-US|access-date=2018-05-14}}&lt;/ref&gt;

==See also==
*[[Human rights in Russia]]

==References==
{{reflist}}

{{Footer Homo Homini Award laureates}}
{{Andrei Sakharov Freedom Award}}
{{Authority control}}

{{DEFAULTSORT:Gannushkina, Svetlana}}
[[Category:1942 births]]
[[Category:Living people]]
[[Category:Moscow State University faculty]]
[[Category:Memorial (society)]]
[[Category:Soviet mathematicians]]
[[Category:Women mathematicians]]
[[Category:Russian human rights activists]]
[[Category:Right Livelihood Award laureates]]

{{Russia-bio-stub}}
[[Category:Women human rights defenders]]</text>
      <sha1>mnuvu2jlrzzcqjl4brljfu5pqxbfznv</sha1>
    </revision>
  </page>
  <page>
    <title>Tree automaton</title>
    <ns>0</ns>
    <id>98748</id>
    <revision>
      <id>833822424</id>
      <parentid>804856834</parentid>
      <timestamp>2018-04-02T16:03:11Z</timestamp>
      <contributor>
        <username>A3nm</username>
        <id>2049718</id>
      </contributor>
      <comment>/* See also */ +* [[Alternating tree automata]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24747">{{for|a different notion of tree automaton|tree walking automaton}}

A '''tree automaton''' is a type of [[state machine]]. Tree automata deal with [[tree structure]]s, rather than the [[string (computer science)|strings]] of more conventional state machines.

The following article deals with branching tree automata, which correspond to [[regular tree language|regular languages of trees]].

As with classical automata, finite tree automata (FTA) can be either a [[deterministic automaton]] or not. According to how the automaton processes the input tree, finite tree automata can be of two types: (a) bottom up, (b) top down. This is an important issue, as although non-deterministic (ND) top-down and ND bottom-up tree automata are equivalent in expressive power, deterministic top-down automata are strictly less powerful than their deterministic bottom-up counterparts, because tree properties specified by deterministic top-down tree automata can only depend on path properties. (Deterministic bottom-up tree automata are as powerful as ND tree automata.)

== Definitions ==

A '''bottom-up finite tree automaton''' over ''F'' is defined as a tuple
(''Q'', ''F'', ''Q''&lt;sub&gt;''f''&lt;/sub&gt;, Δ),
where ''Q'' is a set of states, ''F'' is a [[ranked alphabet]] (i.e., an alphabet whose symbols have an associated [[arity]]), ''Q''&lt;sub&gt;''f''&lt;/sub&gt; ⊆ ''Q'' is a set of final states, and Δ is a set of [[Production (computer science)|transition rules]] of the form ''f''(''q''&lt;sub&gt;1&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;),...,''q''&lt;sub&gt;''n''&lt;/sub&gt;(''x''&lt;sub&gt;''n''&lt;/sub&gt;)) → ''q''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;,...,''x''&lt;sub&gt;''n''&lt;/sub&gt;)), for an ''n''-ary ''f'' ∈ ''F'', ''q'', ''q''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''Q'', and ''x''&lt;sub&gt;''i''&lt;/sub&gt; variables denoting subtrees. That is, members of Δ are rewrite rules from nodes whose childs' roots are states, to nodes whose roots are states. Thus the state of a node is deduced from the states of its children.

For ''n''=0, that is, for a constant symbol ''f'', the above transition rule definition reads ''f''() → ''q''(''f''()); often the empty parentheses are omitted for convenience: ''f'' → ''q''(''f'').
Since these transition rules for constant symbols (leaves) do not require a state, no explicitly defined initial states are needed.
A bottom-up tree automaton is run on a [[ground term]] over ''F'', starting at all its leaves simultaneously and moving upwards, associating a run state from ''Q'' with each subterm.
The term is accepted if its root is associated to an accepting state from ''Q''&lt;sub&gt;''f''&lt;/sub&gt;.{{sfn|Comon et al.|2008|loc=sect. 1.1, p. 20}}

A '''top-down finite tree automaton''' over ''F'' is defined as a tuple
(''Q'', ''F'', ''Q''&lt;sub&gt;''i''&lt;/sub&gt;, Δ),
with two differences with bottom-up tree automata. First, ''Q''&lt;sub&gt;''i''&lt;/sub&gt; ⊆ ''Q'', the set of its initial states, replaces ''Q''&lt;sub&gt;''f''&lt;/sub&gt;; second, its transition rules are oriented conversely:
''q''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;,...,''x''&lt;sub&gt;''n''&lt;/sub&gt;))  → ''f''(''q''&lt;sub&gt;1&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;),...,''q''&lt;sub&gt;''n''&lt;/sub&gt;(''x''&lt;sub&gt;''n''&lt;/sub&gt;)), for an ''n''-ary ''f'' ∈ ''F'', ''q'', ''q''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''Q'', and ''x''&lt;sub&gt;''i''&lt;/sub&gt; variables denoting subtrees.
That is, members of Δ are here rewrite rules from nodes whose roots are states to nodes whose childs' roots are states.
A top-down automaton starts in some of its initial states at the root and moves downward along branches of the tree, associating along a run a state with each subterm inductively.
A tree is accepted if every branch can be gone through this way.{{sfn|Comon et al.|2008|loc=sect. 1.6, p. 38}}

A tree automaton is called '''deterministic''' (abbreviated '''DFTA''') if no two rules from Δ have the same left hand side; otherwise it is called '''nondeterministic''' ('''NFTA''').{{sfn|Comon et al.|2008|loc=sect. 1.1, p. 23}} Non-deterministic top-down tree automata have the same expressive power as non-deterministic bottom-up ones;{{sfn|Comon et al.|2008|loc=sect. 1.6, theorem 1.6.1, p. 38}} the transition rules are simply reversed, and the final states become the initial states.

In contrast, '''deterministic''' top-down tree automata&lt;ref&gt;In a strict sense, deterministic top-down automata are not defined by {{harvp|Comon et al.|2008}} but they are used there (sect. 1.6, proposition 1.6.2, p. 38). They accept the class of path-closed tree languages (sect. 1.8, exercise 1.6, p. 43-44).&lt;/ref&gt; are less powerful than their bottom-up counterparts, because in a deterministic tree automaton no two transition rules have the same left-hand side. For tree automata, transition rules are rewrite rules; and for top-down ones, the left-hand side will be parent nodes. Consequently, a deterministic top-down tree automaton will only be able to test for tree properties that are true in all branches, because the choice of the state to write into each child branch is determined at the parent node, without knowing the child branches contents.

== Examples ==

===Bottom-up automaton accepting boolean lists===
Employing coloring to distinguish members of ''F'' and ''Q'', and using the ranked alphabet ''F''={ {{color|#800000|''false''}},{{color|#800000|''true''}},{{color|#800000|''nil''}},{{color|#800000|''cons''}}(.,.) }, with {{color|#800000|''cons''}} having arity 2 and all other symbols having arity 0, a bottom-up tree automaton accepting the set of all finite lists of boolean values can be defined as (''Q'', ''F'', ''Q''&lt;sub&gt;''f''&lt;/sub&gt;, Δ) with {{nowrap|1=''Q''={ {{color|#008000|''Bool''}},{{color|#008000|''BList''}} } }}, ''Q''&lt;sub&gt;''f''&lt;/sub&gt;={ {{color|#008000|''BList''}} }, and Δ consisting of the rules

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{|
|-
| {{color|#800000|''false''}} || → || {{color|#008000|''Bool''}}({{color|#800000|''false''}}) || (1),
|-
| {{color|#800000|''true''}} || → || {{color|#008000|''Bool''}}({{color|#800000|''true''}}) || (2),
|-
| {{color|#800000|''nil''}} || → || {{color|#008000|''BList''}}({{color|#800000|''nil''}}) || (3), and
|-
| {{color|#800000|''cons''}}({{color|#008000|''Bool''}}(x&lt;sub&gt;1&lt;/sub&gt;),{{color|#008000|''BList''}}(x&lt;sub&gt;2&lt;/sub&gt;)) || → || {{color|#008000|''BList''}}({{color|#800000|''cons''}}(x&lt;sub&gt;1&lt;/sub&gt;,x&lt;sub&gt;2&lt;/sub&gt;)) &amp;nbsp; &amp;nbsp; &amp;nbsp; || (4).
|}

In this example, the rules can be understood intuitively as assigning to each term its type in a bottom-up manner; e.g. rule (4) can be read as "A term {{color|#800000|''cons''}}(''x''&lt;sub&gt;1&lt;/sub&gt;,''x''&lt;sub&gt;2&lt;/sub&gt;) has type {{color|#008000|''BList''}}, provided ''x''&lt;sub&gt;1&lt;/sub&gt; and ''x''&lt;sub&gt;2&lt;/sub&gt; has type {{color|#008000|''Bool''}} and {{color|#008000|''BList''}}, respectively".
An accepting example run is

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{|
|-
|
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''true''}},
| ALIGN=RIGHT | {{color|#800000|''nil''}}
| ))
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''true''}},
| ALIGN=RIGHT | {{color|#008000|''BList''}}({{color|#800000|''nil''}})
| ))
| by (3)
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#008000|''Bool''}}({{color|#800000|''true''}}),
| ALIGN=RIGHT | {{color|#008000|''BList''}}({{color|#800000|''nil''}})
| ))
| by (2)
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#008000|''BList''}}({{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''true''}},
| ALIGN=RIGHT | {{color|#800000|''nil''}}
| )))
| by (4)
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#008000|''Bool''}}({{color|#800000|''false''}}),
| ALIGN=RIGHT | {{color|#008000|''BList''}}({{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''true''}},
| ALIGN=RIGHT | {{color|#800000|''nil''}}
| )))
| by (1)
|-
| ⇒
| ALIGN=RIGHT | {{color|#008000|''BList''}}({{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''true''}},
| ALIGN=RIGHT | {{color|#800000|''nil''}}
| ))) &amp;nbsp; &amp;nbsp; &amp;nbsp;
| by (4), accepted.
|}

Cf. the derivation of the same term from a regular tree grammar corresponding to the automaton, shown at [[Regular tree grammar#Examples]].

An rejecting example run is

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{|
|-
|
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#800000|''true''}}
| )
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#800000|''false''}},
| ALIGN=RIGHT | {{color|#008000|''Bool''}}({{color|#800000|''true''}})
| )
| by (1)
|-
| ⇒
| ALIGN=RIGHT | {{color|#800000|''cons''}}(
| ALIGN=RIGHT | {{color|#008000|''Bool''}}({{color|#800000|''false''}}),
| ALIGN=RIGHT | {{color|#008000|''Bool''}}({{color|#800000|''true''}})
| ) &amp;nbsp; &amp;nbsp; &amp;nbsp;
| by (2), no further rule applicable.
|}
Intuivitvely, this corresponds to the term {{color|#800000|''cons''}}({{color|#800000|''false''}},{{color|#800000|''true''}}) not being well-typed.

===Top-down automaton accepting multiples of 3 in binary notation===

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{| class=wikitable style="float:right;"
|-
!
! ALIGN=center | '''(A)'''
! ALIGN=center | '''(B)'''
! ALIGN=center | '''(C)'''
! ALIGN=center | '''(D)'''
|-
!
! ALIGN=center | [[Regular grammar#Strictly regular grammars|'''String'''&lt;BR&gt;'''grammar''']]&lt;BR&gt;'''rules'''
! ALIGN=center | [[Deterministic finite automaton#Formal definition|'''String'''&lt;BR&gt;'''automaton''']]&lt;BR&gt;'''transitions'''
! ALIGN=center | '''Tree'''&lt;BR&gt;'''automaton'''&lt;BR&gt;'''transitions'''
! ALIGN=center | [[Regular tree grammar#Definition|'''Tree'''&lt;BR&gt;'''grammar''']]&lt;BR&gt;'''rules'''
|-
| &lt;!---line numbers---&gt;
{|
|-
! 0
|-
! 1
|-
! 2
|-
! 3
|-
! 4
|-
! 5
|-
! 6
|}
| &lt;!---string grammar---&gt;
{| 
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || ε
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || {{color|#800000|0}} {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || {{color|#800000|1}} {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}} || → || {{color|#800000|0}} {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}} || → || {{color|#800000|1}} {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}
|- 
| {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} || → || {{color|#800000|0}} {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}
|- 
| {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} || → || {{color|#800000|1}} {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}
|}
| &lt;!---string automaton---&gt;
{| 
|- 
| &amp;nbsp;
|- 
| δ({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}},{{color|#800000|0}}) || = {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}
|- 
| δ({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}},{{color|#800000|1}}) || = {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}
|- 
| δ({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}},{{color|#800000|0}}) || = {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}
|- 
| δ({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}},{{color|#800000|1}}) || = {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}
|- 
| δ({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}},{{color|#800000|0}}) || = {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}
|- 
| δ({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}},{{color|#800000|1}}) || = {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}
|}
| &lt;!--- tree automaton---&gt;
{|
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}({{color|#800000|''nil''}}) || → || {{color|#800000|''nil''}}
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}({{color|#800000|0}}(x)) || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}(x))
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}({{color|#800000|1}}(x)) || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}(x))
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}({{color|#800000|0}}(x)) || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}(x))
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}({{color|#800000|1}}(x)) || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}(x))
|- 
| ''{{color|#008000|S''&lt;sub&gt;2&lt;/sub&gt;}}({{color|#800000|0}}(x)) || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}(x))
|- 
| {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}({{color|#800000|1}}(x)) || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}(x))
|}
| &lt;!--- tree grammar---&gt;
{|
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || {{color|#800000|''nil''}}
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}})
|- 
| {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}})
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}} || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}})
|- 
| {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}} || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}})
|- 
| {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} || → || {{color|#800000|0}}({{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}})
|- 
| {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} || → || {{color|#800000|1}}({{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}})
|}
|}

{| style="float:right;"
| [[File:DFA example multiplies of 3.svg|thumb|[[Deterministic finite automaton|Deterministic finite (string) automaton]] accepting multiples of 3 in binary notation]]
|}

Using the same colorization as above, this example shows how tree automata generalize ordinary string automata.
The finite deterministic string automaton shown in the picture accepts all strings of binary digits that denote a multiple of 3.
Using the notions from [[Deterministic finite automaton#Formal definition]], it is defined by:
* the set ''Q'' of states being { {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}, {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}, {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} },
* the input alphabet being { {{color|#800000|0}}, {{color|#800000|1}} },
* the initial state being {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}},
* the set of final states being { {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} }, and
* the transitions being as shown in column (B) of the table.

In the tree automaton setting, the input alphabet is changed such that the symbols {{color|#800000|0}} and {{color|#800000|1}} are both unary, and a nullary symbol, say {{color|#800000|''nil''}} is used for tree leaves.
For example, the binary string "{{color|#800000|110}}" in the string automaton setting corresponds to the term "{{color|#800000|1}}({{color|#800000|1}}({{color|#800000|0}}({{color|#800000|''nil''}})))" in the tree automaton setting; this way, strings can be generalized to trees, or terms.
The top-down finite tree automaton accepting the set of all terms corresponding to multiples of 3 in binary string notation is then defined by:
* the set ''Q'' of states being still { {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}, {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}, {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}} },
* the ranked input alphabet being { {{color|#800000|0}}, {{color|#800000|1}}, {{color|#800000|''nil''}} }, with ''Arity''({{color|#800000|0}})=''Arity''({{color|#800000|1}})=1 and ''Arity''({{color|#800000|''nil''}})=0, as explained,
* the set of initial states being { {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} }, and
* the transitions being as shown in column (C) of the table.
For example, the tree "{{color|#800000|1}}({{color|#800000|1}}({{color|#800000|0}}({{color|#800000|''nil''}})))" is accepted by the following tree automaton run:

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{|
|-
|    || {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}( || {{color|#800000|1}}( ||  || {{color|#800000|1}}( || ||  {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || ))))
|- 
| ⇒  || || {{color|#800000|1}}( || {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}( || {{color|#800000|1}}( ||  || {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || )))) || by 2
|- 
| ⇒  || || {{color|#800000|1}}( ||  || {{color|#800000|1}}( || {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}( || {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || )))) || by 4
|- 
| ⇒  || || {{color|#800000|1}}( ||  || {{color|#800000|1}}( ||  || {{color|#800000|0}}( || {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}( || {{color|#800000|''nil''}} || )))) || by 1
|- 
| ⇒  || || {{color|#800000|1}}( ||  || {{color|#800000|1}}(  ||  || {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || ))) &amp;nbsp; &amp;nbsp; &amp;nbsp; || by 0
|}

In contrast, the term "{{color|#800000|1}}({{color|#800000|0}}({{color|#800000|''nil''}}))" leads to following non-accepting automaton run:

&lt;!-- -tabular alignment chosen intentionally - please don't change without understanding the example or without proper reason- --&gt;
{|
|- 
| ⇒  {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}}( || {{color|#800000|1}}( ||  || {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || )))
|- 
| ⇒  || {{color|#800000|1}}( || {{color|#008000|''S''&lt;sub&gt;1&lt;/sub&gt;}}( || {{color|#800000|0}}( ||  || {{color|#800000|''nil''}} || )))) || by 2
|- 
| ⇒   || {{color|#800000|1}}( ||  || {{color|#800000|0}}( || {{color|#008000|''S''&lt;sub&gt;2&lt;/sub&gt;}}( || {{color|#800000|''nil''}} || )))) &amp;nbsp; &amp;nbsp; &amp;nbsp; || by 3, no further rule applicable
|}

Since there are no other initial states than {{color|#008000|''S''&lt;sub&gt;0&lt;/sub&gt;}} to start an automaton run with, the term "{{color|#800000|1}}({{color|#800000|0}}({{color|#800000|''nil''}}))" is not accepted by the tree automaton.

For comparison purposes, the table gives in column (A) and (D) a [[regular grammar#Strictly regular grammars|(right) regular (string) grammar]], and a [[regular tree grammar#Definition|regular tree grammar]], respectively, each accepting the same language as its automaton counterpart.

== Properties ==

=== Recognizability ===

For a bottom-up automaton, a ground term ''t'' (that is, a tree) is accepted if there exists a reduction that starts from ''t'' and ends with ''q''(''t''), where ''q'' is a final state. For a top-down automaton, a ground term ''t'' is accepted if there exists a reduction that starts from ''q''(''t'') and ends with ''t'', where ''q'' is an initial state.

The tree language ''L''(''A'') '''accepted''', or '''recognized''', by a tree automaton ''A'' is the set of all ground terms accepted by ''A''. A set of ground terms is '''recognizable''' if there exists a tree automaton that accepts it.

A linear (that is, arity-preserving) [[tree homomorphism]] preserves recognizability.&lt;ref&gt;The notion in {{harvtxt|Comon et al.|2008|loc=sect. 1.4, theorem 1.4.3, p. 31-32}} of tree homomorphism is more general than that of the article "[[tree homomorphism]]".&lt;/ref&gt;

=== Completeness and reduction ===

A non-deterministic finite tree automaton is '''complete''' if there is at least one transition rule available for every possible symbol-states combination.
A state ''q'' is '''accessible''' if there exists a ground term ''t'' such that there exists a reduction from ''t'' to ''q''(''t'').
An NFTA is '''reduced''' if all its states are accessible.{{sfn|Comon et al.|2008|loc=sect. 1.1, p. 23-24}}

=== Pumping lemma ===

Every sufficiently large&lt;ref&gt;Formally: ''[[Term (logic)#Operations with terms|height]]''(''t'') &gt; ''k'', with ''k'' &gt; 0 depending only on ''L'', not on ''t''&lt;/ref&gt; ground term ''t'' in a recognizable tree language ''L'' can be vertically tripartited&lt;ref&gt;Formally: there is a context ''C''[.], a nontrivial context ''C''’[.], and a ground term ''u'' such that ''t'' = ''C''[''C''’[''u'']]. A "context" ''C''[.] is a tree with one hole (or, correspondingly, a term with one occurrence of one variable). A context is called "trivial" if the tree consists only of the hole node (or, correspondingly, if the term is just the variable). The notation ''C''[''t''] means the result of inserting the tree ''t'' into the hole of ''C''[.] (or, correspondingly, [[Ground instance|instantiating]] the variable to ''t''). {{harvnb|Comon et al.|2008|p=17}}, gives a formal definition.&lt;/ref&gt; such that arbitrary repetition ("pumping") of the middle part keeps the resulting term in ''L''.&lt;ref&gt;Formally: ''C''[''C''’&lt;sup&gt;''n''&lt;/sup&gt;[''u'']] ∈ ''L'' for all ''n'' ≥ 0. The notation ''C''&lt;sup&gt;''n''&lt;/sup&gt;[.] means the result of stacking ''n'' copies of ''C''[.] one in another, cf. {{harvnb|Comon et al.|2008|p=17}}.&lt;/ref&gt;{{sfn|Comon et al.|2008|loc=sect. 1.2, p. 29}}

For the language of all finite lists of boolean values from the above example, all terms beyond the height limit ''k''=2 can be pumped, since they need to contain an occurrence of {{color|#800000|''cons''}}. For example,

{|
|-
| {{color|#800000|''cons''}}({{color|#800000|''false''}},
| {{color|#800000|''cons''}}({{color|#800000|''true''}},{{color|#800000|''nil''}})
| )
| ,
|-
| {{color|#800000|''cons''}}({{color|#800000|''false''}},{{color|#800000|''cons''}}({{color|#800000|''false''}},
| {{color|#800000|''cons''}}({{color|#800000|''true''}},{{color|#800000|''nil''}})
| ))
| ,
|-
| {{color|#800000|''cons''}}({{color|#800000|''false''}},{{color|#800000|''cons''}}({{color|#800000|''false''}},{{color|#800000|''cons''}}({{color|#800000|''false''}},
| {{color|#800000|''cons''}}({{color|#800000|''true''}},{{color|#800000|''nil''}})
| )))
| , ...
|}

all belong to that language.

=== Closure ===

The class of recognizable tree languages is closed under union, under complementation, and under intersection.{{sfn|Comon et al.|2008|loc=sect. 1.3, theorem 1.3.1, p. 30}}

=== Myhill–Nerode theorem ===

A congruence on the set of all trees over a ranked alphabet ''F'' is an [[equivalence relation]] such that ''u''&lt;sub&gt;1&lt;/sub&gt; ≡ ''v''&lt;sub&gt;1&lt;/sub&gt; and ... and ''u''&lt;sub&gt;''n''&lt;/sub&gt; ≡ ''v''&lt;sub&gt;''n''&lt;/sub&gt; implies ''f''(''u''&lt;sub&gt;1&lt;/sub&gt;,...,''u''&lt;sub&gt;''n''&lt;/sub&gt;) ≡ ''f''(''v''&lt;sub&gt;1&lt;/sub&gt;,...,''v''&lt;sub&gt;''n''&lt;/sub&gt;), for every ''f'' ∈ ''F''.
It is of finite index if its number of equivalence-classes is finite.

For a given tree-language ''L'', a congruence can be defined by ''u'' ≡&lt;sub&gt;''L''&lt;/sub&gt; ''v'' if  ''C''[''u''] ∈ ''L'' ⇔ ''C''[''v''] ∈ ''L'' for each context ''C''.

The [[Myhill–Nerode theorem]] for tree automaton states that the following three statements are equivalent:{{sfn|Comon et al.|2008|loc=sect. 1.5, p .36}}

# ''L'' is a recognizable tree language
# ''L'' is the union of some equivalence classes of a congruence of finite index
# the relation ≡&lt;sub&gt;''L''&lt;/sub&gt; is a congruence of finite index

== See also ==

* [[Courcelle's theorem]] - an application of tree automata to prove an algorithmic meta-theorem about graphs
* [[Tree transducers]] - extend tree automata in the same way that [[finite-state transducer|word transducer]]s extend [[finite-state automata|word automata]].
* [[Alternating tree automata]]

== Notes ==

{{reflist}}

== References ==

* {{cite book| first1=Hubert| last1=Comon| first2=Max| last2=Dauchet| first3=Rémi| last3=Gilleron| first4=Florent| last4=Jacquemard| first5=Denis| last5=Lugiez| first6=Christof| last6=Löding| first7=Sophie| last7=Tison| first8=Marc| last8=Tommasi| title=Tree Automata Techniques and Applications|date=November 2008| url=https://gforge.inria.fr/frs/download.php/10994/tata.pdf| accessdate=11 February 2014| ref={{harvid|Comon et al.|2008}}}}
* {{Cite book| publisher = Cambridge University Press| isbn = 978-1-139-49236-2| last = Hosoya| first = Haruo| title = Foundations of XML Processing: The Tree-Automata Approach| date =4 November 2010| ref = harv}}

== External links ==

=== Implementations ===

* [http://www.grappa.univ-lille3.fr/~filiot/tata/ Grappa] - ranked and unranked tree automata libraries (OCaml)
* [https://people.irisa.fr/Thomas.Genet/timbuk Timbuk] - tools for reachability analysis and tree automata calculations (OCaml)
* [http://lethal.sourceforge.net/ LETHAL] - library for working with finite tree and hedge automata (Java)
* [http://afp.sourceforge.net/entries/Tree-Automata.shtml Machine-checked tree automata library] (Isabelle [OCaml, SML, Haskell])
* [http://www.fit.vutbr.cz/research/groups/verifit/tools/libvata/ VATA] - a library for efficient manipulation of non-deterministic tree automata (C++)

{{Formal languages and grammars}}

[[Category:Trees (data structures)]]
[[Category:Automata (computation)]]
[[Category:Formal languages]]
[[Category:Theoretical computer science]]</text>
      <sha1>7x83o1s4h8qjd5m334ti0qealh2h6q4</sha1>
    </revision>
  </page>
  <page>
    <title>Unit sphere</title>
    <ns>0</ns>
    <id>27033090</id>
    <revision>
      <id>847028298</id>
      <parentid>801058988</parentid>
      <timestamp>2018-06-22T12:14:26Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* General area and volume formulas */ surface [meaning hypersurface] → boundary (far more precise without clumsiness)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10495">{{refimprove|date=March 2010}}
[[File:Vector norms.svg|frame|right|Some 1-spheres. &lt;math&gt;\|\boldsymbol{x}\|_2&lt;/math&gt; is the norm for Euclidean space discussed in the first section below.]]
In [[mathematics]], a '''unit [[sphere]]''' is the set of points of [[distance]] 1 from a fixed central point, where a generalized concept of distance may be used; a closed '''unit [[ball (mathematics)|ball]]''' is the set of points of [[distance]] less than or equal to 1 from a fixed central point. Usually a specific point has been distinguished as the [[origin (mathematics)|origin]] of the space under study and it is understood that a unit sphere or unit ball is centered at that point.  Therefore one speaks of "the" unit ball or "the" unit sphere.

For example, a one-dimensional sphere is the surface of what is commonly called a "circle", while such a circle's interior and surface together are the two-dimensional ball.  Similarly, a two-dimensional sphere is the surface of the Euclidean solid known colloquially as a "sphere", while the interior and surface together are the three-dimensional ball.

A unit sphere is simply a [[sphere]] of [[radius]] one.  The importance of the unit sphere is that any sphere can be transformed to a unit sphere by a combination of [[translation (geometry)|translation]] and [[scaling (geometry)|scaling]].  In this way the properties of spheres in general can be reduced to the study of the unit sphere.

==Unit spheres and balls in Euclidean space==

In [[Euclidean space]] of ''n'' dimensions, the {{math|(''n''−1)}}-dimensional unit sphere is the set of all points &lt;math&gt;(x_1, \ldots, x_n)&lt;/math&gt; which satisfy the equation

:&lt;math&gt; x_1^2 + x_2^2 + \cdots + x_n ^2 = 1.&lt;/math&gt;

The ''n''-dimensional open unit ball is the set of all points satisfying the [[inequality (mathematics)|inequality]]

:&lt;math&gt; x_1^2 + x_2^2 + \cdots + x_n ^2 &lt; 1,&lt;/math&gt;

and the ''n''-dimensional closed unit ball is the set of all points satisfying the [[inequality (mathematics)|inequality]]

:&lt;math&gt; x_1^2 + x_2^2 + \cdots + x_n ^2 \le 1.&lt;/math&gt;

===General area and volume formulas===

The classical equation of a unit sphere is that of the ellipsoid with a radius of 1 and no alterations to the ''x''-, ''y''-, or ''z''- axes:
:&lt;math&gt;f(x,y,z) =  x^2 + y^2 + z^2 = 1&lt;/math&gt;

The volume of the unit ball in ''n''-dimensional Euclidean space, and the surface area of the unit sphere, appear in many important formulas of [[mathematical analysis|analysis]].  The volume of the unit ball in ''n'' dimensions, which we denote ''V''&lt;sub&gt;''n''&lt;/sub&gt;, can be expressed by making use of the [[gamma function]].  It is

:&lt;math&gt;V_n = \frac{\pi ^ {n/2}}{\Gamma(1+n/2)} = \begin{cases}
{\pi^{n/2}}/{(n/2)!} &amp; \mathrm{if~}n \ge 0\mathrm{~is~even,} \\
~\\
{\pi^{\lfloor n/2 \rfloor}2^{\lceil n/2 \rceil}}/{n!!} &amp; \mathrm{if~}n \ge 0\mathrm{~is~odd,}
\end{cases} &lt;/math&gt;

where ''n''&lt;nowiki&gt;!!&lt;/nowiki&gt; is the [[double factorial]].

The hypervolume of the (''n''&amp;minus;1)-dimensional unit sphere (''i.e.'', the "area" of the boundary of the ''n''-dimensional unit ball), which we denote ''A''&lt;sub&gt;''n''&lt;/sub&gt;, can be expressed as

:&lt;math&gt;A_n = n V_n = \frac{n \pi ^ {n/2}}{\Gamma(1+n/2)} = \frac{2 \pi ^ {n/2}}{\Gamma(n/2)}\,,&lt;/math&gt;
where the last equality holds only for {{nowrap|''n'' &gt; 0}}.

The surface areas and the volumes for some values of &lt;math&gt;n&lt;/math&gt; are as follows:

{| class="wikitable" style="text-align:center"
! &lt;math&gt;n&lt;/math&gt;
! colspan=2|&lt;math&gt;A_n&lt;/math&gt; (surface area)
! colspan=2|&lt;math&gt;V_n&lt;/math&gt; (volume)
|-
! 0
| &lt;math&gt;0(1/0!)\pi^0 &lt;/math&gt; || 0 || &lt;math&gt;(1/0!)\pi^0 &lt;/math&gt; || 1 
|-
! 1
| &lt;math&gt;1(2^1/1!!)\pi^0 &lt;/math&gt; || 2 || &lt;math&gt;(2^1/1!!)\pi^0 &lt;/math&gt; || 2 
|-
! 2
| &lt;math&gt;2(1/1!)\pi^1 = 2 \pi &lt;/math&gt; || 6.283 || &lt;math&gt;(1/1!)\pi^1 = \pi &lt;/math&gt; || 3.141 
|-
! 3
| &lt;math&gt;3(2^2/3!!)\pi^1  = 4 \pi &lt;/math&gt; || 12.57 || &lt;math&gt;(2^2/3!!)\pi^1  = (4/3)\pi &lt;/math&gt; || 4.189 
|-
! 4
| &lt;math&gt;4(1/2!)\pi^2 = 2 \pi^2 &lt;/math&gt; || 19.74 || &lt;math&gt;(1/2!)\pi^2 = (1/2)\pi^2 &lt;/math&gt; || 4.935 
|-
! 5
| &lt;math&gt;5(2^3/5!!)\pi^2 = (8/3)\pi^2 &lt;/math&gt; || 26.32 || &lt;math&gt;(2^3/5!!)\pi^2 = (8/15)\pi^2 &lt;/math&gt; || 5.264 
|-
! 6
| &lt;math&gt;6(1/3!)\pi^3 = \pi^3 &lt;/math&gt; || 31.01 || &lt;math&gt;(1/3!)\pi^3 = (1/6)\pi^3 &lt;/math&gt; || 5.168 
|-
! 7
| &lt;math&gt;7(2^4/7!!) \pi^3 = (16/15)\pi^3 &lt;/math&gt; || 33.07 || &lt;math&gt;(2^4/7!!) \pi^3 = (16/105)\pi^3 &lt;/math&gt; || 4.725 
|-
! 8
| &lt;math&gt;8(1/4!)\pi^4 = (1/3)\pi^4 &lt;/math&gt; || 32.47 || &lt;math&gt;(1/4!)\pi^4 = (1/24)\pi^4 &lt;/math&gt; || 4.059 
|-
! 9
| &lt;math&gt;9(2^5/9!!) \pi^4 = (32/105)\pi^4 &lt;/math&gt; || 29.69 || &lt;math&gt;(2^5/9!!) \pi^4 = (32/945)\pi^4 &lt;/math&gt; || 3.299 
|-
! 10
| &lt;math&gt;10(1/5!)\pi^5 = (1/12)\pi^5 &lt;/math&gt; || 25.50 || &lt;math&gt;(1/5!)\pi^5 = (1/120)\pi^5 &lt;/math&gt; || 2.550 
|}
where the decimal expanded values for ''n''&amp;nbsp;≥&amp;nbsp;2 are rounded to the displayed precision.

====Recursion====

The ''A''&lt;sub&gt;''n''&lt;/sub&gt; values satisfy the recursion:

:&lt;math&gt;A_0 = 0&lt;/math&gt;
:&lt;math&gt;A_1 = 2&lt;/math&gt;
:&lt;math&gt;A_2 = 2\pi&lt;/math&gt;
:&lt;math&gt;A_n = \frac{2 \pi}{n-2} A_{n-2}&lt;/math&gt; for &lt;math&gt;n &gt; 2&lt;/math&gt;.

The ''V''&lt;sub&gt;''n''&lt;/sub&gt; values satisfy the recursion:

:&lt;math&gt;V_0 = 1&lt;/math&gt;
:&lt;math&gt;V_1 = 2&lt;/math&gt;
:&lt;math&gt;V_n = \frac{2 \pi}{n} V_{n-2}&lt;/math&gt; for &lt;math&gt;n &gt; 1&lt;/math&gt;.

====Fractional dimensions====
{{Main|Hausdorff measure}}

The formulae for ''A''&lt;sub&gt;''n''&lt;/sub&gt; and ''V''&lt;sub&gt;''n''&lt;/sub&gt; can be computed for any real number ''n''&amp;nbsp;≥&amp;nbsp;0, and there are circumstances under which it is appropriate to seek the sphere area or ball volume when ''n'' is not a non-negative integer.

[[File:Sphere area in n dimensions.svg|right|thumb|200px|This shows the hypervolume of an (''x''&amp;ndash;1)-dimensional sphere (''i.e.'', the "area" of the surface of the ''x''-dimensional unit ball) as a continuous function of&amp;nbsp;''x''.]]
[[File:Ball volume in n dimensions.svg|none|thumb|200px|This shows the volume of a ball in ''x'' dimensions as a continuous function of&amp;nbsp;''x''.]]

====Other radii====
{{Main|Sphere}}

The surface area of an (''n''&amp;ndash;1)-dimensional sphere with radius ''r'' is ''A''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;''r''&lt;sup&gt;''n''&amp;minus;1&lt;/sup&gt; and the volume of an ''n''-dimensional ball with radius ''r'' is ''V''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;''r''&lt;sup&gt;''n''&lt;/sup&gt;.  For instance, the area is {{nowrap|''A'' {{=}} 4''&amp;pi;''&amp;thinsp;''r''&lt;sup&gt;&amp;thinsp;2&lt;/sup&gt;}} for the surface of the three-dimensional ball of radius ''r''.  The volume is {{nowrap|''V'' {{=}} 4''&amp;pi;''&amp;thinsp;''r''&lt;sup&gt;&amp;thinsp;3&lt;/sup&gt; / 3}} for the three-dimensional ball of radius&amp;nbsp;''r''.

==Unit balls in normed vector spaces==

More precisely, the '''open unit ball''' in a [[normed vector space]] &lt;math&gt;V&lt;/math&gt;, with the [[Norm (mathematics)|norm]] &lt;math&gt;\|\cdot\|&lt;/math&gt;, is

:&lt;math&gt; \{ x\in V: \|x\|&lt;1 \}.&lt;/math&gt;

It is the [[interior (topology)|interior]] of the '''closed unit ball''' of (''V'',||·||),

:&lt;math&gt; \{ x\in V: \|x\|\le 1\}.&lt;/math&gt;

The latter is the disjoint union of the former and their common border, the '''unit sphere''' of (''V'',||·||),

:&lt;math&gt; \{ x\in V: \|x\| = 1 \}.&lt;/math&gt;

The 'shape' of the ''unit ball'' is entirely dependent on the chosen norm; it may well have 'corners', and for example may look like [&amp;minus;1,1]&lt;sup&gt;''n''&lt;/sup&gt;, in the case of the norm ''l''&lt;sub&gt;∞&lt;/sub&gt; in ''R''&lt;sup&gt;''n''&lt;/sup&gt;. The ''round ball'' is understood as the usual [[Hilbert space]] norm, based in the finite-dimensional case on the [[Euclidean distance]]; its boundary is what is usually meant by the ''unit sphere''.  Here are some images of the unit ball for the two-dimensional [[Lp space|&lt;math&gt;\ell^p&lt;/math&gt; space]] for various values of ''p'' (the unit ball being concave for ''p'' &lt; 1 and convex for ''p'' &amp;ge; 1):

{{panorama|image=File:2D unit balls.svg|height=200|alt=Unit circles using different Minkowski distance metrics.}}

These illustrate why the condition ''p'' &amp;ge; 1 is necessary in the definition of the &lt;math&gt;\ell^p&lt;/math&gt; norm, as the unit ball in any normed space must be [[convex set|convex]] as a consequence of the [[triangle inequality]].

Note that for the circumferences &lt;math&gt;C_p&lt;/math&gt; of the two-dimensional unit balls we have:

:&lt;math&gt;C_{0} = C_{\infty} = 8&lt;/math&gt; is the maximum value.
:&lt;math&gt;C_{1} = 4 \sqrt{2}&lt;/math&gt; is the minimum value.
:&lt;math&gt;C_{2} = 2 \pi \,.&lt;/math&gt;

==Generalizations==

===Metric spaces===
All three of the above definitions can be straightforwardly generalized to a [[metric space]], with respect to a chosen origin. However, topological considerations (interior, closure, border) need not apply in the same way (e.g., in [[ultrametric]] spaces, all of the three are simultaneously open and closed sets), and the unit sphere may even be empty in some metric spaces.

===Quadratic forms===
If ''V'' is a linear space with a real [[quadratic form]] ''F'':''V'' → R, then { p ∈ ''V'' : ''F''(p) = 1 } may be called the unit sphere&lt;ref&gt;Takashi Ono (1994) ''Variations on a Theme of Euler: quadratic forms, elliptic curves, and Hopf maps'', chapter 5: Quadratic spherical maps, page 165, [[Plenum Press]], {{isbn|0-306-44789-4}}&lt;/ref&gt;&lt;ref&gt;F. Reese Harvey (1990) ''Spinors and calibrations'', "Generalized Spheres", page 42, [[Academic Press]], {{isbn|0-12-329650-1}}&lt;/ref&gt; or [[hyperboloid#Relation to the sphere|unit quasi-sphere]] of ''V''. For example, the quadratic form &lt;math&gt;x^2 - y^2&lt;/math&gt;, when set equal to one, produces the [[unit hyperbola]] which plays the role of the "unit circle" in the plane of [[split-complex number]]s. Similarly, quadratic form x&lt;sup&gt;2&lt;/sup&gt; yields a pair of lines for the unit sphere in the [[dual number]] plane.

==See also==
{{wiktionary|unit sphere}}

*[[ball (mathematics)|ball]]
*[[hypersphere]]
*[[sphere]]
*[[superellipse]]
*[[unit circle]]
*[[unit disk]]
*[[unit sphere bundle]]
*[[unit square]]

==Notes and references==
{{reflist}}
* Mahlon M. Day (1958) ''Normed Linear Spaces'', page 24, [[Springer-Verlag]].
*{{citation|last1=Deza|first1=E.|first2=M.|last2=Deza|title=Dictionary of Distances|year=2006|publisher=Elsevier|isbn=0-444-52087-2}}. Reviewed in [https://www.scribd.com/doc/2668595/Newsletter-of-the-European-Mathematical-Society-20070664-featuring-Let-Platonism-Die ''Newsletter of the European Mathematical Society'' '''64''' (June 2007)], p.&amp;nbsp;57. This book is organized as a list of distances of many types, each with a brief description.

== External links ==
* {{mathworld | urlname = UnitSphere | title = Unit sphere}}

{{DEFAULTSORT:Unit Sphere}}
[[Category:Functional analysis]]
[[Category:1 (number)]]
[[Category:Spheres]]

[[es:1-esfera]]</text>
      <sha1>n5d6y0v8ejcd15nskzyj7frboehdxsa</sha1>
    </revision>
  </page>
  <page>
    <title>Yupana</title>
    <ns>0</ns>
    <id>24320887</id>
    <revision>
      <id>808307245</id>
      <parentid>790636587</parentid>
      <timestamp>2017-11-02T02:15:03Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27527">[[File:Yupana 1.png|thumb]]

[[File:Yupana.jpg|thumb|Sketch of a ''[[Quipucamayoc]]'' from ''[[El primer nueva corónica y buen gobierno]]''. Shown on the lower left side is a yupana.]]

A ''yupana'' (from Quechua yupay: count)&lt;ref name="TOM"&gt;[https://archive.org/details/lexiconovocabula00domi Santo Tomas, "Lexicon o Vocabulario de la lengua general del Peru", 1560]&lt;/ref&gt; is  an [[abacus]] used to perform [[arithmetic operations]] dating back to the time of the [[Incas]].

==Types==

The term ''yupana'' refers to two distinct classes of objects:

* '''table-yupana''' (or archaeological yupana): a system of trays of different sizes and materials, carved at the top of the device into geometric boxes, into which seeds or pebbles were placed, presumably for performing complex arithmetic calculations. The first of these tables was found in 1869 in the province of [[Cuenca Canton|Cuenca]] ([[Ecuador]]) and marked the beginning of systematic studies on these objects. All [[archaeological]] finds are very different from each other.&lt;ref name="RDP"&gt;Radicati di Primeglio, [http://sisbib.unmsm.edu.pe/bibvirtualdata/libros/2008/estud_quipu/cap03.pdf "Il sistema contabile degli Inca: Yupana e Quipu"], 1979&lt;/ref&gt;
* '''yupana of Poma de Ayala''': a picture on page 360 of [[El primer nueva corónica y buen gobierno]] written by the [[chronicler]] of the Indies [[Felipe Guaman Poma de Ayala]], representing a 5x4 [[chessboard]].&lt;ref name="GPA"&gt;Guaman Poma de Ayala, [http://www.kb.dk/permalink/2006/poma/info/en/frontpage.htm "Primer Nueva Coronica y Buen Gobierno", 1615]&lt;/ref&gt; The picture, although having some similarities with the majority of table-yupana, presents several differences from these, first of all, the shape of the boxes ([[rectangles]]), when those of table-yupanas are [[polygons]] of varying shape.

Although very different from each other, most of the scholars who have dealt with table-yupana, have then extended its reasoning and theories to the yupana of Poma de Ayala and vice versa, perhaps in an attempt to find a unifying thread or a common method. It should also be noted that the Nueva Coronica was discovered only in 1916 in the [[library]] of [[Copenhagen]] and that part of the studies on it were based on previous studies and theories regarding table-yupanas.&lt;ref name="RDP" /&gt;

==History==

Several chroniclers of the Indies described, unfortunately approximately, the Incan abacus and its operation.

===Felipe Guaman Poma de Ayala===

The first was Guaman Poma de Ayala that in 1615 approximately, wrote:

{{quote|... They count through tables, numbering from one hundred thousand to one hundred and from ten thousand and ten, until the unit. They keep records of everything that happens in this realm: holidays, Sundays, months and years. These accountants and treasurers of the kingdom are found in every city, town, or indigenous village ...|&lt;ref name="GPA" /&gt;}}

In addition to providing this brief description, Poma de Ayala draws a picture of the yupana: a board of five rows and four columns in which are designed a series of white and black circles.

===José de Acosta===

The father [[Jesuit]] ''José de Acosta'' wrote:

{{quote|... they take the corn and put one here, three there, eight from another part; they move from a box and exchanged three other grains from one to another to finally get the result without error|&lt;ref name="ACO"&gt;José de Acosta - Historia Natural y Moral de las Indias - Libro VI cap XVIII (De los memoriales y cuentas que usaron los Indios del Perú)&lt;/ref&gt;}}

===Juan de Velasco===

Father ''Juan de Velasco'' wrote:

{{quote|... these teachers were using something like a series of tables, made of wood, stone, or clay, with different separations, in which they put stones of different shapes, colors and angular shapes|&lt;ref name="VEL"&gt;Juan Velasco - “Historia del Reino de Quito” - 1841 44, Tomo II, 7&lt;/ref&gt;}}

==Table-yupana==

===Chordeleg===

The first table-yupana which we know was found in 1869 in [[Chordeleg]] in the department of [[Cuenca Canton|Cuenca]] ([[Ecuador]]). It is a [[rectangular]] table (33x27 cm) of [[wood]] which contains 17 compartments, of which 14 [[square]], 2 [[rectangular]] and one [[octagonal]]. On two edges of the table there are other square compartments (12x12 cm) raised and symmetrically arranged one another, to which two square platforms (7x7 cm), are overlapped. These structures are called towers. The table presents a symmetry of the compartments with respect to the [[diagonal]] of the [[rectangle]]. The four sides of the board are also engraved with figures of human heads and a [[crocodile]].&lt;ref name="RDP" /&gt; As a result of this discovery, [[Charles Wiener]] began in 1877 a systematic study of these objects. Wiener came to the conclusion that the table-yupanas served to calculate the [[taxes]] that farmers paid to the Incan empire.

===Caraz===

Found at [[Caraz]] in 1878 - 1879, this table-yupana is different from that of Chordeleg as the material of construction is the [[stone]] and the central compartment of octagonal shape is replaced with a rectangular one; towers also have three shelves instead of two.&lt;ref name="RDP" /&gt;

===Callejón de Huaylas===

A series of table-yupanas much different from the first, was described by [[Erland Nordenskiöld]] in 1931. These yupana, made of stone, present a series of rectangular and square compartments. The tower is composed of two rectangular compartments. The compartments are arranged symmetrically with respect to the axis of the smaller side of the table.&lt;ref name="RDP" /&gt;

===Triangular yupana===

These yupana, made of stone, have 18 compartments of triangular shape, arranged around the table. On one side there is a rectangular tower with only one floor and three triangular compartments. In the central part there are four square compartments, coupled between them.&lt;ref name="RDP" /&gt;

===Chan Chan===

Identical to the yupana of Chordeleg, both for the material and the arrangement of the compartments, this table-yupana was found in the archaeological complex of [[Chan Chan]] in [[Peru]] in 1967.&lt;ref name="RDP" /&gt;

===Cárhua de la Bahía===

Discovered in the province of [[Pisco]] ([[Peru]]), these table-yupanas are two tables in [[clay]] and [[bone]]. The first is rectangular (47x32 cm), has 22 square (5x5 cm) and three rectangular (16x18 cm) compartments, and has no towers. The second is rectangular (32x23 cm) containing 22 square compartments, two L-shaped and three rectangular in the center. The compartments are arranged symmetrically with respect to the axis of the longer side.&lt;ref name="RDP" /&gt;

===Huancarcuchu===

Discovered in the upper [[Ecuador]] by [[Max Uhle]] in 1922, this yupana is made of stone and its bins are drawn. It has the shape of a scale consisting of 10 overlapping rectangles: four on the first floor, three on the second, two in the third and one in the fourth. This yupana is the one that is closest to the picture by Poma de Ayala in Nueva Coronica, while having a line less and being half drawn.&lt;ref name="RDP" /&gt;

===Florio===

C. Florio presents a study &lt;ref name="FLO2"&gt;[https://www.academia.edu/12063847/Recovering_memory_the_INCA_KEY_as_YANANTIN C. Florio, "Recovering memory - The Inca Key as Yanantin"]&lt;/ref&gt;
which does not identify a yupana in these archaeological findings, but an object whose name is unknown and which has been forgotten. Instead, this object is to connect to the tocapu (an ideogram already used by pre-Incas civilizations) called “llave inca” (i.e. Inca key) and to the [[Yanantin|yanantin-masintin]] philosophy. The scholar reaches this conclusion starting from the lack of objective evidences which recognize a yupana in this object, a belief that consolidated over years only for the repeat of this hypothesis never demonstrated, and by crossing data from the Miccinelli Documents and the tocapu(s) catalogued by Victoria de la Jara. 
&lt;gallery&gt;
Image: Teoria Florio su yupana a casetta - B.png|Fig. A - Structure of a “Chordeleg” table-yupana. Colouring to differentiate the compartments.
Image: Teoria Florio su yupana a casetta - C.png|Fig. B -  Identication of a stereotyped  color
Image:Teoria Florio su yupana a casetta - D.png|Fig. C -  Really existing tocapu catalogued by [[Victoria de la Jara]]
Image:Teoria Florio su yupana a casetta - E.png|Fig. D - Other tocapu pattern, possible stylization of the previous one
Image:Teoria Florio su yupana a casetta - F.png|Fig. E - Tocapu called “llave inca”, Inca key
&lt;/gallery&gt;

Supposing to colour the different compartments of the table-yupana (fig. A), C. Florio identifies a drawing (fig. B) very similar to a really existing tocapu (fig. C) and catalogued by Victoria de la Jara. In addition, in the tocapu reported in figure D, also catalogued by V. de la Jara, Florio identifies a stylization of the tocapu C and the departure point for creating the tocapu “llave inca” (Inca key). She finds the relation between the table-yupana and the Inca key also in their connection with the concept of duality: the table-yupana structure is clearly dual and Blas Valera in “Exul Immeritus Blas Valera populo suo” (one of the two Miccinelli Documents) describes the tocapu we call Inca key as representing the concept of the “opposite forces” and the “number 2”, both strictly linked to the concept of duality.

According to C. Florio, the real yupana used by the Incas is that of Guáman Poma, but with more columns and rows. Guáman Poma would have represented just the part of the yupana useful for carrying out a specific calculation, which Florio identifies to be a multiplication (see below).

==Theories of Yupana Poma de Ayala==

===Henry Wassen===

In 1931, [[Henry Wassen]] studied the yupana of Poma de Ayala, proposing for the first time a possible representation of the numbers on the board and the operations of [[addition]] and [[multiplication]]. He interpreted the white circles as gaps, carved into yupana in which to insert the seeds described by chroniclers: so the white circles correspond to empty gaps, while the blacks circles correspond to the same gaps filled with a black seed.&lt;ref name="RDP" /&gt;

The numbering system at the base of the abacus was positional notation in base 10 (in line with the writings of the chroniclers of the Indies).

The representation of the numbers, then followed a vertical progression such that the units were positioned in the first row from the bottom, in the second the tens, hundreds in the third, and so on.

Wassen proposed a progression of values of the seeds that depends on their position in the table: 1, 5, 15, 30, respectively, depending on who occupy a gap in the first, second, third and fourth columns (see the table below). Only a maximum of five seeds could be included in a box belonging to the first column, so that the maximum value of said box was 5, multiplied by the power of the corresponding line. These seeds could be replaced with one seed of the next column, useful during arithmetic operations. According to the theory of Wassen, therefore, the operations of sum and product were carried out horizontally.

This theory received a lot of criticism due to the high complexity of the calculations and was therefore considered inadequate and soon abandoned.

By way of example, the following table shows the number 13457.

{| style="width:100%; background:transparent"
| align="left" |
{| class="wikitable"
|+ Yupana by Wassen
!|Powers\Values||1||5||15||30
|-
!|10&lt;sup&gt;4&lt;/sup&gt;
||•&lt;small&gt;oooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;3&lt;/sup&gt;
||•••&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;2&lt;/sup&gt;
||••••&lt;small&gt;o&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;1&lt;/sup&gt;
||&lt;small&gt;ooooo&lt;/small&gt;
||•&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;0&lt;/sup&gt;
||••&lt;small&gt;ooo&lt;/small&gt;
||•&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|}
Representation of 13457
|}

This first interpretation of the yupana of Poma de Ayala was the starting point for the theories developed by subsequent authors, up to the present day. In particular, no one ever moved away from the positional numbering system until 2008.

===Emilio Mendizabal===

[[Emilio Mendizabal]] was the first to propose in 1976 that the [[Inca]] were using, as well as the decimal representation, also a representation based on the progression 1,2,3,5. Mendizabal in the same publication pointed out that the series of numbers 1,2,3 and 5, in the drawing of Poma de Ayala, are part of the [[Fibonacci sequence]], and stressed the importance of "magic" that had the number 5 for civilization the [[north]] of [[Peru]], and the number 8 for the civilizations of the [[south]] of [[Peru]].&lt;ref name="RDP" /&gt;

===Radicati di Primeglio===

In 1979, [[Carlos Radicati di Primeglio]] emphasized the difference of table-yupana from that of Poma de Ayala, describing the state of the art of the research and theories advanced so far. He also proposed the [[algorithms]] for calculating the four basic [[arithmetic operations]] for yupana of Poma de Ayala, according to a new interpretation for which it was possible to have up to nine seeds in each box with vertical progression for powers of ten.&lt;ref name="RDP" /&gt; The choice of Radicati was to associate to each gap a value of 1.

In the following table is represented the number 13457

{| style="width:100%; background:transparent"
| align="left" |
{| class="wikitable"
|+ Yupana by Radicati
!|Powers\Values||1||1||1||1
|-
!|10&lt;sup&gt;4&lt;/sup&gt;
||&lt;small&gt;•oooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
|-
!|10&lt;sup&gt;3&lt;/sup&gt;
||&lt;small&gt;•••oo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
|-
!|10&lt;sup&gt;2&lt;/sup&gt;
||&lt;small&gt;••••o
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
|-
!|10&lt;sup&gt;1&lt;/sup&gt;
||&lt;small&gt;•••••
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
|-
!|10&lt;sup&gt;0&lt;/sup&gt;
||&lt;small&gt;•••••
••oo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
||&lt;small&gt;ooooo
oooo&lt;/small&gt;
|}
Representation of 13457
|}

===William Burns Glynn===

In 1981, the English textile [[engineer]] [[William Burns Glynn]] proposed a positional base 10 solution for the yupana of Poma de Ayala.&lt;ref name="WBG"&gt;William Burns Glynn, [http://www.boletindelima.com/1981-11.htm "Calculation table of the Incas"], ''Bol. Lima No. 11'', 1981, 1-15.&lt;/ref&gt;

Glynn, as Radicati, adopted the same Wassen's idea of full and empty gaps, as well as a vertical progression of the powers of ten, but proposed an architecture that allowed to greatly simplify the arithmetic operations.

The horizontal progression of the values of the seeds in its representation is 1, 1, 1 for the first three columns, so that in each row is possible to deposit a maximum of ten seeds (5 + 3 + 2 seeds). Ten seeds of any row is correspond to a single seed of the upper line.

The last column is dedicated to the ''memory'', which is a place where you can drop momentarily ten seeds, waiting to move them to the upper line. According to the author, this is very useful during arithmetic operations in order to reduce the possibility of error.

The solution of Glynn has been adopted in various teaching projects all over the world, and even today some of its variants are used in some [[schools]] of [[South America]].&lt;ref name="MRV"&gt;[http://cursa.ihmc.us/rid=1J2NH8QTM-2912G6-PZ5/yupana_como_herramienta_pedagogica.pdf Mora &amp; Valero "La Yupana come strumento pedagogico alle elementari"]&lt;/ref&gt;&lt;ref name="FIO"&gt;[http://www.seminariodidama.unito.it/fiorentino.pdf Fiorentino, "La yupana elettronica: uno strumento per la didattica interculturale della matematica"]&lt;/ref&gt;

In the following table is represented the number 13457

{| style="width:100%; background:transparent"
| align="left" |
{| class="wikitable"
|+ Yupana di Glynn Burns
!|Potenze\Valori||1||1||1||Memoria
|-
!|10&lt;sup&gt;4&lt;/sup&gt;
||•&lt;small&gt;oooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;3&lt;/sup&gt;
||•••&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;2&lt;/sup&gt;
||••••&lt;small&gt;o&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;1&lt;/sup&gt;
||•••••
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|10&lt;sup&gt;0&lt;/sup&gt;
||•••••
||••&lt;small&gt;o&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|}
|}

===Nicolino de Pasquale===

The [[Italy|Italian]] [[engineer]] [[Nicolino de Pasquale]] in 2001 proposed a positional solution in base 40 of the yupana of Poma de Ayala, taking the representation theory of [[Fibonacci]] already proposed by [[Emilio Mendizabal]] and developing it for the four operations.

De Pasquale also adopts a vertical progression to represent numbers by powers of 40. The representation of the numbers is based on the fact that the sum of the values of the circles in each row gives as total 39, if each circle takes the value 5 in the first column, 3 in the second column, 2 in the third and 1 in the fourth one; it is thus possible to represent 39 numbers, united to [[neutral element]] ( [[zero]] or no seeds in the table); this forms the basis of 40 symbols necessary for the numbering system.&lt;ref name="DP1"&gt;N. De Pasquale [http://www.quipus.it/DePasquale_Volo%20_del_Condor.pdf "Il volo del condor", ''Pescara Informa'', 2001]&lt;/ref&gt;

One of the possible representations of the number 13457 in the yupana by De Pasquale is shown in the following table:

{| style="width:100%; background:transparent"
| align="left" |
{| class="wikitable"
|+ Yupana by De Pasquale
!|Powers\Values||5||3||2||1
|-
!|40&lt;sup&gt;4&lt;/sup&gt;
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|40&lt;sup&gt;3&lt;/sup&gt;
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|40&lt;sup&gt;2&lt;/sup&gt;
||•&lt;small&gt;oooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||•&lt;small&gt;o&lt;/small&gt;
||•
|-
!|40&lt;sup&gt;1&lt;/sup&gt;
||••&lt;small&gt;ooo&lt;/small&gt;
||••&lt;small&gt;o&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
!|40&lt;sup&gt;0&lt;/sup&gt;
||••&lt;small&gt;ooo&lt;/small&gt;
||•&lt;small&gt;oo&lt;/small&gt;
||••
||&lt;small&gt;o&lt;/small&gt;
|}
|}

The theory of De Pasquale opened, in the years after his birth, great controversy among researchers who divided mainly into two groups: one supporting the base 10 theory and another supporting the base 40 one. It should be noted in this regard that the Spanish chronicles of the time of the [[conquest of the Americas]] indicated that the Incas used a decimal system and that since 2003 the base 10 has been proposed as the basis for calculating both with the abacus and the [[quipu]]&lt;ref name="ABC"&gt;[http://www.abc.net.au/science/articles/2004/02/02/1036168.htm?site=science/memory Lorenzi, Incan counting system as easy as 1,2,3,5 (2004)]&lt;/ref&gt;

De Pasquale has recently proposed the use of yupana as astronomical [[calendar]] running in mixed base 36/40&lt;ref name="DP2"&gt;[http://www.quipus.it/english/THE%20SAVED%20KINGDOM.pdf N. De Pasquale, "The Saved Kingdom"]&lt;/ref&gt; and provided its own interpretation of the [[Quechuan languages|Quechua]] word ''huno'', translating it as 0.1.&lt;ref name="DP3"&gt;[http://www.quipus.it/DECIMAL%20POMA.pdf N. De Pasquale, "Decimal Guaman Poma"]&lt;/ref&gt; This interpretation diverges from all the chroniclers of the Indies, starting from [[Domingo de Santo Tomas]]&lt;ref name="TOM" /&gt; which in 1560 translated ''huno'' with ''chunga guaranga'' (ten thousand).

===Cinzia Florio===

In 2008 [[Cinzia Florio]] proposes an alternative and revolutionary approach in respect to all the theories proposed so far. For the first time we deviate from the positional numbering system and we adopt the additive, or [[sign-value notation]].&lt;ref name="FLO"&gt;[http://issuu.com/casaeditriceoedipus/docs/cinziaflorio C. Florio, "Incontri e disincontri nella individuazione di una relazione matematica nella yupana in Guaman Poma de Ayala", Salerno, 14-15 maggio e 10-12 Dicembre 2008 - Oédipus Editore, 2009]&lt;/ref&gt;

Relying exclusively on the design of Poma de Ayala, the author explains the arrangement of white and black circles and interprets the use of the abacus as a board for making [[multiplications]], in which the [[multiplicand]] is represented in the right column, the multiplier in the two central columns and the result ([[product (mathematics)|product]]) is shown in the left column. See the following table.

{| style="width:100%; background:transparent"
| align="left" |
{| class="wikitable"
|+ Yupana by Florio
!|Product||Multiplier||Multiplier||Multiplicand
|-
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;ooooo&lt;/small&gt;
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;oo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;
|}
|}

The theory differs from all the previous by several aspects: first, the white and black circles would not be any gaps that may be filled with a seed, but different colors of the seeds, representatives respectively tens and units (this according to the chronicler Juan de Velasco ).&lt;ref name="VEL" /&gt;

Secondly, the multiplicand is entered in the first column respecting the sign-value notation: so, the seeds can be entered in any order and the number is given by the sum of the values of these seeds.

The multiplier is represented as the sum of two factors, since the procedure for obtaining the product is based on the distributive property of multiplication over addition.

The table multiplier drawn by Poma de Ayala with that provision of the seeds, represent according to the author, the calculation: 32 x 5, where the multiplier 5 is decomposed into 3 + 2. The sequence of numbers 1,2,3,5 would be casual, contingent to the calculation done and not related to the Fibonacci series.

{| class="wikitable"
|+ Yupana by Florio
!|Product||Multiplicator||Multiplicator||Multiplicand
|-
!| ||3X||2X||
|-
||&lt;small&gt;ooo&lt;/small&gt;••
||&lt;small&gt;oo&lt;/small&gt;•
||••
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;oooo&lt;/small&gt;•
||&lt;small&gt;oo&lt;/small&gt;•
||&lt;small&gt;oo&lt;/small&gt;
||•
|-
||•••••
||&lt;small&gt;ooo&lt;/small&gt;
||&lt;small&gt;o&lt;/small&gt;•
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;oooo&lt;/small&gt;•
||&lt;small&gt;oo&lt;/small&gt;•
||&lt;small&gt;o&lt;/small&gt;•
||&lt;small&gt;o&lt;/small&gt;
|-
||&lt;small&gt;ooo&lt;/small&gt;••
||•••
||&lt;small&gt;oo&lt;/small&gt;
||•
|-
!| 151(160)||96||64||32
|}

Key: o = 10; • = 1; The operation represented is: 32 x 5 = 32 x (2 + 3) = (32 x 2) + (32 x 3) = 64 + 96 = 160

The numbers represented in the columns are, from left to right: 32 (the multiplicand), 64 = 32 x 2 and 32 x 3 = 96 (which together constitute the multiplicand, multiplied by the two factors in which the multiplier has been broken down) and finally 151. In this issue (error) are based all possible criticisms of this interpretation, since 151 is obviously not the sum of 96 and 64. Florio, however, notes that a mistake of Poma de Ayala, in designing a black circle instead of a white one, would have been possible. In this case, changing just a black circle with a white one in the last column, we obtain the number 160, which is exactly the product sought as the sum of the quantities present in the central columns.

With a yupana as the one designed by Poma de Ayala can not be represented every multiplicands, but it is necessary to extend the yupana vertically (adding rows) to represent numbers whose sum of digits exceeds 5. The same thing goes for the multipliers: to represent all the numbers is necessary to extend the number of columns. It should be emphasized that this interpretation, apart the supposed error calculation  (or representation by the designer), is the only one that identifies in the yupana of Poma de Ayala a mathematical and consistent message (multiplication) and not a series of random numbers as in other interpretations.

==See also==

* [[Quipu]]
* [[Inca]]
* [[Inca Empire]]
* [[Numbering System]]

==References==
{{Reflist}}

==External links==
* [http://www.springerreference.com/docs/html/chapterdbid/77966.html Gilsdorf - Ethnomathematics of the Inkas]
* [https://books.google.com/books?id=2hTyfurOH8AC&amp;pg Heliane Seline - Mathematics through cultures]
* [http://www-history.mcs.st-and.ac.uk/HistTopics/Inca_mathematics.html O'Connor &amp; Robertson - Mathematics of the Incas]

===Chroniclers of the Indies===
* {{es icon}} [http://www.kb.dk/permalink/2006/poma/info/en/frontpage.htm Poma de Ayala - El Primer Nueva Coronica y Buen Gobierno]
* {{es icon}} [http://www.cervantesvirtual.com/obra-visor/historia-natural-y-moral-de-las-indias--0/html/ José De Acosta - Historia Natural y Moral de las Indias]
* {{es icon}} [http://www.memoriachilena.cl/archivos2/pdfs/MC0033193.pdf Velasco - Historia del reyno de Quito del America del Sur]

===Theory by Wassen and table-Yupana===
* {{es icon}} [http://sisbib.unmsm.edu.pe/bibvirtualdata/libros/2008/estud_quipu/cap03.pdf Radicati di Primeglio - El sistema contable de los Incas: Yupana y Quipu]

===Theory by Glynn Burns and school projects===
* {{es icon}} [http://cursa.ihmc.us/rid=1J2NH8QTM-2912G6-PZ5/yupana_como_herramienta_pedagogica.pdf Mora &amp; Valero - La Yupana come strumento pedagogico alle elementari]
* [http://nasgem.rpi.edu/files/4092 Leonard &amp; Shakiban - The Incan Abacus]
* {{it icon}} [http://www.seminariodidama.unito.it/fiorentino.pdf Fiorentino - La yupana elettronica: uno strumento per la didattica interculturale della matematica]

===Theory by De Pasquale===

*{{it icon}} [http://matematica.unibocconi.it/articoli/la-matematica-nelle-civilt%C3%A0-pre-colombiane Università Bocconi di Milano - La Matematica nelle civiltà pre-colombiane]
*{{en icon}}[http://www.abc.net.au/science/news/ancient/AncientRepublish_1036168.htm Incan counting system as easy as 1,2,3,5 - by Rossella Lorenzi]
*{{it icon}} [http://it.geocities.com/newsarcheo/precolombiane4.htm Notizie sulla numerazione Inca e sulla yupana]
*{{it icon}} [http://www.margheritacampaniolo.it/matematica_inca.htm Un italiano scopre l'enigma della matematica inca]
*{{it icon}} [http://www.ingegneripescara.it/old/_contenuti/archivio/2002/rassegna_2002.htm Il Sole 24 Ore Domenica 10 Novembre 2002 – N. 308 – Pagina 35 - di Antonio Aimi - SCIENZA E FILOSOFIA Matematica precolombiana Scoperto il metodo di calcolo degli Inca]
*{{it icon}} [http://4.bp.blogspot.com/_K8aa26UngiU/SEXI6P-odEI/AAAAAAAABQI/OqPjrzw84rY/s1600-h/yupane.jpg L'unione Sarda - I numeri della natura nella scacchiera degli Inca - di Andrea Mameli]
*{{en icon}} [http://www.quipus.it/gpg/index.html "Guaman Poma Game, by N. De Pasquale, D. D'Ottavio]

===Theory by C. Florio===
* {{it icon}} [http://issuu.com/casaeditriceoedipus/docs/cinziaflorio Florio - Incontri e disincontri nella individuazione di una relazione matematica nella yupana in Guaman Poma de Ayala]
* {{es icon}} [https://www.academia.edu/3989534/Decifrata_la_yupana_di_Guaman_Poma_versione_in_spagnolo Florio - Encuentros y Desencuentros en la identificación de unarelación matemática en la yupana de Guaman Poma de Ayala]

[[Category:Inca]]
[[Category:Mathematical tools]]
[[Category:Quechua words and phrases]]</text>
      <sha1>7pcariqz14w39cdqus4e1gciwt8wmpj</sha1>
    </revision>
  </page>
</mediawiki>
