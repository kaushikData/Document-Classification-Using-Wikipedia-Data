<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>120 (number)</title>
    <ns>0</ns>
    <id>410563</id>
    <revision>
      <id>870369353</id>
      <parentid>864086515</parentid>
      <timestamp>2018-11-24T09:30:28Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7449">{{Infobox number
| number = 120
| divisor = 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 24, 30, 40, 60, 120
}}
[[Image:Schlegel wireframe 120-cell.png|thumb|right|246px|The [[120-cell]] (or hecatonicosachoron) is a [[convex regular 4-polytope]] consisting of 120 [[Dodecahedron|dodecahedral]] [[Cell (geometry)|cells]]]]
'''120''', read as '''one hundred [and] twenty''', is the [[natural number]] following [[119 (number)|119]] and preceding [[121 (number)|121]]. 

In the [[Germanic languages]], the number 120 was also formerly known as "one hundred". This "hundred" of six [[score (number)|score]] is now obsolete, but is described as the '''[[long hundred]]''' or '''[[great hundred]]''' in historical contexts.&lt;ref&gt;{{cite book|last=Gordon|first=E V|title=Introduction to Old Norse|year=1957|publisher=Claredon Press|location=Oxford|pages=292–293|url=https://www.scribd.com/doc/49127454/Introduction-to-Old-Norse-by-E-V-Gordon|access-date=2018-06-20|archive-url=https://web.archive.org/web/20160415205641/https://www.scribd.com/doc/49127454/Introduction-to-Old-Norse-by-E-V-Gordon#|archive-date=2016-04-15|dead-url=yes|df=}}&lt;/ref&gt;

==In mathematics==
'''120''' is the [[factorial]] of 5 and one less than a square, making (5, 11) a [[Brown number]] pair.  120 is the sum of a [[twin prime]] pair (59 + 61) and the sum of four consecutive [[prime number]]s (23 + 29 + 31 + 37), four consecutive powers of 2 (8 + 16 + 32 + 64), and four consecutive powers of 3 (3 + 9 + 27 + 81). It is [[highly composite number|highly composite]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A002182|title=Sloane's A002182 : Highly composite numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt; [[superabundant number|superabundant]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A004394|title=Sloane's A004394 : Superabundant numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt; and [[colossally abundant number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A004490|title=Sloane's A004490 : Colossally abundant numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt; with its 16 divisors being more than any number lower than it has, and it is also the smallest number to have exactly that many divisors. It is also a [[sparsely totient number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A036913|title=Sloane's A036913 : Sparsely totient numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt; 120 is the smallest number to appear six times in [[Pascal's triangle]]. 120 is also the smallest multiple of 6 with no adjacent prime number, being adjacent to 119 = 7 × 17 and 121 = 11&lt;sup&gt;2&lt;/sup&gt;.

It is the eighth [[hexagonal number]] and the fifteenth [[triangular number]], as well as the sum of the first eight triangular numbers, making it also a [[tetrahedral number]]. 120 is divisible by the first 5 triangular numbers and the first 4 tetrahedral numbers.

120 is the first [[multiply perfect number]] of order three (''a 3-perfect'' or ''[[triperfect number]]'').&lt;ref&gt;{{Cite web|url=https://oeis.org/A005820|title=Sloane's A005820 : 3-perfect numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt; The sum of its factors (including one and itself) sum to [[360 (number)|360]]; exactly three times 120. Note that [[perfect number]]s are order two (''2-perfect'') by the same definition.

120 is divisible by the number of primes below it, 30 in this case. However, there is no integer which has 120 as the sum of its proper divisors, making 120 an [[untouchable number]].

The sum of [[Euler's totient function]] φ(''x'') over the first nineteen integers is 120.

120 figures in [[Pierre de Fermat]]'s modified Diophantine problem as the largest known integer of the sequence 1, 3, 8, 120. Fermat wanted to find another positive integer that multiplied with any of the other numbers in the sequence yields a number that is one less than a square. [[Leonhard Euler]] also searched for this number, but failed to find it, but did find a fractional number that meets the other conditions, {{sfrac|777480|2879&lt;sup&gt;2&lt;/sup&gt;}}.

The internal angles of a regular [[hexagon]] (one where all sides and all angles are equal) are all 120&amp;nbsp;[[degree (angle)|degree]]s.

120 is a [[Harshad number]] in [[Decimal|base 10]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A005349|title=Sloane's A005349 : Niven (or Harshad) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-27}}&lt;/ref&gt;

==In science==

120 is the [[atomic number]] of [[Unbinilium]], an element yet to be discovered.

==In religion==
* The [[cubit]]s of the height of the [[Temple in Jerusalem|Temple building]] ([[Books of Chronicles|II Chronicles]] 3:4)
* The age at which [[Moses]] died (Deut. 34:7).
** By extension, in Jewish tradition, to wish someone a long life, one says, "[[Live until 120]]"
* The number of [[Great Assembly|Men of the Great Assembly]] who canonized the Books of the [[Tanakh]] and formulated the [[Jewish services|Jewish prayers]]
* The number of [[Talent (measurement)|talent]]s of gold that the Queen of Sheba gave to [[Solomon]] in tribute ([[Books of Kings|I Kings]] 10:10)
* The number of princes King Darius set over his kingdom ([[Book of Daniel|Daniel]] 6:2)
* The summed weight in [[shekel]]s of the gold spoons offered by each tribal prince of Israel (Num. 7:86).
* In [[astrology]], when two planets in a person's chart are 120&amp;nbsp;degrees apart from each other, this is called a trine. This is supposed to bring good luck in the person's life.&lt;ref&gt;{{cite news |title=Astrology And The Black Man |url=https://news.google.com/newspapers?id=FCEmAAAAIBAJ&amp;sjid=Bv4FAAAAIBAJ&amp;pg=4399,615262&amp;dq=astrology+planets+120+degrees+trine&amp;hl=en |newspaper=Afro American |date=January 31, 1970 |accessdate=December 30, 2010}}&lt;/ref&gt;

==In sports==
* The height in inches of a regulation hoop in the [[National Basketball Association]].&lt;ref&gt;[http://www.nba.com/canada/Basketball_U_Game_Court-Canada_Generic_Article-18039.html The Game Court], [[National Basketball Association]], retrieved 2014-04-07.&lt;/ref&gt;

==In other fields==
120 is also:
* The [[Medicine|medical]] [[emergency telephone number|telephone number]] in [[China]]
* In [[Austria]], the telephone number "to report a car breakdown on the highway.&lt;ref&gt;{{cite book |title=Frommer's Austria |last=Porter |first=Darwin |author2=Danforth Prince |year=2009 |publisher=Frommer's |location=Hoboken, New Jersey |isbn=978-0-470-39897-5 |page=482 }}&lt;/ref&gt;
* In the US Army, a common diameter for a mortar in mm (M120).
* [[TT scale]], a scale for model trains, is 1:120.
* [[120 film]] is a [[medium format film]] developed by [[Kodak]].
* [[120 (film)|''120'' (film)]], a 2008 Turkish film
* The Israeli [[national legislature]], the [[Knesset]], has 120 seats.

==See also==
* [[List of highways numbered 120]]
* [[United Nations Security Council Resolution 120]]

==References==

{{Reflist}}

* Wells, D. ''[[The Penguin Dictionary of Curious and Interesting Numbers]]'' London: Penguin Group. (1987): 135

{{Integers|1}}

{{DEFAULTSORT:120 (Number)}}
[[Category:Integers]]</text>
      <sha1>fcjd0jeuxxzum7bxgcpfh7dp3px5ukq</sha1>
    </revision>
  </page>
  <page>
    <title>46 (number)</title>
    <ns>0</ns>
    <id>399091</id>
    <revision>
      <id>871766278</id>
      <parentid>870887416</parentid>
      <timestamp>2018-12-03T08:22:55Z</timestamp>
      <contributor>
        <ip>98.155.12.187</ip>
      </contributor>
      <comment>/* In mathematics */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5544">{{example farm|date=March 2010}}
{{Infobox number
| number = 46
| divisor = 1, 2, 23, 46 
}}
'''46''' ('''forty-six''') is the [[natural number]] following [[45 (number)|45]] and preceding [[47 (number)|47]].

== In mathematics ==

'''Forty-six''' is a [[Wedderburn-Etherington number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A001190|title=Sloane's A001190 : Wedderburn-Etherington numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; an [[nonagonal number|enneagonal number]]&lt;ref&gt;{{Cite web|url=https://oeis.org/A001106|title=Sloane's A001106 : 9-gonal (or enneagonal or nonagonal) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; and a [[centered triangular number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A005448|title=Sloane's A005448 : Centered triangular numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; It is the sum of the [[Euler's totient function|totient function]] for the first twelve integers.&lt;ref&gt;{{Cite web|url=https://oeis.org/A002088|title=Sloane's A002088 : Sum of totient function|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; 46 is the largest even integer that cannot be expressed as a sum of two [[abundant number]]s. It is also the sixteenth [[Semiprime|semiprime.]]

Since it is possible to find sequences of 46+1 consecutive integers such that each inner member shares a factor with either the first or the last member, 46 is an [[Erdős–Woods number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A059756|title=Sloane's A059756 : Erdős-Woods numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;

== In science ==

* The [[atomic number]] of [[palladium]].
* The number of [[human]] [[chromosomes]].&lt;ref&gt;Barbara J. Trask, "Human genetics and disease: Human cytogenetics: 46 chromosomes, 46 years and counting" ''Nature Reviews Genetics'' '''3''' (2002): 769. "Human cytogenetics was born in 1956 with the fundamental, but empowering, discovery that normal human cells contain 46 chromosomes."&lt;/ref&gt;
* The approximate molar mass of [[ethanol]] (46.07 g mol{{sup|−1}})

=== Astronomy ===

* [[Messier object]] [[Messier 46|M46]], a [[visual magnitude|magnitude]] 6.5 [[open cluster]] in the [[constellation]] [[Puppis]].
* The [[New General Catalogue]] [http://www.ngcic.org/ object] [[NGC 46]], a [[star]] in the constellation [[Pisces (constellation)|Pisces]].

== In sports ==
* [[Valentino Rossi]], one of the most successful motorcycle riders of all time, uses 46 as his number in the [[Grand Prix motorcycles|MotoGP]] motorcycle world championship, and has been using this number in homage to his father since he started racing as a youngster.
* The number of mountains in the ''[[Adirondack High Peaks|46 peaks]]'' of the [[Adirondack Mountains|Adirondack mountain range]]. People who have climbed all of them are called "[[46ers|forty-sixers]]"; there is also an unofficial 47th peak.
* The name of a defensive scheme used in [[American football]]; see [[46 defense]].

== In religion ==
* The total of books in the ''[[Old Testament]]'', [[Catholic]] version, if the Book of ''[[Book of Lamentations|Lamentations]]'' is counted as a book separate from the Book of ''[[Jeremiah]]''.
* The number corresponding to the word "ADAM" where A=1, D=4, M=40&lt;ref&gt;Baker, Peter and [[Michael Lapidge]] (1995) [[Byrhtferth]]'s Enchiridion. Oxford: OUP for The Early English Text Society, p.201&lt;/ref&gt; (on the analogy of the numeric values of letters in ancient alphabets, such as Hebrew&lt;ref&gt;http://www.qsm.co.il/Hebrew/GimatriaH.htm&lt;/ref&gt; and Greek&lt;ref&gt;http://147.52.104.14/PROMWEB/ARXAIA/arxaioi_numbers.htm{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;).

[[File:Flag of Oklahoma (1911–1925).svg|thumb|[[Flag of Oklahoma]] (1911–1925)]]

== In other fields ==
'''Forty-six''' is also:
* The [[code for international direct dial]] phone calls to [[Sweden]].
* The number of samurai, out of 47, who carried out the attack in the historical [[Forty-seven Ronin|Ako vendetta]]; sometimes referred to as ''the 46 Ronins'' to discount the one samurai forced to turn back.
* In the title of the movie ''[[Code 46]]'', starring [[Tim Robbins]] and [[Samantha Morton]].
* Several [[List of highways numbered 46|routes numbered 46]] exist throughout the world.
* Because 46 in Japanese can be pronounced as "yon roku", and "yoroshiku"（よろしく） means "my best regards" in Japanese, people sometimes use 46 for greeting.
* 46 is the number of the City Chevrolet and Superflo cars driven by Cole Trickle in the movie ''[[Days of Thunder]]''.
* The number of the French department [[Lot (department)|Lot]].
* 46 is the number that unlocks the Destiny spaceship on the popular Sci-Fi TV show [[Stargate Universe]].  Dr. Rush discovers that the number 46 relates to the number of human chromosomes and begins sequencing different genetic codes to finally gain control of the ship's operating system.  The episode was called "Humans".
* The number depicted in the first [[flag of Oklahoma]] (replaced in 1925), signifying the fact that Oklahoma was the 46th state to join the [[United States]].

== References ==
{{Reflist}}
{{Integers|zero}}

[[Category:Integers]]</text>
      <sha1>1xyrqqqw9y21oqmy09llzfpd1ne4lom</sha1>
    </revision>
  </page>
  <page>
    <title>81 (number)</title>
    <ns>0</ns>
    <id>391874</id>
    <revision>
      <id>870805858</id>
      <parentid>870789400</parentid>
      <timestamp>2018-11-27T03:16:55Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>/* In other fields */ unsourced and pretty much meaningless</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4866">{{Infobox number
| number = 81
| divisor = 1, 3, 9, 27, 81
}}
'''81''' ('''eighty-one''') is the [[natural number]] following [[80 (number)|80]] and preceding [[82 (number)|82]].

==In mathematics==
'''81''' is:

* the [[square number|square]] of [[9 (number)|9]] and the fourth power of [[3 (number)|3]].
* a [[perfect totient number]] like all powers of three.&lt;ref&gt;{{Cite web|url=https://oeis.org/A082897|title=Sloane's A082897 : Perfect totient numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* a [[heptagonal number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A000566|title=Sloane's A000566 : Heptagonal numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* a [[centered octagonal number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A016754|title=Odd squares: a(n) = (2n+1)^2. Also centered octagonal numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* a [[tribonacci number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A000073|title=Sloane's A000073 : Tribonacci numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* an [[open meandric number]].
* the ninth member of the [[Mian-Chowla sequence]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A005282|title=Sloane's A005282 : Mian-Chowla sequence|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
* a [[palindromic number]] in bases 8 (121&lt;sub&gt;8&lt;/sub&gt;) and 26 (33&lt;sub&gt;26&lt;/sub&gt;).
* a [[Harshad number]] in bases 2, 3, 4, 7, 9, 10 and 13.
* one of three non-trivial numbers (the other two are [[1458 (number)|1458]] and [[1729 (number)|1729]]) which, when its digits (in decimal) are added together, produces a sum which, when multiplied by its reversed self, yields the original number:
: 8 + 1 = 9
: 9 &amp;times; 9 = 81  (although this case is somewhat degenerate, as the sum has only a single digit).

{{wiktionary|eighty-one}}

The inverse of 81 is 0.{{overline|012345679}} [[Recurring decimal|recurring]], missing only the digit "8" from the complete set of digits.  This is an example of the general rule that, in base ''b'',
:&lt;math&gt;\frac{1}{\left(b-1\right)^2} = 0.\overline{012\cdots(b-4)(b-3)(b-1)},&lt;/math&gt;
omitting only the digit ''b''&amp;minus;2.

==In astronomy==
*[[Messier object]] [[Messier 81|M81]], a [[visual magnitude|magnitude]] 8.5 [[spiral galaxy]] in the [[constellation]] [[Ursa Major]], also known as [[Bode's Galaxy]], and the first of what is known as the [[M81 Group]] of galaxies
*The [[New General Catalogue]] object [[NGC 81]], a [[spiral galaxy]] in the constellation [[Andromeda (constellation)|Andromeda]]

==In other fields==
'''Eighty-one''' is also:
*The number of squares on a [[shogi]] playing board
*The year AD '''81''', [[81 BC]], or [[1981]].
*The [[atomic number]] of [[thallium]]
*The symbolic number of the [[Hells Angels]] Motorcycle Club. 'H' and 'A' are the 8th and 1st letter of the alphabet, respectively.&lt;ref&gt;{{citation|title=Despite Outlaw Image, Hells Angels Sue Often|newspaper=[[The New York Times]]|first=Serge F.|last=Kovalevski|date=November 28, 2013|url=https://www.nytimes.com/2013/11/29/us/despite-outlaw-image-hells-angels-sue-often.html}}.&lt;/ref&gt;
*The title of a [[short film]] by Stephen Burke: ''[[81 (film)|81]]''{{importance inline}}
*The model number of [[Sinclair ZX81]]
*The number of the [[French department|department in France]] called [[Tarn (department)|Tarn]] [[Image:Tarn-Position.png|thumb|90px|[[Departments of France|Department]] 81 of France ([[Tarn (department)|Tarn]])]]
*The [[code for international direct dial]] phone calls to [[Japan]]
*One of two [[ISBN]] Group Identifiers for books published in [[India]]
*Number of stanzas or chapters in the [[Tao te Ching]] (in the most common arrangements).
*Number of provinces in [[Turkey]].
*Number of prayers said in the Rosary in each night.
*The 81 is a 1965 song by Candy and the Kisses.{{importance inline}}
*[[Artemis 81]] is a 1981 [[BBC]] TV science fiction drama.
*'The Eighty-One Brothers' is a Japanese fable&lt;ref&gt;http://www.sacred-texts.com/shi/jft2/jft207.htm The Eighty-One Brothers&lt;/ref&gt;

==In culture==
The Arabic characters for the numerals 8 and 1 are visible in the left palm of the human hand.
In China, 81 always reminds people [[People's Liberation Army]] as it was founded on August 1.
81 is used to refer to the motor-club Hell's Angels, since H and A are, respectively, the 8th and 1st letters of the alphabet.

== See also ==
* [[List of highways numbered 81]]

== References ==
{{Reflist}}

{{Integers|zero}}

{{DEFAULTSORT:81 (Number)}}
[[Category:Integers]]</text>
      <sha1>doghoe9fbdr9582b33yeuqqncluje2g</sha1>
    </revision>
  </page>
  <page>
    <title>Admissible numbering</title>
    <ns>0</ns>
    <id>2423078</id>
    <revision>
      <id>782060648</id>
      <parentid>775777836</parentid>
      <timestamp>2017-05-24T18:50:21Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3020">In [[computability theory]], '''admissible numberings''' are enumerations ([[Numbering (computability theory)|numberings]]) of the set of [[partial computable function]]s that can be converted ''to and from'' the standard numbering. These numberings are also called '''acceptable numberings''' and '''acceptable programming systems'''.

'''Rogers' equivalence theorem''' shows that all acceptable programming systems are equivalent to each other in the formal sense of numbering theory. 
 
== Definition ==

The formalization of computability theory by Kleene led to a particular universal partial computable function Ψ(''e'', ''x'') defined using the [[Kleene's T predicate|T predicate]]. This function is universal in the sense that it is partial computable, and for any partial computable function ''f'' there is an ''e'' such that, for all ''x'', ''f''(''x'') = Ψ(''e'',''x''), where the equality means that either both sides are undefined or both are defined and are equal.  It is common to write ψ&lt;sub&gt;''e''&lt;/sub&gt;(''x'') for Ψ(''e'',''x''); thus the sequence ψ&lt;sub&gt;0&lt;/sub&gt;, ψ&lt;sub&gt;1&lt;/sub&gt;, ... is an enumeration of all partial computable functions. Such enumerations are formally called computable numberings of the partial computable functions.

An arbitrary numbering η of partial functions is defined to be an admissible numbering if:
* The function ''H''(''e'',''x'') = η&lt;sub&gt;''e''&lt;/sub&gt;(''x'') is a partial computable function.
* There is a total computable function ''f'' such that, for all ''e'', η&lt;sub&gt;''e''&lt;/sub&gt; = ψ&lt;sub&gt;''f''(''e'')&lt;/sub&gt;.
* There is a total computable function ''g'' such that, for all ''e'', ψ&lt;sub&gt;''e''&lt;/sub&gt; = η&lt;sub&gt;''g''(''e'')&lt;/sub&gt;.
Here, the first bullet requires the numbering to be computable; the second requires that any index for the numbering η can be converted effectively to an index to the numbering ψ; and the third requires that any index for the numbering ψ can be effectively converted to an index for the numbering η.

== Rogers' equivalence theorem ==

[[Hartley Rogers, Jr.]] showed that a numbering η of the partial computable functions is admissible if and only if there is a total computable bijection ''p'' such that, for all η&lt;sub&gt;''e''&lt;/sub&gt; = ψ&lt;sub&gt;''p''(''e'')&lt;/sub&gt; (Soare 1987:25).

== See also ==
* [[Friedberg numbering]]

== References ==
* Y.L. Ershov (1999), "Theory of numberings", ''Handbook of Computability Theory'', E.R. Griffor (ed.), Elsevier, pp.&amp;nbsp;473&amp;ndash;506. {{ISBN|978-0-444-89882-1}}
* M. Machtey and P. Young (1978), ''An introduction to the general theory of algorithms'', North-Holland, 1978. {{ISBN|0-444-00226-X}}
* H. Rogers, Jr. (1967),  ''The Theory of Recursive Functions and Effective Computability'', second edition 1987, MIT Press. {{ISBN|0-262-68052-1}} (paperback), {{ISBN|0-07-053522-1}}
* R. Soare (1987), ''Recursively enumerable sets and degrees'', Perspectives in Mathematical Logic, Springer-Verlag. {{ISBN|3-540-15299-7}}

[[Category:Theory of computation]]
[[Category:Computability theory]]</text>
      <sha1>df7dby969zi7vv2jpz5mkuxa0o7gbpp</sha1>
    </revision>
  </page>
  <page>
    <title>Apotome (mathematics)</title>
    <ns>0</ns>
    <id>3785849</id>
    <revision>
      <id>646222645</id>
      <parentid>589959433</parentid>
      <timestamp>2015-02-08T18:53:19Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>per MOS:QUOTEMARK using [[Project:AWB|AWB]] (10808)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1817">{{about|the mathematical concept|the musical interval|Pythagorean apotome}}
In the [[history of mathematics|historical study of mathematics]], an '''apotome''' is a line segment formed from a longer line segment by breaking it into two parts, one of which is [[Commensurability (mathematics)|commensurable]] only in power to the whole; the other part is the apotome. In this definition, two line segments are said to be "commensurable only in power" when the ratio of their lengths is an [[irrational number]] but the ratio of their squared lengths is rational.&lt;ref&gt;{{citation
 | last = Knorr | first = Wilbur | authorlink = Wilbur Knorr
 | doi = 10.1090/S0273-0979-1983-15155-8
 | issue = 1
 | journal = [[Bulletin of the American Mathematical Society]]
 | mr = 699316
 | pages = 41–69
 | series = New Series
 | title = "La croix des mathématiciens": the Euclidean theory of irrational lines
 | volume = 9
 | year = 1983}}.&lt;/ref&gt;

Translated into modern algebraic language, an apotome can be interpreted as a [[quadratic irrational]] number formed by subtracting one [[square root]] of a rational number from another.
This concept of the apotome appears in [[Euclid's Elements]] beginning in book X, where Euclid defines two special kinds of apotomes. In an apotome of the first kind, the whole is rational, while in an apotome of the second kind, the part subtracted from it is rational; both kinds of apotomes also satisfy an additional condition.  Euclid Proposition XIII.6 states that, if a rational line segment is split into two pieces in the [[golden ratio]], then both pieces may be represented as apotomes.&lt;ref&gt;[http://aleph0.clarku.edu/~djoyce/java/elements/bookXIII/propXIII6.html Euclid Proposition XIII.6].&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Mathematical terminology]]


{{numtheory-stub}}</text>
      <sha1>dsvyxon0yajew4zjw1ajppksax6mxmb</sha1>
    </revision>
  </page>
  <page>
    <title>Broer–Kaup equations</title>
    <ns>0</ns>
    <id>42063759</id>
    <revision>
      <id>866577355</id>
      <parentid>859986687</parentid>
      <timestamp>2018-10-31T05:53:51Z</timestamp>
      <contributor>
        <username>Veryproicelandic</username>
        <id>23790359</id>
      </contributor>
      <comment>added a couple of links, removed that flag... added morefootnote flag...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1375">{{Multiple issues|
{{more footnotes|date=October 2018}}
{{Orphan|date=March 2017}}
}}

The '''Broer–Kaup [[equation]]s''' are a set of two coupled [[Nonlinear system|nonlinear]] [[partial differential equation]]s&lt;ref&gt;阎振亚著 《复杂非线性波的构造性理论及其应用》 第65页  科学出版社 2007年(in Chinese, SCIENCEP  2007)&lt;/ref&gt;

: &lt;math&gt;u_{y,t}+(2 u u_x)_x + 2v_{xx} - u_{xxy}=0&lt;/math&gt;
: &lt;math&gt;v_t + 2(vu)_x + v_{xx}=0&lt;/math&gt;

==References==
&lt;references/&gt;

#Graham W. Griffiths, William E. Shiesser, "Traveling Wave Analysis of Partial Differential Equations", p.&amp;nbsp;135 ''Academic Press''
# Richard H. Enns, George C. McCGuire, ''Nonlinear Physics'', Birkhauser, 1997
#Inna Shingareva, Carlos Lizárraga-Celaya,Solving Nonlinear Partial Differential Equations with Maple Springer.
#Eryk Infeld and George Rowlands,Nonlinear Waves,Solitons and Chaos,Cambridge 2000
#Saber Elaydi,An Introduction to Difference Equationns, Springer 2000
#Dongming Wang, Elimination Practice,Imperial College Press 2004
# David Betounes, Partial Differential Equations for Computational Science: With Maple and Vector Analysis Springer, 1998 {{ISBN|9780387983004}}
# George Articolo Partial Differential Equations &amp; Boundary Value Problems with Maple V Academic Press 1998 {{ISBN|9780120644759}}

[[Category:Nonlinear partial differential equations]]


{{math-stub}}</text>
      <sha1>chi72vpkcsbp014mkhtfiff3qan9gof</sha1>
    </revision>
  </page>
  <page>
    <title>Ciphertext</title>
    <ns>0</ns>
    <id>175560</id>
    <revision>
      <id>816599635</id>
      <parentid>816598867</parentid>
      <timestamp>2017-12-22T11:32:43Z</timestamp>
      <contributor>
        <username>XLinkBot</username>
        <id>6163802</id>
      </contributor>
      <comment>BOT--Reverting link addition(s) by [[:en:Special:Contributions/Robert,Wall.Delacruz|Robert,Wall.Delacruz]] to revision 809396660 (https://www.facebook.com/pages/create/?ref_type=sitefooter [\bfacebook\.com])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8673">{{About|encrypted information|an overview of cryptographic technology in general|Cryptography}}
[[File:Zimmermann Telegram.jpeg|thumb|right|250px|The [[Zimmermann Telegram]] (as it was sent from Washington to Mexico) encrypted as ciphertext.]]
[[File:Hollow Nickel Message.jpg|thumb|KGB ciphertext found in a [[Hollow Nickel Case|hollow nickel]] in Brooklyn in 1953]]

In [[cryptography]], '''ciphertext''' or '''cyphertext''' is the result of [[encryption]] performed on [[plaintext]] using an algorithm, called a [[cipher]].&lt;ref&gt;{{cite book |author=Berti, Hansche, Hare |title=Official (ISC)² Guide to the [[CISSP]] Exam |publisher=Auerbach Publications |year=2003 |pages=379 |isbn=0-8493-1707-X}}&lt;/ref&gt; Ciphertext is also known as encrypted or encoded information because it contains a form of the original plaintext that is unreadable by a human or computer without the proper cipher to decrypt it. [[Decryption]], the inverse of encryption, is the process of turning ciphertext into readable plaintext. Ciphertext is not to be confused with [[codetext]] because the latter is a result of a [[Code (cryptography)|code]], not a cipher.

== Conceptual underpinnings ==
Let &lt;math&gt;m\!&lt;/math&gt;  be the plaintext message that Alice wants to secretly transmit to Bob and let &lt;math&gt;E_k\!&lt;/math&gt; be the encryption cipher, where &lt;math&gt;_k\!&lt;/math&gt; is a [[secret key|cryptographic key]]. Alice must first transform the plaintext into ciphertext, &lt;math&gt;c\!&lt;/math&gt;, in order to securely send the message to Bob, as follows:

: &lt;math&gt;c = E_k(m). \!&lt;/math&gt;&lt;ref name="Fundamentals"&gt;{{cite book|isbn=0-7923-8675-2 |title=Fundamentals of Cryptology |publisher=Kluwer Academic Publishers |year=2000 |first=Henk C.A. |last=van Tilborg |page=3}}&lt;/ref&gt;

In a symmetric-key system, Bob knows Alice's encryption key. Once the message is encrypted, Alice can safely transmit it to Bob (assuming no one else knows the key). In order to read Alice's message, Bob must decrypt the ciphertext using &lt;math&gt;{E_k}^{-1}\!&lt;/math&gt; which is known as the decryption cipher, &lt;math&gt;D_k: \!&lt;/math&gt;

: &lt;math&gt;D_k(c) = D_k(E_k(m)) = m.\!&lt;/math&gt;&lt;ref name="Fundamentals" /&gt;

Alternatively, in a non-symmetric key system, everyone, not just Alice and Bob, knows the encryption key; but the decryption key cannot be inferred from the encryption key. Only Bob knows the decryption key &lt;math&gt;D_k,&lt;/math&gt; and decryption proceeds as 

:&lt;math&gt;D_k(c)=m.&lt;/math&gt;

== Types of ciphers ==
{{Main|Cipher}}
The [[history of cryptography]] began thousands of years ago. Cryptography uses a variety of different types of encryption. Earlier algorithms were performed by hand and are substantially different from modern [[algorithm]]s, which are generally executed by a machine.

=== Historical ciphers ===
Historical pen and paper ciphers used in the past are sometimes known as [[classical cipher]]s. They include:

* [[Substitution cipher]]: the units of plaintext are replaced with ciphertext (e.g., [[Caesar cipher]] and [[one-time pad]])
** [[Polyalphabetic substitution|Polyalphabetic substitution cipher]]: a substitution cipher using multiple substitution alphabets (e.g., [[Vigenère cipher]] and [[Enigma machine]])
** [[Polygraphic substitution]] cipher: the unit of substitution is a sequence of two or more letters rather than just one (e.g., [[Playfair cipher]])
* [[Transposition cipher]]: the ciphertext is a [[permutation]] of the plaintext (e.g., [[Rail fence|rail fence cipher]])

Historical ciphers are not generally used as a standalone encryption technique because they are quite easy to crack. Many of the classical ciphers, with the exception of the one-time pad, can be cracked using [[Brute force attack|brute force]].

=== Modern ciphers ===
Modern ciphers are more secure than classical ciphers and are designed  to withstand a wide range of attacks. An attacker should not be able to find the key used in a modern cipher, even if he knows any amount of plaintext and corresponding ciphertext. Modern encryption methods can be divided into the following categories:

* [[Private-key cryptography]] ([[symmetric key algorithm]]): the same key is used for encryption and decryption
* [[Public-key cryptography]] ([[asymmetric key algorithm]]): two different keys are used for encryption and decryption

In a symmetric key algorithm (e.g., [[Data Encryption Standard|DES]] and [[Advanced Encryption Standard|AES]]), the sender and receiver must have a shared key set up in advance and kept secret from all other parties; the sender uses this key for encryption, and the receiver uses the same key for decryption. In an asymmetric key algorithm (e.g., [[RSA (algorithm)|RSA]]), there are two separate keys: a ''public key'' is published and enables any sender to perform encryption, while a ''private key'' is kept secret by the receiver and enables only him to perform correct decryption.

Symmetric key ciphers can be divided into [[block cipher]]s and [[stream cipher]]s. Block ciphers operate on fixed-length groups of bits, called blocks, with an unvarying transformation. Stream ciphers encrypt plaintext digits one at a time on a continuous stream of data and the transformation of successive digits varies during the encryption process.

== Cryptanalysis ==
[[Image:Zimmermann-telegramm-offen.jpg|thumb|250px|right|The [[Zimmermann Telegram]] decrypted into plaintext (and translated into English).]]
{{Main|Cryptanalysis}}
Cryptanalysis is the study of methods for obtaining the meaning of encrypted information, without access to the secret information that is normally required to do so. Typically, this involves knowing how the system works and finding a secret key. Cryptanalysis is also referred to as codebreaking or [[Password cracking|cracking the code]]. Ciphertext is generally the easiest part of a [[cryptosystem]] to obtain and therefore is an important part of cryptanalysis. Depending on what information is available and what type of cipher is being analyzed, crypanalysts can follow one or more [[attack model]]s to crack a cipher.

=== Attack models ===
* [[Ciphertext-only attack|Ciphertext-only]]: the cryptanalyst has access only to a collection of ciphertexts or codetexts
* [[Known-plaintext attack|Known-plaintext]]: the attacker has a set of ciphertexts to which he knows the corresponding plaintext
* [[Chosen-plaintext attack]]: the attacker can obtain the ciphertexts corresponding to an arbitrary set of plaintexts of his own choosing
** Batch chosen-plaintext attack: where the cryptanalyst chooses all plaintexts before any of them are encrypted. This is often the meaning of an unqualified use of "chosen-plaintext attack".
** Adaptive chosen-plaintext attack: where the cryptanalyst makes a series of interactive queries, choosing subsequent plaintexts based on the information from the previous encryptions.
* [[Chosen-ciphertext attack]]: the attacker can obtain the plaintexts corresponding to an arbitrary set of ciphertexts of his own choosing
** [[Adaptive chosen-ciphertext attack]]
** [[Indifferent chosen-ciphertext attack]]
* [[Related-key attack]]: like a chosen-plaintext attack, except the attacker can obtain ciphertexts encrypted under two different keys. The keys are unknown, but the relationship between them is known; for example, two keys that differ in the one bit.

The ciphertext-only attack model is the weakest because it implies that the cryptanalyst has nothing but ciphertext. Modern ciphers rarely fail under this attack.&lt;ref&gt;{{cite book |last=Schneier |first=Bruce |title=Secrets &amp; Lies |publisher=Wiley Computer Publishing Inc |pages=90–91 |isbn=0-471-25311-1}}&lt;/ref&gt;

== Famous ciphertexts ==
{{Main|List of ciphertexts}}
[[Image:Shugborough inscription.jpg|thumb|650px|right|The Shugborough inscription, England]]
* The [[Babington Plot]] ciphers
* The [[Shugborough inscription]]
* The [[Zimmermann Telegram]]
* [[The Magic Words are Squeamish Ossifrage]]
* The [[cryptogram]] in "[[The Gold-Bug]]"
* [[Beale ciphers]]
* [[Kryptos]]
* [[Zodiac Killer]] ciphers

== See also ==

* [[:Books on cryptography]]
* [[:Category:Uncracked codes and ciphers]]
* [[:Cryptographic hash function]]
* [[:Frequency analysis]]
* [[:RED/BLACK concept]]

==References==
{{Reflist|2}}

== Further reading ==
{{Wiktionary}}
{{Commonscat| Ciphertexts}}
* Helen Fouché Gaines, “Cryptanalysis”, 1939, Dover. {{ISBN|0-486-20097-3}}
* [[David Kahn (writer)|David Kahn]], ''The Codebreakers - The Story of Secret Writing'' ({{ISBN|0-684-83130-9}}) (1967)
* [[Abraham Sinkov]], ''Elementary Cryptanalysis: A Mathematical Approach'', Mathematical Association of America, 1966. {{ISBN|0-88385-622-0}}

{{Cryptography navbox}}

[[Category:Cryptography]]</text>
      <sha1>ca0yhr6ezt9z9ps8btzjh2cdiz8masp</sha1>
    </revision>
  </page>
  <page>
    <title>Cirquent calculus</title>
    <ns>0</ns>
    <id>47037875</id>
    <revision>
      <id>865798682</id>
      <parentid>827206748</parentid>
      <timestamp>2018-10-26T06:35:53Z</timestamp>
      <contributor>
        <ip>2605:E000:1314:8410:AD11:499D:CAA9:C6A6</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8204">'''Cirquent calculus''' is a [[proof calculus]] which manipulates graph-style constructs termed ''cirquents'', as opposed to the traditional tree-style objects such as formulas or sequents. Cirquents come in a variety of forms, but they all share one main characteristic feature, making them different from the more traditional objects of syntactic manipulation. This feature is the ability to explicitly account for possible sharing of subcomponents between different components. For instance, it is possible to write an expression where two subexpressions ''F'' and ''E'', while neither one is a subexpression of the other, still have a common occurrence of a subexpression ''G'' (as opposed to having two different occurrences of ''G'', one in ''F'' and one in ''E''). 

[[File:Cirquents_vs_sequents.png|thumb|Cirquents can be thought of as collections of sequents with possibly shared elements]] The approach was introduced by [[Giorgi Japaridze|G. Japaridze]] in&lt;ref&gt;G.Japaridze, “[http://logcom.oxfordjournals.org/content/16/4/489.abstract Introduction to cirquent calculus and abstract resource semantics]”. Journal of Logic and Computation 16 (2006), pp. 489–532.&lt;/ref&gt; as an alternative proof theory capable of “taming” various nontrivial fragments of his [[computability logic]], which had otherwise resisted all axiomatization attempts within the traditional proof-theoretic frameworks.&lt;ref&gt;G.Japaridze, “[https://link.springer.com/article/10.1007/s00153-012-0313-8 The taming of recurrences in computability logic through cirquent calculus, Part I]”.Archive for Mathematical Logic 52 (2013),  pages 173-212.&lt;/ref&gt;&lt;ref&gt; G.Japaridze, [https://link.springer.com/article/10.1007/s00153-012-0314-7 “The taming of recurrences in computability logic through cirquent calculus, Part II]” Archive for Mathematical Logic 52 (2013),  pages 213–259.&lt;/ref&gt; The origin of the term “cirquent” is CIRcuit+seQUENT, as the simplest form of cirquents, while resembling [[Boolean circuit|circuits]] rather than formulas, can be thought of as collections of one-sided [[sequent]]s (for instance, sequents of a given level of a Gentzen-style proof tree) where some sequents may have shared elements.  

[[File:Cirquent_for_the_"two_out_of_three"_combination_of_resources.png|thumb|Cirquent for the "two out of three" combination of resources, inexpressible in linear logic]] The basic version of cirquent calculus in&lt;ref&gt;G.Japaridze, "[http://logcom.oxfordjournals.org/content/16/4/489.abstract Introduction to cirquent calculus and abstract resource semantics]". Journal of Logic and Computation 16 (2006), pp. 489–532.&lt;/ref&gt; was accompanied with an "''abstract resource semantics''" and the claim that the latter was an adequate formalization of the resource philosophy traditionally associated with [[linear logic]]. Based on that claim and the fact that the semantics induced a logic properly stronger than (affine) linear logic, Japaridze argued that linear logic was incomplete as a logic of resources. Furthermore, he argued that not only the deductive power but also the expressive power of linear logic was weak, for it, unlike cirquent calculus, failed to capture the ubiquitous phenomenon of resource sharing.&lt;ref&gt;G.Japaridze, “[http://logcom.oxfordjournals.org/content/18/6/983.abstract?keytype=ref&amp;ijkey=FWDFEWzz19JWDU0 Cirquent calculus deepened].” Journal of Logic and Computation 18 (2008), pp. 983–1028.&lt;/ref&gt;

[[File:Linear_logic_vs_classical_logic.png|thumb|Linear logic understands the displayed formula as the left cirquent, while classical logic as the right cirquent]] The resource philosophy of cirquent calculus sees the approaches of [[linear logic]] and [[classical logic]] as two extremes: the former does not allow any sharing at all, while in the latter “everything is shared that can be shared”. Unlike cirquent calculus, neither approach thus permits mixed cases where some identical subformulas are shared and some not.

Among the later-found applications of cirquent calculus was the use of it to define a semantics for purely propositional [[independence-friendly logic]].&lt;ref&gt; G.Japaridze, “[http://www.lmcs-online.org/ojs/viewarticle.php?id=717&amp;layout=abstract From formulas to cirquents in computability logic]”. Logical Methods is Computer Science 7 (2011),  Issue 2 , Paper 1, pp. 1–55.&lt;/ref&gt; The corresponding logic was axiomatized by W. Xu.&lt;ref&gt;W.Xu, “[http://jigpal.oxfordjournals.org/content/22/6/982 A propositional system induced by Japaridze's approach to IF logic]”. Logic Journal of the IGPL 22 (2014), pages 982–991.&lt;/ref&gt; 

Syntactically, cirquent calculi are [[deep inference]] systems with the unique feature of subformula-sharing. This feature has been shown to provide speedup for certain proofs. For instance, polynomial size analytic proofs for the propositional pigeonhole have been constructed.&lt;ref&gt;G.Japaridze, “[http://logcom.oxfordjournals.org/content/18/6/983.abstract?keytype=ref&amp;ijkey=FWDFEWzz19JWDU0 Cirquent calculus deepened].” Journal of Logic and Computation 18 (2008), pp. 983–1028.&lt;/ref&gt; Only quasipolynomial analytic proofs have been found for this principle in other deep inference systems.&lt;ref&gt;A. Das, “[http://www.anupamdas.com/items/WeakMonProofsPHP/WeakMonProofsPHP.pdf  On the pigeonhole and related principles in Deep inference and monotone systems]”.&lt;/ref&gt;  In resolution or analytic Gentzen-style systems, the pigeonhole principle is known to have only exponential size proofs.&lt;ref&gt;A. Haken, “The intractability of resolution”. Theoretical Computer Science 39 (1985), pp. 297-308.&lt;/ref&gt;


==Literature==
*M.Bauer, “[http://www.lmcs-online.org/ojs/viewarticle.php?id=1536&amp;layout=abstract The computational complexity of propositional cirquent calculus]”. Logical Methods in Computer Science 11 (2015), 
 
Issue 1, Paper 12, pp. 1–16.
*G.Japaridze, “[http://logcom.oxfordjournals.org/content/16/4/489.abstract Introduction to cirquent calculus and abstract resource semantics]”. Journal of Logic and Computation 16 (2006), pp. 489–532.
*G.Japaridze, “[http://logcom.oxfordjournals.org/content/18/6/983.abstract?keytype=ref&amp;ijkey=FWDFEWzz19JWDU0 Cirquent calculus deepened].” Journal of Logic and Computation 18 (2008), pp. 983–1028. 
* G.Japaridze, “[http://www.lmcs-online.org/ojs/viewarticle.php?id=717&amp;layout=abstract From formulas to cirquents in computability logic]”. Logical Methods in Computer Science 7 (2011),  Issue 2, Paper 1, pp. 1–55.
*G.Japaridze, “[https://link.springer.com/article/10.1007/s00153-012-0313-8 The taming of recurrences in computability logic through cirquent calculus, Part I]”.Archive for Mathematical Logic 52 (2013),  pages 173–212.
* G.Japaridze, [https://link.springer.com/article/10.1007/s00153-012-0314-7 “The taming of recurrences in computability logic through cirquent calculus, Part II]” Archive for Mathematical Logic 52 (2013),  pages 213–259.
*I. Mezhirov and N. Vereshchagin, ''[http://portal.acm.org/citation.cfm?id=1808347.1808575 On abstract resource semantics and computability logic]''. Journal of Computer and System Sciences 76 (2010), pp.&amp;nbsp;356–372.
*W.Xu and S.Liu, “[http://jigpal.oxfordjournals.org/content/20/1/317.abstract Soundness and completeness of the cirquent calculus system CL6 for computability logic]”. Logic Journal of the IGPL 20  (2012), pp. 317–330.
*W.Xu and S.Liu, “Cirquent calculus system CL8S versus calculus of structures system SKSg for propositional logic”. In: Quantitative Logic and Soft Computing. Guojun Wang, Bin Zhao and Yongming Li, eds. Singapore, World Scientific, 2012,   pp. 144–149.
*W.Xu, “[http://jigpal.oxfordjournals.org/content/22/6/982 A propositional system induced by Japaridze's approach to IF logic]”. Logic Journal of the IGPL 22 (2014), pages 982–991.
*W. Xu, ''[http://www.sciencedirect.com/science/article/pii/S1570868316300131 A cirquent calculus system with clustering and ranking]''. Journal of Applied Logic 16 (2016), pp.&amp;nbsp;37-49.

==References==
{{reflist}}

[[Category:Logical calculi]]
[[Category:Proof theory]]
[[Category:Logical expressions]]
[[Category:Non-classical logic]]


{{logic-stub}}</text>
      <sha1>2bkva6jqz2gn2jd4322pxe6m12iobl7</sha1>
    </revision>
  </page>
  <page>
    <title>Compass (drawing tool)</title>
    <ns>0</ns>
    <id>492445</id>
    <revision>
      <id>864018218</id>
      <parentid>863539777</parentid>
      <timestamp>2018-10-14T15:48:47Z</timestamp>
      <contributor>
        <username>Spinningspark</username>
        <id>3727527</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/49.191.143.232|49.191.143.232]] ([[User talk:49.191.143.232|talk]]): [[WP:CITEVAR]]. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9167">{{about|the drafting instrument||Compass (disambiguation)}}
{{refimprove|date = February 2018}}
[[File:Zirkel.jpg|thumb|A beam compass and a regular compass]]
[[File:IMB DQj3Fs.gif|thumb|Using a compass]]
[[File:Cyrkiel RB1.jpg|thumb|A thumbscrew compass for setting and maintaining a precise radius]]
[[File:Rotring S0214750 with Rapidograph 0.5 mm drawing 1.5–15 mm circles.jpg|thumb|A bow compass capable of drawing the smallest possible circles]]

A '''pair of compasses''', also known simply as a ''' bow compass''', is a [[technical drawing]] instrument that can be used for inscribing [[circle]]s or [[Arc (geometry)|arcs]]. As [[Caliper#Divider caliper|dividers]], they can also be used as tools to measure distances, in particular on [[map]]s. Compasses can be used for [[mathematics]], [[technical drawing|drafting]], [[navigation]] and other purposes.

Compasses are usually made of metal or plastic, and consist of two parts connected by a hinge which can be adjusted to allow the changing of the radius of the circle drawn. Typically one part has a spike at its end, and the other part a pencil, or sometimes a pen.

Prior to computerization, compasses and other tools for manual drafting were often packaged as a "bow set"&lt;ref&gt;[http://www.engineersupply.com/alvin-speed-bow-compass-set-366s.aspx a current vendor's product]&lt;/ref&gt; with [[interchangeable parts]]. By the mid–twentieth century, [[Technical drawing tool#Templates|circle templates]] supplemented the use of compasses. Today these facilities are more often provided by [[computer-aided design]] programs, so the physical tools serve mainly a didactic purpose in teaching [[geometry]], technical drawing, etc.

==Construction and parts==
Compasses are usually made of [[metal]] or [[plastic]], and consist of two parts connected by a [[hinge]] which can be adjusted to allow the changing of the [[radius]] of the [[circle]] drawn. Typically one part has a spike at its end, and the other part a [[pencil]], or sometimes a [[pen]]. 

===Handle===
The handle is usually about half an inch long. Users can grip it between their pointer finger and thumb.

===Legs===
There are two types of legs in a pair of compasses: the straight or the steady leg and the adjustable one. Each has a separate purpose; the steady leg serves as the basis or support for the needle point, while the adjustable leg can be altered in order to draw different sizes of circles.

===Hinge===
The screw on your hinge holds the two legs in its position; the hinge can be adjusted depending on desired stiffness. The tighter the screw, the better the compass’ performance.

===Needle point===
The needle point is located on the steady leg, and serves as the center point of circles that are drawn.

===Pencil lead===
The pencil lead draws the circle on a particular paper or material. Alternatively, an ink [[Nib (pen)|nib]] or attachment with a [[technical pen]] may be used.

===Adjusting nut===
This holds the pencil lead or pen in place.

==Uses==

Circles can be made by fastening one leg of the compasses into the [[paper]] with the spike, putting the pencil on the paper, and moving the pencil around while keeping the hinge on the same [[angle]]. The [[radius]] of the circle can be adjusted by changing the angle of the hinge.

Distances can be measured on a map using compasses with two spikes, also called a [[dividers|dividing compass]]. The hinge is set in such a way that the distance between the spikes on the map represents a certain distance in reality, and by measuring how many times the compasses fit between two points on the map the distance between those points can be calculated.

==Compasses and straightedge==
[[Compass-and-straightedge_construction|Compasses-and-straightedge constructions]] are used to illustrate principles of [[plane geometry]]. Although a real pair of compasses is used to draft visible illustrations, the ideal compass used in proofs is an abstract creator of perfect circles. The most rigorous definition of this abstract tool is the "collapsing compass"; having drawn a circle from a given point with a given radius, it disappears; it cannot simply be moved to another point and used to draw another circle of equal radius (unlike a real pair of compasses). [[Euclid]] showed in his second proposition (Book I of the ''[[Euclid's Elements|Elements]]'') that such a collapsing compass could be used to transfer a distance, proving that a collapsing compass could do anything a real compass can do.

==Variants==
A '''[[beam compass]]''' is an instrument with a wooden or brass beam and sliding sockets, or cursors, for drawing and dividing circles larger than those made by a regular pair of compasses.&lt;ref&gt;{{1728 |title= Beam-Compasses}}&lt;/ref&gt;&lt;!-- {{ref label|1728|1|^}} --&gt;

'''Scribe-compasses'''&lt;ref&gt;Fine Woodworking, Build a Fireplace Mantel, Mario Rodriquez, pgs. 73, 75, The Taunton Press, No. 184, June 2006&lt;/ref&gt; is an instrument used by carpenters and other tradesmen. Some compasses can be used to scribe circles, bisect angles and in this case to trace a line. It is the compass in the most simple form. Both branches are crimped metal. One branch has a pencil sleeve while the other branch is crimped with a fine point protruding from the end. A wing nut on the hinge serves two purposes: first it tightens the pencil and secondly it locks in the desired distance when the wing nut is turned clockwise.

'''Loose leg wing dividers'''&lt;ref&gt;The Carpenter's Manifesto, Jeffrey Ehrlich &amp; Marc Mannheimer, Holt, Rhinehart &amp; Winston, pg. 64, 1977&lt;/ref&gt;  are made of all forged steel. The pencil holder, thumb screws, brass pivot and branches are all well built. They are used for scribing circles and stepping off repetitive measurements&lt;ref&gt;Fine Woodworking, Laying out dovetails, Chris Gochnour, pg. 31, The Taunton Press, No. 190, April 2007&lt;/ref&gt; with some accuracy.

A '''[[proportional compass]]''', also known as a military compass or [[sector(instrument)|sector]], was an instrument used for calculation from the end of the sixteenth century until the nineteenth century. It consists of two rulers of equal length joined by a hinge. Different types of scales are inscribed on the rulers that allow for mathematical calculation.

A '''[[reduction compass]]''' is used to reduce or enlarge patterns while conserving angles.
{{Gallery
  |title=Compass variants
  |align=center
  |File:Beam Compass.jpg|Keuffel &amp; Esser Arrow [[beam compass]] set for drafting.
  |File:Compas_de_proportion_1.jpg|[[proportional compass]]
  |File:Ellipse compass-MHS 614-IMG 3827-gradient.jpg|18th-century ellipse-drawing compass ([[Musée d'histoire des sciences de la Ville de Genève|MHS Geneva]])
  |File:Reduction compass-MHS 1880-IMG 3829-gradient.jpg|Simple [[reduction compass]] ([[Musée d'histoire des sciences de la Ville de Genève|MHS Geneva]]).
  |File:Reduction compass-MHS 1914-IMG 3834-gradient.jpg|Sliding-pivot [[reduction compass]] by Nairne on London, 18th century ([[Musée d'histoire des sciences de la Ville de Genève|MHS Geneva]]).
}}

== As a symbol ==
[[File:Nuvola apps designer.svg|thumb|75px|A computer drawn compass, used to symbolize precise designing of applications.]]

A pair of compasses is often used as a symbol of precision and discernment. As such it finds a place in logos and symbols such as the [[Freemason]]s' [[Square and Compasses]] and in various [[computer icon]]s. English poet [[John Donne]] used the compass as a [[conceit]] in "[[A Valediction: Forbidding Mourning]]" (1611).
&lt;gallery&gt;
File:Scribe line A.jpg|Compass for tracing a line.
File:Scribe compass A.jpg|Flat branch, pivot wing nut, pencil sleeve branch of the scribe-compass.
File:Loose leg wing dividers.jpg|6 inch (15 cm) dividers made from forged steel.
File:Compas de proportion 1.jpg|One type of sector.
File:Coat of arms of East Germany.svg|A compass on the [[Coat of arms of East Germany|National Emblem of East Germany]] (German Democratic Republic).
File:Masonic silver pendant.jpg|The compass is a [[Square and Compasses|Masonic symbol]] that appears on jewellery such as this pendant.
&lt;/gallery&gt;

== See also ==
{{portal|Design|Mathematics}}
* [[Caliper#Divider caliper|Dividers]]
* [[Circle]]
* [[Geometrography]]
* Masonic [[Square and Compasses]]
* [[Technical drawing tools]]

==References==
&lt;references /&gt;
&lt;!-- #{{note label|1728|1|^}} {{1728}} [http://digicoll.library.wisc.edu/cgi-bin/HistSciTech/HistSciTech-idx?type=turn&amp;entity=HistSciTech000900240243&amp;isize=L]
# Fine Woodworking, Build a Fireplace Mantel, Mario Rodriquez, pp. 73, 75, The Taunton Press, No. 184, June 2006
# The Carpenter's Manifesto, Jeffrey Ehrlich &amp; Marc Mannheimer, Holt, Rhinehart &amp; Winston, p. 64, 1977
# Fine Woodworking, Laying out dovetails, Chris Gochnour, p. 31, The Taunton Press, No. 190, April 2007
 --&gt;

==External links==
{{Commons and category|Compass (drafting)|Compass_(drafting)}}
* [http://museum.nist.gov/object.asp?ObjID=9 Beam or trammel compass] (variant form)

{{Measuring and alignment tools}}
{{Authority control}}

[[Category:Mathematical tools]]
[[Category:Navigational equipment]]
[[Category:Stonemasonry tools]]
[[Category:Technical drawing]]</text>
      <sha1>9nfe4k7x59p8caplw8nmei43zm10pzg</sha1>
    </revision>
  </page>
  <page>
    <title>Conjugate coding</title>
    <ns>0</ns>
    <id>5205299</id>
    <revision>
      <id>864081594</id>
      <parentid>856768399</parentid>
      <timestamp>2018-10-15T00:11:50Z</timestamp>
      <contributor>
        <username>Darwin Naz</username>
        <id>33688010</id>
      </contributor>
      <comment>stub expansion</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2241">'''Conjugate coding''' is a cryptographic tool, introduced by [[Stephen Wiesner]]&lt;ref&gt;http://portal.acm.org/citation.cfm?id=1008908.1008920&lt;/ref&gt; in the late 1960s. It is part of the two applications Wiesner described for [[Quantum programming|quantum coding]], along with a method for creating fraud-proof banking notes. The application where the concept was based from was a method of transmitting multiple messages in such a way that reading one destroys the others. This is called quantum multiplexing and it uses [[Photon|photons]] polarized in conjugate bases as "[[Qubit|qubits]]" to pass information.&lt;ref&gt;{{Cite book|title=Emerging Trends in ICT Security: Chapter 9. A Survey of Quantum Key Distribution (QKD) Technologies|last=Morris|first=Jeffrey|last2=Grimaila|first2=Michael|last3=Hodson|first3=Douglas|last4=Jacques|first4=David|last5=Baumgartner|first5=Gerald|publisher=Morgan Kaufmann Publishers|year=2013|isbn=9780128070666|location=San Francisco, CA|pages=}}&lt;/ref&gt; Conjugate coding also is a simple extension of the random number generator.&lt;ref name=":0"&gt;{{Cite book|title=Broadband Quantum Cryptography|last=Rogers|first=Daniel|publisher=Morgan &amp; Claypool Publishers|year=2010|isbn=9781608450596|location=San Rafael, CA|pages=31}}&lt;/ref&gt; 

At the behest of [[Charles H. Bennett (computer scientist)|Charles Bennett]],&lt;ref name=":0" /&gt; Wiesner published the manuscript explaining the basic idea of conjugate coding with a number of examples but it was not embraced because it was significantly ahead of its time.&lt;ref&gt;{{Cite book|title=Quantum Bits and Quantum Secrets: How Quantum Physics is Revolutionizing Codes and Computers|last=Morsch|first=Oliver|publisher=John Wiley &amp; Sons|year=2008|isbn=9783527407101|location=Berlin|pages=157}}&lt;/ref&gt;  Because its publication has been rejected, it was developed to the world of public-key cryptography in the 1980s as [[Oblivious Transfer]], first by [[Michael O. Rabin|Michael Rabin]] and then by [[Shimon Even]]. It is used in the field of [[quantum computing]]. The initial concept of [[quantum cryptography]] developed by Bennett and [[Gilles Brassard]] was also based on this concept.&lt;ref name=":0" /&gt; 

==References==
&lt;references/&gt;


{{crypto-stub}}

[[Category:Cryptography]]</text>
      <sha1>mzm6ftf3bbdj7hqg3i49m6fa97etvtk</sha1>
    </revision>
  </page>
  <page>
    <title>Constructive Approximation</title>
    <ns>0</ns>
    <id>10986233</id>
    <revision>
      <id>797642788</id>
      <parentid>795170739</parentid>
      <timestamp>2017-08-28T11:30:57Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[Wikipedia:Bots/Requests for approval/KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1228">{{Infobox Journal
| cover	=	
| discipline	=	[[mathematics]]
| abbreviation	=	Constr. Approx.
| publisher	=	[[Springer Science+Business Media|Springer]]
| country	=	[[United States|U.S.]]
| ISSN		=	0176-4276
| eISSN		=	1432-0940	
| CODEN		=	
| history	=	1985–present
| website	=	http://www.math.vanderbilt.edu/~ca/
}}

'''''Constructive Approximation''''' is "an international mathematics journal dedicated to Approximations and Expansions and related research in computation, function theory, functional analysis, interpolation spaces and interpolation of operators, numerical analysis, space of functions, special functions, and applications."&lt;ref&gt;{{cite web | url = https://www.springer.com/journal/00365/about | title = Constructive Approximation| accessdate = 2007-04-30}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* [https://web.archive.org/web/20070425012247/http://www.math.vanderbilt.edu/~ca/ Constructive Approximation web site]

[[Category:Mathematics journals]]
[[Category:Approximation theory]]
[[Category:English-language journals]]
[[Category:Publications established in 1985]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Bimonthly journals]]


{{math-journal-stub}}</text>
      <sha1>6ysdcovm0ad78dgvrqj7yeuljr36jcn</sha1>
    </revision>
  </page>
  <page>
    <title>Constructive non-standard analysis</title>
    <ns>0</ns>
    <id>25454823</id>
    <revision>
      <id>825055205</id>
      <parentid>795170924</parentid>
      <timestamp>2018-02-11T06:10:44Z</timestamp>
      <contributor>
        <ip>184.23.19.160</ip>
      </contributor>
      <comment>/* References */Repair dead link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1535">In mathematics, '''constructive nonstandard analysis''' is a version of [[Abraham Robinson]]'s [[non-standard analysis]], developed by Moerdijk (1995), Palmgren (1998), Ruokolainen (2004).  Ruokolainen wrote: 

:The possibility of constructivization of nonstandard analysis was studied by Palmgren (1997, 1998, 2001). The model of constructive nonstandard analysis studied there is an extension of Moerdijk’s (1995) model for constructive nonstandard arithmetic.

==See also==
*[[Smooth infinitesimal analysis]]
*[[John Lane Bell]]

==References==
*[[Ieke Moerdijk]], ''A model for intuitionistic nonstandard arithmetic'', Annals of Pure and Applied Logic, vol. 73 (1995), pp. 37&amp;ndash;51. 
: "Abstract: This paper provides an explicit description of a model for intuitionistic non-standard arithmetic, which can be formalized in a constructive metatheory without the axiom of choice."[http://www.sciencedirect.com/science/journal/01680072]
*[[Erik Palmgren]], ''Developments in Constructive Nonstandard Analysis'', Bull. Symbolic Logic Volume 4, Number 3 (1998), 233&amp;ndash;272.
: "Abstract: We develop a constructive version of nonstandard analysis, extending [[Errett Bishop|Bishop]]'s constructive analysis with infinitesimal methods. ..."[http://projecteuclid.org/euclid.bsl/1182353577]
*[[Juha Ruokolainen]] 2004, ''Constructive Nonstandard Analysis Without Actual Infinity''[http://ethesis.helsinki.fi/julkaisut/mat/matem/vk/ruokolainen/construc.pdf]

{{Infinitesimals}}

[[Category:Non-standard analysis]]


{{mathlogic-stub}}</text>
      <sha1>hhy8xy5rhdlj3pv9wwnytou0xoq8yek</sha1>
    </revision>
  </page>
  <page>
    <title>David Aldous</title>
    <ns>0</ns>
    <id>14785295</id>
    <revision>
      <id>806645876</id>
      <parentid>779263978</parentid>
      <timestamp>2017-10-23T09:22:00Z</timestamp>
      <contributor>
        <username>Melcous</username>
        <id>20472590</id>
      </contributor>
      <comment>per [[Template:Infobox academic]] , only for those notable enough for their own wiki article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3491">{{Use dmy dates|date=November 2013}}
{{other people}}
{{Infobox scientist
| name              = David Aldous
| image             = David Aldous 2.jpeg
| image_size        = 250px
| caption           = David Aldous in [[Berkeley, California|Berkeley]]
| birth_date        = {{birth date and age|1952|07|13|df=y}}
| birth_place       = 
| death_date        = 
| death_place       = 
| nationality       = [[United Kingdom|British]], [[Americans|American]]
| fields            = [[Mathematics]]
| workplaces        = [[University of California, Berkeley]]
| alma_mater        = [[University of Cambridge]]
| doctoral_advisor  = [[David J. H. Garling]]
| doctoral_students =
| known_for         = 
| awards            = [[Loève Prize]] (1993)&lt;br&gt;[[Rollo Davidson Prize]] (1980)
}}
'''David John Aldous''', [[Fellow of the Royal Society|FRS]] (born 13 July 1952) is a [[mathematician]] known for his research on  [[probability theory]] and its applications, in particular in topics such as [[Exchangeable random variables|exchangeability]], [[Convergence of measures|weak convergence]], [[Markov chain mixing time]]s, the continuum random tree and stochastic coalescence. He entered [[St. John's College, Cambridge]], in 1970 and received his Ph.D. at the [[University of Cambridge]] in 1977 under his advisor, D. J. H. Garling.&lt;ref&gt;{{MathGenealogy|id=30967}}&lt;/ref&gt; Since 1979 Aldous has been on the faculty at [[University of California, Berkeley]].

He was awarded the [[Rollo Davidson Prize]] in 1980, the [[Loève Prize]] in 1993, and was elected a [[Fellow of the Royal Society|Fellow]] of the [[Royal Society]] in 1994. In 2004, Aldous was elected a Fellow of the [[American Academy of Arts and Sciences]].&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780-2010: Chapter A|url=http://www.amacad.org/publications/BookofMembers/ChapterA.pdf|publisher=American Academy of Arts and Sciences|accessdate=14 April 2011}}&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 3 November 2012.&lt;/ref&gt;

== Selected publications ==
===Books===
* {{cite book| last=Aldous | first=David |  &lt;!-- authorlink=David Aldous --&gt; | title=Probability approximations via the Poisson clumping heuristic | series=Applied Mathematical Sciences | volume=77 | publisher=Springer-Verlag | location=New York | year=1989 | pages=xvi+269 | isbn=0-387-96899-7 | mr=969362 }}

===Papers===
* Aldous, David,  "Deterministic and stochastic models for coalescence (aggregation and coagulation): a review of the mean-field theory for probabilists".  Bernoulli 5  (1999)  pp.&amp;nbsp;3&amp;ndash;48.
* Aldous, David,  "Exchangeability and related topics".  Lecture Notes in Math., 1117 (1985) pp 1&amp;ndash;198. Springer, Berlin.

==References==
{{Reflist}}

==External links==
* {{Official website}}
* {{IMO results|id=10143}}

{{Authority control}}
{{DEFAULTSORT:Aldous, David}}
[[Category:University of California, Berkeley faculty]]
[[Category:Probability theorists]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:1952 births]]
[[Category:Living people]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:International Mathematical Olympiad participants]]

{{US-mathematician-stub}}</text>
      <sha1>c7sblwv6o5yxd4vnaupdikx7xxyuutv</sha1>
    </revision>
  </page>
  <page>
    <title>Density matrix</title>
    <ns>0</ns>
    <id>62844</id>
    <revision>
      <id>866967508</id>
      <parentid>866892644</parentid>
      <timestamp>2018-11-02T19:10:24Z</timestamp>
      <contributor>
        <username>Sbyrnes321</username>
        <id>416440</id>
      </contributor>
      <comment>Undid revision 866892644 by [[Special:Contributions/107.77.235.227|107.77.235.227]] ([[User talk:107.77.235.227|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32211">{{distinguish|dense matrix}}
{{See also|Quantum statistical mechanics}}
{{Quantum mechanics|cTopic=Advanced topics}}
A '''density matrix''' is a [[matrix (math)|matrix]] that describes the statistical state of a system in [[quantum mechanics]]. The density matrix is especially helpful for dealing with ''mixed states'', which consist of a [[statistical ensemble]] of several different quantum systems. The opposite of a mixed state is a [[pure state]]. [[Quantum state|State vectors]], also called [[bra-ket notation|kets]], describe only pure states, whereas a density matrix can describe both pure and mixed states.

Describing a quantum state by its density matrix is a fully general alternative formalism to describing a quantum state by its ket (state vector) or by its statistical ensemble of kets. However, in practice, it is often most convenient to use density matrices for calculations involving mixed states, and to use kets for calculations involving only pure states.

The density matrix is the quantum-mechanical analogue to a [[phase space|phase-space]] [[probability measure]] (probability distribution of position and momentum) in classical [[statistical mechanics]].

Mixed states arise in situations where the experimenter does not know which particular states are being manipulated. Examples include a [[canonical ensemble|system in thermal equilibrium]] at a temperature above [[absolute zero]], or a system with an uncertain or randomly varying preparation history (so one does not know which pure state the system is in). Also, if a quantum system has two or more subsystems that are [[Quantum entanglement|entangled]], then each subsystem must be treated as a mixed state even if the complete system is in a pure state.&lt;ref&gt;{{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | page = 419 | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics|publisher=Springer}}&lt;/ref&gt; The density matrix is also a crucial tool in [[quantum decoherence]] theory.

The density matrix is a representation of a [[linear operator]] called the '''density operator'''. The density matrix is obtained from the density operator by choice of [[basis (linear algebra)|basis]] in the underlying space. In practice, the terms ''density matrix'' and ''density operator'' are often used interchangeably. Both matrix and operator are [[self-adjoint]] (or [[Hermitian matrix|Hermitian]]),  [[positive-semidefinite matrix|positive semi-definite]], of [[trace class|trace]] one, and  may
be [[Dimension (vector space)|infinite-dimensional]].&lt;ref&gt;{{Citation | last =  Fano | first = Ugo | authorlink = Ugo Fano | year = 1957 | title = Description of States in Quantum Mechanics by Density Matrix and Operator Techniques | journal =  Reviews of Modern Physics | volume = 29 | pages = 74–93| doi =10.1103/RevModPhys.29.74 | postscript =  . | bibcode=1957RvMP...29...74F}}&lt;/ref&gt;

==History==
The formalism of density operators and matrices was introduced by [[John von Neumann]]&lt;ref&gt;{{Citation | last = von Neumann | first = John  | year = 1927 | authorlink = John von Neumann  |title=Wahrscheinlichkeitstheoretischer Aufbau der Quantenmechanik | journal = Göttinger Nachrichten | volume = 1|pages= 245–272|url=https://eudml.org/doc/59230}}&lt;/ref&gt; in 1927 and independently, but less systematically by [[Lev Landau]]&lt;ref name="PT"&gt;{{Citation| title=Density functional theory | author=Schlüter, Michael and Lu Jeu Sham | journal=Physics Today | year=1982 | volume=35 | pages=36 | doi=10.1063/1.2914933 | issue=2 | bibcode=1982PhT....35b..36S }}&lt;/ref&gt; and [[Felix Bloch]]&lt;ref name="Ugo "&gt;{{Citation  | title=Density matrices as polarization vectors | author=Ugo Fano | journal=Rendiconti Lincei |date=June 1995 | volume=6 | issue=2 | pages=123–130 | doi=10.1007/BF03001661}}&lt;/ref&gt; in 1927 and 1946 respectively.

== Pure and mixed states ==
In [[mathematical formulation of quantum mechanics#Mathematical structure of quantum mechanics|quantum mechanics]], the state of a quantum system is represented by a [[quantum state|state vector]], denoted &lt;math&gt;| \psi \rangle &lt;/math&gt; (and pronounced ''[[bra–ket notation|ket]]''). A quantum system with a state vector &lt;math&gt;| \psi \rangle &lt;/math&gt; is called a ''pure state''. However, it is also possible for a system to be in a [[statistical ensemble]] of different state vectors: For example, there may be a 50% probability that the state vector is &lt;math&gt;| \psi_1 \rangle &lt;/math&gt; and a 50% chance that the state vector is &lt;math&gt;| \psi_2 \rangle &lt;/math&gt;. This system would be in a ''mixed state''. The density matrix is especially useful for mixed states, because any state, pure or mixed, can be characterized by a single density matrix.

A mixed state is different from a [[quantum superposition]]. The probabilities in a mixed state are classical probabilities (as in the probabilities one learns in classic probability theory / statistics), unlike the quantum probabilities in a quantum superposition.  In fact, a quantum superposition of pure states is another pure state, for example &lt;math&gt;| \psi \rangle = (| \psi_1 \rangle + | \psi_2 \rangle)/\sqrt{2} &lt;/math&gt;. In this case, the coefficients &lt;math&gt;1/\sqrt{2}&lt;/math&gt; are not probabilities, but rather [[probability amplitude]]s.

=== Example: light polarization ===
[[File:vertical polarization.svg|right|thumb|200px|The incandescent light bulb (1) emits completely random polarized  photons (2)  with mixed state density matrix&lt;br /&gt;&lt;center&gt;&lt;math&gt;\begin{bmatrix}
 0.5 &amp; 0  \\
 0 &amp; 0.5  \\
\end{bmatrix}
&lt;/math&gt; &lt;span style="vertical-align:bottom"&gt;。&lt;/span&gt;&lt;/center&gt;&lt;br /&gt;After passing through vertical plane polarizer (3), the remaining photons are all vertically polarized (4) and have pure state density matrix&lt;br /&gt;&lt;center&gt;&lt;math&gt;\begin{bmatrix}
 1 &amp; 0  \\
 0 &amp; 0  \\
\end{bmatrix}
&lt;/math&gt; &lt;span style="vertical-align:bottom"&gt;。&lt;/span&gt;&lt;/center&gt;]]
An example of pure and mixed states is [[light polarization]]. Photons can have two [[circular polarization|helicities]], corresponding to two orthogonal quantum states, &lt;math&gt;|R\rangle&lt;/math&gt; (right [[circular polarization]]) and &lt;math&gt;|L\rangle&lt;/math&gt; (left [[circular polarization]]). A photon can also be in a superposition state, such as &lt;math&gt;(|R\rangle+|L\rangle)/\sqrt{2}&lt;/math&gt; (vertical polarization) or &lt;math&gt;(|R\rangle-|L\rangle)/\sqrt{2}&lt;/math&gt; (horizontal polarization). More generally, it can be in any state &lt;math&gt;\alpha|R\rangle+\beta|L\rangle&lt;/math&gt; (with &lt;math&gt;|\alpha|^2+|\beta|^2=1&lt;/math&gt;), corresponding to [[linear polarization|linear]], [[circular polarization|circular]], or [[elliptical polarization]]. If we pass &lt;math&gt;(|R\rangle+|L\rangle)/\sqrt{2}&lt;/math&gt; polarized light through a [[circular polarizer]] which allows either only &lt;math&gt;|R\rangle&lt;/math&gt; polarized light, or only &lt;math&gt;|L\rangle&lt;/math&gt; polarized light, intensity would be reduced by half in both cases. This may make it ''seem'' like half of the photons are in state &lt;math&gt;|R\rangle&lt;/math&gt; and the other half in state &lt;math&gt;|L\rangle&lt;/math&gt;. But this is not correct: Both &lt;math&gt;|R\rangle&lt;/math&gt; and &lt;math&gt;|L\rangle&lt;/math&gt; photons are partly absorbed by a vertical [[linear polarizer]], but the &lt;math&gt;(|R\rangle+|L\rangle)/\sqrt{2}&lt;/math&gt; light will pass through that polarizer with no absorption whatsoever.

However, [[unpolarized light]] (such as the light from an [[incandescent light bulb]]) is different from any state like &lt;math&gt;\alpha|R\rangle+\beta|L\rangle&lt;/math&gt; (linear, circular, or elliptical polarization). Unlike linearly or elliptically polarized light, it passes through a polarizer with 50% intensity loss whatever the orientation of the polarizer; and unlike circularly polarized light, it cannot be made linearly polarized with any [[wave plate]] because randomly oriented polarization will emerge from a wave plate with random orientation. Indeed, unpolarized light cannot be described as ''any'' state of the form &lt;math&gt;\alpha|R\rangle+\beta|L\rangle&lt;/math&gt; in a definite sense. However, unpolarized light ''can'' be described with ensemble averages, e.g. that each photon is either &lt;math&gt;| R \rangle &lt;/math&gt; with 50% probability or &lt;math&gt;| L \rangle &lt;/math&gt; with 50% probability. The same behavior would occur if each photon was either vertically polarized with 50% probability or horizontally polarized with 50% probability.

Therefore, unpolarized light cannot be described by any pure state, but can be described as a [[statistical ensemble]] of pure states in at least two ways (the ensemble of half left and half right circularly polarized, or the ensemble of half vertically and half horizontally linearly polarized). These two ensembles are completely indistinguishable experimentally, and therefore they are considered the same mixed state. One of the advantages of the density matrix is that there is just one density matrix for each mixed state, whereas there are many statistical ensembles of pure states for each mixed state. Nevertheless, the density matrix contains all the information necessary to calculate any measurable property of the mixed state.

Where do mixed states come from? To answer that, consider how to generate unpolarized light. One way is to use a system in [[thermal equilibrium]], a statistical mixture of enormous numbers of [[Microstate (statistical mechanics)|microstates]], each with a certain probability (the [[Boltzmann factor]]), switching rapidly from one to the next due to [[thermal fluctuations]]. Thermal randomness explains why an [[incandescent light bulb]], for example, emits unpolarized light. A second way to generate unpolarized light is to introduce uncertainty in the preparation of the system, for example, passing it through a [[birefringent crystal]] with a rough surface, so that slightly different parts of the beam acquire different polarizations. A third way to generate unpolarized light uses an [[EPR paradox|EPR]] setup: A radioactive decay can emit two photons traveling in opposite directions, in the quantum state &lt;math&gt;(|R,L\rangle+|L,R\rangle)/\sqrt{2}&lt;/math&gt;. The two photons ''together'' are in a pure state, but if you only look at one of the photons and ignore the other, the photon behaves just like unpolarized light.

More generally, mixed states commonly arise from a statistical mixture of the starting state (such as in thermal equilibrium), from uncertainty in the preparation procedure (such as slightly different paths that a photon can travel), or from looking at a subsystem entangled with something else.

== Definition ==
For a finite-dimensional function space, the most general density operator is of the form

:&lt;math&gt; \rho = \sum_j p_j |\psi_j \rangle \langle \psi_j| &lt;/math&gt;

where the coefficients ''p''&lt;sub&gt;''j''&lt;/sub&gt; are non-negative and add up to one, and &lt;math&gt;\textstyle |\psi_j \rangle \langle \psi_j |&lt;/math&gt; is an [[outer product]] written in [[bra-ket notation]].  This represents a mixed state, with probability ''p''&lt;sub&gt;''j''&lt;/sub&gt; that the system is in the pure state &lt;math&gt;\textstyle |\psi_j \rangle&lt;/math&gt;.

For the above example of unpolarized light, the density operator is

:&lt;math&gt;\rho ={\tfrac {1}{2}}|R\rangle \langle R|+{\tfrac {1}{2}}|L\rangle \langle L|.&lt;/math&gt;

where &lt;math&gt;\textstyle |L \rangle&lt;/math&gt; is the left-circularly-polarized photon state and &lt;math&gt;\textstyle |R \rangle&lt;/math&gt; is the right-circularly-polarized photon state.

=== Different statistical ensembles with the same density matrix ===

An earlier section gave an example of two statistical ensembles of pure states that have the same density operator: unpolarized light can be described as both 50% right-circular-polarized and 50% left-circular-polarized, or 50% horizontally-polarized and 50% vertically-polarized. Such equivalent ensembles or mixtures cannot be distinguished by any measurement. This equivalence can be characterized precisely. Two ensembles ψ,  ψ' define the same density operator [[if and only if]] there is a [[Unitary operator]] U with

:&lt;math&gt; | \psi_i'\rangle \sqrt {p_i'} = \sum_{j} u_{ij} | \psi_j\rangle \sqrt {p_j}~.&lt;/math&gt;

This is simply a restatement of the following fact from linear algebra: for two square matrices {{mvar|M}} and {{mvar|N}}, ''M M''&lt;sup&gt;*&lt;/sup&gt; = ''N N''&lt;sup&gt;*&lt;/sup&gt; if and only if ''M'' = ''NU'' for some unitary {{mvar|U}}. (See [[square root of a matrix]] for more details.) Thus there is a unitary freedom in the ket mixture or ensemble that gives the same density operator.  However, if the kets making up the mixture are restricted to be a specific [[orthonormal]] basis, then the original probabilities ''p''&lt;sub&gt;''j''&lt;/sub&gt; are uniquely recoverable from that basis, as the eigenvalues of the density matrix.

=== Mathematical properties and purity condition ===

In operator language, a density operator is a [[positive-definite matrix|positive semidefinite]], [[Hermitian matrix|Hermitian]] operator  of [[trace class operator|trace 1]] acting on the state space.&lt;ref&gt;{{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | page = 423 |publisher = Springer | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics}}&lt;/ref&gt; A density operator describes a [[Purity (quantum mechanics)|pure]] state if it is a [[Rank (linear algebra)|rank]] one projection. Equivalently, a density operator ρ describes a [[Purity (quantum mechanics)|pure]] state if and only if
: &lt;math&gt; \rho = \rho^2&lt;/math&gt;,
i.e. the state is [[idempotent]]. This is true regardless of whether {{mvar|H}} is finite-dimensional or not.

Geometrically, when the state is not expressible as a [[convex combination]] of other states, it is a pure state.&lt;ref&gt;{{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | page = 439 |publisher = Springer | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics}}&lt;/ref&gt;  The family of mixed states is a convex set and a state is pure if it is an [[extremal point]] of that set.

It follows from the [[compact operator on Hilbert space|spectral theorem for compact self-adjoint operators]] that every mixed state is a countable convex combination of pure states.  This representation is not unique. Furthermore, a theorem of [[Andrew Gleason]] states that certain functions defined on the family of projections and taking values in [0,1] (which can be regarded as quantum analogues of probability measures) are determined by unique mixed states. See [[Quantum logic#Statistical structure|quantum logic]] for more details.

== Measurement ==
Let ''A'' be an [[observable]] of the system, and suppose the ensemble is in a mixed state such that each of the pure states &lt;math&gt;\textstyle |\psi_j\rangle&lt;/math&gt; occurs with probability ''p&lt;sub&gt;j&lt;/sub&gt;''. Then the corresponding density operator is:

:&lt;math&gt;\rho = \sum_j p_j |\psi_j \rangle \langle \psi_j| .&lt;/math&gt;

The [[Expectation value (quantum mechanics)|expectation value]] of the measurement can be calculated by extending from the case of pure states (see [[Measurement in quantum mechanics]]):

:&lt;math&gt; \langle A \rangle = \sum_j p_j \langle \psi_j|A|\psi_j \rangle = \sum_j p_j \operatorname{tr}\left(|\psi_j \rangle \langle \psi_j|A \right) = \sum_j  \operatorname{tr}\left(p_j |\psi_j \rangle \langle \psi_j|A\right)  =   \operatorname{tr}\left(\sum_j p_j |\psi_j \rangle \langle \psi_j|A\right) = \operatorname{tr}(\rho A),&lt;/math&gt;

where &lt;math&gt;\operatorname{tr}&lt;/math&gt; denotes [[trace (linear algebra)|trace]]. Thus, the familiar expression &lt;math&gt;\langle A\rangle=\langle\psi|A|\psi\rangle&lt;/math&gt; for pure states is replaced by
:&lt;math&gt; \langle A \rangle = \operatorname{tr}(\rho A)&lt;/math&gt;
for mixed states.

Moreover, if ''A'' has spectral resolution

:&lt;math&gt;A = \sum_i a_i |a_i \rangle \langle a_i| = \sum _i a_i P_i,&lt;/math&gt;

where &lt;math&gt;P_i = |a_i \rangle \langle a_i|&lt;/math&gt;, the corresponding density operator after the measurement is given by:

:&lt;math&gt;\; \rho ' = \sum_i P_i \rho P_i.&lt;/math&gt;

Note that the above density operator describes the full ensemble after measurement. The sub-ensemble for which the measurement result was the particular value ''a&lt;sub&gt;i&lt;/sub&gt;'' is described by the different density operator

:&lt;math&gt;\rho_i' = \frac{P_i \rho P_i}{\operatorname{tr}[\rho P_i]}.&lt;/math&gt;

This is true assuming that &lt;math&gt;\textstyle |a_i\rangle&lt;/math&gt; is the only eigenket (up to [[phase factor|phase]]) with [[eigenvalue]] ''a&lt;sub&gt;i&lt;/sub&gt;''; more generally, ''P&lt;sub&gt;i&lt;/sub&gt;'' in this expression would be replaced by the [[projection operator]] into the [[eigenspace|eigen''space'']] corresponding to eigenvalue ''a&lt;sub&gt;i&lt;/sub&gt;''.

More generally, suppose &lt;math&gt;\Phi&lt;/math&gt; is a function that associates to each observable ''A''  a number &lt;math&gt;\Phi(A)&lt;/math&gt;, which we may think of as the "expectation value" of ''A''. If &lt;math&gt;\Phi&lt;/math&gt; satisfies some natural properties (such as giving positive values on positive operators), then there is a unique density matrix &lt;math&gt;\rho&lt;/math&gt; such that
:&lt;math&gt;\Phi(A)=\operatorname{tr}(\rho A)&lt;/math&gt;
for all ''A''.&lt;ref&gt;See Theorem 19.9 in {{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics|publisher=Springer}}&lt;/ref&gt; That is to say, any reasonable "family of expectation values" is representable by a density matrix. This observation suggests that density matrices are the most general notion of a quantum state.

== Entropy ==
The [[von Neumann entropy]] &lt;math&gt;S&lt;/math&gt; of a mixture can be expressed in terms of the eigenvalues of &lt;math&gt;\rho&lt;/math&gt; or in terms of the [[Trace (linear algebra)|trace]] and [[Matrix logarithm|logarithm]] of the density operator &lt;math&gt;\rho&lt;/math&gt;. Since &lt;math&gt;\rho&lt;/math&gt; is a positive semi-definite operator, it has a [[spectral theorem|spectral decomposition]] such that &lt;math&gt;\rho = \textstyle\sum_i \lambda_i |\varphi_i\rangle \langle\varphi_i|&lt;/math&gt;, where &lt;math&gt;|\varphi_i\rangle&lt;/math&gt; are orthonormal vectors, &lt;math&gt;\lambda_i &gt; 0&lt;/math&gt;, and &lt;math&gt;\textstyle \sum \lambda_i = 1&lt;/math&gt;. Then the entropy of a quantum system with density matrix &lt;math&gt;\rho&lt;/math&gt; is

:&lt;math&gt;S = -\sum_i \lambda_i \ln\lambda_i = -\operatorname{tr}(\rho \ln\rho).&lt;/math&gt;

This entropy can increase, but never decrease, with a projective measurement. However, generalised measurements can decrease entropy.&lt;ref&gt;{{Citation | last1=Nielsen | first1=Michael | last2=Chuang | first2=Isaac | title=Quantum Computation and Quantum Information | publisher=[[Cambridge University Press]] | isbn=978-0-521-63503-5 | year=2000}}. Chapter 11:  Entropy and information, Theorem 11.9, "Projective measurements cannot decrease entropy".&lt;/ref&gt;&lt;ref name="everett56"&gt;{{Citation | last1=Everett | first1=Hugh | author1-link=Hugh Everett | title=The Many-Worlds Interpretation of Quantum Mechanics | publisher=[[Princeton University Press]] | series=Princeton Series in Physics | isbn=978-0-691-08131-1  | year=1973 | chapter=The Theory of the Universal Wavefunction (1956) Appendix I. "Monotone decrease of information for stochastic processes"  | pages=128–129}}&lt;/ref&gt;  The entropy of a pure state is zero, while that of a proper mixture is always greater than zero.  Therefore, a pure state may be converted into a mixture by a measurement, but a proper mixture can ''never'' be converted into a pure state.  Thus the act of measurement induces a fundamental [[irreversible process|irreversible]] change on the density matrix; this is analogous to the "collapse" of the state vector, or [[wavefunction collapse]]. Perhaps counterintuitively, the measurement actually ''decreases information'' by erasing quantum interference in the composite system, see [[quantum entanglement]], [[einselection]], and [[quantum decoherence]].

A subsystem of a larger system can be turned from a mixed to a pure state, but only by increasing the von Neumann entropy elsewhere in the system. This is analogous to how the entropy of an object can be lowered by putting it in a refrigerator: The air outside the refrigerator's heat exchanger warms up, gaining even more entropy than was lost by the object in the refrigerator. See [[second law of thermodynamics]]. See [[Entropy in thermodynamics and information theory]].

== Systems and subsystems==
Another motivation for considering density matrices comes from consideration of systems and their subsystems.
Suppose we have two quantum systems, described by Hilbert spaces &lt;math&gt;\mathcal{H}_1&lt;/math&gt; and &lt;math&gt;\mathcal{H}_2&lt;/math&gt;. The composite system is then the [[tensor product]] &lt;math&gt;\mathcal{H}_1\otimes\mathcal{H}_2&lt;/math&gt; of the two Hilbert spaces. Suppose now that the composite system is in a pure state &lt;math&gt;\psi\in\mathcal{H}_1\otimes\mathcal{H}_2&lt;/math&gt;. If &lt;math&gt;\psi&lt;/math&gt; happens to have the special form &lt;math&gt;\psi=\psi_1\otimes\psi_2&lt;/math&gt;, then we may reasonably say that the state of the first subsystem is &lt;math&gt;\psi_1&lt;/math&gt;. In this case, we say that the two systems are not entangled. In general, however, &lt;math&gt;\psi&lt;/math&gt; will not decompose as a single tensor product of vectors in &lt;math&gt;\mathcal{H}_1&lt;/math&gt; and &lt;math&gt;\mathcal{H}_2&lt;/math&gt;. If &lt;math&gt;\psi&lt;/math&gt; cannot be decomposed as a single tensor product of states in the component systems, we say that the two systems are entangled. In that case, there is no reasonable way to associate a pure state &lt;math&gt;\psi_1\in\mathcal{H}_1&lt;/math&gt; to the state &lt;math&gt;\psi\in\mathcal{H}_1\otimes\mathcal{H}_2&lt;/math&gt;.&lt;ref&gt;See Sections 19.1 and 19.5 in {{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics|publisher=Springer}}&lt;/ref&gt;

If, for example, we have a wave function &lt;math&gt;\psi(x_1,x_2)&lt;/math&gt; describing the state of two particles, there is no natural way to construct a wave function (i.e., pure state) &lt;math&gt;\psi_1(x_1)&lt;/math&gt; that describes the states of the first particle—unless &lt;math&gt;\psi(x_1,x_2)&lt;/math&gt; happens to be a product of a function &lt;math&gt;\psi_1(x_1)&lt;/math&gt; and a function &lt;math&gt;\psi_2(x_2)&lt;/math&gt;.

The upshot of the preceding discussion is that even if the total system is in a pure state, the various subsystems that make it up will typically be in mixed states. Thus, the use of density matrices is unavoidable.

On the other hand, whether the composite system is in a pure state or a mixed state, we can perfectly well construct a density matrix that describes the state of &lt;math&gt;\mathcal{H}_1&lt;/math&gt;. Denote the density matrix of the composite system of two systems by &lt;math&gt;\rho&lt;/math&gt;. Then the state of, say, &lt;math&gt;\mathcal{H}_1&lt;/math&gt;, is described by a [[Reduced density matrix#Reduced density matrices|reduced density operator]], given by taking the "partial trace" of &lt;math&gt;\rho&lt;/math&gt; over &lt;math&gt;\mathcal{H}_2&lt;/math&gt;.&lt;ref&gt;See Theorem 19.13 in {{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics|publisher=Springer}}&lt;/ref&gt;

If the state of &lt;math&gt;\mathcal{H}_1\otimes\mathcal{H}_2&lt;/math&gt; happens to be a density matrix of the special form &lt;math&gt;\rho=\rho_1\otimes\rho_2&lt;/math&gt; where &lt;math&gt;\rho_1&lt;/math&gt; and &lt;math&gt;\rho_2&lt;/math&gt; are density matrices on &lt;math&gt;\mathcal{H}_1&lt;/math&gt; and &lt;math&gt;\mathcal{H}_2&lt;/math&gt;, then the partial trace of &lt;math&gt;\rho&lt;/math&gt; with respect to &lt;math&gt;\mathcal{H}_2&lt;/math&gt; is just &lt;math&gt;\rho_1&lt;/math&gt;. A typical &lt;math&gt;\rho&lt;/math&gt; will not be of this form, however.

== {{anchor|The Von Neumann equation for time evolution}}The von Neumann equation for time evolution ==
{{See also|Liouville's theorem (Hamiltonian)#Quantum Liouville equation}}
Just as the [[Schrödinger equation]] describes how pure states evolve in time, the '''von Neumann equation''' (also known as the '''Liouville–von Neumann equation''') describes how a density operator evolves in time (in fact, the two equations are equivalent, in the sense that either can be derived from the other.) The von Neumann equation dictates that&lt;ref&gt;{{citation |title=The theory of open quantum systems|last1= Breuer |first1=Heinz|last2= Petruccione|first2=Francesco|page=110|isbn=978-0-19-852063-4|url=https://books.google.com/books?id=0Yx5VzaMYm8C&amp;pg=PA110 |year=2002}}&lt;/ref&gt;&lt;ref&gt;{{Citation|url=https://books.google.com/books?id=o-HyHvRZ4VcC&amp;pg=PA16 |title=Statistical mechanics|last=Schwabl|first=Franz|page=16|isbn=978-3-540-43163-3|year=2002}}&lt;/ref&gt;

:&lt;math&gt; i \hbar \frac{\partial \rho}{\partial t} = [H,\rho]~, &lt;/math&gt;

where the brackets denote a [[commutator]].

Note that this equation only holds when the density operator is taken to be in the [[Schrödinger picture]], even though this equation seems at first look to emulate the Heisenberg equation of motion in the [[Heisenberg picture]], with a crucial sign difference:

:&lt;math&gt; i \hbar \frac{dA^{(H)}}{dt}=-[H,A^{(H)}] ~,&lt;/math&gt;

where &lt;math&gt;A^{(H)}(t)&lt;/math&gt; is some ''Heisenberg picture'' operator; but in this picture the density matrix is ''not time-dependent'', and the relative sign ensures that the time derivative of the expected value &lt;math&gt;\langle A \rangle&lt;/math&gt; comes out ''the same as in the Schrödinger picture''.&lt;ref&gt;See Axiom 8 and the discussion that follows in Section 19.4 of {{citation | last = Hall |first = B.C. |title = Quantum Theory for Mathematicians |volume = 267 | year = 2013|doi=10.1007/978-1-4614-7116-5|isbn=978-1-4614-7115-8|series=Graduate Texts in Mathematics|publisher=Springer}}&lt;/ref&gt;

Taking the density operator to be in the Schrödinger picture makes sense, since it is composed of 'Schrödinger' kets and bras evolved in time, as per the Schrödinger picture.
If the Hamiltonian is time-independent, this differential equation can be easily solved to yield

:&lt;math&gt;\rho(t) = e^{-i H t/\hbar} \rho(0) e^{i H t/\hbar}.&lt;/math&gt;

For a more general Hamiltonian, if &lt;math&gt;G(t)&lt;/math&gt; is the wavefunction propagator over some interval, then the time evolution of the density matrix over that same interval is given by

:&lt;math&gt; \rho(t) = G(t) \rho(0) G(t)^\dagger.&lt;/math&gt;

However,&lt;ref&gt;{{Cite journal|arxiv=cond-mat/0303290|last1=Grandy|first1=W. T|title=Time Evolution in Macroscopic Systems. I: Equations of Motion|journal=Foundations of Physics|volume=34|pages=1|year=2003|doi=10.1023/B:FOOP.0000012007.06843.ed|bibcode=2004FoPh...34....1G}}&lt;/ref&gt; the density matrix contains both classical and quantum-mechanical probabilities it is necessary to account for changes in both in the presence of external influences.

== "Quantum Liouville", Moyal's equation ==
The density matrix operator may also be realized in [[phase space]]. Under the [[Wigner quasi-probability distribution#The Wigner–Weyl transformation|Wigner map]], the density matrix transforms into the equivalent [[Wigner quasi-probability distribution|Wigner function]],
:&lt;math&gt; W(x,p) \stackrel{\mathrm{def}}{=} \frac{1}{\pi\hbar} \int_{-\infty}^\infty \psi^*(x + y) \psi(x - y) e^{2ipy/\hbar} \,dy.&lt;/math&gt;
The equation for the time evolution of the Wigner function is then the Wigner-transform of the above von Neumann equation,
:&lt;math&gt;\frac{\partial W(q, p, t)}{\partial t} = -\{\{W(q, p, t), H(q, p)\}\},&lt;/math&gt;
where ''H''(''q'', ''p'') is the Hamiltonian, and &lt;nowiki&gt;{{•, •}}&lt;/nowiki&gt; is the [[Moyal bracket]], the transform of the quantum [[commutator]].

The evolution equation for the Wigner function is then analogous to that of its classical limit, the [[Liouville's theorem (Hamiltonian)#Liouville equations|Liouville equation]] of [[classical physics]].  In the limit of vanishing Planck's constant ''ħ'', ''W''(''q'', ''p'', ''t'') reduces to the classical Liouville probability density function in [[phase space]].

The classical Liouville equation can be solved using the [[method of characteristics]] for partial differential equations, the characteristic equations being [[Hamilton's equations]]. The Moyal equation in quantum mechanics similarly admits formal solutions in terms of [[method of quantum characteristics|quantum characteristics]], predicated on the [[Moyal product|∗−product]] of phase space, although, in actual practice, solution-seeking follows different methods.

== Example applications ==
Density matrices are a basic tool of quantum mechanics, and appear at least occasionally in almost any type of quantum-mechanical calculation. Some specific examples where density matrices are especially helpful and common are as follows:
* [[Quantum decoherence]] theory typically involves non-isolated quantum systems developing entanglement with other systems, including measurement apparatuses. Density matrices make it much easier to describe the process and calculate its consequences.
* Similarly, in [[quantum computation]], [[quantum information theory]], and other fields where state preparation is noisy and decoherence can occur, density matrices are frequently used.
** [[Quantum tomography]] is the process of experimentally measuring the density matrix of a system.
* When analyzing a system with many electrons, such as an [[atom]] or [[molecule]], an imperfect but useful first approximation is to treat the electrons as [[electronic correlation|uncorrelated]] or each having an independent single-particle wavefunction. This is the usual starting point when building the [[Slater determinant]] in the [[Hartree–Fock]] method. If there are N electrons filling the N single-particle wavefunctions &lt;math&gt;|\psi_i\rangle&lt;/math&gt;, then the collection of N electrons together can be characterized by a density matrix &lt;math&gt;\sum_{i=1}^N |\psi_i\rangle \langle \psi_i|&lt;/math&gt;.

== C*-algebraic formulation of states ==
It is now generally accepted that the description of quantum mechanics in which all self-adjoint operators represent observables is untenable.&lt;ref&gt;See appendix,  {{Citation | last1=Mackey | first1=George Whitelaw | author1-link=George Mackey | title=Mathematical Foundations of Quantum Mechanics | publisher=[[Dover Publications]] | location=New York | series=Dover Books on Mathematics | isbn=978-0-486-43517-6 | year=1963}}&lt;/ref&gt;&lt;ref&gt;{{Citation | last1=Emch | first1=Gerard G. | title=Algebraic methods in statistical mechanics and quantum field theory | publisher=[[Wiley-Interscience]] | isbn=978-0-471-23900-0 | year=1972}}&lt;/ref&gt;  For this reason, observables are identified with elements of an abstract [[C*-algebra]] ''A'' (that is one without a distinguished representation as an algebra of operators) and [[state (functional analysis)|states]] are positive [[linear functional]]s on ''A''. However, by using the [[GNS construction]], we can recover Hilbert spaces which realize ''A'' as a subalgebra of operators.

Geometrically, a pure state on a C*-algebra ''A''  is a state which is an extreme point of the set of all states on ''A''.  By properties of the GNS construction these states correspond to [[irreducible representation]]s of ''A''.

The states of the C*-algebra of [[compact operator]]s ''K''(''H'') correspond exactly to the density operators, and therefore the pure states  of ''K''(''H'') are exactly the pure states in the sense of quantum mechanics.

The C*-algebraic formulation can be seen to include both classical and quantum systems. When the system is classical, the algebra of observables become an abelian C*-algebra.  In that case the states become probability measures, as noted in the introduction.

== See also ==
{{Div col}}
* [[Quantum statistical mechanics]]
* [[Atomic electron transition]]
* [[Born rule]]
* [[Density functional theory]]
* [[Gleason's theorem]]
* [[Green–Kubo relations]]
* [[Green's function (many-body theory)]]
* [[Lindblad equation]]
* [[Quantum state]]
* [[POVM]], generalized measurement of density states
* [[Purification of quantum state]]
* [[Wave function]]
* [[Wigner quasi-probability distribution]]
{{Div col end}}

== Notes and references ==
{{Reflist}}

{{Quantum mechanics topics}}

[[Category:Quantum mechanics]]
[[Category:Functional analysis]]
[[Category:Quantum information science]]
[[Category:Statistical mechanics]]</text>
      <sha1>c67f21s74d27qrhy2b93e035bsjeeix</sha1>
    </revision>
  </page>
  <page>
    <title>Discrete dipole approximation</title>
    <ns>0</ns>
    <id>7430174</id>
    <revision>
      <id>852310895</id>
      <parentid>852247117</parentid>
      <timestamp>2018-07-28T02:06:27Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: . Add: pages, issue. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9515">[[File:Shape DDA1.svg|thumb|upright=1.2|In the discrete dipole approximation a larger object is approximated in terms of discrete dipoles]]
'''The discrete dipole approximation''' (DDA) is a method for computing [[scattering]] of radiation by particles of arbitrary shape and by periodic structures. Given a target of arbitrary geometry, one seeks to calculate its scattering and absorption properties. Exact solutions to [[Maxwell's equations]] are known only for special geometries such as spheres, spheroids, or cylinders, so approximate methods are in general required. However, the DDA employs no physical approximations and can produce accurate enough results, given sufficient computer power.

==Basic concepts==
The basic idea of the DDA was introduced in 1964 by DeVoe
&lt;ref&gt;H. DeVoe,  Optical properties of molecular aggregates. I. Classical model of electronic absorption and refraction, J. Chem. Phys. 41, 393-400 (1964).&lt;/ref&gt;
who applied it to study the optical properties of molecular aggregates; retardation effects were not included, so DeVoe's treatment was limited to aggregates that were small compared with the wavelength. The DDA, including retardation effects, was proposed in 1973 by  [[Edward Mills Purcell|Purcell]] and Pennypacker
&lt;ref&gt;
{{cite journal
|author1=E. M. Purcell |author2=C. R. Pennypacker |title=Scattering and absorption of light by nonspherical dielectric grains
|journal=Astrophysical Journal
|volume=186 |pages=705 | doi = 10.1086/152538
|year=1973|bibcode = 1973ApJ...186..705P }}
&lt;/ref&gt;
who used it to study interstellar dust grains. Simply stated, the DDA is an approximation of the continuum target by a finite array of polarizable points. The points acquire dipole moments in response to the local electric field. The dipoles of course interact with one another via their electric fields, so the DDA is also sometimes referred to as the coupled dipole approximation.
&lt;ref&gt;S. B. Singham and G. C. Salzman, Evaluation of the scattering matrix of an arbitrary particle using the coupled dipole approximation, J. Chem. Phys. 84, 2658-2667(1986).&lt;/ref&gt;
&lt;ref&gt;S. B. Singham and C. F. Bohren, Light scattering by an arbitrary particle: a physical reformulation of the coupled dipoles method, Opt. Lett. 12, 10-12 (1987).&lt;/ref&gt;

Nature provides the physical inspiration for the DDA: in 1909 [[Hendrik Lorentz|Lorentz]]
&lt;ref&gt;H. A. Lorentz, Theory of Electrons (Teubner, Leipzig, 1909)&lt;/ref&gt;
showed that the dielectric properties of a substance could be directly related to the polarizabilities of the individual atoms of which it was composed, with a particularly simple and exact relationship, the [[Clausius-Mossotti relation]] (or Lorentz-Lorenz), when the atoms are located on a cubic lattice. We may expect that, just as a continuum representation of a solid is appropriate on length scales that are large compared with the interatomic spacing, an array of polarizable points can accurately approximate the response of a continuum target on length scales that are large compared with the interdipole separation.

For a finite array of point dipoles the scattering problem may be solved exactly, so the only approximation that is present in the DDA is the replacement of the continuum target by an array of N-point dipoles. The replacement requires specification of both the geometry (location of the dipoles) and the dipole polarizabilities. For monochromatic incident waves the self-consistent solution for the oscillating dipole moments may be found; from these  the absorption and scattering cross sections are computed. If DDA solutions are obtained for two independent polarizations of the incident wave, then the complete amplitude scattering matrix can be determined.

Alternatively, the DDA can be derived from [[Electric-field integral equation|volume integral equation for the electric field]].&lt;ref name=Yurkin2007a&gt;{{cite journal |title=The discrete dipole approximation: an overview and recent developments |author1=M. A. Yurkin |author2=A. G. Hoekstra |arxiv=0704.0038 |journal= Journal of Quantitative Spectroscopy and Radiative Transfer |year=2007 |doi=10.1016/j.jqsrt.2007.01.034 |pages=558–589 |volume=106|bibcode = 2007JQSRT.106..558Y }}&lt;/ref&gt; This highlights that the approximation of point dipoles is equivalent to that of discretizing the integral equation, and thus decreases with decreasing dipole size.

With the recognition that the polarizabilities may be tensors, the DDA can readily be applied to anisotropic materials. The extension of the DDA to treat materials with nonzero magnetic susceptibility is also straightforward, although for most applications magnetic effects are negligible.

==Extensions==
The method was improved by [[Bruce T. Draine|Draine]], [[Piotr J. Flatau|Flatau]], and [[Jeremy Goodman|Goodman]] who applied [[Fast Fourier Transform]] and [[conjugate gradient method]] to calculate [[convolution]] problem arising in the DDA methodology which allowed to calculate scattering by large targets. They distributed discrete dipole approximation open source code DDSCAT.&lt;ref name=draine1994&gt;
{{cite journal
|doi=10.1364/JOSAA.11.001491
|author1=Draine, B.T. |author2=P.J. Flatau
|title=Discrete dipole approximation for scattering calculations
|journal=J. Opt. Soc. Am. A
|volume=11
|pages=1491–1499
|year=1994
|bibcode = 1994JOSAA..11.1491D
|issue=4 }}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|author1=B. T. Draine |author2=P. J. Flatau |title=The discrete dipole approximation for periodic targets: theory and tests
|volume=25
|issue=11 |pages=2693 |year=2008
|journal=J. Opt. Soc. Am. A
|arxiv = 0809.0338|bibcode = 2008JOSAA..25.2693D |doi = 10.1364/JOSAA.25.002693 }}
&lt;/ref&gt;
There are now several [[discrete dipole approximation codes|DDA implementations]].&lt;ref name=Yurkin2007a/&gt;  There are extensions to periodic targets  &lt;ref&gt;P. C. Chaumet, A. Rahmani, and G. W. Bryant, ''Generalization of the coupled dipole method to periodic
structures,'' Phys. Rev. B 67, 165404 (2003).&lt;/ref&gt; and particles placed on or near a plane substrate.&lt;ref&gt;R. Schmehl, B. M. Nebeker, and E. D. Hirleman, ''Discrete dipole approximation for scattering by features on surfaces
by means of a two-dimensional fast Fourier transform technique,'' J. Opt. Soc. Am. A 14, 3026–3036 (1997).&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi = 10.1021/acs.jpcc.5b09271| volume = 119| issue = 52| pages = 29088–29094| author1 = M. A. Yurkin | author2 = M. Huntemann| title = Rigorous and fast discrete dipole approximation for particles near a plane interface| journal = The Journal of Physical Chemistry C| date = 2015| url = https://sites.google.com/site/yurkin/publications/papers/Yurkin%20and%20Huntemann%20-%202015%20-%20Rigorous%20and%20fast%20discrete%20dipole%20approximation.pdf}}&lt;/ref&gt;
A convergence theory of the DDA has been developed&lt;ref&gt;{{Cite journal
| doi = 10.1364/JOSAA.23.002578
| volume = 23
| issue = 10
| pages = 2578–2591
|author1=M. A. Yurkin |author2=V. P. Maltsev |author3=A. G. Hoekstra | title = Convergence of the discrete dipole approximation. I. Theoretical analysis
| journal = Journal of the Optical Society of America A
| date = 2006
| url = http://sites.google.com/site/yurkin/publications/papers/Yurkinetal-2006-ConvergenceofthediscretedipoleapproximationI.pdf
|arxiv = 0704.0033 |bibcode = 2006JOSAA..23.2578Y }}&lt;/ref&gt; and comparisons with exact technique were published.&lt;ref&gt;A. Penttila, E. Zubko, K. Lumme, K. Muinonen, M. A. Yurkin, B. T. Draine, J. Rahola, A. G. Hoekstra, and Y.
Shkuratov, ''Comparison between discrete dipole implementations and exact techniques,'' J. Quant. Spectrosc.
Radiat. Transfer 106, 417-436 (2007).&lt;/ref&gt;
The validity criteria of the discrete dipole approximation have been recently revised.&lt;ref&gt;E. Zubko, D. Petrov, Ye. Grynko, Yu. Shkuratov, H. Okamoto, K. Muinonen, T. Nousiainen, H. Kimura, T.Yamamoto, and G. Videen. ''Validity criteria of the discrete dipole approximation,'' Applied Optics 49, 1267-1279 (2010).&lt;/ref&gt;  That work significantly extends the range of applicability of the DDA for the case of irregularly shaped particles. The DDA has been also extended to employ rectangular-cuboid dipoles,&lt;ref&gt;{{Cite journal| doi = 10.1016/j.jqsrt.2015.01.019| volume = 156| pages = 67–79| author1 = D. A. Smunev| author2 = P. C. Chaumet| author3 = M. A. Yurkin| title = Rectangular dipoles in the discrete dipole approximation| journal = Journal of Quantitative Spectroscopy and Radiative Transfer| date = 2015| url = https://sites.google.com/site/yurkin/publications/papers/Smunev%20et%20al.%20-%202015%20-%20Rectangular%20dipoles%20in%20the%20discrete%20dipole%20approxi.pdf| bibcode = 2015JQSRT.156...67S}}&lt;/ref&gt;
which is very efficient for highly oblate or prolate particles.

==Discrete Dipole Approximation Codes==
{{main|Discrete dipole approximation codes}}

==Gallery of shapes==
&lt;gallery&gt;
File:Shape periodic2d.png|Scattering by periodic structures such as slabs, gratings, of periodic cubes placed on a surface, can be solved in the discrete dipole approximation.
File:Shape_1d_cylinder.png|Scattering by infinite object (such as cylinder) can be solved in the discrete dipole approximation.
&lt;/gallery&gt;

==References==
{{reflist}}

==See also==
*[[Computational electromagnetics]]
*[[Mie theory]]
*[[Finite-difference time-domain method]]

{{DEFAULTSORT:Discrete Dipole Approximation}}
[[Category:Computational science]]
[[Category:Electrodynamics]]
[[Category:Scattering]]
[[Category:Scattering, absorption and radiative transfer (optics)]]
[[Category:Computational electromagnetics]]</text>
      <sha1>re2v5juqs1d7g424nzgxhc4r6w278x8</sha1>
    </revision>
  </page>
  <page>
    <title>Disjunction introduction</title>
    <ns>0</ns>
    <id>8528</id>
    <revision>
      <id>857234498</id>
      <parentid>848263991</parentid>
      <timestamp>2018-08-30T12:15:10Z</timestamp>
      <contributor>
        <username>RussBot</username>
        <id>279219</id>
      </contributor>
      <minor/>
      <comment>Robot: fix [[WP:DPL|links]] to [[WP:D|disambiguation]] page [[Validity]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2432">{{Transformation rules}}

'''Disjunction introduction''' or '''addition''' (also called '''or introduction''')&lt;ref&gt;Hurley{{full|date=January 2015}}&lt;/ref&gt;&lt;ref&gt;Moore and Parker{{full|date=January 2015}}&lt;/ref&gt;&lt;ref&gt;Copi and Cohen{{full|date=January 2015}}&lt;/ref&gt; is a [[rule of inference]] of [[propositional calculus|propositional logic]] and almost every other [[deduction system]]. The rule makes it possible to introduce [[logical disjunction|disjunctions]] to [[formal proof|logical proofs]]. It is the [[inference]] that if ''P'' is true, then ''P or Q'' must be true.

An example in [[English language|English]]:
:Socrates is a man.
:Therefore, Socrates is a man or pigs are flying in formation over the English Channel.

The rule can be expressed as:
:&lt;math&gt;\frac{P}{\therefore P \lor Q}&lt;/math&gt;

where the rule is that whenever instances of "&lt;math&gt;P&lt;/math&gt;" appear on lines of a proof, "&lt;math&gt;P \lor Q&lt;/math&gt;" can be placed on a subsequent line. 

More generally it's also a simple [[Validity (logic)|valid]] [[logical form|argument form]], this means that if the premise is true, then the conclusion is also true as any rule of inference should be, and an [[immediate inference]], as it has a single proposition in its premises. 

Disjunction introduction is not a rule in some [[paraconsistent logic]]s because in combination with other rules of logic, it leads to [[Principle of explosion|explosion]] (i.e. everything becomes provable) and paraconsistent logic tries to avoid explosion and to be able to reason with contradictions. One of the solutions is to introduce disjunction with over rules. See [[Paraconsistent logic#Tradeoff|Tradeoffs in Paraconsistent logic]].

== Formal notation ==
The ''disjunction introduction'' rule may be written in [[sequent]] notation:

: &lt;math&gt;P \vdash (P \lor Q)&lt;/math&gt;

where &lt;math&gt;\vdash&lt;/math&gt; is a [[metalogic]]al symbol meaning that &lt;math&gt;P \lor Q&lt;/math&gt; is a [[logical consequence|syntactic consequence]] of &lt;math&gt;P&lt;/math&gt; in some [[formal system|logical system]];

and expressed as a truth-functional [[tautology (logic)|tautology]] or [[theorem]] of propositional logic:

:&lt;math&gt;P \to (P \lor Q)&lt;/math&gt;

where &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are propositions expressed in some [[formal system]].

== References ==
{{reflist}}

{{DEFAULTSORT:Disjunction Introduction}}
[[Category:Rules of inference]]
[[Category:Paraconsistent logic]]
[[Category:Theorems in propositional logic]]</text>
      <sha1>mhnu0dcp06o34uqn15qxiar5m6vublh</sha1>
    </revision>
  </page>
  <page>
    <title>Doxastic logic</title>
    <ns>0</ns>
    <id>12065590</id>
    <revision>
      <id>870441670</id>
      <parentid>867593927</parentid>
      <timestamp>2018-11-24T20:55:36Z</timestamp>
      <contributor>
        <ip>24.171.59.36</ip>
      </contributor>
      <comment>/* Self-fulfilling beliefs */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15720">'''Doxastic logic''' is a [[Types of logic|type of logic]] concerned with [[reasoning]] about [[belief]]s. The term ''doxastic'' derives from the [[ancient Greek]] δόξα, ''[[doxa]]'', which means "belief". Typically, a doxastic logic uses &lt;math&gt;\mathcal{B}x&lt;/math&gt; to mean "It is believed that &lt;math&gt;x&lt;/math&gt; is the case", and the set &lt;math&gt;\mathbb{B}&lt;/math&gt; [[denotation|denotes]] a [[Theory (mathematical logic)|set of beliefs]]. In doxastic logic, belief is treated as a [[modal operator]].

:&lt;math&gt;\mathbb{B} : \left \{ b_1, \ldots ,b_n \right \}&lt;/math&gt;

There is complete parallelism between a person who believes [[proposition]]s and a [[formal system]] that [[formal proof|derives]] propositions. Using doxastic logic, one can express the [[epistemic logic|epistemic]] counterpart of [[Gödel's incompleteness theorem]] of [[metalogic]], as well as [[Löb's theorem]], and other metalogical results in terms of belief.&lt;ref name="Logicians"&gt;[[Raymond Smullyan|Smullyan, Raymond M.]], (1986) [http://portal.acm.org/ft_gateway.cfm?id=1029818&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=44077077&amp;CFTOKEN=65318791 ''Logicians who reason about themselves''], Proceedings of the 1986 conference on Theoretical aspects of reasoning about knowledge, Monterey (CA), Morgan Kaufmann Publishers Inc., San Francisco (CA), pp. 341–352&lt;/ref&gt;

==Types of reasoners==
To demonstrate the properties of sets of beliefs, [[Raymond Smullyan]] defines the following types of reasoners:

* '''Accurate reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"&gt;https://web.archive.org/web/20070930165226/http://cs.wwc.edu/KU/Logic/Book/book/node17.html Belief, Knowledge and Self-Awareness
  {{dead link|date=June 2016|bot=medic}}{{cbignore|bot=medic}}&lt;/ref&gt;&lt;ref name="modal"&gt;
https://web.archive.org/web/20070213054220/http://moonbase.wwc.edu/~aabyan/Logic/Modal.html Modal Logics
  {{dead link|date=June 2016|bot=medic}}{{cbignore|bot=medic}}&lt;/ref&gt;&lt;ref name="forever"&gt;
[[Raymond Smullyan|Smullyan, Raymond M.]], (1987) ''Forever Undecided'', Alfred A. Knopf Inc.
&lt;/ref&gt; An accurate reasoner never believes any false proposition. (modal axiom '''T''')
::&lt;math&gt;\forall p: \mathcal{B}p \to p&lt;/math&gt;

* '''Inaccurate reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; An inaccurate reasoner believes at least one false proposition.
:: &lt;math&gt;\exists p: \neg p \wedge \mathcal{B}p&lt;/math&gt;

* '''Conceited reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A conceited reasoner believes his or her beliefs are never inaccurate.
::&lt;math&gt;\mathcal{B}[\neg\exists p ( \neg p \wedge \mathcal{B}p )] \quad \text{or} \quad \mathcal{B}[\forall p( \mathcal{B}p \to p) ]&lt;/math&gt;
:A conceited reasoner with rationality of at least type 1 (see below) will necessarily lapse into inaccuracy.

* '''Consistent reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A consistent reasoner never simultaneously believes a proposition and its negation. (modal axiom '''D''')
::&lt;math&gt;\neg\exists p: \mathcal{B}p \wedge \mathcal{B}\neg p  \quad \text{or} \quad  \forall p: \mathcal{B}p \to \neg\mathcal{B}\neg p&lt;/math&gt;

* '''Normal reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A normal reasoner is one who, while believing &lt;math&gt;p,&lt;/math&gt; also ''believes'' he or she believes p (modal axiom '''4''').
:: &lt;math&gt;\forall p: \mathcal{B}p \to \mathcal{BB}p&lt;/math&gt;

* '''Peculiar reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A peculiar reasoner believes proposition p while also believing he or she does not believe &lt;math&gt;p.&lt;/math&gt; Although a peculiar reasoner may seem like a strange psychological phenomenon (see [[Moore's paradox]]), a peculiar reasoner is necessarily inaccurate but not necessarily inconsistent.
:: &lt;math&gt;\exists p: \mathcal{B}p \wedge \mathcal{B\neg B}p&lt;/math&gt;

* '''Regular reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A regular reasoner is one who, while believing  &lt;math&gt; p \to q &lt;/math&gt;, also ''believes''  &lt;math&gt; \mathcal{B}p \to \mathcal{B}q &lt;/math&gt;.
::&lt;math&gt;\forall p \forall q : \mathcal{B}(p \to q) \to \mathcal{B} (\mathcal{B}p \to \mathcal{B}q)&lt;/math&gt;

* '''Reflexive reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A reflexive reasoner is one for whom every proposition &lt;math&gt;p&lt;/math&gt; has some proposition &lt;math&gt;q&lt;/math&gt; such that the reasoner believes &lt;math&gt; q \equiv ( \mathcal{B}q \to p) &lt;/math&gt;.
::&lt;math&gt;\forall p: \exists q \mathcal{B}(q \equiv ( \mathcal{B}q \to p)) &lt;/math&gt;

:If a reflexive reasoner of type 4 [see [[#Increasing levels of rationality|below]]] believes &lt;math&gt; \mathcal{B}p \to p &lt;/math&gt;, he or she will believe p. This is a parallelism of [[Löb's theorem]] for reasoners.

* '''Unstable reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; An unstable reasoner is one who believes that he or she believes some proposition, but in fact does not believe it. This is just as strange a psychological phenomenon as peculiarity; however, an unstable reasoner is not necessarily inconsistent.
::&lt;math&gt;\exists p: \mathcal{B}\mathcal{B}p \wedge \neg\mathcal{B}p &lt;/math&gt;

* '''Stable reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A stable reasoner is not unstable. That is, for every &lt;math&gt;p,&lt;/math&gt; if he or she believes &lt;math&gt;\mathcal{B}p&lt;/math&gt; then he or she believes &lt;math&gt;p.&lt;/math&gt; Note that stability is the converse of normality. We will say that a reasoner believes he or she is stable if for every proposition &lt;math&gt;p,&lt;/math&gt; he or she believes &lt;math&gt;\mathcal{B}\mathcal{B}p \to \mathcal{B}p&lt;/math&gt; (believing: "If I should ever believe that I believe &lt;math&gt;p,&lt;/math&gt; then I really will believe &lt;math&gt;p&lt;/math&gt;").
::&lt;math&gt;\forall p: \mathcal{BB}p\to\mathcal{B}p&lt;/math&gt;

* '''Modest reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A modest reasoner is one for whom every believed proposition &lt;math&gt;p&lt;/math&gt;, &lt;math&gt; \mathcal{B}p \to p &lt;/math&gt; only if he or she believes &lt;math&gt;p&lt;/math&gt;. A modest reasoner never believes &lt;math&gt;\mathcal{B}p \to p&lt;/math&gt; unless he or she believes &lt;math&gt;p&lt;/math&gt;. Any reflexive reasoner of type 4 is modest. ([[Löb's Theorem]])
::&lt;math&gt;\forall p: \mathcal{B}(\mathcal{B}p \to p) \to \mathcal{B}p&lt;/math&gt;

* '''Queer reasoner''':&lt;ref name="forever"/&gt; A queer reasoner is of type G and believes he or she is inconsistent—but is wrong in this belief.
* '''Timid reasoner''':&lt;ref name="forever"/&gt; A timid reasoner does not believe &lt;math&gt;p&lt;/math&gt; [is "afraid to" believe &lt;math&gt;p&lt;/math&gt;] if he or she believes &lt;math&gt; \mathcal{B}p \to \mathcal{B}\bot &lt;/math&gt;

==Increasing levels of rationality==
* '''Type 1 reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt;&lt;ref name="possible"&gt;Rod Girle, ''Possible Worlds'', McGill-Queen's University Press (2003) {{ISBN|0-7735-2668-4}} {{ISBN|978-0773526686}}&lt;/ref&gt; A type 1 reasoner has a complete knowledge of [[propositional logic]] i.e., he or she sooner or later believes every [[tautology (logic)|tautology]] (any proposition provable by [[truth tables]]). Also, his or her set of beliefs (past, present and future) is [[Deductive closure|logically closed]] under [[modus ponens]]. If he or she ever believes &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;p \to q&lt;/math&gt; then he or she will (sooner or later) believe &lt;math&gt;q&lt;/math&gt;.
::&lt;math&gt; \vdash_{PC} p \Rightarrow\  \vdash \mathcal{B}p&lt;/math&gt;
::&lt;math&gt;\forall p \forall q : ( \mathcal{B}p \wedge  \mathcal{B}( p \to q)) \to \mathcal{B} q )&lt;/math&gt;
:This rule can also be thought of as stating that belief distributes over implication, as it's logically equivalent to 
::&lt;math&gt;\forall p \forall q : \mathcal{B}(p \to q) \to (\mathcal{B}p \to \mathcal{B}q )&lt;/math&gt;.
* '''Type 1* reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A type 1* reasoner believes all tautologies; his or her set of beliefs (past, present and future) is logically closed under modus ponens, and for any propositions &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q,&lt;/math&gt; if he or she believes &lt;math&gt;p \to q,&lt;/math&gt; then he or she will believe that if he or she believes &lt;math&gt;p&lt;/math&gt; then he or she will believe &lt;math&gt;q&lt;/math&gt;. The type 1* reasoner has "a shade more" [[self awareness]] than a type 1 reasoner.
::&lt;math&gt;\forall p \forall q : \mathcal{B}(p \to q) \to \mathcal{B} (\mathcal{B}p \to \mathcal{B}q )&lt;/math&gt;
* '''Type 2 reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A reasoner is of type 2 if he or she is of type 1, and if for every &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; he or she (correctly) believes: "If I should ever believe both &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;p \to q,&lt;/math&gt;, then I will believe &lt;math&gt;q&lt;/math&gt;." Being of type 1, he or she also believes the [[logical equivalence|logically equivalent]] proposition: &lt;math&gt;\mathcal{B}(p \to q) \to (\mathcal{B}p \to \mathcal{B}q).&lt;/math&gt; A type 2 reasoner knows his or her beliefs are closed under modus ponens.
::&lt;math&gt;\forall p \forall q : \mathcal{B}(( \mathcal{B}p \wedge  \mathcal{B}( p \to q)) \to \mathcal{B} q )&lt;/math&gt;
* '''Type 3 reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt; A reasoner is of type 3 if he or she is a normal reasoner of type 2.
::&lt;math&gt;\forall p: \mathcal{B} p \to \mathcal{B} \mathcal{B}p &lt;/math&gt;
* '''Type 4 reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="belief"/&gt;&lt;ref name="modal"/&gt;&lt;ref name="forever"/&gt;&lt;ref name="possible"/&gt; A reasoner is of type 4 if he or she is of type 3 and also believes he or she is normal.
::&lt;math&gt;\mathcal{B}[ \forall p ( \mathcal{B} p \to \mathcal{B} \mathcal{B}p )]&lt;/math&gt;
* '''Type G reasoner''':&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt; A reasoner of type 4 who believes he or she is modest.
::&lt;math&gt;\mathcal{B}[ \forall p ( \mathcal{B}(\mathcal{B}p \to p) \to \mathcal{B}p ) ]&lt;/math&gt;

==Gödel incompleteness and doxastic undecidability==
{{see|Gödel's incompleteness theorems}}
Let us say an accurate reasoner is faced with the task of assigning a [[truth value]] to a statement. There exists a statement which the reasoner must either remain forever undecided about or lose his or her accuracy. One solution is the statement:

::S: "I will never believe this statement."

If the reasoner ever believes the statement &lt;math&gt;S,&lt;/math&gt; it becomes falsified by that fact, making &lt;math&gt;S&lt;/math&gt; an untrue belief and hence making the reasoner inaccurate in believing S.

Therefore, since the reasoner is accurate, he or she will never believe &lt;math&gt;S.&lt;/math&gt; Hence the statement was true, because that is exactly what it claimed. It further follows that the reasoner will never have the false belief that &lt;math&gt;S&lt;/math&gt; is false. And so the reasoner must remain forever undecided as to whether the statement &lt;math&gt;S&lt;/math&gt; is true or false.

The equivalent theorem is that for any formal system F, there exists a mathematical statement which can be interpreted as "This statement is not provable in formal system F". If the system F is consistent, neither the statement nor its opposite will be provable in it.&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt;

==Inaccuracy and peculiarity of conceited reasoners==
A reasoner of type 1 is faced with the statement "I will never believe this sentence." The interesting thing now is that if the reasoner believes he or she is always accurate, then he or she will become inaccurate. Such a reasoner will reason: "The statement in question is that I won't believe the statement, so if it's false then I will believe the statement.  Because I am accurate, believing the statement means it must be true.  So if the statement is false then it must be true.  It's tautological that if a statement being false implies the statement, then that statement is true. Therefore the statement is true."

At this point the reasoner believes the statement, which makes it false. Thus the reasoner is inaccurate in believing that the statement is true. If the reasoner hadn't assumed his or her own accuracy, he or she would never have lapsed into an inaccuracy.  Formally:

:&lt;math&gt; 1 \ \ S \equiv \lnot \mathcal{B}S &lt;/math&gt; [definition of &lt;math&gt;S&lt;/math&gt;]
:&lt;math&gt; 2 \ \ (\lnot S \to S) \to S &lt;/math&gt; [elementary tautology]
:&lt;math&gt; 3 \ \ (\mathcal{B}S \to S) \to S &lt;/math&gt; [because &lt;math&gt;\lnot S \equiv \mathcal{B}S&lt;/math&gt;]
:&lt;math&gt; 4 \ \ \mathcal{B}((\mathcal{B}S \to S) \to S)&lt;/math&gt; [reasoner believes all tautologies]
:&lt;math&gt; 5 \ \  \mathcal{B}(\mathcal{B}S \to S)  \to \mathcal{B}S &lt;/math&gt; [the reasoner is of type 1]
:&lt;math&gt; 6 \ \  \mathcal{B}(\mathcal{B}S \to S) &lt;/math&gt; [the reasoner is conceited]
:&lt;math&gt; 7 \ \  \mathcal{B}S&lt;/math&gt; [modus ponens 5 and 6]
:&lt;math&gt; 8 \ \  \lnot S&lt;/math&gt; [because &lt;math&gt;\mathcal{B} S \equiv \lnot S&lt;/math&gt;]

Additionally, the reasoner is peculiar because he or she believes that he/she doesn't believe the statement (symbolically, &lt;math&gt;\mathcal{B}(\lnot \mathcal{B}S),&lt;/math&gt; which follows from &lt;math&gt;\mathcal{B}S&lt;/math&gt; because &lt;math&gt;S \equiv \lnot \mathcal{B}S&lt;/math&gt;) even though he/she actually believes it.

==Self-fulfilling beliefs==
For systems, we define reflexivity to mean that for any &lt;math&gt;p&lt;/math&gt; (in the language of the system) there is some &lt;math&gt;q&lt;/math&gt; such that &lt;math&gt;q \equiv \mathcal{B}q \to p&lt;/math&gt; is provable in the system. [[Löb's theorem]] (in a general form) is that for any reflexive system of type 4, if &lt;math&gt;\mathcal{B}p \to p&lt;/math&gt; is provable in the system, so is &lt;math&gt;p.&lt;/math&gt;&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt;

==Inconsistency of the belief in one's stability==
If a consistent reflexive reasoner of type 4 believes that he or she is stable, then he or she will become unstable. Stated otherwise, if a stable reflexive reasoner of type 4 believes that he or she is stable, then he or she will become inconsistent. Why is this? Suppose that a stable reflexive reasoner of type 4 believes that he or she is stable. We will show that he or she will (sooner or later) believe every proposition &lt;math&gt;p&lt;/math&gt; (and hence be inconsistent). Take any proposition &lt;math&gt;p.&lt;/math&gt; The reasoner believes &lt;math&gt;\mathcal{B}\mathcal{B}p \to \mathcal{B}p,&lt;/math&gt; hence by Löb's theorem he or she will believe &lt;math&gt;\mathcal{B}p&lt;/math&gt; (because he or she believes &lt;math&gt;\mathcal{B}r \to r,&lt;/math&gt; where &lt;math&gt;r&lt;/math&gt; is the proposition &lt;math&gt;\mathcal{B}p,&lt;/math&gt; and so he or she will believe &lt;math&gt;r,&lt;/math&gt; which is the proposition &lt;math&gt;\mathcal{B}p&lt;/math&gt;). Being stable, he or she will then believe &lt;math&gt;p.&lt;/math&gt;&lt;ref name="Logicians"/&gt;&lt;ref name="forever"/&gt;

==See also==
{{Portal|Logic}}
* [[Belief revision]]
* [[Common knowledge (logic)]]
* [[George Boolos]]
* [[Jaakko Hintikka]]
* [[Modal logic]]
* [[Raymond Smullyan]]

==References==
{{Reflist}}

==Further reading==
*{{cite journal |last=Lindström |first=St. |first2=Wl. |last2=Rabinowicz |title=DDL Unlimited. Dynamic Doxastic Logic for Introspective Agents |journal=[[Erkenntnis]] |volume=51 |year=1999 |issue=2–3 |pages=353–385 |doi=10.1023/A:1005577906029 }}
*{{cite journal |last=Linski |first=L. |title=On Interpreting Doxastic Logic |journal=[[Journal of Philosophy]] |volume=65 |year=1968 |issue=17 |pages=500–502 |jstor=2024352 }}
*{{cite journal |last=Segerberg |first=Kr. |title=Default Logic as Dynamic Doxastic Logic |journal=Erkenntnis |volume=50 |issue=2–3 |year=1999 |pages=333–352 |doi=10.1023/A:1005546526502 }}
*{{cite journal |last=Wansing |first=H. |title=A Reduction of Doxastic Logic to Action Logic |journal=Erkenntnis |volume=53 |issue=1–2 |year=2000 |pages=267–283 |doi=10.1023/A:1005666218871 }}

{{Non-classical logic}}

[[Category:Belief]]
[[Category:Belief revision]]
[[Category:Modal logic]]
[[Category:Reasoning]]</text>
      <sha1>c2u99ii9rflwkyrnbe2u1gpqx83dpsv</sha1>
    </revision>
  </page>
  <page>
    <title>Dürer graph</title>
    <ns>0</ns>
    <id>23453065</id>
    <revision>
      <id>852405237</id>
      <parentid>852404948</parentid>
      <timestamp>2018-07-28T19:29:10Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Graphs of radius 3‎ per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 July 21]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5635">[[File:Dürer Melancholia I.jpg|thumb|240px|''Melencolia I'' by Albrecht Dürer, the first appearance of Dürer's solid (1514).]]
In the [[mathematics|mathematical]] field of [[graph theory]], the '''Dürer graph''' is an [[undirected graph]] with 12 vertices and 18 edges. It is named after [[Albrecht Dürer]], whose 1514 [[engraving]] ''[[Melencolia I]]'' includes a depiction of [[Dürer's solid]], a [[convex polyhedron]] having the Dürer graph as its [[skeleton (topology)|skeleton]]. Dürer's solid is one of only four [[well-covered graph|well-covered]] [[Simple polytope|simple]] convex polyhedra.

==Dürer's solid==
{{main|Triangular truncated trapezohedron}}
Dürer's solid is combinatorially equivalent to a [[cube]] with two opposite vertices [[Truncation (geometry)|truncated]],&lt;ref&gt;{{MathWorld|urlname=DuerersSolid|title=Dürer's Solid}}&lt;/ref&gt; although Dürer's depiction of it is not in this form but rather as a truncated [[rhombohedron]] or [[triangular truncated trapezohedron]].{{sfnp|Weber|1900}} The exact geometry of the solid depicted by Dürer is a subject of some academic debate, with different hypothetical values for its acute angles ranging from 72° to 82°.&lt;ref&gt;{{harvtxt|Weitzel|2004}}.&lt;/ref&gt;

==Graph-theoretic properties==
{{Infobox graph
 | name = Dürer graph
 | image = [[File:Dürer graph.svg|200px]]
 | image_caption = The Dürer graph
 | namesake = [[Albrecht Dürer]]
 | vertices = 12
 | edges = 18
 | automorphisms = 12 (D&lt;sub&gt;6&lt;/sub&gt;)
 | diameter = 4
 | girth = 3
 | radius = 3
 | chromatic_number = 3
 | chromatic_index = 3
 | properties = [[Cubic graph|Cubic]]&lt;br&gt;[[Planar graph|Planar]]&lt;br&gt;[[Well-covered graph|well-covered]]
}}
The Dürer graph is the graph formed by the vertices and edges of the Dürer solid. It is a [[cubic graph]] of [[girth (graph theory)|girth]] 3 and diameter 4. As well as its construction as the skeleton of Dürer's solid, it can be obtained by applying a [[Y-Δ transform]] to the opposite vertices of a [[hypercube graph|cube graph]], or as the [[generalized Petersen graph]] ''G''(6,2). As with any [[polyhedral graph|graph of a convex polyhedron]], the Dürer graph is a [[k-vertex-connected graph|3-vertex-connected]] simple [[planar graph]].

The Dürer graph is a [[well-covered graph]], meaning that all of its [[maximal independent set]]s have the same number of vertices, four. It is one of four well-covered cubic polyhedral graphs and one of seven well-covered 3-connected cubic graphs. The only other three well-covered [[Simple polytope|simple]] convex polyhedra are the [[tetrahedron]], [[triangular prism]], and [[pentagonal prism]].&lt;ref&gt;{{harvtxt|Campbell|Plummer|1988}}; {{harvtxt|Campbell|Ellingham|Royle|1993}}.&lt;/ref&gt;

The Dürer graph is [[Hamiltonian path|Hamiltonian]], with [[LCF notation]] [-4,5,2,-4,-2,5;-].&lt;ref&gt;{{harvtxt|Castagna|Prins|1972}} attribute the proof of Hamiltonicity of a class of generalized Petersen graphs that includes the Dürer graph to a 1968 Ph.D. thesis of G. N. Robertson at the University of Waterloo.&lt;/ref&gt; More precisely, it has exactly six Hamiltonian cycles, each pair of which may be mapped into each other by a symmetry of the graph.{{sfnp|Schwenk|1989}}

==Symmetries==
The [[automorphism group]] both of the Dürer graph and of the Dürer solid (in either the truncated cube form or the form shown by Dürer) is isomorphic to the [[dihedral group]] of order 12 : D&lt;sub&gt;6&lt;/sub&gt;.

==Gallery==
&lt;gallery&gt;
Image:Dürer graph 3color edge.svg|The chromatic index of the Dürer graph is 3.
Image:Dürer_graph_3COL.svg|The chromatic number of the Dürer graph is 3.
File:Dürer graph hamiltonicity.svg|The Dürer graph is [[Hamiltonian path|Hamiltonian]].
&lt;/gallery&gt;

{{commons category|Dürer graph}}

==Notes==
{{reflist}}

==References==
*{{citation
 | last1 = Campbell | first1 = S. R.
 | last2 = Ellingham | first2 = M. N. | author2-link = Mark Ellingham
 | last3 = Royle | first3 = Gordon F. | author3-link = Gordon Royle
 | journal = Journal of Combinatorial Mathematics and Combinatorial Computing
 | mr = 1220613
 | pages = 193–212
 | title = A characterisation of well-covered cubic graphs
 | volume = 13
 | year = 1993}}.
*{{citation
 | last1 = Campbell | first1 = Stephen R.
 | last2 = Plummer | first2 = Michael D. | author2-link = Michael D. Plummer
 | issue = A
 | journal = Ars Combinatoria
 | mr = 942505
 | pages = 215–242
 | title = On well-covered 3-polytopes
 | volume = 25
 | year = 1988}}.
*{{citation
 | last1 = Castagna | first1 = Frank
 | last2 = Prins | first2 = Geert
 | journal = [[Pacific Journal of Mathematics]]
 | title = Every Generalized Petersen Graph has a Tait Coloring
 | volume = 40
 | year = 1972
 | doi = 10.2140/pjm.1972.40.53 }}.
*{{citation
 | last = Schwenk | first = Allen J.
 | doi = 10.1016/0095-8956(89)90064-6
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 1007713
 | pages = 53–59
 | title = Enumeration of Hamiltonian cycles in certain generalized Petersen graphs
 | volume = 47
 | year = 1989}}.
*{{citation|title=Beiträge zu Dürers Weltanschauung—Eine Studie über die drei Stiche Ritter, Tod und Teufel, Melancholie und Hieronymus im Gehäus|first=P.|last=Weber|location=Strassburg|year=1900}}. As cited by {{harvtxt|Weitzel|2004}}.
*{{citation|last=Weitzel|first=Hans|title=A further hypothesis on the polyhedron of A. Dürer's engraving Melencolia I|journal=Historia Mathematica|volume=31|issue=1|year=2004|pages=11–14|doi=10.1016/S0315-0860(03)00029-6}}.

{{DEFAULTSORT:Durer Graph}}
[[Category:Individual graphs]]
[[Category:Polyhedra]]
[[Category:Regular graphs]]
[[Category:Planar graphs]]</text>
      <sha1>g48v9ghc2cg01xf745dof6tesdq26z7</sha1>
    </revision>
  </page>
  <page>
    <title>Excess-weighted code</title>
    <ns>0</ns>
    <id>49355949</id>
    <redirect title="Offset binary" />
    <revision>
      <id>703825237</id>
      <parentid>703825076</parentid>
      <timestamp>2016-02-07T22:03:15Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="226">#redirect [[Offset binary#Excess-weighted code]] {{R to related topic}}
&lt;!-- term "Excess-weighted code" is used in "Decimal computation" by Hermann Schmid, 1974 --&gt;

[[Category:Numeral systems]]
[[Category:Binary arithmetic]]</text>
      <sha1>i2ez77qapnc8vo17ngqjhyxfs42im4o</sha1>
    </revision>
  </page>
  <page>
    <title>Frölicher–Nijenhuis bracket</title>
    <ns>0</ns>
    <id>3291722</id>
    <revision>
      <id>868856358</id>
      <parentid>696118769</parentid>
      <timestamp>2018-11-14T22:01:50Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7682">In [[mathematics]], the '''Frölicher–Nijenhuis bracket''' is an extension of the [[Lie bracket of vector fields|Lie bracket]] of [[vector fields]] to [[vector-valued differential form]]s on a [[differentiable manifold]].

It is useful in the study of [[connection (mathematics)|connections]], notably the [[Ehresmann connection]], as well as in the more general study of [[projection (linear algebra)|projections]] in the [[tangent bundle]].
It was introduced by  [[Alfred Frölicher]] and [[Albert Nijenhuis]] (1956) and is related to the work of [[Jan Arnoldus Schouten|Schouten]] (1940).

It is related to but not the same as the [[Nijenhuis–Richardson bracket]] and the [[Schouten–Nijenhuis bracket]].

==Definition==
Let Ω*(''M'') be the [[sheaf (mathematics)|sheaf]] of [[exterior algebra]]s of [[differential form]]s on a [[smooth manifold]] ''M''.  This is a [[graded algebra]] in which forms are graded by degree:
:&lt;math&gt;\Omega^*(M) = \bigoplus_{k=0}^\infty \Omega^k(M).&lt;/math&gt;
A [[graded derivation]] of degree ℓ is a mapping
:&lt;math&gt;D:\Omega^*(M)\to\Omega^{*+l}(M)&lt;/math&gt;
which is linear with respect to constants and satisfies
:&lt;math&gt;D(\alpha\wedge\beta) = D(\alpha)\wedge\beta + (-1)^{\ell\deg(\alpha)}\alpha\wedge D(\beta).&lt;/math&gt;
Thus, in particular, the [[interior product]] with a vector defines a graded derivation of degree ℓ&amp;nbsp;=&amp;nbsp;&amp;minus;1, whereas the [[exterior derivative]] is a graded derivation of degree ℓ&amp;nbsp;=&amp;nbsp;1.

The vector space of all derivations of degree ℓ is denoted by Der&lt;sub&gt;ℓ&lt;/sub&gt;Ω*(''M'').  The direct sum of these spaces is a [[graded vector space]] whose homogeneous components consist of all graded derivations of a given degree; it is denoted
:&lt;math&gt;\mathrm{Der}\, \Omega^*(M) = \bigoplus_{k=-\infty}^\infty \mathrm{Der}_k\, \Omega^*(M).&lt;/math&gt;
This forms a [[graded Lie algebra#graded Lie superalgebras|graded Lie superalgebra]] under the anticommutator of derivations defined on homogeneous derivations ''D''&lt;sub&gt;1&lt;/sub&gt; and ''D''&lt;sub&gt;2&lt;/sub&gt; of degrees ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt;, respectively, by
:&lt;math&gt;[D_1,D_2] = D_1\circ D_2 - (-1)^{d_1d_2}D_2\circ D_1.&lt;/math&gt;

Any [[vector-valued differential form]] ''K'' in Ω&lt;sup&gt;''k''&lt;/sup&gt;(''M'',&amp;nbsp;T''M'') with values in the [[tangent bundle]] of ''M'' defines a graded derivation of degree ''k''&amp;nbsp;&amp;minus;&amp;nbsp;1, denoted by ''i''&lt;sub&gt;''K''&lt;/sub&gt;, and called the insertion operator.  For ω&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;ℓ&lt;/sup&gt;(''M''),
:&lt;math&gt;i_K\,\omega(X_1,\dots,X_{k+\ell-1})=\frac{1}{k!(\ell-1)!}\sum_{\sigma\in{S}_{k+\ell-1}}\textrm{sign}\,\sigma \cdot
\omega(K(X_{\sigma(1)},\dots,X_{\sigma(k)}),X_{\sigma(k+1)},\dots,X_{\sigma(k+\ell-1)})
&lt;/math&gt;
The [[Lie derivative#Nijenhuis–Lie derivative|Nijenhuis–Lie derivative]] along ''K''&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;k&lt;/sup&gt;(''M'',&amp;nbsp;T''M'') is defined by
:&lt;math&gt;\mathcal{L}_K = [d,i_K] =d\,{\circ}\,  i_K-(-1)^{k-1}i_K{\circ}\, d&lt;/math&gt;
where ''d'' is the exterior derivative and ''i''&lt;sub&gt;K&lt;/sub&gt; is the insertion operator.

The Frölicher–Nijenhuis bracket is defined to be the unique vector-valued differential form

:&lt;math&gt;[\cdot, \cdot]_{FN} : \Omega^k(M,\mathrm{T}M) \times \Omega^\ell(M,\mathrm{T}M) \to \Omega^{k+\ell}(M,\mathrm{T}M) : (K, L) \mapsto [K, L]_{FN}&lt;/math&gt; 
such that

:&lt;math&gt;\mathcal{L}_{[K, L]_{FN}} = [\mathcal{L}_K, \mathcal{L}_L].&lt;/math&gt;

Hence,

:&lt;math&gt;
[K, L]_{FN}=-(-1)^{kl}[L,K]_{FN}.
&lt;/math&gt;

If ''k''&amp;nbsp;=&amp;nbsp;0, so that ''K''&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;0&lt;/sup&gt;(''M'',&amp;nbsp;T''M'')
is a vector field, the usual homotopy formula for the Lie derivative is recovered
:&lt;math&gt;\mathcal{L}_K = [d,i_K] =d \,{\circ}\, i_K+i_K \,{\circ}\, d.&lt;/math&gt;

If ''k''=''ℓ''=1, so that ''K,L''&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;1&lt;/sup&gt;(''M'',&amp;nbsp;T''M''),
one has for any vector fields ''X'' and ''Y''
:&lt;math&gt;
[K, L]_{FN}(X,Y) = [KX, LY]+[LX, KY]+(KL+LK)[X,Y]-K([LX,Y]+[X, LY])-L([KX,Y]+[X, KY]).
&lt;/math&gt;

If ''k''=0 and ''ℓ''=1, so that ''K=Z''∈&amp;nbsp;Ω&lt;sup&gt;0&lt;/sup&gt;(''M'',&amp;nbsp;T''M'') is a vector field and ''L''&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;1&lt;/sup&gt;(''M'',&amp;nbsp;T''M''), one has for any vector field ''X''
:&lt;math&gt;
[Z, L]_{FN}(X) = [Z, LX]-L[Z,X].
&lt;/math&gt;

An explicit formula for the Frölicher–Nijenhuis bracket of &lt;math&gt;\phi\otimes X&lt;/math&gt; and &lt;math&gt;\psi\otimes Y&lt;/math&gt; (for forms φ and ψ and vector fields ''X'' and ''Y'') is given by
:&lt;math&gt;\left.\right.[\phi \otimes X,\psi \otimes Y]_{FN} = \phi\wedge\psi\otimes [X,Y] + \phi\wedge\mathcal{L}_X \psi\otimes Y - \mathcal{L}_Y \phi\wedge\psi \otimes  X +(-1)^{\deg(\phi)}(d\phi \wedge i_X(\psi)\otimes Y +i_Y(\phi) \wedge d\psi \otimes X).&lt;/math&gt;

==Derivations of the ring of forms==

Every derivation of Ω&lt;sup&gt;*&lt;/sup&gt;(''M'') can be written as 
:&lt;math&gt;i_L + \mathcal{L}_K&lt;/math&gt;
for unique elements ''K'' and ''L'' of  Ω&lt;sup&gt;*&lt;/sup&gt;(''M'', T''M''). The Lie bracket of these derivations is given as follows.
*The derivations of the form &lt;math&gt;\mathcal{L}_K&lt;/math&gt; form the Lie superalgebra of all derivations commuting with ''d''. The bracket is given by 
::&lt;math&gt;[\mathcal{L}_{K_1},\mathcal{L}_{K_2}]= \mathcal{L}_{[K_1,K_2]}&lt;/math&gt; 
:where the bracket on the right is the Frölicher–Nijenhuis bracket. In particular the Frölicher–Nijenhuis bracket defines a [[graded Lie algebra]] structure on &lt;math&gt;\Omega(M,\mathrm{T}M)&lt;/math&gt;, which extends the [[Lie bracket of vector fields|Lie bracket]] of [[vector field]]s.
*The derivations of the form &lt;math&gt;i_L&lt;/math&gt; form the Lie superalgebra of all derivations vanishing on functions Ω&lt;sup&gt;0&lt;/sup&gt;(''M''). The bracket is given by 
::&lt;math&gt;[i_{L_1},i_{L_2}]= i_{[L_1,L_2]^\land}&lt;/math&gt; 
:where the bracket on the right is the  [[Nijenhuis–Richardson bracket]].
*The bracket of derivations of different types is given by
::&lt;math&gt;[\mathcal{L}_{K}, i_L]= i_{[K,L]} - (-1)^{kl}\mathcal{L}_{i_LK}&lt;/math&gt;
: for ''K'' in &amp;Omega;&lt;sup&gt;k&lt;/sup&gt;(''M'', T''M''), ''L'' in &amp;Omega;&lt;sup&gt;l+1&lt;/sup&gt;(''M'', T''M'').

==Applications==
The [[Nijenhuis tensor]] of an [[almost complex structure]] ''J'', is the Frölicher–Nijenhuis bracket of ''J'' with itself. An almost complex structure is a complex structure if and only if the Nijenhuis tensor is zero.

With the Frölicher–Nijenhuis bracket it is possible to define the [[curvature]] and [[cocurvature]] of a vector-valued 1-form which is a [[projection (mathematics)|projection]]. This generalizes the concept of the curvature of a [[Connection (mathematics)|connection]].

There is a common generalization of the Schouten–Nijenhuis bracket and the Frölicher–Nijenhuis bracket; for details see the article on the [[Schouten–Nijenhuis bracket]].

==References==
*{{citation
 | last1 = Frölicher | first1 = A.
 | last2 = Nijenhuis | first2 = A. | author2-link = Albert Nijenhuis
 | journal = [[Indagationes Mathematicae]]
 | pages = 338–360
 | title = Theory of vector valued differential forms. Part I.
 | volume = 18
 | year = 1956}}.
*{{citation
 | last1 = Frölicher | first1 = A.
 | last2 = Nijenhuis | first2 = A. | author2-link = Albert Nijenhuis
 | journal = Communicationes Mathematicae Helveticae
 | pages = 227–248
 | title = Invariance of vector form operations under mappings
 | volume = 34
 | year = 1960 | doi=10.1007/bf02565938}}.
*{{springer|id=F/f120230|author=P. W. Michor|title=Frölicher–Nijenhuis bracket}}
*{{citation
 | last = Schouten | first = J. A. | author-link = Jan Arnoldus Schouten
 | journal = [[Indagationes Mathematicae]]
 | pages = 449–452
 | title = Über Differentialkonkomitanten zweier kontravarianten Grössen
 | volume = 2
 | year = 1940}}.

{{DEFAULTSORT:Frolicher-Nijenhuis Bracket}}
[[Category:Bilinear operators]]
[[Category:Binary operations]]
[[Category:Differential geometry]]</text>
      <sha1>r2adxs2kq2m54x6h1odqa4lad5t4tvp</sha1>
    </revision>
  </page>
  <page>
    <title>Fuchs relation</title>
    <ns>0</ns>
    <id>57482546</id>
    <revision>
      <id>846310158</id>
      <parentid>846310128</parentid>
      <timestamp>2018-06-17T22:02:51Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <minor/>
      <comment>Michael Hardy moved page [[Fuchs Relation]] to [[Fuchs relation]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5382">In mathematics, the '''Fuchs relation''' is a relation between the starting exponents of formal series solutions of certain linear differential equations, so called ''Fuchsian equations''. It is named after [[Lazarus Fuchs|Lazarus Immanuel Fuchs]].

== Definition Fuchsian equation ==
A [[linear differential equation]] in which every [[Mathematical singularities|singular point]], including the point at infinity, is a [[Regular singular point|regular singularity]] is called ''Fuchsian equation'' or ''equation of Fuchsian type''.&lt;ref name=":2"&gt;{{Cite book|title=Ordinary Differential Equations|last=Ince|first=Edward Lindsay|publisher=Dover Publications|year=1956|isbn=9780486158211|location=New York, USA|pages=370}}&lt;/ref&gt; For Fuchsian equations a formal fundamental system exists at any point, due to the [[Fuchsian theory]].

=== Coefficients of a Fuchsian equation ===
Let &lt;math&gt;a_1, \dots, a_r \in \mathbb{C}&lt;/math&gt; be the &lt;math&gt;r&lt;/math&gt; [[Regular singular point|regular singularities]] in the finite part of the complex plane of the linear differential equation&lt;math&gt;Lf := \frac{d^nf}{dz^n} + q_1\frac{d^{n-1}f}{dz^{n-1}} + \cdots + q_{n-1}\frac{df}{dz} + q_nf&lt;/math&gt;

with [[meromorphic function]]s &lt;math&gt;q_i&lt;/math&gt;. For linear differential equations the singularities are exactly the singular points of the coefficients. &lt;math&gt;Lf=0&lt;/math&gt; is a Fuchsian equation if and only if the coefficients are [[Rational function|rational functions]] of the form

: &lt;math&gt;q_i(z) = \frac{Q_i(z)}{\psi^i}&lt;/math&gt;

with the polynomial &lt;math display="inline"&gt;\psi := \prod_{j=0}^r (z-a_j) \in\mathbb{C}[z]&lt;/math&gt; and certain polynomials &lt;math&gt;Q_i \in \mathbb{C}[z]&lt;/math&gt; for &lt;math&gt;i\in \{1,\dots,n\}&lt;/math&gt;, such that &lt;math&gt;\deg(Q_i) \leq i(r-1)&lt;/math&gt;.&lt;ref&gt;{{Cite book|title=Gewöhnliche Differentialgleichungen beliebiger Ordnung|last=Horn|first=Jakob|publisher=G. J. Göschensche Verlagshandlung|year=1905|isbn=|location=Leipzig, Germany|pages=169}}&lt;/ref&gt; This means the coefficient &lt;math&gt;q_i&lt;/math&gt; has poles of order at most &lt;math&gt;i&lt;/math&gt;, for &lt;math&gt;i\in \{1,\dots,n\}&lt;/math&gt;.

== Fuchs relation ==
Let &lt;math&gt;Lf=0&lt;/math&gt; be a Fuchsian equation of order &lt;math&gt;n&lt;/math&gt; with the singularities &lt;math&gt;a_1, \dots, a_r\in\mathbb{C}&lt;/math&gt; and the point at infinity. Let &lt;math&gt;\alpha_{i1},\dots,\alpha_{in}\in\mathbb{C}&lt;/math&gt; be the roots of the [[Fuchsian Theory|indicial polynomial]] relative to &lt;math&gt;a_i&lt;/math&gt;, for &lt;math&gt;i\in\{1,\dots,r\}&lt;/math&gt;. Let &lt;math&gt;\beta_1,\dots,\beta_n\in\mathbb{C}&lt;/math&gt; be the roots of the indicial polynomial relative to &lt;math&gt;\infty&lt;/math&gt;, which is given by the indicial polynomial of &lt;math&gt;Lf&lt;/math&gt; transformed by &lt;math&gt;z=x^{-1}&lt;/math&gt; at &lt;math&gt;x=0&lt;/math&gt;. Then the so called ''Fuchs relation'' holds:

: &lt;math&gt;\sum_{i=1}^r \sum_{k=1}^n \alpha_{ik} + \sum_{k=1}^n \beta_{k} = \frac{n(n-1)(r-1)}{2}&lt;/math&gt;.&lt;ref&gt;{{Cite book|title=Ordinary Differential Equations|last=Ince|first=Edward Lindsay|publisher=Dover Publications|year=1956|isbn=9780486158211|location=New York, USA|pages=371}}&lt;/ref&gt;

The Fuchs relation can be rewritten as infinite sum. Let &lt;math&gt;P_{\xi}&lt;/math&gt; denote the [[Fuchsian Theory|indicial polynomial]] relative to &lt;math&gt;\xi\in\mathbb{C}\cup\{\infty\}&lt;/math&gt; of the Fuchsian equation &lt;math&gt;Lf=0&lt;/math&gt;. Define &lt;math&gt;\operatorname{defect}: \mathbb{C}\cup\{\infty\}\to\mathbb{C}&lt;/math&gt; as

: &lt;math&gt;\operatorname{defect}(\xi):=
\begin{cases}
	\operatorname{Tr}(P_\xi) - \frac{n(n-1)}{2}\text{, for }\xi\in\mathbb{C}\\
	\operatorname{Tr}(P_\xi) + \frac{n(n-1)}{2}\text{, for }\xi=\infty
\end{cases}&lt;/math&gt;

where &lt;math display="inline"&gt;\operatorname{Tr}(P):=\sum_{\{z\in\mathbb{C}: P(z)=0\}} z&lt;/math&gt; gives the trace of a polynomial &lt;math&gt;P&lt;/math&gt;, i. e., &lt;math&gt;\operatorname{Tr}&lt;/math&gt; denotes the sum of a polynomial's roots counted with multiplicity.

This means that &lt;math&gt;\operatorname{defect}(\xi)=0&lt;/math&gt; for any ordinary point &lt;math&gt;\xi&lt;/math&gt;, due to the fact that the indicial polynomial relative to any ordinary point is &lt;math&gt;P_\xi(\alpha)= \alpha(\alpha-1)\cdots(\alpha-n+1)&lt;/math&gt;. The transformation &lt;math&gt;z=x^{-1}&lt;/math&gt;, that is used to obtain the indicial equation relative to &lt;math&gt;\infty&lt;/math&gt;, motivates the changed sign in the definition of &lt;math&gt;\operatorname{defect}&lt;/math&gt; for &lt;math&gt;\xi=\infty&lt;/math&gt;. The rewritten Fuchs relation is:

: &lt;math&gt;\sum_{\xi\in\mathbb{C}\cup\{\infty\}} \operatorname{defect}(\xi) = 0.&lt;/math&gt;&lt;ref name=":1"&gt;Landl, Elisabeth (2018). The Fuchs Relation (Bachelor Thesis). Linz, Austria. chapter 3.&lt;/ref&gt;

== References ==

* {{Cite book|title=Ordinary Differential Equations|last=Ince|first=Edward Lindsay|publisher=Dover Publications|year=1956|isbn=9780486158211|location=New York, USA}}
* {{Cite book|title=Ordinary Differential Equations|last1=Tenenbaum|first1=Morris|last2=Pollard|first2=Harry|publisher=Dover Publications|year=1963|isbn=9780486649405|location=New York, USA|pages=Lecture 40}}
* {{Cite book|title=Gewöhnliche Differentialgleichungen beliebiger Ordnung|last=Horn|first=Jakob|publisher=G. J. Göschensche Verlagshandlung|year=1905|isbn=|location=Leipzig, Germany}}
* {{Cite book|title=Handbuch der Theorie der linearen Differentialgleichungen (2. Band, 1. Teil)|last=Schlesinger|first=Ludwig Lindsay|publisher=B. G.Teubner|year=1897|isbn=|location=Leipzig, Germany|pages=241 ff.}}
&lt;references /&gt;

[[Category:Complex analysis]]
[[Category:Differential equations]]</text>
      <sha1>tpn7k1stj3pey0pv7z83ckkto26bwoe</sha1>
    </revision>
  </page>
  <page>
    <title>Generic point</title>
    <ns>0</ns>
    <id>3043978</id>
    <revision>
      <id>862641439</id>
      <parentid>862638349</parentid>
      <timestamp>2018-10-05T18:14:22Z</timestamp>
      <contributor>
        <username>Mark viking</username>
        <id>17698045</id>
      </contributor>
      <comment>Adding local [[Wikipedia:Short description|short description]]: "Point of an algebraic variety which has no other property than those shared by almost all other points" ([[User:Galobtter/Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4927">{{short description|Point of an algebraic variety which has no other property than those shared by almost all other points}}
In [[algebraic geometry]], a '''generic point''' ''P'' of an [[algebraic variety]] ''X'' is, roughly speaking, a point at which all [[generic property|generic properties]] are true, a generic property being a property which is true for [[Almost everywhere|almost every]] point.

In classical algebraic geometry, a generic point of an [[affine algebraic variety|affine]] or [[projective algebraic variety]] of dimension ''d'' is a point such that the field generated by its coordinates has the [[transcendence degree]] ''d'' over the field generated by the coefficients of the equations of the variety.

In [[scheme theory]], the [[spectrum of a ring|spectrum]] of an [[integral domain]] has a unique generic point, which is the minimal prime ideal. As the closure of this point for the [[Zariski topology]] is the whole spectrum, the definition has been extended to [[general topology]], where a '''generic point''' of a [[topological space]] ''X'' is a point whose closure is ''X''.

== Definition and motivation ==
A generic point of the topological space ''X'' is a point ''P'' whose [[closure (topology)|closure]] is all of ''X'', that is, a point that is [[dense (topology)|dense]] in ''X''.&lt;ref name="Mumford"&gt;[[David Mumford]], The Red Book of Varieties and Schemes, Springer 1999&lt;/ref&gt;

The terminology arises from the case of the [[Zariski topology]] on the set of [[subvarieties]] of an [[algebraic set]]: the algebraic set is [[irreducible algebraic set|irreducible]] (that is, it is not the union of two proper algebraic subsets) if and only if the topological space of the subvarieties has a generic point.

== Examples ==

*The only [[Hausdorff space]] that has a generic point is the [[singleton set]].
*Any [[Glossary of scheme theory|integral scheme]] has a (unique) generic point; in the case of an affine integral scheme (i.e., the [[Spectrum of a ring|prime spectrum]] of an [[integral domain]]) the generic point is the point associated to the prime ideal (0).

== History ==
{{refimprove|date=July 2011}}
In the foundational approach of [[André Weil]], developed in his ''Foundations of Algebraic Geometry'', generic points played an important role, but were handled in a different manner. For an algebraic variety ''V'' over a [[field (mathematics)|field]] ''K'', ''generic points'' of ''V'' were a whole class of points of ''V'' taking values in a [[universal domain]] Ω, an [[algebraically closed field]] containing ''K'' but also an infinite supply of fresh indeterminates. This approach worked, without any need to deal directly with the topology of ''V'' (''K''-Zariski topology, that is), because the specializations could all be discussed at the field level (as in the [[valuation theory]] approach to algebraic geometry, popular in the 1930s).

This was at a cost of there being a huge collection of equally generic points. [[Oscar Zariski]], a colleague of Weil's at [[São Paulo]] just after [[World War II]], always insisted that generic points should be unique. (This can be put back into topologists' terms: Weil's idea fails to give a [[Kolmogorov space]] and Zariski thinks in terms of the [[Kolmogorov quotient]].)

In the rapid foundational changes of the 1950s Weil's approach became obsolete. In [[scheme theory]], though, from 1957, generic points returned: this time ''à la Zariski''. For example for ''R'' a [[discrete valuation ring]], ''Spec''(''R'') consists of two points, a generic point (coming from the [[prime ideal]] {0}) and a '''closed point''' or '''special point''' coming from the unique [[maximal ideal]]. For morphisms to ''Spec''(''R''), the fiber above the special point is the '''special fiber''', an important concept for example in [[reduction modulo p]], [[monodromy theory]] and other theories about degeneration. The '''generic fiber''', equally, is the fiber above the generic point. Geometry of degeneration is largely then about the passage from generic to special fibers, or in other words how specialization of parameters affects matters. (For a discrete valuation ring the topological space in question is the [[Sierpinski space]] of topologists. Other [[local ring]]s have unique generic and special points, but a more complicated spectrum, since they represent general dimensions. The discrete valuation case is much like the complex [[unit disk]], for these purposes.)

== References ==
&lt;references /&gt;
*{{cite book | first=Steven | last=Vickers | title=Topology via Logic | series=Cambridge Tracts in Theoretic Computer Science | volume=5 | isbn=0-521-36062-5 | year=1989 | page=65 }}
*{{cite book | first=André | last=Weil | title=Foundations of Algebraic Geometry | series=American Mathematical Society Colloquium Publications | volume=XXIX | year=1946 }}

[[Category:Algebraic geometry]]
[[Category:General topology]]</text>
      <sha1>2qqpcyw48zso8a78xz0jptrmdcsytef</sha1>
    </revision>
  </page>
  <page>
    <title>GrGen</title>
    <ns>0</ns>
    <id>19116785</id>
    <revision>
      <id>832455333</id>
      <parentid>774947965</parentid>
      <timestamp>2018-03-26T03:17:51Z</timestamp>
      <contributor>
        <username>Goodmami</username>
        <id>5714311</id>
      </contributor>
      <minor/>
      <comment>Changed "computer linguistics" to "computational linguistics" and other minor language problems</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6350">{{Infobox programming language
| name = GrGen.NET
| logo = [[File:Grgen-256.png|220px]]
| paradigm = [[multi-paradigm programming language|Multi-paradigm]]: [[declarative programming|declarative]], [[imperative programming|imperative]], [[object oriented programming|object-oriented]]
| year = {{Start date|2003}}
| developer = Sebastian Hack, Rubino Geiss, Moritz Kroll, Edgar Jakumeit, and others
| written_in = Java, C#
| latest release version = GrGen.NET 4.5
| latest release date    = {{Start date and age|2017|04|09}}
| turing-complete = Yes
| typing = [[type system|Static, partly dynamic, strong, safe]], [[nominative type system|nominative]]
| operating_system = [[Cross-platform]] (multi-platform)
| license = [[GNU Lesser General Public License]]
| website = {{URL|http://grgen.net/}}
}}

[[File:GrGenNETKochSnowflakeMatch.png|thumb|Debugging of a sequence generating a Koch-snowflake (the rules on the left, GrShell with highlighted current rule below, yComp with highlighted match in the host graph on the right)]]
[[File:GrGenNETKochSnowflakeRewrite.png|thumb|Execution of the replace step]]

'''GrGen.NET''' is a [[software development tool]] that offers [[programming language]]s ([[Domain Specific Language|domain specific languages]]) that are optimized for the processing of [[Graph (data structure)|graph structured]] data.
The core of the languages consists of [[modular]] [[Graph rewriting|graph rewrite rules]], which are built on [[Declarative programming|declarative]] graph pattern matching and rewriting; they are supplemented by many of the constructs that are used in [[Imperative programming|imperative]] and [[Object oriented programming|object-oriented]] programming,
and are completed with language devices known from database [[query language]]s.

The Graph Rewrite [[Code generation (compiler)|GENerator]] [[Compiler|compiles]] the languages into efficient [[Assembly (CLI)|CLI assemblies]] (via [[C Sharp (programming language)|C#]]-Code in an intermediate step), which can be integrated via an [[API]] into code written in any [[List of CLI languages|.NET-language]].
GrGen can be executed under [[Microsoft Windows|Windows]] and [[Linux]] ([[Mono (software)|Mono]] needed) and is [[open source]] available under [[LGPL]] v3.

For rapid prototyping and debugging, an interactive [[Shell (computing)|shell]] and a (VCG-)graph viewer are included in the package.
With its languages and its visual and stepwise debugging, GrGen allows one to develop at the natural level of [[abstraction]] of graph-based representations, such as those employed in [[engineering]], [[model transformation]], [[computational linguistics]], or [[compiler construction]] (as [[Intermediate representation#Intermediate representation|intermediate representation]]).

GrGen increases productivity for those kinds of tasks far beyond what can be achieved by programming in a traditional programming language; due to many implemented performance optimizations it still allows one to achieve high-performance solutions.
Its authors claim that the [[graph rewriting|system]] offers the highest combined speed of [[Software development|development]] and [[Execution (computing)|execution]] available for the [[algorithm]]ic processing of [[Graph (discrete mathematics)|graph]]-based representations (based on their performance regarding diverse tasks posed at different editions of the Transformation Tool Contest (/GraBaTs)).

== Specification sample ==
Below is an example containing a graph model and rule specifications from the GrGen.NET-solution to the [http://www.fots.ua.ac.be/events/grabats2008/cases/grabats2008performancecase.pdf AntWorld-case] posed at [http://www.fots.ua.ac.be/events/grabats2008 Grabats 08].

Graph model:

 '''node class''' GridNode {
     food:int;
     pheromones:int;
 }
 '''node class''' GridCornerNode '''extends''' GridNode;
 '''node class''' AntHill '''extends''' GridNode {
     foodCountdown:int = 10;
 }
 '''node class''' Ant {
     hasFood:boolean;
 }
 
 '''edge class''' GridEdge '''connect''' GridNode[1] -&gt; GridNode[1];
 '''edge class''' PathToHill '''extends''' GridEdge;
 '''edge class''' AntPosition;

Rewrite Rules:

 '''rule''' TakeFood(curAnt:Ant)
 {
     curAnt -:AntPosition-&gt; n:GridNode\AntHill;
     '''if''' { !curAnt.hasFood &amp;&amp; n.food &gt; 0; }
     '''modify''' {
         '''eval''' {
             curAnt.hasFood = true;
             n.food = n.food - 1;
         }
     }
 }
 
 '''rule''' SearchAlongPheromones(curAnt:Ant)
 {
     curAnt -oldPos:AntPosition-&gt; old:GridNode &lt;-:PathToHill- new:GridNode;
     '''if''' { new.pheromones &gt; 9; }
     '''modify''' {
         delete(oldPos);
         curAnt -:AntPosition-&gt; new;
     }
 }
 
 '''test''' ReachedEndOfWorld(curAnt:Ant) : (GridNode)
 {
     curAnt -:AntPosition-&gt; n:GridNode\AntHill;
     '''negative''' { 
         n &lt;-:PathToHill-;
     }
     '''return''' (n);
 }

== External links ==
* Homepage of the [http://www.grgen.net GrGen.NET]-project
* [http://www.info.uni-karlsruhe.de/software/grgen/GrGenNET-Manual.pdf GrGen.NET User Manual]
* [http://www.info.uni-karlsruhe.de/software/grgen/agtive_2007_grgennet.pdf Short introduction into GrGen.NET 1.4 (outdated)]

== Conference papers ==
* [http://www.springerlink.com/content/291511p891rn6616 GrGen: A Fast SPO-Based Graph Rewriting Tool]/[http://www.info.uni-karlsruhe.de/papers/grgen_icgt2006.pdf] - ICGT 06
* [http://www-users.cs.york.ac.uk/~det/Papers/agtive.07.pdf Generation of Sierpinski Triangles: A Case Study for Graph Transformation Tools] - AGTIVE 07
* [http://www.info.uni-karlsruhe.de/papers/agtive_2007_firm.pdf Graph Rewriting for Hardware Dependent Program Optimizations] - AGTIVE 07
* [http://www.info.uni-karlsruhe.de/papers/agtive_2007_search_plan.pdf A First Experimental Evaluation of Search Plan Driven Graph Pattern Matching] - AGTIVE 07 
* [http://www.ipd.uka.de/Tichy/uploads/publikationen/180/gramot2-gelhausen.pdf Customizing GrGen.NET for Model Transformation] - GraMoT 08
* [http://www.informatik.uni-bremen.de/~hof/papers/08-GCM.pdf Graph Rewrite Rules with Structural Recursion] - ICGT/GCM 08 

== See also ==
* [[Graph transformation| Graph transformation / rewriting]] 
* [[Domain Specific Language]] (DSL)
* [[Automatic programming|Source Code Generation]]

[[Category:Domain-specific programming languages]]
[[Category:Graph rewriting]]</text>
      <sha1>g6vyahpble03yy181h7hzd946y2mmir</sha1>
    </revision>
  </page>
  <page>
    <title>Guido Zappa</title>
    <ns>0</ns>
    <id>23748418</id>
    <revision>
      <id>865197208</id>
      <parentid>857359623</parentid>
      <timestamp>2018-10-22T11:48:50Z</timestamp>
      <contributor>
        <ip>86.177.27.206</ip>
      </contributor>
      <comment>/* Honors */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11776">{{Infobox scientist
| name              = Guido Zappa
| image             = Zappa.jpeg
| image_size        = 140px
| alt               =
| caption           = Guido Zappa in 1961
| birth_date        = {{Birth date|df=y|1915|12|7}}
| birth_place       = [[Naples]], Italy
| death_date        = {{Death date and age|2015|3|17|1915|12|7|df=yes}}
| death_place       = [[Florence]], Italy
| residence         =
| citizenship       = [[Italy|Italian]]
| nationality       =
| ethnicity         =
| fields            =
| workplaces        = [[University of Florence]]
| alma_mater        = [[Scuola Normale Superiore]]
| doctoral_advisor  =
| academic_advisors = [[Francesco Severi]]
| doctoral_students =
| notable_students  =
| known_for         = [[Algebraic geometry]]&lt;br&gt;[[Group theory]]
| author_abbrev_bot =
| author_abbrev_zoo =
| influences        =
| influenced        =
| awards            =
| religion          = [[Roman Catholic]]
| signature         =  &lt;!-- (filename only) --&gt;
| signature_alt     =
| footnotes         =
}}

'''Guido Zappa''' (7 December 1915 – 17 March 2015) was an [[Italians|Italian]] mathematician and a noted [[Group theory|group theorist]]: his other main research interests were [[geometry]] and also the [[history of mathematics]]. Zappa was particularly known for some examples of [[algebraic curves]] that strongly influenced the ideas of [[Francesco Severi]].&lt;ref&gt;See the [[#{{harvid|The Editorial Office|2015}}|18 March 2015 obituary]] published on "[[Il Mattino]]" newspaper.&lt;/ref&gt;

== Life and work ==

=== Honors ===

He was elected ordinary non-resident member of the [[Accademia Pontaniana]] on June 16, 1949.&lt;ref&gt;According to the [[#{{harvid|Accademia Pontaniana|2015}}|Accademia Pontaniana yearbook (2015]], p. 116).&lt;/ref&gt;
On June 3, 1951 he was elected corresponding member to the class of mathematical sciences of the [[Società Nazionale di Scienze Lettere e Arti in Napoli]]: subsequently, he became ordinary member (2 June 1951) and ordinary non-resident member (15 December 1953).&lt;ref&gt;See the [[#{{harvid|Società Nazionale di Scienze Lettere e Arti in Napoli|2014}}|Society yearbook (2014]], p. 56).&lt;/ref&gt;
On 14 October 1960 he was elected corresponding member of the [[Accademia Nazionale dei Lincei]]: he became national member of the same [[academy]] on March 21, 1977.&lt;ref&gt;See the [[#{{harvid|Accademia Nazionale dei Lincei|2012}}|Lincean Academy yearbook (2012]], p. 545).&lt;/ref&gt;

== Selected publications ==

*{{Citation
|last = Zappa
|first = Guido
|title = Fondamenti di teoria dei gruppi. Volume primo
|place = [[Rome, Italy|Roma]]
|language = Italian
|publisher = Edizioni Cremonese
|year = 1965
|series = Monografie matematiche del [[Consiglio Nazionale delle Ricerche]]
|volume = 13
|pages = XX+291
|mr = 0197538
|zbl = 0135.03402}}. "''Fundamentals of group theory. First volume''" (English translation of the title) is the first part of monograph in [[group theory]] dealing extensively with many of its aspects.
*{{Citation
|last = Zappa
|first = Guido
|title = Fondamenti di teoria dei gruppi. Volume secondo
|place = [[Rome]]
|language = Italian
|publisher = Edizioni Cremonese
|year = 1970
|series = Monografie matematiche del [[Consiglio Nazionale delle Ricerche]]
|volume = 18
|pages =XXI+411
|mr = 258926
|zbl = 0201.03001}}. "''Fundamentals of group theory. Second volume''" (English translation of the title) is the second part of monograph in [[group theory]] dealing extensively with many of its aspects.
*{{Citation
|last = Zappa
|first = Guido
|author-link = Guido Zappa
|title = La scuola matematica di Francesco Severi intorno al 1940
|trans-title=The mathematical school of Francesco Severi around 1940
|language = Italian
|journal = [[Rivista di Matematica della Università di Parma]]
|series = (4)
|volume = 10&lt;sup&gt;*&lt;/sup&gt;
|pages = 11–14
|year = 1984
|url = http://rivista.math.unipr.it/fulltext/1984-10s/1984-10s-011.pdf
|mr = 0777309
|zbl = 0562.01015
}}. This work describes the research activity at the [[Sapienza University of Rome]] and at the (at that time newly created) "[[Istituto Nazionale di Alta Matematica Francesco Severi]]" from the end of the 1930s to the early 1940s.

== See also ==

* [[Algebraic geometry]]
* [[Group theory]]
* [[Italian school of algebraic geometry]]
* [[Francesco Severi]]
* [[Zappa-Szép product]]

== Notes ==
{{reflist|30em}}

== References ==
{{refbegin}}

=== Biographical and general references ===
*{{Citation
|author = Accademia Nazionale dei Lincei
|author-link = Accademia Nazionale dei Lincei
|title = Annuario dell'Accademia Nazionale dei Lincei 2012 – CDX dalla Sua Fondazione
|place = Roma
|publisher = Accademia Nazionale dei Lincei
|year = 2012
|edition =
|page = 734
|language = Italian
|url = http://www.lincei.it/files/doc/ANL_Annuario_2012.pdf
|doi =
|id =
|isbn =
|accessdate =2016-03-16}}. The "''Yearbook''" of the renowned Italian scientific institution, including an historical sketch of its history, the list of all past and present members as well as a wealth of informations about its academic and scientific activities.
*{{Citation
|last =Accademia Pontaniana
|author-link = Accademia Pontaniana
|title =Annuario della Accademia Pontaniana 2015 (DLXXIII dalla fondazione)
|place =Napoli
|publisher =Nella Sede dell'Accademia
|year =2015
|chapter =
|chapterurl =
|page =180
|language = Italian
|url =http://www.accademiapontaniana.it/AnnuarioAccademiaNA.pdf
|doi =
|id =
|isbn =
|accessdate =2016-03-16}}. The "Yearbook 2015" of the Accademia Pontaniana, published by the Academy itself and describing its past and present hierarchies and its activities. It also gives some notes on its history, the full list of its members and other useful information.
*{{Citation
|last=Mariano
|first=Paolo
|title=Addio a Guido Zappa. Approfondì nell'algebra la teoria dei gruppi
|newspaper=[[Il Corriere della Sera]]
|page=47
|date=19 March 2015
|url=http://archiviostorico.corriere.it/2015/marzo/19/Addio_Guido_Zappa_Approfondi_nell_co_0_20150319_f5b25c78-ce05-11e4-a3a0-3da0e7525085.shtml |accessdate=11 April 2015
|deadurl=yes
|archiveurl=https://web.archive.org/web/20150415110146/http://archiviostorico.corriere.it/2015/marzo/19/Addio_Guido_Zappa_Approfondi_nell_co_0_20150319_f5b25c78-ce05-11e4-a3a0-3da0e7525085.shtml
|archivedate=April 15, 2015}}.
*{{Citation
|editor-last =Ridolfi
|editor-first =Roberto
|editor-link =
|contribution =Guido Zappa
|contribution-url =
|title=Biografie e bibliografie degli Accademici Lincei
|trans-title =Biographies and bibliographies of the Lincean Academicians
|place =[[Rome|Roma]]
|publisher =[[Accademia Nazionale dei Lincei]]
|year =1976
|pages =677–680
|language =Italian
|url =
|doi =
|id =
|isbn =
}}. The biographical and bibliographical entry (updated up to 1976) on Guido Zappa, published under the auspices of the Accademia dei Lincei in a book collecting many profiles of its members living members up to 1976.
*{{Citation
|last =The Editorial Office
|author-link =
|title =Addio a Guido Zappa, gigante napoletano della Matematica
|newspaper =[[Il Mattino]]
|date =18 March 2015
|language =Italian
|url =http://www.ilmattino.it/NAPOLI/CRONACA/morto-guido-zappa-matematica/notizie/1245757.shtml
|accessdate = 11 April 2015}}
*{{Citation
|last =The Editorial Office
|author-link =
|title =Necrologie
|newspaper =[[Quotidiano.net]]
|date =19 March 2015
|language =Italian
|url =http://www.quotidiano.net/necro/ann/ZAPPA%20GUIDO/
|accessdate = 11 April 2015}}
*{{Citation
|last =Società Nazionale di Scienze Lettere e Arti in Napoli
|author-link = Società Nazionale di Scienze Lettere e Arti in Napoli
|title =Annuario della Società Nazionale di Scienze Lettere e Arti in Napoli – 2014
|place =Napoli
|publisher =Società Nazionale di Scienze Lettere e Arti in Napoli
|year =2014
|chapter =
|chapterurl =
|page =82
|language = Italian
|url =http://www.societanazionalescienzeletterearti.it/pdf/annuario2014.pdf
|doi =
|id =
|isbn =
|accessdate =2016-03-16}}. The "Yearbook 2014" of the Società Nazionale di Scienze Lettere e Arti in Napoli, published by the society itself and describing its past and present hierarchies, and its activities. It also reports some notes on its history, the full list of its members and other useful information.

=== Scientific references ===

*{{Citation
|last = Barlotti
|first = A.
|last2 = Rosati
|first2 = L. A.
|title = Guido Zappa e la geometria combinatoria
|booktitle =
|language = Italian
|journal = [[Rendiconti del Circolo Matematico di Palermo]], Supplementi
|series = II
|volume = 19
|pages = 9–18
|year = 1988
|url = http://www.math.unipa.it/~circmat/indice_19_1988.htm
|doi =
|mr = 0988182
|zbl = 0884.51008}}. ''Guido Zappa and combinatorial geometry'' (English translation of the title), a paper from the ''Atti del Convegno Internazionale di Teoria dei Gruppi e Geometria Combinatoria - Firenze, Ottobre 23–26 1986, in onore di Guido Zappa'' (Proceedings of the international conference on group theory and combinatorial geometry held in Florence on October 23–26, 1986 in honor of Guido Zappa), describes his contributions to [[combinatorial geometry]].
*{{Citation
|last = Curzio
|first = Mario
|title = Guido Zappa e la teoria dei gruppi
|journal = [[Rendiconti del Circolo Matematico di Palermo]], Supplementi
|language = Italian
|series = II
|volume = 19
|pages = 19–34
|year = 1988
|url = http://www.math.unipa.it/~circmat/indice_19_1988.htm
|doi =
|mr = 0988184
|zbl = 0900.20001}}. ''Guido Zappa and group theory'' (English translation of the title), a paper from the ''Atti del Convegno Internazionale di Teoria dei Gruppi e Geometria Combinatoria - Firenze, Ottobre 23–26 1986, in onore di Guido Zappa'' (Proceedings of the international conference on group theory and combinatorial geometry held in Florence on October 23–26, 1986 in honor of Guido Zappa), describes his contributions to group theory.
* {{Citation
|last =D’Agnolo
|first =Andrea
|author-link =
|last2 =Zacher
|first2 =Giovanni
|author2-link =
|title =Dedication to Guido Zappa on his 90th anniversary
|journal =[[Rendiconti del Seminario Matematico della Università di Padova]]
|volume =115
|pages =v–xi
|year =2006
|language =
|url =http://www.numdam.org/item?id=RSMUP_2006__115__R5_0
|mr =2245582
|zbl =1167.01318
}}
*{{Citation
|last = Gherardelli
|first = Francesco
|title = I contributi di Zappa alla geometria algebrica
|journal = [[Rendiconti del Circolo Matematico di Palermo]], Supplementi
|language = Italian
|series = II
|volume = 19
|pages = 35–38
|year = 1988
|url = http://www.math.unipa.it/~circmat/indice_19_1988.htm
|doi =
|mr = 0988185
|zbl = 0889.01019}}. ''The contributions of Zappa to algebraic geometry'' (English translation of the title), a paper from the ''Atti del Convegno Internazionale di Teoria dei Gruppi e Geometria Combinatoria - Firenze, Ottobre 23–26 1986, in onore di Guido Zappa'' (Proceedings of the international conference on group theory and combinatorial geometry held in Florence on October 23–26, 1986 in honor of Guido Zappa), describes his contributions to algebraic geometry.
{{refend}}

== External links ==

* {{MathGenealogy|id=113087|title=Guido Zappa}}
* [http://www.accademiadellescienze.it/accademia/soci/guido-zappa Guido Zappa academic member page] at the [[Accademia delle Scienze di Torino]].

{{Authority control}}

{{DEFAULTSORT:Zappa, Guido}}

[[Category:1915 births]]
[[Category:20th-century Italian mathematicians]]
[[Category:Italian mathematicians]]
[[Category:20th-century Roman Catholics]]
[[Category:21st-century Italian mathematicians]]
[[Category:21st-century Roman Catholics]]
[[Category:Algebraic geometers]]
[[Category:Group theorists]]
[[Category:Historians of mathematics]]
[[Category:Members of the Lincean Academy]]
[[Category:2015 deaths]]</text>
      <sha1>9fxw2j35ywqpfq4bgkhhsgg89w934hc</sha1>
    </revision>
  </page>
  <page>
    <title>Henry Helson</title>
    <ns>0</ns>
    <id>35258187</id>
    <revision>
      <id>828494954</id>
      <parentid>828479996</parentid>
      <timestamp>2018-03-02T22:16:25Z</timestamp>
      <contributor>
        <username>Huon</username>
        <id>654492</id>
      </contributor>
      <comment>rv unhelpful links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5446">{{Redirect|Helson|the psychologist|Ravenna Helson}}
[[File:Henry Helson.jpg|thumb|220px|Henry Helson]]
'''Henry Berge  Helson''' (June 2, 1927 – January 10, 2010) was an American mathematician at the [[University of California at Berkeley]] who worked on analysis.

==Education and career==
Helson received his bachelor's degree from Harvard University in 1947. With the support of a Harvard travelling fellowship, he spent the academic year 1947–1948 in Europe; he visited London, Paris, Prague, and Vienna, but spent most of his time in Warsaw and then from spring 1948 in Wroclaw, where he worked with [[Edward Marczewski|Marczewski]]. Helson received his Ph.D. in 1950 from Harvard with supervisor [[Lynn Harold Loomis|Lynn Loomis]]&lt;ref&gt;{{MathGenealogy|id=23215}}&lt;/ref&gt; and then spent the academic year 1950–1951 primarily in Uppsala working with [[Arne Beurling|Beurling]] but with frequent trips elsewhere in Europe. He became in 1951 an instructor and then an assistant professor at Yale University. He became in 1955 an assistant professor, in 1958 an associate professor, and in 1961 a full professor at the [[University of California, Berkeley]], retiring there as professor emeritus in 1993. In 1970 he was an Invited Speaker at the [[International Congress of Mathematicians|ICM]] in Nice.&lt;ref&gt;Helson, Henry. [http://www.mathunion.org/ICM/ICM1970.2/Main/icm1970.2.0477.0482.ocr.pdf "Cocycles in harmonic analysis."] Actes du congreés international des matheèmaticiens (1970).&lt;/ref&gt;

==Helson sets==
If G is an infinite, nondiscrete, [[locally compact group]], then a '''Helson set''' is defined to be a compact set P in G such that every continuous function on P can be extended to a function in the [[Fourier algebra]] A(G) in the group G.&lt;ref&gt;{{cite journal|author=Dunkl, Charles F.|authorlink=Charles F. Dunkl|author2=Ramirez, Donald E.|title=Helson sets in compact and locally compact groups|journal=Michigan Math. J.|year=1972|volume=19|issue=1|pages=65–69|url=http://people.virginia.edu/~der/pdf/der15.pdf|doi=10.1307/mmj/1029000799}}&lt;/ref&gt; Helson was the first to prove that there exist [[Perfect set property|perfect]] Helson sets for the case of the group consisting of the real line.&lt;ref&gt;{{cite journal|author=Rudin, Walter|authorlink=Walter Rudin|title=Fourier-Stieltjes transforms of measures on independent sets|journal=Bull. Amer. Math. Soc.|year=1960|volume=66|issue=3|pages=199–202|url=http://www.ams.org/journals/bull/1960-66-03/S0002-9904-1960-10433-8/S0002-9904-1960-10433-8.pdf|doi=10.1090/s0002-9904-1960-10433-8}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Helson, Henry|title=Fourier transforms on perfect sets|journal=Studia Math.|year=1954|volume=14|pages=209–213}}&lt;/ref&gt;

==Legacy==
Helson founded the mathematics-specialty publishing company Berkeley Books. Upon his death he was survived by his wife, a daughter, two sons, and three grandchildren. His doctoral students include [[Frank Forelli]] and [[Udai Bhan Tewari|Udai Tewari]]. 

==Selected works==
* {{cite journal|title=Proof of a conjecture of Steinhaus|journal=Proc Natl Acad Sci U S A|date=March 1954|volume=40|issue=3|pages=205–208|pmc=527972|doi=10.1073/pnas.40.3.205|pmid=16589456}}
* {{cite journal|title=Conjugate series and a theorem of Paley|journal=Pacific J. Math.|year=1958|volume=8|issue=3|pages=437–446|mr=0098952|doi=10.2140/pjm.1958.8.437}}
* with David Lowdenslager: {{cite journal|title=Prediction theory and Fourier series of several complex  variables|journal=Acta Math.|year=1958|volume=99|pages=165–202|mr=97688|doi=10.1007/bf02392425}}
* {{cite journal|title=Conjugate series in several variables|journal=Pacific J. Math.|year=1959|volume=9|issue=2|pages=513–523|mr=0107777|doi=10.2140/pjm.1959.9.513}}
* with David Lowdenslager: {{cite journal|title=Prediction theory and Fourier series of several complex  variables. II|journal=Acta Math.|year=1961|volume=106|pages=175–213|mr=0176287|doi=10.1007/bf02545786}}
* {{cite book|title=Lectures on invariant subspaces|year=1964|publisher=Academic Press|location=New York}}
* {{cite book|title=Harmonic Analysis|year=1983|publisher=Addison-Wesley|location=Reading, Mass.|postscript=; rev. 2nd edn, 1995, publ. Hindustan Book Agency and Helson Publishing Co.}}&lt;ref&gt;{{cite journal|author=Cooke, Roger|title=Book review of ''Harmonic Analysis, 2nd edn'' by Henry Helson|journal=Bull. Amer. Math. Soc. (N.S.)|date=Oct 1996|volume=3|issue=4|pages=505–508|url=http://www.ams.org/journals/bull/1996-33-04/S0273-0979-96-00682-9/|doi=10.1090/S0273-0979-96-00682-9}}&lt;/ref&gt;
* with Farhad Zabihi: {{cite journal|title=A geometric problem in function theory|journal=Illinois J. Math.|year=2007|volume=51|issue=3|pages=1027–1034|mr=2379736}}

==References==
{{reflist}}
*{{Citation | editor1-last=Sarason | editor1-first=Donald | title=A tribute to Henry Helson | url=http://www.ams.org/notices/201102/index.html |mr=2768120 | year=2011 | journal=[[Notices of the American Mathematical Society]] | issn=0002-9920 | volume=58 | issue=2 | pages=274–288}}
*{{MathGenealogy|id=23215}}

{{Authority control}}

{{DEFAULTSORT:Helson, Henry}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Harvard University alumni]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Mathematical analysts]]
[[Category:1927 births]]
[[Category:2010 deaths]]
[[Category:University of California, Berkeley faculty]]</text>
      <sha1>nxokzlfhnpjlpm3m7xuuqqi2atdci25</sha1>
    </revision>
  </page>
  <page>
    <title>Hexagonal pyramidal number</title>
    <ns>0</ns>
    <id>8748764</id>
    <revision>
      <id>817820853</id>
      <parentid>575621258</parentid>
      <timestamp>2017-12-30T20:04:27Z</timestamp>
      <contributor>
        <username>Nmohar</username>
        <id>32661224</id>
      </contributor>
      <minor/>
      <comment>Edited for clarity of relation to hexagonal numbers</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="670">A '''hexagonal pyramidal number''' is a [[pyramidal number]] formed by adding the first ''n'' [[hexagonal number]]s. The first few hexagonal pyramidal numbers are:
:{{num|1}}, {{num|7}}, {{num|22}}, {{num|50}}, {{num|95}}, {{num|161}}, {{num|252}}, 372, 525, 715, 946, 1222, 1547, 1925 {{OEIS|A002412}}.

The ''n''th number in this sequence, representing the sum of the first ''n'' [[hexagonal number]]s, is given by the formula
:&lt;math&gt;\frac{n(n+1)(4n-1)}{6}.&lt;/math&gt;

== References ==
*[http://mathworld.wolfram.com/HexagonalPyramidalNumber.html Hexagonal pyramidal number at MathWorld]

{{Classes of natural numbers}}

[[Category:Figurate numbers]]


{{numtheory-stub}}</text>
      <sha1>bcduh09s63v1qzkyolpl3iweu9ob8t5</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert's second problem</title>
    <ns>0</ns>
    <id>152759</id>
    <revision>
      <id>841573694</id>
      <parentid>813688068</parentid>
      <timestamp>2018-05-16T17:28:58Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12799">In [[mathematics]], '''Hilbert's second problem''' was posed by [[David Hilbert]] in 1900 as one of his [[Hilbert's problems|23 problems]].  It asks for a proof that the arithmetic is [[consistency proof|consistent]] &amp;ndash; free of any internal contradictions. Hilbert  stated that the axioms he considered for arithmetic were the ones given in {{harvtxt|Hilbert|1900}}, which include a second order completeness axiom.

In the 1930s, [[Kurt Gödel]] and [[Gerhard Gentzen]] proved results that cast new light on the problem.  Some feel that Gödel's theorems give a negative solution to the problem, while others consider Gentzen's proof as a partial positive solution.

== Hilbert's problem and its interpretation ==

In one English translation, Hilbert asks:
&lt;blockquote&gt;
"When we are engaged in investigating the foundations of a science, we must set up a system of axioms which contains an exact and complete description of the relations subsisting between the elementary ideas of that science. ...  But above all I wish to designate the following as the most important among the numerous questions which can be asked with regard to the axioms: To prove that they are not contradictory, that is, that a definite number of logical steps based upon them can never lead to contradictory results. In geometry, the proof of the compatibility of the axioms can be effected by constructing a suitable field of numbers, such that analogous relations between the numbers of this field correspond to the geometrical axioms. ... On the other hand a direct method is needed for the proof of the compatibility of the arithmetical axioms."&lt;ref&gt;From the English translation by M. Newson, 1902 provided by http://aleph0.clarku.edu/~djoyce/hilbert/problems.html .&lt;/ref&gt;  &lt;/blockquote&gt;

Hilbert's statement is sometimes misunderstood, because by the "arithmetical axioms" he did not mean a system equivalent to Peano arithmetic, but a stronger system with a second-order completeness axiom. The system Hilbert asked for a completeness proof of is more like [[second-order arithmetic]] than first-order Peano arithmetic.

As a nowadays common interpretation, a positive solution to Hilbert's second question would in particular provide a proof that [[Peano arithmetic]] is consistent.

There are many known proofs that Peano arithmetic is consistent that can be carried out in strong systems such as [[Zermelo–Fraenkel set theory]].  These do not provide a resolution to Hilbert's second question, however, because someone who doubts the consistency of Peano arithmetic is unlikely to accept the axioms of set theory (which is much stronger) to prove its consistency.  Thus a satisfactory answer to Hilbert's problem must be carried out using principles that would be acceptable to someone who does not already believe PA is consistent.  Such principles are often called [[finitism|finitistic]] because they are completely constructive and do not presuppose a completed infinity of natural numbers.  [[Gödel's incompleteness theorem]] places a severe limit on how weak a finitistic system can be while still proving the consistency of Peano arithmetic.

== Gödel's incompleteness theorem ==
{{main|Gödel's incompleteness theorems}}

Gödel's [[second incompleteness theorem]] shows that it is not possible for any proof that Peano Arithmetic is consistent to be carried out within Peano arithmetic itself.  This theorem shows that if the only acceptable proof procedures are those that can be formalized within arithmetic then Hilbert's call for a consistency proof cannot be answered.  However, as Nagel and Newman (1958:96&amp;ndash;99) explain, there is still room for a proof that cannot be formalized in arithmetic:

:"This imposing result of Godel's analysis should not be misunderstood: it does not exclude a meta-mathematical proof of the consistency of arithmetic. What it excludes is a proof of consistency that can be mirrored by the formal deductions of arithmetic. Meta-mathematical proofs of the consistency of arithmetic have, in fact, been constructed, notably by [[Gerhard Gentzen]], a member of the Hilbert school, in 1936, and by others since then. ...  But these meta-mathematical proofs cannot be represented within the arithmetical calculus; and, since they are not finitistic, they do not achieve the proclaimed objectives of Hilbert's original program. ... The possibility of constructing a finitistic absolute proof of consistency for arithmetic is not excluded by Gödel’s results. Gödel showed that no such proof is possible that can be represented within arithmetic. His argument does not eliminate the possibility of strictly finitistic proofs that cannot be represented within arithmetic. But no one today appears to have a clear idea of what a finitistic proof would be like that is not capable of formulation within arithmetic."&lt;ref&gt;A similar quotation with minor variations in wording appears in the 2001 edition p.107-108, as revised by Douglas R. Hofstadter, New York University Press, NY, {{ISBN|0-8147-5816-9}}.&lt;/ref&gt;

== Gentzen's consistency proof ==

{{main|Gentzen's consistency proof}}

In 1936, Gentzen published a proof that Peano Arithmetic is consistent. Gentzen's result shows that a consistency proof can be obtained in a system that is much weaker than set theory.

Gentzen's proof proceeds by assigning to each proof in Peano arithmetic an [[ordinal number]], based on the structure of the proof, with each of these ordinals less than [[epsilon zero|ε&lt;sub&gt;0&lt;/sub&gt;]].&lt;ref&gt;Actually, the proof assigns a "notation" for an ordinal number to each proof.  The notation is a finite string of symbols that intuitively stands for an ordinal number.  By representing the ordinal in a finite way, Gentzen's proof does not presuppose strong axioms regarding ordinal numbers.&lt;/ref&gt; He then proves by [[transfinite induction]] on these ordinals that no proof can conclude in a contradiction.  The method used in this proof can also be used to prove a [[cut elimination]] result for [[Peano arithmetic]] in a stronger logic than first-order logic, but the consistency proof itself can be carried out in ordinary first-order logic using the axioms of [[primitive recursive arithmetic]] and a transfinite induction principle.  Tait (2005) gives a game-theoretic interpretation of Gentzen's method.

Gentzen's consistency proof initiated the program of [[ordinal analysis]] in proof theory.  In this program, formal theories of arithmetic or set theory are assigned [[ordinal numbers]] that measure the [[consistency strength]] of the theories. A theory will be unable to prove the consistency of another theory with a higher proof theoretic ordinal.

== Modern viewpoints on the status of the problem ==

While the theorems of Gödel and Gentzen are now well understood by the mathematical logic community, no consensus has formed on whether (or in what way) these theorems answer Hilbert's second problem.  Simpson (1988:sec. 3) argues that Gödel's incompleteness theorem shows that it is not possible to produce finitistic consistency proofs of strong theories.  Kreisel (1976) states that although Gödel's results imply that no finitistic syntactic consistency proof can be obtained, semantic (in particular, [[Second-order logic|second-order]]) arguments can be used to give convincing consistency proofs. Detlefsen (1990:p.&amp;nbsp;65) argues that Gödel's theorem does not prevent a consistency proof because its hypotheses might not apply to all the systems in which a consistency proof could be carried out. Dawson (2006:sec. 2) calls the belief that Gödel's theorem eliminates the possibility of a persuasive consistency proof "erroneous", citing the consistency proof given by Gentzen and a later one given by Gödel in 1958.

==See also==
* [[Takeuti conjecture]]

==Notes==
&lt;references/&gt;

==References==
* Dawson, John W. (2006) "Shaken foundations or groundbreaking realignment? A Centennial Assessment of Kurt Gödel’s Impact on Logic, Mathematics, and Computer Science". ''2006 21st Annual IEEE Symposium on Logic in Computer Science'', IEEE, pp.&amp;nbsp;339&amp;ndash;341. {{ISBN|0-7695-2631-4}} {{DOI|10.1109/LICS.2006.47}}
* {{cite journal
| title = On an alleged refutation of Hilbert's Program using Gödel's First Incompleteness Theorem 
| journal = Journal of Philosophical Logic 
| doi = 10.1007/BF00263316
| volume = 19
| issue =  4 
| year =  1990
| pages = 343–377
| author = Michael Detlefsen 
| publisher=	Springer }}
* Torkel Franzen (2005),  ''Godel's theorem: An Incomplete Guide to its Use and Abuse'', A.K. Peters, Wellesley MA.  {{ISBN|1-56881-238-8}}
*[[Gerhard Gentzen]] (1936).  "Die Widerspruchsfreiheit der reinen Zahlentheorie."  ''Mathematische Annalen'', v. 112, pp.&amp;nbsp;493&amp;ndash;565.
* {{cite journal | last1 = Gödel | first1 = Kurt | authorlink = Kurt Gödel | year = 1931 | title = Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme, I | url = http://home.ddc.net/ygg/etext/godel/ | journal = Monatshefte für Mathematik und Physik | volume = 38 | issue =  | pages = 173–98 | deadurl = yes | archiveurl = https://web.archive.org/web/20060705205103/http://home.ddc.net/ygg/etext/godel/ | archivedate = 2006-07-05 | df =  }} Translated in [[Jean van Heijenoort]], 1967. ''From Frege to Gödel: A Source Book on Mathematical Logic''. Harvard University Press: 596-616.
*{{citation|title=Über den Zahlbegriff
|first=David |last=Hilbert|journal=Jahresbericht der Deutschen Mathematiker-Vereinigung|year=1900|volume=8|pages=180–184|url=http://resolver.sub.uni-goettingen.de/purl?PPN37721857X}}
*[[David Hilbert]] [1900] (1901) "Mathematische Probleme". ''Archiv der Mathematik und Physik'', v. 3 n. 1, pp.&amp;nbsp;44&amp;ndash;63 and 213&amp;ndash;237.  English translation,  Maby Winton, ''Bulletin of the American Mathematical Society'' 8 (1902), 437&amp;ndash;479. Available online at http://aleph0.clarku.edu/~djoyce/hilbert/problems.html .
* {{cite conference
  | author = George Kreisel
  | title = What have we learnt from Hilbert's second problem?
  | booktitle = Mathematical developments arising from Hilbert problems (Proc. Sympos. Pure Math., Northern Illinois Univ., De Kalb, Ill.,)
  | pages = 93&amp;ndash;130
  | publisher = Amer. Math. Soc.
  | year = 1976 
  | location = Providence, R. I.
  | isbn = 0-8218-1428-1
}}
* Nagel, Ernest and Newman, James R., ''Godel's Proof'', New York University Press, 1958.
*{{cite journal | doi = 10.2307/2274508 | author = Stephen G. Simpson
| title = Partial realizations of Hilbert's Program | jstor = 2274508
| journal = Journal of Symbolic Logic
| volume = 53
| issue = 2
| year = 1988 
| pages = 349&amp;ndash;363
| ISSN = 0022-4812 
| citeseerx = 10.1.1.79.5808}} Available online at http://www.math.psu.edu/simpson/papers/hilbert.pdf .
* [[William W. Tait]] (2005). "Gödel's reformulation of Gentzen's first consistency proof of arithmetic: the no-counterexample interpretation." ''Bulletin of Symbolic Logic'' v. 11 n. 2, pp.&amp;nbsp;225&amp;ndash;238.
&lt;!-- not cited at the moment, I don't know that it is relevant
*[[Stephen Kleene]] (1952) ''Introduction to Metamathematics''. Walters-Noordhoff &amp; North-Holland, with corrections (6th imprint 1971); Tenth impression 1991, ISBN 0-7204-2103-9. --&gt;
&lt;!-- not cited at the moment
* [[Torkel Franzén]], ''Gödel's Theorem: An Incomplete Guide to Its Use and Abuse'', AK Peters, Wellesley, Mass., 2005.
--&gt;

==External links==
* [http://www.mathematik.uni-bielefeld.de/~kersten/hilbert/rede.html Original text of Hilbert's talk, in German]
* [http://aleph0.clarku.edu/~djoyce/hilbert/toc.html English translation of Hilbert's 1900 address]

&lt;!-- holding area
&lt;ref&gt;
:A definition of a "finitary formal system" is given by Goldstein (p. 144, footnote 7):
:: "...''finitary'' formal systems... formal systems with a finite or denumerable (or countable) alphabet of symbols, wffs [well-formed-formulas] of finite length, and rules of inference involving only finitely many premises. (Logicians also work with formal systems with uncountable alphabets, with infinitely long wffs, and with proofs having infinitely many premises."(p. 144, footnote 7)
&lt;/ref&gt; 
--&gt;

&lt;!-- It is widely held that [[Gödel's second incompleteness theorem]] shows that there is no [[finitism|finitistic]] proof that PA is consistent (though Gödel himself disclaimed this inference [this needs a better reference-- but cf Dawson p.71ff "...Gödel too [like Hilbert] believed that no mathematical problems lay beyond the reach of human reason. Yet his results showed that the program that Hilbert had proposed to validate that belief -- his proof theory -- could not be carried through as Hilbert had envisioned" (p.71) See also p. 98ff for more discussion of 'finite procedure').  --&gt;

{{Hilbert's problems}}

[[Category:Hilbert's problems|#02]]</text>
      <sha1>gsdee3135mz9vw44zf2p3sygezze587</sha1>
    </revision>
  </page>
  <page>
    <title>Information security</title>
    <ns>0</ns>
    <id>15036</id>
    <revision>
      <id>870535599</id>
      <parentid>870531542</parentid>
      <timestamp>2018-11-25T13:22:28Z</timestamp>
      <contributor>
        <username>Wtmitchell</username>
        <id>136745</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2.49.186.214|2.49.186.214]] ([[User talk:2.49.186.214|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="91197">{{Computer security}}
'''Information security''', sometimes shortened to '''InfoSec''', is the practice of preventing unauthorized access, use, disclosure, disruption, modification, inspection, recording or destruction of [[information]]. The information or data may take any form, e.g. electronic or physical.&lt;ref name=":0"&gt;{{usc|44|3542}}(b)(1)&lt;/ref&gt; Information security's primary focus is the balanced protection of the confidentiality, integrity and availability of data (also known as the CIA triad) while maintaining a focus on efficient policy implementation, all without hampering organization productivity.&lt;ref name="AndressTheBasics14"&gt;{{cite book |url=https://books.google.com/books?id=9NI0AwAAQBAJ&amp;pg=PA6 |title=The Basics of Information Security: Understanding the Fundamentals of InfoSec in Theory and Practice |author=Andress, J. |publisher=Syngress |pages=240 |year=2014 |isbn=9780128008126}}&lt;/ref&gt; This is largely achieved through a multi-step risk management process that identifies assets, threat sources, vulnerabilities, potential impacts, and possible controls, followed by assessment of the effectiveness of the risk management plan.

To standardize this discipline, academics and professionals collaborate and seek to set basic guidance, policies, and industry standards on [[password]], [[antivirus software]], [[firewall (computing)|firewall]], [[encryption software]], legal liability and user/administrator training standards.&lt;ref&gt;{{Cite news|url=http://www.wisegeek.org/what-is-information-security.htm|title=What is Information Security? (with pictures)|work=wiseGEEK|access-date=2017-10-06}}&lt;/ref&gt; This standardization may be further driven by a wide variety of laws and regulations that affect how data is accessed, processed, stored, and transferred. However, the implementation of any standards and guidance within an entity may have limited effect if a culture of [[continual improvement process|continual improvement]] isn't adopted.&lt;ref name="Schlienger, Thomas 2003"&gt;{{cite journal | last1 = Schlienger | first1 = Thomas | last2 = Teufel | first2 = Stephanie | year = 2003 | title = Information security culture-from analysis to change | url = | journal = South African Computer Journal | volume = 31 | issue = | pages = 46–52 }}&lt;/ref&gt;

== Overview ==
At the core of information security is information assurance, the act of maintaining the confidentiality, integrity and availability (CIA) of information, ensuring that [[information]] is not compromised in any way when critical issues arise.&lt;ref name="SamonasTheCIA14"&gt;{{cite journal |title=The CIA Strikes Back: Redefining Confidentiality, Integrity and Availability in Security |journal=Journal of Information System Security |author1=Samonas, S.|author2=Coss, D. |volume=10 |issue=3 |pages=21–45 |year=2014 |url=http://www.jissec.org/Contents/V10/N3/V10N3-Samonas.html}}&lt;/ref&gt; These issues include but are not limited to natural disasters, computer/server malfunction, and physical theft. While paper-based business operations are still prevalent, requiring their own set of information security practices, enterprise digital initiatives are increasingly being emphasized,&lt;ref name="GartnerSays17"&gt;{{cite web |url=https://www.gartner.com/newsroom/id/3810771 |title=Gartner Says Digital Disruptors Are Impacting All Industries; Digital KPIs Are Crucial to Measuring Success |publisher=Gartner |date=2 October 2017 |accessdate=25 January 2018}}&lt;/ref&gt;&lt;ref name="GartnerSurvey17"&gt;{{cite web |url=https://www.gartner.com/newsroom/id/3689017 |title=Gartner Survey Shows 42 Percent of CEOs Have Begun Digital Business Transformation |publisher=Gartner |date=24 April 2017 |accessdate=25 January 2018}}&lt;/ref&gt; with information assurance now typically being dealt with by information technology (IT) security specialists. These specialists apply information security to technology (most often some form of computer system). It is worthwhile to note that a [[computer]] does not necessarily mean a home desktop. A computer is any device with a [[Central processing unit|processor]] and some memory. Such devices can range from non-networked standalone devices as simple as calculators, to networked mobile computing devices such as smartphones and tablet computers. IT security specialists are almost always found in any major enterprise/establishment due to the nature and value of the data within larger businesses. They are responsible for keeping all of the [[technology]] within the company secure from malicious cyber attacks that often attempt to acquire critical private information or gain control of the internal systems.

The field of information security has grown and evolved significantly in recent years. It offers many areas for specialization, including securing networks and allied [[infrastructure]], securing [[Application software|applications]] and [[database]]s, [[security testing]], information systems [[Information technology audit|auditing]], [[business continuity planning]], electronic record discovery, and [[digital forensics]]. Information security professionals are very stable in their employment. {{As of|2013}} more than 80 percent of professionals had no change in employer or employment over a period of a year, and the number of professionals is projected to continuously grow more than 11 percent annually from 2014 to 2019.&lt;ref&gt;{{cite web|title=Information Security Qualifications Fact Sheet|url=http://www.itgovernance.co.uk/download/Information-security-qualifications.pdf|website=IT Governance|accessdate=16 March 2018}}&lt;/ref&gt;

=== Threats ===

Information security threats come in many different forms. Some of the most common threats today are software attacks, theft of intellectual property, identity theft, theft of equipment or information, sabotage, and information extortion. Most people have experienced software attacks of some sort. [[Computer virus|Viruses]],&lt;ref&gt;{{Cite book|title=CISSP Study Guide|last=Stewart|first=James|publisher=John Wiley &amp; Sons, Inc.|year=2012|isbn=978-1-118-31417-3|location=Canada|pages=255–257}}&lt;/ref&gt; [[Computer worm|worms]], [[Phishing|phishing attacks]], and [[Trojan horse (computing)|Trojan horses]] are a few common examples of software attacks. The [[Intellectual property infringement|theft of intellectual property]] has also been an extensive issue for many businesses in the IT field. [[Identity theft]] is the attempt to act as someone else usually to obtain that person's personal information or to take advantage of their access to vital information. Theft of equipment or information is becoming more prevalent today due to the fact that most devices today are mobile,&lt;ref&gt;{{cite web|last=Enge|first=Eric|url=https://www.stonetemple.com/mobile-vs-desktop-usage-mobile-grows-but-desktop-still-a-big-player/|title=Stone Temple}} [[Mobile phone|Cell phones]]&lt;/ref&gt; are prone to theft and have also become far more desirable as the amount of data capacity increases. [[Sabotage]] usually consists of the destruction of an organization's [[website]] in an attempt to cause loss of confidence on the part of its customers. Information extortion consists of theft of a company's property or information as an attempt to receive a payment in exchange for returning the information or property back to its owner, as with [[ransomware]]. There are many ways to help protect yourself from some of these attacks but one of the most functional precautions is user carefulness.

[[Governments]], [[military]], [[corporation]]s, [[financial institution]]s, [[hospital]]s and private [[businesses]] amass a great deal of confidential information about their employees, customers, products, research and financial status. Should confidential information about a business' customers or finances or new product line fall into the hands of a competitor or a [[black hat hacker]], a business and its customers could suffer widespread, irreparable financial loss, as well as damage to the company's reputation. From a business perspective, information security must be balanced against cost; the [[Gordon-Loeb Model]] provides a mathematical economic approach for addressing this concern.&lt;ref&gt;{{cite journal|last1=Gordon|first1=Lawrence|last2=Loeb|first2=Martin|title=The Economics of Information Security Investment|journal=ACM Transactions on Information and System Security|date=November 2002|volume=5|issue=4|pages=438–457|doi=10.1145/581271.581274}}&lt;/ref&gt;

For the individual, information security has a significant effect on [[privacy]], which is viewed very differently in various [[cultures]].

==== Responses to threats ====
Possible responses to a security threat or [[IT risk management|risk]] are:&lt;ref&gt;{{Cite book|title=CISSP Certified Information Systems Security Professional Study Guide Sixth Edition|last=Stewart|first=James|publisher=John Wiley &amp; Sons, Inc.|year=2012|isbn=978-1-118-31417-3|location=Canada|pages=255–257}}&lt;/ref&gt;
* reduce/mitigate – implement safeguards and countermeasures to eliminate vulnerabilities or block threats
* assign/transfer – place the cost of the threat onto another entity or organization such as purchasing insurance or outsourcing
* accept – evaluate if the cost of the countermeasure outweighs the possible cost of loss due to the threat

== History ==

Since the early days of communication, diplomats and military commanders understood that it was necessary to provide some mechanism to protect the confidentiality of correspondence and to have some means of detecting [[Tamper-evident|tampering]]. [[Julius Caesar]] is credited with the invention of the [[Caesar cipher]] c. 50 B.C., which was created in order to prevent his secret messages from being read should a message fall into the wrong hands; however, for the most part protection was achieved through the application of procedural handling controls.&lt;ref&gt;{{cite book|first1=Gaius|last1=Suetonius Tranquillus|title=Lives of the Caesars (Oxford World's Classics)|year=2008|publisher=Oxford University Press|location=New York|isbn=978-0-19-953756-3|page=28|authorlink=Suetonius}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=[[The Code Book]] |last=Singh |first=Simon |authorlink=Simon Singh |year=2000 |publisher=Anchor |isbn=0-385-49532-3 |pages=289–290 }}&lt;/ref&gt; Sensitive information was marked up to indicate that it should be protected and transported by trusted persons, guarded and stored in a secure environment or strong box. As postal services expanded, governments created official organizations to intercept, decipher, read and reseal letters (e.g., the U.K.'s Secret Office, founded in 1653&lt;ref name="JohnsonTheEvo97"&gt;{{cite book |first=John |last=Johnson |title=The Evolution of British Sigint: 1653–1939 |year=1997 |publisher=Her Majesty's Stationery Office |asin=B00GYX1GX2}}&lt;/ref&gt;).

In the mid-nineteenth century more complex [[Classified information|classification systems]] were developed to allow governments to manage their information according to the degree of sensitivity. For example, the British Government codified this, to some extent, with the publication of the [[Official Secrets Act 1889|Official Secrets Act]] in 1889.&lt;ref name="HastedtSpies11"&gt;{{cite book |url=https://books.google.com/books?id=A8WoNp2vI-cC&amp;pg=PA589 |chapter=Official Secrets Act (1889; New 1911; Amended 1920, 1939, 1989) |title=Spies, Wiretaps, and Secret Operations: An Encyclopedia of American Espionage |volume=2 |author=Ruppert, K. |editor=Hastedt, G.P. |publisher=ABC-CLIO |year=2011 |pages=589–590 |isbn=9781851098088}}&lt;/ref&gt; By the time of the [[First World War]], multi-tier classification systems were used to communicate information to and from various fronts, which encouraged greater use of code making and breaking sections in diplomatic and military headquarters. Encoding became more sophisticated between the wars as machines were employed to scramble and unscramble information. The volume of information shared by the Allied countries during the [[Second World War]] necessitated formal alignment of classification systems and procedural controls. An arcane range of markings evolved to indicate who could handle documents (usually officers rather than men) and where they should be stored as increasingly complex safes and storage facilities were developed. The [[Enigma Machine]], which was employed by the Germans to encrypt the data of warfare and was successfully decrypted by [[Alan Turing]], can be regarded as a striking example of creating and using secured information.&lt;ref name="Sebag-MontefioreEnigma11"&gt;{{cite book |title=Enigma: The Battle for the Code |author=Sebag–Montefiore, H. |publisher=Orion |pages=576 |year=2011 |isbn=9781780221236}}&lt;/ref&gt; Procedures evolved to ensure documents were destroyed properly, and it was the failure to follow these procedures which led to some of the greatest intelligence coups of the war (e.g., the capture of [[U-570]]&lt;ref name="Sebag-MontefioreEnigma11" /&gt;).

The end of the twentieth century and the early years of the twenty-first century saw rapid advancements in [[telecommunications]], computing [[computer hardware|hardware]] and [[software]], and data [[encryption]]. The availability of smaller, more powerful and less expensive computing equipment made [[Data processing|electronic data processing]] within the reach of [[small business]] and the home user. These computers quickly became interconnected through the [[internet]].

The rapid growth and widespread use of electronic data processing and [[electronic business]] conducted through the internet, along with numerous occurrences of international [[terrorism]], fueled the need for better methods of protecting the computers and the information they store, process and transmit.&lt;ref name="DeLeeuwTheHist07"&gt;{{cite book |chapter=Chapter 24: A History of Internet Security |title=The History of Information Security: A Comprehensive Handbook |author=DeNardis, L. |editor1=de Leeuw, K.M.M.|editor2=Bergstra, J. |publisher=Elsevier |pages=681–704 |year=2007 |isbn=9780080550589}}&lt;/ref&gt; The academic disciplines of [[computer security]] and [[information assurance]] emerged along with numerous professional organizations, all sharing the common goals of ensuring the security and reliability of information systems.

== Definitions ==
[[File:CIAJMK1209.png|thumb|'''Information Security Attributes''': or qualities, i.e., [[Confidentiality]], [[Data integrity|Integrity]] and [[Availability]] (CIA). [[Information Systems]] are composed in three main portions, hardware, software and communications with the purpose to help identify and apply information security industry standards, as mechanisms of protection and prevention, at three levels or layers: [[Physical information security|physical]], personal and organizational. Essentially, procedures or policies are implemented to tell administrators, users and operators how to use products to ensure information security within the organizations.&lt;ref name="Cherdantseva Y 2013"&gt;Cherdantseva Y. and Hilton J.: "Information Security and Information Assurance. The Discussion about the Meaning, Scope and Goals". In: ''Organizational, Legal, and Technological Dimensions of Information System Administrator''. Almeida F., Portela, I. (eds.). IGI Global Publishing. (2013)&lt;/ref&gt;]]
Various definitions of information security are suggested below, summarized from different sources:

# "Preservation of confidentiality, integrity and availability of information. Note: In addition, other properties, such as authenticity, accountability, non-repudiation and reliability can also be involved." (ISO/IEC 27000:2009)&lt;ref&gt;ISO/IEC 27000:2009 (E). (2009). Information technology – Security techniques – Information security management systems – Overview and vocabulary. ISO/IEC.&lt;/ref&gt;
# "The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability." (CNSS, 2010)&lt;ref&gt;Committee on National Security Systems: National Information Assurance (IA) Glossary, CNSS Instruction No. 4009, 26 April 2010.&lt;/ref&gt;
# "Ensures that only authorized users (confidentiality) have access to accurate and complete information (integrity) when required (availability)." (ISACA, 2008)&lt;ref&gt;ISACA. (2008). Glossary of terms, 2008. Retrieved from http://www.isaca.org/Knowledge-Center/Documents/Glossary/glossary.pdf&lt;/ref&gt;
# "Information Security is the process of protecting the intellectual property of an organisation."  (Pipkin, 2000)&lt;ref&gt;Pipkin, D. (2000). ''Information security: Protecting the global enterprise''. New York: Hewlett-Packard Company.&lt;/ref&gt;
# "...information security is a risk management discipline, whose job is to manage the cost of information risk to the business." (McDermott and Geer, 2001)&lt;ref&gt;B., McDermott, E., &amp; Geer, D. (2001). Information security is information risk management. In Proceedings of the 2001 Workshop on New Security Paradigms NSPW ‘01, (pp. 97 – 104). ACM. doi:10.1145/508171.508187&lt;/ref&gt;
# "A well-informed sense of assurance that information risks and controls are in balance." (Anderson, J., 2003)&lt;ref&gt;{{cite journal | last1 = Anderson | first1 = J. M. | year = 2003 | title = Why we need a new definition of information security | url = | journal = Computers &amp; Security | volume = 22 | issue = 4| pages = 308–313 | doi = 10.1016/S0167-4048(03)00407-3 }}&lt;/ref&gt;
# "Information security is the protection of information and minimizes the risk of exposing information to unauthorized parties." (Venter and Eloff, 2003)&lt;ref&gt;{{cite journal | last1 = Venter | first1 = H. S. | last2 = Eloff | first2 = J. H. P. | year = 2003 | title = A taxonomy for information security technologies | url = | journal = Computers &amp; Security | volume = 22 | issue = 4| pages = 299–307 | doi = 10.1016/S0167-4048(03)00406-1 }}&lt;/ref&gt;
# "Information Security is a multidisciplinary area of study and professional activity which is concerned with the development and implementation of security mechanisms of all available types (technical, organizational, human-oriented and legal) in order to keep information in all its locations (within and outside the organization's perimeter) and, consequently, information systems, where information is created, processed, stored, transmitted and destroyed, free from threats.Threats to information and information systems may be categorized and a corresponding security goal may be defined for each category of threats. A set of security goals, identified as a result of a threat analysis, should be revised periodically to ensure its adequacy and conformance with the evolving environment. The currently relevant set of security goals may include: ''confidentiality, integrity, availability, privacy, authenticity &amp; trustworthiness, non-repudiation, accountability and auditability.''" (Cherdantseva and Hilton, 2013)&lt;ref name="Cherdantseva Y 2013" /&gt;

== Basic principles ==

=== Key concepts ===
[[File:Posters for information security for the Ministry of Defense of the Russian Federation.jpg|thumb|Poster promoting information security by the Russian [[Ministry of Defence (Russia)|Ministry of Defence]]]]
The CIA triad of confidentiality, integrity, and availability is at the heart of information security.&lt;ref&gt;{{cite web|last=Perrin|first=Chad|title=The CIA Triad|url=http://www.techrepublic.com/blog/security/the-cia-triad/488|accessdate=31 May 2012}}&lt;/ref&gt; (The members of the classic InfoSec triad—confidentiality, integrity and availability—are interchangeably referred to in the literature as security attributes, properties, security goals, fundamental aspects, information criteria, critical information characteristics and basic building blocks.) However, debate continues about whether or not this CIA triad is sufficient to address rapidly changing technology and business requirements, with recommendations to consider expanding on the intersections between availability and confidentiality, as well as the relationship between security and privacy.&lt;ref name="SamonasTheCIA14" /&gt; Other principles such as "accountability" have sometimes been proposed; it has been pointed out that issues such as [[non-repudiation]] do not fit well within the three core concepts.&lt;ref name="NIST"&gt;{{cite web |title=Engineering Principles for Information Technology Security |url=http://csrc.nist.gov/publications/nistpubs/800-27A/SP800-27-RevA.pdf |publisher=csrc.nist.gov}}&lt;/ref&gt;

In 1992 and revised in 2002, the [[OECD]]'s ''Guidelines for the Security of Information Systems and Networks''&lt;ref&gt;{{cite web|url=http://www.oecd.org/dataoecd/16/22/15582260.pdf |title=oecd.org |format=PDF |accessdate=2014-01-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20110516085505/http://www.oecd.org/dataoecd/16/22/15582260.pdf |archivedate=May 16, 2011 }}&lt;/ref&gt; proposed the nine generally accepted principles: [[information security awareness|awareness]], responsibility, response, ethics, democracy, risk assessment, security design and implementation, security management, and reassessment. Building upon those, in 2004 the [[NIST]]'s ''Engineering Principles for Information Technology Security''&lt;ref name="NIST" /&gt; proposed 33 principles. From each of these derived guidelines and practices.

In 1998, [[Donn Parker]] proposed an alternative model for the classic CIA triad that he called the [[Parkerian Hexad|six atomic elements of information]]. The elements are [[confidentiality]], [[ownership|possession]], [[integrity]], [[authentication|authenticity]], [[availability]], and [[utility]]. The merits of the [[Parkerian Hexad]] are a subject of debate amongst security professionals.&lt;ref&gt;{{cite web|last=Slade|first=Rob|url=http://blog.isc2.org/isc2_blog/2008/12/cia-triad-versus-parkerian-hexad.html|title=(ICS)2 Blog}}&lt;/ref&gt;

In 2011, [[The Open Group]] published the information security management standard [[Open Information Security Maturity Model|O-ISM3]].&lt;ref&gt;{{cite web|last=Aceituno|first=Vicente|title=Open Information Security Maturity Model|url=http://www.ism3.com/node/39|accessdate=12 February 2017}}&lt;/ref&gt; This standard proposed an [[operational definition]] of the key concepts of security, with elements called "security objectives", related to [[access control]] (9), [[availability]] (3), [[data quality]] (1), [[standards-compliant|compliance]] and technical (4). In 2009, [[DoD]] [https://spi.dod.mil/ Software Protection Initiative] released the [https://spi.dod.mil/threat.htm Three Tenets of Cybersecurity] which are System Susceptibility, Access to the Flaw, and Capability to Exploit the Flaw.&lt;ref&gt;http://www.dartmouth.edu/~gvc/ThreeTenetsSPIE.pdf&lt;/ref&gt;&lt;ref&gt;{{cite journal|url=http://www.timreview.ca/article/712|title=Quantitative Metrics and Risk Assessment: The Three Tenets Model of Cybersecurity|first1=Jeff|last1=Hughes|first2=George|last2=Cybenko|date=21 June 2018|journal=Technology Innovation Management Review|volume=3|issue=8}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.continuum.net/blog/are-your-clients-falling-for-these-it-security-myths-chart|title=Are Your Clients Falling for These IT Security Myths? [CHART]|first=Lily|last=Teplow|website=continuum.net}}&lt;/ref&gt; Neither of these models are widely adopted.

==== Confidentiality ====
In information security, confidentiality "is the property, that information is not made available or disclosed to unauthorized individuals, entities, or processes."&lt;ref name="BeckersPattern15"&gt;{{cite book |url=https://books.google.com/books?id=DvdICAAAQBAJ&amp;pg=PA100 |title=Pattern and Security Requirements: Engineering-Based Establishment of Security Standards |author=Beckers, K. |publisher=Springer |page=100 |year=2015 |isbn=9783319166643}}&lt;/ref&gt; While similar to "privacy," the two words aren't interchangeable. Rather, confidentiality is a component of privacy that implements to protect our data from unauthorized viewers. Examples of confidentiality of electronic data being compromised include laptop theft, password theft, or sensitive emails being sent to the incorrect individuals.&lt;ref name="AndressTheBasics14" /&gt;

==== Integrity ====
In information security, [[data integrity]] means maintaining and assuring the accuracy and completeness of data over its entire lifecycle.&lt;ref&gt;{{cite journal|last=Boritz|first=J. Efrim|title=IS Practitioners' Views on Core Concepts of Information Integrity|url=http://www.sciencedirect.com/science/article/pii/S1467089505000473|work=International Journal of Accounting Information Systems|publisher=Elsevier|accessdate=12 August 2011|doi=10.1016/j.accinf.2005.07.001|volume=6|issue=4|pages=260–279}}&lt;/ref&gt;  This means that data cannot be modified in an unauthorized or undetected manner. This is not the same thing as [[referential integrity]] in [[databases]], although it can be viewed as a special case of consistency as understood in the classic [[ACID]] model of [[transaction processing]]. Information security systems typically provide message integrity along side to confidentiality.

==== Availability ====
For any information system to serve its purpose, the information must be [[availability|available]] when it is needed. This means the computing systems used to store and process the information, the [[security controls]] used to protect it, and the communication channels used to access it must be functioning correctly. [[High availability]] systems aim to remain available at all times, preventing service disruptions due to power outages, hardware failures, and system upgrades. Ensuring availability also involves preventing [[denial-of-service attack]]s, such as a flood of incoming messages to the target system, essentially forcing it to shut down.&lt;ref&gt;{{Cite journal | last1 = Loukas | first1 = G. | last2 = Oke | first2 = G. | doi = 10.1093/comjnl/bxp078 | title = Protection Against Denial of Service Attacks: A Survey | journal = [[The Computer Journal|Comput. J.]] | volume = 53 | issue = 7 | pages = 1020–1037 | date=September 2010 | origyear = August 2009| pmid =  | pmc = | url = http://staffweb.cms.gre.ac.uk/~lg47/publications/LoukasOke-DoSSurveyComputerJournal.pdf}}&lt;/ref&gt;

In the realm of information security, availability can often be viewed as one of the most important parts of a successful information security program. Ultimately end-users need to be able to perform job functions; by ensuring availability an organization is able to perform to the standards that an organization's stakeholders expect. This can involve topics such as proxy configurations, outside web access, the ability to access shared drives and the ability to send emails. Executives oftentimes do not understand the technical side of information security and look at availability as an easy fix, but this often requires collaboration from many different organizational teams, such as network operations, development operations, incident response and policy/change management. A successful information security team involves many different key roles to mesh and align for the CIA triad to be provided effectively.

[[File:CIAJMK1209.png|thumb|CIA triad methodology]]

==== Non-repudiation ====
In law, [[non-repudiation]] implies one's intention to fulfill their obligations to a contract. It also implies that one party of a transaction cannot deny having received a transaction, nor can the other party deny having sent a transaction.&lt;ref name="BidgoliHandbook06"&gt;{{cite book |url=https://books.google.com/books?id=0RfANAwOUdIC&amp;pg=PA65 |chapter=Digital Libraries: Security and Preservation Considerations |title=Handbook of Information Security, Threats, Vulnerabilities, Prevention, Detection, and Management |author=McCarthy, C. |editor=Bidgoli, H. |publisher=John Wiley &amp; Sons |volume=3 |pages=49–76 |year=2006 |isbn=9780470051214}}&lt;/ref&gt;

It is important to note that while technology such as cryptographic systems can assist in non-repudiation efforts, the concept is at its core a legal concept transcending the realm of technology. It is not, for instance, sufficient to show that the message matches a digital signature signed with the sender's private key, and thus only the sender could have sent the message, and nobody else could have altered it in transit ([[data integrity]]). The alleged sender could in return demonstrate that the digital signature algorithm is vulnerable or flawed, or allege or prove that his signing key has been compromised. The fault for these violations may or may not lie with the sender, and such assertions may or may not relieve the sender of liability, but the assertion would invalidate the claim that the signature necessarily proves authenticity and integrity. As such, the sender may repudiate the message (because authenticity and integrity are pre-requisites for non-repudiation).

== Risk management ==
{{Main|Risk management}}

The ''[[Certified Information Systems Auditor]] (CISA) Review Manual 2006'' provides the following definition of risk management: "Risk management is the process of identifying [[vulnerability (computing)|vulnerabilities]] and [[threat (computer)|threats]] to the information resources used by an organization in achieving business objectives, and deciding what [[Countermeasure (computer)|countermeasures]], if any, to take in reducing risk to an acceptable level, based on the value of the information resource to the organization."&lt;ref&gt;{{cite book|title=CISA Review Manual 2006|last=ISACA|first=|publisher=Information Systems Audit and Control Association|year=2006|isbn=1-933284-15-3|location=|page=85|pages=}}&lt;/ref&gt;

There are two things in this definition that may need some clarification. First, the ''process'' of risk management is an ongoing, iterative [[Business process|process]]. It must be repeated indefinitely. The business environment is constantly changing and new [[threat (computer)|threats]] and [[vulnerability (computing)|vulnerabilities]] emerge every day. Second, the choice of [[countermeasure (computer)|countermeasures]] ([[security controls|controls]]) used to manage risks must strike a balance between productivity, cost, effectiveness of the countermeasure, and the value of the informational asset being protected.

Risk analysis and risk evaluation processes have their limitations since, when security incidents occur, they emerge in a context, and their rarity and uniqueness give rise to unpredictable threats. The analysis of these phenomena, which are characterized by breakdowns, surprises and side-effects, requires a theoretical approach that is able to examine and interpret subjectively the detail of each incident.&lt;ref&gt;{{cite journal|last=Spagnoletti|first=Paolo|author2=Resca A.|title=The duality of Information Security Management: fighting against predictable and unpredictable threats|journal=Journal of Information System Security|year=2008|volume=4|issue=3|pages=46–62|url=http://eprints.luiss.it/955/}}&lt;/ref&gt;

Risk is the likelihood that something bad will happen that causes harm to an informational asset (or the loss of the asset). A vulnerability is a weakness that could be used to endanger or cause harm to an informational asset. A threat is anything (man-made or [[natural disaster|act of nature]]) that has the potential to cause harm.

The likelihood that a threat will use a vulnerability to cause harm creates a risk. When a threat does use a vulnerability to inflict harm, it has an impact. In the context of information security, the impact is a loss of availability, integrity, and confidentiality, and possibly other losses (lost income, loss of life, loss of real property).&lt;ref name="GramaLegal14"&gt;{{cite book |url=https://books.google.com/books?id=kqoyDwAAQBAJ&amp;pg=PT38 |title=Legal Issues in Information Security |author=Grama, J.L. |publisher=Jones &amp; Bartlett Learning |pages=550 |year=2014 |isbn=9781284151046}}&lt;/ref&gt; It should be pointed out that it is not possible to identify all risks, nor is it possible to eliminate all risk. The remaining risk is called "residual risk."

A [[risk assessment]] is carried out by a team of people who have knowledge of specific areas of the business. Membership of the team may vary over time as different parts of the business are assessed. The assessment may use a subjective qualitative analysis based on informed opinion, or where reliable dollar figures and historical information is available, the analysis may use [[Statistics|quantitative]] analysis.

Research has shown that the most vulnerable point in most information systems is the human user, operator, designer, or other human.&lt;ref&gt;{{cite book|last1=Kiountouzis| first1=E.A.|last2=Kokolakis|first2=S.A.|title=Information systems security: facing the information society of the 21st century|publisher=Chapman &amp; Hall, Ltd.|location= London|isbn=0-412-78120-4}}&lt;/ref&gt; The [[ISO/IEC 17799|ISO/IEC 27002:2005]] Code of practice for [[information security management]] recommends the following be examined during a risk assessment:
* [[security policy]],
* [[organization]] of information security,
* [[asset management]],
* [[human resources]] security,
* physical and [[environmental security]],
* [[communications]] and operations management,
* [[access control]],
* information systems acquisition, development and maintenance,
* information security [[incident management]],
* business continuity management, and
* regulatory compliance.

In broad terms, the risk management process consists of:&lt;ref name="NewsomeAPract13"&gt;{{cite book |title=A Practical Introduction to Security and Risk Management |author=Newsome, B. |publisher=SAGE Publications |pages=208 |year=2013 |isbn=9781483324852}}&lt;/ref&gt;&lt;ref name="WhitmanManage16"&gt;{{cite book |title=Management of Information Security |author1=Whitman, M.E.|author2=Mattord, H.J. |publisher=Cengage Learning |edition=5th |pages=592 |year=2016 |isbn=9781305501256}}&lt;/ref&gt;
# Identification of assets and estimating their value. Include: people, buildings, hardware, software, data (electronic, print, other), supplies.
# Conduct a [[threat assessment]]. Include: Acts of nature, acts of war, accidents, malicious acts originating from inside or outside the organization.
# Conduct a [[vulnerability assessment]], and for each vulnerability, calculate the probability that it will be exploited. Evaluate policies, procedures, standards, training, [[physical security]], [[quality control]], technical security.
# Calculate the impact that each threat would have on each asset. Use qualitative analysis or quantitative analysis.
# Identify, select and implement appropriate controls. Provide a proportional response. Consider productivity, cost effectiveness, and value of the asset.
# Evaluate the effectiveness of the control measures. Ensure the controls provide the required cost effective protection without discernible loss of productivity.

For any given risk, management can choose to accept the risk based upon the relative low value of the asset, the relative low frequency of occurrence, and the relative low impact on the business. Or, leadership may choose to mitigate the risk by selecting and implementing appropriate control measures to reduce the risk. In some cases, the risk can be transferred to another business by buying insurance or outsourcing to another business.&lt;ref name=SP80030&gt;{{cite web|url=http://csrc.nist.gov/publications/nistpubs/800-30/sp800-30.pdf |title=NIST SP 800-30 Risk Management Guide for Information Technology Systems |format=PDF |accessdate=2014-01-17}}&lt;/ref&gt; The reality of some risks may be disputed. In such cases leadership may choose to deny the risk.

=== Security controls ===
{{Main|security controls}}
Selecting and implementing proper security controls will initially help an organization bring down risk to acceptable levels. Control selection should follow and should be based on the risk assessment. Controls can vary in nature, but fundamentally they are ways of protecting the confidentiality, integrity or availability of information. [[ISO/IEC 27001]] has defined controls in different areas. Organizations can implement additional controls according to requirement of the organization.&lt;ref name="JohnsonSecurity15"&gt;{{cite book |url=https://books.google.com/books?id=X7SYBAAAQBAJ&amp;pg=PA9 |title=Security Controls Evaluation, Testing, and Assessment Handbook |author=Johnson, L. |publisher=Syngress |pages=678 |year=2015 |isbn=9780128025642}}&lt;/ref&gt; [[ISO/IEC 27002]] offers a guideline for organizational information security standards.

==== Administrative ====
Administrative controls consist of approved written policies, procedures, standards and guidelines. Administrative controls form the framework for running the business and managing people. They inform people on how the business is to be run and how day-to-day operations are to be conducted. Laws and regulations created by government bodies are also a type of administrative control because they inform the business. Some industry sectors have policies, procedures, standards and guidelines that must be followed – the [[Payment Card Industry Data Security Standard|Payment Card Industry Data Sec]]&lt;ref name=":0" /&gt;[[Payment Card Industry Data Security Standard|urity Sta]][[Payment Card Industry Data Security Standard|ndard]] (PCI DSS) required by [[Visa Inc.|Visa]] and [[MasterCard]] is such an example. Other examples of administrative controls include the corporate security policy, [[password policy]], hiring policies, and disciplinary policies.

Administrative controls form the basis for the selection and implementation of logical and physical controls. Logical and physical controls are manifestations of administrative controls, which are of paramount importance.

==== Logical ====
Logical controls (also called technical controls) use software and data to monitor and control access to information and computing systems. Passwords, network and host-based firewalls, network [[intrusion detection]] systems, [[access control list]]s, and data encryption are examples of logical controls.

An important logical control that is frequently overlooked is the principle of least privilege, which requires that an individual, program or system process not be granted any more access privileges than are necessary to perform the task.&lt;ref name="RansomeCore13"&gt;{{cite book |url=https://books.google.com/books?id=MX5cAgAAQBAJ&amp;pg=PA40 |title=Core Software Security: Security at the Source |author1=Ransome, J.|author2=Misra, A. |publisher=CRC Press |pages=40–41 |year=2013 |isbn=9781466560956}}&lt;/ref&gt; A blatant example of the failure to adhere to the principle of least privilege is logging into Windows as user Administrator to read email and surf the web. Violations of this principle can also occur when an individual collects additional access privileges over time. This happens when employees' job duties change, employees are promoted to a new position, or employees are transferred to another department. The access privileges required by their new duties are frequently added onto their already existing access privileges, which may no longer be necessary or appropriate.

==== Physical ====
Physical controls monitor and control the environment of the work place and computing facilities. They also monitor and control access to and from such facilities and include doors, locks, heating and air conditioning, smoke and fire alarms, fire suppression systems, cameras, barricades, fencing, security guards, cable locks, etc. Separating the network and workplace into functional areas are also physical controls.

An important physical control that is frequently overlooked is separation of duties, which ensures that an individual can not complete a critical task by himself. For example, an employee who submits a request for reimbursement should not also be able to authorize payment or print the check. An applications programmer should not also be the [[System administrator|server administrator]] or the [[database administrator]]; these roles and responsibilities must be separated from one another.&lt;ref&gt;{{cite web|url=http://www.isaca.org/AMTemplate.cfm?Section=CISA1&amp;Template=/ContentManagement/ContentDisplay.cfm&amp;ContentID=40835 |title=Segregation of Duties Control matrix |year=2008 |publisher=ISACA |accessdate=2008-09-30 |deadurl=yes |archiveurl=https://web.archive.org/web/20110703162553/http://www.isaca.org/AMTemplate.cfm?Section=CISA1&amp;Template=%2FContentManagement%2FContentDisplay.cfm&amp;ContentID=40835 |archivedate=3 July 2011 |df= }}&lt;/ref&gt;

=== Defense in depth&lt;!--Section linked from [[Onion model]]: do not rename without fixing incoming link (see [[MOS:HEAD]])--&gt; ===
[[File:Defense In Depth - Onion Model.svg|thumb|right|The [[onion model]] of defense in depth]]
{{Main|Defense in depth (computing)}}
Information security must protect information throughout its lifespan, from the initial creation of the information on through to the final disposal of the information.  The information must be protected while in motion and while at rest. During its lifetime, information may pass through many different information processing systems and through many different parts of information processing systems. There are many different ways the information and information systems can be threatened. To fully protect the information during its lifetime, each component of the information processing system must have its own protection mechanisms. The building up, layering on and overlapping of security measures is called "defense in depth." In contrast to a metal chain, which is famously only as strong as its weakest link, the defense in depth strategy aims at a structure where, should one defensive measure fail, other measures will continue to provide protection.&lt;ref name="VaccaComputer13"&gt;{{cite book |url=https://books.google.com/books?id=zb916YOr16wC&amp;pg=PA546 |chapter=Chapter 31: What is Vulnerability Assessment? |title=Computer and Information Security Handbook |author=Kakareka, A. |editor=Vacca, J.R. |publisher=Elsevier |edition=2nd |pages=541–552 |year=2013 |isbn=9780123946126}}&lt;/ref&gt;

Recall the earlier discussion about administrative controls, logical controls, and physical controls. The three types of controls can be used to form the basis upon which to build a defense in depth strategy. With this approach, defense in depth can be conceptualized as three distinct layers or planes laid one on top of the other. Additional insight into defense in depth can be gained by thinking of it as forming the layers of an onion, with data at the core of the onion, people the next outer layer of the onion, and [[network security]], host-based security and [[application security]] forming the outermost layers of the onion. Both perspectives are equally valid, and each provides valuable insight into the implementation of a good defense in depth strategy.

=== Security classification for information ===
An important aspect of information security and risk management is recognizing the value of information and defining appropriate procedures and protection requirements for the information. Not all information is equal and so not all information requires the same degree of protection. This requires information to be assigned a [[Classified information|security classification]]. The first step in information classification is to identify a member of senior management as the owner of the particular information to be classified. Next, develop a classification policy. The policy should describe the different classification labels, define the criteria for information to be assigned a particular label, and list the required [[security controls]] for each classification.&lt;ref name="BayukEnterprise09"&gt;{{cite book |url=https://books.google.com/books?id=XxPhvm1EP3EC&amp;pg=PA59 |chapter=Chapter 4: Information Classification |title=Enterprise Information Security and Privacy |author=Bayuk, J. |editor1=Axelrod, C.W.|editor2=Bayuk, J.L.|editor3=Schutzer, D. |publisher=Artech House |year=2009 |pages=59–70 |isbn=9781596931916}}&lt;/ref&gt;

Some factors that influence which classification information should be assigned include how much value that information has to the organization, how old the information is and whether or not the information has become obsolete. Laws and other regulatory requirements are also important considerations when classifying information. The [[ISACA|Information Systems Audit and Control Association]] (ISACA) and its ''Business Model for Information Security'' also serves as a tool for security professionals to examine security from a systems perspective, creating an environment where security can be managed holistically, allowing actual risks to be addressed.&lt;ref name="ISACA-BMIS"&gt;{{cite web |url=https://www.isaca.org/KNOWLEDGE-CENTER/BMIS/Pages/Business-Model-for-Information-Security.aspx |title=Business Model for Information Security (BMIS) |publisher=ISACA |accessdate=25 January 2018}}&lt;/ref&gt;

The type of information security classification labels selected and used will depend on the nature of the organization, with examples being:&lt;ref name="BayukEnterprise09" /&gt;
* In the business sector, labels such as: Public, Sensitive, Private, Confidential.
* In the government sector, labels such as: Unclassified, Unofficial, Protected, Confidential, Secret, Top Secret and their non-English equivalents.
* In cross-sectoral formations, the [[Traffic Light Protocol]], which consists of: White, Green, Amber, and Red.

All employees in the organization, as well as business partners, must be trained on the classification schema and understand the required security controls and handling procedures for each classification. The classification of a particular information asset that has been assigned should be reviewed periodically to ensure the classification is still appropriate for the information and to ensure the security controls required by the classification are in place and are followed in their right procedures.

=== Access control ===
Access to protected information must be restricted to people who are authorized to access the information. The computer programs, and in many cases the computers that process the information, must also be authorized. This requires that mechanisms be in place to control the access to protected information. The sophistication of the access control mechanisms should be in parity with the value of the information being protected; the more sensitive or valuable the information the stronger the control mechanisms need to be. The foundation on which access control mechanisms are built start with identification and [[authentication]].

Access control is generally considered in three steps: identification, [[authentication]], and [[authorization]].&lt;ref name="AndressTheBasics14" /&gt;

==== Identification ====
Identification is an assertion of who someone is or what something is. If a person makes the statement "Hello, my name is [[John Doe]]" they are making a claim of who they are. However, their claim may or may not be true. Before John Doe can be granted access to protected information it will be necessary to verify that the person claiming to be John Doe really is John Doe. Typically the claim is in the form of a username. By entering that username you are claiming "I am the person the username belongs to".

==== Authentication ====
Authentication is the act of verifying a claim of identity. When John Doe goes into a bank to make a withdrawal, he tells the [[bank teller]] he is John Doe, a claim of identity. The bank teller asks to see a photo ID, so he hands the teller his [[driver's license]]. The bank teller checks the license to make sure it has John Doe printed on it and compares the photograph on the license against the person claiming to be John Doe. If the photo and name match the person, then the teller has authenticated that John Doe is who he claimed to be. Similarly, by entering the correct password, the user is providing evidence that he/she is the person the username belongs to.

There are three different types of information that can be used for authentication:
* Something you know: things such as a PIN, a [[password]], or your mother's [[maiden name]]
* Something you have: a driver's license or a magnetic [[swipe card]]
* Something you are: [[biometrics]], including [[palm print]]s, [[fingerprint]]s, [[Speaker recognition|voice prints]] and [[Retina scan|retina (eye) scans]]

Strong authentication requires providing more than one type of authentication information (two-factor authentication). The [[username]] is the most common form of identification on computer systems today and the password is the most common form of authentication. Usernames and passwords have served their purpose, but they are increasingly inadequate.&lt;ref&gt;{{cite book|last1=Akpeninor|first1=James Ohwofasa|title=Modern Concepts of Security|date=2013|publisher=AuthorHouse|location=Bloomington, IN|isbn=978-1-4817-8232-6|page=135|url=https://books.google.ca/books?isbn=1481782320|accessdate=18 January 2018}}&lt;/ref&gt; Usernames and passwords are slowly being replaced or supplemented with more sophisticated authentication mechanisms such as [[Time-based One-time Password Algorithm|Time-based One-time Password algorithm]]s.

==== Authorization ====
After a person, program or computer has successfully been identified and authenticated then it must be determined what informational resources they are permitted to access and what actions they will be allowed to perform (run, view, create, delete, or change). This is called [[authorization]]. Authorization to access information and other computing services begins with administrative policies and procedures. The policies prescribe what information and computing services can be accessed, by whom, and under what conditions. The access control mechanisms are then configured to enforce these policies. Different computing systems are equipped with different kinds of access control mechanisms. Some may even offer a choice of different access control mechanisms. The access control mechanism a system offers will be based upon one of three approaches to access control, or it may be derived from a combination of the three approaches.&lt;ref name="AndressTheBasics14" /&gt;

The non-discretionary approach consolidates all access control under a centralized administration. The access to information and other resources is usually based on the individuals function (role) in the organization or the tasks the individual must perform. The discretionary approach gives the creator or owner of the information resource the ability to control access to those resources. In the mandatory access control approach, access is granted or denied basing upon the security classification assigned to the information resource.

Examples of common access control mechanisms in use today include [[Role-Based Access Control|role-based access control]], available in many advanced database management systems; simple [[File system permissions|file permissions]] provided in the UNIX and Windows operating systems; [[Group Policy Object]]s provided in Windows network systems; and [[Kerberos (protocol)|Kerberos]], [[RADIUS]], [[TACACS]], and the simple access lists used in many [[Firewall (networking)|firewalls]] and [[Router (computing)|routers]].

To be effective, policies and other security controls must be enforceable and upheld. Effective policies ensure that people are held accountable for their actions. The [[United States Department of the Treasury|U.S. Treasury]]'s guidelines for systems processing sensitive or proprietary information, for example, states that all failed and successful authentication and access attempts must be logged, and all access to information must leave some type of [[audit trail]].&lt;ref&gt;{{Cite web|url=https://www.treasury.gov/tigta/auditreports/2004reports/200420131fr.html|title=The Use of Audit Trails to Monitor Key Networks and Systems Should Remain Part of the Computer Security Material Weakness|website=www.treasury.gov|access-date=2017-10-06}}&lt;/ref&gt;

Also, the need-to-know principle needs to be in effect when talking about access control. This principle gives access rights to a person to perform their job functions. This principle is used in the government when dealing with difference clearances. Even though two employees in different departments have a [[Classified information|top-secret clearance]], they must have a need-to-know in order for information to be exchanged. Within the need-to-know principle, network administrators grant the employee the least amount of privileges to prevent employees from accessing more than what they are supposed to. Need-to-know helps to enforce the confidentiality-integrity-availability triad. Need-to-know directly impacts the confidential area of the triad.

=== Cryptography ===
{{Main|Cryptography}}
Information security uses [[cryptography]] to transform usable information into a form that renders it unusable by anyone other than an authorized user; this process is called [[encryption]]. Information that has been encrypted (rendered unusable) can be transformed back into its original usable form by an authorized user who possesses the [[Key (cryptography)|cryptographic key]], through the process of decryption. Cryptography is used in information security to protect information from unauthorized or accidental disclosure while the [[information]] is in transit (either electronically or physically) and while information is in storage.&lt;ref name="AndressTheBasics14" /&gt;

Cryptography provides information security with other useful applications as well, including improved authentication methods, message digests, digital signatures, [[non-repudiation]], and encrypted network communications. Older, less secure applications such as [[Telnet]] and [[File Transfer Protocol]] (FTP) are slowly being replaced with more secure applications such as [[Secure Shell]] (SSH) that use encrypted network communications. Wireless communications can be encrypted using protocols such as [[Wi-Fi Protected Access|WPA/WPA2]] or the older (and less secure) [[Wired Equivalent Privacy|WEP]]. Wired communications (such as [[ITU-T|ITU‑T]] [[G.hn]]) are secured using [[Advanced Encryption Standard|AES]] for encryption and [[X.1035]] for authentication and key exchange. Software applications such as [[GnuPG]] or [[Pretty Good Privacy|PGP]] can be used to encrypt data files and email.

Cryptography can introduce security problems when it is not implemented correctly. Cryptographic solutions need to be implemented using industry-accepted solutions that have undergone rigorous peer review by independent experts in cryptography. The [[Key size|length and strength]] of the encryption key is also an important consideration. A key that is [[Weak key|weak]] or too short will produce weak encryption. The keys used for encryption and decryption must be protected with the same degree of rigor as any other confidential information. They must be protected from unauthorized disclosure and destruction and they must be available when needed. [[Public key infrastructure]] (PKI) solutions address many of the problems that surround [[key management]].&lt;ref name="AndressTheBasics14" /&gt;

== Process ==
The terms "reasonable and prudent person," "[[due care]]" and "due diligence" have been used in the fields of finance, securities, and law for many years. In recent years these terms have found their way into the fields of computing and information security.&lt;ref name="WhitmanManage16" /&gt; U.S. [[Federal Sentencing Guidelines]] now make it possible to hold corporate officers liable for failing to exercise due care and due diligence in the management of their information systems.&lt;ref name="VallabhaneniCorporate08"&gt;{{cite book |url=https://books.google.com/books?id=BvYbQr9MV_sC&amp;pg=PA288 |title=Corporate Management, Governance, and Ethics Best Practices |author=Vallabhaneni, S.R. |publisher=John Wiley &amp; Sons |page=288 |year=2008 |isbn=9780470255803}}&lt;/ref&gt;

In the business world, stockholders, customers, business partners and governments have the expectation that corporate officers will run the business in accordance with accepted business practices and in compliance with laws and other regulatory requirements. This is often described as the "reasonable and prudent person" rule. A prudent person takes due care to ensure that everything necessary is done to operate the business by sound business principles and in a legal ethical manner. A prudent person is also diligent (mindful, attentive, and ongoing) in their due care of the business.

In the field of information security, Harris&lt;ref&gt;{{cite book|author=Shon Harris|authorlink=Shon Harris|title=All-in-one CISSP Certification Exam Guide|edition=2nd|publisher=[[McGraw-Hill]]/Osborne|year=2003|location=[[Emeryville, California]]|isbn=0-07-222966-7}}&lt;/ref&gt;
offers the following definitions of due care and due diligence:

&lt;blockquote&gt;''"Due care are steps that are taken to show that a company has taken responsibility for the activities that take place within the corporation and has taken the necessary steps to help protect the company, its resources, and employees."'' And, &lt;nowiki&gt;[Due diligence are the]&lt;/nowiki&gt; ''"continual activities that make sure the protection mechanisms are continually maintained and operational."''
&lt;/blockquote&gt;

Attention should be made to two important points in these definitions. First, in due care, steps are taken to show; this means that the steps can be verified, measured, or even produce tangible artifacts. Second, in due diligence, there are continual activities; this means that people are actually doing things to monitor and maintain the protection mechanisms, and these activities are ongoing.

Organizations have a responsibility with practicing duty of care when applying information security. The Duty of Care Risk Analysis Standard (DoCRA)&lt;ref&gt;{{Cite web|url=https://docra.org/|title=The Duty of Care Risk Analysis Standard|last=|first=|date=|website=DoCRA|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; provides principles and practices for evaluating risk. It considers all parties that could be affected by those risks. DoCRA helps evaluate safeguards if they are appropriate in protecting others from harm while presenting a reasonable burden. With increased data breach litigation, companies must balance security controls, compliance, and its mission.

=== Security governance ===
{{See also|Information Security Governance}}
The [[Software Engineering Institute]] at [[Carnegie Mellon University]], in a publication titled ''Governing for Enterprise Security (GES) Implementation Guide'', defines characteristics of effective security governance. These include:&lt;ref name="WestbyGovern07"&gt;{{cite web |url=https://resources.sei.cmu.edu/asset_files/TechnicalNote/2007_004_001_14837.pdf |format=PDF |title=Governing for Enterprise Security (GES) Implementation Guide |author1=Westby, J.R.|author2=Allen, J.H. |publisher=Software Engineering Institute |date=August 2007 |accessdate=25 January 2018}}&lt;/ref&gt;
* An enterprise-wide issue
* Leaders are accountable
* Viewed as a business requirement
* Risk-based
* Roles, responsibilities, and segregation of duties defined
* Addressed and enforced in policy
* Adequate resources committed
* Staff aware and trained
* A development life cycle requirement
* Planned, managed, measurable, and measured
* Reviewed and audited

=== Incident response plans ===
{{expand section|date=January 2018}}
An incident response plan that addresses how discovered breaches in security is also vital. It should include:
* Selection of team members
* Definition of roles, responsibilities and lines of authority
* Definition of a security incident
* Definition of a reportable incident
* Training
* Detection
* Classification
* Escalation
* Containment
* Eradication
* Documentation

=== Change management ===
{{Main|Change Management (ITSM)}}
{{Copypaste|section|url=https://employment.blurtit.com/1335625/how-information-system-changing-the-management-process|date=April 2018}}
Change management is a formal process for directing and controlling alterations to the information processing environment. This includes alterations to desktop computers, the network, servers and software. The objectives of change management are to reduce the risks posed by changes to the information processing environment and improve the stability and reliability of the processing environment as changes are made. It is not the objective of change management to prevent or hinder necessary changes from being implemented.&lt;ref name="CampbellPractical16"&gt;{{cite book |url=https://books.google.com/books?id=sbWiDQAAQBAJ&amp;pg=PA218 |chapter=Chapter 14: Secure Systems Development |title=Practical Information Security Management: A Complete Guide to Planning and Implementation |author=Campbell, T. |publisher=Apress |year=2016 |page=218 |isbn=9781484216859}}&lt;/ref&gt;

Any change to the information processing environment introduces an element of risk. Even apparently simple changes can have unexpected effects. One of management's many responsibilities is the management of risk. Change management is a tool for managing the risks introduced by changes to the information processing environment. Part of the change management process ensures that changes are not implemented at inopportune times when they may disrupt critical business processes or interfere with other changes being implemented.

Not every change needs to be managed. Some kinds of changes are a part of the everyday routine of information processing and adhere to a predefined procedure, which reduces the overall level of risk to the processing environment. Creating a new user account or deploying a new desktop computer are examples of changes that do not generally require change management. However, relocating user file shares, or upgrading the Email server pose a much higher level of risk to the processing environment and are not a normal everyday activity. The critical first steps in change management are (a) defining change (and communicating that definition) and (b) defining the scope of the change system.

Change management is usually overseen by a change review board composed of representatives from key business areas, security, networking, systems administrators, database administration, application developers, desktop support and the help desk. The tasks of the change review board can be facilitated with the use of automated work flow application. The responsibility of the change review board is to ensure the organization's documented change management procedures are followed. The change management process is as follows&lt;ref name="TaylorProject08"&gt;{{cite book |chapter=Chapter 10: Understanding the Project Change Process |title=Project Scheduling and Cost Control: Planning, Monitoring and Controlling the Baseline |author=Taylor, J. |publisher=J. Ross Publishing |year=2008 |pages=187–214 |isbn=9781932159110}}&lt;/ref&gt;

* '''Request:'''  Anyone can request a change. The person making the change request may or may not be the same person that performs the analysis or implements the change. When a request for change is received, it may undergo a preliminary review to determine if the requested change is compatible with the organizations [[business model]] and practices, and to determine the amount of resources needed to implement the change.
* '''Approve:''' Management runs the business and controls the allocation of resources therefore, management must approve requests for changes and assign a priority for every change. Management might choose to reject a change request if the change is not compatible with the business model, industry standards or best practices. Management might also choose to reject a change request if the change requires more resources than can be allocated for the change.
* '''Plan:''' Planning a change involves discovering the scope and impact of the proposed change; analyzing the complexity of the change; allocation of resources and, developing, testing and documenting both implementation and back-out plans. Need to define the criteria on which a decision to back out will be made.
* '''Test:''' Every change must be tested in a safe test environment, which closely reflects the actual production environment, before the change is applied to the production environment. The backout plan must also be tested.
* '''Schedule:''' Part of the change review board's responsibility is to assist in the scheduling of changes by reviewing the proposed implementation date for potential conflicts with other scheduled changes or critical business activities.
* '''Communicate:'''  Once a change has been scheduled it must be communicated. The communication is to give others the opportunity to remind the change review board about other changes or critical business activities that might have been overlooked when scheduling the change. The communication also serves to make the help desk and users aware that a change is about to occur. Another responsibility of the change review board is to ensure that scheduled changes have been properly communicated to those who will be affected by the change or otherwise have an interest in the change.
* '''Implement:'''  At the appointed date and time, the changes must be implemented.  Part of the planning process was to develop an implementation plan, testing plan and, a back out plan. If the implementation of the change should fail or, the post implementation testing fails or, other "drop dead" criteria have been met, the back out plan should be implemented.
* '''Document:'''  All changes must be documented. The documentation includes the initial request for change, its approval, the priority assigned to it, the implementation, testing and back out plans, the results of the change review board critique, the date/time the change was implemented, who implemented it, and whether the change was implemented successfully, failed or postponed.
* '''Post-change review:'''  The change review board should hold a post-implementation review of changes. It is particularly important to review failed and backed out changes. The review board should try to understand the problems that were encountered, and look for areas for improvement.

Change management procedures that are simple to follow and easy to use can greatly reduce the overall risks created when changes are made to the information processing environment.  Good change management procedures improve the overall quality and success of changes as they are implemented. This is accomplished through planning, peer review, documentation and communication.

[[ISO/IEC 20000]], The Visible OPS Handbook: Implementing ITIL in 4 Practical and Auditable Steps&lt;ref&gt;[http://www.itpi.org/home/visibleops2.php itpi.org] {{webarchive |url=https://web.archive.org/web/20131210081531/http://www.itpi.org/home/visibleops2.php |date=December 10, 2013 }}&lt;/ref&gt; (Full book summary),&lt;ref&gt;{{cite web|url=http://www.wikisummaries.org/wiki/Visible_Ops |title=book summary of The Visible Ops Handbook: Implementing ITIL in 4 Practical and Auditable Steps |publisher=wikisummaries.org |accessdate=2016-06-22}}&lt;/ref&gt; and [[Information Technology Infrastructure Library]] all provide valuable guidance on implementing an efficient and effective change management program information security.

== Business continuity ==

Business continuity management ([[Business continuity planning|BCM]]) concerns arrangements aiming to protect an organization's critical business functions from interruption due to incidents, or at least minimize the effects. BCM is essential to any organization to keep technology and business in line with current threats to the continuation of business as usual. The BCM should be included in an organizations [[risk analysis]] plan to ensure that all of the necessary business functions have what they need to keep going in the event of any type of threat to any business function.&lt;ref&gt;Hotchkiss, Stuart. Business Continuity Management : In Practice, British Informatics Society Limited, 2010. ProQuest Ebook Central, https://ebookcentral.proquest.com/lib/pensu/detail.action?docID=634527.&lt;/ref&gt;

It encompasses:
* Analysis of requirements, e.g., identifying critical business functions, dependencies and potential failure points, potential threats and hence incidents or risks of concern to the organization;
* Specification, e.g., maximum tolerable outage periods; recovery point objectives (maximum acceptable periods of data loss);
* Architecture and design, e.g., an appropriate combination of approaches including resilience (e.g. engineering IT systems and processes for high availability, avoiding or preventing situations that might interrupt the business), incident and emergency management (e.g., evacuating premises, calling the emergency services, triage/situation assessment and invoking recovery plans), recovery (e.g., rebuilding) and contingency management (generic capabilities to deal positively with whatever occurs using whatever resources are available);
* Implementation, e.g., configuring and scheduling backups, data transfers, etc., duplicating and strengthening critical elements; contracting with service and equipment suppliers;
* Testing, e.g., business continuity exercises of various types, costs and assurance levels;
* Management, e.g., defining strategies, setting objectives and goals; planning and directing the work; allocating funds, people and other resources; prioritization relative to other activities; team building, leadership, control, motivation and coordination with other business functions and activities (e.g., IT, facilities, human resources, risk management, information risk and security, operations); monitoring the situation, checking and updating the arrangements when things change; maturing the approach through continuous improvement, learning and appropriate investment;
* Assurance, e.g., testing against specified requirements; measuring, analyzing and reporting key parameters; conducting additional tests, reviews and audits for greater confidence that the arrangements will go to plan if invoked.

Whereas BCM takes a broad approach to minimizing disaster-related risks by reducing both the probability and the severity of incidents, a [[disaster recovery plan]] (DRP) focuses specifically on resuming business operations as quickly as possible after a disaster. A disaster recovery plan, invoked soon after a disaster occurs, lays out the steps necessary to recover critical [[information and communications technology]] (ICT) infrastructure. Disaster recovery planning includes establishing a planning group, performing risk assessment, establishing priorities, developing recovery strategies, preparing inventories and documentation of the plan, developing verification criteria and procedure, and lastly implementing the plan.&lt;ref&gt;{{cite web|title=The Disaster Recovery Plan|url=http://www.sans.org/reading_room/whitepapers/recovery/disaster-recovery-plan_1164|publisher=Sans Institute|accessdate=7 February 2012}}&lt;/ref&gt;

== Laws and regulations ==
[[File:Privacy International 2007 privacy ranking map.png|thumb|[[Privacy International]] 2007 privacy ranking&lt;br /&gt;green: Protections and safeguards&lt;br /&gt;red: Endemic surveillance societies]]

Below is a partial listing of governmental laws and regulations in various parts of the world that have, had, or will have, a significant effect on data processing and information security. Important industry sector regulations have also been included when they have a significant impact on information security.

* The U.K. [[Data Protection Act 1984|Data Protection Act 1998]] makes new provisions for the regulation of the processing of information relating to individuals, including the obtaining, holding, use or disclosure of such information. The European Union Data Protection Directive (EUDPD) requires that all E.U. members adopt national regulations to standardize the protection of [[information privacy|data privacy]] for citizens throughout the E.U.&lt;ref name="UKDataProtAct"&gt;{{cite web |url=http://www.legislation.gov.uk/ukpga/1998/29/contents |title=Data Protection Act 1998 |work=legislation.gov.uk |publisher=The National Archives |accessdate=25 January 2018}}&lt;/ref&gt;
* The [[Computer Misuse Act]] 1990 is an Act of the [[Parliament of the United Kingdom|U.K. Parliament]] making computer crime (e.g., hacking) a criminal offense. The act has become a model upon which several other countries, including [[Canada]] and the [[Republic of Ireland]], have drawn inspiration from when subsequently drafting their own information security laws.&lt;ref name="UKCompMisAct"&gt;{{cite web |url=http://www.legislation.gov.uk/ukpga/1990/18/contents |title=Computer Misuse Act 1990 |work=legislation.gov.uk |publisher=The National Archives |accessdate=25 January 2018}}&lt;/ref&gt;
* The E.U.'s [[Data Retention Directive]] (annulled) required internet service providers and phone companies to keep data on every electronic message sent and phone call made for between six months and two years.&lt;ref name="EU24EC06"&gt;{{cite web |url=http://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:32006L0024 |title=Directive 2006/24/EC of the European Parliament and of the Council of 15 March 2006 |publisher=European Union |work=EUR-Lex |accessdate=25 January 2018}}&lt;/ref&gt;
* The [[Family Educational Rights and Privacy Act]] (FERPA) ({{usc|20|1232}} g; 34 CFR Part 99) is a U.S. Federal law that protects the privacy of student education records. The law applies to all schools that receive funds under an applicable program of the U.S. Department of Education. Generally, schools must have written permission from the parent or eligible student in order to release any information from a student's education record.&lt;ref name="FERPA"&gt;Codified at {{UnitedStatesCode|20|1232g}}, with implementing regulations in title 34, part 99 of the [[Code of Federal Regulations]]&lt;/ref&gt;
* The Federal Financial Institutions Examination Council's (FFIEC) security guidelines for auditors specifies requirements for online banking security.&lt;ref name="FFIECAudit"&gt;{{cite web |url=https://ithandbook.ffiec.gov/it-booklets/audit.aspx |title=Audit Booklet |publisher=FFIEC |work=Information Technology Examination Handbook |accessdate=25 January 2018}}&lt;/ref&gt;
* The [[Health Insurance Portability and Accountability Act]] (HIPAA) of 1996 requires the adoption of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers. Additionally, it requires health care providers, insurance providers and employers to safeguard the security and privacy of health data.&lt;ref name="HIPAAGPO"&gt;{{cite web |url=http://www.gpo.gov/fdsys/pkg/PLAW-104publ191/content-detail.html |title=Public Law 104 - 191 - Health Insurance Portability and Accountability Act of 1996 |publisher=U.S. Government Publishing Office |accessdate=25 January 2018}}&lt;/ref&gt;
* The [[Gramm–Leach–Bliley Act]] of 1999 (GLBA), also known as the Financial Services Modernization Act of 1999, protects the privacy and security of private financial information that financial institutions collect, hold, and process.&lt;ref name="GLBAGPO"&gt;{{cite web |url=https://www.gpo.gov/fdsys/pkg/STATUTE-113/pdf/STATUTE-113-Pg1338.pdf |format=PDF |title=Public Law 106 - 102 - Gramm–Leach–Bliley Act of 1999 |publisher=U.S. Government Publishing Office |accessdate=25 January 2018}}&lt;/ref&gt;
* Section 404 of the [[Sarbanes–Oxley Act|Sarbanes–Oxley Act of 2002 (SOX)]] requires publicly traded companies to assess the effectiveness of their internal controls for financial reporting in annual reports they submit at the end of each fiscal year. Chief information officers are responsible for the security, accuracy and the reliability of the systems that manage and report the financial data. The act also requires publicly traded companies to engage with independent auditors who must attest to, and report on, the validity of their assessments.&lt;ref name="SOAGPO"&gt;{{cite web |url=https://www.gpo.gov/fdsys/pkg/PLAW-107publ204/html/PLAW-107publ204.htm |title=Public Law 107 - 204 - Sarbanes-Oxley Act  of 2002 |publisher=U.S. Government Publishing Office |accessdate=25 January 2018}}&lt;/ref&gt;
* The [[Payment Card Industry Data Security Standard|Payment Card Industry Data Security Standard (PCI DSS)]] establishes comprehensive requirements for enhancing payment account data security. It was developed by the founding payment brands of the PCI Security Standards Council — including [[American Express]], [[Discover Card|Discover Financial Services]], JCB, MasterCard Worldwide and [[Visa Inc.|Visa International]] — to help facilitate the broad adoption of consistent [[data security]] measures on a global basis. The PCI DSS is a multifaceted security standard that includes requirements for security management, policies, procedures, [[network architecture]], software design and other critical protective measures.&lt;ref name="PCIDSS3.2"&gt;{{cite web |url=https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2.pdf |format=PDF |title=Payment Card Industry (PCI) Data Security Standard: Requirements and Security Assessment Procedures - Version 3.2 |publisher=Security Standards Council |date=April 2016 |accessdate=25 January 2018}}&lt;/ref&gt;
* State [[security breach notification laws]] (California and many others) require businesses, nonprofits, and state institutions to notify consumers when unencrypted "personal information" may have been compromised, lost, or stolen.&lt;ref name="NCSLStateSecBreach17"&gt;{{cite web |url=http://www.ncsl.org/research/telecommunications-and-information-technology/security-breach-notification-laws.aspx |title=Security Breach Notification Laws |publisher=National Conference of State Legislatures |date=12 April 2017 |accessdate=25 January 2018}}&lt;/ref&gt;
* The Personal Information Protection and Electronics Document Act ([[Personal Information Protection and Electronic Documents Act|PIPEDA]]) of Canada supports and promotes electronic commerce by protecting personal information that is collected, used or disclosed in certain circumstances, by providing for the use of electronic means to communicate or record information or transactions and by amending the [[Canada Evidence Act]], the Statutory Instruments Act and the Statute Revision Act.&lt;ref name="PIPEDA"&gt;{{cite web |url=http://laws-lois.justice.gc.ca/PDF/P-8.6.pdf |format=PDF |title=Personal Information Protection and Electronic Documents Act |publisher=Canadian Minister of Justice |accessdate=25 January 2018}}&lt;/ref&gt;
* Greece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 165/2011) establishes and describes the minimum information security controls that should be deployed by every company which provides electronic communication networks and/or services in Greece in order to protect customers' confidentiality. These include both managerial and technical controls (e.g., log records should be stored for two years).&lt;ref name="RACEC"&gt;{{cite web |url=http://www.adae.gr/fileadmin/docs/nomoi/kanonismoi/ADAE_REGULATION_165.2011.pdf |format=PDF |title=Regulation for the Assurance of Confidentiality in Electronic Communications |work=Government Gazette of the Hellenic Republic |publisher=Hellenic Authority for Communication Security and Privacy |date=17 November 2011 |accessdate=25 January 2018}}&lt;/ref&gt;
* Greece's Hellenic Authority for Communication Security and Privacy (ADAE) (Law 205/2013) concentrates around the protection of the integrity and availability of the services and data offered by Greek telecommunication companies. The law forces these and other related companies to build, deploy and test appropriate business continuity plans and redundant infrastructures.&lt;ref name="205/2013"&gt;{{cite web |url=http://www.adae.gr/fileadmin/docs/nomoi/kanonismoi/Kanonismos_FEK_1742_B_15_07_2013_asfaleia_akeraiotita__ADAE_205_2013.pdf |format=PDF |title=Αριθμ. απόφ. 205/2013 |work=Government Gazette of the Hellenic Republic |publisher=Hellenic Authority for Communication Security and Privacy |date=15 July 2013 |accessdate=25 January 2018}}&lt;/ref&gt;

== Information security culture ==
Employee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. "Exploring the Relationship between Organizational Culture and Information Security Culture" provides the following definition of information security culture: "ISC is the totality of patterns of behavior in an organization that contribute to the protection of information of all kinds."&lt;ref&gt;Lim, Joo S., et al. "Exploring the Relationship between Organizational Culture and Information Security Culture." Australian Information Security Management Conference.&lt;/ref&gt;

Andersson and Reimers (2014) found that employees often do not see themselves as part of the organization Information Security "effort" and often take actions that ignore organizational information security best interests.&lt;ref name="Andersson &amp; Reimers 2014"&gt;Anderson, D., Reimers, K. and Barretto, C. (March 2014). Post-Secondary Education Network Security: Results of Addressing the End-User Challenge.publication date Mar 11, 2014 publication description INTED2014 (International Technology, Education, and Development Conference)&lt;/ref&gt; Research shows information security culture needs to be improved continuously. In ''Information Security Culture from Analysis to Change'', authors commented, "It's a never ending process, a cycle of evaluation and change or maintenance." To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.&lt;ref name="Schlienger, Thomas 2003" /&gt;

* Pre-Evaluation: to identify the awareness of information security within employees and to analysis current security policy
* Strategic Planning: to come up a better awareness-program, we need to set clear targets. Clustering people is helpful to achieve it
* Operative Planning: create a good security culture based on internal communication, management buy-in, security awareness and training programs
* Implementation: should feature commitment of management, communication with organizational members, courses for all organizational members, and commitment of the employees&lt;ref name="Schlienger, Thomas 2003" /&gt;
* Post-evaluation: to better gauge the effectiveness of the prior steps and build on continuous improvement

== Sources of standards ==
{{Main|Cyber Security Standards}}
The [[International Organization for Standardization]] (ISO) is a consortium of national standards institutes from 157 countries, coordinated through a secretariat in Geneva, Switzerland. ISO is the world's largest developer of standards. ISO 15443: "Information technology – Security techniques – A framework for IT security assurance", [[ISO/IEC 27002]]: "Information technology – Security techniques – Code of practice for information security management", [[ISO 20000|ISO-20000]]: "Information technology – Service management", and [[ISO/IEC 27001]]: "Information technology – Security techniques – Information security management systems – Requirements" are of particular interest to information security professionals.

The US [[National Institute of Standards and Technology]] (NIST) is a non-regulatory federal agency within the [[U.S. Department of Commerce]]. The NIST Computer Security Division
develops standards, metrics, tests and validation programs as well as publishes standards and guidelines to increase secure IT planning, implementation, management and operation.  NIST is also the custodian of the U.S. [[Federal Information Processing Standard]] publications (FIPS).

[[The Internet Society]] is a professional membership society with more than 100 organizations and over 20,000 individual members in over 180 countries. It provides leadership in addressing issues that confront the future of the internet and is the organizational home for the groups responsible for internet infrastructure standards, including the [[Internet Engineering Task Force]] (IETF) and the [[Internet Architecture Board]] (IAB). The ISOC hosts the Requests for Comments (RFCs) which includes the Official Internet Protocol Standards and the RFC-2196 [[Site Security Handbook]].

The [[Information Security Forum]] is a global nonprofit organization of several hundred leading organizations in financial services, manufacturing, telecommunications, consumer goods, government, and other areas. It undertakes research into information security practices and offers advice in its biannual [[Standard of Good Practice]] and more detailed advisories for members.

The [[Institute of Information Security Professionals]] (IISP) is an independent, non-profit body governed by its members, with the principal objective of advancing the professionalism of information security practitioners and thereby the professionalism of the industry as a whole. The institute developed the IISP Skills Framework. This framework describes the range of competencies expected of information security and information assurance professionals in the effective performance of their roles. It was developed through collaboration between both private and public sector organizations and world-renowned academics and security leaders.&lt;ref&gt;{{cite web|title=IISP Skills Framework|url=https://www.iisp.org/imis15/iisp/Accreditation/Our_Skills_Framework/iispv2/Accreditation/Our_Skills_Framework.aspx?hkey=e77a6f03-9498-423e-aa7b-585381290ec4}}&lt;/ref&gt;

The German [[Federal Office for Information Security]] (in German ''Bundesamt für Sicherheit in der Informationstechnik (BSI)'') BSI-Standards 100-1 to 100-4 are a set of recommendations including "methods, processes, procedures, approaches and measures relating to information security".&lt;ref&gt;{{cite web|url=https://www.bsi.bund.de/EN/Publications/BSIStandards/BSIStandards_node.html;jsessionid=8FB8A442EDCF66AECC34651426C22D11.2_cid359|title=BSI-Standards|last=|first=|date=|publisher=BSI|work=|accessdate=29 November 2013}}&lt;/ref&gt; The BSI-Standard 100-2 ''IT-Grundschutz Methodology'' describes how information security management can be implemented and operated. The standard includes a very specific guide, the [[IT Baseline Protection Catalogs]] (also known as IT-Grundschutz Catalogs). Before 2005, the catalogs were formerly known as "[[IT baseline protection|IT Baseline Protection]] Manual". The Catalogs are a collection of documents useful for detecting and combating security-relevant weak points in the IT environment (IT cluster). The collection encompasses as of September 2013 over 4,400 pages with the introduction and catalogs. The IT-Grundschutz approach is aligned with to the ISO/IEC 2700x family.

The [[European Telecommunications Standards Institute]] standardized a catalog of [[information security indicators]], headed by the Industrial Specification Group (ISG) ISI.

== See also ==
{{Portal|Computer security}}
{{colbegin}}
* [[Backup]]
* [[Data breach]]
* [[Data-centric security]]
* [[Enterprise information security architecture]]
* [[Identity-based security]]
* [[Information infrastructure]]
* [[Information security audit]]
* [[Information security indicators]]
* [[Information security management]]
* [[Information security standards]]
* [[Information technology security audit]]
* [[IT risk]]
* [[ITIL security management]]
* [[Kill chain]]
* [[List of Computer Security Certifications]]
* [[Mobile security]]
* [[Network Security Services]]
* [[Privacy engineering]]
* [[Privacy software]]
* [[Privacy-enhancing technologies]]
* [[Security bug]]
* [[Security information management]]
* [[Security level management]]
* [[Security of Information Act]]
* [[Security service (telecommunication)]]
* [[Single sign-on]]
* [[Verification and validation]]
{{colend}}

== References ==
{{Reflist}}

== Further reading ==
* Anderson, K., "[https://web.archive.org/web/20080402234040/http://www.scmagazineus.com/IT-security-professionals-must-evolve-for-changing-market/article/33990/ IT Security Professionals Must Evolve for Changing Market]", ''SC Magazine'', October 12, 2006.
* Aceituno, V., "On Information Security Paradigms", ''ISSA Journal'', September 2005.
* Dhillon, G., ''Principles of Information Systems Security: text and cases'', [[John Wiley &amp; Sons]], 2007.
* Easttom, C., ''Computer Security Fundamentals (2nd Edition)'' [[Pearson Education]], 2011.
* Lambo, T., "ISO/IEC 27001: The future of infosec certification", ''ISSA Journal'', November 2006.
* Dustin, D., " [http://blog.brisbanedatarecovery.com.au/2017/05/awareness-of-how-your-data-is-being.html Awareness of How Your Data is Being Used and What to Do About It]", "CDR Blog", May 2017.

=== Bibliography ===
* {{cite book|last=Allen|first=Julia H.|title=The CERT Guide to System and Network Security Practices|publisher=Addison-Wesley|year=2001|location=Boston, MA|isbn= 0-201-73723-X}}
* {{cite book|last=Krutz|first=Ronald L.|author2=Russell Dean Vines|title=The CISSP Prep Guide|edition=Gold|publisher=Wiley|year=2003|location=Indianapolis, IN| isbn=0-471-26802-X}}
* {{cite book|last=Layton|first=Timothy P.|title=Information Security: Design, Implementation, Measurement, and Compliance|publisher=Auerbach publications|year=2007| location=Boca Raton, FL|isbn=978-0-8493-7087-8 }}
* {{cite book|last=McNab|first=Chris|title=Network Security Assessment|publisher=O'Reilly|year=2004|location=Sebastopol, CA|isbn=0-596-00611-X}}
* {{cite book|last=Peltier|first=Thomas R.|title=Information Security Risk Analysis|publisher=Auerbach publications|year=2001|location=Boca Raton, FL|isbn=0-8493-0880-1}}
* {{cite book|last=Peltier|first=Thomas R.|title=Information Security Policies, Procedures, and Standards: guidelines for effective information security management| publisher=Auerbach publications|year=2002|location=Boca Raton, FL|isbn=0-8493-1137-3}}
* {{cite book|last=White|first=Gregory|title=All-in-one Security+ Certification Exam Guide|publisher=McGraw-Hill/Osborne|year=2003|location=Emeryville, CA|isbn= 0-07-222633-1}}
* {{cite book|last=Dhillon|first=Gurpreet|title=Principles of Information Systems Security: text and cases|publisher=John Wiley &amp; Sons|year=2007|location=NY|isbn= 978-0-471-45056-6}}

== External links ==
{{Commons category}}
* [http://iac.dtic.mil/iatac/ia_policychart.html DoD IA Policy Chart] on the DoD Information Assurance Technology Analysis Center web site.
* [http://msdn2.microsoft.com/en-us/library/ms998382.aspx patterns &amp; practices Security Engineering Explained]
* [http://www.opensecurityarchitecture.org/ Open Security Architecture- Controls and patterns to secure IT systems]
* [http://www.iwar.org.uk/comsec/ IWS – Information Security Chapter]
* [http://www.cl.cam.ac.uk/~rja14/book.html Ross Anderson's book "Security Engineering"]

{{Computer science}}

[[Category:Data security]]
[[Category:Computer security]]
[[Category:Security]]
[[Category:Crime prevention]]
[[Category:National security]]
[[Category:Cryptography]]
[[Category:Information governance]]</text>
      <sha1>7miqf1wu4ci8inskexyz2k49jt2ok7t</sha1>
    </revision>
  </page>
  <page>
    <title>Integral graph</title>
    <ns>0</ns>
    <id>24845923</id>
    <revision>
      <id>849590688</id>
      <parentid>798047034</parentid>
      <timestamp>2018-07-10T01:33:06Z</timestamp>
      <contributor>
        <ip>2600:1:92F3:6F1D:CE6:E9E8:8C2D:202B</ip>
      </contributor>
      <comment>This is usually implied but in a encyclopedia it's better to state it explicitly</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1515">In the [[mathematics|mathematical]] field of [[graph theory]], an '''integral graph''' is a graph whose [[adjacency matrix]]'s [[Spectral graph theory|spectrum]] consists entirely of integers. In other words, a graph is an integral graph if all of the [[zero of a function|roots]] of the [[characteristic polynomial]] of its adjacency matrix are integers.&lt;ref&gt;{{MathWorld|urlname=IntegralGraph|title=Integral Graph}}&lt;/ref&gt;

The notion was introduced in 1974 by [[Frank Harary|Harary]] and Schwenk.&lt;ref&gt;Harary, F. and Schwenk, A. J. "Which Graphs have Integral Spectra?" In Graphs and Combinatorics (Ed. R. Bari and F. Harary). Berlin: Springer-Verlag, pp. 45&amp;ndash;51, 1974.&lt;/ref&gt;

==Examples==
*The [[complete graph]] ''K&lt;sub&gt;n&lt;/sub&gt;'' is integral for all ''n''.
*The [[edgeless graph]] &lt;math&gt;\bar K_n&lt;/math&gt; is integral for all ''n''.
*Among the cubic symmetric graphs the [[utility graph]], the [[Petersen graph]], the [[Nauru graph]] and the [[Desargues graph]] are integral.
*The [[Higman–Sims graph]], the [[Hall–Janko graph]], the [[Clebsch graph]], the [[Hoffman–Singleton graph]], the [[Shrikhande graph]] and the [[Hoffman graph]] are integral.
*A [[regular graph]] is [[Continuous-time quantum walk#Periodic graphs|periodic]] if and only if it is an integral graph.
*A [[walk-regular graph]] that admits [[Continuous-time quantum walk#Perfect state transfer|perfect state transfer]] is an integral graph. 

==References==
{{reflist}}

[[Category:Graph families]]
[[Category:Algebraic graph theory]]</text>
      <sha1>ije20l1k63tus1ip5q145697thhrhn1</sha1>
    </revision>
  </page>
  <page>
    <title>Jucys–Murphy element</title>
    <ns>0</ns>
    <id>24153642</id>
    <revision>
      <id>846647435</id>
      <parentid>756347877</parentid>
      <timestamp>2018-06-20T02:19:06Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3665">In [[mathematics]], the  '''Jucys&amp;ndash;Murphy elements''' in the [[group algebra]] &lt;math&gt;\mathbb{C} [S_n] &lt;/math&gt; of the [[symmetric group]], named after [[Algimantas Adolfas Jucys]] and G. E. Murphy, are defined as a sum of [[transposition (mathematics)|transposition]]s by the formula:

:&lt;math&gt;X_1=0, ~~~  X_k= (1 k)+ (2 k)+\cdots+(k-1\ k), ~~~ k=2,\dots,n. &lt;/math&gt;

They play an important role in the [[representation theory]] of the [[symmetric group]].

==Properties==
They generate a commutative subalgebra of &lt;math&gt;\mathbb{C} [ S_n] &lt;/math&gt;. Moreover,
''X''&lt;sub&gt;''n''&lt;/sub&gt; commutes with all elements of &lt;math&gt;\mathbb{C} [S_{n-1}] &lt;/math&gt;.

The vectors constituting   the basis of Young's "seminormal representation"   are eigenvectors for the action of ''X''&lt;sub&gt;''n''&lt;/sub&gt;.  For any [[standard Young tableau]] ''U'' we have:

:&lt;math&gt;X_k v_U =c_k(U) v_U, ~~~ k=1,\dots,n, &lt;/math&gt;

where ''c''&lt;sub&gt;''k''&lt;/sub&gt;(''U'') is the ''content'' ''b''&amp;nbsp;&amp;minus;&amp;nbsp;''a'' of the cell (''a'',&amp;nbsp;''b'') occupied by  ''k'' in the standard Young tableau&amp;nbsp;''U''.

'''Theorem''' (Jucys): The [[Center (algebra)|center]] &lt;math&gt;Z(\mathbb{C} [S_n])&lt;/math&gt; of the group algebra &lt;math&gt;\mathbb{C} [S_n] &lt;/math&gt;  of the symmetric group is generated by the [[symmetric polynomial]]s in the elements ''X&lt;sub&gt;k&lt;/sub&gt;''.

'''Theorem''' (Jucys): Let ''t'' be a formal variable commuting with everything, then the following identity for polynomials in variable ''t'' with values in the group algebra  &lt;math&gt;\mathbb{C} [S_n] &lt;/math&gt; holds true:

:&lt;math&gt; (t+X_1) (t+X_2) \cdots (t+X_n)= \sum_{\sigma \in S_n} \sigma t^{\text{number of cycles of }\sigma}.&lt;/math&gt;

'''Theorem''' ([[Okounkov]]&amp;ndash;[[Vershik]]): The subalgebra of  &lt;math&gt;\mathbb{C} [S_n] &lt;/math&gt; generated by the centers

: &lt;math&gt; Z(\mathbb{C} [ S_1]), Z(\mathbb{C} [ S_2]), \ldots,  Z(\mathbb{C} [ S_{n-1}]),  Z(\mathbb{C} [S_n])  &lt;/math&gt;

is exactly the subalgebra generated by the Jucys&amp;ndash;Murphy elements ''X&lt;sub&gt;k&lt;/sub&gt;''.

==See also==
* [[Representation theory of the symmetric group]]
* [[Young symmetrizer]]

==References==
*{{Citation
|title=A New Approach to the Representation Theory of the Symmetric Groups. 2
|authorlink1=Okounkov
|first1=Andrei |last1=Okounkov
|authorlink2=Vershik
|first2=Anatoly |last2=Vershik
|year=2004
|volume=307
|journal=Zapiski Seminarod POMI (In Russian) v.
|arxiv = math.RT/0503040
|postscript=  (revised English version). }}

*{{citation
|title=Symmetric polynomials and the center of the symmetric group ring
|authorlink1=Algimantas Adolfas Jucys
|first1=Algimantas Adolfas  |last1=Jucys
| year=1974 | journal=Rep. Mathematical Phys. | volume=5 | issue=1  | pages=107–112
| doi=10.1016/0034-4877(74)90019-6   
|bibcode=1974RpMP....5..107J}}

*{{citation
|title=On the Young operators of the symmetric group
|authorlink1=Algimantas Adolfas Jucys
|first1=Algimantas Adolfas  |last1=Jucys
| year=1966 | journal=Lietuvos Fizikos Rinkinys | volume=6  | pages=163–180
}}

*{{citation
|title=Factorization of Young projection operators for the symmetric group
|authorlink1=Algimantas Adolfas Jucys
|first1=Algimantas Adolfas  |last1=Jucys
| year=1971 | journal=Lietuvos Fizikos Rinkinys | volume=11  | pages=5–10
}}

*{{citation
|title=A new construction of Young's seminormal representation of the symmetric group
|first1=G. E.  |last1=Murphy
| year=1981 | journal=J. Algebra | volume=69  | pages=287–297
|doi=10.1016/0021-8693(81)90205-2
|issue=2
}}

{{DEFAULTSORT:Jucys-Murphy Element}}
[[Category:Permutation groups]]
[[Category:Representation theory]]
[[Category:Symmetry]]
[[Category:Representation theory of finite groups]]
[[Category:Symmetric functions]]</text>
      <sha1>nuka6q4px3ingc18lqh96jtfiw3ir66</sha1>
    </revision>
  </page>
  <page>
    <title>Lieb's square ice constant</title>
    <ns>0</ns>
    <id>16381455</id>
    <revision>
      <id>855916066</id>
      <parentid>849856539</parentid>
      <timestamp>2018-08-21T17:53:32Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2633">{| class="infobox" style ="width: 370px;"
|[[Binary numeral system|Binary]]
| 1.10001010001000110100010111001100…
|-
| [[Decimal]]
| 1.53960071783900203869106341467188…
|-
| [[Hexadecimal]]
| 1.8A2345CC04425BC2CBF57DB94EDCA6B2…
|-
| [[Continued fraction]]
| &lt;math&gt;1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{5 + \cfrac{1}{1 + \cfrac{1}{4 + \ddots}}}}}&lt;/math&gt;
|-
|[[Algebraic form]]
|&lt;math&gt;\frac{8\sqrt{3}}{9}&lt;/math&gt;
|}

'''Lieb's square ice constant''' is a [[mathematical constant]] used in the field of [[combinatorics]] to quantify the number of [[Eulerian path|Eulerian orientation]]s of [[grid graph]]s. It was introduced by [[Elliott H. Lieb]] in 1967.&lt;ref&gt;{{cite journal|last1=Lieb|first1=Elliott|title=Residual Entropy of Square Ice|journal=[[Physical Review]]|volume=162|issue=1|page=162|year=1967|doi= 10.1103/PhysRev.162.162}}&lt;/ref&gt;

==Definition==
An ''n''&amp;nbsp;&amp;times;&amp;nbsp;''n'' grid graph (with [[periodic boundary conditions]] and ''n''&amp;nbsp;≥&amp;nbsp;2) has ''n''&lt;sup&gt;2&lt;/sup&gt; vertices and 2''n''&lt;sup&gt;2&lt;/sup&gt; edges; it is [[regular graph|4-regular]], meaning that each vertex has exactly four neighbors. An [[orientation (graph theory)|orientation]] of this graph is an assignment of a [[directed graph|direction]] to each edge; it is an [[Eulerian path|Eulerian orientation]] if it gives each vertex exactly two incoming edges and exactly two outgoing edges. Denote the number of Eulerian orientations of this graph by ''f''(''n''). Then

: &lt;math&gt;\lim_{n \to \infty}\sqrt[n^2]{f(n)}=\left(\frac{4}{3}\right)^\frac{3}{2}=\frac{8 \sqrt{3}}{9}=1.5396007\dots&lt;/math&gt;&lt;ref&gt;{{OEIS|id=A118273}}&lt;/ref&gt;

is Lieb's square ice constant.

The same constant also quantifies in the same way the number of [[graph coloring|3-colorings]] of grid graphs, and the number of local flat foldings of the [[Miura fold]].&lt;ref&gt;{{citation
 | last1 = Ballinger | first1 = Brad
 | last2 = Damian | first2 = Mirela
 | last3 = Eppstein | first3 = David | author3-link = David Eppstein
 | last4 = Flatland | first4 = Robin
 | last5 = Ginepro | first5 = Jessica
 | last6 = Hull | first6 = Thomas | author6-link = Tom Hull
 | contribution = Minimum forcing sets for Miura folding patterns
 | doi = 10.1137/1.9781611973730.11
 | pages = 136–147
 | publisher = Society for Industrial and Applied Mathematics
 | title = Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms
 | year = 2015| arxiv = 1410.2231}}&lt;/ref&gt;
Some historical and physical background can be found in the article [[Ice-type model]].

== See also ==

* [[Spin ice]]

== References ==
{{reflist}}

[[Category:Mathematical constants]]


{{combin-stub}}</text>
      <sha1>hphe7cc6eb8itusq2w0lav61yfza2a1</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematical knots and links</title>
    <ns>0</ns>
    <id>1168363</id>
    <revision>
      <id>837378206</id>
      <parentid>809838332</parentid>
      <timestamp>2018-04-20T13:13:37Z</timestamp>
      <contributor>
        <username>ArnoldReinhold</username>
        <id>84951</id>
      </contributor>
      <comment>/* Links */ put Brunnian ahead of Borromean</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3085">{{no footnotes|date=February 2013}}
[[Image:Knot table.svg|thumb|350px|right|A table of all [[prime knot]]s with seven [[Crossing number (knot theory)|crossings]] or fewer (not including mirror images).]]

This article contains a '''list of [[knot (mathematics)|mathematical knots]] and [[link (knot theory)|links]]'''. See also [[list of knots]], [[list of geometric topology topics]].

==Knots==
===Prime knots===
{{See also|List of prime knots}}
*0₁ knot/[[Unknot]] - a simple un-knotted closed loop
*3₁ knot/[[Trefoil knot]] - (2,3)-torus knot, the two loose ends of a common overhand knot joined together
*4₁ knot/[[Figure-eight knot (mathematics)]] - a prime knot with a crossing number four
*5₁ knot/[[Cinquefoil knot]], (5,2)-torus knot, Solomon's seal knot, pentafoil knot - a prime knot with crossing number five which can be arranged as a pentagram
*5₂ knot/[[Three-twist knot]] - the twist knot with three-half twists
*6₁ knot/[[Stevedore knot (mathematics)]] - a prime knot with crossing number six, it can also be described as a twist knot with four twists
*[[6₂ knot]] - a prime knot with crossing number six
*[[6₃ knot]] - a prime knot with crossing number six
*[[7₁ knot]], septafoil knot, (7,2)-torus knot - a prime knot with crossing number seven, which can be arranged as a {7,2} star polygon
*[[7₄ knot]], "endless knot"
*[[Carrick mat|8&lt;sub&gt;18&lt;/sub&gt; knot]], "carrick mat"
*10₁₆₁/[[Perko pair]]
*12n242/[[(−2,3,7) pretzel knot]]
*(''p'',&amp;nbsp;''q'')-[[torus knot]] - a special kind of knot that lies on the surface of an unknotted torus in R&lt;sup&gt;3&lt;/sup&gt;

===Composite===
*[[Square knot (mathematics)]] - a composite knot obtained by taking the connected sum of a trefoil knot with its reflection
*[[Granny knot (mathematics)]] - a composite knot obtained by taking the connected sum of two identical trefoil knots

==Links==
*0{{sup sub|2|1}} link/[[Unlink]] - equivalent under ambient isotopy to finitely many disjoint circles in the plane
*2{{sup sub|2|1}} link/[[Hopf link]] - the simplest nontrivial link with more than one component; it consists of two circles linked together exactly once (L2a1)
*4{{sup sub|2|1}} link/[[Solomon's knot]] (a two component "link" rather than a one component "knot") - a traditional decorative motif used since ancient times (L4a1)
*5{{sup sub|2|1}} link/[[Whitehead link]] - two projections of the unknot: one circular loop and one figure eight-shaped loop intertwined such that they are inseparable and neither loses its form (L5a1)
*[[Brunnian link]] - a nontrivial link that becomes trivial if any component is removed
*6{{sup sub|3|2}} link/[[Borromean rings]] - three topological circles which are linked and form a Brunnian link (L6a4)
*[[L10a140 link]] - presumably the simplest non-Borromean Brunnian link
*[[Pretzel link]] -  a [[Montesinos link]] with integer tangles

==External links==
*{{Knot Atlas|Main_Page|Catalogue of all knots and links with 11 or fewer crossings (wiki)}}

{{Knots}}
{{Knot theory}}

[[Category:Mathematics-related lists|Knots and links]]
[[Category:Knot theory]]</text>
      <sha1>rn9gmnwgyepvnrlwt7ck0bocb4c07n0</sha1>
    </revision>
  </page>
  <page>
    <title>Maximum-minimums identity</title>
    <ns>0</ns>
    <id>19167177</id>
    <revision>
      <id>772276817</id>
      <parentid>728435123</parentid>
      <timestamp>2017-03-26T09:49:06Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2323">In mathematics, the '''maximum-minimums identity''' is a relation between the maximum element of a set ''S'' of ''n'' numbers and the minima of the 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1 nonempty subsets of ''S''.

Let ''S'' = {''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;}.  The [[identity (mathematics)|identity]] states that 

:&lt;math&gt;\begin{align}
\max\{x_1,x_2,\ldots,x_{n}\} 
&amp; = \sum_{i=1}^n x_i - \sum_{i&lt;j}\min\{x_i,x_j\} +\sum_{i&lt;j&lt;k}\min\{x_i,x_j,x_k\} - \cdots \\
&amp; \qquad \cdots + \left(-1\right)^{n+1}\min\{x_1,x_2,\ldots,x_n\},\end{align}&lt;/math&gt;
or conversely

:&lt;math&gt;\begin{align}
\min\{x_1,x_2,\ldots,x_{n}\} 
&amp; = \sum_{i=1}^n x_i - \sum_{i&lt;j}\max\{x_i,x_j\} +\sum_{i&lt;j&lt;k}\max\{x_i,x_j,x_k\} - \cdots \\
&amp; \qquad \cdots + \left(-1\right)^{n+1}\max\{x_1,x_2,\ldots,x_n\}.
\end{align}
&lt;/math&gt;

&lt;!--
OK, this didn't go as planned
==Inductive proof==
Clearly the identity holds for ''n'' = 1. Assume it holds for ''n'' and let 
:&lt;math&gt;
M_n = \max(x_1,x_2,\ldots,x_n)
&lt;/math&gt;
Then for arbitrary ''x''&lt;sub&gt;''n''+1&lt;/sub&gt;,
:&lt;math&gt;
M_{n+1} = \max(x_{n+1}, M_n)
&lt;/math&gt;
and
:&lt;math&gt;
M_{n+1} = x_{n+1} + M_n - \min(x_{n+1}, M_n)
&lt;/math&gt;
By the inductive hypothesis,
:&lt;math&gt;
M_{n+1} = x_{n+1} + \sum_{i=1}^n x_i - \sum_{i&lt;j}\min(x_i,x_j) +\sum_{i&lt;j&lt;k}\min(x_i,x_j,x_k) +\cdots+\left(-1\right)^{n+1}\min(x_1,x_2,\ldots,x_n) - \min(x_{n+1}, \sum_{i=1}^n x_i - \sum_{i&lt;j}\min(x_i,x_j) +\sum_{i&lt;j&lt;k}\min(x_i,x_j,x_k) +\cdots+\left(-1\right)^{n}\min(x_1,x_2,\ldots,x_n))
&lt;/math&gt;
collecting terms and applying the fact that the minimum operator is [[distributive property|distributive]],
:&lt;math&gt;
M_{n+1} = \sum_{i=1}^{n+1} x_i - \sum_{i&lt;j}\min(x_i,x_j) +\sum_{i&lt;j&lt;k}\min(x_i,x_j,x_k) +\cdots+\left(-1\right)^{n+1}\min(x_1,x_2,\ldots,x_n) - \min(x_{n+1}, \sum_{i=1}^n x_i) + \min(x_{n+1}, \sum_{i&lt;j}\min(x_i,x_j)) - \min(x_{n+1},\sum_{i&lt;j&lt;k}\min(x_i,x_j,x_k) )+\cdots+\min(x_{n+1}, \left(-1\right)^{n+1}\min(x_1,x_2,\ldots,x_n))
&lt;/math&gt;
--&gt;
For a probabilistic proof, see the reference.

== See also ==

* [[Inclusion–exclusion principle]]
* [[Zaskulnikov's identity]]

==References==
* {{cite book | last = Ross | first = Sheldon | title = A First Course in Probability | publisher = Prentice Hall | location = Englewood Cliffs | year = 2002 | isbn = 0-13-033851-6 }}

[[Category:Mathematical identities]]</text>
      <sha1>8z1n74q2jqi1isnpinriaf2of6o58ue</sha1>
    </revision>
  </page>
  <page>
    <title>NK model</title>
    <ns>0</ns>
    <id>30353558</id>
    <revision>
      <id>862663843</id>
      <parentid>859325790</parentid>
      <timestamp>2018-10-05T21:14:11Z</timestamp>
      <contributor>
        <username>Elplatt</username>
        <id>2964805</id>
      </contributor>
      <comment>/* Mathematical details */ Corrected formal model, consistent notation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8927">The '''NK model''' is a [[mathematical model]] described by its primary inventor [[Stuart Kauffman]] as a "tunably rugged" [[fitness landscape]]. "Tunable ruggedness" captures the intuition that both the overall size of the landscape and the number of its local "hills and valleys" can be adjusted via changes to its two parameters, &lt;math&gt;N&lt;/math&gt; and &lt;math&gt;K&lt;/math&gt;, defined below.  The NK model has found application in a wide variety of fields, including the theoretical study of [[evolutionary biology]], [[immunology]], [[combinatorial optimization|optimisation]], [[technological evolution]], and [[complex systems]]. The model was also adopted in [[organizational theory]], where it is used to describe the way an [[Agent-based model|agent]] may search a landscape by manipulating various characteristics of itself. For example, an agent can be an [[organization]], the hills and valleys represent [[Profit (economics)|profit]] (or changes thereof), and movement on the landscape necessitates organizational decisions (such as adding product lines or altering the organizational structure), which tend to interact with each other and affect profit in a complex fashion.&lt;ref&gt;{{cite journal | last1 = Levinthal | first1 = D. A. | year = 1997 | title = Adaptation on Rugged Landscapes | url = | journal = Management Science | volume = 43 | issue = 7| pages = 934–950 | doi=10.1287/mnsc.43.7.934}}&lt;/ref&gt; 

An early version of the model, which considered only the smoothest (&lt;math&gt;K=0&lt;/math&gt;) and most rugged (&lt;math&gt;K=N-1&lt;/math&gt;) landscapes, was presented in Kauffman and Levin (1987).&lt;ref name = "kauff"&gt;{{cite journal | last1 = Kauffman | first1 = S. | last2 = Levin | first2 = S. | year = 1987 | title = Towards a general theory of adaptive walks on rugged landscapes | url = | journal = Journal of Theoretical Biology | volume = 128 | issue = 1| pages = 11–45 | doi=10.1016/s0022-5193(87)80029-2}}&lt;/ref&gt;  The model as it is currently known first appeared in Kauffman and Weinberger (1989).&lt;ref name = "KandW"&gt;{{cite journal | last1 = Kauffman | first1 = S. | last2 = Weinberger | first2 = E. | year = 1989 | title = The NK Model of rugged fitness landscapes and its application to the maturation of the immune response | url = | journal = Journal of Theoretical Biology | volume = 141 | issue = 2| pages = 211–245 | doi=10.1016/s0022-5193(89)80019-0}}&lt;/ref&gt;

One of the reasons why the model has attracted wide attention in [[combinatorial optimization|optimisation]] is that it is a particularly simple instance of a so-called [[NP-complete problem]].&lt;ref name = "NPcomplete"&gt;Weinberger, E. (1996), "NP-completeness of Kauffman's N-k model, a Tuneably Rugged Fitness Landscape", Santa Fe Institute Working Paper, 96-02-003.&lt;/ref&gt;

== Mathematical details ==
The NK model defines a [[combinatorial]] [[phase space]], consisting of every string (chosen from a given alphabet) of length &lt;math&gt;N&lt;/math&gt;. For each string in this search space, a [[scalar (mathematics)|scalar]] value (called the ''[[fitness function|fitness]]'') is defined. If a distance [[metric (mathematics)|metric]] is defined between strings, the resulting structure is a ''landscape''.

Fitness values are defined according to the specific incarnation of the model, but the key feature of the NK model is that the fitness of a given string &lt;math&gt;S&lt;/math&gt; is the sum of contributions from each locus &lt;math&gt;f_i(S)&lt;/math&gt; in the string:

:&lt;math&gt;F(S) = \sum_i \tilde{f}_i(S),&lt;/math&gt;

and the contribution from each locus in general depends on its state and the state of &lt;math&gt;K&lt;/math&gt; other loci,:

:&lt;math&gt;\tilde{f}_i(S) = f_i(S_i, S_{k_{i1}}, \dots, S_{k_{iK}}), &lt;/math&gt;

where &lt;math&gt;k_{ij}&lt;/math&gt; is the index of the &lt;math&gt;j&lt;/math&gt;th neighbor of locus &lt;math&gt;i&lt;/math&gt;. 

Hence, the fitness function &lt;math&gt;f_i&lt;/math&gt; is a [[Map (mathematics)|mapping]] between strings of length ''K''&amp;nbsp;+&amp;nbsp;1 and scalars, which Weinberger's later work calls "fitness contributions". Such fitness contributions are often chosen randomly from some specified probability distribution.

In 1991, Weinberger published a detailed analysis&lt;ref name="AnalyticOptima" /&gt;  of the case in which &lt;math&gt;1 &lt;&lt; k \le N&lt;/math&gt; and the fitness contributions are chosen randomly.  His analytical estimate of the number of local optima was later shown to be flawed {{Citation needed|date=March 2018}}.  However, numerical experiments included in Weinberger's analysis support his analytical result that the expected fitness of a string is normally distributed with a mean of approximately

&lt;math&gt; \mu + \sigma \sqrt{{2 \ln (k+1)} \over {k+1}}&lt;/math&gt;

and a variance of approximately

&lt;math&gt; {{(k+1)\sigma^2} \over {N[k+1 + 2(k+2)\ln(k+1)]}}&lt;/math&gt;.

[[File:Visualization of two dimensions of a NK fitness landscape.png|thumb|Visualization of two dimensions of a NK fitness landscape. The arrows represent various mutational paths that the population could follow while evolving on the fitness landscape.]]

== Example ==
For simplicity, we will work with [[Binary code|binary]] strings. Consider an NK model with ''N'' = 5, ''K'' = 1. Here, the fitness of a string is given by the sum of individual fitness contributions from each of 5 loci. Each fitness contribution depends on the local locus value and one other. We will employ the convention that &lt;math&gt;f(S_i) = f(S_i, S_{i+1})&lt;/math&gt;, so that each locus is affected by its neighbour, and &lt;math&gt;f(S_5) = f(S_5, S_1)&lt;/math&gt; for cyclicity. If we choose, for example, the fitness function ''f''(0, 0) = 0; ''f''(0, 1) = 1; ''f''(1, 0) = 2; ''f''(1, 1) = 0, the fitness values of two example strings are:

:&lt;math&gt; F(00101) = f(0,0)  + f(0,1) + f(1,0) + f(0, 1) + f(1, 0) = 0 + 1 + 2 + 1 + 2 = 6. &lt;/math&gt;
:&lt;math&gt; F(11100) = f(1,1)  + f(1,1) + f(1,0) + f(0, 0) + f(0, 1) = 0 + 0 + 2 + 0 + 1 = 3. &lt;/math&gt;

== Tunable topology ==
[[Image:Nk model hypercube.PNG|thumb|right|250px|Illustration of tunable topology in the NK model. Nodes are individual binary strings, edges connect strings with a [[Hamming distance]] of exactly one. (left) ''N'' = 5, ''K'' = 0. (centre) ''N'' = 5, ''K'' = 1. (right) ''N'' = 5, ''K'' = 2. The colour of a node denotes its fitness, with redder values having higher fitness. The [[embedding]] of the hypercube is chosen so that the fitness maximum is at the centre. Notice that the ''K'' = 0 landscape appears smoother than the higher-K cases.]]

The value of ''K'' controls the degree of [[epistasis]] in the NK model, or how much other loci affect the fitness contribution of a given locus. With ''K'' = 0, the fitness of a given string is a simple sum of individual contributions of loci: for nontrivial fitness functions, a [[global optimum]] is present and easy to locate (the genome of all 0s if ''f''(0) &gt; ''f''(1), or all 1s if ''f''(1) &gt; ''f''(0)). For nonzero ''K'', the fitness of a string is a sum of fitnesses of substrings, which may interact to [[Geometrical frustration|frustrate]] the system (consider how to achieve optimal fitness in the example above). Increasing ''K'' thus increases the ruggedness of the fitness landscape.

=== Variations with neutral spaces ===
The bare NK model does not support the phenomenon of ''neutral space'' -- that is, sets of genomes connected by single mutations that have the same fitness value. Two adaptations have been proposed to include this [[Neutral theory of molecular evolution|biologically important structure]]. The ''NKP model'' introduces a parameter &lt;math&gt;P&lt;/math&gt;: a proportion &lt;math&gt;P&lt;/math&gt; of the &lt;math&gt;2^K&lt;/math&gt; fitness contributions is set to zero, so that the contributions of several genetic motifs are degenerate {{Citation needed|date=March 2018}}. The ''NKQ model'' introduces a parameter &lt;math&gt;Q&lt;/math&gt; and enforces a discretisation on the possible fitness contribution values so that each contribution takes one of &lt;math&gt;Q&lt;/math&gt; possible values, again introducing degeneracy in the contributions from some genetic motifs {{Citation needed|date=March 2018}}. The bare NK model corresponds to the &lt;math&gt;P = 0&lt;/math&gt; and &lt;math&gt;Q = \infty&lt;/math&gt; cases under these parameterisations.

== Applications ==
The NK model has found use in many fields, including in the study of [[spin glasses]], [[epistasis]] and [[pleiotropy]] in [[evolutionary biology]], and [[combinatorial optimisation]].

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using&lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
&lt;references&gt;
&lt;ref name="AnalyticOptima"&gt;{{cite journal|last=Weinberger|first=Edward|journal=Physical Review A|date=November 15, 1991|volume=44|series=10|pages=6399–6413|doi=10.1103/physreva.44.6399|title=Local properties of Kauffman's N-k model: A tunably rugged energy landscape}}&lt;/ref&gt;
&lt;/references&gt;

{{DEFAULTSORT:Nk Model}}
[[Category:Articles created via the Article Wizard]]
[[Category:Applied mathematics]]
[[Category:Mathematical and theoretical biology]]</text>
      <sha1>9ccqrhjvybof7axpiyfvfxdx5i2nd56</sha1>
    </revision>
  </page>
  <page>
    <title>Non-classical analysis</title>
    <ns>0</ns>
    <id>1178373</id>
    <revision>
      <id>853302695</id>
      <parentid>853301681</parentid>
      <timestamp>2018-08-03T19:56:16Z</timestamp>
      <contributor>
        <ip>2601:58C:201:A884:225:FF:FE4B:69ED</ip>
      </contributor>
      <comment>Readjusted preceding edit.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2104">In [[mathematics]], '''non-classical analysis''' is any system of analysis, other than classical [[real analysis]], and complex, vector, tensor, etc., analysis based upon it.

Such systems include:

*Abstract Stone duality,&lt;ref&gt;{{cite web|url=http://www.PaulTaylor.EU/ASD |title=Paul Taylor's site |publisher=Paultaylor.eu |date= |accessdate=2013-09-23}}&lt;/ref&gt; a programme to re-axiomatise [[general topology]] ''directly'', instead of using [[set theory]]. It is formulated in the style of [[type theory]] and is in principle computable. It is currently able to characterise the [[category (mathematics)|category]] of (not necessarily Hausdorff) computably based locally compact spaces. It allows the development of a form of constructive real analysis using topological rather than [[Cauchy sequence|metrical]] arguments.
*[[Chainlet geometry]], a recent development of geometric integration theory which incorporates [[infinitesimal]]s and allows the resulting calculus to be applied to continuous domains without local Euclidean structure as well as discrete domains.
*[[Constructive analysis]], which is built upon a foundation of [[constructive logic|constructive]], rather than classical, logic and set theory.
*[[Intuitionistic analysis]], which is developed from constructive logic like constructive analysis but also incorporates [[choice sequence]]s.
*[[p-adic analysis]].
*[[Paraconsistent analysis]], which is built upon a foundation of [[paraconsistent logic|paraconsistent]], rather than classical, logic and set theory.
*[[Smooth infinitesimal analysis]], which is developed in a smooth topos.

[[Non-standard analysis]] and the calculus it involves, [[non-standard calculus]], are considered part of [[classical mathematics]] (i.e. The concept of "[[hyperreal number]]" it uses, can be constructed in the framework of [[Zermelo–Fraenkel set theory]]).

[[Multiplicative calculus #History|Non-Newtonian calculus]] is also a part of [[classical mathematics]].

==References==
{{reflist}}

{{DEFAULTSORT:Non-Classical Analysis}}
[[Category:Non-classical analysis]]


{{mathanalysis-stub}}</text>
      <sha1>pqce6z19mfmh0i3qupalv2ekgqv6qkd</sha1>
    </revision>
  </page>
  <page>
    <title>Phase boundary</title>
    <ns>0</ns>
    <id>4742308</id>
    <revision>
      <id>867946055</id>
      <parentid>807639194</parentid>
      <timestamp>2018-11-09T00:24:27Z</timestamp>
      <contributor>
        <username>VanCityUser</username>
        <id>35037242</id>
      </contributor>
      <minor/>
      <comment>Grammar edit.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2020">In [[thermal equilibrium]], each [[phase (matter)|phase]] (i.e. [[liquid]], [[solid]] etc.) of physical [[matter]] comes to an end at a transitional point, or spatial [[interface (matter)|interface]], called a '''phase boundary''', due to the [[immiscibility]] of the matter with the matter on the other side of the boundary.  This immiscibility is due to at least one difference between the two substances' corresponding physical properties. The behavior of phase boundaries has been a developing subject of interest and an active research field, called interface science, in [[physics]] and [[mathematics]] for almost two centuries, due partly to phase boundaries naturally arising in many physical processes, such as the [[capillarity effect]], the growth of [[grain boundary|grain boundaries]], the physics of [[binary alloy]]s, and the formation of [[snow flake]]s. 

One of the oldest problems in the area dates back to Lamé and Clapeyron&lt;ref&gt;[[Gabriel Lamé|G. Lamé]], [[Benoît Paul Émile Clapeyron|B. P. Clapeyron]], Memoire sur la solidification par refroiddissement d'un globe solide, Ann. Chem. Physics, 47, 250–256  (1831).&lt;/ref&gt; who studied the freezing of the ground. Their goal was to determine the thickness of solid crust generated by the cooling of a liquid at constant [[temperature]] filling the [[Half-space (geometry)|half-space]]. In 1889, Stefan, while working on the freezing of the ground developed these ideas further and formulated the two-phase model which came to be known as the [[Stefan problem | Stefan Problem]].&lt;ref&gt;[[Josef Stefan|J. Stefan]], Über einige Probleme der Theorie der Warmeleitung, S.-B Wien Akad. Mat. Natur, 98, 173–484, (1889).&lt;/ref&gt;

The proof of existence and uniqueness of a solution to the [[Stefan problem]] was done in many stages. Proving the general existence and uniqueness of the solutions in the case of &lt;math&gt;d=3&lt;/math&gt; was solved by [[Shoshana Kamin]].

== References ==
{{Reflist}}

[[Category:Phase transitions]]
[[Category:Applied mathematics]]</text>
      <sha1>ccrh3il4ryaohj8awoxvtn5ocf0q5yg</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum ergodicity</title>
    <ns>0</ns>
    <id>23855903</id>
    <revision>
      <id>860603224</id>
      <parentid>860559679</parentid>
      <timestamp>2018-09-21T20:17:34Z</timestamp>
      <contributor>
        <username>Cewbot</username>
        <id>23646674</id>
      </contributor>
      <minor/>
      <comment>bot: Convert [[Steven Zelditch|Zelditch]] to wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3197">[[File:Quantum ergodicity.gif|thumb|360px|right|The eigenmode of a classically integrable system (e.g. the circular cavity on the left) can be very confined even for high mode number. On the contrary the eigenmodes of a classically chaotic system (e.g. the stadium-shaped cavity on the right) tend to become gradually more uniform with increasing mode number.]]

In [[quantum chaos]], a branch of [[mathematical physics]], '''quantum ergodicity''' is a property of the [[Quantization (physics)|quantization]] of [[classical mechanics|classical mechanical systems]] that are [[chaos theory|chaotic]] in the sense of exponential sensitivity to initial conditions.   Quantum ergodicity states, roughly, that in the high-energy limit, the probability distributions associated to [[energy eigenstates]] of a quantized [[ergodic]] [[Hamiltonian mechanics|Hamiltonian]] tend to a [[Uniform distribution (continuous)|uniform distribution]] in the classical [[phase space]].  This is consistent with the intuition that the flows of ergodic systems are equidistributed in phase space.  By contrast, classical [[completely integrable system]]s generally have periodic orbits in phase space, and this is exhibited in a variety of ways in the high-energy limit of the eigenstates: typically that some form of concentration or "scarring" occurs in the limit.

The model case of a Hamiltonian is the [[geodesics as Hamiltonian flows|geodesic Hamiltonian]] on the [[cotangent bundle]] of a [[compact space|compact]] [[Riemannian manifold]].  The quantization of the geodesic flow is given by the [[fundamental solution]] of the [[Schrödinger equation]]
:&lt;math&gt;U_t=\exp(it\sqrt{\Delta})&lt;/math&gt;
where &lt;math&gt;\sqrt{\Delta}&lt;/math&gt; is the square root of the [[Laplace-Beltrami operator]]. The '''quantum ergodicity theorem''' of Shnirelman, [[Yves Colin de Verdière]], and [[Steven Zelditch|Zelditch]] states that a compact Riemannian manifold whose [[unit tangent bundle]] is ergodic under the geodesic flow is also ergodic in the sense that the probability density associated to the ''n''th eigenfunction of the Laplacian tends weakly to the uniform distribution on the unit cotangent bundle as ''n''&amp;nbsp;&amp;rarr;&amp;nbsp;&amp;infin; in a subset of the natural numbers of [[natural density]] equal to one. Quantum ergodicity can be formulated as a non-commutative analogue of the classical ergodicity ([[Toshikazu Sunada|T. Sunada]]).

==See also==
*[[Eigenstate thermalization hypothesis]]
*[[Ergodic hypothesis]]

==References==
* {{Citation | last=Zelditch|first=S|chapter=Quantum ergodicity and mixing of eigenfunctions|editor1-last=Françoise | editor1-first=Jean-Pierre | editor2-last=Naber | editor2-first=Gregory L. | editor3-last=Tsun | editor3-first=Tsou Sheung | title=Encyclopedia of mathematical physics. Vol. 1, 2, 3, 4, 5 | publisher=Academic Press/Elsevier Science, Oxford | isbn=9780125126601 | mr=2238867  | year=2006}}
* {{Citation | last=Sunada|first= T|chapter=Quantum ergodicity |title=Trend in Mathematics |publisher=Birkhauser Verlag,  Basel|year=1997 |pages=175–196}}

[[Category:Modular forms]]
[[Category:Chaos theory]]
[[Category:Ergodic theory]]
[[Category:Quantum mechanics]]


{{math-stub}}</text>
      <sha1>6x2lp5h1pmrizmu12co1c5o3imqtsi3</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum supremacy</title>
    <ns>0</ns>
    <id>54452801</id>
    <revision>
      <id>871359557</id>
      <parentid>860826694</parentid>
      <timestamp>2018-11-30T14:58:26Z</timestamp>
      <contributor>
        <username>XXeducationexpertXX</username>
        <id>35178413</id>
      </contributor>
      <comment>Recent Google partnership with NASA</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19636">'''Quantum supremacy''' or '''quantum advantage''' is the potential ability of [[quantum computing]] devices to solve problems that classical computers practically cannot.&lt;ref name=":0"&gt;{{cite arxiv |last=Preskill |first=John |date=2012-03-26 |title=Quantum computing and the entanglement frontier |eprint=1203.5813 |class=quant-ph}}&lt;/ref&gt; In [[computational complexity theory|computational complexity]]-theoretic terms, this generally means providing a [[Time complexity|superpolynomial]] speedup over the best known or possible classical algorithm.&lt;ref&gt;{{Cite journal |last=Papageorgiou |first=Anargyros |last2=Traub |first2=Joseph F. |date=2013-08-12 |title=Measures of quantum computing speedup |journal=Physical Review A |volume=88 |issue=2 |pages=022316 |doi=10.1103/PhysRevA.88.022316 |issn=1050-2947 |arxiv=1307.7488|bibcode=2013PhRvA..88b2316P}}&lt;/ref&gt; The term was originally popularized by [[John Preskill]]&lt;ref name=":0" /&gt; but the concept of a quantum computational advantage, specifically for simulating quantum systems, dates back to [[Yuri Manin]]'s (1980)&lt;ref name="manin1980vychislimoe"&gt;{{cite book
  | author=Manin, Yu. I.
  | title=Vychislimoe i nevychislimoe
  | trans-title=Computable and Noncomputable
  | year=1980
  | publisher=Sov.Radio
  | url=http://publ.lib.ru/ARCHIVES/M/MANIN_Yuriy_Ivanovich/Manin_Yu.I._Vychislimoe_i_nevychislimoe.(1980).%5Bdjv%5D.zip
  | pages=13–15
  | language=Russian
  | accessdate=2013-03-04
  | deadurl=yes
  | archiveurl=https://web.archive.org/web/20130510173823/http://publ.lib.ru/ARCHIVES/M/MANIN_Yuriy_Ivanovich/Manin_Yu.I._Vychislimoe_i_nevychislimoe.(1980).%5Bdjv%5D.zip
  | archivedate=2013-05-10
  | df=}}
&lt;/ref&gt;
and [[Richard Feynman]]'s (1981) proposals of quantum computing.&lt;ref&gt;{{Cite journal |last=Feynman |first=Richard P. |date=1982-06-01 |title=Simulating Physics with Computers |journal=International Journal of Theoretical Physics |volume=21 |pages=467–488 |issue=6–7 |doi=10.1007/BF02650179 |issn=0020-7748 |bibcode=1982IJTP...21..467F}}&lt;/ref&gt;

[[Shor's algorithm]] for factoring integers, which runs in polynomial time on a quantum computer, provides such a superpolynomial speedup over the best known classical algorithm.&lt;ref name=":2"&gt;{{Cite journal |last=Shor |first=P. |date=1999-01-01 |title=Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer |url=http://epubs.siam.org/doi/10.1137/S0036144598347011 |journal=SIAM Review |volume=41 |issue=2 |pages=303–332 |doi=10.1137/S0036144598347011 |issn=0036-1445 |bibcode=1999SIAMR..41..303S |arxiv=quant-ph/9508027}}&lt;/ref&gt; Although it is yet to be proved, [[Integer factorization|factoring]] is generally believed to be hard using classical resources. The difficulty of proving what cannot be done with classical computing is a common problem in definitively demonstrating quantum supremacy. It also affects the [[boson sampling]] proposal of [[Scott Aaronson|Aaronson]] and Arkhipov,&lt;ref name=":3"&gt;{{Cite journal |last=Aaronson |first=Scott |last2=Arkhipov |first2=Alex |date=2011 |title=The Computational Complexity of Linear Optics |url=http://doi.acm.org/10.1145/1993636.1993682 |journal=Proceedings of the Forty-third Annual ACM Symposium on Theory of Computing |series=STOC '11 |location=New York, NY, USA |publisher=ACM |pages=333–342 |doi=10.1145/1993636.1993682 |isbn=9781450306911 |arxiv=1011.3245}}&lt;/ref&gt; [[D-Wave Systems|D-Wave's]] specialized frustrated cluster loop problems,&lt;ref&gt;{{cite arxiv |last=King |first=James |last2=Yarkoni |first2=Sheir |last3=Raymond |first3=Jack |last4=Ozfidan |first4=Isil |last5=King |first5=Andrew D. |last6=Nevisi |first6=Mayssam Mohammadi |last7=Hilton |first7=Jeremy P. |last8=McGeoch |first8=Catherine C. |date=2017-01-17 |title=Quantum Annealing amid Local Ruggedness and Global Frustration |eprint=1701.04579 |class=quant-ph}}&lt;/ref&gt; and sampling the output of random [[quantum circuit]]s.&lt;ref name=":1"&gt;{{cite arxiv |last=Aaronson |first=Scott |last2=Chen |first2=Lijie |date=2016-12-18 |title=Complexity-Theoretic Foundations of Quantum Supremacy Experiments |eprint=1612.05903 |class=quant-ph}}&lt;/ref&gt;

Like factoring integers, sampling the output distributions of random quantum circuits is believed to be hard for classical computers based on reasonable complexity assumptions.&lt;ref name=":1" /&gt; [[Google]] previously announced plans to demonstrate quantum supremacy before the end of 2017 by solving this problem with an array of 49 [[Superconducting quantum computing|superconducting qubits]].&lt;ref name=":9"&gt;{{Cite news |url=http://spectrum.ieee.org/computing/hardware/google-plans-to-demonstrate-the-supremacy-of-quantum-computing |title=Google Plans to Demonstrate the Supremacy of Quantum Computing |work=IEEE Spectrum: Technology, Engineering, and Science News |access-date=2018-01-11 }}&lt;/ref&gt; However, as of early January 2018, only Intel has announced such hardware.&lt;ref name=":11"&gt;{{Cite news |url=https://spectrum.ieee.org/tech-talk/computing/hardware/intels-49qubit-chip-aims-for-quantum-supremacy |title=CES 2018: Intel's 49-Qubit Chip Shoots for Quantum Supremacy |work=IEEE Spectrum: Technology, Engineering, and Science News |access-date=2017-07-22 }}&lt;/ref&gt;  In October 2017, IBM demonstrated the simulation of 56 qubits on a conventional supercomputer, increasing the number of [[qubit]]s needed for quantum supremacy.&lt;ref name=":8"&gt;{{cite web |url=https://www.newscientist.com/article/2151032-googles-quantum-computing-plans-threatened-by-ibm-curveball/ |title=Google’s quantum computing plans threatened by IBM curveball |date=October 20, 2017 |accessdate=October 22, 2017}}&lt;/ref&gt; In November of 2018, Google announced a partnership with [[NASA]] that would “analyze results from quantum circuits run on Google quantum processors, and ... provide comparisons with classical simulation to both support Google in validating its hardware and establish a baseline for quantum supremacy.”&lt;ref&gt;{{Cite news|url=https://www.technologyreview.com/s/612381/google-has-enlisted-nasa-to-help-it-prove-quantum-supremacy-within-months/|title=Google has enlisted NASA to help it prove quantum supremacy within months|last=Harris|first=Mark|work=MIT Technology Review|access-date=2018-11-30|language=en}}&lt;/ref&gt;

== Computational complexity ==
{{Main|quantum complexity theory}}
[[Computational complexity theory|Complexity]] arguments concern how the amount of some resource needed to solve a problem scales with the size of the input to that problem. As an extension of classical [[computational complexity theory]], [[quantum complexity theory]] is about what a working, [[Quantum Turing machine|universal quantum computer]] could accomplish without necessarily accounting for the difficulty of building one or dealing with [[Quantum decoherence|decoherence]] and noise.&lt;ref name=":5"&gt;{{Cite book |url=https://link.springer.com/referenceworkentry/10.1007/978-0-387-30440-3_428 |title=Encyclopedia of Complexity and Systems Science |last=Watrous |first=John |date=2009 |publisher=Springer New York |isbn=9780387758886 |editor-last=Meyers |editor-first=Robert A. |pages=7174–7201 |doi=10.1007/978-0-387-30440-3_428}}&lt;/ref&gt; Since [[quantum information]] is a generalization of [[Physical information|classical information]], it is clear that a [[Quantum computing|quantum computer]] can efficiently simulate any [[Algorithm|classical algorithm]].&lt;ref name=":5" /&gt;

[[BQP|Bounded quantum polynomial]] (BQP) is the class of decision problems that can be solved in polynomial time by a [[Quantum Turing machine|universal quantum computer]].&lt;ref&gt;{{cite arxiv |last=Tereza |first=Tusarova |date=2004-09-26 |title=Quantum Complexity Classes |arxiv=cs/0409051}}&lt;/ref&gt; It is related to important classical complexity classes by the hierarchy&lt;math&gt;P\subseteq BPP\subseteq BQP\subseteq PSPACE&lt;/math&gt;.&lt;ref name=":6"&gt;{{Cite journal |last=Vazirani |first=Umesh |title=A Survey of Quantum Complexity Theory |url=https://www.csee.umbc.edu/~lomonaco/ams/lecturenotes/Vazirani.pdf |journal=Proceedings of Symposia in Applied Mathematics}}&lt;/ref&gt; Whether any of these containments is proper is still an open question.&lt;ref name=":6" /&gt;

Contrary to decision problems that require yes or no answers, sampling problems ask for samples from [[probability distribution]]s.&lt;ref name=":7"&gt;{{Cite journal |last=Lund |first=A. P. |last2=Bremner |first2=Michael J. |last3=Ralph |first3=T. C. |date=2017-04-13 |title=Quantum sampling problems, BosonSampling and quantum supremacy |url=https://www.nature.com/articles/s41534-017-0018-2 |journal=Npj Quantum Information |volume=3 |issue=1 |page=15 |doi=10.1038/s41534-017-0018-2 |issn=2056-6387 |bibcode=2017npjQI...3...15L |arxiv=1702.03061}}&lt;/ref&gt; If there is a [[Algorithm|classical algorithm]] that can efficiently sample from the output of an arbitrary [[quantum circuit]], the [[polynomial hierarchy]] would collapse to the third level, which is considered very unlikely.&lt;ref name=":1" /&gt; [[Boson sampling|BosonSampling]] is a more specific proposal, the classical hardness of which depends upon the intractability of calculating the [[Permanent (mathematics)|permanent]] of a large matrix with complex entries, which is a P#-complete problem.&lt;ref&gt;{{Cite book |last=Gard |first=Bryan T. |last2=Motes |first2=Keith R. |last3=Olson |first3=Jonathan P. |last4=Rohde |first4=Peter P. |last5=Dowling |first5=Jonathan P. |date=August 2015 |chapter=An introduction to boson-sampling |title=From Atomic to Mesoscale: the Role of Quantum Coherence in Systems of Various Complexities |publisher=World Scientific |isbn=978-981-4678-70-4 |arxiv=1406.6767 |pages=167–192 |doi=10.1142/9789814678704_0008}}&lt;/ref&gt; The arguments used to reach this conclusion have also been extended to IQP Sampling,&lt;ref&gt;{{Cite journal |last=Bremner |first=Michael J. |last2=Montanaro |first2=Ashley |last3=Shepherd |first3=Dan J. |date=2016-08-18 |title=Average-case complexity versus approximate simulation of commuting quantum computations |journal=Physical Review Letters |volume=117 |issue=8 |page=080501 |doi=10.1103/PhysRevLett.117.080501 |pmid=27588839 |issn=0031-9007 |arxiv=1504.07999 |bibcode=2016PhRvL.117h0501B}}&lt;/ref&gt; where only the conjecture that the average- and worst-case complexities of the problem are the same is needed.&lt;ref name=":7" /&gt;

== Superpolynomial speedups ==
The following [[algorithm]]s provide [[Time complexity|superpolynomial]] speedups over the best known classical algorithms:&lt;ref&gt;{{Cite web |url=http://math.nist.gov/quantum/zoo/ |title=Quantum Algorithm Zoo |last=Jordan |first=Stephen |website=math.nist.gov |access-date=2017-07-29}}&lt;/ref&gt;

=== Shor's algorithm for factoring integers ===
{{Main|Shor's algorithm}}
This algorithm finds the prime factorization of an ''n''-bit integer in &lt;math&gt;\tilde{O} (n^3)&lt;/math&gt; time&lt;ref name=":2" /&gt; whereas the best known classical algorithm requires &lt;math&gt;2^{O(n^{1/3})}&lt;/math&gt;time and the best upper bound for the complexity of this problem is &lt;math&gt;O(2^{n/3+o(1)})&lt;/math&gt;.&lt;ref&gt;{{cite arxiv |last=Rubinstein |first=Michael |date=2006-10-19 |title=The distribution of solutions to xy = N mod a with an application to factoring integers|eprint=math/0610612}}&lt;/ref&gt; It can also provide a speedup for any problem that reduces to [[Integer factorization|integer factoring]], including the membership problem for [[matrix group]]s over [[Field (mathematics)|fields]] of odd order.&lt;ref&gt;{{Cite journal|last=Babai|first=László|last2=Beals|first2=Robert|last3=Seress|first3=Ákos|date=2009|title=Polynomial-time Theory of Matrix Groups |url=http://doi.acm.org/10.1145/1536414.1536425 |journal=Proceedings of the Forty-first Annual ACM Symposium on Theory of Computing |series=STOC '09 |location=New York, NY, USA |publisher=ACM |pages=55–64 |doi=10.1145/1536414.1536425 |isbn=9781605585062}}&lt;/ref&gt;

This [[algorithm]] is important both practically and historically for [[quantum computing]]. It was the first polynomial-time [[quantum algorithm]] proposed for a problem that is believed to be hard for classical computers.&lt;ref name=":2" /&gt; This hardness belief is so strong that the security of today's most common encryption protocol, [[RSA (cryptosystem)|RSA]], is based upon it.&lt;ref&gt;{{Cite journal|last=Rivest|first=R. L.|last2=Shamir|first2=A.|last3=Adleman|first3=L.|date=February 1978|title=A Method for Obtaining Digital Signatures and Public-key Cryptosystems|url=http://doi.acm.org/10.1145/359340.359342|journal=Commun. ACM|volume=21|issue=2|pages=120–126|doi=10.1145/359340.359342|issn=0001-0782}}&lt;/ref&gt; A quantum computer successfully and repeatably running this algorithm has the potential to break this encryption system.&lt;ref&gt;{{Cite book|url=https://www.springer.com/us/book/9783540887010|title=Post-Quantum Cryptography|last=Bernstein|first=Daniel|publisher=Springer|year=|isbn=|location=|pages=|language=en}}&lt;/ref&gt; The need to avoid the imminence of this risk is referred to{{bywhom|date=September 2018}} by the term Y2Q.

=== Boson sampling ===
{{Main|Boson sampling}}
This computing paradigm based upon identical [[photon]]s sent through a [[Linear optical quantum computing|linear-optical network]] can solve certain sampling and search problems that, assuming a few conjectures, are intractable for classical computers.&lt;ref name=":3" /&gt; However, it has been shown that [[Boson sampling|BosonSampling]] in a system with large enough loss and noise can be simulated efficiently.&lt;ref&gt;{{Cite journal|last=Rahimi-Keshari|first=Saleh|last2=Ralph|first2=Timothy C.|last3=Caves|first3=Carlton M.|date=2016-06-20|title=Sufficient Conditions for Efficient Classical Simulation of Quantum Optics|url=https://link.aps.org/doi/10.1103/PhysRevX.6.021039|journal=Physical Review X|volume=6|issue=2|pages=021039|doi=10.1103/PhysRevX.6.021039|bibcode=2016PhRvX...6b1039R|arxiv=1511.06526}}&lt;/ref&gt;

The largest experimental implementation of [[Boson sampling|BosonSampling]] to date had 6 modes so could handle up to 6 photons at a time.&lt;ref&gt;{{Cite journal |last=Carolan |first=Jacques |last2=Harrold |first2=Christopher |last3=Sparrow |first3=Chris |last4=Martín-López |first4=Enrique |last5=Russell |first5=Nicholas J. |last6=Silverstone |first6=Joshua W. |last7=Shadbolt |first7=Peter J. |last8=Matsuda |first8=Nobuyuki |last9=Oguma |first9=Manabu |date=2015-08-14 |title=Universal linear optics |url=http://science.sciencemag.org/content/349/6249/711 |journal=Science |volume=349 |issue=6249 |pages=711–716 |doi=10.1126/science.aab3642 |issn=0036-8075 |pmid=26160375}}&lt;/ref&gt; The best proposed classical [[algorithm]] for simulating [[Boson sampling|BosonSampling]] runs in time &lt;math&gt;O(n2^n+mn^2)&lt;/math&gt; for a system with ''n'' [[photon]]s and ''m'' output modes.&lt;ref name=":10"&gt;{{cite arxiv |last=Clifford |first=Peter |last2=Clifford |first2=Raphaël |date=2017-06-05 |title=The Classical Complexity of Boson Sampling |eprint=1706.01260 |class=cs.DS}}&lt;/ref&gt; [https://CRAN.R-project.org/package=BosonSampling BosonSampling] is an open-source implementation in [[R (programming language)|R]]. The algorithm leads to an estimate of 50 [[photon]]s required to demonstrate quantum supremacy with [[Boson sampling|BosonSampling]].&lt;ref name=":10" /&gt;

=== Sampling the output distribution of random quantum circuits ===
The best known [[algorithm]] for simulating an arbitrary random [[quantum circuit]] requires an amount of time that scales exponentially with the number of [[qubit]]s, leading one group to estimate that around 50 [[qubit]]s could be enough to demonstrate quantum supremacy.&lt;ref name=":4"&gt;{{cite arxiv |last=Boixo |first=Sergio |last2=Isakov |first2=Sergei V. |last3=Smelyanskiy |first3=Vadim N. |last4=Babbush |first4=Ryan |last5=Ding |first5=Nan |last6=Jiang |first6=Zhang |last7=Bremner |first7=Michael J. |last8=Martinis |first8=John M. |last9=Neven |first9=Hartmut |date=2016-07-31 |title=Characterizing Quantum Supremacy in Near-Term Devices |eprint=1608.00263 |class=quant-ph}}&lt;/ref&gt; [[Google]] had announced its intention to demonstrate quantum supremacy by the end of 2017 by constructing and running a 49-[[qubit]] chip that will be able to sample distributions inaccessible to any current classical computers in a reasonable amount of time.&lt;ref name=":9" /&gt; But the largest [[quantum circuit]] simulation completed successfully on a [[supercomputer]] now contains 56 [[qubit]]s.&lt;ref&gt;{{cite arxiv |author1=Edwin Pednault |author2=John A. Gunnels |author3=Giacomo Nannicini |author4=Lior Horesh |author5=Thomas Magerlein |author6=Edgar Solomonik |author7=Robert Wisnieff |date=October 2017 |title=Breaking the 49-Qubit Barrier in the Simulation of Quantum Circuits |eprint=1710.05867 |class=quant-ph}}&lt;/ref&gt; This may require increasing the number of [[qubit]]s to demonstrate quantum supremacy.&lt;ref name=":8" /&gt;

== Skepticism ==
[[Quantum computing|Quantum computers]] are much more susceptible to errors than classical computers due to [[Quantum decoherence|decoherence]] and noise.&lt;ref name="Kalai"&gt;{{cite arxiv |last=Kalai |first=Gil |date=2011-06-02 |title=How Quantum Computers Fail: Quantum Codes, Correlations in Physical Systems, and Noise Accumulation |eprint=1106.0485 |class=quant-ph}}&lt;/ref&gt; The threshold theorem states that a noisy quantum computer can use [[Quantum error correction|quantum error-correcting codes]]&lt;ref&gt;{{Cite journal |last=Shor |first=Peter W. |date=1995-10-01 |title=Scheme for reducing decoherence in quantum computer memory |url=https://link.aps.org/doi/10.1103/PhysRevA.52.R2493 |journal=Physical Review A |volume=52 |issue=4 |pages=R2493–R2496 |doi=10.1103/PhysRevA.52.R2493 |bibcode=1995PhRvA..52.2493S}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last=Steane |first=A. M. |date=1996-07-29 |title=Error Correcting Codes in Quantum Theory |url=https://link.aps.org/doi/10.1103/PhysRevLett.77.793 |journal=Physical Review Letters |volume=77 |issue=5 |pages=793–797 |doi=10.1103/PhysRevLett.77.793 |pmid=10062908 |bibcode=1996PhRvL..77..793S}}&lt;/ref&gt; to simulate a noiseless quantum computer assuming the error introduced in each computer cycle is less than some number.&lt;ref&gt;{{cite arxiv |last=Aharonov |first=Dorit |last2=Ben-Or |first2=Michael |date=1999-06-30 |title=Fault-Tolerant Quantum Computation With Constant Error Rate |eprint=quant-ph/9906129}}&lt;/ref&gt; Numerical simulations suggest that that number may be as high as 3%.&lt;ref&gt;{{Cite journal |last=Knill |first=E. |date=2005-03-03 |title=Quantum computing with realistically noisy devices |url=https://www.nature.com/nature/journal/v434/n7029/full/nature03350.html |journal=Nature |volume=434 |issue=7029 |pages=39–44 |doi=10.1038/nature03350 |pmid=15744292 |issn=0028-0836 |bibcode=2005Natur.434...39K |arxiv=quant-ph/0410199}}&lt;/ref&gt;

However, it is not known how the resources needed for [[Quantum error correction|error correction]] will scale with the number of [[qubit]]s.&lt;ref&gt;{{cite arxiv |last=Kalai |first=Gil |date=2016-05-03|title=The Quantum Computer Puzzle (Expanded Version)|eprint=1605.00992|class=quant-ph}}&lt;/ref&gt; Skeptics point to the unknown behavior of noise in scaled-up quantum systems as potential roadblocks for successfully implementing quantum computing and demonstrating quantum supremacy.&lt;ref&gt;{{Cite book |last=Dyakonov |first=M. I. |chapter=Is Fault-Tolerant Quantum Computation Really Possible? |title=Future Trends in Microelectronics. Up the Nano Creek |editor1=S. Luryi |editor2=J. Xu |editor3=A. Zaslavsky |publisher=Wiley |year=2007 |pages=4–18 |arxiv=quant-ph/0610117 |bibcode=2006quant.ph.10117D}}&lt;/ref&gt;&lt;ref name="Kalai"/&gt;

==See also==
* [[List of quantum processors]]

== References ==
{{reflist}}

[[Category:Quantum computing]]
[[Category:Computational complexity theory]]</text>
      <sha1>r69il0nl2a6kdvzhbk48xcm1eailvy3</sha1>
    </revision>
  </page>
  <page>
    <title>Quotient type</title>
    <ns>0</ns>
    <id>42011185</id>
    <revision>
      <id>667056939</id>
      <parentid>667055589</parentid>
      <timestamp>2015-06-15T15:05:35Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>I've never seen it called a "carrier set" before.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1528">In [[type theory]], a kind of foundation of mathematics, a '''quotient type''' is an [[algebraic data type]] that represents a type whose [[Equality (mathematics)|equality]] relation has been redefined by a given [[equivalence relation]] such that the elements of the type are partitioned into a set of [[equivalence class]]es whose [[cardinality]] is less than or equal to that of the base type. Just as [[product type]]s and [[sum type]]s are analogous to the cartesian product and disjoint sum of abstract algebraic structures, quotient types reflect the concept of set-theoretic [[quotient set|quotient]]s, sets whose elements are surjectively partitioned into equivalence classes by a given equivalence relation on the set. Algebraic structures whose [[underlying set]] is a quotient are also termed quotients. Examples of such quotient structures include quotient [[quotient set|sets]], [[quotient group|groups]], [[quotient ring|rings]], [[quotient category|categories]] and, in topology, [[quotient space (topology)|quotient space]]s. For example, &lt;math&gt;\mathbb{Q}&lt;/math&gt;, the rational numbers, is the quotient ring – or "field of fractions" – of &lt;math&gt;\mathbb{Z}&lt;/math&gt;, the integers.

In type theories that lack quotient types, [[setoid]]s – sets explicitly equipped with an equivalence relation – are often used instead.

== See also ==
* [[Algebraic data type]]
* [[Product type]]
* [[Sum type]]
* [[Setoid]]

{{data types}}

[[Category:Data types]]
[[Category:Type theory]]
[[Category:Composite data types]]</text>
      <sha1>hoau003rziw5ripr4or64kkzo3554ew</sha1>
    </revision>
  </page>
  <page>
    <title>Recreational mathematics</title>
    <ns>0</ns>
    <id>26446</id>
    <revision>
      <id>871172961</id>
      <parentid>871167370</parentid>
      <timestamp>2018-11-29T12:14:00Z</timestamp>
      <contributor>
        <username>PJTraill</username>
        <id>522601</id>
      </contributor>
      <comment>Correct punctuation and reposition reference. John Conway: Mention [[Winning Ways]]. Replace "regarded" by the less tendentious "described".</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10150">{{refimprove|date=January 2013}}

'''Recreational mathematics''' is [[mathematics]] carried out for [[recreation]] (entertainment) rather than as a strictly research and application-based professional activity. Although it is not necessarily limited to being an endeavor for amateurs, many topics in this field require no knowledge of advanced mathematics. Recreational mathematics involves [[mathematical puzzle]]s and [[Mathematical games|games]], often appealing to children and untrained adults, inspiring their further study of the subject.&lt;ref&gt;Kulkarni, D. [http://www.matholympiad.info/Documents/TeachingWithKenKen.pdf Enjoying Math: Learning Problem Solving With KenKen Puzzles] {{webarchive|url=https://web.archive.org/web/20130801080339/http://www.matholympiad.info/Documents/TeachingWithKenKen.pdf |date=2013-08-01 }}, a textbook for teaching with KenKen Puzzles.&lt;/ref&gt;

The [[Mathematical Association of America]] (MAA) includes Recreational Mathematics as one of its seventeen [[Mathematical_Association_of_America#Special_Interest_Groups|Special Interest Groups]], commenting:
:''Recreational mathematics is not easily defined because it is more than mathematics done as a diversion or playing games that involve mathematics. Recreational mathematics is inspired by deep ideas that are hidden in puzzles, games, and other forms of play. The aim of the SIGMAA on Recreational Mathematics (SIGMAA-Rec) is to bring together enthusiasts and researchers in the myriad of topics that fall under recreational math. We will share results and ideas from our work, show that real, deep mathematics is there awaiting those who look, and welcome those who wish to become involved in this branch of mathematics''.&lt;ref&gt;[https://www.maa.org/community/sigmaas Special Interest Groups of the MAA] Mathematical Association of America&lt;/ref&gt;

Mathematical competitions (such as those sponsored by [[Mathematical Association|mathematical association]]s) are also categorized under recreational mathematics.
== Topics ==

Some of the more well-known topics in recreational mathematics are [[Rubik's Cube|Rubik's Cubes]], [[magic squares]], [[fractals]], [[logic puzzle]]s and [[mathematical chess problem]]s, but this area of mathematics includes the [[aesthetics]] and [[culture]] of mathematics, peculiar or amusing stories and [[mathematical coincidence|coincidences about mathematics]], and the personal lives of [[mathematician]]s.

===Mathematical games===
[[Mathematical game|Mathematical games]] are [[multiplayer game]]s whose rules, strategies, and outcomes can be studied and explained using [[mathematics]]. The players of the game may not need to use explicit mathematics in order to play mathematical games. For example, [[Mancala]] is studied in the mathematical field of [[combinatorial game theory]], but no mathematics is necessary in order to play it.

===Mathematical puzzles===
[[Mathematical puzzle|Mathematical puzzles]] require mathematics in order to solve them. They have specific rules, as do [[multiplayer games]], but mathematical puzzles don't usually involve competition between two or more players. Instead, in order to solve such a [[puzzle]], the solver must find a solution that satisfies the given conditions.

[[Logic puzzle]]s and [[classical cipher]]s are common examples of mathematical puzzles. [[Cellular automata]] and [[fractals]] are also considered mathematical puzzles, even though the solver only interacts with them by providing a set of initial conditions.

As they often include or require game-like features or thinking, mathematical puzzles are sometimes also called mathematical games.

===Other activities===
Other curiosities and pastimes of non-trivial mathematical interest include:
* patterns in [[juggling]]
* the sometimes profound algorithmic and geometrical characteristics of [[origami]]
* patterns and process in creating [[string figure]]s such as [[Cat's cradle]]s, etc.
* [[fractal-generating software]]

==Publications==
&lt;!--Linked from [[Mathematical game]]--&gt;

* The journal ''[[Eureka (University of Cambridge magazine)|Eureka]]'' published by the mathematical society of the [[University of Cambridge]] is one of the oldest publications in recreational mathematics. It has been published 60 times since 1939 and authors have included many famous mathematicians and scientists such as [[Martin Gardner]], [[John Horton Conway|John Conway]], [[Roger Penrose]], [[Ian Stewart (mathematician)|Ian Stewart]], [[Timothy Gowers]], [[Stephen Hawking]] and [[Paul Dirac]].
* The ''[[Journal of Recreational Mathematics]]'' was the largest publication on this topic from its founding in 1968 until 2014 when it ceased publication.
* ''[[List of Martin Gardner Mathematical Games columns|Mathematical Games]]'' (1956 to 1981) was the title of a long-running ''[[Scientific American]]'' column on recreational mathematics by [[Martin Gardner]].  He inspired several generations of mathematicians and scientists through his interest in mathematical recreations. "Mathematical Games" was succeeded by 25 "[[Metamagical Themas]]" columns (1981-1983), a similarly distinguished, but shorter-running, column by [[Douglas Hofstadter]], then by 78 "Mathematical Recreations" and "Computer Recreations" columns (1984 to 1991) by [[A. K. Dewdney]], then by 96 "Mathematical Recreations" columns (1991 to 2001) by [[Ian Stewart (mathematician)|Ian Stewart]], and most recently "Puzzling Adventures" by [[Dennis Shasha]].
* The [http://rmm.ludus-opuscula.org/ Recreational Mathematics Magazine], published by the [http://ludicum.org/ Ludus Association], is electronic and semiannual, and focuses on results that provide amusing, witty but nonetheless original and scientifically profound mathematical nuggets. The issues are published in the exact moments of the equinox.

==In popular culture==
* The plot of the 1995 action film ''[[Die Hard with a Vengeance]]'' involves the protagonist’s effort to solve a [[water pouring puzzle|water jug problem]].
* In the episode titled "[[42 (Doctor Who)|42]]" of the ''[[Doctor Who]]''  science fiction television series, the Doctor completes a sequence of [[Happy number#Happy primes|happy primes]]. He then complains that schools no longer teach recreational mathematics.
* ''[[The Curious Incident of the Dog in the Night-Time]]'', a book about a young boy with [[Asperger syndrome]], discusses many mathematical games and puzzles.

== People ==
&lt;!--Linked from [[Mathematical game]]--&gt;

Prominent practitioners and advocates of recreational mathematics have included:

{| class="wikitable sortable" style="white-space:nowrap;"
! Full name || Last name || Born || Died || Nationality
! Description
|-
| [[Lewis Carroll]] (Charles Dodgson) || Carroll || 1832 || 1898 || English
|style="white-space:normal;"| Mathematician, puzzlist, [[Anglican]] [[deacon]] and [[photographer]] best known as the author of ''[[Alice in Wonderland]]'' and ''[[Through the Looking-Glass]]''
|-
| [[Sam Loyd]] || Loyd || 1841 || 1911 || American
|style="white-space:normal;"| [[Chess]] player and [[Chess composer|composer]] and recreational mathematician, described as America's greatest [[puzzlist]]{{by whom|date=March 2017}}
|-
| [[Henry Dudeney]] || Dudeney || 1857 || 1930 || English
|style="white-space:normal;"| [[Civil servant]] described as England's "greatest puzzlist".&lt;ref&gt;{{citation|contribution=Henry Ernest Dudeney: Britain's Greatest Puzzlist|first=Angela|last=Newing|title=The Lighter Side of Mathematics: Proceedings of the Eugène Strens Memorial Conference on Recreational Mathematics and Its History|year=1994|editor1-first=Richard K.|editor1-last=Guy|editor1-link=Richard K. Guy|editor2-first=Robert E.|editor2-last=Woodrow|publisher=Cambridge University Press|isbn= 9780883855164|url=https://books.google.com/books?id=-4W_5ZISxpsC&amp;pg=PA294|pages=294–301}}.&lt;/ref&gt;
|-
| [[Yakov Perelman]] || Perelman || 1882 || 1942 || Russian
|style="white-space:normal;"| Author of many [[popular science]] and [[popular mathematics|mathematics]] books, including ''Mathematics Can Be Fun''
|-
| [[Martin Gardner]] || Gardner || 1914 || 2010 || American
|style="white-space:normal;"| [[Popular mathematics]] and [[Popular science|science]] writer; author of ''Mathematical Games'', a long-running ''[[Scientific American]]'' column
|-
| [[Joseph Madachy]] || Madachy || 1927 || 2014 || American
|style="white-space:normal;"| Long-time editor of ''[[Journal of Recreational Mathematics]]'', author of ''Mathematics on Vacation'' and ''Madachy's Mathematical Recreations'', recreational mathematician and mathematician
|-
| [[Solomon W. Golomb]]{{nbsp|2}} || Golomb || 1932 || 2016 || American
|style="white-space:normal;"| Mathematician and engineer, best known as the inventor of [[polyominoes]]
|-
| [[John Horton Conway]]{{nbsp|2}} || Conway || 1937 || — || English
|style="white-space:normal;"| Mathematician and inventor of [[Conway's Game of Life]], co-author of ''[[Winning Ways]]'', an analysis of many [[mathematical games]]
|-
|}

== See also ==
{{Wikipedia books|Recreational mathematics}}
* [[List of recreational number theory topics]]

== References ==
{{reflist}}

== Further reading ==
* [[W. W. Rouse Ball]] and [[H.S.M. Coxeter]] (1987). ''Mathematical Recreations and Essays'', Thirteenth Edition, Dover. {{isbn|0-486-25357-0}}.
* [[Henry E. Dudeney]] (1967). ''536 Puzzles and Curious Problems. Charles Scribner's sons''. {{isbn|0-684-71755-7}}.
* [[Sam Loyd]] (1959. 2 Vols.). in Martin Gardner: The Mathematical Puzzles of Sam Loyd. Dover. {{OCLC|5720955}}.
* [[Raymond M. Smullyan]] (1991). ''The Lady or the Tiger? And Other Logic Puzzles''. Oxford University Press. {{isbn|0-19-286136-0}}.

==External links==
{{Wiktionary}}

*[http://mathworld.wolfram.com/topics/RecreationalMathematics.html Recreational Mathematics] from [[MathWorld]] at [[Wolfram Research]]
*[https://web.archive.org/web/20020207051215/http://anduin.eldar.org/~problemi/singmast/ecmutil.html The Unreasonable Utility of Recreational Mathematics] by [[David Singmaster]]

{{Areas of mathematics|state=collapsed}}
{{Authority control}}

[[Category:Recreational mathematics| ]]</text>
      <sha1>3o3wk35eek5m2vo7671f6iw9bw3abfy</sha1>
    </revision>
  </page>
  <page>
    <title>Rough number</title>
    <ns>0</ns>
    <id>7375449</id>
    <revision>
      <id>842182588</id>
      <parentid>786531464</parentid>
      <timestamp>2018-05-20T20:05:03Z</timestamp>
      <contributor>
        <ip>83.28.195.109</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1695">A ''k''-'''rough number''', as defined by Finch in 2001 and 2003, is a positive [[integer]] whose [[prime factor]]s are all greater than or equal to ''k''. ''k''-roughness has alternately been defined as requiring all prime factors to strictly exceed ''k''.&lt;ref&gt;p. 130, Naccache and Shparlinski 2009.&lt;/ref&gt;

==Examples (after Finch)==
#Every odd positive integer is 3-rough.
#Every positive integer that is [[congruence relation|congruent]] to 1 or 5 mod 6 is 5-rough.
#Every positive integer is 2-rough, since all its prime factors, being prime numbers, exceed 1.

==See also==
* [[Buchstab function]], used to count rough numbers
* [[Smooth number]]

==Notes==
{{reflist}}

== References ==
* {{MathWorld|title=Rough Number|urlname=RoughNumber}}
* [http://listserv.nodak.edu/cgi-bin/wa.exe?A2=ind0108&amp;L=nmbrthry&amp;P=963 Finch's definition from Number Theory Archives]
* "Divisibility, Smoothness and Cryptographic Applications", D. Naccache and I. E. Shparlinski, pp. 115-173 in ''Algebraic Aspects of Digital Communications'', eds. Tanush Shaska and Engjell Hasimaj, IOS Press, 2009, {{isbn|9781607500193}}.	

The [[On-Line Encyclopedia of Integer Sequences]] (OEIS)
lists ''p''-rough numbers for small ''p'':
* 2-rough numbers: [[OEIS:A000027|A000027]]
* 3-rough numbers: [[OEIS:A005408|A005408]]
* 5-rough numbers: [[OEIS:A007310|A007310]]
* 7-rough numbers: [[OEIS:A007775|A007775]]
* 11-rough numbers: [[OEIS:A008364|A008364]]
* 13-rough numbers: [[OEIS:A008365|A008365]]
* 17-rough numbers: [[OEIS:A008366|A008366]]
* 19-rough numbers: [[OEIS:A166061|A166061]]
* 23-rough numbers: [[OEIS:A166063|A166063]]

{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Integer sequences]]</text>
      <sha1>anbi8g0kng4r45vfwtphg1voqgpp7s1</sha1>
    </revision>
  </page>
  <page>
    <title>Rough set</title>
    <ns>0</ns>
    <id>1634778</id>
    <revision>
      <id>863532827</id>
      <parentid>845419726</parentid>
      <timestamp>2018-10-11T11:24:23Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="48269">In [[computer science]], a '''rough set''', first described by [[Poles|Polish]] computer scientist [[Zdzislaw Pawlak|Zdzisław I. Pawlak]], is a formal approximation of a [[crisp set]] (i.e., conventional set) in terms of a pair of sets which give the ''lower'' and the ''upper'' approximation of the original set. In the standard version of rough set theory (Pawlak 1991), the lower- and upper-approximation sets are crisp sets, but in other variations, the approximating sets may be [[fuzzy sets]].

==Definitions==
The following section contains an overview of the basic framework of rough set theory, as originally proposed by [[Zdzislaw Pawlak|Zdzisław I. Pawlak]], along with some of the key definitions. More formal properties and boundaries of rough sets can be found in Pawlak (1991) and cited references. The initial and basic theory of rough sets is sometimes referred to as ''"Pawlak Rough Sets"'' or ''"classical rough sets"'', as a means to distinguish from more recent extensions and generalizations.

===Information system framework===
Let &lt;math&gt;I = (\mathbb{U},\mathbb{A})&lt;/math&gt; be an information system ([[attribute-value system]]), where &lt;math&gt; \mathbb{U}&lt;/math&gt; is a non-empty, finite set of objects (the universe) and &lt;math&gt; \mathbb{A}&lt;/math&gt; is a non-empty, finite set of attributes such that &lt;math&gt;a:\mathbb{U} \rightarrow V_a&lt;/math&gt; for every &lt;math&gt;a \in \mathbb{A}&lt;/math&gt;. &lt;math&gt;V_a&lt;/math&gt; is the set of values that attribute &lt;math&gt;a&lt;/math&gt; may take. The information table assigns a value &lt;math&gt;a(x)&lt;/math&gt; from &lt;math&gt;V_a&lt;/math&gt; to each attribute &lt;math&gt;a&lt;/math&gt; and object &lt;math&gt;x&lt;/math&gt; in the universe &lt;math&gt;\mathbb{U}&lt;/math&gt;.

With any &lt;math&gt;P \subseteq \mathbb{A}&lt;/math&gt; there is an associated [[equivalence relation]] &lt;math&gt;\mathrm{IND}(P)&lt;/math&gt;:

:&lt;math&gt;
  \mathrm{IND}(P) = \left\{(x,y) \in \mathbb{U}^2 \mid \forall a \in P, a(x)=a(y)\right\}
&lt;/math&gt;

The relation &lt;math&gt;\mathrm{IND}(P)&lt;/math&gt; is called a &lt;math&gt;P&lt;/math&gt;''-indiscernibility relation''. The partition of &lt;math&gt;\mathbb{U}&lt;/math&gt; is a family of all equivalence classes of &lt;math&gt;\mathrm{IND}(P)&lt;/math&gt; and is denoted  by &lt;math&gt;\mathbb{U}/\mathrm{IND}(P)&lt;/math&gt; (or &lt;math&gt;\mathbb{U}/P&lt;/math&gt;).

If &lt;math&gt;(x,y)\in \mathrm{IND}(P)&lt;/math&gt;, then &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are ''indiscernible'' (or indistinguishable) by attributes from &lt;math&gt;P&lt;/math&gt; .

The equivalence classes of the &lt;math&gt;P&lt;/math&gt;-indiscernibility relation are denoted &lt;math&gt;[x]_P&lt;/math&gt;.

===Example: equivalence-class structure===
For example, consider the following information table:

:{| class="wikitable" style="text-align:center; width:30%" border="1"
|+ Sample Information System
! Object !! &lt;math&gt;P_{1}&lt;/math&gt; !! &lt;math&gt;P_{2}&lt;/math&gt; !! &lt;math&gt;P_{3}&lt;/math&gt; !! &lt;math&gt;P_{4}&lt;/math&gt; !! &lt;math&gt;P_{5}&lt;/math&gt;
|-
! &lt;math&gt;O_{1}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{2}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{3}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{4}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 1
|-
! &lt;math&gt;O_{5}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 1
|-
! &lt;math&gt;O_{6}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 2
|-
! &lt;math&gt;O_{7}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{8}&lt;/math&gt;
| 0 || 1 || 2 || 2 || 1
|-
! &lt;math&gt;O_{9}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 2
|-
! &lt;math&gt;O_{10}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|}

When the full set of attributes &lt;math&gt;P = \{P_{1},P_{2},P_{3},P_{4},P_{5}\}&lt;/math&gt; is considered, we see that we have the following seven equivalence classes:

:&lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4}\} \\ 
\{O_{5}\} \\
\{O_{6}\} \\
\{O_{8}\} \\
\{O_{9}\} \end{cases}
&lt;/math&gt;

Thus, the two objects within the first equivalence class, &lt;math&gt;\{O_{1},O_{2}\}&lt;/math&gt;, cannot be distinguished from each other based on the available attributes, and the three objects within the second equivalence class, &lt;math&gt;\{O_{3},O_{7},O_{10}\}&lt;/math&gt;, cannot be distinguished from one another based on the available attributes. The remaining five objects are each discernible from all other objects.

It is apparent that different attribute subset selections will in general lead to different indiscernibility classes. For example, if attribute &lt;math&gt;P =\{ P_{1}\}&lt;/math&gt; alone is selected, we obtain the following, much coarser, equivalence-class structure:

:&lt;math&gt;
\begin{cases}
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{5},O_{7},O_{9},O_{10}\} \\ 
\{O_{4},O_{6},O_{8}\} \end{cases}
&lt;/math&gt;

===Definition of a ''rough set''===
Let &lt;math&gt;X \subseteq \mathbb{U}&lt;/math&gt; be a target set that we wish to represent using attribute subset &lt;math&gt;P&lt;/math&gt;; that is, we are told that an arbitrary set of objects &lt;math&gt;X&lt;/math&gt; comprises a single class, and we wish to express this class (i.e., this subset) using the equivalence classes induced by attribute subset &lt;math&gt;P&lt;/math&gt;. In general, &lt;math&gt;X&lt;/math&gt; cannot be expressed exactly, because the set may include and exclude objects which are indistinguishable on the basis of attributes &lt;math&gt;P&lt;/math&gt;.

For example, consider the target set &lt;math&gt;X = \{O_{1},O_{2},O_{3},O_{4}\}&lt;/math&gt;, and let attribute subset &lt;math&gt;P = \{P_{1}, P_{2}, P_{3}, P_{4}, P_{5}\}&lt;/math&gt;, the full available set of features.  It will be noted that the set &lt;math&gt;X&lt;/math&gt; cannot be expressed exactly, because in &lt;math&gt;[x]_P,&lt;/math&gt;, objects &lt;math&gt;\{O_{3}, O_{7}, O_{10}\}&lt;/math&gt; are indiscernible. Thus, there is no way to represent any set &lt;math&gt;X&lt;/math&gt; which ''includes'' &lt;math&gt;O_{3}&lt;/math&gt; but ''excludes'' objects &lt;math&gt;O_{7}&lt;/math&gt; and &lt;math&gt;O_{10}&lt;/math&gt;.

However, the target set &lt;math&gt;X&lt;/math&gt; can be ''approximated'' using only the information contained within &lt;math&gt;P&lt;/math&gt; by constructing the &lt;math&gt;P&lt;/math&gt;-lower and &lt;math&gt;P&lt;/math&gt;-upper approximations of &lt;math&gt;X&lt;/math&gt;:

:&lt;math&gt;
  {\underline P}X= \{x \mid [x]_P \subseteq X\}
&lt;/math&gt;

:&lt;math&gt;
  {\overline P}X = \{x \mid [x]_P \cap X \neq \emptyset \}
&lt;/math&gt;

====Lower approximation and positive region====
The &lt;math&gt;P&lt;/math&gt;''-lower approximation'', or ''positive region'', is the union of all equivalence classes in &lt;math&gt;[x]_P&lt;/math&gt; which are contained by (i.e., are subsets of) the target set – in the example, &lt;math&gt;{\underline P}X = \{O_{1}, O_{2}\} \cup \{O_{4}\}&lt;/math&gt;, the union of the two equivalence classes in &lt;math&gt;[x]_P&lt;/math&gt; which are contained in the target set. The lower approximation is the complete set of objects in &lt;math&gt;\mathbb{U}/P&lt;/math&gt; that can be ''positively'' (i.e., unambiguously) classified as belonging to target set &lt;math&gt;X&lt;/math&gt;.

====Upper approximation and negative region====
The &lt;math&gt;P&lt;/math&gt;''-upper approximation'' is the union of all equivalence classes in &lt;math&gt;[x]_P&lt;/math&gt; which have non-empty intersection with the target set – in the example, &lt;math&gt;{\overline P}X = \{O_{1}, O_{2}\} \cup \{O_{4}\} \cup \{O_{3}, O_{7}, O_{10}\}&lt;/math&gt;, the union of the three equivalence classes in &lt;math&gt;[x]_P&lt;/math&gt; that have non-empty intersection with the target set. The upper approximation is the complete set of objects that in &lt;math&gt;\mathbb{U}/P&lt;/math&gt; that ''cannot'' be positively (i.e., unambiguously) classified as belonging to the ''complement'' (&lt;math&gt;\overline X&lt;/math&gt;) of the target set &lt;math&gt;X&lt;/math&gt;. In other words, the upper approximation is the complete set of objects that are ''possibly'' members of the  target set &lt;math&gt;X&lt;/math&gt;.

The set &lt;math&gt;\mathbb{U}-{\overline P}X&lt;/math&gt; therefore represents the ''negative region'', containing the set of objects that can be definitely ruled out as members of the target set.

====Boundary region====
The ''boundary region'', given by set difference &lt;math&gt;{\overline P}X - {\underline P}X&lt;/math&gt;, consists of those objects that can neither be ruled in nor ruled out as members of the target set &lt;math&gt;X&lt;/math&gt;.

In summary, the lower approximation of a target set is a ''conservative'' approximation consisting of only those objects which can positively be identified as members of the set. (These objects have no indiscernible "clones" which are excluded by the target set.) The upper approximation is a ''liberal'' approximation which includes all objects that might be members of target set. (Some objects in the upper approximation may not be members of the target set.) From the perspective of &lt;math&gt;\mathbb{U}/P&lt;/math&gt;, the lower approximation contains objects that are members of the target set with certainty (probability = 1), while the upper approximation contains objects that are members of the target set with non-zero probability (probability &gt; 0).

====The rough set====
The tuple &lt;math&gt;\langle{\underline P}X,{\overline P}X\rangle&lt;/math&gt; composed of the lower and upper approximation is called a ''rough set''; thus, a rough set is composed of two crisp sets, one representing a ''lower boundary'' of the target set &lt;math&gt;X&lt;/math&gt;, and the other representing an ''upper boundary'' of the target set &lt;math&gt;X&lt;/math&gt;.

The ''accuracy'' of the rough-set representation of the set &lt;math&gt;X&lt;/math&gt; can be given (Pawlak 1991) by the following:

:&lt;math&gt;
\alpha_{P}(X) = \frac{\left | {\underline P}X \right |} {\left | {\overline P}X \right |} 
&lt;/math&gt;

That is, the accuracy of the rough set representation of &lt;math&gt;X&lt;/math&gt;, &lt;math&gt;\alpha_{P}(X)&lt;/math&gt;, &lt;math&gt;0 \leq \alpha_{P}(X) \leq 1&lt;/math&gt;, is the ratio of the number of objects which can ''positively'' be placed in &lt;math&gt;X&lt;/math&gt; to the number of objects that can ''possibly'' be placed in &lt;math&gt;X&lt;/math&gt; – this provides a measure of how closely the rough set is approximating the target set. Clearly, when the upper and lower approximations are equal (i.e., boundary region empty), then &lt;math&gt;\alpha_{P}(X) = 1&lt;/math&gt;, and the approximation is perfect; at the other extreme, whenever the lower approximation is empty, the accuracy is zero (regardless of the size of the upper approximation).

====Objective analysis====
Rough set theory is one of many methods that can be employed to analyse uncertain (including vague) systems, although less common than more traditional methods of [[probability]], [[statistics]], [[Entropy (information theory)|entropy]] and [[Dempster–Shafer theory]]. However a key difference, and a unique strength, of using classical rough set theory is that it provides an objective form of analysis (Pawlak et al. 1995). Unlike other methods, as those given above, classical rough set analysis requires no additional information, external parameters, models, functions, grades or subjective interpretations to determine set membership – instead it only uses the information presented within the given data (Düntsch and Gediga 1995).  More recent adaptations of rough set theory, such as dominance-based, decision-theoretic and fuzzy rough sets, have introduced more subjectivity to the analysis.

===Definability===
In general, the upper and lower approximations are not equal; in such cases, we say that target set &lt;math&gt;X&lt;/math&gt; is ''undefinable'' or ''roughly definable'' on attribute set &lt;math&gt;P&lt;/math&gt;. When the upper and lower approximations are equal (i.e., the boundary is empty),  &lt;math&gt;{\overline P}X = {\underline P}X&lt;/math&gt;, then the target set &lt;math&gt;X&lt;/math&gt; is ''definable'' on attribute set &lt;math&gt;P&lt;/math&gt;. We can distinguish the following special cases of undefinability:

* Set &lt;math&gt;X&lt;/math&gt; is ''internally'' ''undefinable'' if &lt;math&gt;{\underline P}X = \emptyset&lt;/math&gt; and &lt;math&gt;{\overline P}X \neq \mathbb{U}&lt;/math&gt;.  This means that on attribute set &lt;math&gt;P&lt;/math&gt;, there are ''no'' objects which we can be certain belong to target set &lt;math&gt;X&lt;/math&gt;, but there ''are'' objects which we can definitively exclude from set &lt;math&gt;X&lt;/math&gt;.
* Set &lt;math&gt;X&lt;/math&gt; is ''externally undefinable'' if &lt;math&gt;{\underline P}X \neq \emptyset&lt;/math&gt; and &lt;math&gt;{\overline P}X = \mathbb{U}&lt;/math&gt;.  This means that on attribute set &lt;math&gt;P&lt;/math&gt;, there ''are'' objects which we can be certain belong to target set &lt;math&gt;X&lt;/math&gt;, but there are ''no'' objects which we can definitively exclude from set &lt;math&gt;X&lt;/math&gt;.
* Set &lt;math&gt;X&lt;/math&gt; is ''totally undefinable'' if &lt;math&gt;{\underline P}X = \emptyset&lt;/math&gt; and &lt;math&gt;{\overline P}X = \mathbb{U}&lt;/math&gt;.  This means that on attribute set &lt;math&gt;P&lt;/math&gt;, there are ''no'' objects which we can be certain belong to target set &lt;math&gt;X&lt;/math&gt;, and there are ''no'' objects which we can definitively exclude from set &lt;math&gt;X&lt;/math&gt;.  Thus, on attribute set &lt;math&gt;P&lt;/math&gt;, we cannot decide whether any object is, or is not, a member of &lt;math&gt;X&lt;/math&gt;.

===Reduct and core===
An interesting question is whether there are attributes in the information system (attribute-value table) which are more important to the knowledge represented in the equivalence class structure than other attributes.  Often, we wonder whether there is a subset of attributes which can, by itself, fully characterize the knowledge in the database; such an attribute set is called a ''reduct''.

Formally, a reduct is a subset of attributes &lt;math&gt;\mathrm{RED} \subseteq P&lt;/math&gt; such that

* &lt;math&gt;[x]_{\mathrm{RED}}&lt;/math&gt; = &lt;math&gt;[x]_P&lt;/math&gt;, that is, the equivalence classes induced by the reduced attribute set &lt;math&gt;\mathrm{RED}&lt;/math&gt; are the same as the equivalence class structure induced by the full attribute set &lt;math&gt;P&lt;/math&gt;.
* the attribute set &lt;math&gt;\mathrm{RED}&lt;/math&gt; is ''minimal'', in the sense that &lt;math&gt;[x]_{(\mathrm{RED}-\{a\})} \neq [x]_P&lt;/math&gt; for any attribute &lt;math&gt;a \in \mathrm{RED}&lt;/math&gt;; in other words, no attribute can be removed from set &lt;math&gt;\mathrm{RED}&lt;/math&gt; without changing the equivalence classes &lt;math&gt;[x]_P&lt;/math&gt;.

A reduct can be thought of as a ''sufficient'' set of features – sufficient, that is, to represent the category structure. In the example table above, attribute set &lt;math&gt;\{P_3,P_4,P_5\}&lt;/math&gt; is a reduct – the information system projected on just these attributes possesses the same equivalence class structure as that expressed by the full attribute set:

:&lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4}\} \\ 
\{O_{5}\} \\
\{O_{6}\} \\
\{O_{8}\} \\
\{O_{9}\} \end{cases}
&lt;/math&gt;

Attribute set &lt;math&gt;\{P_3,P_4,P_5\}&lt;/math&gt; is a reduct because eliminating any of these attributes causes a collapse of the equivalence-class structure, with the result that &lt;math&gt;[x]_{\mathrm{RED}} \neq [x]_P&lt;/math&gt;.

The reduct of an information system is ''not unique'': there may be many subsets of attributes which preserve the equivalence-class structure (i.e., the knowledge) expressed in the information system.  In the example information system above, another reduct is &lt;math&gt;\{P_1,P_2,P_5\}&lt;/math&gt;, producing the same equivalence-class structure as &lt;math&gt;[x]_P&lt;/math&gt;.

The set of attributes which is common to all reducts is called the ''core'': the core is the set of attributes which is possessed by ''every'' reduct, and therefore consists of attributes which cannot be removed from the information system without causing collapse of the equivalence-class structure.  The core may be thought of as the set of ''necessary'' attributes – necessary, that is, for the category structure to be represented. In the example, the only such attribute is &lt;math&gt;\{P_5\}&lt;/math&gt;; any one of the other attributes can be removed singly without damaging the equivalence-class structure, and hence these are all ''dispensable''.  However, removing &lt;math&gt;\{P_5\}&lt;/math&gt; by itself ''does'' change the equivalence-class structure, and thus &lt;math&gt;\{P_5\}&lt;/math&gt; is the ''indispensable'' attribute of this information system, and hence the core.

It is possible for the core to be empty, which means that there is no indispensable attribute: any single attribute in such an information system can be deleted without altering the equivalence-class  structure. In such cases, there is no ''essential'' or necessary attribute which is required for the class structure to be represented.

===Attribute dependency===
One of the most important aspects of database analysis or data acquisition is the discovery of attribute dependencies; that is, we wish to discover which variables are strongly related to which other variables. Generally, it is these strong relationships that will warrant further investigation, and that will ultimately be of use in predictive modeling.

In rough set theory, the notion of dependency is defined very simply. Let us take two (disjoint) sets of attributes, set &lt;math&gt;P&lt;/math&gt; and set &lt;math&gt;Q&lt;/math&gt;, and inquire what degree of dependency obtains between them.  Each attribute set induces an (indiscernibility) equivalence class structure, the equivalence classes induced by &lt;math&gt;P&lt;/math&gt; given by &lt;math&gt;[x]_P&lt;/math&gt;, and the equivalence classes induced by &lt;math&gt;Q&lt;/math&gt; given by &lt;math&gt;[x]_Q&lt;/math&gt;.

Let &lt;math&gt;[x]_Q = \{Q_1, Q_2, Q_3, \dots, Q_N \}&lt;/math&gt;, where &lt;math&gt;Q_i&lt;/math&gt; is a given equivalence class from the equivalence-class structure induced by attribute set &lt;math&gt;Q&lt;/math&gt;.  Then, the ''dependency'' of attribute set &lt;math&gt;Q&lt;/math&gt; on attribute set &lt;math&gt;P&lt;/math&gt;, &lt;math&gt;\gamma_{P}(Q)&lt;/math&gt;, is given by

:&lt;math&gt;
\gamma_{P}(Q) =  \frac{\sum_{i=1}^N \left | {\underline P}Q_i \right |} {\left | \mathbb{U} \right |} \leq 1
&lt;/math&gt;

That is, for each equivalence class &lt;math&gt;Q_i&lt;/math&gt; in &lt;math&gt;[x]_Q&lt;/math&gt;, we add up the size of its lower approximation by the attributes in &lt;math&gt;P&lt;/math&gt;, i.e., &lt;math&gt;{\underline P}Q_i&lt;/math&gt;.  This approximation (as above, for arbitrary set &lt;math&gt;X&lt;/math&gt;) is the number of objects which on attribute set &lt;math&gt;P&lt;/math&gt; can be positively identified as belonging to target set &lt;math&gt;Q_i&lt;/math&gt;. Added across all equivalence classes in &lt;math&gt;[x]_Q&lt;/math&gt;, the numerator above represents the total number of objects which – based on attribute set &lt;math&gt;P&lt;/math&gt; – can be positively categorized according to the classification induced by attributes &lt;math&gt;Q&lt;/math&gt;. The dependency ratio therefore expresses the proportion (within the entire universe) of such classifiable objects.  The dependency &lt;math&gt;\gamma_{P}(Q)&lt;/math&gt; "can be interpreted as a proportion of such objects in the information system for which it suffices to know the values of attributes in &lt;math&gt;P&lt;/math&gt; to determine the values of attributes in &lt;math&gt;Q&lt;/math&gt;".

Another, intuitive, way to consider dependency is to take the partition induced by Q as the target class C, and consider P as the attribute set we wish to use in order to "re-construct" the target class C. If P can completely reconstruct C, then Q depends totally upon P; if P results in a poor and perhaps a random reconstruction of C, then Q does not depend upon P at all.

Thus, this measure of dependency expresses the degree of ''functional'' (i.e., deterministic) dependency of attribute set &lt;math&gt;Q&lt;/math&gt; on attribute set &lt;math&gt;P&lt;/math&gt;; it is ''not'' symmetric.  The relationship of this notion of attribute dependency to more traditional information-theoretic (i.e., entropic) notions of attribute dependence has been discussed in a number of sources (e.g., Pawlak, Wong, &amp; Ziarko 1988; Yao &amp; Yao 2002; Wong, Ziarko, &amp; Ye 1986, Quafafou &amp; Boussouf 2000).

==Rule extraction==
The category representations discussed above are all ''extensional'' in nature; that is, a category or complex class is simply the sum of all its members. To represent a category is, then, just to be able to list or identify all the objects belonging to that category.  However, extensional category representations have very limited practical use, because they provide no insight for deciding whether novel (never-before-seen) objects are members of the category.

What is generally desired is an ''intentional'' description of the category, a representation of the category based on a set of ''rules'' that describe the scope of the category.  The choice of such rules is not unique, and therein lies the issue of [[inductive bias]]. See [[Version space]] and [[Model selection]] for more about this issue.

There are a few rule-extraction methods.  We will start from a rule-extraction procedure based on Ziarko &amp; Shan (1995).

===Decision matrices===

Let us say that we wish to find the minimal set of consistent rules ([[logical implication]]s) that characterize our sample system.  For a set of ''condition'' attributes &lt;math&gt;\mathcal{P} = \{P_1, P_2, P_3, \dots , P_n\}&lt;/math&gt; and a decision attribute &lt;math&gt;Q, Q \notin \mathcal{P}&lt;/math&gt;, these rules should have the form &lt;math&gt;P_i^a P_j^b \dots P_k^c \to Q^d&lt;/math&gt;, or, spelled out,

:&lt;math&gt;(P_i=a) \land (P_j=b) \land \dots \land (P_k=c) \to (Q=d)&lt;/math&gt;

where &lt;math&gt;\{a, b, c, \dots\}&lt;/math&gt; are legitimate values from the domains of their respective attributes.  This is a form typical of [[association rules]], and the number of items in &lt;math&gt;\mathbb{U}&lt;/math&gt; which match the condition/antecedent is called the ''support'' for the rule.  The method for extracting such rules given in {{Harvtxt|Ziarko|Shan|1995}} is to form a ''decision matrix'' corresponding to each individual value &lt;math&gt;d&lt;/math&gt; of decision attribute &lt;math&gt;Q&lt;/math&gt;.  Informally, the decision matrix for value &lt;math&gt;d&lt;/math&gt; of decision attribute &lt;math&gt;Q&lt;/math&gt; lists all attribute–value pairs that ''differ'' between objects having &lt;math&gt;Q = d &lt;/math&gt; and &lt;math&gt;Q \ne d&lt;/math&gt;.

This is best explained by example (which also avoids a lot of notation).  Consider the table above, and let &lt;math&gt;P_{4}&lt;/math&gt; be the decision variable (i.e., the variable on the right side of the implications) and let &lt;math&gt;\{P_1,P_2,P_3\}&lt;/math&gt; be the condition variables (on the left side of the implication). We note that the decision variable &lt;math&gt;P_{4}&lt;/math&gt; takes on two different values, namely &lt;math&gt;\{1, 2\}&lt;/math&gt;.  We treat each case separately.

First, we look at the case &lt;math&gt;P_{4}=1&lt;/math&gt;, and we divide up &lt;math&gt;\mathbb{U}&lt;/math&gt; into objects that have &lt;math&gt;P_{4}=1&lt;/math&gt; and those that have &lt;math&gt;P_{4} \ne 1&lt;/math&gt;. (Note that objects with &lt;math&gt;P_{4} \ne 1&lt;/math&gt; in this case are simply the objects that have &lt;math&gt;P_{4}=2&lt;/math&gt;, but in general, &lt;math&gt;P_{4} \ne 1&lt;/math&gt; would include all objects having any value for &lt;math&gt;P_{4}&lt;/math&gt; ''other than'' &lt;math&gt;P_{4}=1&lt;/math&gt;, and there may be several such classes of objects (for example, those having &lt;math&gt;P_{4}=2,3,4,etc.&lt;/math&gt;).)  In this case, the objects having &lt;math&gt;P_{4}=1&lt;/math&gt; are &lt;math&gt;\{O_1,O_2,O_3,O_7,O_{10}\}&lt;/math&gt; while the objects which have &lt;math&gt;P_{4} \ne 1&lt;/math&gt; are &lt;math&gt;\{O_4,O_5,O_6,O_8,O_9\}&lt;/math&gt;.  The decision matrix for &lt;math&gt;P_{4}=1&lt;/math&gt; lists all the differences between the objects having &lt;math&gt;P_{4}=1&lt;/math&gt; and those having &lt;math&gt;P_{4} \ne 1&lt;/math&gt;;  that is, the decision matrix lists all the differences between &lt;math&gt;\{O_1,O_2,O_3,O_7,O_{10}\}&lt;/math&gt; and &lt;math&gt;\{O_4,O_5,O_6,O_8,O_9\}&lt;/math&gt;.  We put the "positive" objects (&lt;math&gt;P_{4}=1&lt;/math&gt;) as the rows, and the "negative" objects &lt;math&gt;P_{4} \ne 1&lt;/math&gt; as the columns.

:{| class="wikitable" style="text-align:center; width:30%" border="1"
|+ Decision matrix for &lt;math&gt;P_{4}=1&lt;/math&gt;
! Object !! &lt;math&gt;O_{4}&lt;/math&gt; !! &lt;math&gt;O_{5}&lt;/math&gt; !! &lt;math&gt;O_{6}&lt;/math&gt; !! &lt;math&gt;O_{8}&lt;/math&gt; !! &lt;math&gt;O_{9}&lt;/math&gt;
|-
! &lt;math&gt;O_{1}&lt;/math&gt;
| &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt;|| &lt;math&gt;P_1^1,P_2^2&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2&lt;/math&gt;  
|-
! &lt;math&gt;O_{2}&lt;/math&gt;
| &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^1,P_2^2&lt;/math&gt;
|-
! &lt;math&gt;O_{3}&lt;/math&gt;
| &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_2^0,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt;
|-
! &lt;math&gt;O_{7}&lt;/math&gt;
| &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_2^0,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt;
|-
! &lt;math&gt;O_{10}&lt;/math&gt;
| &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; || &lt;math&gt;P_1^2,P_2^0,P_3^0&lt;/math&gt; || &lt;math&gt;P_2^0&lt;/math&gt;
|}

To read this decision matrix, look, for example, at the intersection of row &lt;math&gt;O_{3}&lt;/math&gt; and column &lt;math&gt;O_{6}&lt;/math&gt;, showing &lt;math&gt;P_1^2,P_3^0&lt;/math&gt; in the cell.  This means that ''with regard to'' decision value &lt;math&gt;P_{4}=1&lt;/math&gt;, object &lt;math&gt;O_{3}&lt;/math&gt; differs from object &lt;math&gt;O_{6}&lt;/math&gt; on attributes &lt;math&gt;P_1&lt;/math&gt; and &lt;math&gt;P_3&lt;/math&gt;, and the particular values on these attributes for the positive object &lt;math&gt;O_{3}&lt;/math&gt; are &lt;math&gt;P_1=2&lt;/math&gt; and &lt;math&gt;P_3=0&lt;/math&gt;. This tells us that the correct classification of &lt;math&gt;O_{3}&lt;/math&gt; as belonging to decision class &lt;math&gt;P_{4}=1&lt;/math&gt; rests on attributes &lt;math&gt;P_1&lt;/math&gt; and &lt;math&gt;P_3&lt;/math&gt;;  although one or the other might be dispensable, we know that ''at least one'' of these attributes is ''in''dispensable.

Next, from each decision matrix we form a set of [[Boolean logic|Boolean]] expressions, one expression for each row of the matrix. The items within each cell are aggregated disjunctively, and the individuals cells are then aggregated conjunctively. Thus, for the above table we have the following five Boolean expressions:

:&lt;math&gt;
\begin{cases}
(P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2) \\ 
(P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2) \\
(P_1^2 \lor P_3^0) \land (P_2^0) \land (P_1^2 \lor P_3^0) \land (P_1^2 \lor P_2^0 \lor P_3^0) \land (P_2^0) \\
(P_1^2 \lor P_3^0) \land (P_2^0) \land (P_1^2 \lor P_3^0) \land (P_1^2 \lor P_2^0 \lor P_3^0) \land (P_2^0) \\
(P_1^2 \lor P_3^0) \land (P_2^0) \land (P_1^2 \lor P_3^0) \land (P_1^2 \lor P_2^0 \lor P_3^0) \land (P_2^0)
\end{cases}
&lt;/math&gt;

Each statement here is essentially a highly specific (probably ''too'' specific) rule governing the membership in class &lt;math&gt;P_{4}=1&lt;/math&gt;  of the corresponding object. For example, the last statement, corresponding to object &lt;math&gt;O_{10}&lt;/math&gt;, states that all the following must be satisfied: 
# Either &lt;math&gt;P_1&lt;/math&gt; must have value 2, or  &lt;math&gt;P_3&lt;/math&gt; must have value 0, or both.
# &lt;math&gt;P_2&lt;/math&gt; must have value 0.
# Either &lt;math&gt;P_1&lt;/math&gt; must have value 2, or  &lt;math&gt;P_3&lt;/math&gt; must have value 0, or both.
# Either &lt;math&gt;P_1&lt;/math&gt; must have value 2, or &lt;math&gt;P_2&lt;/math&gt; must have value 0, or &lt;math&gt;P_3&lt;/math&gt; must have value 0, or any combination thereof.
# &lt;math&gt;P_2&lt;/math&gt; must have value 0.

It is clear that there is a large amount of redundancy here, and the next step is to simplify using traditional [[Boolean algebra (logic)|Boolean algebra]].  The statement &lt;math&gt;(P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2 \lor P_3^0) \land (P_1^1 \lor P_2^2)&lt;/math&gt;  corresponding to objects &lt;math&gt;\{O_{1},O_{2}\}&lt;/math&gt; simplifies to &lt;math&gt;P_1^1  \lor P_2^2&lt;/math&gt;, which yields the implication

:&lt;math&gt;(P_1=1)  \lor (P_2=2) \to (P_{4}=1)&lt;/math&gt;

Likewise, the statement &lt;math&gt;(P_1^2 \lor P_3^0) \land (P_2^0) \land (P_1^2 \lor P_3^0) \land (P_1^2 \lor P_2^0 \lor P_3^0) \land (P_2^0)&lt;/math&gt; corresponding to objects &lt;math&gt;\{O_{3},O_{7},O_{10}\}&lt;/math&gt; simplifies to &lt;math&gt;P_1^2 P_2^0 \lor P_3^0 P_2^0&lt;/math&gt;.  This gives us the implication

:&lt;math&gt;(P_1=2 \land P_2=0) \lor (P_3=0 \land P_2=0) \to (P_{4}=1)&lt;/math&gt;

The above implications can also be written as the following rule set:

:&lt;math&gt;
\begin{cases}
(P_1=1) \to (P_{4}=1) \\
(P_2=2) \to (P_{4}=1) \\
(P_1=2) \land (P_2=0) \to (P_{4}=1) \\
(P_3=0) \land (P_2=0) \to (P_{4}=1) 
\end{cases}
&lt;/math&gt;

It can be noted that each of the first two rules has a ''support'' of 1 (i.e., the antecedent matches two objects), while each of the last two rules has a support of 2.  To finish writing the rule set for this knowledge system, the same procedure as above (starting with writing a new decision matrix) should be followed for the case of &lt;math&gt;P_{4}=2&lt;/math&gt;, thus yielding a new set of implications for that decision value (i.e., a set of implications with &lt;math&gt;P_{4}=2&lt;/math&gt; as the consequent). In general, the procedure will be repeated for each possible value of the decision variable.

===LERS rule induction system===

The data system LERS (Learning from Examples based on Rough Sets) Grzymala-Busse (1997) may induce rules from inconsistent data, i.e., data with conflicting objects.  Two objects are conflicting when they are characterized by the same values of all attributes, but they belong to different concepts (classes). LERS uses rough set theory to compute lower and upper approximations for concepts involved in conflicts with other concepts.

Rules induced from the lower approximation of the concept ''certainly'' describe the concept, hence such rules are called ''certain''.  On the other hand, rules induced from the upper approximation of the concept describe the concept ''possibly'', so these rules are called ''possible''.  For rule induction LERS uses three algorithms: LEM1, LEM2, and IRIM.

The LEM2 algorithm of LERS is frequently used for rule induction and is used not only in LERS but also in other systems, e.g., in RSES (Bazan et al. (2004).  LEM2 explores the search space of [[attribute-value pair]]s.  Its input data set is a lower or upper approximation of a concept, so its input data set is always consistent.  In general, LEM2 computes a local covering and then converts it into a rule set.  We will quote a few definitions to describe the LEM2 algorithm.

The LEM2 algorithm is based on an idea of an attribute-value pair block.  Let &lt;math&gt;X&lt;/math&gt; be a nonempty lower or upper approximation of a concept represented by a decision-value pair &lt;math&gt;(d, w)&lt;/math&gt;.  Set &lt;math&gt;X&lt;/math&gt; ''depends'' on a set &lt;math&gt;T&lt;/math&gt; of attribute-value pairs &lt;math&gt;t = (a, v)&lt;/math&gt;  if and only if

: &lt;math&gt;\emptyset \neq [T] = \bigcap_{t \in T} [t] \subseteq X.&lt;/math&gt;

Set &lt;math&gt;T&lt;/math&gt; is a ''minimal complex'' of &lt;math&gt;X&lt;/math&gt; if and only if &lt;math&gt;X&lt;/math&gt; depends on &lt;math&gt;T&lt;/math&gt; and no proper subset &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;T&lt;/math&gt; exists such that &lt;math&gt;X&lt;/math&gt; depends on &lt;math&gt;S&lt;/math&gt;.  Let &lt;math&gt;\mathbb{T}&lt;/math&gt; be a nonempty collection of nonempty sets of attribute-value pairs.  Then &lt;math&gt;\mathbb{T}&lt;/math&gt; is a ''local covering'' of &lt;math&gt;X&lt;/math&gt; if and only if the following three conditions are satisfied:

each member &lt;math&gt;T&lt;/math&gt; of &lt;math&gt;\mathbb{T}&lt;/math&gt; is a minimal complex of &lt;math&gt;X&lt;/math&gt;,

: &lt;math&gt;
\bigcup_{t \in \mathbb{T}} [T]  = X, &lt;/math&gt;

: &lt;math&gt;\mathbb{T}&lt;/math&gt; is minimal, i.e., &lt;math&gt;\mathbb{T}&lt;/math&gt; has the smallest possible number of members.

For our sample information system, LEM2 will induce the following rules:

:&lt;math&gt;
\begin{cases}
(P_1, 1) \to (P_4, 1) \\
(P_5, 0) \to (P_4, 1) \\
(P_1, 0) \to (P_4, 2) \\
(P_2, 1) \to (P_4, 2)
\end{cases}
&lt;/math&gt;

Other rule-learning methods can be found, e.g., in Pawlak (1991), Stefanowski (1998), Bazan et al. (2004), etc.

==Incomplete data==

Rough set theory is useful for rule induction from incomplete data sets. Using this approach we can distinguish between three types of missing attribute values: ''lost values'' (the values that were recorded but currently are unavailable), ''attribute-concept values'' (these missing attribute values may be replaced by any attribute value limited to the same concept), and ''"do not care" conditions''  (the original values were irrelevant).  A  ''concept'' (''class'') is a set of all objects classified (or diagnosed) the same way.

Two special data sets with missing attribute values were extensively studied: in the first case, all missing attribute values were lost (Stefanowski and Tsoukias, 2001), in the second case, all missing attribute values were "do not care" conditions (Kryszkiewicz, 1999).

In attribute-concept values interpretation of a missing attribute value, the missing attribute value may be replaced by any value of the attribute domain restricted to the concept to which the object with a missing attribute value belongs (Grzymala-Busse and Grzymala-Busse, 2007).  For example, if for a patient the value of an attribute Temperature is missing, this patient is sick with flu, and all remaining patients sick with flu have values high or very-high for  Temperature when using the interpretation of the missing attribute value as the  attribute-concept value, we will replace the missing attribute value with  high and very-high.  Additionally, the ''characteristic relation'', (see, e.g., Grzymala-Busse and Grzymala-Busse, 2007) enables to process data sets with all three kind of missing attribute values at the same time: lost, "do not care" conditions, and attribute-concept values.

==Applications==
{{Unreferenced section|date=July 2017}}

Rough set methods can be applied as a component of hybrid solutions in [[machine learning]] and [[data mining]]. They have been found to be particularly useful for [[rule induction]] and [[feature selection]] (semantics-preserving dimensionality reduction). Rough set-based data analysis methods have been successfully applied in bioinformatics, economics and finance, medicine, multimedia, web and text mining, signal and image processing, software engineering, robotics, and engineering (e.g. power systems and control engineering). Recently the three regions of rough sets are interpreted as regions of acceptance, rejection and deferment. This leads to three-way decision making approach with the model which can potentially lead to interesting future applications.

==History==

The idea of rough set was proposed by [[Zdzisław Pawlak|Pawlak]] (1981) as a new mathematical tool to deal with vague concepts. Comer, Grzymala-Busse, Iwinski, Nieminen, Novotny, Pawlak, Obtulowicz, and Pomykala have studied algebraic properties of rough sets. Different algebraic semantics have been developed by P. Pagliani, I. Duntsch, M. K. Chakraborty, M. Banerjee and A. Mani; these have been extended to more generalized rough sets by D. Cattaneo and A. Mani, in particular. Rough sets can be used to represent [[ambiguity]], [[vagueness]] and general [[uncertainty]].

==Extensions and generalizations==

Since the development of rough sets, extensions and generalizations have continued to evolve. Initial developments focused on the relationship - both similarities and difference - with [[fuzzy sets]]. While some literature contends these concepts are different, other literature considers that rough sets are a generalization of fuzzy sets - as represented through either fuzzy rough sets or rough fuzzy sets.  Pawlak (1995) considered that fuzzy and rough sets should be treated as being complementary to each other, addressing different aspects of uncertainty and vagueness.

Three notable extensions of classical rough sets are:
* [[Dominance-based rough set approach]] (DRSA) is an extension of rough set theory for [[multi-criteria decision analysis]] (MCDA), introduced by Greco, Matarazzo and Słowiński (2001). The main change in this extension of classical rough sets is the substitution of the indiscernibility relation by a ''dominance'' relation, which permits the formalism to deal with inconsistencies typical in consideration of criteria  and preference-ordered decision classes.
* [[Decision-theoretic rough sets]] (DTRS) is a probabilistic extension of rough set theory introduced by Yao, Wong, and Lingras (1990).  It utilizes a Bayesian decision procedure for minimum risk decision making.  Elements are included into the lower and upper approximations based on whether their conditional probability is above thresholds &lt;math&gt;\textstyle \alpha&lt;/math&gt; and &lt;math&gt;\textstyle \beta&lt;/math&gt;.  These upper and lower thresholds determine region inclusion for elements.  This model is unique and powerful since the thresholds themselves are calculated from a set of six loss functions representing classification risks.
* [[Game-theoretic rough sets]] (GTRS) is a game theory-based extension of rough set that was introduced by Herbert and Yao (2011). It utilizes a game-theoretic environment to optimize certain criteria of rough sets based classification or decision making in order to obtain effective region sizes.

===Rough membership===

Rough sets can be also defined, as a generalisation, by employing a rough membership function instead of objective approximation. The rough membership function expresses a conditional probability that &lt;math&gt;x&lt;/math&gt; belongs to &lt;math&gt;X&lt;/math&gt; given &lt;math&gt;\textstyle \R&lt;/math&gt;. This can be interpreted as a degree that &lt;math&gt;x&lt;/math&gt; belongs to &lt;math&gt;X&lt;/math&gt; in terms of information about &lt;math&gt;x&lt;/math&gt; expressed by &lt;math&gt;\textstyle \R&lt;/math&gt;.

Rough membership primarily differs from the fuzzy membership in that the membership of union and intersection of sets cannot, in general, be computed from their constituent membership as is the case of fuzzy sets. In this, rough membership is a generalization of fuzzy membership. Furthermore, the rough membership function is grounded more in probability than the conventionally held concepts of the fuzzy membership function.

===Other generalizations===
Several generalizations of rough sets have been introduced, studied and applied to solving problems. Here are some of these generalizations:

*rough multisets (Grzymala-Busse, 1987)
*fuzzy rough sets extend the rough set concept through the use of fuzzy equivalence classes(Nakamura, 1988)
*Alpha rough set theory (α-RST) - a generalization of rough set theory that allows approximation using of fuzzy concepts (Quafafou, 2000)
*intuitionistic fuzzy rough sets (Cornelis, De Cock and Kerre, 2003)
*generalized rough fuzzy sets (Feng, 2010)
*rough intuitionistic fuzzy sets (Thomas and Nair, 2011)
*soft rough fuzzy sets and soft fuzzy rough sets (Meng, Zhang and Qin, 2011)
*composite rough sets (Zhang, Li and Chen, 2014)

==See also==
* [[Algebraic semantics (mathematical logic)|Algebraic semantics]]
* [[Alternative set theory]]
* [[Analog computer]]
* [[Description logic]]
* [[Fuzzy logic]]
* [[Fuzzy set theory]]
* [[Granular computing]]
* [[Near sets]]
* [[Rough fuzzy hybridization]]
* [[Soft computing]]
* [[Type-2 fuzzy sets and systems]]
* [[Decision-theoretic rough sets]]* [[Version space]]
* [[Dominance-based rough set approach]]

==References==

*{{cite journal
  | last = Pawlak
  | first = Zdzisław 
  | title = Rough sets
  | journal = International Journal of Parallel Programming
  | volume = 11
  | issue = 5
  | pages = 341–356
  | year = 1982
  | doi = 10.1007/BF01001956}}
*{{cite journal
  | last1 = Bazan  | first1 = Jan 
  | last2 = Szczuka |first2= Marcin
  | last3 = Wojna |first3= Arkadiusz
  | last4 = Wojnarski |first4= Marcin
  | title = On the evolution of rough set exploration system
  | journal = Proceedings of the RSCTC 2004
  | pages = 592–601
  | year = 2004
  | doi = 10.1007/978-3-540-25929-9_73}}
*{{cite journal
  | last1 = Dubois  | first1 = D.
  | last2=Prade |first2= H.
  | title = Rough fuzzy sets and fuzzy rough sets
  | journal = International Journal of General Systems
  | volume = 17
  | pages = 191–209
  | year = 1990
  | doi = 10.1080/03081079008935107
  | issue = 2–3}}
* {{cite journal
  | last1 = Herbert | first1 = J. P.
  | last2=Yao |first2= J. T.
  | title = Game-theoretic Rough Sets
  | journal = Fundamenta Informaticae
  | volume = 108
  | pages = 267–286
  | year = 2011
  | doi = 10.3233/FI-2011-423
  | issue = 3-4}}
*{{cite journal
  | last1 = Greco  | first1 = Salvatore
  | last2 = Matarazzo |first2= Benedetto
  | last3 = Słowiński |first3= Roman
  | title = Rough sets theory for multicriteria decision analysis
  | journal = European Journal of Operational Research
  | volume = 129
  | issue = 1
  | year = 2001
  | pages = 1–47
  | doi = 10.1016/S0377-2217(00)00167-3}}
*{{cite journal
  | last = Grzymala-Busse
  | first = Jerzy
  | title = A new version of the rule induction system LERS
  | journal = Fundamenta Informaticae
  | volume = 31
  | year = 1997
  | pages = 27–39}}
*{{cite journal
  | last1 = Grzymala-Busse |first1= Jerzy
  | last2 = Grzymala-Busse |first2= Witold
  | title = An experimental comparison of three rough set approaches to missing attribute values
  | journal = Transactions on Rough Sets
  | volume = 6
  | year = 2007
  | pages = 31–50
  | doi=10.1007/978-3-540-71200-8_3}}
*{{cite journal
  | last = Kryszkiewicz
  | first = Marzena
  | title = Rules in incomplete systems
  | journal = Information Sciences
  | volume = 113
  | year = 1999
  | pages = 271–292
  | doi = 10.1016/S0020-0255(98)10065-8
  | issue = 3–4}}
* Pawlak, Zdzisław ''Rough Sets'' Research Report PAS 431, Institute of Computer Science, Polish Academy of Sciences (1981)
*{{cite journal
  | last1 = Pawlak | first1 = Zdzisław 
  | last2 = Wong |first2= S. K. M.
  | last3 = Ziarko |first3= Wojciech
  | title = Rough sets: Probabilistic versus deterministic approach
  | journal = International Journal of Man-Machine Studies
  | volume = 29
  | pages = 81–95
  | year = 1988
  | doi = 10.1016/S0020-7373(88)80032-4}}
*{{cite book
  | last = Pawlak
  | first = Zdzisław
  | title = Rough Sets: Theoretical Aspects of Reasoning About Data
  | publisher = Kluwer Academic Publishing
  | year = 1991
  | location = Dordrecht
  | isbn =  0-7923-1472-7}}
*{{cite journal
  | last1 = Slezak  | first1 = Dominik
  | last2 = Wroblewski |first2= Jakub
  | last3 = Eastwood |first3= Victoria
  | last4 = Synak |first4= Piotr
  | title = Brighthouse: an analytic data warehouse for ad-hoc queries
  | journal = Pvldb  |volume=1 |issue=2 | pages = 1337–1345
  | year = 2008
  | url=http://www.vldb.org/pvldb/1/1454174.pdf | doi=10.14778/1454159.1454174}}
*{{cite conference
  | first = Jerzy
  | last = Stefanowski
  | title = On rough set based approaches to induction of decision rules
  | booktitle = Rough Sets in Knowledge Discovery 1: Methodology and Applications
  | pages = 500–529
  | publisher = Physica-Verlag
  | editor    = Polkowski, Lech |editor2=Skowron, Andrzej
  | year = 1998
  | location = Heidelberg}}
*{{cite conference
  | last1 = Stefanowski  | first1 = Jerzy
  | last2=Tsoukias |first2=Alexis
  | title = Incomplete information tables and rough classification
  | journal = Computational Intelligence
  | volume = 17
  | pages = 545–566
  | year = 2001
  | doi=10.1111/0824-7935.00162}}
*{{cite journal
  | last1 = Wong  | first1 = S. K. M.
  | last2 = Ziarko |first2= Wojciech
  | last3 = Ye |first3= R. Li
  | title = Comparison of rough-set and statistical methods in inductive learning
  | journal = International Journal of Man-Machine Studies
  | volume = 24
  | pages = 53–72
  | year = 1986}}
*{{cite conference
  | last1 = Yao  | first1 = J. T.
  | last2 = Yao |first2= Y. Y.
  | title = Induction of classification rules by granular computing
  | booktitle = Proceedings of the Third International Conference on Rough Sets and Current Trends in Computing (TSCTC'02)
  | pages = 331–338
  | publisher = Springer-Verlag
  | year = 2002
  | location = London, UK}}
*{{cite conference
  | first = Wojciech
  | last = Ziarko
  | title = Rough sets as a methodology for data mining
  | booktitle = Rough Sets in Knowledge Discovery 1: Methodology and Applications
  | pages = 554–576
  | publisher = Physica-Verlag
  | year = 1998
  | location = Heidelberg}}
*{{cite conference
  | last1 = Ziarko  | first1 = Wojciech 
  | last2=Shan |first2= Ning
  | title = Discovering attribute relationships, dependencies and rules by using rough sets
  | booktitle = Proceedings of the 28th Annual Hawaii International Conference on System Sciences (HICSS'95)
  | pages = 293–299
  | year = 1995
  | location = Hawaii}}
*{{cite journal
  | last = Pawlak
  | first = Zdzisław 
  | title = Decision rules, Bayes' rule and rough sets
  | journal = New direction in rough sets, data mining, and granular-soft computing
  | pages = 1–9
  | year = 1999}}
*{{cite journal
  | last = Pawlak
  | first = Zdzisław 
  | title = Rough relations, reports
  | journal =Institute of computer science
  | volume = 435}}
*{{cite journal
  | last = Orlowska
  | first = E.
  | title = Reasoning about vague concepts
  | journal = Bulletin of the polish academy of sciences
  | volume = 35
  | pages = 643–652
  | year = 1987}}
*{{cite journal
  | last = Polkowski
  | first = L.
  | title = Rough sets: Mathematical foundations
  | journal = Advances in soft computing
   | year = 2002}}
*{{cite journal
  | last = Skowron
  | first = A.
  | title = Rough sets and vague concepts
  | journal = Fundamenta informaticea
  | pages = 417–431
  | year = 1996}}
*Burgin M. (1990). Theory of Named Sets as a Foundational Basis for Mathematics, In Structures in mathematical theories: Reports of the San Sebastian international symposium, September 25–29, 1990 (http://www.blogg.org/blog-30140-date-2005-10-26.html)
*Burgin, M. (2004). Unified Foundations of Mathematics, Preprint Mathematics LO/0403186, p39.  (electronic edition: https://arxiv.org/ftp/math/papers/0403/0403186.pdf) 
*Burgin, M. (2011), Theory of Named Sets, Mathematics Research Developments, Nova Science Pub Inc, {{isbn|978-1-61122-788-8}}
*Cornelis, C., De Cock, M. and Kerre, E. (2003) Intuitionistic fuzzy rough sets: at the crossroads of imperfect knowledge, Expert Systems, 20:5, pp260–270
*Düntsch, I. and Gediga, G. (1995) Rough Set Dependency Analysis in Evaluation Studies – An Application in the Study of Repeated Heart Attacks. University of Ulster, Informatics Research Reports No. 10
*Feng F. (2010). Generalized Rough Fuzzy Sets Based on Soft Sets, Soft Computing, 14:9, pp 899–911
*Grzymala-Busse, J. (1987). Learning from examples based on rough multisets, in Proceedings of the 2nd International Symposium on Methodologies for Intelligent Systems, pp.&amp;nbsp;325–332. Charlotte, NC, USA, 
*Meng, D., Zhang, X. and Qin, K. (2011). Soft rough fuzzy sets and soft fuzzy rough sets, Computers &amp; Mathematics with Applications, 62:12, pp4635–4645
*Quafafou M. (2000). α-RST: a generalization of rough set theory, Information Sciences, 124:1–4, pp301–316.
*Quafafou M. and Boussouf M. (2000). Generalized rough sets based feature selection. Journal Intelligent Data Analysis, 4:1 pp3 – 17
*Nakamura, A. (1988) Fuzzy rough sets, ‘Notes on Multiple-valued Logic in Japan’, 9:1, pp1–8
*Pawlak, Z., Grzymala-Busse, J., Slowinski, R. Ziarko, W. (1995). Rough Sets. Communications of the ACM, 38:11, pp88–95
*Thomas, K. and Nair, L. (2011). Rough intuitionistic fuzzy sets in a lattice, International Mathematical Forum, 6:27, pp1327–1335
*Zhang J., Li T., Chen H. (2014). Composite rough sets for dynamic data mining, Information Sciences, 257, pp81–100
*Zhang J., Wong J-S, Pan Y, Li T. (2015). A parallel matrix-based method for computing approximations in incomplete information systems, IEEE Transactions on Knowledge and Data Engineering, 27(2): 326-339
*Chen H., Li T., Luo C., Horng S-J., Wang G. (2015). A decision-theoretic rough set approach for dynamic data mining. IEEE Transactions on Fuzzy Systems, 23(6): 1958-1970
*Chen H., Li T., Luo C., Horng S-J., Wang G. (2014). A rough set-based method for updating decision rules on attribute values' coarsening and refining, IEEE Transactions on Knowledge and Data Engineering, 26(12): 2886-2899
*Chen H., Li T.,  Ruan D., Lin J., Hu C, (2013) A rough-set based incremental approach for updating approximations under dynamic maintenance environments. IEEE Transactions on Knowledge and Data Engineering, 25(2): 274-284

== Further reading ==
* Gianpiero Cattaneo and Davide Ciucci, "Heyting Wajsberg Algebras as an Abstract Environment Linking Fuzzy and Rough Sets" in J.J. Alpigini et al. (Eds.): RSCTC 2002, LNAI 2475, pp.&amp;nbsp;77–84, 2002. {{doi|10.1007/3-540-45813-1_10}}

==External links==
* [http://www.roughsets.org The International Rough Set Society]
* [http://eecs.ceas.uc.edu/~mazlack/dbm.w2011/Komorowski.RoughSets.tutor.pdf Rough set tutorial]
* [https://web.archive.org/web/20100328002310/http://www.ghastlyfop.com/blog/2006/01/rough-sets-quick-tutorial.html Rough Sets: A Quick Tutorial]
* [http://logic.mimuw.edu.pl/~rses/ Rough Set Exploration System]
* [http://rsctc2008.cs.uakron.edu/Invited%20Speakers/Presentations/Slezak%20Revised%20RSCTC%20Presentation.ppt Rough Sets in Data Warehousing]

[[Category:Systems of set theory]]
[[Category:Theoretical computer science]]
[[Category:Approximations]]</text>
      <sha1>27nndo989c6171divexsgepkza9mcso</sha1>
    </revision>
  </page>
  <page>
    <title>Running total</title>
    <ns>0</ns>
    <id>24032607</id>
    <revision>
      <id>855615611</id>
      <parentid>855615223</parentid>
      <timestamp>2018-08-19T16:21:14Z</timestamp>
      <contributor>
        <username>DavidBrooks</username>
        <id>55225</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2A02:C7F:602E:CD00:2951:273A:CD9D:DB9A|2A02:C7F:602E:CD00:2951:273A:CD9D:DB9A]] ([[User talk:2A02:C7F:602E:CD00:2951:273A:CD9D:DB9A|talk]]) to last revision by ClueBot NG. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2831">A '''running total''' is the [[summation]] of a sequence of numbers which is updated each time a new number is added to the sequence, by adding the value of the new number to the previous running total. Another term for it is [[Series_(mathematics)#Definition|partial sum]].

The purposes of a running total are twofold. First, it allows the total to be stated at any point in time without having to sum the entire sequence each time. Second, it can save having to record the sequence itself, if the particular numbers are not individually important.

==Method==
Consider the [[sequence (mathematics)|sequence]] &lt; &amp;nbsp; 5 &amp;nbsp; 8 &amp;nbsp; 3 &amp;nbsp; 2 &amp;nbsp; &gt;. What is the total of this sequence?

'''Answer''': 5 + 8 + 3 + 2 = 18. This is arrived at by simple summation of the sequence.

Now we insert the number 6 at the end of the sequence to get &lt; &amp;nbsp; 5 &amp;nbsp; 8 &amp;nbsp; 3 &amp;nbsp; 2 &amp;nbsp; 6 &amp;nbsp; &gt;. What is the total of that sequence?

'''Answer''': 5 + 8 + 3 + 2 + 6 = 24. This is arrived at by simple summation of the sequence. ''But'' if we regarded 18 as the running total, we need only add 6 to 18 to get 24. So, 18 was, and 24 now is, the running total. In fact, we would not even need to know the sequence at all, but simply add 6 to 18 to get the new running total; as each new number is added, we get a new running total.

The same method will also work with subtraction, but in that case it is not strictly speaking a total (which implies summation) but a running difference; not to be confused with a [[Difference operator|delta]]. This is used, for example, when scoring the game of [[darts]]. Similarly one can multiply instead of add to get the running product.

==Use==
While this concept is very simple, it is extremely common in everyday use. For example, most [[cash register]]s display a running total of the purchases so far rung in. By the end of the transaction this will, of course, be the total of all the goods. Similarly, the machine may keep a running total of all transactions made, so that at any point in time the total can be checked against the amount in the till, even though the machine has no memory of past transactions.

Typically many games of all kinds use running totals for scoring; the actual values of past events in the sequence are not important, only the current score, that is to say, the running total.

The [[central processing unit]] of computers for many years had a component called the [[Accumulator (computing)|accumulator]] which, essentially, kept a running total (it "accumulated" the results of individual calculations). This term is largely obsolete with more modern computers. A betting [[accumulator (bet)|accumulator]] is the running product of the outcomes of several bets in sequence.

==See also==
*[[Running average]]
*[[Prefix sum]]

[[Category:Arithmetic]]</text>
      <sha1>o3lk0wvvc7ch2g3ya6xl0kpjfbbdpim</sha1>
    </revision>
  </page>
  <page>
    <title>Star of David theorem</title>
    <ns>0</ns>
    <id>24657893</id>
    <revision>
      <id>785523764</id>
      <parentid>785145768</parentid>
      <timestamp>2017-06-14T00:44:52Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* External links */ now redundant wrt reflist</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3924">[[File:Star-of-david-thm.svg|thumb|The ''Star of David theorem'' (the rows of the Pascal triangle are shown as columns here).]]
&lt;!--[[File:Pascal triangle small.png|thumb|right|300px|Pascal's triangle, rows 0 through 7. The Star of David theorem says, for instance, that if we consider the two numbers above the given number 20, the two numbers beside it, and the two numbers below it, the greatest common divisor of the first, third, and fifth of these in clockwise order (gcd(10,&amp;nbsp;15,&amp;nbsp;35)&amp;nbsp;=&amp;nbsp;5) equals the greatest common divisor of the second, fourth, and sixth of them (gcd(10,&amp;nbsp;35,&amp;nbsp;15)&amp;nbsp;=&amp;nbsp;5). --&gt; &lt;!-- That's a really lousy example because it's the same set of three numbers in both cases. But the only examples in this truncated triangle that avoid that symmetry have gcd=1. Likewise, taking the six numbers surrounding either appearance of&amp;nbsp;15, gcd(5,&amp;nbsp;20,&amp;nbsp;21)&amp;nbsp;=&amp;nbsp;1&amp;nbsp;=&amp;nbsp;gcd(10,&amp;nbsp;35,&amp;nbsp;6).]]--&gt;

The '''Star of David theorem''' is a mathematical result on [[arithmetic]] properties of [[binomial coefficients]].  It was discovered by [[Henry W. Gould]] in 1972.

== Statement ==
The [[greatest common divisor]]s of the binomial coefficients forming each of the two triangles in the [[Star of David]] shape in [[Pascal's triangle]] are equal:

:&lt;math&gt;
\begin{align}
&amp; \gcd\left\{ \binom{n-1}{k-1}, \binom{n}{k+1}, \binom{n+1}{k}\right\} \\[8pt]
= {} &amp; \gcd\left\{ \binom{n-1}{k}, \binom{n}{k-1}, \binom{n+1}{k+1}\right\}. 
\end{align}
&lt;/math&gt;

==Examples==

Rows 8, 9, and 10 of Pascal's triangle are

:{|
|- 
| || || ||1|| ||8|| ||28|| ||56|| ||70|| ||56|| ||28|| ||8|| ||1||
|-
| || ||1|| ||9|| ||36|| ||84|| ||126|| ||126|| ||84|| ||36|| ||9|| ||1||
|-
| ||1|| ||10|| ||45|| ||120|| ||210|| ||252|| ||210|| ||120|| ||45|| ||10|| ||1||
|}

For ''n''=9, ''k''=3 or ''n''=9, ''k''=6, the element 84 is surrounded by, in sequence, the elements 28, 56, 126, 210, 120, 36. Taking alternating values, we have gcd(28, 126, 120) = 2 = gcd(56, 210, 36).

The element 36 is surrounded by the sequence 8, 28, 84, 120, 45, 9, and taking alternating values we have gcd(8, 84, 45) = 1 = gcd(28, 120, 9).

==Generalization==

The above greatest common divisor also equals &lt;math&gt;\gcd \left({n-1 \choose k-2}, {n-1 \choose k-1}, {n-1 \choose k}, {n-1 \choose k+1}\right). &lt;/math&gt;&lt;ref name=Weisstein&gt;Weisstein, Eric W. "Star of David Theorem." From MathWorld--A Wolfram Web Resource. http://mathworld.wolfram.com/StarofDavidTheorem.html&lt;/ref&gt; Thus in the above example for the element 84 (in its rightmost appearance), we also have gcd(70, 56, 28, 8) = 2. This result in turn has further generalizations.

==Related results==

The two sets of three numbers which the Star of David theorem says have equal greatest common divisors also have equal products.&lt;ref name=Weisstein/&gt; So for example, again observing that the element 84 is surrounded by, in sequence, the elements 28, 56, 126, 210, 120, 36, and again taking alternating values, we have 28×126×120 =  2&lt;sup&gt;6&lt;/sup&gt;×3&lt;sup&gt;3&lt;/sup&gt;×5×7&lt;sup&gt;2&lt;/sup&gt; = 56×210×36. This result can be confirmed by writing out each binomial coefficient in factorial form, using &lt;math&gt;{a \choose b}=\frac{a!}{(a-b)!b!}.&lt;/math&gt;

== See also ==
* [[List of factorial and binomial topics]]

== References ==
{{reflist}}
* H. W. Gould, "A New Greatest Common Divisor Property of The Binomial Coefficients", ''[[Fibonacci Quarterly]]'' 10 (1972), 579&amp;ndash;584.
* [http://mathforum.org/wagon/fall07/p1088.html Star of David theorem], from ''MathForum''. 
* [http://threesixty360.wordpress.com/2008/12/21/star-of-david-theorem/ Star of David theorem], blog post.

== External links ==

* [http://demonstrations.wolfram.com/StarOfDavidTheorem/ Demonstration of the Star of David theorem], in ''[[Mathematica]]''. 

[[Category:Theorems in discrete mathematics]]
[[Category:Combinatorics]]
[[Category:Factorial and binomial topics]]</text>
      <sha1>izmu4exg2giqcue5jgrif7olzfezayq</sha1>
    </revision>
  </page>
  <page>
    <title>Tame abstract elementary class</title>
    <ns>0</ns>
    <id>43742835</id>
    <revision>
      <id>862654803</id>
      <parentid>855923173</parentid>
      <timestamp>2018-10-05T20:04:31Z</timestamp>
      <contributor>
        <ip>140.247.39.247</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8558">In [[model theory]], a discipline within the field of [[mathematical logic]], a '''tame abstract elementary class''' is an [[abstract elementary class]] (AEC) which satisfies a locality property for types called tameness. Even though it appears implicitly in earlier work of [[Saharon Shelah|Shelah]], tameness as a property of AEC was first isolated by [[Rami Grossberg|Grossberg]] and VanDieren,&lt;ref&gt;{{harvnb|Grossberg|VanDieren|2006a}}.&lt;/ref&gt; who observed that tame AECs were much easier to handle than general AECs.

== Definition ==

Let ''K'' be an [[abstract elementary class|AEC]] with joint embedding, amalgamation, and no maximal models. Just like in first-order model theory, this implies ''K'' has a universal model-homogeneous monster model &lt;math&gt;\mathfrak{C}&lt;/math&gt;. Working inside &lt;math&gt;\mathfrak{C}&lt;/math&gt;, we can define a semantic notion of [[type (model theory)|types]] by specifying that two elements ''a'' and ''b'' have the same type over some base model &lt;math&gt;M&lt;/math&gt; if there is an [[automorphism]] of the monster model sending ''a'' to ''b'' fixing &lt;math&gt;M&lt;/math&gt; pointwise (note that types can be defined in a similar manner without using a monster model&lt;ref&gt;{{harvnb|Shelah|2009}}, Definition II.1.9.&lt;/ref&gt;). Such types are called '''Galois types'''.

One can ask for such types to be determined by their restriction on a small domain. This gives rise to the notion of tameness:

* An AEC &lt;math&gt;K&lt;/math&gt; is ''tame'' if there exists a cardinal &lt;math&gt;\kappa&lt;/math&gt; such that any two distinct Galois types are already distinct on a submodel of their domain of size &lt;math&gt;\le \kappa&lt;/math&gt;. When we want to emphasize &lt;math&gt;\kappa&lt;/math&gt;, we say &lt;math&gt;K&lt;/math&gt; is &lt;math&gt;\kappa&lt;/math&gt;-tame.

Tame AECs are usually also assumed to satisfy amalgamation.

== Discussion and motivation ==

While (without the existence of [[large cardinal]]s) there are examples of non-tame AECs,&lt;ref&gt;{{harvnb|Baldwin|Shelah|2008}}.&lt;/ref&gt; most of the known natural examples are tame.&lt;ref&gt;See the discussion in the introduction of {{harvnb|Grossberg|VanDieren|2006a}}.&lt;/ref&gt; In addition, the following sufficient conditions for a class to be tame are known:

* '''Tameness is a large cardinal axiom''':&lt;ref&gt;{{harvnb|Boney|2014}}, Theorem 1.3.&lt;/ref&gt; There are class-many almost [[strongly compact cardinal]]s iff any abstract elementary class is tame.
* '''Some tameness follows from categoricity''':&lt;ref&gt;{{harvnb|Shelah|1999}}, Main claim 2.3 (9.2 in the online version).&lt;/ref&gt; If an AEC with amalgamation is categorical in a cardinal &lt;math&gt;\lambda&lt;/math&gt; of high-enough cofinality, then tameness holds for types over saturated models of size less than &lt;math&gt;\lambda&lt;/math&gt;.
* '''Conjecture 1.5 in &lt;ref&gt;{{harvnb|Grossberg|VanDieren|2006b}}.&lt;/ref&gt;''':   If K is categorical in some λ ≥ Hanf(K) then there exists χ &lt; Hanf(K) such that K is χ-tame.

Many results in the model theory of (general) AECs assume weak forms of the [[Generalized continuum hypothesis]] and rely on sophisticated combinatorial set-theoretic arguments.&lt;ref&gt;See for example many of the hard theorems of Shelah's book ({{harvnb|Shelah|2009}}).&lt;/ref&gt; On the other hand, the model theory of tame AECs is much easier to develop, as evidenced by the results presented below.

== Results ==

The following are some important results about tame AECs.

* '''Upward categoricity transfer''':&lt;ref&gt;{{harvnb|Grossberg|VanDieren|2006b}}.&lt;/ref&gt; A &lt;math&gt;\kappa&lt;/math&gt;-tame AEC with amalgamation that is categorical in some [[successor cardinal|successor]] &lt;math&gt;\lambda \ge \operatorname{LS}(K)^{++} + \kappa^+&lt;/math&gt; (i.e. has exactly one model of size &lt;math&gt;\lambda&lt;/math&gt; up to isomorphism) is categorical in ''all'' &lt;math&gt;\mu \ge \lambda&lt;/math&gt;.
* '''Upward stability transfer''':&lt;ref&gt;See {{harvnb|Baldwin|Kueker|VanDieren|2006}}, Theorem 4.5 for the first result and {{harvnb|Grossberg|VanDieren|2006a}} for the second.&lt;/ref&gt; A &lt;math&gt;\kappa&lt;/math&gt;-tame AEC with amalgamation that is [[stable]] in a cardinal &lt;math&gt;\lambda \ge \kappa&lt;/math&gt; is stable in &lt;math&gt;\lambda^+&lt;/math&gt; and in every infinite &lt;math&gt;\mu&lt;/math&gt; such that &lt;math&gt;\mu^\lambda = \mu&lt;/math&gt;.
* '''Tameness can be seen as a topological separation principle''':&lt;ref&gt;{{harvnb|Lieberman|2011}}, Proposition 4.1.&lt;/ref&gt; An AEC with amalgamation is tame if and only if an appropriate [[Topological space|topology]] on the set of Galois types is [[Hausdorff space|Hausdorff]].
* '''Tameness and categoricity imply there is a forking notion''':&lt;ref&gt;See {{harvnb|Vasey|2014}} for the first result, and {{harvnb|Boney|Vasey|2014}}, Corollary 6.10.5 for the result on dimension.&lt;/ref&gt; A &lt;math&gt;\kappa&lt;/math&gt;-tame AEC with amalgamation that is categorical in a cardinal &lt;math&gt;\lambda&lt;/math&gt; of [[cofinality]] greater than or equal to &lt;math&gt;\kappa&lt;/math&gt; has a good frame: a forking-like notion for types of singletons (in particular, it is [[stable]] in all cardinals). This gives rise to a well-behaved notion of [[dimension]].

==Notes==

{{Reflist}}

==References==

*{{Citation | last1=Shelah | first1=Saharon | author1-link=Saharon Shelah | title=Categoricity for abstract classes with amalgamation | journal= Annals of Pure and Applied Logic | pages=261–294 | volume=98 | number=1 | year=1999 | url=http://shelah.logic.at/files/394.pdf | doi=10.1016/s0168-0072(98)00016-5}}
*{{citation
 | last = Grossberg | first = Rami
 | contribution = Classification theory for abstract elementary classes
 | contribution-url = https://www.math.cmu.edu/~rami/Rami-NBilgi.pdf
 | doi = 10.1090/conm/302/05080
 | mr = 1928390
 | pages = 165–204
 | publisher = American Mathematical Society | location = Providence, RI
 | series = Contemporary Mathematics
 | title = Logic and algebra
 | volume = 302
 | year = 2002}}
*{{Citation | last1=Grossberg | first1=Rami | last2=VanDieren | first2=Monica | author1-link=Rami Grossberg | title=Galois-stability for tame abstract elementary classes | journal=Journal of Mathematical Logic | pages=25–49 | volume=6  |number=1 | year=2006a | url=http://www.math.cmu.edu/~rami/tame.pdf | doi=10.1142/s0219061306000487| arxiv=math/0509535 }}
*{{Citation | last1=Grossberg | first1=Rami | last2=VanDieren | first2=Monica | author1-link=Rami Grossberg | title=Categoricity from one successor cardinal in tame abstract elementary classes | journal=Journal of Mathematical Logic | pages=181–201 | volume=6 | year=2006b | url=http://www.math.cmu.edu/rami/Onesucc.pdf | doi=10.1142/s0219061306000554 | arxiv=math/0510004 }}{{Dead link|date=June 2018 |bot=InternetArchiveBot |fix-attempted=no }}
*{{Citation | last1=Baldwin | first1=John T. | last2=Kueker | first2=David | last3=VanDieren | first3=Monica | title=Upward stability transfer for tame abstract elementary classes| journal=Notre Dame Journal of Formal Logic | pages=291–298 | volume=47 | number=2 | year=2006 | url=http://www.math.uic.edu/~jbaldwin/pub/bkv_02_23_04.pdf | doi=10.1305/ndjfl/1153858652}}
*{{Citation | last1=Baldwin | first1=John T. | last2=Shelah | first2=Saharon | title=Examples of non-locality | journal=The Journal of Symbolic Logic | pages=765–782 | volume=73  | year=2008 | url=http://shelah.logic.at/files/862.pdf | doi=10.2178/jsl/1230396746}}
*{{Citation | last1=Shelah | first1=Saharon | author1-link=Saharon Shelah | title=Classification theory for elementary abstract classes | publisher=College Publications, London | series=Studies in Logic (London) | isbn=978-1-904987-71-0 | year=2009 | volume=18}}
* {{Citation | last1=Baldwin | first1=John T. | title=Categoricity | publisher=American Mathematical Society | series=University Lecture Series | volume=50 | year=2009 | isbn=978-0821848937 | url=http://homepages.math.uic.edu/~jbaldwin/model11.html}}
* {{Citation | last1=Lieberman | first1=Michael J. | title=A topology for Galois types in abstract elementary classes | journal=Mathematical Logic Quarterly | volume=57 | number=2 | pages=204–216 | year=2011 | doi=10.1002/malq.200910132}}
*{{Cite arXiv | last1=Boney | first1=Will | title=Tameness from large cardinal axioms | arxiv=1303.0550v4 | year=2014 | ref=harv}}
*Boney, Will; Unger Spencer (2015), "Large Cardinal Axioms from Tameness in AECs" arXiv:1509.01191v2.
*{{Cite arXiv | last1=Vasey | first1=Sebastien | title=Forking and superstability in tame AECs | arxiv=1405.7443v2 | year=2014 | ref=harv}}
*{{Cite arXiv | last1=Boney | first1=Will | last2=Vasey | first2=Sebastien | title=Tameness and frames revisited | arxiv=1406.5980v4 | year=2014 | ref=harv}}

{{DEFAULTSORT:Abstract elementary class}}
[[Category:Model theory]]
[[Category:Category theory]]</text>
      <sha1>f9o8l1o5dy7zr50cp0cr5x7c9auq1jl</sha1>
    </revision>
  </page>
  <page>
    <title>Titanic prime</title>
    <ns>0</ns>
    <id>1009505</id>
    <revision>
      <id>753748824</id>
      <parentid>753741878</parentid>
      <timestamp>2016-12-08T23:26:30Z</timestamp>
      <contributor>
        <username>PrimeHunter</username>
        <id>551300</id>
      </contributor>
      <comment>Undid revision 753741878 by WurmWoode. Looks bad to me and probably worse to users with screen readers. No reason to place a simple list of numbers in a table with a "random" width, and prevents easy copy-pasting of the list, e.g for OEIS verification</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1946">{{refimprove|date=August 2012}}
'''Titanic prime''' is a term coined by [[Samuel Yates]] in the 1980s, denoting a [[prime number]] of at least 1000 decimal digits. Few such primes were known then, but the required size is trivial for modern computers.&lt;ref&gt;{{MathWorld|urlname=TitanicPrime|title=Titanic Prime}}&lt;/ref&gt; 

The first 30 titanic primes are of the form:

:&lt;math&gt;p = 10^{999} + n,&lt;/math&gt;

for ''n'' one of 7, 663, 2121, 2593, 3561, 4717, 5863, 9459, 11239, 14397, 17289, 18919, 19411, 21667, 25561, 26739, 27759, 28047, 28437, 28989, 35031, 41037, 41409, 41451, 43047, 43269, 43383, 50407, 51043, 52507 {{OEIS|id=A074282}}.

Apart from the early ''n'' = 7, these values are not far from the expectation based on the [[prime number theorem]].

The first discovered titanic primes were the [[Mersenne prime]]s 2&lt;sup&gt;4253&lt;/sup&gt;&amp;minus;1 (with 1281 digits), and 2&lt;sup&gt;4423&lt;/sup&gt;&amp;minus;1 (with 1332 digits). They were both found November 3, 1961, by [[Alexander Hurwitz]]. It is a matter of definition which one was discovered first, since the primality of 2&lt;sup&gt;4253&lt;/sup&gt;&amp;minus;1 was computed first, but Hurwitz saw the computer output about 2&lt;sup&gt;4423&lt;/sup&gt;&amp;minus;1 first.&lt;ref&gt;[http://primes.utm.edu/notes/by_year.html The Largest Known Prime by Year: A Brief History] from the [[Prime Pages]], at the [[University of Tennessee at Martin]]&lt;/ref&gt;

Samuel Yates called those who proved the primality of a titanic prime "titans".

==See also==
* [[Gigantic prime]] – at least 10,000 digits
* [[Megaprime]] – at least a million digits

==References==
&lt;references/&gt;

==External links==
* Chris Caldwell, [http://primes.utm.edu/largest.html ''The Largest Known Primes''] and "[http://primes.utm.edu/lists/SmallestTitanics.html Smallest Titanics of Special Forms]" at The [[Prime Pages]].

{{Prime number classes}}
{{Large numbers}}
[[Category:Prime numbers]]
[[Category:Large integers]]

{{Num-stub}}

[[fr:Nombre premier#Jalons symboliques]]</text>
      <sha1>8d6m07k2fykl60izj6o9b7d3ai9fhcg</sha1>
    </revision>
  </page>
  <page>
    <title>Truncated tetrahedron</title>
    <ns>0</ns>
    <id>279651</id>
    <revision>
      <id>854304978</id>
      <parentid>833812921</parentid>
      <timestamp>2018-08-10T10:46:05Z</timestamp>
      <contributor>
        <username>Neurowiki</username>
        <id>1362161</id>
      </contributor>
      <minor/>
      <comment>/* Friauf polyhedron */ Its --&gt; It is</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11283">{{Semireg polyhedra db|Semireg polyhedron stat table|tT}}
In [[geometry]], the '''truncated tetrahedron''' is an [[Archimedean solid]]. It has 4 regular [[hexagon]]al faces, 4 [[equilateral triangle]] faces, 12 vertices and 18 edges (of two types). It can be constructed by [[truncation (geometry)|truncating]] all 4 vertices of a regular [[tetrahedron]] at one third of the original edge length.

A deeper truncation, removing a tetrahedron of half the original edge length from each vertex, is called [[Rectification (geometry)|rectification]]. The rectification of a tetrahedron produces an [[octahedron]].&lt;ref&gt;{{cite web |url=https://theory.org/geotopo/tt/html/truncatering.html |title=Truncated Trickery: Truncatering |first=Matt |last=Chisholm |first2=Jeremy |last2=Avnet |work=theory.org |year=1997 |accessdate=2013-09-02}}&lt;/ref&gt;

A ''truncated tetrahedron'' is the [[Goldberg polyhedron]] G&lt;sub&gt;III&lt;/sub&gt;(1,1), containing triangular and hexagonal faces.

A ''truncated tetrahedron'' can be called a '''cantic cube''', with [[Coxeter diagram]], {{CDD|node_h1|4|node|3|node_1}}, having half of the vertices of the cantellated cube ([[rhombicuboctahedron]]), {{CDD|node_1|4|node|3|node_1}}. There are two dual positions of this construction, and combining them creates the uniform [[compound of two truncated tetrahedra]].

==Area and volume==
The area ''A'' and the [[volume]] ''V'' of a truncated tetrahedron of edge length ''a'' are:
:&lt;math&gt;\begin{align}
A &amp;= 7\sqrt{3}a^2 &amp;&amp;\approx 12.124\,355\,65a^2 \\
V &amp;= \tfrac{23}{12}\sqrt{2}a^3 &amp;&amp;\approx 2.710\,575\,995a^3. \end{align}&lt;/math&gt;

==Densest Packing==
The densest packing of the Archimedean truncated tetrahedron is believed to be Φ&amp;nbsp;=&amp;nbsp;{{sfrac|207|208}}, as reported by two independent groups using [[Monte Carlo methods]].&lt;ref name="Damasceno"&gt;{{Cite journal| arxiv=1109.1323| title=Crystalline Assemblies and Densest Packings of a Family of Truncated Tetrahedra and the Role of Directional Entropic Forces | journal=ACS Nano | volume=6 | issue=2012 | pages=609–614 | date= Dec 2011| last1= Damasceno | first1=Pablo F. | last2=Engel | first2=Michael | last3= Glotzer | first3=Sharon C. | doi=10.1021/nn204012y | pmid=22098586}}&lt;/ref&gt;&lt;ref name="Jiao"&gt;{{cite arXiv | eprint=1107.2300| title=A Packing of Truncated Tetrahedra that Nearly Fills All of Space | date= Sep 2011| last1=Jiao | first1=Yang | last2=Torquato | first2=Sal | class=cond-mat.soft }}&lt;/ref&gt; Although no mathematical proof exists that this is the best possible packing for the truncated tetrahedron, the high proximity to the unity and independency of the findings make it unlikely that an even denser packing is to be found. In fact, if the truncation of the corners is slightly smaller than that of an Archimedean truncated tetrahedron, this new shape can be used to completely fill space.&lt;ref name="Damasceno" /&gt;

==Cartesian coordinates==
[[Cartesian coordinates]] for the 12 vertices of a [[Truncation (geometry)|truncated]] [[tetrahedron]] centered at the origin, with edge length √8, are all permutations of (±1,±1,±3) with an even number of minus signs:
*(+3,+1,+1), (+1,+3,+1), (+1,+1,+3)
*(−3,−1,+1), (−1,−3,+1), (−1,−1,+3)
*(−3,+1,−1), (−1,+3,−1), (−1,+1,−3)
*(+3,−1,−1), (+1,−3,−1), (+1,−1,−3)

{|class=wikitable width=600
|- valign=top
|[[File:Truncated_tetrahedron_in_unit_cube.png|200px]]
|[[File:Triangulated truncated tetrahedron.png|200px]]
|[[Image:UC54-2 truncated tetrahedra.png|200px]]
|- valign=top
|[[Orthogonal projection]] showing Cartesian coordinates inside it [[bounding box]]: (±3,±3,±3).
|The hexagonal faces of the truncated tetrahedra can be divided into 6 coplanar equilateral triangles. The 4 new vertices have Cartesian coordinates:&lt;BR&gt; (−1,−1,−1), (−1,+1,+1),&lt;BR&gt;(+1,−1,+1), (+1,+1,−1). As solid this can represent a 3D [[dissection problem|dissection]] making 4 red octahedra and 6 yellow tetrahedra.
|The set of vertex permutations (±1,±1,±3) with an odd number of minus signs forms a complementary truncated tetrahedron, and combined they form a [[Compound polyhedron#Uniform compounds|uniform compound polyhedron]].
|}

Another simple construction exists in 4-space as cells of the [[truncated 16-cell]], with vertices as coordinate permutation of:
:(0,0,1,2)

== Orthogonal projection ==
{| class=wikitable
|+ [[Orthogonal projection]]
!Centered by
!Edge normal
!Face normal
!Edge
!Face
|- align=center
!Wireframe
|[[File:Polyhedron truncated 4a from redyellow max.png|100px]]
|
|[[File:Polyhedron truncated 4a from blue max.png|100px]]
|[[File:Polyhedron truncated 4a from red max.png|100px]] [[File:Polyhedron truncated 4a from yellow max.png|100px]]
|- align=center
!Wireframe
|[[File:tetrahedron t01 ae.png|100px]]
|[[File:tetrahedron t01 af36.png|100px]]
|[[File:3-simplex t01.svg|100px]]
|[[File:3-simplex t01 A2.svg|100px]]
|- align=center
!Dual
|[[File:Dual tetrahedron t01 ae.png|100px]]
|[[File:Dual tetrahedron t01 af36.png|100px]]
|[[File:Dual tetrahedron t01.png|100px]]
|[[File:Dual tetrahedron t01 A2.png|100px]]
|- align=center
|- align=center
!Projective&lt;BR&gt;symmetry
![1]
![1]
![4]
![3]
|}

==Spherical tiling==
The truncated tetrahedron can also be represented as a [[spherical tiling]], and projected onto the plane via a [[stereographic projection]]. This projection is [[Conformal map|conformal]], preserving angles but not areas or lengths. Straight lines on the sphere are projected as circular arcs on the plane.
{|class=wikitable
|- align=center valign=top
|[[File:Uniform_tiling_332-t12.png|160px]]
|[[Image:truncated tetrahedron stereographic projection triangle.png|160px]]&lt;br&gt;[[triangle]]-centered
|[[Image:truncated tetrahedron stereographic projection hexagon.png|160px]]&lt;br&gt;[[hexagon]]-centered
|-
![[Orthographic projection]]
!colspan=3|[[Stereographic projection]]s
|}

=== Friauf polyhedron ===
A lower symmetry version of the truncated tetrahedron (a truncated [[tetragonal disphenoid]] with order 8 D&lt;sub&gt;2d&lt;/sub&gt; symmetry) is called a Friauf polyhedron in crystals such as [[complex metallic alloys]]. This form fits 5 Friauf polyhedra around an axis, giving a 72-degree [[dihedral angle]] on a subset of 6-6 edges.&lt;ref&gt;http://met.iisc.ernet.in/~lord/webfiles/clusters/polyclusters.pdf&lt;/ref&gt; It is named after [[J. B. Friauf]] and his 1927 paper "The crystal structure of the intermetallic compound MgCu&lt;sub&gt;2&lt;/sub&gt;".&lt;ref&gt;{{cite journal|last=Friauf|first=J. B.|title=The crystal structure of the intermetallic compound MgCu&lt;sub&gt;2&lt;/sub&gt;|date=1927|journal=[[J. Am. Chem. Soc.]]|volume=49|pages=3107–3114|doi=10.1021/ja01411a017}}&lt;/ref&gt;

==Uses==
Giant truncated tetrahedra were used for the "Man the Explorer" and "Man the Producer" theme pavilions in [[Expo 67]]. They were made of massive girders of steel bolted together in a geometric lattice. The truncated tetrahedra were interconnected with lattice steel platforms. All of these buildings were demolished after the end of Expo 67, as they had not been built to withstand the severity of the Montreal weather over the years. Their only remnants are in the Montreal city archives, the Public Archives Of Canada and the photo collections of tourists of the times.&lt;ref&gt;http://expo67.ncf.ca/man_the_producer_p1.html&lt;/ref&gt;

The [[Tetraminx]] puzzle has a truncated tetrahedral shape. This puzzle shows a [[Dissection problem|dissection]] of a truncated tetrahedron into 4 [[octahedra]] and 6 [[tetrahedra]]. It contains 4 central planes of rotations.
:[[File:Tetraminx.jpg|160px]]

==Truncated tetrahedral graph==
{{Infobox graph
 | name = Truncated tetrahedral graph
 | image = [[File:Tuncated_tetrahedral_graph.png|240px]]
 | image_caption = 3-fold symmetry
 | namesake = 
 | vertices = 12&lt;ref name=ag&gt;An Atlas of Graphs, page=172, C105&lt;/ref&gt;
 | edges = 18 
 | automorphisms = 24 ([[Symmetric group|S&lt;sub&gt;4&lt;/sub&gt;]])&lt;ref name=ag/&gt;
 | radius = 3
 | diameter = 3&lt;ref name=ag/&gt;
 | girth = 3&lt;ref name=ag/&gt;
 | chromatic_number = 3&lt;ref name=ag/&gt;
 | chromatic_index = 3&lt;ref name=ag/&gt;
 | fractional_chromatic_index = 
 | properties = [[Hamiltonian graph|Hamiltonian]], [[regular graph|regular]], [[K-vertex-connected graph|3-vertex-connected]], [[planar graph]]
}}
In the [[mathematics|mathematical]] field of [[graph theory]], a '''truncated tetrahedral graph''' is a [[Archimedean graph]], the [[1-skeleton|graph of vertices and edges]] of the truncated tetrahedron, one of the [[Archimedean solid]]s. It has 12 [[Vertex (graph theory)|vertices]] and 18 edges.&lt;ref&gt;An Atlas of Graphs, page 267, truncated tetrahedral graph&lt;/ref&gt; It is a connected cubic graph,&lt;ref&gt;An Atlas of Graphs, page 130, connected cubic graphs, 12 vertices, C105&lt;/ref&gt; and connected cubic transitive graph.&lt;ref&gt;An Atlas of Graphs, page 161, connected cubic transitive graphs, 12 vertices, Ct11&lt;/ref&gt;

{| class=wikitable
!Circular
!colspan=2|Orthographic projections
|- align=center valign=top
|[[File:Truncated tetrahedral graph.circo.svg|160px]]
|[[File:3-simplex t01.svg|160px]]&lt;BR&gt;4-fold symmetry
|[[File:3-simplex t01 A2.svg|160px]]&lt;BR&gt;3-fold symmetry
|}
{{Clear}}

==Related polyhedra and tilings==

{{Tetrahedron family}}

It is also a part of a sequence of cantic polyhedra and tilings with [[vertex configuration]] 3.6.''n''.6. In this [[wythoff construction]] the edges between the hexagons represent degenerate [[digon]]s.
{{Cantic small table}}

=== Symmetry mutations===
This polyhedron is topologically related as a part of sequence of uniform [[Truncation (geometry)|truncated]] polyhedra with [[vertex configuration]]s (3.2''n''.2''n''), and [''n'',3] [[Coxeter group]] symmetry.

{{Truncated figure1 small table}}

== Examples ==
&lt;gallery class="center"&gt;
File:Truncatedtetrahedron.gif|Truncated tetrahedron in rotation
File:Tetraedro truncado (Matemateca IME-USP).jpg|Truncated tetrahedron ([[Matemateca IME-USP]])
&lt;/gallery&gt;


==See also==
*[[Quarter cubic honeycomb]] – Fills space using truncated tetrahedra and smaller tetrahedra
*[[Truncated 5-cell]] – Similar uniform polytope in 4-dimensions
*[[Truncated triakis tetrahedron]]
*[[Triakis truncated tetrahedron]]
*[[Octahedron]] – a rectified tetrahedron

==References==
&lt;references/&gt;
*{{The Geometrical Foundation of Natural Structure (book)}} (Section 3-9)
*{{citation|last1=Read|first1=R. C.|last2=Wilson|first2=R. J.|title=An Atlas of Graphs|publisher=Oxford University Press|year= 1998}}

==External links==
*{{mathworld2 |urlname=TruncatedTetrahedron |title=Truncated tetrahedron |urlname2=ArchimedeanSolid |title2=Archimedean solid}}
** {{mathworld | urlname = TruncatedTetrahedralGraph | title = Truncated tetrahedral graph}}
*{{KlitzingPolytopes|polyhedra.htm|3D convex uniform polyhedra|x3x3o - tut}}
*[http://www.dr-mikes-math-games-for-kids.com/polyhedral-nets.html?net=3cqTmfu7gdEZ8I7kRUVvji6qxBATVSp2WpmIWGx7l7pWe7bveylFxv3piHnPNZN&amp;name=Truncated+Tetrahedron#applet Editable printable net of a truncated tetrahedron with interactive 3D view]
*[http://www.mathconsult.ch/showroom/unipoly/ The Uniform Polyhedra]
*[http://www.georgehart.com/virtual-polyhedra/vp.html Virtual Reality Polyhedra] The Encyclopedia of Polyhedra

{{Archimedean solids}}
{{Polyhedron navigator}}

[[Category:Archimedean solids]]
[[Category:Truncated tilings]]
[[Category:Individual graphs]]
[[Category:Planar graphs]]</text>
      <sha1>r5z9wkvgmemxg9w28gmyfn813wv0wah</sha1>
    </revision>
  </page>
  <page>
    <title>Unicity distance</title>
    <ns>0</ns>
    <id>71630</id>
    <revision>
      <id>848463583</id>
      <parentid>844414021</parentid>
      <timestamp>2018-07-02T02:10:49Z</timestamp>
      <contributor>
        <username>Suffusion of Yellow</username>
        <id>10783139</id>
      </contributor>
      <comment>/* Practical application */ rm statement tagged {{dubious}} for nearly four years. OR?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6706">{{Refimprove|date=October 2007}}

In [[cryptography]], '''unicity distance''' is the length of an original [[ciphertext]] needed to break the cipher by reducing the number of possible '''spurious keys''' to zero in a [[brute force attack]]. That is, after trying every possible [[key (cryptography)|key]], there should be just one decipherment that makes sense, i.e. expected amount of ciphertext needed to determine the key completely, assuming the underlying message has redundancy.&lt;ref name=hac&gt;{{Cite book |title=Handbook of Applied Cryptography |authors=[[Alfred J. Menezes]], [[Paul C. van Oorschot]], [[Scott A. Vanstone]] |chapter=Chapter 7 - Block Ciphers |pages=246 |url=http://cacr.uwaterloo.ca/hac/ |chapter-url=http://cacr.uwaterloo.ca/hac/about/chap7.pdf }}&lt;/ref&gt;

[[Claude Shannon]] defined the unicity distance in his 1949 paper "[[Communication Theory of Secrecy Systems]]".

Consider an attack on the ciphertext string "WNAIW" encrypted using a [[Vigenère cipher]] with a five letter key. Conceivably, this string could be deciphered into any other string&amp;mdash;RIVER and WATER are both possibilities for certain keys. This is a general rule of [[cryptanalysis]]: with no additional information it is impossible to decode this message.

Of course, even in this case, only a certain number of five letter keys will result in English words. Trying all possible keys we will not only get RIVER and WATER, but SXOOS and KHDOP as well. The number of "working" keys will likely be very much smaller than the set of all possible keys. The problem is knowing which of these "working" keys is the right one; the rest are spurious.

==Relation with key size and possible plaintexts==
In general, given particular assumptions about the size of the key and the number of possible messages, there is an average ciphertext length where there is only one key (on average) that will generate a readable message. In the example above we see only [[upper case]] English characters, so if we assume that the [[plaintext]] has this form, then there are 26 possible letters for each position in the string. Likewise if we assume five-character upper case keys, there are K=26&lt;sup&gt;5&lt;/sup&gt; possible keys, of which the majority will not "work".

A tremendous number of possible messages, N, can be generated using even this limited set of characters: N = 26&lt;sup&gt;L&lt;/sup&gt;, where L is the length of the message. However, only a smaller set of them is readable [[plaintext]] due to the rules of the language, perhaps M of them, where M is likely to be very much smaller than N. Moreover, M has a one-to-one relationship with the number of keys that work, so given K possible keys, only K &amp;times; (M/N) of them will "work". One of these is the correct key, the rest are spurious.

Since M/N gets arbitrarily small as the length L of the message increases, there is eventually some L that is large enough to make the number of spurious keys equal to zero. Roughly speaking, this is the L that makes KM/N=1. This L is the unicity distance.

==Relation with key entropy and plaintext redundancy==
The unicity distance can equivalently be defined as the minimum amount of ciphertext required to permit a computationally unlimited adversary to recover the unique encryption key.&lt;ref name=hac /&gt;

The expected unicity distance can then be shown to be:&lt;ref name=hac /&gt;

: &lt;math&gt;U = H(k) / D&lt;/math&gt;

where ''U'' is the unicity distance, ''H''(''k'') is the entropy of the key space (e.g. 128 for 2&lt;sup&gt;128&lt;/sup&gt; equiprobable keys, rather less if the key is a memorized pass-phrase). ''D'' is defined as the plaintext redundancy in bits per character.

Now an alphabet of 32 characters can carry 5 bits of information per character (as 32 =&amp;nbsp;2&lt;sup&gt;5&lt;/sup&gt;). In general the number of bits of information per character is  {{math|log&lt;sub&gt;2&lt;/sub&gt;(N)}}, where ''N'' is the number of characters in the alphabet and {{math|log&lt;sub&gt;2&lt;/sub&gt;}} is the [[binary logarithm]]. So for English each character can convey {{math|log&lt;sub&gt;2&lt;/sub&gt;(26) {{=}} 4.7}} bits of information.

However the average amount of actual information carried per character in meaningful English text is only about 1.5 bits per character. So the plain text redundancy is ''D'' =&amp;nbsp;4.7&amp;nbsp;&amp;minus;&amp;nbsp;1.5 =&amp;nbsp;3.2.&lt;ref name=hac /&gt;

Basically the bigger the unicity distance the better. For a one time pad of unlimited size, given the unbounded entropy of the key space, we have &lt;math&gt;U = \infty&lt;/math&gt;, which is consistent with the [[one-time pad]] being unbreakable.

=== Unicity distance of substitution cipher ===
For a simple [[substitution cipher]], the number of possible keys is {{math|26! {{=}} 4.0329 × 10&lt;sup&gt;26&lt;/sup&gt; {{=}} 2&lt;sup&gt;88.4&lt;/sup&gt;}}, the number of ways in which the alphabet can be permuted. Assuming all keys are equally likely, {{math|''H''(''k'') {{=}} log&lt;sub&gt;2&lt;/sub&gt;(26!) {{=}} 88.4}} bits. For English text {{math|''D'' {{=}} 3.2}}, thus {{math|''U'' {{=}} 88.4/3.2 {{=}} 28}}.

So given 28 characters of ciphertext it should be theoretically possible to work out an English plaintext and hence the key.

==Practical application==
Unicity distance is a useful theoretical measure, but it doesn't say much about the security of a block cipher when attacked by an adversary with real-world (limited) resources. Consider a block cipher with a unicity distance of three ciphertext blocks.  Although there is clearly enough information for a computationally unbounded adversary to find the right key (simple exhaustive search), this may be computationally infeasible in practice.

The unicity distance can be increased by reducing the plaintext redundancy. One way to do this is to deploy data compression techniques prior to encryption, for example by removing redundant vowels while retaining readability. This is a good idea anyway, as it reduces the amount of data to be encrypted.

Ciphertexts greater than the unicity distance can be assumed to have only one meaningful decryption. Ciphertexts shorter than the unicity distance may have multiple plausible decryptions. Unicity distance is not a measure of how much ciphertext is required for cryptanalysis,{{why|date=November 2014}} but how much ciphertext is required for there to be only one reasonable solution for cryptanalysis.

==References==
{{Reflist}}

==External links==
*[[Bruce Schneier]]: [http://www.schneier.com/crypto-gram-9812.html#plaintext How to Recognize Plaintext] (Crypto-Gram Newsletter December 15, 1998)
*[http://www.practicalcryptography.com/cryptanalysis/text-characterisation/statistics/#unicity-distance Unicity Distance computed for common ciphers]

[[Category:Cryptography]]
[[Category:Cryptographic attacks]]
[[Category:Information theory]]</text>
      <sha1>oijshdixgbg1snkn0k1vw06c5c7toyi</sha1>
    </revision>
  </page>
  <page>
    <title>Unit in the last place</title>
    <ns>0</ns>
    <id>1498076</id>
    <revision>
      <id>830569036</id>
      <parentid>817654420</parentid>
      <timestamp>2018-03-15T16:54:56Z</timestamp>
      <contributor>
        <username>Intgr</username>
        <id>246230</id>
      </contributor>
      <minor/>
      <comment>tweak per [[MOS:BOLD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8215">{{refimprove|date=March 2015}}
In [[computer science]] and [[numerical analysis]], '''unit in the last place '''or''' unit of least precision''' ('''ULP''') is the spacing between [[floating-point]] numbers, i.e., the value the least significant [[Numerical digit|digit]] represents if it is 1. It is used as a measure of [[Accuracy and precision|accuracy]] in numeric calculations.&lt;ref&gt;David Goldberg: What Every Computer Scientist Should Know About Floating-Point Arithmetic, section 1.2 Relative Error and Ulps, ACM Computing Surveys, Vol 23, No 1, pp.8, March 1991.&lt;/ref&gt;

==Definition==
In [[radix]] ''b'', if ''x'' has exponent ''E'', then ULP(''x'') = [[machine epsilon]] · ''b''&lt;sup&gt;''E''&lt;/sup&gt;,&lt;ref&gt;{{cite book|first=Nicholas | last=Higham |title=Accuracy and Stability of Numerical Algorithms (2 ed)|publisher=SIAM|year=2002}}&lt;/ref&gt; but alternative definitions exist in the numerics and computing literature for ''ULP'', ''exponent'' and ''machine epsilon'', and they may give different equalities.{{fact|date=March 2015}}

Another definition, suggested by John Harrison, is slightly different: ULP(''x'') is the distance between the two closest ''straddling'' floating-point numbers ''a'' and ''b'' (i.e., those with ''a'' ≤ ''x'' ≤ ''b'' and ''a'' ≠ ''b''), assuming that the exponent range is not upper-bounded.&lt;ref&gt;{{cite web|last=Harrison|first=John|title=A Machine-Checked Theory of Floating Point Arithmetic|url=http://www.cl.cam.ac.uk/~jrh13/papers/fparith.html|accessdate=2013-07-17}}&lt;/ref&gt;&lt;ref&gt;Muller, Jean-Michel (2005-11). "On the definition of ulp(x)". INRIA Technical Report 5504. ACM Transactions on Mathematical Software, Vol. V, No. N, November 2005. Retrieved in 2012-03 from http://ljk.imag.fr/membres/Carine.Lucas/TPScilab/JMMuller/ulp-toms.pdf.&lt;/ref&gt; These definitions differ only at signed powers of the radix.{{fact|date=March 2015}}

The [[IEEE 754]] specification&amp;mdash;followed by all modern floating-point hardware&amp;mdash;requires that the result of an [[elementary arithmetic]] operation (addition, subtraction, multiplication, division, and [[square root]] since 1985, and [[Fused multiply–add|FMA]] since 2008) be [[Rounding#Table-maker's dilemma|correctly rounded]]&lt;!-- The current link for correct rounding is under "Table-maker's dilemma" though these elementary arithmetic operations are not concerned by the TMD in practice. --&gt;, which implies that in rounding to nearest, the rounded result is within 0.5 ULP of the mathematically exact result, using John Harrison's definition; conversely, this property implies that the distance between the rounded result and the mathematically exact result is minimized (but for the halfway cases, it is satisfied by two consecutive floating-point numbers). Reputable [[numerical analysis|numeric]] [[library (computing)|libraries]] compute the basic [[transcendental function]]s to between 0.5 and about 1 ULP. Only a few libraries compute them within 0.5 ULP, this problem being complex due to the [[Table-maker's dilemma]].&lt;ref&gt;{{cite web |last=Kahan |first=William |title=A Logarithm Too Clever by Half |url=http://www.cs.berkeley.edu/~wkahan/LOG10HAF.TXT |accessdate=2008-11-14}}&lt;/ref&gt;

==Examples==
===Example 1===
Let ''x'' be a nonnegative floating-point number and assume that the active rounding attribute is [[IEEE floating point#Roundings to nearest|round to nearest, ties to even]], denoted RN. If ULP(''x'') is less than or equal to 1, then {{mono|1=RN(''x''&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;&gt;&amp;nbsp;''x''}}. Otherwise, {{mono|1=RN(''x''&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;=&amp;nbsp;''x''}} or {{mono|1=RN(''x''&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;=&amp;nbsp;''x''&amp;nbsp;+&amp;nbsp;ULP(x)}}, depending on the value of the least significant digit and the exponent of x. This is demonstrated in the following [[Haskell (programming language)|Haskell]] code typed at an interactive prompt:{{fact|date=March 2015}}

&lt;source lang="lhaskell"&gt;
&gt; until (\x -&gt; x == x+1) (+1) 0 :: Float
1.6777216e7
&gt; it-1
1.6777215e7
&gt; it+1
1.6777216e7
&lt;/source&gt;

Here we start with 0 in 32-bit [[single-precision]] and repeatedly add 1 until the operation is [[idempotent]]. The result is equal to 2&lt;sup&gt;24&lt;/sup&gt; since the [[significand]] for a single-precision number in this example contains 24 bits.{{fact|date=March 2015}}

===Example 2===
The following example in [[Java (programming language)|Java]] approximates [[Pi|{{pi}}]] as a floating point value by finding the two double values bracketing {{pi}}:
:{{math|''p''&lt;sub&gt;0&lt;/sub&gt; &lt; &amp;pi; &lt;  ''p''&lt;sub&gt;1&lt;/sub&gt;}}
&lt;source lang="Java"&gt;
// π with 20 decimal digits
BigDecimal π = new BigDecimal("3.14159265358979323846");

// truncate to a double floating point
double p0 = π.doubleValue();
// -&gt; 3.141592653589793  (hex: 0x1.921fb54442d18p1)

// p0 is smaller than π, so find next number representable as double
double p1 = Math.nextUp(p0);
// -&gt; 3.1415926535897936 (hex: 0x1.921fb54442d19p1)
&lt;/source&gt;

Then {{math|ULP(&amp;pi;)}} is determined as 
:{{math|ULP(&amp;pi;) {{=}} ''p''&lt;sub&gt;1&lt;/sub&gt; - ''p''&lt;sub&gt;0&lt;/sub&gt;}}
&lt;source lang="Java"&gt;
// ulp(π) is the difference between p1 and p0
BigDecimal ulp = new BigDecimal(p1).subtract(new BigDecimal(p0));
// -&gt; 4.44089209850062616169452667236328125E-16
// (this is precisely 2**(-51))

// same result when using the standard library function
double ulpMath = Math.ulp(p0);
// -&gt; 4.440892098500626E-16 (hex: 0x1.0p-51)
&lt;/source&gt;

===Example 3===

Another example, in [[Python (programming language)|Python]], also typed at an interactive prompt, is:{{fact|date=March 2015}}

&lt;source lang="pycon"&gt;
&gt;&gt;&gt; x = 1.0
&gt;&gt;&gt; p = 0
&gt;&gt;&gt; while x != x + 1:
...   x = x * 2
...   p = p + 1
... 
&gt;&gt;&gt; x
9007199254740992.0
&gt;&gt;&gt; p
53
&gt;&gt;&gt; x + 2 + 1
9007199254740996.0
&lt;/source&gt;

In this case, we start with {{mono|1=''x''&amp;nbsp;=&amp;nbsp;1}} and repeatedly double it until {{mono|1=''x''&amp;nbsp;=&amp;nbsp;''x''&amp;nbsp;+&amp;nbsp;1}}. The result is 2&lt;sup&gt;53&lt;/sup&gt;, because the [[double-precision]] floating-point format uses a 53-bit significand.{{fact|date=March 2015}}

==Language support==
Since Java 1.5, the [[Java (language)|Java]] standard library has included &lt;tt&gt;{{Javadoc:SE|java/lang|Math|ulp(double)}}&lt;/tt&gt; and  &lt;tt&gt;{{Javadoc:SE|java/lang|Math|ulp(float)}}&lt;/tt&gt; functions.

The [[C (programming language)|C language]] library provides functions to calculate the next floating-point number in some given direction: &lt;code&gt;nextafterf&lt;/code&gt; and &lt;code&gt;nexttowardf&lt;/code&gt; for &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;nextafter&lt;/code&gt; and &lt;code&gt;nexttoward&lt;/code&gt; for &lt;code&gt;double&lt;/code&gt;, &lt;code&gt;nextafterl&lt;/code&gt; and &lt;code&gt;nexttowardl&lt;/code&gt; for &lt;code&gt;long double&lt;/code&gt;, declared in &lt;code&gt;&lt;math.h&gt;&lt;/code&gt;.&lt;ref name=c99&gt;{{cite book | url=http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf  | title=ISO/IEC 9899:1999 specification | at=p. 237, §7.12.11.3 ''The nextafter functions'' and §7.12.11.4 ''The nexttoward functions''}}&lt;/ref&gt;

The [[Boost C++ Libraries]] offer &lt;tt&gt;boost::math::float_next&lt;/tt&gt;, &lt;tt&gt;boost::math::float_prior&lt;/tt&gt;, &lt;tt&gt;boost::math::nextafter&lt;/tt&gt; 
and &lt;tt&gt;boost::math::float_advance&lt;/tt&gt; functions to obtain nearby (and distant) floating-point values,
&lt;ref name="Boost advance"&gt;{{cite book | url=http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/next_float/float_advance.html | title=Boost float_advance}}&lt;/ref&gt;
and &lt;tt&gt;boost::math::float_distance(a, b)&lt;/tt&gt; to calculate the floating-point distance between two doubles.
&lt;ref name="Boost float_distance"&gt;{{cite book | url=http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/next_float/float_distance.html | title=Boost float_distance}}&lt;/ref&gt;

==See also==
* [[IEEE 754]]
* [[ISO/IEC 10967]], part 1 requires an ulp function
* [[Least significant bit]] (LSB)
* [[Machine epsilon]]

==References==
{{Reflist}}

==Bibliography==
* Goldberg, David (1991-03). "Rounding Error" in "What Every Computer Scientist Should Know About Floating-Point Arithmetic". Computing Surveys, ACM, March 1991. Retrieved from http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html#689.
* {{Cite book|title=Handbook of floating-point arithmetic|last=Muller|first=Jean-Michel|publisher=Birkhäuser|year=2010|isbn=978-0-8176-4704-9|location=Boston|pages=32-37|quote=|via=}}

{{use dmy dates|date=January 2012}}

[[Category:Computer arithmetic]]</text>
      <sha1>55cym8iah5ttysnmrf01y1xn2eoq3z9</sha1>
    </revision>
  </page>
  <page>
    <title>Z User Group</title>
    <ns>0</ns>
    <id>2578793</id>
    <revision>
      <id>801326419</id>
      <parentid>794379540</parentid>
      <timestamp>2017-09-19T01:02:23Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3630">The '''Z User Group''' exists to promote use and development of the [[Z notation]], a [[formal specification]] language for the description of and reasoning about computer-based systems.&lt;ref name="JFIT93"&gt;{{cite article| first=J.P. | last=Bowen |  authorlink=Jonathan Bowen | title=Z User Group activities| journal=JFIT News | volume=46 | page=5 | date=September 1993 }}&lt;/ref&gt;&lt;ref name="HIS94"&gt;{{cite article| first=J.P. | last=Bowen | title=Z User Meeting Activities | journal=High Integrity Systems | volume=1 | number=1 | pages=93–94 | year=1994 }}&lt;/ref&gt; It was formally constituted on 14 December 1992 during the ZUM'92 '''Z User Meeting'''&lt;ref name="ZUM92" /&gt; in [[London]], [[England]].

==Meetings and conferences==
ZUG has organised a series of '''Z User Meetings''' approximately every 18 months initially.&lt;ref name="ZUM91"&gt;{{cite book| title=Z User Workshop, York 1991 | url=https://books.google.com/books?isbn=1447132033 | editor-first=J.E. | editor-last=Nicholls | year=1992 | publisher=Springer | series=Workshops in Computing }}&lt;/ref&gt;&lt;ref name="ZUM92"&gt;{{cite book| title=Z User Workshop, London 1992 | url=https://books.google.com/books?isbn=1447135563 | editor-first1=J.P. | editor-last1=Bowen | editor-first2=J.E. | editor-last2=Nicholls | year=1993 | publisher=Springer | series=Workshops in Computing }}&lt;/ref&gt;&lt;ref name="ZUM94"&gt;{{cite book| title=Z User Workshop, Cambridge 1994 | url=https://books.google.com/books?isbn=1447134524 | ISBN=3-540-19884-9 | editor-first1=J.P. | editor-last1=Bowen | editor-first2=J.A. | editor-last2=Hall | year=1994 | publisher=Springer | series=Workshops in Computing }}&lt;/ref&gt; From 2000, these became the '''ZB Conference''' (jointly with the [[B-Method]], co-organized with [[APCB]]), and from 2008 the '''ABZ Conference''' (with [[Abstract State Machines]] as well). In 2010, the ABZ Conference also includes [[Alloy (specification language)|Alloy]], a Z-like specification language with associated tool support.&lt;ref&gt;Frappier, M., Glässer, U.; , Khurshid, S., Laleau, R., and [[Steve Reeves (computer scientist)|Reeves, S.]] (eds.), ''[https://www.springer.com/computer/theoretical+computer+science/book/978-3-642-11810-4 Abstract State Machines, Alloy, B and Z: Second International Conference, ABZ 2010, Orford, QC, Canada, February 22–25, 2010, Proceedings]'', [[Springer-Verlag]], [[Lecture Notes in Computer Science]], Volume 5977, 2010. {{ISBN|978-3-642-11810-4}}.&lt;/ref&gt;

The Z User Group participated at the ''FM'99 World Congress on Formal Methods'' in Toulouse, France, in 1999.&lt;ref name="FM99"&gt;{{cite web| url=https://web.archive.org/web/20070706210024/vl.fmnet.info/fm99/usergroups/zug.html | title=Z User Group Meeting (ZUG) | work=FM'99 World Congress | location=Toulouse, France | date=20–24 September 1999 }}&lt;/ref&gt;

==Chair and secretary==
Successive chairs have been:

*John Nicholls (1992–1994)
*[[Jonathan Bowen]] (1994–2011)
*[[Steve Reeves (computer scientist)|Steve Reeves]] (2011–)

Successive secretaries have been:

*[[Mike Hinchey]] (1994–2011)
*Randolph Johnson (2011–)

==See also==
* [[Formal methods]]

==References==
{{reflist}}

==External links==
*[http://www.zuser.org/ Z User Group]
*[http://www.zuser.org/zum Z User Meetings]
*[http://www.zuser.org/constitution ZUG constitution]
*[http://www.zuser.org/vl Z notation]
*[http://www.abzconference.org/ ABZ conference]

[[Category:1992 establishments in the United Kingdom]]
[[Category:Organizations established in 1992]]
[[Category:Formal methods organizations]]
[[Category:Z notation]]
[[Category:User groups]]
[[Category:Computer clubs in the United Kingdom]]

{{UK-org-stub}}</text>
      <sha1>fogij7up4amyfwip1wwwq53g71g6rsf</sha1>
    </revision>
  </page>
</mediawiki>
