<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>58 (number)</title>
    <ns>0</ns>
    <id>399312</id>
    <revision>
      <id>863325207</id>
      <parentid>863279914</parentid>
      <timestamp>2018-10-10T02:21:13Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/27 is the best number|27 is the best number]] ([[User talk:27 is the best number|talk]]): Seems trivia. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5264">{{example farm|date=March 2010}}
{{Infobox number
| number = 58
| divisor = 1, 2, 29, 58
}}
'''58''' ('''fifty-eight''') is the [[natural number]] following [[57 (number)|57]] and preceding [[59 (number)|59]].

==In mathematics==

'''Fifty-eight''' is the sum of the first seven [[prime numbers]], an 11-[[Polygonal number|gonal number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A051682|title=Sloane's A051682 : 11-gonal numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; and a [[Smith number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A006753|title=Sloane's A006753 : Smith numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;
Given 58, the [[Mertens function]] returns [[0 (number)|0]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A028442|title=Sloane's A028442 : Numbers n such that Mertens' function is zero|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt;

There is no solution to the equation ''x'' – [[Euler's totient function|φ]](''x'') = 58, making 58 a [[noncototient]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A005278|title=Sloane's A005278 : Noncototients|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-30}}&lt;/ref&gt; However, the sum of the totient function for the first thirteen integers is 58.

==In science==
*The [[atomic number]] of [[cerium]], a lanthanide

===Astronomy===

*[[Messier object]] [[Messier 58|M58]], a [[visual magnitude|magnitude]] 11.0 [[galaxy]] in the [[constellation]] [[Virgo (constellation)|Virgo]]
*The [[New General Catalogue]] [http://www.ngcic.org/ object] [[NGC 58]], a [[barred spiral galaxy]] in the constellation [[Cetus]]. It is also the object designated as [[NGC 47]]

==In music==
* John Cage CD "Fifty-Eight"
* Fifty-Eight Now Nine, a collection of songs by Esther Lee
* [[58 (band)|58]] was the name of a side project involving [[Nikki Sixx]] of [[Mötley Crüe]]. They covered the song "[[Alone Again (Naturally)]]"
* Band "Spur 58"
* "58 Poems" by [[Chicago (band)|Chicago]]

==In sports==

In the NBA, the most points ever scored in a fourth quarter was 58 by the [[Buffalo Braves]] (at [[Boston Celtics]]), Oct. 20, 1972. The most points in a game by a rookie player: [[Wilt Chamberlain]], 58: Philadelphia vs. Detroit, Jan. 25, 1960, and Philadelphia vs. New York [[Knicks]], Feb. 21, 1960.

In [[MotoGP]], 58 was the number of [[Marco Simoncelli]] who died in an accident at the Malaysian Round of the 2011 MotoGP season. MotoGP's governing body, the [[Fédération Internationale de Motocyclisme|FIM]], are considering to retire number 58 from use in MotoGP as they did before with the numbers 74 and 48 of [[Daijiro Kato]] and [[Shoya Tomizawa]], respectively.  The retirement, from all motorcycle racing classes, eventually occurred in 2016, joining Kato's 74, the 34 of inaugural MotoGP champion [[Kevin Schwantz]] and the 65 of [[Loris Capirossi]].

On the [[PGA Tour]], 58 is the lowest score in an 18 hole round, achieved by [[Jim Furyk]] in the final round of the 2016 [[Travelers Championship]] at TPC River Highlands.

In [[Formula One]], 58 is the number of laps of the [[Australian Grand Prix]] since [[1996 Australian Grand Prix|1996]], when the Grand Prix held in [[Melbourne Grand Prix Circuit|Albert Park]].

==In mythology==
The number 58 was commonly associated with misfortune in many civilizations native to either [[Central America]] or [[Southern America]]. Due to their beliefs in the original 58 [[sins]], the number came to symbolize curses and ill-luck. Aztec [[oracles]] supposedly stumbled across the number an unnaturally high number of times before disaster fell. One famous recording of this, though largely discredited as mere folktale, concerned the oracle of [[Moctezuma II]], who allegedly counted 58 pieces of [[gold]] scattered before a sacrificial pit the day prior to the arrival of [[Hernán Cortés]].

==In other fields==
*The Alabama county code for [[Shelby County, Alabama|Shelby County]]
*The Ohio county code for [[Morgan County, Ohio|Morgan County]]
*The code for international direct dial phone calls to [[Venezuela]]
*The number of usable cells on a [[Hexxagon]] game board
*Book: "58 Lonely Men: Southern Federal Judges and School [[Desegregation]]" about 58 judges in the South during the [[Brown vs. Board of Education]] decision
*The number of [[counties]] in [[California]]
*The [[minimum]] wind speed (mph) needed to issue a [[Severe Thunderstorm Warning]].
*The number of the French department [[Nièvre]]
*In the popular TV show ''[[SpongeBob SquarePants]]'', Patrick claims that "58 is like the luckiest number ever."
*[[58 Minutes]] is a book by Walter Wager, on which the film [[Die Hard 2]] was based
*''[[Japanese submarine I-58 (1943)|I-58]]'' was the name of one of the Type B3 submarines that fought in World War II. When personified in the free-to-play Japanese video game ''[[Kantai Collection]]'', she tends to be called "Goya", from the number's goroawase.

== References ==
{{Reflist}}

{{Integers|zero}}

[[Category:Integers]]</text>
      <sha1>cmo3obwua7fdedjts7tvo09knlwbg1a</sha1>
    </revision>
  </page>
  <page>
    <title>Affine transformation</title>
    <ns>0</ns>
    <id>38449</id>
    <revision>
      <id>859998669</id>
      <parentid>859977439</parentid>
      <timestamp>2018-09-17T17:46:08Z</timestamp>
      <contributor>
        <username>Anita5192</username>
        <id>13220696</id>
      </contributor>
      <comment>Clarified confusing notation.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21713">{{refimprove|date=April 2012}}
[[File:Fractal fern explained.png|thumb|right|200px|An image of a [[Barnsley fern|fern]]-like [[fractal]] that exhibits affine [[self-similarity]]. Each of the leaves of the fern is related to each other leaf by an affine transformation. For instance, the red leaf can be transformed into both the dark blue leaf and the light blue leaf by a combination of reflection, rotation, scaling, and translation.]]

In [[geometry]], an '''affine transformation''', '''affine map'''&lt;ref name="Berger"&gt;Berger, Marcel (1987), p. 38.&lt;/ref&gt; or an '''affinity''' (from the Latin, ''affinis'', "connected with") is a function between [[affine spaces]] which preserves points, straight lines and planes. Also, sets of [[Parallel (geometry)|parallel]] lines remain parallel after an affine transformation. An affine transformation does not necessarily preserve angles between lines or distances between points, though it does preserve ratios of distances between points lying on a straight line.

Examples of affine transformations include [[Translation (geometry)|translation]], [[Scaling (geometry)|scaling]], [[Homothetic transformation|homothety]], [[Similarity transformation (geometry)|similarity transformation]], [[Reflection (mathematics)|reflection]], [[Rotation (mathematics)|rotation]], [[shear mapping]], and [[Function composition|compositions]] of them in any combination and sequence.

If &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are [[affine space]]s, then every affine transformation &lt;math&gt;f\colon X \to Y&lt;/math&gt; is of the form &lt;math&gt;x \mapsto Mx + b&lt;/math&gt;, where &lt;math&gt;M&lt;/math&gt; is a [[linear transformation]] on the space &lt;math&gt;X&lt;/math&gt;, &lt;math&gt;x&lt;/math&gt; is a vector in &lt;math&gt;X&lt;/math&gt;, and &lt;math&gt;b&lt;/math&gt; is a vector in &lt;math&gt;Y&lt;/math&gt;. Unlike a purely linear transformation, an affine map need not preserve the zero point in a linear space. Thus, every linear transformation is affine, but not every affine transformation is linear.

All Euclidean spaces are affine, but there are affine spaces that are non-Euclidean. In [[affine coordinates]], which include [[Cartesian coordinates]] in Euclidean spaces, each output coordinate of an affine map is a [[Linear function (calculus)|linear function (in the sense of calculus)]] of all input coordinates. Another way to deal with affine transformations systematically is to select a point as the [[Origin (mathematics)|origin]]; then, any affine transformation is equivalent to a [[linear transformation]] (of [[Position (vector)|position vectors]]) followed by a [[Translation (geometry)|translation]].

==Mathematical definition==
An affine map&lt;ref name="Berger" /&gt; &lt;math&gt;f\colon\mathcal{A} \to \mathcal{B}&lt;/math&gt; between two [[affine space]]s is a map on the points that acts [[Linear transformation|linearly]] on the vectors (that is, the vectors between points of the space). In symbols, ''&lt;math&gt;f&lt;/math&gt;'' determines a linear transformation ''&lt;math&gt;\varphi&lt;/math&gt;'' such that, for any pair of points &lt;math&gt;P, Q \in \mathcal{A}&lt;/math&gt;:

:&lt;math&gt;\overrightarrow{f(P)~f(Q)} = \varphi(\overrightarrow{PQ})&lt;/math&gt;
or
:&lt;math&gt;f(Q)-f(P) = \varphi(Q-P)&lt;/math&gt;.

We can interpret this definition in a few other ways, as follows.

If an origin &lt;math&gt;O \in \mathcal{A}&lt;/math&gt; is chosen, and &lt;math&gt;B&lt;/math&gt; denotes its image &lt;math&gt;f(O) \in \mathcal{B}&lt;/math&gt;, then this means that for any vector &lt;math&gt;\vec{x}&lt;/math&gt;:

:&lt;math&gt;f\colon (O+\vec{x}) \mapsto (B+\varphi(\vec{x}))&lt;/math&gt;.

If an origin &lt;math&gt;O' \in \mathcal{B}&lt;/math&gt; is also chosen, this can be decomposed as an affine transformation &lt;math&gt;g\colon \mathcal{A} \to \mathcal{B}&lt;/math&gt; that sends &lt;math&gt;O \mapsto O'&lt;/math&gt;, namely

:&lt;math&gt;g\colon (O+\vec{x}) \mapsto (O'+\varphi(\vec{x}))&lt;/math&gt;,

followed by the translation by a vector &lt;math&gt;\vec{b} = \overrightarrow{O'B}&lt;/math&gt;.

The conclusion is that, intuitively, &lt;math&gt;f&lt;/math&gt; consists of a translation and a linear map.

===Alternative definition===
Given two [[affine space]]s &lt;math&gt;\mathcal{A}&lt;/math&gt; and &lt;math&gt;\mathcal{B}&lt;/math&gt;, over the same field, a function &lt;math&gt;f\colon \mathcal{A} \to \mathcal{B}&lt;/math&gt; is an affine map [[if and only if]] for every family &lt;math&gt;\{(a_i, \lambda_i)\}_{i\in I}&lt;/math&gt; of weighted points in &lt;math&gt;\mathcal{A}&lt;/math&gt; such that 
: &lt;math&gt;\sum_{i\in I}\lambda_i = 1&lt;/math&gt;,

we have&lt;ref&gt;
{{cite book|authors=Schneider, Philip K. &amp; Eberly, David H.|title=Geometric Tools for Computer Graphics|publisher=Morgan Kaufmann|year=2003|isbn=978-1-55860-594-7|page=98|url=https://books.google.com/books?id=3Q7HGBx1uLIC&amp;pg=PA98}}&lt;/ref&gt;

: &lt;math&gt;f\left(\sum_{i\in I}\lambda_i a_i\right)=\sum_{i\in I}\lambda_i f(a_i)&lt;/math&gt;.

In other words, &lt;math&gt;f&lt;/math&gt; preserves [[barycenter]]s.

==Representation==
As shown above, an affine map is the [[Function composition|composition]] of two functions: a [[Translation_(geometry)|translation]] and a [[linear map]]. Ordinary vector algebra uses [[matrix multiplication]] to represent linear maps, and [[vector addition]] to represent translations. Formally, in the finite-dimensional case, if the linear map is represented as a multiplication by a matrix &lt;math&gt;A&lt;/math&gt; and the translation as the addition of a vector &lt;math&gt;\vec{b}&lt;/math&gt;, an affine map &lt;math&gt;f&lt;/math&gt; acting on a vector &lt;math&gt;\vec{x}&lt;/math&gt; can be represented as

:&lt;math&gt;
\vec{y} = f(\vec{x}) = A \vec{x} + \vec{b}.
&lt;/math&gt;

===Augmented matrix===
[[File:Affine transformations.ogv|thumb|250px|right|Affine transformations on the 2D plane can be performed in three dimensions. Translation is done by shearing along over the z axis, and rotation is performed around the z axis.]]

Using an [[augmented matrix]] and an augmented vector, it is possible to represent both the translation and the linear map using a single [[matrix multiplication]]. The technique requires that all vectors are augmented with a "1" at the end, and all matrices are augmented with an extra row of zeros at the bottom, an extra column—the translation vector—to the right, and a "1" in the lower right corner. If &lt;math&gt;A&lt;/math&gt; is a matrix,

:&lt;math&gt;
\begin{bmatrix} \vec{y} \\ 1 \end{bmatrix} = \left[ \begin{array}{ccc|c} \, &amp; A &amp; &amp; \vec{b} \ \\ 0 &amp; \ldots &amp; 0 &amp; 1 \end{array} \right] \begin{bmatrix} \vec{x} \\ 1 \end{bmatrix}
&lt;/math&gt;

is equivalent to the following

:&lt;math&gt;
\vec{y} = A \vec{x} + \vec{b}.
&lt;/math&gt;

The above-mentioned augmented matrix is called an ''[[Transformation matrix#Affine transformations|affine transformation matrix]]'', or ''projective transformation matrix'' (as it can also be used to perform [[projective transformation]]s).

This representation exhibits the set of all [[Inverse function|invertible]] affine transformations as the [[semidirect product]] of &lt;math&gt;K^n&lt;/math&gt; and &lt;math&gt;GL(n, K)&lt;/math&gt;.  This is a [[Group (mathematics)|group]] under the operation of composition of functions,  called the [[affine group]].

Ordinary matrix-vector multiplication always maps the origin to the origin, and could therefore never represent a translation, in which the origin must necessarily be mapped to some other point. By appending the additional coordinate "1" to every vector, one essentially considers the space to be mapped as a subset of a space with an additional dimension. In that space, the original space occupies the subset in which the additional coordinate is 1. Thus the origin of the original space can be found at &lt;math&gt;(0,0, \dotsc, 0, 1)&lt;/math&gt;. A translation within the original space by means of a linear transformation of the higher-dimensional space is then possible (specifically, a shear transformation). The coordinates in the higher-dimensional space are an example of [[homogeneous coordinates]]. If the original space is [[Euclidean space|Euclidean]], the higher dimensional space is a [[real projective space]].

The advantage of using [[homogeneous coordinates]] is that one can [[Function composition|combine]] any number of affine transformations into one by multiplying the respective matrices. This property is used extensively in [[computer graphics]], [[computer vision]] and [[robotics]].

====Example augmented matrix====
If the vectors &lt;math&gt;\vec{x}_1, \dotsc, \vec{x}_{n+1}&lt;/math&gt; are a [[Basis (linear algebra)|basis]] of the domain's projective vector space and if &lt;math&gt;\vec{y}_1, \dotsc, \vec{y}_{n+1}&lt;/math&gt; are the corresponding vectors in the [[codomain]] vector space then the augmented matrix &lt;math&gt;M&lt;/math&gt; that achieves this affine transformation
:&lt;math&gt;\left[\begin{array}{c}\vec{y}\\1\end{array}\right] = M \left[\begin{array}{c}\vec{x}\\1\end{array}\right]&lt;/math&gt;
is
:&lt;math&gt;M = \left[\begin{array}{ccc}\vec{y}_1&amp;\ldots&amp;\vec{y}_{n+1}\\1&amp;\ldots&amp;1\end{array}\right] \left[\begin{array}{ccc}\vec{x}_1&amp;\ldots&amp;\vec{x}_{n+1}\\1&amp;\ldots&amp;1\end{array}\right]^{-1}&lt;/math&gt;.

This formulation works irrespective of whether any of the domain, codomain and image vector spaces have the same number of dimensions.

For example, the affine transformation of a vector plane is uniquely determined from the knowledge of where the three vertices of a non-degenerate triangle are mapped to.

==Properties==
=== Properties preserved ===
An affine transformation preserves:
# '''[[collinearity]]''' between points: three or more points which lie on the same line (called collinear points) continue to be collinear after the transformation.
# '''[[Parallel (geometry)|parallelism]]''': two or more lines which are parallel, continue to be parallel after the transformation.
# '''[[Convex set|convexity]]''' of sets: a convex set continues to be convex after the transformation. Moreover, the [[extreme point]]s of the original set are mapped to the extreme points of the transformed set.&lt;ref name=res&gt;{{cite web|last1=Reinhard Schultz|title=Affine transformations and convexit|url=http://math.ucr.edu/~res/math145A-2014/affine+convex.pdf|accessdate=27 February 2017}}&lt;/ref&gt;
# '''ratios of lengths''' along a line: for distinct collinear points &lt;math&gt;p_1&lt;/math&gt;, &lt;math&gt;p_2&lt;/math&gt;, &lt;math&gt;p_3&lt;/math&gt;, the ratio of &lt;math&gt;\overrightarrow{p_1p_2}&lt;/math&gt; and &lt;math&gt;\overrightarrow{p_2p_3}&lt;/math&gt; is the same as that of &lt;math&gt;\overrightarrow{f(p_1)f(p_2)}&lt;/math&gt; and &lt;math&gt;\overrightarrow{f(p_2)f(p_3)}&lt;/math&gt;.
# '''[[barycenter]]s''' of weighted collections of points.

=== Groups ===
An affine transformation is [[invertible]] [[if and only if]] &lt;math&gt;A&lt;/math&gt; is invertible. In the matrix representation, the inverse is:

:&lt;math&gt;
\left[ \begin{array}{ccc|c} &amp; A^{-1} &amp; &amp; -A^{-1}\vec{b} \ \\ 0 &amp; \ldots &amp; 0 &amp; 1 \end{array} \right]
&lt;/math&gt;

The invertible affine transformations (of an affine space onto itself) form the [[affine group]], which has the [[general linear group]] of degree &lt;math&gt;n&lt;/math&gt; as subgroup and is itself a subgroup of the general linear group of degree &lt;math&gt;n + 1&lt;/math&gt;.

The [[Similarity transformation (geometry)|similarity transformations]] form the subgroup where &lt;math&gt;A&lt;/math&gt; is a scalar times an [[orthogonal matrix]]. For example, if the affine transformation acts on the plane and if the [[determinant]] of &lt;math&gt;A&lt;/math&gt; is 1 or −1 then the transformation is an [[Equiareal map|equiareal mapping]]. Such transformations form a subgroup called the ''equi-affine group''.&lt;ref&gt;[[Oswald Veblen]] (1918) ''Projective Geometry'', volume 2, pp. 105–7.&lt;/ref&gt; A transformation that is both equi-affine and a similarity is an [[isometry]] of the plane taken with [[Euclidean distance]].

Each of these groups has a subgroup of ''[[orientation (mathematics)|orientation]]-preserving'' or ''positive'' affine transformations: those where the determinant of &lt;math&gt;A&lt;/math&gt; is positive. In the last case this is in 3D the group of [[rigid body]] motions ([[Improper rotation|proper rotations]] and pure translations).

If there is a fixed point, we can take that as the origin, and the affine transformation reduces to a linear transformation. This may make it easier to classify and understand the transformation. For example, describing a transformation as a rotation by a certain angle with respect to a certain axis may give a clearer idea of the overall behavior of the transformation than describing it as a combination of a translation and a rotation. However, this depends on application and context.

== Image transformation ==
In their applications to [[digital image processing]], the affine transformations are analogous to printing on a sheet of rubber and stretching the sheet's edges parallel to the plane. This transform relocates pixels requiring intensity interpolation to approximate the value of moved pixels, bicubic [[interpolation]] is the standard for image transformations in image processing applications. Affine transformations scale, rotate, translate, mirror and shear images as shown in the following examples:&lt;ref&gt;{{cite book
  |last = Gonzalez
  |first = Rafael
  |title = 'Digital Image Processing, 3rd'
  |publisher = Pearson Hall
  |date = 2008
  |ISBN = 9780131687288
}}&lt;/ref&gt; 

{| class="wikitable"
|-
! Transformation name
! Affine matrix
! Example
|-
| '''[[Identity operation|Identity]]''' (transform to original image)
| align="center" | &lt;math&gt;
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}
&lt;/math&gt;
| [[File:Checkerboard identity.svg]]
|-
| '''[[Reflection (mathematics)|Reflection]]'''
| align="center" | &lt;math&gt;
\begin{bmatrix}
-1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\ 
0 &amp; 0 &amp; 1
\end{bmatrix}
&lt;/math&gt;
| [[File:Checkerboard reflection.svg]]
|-
| '''[[Scaling (geometry)|Scale]]'''
| align="center" | &lt;math&gt;
\begin{bmatrix}
c_x=2 &amp; 0 &amp; 0 \\
0 &amp; c_y=1 &amp; 0 \\ 
0 &amp; 0 &amp; 1
\end{bmatrix}
&lt;/math&gt;
| [[File:Checkerboard scale.svg]]
|-
| '''[[Rotate]]'''
| align="center" | &lt;math&gt;
\begin{bmatrix}
\cos(\theta) &amp; \sin(\theta) &amp; 0 \\
-\sin(\theta) &amp; \cos(\theta) &amp; 0 \\ 
0 &amp; 0 &amp; 1
\end{bmatrix}
&lt;/math&gt;
| [[File:Checkerboard rotate.svg]] where {{math|''θ'' {{=}} {{sfrac|π|6}} {{=}}30°}}
|-
| '''[[Shear matrix | Shear]]'''
| align="center" | &lt;math&gt;
\begin{bmatrix}
1 &amp; c_x=0.5 &amp; 0 \\
c_y=0 &amp; 1 &amp; 0 \\ 
0 &amp; 0 &amp; 1
\end{bmatrix}
&lt;/math&gt;
| [[File:Checkerboard shear.svg]]
|-
|}

The affine transforms are applicable to the registration process where two or more images are aligned (registered). An example of image registration is the generation of panoramic images that are the product of multiple images [[Image stitching|stitched]] together.

=== Affine warping  ===

The affine transform preserves parallel lines. However, the stretching and shearing transformations warp shapes, as the following example shows: 

{| class="wikitable"
|-
| [[File:White_on_black_circle_image_256_by_256.png]]
| [[File:Affine_transform_sheared_circle.png]]
|}

This is an example of image warping. However, the affine transformations do not facilitate projection onto a curved surface or [[Distortion (optics)|radial distortions]].

==In the plane==
[[File:Central dilation.svg|thumb|right|300px|A central dilation. The triangles A1B1Z, A1C1Z, and B1C1Z get mapped to A2B2Z, A2C2Z, and B2C2Z, respectively.]] 
Affine transformations in two real dimensions include:
* pure translations,
* [[scaling (geometry)|scaling]] in a given direction, with respect to a line in another direction (not necessarily perpendicular), combined with translation that is not purely in the direction of scaling; taking "scaling" in a generalized sense it includes the cases that the scale factor is zero ([[Projection (linear algebra)|projection]]) or negative; the latter includes [[Reflection (mathematics)|reflection]], and combined with translation it includes [[glide reflection]],
* [[rotation]] combined with a [[Homothetic transformation|homothety]] and a translation,
* [[shear mapping]] combined with a homothety and a translation, or 
* [[squeeze mapping]] combined with a homothety and a translation.

To visualise the general affine transformation of the [[Euclidean plane]], take labelled [[parallelogram]]s ''ABCD'' and ''A′B′C′D′''. Whatever the choices of points, there is an affine transformation ''T'' of the plane taking ''A'' to ''A′'', and each vertex similarly. Supposing we exclude the degenerate case where ''ABCD'' has zero [[area]], there is a unique such affine transformation ''T''. Drawing out a whole grid of parallelograms based on ''ABCD'', the image ''T''(''P'') of any point ''P'' is determined by noting that ''T''(''A'') = ''A′'', ''T'' applied to the line segment ''AB'' is ''A′B′'', ''T'' applied to the line segment ''AC'' is ''A′C′'', and ''T'' respects scalar multiples of vectors based at ''A''. [If ''A'', ''E'', ''F'' are collinear then the ratio length(''AF'')/length(''AE'') is equal to length(''A''′''F''′)/length(''A''′''E''′).] Geometrically ''T'' transforms the grid based on ''ABCD'' to that based in ''A′B′C′D′''.

Affine transformations do not respect lengths or angles; they multiply area by a constant factor

:area of ''A′B′C′D′'' / area of ''ABCD''.

A given ''T'' may either be ''direct'' (respect orientation), or ''indirect'' (reverse orientation), and this may be determined by its effect on ''signed'' areas (as defined, for example, by the [[cross product]] of vectors).

==Examples==
===Over the real numbers===
Functions &lt;math&gt;f\colon \R \to \R,\; f(x) = mx + c&lt;/math&gt; with &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; constant, are commonplace affine transformations.

===Over a finite field===
The following equation expresses an affine transformation in [[Galois field|GF]](2&lt;sup&gt;8&lt;/sup&gt;):

:&lt;math&gt;
\{a'\} = M\{a\} \oplus \{v\},
&lt;/math&gt;

{|
|-
| where &lt;math&gt;[M]&lt;/math&gt; is the matrix and &lt;math&gt;\{v\}&lt;/math&gt; is the vector
:&lt;math&gt;M\{a\}=
\begin{bmatrix}
1&amp;0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1 \\
1&amp;1&amp;0&amp;0&amp;0&amp;1&amp;1&amp;1 \\
1&amp;1&amp;1&amp;0&amp;0&amp;0&amp;1&amp;1 \\
1&amp;1&amp;1&amp;1&amp;0&amp;0&amp;0&amp;1 \\
1&amp;1&amp;1&amp;1&amp;1&amp;0&amp;0&amp;0 \\
0&amp;1&amp;1&amp;1&amp;1&amp;1&amp;0&amp;0 \\
0&amp;0&amp;1&amp;1&amp;1&amp;1&amp;1&amp;0 \\
0&amp;0&amp;0&amp;1&amp;1&amp;1&amp;1&amp;1
\end{bmatrix}
&lt;/math&gt;  :&lt;math&gt;\{v\}= \begin{bmatrix} 1 \\ 1 \\ 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ 0 \end{bmatrix}.&lt;/math&gt;
|}

For instance, the affine transformation of the element &lt;math&gt;\{a\} = y^7 + y^6 + y^3 + y = \{11001010_2\}&lt;/math&gt; in [[Endianness|big-endian]] [[Binary numeral system|binary]] notation = &lt;math&gt;\{\text{CA}_{16}\}&lt;/math&gt; in big-endian [[hexadecimal]] notation, is calculated as follows:

:&lt;math&gt;a_0' = a_0 \oplus a_4 \oplus a_5 \oplus a_6 \oplus a_7 \oplus 1 = 0 \oplus 0 \oplus 0 \oplus 1 \oplus 1 \oplus 1 = 1&lt;/math&gt;
:&lt;math&gt;a_1' = a_0 \oplus a_1 \oplus a_5 \oplus a_6 \oplus a_7 \oplus 1 = 0 \oplus 1 \oplus 0 \oplus 1 \oplus 1 \oplus 1 = 0&lt;/math&gt;
:&lt;math&gt;a_2' = a_0 \oplus a_1 \oplus a_2 \oplus a_6 \oplus a_7 \oplus 0 = 0 \oplus 1 \oplus 0 \oplus 1 \oplus 1 \oplus 0 = 1&lt;/math&gt;
:&lt;math&gt;a_3' = a_0 \oplus a_1 \oplus a_2 \oplus a_3 \oplus a_7 \oplus 0 = 0 \oplus 1 \oplus 0 \oplus 1 \oplus 1 \oplus 0 = 1&lt;/math&gt;
:&lt;math&gt;a_4' = a_0 \oplus a_1 \oplus a_2 \oplus a_3 \oplus a_4 \oplus 0 = 0 \oplus 1 \oplus 0 \oplus 1 \oplus 0 \oplus 0 = 0&lt;/math&gt;
:&lt;math&gt;a_5' = a_1 \oplus a_2 \oplus a_3 \oplus a_4 \oplus a_5 \oplus 1 = 1 \oplus 0 \oplus 1 \oplus 0 \oplus 0 \oplus 1 = 1&lt;/math&gt;
:&lt;math&gt;a_6' = a_2 \oplus a_3 \oplus a_4 \oplus a_5 \oplus a_6 \oplus 1 = 0 \oplus 1 \oplus 0 \oplus 0 \oplus 1 \oplus 1 = 1&lt;/math&gt;
:&lt;math&gt;a_7' = a_3 \oplus a_4 \oplus a_5 \oplus a_6 \oplus a_7 \oplus 0 = 1 \oplus 0 \oplus 0 \oplus 1 \oplus 1 \oplus 0 = 1.&lt;/math&gt;

Thus, &lt;math&gt;\{a'\} = y^7 + y^6 + y^5 + y^3 + y^2 + 1 = \{11101101_2\} = \{\text{ED}_{16}\}&lt;/math&gt;.

===In plane geometry===
[[File:Geometric affine transformation example.png|thumb|left|A simple affine transformation on the real plane]]
[[File:2D affine transformation matrix.svg|thumb|250px|Effect of applying various 2D affine transformation matrices on a unit square. Note that the reflection matrices are special cases of the scaling matrix.]]
In ℝ&lt;sup&gt;2&lt;/sup&gt;, the transformation shown at left is accomplished using the map given by:

:&lt;math&gt;\begin{bmatrix} x \\ y\end{bmatrix} \mapsto \begin{bmatrix} 0&amp;1\\ 2&amp;1 \end{bmatrix}\begin{bmatrix} x \\ y\end{bmatrix} + \begin{bmatrix} -100 \\ -100\end{bmatrix}&lt;/math&gt;

Transforming the three corner points of the original triangle (in red) gives three new points which form the new triangle (in blue).  This transformation skews and translates the original triangle.

In fact, all triangles are related to one another by affine transformations. This is also true for all parallelograms, but not for all quadrilaterals.
{{clear|left}}

==See also==
*[[Anamorphosis]] – artistic applications of affine transformations
*[[Affine geometry]]
*[[3D projection]]
*[[Homography]]
*[[Flat (geometry)]]
*[[Bent function]]

==Notes==
{{reflist|30em}}

== References ==
*{{Citation | last1=Berger | first1=Marcel | author1-link=Marcel Berger | title=Geometry I | publisher=Springer | location=Berlin | isbn= 3-540-11658-3 | year=1987}}
* {{citation | last1=Nomizu|first1=Katsumi|last2=Sasaki|first2=S. |authorlink=Katsumi_Nomizu | title = Affine Differential Geometry| publisher=Cambridge University Press | year=1994|edition=New|isbn=978-0-521-44177-3}}
*{{cite book | last = Sharpe | first = R. W. | title = Differential Geometry: Cartan's Generalization of Klein's Erlangen Program | publisher = Springer | location = New York | year=1997 | isbn=0-387-94732-9}}

==External links==
* {{springer|title=Affine transformation|id=p/a011140}}
* [http://homepages.inf.ed.ac.uk/rbf/HIPR2/affine.htm Geometric Operations: Affine Transform], R. Fisher, S. Perkins, A. Walker and E. Wolfart.
* {{MathWorld | urlname=AffineTransformation | title=Affine Transformation}}
* ''[http://demonstrations.wolfram.com/AffineTransform/ Affine Transform]'' by Bernard Vuilleumier, [[Wolfram Demonstrations Project]].
* [http://www.mathworks.com/discovery/affine-transformation.html Affine Transformation with MATLAB]

{{Computer graphics}}

[[Category:Affine geometry]]
[[Category:Transformation (function)]]
[[Category:Articles containing video clips]]</text>
      <sha1>3o5myz90kapir6rjpxwpywdu20b2d47</sha1>
    </revision>
  </page>
  <page>
    <title>Automath</title>
    <ns>0</ns>
    <id>8532185</id>
    <revision>
      <id>814463068</id>
      <parentid>814450684</parentid>
      <timestamp>2017-12-08T23:41:48Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>resectioning per WP:LEAD</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2390">{{About|the programming language|self-taught individuals|Autodidacticism}}
'''Automath''' ("automating mathematics") was a [[formal language]], devised by [[Nicolaas Govert de Bruijn]] starting in 1967, for expressing complete mathematical theories in such a way that an included automated [[proof checker]] can verify their correctness.

==Overview==
The Automath system included many novel notions that were later adopted and/or reinvented in areas such as [[typed lambda calculus]] and [[explicit substitution]]. [[Dependent types]] is one outstanding example. Automath was also the first practical system that exploited the [[Curry&amp;ndash;Howard correspondence]]. Propositions were represented as sets (called "categories") of their proofs, and the question of provability became a question of non-emptiness ([[type inhabitation]]); de Bruijn was unaware of Howard's work, and stated the correspondence independently.&lt;ref&gt;Morten Heine Sørensen, Paweł Urzyczyn, ''Lectures on the Curry&amp;ndash;Howard isomorphism'', Elsevier, 2006, {{ISBN|0-444-52077-5}}, pp 98-99&lt;/ref&gt;  

L. S. van Benthem Jutting, as part of this Ph.D. thesis in 1976, translated [[Edmund Landau]]'s ''Foundations of Analysis'' into Automath and checked its correctness.
 
Automath was never widely publicized at the time, however, and so never achieved widespread use; nonetheless, it proved very influential in the later development of [[logical framework]]s and [[proof assistant]]s.&lt;ref&gt;R. P. Nederpelt, J. H. Geuvers, R. C. de Vrijer (1994) ''Selected Papers on Automath.'' Vol. 133 of Studies Logic, Elsevier, Amsterdam. {{ISBN|0-444-89822-0}}.&lt;/ref&gt;&lt;ref&gt;F. Kamareddine (2003) ''Thirty-five years of automating mathematics.'' Workshop, Dordrecht, Boston, published by Kluwer Academic Publishers, {{ISBN|1-4020-1656-5}}.&lt;/ref&gt; The [[Mizar system]], a system of writing and checking formalized mathematics that is still in active use, was influenced by Automath.

==See also==
* [[QED manifesto]]

== References ==
{{Reflist}}

==External links==
*[http://www.win.tue.nl/automath/ The Automath Archive] (mirror)
*[http://www.macs.hw.ac.uk/~fairouz/forest/events/automath2002/ Thirty Five years of Automath] homepage of a workshop to celebrate the 35th year of Automath
*[http://www.cs.ru.nl/~freek/aut/ Automath page] by Freek Wiedijk

[[Category:Proof assistants]]
[[Category:Type theory]]

{{Formalmethods-stub}}</text>
      <sha1>roxedvk5l7cf9i5ismblweroggosmiy</sha1>
    </revision>
  </page>
  <page>
    <title>Benjamin Cowie</title>
    <ns>0</ns>
    <id>19624442</id>
    <revision>
      <id>782761796</id>
      <parentid>762311925</parentid>
      <timestamp>2017-05-29T00:52:58Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3142">{{Use dmy dates|date=January 2017}}
{{Use British English|date=January 2017}}
{{Infobox officeholder
| honorific-prefix = [[The Very Reverend]]
| name = Benjamin Cowie
| honorific-suffix = DD&lt;ref&gt;[[The Times]], Friday, 12 November 1880; pg. 10; Issue 30037; col E ''University Intelligence.''&lt;/ref&gt; 
| image         =
| imagesize = 150px
| order         =[[Dean of Exeter]]
| term_start    = 1883
| term_end      = 1900
| monarch       =
| predecessor   =
| successor     =
| order2=[[Dean of Manchester]]
| term_start2=1872
| term_end2=1883
| monarch2=
| primeminister2=
| predecessor2=
| successor2=
| order3=
| term_start3=
| term_end3=
| monarch3=
| primeminister3=
| predecessor3=
| successor3=
| order4=
| term_start4=
| term_end4=
| monarch4=
| primeminister4=
| predecessor4=
| successor4=
| order5=
| term_start5=
| term_end5=
| monarch5=
| primeminister5=
| predecessor5=
| successor5=
| order6        =
| term_start6   =
| term_end6     =
| primeminister6=
| predecessor6  =
| successor6    =
| birth_date    =
| birth_place   =
| death_date    =
| death_place   =
| nationality   = British
| party         =
| religion      = [[Church of England]]
| alma_mater    =
| spouse        =
}}{{Portal|Anglicanism}}

'''Benjamin Morgan Cowie''' was [[Dean of Manchester]] and then [[Dean of Exeter|Exeter]] in the last quarter of the 19th century.

Born on 8 June 1816,&lt;ref&gt;[[Who's Who|“Who was Who”]]1897-1990 London, [[A &amp; C Black]], 1991 {{ISBN|0-7136-3457-X}}&lt;/ref&gt; he was educated at [[St John's College, Cambridge]] and graduated [[List of Wranglers of the University of Cambridge|Senior Wrangler]] in 1839.&lt;ref&gt;"Mr Hopkins’ Men: Cambridge Reform and British Mathematics in the 19th Century" Craik,A.D.D: London, Springer, 2007 {{ISBN|978-1-84628-790-9}}&lt;/ref&gt; [[Ordained]] in 1841 he was successively [[Tutor]], Lecturer and [[Fellow]] at his [[St John's College, Cambridge|old college]].&lt;ref&gt;{{acad|id=CWY833BM|name=Cowie, Benjamin Morgan}}&lt;/ref&gt; Afterwards he was  [[Vicar]] of [[St Lawrence Jewry]] followed by an 11-year spell in [[Manchester Cathedral|Manchester]],&lt;ref&gt;Victoria County History A History of the County of Lancaster: Volume 4 J. Brownbill;, William Farrer,W (ed) 1911&lt;/ref&gt; followed by a further 17 at [[Exeter Cathedral|Exeter]]. He died on 3 May 1900.&lt;ref&gt;[[The Times]], Friday, 4 May 1900; pg. 6; Issue 36133; col G ''Obituary-The Dean Of Exeter''&lt;/ref&gt;

==Notes==
{{Reflist}}
{{S-start}}
{{S-rel|en}}
{{S-bef|before= [[George Hull Bowers]] }}
{{S-ttl|title=[[Dean of Manchester]]|years=1872 &amp;ndash; 1883}}
{{S-aft|after=[[John Oakley (cleric)|John Oakley]]}}
{{S-bef|before= [[Archibald Boyd]] }}
{{S-ttl|title=[[Dean of Exeter]]|years=1883 &amp;ndash; 1900}}
{{S-aft|after=[[Alfred Earle (bishop)|Alfred Earle]]}}
{{End}}
{{Deans of Manchester}}
{{Deans of Exeter}}

{{Authority control}}

{{DEFAULTSORT:Cowie, Benjamin Morgan}}
[[Category:1816 births]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:Fellows of St John's College, Cambridge]]
[[Category:Anglican deans]]
[[Category:Deans of Manchester]]
[[Category:Deans of Exeter]]
[[Category:1900 deaths]]
[[Category:Senior Wranglers]]</text>
      <sha1>iolgb1y18t3lq0jcv8ut2rg0nba36x2</sha1>
    </revision>
  </page>
  <page>
    <title>Cantor–Bernstein theorem</title>
    <ns>0</ns>
    <id>382805</id>
    <revision>
      <id>858812245</id>
      <parentid>706971354</parentid>
      <timestamp>2018-09-09T19:29:11Z</timestamp>
      <contributor>
        <username>Nowak Kowalski</username>
        <id>18891628</id>
      </contributor>
      <comment>Better hatnote — both are thms in elementary set theory, now the hatnote tells you the statement of the other thm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1449">{{For|the theorem that injections from A to B and from B to A imply a bijection between A and B|Schröder–Bernstein theorem}}
In [[set theory]] and [[order theory]], the '''Cantor–Bernstein theorem''' states that the [[cardinality]] of the second type class, the class of [[Countable set|countable]] [[order type]]s, equals the [[cardinality of the continuum]]. It was used by [[Felix Hausdorff]] and named by him after [[Georg Cantor]] and [[Felix Bernstein (mathematician)|Felix Bernstein]]. Cantor constructed a family of countable order types with the cardinality of the continuum, and in his 1901 inaugural dissertation Bernstein proved that such a family can have no higher cardinality.&lt;ref name="plotkin"/&gt;

Because the second type class contains the countable [[ordinal number]]s, which have cardinality &lt;math&gt;\aleph_1&lt;/math&gt;, this result proves (by an inclusion of naturally defined sets) that &lt;math&gt;\aleph_1\le 2^{\aleph_0}&lt;/math&gt;, a relation between these two [[aleph number]]s that (without assuming the [[axiom of choice]]) was not previously known.&lt;ref name="plotkin"&gt;{{cite book|title=Hausdorff on Ordered Sets|volume=25|series=History of Mathematics|editor-first=J. M.|editor-last=Plotkin|publisher=American Mathematical Society|isbn=9780821890516|year=2005|page=3|url=https://books.google.com/books?id=M_skkA3r-QAC&amp;pg=PA3}}.&lt;/ref&gt;

== References ==
{{reflist}}

{{DEFAULTSORT:Cantor-Bernstein theorem}}
[[Category:Order theory]]</text>
      <sha1>scpd7kcezmpsx2hv2k1i5hmfzs4plpv</sha1>
    </revision>
  </page>
  <page>
    <title>Chinese Annals of Mathematics, Series B</title>
    <ns>0</ns>
    <id>30667652</id>
    <revision>
      <id>802270567</id>
      <parentid>797638629</parentid>
      <timestamp>2017-09-25T02:11:24Z</timestamp>
      <contributor>
        <username>Worldbruce</username>
        <id>7329773</id>
      </contributor>
      <comment>updated impact factor from [[Journal Citation Reports]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1779">{{Infobox journal
 | title        = Chinese Annals of Mathematics, Series B
 | cover        = 
 | abbreviation = Chin. Ann. Math. Ser. B
 | discipline   = [[Mathematics]]
 | editor       = {{nowrap|1=[[Tatsien Li]]}}
 | publisher    = [[Springer Science+Business Media|Springer]]
 | frequency    = Bimonthly
 | history      = 1983–present
 | impact       = 0.362
 | impact-year  = 2016
 | url          = https://www.springer.com/mathematics/journal/11401
 | ISSN         = 0252-9599
 | eISSN        = 1860-6261
 | CODEN        = 
 | LCCN         = 84641855 
 | OCLC         = 9198455
 | link1        = http://www.springerlink.com/content/119916 
 | link1-name   = Online access
}}

''''' Chinese Annals of Mathematics, Series B''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] focusing on pure and applied mathematics published by [[Springer Science+Business Media|Springer]].
The journal was founded in 1983 when it was split from ''Chinese Annals of Mathematics''. It is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]].
The journal's 2009 [[Mathematical Citation Quotient|MCQ]] was 0.39. According to the ''[[Journal Citation Reports]]'', the journal has a 2016 [[impact factor]] of 0.362.&lt;ref&gt;{{cite book |year=2017 |chapter=Chinese Annals of Mathematics Series B |title=2016 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Sciences |series=[[Web of Science]]}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* {{Official|1=https://www.springer.com/mathematics/journal/11401}}

[[Category:Mathematics journals]]
[[Category:Publications established in 1983]]
[[Category:English-language journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Bimonthly journals]]
{{math-journal-stub}}</text>
      <sha1>f6neufaw98hmaarkui6hy4u20jo7ivv</sha1>
    </revision>
  </page>
  <page>
    <title>Christoffel symbols</title>
    <ns>0</ns>
    <id>1401020</id>
    <revision>
      <id>862708561</id>
      <parentid>860839044</parentid>
      <timestamp>2018-10-06T05:13:57Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25339">In [[mathematics]] and [[physics]], the '''Christoffel symbols''' are an array of numbers describing a [[metric connection]]&lt;ref&gt;See, for instance, {{harv|Spivak|1999}} and {{harv|Choquet-Bruhat|DeWitt-Morette|1977}}&lt;/ref&gt;.  The metric connection is a specialization of the [[affine connection]] to [[surface (topology)|surface]]s or other [[manifold]]s endowed with a [[metric tensor|metric]], allowing distances to be measured on that surface.  In [[differential geometry]], an affine connection can be defined without any reference to a metric, and many additional concepts follow: [[parallel transport]], [[covariant derivative]]s, [[geodesic]]s, etc. also do not require the concept of a metric.&lt;ref&gt;Ronald Adler, Maurice Bazin, Menahem Schiffer, ''Introduction to General Relativity'' (1965) McGraw-Hill Book Company {{ISBN|0-07-000423-4}} (''See section 2.1'')&lt;/ref&gt;&lt;ref&gt;Charles W. Misner, Kip S. Thorne, John Archibald Wheeler, ''Gravitation'' (1973) W. H,. Freeman {{ISBN|0-7167-0334-3}} (''See chapters 8-11'')&lt;/ref&gt; However, when a metric is available, these concepts can be directly tied to the "shape" of the manifold itself; that shape is determined by how the [[tangent space]] is attached to the [[cotangent space]] by the [[metric tensor]].&lt;ref&gt;Misner, Thorne, Wheeler, ''op. cit.'' (''See chapter 13'')&lt;/ref&gt; Abstractly, one would say that the manifold has an associated ([[orthonormal]]) [[frame bundle]], with each "[[vierbein|frame]]" being a possible choice of a [[coordinate frame]]. An invariant metric implies that the [[structure group]] of the frame bundle is the [[orthogonal group]] {{math|SO(''m'',''n'')}}. As a result, such a manifold is necessarily a ([[pseudo-Riemannian manifold|pseudo-]])[[Riemannian manifold]].&lt;ref&gt;Jurgen Jost, ''Riemannian Geometry and Geometric Analysis'', (2002) Springer-Verlag {{ISBN|3-540-42627-2}}&lt;/ref&gt;&lt;ref&gt;David Bleeker, ''Gauge Theory and Variational Principles'' (1991) Addison-Wesely Publishing Company {{ISBN|0-201-10096-7}}&lt;/ref&gt; The Christoffel symbols provide a concrete representation of the connection of (pseudo-)[[Riemannian geometry]] in terms of coordinates on the manifold. Additional concepts, such as parallel transport, geodesics, etc. can then be expressed in terms of Christoffel symbols.

In general, there are an infinite number of metric connections for a given [[metric tensor]]; however, there is one, unique connection, the [[Levi-Civita connection]], that is free of any [[torsion tensor|torsion]]. It is very common in physics and [[general relativity]] to work almost exclusively with the Levi-Civita connection, by working in [[coordinate frame]]s (called [[Holonomic basis|holonomic coordinates]]) where the torsion vanishes. For example, in [[Euclidean spaces]], the Christoffel symbols describe how the [[Curvilinear_coordinates#Covariant_and_contravariant_bases| local coordinate bases]] change from point to point.

At each point of the underlying {{math|''n''}}-dimensional manifold, for any local coordinate system around that point, the Christoffel symbols are denoted {{math|Γ&lt;sup&gt;''i''&lt;/sup&gt;&lt;sub&gt;''jk''&lt;/sub&gt;}} for {{math|''i'', ''j'', ''k'' {{=}} 1, 2, …, ''n''}}. Each entry of this {{math|''n'' × ''n'' × ''n''}} [[Matrix (mathematics)|array]] is a [[real number]]. Under ''linear'' [[coordinate transformations]] on the manifold, the Christoffel symbols transform like the components of a [[tensor]], but under general coordinate transformations ([[diffeomorphism]]s) they do not.  Most of the algebraic properties of the Christoffel symbols follow from their relationship to the affine connection; only a few follow from the fact that the [[structure group]] is the orthogonal group {{math|SO(''m'',''n'')}} (or the [[Lorentz group]] {{math|SO(3,1)}} for general relativity).

Christoffel symbols are used for performing practical calculations. For example, the [[Riemann curvature tensor]] can be expressed entirely in terms of the Christoffel symbols and their first [[partial derivative]]s. In [[general relativity]], the connection plays the role of the gravitational force field with the corresponding gravitational potential being the metric tensor. When the coordinate system and the metric tensor share some symmetry, many of the {{math|Γ&lt;sup&gt;''i''&lt;/sup&gt;&lt;sub&gt;''jk''&lt;/sub&gt;}} are [[0 (number)|zero]].

The Christoffel symbols are named for [[Elwin Bruno Christoffel]] (1829–1900).&lt;ref name="christoffel" &gt;{{citation|title=Ueber die Transformation der homogenen Differentialausdrücke zweiten Grades|last=Christoffel|first=E.B.|author-link=Elwin Bruno Christoffel|journal=Journal für die reine und angewandte Mathematik|volume=70|pages=46–70|year=1869|url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=GDZPPN002153882&amp;IDDOC=266356}}&lt;/ref&gt;

==Note&lt;!--'Connection coefficient' and 'Connection coefficients' and redirect here--&gt;==
The definitions given below are valid for both [[Riemannian manifold]]s and [[pseudo-Riemannian manifold]]s, such as those of [[general relativity]], with careful distinction being made between upper and lower indices ([[covariance and contravariance of vectors|contra-variant and co-variant]] indices). The formulas hold for either [[sign convention]], unless otherwise noted.

[[Einstein notation|Einstein summation convention]] is used in this article, with vectors indicated by bold font. The '''connection coefficients'''&lt;!--boldface per WP:R#PLA--&gt; of the [[Levi-Civita connection]] (or pseudo-Riemannian connection) expressed in a coordinate basis are called ''Christoffel symbols''.

==Preliminary definitions==
Given a [[coordinate system]] {{math|''x''&lt;sup&gt;''i''&lt;/sup&gt;}} for {{math|''i'' {{=}} 1, 2, …, ''n''}} on an {{math|''n''}}-manifold {{math|''M''}}, the [[tangent space|tangent vectors]]
:&lt;math&gt;\mathbf{e}_i = \frac{\partial\mathbf{x}}{\partial x^i}=\partial_i \mathbf{x}, \quad i=1,2,\dots,n&lt;/math&gt;
where {{math|'''x'''}} is the position vector, define what is referred to as the local [[basis of a vector space|basis]] of the tangent space to {{math|''M''}} at each point of its domain. These can be used to define the [[metric tensor]]:

:&lt;math&gt;g_{ij}=\mathbf{e}_i \cdot \mathbf{e}_j&lt;/math&gt;

and its inverse:

:&lt;math&gt;g^{ij}=\left( g_{ij} \right)^{-1}&lt;/math&gt;

which can in turn be used to define the dual basis:

:&lt;math&gt;\mathbf{e}^i = \mathbf{e}_j g^{ji}, \quad i=1,2,\dots,n&lt;/math&gt;

==Definition in Euclidean space==
In [[Euclidean space]], the general definition given below for the Christoffel symbols of the second kind can be proven to be equivalent to:
:&lt;math&gt;\Gamma^k{}_{ij}
    = \frac{\partial \mathbf{e}_{i}}{\partial x^j} \cdot \mathbf{e}^{k}
    = \frac{\partial \mathbf{e}_{i}}{\partial x^j} \cdot g^{km} \mathbf{e}_{m}
&lt;/math&gt;

Christoffel symbols of the first kind can then be found via [[Ricci_calculus#Raising_and_lowering_indices|index juggling]]:

:&lt;math&gt;\Gamma_{kij}
=   \Gamma^m_{ij}g_{mk}
=  \frac{\partial \mathbf{e}_{i}}{\partial x^j} \cdot \mathbf{e}^{m} g_{mk}
    = \frac{\partial \mathbf{e}_{i}}{\partial x^j} \cdot \mathbf{e}_{k} .
&lt;/math&gt;

Rearranging, we see that:
:&lt;math&gt; \frac{\partial \mathbf{e}_{i}}{\partial x^j}=\Gamma^k{}_{ij} \mathbf{e}_{k} =\Gamma{}_{kij} \mathbf{e}^{k} &lt;/math&gt;

In words, the arrays represented by the Christoffel symbols track how the basis changes from point to point. Symbols of the second kind decompose the change with respect to the basis, while symbols of the first kind decompose it with respect to the dual basis. These expressions fail as definitions when such decompositions are not possible - in particular, when the direction of change does not lie in the tangent space, which can occur on a [[curvature | curved]] surface. In this form, it easy to see the symmetry of the lower or last two indices:

&lt;math&gt;\Gamma^k{}_{ij}=\Gamma^k{}_{ji} &lt;/math&gt; and &lt;math&gt;\Gamma_{kij}=\Gamma_{kji} &lt;/math&gt;,

from the definition of &lt;math&gt; \mathbf{e}_i &lt;/math&gt; and the fact that partial derivatives commute (as long as the manifold and coordinate system [[Symmetry_of_second_derivatives| are well behaved]]).

The same numerical values for Christoffel symbols of the second kind also relate to derivatives of the dual basis, as seen in the expression:

:&lt;math&gt; \frac{\partial \mathbf{e}^{i}}{\partial x^j}=- \Gamma^i_{jk} \mathbf{e}^{k} &lt;/math&gt;,

which we can rearrange as:

:&lt;math&gt; \Gamma^i_{jk} =- \frac{\partial \mathbf{e}^{i}}{\partial x^j}  \cdot \mathbf{e}_{k}&lt;/math&gt;.

== General definition==
===Christoffel symbols of the first kind===
The Christoffel symbols of the first kind can be derived either from the Christoffel symbols of the second kind and the metric,&lt;ref name="ludvigsen"&gt;{{citation |last1=Ludvigsen |first1=Malcolm|title=General Relativity: A Geometrical Approach | year=1999|page=88}}&lt;/ref&gt;
:&lt;math&gt;\Gamma_{cab} = g_{cd} \Gamma^{d}{}_{ab}\,,&lt;/math&gt;
or from the metric alone,&lt;ref name="ludvigsen" /&gt;
:&lt;math&gt;\Gamma_{cab}
=\tfrac12 \left(\frac{\partial g_{ca}}{\partial x^b} + \frac{\partial g_{cb}}{\partial x^a} - \frac{\partial g_{ab}}{\partial x^c} \right)
= \tfrac12\, (g_{ca, b} + g_{cb, a} - g_{ab, c}) 
= \tfrac12\, \left(\partial_{b}g_{ca} + \partial_{a}g_{cb} - \partial_{c}g_{ab}\right) \,.
&lt;/math&gt;

As an alternative notation one also finds&lt;ref name="christoffel"/&gt;&lt;ref name="Chatterjeep114"&gt;{{cite book
 |first1=U. |last1=Chatterjee
 |first2=N. |last2=Chatterjee
 |year=2010
 |title=Vector and Tensor Analysis
 |page=480}}&lt;/ref&gt;&lt;ref name="dirkstruik"&gt;{{cite book
 |first1=D.J. |last1=Struik
 |title=Lectures on Classical Differential Geometry
 |edition=first published in 1988 Dover
 |year=1961
 |page=114}}&lt;/ref&gt;

:&lt;math&gt;\Gamma_{cab} = [ab, c].&lt;/math&gt;
It is worth noting that {{math|[''ab'', ''c''] {{=}} [''ba'', ''c'']}}.&lt;ref name="bishopgoldberg" &gt;{{citation | last1=Bishop|first1=R.L.|last2=Goldberg|first2=| title = Tensor Analysis on Manifolds| year=1968|page=241}}&lt;/ref&gt;

===Christoffel symbols of the second kind (symmetric definition)===
The Christoffel symbols of the second kind are the connection coefficients—in a coordinate basis—of the [[Levi-Civita connection]], and since this connection has zero [[Torsion tensor|torsion]], then in this basis the connection coefficients are symmetric, i.e., {{math|Γ{{su|p=''k''|b=''ij''}} {{=}} Γ{{su|p=''k''|b=''ji''}}}}.&lt;ref name="Chatterjee"&gt;{{cite book
 |first1=U. |last1=Chatterjee
 |first2=N. |last2= Chatterjee
 |title=Vector &amp; Tensor Analysis
 |year=2010
 |page=480
}}&lt;/ref&gt; For this reason, a torsion-free connection is often called ''symmetric''.

In other words, the Christoffel symbols of the second kind&lt;ref name="Chatterjee"/&gt;&lt;ref name="wolfram2ndkind" /&gt;
{{math|Γ&lt;sup&gt;''k''&lt;/sup&gt;&lt;sub&gt;''ij''&lt;/sub&gt;}} (sometimes {{math|Γ{{su|p=''k''|b=''ij''}}}} or {{math|&lt;big&gt;{&lt;/big&gt;{{su|p=''k''|b=''ij''}}&lt;big&gt;}&lt;/big&gt;}})&lt;ref name="christoffel"/&gt;&lt;ref name="Chatterjee"/&gt; are defined as the unique coefficients such that the equation
:&lt;math&gt;\nabla_i \mathrm{e}_j = \Gamma^k{}_{ij}\mathrm{e}_k&lt;/math&gt;
holds, where {{math|∇&lt;sub&gt;''i''&lt;/sub&gt;}} is the [[Levi-Civita connection]] on {{math|''M''}} taken in the coordinate direction {{math|e&lt;sub&gt;''i''&lt;/sub&gt;}} (i.e., {{math|∇&lt;sub&gt;''i''&lt;/sub&gt; ≡ ∇&lt;sub&gt;e&lt;sub&gt;''i''&lt;/sub&gt;&lt;/sub&gt;}}) and where {{math|e&lt;sub&gt;''i''&lt;/sub&gt; {{=}} ∂&lt;sub&gt;''i''&lt;/sub&gt;}} is a local coordinate ([[holonomic basis|holonomic]]) [[basis of a vector space|basis]].

The Christoffel symbols can be derived from the vanishing of the [[covariant derivative]] of the [[metric tensor]] {{math|''g&lt;sub&gt;ik&lt;/sub&gt;''}}:

:&lt;math&gt;
  0 = \nabla_l g_{ik}
    = \frac{\partial g_{ik}}{\partial x^l} - g_{mk}\Gamma^m{}_{il} - g_{im}\Gamma^m{}_{kl}
    = \frac{\partial g_{ik}}{\partial x^l} - 2g_{m(k}\Gamma^m{}_{i)l}.
&lt;/math&gt;

As a shorthand notation, the [[nabla symbol]] and the partial derivative symbols are frequently dropped, and instead a [[semicolon]] and a [[comma]] are used to set off the index that is being used for the derivative.  Thus, the above is sometimes written as
:&lt;math&gt;0 = \,g_{ik;l} = g_{ik,l} - g_{mk} \Gamma^m{}_{il} - g_{im} \Gamma^m{}_{kl} .&lt;/math&gt;

Using that the symbols are symmetric in the lower two indices, one can solve explicitly for the Christoffel symbols as a function of the metric tensor by permuting the indices and resumming:&lt;ref name="bishopgoldberg" /&gt;
:&lt;math&gt;\Gamma^i{}_{kl}=\tfrac12g^{im} \left(\frac{\partial g_{mk}}{\partial x^l} + \frac{\partial g_{ml}}{\partial x^k} - \frac{\partial g_{kl}}{\partial x^m} \right) = \tfrac12g^{im} (g_{mk,l} + g_{ml,k} - g_{kl,m}),&lt;/math&gt;

where {{math|(''g&lt;sup&gt;jk&lt;/sup&gt;'')}} is the inverse of the [[matrix (mathematics)|matrix]] {{math|(''g&lt;sub&gt;jk&lt;/sub&gt;'')}}, defined as (using the [[Kronecker delta]], and [[Einstein notation]] for summation) {{math|''g&lt;sup&gt;ji&lt;/sup&gt;g&lt;sub&gt;ik&lt;/sub&gt;'' {{=}} ''δ&amp;thinsp;&lt;sup&gt;j&lt;/sup&gt;&lt;sub&gt;k&lt;/sub&gt;''}}. Although the Christoffel symbols are written in the same notation as [[Classical treatment of tensors|tensors with index notation]], they are '''not''' [[tensor]]s,&lt;ref&gt;See, for example,  {{harv|Kreyszig|1991}}, page 141&lt;/ref&gt;
since they [[#Change of variable|do not transform like tensors under a change of coordinates]].

===Connection coefficients in a nonholonomic basis===
The Christoffel symbols are most typically defined in a coordinate basis, which is the convention followed here. In other words,  the name '''Christoffel symbols''' is reserved only for coordinate (i.e., [[holonomic basis|holonomic]]) frames. However, the connection coefficients can also be defined in an arbitrary (i.e., nonholonomic) basis of tangent vectors {{math|'''u'''&lt;sub&gt;''i''&lt;/sub&gt;}} by
:&lt;math&gt;\nabla_{\mathbf{u}_i}\mathbf{u}_j = \omega^k{}_{ij}\mathbf{u}_k.&lt;/math&gt;
Explicitly, in terms of the metric tensor, this is&lt;ref name="wolfram2ndkind"&gt;http://mathworld.wolfram.com/ChristoffelSymboloftheSecondKind.html.&lt;/ref&gt;
:&lt;math&gt;\omega^i{}_{kl}=\tfrac12g^{im} \left( g_{mk,l} + g_{ml,k} - g_{kl,m} + c_{mkl}+c_{ml k} - c_{kl m} \right) ,&lt;/math&gt;

where {{math|''c&lt;sub&gt;klm&lt;/sub&gt;'' {{=}} ''g&lt;sub&gt;mp&lt;/sub&gt;c&lt;sub&gt;kl&lt;/sub&gt;&lt;sup&gt;p&lt;/sup&gt;''}} are the [[Commutator (ring theory)|commutation coefficients]] of the basis; that is,
:&lt;math&gt;[\mathbf{u}_k,\mathbf{u}_l] = c_{kl}{}^m \mathbf{u}_m&lt;/math&gt;
where {{math|'''u'''&lt;sub&gt;''k''&lt;/sub&gt;}} are the basis [[vector space|vector]]s and {{math|[ , ]}} is the [[Lie derivative|Lie bracket]]. The standard unit vectors in [[vector fields in cylindrical and spherical coordinates|spherical and cylindrical coordinates]] furnish an example of a basis with non-vanishing commutation coefficients. The difference between the connection in such a frame, and the Levi-Civita connection is known as the [[contorsion tensor]].

===Ricci rotation coefficients (asymmetric definition)===
When we choose the basis {{math|'''X'''&lt;sub&gt;''i''&lt;/sub&gt; ≡ '''u'''&lt;sub&gt;''i''&lt;/sub&gt;}} orthonormal: {{math|''g&lt;sub&gt;ab&lt;/sub&gt;'' ≡ ''η&lt;sub&gt;ab&lt;/sub&gt;'' {{=}} ⟨''X&lt;sub&gt;a&lt;/sub&gt;'', ''X&lt;sub&gt;b&lt;/sub&gt;''⟩}} then {{math|''g&lt;sub&gt;mk,l&lt;/sub&gt;'' ≡ ''η&lt;sub&gt;mk,l&lt;/sub&gt;'' {{=}} 0}}. This implies that
:&lt;math&gt;\omega^i{}_{kl}=\tfrac12\eta^{im} \left( c_{mkl}+c_{ml k} - c_{kl m} \right)&lt;/math&gt;
and the connection coefficients become antisymmetric in the first two indices:
:&lt;math&gt;\omega_{abc} = - \omega_{bac}\, ,&lt;/math&gt;
where
:&lt;math&gt;\omega_{abc} = \eta_{ad}\omega^d{}_{bc}\, .&lt;/math&gt;

In this case, the connection coefficients {{math|''ω&lt;sup&gt;a&lt;/sup&gt;&lt;sub&gt;bc&lt;/sub&gt;''}} are called the '''Ricci rotation coefficients'''.&lt;ref&gt;{{cite journal|title=Dei sistemi di congruenze ortogonali in una varietà qualunque|author=G. Ricci-Curbastro|journal=Mem. Acc. Lincei |volume=2|year=1896|pages=276–322|issue=5}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Ricci's coefficients of rotation|author=H. Levy|journal=Bull. Amer. Math. Soc. |volume=31|year=1925|pages=142–145|issue=3-4|url=http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.bams/1183486405|doi=10.1090/s0002-9904-1925-03996-8}}&lt;/ref&gt;

Equivalently, one can define Ricci rotation coefficients as follows:&lt;ref name="wolfram2ndkind" /&gt;
:&lt;math&gt;\omega^k{}_{ij} := {{\mathbf{u}}}^k \cdot \left( \nabla_j {{\mathbf{u}}}_i \right)\, ,&lt;/math&gt;
where {{math|'''u'''&lt;sub&gt;''i''&lt;/sub&gt;}} is an orthonormal nonholonomic basis and {{math|'''u'''&lt;sup&gt;''k''&lt;/sup&gt; {{=}} ''η&lt;sup&gt;kl&lt;/sup&gt;'''''u'''&lt;sub&gt;''l''&lt;/sub&gt;}} its ''co-basis''.

==Relationship to index-free notation==
Let {{math|''X''}} and {{math|''Y''}} be [[vector fields]] with components {{math|''X&lt;sup&gt;i&lt;/sup&gt;''}} and {{math|''Y&lt;sup&gt;k&lt;/sup&gt;''}}. Then the {{math|''k''}}th component of the covariant derivative of {{math|''Y''}} with respect to {{math|''X''}} is given by
:&lt;math&gt;\left(\nabla_X Y\right)^k = X^i (\nabla_i Y)^k = X^i \left(\frac{\partial Y^k}{\partial x^i} + \Gamma^k{}_{im} Y^m\right).&lt;/math&gt;

Here, the [[Einstein notation]] is used, so repeated indices indicate summation over indices and contraction with the metric tensor serves to raise and lower indices:
:&lt;math&gt;g(X,Y) = X^i Y_i = g_{ik}X^i Y^k = g^{ik}X_i Y_k.&lt;/math&gt;

Keep in mind that {{math|''g&lt;sub&gt;ik&lt;/sub&gt;'' ≠ ''g&lt;sup&gt;ik&lt;/sup&gt;''}} and that {{math|''g&lt;sup&gt;i&lt;/sup&gt;&lt;sub&gt;k&lt;/sub&gt;'' {{=}} ''δ&amp;thinsp;&lt;sup&gt;i&lt;/sup&gt;&lt;sub&gt;k&lt;/sub&gt;''}}, the [[Kronecker delta]]. The convention is that the metric tensor is the one with the lower indices; the correct way to obtain {{math|''g&lt;sup&gt;ik&lt;/sup&gt;''}} from {{math|''g&lt;sub&gt;ik&lt;/sub&gt;''}} is to solve the linear equations {{math|''g&lt;sup&gt;ij&lt;/sup&gt;g&lt;sub&gt;jk&lt;/sub&gt;'' {{=}} ''δ&amp;thinsp;&lt;sup&gt;i&lt;/sup&gt;&lt;sub&gt;k&lt;/sub&gt;''}}.

The statement that the connection is [[torsion tensor|torsion]]-free, namely that
:&lt;math&gt;\nabla_X Y - \nabla_Y X = [X,Y]&lt;/math&gt;
is equivalent to the statement that—in a coordinate basis—the Christoffel symbol is symmetric in the lower two indices:
:&lt;math&gt;\Gamma^i{}_{jk}=\Gamma^i{}_{kj}.&lt;/math&gt;

The index-less transformation properties of a tensor are given by [[pullback (differential geometry)|pullbacks]] for covariant indices, and [[pushforward (differential)|pushforwards]] for contravariant indices. The article on [[Covariant derivative#Coordinate description|covariant derivatives]] provides additional discussion of the correspondence between index-free notation and indexed notation.

==Covariant derivatives of tensors==
The [[covariant derivative]] of a vector field {{math|''V&lt;sup&gt;m&lt;/sup&gt;''}} is
:&lt;math&gt;\nabla_l V^m = \frac{\partial V^m}{\partial x^l} + \Gamma^m{}_{kl} V^k.&lt;/math&gt;

The covariant derivative of a scalar field {{math|''φ''}} is just
:&lt;math&gt;\nabla_i \varphi = \frac{\partial \varphi}{\partial x^i}&lt;/math&gt;

and the covariant derivative of a [[covector]] field {{math|''ω&lt;sub&gt;m&lt;/sub&gt;''}} is
:&lt;math&gt;\nabla_l \omega_m = \frac{\partial \omega_m}{\partial x^l} - \Gamma^k{}_{m l} \omega_k.&lt;/math&gt;

The symmetry of the Christoffel symbol now implies
:&lt;math&gt;\nabla_i\nabla_j \varphi = \nabla_j\nabla_i \varphi&lt;/math&gt;

for any scalar field, but in general the covariant derivatives of higher order tensor fields do not commute (see [[Riemann curvature tensor|curvature tensor]]).

The covariant derivative of a type (2,0) [[tensor]] field {{math|''A&lt;sup&gt;ik&lt;/sup&gt;''}} is
:&lt;math&gt;\nabla_l A^{ik}=\frac{\partial A^{ik}}{\partial x^l} + \Gamma^i{}_{ml} A^{mk} + \Gamma^k{}_{ml} A^{im}, &lt;/math&gt;

that is,
:&lt;math&gt; A^{ik} {}_{;l} = A^{ik} {}_{,l} + A^{mk} \Gamma^i{}_{ml} + A^{im} \Gamma^k{}_{ml}. &lt;/math&gt;

If the tensor field is [[mixed tensor|mixed]] then its covariant derivative is
:&lt;math&gt; A^i {}_{k;l} = A^i {}_{k,l} + A^{m} {}_k \Gamma^i{}_{ml} - A^i {}_m \Gamma^m{}_{kl}, &lt;/math&gt;

and if the tensor field is of type {{math|(0,2)}} then its covariant derivative is
:&lt;math&gt; A_{ik;l} = A_{ik,l} - A_{mk} \Gamma^m{}_{il} - A_{im} \Gamma^m{}_{kl}. &lt;/math&gt;

===Contravariant derivatives of tensors===
To find the contravariant derivative of a vector field, we must first transform 
it into a covariant derivative using the metric tensor

:&lt;math&gt;\nabla^l V^m = g^{il} \nabla_i V^m= g^{il} \partial_i V^m + g^{il} \Gamma^m_{ki} V^k=\partial^l V^m + g^{il} \Gamma^m_{ki} V^k&lt;/math&gt;

==Change of variable==
Under a change of variable from {{math|(''y''&lt;sup&gt;1&lt;/sup&gt;, …, ''y&lt;sup&gt;n&lt;/sup&gt;'')}} to {{math|(''x''&lt;sup&gt;1&lt;/sup&gt;, …, ''x&lt;sup&gt;n&lt;/sup&gt;'')}}, vectors transform as
:&lt;math&gt;\frac{\partial}{\partial y^i} = \frac{\partial x^k}{\partial y^i}\frac{\partial}{\partial x^k}&lt;/math&gt;

and so
:&lt;math&gt;{\bar\Gamma}^k{}_{ij} =
\frac{\partial x^p}{\partial y^i}\,
\frac{\partial x^q}{\partial y^j}\,
\Gamma^r{}_{pq}\,
\frac{\partial y^k}{\partial x^r}
+ 
\frac{\partial y^k}{\partial x^m}\, 
\frac{\partial^2 x^m}{\partial y^i \partial y^j}  
&lt;/math&gt;

where the overline denotes the Christoffel symbols in the {{math|''y''}} coordinate system.  Note that the Christoffel symbol does '''not''' transform as a tensor, but rather as an object in the [[jet bundle]]. More precisely, the Christoffel symbols can be considered as functions on the jet bundle of the frame bundle of {{math|''M''}}, independent of any local coordinate system. Choosing a local coordinate system determines a local section of this bundle, which can then be used to pull back the Christoffel symbols to functions on {{math|''M''}}, though of course these functions then depend on the choice of local coordinate system.

At each point, there exist coordinate systems in which the Christoffel symbols vanish at the point.&lt;ref&gt;This is assuming that the connection is symmetric (e.g., the Levi-Civita connection).  If the connection has [[torsion tensor|torsion]], then only the symmetric part of the Christoffel symbol can be made to vanish.&lt;/ref&gt;  These are called (geodesic) [[normal coordinates]], and are often used in [[Riemannian geometry]].

==Applications to general relativity==
The Christoffel symbols find frequent use in Einstein's theory of [[general relativity]], where [[spacetime]] is represented by a curved 4-dimensional [[Lorentz manifold]] with a [[Levi-Civita connection]]. The [[Einstein field equations]]—which determine the geometry of spacetime in the presence of matter—contain the [[Ricci tensor]], and so calculating the Christoffel symbols is essential. Once the geometry is determined, the paths of particles and light beams are calculated by solving the [[Geodesics in general relativity|geodesic equations]] in which the Christoffel symbols explicitly appear.

==See also==
*[[Basic introduction to the mathematics of curved spacetime]]
*[[Proofs involving Christoffel symbols]]
*[[Differentiable manifold]]
*[[List of formulas in Riemannian geometry]]
*[[Ricci calculus]]
*[[Riemann–Christoffel tensor]]
*[[Gauss–Codazzi equations]]
*[[Deriving the Schwarzschild solution#Calculating the Christoffel symbols|Example computation of Christoffel symbols]]

==Notes==
{{Reflist}}

==References==
*{{citation |last1=Abraham |first1=Ralph|authorlink1=Ralph Abraham (mathematician)| first2=Jerrold E.|last2=Marsden|title=Foundations of Mechanics|year=1978|publisher=Benjamin/Cummings Publishing|location=London|isbn=0-8053-0102-X|pages=See chapter 2, paragraph 2.7.1}}
*{{citation | last1=Bishop|first1=R.L.|author1-link=Richard L. Bishop|last2=Goldberg|first2=S.I. | title = Tensor Analysis on Manifolds| publisher=The Macmillan Company | year=1968|edition=First Dover 1980|isbn=0-486-64039-6}}
*{{citation
  |last = Choquet-Bruhat
  |first = Yvonne
  |authorlink = Yvonne Choquet-Bruhat
  |first2 = Cécile |last2=DeWitt-Morette| title = Analysis, Manifolds and Physics| publisher = Elsevier| year= 1977| location = Amsterdam |isbn = 978-0-7204-0494-4}}
*{{citation |last1= Landau|first1=Lev Davidovich|authorlink1=Lev Davidovich Landau|first2=Evgeny Mikhailovich|last2=Lifshitz|authorlink2=Evgeny Mikhailovich Lifshitz|title=The Classical Theory of Fields|edition=Fourth Revised English|series=[[Course of Theoretical Physics]]|volume=Volume 2|year=1951|publisher=Pergamon Press|location=Oxford|isbn=0-08-025072-6|pages=See chapter 10, paragraphs 85, 86 and 87}}
*{{Citation
| last = Kreyszig
| first = Erwin
| authorlink = Erwin Kreyszig
| title = Differential Geometry
| publisher = [[Dover Publications]]
| year = 1991
| isbn = 978-0-486-66721-8 }}
*{{citation |last1=Misner |first1=Charles W.|first2=Kip S.|last2=Thorne
  |first3=John Archibald|last3=Wheeler|title=Gravitation|year=1970|publisher=W.H. Freeman
  |location=New York|isbn=0-7167-0344-0|pages=See chapter 8, paragraph 8.5}}
*{{citation |last1=Ludvigsen |first1=Malcolm|title=General Relativity: A Geometrical Approach|year=1999|publisher=Cambridge University Press|isbn=0-521-63019-3}}
* {{citation|last=Spivak|first=Michael|authorlink=Michael Spivak|title=A Comprehensive introduction to differential geometry
  |volume=Volume 2
  |year=1999|publisher=Publish or Perish|isbn=0-914098-71-3}}
* {{cite book
 |title=Vector &amp; Tensor Analysis
 |first1=U. |last1=Chatterjee
 |first2=N. |last2=Chatterjee
 |publisher=Academic Publishers
 |isbn=978-93-8059-905-2
 |year=2010
 |page=
 |url=https://books.google.com/books?id=oTeGXkg0tn0C&amp;pg=PA480}}
* {{cite book
 |first1=D.J. |last1=Struik
 |year=1961
 |edition=first published in 1988 Dover
 |title=Lectures on Classical Differential Geometry
 |publisher=Dover 
 |isbn=0-486-65609-8
}}
*{{cite book| author=P.Grinfeld| title=Introduction to Tensor Analysis and the Calculus of Moving Surfaces. | publisher=Springer| year=2014 | isbn=1-4614-7866-9}}

{{tensors}}

{{DEFAULTSORT:Christoffel Symbols}}
[[Category:Riemannian geometry]]
[[Category:Lorentzian manifolds]]
[[Category:Mathematical notation]]
[[Category:Mathematical physics]]
[[Category:Connection (mathematics)]]</text>
      <sha1>ev6r007053glv4or629ndhql2dkvgs4</sha1>
    </revision>
  </page>
  <page>
    <title>Circular convolution</title>
    <ns>0</ns>
    <id>3367262</id>
    <revision>
      <id>871215962</id>
      <parentid>869398251</parentid>
      <timestamp>2018-11-29T17:38:11Z</timestamp>
      <contributor>
        <username>Bob K</username>
        <id>586364</id>
      </contributor>
      <minor/>
      <comment>use \triangleq</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8613">The '''circular convolution''', also known as '''cyclic convolution''',  of two aperiodic functions (i.e. [[Schwartz functions]]) occurs when one of them is [[convolution|convolved in the normal way]] with a [[periodic summation]] of the other function. That situation arises in the context of the [[Discrete Fourier transform#Circular convolution theorem and cross-correlation theorem|circular convolution theorem]]. The identical operation can also be expressed in terms of the periodic summations of &lt;u&gt;both&lt;/u&gt; functions, if the infinite integration interval is reduced to just one period. &amp;nbsp;That situation arises in the context of the [[discrete-time Fourier transform]] (DTFT) and is also called '''periodic convolution'''. &amp;nbsp;In particular, the DTFT of the product of two discrete sequences is the periodic convolution of the DTFTs of the individual sequences.&lt;ref&gt;If a sequence, ''x''[''n''], represents samples of a continuous function, ''x''(''t''), with Fourier transform ''X''(ƒ), its DTFT is a periodic summation of ''X''(ƒ). &amp;nbsp;(see [[Discrete-time Fourier transform#Relationship to sampling]])&lt;/ref&gt;

Let ''x'' be a function with a well-defined periodic summation, ''x''&lt;sub&gt;''T''&lt;/sub&gt;, where:

:&lt;math&gt; x_T(t) \ \triangleq \ \sum_{k=-\infty}^\infty  x(t - kT) = \sum_{k=-\infty}^\infty  x(t + kT).&lt;/math&gt;

If ''h'' is any other function for which the convolution ''x''&lt;sub&gt;''T''&lt;/sub&gt; ∗ ''h'' exists, then the convolution ''x''&lt;sub&gt;''T''&lt;/sub&gt; ∗ ''h''  is periodic and identical to''':'''

:&lt;math&gt;
\begin{align}
(x_T * h)(t)\quad &amp;\triangleq \ \int_{-\infty}^\infty h(\tau)\cdot x_T(t - \tau)\,d\tau \\
&amp;\equiv \int_{t_o}^{t_o+T} h_T(\tau)\cdot x_T(t - \tau)\,d\tau,
\end{align}
&lt;/math&gt;&lt;ref&gt;Proof''':'''

:&lt;math&gt;\int_{-\infty}^\infty  h(\tau)\cdot x_T(t - \tau)\,d\tau&lt;/math&gt;
:::&lt;math&gt;
\begin{align}
&amp;= \sum_{k=-\infty}^\infty  \left[\int_{t_o+kT}^{t_o+(k+1)T} h(\tau)\cdot x_T(t - \tau)\ d\tau\right] \\
&amp;\stackrel{\tau \rightarrow \tau+kT}{=}\  \sum_{k=-\infty}^\infty \left[\int_{t_o}^{t_o+T} h(\tau+kT)\cdot x_T(t - \tau -kT)\ d\tau\right] \\
&amp;= \int_{t_o}^{t_o+T} \left[\sum_{k=-\infty}^\infty h(\tau+kT)\cdot \underbrace{x_T(t - \tau-kT)}_{X_T(t - \tau), \text{ by periodicity}}\right]\ d\tau\\
&amp;= \int_{t_o}^{t_o+T} \underbrace{\left[\sum_{k=-\infty}^\infty  h(\tau+kT)\right]}_{\triangleq \ h_T(\tau)}\cdot x_T(t - \tau)\ d\tau \quad \quad \scriptstyle{(QED)}
\end{align}
&lt;/math&gt;
&lt;/ref&gt;

where ''t''&lt;sub&gt;o&lt;/sub&gt; is an arbitrary parameter and ''h''&lt;sub&gt;''T''&lt;/sub&gt; is a [[periodic summation]] of ''h''.

The second integral is called the '''periodic convolution'''&lt;ref&gt;Jeruchim 2000, pp 73-74.&lt;/ref&gt;&lt;ref name="Uday"&gt;Udayashankara 2010, p 189.&lt;/ref&gt; of functions ''x''&lt;sub&gt;''T''&lt;/sub&gt; and ''h''&lt;sub&gt;''T''&lt;/sub&gt; and is sometimes normalized by 1/''T''.&lt;ref&gt;Oppenheim, pp 388-389&lt;/ref&gt; When ''x''&lt;sub&gt;''T''&lt;/sub&gt; is expressed as the [[periodic summation]] of another function, ''x'', the same operation may also be referred to as a '''circular convolution'''&lt;ref name="Uday"/&gt;&lt;ref&gt;Priemer 1991, pp 286-289.&lt;/ref&gt; of functions ''h'' and ''x''.

== Discrete sequences ==
Similarly, for discrete sequences and period '''N''', we can write the '''circular convolution''' of functions ''h'' and ''x'' as''':'''

:&lt;math&gt;
\begin{align}
(x_N * h)[n] \ &amp;\triangleq \ \sum_{m=-\infty}^\infty  h[m] \cdot x_N[n-m] \\
&amp;= \sum_{m=-\infty}^\infty  \left( h[m] \cdot \sum_{k=-\infty}^\infty  x[n -m -kN] \right).
\end{align}
&lt;/math&gt;

For the special case that the non-zero extent of both ''x'' and ''h'' are ''≤ N'', this is reducible to [[matrix multiplication]] where the kernel of the integral transform is a [[circulant matrix]].

== Example ==
[[Image:Circular convolution example.png|right|frame|488x516px]]
A case of great practical interest is illustrated in the figure.  The duration of the '''x''' sequence is '''N''' (or less), and the duration of the '''h''' sequence is significantly less.  Then many of the values of the circular convolution are identical to values of '''x∗h''',&amp;nbsp; which is actually the desired result when the '''h''' sequence is a [[finite impulse response]] (FIR) filter.  Furthermore, the circular convolution is very efficient to compute, using a [[fast Fourier transform]] (FFT) algorithm and the [[Discrete Fourier transform#Circular convolution theorem and cross-correlation theorem|circular convolution theorem]].

There are also methods for dealing with an '''x''' sequence that is longer than a practical value for '''N'''.  The sequence is divided into segments (''blocks'') and processed piecewise.  Then the filtered segments are carefully pieced back together.  Edge effects are eliminated by &lt;u&gt;overlapping&lt;/u&gt; either the input blocks or the output blocks.  To help explain and compare the methods, we discuss them both in the context of an '''h''' sequence of length 201 and an FFT size of&amp;nbsp;''N''&amp;nbsp;=&amp;nbsp;1024.

'''Overlapping input blocks'''

This method uses a block size equal to the FFT size (1024).  We describe it first in terms of normal or ''linear'' convolution.  When a normal convolution is performed on each block, there are start-up and decay transients at the block edges, due to the filter ''latency'' (200-samples).  Only 824 of the convolution outputs are unaffected by edge effects.  The others are discarded, or simply not computed.  That would cause gaps in the output if the input blocks are contiguous.  The gaps are avoided by overlapping the input blocks by 200 samples.  In a sense, 200 elements from each input block are "saved" and carried over to the next block.  This method is referred to as '''[[Overlap-save method|overlap-save]]''',&lt;ref&gt;Rabiner 1975, pp 65–67.&lt;/ref&gt; although the method we describe next requires a similar "save" with the output samples.

When an FFT is used to compute the 824 unaffected DFT samples, we don't have the option of not computing the affected samples, but the leading and trailing edge-effects are overlapped and added because of circular convolution.  Consequently, the 1024-point inverse FFT (IFFT) output contains only 200 samples of edge effects (which are discarded) and the 824 unaffected samples (which are kept).  To illustrate this, the fourth frame of the figure at right depicts a block that has been periodically (or "circularly") extended, and the fifth frame depicts the individual components of a linear convolution performed on the entire sequence.  The edge effects are where the contributions from the extended blocks overlap the contributions from the original block.  The last frame is the composite output, and the section colored green represents the unaffected portion.

'''Overlapping output blocks'''

This method is known as '''[[Overlap-add method|overlap-add]]'''.&lt;ref&gt;Rabiner 1975, pp 63–65.&lt;/ref&gt;  In our example, it uses contiguous input blocks of size 824 and pads each one with 200 zero-valued samples.  Then it overlaps and adds the 1024-element output blocks.  Nothing is discarded, but 200 values of each output block must be "saved" for the addition with the next block.  Both methods advance only 824 samples per 1024-point IFFT, but overlap-save avoids the initial zero-padding and final addition.

== See also ==
*[[Hilbert transform#Discrete Hilbert transform|Discrete Hilbert transform]]
*[[Circulant matrix]]

== Notes ==
{{Reflist}}

== References ==
*Rabiner, Lawrence R.; Gold, Bernard (1975). ''Theory and application of digital signal processing''. Englewood Cliffs, N.J.: Prentice-Hall. pp 63–67. {{ISBN|0139141014}}
*Oppenheim, Alan V.; Schafer, Ronald W.; Buck, John A. (1999). ''Discrete-time signal processing''. Upper Saddle River, N.J.: Prentice Hall. {{ISBN|0137549202}}.
*Priemer, Roland (July 1991). ''Introductory Signal Processing (Advanced Series in Electrical and Computer Engineering) (v. 6)''. Teaneck, N.J.: World Scientific Pub Co Inc. [https://books.google.com/books?id=QBT7nP7zTLgC&amp;printsec=frontcover&amp;dq=Priemer,+Roland&amp;hl=en&amp;sa=X&amp;ei=J2owUZzANIb_ygGex4HAAg&amp;ved=0CC8Q6AEwAA {{isbn|9971509199}}.
*Jeruchim, Michel C.; Philip Balaban, K. Sam Shanmugan (October 2000). ''Simulation of Communication Systems: Modeling, Methodology and Techniques'' (2nd ed.). New York: Kluwer Academic Publishers. {{isbn|0306462672}}.
*Udayashankara, V. (June 2010). ''Real Time Digital Signal Processing''. India: Prentice-Hall. {{isbn|8120340493}}.
*{{cite book |author1=Oppenheim, Alan V. |author2=Willsky, with S. Hamid | title=Signals and Systems | publisher=Pearson Education | year=1998 | isbn=0-13-814757-4}}.

[[Category:Functional analysis]]
[[Category:Image processing]]
[[Category:Binary operations]]</text>
      <sha1>c5lm6x40qlg6xpqyao0unj1xtidj45s</sha1>
    </revision>
  </page>
  <page>
    <title>Clutching construction</title>
    <ns>0</ns>
    <id>8536059</id>
    <revision>
      <id>845476486</id>
      <parentid>672726662</parentid>
      <timestamp>2018-06-12T01:38:26Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>/* Classifying map construction */ fine-tune tex</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6083">In [[topology]], a branch of mathematics, the '''clutching construction''' is a way of constructing fiber bundles, particularly vector bundles on spheres.

==Definition==
Consider the sphere &lt;math&gt;S^n&lt;/math&gt; as the union of the upper and lower hemispheres &lt;math&gt;D^n_+&lt;/math&gt; and &lt;math&gt;D^n_-&lt;/math&gt; along their intersection, the equator, an &lt;math&gt;S^{n-1}&lt;/math&gt;.

Given trivialized [[fiber bundle]]s with fiber &lt;math&gt;F&lt;/math&gt; and structure group &lt;math&gt;G&lt;/math&gt; over the two disks, then given a map &lt;math&gt;f\colon S^{n-1} \to G&lt;/math&gt; (called the ''clutching map''), glue the two trivial bundles together via ''f''.

Formally, it is the [[coequalizer]] of the inclusions &lt;math&gt;S^{n-1} \times F \to D^n_+ \times F \coprod D^n_- \times F&lt;/math&gt; via &lt;math&gt;(x,v) \mapsto (x,v) \in D^n_+ \times F&lt;/math&gt; and &lt;math&gt;(x,v) \mapsto (x,f(x)(v)) \in D^n_- \times F&lt;/math&gt;: glue the two bundles together on the boundary, with a twist.

Thus we have a map &lt;math&gt;\pi_{n-1} G \to \text{Fib}_F(S^n)&lt;/math&gt;: clutching information on the equator yields a fiber bundle on the total space.

In the case of vector bundles, this yields &lt;math&gt;\pi_{n-1} O(k) \to \text{Vect}_k(S^n)&lt;/math&gt;, and indeed this map is an isomorphism (under connect sum of spheres on the right).

===Generalization===
The above can be generalized by replacing the disks and sphere with any closed triad &lt;math&gt;(X;A,B)&lt;/math&gt;, that is, a space ''X'', together with two closed subsets ''A'' and ''B'' whose union is ''X''. Then a clutching map on &lt;math&gt;A \cap B&lt;/math&gt; gives a vector bundle on ''X''.

===Classifying map construction===

Let &lt;math&gt;p \colon M \to N&lt;/math&gt; be a fibre bundle with fibre &lt;math&gt;F&lt;/math&gt;. Let &lt;math&gt;\mathcal U&lt;/math&gt; be a collection of pairs &lt;math&gt;(U_i,q_i)&lt;/math&gt; such that &lt;math&gt;q_i \colon p^{-1}(U_i) \to N \times F&lt;/math&gt; is a local trivialization of &lt;math&gt;p&lt;/math&gt; over &lt;math&gt;U_i \subset N&lt;/math&gt;. Moreover, we demand that the union of all the sets &lt;math&gt;U_i&lt;/math&gt; is &lt;math&gt;N&lt;/math&gt; (i.e. the collection is an atlas of trivializations &lt;math&gt;\coprod_i U_i = N&lt;/math&gt;). 

Consider the space &lt;math&gt;\coprod_i U_i\times F&lt;/math&gt; modulo the equivalence relation &lt;math&gt;(u_i,f_i)\in U_i \times F&lt;/math&gt; is equivalent to &lt;math&gt;(u_j,f_j)\in U_j \times F&lt;/math&gt; if and only if &lt;math&gt;U_i \cap U_j \neq \phi&lt;/math&gt; and &lt;math&gt;q_i \circ q_j^{-1}(u_j,f_j) = (u_i,f_i)&lt;/math&gt;. By design, the local trivializations &lt;math&gt;q_i&lt;/math&gt; give a fibrewise equivalence between this quotient space and the fibre bundle &lt;math&gt;p&lt;/math&gt;.

Consider the space &lt;math&gt;\coprod_i U_i\times \operatorname{Homeo}(F)&lt;/math&gt; modulo the equivalence relation &lt;math&gt;(u_i,h_i)\in U_i \times \operatorname{Homeo}(F)&lt;/math&gt; is equivalent to &lt;math&gt;(u_j,h_j)\in U_j \times \operatorname{Homeo}(F)&lt;/math&gt; if and only if &lt;math&gt;U_i \cap U_j \neq \phi&lt;/math&gt; and consider &lt;math&gt;q_i \circ q_j^{-1}&lt;/math&gt; to be a map &lt;math&gt;q_i \circ q_j^{-1} : U_i \cap U_j \to \operatorname{Homeo}(F)&lt;/math&gt; then we demand that &lt;math&gt;q_i \circ q_j^{-1}(u_j)(h_j)=h_i&lt;/math&gt;.  That is, in our re-construction of &lt;math&gt;p&lt;/math&gt; we are replacing the fibre &lt;math&gt;F&lt;/math&gt; by the topological group of homeomorphisms of the fibre, &lt;math&gt;\operatorname{Homeo}(F)&lt;/math&gt;. If the structure group of the bundle is known to reduce, you could replace &lt;math&gt;\operatorname{Homeo}(F)&lt;/math&gt; with the reduced structure group.  This is a bundle over &lt;math&gt;B&lt;/math&gt; with fibre &lt;math&gt;\operatorname{Homeo}(F)&lt;/math&gt; and is a principal bundle.  Denote it by &lt;math&gt;p \colon M_p \to N&lt;/math&gt;. The relation to the previous bundle is induced from the principal bundle: &lt;math&gt;(M_p \times F)/\operatorname{Homeo}(F) = M&lt;/math&gt;. 

So we have a principal bundle &lt;math&gt;\operatorname{Homeo}(F) \to M_p \to N&lt;/math&gt;. The theory of classifying spaces gives us an induced '''push-forward''' fibration &lt;math&gt;M_p \to N \to B(\operatorname{Homeo}(F))&lt;/math&gt; where &lt;math&gt;B(Homeo(F))&lt;/math&gt; is the classifying space of &lt;math&gt;\operatorname{Homeo}(F)&lt;/math&gt;. Here is an outline:

Given a &lt;math&gt;G&lt;/math&gt;-principal bundle &lt;math&gt;G \to M_p \to N&lt;/math&gt;, consider the space &lt;math&gt;M_p \times_{G} EG&lt;/math&gt;.  This space is a fibration in two different ways:

1) Project onto the first factor: &lt;math&gt;M_p \times_G EG \to M_p/G = N&lt;/math&gt;. The fibre in this case is &lt;math&gt;EG&lt;/math&gt;, which is a contractible space by the definition of a classifying space. 

2) Project onto the second factor: &lt;math&gt;M_p \times_G EG \to EG/G = BG&lt;/math&gt;.  The fibre in this case is &lt;math&gt;M_p&lt;/math&gt;. 

Thus we have a fibration &lt;math&gt;M_p \to N \simeq M_p\times_G EG \to BG&lt;/math&gt;.  This map is called the '''classifying map''' of the fibre bundle &lt;math&gt;p \colon M \to N&lt;/math&gt; since 1) the principal bundle &lt;math&gt;G \to M_p \to N&lt;/math&gt; is the pull-back of the bundle &lt;math&gt;G \to EG \to BG&lt;/math&gt; along the classifying map and 2) The bundle &lt;math&gt;p&lt;/math&gt; is induced from the principal bundle as above.

===Contrast with twisted spheres===
{{see also|Twisted sphere}}
[[Twisted sphere]]s are sometimes referred to as a "clutching-type" construction, but this is misleading: the clutching construction is properly about fiber bundles.

* In twisted spheres, you glue two ''disks'' along their boundary. The disks are ''a priori'' identified (with the standard disk), and points on the boundary sphere do not in general go to their corresponding points on the other boundary sphere. This is a map &lt;math&gt;S^{n-1} \to S^{n-1}&lt;/math&gt;: the gluing is non-trivial in the base.
* In the clutching construction, you glue two ''bundles'' together over the boundary of their base disks. The boundary spheres are glued together via the standard identification: each point goes to the corresponding one, but each fiber has a twist. This is a map &lt;math&gt;S^{n-1} \to G&lt;/math&gt;: the gluing is trivial in the base, but not in the fibers.

==References==
* [[Allen Hatcher]]'s book-in-progress [http://www.math.cornell.edu/~hatcher/VBKT/VBpage.html Vector Bundles &amp; K-Theory] version 2.0, p.&amp;nbsp;22.

{{DEFAULTSORT:Clutching Construction}}
[[Category:Topology]]
[[Category:Geometric topology]]
[[Category:Differential topology]]
[[Category:Differential structures]]</text>
      <sha1>svgeozde2itvbzxoup5zv3wz64hgnvh</sha1>
    </revision>
  </page>
  <page>
    <title>Composition operator</title>
    <ns>0</ns>
    <id>2702039</id>
    <revision>
      <id>861731031</id>
      <parentid>831143663</parentid>
      <timestamp>2018-09-29T16:16:42Z</timestamp>
      <contributor>
        <username>Mcoupal</username>
        <id>8519392</id>
      </contributor>
      <comment>/* In holomorphic functional calculus */ possessive</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4894">{{for|information about the operator ∘ of composition|function composition|composition of relations}}
In [[mathematics]], the '''composition operator''' &lt;math&gt;C_\phi&lt;/math&gt; with symbol &lt;math&gt;\phi&lt;/math&gt; is a [[linear operator]] defined by the rule

:&lt;math&gt;C_\phi (f) = f \circ\phi&lt;/math&gt;

where &lt;math&gt;f \circ\phi&lt;/math&gt; denotes [[function composition]].

The study of composition operators is covered by [http://www.ams.org/msc/47Bxx.html AMS category 47B33].

==In physics==
In [[physics]], and especially the area of [[dynamical systems]], the composition operator is usually referred to as the '''Koopman operator'''&lt;ref&gt;[[Bernard Koopman|B.O. Koopman]], "Hamiltonian systems and transformations in Hilbert space", (1931) ''Proceedings of the National Academy of Sciences of the USA'', '''17''', pp.&amp;nbsp;315–318.&lt;/ref&gt;&lt;ref&gt;Pierre Gaspard, ''Chaos, scattering and statistical mechanics'', (1998) Cambridge University Press&lt;/ref&gt; (and its wild surge in popularity is sometimes jokingly called "Koopmania"&lt;ref&gt;Shervin Predrag Cvitanović, Roberto Artuso, Ronnie Mainieri, Gregor Tanner, Gábor Vattay, Niall Whelan and Andreas Wirzba , Chaos: Classical and Quantum Appendix H version 15.9, (2017), http://chaosbook.org/version15/chapters/appendMeasure.pdf&lt;/ref&gt;), named after [[Bernard Koopman]]. It is the [[left-adjoint]] of the [[transfer operator]] of Frobenius–Perron.

==In Borel functional calculus==
Using the language of [[category theory]], the composition operator is a [[pull-back]] on the space of [[measurable function]]s; it is adjoint to the [[transfer operator]] in the same way that the pull-back is adjoint to the [[Pushforward measure|push-forward]]; the composition operator is the [[inverse image functor]].

Since the domain considered here is that of [[Borel function]]s, the above describes the Koopman operator as it appears in [[Borel functional calculus]].

==In holomorphic functional calculus==
The [[domain (mathematics)|domain]] of a composition operator can be taken more narrowly, as some [[Banach space]], often consisting of [[holomorphic function]]s: for example, some [[Hardy space]] or [[Bergman space]]. In this case, the composition operator lies in the realm of some [[functional calculus]], such as the [[holomorphic functional calculus]].

Interesting questions posed in the study of composition operators often relate to how the [[Spectrum (functional analysis)|spectral properties]] of the operator depend on the [[function space]].  Other questions include whether &lt;math&gt;C_\phi&lt;/math&gt; is [[compact operator|compact]] or [[trace-class]]; answers typically depend on how the function ''φ'' behaves on the [[boundary (topology)|boundary]] of some domain.

When the transfer operator is a left-[[shift operator]], the Koopman operator, as its adjoint, can be taken to be the right-shift operator. An appropriate basis, explicitly manifesting the shift, can often be found in the [[orthogonal polynomials]]. When these are orthogonal on the real number line, the shift is given by the [[Jacobi operator]].&lt;ref&gt;Gerald Teschl, "Jacobi Operators and Completely Integrable Nonlinear Lattices" (2000) American Mathematical Society. https://www.mat.univie.ac.at/~gerald/ftp/book-jac/jacop.pdf&lt;/ref&gt;  When the polynomials are orthogonal on some region of the complex plane (viz, in [[Bergman space]]), the Jacobi operator is replaced by a [[Hessenberg matrix|Hessenberg operator]]&lt;ref&gt;V. Tomeo, E. Torrano, "Two applications of the subnormality of the Hessenberg matrix related to general orthogonal polynomials" (2011) '''Linear Algebra and its Applications''',  Volume 435, Issue 9, Pages 2314-2320 http://oa.upm.es/id/eprint/8725/contents&lt;/ref&gt;

==Applications==
In mathematics, composition operators commonly occur in the study of [[shift operator]]s, for example, in the [[Beurling–Lax theorem]] and the [[Wold decomposition]]. Shift operators can be studied as one-dimensional [[spin lattice]]s.  Composition operators appear in the theory of [[Aleksandrov–Clark measure]]s.

The [[eigenvalue]] equation of the composition operator is [[Schröder's equation]], and the principal [[eigenfunction]]  ''f(x)'' is often called [[Schröder's equation|Schröder's function]] or [[Koenigs function]].

==See also==
* [[Multiplication operator]]
* [[Composition ring]]
* [[Carleman matrix]]

==References==
&lt;references/&gt;
* C. C. Cowen and [[Barbara MacCluer|B. D. MacCluer]], ''Composition operators on spaces of analytic functions''. Studies in Advanced Mathematics. CRC Press, Boca Raton, Florida, 1995. xii+388 pp. {{ISBN|0-8493-8492-3}}.
* [[Joel Shapiro (mathematician)|J. H. Shapiro]],  ''Composition operators and classical function theory.'' Universitext: Tracts in Mathematics. Springer-Verlag, New York, 1993. xvi+223 pp. {{ISBN|0-387-94067-7}}.

[[Category:Operator theory]]
[[Category:Functional analysis]]
[[Category:Dynamical systems]]</text>
      <sha1>phiploz6fe7zhar3m5pzdqoo4boyh77</sha1>
    </revision>
  </page>
  <page>
    <title>Computational model</title>
    <ns>0</ns>
    <id>2815048</id>
    <revision>
      <id>869200289</id>
      <parentid>803637301</parentid>
      <timestamp>2018-11-17T01:32:52Z</timestamp>
      <contributor>
        <username>StraussInTheHouse</username>
        <id>32545823</id>
      </contributor>
      <minor/>
      <comment>/* top */unreferenced to refimprove</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1731">{{for|mathematical models of computers|Model of computation}}
{{refimprove|date=October 2008}}

A '''computational model''' is a [[mathematical model]] in [[computational science]] that requires extensive [[computational resource]]s to study the behavior of a [[complex system]] by [[computer simulation]].&lt;ref&gt;{{cite book |editor-last=Melnik |editor-first=Roderick |title=Mathematical and Computational Modeling: With Applications in Natural and Social Sciences, Engineering, and the Arts |publisher=Wiley |year=2015 |isbn=978-1-118-85398-6 }}&lt;/ref&gt;

The system under study is often a complex [[nonlinear system]] for which simple, intuitive [[analytical solution]]s are not readily available. Rather than deriving a mathematical analytical solution to the problem, experimentation with the model is done by adjusting the parameters of the system in the computer, and studying the differences in the outcome of the experiments.  Operation theories of the model can be derived/deduced from these computational experiments.

Examples of common computational models are [[weather forecasting]] models, [[earth simulator]] models, [[flight simulator]] models, molecular [[protein folding]] models, and [[neural network]] models.

==References==
{{reflist}}

== See also ==
* [[Reversible computing]]
* [[Agent-based model]]
* [[Artificial neural network]]
* [[Computational linguistics]]
* [[Computational human modeling]]
* [[Decision field theory]]
* [[Cognitive model#Dynamical systems| Dynamical systems model of cognition]]
* [[Membrane computing]]
* [[Ontology (information science)]]
* [[Programming language theory]]
* [[Microscale and macroscale models]]

[[Category:Models of computation]]
[[Category:Mathematical modeling]]</text>
      <sha1>2gljxzx0j64l73hcdj5p9gv4ub2d518</sha1>
    </revision>
  </page>
  <page>
    <title>Cylindric algebra</title>
    <ns>0</ns>
    <id>7852887</id>
    <revision>
      <id>831356303</id>
      <parentid>831355424</parentid>
      <timestamp>2018-03-20T04:50:54Z</timestamp>
      <contributor>
        <username>AugPi</username>
        <id>9565</id>
      </contributor>
      <comment>/* Cylindric set algebras */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6722">The notion of '''cylindric algebra''', invented by [[Alfred Tarski]], arises naturally in the [[Algebraic logic|algebraization]] of [[equational first-order logic]]. This is comparable to the role [[Boolean algebra (structure)|Boolean algebra]]s play for [[propositional logic]]. Indeed, cylindric algebras are Boolean algebras equipped with additional cylindrification operations that model [[Quantification (logic)|quantification]] and equality. They differ from [[polyadic algebra]]s in that the latter do not model equality.

== Definition of a cylindric algebra ==

A '''cylindric algebra of dimension''' &lt;math&gt;\alpha&lt;/math&gt; (where &lt;math&gt;\alpha&lt;/math&gt; is any [[ordinal number]]) is an algebraic structure &lt;math&gt;(A,+,\cdot,-,0,1,c_\kappa,d_{\kappa\lambda})_{\kappa,\lambda&lt;\alpha}&lt;/math&gt; such that &lt;math&gt;(A,+,\cdot,-,0,1)&lt;/math&gt; is a [[Boolean algebra (structure)|Boolean algebra]], &lt;math&gt;c_\kappa&lt;/math&gt; a unary operator on &lt;math&gt;A&lt;/math&gt; for every &lt;math&gt;\kappa&lt;/math&gt; (called a ''cylindrification''), and &lt;math&gt;d_{\kappa\lambda}&lt;/math&gt; a distinguished element of &lt;math&gt;A&lt;/math&gt; for every &lt;math&gt;\kappa&lt;/math&gt; and &lt;math&gt;\lambda&lt;/math&gt; (called a ''diagonal''), such that the following hold:

(C1)  &lt;math&gt;c_\kappa 0=0&lt;/math&gt;

(C2)  &lt;math&gt;x\leq c_\kappa x&lt;/math&gt;

(C3)  &lt;math&gt;c_\kappa(x\cdot c_\kappa y)=c_\kappa x\cdot c_\kappa y&lt;/math&gt;

(C4)  &lt;math&gt;c_\kappa c_\lambda x=c_\lambda c_\kappa x&lt;/math&gt;

(C5)  &lt;math&gt;d_{\kappa\kappa}=1&lt;/math&gt;

(C6)  If &lt;math&gt;\kappa\notin\{\lambda,\mu\}&lt;/math&gt;, then &lt;math&gt;d_{\lambda\mu}=c_\kappa(d_{\lambda\kappa}\cdot d_{\kappa\mu})&lt;/math&gt;

(C7)  If &lt;math&gt;\kappa\neq\lambda&lt;/math&gt;, then &lt;math&gt;c_\kappa(d_{\kappa\lambda}\cdot x)\cdot c_\kappa(d_{\kappa\lambda}\cdot -x)=0&lt;/math&gt;

Assuming a presentation of first-order logic [[Functional predicate#Doing without functional predicates|without function symbol]]s, 
the operator &lt;math&gt;c_\kappa x&lt;/math&gt; models [[existential quantification]] over variable &lt;math&gt;\kappa&lt;/math&gt; in formula &lt;math&gt;x&lt;/math&gt; while the operator &lt;math&gt;d_{\kappa\lambda}&lt;/math&gt; models the equality of variables &lt;math&gt;\kappa&lt;/math&gt; and &lt;math&gt;\lambda&lt;/math&gt;. Henceforth, reformulated using standard logical notations, the axioms read as

(C1)  &lt;math&gt;\exists \kappa. \mathit{false} \Leftrightarrow \mathit{false}&lt;/math&gt;

(C2)  &lt;math&gt;x \Rightarrow \exists \kappa. x&lt;/math&gt;

(C3)  &lt;math&gt;\exists \kappa. (x\wedge \exists \kappa. y) \Leftrightarrow (\exists\kappa. x) \wedge (\exists\kappa. y)&lt;/math&gt;

(C4)  &lt;math&gt;\exists\kappa \exists\lambda. x \Leftrightarrow \exists \lambda \exists\kappa. x&lt;/math&gt;

(C5)  &lt;math&gt;\kappa=\kappa \Leftrightarrow \mathit{true}&lt;/math&gt;

(C6)  If &lt;math&gt;\kappa&lt;/math&gt; is a variable different from both &lt;math&gt;\lambda&lt;/math&gt; and &lt;math&gt;\mu&lt;/math&gt;, then &lt;math&gt;\lambda=\mu \Leftrightarrow \exists\kappa. (\lambda=\kappa \wedge \kappa=\mu)&lt;/math&gt;

(C7)  If &lt;math&gt;\kappa&lt;/math&gt; and &lt;math&gt;\lambda&lt;/math&gt; are different variables, then &lt;math&gt;\exists\kappa. (\kappa=\lambda \wedge x) \wedge \exists\kappa. (\kappa=\lambda\wedge \neg x) \Leftrightarrow \mathit{false}&lt;/math&gt;

== Cylindric set algebras ==
A '''cylindric set algebra of dimension''' &lt;math&gt;\alpha&lt;/math&gt; is an algebraic structure &lt;math&gt;(A, \cup, \cap, -, \empty, X^\alpha, c_\kappa,d_{\kappa\lambda})_{\kappa,\lambda&lt;\alpha}&lt;/math&gt; such that &lt;math&gt;\langle X^\alpha, A \rangle&lt;/math&gt; is a [[field of sets]]. Its axioms are the axioms C1–C7 of a cylindric algebra but with &lt;math&gt;\cup&lt;/math&gt; instead of &lt;math&gt;+&lt;/math&gt;, &lt;math&gt;\cap&lt;/math&gt; instead of &lt;math&gt;\cdot&lt;/math&gt;, set complement for complement, empty set as 0, &lt;math&gt;X^\alpha&lt;/math&gt; as the unit, and &lt;math&gt;\subseteq&lt;/math&gt; instead of &lt;math&gt;\le&lt;/math&gt;. The set ''X'' is the domain of each of the variables and it is called the ''base''.

Any cylindric algebra has a representation as a cylindric set algebra, due to [[Stone's representation theorem]]. It is easier to connect the semantics of first-order predicate logic with cylindric set algebra. (For more details, see the ''Further reading'' section.)

== Generalizations ==

Cylindric algebras have been generalized to the case of [[many-sorted logic]] (Caleiro and Gonçalves 2006), which allows for a better modeling of the duality between first-order formulas and terms.

== Relation to monadic Boolean algebra ==
When &lt;math&gt;\alpha = 1&lt;/math&gt; and &lt;math&gt;\kappa, \lambda&lt;/math&gt; are restricted to being only 0, then &lt;math&gt;c_\kappa&lt;/math&gt; becomes &lt;math&gt;\exists&lt;/math&gt;, the diagonals can be dropped out, and the following theorem of cylindric algebra (Pinter 1973):
:&lt;math&gt; c_\kappa (x + y) = c_\kappa x + c_\kappa y &lt;/math&gt; 
turns into the axiom
:&lt;math&gt; \exists (x + y) = \exists x + \exists y &lt;/math&gt;
of [[monadic Boolean algebra]]. The axiom (C4) drops out. Thus monadic Boolean algebra can be seen as a restriction of cylindric algebra to the one variable case.

==See also==
*[[Abstract algebraic logic]]
*[[Lambda calculus]] and [[Combinatory logic]]—other approaches to modelling quantification and eliminating variables
*[[Hyperdoctrine]]s are a [[Category theory|categorical]] formulation of cylindric algebras
*[[Relation algebra]]s (RA)
*[[Polyadic algebra]]

==References==
* {{Cite journal | author = Charles Pinter | last1 = | first1 = | authorlink= | last2 = | first2 = | doi = | title = A Simple Algebra of First Order Logic | journal = [[Notre Dame Journal of Formal Logic]] | volume = XIV | pages = 361–366| year = 1973 | pmid =  | pmc = | url = https://www.researchgate.net/profile/Charles_Pinter/publication/38356319_A_simple_algebra_of_first_order_logic/links/56fc016808aef6d10d91b894.pdf}}
* [[Leon Henkin]], Monk, J.D., and [[Alfred Tarski]] (1971) ''Cylindric Algebras, Part I''. North-Holland. {{ISBN|978-0-7204-2043-2}}.
* Leon Henkin, Monk, J.D., and Alfred Tarski (1985) ''Cylindric Algebras, Part II''. North-Holland. 
* {{cite book| author=Carlos Caleiro, Ricardo Gonçalves| chapter=On the algebraization of many-sorted logics| title=Proc. 18th int. conf. on Recent trends in algebraic development techniques (WADT)|editor=J. Fiadeiro and P.-Y. Schobbens| year=2006| volume=4409| pages=21–36| publisher=Springer| series=LNCS| isbn=978-3-540-71997-7| contributionurl=http://sqig.math.ist.utl.pt/pub/CaleiroC/06-CG-manysorted.pdf}}

== Further reading ==
* {{Cite journal | last1 = Imieliński | first1 = T. | authorlink= Tomasz Imieliński | last2 = Lipski | first2 = W. | doi = 10.1016/0022-0000(84)90077-1 | title = The relational model of data and cylindric algebras | journal = [[Journal of Computer and System Sciences]] | volume = 28 | pages = 80–102| year = 1984 | pmid =  | pmc = }}

== External links ==
* [http://www.planetmath.org/exampleofcylindricalgebra example of cylindrical algebra] by CWoo on planetmath.org

[[Category:Algebraic logic]]</text>
      <sha1>2kprbh2hag7j5wqwb3n7dcuih2h8572</sha1>
    </revision>
  </page>
  <page>
    <title>Digital Morse theory</title>
    <ns>0</ns>
    <id>17349502</id>
    <revision>
      <id>865522650</id>
      <parentid>862708739</parentid>
      <timestamp>2018-10-24T12:58:03Z</timestamp>
      <contributor>
        <username>Hyh1048576</username>
        <id>5237105</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4952">In [[mathematics]], '''Digital Morse theory'''&lt;ref&gt;{{cite journal | last1 = Cox | first1 = J. | last2 = Karron | first2 = D. B. | last3 = Ferdous | first3 = N. | year = 2003 | title = Topological Zone Organization of Scalar Volume Data | url = https://link.springer.com/article/10.1023%2FA%3A1022113114311 | journal = Journal of Mathematical Imaging and Vision | volume = 18 | issue = 2| pages = 95–117 | doi=10.1023/A:1022113114311}}&lt;/ref&gt;&lt;ref&gt;[http://www.casi.net/DMT.pdf Digital Morse Theory for Scalar Volume Data] .  DIMACS 2003. [https://archive.org/details/drdbkarron_gmail_DMT]&lt;/ref&gt; is a digital adaptation of continuum [[Morse theory]] for scalar [[voxel|volume data]]. This is not about the [[Samuel Morse]]'s [[Morse Code]] of long and short clicks or tones used in manual electric telegraphy.  The term was first promulgated by DB Karron based on the work of JL Cox and DB Karron.

The main utility of a digital Morse theory is that it serves to provide a theoretical basis for [[isosurface]]s (a kind of embedded manifold [[submanifold]] ), and perpendicular [[Streamlines, streaklines, and pathlines|streamlines]] in a digital context. The intended main application of DMT is in the rapid semiautomatic segmentation objects such as organs and anatomic structures from stacks of medical images such as produced by Three Dimensional Computer Tomography by CT or MRI technology.

==DMT Tree==

A '''DMT Tree''' is a digital version of a [[Reeb graph]] or contour tree graph, showing the relationship and connectivity of one isovalued defined object to another. Typically, these are nested objects, one inside another, giving a parent-child relationship, or two objects standing alone with a peer relationship.

The essential insight of Morse theory can be given in a little parable.

==The Fish Tank thought experiment==
The Fish Tank thought experiment: Counting islands as the water level changes

The essential insight of continuous Morse theory can be intuited by a thought experiment. Consider a rectangular glass fish tank. Into this tank, we pour a small quantity of sand such that we have two smoothly sloping small hills, one taller than the other. Now, we fill this tank to the brim with water. We now start a count of the number of island objects as we very slowly drain the tank.

Our initial observation is that there are no island features in our tank scene. As the water level drops, we observe the water level just coincident with the peak of the tallest sand hill. 
We next observe the behavior of the water at the critical peak of the hill. We see a degenerate point island contour, with zero area, zero perimeter, and infinite curvature. A vanishing small change in the water level and this point contour expand into a tiny island. 
We now increment our island object count by +1. 
We continue to drain water from the tank.
We next observe the creation of the second island at the peak of the second little hill. We again increment our island object count by +1 to two objects. Our little sea has two island objects in it.  
As we continue to slowly lower the water level in our little tank sea.
We now observe the two island contours gradually expand and grow toward each other. As the water level reaches the level of the critical saddle point between the two hills the island contours touch at precisely the saddle point. 
We observe that our object count decrements by –1 to give a total island count of one. 
The essential feature of this rubric is that we '''only need to count the peaks and passes to inventory '''all of the''' '''islands in our sea, or objects in our scene. This approach works even as we increase the complexity of the scene.

We can use the same idea of enumerating peak, pits and pass criticalities in a very complex archipelago of island features, at any size scale, or any range of size scales, including noise at any size scale.

The relationship between island features can be
# '''Peers''': two islands that at a lower water level 'merge' into a common parent.
# '''Parent''': an island that splits into two child islands at a higher water level.
# '''Progeny''': An island that has a Parent island feature as related above.

Digital Morse Theory relates Peaks, Pits and Passes to Parents, Peers and Progeny. This gives a cute mnemonic: PPP →  ppp.

As the topology does not care about geometry or dimensionality (directly), complex optimizations in infinite dimensional Hilbert spaces are amenable to this kind of analysis.

==See also==
*[[Topological data analysis]]
*[[Discrete Morse theory]]
* [[Stratified Morse theory|Stratified Morse Theory]]

==References==
&lt;references /&gt;
* {{cite book | author=Sanjay Rana | url=https://books.google.com/books?id=RcxhB69aeNIC | title=Topological Data Structures for Surfaces | publisher=John Wiley and Sons | year=2004 | isbn=978-0470851517}}

[[Category:Computational topology]]
[[Category:Digital geometry]]
[[Category:Medical imaging]]</text>
      <sha1>evnq7191ji60inbp4t4eqjtu738esn9</sha1>
    </revision>
  </page>
  <page>
    <title>Dirk van Dalen</title>
    <ns>0</ns>
    <id>26828544</id>
    <revision>
      <id>865781734</id>
      <parentid>800026336</parentid>
      <timestamp>2018-10-26T03:08:59Z</timestamp>
      <contributor>
        <username>WikiPedant</username>
        <id>596674</id>
      </contributor>
      <comment>tweaked infobox parameter</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3306">[[File:Dirk van Dalen.jpg|thumb|215px|Dirk van Dalen]]
'''Dirk van Dalen''' (born 20 December 1932, [[Amsterdam]]) is a [[Dutch people|Dutch]] [[mathematician]] and [[historian]] of science.

Van Dalen studied mathematics and physics and astronomy at the [[University of Amsterdam]]. Inspired by the work of [[LEJ Brouwer]] and [[Arend Heyting]], he received his Ph.D. in 1963 from the University of Amsterdam for the thesis ''Extension problems in intuitionistic plane Projective geometry.'' From 1964 to 1966 Van Dalen taught logic and mathematics at [[Massachusetts Institute of Technology|MIT]], and later [[University of Oxford|Oxford]]. From 1967 he was professor at the [[University of Utrecht]]. In 2003 Dirk van Dalen was awarded the Academy Medal 2003 of the Royal Dutch Academy of Sciences for bringing the works of Brouwer to international attention.&lt;ref&gt;[https://web.archive.org/web/20101226081522/http://www.knaw.nl/cfdata/nieuws/nieuws_detail.cfm?nieuws__id=145 Persbericht KNAW 2003]&lt;/ref&gt;

== Works ==
* 1958: (with [[Yehoshua Bar-Hillel]] and [[Azriel Levy]]) ''Foundations of Set Theory'', North Holland Publishing
* 1963: Extension problems in intuitionistic plane projective geometry
* 1978: (with H.C. Doets and H. De Swart) ''Sets: Naive, Axiomatic and Applied'', [[Pergamon Press]] {{ISBN|0-08-021166-6}}
* 1980: ''Logic and Structure'', Springer Universitext {{ISBN|3-540-20879-8}}
* 1981: (editor) ''Brouwer's Cambridge Lectures on Intuitionism'' [[Cambridge University Press]] {{ISBN|0521234417}}
* 1988: {{cite book|isbn=0-444-70358-6|title=Constructivism in Mathematics, Vol. 2|last1=Troelstra|first1=Anne|authorlink1=Anne Sjerp Troelstra|last2=van Dalen|first2=Dirk|series=Studies in Logic and the Foundations of Mathematics}}
* 2000: (with [[Heinz-Dieter Ebbinghaus]]) "Zermelo and the Skolem Paradox", [[Bulletin of Symbolic Logic]] 6(2)
* 2001: "Intuitionistic Logic", in: ''The Blackwell Guide to Philosophical Logic'', Lou Goble (editor), Blackwell
* 2013: ''L.E.J. Brouwer - Topologist, Intuitionalist, Philosopher: How mathematics is rooted in life'', Springer-Verlag {{ISBN|9781447146155}}

== References ==
{{Reflist}}

* The article was originally created as a translation (Google) of the corresponding article in [[Dutch Wikipedia]].

== Further reading ==
* ''Dirk van Dalen Festschrift'', [[Henk Barendregt]] en anderen (redactie),   University of Utrecht, Department of Philosophy, 1993
* ''Special issue: a tribute to Dirk van Dalen'', [[Yuri Gurevich]] (redactie), uitgeverij North-Holland, Amsterdam, 1995.

==External links==
* [http://poortman.kb.nl/long2.php?TABEL=T_NAAM&amp;ID=4893 Koninklijke bibliotheek] over Dirk van Dalen
* [https://web.archive.org/web/20100328192916/http://www.phil.uu.nl/~dvdalen/ Homepage] aan de Universiteit van Utrecht
* {{MathGenealogy|id=45022}}

{{Authority control}}

{{DEFAULTSORT:Dalen, Dirk van}}
[[Category:1932 births]]
[[Category:Living people]]
[[Category:Dutch mathematicians]]
[[Category:Dutch historians]]
[[Category:Dutch logicians]]
[[Category:Historians of mathematics]]
[[Category:Historians of science]]
[[Category:Intuitionism]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:Scientists from Amsterdam]]
[[Category:University of Amsterdam alumni]]
[[Category:Utrecht University faculty]]</text>
      <sha1>s08rnkq926n4duai2o00yqz1xantmwk</sha1>
    </revision>
  </page>
  <page>
    <title>Dominated convergence theorem</title>
    <ns>0</ns>
    <id>351853</id>
    <revision>
      <id>801718443</id>
      <parentid>778282804</parentid>
      <timestamp>2017-09-21T12:01:44Z</timestamp>
      <contributor>
        <ip>169.149.45.45</ip>
      </contributor>
      <comment>/* Statement of the theorem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10167">In [[measure theory]], [[Henri Lebesgue|Lebesgue]]'s '''dominated convergence theorem''' provides [[sufficient condition]]s under which [[almost everywhere]] [[convergence (mathematics)|convergence]] of a [[sequence]] of [[Function (mathematics)|functions]] implies convergence in the ''L''&lt;sup&gt;1&lt;/sup&gt; norm. Its power and utility are two of the primary theoretical advantages of [[Lebesgue integral|Lebesgue integration]] over [[Riemann integral|Riemann integration]].

It is widely used in [[probability theory]], since it gives a sufficient condition for the convergence of [[expected value]]s of [[random variable]]s.

==Statement of the theorem==
'''Lebesgue's Dominated Convergence Theorem.''' Let {''f&lt;sub&gt;n&lt;/sub&gt;''} be a sequence of [[real number|real]]-valued [[measurable function]]s on a [[measure space]] {{nowrap|(''S'', Σ, μ)}}. Suppose that the sequence [[Pointwise convergence|converges pointwise]] to a function ''f'' and is dominated by some integrable function ''g'' in the sense that
: &lt;math&gt;    |f_n(x)| \le g(x)&lt;/math&gt;
for all numbers ''n'' in the index set of the sequence and all points ''x'' ∈ ''S''.
Then ''f'' is integrable and
: &lt;math&gt; \lim_{n\to\infty} \int_S |f_n-f|\,d\mu = 0&lt;/math&gt;
which also implies
:&lt;math&gt;\lim_{n\to\infty} \int_S f_n\,d\mu = \int_S f\,d\mu&lt;/math&gt;

'''Remark 1.''' The statement "''g'' is integrable" is meant in the sense of Lebesgue; i.e
:&lt;math&gt;\int_S|g|\,d\mu &lt; \infty.&lt;/math&gt;

'''Remark 2.''' The convergence of the sequence and domination by ''g'' can be relaxed to hold only {{nowrap|μ-}}[[almost everywhere]] provided the measure space {{nowrap|(''S'', Σ, μ)}} is [[measure (mathematics)#Completeness|complete]] or ''f'' is chosen as a measurable function which agrees {{nowrap|μ-almost}} everywhere with the {{nowrap|μ-almost}} everywhere existing pointwise limit. (These precautions are necessary, because otherwise there might exist a [[non-measurable set|non-measurable subset]] of a {{nowrap|μ-null}} set {{nowrap|''N'' ∈ Σ}}, hence ''f'' might not be measurable.)&lt;br&gt;

'''Remark 3.''' If μ(''S'') &lt; ∞, the condition that there is a dominating integrable function ''g'' can be relaxed to [[uniformly integrable|uniform integrability]] of the sequence {''f&lt;sub&gt;n&lt;/sub&gt;''}, see [[Vitali convergence theorem]].

==Proof of the theorem==
Lebesgue's dominated convergence theorem is a special case of the [[Fatou–Lebesgue theorem]]. Below, however, is a direct proof that uses [[Fatou’s lemma]] as the essential tool.

Since ''f'' is the pointwise limit of the sequence ''(f&lt;sub&gt;n&lt;/sub&gt;)'' of measurable functions that are dominated by ''g'', it is also measurable and dominated by ''g'', hence it is integrable. Furthermore (these will be needed later),
: &lt;math&gt;    |f-f_n| \le |f| + |f_n| \leq 2g&lt;/math&gt;
for all ''n'' and
: &lt;math&gt;    \limsup_{n\to\infty} |f-f_n| = 0.&lt;/math&gt;
The second of these is trivially true (by the very definition of ''f''). Using [[Lebesgue integral#Basic theorems of the Lebesgue integral|linearity and monotonicity of the Lebesgue integral]],
: &lt;math&gt;    \left | \int_S{f\,d\mu} - \int_S{f_n\,d\mu} \right|=   \left| \int_S{(f-f_n)\,d\mu} \right|\le \int_S{|f-f_n|\,d\mu}.&lt;/math&gt;
By the [[reverse Fatou lemma]] (it is here that we use the fact that |''f''−''f&lt;sub&gt;n&lt;/sub&gt;''| is bounded above by an integrable function)
: &lt;math&gt;\limsup_{n\to\infty} \int_S |f-f_n|\,d\mu \le \int_S \limsup_{n\to\infty} |f-f_n|\,d\mu = 0,&lt;/math&gt;
which implies that the limit exists and vanishes i.e.
: &lt;math&gt;\lim_{n\to\infty} \int_S |f-f_n|\,d\mu= 0.&lt;/math&gt;
Finally, since
: &lt;math&gt;\lim_{n\to\infty} \left|\int_S fd\mu-\int_S f_nd\mu\right| \leq\lim_{n\to\infty} \int_S |f-f_n|\,d\mu= 0.&lt;/math&gt;
we have that
: &lt;math&gt;\lim_{n\to\infty} \int_S f_n\,d\mu= \int_S f\,d\mu.&lt;/math&gt;
The theorem now follows.

If the assumptions hold only {{nowrap|μ-almost}} everywhere, then there exists a {{nowrap|μ-null}} set {{nowrap|''N'' ∈ Σ}} such that the functions ''f&lt;sub&gt;n&lt;/sub&gt;'' '''1'''&lt;sub&gt;''N''&lt;/sub&gt; satisfy the assumptions everywhere on&amp;nbsp;''S''. Then ''f''(''x'') is the pointwise limit of ''f&lt;sub&gt;n&lt;/sub&gt;''(''x'') for {{nowrap|''x'' ∈ ''S'' \ ''N''}} and {{nowrap|''f''(''x'') {{=}} 0}} for {{nowrap|''x'' ∈ ''N''}}, hence ''f'' is measurable. The values of the integrals are not influenced by this μ-null set&amp;nbsp;''N''.

DCT holds even if f&lt;sub&gt;n&lt;/sub&gt; converges to f in measure (finite measure) and the dominating function is non-negative almost everywhere.

==Discussion of the assumptions==
The assumption that the sequence is dominated by some integrable ''g'' cannot be dispensed with. This may be seen as follows: define {{nowrap|''f&lt;sub&gt;n&lt;/sub&gt;''(''x'') {{=}} ''n''}} for ''x'' in the [[interval (mathematics)|interval]] {{nowrap|(0, 1/''n'']}} and {{nowrap|''f''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') {{=}} 0}} otherwise. Any ''g'' which dominates the sequence must also dominate the pointwise [[supremum]] {{nowrap|''h'' {{=}} sup&lt;sub&gt;''n''&lt;/sub&gt; ''f&lt;sub&gt;n&lt;/sub&gt;''}}. Observe that
: &lt;math&gt;\int_0^1 h(x)\,dx \ge \int_{\frac{1}{m}}^1{h(x)\,dx} = \sum_{n=1}^{m-1} \int_{\left(\frac{1}{n+1},\frac{1}{n}\right]}{h(x)\,dx} \ge \sum_{n=1}^{m-1} \int_{\left(\frac{1}{n+1},\frac{1}{n}\right]}{n\,dx}=\sum_{n=1}^{m-1} \frac{1}{n+1} \to \infty \qquad \text{as }m\to\infty  &lt;/math&gt;
by the divergence of the [[harmonic series (mathematics)|harmonic series]]. Hence, the monotonicity of the Lebesgue integral tells us that there exists no integrable function which dominates the sequence on [0,1]. A direct calculation shows that integration and pointwise limit do not commute for this sequence:
: &lt;math&gt;\int_0^1 \lim_{n\to\infty} f_n(x)\,dx = 0 \neq 1 = \lim_{n\to\infty}\int_0^1 f_n(x)\,dx,&lt;/math&gt;
because the pointwise limit of the sequence is the [[zero function]]. Note that the sequence {''f&lt;sub&gt;n&lt;/sub&gt;''} is not even [[uniformly integrable]], hence also the [[Vitali convergence theorem]] is not applicable.

==Bounded convergence theorem==
One corollary to the dominated convergence theorem is the '''bounded convergence theorem''', which states that if {''f&lt;sub&gt;n&lt;/sub&gt;''} is a sequence of [[uniform boundedness|uniformly bounded]] [[real number|real]]-valued [[measurable function]]s which converges pointwise on a bounded [[measure space]] {{nowrap|(''S'', Σ, μ)}} (i.e. one in which μ(''S'') is finite) to a function ''f'', then the limit ''f'' is an integrable function and

:&lt;math&gt;\lim_{n\to\infty} \int_S{f_n\,d\mu} = \int_S{f\,d\mu}.&lt;/math&gt;

'''Remark:''' The pointwise convergence and uniform boundedness of the sequence can be relaxed to hold only {{nowrap|μ-}}[[almost everywhere]], provided the measure space {{nowrap|(''S'', Σ, μ)}} is [[measure (mathematics)#Completeness|complete]] or ''f'' is chosen as a measurable function which agrees μ-almost everywhere with the {{nowrap|μ-almost}} everywhere existing pointwise limit.

===Proof===
Since the sequence is uniformly bounded, there is a real number ''M'' such that {{nowrap|{{!}}''f&lt;sub&gt;n&lt;/sub&gt;''(''x''){{!}} ≤ ''M''}} for all {{nowrap|''x'' ∈ ''S''}} and for all ''n''. Define {{nowrap|''g''(''x'') {{=}} ''M''}} for all {{nowrap|''x'' ∈ ''S''}}. Then the sequence is dominated by ''g''. Furthermore, ''g'' is integrable since it is a constant function on a set of finite measure. Therefore the result follows from the dominated convergence theorem.

If the assumptions hold only {{nowrap|μ-almost}} everywhere, then there exists a {{nowrap|μ-null}} set {{nowrap|''N'' ∈ Σ}} such that the functions ''f&lt;sub&gt;n&lt;/sub&gt;'''''1'''&lt;sub&gt;''N''&lt;/sub&gt; satisfy the assumptions everywhere on&amp;nbsp;''S''.

==Dominated convergence in ''L''&lt;sup&gt;''p''&lt;/sup&gt;-spaces (corollary)==
Let &lt;math&gt;(\Omega,\mathcal{A},\mu)&lt;/math&gt; be a [[measure space]], {{nowrap| 1 ≤ ''p'' &amp;lt; ∞}} a real number and {''f&lt;sub&gt;n&lt;/sub&gt;''} a sequence of &lt;math&gt;\mathcal{A}&lt;/math&gt;-measurable functions &lt;math&gt;f_n:\Omega\to\R\cup\{\infty\}&lt;/math&gt;.

Assume the sequence {''f&lt;sub&gt;n&lt;/sub&gt;''} converges μ-almost everywhere to an &lt;math&gt;\mathcal{A}&lt;/math&gt;-measurable function ''f'', and is dominated by a &lt;math&gt;g \in L^p&lt;/math&gt; (cf. [[Lp space]]), i.e., for every natural number ''n'' we have: |''f&lt;sub&gt;n&lt;/sub&gt;''| ≤ ''g'', μ-almost everywhere.

Then all ''f&lt;sub&gt;n&lt;/sub&gt;'' as well as ''f'' are in &lt;math&gt;L^p&lt;/math&gt; and the sequence {''f&lt;sub&gt;n&lt;/sub&gt;''} converges to ''f'' in [[Lp-space|the sense of &lt;math&gt;L^p&lt;/math&gt;]], i.e.:

:&lt;math&gt;\lim_{n \to \infty}\|f_n-f\|_p =\lim_{n \to \infty}\left(\int_\Omega |f_n-f|^p \,d\mu\right)^{\frac{1}{p}} = 0.&lt;/math&gt;

Idea of the proof: Apply the original theorem to the function sequence &lt;math&gt;h_n = |f_n-f|^p&lt;/math&gt; with the dominating function &lt;math&gt;(2g)^p&lt;/math&gt;.

==Extensions==
The dominated convergence theorem applies also to measurable functions with values in a [[Banach space]], with the dominating function still being non-negative and integrable as above. The assumption of convergence almost everywhere can be weakened to require only [[convergence in measure]].

==See also==
* [[Convergence of random variables]], [[Convergence in mean]]
* [[Monotone convergence theorem]] (does not require domination by an integrable function but assumes monotonicity of the sequence instead)
* [[Scheffé’s lemma]]
* [[Uniform integrability]]
* [[Vitali convergence theorem]] (a generalization of Lebesgue's dominated convergence theorem)

==References==
{{refbegin}}
* {{cite book
  | last = Bartle | first = R.G.
  | title = The Elements of Integration and Lebesgue Measure
  | year = 1995
  | publisher = Wiley Interscience
  | url = https://books.google.com/books?id=8oNGAAAAYAAJ
  | ref = harv
  }}
* {{cite book
  | last = Royden | first = H.L.
  | title = Real Analysis
  | year = 1988
  | publisher = Prentice Hall
  | url = https://books.google.com/books?id=J4k_AQAAIAAJ
  | ref = harv
  }}
* {{cite book
  | last = Williams | first = D. | authorlink = David Williams (mathematician)
  | title = Probability with martingales
  | year = 1991
  | publisher = Cambridge University Press
  | isbn = 0-521-40605-6
  | ref = harv
  }}
{{refend}}

[[Category:Theorems in real analysis]]
[[Category:Theorems in measure theory]]
[[Category:Probability theorems]]
[[Category:Articles containing proofs]]</text>
      <sha1>5sg6906vlfnrf6e4r6okpfegi6t6pgi</sha1>
    </revision>
  </page>
  <page>
    <title>Elasticity of a function</title>
    <ns>0</ns>
    <id>5902964</id>
    <revision>
      <id>852666437</id>
      <parentid>843454508</parentid>
      <timestamp>2018-07-30T15:06:33Z</timestamp>
      <contributor>
        <ip>164.82.1.13</ip>
      </contributor>
      <comment>/* Estimating point elasticities */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8149">In [[mathematics]], the '''elasticity''' or '''point elasticity''' of a positive [[differentiable function]] ''f'' of a positive variable (positive input, positive output)&lt;ref&gt;The elasticity can also be defined if the input and/or output is consistently negative, or simply away from any points where the input or output is zero, but in practice the elasticity is used for positive quantities.&lt;/ref&gt; at point ''a'' is defined as&lt;ref name=sydsaeter&gt;{{cite book |authorlink=Knut Sydsæter |last=Sydsaeter |first=Knut |last2=Hammond |first2=Peter |title=Mathematics for Economic Analysis |location=Englewood Cliffs, NJ |publisher=Prentice Hall |year=1995 |pages=173–175 |isbn=013583600X }}&lt;/ref&gt;

:&lt;math&gt;Ef(a) = \frac{a}{f(a)}f'(a)&lt;/math&gt;
:&lt;math&gt;=\lim_{x\to a}\frac{f(x)-f(a)}{x-a}\frac{a}{f(a)}=\lim_{x\to a}\frac{f(x)-f(a)}{f(a)}\frac{a}{x-a}=\lim_{x\to a}\frac{1- \frac{f(x)}{f(a)}}{1-\frac{x}{a}}\approx \frac{\%\Delta f(a)}{\%\Delta a} &lt;/math&gt;
or equivalently
:&lt;math&gt;Ef(x) = \frac{d \log f(x)}{d \log x}.&lt;/math&gt;
It is thus the ratio of the relative (percentage) change in the function's output &lt;math&gt;f(x)&lt;/math&gt; with respect to the relative change in its input &lt;math&gt;x&lt;/math&gt;, for infinitesimal changes from a point &lt;math&gt;(a, f(a))&lt;/math&gt;. Equivalently, it is the ratio of the infinitesimal change of the logarithm of a function with respect to the infinitesimal change of the logarithm of the argument. Generalisations to multi-input-multi-output cases also exist in the literature.&lt;ref&gt;[https://ideas.repec.org/a/ijb/journl/v12y2013i1p85-89.html Zelenyuk, V. (2013) "A Note on Equivalences in Measuring Returns to Scale," International Journal of Business and Economics 12:1, pp. 85-89.] and see references therein&lt;/ref&gt;&lt;ref&gt;[https://ideas.repec.org/a/eee/ejores/v228y2013i3p592-600.html Zelenyuk, V. (2013) “A scale elasticity measure for directional distance function and its dual: Theory and DEA estimation.” European Journal of Operational Research 228:3, pp 592–600]&lt;/ref&gt;

The elasticity of a function is a constant &lt;math&gt;\alpha&lt;/math&gt; if and only if the function has the form &lt;math&gt;f(x) = C x ^ \alpha&lt;/math&gt; for a constant &lt;math&gt;C&gt;0&lt;/math&gt;.

The elasticity at a point is the limit of the [[arc elasticity]] between two points as the separation between those two points approaches zero.

The concept of elasticity is widely used in [[economics]]; see [[elasticity (economics)]] for details.&lt;ref&gt;• Hanoch, G. (1975) “The elasticity of scale and the shape of average costs,” American Economic Review 65, pp. 492-497.&lt;/ref&gt;&lt;ref&gt;• Panzar, J.C. and R.D. Willig (1977) “Economies of scale in multi-output production, Quarterly Journal of Economics 91, 481-493.&lt;/ref&gt;&lt;ref&gt;• [https://ideas.repec.org/a/eee/ejores/v228y2013i3p592-600.html Zelenyuk, V. (2013) “A scale elasticity measure for directional distance function and its dual: Theory and DEA estimation.” European Journal of Operational Research 228:3, pp 592–600]&lt;/ref&gt;

==Rules==
Rules for finding the elasticity of products and quotients are simpler than those for derivatives.  Let ''f, g'' be differentiable.  Then&lt;ref name=sydsaeter /&gt;
:&lt;math&gt;E ( f(x) \cdot g(x) ) = E f(x) + E g(x)&lt;/math&gt;
:&lt;math&gt;E \frac{f(x)}{g(x)} = E f(x) - E g(x)&lt;/math&gt;
:&lt;math&gt;E ( f(x) + g(x) ) = \frac{f(x) \cdot E(f(x)) + g(x) \cdot E(g(x))}{f(x) + g(x)} &lt;/math&gt;
:&lt;math&gt;E ( f(x) - g(x) ) = \frac{f(x) \cdot E(f(x)) - g(x) \cdot E(g(x))}{f(x) - g(x)} &lt;/math&gt;

The derivative can be expressed in terms of elasticity as
:&lt;math&gt;D f(x) = \frac{E f(x) \cdot f(x)}{x}&lt;/math&gt;
Let ''a'' and ''b'' be constants.  Then
:&lt;math&gt;E ( a ) = 0 \ &lt;/math&gt;
:&lt;math&gt; E ( a \cdot f(x) ) = E f(x) &lt;/math&gt;,
:&lt;math&gt; E (b x^a) = a \ &lt;/math&gt;.

==Estimating point elasticities==

In economics, the [[elasticity of demand|price elasticity of demand]] refers to the elasticity of a [[demand function]] ''Q''(''P''), and can be expressed as (dQ/dP)/(Q(P)/P) or the ratio of the value of the [[marginal concepts|marginal function]] (dQ/dP) to the value of the average function (Q(P)/P). This relationship provides an easy way of determining whether  a demand curve is elastic or inelastic at a particular point. First, suppose one follows the usual convention in mathematics of plotting the independent variable (P) horizontally and the dependent variable (Q) vertically. Then the slope of a line tangent to the curve at that point is the value of the marginal function at that point. The slope of a [[ray (geometry)|ray]] drawn from the origin through the point is the value of the average function. If the absolute value of the slope of the tangent is greater than the slope of the ray then the function is elastic at the point; if the slope of the secant is greater than the absolute value of the slope of the tangent then the curve is inelastic at the point.&lt;ref&gt;{{cite book |last=Chiang |last2=Wainwright |title=Fundamental Methods of Mathematical Economics |edition=4th |pages=192–193 |publisher=McGraw-Hill |year=2005 |location=Boston |isbn=0070109109 }}&lt;/ref&gt; If the tangent line is extended to the horizontal axis the problem is simply a matter of comparing angles created by the lines and the horizontal axis. If the marginal angle is greater than the average angle then the function is elastic at the point; if the marginal angle is less than the average angle then the function is inelastic at that point. If, however, one follows the convention adopted by economists and plots the independent variable ''P'' on the vertical axis and the dependent variable ''Q'' on the horizontal axis, then the  opposite rules would apply.

The same graphical procedure can also be applied to a [[supply function]] or other functions.

==Semi-elasticity==
A semi-elasticity (or semielasticity) gives the percentage change in ''f(x)'' in terms of a change (not percentage-wise) in ''x''. Algebraically, the semi-elasticity S of a function ''f'' at point ''x'' is &lt;ref&gt;{{cite book |title=Introductory Econometrics: A Modern Approach |edition=2nd |authorlink=Jeffrey Wooldridge |first=Jeffrey |last=Wooldridge |publisher=South-Western |ISBN=0-324-11364-1 |year=2003 |page=656}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=The theory of monetary institutions |first=Lawrence Henry |last=White |ISBN=0-631-21214-0 |year=1999 |location=Malden |publisher=Blackwell |page=148}}&lt;/ref&gt;
:&lt;math&gt;Sf(x) = \frac{1}{f(x)}f'(x) = \frac{d \ln f(x)}{d x}&lt;/math&gt;

The semi-elasticity will be constant for exponential functions of the form, &lt;math&gt;f(x) = C \alpha^x&lt;/math&gt; since,

:&lt;math&gt; \ln{f} = \ln{C\alpha^x} = \ln{C} + x \ln{\alpha} \implies \frac{d \ln{f}}{d x} = \ln{\alpha}. &lt;/math&gt;

An example of semi-elasticity is [[modified duration]] in bond trading.

The term "semi-elasticity" is also sometimes used for the change if ''f(x)'' in terms of a percentage change in ''x''&lt;ref&gt;https://www.stata.com/help.cgi?margins&lt;/ref&gt; which would be
:&lt;math&gt;\frac{d f(x)}{d\ln(x)}=\frac{d f(x)}{dx}x&lt;/math&gt;

==See also==
* [[Arc elasticity]]
* [[Elasticity (economics)]]
* [[Homogeneous function]]
* [[Multiplicative calculus]]

==References==
{{Reflist}}
*{{cite journal |first=Yves |last=Nievergelt |title=The Concept of Elasticity in Economics |journal=SIAM Review |volume=25 |issue=2 |year=1983 |pages=261–265 |doi=10.1137/1025049 }}
* Färe, R., S. Grosskopf and C.A.K. Lovell (1986), “Scale economies and duality” Zeitschrift für Nationalökonomie 46:2, pp.&amp;nbsp;175–182.
* Hanoch, G. (1975) “The elasticity of scale and the shape of average costs,” American Economic Review 65, pp.&amp;nbsp;492–497.
* Panzar, J.C. and R.D. Willig (1977) “Economies of scale in multi-output production, Quarterly Journal of Economics 91, 481-493.
* [https://ideas.repec.org/a/kap/jproda/v42y2014i1p15-24.html Zelenyuk V. (2014) “Scale efficiency and homotheticity: equivalence of primal and dual measures” Journal of Productivity Analysis 42:1,  pp 15-24.]
* [https://ideas.repec.org/a/eee/ejores/v240y2015i1p269-277.html Zelenyuk, V. (2015) "Aggregation of scale efficiency," European Journal of Operational Research, 240:1, pp 269-277.]

{{DEFAULTSORT:Elasticity Of A Function}}
[[Category:Functions and mappings]]
[[Category:Mathematical economics]]</text>
      <sha1>ge2yonbwoy62wxf4fe725s5nttrxv4z</sha1>
    </revision>
  </page>
  <page>
    <title>Fictionalism</title>
    <ns>0</ns>
    <id>1535731</id>
    <revision>
      <id>858991793</id>
      <parentid>858900616</parentid>
      <timestamp>2018-09-11T00:19:44Z</timestamp>
      <contributor>
        <username>Wikiain</username>
        <id>9946363</id>
      </contributor>
      <minor/>
      <comment>/* External links */ ordered</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2398">'''Fictionalism''' is the view in [[philosophy]] according to which statements that appear to be descriptions of the world should not be construed as such, but should instead be understood as cases of "make believe", of pretending to treat something as literally true (a "useful fiction"). Two important strands of fictionalism are [[modal fictionalism]] developed by [[Gideon Rosen]], which states that [[possible worlds]], regardless of whether they exist or not, may be a part of a useful discourse, and [[Philosophy of mathematics#Fictionalism|mathematical fictionalism]] advocated by [[Hartry Field]], which states that talk of numbers and other mathematical objects is nothing more than a convenience for doing science. Also in [[meta-ethics]], there is an equivalent position called moral fictionalism (championed by [[Richard Joyce (philosopher)|Richard Joyce]]). Many modern versions of fictionalism are influenced by the work of [[Kendall Walton]] in aesthetics.

Fictionalism consists in at least the following three theses:
# Claims made within the [[domain of discourse]] are taken to be [[truth-apt]]; that is, true or false
# The domain of discourse is to be interpreted at face value—not reduced to meaning something else 
# The aim of discourse in any given domain is not truth, but some other virtue(s) (e.g., simplicity, explanatory scope).

== See also ==
* [[Color fictionalism]]
* [[Hans Vaihinger]]

== Further reading ==
* {{cite book | last = Balaguer | first = Mark | title = Platonism and Anti-Platonism in Mathematics | publisher = Oxford University Press | location = Oxford | year = 1998 | isbn = 978-0-19-514398-0 }}
* {{cite book | last = Kalderon | first = Mark | title = Moral Fictionalism | publisher = Clarendon Press | location = Oxford | year = 2005 | isbn = 978-0-19-927597-7 }}

== External links ==
* {{cite SEP |url-id=fictionalism-mathematics |title=Mathematical fictionalism |last=Balaguer  |first=Mark|date=2011-10-16}}
* {{cite SEP |url-id=fictionalism |title=Fictionalism |last=Eklund  |first=Matti|date=2015-10-19}}
* {{cite IEP |url-id=mathfict|title=Fictionalism in the Philosophy of Mathematics|last=Leng|first=Mary}}
* {{cite SEP |url-id=fictionalism-modal |title=Modal Fictionalism |last=Nolan  |first=Daniel|date=2016-02-13}}

{{Philosophical logic}}

[[Category:Philosophical methodology]]
[[Category:Theories of deduction]]


{{Philo-stub}}</text>
      <sha1>so7kzc2709qtwqybiqt17pat5tunk7m</sha1>
    </revision>
  </page>
  <page>
    <title>General existence theorem of discontinuous maps</title>
    <ns>0</ns>
    <id>34558799</id>
    <redirect title="Discontinuous linear map" />
    <revision>
      <id>785400351</id>
      <parentid>474602825</parentid>
      <timestamp>2017-06-13T09:46:35Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Redirect category shell|Redirect category shell]]}} for multiple-{{R}} #Rs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="221">#REDIRECT [[Discontinuous linear map#General existence theorem]]

{{Redirect category shell|1=
{{R to section}}
{{R with possibilities}}
}}

[[Category:Theorems in functional analysis]]
[[Category:Functions and mappings]]</text>
      <sha1>ahpc48dp576sh4i2ikx51dx5bj8t9n2</sha1>
    </revision>
  </page>
  <page>
    <title>Gordon Royle</title>
    <ns>0</ns>
    <id>10305032</id>
    <revision>
      <id>787880096</id>
      <parentid>710724893</parentid>
      <timestamp>2017-06-28T03:27:19Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1300">{{Use dmy dates|date=September 2015}}
{{Use Australian English|date=September 2015}}
'''Gordon F. Royle''' is a Professor at the School of Mathematics and Statistics  at [[University of Western Australia|The University of Western Australia]].&lt;ref&gt;[http://school.maths.uwa.edu.au/~gordon Gordon Royle's Homepage at the School of Mathematics and Statistics]&lt;/ref&gt;

Royle is the co-author (with [[Chris Godsil]]) of the book ''Algebraic Graph Theory'' (Springer Verlag, 2001, {{ISBN|0-387-95220-9}}).
Royle is also known for his research into the [[mathematics of Sudoku]] and his search for the Sudoku puzzle with the smallest number of entries that has a unique solution.&lt;ref&gt;[http://school.maths.uwa.edu.au/~gordon/sudokumin.php Gordon Royle's Minimum Sudoku Page]&lt;/ref&gt;

Royle earned his Ph.D. in 1987 from the [[University of Western Australia]] under the supervision of [[Cheryl Praeger]] and [[Brendan McKay]].&lt;ref&gt;{{mathgenealogy|name=Gordon F. Royle|id=35947}}&lt;/ref&gt;

== References ==
&lt;references/&gt;

{{Authority control}}
{{DEFAULTSORT:Royle, Gordon}}
[[Category:People from Western Australia]]
[[Category:Living people]]
[[Category:Australian mathematicians]]
[[Category:Graph theorists]]
[[Category:University of Western Australia alumni]]
[[Category:University of Western Australia faculty]]</text>
      <sha1>9ryz2xxj6xthiykx866gznjxhagdzvw</sha1>
    </revision>
  </page>
  <page>
    <title>Gradient conjecture</title>
    <ns>0</ns>
    <id>600373</id>
    <revision>
      <id>854968141</id>
      <parentid>822415086</parentid>
      <timestamp>2018-08-15T00:54:21Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Annals of Math. → Annals of Mathematics, Annals of Math → Annals of Mathematics, Annals of Mathematicsematics → Annals of Mathematics using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1338">In [[mathematics]], the '''gradient conjecture''', due to [[René Thom]] (1989), was proved in 2000 by three Polish mathematicians, Krzysztof Kurdyka ([[University of Savoie]], France), Tadeusz Mostowski ([[Warsaw University]], Poland) and Adam Parusiński ([[University of Angers]], France). It states that given a real-valued [[analytic function]] ''f'' defined on R&lt;sup&gt;''n''&lt;/sup&gt; and a [[trajectory]] ''x''(''t'') of the [[gradient]] vector field of ''f'' having a [[limit point]] ''x''&lt;sub&gt;0&lt;/sub&gt; ∈ R&lt;sup&gt;''n''&lt;/sup&gt;, where ''f'' has an isolated critical point at ''x''&lt;sub&gt;0&lt;/sub&gt;, there exists a limit (in the [[projective space]] PR&lt;sup&gt;''n-1''&lt;/sup&gt;) for the [[secant line]]s from ''x''(''t'') to ''x''&lt;sub&gt;0&lt;/sub&gt;, as ''t'' tends to zero.

==References==

*A published statement of the conjecture: R. Thom, Problèmes rencontrés dans mon parcours mathématique: un bilan, Publ. Math. IHES 70 (1989), 200-214. (This gradient conjecture due to René Thom was in fact well-known among specialists by the early 70's, having been often discussed during that period by Thom during his weekly seminar on singularities at the [[IHES]].)
*The paper where it is proved: Annals of Mathematics 152 (2000), 763-792. It is available [https://arxiv.org/abs/math.AG/9906212 here].

[[Category:Theorems in analysis]]


{{Mathanalysis-stub}}</text>
      <sha1>4mx985chieu59fqu9nka1upnyhvkclx</sha1>
    </revision>
  </page>
  <page>
    <title>Growth and underinvestment</title>
    <ns>0</ns>
    <id>45152804</id>
    <revision>
      <id>803460732</id>
      <parentid>736819638</parentid>
      <timestamp>2017-10-02T17:47:13Z</timestamp>
      <contributor>
        <username>Galgenstein</username>
        <id>19642374</id>
      </contributor>
      <comment>A thermometer does not switch off the heating. The correct word for the device is thermostat.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17865">The Growth and Underinvestment Archetype is one of the common [[system archetype]] patterns defined as part of the [[system dynamics]] discipline.

[[System dynamics]] is an approach which strives to understand, describe and optimize nonlinear behaviors of complex systems over time, using tools such as feedback loops in order to find a [http://www.donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/ leverage point] of the system. As part of this discipline, several commonly found patterns of system behavior were found, named and described in detail. The Growth and Underinvestment Archetype is one of such patterns.

[[File:Growth and underinvestment.PNG|none|framed|'''Causal loop diagram "Growth and underinvestment"''']]

== Elements of Archetype ==

The system described in the Growth and Underinvestment Archetype consists of three feedback loops. Each feedback loop can be one of two types:&lt;ref&gt;{{cite book|last1=Senge|first1=Peter M.|title=The fifth discipline the art and practice of the learning organization|date=2006|publisher=Broadway Books|location=New York|isbn=978-0-307-47764-4|pages=82–83|edition=Rev.}}&lt;/ref&gt;
* '''Reinforcing loop''' – A reinforcing loop is a type of a feedback loop, where a positive increase of variable A causes an '''increase''' in variable B, which then in turn causes a positive increase in variable A. The behavior of such system in time is an exponential increase in both variables A and B. As an example, consider the behavior of a long-term bank savings account. As your savings accumulate, the more interest per time period you receive, further increasing the balance on your savings account. This is the crowning principle of retirement planning schemes, such as the American [[401k]] pension system. In many cases however, there is a balancing loop to prevent the reinforcing behavior from occurring indefinitely.
* '''Balancing loop''' – A balancing loop is a type of a feedback loop, where a positive increase of variable A causes a '''decrease''' in variable B, which in turn causes a positive increase in variable A. The behavior of such a system leads to the system finding stable state over time. Consider the behavior of a thermostat. The thermostat is a very simple device in its core. If the measured temperature exceeds a certain preconfigured value, the heating is turned off. Otherwise the heating is turned on. The heating in turn influences the temperature, forcing the thermostat to reevaluate its behavior periodically. Since there is a delay in the system (it takes a while for the room to heat up after the heating has been turned on), the temperature in the room will oscillate around the preconfigured value. This happens because when the heating is turned on, it doesn’t have an immediate effect (the body emitting heat must warm up first), causing the temperature to fall below desired level. The same effect is in play when the temperature exceeds the desired value and the heating is turned off, since it takes a while for the heating body to cool down, causing further undesired temperature increases. This behavior could be potentially mitigated by setting two separate temperature thresholds, a lower one as a signal for the heating to activate and a higher one as a signal for the heating to deactivate.

=== Reinforcing loop ===

The reinforcing loop consists of a growing action, such as units of a specific product shipped to a customer, and a current state, such as current demand for a specific product. The growing action causes a positive increase in the current state. The increase of the current state then in turn causes a positive increase of the growing action, thereby creating the reinforcing characteristic of the loop.

As discussed above, this reinforcing loop would have exponential behavior in time, if its growth wouldn’t be bound by the combination of the two balancing loops present in the system.

=== First balancing loop ===

The first balancing loop is directly connected to the reinforcing loop via the current state variable. The first balancing loop consists of a current state and a slowing action (for example exceeding capacity limits). The growth of the current state causes the growth of the slowing action. The growth of the slowing action in turn reduces the current state, thereby creating a balancing loop.

One example of this balancing loop is a situation where a number of units manufactured is increasing (current state), which causes the manufacturing utilization to increase (end eventually exceed capacity). This will make each additional unit of manufacturing more expensive, reducing the growth in units manufacture. One can note that a rubber-banding effect occurs, since the more units are manufactured, the more expensive the manufacturing is. This loop taken in isolation would eventually find a stable state, independently of its beginning state.

=== Second balancing loop ===

The second balancing loop is what differentiates the Growth and Underinvestment Archetype from other archetypes. It is directly connected to the first balancing loop via the slowing action variable. The balancing loop consists of several elements:

* A slowing action
* A performance standard – represents a pressure on upholding a certain standard of the system's output (e.g. the manufactured product)
* A perceived need for investment – the first step toward an actual investment
* An investment
* A delay in investment – represents the time needed for the system to go from a perception of an investment need to actually making the investment. In the real world this element is often caused by hesitation of management to invest in additional capacity.

First, the growth of the slowing action causes growth of the perceived need for investment (e.g. building additional manufacturing capacity). Another factor that can positively contribute to the perceived need to invest is the failure to uphold the performance standard (for example manufacturing error rate). The perceived need to invest positively translates into actually making the investment. The investment made then negatively influences the slowing action (e.g. removal of capacity limits).

The last element of the second balancing loop is the delay in investment, which happens for a variety of reasons, for example hesitation of management to invest in additional capacity.

=== Behavior of Archetype ===
The key to understanding the Growth and Underinvestment Archetype is in the delay in investment. This delay causes the second balancing loop to have longer cycle times than the first balancing loop. That in turn has the following effect:

Since the second balancing loop has a shorter loop cycle, it causes the current state to be reduced, which in turn decreases the slowing action. This happens before an investment is made, in effect reducing the perceived need for investment.

In effect, the first and second reinforcing loop act together as a reinforcing loop to restrict growth.

If it were not for the delay, the whole system would work optimally thanks to timely investments.

==== Difficulties Identifying Archetype ====
At least two factors can contribute to the difficulty of identifying the Growth and Underinvestment Archetype in real-world complex systems.

First, the archetype can be temporarily covered up by [http://www.systems-thinking.org/theWay/ssb/sb.htm shifting the burden], that is, by trying to solve the underlying problem by a symptomatic solution, instead of a fundamental one. This leads to further delaying the investment decision, narrowing the window for effective and timely investment or missing it entirely.

Second, in order to recognize the archetype, a holistic view of the system is required. This can be difficult, since the Growth and Underinvestment Archetype can create many issues that management must attend to,&lt;ref&gt;{{cite book|last1=Senge|first1=Peter M.|title=The fifth discipline the art and practice of the learning organization|date=2006|publisher=Broadway Books|location=New York|isbn=978-0-307-47764-4|page=117|edition=Rev.}}&lt;/ref&gt; in effect preventing them from stepping back and seeing the bigger picture.

=== Optimizing the System ===
When discussing how to optimize the system, it can be beneficial to discuss what a leverage point is.

The leverage point in the system is a place where structural changes can lead to significant and lasting improvements to the system. There are two kinds of leverage points:&lt;ref&gt;{{cite web|title=Leverage Point|url=http://thwink.org/sustain/glossary/LeveragePoint.htm|website=thwink.org|accessdate=31 December 2014}}&lt;/ref&gt;
* '''Low leverage point''' – These points are usually the places in the system where the stress is greatest. However, solving problems at these points usually doesn’t lead to a lasting improvement
* '''High leverage point''' – These points are often hidden in the system, but even smaller changes in these components can lead to significant and lasting improvements in the system as a whole

When dealing with this archetype, several generic strategies can be considered in order to solve the problem the archetype presents.

==== Reduction of Investment Delay ====
The first strategy to consider is whether it is possible to shorten the delay between the perceived need to invest and actually making an investment.

One tool one can utilize in order to shorten the delay is [[Business Process Management]], a field of study focusing on improving the efficiency of business processes. With its help, we might be able to identify the excessive delays in the investment process and shorten the delays or eliminate the parts of process that cause it entirely.

==== Plan Ahead, Identify Growth Potential ====
When the reduction of investment delay is not possible, consider having a plan in advance. This includes monitoring the right [[key performance indicators]] (some KPIs such as [[utilization rate]] might act as an inhibitor for investment, since they frown upon unused capacity) and have an investment plan prepared in advance.

Such plan can also include a stop-gap solution that can temporarily weaken the growth inhibitor, such as hiring outside help in the form of contractors or lending additional capacity. But beware to not let the stop-gap solution become a permanent one, which could become a [[Shifting the Burden]] archetype.

== Example – Home Delivery Pizza ==
A new home delivery-focused pizzeria opens up in the neighborhood. At first, the demand is low, but the pizza’s quality is excellent, as well as the delivery times. After a while, the pizzeria gets noticed and is featured in a local online food blog. As a result, the demand for the pizza rises sharply. But the pizzeria owners are reluctant to purchase more delivery capacity (pizza delivery vehicles and personnel) along with higher pizza production capacity (additional pizza ovens). That results in higher delivery times and a larger percentage of undercooked pizzas, in turn lowering the number of returning customers. As a result, the pressure for additional investment in both delivery and production capacity is eliminated. The pizzeria owners are happy that they held off on the additional investment.

[[File:Home Delivery Pizza Company - Growth and Underinvestment Archetype.PNG|none|framed|Home Delivery Pizza Company - Growth and Underinvestment Archetype]]

Such an example clearly represents a missed opportunity for further growth. It could have been avoided in two ways:
* '''Reduction of the delay in investment.''' If the owners would react quicker, they could have seized the opportunity and convert more of the opportune customers into recurring ones, creating a sustained growth.
* '''Having a plan in advance.''' This might include having a trigger for when a certain amount of pizza is delivered, that will act as an indicator that an investment is needed. Such a trigger needs to be triggered with minimal delay based on the growth variable. Also having a simulation prepared might be helpful, in order to predict the demand in the future based on the current trend, which can be used as a tool to justify the investment, shortening the time needed to make an investment decision.

== Example – Startup Company ==
The application of the Growth and Underinvestment Archetype can be especially crucial for startup businesses, which need to grow fast or might have to face failure to raise additional funds. For them, the growing concern is a [[going concern]].&lt;ref&gt;{{cite web|last1=David|first1=Schneider|title=Growth &amp; Underinvestment - System Archetype 10|url=http://wearethepractitioners.com/library/the-practitioner/2013/08/05/growth-underinvestment---system-archetype-10|website=We Are the Practitioners|accessdate=31 December 2014}}&lt;/ref&gt;

A new startup company focused on developing mobile gaming experiences has recently released its first game after successfully completing the first round of raising capital from investors. The game is initially priced at $5.99 in the Store. After the initial release, the game starts gaining a little bit of traction, but not enough to be considered a success. The company operates as usual, adding more content into the game and fixing bugs. Also, the game has an online component that is sized well for the current audience.

After several weeks, the company comes to a major decision. It will re-release the game as free, instead focusing on selling additional content on the form in in-app purchases. The strategy works and many new users start playing the game. This has two effects:
* The online component of the game becomes overloaded. It becomes clear that an investment is needed to rearchitect the component in order to scale it up without friction 
* The company is making little money from in-app purchases, since it doesn’t have a lot of premium content built for the game yet

Shortly after the free version of the game comes out, the influx of players starts to affect the online component, which occasionally crashes and disconnects users, causing them to save progress they have made in the game. The company redeploys its resources and tries to mitigate the situation by incrementally improving the online component. It is clear, however, that a complete rewrite of the online component is needed on order to eliminate the problem entirely. Therefore the company contacts its investors in order to raise additional funds to rebuild the online component.

Meanwhile, the number of active players dwindles. In response to this fact, as well as the weak cash flow generated by the game, the investor decides to take time to make the investment decision. Unfortunately, the cash flow from the game is not improving, since the remaining user base purchased the content they were interested in and new content is delayed, since most of the developers have been reassigned to solving the online component woes. In response to this, the investor sees the ever-flattening sales and dwindling user base and decides not to invest further resources into the company. A few weeks later, the company runs out of funds and declares bankruptcy.

[[File:Mobile Gaming Startup - Growth and Underinvestment Archetype.PNG|none|framed|Mobile Gaming Startup - Growth and Underinvestment Archetype]]

How such a situation could be prevented:
* The company clearly didn’t calculate with growing quickly and haven’t prepared its infrastructure for it. If it set out to build an architecture that scales out well from the outset, it would diminish the power of the slowing action significantly.
* Instead of redeploying resources when the system was under stress, it might have introduced a stop-gap solution, such as restricting the number of players online in order to keep the standard for the users that got online. Meanwhile, it would produce new content to prove to its investors, that the in-app purchase model will work in the longer-term

== Modification with a Drifting Standard ==
[[File:Growth and Underinvestment Archetype with Drifting Standard.png|none|framed|A casual loop diagram describing the Growth and Underinvestment Archetype with Drifting Standard]]
The Growth and Underinvestment with a Drifting Standard is a special case of the archetype.

It adds an additional relationship between the slowing action and the performance standard.&lt;ref&gt;{{cite web|last1=Sherrer|first1=J. Alex|title=A Project Manager's Guide to Systems Thinking: Part II|url=http://www.projectsmart.co.uk/project-managers-guide-to-systems-thinking-part-2.php|website=Project Smart|accessdate=31 December 2014}}&lt;/ref&gt; When the slowing action is growing (e.g. the backlog of order is increasing in size), it has a negative effect on the performance standard (e.g. raising the maximum permitted time it takes to deliver an order). The rest of the system behaves in the same way as the original archetype.

This additional relationship can have severe consequences, since in some cases the performance standard can have major contribution to pressure exerted on individuals deciding whether to make the investment. With the slowing action actively undermining the performance standard, it can be harder to find the incentive to invest into additional resources.

== Related Archetypes ==
The Growth and Underinvestment Archetype can be considered to be an elaboration o the [http://www.systems-thinking.org/arch/arch.htm#archls Limits to Success archetype].&lt;ref&gt;{{cite web|last1=Bellinger|first1=Gene|author-link=Gene Bellinger|title=Archetypes|url=http://www.systems-thinking.org/arch/arch.htm#archgu|website=Systems Thinking|accessdate=31 December 2014}}&lt;/ref&gt; It adds another feedback loop which effectively elaborates the Limiting State part of the Limits to Success archetype.

==References==
{{Reflist}}

[[Category:Complex systems theory]]
[[Category:Systems theory]]</text>
      <sha1>8523087t23qath6jbwot2avu8y6tz9r</sha1>
    </revision>
  </page>
  <page>
    <title>Homotopy hypothesis</title>
    <ns>0</ns>
    <id>40965653</id>
    <revision>
      <id>812705322</id>
      <parentid>810039735</parentid>
      <timestamp>2017-11-29T11:28:33Z</timestamp>
      <contributor>
        <username>Opus132Mov3</username>
        <id>31568601</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="998">In [[category theory]], a branch of mathematics, [[Grothendieck]]'s '''homotopy hypothesis''' states that the [[∞-groupoid]]s are [[equivalence of categories|equivalent]] to the [[space (mathematics)|topological spaces]]. If we shall to model our ∞-groupoids as [[Kan complex]]es, then the homotopy types of the geometric realizations of these sets give models for every homotopy type. It is conjectured that there are many different "equivalent" models for ∞-groupoids all which can be realized as homotopy types.

== See also ==
*''[[Pursuing Stacks]]''

== References ==
*John Baez, [http://math.ucr.edu/home/baez/homotopy/homotopy.pdf The Homotopy Hypothesis]

== External links ==
*{{nlab|id=homotopy+hypothesis|title=homotopy hypothesis}}
*http://mathoverflow.net/questions/234492/what-is-the-mistake-in-the-proof-of-the-homotopy-hypothesis-by-kapranov-and-voev/

{{Category theory}}
{{Topology}}
[[Category:Homotopy theory]]
[[Category:Higher category theory]]

{{categorytheory-stub}}</text>
      <sha1>d7kxeheip3dez3xdsqj9qlobhqe4ftw</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperperfect number</title>
    <ns>0</ns>
    <id>322170</id>
    <revision>
      <id>862839583</id>
      <parentid>862839311</parentid>
      <timestamp>2018-10-07T01:34:52Z</timestamp>
      <contributor>
        <username>Bubba73</username>
        <id>218586</id>
      </contributor>
      <minor/>
      <comment>/* Books */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10291">In [[mathematics]], a '''''k''-hyperperfect number''' is a [[natural number]] ''n'' for which the equality ''n'' = 1 + ''k''(''σ''(''n'')  &amp;minus; ''n''  &amp;minus; 1) holds, where ''σ''(''n'') is the [[divisor function]] (i.e., the sum of all positive [[divisor]]s of ''n''). A '''hyperperfect number''' is a ''k''-hyperperfect number for some integer ''k''. Hyperperfect numbers generalize [[perfect number]]s, which are 1-hyperperfect.

The first few numbers in the sequence of ''k''-hyperperfect numbers are 6, 21, 28, 301, 325, 496, 697, ... {{OEIS|A034897}}, with the corresponding values of ''k'' being 1, 2, 1, 6, 3, 1, 12, ... {{OEIS|id=A034898}}. The first few ''k''-hyperperfect numbers that are not perfect are 21, 301, 325, 697, 1333, ... {{OEIS|A007592}}.

==List of hyperperfect numbers==
The following table lists the first few ''k''-hyperperfect numbers for some values of ''k'', together with the sequence number in the [[On-Line Encyclopedia of Integer Sequences]] (OEIS) of the sequence of ''k''-hyperperfect numbers:

{| class="wikitable"
! ''k'' !! OEIS !! Some known ''k''-hyperperfect numbers
|-
| 1 || {{OEIS2C|A000396}} || 6, 28, 496, 8128, 33550336, ...
|-
| 2 || {{OEIS2C|A007593}} || 21, 2133, 19521, 176661, 129127041, ...
|-
| 3 || &amp;nbsp; || 325, ...
|-
| 4 || &amp;nbsp; || 1950625, 1220640625, ...
|-
| 6 || {{OEIS2C|A028499}} || 301, 16513, 60110701, 1977225901, ...
|-
| 10 || &amp;nbsp; || 159841, ...
|-
| 11 || &amp;nbsp; || 10693, ...
|-
| 12 || {{OEIS2C|A028500}} || 697, 2041, 1570153, 62722153, 10604156641, 13544168521, ...
|-
| 18 || {{OEIS2C|A028501}} || 1333, 1909, 2469601, 893748277, ...
|-
| 19 || &amp;nbsp; || 51301, ...
|-
| 30 || &amp;nbsp; || 3901, 28600321, ...
|-
| 31 || &amp;nbsp; || 214273, ...
|-
| 35 || &amp;nbsp; || 306181, ...
|-
| 40 || &amp;nbsp; || 115788961, ...
|-
| 48 || &amp;nbsp; || 26977, 9560844577, ...
|-
| 59 || &amp;nbsp; || 1433701, ...
|-
| 60 || &amp;nbsp; || 24601, ...
|-
| 66 || &amp;nbsp; || 296341, ...
|-
| 75 || &amp;nbsp; || 2924101, ...
|-
| 78 || &amp;nbsp; || 486877, ...
|-
| 91 || &amp;nbsp; || 5199013, ...
|-
| 100 || &amp;nbsp; || 10509080401, ...
|-
| 108 || &amp;nbsp; || 275833, ...
|-
| 126 || &amp;nbsp; || 12161963773, ...
|-
| 132 || &amp;nbsp; || 96361, 130153, 495529, ...
|-
| 136 || &amp;nbsp; || 156276648817, ...
|-
| 138 || &amp;nbsp; || 46727970517, 51886178401, ...
|-
| 140 || &amp;nbsp; || 1118457481, ...
|-
| 168 || &amp;nbsp; || 250321, ...
|-
| 174 || &amp;nbsp; || 7744461466717, ...
|-
| 180 || &amp;nbsp; || 12211188308281, ...
|-
| 190 || &amp;nbsp; || 1167773821, ...
|-
| 192 || &amp;nbsp; || 163201, 137008036993, ...
|-
| 198 || &amp;nbsp; || 1564317613, ...
|-
| 206 || &amp;nbsp; || 626946794653, 54114833564509, ...
|-
| 222 || &amp;nbsp; || 348231627849277, ...
|-
| 228 || &amp;nbsp; || 391854937, 102744892633, 3710434289467, ...
|-
| 252 || &amp;nbsp; || 389593, 1218260233, ...
|-
| 276 || &amp;nbsp; || 72315968283289, ...
|-
| 282 || &amp;nbsp; || 8898807853477, ...
|-
| 296 || &amp;nbsp; || 444574821937, ...
|-
| 342 || &amp;nbsp; || 542413, 26199602893, ...
|-
| 348 || &amp;nbsp; || 66239465233897, ...
|-
| 350 || &amp;nbsp; || 140460782701, ...
|-
| 360 || &amp;nbsp; || 23911458481, ...
|-
| 366 || &amp;nbsp; || 808861, ...
|-
| 372 || &amp;nbsp; || 2469439417, ...
|-
| 396 || &amp;nbsp; || 8432772615433, ...
|-
| 402 || &amp;nbsp; || 8942902453, 813535908179653, ...
|-
| 408 || &amp;nbsp; || 1238906223697, ...
|-
| 414 || &amp;nbsp; || 8062678298557, ...
|-
| 430 || &amp;nbsp; || 124528653669661, ...
|-
| 438 || &amp;nbsp; || 6287557453, ...
|-
| 480 || &amp;nbsp; || 1324790832961, ...
|-
| 522 || &amp;nbsp; || 723378252872773, 106049331638192773, ...
|-
| 546 || &amp;nbsp; || 211125067071829, ...
|-
| 570 || &amp;nbsp; || 1345711391461, 5810517340434661, ...
|-
| 660 || &amp;nbsp; || 13786783637881, ...
|-
| 672 || &amp;nbsp; || 142718568339485377, ...
|-
| 684 || &amp;nbsp; || 154643791177, ...
|-
| 774 || &amp;nbsp; || 8695993590900027, ...
|-
| 810 || &amp;nbsp; || 5646270598021, ...
|-
| 814 || &amp;nbsp; || 31571188513, ...
|-
| 816 || &amp;nbsp; || 31571188513, ...
|-
| 820 || &amp;nbsp; || 1119337766869561, ...
|-
| 968 || &amp;nbsp; || 52335185632753, ...
|-
| 972 || &amp;nbsp; || 289085338292617, ...
|-
| 978 || &amp;nbsp; || 60246544949557, ...
|-
| 1050 || &amp;nbsp; || 64169172901, ...
|-
| 1410 || &amp;nbsp; || 80293806421, ...
|-
| 2772 || {{OEIS2C|A028502}} || 95295817, 124035913, ...
|-
| 3918 || &amp;nbsp; || 61442077, 217033693, 12059549149, 60174845917, ...
|-
| 9222 || &amp;nbsp; || 404458477, 3426618541, 8983131757, 13027827181, ...
|-
| 9828 || &amp;nbsp; || 432373033, 2797540201, 3777981481, 13197765673, ...
|-
| 14280 || &amp;nbsp; || 848374801, 2324355601, 4390957201, 16498569361, ...
|-
| 23730 || &amp;nbsp; || 2288948341, 3102982261, 6861054901, 30897836341, ...
|-
| 31752 || {{OEIS2C|A034916}} || 4660241041, 7220722321, 12994506001, 52929885457, 60771359377, ...
|-
| 55848 || &amp;nbsp; || 15166641361, 44783952721, 67623550801, ...
|-
| 67782 || &amp;nbsp; || 18407557741, 18444431149, 34939858669, ...
|-
| 92568 || &amp;nbsp; || 50611924273, 64781493169, 84213367729, ...
|-
| 100932 || &amp;nbsp; || 50969246953, 53192980777, 82145123113, ...
|}

It can be shown that if ''k'' &gt; 1 is an [[Even and odd numbers|odd]] [[integer]] and ''p'' = (3''k'' + 1) / 2 and ''q'' = 3''k'' + 4 are [[prime number]]s, then ''p''²''q'' is ''k''-hyperperfect; Judson S. McCranie has conjectured in 2000 that all ''k''-hyperperfect numbers for odd ''k'' &gt; 1 are of this form, but the hypothesis has not been proven so far. Furthermore, it can be proven that if ''p'' ≠ ''q'' are odd primes and ''k'' is an integer such that ''k''(''p'' + ''q'') = ''pq'' - 1, then ''pq'' is ''k''-hyperperfect.

It is also possible to show that if ''k'' &gt; 0 and ''p'' = ''k'' + 1 is prime, then for all ''i'' &gt; 1 such that ''q'' = ''p''&lt;sup&gt;''i''&lt;/sup&gt; &amp;minus; ''p'' + 1 is prime, ''n'' = ''p''&lt;sup&gt;''i'' &amp;minus; 1&lt;/sup&gt;''q'' is ''k''-hyperperfect. The following table lists known values of ''k'' and corresponding values of ''i'' for which ''n'' is ''k''-hyperperfect:

{| class="wikitable"
! ''k'' !! OEIS !! Values of ''i''
|-
| 16 || {{OEIS2C|A034922}} || 11, 21, 127, 149, 469, ...
|-
| 22 ||  || 17, 61, 445, ...
|-
| 28 ||  || 33, 89, 101, ...
|-
| 36 ||  || 67, 95, 341, ...
|-
| 42 || {{OEIS2C|A034923}} || 4, 6, 42, 64, 65, ...
|-
| 46 || {{OEIS2C|A034924}} || 5, 11, 13, 53, 115, ...
|-
| 52 ||  || 21, 173, ...
|-
| 58 ||  || 11, 117, ...
|-
| 72 ||  || 21, 49, ...
|-
| 88 || {{OEIS2C|A034925}} || 9, 41, 51, 109, 483, ...
|-
| 96 ||  || 6, 11, 34, ...
|-
| 100 || {{OEIS2C|A034926}} || 3, 7, 9, 19, 29, 99, 145, ...
|}

== Hyperdeficiency ==

The newly introduced mathematical concept of '''hyperdeficiency''' is related to the '''hyperperfect numbers'''.

'''Definition''' (Minoli 2010): For any integer ''n'' and for integer ''k'', &lt;math&gt;k&gt;0&lt;/math&gt;, define the '''k-hyperdeficiency''' (or simply the [[hyperdeficiency]]) for the number ''n'' as

    δ&lt;sub&gt;k&lt;/sub&gt;(n) = n(k+1) +(k-1) – kσ(n)

A number ''n'' is said to be '''k-hyperdeficient''' if δ&lt;sub&gt;''k''&lt;/sub&gt;(''n'') &gt; 0.

Note that for ''k''=1 one gets δ&lt;sub&gt;1&lt;/sub&gt;(''n'')= 2''n''–σ(''n''), which is the standard traditional definition of [[Deficient number|deficiency]].

'''Lemma:''' A number ''n'' is k-hyperperfect (including ''k''=1) if and only if the k-hyperdeficiency of ''n'', δ&lt;sub&gt;''k''&lt;/sub&gt;(''n'') = 0.
 
'''Lemma:''' A number ''n'' is k-hyperperfect (including ''k''=1) if and only if for some ''k'', δ&lt;sub&gt;''k-j''&lt;/sub&gt;(''n'') = -δ&lt;sub&gt;''k+j''&lt;/sub&gt;(''n'') for at least one ''j'' &gt; 0.

==References==
{{reflist}}
* {{cite book | editor1-last=Sándor | editor1-first=József | editor2-last=Mitrinović | editor2-first=Dragoslav S. | editor3-last=Crstici |editor3-first=Borislav | title=Handbook of number theory I | location=Dordrecht | publisher=[[Springer-Verlag]] | year=2006 | isbn=1-4020-4215-9 | zbl=1151.11300 | page=114}}

== Further reading ==

=== Articles ===

* {{citation| last1=Minoli | first1=Daniel | first2=Robert | last2=Bear|title=Hyperperfect numbers|journal=Pi Mu Epsilon Journal|volume=6|number=3|date=Fall 1975|pages=153–157}}.
* {{citation|last1=Minoli | first1=Daniel | title=Sufficient forms for generalized perfect numbers|journal=Annales de la Faculté des Sciences [[University of Kinshasa|UNAZA]]|volume=4|number=2|date=Dec 1978|pages=277–302}}.
* {{citation|last1=Minoli | first1=Daniel | title=Structural issues for hyperperfect numbers|journal=Fibonacci Quarterly|date=Feb 1981|volume=19|number=1|pages=6–14}}.
* {{citation|last1=Minoli | first1=Daniel | title=Issues in non-linear hyperperfect numbers|journal=Mathematics of Computation|volume=34|number=150|date=April 1980|pages=639–645|doi=10.2307/2006107}}.
* {{citation|last1=Minoli | first1=Daniel | title=New results for hyperperfect numbers|journal=Abstracts of the American Mathematical Society|date=October 1980|volume=1|number=6|pages=561}}.
* {{citation|last1=Minoli | first1=Daniel | first2=W. | last2=Nakamine|title=Mersenne numbers rooted on 3 for number theoretic transforms|journal=[[International Conference on Acoustics, Speech, and Signal Processing]]|year=1980}}.
* {{citation|first=Judson S. |last=McCranie |title=A study of hyperperfect numbers |journal=Journal of Integer Sequences |volume=3 |year=2000 |url=http://www.math.uwaterloo.ca/JIS/VOL3/mccranie.html |deadurl=yes |archiveurl=https://web.archive.org/web/20040405175234/http://www.math.uwaterloo.ca/JIS/VOL3/mccranie.html |archivedate=2004-04-05 |df= }}.
* {{citation | title=Hyperperfect numbers with three different prime factors | first=Herman J.J. | last=te Riele | authorlink=Herman te Riele | journal=Math. Comp.  | volume=36 | year=1981 | pages=297–298 | mr=595066 | zbl=0452.10005 | doi=10.1090/s0025-5718-1981-0595066-9}}. 
* {{citation | last=te Riele | first=Herman J.J. | authorlink=Herman te Riele | title=Rules for constructing hyperperfect numbers | zbl=0531.10005 | journal=Fibonacci Q. | volume=22 | pages=50–60 | year=1984 }}.

=== Books ===

* Daniel Minoli, ''Voice over MPLS'', McGraw-Hill, New York, NY, 2002, {{ISBN|0-07-140615-8}} (p.&amp;nbsp;114-134)

== External links ==
* [http://mathworld.wolfram.com/HyperperfectNumber.html MathWorld: Hyperperfect number]
* [https://web.archive.org/web/20081205065046/http://j.mccranie.home.comcast.net/ A long list of hyperperfect numbers under Data]

{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Divisor function]]
[[Category:Integer sequences]]</text>
      <sha1>t2dbg6s7azc9hgefmxik7lzu4w4vzqk</sha1>
    </revision>
  </page>
  <page>
    <title>Hypervalent molecule</title>
    <ns>0</ns>
    <id>1085606</id>
    <revision>
      <id>867244900</id>
      <parentid>866124369</parentid>
      <timestamp>2018-11-04T15:50:49Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33336">A '''hypervalent molecule''' (the phenomenon is sometimes colloquially known as '''expanded octet''') is a [[molecule]] that contains one or more [[main group element]]s apparently bearing more than eight [[electron]]s in their [[valence shell]]s. [[Phosphorus pentachloride]] (PCl&lt;sub&gt;5&lt;/sub&gt;), [[sulfur hexafluoride]] (SF&lt;sub&gt;6&lt;/sub&gt;), [[chlorine trifluoride]] (ClF&lt;sub&gt;3&lt;/sub&gt;), the [[chlorite]] (ClO&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;) ion, and the [[triiodide]] (I&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;) ion are examples of hypervalent molecules.

==Definitions and nomenclature==
Hypervalent molecules were first formally defined by Jeremy I. Musher in 1969 as molecules having central atoms of group 15–18 in any [[valence (chemistry)|valence]] other than the lowest (i.e. 3, 2, 1, 0 for Groups 15, 16, 17, 18 respectively, based on the [[octet rule]]).&lt;ref name=Musher&gt;{{cite journal | title = The Chemistry of Hypervalent Molecules | journal = [[Angew. Chem. Int. Ed.]] | year = 1969 | volume = 8 | pages = 54–68 | doi = 10.1002/anie.196900541 | author1 = Musher, J.I.}}&lt;/ref&gt;

Several specific classes of hypervalent molecules exist:
* [[Hypervalent iodine]] compounds are useful reagents in organic chemistry (e.g. [[Dess–Martin periodinane]])
* Tetra-, penta- and hexacoordinated phosphorus, silicon, and sulfur compounds (ex. PCl&lt;sub&gt;5&lt;/sub&gt;, PF&lt;sub&gt;5&lt;/sub&gt;, SF&lt;sub&gt;6&lt;/sub&gt;, [[sulfuranes]] and [[persulfuranes]])
* [[Noble gas compounds]] (ex. xenon tetrafluoride, XeF&lt;sub&gt;4&lt;/sub&gt;)
* Halogen polyfluorides (ex. ClF&lt;sub&gt;5&lt;/sub&gt;)

===N-X-L notation===
N-X-L nomenclature, introduced collaboratively by the research groups of [[James Cullen Martin|Martin]], [[Anthony Joseph Arduengo III|Arduengo]], and [[Jay Kochi|Kochi]] in 1980,&lt;ref&gt;Perkins, C. W.; [[James Cullen Martin|Martin, J. C.]]; [[Anthony Joseph Arduengo III|Arduengo, A. J.]]; Lau, W.; Alegria, A,; [[Jay Kochi|Kochi, J. K.]]; An Electrically Neutral σ-Sulfuranyl Radical from the Homolysis of a Perester with Neighboring Sulfenyl Sulfur: 9-S-3  species ''J.Am. Chem. Soc. 1980, 102, 7753–7759'' {{doi|10.1021/ja00546a019}}&lt;/ref&gt; is often used to classify hypervalent compounds of main group elements, where:
* N represents the number of valence electrons
* X is the chemical symbol of the central atom
* L the number of ligands to the central atom
Examples of N-X-L nomenclature include: 
* [[xenon difluoride|XeF&lt;sub&gt;2&lt;/sub&gt;]], '''10-Xe-2'''
* [[phosphorus pentachloride|PCl&lt;sub&gt;5&lt;/sub&gt;]], '''10-P-5'''
* [[sulfur hexafluoride|SF&lt;sub&gt;6&lt;/sub&gt;]], '''12-S-6'''
* [[iodine heptafluoride|IF&lt;sub&gt;7&lt;/sub&gt;]], '''14-I-7'''

==History and controversy==
The debate over the nature and classification of hypervalent molecules goes back to [[Gilbert N. Lewis]] and [[Irving Langmuir]] and the debate over the nature of the chemical bond in the 1920s.&lt;ref name=Jensen&gt;{{cite journal | doi = 10.1021/ed083p1751 | title = The Origin of the Term "Hypervalent" | journal = [[J. Chem. Educ.]] | year = 2006| volume = 83 | pages = 1751 | author1 = Jensen, W. | issue = 12|bibcode = 2006JChEd..83.1751J }} | [http://jchemed.chem.wisc.edu/Journal/Issues/2006/Dec/abs1751.html Link]&lt;/ref&gt;  Lewis maintained the importance of the two-center two-electron (2c-2e) bond in describing hypervalence, thus using expanded octets to account for such molecules.  Using the language of orbital hybridization, the bonds of molecules like PF&lt;sub&gt;5&lt;/sub&gt; and SF&lt;sub&gt;6&lt;/sub&gt; were said to be constructed from sp&lt;sup&gt;3&lt;/sup&gt;d&lt;sup&gt;n&lt;/sup&gt; orbitals on the central atom.  Langmuir, on the other hand, upheld the dominance of the octet rule and preferred the use of ionic bonds to account for hypervalence without violating the rule (e.g. "SF&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2+&lt;/sup&gt; 2F&lt;sup&gt;−&lt;/sup&gt;" for SF&lt;sub&gt;6&lt;/sub&gt;).

In the late 1920s and 1930s, Sugden argued for the existence of a two-center one-electron (2c-1e) bond and thus rationalized bonding in hypervalent molecules without the need for expanded octets or ionic bond character; this was poorly accepted at the time.&lt;ref name="Jensen"/&gt;  In the 1940s and 1950s, Rundle and [[George C. Pimentel|Pimentel]] popularized the idea of the [[three-center four-electron bond]], which is essentially the same concept which Sugden attempted to advance decades earlier; the three-center four-electron bond can be alternatively viewed as consisting of two collinear two-center one-electron bonds, with the remaining two nonbonding electrons localized to the ligands.&lt;ref name="Jensen"/&gt;

The attempt to actually prepare hypervalent organic molecules began with [[Hermann Staudinger]] and [[Georg Wittig]] in the first half of the twentieth century, who sought to challenge the extant valence theory and successfully prepare nitrogen and phosphorus-centered hypervalent molecules.&lt;ref name = Akiba&gt;{{cite book | title = Chemistry of Hypervalent Compounds | publisher = Wiley VCH | location = New York | isbn = 0-471-24019-2 | author1 = Kin-ya Akiba}}&lt;/ref&gt; The theoretical basis for hypervalency was not delineated until J.I. Musher's work in 1969.&lt;ref name="Musher"/&gt;

In 1990, Magnusson published a seminal work definitively excluding the significance of d-orbital hybridization in the bonding of hypervalent compounds of second-row elements.  This had long been a point of contention and confusion in describing these molecules using [[molecular orbital theory]].  Part of the confusion here originates from the fact that one must include d-functions in the basis sets used to describe these compounds (or else unreasonably high energies and distorted geometries result), and the contribution of the d-function to the molecular wavefunction is large.  These facts were historically interpreted to mean that d-orbitals must be involved in bonding.  However, Magnusson concludes in his work that d-orbital involvement is not implicated in hypervalency.&lt;ref name="ReferenceA"&gt;E. Magnusson. Hypercoordinate molecules of second-row elements: d functions or d orbitals? ''J. Am. Chem. Soc.'' '''1990''', ''112'', 7940–7951. {{doi|10.1021/ja00178a014}}&lt;/ref&gt;

Nevertheless, a 2013 study showed that although the Pimentel ionic model best accounts for the bonding of hypervalent species, the energetic contribution of an expanded octet structure is also not null.  In this [[modern valence bond theory]] study of the bonding of [[xenon difluoride]], it was found that ionic structures account for about 81% of the overall wavefunction, of which 70% arises from ionic structures employing only the p orbital on xenon while 11% arises from ionic structures employing an &lt;math&gt;\mathrm{sd}_{z^2}&lt;/math&gt;hybrid on xenon.  The contribution of a formally hypervalent structure employing an orbital of sp&lt;sup&gt;3&lt;/sup&gt;d hydridization on xenon accounts for 11% of the wavefunction, with a diradical contribution making up the remaining 8%.  The 11% sp&lt;sup&gt;3&lt;/sup&gt;d contribution results in a net stabilization of the molecule by {{convert|7.2|kcal|kJ|abbr=on}} mol&lt;sup&gt;-1&lt;/sup&gt;,&lt;ref&gt;{{Cite journal|last=Braïda|first=Benoît|last2=Hiberty|first2=Philippe C.|date=2013-04-07|title=The essential role of charge-shift bonding in hypervalent prototype XeF2|url=https://www.nature.com/articles/nchem.1619.pdf|journal=Nature Chemistry|language=En|volume=5|issue=5|pages=417–422|bibcode=2013NatCh...5..417B|doi=10.1038/nchem.1619|issn=1755-4330}}&lt;/ref&gt; a minor but significant fraction of the total energy of the total bond energy ({{convert|64|kcal|kJ|abbr=on}} mol&lt;sup&gt;-1&lt;/sup&gt;).&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/953379200|title=The Chemistry of the Monatomic Gases : Pergamon Texts in Inorganic Chemistry.|last=H.|first=Cockett, A.|date=2013|publisher=Elsevier Science|others=Smith, K. C., Bartlett, Neil.|isbn=9781483157368|location=Saint Louis|oclc=953379200}}&lt;/ref&gt;  Other studies have similarly found minor but non-negligible energetic contributions from expanded octet structures in SF&lt;sub&gt;6&lt;/sub&gt; (17%) and XeF&lt;sub&gt;6&lt;/sub&gt; (14%).&lt;ref&gt;{{Cite journal|date=2005-01-01|title=The nature of the chemical bond in the light of an energy decomposition analysis|url=https://www.sciencedirect.com/science/article/pii/B9780444517197500561|journal=Theory and Applications of Computational Chemistry|language=en|pages=291–372|doi=10.1016/B978-044451719-7/50056-1}}&lt;/ref&gt; 

==Criticism==
Both the term and concept of hypervalency still fall under criticism.  In 1984, in response to this general controversy, [[Paul von Ragué Schleyer]] proposed the replacement of 'hypervalency' with use of the term '''hypercoordination''' because this term does not imply any mode of chemical bonding and the question could thus be avoided altogether.&lt;ref name=Jensen/&gt;

The concept itself has been criticized by [[Ronald Gillespie]] who, based on an analysis of electron localization functions, wrote in 2002 that "as there is no fundamental difference between the bonds in hypervalent and non-hypervalent (Lewis octet) molecules there is no reason to continue to use the term hypervalent."&lt;ref&gt;{{cite journal | doi = 10.1016/S0010-8545(02)00102-9 | title = The octet rule and hypervalence: Two misunderstood concepts | year = 2002 | last1 = Gillespie | first1 = R | journal = Coordination Chemistry Reviews | volume = 233–234 | pages = 53–62 }}&lt;/ref&gt;

For hypercoordinated molecules with [[electronegative]] ligands such as PF&lt;sub&gt;5&lt;/sub&gt; it has been demonstrated that the ligands can pull away enough electron density from the central atom so that its net content is again 8 electrons or fewer. Consistent with this alternative view is the finding that hypercoordinated molecules based on fluorine ligands, for example PF&lt;sub&gt;5&lt;/sub&gt; do not have [[hydride]] counterparts e.g. [[phosphorane]] PH&lt;sub&gt;5&lt;/sub&gt; which is unknown.

The ionic model holds up well in [[thermochemistry|thermochemical]] calculations. It predicts favorable [[exothermic]] formation of PF&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;F&lt;sup&gt;−&lt;/sup&gt; from [[phosphorus trifluoride]] PF&lt;sub&gt;3&lt;/sub&gt; and [[fluorine]] F&lt;sub&gt;2&lt;/sub&gt; whereas a similar reaction forming PH&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;H&lt;sup&gt;−&lt;/sup&gt; is not favorable.&lt;ref&gt;''Predicting the Stability of Hypervalent Molecules '' Mitchell, Tracy A.; Finocchio, Debbie; Kua, Jeremy. J. Chem. Educ. '''2007''', 84, 629. [http://jchemed.chem.wisc.edu/Journal/Issues/2007/Apr/abs629.html Link]&lt;/ref&gt;

==Alternative definition==
Durrant has proposed an alternative definition of hypervalency, based on the analysis of atomic charge maps obtained from [[Atoms in molecules]] theory.&lt;ref&gt;{{cite journal | title = A quantitative definition of hypervalency | journal = [[Chemical Science (journal)|Chemical Science]] | year = 2015 | volume = 6 | pages = 6614–6623 | doi = 10.1039/C5SC02076J | author1 = Durrant, M. C. | url = http://nrl.northumbria.ac.uk/24137/1/a%20quantitative%20definition%20of%20hypervalency.pdf }}&lt;/ref&gt;  This approach defines a parameter called the valence electron equivalent, γ, as “the formal shared electron count at a given atom, obtained by any combination of valid ionic and covalent resonance forms that reproduces the observed charge distribution”.  For any particular atom X, if the value of γ(X) is greater than 8, that atom is hypervalent.  Using this alternative definition, many species such as PCl&lt;sub&gt;5&lt;/sub&gt;, SO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;2−&lt;/sup&gt;, and XeF&lt;sub&gt;4&lt;/sub&gt;, that are hypervalent by Musher's definition, are reclassified as hypercoordinate but not hypervalent, due to strongly ionic bonding that draws electrons away from the central atom.  On the other hand, some compounds that are normally written with ionic bonds in order to conform to the octet rule, such as [[ozone]] O&lt;sub&gt;3&lt;/sub&gt;,  [[nitrous oxide]] NNO, and [[trimethylamine N-oxide]] (CH&lt;sub&gt;3&lt;/sub&gt;)&lt;sub&gt;3&lt;/sub&gt;NO, are found to be genuinely hypervalent.  Examples of γ calculations for [[phosphate]] PO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;3−&lt;/sup&gt; (γ(P) = 2.6, non-hypervalent) and [[orthonitrate]] NO&lt;sub&gt;4&lt;/sub&gt;&lt;sup&gt;3−&lt;/sup&gt; (γ(N) = 8.5, hypervalent) are shown below.

[[File:Hypervalency Gamma calculations.png|thumb|600px| center|Calculation of the valence electron equivalent for phosphate and orthonitrate]]

==Bonding in hypervalent molecules==
Early considerations of the geometry of hypervalent molecules returned familiar arrangements that were well explained by the [[VSEPR model]] for atomic bonding.  Accordingly, AB&lt;sub&gt;5&lt;/sub&gt; and AB&lt;sub&gt;6&lt;/sub&gt; type molecules would possess a trigonal bi-pyramidal and octahedral geometry, respectively.  However, in order to account for the observed bond angles, bond lengths and apparent violation of the Lewis [[octet rule]], several alternative models have been proposed.

In the 1950s an expanded valence shell treatment of hypervalent bonding was adduced to explain the molecular architecture, where the central atom of penta- and hexacoordinated molecules would utilize d AOs in addition to s and p AOs. However, advances in the study of ''[[ab initio]]'' calculations have revealed that the contribution of d-orbitals to hypervalent bonding is too small to describe the bonding properties, and this description is now regarded as much less important.&lt;ref name="ReferenceA"/&gt;  It was shown that in the case of hexacoordinated SF&lt;sub&gt;6&lt;/sub&gt;, d-orbitals are not involved in S-F bond formation, but charge transfer between the sulfur and fluorine atoms and the apposite resonance structures were able to account for the hypervalency (See below).

Additional modifications to the octet rule have been attempted to involve ionic characteristics in hypervalent bonding. As one of these modifications, in 1951, the concept of the [[three-center four-electron bond|3-center 4-electron (3c-4e) bond]], which described hypervalent bonding with a qualitative [[molecular orbital]], was proposed. The 3c-4e bond is described as three molecular orbitals given by the combination of a p atomic orbital on the central atom and an atomic orbital from each of the two [[ligand]]s on opposite sides of the central atom. Only one of the two pairs of electrons is occupying a molecular orbital that involves bonding to the central atom, the second pair being non-bonding and occupying a molecular orbital composed of only atomic orbitals from the two ligands. This model in which the octet rule is preserved was also advocated by Musher.&lt;ref name=Jensen/&gt;  
[[image:XeF2.png|thumb|400px|center|Qualitative model for a [[three-center four-electron bond]]]]

=== Molecular orbital theory ===
A complete description of hypervalent molecules arises from consideration of molecular orbital theory through quantum mechanical methods. A [[LCAO]] in, for example, sulfur hexafluoride, taking a basis set of the one sulfur 3s-orbital, the three sulfur 3p-orbitals, and six octahedral geometry symmetry-adapted linear combinations (SALCs) of fluorine orbitals, a total of ten molecular orbitals are obtained (four fully occupied bonding MOs of the lowest energy, two fully occupied intermediate energy non-bonding MOs and four vacant antibonding MOs with the highest energy) providing room for all 12 valence electrons.  This is a stable configuration only for S''X''&lt;sub&gt;6&lt;/sub&gt; molecules containing electronegative ligand atoms like fluorine, which explains why SH&lt;sub&gt;6&lt;/sub&gt; is not a stable molecule. In the bonding model, the two non-bonding MOs (1e&lt;sub&gt;g&lt;/sub&gt;) are localized equally on all six fluorine atoms.

===Valence bond theory===
For hypervalent compounds in which the ligands are more [[electronegative]] than the central, hypervalent atom, [[resonance structures]] can be drawn with no more than four covalent electron pair bonds and completed with ionic bonds to obey the octet rule.  For example, in [[phosphorus pentafluoride]] (PF&lt;sub&gt;5&lt;/sub&gt;), 5 resonance structures can be generated each with four covalent bonds and one ionic bond with greater weight in the structures placing ionic character in the axial bonds, thus satisfying the octet rule and explaining both the observed [[trigonal bipyramidal molecular geometry]] and the fact that the axial bond length (158 pm) is longer than the equatorial (154 pm).&lt;ref&gt;{{cite journal | title = A Simple Qualitative Molecular-Orbital/Valence-Bond Description of the Bonding in Main Group "Hypervalent" Molecules | journal = [[Journal of Chemical Education]] | year = 1998 | volume = 75 | pages = 910–915 | doi = 10.1021/ed075p910 | author1 = Curnow, Owen J. | issue = 7|bibcode = 1998JChEd..75..910C }}&lt;/ref&gt;

[[image:penta phos.svg|thumb|500px | center | Phosphorus pentafluoride. There are 2 structures with an axial ionic bond, plus 3 structures with an equatorial ionic bond.]]

For a hexacoordinate molecule such as [[sulfur hexafluoride]], each of the six bonds is the same length.  The rationalization described above can be applied to generate 15 resonance structures each with four covalent bonds and two ionic bonds, such that the ionic character is distributed equally across each of the sulfur-fluorine bonds.

[[image:hexa sulf.svg|thumb|500px | center | Sulfur hexafluoride. There are 12 structures with the two ionic bonds in adjacent (''cis'') positions, plus 3 structures with the two ionic bonds in opposite (''trans'') positions.]]

Spin-coupled valence bond theory has been applied to [[diazomethane]] and the resulting orbital analysis was interpreted in terms of a chemical structure in which the central nitrogen has five covalent bonds;

[[File:Hypervalent diazomethane.png|thumb|150px| center|Chemical formula of diazomethane, showing hypervalent nitrogen]]

This led the authors to the interesting conclusion that "Contrary to what we were all taught as undergraduates, the nitrogen atom does indeed form five covalent linkages and the availability or otherwise of d-orbitals has nothing to do with this state of affairs."&lt;ref&gt;{{cite journal | title = Modern valence bond theory | journal = [[Chemical Society Reviews]] | year = 1997 | volume = 26 | pages = 87–100 | doi = 10.1039/CS9972600087 | author1 = Gerratt, Joe | issue = 2 }}&lt;/ref&gt;

==Structure, reactivity, and kinetics==

===Structure===

====Hexacoordinated phosphorus====
Hexacoordinate [[phosphorus]] molecules involving nitrogen, oxygen, or sulfur ligands provide examples of Lewis acid-Lewis base hexacoordination.&lt;ref name=Holmes&gt;{{cite journal | title = Comparison of Phosphorus and Silicon:  Hypervalency, Stereochemistry, and Reactivity | journal = [[Chem. Rev.]] | year = 1996 | volume = 96 | pages = 927–950 | doi = 10.1021/cr950243n | author1 = Holmes, R.R. | pmid=11848776 | issue = 3}}&lt;/ref&gt;  For the two similar complexes shown below, the length of the C-P bond increases with decreasing length of the N-P bond; the strength of the C-P bond decreases with increasing strength of the N-P Lewis acid-Lewis base interaction.

[[image:hexa phos.png|thumb|300px | center | Relative bond strengths in hexacoordinated phosphorus compounds. In A, the N-P bond is 1.980Å long and the C-P is 1.833Å long, and in B, the N-P bond increases to 2.013Å as the C-P bond decreases to 1.814Å.&lt;ref name="Holmes"/&gt;]]

====Pentacoordinated silicon====
This trend is also generally true of pentacoordinated main-group elements with one or more lone-pair-containing ligand, including the oxygen-pentacoordinated [[silicon]] examples shown below.

[[image:penta sil oxy.png|thumb|500px | center | Relative bond strengths in pentacoordinated silicon compounds. In A, the Si-O bond length is 1.749Å and the Si-I bond length is 3.734Å; in B, the Si-O bond lengthens to 1.800Å and the Si-Br bond shortens to 3.122Å, and in C, the Si-O bond is the longest at 1.954Å and the Si-Cl bond the shortest at 2.307A.&lt;ref name="Holmes"/&gt;]]

The Si-halogen bonds range from close to the expected van der Waals value in A (a weak bond) almost to the expected covalent single bond value in C (a strong bond).&lt;ref name="Holmes"/&gt;

===Reactivity===

====Silicon====
{|class="wikitable sortable" align=right
|+Observed third-order [[reaction rate constant]]s&lt;br /&gt;for hydrolysis (displacement of chloride from silicon)&lt;ref name= Corriu1978/&gt;
|-
! Chlorosilane
! Nucleophile
! ''k''&lt;sub&gt;obs&lt;/sub&gt; (M&lt;sup&gt;−2&lt;/sup&gt;s&lt;sup&gt;−1&lt;/sup&gt;)&lt;br /&gt;at 20&amp;nbsp;°C in anisole
|-
||[[Phenyl group|Ph]]&lt;sub&gt;3&lt;/sub&gt;SiCl || [[Hexamethylphosphoramide|HMPT]] || 1200
|-
||Ph&lt;sub&gt;3&lt;/sub&gt;SiCl || [[Dimethyl sulfoxide|DMSO]] || 50
|-
||Ph&lt;sub&gt;3&lt;/sub&gt;SiCl || [[Dimethylformamide|DMF]]  || 6
|-
||[[Methyl group|Me]]Ph&lt;sub&gt;2&lt;/sub&gt;SiCl || HMPT || 2000
|-
||MePh&lt;sub&gt;2&lt;/sub&gt;SiCl || DMSO || 360
|-
||MePh&lt;sub&gt;2&lt;/sub&gt;SiCl || DMF  || 80
|-
||Me(1-[[Naphthyl|Np]])PhSiCl || HMPT || 3500
|-
||Me(1-Np)PhSiCl || DMSO || 180
|-
||Me(1-Np)PhSiCl || DMF  || 40
|-
||(1-Np)Ph([[vinyl group|vinyl]])SiCl || HMPT || 2200
|-
||(1-Np)Ph(vinyl)SiCl || DMSO || 90
|-
||(1-Np)(''m''-[[Trifluoromethyl|CF&lt;sub&gt;3&lt;/sub&gt;]]Ph)HSiCl || DMSO || 1800
|-
||(1-Np)(''m''-CF&lt;sub&gt;3&lt;/sub&gt;Ph)HSiCl || DMF || 300
|-
|}

Corriu and coworkers performed early work characterizing reactions thought to proceed through a hypervalent transition state.&lt;ref name= Corriu1978&gt;{{cite journal | doi = 10.1016/S0022-328X(00)85545-X | author1 = Corriu, RJP | title = Mécanisme de l'hydrolyse des chlorosilanes, catalysée par un nucléophile: étude cinétique et mise en evidence d'un intermediaire hexacoordonné| journal = [[J. Organomet. Chem.]]| year = 1978|volume = 150|pages = 27–38 | last2 = Dabosi | first2 = G. | last3 = Martineau | first3 = M.}}&lt;/ref&gt;  Measurements of the [[reaction rate]]s of hydrolysis of tetravalent chlorosilanes incubated with catalytic amounts of water returned a rate that is [[Order of reaction|first order]] in chlorosilane and second order in water.  This indicated that two water molecules interacted with the silane during hydrolysis and from this a binucleophilic reaction mechanism was proposed. Corriu and coworkers then measured the rates of hydrolysis in the presence of nucleophilic catalyst HMPT, DMSO or DMF.  It was shown that the rate of hydrolysis was again first order in chlorosilane, first order in catalyst and now first order in water.  Appropriately, the rates of hydrolysis also exhibited a dependence on the magnitude of charge on the oxygen of the nucleophile.

Taken together this led the group to propose a reaction mechanism in which there is a pre-rate determining nucleophilic attack of the tetracoordinated silane by the nucleophile (or water) in which a hypervalent pentacoordinated silane is formed.  This is followed by a nucleophilic attack of the intermediate by water in a rate determining step leading to hexacoordinated species that quickly decomposes giving the hydroxysilane.

Silane hydrolysis was further investigated by Holmes and coworkers &lt;ref name= Johnson1989&gt;{{cite journal | doi= 10.1021/ja00191a023 | author1= Johnson, SE|author2=Deiters, JA|author3=Day, RO|author4=Holmes, RR | title= Pentacoordinated molecules. 76. Novel hydrolysis pathways of dimesityldifluorosilane via an anionic five-coordinated silicate and a hydrogen-bonded bisilonate. Model intermediates in the sol-gel process| journal = [[J. Am. Chem. Soc.]]| year = 1989|volume = 111|pages = 3250 | issue= 9}}&lt;/ref&gt; in which tetracoordinated Mes&lt;sub&gt;2&lt;/sub&gt;SiF&lt;sub&gt;2&lt;/sub&gt; (Mes = [[mesitylene|mesityl]]) and pentacoordinated Mes&lt;sub&gt;2&lt;/sub&gt;SiF&lt;sub&gt;3&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt; were reacted with two equivalents of water.  Following twenty-four hours, almost no hydrolysis of the tetracoordinated silane was observed, while the pentacoordinated silane was completely hydrolyzed after fifteen minutes.  Additionally, X-ray diffraction data collected for the tetraethylammonium salts of the fluorosilanes showed the formation of hydrogen bisilonate lattice supporting a hexacoordinated intermediate from which HF&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt; is quickly displaced leading to the hydroxylated product. This reaction and crystallographic data support the mechanism proposed by Corriu ''et al.''.

[[image:Hydrolysis Silane Xray structure.png|thumb|500px | center | Mechanism of silane hydrolysis and structure of the hydrogen bisilonate lattice]]

The apparent increased reactivity of hypervalent molecules, contrasted with tetravalent analogues, has also been observed for Grignard reactions.  The Corriu group measured&lt;ref name= Corriu1988&gt;{{cite journal | doi = 10.1021/om00091a038 | author = Corriu, RJP | title = Pentacoordinated silicon anions: reactivity toward strong nucleophiles| journal = [[Organometallics]]| year = 1988|volume = 7|pages = 237–8 | last2 = Guerin | first2 = Christian. | last3 = Henner | first3 = Bernard J. L. | last4 = Wong Chi Man | first4 = W. W. C.}}&lt;/ref&gt; Grignard reaction half-times by NMR for related 18-crown-6 potassium salts of a variety of tetra- and pentacoordinated fluorosilanes in the presence of catalytic amounts of nucleophile.

Though the half reaction method is imprecise, the magnitudinal differences in reactions rates allowed for a proposed reaction scheme wherein, a pre-rate determining attack of the tetravalent silane by the nucleophile results in an equilibrium between the neutral tetracoordinated species and the anionic pentavalent compound.  This is followed by nucleophilic coordination by two Grignard reagents as normally seen, forming a hexacoordinated transition state and yielding the expected product.
[[image:Hypercoordinated Silane Grignard.png|thumb|500px | center | Grignard reaction mechanism for tetracoordinate silanes and the analogous hypervalent pentacoordinated silanes]]

The mechanistic implications of this are extended to a hexacoordinated silicon species that is thought to be active as a transition state in some reactions. The reaction of [[allyl]]- or [[crotyl]]-trifluorosilanes with aldehydes and ketones only precedes with fluoride activation to give a pentacoordinated silicon. This intermediate then acts as a [[Lewis acid]] to coordinate with the carbonyl oxygen atom. The further weakening of the silicon–carbon bond as the silicon becomes hexacoordinate helps drive this reaction.&lt;ref name=abinitio3&gt;{{cite journal | title = Regiospecific and highly stereoselective allylation of aldehydes with allyltrifluorosilane activated by fluoride ions | journal = [[Tetrahedron Letters]] | year = 1987 | volume = 28 | pages = 4081–4084 | doi = 10.1016/S0040-4039(01)83867-3 | author1 = Kira, M | author2 = Kobayashi, M. | author3 = Sakurai, H. | issue = 35}}&lt;/ref&gt;

[[File:Aldehyde crotylation with hypervalent silicon.png|thumb|500px|center]]

====Phosphorus====
Similar reactivity has also been observed for other hypervalent structures such as the miscellany of phosphorus compounds, for which hexacoordinated transition states have been proposed.
Hydrolysis of phosphoranes and oxyphosphoranes have been studied &lt;ref name= Bel&gt;{{cite journal | author = Bel'Skii, VE| journal = [[J. Gen. Chem. USSR]]| year = 1979|volume = 49|pages = 298}}&lt;/ref&gt; and shown to be second order in water. Bel'skii ''et al.''. have proposed a prerate determining nucleophilic attack by water resulting in an equilibrium between the penta- and hexacoordinated phosphorus species, which is followed by a proton transfer involving the second water molecule in a rate determining ring-opening step, leading to the hydroxlyated product.  
[[image:Hydrolysis Pentacoordinated Phosphorous.png|thumb|500px | center | Mechanism of the hydrolysis of pentacoordinated phosphorus]]

Alcoholysis of pentacoordinated phosphorus compounds, such as trimethoxyphospholene with benzyl alcohol, have also been postulated to occur through a similar octahedral transition state, as in hydrolysis, however without ring opening.&lt;ref name= Ramirez1968&gt;{{cite journal | doi = 10.1021/ja01005a035 | author = Ramirez, F | title = Nucleophilic substitutions at pentavalent phosphorus. Reaction of 2,2,2-trialkoxy-2,2-dihydro-1,3,2-dioxaphospholenes with alcohols| journal = [[J. Am. Chem. Soc.]]| year = 1968|volume = 90|pages = 751 | last2 = Tasaka | first2 = K. | last3 = Desai | first3 = N. B. | last4 = Smith | first4 = Curtis Page. | issue = 3}}&lt;/ref&gt;

[[image:Base Catalyzed Alcoholysis Pentacoordinated Phosphorous.png|thumb|500px | center | Mechanism of the base catalyzed alcoholysis of pentacoordinated phosphorus]]

It can be understood from these experiments that the increased reactivity observed for hypervalent molecules, contrasted with analogous nonhypervalent compounds, can be attributed to the congruence of these species to the hypercoordinated activated states normally formed during the course of the reaction.

===Ab initio calculations===
The enhanced reactivity at pentacoordinated silicon is not fully understood. Corriu and coworkers suggested that greater electropositive character at the pentavalent silicon atom may be responsible for its increased reactivity.&lt;ref name=abinitio2&gt;{{cite journal | doi = 10.1021/om00157a016 | title = Pentacoordinated silicon anions: Synthesis and reactivity | year = 1990 | last1 = Brefort | first1 = Jean Louis | last2 = Corriu | first2 = Robert J. P. | last3 = Guerin | first3 = Christian | last4 = Henner | first4 = Bernard J. L. | last5 = Wong Chi Man | first5 = Wong Wee Choy | journal = [[Organometallics]] | volume = 9 | issue = 7 | pages = 2080 }}&lt;/ref&gt; Preliminary ab initio calculations supported this hypothesis to some degree, but used a small basis set.&lt;ref name=abinitio1&gt;{{cite journal | title = Enhanced Reactivity of Pentacoordinated Silicon Species. An ab Initio Approach | journal = [[J. Am. Chem. Soc.]] | year = 1990 | volume = 112 | pages = 7197–7202 | doi = 10.1021/ja00176a018 | author1 = Dieters, J. A. | author2 = Holmes, R. R. | issue = 20}}&lt;/ref&gt;

A software program for ab initio calculations, [[Gaussian (software)|Gaussian 86]], was used by Dieters and coworkers to compare tetracoordinated silicon and phosphorus to their pentacoordinate analogues. This [[ab initio quantum chemistry methods|ab initio]] approach is used as a supplement to determine why reactivity improves in nucleophilic reactions with pentacoordinated compounds.  For silicon, the [[Basis set (chemistry)|6-31+G* basis set]] was used because of its pentacoordinated anionic character and for phosphorus, the [[Basis set (chemistry)|6-31G* basis set]] was used.&lt;ref name=abinitio1 /&gt;

Pentacoordinated compounds should theoretically be less electrophilic than tetracoordinated analogues due to steric hindrance and greater electron density from the ligands, yet experimentally show greater reactivity with nucleophiles than their tetracoordinated analogues. Advanced ab initio calculations were performed on series of tetracoordinated and pentacoordinated species to further understand this reactivity phenomenon. Each series varied by degree of fluorination. Bond lengths and charge densities are shown as functions of how many hydride ligands are on the central atoms. For every new hydride, there is one less fluoride.&lt;ref name="abinitio1"/&gt;

For silicon and phosphorus bond lengths, charge densities, and Mulliken bond overlap, populations were calculated for tetra and pentacoordinated species by this ab initio approach.&lt;ref name="abinitio1"/&gt; Addition of a fluoride ion to tetracoordinated silicon shows an overall average increase of 0.1 electron charge, which is considered insignificant.  In general, bond lengths in trigonal bipyramidal pentacoordinate species are longer than those in tetracoordinate analogues. Si-F bonds and Si-H bonds both increase in length upon pentacoordination and related effects are seen in phosphorus species, but to a lesser degree. The reason for the greater magnitude in bond length change for silicon species over phosphorus species is the increased effective nuclear charge at phosphorus. Therefore, silicon is concluded to be more loosely bound to its ligands.{{multiple image  | align = center  | direction = horizontal  | header = Effects of fluorine substitution on positive charge density  | width = 500   | image1  = charge densities - silicon.png  | caption1  = Comparison of Charge Densities with Degree of Fluorination for Tetra and Pentacoordinated Silicon}}

In addition Dieters and coworkers &lt;ref name="abinitio1"/&gt; show an inverse correlation between bond length and bond overlap for all series. Pentacoordinated species are concluded to be more reactive because of their looser bonds as trigonal-bipyramidal structures.{{multiple image  | align = center  | direction = horizontal  | header    = Calculated bond length and bond overlap with degree of fluorination | width = 500| image1 = Si-F bond lengths.png  | caption1  = Comparison of Bond Lengths with Degree of Fluorination for Tetra and Pentacoordinated Silicon| image2 = bond lengths - phosphorus.png  | caption2  = Comparison of Bond Lengths with Degree of Fluorination for Tetra and Pentacoordinated Phosphorus}}

By calculating the energies for the addition and removal of a fluoride ion in various silicon and phosphorus species, several trends were found. In particular, the tetracoordinated species have much higher energy requirements for ligand removal than do pentacoordinated species. Further, silicon species have lower energy requirements for ligand removal than do phosphorus species, which is an indication of weaker bonds in silicon.

== See also ==
* [[Charge-shift bond]]

==References==
{{reflist|30em}}

==External links==
*{{Commonscatinline|Hypervalent molecules}}

{{Chemical bonds}}

{{DEFAULTSORT:Hypervalent Molecule}}
[[Category:Chemical bonding]]
[[Category:Molecular geometry]]
[[Category:Hypervalent molecules| ]]</text>
      <sha1>qz4az821a61zoyldmnsctdx2htqz9g8</sha1>
    </revision>
  </page>
  <page>
    <title>Joseph Diez Gergonne</title>
    <ns>0</ns>
    <id>3431943</id>
    <revision>
      <id>868754220</id>
      <parentid>867364491</parentid>
      <timestamp>2018-11-14T06:27:52Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7611">{{Use dmy dates|date=May 2013}}
{{Infobox scientist
| name        = Joseph Diez Gergonne
| image       = 
| image_size  = 
| caption     = 
| birth_date  = {{birth date |1771|6|19|df=y}}
| birth_place = Nancy, France
| death_date  = {{death date and age |1859|5|4 |1771|6|19|df=y}}
| death_place = Montpellier, France
| residence   = France
| citizenship = 
| nationality = 
| fields      = [[Mathematics]]&lt;br&gt;[[Logic]]
| workplaces  = 
| patrons     = 
| education   = 
| alma_mater  = 
| thesis_title =        &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_year =         &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor =    &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| footnotes   = 
}}
'''Joseph Diez Gergonne''' (19 June 1771 at [[Nancy, France|Nancy]], [[France]] – 4 May 1859 at [[Montpellier]], France) was a French [[mathematician]] and [[logician]].

==Life==
In 1791, Gergonne enlisted in the French army as a captain. That army was undergoing rapid expansion because the French government feared a foreign invasion intended to undo the [[French Revolution]] and restore [[Louis XVI]] to the throne of France. He saw action in the major battle of [[Valmy]] on 20 September 1792. He then returned to civilian life but soon was called up again and took part in the French invasion of Spain in 1794.

In 1795, Gergonne and his regiment were sent to [[Nîmes]]. At this point, he made a definitive transition to civilian life by taking up the chair of "transcendental mathematics" at the new École centrale. He came under the influence of [[Gaspard Monge]], the Director of the new [[École Polytechnique|École polytechnique]] in [[Paris]].

In 1810, in response to difficulties he encountered in trying to publish his work, Gergonne founded his own mathematics journal, officially named the ''[[Annales de mathématiques pures et appliquées]]'' but generally referred to as the ''[[Annales de Gergonne]]''. The most common subject of articles in his journal was [[geometry]], Gergonne's specialty. Over a period of 22 years, the ''Annales de Gergonne'' published about 200 articles by Gergonne himself, and other articles by many distinguished mathematicians, including [[Jean-Victor Poncelet|Poncelet]], [[François-Joseph Servois|Servois]], [[Étienne Bobillier|Bobillier]], [[Jakob Steiner|Steiner]], [[Julius Plücker|Plücker]], [[Michel Chasles|Chasles]], [[Charles Julien Brianchon|Brianchon]], [[Charles Dupin|Dupin]], [[Gabriel Lamé|Lamé]], even [[Évariste Galois|Galois]].

Gergonne was appointed to the chair of astronomy at the University of Montpellier in 1816. In 1830, he was appointed [[Rector (academia)|Rector]] of the University of Montpellier, at which time he ceased publishing his journal. He retired in 1844.

==Work==
Gergonne was among the first mathematicians to employ the word [[polar coordinate system|''polar'']]. In a series of papers beginning in 1810, he contributed to elaborating the ''principle of duality'' in [[projective geometry]], by noticing that every [[theorem]] in the [[Plane (geometry)|plane]] connecting points and lines corresponds to another theorem in which points and lines are interchanged, provided that the theorem embodied no metrical notions. Gergonne was an early proponent of the techniques of [[analytical geometry]] and in 1816, he devised an elegant coordinate solution to the classical [[problem of Apollonius]]: to find a circle which touches three given circles, thus demonstrating the power of the new methods.

In 1813, Gergonne wrote the prize-winning essay for the Bordeaux Academy, ''Methods of synthesis and analysis in mathematics'', unpublished to this day and known only via a summary. The essay is very revealing of Gergonne's philosophical ideas. He called for the abandonment of the words ''[[wiktionary:Analysis|analysis]]'' and ''[[wikt:synthesis|synthesis]]'', claiming they lacked clear meanings. Surprisingly for a geometer, he suggested that algebra is more important than geometry at a time when [[abstract algebra|algebra]] consisted almost entirely of the elementary algebra of the [[real number|real field]]. He predicted that one day quasi-mechanical methods would be used to discover new results.

In 1815, Gergonne wrote the first paper on the [[optimal design]] of [[Design of experiments|experiments]] for [[polynomial regression]]. &lt;!-- Preceding even [[Charles Sanders Peirce|C. S. Peirce]], --&gt;According to [[Stephen M. Stigler|S. M. Stigler]], Gergonne is the pioneer of [[optimal design]] as well as [[response surface methodology]]. &lt;!-- statistical areas associated with [[Ronald A. Fisher|R. A. Fisher]] and [[George E. P. Box|G. E. P. Box]]. --&gt;

He published his "Essai sur la théorie des définitions" (An essay on the theory of definition) in his ''Annales'' in 1818. This essay is generally credited for first recognizing and naming the construct of ''implicit definition''.&lt;ref&gt;[[Willard Van Orman Quine|W. V. O. Quine]], "Implicit Definition Sustained", ''The Journal of Philosophy'', Vol. 61, No. 2 (Jan. 16, 1964), pp. 71-74.&lt;/ref&gt;&lt;ref&gt;[http://www.persee.fr/web/revues/home/prescript/article/rhs_0048-7996_1970_num_23_3_3143 Mario H. Otero, "Les définitions implicites chez Gergonne", ''Revue d’histoire des sciences et de leurs applications'', Vol. 23, No. 3 (1970), pp. 251–55.] DOI: 10.3406/rhs.1970.3143&lt;/ref&gt;

==Quote==
*"It is not possible to feel satisfied at having said the last word about some theory as long as it cannot be explained in a few words to any passer-by encountered in the street."&lt;ref&gt;[[Michel Chasles]]. [https://books.google.com/books?id=L9QSAQAAMAAJ Aperçu historique], Volume 2. 1875.&lt;/ref&gt;

==Notes==
{{reflist}}

==References==
*{{cite journal
|title=The application of the method of least squares to the interpolation of sequences
|author=Gergonne, J. D.
|journal=Historia Mathematica
|volume=1
|issue=4
|date=November 1974 |origyear=1815
|pages=439–447
|edition=Translated by Ralph St. John and [[Stephen M. Stigler|S. M. Stigler]] from the 1815 French
|doi=10.1016/0315-0860(74)90034-2
|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-20/2/df451ec5fbb7c044d0f4d900af80ec86
}}
*{{cite journal
|title=Gergonne's 1815 paper on the design and analysis of polynomial regression experiments
|author=[[Stephen M. Stigler|Stigler, Stephen M.]]
|journal=Historia Mathematica
|volume=1
|issue=4
|date=November 1974
|pages=431–439
|doi=10.1016/0315-0860(74)90033-0
|url=http://www.sciencedirect.com/science/article/B6WG9-4D7JMHH-1Y/2/680c7ada0198761e9866197d53512ab4
}}

==External links==
*Biography in the MacTutor History of Mathematics archive: [http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Gergonne.html Joseph Gergonne.]

{{Authority control}}

{{DEFAULTSORT:Gergonne, Joseph Diaz}}
[[Category:1771 births]]
[[Category:1859 deaths]]
[[Category:18th-century French mathematicians]]
[[Category:19th-century French mathematicians]]
[[Category:French logicians]]
[[Category:Geometers]]
[[Category:French military personnel of the French Revolutionary Wars]]
[[Category:People from Nancy, France]]
[[Category:French philosophers]]
[[Category:French male non-fiction writers]]
[[Category:19th-century French male writers]]</text>
      <sha1>f5cbxq4ldy2rkr0hu9x7j35rqi0n6c2</sha1>
    </revision>
  </page>
  <page>
    <title>Keith Medal</title>
    <ns>0</ns>
    <id>2469940</id>
    <revision>
      <id>841208349</id>
      <parentid>838196351</parentid>
      <timestamp>2018-05-14T16:22:01Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Columns-list]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12694">{{Use dmy dates|date=August 2017}}
{{Use British English|date=August 2017}}
[[File:Lord Kelvin's Keith medal in the Hunterian Museum, Glasgow.png|thumb|330px|[[Lord Kelvin]]'s Keith medal in the Hunterian Museum, Glasgow]]
The '''Keith Medal''' was a [[prize]] awarded by the [[Royal Society of Edinburgh]], [[Scotland]]'s [[national academy]], for a [[scientific paper]] published in the society's [[scientific journal]]s, preference being given to a paper containing a discovery, either in [[mathematics]] or [[earth science]]s.

The Medal was inaugurated in 1827 as a result of a gift from [[Alexander Keith of Dunnottar]], the first Treasurer of the Society. It was awarded quadrennially, alternately for a paper published in: Proceedings A (Mathematics) or Transactions (Earth and Environmental Sciences). The medal bears the head of [[John Napier]] of Merchiston.

The medal is no longer awarded. &lt;ref&gt; {{cite web|url=http://rse.mtcserver6.com/661_KeithMedal.html|title= Keith Medal|publisher= RSE|accessdate= 17 March 2017}} &lt;/ref&gt;

==Recipients of the Keith Gold Medal==
Source (1827 to 1913): [https://archive.org/stream/proceedings3419131914roya/proceedings3419131914roya_djvu.txt Proceedings of the Royal Society of Edinburgh]
;19th century
*1827–29: [[David Brewster]]&lt;ref name = KM1/&gt;, ''on his Discovery of Two New Immiscible Fluids in the Cavities of certain Minerals''
*1829–31: [[David Brewster]]&lt;ref name = KM1/&gt;, ''on a New Analysis of Solar Light''
*1831–33: [[Thomas Graham (chemist)|Thomas Graham]]&lt;ref&gt;{{cite web|url=http://www.strath.ac.uk/science/news_and_events/ |title=News and Events |publisher=University of Strathclyde |accessdate=28 November 2014 |deadurl=yes |archiveurl=https://web.archive.org/web/20141205144306/http://www.strath.ac.uk/science/news_and_events/ |archivedate= 5 December 2014 |df= }}&lt;/ref&gt;&lt;ref name = KM1/&gt;, ''on the Law of the Diffusion of Gases''
*1833–35: [[James David Forbes]]&lt;ref name = KM1/&gt;, ''on the Refraction and Polarization of Heat''
*1835–37: [[John Scott Russell]]&lt;ref name = KM2/&gt;, ''on Hydrodynamics''
*1837–39: John Shaw&lt;ref name= CJO&gt;{{cite web|url = http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=8735503|title= Keith Awards 1827-1890|publisher=Cambridge Journals Online|accessdate = 29 November 2014}}&lt;/ref&gt;, ''on the Development and Growth of the Salmon''
*1839–41: ''Not awarded''&lt;ref name = CJO/&gt;
*1841–43: [[James David Forbes]]&lt;ref name = KM1/&gt;, ''on Glaciers''
*1843–45: ''Not awarded''&lt;ref name = CJO/&gt;
*1845–47: Sir [[Thomas Brisbane]]&lt;ref name = CJO/&gt;, ''for the Makerstoun Observations on Magnetic Phenomena''
*1847–49: ''Not awarded''&lt;ref name = CJO/&gt;
*1849–51: [[Philip Kelland]]&lt;ref name = KM2&gt;{{cite web|url=http://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp2.pdf|title = Former Fellows of the Royal Society of Edinburgh| publisher=Royal Society of Edinburgh|accessdate= 27 November 2014}}&lt;/ref&gt;, ''on General Differentiation, including his more recent Communication on a process of the Differential Calculus, and its application to the solution of certain Differential Equations''
*1851–53: [[William John Macquorn Rankine]]&lt;ref name = KM2/&gt;, ''on the Mechanical Action of Heat''
*1853–55: [[Thomas Anderson (chemist)|Thomas Anderson]]&lt;ref name = KM1&gt;{{cite web|url=http://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp1.pdf|title = Former Fellows of the Royal Society of Edinburgh|publisher=Royal Society of Edinburgh|accessdate= 29 November 2014}}&lt;/ref&gt;, ''on the Crystalline Constituents of Opium, and on the Products of the Destructive Distillation of Animal Substances''
*1855–57: [[George Boole]]&lt;ref name = CJO/&gt;, ''on the Application of the Theory of Probabilities to Questions of the Combination of Testimonies and Judgments''
*1857–59: ''Not awarded''&lt;ref name = CJO/&gt;
*1859–61: [[John Allan Broun]], ''on the Horizontal Force of the Earth’s Magnetism, on the Correction of the Bifilar Magnetometer, and on Terrestrial Magnetism generally''
*1861–63: [[William Thomson, 1st Baron Kelvin|William Thomson]]&lt;ref name = KM2/&gt;,''on some Kinematical and Dynamical Theorems''
*1863–65: [[James David Forbes]]&lt;ref name = KM1/&gt;, ''for Experimental Inquiry into the Laws of Conduction of Heat in Iron Bars''
*1865–67: [[Charles Piazzi Smyth]]&lt;ref name = KM2/&gt;, ''on Recent Measures at the Great Pyramid''
*1867–69: [[Peter Guthrie Tait]]&lt;ref name = KM2/&gt;, ''on the Rotation of a Rigid Body about a Fixed Point''
*1869–71: [[James Clerk Maxwell]]&lt;ref name = KM2/&gt;, ''on Figures, Frames, and Diagrams of Forces''
*1871–73: [[Peter Guthrie Tait]]&lt;ref name = KM2/&gt;, ''First Approximation to a Thermo-electric Diagram''
*1873–75: [[Alexander Crum Brown]]&lt;ref name = KM1/&gt;, ''on the Sense of Rotation, and on the Anatomical Relations of the Semicircular Canals of the Internal Ear''
*1875–77: [[Matthew Forster Heddle]]&lt;ref name = KM1/&gt;, ''on the Rhombohedral Carbonates'' and ''on the Felspars of Scotland''
*1877–79: [[Henry Charles Fleeming Jenkin]]&lt;ref name = KM1/&gt;, ''on the Application of Graphic Methods to the Determination of the Efficiency of Machinery''
*1879–81: [[George Chrystal]]&lt;ref name = KM1/&gt;, ''on the Differential Telephone''
*1881–83: [[Thomas Muir (mathematician)|Sir Thomas Muir]]&lt;ref name = KM2/&gt;, ''Researches into the Theory of Determinants and Continued Fractions''
*1883–85: [[John Aitken (meteorologist)|John Aitken]]&lt;ref&gt;{{Cite EB1922|wstitle=Aitken, John}}&lt;/ref&gt;, ''on the Formation of Small Clear Spaces in Dusty Air''
*1885–87: [[John Young Buchanan]]&lt;ref name = KM1/&gt;,''for a series of communications, extending over several years, on subjects connected with Ocean Circulation, Compressibility of Glass, etc.''
*1887–89: [[E. A. Letts|Edmund Albert Letts]]&lt;ref name = KM2/&gt;, ''for his papers on the Organic Compounds of Phosphorus''
*1889–91: [[Robert Traill Omond]]&lt;ref name = KM2/&gt;, ''for his contributions to Meteorological Science''
*1891–93: Sir [[Thomas Richard Fraser]]&lt;ref name = KM1/&gt;, ''for his papers on Strophanthus hispidus, Strophanthin, and Strophanthidin''
*1893–95: [[Cargill Gilston Knott]]&lt;ref name = KM2/&gt;, ''for his papers on the Strains produced by Magnetism in Iron and in Nickel''
*1895–97: [[Thomas Muir (mathematician)|Sir Thomas Muir]]&lt;ref name = KM2/&gt;, ''for his continued ommunications on Determinants and Allied Questions''
*1897–99: [[James Burgess (archaeologist)|James Burgess]]&lt;ref&gt;{{cite journal|url=http://www.tandfonline.com/doi/abs/10.1080/14702541608541591?journalCode=rsgj19#.VHkkVbtIPRo|title= Obituary-James Burgess|accessdate= 28 November 2014 | doi=10.1080/14702541608541591|volume=32|journal=Scottish Geographical Magazine|pages=535–538}}&lt;/ref&gt;&lt;ref name = KM1/&gt;, ''on the Definite Integral ...''

;20th/21st century
{{columns-list|colwidth=30em|
*1899–1901: [[Hugh Marshall]]&lt;ref name = KM2/&gt;, ''for his discovery of the Persulphates, and for his Communications on the Properties and Reactions of these Salts''
*1901–03: [[William Turner (anatomist)|Sir William Turner]]&lt;ref name = KM2/&gt;, ''for A Contribution to the Craniology of the People of Scotland'' and ''Contributions to the Craniology of the People of the Empire of India''
*1903–05: [[Thomas Hastie Bryce]]&lt;ref name = KM1/&gt;, ''for his two papers on The Histology of the Blood of the Larva of Lepidosiren paradoxa''
*1905–07: [[Alexander Bruce (neurologist)|Alexander Bruce]]&lt;ref name = KM2/&gt;, ''on the Distribution of the Cells in the Intermedio-Lateral Tract of the Spinal Cord''
*1907–09: Wheelton Hind, ''On the Lamellibranch and Gasteropod Fauna found in the Millstone Grit of Scotland
''
*1909–11: [[Alexander Smith (chemist)|Alexander Smith]]&lt;ref name = KM2/&gt;, ''for his researches upon Sulphur and upon Vapour Pressure''
*1911–13: James Russell&lt;ref name = KM2/&gt;, ''for his series of investigations relating to magnetic phenomena in metals and the molecular theory of magnetism''
*1913–15: [[James Hartley Ashworth]]&lt;ref name = KM1/&gt;
*1915–17: [[Robert Mossman|Robert Cockburn Mossmann]]&lt;ref name = KM2/&gt;
*1917–19: [[John Stephenson (zoologist)|John Stephenson]]&lt;ref name = KM2/&gt;
*1919–21: [[Ralph Allan Sampson]]&lt;ref name = KM2/&gt;
*1921–23: [[John Walter Gregory]]&lt;ref name = KM1/&gt;
*1923–25: [[Herbert Westren Turnbull]]&lt;ref name = KM2/&gt;
*1925–27: [[Robert Meldrum Craig]]&lt;ref name = KM1/&gt; jointly with ?
*1927–29: [[Christina Miller]]&lt;ref name = KM2/&gt;
*1929–31: [[Alan William Greenwood]]&lt;ref name = KM1/&gt;
*1931–33: [[Arthur Crichton Mitchell]]&lt;ref name = KM2/&gt;, ''for his work on geomagnetism''
*1933–35: [[Lancelot Thomas Hogben]]&lt;ref name = KM1/&gt;
*1935–37: [[Harold Stanley Ruse]]&lt;ref name = KM2/&gt;
*1937–39: [[Francis Albert Eley Crew]]&lt;ref name = KM1/&gt;
*1939–41: [[William McCrea (astronomer)|Sir William Hunter McCrea]]&lt;ref name = KM2/&gt; jointly with [[Edward Copson]]&lt;ref name = KM1/&gt;&lt;ref&gt;{{cite web|url=http://www.gap-system.org/~history/Extras/Copson_Professor.html |title=Archived copy |accessdate=2010-02-22 |deadurl=yes |archiveurl=https://web.archive.org/web/20110607140306/http://www.gap-system.org/~history/Extras/Copson_Professor.html |archivedate=2011-06-07 |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite news |url=https://news.google.com/newspapers?id=U0lAAAAAIBAJ&amp;sjid=gVkMAAAAIBAJ&amp;pg=6395%2C1703292 |title=The Royal Society of Edinburgh. Keith Prize Award |work=[[The Glasgow Herald]] |date=2 June 1942 |page=5 |accessdate=17 March 2017}}&lt;/ref&gt;
*1941–43: [[James Ritchie (naturalist)|James Ritchie]]&lt;ref name = KM2/&gt;
*1943–45: [[William Edge (mathematician)|William Leonard Edge]]&lt;ref name = KM1/&gt;
*1945–47: [[Charlotte Auerbach]]&lt;ref name = KM1/&gt;
*1947–49: [[Arthur Geoffrey Walker]]&lt;ref name = KM2/&gt;
*1949–51: [[Alastair Graham]] &lt;ref&gt; {{cite web|url=http://www.malacsoc.org.uk/malacological_bulletin/BULL37/OBITUARY.htm|title=Professor Alistair Graham FRS|publisher= Malacological Society|accessdate= 17 November 2017}} &lt;/ref&gt;
*1951–53: [[Daniel Edwin Rutherford]]&lt;ref name = KM2/&gt;
*1953–55: [[Alexander David Peacock]]&lt;ref name = KM2/&gt;
*1955–57: [[Ivor Malcolm Haddon Etherington]]&lt;ref name = KM1/&gt;
*1957–59: [[John Barclay Tait]]&lt;ref name = KM2/&gt;
*1959–61:
*1961–63: [[Robert Alexander Rankin]]&lt;ref name = KM2/&gt;
*1963–65: [[Reinhold Furth|Reinhold Henry Furth]]&lt;ref name = KM1/&gt;
*1965–67: [[Alexander John Haddow]]&lt;ref name = KM1/&gt;
*1967–69: [[Henry Jack]]&lt;ref name = KM1/&gt;
*1969–71: [[Charles Dewar Waterston]]&lt;ref name = RSE2013&gt;{{cite web| url =http://www.royalsoced.org.uk/cms/files/publications/directory/directory_nolist.pdf| title= Directory 2013/2014|publisher= RSE|accessdate = 29 November 2014}}&lt;/ref&gt;
*1971–73: [[Douglas Samuel Jones]]&lt;ref&gt; {{cite web|url=https://www.rse.org.uk/cms/files/fellows/obits_alpha/Jones_DS.pdf|title=Douglas Samuel Jones|publisher= Royal Society of Edinburgh|accessdate=17 November 2017}} &lt;/ref&gt;
*1973–75: [[Kenneth Lyon Blaxter]]&lt;ref name = KM1/&gt;
*1975–77: Michael Stephen Patrick Eastham &lt;ref&gt; {{cite web|url=https://www.cardiff.ac.uk/obituaries/obituary/michael-stephen|title=Professor Michael Stephen Patrick Eastham|publisher= Cardiff University|accessdate= 17 November 2017}} &lt;/ref&gt;
*1977–79: [[Brian John Bluck]]&lt;ref name = RSE2013/&gt;
*1979–81: [[John Mackintosh Howie]]
*1981–83: [[John Heslop-Harrison]]&lt;ref name = KM1/&gt;
*1983–85: [[John Bryce McLeod]]&lt;ref name = RSE2013/&gt;&lt;ref&gt;{{cite web|url=http://www.maths.ox.ac.uk/node/12898| title=Professor John Bryce McLeod FRS FRSE (1929 - 2014)|publisher=University of Oxford|accessdate=28 November 2014}}&lt;/ref&gt;
*1985–87: 
*1987–89: [[John Macleod Ball]]&lt;ref name = RSE2013/&gt;
*1989–91: 
*1991–93:
*1993–95: [[Euan Clarkson]] (78th award)&lt;ref name = RSE2013/&gt;
*1995–97: ''No award''
*1997–99: [[Vladimír Šverák]] (79th award)
*1999–2001:
*2001–03: ''No award''
*2005–07: ''No award''
*2007: [[Antonio DeSimone]], [[Stefan Müller (mathematician)|Stefan Müller]], [[Robert Kohn (mathematician)|Robert Kohn]], [[Felix Otto (mathematician)|Felix Otto]]
* ''Medal no longer awarded''
}}

==References==
{{reflist}}

==External links==
*[http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=8735503 Awards of Keith Prize 1827-1890]
*[https://web.archive.org/web/20081122042710/http://www.rse.org.uk/research_fellowships/prizes/winners.htm List of recent winners]
*[http://www.nature.com/nature/journal/v22/n549/abs/022016a0.html Announcement of Jenkin's award]

[[Category:British science and technology awards]]
[[Category:Mathematics awards]]
[[Category:Royal Society of Edinburgh]]
[[Category:Scottish awards]]
[[Category:1827 establishments in Scotland]]
[[Category:Awards established in 1827]]</text>
      <sha1>t1un294n399esge6bdivjkezhixsh27</sha1>
    </revision>
  </page>
  <page>
    <title>Lagrange polynomial</title>
    <ns>0</ns>
    <id>217523</id>
    <revision>
      <id>864631885</id>
      <parentid>863568391</parentid>
      <timestamp>2018-10-18T13:40:10Z</timestamp>
      <contributor>
        <username>Kegelkugel</username>
        <id>15089198</id>
      </contributor>
      <minor/>
      <comment>/* A perspective from linear algebra */ fixed link to Fast Fourier Transform</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17766">[[Image:Lagrange polynomial.svg|thumb|upright=2|This image shows, for four points (&lt;span style="color:#5e81B5;"&gt;(&amp;minus;9,&amp;nbsp;5)&lt;/span&gt;, &lt;span style="color:#e19c24;"&gt;(&amp;minus;4,&amp;nbsp;2)&lt;/span&gt;, &lt;span style="color:#8FB131;"&gt;(&amp;minus;1,&amp;nbsp;&amp;minus;2)&lt;/span&gt;, &lt;span style="color:#EC6235;"&gt;(7,&amp;nbsp;9)&lt;/span&gt;), the (cubic) interpolation polynomial &lt;span style="color:black;"&gt;''L''(''x'')&lt;/span&gt; (dashed, black), which is the sum of the ''scaled'' basis polynomials &lt;span style="color:#5e81B5;"&gt;y&lt;sub&gt;0&lt;/sub&gt;''ℓ''&lt;sub&gt;0&lt;/sub&gt;(''x'')&lt;/span&gt;, &lt;span style="color:#e19c24;"&gt;y&lt;sub&gt;1&lt;/sub&gt;''ℓ''&lt;sub&gt;1&lt;/sub&gt;(''x'')&lt;/span&gt;, &lt;span style="color:#8FB131;"&gt;y&lt;sub&gt;2&lt;/sub&gt;''ℓ''&lt;sub&gt;2&lt;/sub&gt;(''x'')&lt;/span&gt; and &lt;span style="color:#EC6235;"&gt;y&lt;sub&gt;3&lt;/sub&gt;''ℓ''&lt;sub&gt;3&lt;/sub&gt;(''x'')&lt;/span&gt;. The interpolation polynomial passes through all four control points, and each ''scaled'' basis polynomial passes through its respective control point and is 0 where ''x'' corresponds to the other three control points.]]

In [[numerical analysis]], '''Lagrange polynomials''' are used for [[polynomial interpolation]]. For a given set of points &lt;math&gt;(x_j,y_j)&lt;/math&gt; with no two &lt;math&gt;x_j&lt;/math&gt; values equal, the Lagrange polynomial is the polynomial of lowest [[degree of a polynomial|degree]] that assumes at each value &lt;math&gt;x_j&lt;/math&gt; the corresponding value &lt;math&gt;y_j&lt;/math&gt; (i.e. the functions coincide at each point).
The interpolating polynomial of the least degree is unique, however, and since it can be arrived at through multiple methods, referring to "the Lagrange polynomial" is perhaps not as correct as referring to "the Lagrange form" of that unique polynomial.

Although named after [[Joseph Louis Lagrange]], who published it in 1795, the method was first discovered in 1779 by [[Edward Waring]]&lt;ref&gt;{{cite journal
 |title=Problems concerning interpolations
 |first=Edward |last=Waring |authorlink=Edward Waring
 |journal=[[Philosophical Transactions of the Royal Society]]
 |date=9 January 1779 |volume=69 |pages=59–67
 |doi=10.1098/rstl.1779.0008
 |url=http://rstl.royalsocietypublishing.org/content/69/59.full.pdf
}}&lt;/ref&gt; It is also an easy consequence of a formula published in 1783 by [[Leonhard Euler]].&lt;ref&gt;{{Cite journal
 | last1=Meijering | first1=Erik
 | title=A chronology of interpolation: from ancient astronomy to modern signal and image processing
 | doi=10.1109/5.993400 | year=2002
 | journal=Proceedings of the IEEE | volume=90 | issue=3 | pages=319–342
 | url = http://bigwww.epfl.ch/publications/meijering0201.pdf}}&lt;/ref&gt;

Uses of Lagrange polynomials include the [[Newton–Cotes formulas|Newton–Cotes method]] of [[numerical integration]] and [[Shamir's Secret Sharing|Shamir's secret sharing scheme]] in [[cryptography]].

Lagrange interpolation is susceptible to [[Runge's phenomenon]] of large oscillation. As changing the points &lt;math&gt;x_j&lt;/math&gt; requires recalculating the entire interpolant, it is often easier to use [[Newton polynomials]] instead.

==Definition==
Given a set of ''k''&amp;nbsp;+&amp;nbsp;1 data points
:&lt;math&gt;(x_0, y_0),\ldots,(x_j, y_j),\ldots,(x_k, y_k)&lt;/math&gt;
where no two &lt;math&gt;x_j&lt;/math&gt; are the same, the '''interpolation polynomial in the Lagrange form''' is a [[linear combination]]
:&lt;math&gt;L(x) := \sum_{j=0}^{k} y_j \ell_j(x)&lt;/math&gt;
of Lagrange basis polynomials
:&lt;math&gt;\ell_j(x) := \prod_{\begin{smallmatrix}0\le m\le k\\ m\neq j\end{smallmatrix}} \frac{x-x_m}{x_j-x_m} = \frac{(x-x_0)}{(x_j-x_0)} \cdots \frac{(x-x_{j-1})}{(x_j-x_{j-1})} \frac{(x-x_{j+1})}{(x_j-x_{j+1})} \cdots \frac{(x-x_k)}{(x_j-x_k)},&lt;/math&gt;[[File:Lagrange basis functions.svg|thumb|Here we plot the Lagrange basis functions of 1st, 2nd, and 3rd order on a bi-unit domain. Linear combinations of Lagrange basis functions are used to construct Lagrange interpolating polynomials. Lagrange basis functions are commonly used in Finite Element Analysis as the bases for the element shape-functions. Furthermore, it is common to use a bi-unit domain as the natural space for the finite-element's definition.]]

where &lt;math&gt;0\le j\le k&lt;/math&gt;. Note how, given the initial assumption that no two &lt;math&gt;x_j&lt;/math&gt; are the same, &lt;math&gt;x_j - x_m \neq 0&lt;/math&gt;, so this expression is always well-defined. The reason pairs &lt;math&gt;x_i = x_j&lt;/math&gt; with &lt;math&gt;y_i\neq y_j&lt;/math&gt; are not allowed is that no interpolation function &lt;math&gt;L&lt;/math&gt; such that &lt;math&gt;y_i = L(x_i)&lt;/math&gt; would exist; a function can only get one value for each argument &lt;math&gt;x_i&lt;/math&gt;. On the other hand, if also &lt;math&gt;y_i = y_j&lt;/math&gt;, then those two points would actually be one single point.

For all &lt;math&gt;i\neq j&lt;/math&gt;, &lt;math&gt;\ell_j(x)&lt;/math&gt; includes the term &lt;math&gt;(x-x_i)&lt;/math&gt; in the numerator, so the whole product will be zero at &lt;math&gt;x=x_i&lt;/math&gt;:
:&lt;math&gt;\ell_{j\ne i}(x_i) = \prod_{m\neq j} \frac{x_i-x_m}{x_j-x_m} = \frac{(x_i-x_0)}{(x_j-x_0)} \cdots \frac{(x_i-x_i)}{(x_j-x_i)} \cdots \frac{(x_i-x_k)}{(x_j-x_k)} = 0.&lt;/math&gt;

On the other hand,
:&lt;math&gt;\ell_i(x_i) := \prod_{m\neq i} \frac{x_i-x_m}{x_i-x_m} = 1&lt;/math&gt;

In other words, all basis polynomials are zero at &lt;math&gt;x=x_i&lt;/math&gt;, except &lt;math&gt;\ell_i(x)&lt;/math&gt;, for which it holds that &lt;math&gt;\ell_i(x_i)=1&lt;/math&gt;, because it lacks the &lt;math&gt;(x-x_i)&lt;/math&gt; term.

It follows that &lt;math&gt;y_i \ell_i(x_i)=y_i&lt;/math&gt;, so at each point &lt;math&gt;x_i&lt;/math&gt;, &lt;math&gt;L(x_i)=y_i+0+0+\dots +0=y_i&lt;/math&gt;, showing that &lt;math&gt;L&lt;/math&gt; interpolates the function exactly.

==Proof==

The function ''L''(''x'') being sought is a polynomial in &lt;math&gt;x&lt;/math&gt; of the least degree that interpolates the given data set; that is, assumes value &lt;math&gt;y_j&lt;/math&gt; at the corresponding &lt;math&gt;x_j&lt;/math&gt; for all data points &lt;math&gt;j&lt;/math&gt;:

:&lt;math&gt;L(x_j) = y_j \qquad j=0,\ldots,k&lt;/math&gt;

Observe that:
# In &lt;math&gt;\ell_j(x)&lt;/math&gt; there are ''k'' factors in the product and each factor contains one ''x'', so ''L''(''x'') (which is a sum of these ''k''-degree polynomials) must be a polynomial of degree at most ''k''.
# &lt;math&gt;\ell_j(x_i)
= \prod_{m=0,\, m\neq j}^{k} \frac{x_i-x_m}{x_j-x_m}
&lt;/math&gt;

We consider what happens when this product is expanded.  Because the product skips &lt;math&gt;m = j&lt;/math&gt;, if &lt;math&gt;i = j&lt;/math&gt; then all terms are &lt;math&gt;\frac{x_j-x_m}{x_j-x_m} = 1&lt;/math&gt; (except where &lt;math&gt;x_j = x_m&lt;/math&gt;, but that case is impossible, as pointed out in the definition section—in that term, &lt;math&gt;m=j&lt;/math&gt;, and since &lt;math&gt;m\neq j&lt;/math&gt;, &lt;math&gt;i\neq j&lt;/math&gt;, contrary to &lt;math&gt;i=j&lt;/math&gt;).
Also if &lt;math&gt;i \neq j&lt;/math&gt; then since &lt;math&gt;m \neq j&lt;/math&gt; does not preclude it, one term in the product '''will''' be for &lt;math&gt;m=i&lt;/math&gt;, i.e. &lt;math&gt;\frac{x_i-x_i}{x_j-x_i} = 0&lt;/math&gt;, zeroing the entire product. So
# &lt;math&gt;\ell_j(x_i)
 = \delta_{ji} = \begin{cases} 
1, &amp; \text{if } j=i   \\ 
0, &amp; \text{if } j \ne i \end{cases}
&lt;/math&gt;

where &lt;math&gt;\delta_{ij}&lt;/math&gt; is the [[Kronecker delta]]. So:

: &lt;math&gt;L(x_i) = \sum_{j=0}^k y_j \ell_j(x_i) = \sum_{j=0}^{k} y_j \delta_{ji} = y_i.&lt;/math&gt;

Thus the function ''L''(''x'') is a polynomial with degree at most ''k'' and where &lt;math&gt;L(x_i) = y_i&lt;/math&gt;.

Additionally, the interpolating polynomial is unique, as shown by the unisolvence theorem at the [[Polynomial interpolation#Uniqueness of the interpolating polynomial|polynomial interpolation]] article.

==A perspective from linear algebra==

Solving an [[Polynomial interpolation#Constructing the interpolation polynomial|interpolation problem]] leads to a problem in [[linear algebra]] amounting to inversion of a matrix. Using a standard [[monomial basis]] for our interpolation polynomial &lt;math&gt;L(x) = \sum_{j=0}^k x^j m_j&lt;/math&gt;, we must invert the [[Vandermonde matrix]] &lt;math&gt;(x_i)^j&lt;/math&gt; to solve &lt;math&gt;L(x_i) = y_i&lt;/math&gt; for the coefficients &lt;math&gt;m_j&lt;/math&gt; of &lt;math&gt;L(x)&lt;/math&gt;. By choosing a better basis, the Lagrange basis,  &lt;math&gt;L(x) = \sum_{j=0}^k l_j(x) y_j&lt;/math&gt;, we merely get the [[identity matrix]], [[Kronecker delta|&lt;math&gt;\delta_{ij}&lt;/math&gt;]], which is its own inverse: the Lagrange basis automatically ''inverts'' the analog of the Vandermonde matrix.

This construction is analogous to the [[Chinese Remainder Theorem]]. Instead of checking for remainders of integers modulo prime numbers, we are checking for remainders of polynomials when divided by linears.


Furthermore, when the order is large, [[Fast Fourier transform|Fast Fourier Transformation]] can be used to solve for the coefficients of the interpolated polynomial.

==Examples==

===Example 1===
We wish to interpolate ''ƒ''(''x'')&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt; over the range 1&amp;nbsp;≤&amp;nbsp;''x''&amp;nbsp;≤&amp;nbsp;3, given these three points:

: &lt;math&gt;
\begin{align}
x_0 &amp; = 1 &amp; &amp; &amp; f(x_0) &amp; = 1 \\
x_1 &amp; = 2 &amp; &amp; &amp; f(x_1) &amp; = 4 \\
x_2 &amp; = 3 &amp; &amp; &amp; f(x_2) &amp; =9.
\end{align}
&lt;/math&gt;

The interpolating polynomial is:
:&lt;math&gt; \begin{align}
L(x) &amp;= {1}\cdot{x - 2 \over 1 - 2}\cdot{x - 3 \over 1 - 3}+{4}\cdot{x - 1 \over 2 - 1}\cdot{x - 3 \over 2 - 3}+{9}\cdot{x - 1 \over 3 - 1}\cdot{x - 2 \over 3 - 2} \\[10pt]
&amp;= x^2.
\end{align} &lt;/math&gt;

===Example 2===
We wish to interpolate ''ƒ''(''x'')&amp;nbsp;=&amp;nbsp;''x''&lt;sup&gt;3&lt;/sup&gt; over the range 1&amp;nbsp;≤&amp;nbsp;''x''&amp;nbsp;≤&amp;nbsp;3, given these three points:
{| cellpadding=10px
|-
| &lt;math&gt;x_0=1&lt;/math&gt;  || &lt;math&gt;f(x_0)=1&lt;/math&gt;
|-
| &lt;math&gt;x_1=2&lt;/math&gt; || &lt;math&gt;f(x_1)=8&lt;/math&gt;
|-
| &lt;math&gt;x_2=3&lt;/math&gt;     || &lt;math&gt;f(x_2)=27&lt;/math&gt;
|}

The interpolating polynomial is:
:&lt;math&gt; \begin{align}
L(x) &amp;= {1}\cdot{x - 2 \over 1 - 2}\cdot{x - 3 \over 1 - 3}+{8}\cdot{x - 1 \over 2 - 1}\cdot{x - 3 \over 2 - 3}+{27}\cdot{x - 1 \over 3 - 1}\cdot{x - 2 \over 3 - 2} \\[8pt]
&amp;=  6x^2 - 11x + 6.
\end{align} &lt;/math&gt;

===Notes===
[[File:Runge's phenomenon in Lagrange polynomials.svg|thumb|upright=2|Example of interpolation divergence for a set of Lagrange polynomials.]]

The Lagrange form of the interpolation polynomial shows the linear character of polynomial interpolation and the uniqueness of the interpolation polynomial.  Therefore, it is preferred in proofs and theoretical arguments.  Uniqueness can also be seen from the invertibility of the Vandermonde matrix, due to the non-vanishing of the [[Vandermonde determinant]].

But, as can be seen from the construction, each time a node ''x''&lt;sub&gt;''k''&lt;/sub&gt; changes, all Lagrange basis polynomials have to be recalculated. A better form of the interpolation polynomial for practical (or computational) purposes is the barycentric form of the Lagrange interpolation (see below) or [[Newton polynomial]]s. &lt;!-- Using [[Horner scheme|nested multiplication]] amounts to the same idea. --&gt;

Lagrange and other interpolation at equally spaced points, as in the example above, yield a polynomial oscillating above and below the true function. This behaviour tends to grow with the number of points, leading to a divergence known as [[Runge's phenomenon]]; the problem may be eliminated by choosing interpolation points at [[Chebyshev nodes]].&lt;ref&gt;{{cite book|title=Scientific Computing with MATLAB|volume=2|series=Texts in computational science and engineering|first1=Alfio|last1=Quarteroni|first2=Fausto|last2=Saleri|publisher=Springer|year=2003|isbn=978-3-540-44363-6|page=66|url=https://books.google.com/books?id=fE1W5jsU4zoC&amp;pg=PA66}}.&lt;/ref&gt;

The Lagrange basis polynomials can be used in [[numerical integration]] to derive the [[Newton–Cotes formulas]].
&lt;!-- Lagrange interpolation is often used in [[digital signal processing]] of audio for the implementation of fractional delay [[finite impulse response|FIR]] filters (e.g., to precisely tune [[digital waveguide synthesis|digital waveguides]] in [[physical modelling synthesis]]). --&gt;

==Barycentric form==

Using

:&lt;math&gt;\ell(x) = (x - x_0)(x - x_1) \cdots (x - x_k)&lt;/math&gt;
:&lt;math&gt;\ell'(x_j) = \frac{\mathrm{d} \ell(x)}{\mathrm{d} x}\Big|_{x=x_j} = \prod_{i=0,i \neq j}^k(x_j-x_i) &lt;/math&gt;

we can rewrite the Lagrange basis polynomials as

:&lt;math&gt;\ell_j(x) = \frac{\ell(x)}{\ell'(x_j)(x-x_j)} &lt;/math&gt;
or, by defining the ''barycentric weights''&lt;ref&gt;{{cite journal
 | first1 = Jean-Paul | last1 = Berrut
 | first2 = Lloyd N. | last2 = Trefethen |authorlink = Lloyd N. Trefethen
 | year = 2004
 | title = Barycentric Lagrange Interpolation
 | journal = [[Society for Industrial and Applied Mathematics|SIAM]] Review
 | volume = 46
 | issue = 3
 | pages = 501&amp;ndash;517
 | doi = 10.1137/S0036144502417715
 | url = https://people.maths.ox.ac.uk/trefethen/barycentric.pdf
 }}&lt;/ref&gt;

:&lt;math&gt;w_j = \frac{1}{\ell'(x_j)}&lt;/math&gt;

we can simply write

:&lt;math&gt;\ell_j(x) = \ell(x)\frac{w_j}{x-x_j}&lt;/math&gt;

which is commonly referred to as the ''first form'' of the barycentric interpolation formula.

The advantage of this representation is that the interpolation polynomial may now be evaluated as

:&lt;math&gt;L(x) = \ell(x) \sum_{j=0}^k \frac{w_j}{x-x_j}y_j&lt;/math&gt;

which, if the weights &lt;math&gt;w_j&lt;/math&gt; have been pre-computed, requires only &lt;math&gt;\mathcal O(n)&lt;/math&gt; operations (evaluating &lt;math&gt;\ell(x)&lt;/math&gt; and the weights &lt;math&gt;w_j/(x-x_j)&lt;/math&gt;) as opposed to &lt;math&gt;\mathcal O(n^2)&lt;/math&gt; for evaluating the Lagrange basis polynomials &lt;math&gt;\ell_j(x)&lt;/math&gt; individually.

The barycentric interpolation formula can also easily be updated to incorporate a new node &lt;math&gt;x_{k+1}&lt;/math&gt; by dividing each of the &lt;math&gt;w_j&lt;/math&gt;, &lt;math&gt;j=0 \dots k&lt;/math&gt; by &lt;math&gt;(x_j - x_{k+1})&lt;/math&gt; and constructing the new &lt;math&gt;w_{k+1}&lt;/math&gt; as above.

We can further simplify the first form by first considering the barycentric interpolation of the constant function &lt;math&gt;g(x)\equiv 1&lt;/math&gt;:

:&lt;math&gt;g(x) = \ell(x) \sum_{j=0}^k \frac{w_j}{x-x_j}.&lt;/math&gt;

Dividing &lt;math&gt;L(x)&lt;/math&gt; by &lt;math&gt;g(x)&lt;/math&gt; does not modify the interpolation, yet yields

:&lt;math&gt;L(x) = \frac{\sum_{j=0}^k \frac{w_j}{x-x_j}y_j}{\sum_{j=0}^k \frac{w_j}{x-x_j}}&lt;/math&gt;

which is referred to as the ''second form'' or ''true form'' of the barycentric interpolation formula. This second form has the advantage that &lt;math&gt;\ell(x)&lt;/math&gt; need not be evaluated for each evaluation of &lt;math&gt;L(x)&lt;/math&gt;.

==Remainder in Lagrange interpolation formula==
When interpolating a given function ''f'' by a polynomial of degree {{mvar|n}} at the nodes ''x''&lt;sub&gt;0&lt;/sub&gt;,...,''x''&lt;sub&gt;''n''&lt;/sub&gt; we get the remainder &lt;math&gt;R(x) = f(x) - L(x)&lt;/math&gt; which can be expressed as&lt;ref&gt;{{AS ref|25, eqn 25.2.3|878}}&lt;/ref&gt;

:&lt;math&gt; R(x) = f[x_0,\ldots,x_n,x] \ell(x) = \ell(x) \frac{f^{n+1}(\xi)}{(n+1)!},  \quad \quad x_0 &lt; \xi &lt; x_n,&lt;/math&gt;

where &lt;math&gt;f[x_0,\ldots,x_n,x]&lt;/math&gt; is the notation for [[divided differences]]. Alternatively, the remainder can be expressed as a contour integral in complex domain as

:&lt;math&gt;R(z) = \frac{\ell(z)}{2\pi i} \int_C \frac{f(t)}{(t-z)(t-z_0) \cdots (t-z_n)} dt = \frac{\ell(z)}{2\pi i} \int_C \frac{f(t)}{(t-z)\ell(t)} dt.&lt;/math&gt;

The remainder can be bound as

:&lt;math&gt;|R(x)| \leq \frac{(x_n-x_0)^{n+1}}{(n+1)!}\max_{x_0 \leq \xi \leq x_n} |f^{(n+1)}(\xi)|. &lt;/math&gt;

==Derivatives==
The &lt;math&gt;d&lt;/math&gt;th derivatives of the Lagrange polynomial can be written as

:&lt;math&gt;L^{(d)}(x) := \sum_{j=0}^{k} y_j \ell_j^{(d)}(x)&lt;/math&gt;.

For the first derivative, the coefficients are given by

:&lt;math&gt;\ell_j^{(1)}(x) := \sum_{i=0, i\not=j}^k \left[ \frac{1}{x_j-x_i}\prod_{m=0,m\not = (i , j)}^k \frac{x-x_m}{x_j-x_m} \right]&lt;/math&gt;

and for the second derivative 

:&lt;math&gt;\ell^{(2)}_j(x) := \sum_{i=0, i\ne j}^{k} \frac{1}{x_j-x_i} \left[ \sum_{m=0,m\ne(i,j)}^{k} \left( \frac{1}{x_j-x_m}\prod_{l=0, l\ne(i,j,m)}^{k} \frac{x-x_l}{x_j-x_l} \right) \right] &lt;/math&gt;.

Through recursion, one can compute formulas for higher derivatives.

==Finite fields==
The Lagrange polynomial can also be computed in [[finite field]]s.  This has applications in [[cryptography]], such as in [[Shamir's Secret Sharing]] scheme.

==See also==
*[[Neville's algorithm]]
*[[Newton polynomial|Newton form]] of the interpolation polynomial
*[[Bernstein polynomial]]
*[[Carlson's theorem]]
*[[Lebesgue constant (interpolation)]]
*[[Chebfun|The Chebfun system]]
*[[Table of Newtonian series]]
*[[Frobenius covariant]]
*[[Sylvester's formula]]
*[[Finite difference coefficient]]

==References==
{{reflist}}

==External links==
* {{springer|title=Lagrange interpolation formula|id=p/l057170}}
* [http://www.alglib.net/interpolation/polynomial.php ALGLIB] has an implementations in C++ / C# / VBA / Pascal.
* [https://www.gnu.org/software/gsl/ GSL] has a polynomial interpolation code in C
* [https://stackoverflow.com/questions/11029615/lagrange-interpolation-method/11552763 SO] has a MATLAB example that demonstrates the algorithm and recreates the first image in this article
* [http://numericalmethods.eng.usf.edu/topics/lagrange_method.html Lagrange Method of Interpolation &amp;mdash; Notes, PPT, Mathcad, Mathematica, MATLAB, Maple] at [http://numericalmethods.eng.usf.edu Holistic Numerical Methods Institute]
*[http://www.math-linux.com/spip.php?article71 Lagrange interpolation polynomial] on www.math-linux.com
* {{MathWorld|urlname=LagrangeInterpolatingPolynomial|title=Lagrange Interpolating Polynomial}}
{{ProofWiki|id=Lagrange_Polynomial_Approximation|title=Estimate of the error in Lagrange Polynomial Approximation}}
* [http://jsxgraph.uni-bayreuth.de/wiki/index.php/Lagrange_interpolation Dynamic Lagrange interpolation with JSXGraph]
* Numerical computing with functions: [https://web.archive.org/web/20101013180326/http://www2.maths.ox.ac.uk/chebfun/ The Chebfun Project]
* [http://mathformeremortals.wordpress.com/2013/01/15/bicubic-interpolation-excel-worksheet-function/ Excel Worksheet Function for Bicubic Lagrange Interpolation]
* [http://pastebin.com/bNVcQt4x Lagrange polynomials in Python]

{{DEFAULTSORT:Lagrange Polynomial}}
[[Category:Interpolation]]
[[Category:Polynomials]]
[[Category:Articles containing proofs]]

[[de:Lagrange-Polynom]]
[[he:אינטרפולציה#צורת לגראנז']]</text>
      <sha1>plp2x36uy2k2zols6jfu65gfvvxm56x</sha1>
    </revision>
  </page>
  <page>
    <title>Lambda calculus</title>
    <ns>0</ns>
    <id>18203</id>
    <revision>
      <id>870846628</id>
      <parentid>870846591</parentid>
      <timestamp>2018-11-27T10:46:34Z</timestamp>
      <contributor>
        <username>Binod Basnet</username>
        <id>33136685</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/117.211.50.139|117.211.50.139]] ([[User talk:117.211.50.139|talk]]) to last revision by 12.130.9.139. ([[Wikipedia:Twinkle|Twinkle]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="77312">'''Lambda calculus''' (also written as '''λ-calculus''') is a [[formal system]] in [[mathematical logic]] for expressing [[computability|computation]] based on function [[Abstraction (computer science)|abstraction]] and [[function application|application]] using variable [[Name binding|binding]] and [[Substitution (algebra)|substitution]]. It is a universal [[model of computation]] that can be used to simulate any [[Turing machine]]. It was first introduced by mathematician [[Alonzo Church]] in the 1930s as part of his research of the [[foundations of mathematics]].

Lambda calculus consists of constructing lambda terms and performing reduction operations on them. In the simplest form of lambda calculus, terms are built using only the following rules:
{| class="wikitable"
|-
! Syntax !! Name !! Description
|-
| x || Variable || A character or string representing a parameter or mathematical/logical value
|-
| (λx.M) || Abstraction || Function definition (M is a lambda term). The variable x becomes [[Free variables and bound variables|bound]] in the expression.
|-
| (M N) || Application || Applying a function to an argument. M and N are lambda terms.
|}

producing expressions such as: (λ''x''.λ''y''.(λ''z''.(λ''x''.''z x'') (λ''y.z y'')) (''x y'')). Parentheses can be dropped if the expression is unambiguous. For some applications, terms for logical and mathematical constants and operations may be included.

The reduction operations include:

{| class="wikitable"
|-
! Operation !! Name !! Description
|-
| (λx.M[x]) → (λy.M[y]) || α-conversion || Renaming the bound (formal) variables in the expression. Used to avoid [[name collision]]s.
|-
| ((λx.M) E) → (M[x:=E]) || β-reduction || Replacing the bound variable with the argument expression in the body of the abstraction
|}

If [[De Bruijn index]]ing is used then α-conversion is no longer required as there will be no name collisions. If [[Reduction strategy (lambda calculus)|repeated application]] of the reduction steps eventually terminates then by the [[Church-Rosser theorem]] it will produce a [[beta normal form]].

==Explanation and applications==
Lambda calculus is [[Turing completeness|Turing complete]], that is, it is a universal [[model of computation]] that can be used to simulate any [[Turing machine]].&lt;ref&gt;{{cite journal |first=A. M. |last=Turing |authorlink=Alan Turing |title=Computability and λ-Definability |jstor=2268280 |journal=The Journal of Symbolic Logic |volume=2 |issue=4 |date=December 1937 |pages=153–163 |doi=10.2307/2268280}}&lt;/ref&gt; Its namesake, the Greek letter lambda (λ), is used in '''lambda expressions''' and '''lambda terms''' to denote [[Free variables and bound variables|binding]] a variable in a [[function (mathematics)|function]].

Lambda calculus may be ''untyped'' or ''typed''. In typed lambda calculus, functions can be applied only if they are capable of accepting the given input's "type" of data. Typed lambda calculi are ''weaker'' than the untyped lambda calculus that is the primary subject of this article, in the sense that ''typed lambda calculi can express less'' than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proved; in the [[simply typed lambda calculus]] it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate. One reason there are many different typed lambda calculi has been the desire to do more (of what the untyped calculus can do) without giving up on being able to prove strong theorems about the calculus.

Lambda calculus has applications in many different areas in [[mathematics]], [[philosophy]],&lt;ref&gt;[[Thierry Coquand|Coquand, Thierry]], [http://plato.stanford.edu/archives/sum2013/entries/type-theory/ "Type Theory"], ''The Stanford Encyclopedia of Philosophy''  (Summer 2013 Edition), Edward N. Zalta (ed.).&lt;/ref&gt; [[linguistics]],&lt;ref&gt;{{cite book |url=https://books.google.com/books?id=9CdFE9X_FCoC |title=Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus |first=Michael |last=Moortgat |publisher=Foris Publications |year=1988 |isbn=9789067653879}}&lt;/ref&gt;&lt;ref&gt;{{Citation|url=https://books.google.com/books?id=nyFa5ngYThMC |title=Computing Meaning |editor1-first=Harry |editor1-last=Bunt |editor2-first=Reinhard |editor2-last=Muskens |publisher=Springer |year=2008 |isbn=9781402059575}}&lt;/ref&gt; and [[computer science]].&lt;ref&gt;{{citation|title=Concepts in Programming Languages|first=John C.|last=Mitchell|authorlink=John C. Mitchell|publisher=Cambridge University Press|year=2003|isbn=9780521780988|page=57|url=https://books.google.com/books?id=7Uh8XGfJbEIC&amp;pg=PA57}}.&lt;/ref&gt; Lambda calculus has played an important role in the development of the [[Programming language theory|theory of programming languages]]. [[Functional programming language]]s implement the lambda calculus. Lambda calculus is also a current research topic in [[Category theory]].&lt;ref&gt;{{cite book |title=Basic Category Theory for Computer Scientists|page=53|first=Benjamin C.|last=Pierce|authorlink=Benjamin C. Pierce}}&lt;/ref&gt;

==History==
The lambda calculus was introduced by mathematician [[Alonzo Church]] in the 1930s as part of an investigation into the [[foundations of mathematics]].&lt;ref&gt;{{cite journal |first=A. |last=Church |authorlink=Alonzo Church |title=A set of postulates for the foundation of logic |journal=Annals of Mathematics |series=Series 2 |volume=33 |issue=2 |pages=346–366 |year=1932 |doi=10.2307/1968337 |jstor=1968337}}&lt;/ref&gt;&lt;ref&gt;For a full history, see Cardone and Hindley's "History of Lambda-calculus and Combinatory Logic" (2006).&lt;/ref&gt; The original system was shown to be [[Consistency|logically inconsistent]] in 1935 when [[Stephen Kleene]] and [[J. B. Rosser]] developed the [[Kleene–Rosser paradox]].&lt;ref&gt;{{cite journal|last1=Kleene|first1=S. C.|authorlink1=Stephen Kleene|last2=Rosser|first2=J. B.|authorlink2=J. B. Rosser|title=The Inconsistency of Certain Formal Logics|journal=The Annals of Mathematics|date=July 1935|volume=36|issue=3|pages=630|doi=10.2307/1968646}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Church|first=Alonzo|authorlink=Alonzo Church|title=Review of Haskell B. Curry, ''The Inconsistency of Certain Formal Logics''|journal=The Journal of Symbolic Logic|date=December 1942|volume=7|issue=4|pages=170–171|doi=10.2307/2268117|jstor=2268117}}&lt;/ref&gt;

Subsequently, in 1936 Church isolated and published just the portion relevant to computation, what is now called the untyped lambda calculus.&lt;ref&gt;{{cite journal |first=A. |last=Church |authorlink=Alonzo Church |title=An unsolvable problem of elementary number theory |journal=American Journal of Mathematics |volume=58 |number=2 |year=1936 |pages=345–363 |doi=10.2307/2371045 |jstor=2371045 }}&lt;/ref&gt; In 1940, he also introduced a computationally weaker, but logically consistent system, known as the [[simply typed lambda calculus]].&lt;ref&gt;{{cite journal | last1 = Church | authorlink=Alonzo Church | first1 = A. | year = 1940 | title = A Formulation of the Simple Theory of Types | journal = Journal of Symbolic Logic | volume = 5 | issue = 2 | pages = 56–68 | doi=10.2307/2266170 |jstor=2266170}}&lt;/ref&gt;

Until the 1960s when its relation to programming languages was clarified, the λ-calculus was only a formalism. Thanks to [[Richard Montague]] and other linguists' applications in the semantics of natural language, the λ-calculus has begun to enjoy a respectable place in both linguistics&lt;ref name='mm-linguistics'&gt;{{cite book|last1=Partee|first1=B. B. H.|last2=ter Meulen|first2=A.|last3=Wall|first3=R. E.|title=Mathematical Methods in Linguistics |url=https://books.google.com/books?id=qV7TUuaYcUIC&amp;pg=PA317 |accessdate=29 Dec 2016|year=1990|publisher=Springer}}&lt;/ref&gt; and computer science.&lt;ref&gt;Alama, Jesse [http://plato.stanford.edu/entries/lambda-calculus/ "The Lambda Calculus"], ''The Stanford Encyclopedia of Philosophy'' (Summer 2013 Edition), Edward N. Zalta (ed.).&lt;/ref&gt;

==Informal description==
{{no footnotes|section|date=September 2013}}

===Motivation===
[[Computable function]]s are a fundamental concept within computer science and mathematics. The λ-calculus provides a simple [[Semantics#Computer science|semantics]] for computation, enabling properties of computation to be studied formally. The λ-calculus incorporates two simplifications that make this semantics simple.
The first simplification is that the λ-calculus treats functions "anonymously", without giving them explicit names. For example, the function 
:&lt;math&gt;\operatorname{square\_sum}(x, y) = x^2 + y^2&lt;/math&gt;
can be rewritten in ''anonymous form'' as 
:&lt;math&gt;(x, y) \mapsto x^2 + y^2&lt;/math&gt;
(read as "a tuple of {{mvar|x}} and {{mvar|y}} is [[Map (mathematics)|mapped]] to &lt;math display="inline"&gt;x^2 + y^2&lt;/math&gt;"). Similarly, 
:&lt;math&gt;\operatorname{id}(x) = x&lt;/math&gt;
can be rewritten in anonymous form as
:&lt;math&gt;x \mapsto x&lt;/math&gt;
where the input is simply mapped to itself.

The second simplification is that the λ-calculus only uses functions of a single input. An ordinary function that requires two inputs, for instance the &lt;math display="inline"&gt;\operatorname{square\_sum}&lt;/math&gt; function, can be reworked into an equivalent function that accepts a single input, and as output returns ''another'' function, that in turn accepts a single input. For example, 
:&lt;math&gt;(x, y) \mapsto x^2 + y^2&lt;/math&gt;
can be reworked into 
:&lt;math&gt;x \mapsto (y \mapsto x^2 + y^2)&lt;/math&gt;
This method, known as [[currying]], transforms a function that takes multiple arguments into a chain of functions each with a single argument.

[[Function application]] of the &lt;math display="inline"&gt;\operatorname{square\_sum}&lt;/math&gt; function to the arguments (5, 2), yields at once
:&lt;math display="inline"&gt;((x, y) \mapsto x^2 + y^2)(5, 2)&lt;/math&gt;
:&lt;math display="inline"&gt; = 5^2 + 2^2 &lt;/math&gt;
:&lt;math display="inline"&gt; = 29&lt;/math&gt;,
whereas evaluation of the curried version requires one more step
:&lt;math display="inline"&gt;\Bigl(\bigl(x \mapsto (y \mapsto x^2 + y^2)\bigr)(5)\Bigr)(2)&lt;/math&gt;
:&lt;math display="inline"&gt; = (y \mapsto 5^2 + y^2)(2)&lt;/math&gt; // the definition of &lt;math&gt;x&lt;/math&gt; has been used with &lt;math&gt;5&lt;/math&gt; in the inner expression.  This is like β-reduction.
:&lt;math display="inline"&gt; = 5^2 + 2^2&lt;/math&gt;  // the definition of &lt;math&gt;y&lt;/math&gt; has been used with &lt;math&gt;2&lt;/math&gt;. Again, similar to β-reduction.
:&lt;math display="inline"&gt; = 29&lt;/math&gt;
to arrive at the same result.

===The lambda calculus===
The lambda calculus consists of a language of '''lambda terms''', which is defined by a certain formal syntax, and a set of transformation rules, which allow manipulation of the lambda terms. These transformation rules can be viewed as an equational theory or as an [[operational definition]].

As described above, all functions in the lambda calculus are anonymous functions, having no names. They only accept one input variable, with currying used to implement functions with several variables.

====Lambda terms====

The syntax of the lambda calculus defines some expressions as valid lambda calculus expressions and some as invalid, just as some strings of characters are valid [[C (programming language)|C]] programs and some are not. A valid lambda calculus expression is called a "lambda term".

The following three rules give an [[inductive definition]] that can be applied to build all syntactically valid lambda terms:
* a variable, &lt;math&gt;x&lt;/math&gt;, is itself a valid lambda term
* if &lt;math&gt;t&lt;/math&gt; is a lambda term, and &lt;math&gt;x&lt;/math&gt; is a variable, then &lt;math&gt;(\lambda x.t)&lt;/math&gt; is a lambda term (called a '''lambda abstraction''');
* if &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt; are lambda terms, then &lt;math&gt;(ts)&lt;/math&gt; is a lambda term (called an '''application''').
Nothing else is a lambda term. Thus a lambda term is valid if and only if it can be obtained by repeated application of these three rules. However, some parentheses can be omitted according to certain rules. For example, the outermost parentheses are usually not written. See ''[[#Notation|Notation]]'', below.

A '''lambda abstraction''' &lt;math&gt;\lambda x.t&lt;/math&gt; is a definition of an anonymous function that is capable of taking a single input &lt;math&gt;x&lt;/math&gt; and substituting it into the expression &lt;math&gt;t&lt;/math&gt;. 
It thus defines an anonymous function that takes &lt;math&gt;x&lt;/math&gt; and returns &lt;math&gt;t&lt;/math&gt;. For example, &lt;math&gt;\lambda x.x^2+2&lt;/math&gt; is a lambda abstraction for the function &lt;math&gt;f(x) = x^2 + 2&lt;/math&gt; using the term &lt;math&gt;x^2+2&lt;/math&gt; for &lt;math&gt;t&lt;/math&gt;. The definition of a function with a lambda abstraction merely "sets up" the function but does not invoke it.  The abstraction [[Free variables and bound variables|binds]] the variable &lt;math&gt;x&lt;/math&gt; in the term &lt;math&gt;t&lt;/math&gt;.

An '''application''' &lt;math&gt;ts&lt;/math&gt; represents the application of a function &lt;math&gt;t&lt;/math&gt; to an input &lt;math&gt;s&lt;/math&gt;, that is, it represents the act of calling function &lt;math&gt;t&lt;/math&gt; on input &lt;math&gt;s&lt;/math&gt; to produce &lt;math&gt;t(s)&lt;/math&gt;.

There is no concept in lambda calculus of variable declaration. In a definition such as &lt;math&gt;\lambda x.x+y&lt;/math&gt; (i.e. &lt;math&gt;f(x) = x + y&lt;/math&gt;), the lambda calculus treats &lt;math&gt;y&lt;/math&gt; as a variable that is not yet defined. The lambda abstraction &lt;math&gt;\lambda x.x+y&lt;/math&gt; is syntactically valid, and represents a function that adds its input to the yet-unknown &lt;math&gt;y&lt;/math&gt;.

Bracketing may be used and may be needed to disambiguate terms. For example, &lt;math&gt;\lambda x.((\lambda x.x)x)&lt;/math&gt; and &lt;math&gt;(\lambda x.(\lambda x.x)) x&lt;/math&gt; denote different terms (although they coincidentally reduce to the same value). Here the first example defines a function that defines a function and returns the result of applying x to the child-function (apply function then return), while the second example defines a function that returns a function for any input and then returns it on application of x (return function then apply).

==== Functions that operate on functions ====

In lambda calculus, functions are taken to be '[[First-class object|first class values]]', so functions may be used as the inputs, or be returned as outputs from other functions.

For example, &lt;math&gt;\lambda x.x&lt;/math&gt; represents the identity function, &lt;math&gt;x \mapsto x&lt;/math&gt;, and &lt;math&gt;(\lambda x.x)y&lt;/math&gt; represents the identity function applied to &lt;math&gt;y&lt;/math&gt;. Further, &lt;math&gt;(\lambda x.y)&lt;/math&gt; represents the '''constant function''' &lt;math&gt;x \mapsto y&lt;/math&gt;, the function that always returns &lt;math&gt;y&lt;/math&gt;, no matter the input. In lambda calculus, function application is regarded as [[Operator associativity|left-associative]], so that &lt;math&gt;stx&lt;/math&gt; means &lt;math&gt;(st)x&lt;/math&gt;.

There are several notions of "equivalence" and "reduction" that allow lambda terms to be "reduced" to "equivalent" lambda terms.

====Alpha equivalence====
A basic form of equivalence, definable on lambda terms, is alpha equivalence. It captures the intuition that the particular choice of a bound variable, in a lambda abstraction, does not (usually) matter.
For instance, &lt;math&gt;\lambda x.x&lt;/math&gt; and &lt;math&gt;\lambda y.y&lt;/math&gt; are alpha-equivalent lambda terms, and they both represent the same function (the identity function). 
The terms &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are not alpha-equivalent, because they are not bound in a lambda abstraction.
In many presentations, it is usual to identify alpha-equivalent lambda terms.

The following definitions are necessary in order to be able to define beta reduction:

====Free variables====
The '''free variables''' of a term are those variables not bound by a lambda abstraction. The set of free variables of an expression is defined inductively:
* The free variables of &lt;math&gt;x&lt;/math&gt; are just &lt;math&gt;x&lt;/math&gt;
* The set of free variables of &lt;math&gt;\lambda x.t&lt;/math&gt; is the set of free variables of &lt;math&gt;t&lt;/math&gt;, but with &lt;math&gt;x&lt;/math&gt; removed
* The set of free variables of &lt;math&gt;ts&lt;/math&gt; is the union of the set of free variables of &lt;math&gt;t&lt;/math&gt; and the set of free variables of &lt;math&gt;s&lt;/math&gt;.

For example, the lambda term representing the identity &lt;math&gt;\lambda x.x&lt;/math&gt; has no free variables, but the function &lt;math&gt;\lambda x. yx&lt;/math&gt; has a single free variable, &lt;math&gt;y&lt;/math&gt;.

====Capture-avoiding substitutions====

Suppose &lt;math&gt;t&lt;/math&gt;, &lt;math&gt;s&lt;/math&gt; and &lt;math&gt;r&lt;/math&gt; are lambda terms and &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are variables.
The notation &lt;math&gt;t[x := r]&lt;/math&gt; indicates substitution of &lt;math&gt;r&lt;/math&gt; for &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;t&lt;/math&gt; in a ''capture-avoiding'' manner. This is defined so that:
* &lt;math&gt;x[x := r] = r&lt;/math&gt;;
* &lt;math&gt;y[x := r] = y&lt;/math&gt; if &lt;math&gt;x \neq y&lt;/math&gt;;
* &lt;math&gt;(ts)[x := r] = (t[x := r])(s[x := r])&lt;/math&gt;;
* &lt;math&gt;(\lambda x.t)[x := r] = \lambda x.t&lt;/math&gt;;
* &lt;math&gt;(\lambda y.t)[x := r] = \lambda y.(t[x := r])&lt;/math&gt; if &lt;math&gt;x \neq y&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; is not in the free variables of &lt;math&gt;r&lt;/math&gt;. The variable &lt;math&gt;y&lt;/math&gt; is said to be "fresh" for &lt;math&gt;r&lt;/math&gt;.

For example, &lt;math&gt;(\lambda x.x)[y := y] = \lambda x.(x[y := y]) = \lambda x.x&lt;/math&gt;, and &lt;math&gt;((\lambda x.y)x)[x := y] = ((\lambda x.y)[x := y])(x[x := y]) = (\lambda x.y)y&lt;/math&gt;.

The freshness condition (requiring that &lt;math&gt;y&lt;/math&gt; is not in the free variables of &lt;math&gt;r&lt;/math&gt;) is crucial in order to ensure that substitution does not change the meaning of functions.
For example, a substitution is made that ignores the freshness condition: &lt;math&gt;(\lambda x.y)[y := x] = \lambda x.(y[y := x]) = \lambda x.x&lt;/math&gt;. This substitution turns the constant function &lt;math&gt;\lambda x.y&lt;/math&gt; into the identity &lt;math&gt;\lambda x.x&lt;/math&gt; by substitution.

In general, failure to meet the freshness condition can be remedied by alpha-renaming with a suitable fresh variable.
For example, switching back to our correct notion of substitution, in &lt;math&gt;(\lambda x.y)[y := x]&lt;/math&gt; the lambda abstraction can be renamed with a fresh variable &lt;math&gt;z&lt;/math&gt;, to obtain &lt;math&gt;(\lambda z.y)[y := x] = \lambda z.(y[y := x]) = \lambda z.x&lt;/math&gt;, and the meaning of the function is preserved by substitution.

====Beta reduction====
The beta reduction rule states that an application of the form &lt;math&gt;( \lambda x . t) s&lt;/math&gt; reduces to the term &lt;math&gt; t [ x := s]&lt;/math&gt;. The notation &lt;math&gt;( \lambda x . t ) s \to t [ x := s ] &lt;/math&gt; is used to indicate that &lt;math&gt;( \lambda x .t ) s &lt;/math&gt; beta reduces to &lt;math&gt; t [ x := s ] &lt;/math&gt;.
For example, for every &lt;math&gt;s&lt;/math&gt;, &lt;math&gt;( \lambda x . x ) s \to x[ x := s ] = s &lt;/math&gt;. This demonstrates that &lt;math&gt; \lambda x . x &lt;/math&gt; really is the identity.
Similarly, &lt;math&gt;( \lambda x . y ) s \to y [ x := s ] = y &lt;/math&gt;, which demonstrates that &lt;math&gt; \lambda x . y &lt;/math&gt; is a constant function.

The lambda calculus may be seen as an idealised version of a functional programming language, like [[Haskell (programming language)|Haskell]] or [[Standard ML]].
Under this view, beta reduction corresponds to a computational step. This step can be repeated by additional beta conversions until there are no more applications left to reduce. In the untyped lambda calculus, as presented here, this reduction process may not terminate.
For instance, consider the term &lt;math&gt;\Omega = (\lambda x . xx)( \lambda x . xx )&lt;/math&gt;.
Here &lt;math&gt;( \lambda x . xx)( \lambda x . xx) \to ( xx )[ x := \lambda x . xx ] = ( x [ x := \lambda x . xx ] )( x [ x := \lambda x . xx ] ) = ( \lambda x . xx)( \lambda x . xx )&lt;/math&gt;.
That is, the term reduces to itself in a single beta reduction, and therefore the reduction process will never terminate.

Another aspect of the untyped lambda calculus is that it does not distinguish between different kinds of data.
For instance, it may be desirable to write a function that only operates on numbers. However, in the untyped lambda calculus, there is no way to prevent a function from being applied to [[truth value]]s, strings, or other non-number objects.

==Formal definition==
{{main|Lambda calculus definition}}

===Definition===
Lambda expressions are composed of:
* variables v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ..., v&lt;sub&gt;n&lt;/sub&gt;, ...
* the abstraction symbols lambda 'λ' and dot '.'
* parentheses ( )
The set of lambda expressions, Λ, can be [[Recursive definition|defined inductively]]:
#If x is a variable, then x ∈ Λ
#If x is a variable and M ∈ Λ, then (λx.M) ∈ Λ
#If M, N ∈ Λ, then (M N) ∈ Λ
Instances of rule 2 are known as abstractions and instances of rule 3 are known as applications.&lt;ref&gt;{{Citation
 |last=Barendregt 
 |first=Hendrik Pieter 
 |author-link=Henk Barendregt
 |last2= 
 |first2= 
 |author2-link= 
 |title=The Lambda Calculus: Its Syntax and Semantics 
 |place= 
 |publisher=North Holland, Amsterdam
 |year=1984 
 |volume=103 
 |series=Studies in Logic and the Foundations of Mathematics 
 |edition=Revised 
 |url=http://www.elsevier.com/wps/find/bookdescription.cws_home/501727/description 
 |doi= 
 |id= 
 |isbn=0-444-87508-5 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20040823174002/https://www.elsevier.com/wps/find/bookdescription.cws_home/501727/description 
 |archivedate=2004-08-23 
 |df= 
}}  [ftp://ftp.cs.ru.nl/pub/CompMath.Found/ErrataLCalculus.pdf Corrections].
&lt;/ref&gt;

===Notation===
To keep the notation of lambda expressions uncluttered, the following conventions are usually applied:
* Outermost parentheses are dropped: M N instead of (M N)
* Applications are assumed to be left associative: M N P may be written instead of ((M N) P)&lt;ref name="lambda-bound"&gt;{{cite web|url=http://www.lambda-bound.com/book/lambdacalc/node27.html |title=Example for Rules of Associativity |publisher=Lambda-bound.com |date= |accessdate=2012-06-18}}&lt;/ref&gt;
* The body of an abstraction extends [[Regular expression#Lazy matching|as far right as possible]]: λx.M N means λx.(M N) and not (λx.M) N
* A sequence of abstractions is contracted: λx.λy.λz.N is abbreviated as λxyz.N&lt;ref name="Selinger"&gt;
{{Citation
  | first = Peter
  | last = Selinger
  | author-link =
  | title = Lecture Notes on the Lambda Calculus
  | year =2008
  | page = 9
  | place =
  | publisher = Department of Mathematics and Statistics, University of Ottawa
  | url = http://www.mathstat.dal.ca/~selinger/papers/lambdanotes.pdf
  | bibcode = 2008arXiv0804.3434S
  | volume = 0804
  | arxiv = 0804.3434
  | issue=class: cs.LO }}&lt;/ref&gt;&lt;ref name="lambda-bound"/&gt;

===Free and bound variables===
The abstraction operator, λ, is said to bind its variable wherever it occurs in the body of the abstraction. Variables that fall within the scope of an abstraction are said to be ''bound''. All other variables are called ''free''. For example, in the expression &lt;tt&gt;λ''y''.''x'' ''x'' ''y''&lt;/tt&gt;, y is a bound variable and x is free. Also note that a variable is bound by its "nearest" abstraction. In the following example the single occurrence of x in the expression is bound by the second lambda: &lt;tt&gt;λ''x''.''y''  (λ''x''.''z'' ''x'')&lt;/tt&gt;

The set of ''free variables'' of a lambda expression, M, is denoted as FV(M) and is defined by recursion on the structure of the terms, as follows:
# FV(x) = {x}, where x is a variable
# FV(λx.M) = FV(M) \ {x}
# FV(M N) = FV(M) ∪ FV(N)&lt;ref name="BarendregtBarendsen"&gt;{{Citation
  | last = Barendregt
  | first = Henk
  | author-link = Henk Barendregt
  | last2 = Barendsen
  | first2 = Erik
  | author2-link =
  | title = Introduction to Lambda Calculus
  | place =
  | publisher =
  | year = March 2000
  | volume =
  | edition =
  | url = ftp://ftp.cs.ru.nl/pub/CompMath.Found/lambda.pdf
  | doi =
  | id =
  | isbn = }}&lt;/ref&gt;

An expression that contains no free variables is said to be ''closed''. Closed lambda expressions are also known as combinators and are equivalent to terms in [[combinatory logic]].

==Reduction==
The meaning of lambda expressions is defined by how expressions can be reduced.&lt;ref&gt;{{cite journal |authorlink=Ruy de Queiroz |last=de Queiroz |first=Ruy J. G. B. |doi=10.1111/j.1746-8361.1988.tb00919.x |title=A Proof-Theoretic Account of Programming and the Role of Reduction Rules |journal=Dialectica |volume=42 |issue=4 |pages=265–282 |year=1988}}&lt;/ref&gt;

There are three kinds of reduction:
* '''α-conversion''': changing bound variables ('''alpha''');
* '''β-reduction''': applying functions to their arguments ('''beta''');
* '''η-conversion''': which captures a notion of extensionality ('''eta''').
We also speak of the resulting equivalences: two expressions are ''β-equivalent'', if they can be β-converted into the same expression, and α/η-equivalence are defined similarly.

The term ''redex'', short for ''reducible expression'', refers to subterms that can be reduced by one of the reduction rules. For example, &lt;tt&gt;(λ''x''.M) N&lt;/tt&gt; is a beta-redex in expressing the substitution of N for x in M. The expression to which a redex reduces is called its reduct; the reduct of &lt;tt&gt;(λ''x''.M) N&lt;/tt&gt; is &lt;tt&gt;M[''x'':=N]&lt;/tt&gt;.

If &lt;tt&gt;''x''&lt;/tt&gt; is not free in &lt;tt&gt;M&lt;/tt&gt;, &lt;tt&gt;λ''x''.M ''x''&lt;/tt&gt; is also an eta-redex, with a reduct of &lt;tt&gt;M&lt;/tt&gt;.

===α-conversion===
Alpha-conversion, sometimes known as alpha-renaming,&lt;ref&gt;{{Citation |title=Design concepts in programming languages |last1=Turbak |first1=Franklyn |last2=Gifford |first2=David |year=2008 |publisher=MIT press |page=251| isbn=978-0-262-20175-9}}&lt;/ref&gt; allows bound variable names to be changed. For example, alpha-conversion of &lt;tt&gt;λ''x''.''x''&lt;/tt&gt; might yield &lt;tt&gt;λ''y''.''y''&lt;/tt&gt;. Terms that differ only by alpha-conversion are called ''α-equivalent''. Frequently, in uses of lambda calculus, α-equivalent terms are considered to be equivalent.

The precise rules for alpha-conversion are not completely trivial. First, when alpha-converting an abstraction, the only variable occurrences that are renamed are those that are bound to the same abstraction. For example, an alpha-conversion of &lt;tt&gt;λ''x''.λ''x''.''x''&lt;/tt&gt; could result in &lt;tt&gt;λ''y''.λ''x''.''x''&lt;/tt&gt;, but it could ''not'' result in &lt;tt&gt;λ''y''.λ''x''.''y''&lt;/tt&gt;. The latter has a different meaning from the original. This is analogous to the programming notion of [[variable shadowing]].

Second, alpha-conversion is not possible if it would result in a variable getting captured by a different abstraction. For example, if we replace &lt;tt&gt;''x''&lt;/tt&gt; with &lt;tt&gt;''y''&lt;/tt&gt; in &lt;tt&gt;λ''x''.λ''y''.''x''&lt;/tt&gt;, we get &lt;tt&gt;λ''y''.λ''y''.''y''&lt;/tt&gt;, which is not at all the same.

In programming languages with static scope, alpha-conversion can be used to make [[Name resolution (programming languages)|name resolution]] simpler by ensuring that no variable name [[Variable shadowing|masks]] a name in a containing [[scope (programming)|scope]] (see [[Name resolution (programming languages)#Alpha renaming to make name resolution trivial|alpha renaming to make name resolution trivial]]).

In the [[De Bruijn index]] notation, any two alpha-equivalent terms are syntactically identical.

====Substitution====
Substitution, written {{mono|1=''E''[''V'' := ''R'']}}, is the process of replacing all free occurrences of the variable {{mono|''V''}} in the expression {{mono|''E''}} with expression {{mono|''R''}}.
Substitution on terms of the λ-calculus is defined by recursion on the structure of terms, as follows (note: x and y are only variables while M and N are any λ expression).
 ''x''[''x'' := N]&amp;#09;&amp;equiv; N
 ''y''[''x'' := N]&amp;#09;&amp;equiv; ''y'', if ''x'' ≠ ''y''
 (M&lt;sub&gt;1&lt;/sub&gt; M&lt;sub&gt;2&lt;/sub&gt;)[''x'' := N]&amp;#09;&amp;equiv; (M&lt;sub&gt;1&lt;/sub&gt;[''x'' := N]) (M&lt;sub&gt;2&lt;/sub&gt;[''x'' := N])
 (λ''x''.M)[''x'' := N]&amp;#09;&amp;equiv; λ''x''.M
 (λ''y''.M)[''x'' := N]&amp;#09;&amp;equiv; λ''y''.(M[''x'' := N]), if ''x'' ≠ ''y'', ''provided'' ''y'' ∉ FV(N)

To substitute into a lambda abstraction, it is sometimes necessary to α-convert the expression. For example, it is not correct for {{mono|1=(λ''x''.''y'')[''y'' := ''x'']}} to result in {{mono|(λ''x''.''x'')}}, because the substituted {{mono|''x''}} was supposed to be free but ended up being bound. The correct substitution in this case is {{mono|(λ''z''.''x'')}}, up to α-equivalence. Notice that substitution is defined uniquely up to α-equivalence.

===&amp;beta;-reduction===
Beta-reduction captures the idea of function application. Beta-reduction is defined in terms of substitution: the beta-reduction of &lt;tt&gt;&amp;nbsp;((λ''V''.''E'') ''E&amp;prime;'')&amp;nbsp;&lt;/tt&gt; is &lt;tt&gt;''E''[''V'' := ''E&amp;prime;'']&lt;/tt&gt;.

For example, assuming some encoding of &lt;tt&gt;2, 7, &amp;times;&lt;/tt&gt;, we have the following β-reduction: &lt;tt&gt;((λ''n''.''n''&amp;times;2) 7) &lt;/tt&gt;→&lt;tt&gt; 7&amp;times;2&lt;/tt&gt;.

===&amp;eta;-conversion===
Eta-conversion expresses the idea of [[extensionality]], which in this context is that two functions are the same [[if and only if]] they give the same result for all arguments. Eta-conversion converts between &lt;tt&gt;λ''x''.(''f'' ''x'')&lt;/tt&gt; and &lt;tt&gt;''f''&lt;/tt&gt; whenever &lt;tt&gt;''x''&lt;/tt&gt; does not appear free in &lt;tt&gt;''f''&lt;/tt&gt;.

== Normal forms and confluence ==
{{Main|Normalization property (abstract rewriting)}}
For the untyped lambda calculus, β-reduction as a [[rewrite system|rewriting rule]] is neither [[strongly normalising]] nor [[weakly normalising]].

However, it can be shown that β-reduction is [[confluence (abstract rewriting)|confluent]]. (Of course, we are working up to α-conversion, i.e. we consider two normal forms to be equal, if it is possible to α-convert one into the other.)

Therefore, both strongly normalising terms and weakly normalising terms have a unique normal form. For strongly normalising terms, any reduction strategy is guaranteed to yield the normal form, whereas for weakly normalising terms, some reduction strategies may fail to find it.

==Encoding datatypes==
{{Main|Church encoding|Mogensen–Scott encoding}}

The basic lambda calculus may be used to model booleans, [[arithmetic]], data structures and recursion, as illustrated in the following sub-sections.

===Arithmetic in lambda calculus===
There are several possible ways to define the [[natural number]]s in lambda calculus, but by far the most common are the [[Church numeral]]s, which can be defined as follows:
: &lt;tt&gt;0 := λ''f''.λ''x''.''x''&lt;/tt&gt;
: &lt;tt&gt;1 := λ''f''.λ''x''.''f'' ''x''&lt;/tt&gt;
: &lt;tt&gt;2 := λ''f''.λ''x''.''f'' (''f'' ''x'')&lt;/tt&gt;
: &lt;tt&gt;3 := λ''f''.λ''x''.''f'' (''f'' (''f'' ''x''))&lt;/tt&gt;
and so on. Or using the alternative syntax presented above in ''[[#Notation|Notation]]'':

: &lt;tt&gt;0 := λ''fx''.''x''&lt;/tt&gt;
: &lt;tt&gt;1 := λ''fx''.''f'' ''x''&lt;/tt&gt;
: &lt;tt&gt;2 := λ''fx''.''f'' (''f'' ''x'')&lt;/tt&gt;
: &lt;tt&gt;3 := λ''fx''.''f'' (''f'' (''f'' ''x''))&lt;/tt&gt;

A Church numeral is a [[higher-order function]]—it takes a single-argument function &lt;tt&gt;''f''&lt;/tt&gt;, and returns another single-argument function. The Church numeral &lt;tt&gt;''n''&lt;/tt&gt; is a function that takes a function &lt;tt&gt;''f''&lt;/tt&gt; as argument and returns the &lt;tt&gt;''n''&lt;/tt&gt;-th composition of &lt;tt&gt;''f''&lt;/tt&gt;, i.e. the function &lt;tt&gt;''f''&lt;/tt&gt; composed with itself &lt;tt&gt;''n''&lt;/tt&gt; times. This is denoted &lt;tt&gt;''f''&lt;sup&gt;(''n'')&lt;/sup&gt;&lt;/tt&gt; and is in fact the &lt;tt&gt;''n''&lt;/tt&gt;-th power of &lt;tt&gt;''f''&lt;/tt&gt; (considered as an operator); &lt;tt&gt;''f''&lt;sup&gt;(0)&lt;/sup&gt;&lt;/tt&gt; is defined to be the identity function. Such repeated compositions (of a single function &lt;tt&gt;''f''&lt;/tt&gt;) obey the [[laws of exponents]], which is why these numerals can be used for arithmetic. (In Church's original lambda calculus, the formal parameter of a lambda expression was required to occur at least once in the function body, which made the above definition of &lt;tt&gt;0&lt;/tt&gt; impossible.)

One way of thinking about the Church numeral &lt;tt&gt;''n''&lt;/tt&gt;, which is often useful when analysing programs, is as an instruction 'repeat ''n'' times'. For example, using the &lt;tt&gt;PAIR&lt;/tt&gt; and &lt;tt&gt;NIL&lt;/tt&gt; functions defined below, one can define a function that constructs a (linked) list of ''n'' elements all equal to ''x'' by repeating 'prepend another ''x'' element' ''n'' times, starting from an empty list. The lambda term is
: &lt;tt&gt;λ''n''.λ''x''.''n'' (PAIR ''x'') NIL&lt;/tt&gt;
By varying what is being repeated, and varying what argument that function being repeated is applied to, a great many different effects can be achieved.

We can define a successor function, which takes a Church numeral &lt;tt&gt;''n''&lt;/tt&gt; and returns &lt;tt&gt;''n'' + 1&lt;/tt&gt; by adding another application of &lt;tt&gt;''f''&lt;/tt&gt;, where '(mf)x' means the function 'f' is applied 'm' times on 'x':
: &lt;tt&gt;SUCC := λ''n''.λ''f''.λ''x''.''f'' (''n'' ''f'' ''x'')&lt;/tt&gt;
Because the &lt;tt&gt;''m''&lt;/tt&gt;-th composition of &lt;tt&gt;''f''&lt;/tt&gt; composed with the &lt;tt&gt;''n''&lt;/tt&gt;-th composition of &lt;tt&gt;''f''&lt;/tt&gt; gives the &lt;tt&gt;''m''+''n''&lt;/tt&gt;-th composition of &lt;tt&gt;''f''&lt;/tt&gt;, addition can be defined as follows:
: &lt;tt&gt;PLUS := λ''m''.λ''n''.λ''f''.λ''x''.''m'' ''f'' (''n'' ''f'' ''x'')&lt;/tt&gt;
&lt;tt&gt;PLUS&lt;/tt&gt; can be thought of as a function taking two natural numbers as arguments and returning a natural number; it can be verified that
: &lt;tt&gt;PLUS 2 3&lt;/tt&gt;
and
: &lt;tt&gt;5&lt;/tt&gt;
are β-equivalent lambda expressions. Since adding &lt;tt&gt;''m''&lt;/tt&gt; to a number &lt;tt&gt;''n''&lt;/tt&gt; can be accomplished by adding 1 &lt;tt&gt;''m''&lt;/tt&gt; times, an alternative definition is:
: &lt;tt&gt;PLUS := λ''m''.λ''n''.''m'' SUCC ''n&amp;thinsp;''&lt;/tt&gt;&lt;ref&gt;{{Citation
  | last1 = Felleisen
  | first1 = Matthias
  | last2 = Flatt
  | first2 = Matthew
  | authorlink =
  | title = Programming Languages and Lambda Calculi
  | publisher =
  | year = 2006
  | location =
  | page = 26
  | url = http://www.cs.utah.edu/plt/publications/pllc.pdf
  | archive-url = https://web.archive.org/web/20090205113235/http://www.cs.utah.edu/plt/publications/pllc.pdf
  | archive-date = 2009-02-05
  | doi =
  | id =
  | isbn = }}; a note (accessed 2017) at the original location suggests that the authors consider the work originally referenced to have been superseded by a book.&lt;/ref&gt;
Similarly, multiplication can be defined as
: &lt;tt&gt;MULT := λ''m''.λ''n''.λ''f''.''m'' (''n'' ''f'')&lt;/tt&gt;&lt;ref name="Selinger" /&gt;
Alternatively
: &lt;tt&gt;MULT := λ''m''.λ''n''.''m'' (PLUS ''n'') 0&lt;/tt&gt;
since multiplying &lt;tt&gt;''m''&lt;/tt&gt; and &lt;tt&gt;''n''&lt;/tt&gt; is the same as repeating the add &lt;tt&gt;''n''&lt;/tt&gt; function &lt;tt&gt;''m''&lt;/tt&gt; times and then applying it to zero.
Exponentiation has a rather simple rendering in Church numerals, namely
: &lt;tt&gt;POW := λ''b''.λ''e''.''e'' ''b''&lt;/tt&gt;{{citation needed|date=September 2017}}
The predecessor function defined by &lt;tt&gt;PRED ''n'' = ''n'' − 1&lt;/tt&gt; for a positive integer &lt;tt&gt;''n''&lt;/tt&gt; and &lt;tt&gt;PRED 0 = 0&lt;/tt&gt; is considerably more difficult. The formula
: &lt;tt&gt;PRED := λ''n''.λ''f''.λ''x''.''n'' (λ''g''.λ''h''.''h'' (''g'' ''f'')) (λ''u''.''x'') (λ''u''.''u'')&lt;/tt&gt;
can be validated by showing inductively that if ''T'' denotes &lt;tt&gt;(λ''g''.λ''h''.''h'' (''g'' ''f''))&lt;/tt&gt;, then &lt;tt&gt;T&lt;sup&gt;(''n'')&lt;/sup&gt;(λ''u''.''x'') = (λ''h''.''h''(''f''&lt;sup&gt;(''n''−1)&lt;/sup&gt;(''x'')))&lt;/tt&gt; for &lt;tt&gt;''n'' &gt; 0&lt;/tt&gt;. Two other definitions of &lt;tt&gt;PRED&lt;/tt&gt; are given below, one using [[#Logic and predicates|conditionals]] and the other using [[#Pairs|pairs]]. With the predecessor function, subtraction is straightforward. Defining
: &lt;tt&gt;SUB := λ''m''.λ''n''.''n'' PRED ''m''&lt;/tt&gt;,
&lt;tt&gt;SUB ''m'' ''n''&lt;/tt&gt; yields &lt;tt&gt;''m'' − ''n''&lt;/tt&gt; when &lt;tt&gt;''m'' &gt; ''n''&lt;/tt&gt; and &lt;tt&gt;0&lt;/tt&gt; otherwise.

===Logic and predicates===
By convention, the following two definitions (known as Church booleans) are used for the boolean values &lt;tt&gt;TRUE&lt;/tt&gt; and &lt;tt&gt;FALSE&lt;/tt&gt;:
: &lt;tt&gt;TRUE := λ''x''.λ''y''.''x''&lt;/tt&gt;
: &lt;tt&gt;FALSE := λ''x''.λ''y''.''y''&lt;/tt&gt;
::(Note that &lt;tt&gt;FALSE&lt;/tt&gt; is equivalent to the Church numeral zero defined above)
Then, with these two λ-terms, we can define some logic operators (these are just possible formulations; other expressions are equally correct):
: &lt;tt&gt;AND := λ''p''.λ''q''.''p'' ''q'' ''p''&lt;/tt&gt;
: &lt;tt&gt;OR := λ''p''.λ''q''.''p'' ''p'' ''q''&lt;/tt&gt;
: &lt;tt&gt;NOT := λ''p''.p FALSE TRUE&lt;/tt&gt;
: &lt;tt&gt;IFTHENELSE := λ''p''.λ''a''.λ''b''.''p'' ''a'' ''b''&lt;/tt&gt;
We are now able to compute some logic functions, for example:

: &lt;tt&gt;AND TRUE FALSE&lt;/tt&gt;
::&lt;tt&gt;≡ (λ''p''.λ''q''.''p'' ''q'' ''p'') TRUE FALSE →&lt;sub&gt;β&lt;/sub&gt; TRUE FALSE TRUE&lt;/tt&gt;
::&lt;tt&gt;≡ (λ''x''.λ''y''.''x'') FALSE TRUE →&lt;sub&gt;β&lt;/sub&gt;  FALSE&lt;/tt&gt;
and we see that &lt;tt&gt;AND TRUE FALSE&lt;/tt&gt; is equivalent to &lt;tt&gt;FALSE&lt;/tt&gt;.

A ''predicate'' is a function that returns a boolean value. The most fundamental predicate is &lt;tt&gt;ISZERO&lt;/tt&gt;, which returns &lt;tt&gt;TRUE&lt;/tt&gt; if its argument is the Church numeral &lt;tt&gt;0&lt;/tt&gt;, and &lt;tt&gt;FALSE&lt;/tt&gt; if its argument is any other Church numeral:
: &lt;tt&gt;ISZERO := λ''n''.''n'' (λ''x''.FALSE) TRUE&lt;/tt&gt;
The following predicate tests whether the first argument is less-than-or-equal-to the second:
: &lt;tt&gt;LEQ := λ''m''.λ''n''.ISZERO (SUB ''m'' ''n'')&lt;/tt&gt;,
and since &lt;tt&gt;''m'' = ''n''&lt;/tt&gt;, if &lt;tt&gt;LEQ ''m'' ''n''&lt;/tt&gt; and &lt;tt&gt;LEQ ''n'' ''m''&lt;/tt&gt;, it is straightforward to build a predicate for numerical equality.

The availability of predicates and the above definition of &lt;tt&gt;TRUE&lt;/tt&gt; and &lt;tt&gt;FALSE&lt;/tt&gt; make it convenient to write "if-then-else" expressions in lambda calculus. For example, the predecessor function can be defined as:
: &lt;tt&gt;PRED := λ''n''.''n'' (λ''g''.λ''k''.ISZERO (''g'' 1) ''k'' (PLUS (''g'' ''k'') 1)) (λ''v''.0) 0 &lt;/tt&gt;
which can be verified by showing inductively that &lt;tt&gt;''n'' (λ''g''.λ''k''.ISZERO (''g'' 1) ''k'' (PLUS (''g'' ''k'') 1)) (λ''v''.0)&lt;/tt&gt; is the add &lt;tt&gt;''n''&lt;/tt&gt; − 1 function for &lt;tt&gt;''n''&lt;/tt&gt; &gt; 0.

===Pairs===
A pair (2-tuple) can be defined in terms of &lt;tt&gt;TRUE&lt;/tt&gt; and &lt;tt&gt;FALSE&lt;/tt&gt;, by using the [[Church encoding#Church pairs|Church encoding for pairs]]. For example, &lt;tt&gt;PAIR&lt;/tt&gt; encapsulates the pair (&lt;tt&gt;''x''&lt;/tt&gt;,&lt;tt&gt;''y''&lt;/tt&gt;), &lt;tt&gt;FIRST&lt;/tt&gt; returns the first element of the pair, and &lt;tt&gt;SECOND&lt;/tt&gt; returns the second.

: &lt;tt&gt;PAIR := λ''x''.λ''y''.λ''f''.''f'' ''x'' ''y''&lt;/tt&gt;
: &lt;tt&gt;FIRST := λ''p''.''p'' TRUE&lt;/tt&gt;
: &lt;tt&gt;SECOND := λ''p''.''p'' FALSE&lt;/tt&gt;
: &lt;tt&gt;NIL := λ''x''.TRUE &lt;/tt&gt;
: &lt;tt&gt;NULL := λ''p''.''p'' (λ''x''.λ''y''.FALSE)&lt;/tt&gt;

A linked list can be defined as either NIL for the empty list, or the &lt;tt&gt;PAIR&lt;/tt&gt; of an element and a smaller list. The predicate &lt;tt&gt;NULL&lt;/tt&gt; tests for the value &lt;tt&gt;NIL&lt;/tt&gt;. (Alternatively, with &lt;tt&gt;NIL := FALSE&lt;/tt&gt;, the construct &lt;tt&gt;''l'' (λ''h''.λ''t''.λ''z''.deal_with_head_''h''_and_tail_''t'') (deal_with_nil)&lt;/tt&gt; obviates the need for an explicit NULL test).

As an example of the use of pairs, the shift-and-increment function that maps &lt;tt&gt;(''m'', ''n'')&lt;/tt&gt; to &lt;tt&gt;(''n'', ''n'' + 1)&lt;/tt&gt; can be defined as
: &lt;tt&gt;Φ := λ''x''.PAIR (SECOND ''x'') (SUCC (SECOND ''x''))&lt;/tt&gt;
which allows us to give perhaps the most transparent version of the predecessor function:
: &lt;tt&gt;PRED := λ''n''.FIRST (''n'' Φ (PAIR 0 0)).&lt;/tt&gt;

==Additional programming techniques==
There is a considerable body of [[programming idiom]]s for lambda calculus. Many of these were originally developed in the context of using lambda calculus as a foundation for programming language semantics, effectively using lambda calculus as a [[low-level programming language]]. Because several programming languages include the lambda calculus (or something very similar) as a fragment, these techniques also see use in practical programming, but may then be perceived as obscure or foreign.

===Named constants===
In lambda calculus, a [[library (computing)|library]] would take the form of a collection of previously defined functions, which as lambda-terms are merely particular constants. The pure lambda calculus does not have a concept of named constants since all atomic lambda-terms are variables, but one can emulate having named constants by setting aside a variable as the name of the constant, using lambda-abstraction to bind that variable in the main body, and apply that lambda-abstraction to the intended definition. Thus to use &lt;tt&gt;''f''&lt;/tt&gt; to mean ''M'' (some explicit lambda-term) in ''N'' (another lambda-term, the "main program"), one can say
: &lt;tt&gt;(λ''f''.&lt;/tt&gt;''N''&lt;tt&gt;)&lt;/tt&gt; ''M''
Authors often introduce [[syntactic sugar]], such as &lt;tt&gt;let&lt;/tt&gt;, to permit writing the above in the more intuitive order
: &lt;tt&gt;let ''f'' = &lt;/tt&gt;''M''&lt;tt&gt; in &lt;/tt&gt;''N''
By chaining such definitions, one can write a lambda calculus "program" as zero or more function definitions, followed by one lambda-term using those functions that constitutes the main body of the program.

A notable restriction of this &lt;tt&gt;let&lt;/tt&gt; is that the name &lt;tt&gt;''f''&lt;/tt&gt; is not defined in ''M'', since ''M'' is outside the scope of the lambda-abstraction binding &lt;tt&gt;''f''&lt;/tt&gt;; this means a recursive function definition cannot be used as the ''M'' with &lt;tt&gt;let&lt;/tt&gt;. The more advanced &lt;tt&gt;letrec&lt;/tt&gt; syntactic sugar construction that allows writing recursive function definitions in that naive style instead additionally employs fixed-point combinators.

===Recursion and fixed points===
{{Main|Fixed-point combinator}}
{{see also|SKI combinator calculus#Self-application and recursion}}
[[Recursion]] is the definition of a function using the function itself. Lambda calculus cannot express this as directly as some other notations: all functions are anonymous in lambda calculus, so we can't refer to a value which is yet to be defined, inside the lambda term defining that same value. However, recursion can still be achieved by arranging for a lambda expression to receive itself as its argument value, for example in&amp;ensp; &lt;tt&gt;(λ''x''.''x'' ''x'') ''E''&lt;/tt&gt;.

Consider the [[factorial]] function &lt;tt&gt;F(''n'')&lt;/tt&gt; recursively defined by

:&lt;tt&gt;F(''n'') = 1, if ''n'' = 0; else ''n'' &amp;times; F(''n'' − 1)&lt;/tt&gt;.

In the lambda expression which is to represent this function, a ''parameter'' (typically the first one) will be assumed to receive the lambda expression itself as its value, so that calling it &amp;ndash; applying it to an argument &amp;ndash; will amount to recursion. Thus to achieve recursion, the intended-as-self-referencing argument (called &lt;tt&gt;''r''&lt;/tt&gt; here) must always be passed to itself within the function body, at a call point:

:&lt;tt&gt;G := λ''r''. λ''n''.(1, if ''n'' = 0; else ''n'' &amp;times; (''r'' ''r'' (''n''−1)))&lt;/tt&gt;
::: with&amp;ensp; &lt;tt&gt; ''r'' ''r'' ''x'' = F ''x'' = G ''r'' ''x''&lt;/tt&gt; &amp;ensp;to hold, so&amp;ensp; &lt;tt&gt;''r'' = G&lt;/tt&gt; &amp;ensp;and
:&lt;tt&gt;F := G G = (λ''x''.''x'' ''x'') G&lt;/tt&gt;

The self-application achieves replication here, passing the function's lambda expression on to the next invocation as an argument value, making it available to be referenced and called there.

This solves it but requires re-writing each recursive call as self-application. We would like to have a generic solution, without a need for any re-writes:

:&lt;tt&gt;G := λ''r''. λ''n''.(1, if ''n'' = 0; else ''n'' &amp;times; (''r'' (''n''−1)))&lt;/tt&gt;
::: with&amp;ensp; &lt;tt&gt; ''r'' ''x'' = F ''x'' = G ''r'' ''x''&lt;/tt&gt; &amp;ensp;to hold, so&amp;ensp; &lt;tt&gt;''r'' = G ''r'' =: FIX G&lt;/tt&gt; &amp;ensp;and
:&lt;tt&gt;F := FIX G&lt;/tt&gt; &amp;ensp;where&amp;ensp; &lt;tt&gt;FIX ''g'' := (''r'' where ''r'' = ''g'' ''r'') = ''g'' (FIX ''g'')&lt;/tt&gt;
::: so that&amp;ensp; &lt;tt&gt; FIX G = G (FIX G) = (λ''n''.(1, if ''n'' = 0; else ''n'' &amp;times; ((FIX G) (''n''−1)))) &lt;/tt&gt;

Given a lambda term with first argument representing recursive call (e.g. &lt;tt&gt;G&lt;/tt&gt; here), the ''fixed-point'' combinator &lt;tt&gt;FIX&lt;/tt&gt; will return a self-replicating lambda expression representing the recursive function (here, &lt;tt&gt;F&lt;/tt&gt;). The function does not need to be explicitly passed to itself at any point, for the self-replication is arranged in advance, when it is created, to be done each time it is called. Thus the original lambda expression &lt;tt&gt;(FIX G)&lt;/tt&gt; is re-created inside itself, at call-point, achieving [[self-reference]].

In fact, there are many possible definitions for this &lt;tt&gt;FIX&lt;/tt&gt; operator, the simplest of them being:

:&lt;tt&gt;'''Y''' := λ''g''.(λ''x''.''g'' (''x'' ''x'')) (λ''x''.''g'' (''x'' ''x''))&lt;/tt&gt;

In the lambda calculus, &lt;tt&gt;'''Y''' ''g''&lt;/tt&gt;&amp;thinsp; is a fixed-point of &lt;tt&gt;''g''&lt;/tt&gt;, as it expands to:

:&lt;tt&gt;'''Y''' ''g''&lt;/tt&gt;
:&lt;tt&gt;(λ''h''.(λ''x''.''h'' (''x'' ''x'')) (λ''x''.''h'' (''x'' ''x''))) ''g''&lt;/tt&gt;
:&lt;tt&gt;(λ''x''.''g'' (''x'' ''x'')) (λ''x''.''g'' (''x'' ''x''))&lt;/tt&gt;
:&lt;tt&gt;''g'' ((λ''x''.''g'' (''x'' ''x'')) (λ''x''.''g'' (''x'' ''x'')))&lt;/tt&gt;
:&lt;tt&gt;''g'' ('''Y''' ''g'')&lt;/tt&gt;

Now, to perform our recursive call to the factorial function, we would simply call &lt;tt&gt;('''Y''' G) ''n''&lt;/tt&gt;,&amp;nbsp; where ''n'' is the number we are calculating the factorial of. Given ''n'' = 4, for example, this gives:

:&lt;tt&gt;('''Y''' G) 4 &lt;/tt&gt;
:&lt;tt&gt;G ('''Y''' G) 4 &lt;/tt&gt;
:&lt;tt&gt;(λ''r''.λ''n''.(1, if ''n'' = 0; else ''n'' × (''r'' (''n''−1)))) ('''Y''' G) 4&lt;/tt&gt;
:&lt;tt&gt;(λ''n''.(1, if ''n'' = 0; else ''n'' × (('''Y''' G) (''n''−1)))) 4&lt;/tt&gt;
:&lt;tt&gt;1, if 4 = 0; else 4 × (('''Y''' G) (4−1))&lt;/tt&gt;
:&lt;tt&gt;4 × (G ('''Y''' G) (4−1))&lt;/tt&gt;
:&lt;tt&gt;4 × ((λ''n''.(1, if ''n'' = 0; else ''n'' × (('''Y''' G) (''n''−1)))) (4−1))&lt;/tt&gt;
:&lt;tt&gt;4 × (1, if 3 = 0; else 3 × (('''Y''' G) (3−1)))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (G ('''Y''' G) (3−1)))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × ((λ''n''.(1, if ''n'' = 0; else ''n'' × (('''Y''' G) (''n''−1)))) (3−1)))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (1, if 2 = 0; else 2 × (('''Y''' G) (2−1))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (G ('''Y''' G) (2−1))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × ((λ''n''.(1, if ''n'' = 0; else ''n'' × (('''Y''' G) (''n''−1)))) (2−1))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (1, if 1 = 0; else 1 × (('''Y''' G) (1−1)))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (1 × (G ('''Y''' G) (1−1)))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (1 × ((λ''n''.(1, if ''n'' = 0; else ''n'' × (('''Y''' G) (''n''−1)))) (1−1)))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (1 × (1, if 0 = 0; else 0 × (('''Y''' G) (0−1))))))&lt;/tt&gt;
:&lt;tt&gt;4 × (3 × (2 × (1 × (1))))&lt;/tt&gt;
:&lt;tt&gt;24&lt;/tt&gt;

Every recursively defined function can be seen as a fixed point of some suitably defined function closing over the recursive call with an extra argument, and therefore, using &lt;tt&gt;'''Y'''&lt;/tt&gt;, every recursively defined function can be expressed as a lambda expression. In particular, we can now cleanly define the subtraction, multiplication and comparison predicate of natural numbers recursively.

===Standard terms===
Certain terms have commonly accepted names:
: {{anchor|I}} &lt;tt&gt;'''I''' := λ''x''.''x''&lt;/tt&gt;
: {{anchor|K}} &lt;tt&gt;'''K''' := λ''x''.λ''y''.''x''&lt;/tt&gt;
: {{anchor|S}} &lt;tt&gt;'''S''' := λ''x''.λ''y''.λ''z''.''x'' ''z'' (''y'' ''z'') &lt;/tt&gt;
: {{anchor|B}} &lt;tt&gt;'''B''' := λ''x''.λ''y''.λ''z''.''x'' (''y'' ''z'') &lt;/tt&gt;
: {{anchor|C}} &lt;tt&gt;'''C''' := λ''x''.λ''y''.λ''z''.''x'' ''z'' ''y''&lt;/tt&gt;
: {{anchor|W}} &lt;tt&gt;'''W''' := λ''x''.λ''y''.''x'' ''y'' ''y''&lt;/tt&gt;
: {{anchor|U}} &lt;tt&gt;'''U''' := λ''x''.λ''y''.''y'' (''x'' ''x'' ''y'')  &lt;/tt&gt;
: {{anchor|omega}} &lt;tt&gt;'''ω''' := λ''x''.''x'' ''x'' &lt;/tt&gt;
: {{anchor|Omega}} &lt;tt&gt;'''Ω''' := '''ω''' '''ω''' &lt;/tt&gt;
: {{anchor|Y}} &lt;tt&gt;'''Y''' := λ''g''.(λ''x''.''g'' (''x'' ''x'')) (λ''x''.''g'' (''x'' ''x''))&lt;/tt&gt;
Several of these have direct applications in the ''elimination of lambda-abstraction'' that turns lambda terms into [[combinator calculus]] terms.

===Abstraction elimination===
{{main|Combinatory_logic#Completeness_of_the_S-K_basis}}
If ''N'' is a lambda-term without lambda-abstraction, but possibly containing named constants ([[combinatory logic|combinators]]), then there exists a lambda-term ''T''(&lt;tt&gt;''x''&lt;/tt&gt;,''N'') which is equivalent to &lt;tt&gt;λ''x''.&lt;/tt&gt;''N'' but lacks lambda-abstraction (except as part of the named constants, if these are considered non-atomic). This can also be viewed as anonymising variables, as ''T''(&lt;tt&gt;''x''&lt;/tt&gt;,''N'') removes all occurrences of &lt;tt&gt;''x''&lt;/tt&gt; from ''N'', while still allowing argument values to be substituted into the positions where ''N'' contains an &lt;tt&gt;''x''&lt;/tt&gt;. The conversion function ''T'' can be defined by:
: ''T''(&lt;tt&gt;''x''&lt;/tt&gt;, &lt;tt&gt;''x''&lt;/tt&gt;) := '''I'''
: ''T''(&lt;tt&gt;''x''&lt;/tt&gt;, ''N'') := '''K''' ''N'' if &lt;tt&gt;''x''&lt;/tt&gt; is not free in ''N''.
: ''T''(&lt;tt&gt;''x''&lt;/tt&gt;, ''M'' ''N'') := '''S''' ''T''(&lt;tt&gt;''x''&lt;/tt&gt;, ''M'') ''T''(&lt;tt&gt;''x''&lt;/tt&gt;, ''N'')
In either case, a term of the form ''T''(&lt;tt&gt;''x''&lt;/tt&gt;,''N'') ''P'' can reduce by having the initial combinator '''I''', '''K''', or '''S''' grab the argument ''P'', just like β-reduction of &lt;tt&gt;(λ''x''.&lt;/tt&gt;''N''&lt;tt&gt;)&lt;/tt&gt; ''P'' would do. '''I''' returns that argument. '''K''' throws the argument away, just like &lt;tt&gt;(λ''x''.&lt;/tt&gt;''N''&lt;tt&gt;)&lt;/tt&gt; would do if &lt;tt&gt;''x''&lt;/tt&gt; has no free occurrence in ''N''. '''S''' passes the argument on to both subterms of the application, and then applies the result of the first to the result of the second.

The combinators '''B''' and '''C''' are similar to '''S''', but pass the argument on to only one subterm of an application ('''B''' to the "argument" subterm and '''C''' to the "function" subterm), thus saving a subsequent '''K''' if there is no occurrence of &lt;tt&gt;''x''&lt;/tt&gt; in one subterm. In comparison to '''B''' and '''C''', the '''S''' combinator actually conflates two functionalities: rearranging arguments, and duplicating an argument so that it may be used in two places. The '''W''' combinator does only the latter, yielding the [[B, C, K, W system]] as an alternative to [[SKI combinator calculus]].

== Typed lambda calculus ==
{{main|Typed lambda calculus}}
{{Summarize|from|typed lambda calculus|date=August 2009}}&lt;!-- this was requested by multiple editor on talk --&gt;
A '''typed lambda calculus''' is a typed [[formalism (mathematics)|formalism]] that uses the lambda-symbol (&lt;math&gt;\lambda&lt;/math&gt;) to denote anonymous function abstraction. In this context, types are usually objects of a syntactic nature that are assigned to lambda terms; the exact nature of a type depends on the calculus considered (see kinds below). From a certain point of view, typed lambda calculi can be seen as refinements of the [[untyped lambda calculus]] but from another point of view, they can also be considered the more fundamental theory and  ''untyped lambda calculus'' a special case with only one type.&lt;ref&gt;Types and Programming Languages, p. 273, Benjamin C. Pierce&lt;/ref&gt;

Typed lambda calculi are foundational [[programming languages]] and are the base of typed [[functional programming languages]] such as [[ML programming language|ML]] and [[Haskell (programming language)|Haskell]] and, more indirectly, typed [[imperative programming|imperative programming languages]]. Typed lambda calculi play an important role in the design of [[type systems]] for programming languages; here typability usually captures desirable properties of the program, e.g. the program will not cause a memory access violation.

Typed lambda calculi are closely related to [[mathematical logic]] and [[proof theory]] via the [[Curry–Howard isomorphism]] and they can be considered as the [[internal language]] of classes of [[category theory|categories]], e.g. the simply typed lambda calculus is the language of [[cartesian closed category|Cartesian closed categories]] (CCCs).

==Computable functions and lambda calculus==
A function ''F'': '''N''' → '''N''' of natural numbers is a computable function if and only if there exists a lambda expression ''f'' such that for every pair of ''x'', ''y'' in '''N''', ''F''(''x'')=''y'' if and only if ''f'' &lt;tt&gt;''x''&lt;/tt&gt;&amp;nbsp;=&lt;sub&gt;β&lt;/sub&gt;&amp;nbsp;&lt;tt&gt;''y''&lt;/tt&gt;,&amp;nbsp; where &lt;tt&gt;''x''&lt;/tt&gt; and &lt;tt&gt;''y''&lt;/tt&gt; are the Church numerals corresponding to ''x'' and ''y'', respectively and =&lt;sub&gt;β&lt;/sub&gt; meaning equivalence with beta reduction. This is one of the many ways to define computability; see the [[Church–Turing thesis]] for a discussion of other approaches and their equivalence.

==Undecidability of equivalence==
There is no algorithm that takes as input two lambda expressions and outputs &lt;tt&gt;TRUE&lt;/tt&gt; or &lt;tt&gt;FALSE&lt;/tt&gt; depending on whether or not the two expressions are equivalent. This was historically the first problem for which undecidability could be proven. As is common for a proof of undecidability, the proof shows that no computable function can decide the equivalence. [[Church's thesis]] is then invoked to show that no algorithm can do so.

Church's proof first reduces the problem to determining whether a given lambda expression has a ''normal form''. A normal form is an equivalent expression that cannot be reduced any further under the rules imposed by the form. Then he assumes that this predicate is computable, and can hence be expressed in lambda calculus. Building on earlier work by Kleene and constructing a [[Gödel numbering]] for lambda expressions, he constructs a lambda expression &lt;tt&gt;''e''&lt;/tt&gt; that closely follows the proof of [[Gödel's incompleteness theorems|Gödel's first incompleteness theorem]]. If &lt;tt&gt;''e''&lt;/tt&gt; is applied to its own Gödel number, a contradiction results.

==Lambda calculus and programming languages==
As pointed out by [[Peter Landin]]'s 1965 paper "A Correspondence between ALGOL 60 and Church's Lambda-notation"&lt;ref&gt;{{cite journal |url=http://portal.acm.org/citation.cfm?id=363749&amp;coll=portal&amp;dl=ACM |title=A Correspondence between ALGOL 60 and Church's Lambda-notation |first=P. J. |last=Landin |authorlink=Peter Landin |journal=Communications of the ACM |volume=8 |issue=2 |year=1965 |pages=89–101 |doi=10.1145/363744.363749}}&lt;/ref&gt;, sequential [[procedural programming|procedural programming languages]] can be understood in terms of the lambda calculus, which provides the basic mechanisms for procedural abstraction and procedure (subprogram) application.

===Anonymous functions===
{{main|Anonymous function}}
For example, in [[Lisp (programming language)|Lisp]] the "square" function can be expressed as a lambda expression as follows:
&lt;!-- Please do not add the same example in different languages to this article, see Anonymous function for that. Thank you! --&gt;
&lt;source lang="Lisp"&gt;
(lambda (x) (* x x))
&lt;/source&gt;

The above example is an expression that evaluates to a first-class function. The symbol &lt;code&gt;lambda&lt;/code&gt; creates an anonymous function, given a list of parameter names, &lt;code&gt;(x)&lt;/code&gt; – just a single argument in this case, and an expression that is evaluated as the body of the function, &lt;code&gt;(* x x)&lt;/code&gt;. Anonymous functions are sometimes called lambda expressions.

For example, [[Pascal (programming language)|Pascal]] and many other imperative languages have long supported passing [[subprograms]] as [[arguments]] to other subprograms through the mechanism of [[function pointers]]. However, function pointers are not a sufficient condition for functions to be [[First-class function|first class]] datatypes, because a function is a first class datatype if and only if new instances of the function can be created at run-time. And this run-time creation of functions is supported in [[Smalltalk]], [[JavaScript]], and more recently in [[Scala (programming language)|Scala]], [[Eiffel (programming language)|Eiffel]] ("agents"), [[C Sharp (programming language)|C#]] ("delegates") and [[C++11]], among others.

===Reduction strategies===
{{details|Evaluation strategy}}
Whether a term is normalising or not, and how much work needs to be done in normalising it if it is, depends to a large extent on the reduction strategy used. The distinction between reduction strategies relates to the distinction in functional programming languages between [[eager evaluation]] and [[lazy evaluation]].

;Full beta reductions: Any redex can be reduced at any time. This means essentially the lack of any particular reduction strategy—with regard to reducibility, "all bets are off".
;Applicative order: The rightmost, innermost redex is always reduced first. Intuitively this means a function's arguments are always reduced before the function itself. Applicative order always attempts to apply functions to normal forms, even when this is not possible.
:Most programming languages (including Lisp, ML and imperative languages like C and [[Java programming language|Java]]) are described as "strict", meaning that functions applied to non-normalising arguments are non-normalising. This is done essentially using applicative order, call by value reduction ([[#Call by value|see below]]), but usually called "eager evaluation".
;Normal order: The leftmost, outermost redex is always reduced first. That is, whenever possible the arguments are substituted into the body of an abstraction before the arguments are reduced.
;Call by name: As normal order, but no reductions are performed inside abstractions. For example, &lt;tt&gt;λ''x''.(λ''x''.''x'')''x''&lt;/tt&gt; is in normal form according to this strategy, although it contains the redex &lt;tt&gt;(λ''x''.''x'')''x''&lt;/tt&gt;.
;Call by value: Only the outermost redexes are reduced: a redex is reduced only when its right hand side has reduced to a value (variable or lambda abstraction).
;Call by need: As normal order, but function applications that would duplicate terms instead name the argument, which is then reduced only "when it is needed". Called in practical contexts "lazy evaluation". In implementations this "name" takes the form of a pointer, with the redex represented by a [[thunk (functional programming)|thunk]].

Applicative order is not a normalising strategy. The usual counterexample is as follows: define &lt;tt&gt;'''Ω''' = ωω&lt;/tt&gt; where &lt;tt&gt;'''ω''' = λ''x''.''xx''&lt;/tt&gt;. This entire expression contains only one redex, namely the whole expression; its reduct is again &lt;tt&gt;'''Ω'''&lt;/tt&gt;. Since this is the only available reduction, &lt;tt&gt;'''Ω'''&lt;/tt&gt; has no normal form (under any evaluation strategy). Using applicative order, the expression &lt;tt&gt;'''KIΩ''' = (λ''x''.λ''y''.''x'') (λ''x''.''x'')'''Ω'''&lt;/tt&gt; is reduced by first reducing &lt;tt&gt;'''Ω'''&lt;/tt&gt; to normal form (since it is the rightmost redex), but since &lt;tt&gt;'''Ω'''&lt;/tt&gt; has no normal form, applicative order fails to find a normal form for &lt;tt&gt;'''KIΩ'''&lt;/tt&gt;.

In contrast, normal order is so called because it always finds a normalising reduction, if one exists. In the above example, &lt;tt&gt;'''KIΩ'''&lt;/tt&gt; reduces under normal order to ''I'', a normal form. A drawback is that redexes in the arguments may be copied, resulting in duplicated computation (for example, &lt;tt&gt;(λ''x''.''xx'') ((λ''x''.''x'')''y'')&lt;/tt&gt; reduces to &lt;tt&gt;((λ''x''.''x'')''y'') ((λ''x''.''x'')''y'')&lt;/tt&gt; using this strategy; now there are two redexes, so full evaluation needs two more steps, but if the argument had been reduced first, there would now be none).

The positive tradeoff of using applicative order is that it does not cause unnecessary computation, if all arguments are used, because it never substitutes arguments containing redexes and hence never needs to copy them (which would duplicate work). In the above example, in applicative order &lt;tt&gt;(λ''x''.''xx'') ((λ''x''.''x'')''y'')&lt;/tt&gt; reduces first to &lt;tt&gt;(λ''x''.''xx'')''y''&lt;/tt&gt; and then to the normal order &lt;tt&gt;''yy''&lt;/tt&gt;, taking two steps instead of three.

Most ''purely'' functional programming languages (notably [[Miranda (programming language)|Miranda]] and its descendents, including Haskell), and the proof languages of [[Automated theorem prover|theorem provers]], use ''lazy evaluation'', which is essentially the same as call by need. This is like normal order reduction, but call by need manages to avoid the duplication of work inherent in normal order reduction using ''sharing''. In the example given above, &lt;tt&gt;(λ''x''.''xx'') ((λ''x''.''x'')''y'')&lt;/tt&gt; reduces to &lt;tt&gt;((λ''x''.''x'')''y'') ((λ''x''.''x'')''y'')&lt;/tt&gt;, which has two redexes, but in call by need they are represented using the same object rather than copied, so when one is reduced the other is too.

===A note about complexity===
While the idea of beta reduction seems simple enough, it is not an atomic step, in that it must have a non-trivial cost when estimating [[Computational complexity theory|computational complexity]].&lt;ref&gt;{{cite journal |first=R. |last=Statman |authorlink=Richard Statman |url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4567929 |title=The typed λ-calculus is not elementary recursive |journal=Theoretical Computer Science |year=1979 |volume=9 |issue=1 |pages=73–81 |doi=10.1016/0304-3975(79)90007-0}}&lt;/ref&gt; To be precise, one must somehow find the location of all of the occurrences of the bound variable &lt;tt&gt;''V''&lt;/tt&gt; in the expression &lt;tt&gt;''E''&lt;/tt&gt;, implying a time cost, or one must keep track of these locations in some way, implying a space cost. A naïve search for the locations of &lt;tt&gt;''V''&lt;/tt&gt; in &lt;tt&gt;''E''&lt;/tt&gt; is [[Big O notation|''O''(''n'')]] in the length ''n'' of &lt;tt&gt;''E''&lt;/tt&gt;. This has led to the study of systems that use [[explicit substitution]]. Sinot's [[director string]]s&lt;ref&gt;{{cite journal |first=F.-R. |last=Sinot |url=http://www.lsv.ens-cachan.fr/~sinot/publis.php?onlykey=sinot-jlc05 |title=Director Strings Revisited: A Generic Approach to the Efficient Representation of Free Variables in Higher-order Rewriting |journal=Journal of Logic and Computation |volume=15 |number=2 |pages=201–218 |year=2005 |doi=10.1093/logcom/exi010 }}{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; offer a way of tracking the locations of free variables in expressions.

===Parallelism and concurrency===
The [[Church–Rosser theorem|Church–Rosser]] property of the lambda calculus means that evaluation (β-reduction) can be carried out in ''any order'', even in parallel. This means that various [[evaluation strategy#Nondeterministic strategies|nondeterministic evaluation strategies]] are relevant. However, the lambda calculus does not offer any explicit constructs for [[parallel computing|parallelism]]. One can add constructs such as [[Futures and promises|Futures]] to the lambda calculus. Other [[process calculi]] have been developed for describing communication and concurrency.

===Optimal reduction===
In Lévy's 1988 paper "[http://pauillac.inria.fr/~levy/pubs/88icot.pdf Sharing in the Evaluation of lambda Expressions]", he defines a notion of optimal sharing, such that no work is ''duplicated''. For example, performing a beta reduction in normal order on &lt;tt&gt;(λ''x''.''xx'') (II)&lt;/tt&gt; reduces it to &lt;tt&gt;II (II)&lt;/tt&gt;. The argument &lt;tt&gt;II&lt;/tt&gt; is duplicated by the application to the first lambda term. If the reduction was done in an applicative order first, we save work because work is not duplicated: &lt;tt&gt;(λ''x''.''xx'') (II)&lt;/tt&gt; reduces to &lt;tt&gt;(λ''x''.''xx'') I&lt;/tt&gt;. On the other hand, using applicative order can result in redundant reductions or even possibly never reduce to normal form. For example, performing a beta reduction in normal order on &lt;tt&gt;(λ''f''.f I) (λy.(λ''x''.''xx'') (y I))&lt;/tt&gt; yields &lt;tt&gt;(λy.(λ''x''.''xx'') (y I)) I&lt;/tt&gt;, &lt;tt&gt;(λ''x''.''xx'') (II)&lt;/tt&gt; which we know we can do without duplicating work. Doing the same but in applicative order yields &lt;tt&gt;(λ''f''.f I) (λy.y I (y I))&lt;/tt&gt;, &lt;tt&gt;(λy.y I (y I)) I&lt;/tt&gt;, &lt;tt&gt;I I (I I)&lt;/tt&gt;, and now work is duplicated.

Lévy shows the existence of lambda terms where there ''does not exist'' a sequence of reductions which reduces them without duplicating work. The below lambda term is such an example.

&lt;tt&gt;((λg.(g(g(λx.x))))
(λh.((λf.(f(f(λz.z))))
(λw.(h(w(λy.y)))))))&lt;/tt&gt;

It is composed of three similar terms, &lt;tt&gt;x=((λg. ... ) (λh.y))&lt;/tt&gt; and &lt;tt&gt;y=((λf. ...) (λw.z) )&lt;/tt&gt;, and finally &lt;tt&gt;z=λw.(h(w(λy.y)))&lt;/tt&gt;. There are only two possible beta reductions to be done here, on x and on y. Reducing the outer x term first results in the inner y term being duplicated, and each copy will have to be reduced, but reducing the inner y term first will duplicate its argument z, which will cause work to be duplicated when the values of h and w are made known. Incidentally, the above term reduces to the identity function &lt;tt&gt;(λy.y)&lt;/tt&gt;, and is constructed by making wrappers which make the identity function available to the binders &lt;tt&gt;g=λh...&lt;/tt&gt;, &lt;tt&gt;f=λw...&lt;/tt&gt;, &lt;tt&gt;h=λx.x&lt;/tt&gt; (at first), and &lt;tt&gt;w=λz.z&lt;/tt&gt; (at first), all of which are applied to the innermost term &lt;tt&gt;λy.y&lt;/tt&gt;.

The precise notion of duplicated work relies on noticing that after the first reduction of &lt;tt&gt;I I&lt;/tt&gt; is done, the value of the other &lt;tt&gt;I I&lt;/tt&gt; can be determined, because they have the same structure (and in fact they have exactly the same values), and result from a common ancestor. Such similar structures can each be assigned a label that can be tracked across reductions. If a name is assigned to the redex that produces all the resulting &lt;tt&gt;II&lt;/tt&gt; terms, and then all duplicated occurrences of &lt;tt&gt;II&lt;/tt&gt; can be tracked and reduced in one go. However, it is not obvious that a redex will produce the &lt;tt&gt;II&lt;/tt&gt; term. Identifying the structures that are similar in different parts of a lambda term can involve a complex algorithm and can possibly have a complexity equal to the history of the reduction itself.

While Lévy defines the notion of optimal sharing, he does not provide an algorithm to do it. In Vincent van Oostrom, Kees-Jan van de Looij, and Marijn Zwitserlood's paper ''[https://www.researchgate.net/publication/237723293_Lambdascope_Another_optimal_implementation_of_the_lambda-calculus Lambdascope: Another optimal implementation of the lambda-calculus]'', they provide such an algorithm by transforming lambda terms into [[interaction nets]], which are then reduced. Roughly speaking, the resulting reduction is optimal because every term that would have the same labels as per Lévy's paper would also be the same graph in the interaction net. In the paper, they mention that their prototype implementation of Lambdascope performs as well as the ''optimised'' version of the reference optimal higher order machine BOHM.

More details can be found in the short article [https://www.researchgate.net/publication/312462365_About_the_efficient_reduction_of_lambda_terms About the efficient reduction of lambda terms].

==Semantics==
The fact that lambda calculus terms act as functions on other lambda calculus terms, and even on themselves, led to questions about the semantics of the lambda calculus. Could a sensible meaning be assigned to lambda calculus terms? The natural semantics was to find a set ''D'' isomorphic to the function space ''D'' → ''D'', of functions on itself. However, no nontrivial such ''D'' can exist, by [[cardinality]] constraints because the set of all functions from ''D'' to ''D'' has greater cardinality than ''D'', unless ''D'' is a [[singleton set]].

In the 1970s, [[Dana Scott]] showed that, if only [[Scott continuity|continuous functions]] were considered, a set or [[Domain theory|domain]] ''D'' with the required property could be found, thus providing a [[Model theory|model]] for the lambda calculus.

This work also formed the basis for the [[denotational semantics]] of programming languages.

==See also==
{{portal|Mathematics}}
{{colbegin|colwidth=30em}}
* [[Applicative computing systems]] – Treatment of [[object (computer science)|objects]] in the style of the lambda calculus
* [[Binary lambda calculus]] – A version of lambda calculus with binary I/O, a binary encoding of terms, and a designated universal machine.
* [[Calculus of constructions]] – A typed lambda calculus with [[type system|types]] as first-class values
* [[Cartesian closed category]] – A setting for lambda calculus in [[category theory]]
* [[Categorical abstract machine]] – A [[model of computation]] applicable to lambda calculus
* [[Combinatory logic]] – A notation for mathematical logic without variables
* [[Curry–Howard isomorphism]] – The formal correspondence between programs and [[mathematical proof|proofs]]
* [[De Bruijn index]] – notation disambugating alpha conversions
* [[De Bruijn notation]] – notation using postfix modification functiond 
* [[Deductive lambda calculus]] – The consideration of the problems associated with considering lambda calculus as a [[Deductive system]].
* [[Domain theory]] – Study of certain [[partially ordered sets|posets]] giving [[denotational semantics]] for lambda calculus
* [[Evaluation strategy]] – Rules for the evaluation of expressions in [[programming language]]s
* [[Explicit substitution]] – The theory of substitution, as used in [[#β-reduction|β-reduction]]
* [[Functional programming]]
* [[Harrop formula]] – A kind of constructive logical formula such that proofs are lambda terms
* [[Interaction nets]]
* [[Kappa calculus]] – A first-order analogue of lambda calculus
* [[Kleene–Rosser paradox]] – A demonstration that some form of lambda calculus is inconsistent
* [[Knights of the Lambda Calculus]] – A semi-fictional organization of LISP and [[Scheme (programming language)|Scheme]] [[Hacker (programmer subculture)|hackers]]
* [[Krivine machine]] – An abstract machine to interpret call-by-name in lambda-calculus
* [[Lambda calculus definition]] – Formal definition of the lambda calculus.
* [[Lambda cube]] – A framework for some extensions of typed lambda calculus
* [[Lambda-mu calculus]] – An extension of the lambda calculus for treating [[classical logic]]
* [[Let expression]] – An expression closely related to a lambda abstraction.
* [[Minimalism (computing)]]
* [[Rewriting]] – Transformation of formulæ in formal systems
* [[SECD machine]] – A [[virtual machine]] designed for the lambda calculus
* [[SKI combinator calculus]] – A computational system based on the '''[[#S|S]]''', '''[[#K|K]]''' and '''[[#I|I]]''' combinators
* [[System F]] – A typed lambda calculus with type-variables
* [[To Mock a Mockingbird]] - An introduction to [[Haskell (programming language)]] and lambda calculus
* [[Typed lambda calculus]] – Lambda calculus with typed variables (and functions)
* [[Universal Turing machine]] – A formal computing machine that is equivalent to lambda calculus
* [[Unlambda]] – An [[esoteric programming language|esoteric]] functional programming language based on combinatory logic
{{colend}}

==References==
{{Reflist|30em}}

==Further reading==
*Abelson, Harold &amp; Gerald Jay Sussman. [[Structure and Interpretation of Computer Programs]]. [[The MIT Press]]. {{isbn|0-262-51087-1}}.
*[[Henk Barendregt|Hendrik Pieter Barendregt]] [http://www.cse.chalmers.se/research/group/logic/TypesSS05/Extra/geuvers.pdf ''Introduction to Lambda Calculus''].
*[[Henk Barendregt]], [http://enl.usc.edu/~jkna/fpl/church.pdf The Impact of the Lambda Calculus in Logic and Computer Science]. The Bulletin of Symbolic Logic, Volume 3, Number 2, June 1997.
*[[Henk Barendregt|Barendregt, Hendrik Pieter]], ''The Type Free Lambda Calculus'' pp1091–1132 of ''Handbook of Mathematical Logic'', [[North-Holland]] (1977) {{isbn|0-7204-2285-X}}
*Cardone and Hindley, 2006. [http://www.users.waitrose.com/~hindley/SomePapers_PDFs/2006CarHin,HistlamRp.pdf History of Lambda-calculus and Combinatory Logic]. In Gabbay and Woods (eds.), ''Handbook of the History of Logic'', vol. 5. Elsevier.
*Church, Alonzo, ''An unsolvable problem of elementary number theory'', [[American Journal of Mathematics]], 58 (1936), pp.&amp;nbsp;345–363. This paper contains the proof that the equivalence of lambda expressions is in general not decidable.
* Alonzo Church, ''The Calculi of Lambda-Conversion'' ({{isbn|978-0-691-08394-0}})&lt;ref&gt;{{cite journal|authorlink=Orrin Frink|author=Frink Jr., Orrin|title=Review: ''The Calculi of Lambda-Conversion'' by Alonzo Church|journal=Bull. Amer. Math. Soc.|year=1944|volume=50|issue=3|pages=169–172|url=http://www.ams.org/bull/1944-50-03/S0002-9904-1944-08090-7/S0002-9904-1944-08090-7.pdf|doi=10.1090/s0002-9904-1944-08090-7}}&lt;/ref&gt;
*Kleene, Stephen, ''A theory of positive integers in formal logic'', [[American Journal of Mathematics]], 57 (1935), pp.&amp;nbsp;153–173 and 219–244. Contains the lambda calculus definitions of several familiar functions.
*[[Peter Landin|Landin, Peter]], ''A Correspondence Between ALGOL 60 and Church's Lambda-Notation'', [[Communications of the ACM]], vol. 8, no. 2 (1965), pages 89–101. Available from the [http://portal.acm.org/citation.cfm?id=363749&amp;coll=portal&amp;dl=ACM ACM site]. A classic paper highlighting the importance of lambda calculus as a basis for programming languages.
*Larson, Jim, [https://web.archive.org/web/20011206080336/http://www.jetcafe.org/~jim/lambda.html ''An Introduction to Lambda Calculus and Scheme'']. A gentle introduction for programmers.
*Schalk, A. and Simmons, H. (2005) ''[http://www.cs.man.ac.uk/~hsimmons/BOOKS/lcalculus.pdf An introduction to λ-calculi and arithmetic with a decent selection of exercises]. Notes for a course in the Mathematical Logic MSc at Manchester University.
*[[Ruy de Queiroz|de Queiroz, Ruy J.G.B.]] (2008) [http://www.springerlink.com/content/27nk266126k817gq/ "On Reduction Rules, Meaning-as-Use and Proof-Theoretic Semantics"]. ''[[Studia Logica]]'', '''90'''(2):211–247. {{doi|10.1007/s11225-008-9150-5}}. A paper giving a formal underpinning to the idea of 'meaning-is-use' which, even if based on proofs, it is different from proof-theoretic semantics as in the Dummett–Prawitz tradition since it takes reduction as the rules giving meaning.
* Hankin, Chris, ''An Introduction to Lambda Calculi for Computer Scientists,'' {{isbn|0954300653}}
Monographs/textbooks for graduate students:
* Morten Heine Sørensen, Paweł Urzyczyn, ''Lectures on the Curry-Howard isomorphism'', Elsevier, 2006, {{isbn|0-444-52077-5}} is a recent monograph that covers the main topics of lambda calculus from the type-free variety, to most [[typed lambda calculi]], including more recent developments like [[pure type system]]s and the [[lambda cube]]. It does not cover [[subtyping]] extensions.
* {{Citation|last=Pierce|first=Benjamin|title=Types and Programming Languages|publisher=MIT Press|year=2002|isbn=0-262-16209-1}} covers lambda calculi from a practical type system perspective; some topics like dependent types are only mentioned, but subtyping is an important topic.

''Some parts of this article are based on material from [[Free On-line Dictionary of Computing|FOLDOC]], used with [[Wikipedia:Foldoc license|permission]].''

==External links==
*Graham Hutton, [https://www.youtube.com/watch?v=eis11j_iGMs Lambda Calculus], a short (12 minutes) Computerphile video on the Lambda Calculus
*Helmut Brandl, ''[https://www.dropbox.com/s/i0qgfoye6artcp8/untyped_lambda.pdf?dl=0 A Step by Step Introduction into Lambda Calculus]''
* {{springer|title=Lambda-calculus|id=p/l057000}}
*Achim Jung, ''[http://www.cs.bham.ac.uk/~axj/pub/papers/lambda-calculus.pdf A Short Introduction to the Lambda Calculus]''-([[Portable Document Format|PDF]]) 
*Dana Scott, ''[http://turing100.acm.org/lambda_calculus_timeline.pdf A timeline of lambda calculus]''-([[Portable Document Format|PDF]])
*David C. Keenan, ''[http://dkeenan.com/Lambda/ To Dissect a Mockingbird: A Graphical Notation for the Lambda Calculus with Animated Reduction]''
*Raúl Rojas, ''[http://www.inf.fu-berlin.de/inst/ag-ki/rojas_home/documents/tutorials/lambda.pdf A Tutorial Introduction to the Lambda Calculus]''-([[Portable Document Format|PDF]])
* Peter Selinger, ''[http://www.mscs.dal.ca/~selinger/papers/#lambdanotes Lecture Notes on the Lambda Calculus]''-([[Portable Document Format|PDF]])
*L. Allison, ''[http://www.allisons.org/ll/FP/Lambda/Examples/ Some executable λ-calculus examples]''
*Georg P. Loczewski, [http://www.lambda-bound.com/book/lambdacalc/lcalconl.html ''The Lambda Calculus and A++'']
* Bret Victor, ''[http://worrydream.com/AlligatorEggs/ Alligator Eggs: A Puzzle Game Based on Lambda Calculus]''
*''[http://www.safalra.com/science/lambda-calculus/ Lambda Calculus]'' on [http://www.safalra.com/ Safalra's Website]
*''{{planetmath reference|id=2788|title=Lambda Calculus}}''
* [https://chatziko.github.io/lci/ LCI Lambda Interpreter] a simple yet powerful pure calculus interpreter
* [http://lambda-the-ultimate.org/classic/lc.html Lambda Calculus links on Lambda-the-Ultimate]
*Mike Thyer, [http://thyer.name/lambda-animator/ Lambda Animator], a graphical Java applet demonstrating alternative reduction strategies.
* [http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/ Implementing the Lambda calculus] using [[C++ Templates]]
* Marius Buliga, [http://imar.ro/~mbuliga/graphic_revised.pdf ''Graphic lambda calculus'']
* [https://web.archive.org/web/20160729210437/http://cs.adelaide.edu.au/~pmk/publications/wage2008.pdf ''Lambda Calculus as a Workflow Model''] by Peter Kelly, Paul Coddington, and Andrew Wendelborn; mentions [[graph reduction]] as a common means of evaluating lambda expressions and discusses the applicability of lambda calculus for [[distributed computing]] (due to the [[Church–Rosser theorem|Church–Rosser]] property, which enables [[parallel computing|parallel]] graph reduction for lambda expressions).
*Shane Steinert-Threlkeld, [http://www.iep.utm.edu/lambda-calculi/ "Lambda Calculi"], ''[[Internet Encyclopedia of Philosophy]]''
* Anton Salikhmetov, [https://codedot.github.io/lambda/ ''Macro Lambda Calculus'']
{{authority control}}
{{DEFAULTSORT:Lambda Calculus}}
[[Category:1936 in computer science]]
[[Category:American inventions]]
[[Category:Articles with example code]]
[[Category:Computability theory]]
[[Category:Formal methods]]
[[Category:Lambda calculus| ]]
[[Category:Models of computation]]
[[Category:Theoretical computer science]]</text>
      <sha1>fzjw0qoimm5bdgc69vhps4oky310kt7</sha1>
    </revision>
  </page>
  <page>
    <title>Lazy caterer's sequence</title>
    <ns>0</ns>
    <id>2038304</id>
    <revision>
      <id>862608753</id>
      <parentid>852506480</parentid>
      <timestamp>2018-10-05T13:55:26Z</timestamp>
      <contributor>
        <username>Archon 2488</username>
        <id>7646666</id>
      </contributor>
      <minor/>
      <comment>insert spaces to fix LaTeX problem</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4964">[[Image:PancakeCutThrice.agr.jpg|thumb|Pancake cut into seven pieces with three straight cuts.]]
The '''lazy caterer's sequence,''' more formally known as the '''central polygonal numbers''', describes the maximum number of pieces of a [[Disk (mathematics)|disk]] (a [[pancake]] or [[pizza]] is usually used to describe the situation) that can be made with a given number of straight cuts. For example, three cuts across a pancake will produce six pieces if the cuts all meet at a common point inside the circle, but up to seven if they do not. This problem can be formalized mathematically as one of counting the cells in an [[arrangement of lines]]; for generalizations to higher dimensions, ''see'' [[arrangement of hyperplanes]].

The analogue of this sequence in three dimensions is the [[cake number]].

==Formula and sequence==
The maximum number ''p'' of pieces that can be created with a given number of cuts ''n'', where ''n''&amp;nbsp;≥&amp;nbsp;0, is given by the formula

:&lt;math&gt; p = \frac{n^2+n+2}{2}.&lt;/math&gt;

Using [[binomial coefficient]]s, the formula can be expressed as

:&lt;math&gt;p = 1 + {\tbinom {n + 1} 2} = {\tbinom n 0}+{\tbinom n 1}+{\tbinom n 2}. &lt;/math&gt;

This [[sequence]] {{OEIS|id=A000124}}, starting with &lt;math&gt;n=0&lt;/math&gt;, results in

:[[1 (number)|1]], [[2 (number)|2]], [[4 (number)|4]], [[7 (number)|7]], [[11 (number)|11]], [[16 (number)|16]], [[22 (number)|22]], [[29 (number)|29]], [[37 (number)|37]], [[46 (number)|46]], [[56 (number)|56]], [[67 (number)|67]], [[79 (number)|79]], [[92 (number)|92]], [[106 (number)|106]], [[121 (number)|121]], [[137 (number)|137]], [[154 (number)|154]], [[172 (number)|172]], [[191 (number)|191]], [[211 (number)|211]], ...

Each number equals 1 plus a [[triangular number]].

==Proof==
[[File:Lazy Caterer's Sequence (Cuts).gif|thumb|The maximum number of pieces from consecutive cuts are the numbers in the Lazy Caterer's Sequence.]]
When a circle is cut ''n'' times to produce the maximum number of pieces, represented as ''p''&amp;nbsp;=&amp;nbsp;''&amp;fnof;''(''n''), the ''n''th cut must be considered; the number of pieces before the last cut is ''&amp;fnof;''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1), while the number of pieces added by the last cut is ''n''.

To obtain the maximum number of pieces, the ''n''th cut line should cross all the other previous cut lines inside the circle, but not cross any intersection of previous cut lines. Thus, the ''n''th line itself is cut in ''n'' &amp;minus; 1 places, and into ''n'' line segments.  Each segment divides one piece of the (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)-cut pancake into 2 parts, adding exactly ''n'' to the number of pieces. The new line can't have any more segments since it can only cross each previous line once.  A cut line can always cross over all previous cut lines, as rotating the knife at a small angle around a point that is not an existing intersection will, if the angle is small enough, intersect all the previous lines including the last one added.

Thus, the total number of pieces after ''n'' cuts is

:&lt;math&gt;f(n)=n+f(n-1).&lt;/math&gt;

This [[recurrence relation]] can be solved.  If ''&amp;fnof;''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1) is expanded one term the relation becomes

:&lt;math&gt;f(n)=n+(n-1)+f(n-2).&lt;/math&gt;

Expansion of the term ''&amp;fnof;''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;2) can continue until the last term is reduced to ''&amp;fnof;''(0), thus,

:&lt;math&gt;f(n)=n+(n-1)+(n-2)+\cdots+1+f(0).&lt;/math&gt;

Since &lt;math&gt;f(0)=1&lt;/math&gt;, because there is one piece before any cuts are made, this can be rewritten as

:&lt;math&gt;f(n)=1+(1+2+3+\cdots + n).&lt;/math&gt;

This can be simplified, using the formula for the sum of an [[arithmetic progression]]:

:&lt;math&gt;f(n)=1+\frac{n(n+1)}{2}=\frac{n^2+n+2}{2}.&lt;/math&gt;

==See also      ==
*[[Floyd's triangle]]

==References==
*{{citation
 | last = Moore | first = T. L.
 | issue = 2
 | journal = The College Mathematics Journal
 | pages = 125–130
 | title = Using Euler's formula to solve plane separation problems
 | jstor = 2686448
 | volume = 22
 | year = 1991
 | doi = 10.2307/2686448
 | publisher = Mathematical Association of America}}.

*{{citation
 | last = Steiner | first = J. | author-link = Jakob Steiner
 | journal = [[Crelle's Journal|J. Reine Angew. Math.]]
 | pages = 349–364
 | title = Einige Gesetze über die Theilung der Ebene und des Raumes ("A Few Statements about the Division of the Plane and of Space")
 | volume = 1
 | year = 1826}}.

*{{citation
 | last = Wetzel | first = J. E.
 | issue = 8
 | journal = American Mathematical Monthly
 | pages = 647–656
 | title = On the division of the plane by lines
 | url = http://webcourse.cs.technion.ac.il/236603/Spring2008/ho/WCFiles/Wetzel.pdf
 | volume = 85
 | year = 1978
 | doi = 10.2307/2320333
 | publisher = Mathematical Association of America
 | jstor = 2320333}}.

==External links==
*{{mathworld|title=Circle Division by Lines|urlname=CircleDivisionbyLines}}

[[Category:Mathematical optimization]]
[[Category:Integer sequences]]
[[Category:Articles containing proofs]]</text>
      <sha1>9jeiwyogotdgsukbe2ww3wbfmhucogt</sha1>
    </revision>
  </page>
  <page>
    <title>Lemma (mathematics)</title>
    <ns>0</ns>
    <id>18634</id>
    <revision>
      <id>852089820</id>
      <parentid>840329097</parentid>
      <timestamp>2018-07-26T15:17:04Z</timestamp>
      <contributor>
        <username>OrdinaryArtery</username>
        <id>32352509</id>
      </contributor>
      <minor/>
      <comment>/* Comparison with theorem */ Minor addition to the comparison with theorems</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2622">In [[mathematics]], a "helping theorem" or '''lemma''' (plural '''lemmas''' or '''lemmata''') is a proven [[Theorem#Terminology|proposition]] which is used as a stepping stone to a larger result rather than as a statement of interest by itself.&lt;ref&gt;{{cite book |last= Higham |first= Nicholas J. |title= Handbook of Writing for the Mathematical Sciences |publisher= [[Society for Industrial and Applied Mathematics]] |year= 1998 |isbn= 0-89871-420-6 |pages= 16}}&lt;/ref&gt;  The word derives from the [[Ancient Greek]] [[wikt:en:λῆμμα#Ancient Greek|λῆμμα]] ("anything which is received, such as a gift, profit, or a bribe"). 

==Comparison with theorem==
There is no formal distinction between a lemma and a [[theorem]], only one of intention&amp;nbsp;– see [[Theorem#Terminology|Theorem terminology]].  However, a lemma can be considered a minor result whose sole purpose is to help prove a theorem &amp;nbsp;– a step in the direction of proof&lt;ref&gt;[http://divisbyzero.com/2008/09/22/what-is-the-difference-between-a-theorem-a-lemma-and-a-corollary/ "What is the difference between a theorem, a lemma, and a corollary?"]&lt;/ref&gt; – or a short theorem appearing at an intermediate stage in a proof.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=1176|isbn=1-57955-008-8}}&lt;/ref&gt;

==Well-known lemmas==
A good stepping stone can lead to many others. Some powerful results in mathematics are known as lemmas, such as [[Bézout's identity|Bézout's lemma]], [[Dehn's lemma]], [[Euclid's lemma]], [[Farkas' lemma]], [[Fatou's lemma]], [[Gauss's lemma (disambiguation)|Gauss's lemma]], [[Small_cancellation_theory#Greendlinger.27s_lemma|Greendlinger's lemma]], [[Itō's lemma]], [[Jordan's lemma]], [[Nakayama's lemma]], [[Closed_and_exact_differential_forms#Poincar.C3.A9_lemma|Poincaré's lemma]], [[Riesz's lemma]], [[Schur's lemma]], [[Schwarz's lemma]], [[Urysohn's lemma]], [[Vitali covering lemma]], [[Yoneda lemma|Yoneda's lemma]] and [[Zorn's lemma]]. While these results originally seemed too simple or too technical to warrant independent interest, they have turned out to be central to the theories in which they occur.

==See also==
{{wiktionary|lemma}}
*[[Corollary]]
*[[Fundamental lemma]]
*[[List of lemmas]]
*[[Theorem#Terminology|Theorem terminology]]

==References==
{{reflist}}

==External links==
*[[Doron Zeilberger]], [http://www.math.rutgers.edu/~zeilberg/Opinion82.html Opinion 82: A Good Lemma is Worth a Thousand Theorems]

{{PlanetMath attribution|id=4492|title=Lemma}}


[[Category:Mathematical terminology]]
[[Category:Lemmas|*]]</text>
      <sha1>hjf17a1ypswk0od4x8ry02ubwrdxlyd</sha1>
    </revision>
  </page>
  <page>
    <title>Loop space</title>
    <ns>0</ns>
    <id>2174332</id>
    <revision>
      <id>776970787</id>
      <parentid>776969946</parentid>
      <timestamp>2017-04-24T13:29:10Z</timestamp>
      <contributor>
        <username>Tgoodwil</username>
        <id>10564144</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4236">In [[topology]], a branch of [[mathematics]], the '''loop space''' Ω''X'' of a [[pointed space|pointed topological space]] ''X'' is the space of (based) loops in ''X'', maps from the [[circle]] ''S''&lt;sup&gt;1&lt;/sup&gt; to ''X'', equipped with the [[compact-open topology]]. Two loops can be multiplied by concatenation. With this operation, the loop space is an [[A-infinity operad|''A''&lt;sub&gt;∞&lt;/sub&gt;-space]]. That is, the multiplication is [[homotopy|homotopy coherently]] [[associative property|associative]].

The set of path components of Ω''X'', i.e. the set of based homotopy of based loops in ''X'', is a group, the [[fundamental group]] ''&amp;pi;''&lt;sub&gt;1&lt;/sub&gt;(''X'').

The '''iterated loop spaces''' of ''X'' are formed by applying Ω a number of times.

There is an analogous construction for [[topological spaces]] without basepoint. The '''free loop space''' of a [[topological space]] ''X'' is the space of maps from the circle ''S''&lt;sup&gt;1&lt;/sup&gt; to ''X'' with the [[compact-open topology]]. The free loop space of ''X'' is often denoted by &lt;math&gt; \mathcal{L}X&lt;/math&gt;. 
 
As a functor, the free loop space construction is [[right adjoint]] to [[cartesian product]] with the circle, while the loop space construction is right adjoint to the [[reduced suspension]]. This adjunction accounts for much of the importance of loop spaces in [[stable homotopy theory]]. (A related phenomenon in computer science is [[currying]], where the cartesian product is adjoint to the [[hom functor]].) Informally this is all referred to as [[Eckmann–Hilton duality]].

== Eckmann–Hilton duality ==
The loop space is dual to the [[Suspension (topology)|suspension]] of the same space; this duality is sometimes called [[Eckmann–Hilton duality]]. The basic observation is that
:&lt;math&gt;[\Sigma Z,X] \approxeq [Z, \Omega X]&lt;/math&gt;
where &lt;math&gt;[A,B]&lt;/math&gt; is the set of homotopy classes of maps &lt;math&gt;A \rightarrow B&lt;/math&gt;,
and &lt;math&gt;\Sigma A&lt;/math&gt; is the [[Suspension (topology)|suspension]] of A, and &lt;math&gt;\approxeq&lt;/math&gt; denotes the [[natural transformation|natural]] [[homeomorphism]].  This homeomorphism is essentially that of [[currying]], modulo the quotients needed to convert the products to reduced products.

In general, &lt;math&gt;[A, B]&lt;/math&gt; does not have a group structure for arbitrary spaces &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;. However, it can be shown that &lt;math&gt;[\Sigma Z,X]&lt;/math&gt; and &lt;math&gt;[Z, \Omega X]&lt;/math&gt; do have natural group structures when &lt;math&gt;Z&lt;/math&gt; and &lt;math&gt;X&lt;/math&gt; are [[Pointed space|pointed]], and the aforesaid isomorphism is of those groups. 
&lt;ref name="may"&gt;{{citation |last= May |first=J. P. |authorlink=J. Peter May|title=A Concise Course in Algebraic Topology |year=1999 |publisher=U. Chicago Press, Chicago |url=http://www.math.uchicago.edu/~may/CONCISE/ConciseRevised.pdf |accessdate=2016-08-27}} ''(See chapter 8, section 2)''&lt;/ref&gt;  Thus, setting &lt;math&gt;Z = S^{k-1}&lt;/math&gt; (the &lt;math&gt;k-1&lt;/math&gt; sphere) gives the relationship

:&lt;math&gt;\pi_k(X) \approxeq \pi_{k-1}(\Omega X)&lt;/math&gt;

This follows, since the [[homotopy group]] is defined as &lt;math&gt;\pi_k(X)=[S^k,X]&lt;/math&gt;, and the spheres can be obtained via suspensions of each-other: that is, &lt;math&gt;S^k=\Sigma S^{k-1}&lt;/math&gt;. &lt;ref&gt;[http://topospaces.subwiki.org/wiki/Loop_space_of_a_based_topological_space Topospaces wiki - Loop space of a based topological space]&lt;/ref&gt;

==See also==
*[[fundamental group]]
*[[path (topology)]]
*[[loop group]]
*[[free loop]]
*[[quasigroup]]
*[[Spectrum (topology)]]
*[[Eilenberg–MacLane space]]

==References==
{{Reflist}}

*{{Citation | last1=Adams | first1=John Frank |authorlink=Frank Adams| title=Infinite loop spaces | url=https://books.google.com/books?id=e2rYkg9lGnsC | publisher=[[Princeton University Press]] | series=Annals of Mathematics Studies | isbn=978-0-691-08207-3| mr=505692 | year=1978 | volume=90}}
*{{Citation | last1=May | first1=J. Peter | author1-link=J. Peter May | title=The Geometry of Iterated Loop Spaces | url=http://www.math.uchicago.edu/~may/BOOKSMaster.html | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-05904-2 | doi=10.1007/BFb0067491 | mr=0420610 | year=1972}}

[[Category:Topology]]
[[Category:Homotopy theory]]
[[Category:Topological spaces]]</text>
      <sha1>1rvq0tspq5ejrllf3iamu0fiug2yc3v</sha1>
    </revision>
  </page>
  <page>
    <title>M. T. Naraniengar</title>
    <ns>0</ns>
    <id>39723141</id>
    <revision>
      <id>857400583</id>
      <parentid>745036230</parentid>
      <timestamp>2018-08-31T13:05:41Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1643">[[File:M. T. Naraniengar.jpg|thumb|M. T. Naraniengar]]
'''Mandyam Tondanur Naraniengar''' (1871–1940)&lt;ref name="gazette"&gt;{{cite journal|title=Mandyam Tondanur Naraniengar, 1870–1940|jstor=3606553|journal=The Mathematical Gazette|volume=25|issue=267|date=December 1941|page=265}}&lt;/ref&gt;  was an Indian mathematician. He first proved in 1909 the [[Morley's trisector theorem]] after it was posed in 1899 by [[Frank Morley]].&lt;ref&gt;{{cite web|title=An Essay on Morley's Theorem|url=http://jwilson.coe.uga.edu/EMT668/EMAT6680.F99/Estes/morley/morley.html}}&lt;/ref&gt;

He was the president of [[Indian Mathematical Society]] from 1930 to 1932&lt;ref&gt;{{cite web|title=The Succession List of the Office-Bearers of The Indian Mathematical Society|url=http://www.indianmathsociety.org.in/officebearers.htm|publisher=[[Indian Mathematical Society]]}}&lt;/ref&gt; and the editor of the ''Journal of the Indian Mathematical Society'' from its founding in 1909 until 1927.&lt;ref name="gazette"/&gt;

==References==
{{Reflist}}

==External links==
*[http://www.cut-the-knot.org/triangle/Morley/Naraniengar.shtml Proof]
*[http://www.thehindu.com/features/friday-review/history-and-culture/madras-miscellany/article2562418.ece Picture]
*[https://books.google.com/books?id=DrXxAAAAMAAJ&amp;q=M.+T.+Naraniengar&amp;dq=M.+T.+Naraniengar&amp;hl=en&amp;sa=X&amp;ei=5AnCUfX_AsqxrAfx_ICgCg&amp;ved=0CDMQ6AEwAQ Biography]

{{authority control}}

{{DEFAULTSORT:Naraniengar, M. T.}}
[[Category:1871 births]]
[[Category:1940 deaths]]
[[Category:19th-century Indian mathematicians]]
[[Category:Geometers]]
[[Category:Presidents of the Indian Mathematical Society]]
[[Category:20th-century Indian mathematicians]]</text>
      <sha1>fzjtwa0kqrioq3wwnfe3qvm6j255kb6</sha1>
    </revision>
  </page>
  <page>
    <title>Martin Bridson</title>
    <ns>0</ns>
    <id>36378173</id>
    <revision>
      <id>860111844</id>
      <parentid>853560693</parentid>
      <timestamp>2018-09-18T12:25:58Z</timestamp>
      <contributor>
        <username>Blackcat</username>
        <id>2007507</id>
      </contributor>
      <comment>removed [[Category:Manx people]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5229">{{Infobox scientist
| name = Martin Bridson
| honorific_suffix = {{post-nominals|FRS|size=100%}}
| image = Professor Martin Bridson FRS.jpg
| caption = Martin Bridson at the [[Royal Society]] admissions day in London in 2016
| birth_date = {{birth year and age|1964}}&lt;ref name=whoswho/&gt;
| birth_name = Martin Robert Bridson
| birth_place = [[Douglas, Isle of Man]]
| death_date =
| death_place =
| website = {{URL|https://people.maths.ox.ac.uk/bridson}}
| citizenship =
| nationality =
| ethnicity =
| field = [[Geometric Group Theory]]
| work_institutions = [[University of Oxford]]
| education = [[St Ninian's High School, Douglas]]
| alma_mater = [[University of Oxford]] (BA)&lt;br&gt;[[Cornell University]] (PhD)
| doctoral_advisor = [[Karen Vogtmann]]&lt;ref name=mathgene/&gt;
| doctoral_students = [[Daniel Wise (mathematician)|Daniel Wise]]&lt;ref name=mathgene/&gt;
| thesis_title =  Geodesics and Curvature in Metric Simplicial Complexes
| thesis_url = http://www.worldcat.org/oclc/64067761
| thesis_year =1991
| known_for = 
| influences =
| influenced =
| prizes = {{Plainlist|
* [[Royal Society Wolfson Research Merit Award]]{{when|date=May 2018}}
* [[Whitehead Prize]] (1999)}}
}}
'''Martin Robert Bridson''' {{post-nominals|FRS|size=100%}} is a [[Manx people|Manx]] [[mathematician]]. He is 
the Whitehead Professor of Pure Mathematics and Head of the Mathematical Institute at the [[University of Oxford]]. He is a Fellow of [[Magdalen College, Oxford]], and an Honorary Fellow of [[Hertford College, Oxford]]. Specializing in geometry, topology and group theory, Bridson is best known for his work in [[Geometric Group Theory]].&lt;ref name=mathgene&gt;{{MathGenealogy|id=24021}}&lt;/ref&gt;&lt;ref name=gs&gt;{{Google scholar id}}&lt;/ref&gt;&lt;ref name=scopus&gt;{{Scopus id}}&lt;/ref&gt; 

==Education and early life==
[[File:Martin_Bridson2.jpg|thumb|right|Martin Bridson at [[Mathematical Research Institute of Oberwolfach|Oberwolfach]] in 2013]]
Bridson is a native of the [[Isle of Man]].&lt;ref&gt;{{cite web|url=https://www.nytimes.com/1995/12/31/style/weddings-julie-a-lynch-martin-r-bridson.html|title=WEDDINGS;Julie A. Lynch, Martin R. Bridson|publisher=}}&lt;/ref&gt; He was educated at [[St Ninian's High School, Douglas]], then [[Hertford College, Oxford]], and [[Cornell University]],&lt;ref name=whoswho&gt;{{Who's Who | surname = Bridson | othernames = Prof. Martin Robert | id = U250830 |doi=10.1093/ww/9780199540884.013.250830|author=Anon | year = 2017 | edition = online [[Oxford University Press]]}} {{subscription required}}&lt;/ref&gt;
receiving a [[Master of Arts]] degree from Oxford in 1986, and a [[Master of Science]] degree in 1988 followed by a [[PhD]] in 1991 from Cornell.&lt;ref&gt;{{cite web |url=http://www.magd.ox.ac.uk/whos-here/fellows-and-lecturers/fellows/bridsonm |title=Archived copy |accessdate=2012-07-09 |deadurl=yes |archiveurl=https://web.archive.org/web/20120723110312/http://www.magd.ox.ac.uk/whos-here/fellows-and-lecturers/fellows/bridsonm |archivedate=2012-07-23 |df= }}&lt;/ref&gt;&lt;ref name=mathgene/&gt; His PhD thesis was supervised by [[Karen Vogtmann]],&lt;ref name=mathgene/&gt; and was entitled ''Geodesics and Curvature in Metric Simplicial Complexes''.

==Career and research==
He was an Assistant Professor at [[Princeton University]] until 1996, was twice a Visiting Professor at the [[University of Geneva]] (1992 and 2006), and was Professor of Mathematics at [[Imperial College London]] from 2002 to 2007. From 1993 to 2002 he was a Tutorial Fellow of Pembroke College, Oxford, and  Reader (1996) then Professor of Topology (2000) in the University of Oxford. He remains a Supernumerary Fellow of Pembroke College.&lt;ref&gt;{{cite web|url=http://people.maths.ox.ac.uk/bridson/|title=Martin R. Bridson|first=Martin|last=Bridson|website=people.maths.ox.ac.uk}}&lt;/ref&gt;

===Honours and awards===
Bridson was an Invited Lecturer at the [[International Congress of Mathematicians]] in 2006.{{fact|date=May 2018}}
* In 2016 he was elected a [[Fellow of the Royal Society]].&lt;ref&gt; {{cite web|url= https://royalsociety.org/people/martin-bridson-12847/|title= Martin bridson biography|publisher= Royal Society|accessdate= 1 May 2016}} &lt;/ref&gt;
* In 2014 he was elected a [[Fellow]] of the [[American Mathematical Society]].&lt;ref&gt;{{cite web|url=http://www.ams.org/profession/fellows-list|title=American Mathematical Society|website=www.ams.org}}&lt;/ref&gt;
* 1999 Whitehead Prize{{fact|date=May 2018}}
* 2012 [[Royal Society Wolfson Research Merit Award]] 

== References ==
{{reflist|30em}}
{{CC-notice|cc=by4|url= https://royalsociety.org/people/martin-bridson-12847}}

{{FRS 2016}}
{{Authority control}}

{{DEFAULTSORT:Bridson, Martin}}
[[Category:1964 births]]
[[Category:Living people]]
[[Category:People educated at St Ninian's High School, Douglas]]
[[Category:Alumni of Hertford College, Oxford]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Fellows of Magdalen College, Oxford]]
[[Category:Fellows of Pembroke College, Oxford]]
[[Category:Statutory Professors of the University of Oxford]]
[[Category:Whitehead Prize winners]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Royal Society]]
[[Category:People from Douglas, Isle of Man]]
{{IsleofMan-bio-stub}}</text>
      <sha1>dgatmlp45827hfwj5pl1k976xg61s8l</sha1>
    </revision>
  </page>
  <page>
    <title>MathMagic</title>
    <ns>0</ns>
    <id>31383296</id>
    <revision>
      <id>829496374</id>
      <parentid>815201835</parentid>
      <timestamp>2018-03-09T00:12:24Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>Fix [[:Category:Pages using deprecated image syntax]]; [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4719">{{Multiple issues|
{{more citations needed|date=June 2013}}
{{Notability|Products|date=December 2012}}
}}

{{Infobox software
| name                   = MathMagic
| logo                   = [[File:MathMagic icon.png|64px|MathMagic Icon]]
| screenshot             = MMPE7Mac.png
| screenshot size        = 230px
| caption                = MathMagic Personal with sample equations and a few palettes, running on Mac OS X
| developer              = InfoLogic
| released               = {{Start date and age|1998|09|01|df=yes}}&lt;ref&gt;{{citation|title= InfoLogic celebrates its 10th anniversary of MathMagic |url=http://www.mathmagic.com/news/anniversary.html|publisher=InfoLogic|accessdate=2 Jul 2016}}&lt;/ref&gt;
| latest release version = v9.31 for macOS, v8.31 for Windows
| latest release date    = {{release date|2017|7|7|df=yes}}
| operating system       = [[macOS]], [[Microsoft Windows]], [[Android (operating system)|Android]], [[iOS]]
| genre                  = [[Formula editors]]
| license                = [[Proprietary software|Proprietary]]
| website                = [http://www.mathmagic.com www.mathmagic.com]
}}
'''MathMagic''' is a mathematical [[WYSIWYG]] equation editor, available for Windows, macOS, [[Android (operating system)|Android]] and [[iOS]] since its debut in 1998. MathMagic is known for its [[Desktop publishing|DTP]] quality equations and widely used by Adobe [[InDesign]] and [[QuarkXPress]] users. MathMagic is a stand-alone multi-purpose equation editor application so its equation can be used by most software, such as word processors, presentation software, DTP layout software, and graphic software, via Copy and Paste, Drag and Drop, or by exporting to one of its supported formats.

==MathMagic Products==
MathMagic product line includes "MathMagic Personal Edition", "MathMagic Pro for Adobe InDesign", "MathMagic Pro for QuarkXPress", and "MathMagic Prime Edition", depending on the configuration and their target market.

In June 2012, "MathMagic Lite Edition", their complimentary version, was introduced for Mac OS X and [[Android (operating system)|Android]] platforms,&lt;ref&gt;{{cite news | url=http://prmac.com/release-id-44785.htm |title= MathMagic 8.0 Lite for Mac OS X - Free, Standalone, Equation Editor | publisher=prmac.com |date=2012-06-28}}&lt;/ref&gt; with some limited features according to their [http://www.mathmagic.com/download/mm.html Feature Comparison Table]. In September 2014, "MathMagic Lite for Windows" was released.&lt;ref&gt;{{cite news | url= http://www.prweb.com/releases/2014/09/prweb12161181.htm | title= InfoLogic Releases MathMagic Lite for Windows - Math Equation Editor for K12 | publisher=prweb.com |date=2014-09-15}}&lt;/ref&gt; Now, their Lite Edition is available on all Android OS, iOS, macOS, and Windows platforms.

==MathMagic Features==
MathMagic supports [[MathML]], [[LaTeX]], [[TeX|Plain TeX]], [[Scalable Vector Graphics|SVG]], ASCIIMath, EPS, PDF, PICT, WMF, JPEG, GIF, BMP, PNG, TIFF,  [[MathType]] equations, MS Equation Editor equations, MS Word 2007 equation, Google Docs equation, Zoho Writer equation, Math-To-Speech, and others. Some formats are platform specific.  Although it is a WYSIWYG equation editor, MathMagic allows you type or paste LaTeX expressions directly into the editor window. [[MathML]], ASCIIMathML, and other formats can also be pasted in or copied out. It also supports [[Speech synthesis|Text To Speech]] to read out mathematical expressions via the OS built-in TTS engine or a few internet based remote TTS services.

MathMagic understands a certain level of natural English expressions to convert spoken language based Math reading into equation. For example, pasting ''"y equals 3x plus 2a minus 2.5 squareroot b"'' will form
:&lt;math&gt;y = 3 x + 2 a - 2.5 \sqrt{b}.&lt;/math&gt;

MathMagic Pro comes with all the features of Personal Edition, plus extra features and fonts for high-end users, and Plug-ins or XTensions to work directly with Adobe InDesign or QuarkXPress. MathMagic Pro for Adobe InDesign works with InDesign CS ~ CS6 and CC ~ CC2017. MathMagic Pro for QuarkXPress works with QuarkXPress 6.x ~ 9.x.

MathMagic equation can be pasted into MS Word 2007 or newer's document in MathML format because MS Word's new built-in Equation editor can display and edit [[MathML]].

MathMagic does not support computation.

==Competing software==
* [[MathType]]
* [[Office 2007|Microsoft Word 2007 equation editor]]

==See also==
* [[Formula editor]]
* [[MathML]]
* [[LaTeX]]
* [[ASCIIMathML]]

==External links==
* [http://www.mathmagic.com/ MathMagic homepage]

==References==
{{reflist|1}}

[[Category:Mathematical software]]
[[Category:Formula editors]]
[[Category:Science software]]
[[Category:Desktop publishing software]]</text>
      <sha1>pgeqhxodw04ldizttsyxapa65ecwmdq</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematics of Sudoku</title>
    <ns>0</ns>
    <id>2912292</id>
    <revision>
      <id>867851853</id>
      <parentid>860426865</parentid>
      <timestamp>2018-11-08T11:59:50Z</timestamp>
      <contributor>
        <ip>152.231.86.22</ip>
      </contributor>
      <comment>/* Maximum number of givens */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="70433">[[File:Sudoku_Puzzle_(automorphic_with_translational_symmetry).png|thumb|upright=1.2|right|alt=A 24-clue automorphic sudoku with translational symmetry.|A 24-clue [[#Automorphic Sudokus|automorphic Sudoku]] with [[Translational symmetry|translational]] symmetry.]]
The [[class (set theory)|class]] of '''[[Sudoku]]''' [[puzzle]]s consists of a partially completed row-column grid of cells partitioned into ''N'' regions each of size ''N'' cells, to be filled in ("solved") using a prescribed set of ''N'' distinct symbols (typically the numbers {1, ..., ''N''}), so that each row, column and region contains exactly one of each element of the set. The properties of Sudoku puzzles and their solutions can be investigated using [[mathematics]] and [[Sudoku solving algorithms|algorithms]].

==Overview==
The analysis of Sudoku falls into two main areas: analyzing the properties of (1) completed grids and (2) puzzles. Also studied are [[Sudoku solving algorithms|computer algorithms]] to solve Sudokus, and to develop (or search for) new Sudokus. Analysis has largely focused on enumerating solutions, with results first appearing in 2004.&lt;ref&gt;{{citation|last=Lin|first=Keh Ying|title=Number Of Sudokus|journal= Journal of Recreational Mathematics|volume=33|issue=2|year=2004|pages=120–24}}.&lt;/ref&gt; There are many [[Sudokian|Sudoku variants]], partially characterized by size (''N''), and the shape of their ''regions''. Unless noted, discussion in this article assumes classic Sudoku, i.e. ''N''=9 (a 9×9 grid and 3×3 regions). A rectangular Sudoku uses rectangular regions of row-column dimension ''R''×''C''. Other variants include those with irregularly-shaped regions or with additional constraints ([[#Sudoku with additional constraints|hypercube]]) or different constraint types ([[#Sum number place ("Killer Sudoku")|Samunamupure]]).

A ''puzzle'' is a partially completed ''grid'', and the initial values are ''givens'' or ''clues''. ''Regions'' are also called ''blocks'' or ''boxes''. Horizontally adjacent ''rows'' are a ''band'', and vertically adjacent ''columns'' are a ''stack''. A ''proper'' puzzle has a unique solution. See [[Glossary of Sudoku]] for other terminology.&lt;ref name="basicterms"&gt;{{cite web|author= |url=http://forum.enjoysudoku.com/viewtopic.php?t=4120 |title=Basic terms : About the New Sudoku Players' Forum |publisher=Forum.enjoysudoku.com |date=16 May 2006 |accessdate=20 October 2013}}&lt;/ref&gt; Solving Sudokus from the viewpoint of a player has been explored in Denis Berthier's book "The Hidden Logic of Sudoku" (2007)&lt;ref&gt;{{cite book | first = Denis | last = Berthier | url = http://denis.berthier.pagesperso-orange.fr/HLS/index.html | date = November 2007 | title = The Hidden Logic of Sudoku | edition = Second, revised and extended | isbn =  978-1-84799-214-7 | publisher = Lulu.com | accessdate = 2017-11-21 }}&lt;/ref&gt;  which considers strategies such as "hidden xy-chains".

===Mathematical context===
The general problem of solving Sudoku puzzles on ''n''&lt;sup&gt;2&lt;/sup&gt;×''n''&lt;sup&gt;2&lt;/sup&gt; grids of ''n''×''n'' blocks is known to be [[NP-complete]].&lt;ref name="SIGAL87"&gt;{{cite web|url=http://www-imai.is.s.u-tokyo.ac.jp/~yato/data2/SIGAL87-2.pdf |title=NP complete – Sudoku|publisher=Imai.is.su-tokyo.ac.jp |accessdate=20 October 2013}}&lt;/ref&gt; For ''n''=3 (classical Sudoku), however, this result is of little relevance: [[algorithm]]s such as [[Dancing Links]] can solve puzzles in fractions of a second.

A puzzle can be expressed as a [[graph coloring]] problem.&lt;ref name="Lewis2015"&gt;Lewis, R. ''A Guide to Graph Colouring: Algorithms and Applications''. Springer International Publishers, 2015.&lt;/ref&gt; The aim is to construct a 9-coloring of a particular graph, given a partial 9-coloring. The graph has 81 vertices, one vertex for each cell. The vertices are labeled with ordered pairs (''x'', ''y''), where ''x'' and ''y'' are integers between 1 and 9. In this case, two distinct vertices labeled by (''x'', ''y'') and (''x''′, ''y''′) are joined by an edge if and only if:
* ''x'' = ''x''′ (same column) or,
* ''y'' = ''y''′ (same row) or,
* ⌈ ''x''/3 ⌉ = ⌈ ''x''′/3 ⌉ and ⌈ ''y''/3 ⌉ = ⌈ ''y''′/3 ⌉ (same 3×3 cell)
The puzzle is then completed by assigning an integer between 1 and 9 to each vertex, in such a way that vertices that are joined by an edge do not have the same integer assigned to them.

A Sudoku solution grid is also a [[Latin square]].&lt;ref name="Lewis2015" /&gt;  There are significantly fewer Sudoku grids than Latin squares because Sudoku imposes the additional regional constraint.  Nonetheless, the number of Sudoku grids was calculated by Bertram Felgenhauer and Frazer Jarvis in 2005 to be 6,670,903,752,021,072,936,960&lt;ref name="afj2"&gt;{{cite web|url=http://www.afjarvis.staff.shef.ac.uk/sudoku|title=Sudoku enumeration problems |publisher=Afjarvis.staff.shef.ac.uk|accessdate=20 October 2013}}&lt;/ref&gt;{{OEIS|id=A107739}}.&amp;nbsp; The number computed by Felgenhauer and Jarvis confirmed a result first identified by QSCGZ in September 2003.&lt;ref name="afj2"/&gt; This number is equal to 9! × 72&lt;sup&gt;2&lt;/sup&gt; × 2&lt;sup&gt;7&lt;/sup&gt; × 27,704,267,971, the last factor of which is [[prime number|prime]].  The result was derived through logic and [[brute force search|brute force]] [[computation]].  Russell and Jarvis also showed that when symmetries were taken into account, there were 5,472,730,538 solutions&lt;ref name="sudgroup"&gt;{{cite web|url=http://www.afjarvis.staff.shef.ac.uk/sudoku/sudgroup.html |title=Sudoku enumeration: the symmetry group |publisher=Afjarvis.staff.shef.ac.uk |date=7 September 2005|accessdate=20 October 2013}}&lt;/ref&gt; {{OEIS|id=A109741}}. The number of grids for 16×16 Sudoku is not known.

The number of minimal Sudokus (Sudokus in which no clue can be deleted without losing uniqueness of the solution) is not precisely known. However, statistical techniques combined with a generator ({{lang|en|'Unbiased Statistics of a CSP – A Controlled-Bias Generator'}}),&lt;ref name='Unbiased Statistics of a CSP - A Controlled-Bias Generator'&gt;{{cite news | first = Denis | last = Berthier | url = http://hal.archives-ouvertes.fr/hal-00641955 | date = 4 December 2009 | title = Unbiased Statistics of a CSP – A Controlled-Bias Generator | accessdate = 4 December 2009 }}&lt;/ref&gt; show that there are approximately (with 0.065% relative error):
* 3.10&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;37&lt;/sup&gt; minimal puzzles,
* 2.55&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;25&lt;/sup&gt; non-essentially-equivalent minimal puzzles.
Other authors used faster methods and calculated additional precise distribution statistics.&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/counting-minimal-puzzles-subsets-supersets-etc-t31190.html |title=Counting minimal puzzles: subsets, supersets, etc. |publisher=Forum.enjoysudoku.com |date=2013-06-11 |accessdate=2017-04-18}}&lt;/ref&gt;

===Sudokus from group tables===
As in the case of [[Latin square]]s the (addition- or) [[multiplication table]]s ([[Cayley table]]s) of finite groups can be used to construct Sudokus and related tables of numbers. Namely, one has to take [[Subgroups|subgroup]]s and [[quotient group]]s into account:

Take for example &lt;math&gt;\mathbb{Z}_{n}\oplus\mathbb{Z}_{n}&lt;/math&gt; the group of pairs, adding each component separately modulo some &lt;math&gt;n&lt;/math&gt;.
By omitting one of the components, we suddenly find ourselves in &lt;math&gt;\mathbb{Z}_{n}&lt;/math&gt; (and this mapping is obviously compatible with the respective additions, i.e. it is a [[group homomorphism]]).
One also says that the latter is a [[quotient group]] of the former, because some once different elements become equal in the new group.
However, it is also a [[subgroup]], because we can simply fill the missing component with &lt;math&gt;0&lt;/math&gt; to get back to &lt;math&gt;\mathbb{Z}_{n}\oplus\mathbb{Z}_{n}&lt;/math&gt;. 

Under this view, we write down the example, '''Grid 1''', for &lt;math&gt;n=3&lt;/math&gt;.

Each Sudoku region looks the same on the second component (namely like the subgroup &lt;math&gt;\mathbb{Z}_{3}&lt;/math&gt;), because these are added regardless of the first one.
On the other hand, the first components are equal in each block, and if we imagine each block as one cell, these first components show the same pattern (namely the quotient group &lt;math&gt;\mathbb{Z}_{3}&lt;/math&gt;). As outlined in the article of [[Latin square]]s, this is a Latin square of order &lt;math&gt;9&lt;/math&gt;.

Now, to yield a Sudoku, let us permute the rows (or equivalently the columns) in such a way, that each block is redistributed exactly once into each block – for example order them &lt;math&gt;1,4,7,2,5,8,3,6,9&lt;/math&gt;.
This of course preserves the Latin square property. Furthermore, in each block the lines have distinct first component by construction
and each line in a block has distinct entries via the second component, because the blocks' second components originally formed a Latin square of order &lt;math&gt;3&lt;/math&gt; (from the subgroup &lt;math&gt;\mathbb{Z}_{3}&lt;/math&gt;). Thus we arrive at a Sudoku (rename the pairs to numbers 1...9 if you wish). With the example and the row permutation above, we arrive at '''Grid 2'''.
{| style="border-spacing: 10px;
|-
|{{Sudoku 9x9 grid|title='''Grid 1''' - The addition table in &lt;math&gt;\mathbb{Z}_{3}\oplus\mathbb{Z}_{3}&lt;/math&gt;|align=center|cellsize=24pt
|s1=(0,0) |s2=(0,1) |s3=(0,2) |s4=(1,0) |s5=(1,1) |s6=(1,2) |s7=(2,0) |s8=(2,1) |s9=(2,2) 
|s10=(0,1)|s11=(0,2)|s12=(0,0)|s13=(1,1)|s14=(1,2)|s15=(1,0)|s16=(2,1)|s17=(2,2)|s18=(2,0)
|s19=(0,2)|s20=(0,0)|s21=(0,1)|s22=(1,2)|s23=(1,0)|s24=(1,1)|s25=(2,2)|s26=(2,0)|s27=(2,1)
|s28=(1,0)|s29=(1,1)|s30=(1,2)|s31=(2,0)|s32=(2,1)|s33=(2,2)|s34=(0,0)|s35=(0,1)|s36=(0,2)
|s37=(1,1)|s38=(1,2)|s39=(1,0)|s40=(2,1)|s41=(2,2)|s42=(2,0)|s43=(0,1)|s44=(0,2)|s45=(0,0)
|s46=(1,2)|s47=(1,0)|s48=(1,1)|s49=(2,2)|s50=(2,0)|s51=(2,1)|s52=(0,2)|s53=(0,0)|s54=(0,1)
|s55=(2,0)|s56=(2,1)|s57=(2,2)|s58=(0,0)|s59=(0,1)|s60=(0,2)|s61=(1,0)|s62=(1,1)|s63=(1,2)
|s64=(2,1)|s65=(2,2)|s66=(2,0)|s67=(0,1)|s68=(0,2)|s69=(0,0)|s70=(1,1)|s71=(1,2)|s72=(1,0)
|s73=(2,2)|s74=(2,0)|s75=(2,1)|s76=(0,2)|s77=(0,0)|s78=(0,1)|s79=(1,2)|s80=(1,0)|s81=(1,1)
|c55=yellow|c56=yellow|c57=yellow|c64=yellow|c65=yellow|c66=yellow
|c73=yellow|c74=yellow|c75=yellow
}}
|{{Sudoku 9x9 grid|title='''Grid 2''' - Generating a Sudoku|align=center|cellsize=24pt
|s1=(0,0) |s2=(0,1) |s3=(0,2) |s4=(1,0) |s5=(1,1) |s6=(1,2) |s7=(2,0) |s8=(2,1) |s9=(2,2) 
|s10=(1,0)|s11=(1,1)|s12=(1,2)|s13=(2,0)|s14=(2,1)|s15=(2,2)|s16=(0,0)|s17=(0,1)|s18=(0,2)
|s19=(2,0)|s20=(2,1)|s21=(2,2)|s22=(0,0)|s23=(0,1)|s24=(0,2)|s25=(1,0)|s26=(1,1)|s27=(1,2)
|s28=(0,1)|s29=(0,2)|s30=(0,0)|s31=(1,1)|s32=(1,2)|s33=(1,0)|s34=(2,1)|s35=(2,2)|s36=(2,0)
|s37=(1,1)|s38=(1,2)|s39=(1,0)|s40=(2,1)|s41=(2,2)|s42=(2,0)|s43=(0,1)|s44=(0,2)|s45=(0,0)
|s46=(2,1)|s47=(2,2)|s48=(2,0)|s49=(0,1)|s50=(0,2)|s51=(0,0)|s52=(1,1)|s53=(1,2)|s54=(1,0)
|s55=(0,2)|s56=(0,0)|s57=(0,1)|s58=(1,2)|s59=(1,0) |s60=(1,1)|s61=(2,2)|s62=(2,0)|s63=(2,1)
|s64=(1,2)|s65=(1,0)|s66=(1,1)|s67=(2,2)|s68=(2,0)|s69=(2,1)|s70=(0,2)|s71=(0,0)|s72=(0,1)
|s73=(2,2)|s74=(2,0)|s75=(2,1)|s76=(0,2)|s77=(0,0)|s78=(0,1)|s79=(1,2)|s80=(1,0)|s81=(1,1)
|c19=yellow|c20=yellow|c21=yellow|c46=yellow|c47=yellow|c48=yellow
|c73=yellow|c74=yellow|c75=yellow
}}
|}
For this method to work, one generally does not need a product of two equally-sized groups. A so-called short [[exact sequence]] of finite groups
of appropriate size already does the job. Try for example the group &lt;math&gt;\mathbb{Z}_{4}&lt;/math&gt; with quotient- and subgroup &lt;math&gt;\mathbb{Z}_{2}&lt;/math&gt;.
It seems clear (already from enumeration arguments), that not all Sudokus can be generated this way.

==Enumerating Sudoku solutions==
The answer to the question 'How many Sudoku grids are there?' depends on the definition of when similar solutions are considered different.

===Enumerating all possible Sudoku solutions===
For the enumeration of ''all'' possible solutions, two solutions are considered distinct if any of their corresponding (81) cell values differ. Symmetry relations between similar solutions are ignored., e.g. the rotations of a solution are considered distinct. Symmetries play a significant role in the enumeration strategy, but not in the count of ''all'' possible solutions.

The first known solution to complete enumeration was posted by QSCGZ [Guenter Stertenbrink] to the ''rec.puzzles'' [[newsgroup]] in 2003,&lt;ref name="afj2"/&gt;&lt;ref&gt;{{cite web|url=https://groups.google.com/forum/#!topic/rec.puzzles/A7pi7S12oFI |title=Google Discussiegroepen |publisher=Groups.google.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/6670903752021072936960-is-old-hat-t5871.html |title=6670903752021072936960 is old hat : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; obtaining 6,670,903,752,021,072,936,960 ({{val|6.67|e=21}}) distinct solutions.

In a 2005 study, Felgenhauer and Jarvis&lt;ref name="afjarvis"&gt;{{citation|title=Enumerating possible Sudoku grids|first1=Bertram|last1=Felgenhauer|first2=Frazer|last2=Jarvis|date=June 20, 2005|url=http://www.afjarvis.staff.shef.ac.uk/sudoku/sudoku.pdf}}.&lt;/ref&gt; analyzed the [[combinations and permutations|permutations]] of the top band used in valid solutions. Once the Band1 [[symmetry in mathematics|symmetries]] and [[equivalence class]]es for the partial grid solutions were identified, the completions of the lower two bands were constructed and counted for each equivalence class. Summing completions over the equivalence classes, weighted by class size, gives the total number of solutions as 6,670,903,752,021,072,936,960, confirming the value obtained by QSCGZ. The value was subsequently confirmed numerous times independently. A second enumeration technique based on band generation was later developed that is significantly less computationally intensive.

==={{anchor|Transformations}}Enumerating essentially different Sudoku solutions===

Two valid grids are ''essentially'' the same if one can be derived from the other. The following operations are Sudoku preserving symmetries and always translate a valid grid into another valid grid:

* Relabeling symbols (9!)
* Band permutations (3!)
* Row permutations within a band (3!&lt;sup&gt;3&lt;/sup&gt;)
* Stack permutations (3!)
* Column permutations within a stack (3!&lt;sup&gt;3&lt;/sup&gt;)
* Reflection, transposition and rotation (2). (Given any transposition or quarter-turn rotation in conjunction with the above permutations, any combination of reflections, transpositions and rotations can be produced, so these operations only contribute a factor of 2.)

These operations define a symmetry relation between equivalent grids. Excluding relabeling, and with respect to the 81 grid cell values, the operations form a [[subgroup]] of the [[symmetric group]] S&lt;sub&gt;81&lt;/sub&gt;, of order 3!&lt;sup&gt;8&lt;/sup&gt;×2&amp;nbsp;=&amp;nbsp;3,359,232. Applying the above operations on majority of the grids results in 3!&lt;sup&gt;8&lt;/sup&gt;×2×9! essentially equivalent grids. Exceptions are [[#Automorphic Sudokus|Automorphic Sudokus]] which due to additional non-trivial symmetry generate fewer grids.

The number of distinct solutions can also be identified with [[Burnside's Lemma]]. For a solution, the set of equivalent solutions which can be reached using these operations (excluding relabeling), form an [[Orbit (group theory)|orbit]] of the [[symmetric group]]. The number of essentially different solutions is then the number of orbits, which can be computed using Burnside's lemma. The Burnside ''fixed points'' are solutions that differ only by relabeling. Using this technique, Jarvis/Russell&lt;ref name="sudgroup" /&gt; computed the number of essentially different (symmetrically distinct) solutions as 5,472,730,538.

==Enumeration results==
Enumeration results for many Sudoku variants have been calculated: these are summarised below.

===Sudoku with rectangular regions===
In the table, "Dimensions" are those of the regions (e.g. 3x3 in normal Sudoku). The "Rel Err" column indicates how a simple approximation, using the generalised method of Kevin Kilfoil,&lt;ref name="forum.enjoysudoku.com"&gt;{{cite web|url=http://forum.enjoysudoku.com/post15920.html#p15920 |title=Su-Doku's maths : General - Page 36 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; compares to the true grid count: it is an underestimate in all cases evaluated so far.

{| class="wikitable"
|-
! Dimensions
! Nr Grids
! Attribution
! Verified?
! Rel Err
|-
|align=center|1x?|| colspan="3" style="text-align:center;"|''see [[Latin squares]]''||align=center|n/a
|-
|align=center|2×2||288|| various&lt;ref name=":0"&gt;{{Cite OEIS|1=A107739|2=Number of (completed) sudokus (or Sudokus) of size n^2 X n^2|accessdate=14 April 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post2992.html#p2992 |title=Sudoku maths - can mortals work it out for the 2x2 square ? : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; || align="center" |Yes||align=center|-11.1%
|-
|align=center|2×3||28200960 = c. {{val|2.8|e=7}}|| Pettersen&lt;ref name="ReferenceA"&gt;{{cite web|url=http://forum.enjoysudoku.com/post11444.html#p11444 |title=Su-Doku's maths : General - Page 28 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|Yes||align=center|-5.88%
|-
|align=center|2×4||29136487207403520 = c. {{val|2.9|e=16}}|| Russell&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post11874.html#p11874 |title=Su-Doku's maths : General - Page 29 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|Yes||align=center|-1.91%
|-
|align=center|2×5||1903816047972624930994913280000 = c. {{val|1.9|e=30}}|| Pettersen&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post12191.html#p12191 |title=Su-Doku's maths : General - Page 29 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|Yes||align=center|-0.375%
|-
|align=center|2×6||38296278920738107863746324732012492486187417600000 = c. {{val|3.8|e=49}}|| Pettersen&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/viewtopic.php?p=37761#p37761 |title=6x2 counting : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;||align=center|No||align=center|-0.238%
|-
|align=center|3×3||6670903752021072936960 = c. {{val|6.7|e=21}}|| Felgenhauer/Jarvis&lt;ref name=":0" /&gt;&lt;ref name="afj2" /&gt;|| align="center" |Yes||align=center|-0.207%
|-
|align=center|3×4||81171437193104932746936103027318645818654720000 = c. {{val|8.1|e=46}}|| Pettersen / Silver&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post25773.html#p25773 |title=4x3 Sudoku counting : General - Page 2 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|No||align=center|-0.132%
|-
|align=center|3×5||'''unknown''', estimated c. {{val|3.5086|e=84}}|| Silver&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post17768.html#p17768 |title=Su-Doku's maths : General - Page 38 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; || colspan="2" style="text-align:center;"|n/a
|-
|align=center|4×4||'''unknown''', estimated c. {{val|5.9584|e=98}}|| Silver&lt;ref name="ReferenceB"&gt;{{cite web|url=http://forum.enjoysudoku.com/post15909.html#p15909 |title=Su-Doku's maths : General - Page 36 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; || colspan="2" style="text-align:center;"|n/a
|-
|align=center|4×5||'''unknown''', estimated c. {{val|3.1764|e=175}}|| Silver&lt;ref name="ReferenceC"&gt;{{cite web|url=http://forum.enjoysudoku.com/post17750.html#p17750 |title=Su-Doku's maths : General - Page 38 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; || colspan="2" style="text-align:center;"|n/a
|-
|align=center|5×5||'''unknown''', estimated c. {{val|4.3648|e=308}}|| Silver / Pettersen&lt;ref name=p19318&gt;{{cite web|url=http://forum.enjoysudoku.com/post19318.html#p19318 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; || colspan="2" style="text-align:center;"|n/a
|}

===Sudoku bands===
For large (''R'',''C''), the method of Kevin Kilfoil&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post788.html#p788 |title=Su-Doku's maths : General - Page 3 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; (generalised method:&lt;ref name="forum.enjoysudoku.com"/&gt;) is used to estimate the number of grid completions. The method asserts that the Sudoku row and column constraints are, to first approximation, [[Statistical independence#Conditionally independent random variables|conditionally independent]] given the box constraint. Omitting a little algebra, this gives the Kilfoil-Silver-Pettersen formula:
:&lt;math&gt;\mbox{Number of Grids} \simeq \frac{b_{R,C}^C \times b_{C,R}^R}{(RC)!^{RC}}&lt;/math&gt;
where ''b''&lt;sub&gt;R,C&lt;/sub&gt; is the number of ways of completing a Sudoku band&lt;ref name="basicterms" /&gt; of ''R'' horizontally adjacent ''R''×''C'' boxes. Petersen's algorithm,&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post18161.html#p18161 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; as implemented by Silver,&lt;ref name=p20867&gt;{{cite web|url=http://forum.enjoysudoku.com/post20867.html#p20867 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; is currently the fastest known technique for exact evaluation of these ''b''&lt;sub&gt;R,C&lt;/sub&gt;.

The band counts '''for problems whose full Sudoku grid-count is unknown''' are listed below. As in the previous section, "Dimensions" are those of the regions.

{| class="wikitable"
! Dimensions
! Nr Bands
! Attribution
! Verified?
|-
|align=center|2×''C''||(2''C'')! (''C''!)&lt;sup&gt;2&lt;/sup&gt;||(obvious result)||align=center|Yes
|-
|align=center|3×''C''||&lt;math&gt;(3C)! (C!)^6 \sum_{k=0}^C {C \choose k}^3&lt;/math&gt;|| Pettersen&lt;ref name="ReferenceA"/&gt; ||align=center|Yes
|-
|align=center|4×''C''||(long expression: see below)|| Pettersen&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post16169.html#p16169 |title=Su-Doku's maths : General - Page 37 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|Yes&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post18396.html#p18396 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;
|-
|align=center|4×4||16! × 4!&lt;sup&gt;12&lt;/sup&gt; × 1273431960 = c. {{val|9.7304|e=38}}|| Silver&lt;ref name="ReferenceB"/&gt; ||align=center|Yes
|-
|align=center|4×5||20! × 5!&lt;sup&gt;12&lt;/sup&gt; × 879491145024 = c. {{val|1.9078|e=55}}|| Russell&lt;ref name=p16071&gt;{{cite web|url=http://forum.enjoysudoku.com/post16071.html#p16071 |title=Su-Doku's maths : General - Page 37 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|Yes
|-
|align=center|4×6||24! × 6!&lt;sup&gt;12&lt;/sup&gt; × 677542845061056 = c. {{val|8.1589|e=72}}|| Russell&lt;ref name=p16071/&gt; ||align=center|Yes
|-
|align=center|4×7||28! × 7!&lt;sup&gt;12&lt;/sup&gt; × 563690747238465024 = c. {{val|4.6169|e=91}}|| Russell&lt;ref name=p16071/&gt; ||align=center|Yes
|-
| colspan="4" style="text-align:center;"|(calculations up to 4×100 have been performed by Silver,&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post21245.html#p21245 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; but are not listed here)
|-
|align=center|5×3||15! × 3!&lt;sup&gt;20&lt;/sup&gt; × 324408987992064 = c. {{val|1.5510|e=42}}|| Silver&lt;ref name="ReferenceC"/&gt; ||align=center|Yes&lt;sup&gt;'''#'''&lt;/sup&gt;
|-
|align=center|5×4||20! × 4!&lt;sup&gt;20&lt;/sup&gt; × 518910423730214314176 = c. {{val|5.0751|e=66}}|| Silver&lt;ref name="ReferenceC"/&gt;||align=center|Yes&lt;sup&gt;'''#'''&lt;/sup&gt;
|-
|align=center|5×5||25! × 5!&lt;sup&gt;20&lt;/sup&gt; × 1165037550432885119709241344 = c. {{val|6.9280|e=93}}|| Pettersen / Silver&lt;ref name=p19318/&gt; ||align=center|No
|-
|align=center|5×6||30! × 6!&lt;sup&gt;20&lt;/sup&gt; × 3261734691836217181002772823310336 = c. {{val|1.2127|e=123}}|| Pettersen / Silver&lt;ref name=p19318/&gt; ||align=center|No
|-
|align=center|5×7||35! × 7!&lt;sup&gt;20&lt;/sup&gt; × 10664509989209199533282539525535793414144 = c. {{val|1.2325|e=154}}|| Pettersen / Silver&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post19416.html#p19416 |title=RxC Sudoku band counting algorithm : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||align=center|No
|-
|align=center|5×8||40! × 8!&lt;sup&gt;20&lt;/sup&gt; × 39119312409010825966116046645368393936122855616 = c. {{val|4.1157|e=186}}|| Pettersen / Silver&lt;ref name=p20867/&gt; ||align=center|No
|-
|align=center|5×9||45! × 9!&lt;sup&gt;20&lt;/sup&gt; × 156805448016006165940259131378329076911634037242834944 = c. {{val|2.9406|e=220}}|| Pettersen / Silver&lt;ref name=p20867/&gt; ||align=center|No
|-
|align=center|5×10||50! × 10!&lt;sup&gt;20&lt;/sup&gt; × 674431748701227492664421138490224315931126734765581948747776 = c. {{val|3.2157|e=255}}|| Pettersen / Silver&lt;ref name=p20867/&gt; ||align=center|No
|}
:&lt;sup&gt;'''#''' : same author, different method&lt;/sup&gt;

The expression for the 4×C case is:
&lt;math&gt;(4C)!(C!)^{12}\sum_{a, b, c} {\left( \frac{C!^2}{a! b! c!} \cdot \sum_{k_{12},k_{13},k_{14},\atop k_{23},k_{24},k_{34}} {{a\choose k_{12}}{b\choose k_{13}}{c \choose k_{14}}{c \choose k_{23}}{b \choose k_{24}}{a \choose k_{34}} } \right)^2 }&lt;/math&gt;

where:
: the outer summand is taken over all ''a'',''b'',''c'' such that 0&lt;=''a'',''b'',''c'' and ''a''+''b''+''c''=2''C''
: the inner summand is taken over all ''k''&lt;sub&gt;12&lt;/sub&gt;,''k''&lt;sub&gt;13&lt;/sub&gt;,''k''&lt;sub&gt;14&lt;/sub&gt;,''k''&lt;sub&gt;23&lt;/sub&gt;,''k''&lt;sub&gt;24&lt;/sub&gt;,''k''&lt;sub&gt;34&lt;/sub&gt; ≥ 0 such that
:: ''k''&lt;sub&gt;12&lt;/sub&gt;,''k''&lt;sub&gt;34&lt;/sub&gt; ≤ ''a'' &amp;nbsp;&amp;nbsp; and
:: ''k''&lt;sub&gt;13&lt;/sub&gt;,''k''&lt;sub&gt;24&lt;/sub&gt; ≤ ''b'' &amp;nbsp;&amp;nbsp; and
:: ''k''&lt;sub&gt;14&lt;/sub&gt;,''k''&lt;sub&gt;23&lt;/sub&gt; ≤ ''c'' &amp;nbsp;&amp;nbsp; and
:: ''k''&lt;sub&gt;12&lt;/sub&gt;+''k''&lt;sub&gt;13&lt;/sub&gt;+''k''&lt;sub&gt;14&lt;/sub&gt; = ''a''-''k''&lt;sub&gt;12&lt;/sub&gt;+''k''&lt;sub&gt;23&lt;/sub&gt;+''k''&lt;sub&gt;24&lt;/sub&gt; = ''b''-''k''&lt;sub&gt;13&lt;/sub&gt;+''c''-''k''&lt;sub&gt;23&lt;/sub&gt;+''k''&lt;sub&gt;34&lt;/sub&gt; = ''c''-''k''&lt;sub&gt;14&lt;/sub&gt;+''b''-''k''&lt;sub&gt;24&lt;/sub&gt;+''a''-''k''&lt;sub&gt;34&lt;/sub&gt; = ''C''

===Sudoku with additional constraints===
The following are all restrictions of 3x3 Sudokus. The type names have not been standardised: click on the attribution links to see the definitions.

{| class="wikitable"
|-
! Type
! Nr Grids
! Attribution
! Verified?
|-
|Quasi-Magic Sudoku||248832|| Jones, Perkins and Roach&lt;ref&gt;{{cite journal|url=http://www.sciencedirect.com/science/article/pii/S0012365X10003778 |title=Properties, isomorphisms and enumeration of 2-Quasi-Magic Sudoku grids  |date=2011-07-06 |accessdate=2013-10-20 |doi=10.1016/j.disc.2010.09.026 |volume=311 |journal=Discrete Mathematics |pages=1098–1110}}&lt;/ref&gt; ||Yes
|-
|3doku||104015259648|| Stertenbrink&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post11088.html#p11088 |title=Su-Doku's maths : General - Page 27 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||Yes
|-
|Disjoint Groups||201105135151764480|| Russell&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post2536.html#p2536 |title=Su-Doku's maths : General - Page 13 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;||Yes
|-
|Hypercube||37739520|| Stertenbrink&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post11216.html#p11216 |title=Su-Doku's maths : General - Page 27 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; ||Yes
|-
|Magic Sudoku||5971968||Stertenbrink&lt;ref&gt;{{cite web |url=http://www.setbb.com/phpbb/viewtopic.php?t=366&amp;mforum=sudoku |title=Sudoku Programmers :: View topic - Number of "magic sudokus" (and random generation) |publisher=Setbb.com |date= |accessdate=2013-10-20 |deadurl=yes |archiveurl=https://web.archive.org/web/20120206221359/http://www.setbb.com/phpbb/viewtopic.php?t=366&amp;mforum=sudoku |archivedate=6 February 2012 |df=dmy-all }}&lt;/ref&gt;||Yes
|-
|Sudoku X||55613393399531520|| Russell&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post3366.html#p3366 |title=Calling all sudoku experts : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;||Yes
|-
|NRC Sudoku||6337174388428800|| Brouwer&lt;ref name="homepages.cwi.nl"&gt;{{cite web|url=http://homepages.cwi.nl/~aeb/games/sudoku/nrc.html |title=NRC Sudokus |publisher=Homepages.cwi.nl |date= |accessdate=2013-10-20}}&lt;/ref&gt;||Yes
|}

A Sudoku will remain valid under the actions of the [[#Transformations|Sudoku preserving symmetries]] (see also Jarvis&lt;ref name="sudgroup" /&gt;). Some Sudokus are special in that some operations merely have the effect of relabelling the digits; several of these are listed below.

{| class="wikitable"
! Transformation
! Nr Grids
! Verified?
|-
|Transposition||10980179804160||Indirectly
|-
|Quarter Turn||4737761280||Indirectly
|-
|Half Turn||56425064693760||Indirectly
|-
|Band cycling||5384326348800||Indirectly
|-
|Within-band row cycling||39007939461120||Indirectly
|}

Further calculations of this ilk combine to show that the number of essentially different Sudoku grids is 5,472,730,538, for example as demonstrated by Jarvis / Russell&lt;ref name="sudgroup" /&gt; and verified by Pettersen.&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post13388.html#p13388 |title=Su-Doku's maths : General - Page 31 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; Similar methods have been applied to the 2x3 case, where Jarvis / Russell&lt;ref&gt;{{cite web|url=http://www.afjarvis.staff.shef.ac.uk/sudoku/sud23gp.html |title=Sudoku enumeration 2x3: the symmetry group |publisher=Afjarvis.staff.shef.ac.uk |date= |accessdate=20 October 2013}}&lt;/ref&gt; showed that there are 49 essentially different grids (see also the article by Bailey, Cameron and Connelly&lt;ref&gt;{{cite web|url=http://www.maths.qmul.ac.uk/~pjc/preprints/sudoku.pdf |title=Sudoku |publisher=Maths.qmul.ac.uk |accessdate=2013-10-20}}&lt;/ref&gt;), to the 2x4 case, where Russell&lt;ref&gt;{{cite web|url=http://www.afjarvis.staff.shef.ac.uk/sudoku/sud24gp.html |title=Sudoku enumeration 2x4: the symmetry group |publisher=Afjarvis.staff.shef.ac.uk |date= |accessdate=20 October 2013}}&lt;/ref&gt; showed that there are 1,673,187 essentially different grids (verified by Pettersen&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post29983.html#p29983 |title=Number of essentially different Sudoku grids : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;), and to the 2x5 case where Pettersen&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post32483.html#p32483 |title=Number of essentially different Sudoku grids : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; showed that there are 4,743,933,602,050,718 essentially different grids (not verified).

=={{anchor|Sudokus with Few Clues}}Minimum number of givens==
Ordinary Sudokus (''proper'' puzzles) have a unique solution. A ''minimal'' Sudoku is a Sudoku from which no clue can be removed leaving it a proper Sudoku. Different minimal Sudokus can have a different number of clues. This section discusses the minimum number of givens for proper puzzles.

===Ordinary Sudoku===
{| align="right" border="0" cellpadding="1" cellspacing="0"
 |-valign="top"
 |
[[File:Oceans_Sudoku17_Puzzle-39451_trimmed.png|thumb|180px|A Sudoku with 17 clues.]]
 |
[[File:Sudoku Puzzle (a symmetrical puzzle with 17 clues) R4.png|thumb|180px|A Sudoku with 17 clues and diagonal symmetry.&lt;ref name="symmetrical 17 clue"&gt;[https://www.flickr.com/photos/npcomplete/2599486458 "Symmetrical 17 Clue Puzzle"] Symmetrical 17 Clue Puzzle.&lt;/ref&gt;]]
 |
[[File:Sudoku (18 clue symmetrical).png|thumb|180px|A Sudoku with 18 clues and orthogonal symmetry.&lt;ref name="sym18clue"&gt;[https://www.flickr.com/photos/npcomplete/3029170798 "Raphael - 18 Clue Symmetrical"] Raphael - an 18 clue Sudoku with orthogonal symmetry.&lt;/ref&gt;]]
|}
{| align="right" border="0" cellpadding="1" cellspacing="0"
 |-valign="top"
[[File:Sudoku_Puzzle_(a_puzzle_with_total_symmetry)_trimmed.png|thumb|180px|An [[#Automorphic Sudokus|automorphic]] Sudoku with 24 clues and complete geometric symmetry.&lt;ref name="totsym"&gt;[https://www.flickr.com/photos/npcomplete/2828956005 "Total symmetry"] Total symmetry - a 24 clue Sudoku with total symmetry.&lt;/ref&gt;]]
 |
[[File:Sudoku_Puzzle_(Tourmaline)R2.png|thumb|180px|A Sudoku with 19 clues and two-way orthogonal symmetry.&lt;ref name="sym19clue"&gt;[https://www.flickr.com/photos/npcomplete/3339872043 "Tourmaline - 19 Clue Two-Way Symmetry"] Tourmaline - a 19 clue Sudoku with two-way orthogonal symmetry.&lt;/ref&gt;]]
|}
Many Sudokus have been found with 17 clues, although finding them is not a trivial task.&lt;ref&gt;{{cite web|url=http://www2.ic-net.or.jp/~takaken/auto/guest/bbs46.html |title=プログラミングパズル雑談コーナー |publisher=.ic-net.or.jp |accessdate=20 October 2013}}&lt;/ref&gt;&lt;ref name="sudokumin"&gt;{{cite web|url=http://www.csse.uwa.edu.au/~gordon/sudokumin.php |title=Minimum Sudoku |publisher=Csse.uwa.edu.au |accessdate=20 October 2013}}&lt;/ref&gt; A paper by Gary McGuire, Bastian Tugemann, and Gilles Civario, released on 1 January 2012, explains how it was proved through an exhaustive computer search that the minimum number of clues in any proper Sudoku is 17,&lt;ref&gt;{{cite news|last=Yirka|first=Bob|title=Mathematicians Use Computer to Solve Minimum Sudoku Solution Problem|url=http://www.physorg.com/news/2012-01-mathematicians-minimum-sudoku-solution-problem.html|accessdate=6 January 2012|newspaper=PhysOrg|date=6 January 2012}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=McGuire|first=Gary|title=There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues Problem|date=1 January 2012|url=http://www.math.ie/checker.html}}&lt;/ref&gt;&lt;ref&gt;G. McGuire, B. Tugemann, G. Civario. [https://arxiv.org/abs/1201.0749 "There is no 16-Clue Sudoku: Solving the Sudoku Minimum Number of Clues Problem"]. Arxiv.org.&lt;/ref&gt; and this was independently confirmed in September 2013.&lt;ref&gt;H.H. Lin, I-C. Wu. [http://sudoku.nctu.edu.tw "No 16-clue Sudoku puzzles by sudoku@vtaiwan project"] {{Webarchive|url=https://web.archive.org/web/20140214074135/http://sudoku.nctu.edu.tw/ |date=14 February 2014 }}, September, 2013.&lt;/ref&gt; A few 17-clue puzzles with diagonal symmetry were provided by Ed Russell, after a search through equivalence transformations of [[Gordon Royle]]'s database of 17-clue puzzles.&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/symmetrically-clued-17s-t3570.html |title=Symmetrically-clued 17s |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-11-30}}&lt;/ref&gt;&lt;ref name="symmetrical 17 clue"/&gt; Sudoku puzzles with 18 clues have been found with 180° rotational symmetry, and others with orthogonal symmetry, although it is not known if this number of clues is minimal in either case.&lt;ref name="sym18clue"/&gt; Sudoku puzzles with 19 clues have been found with two-way orthogonal symmetry, and again it is unknown if this number of clues is minimal for this case.&lt;ref name="sym19clue"/&gt;

A Sudoku with 24 clues, [[Dihedral group|dihedral]] symmetry (symmetry on both orthogonal axis, 90° rotational symmetry, 180° rotational symmetry, and diagonal symmetry) is known to exist, and is also [[#Automorphic Sudokus|automorphic]]. Again here, it is not known if this number of clues is minimal for this class of Sudoku.&lt;ref name="totsym"/&gt;&lt;ref&gt;
{{citation
 | last = Taalman | first = Laura | authorlink = Laura Taalman
 | issue = 1
 | journal = Math Horizons
 | jstor = 25678701
 | pages = 5–9
 | title = Taking Sudoku seriously
 | volume = 15
 | year = 2007}}. See in particular Figure&amp;nbsp;7, p.&amp;nbsp;7.&lt;/ref&gt; The fewest clues in a Sudoku with two-way diagonal symmetry is believed to be 18, and in at least one case such a Sudoku also exhibits [[#Automorphic Sudokus|automorphism]].

===Sudokus of other sizes===
* 4×4(2×2) Sudoku: The fewest clues in any 4×4 Sudoku is 4, of which there are 13 non-equivalent puzzles. (The total number of non-equivalent minimal Sudokus of this size is 36).&lt;ref&gt;[http://forum.enjoysudoku.com/my-4-year-old-is-doing-sudoku-t30643.html#p219790 http://forum.enjoysudoku.com] The New Sudoku Players' Forum.&lt;/ref&gt;
* 6×6(2×3) Sudoku: The fewest clues is 8.&lt;ref name="Minimal number of clues for Sudokus"&gt;[https://www.researchgate.net/publication/257909952_Minimal_number_of_clues_for_Sudokus] Minimal number of clues for Sudokus&lt;/ref&gt;
* 8×8(2×4) Sudoku: The fewest clues is 14.&lt;ref name="Minimal number of clues for Sudokus"&gt;&lt;/ref&gt;
* 10×10(2×5) Sudoku: At least one puzzle with 22 clues has been created.&lt;ref name="Minimum givens on larger puzzles"&gt;[http://forum.enjoysudoku.com/minimum-givens-on-larger-puzzles-t4801.html http://forum.enjoysudoku.com] Minimum givens on larger puzzles.&lt;/ref&gt; It is not known if this is the fewest possible.
* 12×12(2×6) Sudoku: At least one puzzle with 32 clues has been created.&lt;ref name="Minimum givens on larger puzzles"&gt;&lt;/ref&gt; It is not known if this is the fewest possible.
* 12×12(3×4) Sudoku: At least one puzzle with 30 clues has been created.&lt;ref name="Minimum givens on larger puzzles"&gt;&lt;/ref&gt; It is not known if this is the fewest possible.
* 15×15(3×5) Sudoku: At least one puzzle with 48 clues has been created.&lt;ref name="Minimum givens on larger puzzles"&gt;&lt;/ref&gt; It is not known if this is the fewest possible.
* 16×16(4×4) Sudoku: At least one puzzle with 55 clues has been created.&lt;ref name="Minimum givens on larger puzzles"&gt;&lt;/ref&gt; It is not known if this is the fewest possible.
* 25×25(5×5) Sudoku: A puzzle with 151 clues has been created.&lt;ref&gt;{{cite book |author=とん |date=January 2015 |script-title=ja:ヒントの少ないナンプレの作り方 |edition=2 |url=http://mikaka.org/~kana/ |language=japanese |publisher=暗黒通信団 |isbn=978-4873102238 |deadurl=yes |archiveurl=https://web.archive.org/web/20140811013935/http://mikaka.org/~kana/ |archivedate=11 August 2014 |df=dmy-all }}&lt;/ref&gt;{{citation needed|date=November 2017}} It is not known if this is the fewest possible.

===Sudoku with additional constraints===
[[Image:Oceans_SudokuDG11_Puzzle_trimmed.png|thumb|180px|Disjoint Groups: 11 clues]]
Additional constraints (here, on 3×3 Sudokus) lead to a smaller minimum number of clues.
* 3doku: ''no results for this variant''
* Disjoint Groups: some 12-clue puzzles&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post22062.html#p22062 |title=Minimum number of clues in Sudoku DG : Sudoku variants |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; have been demonstrated by Glenn Fowler. Later also 11-clue puzzles are found. It is not known if this is the best possible.
* Hypercube: various 8-clue puzzles&lt;ref&gt;{{cite web|url=http://magictour.free.fr/sudoku6 |title=100 randomized minimal sudoku-like puzzles with 6 constraints |publisher=Magictour.free.fr |accessdate=2013-10-20}}&lt;/ref&gt; (the best possible) have been demonstrated by Guenter Stertenbrink.
* Magic Sudoku: a 7-clue example&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post13320.html#p13320 |title=Number of "magic sudokus" (and random generation) : General - Page 2 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; has been provided by Guenter Stertenbrink. It is not known if this is the best possible.
* Sudoku X: a list of 7193 12-clue puzzles&lt;ref&gt;{{cite web|url=http://www.sudocue.net/minx.php |title=Minimum Sudoku-X Collection |publisher=Sudocue.net |date= |accessdate=2013-10-20}}&lt;/ref&gt; has been collected by Ruud van der Werf. It is not known if this is the best possible.
* NRC Sudoku: an 11-clue example&lt;ref name="homepages.cwi.nl"/&gt; has been provided by Andries Brouwer. It is not known if this is the best possible.
* 2-Quasi-Magic Sudoku: a 4-clue example&lt;ref&gt;{{cite web|url=http://anthony.d.forbes.googlepages.com/M215qm.pdf |title=Download Attachment |publisher=Anthony.d.forbes.googlepages.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; has been provided by Tony Forbes. It is suspected that this is the best possible.

===Sudoku with irregular regions===
"Du-sum-oh"&lt;ref&gt;{{cite web|url=http://www.bumblebeagle.org/dusumoh/9x9/index.html |title=Du-Sum-Oh Puzzles |publisher=Bumblebeagle.org |date= |accessdate=2013-10-20}}&lt;/ref&gt; (a.k.a. "geometry number place") puzzles replace the 3×3 (or ''R''×''C'') regions of Sudoku with irregular shapes of a fixed size. Bob Harris has proved&lt;ref&gt;{{cite web|url=http://www.bumblebeagle.org/dusumoh/proof/index.html |title=Du-Sum-Oh Puzzles |publisher=Bumblebeagle.org |date= |accessdate=2013-10-20}}&lt;/ref&gt; that it is always possible to create (''N''&amp;nbsp;−&amp;nbsp;1)-clue du-sum-ohs on an ''N''×''N'' grid, and has constructed several examples. Johan de Ruiter has proved&lt;ref&gt;{{cite web|url=http://www.liacs.nl/assets/Bachelorscripties/10-04-JohandeRuiter.pdf |title=Universiteit Leiden Opleiding Informatica : Internal Report 2010-4 : March 2010 |publisher=Liacs.nl |accessdate=2013-10-20}}&lt;/ref&gt; that for any ''N''&gt;3 there exist polyomino tilings that can not be turned into a Sudoku puzzle with ''N'' irregular shapes of size ''N''.

===Sum number place ("Killer Sudoku")===
In sum number place (Samunampure), the regions are of irregular shape and various sizes. The usual constraints of no repeated value in any row, column or region apply. The clues are given as sums of values within regions (e.g. a 4-cell region with sum 10 must consist of values 1,2,3,4 in some order). The minimum number of clues for Samunampure is not known, nor even conjectured. A variant on Miyuki Misawa's web site&lt;ref&gt;[http://www7a.biglobe.ne.jp/~sumnumberplace/79790008/] {{dead link|date=February 2018|bot=medic}}{{cbignore|bot=medic}}&lt;/ref&gt; replaces sums with relations: the clues are symbols '''=''', '''&lt;''' and '''&gt;''' showing the relative values of (some but not all) adjacent region sums. She demonstrates an example with only eight relations. It is not known whether this is the best possible.

==Maximum number of givens==
[[File:The_first_discovered_minimal_9x9_Sudoku_puzzle_with_40_givens.png|thumb|200px|A minimal Sudoku with 40 clues.&lt;ref name="maximum"&gt;[http://forum.enjoysudoku.com/high-clue-tamagotchis-t30020-135.html http://forum.enjoysudoku.com/high-clue-tamagotchis] High clue tamagotchis (forum: pages 1-14; 40 clue minimal: page 10).&lt;/ref&gt;]]

The most clues for a ''minimal'' Sudoku is believed to be 40, of which only two are known. If any clue is removed from either of these Sudokus, the puzzle would have more than one solution (and thus not be a proper Sudoku). In the work to find these Sudokus, other high-clue puzzles were catalogued, including more than 6,500,000,000 minimal puzzles with 36 clues. About 2600 minimal Sudokus with 39 clues were also found.&lt;ref name="maximum"/&gt;

If dropping the requirement for the uniqueness of the solution, 41-clue minimal pseudo-puzzles are known to exist, but they can be completed to more than one solution grid. Removal of any clue increases the number of the completions and from this perspective none of the 41 clues is redundant. With slightly more than half the grid filled with givens (41 of 81 cells), the ''uniqueness'' of the solution constraint still dominates over the ''minimality'' constraint.&lt;ref&gt;[http://forum.enjoysudoku.com/high-clue-tamagotchis-t30020.html http://forum.enjoysudoku.com/high-clue-tamagotchis] High clue tamagotchis (forum: page 5).&lt;/ref&gt;

As for the ''most'' clues possible in a Sudoku while still ''not'' rendering a unique solution, it is four short of a full grid (77). If two instances of two numbers each are missing and the cells they are to occupy are the corners of an orthogonal rectangle, and exactly two of these cells are within one region, there are two ways the last digits can be added (two solutions).

==Constraints of Clue Geometry==
{| style="border-spacing: 20px;
|-
|[[Image:Mask of non legal sudoku.svg|thumb|200px|none|A range of clue positions insufficient for a proper Sudoku.]]
|[[Image:Sudoku Puzzle with large rectangular hole.svg|thumb|200px|none|Sudoku with a 30 cell (5 x 6) empty rectangle. (22 clues)]]
|[[Image:Sudoku Puzzle with nine empty groups.svg|thumb|200px|none|Sudoku with nine empty groups. (22 clues)]]
|}
{{clear}}
It has been conjectured that no proper Sudoku can have clues limited to the range of positions in the pattern above (first image).&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/viewtopic.php?t=5384&amp;postdays=0&amp;postorder=asc&amp;start=0 |title=Ask for some patterns that they don't have puzzles. : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt; The largest rectangular orthogonal "hole" (region with no clues) in a proper Sudoku is believed to be a rectangle of 30 cells (a 5 x 6 rectangular area).&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/viewtopic.php?t=4209 |title=Largest 'hole' in a Sudoku; Largest 'emtpy space' : General |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.flickr.com/photos/npcomplete/2471768905/ |title=Large Empty Space &amp;#124; Flickr - Photo Sharing! |publisher=Flickr |date=2008-05-06 |accessdate=2013-10-20}}&lt;/ref&gt;{{irrelevant citation|date=April 2017|reason=Self-promotion}} One example is a Sudoku with 22 clues (second image). The largest total number of empty groups (rows, columns, and boxes) in a Sudoku is believed to be nine. One example is a Sudoku with 3 empty rows, 3 empty columns, and 3 empty boxes (third image).&lt;ref&gt;{{cite web|url=http://forum.enjoysudoku.com/post7486.html#p7486 |title=Largest number of empty groups? : General - Page 2 |publisher=Forum.enjoysudoku.com |date= |accessdate=2013-10-20}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.flickr.com/photos/npcomplete/2361922691/ |title=Clues Bunched in Clusters &amp;#124; Flickr - Photo Sharing! |publisher=Flickr |date=2008-03-25 |accessdate=2013-10-20}}&lt;/ref&gt;{{irrelevant citation|date=April 2017|reason=Self-promotion}}

=={{anchor|Automorphic Sudokus}}Automorphic Sudokus==
A Sudoku grid is automorphic if it can be transformed in a way that leads back to the original grid, when that same transformation would not otherwise lead back to the original grid.  One example of a grid which is automorphic would be a grid which can be rotated 180 degrees resulting in a new grid where the new cell values are a permutation of the original grid. Automorphic Sudokus are Sudoku puzzles which solve to an automorphic grid. Two examples of automorphic Sudokus, and an automorphic grid are shown below.
{| align="left" border="0" cellpadding="1" cellspacing="0"
|-valign="top"
|
[[File:Sudoku Puzzle (an automorphic puzzle with 18 clues).svg|thumb|200px|An automorphic Sudoku with 18 clues. (two-way diagonal symmetry).&lt;ref&gt;[https://www.flickr.com/photos/npcomplete/2691474926 "18 Clue Automorphic Sudoku"] 18 Clue Automorphic Sudoku.&lt;/ref&gt;{{irrelevant citation|date=April 2017|reason=Self-promotion}}]]
|
[[Image:Sudoku_Puzzle_(automorphic40).svg|thumb|200px|An automorphic Sudoku with 24 clues. (two-way diagonal symmetry, and translational symmetry).&lt;ref&gt;{{cite web|url=https://www.flickr.com/photos/npcomplete/2629305621/ |title=Six Dots with 5 x 5 Empty Hole &amp;#124; Flickr - Photo Sharing! |publisher=Flickr |date=2008-07-01 |accessdate=2013-10-20}}&lt;/ref&gt;{{irrelevant citation|date=April 2017|reason=Self-promotion}}]]
|
[[File:Sudoku_Most_Canonical_grid_trimmed.png|thumb|200px|The "Most Canonical" solution grid (648 automorphisms).]]
|}
{{clear}}
{| class="wikitable floatright"
|+ '''Number of essentially different grids at each&lt;br /&gt;automorphism count'''
! Automorphisms
! style="width: 80px;" | Nr Grids
! Automorphisms
! style="width: 80px;" | Nr Grids
|-
| align=right | 1 || align=right | 5472170387 || align=right | 18 || align=right | 85
|-
| align=right | 2 || align=right | 548449 || align=right | 27 || align=right | 2
|-
| align=right | 3 || align=right | 7336 || align=right | 36 || align=right | 15
|-
| align=right | 4 || align=right | 2826 || align=right | 54 || align=right | 11
|-
| align=right | 6 || align=right | 1257 || align=right | 72 || align=right | 2
|-
| align=right | 8 || align=right | 29 || align=right | 108 || align=right | 3
|-
| align=right | 9 || align=right | 42 || align=right | 162 || align=right | 1
|-
| align=right | 12 || align=right | 92 || align=right | 648 || align=right | 1
|}
In the first two examples, notice that if the Sudoku is rotated 180 degrees, and the clues relabeled with the permutation (123456789) -&gt; (987654321), it returns to the same Sudoku. Expressed another way, these Sudokus have the property that every 180 degree rotational pair of clues (a, b) follows the rule (a) + (b) = 10.

Since these Sudokus are automorphic, so too their solutions grids are automorphic.  Furthermore, every cell which is solved has a symmetrical partner which is solved with the same technique (and the pair would take the form a + b = 10). Notice that in the second example, the Sudouku also exhibits [[Translational symmetry|translational]] (or repetition) symmetry; clues are clustered in groups, with the clues in each group ordered sequentially (i.e., n, n+1, n+2, and n+3).

The third image is the ''Most Canonical'' solution grid.&lt;ref&gt;[http://sudopedia.enjoysudoku.com/Canonical_Form.html http://sudopedia.enjoysudoku.com/Canonical_Form] "Canonical Form".&lt;/ref&gt; This grid has 648 automorphisms and contributes to all ~{{val|6.67|e=21}} solution grids by factor of 1/648 compared to any non-automorphic grid.

In these examples the automorphisms are easy to identify, but in general automorphism is not always obvious. The table at right shows the number of the essentially different Sudoku solution grids for all existing automorphisms.&lt;ref&gt;{{cite web|last1=Fowler|first1=Glenn|title=Number of automorphisms for any grid|url=http://forum.enjoysudoku.com/post41438.html#p41438|website=The New Sudoku Players' Forum|accessdate=29 April 2017|date=2007-02-15}}&lt;/ref&gt;

==Details of enumerating distinct grids (9×9)==
An enumeration technique based on ''band generation'' was developed that is significantly less computationally intensive. The strategy begins by analyzing the [[combinations and permutations|permutations]] of the top band used in valid solutions. Once the Band1 [[symmetry in mathematics|symmetries]] and [[equivalence class]] for the partial solutions are identified, the completions of the lower two bands are constructed and counted for each equivalence class.

===Counting the top band permutations===
{| class="wikitable floatright"
|-
| style="width: 20px;" | 1 
| style="width: 20px;" | 2 
| style="width: 20px;" | 3
|-
| 4
| 5
| 6
|-
| 7
| 8
| 9
|}
The Band1 algorithm proceeds as follows:
* Choose a canonical labeling of the digits by assigning values for B1 (see grid), and compute the rest of the Band1 permutations relative B1.
* Compute the permutations of B2 by [[Partition of a set|partitioning]] the B1 cell values over the B2 row [[#Definition of terms and labels|triplets]]. From the triplet combinations compute the B2 permutations. There are k=0..3 ways to choose the:
:B1 r11 values for B2 r22, the rest must go to r16,
:B1 r12 values for B2 r23, the rest must go to r16,
:B1 r13 values for B2 r21, the rest must go to r16, i.e.
::&lt;math&gt; \mbox{N combinations for B2} = \sum_{k=0..3}{{3 \choose k}^3}&lt;/math&gt;
(This expression may be generalized to any ''R''×3 box band variant. (Pettersen&lt;ref name="ReferenceA"/&gt;). Thus B2 contributes 56 × 6&lt;sup&gt;3&lt;/sup&gt; permutations.
* The choices for B3 triplets are row-wise determined by the B1 B2 row triplets. B3 always contributes 6&lt;sup&gt;3&lt;/sup&gt; permutations.
The permutations for Band1 are 9!&amp;nbsp;×&amp;nbsp;56&amp;nbsp;×&amp;nbsp;6&lt;sup&gt;6 &lt;/sup&gt; = 9!&amp;nbsp;×&amp;nbsp;2612736 ~ {{val|9.48|e=11}}.

====Band1 permutation details====
{{Sudoku 3x9 band|b1c=white|b2c=d8f0ff
|title=Triplet rBR(box/row) Labels|align=right
|s1=r |s2=1 |s3=1 |s4=r |s5=2 |s6=1 |s7=r |s8=3 |s9=1
|s10=r|s11=1|s12=2|s13=r|s14=2|s15=2|s16=r|s17=3|s18=2
|s19=r|s20=1|s21=3|s22=r|s23=2|s24=3|s25=r|s26=3|s27=3
}}
The permutations of B1 are the number of ways to relabel the 9 digits, 9! = 362880. Counting the permutations for B2 is more complicated, because the choices for B2 depend on the values in B1. (This is a visual representation of the expression given above.) The conditional calculation needs a branch (sub-calculation) for each alternative. Fortunately, there are just 4 cases for the top B2 triplet (r21): it contains either 0, 1, 2, or 3 of the digits from the B1 middle row triplet(r12). Once this B2 top row choice is made, the rest of the B2 combinations are fixed. The Band1 row triplet labels are shown on the right.

(Note: Conditional combinations becomes an increasingly difficult as the computation progresses through the grid. At this point the impact is minimal.)
{{Sudoku 3x9 band|b1c=white
|title=Case 0 Matching Cells Triplets|align=right
|s1=1 |s2=2 |s3=3 |s4=7 |s5=8 |s6=9 |s7=4 |s8=5 |s9=6
|s10=4|s11=5|s12=6|s13=1|s14=2|s15=3|s16=7|s17=8|s18=9
|s19=7|s20=8|s21=9|s22=4|s23=5|s24=6|s25=1|s26=2|s27=3
|b2c=pink|b3c=pink
}}
Case 0: No Overlap. The choices for the triplets can be determined by elimination.
; r21 can't be r11 or r12 so it must be = r13; r31 must be = r12 etc.

The Case 0 diagram shows this configuration, where the pink cells are triplet values that can be arranged in any order within the triplet.
Each triplet has 3! = 6 permutations. The 6 triplets contribute 6&lt;sup&gt;6&lt;/sup&gt; permutations.

Case 3: 3 Digits Match: triplet r21 = r12. The same logic as case 0 applies, but with a different triplet usage.
Triplet r22 must be = r13, etc.
The number of permutations is again 6&lt;sup&gt;6&lt;/sup&gt; (Felgenhauer/Jarvis).&lt;ref name="afjarvis" /&gt; Call the cases 0 and 3 the ''pure match'' case.
{{Sudoku 3x9 band|b1c=white|b2c=d8f0ff|align=right
|title=Case 1 Match — Triplet Cell Options
|s1=1 |s2=2 |s3=3 |s4=3 |s5=3 |s6=2 |s7=3 |s8=2 |s9=1
|s10=4|s11=5|s12=6|s13=1|s14=3|s15=2|s16=3|s17=2|s18=1
|s19=7|s20=8|s21=9|s22=1|s23=2|s24=1|s25=3|s26=2|s27=1
|c1=yellow|c2=yellow|c3=yellow|c10=pink|c11=pink|c12=pink
|c19=lime|c20=lime|c21=lime
|c4=pink|c5=lime|c6=lime
|c13=lime|c14=yellow|c15=yellow
|c22=yellow|c23=pink|c24=pink
}}
Case 1: 1 Match for r21 from r12

In the Case 1 diagram, B1 cells show canonical values, which are color-coded to show their row-wise distribution in B2 triplets. Colors reflect distribution but not location or values. For this case: the B2 top row triplet (r21) has 1 value from B1 middle triplet, the other colorings can now be deduced. E.g. the B2 bottom row triplet (r23) coloring is forced by r21: the other 2 B1 middle values must go to bottom, etc. Fill in the number of B2 options for each color, 3..1, beginning top left. The B3 color-coding is omitted since the B3 choices are row-wise determined by B1, B2. B3 always contributes 3! permutations per row triplet, or 6&lt;sup&gt;3&lt;/sup&gt; for the block.

For B2, the triplet values can appear in any position, so a 3! permutation factor still applies, for each triplet. However,
since some of the values were paired relative to their origin, using the raw option counts would overcount the number of permutations, due to interchangeability within the pairing. The option counts need to be divided by the permuted size of their grouping (2), here 2!.= 2 (See [[Combinations|n Choose k]]) The pair in each row cancels the 2s for the B2 option counts, leaving a B2 contribution of 3&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;×&amp;nbsp;6&lt;sup&gt;3&lt;/sup&gt;. The B2×B3 combined contribution is 3&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;×&amp;nbsp;6&lt;sup&gt;6&lt;/sup&gt;.
{{Sudoku 3x9 band|b1c=white|b2c=d8f0ff|align=right
|title=Case 2 Match — Triplet Cell Options
|s1=1 |s2=2 |s3=3 |s4=3 |s5=2 |s6=3 |s7=3 |s8=2 |s9=1
|s10=4|s11=5|s12=6|s13=2|s14=1|s15=3|s16=3|s17=2|s18=1
|s19=7|s20=8|s21=9|s22=2|s23=1|s24=1|s25=3|s26=2|s27=1
|c1=yellow|c2=yellow|c3=yellow
|c10=pink|c11=pink|c12=pink
|c19=lime|c20=lime|c21=lime
|c4=pink|c5=pink|c6=lime
|c13=lime|c14=lime|c15=yellow
|c22=yellow|c23=yellow|c24=pink
}}
Case 2: 2 Matches for r21 from r12. The same logic as case 1 applies, but with the B2 option count column groupings reversed. Case 3 also contributes 3&lt;sup&gt;3&lt;/sup&gt;×6&lt;sup&gt;6&lt;/sup&gt; permutations.

Totaling the 4 cases for Band1 B1..B3 gives
9!&amp;nbsp;×&amp;nbsp;2&amp;nbsp;×&amp;nbsp;(3&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;×&amp;nbsp;6&lt;sup&gt;6 &lt;/sup&gt; = 9!&amp;nbsp;56&amp;nbsp;×&amp;nbsp;6&lt;sup&gt;6&lt;/sup&gt; permutations.

===Band1 symmetries and equivalence classes===
''Symmetries'' are used to reduce the computational effort to enumerate the Band1 permutations. A [[symmetry in mathematics|symmetry]] is an operation that preserves a quality of an object. For a Sudoku grid, a symmetry is a transformation whose result is also a valid grid. The following symmetries apply independently for the top band:
* Block B1 values may be relabeled, giving 9! permutations
* Blocks B1..3 may be interchanged, with 3!=6 permutations
* Rows 1..3 may be interchanged, with 3!=6 permutations
* Within each block, the 3 columns may be interchanged, giving 3!&lt;sup&gt;3&lt;/sup&gt; = 6&lt;sup&gt;3&lt;/sup&gt; permutations.
Combined, the symmetries give 9! × 6&lt;sup&gt;5&lt;/sup&gt; = 362880 × 7776 equivalent permutations for each Band1 solution.

A symmetry defines an [[equivalence relation]], here, between the solutions, and [[Partition of a set|partitions]] the solutions into a set of [[equivalence class]]es. The Band1 row, column and block symmetries divide the 56*6^6 permutations into (not less than) 336 (56×6) equivalence classes with (up to) 6&lt;sup&gt;5&lt;/sup&gt; permutations in each, and 9! relabeling permutations for each class. (''Min/Max'' caveats apply since some permutations may not yield distinct elements due to relabeling.)

Since the solution for any member of an equivalence class can be generated from the solution of any other member, we only need to enumerate the solutions for a single member in order to enumerate all solutions over all classes. Let
* sb : be a valid permutation of the top band
* Sb = [sb] : be an equivalence class, relative to sb and some [[equivalence relation]]
* Sb.z = |Sb| : the size of Sb, be the number of sb elements (permutations) in [sb]
* Sb.n : be the number of Band2,3 completions for (any) sb in Sb
* {Sb} : be the set of all Sb equivalence classes relative to the [[equivalence relation]]
* {Sb}.z = |{Sb}| : be the number of equivalence classes

The total number of solutions ''N'' is then:
:&lt;math&gt;N = \sum_{\{Sb\}} \mbox{Sb.z} \times \mbox{Sb.n}&lt;/math&gt;
====Solution and counting permutation symmetry====
The Band1 symmetries (above) are ''solution permutation symmetries'' defined so that a permuted solution is also a solution. For the purpose of enumerating solutions, a ''counting symmetry'' for grid completion can be used to define band equivalence classes that yield a minimal number of classes.

''Counting symmetry'' partitions valid Band1 permutations into classes that place the same completion constraints on lower bands; all members of a band ''counting symmetry'' equivalence class must have the same number of grid completions since the completion constraints are equivalent. Counting symmetry constraints are identified by the Band1 column triplets (a column value set, no implied element order). Using band counting symmetry, a minimal generating set of 44 equivalence classes&lt;ref name="ed44"&gt;{{cite web|url=http://www.afjarvis.staff.shef.ac.uk/sudoku/ed44.html |title=Summary of method and results |publisher=Afjarvis.staff.shef.ac.uk |accessdate=20 October 2013}}&lt;/ref&gt; was established.
{| align="right" border="0" cellpadding="1" cellspacing="0"
 |-valign="top"
 |
{{Sudoku 3x9 band|b1c=white|b2c=d8f0ff|align=right
|title=(1) Band1 Example
|s1=1 |s2=2 |s3=3 |s4=5 |s5=8 |s6=6 |s7=7 |s8=4 |s9=9
|s10=4|s11=5|s12=6|s13=9|s14=1|s15=7|s16=8|s17=2|s18=3
|s19=7|s20=8|s21=9|s22=4|s23=3|s24=2|s25=5|s26=1|s27=6
}}
 |
{{Sudoku 3x9 band|b1c=white|b2c=d8f0ff|align=right
|title=(2) Column Triplets
|s1=1 |s2=2 |s3=3 |s4=4 |s5=1 |s6=2 |s7=5 |s8=1 |s9=3
|s10=4|s11=5|s12=6|s13=5|s14=3|s15=6|s16=7|s17=2|s18=6
|s19=7|s20=8|s21=9|s22=9|s23=8|s24=7|s25=8|s26=4|s27=9
|c5=pink|c14=pink|c23=pink
|c8=pink|c17=pink|c26=pink
}}
 |
{{Sudoku 3x9 band|b1c=white|b3c=d8f0ff|align=right
|title=(3) Ordered Col. Triplets
|s1=1 |s2=2 |s3=3 |s4=1 |s5=3 |s6=5 |s7=1 |s8=2 |s9=4
|s10=4|s11=5|s12=6|s13=2|s14=6|s15=7|s16=3|s17=6|s18=5
|s19=7|s20=8|s21=9|s22=4|s23=9|s24=8|s25=8|s26=7|s27=9
|c4=pink|c13=pink|c22=pink
|c7=pink|c16=pink|c25=pink
}}
|}
The following sequence demonstrates mapping a band configuration to a counting symmetry equivalence class. Begin with a valid band configuration (1). Build column triplets by ordering the column values within each column. This is not a valid Sudoku band, but does place the same constraints on the lower bands as the example (2). Construct an equivalence class ID from the B2, B3 column triplet values. Use column and box swaps to achieve the lowest lexicographical ID. The last figure shows the column and box ordering for the ID: 124 369 578 138 267 459. All Band1 permutations with this counting symmetry ID will have the same number of grid completions as the original example. An extension of this process can be used to build the largest possible ''band counting symmetry'' equivalence classes (3).

Note, while column triplets are used to construct and identify the equivalence classes, the class members themselves are the valid Band1 permutations: class size (Sb.z) reflects column triplet permutations compatible with the ''One Rule'' solution requirements. ''Counting symmetry'' is a completion property and applies only to a partial grid (band or stack). ''Solution symmetry'' for preserving solutions can be applied to either partial grids (bands, stacks) or full grid solutions. Lastly note, ''counting symmetry'' is more restrictive than simple numeric completion count equality: two (distinct) bands belong to the same ''counting symmetry'' equivalence class only if they impose equivalent completion constraints.

====Band 1 reduction details====
Symmetries group similar object into [[equivalence class]]es. Two numbers need to be distinguished for equivalence classes, and band symmetries as used here, a third:
* the number of equivalence classes ({Sb}.n).
* the [[cardinality]], size or number of elements in an equivalence class, which may vary by class (Sb.z)
* the number of Band2,3 completions compatible with a member of a Band1 equivalence class (Sb.n)

The Band1 (6&lt;sup&gt;5&lt;/sup&gt;) symmetries divide the (56×6&lt;sup&gt;6&lt;/sup&gt;) Band1 valid permutations into (not less than) 336 (56×6) equivalence classes with (up to) 6^5 permutations each.
The ''not less than'' and ''up to'' caveats are necessary, since some combinations of the transformations may not produce distinct results, when relabeling is required (see below). Consequently, some equivalence classes may contain less than 6&lt;sup&gt;5&lt;/sup&gt; distinct permutations and the theoretical minimum number of classes may not be achieved.

Each of the valid Band1 permutations can be expanded (completed) into a specific number of solutions with the Band2,3 permutations. By virtue of their similarity, each member of an equivalence class will have the same number of completions. Consequently, we only need to construct the solutions for one member of each equivalence class and then multiply the number of solutions by the size of the equivalence class. We are still left with the task of identifying and calculating the size of each equivalence class. Further progress requires the dexterous application of computational techniques to catalogue (classify and count) the permutations into equivalence classes.

Felgenhauer/Jarvis&lt;ref name="afjarvis" /&gt; catalogued the Band1 permutations using [[lexicographical order]]ed IDs based on the ordered digits from blocks B2,3. Block 1 uses a canonical digit assignment and is not needed for a unique ID. Equivalence class identification and linkage uses the lowest ID within the class.

Application of the (2×6&lt;sup&gt;2&lt;/sup&gt;) B2,3 symmetry permutations produces 36288 (28×6&lt;sup&gt;4&lt;/sup&gt;) equivalence classes, each of size 72. Since the size is fixed, the computation only needs to find the 36288 equivalence class IDs. (Note: in this case,
for any Band1 permutation, applying these permutations to achieve the lowest ID provides an index to the associated equivalence class.)

Application of the rest of the block, column and row symmetries provided further reduction, i.e. allocation of the 36288 IDs into fewer, larger equivalence classes.
When the B1 canonical labeling is lost through a transformation, the result is relabeled to the canonical B1 usage and then catalogued under this ID. This approach generated 416 equivalence classes, somewhat less effective than the theoretical 336 minimum limit for a full reduction. Application of ''counting symmetry'' patterns for ''duplicate paired'' digits achieved reduction to 174 and then to 71 equivalence classes. The introduction of equivalence classes based on ''band counting symmetry'' (subsequent to Felgenhauer/Jarvis by Russell&lt;ref name="ed44" /&gt;) reduced the equivalence classes to a minimum generating set of 44.

The diversity of the ~{{val|2.6|e=6}}, 56×6&lt;sup&gt;6&lt;/sup&gt; Band1 permutations can be reduced to a set of 44 Band1 equivalence classes. Each of the 44 equivalence classes can be expanded to millions of distinct full solutions, but the entire solution space has a common origin in these 44. The 44 equivalence classes play a central role in other enumeration approaches as well, and speculation will return to the characteristics of the 44 classes when puzzle properties are explored later.

===Band 2-3 completion and results===
Enumerating the Sudoku solutions breaks into an initial setup stage and then into two nested loops. Initially all the valid Band1 permutations are grouped into equivalence classes, who each impose a common constraint on the Band2,3 completions.
For each of the Band1 equivalence classes, all possible Band2,3 solutions need to be enumerated. An outer Band1 loop iterates over the 44 equivalence classes. In the inner loop, all lower band completions for each of the Band1 equivalence class are found and counted.

The computation required for the lower band solution search can be minimised by the same type of symmetry application used for Band1. There are 6! (720) permutations for the 6 values in column 1 of Band2,3. Applying the lower band (2) and row within band (6×6) permutations creates 10 equivalence classes of size 72. At this point, completing 10 sets of solutions for the remaining 48 cells with a recursive descent, [[backtracking]] algorithm is feasible with 2&amp;nbsp;GHz class PC so further simplification is not required to carry out the enumeration. Using this approach, the number of ways of filling in a blank Sudoku grid has been shown to be 6,670,903,752,021,072,936,960 ({{val|6.67|e=21}}).&lt;ref name="afjarvis"/&gt;

The result, as confirmed by Russell,&lt;ref name="ed44" /&gt; also contains the distribution of solution counts for the 44 equivalence classes. The listed values are before application of the 9! factor for labeling and the two 72 factors (72&lt;sup&gt;2&lt;/sup&gt; = 5184) for each of Stack 2,3 and Band2,3 permutations. The number of completions for each class is consistently on the order of 100,000,000, while the number of Band1 permutations covered by each class however varies from 4 – 3240. Within this wide size range, there are clearly two clusters. Ranked by size, the lower 33 classes average ~400 permutations/class, while the upper 11 average ~2100. The disparity in consistency between the distributions for size and number of completions or the separation into two clusters by size is yet to be examined.

==Variants==
Sudoku regions are [[polyominoes]].  Although the classic 9×9 Sudoku is made of square [[nonominoes]], it is possible to apply the rules of Sudoku to puzzles of other sizes – the 2×2 and 4×4 square puzzles, for example.  Only ''N''&lt;sup&gt;2&lt;/sup&gt;×''N''&lt;sup&gt;2&lt;/sup&gt; Sudoku puzzles can be tiled with square polyominoes. Another popular variant is made of rectangular regions – for example, 2×3 [[hexominoes]] tiled in a 6×6 grid.  The following notation is used for discussing this variant.
* ''R''×''C'' denotes a rectangular region with ''R'' rows and ''C'' columns.
* The implied grid configuration has:
** ''C'' blocks per band,
**  ''R'' blocks per stack,
**  ''C''×''R'' bands×stacks,
** an arrangement of ''C''×''R'' regions, and
** grid dimensions ''N''×''N'', where ''N'' = ''R''×''C''.

Puzzles of size ''N''×''N'', where ''N'' is prime can only be tiled with irregular ''N''-ominoes.  Each ''N''×''N'' grid can be tiled multiple ways with ''N''-ominoes.  Before enumerating the number of solutions to a Sudoku grid of size ''N''x''N'', it is necessary to determine how many ''N''-omino tilings exist for a given size (including the standard square tilings, as well as the rectangular tilings).

The size ordering of Sudoku puzzle can be used to define an integer series, e.g. for square Sudoku, the integer series of possible solutions {{OEIS|id=A107739}}. Sudoku with square ''N''×''N'' regions are more symmetrical than immediately obvious from the ''One Rule''. Each row and column intersects ''N'' regions and shares ''N'' cells with each. The number of bands and stacks also equals ''N''. Rectangular Sudoku do not have these properties. The "3×3" Sudoku is additionally unique: ''N'' is also the number of row-column-region constraints from the ''One Rule'' (i.e. there are ''N''=3 types of ''units''). See the [[Glossary of Sudoku]] for an expanded list of variants.

==See also==
* [[Sudoku]] — main article
* [[Sudoku solving algorithms]]
* [[Glossary of Sudoku]]
* [[Combinatorial explosion]] (with summary of grid count of Sudoku compared to Latin squares)
* [[Sudokian|Sudoku variants]]
* [[Dancing Links]]
* [[Sudoku Codes]]

==References==
{{Reflist|30em}}

==External links==
* [http://plus.maths.org/latestnews/jan-apr06/sudoku/index.html V. Elser's difference-map algorithm also solves Sudoku]
* [http://www.visual-prolog.com/vip/example/pdcExample/sudoku.htm Sudoku Puzzle — an Exercise in Constraint Programming and Visual Prolog 7] by Carsten Kehler Holst (in [[Visual Prolog]])
* [http://www.ams.org/notices/200706/tx070600708p.pdf Sudoku Squares and Chromatic Polynomials] by [[Agnes M. Herzberg|Herzberg]] and Murty, treats Sudoku puzzles as [[graph coloring|vertex coloring]] problems in [[graph theory]].

{{Use dmy dates|date=September 2010}}

{{DEFAULTSORT:Mathematics Of Sudoku}}
[[Category:Sudoku]]
[[Category:Latin squares]]
[[Category:Puzzles]]
[[Category:Game theory]]
[[Category:Logic puzzles]]
[[Category:Abstract strategy games]]
[[Category:Recreational mathematics]]</text>
      <sha1>p750tmtfmrjuycr4wkute66l8hegcfo</sha1>
    </revision>
  </page>
  <page>
    <title>Mereology</title>
    <ns>0</ns>
    <id>375380</id>
    <revision>
      <id>869798161</id>
      <parentid>864649777</parentid>
      <timestamp>2018-11-20T12:47:36Z</timestamp>
      <contributor>
        <username>Wikieditor 247</username>
        <id>32159644</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47159">In [[philosophy]] and [[mathematical logic]], '''mereology''' (from the [[Ancient Greek|Greek]] μέρος ''meros'' (root: μερε- ''mere-'', "part" [but in Greek: ''μερολογία'']) and the suffix -logy "study, discussion, science") is the study of parts and the wholes they form.  Whereas [[set theory]] is founded on the membership relation between a set and its elements, mereology emphasizes the [[Meronomy|meronomic]] relation between entities, which—from a set-theoretic perspective—is closer to the concept of [[Inclusion (set theory)|inclusion]] between [[set (mathematics)|sets]].

Mereology has been explored in various ways as applications of [[predicate logic]] to [[formal ontology]], in each of which mereology is an important part. Each of these fields provides its own axiomatic definition of mereology. A common element of such axiomatizations is the assumption, shared with inclusion, that the part-whole relation [[partial order|orders]] its universe, meaning that everything is a part of itself ([[reflexive relation|reflexivity]]), that a part of a part of a whole is itself a part of that whole ([[transitive relation|transitivity]]), and that two distinct entities cannot each be a part of the other ([[antisymmetric relation|antisymmetry]]), thus forming a [[poset]].  A variant of this axiomatization denies that anything is ever part of itself (irreflexivity) while accepting transitivity, from which antisymmetry follows automatically.

Although mereology is an application of [[mathematical logic]], what could be argued to be a sort of "proto-geometry", it has been wholly developed by logicians, [[ontology|ontologists]], linguists, engineers, and computer scientists, especially those working in [[artificial intelligence]]. In particular, mereology is also on the basis for a [[Whitehead's point-free geometry|point-free]] foundation of geometry (see for example the quoted pioniering paper of Alfred Tarski and the review paper by Gerla 1995).

"Mereology" can also refer to formal work in [[general systems theory]] on system decomposition and parts, wholes and boundaries (by, e.g., [[Mihajlo D. Mesarovic]] (1970), [[Gabriel Kron]] (1963), or Maurice Jessel (see Bowden (1989, 1998)). A hierarchical version of [[Gabriel Kron]]'s Network Tearing was published by Keith Bowden (1991), reflecting David Lewis's ideas on [[Gunk (mereology)|gunk]]. Such ideas appear in theoretical [[computer science]] and [[theoretical physics|physics]], often in combination with [[sheaf theory]], [[topos]], or [[category theory]]. See also the work of [[Steve Vickers (computer scientist)|Steve Vickers]] on (parts of) specifications in computer science, [[Joseph Goguen]] on physical systems, and Tom Etter (1996, 1998) on link theory and [[quantum mechanics]].

==History==
Informal part-whole reasoning was consciously invoked in [[metaphysics]] and [[ontology]] from [[Plato]] (in particular, in the second half of the ''[[Parmenides (dialogue)|Parmenides]]'') and [[Aristotle]] onwards, and more or less unwittingly in 19th-century mathematics until the triumph of [[set theory]] around 1910. [[Ivor Grattan-Guinness]] (2001) sheds much light on part-whole reasoning during the 19th and early 20th centuries, and reviews how [[Georg Cantor|Cantor]] and [[Peano]] devised [[set theory]]. In seventh century India, parts and wholes were studied extensively by Dharmakirti (see &lt;ref&gt;Dunne, John D., 2004. ''Foundations of Dharmakirti's Philosophy''. Wisdom Publications.&lt;/ref&gt;{{nonspecific|date=July 2017}}). In Europe, however, it appears that the first to reason consciously and at length about parts and wholes{{citation needed|date=July 2017}} was [[Edmund Husserl]], in 1901, in the second volume of ''Logical Investigations'' – Third Investigation: "On the Theory of Wholes and Parts" (Husserl 1970 is the English translation). However, the word "mereology" is absent from his writings, and he employed no symbolism even though his doctorate was in mathematics.

[[Stanisław Leśniewski]] coined "mereology" in 1927, from the Greek word μέρος (''méros'', "part"), to refer to a formal theory of part-whole he devised in a series of highly technical papers published between 1916 and 1931, and translated in Leśniewski (1992). Leśniewski's student [[Alfred Tarski]], in his Appendix E to Woodger (1937) and the paper translated as Tarski (1984), greatly simplified Leśniewski's formalism. Other students (and students of students) of Lesniewski elaborated this "Polish mereology" over the course of the 20th century. For a good selection of the literature on Polish mereology, see Srzednicki and Rickey (1984). For a survey of Polish mereology, see Simons (1987). Since 1980 or so, however, research on Polish mereology has been almost entirely historical in nature.

[[A. N. Whitehead]] planned a fourth volume of ''[[Principia Mathematica]]'', on [[geometry]], but never wrote it. His 1914 correspondence with [[Bertrand Russell]] reveals that his intended approach to geometry can be seen, with the benefit of hindsight, as mereological in essence. This work culminated in Whitehead (1916) and the mereological systems of Whitehead (1919, 1920).

In 1930, Henry Leonard completed a Harvard Ph.D. dissertation in philosophy, setting out a formal theory of the part-whole relation. This evolved into the "calculus of individuals" of Goodman and Leonard (1940). Goodman revised and elaborated this calculus in the three editions of Goodman (1951). The calculus of individuals is the starting point for the post-1970 revival of mereology among logicians, ontologists, and computer scientists, a revival well-surveyed in Simons (1987) and Casati and Varzi (1999).

==Axioms and primitive notions==

Reflexivity: A basic choice in defining a mereological system, is whether to consider things to be parts of themselves. In [[naive set theory]] a similar question arises: whether a set is to be considered a "subset" of itself. In both cases, "yes" gives rise to paradoxes analogous to [[Russell's paradox]]: Let there be an object '''O''' such that every object that is not a proper part of itself is a proper part of '''O'''. Is '''O''' a proper part of itself? No, because no object is a proper part of itself; and yes, because it meets the specified requirement for inclusion as a proper part of '''O'''. In set theory, a set is often termed an ''improper'' subset of itself. Given such paradoxes, mereology requires an [[axioms|axiomatic]] formulation.

A mereological "system" is a [[first-order logic|first-order theory]] (with [[identity (philosophy)|identity]]) whose [[universe of discourse]] consists of wholes and their respective parts, collectively called ''objects''. Mereology is a collection of nested and non-nested [[axiomatic system]]s, not unlike the case with [[modal logic]].

The treatment, terminology, and hierarchical organization below follow Casati and Varzi (1999: Ch. 3) closely. For a more recent treatment, correcting certain misconceptions, see Hovda (2008). Lower-case letters denote variables ranging over objects. Following each symbolic axiom or definition is the number of the corresponding formula in Casati and Varzi, written in bold.

A mereological system requires at least one primitive [[binary relation]] ([[Arity|dyadic]] [[Predicate (logic)|predicate]]). The most conventional choice for such a relation is '''parthood''' (also called "inclusion"), "''x'' is a ''part'' of ''y''", written ''Pxy''. Nearly all systems require that parthood [[partial order|partially order]] the universe. The following defined relations, required for the axioms below, follow immediately from parthood alone:
*An immediate defined [[Predicate (logic)|predicate]] is "x is a '''proper part''' of ''y''", written ''PPxy'', which holds (i.e., is satisfied, comes out true) if ''Pxy'' is true and ''Pyx'' is false. Compared to parthood (which is a [[partial order]]), ProperPart is a [[strict partial order]].
:&lt;math&gt;PPxy \leftrightarrow (Pxy \land  \lnot Pyx).&lt;/math&gt; '''3.3'''
:An object lacking proper parts is an ''atom''. The mereological [[universe of discourse|universe]] consists of all objects we wish to think about, and all of their proper parts:
*'''Overlap''': ''x'' and ''y'' overlap, written ''Oxy'', if there exists an object ''z'' such that ''Pzx'' and ''Pzy'' both hold.
:&lt;math&gt;Oxy \leftrightarrow \exists z[Pzx \land Pzy ].&lt;/math&gt; '''3.1'''
:The parts of ''z'', the "overlap" or "product" of ''x'' and ''y'', are precisely those objects that are parts of both ''x'' and ''y''.
*'''Underlap''': ''x'' and ''y'' underlap, written ''Uxy'', if there exists an object ''z'' such that ''x'' and ''y'' are both parts of ''z''.
:&lt;math&gt;Uxy \leftrightarrow \exists z[Pxz \land Pyz ].&lt;/math&gt; '''3.2'''
Overlap and Underlap are [[reflexive relation|reflexive]], [[symmetric]], and [[Transitive relation|intransitive]].

Systems vary in what relations they take as primitive and as defined. For example, in extensional mereologies (defined below), ''parthood'' can be defined from Overlap as follows:
:&lt;math&gt;Pxy \leftrightarrow \forall z[Ozx \rightarrow Ozy].&lt;/math&gt; '''3.31'''

The axioms are:
*'''Parthood''' [[Partial order|partially orders]] the [[universe]]:
:M1, '''[[Reflexive relation|Reflexive]]''': An object is a part of itself.
:&lt;math&gt;\ Pxx.&lt;/math&gt; '''P.1'''
:M2, '''[[Antisymmetric relation|Antisymmetric]]''': If ''Pxy'' and ''Pyx'' both hold, then ''x'' and ''y'' are the same object.
:&lt;math&gt;(Pxy \land  Pyx) \rightarrow x = y.&lt;/math&gt; '''P.2'''
:M3, '''[[Transitive relation|Transitive]]''': If ''Pxy'' and ''Pyz'', then ''Pxz''.
:&lt;math&gt;(Pxy \land Pyz) \rightarrow Pxz.&lt;/math&gt; '''P.3'''
*M4, '''Weak Supplementation''': If ''PPxy'' holds, there exists a ''z'' such that ''Pzy'' holds but ''Ozx'' does not.
:&lt;math&gt;PPxy \rightarrow \exists z[Pzy \land \lnot Ozx].&lt;/math&gt; '''P.4''' &lt;ref&gt;Weak supplementation is a theorem in [[Finitist set theory]].&lt;/ref&gt;

*M5, '''Strong Supplementation''': If ''Pyx'' does not hold, there exists a ''z'' such that ''Pzy'' holds but ''Ozx'' does not.
:&lt;math&gt;\lnot Pyx \rightarrow \exists z[Pzy \land \lnot Ozx].&lt;/math&gt; '''P.5'''

*M5', '''Atomistic Supplementation''': If ''Pxy'' does not hold, then there exists an atom ''z'' such that ''Pzx'' holds but ''Ozy'' does not.
:&lt;math&gt;\lnot Pxy \rightarrow \exists z[Pzx \land \lnot Ozy \land \lnot \exists v [PPvz]].&lt;/math&gt; '''P.5' '''

*'''Top''': There exists a "universal object", designated ''W'', such that ''PxW'' holds for any ''x''.
:&lt;math&gt;\exists W \forall x [PxW].&lt;/math&gt; '''3.20'''
:Top is a theorem if M8 holds.

*'''Bottom''': There exists an atomic "null object", designated ''N'', such that ''PNx'' holds for any ''x''.
:&lt;math&gt;\exists N \forall x [PNx].&lt;/math&gt; '''3.22'''

*M6, '''Sum''': If ''Uxy'' holds, there exists a ''z'', called the "sum" or "fusion" of ''x'' and ''y'', such that the objects overlapping of ''z'' are just those objects that overlap '''either''' ''x'' or ''y''.
:&lt;math&gt;Uxy \rightarrow \exists z \forall v [Ovz \leftrightarrow (Ovx \lor Ovy)].&lt;/math&gt; '''P.6'''
*M7, '''Product''': If ''Oxy'' holds, there exists a ''z'', called the "product" of ''x'' and ''y'', such that the parts of ''z'' are just those objects that are parts of '''both''' ''x'' and ''y''.
:&lt;math&gt;Oxy \rightarrow \exists z \forall v [Pvz \leftrightarrow (Pvx \land Pvy)].&lt;/math&gt; '''P.7'''
:If ''Oxy'' does not hold, ''x'' and ''y'' have no parts in common, and the product of ''x'' and ''y'' is undefined.
*M8, '''Unrestricted Fusion''': Let φ(''x'') be a [[first-order logic|first-order]] formula in which ''x'' is a [[free variable]]. Then the fusion of all objects satisfying φ exists.
:&lt;math&gt;\exists x [\phi(x)] \to \exists z \forall y [Oyz \leftrightarrow \exists x[\phi (x) \land Oyx]].&lt;/math&gt; '''P.8'''
:M8 is also called "General Sum Principle", "Unrestricted Mereological Composition", or "Universalism". M8 corresponds to the [[set builder notation|principle of unrestricted comprehension]] of [[naive set theory]], which gives rise to [[Russell's paradox]]. There is no mereological counterpart to this paradox simply because ''parthood'', unlike set membership, is [[Reflexive relation|reflexive]].

*M8', '''Unique Fusion''': The fusions whose existence M8 asserts are also unique. '''P.8' '''
*M9, '''Atomicity''': All objects are either atoms or fusions of atoms.
:&lt;math&gt; \exists y[Pyx \land \forall z[\lnot PPzy]].&lt;/math&gt; '''P.10'''

==Various systems==
Simons (1987), Casati and Varzi (1999) and Hovda (2008) describe many mereological systems whose axioms are taken from the above list. We adopt the boldface nomenclature of Casati and Varzi. The best-known such system is the one called ''classical extensional mereology'', hereinafter abbreviated '''CEM''' (other abbreviations are explained below). In '''CEM''', '''P.1''' through '''P.8' ''' hold as axioms or are theorems. M9, ''Top'', and ''Bottom'' are optional.

The systems in the table below are [[partial order|partially ordered]] by [[Inclusion (set theory)|inclusion]], in the sense that, if all the theorems of system A are also theorems of system B, but the converse is not [[logical truth|necessarily true]], then B ''includes'' A. The resulting [[Hasse diagram]] is similar to that in [http://plato.stanford.edu/entries/mereology/#4.2 Fig. 2], and Fig. 3.2 in Casati and Varzi (1999: 48).

{| class=wikitable
|-
!Label!!Name!!System!!Included Axioms
|-
|- style="border-top:1px solid #999;"
|-
|M1-M3||'''Parthood''' is a partial order||'''M'''||M1–M3
|-
|M4||'''Weak Supplementation'''||'''MM'''||'''M''', M4
|-
|M5||'''Strong Supplementation'''||'''EM'''||'''M''', M5
|-
|M5'||'''Atomistic Supplementation'''|| || 
|-
|M6||'''General Sum Principle''' (Sum)|| ||
|-
|M7||'''Product'''||'''CEM'''||'''EM''', M6–M7
|-
|M8||'''Unrestricted Fusion'''||'''GM'''||'''M''', M8
|-
| || ||'''GEM'''||'''EM''', M8
|-
|M8'||'''Unique Fusion'''||'''GEM'''||'''EM''', M8'
|-
|M9||'''Atomicity'''||'''AGEM'''||M2, M8, M9
|-
| || ||'''AGEM'''||'''M''', M5', M8
|}

There are two equivalent ways of asserting that the [[universe]] is [[partial order|partially ordered]]: Assume either M1–M3, or that Proper ''Parthood'' is [[Transitive relation|transitive]] and [[Asymmetric relation|asymmetric]], hence a [[strict partial order]]. Either axiomatization results in the system '''M'''. M2 rules out closed loops formed using ''Parthood'', so that the part relation is [[well-founded]]. Sets are well-founded if the [[axiom of regularity]] is assumed. The literature contains occasional philosophical and common-sense objections to the transitivity of ''Parthood''.

M4 and M5 are two ways of asserting ''supplementation'', the mereological analog of set [[complement (set theory)|complement]]ation, with M5 being stronger because M4 is derivable from M5. '''M''' and M4 yield ''minimal'' mereology, '''MM'''. '''MM''', reformulated in terms of Proper Part, is Simons's (1987) preferred minimal system.

In any system in which M5 or M5' are assumed or can be derived, then it can be proved that two objects having the same proper parts are identical. This property is known as ''[[Extensionality]]'', a term borrowed from set theory, for which [[Axiom of Extensionality|extensionality]] is the defining axiom. Mereological systems in which Extensionality holds are termed ''extensional'', a fact denoted by including the letter '''E''' in their symbolic names.

M6 asserts that any two underlapping objects have a unique sum; M7 asserts that any two overlapping objects have a unique product. If the universe is finite or if ''Top'' is assumed, then the universe is closed under ''sum''. Universal closure of ''Product'' and of supplementation relative to ''W'' requires ''Bottom''. ''W'' and ''N'' are, evidently, the mereological analog of the [[universal set|universal]] and [[empty set]]s, and ''Sum'' and ''Product'' are, likewise, the analogs of set-theoretical ''[[Union (set theory)|union]]'' and ''[[Intersection (set theory)|intersection]]''. If M6 and M7 are either assumed or derivable, the result is a mereology with ''closure''.

Because ''Sum'' and ''Product'' are binary operations, M6 and M7 admit the sum and product of only a finite number of objects. The ''fusion'' axiom, M8, enables taking the sum of infinitely many objects. The same holds for ''Product'', when defined. At this point, mereology often invokes [[set theory]], but any recourse to set theory is eliminable by replacing a formula with a [[Quantification (logic)|quantified]] variable ranging over a universe of sets by a schematic formula with one [[free variable]]. The formula comes out true (is satisfied) whenever the name of an object that would be a [[Element (mathematics)|member]] of the set (if it existed) replaces the free variable. Hence any axiom with sets can be replaced by an [[axiom schema]] with monadic atomic subformulae. M8 and M8' are schemas of just this sort. The [[syntax]] of a [[first-order theory]] can describe only a [[denumerable]] number of sets; hence, only denumerably many sets may be eliminated in this fashion, but this limitation is not binding for the sort of mathematics contemplated here.

If M8 holds, then ''W'' exists for infinite universes. Hence, ''Top'' need be assumed only if the universe is infinite and M8 does not hold. ''Top'' (postulating ''W'') is not controversial, but ''Bottom'' (postulating ''N'') is. Leśniewski rejected ''Bottom'', and most mereological systems follow his example (an exception is the work of [[Richard Milton Martin]]). Hence, while the universe is closed under sum, the product of objects that do not overlap is typically undefined. A system with ''W'' but not ''N'' is isomorphic to:
* A [[Boolean algebra (structure)|Boolean algebra]] lacking a 0
* A [[Join (mathematics)|join]] [[semilattice]] bounded from above by 1. Binary fusion and ''W'' interpret join and 1, respectively.
Postulating ''N'' renders all possible products definable, but also transforms classical extensional mereology into a set-free [[model theory|model]] of [[Boolean algebra (logic)|Boolean algebra]].

If sets are admitted, M8 asserts the existence of the fusion of all members of any nonempty set. Any mereological system in which M8 holds is called ''general'', and its name includes '''G'''. In any general mereology, M6 and M7 are provable. Adding M8 to an extensional mereology results in ''general extensional mereology'', abbreviated '''GEM'''; moreover, the extensionality renders the fusion unique. On the converse, however, if the fusion asserted by M8 is assumed unique, so that M8' replaces M8, then—as Tarski (1929) had shown—M3 and M8' suffice to axiomatize '''GEM''', a remarkably economical result. Simons (1987: 38–41) lists a number of '''GEM''' theorems.

M2 and a finite universe necessarily imply ''Atomicity'', namely that everything either is an atom or includes atoms among its proper parts. If the universe is infinite, ''Atomicity'' requires M9. Adding M9 to any mereological system, '''X''' results in the atomistic variant thereof, denoted '''AX'''. ''Atomicity'' permits economies, for instance, assuming that M5' implies ''Atomicity'' and extensionality, and yields an alternative axiomatization of '''AGEM'''.

==Set theory==
The notion of "subset" in set theory is not entirely the same as the notion of "subpart" in mereology [[Stanisław Leśniewski]] rejected set theory (a related to but not the same as [[nominalism]] (see https://plato.stanford.edu/entries/nominalism-metaphysics/). For a long time, nearly all philosophers and mathematicians avoided mereology, seeing it as tantamount to a rejection of set theory{{citation needed|date=August 2017}}. Goodman too was a nominalist, and his fellow nominalist [[Richard Milton Martin]] employed a version of the calculus of individuals throughout his career, starting in 1941.

Much early work on mereology was motivated by a suspicion that [[set theory]] was [[ontology|ontologically]] suspect, and that [[Occam's razor]] requires that one minimise the number of posits in one's theory of the world and of mathematics{{citation needed|date=August 2017}}. Mereology replaces talk of "sets" of objects with talk of "sums" of objects, objects being no more than the various things that make up wholes{{citation needed|date=August 2017}}.

Many logicians and philosophers{{who|date=August 2017}} reject these motivations, on such grounds as: 
* They deny that sets are in any way ontologically suspect
* Occam's razor, when applied to [[abstract object]]s like sets, is either a dubious principle or simply false
* Mereology itself is guilty of proliferating new and ontologically suspect entities such as fusions.
For a survey of attempts to found mathematics without using set theory, see Burgess and Rosen (1997).

In the 1970s, thanks in part to Eberle (1970), it gradually came to be understood that one can employ mereology regardless of one's ontological stance regarding sets. This understanding is called the "ontological innocence" of mereology. This innocence stems from mereology being formalizable in either of two equivalent ways:
*Quantified variables ranging over a [[universe]] of sets
*Schematic [[Predicate (mathematical logic)|predicates]] with a single [[free variable]].
Once it became clear that mereology is not tantamount to a denial of set theory, mereology became largely accepted as a useful tool for formal [[ontology]] and [[metaphysics]].

In set theory, [[Singleton (mathematics)|singletons]] are "atoms" that have no (non-empty) proper parts; many consider set theory useless or incoherent (not "well-founded") if sets cannot be built up from unit sets. The calculus of individuals was thought to require that an object either have no proper parts, in which case it is an "atom", or be the mereological sum of atoms. Eberle (1970), however, showed how to construct a calculus of individuals lacking "[[Atomism|atoms]]", i.e., one where every object has a "proper part" (defined below) so that the [[universe]] is infinite.

There are analogies between the axioms of mereology and those of standard [[Zermelo–Fraenkel set theory]] (ZF), if ''Parthood'' is taken as analogous to [[subset]] in set theory. On the relation of mereology and ZF, also see Bunt (1985). One of the very few contemporary set theorists to discuss mereology is Potter (2004).

[[David Lewis (philosopher)|Lewis]] (1991) went further, showing informally that mereology, augmented by a few [[ontology|ontological]] assumptions and [[plural quantification]], and some novel reasoning about [[Singleton (mathematics)|singletons]], yields a system in which a given individual can be both a member{{clarify|date=August 2017}} and a subset of another individual. In the resulting system, the axioms of [[ZFC]] (and of [[Peano arithmetic]]) are theorems.

Forrest (2002) revises Lewis's analysis by first formulating a generalization of '''CEM''', called "Heyting mereology", whose sole nonlogical primitive is ''Proper Part'', assumed [[transitive relation|transitive]] and [[antireflexive]]. There exists a "fictitious" null individual that is a proper part of every individual. Two schemas assert that every [[lattice (order)|lattice]] join exists (lattices are [[complete lattice|complete]]) and that meet [[distributive property|distributes]] over join. On this Heyting mereology, Forrest erects a theory of ''pseudosets'', adequate for all purposes to which sets have been put.

==Mathematics==
Husserl never claimed that mathematics could or should be grounded in part-whole rather than set theory. Lesniewski consciously derived his mereology as an alternative to set theory as a [[foundation of mathematics]], but did not work out the details. Goodman and Quine (1947) tried to develop the [[natural numbers|natural]] and [[real number]]s using the calculus of individuals, but were mostly unsuccessful; Quine did not reprint that article in his ''Selected Logic Papers''. In a series of chapters in the books he published in the last decade of his life, [[Richard Milton Martin]] set out to do what Goodman and Quine had abandoned 30 years prior. A recurring problem with attempts to ground mathematics in mereology is how to build up the theory of [[Relation (mathematics)|relations]] while abstaining from set-theoretic definitions of the [[ordered pair]]. Martin argued that Eberle's (1970) theory of relational individuals solved this problem.

[[Topology|Topological]] notions of [[Boundary (topology)|boundaries]] and connection can be married to mereology, resulting in [[mereotopology]]; see Casati and Varzi (1999: chpts. 4,5). Whitehead's 1929 ''[[Process and Reality]]'' contains a good deal of informal [[mereotopology]].

==Natural language==
Bunt (1985), a study of the [[semantics]] of natural language, shows how mereology can help understand such phenomena as the [[mass noun|mass–count distinction]] and [[grammatical aspect|verb aspect]]{{Example needed}}. But Nicolas (2008) argues that a different logical framework, called [[Plural quantification|plural logic]], should be used for that purpose.
Also, [[natural language]] often employs "part of" in ambiguous ways (Simons 1987 discusses this at length){{Example needed}}. Hence, it is unclear how, if at all, one can translate certain natural language expressions into mereological predicates. Steering clear of such difficulties may require limiting the interpretation of mereology to [[mathematics]] and [[natural science]]. Casati and Varzi (1999), for example, limit the scope of mereology to [[physical object]]s.

== Metaphysics ==
In [[metaphysics]] there are many troubling questions pertaining to parts and wholes. One question addresses constitution and persistence, another asks about composition.

=== Mereological constitution ===
In metaphysics, there are several puzzles concerning cases of mereological constitution.&lt;ref&gt;{{cite SEP|url=https://plato.stanford.edu/entries/material-constitution/|title=Mereological constitution}}&lt;/ref&gt; That is, what makes up a whole. We are still concerned with parts and wholes, but instead of looking at what parts make up a whole, we are wondering what a thing is made of, such as its materials:  e.g. the bronze in a bronze statue. Below are two of the main puzzles that philosophers use to discuss constitution.

''Ship of Theseus:''  Briefly, the puzzle goes something like this. There is a ship called the [[Ship of Theseus]]. Overtime the boards start to rot so we remove the boards and place them in a pile. First question, is the ship made of the new boards the same as the ship that had all the old boards? Second, if we reconstruct a ship using all of the old planks, etc. from the Ship of Theseus, and we also have a ship that was built out of new boards (each added one-by-one over time to replace old decaying boards), which ship is the real Ship of Theseus?

''Statue and Lump of Clay:''  Roughly, a sculptor decides to mold a statue out of a lump of clay. At time t1 the sculptor has a lump of clay. After many manipulations at time t2 there is a statue. The question asked is, is the lump of clay and the statue (numerically) identical? If so, how and why?&lt;ref&gt;{{Cite journal|last=Rea|first=Michael|year=1995|title=The Problem of Material Constitution|url=|journal=The Philosophical Review|volume=104.4|pages=525–552|via=|doi=10.2307/2185816}}&lt;/ref&gt;

Constitution typically has implications for views on persistence:  how does an object persist over time if any of its parts (materials) change or are removed, as is the case with humans who lose cells, change height, hair color, memories, and yet we are said to be the same person today as we were when we were first born. For example, Ted Sider is the same today as he was when he was born—he just changed. But how can this be if many parts of Ted today did not exist when Ted was just born? Is it possible for things, such as organisms to persist? And if so, how? There are several views that attempt to answer this question. Some of the views are as follows (note, there are several other views):&lt;ref name=":7" /&gt;&lt;ref&gt;In Theodore Sider, John Hawthorne &amp; Dean W. Zimmerman (eds.), ''Contemporary Debates in Metaphysics''. Blackwell Pub. 241--262 (2007).&lt;/ref&gt;

(a) Constitution View. This view accepts cohabitation. That is, two objects share exactly the same matter. Here, it follows, that there are no temporal parts.

(b) [[Mereological essentialism]], which states that the only objects that exist are quantities of matter, which are things defined by their parts. The object persists if matter is removed (or the form changes); but the object ceases to exist if any matter is destroyed.

(c) Dominant Sorts. This is the view that tracing is determined by which sort is dominant; they reject cohabitation. For example, lump does not equal statue because they're different "sorts".

(d) [[Nihilism]]—which makes the claim that no objects exist, except simples, so there is no persistence problem.

(e) 4 Dimensionalism, or [[Temporal parts|Temporal Parts]] (may also go by the names Perdurantism or Exdurantism), which roughly states that aggregates of temporal parts are intimately related. For example, two roads merging, momentarily and spatially, are still one road, because they share a part.

(f) 3 Dimensionalism (may also go by the name Endurantism), where the object is wholly present. That is, the persisting object retains numerical identity.

=== Mereological composition ===
One question that is addressed by philosophers is which is more fundamental: parts, wholes, or neither?&lt;ref name=":0"&gt;{{Cite journal|last=Healey|first=Richard|last2=Uffink|first2=Jos|year=2013|title=Part and Whole in Physics:  An Introduction|url=|journal=Studies in History and Philosophy of Science Part B|volume=44.1|pages=20–21|via=|doi=10.1016/j.shpsb.2011.11.004|bibcode=2013SHPMP..44...20H}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite journal|last=Healey|first=Richard|year=2013|title=Physical Composition|url=|journal=Studies in History and Philosophy of Science Part B|volume=44.1|pages=48–62|via=|doi=10.1016/j.shpsb.2011.05.001|bibcode=2013SHPMP..44...48H}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite journal|last=Kadanoff|first=Leo|year=2013|title=Relating Theories Via Renormalization|url=|journal=Studies in History and Philosophy of Science Part B|volume=44.1|pages=22–39|via=|doi=10.1016/j.shpsb.2012.05.002|arxiv=1102.3705|bibcode=2013SHPMP..44...22K}}&lt;/ref&gt;&lt;ref name=":3"&gt;{{Cite journal|last=Ghirardi|first=GianCarlo|year=2013|title=The Parts and the Whole:  Collapse Theories and Systems with Identical Constituents|url=|journal=Studies in History and Philosophy of Science Part B|volume=44.1|pages=40–47|via=|doi=10.1016/j.shpsb.2011.06.002|bibcode=2013SHPMP..44...40G}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Shaffer|first=Jonathan|year=2010|title=Monism: The Priority of the Whole|url=|journal=Philosophical Review|volume=119.1|pages=31–76|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Cameron|first=Ross|year=2014|title=Parts Generate the Whole but they are not Identical to it|url=|journal=Oxford University Press|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Loss|first=Roberto|year=2016|title=Parts Ground the Whole and are Identical to it|url=|journal=Australasian Journal of Philosophy|volume=94.3|pages=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Cotnoir|first=Aaron|year=2014|title=Composition as Identity:  Framing the Debate|url=|journal=Oxford University Press|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sider|first=Ted|year=2015|title=Nothing Over and Above|url=|journal=Grazer Philosophische Studien|volume=91|pages=191–216|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Wallace|first=Megan|year=2011|title=Composition as Identity:  Pt. I &amp; II|url=|journal=Philosophy Compass|volume=6.11|pages=804–827|via=}}&lt;/ref&gt; Another pressing question is called the Special Composition Question (SCQ):  For any Xs, when is it the case that there is a Y such that the Xs compose Y?&lt;ref name=":7"&gt;{{Cite book|title=Metaphysics:  An Introduction|last=Ney|first=Alyssa|publisher=Routledge|year=2014|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title=Contemporary Debates in Metaphysics|editor-last=Sider|editor-first=Ted|publisher=Blackwell Publishing|year=2008|isbn=|location=|pages=|chapter=The Moon and Sixpence:  A Defense of Mereological Universalism|quote=|via=| author=James van Cleve}}&lt;/ref&gt;&lt;ref name=":4"&gt;{{Cite book|title=Contemporary Debates in Metaphysics|editor-last=Sider|editor-first=Ted|publisher=Blackwell Publishing|year=2008|isbn=|location=|pages=341–363|chapter=Restricted Composition|quote=|via=| author=Ned Markosian}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=McDaniel|first=Kris|year=2010|title=Parts and Wholes|url=|journal=Philosophy Compass|volume=5.5|pages=412–425|via=|doi=10.1111/j.1747-9991.2009.00238.x}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Korman|first=Daniel|last2=Carmichael|first2=Chad|year=2016|title=Composition (Draft:  9/29/15)|url=|journal=Oxford Handbooks Online|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://plato.stanford.edu/entries/mereology/|title=Mereology|last=Varzi|first=Achille|date=|website=|publisher=|access-date=}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{Cite journal|last=Sider|first=Ted|year=2013|title=Against Parthood|url=|journal=Oxford Studies in Metaphysics|volume=8|pages=237–293|via=}}&lt;/ref&gt; This question has caused philosophers to run in three different directions:  nihilism, universal composition (UC), or a moderate view (restricted composition). The first two views are considered extreme since the first denies composition, and the second allows any and all non-spatially overlapping objects to compose another object. The moderate view encompasses several theories that try to make sense of SCQ without saying 'no' to composition or 'yes' to unrestricted composition.

==== Fundamentality ====
There are philosophers who are concerned with the question of fundamentality. That is, which is more ontologically fundamental the parts or their wholes. There are several responses to this question, though one of the default assumptions is that the parts are more fundamental. That is, the whole is grounded in its parts. This is the mainstream view. Another view, explored by Shaffer (2010) is monism, where the parts are grounded in the whole. Shaffer does not just mean that, say, the parts that make up my body are grounded in my body. Rather, Shaffer argues that the whole ''cosmos'' is more fundamental and everything else is a part of the cosmos. Then, there is the identity theory which claims that there is no hierarchy or fundamentality to parts and wholes. Instead wholes ''are just'' (or equivalent to) their parts. There can also be a two-object view which says that the wholes are not equal to the parts—they are numerically distinct from one another. Each of these theories has benefits and costs associated with them.&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt;

==== &lt;span id="SCQ"&gt;&lt;/span&gt; Special Composition Question (SCQ) ====
Philosophers want to know when some Xs compose something Y. There are several kinds of responses:

*One response to this question is called ''nihilism''. Nihilism states that there are no mereological complex objects (read:  composite objects); there are only [[simples (philosophy)|simples]].  Nihilists do not entirely reject composition because they do think that simples compose themselves, but this is a different point. More formally Nihilists would say: Necessarily, for any non-overlapping Xs, there is an object composed of the Xs if and only if there is only one of the Xs.&lt;ref name=":4" /&gt;&lt;ref name=":5" /&gt;&lt;ref name=":6"&gt;{{Cite book|title=Material Beings|last=van Inwagen|first=Peter|publisher=Cornell University Press|year=1990|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt; This theory, though well explored, has its own set of problems. Some of which include, but are not limited to: experiences and common sense, incompatible with atomless gunk, and it is unsupported by space-time physics.&lt;ref name=":4" /&gt;&lt;ref name=":5" /&gt;
*Another prominent response is called ''universal composition'' (UC). UC says that so long as the Xs do not spatially overlap, the Xs can compose a complex object. Universal compositionalists are also considered those who support unrestricted composition. More formally: Necessarily, for any non-overlapping Xs, there is a Y such that Y is composed of the Xs. For example, someone's left thumb, the top half of another person's right shoe, and a quark in the center of their galaxy can compose a complex object according to universal composition. Likewise, this theory also has some issues, most of them dealing with our experiences that these randomly chosen parts make up a complex whole and there are far too many objects posited in our ontology.
*A third response (perhaps less explored than the previous two) includes a range of ''restricted composition views''. Though there are several views, they all share a common idea:  that there is a restriction on what counts as a complex object: some (but not all) Xs come together to compose a complex Y. Some of these theories include:

(a) Contact—the Xs compose a complex Y if and only if the Xs are in contact;

(b) Fastenation—the Xs compose a complex Y if and only if the Xs are fastened;

(c) Cohesion—the Xs compose a complex Y if and only if the Xs cohere (cannot be pulled apart or moved in relation to each other without breaking);

(d) Fusion—the Xs compose a complex Y if and only if the Xs are fused (fusion is when the Xs are joined together such that there is no boundary);

(e) VIPA—van Inwagen's Proposed Answer—the Xs compose a complex Y if and only if either the activities of the Xs constitute a life or there is only one of the Xs;&lt;ref name=":6" /&gt; and

(f) Brutal Composition—"It's just the way things are." There is no true, nontrivial, and finitely long answer.&lt;ref&gt;{{Cite journal|last=Markosian|first=Ned|year=1998|title=Brutal Composition|url=|journal=Philosophical Studies|volume=92|pages=211–249|via=|doi=10.1023/a:1004267523392}}&lt;/ref&gt;

This is not an exhaustive list as many more hypotheses continue to be explored. However, a common problem with these theories is that they are vague. It remains unclear what "fastened" or "life" mean, for example. But there are many other issues within the restricted composition responses—though many of them are subject to which theory is being discussed.&lt;ref name=":4" /&gt;

== Important surveys ==
The books by Simons (1987) and Casati and Varzi (1999) differ in their strengths:
*Simons (1987) sees mereology primarily as a way of formalizing [[ontology]] and [[metaphysics]]. His strengths include the connections between mereology and:
**The work of [[Stanisław Leśniewski]] and his descendants
**Various continental philosophers, especially [[Edmund Husserl]]
**Contemporary English-speaking technical philosophers such as [[Kit Fine]] and [[Roderick Chisholm]]
**Recent work on [[formal ontology]] and [[metaphysics]], including continuants, occurrents, [[class noun]]s, [[mass noun]]s, and ontological dependence and [[integrity]]
**[[Free logic]] as a background logic
**Extending mereology with [[tense logic]] and [[modal logic]]
**[[Boolean algebra (structure)|Boolean algebra]]s and [[lattice theory]].
*Casati and Varzi (1999) see mereology primarily as a way of understanding the material world and how humans interact with it. Their strengths include the connections between mereology and:
** A "proto-geometry" for physical objects
** [[Topology]] and [[mereotopology]], especially [[Boundary (topology)|boundaries]], regions, and holes
** A formal theory of events
** Theoretical [[computer science]]
** The writings of [[Alfred North Whitehead]], especially his ''[[Process and Reality]]'' and work descended therefrom.&lt;ref&gt;Cf. Peter Simons, "Whitehead and Mereology", in Guillaume Durand et [[Michel Weber]] (éditeurs), ''[https://www.academia.edu/279950/Les_principes_de_la_connaissance_naturelle_dAlfred_North_Whitehead_-_Alfred_North_Whiteheads_Principles_of_Natural_Knowledge Les principes de la connaissance naturelle d’Alfred North Whitehead — Alfred North Whitehead’s Principles of Natural Knowledge]'', Frankfurt / Paris / Lancaster, ontos verlag, 2007. See also the relevant entries of [[Michel Weber]] and Will Desmond, (eds.), ''[https://www.academia.edu/279955/Handbook_of_Whiteheadian_Process_Thought Handbook of Whiteheadian Process Thought]'', Frankfurt / Lancaster, ontos verlag, Process Thought X1 &amp; X2, 2008.&lt;/ref&gt;

Simons devotes considerable effort to elucidating historical notations. The notation of Casati and Varzi is often used. Both books include excellent bibliographies. To these works should be added Hovda (2008), which presents the latest state of the art on the axiomatization of mereology.

==See also==
* [[Attitude polarization]]
* [[Finitist set theory]]
* [[Gunk (mereology)]]
* [[Implicate and explicate order]] according to David Bohm
* ''[[Laws of Form]]'' by [[G. Spencer-Brown]]
* [[Mereological essentialism]]
* [[Mereological nihilism]]
* [[Mereotopology]]
* [[Meronomy]]
* [[Meronymy]]
* [[Monad (philosophy)]]
* [[Plural quantification]]
* [[Quantifier variance]]
* [[Simple (philosophy)]]
* [[Whitehead's point-free geometry]]

==References==
{{Reflist}}
{{more footnotes|date=February 2010}}
* Bowden, Keith, 1991. ''Hierarchical Tearing: An Efficient Holographic Algorithm for System Decomposition'', Int. J. General Systems, Vol. 24(1), pp 23–38.
* Bowden, Keith, 1998. ''Huygens Principle, Physics and Computers''. Int. J. General Systems, Vol. 27(1-3), pp.&amp;nbsp;9–32.
* Bunt, Harry, 1985. ''Mass terms and model-theoretic semantics''. Cambridge Univ. Press.
* Burgess, John, and Rosen, Gideon, 1997. ''A Subject with No Object''. Oxford Univ. Press.
* Burkhardt, H., and Dufour, C.A., 1991, "Part/Whole I: History" in Burkhardt, H., and Smith, B., eds., ''Handbook of Metaphysics and Ontology''. Muenchen: Philosophia Verlag.
* Casati, R., and Varzi, A., 1999. ''Parts and Places: the structures of spatial representation''. MIT Press.
* Eberle, Rolf, 1970. ''Nominalistic Systems''. Kluwer.
* Etter, Tom, 1996. ''Quantum Mechanics as a Branch of Mereology'' in Toffoli T., ''et al.'', ''PHYSCOMP96, Proceedings of the Fourth Workshop on Physics and Computation'', New England Complex Systems Institute.
* Etter, Tom, 1998. ''Process, System, Causality and Quantum Mechanics''. SLAC-PUB-7890, Stanford Linear Accelerator Centre.
* Forrest, Peter, 2002, "[http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdfview_1&amp;handle=euclid.ndjfl/1071509430 Nonclassical mereology and its application to sets]", ''Notre Dame Journal of Formal Logic 43'': 79-94.
* Gerla, Giangiacomo, (1995). "[https://web.archive.org/web/20110717210751/http://www.dmi.unisa.it/people/gerla/www/Down/point-free.pdf Pointless Geometries]", in Buekenhout, F., Kantor, W. eds., "Handbook of incidence geometry: buildings and foundations". North-Holland: 1015-31.
* [[Nelson Goodman|Goodman, Nelson]], 1977 (1951). ''The Structure of Appearance''. Kluwer.
* Goodman, Nelson, and [[Willard Quine|Quine, Willard]], 1947, "Steps toward a constructive nominalism", ''Journal of Symbolic Logic'' 12: 97-122.
*Gruszczynski R., and Pietruszczak A., 2008, "[http://www.math.ucla.edu/~asl/bsl/1404/1404-002.ps Full development of Tarski's geometry of solids]", ''Bulletin of Symbolic Logic'' 14: 481-540. A system of geometry based on Lesniewski's mereology, with basic properties of mereological structures.
* Hovda, Paul, 2008, "[http://www.springerlink.com/content/76l18850p2325p16/ What is classical mereology?]" ''Journal of Philosophical Logic'' 38(1): 55-82.
* [[Edmund Husserl|Husserl, Edmund]], 1970. ''Logical Investigations, Vol. 2''. Findlay, J.N., trans. Routledge.
* Kron, Gabriel, 1963, ''Diakoptics: The Piecewise Solution of Large Scale Systems''. Macdonald, London.
* [[David Lewis (philosopher)|Lewis, David K.]], 1991. ''Parts of Classes''. Blackwell.
* Leonard, H.S., and [[Nelson Goodman|Goodman, Nelson]], 1940, "The calculus of individuals and its uses", ''Journal of Symbolic Logic 5'': 45–55.
* [[Stanisław Leśniewski|Leśniewski, Stanisław]], 1992. ''Collected Works''. Surma, S.J., Srzednicki, J.T., Barnett, D.I., and Rickey, V.F., editors and translators. Kluwer.
*[[John Lucas (philosopher)|Lucas, J. R.]], 2000. ''Conceptual Roots of Mathematics''. Routledge. Chpts. 9.12 and 10 discuss mereology, mereotopology, and the related theories of [[A.N. Whitehead]], all strongly influenced by the unpublished writings of David Bostock.
* Mesarovic, M.D., Macko, D., and Takahara, Y., 1970, "Theory of Multilevel, Hierarchical Systems". Academic Press.
* Nicolas, David, 2008, "[https://web.archive.org/web/20120219021719/http://d.a.nicolas.free.fr/Nicolas-Mass-nouns-and-plural-logic-Revised-2.pdf Mass nouns and plural logic]", ''Linguistics and Philosophy'' 31(2): 211–44.
*Pietruszczak A., 1996, "[https://dx.doi.org/10.12775/LLP.1996.005 Mereological sets of distributive classes]", ''Logic and Logical Philosophy'' 4: 105-22. Constructs, using mereology, mathematical entities from set theoretical classes.
*Pietruszczak A., 2005, "[https://dx.doi.org/10.12775/LLP.2005.014 Pieces of mereology]", ''Logic and Logical Philosophy'' 14: 211-34. Basic mathematical properties of Lesniewski's mereology.
*Potter, Michael, 2004. '' Set Theory and Its Philosophy''. Oxford Univ. Press.
* Simons, Peter, 1987 (reprinted 2000). ''Parts: A Study in Ontology''. Oxford Univ. Press.
* Srzednicki, J. T. J., and Rickey, V. F., eds., 1984. ''Lesniewski's Systems: Ontology and Mereology''. Kluwer.
* [[Alfred Tarski|Tarski, Alfred]], 1984 (1956), "Foundations of the Geometry of Solids" in his ''Logic, Semantics, Metamathematics: Papers 1923–38''. Woodger, J., and Corcoran, J., eds. and trans. Hackett.
* Varzi, Achille C., 2007, "[http://www.columbia.edu/~av72/papers/Space_2007.pdf Spatial Reasoning and Ontology: Parts, Wholes, and Locations]" in Aiello, M. et al., eds., ''Handbook of Spatial Logics''. Springer-Verlag: 945-1038.
*[[A. N. Whitehead|Whitehead, A. N.]], 1916, "La Theorie Relationiste de l'Espace", ''Revue de Metaphysique et de Morale 23'': 423-454. Translated as Hurley, P.J., 1979, "The relational theory of space", ''Philosophy Research Archives 5'': 712-741.
*------, 1919. ''An Enquiry Concerning the Principles of Natural Knowledge''. Cambridge Univ. Press. 2nd ed., 1925.
*------, 1920. ''The Concept of Nature''. Cambridge Univ. Press. 2004 paperback, Prometheus Books. Being the 1919 Tarner Lectures delivered at [[Trinity College, Cambridge]].
*------, 1978 (1929). ''[[Process and Reality]]''. Free Press.
* Woodger, J. H., 1937. ''The Axiomatic Method in Biology''. Cambridge Univ. Press.

==External links==
{{Wiktionary}}
*{{Commonscat-inline}}
*[[Stanford Encyclopedia of Philosophy]]:
**"[http://plato.stanford.edu/entries/mereology/ Mereology]" – Achille Varzi.
**"[http://plato.stanford.edu/entries/boundary/ Boundary]" – Achille Varzi.

[[Category:Mereology| ]]
[[Category:Mathematical logic]]
[[Category:Ontology]]
[[Category:Predicate logic]]</text>
      <sha1>ep9tis21r4ve5himlt4pti4d0kd539n</sha1>
    </revision>
  </page>
  <page>
    <title>Multiplicative cascade</title>
    <ns>0</ns>
    <id>12779248</id>
    <revision>
      <id>866259759</id>
      <parentid>822536197</parentid>
      <timestamp>2018-10-29T08:15:17Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <minor/>
      <comment>move see also above refs</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3365">In mathematics, a '''multiplicative cascade'''&lt;ref&gt;{{cite journal|last1=Meakin|first1=Paul|title=Diffusion-limited aggregation on multifractal lattices: A model for fluid-fluid displacement in porous media|journal=Physical Review A|date=September 1987|volume=36|issue=6|pages=2833–2837|doi=10.1103/PhysRevA.36.2833|pmid=9899187|url=http://journals.aps.org/pra/abstract/10.1103/PhysRevA.36.2833}}&lt;/ref&gt;&lt;ref&gt;[https://arxiv.org/abs/0803.3212 Cristano G. Sabiu, Luis Teodoro, Martin Hendry, arXiv:0803.3212v1 ''Resolving the universe with multifractals'']&lt;/ref&gt; is a [[fractal]]/[[multifractal]] distribution of points produced via an iterative and multiplicative [[random process]].

[[Image:3fractals2.jpg|800px]]&lt;br /&gt;
'''Model I (left plot):
: '''&lt;math&gt;\lbrace p_1,p_2,p_3,p_4 \rbrace = \lbrace 1,1,1,0 \rbrace&lt;/math&gt; 
'''Model II (middle plot):
: '''&lt;math&gt;\lbrace p_1,p_2,p_3,p_4 \rbrace = \lbrace 1,0.75,0.75,0.5 \rbrace&lt;/math&gt; 
'''Model III (right plot):
: '''&lt;math&gt;\lbrace p_1,p_2,p_3,p_4 \rbrace = \lbrace 1,0.5,0.5,0.25 \rbrace&lt;/math&gt;

The plots above are examples of multiplicative cascade multifractals.
To create these distributions there are a few steps to take. Firstly, we must create a lattice of cells which will be our underlying probability density field. 

Secondly, an iterative process is followed to create multiple levels of the lattice: at each iteration the cells are split into four equal parts (cells). Each new cell is then assigned a probability randomly from the set &lt;math&gt;\lbrace p_1,p_2,p_3,p_4 \rbrace&lt;/math&gt; without replacement, where &lt;math&gt;p_i \in [0,1]&lt;/math&gt;. This process is continued to the ''N''th level. For example, in constructing such a model down to level 8 we produce a 4&lt;sup&gt;8&lt;/sup&gt; array of cells. 

Thirdly, the cells are filled as follows: We take the probability of a cell being occupied as the product of the cell's own ''p''&lt;sub&gt;''i''&lt;/sub&gt; and those of all its parents (up to level 1). A [[Monte Carlo method|Monte Carlo rejection scheme]] is used repeatedly until the desired cell population is obtained, as follows: ''x'' and ''y'' cell coordinates are chosen randomly, and a random number between 0 and 1 is assigned; the (''x'', ''y'') cell is then populated depending on whether the assigned number is lesser than (outcome: not populated) or greater or equal to (outcome: populated) the cell's occupation probability.

To produce the plots above we filled the probability density field with 5,000 points in a space of 256&amp;nbsp;&amp;times;&amp;nbsp;256.

An example of the probability density field:&lt;br /&gt;
[[Image:Multifractal density field.jpg]]

The fractals are generally not scale-invariant and therefore cannot be considered ''standard''  [[fractals]]. They can however be considered [[multifractals]]. The Rényi (generalized) dimensions can be theoretically predicted.  It can be shown &lt;ref&gt;Martinez et al. ApJ 357 50M "Clustering Paradigms and Multifractal Measures" [http://adsabs.harvard.edu/abs/1990ApJ...357...50M]&lt;/ref&gt; that as &lt;math&gt;N \rightarrow \infty&lt;/math&gt;,

: &lt;math&gt;D_q=\frac{\log_2\left( f^q_1+f^q_2+f^q_3+f^q_4\right)}{1-q},&lt;/math&gt;

where N is the level of the grid refinement and,

: &lt;math&gt;f_i=\frac{p_i}{\sum_i p_i}.&lt;/math&gt;

== See also ==
{{Commons|Fractal|fractals}}
* [[Fractal dimension]]
* [[Hausdorff dimension]]
* [[Scale invariance]]

==References==
{{reflist}}

[[Category:Fractals]]</text>
      <sha1>8xpd1b6ys0r2a97751heqtxyzj4yr1o</sha1>
    </revision>
  </page>
  <page>
    <title>Ordinal logic</title>
    <ns>0</ns>
    <id>32123297</id>
    <revision>
      <id>786597233</id>
      <parentid>490075488</parentid>
      <timestamp>2017-06-20T12:23:33Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1506">In [[mathematics]], '''ordinal logic''' is a logic associated with an [[ordinal number]] by recursively adding elements to a sequence of previous logics.&lt;ref name=feferman &gt;Solomon Feferman, ''Turing in the Land of O(z)'' in "The universal Turing machine: a half-century survey" by Rolf Herken 1995 {{isbn|3-211-82637-8}} page 111&lt;/ref&gt;&lt;ref&gt;''Concise Routledge encyclopedia of philosophy'' 2000 {{isbn|0-415-22364-4}} page 647&lt;/ref&gt; The concept was introduced in 1938 by [[Alan Turing]] in his PhD dissertation at Princeton in view of [[Gödel's incompleteness theorems]].&lt;ref name=alan &gt;Alan Turing, ''Systems of Logic Based on Ordinals'' Proceedings London Mathematical Society Volumes 2–45, Issue 1, pp. 161–228.[http://plms.oxfordjournals.org/content/s2-45/1/161.extract]&lt;/ref&gt;&lt;ref name=feferman /&gt;

While Gödel showed that every system of logic suffers from some form of incompleteness, Turing focused on a method so that from a given system of logic a more complete system may be constructed. By repeating the process a sequence L1, L2, … of logics is obtained, each more complete than the previous one. A logic L can then be constructed in which the provable theorems are the totality of theorems provable with the help of the L1, L2, … etc. Thus Turing showed how one can associate a logic with any [[constructive ordinal]].&lt;ref name=alan /&gt; 

==References==
{{Reflist}}

[[Category:Mathematical logic]]
[[Category:Systems of formal logic]]
[[Category:Ordinal numbers]]

{{mathlogic-stub}}</text>
      <sha1>t5y1cj89m921t1xk1ixft3om88aidf5</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonal array</title>
    <ns>0</ns>
    <id>17887653</id>
    <revision>
      <id>871192431</id>
      <parentid>824576683</parentid>
      <timestamp>2018-11-29T15:25:06Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: J. Roy. Stat. Soc., Suppl. → J. R. Stat. Soc. Suppl.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20500">In mathematics, in the area of [[combinatorial design]]s, an '''orthogonal array''' is a "table" (array) whose entries come from a fixed finite set of symbols (typically, {1,2,...,''n''}), arranged in such a way that there is an integer ''t'' so that for every selection of ''t'' columns of the table, all ordered ''t''-[[tuples]] of the symbols, formed by taking the entries in each row restricted to these columns, appear the same number of times. The number ''t'' is called the ''strength'' of the orthogonal array. Here is a simple example of an orthogonal array with symbol set {1,2} and strength 2:

::{| class="wikitable"
|-
| 1 || 1 || 1
|-
| 2 || 2 || 1
|-
| 1 || 2 || 2
|-
| 2 || 1 || 2
|}

Notice that the four [[ordered pair]]s (2-tuples) formed by the rows restricted to the first and third columns, namely (1,1), (2,1), (1,2) and (2,2) are all the possible ordered pairs of the two element set and each appears exactly once. The second and third columns would give, (1,1), (2,1), (2,2) and (1,2); again, all possible ordered pairs each appearing once. The same statement would hold had the first and second columns been used. This is thus an orthogonal array of strength two.

Orthogonal arrays generalize the idea of [[mutually orthogonal latin square]]s in a tabular form. These arrays have many connections to other combinatorial designs and have applications in the statistical [[design of experiments]], [[coding theory]], [[cryptography]] and various types of [[software testing]].

==Definition==

A '''''t''-(''v'',''k'',λ) ''orthogonal array''''' (''t'' ≤ ''k'') is a λ''v''&lt;sup&gt;''t''&lt;/sup&gt; × ''k'' array whose entries are chosen from a set ''X'' with ''v'' points such that in every subset of ''t'' columns of the array, every ''t''-tuple of points of ''X'' appears in exactly λ rows.

In this formal definition, provision is made for repetition of the ''t''-tuples (λ is the number of repeats) and the number of rows is determined by the other parameters.

In many applications these parameters are given the following names:
: ''v'' is the number of ''levels'',
: ''k'' is the number of ''factors'',
: λ''v''&lt;sup&gt;''t''&lt;/sup&gt; is the number of experimental ''runs'',
: ''t'' is the ''strength'', and
: λ is the ''index''.

An orthogonal array is ''simple'' if it does not contain any repeated rows.

An orthogonal array is ''linear'' if ''X'' is a [[finite field]] of order ''q'', '''F'''&lt;sub&gt;''q''&lt;/sub&gt; (''q'' a prime power) and the rows of the array form a subspace of the [[vector space]] ('''F'''&lt;sub&gt;''q''&lt;/sub&gt;)&lt;sup&gt;''k''&lt;/sup&gt;.&lt;ref&gt;{{harvnb|Stinson|2003|loc=pg. 225}}&lt;/ref&gt;

Every linear orthogonal array is simple.

==Examples==

An example of a 2-(4, 5, 1) orthogonal array; a strength 2, 4 level design of index 1 with 16 runs.
&lt;center&gt;
{| class="wikitable"
|-
| 1 || 1 || 1 || 1 || 1
|-
| 1 || 2 || 2 || 2 || 2
|-
| 1 || 3 || 3 || 3 || 3
|-
| 1 || 4 || 4 || 4 || 4
|-
| 2 || 1 || 4 || 2 || 3
|-
| 2 || 2 || 3 || 1 || 4
|-
| 2 || 3 || 2 || 4 || 1
|-
| 2 || 4 || 1 || 3 || 2
|-
| 3 || 1 || 2 || 3 || 4
|-
| 3 || 2 || 1 || 4 || 3
|-
| 3 || 3 || 4 || 1 || 2
|-
| 3 || 4 || 3 || 2 || 1
|-
| 4 || 1 || 3 || 4 || 2
|-
| 4 || 2 || 4 || 3 || 1
|-
| 4 || 3 || 1 || 2 || 4
|-
| 4 || 4 || 2 || 1 || 3
|}
&lt;/center&gt;

An example of a 2-(3,5,3) orthogonal array (written as its  [[transpose]] for ease of viewing):&lt;ref name="Dénes 1974 loc=pg. 191"&gt;{{harvnb|Dénes|Keedwell|1974|loc=pg. 191}}&lt;/ref&gt;
&lt;center&gt;
{| class="wikitable"
|-
| 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 0 || 1 || 1 || 1 || 1 || 1 || 1 || 1 || 1 || 1 || 2 || 2 || 2 || 2 || 2 || 2 || 2 || 2 || 2
|-
| 0 || 0 || 0 || 1 || 1 || 1 || 2 || 2 || 2 || 0 || 0 || 0 || 1 || 1 || 1 || 2 || 2 || 2 || 0 || 0 || 0 || 1 || 1 || 1 || 2 || 2 || 2
|-
| 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2 || 0 || 1 || 2
|-
| 0 || 0 || 0 || 1 || 1 || 1 || 2 || 2 || 2 || 2 || 2 || 2 || 0 || 0 || 0 || 1 || 1 || 1 || 1 || 1 || 1 || 2 || 2 || 2 || 0 || 0 || 0
|-
| 0 || 1 || 2 || 1 || 2 || 0 || 2 || 0 || 1 || 0 || 1 || 2 || 1 || 2 || 0 || 2 || 0 || 1 || 0 || 1 || 2 || 1 || 2 || 0 || 2 || 0 || 1
|}
&lt;/center&gt;

===Trivial examples===

Any ''t''-(''v'', ''t'', λ) orthogonal array would be considered ''trivial'' since they are easily constructed by simply listing all the ''t''-tuples of the ''v''-set λ times.

==Mutually orthogonal latin squares==
{{main|mutually orthogonal latin square}}

A 2-(''v'',''k'',1) orthogonal array is equivalent to a set of ''k''&amp;nbsp;−&amp;nbsp;2 [[mutually orthogonal latin square]]s of order ''v''.

Index one, strength 2 orthogonal arrays are also known as ''Hyper-Graeco-Latin square designs'' in the statistical literature.

Let ''A'' be a strength 2, index 1 orthogonal array on a ''v''-set of elements, identified with the set of natural numbers {1,...,''v''}. Chose and fix, in order, two columns of ''A'', called the ''indexing columns''. All ordered pairs (''i'', ''j'') with 1 ≤ ''i'', ''j'' ≤ ''v'' appear exactly once in the rows of the indexing columns. Take any other column of ''A'' and create a square array whose entry in position (''i'',''j'') is the entry of ''A'' in this column in the row that contains (''i'', ''j'') in the indexing columns of ''A''. The resulting square is a [[latin square]] of order ''v''. For example, consider the 2-(3,4,1) orthogonal array:
{| class="wikitable"
|-
| 1 || 1 || 1 || 1
|-
| 1 || 2 || 2 || 2
|-
| 1 || 3 || 3 || 3
|-
| 2 || 1 || 2 || 3
|-
| 2 || 2 || 3 || 1
|-
| 2 || 3 || 1 || 2
|-
| 3 || 1 || 3 || 2
|-
| 3 || 2 || 1 || 3
|-
| 3 || 3 || 2 || 1
|}
By choosing columns 3 and 4 (in that order) as the indexing columns, the first column produces the latin square,
{| class="wikitable"
|-
| 1 || 2 || 3
|-
| 3 || 1 || 2
|-
| 2 || 3 || 1
|}
while the second column produces the latin square,
{| class="wikitable"
|-
| 1 || 3 || 2
|-
| 3 || 2 || 1
|-
| 2 || 1 || 3
|}

The latin squares produced in this way from an orthogonal array will be [[orthogonal latin squares]], so the ''k''&amp;nbsp;−&amp;nbsp;2 columns other than the indexing columns will produce a set of ''k''&amp;nbsp;−&amp;nbsp;2 [[mutually orthogonal latin square]]s.

This construction is completely reversible and so strength 2, index 1 orthogonal arrays can be constructed from sets of mutually orthogonal latin squares.&lt;ref&gt;{{harvnb|Stinson|2003|loc=pp. 140–141, Section 6.5.1}}&lt;/ref&gt;

==Latin squares, latin cubes and latin hypercubes==

Orthogonal arrays provide a uniform way to describe these diverse objects which are of interest in the statistical [[design of experiments]].

===Latin squares===

As mentioned in the previous section a latin square of order ''n'' can be thought of as a 2-(''n'', 3, 1) orthogonal array. Actually, the orthogonal array can lead to six latin squares since any ordered pair of distinct columns can be used as the indexing columns. However, these are all [[Quasigroup|isotopic]] and are considered equivalent. For concreteness we shall always assume that the first two columns in their natural order are used as the indexing columns.

===Latin cubes===

In the statistics literature, a '''latin cube''' is an ''n'' × ''n'' × ''n'' three-dimensional matrix consisting of ''n'' layers, each having ''n'' rows and ''n'' columns such that the ''n'' distinct elements which appear are repeated ''n''&lt;sup&gt;2&lt;/sup&gt; times and arranged so that in each layer parallel to each of the three pairs of opposite faces of the cube all the ''n'' distinct elements appear and each is repeated exactly ''n'' times in that layer.&lt;ref&gt;{{harvnb|Dénes|Keedwell|1974|loc=pg. 187}} credit the definition to {{harvtxt|Kishen|1950|loc=pg. 21}}&lt;/ref&gt;

Note that with this definition a layer of a latin cube need not be a latin square. In fact, no row, column or file (the cells of a particular position in the different layers) need be a [[permutation]] of the ''n'' symbols.&lt;ref&gt;In the combinatorialist's preferred definition, each row, column and file would contain a permutation of the symbols, but this is only a special type of latin cube called a ''permutation cube''.&lt;/ref&gt;

A latin cube of order ''n'' is equivalent to a 2-(''n'', 4, ''n'') orthogonal array.&lt;ref name="Dénes 1974 loc=pg. 191"/&gt;

Two latin cubes of order ''n'' are ''orthogonal'' if, among the ''n''&lt;sup&gt;3&lt;/sup&gt; pairs of elements chosen from corresponding cells of the two cubes, each distinct ordered pair of the elements occurs exactly ''n'' times.

A set of ''k''&amp;nbsp;−&amp;nbsp;3 mutually orthogonal latin cubes of order ''n'' is equivalent to a 2-(''n'', ''k'', ''n'') orthogonal array.&lt;ref name="Dénes 1974 loc=pg. 191"/&gt;

An example of a pair of mutually orthogonal latin cubes of order three was given as the 2-(3,5,3) orthogonal array in the [[#Examples|Examples]] section above.

Unlike the case with latin squares, in which there are no constraints, the indexing columns of the orthogonal array representation of a latin cube must be selected so as to form a 3-(''n'',3,1) orthogonal array.

===Latin hypercubes===

An ''m''-dimensional '''latin hypercube''' of order ''n'' of the ''r''th class is an ''n'' × ''n'' × ... ×''n'' ''m''-dimensional matrix having ''n''&lt;sup&gt;''r''&lt;/sup&gt; distinct elements, each repeated ''n''&lt;sup&gt;''m''&amp;nbsp;−&amp;nbsp;''r''&lt;/sup&gt; times, and such that each element occurs exactly ''n'' &lt;sup&gt;''m''&amp;nbsp;−&amp;nbsp;''r''&amp;nbsp;−&amp;nbsp;1&lt;/sup&gt; times in each of its ''m'' sets of ''n'' parallel (''m''&amp;nbsp;−&amp;nbsp;1)-dimensional linear subspaces (or "layers"). Two such latin hypercubes of the same order ''n'' and class ''r'' with the property that, when one is superimposed on the other, every element of the one occurs exactly ''n''&lt;sup&gt;''m''&amp;nbsp;−&amp;nbsp;2''r''&lt;/sup&gt; times with every element of the other, are said to be ''orthogonal''.&lt;ref&gt;{{harvnb|Dénes|Keedwell|1974|loc=pg. 189}}&lt;/ref&gt;

A set of ''k''&amp;nbsp;−&amp;nbsp;''m'' mutually orthogonal ''m''-dimensional latin hypercubes of order ''n'' is equivalent to a 2-(''n'', ''k'', ''n''&lt;sup&gt;''m''&amp;nbsp;−&amp;nbsp;2&lt;/sup&gt;) orthogonal array, where the indexing columns form an ''m''-(''n'', ''m'', 1) orthogonal array.

==History==
The concepts of [[latin square]]s and [[mutually orthogonal latin square]]s were generalized to latin cubes and hypercubes, and orthogonal latin cubes and hypercubes by {{harvtxt|Kishen|1942}}.&lt;ref&gt;{{harvnb|Raghavarao|1988|loc=pg. 9}}&lt;/ref&gt; {{harvtxt|Rao|1946}} generalized these results to strength ''t''. The present notion of orthogonal array as a generalization of these ideas, due to [[C. R. Rao]], appears in {{harvtxt|Rao|1947}}.&lt;ref&gt;{{harvnb|Raghavarao|1988|loc=pg. 10}}&lt;/ref&gt;

==Other constructions==

===Hadamard matrices===

If there exists an [[Hadamard matrix]] of order 4''m'', then there exists a 2-(2, 4''m''&amp;nbsp;−&amp;nbsp;1, ''m'') orthogonal array.

Let ''H'' be an Hadamard matrix of order 4''m'' in standardized form (first row and column entries are all +1). Delete the first row and take the [[transpose]] to obtain the desired orthogonal array.&lt;ref&gt;{{harvnb|Stinson|2003|loc=pg. 225, Theorem 10.2}}&lt;/ref&gt;

The order 8 standardized Hadamard matrix below (±1 entries indicated only by sign),
{| class="wikitable"
|-
| + || + || + || + || + || + || + || +
|-
| + || + || + || + || − || − || − || −
|-
| + || + || − || − || + || + || − || −
|-
| + || + || − || − || − || − || + || +
|-
| + || − || + || − || + || − || + || −
|-
| + || − || + || − || − || + || − || +
|-
| + || − || − || + || + || − || − || +
|-
| + || − || − || + || − || + || + || −
|}

produces the 2-(2,7,2) orthogonal array:&lt;ref&gt;{{harvnb|Stinson|2003|loc=pg. 226, Example 10.3}}&lt;/ref&gt;
{| class="wikitable"
|-
| + || + || + || + || + || + || +
|-
| + || + || + || − || − || − || −
|-
| + || − || − || + || + || − || −
|-
| + || − || − || − || − || + || +
|-
| − || + || − || + || − || + || −
|-
| − || + || − || − || + || − || +
|-
| − || − || + || + || − || − || +
|-
| − || − || + || − || + || + || −
|}
Using columns 1, 2 and 4 as indexing columns, the remaining columns produce four mutually orthogonal latin cubes of order 2.

===Codes===

Let ''C'' ⊆ ('''F'''&lt;sub&gt;''q''&lt;/sub&gt;)&lt;sup&gt;''n''&lt;/sup&gt;, be a [[linear code]] of dimension ''m'' with minimum distance ''d''. Then ''C''&lt;sup&gt;⊥&lt;/sup&gt; (the orthogonal complement of the vector subspace ''C'') is a (linear) (''d''&amp;nbsp;−&amp;nbsp;1)-(''n'', ''q'', λ) orthogonal array where &lt;br&gt; λ&amp;nbsp;=&amp;nbsp;''q''&lt;sup&gt;''n''&amp;nbsp;−&amp;nbsp;''m''&amp;nbsp;−&amp;nbsp;''d''&amp;nbsp;+&amp;nbsp;1&lt;/sup&gt;.&lt;ref&gt;{{harvnb|Stinson|2003|loc=pg. 231, Theorem 10.17}}&lt;/ref&gt;

==Applications==

===Threshold schemes===
{{main|Secret sharing}}

[[Secret sharing]] (also called '''secret splitting''') consists of methods for distributing a ''[[secrecy|secret]]'' amongst a group of participants, each of whom is allocated a ''share'' of the secret. The secret can be reconstructed only when a sufficient number of shares, of possibly different types, are combined together; individual shares are of no use on their own. A secret sharing scheme is ''perfect'' if every collection of participants that does not meet the criteria for obtaining the secret, has no additional knowledge of what the secret is than does an individual with no share.

In one type of secret sharing scheme there is one ''dealer'' and ''n'' ''players''. The dealer gives shares of a secret to the players, but only when specific conditions are fulfilled will the players be able to reconstruct the secret. The dealer accomplishes this by giving each player a share in such a way that any group of ''t'' (for ''threshold'') or more players can together reconstruct the secret but no group of fewer than ''t'' players can. Such a system is called a (''t'',&amp;nbsp;''n'')-threshold scheme.

A ''t''-(''v'', ''n'' + 1, 1) orthogonal array may be used to construct a perfect (''t'', ''n'')-threshold scheme.&lt;ref&gt;{{harvnb|Stinson|2003|loc=pg. 262, Theorem 11.5}}&lt;/ref&gt;

:Let ''A'' be the orthogonal array. The first ''n'' columns will be used to provide shares to the players, while the last column represents the secret to be shared. If the dealer wishes to share a secret ''S'', only the rows of ''A'' whose last entry is ''S'' are used in the scheme. The dealer randomly selects one of these rows, and hands out to player ''i'' the entry in this row in column ''i'' as shares.

===Factorial designs===
{{main|Factorial experiment}}
A [[factorial experiment]] is a statistically structured experiment in which several ''factors'' (watering levels, antibiotics, fertilizers, etc.) are applied to each experimental unit at varying (but integral) ''levels'' (high, low, or various intermediate levels).&lt;ref&gt;{{harvnb|Street|Street|1987|loc=pg. 194, Section 9.2}}&lt;/ref&gt; In a ''full factorial experiment'' all combinations of levels of the factors need to be tested, but to minimize confounding influences the levels should be varied within any experimental run.

An orthogonal array of strength 2 can be used to design a factorial experiment. The columns represent the various factors and the entries are the levels that the factors can be applied at (assuming that all factors can be applied at the same number of levels). An experimental run is a row of the orthogonal array, that is, apply the corresponding factors at the levels which appear in the row. When using one of these designs, the treatment units and trial order should be randomized as much as the design allows. For example, one recommendation is that an appropriately sized orthogonal array be randomly selected from those available, then randomize the run order.

===Quality control===

Orthogonal arrays played a central role in the development of [[Taguchi methods]] by [[Genichi Taguchi]], which took place during his visit to [[Indian Statistical Institute]] in early 1950s. His methods were successfully applied and adopted by Japanese and Indian industries and subsequently were also embraced by US industry albeit with some reservations.

===Testing===
'''Orthogonal array testing''' is a [[black box testing]] technique which is a systematic, [[statistical]] way of [[software testing]].&lt;ref name="Pressman, p. 446"&gt;{{cite book |last=Pressman |first=Roger S |title=Software Engineering: A Practitioner's Approach |edition=6th |publisher=McGraw–Hill |year=2005 |isbn=0-07-285318-2}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://paportal.phadkeassociates.net/learning.aspx |title=Planning Efficient Software Tests |first=Madhav S |last=Phadke |publisher=Phadke Associates, Inc. |quote=Numerous articles on utilizing Orthogonal Arrays for Software and System Testing.}}&lt;/ref&gt; It is used when the number of inputs to the system is relatively small, but too large to allow for exhaustive testing of every possible input to the [[software system|systems]].&lt;ref name="Pressman, p. 446" /&gt; It is particularly effective in finding errors associated with faulty [[logic]] within [[computer]] [[software systems]].&lt;ref name="Pressman, p. 446" /&gt; Orthogonal arrays can be applied in [[user interface]] testing, [[system testing]], [[Regression analysis|regression]] testing and [[Performance test (assessment)|performance testing]].
The [[permutations]] of factor levels comprising a single treatment are so chosen that their responses are uncorrelated and hence each treatment gives a unique piece of [[information]]. The net effect of organizing the experiment in such treatments is that the same piece of information is gathered in the minimum number of [[experiment]]s.

==See also==

* [[Combinatorial design]]
* [[Latin square]]s
* [[Latin hypercube sampling]]
* [[Graeco-Latin square]]s

==Notes==
{{reflist}}

==References==
* {{cite book |last1=Box|first1= G. E. P.|last2= Hunter|first2= W. G.|last3=Hunter|first3= J. S.| year=1978|title=Statistics for Experimenters: An Introduction to Design, Data Analysis, and Model Building|publisher=John Wiley and Sons}}
* {{citation|last1=Dénes|first1=J.|last2=Keedwell|first2=A. D.|title=Latin squares and their applications|publisher=Academic Press  |location=New York-London|year=1974|mr=351850|isbn=0-12-209350-X}}
* {{citation|first1=A.S.|last1=Hedayat|first2=N.J.A. |last2=Sloane|first3=J.|last3=Stufken|title=Orthogonal arrays, theory and applications|publisher=Springer|place=New York|year=1999}}
* {{citation|first=K.|last=Kishen|year=1942|title=On latin and hyper-graeco cubes and hypercubes|journal=Current Science|volume=11|pages=98–99}}
* {{citation|first=K.|last=Kishen|year=1950|title=On the construction of latin and hyper-graeco-latin cubes and hypercubes|journal=J. Indian Soc. Agric. Statistics|volume=2|pages=20–48}}
* {{cite book
|title=Constructions and Combinatorial Problems in Design of Experiments
|authorlink=Damaraju Raghavarao|last=Raghavarao|first= Damaraju|ref=harv
|location=New York
|year=1988
|edition=corrected reprint of the 1971 Wiley
|publisher=Dover
}}
* {{cite book
|title=Block Designs: Analysis, Combinatorics and Applications
|author=[[Damaraju Raghavarao|Raghavarao, Damaraju]] and Padgett, L.V.
|location=
|year=2005
|edition=
|publisher=World Scientific
}}
*{{citation|first=C.R.|last=Rao|year=1946|title=Hypercubes of strength &lt;nowiki&gt;''d''&lt;/nowiki&gt; leading to confounded designs in factorial experiments|journal=Bull. Calcutta Math. Soc.|volume=38|pages=67–78}}
*{{citation|first=C.R.|last=Rao|year=1947|title=Factorial experiments derivable from combinatorial arrangements of arrays|journal=J. R. Stat. Soc. Suppl.|volume=9|pages=128–139}}
* {{citation|last=Stinson|first=Douglas R.|title=Combinatorial Designs: Constructions and Analysis|year=2003|publisher=Springer|location=New York|isbn=0-387-95487-2}}
* {{cite book
|last1=Street|first1= Anne Penfold|author1-link=Anne Penfold Street  |last2=Street|first2= Deborah J.|ref=harv
 |lastauthoramp=yes |title=Combinatorics of Experimental Design
|publisher=Oxford U. P. [Clarendon]
|year=1987
|pages=400+xiv
|isbn=0-19-853256-3
}}

==External links==
*[http://www.itl.nist.gov/div898/handbook/pri/section3/pri3323.htm Hyper-Graeco-Latin square designs]
*[http://support.sas.com/documentation/cdl/en/qcug/59658/HTML/default/fac_details_sect23.htm A SAS example using PROC FACTEX]
*[http://support.sas.com/techsup/technote/ts723.html Kuhfeld, Warren F. "Orthogonal Arrays". SAS Institute Inc. SAS provides a catalog of over 117,000 orthogonal arrays.]
{{Experimental design}}
{{NIST-PD}}

[[Category:Combinatorics]]
[[Category:Design of experiments]]
[[Category:Latin squares]]
[[Category:Design theory]]</text>
      <sha1>ni1h01ycfyeqf69084mjjy5xxskus0d</sha1>
    </revision>
  </page>
  <page>
    <title>Photolith film</title>
    <ns>0</ns>
    <id>45097232</id>
    <revision>
      <id>761061528</id>
      <parentid>729319468</parentid>
      <timestamp>2017-01-20T17:23:25Z</timestamp>
      <contributor>
        <username>Edward</username>
        <id>4261</id>
      </contributor>
      <comment>fix spelling mistake: tranparent -&gt; transparent</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1928">{{refimprove|date=March 2015}}
[[File:Navrh_plosny_spoj_vyroba.png|thumb| A photolitah film as used in PCB-s [[contact copier]]s.]]

A '''photolith film'''&lt;ref&gt;[http://www.merriam-webster.com/dictionary/photolith Photolith dictionary definition]&lt;/ref&gt; is a transparent film, made with some sort of transparent plastic (formerly made of [[acetate]]). Nowadays, with the use of laser printers and computers, the photolith film can be based on polyester, vegetable paper or laser film paper. It is mainly used in all [[photolithography]] processes.

A color image, or polychromatic, is divided into four basic colors: [[cyan]], the [[magenta]], the [[yellow]] and [[black]] (the so-called system [[CMYK]] (short name from ''cyan'', '' magenta '', '' yellow '' and '' black ''), generating four photolith film images, a photo filtered with each of the three basic colors plus a B&amp;W film (addition of the three). For black-and-white images, such as text or simple logos, only one photolith film is needed.

The ''photolith film'' it is sometimes recorded by an optical laser process on an ''[[imagesetter]]'' machine, coming from a digital file, or by a photographic process in a [[contact copier]], if a physical copy of the original already exist. In the old offset printing plates acquire text or images to be printed after being sensitized from a photolith film.

The photolith films, as well as vegetable and the ''laser'' films, are used to store plates, screens or other media sensitive to [[light]] as a backup for repeating their processes in the future. They normally store the information of the three or four separated [[colour]]s on monochrome photolith films.

==See also==
* [[Azo compound]]
* [[Contact copier]]
* [[Ozalid]]
* [[Diazo copier]]

==References==
{{reflist}}

[[Category:Animation techniques]]
[[Category:Non-impact printing]]
[[Category:Technical drawing]]
[[Category:Infographics]]

{{technology-stub}}</text>
      <sha1>q5z8xtuykxsnxp20kp6b731z4qw6ks0</sha1>
    </revision>
  </page>
  <page>
    <title>Recursive function</title>
    <ns>0</ns>
    <id>5987264</id>
    <revision>
      <id>817180267</id>
      <parentid>817180173</parentid>
      <timestamp>2017-12-26T18:33:52Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* top */ typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="617">'''Recursive function''' may refer to:
*[[Recursive function (programming)]], a procedure or subroutine that references itself
*[[Recursive function (computability)]], a member of a class of functions defined over the integers, which may be used for defining what is computable
** [[Primitive recursive function]] a subclass of the preceding

==See also==

*[[Recurrence relation]], in mathematics, an equation that defines a sequence recursively
*Recursion theory or [[computability theory]], a branch of mathematical logic, of computer science, and of the theory of computation

{{disambig}}

[[Category:Recursion]]</text>
      <sha1>cl1fmrfy7oqux2x6fody98q1x0zzbox</sha1>
    </revision>
  </page>
  <page>
    <title>Register machine</title>
    <ns>0</ns>
    <id>505218</id>
    <revision>
      <id>858401707</id>
      <parentid>858401697</parentid>
      <timestamp>2018-09-06T22:44:11Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:Headbomb|Headbomb]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47200">{{multiple issues|
{{lead too short|date=August 2011}}
{{Tone|date=August 2009}}
}}

In [[mathematical logic]] and [[theoretical computer science]] a '''register machine''' is a generic class of [[abstract machine]]s used in a manner similar to a [[Turing machine]]. All the models are [[Turing completeness|Turing equivalent]].

==Overview==
The register machine gets its name from its use of one or more "[[Processor register|registers]]".  In contrast to the tape and head used by a Turing machine, the model uses '''multiple, uniquely addressed registers''', each of which holds a single positive [[integer]].

There are at least four sub-classes found in literature, here listed from most primitive to the most like a [[computer]]:
* [[Counter machine]] – the most primitive and reduced theoretical model of a computer hardware. Lacks indirect addressing. Instructions are in the finite state machine in the manner of the [[Harvard architecture]].
*[[Pointer machine]]  – a blend of counter machine and RAM models. Less common and more abstract than either model. Instructions are in the finite state machine in the manner of the Harvard architecture.
*[[Random-access machine]] (RAM) – a counter machine with indirect addressing and, usually, an augmented instruction set. Instructions are in the finite state machine in the manner of the Harvard architecture.
*[[Random-access stored-program machine]] model (RASP) – a RAM with instructions in its registers analogous to the [[Universal Turing machine]]; thus it is an example of the [[von Neumann architecture]]. But unlike a computer, the model is ''idealized'' with effectively infinite registers (and if used, effectively infinite special registers such as an accumulator). Unlike a computer or even [[Reduced instruction set computing|RISC]]{{Dubious|date=February 2017}}, the instruction set is much reduced in number.

Any properly defined register machine model is [[Turing completeness|Turing equivalent]]. Computational speed is very dependent on the model specifics.

In practical computer science, a similar concept known as a [[virtual machine]] is sometimes used to minimise dependencies on underlying machine architectures.  Such machines are also used for teaching.  The term "register machine" is sometimes used to refer to a virtual machine in textbooks.&lt;ref&gt;[[Harold Abelson]] and [[Gerald Jay Sussman]] with Julie Sussman, [[Structure and Interpretation of Computer Programs]], [[MIT Press]], [[Cambridge, Massachusetts]], 2nd Ed, 1996&lt;/ref&gt;

== Formal definition ==
:''No standard terminology exists; each author is responsible for defining in prose the meanings of their mnemonics or symbols. Many authors use a "register-transfer"-like symbolism to explain the actions of their models, but again they are responsible for defining its syntax.''

A register machine consists of:

#'''An unbounded number of labeled, discrete, unbounded registers unbounded in extent (capacity)''': a finite (or infinite in some models) set of registers &lt;math&gt;r_0 \ldots r_n&lt;/math&gt; each considered to be of infinite extent and each of which holds a single non-negative integer (0, 1, 2, ...).&lt;ref&gt;". . . a denumerable sequence of registers numbered 1, 2, 3, ..., each of which can sto3e any natural number 0, 1, 2, .... Each particular program, however, involves only a finite number of these registers, the others remaining empty (i.e. containing 0) throughout the computation." Shepherdson and Sturgis 1961:219. Lambek 1961:295 proposed: "a countably infinite set of ''locations'' (holes, wires, etc).&lt;/ref&gt; The registers may do their own arithmetic, or there may be one or more special registers that do the arithmetic e.g. an "accumulator" and/or "address register". ''See also [[Random-access machine]].''
#'''Tally counters or marks''':&lt;ref&gt;For example, Lambek 1961:295 proposed the use of pebbles, beads, etc.&lt;/ref&gt; discrete, indistinguishable objects or marks of only one sort suitable for the model. In the most-reduced [[counter machine]] model, per each arithmetic operation only one object/mark is either added to or removed from its location/tape. In some counter machine models (e.g. Melzak (1961), Minsky (1961)) and most RAM and RASP models more than one object/mark can be added or removed in one operation with "addition" and usually "subtraction"; sometimes with "multiplication" and/or "division". Some models have control operations such as "copy" (variously: "move", "load", "store") that move "clumps" of objects/marks from register to register in one action.
#'''A (very) limited set of instructions''': the instructions tend to divide into two classes: arithmetic and control. The instructions are drawn from the two classes to form "instruction-sets", such that an instruction set must allow the model to be [[Turing completeness|Turing equivalent]] (it must be able to compute any [[partial recursive function]]).
##'''Arithmetic''': arithmetic instructions may operate on all registers or on just a special register (e.g. accumulator). They are ''usually'' chosen from the following sets (but exceptions abound):
##*Counter machine: { Increment (r), Decrement (r), Clear-to-zero (r) }
##*Reduced RAM, RASP: { Increment (r), Decrement (r), Clear-to-zero (r), Load-immediate-constant k, Add (r&lt;sub&gt;1&lt;/sub&gt;,r&lt;sub&gt;2&lt;/sub&gt;), proper-Subtract (r&lt;sub&gt;1&lt;/sub&gt;,r&lt;sub&gt;2&lt;/sub&gt;), Increment accumulator, Decrement accumulator, Clear accumulator, Add to accumulator contents of register r, proper-Subtract from accumulator contents of register r, }
##*Augmented RAM, RASP: All of the reduced instructions plus: { Multiply, Divide, various Boolean bit-wise (left-shift, bit test, etc.)}
##'''Control''':
##*Counter machine models: optional { Copy (r&lt;sub&gt;1&lt;/sub&gt;,r&lt;sub&gt;2&lt;/sub&gt;) }
##*RAM and RASP models: most have { Copy (r&lt;sub&gt;1&lt;/sub&gt;,r&lt;sub&gt;2&lt;/sub&gt;) }, or { Load Accumulator from r, Store accumulator into r, Load Accumulator with immediate constant }
##*All models: at least one ''conditional "jump"'' (branch, goto) following test of a register e.g. { Jump-if-zero, Jump-if-not-zero (i.e. Jump-if-positive), Jump-if-equal, Jump-if-not equal  }
##*All models optional: { unconditional program jump (goto) }
##'''Register-addressing method''':
##*Counter machine: no indirect addressing, immediate operands possible in highly atomized models
##*RAM and RASP: indirect addressing available, immediate operands typical
##'''Input-output''': optional in all models
#'''State register''': A special Instruction Register "IR", finite and separate from the registers above, stores the current instruction to be executed and its address in the TABLE of instructions; this register and its TABLE is located in the finite state machine.
#*The IR is off-limits to all models. In the case of the RAM and RASP, for purposes of determining the "address" of a register, the model can select either (i) in the case of direct addressing—the address specified by the TABLE and temporarily located in the IR or (ii) in the case of indirect addressing—the contents of the register specified by the IR's instruction.
#*The IR is ''not'' the "program counter" (PC) of the RASP (or conventional [[computer]]). The PC is just another register similar to an accumulator, but dedicated to holding the number of the RASP's current register-based instruction. Thus a RASP has ''two'' "instruction/program" registers—(i) the IR (finite state machine's Instruction Register), and (ii) a PC (Program Counter) for the program located in the registers. (As well as a register dedicated to "the PC", a RASP may dedicate another register to "the Program-Instruction Register" (going by any number of names such as "PIR, "IR", "PR", etc.)
#'''List of labeled instructions, usually in sequential order''': A finite list of instructions &lt;math&gt;I_1 \ldots I_m&lt;/math&gt;. In the case of the counter machine, random-access machine (RAM) and pointer machine the instruction store is in the "TABLE" of the finite state machine; thus these models are example of the [[Harvard architecture]]. In the case of the RASP the program store is in the registers; thus this is an example of the [[von Neumann architecture]]. ''See also Random-access machine and [[Random-access stored-program machine]].''&lt;br&gt;Usually, like [[computer program]]s, the instructions are listed in sequential order; unless a jump is successful the default sequence continues in numerical order. An exception to this is the abacus (Lambek (1961), Minsky (1961)) counter machine models—every instruction has at least one "next" instruction identifier "z", and the conditional branch has two.
#*Observe also that the abacus model combines two instructions, JZ then DEC: e.g. { INC ( r, z ), JZDEC ( r, z&lt;sub&gt;true&lt;/sub&gt;, z&lt;sub&gt;false&lt;/sub&gt; ) }.&lt;br&gt;See [[McCarthy Formalism]] for more about the ''conditional expression'' "IF r=0 THEN z&lt;sub&gt;true&lt;/sub&gt; ELSE  z&lt;sub&gt;false&lt;/sub&gt;" (cf McCarthy (1960)).

== Historical development of the register machine model ==

Two trends appeared in the early 1950s—the first to characterize the [[computer]] as a [[Turing machine]], the second to define computer-like models—models with sequential instruction sequences and conditional jumps—with the power of a Turing machine, i.e. a so-called [[Turing completeness|Turing equivalence]].  Need for this work was carried out in context of two "hard" problems: the unsolvable word problem posed by [[Emil Post]]—his problem of "tag"—and the very "hard" problem of [[Hilbert's problems]]—the 10th question around [[Diophantine equation]]s. Researchers were questing for Turing-equivalent models that were less "logical" in nature and more "arithmetic" (cf Melzak (1961) p.&amp;nbsp;281, Shepherdson–Sturgis (1963) p.&amp;nbsp;218).

The first trend—toward characterizing computers—seems to have originated&lt;ref&gt;See the "Note" in Shepherdson and Sturgis 1963:219. In their Appendix A the authors follow up with a listing and discussions of Kaphengst's, Ershov's and Péter's instruction sets (cf p. 245ff).&lt;/ref&gt; with [[Hans Hermes]] (1954), [[Rózsa Péter]] (1958), and [[Heinz Kaphengst]] (1959), the second trend with [[Hao Wang (academic)|Hao Wang]] (1954, 1957) and, as noted above, furthered along by [[Zdzislaw Alexander Melzak]] (1961), [[Joachim Lambek]] (1961), [[Marvin Minsky]] (1961, 1967), and [[John Shepherdson]] and [[Howard E. Sturgis]] (1963).

The last five names are listed explicitly in that order by [[Yuri Matiyasevich]]. He follows up with:
:"Register machines [some authors use "register machine" synonymous with "counter-machine"] are particularly suitable for constructing Diophantine equations. Like Turing machines, they have very primitive instructions and, in addition, they deal with numbers" (Yuri Matiyasevich (1993), ''Hilbert's Tenth Problem'', commentary to Chapter 5 of the book, at http://logic.pdmi.ras.ru/yumat/H10Pbook/commch_5htm. )

It appears that Lambek, Melzak, Minsky and Shepherdson and Sturgis independently anticipated the same idea at the same time. See Note On Precedence below.

The history begins with Wang's model.

=== (1954, 1957) Wang's model: Post–Turing machine ===
Wang's work followed from [[Emil Post]]'s (1936) paper and led Wang to his definition of his [[Wang B-machine]]—a two-symbol [[Post–Turing machine]] computation model with only four atomic instructions:
:{ LEFT, RIGHT, PRINT, JUMP_if_marked_to_instruction_z }

To these four both Wang (1954, 1957) and then C.Y. Lee (1961) added another instruction from the Post set { ERASE }, and then a Post's unconditional jump { JUMP_to_ instruction_z } (or to make things easier, the conditional jump JUMP_IF_blank_to_instruction_z, or both. Lee named this a "W-machine" model:
:{ LEFT, RIGHT, PRINT, ERASE, JUMP_if_marked, [maybe JUMP or JUMP_IF_blank] }

Wang expressed hope that his model would be "a rapprochement" (p.&amp;nbsp;63) between the theory of Turing machines and the practical world of the computer.

Wang's work was highly influential. We find him referenced by Minsky (1961) and (1967), Melzak (1961), Shepherdson and Sturgis (1963). Indeed, Shepherdson and Sturgis (1963) remark that:
:"...we have tried to carry a step further the 'rapprochement' between the practical and theoretical aspects of computation suggested by Wang" (p. 218)

[[Martin Davis]] eventually evolved this model into the (2-symbol) Post–Turing machine.

'''Difficulties with the Wang/Post–Turing model''':

Except there was a problem: the Wang model (the six instructions of the 7-instruction Post–Turing machine) was still a single-tape Turing-like device, however nice its ''sequential program instruction-flow'' might be. Both Melzak (1961) and Shepherdson and Sturgis (1963) observed this (in the context of certain proofs and investigations):

:"...a Turing machine has a certain opacity... a Turing machine is slow in (hypothetical) operation and, usually, complicated. This makes it rather hard to design it, and even harder to investigate such matters as time or storage optimization or a comparison between efficiency of two algorithms. (Melzak (1961) p. 281)

:"...although not difficult ... proofs are complicated and tedious to follow for two reasons: (1) A Turing machine has only head so that one is obliged to break down the computation into very small steps of operations on a single digit. (2) It has only one tape so that one has to go to some trouble to find the number one wishes to work on and keep it separate from other numbers" (Shepherdson and Sturgis (1963) p. 218).

Indeed, as examples at [[Turing machine examples]], Post–Turing machine and [[partial function]] show, the work can be "complicated".
&lt;!-- Example: Multiply '''a''' x '''b''' = '''c''', for example: 3 x 4 = 12.

The scanned square is indicated by brackets around the mark i.e. ['''1''']. An extra mark serves to indicate the symbol "0".

At the start of a computation, just as Shepherdson–Sturgis and Melzak complain, we see the variables expressed in unary—i.e. the tally marks for '''a'''= '''| | | |''' and '''b''' = '''| | | | |''' – "in a line" (concatenated on what Melzak calls a "linear tape"). Space must be available for '''c''' at the end of the computation, extending without bounds to the right:
{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="14.4" Height="11.4" |
| width="13.8" |
| width="13.8" |
| width="13.8" | top
| width="13.8" | a
| width="13.8" | a
| width="13.8" | a
| width="13.8" |
| width="13.8" | top
| width="13.8" | b
| width="13.8" | b
| width="13.8" | b
| width="15.6" | b
| width="13.8" |
| width="13.8" | btm
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" |
| width="13.8" |
| width="13.8" |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="11.4" |
 |
 |
|style="background-color:#FFFF99" | [1]
|style="background-color:#FFFF99" | 1
|style="background-color:#FFFF99" | 1
|style="background-color:#FFFF99" | 1
 |
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|}

At the end of the computation the multiplier '''b''' is 5 marks "in a line" (i.e. concatenated) to left of the 13 marks of product '''c'''.
{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="14.4" Height="11.4" |
| width="13.8" |
| width="13.8" |
| width="13.8" | top
| width="13.8" | a
| width="13.8" | a
| width="13.8" | a
| width="13.8" |
| width="13.8" | top
| width="13.8" | b
| width="13.8" | b
| width="13.8" | b
| width="15.6" | b
| width="13.8" |
| width="16.8" | btm
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
| width="13.8" | c
|- style="font-size:9pt" align="center" valign="bottom"
| Height="11.4" |
 |
 |
 |
 |
 |
 |
 |
|style="background-color:#CCFFCC" | [1]
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
 |
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
|style="background-color:#99CCFF" | 1
 |
 |
 |
|}--&gt;

===Minsky, Melzak-Lambek and Shepherdson–Sturgis models "cut the tape" into many===
So why not 'cut the tape' so each is infinitely long (to accommodate any size integer) but left-ended, and call these three tapes "Post–Turing (i.e. Wang-like) tapes"? The individual heads will move left (for decrement) and right (for increment). In one sense the heads indicate "the tops of the stack" of concatenated marks. Or in Minsky (1961) and Hopcroft and Ullman (1979, p.&amp;nbsp;171ff) the tape is always blank except for a mark at the left end—at no time does a head ever print or erase.

We just have to be careful to write our instructions so that a test-for-zero and jump occurs ''before'' we decrement otherwise our machine will "fall off the end" or "bump against the end"—we will have an instance of a [[partial function]]. Before a decrement our machine must always ask the question: "Is the tape/counter empty? If so then I can't decrement, otherwise I can."

:''For an example of (im-) proper subtraction see [[Partial function]].''

Minsky (1961) and Shepherdson–Sturgis (1963) prove that only a few tapes—as few as one—still allow the machine to be Turing equivalent ''IF'' the data on the tape is represented as a [[Gödel number]] (or some other uniquely encodable-decodable number); this number will evolve as the computation proceeds. In the one tape version with Gödel number encoding the counter machine must be able to (i) multiply the Gödel number by a constant (numbers "2" or "3"), and (ii) divide by a constant (numbers "2" or "3") and jump if the remainder is zero. Minsky (1967) shows that the need for this bizarre instruction set can be relaxed to { INC (r), JZDEC (r, z) } and the convenience instructions { CLR (r), J (r) } if two tapes are available. A simple Gödelization is still required, however. A similar result appears in Elgot–Robinson (1964) with respect to their RASP model.
&lt;!-- To do a multiplication algorithm we don't need the extra mark to indicate "0", but we will need an extra "temporary" tape '''t'''.  And we will need an extra "blank/zero" register (e.g. register #0) for an unconditional jump:

{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
|style="font-weight:bold" width="83.4" Height="12" | At  the start:
| width="16.8" |
| width="15" |
| width="16.2" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
| width="15" |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | register 0:
|style="font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | a = register 1:
|style="background-color:#FFFF99" | 1
|style="background-color:#FFFF99" | 1
|style="background-color:#FFFF99" | 1
|style="background-color:#FFFF99;font-weight:bold" | []
|style="font-weight:bold" |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | b = register 2:
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC;font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | c = register 3:
|style="background-color:#CCFFFF;font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | t = register 4:
|style="font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="3" |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt"
|style="font-weight:bold" Height="12" align="center" valign="bottom" | At the end:
|  valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
| align="center" valign="bottom" |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | register 0:
|style="font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | a = register 1:
|style="background-color:#FFFF99;font-weight:bold" | []
 |
 |
 |
|style="font-weight:bold" |
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | b = register 2:
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC" | 1
|style="background-color:#CCFFCC;font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | c = register 3:
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF" | 1
|style="background-color:#CCFFFF;font-weight:bold" | []
 |
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | t = register 4:
 | 1
 | 1
 | 1
 | 1
|style="font-weight:bold" | []
 |
 |
 |
 |
 |
 |
 |
 |
 |
|}

We can write simple Post–Turing "subroutines" to atomize "increment" and "decrement" into Post–Turing instructions. Note that the head stays always just one square to the right of the top-most printed mark, i.e. at the "top of the stack". "r" is a parameter in the instructions that symbolizes the tape-as-register to be moved and printed or erased, and tested:
:
: "Increment r" = PRINT_SCANNED_SQUARE_of_TAPE_r, MOVE_TAPE_r_LEFT; i.e. (or: move tape r's head right)
::'''X+''' r is equivalent to '''P''' r; '''L''' r
: "Decrement r" = JUMP_IF_TAPE_r_BLANK(ZERO) TO XXX, ELSE MOVE_TAPE_r_RIGHT, ERASE_SCANNED_SQUARE_of_TAPE_rN; (or: move tape r's head left)
::'''X-''' r is equivalent to '''J0''' r, xxx; '''R''' r; '''E''' r

Indeed this is similar to the approach that Minsky (1961) took. He started with 4 left-ended tape-machine that:
: "used the basic arithmetic device of the present paper. Then, two of the tapes were eliminated by the prime-factor method" (p. 438).

He then observed that:
: "we may formulate these results so that the operations act essentially only on the ''length'' of the strings" (his italics, p. 449).

His first model, "1961" (it had changed by 1967) started out with only a single mark at the left end of each tape-as-register. The machine was not allowed to '''P'''rint any marks, just move '''L'''eft or '''R'''ight and test for the mark = "1" in the following example. Thus the conventional Post–Turing-like instruction set went from
: { R; L; P; E; J0 xxx; J1 xxx, H }

to, for each tape-as-register:
: { R; L; J1 xxx, H }

where '''R''' can be renamed '''INC'''rement, '''R''' can be renamed '''DEC'''rement, "J1" can be combined with "DEC" to create a non-atomized instruction, or can be kept separate and renamed '''J'''ump if '''Z'''ero. --&gt;

=== (1961) Melzak's model is different: clumps of pebbles go into and out of holes ===
Melzak's (1961) model is significantly different. He took his own model, flipped the tapes vertically, called them "holes in the ground" to be filled with "pebble counters". Unlike Minsky's "increment" and "decrement", Melzak allowed for proper subtraction of any count of pebbles and "adds" of any count of pebbles.

He defines indirect addressing for his model (p.&amp;nbsp;288) and provides two examples of its use (p.&amp;nbsp;89); his "proof" (p.&amp;nbsp;290-292) that his model is [[Turing completeness|Turing equivalent]] is so sketchy that the reader cannot tell whether or not he intended the indirect addressing to be a requirement for the proof.

Legacy of Melzak's model is Lambek's simplification and the reappearance of his mnemonic conventions in Cook and Reckhow 1973.

=== Lambek (1961) atomizes Melzak's model into the Minsky (1961) model: INC and DEC-with-test ===
Lambek (1961) took Melzak's ternary model and atomized it down to the two unary instructions—X+, X- if possible else jump—exactly the same two that Minsky (1961) had come up with.

However, like the Minsky (1961) model, the Lambek model does execute its instructions in a default-sequential manner—both X+ and X- carry the identifier of the next instruction, and X- also carries the jump-to instruction if the zero-test is successful.

=== Elgot–Robinson (1964) and the problem of the RASP without indirect addressing ===
A RASP or [[random-access stored-program machine]] begins as a counter machine with its "program of instruction" placed in its "registers". Analogous to, but independent of, the finite state machine's "Instruction Register", at least one of the registers (nicknamed the "program counter" (PC)) and one or more "temporary" registers maintain a record of, and operate on, the current instruction's number. The finite state machine's TABLE of instructions is responsible for (i) fetching the current ''program'' instruction from the proper register, (ii) parsing the ''program'' instruction, (iii) fetching operands specified by the ''program '' instruction, and (iv) executing the ''program'' instruction.

Except there is a problem: If based on the ''counter machine'' chassis this computer-like, [[von Neumann]] machine will not be Turing equivalent. It cannot compute everything that is computable. Intrinsically the model is bounded by the size of its (very-) ''finite'' state machine's instructions. The counter machine based RASP can compute any [[primitive recursive function]] (e.g. multiplication) but not all [[mu recursive function]]s (e.g. the [[Ackermann function]] ).

Elgot–Robinson investigate the possibility of allowing their RASP model to "self modify" its program instructions. The idea was an old one, proposed by Burks-Goldstine-von Neumann (1946-7), and sometimes called "the computed goto." Melzak (1961) specifically mentions the "computed goto" by name but instead provides his model with indirect addressing.

'''Computed goto:''' A RASP ''program'' of instructions that modifies the "goto address" in a conditional- or unconditional-jump ''program'' instruction.

But this does not solve the problem (unless one resorts to [[Gödel number]]s). What is necessary is a method to fetch the address of a program instruction that lies (far) "beyond/above" the upper bound of the ''finite'' state machine's instruction register and TABLE.

:Example: A counter machine equipped with only four unbounded registers can e.g. multiply any two numbers ( m, n ) together to yield p—and thus be a primitive recursive function—no matter how large the numbers m and n; moreover, less than 20 instructions are required to do this! e.g. { 1: CLR ( p ), 2: JZ ( m, done ), 3 outer_loop: JZ ( n, done ), 4: CPY ( m, temp ), 5: inner_loop: JZ ( m, outer_loop ), 6: DEC ( m ), 7: INC ( p ), 8: J ( inner_loop ), 9: outer_loop: DEC ( n ), 10 J ( outer_loop ), HALT }

:However, with only 4 registers, this machine has not nearly big enough to build a RASP that can execute the multiply algorithm as a ''program''. No matter how big we build our finite state machine there will always be a ''program'' (including its parameters) which is larger. So by definition the bounded program machine that does not use unbounded encoding tricks such as Gödel numbers cannot be ''universal''.

Minsky (1967) hints at the issue in his investigation of a counter machine (he calls them "program computer models") equipped with the instructions { CLR (r), INC (r), and RPT ("a" times the instructions m to n) }. He doesn't tell us how to fix the problem, but he does observe that:
: "... the program computer has to have some way to keep track of how many RPT's remain to be done, and this might exhaust any particular amount of storage allowed in the finite part of the computer. RPT operations require infinite registers of their own, in general, and they must be treated differently from the other kinds of operations we have considered." (p. 214)

But Elgot and Robinson solve the problem: They augment their P&lt;sub&gt;0&lt;/sub&gt; RASP with an indexed set of instructions—a somewhat more complicated (but more flexible) form of indirect addressing. Their P'&lt;sub&gt;0&lt;/sub&gt; model addresses the registers by adding the contents of the "base" register (specified in the instruction) to the "index" specified explicitly in the instruction (or vice versa, swapping "base" and "index"). Thus the indexing P'&lt;sub&gt;0&lt;/sub&gt; instructions have one more parameter than the non-indexing P&lt;sub&gt;0&lt;/sub&gt; instructions:
: Example: INC ( r&lt;sub&gt;base&lt;/sub&gt;, index ) ; effective address will be [r&lt;sub&gt;base&lt;/sub&gt;] + index, where the natural number "index" is derived from the finite-state machine instruction itself.

=== Hartmanis (1971) ===
By 1971 Hartmanis has simplified the indexing to [[indirection]] for use in his RASP model.

'''Indirect addressing:''' A pointer-register supplies the finite state machine with the address of the target register required for the instruction. Said another way: The ''contents'' of the pointer-register is the ''address'' of the "target" register to be used by the instruction. If the pointer-register is unbounded, the RAM, and a suitable RASP built on its chassis, will be Turing equivalent. The target register can serve either as a source or destination register, as specified by the instruction.

Note that the finite state machine does not have to explicitly specify this target register's address. It just says to the rest of the machine: Get me the contents of the register pointed to by my pointer-register and then do xyz with it. It must specify explicitly by name, via its instruction, this pointer-register (e.g. "N", or "72" or "PC", etc.) but it doesn't have to know what number the pointer-register actually contains (perhaps 279,431).

=== Cook and Reckhow (1973) describe the RAM ===
Cook and Reckhow (1973) cite Hartmanis (1971) and simplify his model to what they call a [[random-access machine]] (RAM—i.e. a machine with indirection and the [[Harvard architecture]]). In a sense we are back to Melzak (1961) but with a much simpler model than Melzak's.

== Precedence ==

Minsky was working at the [[MIT Lincoln Laboratory]] and published his work there; his paper was received for publishing in the ''Annals of Mathematics'' on August 15, 1960 but not published until November 1961. While receipt occurred a full year before the work of Melzak and Lambek was received and published (received, respectively, May and June 15, 1961 and published side-by-side September 1961). That (i) both were Canadians and published in the Canadian Mathematical Bulletin, (ii) neither would have had reference to Minsky's work because it was not yet published in a peer-reviewed journal, but (iii) Melzak references Wang, and Lambek references Melzak, leads one to hypothesize that their work occurred simultaneously and independently.

Almost exactly the same thing happened to Shepherdson and Sturgis. Their paper was received in December 1961—just a few months after Melzak and Lambek's work was received. Again, they had little (at most 1 month) or no benefit of reviewing the work of Minsky. They were careful to observe in footnotes that papers by Ershov, Kaphengst and Peter had "recently appeared" (p.&amp;nbsp;219). These were published much earlier but appeared in the German language in German journals so issues of accessibility present themselves.

The final paper of Shepherdson and Sturgis did not appear in a peer-reviewed journal until 1963. And as they fairly and honestly note in their Appendix A, the 'systems' of Kaphengst (1959), Ershov (1958), Peter (1958) are all so similar to what results were obtained later as to be indistinguishable to a set of the following:
: produce 0 i.e. 0 --&gt; n
: increment a number i.e. n+1 --&gt; n
::"i.e. of performing the operations which generate the natural numbers" (p. 246)
: copy a number i.e. n --&gt; m
: to "change the course of a computation", either comparing two numbers or decrementing until 0

Indeed, Shepherson and Sturgis conclude
::"The various minimal systems are very similar"( p. 246)

By order of ''publishing'' date the work of Kaphengst (1959), Ershov (1958), Peter (1958) were first.

==See also==
{{div col|colwidth=25em}}
* [[Counter machine]]
** [[Counter machine:Reference model]]
** [[Counter-machine model]]
* [[Pointer machine]]
* [[Random-access machine]]
* [[Random-access stored-program machine]]
* [[Turing machine]]
** [[Universal Turing machine]]
** [[Turing machine gallery]]
** [[Turing machine examples]]
* [[Wang B-machine]]
* [[Post–Turing machine]] - description plus examples
* [[Algorithm]]
** [[Algorithm characterizations]]
** [[Algorithm examples]]
* [[Halting problem]]
* [[Busy beaver]]
* [[Stack machine]]
{{div col end}}

== Bibliography ==
'''Background texts:''' The following bibliography of source papers includes a number of texts to be used as background. The mathematics that led to the flurry of papers about abstract machines in the 1950s and 1960s can be found in van Heijenoort (1967)—an assemblage of original papers spanning the 50 years from Frege (1879) to Gödel (1931). Davis (ed.) ''The Undecidable'' (1965) carries the torch onward beginning with Gödel (1931) through Gödel's (1964) postscriptum (p.&amp;nbsp;71); the original papers of [[Alan Turing]] (1936-7) and [[Emil Post]] (1936) are included in ''The Undecidable''. The mathematics of Church, Rosser and Kleene that appear as reprints of original papers in ''The Undecidable'' is carried further in Kleene (1952), a mandatory text for anyone pursuing a deeper understanding of the mathematics behind the machines. Both Kleene (1952) and Davis (1958) are referenced by a number of the papers.

For a good treatment of the counter machine see Minsky (1967) Chapter 11 "Models similar to Digital Computers"—he calls the counter machine a "program computer". A recent overview is found at van Emde Boas (1990). A recent treatment of the Minsky (1961)/Lambek (1961) model can be found Boolos-Burgess-Jeffrey (2002); they reincarnate Lambek's "abacus model" to demonstrate equivalence of Turing machines and partial recursive functions, and they provide a graduate-level introduction to both abstract machine models (counter- and Turing-) and the mathematics of recursion theory. Beginning with the first edition Boolos-Burgess (1970) this model appeared with virtually the same treatment.

'''The papers''': The papers begin with Wang (1957) and his dramatic simplification of the Turing machine.  Turing (1936), Kleene (1952), Davis (1958) and in particular Post (1936) are cited in Wang (1957); in turn, Wang is referenced by Melzak (1961), Minsky (1961) and Shepherdson–Sturgis (1961-3) as they independently reduce the Turing tapes to "counters". Melzak (1961) provides his pebble-in-holes counter machine model with indirection but doesn't carry the treatment further. The work of Elgot–Robinson (1964) define the RASP—the computer-like [[random-access stored-program machine]]s—and appear to be the first to investigate the failure of the bounded [[counter machine]] to calculate the mu-recursive functions. This failure—except with the draconian use of [[Gödel number]]s in the manner of Minsky (1961))—leads to their definition of "indexed" instructions (i.e. indirect addressing) for their RASP model. Elgot–Robinson (1964) and more so Hartmanis (1971) investigate RASPs with self-modifying programs. Hartmanis (1971) specifies an instruction set with indirection, citing lecture notes of Cook (1970). For use in investigations of computational complexity Cook and his graduate student Reckhow (1973) provide the definition of a RAM (their model and mnemonic convention are similar to Melzak's, but offer him no reference in the paper). The pointer machines are an offshoot of Knuth (1968, 1973) and independently Schönhage (1980).

For the most part the papers contain mathematics beyond the undergraduate level—in particular the [[primitive recursive function]]s and [[mu recursive function]]s presented elegantly in Kleene (1952) and less in depth, but useful nonetheless, in Boolos-Burgess-Jeffrey (2002).

All texts and papers excepting the four starred have been witnessed. These four are written in German and appear as references in Shepherdson–Sturgis (1963) and Elgot–Robinson (1964); Shepherdson–Sturgis (1963) offer a brief discussion of their results in Shepherdson–Sturgis' Appendix A. The terminology of at least one paper (Kaphengst (1959) seems to hark back to the Burke-Goldstine-von Neumann (1946-7) analysis of computer architecture.

{|class="wikitable" style="text-align:center; font-size:88%"
|-  style="vertical-align:bottom;"
! style="width:114.6;"| Author
! style="width:43.2;"| Year
! style="width:46.8;"| Reference
! style="width:41.4;"| Turing machine
! style="width:43.2;"| Counter machine
! style="width:27.6;"| RAM
! style="width:28.2;"| RASP
! style="width:38.4;"| Pointer machine
! style="width:54px;"| Indirect addressing
! style="width:43.8;"| Self-modifying program
|-  style="vertical-align:bottom;"
| style="text-align:left" | Goldstine &amp; von Neumann
| 1947
| X
|
|
|
|
|
|
| X
|-  style="vertical-align:bottom;"
| style="text-align:left" | Kleene
| 1952
| X
|
|
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | *Hermes
| 1954, 5
|
|
| ?
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Wang
| 1957
| X
| X
| hints
|
|
|
| hints
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | *Peter
| 1958
|
|
| ?
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Davis
| 1958
| X
| X
|
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | *Ershov
| 1959
|
|
| ?
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | *Kaphengst
| 1959
|
|
| ?
|
| X
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Melzak
| 1961
|
|
| X
|
|
|
| X
| hints
|-  style="vertical-align:bottom;"
| style="text-align:left" | Lambek
| 1961
|
|
| X
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Minsky
| 1961
|
|
| X
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Shepherdson &amp; Sturgis
| 1963
|
|
| X
|
|
|
| hints
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Elgot &amp; Robinson
| 1964
|
|
|
|
| X
|
| X
| X
|-  style="vertical-align:bottom;"
| style="text-align:left" | Davis- Undecidable
| 1965
| X
| X
|
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | van Heijenoort
| 1967
| X
|
|
|
|
|
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Minsky
| 1967
|
|
| X
| hints
|
|
| hints
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Knuth
| 1968, 73
| X
|
|
|
|
| X
| X
| X
|-  style="vertical-align:bottom;"
| style="text-align:left" | Hartmanis
| 1971
|
|
|
|
| X
|
|
| X
|-  style="vertical-align:bottom;"
| style="text-align:left" | Cook &amp; Reckhow
| 1973
|
|
|
| X
| X
|
| X
| X
|-  style="vertical-align:bottom;"
| style="text-align:left" | Schonhage
| 1980
|
|
|
| X
|
| X
| X
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | van Emde Boas
| 1990
| X
| X
| X
| X
| X
| X
|
|
|-  style="vertical-align:bottom;"
| style="text-align:left" | Boolos &amp; Burgess; Boolos, Burgess &amp; Jeffrey
| 1970–2002
| X
| X
| X
|
|
|
|
|
|}

==References==
'''Notes'''
{{reflist}}
'''Sources'''
{{refbegin}}
* [[George Boolos]], [[John P. Burgess]], [[Richard Jeffrey]] (2002), ''Computability and Logic: Fourth Edition'', Cambridge University Press, Cambridge, England. The original Boolos-Jeffrey text has been extensively revised by Burgess: more advanced than an introductory textbook. "Abacus machine" model is extensively developed in Chapter 5 ''Abacus Computability''; it is one of three models extensively treated and compared—the Turing machine (still in Boolos' original 4-tuple form) and recursion the other two.
* [[Arthur Burks]], [[Herman Goldstine]], [[John von Neumann]] (1946), "Preliminary discussion of the logical design of an electronic computing instrument", reprinted pp.&amp;nbsp;92ff in [[Gordon Bell]] and [[Allen Newell]] (1971), ''Computer Structures: Readings and Examples'', McGraw-Hill Book Company, New York. {{isbn|0-07-004357-4}}  .
* [[Stephen Cook|Stephen A. Cook]] and Robert A. Reckhow (1972), ''Time-bounded random access machines'', Journal of Computer Systems Science 7 (1973), 354-375.
* [[Martin Davis]] (1958), ''Computability &amp; Unsolvability'', McGraw-Hill Book Company, Inc. New York.
* [[Calvin Elgot]] and [[Abraham Robinson]] (1964), "Random-Access Stored-Program Machines, an Approach to Programming Languages", ''Journal of the Association for Computing Machinery'', Vol. 11, No. 4 (October, 1964), pp.&amp;nbsp;365–399.
* [[Juris Hartmanis|J. Hartmanis]] (1971), "Computational Complexity of Random Access Stored Program Machines," ''Mathematical Systems Theory'' 5, 3 (1971) pp.&amp;nbsp;232–245.
* [[John Hopcroft]], [[Jeffrey Ullman]] (1979). ''Introduction to Automata Theory, Languages and Computation'', 1st ed., Reading Mass: Addison-Wesley. {{isbn|0-201-02988-X}}.  A difficult book centered around the issues of machine-interpretation of "languages", NP-Completeness, etc.
* [[Stephen Kleene]] (1952), ''Introduction to Metamathematics'', North-Holland Publishing Company, Amsterdam, Netherlands. {{isbn|0-7204-2103-9}}.
*[[Donald Knuth]] (1968), ''The Art of Computer Programming'', Second Edition 1973, Addison-Wesley, Reading, Massachusetts. Cf pages 462-463 where he defines "a new kind of abstract machine or 'automaton' which deals with linked structures."
*[[Joachim Lambek]] (1961, received 15 June 1961), "How to Program an Infinite Abacus", ''Mathematical Bulletin'', vol. 4, no. 3. September 1961 pages 295-302. In his Appendix II, Lambek proposes a "formal definition of 'program'. He references Melzak (1961) and Kleene (1952) ''Introduction to Metamathematics''.
*[[Zdzislaw Alexander Melzak|Z. A. Melzak]] (1961, received 15 May 1961), "An informal Arithmetical Approach to Computability and Computation", ''Canadian Mathematical Bulletin'', vol. 4, no. 3. September 1961 pages 279-293. Melzak offers no references but acknowledges "the benefit of conversations with Drs. R. Hamming, D. McIlroy and V. Vyssots of the Bell telephone Laborators and with Dr. H. Wang of Oxford University."
*{{cite journal |last=Minsky |first=Marvin |authorlink=Marvin Minsky
 |date=1961
 |title=Recursive Unsolvability of Post's Problem of 'Tag' and Other Topics in Theory of Turing Machines
 |journal=Annals of Mathematics
 |jstor=1970290
 |volume=74
 |issue=3
 |pages=437–455
 |doi=10.2307/1970290
}}
*{{cite book |last=Minsky |first=Marvin |authorlink=Marvin Minsky |date=1967 |title=Computation: Finite and Infinite Machines |edition=1st |publisher=Prentice-Hall, Inc. |location=Englewood Cliffs, NJ}} In particular see chapter 11: ''Models Similar to Digital Computers'' and chapter 14: ''Very Simple Bases for Computability''. In the former chapter he defines "Program machines" and in the later chapter he discusses "Universal Program machines with Two Registers" and "...with one register", etc.
*[[John C. Shepherdson]] and [[H. E. Sturgis]] (1961) received December 1961 "Computability of Recursive Functions", ''Journal of the Association of Computing Machinery'' (JACM) 10:217-255, 1963. An extremely valuable reference paper. In their Appendix A the authors cite 4 others with reference to "Minimality of Instructions Used in 4.1: Comparison with Similar Systems".
:*Kaphengst, Heinz, "Eine Abstrakte programmgesteuerte Rechenmaschine", ''Zeitschrift fur mathematische Logik und Grundlagen der Mathematik'' 5 (1959), 366-379.
:*[[Andrey Ershov|Ershov, A. P.]] "On operator algorithms", (Russian) ''Dok. Akad. Nauk'' 122 (1958), 967-970. English translation, Automat. Express 1 (1959), 20-23.
:*[[Rózsa Péter|Péter, Rózsa]] "Graphschemata und rekursive Funktionen", ''Dialectica'' 12 (1958), 373.
:*Hermes, Hans "Die Universalität programmgesteuerter Rechenmaschinen". ''Math.-Phys. Semesterberichte'' (Göttingen) 4 (1954), 42-53.
* [[Arnold Schönhage]] (1980), ''Storage Modification Machines'', Society for Industrial and Applied Mathematics, SIAM J. Comput. Vol. 9, No. 3, August 1980. Wherein Schōnhage shows the equivalence of his SMM with the "successor RAM" (Random Access Machine), etc. resp. ''Storage Modification Machines'', in ''Theoretical Computer Science'' (1979), pp.&amp;nbsp;36–37
*[[Peter van Emde Boas]], "Machine Models and Simulations" pp.&amp;nbsp;3–66, in: [[Jan van Leeuwen]], ed. ''Handbook of Theoretical Computer Science. Volume A: Algorithms and Complexity'', The MIT PRESS/Elsevier, 1990. {{isbn|0-444-88071-2}} (volume A). QA 76.H279 1990. van Emde Boas' treatment of SMMs appears on pp.&amp;nbsp;32–35. This treatment clarifies Schōnhage 1980—it closely follows but expands slightly the Schōnhage treatment. Both references may be needed for effective understanding.
*[[Hao Wang (academic)|Hao Wang]] (1957), "A Variant to Turing's Theory of Computing Machines", ''JACM'' (''Journal of the Association for Computing Machinery'') 4; 63-92. Presented at the meeting of the Association, June 23–25, 1954.
{{refend}}

==External links==
* {{MathWorld|title=Register machine|urlname=RegisterMachine}}
* [http://www.igblan.free-online.co.uk/igblan/ca/minsky.html Igblan - Minsky Register Machines]

{{DEFAULTSORT:Register Machine}}
[[Category:Models of computation]]
[[Category:Register machines|*]]</text>
      <sha1>31f19op5ubksxy7qig5uw7pbawg8z58</sha1>
    </revision>
  </page>
  <page>
    <title>Representation theory</title>
    <ns>0</ns>
    <id>19378200</id>
    <revision>
      <id>871380699</id>
      <parentid>836499536</parentid>
      <timestamp>2018-11-30T17:40:36Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51777">{{otheruses4|the theory of representations of algebraic structures by linear transformations and matrices| representation theory in other disciplines|Representation (disambiguation)}}{{confused|group presentation}}

'''Representation theory''' is a branch of [[mathematics]] that studies [[abstract algebra|abstract]] [[algebraic structure]]s by ''representing'' their [[element (set theory)|elements]] as [[linear transformation]]s of [[vector space]]s, and studies 
[[Module (mathematics)|modules]] over these abstract algebraic structures.&lt;ref&gt;Classic texts on representation theory include {{Harvtxt|Curtis|Reiner|1962}} and {{Harvtxt|Serre|1977}}. Other excellent sources are {{Harvtxt|Fulton|Harris|1991}} and {{Harvtxt|Goodman|Wallach|1998}}.&lt;/ref&gt; In essence, a representation makes an abstract algebraic object more concrete by describing its elements by [[matrix (mathematics)|matrices]] and the [[algebraic operation]]s in terms of [[matrix addition]] and [[matrix multiplication]]. The [[algebra]]ic objects amenable to such a description include [[group (mathematics)|groups]], [[associative algebra]]s and [[Lie algebra]]s. The most prominent of these (and historically the first) is the [[group representation|representation theory of groups]], in which elements of a group are represented by invertible matrices in such a way that the group operation is matrix multiplication.&lt;ref&gt;For the history of the representation theory of finite groups, see {{Harvtxt|Lam|1998}}. For algebraic and Lie groups, see {{Harvtxt|Borel|2001}}.&lt;/ref&gt;

Representation theory is a useful method because it reduces problems in [[abstract algebra]] to problems in [[linear algebra]], a subject that is well understood.&lt;ref name=linalg&gt;There are many textbooks on [[vector spaces]] and [[linear algebra]]. For an advanced treatment, see {{Harvtxt|Kostrikin|Manin|1997}}.&lt;/ref&gt; Furthermore, the vector space on which a group (for example) is represented can be infinite-dimensional, and by allowing it to be, for instance, a [[Hilbert space]], methods of [[mathematical analysis|analysis]] can be applied to the theory of groups.&lt;ref&gt;{{Harvnb|Sally|Vogan|1989}}.&lt;/ref&gt; Representation theory is also important in [[physics]] because, for example, it describes how the [[symmetry group]] of a physical system affects the solutions of equations describing that system.&lt;ref name=Sternberg&gt;{{Harvnb|Sternberg|1994}}.&lt;/ref&gt;

Representation theory is pervasive across fields of mathematics, for two reasons. First, the applications of representation theory are diverse:&lt;ref&gt;{{Harvnb|Lam|1998|p=372}}.&lt;/ref&gt; in addition to its impact on algebra, representation theory:
* illuminates and generalizes [[Fourier analysis]] via [[harmonic analysis]],&lt;ref name=Folland&gt;{{Harvnb|Folland|1995}}.&lt;/ref&gt; 
* is connected to [[geometry]] via [[invariant theory]] and the [[Erlangen program]],&lt;ref&gt;{{Harvnb|Goodman|Wallach|1998}}, {{Harvnb|Olver|1999}}, {{Harvnb|Sharpe|1997}}.&lt;/ref&gt;
* has an impact in number theory via [[automorphic form]]s and the [[Langlands program]].&lt;ref&gt;{{Harvnb|Borel|Casselman|1979}}, {{Harvnb|Gelbart|1984}}.&lt;/ref&gt;

Secondly, there are diverse approaches to representation theory. The same objects can be studied using methods from [[algebraic geometry]], [[module theory]], [[analytic number theory]], [[differential geometry]], [[operator theory]], [[algebraic combinatorics]] and [[topology]].&lt;ref&gt;See the previous footnotes and also {{Harvtxt|Borel|2001}}.&lt;/ref&gt;

The success of representation theory has led to numerous generalizations. One of the most general is in [[category theory]].&lt;ref name=SSA&gt;{{Harvnb|Simson|Skowronski|Assem|2007}}.&lt;/ref&gt; The algebraic objects to which representation theory applies can be viewed as particular kinds of categories, and the representations as [[functor]]s from the object category to the [[category of vector spaces]]. This description points to two obvious generalizations: first, the algebraic objects can be replaced by more general categories; second, the target category of vector spaces can be replaced by other well-understood categories.

==Definitions and concepts==

Let ''V'' be a [[vector space]] over a [[field (mathematics)|field]] '''F'''.&lt;ref name=linalg/&gt; For instance, suppose ''V'' is '''R'''&lt;sup&gt;''n''&lt;/sup&gt; or '''C'''&lt;sup&gt;''n''&lt;/sup&gt;, the standard ''n''-dimensional space of [[column vector]]s over the [[real number|real]] or [[complex number]]s respectively. In this case, the idea of representation theory is to do [[abstract algebra]] concretely by using ''n'' &amp;times; ''n'' [[matrix (mathematics)|matrices]] of real or complex numbers.

There are three main sorts of [[algebra]]ic objects for which this can be done: [[group (mathematics)|groups]], [[associative algebra]]s and [[Lie algebra]]s.&lt;ref&gt;{{Harvnb|Fulton|Harris|1991}}, {{Harvnb|Simson|Skowronski|Assem|2007}}, {{Harvnb|Humphreys|1972}}.&lt;/ref&gt;
* The set of all ''[[invertible matrix|invertible]]'' ''n'' &amp;times; ''n'' matrices is a group under [[matrix multiplication]] and the [[group representation|representation theory of groups]] analyzes a group by describing ("representing") its elements in terms of invertible matrices.
* Matrix addition and multiplication make the set of ''all'' ''n'' &amp;times; ''n'' matrices into an associative algebra and hence there is a corresponding [[representation of an associative algebra|representation theory of associative algebras]].
* If we replace matrix multiplication ''MN'' by the matrix [[commutator]] ''MN'' &amp;minus; ''NM'', then the ''n'' &amp;times; ''n'' matrices become instead a Lie algebra, leading to a [[representation of a Lie algebra|representation theory of Lie algebras]].

This generalizes to any field '''F''' and any vector space ''V'' over '''F''', with [[linear map]]s replacing matrices and [[function composition|composition]] replacing matrix multiplication: there is a group [[general linear group#General linear group of a vector space|GL(''V'','''F''')]] of [[linear map#Endomorphisms and automorphisms|automorphism]]s of ''V'', an associative algebra End&lt;sub&gt;'''F'''&lt;/sub&gt;(''V'') of all endomorphisms of ''V'', and a corresponding Lie algebra '''gl'''(''V'','''F''').

===Definition===
{{See also|group representation|algebra representation|Lie algebra representation}}

There are two ways to say what a representation is.&lt;ref&gt;This material can be found in standard textbooks, such as {{Harvtxt|Curtis|Reiner|1962}}, {{Harvtxt|Fulton|Harris|1991}}, {{Harvtxt|Goodman|Wallach|1998}}, {{Harvtxt|Gordon|Liebeck|1993}}, {{Harvtxt|Humphreys|1972}}, {{Harvtxt|Jantzen|2003}}, {{Harvtxt|Knapp|2001}} and {{Harvtxt|Serre|1977}}.&lt;/ref&gt; The first uses the idea of an [[group action|action]], generalizing the way that matrices act on column vectors by matrix multiplication. A representation of a [[group (mathematics)|group]] ''G'' or (associative or Lie) algebra ''A'' on a vector space ''V'' is a map
:&lt;math&gt; \Phi\colon G\times V \to V \quad\text{or}\quad \Phi\colon A\times V \to V&lt;/math&gt;
with two properties. First, for any ''g'' in ''G'' (or ''a'' in ''A''), the map
:&lt;math&gt; \begin{align}\Phi(g)\colon V&amp; \to V\\
v &amp; \mapsto \Phi(g, v)\end{align}&lt;/math&gt;
is linear (over '''F'''). Second, if we introduce the notation ''g'' · ''v'' for &lt;math&gt;\Phi&lt;/math&gt; (''g'', ''v''), then for any ''g''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt; in ''G'' and ''v'' in ''V'':
:&lt;math&gt; (1)\quad e \cdot v = v &lt;/math&gt;
:&lt;math&gt; (2)\quad g_1\cdot (g_2 \cdot v) = (g_1g_2) \cdot v &lt;/math&gt;
where ''e'' is the [[identity element]] of ''G'' and ''g''&lt;sub&gt;1&lt;/sub&gt;''g''&lt;sub&gt;2&lt;/sub&gt; is the product in ''G''. The requirement for associative algebras is analogous, except that associative algebras do not always have an identity element, in which case equation (1) is ignored. Equation (2) is an abstract expression of the associativity of matrix multiplication. This doesn't hold for the matrix commutator and also there is no identity element for the commutator. Hence for Lie algebras, the only requirement is that for any ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt; in ''A'' and ''v'' in ''V'':
:&lt;math&gt; (2')\quad x_1\cdot (x_2 \cdot v) - x_2\cdot (x_1 \cdot v) = [x_1,x_2] \cdot v &lt;/math&gt;
where [''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;] is the [[Lie algebra#Definition and first properties|Lie bracket]], which generalizes the matrix commutator ''MN'' &amp;minus; ''NM''.

The second way to define a representation focuses on the map ''φ'' sending ''g'' in ''G'' to a linear map ''φ''(''g''): ''V'' → ''V'', which satisfies
:&lt;math&gt; \varphi(g_1 g_2) = \varphi(g_1)\circ \varphi(g_2) \quad \text{for all }g_1,g_2 \in G &lt;/math&gt;
and similarly in the other cases. This approach is both more concise and more abstract.
From this point of view:
* a representation of a group ''G'' on a vector space ''V'' is a [[group homomorphism]] ''φ'': ''G'' → GL(''V'','''F''');
* a representation of an associative algebra ''A'' on a vector space ''V'' is an [[algebra homomorphism]] ''φ'': ''A'' → End&lt;sub&gt;'''F'''&lt;/sub&gt;(''V'');
* a representation of a Lie algebra '''a''' on a vector space ''V'' is a [[Lie algebra homomorphism]] ''φ'': '''a''' → '''gl'''(''V'','''F''').

===Terminology===

The vector space ''V'' is called the '''representation space''' of ''φ'' and its [[dimension of a vector space|dimension]] (if finite) is called the '''dimension''' of the representation (sometimes ''degree'', as in &lt;ref name="Serre 1977"&gt;{{Harvnb|Serre|1977}}.&lt;/ref&gt;). It is also common practice to refer to ''V'' itself as the representation when the homomorphism ''φ'' is clear from the context; otherwise the notation (''V'',''φ'') can be used to denote a representation.

When ''V'' is of finite dimension ''n'', one can choose a [[basis (linear algebra)|basis]] for ''V'' to identify ''V'' with '''F'''&lt;sup&gt;''n''&lt;/sup&gt; and hence recover a matrix representation with entries in the field '''F'''.

An effective or [[faithful representation]] is a representation (''V'',''φ'') for which the homomorphism ''φ'' is [[injective]].

=== Equivariant maps and isomorphisms ===
{{See also|Equivariant map}}

If ''V'' and ''W'' are vector spaces over '''F''', equipped with representations ''φ'' and ''ψ'' of a group ''G'', then an '''equivariant map''' from ''V'' to ''W'' is a linear map ''α'': ''V'' → ''W'' such that
:&lt;math&gt; \alpha( g\cdot v ) = g \cdot \alpha(v)&lt;/math&gt;
for all ''g'' in ''G'' and ''v'' in ''V''. In terms of ''φ'': ''G'' → GL(''V'') and ''ψ'': ''G'' → GL(''W''), this means
:&lt;math&gt; \alpha\circ \phi(g) = \psi(g)\circ \alpha &lt;/math&gt;
for all ''g'' in ''G'', i.e. the following [[Commutative diagram|diagram commutes]]:

:[[Image:Equivariant map 2.svg|200px]]

Equivariant maps for representations of an associative or Lie algebra are defined similarly. If ''α'' is invertible, then it is said to be an [[isomorphism]], in which case ''V'' and ''W'' (or, more precisely, ''φ'' and ''ψ'') are ''isomorphic representations'', also phrased as ''equivalent representations''. An equivariant map is often called an ''intertwining map'' of representations. Also, in the case of a group {{mvar|G}}, it is on occasion called a {{math|''G''}}-map.

Isomorphic representations are, for practical purposes, "the same"; they provide the same information about the group or algebra being represented. Representation theory therefore seeks to classify representations [[up to isomorphism]].

===Subrepresentations, quotients, and irreducible representations===
{{See also|Irreducible representation|simple module}}

If (''V'',''ψ'') is a representation of (say) a group ''G'', and ''W'' is a linear subspace of ''V'' that is preserved by the action of ''G'' in the sense that ''g'' · ''w'' ∈ ''W'' for all ''w'' ∈ ''W'' (Serre &lt;ref name="Serre 1977"/&gt; calls these ''W'' ''stable under G''), then ''W'' is called a ''[[subrepresentation]]'': by defining ''φ''(''g'') to be the restriction of ''ψ''(''g'') to ''W'', (''W'', ''φ'') is a representation of ''G'' and the inclusion of ''W'' into ''V'' is an equivariant map. The [[quotient space (linear algebra)|quotient space]] ''V''/''W'' can also be made into a representation of ''G''.

If ''V'' has exactly two subrepresentations, namely the [[zero vector space|trivial subspace]] {0} and ''V'' itself, then the representation is said to be ''irreducible''; if ''V'' has a proper nontrivial subrepresentation, the representation is said to be ''reducible''.&lt;ref&gt;The representation {0} of dimension zero is considered to be neither reducible nor irreducible, just like the number 1 is considered to be neither composite nor [[prime number|prime]].&lt;/ref&gt;

The definition of an irreducible representation implies [[Schur's lemma]]: an equivariant map ''α'': ''V'' → ''W'' between irreducible representations is either the [[zero map]] or an isomorphism, since its [[kernel (linear algebra)|kernel]] and [[image (mathematics)|image]] are subrepresentations. In particular, when ''V'' = ''W'', this shows that the equivariant [[endomorphism]]s of ''V'' form an associative [[division algebra]] over the underlying field '''F'''. If '''F''' is [[algebraically closed]], the only equivariant endomorphisms of an irreducible representation are the scalar multiples of the identity.

Irreducible representations are the building blocks of representation theory: if a representation ''V'' is not irreducible then it is built from a subrepresentation and a quotient that are both "simpler" in some sense; for instance, if ''V'' is finite-dimensional, then both the subrepresentation and the quotient have smaller dimension.

=== Direct sums and indecomposable representations ===
{{See also|Direct sum|indecomposable module|semisimple module}}

If (''V'',''φ'') and (''W'',''ψ'') are representations of (say) a group ''G'', then the [[direct sum of vector spaces|direct sum]] of ''V'' and ''W'' is a representation, in a canonical way, via the equation
:&lt;math&gt; g\cdot (v,w) = (g\cdot v, g\cdot w).&lt;/math&gt;

The [[direct sum of representations|direct sum of two representations]] carries no more information about the group ''G'' than the two representations do individually. If a representation is the direct sum of two proper nontrivial subrepresentations, it is said to be decomposable. Otherwise, it is said to be indecomposable.

===Complete reducibility===
In favorable circumstances, every finite-dimensional representation is a direct sum of irreducible representations: such representations are said to be semisimple. In this case, it suffices to understand only the irreducible representations. Examples where this "[[Weyl's theorem on complete reducibility|complete reducibility]]" phenomenon occur include finite and compact groups, and semisimple Lie algebras. 

In cases where complete reducibility does not hold, one must understand how indecomposable representations can be built from irreducible representations as extensions of a quotient by a subrepresentation.

===Tensor products of representations===
{{main|Tensor product of representations}}
Suppose &lt;math&gt;\phi_1:G\rightarrow \mathrm{GL}(V_1)&lt;/math&gt; and &lt;math&gt;\phi_2:G\rightarrow \mathrm{GL}(V_2)&lt;/math&gt; are representations of a group &lt;math&gt;G&lt;/math&gt;. Then we can form a representation &lt;math&gt;\phi_1\otimes\phi_2&lt;/math&gt; of G acting on the [[tensor product]] vector space &lt;math&gt;V_1\otimes V_2&lt;/math&gt; as follows:&lt;ref&gt;{{harvnb|Hall|2015}} Section 4.3.2&lt;/ref&gt;
:&lt;math&gt;(\phi_1\otimes\phi_2)(g)=\phi_1(g)\otimes\phi_2(g)&lt;/math&gt;.
If &lt;math&gt;\phi_1&lt;/math&gt; and &lt;math&gt;\phi_2&lt;/math&gt; are representations of a Lie algebra, then the correct formula to use is&lt;ref&gt;{{harvnb|Hall|2015}} Proposition 4.18 and Definition 4.19&lt;/ref&gt;
:&lt;math&gt;(\phi_1\otimes\phi_2)(X)=\phi_1(X)\otimes I+I\otimes\phi_2(X)&lt;/math&gt;.

In general, the tensor product of irreducible representations is ''not'' irreducible; the process of decomposing a tensor product as a direct sum of irreducible representations is known as [[Clebsch–Gordan_coefficients|Clebsch–Gordan theory]].

In the case of the [[Representation theory of SU(2)|representation theory of the group SU(2)]] (or equivalently, of its complexified Lie algebra &lt;math&gt;\mathrm{sl}(2;\mathbb{C})&lt;/math&gt;), the decomposition is easy to work out.&lt;ref&gt;{{harvnb|Hall|2015}} Appendix C&lt;/ref&gt; The irreducible representations are labeled by a parameter &lt;math&gt;l&lt;/math&gt; that is a non-negative integer or half integer; the representation then has dimension &lt;math&gt;2l+1&lt;/math&gt;. Suppose we take the tensor product of the representation of two representations, with labels &lt;math&gt;l_1&lt;/math&gt; and &lt;math&gt;l_2,&lt;/math&gt; where we assume &lt;math&gt;l_1\geq l_2&lt;/math&gt;. Then the tensor product decomposes as a direct sum of one copy of each representation with label &lt;math&gt;l&lt;/math&gt;, where &lt;math&gt;l&lt;/math&gt; ranges from &lt;math&gt;l_1-l_2&lt;/math&gt; to &lt;math&gt;l_1+l_2&lt;/math&gt; in increments of 1. If, for example, &lt;math&gt;l_1=l_2=1&lt;/math&gt;, then the values of &lt;math&gt;l&lt;/math&gt; that occur are 0, 1, and 2. Thus, the tensor product representation of dimension &lt;math&gt;3\times 3=9&lt;/math&gt; decomposes as a direct sum of a 1-dimensional representation &lt;math&gt;(l=0),&lt;/math&gt; a 3-dimensional representation &lt;math&gt;(l=1),&lt;/math&gt; and a 5-dimensional representation &lt;math&gt;(l=2)&lt;/math&gt;.

==Branches and topics==
{{See also|Group representation}}

Representation theory is notable for the number of branches it has, and the diversity of the approaches to studying representations of groups and algebras. Although, all the theories have in common the basic concepts discussed already, they differ considerably in detail. The differences are at least 3-fold:
# Representation theory depends upon the type of algebraic object being represented. There are several different classes of groups, associative algebras and Lie algebras, and their representation theories all have an individual flavour.
# Representation theory depends upon the nature of the vector space on which the algebraic object is represented. The most important distinction is between [[dimension (vector space)|finite-dimensional]] representations and infinite-dimensional ones. In the infinite-dimensional case, additional structures are important (e.g. whether or not the space is a [[Hilbert space]], [[Banach space]], etc.). Additional algebraic structures can also be imposed in the finite-dimensional case.
# Representation theory depends upon the type of [[field (mathematics)|field]] over which the vector space is defined. The most important case is the field of complex numbers. The other important cases are the field of real numbers, [[finite field]]s, and fields of [[p-adic number]]s. Additional difficulties arise for fields of [[positive characteristic]] and for fields that are not [[algebraically closed]].

===Finite groups===
{{Main|Representation of a finite group}}

Group representations are a very important tool in the study of finite groups.&lt;ref&gt;{{Harvnb|Alperin|1986}}, {{Harvnb|Lam|1998}}, {{Harvnb|Serre|1977}}.&lt;/ref&gt; They also arise in the applications of finite group theory to geometry and [[crystallographic group|crystallography]].&lt;ref&gt;{{Harvnb|Kim|1999}}.&lt;/ref&gt; Representations of finite groups exhibit many of the features of the general theory and point the way to other branches and topics in representation theory.

Over a field of [[characteristic zero]], the representation of a finite group ''G'' has a number of convenient properties. First, the representations of ''G'' are semisimple (completely reducible). This is a consequence of [[Maschke's theorem]], which states that any subrepresentation ''V'' of a ''G''-representation ''W'' has a ''G''-invariant complement. One proof is to choose any [[projection (linear algebra)|projection]] ''π'' from ''W'' to ''V'' and replace it by its average ''π''&lt;sub&gt;''G''&lt;/sub&gt; defined by
:&lt;math&gt; \pi_G(x) = \frac1{|G|}\sum_{g\in G} g\cdot \pi(g^{-1}\cdot x).&lt;/math&gt;
''π''&lt;sub&gt;''G''&lt;/sub&gt; is equivariant, and its kernel is the required complement.

The finite-dimensional ''G''-representations can be understood using [[character theory]]: the character of a representation ''φ'': ''G'' → GL(''V'') is the class function ''χ''&lt;sub&gt;''φ''&lt;/sub&gt;: ''G'' → '''F''' defined by
:&lt;math&gt;\chi_{\varphi}(g) = \mathrm{Tr}(\varphi(g))&lt;/math&gt;
where &lt;math&gt;\mathrm{Tr}&lt;/math&gt; is the [[trace of a matrix|trace]]. An irreducible representation of ''G'' is completely determined by its character.

Maschke's theorem holds more generally for fields of [[positive characteristic]] ''p'', such as the [[finite field]]s, as long as the prime ''p'' is [[coprime]] to the [[group order|order]] of ''G''. When ''p'' and |''G''| have a [[common factor]], there are ''G''-representations that are not semisimple, which are studied in a subbranch called [[modular representation theory]].

Averaging techniques also show that if '''F''' is the real or complex numbers, then any ''G''-representation preserves an [[inner product]] &lt;math&gt;\langle\cdot,\cdot\rangle&lt;/math&gt; on ''V'' in the sense that
:&lt;math&gt;\langle g\cdot v,g\cdot w\rangle = \langle v,w\rangle&lt;/math&gt;
for all ''g'' in ''G'' and ''v'', ''w'' in ''W''. Hence any ''G''-representation is [[unitary representation|unitary]].

Unitary representations are automatically semisimple, since Maschke's result can be proven by taking the [[orthogonal complement]] of a subrepresentation. When studying representations of groups that are not finite, the unitary representations provide a good generalization of the real and complex representations of a finite group.

Results such as Maschke's theorem and the unitary property that rely on averaging can be generalized to more general groups by replacing the average with an integral, provided that a suitable notion of integral can be defined. This can be done for [[compact group|compact topological groups]] (including compact Lie groups), using [[Haar measure]], and the resulting theory is known as [[abstract harmonic analysis]].

Over arbitrary fields, another class of finite groups that have a good representation theory are the [[finite groups of Lie type]]. Important examples are [[linear algebraic group]]s over finite fields. The representation theory of linear algebraic groups and [[Lie group]]s extends these examples to infinite-dimensional groups, the latter being intimately related to [[Lie algebra representation]]s. The importance of character theory for finite groups has an analogue in the theory of [[weight (representation theory)|weights]] for representations of Lie groups and Lie algebras.

Representations of a finite group ''G'' are also linked directly to algebra representations via the [[group ring|group algebra]] '''F'''[''G''], which is a vector space over '''F''' with the elements of ''G'' as a basis, equipped with the multiplication operation defined by the group operation, linearity, and the requirement that the group operation and scalar multiplication commute.

===Modular representations===
{{Main|Modular representation theory}}

Modular representations of a finite group ''G'' are representations over a field whose characteristic is not coprime to |''G''|, so that Maschke's theorem no longer holds (because |''G''| is not invertible in '''F''' and so one cannot divide by it).&lt;ref&gt;{{Harvnb|Serre|1977|loc=Part III}}.&lt;/ref&gt; Nevertheless, [[Richard Brauer]] extended much of character theory to modular representations, and this theory played an important role in early progress towards the [[classification of finite simple groups]], especially for simple groups whose characterization was not amenable to purely group-theoretic methods because their [[Sylow subgroup|Sylow 2-subgroup]]s were "too small".&lt;ref&gt;{{Harvnb|Alperin|1986}}.&lt;/ref&gt;

As well as having applications to group theory, modular representations arise naturally in other branches of [[mathematics]], such as [[algebraic geometry]], [[coding theory]], [[combinatorics]] and [[number theory]].

===Unitary representations===
{{Main|Unitary representation}}

A unitary representation of a group ''G'' is a linear representation ''φ'' of ''G'' on a real or (usually) complex [[Hilbert space]] ''V'' such that ''φ''(''g'') is a [[unitary operator]] for every ''g'' ∈ ''G''. Such representations have been widely applied in [[quantum mechanics]] since the 1920s, thanks in particular to the influence of [[Hermann Weyl]],&lt;ref&gt;See {{Harvnb|Weyl|1928}}.&lt;/ref&gt; and this has inspired the development of the theory, most notably through the analysis of [[representation theory of the Poincaré group|representations of the Poincaré group]] by [[Eugene Wigner]].&lt;ref&gt;{{Harvnb|Wigner|1939}}.&lt;/ref&gt; One of the pioneers in constructing a general theory of unitary representations (for any group ''G'' rather than just for particular groups useful in applications) was [[George Mackey]], and an extensive theory was developed by [[Harish-Chandra]] and others in the 1950s and 1960s.&lt;ref&gt;{{Harvnb|Borel|2001}}.&lt;/ref&gt;

A major goal is to describe the "[[unitary dual]]", the space of irreducible unitary representations of ''G''.&lt;ref name=Knapp&gt;{{Harvnb|Knapp|2001}}.&lt;/ref&gt; The theory is most well-developed in the case that ''G'' is a [[locally compact]] (Hausdorff) [[topological group]] and the representations are [[strongly continuous]].&lt;ref name=Folland/&gt; For ''G'' abelian, the unitary dual is just the space of [[character theory|characters]], while for ''G'' compact, the [[Peter–Weyl theorem]] shows that the irreducible unitary representations are finite-dimensional and the unitary dual is discrete.&lt;ref name="Peter–Weyl"&gt;{{Harvnb|Peter|Weyl|1927}}.&lt;/ref&gt; For example, if ''G'' is the circle group ''S''&lt;sup&gt;1&lt;/sup&gt;, then the characters are given by integers, and the unitary dual is '''Z'''.

For non-compact ''G'', the question of which representations are unitary is a subtle one. Although irreducible unitary representations must be "admissible" (as [[Harish-Chandra module]]s) and it is easy to detect which admissible representations have a nondegenerate invariant [[sesquilinear form]], it is hard to determine when this form is positive definite. An effective description of the unitary dual, even for relatively well-behaved groups such as real [[Semisimple Lie group|reductive]] [[Lie group]]s (discussed below), remains an important open problem in representation theory. It has been solved for many particular groups, such as [[representation theory of SL2(R)|SL(2,'''R''')]] and the [[representation theory of the Lorentz group|Lorentz group]].&lt;ref&gt;{{Harvnb|Bargmann|1947}}.&lt;/ref&gt;

===Harmonic analysis===
{{Main|Abstract harmonic analysis}}

The duality between the circle group ''S''&lt;sup&gt;1&lt;/sup&gt; and the integers '''Z''', or more generally, between a torus ''T''&lt;sup&gt;''n''&lt;/sup&gt; and '''Z'''&lt;sup&gt;''n''&lt;/sup&gt; is well known in analysis as the theory of [[Fourier series]], and the [[Fourier transform]] similarly expresses the fact that the space of characters on a real vector space is the [[dual vector space]]. Thus unitary representation theory and [[harmonic analysis]] are intimately related, and abstract harmonic analysis exploits this relationship, by developing the [[mathematical analysis|analysis]] of functions on [[local compactness|locally compact topological groups]] and related spaces.&lt;ref name=Folland/&gt;

A major goal is to provide a general form of the Fourier transform and the [[Plancherel theorem]]. This is done by constructing a [[measure (mathematics)|measure]] on the [[unitary dual]] and an isomorphism between the regular representation of ''G'' on the space L&lt;sup&gt;2&lt;/sup&gt;(''G'') of [[square integrable]] functions on ''G'' and its representation on the [[L2-space|space of L&lt;sup&gt;2&lt;/sup&gt; functions]] on the unitary dual. [[Pontrjagin duality]] and the [[Peter–Weyl theorem]] achieve this for abelian and compact ''G'' respectively.&lt;ref name="Peter–Weyl"/&gt;&lt;ref&gt;{{Harvnb|Pontrjagin|1934}}.&lt;/ref&gt;

Another approach involves considering all unitary representations, not just the irreducible ones. These form a [[category (mathematics)|category]], and [[Tannaka–Krein duality]] provides a way to recover a compact group from its category of unitary representations.

If the group is neither abelian nor compact, no general theory is known with an analogue of the Plancherel theorem or Fourier inversion, although [[Alexander Grothendieck]] extended Tannaka–Krein duality to a relationship between [[linear algebraic group]]s and [[tannakian category|tannakian categories]].

Harmonic analysis has also been extended from the analysis of functions on a group ''G'' to functions on [[homogeneous spaces]] for ''G''. The theory is particularly well developed for [[symmetric space]]s and provides a theory of [[automorphic form]]s (discussed below).

===Lie groups===
{{main|Representation of a Lie group}}
{{Lie groups}}

A [[Lie group]] is a group that is also a [[smooth manifold]]. Many classical groups of matrices over the real or complex numbers are Lie groups.&lt;ref name=Weyl&gt;{{Harvnb|Weyl|1946}}.&lt;/ref&gt; Many of the groups important in physics and chemistry are Lie groups, and their representation theory is crucial to the application of group theory in those fields.&lt;ref name="Sternberg"/&gt;

The representation theory of Lie groups can be developed first by considering the compact groups, to which results of compact representation theory apply.&lt;ref name=Knapp/&gt; This theory can be extended to finite-dimensional representations of [[semisimple Lie group]]s using [[Weyl's unitary trick]]: each semisimple real Lie group ''G'' has a complexification, which is a complex Lie group ''G''&lt;sup&gt;c&lt;/sup&gt;, and this complex Lie group has a maximal compact subgroup ''K''. The finite-dimensional representations of ''G'' closely correspond to those of ''K''.

A general Lie group is a [[semidirect product]] of a [[solvable Lie group]] and a semisimple Lie group (the [[Levi decomposition]]).&lt;ref name="Fulton-Harris"&gt;{{Harvnb|Fulton|Harris|1991}}.&lt;/ref&gt; The classification of representations of solvable Lie groups is intractable in general, but often easy in practical cases. Representations of semidirect products can then be analysed by means of general results called ''[[Mackey theory]]'', which is a generalization of the methods used in [[Wigner's classification]] of representations of the Poincaré group.

===Lie algebras===
{{Main|Lie algebra representation}}

A [[Lie algebra]] over a field '''F''' is a vector space over '''F''' equipped with a [[skew-symmetric graph|skew-symmetric]] [[bilinear operation]] called the [[Lie bracket]], which satisfies the [[Jacobi identity]]. Lie algebras arise in particular as [[tangent space]]s to [[Lie group]]s at the [[identity element]], leading to their interpretation as "infinitesimal symmetries".&lt;ref name="Fulton-Harris"/&gt; An important approach to the representation theory of Lie groups is to study the corresponding representation theory of Lie algebras, but representations of Lie algebras also have an intrinsic interest.&lt;ref&gt;{{Harvnb|Humphreys|1972a}}.&lt;/ref&gt;

Lie algebras, like Lie groups, have a Levi decomposition into semisimple and solvable parts, with the representation theory of solvable Lie algebras being intractable in general. In contrast, the finite-dimensional representations of semisimple Lie algebras are completely understood, after work of [[Élie Cartan]]. A representation of a semisimple Lie algebra '''g''' is analysed by choosing a [[Cartan subalgebra]], which is essentially a generic maximal subalgebra '''h''' of '''g''' on which the Lie bracket is zero ("abelian"). The representation of '''g''' can be decomposed into [[weight (representation theory)|weight spaces]] that are [[eigenspace]]s for the action of '''h''' and the infinitesimal analogue of characters. The structure of semisimple Lie algebras then reduces the analysis of representations to easily understood combinatorics of the possible weights that can occur.&lt;ref name="Fulton-Harris"/&gt;

====Infinite-dimensional Lie algebras====
{{See also|Affine Lie algebra|Kac–Moody algebra}}

There are many classes of infinite-dimensional Lie algebras whose representations have been studied. Among these, an important class are the Kac–Moody algebras.&lt;ref&gt;{{Harvnb|Kac|1990}}.&lt;/ref&gt; They are named after [[Victor Kac]] and [[Robert Moody]], who independently discovered them. These algebras form a generalization of finite-dimensional [[semisimple Lie algebra]]s, and share many of their combinatorial properties. This means that they have a class of representations that can be understood in the same way as representations of semisimple Lie algebras.

Affine Lie algebras are a special case of Kac–Moody algebras, which have particular importance in mathematics and [[theoretical physics]], especially [[conformal field theory]] and the theory of [[exactly solvable model]]s. Kac discovered an elegant proof of certain combinatorial identities, [[Macdonald identities]], which is based on the representation theory of affine Kac–Moody algebras.

====Lie superalgebras====
{{Main|Representation of a Lie superalgebra}}

[[Lie superalgebra]]s are generalizations of Lie algebras in which the underlying vector space has a '''Z'''&lt;sub&gt;2&lt;/sub&gt;-grading, and skew-symmetry and Jacobi identity properties of the Lie bracket are modified by signs. Their representation theory is similar to the representation theory of Lie algebras.&lt;ref&gt;{{Harvnb|Kac|1977}}.&lt;/ref&gt;

===Linear algebraic groups===
{{See also|Linear algebraic group}}

Linear algebraic groups (or more generally, affine [[group scheme]]s) are analogues in algebraic geometry of [[Lie group]]s, but over more general fields than just '''R''' or '''C'''. In particular, over finite fields, they give rise to [[finite groups of Lie type]]. Although linear algebraic groups have a classification that is very similar to that of Lie groups, their representation theory is rather different (and much less well understood) and requires different techniques, since the [[Zariski topology]] is relatively weak, and techniques from analysis are no longer available.&lt;ref&gt;{{Harvnb|Humphreys|1972b}}, {{Harvnb|Jantzen|2003}}.&lt;/ref&gt;

===Invariant theory===
{{Main|Invariant theory}}

Invariant theory studies [[group action|actions]] on [[algebraic variety|algebraic varieties]] from the point of view of their effect on functions, which form representations of the group. Classically, the theory dealt with the question of explicit description of [[polynomial function]]s that do not change, or are ''invariant'', under the transformations from a given [[linear group]]. The modern approach analyses the decomposition of these representations into irreducibles.&lt;ref&gt;{{Harvnb|Olver|1999}}.&lt;/ref&gt;

Invariant theory of [[infinite group]]s is inextricably linked with the development of [[linear algebra]], especially, the theories of [[quadratic form]]s and [[determinant]]s. Another subject with strong mutual influence is [[projective geometry]], where invariant theory can be used to organize the subject, and during the 1960s, new life was breathed into the subject by [[David Mumford]] in the form of his [[geometric invariant theory]].&lt;ref&gt;{{Harvnb|Mumford|Fogarty|Kirwan|1994}}.&lt;/ref&gt;

The representation theory of [[semisimple Lie group]]s has its roots in invariant theory&lt;ref name="Weyl" /&gt; and the strong links between representation theory and algebraic geometry have many parallels in differential geometry, beginning with [[Felix Klein]]'s [[Erlangen program]] and [[Élie Cartan]]'s [[Cartan connection|connections]], which place groups and symmetry at the heart of geometry.&lt;ref&gt;{{Harvnb|Sharpe|1997}}.&lt;/ref&gt; Modern developments link representation theory and invariant theory to areas as diverse as [[holonomy]], [[differential operator]]s and the theory of [[several complex variables]].

===Automorphic forms and number theory===
{{Main|Automorphic form}}

Automorphic forms are a generalization of [[modular form]]s to more general [[analytic function]]s, perhaps of [[several complex variables]], with similar transformation properties.&lt;ref&gt;{{Harvnb|Borel|Casselman|1979}}.&lt;/ref&gt; The generalization involves replacing the modular group [[PSL2(R)|PSL&lt;sub&gt;2&lt;/sub&gt; ('''R''')]] and a chosen [[congruence subgroup]] by a semisimple Lie group ''G'' and a [[discrete subgroup]] ''Γ''. Just as modular forms can be viewed as [[differential form]]s on a quotient of the [[upper half space]] '''''H''''' = PSL&lt;sub&gt;2&lt;/sub&gt; ('''R''')/SO(2), automorphic forms can be viewed as differential forms (or similar objects) on ''Γ''\''G''/''K'', where ''K'' is (typically) a [[maximal compact subgroup]] of ''G''. Some care is required, however, as the quotient typically has singularities. The quotient of a semisimple Lie group by a compact subgroup is a [[symmetric space]] and so the theory of automorphic forms is intimately related to harmonic analysis on symmetric spaces.

Before the development of the general theory, many important special cases were worked out in detail, including the [[Hilbert modular form]]s and [[Siegel modular form]]s. Important results in the theory include the [[Selberg trace formula]] and the realization by [[Robert Langlands]] that the [[Riemann-Roch theorem]] could be applied to calculate the dimension of the space of automorphic forms. The subsequent notion of "automorphic representation" has proved of great technical value for dealing with the case that ''G'' is an [[algebraic group]], treated as an [[adelic algebraic group]]. As a result, an entire philosophy, the [[Langlands program]] has developed around the relation between representation and number theoretic properties of automorphic forms.&lt;ref&gt;{{Harvnb|Gelbart|1984}}.&lt;/ref&gt;

===Associative algebras===
{{Main|Algebra representation}}

In one sense, [[associative algebra]] representations generalize both representations of groups and Lie algebras. A representation of a group induces a representation of a corresponding [[group ring]] or [[group algebra]], while representations of a Lie algebra correspond bijectively to representations of its [[universal enveloping algebra]]. However, the representation theory of general associative algebras does not have all of the nice properties of the representation theory of groups and Lie algebras.

====Module theory====
{{Main|Module theory}}

When considering representations of an associative algebra, one can forget the underlying field, and simply regard the associative algebra as a ring, and its representations as modules. This approach is surprisingly fruitful: many results in representation theory can be interpreted as special cases of results about modules over a ring.

====Hopf algebras and quantum groups====
{{Main|Representation theory of Hopf algebras}}

[[Hopf algebra]]s provide a way to improve the representation theory of associative algebras, while retaining the representation theory of groups and Lie algebras as special cases. In particular, the tensor product of two representations is a representation, as is the dual vector space.

The Hopf algebras associated to groups have a commutative algebra structure, and so general Hopf algebras are known as [[quantum group]]s, although this term is often restricted to certain Hopf algebras arising as deformations of groups or their universal enveloping algebras. The representation theory of quantum groups has added surprising insights to the representation theory of Lie groups and Lie algebras, for instance through the [[crystal basis]] of Kashiwara.

==Generalizations==

===Set-theoretic representations===
{{Main|Group action}}

A ''set-theoretic representation'' (also known as a [[group action]] or ''permutation representation'') of a [[group (mathematics)|group]] ''G'' on a [[set (mathematics)|set]] ''X'' is given by a [[function (mathematics)|function]] ρ from ''G'' to ''X''&lt;sup&gt;''X''&lt;/sup&gt;, the [[set (mathematics)|set]] of [[function (mathematics)|function]]s from ''X'' to ''X'', such that for all ''g''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt; in ''G'' and all ''x'' in ''X'':

:&lt;math&gt;\rho(1)[x] = x&lt;/math&gt;
:&lt;math&gt;\rho(g_1 g_2)[x]=\rho(g_1)[\rho(g_2)[x]].&lt;/math&gt;

This condition and the axioms for a group imply that ρ(''g'') is a [[bijection]] (or [[permutation]]) for all ''g'' in ''G''. Thus we may equivalently define a permutation representation to be a [[group homomorphism]] from G to the [[symmetric group]] S&lt;sub&gt;''X''&lt;/sub&gt; of ''X''.

===Representations in other categories===
{{See also|Category theory}}

Every group ''G'' can be viewed as a [[category (mathematics)|category]] with a single object; [[morphism]]s in this category are just the elements of ''G''. Given an arbitrary category ''C'', a ''representation'' of ''G'' in ''C'' is a [[functor]] from ''G'' to ''C''. Such a functor selects an object ''X'' in ''C'' and a group homomorphism from ''G'' to Aut(''X''), the [[automorphism group]] of ''X''.

In the case where ''C'' is '''Vect'''&lt;sub&gt;'''F'''&lt;/sub&gt;, the [[category of vector spaces]] over a field '''F''', this definition is equivalent to a linear representation. Likewise, a set-theoretic representation is just a representation of ''G'' in the [[category of sets]].

For another example consider the [[category of topological spaces]], '''Top'''. Representations in '''Top''' are homomorphisms from ''G'' to the [[homeomorphism]] group of a topological space ''X''.

Two types of representations closely related to linear representations are:
*[[projective representation]]s: in the category of [[projective space]]s. These can be described as "linear representations [[up to]] scalar transformations".
*[[affine representation]]s: in the category of [[affine space]]s. For example, the [[Euclidean group]] acts affinely upon [[Euclidean space]].

===Representations of categories===

{{See also|Quiver (mathematics)}}

Since groups are categories, one can also consider representation of other categories. The simplest generalization is to [[monoid]]s, which are categories with one object. Groups are monoids for which every morphism is invertible. General monoids have representations in any category. In the category of sets, these are [[monoid action]]s, but monoid representations on vector spaces and other objects can be studied.

More generally, one can relax the assumption that the category being represented has only one object. In full generality, this is simply the theory of [[functor]]s between categories, and little can be said.

One special case has had a significant impact on representation theory, namely the representation theory of quivers.&lt;ref name=SSA/&gt; A quiver is simply a [[directed graph]] (with loops and multiple arrows allowed), but it can be made into a category (and also an algebra) by considering paths in the graph. Representations of such categories/algebras have illuminated several aspects of representation theory, for instance by allowing non-semisimple representation theory questions about a group to be reduced in some cases to semisimple representation theory questions about a quiver.

==See also==
* [[Numerical analysis]]
* [[Philosophy of cusp forms]]
* [[Representation (mathematics)]]
* [[Representation theorem]]
* [[List of representation theory topics]]
* [[List of harmonic analysis topics]]
* [[Galois representation]]
* [[Glossary of representation theory]]
* [[Itô's theorem]]

==Notes==

{{Reflist|2}}

==References==

* {{Citation|title= Local Representation Theory: Modular Representations as an Introduction to the Local Representation Theory of Finite Groups|first=J. L.|last= Alperin|author-link=J. L. Alperin|publisher=Cambridge University Press|year= 1986|isbn=978-0-521-44926-7}}.
* {{Citation|first=V.|last=Bargmann|title=Irreducible unitary representations of the Lorenz group|journal= [[Annals of Mathematics]]|volume=48|year=1947|pages=568–640|doi=10.2307/1969129|issue=3|jstor=1969129}}.
* {{Citation|title=Essays in the History of Lie Groups and Algebraic Groups|first=Armand|last= Borel|authorlink=Armand Borel|publisher=American Mathematical Society|year= 2001|isbn=978-0-8218-0288-5}}.
* {{Citation|title=Automorphic Forms, Representations, and L-functions|first=Armand |last=Borel|first2= W.|last2=Casselman|publisher=American Mathematical Society|year= 1979|isbn=978-0-8218-1435-2}}.
* {{Citation| title= Representation Theory of Finite Groups and Associative Algebras|first1=Charles W.|last1= Curtis | author1-link = Charles W. Curtis|first2=Irving|last2= Reiner|author2-link=Irving Reiner|publisher=John Wiley &amp; Sons (Reedition 2006 by AMS Bookstore)|year=1962|isbn= 978-0-470-18975-7 }}.&lt;!---citation template accepts only one isbn---(ISBN 978-0821840665)---&gt;
* {{Citation|first=Stephen|last=Gelbart|authorlink= Stephen Gelbart |title=An Elementary Introduction to the Langlands Program|journal=Bulletin of the American Mathematical Society|volume=10|issue=2|year=1984|pages=177–219|url=http://www.ams.org/bull/1984-10-02/S0273-0979-1984-15237-6/home.html|doi=10.1090/S0273-0979-1984-15237-6}}.
* {{Citation|title=A Course in Abstract Harmonic Analysis|first=Gerald B.|last= Folland|publisher=CRC Press|year= 1995|isbn=978-0-8493-8490-5}}.
* {{Fulton-Harris}}.
* {{Citation|last2=Wallach|first2=Nolan R.|last1=Goodman|first1=Roe|year=1998|title=Representations and Invariants of the Classical Groups|publisher= Cambridge University Press|isbn= 978-0-521-66348-9}}.
* {{citation |first1=James|last1= Gordon|last2=Liebeck|first2= Martin | title=Representations and Characters of Finite Groups | location=Cambridge | publisher=Cambridge University Press | year=1993 | isbn=978-0-521-44590-0}}.
* {{Citation| last=Hall|first=Brian C.|title=Lie Groups, Lie Algebras, and Representations: An Elementary Introduction|edition=2nd|series=Graduate Texts in Mathematics|volume=222|publisher=Springer|year=2015|isbn= 978-3319134666}}
* {{Citation|first=Sigurdur|last=Helgason|title=Differential Geometry, Lie groups and Symmetric Spaces|publisher=Academic Press|year=1978|isbn=978-0-12-338460-7}}
* {{citation | title =Introduction to Lie Algebras and Representation Theory|first=James E.|last=Humphreys|publisher=Birkhäuser|year= 1972a|isbn=978-0-387-90053-7}}.
* {{citation | last1=Humphreys | first1=James E. | title=Linear Algebraic Groups | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-90108-4 |mr=0396773 | year=1972b | volume=21}}
* {{Citation|title=Representations of Algebraic Groups|first=Jens Carsten|last= Jantzen|publisher=American Mathematical Society|year= 2003|isbn=978-0-8218-3527-2}}.
* {{Citation|last=Kac|first= Victor G.|authorlink=Victor Kac|title= Lie superalgebras|journal= Advances in Mathematics|volume= 26 |year=1977|issue= 1|pages=8&amp;ndash;96|doi=10.1016/0001-8708(77)90017-2}}.
* {{Citation|last=Kac|first= Victor G.|title=Infinite Dimensional Lie Algebras|edition=3rd|publisher=Cambridge University Press|year= 1990|isbn=978-0-521-46693-6}}.
* {{Citation|title=Representation Theory of Semisimple Groups: An Overview Based on Examples|first=Anthony W.|last= Knapp|authorlink=Anthony Knapp|publisher= Princeton University Press|year= 2001|isbn=978-0-691-09089-4}}.
* {{Citation|title=Group Theoretical Methods and Applications to Molecules and Crystals: And Applications to Molecules and Crystals|first=Shoon Kyung|last=Kim|publisher=Cambridge University Press|year= 1999|isbn=978-0-521-64062-6}}.
* {{Citation|title=Linear Algebra and Geometry|first1=A. I.|last1=Kostrikin|authorlink=Alexei Kostrikin|first2=Yuri I.|last2= Manin|author2-link=Yuri Manin|publisher=Taylor &amp; Francis|year= 1997|isbn=978-90-5699-049-7}}.
* {{Citation|title=Representations of finite groups: a hundred years|first=T. Y.|last=Lam|journal=Notices of the AMS|volume = 45|publisher=American Mathematical Society| issue= 3,4|year=1998|pages =[http://www.ams.org/notices/199803/lam.pdf 361&amp;ndash;372 (Part I)], [http://www.ams.org/notices/199804/lam2.pdf 465&amp;ndash;474 (Part II)]}}.
* Yurii I. Lyubich. ''Introduction to the Theory of Banach Representations of Groups''. Translated from the 1985 Russian-language edition (Kharkov, Ukraine). Birkhäuser Verlag. 1988.
*{{citation | last1=Mumford | first1=David | author1-link=David Mumford | last2=Fogarty | first2=J. | last3=Kirwan | first3=F. | title=Geometric invariant theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=3rd | series=Ergebnisse der Mathematik und ihrer Grenzgebiete (2) [Results in Mathematics and Related Areas (2)] | isbn=978-3-540-56963-3 |mr=0214602&lt;!--(1st ed. 1965)--&gt; | year=1994 | volume=34}}; {{MathSciNet|id=0719371}} (2nd ed.); {{MathSciNet | id = 1304906}}(3rd ed.)
* {{citation | last=Olver|first= Peter J. |author-link=Peter J. Olver | title=Classical invariant theory | location=Cambridge | publisher=Cambridge University Press | year=1999 | isbn= 0-521-55821-2}}.
* {{Citation|first1=F.|last1=Peter|first2=Hermann|last2=Weyl|title=Die Vollständigkeit der primitiven Darstellungen einer geschlossenen kontinuierlichen Gruppe|journal=Mathematische Annalen|volume=97|year=1927|issue=1|pages=737–755|doi=10.1007/BF01447892|url=http://gdz.sub.uni-goettingen.de/index.php?id=11&amp;PPN=PPN235181684_0097&amp;DMDID=DMDLOG_0039&amp;L=1|deadurl=yes|archiveurl=https://web.archive.org/web/20140819143253/http://gdz.sub.uni-goettingen.de/index.php?id=11&amp;PPN=PPN235181684_0097&amp;DMDID=DMDLOG_0039&amp;L=1|archivedate=2014-08-19|df=}}.
* {{Citation|first=Lev S.|last= Pontrjagin|authorlink=Lev Pontryagin|title=The theory of topological commutative groups|journal=[[Annals of Mathematics]]|volume=35|year= 1934|pages= 361–388|doi=10.2307/1968438|issue=2|publisher=Annals of Mathematics|jstor=1968438}}.
* {{Citation|title=Representation Theory and Harmonic Analysis on Semisimple Lie Groups|first1=Paul|last1= Sally|first2= David A.|last2= Vogan|author2-link=David Vogan|publisher=American Mathematical Society|year=1989|isbn=978-0-8218-1526-7}}.
* {{citation | authorlink=Jean-Pierre Serre|first=Jean-Pierre|last= Serre| title=Linear Representations of Finite Groups | publisher=Springer-Verlag | year=1977 | isbn=978-0387901909}}.
* {{Citation| title= Differential Geometry: Cartan's Generalization of Klein's Erlangen Program|first=Richard W.|last= Sharpe|publisher=Springer|year= 1997|isbn= 978-0-387-94732-7}}.
* {{citation | title=Elements of the Representation Theory of Associative Algebras|first1=Daniel|last1= Simson|first2= Andrzej|last2=Skowronski|first3= Ibrahim|last3= Assem|publisher= Cambridge University Press|year= 2007|isbn=978-0-521-88218-7}}.
* {{citation | title =Group Theory and Physics|first=Shlomo|last= Sternberg|authorlink=Shlomo Sternberg|publisher=Cambridge University Press|year=1994|isbn=978-0-521-55885-3}}.
* {{cite book|ref=harv|title=Group Theory in Physics|edition=1st|location=New Jersey·London·Singapore·Hong Kong|year=1985|isbn=978-9971966577|publisher=[[World Scientific Publishing|World Scientific]]|last=Tung|first=Wu-Ki}}
* {{citation | title= Gruppentheorie und Quantenmechanik|first=Hermann|last= Weyl|authorlink=Hermann Weyl|edition=The Theory of Groups and Quantum Mechanics, translated H.P. Robertson, 1931|publisher= S. Hirzel, Leipzig (reprinted 1950, Dover)|year=1928|isbn=978-0-486-60269-1}}.
* {{Citation|title=The Classical Groups: Their Invariants and Representations|first=Hermann|last= Weyl|year=1946|edition=2nd|publisher = Princeton University Press (reprinted 1997)| isbn= 978-0-691-05756-9}}.
* {{Citation|first= Eugene P.|last=Wigner|authorlink=Eugene Wigner|title=On unitary representations of the inhomogeneous Lorentz group|journal=[[Annals of Mathematics]]| volume=40|pages=149–204|year=1939|doi=10.2307/1968551|issue=1|publisher=Annals of Mathematics|jstor= 1968551}}.

==External links==
{{Sister project links| wikt=no | commons=no | b=no | n=no | q=Representation theory | s=no | v=no | voy=no | species=no | d=no}}

* {{springer|title=Representation theory|id=p/r081480}}

{{Areas of mathematics | state=collapsed}}

[[Category:Representation theory| ]]
{{bots|deny=Yobot}}</text>
      <sha1>hcolzdmrxl3kdcvgd6d1i29pxl4vp5x</sha1>
    </revision>
  </page>
  <page>
    <title>Shimshon Amitsur</title>
    <ns>0</ns>
    <id>19937535</id>
    <revision>
      <id>842798758</id>
      <parentid>842731634</parentid>
      <timestamp>2018-05-24T18:46:14Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove [[:Category:Jewish mathematicians]]. [[WP:G4]] per [[:WP:Categories for discussion/Log/2007 May 14#Category:Jewish_mathematicians]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6212">{{Infobox scientist
| name              = Shimshon Amitsur
| image             = Amitsur.jpg
| image_size        = 240px
| caption           = Shimshon Amitsur, [[Leeds University|Leeds]], 1972 (photo by George M. Bergman)
| birth_date        = {{birth date|1921|08|26|mf=y}}
| birth_place       = [[Jerusalem]]
| death_date        = {{death date and age|1994|09|05|1921|08|26|mf=y}}
| death_place       = Jerusalem
| nationality       = {{flag|ISR|name=Israeli}}
| fields            = [[Mathematics]]
| workplaces        = [[Hebrew University]]
| alma_mater        = Hebrew University
| doctoral_advisor  = [[Jacob Levitzki]]
| doctoral_students = [[Amitai Regev]]&lt;br&gt;[[Eliyahu Rips]]&lt;br&gt;[[Aner Shalev]]
| known_for         = 
| awards            = 
}}
'''Shimshon Avraham Amitsur''' (born '''Kaplan'''; {{lang-he|שמשון אברהם עמיצור}}; August 26, 1921 – September 5, 1994) was an Israeli [[mathematician]]. He is best known for his work in [[ring theory]], in particular [[PI ring]]s,  an area of [[abstract algebra]].

==Biography==
Amitsur was born in [[Jerusalem]] and studied at the [[Hebrew University]] under the supervision of [[Jacob Levitzki]].  His studies were repeatedly interrupted, first by [[World War II]] and then by the [[Israel's War of Independence]].  He received his [[Master of Science|M.Sc.]] degree in 1946, and his Ph.D. in 1950.  Later, for his joint work with Levitzki, he received the first Israel Prize in Exact Sciences.  He worked at the Hebrew University until his retirement in 1989. Amitsur was a visiting scholar at the [[Institute for Advanced Study]] from 1952 to 1954.&lt;ref&gt;[http://www.ias.edu/people/cos/frontpage?page=3 Institute for Advanced Study: A Community of Scholars] {{webarchive|url=https://web.archive.org/web/20130106144327/http://www.ias.edu/people/cos/frontpage?page=3 |date=2013-01-06 }}&lt;/ref&gt; He was an Invited Speaker at the [[International Congress of Mathematicians|ICM]] in 1970 in Nice.&lt;ref&gt;Amitsur, S. A. [http://www.mathunion.org/ICM/ICM1970.1/Main/icm1970.1.0269.0272.ocr.pdf "Some results on rings with polynomial identities."] {{webarchive|url=https://web.archive.org/web/20161001224428/http://www.mathunion.org/ICM/ICM1970.1/Main/icm1970.1.0269.0272.ocr.pdf |date=2016-10-01 }} Actes, Congrès. intern. math. Tome 1 (1970): 269–272.&lt;/ref&gt; He was a member of the [[Israel Academy of Sciences and Humanities|Israel Academy of Sciences]], where he was the Head for Experimental Science Section.  He was one of the founding editors of the ''Israel Journal of Mathematics'', and the mathematical editor of the [[Encyclopaedia Hebraica|Hebrew Encyclopedia]].  Amitsur received a number of awards, including the [[honorary degree|honorary doctorate]] from [[Ben-Gurion University]] in 1990.  His students included [[Avinoam Mann]], [[Amitai Regev]], [[Eliyahu Rips]] and [[Aner Shalev]].

==Awards==
Amitsur and Jacob Levitzki were each awarded the [[Israel Prize]] in [[exact science]]s, in 1953, its inaugural year.&lt;ref&gt;{{cite web |url=http://cms.education.gov.il/educationcms/units/prasisrael/tashyag/tashkab_tashyag_rikuz.htm?dictionarykey=tashyag |title=Israel Prize recipients in 1953 (in Hebrew) |publisher=Israel Prize Official Site |archiveurl=https://www.webcitation.org/5n1ADmz0X?url=http://cms.education.gov.il/educationcms/units/prasisrael/tashyag/tashkab_tashyag_rikuz.htm?dictionarykey=tashyag |archivedate=January 24, 2010 |deadurl=yes |df= }}&lt;/ref&gt;

==See also==

*[[Amitsur–Levitzki theorem]]
*[[List of Israel Prize recipients]]

==Publications==

*{{Citation | doi=10.1090/S0002-9939-1950-0036751-9 | last1=Amitsur | first1=A. S. | last2=Levitzki | first2=Jakob | author2-link=Jacob Levitzki | title=Minimal identities for algebras | jstor=2032312 | mr=0036751 | year=1950 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=1 | issue=4 | pages=449–463}}
*{{Citation | last1=Amitsur | first1=S. A. | editor1-last=Mann | editor1-first=Avinoam | editor2-last=Regev | editor2-first=Amitai | editor3-last=Rowen | editor3-first=Louis | editor4-last=Saltman | editor4-first=David J. | editor5-last=Small | editor5-first=Lance W. | title=Selected papers of S. A. Amitsur with commentary. Part 1 | url=https://books.google.com/books?id=VQ8Kjp6KqjYC | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-2924-0 | mr=1866636 | year=2001}}
*{{Citation | last1=Amitsur | first1=S. A. | editor1-last=Mann | editor1-first=Avinoam | editor2-last=Regev | editor2-first=Amitai | editor3-last=Rowen | editor3-first=Louis | editor4-last=Saltman | editor4-first=David J. | editor5-last=Small | editor5-first=Lance W. | title=Selected papers of S. A. Amitsur with commentary. Part 2 | url=http://www.ams.org/bookstore-getitem/item=CWORKS-16 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-2925-7 | mr=1866637 | year=2001}}

==References==
{{reflist}}
* "Shimshon Avraham Amitsur (1921 — 1994)", by A. Mann, ''Israel Journal of Mathematics'', Vol. 96 (December 1996), ix - xxvii.
*{{Citation | last1=Formanek | first1=Edward | title=Review of Selected papers of S. A. Amitsur  | url=http://www.ams.org/journals/bull/2003-40-01/S0273-0979-02-00960-6/home.html | year=2003 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=40 | pages=131–135 | doi=10.1090/s0273-0979-02-00960-6}}

== External links ==
* {{MathGenealogy|name=Shimshon Amitsur|id=15652}}
* {{MacTutor Biography|id=Amitsur}}

{{Authority control}}

{{DEFAULTSORT:Amitsur, Shimshon}}
[[Category:Hebrew University of Jerusalem alumni]]
[[Category:Hebrew University of Jerusalem faculty]]
[[Category:Jews in Mandatory Palestine]]
[[Category:Israeli Jews]]
[[Category:Israel Prize in exact science recipients]]
[[Category:Israel Prize in exact science recipients who were mathematicians]]
[[Category:Members of the Israel Academy of Sciences and Humanities]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Israeli mathematicians]]
[[Category:20th-century Israeli mathematicians]]
[[Category:Algebraists]]
[[Category:People from Jerusalem]]
[[Category:1921 births]]
[[Category:1994 deaths]]</text>
      <sha1>kulgik79fnba1iwqzu47ex5yoee52n8</sha1>
    </revision>
  </page>
  <page>
    <title>Teo Mora</title>
    <ns>0</ns>
    <id>53596978</id>
    <revision>
      <id>865338077</id>
      <parentid>816830815</parentid>
      <timestamp>2018-10-23T09:06:51Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>/* Life and work */Typo fixing, replaced: algoritm → algorithm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19157">'''Ferdinando 'Teo' Mora'''{{efn|Teo Mora is his nickname, but used in most of his post-1980s publications; he has also used the [[pen name]] Theo Moriarty.&lt;ref name=universityBio/&gt;}} is an Italian [[mathematician]], and since 1990,&lt;ref name=universityBio/&gt; a professor of [[Algebraic geometry#Computational algebraic geometry|algebra]] at the [[University of Genoa]].{{efn|Currently in the Dipartimento di Matematica,&lt;ref name=universityBio/&gt; formerly{{when|date=April 2017}} in the Dipartimento di Informatica e Scienze dell'Informazione.  See [http://www.disi.unige.it/person/MoraF/ previous faculty-page].}}

== Life and work ==
Mora's degree is in mathematics from the [[University of Genoa]] in 1974.&lt;ref name=universityBio/&gt;  Mora's [[#Further_reading|publications]] span forty years; his notable contributions in [[computer algebra]] are the 
[[tangent cone]] algorithm&lt;ref&gt;[[#mora82|An algorithm to compute the equations of tangent cones]]; [[#PMT|An introduction to the tangent cone algorithm]].&lt;/ref&gt;&lt;ref&gt;Better algorithms due to [[#GP|Greuel-Pfister]] and [[#GR|Gräbe]] are currently available.&lt;/ref&gt; and its extension of [[Bruno Buchberger|Buchberger]] theory of [[Gröbner bases]] and related [[Buchberger's algorithm|algorithm]] earlier&lt;ref&gt;[[#mora85|Gröbner bases for non-commutative polynomial rings]].&lt;/ref&gt; to non-commutative [[polynomial ring]]s&lt;ref&gt;Extending the proposal set by [[#Diamond|George M. Bergman]].&lt;/ref&gt; and more recently&lt;ref&gt;[[#NG4|De Nugis Groebnerialium 4: Zacharias, Spears, Möller]], [[#Ceria|Buchberger–Weispfenning theory for effective associative rings]]; see also [[#7Var|Seven variations on standard bases]].&lt;/ref&gt; to effective rings; less significant&lt;ref&gt;The result is a weaker version of the result presented  
[[#BayerMorrison|in the same issue of the journal]] 
by Bayer and Morrison.&lt;/ref&gt; the notion of [[Gröbner fan]]; marginal, with respect to the other authors, his contribution to the [[FGLM algorithm]].
 
&lt;!-- * [[#mora82|1982 paper]] on [[tangent cone]]s
* [[#mora84|1984 paper]] on [[Gröbner bases]] and bounding the degree thereof 
* [[#mora85|1985 paper]] on [[Gröbner bases]] and non-commutative [[polynomial ring]]s
* [[#moellerMora86|1986 paper]] on [[ideal theory]] methods
* [[#mora88|1988 paper]] on the [[Gröbner fan]]
* [[#gianniMora89|1989 paper]] on [[Gröbner bases]] and [[systems of polynomial equations]] 
* [[#gioviniMora91|1991 paper]] on [[Buchberger algorithm]] selection-strategies
* [[#moellerMora92|1992 paper]] on [[Gröbner bases]] and [[syzygies]] 
* [[#marinariMoellerMora93|1993 paper]] on [[Gröbner bases]] and [[projective geometry|projective]] points 
* [[#fglm93|1993 paper]] on computing [[Gröbner bases]] using the [[FGLM algorithm]] (named for Mora and his co-authors) 
* [[#beckerMora94|1994 paper]] on the [[System of polynomial equations#Algebraic representation of the solutions|shape lemma]]
* [[#mora94|1994 paper]] on [[commutative]] and non-commutative [[Gröbner bases]]  
* [[#maranariMoellerMora96|1996 paper]] on [[multiplicities]] in [[polynomial system]]s
* [[#salaMora09|2009 book]] (co-editor and author of four chapters) on several aspects of [[Gröbner bases]] 
* [[#mora03|2003 book-volume]], ''Solving Polynomial Equation Systems I: The [[Kronecker]]-[[Duval]] Philosophy'', on equations [[Univariate polynomial#Equations|in one variable]]&lt;ref name=roberts06/&gt;
* [[#mora05|2005 book-volume]], ''Solving Polynomial Equation Systems II: [[Francis Sowerby Macaulay|Macaulay]]'s paradigm and [[Gröbner bases|Gröbner]] technology'', on [[system of polynomial equations|equations in several variables]]&lt;ref name=coutinho09/&gt;&lt;ref name=roberts06/&gt;
* [[#mora16|2016 book-volume]], ''Solving Polynomial Equation Systems IV: [[Bruno Buchberger|Buchberger]] Theory and Beyond'', on the [[Buchberger algorithm]] 
--&gt;
Mora is on the [[scientific peer review|managing-editorial-board]] of the journal ''[[Applicable Algebra in Engineering, Communication and Computing|AAECC]]'' published by [[Springer Science+Business Media|Springer]],&lt;ref name=aaeccBoard/&gt; and was also formerly an editor of the ''Bulletin of the [[Iranian Mathematical Society]]''.{{efn|See [http://www.disi.unige.it/person/MoraF/ previous faculty-page].}}

He is the author of the tetralogy ''Solving Polynomial Equation Systems'':
* ''Solving Polynomial Equation Systems I: The [[Kronecker]]-[[Duval]] Philosophy'', on equations [[Univariate polynomial#Equations|in one variable]]&lt;ref name=roberts06/&gt;
* ''Solving Polynomial Equation Systems II: [[Francis Sowerby Macaulay|Macaulay]]'s paradigm and [[Gröbner bases|Gröbner]] technology'', on [[system of polynomial equations|equations in several variables]]&lt;ref name=coutinho09/&gt;&lt;ref name=roberts06/&gt;
* ''Solving Polynomial Equation Systems III: Algebraic Solving'', 
* ''Solving Polynomial Equation Systems IV: [[Bruno Buchberger|Buchberger]] Theory and Beyond'', on the [[Buchberger algorithm]]

== Personal life ==

Mora lives in [[Genoa]].&lt;ref name=repubblica2002/&gt;  Mora published a [[#mora77|book trilogy in 1977-1978]] (reprinted 2001-2003) called ''{{illm|Storia del cinema dell'orrore|it|Storia del cinema dell'orrore (saggio)}}'' on the [[Horror film#History|history of horror films]].&lt;ref name=repubblica2002/&gt;  [[Radiotelevisione Italiana|Italian television]] said in 2014 that the books are an "authoritative guide with in-depth detailed descriptions and analysis."&lt;ref name=rai2014/&gt;

== See also ==

* [[FGLM algorithm]], [[Buchberger's algorithm]] 
* [[Gröbner fan]], [[Gröbner basis]] 
* [[Algebraic geometry#Computational algebraic geometry]], [[System of polynomial equations]]

== References ==
{{reflist|refs=

&lt;ref name=rai2014&gt;{{cite news 
|title= Mostri Universal 
|trans-title= The Universal Pictures monsters
|episode= 20 
|date= September 12, 2014 
|author= &lt;!-- unknown... who was the interviewer? --&gt; 
|publisher= RAI 4, [[Radiotelevisione Italiana]] 
|url= http://www.melevisione.rai.it/dl/portali/site/puntata/ContentItem-adc98db7-9c95-4f96-a77e-59b8f27ecd00.html 
|quote= "...[text:] L'intervista &amp;mdash; Teo Mora: Professore di Algebra presso il dipartimento di Informatica e Scienze dell'Informazione dell'Università di Genova, è anche un noto esperto di cinema horror. Ha curato ''Storia del cinema dell'orrore'', un'autorevole guida in tre volumi con approfondimenti, schede e analisi dettagliate sui film, i registi e gli attori... [multimedia: video content] ..."
}}  Translation:  "...[text:] professor of Algebra in the Computer and Information Science department of the [[University of Genoa]], also a well-known expert on horror films.  His book ''Storia del cinema dell'orrore'' is an authoritative guide with in-depth detailed descriptions and analysis of films, directors, and actors... [multimedia: video content] ..."&lt;/ref&gt;

&lt;ref name=repubblica2002&gt;{{cite news 
|title= O tempora, O... Teo Mora
|author= [[Giovanni Bogani]] 
|date= December 11, 2002
|publisher= [[Repubblica.it]] 
|location= [[Genoa, Italy]] &lt;!-- byline --&gt; 
|url= http://trovacinema.repubblica.it/news/dettaglio/o-tempora-oteo-mora/198071/
|quote= ...Teo Mora vive a Genova. ...scritto libri come ''[[#alonsoMarinariMora03|La madre di tutte le dualità: l'algoritmo di Moeller]]'', ''[[#caboaraMora02|Il teorema di Kalkbrenner]]'', o ''[[#mora94|L'algoritmo di Buchberger]]'' ... Negli [1977] anni ’70, Mora aveva scritto una monumentale ''Storia del cinema horror''. ... la [2001] ripropone, in una nuova edizione, riveduta, corretta e completamente aggiornata. ...Nel primo volume... fino al 1957... ''[[Nosferatu]]'', attori come [[Boris Karloff]] e [[Bela Lugosi]]... film come ''[[The Cabinet of Dr Caligari|Il gabinetto del dottor Caligari]]''. ...Nel secondo volume si arriva fino al 1966... [[Roger Corman]]... Il terzo volume arriva fino al 1978... [[Brian De Palma]], [[David Cronenberg]], [[George Romero]], [[Dario Argento]], [[Mario Bava]]. ...
}} Translation:  "...Teo Mora lives in [[Genoa]]. ...written works include ''[[#alonsoMarinariMora03|The Mother of All Dualities: The Möller Algorithm]]'', ''[[#caboaraMora02|The Kalkbrenner Theorem]]'', and ''[[#mora94|The Buchberger Algorithm]]'' ... In the 1970s, Mora wrote the monumental ''[[#mora77|History of Horror Cinema]]''. ...reprinted [in 2001], as a new edition: revised, corrected, and completely updated. Two volume are already out, the third [volume] will be released in late January [2002], the fourth [volume] in spring 2003. ... In the first volume... [covering] through 1957... ''[[Nosferatu]]'', actors like [[Boris Karloff]] and [[Bela Lugosi]]... films like ''[[The Cabinet of Dr Caligari]]''. ...The second volume covers until 1966... [[Roger Corman]], director ...The third volume covers through 1978... [[Brian De Palma]], [[David Cronenberg]], [[George Romero]], [[Dario Argento]], [[Mario Bava]]. ..."&lt;/ref&gt;

&lt;ref name=universityBio&gt;
[https://fermat.dima.unige.it/didattica/matematica/new/index.php/component/anagrafica/docenti/27/MoraTeo.html University of Genoa faculty-page]. 
&lt;/ref&gt;

&lt;ref name=aaeccBoard&gt;
[https://www.springer.com/computer/theoretical+computer+science/journal/200/PS2?detailsPage=editorialBoard Springer-Verlag website].
&lt;/ref&gt;

&lt;!--&lt;ref name=catania08&gt;
[http://www.sci.ccny.cuny.edu/~ksda/darca.pdf CUNY website].
&lt;/ref&gt; --&gt;

&lt;ref name=coutinho09&gt;{{cite web 
|title= Review of solving polynomial equation systems II: Macaulay's paradigm and Gröbner technology by Teo Mora (Cambridge University Press 2005)
|author= S. C. Coutinho ([[Federal University of Rio de Janeiro|UFRJ]]) &lt;!-- associate professor of computer science per http://dcc.ufrj.br/~collier/ --&gt; 
|date= March 2009
|publisher= [[Association for Computing Machinery]] 
|work= [[SIGACT]] Newsletter
|volume= 40
|issue= 1
|pages= 14–17
|location= [[NYC|New York]]
|doi= 10.1145/1515698.1515702
|url= https://www.cs.umd.edu/~gasarch/bookrev/40-1.pdf#page=7  &lt;!-- ''The Book Review Column'' by William Gasarch ([[University of Maryland at College Park|UMCP]]) --&gt;
|via= [http://dl.acm.org/citation.cfm?id=1515702 Publisher's site] 
}}&lt;/ref&gt;

&lt;ref name=roberts06&gt;{{cite web 
|title= [Review of the book] Solving Polynomial Equation Systems I: The Kronecker-Duval Philosophy [and also Solving Polynomial Equation Systems II: Macaulay's Paradigm and Gröbner Technology] 
|author= David P. Roberts ([[University of Minnesota, Morris|UMN]]) &lt;!-- associate professor of mathematics, see http://cda.morris.umn.edu/~roberts --&gt;
|date= September 14, 2006
|publisher= [[Mathematical Association of America]] Press &lt;!-- http://www.maa.org/press/maa-reviews/about-maa-reviews --&gt; 
|url= http://www.maa.org/press/maa-reviews/solving-polynomial-equation-systems-i-the-kronecker-duval-philosophy 
}}&lt;/ref&gt;

}}&lt;!-- end reflist --&gt;

== Notes ==
{{notelist}}

== Further reading ==
* {{anchor|mora77}}{{cite book 
|title= Storia del cinema dell'orrore
|author= Teo Mora
|date= 1977 &lt;!-- and 1978 --&gt; 
|isbn= 88-347-0800-8
|volume= 1
|publisher= [[Fanucci]] 
|url= http://www.fantascienza.com/catalogo/opere/NILF1133301/storia-del-cinema-dell-orrore-vol-primo-1895-1956/
}}.  {{cite web|title= Second |url= http://www.fantascienza.com/catalogo/opere/NILF1133300/storia-del-cinema-dell-orrore-vol-secondo-tomo-primo-1957-19/}} and {{cite web|title= third |url= http://www.fantascienza.com/catalogo/opere/NILF1133299/storia-del-cinema-dell-orrore-vol-secondo-tomo-secondo-1957/}} volumes:  {{ISBN|88-347-0850-4}}, {{ISBN|88-347-0897-0}}.  Reprinted 2001.
* {{anchor|Diamond}}{{cite journal 
|title = The diamond lemma for ring theory
|journal = Advances in Mathematics
|volume = 29
|number = 2
|pages = 178–218
|year = 1978
|url = http://www.sciencedirect.com/science/article/pii/0001870878900105
|author = George M Bergman
}}
* {{anchor|mora82}}&lt;!-- 119 cites in scholar.google.com as of 2017--&gt;{{cite journal 
|title= An algorithm to compute the equations of tangent cones
|author= F. Mora
|work= Proc.EUROCAM'82: [[Lecture Notes in Computer Science]] (Computer algebra) 
|volume= 144
|pages= 158–165
|date= 1982 
|publisher= [[Springer Science+Business Media|Springer]]
|url= http://www.springerlink.com/index/F4R7R80301521161.pdf
}} 
* {{anchor|mora85}}&lt;!-- 211 cites in scholar.google.com as of 2017--&gt;{{cite journal 
|title= Gröbner bases for non-commutative polynomial rings
|author= F. Mora
|date= 1986
|work= Proc.AAECC3: [[Lecture Notes in Computer Science]]
|volume= 229
|pages= 353–362
|publisher= [[Springer Science+Business Media|Springer]]
|url= https://link.springer.com/content/pdf/10.1007/3-540-16776-5_740.pdf
}} 
* {{anchor|BayerMorrison}}{{cite journal 
|title= Standard bases and geometric invariant theory I. Initial ideals and state polytopes
|author1= David Bayer
|author2= Ian Morrison
|work= [[Journal of Symbolic Computation]]
|date= 1988
|publisher= [[Elsevier]]
|volume= 6
|pages= 209–218
|url= http://www.sciencedirect.com/science/article/pii/S0747717188800439
}} 
** also in: {{cite book 
|title=Computational Aspects of Commutative Algebra 
|editor= Lorenzo Robbiano
|date= 1989 
|publisher=[[Academic Press]] 
|volume= 6
|number= 2-3 
|location= [[London]] 
}} 
*{{anchor|7Var}}{{cite journal 
|title= Seven variations on standard bases
|author= Teo Mora
|date= 1988
|url= http://www.dima.unige.it/~morafe/PUBLICATIONS/7Variations.pdf.gz
|via= [http://www.ricam.oeaw.ac.at/Groebner-Bases-Bibliography/details.php?details_id=1082 Bibliography] 
}}
*{{anchor|PMT}}{{cite journal 
|title= An introduction to the tangent cone algorithm
|author= Gerhard Pfister, T.Mora, Carlo Traverso
|date= 1992
|editor= Christoph M Hoffmann
|work= Issues in Robotics and Nonlinear Geometry (Advances in Computing Research)
|volume= 6
|pages= 199–270
|publisher= [[JAI Press]]
|location= [[Greenwich, Connecticut]]
|url= http://www.dima.unige.it/~morafe/PUBLICATIONS/TgCone.ps.gz  
}} 
* {{anchor|mora94}}&lt;!-- 268 cites in scholar.google.com as of 2017--&gt;{{cite journal 
|title= An introduction to commutative and non-commutative Gröbner bases
|author= T. Mora
|date= 1994
|work= [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
|volume= 134
|pages= 131–173
|publisher= [[Elsevier]]
|url= http://www.dima.unige.it/~morafe/PUBLICATIONS/Kyoto.ps.gz
|via= [http://www.sciencedirect.com/science/article/pii/0304397594902836 Publisher's site] 
}} 
*{{anchor|Gr}}{{cite journal 
|title = Algorithms in Local Algebra
|journal = Journal of Symbolic Computation
|volume = 19
|year=1995
|number = 6
|pages = 545–557
|url = http://www.sciencedirect.com/science/article/pii/S0747717185710310
|author = Hans-Gert Gräbe 
}}
*{{anchor|GP}}{{cite journal 
| title=Advances and improvements in the theory of standard bases and syzygies 
| author1=Gert-Martin Greuel 
| author2=G. Pfister
| year=1996 
| url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.49.1231&amp;rep=rep1&amp;type=pdf 
}}
* {{anchor|caboaraMora02}}&lt;!-- 19 cites in scholar.google.com as of 2017--&gt;{{cite journal 
|title= The Chen-Reed-Helleseth-Truong Decoding Algorithm and the Gianni-Kalkbrenner Gröbner Shape Theorem
|author= M.Caboara, T.Mora
|date= 2002
|work= AAECC:  J.Appl.Alg
|volume= 13
|pages= 209–232
|publisher= [[Springer Science+Business Media|Springer]] 
|url= https://www.researchgate.net/profile/Massimo_Caboara/publication/2842166_The_Chen-Reed-Helleseth-Truong_Decoding_Algorithm_and_the_Gianni-Kalkbrenner_Grbner_Shape_Theorem/links/0fcfd50a665923b3ea000000.pdf
|via= [https://link.springer.com/article/10.1007/s002000200097 Publisher's site]. [http://www.dima.unige.it/~morafe/PUBLICATIONS/codici.ps.gz Author's site]. 
}} 
* {{anchor|alonsoMarinariMora03}}&lt;!-- 24 cites in scholar.google.com as of 2017--&gt;{{cite journal 
|title= The Big Mother of All the Dualities, I: Möller Algorithm
|author= M.E. Alonso, M.G. Marinari, M.T. Mora
|work= [[Communications in Algebra]]
|date= 2003
|volume= 31
|pages= 783–818
|publisher= [[Taylor &amp; Francis]]
|url= https://www.researchgate.net/profile/Mariemi_Alonso/publication/2656876_The_Big_Mother_of_All_the_Dualities_Mller_Algorithm/links/55a757bb08aeb4e8e646e270.pdf
|via= [https://tandfonline.com/doi/abs/10.1081/AGB-120017343 Publisher's site]. [http://www.dima.unige.it/~morafe/PUBLICATIONS/3Marie.ps.gz Author's site].  
}} 
* {{anchor|spes1}}&lt;!-- 126 cites in scholar.google.com as of 2017 for the series --&gt;{{cite book 
|title= Solving Polynomial Equation Systems I: The Kronecker-Duval Philosophy
|author= Teo Mora
|isbn= 9780521811545
|date= March 1, 2003
|publisher= [[Cambridge University Press]]
|series= Encyclopedia of Mathematics and its Applications Series
|volume= 88
|url= https://pdfs.semanticscholar.org/2a1b/a06e6d22c18caf539b7862d6e9c9d7b076ab.pdf 
|via= [http://www.cambridge.org/ca/academic/subjects/mathematics/algebra/solving-polynomial-equation-systems-i-kronecker-duval-philosophy?format=HB&amp;isbn=9780521811545 Publisher's website]. [http://www.langtoninfo.com/web_content/9780521811545_excerpt.pdf Excerpt]. 
}}
* {{anchor|spes2}}&lt;!-- 126 cites in scholar.google.com as of 2017 for the series --&gt;{{cite book 
|title= Solving Polynomial Equation Systems II: Macaulay's Paradigm and Gröbner Technology
|author= T. Mora
|date= 2005
|publisher= [[Cambridge University Press]]
|series= Encyclopedia of Mathematics and its Applications
|volume= 99
}} 
* {{anchor|spes3}}{{cite book 
|title= Solving Polynomial Equation Systems III: Algebraic Solving
|author= T. Mora
|date= 2015
|publisher= [[Cambridge University Press]]
|series= Encyclopedia of Mathematics and its Applications
|volume= 157
}} 
* {{anchor|spes1}}&lt;!-- 126 cites in scholar.google.com as of 2017 for the series--&gt;{{cite book 
|title= Solving Polynomial Equation Systems IV: Buchberger Theory and Beyond
|author= T Mora
|date= 2016
|publisher= [[Cambridge University Press]]
|series= Encyclopedia of Mathematics and its Applications
|volume= 158
|url= https://books.google.com/books?id=3O-7CwAAQBAJ
}} 
*{{anchor|NG4}}{{cite journal 
|title= De Nugis Groebnerialium 4: Zacharias, Spears, Möller
|author= T. Mora
|date= 2015
|work= Proc. ISSAC '15
|pages= 283–290
|publisher= [[Association for Computing Machinery]] 
|url= http://doi.acm.org/10.1145/2755996.2756640
}} 
*{{anchor|Ceria}}{{cite journal 
|title = Buchberger–Weispfenning theory for effective associative rings
|journal = Journal of Symbolic Computation
|year = 2016
|url = http://www.sciencedirect.com/science/article/pii/S0747717116301274,
|author1 = Michela Ceria
|author2 = Teo Mora
}}  
* {{anchor|mora16}}&lt;!-- 126 cites in scholar.google.com as of 2017 for the series--&gt;{{cite book 
|title= Solving Polynomial Equation Systems IV: Buchberger Theory and Beyond
|author= T Mora
|date= 2016
|publisher= [[Cambridge University Press]]
|series= Encyclopedia of Mathematics and its Applications
|volume= 158
|url= https://books.google.com/books?id=3O-7CwAAQBAJ
}}

== External links ==
* [http://www.dima.unige.it/~morafe Official page]

{{Authority control}}

{{DEFAULTSORT:Mora, Teo}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Italian mathematicians]]
[[Category:Computer algebra]]
[[Category:University of Genoa faculty]]
[[Category:University of Genoa alumni]]</text>
      <sha1>oxxnniu3kw003m0z6qoqryhyxn9bzdu</sha1>
    </revision>
  </page>
  <page>
    <title>Toilet paper orientation</title>
    <ns>0</ns>
    <id>27936530</id>
    <revision>
      <id>860347229</id>
      <parentid>860347160</parentid>
      <timestamp>2018-09-20T01:29:52Z</timestamp>
      <contributor>
        <ip>2620:102:401F:4000:D:188D:C6DE:9574</ip>
      </contributor>
      <comment>/* Survey results */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="53241">{{Use dmy dates|date=October 2013}}
{{multiple image
| header    = Toilet paper orientation
| width     = 200
| image1    = Toilet paper orientation over.jpg
| caption1  = The ''over'' orientation
| image2    = Toilet paper orientation under.jpg
| caption2  = The ''under'' orientation
}}

[[Toilet paper]] when used with a [[toilet roll holder]] with a horizontal [[axle]] [[parallel (geometry)|parallel]] to the floor and also parallel to the wall has two possible orientations: the toilet paper may hang ''over'' (in front of) or ''under'' (behind) the roll; if perpendicular to the wall, the two orientations are right-left or near-away. The choice is largely a matter of personal preference, dictated by [[habit (psychology)|habit]]. In surveys of US consumers and of bath and kitchen specialists, 60–70 percent of respondents prefer ''over''.

Some people hold strong opinions on the matter; advice columnist [[Ann Landers]] said that the subject was the most responded to (15,000 letters in 1986) and controversial issue in her column's history. Defenders of either position cite advantages ranging from aesthetics, hospitality, and cleanliness to paper conservation, the ease of detaching individual sheets, and compatibility with setting specifics such as [[recreational vehicle]]s or having pets. Some writers have proposed connections to age, sex, or political philosophy, and survey evidence has shown a correlation with socioeconomic status.&lt;ref&gt;For pros and cons, including RVs and cats, see [[#Arguments|Arguments]]; for celebrities and experts, including Ann Landers, see [[#Noted preferences|Noted preferences]]; for theories, see [[#Themes|Themes]].&lt;/ref&gt;  

Solutions range from compromise, to using separate dispensers or separate bathrooms entirely, or simply ignoring the issue altogether. One man advocates a plan under which his country will standardize on a single forced orientation, and at least one inventor hopes to popularize a new kind of toilet roll holder which swivels from one orientation to the other.&lt;ref&gt;The enthusiast, Bill Jarrett, and the inventor, Curtis Batts, are described in [[#Solutions|Solutions]].&lt;/ref&gt;

=={{anchor|Motivations for study}}Context and relevance==
In the article "Bathroom Politics: Introducing Students to Sociological Thinking from the Bottom Up",{{sfn|Burns|2003}} [[Eastern Institute of Technology]] [[sociology]] professor Edgar Alan Burns describes some reasons toilet paper politics is worthy of examination. On the first day of Burns' introductory course in sociology, he asks his students, "Which way do you think a roll of toilet paper should hang?"{{sfn|Burns|2003|p=111}} In the following fifty minutes, the students examine why they picked their answers, exploring the [[social construction]] of "rules and practices which they have never consciously thought about before".{{sfn|Burns|2003|p=113}} 

Burns' activity has been adopted by a [[social psychology]] course at the [[University of Notre Dame]], where it is used to illustrate the principles of [[Peter L. Berger|Berger]] and [[Thomas Luckmann|Luckmann]]'s 1966 classic ''[[The Social Construction of Reality]]''.{{sfn|Collett|2008}} 

[[Christopher Peterson (psychologist)|Christopher Peterson]], a professor of psychology at the [[University of Michigan]], classifies the choice of toilet paper orientation under "tastes, preferences, and interests" as opposed to either [[value (personal and cultural)|values]] or "attitudes, traits, norms, and needs". Other personal interests include one's favorite cola or baseball team. Interests are an important part of [[identity (social science)|identity]]; one expects and prefers that different people have different interests, which serves one's "sense of uniqueness". Differences in interests usually lead at most to teasing and gentle chiding. For most people, interests don't cause the serious divisions caused by conflicts of values; a possible exception is what Peterson calls "the 'get a life' folks among us" who elevate interests into moral issues.{{sfn|Peterson|2006|pp=173–175}}

[[Morton Ann Gernsbacher]], a professor of psychology at the [[University of Wisconsin–Madison]], compares the orientation of toilet paper to the orientation of cutlery in a dishwasher, the choice of which drawer in a [[chest of drawers]] to place one's socks, and the order of shampooing one's hair and lathering one's body in the shower. In each choice, there is a prototypical solution chosen by the majority, and it is tempting to offer simplistic explanations of how the minority must be different. She warns that [[neuroimaging]] experiments—which as of 2007 were beginning to probe behaviors from [[mental rotation]] and [[facial expression]]s to grocery shopping and [[tickling]]—must strive to avoid such [[cultural bias]] and [[stereotype]]s.{{sfn|Gernsbacher|2007}}

In his book ''[[Conversational Capital]]'', Bertrand Cesvet gives toilet paper placement as an example of [[ritual]]ized behavior—one of the ways designers and marketers can create a memorable experience around a product that leads to [[word-of-mouth]] momentum. Cesvet's other examples include shaking a box of [[Tic Tac]]s and dissecting [[Oreo]] cookies.{{sfn|Cesvet|Babinski|Alper|2008|p=68}}

Broadcaster [[Jim Bohannon]] has said that such issues are good for [[talk radio]]: "It is an interactive medium, a certain kind of clash, it doesn't have to be a violent clash, but at least a disagreement would certainly be at the top of the list. It has to be something that's of general interest."{{sfn|Voice of America|2004}}

==Arguments for over or under==
[[File:Toilet paper in Hotel Monasterio.jpg|thumb|Folded and sealed toilet paper with cover, [[Hotel Monasterio]] 2009]]
[[File:ToiletPaper Boo WrongWay.jpg|thumb|Paper mounted ''under'' with upside-down images and text]]
The main reasons given by people to explain why they hang their toilet paper a given way are ease of grabbing and habit.{{sfn|Progressive Grocer|2010}} Some particular advantages cited for each orientation include:
* ''Over'' reduces the risk of accidentally brushing the wall or cabinet with one's knuckles, potentially transferring grime and germs.&lt;ref&gt;{{harvnb|Ode|2010}}: "The Kimberly-Clark company cites three advantages for rolling over: perforation control, viewing advantage and wall avoidance."; {{harvnb|Garton|2005}}; {{harvnb|Jarski|Jarski|2007}}.&lt;/ref&gt;
* ''Over'' makes it easier to visually locate and to grasp the loose end.&lt;ref&gt;{{harvnb|Ode|2010}}; {{harvnb|Elliott|2006}}&lt;/ref&gt;
* ''Over'' gives hotels, cruise ships, office buildings, public places and homeowners with guest bathrooms the option [[hotel toilet paper folding|to fold over the last sheet]] to show that the room has been cleaned.&lt;ref&gt;{{harvnb|Lind|1992}}; "The Grand Princess cruise ship replaces its toilet paper with the leading edge over the front, so that it can be folded as is done in five-star hotels. (Yes, someone really did ask this question.)" {{harv|Carpenter|1999}}; {{harvnb|Rosencrans|1998}}; {{harvnb|Garton|2005}}.&lt;/ref&gt;
* ''Over'' is generally the intended direction of viewing for the manufacturer's branding, so patterned toilet paper looks better this way.&lt;ref&gt;{{harvnb|Grant|1991b}}; {{harvnb|Garton|2005}}; {{harvnb|Mitchell|Sugar|2005a}}; {{harvnb|Jarski|Jarski|2007}}.&lt;/ref&gt;
* ''Under'' provides a tidier appearance, in that the loose end can be more hidden from view.&lt;ref&gt;{{harvnb|Jarski|Jarski|2007}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Toilet Paper Orientation Re: Brandweek 2009| url=http://plumbersshrewsbury.co.uk/toilet-paper-orientation-brandweek-2009/ |accessdate=2015-01-21 }}&lt;/ref&gt;
* ''Under'' reduces the risk that a toddler or a house pet, such as a dog or cat, will completely unroll the toilet paper when batting at the roll.&lt;ref&gt;{{harvnb|Darbo|2007}}; {{harvnb|Garton|2005}}; {{harvnb|O'Connor|2005|p=63}}.&lt;/ref&gt;
* ''Under'' in a [[recreational vehicle]] may reduce unrolling during driving.{{sfn|Nerbas|2009}}

Partisans have claimed that each method makes it easier to tear the toilet paper on a [[perforated]] sheet boundary, depending on the direction of pulling and the use of a second hand to stabilize the roll.&lt;ref&gt;{{harvnb|Ode|2010}}; {{harvnb|Weingarten|2008}}; {{harvnb|Keeran|1993}}.&lt;/ref&gt; (A traveller from the U.S. to China in 1991 noted a different setup: non-perforated paper with a metal cutter above the roll, which obliges the ''over'' direction.){{sfn|Downey|Harrison|1993}}

It is unclear if one orientation is more economical than the other. The ''[[Centralian Advocate]]'' attributes a claim that ''over'' saves on paper usage to [[Planet Green]].{{sfn|McNatt|2010}}

In the academic field of [[evaluation]], [[Michael Scriven]] writes that the question of the correct way to insert toilet paper is a "one-item aptitude test" for measuring one's evaluation skills. These skills include the evaluative attitude, practical logical analysis, empathy, teaching, and being a quick study. To prove one's competence, one may either derive the "one right answer" or prove that the test is or is not culturally biased.{{sfn|Scriven|1991|loc="Evaluation Thesaurus", pp. 151–153, especially p. 153 for the quotations}}

==Preferences==
[[File:Multi-orientable toilet paper holder.jpg|thumb|right|Multi-orientable toilet paper holder]]
[[File:Zijdezacht en schuurpapier.JPG|thumb|Another solution: two paper holders, even with different toilet paper.]]

===Survey results===
The question "Do you prefer that your toilet tissue unwinds over or under the spool?" is featured on the cover of Barry Sinrod and Mel Poretz's 1989 book ''The First Really Important Survey of American Habits''. The overall result: 68 percent chose over.{{sfn|Rubin|1989}} Sinrod explained, "To me, the essence of the book is the toilet paper question ... Either people don't care, or they care so much that they practically cause bodily injury to one another."{{sfn|Oldenburg|1989}} Poretz observed, "The toilet-paper question galvanizes people almost like the [[Miller Lite]] tastes-great/less-filling commercial."{{sfn|Mark Wolf Scripps Howard News Service|1990}}

In Bernice Kanner's 1995 book ''Are You Normal?'', 53 percent of survey respondents prefer ''over'', while "a fourth" prefer ''under'' and 8 percent do not know or care.{{sfn|Kanner|1995|pp=56, 120}}

''Sitting Pretty: The History of the Toilet'', a [[travelling exhibition]] that tours Canadian museums, asks visitors to register their preferred roll direction. When the exhibition reached [[Huntsville, Ontario]], in June 2001, 13,000 visitors had taken the survey, with 67 percent preferring ''over''.{{sfn|Ladan|2001}} At the [[Saint Boniface Museum]] in [[Winnipeg]] in February 2005, a voting machine registered 5,831 ''over'' versus 5,679 ''under'', or 51 percent ''over''. Saint Boniface's director noted, "I think there's been some cheating, though."{{sfn|Nestruck|2005}}

[[Georgia-Pacific]] commissioned a survey of Americans' bathroom habits in 1993 to launch its new [[Quilted Northern]] brand, and more surveys followed:&lt;ref&gt;The 1996 report, which may not have contained this question, was the fourth annual report: {{harv|McCarthey|1996}}&lt;/ref&gt;
* 1993 Practices and Preferences of Toilet Paper Users: 73 percent ''over'' out of 1,200 respondents. The press release claims, "A first-of-its-kind survey has settled, once and for all, the great toilet paper debate."{{sfn|PR Newswire|1993}}
* 1994 Toilet Paper Report: 59 percent ''over'',{{sfn|Ortega|1995}} out of 1,000 respondents; conducted by KRC Research and Consulting{{sfn|Ciancio|1994}}
* 1995 Bathroom Tissue Report: 59 percent ''over'' versus 29 percent ''under'',{{sfn|Ciancio|1995}} out of 1,000 respondents; conducted by KRC Research and Consulting{{sfn|Ortega|1995}}
* 2001 Bathroom Confidential: 63 percent ''over'' out of 1,001 respondents; conducted by Impulse Research{{sfn|Dickson|2001}}
* 2004 Bathroom Confidential: 72 percent ''over''&lt;ref&gt;{{harvnb|Ebenkamp|2004}}; {{harvnb|Pierson|2004}}.&lt;/ref&gt;

In 1993, [[American Standard Brands]] conducted a poll of "designers, contractors, dealers, distributors and other bath and kitchen reps"{{sfn|Toronto Star staff and news services|1993}} at the [[Kitchen/Bath Industry Show &amp; Conference]] in [[Atlanta]]. The question: "What is the correct and only way to hang the toilet paper – under or over?"{{sfn|Stark|1993}} ''Over'' won 59 percent of the vote, 1,826 to 1,256.{{sfn|Toronto Star staff and news services|1993}} American Standard spokeswoman Nora Monroe observed, "The bathroom is a territorial place. You'd be surprised how many people have definite opinions on this issue."{{sfn|Clark|1993}} In 2008, American Standard commissioned the 2008 Bathroom Habits Survey, a more traditional format conducted by [[Opinion Research Corporation]] with 1,001 respondents. This time, "three-quarters" answered ''over''.{{sfn|American Standard Press|2008}}

In 1995, a survey by [[Scott Paper Company]]'s "Cottonelle College of Freshness Knowledge" had "most Americans over 50" preferring ''over''.{{sfn|Harden|1995}} In another [[Cottonelle]] survey in 1999, 68 percent of respondents preferred ''over'' to 25 percent ''under''. Columnist Bonnie Henry hypothesizes of the others: "Meanwhile, 7 percent – no doubt bored beyond belief at this point by the inane questioning – had slipped into a deep, irreversible coma."{{sfn|Henry|1999}}

On January 27, 2010, the 100th anniversary of [[Thomas Crapper]]'s death,{{sfn|Progressive Grocer|2010}} Cottonelle launched a "Great Debate" advertising campaign, inviting American consumers to vote their preference at a [[Kimberly-Clark]] website.&lt;ref&gt;[http://www.cottonellerollpoll.com/ CottonelleRollPoll.com]&lt;/ref&gt; The result was announced during the [[82nd Academy Awards]]: 72 percent had voted ''over''.{{sfn|Ode|2010}} In a more traditional preliminary survey of 1,000 Americans, Cottonelle found that "overs" are more likely than "unders" to notice a roll's direction (74 percent), to be annoyed when the direction is incorrect (24 percent), and to have flipped the direction at a friend's home (27 percent).{{sfn|PR Newswire|2010}}

===Themes===

====Sex and age====
Poretz and Sinrod break down the results of their 1989 survey by sex and age. These are the percentages of respondents who roll their paper ''under'':{{sfn|Poretz|Sinrod|1989|p=34}}
{| class="wikitable"
|-
! {{diagonal split header|Sex|Age}}
! colspan="2" style="width:3.5em;"|21–34
! colspan="2" style="width:3.5em;"|35–44
! colspan="2" style="width:3.5em;"|45–54
! colspan="2" style="width:3.5em;"|55+
! colspan="2" style="width:4.5em;"|Average
|- style="text-align:center;"
! Male
| {{bartable|29|%}} || {{bartable|19|%}} || {{bartable|40|%}} || {{bartable|37|%}} || {{bartable|31|%}}
|- style="text-align:center;"
! Female
| {{bartable|19|%}} || {{bartable|35|%}} || {{bartable|38|%}} || {{bartable|17|%}} || {{bartable|33|%}}
|- style="text-align:center;"
! Average
| {{bartable|24|%}} || {{bartable|27|%}} || {{bartable|39|%}} || {{bartable|27|%}} || {{bartable|32|%}}
|}

The book does not note the number of respondents in each segment, so it is difficult to say whether any of the deviations are [[statistically significant]], but there does not seem to be a difference between men's and women's preferences. Nonetheless, such a difference has been claimed by other authors, in both directions. The American Standard conference poll concluded: "Many men voted for over, saying it made the paper easier to reach."{{sfn|Clark|1993}} Inventor Curtis Batts arrives at a different conclusion from his personal experience: "Women like it over, and men like it under. I think it bugs women when it touches the wall."{{sfn|Floyd|1999}} Advice columnist Ms Maud of ''[[The Press]]'' asserts that women prefer ''over'' because they are "logical thinkers".{{sfn|Ms Maud|2002}}

A Cottonelle survey indicated that men were more likely than women to notice, and become annoyed with, a toilet roll hung against their preference.{{sfn|Kimberly-Clark|2010}}

A [[popular-culture]] occurrence of a gender theory is found in the ''[[Weekly World News]]'', a [[supermarket tabloid]] that runs outlandish stories for comedic effect. In the 2003 story ''North Korea Shocker!'', the ''WWN'' claimed that North Korean leader [[Kim Jong-il]] was [[Passing (gender)|secretly female]]. As supporting evidence, Kim supposedly watched the [[Home Shopping Network]], is a member of [[Oprah's Book Club]], and "Yells at staffers who leave the toilet seat up and hang toilet paper rolls outward instead of inward."{{sfn|LaForte|2003}}

According to ''W. C. Privy's Original Bathroom Companion, Number 2'', "By more than 4 to 1, older folks prefer to have their toilet paper dispense over the front."{{sfn|Barrett|Mingo|2003|p=400}} The same claim is made by James Buckley's ''The Bathroom Companion'' for people older than 50.{{sfn|Buckley|2005|p=106}}

====Class and politics====
Sinrod observed of his survey, "60 percent of those who earn $50,000 or more prefer it to be over and 73 percent of those who earn less than $20,000 prefer under".{{sfn|Oldenburg|1989}} On what that proves: "I don't know, but it's sure interesting."{{sfn|Rubin|1989}}

In one [[local election]] in [[Saskatoon, Saskatchewan]], new [[voting machine]]s were given a trial run by asking the question, "Are you in favor of toilet paper in all public washrooms being installed with the loose end coming up and over the front of the roll?" The answer was yes: 768 to 196, or 80 percent ''over''. It was thought to be a question "which carried no political association".{{sfn|Landers|1998}} Yet one teenager's [[science project]] at the Southern Appalachian Science and Engineering Fair, and a favorite of the fair's coordinator, was a survey concluding that [[liberalism|liberals]] roll over while [[conservatism|conservatives]] roll under.{{sfn|Keim|1997}}

===Noted preferences===

Advice columnist [[Ann Landers]] ([[Eppie Lederer]]) was once asked which way toilet paper should hang. She answered ''under'', prompting thousands of letters in protest; she then recommended ''over'', prompting thousands more.{{sfn|Marelius|1987}} She reflected that the 15,000 letters made toilet paper the most controversial issue in her column's 31-year history,{{sfn|Toronto Star|1986}} wondering, "With so many problems in the world, why were thousands of people making an issue of tissue?"{{sfn|Marelius|1987}}

In November 1986, Landers told the [[Canadian Commercial Travellers Association]] that "Fine-quality toilet paper has designs that are right side up" in the ''over'' position.{{sfn|Toronto Star|1986}} In 1996, she explained the issue on ''[[The Oprah Winfrey Show]]'', where 68 percent of the [[studio audience]] favored ''over''; [[Oprah Winfrey|Oprah]] suggested that ''under'' uses more paper.{{sfn|The Oprah Winfrey Show|1996}} In 1998, she wrote that the issue "seems destined to go on forever", insisting, "In spite of the fact that an overwhelming number of people prefer the roll hung so that the paper comes over the top, I still prefer to have the paper hanging close to the wall."{{sfn|Landers|1998}} On the day of her last column in 2002, Landers wrote, "P.S. The toilet paper hangs over the top."{{sfn|Landers|2002}} Her published commentary on the issue has even continued after her death. 2005 saw the premiere of a one-woman play written by [[David Rambo]]: a character study of Ann Landers titled ''The Lady with All the Answers''. Toilet paper comes up once again, and the actress surveys the audience for their opinions.&lt;ref&gt;{{harvnb|Welsh|2005}}; {{harvnb|Rawson|2008}}.&lt;/ref&gt;

In his article in ''Teaching Sociology'', Burns writes that the toilet paper hanging exercise is valuable in part because "[the] subject matter is familiar to everybody; everyone is an expert, and everyone has an opinion."{{sfn|Burns|2003|p=116}} Many entertainers, celebrities and businesspeople have publicized their opinion on the topic. 

[[image:Toilet-paper-roll-patent-US465588-0.png|thumb|Seth Wheeler's original (''[[circa|c.]]'' 1891) U.S. Patent illustration.&lt;ref&gt;{{cite web|author1=Maybelle Morgan|title=Over or under? The age-old debate of which way a roll of toilet paper should sit is FINALLY settled... by a 124-year-old diagram|url=http://www.dailymail.co.uk/femail/article-3002112/Age-old-debate-toilet-paper-settled-patent-1891.html|website=Mailonline, dailymail.co.uk|publisher=Daily Mail|accessdate=2 May 2015|date=19 March 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web|author1=Jenny Che|title=This 124-Year-Old Patent Reveals The Right Way To Use Toilet Paper|url=http://www.huffingtonpost.com/2015/03/17/toilet-paper-actually-goes-over_n_6887724.html|website=HuffPost: Business|publisher=The Huffington Post|accessdate=2 May 2015|date=17–19 March 2015}}&lt;/ref&gt;]]

==Social consequences==
Toilet paper orientation is often mentioned as a hurdle for married couples.&lt;ref&gt;{{harvnb|Wolf|1999|pp=74–75}}; {{harvnb|Hogan|Hogan|2000|p=200}}.&lt;/ref&gt; The issue may also arise in businesses and public places.&lt;ref&gt;{{harvnb|Lui|2009}}; {{harvnb|Grant|1991a}}.&lt;/ref&gt;

Even at the [[Amundsen–Scott Research Station]] at the [[South Pole]], complaints have been raised over which way to install toilet paper. During the six-month-long [[polar night]], a few dozen residents are stuck living together, and while many of the headaches of modern life are far away, food and hygiene are not. Despite the challenges posed by the hostile [[Antarctic climate]], "It is in the more mundane trials of everyday life that personality clashes are revealed."{{sfn|Daily Express|1999|p=39}}

==Solutions==

Some of the proposed solutions to this problem involve more or better technology, while others concentrate on human behavior.

===Mechanical===
The Tilt-A-Roll is a swiveling toilet paper dispenser invented by Curtis Batts in 1996, a [[Dallas]]-native [[industrial engineer]].{{sfn|Floyd|1999}} His patents on the invention, summarize its design as "An adjustable angle coupling secures the yoke to the mounting assembly and permits rotation of the yoke about an axis directed orthogonally through the spindle such that the paper roll can be oriented to unroll paper either from over or from under the roll as desired."&lt;ref&gt;{{patent|US|5588615}} and {{patent|US|5690302}}&lt;/ref&gt; An inventor named Rocky Hutson demonstrated a similar device he called the T.P. Swivel to the producers of the television program ''[[PitchMen]]'' in late 2009. {{sfn|Zayas|2009}}

Another solution is to install two toilet paper dispensers, as is more common in public restrooms and hotels.&lt;ref&gt;{{harvnb|Walsh|1999}}; {{harvnb|Marelius|1987}}.&lt;/ref&gt; A reader of the ''[[Annie's Mailbox]]'' column recommends using a holder large enough to fit two rolls, noting that the roll mounted ''over'' is more popular. Another reader sidesteps the issue by foregoing the holder, instead piling five or six rolls in a big wicker basket.{{sfn|Mitchell|Sugar|2005b}} Even using separate bathrooms can help.&lt;ref&gt;{{harvnb|Arkins|1994}}; {{harvnb|Jarski|Jarski|2007}}.&lt;/ref&gt; Other solutions include vertical holders.

===Behavioral===
Toilet paper orientation has been used rhetorically as the ultimate issue that government has no business dictating, in letters to the editor protesting the regulation of [[noise pollution]]{{sfn|Ratzlaff|2009}} and stricter requirements to get a divorce.{{sfn|Wuthrich|2006}} In 2006, protesting [[New Hampshire]]'s [[List of smoking bans in the United States#New Hampshire|ban on smoking]] in restaurants and bars, representative Ralph Boehm ([[Republican Party (United States)|R]]&amp;ndash;[[Litchfield, New Hampshire|Litchfield]]) asked "Will we soon be told which direction the toilet paper must hang from the roll?"{{sfn|Saunders|2006}}

David O'Connor's 2005 book ''Henderson's House Rules: The Official Guide to Replacing the Toilet Paper and Other Domestic Topics of Great Dispute'' aims to solve disagreements with a minimum of debate or compromise by offering authoritative, reasonable rules.{{sfn|O'Connor|2005|pp=2–3}} The "House Rule" for toilet paper is ''over and out'', and a full page is dedicated to a diagram of this orientation. But O'Connor writes that "if a female household member has a strong preference for the toilet paper to hang over and in, against the wall, that preference prevails. It is admittedly an odd preference, but women use toilet paper far more often than men—hence the rule."&lt;ref&gt;{{harvnb|O'Connor|2005|pp=63–64}}; {{harvnb|Davis|2006}}.&lt;/ref&gt;

==Notes and references==

===Notes===
{{Reflist|colwidth=20em}}

===References===
{{Refbegin|30em}}
*{{Citation |author=Answer Fella |date=January 2007 |title=Famous Birthdays, Girlfriend Advice &amp; a Brief History of Toilet Paper |work=[[Esquire (magazine)|Esquire]] |volume=147 |issue=1 |page=52 |url=http://www.esquire.com/style/answer-fella/ESQ0107toiletpaper |accessdate=11 July 2010}}
*{{Citation |last=Arkins |first=Diane C. |title=Consider Fallout of New Bath |date=7 October 1994|work=[[Chicago Sun-Times]] |page=22N |id={{Factiva|chi0000020011028dqa700wzz}}}}
*{{Citation |title=W. C. Privy's Original Bathroom Companion, Number 2 |editor-first=Erin |editor-last=Barrett |editor2-first=Jack |editor2-last=Mingo |isbn=0-312-31580-5 |publisher=St. Martin's Press |date=December 2003}}
*{{Citation |last=Blow |first=Steve |title=This survey asks questions we care about |date=7 November 1990 |work=[[The Dallas Morning News]] |page=HOME FINAL 23A |id={{Factiva|dal0000020011207dmb702ey9}}}}
*{{Citation |last=Braun |first=Jenifer D. |title=Makeover host trades roles |date=28 August 2003 |work=[[The Star-Ledger]] |page=71 |id={{Factiva|NSL0000020030828dz8s0008a}}}}
*{{Citation |last=Breithaupt |first=Tim |title=10 Steps to Sales Success |year=2003 |isbn=0-8144-7165-X |publisher=AMACOM}}
*{{Citation |last=Brewer |first=Jack |title=Among Friends: There's always time to change |date=1 December 2002 |work=[[Houston Chronicle]] |page=Lifestyle 8 |id={{Factiva|hou0000020021203dyc10005u}}}}
*{{Citation |last=Buckley |first=James |year=2005 |title=The Bathroom Companion: A Collection of Facts About the Most-Used Room in the House |publisher=[[Quirk Books]] |isbn=1-59474-028-3}}
*{{Cite journal |last=Burns |first=Edgar Alan |date=January 2003 |jstor=3211429 |title=Bathroom Politics: Introducing Students to Sociological Thinking from the Bottom Up |journal=[[Teaching Sociology]] |volume=31 |issue=1 |pages=110–118 |doi=10.2307/3211429 |ref={{harvid|Burns|2003}}}}
*{{Citation |last=Cantor |first=Paul A. |title=Gilligan Unbound: Pop Culture in the Age of Globalization |publisher=Rowman &amp; Littlefield |year=2003 |isbn=0-7425-0779-3}}
*{{Citation |last=Cesvet |first=Bertrand |last2=Babinski |first2=Tony |last3=Alper |first3=Eric |title=Conversational Capital: How to Create Stuff People Love to Talk About |year=2008 |publisher=Pearson Education |isbn=0-13-714550-0}}
*{{Citation |last=Ciancio |first=Dan |title=New study flushes out facts on the American bathroom (press release) |date=1 February 1994 |work=[[PR Newswire]] |id={{Factiva|prn0000020011030dq210061e}}}}
*{{Citation |last=Ciancio |first=Dan |title=Potty Break |date=13 February 1995 |work=[[Rocky Mountain News]] |id={{Factiva|rmtn000020011026dr2d005jw}}}}
*{{Citation |last=Clark |first=Gary A. |title=Monday Memo |date=21 June 1993 |work=[[St. Louis Post-Dispatch]] |page=9 |id={{Factiva|SLMO000020040622dp6l00hkc}}}}
*{{Citation |last=Collett |first=Jessica |date=Spring 2008 |title=Class 4: Social Construction of Reality |work=Notre Dame OpenCourseWare |url=http://ocw.nd.edu/sociology/introduction-to-social-psychology/lectures/social-construction-of-reality |accessdate=12 July 2010}}
*{{Citation |last=Darbo |first=Paul |date=April 2007 |title=This Way In: The Sound and the Fury: ELSEWHERE IN THE BIN (letters to the editor) |work=Esquire |volume=147 |page=22}}
*{{Citation |last=Davis |first=Rich |title={{-'}}House Rules' Aims At Harmony |date=14 February 2006 |work=[[The Evansville Courier]] |page=D5 |id={{Factiva|EVVL000020060216e22e0004u}}}}
*{{Citation |last=Dickson |first=Gunna |title=New Products – Clean All Over |date=3 July 2001 |agency=[[Reuters News]] |id={{Factiva|lba0000020010912dx730069x}}}}
*{{Citation |last=Downey |first=Maureen |last2=Harrison |first2=Bette |title=Peach buzz talk of our town |date=27 June 1993 |work=[[Atlanta Journal and Constitution]] |id={{Factiva|atjc000020011031dp6r00w44}} |page=D/2}}
*{{Citation |last=Ebenkamp |first=Becky |title=Out of the Box |date=19 January 2004 |work=[[Brandweek]] |id={{Factiva|ADMW000020040202e01j0002m}}}}
*{{Citation |last1=Elger |first1=Dietmar |last2=Solaro |first2=Elizabeth M. |title=Gerhard Richter: A Life in Painting |publisher=University of Chicago Press |year=2010 |isbn=0-226-20323-9}}
*{{Citation |last=Elliott |first=Carson |title=The proper thing: Position plates so that meat is closest to diner, unless dishes display pictures |date=11 June 2006 |id={{Factiva|AGCR000020060809e26b00004}} |work=[[Augusta Chronicle]] |page=G02}}
*{{Citation |last=FitzSimons |first=Peter |authorlink=Peter FitzSimons |year=2009 |title=How Hemlines Predict the Economy: Explanations, Rationalizations, and Theories on Everything |publisher=[[Skyhorse Publishing]] |isbn=978-1-60239-311-0}}
*{{Citation |last=Flatow |first=Ira |title=Left handedness and Meteor Showers |date=8 August 1997 |work=[[Talk of the Nation]] |id={{Factiva|totn000020011008dt88000by}}}}
*{{Citation |last=Floyd |first=Jacquielynn |title=Inventor rolls out solution to toilet paper war |date=29 June 1999 |work=[[The Dallas Morning News]] |page=15A |id={{Factiva|dal0000020010829dv6t005qf}}}}
*{{Citation |last=Freiberg |first=Kevin |last2=Freiberg |first2=Jackie |year=1998 |title=Nuts!: Southwest Airlines' crazy recipe for business and personal success |edition=1st paperback |publisher=[[Broadway Books]] |isbn=0-7679-0184-3}}
*{{Citation |last=Galupo |first=Scott |title=Four troubadours trade tunes, tales |date=16 February 2005 |work=The Washington Times |page=B05 |id={{Factiva|WATI000020050216e12g0000t}}}}
*{{Citation |last=Garton |first=Nicole |title=Over or under? The great toilet paper debate continues |date=8 January 2005 |work=[[Tulsa World]] |page=D10 |id={{Factiva|TUL0000020050111e1180000y}}}}
*{{Citation |last=Gernsbacher |first=Morton Ann |authorlink=Morton Ann Gernsbacher |date=March 2007 |title=Presidential Column: Neural Diversity |journal=Observer |publisher=[[Association for Psychological Science]] |volume=20 |issue=3 |pages=5, 15 |url=http://www.psychologicalscience.org/index.php/publications/observer/2007/march-07/neural-diversity.html |accessdate=28 March 2013}}
*{{Citation |last=Godfrey |first=Linda S. |title=Weird Michigan: Your Travel Guide to Michigan's Local Legends and Best Kept Secrets |year=2006 |editor=Mark Sceurman and Mark Moran |publisher=Sterling |isbn=1-4027-3907-9}}
*{{Citation |last=Grant |first=Michael |date=16 July 1991 |title=Paper chase unravels at 30,000&amp;nbsp;feet |work=[[The San Diego Union-Tribune]] |page=C-1 |id={{Factiva|SDU0000020070627dn7g002uk}} |ref={{harvid|Grant|1991a}}}}
*{{Citation |last=Grant |first=Michael |date=1 September 1991 |title=Toilet paper theorist is on a roll, but issue is still under scrutiny |work=[[The San Diego Union-Tribune]] |page=D-1 |id={{Factiva|SDU0000020070627dn91007fo}} |ref={{harvid|Grant|1991b}}}}
*{{Citation |last=Greenberg |first=Steve |title=Gadget Nation: A Journey Through the Eccentric World of Invention |year=2007 |publisher=Sterling |isbn=978-1-4027-3686-5}}
*{{Citation |last=Grimes |first=David |title=When tissue is an issue |date=15 February 1999 |work=[[Sarasota Herald-Tribune]] |page=1E |id={{Factiva|ssta000020010829dv2f003ir}} |url=https://news.google.com/newspapers?id=owUiAAAAIBAJ&amp;sjid=4n0EAAAAIBAJ&amp;pg=6220%2C8365671 |deadurl=no |accessdate=11 October 2013}}
*{{Citation |last=Hage |first=Joe |year=2010 |title=Gerhard Richter » Art » Atlas » Atlas Sheet 15 » Associated Paintings » Toilet Paper » 75-3 |work=gerhard-richter.com |url=http://www.gerhard-richter.com/art/atlas/detail.php?number=15&amp;paintID=4995 |accessdate=12 July 2010}}
*{{Citation |last=Harden |first=Hike |title=Like these ideas? OK, then start your own column |date=30 July 1995 |work=[[The Columbus Dispatch]] |page=01I |id={{Factiva|clmb000020011024dr7u00d2h}}}}
*{{Citation |last=Harris |first=David |title=Letters to the Editor: One way or another, just let it roll |date=1 January 2010 |work=[[The Australian]] |page=19 |id={{Factiva|AUSTLN0020091231e6110002o}}}}
*{{Citation |last=Henry |first=Bonnie |title=The key role of toilet paper has columnist's eyes rolling |date=1 August 1999 |work=[[The Arizona Daily Star]] |page=3E |id={{Factiva|tucs000020010830dv81006wg}}}}
*{{Citation |last=Hogan |first=Eve Eschner |last2=Hogan |first2=Steve |title=Intellectual Foreplay: Questions for Lovers and Lovers-To-Be |publisher=Hunter House |year=2000}}
*{{Citation |last=Hunt |first=Don |last2=Edwards |first2=Brian |title=Toilet Seat Creates Flush Of Excitement |date=28 April 2000 |work=[[Chicago Tribune]] |url=http://articles.chicagotribune.com/2000-04-28/business/0004280253_1_toilet-seat-hinge-closing/2 |accessdate=3 July 2010}}
*{{Citation |last=Ichikawa |first=Anne |title=Celebrity Bathroom |page=64 |work=[[Elle Girl]] |date=June–July 2004}}
*{{Citation |last=Ichikawa |first=Anne |title=Celebrity Bathroom |page=106 |work=[[Elle Girl]] |date=March 2005}}
*{{Citation |last=Jarski |first=Rosemarie |last2=Jarski |first2=Milena |title=How to Do Everything! |page=143 |publisher=Globe Pequot |year=2007 |isbn=978-1-84537-415-0}}
*{{Citation |last=Kanner |first=Bernice |title=Are You Normal?: Do You Behave Like Everyone Else? |isbn=0-312-95592-8 |publisher=St. Martin's Paperbacks |date=15 September 1995}}
*{{Citation |last=Keeran |first=James |title=Professor Jaggi // Rocket Scientist |date=30 December 1993 |work=[[The Pantagraph]] |page=C1 |id={{Factiva|blm0000020011031dpcu00n58}}}}
*{{Citation |last=Keim |first=David |title=Science fair has 301 entries from 40 schools |date=7 April 1997 |page=A4 |work=[[The Knoxville News-Sentinel]] |id={{Factiva|kxvl000020011007dt47006av}}}}
*{{Citation |author=Kimberly-Clark |title=How Does America Roll? Cottonelle Brand Teams With Tori and Dean to End the Age-Old Debate: Over or Under? (press release) |date=27 January 2010 |work=[[PR Newswire]] |id=Factiva|url=http://investor.kimberly-clark.com/releasedetail.cfm?releaseid=440769}}
*{{Citation |last=Ladan |first=Mark |title=New exhibit from Guelph lifts the lid on toilet history |date=20 March 2001 |work=[[The Toronto Star]] |page=A04 |id={{Factiva|tor0000020010713dx6k00ldj}}}}
*{{Citation |last=LaForte |first=Babs |title=North Korea Shocker! |date=29 April 2003 |work=[[Weekly World News]] |page=20}}
*{{Citation |last=Landers |first=Ann |date=24 April 1992 |title=Which way do you hang the roll? A poll |work=[[The Dallas Morning News]] |page=2c |id={{Factiva|dal0000020011206do4o00fma}}}}
*{{Citation |last=Landers |first=Ann |date=8 February 1997 |title=Ann Landers |work=[[The Washington Post]] |page=B09 |id={{Factiva|wp00000020020504dt2800ipf}}}}
*{{Citation |last=Landers |first=Ann |date=7 January 1998 |title={{-'}}Illegitimate daughter' harassing you could be a dangerous weirdo |id={{Factiva|SLMO000020040607du17004nd}} |work=[[St. Louis Post-Dispatch]] |page=E2}}
*{{Citation |last=Landers |first=Ann |date=27 July 2002 |title=It's been an interesting 47&amp;nbsp;years |editor=Mary K. Nolan |page=A01 |work=[[The Hamilton Spectator]] |id={{Factiva|hmsp000020030501dy7r000xe}}}}
*{{Citation |last=Lawrence |first=Keith |work=[[Messenger-Inquirer]] |date=20 November 1999 |title=Here's another tidbit you can use to win an argument |id={{Factiva|krtbn00020010828dvbk0256f}}}}
*{{Citation |last=Lind |first=Angus |title=In a spin over tissue issue |date=17 July 1992|work=[[Times-Picayune]] |page=E1 |id={{Factiva|notp000020011107do7h00dum}}}}
*{{Citation |last=Lipman |title=Censored Scenes: Why You Rarely See Some Things in Television Ads |first=Joanne |work=[[The Wall Street Journal]] |date=17 August 1987|id={{Factiva|j000000020011118dj8h00kz8}}}}
*{{Citation |last=Loftin |title=Hiatt warms up crowd slowly |first=Josh |work=Deseret Morning News |date=22 June 2004 |page=C04 |id={{Factiva|DN00000020040622e06m0000w}}}}
*{{Citation |last=Lui |title=Hip night owl |first=John |date=13 April 2009 |work=[[Straits Times]] |id={{Factiva|STIMES0020090412e54d00022}}}}
*{{Citation |last=Luna |first=Aaron |date=29 August 2009 |title=Toilet Paper Debate Finally Solved: Paper from the top or bottom, now you can have it both ways. |work=nbc11news.com |publisher=[[KKCO]] |url=http://www.nbc11news.com/home/headlines/56129292.html |accessdate=23 August 2010}}
*{{Citation |editor-last=Magill |editor-first=Frank Northen |year=1993 |chapter=''All in the Family'' Introduces a New Style of Television Comedy |title=Great Events from History II: Arts and Culture Series |volume=5 |location=[[Pasadena, California]] |publisher=Salem Press |isbn=0-89356-812-0 |pages=2234–2238}}
*{{Citation |last=Marelius |title=Ann Landers' world has changed in 31&amp;nbsp;years |first=John |date=18 February 1987 |work=[[The San Diego Union-Tribune]] |page=D-3 |id={{Factiva|SDU0000020070707dj2i00mgk}}}}
*{{Citation |author=Mark Wolf Scripps Howard News Service |title=Little habits tell a lot about us all |date=1 January 1990|work=[[St. Louis Post-Dispatch]] |page=EVERYDAY MAGAZINE 1D |id={{Factiva|SLMO000020040626dm1101jgj}}}}
*{{Citation |last=Matsushita |title=Looking for Matt Wertz? Check in the butler's pantry |first=Elaine |date=12 October 2008|work=[[Chicago Tribune]] |id={{Factiva|KRTTB00020081012e4ac00046}}|url=http://www.chicagotribune.com/classified/realestate/chi-matt-wertz-snoop-1012oct12,0,3258691.story}}
*{{Citation |last=Matsushita |title=Daren Kagasoff reveals what's really in his closet (think Imelda Marcos) |first=Elaine |date=22 March 2009|work=[[Chicago Tribune]] |id={{Factiva|KRTTB00020090322e53m00037}}|url=http://articles.chicagotribune.com/2009-03-22/news/0903190695_1_shoe-thing-collection}}
*{{Citation |last=McCarthey |first=Tom |date=3 March 1996|title=Unraveling Toilet Trivia |page=Travel H1 |work=[[The Salt Lake Tribune]] |id={{Factiva|sltr000020011015ds33006we}}}}
*{{Citation |last=McNatt |title=Small ways to go GREEN |first=Cindy |date=25 April 2010|work=[[The Orange County Register]] |id={{Factiva|OCR0000020100503e64p0002t}} |quote=Planet Green says that if you hang your toilet paper roll so the paper comes out over the top, not from under, you'll save on toilet paper.}}
*{{Citation |last=Miller |title=Glowing with inspiration, perspiration |work=[[Pittsburgh Business Times]] |date=28 May 1999 |first=Michael |url=http://pittsburgh.bizjournals.com/pittsburgh/stories/1999/05/31/editorial2.html |accessdate=3 July 2010}}
*{{Citation |last1=Mitchell |last2=Sugar |date=19 April 2005a |title=Annie's Mailbox: Friend's abuse should be reported |first1=Kathy |first2=Marcy |work=[[Vernon Daily Record]] |page=6 |url=http://www.vernonrecord.com/April%2019.pdf |accessdate=3 July 2010 }}{{Dead link|date=July 2018 |bot=InternetArchiveBot |fix-attempted=no }}
*{{Citation |last1=Mitchell |last2=Sugar |date=13 September 2005b |title=Annie's Mailbox: Ask phone company to block prank calls |first1=Kathy |first2=Marcy |work=[[Montreal Gazette]] |page=E8 |id={{Factiva|MTLG000020050915e19d0000c}}}}
*{{Citation |author=Ms Maud |title=Toilet Training |date=23 November 2002|work=[[The Press]] |page=2 |id={{Factiva|thepre0020021125dybn000xi}}}}
*{{Citation |last1=Nalebuff |last2=Ayres |title=Why Not?: How to Use Everyday Ingenuity to Solve Problems Big And Small |first1=Barry |author1-link=Barry Nalebuff |first2=Ian |author2-link=Ian Ayres |publisher=Harvard Business Press |year=2006}}
*{{Citation |last=Nestruck |title=In loo of usual exhibits |first=J. Kelly |work=[[National Post]] |page=AL5 |date=1 February 2005|id={{Factiva|FINP000020050201e1210002l}}}}
*{{Citation |last=Newman |title=INVENTOR PROFILE: Curtis Batts, Inventor of the Tilt-A-Roll |first=Paul |url=http://www.marketlaunchers.com/october2000.html |accessdate=3 July 2010 |date=October 2000 |work=The Online Inventor |deadurl=yes |archiveurl=https://web.archive.org/web/20110209193915/http://www.marketlaunchers.com/october2000.html |archivedate=9 February 2011 |df=dmy-all }}
*{{Citation |last=O'Connor |first=David |title=Henderson's House Rules: The Official Guide to Replacing the Toilet Paper and Other Domestic Topics of Great Dispute |date=2 May 2005 |publisher=East Quincy Publishing |url=https://books.google.com/books?id=MVk1a1m6KcsC&amp;pg=PA63 |isbn=0-9764078-0-9}}
*{{Citation |last=Ode |title=psst... |first=Kim |date=16 March 2010|work=[[Star-Tribune]] |page=1E |id={{Factiva|MSP0000020100322e63g0006s}}}}
*{{Citation |last=Oldenburg |title=Little Did You Know ... |first=Don |work=[[The Washington Post]] |page=STYLE c05 |date=12 October 1989|id={{Factiva|wp00000020011117dlac01bs2}}}}
*{{Citation |last=Orr |title=We meet face to face, but see only a face |first=Karin |date=17 September 1995|work=[[The Grand Rapids Press]] |page=j1 |id={{Factiva|grpr000020011025dr9h00ajp}}}}
*{{Citation |last=Ortega |title=Caught in the act: America's bathroom detectives (press release) |first=Mary |date=26 January 1995|work=[[PR Newswire]] |id= {{Factiva|prn0000020011026dr1q005hj}}}}
*{{Citation |last=Paul |title="Flushing" Out Sociology: Using the Urinal Game and other Bathroom Customs to Teach the Sociological Perspective |first=John |journal=Electronic Journal of Sociology |year=2006 |url=http://www.sociology.org/content/2006/tier2/johnpaul_the_urinal_game.pdf |accessdate=11 July 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20100714162813/http://www.sociology.org/content/2006/tier2/johnpaul_the_urinal_game.pdf |archivedate=14 July 2010 |df=dmy-all }}
*{{Citation |last=Peterson |first=Christopher |title=A Primer in Positive Psychology |publisher=Oxford University Press |location=Oxford |year=2006}}
*{{Citation |last=Pierson |first=Amy |title=Dick Clark Helps Usher in a New Year of Softness (press release) |work=[[Market Wire]] |date=13 January 2004|id={{Factiva|ITWR000020040113e01d00001}}}}
*{{Citation |last1=Poretz |last2=Sinrod |title=The First Really Important Survey of American Habits |first1=Mel |first2=Barry |date=19 July 1989 |publisher=Price Stern Sloan |isbn=0-8431-2735-X}}
*{{Citation |last=Rademacher |title=Toilet tissue collector is a real roll player |first=Tom |date=11 April 2005 |agency=Associated Press Newswires |id={{Factiva|APRS000020050411e14b00c1j}}}}
*{{Citation |last=Ratzlaff |first=Brian |title=Is 'Nanny State' Neutering Us? |date=28 June 2009|work=[[The Modesto Bee]] |page=A11 |id={{Factiva|MBEE000020090630e56s0000b}}}}
*{{Citation |last=Rawson |title=Sage advice:Don't miss Ruoti playing Ann Landers |first=Christopher |date=24 November 2008 |work=Pittsburgh Post-Gazette |page=E-1 |id={{Factiva|PPGZ000020081124e4bo0001v}}}}
*{{Citation |last=Rosencrans |title=To fold or not to fold/ guest-bathroom tissue |first=Joyce |date=7 November 1998|work=[[The Cincinnati Post]] |page=1C |id={{Factiva|cinp000020010916dub700mw1}}}}
*{{Citation |last=Rubin |title=From socks to toilet paper roll, answers unfold in U.S. survey |first=Neal |date=28 September 1989|work=[[The Toronto Star]] |page=LIFE L2 |id={{Factiva|TOR0000020080325dl9s019zs}}}}
*{{Citation |last=Russell |title=Texas Monthly on... Texas Women |chapter=Can You Take a Hint? |first=Jan Jarboe |year=2006 |publisher=Emmis Publishing |isbn=0-292-71327-4 |page=84}}
*{{Citation |last=Saunders |title=Restaurant smoking ban passes in the House |first=Anne |date=21 March 2006|agency=Associated Press Newswires |id={{Factiva|APRS000020060321e23l002xm}}|url=http://www.fosters.com/apps/pbcs.dll/article?AID=/20060321/NEWS0201/103210143}}
*{{Citation |last=Scriven |first=Michael |authorlink=Michael Scriven |year=1991 |title=Evaluation Thesaurus |edition=4th |publisher=[[SAGE Publications]] |isbn=0-8039-4363-6}}
*{{Citation |last=Stark |first=Judy |title=They must be flushed |date=27 June 1993|work=[[St. Petersburg Times]] |page=AT HOME, 1 |id={{Factiva|stpt000020011101dp6r00yb8}}}}
*{{Citation |last=Stovall |title=Looks like a good idea on toilet paper: Roll-holder inventor, others vie for spots on shopping channel |first=Waltrina |work=[[The Dallas Morning News]] |date=1 August 1997 |id={{Factiva|dal0000020011006dt81013qz}}}}
*{{Citation |last=Tighe |first=Mike |title=Incorrect Twist-Ties Put Some In Knots |date=30 April 2008 |work=The Palm Beach Post |page=3 |id={{Factiva|PMBP000020080501e44u00013}}}}
*{{Citation |author=Toronto Star staff and news services |title=Over beats under in toilet paper poll |work=[[Toronto Star]] |date=15 June 1993|page=LIFE, B1 |id={{Factiva|TOR0000020080312dp6f00bo2}}}}
*{{Citation |last=Walsh |first=Michael |date=8 August 1999 |work=[[Patriot-News]] |title=What's new: Four recent additions to product list for homes promising |page=H01 |id={{Factiva|pathar0020010827dv8800j36}}}}
*{{Citation |last=Weingarten |title=Chatological Humor |first=Gene |date=4 November 2008|work=Washington Post.com |id={{Factiva|WPCOM00020081105e4b40000a}}}}
*{{Citation |last=Welsh |title=`Lady' a better read in newsprint |first=Anne Marie |date=13 August 2005 |work=[[The San Diego Union-Tribune]] |page=E-1 |id={{Factiva|SDU0000020050815e18d00031}} |url=http://legacy.signonsandiego.com/uniontrib/20050813/news_1c13lady.html |accessdate=12 July 2010}}
*{{Citation |last=Widdicombe |title=Butler Servers Up More Dish On Diana |first=Ben |date=8 June 2004 |work=[[New York Daily News]] |page=38 |id={{Factiva|NYDN000020040608e0680005m}}}}
*{{Citation |last=Wizda |title=Personalities |first=Sharyn |date=19 March 1990|work=[[The Washington Post]] |page=c03 |id={{Factiva|wp00000020011116dm3j00bd9}}}}
*{{Citation |last=Wolf |title=So You Want to Get Married: Guerrilla Tactics for Turning a Date Into a Mate |first=Sharyn |publisher=Plume |year=1999}}
*{{Citation |last=Wuthrich |first=John F. |title=Who elected these freaks? |date=26 January 2006|page=A10 |work=[[The Salt Lake Tribune]] |id={{Factiva|SLTR000020060127e21q0001a}}}}
*{{Citation |last=Wyman |title=Three Keys to Self-Understanding: An Innovative and Effective Combination of the Myers-Briggs Type Indicator, the Enneagram, and Inner-Child Healing |first=Pat |publisher=Center for Applications of Psychological Type |year=2001 |isbn=0-935652-57-4}}
*{{Citation |last=Yeld |first=John |title=SMS feedback – March 31, 2010 |date=31 March 2010 |work=Cape Argus |url=http://www.capeargus.co.za/index.php?fArticleId=5412902 |id={{Factiva|MEWCAP0020100401e63v00011}} |quote=A British loo paper manufacturer investigated whether it was more economical to run loo paper over the top or draw it from below. From below was the verdict.}}
*{{Citation |last=Zayas |title=Inventors gather in Ybor City to pitch for ''Pitchmen'' |first=Alexandra |date=5 November 2009 |work=[[St. Petersburg Times]] |url=http://www.tampabay.com/news/humaninterest/inventors-gather-in-ybor-city-to-pitch-for-ipitchmeni/1049380 |deadurl=yes |accessdate=11 October 2013 |archiveurl=https://web.archive.org/web/20091209024743/http://www.tampabay.com/news/humaninterest/inventors-gather-in-ybor-city-to-pitch-for-ipitchmeni/1049380 |archivedate=9 December 2009 |df=dmy-all }}
*{{Citation |ref={{SfnRef|American Standard Press|2008}} |title=American Standard Bathroom Habits Survey Shows We’re Multitasking, Even In the Bath (press release) |work=American Standard Press |date=20 August 2008|url=http://www.americanstandard-us.com/pressroom/american-standard-bathroom-habits-survey-shows-we-are-multitasking-even-in-the-bath/ |deadurl=no |accessdate=11 October 2013}}
*{{Citation |ref={{SfnRef|Brandweek|2009}} |title=The Self-styled Publisher |date=4 May 2009|work=[[Brandweek]] |id={{Factiva|ADMW000020090604e5540002j}}}}
*{{Citation |ref={{SfnRef|Centralian Advocate|2002}} |title=Dingo – Fisherman's tale |date=7 May 2002|work=[[Centralian Advocate]] |page=6 |id={{Factiva|cadvoc0020021123dy57002nt}} |quote=A particularly fascinating response came from a reader who found a university in the US conducted a study into the most economical toilet paper use. The six month study found that when the toilet paper came over the front of the roll less was used than if the paper was pulled from the back.}}
*{{Citation |ref={{SfnRef|The Courier-Mail|2000}} |title=Manners Column |date=1 November 2000|page=18 |work=[[The Courier-Mail]] |id={{Factiva|coumai0020010805dwb10037p}}}}
*{{Citation |ref={{SfnRef|The Daily Examiner|2009}} |title=Wines from the Fourth Estate |date=23 May 2009 |work=[[The Daily Examiner]] |page=26 |id={{Factiva|APNDEG0020090522e55n000b7}}}}
*{{Citation |ref={{SfnRef|Daily Express|1999}} |title=At long last, I can escape from my Polar prison |date=14 October 1999 |work=[[Daily Express]] |pages=38–39 |id={{Factiva|theexp0020010826dvae0066w}}}}
*{{Citation |ref={{SfnRef|Dayton Daily News|1996}} |title=StartUP: The Last Word: No detail missed by Southwest exec |date=19 June 1996|work=[[Dayton Daily News]] |page=1A |id={{Factiva|ddnw000020011017ds6j000tc}}}}
*{{Citation |ref={{SfnRef|Fund Action|2009}} |title=Pandora's Portfolio |date=2 March 2009|work=Fund Action |publisher=[[Euromoney Institutional Investor]] |id={{Factiva|FUNDAC0020090316e52r00007}}}}
*{{Citation |ref={{SfnRef|The Oprah Winfrey Show|1996}} |title=Interview: Ann Landers; Ann Landers discusses her life, her column and her new book, 'Wake Up and Smell the Coffee!' |date=6 June 1996 |work=[[The Oprah Winfrey Show]] |id={{Factiva|OPRH000020070817ds66000bj}}}}
*{{Citation |ref={{SfnRef|PR Newswire|1993}} |title=Quilted Northern survey answers age-old question (press release) |date=21 May 1993|work=[[PR Newswire]]}}
*{{Citation |ref={{SfnRef|PR Newswire|2010}} |title=America Sides With Tori Spelling, Rolls Over |author=Kimberly-Clark |work=[[PR Newswire]] |date=8 March 2010 |id={{Factiva|PRN0000020100308e638001jl}}|url=http://www.prnewswire.com/news-releases/america-sides-with-tori-spelling-rolls-over-86810867.html}}
*{{Citation |ref={{SfnRef|Progressive Grocer|2010}} |title=Cottonelle on a Roll With Consumers |date=31 January 2010|work=[[Progressive Grocer]] |id={{Factiva|PRGR000020100202e61v0000s}}}}
*{{Citation |ref={{SfnRef|Toronto Star|1986}} |title=Hang toilet paper over top of roll, Ann Landers says |date=19 November 1986 |work=[[The Toronto Star]] |page=A4 |id={{Factiva|TOR0000020080607dibj01g0q}}}}
*{{Citation |ref={{SfnRef|Voice of America|2004}} |title=TTA/Talk Radio |work=[[Voice of America]] Press Releases and Documents |date=2 March 2004|id={{Factiva|VOA0000020040303e0320001j}}}}
{{Refend}}

===Further reading===
{{Refbegin|30em}}
*{{Citation |title=For Your Information |work=[[The News &amp; Observer]] |date=4 October 1993|page=C1 |id={{Factiva|rnob000020011101dpa400p2p}}}}
*:References "a Reader's Digest poll". Primary source unclear.
*{{Citation |last=Brody |title=Spinning Tales, Weaving Hope: Stories, Storytelling, and Activities for Peace, Justice and the Environment |page=158 |first=Ed |year=2002 |publisher=New Society Publishers}}
*{{Citation |last=Cameron |title=How to Remodel a Man: Tips and Techniques on Accomplishing Something You Know Is Impossible But Want to Try Anyway |authorlink=W. Bruce Cameron |first=W. Bruce |publisher=Macmillan |year=2004 |page=185}}
*{{Citation |last=Carpenter |title=It's swimming vs. snoozing |first=Richard P. |date=28 March 1999|work=[[The Boston Globe]] |page=M4 |id={{Factiva|bstngb0020010825dv3s00asy}}}}
*{{Citation |last=Freeman |title=Vox Jox |first=Kim |work=Billboard |date=8 February 1986 |page=16}}
*:References a poll by Ric Hanson featured in USA Today.
*{{Citation |last=Grossvogel |title=Dear Ann Landers: our intimate and changing dialogue with America's best-loved confidante |first=David I. |page=257 |publisher=Contemporary Books |year=1987}}
*{{Citation |last=Kelly |title=Models in process: a rhetoric and reader |page=154 |first=William Jude |publisher=Macmillan |year=1988}}
*{{Citation |last=Kogan |title=America's Mom: The Life, Lessons, and Legacy of Ann Landers |first=Rick |publisher=Thorndike Press |year=2004 |page=224}}
*{{Citation |last=Praeger |title=Poop Culture: How America Is Shaped by Its Grossest National Product |first=Dave |publisher=Feral House |year=2007 |page=72}}
*{{Citation |last=Selby |title=Earthkind: a teachers' handbook on humane education |first=David |page=367 |publisher=Trentham Books |year=1995}}
*{{Citation |last=Singular |title=Talked to death: the life and murder of Alan Berg |first=Stephen |year=1987 |page=305}}
*:Mentions Bob Palmer of Denver's KCNC-TV doing a show on this topic.
*{{Citation |title=Reliability and robust design in automotive engineering |author=Society of Automotive Engineers |year=2004 |page=412}}
*:Presents a statistical test to determine gender differences in toilet paper orientation.
*{{Citation |last=Trachtenberg |title=When I Knew |first=Robert |page=69 |publisher=HarperCollins |year=2005}}
{{Refend}}

{{Toilets}}

{{DEFAULTSORT:Toilet Paper Orientation}}
[[Category:Toilet paper]]
[[Category:Orientation (geometry)]]
[[Category:Symmetry]]
[[Category:Interpersonal conflict]]
[[Category:Surveys]]</text>
      <sha1>g3hqjktm3fj0i5ueli3v2iw9gxucrff</sha1>
    </revision>
  </page>
  <page>
    <title>Transitive reduction</title>
    <ns>0</ns>
    <id>3757117</id>
    <revision>
      <id>853162929</id>
      <parentid>826543759</parentid>
      <timestamp>2018-08-02T20:58:21Z</timestamp>
      <contributor>
        <username>Gymel</username>
        <id>12120335</id>
      </contributor>
      <minor/>
      <comment>confined IW link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11245">In [[mathematics]], a '''transitive reduction''' of a [[directed graph]] ''D'' is another directed graph with the same vertices and as few edges as possible, such that if there is a (directed) path from vertex ''v'' to vertex ''w'' in ''D'', then there is also such a path in the reduction.  Transitive reductions were introduced by {{harvtxt|Aho|Garey|Ullman|1972}}, who provided tight bounds on the computational complexity of constructing them.

More technically, the reduction is a directed graph that has the same [[reachability]] relation as ''D''. Equivalently, ''D'' and its transitive reduction should have the same [[transitive closure]] as each other, and its transitive reduction should have as few edges as possible among all graphs with this property. 

The transitive reduction of a finite [[directed acyclic graph]] (a directed graph without directed cycles) is unique and is a [[Induced subgraph|subgraph]] of the given graph. However, uniqueness fails for graphs with (directed) cycles, and for infinite graphs not even existence is guaranteed. 

The closely related concept of a '''minimum equivalent graph''' is a subgraph of ''D'' that has the same reachability relation and as few edges as possible.{{sfnp|Moyles|Thompson|1969}}  The difference is that a transitive reduction does not have to be a subgraph of ''D''.  For finite directed acyclic graphs, the minimum equivalent graph is the same as the transitive reduction.  However, for graphs that may contain cycles, minimum equivalent graphs are [[NP-hard]] to construct, while transitive reductions can be constructed in [[polynomial time]].  

Transitive reduction can be defined for an abstract [[binary relation]] on a [[set (mathematics)|set]], by interpreting the pairs of the relation as arcs in a directed graph.

==In acyclic directed graphs==
The transitive reduction of a finite [[directed graph]] ''G'' is a graph with the fewest possible edges that has the same [[reachability]] relation as the original graph. That is, if there is a path from a vertex ''x'' to a vertex ''y'' in graph ''G'', there must also be a path from ''x'' to ''y'' in the transitive reduction of ''G'', and vice versa.  The following image displays drawings of graphs corresponding to a non-transitive binary relation (on the left) and its transitive reduction (on the right).

&lt;div class="center"&gt;
{|
| [[Image:tred-G.svg|124px]]
| [[Image:tred-Gprime.svg|80px]]
|}
&lt;/div&gt;

The transitive reduction of a finite [[directed acyclic graph]] ''G'' is unique, and consists of the edges of ''G'' that form the only path between their endpoints. In particular, it is always a [[Induced subgraph|subgraph]] of the given graph. For this reason, the transitive reduction coincides with the minimum equivalent graph in this case.

In the mathematical theory of [[binary relation]]s, any relation ''R'' on a set ''X'' may be thought of as a [[directed graph]] that has the set ''X'' as its vertex set and that has an arc ''xy'' for every [[ordered pair]] of elements that are related in ''R''. In particular, this method lets [[partially ordered set]]s be reinterpreted as directed acyclic graphs, in which there is an arc ''xy'' in the graph whenever there is an order relation ''x''&amp;nbsp;&amp;lt;&amp;nbsp;''y'' between the given pair of elements of the partial order. When the transitive reduction operation is applied to a directed acyclic graph that has been constructed in this way, it generates the [[covering relation]] of the partial order, which is frequently given visual expression by means of a [[Hasse diagram]].

Transitive reduction has been used on networks which can be represented as directed acyclic graphs (e.g. [[citation graph]]s or [[citation graph|citation networks]]) to reveal structural differences between networks.{{sfnp|Clough|Gollings|Loach|Evans|2014}}

==In graphs with cycles==
In a finite graph that may have cycles, the transitive reduction is not unique: there may be more than one graph on the same vertex set that has a minimum number of edges and has the same reachability relation as the given graph. Additionally, it may be the case that none of these minimum graphs is a subgraph of the given graph. Nevertheless, it is straightforward to characterize the minimum graphs with the same reachability relation as the given graph ''G''.&lt;ref name="agu72"&gt;{{harvtxt|Aho|Garey|Ullman|1972}}&lt;/ref&gt; If ''G'' is an arbitrary directed graph, and ''H'' is a graph with the minimum possible number of edges having the same reachability relation as ''G'', then ''H'' consists of
*A [[directed cycle]] for each [[strongly connected component]] of ''G'', connecting together the vertices in this component
*An edge ''xy'' for each edge ''XY'' of the transitive reduction of the [[strongly connected component|condensation]] of ''G'', where ''X'' and ''Y'' are two strongly connected components of ''G'' that are connected by an edge in the condensation, ''x'' is any vertex in component ''X'', and ''y'' is any vertex in component ''Y''. The condensation of ''G'' is a directed acyclic graph that has a vertex for every strongly connected component of ''G'' and an edge for every two components that are connected by an edge in ''G''. In particular, because it is acyclic, its transitive reduction can be defined as in the previous section.
The total number of edges in this type of transitive reduction is then equal to the number of edges in the transitive reduction of the condensation, plus the number of vertices in nontrivial strongly connected components (components with more than one vertex).

The edges of the transitive reduction that correspond to condensation edges can always be chosen to be a subgraph of the given graph ''G''. However, the cycle within each strongly connected component can only be chosen to be a subgraph of ''G'' if that component has a [[Hamiltonian cycle]], something that is not always true and is difficult to check. Because of this difficulty, it is [[NP-hard]] to find the smallest subgraph of a given graph ''G'' with the same reachability (its minimum equivalent graph).&lt;ref name="agu72"/&gt;

==Computational complexity==
As Aho et al. show,&lt;ref name="agu72"/&gt; when the [[time complexity]] of graph algorithms is measured only as a function of the number ''n'' of vertices in the graph, and not as a function of the number of edges, transitive closure and transitive reduction of directed acyclic graphs have the same complexity. It had already been shown that transitive closure and [[matrix multiplication|multiplication]] of [[Logical matrix|Boolean matrices]] of size ''n''&amp;nbsp;&amp;times;&amp;nbsp;''n'' had the same complexity as each other,&lt;ref&gt;Aho et al. credit this result to an unpublished 1971 manuscript of Ian Munro, and to a 1970 Russian-language paper by M. E. Furman.&lt;/ref&gt; so this result put transitive reduction into the same class.  The fastest known exact algorithms for matrix multiplication, as of 2015, take time O(''n''&lt;sup&gt;2.3729&lt;/sup&gt;),{{sfnp|Le Gall|2014}} and this gives the fastest known worst-case time bound for transitive reduction in dense graphs.

===Computing the reduction using the closure===
To prove that transitive reduction is as easy as transitive closure, Aho et al. rely on the already-known equivalence with Boolean matrix multiplication. They let ''A'' be the [[adjacency matrix]] of the given directed acyclic graph, and ''B'' be the adjacency matrix of its transitive closure (computed using any standard transitive closure algorithm). Then an edge ''uv'' belongs to the transitive reduction if and only if there is a nonzero entry in row ''u'' and column ''v'' of matrix ''A'', and there is a zero entry in the same position of the matrix product ''AB''. In this construction, the nonzero elements of the matrix ''AB'' represent pairs of vertices connected by paths of length two or more.&lt;ref name="agu72"/&gt;

===Computing the closure using the reduction===
To prove that transitive reduction is as hard as transitive closure, Aho et al. construct from a given directed acyclic graph ''G'' another graph ''H'', in which each vertex of ''G'' is replaced by a path of three vertices, and each edge of ''G'' corresponds to an edge in ''H'' connecting the corresponding middle vertices of these paths. In addition, in the graph ''H'', Aho et al. add an edge from every path start to every path end. In the transitive reduction of ''H'', there is an edge from the path start for ''u'' to the path end for ''v'', if and only if edge ''uv'' does not belong to the transitive closure of ''G''. Therefore, if the transitive reduction of ''H'' can be computed efficiently, the transitive closure of ''G'' can be read off directly from it.&lt;ref name="agu72"/&gt;

===Computing the reduction in sparse graphs===
When measured both in terms of the number ''n'' of vertices and the number ''m'' of edges in a directed acyclic graph, transitive reductions can also be found in time O(''nm''), a bound that may be faster than the matrix multiplication methods for [[sparse graph]]s. To do so, collect edges (''u'',''v'') such that the [[longest path problem|longest-path distance]] from ''u'' to ''v'' is one, calculating those distances by [[linear time|linear-time]] search from each possible starting vertex, ''u''.  This O(''nm'') time bound matches the complexity of constructing transitive closures by using [[depth first search]] or [[breadth first search]] to find the vertices reachable from every choice of starting vertex, so again with these assumptions transitive closures and transitive reductions can be found in the same amount of time.

==Notes==
{{reflist}}

==References==
*{{citation
 | last1 = Aho | first1 = A. V. | author1-link = Alfred Aho
 | last2 = Garey | first2 = M. R. | author2-link = Michael Garey
 | last3 = Ullman | first3 = J. D. | author3-link = Jeffrey Ullman
 | doi = 10.1137/0201008
 | issue = 2
 | journal = [[SIAM Journal on Computing]]
 | mr = 0306032
 | pages = 131–137
 | title = The transitive reduction of a directed graph
 | volume = 1
 | year = 1972}}.
*{{citation
 | last1 = Clough | first1 = J. R.
 | last2 = Gollings | first2 = J.
 | last3 = Loach | first3 = T. V.
 | last4 = Evans | first4 = T. S.
 | arxiv = 1310.8224
 | doi = 10.1093/comnet/cnu039
 | issue = 2
 | journal = Journal of Complex Networks
 | pages = 189–203
 | title = Transitive reduction of citation networks
 | volume = 3
 | year = 2015}}.
*{{citation
 | last1 = Moyles | first1 = Dennis M.
 | last2 = Thompson | first2 = Gerald L.
 | doi = 10.1145/321526.321534
 | issue = 3
 | journal = [[Journal of the ACM]]
 | pages = 455–460
 | title = An Algorithm for Finding a Minimum Equivalent Graph of a Digraph
 | volume = 16
 | year = 1969}}.
*{{citation
 | last = Le Gall | first = François
 | contribution = Powers of Tensors and Fast Matrix Multiplication
 | doi = 10.1145/2608628.2608664
 | pages = 296–303
 | title = Proc. 39th International Symposium on Symbolic and Algebraic Computation (ISSAC '14)
 | year = 2014}}.

==External links==
* {{mathworld|id=TransitiveReduction|title=Transitive Reduction}}

{{DEFAULTSORT:Transitive Reduction}}
[[Category:Set theory]]
[[Category:Graph theory]]
[[Category:Graph algorithms]]

[[de:Transitive_Hülle_(Relation)#Transitive_Reduktion]]</text>
      <sha1>9k7rkivsdiuhda7t9bmmp8jekuln1ua</sha1>
    </revision>
  </page>
  <page>
    <title>Valery Alexeev (mathematician)</title>
    <ns>0</ns>
    <id>53880784</id>
    <revision>
      <id>780743250</id>
      <parentid>777198849</parentid>
      <timestamp>2017-05-16T22:39:21Z</timestamp>
      <contributor>
        <username>Bamyers99</username>
        <id>12311825</id>
      </contributor>
      <comment>+[[Category:Year of birth missing (living people)]]; +[[Category:Living people]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="744">'''Valery Alexeev''' is an American mathematician currently the David C. Barrow Professor at [[University of Georgia]] and an Elected Fellow of the [[American Mathematical Society]].&lt;ref&gt;{{Cite web |url=http://www.ams.org/profession/fellows-list |title=Fellows |publisher=ams.org |accessdate=April 25, 2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.math.uga.edu/directory/valery-alexeev |title=Valery Alexeev |publisher=uga.edu |accessdate=April 25, 2017}}&lt;/ref&gt;

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Alexeev, Valery}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:American mathematicians]]


{{US-mathematician-stub}}</text>
      <sha1>ekjd1fupde1fjmgjp7kff7iklpmyxtp</sha1>
    </revision>
  </page>
  <page>
    <title>Van der Corput lemma (harmonic analysis)</title>
    <ns>0</ns>
    <id>24993240</id>
    <revision>
      <id>790778374</id>
      <parentid>789016688</parentid>
      <timestamp>2017-07-16T00:43:16Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; (13) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1925">In [[mathematics]], in the field of [[harmonic analysis]],
the '''van der Corput lemma''' is an estimate for [[oscillatory integral]]s
named after the [[Netherlands|Dutch]] mathematician [[Johannes van der Corput|J. G. van der Corput]].

The following result
is stated by [[Elias M. Stein|E. Stein]]:&lt;ref&gt;Elias Stein, ''Harmonic Analysis: Real-variable Methods, Orthogonality and Oscillatory Integrals''. Princeton University Press, 1993. {{ISBN|0-691-03216-5}}&lt;/ref&gt;

Suppose that a real-valued function &lt;math&gt;\phi(x)&lt;/math&gt; is smooth in an open interval &lt;math&gt;(a,b)&lt;/math&gt;,
and that &lt;math&gt;|\phi^{(k)}(x)|\ge 1&lt;/math&gt; for all &lt;math&gt;x\in (a,b)&lt;/math&gt;.
Assume that either &lt;math&gt;k\ge 2&lt;/math&gt;, or that
&lt;math&gt;k=1&lt;/math&gt; and &lt;math&gt;\phi'(x)&lt;/math&gt; is monotone for &lt;math&gt;x\in\R&lt;/math&gt;.
There is a constant &lt;math&gt;c_k&lt;/math&gt;, which does not depend on &lt;math&gt;\phi&lt;/math&gt;,
such that
:&lt;math&gt;
\Big|\int_a^b e^{i\lambda\phi(x)}\Big|\le c_k\lambda^{-1/k},
&lt;/math&gt;

for any &lt;math&gt;\lambda\in\R&lt;/math&gt;.

==Sublevel set estimates==

The van der Corput lemma is closely related to the [[sublevel set]] estimates
(see for example
&lt;ref&gt;M. Christ, ''Hilbert transforms along curves'', Ann. of Math. '''122''' (1985), 575--596&lt;/ref&gt;),
which give the upper bound on the [[Measure (mathematics)|measure]] of the set
where a function takes values not larger than &lt;math&gt;\epsilon&lt;/math&gt;.

Suppose that a real-valued function &lt;math&gt;\phi(x)&lt;/math&gt; is smooth
on a finite or infinite interval &lt;math&gt;I\subset\R&lt;/math&gt;,
and that &lt;math&gt;|\phi^{(k)}(x)|\ge 1&lt;/math&gt; for all &lt;math&gt;x\in I&lt;/math&gt;.
There is a constant &lt;math&gt;c_k&lt;/math&gt;, which does not depend on &lt;math&gt;\phi&lt;/math&gt;,
such that
for any &lt;math&gt;\epsilon\ge 0&lt;/math&gt;
the measure of the sublevel set
&lt;math&gt;\{x\in I:|\phi(x)|\le\epsilon\}&lt;/math&gt;
is bounded by &lt;math&gt;c_k\epsilon^{1/k}&lt;/math&gt;.

==References==
&lt;references /&gt;

[[Category:Inequalities]]
[[Category:Harmonic analysis]]
[[Category:Fourier analysis]]</text>
      <sha1>r1nhgu0ts72voni1eao76azgvjhe9gw</sha1>
    </revision>
  </page>
  <page>
    <title>Vector area</title>
    <ns>0</ns>
    <id>3103326</id>
    <revision>
      <id>858514181</id>
      <parentid>752387117</parentid>
      <timestamp>2018-09-07T18:40:21Z</timestamp>
      <contributor>
        <ip>94.185.61.122</ip>
      </contributor>
      <comment>/* Projection of area onto planes */Grammer</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2602">In 3-dimensional geometry, for a finite planar surface of scalar area {{mvar|S}} and [[unit normal]] {{math|'''n̂'''}}, the vector area {{math|'''S'''}} is defined as the unit normal scaled by the area:

:&lt;math&gt;\mathbf{S} = \mathbf{\hat n}S&lt;/math&gt;

For an [[orientable]] surface {{mvar|S}} composed of a set {{mvar|S&lt;sub&gt;i&lt;/sub&gt;}} of flat [[Facet_(geometry)|facet]] areas, the vector area of the surface is given by

:&lt;math&gt;\mathbf{S} = \sum_i \mathbf{\hat n}_i S_i&lt;/math&gt;

where {{math|'''n̂'''&lt;sub&gt;''i''&lt;/sub&gt;}} is the unit normal vector to the area {{mvar|S&lt;sub&gt;i&lt;/sub&gt;}}.

For bounded, oriented curved surfaces that are sufficiently [[well-behaved]], we can still define vector area. First, we split the surface into infinitesimal elements, each of which is effectively flat.  For each infinitesimal element of area, we have an area vector, also infinitesimal.

:&lt;math&gt;d\mathbf{S} = \mathbf{\hat n}dS&lt;/math&gt;

where {{math|'''n̂'''}} is the local unit vector perpendicular to {{mvar|dS}}.  Integrating gives the vector area for the surface.

:&lt;math&gt;\mathbf{S} = \int d\mathbf{S}&lt;/math&gt;

For a curved or faceted surface, the vector area is smaller in magnitude than the area.  As an extreme example, a closed surface can possess arbitrarily large area, but its vector area is necessarily zero.&lt;ref&gt;{{cite book|first=Murray R.|last=Spiegel|title=Theory and problems of vector analysis|series=Schaum's Outline Series|publisher=McGraw Hill|date=1959|page=25}}&lt;/ref&gt;  Surfaces that share a boundary may have very different areas, but they must have the same vector area—the vector area is entirely determined by the boundary.  These are consequences of [[Stokes' theorem]].

The concept of an area vector simplifies the equation for determining the [[flux]] through the surface. Consider a planar surface in a uniform [[Field (physics)|field]]. The flux can be written as the [[dot product]] of the field and area vector. This is much simpler than multiplying the field strength by the surface area and the cosine of the angle between the field and the surface normal.

== Projection of area onto planes ==
The projected area onto (for example) the {{mvar|xy}}-plane is equivalent to the {{mvar|z}}-component of the vector area, and is given as

:&lt;math&gt;\mathbf{S}_z = \left| \mathbf{S} \right| \cos \theta&lt;/math&gt;

where {{mvar|θ}} is the angle between the plane normal and the {{mvar|z}}-axis.

== See also ==
* [[Cross product]]
* [[Surface normal]]
* [[Surface integral]]

== Notes ==
&lt;references /&gt;

[[Category:Area]]
[[Category:Vectors (mathematics and physics)]]
[[Category:Analytic geometry]]</text>
      <sha1>64odtw09t01c1mtadrliqwn0huy239n</sha1>
    </revision>
  </page>
</mediawiki>
