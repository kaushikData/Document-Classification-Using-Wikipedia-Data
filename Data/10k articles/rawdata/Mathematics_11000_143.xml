<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>42 (number)</title>
    <ns>0</ns>
    <id>191178</id>
    <revision>
      <id>870765694</id>
      <parentid>870765347</parentid>
      <timestamp>2018-11-26T21:39:32Z</timestamp>
      <contributor>
        <username>KNHaw</username>
        <id>412108</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/89.73.214.158|89.73.214.158]] ([[User talk:89.73.214.158|talk]]) to last revision by Arthur Rubin. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31789">{{Refimprove|date=February 2011}}

{{Infobox number
| number = 42
| divisor = 1, 2, 3, 6, 7, 14, 21, 42
| unicode = *
| greek prefix = μβ
| latin prefix =
}}

'''42''' ('''forty-two''') is the [[natural number]] that succeeds [[41 (number)|41]] and precedes [[43 (number)|43]].

==Mathematics==
Forty-two (42) is a [[pronic number]]&lt;ref&gt;{{Cite OEIS|1=A002378|2=Oblong (or promic, pronic, or heteromecic) numbers|accessdate=2016-05-30}}&lt;/ref&gt; and an [[abundant number]]; its [[prime factorization]] 2&amp;nbsp;·&amp;nbsp;3&amp;nbsp;·&amp;nbsp;7 makes it the second [[sphenic number]] and also the second of the form (2&amp;nbsp;·&amp;nbsp;3&amp;nbsp;·&amp;nbsp;''r'').

Additional properties of the number 42 include:

* It is the number of [[Isomorphism class|isomorphism classes]] of all simple and oriented [[Directed graph|directed graphs]] on 4 vertices. In other words, it is the number of all possible outcomes (up to isomorphism) of a tournament consisting of 4 teams where the game between any pair of teams results in three possible outcomes: the first team wins, the second team wins, or there is a draw. The group stage of the FIFA World cup is a good example.
* It is the third [[primary pseudoperfect number]].&lt;ref&gt;{{Cite OEIS|1=A054377|2=Primary pseudoperfect numbers|accessdate=2016-05-30}}&lt;/ref&gt;
* It is a [[Catalan number]].&lt;ref&gt;{{Cite OEIS|1=A000108|2=Catalan numbers|accessdate=2016-05-30}}&lt;/ref&gt; Consequently, 42 is the number of [[noncrossing partition]]s of a set of five elements, the number of triangulations of a [[heptagon]], the number of rooted ordered binary [[Tree (graph theory)|trees]] with six leaves, the number of ways in which five pairs of nested parentheses can be arranged, etc.
* It is an [[alternating sign matrix]] number, that is, the number of 4-by-4 alternating sign matrices.
* It is the number of [[Integer partition|partitions]] of 10—the number of ways of expressing 10 as a sum of positive integers (note a different sense of partition from that above).
[[File:Simple Magic Cube.svg|thumb|right|The 3&amp;nbsp;×&amp;nbsp;3&amp;nbsp;×&amp;nbsp;3 [[magic cube]] with rows summing to 42.]]
* Given 27 same-size cubes whose nominal values progress from 1 to 27, a 3&amp;nbsp;×&amp;nbsp;3&amp;nbsp;×&amp;nbsp;3 [[magic cube]] can be constructed such that every row, column, and corridor, and every diagonal passing through the center, is composed of 3 numbers whose sum of values is 42.
* It is the third [[polygonal number|pentadecagonal number]].&lt;ref&gt;{{Cite OEIS|1=A051867|2=15-gonal (or pentadecagonal) numbers|accessdate=2016-05-30}}&lt;/ref&gt; It is a [[meander (mathematics)|meandric number]] and an [[meander (mathematics)#Open meandric numbers|open meandric number]].
* 42 is the only known value that is the number of sets of four distinct positive integers ''a'', ''b'', ''c'', ''d'', each less than the value itself, such that ''ab'' − ''cd'', ''ac'' − ''bd'', and ''ad'' − ''bc'' are each multiples of the value. Whether there are other values remains an open question.&lt;ref&gt;{{cite web|url=http://www.mathpages.com/home/kmath255.htm|title=Differently Perfect|website=www.mathpages.com}}&lt;/ref&gt;
* 42 is a (2,6)-perfect number ([[superperfect number|super-multiperfect]]), as σ{{sup|2}}(''n'') = σ(σ(''n'')) = 6''n''.&lt;ref&gt;{{Cite OEIS|1=A019283|2=Let sigma_m (n) be result of applying sum-of-divisors function m times to n; ... (m,k)-perfect if ...; sequence gives the (2,6)-perfect numbers. |formalname=Let sigma_m (n) be result of applying sum-of-divisors function m times to n; call n (m,k)-perfect if sigma_m (n) = k*n; sequence gives the (2,6)-perfect numbers}}&lt;/ref&gt;
* 42 is the resulting number of the original [[Smith number]] (4937775 = 3 × 5 × 5 × 65837): Both the sum of its digits (4 + 9 + 3 + 7 + 7 + 7 + 5) and the sum of the digits in its prime factorization (3 + 5 + 5 + (6 + 5 + 8 + 3 + 7)) result in 42.
* The dimension of the [[Borel subalgebra]] in the [[exceptional Lie algebra]] [[e6 (mathematics)|''e''&lt;sub&gt;6&lt;/sub&gt;]] is 42.
* 42 is the largest number ''n'' such that there exist positive integers ''p'', ''q'', ''r'' with 1 = {{sfrac|''n''}} + {{sfrac|''p''}} + {{sfrac|''q''}} + {{sfrac|''r''}}
* 42 is the smallest number ''k'' such that for every Riemann surface ''C'', #Aut(''C'') ≤ ''k'' deg(''K''&lt;sub&gt;''C''&lt;/sub&gt;) = ''k''(2''g'' − 2) ([[Hurwitz's automorphisms theorem]])
* 42 is the sum of the first 6 positive even numbers.

==Science==
* 42 is the [[atomic number]] of [[molybdenum]].
* 42 is the [[atomic mass]] of one of the naturally occurring stable isotopes of [[calcium]].
* The angle rounded to whole degrees for which a [[Water lens|rainbow]] appears (the critical angle).
* In 1966, mathematician Paul Cooper theorized that the fastest, most efficient way to travel across continents would be to bore a straight hollow tube directly through the [[Earth]], connecting a set of [[antipodes]], remove the air from the tube and fall through.&lt;ref&gt;{{cite journal |last=Cooper |first=Paul W. |journal=American Journal of Physics |title=Through the Earth in Forty Minutes |volume=34 |year=1966 |issue=1 |pages=68–69 |doi=10.1119/1.1972773 |bibcode=1966AmJPh..34...68C }}&lt;/ref&gt; The first half of the journey consists of free-fall acceleration, while the second half consists of an exactly equal deceleration. The time for such a journey works out to be 42&amp;nbsp;minutes. Even if the tube does not pass through the exact center of the Earth, the time for a journey powered entirely by gravity (known as a [[gravity train]]) always works out to be 42&amp;nbsp;minutes, so long as the tube remains friction-free, as while the force of gravity would be lessened, the distance traveled is reduced at an equal rate.&lt;ref&gt;{{cite news|url=http://www.time.com/time/magazine/article/0,9171,842469,00.html |title=To Everywhere in 42 Minutes |accessdate=2008-05-18 |work=Time |date=February 11, 1966 |archiveurl=https://web.archive.org/web/20080512131156/http://www.time.com/time/magazine/article/0%2C9171%2C842469%2C00.html |archivedate=12 May 2008 |deadurl=no |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.youtube.com/watch?v=FAFUSbIs5KA |title=Jumping into a 7,965&amp;nbsp;mile deep hole |accessdate=2008-05-18 |archiveurl=https://web.archive.org/web/20080602142755/https://www.youtube.com/watch?v=FAFUSbIs5KA |archivedate=June 2, 2008 |deadurl=yes }}&lt;/ref&gt; (The same idea was proposed, without calculation by [[Lewis Carroll]] in 1893 in ''[[Sylvie and Bruno Concluded]]''.&lt;ref&gt;{{cite book
|last=Carroll |first=Lewis |authorlink=Lewis Carroll |others=illustrated by [[Harry Furniss]] |title=[[Sylvie and Bruno Concluded]]
|volume=2 |date=29 December 1893 |publisher=Macmillan and Co. |location=United Kingdom |chapter=Chapter 7
|quote=Each railway is in a long tunnel, perfectly straight: so of course the ''middle'' of it is nearer the centre of the globe than the two ends: so every train runs half-way ''down''-hill, and that gives it force enough to run the ''other'' half ''up''-hill.
}}&lt;/ref&gt;) Now we know that is not true, and it only would take about [https://www.livescience.com/50312-how-long-to-fall-through-earth.html 38 minutes.]
* As determined by the Babylonians, in 79 years Mars orbits the Sun almost exactly 42 times.&lt;ref&gt;{{cite web|last1=Powell|first1=Martin J|title=Ancient astronomy and the naked-eye planets|url=http://www.eternalgadgetry.com/ancient_astronomy.html|website=Eternal Gadgetry|publisher=MS|accessdate=January 6, 2018}}&lt;/ref&gt;

==Technology==
* [[Magic number (programming)|Magic numbers]] used by [[programmer]]s:
** In [[Tagged Image File Format|TIFF]] (Tagged Image File Format), the second [[16-bit]] [[Word (data type)|word]] of every file is 42, "an arbitrary but carefully chosen number that further identifies the file as a TIFF file".
** In the [[reiser4]] file system, 42 is the [[inode]] number of the [[root directory]].
** In the military [http://www.irig106.org/docs/106-09/chapter10.pdf IRIG 106 Chapter 10] data recording standard, the hex value 0x464F52545974776F (ASCII "FORTYtwo") is used as a magic number to identify directory blocks.
* The [[GNU C Library]], a set of standard routines available for use in [[computer programming]], contains a [[subroutine|function]]—'''&lt;kbd&gt;memfrob()&lt;/kbd&gt;'''—which performs an [[exclusive or|XOR]] combination of a given variable and the [[Binary numeral system|binary]] pattern 00101010 (42) as an [[XOR cipher]].
* [[Hexagonal tiling|Tiling a plane using regular hexagons]], which is [[honeycomb]] in appearance, is [[Hexagonal tiling#Topologically equivalent tilings|approximated in a topological sense]] to an accuracy of better than 1% using a [[Brickwork#Bonds|stretcher bond brick pattern]] with bricks of 42 squares (6 by 7).&lt;ref&gt;{{cite journal|author1=Lee Middleton|author2=Jayanthi Sivaswamy|title=Framework for practical hexagonal-image processing|journal=Journal of Electronic Imaging|volume=11|issue=104|year=2002|url=http://spiedl.aip.org/getabs/servlet/GetabsServlet?prog=normal&amp;id=JEIME5000011000001000104000001&amp;idtype=cvips&amp;gifs=yes&amp;ref=no|doi=10.1117/1.1426078|accessdate=January 17, 2010|bibcode=2002JEI....11..104M}}{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;
* The password expiration policy for a [[Windows domain|Microsoft Windows domain]] defaults to 42 days.&lt;ref&gt;{{cite web|title=Maximum password age|url=https://technet.microsoft.com/en-us/library/hh994573.aspx|publisher=Microsoft TechNet|accessdate=15 January 2014}}&lt;/ref&gt;
* The [[ASCII]] code 42 is for the [[asterisk]] symbol, being a [[Wildcard character|wildcard]] for everything.
* 4.2V is the maximum safe voltage for most lithium ([[Lithium-ion_battery|Li-ion]] and [[Lithium_polymer_battery|Li-pol]]) battery cells.

==Astronomy==
* [[Messier object]] [[Orion Nebula|M42]], a [[apparent magnitude|magnitude]] 5.0 [[diffuse nebula]] in the [[constellation]] [[Orion (constellation)|Orion]], also known as the [[Orion Nebula]].
* The [[New General Catalogue]] object [[NGC 42]], a [[spiral galaxy]] in the constellation [[Pegasus (constellation)|Pegasus]].
* In January 2004, [[asteroid]] {{mp|2001 DA|42}} was given the permanent name [[25924 Douglasadams]], for the author [[Douglas Adams]] who popularized the number 42 and died in 2001. [[Brian G. Marsden]], the director of the [[Minor Planet Center]] and the secretary for the naming committee, remarked that, with even his initials in the provisional designation, "This was sort of made for him, wasn't it?".
* [[Kepler-42]], a red dwarf in the constellation [[Cygnus (constellation)|Cygnus]] around which orbits the three smallest [[exoplanets]] found to date.
* [[42 Isis]], a large [[main-belt]] [[asteroid]] measuring about 100&amp;nbsp;km in diameter.

==Religion==
* In Japanese culture, the number 42 is considered unlucky because the numerals when pronounced separately—''shi ni'' (four two)—sound like the word "[[death|dying]]"&lt;ref&gt;Niiya, Brian. Japanese American history: an A-to-Z reference from 1868 to the present. Facts on File, Inc., 1993, p. 352&lt;/ref&gt; like a Latin word "[[mori]]".
* In [[Egyptian mythology]], there are 42 questions asked of persons making their journey through Death. [[Ma'at]], a female personification, considered to be both maternal and a delivering force, is an  Ancient Egyptian personification of physical and moral law, order, and truth. In the judgment scene described in the Egyptian and the Book of Pass (the [[Book of the Dead]], which evolved from the [[Coffin Texts]] and the [[Pyramid Texts]]), there are 42 questions personifying the analysis of [[Ma'at]]. If the departed reasonably can give answers to the 42 questions, they have the potential to either be reincarnate, or if completely successful, reach the ultimate goal of becoming a Star, whereon, they can continue to give Light, and fuel Universal growth. 
* 42 is the number with which God creates the Universe in [[Kabbalah|Kabbalistic tradition]]. In Kabbalah, the most significant name is that of the En Sof (also known as "[[Ein Sof]]", "Infinite" or "Endless"), who is above the Sefirot (sometimes spelled "[[Sephirot]]").&lt;ref&gt;{{cite web|url=http://physics.ucsc.edu/cosmo/primack_abrams/InABeginningTikkun1995.pdf|title=In A Beginning...Quantum Cosmology and Kabbalah|accessdate=2008-03-14|author1=Joel Primack|author2=Nancy E. Abrams|format=PDF}}&lt;/ref&gt; The Forty-Two-Lettered Name contains four combined names which are spelled in Hebrew letters  (spelled in letters   = 42 letters), which is the name of Azilut (or "[[Atziluth]]" "Emanation"). While there are obvious links between the Forty-Two Lettered Name of the Babylonian Talmud and the Kabbalah's Forty-Two Lettered Name, they are probably not identical because of the Kabbalah's emphasis on numbers. The Kabbalah also contains a Forty-Five Lettered Name and a Seventy-Two Lettered Name.
* The number 42 appears in various contexts in [[Christianity]]. There are 42 generations (names) in the [[Gospel of Matthew]]'s version of the [[Genealogy of Jesus]]; it is prophesied that for 42 months the [[The Beast (Revelation)|Beast]] will hold dominion over the Earth ([[Book of Revelation|Revelation]] 13:5); 42 men of Beth-azmaveth were counted in the [[census]] of men of [[Israel]] upon return from exile ([[Book of Ezra|Ezra]] 2:24); [[God in Christianity|God]] sent bears to maul 42 of the teenage boys who mocked [[Elisha]] for his baldness ([[Books of Kings|2 Kings]] 2:23), etc.
* In [[Judaism]], the number (in the ''Babylonian Talmud'', compiled 375&amp;nbsp;AD to 499&amp;nbsp;AD) of the "Forty-Two Lettered Name" ascribed to God. Rab (or Rabhs), a 3rd-century source in the Talmud stated "The Forty-Two Lettered Name is entrusted only to him who is pious, meek, middle-aged, free from bad temper, sober, and not insistent on his rights". [Source: ''Talmud Kidduschin'' 71a, Translated by Rabbi Dr. I. Epstein]. [[Maimonides]] felt that the original Talmudic Forty-Two Lettered Name was perhaps composed of several combined divine names [Maimonides "Moreh"]. The apparently unpronouncable [[Tetragrammaton]] provides the backdrop from the Twelve-Lettered Name and the Forty-Two Lettered Name of the Talmud.{{Citation needed|date=February 2011}}
* The [[Gutenberg Bible]] is also known as the "42-line Bible", as the book contained 42 lines per page.
* The [[Forty-Two Articles|Forty-Two Articles (1552)]], largely the work of [[Thomas Cranmer]], were intended to summarize Anglican doctrine, as it now existed under the reign of [[Edward VI]].
* The [[Sutra of 42 Sections]] is a Buddhist scripture.

==Popular culture==
===''The Hitchhiker's Guide to the Galaxy''===&lt;!-- This section is linked from [[Douglas Adams]] --&gt;
[[File:Answer to Life.png|thumb|The Answer to the Ultimate Question of Life, The Universe, and Everything.]]
The number 42 is, in ''[[The Hitchhiker's Guide to the Galaxy (novel)|The Hitchhiker's Guide to the Galaxy]]'' by [[Douglas Adams]], the "[[Phrases from The Hitchhiker's Guide to the Galaxy#Answer to the Ultimate Question of Life, the Universe, and Everything (42)|Answer to the Ultimate Question of Life, the Universe, and Everything]]", calculated by [[Deep Thought (The Hitchhiker's Guide to the Galaxy)|an enormous supercomputer named Deep Thought]] over a period of 7.5 million years. Unfortunately, no one knows what the question is. Thus, to calculate the Ultimate Question, a special computer the size of a small planet was built from organic components and named "Earth". The Ultimate Question "What do you get when you multiply six by nine"&lt;!-- please do not change to seven--&gt;&lt;ref&gt;{{cite web
|url=http://kasmana.people.cofc.edu/MATHFICT/mfview.php?callnumber=mf458
|title=Mathematical Fiction: Hitchhiker's Guide to the Galaxy (1979)
|accessdate=30 November 2016
}} See this website for possible explanations of this seeming error.&lt;/ref&gt; was found by Arthur Dent and Ford Prefect in the second book of the series, ''[[The Restaurant at the End of the Universe]]''. This appeared first in the [[radio play]] and later in the novelization of ''[[The Hitchhiker's Guide to the Galaxy]]''.  The fact that Adams named the episodes of the radio play "fits", the same archaic title for a chapter or section used by Lewis Carroll in ''[[The Hunting of the Snark]]'', suggests that Adams was influenced by Carroll's fascination with and frequent use of the number. The fourth book in the series, {{H2G2|book|4|link=yes}}, contains 42 chapters.  According to {{H2G2|book|5|link=yes}}, 42 is the street address of [[Places in The Hitchhiker's Guide to the Galaxy#Stavromula Beta|Stavromula Beta]]. In 1994 Adams created the ''[[42 Puzzle]]'', a game based on the number 42.

The 2011 book ''42: Douglas Adams' Amazingly Accurate Answer to Life, the Universe and Everything''&lt;ref&gt;{{cite news |last=Gill |first=Peter |title=42: Douglas Adams' Amazingly Accurate Answer to Life the Universe and Everything |url= https://www.theguardian.com/books/2011/feb/03/douglas-adams-42-hitchhiker?INTCMP=SRCH |publisher=Guardian |accessdate=3 April 2011 |location=London |date=February 3, 2011}}&lt;/ref&gt;  examines Adams' choice of the number 42 and also contains a compendium of some instances of the number in science, popular culture, and humour.

===Works of Lewis Carroll===
[[Lewis Carroll]], who was a mathematician,&lt;ref&gt;{{cite web|url=http://findarticles.com/p/articles/mi_hb346/is_1_38/ai_n29162565/|archiveurl=https://archive.is/20120629081121/http://findarticles.com/p/articles/mi_hb346/is_1_38/ai_n29162565/|deadurl=yes|title=Lewis Carroll and Douglas Adams - Word Ways - Find Articles|date=29 June 2012|archivedate=29 June 2012|publisher=}}&lt;/ref&gt; made repeated use of this number in his writings.&lt;ref&gt;''The Mystery of Lewis Carroll,'' Jenny Woolf&lt;/ref&gt;

Examples of Carroll's use of 42:
* ''[[Alice's Adventures in Wonderland]]'' has 42 illustrations.
* Alice's attempts at multiplication (chapter two of ''Alice in Wonderland'') work if one uses base 18 to write the first answer, and increases the base by threes to 21, 24, etc. (the answers working up to 4 × 12 = "19" in base 39), but "breaks" precisely when one attempts the answer to 4 × 13 in base 42, leading Alice to declare "oh dear! I shall never get to twenty at that rate!"
* Rule Forty-two in ''Alice's Adventures in Wonderland'' ("All persons more than a mile high to leave the court").
* Rule 42 of the Code in the preface&lt;ref name="CarrollSnark"&gt;{{cite web| url= http://www.snrk.de/snarkhunt/?newpics=no#preface |title=The Hunting of the Snark |first=Lewis |last=Carroll |authorlink= Lewis Carroll |publisher=}}&lt;/ref&gt; to ''[[The Hunting of the Snark]]'' ("No one shall speak to the Man at the Helm").
* In "fit the first" of ''[[The Hunting of the Snark]]'' the Baker had "forty-two boxes, all carefully packed, With his name painted clearly on each."&lt;ref name="CarrollSnark"/&gt;
* The White Queen announces her age as "one hundred and one, five months and a day", which—if the best possible date is assumed for the action of ''[[Through the Looking-Glass]]'' (e.g., a date is chosen such that the rollover from February to March is excluded from what would otherwise be an imprecise measurement of "five months and a day")—gives a total of 37,044 days.  If the Red Queen, as part of the same chess set, is regarded as the same age, their combined age is 74,088 days, or 42 × 42 × 42.&lt;ref&gt;[http://www.slate.com/id/2245647/ What Lewis Carroll Taught Us: Alice's creator knew all about role-playing.] by Seth Lerer, March 4, 2010&lt;/ref&gt;

===Music===
* [[Level 42]] is an English [[pop music|pop]]/[[rock music|rock]] music band.
* "[[42 (song)|42]]" is one of the tracks on [[Coldplay]]'s 2008 album ''[[Viva la Vida or Death and All His Friends]]''.
* "[[Channel 42 (song)|Channel 42]]" is an electronic music song by [[deadmau5]] featuring [[Wolfgang Gartner]]; it appears on the 2012 deadmau5 album ''[[Album Title Goes Here]]''.

===Television and film===
* ''[[The Kumars at No. 42]]'' television series
* "[[42 (Doctor Who)|42]]" is an episode of ''[[Doctor Who]]'', set in [[Real time (media)|real time]] lasting approximately 42&amp;nbsp;minutes.
* On the game show ''[[Jeopardy!]]'',  "[[Watson (computer)|Watson]]" the IBM supercomputer, has 42 "threads" in its avatar.&lt;ref&gt;{{cite news|url=http://www.slate.com/id/2284721/|title=Watson Jeopardy! computer: Ken Jennings describes what it's like to play against a machine.|work=[[Slate (magazine)|Slate]]|accessdate=2 October 2015}}&lt;/ref&gt;
* ''[[42 (film)|42]]'' is a film on the life of American baseball player Jackie Robinson.

===Video games===
* [[42 Entertainment]] is the company responsible for several [[alternate reality game]]s, including ''[[I Love Bees]]'', ''[[Year Zero (game)|Year Zero]]'', and ''Why So Serious''.
* ''[[Tokyo 42]]'' is a videogame released in 2017.
*''[[Squadron 42]]'' is a videogame set in the Star Citizen Universe with an unspecified release date.

===Sports===
[[File:Jrobinson.jpg|thumb|right|[[Jackie Robinson]] in his now-retired number 42 jersey.]]
* The [[squad number|jersey number]] of [[Jackie Robinson]], which is the only number [[retired number|retired]] by all [[Major League Baseball]] teams. Although the number was retired in 1997, [[Mariano Rivera]] of the [[New York Yankees]], the last professional baseball player to wear number 42, continued to wear it until he retired at the end of the 2013 season. As of the 2014 season, no player will ever again wear the number 42 in Major League Baseball except on [[Jackie Robinson Day]] (April 15), when ''all'' uniformed personnel (players, managers, coaches, and umpires) wear the number.
* The number of [[laws of cricket]] &lt;ref&gt;{{Cite web|url=https://www.lords.org/mcc/laws-of-cricket/|title=The Laws of Cricket|last=|first=|date=|website=|publisher=|accessdate=26 January 2017}}&lt;/ref&gt;
* [[Rule 42]] is the historic name of a [[Gaelic Athletic Association]] rule (now codified in Rule 5.1 and Rule 44) that in practice prohibits the playing of "foreign sports" (generally [[association football]] and the [[rugby football|rugby codes]]) at GAA grounds.

===Architecture===
* The architects of the [[Rockefeller Center]] in [[New York City]] worked daily in the [[Graybar Building]] where on "the twenty-fifth floor, one enormous drafting room contained forty-two identical drawing boards, each the size of a six-seat dining room table; another room harboured twelve more, and an additional fourteen stood just outside the principals' offices at the top of the circular iron staircase connecting 25 to 26".&lt;ref&gt;Okrent, Daniel. Great Fortune: the Epic of the Rockefeller Centre. Viking Penguin, 2003, p. 147&lt;/ref&gt;

* In the [[Rockefeller Center]] ([[New York City]]) there are a total of "forty-two elevators in five separate banks"&lt;ref&gt;Okrent, Daniel. Great Fortune: the Epic of the Rockefeller Centre. Viking Penguin, 2003, p. 162&lt;/ref&gt; which carry tenants and visitors to the sixty-six floors.

==Other fields==
* +42 is the historic [[country calling code]] for the former country of [[Czechoslovakia]].
* There are 42 US gallons in a [[Barrel_of_oil_equivalent|barrel of oil]].
* 42 is the number of the French [[Departments of France|department]] of [[Loire (department)|Loire]]. The number is also reflected in the [[Postal codes in France|postal code]] for that area.
* [[Tower 42]] is a skyscraper in the [[City of London]], formerly known as the [[National Westminster Bank|NatWest]] Tower.&lt;ref&gt;{{cite web |title=Tower 42 - City of London |url=https://www.cityoflondon.gov.uk/services/environment-and-planning/building-control/our-projects/Pages/tower-42.aspx |website=www.cityoflondon.gov.uk |accessdate=23 October 2018}}&lt;/ref&gt;
* In [[New York City]], [[42nd Street (Manhattan)|42nd Street]] is a main and very popular two-way thoroughfare. Landmarks on it include the [[Chrysler Building]], [[Grand Central Terminal]], the main branch of the [[New York Public Library]], and [[Times Square]]. The [[Headquarters of the United Nations]] is at the east end of the street. The New York City street is also the setting for a [[42nd Street (film)|movie]] by the same name (which also gave fame to its [[42nd Street (song)|eponymous title song]]), and which later inspired a musical adaptation, ''[[42nd Street (musical)|42nd Street]]''.
* 42 is the inspiration for the name of the 42 Center of Excellence for Artificial Intelligence, based in Vienna, Austria&lt;ref&gt;{{cite web|url=http://futurezone.at/thema/start-ups/42-neues-ki-start-up-von-jajah-gruender-daniel-mattes/165.491.442|title=42: Neues KI-Start-up von Jajah-Gründer Daniel Mattes|publisher=Futurezone|accessdate=2015-11-22}}&lt;/ref&gt;.
* 42 is the name of the private [[computer science]] [[42 (school)|school]] located in [[Paris, France]] and [[Fremont, California]].
* If one were to fold a piece of paper 42 times, it would reach beyond the orbit of the moon.&lt;ref&gt;{{cite web|url=http://scienceblogs.com/startswithabang/2009/08/31/paper-folding-to-the-moon/|title=Paper Folding to the Moon – Starts With A Bang|website=scienceblogs.com}}&lt;/ref&gt;
* 42 is the number of seats in [[Social Democratic Youth of Denmark|Social Democratic Youth of Denmark's]] major council ''Hovedbestyrelsen''. At the 2016 national convention, lowering the number of seats to 32 was discussed, but eventually the convention decided to stick with 42 members.
* 42 in Chinese reads sì èr which is very close to shì a (是啊) and that means 'yes'. It was once popular among young Chinese to send 42 in short message which stands for 'yes'.{{cn|date=April 2018}}

==Other languages==
{| class="wikitable collapsible collapsed" style="margin:1em auto 1em auto;"
|- style="vertical-align:bottom;"
! scope="col" | Language
! scope="col" | Translation
|-
|[[Afrikaans Language|Afrikaans]] || ''{{lang|af|twee-en-veertig}}''
|-
|[[Albanian Language|Albanian]] || {{lang|sq|dyzetedy}}
|-
|[[Arabic numerals|Arabic]] || {{lang|ar|إثنان و أربعون}} (''ʾithnān wa ʾarbaʿūn'')
|-
|[[Basque language|Basque]] || ''{{lang|eu|berrogeita bi}}''
|-
|[[Belarusian language|Belarusian]] || {{lang|be|сорак два}} (''sorak dva'')
|-
|[[Bosnian language|Bosnian]] || ''{{lang|bs|četrdeset dva}}''
|-
|[[Bulgarian language|Bulgarian]] || {{lang|bg|четиридесет и две}} (''četirideset i dve'')
|-
|[[Catalan language|Catalan]] || ''{{lang|ca|quaranta-dos}}''
|-
|[[Chinese numerals|Chinese]] || {{lang|zh|四十二}} (&lt;big&gt;{{lang|zh|肆拾贰}}&lt;/big&gt;) (''sìshí'èr'')
|-   
|[[Chuvash numerals|Chuvash]] || хĕрĕх иккĕ (''xĕrĕx ikkĕ'', IIXXXX)
|-
|[[Croatian language|Croatian]] || ''{{lang|hr|četrdeset dva}}''
|-
|[[Czech language|Czech]] || ''{{lang|cs|čtyřicet dva}}''
|-
|[[Danish language|Danish]] || ''{{lang|da|toogfyrre}}''
|-
|[[Maldivian language|Dhivehi]] || ''Saalhees Dheyh''
|-
|[[Dutch language|Dutch]] || ''{{lang|nl|tweeënveertig}}''
|-
|[[Esperanto]] || ''{{lang|eo|kvardek du}}''
|-
|[[Estonian language|Estonian]] || ''{{lang|et|nelikümmend kaks}}''
|-
|[[Finnish language|Finnish]]|| ''{{lang|fi|neljäkymmentäkaksi}}''
|-
|[[Filipino language|Filipino]] || ''{{lang|fil|apatnapu't dalawa}}''
|-
|[[French language|French]] || ''{{lang|fr|quarante-deux}}''
|-
|[[West Frisian language|West Frisian]] || ''{{lang|fy|twaenfjirtich}}''
|-
|[[Galician language|Galician]] || ''{{lang|gl|corenta e dous}}''
|-
|[[Georgian language|Georgian]] || {{lang|ka|ორმოცდაორი}} (''ormocdaori'')
|-
|[[German language|German]] || ''{{lang|de|zweiundvierzig}}''
|-
|[[Greek language|Greek]]|| {{lang|el|σαράντα δύο}} (''saránta dýo'')
|-
|[[Gujarati language|Gujarati]]|| ''betalis''
|-
|[[Hebrew numerals|Hebrew]] || {{lang|he|ארבעים ושתיים}} (''arbayim u-shtayim'')
|-
|[[Hindi language|Hindi]] || {{lang|hi|बयालीस, ४२}} (''bayālīs'')
|-
|[[Hungarian language|Hungarian]] || ''{{lang|hu|negyvenkettő}}''
|-
|[[Icelandic language|Icelandic]] || ''{{lang|is|fjörutíu og tveir}}''
|-
|[[Indonesian language|Indonesian]] || ''{{lang|id|empat puluh dua}}''
|-
|[[Irish language|Irish]] || ''{{lang|ga|daichead a dó}}''
|-
|[[Italian language|Italian]] || ''{{lang|it|quarantadue}}''
|-
|[[Japanese writing system|Japanese]]|| {{lang|ja|四十二 (よんじゅうに)}} (''yonjūni'')
|-
|[[Kazakh language|Kazakh]] || {{lang|kk|қырық екі}} (''qırıq eki'')
|-
|[[Korean writing system|Korean]]|| {{lang|ko|사십이 / 마흔둘}} (''sasibi''/''maheundul'')
|-
|[[Kannada Language|Kannada]] || {{lang|kn|ನಲವತ್ತು ಎರಡು}} (''nalavatthu eradu'')
|-
|[[Latvian language|Latvian]]|| ''{{lang|lv|četrdesmit divi}}''
|-
|[[Livonian language|Livonian]]|| ''{{lang|liv|nēļakimdõ kakš}}''
|-
|[[Lithuanian language|Lithuanian]]|| ''{{lang|lt|keturiasdešimt du}}''
|-
|[[Lojban]]|| ''{{lang|jbo|vore}}''
|-
|[[Luxembourgish language|Luxembourgish]]|| ''{{lang|lb|zweeavéierzeg}}''
|-
|[[Macedonian language|Macedonian]] || {{lang|mk|четириесет и два}} (''četirieset i dva'')
|-
|[[Malayalam language|Malayalam]] || &lt;big&gt;{{lang|ml|നാല്പത്തിരണ്ടു}}&lt;/big&gt;
|-
|[[Maltese language|Maltese]] || ''{{lang|mt|tnejn u erbgħin}}''
|-
|[[Maori language|Māori]] || ''{{lang|mi|whā tekau ma rua}}''
|-
|[[Marathi language|Marathi]] || ''bechalis''
|-
|[[Mongolian language|Mongolian]] || {{lang|mn|дөчин хоёр}} (''döchin khoyor'')
|-
|[[Norwegian language|Norwegian]] || ''{{lang|no|førtito}}''
|-
|[[Persian language|Persian]] || {{lang|fa|چهل و دو}} (''chehel o du'')
|-
|[[Polish language|Polish]] || ''{{lang|pl|czterdzieści dwa}}''
|-
|[[Portuguese language|Portuguese]] || ''{{lang|pt|quarenta e dois}}''
|-
|[[Romanian language|Romanian]] || ''{{lang|ro|patruzeci și doi}}''
|-
|[[Russian language|Russian]] || {{lang|ru|сорок два}} (''sorok dva'')
|-
|[[Serbian language|Serbian]] || {{lang|sr|четрдесет два}} (''četrdeset dva'')
|-
|[[Shona language|Shona]] || ''{{lang|sn|Makumi mana nemaviri}}''
|-
|[[Sinhala language|Sinhala]] || &lt;big&gt;{{lang|si|හතලිස් දෙක}}&lt;/big&gt; (''hathalis deka'')
|-
|[[Slovene language|Slovene]] || ''{{lang|sl|dvainštirideset}}''
|-
|[[Slovak language|Slovak]] || ''{{lang|sk|štyridsaťdva}}''
|-
|[[Somali language|Somali]] || ''{{lang|so|laba iyo afartan}}''
|-
|[[Spanish language|Spanish]] || ''{{lang|es|cuarenta y dos}}''
|-
|[[Swedish language|Swedish]] || ''{{lang|sv|fyrtiotvå}}''
|-
|[[Tagalog language|Tagalog]] || ''{{lang|tl|apatnapu't dalawa}}''
|-
|[[Tamil language|Tamil]] || {{lang|ta|&lt;big&gt;நாற்பத்திரண்டு&lt;/big&gt;}} (''narpatti errundu'')
|-
|[[Telugu language|Telugu]] || &lt;big&gt;{{lang|te|నలభై రెండు}}&lt;/big&gt; (''nalabai rendu'')
|-
|[[Thai language|Thai]] || &lt;big&gt;{{lang|th|สี่สิบสอง}}&lt;/big&gt;
|-
|[[Turkish language|Turkish]] || ''{{lang|tr|kırk iki}}''
|-
|[[Ukrainian language|Ukrainian]] || {{lang|uk|сорок два}} (''sorok dva'')
|-
|[[Urdu]] || &lt;big&gt;{{lang|ur|بیالیس}}&lt;/big&gt; (''bayālīs'')
|-
|[[Vietnamese language|Vietnamese]]||''{{lang|vi|bốn mươi hai}}''
|-
|[[Welsh language|Welsh]] || ''{{lang|cy|pedwar deg dau}}'' / ''{{lang|cy|dau-ar-ddeugain}}''
|-
|[[Yoruba language|Yoruba]]|| ''{{lang|yo|mokanlelogoji}}''
|}

==References==
{{Reflist|30em}}

==External links==
{{Wikiquote}}
{{Wiktionary|forty-two}}
{{commonscatinline}}
* {{cite web|last=Grime|first=James|title=42 and Douglas Adams|url=http://www.numberphile.com/videos/42.html|work=Numberphile|publisher=[[Brady Haran]]|author2=Gerardo Adesso|author3=Phil Moriarty}}
* [http://math.ucr.edu/home/baez/42.html My latest favorite Number: 42], [[John C. Baez]]
* [http://st-news.com/issues/st-news-volume-11-issues-1-2/features/the-significance/forty-two-in-real-life/ The number Forty-two in real life]
{{Integers|zero}}

{{DEFAULTSORT:42 (Number)}}
[[Category:Integers]]
[[Category:In-jokes]]</text>
      <sha1>5qr9fz9zbpke4y8x5v8qeqtazup5osf</sha1>
    </revision>
  </page>
  <page>
    <title>Actuarial reserves</title>
    <ns>0</ns>
    <id>4474244</id>
    <revision>
      <id>826599343</id>
      <parentid>689827025</parentid>
      <timestamp>2018-02-20T00:58:13Z</timestamp>
      <contributor>
        <username>Mattg82</username>
        <id>8578499</id>
      </contributor>
      <comment>has some sources</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6662">{{refimprove|date=February 2018}}
An '''actuarial reserve''' is a liability equal to the [[actuarial present value]] of the future  cash flows of a contingent event. In the insurance context an actuarial reserve is the present value of the future cash flows of an insurance policy and the total liability of the insurer is the sum of the actuarial reserves for every individual policy. Regulated insurers are required to keep offsetting assets to pay off this future liability.

==The loss random variable==
The loss [[random variable]] is the starting point in the determination of any type of actuarial reserve calculation. Define &lt;math&gt;K(x)&lt;/math&gt; to be the future state lifetime random variable of a person aged x. Then, for a death benefit of one dollar and premium &lt;math&gt;P&lt;/math&gt;, the loss random variable, &lt;math&gt;L&lt;/math&gt;, can be written in [[actuarial notation]] as a function of &lt;math&gt;K(x)&lt;/math&gt;
 
:&lt;math&gt; L = v^{K(x)+1} - P\ddot{a}_{\overline{K(x)+1}|}&lt;/math&gt;

From this we can see that the present value of the loss to the insurance company now if the person dies in ''t'' years, is equal to the present value of the death benefit minus the present value of the premiums.

The loss random variable described above only defines the loss at issue. For ''K''(''x'')&amp;nbsp;&gt;&amp;nbsp;''t'', the loss random variable at time ''t'' can be defined as:

:&lt;math&gt; {}_t L = v^{K(x)+1-t} - P\ddot{a}_{\overline{K(x)+1-t|}}&lt;/math&gt;

==Net level premium reserves==
Net level premium reserves, also called benefit reserves, only involve two cash flows and are used for some [[Generally Accepted Accounting Principles (USA)|US GAAP]] reporting purposes. The valuation premium in an NLP reserve is a premium such that the value of the reserve at time zero is equal to zero. The net level premium reserve is found by taking the expected value of the loss random variable defined above. They can be formulated prospectively or retrospectively. The amount of prospective reserves at a point in time is derived by subtracting the [[actuarial present value]] of future valuation premiums from the actuarial present value of the future insurance benefits. Retrospective reserving subtracts accumulated value of benefits from accumulated value of valuation premiums as of a point in time. The two methods yield identical results (assuming bases are the same for both prospective and retrospective calculations).

As an example, consider a whole life insurance policy of one dollar issues on (x) with yearly premiums paid at the start of the year and death benefit paid at the end of the year. In actuarial notation, a benefit reserve is denoted as ''V''. Our objective is to find the value of the net level premium reserve at time t. First we define the loss random variable at time zero for this policy. Hence

:&lt;math&gt;L = v^{K(x)+1} - P\ddot{a}_{\overline{K(x)+1|}}&lt;/math&gt;
Then, taking expected values we have:
:&lt;math&gt;\operatorname{E}[L] = \operatorname{E}[v^{K(x)+1} - P\ddot{a}_{\overline{K(x)+1|}}]&lt;/math&gt;

:&lt;math&gt;\operatorname{E}[L] = \operatorname{E}[v^{K(x)+1}] - P\operatorname{E}[\ddot{a}_{\overline{K(x)+1|}}]&lt;/math&gt;

:&lt;math&gt;{}_0\!V_x=A_x - P\cdot\ddot{a}_x&lt;/math&gt;

Setting the reserve equal to zero and solving for P yields:

:&lt;math&gt;P=\frac{A_x}{\ddot{a}_x}&lt;/math&gt;
For a whole life policy as defined above the premium is denoted as &lt;math&gt;P_x&lt;/math&gt; in actuarial notation. The NLP reserve at time ''t'' is the expected value of the loss random variable at time ''t'' given ''K''(''x'')&amp;nbsp;&gt;&amp;nbsp;''t''

:&lt;math&gt; {}_t L = v^{K(x)+1-t} - P_x \ddot{a}_{\overline{K(x)+1-t|}}&lt;/math&gt;
:&lt;math&gt; \operatorname{E}[{}_t L\mid K(x)&gt;t] = \operatorname{E}[v^{K(x)+1-t}\mid K(x)&gt;t] - P_x \operatorname{E}[\ddot{a}_{\overline{K(x)+1-t|}}\mid K(x)&gt;t]&lt;/math&gt;

:&lt;math&gt;{}_t\!V_x=A_{x+t}-P_x\cdot\ddot{a}_{x+t}&lt;/math&gt;

where &lt;math&gt;{ }P_x=\frac{A_x}{\ddot{a}_{x}}&lt;/math&gt;

==Modified reserves==
Modified reserves are based on premiums which are not level by duration. Almost all modified reserves are intended to accumulate lower reserves in early policy years than they would under the net level premium method. This is to allow the issuer greater margins to pay for expenses which are usually very high in these years. To do this, modified reserves assume a lower premium in the first year or two than the net level premium, and later premiums are higher. The [[Commissioner's Reserve Valuation Method]], used for [[statutory reserve]]s in the United States, allows for use of modified reserves.&lt;ref&gt;{{cite book |first1=Albert |last1=Easton |first2=Timothy |last2=Harris |first3=Noel |last3=Abkemeier |title=Actuarial Aspects of Individual Life insurance and Annuity Contracts |edition=3rd |publisher=ACTEX |year=2014 |pages=24–25}}&lt;/ref&gt;
===Full preliminary term method===
A full preliminary term reserve is calculated by treating the first year of insurance as a one- year term insurance. Reserves for the remainder of the insurance are calculated as if they are for the same insurance minus the first year. This method usually decreases reserves in the first year sufficiently to allow payment of first  year expenses for low-premium plans, but not high-premium plans such as limited-pay whole life.&lt;ref&gt;{{Cite book |last1=Black |first1=Kenneth, Jr. |last2=Skipper |first2=Harold D., Jr. |title=Life Insurance |year=1994 |pages=567-568}}&lt;/ref&gt;

==Computation of actuarial reserves==
The calculation process often involves a number of assumptions, particularly in relation to future claims experience, and investment earnings potential.  Generally, the computation involves calculating the expected claims for each future time period.  These expected future cash outflows are then discounted to reflect interest to the date of the expected cash flow.

For example, if we expect to pay $300,000 in Year 1, $200,000 in year 2 and $150,000 in Year 3, and we are able to invest reserves to earn 8%p.a., the respective contributions to Actuarial Reserves are:

*Year 1:  $300,000 × (1.08)&lt;sup&gt;−1&lt;/sup&gt; = $277,777.78
*Year 2:  $200,000 × (1.08)&lt;sup&gt;−2&lt;/sup&gt; = $171,467.76
*Year 3:  $150,000 × (1.08)&lt;sup&gt;−3&lt;/sup&gt; = $119,074.84.

If we sum the discounted expected claims over all years in which a claim could be experienced, we have completed the computation of Actuarial Reserves.  In the above example, if there were no expected future claims after year 3, our computation would give Actuarial Reserves of $568,320.38.

==See also==
* [[Actuarial science]]
* [[Actuary]]
* [[Force of mortality]]
* [[Life insurance]]
* [[Life table]]
* [[Statutory reserve]]

==References==
{{reflist}}


{{DEFAULTSORT:Actuarial Reserves}}
[[Category:Actuarial science]]

[[de:Deckungsrückstellung]]</text>
      <sha1>omgublxhjgiir8anb5gzenl12zggijo</sha1>
    </revision>
  </page>
  <page>
    <title>Bar induction</title>
    <ns>0</ns>
    <id>5492505</id>
    <revision>
      <id>848302290</id>
      <parentid>811958113</parentid>
      <timestamp>2018-07-01T03:03:53Z</timestamp>
      <contributor>
        <ip>87.64.232.134</ip>
      </contributor>
      <comment>Typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6832">'''Bar induction''' is a reasoning principle used in [[Intuitionism|intuitionistic mathematics]], introduced by [[L.E.J. Brouwer]].  Bar induction's main use is the intuitionistic derivation of the [[Fan Theorem]], a key result used in the derivation of the [[Uniform Continuity Theorem]].

It is also useful in giving constructive alternatives to other [[classical logic|classical]] results.

The goal of the principle is to prove properties for all infinite sequences of natural numbers (called [[choice sequence|choice sequences]] in intuitionistic terminology), by inductively reducing them to properties of finite lists.  Bar induction can also be used to prove properties about all [[choice sequence|choice sequences]] in a "spread" (a special kind of [[Set_(mathematics)|set]]).

==Definition==

Given a choice sequence &lt;math&gt;x_{0},x_{1},x_{2},x_{3},...&lt;/math&gt;, any finite sequence of elements &lt;math&gt;x_{0},x_{1},x_{2},x_{3},...x_{i}&lt;/math&gt; of this sequence is called an ''initial segment'' of this choice sequence.

There are three forms of bar induction currently in the literature, each one places certain restrictions on a pair of predicates and the key differences are highlighted using bold font.

===Decidable Bar Induction (&lt;math&gt;BI_{D}&lt;/math&gt;)===

Given two predicates &lt;math&gt;R&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; on finite sequences of natural numbers such that all of the following conditions hold:
* every choice sequence contains at least one initial segment satisfying &lt;math&gt;R&lt;/math&gt; at some point (this is expressed by saying that &lt;math&gt;R&lt;/math&gt; is a ''bar'');
* '''&lt;math&gt;R&lt;/math&gt; is [[Decidability_(logic)|decidable]]''' (i.e. our bar is ''decidable'');
* every finite sequence satisfying &lt;math&gt;R&lt;/math&gt; also satisfies &lt;math&gt;A&lt;/math&gt; (so &lt;math&gt;A&lt;/math&gt; holds for every choice sequence beginning with the aforementioned finite sequence);
* if all extensions of a finite sequence by one element satisfy &lt;math&gt;A&lt;/math&gt;, then that finite sequence also satisfies &lt;math&gt;A&lt;/math&gt; (this is sometimes referred to as &lt;math&gt;A&lt;/math&gt; being ''upward hereditary'');

then we can conclude that &lt;math&gt;A&lt;/math&gt; holds for the empty sequence (i.e. A holds for all choice sequences starting with the empty sequence).

This principle of bar induction is favoured in the works of, [[A. S. Troelstra]], [[Stephen Cole Kleene|S.C. Kleene]] and Dragalin.

===Thin Bar Induction (&lt;math&gt;BI_{T}&lt;/math&gt;)===

Given two predicates &lt;math&gt;R&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; on finite sequences of natural numbers such that all of the following conditions hold:
* every choice sequence contains at least '''a unique''' initial segment satisfying &lt;math&gt;R&lt;/math&gt; at some point (i.e. our bar is ''thin'');
* every finite sequence satisfying &lt;math&gt;R&lt;/math&gt; also satisfies &lt;math&gt;A&lt;/math&gt;;
* if all extensions of a finite sequence by one element satisfy &lt;math&gt;A&lt;/math&gt;, then that finite sequence also satisfies &lt;math&gt;A&lt;/math&gt;;

then we can conclude that &lt;math&gt;A&lt;/math&gt; holds for the empty sequence.

This principle of bar induction is favoured in the works of [[Joan Moschovakis]] and is (intuitionistically) provably equivalent to decidable bar induction.

===Monotonic Bar Induction (&lt;math&gt;BI_{M}&lt;/math&gt;)===

Given two predicates &lt;math&gt;R&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; on finite sequences of natural numbers such that all of the following conditions hold:
* every choice sequence contains at least one initial segment satisfying &lt;math&gt;R&lt;/math&gt; at some point;
* '''once a finite sequence satisfies &lt;math&gt;R&lt;/math&gt;, then every possible extension of that finite sequence also satisfies &lt;math&gt;R&lt;/math&gt;''' (i.e. our bar is ''monotonic'');
* every finite sequence satisfying &lt;math&gt;R&lt;/math&gt; also satisfies &lt;math&gt;A&lt;/math&gt;;
* if all extensions of a finite sequence by one element satisfy &lt;math&gt;A&lt;/math&gt;, then that finite sequence also satisfies &lt;math&gt;A&lt;/math&gt;;

then we can conclude that &lt;math&gt;A&lt;/math&gt; holds for the empty sequence.

This principle of bar induction is used in the works of [[A. S. Troelstra]], [[Stephen Cole Kleene|S.C. Kleene]], Dragalin and [[Joan Moschovakis]].  It is usually derived from either thin bar induction or monotonic bar induction.  (Dummett 1977)

===Relationships between these schemata and other information===

The following results about these schemata can be [[Intuitionism|intuitionistically]] proven (mouse over symbols for meaning):

*&lt;math&gt;B_{M}&lt;/math&gt;[[Turnstile_(symbol)|&lt;math&gt;\vdash&lt;/math&gt;]] &lt;math&gt;B_{D}&lt;/math&gt;
*&lt;math&gt;B_{D}&lt;/math&gt;[[Turnstile_(symbol)|&lt;math&gt;\vdash&lt;/math&gt;]] &lt;math&gt; B_{T}&lt;/math&gt;
*&lt;math&gt;B_{T}&lt;/math&gt;[[Turnstile_(symbol)|&lt;math&gt;\vdash&lt;/math&gt;]] &lt;math&gt; B_{D}&lt;/math&gt;

===Unrestricted bar induction===

An additional schemata of bar induction was originally given as a theorem by [[L._E._J._Brouwer|Brouwer]] (1975) containing no "extra" restriction on R under the name ''The Bar Theorem''.  However, the proof for this theorem was erroneous, and unrestricted bar induction is not considered to be intuitionistically valid (see Dummett 1977 pp94-104 for a summary of why this is so).  The schema of unrestricted bar induction is given below for completeness.

Given two predicates &lt;math&gt;R&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; on finite sequences of natural numbers such that all of the following conditions hold:
* every choice sequence contains at least one initial segment satisfying &lt;math&gt;R&lt;/math&gt; at some point;
* every finite sequence satisfying &lt;math&gt;R&lt;/math&gt; also satisfies &lt;math&gt;A&lt;/math&gt;;
* if all extensions of a finite sequence by one element satisfy &lt;math&gt;A&lt;/math&gt;, then that finite sequence also satisfies &lt;math&gt;A&lt;/math&gt;;

then we can conclude that &lt;math&gt;A&lt;/math&gt; holds for the empty sequence.

==Relations to Other Fields==

In classical [[reverse mathematics]], "bar induction" (&lt;math&gt;BI_{D}&lt;/math&gt;) denotes the related principle stating that if a relation &lt;math&gt;R&lt;/math&gt;'' is a [[well-order]], then we have the schema of [[transfinite induction]] over &lt;math&gt;R&lt;/math&gt; for arbitrary formulas.

==References==

* [[L. E. J. Brouwer]] ''Brouwer, L. E. J. Collected Works'', Vol. I, Amsterdam: North-Holland  (1975).
*{{SpringerEOM| title=Bar induction | id=Bar_induction | oldid=12849 | first=A.G. | last=Dragalin }}
* [[Michael Dummett]], ''Elements of intuitionism'', Clarendon Press  (1977)
* [[Stephen Cole Kleene|S.C. Kleene]],   R.E. Vesley, ''The foundations of intuitionistic mathematics: especially in relation to recursive functions'', North-Holland  (1965)
* Michael Rathjen, ''The role of parameters in bar rule and bar induction'', Journal of Symbolic Logic 56 (1991), no.&amp;nbsp;2, pp.&amp;nbsp;715–730.
* [[A. S. Troelstra]], ''Choice sequences'', Clarendon Press  (1977)
* [[A. S. Troelstra]] and [[Dirk Van Dalen]], ''Constructivism in Mathematics, Studies in Logic and the Foundations of Mathematics'', Elsevier (1988)

[[Category:Constructivism (mathematics)]]
[[Category:Mathematical induction]]


{{logic-stub}}</text>
      <sha1>azksaxji0kmdvn5srqjmyhrtnledod9</sha1>
    </revision>
  </page>
  <page>
    <title>Barnardisation</title>
    <ns>0</ns>
    <id>11682860</id>
    <revision>
      <id>750208442</id>
      <parentid>720926389</parentid>
      <timestamp>2016-11-18T09:56:52Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Statistical analysis]]; added [[Category:Survey methodology]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1356">'''Barnardisation''' is a method of disclosure control for tables of counts that involves randomly adding or subtracting 1 from some cells in the table.

It is named after Professor [[George Alfred Barnard]] (1915&amp;ndash;2002), a professor of [[mathematics]] at the [[University of Essex]].

In the [[United Kingdom]], barnardisation is sometimes employed by public agencies in order to enable them to provide information for statistical purposes without infringing the [[information privacy]] rights of the individuals to whom the information relates. The question whether barnardisation may fall short of the complete anonymisation of data and the status of barnardised data under the complex provisions of the [[Data Protection Act 1998]] were considered by the [[Judicial functions of the House of Lords|House of Lords]] in the case of ''Common Services Agency v Scottish Information Commissioner'' [2008] 1 WLR 1550, the above case is also reported at All ER 2008 (4) 851.

==References==
*[[Office For National Statistics]] - Review of the Dissemination of Health Statistics: Confidentiality Guidance Working Paper 3: Risk Management http://www.ons.gov.uk/ons/guide-method/best-practice/disclosure-control-of-health-statistics/working-paper-3--risk-management.pdf

[[Category:Survey methodology]]
[[Category:Information privacy]]


{{statistics-stub}}</text>
      <sha1>50xl1jto29lg5wthuudvteanhqegf33</sha1>
    </revision>
  </page>
  <page>
    <title>Box–Cox distribution</title>
    <ns>0</ns>
    <id>15811316</id>
    <revision>
      <id>753618908</id>
      <parentid>624734972</parentid>
      <timestamp>2016-12-08T06:43:26Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed parent category of [[Category:Continuous distributions]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1320">In [[statistics]], the '''Box–Cox distribution''' (also known as the '''power-normal distribution''') is the distribution of a [[random variable]] ''X'' for which the [[Box–Cox transformation]] on ''X'' follows a [[truncated normal distribution]]. It is a continuous [[probability distribution]] having [[probability density function]] (pdf) given by

:&lt;math&gt;
f(y) = \frac{1}{\left(1-I(f&lt;0)-\sgn(f)\Phi(0,m,\sqrt{s})\right)\sqrt{2 \pi s^2}} \exp\left\{-\frac{1}{2s^2}\left(\frac{y^f}{f} - m\right)^2\right\}
&lt;/math&gt;

for ''y'' &gt; 0, where ''m'' is the [[location parameter]] of the distribution, ''s'' is the dispersion, ''&amp;fnof;'' is the family parameter, ''I'' is the [[indicator function]], &amp;Phi; is the [[cumulative distribution function]] of the [[standard normal distribution]], and sgn is the [[sign function]].

==Special cases==
* ''&amp;fnof;'' = 1 gives a [[truncated normal distribution]].

==References==
*{{cite paper
|title = Properties of the Power-Normal Distribution
|last = Freeman
|first = Jade
|author2=Reza Modarres
 |publisher = U.S. Environmental Protection Agency
|url = http://www.udc.edu/docs/dc_water_resources/technical_reports/report_n_190.pdf
}}

{{ProbDistributions|continuous-semi-infinite}}

{{DEFAULTSORT:Box-Cox distribution}}
[[Category:Continuous distributions]]

{{statistics-stub}}</text>
      <sha1>p6pgojcyhbh29mgbdmwzkv1n0qgbp5w</sha1>
    </revision>
  </page>
  <page>
    <title>Bramble (graph theory)</title>
    <ns>0</ns>
    <id>36601188</id>
    <revision>
      <id>846503774</id>
      <parentid>845120271</parentid>
      <timestamp>2018-06-19T04:58:30Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7611">[[File:3x3 grid graph haven.svg|thumb|A bramble of order four in a 3&amp;times;3 grid graph, consisting of six mutually touching connected subgraphs]]
In graph theory, a '''bramble''' for an [[undirected graph]] ''G'' is a family of [[connected graph|connected]] [[Glossary of graph theory#Subgraphs|subgraphs]] of ''G'' that all touch each other: for every pair of disjoint subgraphs, there must exist an edge in ''G'' that has one endpoint in each subgraph. The ''order'' of a bramble is the smallest size of a [[hitting set]], a set of vertices of ''G'' that has a nonempty intersection with each of the subgraphs. Brambles may be used to characterize the [[treewidth]] of ''G''.&lt;ref name="st93"&gt;{{citation
 | last1 = Seymour | first1 = Paul D. | author1-link = Paul Seymour (mathematician)
 | last2 = Thomas | first2 = Robin | author2-link = Robin Thomas (mathematician)
 | doi = 10.1006/jctb.1993.1027
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 1214888
 | pages = 22–33
 | title = Graph searching and a min-max theorem for tree-width
 | volume = 58
 | year = 1993}}. In this reference, brambles are called "screens" and their order is called "thickness".&lt;/ref&gt;

==Treewidth and havens==
A [[haven (graph theory)|haven]] of order ''k'' in a graph ''G'' is a function ''&amp;beta;'' that maps each set ''X'' of fewer than ''k'' vertices to a connected component of ''G''&amp;nbsp;&amp;minus;&amp;nbsp;''X'', in such a way that every two subsets ''&amp;beta;''(''X'') and ''&amp;beta;''(''Y'') touch each other. Thus, the set of images of ''&amp;beta;'' forms a bramble in ''G'', with order ''k''. Conversely, every bramble may be used to determine a haven: for each set ''X'' of size smaller than the order of the bramble, there is a unique connected component ''&amp;beta;''(''X'') that contains all of the subgraphs in the bramble that are disjoint from ''X''.

As Seymour and Thomas showed, the order of a bramble (or equivalently, of a haven) characterizes [[treewidth]]: a graph has a bramble of order ''k'' if and only if it has treewidth at least {{nowrap|''k'' &amp;minus; 1}}.&lt;ref name="st93"/&gt;

==Size of brambles==
[[Expander graph]]s of bounded [[degree (graph theory)|degree]] have treewidth proportional to their number of vertices, and therefore also have brambles of linear order. However, as Grohe and Marx showed, for these graphs, a bramble of such a high order must include exponentially many sets. More strongly, for these graphs, even brambles whose order is slightly larger than the square root of the treewidth must have exponential size. However, Grohe and Marx also showed that every graph of treewidth ''k'' has a bramble of polynomial size and of order &lt;math&gt;\Omega(k^{1/2}/\log^2 k)&lt;/math&gt;.&lt;ref&gt;{{citation
 | last1 = Grohe | first1 = Martin
 | last2 = Marx | first2 = Dániel
 | doi = 10.1016/j.jctb.2008.06.004
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 2467827
 | pages = 218–228
 | title = On tree width, bramble size, and expansion
 | volume = 99
 | year = 2009}}.&lt;/ref&gt;

==Computational complexity==
Because brambles may have exponential size, it is not always possible to construct them in [[polynomial time]] for graphs of unbounded treewidth. However, when the treewidth is bounded, a polynomial time construction is possible: it is possible to find a bramble of order ''k'', when one exists, in time O(''n''&lt;sup&gt;''k''&amp;nbsp;+&amp;nbsp;2&lt;/sup&gt;) where ''n'' is the number of vertices in the given graph. Even faster algorithms are possible for graphs with few minimal separators.&lt;ref&gt;{{citation
 | last1 = Chapelle | first1 = Mathieu
 | last2 = Mazoit | first2 = Frédéric
 | last3 = Todinca | first3 = Ioan
 | contribution = Constructing brambles
 | doi = 10.1007/978-3-642-03816-7_20
 | location = Berlin
 | mr = 2539494
 | pages = 223–234
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = Mathematical Foundations of Computer Science 2009: 34th International Symposium, MFCS 2009, Novy Smokovec, High Tatras, Slovakia, August 24-28, 2009, Proceedings
 | volume = 5734
 | year = 2009| bibcode = 2009LNCS.5734..223C
 }}.&lt;/ref&gt;

Bodlaender, Grigoriev, and Koster&lt;ref&gt;{{citation
 | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender
 | last2 = Grigoriev | first2 = Alexander
 | last3 = Koster | first3 = Arie M. C. A.
 | doi = 10.1007/s00453-007-9056-z
 | issue = 1
 | journal = [[Algorithmica]]
 | mr = 2385750
 | pages = 81–98
 | title = Treewidth lower bounds with brambles
 | volume = 51
 | year = 2008}}.&lt;/ref&gt; studied heuristics for finding brambles of high order. Their methods do not always generate brambles of order close to the treewidth of the input graph, but for planar graphs they give a constant [[approximation ratio]]. Kreutzer and Tazari&lt;ref&gt;{{citation
 | last1 = Kreutzer | first1 = Stephan
 | last2 = Tazari | first2 = Siamak
 | contribution = On brambles, grid-like minors, and parameterized intractability of monadic second-order logic
 | pages = 354–364
 | title = Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms (SODA '10)
 | url = http://dl.acm.org/citation.cfm?id=1873601.1873631
 | year = 2010}}.&lt;/ref&gt; provide [[randomized algorithm]]s that, on graphs of treewidth ''k'', find brambles of polynomial size and of order &lt;math&gt;\Omega(k^{1/2}/\log^3 k)&lt;/math&gt; within polynomial time, coming within a logarithmic factor of the order shown by {{harvtxt|Grohe|Marx|2009}} to exist for polynomial size brambles.

==Directed brambles==
The concept of bramble has also been defined for directed graphs&lt;ref&gt;{{citation
 | last1 = Reed | first1 = Bruce
 | contribution = Introducing directed tree width
 | pages = 222–229
 | title =Electronic Notes in Discrete Mathematics
 | doi = 10.1016/S1571-0653(05)80061-7
 | url = https://www.sciencedirect.com/science/article/pii/S1571065305800617
 | volume = 3
 | year = 1999
 | publisher = Elsevier
}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | contribution = Directed Tree-Width
 | title  = Journal of Combinatorial Theory, Series B
 | volume = 82
 | number = 1
 | pages = 138–154
 | year = 2001
 | doi = 10.1006/jctb.2000.2031
 | url = https://www.sciencedirect.com/science/article/pii/S0095895600920318
 | first1 = Thor | last1 = Johnson
 | first2 = Neil | last2 = Robertson
 | first3 = Paul | last3 = Seymour
 | first4 = Robin | last4 = Thomas
}}&lt;/ref&gt;. In a [[directed graph]] ''D'', a '''bramble''' is a collection of [[Graph_(discrete_mathematics)#Connected_graph|strongly connected]] subgraphs of ''D'' that all touch each other: for every pair of disjoint elements ''X'', ''Y'' of the bramble, there must exist an arc in ''D'' from ''X'' to ''Y'' and one from ''Y'' to ''X''. The ''order'' of a bramble is the smallest size of a [[hitting set]], a set of vertices of ''D'' that has a nonempty intersection with each of the elements of the bramble. The ''bramble number'' of ''D'' is the maximum order of a bramble in ''D''.
As noted in &lt;ref&gt;{{citation
 | last1 = Kawarabayashi | first1 = Ken-ichi
 | last2 = Kreutzer | first2 = Stephan
 | contribution = The Directed Grid Theorem
 | title = Proceedings of the Forty-seventh Annual ACM Symposium on Theory of Computing (STOC '15)
 | year = 2015
 | location = Portland, Oregon, USA
 | pages = 655–664
 | url = http://doi.acm.org/10.1145/2746539.2746586
 | doi = 10.1145/2746539.2746586
 | publisher = ACM| arxiv = 1411.5681
 }}&lt;/ref&gt;, the bramble number of a directed graph is within a constant factor of its directed treewidth.

==References==
{{reflist}}

[[Category:Graph theory objects]]
[[Category:Graph minor theory]]</text>
      <sha1>64tanhn0uv5swbydpwsbkixj8ezldpm</sha1>
    </revision>
  </page>
  <page>
    <title>Brooks' theorem</title>
    <ns>0</ns>
    <id>21042117</id>
    <revision>
      <id>833358395</id>
      <parentid>833309226</parentid>
      <timestamp>2018-03-31T02:16:34Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 833309226 by [[Special:Contributions/Sudarshansudarshan|Sudarshansudarshan]] ([[User talk:Sudarshansudarshan|talk]]) that proves chromatic # is less than delta+1 but the theorem says delta not delta+1</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7448">[[File:Graph exact coloring.svg|179px|thumb|[[Complete graph]]s need one more color than their maximum degree. They and the odd cycles are the only exceptions to Brooks' theorem.]]
In [[graph theory]], '''Brooks' theorem''' states a relationship between the maximum [[degree (graph theory)|degree]] of a graph and its [[chromatic number]]. According to the theorem, in a connected graph in which every vertex has at most Δ neighbors, the vertices can be [[graph coloring|colored]] with only Δ colors, except for two cases, [[complete graph]]s and [[cycle graph]]s of odd length, which require Δ&amp;nbsp;+&amp;nbsp;1 colors.

The theorem is named after [[R. Leonard Brooks]], who published a proof of it in 1941. A coloring with the number of colors described by Brooks' theorem is sometimes called a ''Brooks coloring'' or a Δ-''coloring''.

==Formal statement==
For any [[connected graph|connected]] [[undirected graph]] ''G'' with maximum [[degree (graph theory)|degree]] Δ,
the [[chromatic number]] of ''G'' is at most Δ unless ''G'' is a complete graph or an odd cycle, in which case the chromatic number is&amp;nbsp;Δ&amp;nbsp;+&amp;nbsp;1.

==Proof==
{{harvs|last=Lovász|first=László|authorlink=László Lovász|year=1975|txt}} gives a simplified proof of Brooks' theorem. If the graph is not [[biconnected graph|biconnected]], its biconnected components may be colored separately and then the colorings combined. If the graph has a vertex ''v'' with degree less than Δ, then a [[greedy coloring]] algorithm that colors vertices farther from ''v'' before closer ones uses at most Δ colors. Therefore, the most difficult case of the proof concerns biconnected Δ-[[regular graph|regular]] graphs with Δ&amp;nbsp;≥&amp;nbsp;3. In this case, Lovász shows that one can find a [[spanning tree]] such that two nonadjacent neighbors ''u'' and ''w'' of the root ''v'' are leaves in the tree. A greedy coloring starting from ''u'' and ''w'' and processing the remaining vertices of the spanning tree in bottom-up order, ending at ''v'', uses at most Δ colors. For, when every vertex other than ''v'' is colored, it has an uncolored parent, so its already-colored neighbors cannot use up all the free colors, while at ''v'' the two neighbors ''u'' and ''w'' have equal colors so again a free color remains for ''v'' itself.

==Extensions==
A more general version of the theorem applies to [[list coloring]]: given any connected undirected graph with maximum degree Δ that is neither a [[clique (graph theory)|clique]] nor an odd cycle, and a list of Δ colors for each vertex, it is possible to choose a color for each vertex from its list so that no two adjacent vertices have the same color. In other words, the list chromatic number of a connected undirected graph G never exceeds Δ, unless G is a clique or an odd cycle. This has been proved by {{harvs|first=Vadim|last=Vizing|authorlink=Vadim G. Vizing|year=1976|txt}}.

For certain graphs, even fewer than Δ colors may be needed. {{harvs|last=Reed|first=Bruce|authorlink=Bruce Reed (mathematician)|year=1999|txt}} shows that Δ&amp;nbsp;&amp;minus;&amp;nbsp;1 colors suffice if and only if the given graph has no Δ-clique, ''provided'' Δ is large enough. For [[triangle-free graph]]s, or more generally graphs in which the [[neighborhood (graph theory)|neighborhood]] of every vertex is sufficiently [[sparse graph|sparse]], O(Δ/log&amp;nbsp;Δ) colors suffice.&lt;ref&gt;{{harvtxt|Alon|Krivelevich|Sudakov|1999}}.&lt;/ref&gt;

The degree of a graph also appears in upper bounds for other types of coloring; for [[edge coloring]], the result that the chromatic index is at most Δ&amp;nbsp;+&amp;nbsp;1 is [[Vizing's theorem]]. An extension of Brooks' theorem to [[total coloring]], stating that the total chromatic number is at most Δ&amp;nbsp;+&amp;nbsp;2, has been conjectured by [[Mehdi Behzad]] and Vizing. The Hajnal–Szemerédi theorem on [[equitable coloring]] states that any graph has a (Δ&amp;nbsp;+&amp;nbsp;1)-coloring in which the sizes of any two color classes differ by at most one.

==Algorithms==
A Δ-coloring, or even a Δ-list-coloring, of a degree-Δ graph may be found in linear time.&lt;ref&gt;{{harvtxt|Skulrattanakulchai|2006}}.&lt;/ref&gt; Efficient algorithms are also known for finding Brooks colorings in parallel and distributed models of computation.&lt;ref&gt;{{harvtxt|Karloff|1989}}; {{harvtxt|Hajnal|Szemerédi|1990}}; {{harvtxt|Panconesi|Srinivasan|1995}}; {{harvtxt|Grable|Panconesi|2000}}.&lt;/ref&gt;

==Notes==
{{reflist|2}}

==References==
*{{citation
 | last1 = Alon | first1 = Noga | author1-link = Noga Alon
 | last2 = Krivelevich | first2 = Michael | author2-link = Michael Krivelevich
 | last3 = Sudakov | first3 = Benny | author3-link = Benny Sudakov
 | doi = 10.1006/jctb.1999.1910
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 73–82
 | title = Coloring graphs with sparse neighborhoods
 | volume = 77
 | year = 1999}}
*{{citation
 | last = Brooks | first = R. L. | authorlink = R. Leonard Brooks
 | journal = [[Mathematical Proceedings of the Cambridge Philosophical Society]]
 | pages = 194–197
 | title = On colouring the nodes of a network
 | volume = 37
 | doi = 10.1017/S030500410002168X
 | year = 1941}}.
*{{citation
 | last1 = Grable | first1 = David A.
 | last2 = Panconesi | first2 = Alessandro
 | title = Fast distributed algorithms for Brooks–Vizing colourings
 | pages = 85–120
 | volume = 37
 | journal = Journal of Algorithms
 | doi = 10.1006/jagm.2000.1097
 | year = 2000}}.
*{{citation
 | last1 = Hajnal | first1 = Péter
 | last2 = Szemerédi | first2 = Endre | author2-link = Endre Szemerédi
 | doi = 10.1137/0403008
 | issue = 1
 | journal = [[SIAM Journal on Discrete Mathematics]]
 | pages = 74–80
 | title = Brooks coloring in parallel
 | volume = 3
 | year = 1990}}.
*{{citation
 | last = Karloff | first = H. J.
 | doi = 10.1016/0304-3975(89)90121-7
 | issue = 1
 | journal = Theoretical Computer Science
 | pages = 89–103
 | title = An NC algorithm for Brooks' theorem
 | volume = 68
 | year = 1989}}.
*{{citation
 | last = Lovász | first = L. | author-link = László Lovász
 | doi = 10.1016/0095-8956(75)90089-1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 269–271
 | title = Three short proofs in graph theory
 | volume = 19
 | year = 1975}}.
*{{citation
 | last1 = Panconesi | first1 = Alessandro
 | last2 = Srinivasan | first2 = Aravind
 | doi = 10.1007/BF01200759
 | issue = 2
 | journal = [[Combinatorica]]
 | pages = 255–280
 | title = The local nature of Δ-coloring and its algorithmic applications
 | volume = 15
 | year = 1995}}.
*{{citation
 | doi = 10.1006/jctb.1998.1891
 | last = Reed | first = Bruce | authorlink = Bruce Reed (mathematician)
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 136–149
 | title = A strengthening of Brooks' theorem
 | volume = 76
 | year = 1999}}.
*{{citation
 | last = Skulrattanakulchai | first = San
 | doi = 10.1016/j.ipl.2005.12.007
 | issue = 3
 | journal = [[Information Processing Letters]]
 | pages = 101–106
 | title = Δ-List vertex coloring in linear time
 | volume = 98
 | year = 2006}}.
*{{citation|last=Vizing|first= V. G.|year=1976|title=Vertex colorings with given colors|language=Russian|journal=Diskret. Analiz.|volume=29|pages=3–10}}.

==External links==
*{{mathworld|title=Brooks' Theorem|urlname=BrooksTheorem}}

[[Category:Graph coloring]]
[[Category:Theorems in graph theory]]</text>
      <sha1>4ypw5k9imtgwh8k4p4drh0t34gojdiq</sha1>
    </revision>
  </page>
  <page>
    <title>Cas (mathematics)</title>
    <ns>0</ns>
    <id>55635210</id>
    <redirect title="Hartley transform" />
    <revision>
      <id>807256131</id>
      <parentid>807255639</parentid>
      <timestamp>2017-10-26T21:35:23Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="136">#redirect [[Hartley transform#cas]] {{R to related topic}}
{{lowercase}}

[[Category:Trigonometry]]
[[Category:Mathematical identities]]</text>
      <sha1>gez71hu37pxo70w779vrz6stt0imur5</sha1>
    </revision>
  </page>
  <page>
    <title>Conformally flat manifold</title>
    <ns>0</ns>
    <id>3415428</id>
    <revision>
      <id>790301103</id>
      <parentid>748791782</parentid>
      <timestamp>2017-07-12T21:03:23Z</timestamp>
      <contributor>
        <ip>144.174.11.69</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1844">A ([[pseudo-Riemannian manifold|pseudo]]-)[[Riemannian manifold]] is '''conformally flat''' if each point has a neighborhood that can be mapped to flat space by a [[conformal transformation]].

More formally, let (''M'', ''g'') be a pseudo-Riemannian manifold. Then (''M'', ''g'') is conformally flat if for each point ''x'' in ''M'', there exists a neighborhood ''U'' of ''x'' and a [[smooth function]] ''f'' defined on ''U'' such that (''U'', ''e''&lt;sup&gt;2''f''&lt;/sup&gt;''g'') is [[flat manifold|flat]] (i.e. the [[Riemann curvature tensor|curvature]] of ''e''&lt;sup&gt;2''f''&lt;/sup&gt;''g'' vanishes on ''U''). The function ''f'' need not be defined on all of ''M''.

Some authors use ''locally conformally flat'' to describe the above notion and reserve ''conformally flat'' for the case in which the function ''f'' is defined on all of ''M''.

==Examples==
*Every manifold with [[constant curvature|constant]] [[sectional curvature]] is conformally flat.
*Every 2-dimensional pseudo-Riemannian manifold is conformally flat.
*A 3-dimensional pseudo-Riemannian manifold is conformally flat if and only if the [[Cotton tensor]] vanishes.
*An ''n''-dimensional pseudo-Riemannian manifold for ''n'' ≥ 4 is conformally flat if and only if the [[Weyl tensor]] vanishes.
*Every [[compact space|compact]], [[simply connected]], conformally Euclidean Riemannian manifold is conformally equivalent to the [[n-sphere|round sphere]].&lt;ref&gt;{{cite journal|last1=Kuiper|first1=N. H.|title=On conformally flat spaces in the large|journal=Annals of Mathematics|date=1949|volume=50|pages=916–924|doi=10.2307/1969587|jstor=1969587|ref=Kuiper}}&lt;/ref&gt;

== See also ==
* [[Weyl–Schouten theorem]]
* [[conformal geometry]]

==References==
{{Reflist}}

[[Category:Conformal geometry]]
[[Category:Riemannian geometry]]
[[Category:Manifolds]]


{{differential-geometry-stub}}</text>
      <sha1>khmvpj4e0qsbxtodj7xq24j4hzymh9r</sha1>
    </revision>
  </page>
  <page>
    <title>Confrontation analysis</title>
    <ns>0</ns>
    <id>29947659</id>
    <revision>
      <id>740692939</id>
      <parentid>726406641</parentid>
      <timestamp>2016-09-22T17:42:31Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Mathematical economics]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12287">[[Image:BosnianSoap.jpg|thumb|right|x250px|alt=Screenshot illustrating the use of confrontation analysis in a role play written by Professor Nigel Howard in a computer-aided role play depicting the Siege of Sarajevo |Screenshot illustrating the use of confrontation analysis in a computer-aided role play depicting the [[Siege of Sarajevo]].  The software was written by Professor [[Nigel Howard (professor)|Nigel Howard]] for General [[Rupert Smith]] in 1996.]]
'''Confrontation analysis''' (also known as '''dilemma analysis''') is an [[operational analysis]] technique used to structure, understand and think through multi-party interactions such as negotiations. It is the underpinning mathematical basis of [[drama theory]]. 

It is derived from [[game theory]] but considers that instead of resolving the game, the players often redefine the game when interacting. Emotions triggered from the potential interaction play a large part in this redefinition. So whereas game theory looks on an interaction as a single decision matrix and resolves that, confrontation analysis looks on the interaction as a sequence of linked interactions, where the decision matrix changes under the influence of precisely defined emotional ''dilemmas''.&lt;ref name="dilemm"&gt;See [http://www.dilemmasgalore.com/forum/viewtopic.php?f=15&amp;t=17 definition of Dilemma]&lt;/ref&gt;

==Derivation and use==

Confrontation analysis was devised by Professor [[Nigel Howard (professor)|Nigel Howard]] in the early 1990s drawing from his work on game theory and [[metagame analysis]]. It has been turned to defence,&lt;ref name="dw1"&gt;See [http://www.decisionworkshops.com/#/the-future-of-libya/4553627902 The future of Libya]&lt;/ref&gt; political, legal, financial&lt;ref name="ft"&gt;"role playing... can also be used by investors in the form of "confrontation analysis' such as that organised by former military analyst [[Michael Young (former military analyst)|Mike Young's]] [http://www.decisionworkshops.com Decision Workshops]" –  ''Greek Dungeons and German Dragons'', James Macintosh, ''[[Financial Times]]'', 9 November 2011.&lt;/ref&gt; and commercial &lt;ref&gt;See [http://www.decisionworkshops.com/#/letting-agency/4550567082 Letting agency case study]&lt;/ref&gt; applications.

Much of the theoretical background to General [[Rupert Smith]]'s book ''[[The Utility of Force]]'' drew its inspiration from the theory of confrontation analysis.{{quotation|I am in debt to Professor Nigel Howard, whose explanation of Confrontation Analysis and Game Theory at a seminar in 1998 excited my interest. Our subsequent discussions helped me to order my thoughts and the lessons I had learned into a coherent structure with the result that, for the first time, I was able to understand my experiences within a theoretical model which allowed me to use them further|General Rupert Smith|[[The Utility of Force]] (p.xvi)}}

Confrontation analysis can also be used in a ''decision workshop'' as structure to support role-playing&lt;ref name="ft"/&gt; for training, analysis and decision rehearsal.

== Method ==
[[Image:BosniaConfrontation0.JPG|thumb|361px|left|An interaction as a sequence of confrontations where the ''card table''&lt;ref name="ct"/&gt; changes as the parties struggle to eliminate their ''dilemmas''&lt;ref name="dilemm"/&gt;]]
Confrontation analysis looks on an interaction as a sequence of confrontations. During each confrontation the parties communicate until they have made their ''positions''&lt;ref name="posn"&gt;See [http://www.dilemmasgalore.com/forum/viewtopic.php?f=15&amp;t=29 definition of Position]&lt;/ref&gt; clear to one another.  These positions can be expressed as a ''card table'' (also known as an options board&lt;ref name="ct"&gt;See [http://www.dilemmasgalore.com/forum/viewtopic.php?f=15&amp;t=29 definition of Options Board/Card table]&lt;/ref&gt;) of yes/no decisions. For each decision each party communicates what they would like to happen (their ''position''&lt;ref name="posn"/&gt;) and what will happen if they cannot agree (the ''threatened future''). These interactions produce ''dilemmas''&lt;ref name="dilemm"/&gt; and the ''card table'' changes as players attempt to eliminate these.
{{clear|right}}

[[Image:BosniaConfrontation1.JPG|thumb|x250px|right|Initial Card Table:&lt;ref name="ct"/&gt; The UN threatens to use air strikes, but is not believed by the Bosnian Serbs: The UN has three dilemmas&lt;ref name="dilemm"/&gt; The Bosnians have none]]
Consider the example on the [[:File:BosniaConfrontation2.JPG|right]] (Initial Card Table), taken from the [[Bosnian War#1995|1995 Bosnian Conflict]].&lt;ref&gt;This example developed from that described in [[Rupert Smith|Smith R]], Tait A, Howard N (1999) [http://www.decisionmechanics.com/wp-content/uploads/2009/11/warandpeace.pdf Confrontations in War and Peace]. ''Proceedings of the 6th international Command and Control Research and Technology Symposium'', U.S. Naval Academy, Annapolis, Maryland, 19–20 June 2001&lt;/ref&gt; This represents an interaction between the Bosnian Serbs and the United Nations forces over the safe areas. The [[Bosnian Serbs]] had [[Bosniak]] enclaves surrounded and were threatening to attack.

Each side had a position as to what they wanted to happen:

The Bosnian Serbs wanted (see 4th column):
* To be able to attack the enclaves
* NOT to withdraw their heavy weapons from the enclaves
* For the UN NOT to use air strikes
The UN wanted (See 5th column):
* The Bosnian Serbs NOT to attack the enclaves
* The Bosnian Serbs to withdraw their heavy weapons
* The Bosnian Serbs NOT to take hostages.
If no further changes were made then what the sides were saying would happen was (see 1st column):
*The Bosnian Serbs said they would attack the enclaves
*The Bosnian Serbs said they would NOT withdraw their heavy weapons
*The Bosnian Serbs said they would take hostages if the UN uses air strikes
*The UN said it would initiate air strikes.  However the Bosnian Serbs DID NOT BELIEVE them. (Hence the question mark on the Card Table).

Confrontation analysis then specifies a number of precisely defined ''dilemmas''&lt;ref name="dilemm"/&gt; that occur to the parties following from the structure of the card tables.  It states that motivated by the desire to eliminate these dilemmas, the parties involved will CHANGE THE CARD TABLE, to eliminate their problem.

In the situation at the start the Bosnian Serbs have no dilemmas, but the UN has four. It has three ''persuasion dilemmas''&lt;ref name="pd"&gt;See [http://www.dilemmasgalore.com/forum/viewtopic.php?f=15&amp;t=32 definition of Persuasion Dilemma]&lt;/ref&gt; in that the Bosnian Serbs are not going to do the three things they want them to (not attack the enclaves, withdraw the heavy weapons and not take hostages). It also has a ''rejection dilemma''&lt;ref name="rd"&gt;See [http://www.dilemmasgalore.com/forum/viewtopic.php?f=15&amp;t=40 definition of Rejection Dilemma]&lt;/ref&gt; in that the Bosnian Serbs do not believe they will actually use the air strikes, as they think the UN will submit to their position, for fear of having hostages taken.

Faced with these dilemmas, the UN modified the card table to eliminate its dilemmas.  It took two actions:

Firstly, it withdrew its forces from the positions where they were vulnerable to being taken hostage.  This action eliminated the Bosnian Serbs' option (card) of taking hostages.

[[Image:BosniaConfrontation2.JPG|thumb|x250px|right|Second Card Table:&lt;ref name="ct"/&gt; The UN eliminated the Bosnian "hostage" card and brought in an additional, credible "Artillery" card, changing the situation in their favour: The Bosnian Serbs now have two ''persuasion dilemmas''&lt;ref name="pd"/&gt; and two ''rejection dilemmas''&lt;ref name="rd"/&gt;]]
Secondly, with the addition of the [[Rapid Reaction Force]], and in particular its artillery the UN had an additional capability to engage Bosnian Serb weapons; they added the card "Use artillery against Bosnian Serbs". Because of this, the UN's threat of air strikes became more credible.  The situation changed to that of the Second Card Table:

The Bosnian Serbs wanted (see 4th column):
* To be able to attack the enclaves
* NOT to withdraw heavy weapons from the enclaves
* For the UN NOT to use air strikes
* For the UN NOT to use artillery
The UN wanted (See 5th column):
* The Bosnian Serbs NOT to attack the enclaves
* The Bosnian Serbs to withdraw their heavy weapons
If no further changes were made then what the sides were saying would happen was (see 1st column):
*The Bosnian Serbs said they would attack the enclaves, but the UN did not believe them.
*The Bosnian Serbs said they would NOT withdraw their heavy weapons, but the UN did not believe them.
*The UN said it would use artillery.  The Bosnian Serbs believed this.
*The UN said it would use air strikes.  This time, however, the Bosnian Serbs believed them.
{{clear|right}}

[[Image:BosniaConfrontation3.JPG|thumb|x250px|right|Final Card Table:&lt;ref name="ct"/&gt; The final situation. The Bosnian Serbs modified their position to eliminate their dilemmas. This involved accepting their initial goals as unobtainable]]
Faced with this new situation, the Bosnian Serbs modified their position to accept the UN proposal.  The final table was an agreement as shown in the Final Card table (see thumbnail and picture).

Confrontation analysis does not necessarily produce a win-win solution (although end states are more likely to remain stable if they do); however, the word ''confrontation'' should not necessarily imply that any negotiations should be carried out in an aggressive way.

The ''card tables'' or are isomorphic to [[game theory]] models, but are not built with the aim of finding a ''solution''. Instead, the aim is to find the dilemmas facing characters and so help to predict how they will change the table itself. Such prediction requires not only analysis of the model and its dilemmas, but also exploration of the reality outside the model; without this it is impossible to decide which ways of changing the model in order to eliminate dilemmas might be rationalized by the characters.

Sometimes analysis of the ticks and crosses can be supported by values showing the payoff to each of the parties.&lt;ref&gt;See [http://www.decisionworkshops.com/#/the-tables-in-a-decision-works/4557003218 understanding the tables used in confrontation analysis]&lt;/ref&gt;

==References==
{{reflist|3}}

== External links==
* [http://www.dilemmasgalore.com Dilemmas Galore] – A user discussion group.  Deals with applications of Confrontation analysis to current politics, military campaigns, business problems, psychology, etc. Also contains a good introduction and glossary of the terms used in Confrontation Analysis.
*[http://www.decisionworkshops.com/dilemma-explorer/4581290653 Dilemma Explorer] - A software application to do Confrontation Analysis
*[http://www.ideasciences.com/products/confrontationmanager/index.php Confrontation Manager] — A software application using an earlier version of Confrontation Analysis.
*[http://www.decisionmechanics.com/decision-making-software/confronteer/ Confronteer] an iPhone app to do Confrontation Analysis.
* N. Howard, '[http://www.dodccrp.org/files/Howard_Confrontation.pdf Confrontation Analysis: How to win operations other than war]', CCRP Publications, 1999.
* P. Bennett, J. Bryant and N. Howard, 'Drama Theory and Confrontation Analysis' — can be found (along with other recent PSM methods) in: J. V. Rosenhead and J. Mingers (eds) Rational Analysis for a Problematic World Revisited: problem structuring methods for complexity, uncertainty and conflict, Wiley, 2001.
* J. Bryant, The Six Dilemmas of Collaboration: inter-organisational relationships as drama, Wiley, 2003.
* N. Howard, [http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=9719 Paradoxes of Rationality]', MIT Press, 1971.
* [http://www.decisionworkshops.com/#/i-structure/4548609042 How to structure disputes using Confrontation Analysis] contains an illustrated explanation of Confrontation Analysis.
* [http://www.ideasciences.com/library/papers/speed.pdf Speed Confrontation Management] a brief "How to" manual on doing Confrontation Analysis without using an Options Table.

{{Game_theory}}
{{Use British English|date=December 2011}}
[[Category:Formal sciences]]
[[Category:Game theory]]
[[Category:Operations research]]
[[Category:Problem structuring methods]]</text>
      <sha1>ndpxh45ontqc9wna62hqtlmyld4qulm</sha1>
    </revision>
  </page>
  <page>
    <title>Craps principle</title>
    <ns>0</ns>
    <id>5213404</id>
    <revision>
      <id>807274848</id>
      <parentid>807274124</parentid>
      <timestamp>2017-10-27T00:05:55Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* top */ clarification</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5347">In [[probability theory]], the '''craps principle''' is a theorem about [[Event (probability theory)|event]] [[probabilities]] under repeated [[Independent and identically-distributed random variables|iid]] trials. Let &lt;math&gt;E_1&lt;/math&gt; and &lt;math&gt;E_2&lt;/math&gt; denote two [[mutually exclusive]] events which might occur on a given trial. Then the probability that &lt;math&gt;E_1&lt;/math&gt; occurs before &lt;math&gt;E_2&lt;/math&gt; equals the [[conditional probability]] that &lt;math&gt;E_1&lt;/math&gt; occurs given that &lt;math&gt;E_1&lt;/math&gt; or &lt;math&gt;E_2&lt;/math&gt; occur on the next trial, which is

:&lt;math&gt;\operatorname{P}[ E_1 \, \, \text{before}\,\, E_2]=\operatorname{P}\left[E_1\mid E_1\cup E_2\right]=\frac{\operatorname{P}[E_1]}{\operatorname{P}[E_1]+\operatorname{P}[E_2]}&lt;/math&gt;

The events &lt;math&gt;E_1&lt;/math&gt; and &lt;math&gt;E_2&lt;/math&gt; need not be [[collectively exhaustive]] (if they are, the result is trivial).&lt;ref name="stat_TheC"&gt;{{Cite web| title = The Craps principle 10/16| author = Susan Holmes| work = statweb.stanford.edu| date = 1998-12-07| accessdate = 2016-03-17| url = http://statweb.stanford.edu/~susan/courses/s116/node63.html}}&lt;/ref&gt;&lt;ref name="Ouellette2010"&gt;{{cite book|author=Jennifer Ouellette|title=The Calculus Diaries: How Math Can Help You Lose Weight, Win in Vegas, and Survive a Zombie Apocalypse|url=https://books.google.com/books?id=fQzJoqBwtT4C&amp;pg=PT50|date=31 August 2010|publisher=Penguin Publishing Group|isbn=978-1-101-45903-4|pages=50–}}&lt;/ref&gt;

==Proof==
Let &lt;math&gt;A&lt;/math&gt; be the event that &lt;math&gt;E_1&lt;/math&gt; occurs before &lt;math&gt;E_2&lt;/math&gt;. Let &lt;math&gt;B&lt;/math&gt; be the event that neither &lt;math&gt;E_1&lt;/math&gt; nor &lt;math&gt;E_2&lt;/math&gt; occurs on a given trial. Since &lt;math&gt;B&lt;/math&gt;, &lt;math&gt;E_1&lt;/math&gt; and &lt;math&gt;E_2&lt;/math&gt; are [[mutually exclusive]] and [[collectively exhaustive]] for the first trial, we have

:&lt;math&gt; \operatorname{P}(A) = \operatorname{P}(E_1)\operatorname{P}(A \mid E_1) + \operatorname{P}(E_2)\operatorname{P}(A \mid E_2) + \operatorname{P}(B) \operatorname{P}(A \mid B) = \operatorname{P}(E_1) + \operatorname{P}(B) \operatorname{P}(A \mid B)&lt;/math&gt;

and &lt;math&gt;\operatorname{P}(B) = 1 - \operatorname{P}(E_1) - \operatorname{P}(E_2)&lt;/math&gt;. 
Since the trials are i.i.d., we have &lt;math&gt;\operatorname{P}(A \mid B) = \operatorname{P}(A)&lt;/math&gt;. Using &lt;math&gt;\operatorname{P}(A|E_1)=1,\quad \operatorname{P}(A|E_2)=0&lt;/math&gt; and solving the displayed equation for &lt;math&gt;\operatorname{P}(A)&lt;/math&gt; gives the formula 
:&lt;math&gt;\operatorname{P}(A) = \frac{\operatorname{P}(E_1)}{\operatorname{P}(E_1)+\operatorname{P}(E_2)}&lt;/math&gt;.

==Application==

If the trials are repetitions of a game between two players, and the events are

:&lt;math&gt;E_1:\mathrm{ player\ 1\ wins}&lt;/math&gt;
:&lt;math&gt;E_2:\mathrm{ player\ 2\ wins}&lt;/math&gt;

then the craps principle gives the respective conditional probabilities of each player winning a certain repetition, given that someone wins (i.e., given that a [[draw (tie)|draw]] does not occur). In fact, the result is only affected by the relative marginal probabilities of winning &lt;math&gt;\operatorname{P}[E_1]&lt;/math&gt; and &lt;math&gt;\operatorname{P}[E_2]&lt;/math&gt; ; in particular, the probability of a draw is irrelevant.

===Stopping===
If the game is played repeatedly until someone wins, then the conditional probability above is the probability that the player wins the game. This is illustrated below for the original game of [[craps]], using an alternative proof.

==Craps example==
If the game being played is [[craps]], then this principle can greatly simplify the computation of the probability of winning in a certain scenario. Specifically, if the first roll is a 4, 5, 6, 8, 9, or 10, then the dice are repeatedly re-rolled until one of two events occurs:
:&lt;math&gt;E_1:\text{ the original roll (called ‘the point’) is rolled (a win) }&lt;/math&gt;
:&lt;math&gt;E_2:\text{ a 7 is rolled (a loss) }&lt;/math&gt;

Since &lt;math&gt;E_1&lt;/math&gt; and &lt;math&gt;E_2&lt;/math&gt; are mutually exclusive, the craps principle applies. For example, if the original roll was a 4, then the probability of winning is

:&lt;math&gt;\frac{3/36}{3/36 + 6/36}=\frac{1}{3}&lt;/math&gt;

This avoids having to sum the [[infinite series]] corresponding to all the possible outcomes:

:&lt;math&gt;\sum_{i=0}^{\infty}\operatorname{P}[\text{first i rolls are ties,}(i+1)^{\text{th}}\text{roll is ‘the point’}]&lt;/math&gt;

Mathematically, we can express the probability of rolling &lt;math&gt;i&lt;/math&gt; ties followed by rolling the point:

:&lt;math&gt;\operatorname{P}[\text{first i rolls are ties, }(i+1)^{\text{th}} \text{roll is ‘the point’}]
 = (1-\operatorname{P}[E_1]-\operatorname{P}[E_2])^i\operatorname{P}[E_1]
&lt;/math&gt;

The summation becomes an infinite [[geometric series]]:

:&lt;math&gt;\sum_{i=0}^{\infty} (1-\operatorname{P}[E_1]-\operatorname{P}[E_2])^i\operatorname{P}[E_1]
= \operatorname{P}[E_1] \sum_{i=0}^{\infty} (1-\operatorname{P}[E_1]-\operatorname{P}[E_2])^i
&lt;/math&gt;

::&lt;math&gt; = \frac{\operatorname{P}[E_1]}{1-(1-\operatorname{P}[E_1]-\operatorname{P}[E_2])}
= \frac{\operatorname{P}[E_1]}{\operatorname{P}[E_1]+\operatorname{P}[E_2]}
&lt;/math&gt;

which agrees with the earlier result.

==References==
{{reflist}}

===Notes===
*{{cite book |author=Pitman, Jim |title=Probability |publisher=Springer-Verlag |location=Berlin |year=1993 |pages= |isbn=0-387-97974-3 |oclc= |doi=}}

{{Craps}}

[[Category:Statistical theorems]]
[[Category:Probability theorems]]
[[Category:Statistical principles]]</text>
      <sha1>ogp0fom7e07vvq3onfgijn9f1zorg3g</sha1>
    </revision>
  </page>
  <page>
    <title>Ermelinda DeLaViña</title>
    <ns>0</ns>
    <id>56706426</id>
    <revision>
      <id>843601751</id>
      <parentid>828074737</parentid>
      <timestamp>2018-05-30T06:23:40Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3548">'''Ermelinda DeLaViña''' is a [[Hispanic and Latino Americans|Hispanic American]] mathematician specializing in [[graph theory]].{{r|sacnas}} One of her results in this area is related to an [[Inequality (mathematics)|inequality]] showing that every [[undirected graph]] has an [[independent set (graph theory)|independent set]] that is at least as large as its [[Distance (graph theory)|radius]]; DeLaViña showed that the graphs with no larger independent set always contain a [[Hamiltonian path]].{{r|cgt}}
She is a professor in the Computer and Mathematical Sciences Department of the [[University of Houston–Downtown]], where she is also Associate Dean of the College of Science and Technology.{{r|cv}}

DeLaViña grew up in a working-class family in Texas, with roots stretching back for five generations there. Her parents came from [[Bishop, Texas]], but raised her in [[Houston]]. Inspired by a 9th-grade algebra teacher, she aimed for a college education despite the discouragement of her school counselors. She started her undergraduate studies at the [[University of Houston]], but dropped out after one term, and after working for two years began again at the [[University of Texas–Pan American]],{{r|sacnas}} where she graduated with a bachelor's degree in mathematics and a minor in computer science in 1989,{{r|cv}} becoming the first in her family with a college degree.{{r|brave}}
She returned to graduate school at the University of Houston and completed a Ph.D. in mathematics there in 1997. Her [[doctoral supervisor]] was [[Siemion Fajtlowicz]], with whom she worked on the [[Graffiti (program)|Graffiti]] computer program for automatically formulating conjectures in graph theory.{{r|sacnas|cv|mgp}}

After completing her doctorate, DeLaViña became an assistant professor at the University of Houston–Downtown. She was promoted to full professor there in 2010, and became associate dean in 2012.{{r|cv}}

==References==
{{reflist|refs=

&lt;ref name=brave&gt;{{citation|magazine=Computerworld|date=September 27, 2004|title=IT Careers: Being Brave Part of Professional Development|page=53|url=https://books.google.com/books?id=xDAnRoP05PgC&amp;pg=PA53}}&lt;/ref&gt;

&lt;ref name=cgt&gt;{{citation|title=Chromatic Graph Theory|series=Discrete Mathematics and Its Applications|first1=Gary|last1=Chartrand|author1-link=Gary Chartrand|first2=Ping|last2=Zhang|author2-link=Ping Zhang (graph theorist)|publisher=CRC Press|year=2008|isbn=9781584888017|page=100|url=https://books.google.com/books?id=_l4CJq46MXwC&amp;pg=PA100}}&lt;/ref&gt;

&lt;ref name=cv&gt;{{citation|url=http://cms.dt.uh.edu/faculty/delavinae/currentcv.html|title=Curriculum vitae|accessdate=2018-02-27}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=12222}}&lt;/ref&gt;

&lt;ref name=sacnas&gt;{{citation|title=Dr. Ermelinda DeLaViña - Mathematician|url=http://bio.sacnas.org/biography/Biography.asp?mem=155&amp;type=2|work=SACNAS Biography Project|publisher=[[Society for the Advancement of Chicanos/Hispanics and Native Americans in Science]]|accessdate=2018-02-27}}&lt;/ref&gt;

}}

==External links==
*[http://cms.dt.uh.edu/faculty/delavinae/ Home page]

{{Authority control}}

{{DEFAULTSORT:Delavina, Ermelinda}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:American women mathematicians]]
[[Category:Graph theorists]]
[[Category:University of Texas–Pan American alumni]]
[[Category:University of Houston alumni]]
[[Category:University of Houston–Downtown faculty]]</text>
      <sha1>c8ydjutx6m306u43fy8f0qkudn8qesl</sha1>
    </revision>
  </page>
  <page>
    <title>Extended static checking</title>
    <ns>0</ns>
    <id>27989949</id>
    <revision>
      <id>786179338</id>
      <parentid>708497896</parentid>
      <timestamp>2017-06-17T20:01:30Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>[[James B. Saxe]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6775">'''Extended static checking''' ('''ESC''') is a collective name for a range of techniques for [[static code analysis|statically checking]] the correctness of various program constraints.&lt;ref&gt;C. Flanagan, K.R.M. Leino, M. Lillibridge, G. Nelson, [[James B. Saxe|J. B. Saxe]] and R. Stata. "Extended static checking for Java". In ''Proceedings of the Conference on Programming Language Design and Implementation'', pages 234-245, 2002. doi: http://doi.acm.org/10.1145/512529.512558&lt;/ref&gt; ESC can be thought of as an extended form of [[type checking]]. As with type checking, ESC is performed automatically at [[compile time]] (i.e. without human intervention). This distinguishes it from more general approaches to the [[formal verification]] of software, which typically rely on human-generated proofs. Furthermore, it promotes practicality over soundness, in that it aims to dramatically reduce the number of ''false positives'' (overestimated errors that are not real errors, that is, ESC over strictness) at the cost of introducing some ''false negatives'' (real ESC underestimation error, but that need no programmer's attention, or are not targeted by ESC).&lt;ref name=GNESCUWCSC /&gt;&lt;ref&gt;Calysto: Scalable and Precise Extended Static Checking, Domagoj Babic and Alan J. Hu. In Proceedings of the International Conference on Software Engineering (ICSE), 2008. {{DOI|10.1145/1368088.1368118}}&lt;/ref&gt; ESC can identify a range of errors which are currently outside the scope of a type checker, including [[division by zero]], [[bounds checking|array out of bounds]], [[integer overflow]] and [[Null pointer|null dereferences]].

The techniques used in extended static checking come from various fields of [[Computer Science]], including [[static program analysis]], [[symbolic simulation]], [[model checking]], [[abstract interpretation]], [[satisfiability modulo theories|SAT solving]] and [[automated theorem proving]] and [[type checking]]. Extended static checking is generally performed only at an intraprocedural level (rather than an interprocedural one) in order to scale to large programs.&lt;ref name=GNESCUWCSC&gt;{{Cite web
| title = Extended Static Checking
| work = UWTV
| accessdate = 2012-02-01
| url = http://stage.uwtv.org/video/player.aspx?mediaid=1577083988
}}&lt;/ref&gt; Furthermore, extended static checking aims to report errors by exploiting user-supplied specifications, in the form of [[precondition|pre-]] and [[postcondition|post-conditions]], [[loop invariant]]s and [[class invariant]]s.

Extended static checkers typically operate by propagating [[predicate transformer semantics#Strongest postcondition|strongest postconditions]] (resp. [[predicate transformer semantics#Weakest preconditions|weakest preconditions]]) intraprocedurally through a method starting from the precondition (resp. postcondition). At each point during this process an intermediate condition is generated that captures what is known at that program point. This is combined with the necessary conditions of the program statement at that point to form a ''verification condition''. An example of this is a statement involving a division, whose necessary condition is that the [[divisor]] be non-zero. The verification condition arising from this effectively states: ''given the intermediate condition at this point, it must follow that the divisor is non-zero''. All verification conditions must be shown to be false (hence correct by means of [[excluded third]]) in order for a method to pass extended static checking (or "unable to find more errors"). Typically, some form of automated theorem prover is used to discharge verification conditions.

Extended Static Checking was pioneered in ESC/Modula-3&lt;ref&gt;An extended Static Checker for Modula-3, K. Rustan M. Leino and Greg Nelson. In Proceedings of the Conference on Compiler Construction, pages 302-305, 1998. {{DOI|10.1007/BFb0026418}}&lt;/ref&gt; and, later, [[ESC/Java]]. Its roots originate from more simplistic static checking techniques, such as static debugging&lt;ref&gt;Catching bugs in the web of program invariants, C. Flanagan, M. Flatt, S. Krishnamurthi. S. Weirich, and M. Felleisen, pages 23-32, 1996, dpi: http://doi.acm.org/10.1145/249069.231387&lt;/ref&gt; or [[Lint (software)]] and [[FindBugs]]. A number of other languages have adopted ESC, including [[Spec Sharp|Spec#]] and [[SPARK (programming language)|SPARKada]] and [[VHDL]] VSPEC. However, there is currently no widely used software programming language that provides extended static checking in its base development environment.

== See also ==
*[[Java Modeling Language]] (JML)

== References ==
{{reflist}}

==Further reading==
*{{cite journal |author1=Cormac Flanagan |author2=K. Rustan M. Leino, Mark Lillibridge, Greg Nelson, James B. Saxe, Raymie Stata|year=2002|title=Extended static checking for Java |journal=Proceedings of the [[Conference on Programming Language Design and Implementation]] (PLDI)|page=234|doi=10.1145/512529.512558}}
*{{cite journal|last1=Babic|first1=Domagoj|first2=Alan J. |last2=Hu|year=2008|title=Calysto: Scalable and Precise Extended Static Checking|journal=Proceedings of the International Conference on Software Engineering (ICSE)|page=211|doi=10.1145/1368088.1368118}}
*{{cite journal|last=Chess|first=B.V.|year=2002|title=Improving computer security using extended static checking|journal=Proceedings of IEEE Symposium on Security and Privacy|pages=160–173|doi=10.1109/SECPRI.2002.1004369}}
*{{cite journal|last1=Rioux|first1=Frédéric|first2=Patrice |last2=Chalin|year=2006|title=Improving the Quality of Web-based Enterprise Applications with Extended Static Checking: A Case Study|journal=Electronic Notes in Theoretical Computer Science|volume=157|issue=2|pages=119–132|issn=1571-0661|doi=10.1016/j.entcs.2005.12.050}}
*{{cite journal|last1=James|first1=Perry R.|first2=Patrice |last2=Chalin|year=2009|title=Faster and More Complete Extended Static Checking for the Java Modeling Language|journal=Journal of Automated Reasoning|volume=44|issue=1–2|pages=145–174|issn=0168-7433|doi=10.1007/s10817-009-9134-9}}
*{{cite journal|last=Xu|first=Dana N.|year=2006|title=Extended static checking for haskell|journal=Proceedings of the ACM workshop on Haskell|page=48|doi=10.1145/1159842.1159849}}
*{{cite journal|last=Leino|first=K. Rustan M.|title=Extended Static Checking: A Ten-Year Perspective|journal=Informatics|volume=2000|pages=157–175|doi=10.1007/3-540-44577-3_11|year=2001}}
*{{cite journal|year=1998|title=Extended Static Checking|journal=Compaq SRC Research Report|issue=159|first1=David L. |last1=Detlefs |first2=K. Rustan M. |last2=Leino |first3=Greg |last3=Nelson |first4=James B. |last4=Saxe}}

{{DEFAULTSORT:Extended Static Checking}}
[[Category:Static program analysis tools]]
[[Category:Formal methods]]</text>
      <sha1>rf8p1afajfbutwi9f5v1p7s3a5wp1gp</sha1>
    </revision>
  </page>
  <page>
    <title>Fusion frame</title>
    <ns>0</ns>
    <id>38447249</id>
    <revision>
      <id>797707344</id>
      <parentid>732972828</parentid>
      <timestamp>2017-08-28T18:46:53Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[Wikipedia:Bots/Requests for approval/KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8830">{{Orphan|date=April 2013}}

In mathematics, a '''fusion frame''' of a [[vector space]] is a natural extension of a [[Frame of a vector space|frame]]. It is an additive construct of several, potentially "overlapping" frames. The motivation for this concept comes from the event that a [[Signal (electrical engineering)|signal]] can not be acquired by a single sensor alone (a constraint found by limitations of hardware or data throughput), rather the partial components of the signal must be collected via a network of sensors, and the partial signal representations are then ''fused'' into the complete signal.

By construction, fusion frames easily lend themselves to parallel or distributed processing&lt;ref name="DistProc"&gt;{{cite journal|last=Casazza|first=Peter G.|author2=Kutyniok, Gitta|author3=Li, Shidong|title=Fusion frames and distributed processing|journal=Applied and Computational Harmonic Analysis|year=2008|volume=25|issue=1|pages=114–132|doi=10.1016/j.acha.2007.10.001|url=https://dx.doi.org/10.1016/j.acha.2007.10.001}}&lt;/ref&gt; of sensor networks consisting of arbitrary overlapping sensor fields.

== Definition ==
Given a [[Hilbert space]] &lt;math&gt;\mathcal{H}&lt;/math&gt;, let &lt;math&gt;\{W_i\}_{i \in \mathcal{I}}&lt;/math&gt; be closed subspaces of &lt;math&gt;\mathcal{H}&lt;/math&gt;, where &lt;math&gt;\mathcal{I}&lt;/math&gt; is an index set. Let &lt;math&gt;\{ v_i \}_{i \in \mathcal{I}}&lt;/math&gt; be a set of positive scalar weights. Then &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; is a '''fusion frame''' of &lt;math&gt;\mathcal{H}&lt;/math&gt; if there exist constants &lt;math&gt;0 &lt; A \leq B&lt;\infty&lt;/math&gt; such that for all &lt;math&gt;f\in\mathcal{H}&lt;/math&gt; we have

&lt;math&gt;A\|f\|^2\leq\sum_{i\in\mathcal{I}}v_i^2\big\|P_{W_i}f\big\|^2\leq B\|f\|^2&lt;/math&gt;,

where &lt;math&gt;P_{W_i}&lt;/math&gt; denotes the [[Projection (linear algebra)#Orthogonal projection|orthogonal projection]] onto the subspace &lt;math&gt;W_i&lt;/math&gt;. The constants &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; are called lower and upper bound, respectively. When the lower and upper bounds are equal to each other, &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; becomes a &lt;math&gt;A&lt;/math&gt;-tight fusion frame. Furthermore, if &lt;math&gt;A=B=1&lt;/math&gt;, we can call &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; Parseval fusion frame.&lt;ref name="DistProc"/&gt;

Assume &lt;math&gt;\{f_{ij}\}_{i \in \mathcal{I}, j\in J_i}&lt;/math&gt; is a frame for &lt;math&gt;W_i&lt;/math&gt;. Then &lt;math&gt;\{ \left(W_i, v_i, \{f_{ij}\}_{j\in J_i} \right)\}_{i \in \mathcal{I}}&lt;/math&gt; is called a fusion frame system for &lt;math&gt;\mathcal{H}&lt;/math&gt;.&lt;ref name="DistProc"/&gt;

== Theorem for the relationship between fusion frames and global frames ==
Let &lt;math&gt;\{W_i\}_{i\in\mathcal{H}}&lt;/math&gt; be closed subspaces of &lt;math&gt;\mathcal{H}&lt;/math&gt; with positive weights &lt;math&gt;\{ v_i \}_{i \in \mathcal{I}}&lt;/math&gt;. Suppose &lt;math&gt;\{f_{ij}\}_{i \in \mathcal{I}, j\in J_i}&lt;/math&gt; is a frame for &lt;math&gt;W_i&lt;/math&gt; with frame bounds &lt;math&gt;C_i&lt;/math&gt; and &lt;math&gt;D_i&lt;/math&gt;. Let &lt;math&gt;C=inf_{i\in\mathcal{I}}C_i&lt;/math&gt; and &lt;math&gt;D=inf_{i\in\mathcal{I}}D_i&lt;/math&gt;, which satisfy that &lt;math&gt;0&lt;C\leq D&lt;\infty&lt;/math&gt;. Then &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; is a fusion frame of &lt;math&gt;\mathcal{H}&lt;/math&gt; if and only if &lt;math&gt;\{v_if_{ij}\}_{i \in \mathcal{I}, j\in J_i}&lt;/math&gt; is a frame of &lt;math&gt;\mathcal{H}&lt;/math&gt;.

Additionally, if &lt;math&gt;\{ \left(W_i, v_i, \{f_{ij}\}_{j\in J_i} \right)\}_{i \in \mathcal{I}}&lt;/math&gt; is called a fusion frame system for &lt;math&gt;\mathcal{H}&lt;/math&gt; with lower and upper bounds &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, then &lt;math&gt;\{v_if_{ij}\}_{i \in \mathcal{I}, j\in J_i}&lt;/math&gt; is a frame of &lt;math&gt;\mathcal{H}&lt;/math&gt; with lower and upper bounds &lt;math&gt;AC&lt;/math&gt; and &lt;math&gt;BD&lt;/math&gt;. And if &lt;math&gt;\{v_if_{ij}\}_{i \in \mathcal{I}, j\in J_i}&lt;/math&gt; is a frame of &lt;math&gt;\mathcal{H}&lt;/math&gt; with lower and upper bounds &lt;math&gt;E&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt;, then &lt;math&gt;\{ \left(W_i, v_i, \{f_{ij}\}_{j\in J_i} \right)\}_{i \in \mathcal{I}}&lt;/math&gt; is called a fusion frame system for &lt;math&gt;\mathcal{H}&lt;/math&gt; with lower and upper bounds &lt;math&gt;E/D&lt;/math&gt; and &lt;math&gt;F/C&lt;/math&gt;.&lt;ref name="FrameSubspace"&gt;{{cite journal|last1=Casazza|first1=P.G.|last2=Kutyniok|first2=G.|title=Frames of subspaces|journal=Wavelets, Frames and Operator Theory|date=2004|volume=345|pages=87–113}}&lt;/ref&gt;

== Local frame representation ==
Let &lt;math&gt;W\subset\mathcal{H}&lt;/math&gt; be a closed subspace, and let &lt;math&gt;\{x_n\}&lt;/math&gt; be an [[orthonormal basis]] of &lt;math&gt;W&lt;/math&gt;. Then for all &lt;math&gt;f\in\mathcal{H}&lt;/math&gt;, the orthogonal projection of &lt;math&gt;f&lt;/math&gt; onto &lt;math&gt;W&lt;/math&gt; is given by &lt;math&gt;P_Wf = \sum\langle f,x_n\rangle x_n&lt;/math&gt;.&lt;ref&gt;{{cite book|last=Christensen|first=Ole|title=An introduction to frames and Riesz bases|year=2003|publisher=Birkhäuser|location=Boston [u.a.]|isbn=0817642951|page=8}}&lt;/ref&gt;

We can also express the orthogonal projection of &lt;math&gt;f&lt;/math&gt; onto &lt;math&gt;W&lt;/math&gt; in terms of given local frame &lt;math&gt;\{f_k\}&lt;/math&gt; of &lt;math&gt;W&lt;/math&gt;,

&lt;math&gt;P_Wf = \sum\langle f,f_k\rangle \tilde{f}_k&lt;/math&gt;,

where &lt;math&gt;\{\tilde{f}_k\}&lt;/math&gt; is a dual frame of the local frame &lt;math&gt;\{f_k\}&lt;/math&gt;.&lt;ref name="DistProc"/&gt;

== Definition of fusion frame operator ==
Let &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; be a fusion frame for &lt;math&gt;\mathcal{H}&lt;/math&gt;. Let &lt;math&gt;\{\sum\bigoplus W_i\}_{l_2}&lt;/math&gt; be representation space for projection. The analysis operator &lt;math&gt;T_W: \mathcal{H}\rightarrow\{\sum\bigoplus W_i\}_{l_2}&lt;/math&gt; is defined by

&lt;math&gt;T_W\left(f \right)=\{v_iP_{W_i}\left(f \right)\}_{i\in\mathcal{I}}&lt;/math&gt;.

Then The adjoint operator &lt;math&gt;T^{\ast}_W: \{\sum\bigoplus W_i\}_{l_2}\rightarrow \mathcal{H}&lt;/math&gt;, which we call the synthesis operator, is given by

&lt;math&gt;T^{\ast}_W\left(g \right)=\sum v_if_i&lt;/math&gt;,

where &lt;math&gt;g=\{f_i\}_{i\in\mathcal{I}}\in\{\sum\bigoplus W_i\}_{l_2}&lt;/math&gt;.

The fusion frame operator &lt;math&gt;S_W: \mathcal{H}\rightarrow\mathcal{H}&lt;/math&gt; is defined by

&lt;math&gt;S_W\left(f \right)=T^{\ast}_WT_W\left(f \right)=\sum v^{2}_iP_{W_i}\left(f \right)&lt;/math&gt;.&lt;ref name="FrameSubspace"/&gt;

== Properties of fusion frame operator ==
Given the lower and upper bounds of the fusion frame &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt;, &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;,  the fusion frame operator &lt;math&gt;S_W&lt;/math&gt; can be bounded by

&lt;math&gt;AI\leq S_W\leq BI&lt;/math&gt;,
where &lt;math&gt;I&lt;/math&gt; is the identity operator. Therefore, the fusion frame operator &lt;math&gt;S_W&lt;/math&gt; is positive and invertible.&lt;ref name="FrameSubspace"/&gt;

== Representation of fusion frame operator ==
Given a fusion frame system &lt;math&gt;\{ \left(W_i, v_i, \mathcal{F}_i\right)\}_{i \in \mathcal{I}}&lt;/math&gt; for &lt;math&gt;\mathcal{H}&lt;/math&gt;, where &lt;math&gt;\mathcal{F}_i=\{f_{ij}\}_{j\in J_i} &lt;/math&gt;, and &lt;math&gt;\tilde{\mathcal{F}}_i=\{\tilde{f}_{ij}\}_{j\in J_i} &lt;/math&gt;, which is a dual frame for &lt;math&gt;\mathcal{F}_i&lt;/math&gt;, the fusion frame operator &lt;math&gt;S_W&lt;/math&gt; can be expressed as

&lt;math&gt;S_W=\sum v^2_iT^{\ast}_{\tilde{\mathcal{F}}_i}T_{\mathcal{F}_i}=\sum v^2_iT^{\ast}_{\mathcal{F}_i}T_{\tilde{\mathcal{F}}_i}&lt;/math&gt;,

where &lt;math&gt;T_{\mathcal{F}_i}&lt;/math&gt;, &lt;math&gt;T_{\tilde{\mathcal{F}}_i}&lt;/math&gt; are analysis operators for &lt;math&gt;\mathcal{F}_i&lt;/math&gt; and &lt;math&gt;\tilde{\mathcal{F}}_i&lt;/math&gt; respectively, and &lt;math&gt;T^{\ast}_{\mathcal{F}_i}&lt;/math&gt;, &lt;math&gt;T^{\ast}_{\tilde{\mathcal{F}}_i}&lt;/math&gt; are synthesis operators for &lt;math&gt;\mathcal{F}_i&lt;/math&gt; and &lt;math&gt;\tilde{\mathcal{F}}_i&lt;/math&gt; respectively.&lt;ref name="DistProc"/&gt;

For finite frames (i.e., &lt;math&gt;\dim\mathcal H =: N &lt; \infty&lt;/math&gt; and &lt;math&gt;|\mathcal I|&lt;\infty&lt;/math&gt;), the fusion frame operator can be constructed with a matrix.&lt;ref name="DistProc"/&gt; Let &lt;math&gt;\{ W_i, v_i \}_{i \in \mathcal{I}}&lt;/math&gt; be a fusion frame for &lt;math&gt;\mathcal{H}_N&lt;/math&gt;, and let &lt;math&gt;\{ f_{ij} \}_{j \in \mathcal{J}_i}&lt;/math&gt; be a frame for the subspace &lt;math&gt;W_i&lt;/math&gt; and &lt;math&gt;J_i&lt;/math&gt; an index set for each &lt;math&gt;i\in\mathcal{I}&lt;/math&gt;. With

&lt;math&gt;F_i = \begin{bmatrix} \vdots &amp; \vdots &amp; &amp; \vdots \\ f_{i1} &amp; f_{i2} &amp; \cdots &amp; f_{i|J_i|} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\\end{bmatrix}_{N \times |J_i|}&lt;/math&gt;

and

&lt;math&gt;\tilde{F}_i = \begin{bmatrix} \vdots &amp; \vdots &amp; &amp; \vdots \\ \tilde{f}_{i1} &amp; \tilde{f}_{i2} &amp; \cdots &amp; \tilde{f}_{i|J_i|} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\\end{bmatrix}_{N \times |J_i|},&lt;/math&gt;

where &lt;math&gt;\tilde{f}_{ij}&lt;/math&gt; is the canonical [[Frame of a vector space#Dual frames|dual frame]] of &lt;math&gt;f_{ij}&lt;/math&gt;, the fusion frame operator &lt;math&gt;S: \mathcal{H}\to\mathcal{H}&lt;/math&gt; is given by

&lt;math&gt;S = \sum_{i\in\mathcal{I}}v_i^2 F_i \tilde{F}_i^T&lt;/math&gt;.

The fusion frame operator &lt;math&gt;S&lt;/math&gt; is then given by an &lt;math&gt;N\times N&lt;/math&gt; matrix.

==References==
{{Reflist}}

== External links ==
* [http://www.fusionframe.org/ Fusion Frames]

== See also ==
* [[Hilbert space]]
* [[Frame (linear algebra)]]

[[Category:Linear algebra]]
[[Category:Functional analysis]]</text>
      <sha1>5oqvbb03w46hxxr33q25e03de7dmjce</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized linear model</title>
    <ns>0</ns>
    <id>747122</id>
    <revision>
      <id>870782032</id>
      <parentid>870781310</parentid>
      <timestamp>2018-11-26T23:34:20Z</timestamp>
      <contributor>
        <ip>128.227.164.183</ip>
      </contributor>
      <comment>Undid revision 870781310 by [[Special:Contributions/128.227.164.183|128.227.164.183]] ([[User talk:128.227.164.183|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30523">{{distinguish|general linear model|generalized least squares}}
{{Regression bar}}
In [[statistics]], the '''generalized linear model''' ('''GLM''') is a flexible generalization of ordinary [[linear regression]] that allows for [[response variable]]s that have error distribution models other than a [[normal distribution]].  The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a ''link function'' and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.

Generalized linear models were formulated by [[John Nelder]] and [[Robert Wedderburn (statistician)|Robert Wedderburn]] as a way of unifying various other statistical models, including [[linear regression]], [[logistic regression]] and [[Poisson regression]].&lt;ref&gt;{{cite journal | last= Nelder | first = John |authorlink = John Nelder | first2 = Robert |last2 = Wedderburn |authorlink2 = Robert Wedderburn (statistician) | title = Generalized Linear Models | year=1972 | journal = [[Journal of the Royal Statistical Society]]. Series A (General) | volume= 135 |issue=3 | pages=370–384 | doi= 10.2307/2344614 | publisher= Blackwell Publishing | jstor= 2344614 }}&lt;/ref&gt; They proposed an [[iteratively reweighted least squares]] [[iterative method|method]] for [[maximum likelihood]] estimation of the model parameters. Maximum-likelihood estimation remains popular and is the default method on many statistical computing packages.  Other approaches, including [[Bayesian statistics|Bayesian approaches]] and [[least squares]] fits to [[variance-stabilizing transformation|variance stabilized]] responses, have been developed.

==Intuition==
Ordinary linear regression predicts the [[expected value]] of a given unknown quantity (the ''response variable'', a [[random variable]]) as a [[linear combination]] of a set of observed values (''predictors'').  This implies that a constant change in a predictor leads to a constant change in the response variable (i.e. a ''linear-response model'').  This is appropriate when the response variable has a [[normal distribution]] (intuitively, when a response variable can vary essentially indefinitely in either direction with no fixed "zero value", or more generally for any quantity that only varies by a relatively small amount, e.g. human heights).

However, these assumptions are inappropriate for some types of response variables.  For example, in cases where the response variable is expected to be always positive and varying over a wide range, constant input changes lead to geometrically varying, rather than constantly varying, output changes. As an example, a prediction model might predict that 10 degree temperature decrease would lead to 1,000 fewer people visiting the beach is unlikely to generalize well over both small beaches (e.g. those where the expected attendance was 50 at a particular temperature) and large beaches (e.g. those where the expected attendance was 10,000 at a low temperature).  The problem with this kind of prediction model would imply a temperature drop of 10 degrees would lead to 1,000 fewer people visiting the beach, a beach whose expected attendance was 50 at a higher temperature would now be predicted to have the impossible attendance value of −950. Logically, a more realistic model would instead predict a constant ''rate'' of increased beach attendance (e.g. an increase in 10 degrees leads to a doubling in beach attendance, and a drop in 10 degrees leads to a halving in attendance).  Such a model is termed an ''exponential-response model'' (or ''[[log-linear model]]'', since the [[logarithm]] of the response is predicted to vary linearly).

Similarly, a model that predicts a probability of making a yes/no choice (a [[Bernoulli distribution|Bernoulli variable]]) is even less suitable as a linear-response model, since probabilities are bounded on both ends (they must be between 0 and 1).  Imagine, for example, a model that predicts the likelihood of a given person going to the beach as a function of temperature.  A reasonable model might predict, for example, that a change in 10 degrees makes a person two times more or less likely to go to the beach.  But what does "twice as likely" mean in terms of a probability? It cannot literally mean to double the probability value (e.g. 50% becomes 100%, 75% becomes 150%, etc.).  Rather, it is the ''[[odds ratio|odds]]'' that are doubling: from 2:1 odds, to 4:1 odds, to 8:1 odds, etc. Such a model is a ''log-odds or [[Logistic regression|logistic]] model''.

Generalized linear models cover all these situations by allowing for response variables that have arbitrary distributions (rather than simply [[normal distribution]]s), and for an arbitrary function of the response variable (the ''link function'') to vary linearly with the predicted values (rather than assuming that the response itself must vary linearly).  For example, the case above of predicted number of beach attendees would typically be modeled with a [[Poisson distribution]] and a log link, while the case of predicted probability of beach attendance would typically be modeled with a [[Bernoulli distribution]] (or [[binomial distribution]], depending on exactly how the problem is phrased) and a log-odds (or ''[[logit]]'') link function.

==Overview==

In a generalized linear model (GLM), each outcome '''Y''' of the [[dependent variable]]s is assumed to be generated from a particular [[probability distribution|distribution]] in the [[exponential family]], a large range of [[probability distributions]] that includes the [[normal distribution|normal]], [[binomial distribution|binomial]], [[poisson distribution|Poisson]] and [[gamma distribution|gamma]] distributions, among others. The mean, '''''μ''''', of the distribution depends on the independent variables, '''X''', through:

: &lt;math&gt;\operatorname{E}(\mathbf{Y}) = \boldsymbol{\mu} = g^{-1}(\mathbf{X}\boldsymbol{\beta}) &lt;/math&gt;

where E('''Y''') is the [[expected value]] of '''Y'''; '''X''&amp;beta;''''' is the ''linear predictor'', a linear combination of unknown parameters '''''&amp;beta;'''''; ''g'' is the link function.

In this framework, the variance is typically a function, '''V''', of the mean:

:&lt;math&gt; \operatorname{Var}(\mathbf{Y}) = \operatorname{V}( \boldsymbol{\mu} ) = \operatorname{V}(g^{-1}(\mathbf{X}\boldsymbol{\beta})). &lt;/math&gt;

It is convenient if '''V''' follows from the exponential family distribution, but it may simply be that the variance is a function of the predicted value.

The unknown parameters, '''''β''''', are typically estimated with [[maximum likelihood]], maximum [[quasi-likelihood]], or [[Bayesian probability|Bayesian]] techniques.

== Model components ==

The GLM consists of three elements:
: 1. A probability distribution from the exponential family.
: 2. A linear predictor ''&amp;eta;'' = '''X''&amp;beta;''''' .
: 3. A link function ''g'' such that E('''Y''') = ''&amp;mu;'' = ''g''&lt;sup&gt;−1&lt;/sup&gt;(''&amp;eta;'').

=== Probability distribution ===
The '''overdispersed exponential family''' of distributions is a generalization of the [[exponential family]] and [[exponential dispersion model]] of distributions and includes those probability distributions, parameterized by &lt;math&gt;\boldsymbol\theta&lt;/math&gt; and &lt;math&gt;\tau&lt;/math&gt;, whose density functions ''f'' (or [[probability mass function]], for the case of a [[discrete distribution|discrete]] distribution) can be expressed in the form

: &lt;math&gt; f_Y(\mathbf{y} \mid \boldsymbol\theta, \tau) = h(\mathbf{y},\tau) \exp \left(\frac{\mathbf{b}(\boldsymbol\theta)^{\rm T}\mathbf{T}(y) - A(\boldsymbol\theta)} {d(\tau)} \right). \,\!&lt;/math&gt;

The ''dispersion parameter'', &lt;math&gt;\tau&lt;/math&gt;, typically is known and is usually related to the variance of the distribution.  The functions &lt;math&gt;h(\mathbf{y},\tau)&lt;/math&gt;, &lt;math&gt;\mathbf{b}(\boldsymbol\theta)&lt;/math&gt;, &lt;math&gt;\mathbf{T}(y)&lt;/math&gt;, &lt;math&gt;A(\boldsymbol\theta)&lt;/math&gt;, and &lt;math&gt;d(\tau)&lt;/math&gt; are known.  Many common distributions are in this family, including the normal, exponential, gamma, Poisson, Bernoulli, and (for fixed number of trials) binomial, multinomial, and negative binomial.

For scalar &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;\theta&lt;/math&gt;, this reduces to

: &lt;math&gt; f_Y(y \mid \theta, \tau) = h(y,\tau) \exp \left(\frac{b(\theta)T(y) - A(\theta)}{d(\tau)} \right). \,\!&lt;/math&gt;

&lt;math&gt;\boldsymbol\theta&lt;/math&gt; is related to the mean of the distribution.  If &lt;math&gt;\mathbf{b}(\boldsymbol\theta)&lt;/math&gt; is the identity function, then the distribution is said to be in [[canonical form]] (or ''natural form''). Note that any distribution can be converted to canonical form by rewriting &lt;math&gt;\boldsymbol\theta&lt;/math&gt; as &lt;math&gt;\boldsymbol\theta'&lt;/math&gt; and then applying the transformation &lt;math&gt;\boldsymbol\theta = \mathbf{b}(\boldsymbol\theta')&lt;/math&gt;.  It is always possible to convert &lt;math&gt;A(\boldsymbol\theta)&lt;/math&gt; in terms of the new parametrization, even if &lt;math&gt;\mathbf{b}(\boldsymbol\theta')&lt;/math&gt; is not a [[one-to-one function|one-to-one]] function; see comments in the page on the [[exponential family]]. If, in addition, &lt;math&gt;\mathbf{T}(y)&lt;/math&gt; is the identity and &lt;math&gt;\tau&lt;/math&gt; is known, then &lt;math&gt;\boldsymbol\theta&lt;/math&gt; is called the ''canonical parameter'' (or ''natural parameter'') and is related to the mean through

:&lt;math&gt; \boldsymbol\mu = \operatorname{E}(\mathbf{Y}) = \nabla A(\boldsymbol\theta). \,\!&lt;/math&gt;

For scalar &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;\theta&lt;/math&gt;, this reduces to

:&lt;math&gt; \mu = \operatorname{E}(Y) = A'(\theta). \,\!&lt;/math&gt;

Under this scenario, the variance of the distribution can be shown to be&lt;ref name="McCullagh1989Ch2"&gt;[[#McCullagh1989|McCullagh and Nelder (1989)]], chapter 2.&lt;/ref&gt;

:&lt;math&gt;\operatorname{Var}(\mathbf{Y}) = \nabla^2 A(\boldsymbol\theta) d(\tau). \,\!&lt;/math&gt;

For scalar &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;\theta&lt;/math&gt;, this reduces to

:&lt;math&gt;\operatorname{Var}(Y) = A''(\theta) d(\tau). \,\!&lt;/math&gt;

=== Linear predictor ===

The linear predictor is the quantity which incorporates the information about the independent variables into the model.  The symbol ''&amp;eta;'' ([[Greek alphabet|Greek]] "[[Eta (letter)|eta]]") denotes a linear predictor.  It is related to the [[expected value]] of the data through the link function.

''&amp;eta;'' is expressed as linear combinations (thus, "linear") of unknown parameters '''''β'''''.  The coefficients of the linear combination are represented as the matrix of independent variables '''X'''.  ''&amp;eta;'' can thus be expressed as

:&lt;math&gt; \eta = \mathbf{X}\boldsymbol{\beta}.\,&lt;/math&gt;

=== Link function ===

The link function provides the relationship between the linear predictor and the [[Expected value|mean]] of the distribution function.  There are many commonly used link functions, and their choice is informed by several considerations. There is always a well-defined ''canonical'' link function which is derived from the exponential  of the response's [[density function]]. However, in some cases it makes sense to try to match the [[Domain of a function|domain]] of the link function to the [[Range (mathematics)|range]] of the distribution function's mean, or use a non-canonical link function for algorithmic purposes, for example [[Probit model#Gibbs sampling|Bayesian probit regression]].

When using a distribution function with a canonical parameter &lt;math&gt;\theta&lt;/math&gt;, the canonical link function is the function that expresses &lt;math&gt;\theta&lt;/math&gt; in terms of &lt;math&gt;\mu&lt;/math&gt;, i.e. &lt;math&gt;\theta = b(\mu)&lt;/math&gt;.  For the most common distributions, the mean &lt;math&gt;\mu&lt;/math&gt; is one of the parameters in the standard form of the distribution's [[density function]], and then &lt;math&gt;b(\mu)&lt;/math&gt;  is the function as defined above that maps the density function into its canonical form.  When using the canonical link function, &lt;math&gt;b(\mu) = \theta = \mathbf{X}\boldsymbol{\beta}&lt;/math&gt;, which allows &lt;math&gt;\mathbf{X}^{\rm T} \mathbf{Y}&lt;/math&gt; to be a [[sufficiency (statistics)|sufficient statistic]] for &lt;math&gt;\boldsymbol{\beta}&lt;/math&gt;.

Following is a table of several exponential-family distributions in common use and the data they are typically used for, along with the canonical link functions and their inverses (sometimes referred to as the mean function, as done here).

{| class="wikitable" style="background:white;"
|+ Common distributions with typical uses and canonical link functions 
! Distribution !! Support of distribution !! Typical uses !! Link name !! Link function, &lt;math&gt;\mathbf{X}\boldsymbol{\beta}=g(\mu)\,\!&lt;/math&gt;  !! Mean function
|-
| [[normal distribution|Normal]]
| real: &lt;math&gt;(-\infty,+\infty)&lt;/math&gt; || Linear-response data || Identity
| &lt;math&gt;\mathbf{X}\boldsymbol{\beta}=\mu\,\!&lt;/math&gt; || &lt;math&gt;\mu=\mathbf{X}\boldsymbol{\beta}\,\!&lt;/math&gt;
|-
| [[exponential distribution|Exponential]]
| rowspan="2" | real: &lt;math&gt;(0,+\infty)&lt;/math&gt; || rowspan="2" | Exponential-response data, scale parameters
| rowspan="2" | [[Multiplicative inverse|Negative inverse]]
| rowspan="2" | &lt;math&gt;\mathbf{X}\boldsymbol{\beta}=-\mu^{-1}\,\!&lt;/math&gt; 
| rowspan="2" | &lt;math&gt;\mu=-(\mathbf{X}\boldsymbol{\beta})^{-1}\,\!&lt;/math&gt;
|-
| [[gamma distribution|Gamma]]
|-
| [[Inverse Gaussian distribution|Inverse &lt;br&gt;Gaussian]]
| real: &lt;math&gt;(0, +\infty)&lt;/math&gt; || || Inverse &lt;br&gt;squared || &lt;math&gt;\mathbf{X}\boldsymbol{\beta}=\mu^{-2}\,\!&lt;/math&gt; || &lt;math&gt;\mu=(\mathbf{X}\boldsymbol{\beta})^{-1/2}\,\!&lt;/math&gt;
|-
| [[Poisson distribution|Poisson]]
| integer: &lt;math&gt;0,1,2,\ldots&lt;/math&gt; || count of occurrences in fixed amount of time/space || [[Natural logarithm|Log]] || &lt;math&gt;\mathbf{X}\boldsymbol{\beta} = \ln(\mu) \,\!&lt;/math&gt; || &lt;math&gt;\mu=\exp (\mathbf{X}\boldsymbol{\beta}) \,\!&lt;/math&gt;
|-
| [[Bernoulli distribution|Bernoulli]]
| integer: &lt;math&gt;\{0,1\}&lt;/math&gt; || outcome of single yes/no occurrence 
| rowspan="5" | [[Logit]]
| rowspan="5" | &lt;math&gt;\mathbf{X}\boldsymbol{\beta}=\ln \left(\frac \mu {1-\mu}\right) \,\!&lt;/math&gt; 
| rowspan="5" | &lt;math&gt;\mu=\frac{\exp(\mathbf{X}\boldsymbol{\beta})}{1 + \exp(\mathbf{X}\boldsymbol{\beta})} = \frac 1 {1 + \exp(-\mathbf{X} \boldsymbol{\beta})} \,\!&lt;/math&gt;
|-
| [[binomial distribution|Binomial]]
| integer: &lt;math&gt;0,1,\ldots,N&lt;/math&gt; || count of # of "yes" occurrences out of N yes/no occurrences 
|-
| rowspan=2| [[categorical distribution|Categorical]]
| integer: &lt;math&gt;[0,K)&lt;/math&gt;|| rowspan=2| outcome of single K-way occurrence 
|-
| K-vector of integer: &lt;math&gt;[0,1]&lt;/math&gt;, where exactly one element in the vector has the value 1
|-
| [[multinomial distribution|Multinomial]]
| ''K''-vector of integer: &lt;math&gt;[0,N]&lt;/math&gt; || count of occurrences of different types (1 .. ''K'') out of ''N'' total ''K''-way occurrences 
|}

In the cases of the exponential and gamma distributions, the domain of the canonical link function is not the same as the permitted range of the mean. In particular, the linear predictor may be positive, which would give an impossible negative mean.  When maximizing the likelihood, precautions must be taken to avoid this.  An alternative is to use a noncanonical link function.

Note also that in the case of the Bernoulli, binomial, categorical and multinomial distributions, the support of the distributions is not the same type of data as the parameter being predicted.  In all of these cases, the predicted parameter is one or more probabilities, i.e. real numbers in the range &lt;math&gt;[0,1]&lt;/math&gt;.  The resulting model is known as ''[[logistic regression]]'' (or ''[[multinomial logistic regression]]'' in the case that K-way rather than binary values are being predicted).

For the Bernoulli and binomial distributions, the parameter is a single probability, indicating the likelihood of occurrence of a single event.  The Bernoulli still satisfies the basic condition of the generalized linear model in that, even though a single outcome will always be either 0 or 1, the ''[[expected value]]'' will nonetheless be a real-valued probability, i.e. the probability of occurrence of a "yes" (or 1) outcome.  Similarly, in a binomial distribution, the expected value is ''Np'', i.e. the expected proportion of "yes" outcomes will be the probability to be predicted.

For categorical and multinomial distributions, the parameter to be predicted is a ''K''-vector of probabilities, with the further restriction that all probabilities must add up to 1.  Each probability indicates the likelihood of occurrence of one of the ''K'' possible values.  For the multinomial distribution, and for the vector form of the categorical distribution, the expected values of the elements of the vector can be related to the predicted probabilities similarly to the binomial and Bernoulli distributions.

== Fitting ==

=== Maximum likelihood ===

The [[maximum likelihood]] estimates can be found using an [[iteratively reweighted least squares]] algorithm or a [[Newton–Raphson method]] with updates of the form:

:&lt;math&gt; \boldsymbol\beta^{(t+1)} = \boldsymbol\beta^{(t)} + \mathcal{J}^{-1}(\boldsymbol\beta^{(t)}) u(\boldsymbol\beta^{(t)}), &lt;/math&gt;

where &lt;math&gt;\mathcal{J}(\boldsymbol\beta^{(t)})&lt;/math&gt; is the [[observed information|observed information matrix]] (the negative of the [[Hessian matrix]]) and &lt;math&gt;u(\boldsymbol\beta^{(t)})&lt;/math&gt; is the [[score (statistics)|score function]]; or a [[Scoring algorithm|Fisher's scoring]] method:

:&lt;math&gt; \boldsymbol\beta^{(t+1)} = \boldsymbol\beta^{(t)} + \mathcal{I}^{-1}(\boldsymbol\beta^{(t)}) u(\boldsymbol\beta^{(t)}), &lt;/math&gt;

where &lt;math&gt;\mathcal{I}(\boldsymbol\beta^{(t)})&lt;/math&gt; is the [[Fisher information]] matrix. Note that if the canonical link function is used, then they are the same.&lt;ref&gt;[[#McCullagh1989|McCullagh and Nelder (1989)]], page 43.&lt;/ref&gt;

=== Bayesian methods ===
In general, the [[posterior distribution]] cannot be found in [[Closed-form expression|closed form]] and so must be approximated, usually using [[Laplace approximation]]s or some type of [[Markov chain Monte Carlo]] method such as [[Gibbs sampling]].

== Examples ==

=== General linear models ===

A possible point of confusion has to do with the distinction between generalized linear models and the [[general linear model]], two broad statistical models.  The general linear model may be viewed as a special case of the generalized linear model with identity link and responses normally distributed.  As most exact results of interest are obtained only for the general linear model, the general linear model has undergone a somewhat longer historical development.  Results for the generalized linear model with non-identity link are [[asymptotic]] (tending to work well with large samples).

=== Linear regression ===

A simple, very important example of a generalized linear model (also an example of a general linear model) is [[linear regression]]. In linear regression, the use of the [[least-squares]] estimator is justified by the [[Gauss–Markov theorem]], which does not assume that the distribution is normal.

From the perspective of generalized linear models, however, it is useful to suppose that the distribution function is the normal distribution with constant variance and the link function is the identity, which is the canonical link if the variance is known.

For the normal distribution, the generalized linear model has a [[Closed-form expression|closed form]] expression for the maximum-likelihood estimates, which is convenient. Most other GLMs lack [[Closed-form expression|closed form]] estimates.

=== Binary data ===
When the response data, ''Y'', are binary (taking on only values 0 and 1), the distribution function is generally chosen to be the [[Bernoulli distribution]] and the interpretation of ''μ''&lt;sub&gt;i&lt;/sub&gt; is then the probability, ''p'', of ''Y''&lt;sub&gt;i&lt;/sub&gt; taking on the value one.

There are several popular link functions for binomial functions.

==== Logit link function ====
The most typical link function is the canonical [[logit]] link:

:&lt;math&gt;g(p) = \ln \left( { p \over 1-p } \right).&lt;/math&gt;

GLMs with this setup are [[logistic regression]] models (or ''logit models'').

==== Probit link function as popular choice of inverse cumulative distribution function ====
Alternatively, the inverse of any continuous [[cumulative distribution function]] (CDF) can be used for the link since the CDF's range is &lt;math&gt;[0,1]&lt;/math&gt;, the range of the binomial mean. The [[Normal distribution#Cumulative distribution function|normal CDF]] &lt;math&gt;\Phi&lt;/math&gt; is a popular choice and yields the [[probit model]]. Its link is

:&lt;math&gt;g(p) = \Phi^{-1}(p).\,\!&lt;/math&gt;

The reason for the use of the probit model is that a constant scaling of the input variable to a normal CDF (which can be absorbed through equivalent scaling of all of the parameters) yields a function that is practically identical to the logit function, but probit models are more tractable in some situations than logit models. (In a Bayesian setting in which normally distributed [[prior distribution]]s are placed on the parameters, the relationship between the normal priors and the normal CDF link function means that a [[probit model]] can be computed using [[Gibbs sampling]], while a logit model generally cannot.)

==== Complementary log-log (cloglog) ====
The complementary log-log function may also be used:
:&lt;math&gt;g(p) = \log(-\log(1-p)).&lt;/math&gt;
This link function is asymmetric and will often produce different results from the logit and probit link functions.{{citation needed|date=November 2011}} The cloglog model corresponds to applications where we observe either zero events (e.g., defects) or one or more, where the number of events is assumed to follow the [[Poisson distribution]]. The Poisson assumption means that

:&lt;math&gt;\Pr(0) = \exp(-\mu),&lt;/math&gt;

where ''&amp;mu;'' is a positive number denoting the inverse of the expected number of events.  If ''p'' represents the proportion of observations with at least one event, its complement

:&lt;math&gt;(1-p) = \Pr(0) = \exp(-\mu),&lt;/math&gt;

and then

:&lt;math&gt;(-\log(1-p)) = \mu.&lt;/math&gt;

A linear model requires the response variable to take values over the entire real line. Since ''&amp;mu;'' must be positive, we can enforce that by taking the logarithm, and letting log(''&amp;mu;'') be a linear model.  This produces the "cloglog" transformation

:&lt;math&gt;\log(-\log(1-p)) = \log(\mu).&lt;/math&gt;

==== Identity link ====
The identity link ''g(p) = p'' is also sometimes used for binomial data to yield a [[linear probability model]].  However, the identity link can predict nonsense "probabilities" less than zero or greater than one.  This can be avoided by using a transformation like cloglog, probit or logit (or any inverse cumulative distribution function).  A primary merit of the identity link is that it can be estimated using linear math—and other standard link functions are approximately linear matching the identity link near p = 0.5.

==== Variance function ====
The [[variance function]] for "quasibinomial" data is:

:&lt;math&gt;\operatorname{Var}(Y_i)= \tau\mu_i (1-\mu_i)\,\!&lt;/math&gt;

where the dispersion parameter ''&amp;tau;'' is exactly 1 for the binomial distribution. Indeed, the standard binomial likelihood omits ''&amp;tau;''.  When it is present, the model is called "quasibinomial", and the modified likelihood is called a [[quasi-likelihood]], since it is not generally the likelihood corresponding to any real probability distribution.  If ''&amp;tau;'' exceeds 1, the model is said to exhibit [[overdispersion]].

===Multinomial regression===
The binomial case may be easily extended to allow for a [[multinomial distribution]] as the response (also, a Generalized Linear Model for counts, with a constrained total). There are two ways in which this is usually done:

====Ordered response====
If the response variable is an [[Level of measurement#Ordinal measurement|ordinal measurement]], then one may fit a model function of the form:

:&lt;math&gt; g(\mu_m) = \eta_m = \beta_0 + X_1 \beta_1 + \cdots + X_p \beta_p + \gamma_2 + \cdots + \gamma_m = \eta_1 + \gamma_2 + \cdots + \gamma_m \text{ where } \mu_m = \operatorname{P}(Y \leq m). \,&lt;/math&gt;

for ''m'' &gt; 2. Different links ''g'' lead to [[Ordered logit|proportional odds model]]s or [[ordered probit]] models.

====Unordered response====
If the response variable is a [[Level of measurement#Nominal scale|nominal measurement]], or the data do not satisfy the assumptions of an ordered model, one may fit a model of the following form:

:&lt;math&gt; g(\mu_m) = \eta_m = \beta_{m,0} + X_1 \beta_{m,1} + \cdots + X_p \beta_{m,p} \text{ where } \mu_m = \mathrm{P}(Y = m \mid Y \in \{1,m\} ). \,&lt;/math&gt;

for ''m'' &gt; 2. Different links ''g'' lead to [[multinomial logit]] or [[multinomial probit]] models.  These are more general than the ordered response models, and more parameters are estimated. 
*

===Count data===
Another example of generalized linear models includes [[Poisson regression]] which models [[count data]] using the [[Poisson distribution]].  The link is typically the logarithm, the canonical link.

The variance function is proportional to the mean

:&lt;math&gt;\operatorname{var}(Y_i) = \tau\mu_i,\, &lt;/math&gt;

where the dispersion parameter ''&amp;tau;'' is typically fixed at exactly one. When it is not, the resulting [[quasi-likelihood]] model is often described as poisson with [[overdispersion]] or ''quasipoisson''.

==Extensions==

===Correlated or clustered data===
The standard GLM assumes that the observations are [[uncorrelated]]. Extensions have been developed to allow for [[correlation]] between observations, as occurs for example in [[longitudinal studies]] and clustered designs:
*'''[[Generalized estimating equation]]s''' (GEEs) allow for the correlation between observations without the use of an explicit probability model for the origin of the correlations, so there is no explicit [[likelihood]]. They are suitable when the [[random effects]] and their variances are not of inherent interest, as they allow for the correlation without explaining its origin. The focus is on estimating the average response over the population ("population-averaged" effects) rather than the regression parameters that would enable prediction of the effect of changing one or more components of '''X''' on a given individual. GEEs are usually used in conjunction with [[Huber-White standard errors]].&lt;ref&gt;{{cite journal
 |title=Models for Longitudinal Data: A Generalized Estimating Equation Approach| first=Scott L. | last=Zeger |author2=Liang, Kung-Yee |author3=Albert, Paul S.| journal=Biometrics| volume= 44| year=1988|pages=1049–1060| issue= 4
 |doi=10.2307/2531734
 |pmid=3233245
 |publisher=International Biometric Society
 |jstor=2531734 
}}&lt;/ref&gt;&lt;ref&gt;{{cite book  | last = Hardin| first = James |author2=Hilbe, Joseph |authorlink2=Joseph Hilbe  | title = Generalized Estimating Equations | publisher = London: Chapman and Hall/CRC  | year = 2003 |isbn=1-58488-307-3}}&lt;/ref&gt;
* '''[[Generalized linear mixed model]]s''' (GLMMs) are an extension to GLMs that includes [[random effects]] in the linear predictor, giving an explicit probability model that explains the origin of the correlations. The resulting "subject-specific" parameter estimates are suitable when the focus is on estimating the effect of changing one or more components of '''X''' on a given individual. GLMMs are also referred to as [[multilevel model]]s and as [[mixed model]]. In general, fitting GLMMs is more computationally complex and intensive than fitting GEEs.

===Generalized additive models===
[[Generalized additive model]]s (GAMs) are another extension to GLMs in which the linear predictor ''η'' is not restricted to be linear in the covariates '''X''' but is the sum of [[smoothing|smoothing functions]] applied to the ''x&lt;sub&gt;i&lt;/sub&gt;''s:

:&lt;math&gt;\eta = \beta_0 + f_1(x_1) + f_2(x_2) + \cdots \,\!&lt;/math&gt;

The smoothing functions ''f&lt;sub&gt;i&lt;/sub&gt;'' are estimated from the data. In general this requires a large number of data points and is computationally intensive.&lt;ref&gt;Hastie &amp; Tibshirani 1990.&lt;/ref&gt;&lt;ref&gt;Wood 2006.&lt;/ref&gt;

==Confusion with general linear models==
{{further|General linear model}}
The term "generalized linear model", and especially its abbreviation GLM, are sometimes confused with the term "general linear model". Co-originator [[John Nelder]] has expressed regret over this terminology.&lt;ref&gt;{{cite journal |last= Senn|first=Stephen |year=2003 |title=A conversation with John Nelder |journal=Statistical Science |volume=18 |issue=1 |pages=118–131 |doi=10.1214/ss/1056397489|quote=I suspect we should have found some more fancy name for it that would have stuck and not been confused with the general linear model, although general and generalized are not quite the same. I can see why it might have been better to have thought of something else.}}&lt;/ref&gt;

==See also==
* [[Comparison of general and generalized linear models]]
* [[Generalized linear array model]]
* [[Tweedie distributions]]
* [[GLIM (software)]]
* [[Natural exponential family]]
* [[Vector generalized linear model]] (VGLM)
* [[Quasi-variance]]

== Notes ==
{{reflist}}

==References==
*{{cite book|last = Hastie |first= T. J. |last2=Tibshirani |first2=R. J.|title = Generalized Additive Models|publisher = Chapman &amp; Hall/CRC|year = 1990|isbn=978-0-412-34390-2}}
* {{cite book |author1=Madsen, Henrik |author2=Thyregod, Poul|title= Introduction to General and Generalized Linear Models | year=2011 | publisher=Chapman &amp; Hall/CRC | isbn=978-1-4200-9155-7| ref=harv}}
* {{cite book  | last = McCullagh | first = Peter | authorlink= Peter McCullagh |author2=Nelder, John |authorlink2=John Nelder  | title = Generalized Linear Models, Second Edition | publisher = Boca Raton: Chapman and Hall/CRC | year = 1989 | isbn = 0-412-31760-5 |ref=McCullagh1989}}
*{{cite book| last=Wood | first=Simon |year=2006 | title = Generalized Additive Models: An Introduction with R |publisher=Chapman &amp; Hall/CRC | isbn=1-58488-474-6}}

==Further reading==

* {{cite book  | last = Dobson| first = A.J. |author2=Barnett, A.G. |  title = Introduction to Generalized Linear Models |edition = 3rd | publisher = Boca Raton, FL: Chapman and Hall/CRC | year = 2008 |isbn = 1-58488-165-8}}
* {{cite book  | last = Hardin| first = James |author2=Hilbe, Joseph |authorlink2=Joseph Hilbe  | title = Generalized Linear Models and Extensions | publisher = College Station: Stata Press | year = 2007 |edition=2nd |isbn=1-59718-014-9 }}

{{statistics|correlation}}

{{DEFAULTSORT:Generalized Linear Model}}
[[Category:Actuarial science]]
[[Category:Generalized linear models| ]]
[[Category:Regression models]]</text>
      <sha1>17hatp4h25e9ofto6xqbr984pisp8k4</sha1>
    </revision>
  </page>
  <page>
    <title>Haridatta</title>
    <ns>0</ns>
    <id>26066377</id>
    <revision>
      <id>871060672</id>
      <parentid>861375419</parentid>
      <timestamp>2018-11-28T17:55:57Z</timestamp>
      <contributor>
        <username>GoodDay</username>
        <id>589223</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6021">{{infobox person
| name                      = Haridatta
| image                     = 
| image_size                = 
| alt                       = 
| caption                   = 
| birth_name                = 
| birth_date                = ca.650 CE
| birth_place               = 
| death_date                = 
| death_place               = 
| body_discovered           = 
| death_cause               = 
| resting_place             = 
| resting_place_coordinates = &lt;!-- {{coord|LAT|LONG|display=inline,title}} --&gt;
| residence                 = [[Thirunnavaya]], [[Kerala]]
| nationality               = [[India]]n
| ethnicity                 = 
| citizenship               = 
| other_names               = 
| known_for                 = Promulgation of the ''Parahita'' system of astronomical computations
| education                 = 
| alma_mater                = 
| employer                  = 
| notable works             = Grahacaranibandhana
| occupation                = Astronomer-astrologer
| years_active              = 
| home_town                 = 
| salary                    = 
| networth                  = 
| height                    = 
| weight                    = 
| title                     = 
| term                      = 
| predecessor               = 
| successor                 = 
| party                     = 
| opponents                 = 
| boards                    = 
| spouse                    = 
| partner                   = 
| children                  = 
| parents                   = 
| relations                 = 
| callsign                  = 
| awards                    = 
| signature                 = 
| signature_alt             = 
| website                   = 
| footnotes                 =Promulgated the ''Parahita'' system of astronomical computations in 683 CE at [[Thirunnavaya]].
| box_width                 = 
| misc                      = 
}}

'''Haridatta''' (c. 683 CE) was an [[astronomer]]-[[mathematician]] of [[Kerala]], [[India]], who is believed to be the promulgator of the Parahita system of astronomical computations. This system of computations is widely popular in [[Kerala]] and [[Tamil Nadu]]. According to legends, Haridatta promulgated the [[Parahita]] system on the occasion of the ''[[Mamankam]]'' held in the year 683 CE.&lt;ref name=EHSTM&gt;[[K. V. Sarma]] (1997), "Haridatta", [[Encyclopaedia of the History of Science, Technology, and Medicine in Non-Western Cultures]], edited by [[Helaine Selin]], Springer, {{ISBN|978-1-4020-4559-2}}.
&lt;/ref&gt; Mamankam was a 12-yearly festival held in [[Thirunnavaya]] on the banks of the [[Bharathapuzha]] river.

The distinctive contribution of Harfidatta, apart from his resolving the [[Aryabhatiya]] calculations and using the [[Katapayadi system]] of [[numeral system|numerals]] is the corrections he introduced to the values of the mean and true positions, the velocity, etc., of the moon and other planets as obtained from [[Aryabhata]]'s constants. This correction is called the ''[[Saka era|Sakabda]]-samskara'' since it applied from the date of [[Aryabhata]] in the [[Saka era]] 444, at which date his constants gave accurate results.&lt;ref&gt;{{cite journal|last=K. Chandra Hari|date=2002|title=Date of Haridatta, promulgator of the [[Parahita]] system of astronomy in Kerala|journal=Indian Journal of History of Science|volume=37|issue=3|pages=223&amp;ndash;236}}&lt;/ref&gt;

==Parahita system==

The Parahita system of computations introduced by Haridatta was a simplification of the system propounded in [[Aryabhatiya]] by [[Aryabhata]]. Haridatta introduced the following simplificattions.&lt;ref name=EHSTM/&gt;&lt;ref&gt;{{cite book|last=K.V. Sarma|title=[[A History of the Kerala School of Hindu Astronomy]]|publisher=Vishveshwaranand Institute|location=Hoshiarpur|date=1972|pages=7–9|chapter=Parahita system of astronomy}}&lt;/ref&gt;
The system was called Parahita meaning ''suitable for the common man'' because it simplified astronomical computations and made it accessible for practice even for ordinary persons.

*Haridatta dispensed with the numerical symbolism used by Aryabhata  and replaced it with the more flexible [[Katapayadi system]]. In this system, letters are used to represent digits and these letters are then  used to invent meaningful words and sentences to denote specific numbers. These words and sentences could be remembered with much less effort.
*Computations in Indian astronomy involved long numbers representing various parameters   associated with the several celestial objects which are applicable for a ''[[Mahayuga]]'', a period of 4,320,000 years. To avoid computations with these large numbers, Haridatta introduced a smaller [[Yuga]], called a ''Dhijagannupura-yuga'', of 576 years or 210,389 days (which 1/7500 th part of a Mahyuga) and accurately determined the zero corrections for this sub-Yuga for the mean motion of the several planets. These corrections were then used to compute the mean planets for any given date.

==Works of Haridatta==
Scholars have been able to identify only two works as authored by Haridatta. One of them, titled ''Grahacaranibandhana'', is the basic manual of computations of the Parahita system of astronomy. This was unearthed by [[K.V. Sarma]] and was published in 1954.&lt;ref&gt;{{cite book|last=K.V. Sarma|title=Grahacaranibandhana: A Parahita manual by Haridatta|publisher=Kuppuswamy Research Foundation|location=Madras|date=1954}}&lt;/ref&gt; The other work titled ''Mahamarganibandhana'' is no longer extant.

==See also==
*[[Indian astronomy]]
*[[Indian mathematics]]
*[[Indian mathematicians]]
*[[History of mathematics]]

==References==
{{reflist}}

{{Indian mathematics}}
{{Scientific Research in Kerala |state=collapsed}}

{{authority control}}

[[Category:Hindu astronomy]]
[[Category:History of mathematics]]
[[Category:Kerala school]]
[[Category:People from Malappuram district]]
[[Category:Scientists from Kerala]]
[[Category:7th-century Indian mathematicians]]
[[Category:7th-century Indian astronomers]]
[[Category:Scholars from Kerala]]</text>
      <sha1>31s0u4dpaqcrhuydqu1k32i2f8wx4wp</sha1>
    </revision>
  </page>
  <page>
    <title>Ignatov's theorem</title>
    <ns>0</ns>
    <id>39806471</id>
    <revision>
      <id>753391372</id>
      <parentid>651327845</parentid>
      <timestamp>2016-12-06T21:57:05Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>more specific categorisation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3137">In [[probability]] and [[mathematical statistics]], '''Ignatov's theorem''' is a basic result on the distribution of record values of a [[stochastic process]].

== Statement ==

Let ''X''&lt;sub&gt;1&lt;/sub&gt;, ''X''&lt;sub&gt;2&lt;/sub&gt;, ... be an infinite sequence of [[independent and identically distributed random variables]].  The ''initial rank'' of the ''n''th term of this sequence is the value ''r'' such that {{nowrap|''X''&lt;sub&gt;''i''&lt;/sub&gt; &amp;ge; ''X''&lt;sub&gt;''n''&lt;/sub&gt;}} for exactly ''r'' values of ''i'' less than or equal to ''n''.  Let {{nowrap|'''Y'''&lt;sub&gt;''k''&lt;/sub&gt; {{=}} (''Y''&lt;sub&gt;''k'',1&lt;/sub&gt;, ''Y''&lt;sub&gt;''k'',2&lt;/sub&gt;, ''Y''&lt;sub&gt;''k'',3&lt;/sub&gt;, ...)}} denote the stochastic process consisting of the terms ''X''&lt;sub&gt;''i''&lt;/sub&gt; having initial rank ''k''; that is, ''Y''&lt;sub&gt;''k'',''j''&lt;/sub&gt; is the ''j''th term of the stochastic process that achieves initial rank ''k''.  The sequence '''Y'''&lt;sub&gt;''k''&lt;/sub&gt; is called the sequence of ''k''th '''partial records'''.  Ignatov's theorem states that the sequences '''Y'''&lt;sub&gt;1&lt;/sub&gt;, '''Y'''&lt;sub&gt;2&lt;/sub&gt;, '''Y'''&lt;sub&gt;3&lt;/sub&gt;, ... are independent and identically distributed.

== Note ==

The theorem is named after Tzvetan Ignatov a Bulgarian professor in probability and mathematical statistics at Sofia University. Due to it and his general contributions to mathematics, Prof. Ignatov was granted a Doctor Honoris Causa degree in 2013 from Sofia University. The recognition is given on extremely rare occasions and only to scholars with internationally landmark results.

== References ==

* Ilan Adler and Sheldon M. Ross, "Distribution of the Time of the First ''k''-Record", Probability in the Engineering and Informational Sciences, Volume 11, Issue 3, July 1997, pp.&amp;nbsp;273–278
* Ron Engelen, Paul Tommassen and Wim Vervaat, "Ignatov's Theorem: A New and Short Proof", Journal of Applied Probability, Vol. 25, A Celebration of Applied Probability (1988), pp.&amp;nbsp;229–236
* Ignatov, Z., "Ein von der Variationsreihe erzeugter Poissonscher Punktprozess", Annuaire Univ. Sofia Fac. Math. Mech. 71, 1977, pp.&amp;nbsp;79–94
* Ignatov, Z., "Point processes generated by order statistics and their applications". In: P. Bartfai and J. Tomko, eds., ''Point Processes and Queueing Problems'', Keszthely (Hungary). Coll. Mat. Soc. 5. Janos Bolyai 24, 1978, pp.&amp;nbsp;109–116
* Samuels, S., "All at once proof of Ignatov’s theorem", Contemp. Math. 125, 1992, pp.&amp;nbsp;231–237
* Yi-Ching Yao, "On Independence of ''k''-Record Processes: Ignatov's Theorem Revisited", The Annals of Applied Probability, Vol. 7, No. 3 (Aug., 1997), pp.&amp;nbsp;815–821
* [https://www.uni-sofia.bg/index.php/eng/news/calendar/assoc_prof_tzvetan_ignatov_faculty_of_economics_and_business_administration_will_receive_the_honorary_degree_doctor_honoris_causa_of_sofia_university Doctor Honoris Causa degree], 2013, in English
* [https://www.uni-sofia.bg/index.php/bul/novini/arhiv/arhiv_na_goreschi_novini/doc_cvetan_ignatov_be_udostoen_s_pochetnata_titla_doktor_honoris_kauza_na_su Doctor Honoris Causa degree], 2013, in Bulgarian

[[Category:Theorems regarding stochastic processes]]

{{probability-stub}}</text>
      <sha1>67m46g9p9hrenpcmw01eyjhvkfizdiw</sha1>
    </revision>
  </page>
  <page>
    <title>Jim Geelen</title>
    <ns>0</ns>
    <id>24393682</id>
    <revision>
      <id>860742819</id>
      <parentid>858406064</parentid>
      <timestamp>2018-09-22T18:48:17Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:JCW-CleanerBot#Logic|task]], replaced: J. Comb. Theory Ser. B → J. Comb. Theory B</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3035">{{Infobox scientist
| name              = Jim Geelen
| image             = 
| birth_date        = 
| birth_place       = 
| death_date        = 
| death_place       = 
| residence         = [[Waterloo, ON]]
| citizenship       =
| nationality       = 
| ethnicity         =
| field             = [[Combinatorial optimization]]
| work_institution  = [[University of Waterloo]]
| alma_mater        = [[University of Waterloo]]
| doctoral_advisor  = William H. Cunningham
| doctoral_students = 
| known_for         = 
| prizes            = [[Fulkerson Prize]]
| religion          =
| footnotes         = 
}}
'''Jim Geelen''' is a [[professor]] at the Department of [[Combinatorics]] and [[Optimization (mathematics)|Optimization]] in the [[University of Waterloo Faculty of Mathematics|faculty of mathematics]] at the [[University of Waterloo]], where he holds the [[Canada Research Chair]] in [[Combinatorial optimization]].&lt;ref&gt;[http://www.chairs-chaires.gc.ca/chairholders-titulaires/profile-eng.aspx?profileID=1117 Jim Geelen] at the [[Canada Research Chairs]] website.&lt;/ref&gt; He is known for his work on [[Matroid theory]] and the extension of the [[Robertson–Seymour theorem|Graph Minors Project]] to representable matroids. In 2003, he won the [[Fulkerson Prize]] with his co-authors A. M. H. Gerards, and A. Kapoor for their research on [[Rota's excluded minors conjecture]].&lt;ref&gt;[http://www.mathopt.org/?nav=fulkerson_2003 2003 Fulkerson Prize citation], retrieved 2012-08-18.&lt;/ref&gt;&lt;ref&gt;{{Citation|last1=Geelen |first1=James F. |last2=Gerards |first2=A. M. H. |last3=Kapoor |first3=Ajai |title=The Excluded Minors for GF(4)-Representable Matroids |year=2000 |journal=J. Comb. Theory B |volume=79 |issue=2 |pages=247–299 |url=http://www.math.uwaterloo.ca/~jfgeelen/publications/gf4.pdf |doi=10.1006/jctb.2000.1963 |deadurl=yes |archiveurl=https://web.archive.org/web/20100924110912/http://www.math.uwaterloo.ca/~jfgeelen/publications/gf4.pdf |archivedate=2010-09-24 |df= }}&lt;/ref&gt; In 2006, he won the [[Coxeter–James Prize]] presented by the [[Canadian Mathematical Society]].&lt;ref&gt;[http://www.cms.math.ca/Prizes/recip?id=CJ Winners of the Coxeter–James Prize].&lt;/ref&gt;

He received a [[Bachelor of Science]] degree in 1992 from [[Curtin University]] in [[Australia]], and obtained his [[Ph.D.]] in 1996 at the [[University of Waterloo]] under the supervision of William Cunningham.&lt;ref&gt;{{MathGenealogy|id=43649}}.&lt;/ref&gt;  After brief postdoctoral fellowships in the Netherlands, Germany, and Japan, he returned to the University of Waterloo in 1997.&lt;ref&gt;{{Cite web|url = https://cms.math.ca/Prix/citations/cj2006.pdf|title = 2006 Coxeter James Prize|last =|first =|date =|website =|publisher =|access-date =}}&lt;/ref&gt;

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Geelen, Jim}}
[[Category:Living people]]
[[Category:University of Waterloo faculty]]
[[Category:University of Waterloo alumni]]
[[Category:Combinatorialists]]
[[Category:Canada Research Chairs]]


{{canada-scientist-stub}}
{{mathematician-stub}}</text>
      <sha1>9bmrrizu9vu7h064vc3r8dg4kge7hnw</sha1>
    </revision>
  </page>
  <page>
    <title>John G. Thompson</title>
    <ns>0</ns>
    <id>862189</id>
    <revision>
      <id>862291334</id>
      <parentid>852694126</parentid>
      <timestamp>2018-10-03T12:29:01Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Members of the Department of Pure Mathematics and Mathematical Statistics to [[:Category:Cambridge mathematicians]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 August 25]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9041">{{Infobox scientist
|name              = John Thompson
|image             = John Griggs Thompson.jpg
|image_size        = 250px
|caption           = John Thompson in 2007
|birth_date        = {{Birth date and age|1932|10|13}}
|birth_place       = [[Ottawa, Kansas]], U.S.
|nationality       = American
|field             = [[Group theory]]
|work_institutions = [[Harvard University]] (1961–62)&lt;br /&gt;[[University of Chicago]] (1962–68)&lt;br /&gt;[[University of Cambridge]] (1968–93)&lt;br /&gt;[[University of Florida]] (1993–present)
|alma_mater        = [[Yale University]] {{small|([[Bachelor of Arts|B.A.]] 1955)}}&lt;br /&gt;[[University of Chicago]] {{small|([[Ph.D.]] 1959)}}
|doctoral_advisor  = [[Saunders Mac Lane]]
|doctoral_students = [[R. L. Griess]] &lt;br&gt; [[Richard Lyons (mathematician)|Richard Lyons]] &lt;br&gt; [[Charles Sims (mathematician)|Charles Sims]]
|thesis_title = A Proof that a Finite Group with a Fixed-Point-Free Automorphism of Prime Order is Nilpotent
|thesis_year = 1959
|known_for         =
|prizes            = {{no wrap|[[Cole Prize]] (1965)&lt;br /&gt;[[Fields Medal]] (1970)&lt;br /&gt;Fellow of the [[Royal Society]] (1979)&lt;br /&gt;[[Senior Berwick Prize]] (1982)&lt;br /&gt;[[Sylvester Medal]] (1985)&lt;br /&gt;[[Wolf Prize]] (1992)&lt;br /&gt;Médaille Poincaré (1992)&lt;ref&gt;[http://serge.mehl.free.fr/chrono/thompson.html Thompson, John Griggs — serge.mehl.free.fr]&lt;/ref&gt;&lt;ref&gt;[http://www.academie-sciences.fr/activite/prix/grande_medaille_fondations.pdf Liste des 122 fondations] {{webarchive|url=https://web.archive.org/web/20141006162842/http://www.academie-sciences.fr/activite/prix/grande_medaille_fondations.pdf |date=2014-10-06 }}. The ''médaille Poincaré'' awarded by the French Academy of Sciences was eliminated in 1997 in favor of the ''[[Grande Médaille]]''.&lt;/ref&gt; &lt;br /&gt;[[National Medal of Science]] (2000)&lt;br&gt;[[Abel Prize]] (2008)&lt;br&gt;[[De Morgan Medal]] (2013)}}
}}

'''John Griggs Thompson''' (born October 13, 1932) is a [[mathematician]] at the [[University of Florida]] noted for his work in the field of [[finite group]]s. He was awarded the [[Fields Medal]] in 1970, the [[Wolf Prize]] in 1992 and the 2008 [[Abel Prize]].

==Biography==
He received his [[Bachelor of Arts|B.A.]] from [[Yale University]] in 1955 and his [[doctorate]] from the [[University of Chicago]] in 1959 under the supervision of [[Saunders Mac Lane]]. After spending some time on the Mathematics faculty at the University of Chicago, he moved in 1970 to the [[Rouse Ball Professor of Mathematics|Rouse Ball Professorship in Mathematics]] at the [[University of Cambridge]], [[England]], and later moved to the Mathematics Department of the [[University of Florida]] as a Graduate Research Professor.  He is currently a [[Professor Emeritus]] of [[Pure Mathematics]] at the University of Cambridge, and [[professor]] of [[mathematics]] at the University of Florida.  He received the [[Abel Prize]] 2008 together with [[Jacques Tits]].&lt;ref name=abel&gt;{{cite web
 |url=http://www.abelprisen.no/en/nyheter/nyhet.html?id=163 
 |title=Thompson and Tits share the Abel Prize for 2008 
 |publisher=[[Norwegian Academy of Science and Letters]] 
 |date=2008-05-17 
 |accessdate=2008-05-20 
 |archiveurl=https://www.webcitation.org/5XxtY4s3z?url=http://www.abelprisen.no/en/nyheter/nyhet.html?id=163 
 |archivedate=2008-05-20 
 |quote=The Norwegian Academy of Science and Letters has decided to award the Abel Prize for 2008 to John Griggs Thompson, University of Florida and Jacques Tits, Collège de France. This was announced by the Academy's President, Ole Didrik Lærum, at a press conference in Oslo today. Thompson and Tits receives the Abel Prize "for their profound achievements in algebra and in particular for shaping modern group theory". 
 |deadurl=yes 
 |df= 
}}&lt;/ref&gt;

==Work==
Thompson's doctoral thesis introduced new techniques, and included the solution of a problem in [[finite group theory]] which had stood for around sixty years, the [[nilpotent group|nilpotency]] of [[Frobenius group|Frobenius kernels]]. At the time, this achievement was noted in ''[[The New York Times]]''&lt;ref&gt;http://www.cecm.sfu.ca/organics/papers/lam/paper/html/NYTimes.html New York Times article, April 26, 1959.&lt;/ref&gt;.

Thompson became a figure in the progress toward the [[classification of finite simple groups]].  In 1963, he and [[Walter Feit]] proved that all [[Abelian group|nonabelian]] finite [[simple group]]s are of even [[Order (group theory)|order]] (the ''[[Feit–Thompson theorem|Odd Order Paper]]'', filling a whole issue of the ''[[Pacific Journal of Mathematics]]''). This work was recognised by the award of the 1965 [[Cole Prize]] in Algebra of the [[American Mathematical Society]]. His [[N-group (finite group theory)|N-group papers]] classified all finite simple groups for which the [[Centralizer and normalizer|normalizer]] of every non-identity [[Solvable group|solvable]] [[subgroup]] is solvable. This included, as a by-product, the classification of all minimal finite simple groups (simple groups for which every proper subgroup is solvable). This work had some influence on later developments in the classification of finite simple groups, and was quoted in the citation by [[Richard Brauer]] for the award of Thompson's Fields Medal in 1970 (Proceedings of the [[International Congress of Mathematicians]], [[Nice]], [[France]], 1970).

The [[Thompson group (finite)|Thompson group]] ''Th'' is one of the 26 [[sporadic group|sporadic]] finite simple groups. Thompson also made major contributions to the [[inverse Galois problem]]. He found a criterion for a finite group to be a [[Galois group]], that in particular implies that the [[Monster group|monster simple group]] is a Galois group.

==Awards==
In 1971, Thompson was elected to the [[United States National Academy of Sciences]].   In 1982, he was awarded the Senior Berwick Prize of the [[London Mathematical Society]], and in 1988, he received the honorary degree of [[Doctor of Science]] from the [[University of Oxford]]. Thompson was awarded the United States [[National Medal of Science]] in 2000.&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Thompson_John.html|title=John Griggs Thompson|publisher=University of St. Andrews|accessdate=24 October 2016}}&lt;/ref&gt; He is a [[Fellow of the Royal Society]] ([[United Kingdom]]), and a recipient of its [[Sylvester Medal]] in 1985.&lt;ref&gt;{{cite web|url=http://royalsociety.org/awards/sylvester-medal|title=Royal Society Sylvester Medalists|accessdate=2 March 2014}}&lt;/ref&gt; He is a member of the [[Norwegian Academy of Science and Letters]].&lt;ref&gt;{{cite web|url=http://www.dnva.no/c26849/artikkel/vis.html?tid=40116 |title=Gruppe 1: Matematiske fag |publisher=[[Norwegian Academy of Science and Letters]] |language=Norwegian |accessdate=7 October 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20131110152102/http://www.dnva.no/c26849/artikkel/vis.html?tid=40116 |archivedate=10 November 2013 |df= }}&lt;/ref&gt;

==See also==

*[[Feit–Thompson theorem]]
*[[McKay–Thompson series]]
*[[Quadratic pair]]
*[[Thompson factorization]]
*[[Thompson order formula]]
*[[Thompson subgroup]]
*[[Thompson transitivity theorem]]
*[[Thompson uniqueness theorem]]

==References==
&lt;!--See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the &lt;ref(erences/)&gt; tags--&gt;
&lt;!--to cite a web resource, use this template
&lt;ref&gt;{{cite web
 | url =
 | title =
 | last =
 | first =
 | authorlink =
 | coauthors =
 | work =
 | publisher =
 | date =
 | format =
 | language=
 | doi =
 | accessdate =  
 | quote = 
}}&lt;/ref&gt;
--&gt;
{{Reflist}}

==External links==
* {{MacTutor Biography|id=Thompson_John}}
* {{MathGenealogy|id=6488}}
* [https://web.archive.org/web/20050414155503/http://www.math.ufl.edu/fac/facmr/Thompson.html List of mathematical articles by John G. Thompson]
* [http://www.abelprize.no/c53860/binfil/download.php?tid=53792 Biography from the Abel Prize center]

{{Abel Prize laureates}}
{{Fields medalists}}
{{Wolf Prize in Mathematics}}
{{Winners of the National Medal of Science|math-stat-comp}}

{{Authority control}}

{{DEFAULTSORT:Thompson, John Griggs}}
[[Category:1932 births]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Living people]]
[[Category:People from Ottawa, Kansas]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Yale University alumni]]
[[Category:University of Chicago alumni]]
[[Category:Harvard University faculty]]
[[Category:University of Chicago faculty]]
[[Category:Cambridge mathematicians]]
[[Category:University of Florida faculty]]
[[Category:20th-century mathematicians]]
[[Category:Fellows of Churchill College, Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:Fields Medalists]]
[[Category:Abel Prize laureates]]
[[Category:Group theorists]]
[[Category:National Medal of Science laureates]]
[[Category:Wolf Prize in Mathematics laureates]]
[[Category:Members of the Norwegian Academy of Science and Letters]]
[[Category:Mathematicians from Kansas]]</text>
      <sha1>5ypoqib4trzee5m1hbsatsomsb1xp5c</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of the European Mathematical Society</title>
    <ns>0</ns>
    <id>30673871</id>
    <revision>
      <id>841462074</id>
      <parentid>771272563</parentid>
      <timestamp>2018-05-16T00:43:49Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>| mathscinet   = J. Eur. Math. Soc. (JEMS)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1845">{{Infobox journal
 | title        = Journal of the European Mathematical Society
 | cover        = 
 | abbreviation = J. Eur. Math. Soc.
 | mathscinet   = J. Eur. Math. Soc. (JEMS)
| discipline   = Pure and applied mathematics
 | editor       = [[François Loeser]]
 | publisher    = [[European Mathematical Society]]
 | frequency    = Monthly
 | history      = 1999–present
 | openaccess   = no
 | impact       = 1.950
 | impact-year  = 2015
 | url          = http://www.ems-ph.org/journals/journal.php?jrn=jems
 | ISSN         = 1435-9855
 | eISSN        = 1435-9863
 | CODEN        = 
 | LCCN         = 
 | OCLC         = 614880774
 | link1        = http://www.ems-ph.org/journals/show_issue.php?issn=1435-9855&amp;vol=13&amp;iss=2 
 | link1-name   = Online access
}}

''''' Journal of the European Mathematical Society''''' is a [[peer review|peer-reviewed]],  [[mathematics journal]] published monthly by the [[European Mathematical Society]].
Founded in 1999, the journal publishes articles on [[Mathematics|pure and applied mathematics]].

==Abstracting and indexing==
The journal is indexed in the following database:
* ''[[Mathematical Reviews]]'' 
* ''[[Current Mathematical Publications]]'' 
* ''[[MathSciNet]]'' 
* ''[[Zentralblatt für Mathematik]]'' 
* ''[[Zentralblatt MATH]] Database'' 
* ''[[Science Citation Index Expanded]]'' 
* ''[[CompuMath Citation Index]]'' 
* ''[[Current Contents]]'' / Physical, Chemical &amp; Earth Sciences 
* ''ISI Alerting Services'' 
* ''[[Journal Citation Reports]]''/Science Edition

==External links==
*{{Official|1=http://www.ems-ph.org/journals/journal.php?jrn=jems}}


[[Category:Mathematics journals]]
[[Category:Publications established in 1999]]
[[Category:English-language journals]]
[[Category:European Mathematical Society academic journals]]
[[Category:Quarterly journals]]
{{math-journal-stub}}</text>
      <sha1>1zivj7wlrr9p357bpxaxdapkd3rlghf</sha1>
    </revision>
  </page>
  <page>
    <title>Karnaugh map</title>
    <ns>0</ns>
    <id>10854684</id>
    <revision>
      <id>867781059</id>
      <parentid>867675692</parentid>
      <timestamp>2018-11-07T23:41:03Z</timestamp>
      <contributor>
        <ip>72.200.10.77</ip>
      </contributor>
      <comment>/* Solution */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="43421">{{Expand German|Karnaugh-Veitch-Diagramm|date=February 2018}}
[[File:K-map 6,8,9,10,11,12,13,14 anti-race.svg|thumb|right|An example Karnaugh map. This image actually shows two Karnaugh maps: for the function ''ƒ'', using [[minterm]]s (colored rectangles) and for its complement, using [[maxterm]]s (gray rectangles). In the image, ''E''() signifies a sum of minterms, denoted in the article as &lt;math&gt;\sum m_i&lt;/math&gt;.]]

The '''Karnaugh map''' ('''KM''' or '''K-map''') is a method of simplifying [[Boolean algebra]] expressions. [[Maurice Karnaugh]] introduced it in 1953&lt;ref name="Karnaugh_1953"/&gt;&lt;ref name="Curtis_1962"/&gt; as a refinement of [[Edward Veitch]]'s 1952 '''Veitch chart''',&lt;ref name="Veitch_1952"/&gt;&lt;ref name="Brown_2012"/&gt; which actually was a rediscovery of [[Allan Marquand]]'s 1881 ''logical diagram''&lt;ref name="Marquand_1881"/&gt; aka '''Marquand diagram'''&lt;ref name="Brown_2012"/&gt; but with a focus now set on its utility for switching circuits.&lt;ref name="Brown_2012"/&gt; Veitch charts are therefore also known as ''Marquand–Veitch diagrams'',&lt;ref name="Brown_2012"/&gt; and Karnaugh maps as ''Karnaugh–Veitch maps'' (''KV maps'').

The Karnaugh map reduces the need for extensive calculations by taking advantage of humans' pattern-recognition capability.&lt;ref name="Karnaugh_1953"/&gt; It also permits the rapid identification and elimination of potential [[race condition]]s.

The required Boolean results are transferred from a [[truth table]] onto a two-dimensional grid where, in Karnaugh maps, the cells are ordered in [[Gray code]],&lt;ref name="Wakerly_1994"/&gt;&lt;ref name="Brown_2012"/&gt; and each cell position represents one combination of input conditions, while each cell value represents the corresponding output value. Optimal groups of 1s or 0s are identified, which represent the terms of a [[Canonical form (Boolean algebra)|canonical form]] of the logic in the original truth table.&lt;ref name="Belton_1998"/&gt; These terms can be used to write a minimal Boolean expression representing the required logic.

Karnaugh maps are used to simplify real-world logic requirements so that they can be implemented using a minimum number of physical logic gates. A [[Conjunctive normal form|sum-of-products expression]] can always be implemented using [[AND gate]]s feeding into an [[OR gate]], and a [[Disjunctive normal form|product-of-sums expression]] leads to OR gates feeding an AND gate.&lt;ref name="Dodge_2016"/&gt; Karnaugh maps can also be used to simplify logic expressions in software design. Boolean conditions, as used for example in [[Conditional (programming)|conditional statements]], can get very complicated, which makes the code difficult to read and to maintain. Once minimised, canonical sum-of-products and product-of-sums expressions can be implemented directly using AND and OR logic operators.&lt;ref name="Cook_2012"/&gt; Diagrammatic and mechanical methods for minimizing simple logic expressions have existed since at least the medieval times. More systematic methods for minimizing complex expressions began to be developed in the early 1950s, but until the mid to late 1980's the Karnaugh map was the most common used in practice.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=1097|isbn=1-57955-008-8}}&lt;/ref&gt;

==Example==
Karnaugh maps are used to facilitate the simplification of [[Boolean algebra (logic)|Boolean algebra]] functions. For example, consider the Boolean function described by the following [[truth table]].

{| class="wikitable" style="text-align: center"
|+ Truth table of a function
|-
! &amp;nbsp; !! ''A'' !! ''B'' !! ''C'' !! ''D'' !! {{tmath|f(A, B, C, D)}}&lt;/font&gt;
|-
! scope="row" |  0 
| 0 || 0 || 0 || 0 || 0
|-
! scope="row" |  1 
| 0 || 0 || 0 || 1 || 0
|-
! scope="row" |  2 
| 0 || 0 || 1 || 0 || 0
|-
! scope="row" |  3 
| 0 || 0 || 1 || 1 || 0
|-
! scope="row" |  4 
| 0 || 1 || 0 || 0 || 0
|-
! scope="row" |  5 
| 0 || 1 || 0 || 1 || 0
|-
! scope="row" |  6 
| 0 || 1 || 1 || 0 || 1
|-
! scope="row" |  7 
| 0 || 1 || 1 || 1 || 0
|-
! scope="row" |  8 
| 1 || 0 || 0 || 0 || 1
|-
! scope="row" |  9 
| 1 || 0 || 0 || 1 || 1
|-
! scope="row" | 10 
| 1 || 0 || 1 || 0 || 1
|-
! scope="row" | 11 
| 1 || 0 || 1 || 1 || 1
|-
! scope="row" | 12 
| 1 || 1 || 0 || 0 || 1
|-
! scope="row" | 13 
| 1 || 1 || 0 || 1 || 1
|-
! scope="row" | 14 
| 1 || 1 || 1 || 0 || 1
|-
! scope="column" | 15 
| 1 || 1 || 1 || 1 || 0
|}

Following are two different notations describing the same function in unsimplified Boolean algebra, using the Boolean variables {{mvar|A}}, {{mvar|B}}, {{mvar|C}}, {{mvar|D}}, and their inverses.

*&lt;math&gt;f(A, B, C, D) = \sum_{}m_i, i \in \{6, 8, 9, 10, 11, 12, 13, 14\}&lt;/math&gt; where &lt;math&gt;m_i&lt;/math&gt; are the [[minterm]]s to map (i.e., rows that have output 1 in the truth table).
*&lt;math&gt;f(A, B, C, D) = \prod_{}M_i, i \in \{0, 1, 2, 3, 4, 5, 7, 15\}&lt;/math&gt; where &lt;math&gt;M_i&lt;/math&gt; are the [[maxterm]]s to map (i.e., rows that have output 0 in the truth table).

===Karnaugh map===
[[File:Karnaugh6.gif|center|thumb|400px|K-map drawn on a torus, and in a plane. The dot-marked cells are adjacent.]]
[[File:K-map minterms A.svg|thumb|right|K-map construction. Instead of the output values (the rightmost values in the truth table), this diagram shows a decimal representation of the input ABCD (the leftmost values in the truth table), therefore it is not a Karnaugh map.]]
[[File:Torus from rectangle.gif|thumb|right|In three dimensions, one can bend a rectangle into a torus.]]

1)In this time the four input variables can be combined in 16 different ways, so the truth table has 16 rows, and the K-map has 16 positions. The K-map is therefore arranged in a 4&amp;nbsp;×&amp;nbsp;4 grid.

The row and column indices (shown across the top, and down the left side of the Karnaugh map) are ordered in [[Gray code]] rather than binary numerical order. Gray code ensures that only one variable changes between each pair of adjacent cells. Each cell of the completed Karnaugh map contains a binary digit representing the function's output for that combination ofÀ inputs.

After the Karnaugh map has been constructed, it is used to find one of the simplest possible forms — a [[Canonical form (Boolean expression)|canonical form]] — for the information in the truth table. Adjacent 1s in the Karnaugh map represent opportunities to simplify the expression. The minterms ('minimal terms') for the final expression are found by encircling groups of 1s in the map. Minterm groups must be rectangular and must have an area that is a power of two (i.e., 1,&amp;nbsp;2,&amp;nbsp;4,&amp;nbsp;8…). Minterm rectangles should be as large as possible without containing any 0s. Groups may overlap in order to make each one larger. The optimal groupings in the example below are marked by the green, red and blue lines, and the red and green groups overlap. The red group is a 2&amp;nbsp;×&amp;nbsp;2 square, the green group is a 4&amp;nbsp;×&amp;nbsp;1 rectangle, and the overlap area is indicated in brown.

The cells are often denoted by a shorthand which describes the logical value of the inputs that the cell covers. For example, {{mvar|AD}} would mean a cell which covers the 2x2 area where {{mvar|A}} and {{mvar|D}} are true, i.e. the cells numbered 13, 9, 15, 11 in the diagram above. On the other hand, {{mvar|A{{overline|D}}}} would mean the cells where {{mvar|A}} is true and {{mvar|D}} is false (that is, {{mvar|{{overline|D}}}} is true).

The grid is [[torus|toroidally]] connected, which means that rectangular groups can wrap across the edges (see picture). Cells on the extreme right are actually 'adjacent' to those on the far left, in the sense that the corresponding input values only differ by one bit's; similarly, so are those at the very top and those at the bottom. Therefore, {{mvar|A{{overline|D}}}} can be a valid term—it includes cells 12 and 8 at the top, and wraps to the bottom to include cells 10 and 14—as is {{mvar|{{overline|B}}, {{overline|D}}}}, which includes the four corners.

===Solution===
[[File:K-map 6,8,9,10,11,12,13,14.svg|thumb|Diagram showing two K-maps. The K-map for the function f(A, B, C, D) is shown as colored rectangles which correspond to minterms. The brown region is an overlap of the red 2×2 square and the green 4×1 rectangle. The K-map for the inverse of f is shown as gray rectangles, which correspond to maxterms.]]

Once the Karnaugh map has been constructed and the adjacent 1s linked by rectangular and square boxes, the algebraic minterms can be found by examining which variables stay the same within each box.

For the red grouping:
* ''A'' is the same and is equal to 1 throughout the box, therefore it should be included in the algebraic representation of the red minterm.
* ''B'' does not maintain the same state (it shifts from 1 to 0), and should therefore be excluded.
* ''C'' does not change. It is always 0, so its complement, NOT-C, should be included. Thus, {{mvar|{{overline|C}}}} should be included.
* ''D'' changes, so it is excluded.

Thus the first minterm in the Boolean sum-of-products expression is {{mvar|A{{overline|C}}}}.

For the green grouping, ''A'' and ''B'' maintain the same state, while ''C'' and ''D'' change. ''B'' is 0 and has to be negated before it can be included. The second term is therefore {{mvar|A{{overline|B}}}}. Note that it is acceptable that the green grouping overlaps with the red one.

In the same way, the blue grouping gives the term {{mvar|BC{{overline|D}}}}.

The solutions of each grouping are combined: the normal form of the circuit is &lt;math&gt;AB\overline{C} + A\overline{B} + BC\overline{D}&lt;/math&gt;.

Thus the Karnaugh map has guided a simplification of
:&lt;math&gt;\begin{align}
              f(A, B, C, D) = {} &amp;\overline{A}BC\overline{D} + A\overline{B}\,\overline{C}\,\overline{D} + A\overline{B}\,\overline{C}D + A\overline{B}C\overline{D} + {}\\
                                 &amp;A\overline{B}CD + AB\overline{C}\,\overline{D} + AB\overline{C}D + ABC\overline{D}\\
                            = {} &amp;AB\overline{C} + A\overline{B} + BC\overline{D}
\end{align}&lt;/math&gt;

It would also have been possible to derive this simplification by carefully applying the [[Boolean algebra (logic)#Axiomatizing Boolean algebra|axioms of boolean algebra]], but the time it takes to do that grows exponentially with the number of terms.

===Inverse===
The inverse of a function is solved in the same way by grouping the 0s instead.

The three terms to cover the inverse are all shown with grey boxes with different colored borders:
*brown: {{mvar|{{overline|A}}, {{overline|B}}}}
*gold: {{mvar|{{overline|A}}, {{overline|C}}}}
*blue: {{mvar|BCD}}

This yields the inverse:
:&lt;math&gt;\overline{f(A,B,C,D)} = \overline{A}\,\overline{B} + \overline{A}\,\overline{C} + BCD&lt;/math&gt;

Through the use of [[De Morgan's laws]], the [[product of sums]] can be determined:
:&lt;math&gt;\begin{align}
 f(A,B,C,D) &amp;= \overline{\overline{f(A,B,C,D)}} \\
            &amp;= \overline{\overline{A}\,\overline{B} + \overline{A}\,\overline{C} + BCD} \\
            &amp;= \left(\overline{\overline{A}\,\overline{B}}\right) \left(\overline{\overline{A}\,\overline{C}}\right) \left(\overline{BCD}\right) \\
            &amp;= \left(A + B\right)\left(A + C\right)\left(\overline{B} + \overline{C} + \overline{D}\right)
\end{align}&lt;/math&gt;

===Don't cares===
[[File:K-map 6,8,9,10,11,12,13,14 don't care.svg|thumb|The value of {{tmath|f(A,B,C,D)}} for ''ABCD'' = 1111 is replaced by a "don't care". This removes the green term completely and allows the red term to be larger. It also allows blue inverse term to shift and become larger]]

Karnaugh maps also allow easy minimizations of functions whose truth tables include "[[Don't-care (logic)|don't care]]" conditions. A "don't care" condition is a combination of inputs for which the designer doesn't care what the output is. Therefore, "don't care" conditions can either be included in or excluded from any rectangular group, whichever makes it larger. They are usually indicated on the map with a dash or X.

The example on the right is the same as the example above but with the value of ''f''(1,1,1,1) replaced by a "don't care". This allows the red term to expand all the way down and, thus, removes the green term completely.

This yields the new minimum equation:
:&lt;math&gt;f(A,B,C,D) = A + BC\overline{D}&lt;/math&gt;

Note that the first term is just {{mvar|A}}, not {{mvar|A{{overline|C}}}}. In this case, the don't care has dropped a term (the green rectangle); simplified another (the red one); and removed the race hazard (removing the yellow term as shown in the following section on race hazards).

The inverse case is simplified as follows:
:&lt;math&gt;\overline{f(A,B,C,D)} = \overline{A}\,\overline{B} + \overline{A}\,\overline{C} + \overline{A}D&lt;/math&gt;

==Race hazards==
===Elimination===
Karnaugh maps are useful for detecting and eliminating [[race condition]]s. Race hazards are very easy to spot using a Karnaugh map, because a race condition may exist when moving between any pair of adjacent, but disjoint, regions circumscribed on the map. However, because of the nature of Gray coding, ''adjacent'' has a special definition explained above – we're in fact moving on a torus, rather than a rectangle, wrapping around the top, bottom, and the sides.

* In the example [[Karnaugh map#Solution|above]], a potential race condition exists when ''C'' is 1 and ''D'' is 0, ''A'' is 1, and ''B'' changes from 1 to 0 (moving from the blue state to the green state). For this case, the output is defined to remain unchanged at 1, but because this transition is not covered by a specific term in the equation, a potential for a ''glitch'' (a momentary transition of the output to 0) exists.
* There is a second potential glitch in the same example that is more difficult to spot: when ''D'' is 0 and ''A'' and ''B'' are both 1, with C changing from 1 to 0 (moving from the blue state to the red state). In this case the glitch wraps around from the top of the map to the bottom.

[[File:K-map 6,8,9,10,11,12,13,14.svg|thumb|Race hazards are present in this diagram.]]
[[File:K-map 6,8,9,10,11,12,13,14 anti-race.svg|thumb|Above diagram with consensus terms added to avoid race hazards.]]

Whether glitches will actually occur depends on the physical nature of the implementation, and whether we need to worry about it depends on the application. In clocked logic, it is enough that the logic settles on the desired value in time to meet the timing deadline. In our example, we are not considering clocked logic.

In our case, an additional term of &lt;math&gt;A\overline{D}&lt;/math&gt; would eliminate the potential race hazard, bridging between the green and blue output states or blue and red output states: this is shown as the yellow region (which wraps around from the bottom to the top of the right half) in the adjacent diagram.

The term is [[logic redundancy|redundant]] in terms of the static logic of the system, but such redundant, or [[consensus theorem|consensus terms]], are often needed to assure race-free dynamic performance.

Similarly, an additional term of &lt;math&gt;\overline{A}D&lt;/math&gt; must be added to the inverse to eliminate another potential race hazard. Applying De Morgan's laws creates another product of sums expression for ''f'', but with a new factor of &lt;math&gt;\left(A + \overline{D}\right)&lt;/math&gt;.

===2-variable map examples===
The following are all the possible 2-variable, 2&amp;nbsp;×&amp;nbsp;2 Karnaugh maps. Listed with each is the minterms as a function of &lt;math&gt;\sum m()&lt;/math&gt; and the race hazard free (''see [[#Race hazards|previous section]]'') minimum equation. A minterm is defined as an expression that gives the most minimal form of expression of the mapped variables. All possible horizontal and vertical interconnected blocks can be formed. These blocks must be of the size of the powers of 2 (1, 2, 4, 8, 16, 32, ...). These expressions create a minimal logical mapping of the minimal logic variable expressions for the binary expressions to be mapped. Here are all the blocks with one field.

A block can be continued across the bottom, top, left, or right of the chart. That can even wrap beyond the edge of the chart for variable minimization. This is because each logic variable corresponds to each vertical column and horizontal row. A visualization of the k-map can be considered cylindrical. The fields at edges on the left and right are adjacent, and the top and bottom are adjacent. K-Maps for four variables must be depicted as a donut or torus shape. The four corners of the square drawn by the k-map are adjacent. Still more complex maps are needed for 5 variables and more. 
&lt;gallery perrow="5"&gt;
File:K-map 2x2 none.svg | &amp;Sigma;''m''(0); ''K'' = 0
File:K-map 2x2 1.svg | &amp;Sigma;''m''(1); ''K'' = ''A''′''B''′
File:K-map 2x2 2.svg | &amp;Sigma;''m''(2); ''K'' = ''AB''′
File:K-map 2x2 3.svg | &amp;Sigma;''m''(3); ''K'' = ''A''′''B''
File:K-map 2x2 4.svg | &amp;Sigma;''m''(4); ''K'' = ''AB''
File:K-map 2x2 1,2.svg | &amp;Sigma;''m''(1,2); ''K'' = ''B''′
File:K-map 2x2 1,3.svg | &amp;Sigma;''m''(1,3); ''K'' = ''A''′
File:K-map 2x2 1,4.svg | &amp;Sigma;''m''(1,4); ''K'' = ''A''′''B''′ + ''AB''
File:K-map 2x2 2,3.svg | &amp;Sigma;''m''(2,3); ''K'' = ''AB''′ + ''A''′''B''
File:K-map 2x2 2,4.svg | &amp;Sigma;''m''(2,4); ''K'' = ''A''
File:K-map 2x2 3,4.svg | &amp;Sigma;''m''(3,4); ''K'' = ''B''
File:K-map 2x2 1,2,3.svg | &amp;Sigma;''m''(1,2,3); ''K'' = ''A''' + ''B''′
File:K-map 2x2 1,2,4.svg | &amp;Sigma;''m''(1,2,4); ''K'' = ''A'' + ''B''′
File:K-map 2x2 1,3,4.svg | &amp;Sigma;''m''(1,3,4); ''K'' = ''A''′ + ''B''
File:K-map 2x2 2,3,4.svg | &amp;Sigma;''m''(2,3,4); ''K'' = ''A'' + ''B''
File:K-map 2x2 1,2,3,4.svg | &amp;Sigma;''m''(1,2,3,4); ''K'' = 1
&lt;/gallery&gt;

=={{anchor|Marquand|Harvard|Veitch|Svoboda|Händler|Kortum}}Other graphical methods==
Alternative graphical minimization methods include:
* '''Marquand diagram''' (1881) by [[Allan Marquand]] (1853–1924)&lt;ref name="Marquand_1881"/&gt;&lt;ref name="Brown_2012"/&gt;&lt;!-- a precursor to Karnaugh maps, needs to be covered explicitly inhere or in a separate article - until then parked here for completeness --&gt;
* ''[[Harvard minimizing chart]]'' (1951) by [[Howard H. Aiken]] and Martha L. Whitehouse of the [[Harvard Computation Laboratory]]&lt;ref name="Aiken_1952"/&gt;&lt;ref name="Karnaugh_1953"/&gt;&lt;ref name="Phister_1959"/&gt;&lt;ref name="Curtis_1962"/&gt;
* ''[[Veitch chart]]'' (1952) by [[Edward Veitch]] (1924–2013)&lt;ref name="Veitch_1952"/&gt;&lt;ref name="Brown_2012"/&gt;&lt;!-- a precursor to Karnaugh maps, needs to be covered explicitly inhere or in a separate article -  until then parked here for completeness --&gt;
* Svoboda's graphical aids (1956) and ''[[triadic map]]'' by [[Antonín Svoboda (computer scientist)|Antonín Svoboda]] (1907–1980)&lt;ref name="Svoboda_1956_1"/&gt;&lt;ref name="Svoboda_1956_2"/&gt;&lt;ref name="Steinbuch-Weber_1974"/&gt;&lt;ref name="Svoboda_1979"/&gt;
* ''[[Händler circle graph]]'' (aka &lt;!-- Händler-circle graph, Handler-circle graph, --&gt;{{lang|de|Händler'scher Kreisgraph}}, {{lang|de|Kreisgraph nach Händler}}, {{lang|de|Händler-Kreisgraph}}, {{lang|de|Händler-Diagramm}}, ''{{sic|{{lang|de|Minimisierungsgraph}}|expected={{lang|de|Minimierungsgraph}}}}'') (1958) by [[Wolfgang Händler]] (1920–1998)&lt;ref name="Händler_1958"/&gt;&lt;ref name="Colloquium_1960"/&gt;&lt;ref name="Steinbuch-Wagner_1967"/&gt;&lt;ref name="Steinbuch-Weber_1974"/&gt;&lt;ref name="Hotz_1974"/&gt;&lt;ref name="ISER_1"/&gt;&lt;ref name="ISER_2"/&gt;&lt;ref name="Broy_1990"/&gt;&lt;ref name="Bauer-Wirsing_1991"/&gt;
* Graph method (1965) by {{ill|Herbert Kortum|de}} (1907–1979)&lt;ref name="Kortum_1964_12"/&gt;&lt;ref name="Kortum_1965_1"/&gt;&lt;ref name="Kortum_1965_3"/&gt;&lt;ref name="Kortum_1965_5"/&gt;&lt;ref name="Kortum_1967_6"/&gt;&lt;ref name="Kortum_1966_12"/&gt;&lt;ref name="Tafel_1971"/&gt;

==See also==
* [[Circuit minimization]]
* [[Espresso heuristic logic minimizer]]
* [[List of Boolean algebra topics]]
* [[Quine–McCluskey algorithm]]
* [[Algebraic normal form]] (ANF)
* [[Ring sum normal form]] (RSNF)
* [[Zhegalkin normal form]]
* [[Reed–Muller expansion]]
* [[Venn diagram]]
* [[Punnett square]] (a similar diagram in biology)

==References==
{{reflist|refs=
&lt;ref name="Aiken_1952"&gt;{{cite book |title=Synthesis of electronic computing and control circuits |orig-year=January 1951 |date=1952 |edition=second printing, revised |chapter=Chapter V: Minimizing charts |pages=preface, 50–67 |author-first1=Howard H. |author-last1=Aiken |author-link1=Howard H. Aiken |author-first2=Gerrit |author-last2=Blaauw |author-link2=Gerrit Blaauw |author-first3=William |author-last3=Burkhart |author-first4=Robert J. |author-last4=Burns |author-first5=Lloyd |author-last5=Cali |author-first6=Michele |author-last6=Canepa |author-first7=Carmela M. |author-last7=Ciampa |author-first8=Charles A. |author-last8=Coolidge, Jr. |author-first9=Joseph R. |author-last9=Fucarile |author-first10=J. Orten |author-last10=Gadd, Jr. |author-first11=Frank F. |author-last11=Gucker |author-first12=John A. |author-last12=Harr |author-first13=Robert L. |author-last13=Hawkins |author-first14=Miles V. |author-last14=Hayes |author-first15=Richard |author-last15=Hofheimer |author-first16=William F. |author-last16=Hulme |author-first17=Betty L. |author-last17=Jennings |author-first18=Stanley A. |author-last18=Johnson |author-first19=Theodore |author-last19=Kalin |author-first20=Marshall |author-last20=Kincaid |author-first21=E. Edward |author-last21=Lucchini |author-first22=William |author-last22=Minty |author-first23=Benjamin L. |author-last23=Moore |author-first24=Joseph |author-last24=Remmes |author-first25=Robert J. |author-last25=Rinn |author-first26=John W. |author-last26=Roche |author-first27=Jacquelin |author-last27=Sanbord |author-first28=Warren L. |author-last28=Semon |author-first29=Theodore |author-last29=Singer |author-first30=Dexter |author-last30=Smith |author-first31=Leonard |author-last31=Smith |author-first32=Peter F. |author-last32=Strong |author-first33=Helene V. |author-last33=Thomas |author-first34=An |author-last34=Wang |author-link34=An Wang |author-first35=Martha L. |author-last35=Whitehouse |author-first36=Holly B. |author-last36=Wilkins |author-first37=Robert E. |author-last37=Wilkins |author-first38=Way Dong |author-last38=Woo |author-first39=Elbert P. |author-last39=Little |author-first40=M. Scudder |author-last40=McDowell |location=Write-Patterson Air Force Base |publisher=[[Harvard University Press]] (Cambridge, Massachusetts, USA) / Geoffrey Cumberlege Oxford University Press (London) |url=https://archive.org/stream/in.ernet.dli.2015.509288/2015.509288.Synthesis-Of#page/n6/mode/1up |access-date=2017-04-16 |quote=[…] Martha Whitehouse constructed the minimizing charts used so profusely throughout this book, and in addition  prepared minimizing charts of seven and eight variables for experimental purposes. […] Hence, the present writer is obliged to record that the general algebraic approach, the switching function, the vacuum-tube operator, and the minimizing chart are his proposals, and that he is responsible for their inclusion herein. […]}} (NB. Work commenced in April 1948.)&lt;/ref&gt;
&lt;ref name="Phister_1959"&gt;{{cite book |title=Logical design of digital computers |author-first=Montgomery |author-last=Phister, Jr. |publisher=[[John Wiley &amp; Sons Inc.]] |date=1959 |orig-year=December 1958 |location=New York, USA |isbn=0471688053&lt;!-- |id=ISBN978-0471688051? --&gt; |pages=75–83 |url=https://archive.org/stream/in.ernet.dli.2015.74854/2015.74854.Logical-Design-Of-Digital-Computers#page/n0/mode/1up}}&lt;/ref&gt;
&lt;ref name="Curtis_1962"&gt;{{cite book |title=A new approach to the design of switching circuits |author-first=H. Allen |author-last=Curtis |publisher=[[D. van Nostrand Company, Inc.]] |date=1962 |location=Princeton, New Jersey, USA |series=Bell Laboratories Series}}&lt;/ref&gt;
&lt;ref name="Karnaugh_1953"&gt;{{cite journal |author-last=Karnaugh |author-first=Maurice |author-link=Maurice Karnaugh |title=The Map Method for Synthesis of Combinational Logic Circuits |journal=[[Transactions of the American Institute of Electrical Engineers]] part I |volume=72 |issue=9 |pages=593–599 |date=November 1953 |orig-year=1953-04-23&lt;!-- available for printing --&gt;, 1953-03-17&lt;!-- sent in --&gt; |id=Paper 53-217 |doi=10.1109/TCE.1953.6371932 |url=http://philectrosophy.com/documents/The%20Map%20Method%20For%20Synthesis%20of.pdf |access-date=2017-04-16 |dead-url=no |archive-url=https://web.archive.org/web/20170416232229/http://philectrosophy.com/documents/The%20Map%20Method%20For%20Synthesis%20of.pdf |archive-date=2017-04-16}} (NB. Also contains a short review by [[Samuel H. Caldwell]].)&lt;/ref&gt;
&lt;ref name="Brown_2012"&gt;{{cite book |title=Boolean Reasoning - The Logic of Boolean Equations |author-first=Frank Markham |author-last=Brown |edition=&lt;!-- 2012 --&gt;reissue of 2nd |publisher=[[Dover Publications, Inc.]] |location=Mineola, New York |date=2012 |orig-year=2003, 1990 |isbn=978-0-486-42785-0}} [&lt;!-- 1st edition --&gt;http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf&lt;!-- https://web.archive.org/web/20170416231752/http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf --&gt;]&lt;/ref&gt;
&lt;ref name="Wakerly_1994"&gt;{{cite book |title=Digital Design: Principles &amp; Practices |author-last=Wakerly |author-first=John F. |year=1994 |publisher=[[Prentice Hall]] |location=New Jersey, USA |isbn=0-13-211459-3 |pages=222, 48–49}} (NB. The two page sections taken together say that K-maps are labeled with [[Gray code]]. The first section says that they are labeled with a code that changes only one bit between entries and the second section says that such a code is called Gray code.)&lt;/ref&gt;
&lt;ref name="Belton_1998"&gt;{{cite web |author-first=David |author-last=Belton |date=April 1998 |url=http://www.ee.surrey.ac.uk/Projects/Labview/minimisation/karrules.html |title=Karnaugh Maps – Rules of Simplification |access-date=2009-05-30 |dead-url=no |archive-url=https://web.archive.org/web/20170418140519/http://www.ee.surrey.ac.uk/Projects/Labview/minimisation/karrules.html |archive-date=2017-04-18}}&lt;/ref&gt;
&lt;ref name="Dodge_2016"&gt;{{cite web |title=Simplifying Logic Circuits with Karnaugh Maps |author-first=Nathan B. |author-last=Dodge |date=September 2015 |publisher=[[The University of Texas at Dallas]], [[Erik Jonsson School of Engineering and Computer Science]] |url=http://www.utdallas.edu/~dodge/EE2310/lec5.pdf |access-date=2017-04-18 |dead-url=no |archive-url=https://web.archive.org/web/20170418140824/https://www.utdallas.edu/~dodge/EE2310/lec5.pdf |archive-date=2017-04-18}}&lt;/ref&gt;
&lt;ref name="Cook_2012"&gt;{{cite web |author-last=Cook |author-first=Aaron |title=Using Karnaugh Maps to Simplify Code |publisher=Quantum Rarity |url=http://www.quantumrarity.com/archives/255 |access-date=2012-10-07 |dead-url=no |archive-url=https://web.archive.org/web/20170418141624/http://www.quantumrarity.com/archives/255 |archive-date=2017-04-18}}&lt;/ref&gt;
&lt;ref name="Marquand_1881"&gt;{{cite journal |title=XXXIII: On Logical Diagrams for ''n'' terms |author-first=Allan |author-last=Marquand |author-link=Allan Marquand |journal=[[The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science]] |issue=75 |series=5 |date=1881 |volume=12 |doi=10.1080/14786448108627104 |pages=266–270 |url=http://www.tandfonline.com/doi/abs/10.1080/14786448108627104 |access-date=2017-05-15}} (NB. Quite many secondary sources erroneously cite this work as "A logical diagram for ''n'' terms" or "On a logical diagram for ''n'' terms".)&lt;/ref&gt;
&lt;ref name="Veitch_1952"&gt;{{cite journal |author-last=Veitch |author-first=Edward W. |author-link=Edward Veitch |title=A Chart Method for Simplifying Truth Functions |journal=ACM Annual Conference/Annual Meeting: Proceedings of the 1952 ACM Annual Meeting (Pittsburg) |publisher=[[Association for Computing Machinery|ACM]] |location=New York, USA |pages=127–133 |date=1952-05-03 |orig-year=1952-05-02 |doi=10.1145/609784.609801}}&lt;/ref&gt;
&lt;ref name="Svoboda_1956_1"&gt;{{cite book |title=Graficko-mechanické pomůcky užívané při analyse a synthese kontaktových obvodů |trans-title=Utilization of graphical-mechanical aids for the analysis and synthesis of contact circuits |journal=Stroje na zpracování informací [Symphosium IV on information processing machines] |author-first=Antonín |author-last=Svoboda |author-link=Antonín Svoboda (computer scientist) |location=Prague |publisher=Czechoslovak Academy of Sciences, Research Institute of Mathematical Machines |language=Czech |date=1956 |volume=IV |pages=9–21}}&lt;/ref&gt;
&lt;ref name="Svoboda_1956_2"&gt;{{cite book |title=Graphical Mechanical Aids for the Synthesis of Relay Circuits |journal=Nachrichtentechnische Fachberichte (NTF), Beihefte der Nachrichtentechnischen Zeitschrift (NTZ) |publisher=[[Vieweg-Verlag]] |location=Braunschweig, Germany |author-first=Antonín |author-last=Svoboda |author-link=Antonín Svoboda (computer scientist) |date=1956}}&lt;/ref&gt;
&lt;ref name="Svoboda_1979"&gt;{{cite book |title=Advanced Logical Circuit Design Techniques |author-first1=Antonín |author-last1=Svoboda |author-link1=Antonín Svoboda (computer scientist) |author-first2=Donnamaie E. |author-last2=White |date=2016 |orig-year=1979-08-01 |edition=retyped electronic reissue |publisher=[[Garland STPM Press]] (original issue) / WhitePubs (reissue) |isbn=978-0-8240-7014-4&lt;!-- 1990 1st issue --&gt; |url=http://www.donnamaie.com/Advanced_logic_ckt/Advanced_Logical_Circuit_Design_Techniques%20sm.pdf |access-date=2017-04-15 |dead-url=no |archive-url=https://web.archive.org/web/20170414163013/http://www.donnamaie.com/Advanced_logic_ckt/Advanced_Logical_Circuit_Design_Techniques%20sm.pdf |archive-date=2017-04-14}} [http://www.donnamaie.com/&lt;!-- https://web.archive.org/web/20170415220158/http://www.donnamaie.com/ --&gt;] [https://books.google.com/books?id=g3uzAAAAIAAJ]&lt;/ref&gt;
&lt;ref name="Händler_1958"&gt;{{cite book |title=Ein Minimisierungsverfahren zur Synthese von Schaltkreisen (Minimisierungsgraphen) |language=German |author-first=Wolfgang |author-last=Händler |author-link=Wolfgang Händler |publisher=[[Technische Hochschule Darmstadt]] |date=1958 |id=D&amp;nbsp;17 |type=Dissertation |url=https://books.google.com/books?id=D58TAQAAIAAJ}} [https://www.tib.eu/de/suchen/id/TIBKAT%3A044782241/Ein-Minimisierungsverfahren-zur-Synthese-von-Schaltkreisen/] (NB. Although written by a German, the title contains an [[anglicism]]; the correct German term would be "Minimierung" instead of "Minimisierung".)&lt;/ref&gt;
&lt;ref name="Hotz_1974"&gt;{{cite book |title=Schaltkreistheorie |language=German |trans-title=Switching circuit theory |author-first=Günter |author-last=Hotz |publisher=[[Walter de Gruyter &amp; Co.]] |series=DeGruyter Lehrbuch |date=1974 |isbn=3-11-00-2050-5 |page=117 |quote=[…] Der Kreisgraph von ''[[Wolfgang Händler|Händler]]'' ist für das Auffinden von [[prime implicant|Primimplikanten]] gut brauchbar. Er hat den Nachteil, daß er schwierig zu zeichnen ist. Diesen Nachteil kann man allerdings durch die Verwendung von Schablonen verringern. […] [The circle graph by ''Händler'' is well suited to find [[prime implicant]]s. A disadvantage is that it is difficult to draw. This can be remedied using stencils.]}}&lt;/ref&gt;
&lt;ref name="ISER_1"&gt;{{cite web |title=Informatik Sammlung Erlangen (ISER) |date=2012-03-13 |publisher=[[Friedrich-Alexander Universität]] |location=Erlangen, Germany |language=German |url=https://www.rrze.fau.de/wir-ueber-uns/kooperationen/iser.shtml |access-date=2017-04-12 |dead-url=yes |archive-url=https://web.archive.org/web/20170516154655/https://www.rrze.fau.de/wir-ueber-uns/kooperationen/iser.shtml |archive-date=2017-05-16}} (NB. Shows a picture of a {{lang|de|Kreisgraph}} by ''[[Wolfgang Händler|Händler]]''.)&lt;/ref&gt;
&lt;ref name="ISER_2"&gt;{{cite web |title=Informatik Sammlung Erlangen (ISER) - Impressum |date=2012-03-13 |publisher=[[Friedrich-Alexander Universität]] |location=Erlangen, Germany |language=German |url=http://www.iser.uni-erlangen.de:80/index.php?ort_id=327&amp;tree=0 |access-date=2017-04-15 |dead-url=no |archive-url=https://web.archive.org/web/20120226004316/http://www.iser.uni-erlangen.de/index.php?ort_id=327&amp;tree=0 |archive-date=2012-02-26}} (NB. Shows a picture of a {{lang|de|Kreisgraph}} by ''[[Wolfgang Händler|Händler]]''.)&lt;/ref&gt;
&lt;ref name="Broy_1990"&gt;{{cite book |title=Informatik und Mathematik |language=German |trans-title=Computer Sciences and Mathematics |chapter=Geschichte der Schaltalgebra |trans-chapter=History of circuit switching algebra |author-first=Heinz |author-last=Zemanek |author-link=Heinz Zemanek |editor-first=Manfred |editor-last=Broy |editor-link=Manfred Broy |orig-year=1990 |date=2013 |publisher=[[Springer-Verlag]] |isbn=9783642766770 |pages=43–72 |url=https://books.google.com/books?id=y5GfBgAAQBAJ |quote=Einen Weg besonderer Art, der damals zu wenig beachtet wurde, wies [[Wolfgang Händler|W. Händler]] in seiner Dissertation […] mit einem Kreisdiagramm. […]}} [https://link.springer.com/chapter/10.1007%2F978-3-642-76677-0_3] (NB. Collection of papers at a colloquium held at the [[Bayerische Akademie der Wissenschaften]],
1989-06-12/14, in honor of [[Friedrich L. Bauer]].)&lt;/ref&gt;
&lt;ref name="Bauer-Wirsing_1991"&gt;{{cite book |author-first1=Friedrich Ludwig |author-last1=Bauer |author-link1=Friedrich Ludwig Bauer |author-first2=Martin |author-last2=Wirsing |author-link2=Martin Wirsing |title=Elementare Aussagenlogik |publisher=[[Springer-Verlag]] |language=German |location=Berlin / Heidelberg |date=March 1991 |isbn=978-3-540-52974-3 |pages=54–56, 71, 112–113, 138–139 |url=https://books.google.com/books?id=Ff58BwAAQBAJ |quote=[…] handelt es sich um ein [[Wolfgang Händler|Händler]]-Diagramm […], mit den Würfelecken als Ecken eines 2&lt;sup&gt;m&lt;/sup&gt;-gons. […] Abb. […] zeigt auch Gegenstücke für andere Dimensionen. Durch waagerechte Linien sind dabei Tupel verbunden, die sich nur in der ersten Komponente unterscheiden; durch senkrechte Linien solche, die sich nur in der zweiten Komponente unterscheiden; durch 45°-Linien und 135°-Linien solche, die sich nur in der dritten Komponente unterscheiden usw. Als Nachteil der Händler-Diagramme wird angeführt, daß sie viel Platz beanspruchen. […]}}&lt;/ref&gt;
&lt;ref name="Colloquium_1960"&gt;{{cite book |editor-first1=Ernst Ferdinand |editor-last1=Peschl |editor-link1=Ernst Ferdinand Peschl |editor-first2=Heinz |editor-last2=Unger |editor-link2=:de:Heinz Unger (Mathematiker) |title=Colloquium über Schaltkreis- und Schaltwerk-Theorie - Vortragsauszüge vom 26. bis 28. Oktober 1960 in Bonn - Band 3 von Internationale Schriftenreihe zur Numerischen Mathematik [International Series of Numerical Mathematics] (ISNM) |language=German |volume=3 |chapter=Zum Gebrauch von Graphen in der Schaltkreis- und Schaltwerktheorie |author-first=Wolfgang |author-last=Händler |author-link=Wolfgang Händler |location=Institut für Angewandte Mathematik, [[Universität Saarbrücken]], Rheinisch-Westfälisches Institut für Instrumentelle Mathematik |publisher=[[Springer Basel AG]] / [[Birkhäuser Verlag Basel]] |date=2013 |orig-year=1961 |isbn=978-3-0348-5771-0 |doi=10.1007/978-3-0348-5770-3 |url=https://books.google.com/books?id=myTnoAEACAAJ |pages=169–198}} [https://link.springer.com/chapter/10.1007%2F978-3-0348-5770-3_10]&lt;/ref&gt;
&lt;ref name="Kortum_1964_12"&gt;{{cite journal |title=Minimierung von Kontaktschaltungen durch Kombination von Kürzungsverfahren und Graphenmethoden |trans-title=Minimization of contact circuits by combination of reduction procedures and graphical methods |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1965 |volume=8 |issue=12 |pages=421–425 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966001170/MINIMIERUNG-VON-KONTAKTSCHALTUNGEN-DURCH-KOMBINATION/}} [https://www.tib.eu/en/search/id/ei-backfile%3Ac84_64eb63f914c231eeM6f1319817173212/Minimization-of-contact-circuits-by-combination/]&lt;/ref&gt;
&lt;ref name="Kortum_1965_1"&gt;{{cite journal |title=Konstruktion und Minimierung von Halbleiterschaltnetzwerken mittels Graphentransformation |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=1 |pages=9–12 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966002519/KONSTRUKTION-UND-MINIMIERUNG-VON-HALBLEITER-SCHALTNETZWERKEN/}}&lt;/ref&gt;
&lt;ref name="Kortum_1965_3"&gt;{{cite journal |title=Weitere Bemerkungen zur Minimierung von Schaltnetzwerken mittels Graphenmethoden |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=3 |pages=96–102 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966002896/WEITERE-BEMERKUNGEN-ZUR-MINIMIERUNG-VON-SCHALTNETZWERKEN/}}&lt;/ref&gt;
&lt;ref name="Kortum_1965_5"&gt;{{cite journal |title=Weitere Bemerkungen zur Behandlung von Schaltnetzwerken mittels Graphen. Konstruktion von vermaschten Netzwerken (Brückenschaltungen) |trans-title=Further remarks on treatment of switching networks by means of graphs |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=5 |pages=151–157 |issn=0026-0347 |id={{CODEN|MSRGAN}}}} {{cite journal |title=Weitere Bemerkungen zur Behandlung von Schaltnetzwerken mittels Graphen |trans-title=Further remarks on treatment of switching networks by means of graphs |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=Regelungstechnik |language=German |publisher= |date=1965 |volume=10 |issue=5 |pages=33–39 |location=10. Internationales Wissenschaftliches Kolloquium, Ilmenau. Technische Hochschule |url=https://www.tib.eu/en/search/id/ei-backfile%3Ac84_a3574af8cb8d6293M72eb19817173212/Further-remarks-on-treatment-of-switching-networks/}}&lt;/ref&gt;
&lt;ref name="Kortum_1966_12"&gt;{{cite journal |title=Zur Minimierung von Schaltsystemen |trans-title=Minimization of switching circuits |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=Wissenschaftliche Zeitschrift der TU Ilmenau |location=Jena |language=German |publisher=Technische Hochschule für Elektrotechnik Ilmenau / Forschungsstelle für Meßtechnik und Automatisierung der Deutschen Akademie der Wissenschaften |date=1966&lt;!-- one source states: 1965 --&gt; |volume=12 |issue=2&lt;!-- one sources states: 2, 3. --&gt; |pages=181–186 |url=https://www.tib.eu/en/search/id/ei-backfile%3Ac84_125e37df8f0a3cd4eM7a8919817173212/Minimization-of-switching-circuits/}}&lt;/ref&gt;
&lt;ref name="Kortum_1967_6"&gt;{{cite journal |title=Über zweckmäßige Anpassung der Graphenstruktur diskreter Systeme an vorgegebene Aufgabenstellungen |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1967 |volume=10 |issue=6 |pages=208–211 |issn=0026-0347 |id={{CODEN|MSRGAN}}}}&lt;/ref&gt;
&lt;ref name="Tafel_1971"&gt;{{cite book |title=Einführung in die digitale Datenverarbeitung |language=German |trans-title=Introduction to digital information processing |chapter=4.3.5. Graphenmethode zur Vereinfachung von Schaltfunktionen |author-first=Hans Jörg |author-last=Tafel |publisher=[[Carl Hanser Verlag]] |date=1971 |location=[[RWTH]], Aachen, Germany |publication-place=Munich, Germany |isbn=3-446-10569-7 |pages=98–105, 107–113}}&lt;/ref&gt;
&lt;ref name="Steinbuch-Wagner_1967"&gt;{{cite book |title=Taschenbuch der Nachrichtenverarbeitung |language=German |editor-first1=Karl W. |editor-last1=Steinbuch |editor-link1=Karl W. Steinbuch |editor-first2=Siegfried W. |editor-last2=Wagner |author-first1=Erich R. |author-last1=Berger |author-first2=Wolfgang |author-last2=Händler |author-link2=Wolfgang Händler |date=1967 |orig-year=1962 |edition=2 |publisher=[[Springer-Verlag OHG]] |location=Berlin, Germany |id=Title No. 1036 |lccn=67-21079 |pages=64, 1034–1035, 1036, 1038 |quote=[…] Übersichtlich ist die Darstellung nach ''[[Wolfgang Händler|Händler]]'', die sämtliche Punkte, numeriert nach dem ''[[Gray-Code]]'' […], auf dem Umfeld eines Kreises anordnet. Sie erfordert allerdings sehr viel Platz. […] [''Händler's'' illustration, where all points, numbered according to the ''[[Gray code]]'', are arranged on the circumference of a circle, is easily comprehensible. It needs, however, a lot of space.]}}&lt;/ref&gt;
&lt;ref name="Steinbuch-Weber_1974"&gt;{{cite book |title=Taschenbuch der Informatik - Band II - Struktur und Programmierung von EDV-Systemen |language=German |editor-first1=Karl W. |editor-last1=Steinbuch |editor-link1=Karl W. Steinbuch |editor-first2=Wolfgang |editor-last2=Weber |editor-first3=Traute |editor-last3=Heinemann |date=1974 |orig-year=1967 |edition=3 |volume=2 |work=Taschenbuch der Nachrichtenverarbeitung |publisher=[[Springer-Verlag]] |location=Berlin, Germany |isbn=3-540-06241-6 |lccn=73-80607 |pages=25, 62, 96, 122–123, 238}}&lt;/ref&gt;
}}

==Further reading==
* {{cite book |author-last=Katz |author-first=Randy Howard |author-link=Randy Howard Katz |title=Contemporary Logic Design |orig-year=1994 |publisher=[[The Benjamin/Cummings Publishing Company]] |isbn=0-8053-2703-7 |doi=10.1016/0026-2692(95)90052-7 |pages=70–85 |year=1998}}
* {{cite book |author-last=Vingron |author-first=Shimon Peter |title=Switching Theory: Insight Through Predicate Logic |orig-year=2003-11-05 |publisher=[[Springer-Verlag]] |location=Berlin, Heidelberg, New York |isbn=3-540-40343-4 |pages=57–76 |chapter=Karnaugh Maps |year=2004}}
* {{cite book |author-last=Wickes |author-first=William E. |title=Logic Design with Integrated Circuits |year=1968 |publisher=[[John Wiley &amp; Sons]] |location=New York, USA |lccn=68-21185 |pages=36–49 |quote=A refinement of the [[Venn diagram]] in that circles are replaced by squares and arranged in a form of matrix. The Veitch diagram labels the squares with the [[minterm]]s. [[Maurice Karnaugh|Karnaugh]] assigned 1s and 0s to the squares and their labels and deduced the numbering scheme in common use.}}
* {{cite web |title=Reed-Muller Logic |work=Logic 101 |at=Part 3 |author-first=Clive "Max" |author-last=Maxfield |date=2006-11-29 |publisher=[[EETimes]] |url=http://www.eetimes.com/author.asp?section_id=216&amp;doc_id=1274545 |access-date=2017-04-19 |dead-url=no |archive-url=https://web.archive.org/web/20170419235904/http://www.eetimes.com/author.asp?section_id=216&amp;doc_id=1274545 |archive-date=2017-04-19}}

== External links ==
{{sisterlinks}}
* [http://gandraxa.com/detect_overlapping_subrectangles.xml Detect Overlapping Rectangles], by Herbert Glarner.
* [http://www.sccs.swarthmore.edu/users/06/adem/engin/e15/lab1/ Using Karnaugh maps in practical applications], Circuit design project to control traffic lights.
* [http://fullchipdesign.com/kmap2v.htm K-Map Tutorial for 2,3,4 and 5 variables ]
* [http://www.generalnumbers.com/karnaugh_application1.html Karnaugh Map Example]
* [http://iris.elf.stuba.sk/JEEEC/data/pdf/07-08_105-08.pdf POCKET–PC BOOLEAN FUNCTION SIMPLIFICATION, Ledion Bitincka — George E. Antoniou]

[[Category:Boolean algebra]]
[[Category:Diagrams]]
[[Category:Electronics optimization]]
[[Category:Logic in computer science]]</text>
      <sha1>m4w64yrhnuw32j8rn5nfz2x8r90vt7g</sha1>
    </revision>
  </page>
  <page>
    <title>Leading-one detector</title>
    <ns>0</ns>
    <id>55974779</id>
    <revision>
      <id>813851465</id>
      <parentid>813851369</parentid>
      <timestamp>2017-12-05T15:50:20Z</timestamp>
      <contributor>
        <username>ToThAc</username>
        <id>30690290</id>
      </contributor>
      <comment>added [[Category:Binary arithmetic]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="393">{{unreferenced|date=December 2017}}
A '''leading-one detector''' is an [[electronic circuit]] commonly found in [[central processing unit]]s and especially their [[arithmetic logic unit]]s (ALUs). It is used to detect whether the leading bit in a [[computer word]] is 1 or 0, which is used to perform basic binary tests like &lt;code&gt;IF A&gt;0&lt;/code&gt;.

{{compu-stub}}

[[Category:Binary arithmetic]]</text>
      <sha1>cuows40sf5l1ra7r1iap435n56e1isz</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematicians (Z)</title>
    <ns>0</ns>
    <id>5971846</id>
    <revision>
      <id>871127830</id>
      <parentid>869901159</parentid>
      <timestamp>2018-11-29T03:10:09Z</timestamp>
      <contributor>
        <username>Mathbot</username>
        <id>234358</id>
      </contributor>
      <comment>Daily update. See [[User:Mathbot/Changes to mathlists]] for changes.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9059">__NOTOC__
{{MathTopicTOC}}

== Zaa ==

* [[Adriaan Cornelis Zaanen|Zaanen, Adriaan Cornelis]] (Netherlands, 1913–2003)
* [[Yevgeny Zababakhin|Zababakhin, Yevgeny]] (Soviet Union/Russia, 1917–1984)
* [[Ignacy Zaborowski|Zaborowski, Ignacy]] (Poland, 1754–1803)
* [[Richard Zach|Zach, Richard]] (?, ?–?)
* [[Stathis Zachos|Zachos, Stathis]] (Greece, born 1947)
* [[Abraham Zacuto|Zacuto, Abraham]] (Portugal, 1452–1515)
* [[Lotfi A. Zadeh|Zadeh, Lotfi A.]] (Azerbaijan/Iranian Azerbaijan/USA, 1921–2017)
* [[Lotfi Asker Zadeh|Zadeh, Lotfi Asker]] (Azerbaijan, born 1921)
* [[Pedro E. Zadunaisky|Zadunaisky, Pedro E.]] (Argentina, 1917–2009)
* [[Jafar Zafarani|Zafarani, Jafar]] (Iran, born 1947)
* [[Don Zagier|Zagier, Don]] (USA, born 1951)
* [[Alexandru Zaharescu|Zaharescu, Alexandru]] (Romania, born 1961)
* [[Mohammad Mehdi Zahedi|Zahedi, Mohammad Mehdi]] (Iran, born 1953)
* [[Sara Zahedi|Zahedi, Sara]] (Iran/Sweden, born 1981)
* [[Karel Zahradnik|Zahradnik, Karel]] (Czech Republic, 1848–1916)
* [[Miloš Zahradník|Zahradník, Miloš]] (Czech Republic, ?–?)
* [[Zhu Zaiyu|Zaiyu, Zhu]] (China, 1536–1611)
* [[Władysław Zajączkowski|Zajączkowski, Władysław]] (Poland, 1837–1898)
* [[Fyodor Zak|Zak, Fyodor]] (Russia, born 1949)
* [[Moshe Zakai|Zakai, Moshe]] (?, 1926–2015)
* [[Vladimir Zakalyukin|Zakalyukin, Vladimir]] (Russia, 1951–2011)
* [[Hossein Zakeri|Zakeri, Hossein]] (Iran/Iranian Azerbaijan, born 1942)
* [[Vladimir Zakharov (mathematician)|Zakharov, Vladimir (mathematician)]] (Russia, ?–?)
* [[Egon Zakrajšek|Zakrajšek, Egon]] (Slovenia, 1941–2002)
* [[Lawrence Zalcman|Zalcman, Lawrence]] (Israel, ?–?)
* [[Zygmunt Zalcwasser|Zalcwasser, Zygmunt]] (Poland, 1898–1943)
* [[Victor Zalgaller|Zalgaller, Victor]] (Israel/Russia/Soviet Union, born 1920)
* [[Arif Zaman|Zaman, Arif]] (Pakistan, ?–?)
* [[Marc Zamansky|Zamansky, Marc]] (France, 1916–1996)
* [[William Zame|Zame, William]] (USA, ?–?)
* [[Israel Zamosz|Zamosz, Israel]] (?, ?–1772)

== Zan ==

* [[Umberto Zannier|Zannier, Umberto]] (Italy, born 1957)
* [[Hans Zantema|Zantema, Hans]] (Netherlands, born 1956)
* [[Guido Zappa|Zappa, Guido]] (Italy, 1915–2015)
* [[Kazimierz Zarankiewicz|Zarankiewicz, Kazimierz]] (Poland, 1902–1959)
* [[Eduardo Héctor Zarantonello|Zarantonello, Eduardo Héctor]] (Argentina, 1918–2010)
* [[Hasan bey Zardabi|bey Zardabi, Hasan]] (Azerbaijan, 1837–1907)
* [[Stanisław Zaremba (mathematician)|Zaremba, Stanisław]] (Poland, 1863–1942)
* [[Wojciech Zaremba|Zaremba, Wojciech]] (Poland, born 1988)
* [[Thaleia Zariphopoulou|Zariphopoulou, Thaleia]] (Greece, born 1962)
* [[Oscar Zariski|Zariski, Oscar]] (USA, 1899–1986)
* [[Abū Ishāq Ibrāhīm al-Zarqālī|al-Zarqālī, Abū Ishāq Ibrāhīm]] (Medieval Arabia, 1029–1087)
* [[Lucjan Zarzecki|Zarzecki, Lucjan]] (Poland, 1873–1925)
* [[Claudia Zaslavsky|Zaslavsky, Claudia]] (USA, 1917–2006)
* [[Thomas Zaslavsky|Zaslavsky, Thomas]] (USA, born 1945)
* [[Eric Zaslow|Zaslow, Eric]] (USA, ?–?)
* [[Hans Zassenhaus|Zassenhaus, Hans]] (Germany, 1912–1991)
* [[Zygmunt Zawirski|Zawirski, Zygmunt]] (Poland, 1882–1948)
* [[Ahmed I. Zayed|Zayed, Ahmed I.]] (USA, ?–?)
* [[Fedor Zaytsev|Zaytsev, Fedor]] (Russia, ?–?)
* [[Tatjana Ždanoka|Ždanoka, Tatjana]] (Latvia, born 1950)
* [[Teofil Żebrawski|Żebrawski, Teofil]] (Poland, 1800–1887)
* [[Thomas Zebrowski|Zebrowski, Thomas]] (Lithuania, 1714–1758)
* [[Julius August Christoph Zech|Zech, Julius August Christoph]] (Germany, 1821–1864)
* [[Edouard Zeckendorf|Zeckendorf, Edouard]] (Belgium, 1901–1983)
* [[Christopher Zeeman|Zeeman, Christopher]] (Britain, 1925–2016)
* [[Mary Lou Zeeman|Zeeman, Mary Lou]] (Britain, ?–?)
* [[Jiang Zehan|Zehan, Jiang]] (China, 1902–1994)
* [[Eduard Zehnder|Zehnder, Eduard]] (Switzerland, ?–?)
* [[Doron Zeilberger|Zeilberger, Doron]] (Israel, born 1950)
* [[Ofer Zeitouni|Zeitouni, Ofer]] (Israel, born 1960)
* [[Paul Zeitz|Zeitz, Paul]] (?, born 1958)

== Zek ==

* [[Salih Zeki|Zeki, Salih]] (Turkey, 1864–1921)
* [[Andrei Zelevinsky|Zelevinsky, Andrei]] (Russia/Soviet Union, 1953–2013)
* [[Mikhail Zelikin|Zelikin, Mikhail]] (Russia/Soviet Union, born 1936)
* [[Christian Zeller|Zeller, Christian]] (Germany, 1822–1899)
* [[Karl Longin Zeller|Zeller, Karl Longin]] (Germany, 1924–2006)
* [[Arnold Zellner|Zellner, Arnold]] (USA, born 1927)
* [[Shea Zellweger|Zellweger, Shea]] (?, ?–?)
* [[Efim Zelmanov|Zelmanov, Efim]] (Russia/Soviet Union, born 1955)
* [[Elmārs Zemgalis|Zemgalis, Elmārs]] (USA, 1923–2014)
* [[Christoph Zenger|Zenger, Christoph]] (Germany, born 1940)
* [[Zeno of Elea]] (Ancient Greece, 490 BC–430 BC)
* [[Zeno of Sidon]] (Ancient Greece, ?–?)
* [[Zenodorus (mathematician)|Zenodorus]] (Ancient Greece, 200s BC–140s BC)
* [[Sarah Zerbes|Zerbes, Sarah]] (Germany/Britain, born 1978)
* [[Ernst Zermelo|Zermelo, Ernst]] (Germany, 1871–1953)
* [[Mihail Zervos|Zervos, Mihail]] (Greece, ?–?)
* [[Karl Eduard Zetzsche|Zetzsche, Karl Eduard]] (Germany, 1830–1894)
* [[Hieronymus Georg Zeuthen|Zeuthen, Hieronymus Georg]] (Denmark, 1839–1920)
* [[Zhang Heng|Zhang, Heng]] (China, 78–139)
* [[Ping Zhang (graph theorist)|Zhang, Ping (graph theorist)]] (?, ?–?)
* [[Shou-Wu Zhang|Zhang, Shou-Wu]] (China, born 1962)
* [[Wei Zhang (mathematician)|Zhang, Wei]] (China, born 1981)
* [[Yitang Zhang|Zhang, Yitang]] (USA/China, born 1955)
* [[Ke Zhao|Zhao, Ke]] (China, 1910–2002)
* [[Ivan Ivanovich Zhegalkin|Zhegalkin, Ivan Ivanovich]] (Russia, 1869–1947)
* [[Yuliang Zheng|Zheng, Yuliang]] (?, ?–?)
* [[Wang Zhenyi (astronomer)|Zhenyi, Wang (astronomer)]] (?, 1768–1797)
* [[Rozetta Zhilina|Zhilina, Rozetta]] (Soviet Union, 1933–2003)
* [[Chen Zhiming|Zhiming, Chen]] (China, born 1965)
* [[Shi Zhongci|Zhongci, Shi]] (China, born 1933)
* [[Xin Zhou|Zhou, Xin]] (?, ?–?)

== Zhu ==

* [[Zhu Shijie|Zhu, Shijie]] (Medieval China, 1249–1314)
* [[Xinwen Zhu|Zhu, Xinwen]] (China, ?–?)
* [[Nikolay Yegorovich Zhukovsky|Zhukovsky, Nikolay Yegorovich]] (Russia, 1847–1921)
* [[Yang Zhuoxin|Zhuoxin, Yang]] (China, 1890–1963)
* [[Yuri Zhuravlyov (mathematician)|Zhuravlyov, Yuri]] (Russia/Soviet Union, born 1935)
* [[Günter M. Ziegler|Ziegler, Günter M.]] (Germany, born 1963)
* [[Tamar Ziegler|Ziegler, Tamar]] (Israel, ?–?)
* [[Olgierd Zienkiewicz|Zienkiewicz, Olgierd]] (Poland, 1921–2009)
* [[Heiner Zieschang|Zieschang, Heiner]] (Germany, 1936–2004)
* [[Henk Zijm|Zijm, Henk]] (Netherlands, born 1952)
* [[Boris Zilber|Zilber, Boris]] (Soviet Union/Russia, born 1949)
* [[Magdolna Zimányi|Zimányi, Magdolna]] (Hungary, 1934–2016)
* [[Robert Zimmer|Zimmer, Robert]] (USA, born 1947)
* [[Johann Jacob Zimmermann|Zimmermann, Johann Jacob]] (Germany, 1644–1693)
* [[Paul Zimmermann (mathematician)|Zimmermann, Paul]] (France, born 1964)
* [[Vasili Yakovlevich Zinger|Zinger, Vasili Yakovlevich]] (Russia, 1836–1907)
* [[Thomas Zink|Zink, Thomas]] (Germany, born 1949)
* [[Mariusz Ziółko|Ziółko, Mariusz]] (Poland, born 1946)
* [[George Kingsley Zipf|Zipf, George Kingsley]] (USA, 1902–1950)
* [[Leo Zippin|Zippin, Leo]] (USA, 1905–1995)
* [[Abraham Ziv|Ziv, Abraham]] (Israel, 1940–2013)
* [[Vaclav Zizler|Zizler, Vaclav]] (Canada/Czech Republic, ?–?)
* [[Wawrzyniec Żmurko|Żmurko, Wawrzyniec]] (Poland, 1824–1889)
* [[Štefan Znám|Znám, Štefan]] (Slovakia, 1936–1993)
* [[Yegor Ivanovich Zolotarev|Zolotarev, Yegor Ivanovich]] (Russia, 1847–1878)
* [[Yevgenii Vasilevich Zolotov|Zolotov, Yevgenii Vasilevich]] (Soviet Union, 1922–1990)
* [[Kazimierz Żorawski|Żorawski, Kazimierz]] (Poland, 1866–1953)
* [[Anton Zorich|Zorich, Anton]] (Russia/Soviet Union, ?–?)
* [[Vladimir A. Zorich|Zorich, Vladimir A.]] (Russia/Soviet Union, born 1937)
* [[Max August Zorn|Zorn, Max August]] (USA/Germany, 1906–1993)

== Zou ==

* [[Hui Zou|Zou, Hui]] (China/USA, ?–?)
* [[Jie-zhong Zou|Zou, Jie-zhong]] (China, born 1947)
* [[Karl Zsigmondy|Zsigmondy, Karl]] (Austria/Hungary, 1867–1925)
* [[Zu Chongzhi|Zu, Chongzhi]] (Ancient China, 429–500)
* [[Enrique Zuazua|Zuazua, Enrique]] (Spain, born 1961)
* [[Steven Zucker|Zucker, Steven]] (?, ?–?)
* [[Gregg Zuckerman|Zuckerman, Gregg]] (USA, ?–?)
* [[Benedict Zuckermann|Zuckermann, Benedict]] (Germany, 1818–1891)
* [[Wadim Zudilin|Zudilin, Wadim]] (Russia, ?–?)
* [[Bruno Zumbo|Zumbo, Bruno]] (USA, born 1966)
* [[Giovanni Battista Zupi|Zupi, Giovanni Battista]] (Italy, 1590s–1650)
* [[Marcin Król z Żurawicy|z Żurawicy, Marcin Król]] (Poland, ?–1460)
* [[Moses Zuriel|Zuriel, Moses]] (?, ?–?)
* [[Sander P. Zwegers|Zwegers, Sander P.]] (Netherlands, born 1975)
* [[Uri Zwick|Zwick, Uri]] (Israel, ?–?)
* [[William S. Zwicker|Zwicker, William S.]] (USA, born 1949)
* [[Maciej Zworski|Zworski, Maciej]] (Canada, born 1963)
* [[Karol Życzkowski|Życzkowski, Karol]] (Poland, born 1960)
* [[Henryk Zygalski|Zygalski, Henryk]] (Poland, 1908–1978)
* [[Antoni Zygmund|Zygmund, Antoni]] (Poland, 1900–1992)

[[Category:Mathematics-related lists]]</text>
      <sha1>cdfqacoj4smtj18p3l732qvaauyn7tg</sha1>
    </revision>
  </page>
  <page>
    <title>List of polygons, polyhedra and polytopes</title>
    <ns>0</ns>
    <id>517370</id>
    <revision>
      <id>863072533</id>
      <parentid>839136132</parentid>
      <timestamp>2018-10-08T14:56:36Z</timestamp>
      <contributor>
        <username>Yahya Abdal-Aziz</username>
        <id>313039</id>
      </contributor>
      <comment>amend section heading "Three dimensional" to wikilink ([[polyhedron|polyhedra]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29909">A polytope is a geometric object with flat sides, which exists in any general number of dimensions. The following '''list of polygons, polyhedra and polytopes''' gives the names of various classes of polytopes and lists some specific examples.

==Polytope elements==
===Polygon (2-polytope)===
*[[Vertex (geometry)|Vertex]]
*[[Edge (geometry)|Edge]] the ''facet'' or ''(n−1)-face'' of the polygon

===Polyhedron (3-polytope)===
*[[Vertex (geometry)|Vertex]] the ''peak'' or ''(n−3)-face'' of the polyhedron
*[[Edge (geometry)|Edge]] the ''ridge'' or ''(n−2)-face'' of the polyhedron
*[[Face (geometry)|Face]] the ''facet'' or ''(n−1)-face'' of the polyhedron

===4-polytope===
*[[Vertex (geometry)|Vertex]]
*[[Edge (geometry)|Edge]] the ''peak'' or ''(n−3)-face'' of the 4-polytope
*[[Face (geometry)|Face]] the ''ridge'' or ''(n−2)-face'' of the 4-polytope
*[[Cell (geometry)|Cell]] the ''facet'' or ''(n−1)-face'' of the 4-polytope

===5-polytope===
*[[Vertex (geometry)|Vertex]] the ''(n−5)-face'' of the 5-polytope
*[[Edge (geometry)|Edge]] the ''(n−4)-face'' of the 5-polytope
*[[Face (geometry)|Face]] the ''peak'' or ''(n−3)-face'' of the 5-polytope
*[[Cell (geometry)|Cell]] the ''ridge'' or ''(n−2)-face'' of the 5-polytope
*[[Hypercell]] or Teron the ''facet'' or ''(n−1)-face'' of the 5-polytope

===Other===
*[[Point (geometry)|Point]]
*[[Line segment]]
*[[Vertex figure]]
*[[Peak (geometry)|Peak]] – ''(n−3)-face''
*[[Ridge (geometry)|Ridge]] – ''(n−2)-face''
*[[Facet (geometry)|Facet]] – ''(n−1)-face''

==Two dimensional ([[polygon]]s)==
;[[Triangle]]
*[[Equilateral triangle]]
*[[Isosceles triangle]]
*[[Scalene triangle]], [[Right triangle]] 

;[[Quadrilateral]]
*[[Square (geometry)|Square]]
*[[Quadrilateral]]
*[[Rectangle]]
*[[Rhombus]]
*[[Parallelogram]]
*[[Trapezoid]]
*[[Isosceles trapezoid]]
*[[Kite (geometry)|Kite]]
*[[Rhomboid]]

;[[Pentagon]]
;[[Hexagon]]
;[[Heptagon]]
;[[Octagon]]
;[[Nonagon]]
;[[Decagon]]
;[[Hendecagon]]
;[[Dodecagon]]
;[[Triskaidecagon]]
;[[Tetradecagon]]
;[[Pentadecagon]]
;[[Hexadecagon]]
;[[Heptadecagon]]
;[[Octadecagon]]
;[[Enneadecagon]]
;[[Icosagon]]
;[[Icosihenagon]]
;[[Icosidigon]]
;[[Icositrigon]]
;[[Icositetragon]]
;[[Icosipentagon]]
;[[Icosihexagon]]
;[[Icosiheptagon]]
;[[Icosioctagon]]
;[[Icosienneagon]]
;[[Triacontagon]]
;[[Tetracontagon]]
;[[257-gon]]
;[[Chiliagon]]
;[[Myriagon]]
;[[65537-gon]]
;[[Megagon]]
;[[Apeirogon]]

===[[Star polygon]]s===
*[[Pentagram]]
*[[Hexagram]]
*[[Heptagram]]
*[[Octagram]]
*[[Enneagram (geometry)|Enneagram]]
*[[Decagram (geometry)|Decagram]]
*[[Hendecagram]]
*[[Dodecagram]]

===Families===
*[[Concave polygon]]
*[[Cyclic polygon]]
*[[Regular polygon]]
*[[Polyform]]
*[[Gnomon (figure)|Gnomon]]
*[[Golygon]]

===Tilings===
[[List of uniform tilings]]
[[Uniform tilings in hyperbolic plane]]

;[[Archimedean tiling]]
*[[Square tiling]]
*[[Triangular tiling]]
*[[Hexagonal tiling]]
*[[Truncated square tiling]]
*[[Snub square tiling]]
*[[Trihexagonal tiling]]
*[[Truncated hexagonal tiling]]
*[[Rhombitrihexagonal tiling]]
*[[Truncated trihexagonal tiling]]
*[[Snub hexagonal tiling]]
*[[Elongated triangular tiling]]

==Three dimensional ([[polyhedron|polyhedra]])==
;[[Three-dimensional space]]

===Regular===
[[Regular polyhedron]]
*[[Platonic solid]]:
**[[Tetrahedron]], [[Cube]], [[Octahedron]], [[Dodecahedron]], [[Icosahedron]]
*Regular [[spherical polyhedron]]
**[[Dihedron]], [[Hosohedron]]
*[[Kepler–Poinsot polyhedron]] (Regular star polyhedra)
**[[Small stellated dodecahedron]], [[Great stellated dodecahedron]], [[Great icosahedron]], [[Great dodecahedron]]
*Abstract regular polyhedra ([[Projective polyhedron]])
**[[Hemicube (geometry)]], [[hemi-octahedron]], [[hemi-dodecahedron]], [[hemi-icosahedron]]

;[[Tetrahedron]]
*[[Disphenoid]]
;[[Pentahedron]]
*[[Square pyramid]], [[Triangular prism]]
;[[Hexahedron]]
*[[Parallelepiped]], [[Cuboid]], [[Rhombohedron]], [[Trigonal trapezohedron]], [[Cube]], [[Pentagonal pyramid]], [[Triangular dipyramid]], quadrilateral [[frustum]]
;[[Heptahedron]]
*[[hexagonal pyramid]], [[pentagonal prism]], [[tetrahemihexahedron]]
;[[Octahedron]]
*[[Hexagonal prism]], [[Truncated tetrahedron]], [[Tetragonal trapezohedron]]
;[[Enneahedron]]
*[[Octagonal pyramid]], [[Heptagonal prism]]
;[[Decahedron]]
*[[Octagonal prism]], [[Square antiprism]], [[Square cupola]], [[Pentagonal dipyramid]], [[Augmented pentagonal prism]]
;[[Dodecahedron]]
*[[Pentagonal antiprism]], [[Decagonal prism]], [[Pentagonal cupola]], [[Snub disphenoid]], [[Elongated square dipyramid]], [[Metabidiminished icosahedron]], [[Hexagonal bipyramid]], [[Hexagonal trapezohedron]], [[Triakis tetrahedron]], [[Rhombic dodecahedron]], [[Hendecagonal pyramid]], [[Trapezo-rhombic dodecahedron]], [[Rhombo-hexagonal dodecahedron]]

===Archimedean solids===
;[[Archimedean solid]]
*[[Truncated tetrahedron]], [[Cuboctahedron]], [[Truncated cube]], [[Truncated octahedron]], [[Rhombicuboctahedron]], [[Truncated cuboctahedron]], [[Snub cube]], [[Icosidodecahedron]], [[Truncated dodecahedron]], [[Truncated icosahedron]], [[Rhombicosidodecahedron]], [[Truncated icosidodecahedron]], [[Snub dodecahedron]]

===Prisms and antiprisms===
;[[Prism (geometry)|Prism]]
*[[Triangular prism]], [[Pentagonal prism]], [[Hexagonal prism]], [[Heptagonal prism]], [[Octagonal prism]], [[Enneagonal prism]], [[Decagonal prism]], [[Hendecagonal prism]], [[Dodecagonal prism]]
;[[Antiprism]]
*[[Square antiprism]], [[Pentagonal antiprism]], [[Hexagonal antiprism]], [[Heptagonal antiprism]], [[Octagonal antiprism]], [[Enneagonal antiprism]], [[Decagonal antiprism]], [[Dodecagonal antiprism]]

===Catalan solids===
;[[Catalan solid]]
*[[Triakis tetrahedron]], [[Rhombic dodecahedron]], [[Triakis octahedron]], [[Tetrakis hexahedron]], [[Deltoidal icositetrahedron]], [[Disdyakis dodecahedron]], [[Pentagonal icositetrahedron]], [[Rhombic triacontahedron]], [[Triakis icosahedron]], [[Pentakis dodecahedron]], [[Deltoidal hexecontahedron]], [[Disdyakis triacontahedron]], [[Pentagonal hexecontahedron]]

===Bipyramids and Trapezohedron===
*[[Bipyramid]]
**[[Triangular dipyramid]], [[Pentagonal dipyramid]], [[Hexagonal bipyramid]], [[Octagonal bipyramid]], [[Decagonal bipyramid]]
*[[Trapezohedron]]

===Uniform star polyhedra===
;[[Uniform star polyhedron]]
*[[Cubitruncated cuboctahedron]]
*[[Cubohemioctahedron]]
*[[Ditrigonal dodecadodecahedron]]
*[[Dodecadodecahedron]]
*[[Great cubicuboctahedron]]
*[[Great dirhombicosidodecahedron]]
*[[Great disnub dirhombidodecahedron]]
*[[Great ditrigonal dodecicosidodecahedron]]
*[[Great ditrigonal icosidodecahedron]]
*[[Great dodecahemicosahedron]]
*[[Great dodecahemidodecahedron]]
*[[Great dodecicosahedron]]
*[[Great dodecicosidodecahedron]]
*[[Great icosicosidodecahedron]]
*[[Great icosidodecahedron]]
*[[Great icosihemidodecahedron]]
*[[Great inverted snub icosidodecahedron]]
*[[Great retrosnub icosidodecahedron]]
*[[Great rhombidodecahedron]]
*[[Great rhombihexahedron]]
*[[Great snub dodecicosidodecahedron]]
*[[Great snub icosidodecahedron]]
*[[Great stellated truncated dodecahedron]]
*[[Great truncated cuboctahedron]]
*[[Great truncated icosidodecahedron]]
*[[Icosidodecadodecahedron]]
*[[Icositruncated dodecadodecahedron]]
*[[Inverted snub dodecadodecahedron]]
*[[Nonconvex great rhombicosidodecahedron]]
*[[Nonconvex great rhombicuboctahedron]]
*[[Octahemioctahedron]]
*[[Rhombicosahedron]]
*[[Rhombidodecadodecahedron]]
*[[Small cubicuboctahedron]]
*[[Small ditrigonal dodecicosidodecahedron]]
*[[Small ditrigonal icosidodecahedron]]
*[[Small dodecahemicosahedron]]
*[[Small dodecahemidodecahedron]]
*[[Small dodecicosahedron]]
*[[Small dodecicosidodecahedron]]
*[[Small icosicosidodecahedron]]
*[[Small icosihemidodecahedron]]
*[[Small retrosnub icosicosidodecahedron]]
*[[Small rhombidodecahedron]]
*[[Small rhombihexahedron]]
*[[Small snub icosicosidodecahedron]]
*[[Small stellated truncated dodecahedron]]
*[[Snub dodecadodecahedron]]
*[[Snub icosidodecadodecahedron]]
*[[Stellated truncated hexahedron]]
*[[Tetrahemihexahedron]]
*[[Truncated dodecadodecahedron]]
*[[Truncated great dodecahedron]]
*[[Truncated great icosahedron]]

===Uniform prismatic star polyhedra===
;[[Prismatic uniform polyhedron]]
*[[Pentagrammic prism]], [[Pentagrammic antiprism]], [[Pentagrammic crossed-antiprism]]
*[[Heptagrammic antiprism (7/2)]], [[Heptagrammic antiprism (7/3)]]
*[[Enneagrammic antiprism (9/2)]]. [[Enneagrammic antiprism (9/4)]]
*[[Enneagrammic crossed-antiprism]], [[Enneagrammic prism (9/2)]], [[Enneagrammic prism (9/4)]]
*[[Decagrammic prism]], [[Decagrammic antiprism]]

===Johnson solids===
;[[Johnson solid]]
#[[Augmented dodecahedron]]
#[[Augmented hexagonal prism]]
#[[Augmented pentagonal prism]]
#[[Augmented sphenocorona]]
#[[Augmented triangular prism]]
#[[Augmented tridiminished icosahedron]]
#[[Augmented truncated cube]]
#[[Augmented truncated dodecahedron]]
#[[Augmented truncated tetrahedron]]
#[[Biaugmented pentagonal prism]]
#[[Biaugmented triangular prism]]
#[[Biaugmented truncated cube]]
#[[Bigyrate diminished rhombicosidodecahedron]]
#[[Bilunabirotunda]]
#[[Diminished rhombicosidodecahedron]]
#[[Disphenocingulum]]
#[[Elongated pentagonal bipyramid]]
#[[Elongated pentagonal cupola]]
#[[Elongated pentagonal gyrobicupola]]
#[[Elongated pentagonal gyrobirotunda]]
#[[Elongated pentagonal gyrocupolarotunda]]
#[[Elongated pentagonal orthobicupola]]
#[[Elongated pentagonal orthobirotunda]]
#[[Elongated pentagonal orthocupolarotunda]]
#[[Elongated pentagonal pyramid]]
#[[Elongated pentagonal rotunda]]
#[[Elongated square bipyramid]]
#[[Elongated square cupola]]
#[[Elongated square gyrobicupola]]
#[[Elongated square pyramid]]
#[[Elongated triangular bipyramid]]
#[[Elongated triangular cupola]]
#[[Elongated triangular gyrobicupola]]
#[[Elongated triangular orthobicupola]]
#[[Elongated triangular pyramid]]
#[[Gyrate bidiminished rhombicosidodecahedron]]
#[[Gyrate rhombicosidodecahedron]]
#[[Gyrobifastigium]]
#[[Gyroelongated pentagonal bicupola]]
#[[Gyroelongated pentagonal birotunda]]
#[[Gyroelongated pentagonal cupola]]
#[[Gyroelongated pentagonal cupolarotunda]]
#[[Gyroelongated pentagonal pyramid]]
#[[Gyroelongated pentagonal rotunda]]
#[[Gyroelongated square bicupola]]
#[[Gyroelongated square bipyramid]]
#[[Gyroelongated square cupola]]
#[[Gyroelongated square pyramid]]
#[[Gyroelongated triangular bicupola]]
#[[Gyroelongated triangular cupola]]
#[[Hebesphenomegacorona]]
#[[Metabiaugmented dodecahedron]]
#[[Metabiaugmented hexagonal prism]]
#[[Metabiaugmented truncated dodecahedron]]
#[[Metabidiminished icosahedron]]
#[[Metabidiminished rhombicosidodecahedron]]
#[[Metabigyrate rhombicosidodecahedron]]
#[[Metagyrate diminished rhombicosidodecahedron]]
#[[Parabiaugmented dodecahedron]]
#[[Parabiaugmented hexagonal prism]]
#[[Parabiaugmented truncated dodecahedron]]
#[[Parabidiminished rhombicosidodecahedron]]
#[[Parabigyrate rhombicosidodecahedron]]
#[[Paragyrate diminished rhombicosidodecahedron]]
#[[Pentagonal bipyramid]]
#[[Pentagonal cupola]]
#[[Pentagonal gyrobicupola]]
#[[Pentagonal gyrocupolarotunda]]
#[[Pentagonal orthobicupola]]
#[[Pentagonal orthobirotunda]]
#[[Pentagonal orthocupolarotunda]]
#[[Pentagonal pyramid]]
#[[Pentagonal rotunda]]
#[[Snub disphenoid]]
#[[Snub square antiprism]]
#[[Sphenocorona]]
#[[Sphenomegacorona]]
#[[Square cupola]]
#[[Square gyrobicupola]]
#[[Square orthobicupola]]
#[[Square pyramid]]
#[[Triangular bipyramid]]
#[[Triangular cupola]]
#[[Triangular hebesphenorotunda]]
#[[Triangular orthobicupola]]
#[[Triaugmented dodecahedron]]
#[[Triaugmented hexagonal prism]]
#[[Triaugmented triangular prism]]
#[[Triaugmented truncated dodecahedron]]
#[[Tridiminished icosahedron]]
#[[Tridiminished rhombicosidodecahedron]]
#[[Trigyrate rhombicosidodecahedron]]

===Dual uniform star polyhedra===
*[[Great complex icosidodecahedron]]
*[[Great deltoidal hexecontahedron]]
*[[Great deltoidal icositetrahedron]]
*[[Great dirhombicosidodecacron]]
*[[Great dirhombicosidodecahedron]]
*[[Great disdyakis dodecahedron]]
*[[Great disdyakis triacontahedron]]
*[[Great disnub dirhombidodecacron]]
*[[Great ditrigonal dodecacronic hexecontahedron]]
*[[Great dodecacronic hexecontahedron]]
*[[Great dodecahemicosacron]]
*[[Great dodecicosacron]]
*[[Great hexacronic icositetrahedron]]
*[[Great hexagonal hexecontahedron]]
*[[Great icosacronic hexecontahedron]]
*[[Great icosihemidodecacron]]
*[[Great inverted pentagonal hexecontahedron]]
*[[Great pentagonal hexecontahedron]]
*[[Great pentagrammic hexecontahedron]]
*[[Great pentakis dodecahedron]]
*[[Great rhombic triacontahedron]]
*[[Great rhombidodecacron]]
*[[Great rhombihexacron]]
*[[Great stellapentakis dodecahedron]]
*[[Great triakis icosahedron]]
*[[Great triakis octahedron]]
*[[Great triambic icosahedron]]
*[[Medial deltoidal hexecontahedron]]
*[[Medial disdyakis triacontahedron]]
*[[Medial hexagonal hexecontahedron]]
*[[Medial icosacronic hexecontahedron]]
*[[Medial inverted pentagonal hexecontahedron]]
*[[Medial pentagonal hexecontahedron]]
*[[Medial rhombic triacontahedron]]
*[[Hexahemioctacron]]
*[[Hemipolyhedron]]
*[[Octahemioctacron]]
*[[Rhombicosacron]]
*[[Small complex icosidodecahedron]]
*[[Small ditrigonal dodecacronic hexecontahedron]]
*[[Small dodecacronic hexecontahedron]]
*[[Small dodecahemicosacron]]
*[[Small dodecahemidodecacron]]
*[[Small dodecicosacron]]
*[[Small hexacronic icositetrahedron]]
*[[Small hexagonal hexecontahedron]]
*[[Small hexagrammic hexecontahedron]]
*[[Small icosacronic hexecontahedron]]
*[[Small icosihemidodecacron]]
*[[Small rhombidodecacron]]
*[[Small rhombihexacron]]
*[[Small stellapentakis dodecahedron]]
*[[Small triambic icosahedron]]
*[[Tetrahemihexacron]]

===Honeycombs===
;[[Convex uniform honeycomb]]
*[[Cubic honeycomb]]
*[[Truncated cubic honeycomb]]
*[[Bitruncated cubic honeycomb]]
*[[Cantellated cubic honeycomb]]
*[[Cantitruncated cubic honeycomb]]
*[[Rectified cubic honeycomb]]
*[[Runcitruncated cubic honeycomb]]
*[[Omnitruncated cubic honeycomb]]
*[[Tetrahedral-octahedral honeycomb]]
*[[Truncated alternated cubic honeycomb]]
*[[Cantitruncated alternated cubic honeycomb]]
*[[Runcinated alternated cubic honeycomb]]
*[[Quarter cubic honeycomb]]
*[[Gyrated tetrahedral-octahedral honeycomb]]
*[[Gyrated triangular prismatic honeycomb]]
*[[Gyroelongated alternated cubic honeycomb]]
*[[Gyroelongated triangular prismatic honeycomb]]
*[[Elongated triangular prismatic honeycomb]]
*[[Elongated alternated cubic honeycomb]]
*[[Hexagonal prismatic honeycomb]]
*[[Triangular prismatic honeycomb]]
*[[Triangular-hexagonal prismatic honeycomb]]
*[[Truncated hexagonal prismatic honeycomb]]
*[[Truncated square prismatic honeycomb]]
*[[Rhombitriangular-hexagonal prismatic honeycomb]]
*[[Omnitruncated triangular-hexagonal prismatic honeycomb]]
*[[Snub triangular-hexagonal prismatic honeycomb]]
*[[Snub square prismatic honeycomb]]

;Dual uniform honeycomb
*[[Disphenoid tetrahedral honeycomb]]
*[[Rhombic dodecahedral honeycomb]]

;Others
*[[Trapezo-rhombic dodecahedral honeycomb]]
*[[Weaire–Phelan structure]]

;[[Convex uniform honeycombs in hyperbolic space]]
*[[Order-4 dodecahedral honeycomb]]
*[[Order-5 cubic honeycomb]]
*[[Order-5 dodecahedral honeycomb]]
*[[Icosahedral honeycomb]]

===Other===
*[[Apeirogonal prism]]
*[[Apeirohedron]]
*[[Bicupola (geometry)|Bicupola]]
*[[Cupola (geometry)|Cupola]]
*[[Bifrustum]]
*[[Boerdijk–Coxeter helix]]
*[[Császár polyhedron]]
*[[Flexible polyhedron]]
*[[Gyroelongated square dipyramid]]
*[[Heronian tetrahedron]]
*[[Hexagonal bifrustum]]
*[[Hexagonal truncated trapezohedron]]
*[[Hill tetrahedron]]
*[[Holyhedron]]
*[[Infinite skew polyhedron]]
*[[Jessen's icosahedron]]
*[[Near-miss Johnson solid]]
*[[Parallelepiped]]
*[[Pentagonal bifrustum]]
*[[Polytetrahedron]]
*[[Pyritohedron]]
*[[Rhombic enneacontahedron]]
*[[Rhombic icosahedron]]
*[[Rhombo-hexagonal dodecahedron]]
*[[Rhombohedron]]
*[[Scalenohedron]]
*[[Schönhardt polyhedron]]
*[[Square bifrustum]]
*[[Square truncated trapezohedron]]
*[[Szilassi polyhedron]]
*[[Tetradecahedron]]
*[[Tetradyakis hexahedron]]
*[[Tetrated dodecahedron]]
*[[Triangular bifrustum]]
*[[Triaugmented triangular prism]]
*[[Truncated rhombic dodecahedron]]
*[[Truncated trapezohedron]]
*[[Truncated triakis tetrahedron]]
*[[Tridyakis icosahedron]]
*[[Trigonal trapezohedron]]
*[[Regular skew polyhedron]]
*[[Waterman polyhedron]]
*[[Wedge (geometry)|Wedge]]

===Regular and uniform compound polyhedra===
;[[Polyhedral compound]] and [[Uniform polyhedron compound]]
*[[Compound of cube and octahedron]]
*[[Compound of dodecahedron and icosahedron]]
*[[Compound of eight octahedra with rotational freedom]]
*[[Compound of eight triangular prisms]]
*[[Compound of five cubes]]
*[[Compound of five cuboctahedra]]
*[[Compound of five cubohemioctahedra]]
*[[Compound of five great cubicuboctahedra]]
*[[Compound of five great dodecahedra]]
*[[Compound of five great icosahedra]]
*[[Compound of five great rhombihexahedra]]
*[[Compound of five icosahedra]]
*[[Compound of five octahedra]]
*[[Compound of five octahemioctahedra]]
*[[Compound of five small cubicuboctahedra]]
*[[Compound of five small rhombicuboctahedra]]
*[[Compound of five small rhombihexahedra]]
*[[Compound of five small stellated dodecahedra]]
*[[Compound of five stellated truncated cubes]]
*[[Compound of five tetrahedra]]
*[[Compound of five tetrahemihexahedra]]
*[[Compound of five truncated cubes]]
*[[Compound of five truncated tetrahedra]]
*[[Compound of five uniform great rhombicuboctahedra]]
*[[Compound of four hexagonal prisms]]
*[[Compound of four octahedra]]
*[[Compound of four octahedra with rotational freedom]]
*[[Compound of four tetrahedra]]
*[[Compound of four triangular prisms]]
*[[Compound of great icosahedron and great stellated dodecahedron]]
*[[Compound of six cubes with rotational freedom]]
*[[Compound of six decagonal prisms]]
*[[Compound of six decagrammic prisms]]
*[[Compound of six pentagonal antiprisms]]
*[[Compound of six pentagonal prisms]]
*[[Compound of six pentagrammic antiprisms]]
*[[Compound of six pentagrammic crossed antiprisms]]
*[[Compound of six pentagrammic prisms]]
*[[Compound of six square antiprisms]]
*[[Compound of six tetrahedra]]
*[[Compound of six tetrahedra with rotational freedom]]
*[[Compound of small stellated dodecahedron and great dodecahedron]]
*[[Compound of ten hexagonal prisms]]
*[[Compound of ten octahedra]]
*[[Compound of ten tetrahedra]]
*[[Compound of ten triangular prisms]]
*[[Compound of ten truncated tetrahedra]]
*[[Compound of three cubes]]
*[[Compound of three square antiprisms]]
*[[Compound of three tetrahedra]]
*[[Compound of twelve pentagonal antiprisms with rotational freedom]]
*[[Compound of twelve pentagonal prisms]]
*[[Compound of twelve pentagrammic antiprisms]]
*[[Compound of twelve pentagrammic crossed antiprisms with rotational freedom]]
*[[Compound of twelve pentagrammic prisms]]
*[[Compound of twelve tetrahedra with rotational freedom]]
*[[Compound of twenty octahedra]]
*[[Compound of twenty octahedra with rotational freedom]]
*[[Compound of twenty tetrahemihexahedra]]
*[[Compound of twenty triangular prisms]]
*[[Compound of two great dodecahedra]]
*[[Compound of two great icosahedra]]
*[[Compound of two great inverted snub icosidodecahedra]]
*[[Compound of two great retrosnub icosidodecahedra]]
*[[Compound of two great snub icosidodecahedra]]
*[[Compound of two icosahedra]]
*[[Compound of two inverted snub dodecadodecahedra]]
*[[Compound of two small stellated dodecahedra]]
*[[Compound of two snub cubes]]
*[[Compound of two snub dodecadodecahedra]]
*[[Compound of two snub dodecahedra]]
*[[Compound of two snub icosidodecadodecahedra]]
*[[Compound of two truncated tetrahedra]]
*[[Prismatic compound of antiprisms]]
*[[Prismatic compound of antiprisms with rotational freedom]]
*[[Prismatic compound of prisms]]
*[[Prismatic compound of prisms with rotational freedom]]

==Four dimensions==
;[[Four-dimensional space]]
[[4-polytope]] – general term for a [[four dimensional]] polytope

;[[Regular 4-polytope]]
*[[5-cell]], [[Tesseract]], [[16-cell]], [[24-cell]], [[120-cell]], [[600-cell]]

;[[Abstract regular polytope]]
*[[11-cell]], [[57-cell]]

;[[Regular star 4-polytope]]
*[[Icosahedral 120-cell]], [[Small stellated 120-cell]], [[Great 120-cell]], [[Grand 120-cell]], [[Great stellated 120-cell]], [[Grand stellated 120-cell]], [[Great grand 120-cell]], [[Great icosahedral 120-cell]], [[Grand 600-cell]], [[Great grand stellated 120-cell]]

;[[Uniform 4-polytope]]
*[[Rectified 5-cell]], [[Truncated 5-cell]], [[Cantellated 5-cell]], [[Runcinated 5-cell]]
*[[Rectified tesseract]], [[Truncated tesseract]], [[Cantellated tesseract]], [[Runcinated tesseract]]
*[[Rectified 16-cell]], [[Truncated 16-cell]]
*[[Rectified 24-cell]], [[Truncated 24-cell]], [[Cantellated 24-cell]], [[Runcinated 24-cell]], [[Snub 24-cell]]
*[[Rectified 120-cell]], [[Truncated 120-cell]], [[Cantellated 120-cell]], [[Runcinated 120-cell]]
*[[Rectified 600-cell]], [[Truncated 600-cell]], [[Cantellated 600-cell]]

;[[Prismatic uniform 4-polytope]]
*[[Grand antiprism]]
*[[Duoprism]]
*[[Tetrahedral prism]], [[Truncated tetrahedral prism]]
*[[Truncated cubic prism]], [[Truncated octahedral prism]], [[Cuboctahedral prism]], [[Rhombicuboctahedral prism]], [[Truncated cuboctahedral prism]], [[Snub cubic prism]]
*[[Truncated dodecahedral prism]], [[Truncated icosahedral prism]], [[Icosidodecahedral prism]], [[Rhombicosidodecahedral prism]], [[Truncated icosidodecahedral prism]], [[Snub dodecahedral prism]]

;[[Uniform antiprismatic prism]]
*[[Triangular antiprismatic prism]], [[Square antiprismatic prism]], [[Pentagonal antiprismatic prism]], [[Hexagonal antiprismatic prism]], [[Heptagonal antiprismatic prism]], [[Octagonal antiprismatic prism]], [[Enneagonal antiprismatic prism]], [[Decagonal antiprismatic prism]]
*[[Pentagrammic antiprismatic prism]], [[Hexagrammic antiprismatic prism]], [[Heptagrammic antiprismatic prism]], [[Octagrammic antiprismatic prism]], [[Enneagrammic antiprismatic prism]], [[Decagrammic antiprismatic prism]]
*[[Pentagrammic crossed antiprismatic prism]], [[Hexagrammic crossed antiprismatic prism]], [[Heptagrammic crossed antiprismatic prism]], [[Octagrammic crossed antiprismatic prism]], [[Enneagrammic crossed antiprismatic prism]], [[Decagrammic crossed antiprismatic prism]]

===Honeycombs===
*[[Tesseractic honeycomb]]
*[[24-cell honeycomb]]
*[[Snub 24-cell honeycomb]]
*[[Rectified 24-cell honeycomb]]
*[[Truncated 24-cell honeycomb]]
*[[16-cell honeycomb]]
*[[5-cell honeycomb]]
*[[Omnitruncated 5-cell honeycomb]]
*[[Truncated 5-cell honeycomb]]
*[[Omnitruncated 5-simplex honeycomb]]

==Five dimensions==
;[[Five-dimensional space]], [[5-polytope]] and [[uniform 5-polytope]]
*[[5-simplex]], [[Rectified 5-simplex]], [[Truncated 5-simplex]], [[Cantellated 5-simplex]], [[Runcinated 5-simplex]], [[Stericated 5-simplex]]
*[[5-demicube]], [[Truncated 5-demicube]], [[Cantellated 5-demicube]], [[Runcinated 5-demicube]]
*[[5-cube]], [[Rectified 5-cube]], [[5-cube]], [[Truncated 5-cube]], [[Cantellated 5-cube]], [[Runcinated 5-cube]], [[Stericated 5-cube]]
*[[5-orthoplex]], [[Rectified 5-orthoplex]], [[Truncated 5-orthoplex]], [[Cantellated 5-orthoplex]], [[Runcinated 5-orthoplex]]

;[[Prismatic uniform 5-polytope]]
*[[5-cell prism]], [[Rectified 5-cell prism]], [[Truncated 5-cell prism]], [[Cantellated 5-cell prism]], [[Runcinated 5-cell prism]], [[Bitruncated 5-cell prism]], [[Cantitruncated 5-cell prism]], [[Runcitruncated 5-cell prism]], [[Omnitruncated 5-cell prism]]
*[[Tesseractic prism]], [[Rectified tesseractic prism]], [[Truncated tesseractic prism]], [[Cantellated tesseractic prism]], [[Runcinated tesseractic prism]], [[Bitruncated tesseractic prism]], [[Cantitruncated tesseractic prism]], [[Runcitruncated tesseractic prism]], [[Omnitruncated tesseractic prism]]
*[[16-cell prism]], [[Truncated 16-cell prism]], [[Runcitruncated 16-cell prism]]
*[[24-cell prism]], [[rectified 24-cell prism]], [[truncated 24-cell prism]], [[cantellated 24-cell prism]], [[runcinated 24-cell prism]], [[bitruncated 24-cell prism]], [[cantitruncated 24-cell prism]], [[runcitruncated 24-cell prism]], [[omnitruncated 24-cell prism]], [[snub 24-cell prism]]
*[[120-cell prism]], [[Rectified 120-cell prism]], [[Truncated 120-cell prism]], [[Cantellated 120-cell prism]], [[Runcinated 120-cell prism]], [[Bitruncated 120-cell prism]], [[Cantitruncated 120-cell prism]], [[Runcitruncated 120-cell prism]], [[Omnitruncated 120-cell prism]]
*[[600-cell prism]], [[Rectified 600-cell prism]], [[Truncated 600-cell prism]], [[Cantellated 600-cell prism]], [[Cantitruncated 600-cell prism]], [[Runcitruncated 600-cell prism]]
*[[Grand antiprism prism]]

===Honeycombs===
*[[5-cubic honeycomb]]
*[[5-simplex honeycomb]]
*[[Truncated 5-simplex honeycomb]]
*[[5-demicubic honeycomb]]

==Six dimensions==
;[[Six-dimensional space]], [[6-polytope]] and [[uniform 6-polytope]]
*[[6-simplex]], [[Rectified 6-simplex]], [[Truncated 6-simplex]], [[Cantellated 6-simplex]], [[Runcinated 6-simplex]], [[Stericated 6-simplex]], [[Pentellated 6-simplex]]
*[[6-demicube]], [[Truncated 6-demicube]], [[Cantellated 6-demicube]], [[Runcinated 6-demicube]], [[Stericated 6-demicube]]
*[[6-cube]], [[Rectified 6-cube]], [[6-cube]], [[Truncated 6-cube]], [[Cantellated 6-cube]], [[Runcinated 6-cube]], [[Stericated 6-cube]], [[Pentellated 6-cube]]
*[[6-orthoplex]], [[Rectified 6-orthoplex]], [[Truncated 6-orthoplex]], [[Cantellated 6-orthoplex]], [[Runcinated 6-orthoplex]], [[Stericated 6-orthoplex]]
*[[1 22 polytope|1&lt;sub&gt;22&lt;/sub&gt; polytope]], [[2 21 polytope|2&lt;sub&gt;21&lt;/sub&gt; polytope]]

===Honeycombs===
*[[6-cubic honeycomb]]
*[[6-simplex honeycomb]]
*[[6-demicubic honeycomb]]
*[[2 22 honeycomb|2&lt;sub&gt;22&lt;/sub&gt; honeycomb]]

==Seven dimensions==
;[[Seven-dimensional space]], [[uniform 7-polytope]]
*[[7-simplex]], [[Rectified 7-simplex]], [[Truncated 7-simplex]], [[Cantellated 7-simplex]], [[Runcinated 7-simplex]], [[Stericated 7-simplex]], [[Pentellated 7-simplex]], [[Hexicated 7-simplex]]
*[[7-demicube]], [[Truncated 7-demicube]], [[Cantellated 7-demicube]], [[Runcinated 7-demicube]], [[Stericated 7-demicube]], [[Pentellated 7-demicube]]
*[[7-cube]], [[Rectified 7-cube]], [[7-cube]], [[Truncated 7-cube]], [[Cantellated 7-cube]], [[Runcinated 7-cube]], [[Stericated 7-cube]], [[Pentellated 7-cube]], [[Hexicated 7-cube]]
*[[7-orthoplex]], [[Rectified 7-orthoplex]], [[Truncated 7-orthoplex]], [[Cantellated 7-orthoplex]], [[Runcinated 7-orthoplex]], [[Stericated 7-orthoplex]], [[Pentellated 7-orthoplex]]
*[[1 32 polytope|1&lt;sub&gt;32&lt;/sub&gt; polytope]], [[2 31 polytope|2&lt;sub&gt;31&lt;/sub&gt; polytope]], [[3 21 polytope|3&lt;sub&gt;21&lt;/sub&gt; polytope]]

===Honeycombs===
*[[7-cubic honeycomb]]
*[[7-demicubic honeycomb]]
*[[3 31 honeycomb|3&lt;sub&gt;31&lt;/sub&gt; honeycomb]], [[1 33 honeycomb|1&lt;sub&gt;33&lt;/sub&gt; honeycomb]]

==Eight dimension==
;[[Eight-dimensional space]], [[uniform 8-polytope]]
*[[8-simplex]], [[Rectified 8-simplex]], [[Truncated 8-simplex]], [[Cantellated 8-simplex]], [[Runcinated 8-simplex]], [[Stericated 8-simplex]], [[Pentellated 8-simplex]], [[Hexicated 8-simplex]], [[Heptellated 8-simplex]]
*[[8-orthoplex]], [[Rectified 8-orthoplex]], [[Truncated 8-orthoplex]], [[Cantellated 8-orthoplex]], [[Runcinated 8-orthoplex]], [[Stericated 8-orthoplex]], [[Pentellated 8-orthoplex]], [[Hexicated 8-orthoplex]],
*[[8-cube]], [[Rectified 8-cube]], [[Truncated 8-cube]], [[Cantellated 8-cube]], [[Runcinated 8-cube]], [[Stericated 8-cube]], [[Pentellated 8-cube]], [[Hexicated 8-cube]], [[Heptellated 8-cube]]
*[[8-demicube]], [[Truncated 8-demicube]], [[Cantellated 8-demicube]], [[Runcinated 8-demicube]], [[Stericated 8-demicube]], [[Pentellated 8-demicube]], [[Hexicated 8-demicube]]
*[[1 42 polytope|1&lt;sub&gt;42&lt;/sub&gt; polytope]], [[2 41 polytope|2&lt;sub&gt;41&lt;/sub&gt; polytope]], [[4 21 polytope|4&lt;sub&gt;21&lt;/sub&gt; polytope]], [[Truncated 4 21 polytope|Truncated 4&lt;sub&gt;21&lt;/sub&gt; polytope]], [[Truncated 2 41 polytope|Truncated 2&lt;sub&gt;41&lt;/sub&gt; polytope]], [[Truncated 1 42 polytope|Truncated 1&lt;sub&gt;42&lt;/sub&gt; polytope]], [[Cantellated 4 21 polytope|Cantellated 4&lt;sub&gt;21&lt;/sub&gt; polytope]], [[Cantellated 2 41 polytope|Cantellated 2&lt;sub&gt;41&lt;/sub&gt; polytope]], [[Runcinated 4 21 polytope|Runcinated 4&lt;sub&gt;21&lt;/sub&gt; polytope]]

===Honeycombs===
*[[8-cubic honeycomb]]
*[[8-demicubic honeycomb]]
*[[5 21 honeycomb|5&lt;sub&gt;21&lt;/sub&gt; honeycomb]], [[2 51 honeycomb|2&lt;sub&gt;51&lt;/sub&gt; honeycomb]], [[1 52 honeycomb|1&lt;sub&gt;52&lt;/sub&gt; honeycomb]]

==Nine dimensions==
;[[9-polytope]]
*[[9-cube]]
*[[9-demicube]]
*[[9-orthoplex]]
*[[9-simplex]]

===Hyperbolic honeycombs===
*[[E9 honeycomb|E&lt;sub&gt;9&lt;/sub&gt; honeycomb]]

==Ten dimensions==
;[[10-polytope]]
*[[10-cube]]
*[[10-demicube]]
*[[10-orthoplex]]
*[[10-simplex]]

==Dimensional families==
;[[Regular polytope]] and [[List of regular polytopes]]
*[[Simplex]]
*[[Hypercube]]
*[[Cross-polytope]]
;[[Uniform polytope]]
*[[Demihypercube]]
*[[Uniform 1 k2 polytope|Uniform 1&lt;sub&gt;''k''2&lt;/sub&gt; polytope]]
*[[Uniform 2 k1 polytope|Uniform 2&lt;sub&gt;''k''1&lt;/sub&gt; polytope]]
*[[Uniform k 21 polytope|Uniform ''k''&lt;sub&gt;21&lt;/sub&gt; polytope]]

;Honeycombs
*[[Hypercubic honeycomb]]
*[[Alternated hypercubic honeycomb]]

==Geometric operators==
*[[Rectification (geometry)]]
*[[Truncation (geometry)]]
*[[Bitruncation]]
*[[Cantellation]]
*[[Runcination]]
*[[Sterication]]
*[[Omnitruncation]]
*[[Expansion (geometry)]]
*[[Snub (geometry)]]
*[[Alternation (geometry)]]
*[[Dual polyhedron]]
*[[Gyration (geometry)]]
*[[Elongation (geometry)]]
*[[Augmentation (geometry)]]
*[[Diminishment (geometry)]]
*[[Greatening (geometry)]]
*[[Aggrandizement (geometry)]]
*[[Stellation]]
*[[Kleetope]]
*[[Conway polyhedron notation]]

==See also==
*[[List of geometry topics]]

{{Polygons}}
{{Polyhedron navigator}}
{{Nonconvex polyhedron navigator}}
{{Polytopes}}

[[Category:Polyhedra| ]]
[[Category:Polygons| ]]
[[Category:Polytopes| ]]
[[Category:Mathematics-related lists|Polygons, polyhedra and polytopes]]</text>
      <sha1>h0fv0r0knxij60081elnz7ei1738duv</sha1>
    </revision>
  </page>
  <page>
    <title>Locally nilpotent</title>
    <ns>0</ns>
    <id>3100179</id>
    <revision>
      <id>666895121</id>
      <parentid>666895009</parentid>
      <timestamp>2015-06-14T12:12:49Z</timestamp>
      <contributor>
        <username>Zundark</username>
        <id>70</id>
      </contributor>
      <comment>better still, we have an article on the Hirsch-Plotkin radical</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1030">{{unreferenced|date=May 2014}}
In the [[mathematics|mathematical]] field of [[commutative algebra]], an [[ideal (ring theory)|ideal]] ''I'' in a [[commutative ring]] ''A'' is '''locally nilpotent''' at a [[prime ideal]] ''p'' if ''I''&lt;sub&gt;''p''&lt;/sub&gt;, the [[Localization of a ring|localization]] of ''I'' at ''p'', is a [[nilpotent ideal]] in ''A''&lt;sub&gt;''p''&lt;/sub&gt;.

In non-commutative algebra and group theory, an algebra or group is locally nilpotent if and only if every finitely generated subalgebra or subgroup is nilpotent.  The subgroup generated by the normal locally nilpotent subgroups is called the [[Hirsch–Plotkin radical]] and is the generalization of the [[Fitting subgroup]] to groups without the ascending chain condition on normal subgroups.  

A locally nilpotent ring is one in which every finitely generated subring is nilpotent: locally nilpotent rings form a [[radical class]], giving rise to the [[Levitzki radical]].

{{DEFAULTSORT:Locally Nilpotent}}
[[Category:Commutative algebra]]


{{algebra-stub}}</text>
      <sha1>37hjip00es25ig8vhmvy7eod54xucx0</sha1>
    </revision>
  </page>
  <page>
    <title>Math Horizons</title>
    <ns>0</ns>
    <id>21340642</id>
    <revision>
      <id>830661293</id>
      <parentid>819574949</parentid>
      <timestamp>2018-03-16T05:30:32Z</timestamp>
      <contributor>
        <ip>131.191.72.93</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2425">{{Infobox Magazine
| title           = Math Horizons
| image_file      = Math Horizons cover November 2008.jpg
| image_size      = 217 px
| image_caption   = Cover of November 2008 issue
| editor          = Dave Richeson
| editor_title    = Editors
| previous_editor = Steve Abbot and Bruce Torrence; Arthur Benjamin and Jennifer Quinn; Deanna Haunsperger and Steve Kennedy; Don Albers
| staff_writer    = 
| frequency       = 4 times yearly
| circulation     = 
| category        = 
| company         = [[Taylor &amp; Francis]] for the [[Mathematical Association of America]]
| publisher       = 
| firstdate       = 1993
| country         = [[United States]]
| based           = [[Washington, D.C.]]
| language        = English
| website         = http://www.maa.org/mathhorizons/
| issn            = 1072-4117
}}

'''''Math Horizons''''' is a magazine aimed at undergraduates interested in mathematics, published by the [[Mathematical Association of America]]. It publishes expository articles about "beautiful mathematics" as well as articles about the culture of mathematics covering mathematical people, institutions, humor, games, cartoons, and book reviews.&lt;ref&gt;
{{cite web |url=http://www.maa.org/mathhorizons/author_instructions.html |title=Math Horizons: Instructions for Authors |accessdate=2009-01-31 |work= |publisher=Mathematical Association of America |date=January 3, 2009}}
&lt;/ref&gt;

The MAA gives the [[Trevor Evans Award]]s annually to "authors of exceptional articles that are accessible to undergraduates" that are published in ''Math Horizons''.&lt;ref&gt;
{{cite web |url=http://www.maa.org/awards/evans.html |title=The Mathematical Association of America's Trevor Evans Awards |accessdate=2009-01-31 |work= |publisher=Mathematical Association of America |date=October 16, 2008}}
&lt;/ref&gt;

==Notes==
{{Reflist}}

==Further reading==
* {{cite book |editor1-first=Deanna |editor1-last=Haunsperger |editor2-first=Stephen |editor2-last=Kennedy |title=The Edge of the Universe: Celebrating Ten Years of Math Horizons|year=2006|publisher= Mathematical Association of America |location=Washington, D.C.|isbn=978-0-88385-555-3 }}

==External links==
*{{official|http://www.maa.org/mathhorizons/}}
*[https://www.jstor.org/journal/mathhorizons ''Math Horizons''] at [[JSTOR]]
*[http://www.tandfonline.com/loi/umho20 ''Math Horizons''] at [[Taylor &amp; Francis]] Online

{{mathpublication-stub}}
[[Category:Mathematics journals]]</text>
      <sha1>69zlfnga4bq08e23bqoga9ibw2xl0yn</sha1>
    </revision>
  </page>
  <page>
    <title>Meaning and Necessity</title>
    <ns>0</ns>
    <id>35811096</id>
    <revision>
      <id>847821627</id>
      <parentid>847819554</parentid>
      <timestamp>2018-06-28T00:56:02Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Cleanup section}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4398">{{Infobox book | &lt;!-- See Wikipedia:WikiProject_Books --&gt;
| name = Meaning and Necessity: A Study in Semantics and Modal Logic
| image = Meaning and Necessity.jpg
| caption = Cover of the first edition
| author = [[Rudolf Carnap]]
| country = United States
| language = English
| subject = [[Logic]]
| publisher = [[University of Chicago Press]]
| pub_date = 1947
| media_type = Print ([[Hardcover]] and [[Paperback]])
| pages =
| isbn = 978-0226093475
}}
'''''Meaning and Necessity: A Study in Semantics and Modal Logic''''' is a 1947 book about [[logic]] by the philosopher [[Rudolf Carnap]].

==Background==
''Meaning and Necessity'' was the culmination of Carnap's concern with the [[semantics]] of natural and [[formal language]]s, which developed subsequent to his publication of ''The Logical Syntax of Language'' in 1934.&lt;ref&gt;[[#Low05|Lowe 2005]]. pp. 126-127.&lt;/ref&gt;

==Summary==
{{cleanup section||reason=Section is currently based on secondary sources discussing the work. It should be based principally on the book itself|date=June 2018}}
Carnap attempts to develop a new method for analyzing the meanings of linguistic expressions as well as to lay a semantic foundation for modal logic. Carnap maintains that his new method consists in doing away with the traditional assumption that linguistic expressions name concrete or abstract entities and in replacing it with the ascription to them of intensions and extensions. He states that linguistic expressions designate their intensions and extensions: every designation refers to both an intension and an extension.&lt;ref&gt;[[#Aye82|Ayer 1982]]. p. 157.&lt;/ref&gt;

The intensional entities to which individual constants or descriptions, predicates, and declarative sentences are respectively said to refer are individual concepts, properties and propositions, the corresponding extensions being individuals, classes and truth-values. Carnap insists that intensions, including individual concepts, are objectively real, not mental concepts. However, he rejects the charge of hypostatization: individual concepts and properties and propositions must not be considered as things, but this does not prevent them from being genuine objective entities.&lt;ref&gt;[[#Aye82|Ayer 1982]]. p. 157.&lt;/ref&gt;

Carnap's method is an alternative to [[Gottlob Frege]]'s theory of sense and reference, which he refers to as the "method of extension and intension". Carnap holds that his method provides the most economical account of the logical behavior of expressions in modal contexts - for instance, the expressions '9' and '7' in the sentence '9 is necessarily greater than 7.' His criticism of Frege involves a rejection of the traditional category of names, conceived as a class of expressions each of which stands for a unique thing.&lt;ref&gt;[[#Low05|Lowe 2005]]. pp. 126-127.&lt;/ref&gt;

==Reception==
''Meaning and Necessity'' was influential, and laid the foundations of much subsequent work in the semantics of [[modal logic]].&lt;ref&gt;[[#Low05|Lowe 2005]]. pp. 126-127.&lt;/ref&gt; The work is seen by the British philosopher [[A. J. Ayer]] as the most important of Carnap's three books on semantics, the other two being ''Introduction to Semantics'' (1942) and ''Formalization of Logic'' (1943). Ayer criticizes the book, on the grounds that since, according to Carnap, linguistic expressions designate their intensions and extensions, it is not clear that the difference between Carnap's view and what Carnap calls the traditional assumption that linguistic expressions name concrete or abstract entities is more than nominal.&lt;ref&gt;[[#Aye82|Ayer 1982]]. p. 157.&lt;/ref&gt;

==References==

===Footnotes===
{{reflist|20em}}

===Bibliography===
;Books
{{refbegin}}
* {{cite book |author=Ayer, A. J. |title=Philosophy in the Twentieth Century |publisher=Unwin Paperbacks |location=London |year=1982 |isbn=0-04-100044-7 |oclc= |doi= |accessdate=}}
* {{cite book |author=Lowe, E. J. |editor=Honderich, Ted |title=The Oxford Companion to Philosophy |publisher=Oxford University Press |location=Oxford |year=2005 |isbn=0-19-926479-1 |oclc= |doi= |accessdate=}}
{{refend}}

[[Category:1947 books]]
[[Category:Analytic philosophy literature]]
[[Category:English-language books]]
[[Category:Meaning (philosophy of language)]]
[[Category:Modal logic]]
[[Category:Necessity]]
[[Category:Philosophy of language literature]]
[[Category:Semantics]]
[[Category:University of Chicago Press books]]</text>
      <sha1>q89kpgbktmuytu7syp78yvwfll11qwz</sha1>
    </revision>
  </page>
  <page>
    <title>Metavariable</title>
    <ns>0</ns>
    <id>29557417</id>
    <revision>
      <id>822493847</id>
      <parentid>821661955</parentid>
      <timestamp>2018-01-26T18:05:33Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3007">{{for|the term as used in computer science and programming|Metasyntactic variable}}
In [[logic]], a '''metavariable''' (also '''metalinguistic variable'''&lt;ref&gt;{{harvnb|Hunter|page=13}}.&lt;/ref&gt; or '''syntactical variable'''&lt;ref&gt;{{harvnb|Shoenfield|2001|page=7}}.&lt;/ref&gt;) is a [[symbol (formal)|symbol]] or symbol string which belongs to a [[metalanguage]] and stands for elements of some [[object language]]. For instance, in the sentence

:''Let '''A''' and '''B''' be two sentences of a language ℒ''

the symbols '''A''' and '''B''' are part of the metalanguage in which the statement about the object language ℒ is formulated.

[[John Corcoran (logician)|John Corcoran]] considers this terminology unfortunate because it obscures the use of [[schema (logic)|schema]]ta and because such "variables" do not actually range over a domain.&lt;ref&gt;{{harvnb|Corcoran|2006|page=220}}.&lt;/ref&gt;{{rp|220|date=November 2012}}

The convention is that a metavariable is to be uniformly substituted with the same instance in all its appearances in a given schema. This is in contrast with [[nonterminal]] symbols in [[formal grammars]] where the nonterminals on the right of a production can be substituted by different instances.&lt;ref name="Tennent2002"&gt;{{harvnb|Tennent|2002|pages=36–37, 210}}.&lt;/ref&gt;

Attempts to formalize the notion of metavariable result in some kind of [[type theory]].&lt;ref&gt;Masahiko Sato, Takafumi Sakurai, Yukiyoshi Kameyama, and Atsushi Igarashi. "[http://www.sato.kuis.kyoto-u.ac.jp/~masahiko/papers/csl-03.ps Calculi of Meta-variables]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}" in ''Computer Science Logic. 17th International Workshop CSL 2003. 12th Annual Conference of the [[EACSL]]. 8th Kurt Gödel Colloquium, KGC 2003, Vienna, Austria, August 25-30, 2003. Proceedings'', Springer [[Lecture Notes in Computer Science]] 2803. {{ISBN|3-540-40801-0}}. pp. 484–497&lt;/ref&gt;

==See also==
*[[Explicit substitution]]

== Notes ==
{{Reflist}}

==References==
* {{cite journal|ref=harv|last1=Corcoran|first1=J.|year=2006|title=Schemata: the Concept of Schema in the History of Logic|journal=Bulletin of Symbolic Logic|volume=12|pages=219–240|url=https://philpapers.org/archive/CORSTC.pdf}}
* {{cite book|ref=harv|last1=Hunter|first1=Geoffrey|author1-link=Geoffrey Hunter (logician)|title=Metalogic: An Introduction to the Metatheory of Standard First-Order Logic|url=https://books.google.com/books?id=oHpMtskGcv0C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false}}
* {{Cite book |ref=harv| last1=Shoenfield | first1=Joseph R. | author1-link=Joseph R. Shoenfield | title=Mathematical Logic | origyear=1967 | publisher=[[A K Peters]] | edition=2nd | isbn=978-1-56881-135-2 | year=2001}}
* {{cite book|ref=harv|last1=Tennent|first=R. D.|title=Specifying Software: A Hands-On Introduction|year=2002|publisher=Cambridge University Press|isbn=978-0-521-00401-5}}


[[Category:Metalogic]]
[[Category:Variables (mathematics)]]
[[Category:Syntax (logic)]]
[[Category:Logic symbols]]</text>
      <sha1>e0otbtm7o6220j1t2stz0al956puiwx</sha1>
    </revision>
  </page>
  <page>
    <title>Network on a chip</title>
    <ns>0</ns>
    <id>3842768</id>
    <revision>
      <id>863725645</id>
      <parentid>863725566</parentid>
      <timestamp>2018-10-12T16:21:55Z</timestamp>
      <contributor>
        <username>Daviddwd</username>
        <id>14327137</id>
      </contributor>
      <minor/>
      <comment>typo fix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12659">{{Use American English|date=October 2018}}{{Network science}}

A '''network on a chip''' or '''network-on-chip''' ('''{{Abbr|NoC|Network on Chip}},''' {{IPAc-en|ˌ|ɛ|n|ˌ|oʊ|ˈ|s|iː}} {{respell|en|oh|SEE}} or {{IPAc-en|n|ɒ|k}} {{respell|knock}})&lt;ref group="nb"&gt;This article uses the convention that "NoC" is pronounced {{IPAc-en|n|ɒ|k}} {{respell|nock}}. Therefore, it uses the convention "a" for the [[indefinite article]] corresponding to NoC ("'''a''' NoC"). Other sources may pronounce it as {{IPAc-en|ˌ|ɛ|n|ˌ|oʊ|ˈ|s|iː|}} {{respell|en|oh|SEE}} and therefore use "'''an''' NoC".&lt;/ref&gt; is a [[Network theory|network]]-based [[Communications system|communications subsystem]] on an [[integrated circuit]] ("microchip"), most typically between [[Modular programming|modules]] in a [[system on a chip]] (SoC).  The modules on the IC are typically semiconductor [[IP core|IP cores]] schematizing various functions of the [[computer system]], and are designed to be [[Modularity (networks)|modular]] in the sense of [[network science]].  The network on chip is a [[Router (computing)|router]]-based [[packet switching]] network between SoC [[Modularity|modules]].  

NoC technology applies the theory and methods of [[Computer network|computer networking]] to on-chip [[communication]] and brings notable improvements over conventional [[Bus (computing)|bus]] and [[Crossbar switch|crossbar]] [[Network architecture|communication architectures]].  Networks-on-chip come in many [[Network topology|network topologies]], many of which are still experimental as of 2018. 

Networks-on-chip improve the [[scalability]] of systems-on-chip and the [[power efficiency]] of complex SoCs compared to other communication subsystem designs.  A very common NoC used in contemporary [[Personal computer|personal computers]] is a [[graphics processing unit]] (GPU), which is commonly used in [[computer graphics]], [[PC game|video gaming]] and [[AI accelerator|accelerating]] [[artificial intelligence]].  They are an [[Emerging technologies|emerging technology]], with projections for large growth in the near future as [[manycore]] computer architectures become more common.

== Structure ==
{{Expand section|date=October 2018}}
Networks-on-chip can span synchronous and asynchronous clock domains, known as [[clock domain crossing]], or use unclocked [[asynchronous circuit|asynchronous]] logic.  NoCs support [[Globally asynchronous locally synchronous|globally asynchronous, locally synchronous]] electronics architectures, allowing each [[processor core]] or functional unit on the System-on-Chip to have its own [[clock domain]].&lt;ref name=":02"&gt;{{Cite book|url=https://www.worldcat.org/oclc/895661009|title=Network-on-chip: the Next Generation of System-on-Chip Integration|last=Kundu|first=Santanu|last2=Chattopadhyay|first2=Santanu|publisher=CRC Press|others=|year=2014|isbn=9781466565272|edition=1st|location=Boca Raton, FL|pages=3|oclc=895661009}}&lt;/ref&gt;

== Architectures ==
{{Expand section|date=October 2018}}
NoC architectures typically model [[Sparsity|sparse]] [[Small-world network|small-world networks]] (SWNs) and [[Scale-free network|scale-free networks]] (SFNs) to limit the number, length, area and [[power consumption]] of interconnection wires and [[Point-to-point (telecommunications)|point-to-point]] connections.

==Benefits ==
Traditionally, ICs have been designed with dedicated [[Point-to-point (telecommunications)|point-to-point]] connections, with one wire dedicated to each signal.  This results in a [[Dense network|dense network topology]].  For large designs, in particular, this has several limitations from a [[Integrated circuit design|physical design]] viewpoint.  It requires [[Power consumption|power]] [[Quadratic function|quadratic]] in the number of interconnections.  The wires occupy much of the [[Die (integrated circuit)|area of the chip]], and in [[nanometer]] [[CMOS]] technology, interconnects dominate both performance and dynamic [[power dissipation]], as signal propagation in wires across the chip requires multiple [[Clock cycle|clock cycles]].  This also allows more [[parasitic capacitance]], [[Parasitic element (electrical networks)|resistance and inductance]] to accrue on the circuit.  (See [[Rent's rule]] for a discussion of wiring requirements for point-to-point connections).

[[Sparse network|Sparsity]] and [[Locality of reference|locality]] of interconnections in the communications subsystem yield several improvements over traditional [[Bus (computing)|bus]]-based and [[Crossbar switch|crossbar]]-based systems.

{{Clear}}

==Parallelism and scalability==
The wires in the links of the network-on-chip are shared by many [[Signaling (telecommunications)|signals]]. A high level of [[Parallel computing|parallelism]] is achieved, because all [[data link|data links]] in the NoC can operate simultaneously on different [[Packet switching|data packets]].{{Why?|date=October 2018}} Therefore, as the complexity of [[Very-large-scale integration|integrated systems]] keeps growing, a NoC provides enhanced performance (such as [[throughput]]) and [[scalability]] in comparison with previous communication architectures (e.g., dedicated point-to-point signal [[wire]]s, shared [[Bus (computing)|buses]], or segmented buses with [[Bridging (networking)|bridges]]). Of course, the [[Algorithm|algorithms]]{{Which|date=October 2018}} must be designed in such a way that they offer [[Massively parallel|large parallelism]] and can hence utilize the potential of NoC.

==Current research==
Some researchers{{Who|date=June 2015}} think that NoCs need to support [[quality of service]] (QoS), namely achieve the various requirements in terms of [[throughput]], end-to-end delays, [[Fairness measure|fairness]],&lt;ref&gt;{{cite journal|title=Balancing On-Chip Network Latency in Multi-Application Mapping for Chip-Multiprocessors|journal=IPDPS|date=May 2014}}&lt;/ref&gt; and [[Time limit|deadlines]].{{citation needed|date=June 2015}} Real-time computation, including audio and video playback, is one reason for providing QoS support. However, current system implementations like [[VxWorks]], [[RTLinux]] or [[QNX]] are able to achieve sub-millisecond real-time computing without special hardware.{{citation needed|date=June 2015}} 

This may indicate that for many [[Real-time computing|real-time]] applications the service quality of existing on-chip interconnect infrastructure is sufficient, and dedicated [[hardware logic]] would be necessary to achieve microsecond precision, a degree that is rarely needed in practice for end users (sound or video jitter need only tenth of milliseconds latency guarantee).  Another motivation for NoC-level [[quality of service]] (QoS) is to support multiple concurrent users sharing resources of a single [[Multi-core (computing)|chip multiprocessor]] in a public [[cloud computing]] infrastructure.  In such instances, hardware QoS logic enables the service provider to make [[Service-level agreement|contractual guarantees]] on the level of service that a user receives, a feature that may be deemed desirable by some corporate or government clients.{{citation needed|date=June 2015}}

Many challenging research problems remain to be solved at all levels, from the physical link level through the network level, and all the way up to the system architecture and application software. The first dedicated research symposium on networks on chip was held at [[Princeton University]], in May 2007.&lt;ref&gt;[http://2007.nocsymposium.org/ NoCS 2007] website.&lt;/ref&gt; The second [[Institute of Electrical and Electronics Engineers|IEEE]] ''International Symposium on Networks-on-Chip'' was held in April 2008 at [[Newcastle University]].

Research has been conducted on integrated [[Waveguide (optics)|optical waveguides]] and devices comprising an '''optical network on a chip '''('''ONoC''').&lt;ref&gt;[http://www.cl.cam.ac.uk/users/rdm34/onChipNetBib/browser.htm On-Chip Networks Bibliography]&lt;/ref&gt;&lt;ref name="ONoC"&gt;[http://www.ece.ust.hk/~eexu/bibliography.html Inter/Intra-Chip Optical Network Bibliography-]&lt;/ref&gt;

==Benchmarks==
NoC development and studies require comparing different proposals and options.  NoC traffic patterns are under development to help such evaluations.  Existing NoC benchmarks include NoCBench and MCSL NoC Traffic Patterns.&lt;ref name="MCSL NoC Traffic Patterns"&gt;{{Cite web|url=http://www.ece.ust.hk/~eexu/traffic.html|title=NoC traffic|website=www.ece.ust.hk|access-date=2018-10-08}}&lt;/ref&gt;

==Interconnect processing unit==
An ''interconnect processing unit'' (IPU)&lt;ref&gt;Marcello Coppola, Miltos D. Grammatikakis, Riccardo Locatelli, Giuseppe Maruccia, Lorenzo Pieralisi, "Design of Cost-Efficient Interconnect Processing Units: Spidergon STNoC", CRC Press, 2008, {{ISBN|978-1-4200-4471-3}}&lt;/ref&gt; is a on-chip communication network with [[computer hardware|hardware]] and [[software]] components which jointly implement key functions of different [[System on a chip|system-on-chip]] programming models through a set of communication and [[Synchronization primitive|synchronization primitives]] and provide [[High- and low-level|low-level]] platform services to enable advanced features{{Which|date=October 2018}} in modern heterogeneous applications{{Definition needed|date=October 2018}} on a single [[Die (integrated circuit)|die]].

==Commercial providers ==
* [http://www.netspeedsystems.com/ NetSpeed Systems]
* [http://www.arteris.com/ Arteris] 
* [http://sonicsinc.com/ Sonics]
* [http://aimstechnologyinc.com/ Aims Technology Inc]

==See also==
*[[Electronic design automation]] (EDA)
*[[Integrated circuit design]]
*[[MPSoC]]
*[[manycore]]
* [[CUDA]]
*[[Globally asynchronous locally synchronous|Globally asynchronous, locally synchronous]]
*[[Network architecture]]

== Notes ==
{{Reflist|group=nb}}

== References ==
{{Reflist}}
Adapted from [http://www.ee.technion.ac.il/people/kolodny/ Avinoam Kolodny's]'s column in the ACM [http://www.sigda.org SIGDA] [https://web.archive.org/web/20070208034716/http://www.sigda.org/newsletter/index.html e-newsletter] by [http://www.eecs.umich.edu/~imarkov/ Igor Markov] &lt;br&gt;The original text can be found at http://www.sigda.org/newsletter/2006/060415.txt

== Further reading ==

* {{Cite book|url=https://www.worldcat.org/oclc/895661009|title=Network-on-chip: the Next Generation of System-on-Chip Integration|last=Kundu|first=Santanu|last2=Chattopadhyay|first2=Santanu|publisher=CRC Press|year=2014|isbn=9781466565272|edition=1st|location=Boca Raton, FL|pages=|oclc=895661009}}
* {{Cite book|url=https://www.worldcat.org/oclc/894609116|title=Networks-on-Chip: From Implementations to Programming Paradigms|publisher=Morgan Kaufmann|others=|year=2014|isbn=9780128011782|edition=1st|location=Amsterdam, NL|pages=|oclc=894609116|authors=Sheng Ma, Libo Huang, Mingche Lai, Wei Shi, Zhiying Wang}}
* {{Cite book|url=https://www.worldcat.org/oclc/890132032|title=Microarchitecture of Network-on-Chip Routers: A Designer's Perspective|authors=Giorgios Dimitrakopoulos, Anastasios Psarras, Ioannis Seitanidis|isbn=9781461443018|location=New York, NY|oclc=890132032|edition=1st}}
* {{Cite book|url=https://www.worldcat.org/oclc/991871622|title=On-chip Networks|authors=Natalie Enright Jerger, Tushar Krishna, Li-Shiuan Peh|isbn=9781627059961|edition=2nd|location=San Rafael, California|oclc=991871622}}

==External links==
* [http://async.org.uk/noc2006 DATE 2006 workshop on NoC]
* [http://2007.nocsymposium.org/ NoCS 2007 - The 1st ACM/IEEE International Symposium on Networks-on-Chip]
* [http://async.org.uk/nocs2008 NoCS 2008 - The 2nd IEEE International Symposium on Networks-on-Chip]
* Cristian Grecu, Andrè Ivanov, Partha Pande, Axel Jantsch, Erno Salminen, Umit Ogras, Radu Marculescu, An Initiative towards Open Network-on-Chip Benchmarks, OCP-Ip white paper, 2007, [Online] http://www.ocpip.org/uploads/documents/NoC-Benchmarks-WhitePaper-15.pdf
* Jean-Jacques Lecler, Gilles Baillieu, ''Design Automation for Embedded Systems (Springer), "Application driven network-on-chip architecture exploration &amp; refinement for a complex SoC", June 2011, Volume 15, Issue 2, pp 133–158, [[doi:10.1007/s10617-011-9075-5]] [Online] http://www.arteris.com/hs-fs/hub/48858/file-14363521-pdf/docs/springer-appdrivennocarchitecture8.5x11.pdf''

{{CPU technologies}}
{{Hardware acceleration}}

[[Category:Electronic design automation]]
[[Category:Integrated circuits]]
[[Category:System on a chip]]
[[Category:Network on a chip]]
[[Category:Hardware acceleration]]
[[Category:Network theory]]
[[Category:Computer networking]]
[[Category:Parallel computing]]
[[Category:Communication circuits]]
[[Category:Modularity]]</text>
      <sha1>hij2iqspa35zjhuw9zbar5c3jzq8e14</sha1>
    </revision>
  </page>
  <page>
    <title>New York Number Theory Seminar</title>
    <ns>0</ns>
    <id>10843656</id>
    <revision>
      <id>845822717</id>
      <parentid>823646365</parentid>
      <timestamp>2018-06-14T11:29:04Z</timestamp>
      <contributor>
        <ip>213.24.125.160</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2577">{{Notability|date=July 2009}}

'''The New York Number Theory Seminar''' is a research [[seminar]] devoted to the theory of numbers and related parts of [[mathematics]] and [[physics]]. In 1981, Number Theorists Harvey Cohn, David and Gregory [[Chudnovsky brothers|Chudnovsky]] and Melvyn B. Nathanson, who were then affiliated with [[City University of New York|City College (CUNY)]], [[Columbia University]], and [[Rutgers–Newark]], and currently at [[Lehman College]] (CUNY) and the [[Polytechnic University of New York]], began to meet regularly, usually on Thursday afternoons, during the academic year at the Graduate Center of the City University of New York. The location was convenient to all parts of the city and major transportation hubs. Harvey Cohn has retired, but Nathanson is now based in the City University and acts as the host of the seminar.  The New York Number Theory Seminar also organizes an annual Workshop on Combinatorial and Additive Number Theory (CANT) at the CUNY Graduate Center. Proceedings of the seminar have been published regularly by [[Springer-Verlag]].

The Graduate Center is currently located at 365 Fifth Avenue, between 34th and 35th Streets. The Ph.D. program in mathematics is located on the fourth floor. The seminar has met on Thursday afternoons for several years.

== Key Speakers ==
[[Harald Helfgott]]: In 2013, he released two papers claiming to be a proof of [[Goldbach's weak conjecture]]; the claim is now broadly accepted. The problem had a history of over 250 years without a full proof.

Tom Sanders: Went to Oxford University.

[[Melvyn B. Nathanson]]: Frequent collaborator with [[Paul Erdős]], who has published more papers in the field of mathematics than any other person. Erdős has collaborated with over 500 people, and wrote 19 papers in number theory with Nathanson. He also organizes the Workshop on Combinatorial and Additive Number Theory, which has been held annually at the Graduate Center, CUNY since 2003. Nathanson's essays on political and social issues related to science have appeared in The New York Times, The Bulletin of the Atomic Scientists, The Mathematical Intelligencer, Notices of the American Mathematical Society, and other publications.

==External links==
*[http://www.math.rutgers.edu/~bumby/nyntsem/ Lecture schedule for the NNTS, spring semester, 2007]
*http://www.math.columbia.edu/~goldfeld/JointNTS.html
*http://www.theoryofnumbers.com/
*http://www.numbertheory.org/ntw/N3.html

[[Category:Mathematics education]]
[[Category:City University of New York]]


{{numtheory-stub}}</text>
      <sha1>q55u0g4fv8u5aqgcyyo4vp9olkldpca</sha1>
    </revision>
  </page>
  <page>
    <title>Panlogism</title>
    <ns>0</ns>
    <id>24184879</id>
    <revision>
      <id>791461873</id>
      <parentid>757976668</parentid>
      <timestamp>2017-07-20T12:20:56Z</timestamp>
      <contributor>
        <username>Fadesga</username>
        <id>5042921</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="798">In [[philosophy]], '''panlogism''' is a [[Hegelianism|Hegelian]] doctrine that holds that the [[universe]] is the act or realization of [[Logos]].&lt;ref&gt;[http://www.ditext.com/runes/p.html "Dagobert D. Runes, Dictionary of Philosophy, 1942"] Retrieved September 1, 2009&lt;/ref&gt;&lt;ref&gt;[http://www.thefreedictionary.com/panlogism "Panlogism" at the free dictionary] Retrieved September 1, 2009&lt;/ref&gt;  According to the doctrine of panlogism, [[logic]] and [[ontology]] are the same study.&lt;ref&gt;[http://atheism.about.com/library/glossary/general/bldef_panlogism.htm "Panlogism" at About.com] Retrieved September 1, 2009&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Georg Wilhelm Friedrich Hegel]]
[[Category:Metaphysical theories]]
[[Category:Ontology]]
[[Category:Theories of deduction]]


{{Ontology-stub}}</text>
      <sha1>muslped4rmo0f9jmev0do0wdz583zcj</sha1>
    </revision>
  </page>
  <page>
    <title>Pebble motion problems</title>
    <ns>0</ns>
    <id>24615296</id>
    <revision>
      <id>816260312</id>
      <parentid>816260260</parentid>
      <timestamp>2017-12-20T07:11:16Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* References */ unnecessary brackets</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5279">The '''pebble motion problems''', or '''pebble motion on graphs''', are a set of related problems in [[graph theory]] dealing with the movement of multiple objects ("pebbles") from vertex to vertex in a [[Graph (discrete mathematics)|graph]] with a constraint on the number of pebbles that can occupy a vertex at any time. Pebble motion problems occur in domains such as multi-[[robot]] [[motion planning]] (in which the pebbles are robots) and [[network routing]] (in which the pebbles are [[Data packet|packets]] of data). The best-known example of a pebble motion problem is the famous [[15 puzzle]] where a disordered group of fifteen tiles must be rearranged within a 4x4 grid by sliding one tile at a time.

==Theoretical formulation==
The general form of the pebble motion problem is Pebble Motion on Graphs{{r|Kornhauser}} formulated as follows:

Let &lt;math&gt;G = (V,E)&lt;/math&gt; be a graph with &lt;math&gt;n&lt;/math&gt; vertices. Let &lt;math&gt;P = \{1,\ldots,k\}&lt;/math&gt; be a set of pebbles with &lt;math&gt;k &lt; n&lt;/math&gt;. An arrangement of pebbles is a mapping &lt;math&gt;S : P \rightarrow V&lt;/math&gt; such that &lt;math&gt;S(i) \neq S(j)&lt;/math&gt; for &lt;math&gt;i \neq j&lt;/math&gt;. A move &lt;math&gt;m = (p, u, v)&lt;/math&gt; consists of transferring pebble &lt;math&gt;p&lt;/math&gt; from vertex &lt;math&gt;u&lt;/math&gt; to adjacent unoccupied vertex &lt;math&gt;v&lt;/math&gt;. The Pebble Motion on Graphs problem is to decide, given two arrangements &lt;math&gt;S_0&lt;/math&gt; and &lt;math&gt;S_+&lt;/math&gt;, whether there is a sequence of moves that transforms &lt;math&gt;S_0&lt;/math&gt; into &lt;math&gt;S_+&lt;/math&gt;.

===Variations===
Common variations on the problem limit the structure of the graph to be:
* a [[Tree graph|tree]]{{r|Auletta}}
* a [[Lattice graph|square grid]],{{r|Calinescu}}
* a [[Biconnected graph|bi-connected]] graph.{{r|Surynek}}

Another set of variations consider the case in which some{{r|Papadimitriou}} or all{{r|Calinescu}} of the pebbles are unlabeled and interchangeable.

Other versions of the problem seek not only to prove reachability but to find a (potentially optimal) sequence of moves (i.e. a plan) which performs the transformation.

==Complexity==
Finding the shortest path in the pebble motion on graphs problem (with labeled pebbles) is known to be [[NP hard|NP-hard]]{{r|Ratner}} and [[APX|APX-hard]].{{r|Calinescu}}  The unlabeled problem can be solved in polynomial time when using the cost metric mentioned above (minimizing the total number of moves to adjacent vertices), but is [[NP hard|NP-hard]] for other natural cost metrics.{{r|Calinescu}}

== References ==
{{Reflist|refs=

&lt;ref name=Auletta&gt;{{citation
 | last1 = Auletta | first1 = V.
 | last2 = Monti | first2 = A.
 | last3 = Parente | first3 = M.
 | last4 = Persiano | first4 = P.
 | doi = 10.1007/PL00009259
 | issue = 3
 | journal = Algorithmica
 | mr = 1664708
 | pages = 223–245
 | title = A linear-time algorithm for the feasibility of pebble motion on trees
 | volume = 23
 | year = 1999}}&lt;/ref&gt;

&lt;ref name=Calinescu&gt;{{citation
 | last1 = Călinescu | first1 = Gruia
 | last2 = Dumitrescu | first2 = Adrian
 | last3 = Pach | first3 = János | author3-link = János Pach
 | doi = 10.1137/060652063
 | issue = 1
 | journal = [[SIAM Journal on Discrete Mathematics]]
 | mr = 2383232
 | pages = 124–138
 | title = Reconfigurations in graphs and grids
 | volume = 22
 | year = 2008}}&lt;/ref&gt;

&lt;ref name=Kornhauser&gt;{{citation
 | last1 = Kornhauser | first1 = Daniel
 | last2 = Miller | first2 = Gary | author2-link = Gary Miller (computer scientist)
 | last3 = Spirakis | first3 = Paul | author3-link = Paul Spirakis
 | contribution = Coordinating pebble motion on graphs, the diameter of permutation groups, and applications
 | doi = 10.1109/sfcs.1984.715921
 | publisher = IEEE Computer Society Press
 | title = Proceedings of the 25th Annual [[Symposium on Foundations of Computer Science]] (FOCS 1984)
 | year = 1984}}&lt;/ref&gt;

&lt;ref name=Papadimitriou&gt;{{citation
 | last1 = Papadimitriou | first1 = Christos H. | author1-link = Christos Papadimitriou
 | last2 = Raghavan | first2 = Prabhakar | author2-link = Prabhakar Raghavan
 | last3 = Sudan | first3 = Madhu | author3-link = Madhu Sudan
 | last4 = Tamaki | first4 = Hisao
 | contribution = Motion planning on a graph
 | doi = 10.1109/sfcs.1994.365740
 | publisher = IEEE Computer Society Press
 | title = Proceedings of the 35th Annual [[Symposium on Foundations of Computer Science]] (FOCS 1994)
 | year = 1994}}&lt;/ref&gt;

&lt;ref name=Ratner&gt;{{citation
 | last1 = Ratner | first1 = Daniel
 | last2 = Warmuth | first2 = Manfred | author2-link = Manfred K. Warmuth
 | doi = 10.1016/S0747-7171(08)80001-6
 | issue = 2
 | journal = [[Journal of Symbolic Computation]]
 | mr = 1080669
 | pages = 111–137
 | title = The &lt;math&gt;(n^2-1)&lt;/math&gt;-puzzle and related relocation problems
 | volume = 10
 | year = 1990}}&lt;/ref&gt;

&lt;ref name="Surynek"&gt;{{citation
 | last = Surynek | first = Pavel
 | contribution = A novel approach to path planning for multiple robots in bi-connected graphs
 | doi = 10.1109/robot.2009.5152326
 | publisher = IEEE
 | title = Proceedings of the IEEE [[International Conference on Robotics and Automation]] (ICRA 2009)
 | year = 2009}}&lt;/ref&gt;

}}

{{DEFAULTSORT:Pebble Motion Problems}}
[[Category:Multi-agent systems]]
[[Category:Automated planning and scheduling]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>djc0jfisn48egyv965jcz35ihszimvb</sha1>
    </revision>
  </page>
  <page>
    <title>Penrose graphical notation</title>
    <ns>0</ns>
    <id>2973987</id>
    <revision>
      <id>790740679</id>
      <parentid>786522156</parentid>
      <timestamp>2017-07-15T19:57:36Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Metric tensor */LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8020">In [[mathematics]] and [[physics]], '''Penrose graphical notation''' or '''tensor diagram notation''' is a (usually handwritten) visual depiction of [[multilinear function]]s or [[tensor]]s proposed by [[Roger Penrose]] in 1971.&lt;ref&gt;[[Roger Penrose]], "Applications of negative dimensional tensors," in ''Combinatorial Mathematics and its Applications'', Academic Press (1971). See Vladimir Turaev, ''Quantum invariants of knots and 3-manifolds'' (1994), De Gruyter, p. 71 for a brief commentary.&lt;/ref&gt; A diagram in the notation consists of several shapes linked together by lines. The notation has been studied extensively by [[Predrag Cvitanović]], who used it to classify the [[classical Lie groups]].&lt;ref&gt;{{cite book|author=[[Predrag Cvitanović]] |year=2008 |title=Group Theory: Birdtracks, Lie's, and Exceptional Groups | publisher=Princeton University Press | url=http://birdtracks.eu/}}&lt;/ref&gt; It has also been generalized using [[representation theory]] to [[spin network]]s in physics, and with the presence of [[matrix group]]s to [[trace diagram]]s in [[linear algebra]].

== Interpretations ==

=== Multilinear algebra ===

In the language of [[multilinear algebra]], each shape represents a [[multilinear function]]. The lines attached to shapes represent the inputs or outputs of a function, and attaching shapes together in some way is essentially the [[composition of functions]].

=== Tensors ===

In the language of [[tensor|tensor algebra]], a particular tensor is associated with a particular shape with many lines projecting upwards and downwards, corresponding to [[abstract index notation|abstract]] [[Covariance and contravariance of vectors|upper and lower]] indices of tensors respectively. Connecting lines between two shapes corresponds to [[tensor contraction|contraction of indices]]. One advantage of this [[Mathematical notation|notation]] is that one does not have to invent new letters for new indices. This notation is also explicitly [[basis (linear algebra)|basis]]-independent.&lt;ref&gt;[[Roger Penrose]], ''[[The Road to Reality: A Complete Guide to the Laws of the Universe]]'', 2005, {{isbn|0-09-944068-7}}, Chapter ''Manifolds of n dimensions''.&lt;/ref&gt;

=== Matrices ===
Each shape represents a matrix, and [[tensor product|tensor multiplication]] is done horizontally, and [[matrix multiplication]] is done vertically.

== Representation of special tensors ==

=== Metric tensor ===
The [[metric tensor]] is represented by a U-shaped loop or an upside-down U-shaped loop, depending on the type of tensor that is used.
{|
|[[File:Penrose g.svg|framed|metric tensor &lt;math&gt;g^{ab}&lt;/math&gt;]]
|[[File:Penrose g ab.svg|framed|metric tensor &lt;math&gt;g_{ab}&lt;/math&gt;]]
|}

=== Levi-Civita tensor ===
The [[Levi-Civita tensor|Levi-Civita antisymmetric tensor]] is represented by a thick horizontal bar with sticks pointing downwards or upwards, depending on the type of tensor that is used.
{|
|valign="top"|[[File:Penrose varepsilon a-n.svg|framed|&lt;math&gt;\varepsilon_{ab\ldots n}&lt;/math&gt;]]
|valign="top"|[[File:Penrose epsilon^a-n.svg|framed|&lt;math&gt;\epsilon^{ab\ldots n}&lt;/math&gt;]]
|valign="top"|[[File:Penrose varepsilon a-n epsilon^a-n.svg|framed|&lt;math&gt;\varepsilon_{ab\ldots n}\,\epsilon^{ab\ldots n}&lt;/math&gt;&lt;math&gt;= n!&lt;/math&gt;]]
|}

=== Structure constant ===
&lt;!-- {| 
| --&gt; [[File:Penrose gamma ab^c.svg|thumb|x120px|structure constant &lt;math&gt;{\gamma_{\alpha\beta}}^\chi = -{\gamma_{\beta\alpha}}^\chi&lt;/math&gt;]]
&lt;!-- |[[File:Penrose killing form.svg|thumb|x150px|[[Killing form]] &lt;math&gt;\kappa_{\alpha\beta}=\kappa_{\beta\alpha}=\gamma_{\alpha\zeta}^{\ \ \xi}\,\gamma_{\beta\xi}^{\ \ \zeta}&lt;/math&gt;]]
|}  --&gt;
The structure constants (&lt;math&gt;{\gamma_{ab}}^c&lt;/math&gt;) of a [[Lie algebra]] are represented by a small triangle with one line pointing upwards and two lines pointing downwards.

== Tensor operations ==

=== Contraction of indices ===

[[Tensor contraction|Contraction]] of indices is represented by joining the index lines together.
{|
|[[File:Penrose delta^a b.svg|thumb|x120px|[[Kronecker delta]] &lt;math&gt;\delta^a_b&lt;/math&gt;]]
|[[File:Penrose beta a xi^a.svg|thumb|x120px|[[Dot product]] &lt;math&gt;\beta_a\,\xi^a&lt;/math&gt;]]
|[[File:Penrose g ab g^bc-d^c a-g^cb g ba.svg|thumb|x120px|&lt;math&gt;g_{ab}\,g^{bc} = \delta_a^c = g^{cb}\,g_{ba}&lt;/math&gt;]]
|}

=== Symmetrization ===

[[Symmetric tensor|Symmetrization]] of indices is represented by a thick zig-zag or wavy bar crossing the index lines horizontally.
{|
|[[File:Penrose asymmetric Q^a-n.svg|thumb|x120px|Symmetrization&lt;br/&gt;&lt;math&gt;Q^{(ab\ldots n)}&lt;/math&gt;&lt;br/&gt;(with &lt;math&gt;{}_{Q^{ab}=Q^{[ab]}+Q^{(ab)}}&lt;/math&gt;)]]
|}

=== Antisymmetrization ===

[[Antisymmetric tensor|Antisymmetrization]] of indices is represented by a thick straight line crossing the index lines horizontally.
{|
|[[File:Penrose symmetric E a-n.svg|thumb|x120px|Antisymmetrization&lt;br/&gt;&lt;math&gt;E_{[ab\ldots n]}&lt;/math&gt;&lt;br/&gt;(with &lt;math&gt;{}_{E_{ab}=E_{[ab]}+E_{(ab)}}&lt;/math&gt;)]]
|}

==Determinant==

The determinant is formed by applying antisymmetrization to the indices.
{|
|[[File:Penrose det T.svg|thumb|x120px|[[Determinant]] &lt;math&gt;\det\mathbf{T} = \det\left(T^a_{\ b}\right)&lt;/math&gt;]]
|[[File:Penrose T^-1.svg|thumb|x120px|Inverse of matrix &lt;math&gt;\mathbf{T}^{-1} = \left(T^a_{\ b}\right)^{-1}&lt;/math&gt;]]
|}

=== Covariant derivative ===

The [[covariant derivative]] (&lt;math&gt;\nabla&lt;/math&gt;) is represented by a circle around the tensor(s) to be differentiated and a line joined from the circle pointing downwards to represent the lower index of the derivative.
{|
|[[File:Penrose covariant derivate.svg|framed|covariant derivative &lt;math&gt;
12\nabla_a\left( \xi^f\,\lambda^{(d}_{fb[c}\,D^{e)b}_{gh]} \right)&lt;/math&gt;
&lt;math&gt;= 12\left(  \xi^f (\nabla_a \lambda^{(d}_{fb[c}) \, D^{e)b}_{gh]} + (\nabla_a \xi^f) \lambda^{(d}_{fb[c}\,D^{e)b}_{gh]} + \xi^f \lambda^{(d}_{fb[c} \, (\nabla_a D^{e)b}_{gh]} ) \right)
&lt;/math&gt;]]
|}

== Tensor manipulation ==

The diagrammatic notation is useful in manipulating tensor algebra. It usually involves a few simple "[[Identity (mathematics)|identities]]" of tensor manipulations.

For example, &lt;math&gt;\varepsilon_{a...c} \epsilon^{a...c} = n!&lt;/math&gt;, where ''n'' is the number of dimensions, is a common "identity".

===Riemann curvature tensor===

The Ricci and Bianchi identities given in terms of the Riemann curvature tensor illustrate the power of the notation

{|
|[[File:Penrose riemann curvature tensor.svg|thumb|x120px|Notation for the [[Riemann curvature tensor]]]]
|[[File:Penrose ricci tensor.svg|thumb|x120px|[[Ricci tensor]] &lt;math&gt;R_{ab} = R_{acb}^{\ \ \ c}&lt;/math&gt;]]
|[[File:Penrose ricci identity.svg|thumb|x120px|Ricci identity &lt;math&gt;(\nabla_a\,\nabla_b -\nabla_b\,\nabla_a)\,\mathbf{\xi}^d&lt;/math&gt;&lt;math&gt;= R_{abc}^{\ \ \ d}\,\mathbf{\xi}^c&lt;/math&gt;]]
|[[File:Penrose bianchi identity.svg|thumb|120px|[[Bianchi identity]] &lt;math&gt;\nabla_{[a} R_{bc]d}^{\ \ \ e} = 0&lt;/math&gt;]]
|}

==Extensions==

The notation has been extended with support for [[spinor]]s and [[Twistor theory|twistor]]s.&lt;ref&gt;{{cite book |title= Spinors and Space-Time: Vol I, Two-Spinor Calculus and Relativistic Fields |last1=Penrose |first1=R. |last2=Rindler |first2=W. |pages=424–434 |year=1984 |publisher=Cambridge University Press |isbn=0-521-24527-3 |url= https://books.google.com/books?id=CzhhKkf1xJUC}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title= Spinors and Space-Time: Vol. II, Spinor and Twistor Methods in Space-Time Geometry  |last1=Penrose |first1=R. |last2=Rindler |first2=W. |year=1986 |publisher=Cambridge University Press |isbn=0-521-25267-9 |url=https://books.google.com/books?id=f0mgGmtx0GEC }}&lt;/ref&gt;

==See also==
{{Commons category |Penrose graphical notation}}
* [[Abstract index notation]]
* [[Angular momentum diagrams (quantum mechanics)]]
* [[Braided monoidal category]]
* [[Categorical quantum mechanics]] uses tensor diagram notation
* [[Ricci calculus]]
* [[Spin network]]s
* [[Trace diagram]]

== Notes ==
&lt;references/&gt;

{{Roger Penrose}}
{{tensors}}

[[Category:Tensors]]
[[Category:Theoretical physics]]
[[Category:Mathematical notation]]
[[Category:Diagram algebras]]</text>
      <sha1>6z02nk0g0ede6veas4xroleym8w3nkf</sha1>
    </revision>
  </page>
  <page>
    <title>Ping-pong lemma</title>
    <ns>0</ns>
    <id>18786361</id>
    <revision>
      <id>845671091</id>
      <parentid>842423340</parentid>
      <timestamp>2018-06-13T10:41:07Z</timestamp>
      <contributor>
        <ip>2A00:5BA0:20:67:0:0:0:104</ip>
      </contributor>
      <comment>/* Ping-pong lemma for several subgroups */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16804">In [[mathematics]], the '''ping-pong lemma''', or '''table-tennis lemma''', is any of several mathematical statements that ensure that several elements in a group [[group action|acting]] on a set freely [[Generating set of a group|generates]] a [[free group|free]] [[subgroup]] of that group.

==History==

The ping-pong argument goes back to late 19th century and is commonly attributed&lt;ref name="DH"/&gt; to [[Felix Klein]] who used it to study subgroups of [[Kleinian group]]s, that is, of discrete groups of isometries of the [[hyperbolic 3-space]] or, equivalently [[Möbius transformation]]s of the [[Riemann sphere]]. The ping-pong lemma was a key tool used by [[Jacques Tits]] in his 1972 paper&lt;ref name="T"&gt;J. Tits. [http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WH2-4D7K6RV-19X&amp;_user=10&amp;_coverDate=02%2F29%2F1972&amp;_rdoc=3&amp;_fmt=high&amp;_orig=browse&amp;_srch=doc-info(%23toc%236838%231972%23999799997%23518342%23FLP%23display%23Volume)&amp;_cdi=6838&amp;_sort=d&amp;_docanchor=&amp;_ct=12&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=bb8d98f320404accc3525ca235cf821e ''Free subgroups in linear groups.''] [[Journal of Algebra]], vol. 20 (1972), pp. 250–270&lt;/ref&gt; containing the proof of a famous result now known as the [[Tits alternative]]. The result states that a [[finitely generated group|finitely generated]] [[linear group]] is either [[virtually]] [[solvable group|solvable]] or contains a [[free group|free]] [[subgroup]] of rank two. The ping-pong lemma and its variations are widely used in [[geometric topology]] and [[geometric group theory]].

Modern versions of the ping-pong lemma can be found in many books such as Lyndon&amp;Schupp,&lt;ref name="LS"&gt;[[Roger Lyndon|Roger C. Lyndon]] and Paul E. Schupp. ''Combinatorial Group Theory.'' Springer-Verlag, New York, 2001. "Classics in Mathematics" series, reprint of the 1977 edition. {{isbn|978-3-540-41158-1}}; Ch II, Section 12, pp. 167&amp;ndash;169&lt;/ref&gt; de la Harpe,&lt;ref name="DH"&gt;Pierre de la Harpe. [https://books.google.com/books?id=cRT01C5ADroC&amp;pg=PA25&amp;dq=ping+pong+lemma+group+theory&amp;sig=_1EZ9oSfAdljZFH1g7uvFiHuI-w#PPA25,M1 ''Topics in geometric group theory.''] Chicago Lectures in Mathematics. University of Chicago Press, Chicago. {{isbn|0-226-31719-6}}; Ch. II.B "The table-Tennis Lemma (Klein's criterion) and examples of free products"; pp. 25&amp;ndash;41.&lt;/ref&gt; Bridson&amp;Haefliger&lt;ref name="BH"&gt;Martin R. Bridson, and André Haefliger. [https://books.google.com/books?id=3DjaqB08AwAC&amp;printsec=frontcover&amp;dq=Martin+R.+Bridson,+and+Andr%C3%A9+Haefliger.+%22Metric+spaces+of+non-positive+curvature%22 ''Metric spaces of non-positive curvature.''] Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], 319. Springer-Verlag, Berlin, 1999. {{isbn|3-540-64324-9}}; Ch.III.&amp;Gamma;, pp. 467&amp;ndash;468&lt;/ref&gt; and others.

==Formal statements==

===Ping-pong lemma for several subgroups===

This version of the ping-pong lemma ensures that several [[subgroup]]s of a group acting on a set generate a [[free product]]. The following statement appears in&lt;ref&gt;Andrij Olijnyk and Vitaly Suchchansky. [http://www.worldscinet.com/cgi-bin/details.cgi?id=pii:S0218196704001931&amp;type=html Representations of free products by infinite unitriangular matrices over finite fields.] International Journal of Algebra and Computation. Vol. 14 (2004), no. 5&amp;ndash;6, pp. 741&amp;ndash;749; Lemma 2.1&lt;/ref&gt;, and the proof is from&lt;ref name="DH"/&gt;.

Let ''G'' be a group acting on a set ''X'' and let ''H''&lt;sub&gt;1&lt;/sub&gt;, ''H''&lt;sub&gt;2&lt;/sub&gt;,...., ''H''&lt;sub&gt;''k''&lt;/sub&gt; be nontrivial subgroups of ''G'' where ''k''≥2, such that at least one of these subgroups has [[order (group theory)|order]] greater than 2.
Suppose there exist [[Disjoint_sets#Generalizations|pairwise disjoint]] nonempty subsets ''X''&lt;sub&gt;1&lt;/sub&gt;, ''X''&lt;sub&gt;2&lt;/sub&gt;,....,''X''&lt;sub&gt;''k''&lt;/sub&gt; of ''X'' such that the following holds:

*For any ''i''≠''s'' and for any ''h''∈''H''&lt;sub&gt;''i''&lt;/sub&gt;, ''h''≠1  we have ''h''(''X''&lt;sub&gt;''s''&lt;/sub&gt;)⊆''X''&lt;sub&gt;''i''&lt;/sub&gt;.

Then
:&lt;math&gt;\langle H_1,\dots, H_k\rangle=H_1\ast\dots \ast H_k.&lt;/math&gt;

====Proof====
By the definition of free product, it suffices to check that a given reduced word is nontrivial. Let ''w'' be such a word, and let

:&lt;math&gt; w= \prod_{i=1}^m w_{\alpha_i,\beta_i}. &lt;/math&gt;

Where ''w''&lt;sub&gt;''s'',''β''&lt;sub&gt;''k''&lt;/sub&gt;&lt;/sub&gt;∈ ''H''&lt;sub&gt;''s''&lt;/sub&gt; for all such ''β''&lt;sub&gt;''k''&lt;/sub&gt;, and since ''w'' is fully reduced ''α''&lt;sub&gt;''i''&lt;/sub&gt;≠ α&lt;sub&gt;''i''+1 &lt;/sub&gt; for any ''i''. We then let ''w'' act on an element of one of the sets ''X''&lt;sub&gt;''i''&lt;/sub&gt;. As we assume for at least one subgroup ''H''&lt;sub&gt;i&lt;/sub&gt; has order at least 3, without loss of generality we may assume that ''H''&lt;sub&gt;1&lt;/sub&gt; has order at least 3. We first make the assumption that α&lt;sub&gt;1&lt;/sub&gt; and α&lt;sub&gt;m&lt;/sub&gt; are both 1. From here we consider ''w'' acting on ''X''&lt;sub&gt;2&lt;/sub&gt;. We get the following chain of containments and note that since the ''X''&lt;sub&gt;i&lt;/sub&gt; are disjoint that ''w'' acts nontrivially and is thus not the identity element.

:&lt;math&gt; w(X_2) \subseteq \prod_{i=1}^{m-1} w_{\alpha_i,\beta_i}(X_1) \subseteq \prod_{i=1}^{m-2} w_{\alpha_i,\beta_i}(X_{\alpha_{m-1}})\subseteq \dots \subseteq w_{1,\beta_1}w_{\alpha_2,\beta_2}(X_{\alpha_3}) \subseteq &lt;/math&gt; &lt;math&gt; w_{1,\beta_1}(X_{\alpha_2})\subseteq X_1 &lt;/math&gt;

To finish the proof we must consider the three cases: 
*If &lt;math&gt; \alpha_1 = 1;\alpha_m\neq 1 &lt;/math&gt;, then let &lt;math&gt; h\in H_1\setminus \{w_{1,\beta_1}^{-1},1\}. &lt;/math&gt; (Such &lt;math&gt;h&lt;/math&gt; exists since by assumption ''H''&lt;sub&gt;1&lt;/sub&gt; has order at least 3.)
*If &lt;math&gt;\alpha_1\neq 1;\alpha_m=1&lt;/math&gt;, then let &lt;math&gt; h\in H_1\setminus \{w_{1,\beta_m},1\} &lt;/math&gt;
*And if &lt;math&gt; \alpha_1\neq 1;\alpha_m\neq 1&lt;/math&gt;, then let &lt;math&gt; h\in H_1\setminus \{1\} &lt;/math&gt;
In each case, ''hwh''&lt;sup&gt;−1&lt;/sup&gt; is a reduced word with ''α''&lt;sub&gt;1&lt;/sub&gt;'  and ''α''&lt;sub&gt;''m'' '&lt;/sub&gt;' both 1, and thus is nontrivial. Finally, ''hwh''&lt;sup&gt;−1&lt;/sup&gt; is not 1, and so neither is ''w''. This proves the claim.

===The Ping-pong lemma for cyclic subgroups===

Let ''G'' be a group [[group action|acting]] on a set ''X''. Let ''a''&lt;sub&gt;1&lt;/sub&gt;,...,''a''&lt;sub&gt;''k''&lt;/sub&gt; be elements of ''G'' of infinite order, where ''k'' ≥ 2. Suppose there exist disjoint nonempty subsets

:''X''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;,...,''X''&lt;sub&gt;''k''&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt; and ''X''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;&amp;ndash;&lt;/sup&gt;,...,''X''&lt;sub&gt;''k''&lt;/sub&gt;&lt;sup&gt;&amp;ndash;&lt;/sup&gt;

of ''X'' with the following properties:

*''a''&lt;sub&gt;''i''&lt;/sub&gt;(''X''&amp;nbsp;&amp;minus;&amp;nbsp;''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;&amp;ndash;&lt;/sup&gt;) ⊆ ''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt; for ''i'' = 1, ..., ''k'';
*''a''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;&amp;minus;1&lt;/sup&gt;(''X''&amp;nbsp;&amp;minus;&amp;nbsp;''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;) ⊆ ''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;&amp;ndash;&lt;/sup&gt; for ''i'' = 1, ..., ''k''.

Then the subgroup ''H'' = &lt;''a''&lt;sub&gt;1&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''k''&lt;/sub&gt;&gt; ≤ ''G'' [[Generating set of a group|generated]] by ''a''&lt;sub&gt;1&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''k''&lt;/sub&gt; is [[free group|free]] with free basis {''a''&lt;sub&gt;1&lt;/sub&gt;, ..., ''a''&lt;sub&gt;''k''&lt;/sub&gt;}.

====Proof====
This statement follows as a corollary of the version for general subgroups if we let ''X''&lt;sub&gt;''i''&lt;/sub&gt;= ''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;∪''X''&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt; and let ''H''&lt;sub&gt;''i''&lt;/sub&gt; = ⟨''a''&lt;sub&gt;''i''&lt;/sub&gt;⟩.

==Examples==

===Special linear group example===
One can use the ping-pong lemma to prove&lt;ref name="DH"/&gt; that the subgroup ''H'' = &lt;''A'',''B''&gt;≤SL(2,'''Z'''), generated by  the matrices

:&lt;math&gt;\scriptstyle A=\begin{pmatrix}1 &amp; 2\\ 0 &amp;1 \end{pmatrix} &lt;/math&gt; and &lt;math&gt;\scriptstyle B=\begin{pmatrix}1 &amp; 0\\ 2 &amp;1 \end{pmatrix} &lt;/math&gt;

is [[free group|free]] of rank two.

====Proof====
Indeed, let ''H''&lt;sub&gt;1&lt;/sub&gt; = &lt;''A''&gt; and ''H''&lt;sub&gt;2&lt;/sub&gt; = &lt;''B''&gt; be [[cyclic group|cyclic]] [[subgroup]]s of SL(2,'''Z''') generated by ''A'' and ''B'' accordingly.   It is not hard to check that A and B are elements of infinite order in SL(2,'''Z''') and that

:&lt;math&gt;H_1=\{A^n|n\in \mathbb Z\}=\left\{\begin{pmatrix}1 &amp; 2n\\ 0 &amp; 1 \end{pmatrix} : n\in\mathbb Z\right\}&lt;/math&gt;

and

:&lt;math&gt;H_2=\{B^n|n\in \mathbb Z\}=\left\{\begin{pmatrix}1 &amp; 0\\ 2n &amp; 1 \end{pmatrix} : n\in\mathbb Z\right\}.&lt;/math&gt;

Consider the standard action of SL(2,'''Z''') on '''R'''&lt;sup&gt;2&lt;/sup&gt; by [[linear transformation]]s. Put

:&lt;math&gt;X_1=\left\{\begin{pmatrix}x \\ y \end{pmatrix}\in \mathbb R^2 : |x|&gt;|y|\right\}&lt;/math&gt;

and

:&lt;math&gt;X_2=\left\{\begin{pmatrix}x \\ y \end{pmatrix}\in \mathbb R^2 : |x|&lt;|y|\right\}.&lt;/math&gt;

It is not hard to check, using the above explicitly descriptions of ''H''&lt;sub&gt;1&lt;/sub&gt; and ''H''&lt;sub&gt;2&lt;/sub&gt; that for every nontrivial ''g''&amp;nbsp;∈&amp;nbsp;''H''&lt;sub&gt;1&lt;/sub&gt; we have ''g''(''X''&lt;sub&gt;2&lt;/sub&gt;)&amp;nbsp;⊆&amp;nbsp;''X''&lt;sub&gt;1&lt;/sub&gt; and that for every nontrivial ''g''&amp;nbsp;∈&amp;nbsp;''H''&lt;sub&gt;2&lt;/sub&gt; we have ''g''(''X''&lt;sub&gt;1&lt;/sub&gt;)&amp;nbsp;⊆&amp;nbsp;''X''&lt;sub&gt;2&lt;/sub&gt;. Using the alternative form of the ping-pong lemma, for two subgroups, given above, we conclude that ''H''&amp;nbsp;=&amp;nbsp;''H''&lt;sub&gt;1&lt;/sub&gt;∗''H''&lt;sub&gt;2&lt;/sub&gt;. Since the groups ''H''&lt;sub&gt;1&lt;/sub&gt; and ''H''&lt;sub&gt;2&lt;/sub&gt; are [[infinite cyclic group|infinite cyclic]], it follows that ''H'' is a [[free group]] of rank two.

===Word-hyperbolic group example===

Let ''G'' be a [[word-hyperbolic group]] which is [[torsion-free group|torsion-free]], that is, with no nontrivial elements of finite [[Order (group theory)|order]]. Let ''g'',&amp;nbsp;''h''&amp;nbsp;∈&amp;nbsp;''G'' be two non-commuting elements, that is such that ''gh''&amp;nbsp;≠&amp;nbsp;''hg''. Then there exists ''M''≥1 such that for any integers ''n''&amp;nbsp;≥&amp;nbsp;''M'', ''m''&amp;nbsp;≥&amp;nbsp;''M'' the subgroup H&amp;nbsp;=&amp;nbsp;&lt;''g''&lt;sup&gt;''n''&lt;/sup&gt;, ''h''&lt;sup&gt;''m''&lt;/sup&gt;&gt;&amp;nbsp;≤&amp;nbsp;''G'' is [[free group|free]] of rank two.

====Sketch of the proof&lt;ref name="Gromov"&gt;M. Gromov. ''Hyperbolic groups.'' Essays in group theory, pp. 75&amp;ndash;263, Mathematical Sciences Research Institute Publications, 8, Springer, New York, 1987;  {{isbn|0-387-96618-8}}; Ch. 8.2, pp. 211&amp;ndash;219.&lt;/ref&gt;====
The group ''G'' [[Group action|acts]] on its ''hyperbolic boundary'' ∂''G'' by [[homeomorphism]]s. It is known that if ''a''&amp;nbsp;∈&amp;nbsp;''G'' is a nontrivial element then ''a'' has exactly two distinct fixed points, ''a''&lt;sup&gt;∞&lt;/sup&gt; and ''a''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt; in ∂''G'' and that ''a''&lt;sup&gt;∞&lt;/sup&gt; is an [[attracting fixed point]] while ''a''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt; is a [[Fixed point (mathematics)|repelling fixed point]].

Since ''g'' and ''h'' do not commute, the basic facts about [[word-hyperbolic group]]s imply that ''g''&lt;sup&gt;∞&lt;/sup&gt;, ''g''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt;, ''h''&lt;sup&gt;∞&lt;/sup&gt; and ''h''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt; are four distinct points in   ∂''G''. Take disjoint [[Neighbourhood (mathematics)|neighborhoods]] ''U''&lt;sub&gt;+&lt;/sub&gt;, ''U''&lt;sub&gt;&amp;ndash;&lt;/sub&gt;, ''V''&lt;sub&gt;+&lt;/sub&gt; and ''V''&lt;sub&gt;&amp;ndash;&lt;/sub&gt; of ''g''&lt;sup&gt;∞&lt;/sup&gt;, ''g''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt;, ''h''&lt;sup&gt;∞&lt;/sup&gt; and ''h''&lt;sup&gt;&amp;minus;∞&lt;/sup&gt; in ∂''G'' respectively.
Then the attracting/repelling properties of the fixed points of ''g'' and ''h'' imply that there exists ''M''&amp;nbsp;≥&amp;nbsp;1 such that for any integers ''n''&amp;nbsp;≥&amp;nbsp;''M'', ''m''&amp;nbsp;≥&amp;nbsp;''M'' we have:
*''g''&lt;sup&gt;''n''&lt;/sup&gt;(∂''G'' &amp;ndash; ''U''&lt;sub&gt;&amp;ndash;&lt;/sub&gt;) ⊆ ''U''&lt;sub&gt;+&lt;/sub&gt;
*''g''&lt;sup&gt;&amp;minus;''n''&lt;/sup&gt;(∂''G'' &amp;ndash; ''U''&lt;sub&gt;+&lt;/sub&gt;) ⊆ ''U''&lt;sub&gt;&amp;ndash;&lt;/sub&gt;
*''h''&lt;sup&gt;''m''&lt;/sup&gt;(∂''G'' &amp;ndash; ''V''&lt;sub&gt;&amp;ndash;&lt;/sub&gt;) ⊆ ''V''&lt;sub&gt;+&lt;/sub&gt;
*''h''&lt;sup&gt;&amp;minus;''m''&lt;/sup&gt;(∂''G'' &amp;ndash; ''V''&lt;sub&gt;+&lt;/sub&gt;) ⊆ ''V''&lt;sub&gt;&amp;ndash;&lt;/sub&gt;

The ping-pong lemma now implies that ''H''&amp;nbsp;=&amp;nbsp;&lt;''g''&lt;sup&gt;''n''&lt;/sup&gt;, ''h''&lt;sup&gt;''m''&lt;/sup&gt;&gt;&amp;nbsp;≤&amp;nbsp;''G'' is [[free group|free]] of rank two.

==Applications of the ping-pong lemma==

*The ping-pong lemma is used in [[Kleinian group]]s to study their so-called [[Schottky group|Schottky subgroups]].  In the Kleinian groups context the ping-pong lemma can be used to show that a particular group of isometries of the [[hyperbolic 3-space]] is not just [[free group|free]] but also [[properly discontinuous]] and [[geometrically finite group|geometrically finite]].
*Similar Schottky-type arguments are widely used in [[geometric group theory]], particularly for subgroups of [[word-hyperbolic group]]s&lt;ref name="Gromov"/&gt; and for automorphism groups of trees.&lt;ref&gt;[[Alexander Lubotzky]]. [http://www.springerlink.com/content/g374700j2401nl64/ ''Lattices in rank one Lie groups over local fields.'']  [[Geometric and Functional Analysis]], vol. 1 (1991),  no. 4, pp. 406&amp;ndash;431&lt;/ref&gt;
*Ping-pong lemma is also used for studying Schottky-type subgroups of [[mapping class group]]s of [[Riemann surface]]s, where the set on which the mapping class group acts is the Thurston boundary of the [[Teichmüller space]].&lt;ref&gt;Richard P. Kent, and Christopher J. Leininger. ''Subgroups of mapping class groups from the geometrical viewpoint.'' In the tradition of Ahlfors-Bers. IV, pp. 119&amp;ndash;141,
Contemporary Mathematics series, 432, [[American Mathematical Society]], Providence, RI, 2007; {{isbn|978-0-8218-4227-0}}; 0-8218-4227-7&lt;/ref&gt; A similar argument is also utilized in the study of subgroups of the [[outer automorphism group]] of a [[free group]].&lt;ref&gt;[[Mladen Bestvina|M. Bestvina]], M. Feighn, and M. Handel. [http://www.springerlink.com/content/50hq64n0l6gpuukk/ ''Laminations, trees, and irreducible automorphisms of free groups.'']  [[Geometric and Functional Analysis]], vol. 7  (1997),  no. 2, pp. 215&amp;ndash;244.&lt;/ref&gt;
*One of the most famous applications of the ping-pong lemma is in the proof of [[Jacques Tits]] of the so-called [[Tits alternative]] for [[linear group]]s.&lt;ref name="T"/&gt; (see also &lt;ref&gt;Pierre de la Harpe. ''Free groups in linear groups.'' L'Enseignement Mathématique (2), vol. 29 (1983), no. 1-2, pp. 129&amp;ndash;144&lt;/ref&gt; for an overview of Tits' proof and an explanation of the ideas involved, including the use of the ping-pong lemma).
*There are generalizations of the ping-pong lemma that produce not just [[free product]]s but also [[free product with amalgamation|amalgamated free products]] and [[HNN extension]]s.&lt;ref name="LS"/&gt; These generalizations are used, in particular, in the proof of Maskit's Combination Theorem for [[Kleinian group]]s.&lt;ref&gt;[[Bernard Maskit]].
''Kleinian groups.'' Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences], 287. Springer-Verlag, Berlin, 1988. {{isbn|3-540-17746-9}};  Ch. VII.C and Ch. VII.E pp.149&amp;ndash;156 and pp. 160&amp;ndash;167&lt;/ref&gt;
*There are also versions of the ping-pong lemma which guarantee that several elements in a group generate a [[free semigroup]]. Such versions are available both in the general context of a [[group action]] on a set,&lt;ref name="DH1"&gt;Pierre de la Harpe. [https://books.google.com/books?id=cRT01C5ADroC&amp;pg=PA188&amp;vq=semi-group&amp;dq=ping+pong+lemma+group+theory&amp;source=gbs_search_s&amp;sig=ACfU3U2oMEeKTE_pB7Gt_MqNjOaUNZL8yw ''Topics in geometric group theory.''] Chicago Lectures in Mathematics. University of Chicago Press, Chicago. {{isbn|0-226-31719-6}}; Ch. II.B "The table-Tennis Lemma (Klein's criterion) and examples of free products"; pp. 187&amp;ndash;188.&lt;/ref&gt;  and for specific types of actions, e.g. in the context of [[linear group]]s,&lt;ref&gt;Alex Eskin, Shahar Mozes and Hee Oh. [http://www.springerlink.com/content/3ybuud1bpkkkcxn0/ On uniform exponential growth for linear groups.] [[Inventiones Mathematicae]]. vol. 60 (2005), no. 1, pp.1432&amp;ndash;1297; Lemma 2.2&lt;/ref&gt; groups [[Bass-Serre theory|acting on trees]]&lt;ref&gt;Roger C. Alperin and Guennadi A. Noskov. [https://books.google.com/books?id=w7LO6AkB8Y8C&amp;pg=PA2&amp;lpg=PA2&amp;dq=%22ping-pong+lemma%22+semigroup&amp;source=web&amp;ots=aBPNu6adQ2&amp;sig=7mZjESpp-6Bkekw68RCPEDYJSTM&amp;hl=en&amp;sa=X&amp;oi=book_result&amp;resnum=4&amp;ct=result#PPA2,M1 Uniform growth, actions on trees and GL&lt;sub&gt;2&lt;/sub&gt;.] Computational and Statistical Group Theory:AMS Special Session Geometric Group Theory, April 21–22, 2001, Las Vegas, Nevada, AMS Special Session Computational Group Theory, April 28–29, 2001, Hoboken, New Jersey. (Robert H. Gilman, Vladimir Shpilrain, Alexei G. Myasnikov, editors). [[American Mathematical Society]], 2002. {{isbn|978-0-8218-3158-8}}; page 2, Lemma 3.1&lt;/ref&gt; and others.&lt;ref&gt;Yves de Cornulier and Romain Tessera. [http://msp.warwick.ac.uk/gt/2008/12-01/p011.xhtml Quasi-isometrically embedded free sub-semigroups.] [[Geometry &amp; Topology]], vol. 12 (2008), pp. 461&amp;ndash;473; Lemma 2.1&lt;/ref&gt;

==References==
{{reflist}}

==See also==
*[[Free group]]
*[[Free product]]
*[[Kleinian group]]
*[[Tits alternative]]
*[[Word-hyperbolic group]]
*[[Schottky group]]

[[Category:Algebra]]
[[Category:Group theory]]
[[Category:Discrete groups]]
[[Category:Lie groups]]
[[Category:Combinatorics on words]]</text>
      <sha1>p7prohe1d7pwdziuuf636k1rocqb5yg</sha1>
    </revision>
  </page>
  <page>
    <title>Quadratic equation</title>
    <ns>0</ns>
    <id>25175</id>
    <revision>
      <id>869128992</id>
      <parentid>869126702</parentid>
      <timestamp>2018-11-16T16:19:15Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* top */ per [[MOS:LINKSPECIFIC]] and [[MOS:LINKCLARITY]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51511">{{About|algebraic equations of degree two and their solutions|functions defined by polynomials of degree two|Quadratic function}}
[[File:Quadratic formula.svg|thumbnail|The [[quadratic formula]] for the roots of the general quadratic equation]]
In [[algebra]], a '''quadratic equation''' (from the [[Latin]] {{lang|la|quadratus}} for "[[Square (algebra)|square]]") is any equation having the form 
: &lt;math&gt;ax^2 + bx + c = 0,&lt;/math&gt;
where {{math|''x''}} represents an unknown, and {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} represent known numbers, with {{math|''a'' ≠ 0}}. If {{math|''a'' {{=}} 0}}, then the equation is [[linear equation|linear]], not quadratic.  The numbers {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} are the ''[[coefficient]]s'' of the equation and may be distinguished by calling them, respectively, the ''quadratic coefficient'', the ''linear coefficient'' and the ''constant'' or ''free term''.&lt;ref&gt;Protters &amp; Morrey: "Calculus and Analytic Geometry. First Course".&lt;/ref&gt;

Because the quadratic equation involves only one unknown, it is called "[[univariate]]". The quadratic equation only contains [[exponentiation|powers]] of {{math|''x''}} that are non-negative integers, and therefore it is a [[polynomial equation]]. In particular, it is a [[degree of a polynomial|second-degree]] polynomial equation, since the greatest power is two.

Quadratic equations can be solved by a process known in American English as [[Factorization|factoring]] and in other varieties of English as ''factorising'', by [[completing the square]], by using the [[quadratic formula]], or by [[Graph of a function|graphing]].  Solutions to problems equivalent to the quadratic equation were known as early as 2000 BC.

==Solving the quadratic equation==
[[File:Quadratic equation coefficients.png|thumb|right|300px|Figure 1. Plots of quadratic function {{nowrap|''y'' {{=}} ''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c''}}, varying each coefficient separately while the other coefficients are fixed (at values ''a''&amp;nbsp;=&amp;nbsp;1, ''b''&amp;nbsp;=&amp;nbsp;0, ''c''&amp;nbsp;=&amp;nbsp;0)|&lt;!-- Note: The unusual spellings in this alt text (for example, "eh" for the constant "a" ) is intended to aid enunciation by screen readers. Before changing any alt text, please test your changes in multiple screen readers. --&gt;alt=Figure 1. Plots of the quadratic function, y = eh x squared plus b x plus c, varying each coefficient separately while the other coefficients are fixed at values eh = 1, b = 0, c = 0. The left plot illustrates varying c. When c equals 0, the vertex of the parabola representing the quadratic function is centered on the origin, and the parabola rises on both sides of the origin, opening to the top. When c is greater than zero, the parabola does not change in shape, but its vertex is raised above the origin. When c is less than zero, the vertex of the parabola is lowered below the origin. The center plot illustrates varying b. When b is less than zero, the parabola representing the quadratic function is unchanged in shape, but its vertex is shifted to the right of and below the origin. When b is greater than zero, its vertex is shifted to the left of and below the origin. The vertices of the family of curves created by varying b follow along a parabolic curve. The right plot illustrates varying eh. When eh is positive, the quadratic function is a parabola opening to the top. When eh is zero, the quadratic function is a horizontal straight line. When eh is negative, the quadratic function is a parabola opening to the bottom.]]
A quadratic equation with [[real number|real]] or [[complex number|complex]] [[coefficients]] has two solutions, called ''roots''. These two solutions may or may not be distinct, and they may or may not be real.

===Factoring by inspection===
It may be possible to express a quadratic equation {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c'' {{=}} 0}} as a product {{math|(''px'' + ''q'')(''rx'' + ''s'') {{=}} 0}}. In some cases, it is possible, by simple inspection, to determine values of ''p'', ''q'', ''r,'' and ''s'' that make the two forms equivalent to one another. If the quadratic equation is written in the second form, then the "Zero Factor Property" states that the quadratic equation is satisfied if {{math|''px'' + ''q'' {{=}} 0}} or {{math|''rx'' + ''s'' {{=}} 0}}. Solving these two linear equations provides the roots of the quadratic.

For most students, factoring by inspection is the first method of solving quadratic equations to which they are exposed.&lt;ref name=Washington2000&gt;{{cite book|last=Washington|first=Allyn J.|title=Basic Technical Mathematics with Calculus, Seventh Edition|year=2000|publisher=Addison Wesley Longman, Inc.|isbn=978-0-201-35666-3}}&lt;/ref&gt;{{rp|202&amp;ndash;207}} If one is given a quadratic equation in the form {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c'' {{=}} 0}}, the sought factorization has the form {{math|(''x'' + ''q'')(''x'' + ''s'')}}, and one has to find two numbers {{math|''q''}} and {{math|''s''}} that add up to {{math| ''b''}} and whose product is {{math|''c''}} (this is sometimes called "Vieta's rule"&lt;ref&gt;{{citation|title=Numbers|series=Graduate Texts in Mathematics|volume=123|first1=Heinz-Dieter|last1=Ebbinghaus|first2=John H.|last2=Ewing|publisher=Springer|year=1991|isbn=9780387974972|page=77|url=https://books.google.com/books?id=OKcKowxXwKkC&amp;pg=PA77}}.&lt;/ref&gt; and is related to [[Vieta's formulas]]). As an example, {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + 5''x'' + 6}} factors as {{math|(''x'' + 3)(''x'' + 2)}}. The more general case where {{math|''a''}} does not equal {{math|1}} can require a considerable effort in trial and error guess-and-check, assuming that it can be factored at all by inspection.

Except for special cases such as where {{math|''b'' {{=}} 0}} or {{math|''c'' {{=}} 0}}, factoring by inspection only works for quadratic equations that have rational roots. This means that the great majority of quadratic equations that arise in practical applications cannot be solved by factoring by inspection.&lt;ref name=Washington2000/&gt;{{rp|207}}

===Completing the square===
{{Main|Completing the square}}
[[File:Polynomialdeg2.svg|thumb|right|300px|Figure 2. For the [[quadratic function]] {{math|''y'' {{=}} ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; ''x'' &amp;minus; 2}}, the points where the graph crosses the {{math|''x''}}-axis, {{math|''x'' {{=}} −1}} and {{math|''x'' {{=}} 2}}, are the solutions of the quadratic equation {{math|''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; ''x'' &amp;minus; 2 {{=}} 0}}.
|alt=Figure 2 illustrates an x y plot of the quadratic function f of x equals x squared minus x minus 2. The x-coordinate of the points where the graph intersects the x-axis, x equals &amp;minus;1 and x equals 2, are the solutions of the quadratic equation x squared minus x minus 2 equals zero.]]
The process of completing the square makes use of the algebraic identity
:&lt;math&gt;x^2+2hx+h^2 = (x+h)^2,&lt;/math&gt;
which represents a well-defined [[algorithm]] that can be used to solve any quadratic equation.&lt;ref name=Washington2000/&gt;{{rp|207}} Starting with a quadratic equation in standard form, {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c'' {{=}} 0}} 
#Divide each side by {{math|''a''}}, the coefficient of the squared term.
#Subtract the constant term {{math|''c''/''a''}} from both sides.
#Add the square of one-half of {{math|''b''/''a''}}, the coefficient of {{math|''x''}}, to both sides. This "completes the square", converting the left side into a perfect square.
#Write the left side as a square and simplify the right side if necessary.
#Produce two linear equations by equating the square root of the left side with the positive and negative square roots of the right side.
#Solve the two linear equations.

We illustrate use of this algorithm by solving {{math|2''x''&lt;sup&gt;2&lt;/sup&gt; + 4''x'' &amp;minus; 4 {{=}} 0}}
:&lt;math&gt;1) \ x^2+2x-2=0&lt;/math&gt;
:&lt;math&gt;2) \ x^2+2x=2&lt;/math&gt;
:&lt;math&gt;3) \ x^2+2x+1=2+1&lt;/math&gt;
:&lt;math&gt;4) \ \left(x+1 \right)^2=3&lt;/math&gt;
:&lt;math&gt;5) \ x+1=\pm\sqrt{3}&lt;/math&gt;
:&lt;math&gt;6) \ x=-1\pm\sqrt{3}&lt;/math&gt;

The [[plus-minus sign|plus-minus symbol "±"]] indicates that both {{math|''x'' {{=}} &amp;minus;1 + {{radic|3}}}} and {{math|''x'' {{=}} &amp;minus;1 &amp;minus; {{radic|3}}}} are solutions of the quadratic equation.&lt;ref&gt;{{Citation|last=Sterling|first=Mary Jane|title=Algebra I For Dummies|year=2010|publisher=Wiley Publishing|isbn=978-0-470-55964-2|url=https://books.google.com/books?id=2toggaqJMzEC&amp;pg=PA219&amp;dq=quadratic+formula#v=onepage&amp;q=quadratic%20formula&amp;f=false|page=219}}&lt;/ref&gt;

===Quadratic formula and its derivation===
{{main|Quadratic formula}}
[[Completing the square]] can be used to [[Quadratic formula#Derivation of the formula|derive a general formula]] for solving quadratic equations, called the quadratic formula.&lt;ref&gt;{{citation
|title=Schaum's Outline of Theory and Problems of Elementary Algebra
|first1=Barnett
|last1=Rich
|first2=Philip
|last2=Schmidt
|publisher=The McGraw-Hill Companies
|year=2004
|isbn=978-0-07-141083-0
|url=https://books.google.com/books?id=8PRU9cTKprsC}}, [https://books.google.com/books?id=8PRU9cTKprsC&amp;pg=PA291 Chapter 13 §4.4, p. 291]&lt;/ref&gt; The [[mathematical proof]] will now be briefly summarized.&lt;ref&gt;Himonas, Alex.  ''[https://books.google.com/books?id=1Mg5u98BnEMC&amp;q=%22left+as+an+exercise%22+and+%22quadratic+formula%22&amp;dq=%22left+as+an+exercise%22+and+%22quadratic+formula%22&amp;hl=en&amp;sa=X&amp;ei=6CJbUu2aFMylkQei6YGABA&amp;ved=0CDMQ6AEwATgK Calculus for Business and Social Sciences]'', p. 64 (Richard Dennis Publications, 2001).&lt;/ref&gt;  It can easily be seen, by [[polynomial expansion]], that the following equation is equivalent to the quadratic equation:
:&lt;math&gt;\left(x+\frac{b}{2a}\right)^2=\frac{b^2-4ac}{4a^2}.&lt;/math&gt;
Taking the [[square root]] of both sides, and isolating {{math|''x''}}, gives:
:&lt;math&gt;x=\frac{-b\pm\sqrt{b^2-4ac\ }}{2a}.&lt;/math&gt;

Some sources, particularly older ones, use alternative parameterizations of the quadratic equation such as {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + 2''bx'' + ''c'' {{=}} ''0''}} or {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 2''bx'' + ''c'' {{=}} 0}}&amp;nbsp;,&lt;ref name="kahan"&gt;{{Citation |first=Willian |last=Kahan |title=On the Cost of Floating-Point Computation Without Extra-Precise Arithmetic |url=http://www.cs.berkeley.edu/~wkahan/Qdrtcs.pdf |date=November 20, 2004 |accessdate=2012-12-25}}&lt;/ref&gt; where {{math|''b''}} has a magnitude one half of the more common one, possibly with opposite sign. These result in slightly different forms for the solution, but are otherwise equivalent.

A number of [[Quadratic formula#Other derivations|alternative derivations]] can be found in the literature.  These proofs are simpler than the standard completing the square method, represent interesting applications of other frequently used techniques in algebra, or offer insight into other areas of mathematics.

A lesser known quadratic formula, as used in [[Muller's method]], and which can be found from [[Vieta's formulas]], provides the same roots via the equation:
:&lt;math&gt;x=\frac{-2c}{b\pm\sqrt{b^2-4ac}}.&lt;/math&gt;

One property of this form is that it yields one valid root when {{math|''a'' {{=}} 0}}, while the other root contains division by zero, because when {{math|''a'' {{=}} 0}}, the quadratic equation becomes a linear equation, which has one root. By contrast, in this case, the more common formula has a division by zero for one root and an [[indeterminate form]] {{math|0/0}} for the other root. On the other hand, when {{math|''c'' {{=}} 0}}, the more common formula yields two correct roots whereas this form yields the zero root and an indeterminate form {{math|0/0}}.

===Reduced quadratic equation===
It is sometimes convenient to reduce a quadratic equation so that its [[leading coefficient]] is one. This is done by dividing both sides by ''a'', which is always possible since ''a'' is non-zero.  This produces the ''reduced quadratic equation'':&lt;ref&gt;Alenit͡syn, Aleksandr and Butikov, Evgeniĭ. ''Concise Handbook of Mathematics and Physics'', p. 38 (CRC Press 1997)&lt;/ref&gt;

:&lt;math&gt;x^2+px+q=0,&lt;/math&gt;

where ''p'' = ''b''/''a'' and ''q'' = ''c''/''a''. This [[monic polynomial|monic equation]] has the same solutions as the original.

The quadratic formula for the solutions of the reduced quadratic equation, written in terms of its coefficients, is:
:&lt;math&gt;x = \frac{1}{2} \left( - p \pm \sqrt{p^2 - 4q} \right) ,&lt;/math&gt;
or equivalently:
:&lt;math&gt;x = - \frac{p}{2} \pm \sqrt{\left(\frac{p}{2}\right)^2 - q}.&lt;/math&gt;

===Discriminant===
[[File:Quadratic eq discriminant.svg|thumb|right|Figure 3. Discriminant signs|alt=Figure 3. This figure plots three quadratic functions on a single Cartesian plane graph to illustrate the effects of discriminant values. When the discriminant, delta, is positive, the parabola intersects the {{math|''x''}}-axis at two points. When delta is zero, the vertex of the parabola touches the {{math|''x''}}-axis at a single point. When delta is negative, the parabola does not intersect the {{math|''x''}}-axis at all.]]
In the quadratic formula, the expression underneath the square root sign is called the ''[[discriminant]]'' of the quadratic equation, and is often represented using an upper case {{math|''D''}} or an upper case Greek [[Delta (letter)|delta]]:&lt;ref&gt;'''Δ''' is the initial of the [[Greek language|Greek]] word '''Δ'''ιακρίνουσα, ''Diakrínousa'', discriminant.&lt;/ref&gt;
:&lt;math&gt;\Delta = b^2 - 4ac.&lt;/math&gt;
A quadratic equation with ''real'' coefficients can have either one or two distinct real roots, or two distinct complex roots. In this case the discriminant determines the number and nature of the roots. There are three cases:

*If the discriminant is positive, then there are two distinct roots
::&lt;math&gt;\frac{-b + \sqrt {\Delta}}{2a} \quad\text{and}\quad \frac{-b - \sqrt {\Delta}}{2a},&lt;/math&gt;
:both of which are real numbers. For quadratic equations with [[rational number|rational]] coefficients, if the discriminant is a [[square number]], then the roots are rational—in other cases they may be [[quadratic irrational]]s.

*If the discriminant is zero, then there is exactly one [[real number|real]] root
::&lt;math&gt;-\frac{b}{2a},&lt;/math&gt;
:sometimes called a repeated or [[multiple root|double root]].

*If the discriminant is negative, then there are no real roots. Rather, there are two distinct (non-real) [[complex number|complex]] roots&lt;ref&gt;{{cite book|last=Achatz|first=Thomas|last2=Anderson|first2=John G.|last3=McKenzie|first3=Kathleen|title=Technical Shop Mathematics|year=2005|publisher=Industrial Press|isbn=978-0-8311-3086-2|url=https://books.google.com/?id=YOdtemSmzQQC&amp;pg=PA276&amp;dq=quadratic+formula#v=onepage&amp;q=quadratic%20formula&amp;f=false|page=277}}&lt;/ref&gt;
::&lt;math&gt; \frac{-b}{2a} + i \frac{\sqrt {-\Delta}}{2a} \quad\text{and}\quad \frac{-b}{2a} - i \frac{\sqrt {-\Delta}}{2a},&lt;/math&gt;
:which are [[complex conjugate]]s of each other. In these expressions {{math|''i''}} is the [[imaginary unit]].

Thus the roots are distinct if and only if the discriminant is non-zero, and the roots are real if and only if the discriminant is non-negative.

===Geometric interpretation===
{{quadratic_equation_graph_key_points.svg}}
{{quadratic_function_graph_complex_roots.svg}}
The function {{math|''f''(''x'') {{=}} ''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c''}} is the [[quadratic function]].&lt;ref&gt;{{cite book |last=Wharton |first=P. |title=Essentials of Edexcel Gcse Math/Higher |year=2006 |publisher=Lonsdale |isbn=978-1-905-129-78-2|url=https://books.google.com/?id=LMmKq-feEUoC&amp;pg=PA63&amp;dq=%22Quadratic+function%22+%22Quadratic+equation%22#v=onepage&amp;q=%22Quadratic%20function%22%20%22Quadratic%20equation%22&amp;f=false |page=63}}&lt;/ref&gt; The graph of any quadratic function has the same general shape, which is called a [[parabola]]. The location and size of the parabola, and how it opens, depend on the values of {{math|''a''}}, {{math|''b''}}, and {{math|''c''}}. As shown in Figure&amp;nbsp;1, if {{math|''a'' &amp;gt; 0}}, the parabola has a minimum point and opens upward. If {{math|''a'' &amp;lt; 0}}, the parabola has a maximum point and opens downward. The extreme point of the parabola, whether minimum or maximum, corresponds to its [[vertex (curve)|vertex]]. The ''{{math|x}}-coordinate'' of the vertex will be located at &lt;math&gt;\scriptstyle x=\tfrac{-b}{2a}&lt;/math&gt;, and the ''{{math|y}}-coordinate'' of the vertex may be found by substituting this ''{{math|x}}-value'' into the function. The ''{{math|y}}-intercept'' is located at the point {{math|(0, ''c'')}}.

The solutions of the quadratic equation {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + {{math|''bx''}} + {{math|''c''}} {{=}} 0}} correspond to the [[root of a function|roots]] of the function {{math|''f''(''x'') {{=}} ''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c''}}, since they are the values of {{math|''x''}} for which {{math|''f''(''x'') {{=}} 0}}. As shown in Figure&amp;nbsp;2, if {{math|''a''}}, {{math|''b''}}, and {{math|''c''}} are [[real numbers]] and the [[domain (mathematics)|domain]] of {{math|''f''}} is the set of real numbers, then the roots of {{math|''f''}} are exactly the {{math|''x''}}-[[coordinates]] of the points where the graph touches the {{math|''x''}}-axis. As shown in Figure&amp;nbsp;3, if the discriminant is positive, the graph touches the [[x-axis|{{math|''x''}}-axis]] at two points; if zero, the graph touches at one point; and if negative, the graph does not touch the {{math|''x''}}-axis.

===Quadratic factorization===
The term
:&lt;math&gt;x - r&lt;/math&gt;
is a factor of the polynomial
: &lt;math&gt;ax^2+bx+c&lt;/math&gt;
if and only if {{math|''r''}} is a [[root of a function|root]] of the quadratic equation
: &lt;math&gt;ax^2+bx+c=0.&lt;/math&gt;
It follows from the quadratic formula that
: &lt;math&gt;ax^2+bx+c = a \left( x - \frac{-b + \sqrt {b^2-4ac}}{2a} \right) \left( x - \frac{-b - \sqrt {b^2-4ac}}{2a} \right).&lt;/math&gt;
In the special case {{math|''b''&lt;sup&gt;2&lt;/sup&gt; {{=}} 4''ac''}} where the quadratic has only one distinct root (''i.e.'' the discriminant is zero), the quadratic polynomial can be [[Factorization|factored]] as
:&lt;math&gt;ax^2+bx+c = a \left( x + \frac{b}{2a} \right)^2.&lt;/math&gt;

===Graphing for real roots===
[[File:Graphical calculation of root of quadratic equation.png|240px|thumb|Figure 4. Graphing calculator computation of one of the two roots of the quadratic equation {{math|2''x''&lt;sup&gt;2&lt;/sup&gt; + 4''x'' &amp;minus; 4 {{=}} 0}}. Although the display shows only five significant figures of accuracy, the retrieved value of {{math|''xc''}} is 0.732050807569, accurate to twelve significant figures.]]
For most of the 20th century, graphing was rarely mentioned as a method for solving quadratic equations in high school or college algebra texts. Students learned to solve quadratic equations by factoring, completing the square, and applying the quadratic formula. Recently, [[graphing calculators]] have become common in schools and graphical methods have started to appear in textbooks, but they are generally not highly emphasized.&lt;ref name=Ballew2007/&gt;

Being able to use a graphing calculator to solve a quadratic equation requires the ability to produce a graph of {{math|''y'' {{=}} ''f''(''x'')}}, the ability to scale the graph appropriately to the dimensions of the graphing surface, and the recognition that when {{math|''f''(''x'') {{=}} 0}}, {{math|''x''}} is a solution to the equation. The skills required to solve a quadratic equation on a calculator are in fact applicable to finding the real roots of any arbitrary function.

Since an arbitrary function may cross the {{math|''x''}}-axis at multiple points, graphing calculators generally require one to identify the desired root by positioning a cursor at a "guessed" value for the root. (Some graphing calculators require bracketing the root on both sides of the zero.) The calculator then proceeds, by an iterative algorithm, to refine the estimated position of the root to the limit of calculator accuracy.

===Avoiding loss of significance===
Although the quadratic formula provides an exact solution, the result is not exact if [[real number]]s are approximated during the computation, as usual in [[numerical analysis]], where real numbers are approximated by [[floating point number]]s (called "reals" in many [[programming language]]s). In this context, the quadratic formula is not completely [[numerical stability|stable]].

This occurs when the roots have different [[order of magnitude]], or, equivalently, when {{math|''b''&lt;sup&gt;2&lt;/sup&gt;}} and  {{math|''b''&lt;sup&gt;2&lt;/sup&gt; − 4''ac''}} are close in magnitude. In this case, the subtraction of two nearly equal numbers will cause [[loss of significance]] or [[catastrophic cancellation]] in the smaller root. To avoid this, the root that is smaller in magnitude, {{math|''r''}}, can be computed as &lt;math&gt;(c/a)/R&lt;/math&gt; where {{math|''R''}} is the root that is bigger in magnitude.

A second form of cancellation can occur between the terms {{math|''b''&lt;sup&gt;2&lt;/sup&gt;}} and {{math|4''ac''}} of the discriminant, that is when the two roots are very close. This can lead to loss of up to half of correct significant figures in the roots.&lt;ref name="kahan"/&gt;&lt;ref name="Higham2002"&gt;{{Citation |first=Nicholas |last=Higham |title=Accuracy and Stability of Numerical Algorithms |edition=2nd |publisher=SIAM |year=2002 |isbn=978-0-89871-521-7 |page=10 }}&lt;/ref&gt;

==Examples and applications==
[[File:La Jolla Cove cliff diving - 02.jpg|thumb|The trajectory of the cliff jumper is [[parabola|parabolic]] because horizontal displacement is a linear function of time &lt;math&gt;x=v_x t&lt;/math&gt;, while vertical displacement is a quadratic function of time &lt;math&gt;y=\tfrac{1}{2} at^2+v_y t+h&lt;/math&gt;. As a result, the path follows quadratic equation &lt;math&gt;y=\tfrac{a}{2v_x^2} x^2+\tfrac{v_y}{v_x} x+h&lt;/math&gt;, where &lt;math&gt;v_x&lt;/math&gt; and &lt;math&gt;v_y&lt;/math&gt; are horizontal and vertical components of the original velocity, {{math|a}} is [[Gravity of Earth|gravitational]] [[acceleration]] and {{math|h}} is original height. The {{math|a}} value should be considered negative here, as its direction (downwards) is opposite to the height measurement (upwards).]]
The [[golden ratio]] is found as the positive solution of the quadratic equation &lt;math&gt;x^2-x-1=0.&lt;/math&gt;

The equations of the [[circle]] and the other [[conic sections]]&amp;mdash;[[ellipse]]s, [[parabola]]s, and [[hyperbola]]s&amp;mdash;are quadratic equations in two variables.

Given the [[cosine]] or [[sine]] of an angle, finding the cosine or sine of [[Bisection#Angle bisector|the angle that is half as large]] involves solving a quadratic equation.

The process of simplifying expressions involving the [[nested radical|square root of an expression involving the square root of another expression]] involves finding the two solutions of a quadratic equation.

[[Descartes' theorem]] states that for every four kissing (mutually tangent) circles, their [[radius|radii]] satisfy a particular quadratic equation.

The equation given by [[Fuss' theorem]], giving the relation among the radius of a [[bicentric quadrilateral]]'s [[inscribed circle]], the radius of its [[circumscribed circle]], and the distance between the centers of those circles, can be expressed as a quadratic equation for which the distance between the two circles' centers in terms of their radii is one of the solutions. The other solution of the same equation in terms of the relevant radii gives the distance between the circumscribed circle's center and the center of the [[excircle]] of an [[ex-tangential quadrilateral]].

==History==
[[Babylonian mathematics|Babylonian mathematicians]], as early as 2000 BC (displayed on [[First Babylonian Dynasty|Old Babylonian]] [[clay tablet]]s) could solve problems relating the areas and sides of rectangles. There is evidence dating this algorithm as far back as the [[Third Dynasty of Ur]].&lt;ref name=Friberg2009&gt;{{cite journal|last=Friberg|first=Jöran|title=A Geometric Algorithm with Solutions to Quadratic Equations in a Sumerian Juridical Document from Ur III Umma|journal=Cuneiform Digital Library Journal|year=2009|volume=3|url=http://cdli.ucla.edu/pubs/cdlj/2009/cdlj2009_003.html}}&lt;/ref&gt; In modern notation, the problems typically involved solving a pair of simultaneous equations of the form:
:&lt;math&gt; x+y=p,\ \ xy=q, &lt;/math&gt;
which is equivalent to the statement that {{mvar|x}} and {{mvar|y}} are the roots of the equation:&lt;ref name=Stillwell2004&gt;{{cite book |last=Stillwell |first=John |title=Mathematics and Its History (2nd ed.) |year=2004 |publisher=Springer |isbn=978-0-387-95336-6}}&lt;/ref&gt;{{rp|86}}
:&lt;math&gt;z^2+q=pz.&lt;/math&gt;

The steps given by Babylonian scribes for solving the above rectangle problem, in terms of {{mvar|x}} and {{mvar|y}}, were as follows:
#Compute half of ''p''.
#Square the result.
#Subtract ''q''.
#Find the (positive) square root using a table of squares.
#Add together the results of steps (1) and (4) to give {{math|''x''}}. In modern notation this means calculating &lt;math&gt;x = \frac{p}{2} + \sqrt{\left(\frac{p}{2}\right)^2 - q}.&lt;/math&gt;

Geometric methods were used to solve quadratic equations in Babylonia, Egypt, Greece, China, and India. The Egyptian [[Berlin Papyrus 6619|Berlin Papyrus]], dating back to the [[Middle Kingdom of Egypt|Middle Kingdom]] (2050 BC to 1650 BC), contains the solution to a two-term quadratic equation.&lt;ref&gt;{{cite book|title=The Cambridge Ancient History Part 2 Early History of the Middle East|url=https://books.google.com/books?id=slR7SFScEnwC&amp;pg=PA530|year=1971|publisher=Cambridge University Press|isbn=978-0-521-07791-0|page=530}}&lt;/ref&gt; Babylonian mathematicians from circa 400 BC and [[Chinese mathematics|Chinese mathematicians]] from circa 200 BC used [[Dissection problem|geometric methods of dissection]] to solve quadratic equations with positive roots.&lt;ref name=Henderson&gt;{{cite web|last=Henderson|first=David W.|title=Geometric Solutions of Quadratic and Cubic Equations |publisher=Mathematics Department, Cornell University |url=http://www.math.cornell.edu/~dwh/papers/geomsolu/geomsolu.html|accessdate=28 April 2013}}&lt;/ref&gt;&lt;ref name=Aitken&gt;{{cite web|last=Aitken|first=Wayne|title=A Chinese Classic: The Nine Chapters|url=http://public.csusm.edu/aitken_html/m330/china/ninechapters.pdf|publisher=Mathematics Department, California State University|accessdate=28 April 2013}}&lt;/ref&gt; Rules for quadratic equations were given in ''[[The Nine Chapters on the Mathematical Art]]'', a Chinese treatise on mathematics.&lt;ref name=Aitken/&gt;&lt;ref&gt;{{cite book|last=Smith|first=David Eugene|title=History of Mathematics|url=https://books.google.com/books?id=uTytJGnTf1kC&amp;pg=PA380|year=1958|publisher=Courier Dover Publications|isbn=978-0-486-20430-7|page=380}}&lt;/ref&gt; These early geometric methods do not appear to have had a general formula. [[Euclid]], the [[Greek mathematics|Greek mathematician]], produced a more abstract geometrical method around 300 BC. With a purely geometric approach [[Pythagoras]] and Euclid created a general procedure to find solutions of the quadratic equation. In his work ''[[Arithmetica]]'', the Greek mathematician [[Diophantus]] solved the quadratic equation, but giving only one root, even when both roots were positive.&lt;ref&gt;{{cite book |title=History of Mathematics, Volume 1 |first1=David Eugene |last1=Smith |publisher=Courier Dover Publications |year=1958 |isbn=978-0-486-20429-1 |page=134 |url=https://books.google.com/books?id=12qdOZ0gsWoC}} [https://books.google.com/books?id=12qdOZ0gsWoC&amp;pg=PA134 Extract of page 134]&lt;/ref&gt;

In 628 AD, [[Brahmagupta]], an [[Indian mathematics|Indian mathematician]], gave the first explicit (although still not completely general) solution of the quadratic equation {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' {{=}} ''c''}} as follows: "To the absolute number multiplied by four times the [coefficient of the] square, add the square of the [coefficient of the] middle term; the square root of the same, less the [coefficient of the] middle term, being divided by twice the [coefficient of the] square is the value." (''Brahmasphutasiddhanta'', Colebrook translation, 1817, page 346)&lt;ref name=Stillwell2004/&gt;{{rp|87}} This is equivalent to:
:&lt;math&gt;x = \frac{\sqrt{4ac+b^2}-b}{2a}.&lt;/math&gt;
The ''[[Bakhshali Manuscript]]'' written in India in the 7th century AD contained an algebraic formula for solving quadratic equations, as well as quadratic [[indeterminate equation]]s (originally of type {{math|''ax''/''c'' {{=}} ''y''}}{{clarify|post-text=: this is linear, not quadratic|date=October 2017}}). [[Muhammad ibn Musa al-Khwarizmi]] ([[Persia]], 9th century), inspired by Brahmagupta,{{original research inline|date=October 2017}} developed a set of formulas that worked for positive solutions. Al-Khwarizmi goes further in providing a full solution to the general quadratic equation, accepting one or two numerical answers for every quadratic equation, while providing geometric [[Mathematical proof|proofs]] in the process.&lt;ref name=Katz2007&gt;{{Cite journal | last1 = Katz | first1 = V. J. | last2 = Barton | first2 = B. | doi = 10.1007/s10649-006-9023-7 | title = Stages in the History of Algebra with Implications for Teaching | journal = Educational Studies in Mathematics | volume = 66 | issue = 2 | pages = 185&amp;ndash;201 | year = 2006 | pmid =  | pmc = }}&lt;/ref&gt; He also described the method of completing the square and recognized that the [[discriminant]] must be positive,&lt;ref name=Katz2007/&gt;&lt;ref name=Boyer1991/&gt;{{rp|230}} which was proven by his contemporary [['Abd al-Hamīd ibn Turk]] (Central Asia, 9th century) who gave geometric figures to prove that if the discriminant is negative, a quadratic equation has no solution.&lt;ref name=Boyer1991&gt;{{cite book|last=Boyer|first=Carl B.; [[Uta Merzbach|Uta C. Merzbach]], rev. editor|title=A History of Mathematics|year=1991|publisher=John Wiley &amp; Sons, Inc.|isbn=978-0-471-54397-8}}&lt;/ref&gt;{{rp|234}} While al-Khwarizmi himself did not accept negative solutions, later [[Mathematics in medieval Islam|Islamic mathematicians]] that succeeded him accepted negative solutions,&lt;ref name=Katz2007/&gt;{{rp|191}} as well as [[irrational number]]s as solutions.&lt;ref&gt;{{MacTutor|class=HistTopics|id=Arabic_mathematics|title=Arabic mathematics: forgotten brilliance?|year=1999}} "Algebra was a unifying theory which allowed rational numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as "algebraic objects"."&lt;/ref&gt; [[Abū Kāmil Shujā ibn Aslam]] (Egypt, 10th century) in particular was the first to accept irrational numbers (often in the form of a [[square root]], [[cube root]] or [[Nth root|fourth root]]) as solutions to quadratic equations or as [[coefficient]]s in an equation.&lt;ref&gt;Jacques Sesiano, "Islamic mathematics", p. 148, in {{citation|title=Mathematics Across Cultures: The History of Non-Western Mathematics|editor1-first=Helaine|editor1-last=Selin|editor1-link=Helaine Selin|editor2-first=Ubiratan|editor2-last=D'Ambrosio|editor2-link=Ubiratan D'Ambrosio|year=2000|publisher=[[Springer Science+Business Media|Springer]]|isbn=978-1-4020-0260-1}}&lt;/ref&gt; The 9th century Indian mathematician [[Sridhara]] wrote down rules for solving quadratic equations.&lt;ref&gt;{{cite book|last=Smith|first=David Eugene|title=History of Mathematics|url=https://books.google.com/books?id=12qdOZ0gsWoC&amp;pg=PA280|year=1958|publisher=Courier Dover Publications|isbn=978-0-486-20429-1|page=280}}&lt;/ref&gt;

The Jewish mathematician [[Abraham bar Hiyya|Abraham bar Hiyya Ha-Nasi]] (12th century, Spain) authored the first European book to include the full solution to the general quadratic equation.&lt;ref name=Livio2006&gt;{{cite book |last=Livio |first=Mario |title=The Equation that Couldn't Be Solved |year=2006 |publisher=Simon &amp; Schuster |isbn=978-0743258210 |url=https://books.google.com/?id=veQ9a3nixDUC&amp;pg=PA62&amp;lpg=PA62&amp;dq=Abraham+bar+Hiyya+Ha-Nasi+quadratic}}&lt;/ref&gt; His solution was largely based on Al-Khwarizmi's work.&lt;ref name=Katz2007/&gt; The writing of the Chinese mathematician [[Yang Hui]] (1238–1298 AD) is the first known one in which quadratic equations with negative coefficients of 'x' appear, although he attributes this to the earlier [[Liu Yi (mathematician)|Liu Yi]].&lt;ref name=Ron&gt;{{cite book|last=Ronan|first=Colin|title=The Shorter Science and Civilisation in China|url=https://books.google.com/books?id=XsMxmS7NyukC&amp;pg=PA15|year=1985|publisher=Cambridge University Press|isbn=978-0-521-31536-4|page=15}}&lt;/ref&gt; By 1545 [[Gerolamo Cardano]] compiled the works related to the quadratic equations. The quadratic formula covering all cases was first obtained by [[Simon Stevin]] in 1594.&lt;ref&gt;{{Citation |title=The Principal Works of Simon Stevin, Mathematics |volume=II-B |first1=D. J. |last1=Struik |first2=Simon |last2=Stevin |publisher=C. V. Swets &amp; Zeitlinger |year=1958 |page=470 |url=http://www.dwc.knaw.nl/pub/bronnen/Simon_Stevin-%5bII_B%5d_The_Principal_Works_of_Simon_Stevin,_Mathematics.pdf}}&lt;/ref&gt; In 1637 [[René Descartes]] published ''[[La Géométrie]]'' containing the quadratic formula in the form we know today. The first appearance of the general solution in the modern mathematical literature appeared in an 1896 paper by [[Henry Heaton]].&lt;ref name="heaton-1896"&gt;{{cite journal | last1 = Heaton | first1 = H | year = 1896 | title = A Method of Solving Quadratic Equations | journal = [[American Mathematical Monthly]] | volume = 3 | issue = 10| pages = 236–237 | jstor=2971099 | doi=10.2307/2971099}}&lt;/ref&gt;

==Advanced topics==

===Alternative methods of root calculation===

====Vieta's formulas====
{{Main|Vieta's formulas}}
[[File:Excel quadratic error.PNG|thumb|350px|Figure 5. Graph of the difference between Vieta's approximation for the smaller of the two roots of the quadratic equation {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c'' {{=}} 0}} compared with the value calculated using the quadratic formula. Vieta's approximation is inaccurate for small {{math|''b''}} but is accurate for large {{math|''b''}}. The direct evaluation using the quadratic formula is accurate for small {{math|''b''}} with roots of comparable value but experiences loss of significance errors for large {{math|''b''}} and widely spaced roots. The difference between Vieta's approximation ''versus'' the direct computation reaches a minimum at the large dots, and rounding causes squiggles in the curves beyond this minimum.|alt=Figure 5. Graph of the difference between Vieta's approximation for the smaller of the two roots of the quadratic equation x squared plus b x plus c equals zero compared with the value calculated using the quadratic formula. The difference is plotted as a function of b for two different values of c, c equals 4, and c equals 400,000. The graph is a log log graph, with the vertical axis, the difference, ranging from ten to the minus 13 at the bottom to ten to the minus 1 at the top. The horizontal axis, b, ranges from 10 at the left to ten to the eighth at the right. Vieta's approximation for the smaller root is not accurate for small b but is accurate for large b. The direct evaluation of the smaller root using the quadratic formula is accurate for small b with roots of comparable value, but experiences loss of significance errors for large b and widely spaced roots. When c equals 4, Vieta's approximation starts off poorly at the left, but gets better with larger b, the difference between Vieta's approximation and the quadratic formula reaching a minimum at approximately b equals ten to the fifth. Vieta's approximation and the quadratic formula then start diverging again because the quadratic formula experiences loss of significance error. When c equals four hundred thousand, the difference between Vieta's approximation and the quadratic formula reaches a minimum at approximately b equals ten to the seventh. The curves are both straight to the left of the minimum, indicating a simple monomial power relationship between the difference and b. Likewise, the curves are both approximately straight to the right of the minimum, indicating a power relationship, except that the straight lines have squiggles in them due to the loss of significance errors in the quadratic formula.]]

Vieta's formulas give a simple relation between the roots of a polynomial and its coefficients. In the case of the quadratic polynomial, they take the following form:
:&lt;math&gt; x_1 + x_2 = -\frac{b}{a} &lt;/math&gt;
and
:&lt;math&gt; x_1 \ x_2 = \frac{c}{a}.&lt;/math&gt;
These results follow immediately from the relation:
:&lt;math&gt;\left( x - x_1 \right) \ \left( x-x_2 \right ) = x^2 \ - \left( x_1+x_2 \right)x +x_1 x_2 = 0,&lt;/math&gt;
which can be compared term by term with
:&lt;math&gt; x^2 + (b/a)x +c/a = 0.&lt;/math&gt;
The first formula above yields a convenient expression when graphing a quadratic function. Since the graph is symmetric with respect to a vertical line through the [[Quadratic function#Vertex|vertex]], when there are two real roots the vertex's {{math|''x''}}-coordinate is located at the average of the roots (or intercepts). Thus the {{math|''x''}}-coordinate of the vertex is given by the expression
:&lt;math&gt; x_V = \frac {x_1 + x_2} {2} = -\frac{b}{2a}.&lt;/math&gt;
The {{math|''y''}}-coordinate can be obtained by substituting the above result into the given quadratic equation, giving
:&lt;math&gt; y_V = - \frac{b^2}{4a} + c = - \frac{ b^2 - 4ac} {4a}.&lt;/math&gt;

As a practical matter, Vieta's formulas provide a useful method for finding the roots of a quadratic in the case where one root is much smaller than the other. If {{math|{{!}}&amp;#8239;''x'' &lt;sub&gt;2&lt;/sub&gt;{{!}} &amp;lt;&amp;lt; {{!}}&amp;#8239;''x'' &lt;sub&gt;1&lt;/sub&gt;{{!}}}}, then {{math|''x'' &lt;sub&gt;1&lt;/sub&gt; + ''x'' &lt;sub&gt;2&lt;/sub&gt; &amp;asymp; ''x'' &lt;sub&gt;1&lt;/sub&gt;}}, and we have the estimate:
:&lt;math&gt; x_1 \approx -\frac{b}{a} .&lt;/math&gt;
The second Vieta's formula then provides:
:&lt;math&gt;x_2 = \frac{c}{a \ x_1} \approx -\frac{c}{b} .&lt;/math&gt;
These formulas are much easier to evaluate than the quadratic formula under the condition of one large and one small root, because the quadratic formula evaluates the small root as the difference of two very nearly equal numbers (the case of large {{math|''b''}}), which causes [[round-off error]] in a numerical evaluation. Figure&amp;nbsp;5 shows the difference between (i)&amp;nbsp;a direct evaluation using the quadratic formula (accurate when the roots are near each other in value) and (ii)&amp;nbsp;an evaluation based upon the above approximation of Vieta's formulas (accurate when the roots are widely spaced). As the linear coefficient {{math|''b''}} increases, initially the quadratic formula is accurate, and the approximate formula improves in accuracy, leading to a smaller difference between the methods as {{math|''b''}} increases. However, at some point the quadratic formula begins to lose accuracy because of round off error, while the approximate method continues to improve. Consequently, the difference between the methods begins to increase as the quadratic formula becomes worse and worse.

This situation arises commonly in amplifier design, where widely separated roots are desired to ensure a stable operation (see [[step response]]).

====Trigonometric solution====
In the days before calculators, people would use [[mathematical table]]s&amp;mdash;lists of numbers showing the results of calculation with varying arguments&amp;mdash;to simplify and speed up computation. Tables of logarithms and trigonometric functions were common in math and science textbooks. Specialized tables were published for applications such as astronomy, celestial navigation and statistics. Methods of numerical approximation existed, called [[prosthaphaeresis]], that offered shortcuts around time-consuming operations such as multiplication and taking powers and roots.&lt;ref name=Ballew2007&gt;{{cite web|last=Ballew|first=Pat|title=Solving Quadratic Equations &amp;mdash; By analytic and graphic methods; Including several methods you may never have seen|url=http://www.pballew.net/quadsol.pdf|accessdate=18 April 2013}}&lt;/ref&gt; Astronomers, especially, were concerned with methods that could speed up the long series of computations involved in [[celestial mechanics]] calculations.

It is within this context that we may understand the development of means of solving quadratic equations by the aid of trigonometric substitution. Consider the following alternate form of the quadratic equation,

'''[1]'''&amp;nbsp;&amp;nbsp; &lt;math&gt;ax^2 + bx \pm c = 0 ,&lt;/math&gt;

where the sign of the ± symbol is chosen so that {{math|''a''}} and {{math|''c''}} may both be positive. By substituting

'''[2]'''&amp;nbsp;&amp;nbsp; &lt;math&gt;x = \sqrt{c/a} \tan\theta &lt;/math&gt;

and then multiplying through by {{math|cos&lt;sup&gt;2&lt;/sup&gt;''&amp;theta;''}}, we obtain

'''[3]'''&amp;nbsp;&amp;nbsp; &lt;math&gt;\sin^2\theta + \frac{b}{\sqrt {ac}} \sin\theta  \cos\theta \pm \cos^2\theta = 0 .&lt;/math&gt;

Introducing functions of {{math|2''&amp;theta;''}} and rearranging, we obtain

'''[4]'''&amp;nbsp;&amp;nbsp; &lt;math&gt; \tan 2 \theta_n = + 2 \frac{\sqrt{ac}}{b} ,&lt;/math&gt;

'''[5]'''&amp;nbsp;&amp;nbsp; &lt;math&gt; \sin 2 \theta_p = - 2 \frac{\sqrt{ac}}{b} ,&lt;/math&gt;

where the subscripts {{math|''n''}} and {{math|''p''}} correspond, respectively, to the use of a negative or positive sign in equation '''[1]'''. Substituting the two values of {{math|''&amp;theta;''&lt;sub&gt;n&lt;/sub&gt;}} or {{math|''&amp;theta;''&lt;sub&gt;p&lt;/sub&gt;}} found from equations '''[4]''' or '''[5]''' into '''[2]''' gives the required roots of '''[1]'''. Complex roots occur in the solution based on equation '''[5]''' if the absolute value of {{math|sin 2''&amp;theta;''&lt;sub&gt;p&lt;/sub&gt;}} exceeds unity. The amount of effort involved in solving quadratic equations using this mixed trigonometric and logarithmic table look-up strategy was two-thirds the effort using logarithmic tables alone.&lt;ref name=Seares1945&gt;{{cite journal|last=Seares|first=F. H.|title=Trigonometric Solution of the Quadratic Equation|journal=Publications of the Astronomical Society of the Pacific |year=1945 |volume=57 |issue=339 |page=307&amp;ndash;309 |doi=10.1086/125759 |bibcode=1945PASP...57..307S}}&lt;/ref&gt; Calculating complex roots would require using a different trigonometric form.&lt;ref name=Aude1938&gt;{{cite journal |last=Aude |first=H. T. R. |title=The Solutions of the Quadratic Equation Obtained by the Aid of the Trigonometry |journal=National Mathematics Magazine |year=1938 |volume=13 |issue=3 |page=118&amp;ndash;121 |doi=10.2307/3028750 |jstor=3028750}}&lt;/ref&gt;

:To illustrate, let us assume we had available seven-place logarithm and trigonometric tables, and wished to solve the following to six-significant-figure accuracy:
:::&lt;math&gt;4.16130x^2 + 9.15933x - 11.4207 = 0&lt;/math&gt;
#A seven-place lookup table might have only 100,000 entries, and computing intermediate results to seven places would generally require interpolation between adjacent entries. 
#&lt;math&gt;\log a = 0.6192290,  \log b = 0.9618637, \log c  = 1.0576927&lt;/math&gt;
#&lt;math&gt;2 \sqrt{ac}/b = 2 \times 10^{(0.6192290 + 1.0576927)/2 - 0.9618637} = 1.505314 &lt;/math&gt;
#&lt;math&gt;\theta = (\tan^{-1}1.505314) / 2 = 28.20169^{\circ} \text{ or } -61.79831^{\circ} &lt;/math&gt;
#&lt;math&gt;\log | \tan \theta | = -0.2706462 \text{ or } 0.2706462&lt;/math&gt;
#&lt;math&gt; \log\sqrt{c/a} = (1.0576927 - 0.6192290) / 2 = 0.2192318&lt;/math&gt;
#&lt;math&gt;x_1 = 10^{0.2192318 - 0.2706462} = 0.888353&lt;/math&gt; (rounded to six significant figures)
::&lt;math&gt;x_2 = -10^{0.2192318 + 0.2706462} = -3.08943&lt;/math&gt;

====Solution for complex roots in polar coordinates====

If the quadratic equation &lt;math&gt;ax^2+bx+c=0&lt;/math&gt; with real coefficients has two complex roots&amp;mdash;the case where &lt;math&gt;b^2-4ac&lt;0,&lt;/math&gt; requiring ''a'' and ''c'' to have the same sign as each other&amp;mdash;then the solutions for the roots can be expressed in polar form as&lt;ref&gt;Simons, Stuart, "Alternative approach to complex roots of real quadratic equations", ''Mathematical Gazette'' 93, March 2009, 91–92.&lt;/ref&gt;

:&lt;math&gt;x_1, \, x_2=r(\cos \theta \pm i\sin \theta), &lt;/math&gt;

where &lt;math&gt;r=\sqrt{\tfrac{c}{a}}&lt;/math&gt; and &lt;math&gt;\theta =\cos ^{-1}\left(\tfrac{-b}{2\sqrt{ac}}\right).&lt;/math&gt;

====Geometric solution====
[[File:LillsQuadratic.svg|thumb|180px|Figure 6. Geometric solution of {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c'' {{=}} 0}} using Lill's method. Solutions are −AX1/SA, −AX2/SA|alt=Figure 6. Geometric solution of eh x squared plus b x plus c = 0 using Lill's method. The geometric construction is as follows: Draw a trapezoid S Eh B C. Line S Eh of length eh is the vertical left side of the trapezoid. Line Eh B of length b is the horizontal bottom of the trapezoid. Line B C of length c is the vertical right side of the trapezoid. Line C S completes the trapezoid. From the midpoint of line C S, draw a circle passing through points C and S. Depending on the relative lengths of eh, b, and c, the circle may or may not intersect line Eh B. If it does, then the equation has a solution. If we call the intersection points X 1 and X 2, then the two solutions are given by negative Eh X 1 divided by S Eh, and negative Eh X 2 divided by S Eh.]]

The quadratic equation may be solved geometrically in a number of ways. One way is via [[Lill's method]]. The three coefficients {{math|''a''}}, {{math|''b''}}, {{math|''c''}} are drawn with right angles between them as in SA, AB, and BC in Figure&amp;nbsp;6. A circle is drawn with the start and end point SC as a diameter. If this cuts the middle line AB of the three then the equation has a solution, and the solutions are given by negative of the distance along this line from A divided by the first coefficient {{math|''a''}} or SA. If {{math|''a''}} is {{math|1}} the coefficients may be read off directly. Thus the solutions in the diagram are &amp;minus;AX1/SA and &amp;minus;AX2/SA.&lt;ref&gt;{{Citation |title=Graphical Method for finding readily the Real Roots of Numerical Equations of Any Degree |first=William Herbert |last=Bixby |year=1879 |publisher=West Point N. Y.}}&lt;/ref&gt;

[[File:CarlyleCircle.svg|thumb|300px|left|Carlyle circle of the quadratic equation ''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''sx''&amp;nbsp;+&amp;nbsp;''p''&amp;nbsp;=&amp;nbsp;0.]]
The [[Carlyle circle]], named after [[Thomas Carlyle]], has the property that the solutions of the quadratic equation are the horizontal coordinates of the intersections of the circle with the [[horizontal axis]].&lt;ref name=Wolfram&gt;{{cite web|last=Weisstein|first=Eric W|title=Carlyle Circle|url=http://mathworld.wolfram.com/CarlyleCircle.html|work=From MathWorld—A Wolfram Web Resource|accessdate=21 May 2013}}&lt;/ref&gt; Carlyle circles have been used to develop [[ruler-and-compass construction]]s of [[regular polygon]]s.

====Alternative quadratic formula====
The general quadratic equation can be written in the standard form
:&lt;math&gt;x^2-4ux+4v^2=0&lt;/math&gt;
where {{math|''u''}} and {{math|''v''}} are [[complex number]]s. Then the solutions can be written in the particularly symmetric form
:&lt;math&gt;x_{1,2}=(\sqrt{u+v}\pm\sqrt{u-v})^2&lt;/math&gt;
or equivalently
:&lt;math&gt;x_{1,2}=(\sqrt{u-v}\pm\sqrt{u+v})^2.&lt;/math&gt;
The correctness of the formula can easily be verified by inserting the expression into the equation. This formula has the advantage that it is numerically more stable than the classical quadratic formula. It appeared in.&lt;ref name=Hungerbühler2017&gt;{{cite arxiv|last=Hungerbühler|first=Norbert|title=An alternative quadratic formula|year=2017|eprint=1702.05789|class=math.HO}}&lt;/ref&gt; Problems originating from physics or geometry often present themselves in the homogeneous standard form on which the alternative formula is based. In particular, [[René Descartes]]' first example in ''[[La Géométrie]]'', at the very hour of birth of the quadratic formula, was geometric and of this particular homogeneous form.

===Generalization of quadratic equation===
The formula and its derivation remain correct if the coefficients {{math|''a''}}, {{math|''b''}} and {{math|''c''}} are [[complex number]]s, or more generally members of any [[field (mathematics)|field]] whose [[characteristic (algebra)|characteristic]] is not {{math|2}}. (In a field of characteristic 2, the element {{math|2''a''}} is zero and it is impossible to divide by it.)

The symbol
:&lt;math&gt;\pm \sqrt {b^2-4ac}&lt;/math&gt;
in the formula should be understood as "either of the two elements whose square is {{math|''b''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 4''ac''}}, if such elements exist". In some fields, some elements have no square roots and some have two; only zero has just one square root, except in fields of characteristic {{math|2}}. Even if a field does not contain a square root of some number, there is always a quadratic [[extension field]] which does, so the quadratic formula will always make sense as a formula in that extension field.

====Characteristic 2====
In a field of characteristic {{math|2}}, the quadratic formula, which relies on {{math|2}} being a [[unit (ring theory)|unit]], does not hold. Consider the [[monic polynomial|monic]] quadratic polynomial
:&lt;math&gt;x^{2} + bx + c&lt;/math&gt;
over a field of characteristic {{math|2}}. If {{math|''b'' {{=}} 0}}, then the solution reduces to extracting a square root, so the solution is
:&lt;math&gt;x = \sqrt{c}&lt;/math&gt;
and there is only one root since
:&lt;math&gt;-\sqrt{c} = -\sqrt{c} + 2\sqrt{c} = \sqrt{c}.&lt;/math&gt;
In summary,
:&lt;math&gt;\displaystyle x^{2} + c = (x + \sqrt{c})^{2}.&lt;/math&gt;
See [[quadratic residue]] for more information about extracting square roots in finite fields.

In the case that {{math|''b'' &amp;ne; 0}}, there are two distinct roots, but if the polynomial is [[irreducible polynomial|irreducible]], they cannot be expressed in terms of square roots of numbers in the coefficient field. Instead, define the '''2-root''' {{math|''R''(''c'')}} of {{math|''c''}} to be a root of the polynomial {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''x'' + ''c''}}, an element of the [[splitting field]] of that polynomial. One verifies that {{math|''R''(''c'') + 1}} is also a root. In terms of the 2-root operation, the two roots of the (non-monic) quadratic {{math|''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' + ''c''}} are
:&lt;math&gt;\frac{b}{a}R\left(\frac{ac}{b^2}\right)&lt;/math&gt;
and
:&lt;math&gt;\frac{b}{a}\left(R\left(\frac{ac}{b^2}\right)+1\right).&lt;/math&gt;

For example, let {{math|''a''}} denote a multiplicative generator of the group of units of {{math|''F''&lt;sub&gt;4&lt;/sub&gt;}}, the [[Galois field]] of order four (thus {{math|''a''}} and {{math|''a'' + 1}} are roots of {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''x'' + 1}} over {{math|''F''&lt;sub&gt;4&lt;/sub&gt;}}. Because {{math|(''a'' + 1)&lt;sup&gt;2&lt;/sup&gt; {{=}} ''a''}}, {{math|''a'' + 1}} is the unique solution of the quadratic equation {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''a'' {{=}} 0}}. On the other hand, the polynomial {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''ax'' + 1}} is irreducible over {{math|''F''&lt;sub&gt;4&lt;/sub&gt;}}, but it splits over {{math|''F''&lt;sub&gt;16&lt;/sub&gt;}}, where it has the two roots {{math|''ab''}} and {{math|''ab'' + ''a''}}, where {{math|''b''}} is a root of {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + ''x'' + ''a''}} in {{math|''F''&lt;sub&gt;16&lt;/sub&gt;}}.

This is a special case of [[Artin–Schreier theory]].

==See also==
{{Div col|colwidth=25em}}
* [[Chakravala method]]
*[[Completing the square]]
* [[Cubic function]]
* [[Fundamental theorem of algebra]]
* [[Linear equation]]
* [[Parabola]]
* [[Periodic points of complex quadratic mappings]]
* [[Quadratic function]]
* [[Quadratic polynomial]]
* [[Quartic function]]
* [[Quintic function]]
* [[Solving quadratic equations with continued fractions]]
{{colend}}

==References==
{{reflist|30em}}

==External links==
{{commons category}}
* {{springer|title=Quadratic equation|id=p/q076050}}
* {{MathWorld|title=Quadratic equations|urlname=QuadraticEquation}}
* [http://plus.maths.org/issue29/features/quadratic/index-gifd.html 101 uses of a quadratic equation]
* [http://plus.maths.org/issue30/features/quadratic/index-gifd.html 101 uses of a quadratic equation: Part II]
{{Polynomials}}

{{DEFAULTSORT:Quadratic Equation}}
[[Category:Elementary algebra]]
[[Category:Equations]]</text>
      <sha1>qhn8r9f034iwzak030w4ejk4p5xdk6p</sha1>
    </revision>
  </page>
  <page>
    <title>Quasispecies model</title>
    <ns>0</ns>
    <id>25308</id>
    <revision>
      <id>841408190</id>
      <parentid>837438808</parentid>
      <timestamp>2018-05-15T17:23:24Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19092">{{more citations needed|date=August 2013}}
The '''quasispecies model''' is a description of the process of the Darwinian [[evolution]] of certain [[self-replication|self-replicating]] entities within the framework of [[physical chemistry]]. A quasispecies is a large group or "'''cloud'''" of related [[genotype]]s that exist in an environment of high mutation rate (at stationary state&lt;ref&gt;{{Cite journal|last=Eigen|first=Manfred|last2=McCaskill|first2=John|last3=Schuster|first3=Peter|title=Molecular quasi-species|url=http://pubs.acs.org/doi/pdf/10.1021/j100335a010|journal=The Journal of Physical Chemistry|language=en|volume=92|issue=24|pages=6881–6891|doi=10.1021/j100335a010|hdl=11858/00-001M-0000-002C-84A7-C}}&lt;/ref&gt;), where a large fraction of offspring are expected to contain one or more mutations relative to the parent.  This is in contrast to a [[species]], which from an evolutionary perspective is a more-or-less stable single genotype, most of the offspring of which will be genetically accurate copies.&lt;ref&gt;{{cite book|authors=Biebricher, C.K &amp; Eigen, M.|chapter=What is a Quasispecies|editor=Esteban Domingo|title=Quasispecies: Concept and Implications for Virology |publisher=Springer|year=2006|isbn=978-3-540-26395-1|page=1}}&lt;/ref&gt;

It is useful mainly in providing a qualitative understanding of the evolutionary processes of self-replicating macromolecules such as [[RNA]] or [[DNA]] or simple asexual organisms such as [[bacterium|bacteria]] or [[virus]]es (see also [[viral quasispecies]]), and is helpful in explaining something of the early stages of the [[Abiogenesis|origin of life]]. Quantitative predictions based on this model are difficult because the parameters that serve as its input are impossible to obtain from actual biological systems. The quasispecies model was put forward by [[Manfred Eigen]] and [[Peter Schuster]]&lt;ref&gt;{{cite book |vauthors=Eigen M, Schuster P |year=1979 |title=The Hypercycle: A Principle of Natural Self-Organization |publisher=Springer-Verlag |location=Berlin |isbn=0-387-09293-5}}&lt;/ref&gt; based on initial work done by Eigen.&lt;ref&gt;{{cite journal |last=Eigen |first=Manfred |date=October 1971 |title=Selforganization of matter and the evolution of biological macromolecules |journal=Die Naturwissenschaften |volume=58 |issue=10 |pages=465–523 |doi=10.1007/BF00623322 |pmid=4942363}}&lt;/ref&gt;

==Simplified explanation==

When evolutionary biologists describe competition between species, they generally assume that each species is a single genotype whose descendants are mostly accurate copies.  (Such genotypes are said to have a high reproductive ''fidelity''.)  Evolutionarily, we are interested in the behavior and fitness of that one species or genotype over time.{{citation needed|date=August 2013}}

Some organisms or genotypes, however, may exist in circumstances of low fidelity, where most descendants contain one or more mutations.  A group of such genotypes is constantly changing, so discussions of which single genotype is the most fit become meaningless.  Importantly, if many closely related genotypes are only one mutation away from each other, then genotypes in the group can mutate back and forth into each other.  For example, with one mutation per generation, a child of the sequence AGGT could be AGTT, and a grandchild could be AGGT again.  Thus we can envision a "'''cloud'''" of related genotypes that is rapidly mutating, with sequences going back and forth among different points in the cloud.  Though the proper definition is mathematical, that cloud, roughly speaking, is a quasispecies.{{citation needed|date=August 2013}}

Quasispecies behavior exists for large numbers of individuals existing at a certain (high) range of mutation rates.&lt;ref&gt;Martinez, MA, Martus G, Capel E, Parera M, Franco S, Nevot M (2012) Quasispecies Dynamics of RNA Viruses. In: Viruses: Essential Agents of Life, Springer, Dordrecht, pp. 21-42.&lt;/ref&gt;

===Quasispecies, fitness, and evolutionary selection===
In a species, though reproduction may be mostly accurate, periodic mutations will give rise to one or more competing genotypes.  If a mutation results in greater replication and survival, the mutant genotype may out-compete the parent genotype and come to dominate the species.  Thus, the individual genotypes (or species) may be seen as the units on which selection acts and biologists will often speak of a single genotype's [[fitness (biology)|fitness]].{{citation needed|date=August 2013}}

In a quasispecies, however, mutations are ubiquitous and so the fitness of an individual genotype becomes meaningless: if one particular mutation generates a boost in reproductive success, it can't amount to much because that genotype's offspring are unlikely to be accurate copies with the same properties.  Instead, what matters is the ''connectedness'' of the cloud.&lt;ref&gt;{{cite journal | last1 = Villarreal | first1 = L.P. | last2 = Witzany | first2 = G. | year = 2013 | title = Rethinking quasispecies theory: From fittest type to cooperative consortia | journal = World Journal of Biological Chemistry | volume = 4 | issue = | pages = 70–79 | doi = 10.4331/wjbc.v4.i4.79 | pmid = 24340131 | pmc=3856310}}&lt;/ref&gt;  For example, the sequence AGGT has 12 (3+3+3+3) possible single point mutants AGGA, AGGG, and so on.  If 10 of those mutants are viable genotypes that may reproduce (and some of whose offspring or grandchildren may mutate back into AGGT again), we would consider that sequence a well-connected node in the cloud.  If instead only two of those mutants are viable, the rest being lethal mutations, then that sequence is poorly connected and most of its descendants will not reproduce. The analog of fitness for a quasispecies is the tendency of nearby relatives within the cloud to be well-connected, meaning that more of the mutant descendants will be viable and give rise to further descendants within the cloud.{{citation needed|date=August 2013}}

When the fitness of a single genotype becomes meaningless because of the high rate of mutations, the cloud as a whole or quasispecies becomes the natural unit of selection.

===Application to biological research===

Quasispecies represents the evolution of high-mutation-rate viruses such as [[HIV]] and sometimes single genes or molecules within the genomes of other organisms.&lt;ref&gt;{{cite journal |last1=Holland |last2=et. al. |year= |title=RNA virus populations as quasispecies |journal=Genetic Diversity of RNA Viruses}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Domingo |first1=E. |year=2002 |title=Quasispecies theory in virology |journal=Journal of Virology |volume=76 |pages=463–465 |doi= 10.1128/jvi.76.1.463-465.2002|url=http://jvi.asm.org/content/76/1/463.full|pmc=135734 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Wilke |year=2005 |title=Quasispecies theory in the context of population genetics |journal=BMC Evolutionary Biology |volume=5 |pages=44 |doi=10.1186/1471-2148-5-44 |url=http://www.biomedcentral.com/1471-2148/5/44|pmc=1208876 }}&lt;/ref&gt; Quasispecies models have also been proposed by Jose Fontanari and [[Emmanuel David Tannenbaum]] to model the evolution of sexual reproduction.&lt;ref&gt;{{cite journal |vauthors=Tannenbaum ED, Fontanari JF |year=2008 |title=A quasispecies approach to the evolution of sexual replication in unicellular organisms |journal=Theory Bioscience |volume=127 |pages=53–65 |doi=10.1007/s12064-008-0023-2}}&lt;/ref&gt; Quasispecies was also shown in compositional replicators (based on the [[Gard model]] for [[abiogenesis]])&lt;ref&gt;{{cite journal|last1=Gross |first1=R. |last2=Fouxon |first2=I. |last3=Lancet |first3=D. |last4=Markovitch |first4=O. |year=2014 |title=Quasispecies in population of compositional assemblies |journal=BMC Evolutionary Biology |volume=14 |pages=2623 |doi=10.1186/s12862-014-0265-1 |url=http://www.biomedcentral.com/1471-2148/14/2623/abstract |deadurl=yes |archiveurl=https://web.archive.org/web/20150102125325/http://www.biomedcentral.com/1471-2148/14/2623/abstract |archivedate=January 2, 2015 |pmid=25547629 |pmc=4357159}}&lt;/ref&gt; and was also suggested to be applicable to describe cell's replication, which amongst other things requires the maintenance and evolution of the internal composition of the parent and bud.

==Formal background==

The model rests on four assumptions{{citation needed|date=August 2013}}:
# The self-replicating entities can be represented as sequences composed of a small number of building blocks—for example, sequences of RNA consisting of the four bases [[adenine]], [[guanine]], [[cytosine]], and [[uracil]].
# New sequences enter the system solely as the result of a copy process, either correct or erroneous, of other sequences that are already present.
# The substrates, or raw materials, necessary for ongoing replication are always present in sufficient quantity. Excess sequences are washed away in an outgoing flux.
# Sequences may decay into their building blocks. The probability of decay does not depend on the sequences' age; old sequences are just as likely to decay as young sequences.

In the quasispecies model, [[mutation]]s occur through errors made in the process of copying already existing sequences. Further, [[natural selection|selection]] arises because different types of sequences tend to replicate at different rates, which leads to the suppression of sequences that replicate more slowly in favor of sequences that replicate faster. However, the quasispecies model does not predict the ultimate extinction of all but the fastest replicating sequence. Although the sequences that replicate more slowly cannot sustain their abundance level by themselves, they are constantly replenished as sequences that replicate faster mutate into them. At equilibrium, removal of slowly replicating sequences due to decay or outflow is balanced by replenishing, so that even relatively slowly replicating sequences can remain present in finite abundance.{{citation needed|date=August 2013}}

Due to the ongoing production of mutant sequences, selection does not act on single sequences, but on mutational "clouds" of closely related sequences, referred to as ''quasispecies''. In other words, the evolutionary success of a particular sequence depends not only on its own replication rate, but also on the replication rates of the mutant sequences it produces, and on the replication rates of the sequences of which it is a mutant. As a consequence, the sequence that replicates fastest may even disappear completely in selection-mutation equilibrium, in favor of more slowly replicating sequences that are part of a quasispecies with a higher average growth rate.&lt;ref&gt;{{cite journal |vauthors=Schuster P, Swetina J |date=November 1988 |title=Stationary mutant distributions and evolutionary optimization |journal=Bulletin of Mathematical Biology |volume=50 |issue=6  |pages=635–660 |issn=0092-8240 |doi=10.1007/BF02460094 |publisher=Kluwer Academic Publishers |location=Dordrecht |pmid=3219448}}&lt;/ref&gt;  Mutational clouds as predicted by the quasispecies model have been observed in RNA viruses and in ''in vitro'' RNA replication.&lt;ref&gt;{{cite journal |vauthors=Domingo E, Holland JJ |date=October 1997 |title=RNA virus mutations and fitness for survival |journal=Annual Review of Microbiology |volume=51 |pages=151–178  |doi=10.1146/annurev.micro.51.1.151 |pmid=9343347}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |vauthors=Burch CL, Chao L |year=2000 |title=Evolvability of an RNA virus is determined by its mutational neighbourhood |journal=Nature |volume=406 |pages=625–628 |doi=10.1038/35020564 |pmid=10949302 |issue=6796}}&lt;/ref&gt;

The mutation rate and the general fitness of the molecular sequences and their neighbors is crucial to the formation of a quasispecies. If the mutation rate is zero, there is no exchange by mutation, and each sequence is its own species. If the mutation rate is too high, exceeding what is known as the [[Error threshold (evolution)|error threshold]], the quasispecies will break down and be dispersed over the entire range of available sequences.{{citation needed|date=August 2013}}

==Mathematical description==

A simple mathematical model for a quasispecies is as follows:&lt;ref&gt;{{Cite journal|last=Eigen|first=Manfred|last2=McCaskill|first2=John|last3=Schuster|first3=Peter|title=Molecular quasi-species|url=http://pubs.acs.org/doi/pdf/10.1021/j100335a010|journal=The Journal of Physical Chemistry|language=en|volume=92|issue=24|pages=6881–6891|doi=10.1021/j100335a010|hdl=11858/00-001M-0000-002C-84A7-C}}&lt;/ref&gt; let there be  &lt;math&gt;S&lt;/math&gt;  possible sequences and let there be &lt;math&gt;n_i&lt;/math&gt; organisms with sequence ''i''. Let's say that each of these organisms asexually gives rise to &lt;math&gt;A_i&lt;/math&gt; offspring. Some are duplicates of their parent, having sequence ''i'', but some are mutant and have some other sequence. Let the mutation rate &lt;math&gt;q_{ij}&lt;/math&gt; correspond to the [[probability]] that a ''j'' type parent will produce an ''i'' type organism. Then the [[Expected value|expected]] fraction of offspring generated by ''j'' type organisms that would be ''i'' type organisms is &lt;math&gt;w_{ij}=A_j q_{ij}&lt;/math&gt;,

where &lt;math&gt;\sum_i q_{ij}=1&lt;/math&gt;.

Then the total number of ''i''-type organisms after the first round of reproduction, given as &lt;math&gt;n'_i&lt;/math&gt;, is

:&lt;math&gt;n'_i=\sum_j w_{ij}n_j&lt;/math&gt;

Sometimes a death rate term &lt;math&gt;D_i&lt;/math&gt; is included so that:

:&lt;math&gt;w_{ij}=A_j q_{ij}-D_i\delta_{ij}&lt;/math&gt;

where &lt;math&gt;\delta_{ij}&lt;/math&gt; is equal to 1 when i=j and is zero otherwise. Note that the ''n-th'' generation can be found by just taking the ''n-th'' power of '''W''' substituting it in place of '''W''' in the above formula.

This is just a [[system of linear equations]]. The usual way to solve such a system is to first [[Diagonalizable matrix|diagonalize]] the '''W''' matrix. Its diagonal entries will be [[eigenvalues]] corresponding to certain linear combinations of certain subsets of sequences which will be [[eigenvectors]] of the '''W''' matrix. These subsets of sequences are the quasispecies.  Assuming that the matrix '''W''' is a [[primitive matrix]] ([[Irreducibility (mathematics)|irreducible]] and [[Perron–Frobenius theorem|aperiodic]]), then after very many generations only the eigenvector with the largest eigenvalue will prevail, and it is this quasispecies that will eventually dominate. The components of this eigenvector give the relative abundance of each sequence at equilibrium.{{citation needed|date=August 2013}}

=== Note about primitive matrices ===

'''W''' being primitive means that for some integer &lt;math&gt; n &gt; 0 &lt;/math&gt;, that the &lt;math&gt;n^{th} &lt;/math&gt; power of '''W''' is &gt; 0, i.e. all the entries are positive.  If '''W''' is primitive then each type can, through a sequence of mutations (i.e. powers of '''W''') mutate into all the other types after some number of generations. '''W''' is not primitive if it is periodic, where the population can perpetually cycle through different disjoint sets of compositions, or if it is reducible, where the dominant species (or quasispecies) that develops can depend on the initial population, as is the case in the simple example given below.{{citation needed|date=August 2013}}

===Alternative formulations===

The quasispecies formulae may be expressed as a set of linear differential equations. If we consider the difference between the new state &lt;math&gt;n'_i&lt;/math&gt; and the old state &lt;math&gt;n_i&lt;/math&gt; to be the state change over one moment of time, then we can state that the time derivative of &lt;math&gt;n_i&lt;/math&gt; is given by this difference,   &lt;math&gt;\dot{n}_i = n'_i-n_i&lt;/math&gt; we can write:

:&lt;math&gt;\dot{n}_i=\sum_j w_{ij}n_j-n_i&lt;/math&gt;

The quasispecies equations are usually expressed in terms of concentrations &lt;math&gt;x_i&lt;/math&gt; where

:&lt;math&gt;x_i\ \stackrel{\mathrm{def}}{=}\  \frac{n_i}{\sum_j n_j}&lt;/math&gt;.
:&lt;math&gt;x'_i\ \stackrel{\mathrm{def}}{=}\  \frac{n'_i}{\sum_j n'_j}&lt;/math&gt;.

The above equations for the quasispecies then become for the discrete version:

:&lt;math&gt;x'_i = \frac{\sum_j w_{ij}x_j}{\sum_{ij} w_{ij}x_j}&lt;/math&gt;

or, for the continuum version:

:&lt;math&gt;\dot{x}_i =\sum_j w_{ij}x_j-x_i\sum_{ij}w_{ij}x_j.&lt;/math&gt;

===Simple example===
The quasispecies concept can be illustrated by a simple system consisting of 4 sequences. Sequences [0,0], [0,1], [1,0], and [1,1] are numbered 1, 2, 3, and 4, respectively. Let's say the [0,0] sequence never mutates and always produces a single offspring. Let's say the other 3 sequences all produce, on average, &lt;math&gt;1-k&lt;/math&gt; replicas of themselves, and &lt;math&gt;k&lt;/math&gt; of each of the other two types, where &lt;math&gt;0\le k\le 1&lt;/math&gt;. The '''W''' matrix is then:

:&lt;math&gt;\mathbf{W}=
\begin{bmatrix}
1&amp;0&amp;0&amp;0\\
0&amp;1-k&amp;k&amp;k\\
0&amp;k&amp;1-k&amp;k\\
0&amp;k&amp;k&amp;1-k
\end{bmatrix}
&lt;/math&gt;.

The diagonalized matrix is:

:&lt;math&gt;\mathbf{W'}=
\begin{bmatrix}
1-2k&amp;0&amp;0&amp;0\\
0&amp;1-2k&amp;0&amp;0\\
0&amp;0&amp;1&amp;0\\
0&amp;0&amp;0&amp;1+k
\end{bmatrix}
&lt;/math&gt;.

And the eigenvectors corresponding to these eigenvalues are:

:{| class="wikitable"
|-
![[Eigenvalue]] !! [[Eigenvector]]
|-
|1-2k || [0,-1,0,1]
|-
| 1-2k || [0,-1,1,0]
|-
| 1 || [1,0,0,0]
|-
| 1+k || [0,1,1,1]
|}

Only the eigenvalue &lt;math&gt;1+k&lt;/math&gt; is more than unity. For the n-th generation, the corresponding eigenvalue will be &lt;math&gt;(1+k)^n&lt;/math&gt; and so will increase without bound as time goes by. This eigenvalue corresponds to the eigenvector [0,1,1,1], which represents the quasispecies consisting of sequences 2, 3, and 4, which will be present in equal numbers after a very long time. Since all population numbers must be positive,  the first two quasispecies are not legitimate. The third quasispecies consists of only the non-mutating sequence 1. It's seen that even though sequence 1 is the most fit in the sense that it reproduces more of itself than any other sequence, the quasispecies consisting of the other three sequences will eventually dominate (assuming that the initial population was not homogeneous of the sequence 1 type).{{citation needed|date=August 2013}}

== References ==

{{Reflist}}

== Further reading ==
*{{cite journal |author1=Eigen M. |author2=McCaskill J. |author3=Schuster P. | year = 1989 | title = The Molecular Quasi-species | url = | journal = Advances in Chemical Physics | volume = 75 | issue = | pages = 149–263 | doi=10.1002/9780470141243.ch4}}
*{{cite journal | author = Nowak M. A. | year = 1992 | title = What is a Quasi-species? | url = | journal = Trends in Ecology and Evolution | volume = 7 | issue = | pages = 118–121 | doi=10.1016/0169-5347(92)90145-2}}
*{{cite journal |author1=Villarreal L. P. |author2=Witzany G. | year = 2013 | title = Rethinking quasispecies theory: From fittest type to cooperative consortia | journal = World Journal of Biological Chemistry | volume = 4 | issue = | pages = 79–90 | doi=10.4331/wjbc.v4.i4.79 | pmid=24340131 | pmc=3856310}}
&lt;!-- 
Based on article from [[Nupedia]] (http://www.nupedia.com/article/600/) by Claus O. Wilke, posted 2001-10-12. --&gt;

{{Clear}}
{{Origin of life}}

[[Category:Virology]]
[[Category:Evolutionary biology]]
[[Category:Microbial population biology]]
[[Category:Evolutionary dynamics]]
[[Category:Mathematical modeling]]</text>
      <sha1>nl8gpofdjymvpumb3f2f3bxlx7j5o7y</sha1>
    </revision>
  </page>
  <page>
    <title>Recursive ordinal</title>
    <ns>0</ns>
    <id>5173979</id>
    <revision>
      <id>813676873</id>
      <parentid>786594487</parentid>
      <timestamp>2017-12-04T17:56:52Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1571">In [[mathematics]], specifically [[set theory]], an [[ordinal number|ordinal]] &lt;math&gt;\alpha&lt;/math&gt; is said to be '''recursive''' if there is a [[recursive set|recursive]] [[well-order]]ing of a [[subset]] of the [[natural numbers]] having the [[order type]] &lt;math&gt;\alpha&lt;/math&gt;.

It is trivial to check that &lt;math&gt;\omega&lt;/math&gt; is recursive, the [[successor ordinal|successor]] of a recursive ordinal is recursive, and the [[Set (mathematics)|set]] of all recursive ordinals is [[closure (mathematics)|closed]] downwards.  The [[supremum]] of all recursive ordinals is called the [[Church–Kleene ordinal]] and denoted by &lt;math&gt;\omega^{CK}_1&lt;/math&gt;. Indeed, an ordinal is recursive if and only if it is smaller than &lt;math&gt;\omega^{CK}_1&lt;/math&gt;. Since there are only countably many recursive relations, there are also only [[countable|countably]] many recursive ordinals. Thus, &lt;math&gt;\omega^{CK}_1&lt;/math&gt; is countable.

The recursive ordinals are exactly the ordinals that have an [[ordinal notation]] in [[Kleene's O|Kleene's &lt;math&gt;\mathcal{O}&lt;/math&gt;]]. 

==See also==
*[[Arithmetical hierarchy]]
*[[Large countable ordinal]]
*[[Ordinal notation]]

== References ==

* Rogers, H. ''The Theory of Recursive Functions and Effective Computability'', 1967.  Reprinted 1987, MIT Press, {{isbn|0-262-68052-1}} (paperback), {{isbn|0-07-053522-1}}
* Sacks, G.  ''Higher Recursion Theory''.  Perspectives in mathematical logic, Springer-Verlag, 1990. {{isbn|0-387-19305-7}}

[[Category:Set theory]]
[[Category:Computability theory]]
[[Category:Ordinal numbers]]
{{settheory-stub}}</text>
      <sha1>mpsgnxsunxmps1o6of6hpcsfs80qzy7</sha1>
    </revision>
  </page>
  <page>
    <title>Refinement (topology)</title>
    <ns>0</ns>
    <id>8017713</id>
    <redirect title="Cover (topology)" />
    <revision>
      <id>342900130</id>
      <parentid>342900034</parentid>
      <timestamp>2010-02-09T09:19:12Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="93">#REDIRECT [[Cover (topology)#Refinement]]
[[Category:Topology]]
[[Category:General topology]]</text>
      <sha1>9bop0jmdx2ug0b03f16fuv3y9ly8cfo</sha1>
    </revision>
  </page>
  <page>
    <title>Regular part</title>
    <ns>0</ns>
    <id>5238435</id>
    <revision>
      <id>745787006</id>
      <parentid>633777269</parentid>
      <timestamp>2016-10-23T08:43:57Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="731">In [[mathematics]], the '''regular part''' of a [[Laurent series]] consists of the series of terms with positive powers.&lt;ref name="caa"&gt;{{citation|title=Complex Analysis and Applications|first=Alan|last=Jeffrey|edition=2nd|publisher=CRC Press|year=2005|isbn=9781584885535|page=256|url=https://books.google.com/books?id=O039eVfuV04C&amp;pg=PA256}}.&lt;/ref&gt; That is, if
:&lt;math&gt;f(z) = \sum_{n=-\infty}^{\infty} a_n (z - c)^n,&lt;/math&gt;
then the regular part of this Laurent series is
:&lt;math&gt;\sum_{n=0}^{\infty} a_n (z - c)^n.&lt;/math&gt;

In contrast, the series of terms with negative powers is the [[principal part]].&lt;ref name="caa"/&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Regular Part}}
[[Category:Complex analysis]]


{{mathanalysis-stub}}</text>
      <sha1>41ltrp6wyrs0to9lqxtqxd3kpll7hk7</sha1>
    </revision>
  </page>
  <page>
    <title>Schröder's equation</title>
    <ns>0</ns>
    <id>5834541</id>
    <revision>
      <id>848628830</id>
      <parentid>846320886</parentid>
      <timestamp>2018-07-03T06:06:59Z</timestamp>
      <contributor>
        <ip>71.166.54.122</ip>
      </contributor>
      <comment>Ambiguity between the equation being named after him and him formulating the equation.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11352">[[Image:Ernst schroeder.jpg|thumb|[[Ernst Schröder]] (1841&amp;ndash;1902) in 1870 formulated his namesake equation.]]
{{distinguish|Schrödinger's equation}}
'''Schröder's equation''',&lt;ref name="schr"&gt;{{cite journal |last=Schröder |first=Ernst |authorlink=Ernst Schröder |year=1870 |title=Ueber iterirte Functionen|journal=Math. Ann. |volume=3 |issue= 2|pages=296–322 | doi=10.1007/BF01443992 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Complex Dynamics |last=Carleson |first=Lennart|authorlink=Lennart Carleson |last2=Gamelin |first2=Theodore W. |series=Textbook series: Universitext: Tracts in Mathematics |year=1993 |publisher=Springer-Verlag |location=New York |isbn=0-387-97942-5 |page=}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Functional equations in a single variable |last=Kuczma |first=Marek|authorlink=Marek Kuczma|series=Monografie Matematyczne |year=1968 |publisher=PWN – Polish Scientific Publishers |location=Warszawa}}  ASIN: B0006BTAC2&lt;/ref&gt; named after [[Ernst Schröder]], is a [[functional equation]] with one [[independent variable]]:  given the function {{math|''h''(''x'')}}, find the function {{math|Ψ(''x'')}} such that:
{{Equation box 1
|indent =::
|equation =  &lt;math&gt;\Psi (h(x)) = s\Psi(x)~.&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
Schröder's equation is an eigenvalue equation for the [[composition operator]] {{math|''C''&lt;sub&gt;''h''&lt;/sub&gt;}}, which sends a function {{math|''f''(''x'')}} to {{math|''f''(''h''(''x''))}}.

If {{mvar|a}} is a [[fixed point iteration|fixed point]]  of {{math|''h''}}, meaning {{math|''h''(''a'') {{=}} ''a''}}, then either {{math|Ψ(''a'') {{=}} 0}}   (or {{mvar|∞}}) or {{math|''s'' {{=}} 1}}. Thus, provided
{{math|Ψ(''a'')}} is finite and {{math|Ψ&amp;prime;(''a'')}} does not vanish or diverge, the [[eigenvalue]] {{mvar|''s''}} is given by {{math|''s'' {{=}} ''h''&amp;prime;(''a'')}}.

==Functional significance==
For {{math| ''a'' {{=}} 0}}, if {{mvar|''h''}} is analytic on the unit disk, fixes {{math|0}}, and {{math|0 &lt; {{!}}''h''&amp;prime;(0){{!}} &lt; 1}}, then [[Gabriel Koenigs]] showed in 1884 that there is an analytic (non-trivial) {{math|Ψ}} satisfying Schröder's equation. This is one of the first steps in a long line of theorems fruitful for understanding composition operators on analytic function spaces,  cf. [[Koenigs function]].

Equations such as Schröder's are suitable to encoding [[self-similarity]], and have thus been extensively utilized in studies of [[nonlinear dynamics]] (often referred to colloquially as [[chaos theory]]). It is also used in studies of [[turbulence]], as well as the [[renormalization group]].&lt;ref&gt;{{cite journal |last=Gell-Mann |first=M. |authorlink=Murray Gell-Mann |author2=Low, F.E. |authorlink2=Francis E. Low  |year=1954 |title=Quantum Electrodynamics at Small Distances | journal=Physical Review |volume=95|issue=5|pages=1300–1312 | doi=10.1103/PhysRev.95.1300| bibcode=1954PhRv...95.1300G}}&lt;/ref&gt;&lt;ref name="renorm"&gt;{{cite journal |last=Curtright |first=T.L. |authorlink=Thomas Curtright |author2=Zachos, C.K.  |date=March 2011 |title=Renormalization Group Functional Equations | journal=Physical Review D|volume=83|issue= 6|pages=065019| doi=10.1103/PhysRevD.83.065019 |bibcode=2011PhRvD..83f5019C|arxiv = 1010.5174 }}&lt;/ref&gt;

An equivalent  transpose form of Schröder's equation for the inverse {{math|Φ {{=}} Ψ&lt;sup&gt;−1&lt;/sup&gt;}} of Schröder's conjugacy function is {{math|''h''(Φ(''y'')) {{=}} Φ(''sy'')}}. The change of variables {{math|α(''x'') {{=}} log(Ψ(''x''))/log(''s'')}} (the [[Abel function]]) further converts Schröder's equation to the older [[Abel equation]], {{math|α(''h''(''x'')) {{=}} α(''x'') + 1}}. Similarly, the change of variables {{math|Ψ(''x'') {{=}} log(φ(''x''))}} converts Schröder's equation to [[Böttcher's equation]], {{math|φ(''h''(''x'')) {{=}} (φ(''x''))&lt;sup&gt;''s''&lt;/sup&gt;}}.   

Moreover, for the velocity,&lt;ref name="renorm"/&gt; {{math|β(''x'') {{=}} Ψ/Ψ&amp;prime;}}, &amp;nbsp;  ''[[Gaston Julia|Julia]]'s equation'',  &amp;nbsp;  {{math|β(''f''(''x'')) {{=}} ''f''&amp;prime;(''x'')β(''x'')}}, holds.  

The {{math|''n''}}-th power of a solution of Schröder's equation provides a solution of Schröder's equation with eigenvalue {{math|''s''&lt;sup&gt;''n''&lt;/sup&gt;}}, instead. In the same vein, for an invertible solution {{math|Ψ(''x'')}} of Schröder's equation, the (non-invertible) function {{math|Ψ(''x'') ''k''(log Ψ(''x''))}} is also a solution, for ''any'' periodic function {{math| ''k''(''x'')}} with period {{math|log(''s'')}}. All solutions of Schröder's equation are related in this manner.

==Solutions==
Schröder's equation was solved analytically if {{mvar|a}} is an attracting (but not superattracting)
fixed point, that is {{math|0 &lt; {{!}}''h''&amp;prime;(''a''){{!}} &lt; 1}} by [[Gabriel Xavier Paul Koenigs|Gabriel Koenigs]] (1884).&lt;ref&gt;{{cite journal |last=Koenigs |first=G. |authorlink=Gabriel Xavier Paul Koenigs |year=1884 |title=Recherches sur les intégrales de certaines équations fonctionelles |journal=Annales Scientifiques de l'École Normale Supérieure |volume=1 |issue=3, Supplément |pages=3–41 |url=http://www.numdam.org/article/ASENS_1884_3_1__S3_0.pdf|doi=10.24033/asens.247}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Erdős |first=P. |authorlink=Paul Erdős |author2=Jabotinsky, E.  | year=1960|title=On Analytic Iteration |journal=Journal d'Analyse Mathématique |volume=8|issue=1 |pages=361–376 |doi=10.1007/BF02786856}}&lt;/ref&gt;

In the case of a superattracting fixed point, {{math|{{!}}''h''&amp;prime;(''a''){{!}} {{=}} 0}}, Schröder's equation is unwieldy, and had best be transformed to [[Böttcher's equation]].&lt;ref&gt;{{cite journal |last=Böttcher |first=L. E. |authorlink=Lucjan Böttcher|year=1904 |title=The principal laws of convergence of iterates and their application to analysis|journal=Izv. Kazan. Fiz.-Mat. Obshch. (Russian) |volume=14 |issue= |pages=155–234}}&lt;/ref&gt;

There are a good number of particular solutions dating back to Schröder's original 1870 paper.&lt;ref name="schr"/&gt;

The series expansion around a fixed point and the relevant convergence properties of the solution for the resulting orbit and its analyticity properties are cogently summarized by [[George Szekeres|Szekeres]].&lt;ref&gt;{{cite journal |last=Szekeres |first=G. |authorlink=George Szekeres | year=1958|title=Regular iteration of real and complex functions |journal=Acta Mathematica |volume=100|issue=3–4 |pages=361–376 |doi=10.1007/BF02559539 }} [http://eretrandre.org/rb/files/Szekeres1958_142.pdf]&lt;/ref&gt; Several of the solutions are furnished in terms of [[asymptotic series]], cf. [[Carleman matrix]].

==Applications==
[[Image:Phase-space Orbit of-Logistic map.jpg|right|thumb|300px| First five half periods of the phase-space orbit of the&lt;span style="color:red"&gt; ''s''=4 chaotic logistic map {{math|''h''(''x'')}}&lt;/span&gt;, interpolated holographically through Schröder's equation. The velocity &lt;span style="color:green"&gt;{{math|''v''{{=}}d''h''&lt;sub&gt;''t''&lt;/sub&gt;/d''t''}} plotted against {{math|''h''&lt;sub&gt;''t''&lt;/sub&gt;&lt;/span&gt;}}. Chaos is evident in the orbit sweeping all {{mvar|x}}s at all times.]]
{{See also|Rational difference equation}}

It is used to analyse discrete dynamical systems by finding a new coordinate system in which the system (orbit) generated by ''h''(''x'') looks simpler, a mere dilation.

More specifically, a system for which a discrete unit time step amounts to {{math|''x'' → ''h''(''x'')}}, can have its smooth [[Orbit (dynamics)|orbit]] (or [[Flow (mathematics)|flow]]) reconstructed from the solution of the above Schröder's equation, its [[Topological conjugacy|conjugacy
 equation]].

That is,  &amp;nbsp;  {{math| ''h''(''x'') {{=}} Ψ&lt;sup&gt;−1&lt;/sup&gt;(''s'' Ψ(''x'')) ≡ ''h''&lt;sub&gt;1&lt;/sub&gt;(''x'')}}.

In general, '''''all of its functional iterates''''' (its ''regular iteration [[One-parameter group|group]]'', cf. [[iterated function]]) are provided by the '''orbit'''
{{Equation box 1
|indent =::
|equation =  &lt;math&gt;h_t(x) = \Psi^{-1} ( s^t \Psi (x))~,&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|background colour=#F9FFF7}}
for {{mvar|t}} real — not necessarily positive or integer. (Thus a full [[continuous group]].)
The set of {{math|''h''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')}}, i.e., of all positive integer iterates of {{math|''h''(''x'')}} ([[semigroup]]) is called the ''splinter'' (or Picard sequence) of {{math|''h''(''x'')}}.

However, '''''all iterates''''' (fractional, infinitesimal, or negative) of {{math|''h''(''x'')}} are likewise specified through the coordinate transformation {{math|''Ψ''(''x'')}} determined to solve Schröder's equation: a holographic continuous interpolation of the initial discrete recursion {{math|''x'' → ''h''(''x'')}} has been constructed;&lt;ref name="tlc"&gt;{{cite journal |last=Curtright |first=T.L. |authorlink=Thomas Curtright|author2=Zachos, C.K. |authorlink2=Cosmas Zachos | year=2009|title=Evolution Profiles and Functional Equations |journal=Journal of Physics A |volume=42|issue=48 |pages=485208|doi=10.1088/1751-8113/42/48/485208|arxiv = 0909.2424 |bibcode = 2009JPhA...42V5208C }}&lt;/ref&gt; in effect, the entire [[orbit (dynamics)|orbit]].

For instance, the [[functional square root]] is  {{math|''h''&lt;sub&gt;½&lt;/sub&gt;(''x'') {{=}} Ψ&lt;sup&gt;−1&lt;/sup&gt; (''s''&lt;sup&gt;½&lt;/sup&gt;  Ψ(''x'') )}}, so that {{math|''h''&lt;sub&gt;½&lt;/sub&gt;( ''h''&lt;sub&gt;½&lt;/sub&gt;(''x'') ) {{=}} ''h'' (''x'')}}, and so on.

For example,&lt;ref&gt;Curtright, T.L. [http://www.physics.miami.edu/~curtright/Schroeder.html Evolution surfaces and Schröder functional methods.]&lt;/ref&gt; special cases of the [[logistic map]] such as the chaotic case {{math|''h''(''x''){{=}}4''x''(1−''x'')}} were already worked out by Schröder in his original paper&lt;ref name="schr" /&gt; (cf. p.&amp;nbsp;306), 
:{{math|Ψ(''x'') {{=}} (arcsin {{radic|''x''}})&lt;sup&gt;2&lt;/sup&gt;}}, {{math|''s'' {{=}} 4}}, and hence {{math|''h''&lt;sub&gt;''t''&lt;/sub&gt;(''x'') {{=}} sin&lt;sup&gt;2&lt;/sup&gt;(2&lt;sup&gt;''t''&lt;/sup&gt; arcsin {{radic|''x''}})}}.

In fact, this solution is seen to result as motion dictated by a sequence of switchback potentials,&lt;ref&gt;{{cite journal |last=Curtright|first=T.L. |authorlink=Thomas Curtright|author2=Zachos, C.K. | year=2010|title=Chaotic Maps, Hamiltonian Flows, and Holographic Methods |journal=Journal of Physics A |volume=43|issue=44 |pages=445101|doi=10.1088/1751-8113/43/44/445101|arxiv = 1002.0104 |bibcode = 2010JPhA...43R5101C }}&lt;/ref&gt; {{math|''V''(''x'') ∝ ''x''(''x''−1) (''nπ''+arcsin {{radic|''x''}})&lt;sup&gt;2&lt;/sup&gt;}}, a generic feature of continuous iterates effected by Schröder's equation.

A nonchaotic case he also illustrated with his method,  {{math|''h''(''x'') {{=}} 2''x''(1−''x'')}}, yields  
:{{math|Ψ(''x'') {{=}} −½ln(1−2''x'')}}, and hence  {{math|''h''&lt;sub&gt;t&lt;/sub&gt;(''x'') {{=}} −½((1−2''x'')&lt;sup&gt;2&lt;sup&gt;t&lt;/sup&gt;&lt;/sup&gt;−1)}}.


Likewise, for the [[Beverton–Holt model]],  {{math|''h''(''x''){{=}}''x''/(2−''x'')}}, one readily finds&lt;ref name="tlc" /&gt;  {{math|Ψ(''x'') {{=}}  ''x''/(1−''x'')}}, so that&lt;ref&gt;Skellam,  J.G. (1951).  “Random dispersal in theoretical populations”, ''Biometrika'' '''38''' 196−218, eqns (41,42)&lt;/ref&gt;
:&lt;math&gt;h_t(x)= \Psi^{-1} (2^{-t} \Psi (x))= \frac{x}{2^t + x(1-2^t)}   ~.&lt;/math&gt;

== See also ==

* [[Böttcher's equation]]

==References==
&lt;references /&gt;

{{DEFAULTSORT:Schroder's equation}}
[[Category:Functional equations]]
[[Category:Mathematical physics]]</text>
      <sha1>gftwr0aiu9fjdyw794qqjr82nut5xpv</sha1>
    </revision>
  </page>
  <page>
    <title>Septic equation</title>
    <ns>0</ns>
    <id>25451646</id>
    <revision>
      <id>801791567</id>
      <parentid>801791008</parentid>
      <timestamp>2017-09-21T21:50:55Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* Solvable septics */ wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7024">{{Other uses|Septic (disambiguation){{!}}Septic}}
[[Image:Septic graph.svg|thumb|right|233px|Graph of a polynomial of degree 7, with 7 [[real number|real]] [[root of a polynomial|roots]] (crossings of the {{math|''x''}} axis) and 6 [[critical point (mathematics)|critical points]]. Depending on the number and vertical location of the [[minimum|minima and maxima]], the septic could have 7, 5, 3, or 1 real root; the number of [[complex number|complex]] roots is 7 minus the number of real roots.  ]]

In [[algebra]], a '''septic equation''' is an [[equation]] of the form

:&lt;math&gt;ax^7+bx^6+cx^5+dx^4+ex^3+fx^2+gx+h=0,\,&lt;/math&gt;

where {{math|''a'' ≠ 0}}.

A '''septic function''' is a [[Function (mathematics)|function]] of the form

:&lt;math&gt;f(x)=ax^7+bx^6+cx^5+dx^4+ex^3+fx^2+gx+h\,&lt;/math&gt;

where {{math|''a'' ≠ 0}}. In other words, it is a [[polynomial]] of [[Degree of a polynomial|degree]] seven. If {{math|1=''a'' = 0}}, then ''f'' is a [[sextic function]] ({{math|''b'' ≠ 0}}), [[quintic function]] ({{math|1=''b'' = 0, ''c'' ≠ 0}}), etc.

The equation may be obtained from the function by setting {{math|1=''f''(''x'') = 0}}.

The ''coefficients'' {{math|''a'', ''b'', ''c'', ''d'', ''e'', ''f'', ''g'', ''h''}} may be either [[integers]], [[rational number]]s, [[real number]]s, [[complex number]]s or, more generally, members of any [[field (mathematics)|field]].

Because they have an odd degree, '''septic functions''' appear similar to [[quintic function|quintic]] or [[cubic function]] when graphed, except they may possess additional [[Maxima and minima|local maxima]] and local minima (up to three maxima and three minima). The [[derivative]] of a septic function is a [[sextic function]].

==Solvable septics==
Some seventh degree equations can be solved by factorizing into [[radical expression|radicals]], but other septics cannot. [[Évariste Galois]] developed techniques for determining whether a given equation could be solved by radicals which gave rise to the field of [[Galois theory]].  To give an example of an irreducible but solvable septic, one can generalize the solvable [[de Moivre]] [[quintic]] to get,
:&lt;math&gt;x^7+7\alpha x^5+14\alpha^2x^3+7\alpha^3x+\beta = 0\,&lt;/math&gt;,

where the auxiliary equation is 
:&lt;math&gt;y^2+\beta y-\alpha^7 = 0\,&lt;/math&gt;.

This means that the septic is obtained by eliminating {{math|''u''}} and {{math|''v''}} between {{math|1=''x'' = ''u'' + ''v''}},  {{math|1=''uv'' + ''α'' = 0}} and {{math|1=''u''&lt;sup&gt;7&lt;/sup&gt; + ''v''&lt;sup&gt;7&lt;/sup&gt; + ''β'' = 0}}.

It follows that the septic's seven roots are given by

:&lt;math&gt;x_k = \omega_k\sqrt[7]{y_1} + \omega_k^6\sqrt[7]{y_2}&lt;/math&gt;

where {{math|''ω&lt;sub&gt;k&lt;/sub&gt;''}} is any of the 7 seventh [[root of unity|roots of unity]]. The [[Galois group]] of this septic is the maximal solvable group of order 42. This is easily generalized to any other degrees {{math|''k''}}, not necessarily prime.

Another solvable family is,

:&lt;math&gt;x^7-2x^6+(\alpha+1)x^5+(\alpha-1)x^4-\alpha x^3-(\alpha+5)x^2-6x-4 = 0\,&lt;/math&gt;

whose members appear in Kluner's ''Database of Number Fields''.  Its [[discriminant]] is

:&lt;math&gt;\Delta = -4^4\left(4\alpha^3+99\alpha^2-34\alpha+467\right)^3\,&lt;/math&gt;

The [[Galois group]] of these septics is the [[dihedral group]] of order 14.

The general septic equation can be solved with the [[alternating group|alternating]] or [[symmetric group|symmetric]] [[Galois group]]s {{math|''A''&lt;sub&gt;7&lt;/sub&gt;}} or {{math|''S''&lt;sub&gt;7&lt;/sub&gt;}}.&lt;ref name="BeyondQuartic"/&gt; Such equations require [[hyperelliptic function]]s and associated [[theta function]]s of [[genus (mathematics)|genus]] 3 for their solution.&lt;ref name="BeyondQuartic"/&gt; However, these equations were not studied specifically by the nineteenth-century mathematicians studying the solutions of algebraic equations, because the [[sextic equation]]s' solutions were already at the limits of their computational abilities without computers.&lt;ref name="BeyondQuartic"&gt;{{citation|url=https://books.google.com/books?id=9cKX_9zkeg4C&amp;pg=PA143&amp;lpg=PA143&amp;dq=septic+equation&amp;source=bl&amp;ots=nld9eMx3DE&amp;sig=wZ9V5zL0vNqsJvCguye-NCzqhq0&amp;hl=en&amp;ei=aF4oS570JdGHkQWd-936DA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=7&amp;ved=0CDMQ6AEwBg#v=onepage&amp;q=septic%20equation&amp;f=false |author=R. Bruce King |title=Beyond the Quartic Equation |publisher= Birkhaüser|page=  143 and 144}}&lt;/ref&gt;

Septics are the lowest order equations for which it is not obvious that their solutions may be obtained by superimposing ''continuous functions'' of two variables.  [[Hilbert's thirteenth problem|Hilbert's 13th problem]] was the conjecture this was not possible in the general case for seventh-degree equations. [[Vladimir Arnold]] solved this in 1957, demonstrating that this was always possible.&lt;ref&gt;{{citation |url=https://books.google.com/books?id=SpTv44Ia-J0C&amp;pg=PA254 |title=Kolmogorov's heritage in mathematics |author=Vasco Brattka |chapter=Kolmogorov's Superposition Theorem|publisher=Springer}}&lt;/ref&gt;  However, Arnold himself considered the ''genuine'' Hilbert problem to be whether for septics their solutions may be obtained by superimposing ''algebraic functions'' of two variables (the problem still being open).&lt;ref&gt;{{citation |url=http://www.pdmi.ras.ru/~arnsem/Arnold/arnlect1.ps.gz |title=From Hilbert's Superposition Problem to Dynamical Systems |author=V.I. Arnold |page=4}}&lt;/ref&gt;

==Galois groups==
[[Image:Fano plane.svg|thumb|[[Fano plane]]]]
*Septic equations solvable by radicals have a [[Galois group]] which is either the [[cyclic group]] of order 7, or the [[dihedral group]] of order 14 or a [[metacyclic group]] of order 21 or 42.&lt;ref name="BeyondQuartic"/&gt;
*The {{math|''L''(3, 2)}} [[Galois group]] (of order 168) is formed by the [[permutations]] of the 7 vertex labels which preserve the 7 "lines" in the [[Fano plane]].&lt;ref name="BeyondQuartic"/&gt; Septic equations with this [[Galois group]] {{math|''L''(3, 2)}} require [[elliptic function]]s but not [[hyperelliptic function]]s for their solution.&lt;ref name="BeyondQuartic"/&gt;
*Otherwise the Galois group of a septic is either the [[alternating group]] of order 2520 or the [[symmetric group]] of order 5040.

==Septic equation for the squared area of a cyclic pentagon or hexagon==

The square of the area of a [[Pentagon#Cyclic pentagons|cyclic pentagon]] is a root of a septic equation whose coefficients are [[symmetric function]]s of the sides of the pentagon.&lt;ref&gt;Weisstein, Eric W. "Cyclic Pentagon." From MathWorld--A Wolfram Web Resource. [http://mathworld.wolfram.com/CyclicPentagon.html]&lt;/ref&gt; The same is true of the square of the area of a [[Hexagon#Cyclic hexagon|cyclic hexagon]].&lt;ref&gt;Weisstein, Eric W. "Cyclic Hexagon." From MathWorld--A Wolfram Web Resource. [http://mathworld.wolfram.com/CyclicHexagon.html]&lt;/ref&gt;

==See also==
*[[Cubic function]]
*[[Quartic function]]
*[[Quintic function]]
*[[Sextic equation]]
*[[Labs septic]]

==References==
&lt;references/&gt;

{{Polynomials}}

{{DEFAULTSORT:Septic Equation}}
[[Category:Equations]]
[[Category:Galois theory]]
[[Category:Polynomials]]</text>
      <sha1>5b8hyh7emqx4rgsny3xr9zsylqlmmt8</sha1>
    </revision>
  </page>
  <page>
    <title>Short integer solution problem</title>
    <ns>0</ns>
    <id>50448848</id>
    <revision>
      <id>864809959</id>
      <parentid>864808514</parentid>
      <timestamp>2018-10-19T16:22:40Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* SISn,m,q,&amp;beta; */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14638">'''Short integer solution (SIS)''' and '''ring-SIS''' problems are two ''average''-case problems that are used in [[lattice-based cryptography]] constructions. Lattice-based cryptography began in 1996 from a seminal work by Ajtai &lt;ref name="Ajtai, Miklós 1996"&gt;Ajtai, Miklós. [Generating hard instances of lattice problems.] Proceedings of the twenty-eighth annual ACM symposium on Theory of computing. ACM, 1996.&lt;/ref&gt; who presented a family of one-way functions based on SIS problem. He showed that it is secure in an average case if [[Shortest vector problem|&lt;math&gt;\mathrm{SVP}_\gamma&lt;/math&gt;]] (where &lt;math&gt;\gamma = n^c&lt;/math&gt; for some constant &lt;math&gt;c&gt;0&lt;/math&gt;) is hard in a worst-case scenario.

Average case problems are the problems that are hard to be solved for some randomly selected instances. For cryptography applications, worse case complexity is not sufficient, and we need to guarantee cryptographic construction are hard based on average case complexity.

==Lattices==
A ''full rank [[Lattice (group)|lattice]]'' &lt;math&gt; \mathfrak{L} \subset \R^n &lt;/math&gt; is a set of integer linear combinations of &lt;math&gt; n &lt;/math&gt; linearly independent vectors &lt;math&gt; \{b_1,\ldots,b_n\} &lt;/math&gt;, named ''basis'':

: &lt;math&gt;
    \mathfrak{L}(b_1,\ldots,b_n) = \left\{ \sum_{i=1}^n z_i b_i: z_i \in \Z \right\} = \{ B\boldsymbol{z}: \boldsymbol{z} \in \Z^n \}
&lt;/math&gt;

where &lt;math&gt; B \in \R ^{n\times n} &lt;/math&gt; is a matrix having basis vectors in its columns.

'''Remark:''' Given &lt;math&gt; B_1,B_2 &lt;/math&gt; two bases for lattice &lt;math&gt; \mathfrak{L} &lt;/math&gt;, there exist unimodular matrices &lt;math&gt; U_1 &lt;/math&gt; such that &lt;math&gt; B_1 = B_2U_1^{-1}, B_2 = B_1U_1 &lt;/math&gt;.

==Ideal lattice==
'''Definition:''' Rotational shift operator on &lt;math&gt; \R^n (n \geq 2) &lt;/math&gt; is denoted by &lt;math&gt; \operatorname{rot} &lt;/math&gt;, and is defined as:

: &lt;math&gt;
    \forall \boldsymbol{x} = (x_1,\ldots,x_{n-1},x_n) \in \R^n: \operatorname{rot}(x_1,\ldots,x_{n-1},x_n) = (x_n,x_1,\ldots,x_{n-1})
&lt;/math&gt;

===Cyclic lattices===
Micciancio introduced ''cyclic lattices'' in his work in generalizing the compact [[Knapsack_problem|knapsack problem]] to arbitrary rings.&lt;ref name="micciancio2002generalized"&gt;Micciancio, Daniele. [Generalized compact knapsacks, cyclic lattices, and efficient one-way functions from worst-case complexity assumptions.] Foundations of Computer Science, 2002. Proceedings. The 43rd Annual IEEE Symposium on. IEEE, 2002.&lt;/ref&gt; A cyclic lattice is a lattice that is closed under rotational shift operator. Formally, cyclic lattices are defined as follows:

'''Definition:''' A lattice &lt;math&gt; \mathfrak{L} \in \Z^n &lt;/math&gt; is cyclic if &lt;math&gt; \forall \boldsymbol{x} \in \mathfrak{L}: \operatorname{rot}(\boldsymbol{x}) \in \mathfrak{L} &lt;/math&gt;.

'''Examples:''' &lt;ref&gt;Fukshansky, Lenny, and Xun Sun. [On the geometry of cyclic lattices.] Discrete &amp; Computational Geometry 52.2 (2014): 240-259.&lt;/ref&gt;
# &lt;math&gt; \Z^n &lt;/math&gt; itself is a cyclic lattice.
# Lattices corresponding to any ideal in the quotient polynomial ring &lt;math&gt; R = \Z[x]/(x^n-1) &lt;/math&gt; are cyclic: 
consider the quotient polynomial ring &lt;math&gt; R = \Z[x]/(x^n-1) &lt;/math&gt;, and let &lt;math&gt; p(x) &lt;/math&gt; be some polynomial in &lt;math&gt; R &lt;/math&gt;, i.e. &lt;math&gt; p(x) = \sum_{i=0}^{n-1}a_ix^i &lt;/math&gt; where &lt;math&gt; a_i \in \Z &lt;/math&gt; for &lt;math&gt; i = 0,\ldots, n-1 &lt;/math&gt;.

Define the embedding coefficient &lt;math&gt; \Z &lt;/math&gt;-module isomorphism &lt;math&gt; \rho &lt;/math&gt; as:

: &lt;math&gt;
    \begin{align}
        \quad \rho: R &amp; \rightarrow \Z^n \\[4pt]
         p(x) = \sum_{i=0}^{n-1}a_ix^i &amp; \mapsto (a_0,\ldots,a_{n-1})
    \end{align}
&lt;/math&gt;

Let &lt;math&gt; I \subset R &lt;/math&gt; be an ideal. The lattice corresponding to ideal &lt;math&gt; I \subset R &lt;/math&gt;, denoted by &lt;math&gt; \mathfrak{L}_I &lt;/math&gt;, is a sublattice of &lt;math&gt; \Z^n &lt;/math&gt;, and is defined as

: &lt;math&gt; \mathfrak{L}_I := \rho(I) = \left\{ (a_0,\ldots,a_{n-1}) \mid \sum_{i=0}^{n-1}a_ix^i \in I \right\} \subset \Z^n. &lt;/math&gt;

'''Theorem:''' &lt;math&gt; \mathfrak{L} \subset \Z^n &lt;/math&gt; is cyclic if and only if &lt;math&gt; \mathfrak{L} &lt;/math&gt; corresponds to some ideal &lt;math&gt; I &lt;/math&gt; in the quotient polynomial ring &lt;math&gt; R = \Z[x]/(x^n-1) &lt;/math&gt;.

'''proof:'''
&lt;math&gt; \Leftarrow)&lt;/math&gt; We have:
: &lt;math&gt;
    \mathfrak{L} = \mathfrak{L}_I := \rho(I) = \left\{ (a_0,\ldots,a_{n-1}) \mid \sum_{i=0}^{n-1}a_ix^i \in I\right\}
&lt;/math&gt;

Let &lt;math&gt; (a_0,\ldots,a_{n-1}) &lt;/math&gt; be an arbitrary element in &lt;math&gt; \mathfrak{L} &lt;/math&gt;. Then, define &lt;math&gt; p(x) = \sum_{i=0}^{n-1}a_ix^i \in I &lt;/math&gt;. But since &lt;math&gt; I &lt;/math&gt; is an ideal, we have &lt;math&gt; xp(x) \in I &lt;/math&gt;. Then, &lt;math&gt; \rho(xp(x)) \in \mathfrak{L}_I &lt;/math&gt;. But, &lt;math&gt; \rho(xp(x)) = \operatorname{rot}(a_0,\ldots,a_{n-1}) \in \mathfrak{L}_I &lt;/math&gt;. Hence, &lt;math&gt; \mathfrak{L} &lt;/math&gt; is cyclic.

&lt;math&gt; \Rightarrow)&lt;/math&gt;

Let &lt;math&gt; \mathfrak{L} \subset \Z^n &lt;/math&gt; be a cyclic lattice. Hence &lt;math&gt; \forall (a_0,\ldots,a_{n-1}) \in \mathfrak{L}: \operatorname{rot}(a_0,\ldots,a_{n-1}) \in \mathfrak{L} &lt;/math&gt;.

Define the set of polynomials &lt;math&gt; I: = \left\{ \sum_{i=0}^{n-1}a_ix^i \mid (a_0,\ldots,a_{n-1}) \in \mathfrak{L} \right\} &lt;/math&gt;:

# Since &lt;math&gt; \mathfrak{L} &lt;/math&gt; a lattice and hence an additive subgroup of &lt;math&gt; \Z^n &lt;/math&gt;, &lt;math&gt; I \subset R &lt;/math&gt; is an additive subgroup of &lt;math&gt; R &lt;/math&gt;.
# Since &lt;math&gt; \mathfrak{L} &lt;/math&gt; is cyclic, &lt;math&gt; \forall p(x) \in I: xp(x) \in I &lt;/math&gt;.

Hence, &lt;math&gt; I \subset R &lt;/math&gt; is an ideal, and consequently, &lt;math&gt; \mathfrak{L} = \mathfrak{L}_I &lt;/math&gt;.

===Ideal lattices &lt;ref&gt;Craig Gentry. [http://portal.acm.org/citation.cfm?id=1536414.1536440 Fully Homomorphic Encryption Using Ideal Lattices]. In ''the 41st ACM Symposium on Theory of Computing (STOC)'', 2009.&lt;/ref&gt;&lt;ref&gt;http://web.cse.ohio-state.edu/~lai/5359-aut13/05.Gentry-FHE-concrete-scheme.pdf&lt;/ref&gt; ===
Let &lt;math&gt; f(x) \in \Z[x] &lt;/math&gt; be a monic polynomial of degree &lt;math&gt; n &lt;/math&gt;. For cryptographic applications, &lt;math&gt; f(x) &lt;/math&gt; is usually selected to be irreducible. The ideal generated by &lt;math&gt; f(x) &lt;/math&gt; is:

: &lt;math&gt;
    (f(x)) := f(x) \cdot\Z[x] = \{ f(x)g(x): \forall g(x) \in \Z[x] \}.
&lt;/math&gt;

The quotient polynomial ring &lt;math&gt;R = \Z[x]/(f(x))&lt;/math&gt; partitions &lt;math&gt;\Z[x]&lt;/math&gt; into equivalence classes of polynomials of degree at most &lt;math&gt;n-1&lt;/math&gt;:

: &lt;math&gt;
    R = \Z[x]/(f(x)) = \left\{ \sum_{i=0}^{n-1}a_ix^i: a_i \in \Z \right\}
&lt;/math&gt;
where addition and multiplication are reduced modulo &lt;math&gt;f(x)&lt;/math&gt;.

Consider the embedding coefficient &lt;math&gt;\Z&lt;/math&gt;-module isomorphism &lt;math&gt;\rho&lt;/math&gt;. Then, each ideal in &lt;math&gt;R&lt;/math&gt; defines a sublattice of &lt;math&gt;\Z^n&lt;/math&gt; called [[Ideal lattice cryptography|ideal lattice]].

'''Definition:''' &lt;math&gt;\mathfrak{L}_I&lt;/math&gt;, the lattice corresponding to an ideal &lt;math&gt;I&lt;/math&gt;, is called ideal lattice. More precisely, consider a quotient polynomial ring &lt;math&gt;R = \Z[x]/(p(x))&lt;/math&gt;, where &lt;math&gt;(p(x))&lt;/math&gt; is the ideal generated by a degree &lt;math&gt;n&lt;/math&gt; polynomial &lt;math&gt;p(x) \in \Z[x]&lt;/math&gt;.  &lt;math&gt;\mathfrak{L}_I&lt;/math&gt;, is a sublattice of &lt;math&gt;\Z^n&lt;/math&gt;, and is defined as:

: &lt;math&gt;
    \mathfrak{L}_I := \rho(I) = \left\{ (a_0,\ldots,a_{n-1}) \mid \sum_{i=0}^{n-1}a_i x^i \in I \right\} \subset \Z^n.
&lt;/math&gt;

'''Remark:&lt;ref&gt;Peikert, Chris. [A decade of lattice cryptography.] Cryptology ePrint Archive, Report 2015/939, 2015.&lt;/ref&gt;'''
# It turns out that [[Lattice problem|&lt;math&gt;\text{GapSVP}_\gamma&lt;/math&gt;]] for even small &lt;math&gt;\gamma = \operatorname{poly(n)}&lt;/math&gt; is typically easy on ideal lattices. The intuition is that the algebraic symmetries results the minimum distance of an ideal to lie within a narrow, easily computable range. 
# By exploiting the provided algebraic symmetries in ideal lattices, one can convert a short nonzero vector into &lt;math&gt;n&lt;/math&gt; linearly independent ones of (nearly) the same length. Therefore, on ideal lattices, [[Shortest vector problem|&lt;math&gt;\mathrm{SVP}_\gamma&lt;/math&gt;]] and [[Lattice problem|&lt;math&gt;SIVP_{\gamma}&lt;/math&gt;]] are equivalent with a small loss.&lt;ref&gt;Peikert, Chris, and Alon Rosen. [Efficient collision-resistant hashing from worst-case assumptions on cyclic lattices.] Theory of Cryptography. Springer Berlin Heidelberg, 2006. 145–166.&lt;/ref&gt; Furthermore, even for quantum algorithms, [[Shortest vector problem|&lt;math&gt;\mathrm{SVP}_\gamma&lt;/math&gt;]] and [[Lattice problem|&lt;math&gt;SIVP_{\gamma}&lt;/math&gt;]] are very hard in the worst-case scenario.

==Short integer solution problem==
SIS and Ring-SIS are two ''average'' case problems that are used in lattice-based cryptography constructions. Lattice-based cryptography began in 1996 from a seminal work by Ajtai &lt;ref name="Ajtai, Miklós 1996"/&gt; who presented a family of one-way functions based on SIS problem. He showed that it is secure in an average case if &lt;math&gt;SVP_{\gamma}&lt;/math&gt; (where &lt;math&gt;\gamma = n^c&lt;/math&gt; for some constant &lt;math&gt;c&gt;0&lt;/math&gt;) is hard in a worst-case scenario.

===SIS&lt;sub&gt;''n'',''m'',''q'',''&amp;beta;''&lt;/sub&gt;===
Let &lt;math&gt;A \in \Z^{n\times m}_q&lt;/math&gt; be an &lt;math&gt;n\times m&lt;/math&gt; matrix with entries in &lt;math&gt;\Z_q&lt;/math&gt; that consists of &lt;math&gt;m&lt;/math&gt; uniformly random vectors &lt;math&gt;\boldsymbol{a_i} \in \Z^n_q&lt;/math&gt;: &lt;math&gt;A = [\boldsymbol{a_1}|\cdots|\boldsymbol{a_m}]&lt;/math&gt;. Find a nonzero vector &lt;math&gt;\boldsymbol{x} \in \Z^m&lt;/math&gt; such that:
* &lt;math&gt; \|\boldsymbol{x}\| \leq \beta&lt;/math&gt;
* &lt;math&gt;f_A(\boldsymbol{x}) := A\boldsymbol{x} = \boldsymbol{0} \in \Z^n_q&lt;/math&gt;

It should be noted that a solution to SIS without the required constraint on the length of the solution (&lt;math&gt;\|\boldsymbol{x}\| \leq \beta&lt;/math&gt;) is easy to compute by using ''Gaussian elimination'' technique. We also require &lt;math&gt;\beta &lt; q&lt;/math&gt;, otherwise &lt;math&gt;\boldsymbol{x} = (q,0,\ldots,0) \in \Z^m&lt;/math&gt; is a trivial solution.
 
In order to guarantee &lt;math&gt;f_A(\boldsymbol{x})&lt;/math&gt; has non-trivial, short solution, we require:
* &lt;math&gt;\beta \geq \sqrt{n\log q}&lt;/math&gt;, and
* &lt;math&gt;m \geq n\log q&lt;/math&gt;

'''Theorem:''' For any &lt;math&gt;m = \operatorname{poly}(n)&lt;/math&gt;, any  &lt;math&gt;\beta &gt; 0&lt;/math&gt;, and any sufficiently large &lt;math&gt;q \geq \beta n^c&lt;/math&gt; (for any constant &lt;math&gt;c &gt;0&lt;/math&gt;), solving &lt;math&gt;\operatorname{SIS}_{n,m,q,\beta}&lt;/math&gt; with nonnegligible probability is at least as hard as solving the &lt;math&gt;\operatorname{GapSVP}_\gamma&lt;/math&gt; and &lt;math&gt;\operatorname{SIVP}_\gamma&lt;/math&gt; for some &lt;math&gt;\gamma = \beta \cdot O(\sqrt{n})&lt;/math&gt; with a high probability in the worst-case scenario.

===Ring-SIS===
Ring-SIS problem, a compact ring-based analogue of SIS problem, was studied in.&lt;ref name="micciancio2002generalized" /&gt;&lt;ref&gt;Lyubashevsky, Vadim, et al. [SWIFFT: A modest proposal for FFT hashing.] Fast Software Encryption. Springer Berlin Heidelberg, 2008.&lt;/ref&gt; 
They consider quotient polynomial ring &lt;math&gt;R = \Z/(f(x))&lt;/math&gt; with &lt;math&gt;f(x) = x^n-1&lt;/math&gt; and &lt;math&gt;x^{2^k}+1&lt;/math&gt;, respectively, and extend the definition of ''norm'' on vectors in &lt;math&gt;\R^n&lt;/math&gt; to vectors in &lt;math&gt;R^m&lt;/math&gt; as follows:

Given a vector &lt;math&gt;\vec{\boldsymbol{z}} = (p_1,\ldots,p_m)\in R^m&lt;/math&gt; where &lt;math&gt;p_i(x)&lt;/math&gt; are some polynomial in &lt;math&gt;R&lt;/math&gt;. Consider the embedding coefficient &lt;math&gt;\Z&lt;/math&gt;-module isomorphism &lt;math&gt;\rho&lt;/math&gt;:

: &lt;math&gt;
    \begin{align}
       &amp; \rho: R \rightarrow \Z^n \\[3pt]
       p(x) &amp; = \sum_{i=0}^{n-1}a_ix^i \mapsto (a_0,\ldots,a_{n-1})
    \end{align}
&lt;/math&gt;

Let &lt;math&gt;\boldsymbol{z_i} = \rho(p_i(x)) \in Z^n&lt;/math&gt;. Define norm &lt;math&gt;\vec{\boldsymbol{z}}&lt;/math&gt; as:

: &lt;math&gt;
    \|\vec{\boldsymbol{z}}\| := \sqrt{\sum_{i=1}^m \|\boldsymbol{z_i}\|^2}
&lt;/math&gt;

Alternatively, a better notion for norm is achieved by exploiting the ''canonical embedding''. The canonical embedding is defined as:

: &lt;math&gt;
    \begin{align}
         \sigma: R = \Z/(f(x)) &amp; \rightarrow \mathbb{C}^n \\
         p(x) &amp; \mapsto (p(\alpha_1),\ldots,p(\alpha_{n})    
    \end{align}
&lt;/math&gt;

where &lt;math&gt;\alpha_i&lt;/math&gt; is the &lt;math&gt;i^{th}&lt;/math&gt; complex root of &lt;math&gt;f(x)&lt;/math&gt; for &lt;math&gt;i=1,\ldots, n&lt;/math&gt;.

===R-SIS&lt;sub&gt;''m'',''q'',''&amp;beta;''&lt;/sub&gt;===
Given the quotient polynomial ring &lt;math&gt;R = \Z/(f(x))&lt;/math&gt;, define

&lt;math&gt;R_q:= R/qR = \Z_q[x]/(f(x))&lt;/math&gt;. Select &lt;math&gt;m&lt;/math&gt; independent uniformly random elements &lt;math&gt;a_i \in R_q&lt;/math&gt;. Define vector &lt;math&gt;\vec{\boldsymbol{a}}:=(a_1,\ldots,a_m) \in R_q^m&lt;/math&gt;. Find a nonzero vector &lt;math&gt;\vec{\boldsymbol{z}}:=(p_1,\ldots,p_m) \in R^m&lt;/math&gt; such that:
* &lt;math&gt; \|\vec{\boldsymbol{z}}\| \leq \beta&lt;/math&gt;
* &lt;math&gt;f_{\vec{\boldsymbol{a}}}(\vec{\boldsymbol{z}}) := \vec{\boldsymbol{a}}^{\,t}.\vec{\boldsymbol{z}} = \sum_{i=1}^m a_i.p_i = 0 \in R_q&lt;/math&gt;

Recall that to guarantee existence of a solution to SIS problem, we require &lt;math&gt;m \approx n\log q&lt;/math&gt;. However, Ring-SIS problem provide us with more compactness and efficacy: to guarantee existence of a solution to Ring-SIS problem, we require &lt;math&gt;m \approx \log q&lt;/math&gt;.

'''Definition:''' The ''nega-circulant matrix'' of &lt;math&gt;b&lt;/math&gt; is defined as:

: &lt;math&gt;
\text{for} \quad b = \sum_{i=0}^{n-1}b_ix^i \in R, \quad 
    \mathrm{Rot}(b) := \begin{bmatrix}
       b_0 &amp; -b_{n-1} &amp; \ldots &amp; -b_1  \\[0.3em]
       b_1 &amp; b_0 &amp; \ldots &amp; -b_2 \\[0.3em]
       \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\[0.3em]
       b_{n-1} &amp; b_{n-2} &amp; \ldots &amp; b_0
     \end{bmatrix}
&lt;/math&gt;

When the quotient polynomial ring is &lt;math&gt;R = \Z/(x^n+1)&lt;/math&gt; for &lt;math&gt;n = 2^k&lt;/math&gt;, the ring multiplication &lt;math&gt;a_i.p_i&lt;/math&gt; can be efficiently computed by first forming &lt;math&gt;\operatorname{Rot}(a_i)&lt;/math&gt;, the nega-circulant matrix of &lt;math&gt;a_i&lt;/math&gt;, and then multiplying &lt;math&gt;\operatorname{Rot}(a_i)&lt;/math&gt; with &lt;math&gt;\rho(p_i(x)) \in Z^n&lt;/math&gt;, the embedding coefficient vector of &lt;math&gt;p_i&lt;/math&gt; (or, alternatively with &lt;math&gt;\sigma(p_i(x)) \in Z^n&lt;/math&gt;, the canonical coefficient vector).
 
Moreover, R-SIS problem is a special case of SIS problem where the matrix &lt;math&gt;A&lt;/math&gt; in the SIS problem is restricted to negacirculant blocks: &lt;math&gt;A = [\operatorname{Rot}(a_1)|\cdots|\operatorname{Rot}(a_m)]&lt;/math&gt;.&lt;ref&gt;Langlois, Adeline, and Damien Stehlé. [Worst-case to average-case reductions for module lattices.] Designs, Codes and Cryptography 75.3 (2015): 565–599.&lt;/ref&gt;

==See also==
*[[Lattice-based cryptography]]
*[[Homomorphic encryption]]
*[[Ring learning with errors key exchange]]
*[[Post-quantum cryptography]]
*[[Lattice problem]]

== References ==
&lt;references/&gt;

{{Computational hardness assumptions}}

[[Category:Number theory]]
[[Category:Lattice-based cryptography]]
[[Category:Post-quantum cryptography]]
[[Category:Computational problems]]
[[Category:Computational hardness assumptions]]</text>
      <sha1>b8ye8zgmbrc1i0xl94dqpku5jtgz435</sha1>
    </revision>
  </page>
  <page>
    <title>Sievert integral</title>
    <ns>0</ns>
    <id>21769209</id>
    <revision>
      <id>790776611</id>
      <parentid>770426297</parentid>
      <timestamp>2017-07-16T00:28:45Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Definition */LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="578">The '''Sievert integral''', named after [[Sweden|Swedish]] [[medical physicist]] [[Rolf Sievert]], is a [[special function]] commonly encountered in [[radiation transport]] calculations. 

It plays a role in the [[sievert]] (symbol: Sv) unit of ionizing radiation dose in the International System of Units (SI).

==Definition==
: &lt;math&gt; F(x,\theta)=\int_0^\theta {e^{-x\sec(\varphi)}}\,d{\varphi}.&lt;/math&gt;

==References==
*{{AS ref|27|1001}}

==External links==
*{{MathWorld|urlname=SievertIntegral|title=Sievert Integral}}


[[Category:Special functions]]


{{Mathapplied-stub}}</text>
      <sha1>tfgipm3h4m44eus88578ws9k9zrurr8</sha1>
    </revision>
  </page>
  <page>
    <title>Single pushout graph rewriting</title>
    <ns>0</ns>
    <id>51724747</id>
    <revision>
      <id>745112398</id>
      <parentid>742792495</parentid>
      <timestamp>2016-10-19T09:13:12Z</timestamp>
      <contributor>
        <username>Chalst</username>
        <id>92900</id>
      </contributor>
      <comment>Change URL of Ehrig et al 1997 to document with full text</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="894">{{unreferenced|date=September 2016}}
In [[computer science]], '''single pushout graph rewriting''' or SPO graph rewriting refers to a mathematical framework for [[graph rewriting]], and is used in contrast to the [[double-pushout approach]] of graph rewriting.

==References==
{{reflist}}

==Further reading==
* {{cite book|last1=Ehrig |first1=H. |author2=R. Heckel; M. Korff; M. Löwe; L. Ribeiro; A. Wagner; A. Corradini |editor=Grzegorz Rozenberg |title=Handbook of Graph Grammars and Computing by Graph Transformation |chapterurl=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.1644&amp;rep=rep1&amp;type=pdf |date=1997 |publisher=World Scientific  |isbn=978-981-238-472-0 |pages=247–312 |chapter=Chapter 4. Algebraic approaches to graph transformation. Part II: single pushout approach and comparison with double pushout approach}} 

[[Category:Graph rewriting]]


{{compu-sci-stub}}</text>
      <sha1>7efywpt5lo868pgbx2s8380ar1qame8</sha1>
    </revision>
  </page>
  <page>
    <title>Sorin Popa</title>
    <ns>0</ns>
    <id>46788343</id>
    <revision>
      <id>869959400</id>
      <parentid>865681905</parentid>
      <timestamp>2018-11-21T13:42:25Z</timestamp>
      <contributor>
        <ip>92.85.164.138</ip>
      </contributor>
      <comment>Sorin Popa</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3983">{{Infobox scientist

| name = Sorin Teodor Popa
| image = 
| image_size = 
| caption = 
| birth_name = 
| birth_date = {{Birth date and age|df=yes|1953|03|24}}
| birth_place = [[Sprâncenata, Olt]]
| death_date = 
| death_place = 
| residence = 
| citizenship = 
| nationality = 
| fields = Mathematics
| workplaces = [[University of California, Los Angeles]]
| alma_mater = [[University of Bucharest]]
| doctoral_advisor = [[Dan-Virgil Voiculescu]]
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for = [[Von Neumann algebra]]s, [[subfactor]]s, [[ergodic theory]]
| author_abbrev_bot = 
| author_abbrev_zoo = 
| influences = 
| influenced = 
| awards = [[Guggenheim Fellow]] (1995)
[[Ostrowski Prize]] (2009)
| signature = 
| footnotes = 
| honorific_suffix = 
| ethnicity = 
| religion = 
}}'''Sorin Teodor Popa''' (24 March 1953) is a [[Romanian American]] [[mathematician]] working on [[operator algebras]]. He is a professor at the [[University of California, Los Angeles]].&lt;ref name="ostro"&gt;{{cite web|url=http://www.ams.org/notices/201003/rtx100300404p.pdf|website=Notices of the American Mathematical Society|title=Popa Receives Ostrowski Prize}}&lt;/ref&gt; 

== Biography ==
Popa earned his [[Ph.D.]] from the [[University of Bucharest]] in 1983 under the supervision of [[Dan-Virgil Voiculescu]].&lt;ref name="ostro" /&gt;&lt;ref name="MGP"&gt;{{MathGenealogy|id=36702}}&lt;/ref&gt;  He has advised 15 doctoral students at UCLA, including [[Adrian Ioana]].&lt;ref name="MGP" /&gt;

== Honors and awards ==

In 1990 he was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker]] at the [[International Congress of Mathematicians]] (ICM) in [[Kyoto]] (on "Subfactors and Classifications in von Neumann algebras"). He was a [[Guggenheim Fellowship|Guggenheim Fellow]] in 1995.&lt;ref&gt;[http://www.gf.org/fellows/all-fellows/sorin-popa/ Guggenheim Foundation. Fellow: Sorin Popa]&lt;/ref&gt; In 2006 he gave a plenary lecture at the ICM in [[Madrid]] (on "Deformation and Rigidity for group actions and Von Neumann Algebras"&lt;ref&gt;[http://www.mathunion.org/ICM/ICM1990.2/ICM1990.2.ocr.pdf International Mathematical Union – Proceedings of the International Congress of Mathematicians, August 21–29, 1990, Kyoto, Japan] {{webarchive|url=https://web.archive.org/web/20150524213028/http://www.mathunion.org/ICM/ICM1990.2/ICM1990.2.ocr.pdf |date=2015-05-24 }}&lt;/ref&gt;). In 2009 he was awarded the [[Ostrowski Prize]].&lt;ref name="ostro" /&gt; He is one of the inaugural fellows of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list AMS – List of Fellows of the American Mathematical Society]&lt;/ref&gt;

== Selected publications ==
* [https://books.google.com/books/about/Classification_of_Subfactors_and_Their_E.html?id=ihSiFdPlk_0C ''Classification of subfactors and their endomorphisms''], [[American Mathematical Society]], 1995
* co-authored with Mihai Pimsner, "Entropy and index for subfactors", ''Annales scientifiques de l'Ecole normale supérieure'' (1986)
* "Classification of amenable subfactors of type II", ''[[Acta Mathematica]]'' (1994)

== References ==
{{reflist}}

== External links ==
* [http://www.math.ucla.edu/~popa/ Homepage of Sorin Popa at the University of California, Los Angeles]
* [http://www.math.ucla.edu/news/sorin-popa-elected-american-academy-arts-and-sciences UCLA – Sorin Popa elected into the American Academy of Arts and Sciences]

{{Authority control}}

{{DEFAULTSORT:Popa, Sorin}}
[[Category:1953 births]]
[[Category:Algebraists]]
[[Category:Romanian mathematicians]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Romanian emigrants to the United States]]
[[Category:University of California, Los Angeles faculty]]
[[Category:University of Bucharest alumni]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Living people]]</text>
      <sha1>d5gkbj9tv03e2yqrz94ku0pu7gou48q</sha1>
    </revision>
  </page>
  <page>
    <title>Support function</title>
    <ns>0</ns>
    <id>9377661</id>
    <revision>
      <id>840701776</id>
      <parentid>836738647</parentid>
      <timestamp>2018-05-11T15:58:59Z</timestamp>
      <contributor>
        <username>Yangfl</username>
        <id>12172223</id>
      </contributor>
      <minor/>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7516">In [[mathematics]], the '''support function''' ''h''&lt;sub&gt;''A''&lt;/sub&gt; of a non-empty [[Closed set|closed]] [[convex set]] ''A'' in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;
describes the (signed) distances of [[supporting hyperplane]]s of ''A'' from the origin. The support function is a [[convex function]] on &lt;math&gt;\mathbb{R}^n&lt;/math&gt;.
Any non-empty closed convex set ''A''  is uniquely determined by   ''h''&lt;sub&gt;''A''&lt;/sub&gt;. Furthermore, the support function, as a function of the set ''A'' is compatible with many natural geometric operations, like scaling, translation, rotation and [[Minkowski addition]]. 
Due to these properties, the support function is one of the most central basic concepts in convex geometry.

==Definition==
The support function  &lt;math&gt;h_A\colon\mathbb{R}^n\to\mathbb{R}&lt;/math&gt;  
of a  non-empty closed convex set ''A'' in &lt;math&gt;\mathbb{R}^n&lt;/math&gt; is given by 
:&lt;math&gt; h_A(x)=\sup\{ x\cdot a: a\in A\},&lt;/math&gt;
&lt;math&gt;x\in\mathbb{R}^n&lt;/math&gt;; see
&lt;ref name=bonnesen&gt;T. Bonnesen, W. Fenchel, '' Theorie der konvexen Körper,'' Julius Springer, Berlin, 1934. 
English translation: ''Theory of convex bodies,'' BCS Associates, Moscow, ID, 1987.&lt;/ref&gt;
&lt;ref name=gardner&gt;R. J. Gardner, ''Geometric tomography,'' Cambridge University Press, New York, 1995. Second edition: 2006.&lt;/ref&gt;
.&lt;ref name=schneider&gt;R. Schneider, ''Convex bodies: the Brunn-Minkowski theory,'' Cambridge University Press, Cambridge, 1993.&lt;/ref&gt; Its interpretation is most intuitive when ''x'' is a unit vector: 
by definition, ''A'' is contained in the closed half space 
:&lt;math&gt;  \{y\in\mathbb{R}^n: y\cdot x \leqslant h_A(x) \}&lt;/math&gt; 
and there is at least one point of ''A'' in the boundary
:&lt;math&gt; H(x)= \{y\in\mathbb{R}^n: y\cdot x = h_A(x) \}&lt;/math&gt;
of this half space. The hyperplane ''H''(''x'') is therefore called a ''supporting hyperplane'' 
with ''exterior'' (or ''outer'') unit normal vector ''x''.
The word ''exterior'' is important here, as 
the orientation of ''x'' plays a role, the set ''H''(''x'') is in general different from  ''H''(-''x'').
Now  ''h''&lt;sub&gt;''A''&lt;/sub&gt; is the (signed) distance of ''H''(''x'') from the origin.

==Examples==
The support function of a singleton ''A''={''a''}  is  &lt;math&gt;h_{A}(x)=x \cdot a&lt;/math&gt;.

The support function of the Euclidean unit ball ''B''&lt;sub&gt;''1''&lt;/sub&gt; is  &lt;math&gt;h_{B_1}(x)=|x|&lt;/math&gt;.

If ''A'' is a line segment through the origin with endpoints -''a'' and ''a'' then &lt;math&gt;h_A(x)=|x\cdot a|&lt;/math&gt;.

==Properties==

===As a function of ''x''===
The support function of a ''compact'' convex set is real valued and continuous, but if the 
set is unbounded, its support function is extended real valued (it takes the value  
&lt;math&gt;\infty&lt;/math&gt;). As any nonempty closed convex set is the intersection of
its supporting half spaces, the function ''h''&lt;sub&gt;''A''&lt;/sub&gt; determines ''A'' uniquely.  
This can be used to describe certain geometric properties of convex sets analytically. 
For instance, a set ''A'' is point symmetric with respect to the origin if and only ''h''&lt;sub&gt;''A''&lt;/sub&gt;
is an [[even function]].

In general, the support function is not differentiable. However, directional derivatives
exist and yield support functions of support sets. If ''A'' is ''compact'' and convex, 
and ''h''&lt;sub&gt;''A''&lt;/sub&gt;'(''u'';''x'') denotes the directional derivative of
''h''&lt;sub&gt;''A''&lt;/sub&gt; at ''u'' &amp;ne; ''0'' in direction ''x'',
we have 
:&lt;math&gt; h_A'(u;x)= h_{A \cap H(u)}(x) \qquad x \in \mathbb{R}^n.&lt;/math&gt;
Here ''H''(''u'') is the supporting hyperplane of ''A'' with exterior normal vector ''u'', defined
above. If ''A'' &amp;cap; ''H''(''u'') is a singleton {''y''}, say, it follows that the support function is differentiable at 
''u'' and its gradient coincides with ''y''. Conversely, if ''h''&lt;sub&gt;''A''&lt;/sub&gt; is differentiable at ''u'', then ''A'' &amp;cap; ''H''(''u'') is a singleton. Hence ''h''&lt;sub&gt;''A''&lt;/sub&gt; is differentiable at all points ''u'' &amp;ne; ''0'' 
if and only if ''A'' is ''strictly convex'' (the boundary of ''A'' does not contain any line segments).

It follows directly from its definition that the support function is positive homogeneous:
:&lt;math&gt; h_A(\alpha x)=\alpha h_A(x),  \qquad \alpha \ge 0, x\in \mathbb{R}^n,&lt;/math&gt;
and subadditive:
:&lt;math&gt; h_A(x+y)\le h_A(x)+ h_A(y),  \qquad x,y\in \mathbb{R}^n.&lt;/math&gt;
It follows that ''h''&lt;sub&gt;''A''&lt;/sub&gt; is a [[convex function]]. 
It is crucial in convex geometry that these properties characterize support functions:
Any positive homogeneous, convex, real valued function on &lt;math&gt;\mathbb{R}^n&lt;/math&gt; is the 
support function of a nonempty compact convex set. Several proofs are known
,&lt;ref name=schneider/&gt;
one is using the fact that the [[Legendre transformation|Legendre transform]] of a positive homogeneous, convex, real valued function 
is the (convex) indicator function of a compact convex set.

Many authors restrict  the support function to the Euclidean unit sphere 
and consider it as a function on ''S''&lt;sup&gt;''n''-1&lt;/sup&gt;. 
The homogeneity property shows that this restriction determines the 
support function on &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, as defined above.

===As a function of ''A''===
The support functions of a dilated or translated set are closely related to the original set ''A'':
:&lt;math&gt; h_{\alpha A}(x)=\alpha h_A(x),  \qquad \alpha \ge 0, x\in \mathbb{R}^n&lt;/math&gt;
and 
:&lt;math&gt; h_{A+b}(x)=h_A(x)+x\cdot b,  \qquad x,b\in \mathbb{R}^n.&lt;/math&gt;
The latter generalises to 
:&lt;math&gt; h_{A+B}(x)=h_A(x)+h_B(x),  \qquad x\in \mathbb{R}^n,&lt;/math&gt;
where ''A'' + ''B'' denotes the [[Minkowski sum]]:
:&lt;math&gt;A + B := \{\, a + b \in \mathbb{R}^{n} \mid a \in A,\ b \in B \,\}.&lt;/math&gt;
The [[Hausdorff distance]] {{nowrap|''d''&lt;sub&gt;&amp;thinsp;H&lt;/sub&gt;(''A'', ''B'')}}  
of two nonempty compact convex sets ''A'' and ''B'' can be expressed in terms of support functions, 
: &lt;math&gt; d_{\mathrm H}(A,B) =  \| h_A-h_B\|_\infty&lt;/math&gt;
where, on the right hand side, the [[uniform norm]] on the unit sphere is used.

The properties of the support function as a function of the set ''A'' are sometimes summarized in saying
that &lt;math&gt;\tau&lt;/math&gt;:''A'' &lt;math&gt;\mapsto&lt;/math&gt; ''h'' &lt;sub&gt;''A''&lt;/sub&gt; maps the family of non-empty
compact convex sets to the cone of all real-valued continuous functions on the sphere whose positive 
homogeneous extension is convex. Abusing terminology slightly,  &lt;math&gt;\tau&lt;/math&gt; 
is sometimes called ''linear'', as it respects Minkowski addition, although it is not 
defined on a linear space, but rather on an (abstract) convex cone of nonempty compact convex sets. 
The mapping &lt;math&gt;\tau&lt;/math&gt; is an isometry between this cone, endowed with the Hausdorff metric, and 
a subcone of the family of continuous functions on ''S''&lt;sup&gt;''n''-1&lt;/sup&gt; with the uniform norm.

==Variants==
In contrast to the above, support functions are sometimes defined on the boundary of ''A'' rather than on 
''S''&lt;sup&gt;''n''-1&lt;/sup&gt;, under the assumption that there exists a unique exterior unit normal at each boundary point. 
Convexity is not needed for the definition.
For an oriented [[smooth surface|regular surface]], ''M'', with a [[unit normal vector]], ''N'', defined everywhere on its surface, the support function 
is then defined by
: &lt;math&gt;{x}\mapsto{x}\cdot N({x})&lt;/math&gt;.
In other words, for any &lt;math&gt;{x}\in M&lt;/math&gt;, this support function gives the 
signed distance of the unique hyperplane that touches ''M'' in ''x''.

== See also ==
* [[Barrier cone]]
* [[Supporting functional]]

==References==
{{reflist}}

[[Category:Convex geometry]]
[[Category:Types of functions]]</text>
      <sha1>0g9c1crlogfo2757qi1jcha3dbs7v5q</sha1>
    </revision>
  </page>
  <page>
    <title>Transcendental law of homogeneity</title>
    <ns>0</ns>
    <id>35889821</id>
    <revision>
      <id>848453026</id>
      <parentid>808253715</parentid>
      <timestamp>2018-07-02T00:16:12Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1998">In mathematics, the '''transcendental law of homogeneity''' ('''TLH''') is a heuristic principle enunciated by [[Gottfried Wilhelm Leibniz]] most clearly in a 1710 text entitled ''Symbolismus memorabilis calculi algebraici et infinitesimalis in comparatione potentiarum et differentiarum, et de lege homogeneorum transcendentali''.&lt;ref&gt;Leibniz ''Mathematische Schriften'', (1863), edited by C. I. Gerhardt, volume V, pages 377–382)&lt;/ref&gt;  [[Henk J. M. Bos]] describes it as the principle to the effect that in a sum involving [[infinitesimal]]s of different orders, only the lowest-order term must be retained, and the remainder discarded.&lt;ref&gt;{{citation
 | last1 = Bos | first1 = Henk J. M.
 | author1-link = Henk J. M. Bos 
 | arxiv = 
 | doi = 10.1007/BF00327456
 | issue = 
 | journal = [[Archive for History of Exact Sciences]]
 | pages = 1–90
 | title = Differentials, higher-order differentials and the derivative in the Leibnizian calculus
 | volume = 14
 | year = 1974}}&lt;/ref&gt;  Thus, if &lt;math&gt;a&lt;/math&gt; is finite and &lt;math&gt;dx&lt;/math&gt; is infinitesimal, then one sets

:&lt;math&gt;a+dx=a.&lt;/math&gt;

Similarly,

:&lt;math&gt;u\,dv+v\,du+du\,dv=u\,dv+v\,du,&lt;/math&gt;

where the higher-order term ''du''&amp;nbsp;''dv'' is discarded in accordance with the TLH.  A recent study argues that Leibniz's TLH was a precursor of the [[standard part function]] over the [[Hyperreal_number|hyperreals]].&lt;ref&gt;{{citation
 | last1 = Katz | first1 = Mikhail
 | author1-link = Mikhail Katz
 | last2 = Sherry | first2 = David
 | author2-link = 
 | arxiv = 1205.0174
 | doi = 10.1007/s10670-012-9370-y
 | issue = 
 | journal = [[Erkenntnis]]
 | pages = 
 | title = Leibniz’s Infinitesimals: Their Fictionality, Their Modern Implementations, and Their Foes from Berkeley to Russell and Beyond
 | volume = 
 | year = 2012}}&lt;/ref&gt;

==See also==
*[[Law of continuity]]
*[[Adequality]]

== References ==
{{reflist}}

{{Gottfried Wilhelm Leibniz}}
{{Infinitesimals}}

[[Category:History of calculus]]
[[Category:Gottfried Leibniz]]</text>
      <sha1>1xkb3dp48jv8ggb2pnsttbr3rbxc61v</sha1>
    </revision>
  </page>
  <page>
    <title>UMLsec</title>
    <ns>0</ns>
    <id>27126714</id>
    <revision>
      <id>852825986</id>
      <parentid>613851398</parentid>
      <timestamp>2018-07-31T16:45:32Z</timestamp>
      <contributor>
        <username>Jmertel23</username>
        <id>32942831</id>
      </contributor>
      <comment>de-orphaned</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3959">
'''UMLsec''' is an extension to the [[Unified Modelling Language]] for integrating security related information in UML specifications. This information can be used for model based security engineering. Most security information is added using stereotypes and cover many security properties including [[secure information flow]], [[confidentiality]] and [[access control]]. Using an attacker model these properties can be checked on a model level.

==Development==
It was first proposed by Jürjens et al. in 2002&lt;ref&gt;Jürjens, J. UMLsec: Extending UML for secure systems development. UML 2002 —The Unified Modeling Language (2002), 1–9.&lt;/ref&gt; and later revised and extended by the same author.&lt;ref&gt;Jürjens, J. Secure Systems Development with UML, 1 ed. Springer, 2005.&lt;/ref&gt;

==Profile definition==
UMLsec is defined as lightweight extension for UML.&lt;ref&gt;OMG. Unified Modeling Language Superstructure version 2.2. The Object Management Group, February 2009. http://www.omg.org/spec/UML/2.2/Superstructure&lt;/ref&gt; 

The profile is defined through a set of prototypes with properties (tag definitions) and constraints. UMLsec defines 21 stereotypes listed below.

{| class="wikitable"
|-
! Stereotype
! Base class
! Tags
! Description
|-
| fair exchange
| subsystem
| start, stop, adversary
| enforce the fair exchange principle on communication. That is, ensure no cheating of cooperating parties.
|-
| provable
| subsystem
| action, cert, adversary
| provide evidence of activities to obtain non-repudiation.
|-
| rbac
| subsystem
| protected, role, right
| enforce [[role-based access control]].
|-
| Internet&lt;br /&gt;
| link
|
| Internet connection. It is assumed to be susceptible to message deletion, addition and content exposure by the default attacker.
|-
| encrypted
| link
|
| model an encrypted connection. It is assumed to be susceptible to message deletion by the default attackers.
|-
| LAN
| link, node
|
| LAN connection or a LAN network (node).It is assumed to be unaffected by the default external attacker.
|-
| wire
|link
|
|wire connection. It is assumed to be unaffected by the default external attacker.
|-
|smart card&lt;br /&gt; POS device &lt;br /&gt; issuer node
|node
|
|Nodes with varying protection mechanisms. Adversary definitions determine to what extent these nodes may be tampered with. They are assumed to be unaffected by the default external attacker.
|-
|secrecy&lt;br /&gt;integrity&lt;br /&gt;high
|dependency
|
|dependency that indicates an assumption of secrecy and integrity as well as high ''sensitivity'' .
|-
|critical
|object&lt;br /&gt;subsystem
|secrecy,&lt;br /&gt;integrity,&lt;br /&gt;authenticity,&lt;br /&gt;high, fresh
|label a system or object as ''critical''. Tags are used to define in what respect the system/object is critical.
|-
|secure links
|subsystem
|adversary
|enforce secure communication links under the defined adversary model.
|-
|secure dependencies
|subsystem
|
|ensure that secure dependencies are met.
|-
|data security
|subsystem
|adversary,&lt;br /&gt;integrity,&lt;br /&gt;authenticity
|enforce basic security requirements under the defined adversary model.
|-
|no down-flow,&lt;br /&gt;no up-flow
|subsystem
|
|ensure secure information flow.
|-
|guarded access
|subsystem
|
|ensure that guarded objects are accessed only through their guards.
|-
|guarded
|object
|guard
|specify a ''guarded object'' that can only be accessed through the object specified by the guard tag.
|}

==Adversary model==
To ensure security it is necessary to specify what kind of attacker is assumed. In UMLsec, the attacker model is defined through the threats that it poses. The table below defines the ''default'' adversary. Other adversaries may of course be defined.
{| class="wikitable"
|-
! Stereotype
! Threats&lt;sub&gt;''default''&lt;/sub&gt;()
|-
| Internet
| {delete, read, insert}
|-
| encrypted
| {delete}
|-
|LAN
|∅
|-
|wire
|∅
|-
|smart card
|∅
|-
|POS device
|∅
|-
|issuer node
|∅
|}

==References==
&lt;references/&gt;

[[Category:Unified Modeling Language]]</text>
      <sha1>cjlfh79toj5nlqpiy9y25s4g94g6lfk</sha1>
    </revision>
  </page>
  <page>
    <title>Unification (computer science)</title>
    <ns>0</ns>
    <id>54432</id>
    <revision>
      <id>864613456</id>
      <parentid>864563865</parentid>
      <timestamp>2018-10-18T11:02:45Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* Generalization, specialization */ move justifications to notes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="66101">In [[logic]] and [[computer science]], '''unification''' is an algorithmic process of [[equation solving|solving equations]] between symbolic [[expression (mathematics)|expressions]].

Depending on which expressions (also called ''terms'') are allowed to occur in an equation set (also called ''unification problem''), and which expressions are considered equal, several frameworks of unification are distinguished. If higher-order variables, that is, variables representing [[function (mathematics)|function]]s, are allowed in an expression, the process is called '''higher-order unification''', otherwise '''first-order unification'''. If a solution is required to make both sides of each equation literally equal, the process is called '''syntactic''' or '''free unification''', otherwise '''semantic''' or '''equational unification''', or '''E-unification''', or '''unification modulo theory'''.

A ''solution'' of a unification problem is denoted as a [[substitution (logic)|substitution]], that is, a mapping assigning a symbolic value to each variable of the problem's expressions. A unification algorithm should compute for a given problem a ''complete'', and ''minimal'' substitution set, that is, a set covering all its solutions, and containing no redundant members. Depending on the framework, a complete and minimal substitution set may have at most one, at most finitely many, or possibly infinitely many members, or may not exist at all.&lt;ref group=note&gt;in this case, still a complete substitution set exists (e.g. the set of all solutions at all); however, each such set contains redundant members.&lt;/ref&gt;&lt;ref&gt;{{cite journal|first1=François|last1=Fages|first2=Gérard|last2=Huet|title=Complete Sets of Unifiers and Matchers in Equational Theories|journal=Theoretical Computer Science|volume=43|pages=189–200|year=1986|doi=10.1016/0304-3975(86)90175-1}}&lt;/ref&gt; In some frameworks it is generally impossible to decide whether any solution exists. For first-order syntactical unification, Martelli and Montanari&lt;ref name="Martelli.Montanari.1982"&gt;{{cite journal|first1=Alberto|last1=Martelli|first2=Ugo|last2=Montanari|title=An Efficient Unification Algorithm|journal=ACM Trans. Program. Lang. Syst.|volume=4|number=2|pages=258–282|date=Apr 1982|doi=10.1145/357162.357169}}&lt;/ref&gt; gave an algorithm that reports unsolvability or computes a complete and minimal singleton substitution set containing the so-called '''most general unifier'''.

For example, using ''x'',''y'',''z'' as variables, the singleton equation set { ''[[cons]]''(''x'',''cons''(''x'',''[[Lisp (programming language)#Lists|nil]]'')) = ''cons''(2,''y'') } is a syntactic first-order unification problem that has the substitution { ''x'' ↦ 2, ''y'' ↦ ''cons''(2,''nil'') } as its only solution.
The syntactic first-order unification problem { ''y'' = ''cons''(2,''y'') } has no solution over the set of [[term (logic)|finite terms]]; however, it has the single solution { ''y'' ↦ ''cons''(2,''cons''(2,''cons''(2,...))) } over the set of [[Tree (set theory)|infinite trees]].
The semantic first-order unification problem { ''a''⋅''x'' = ''x''⋅''a'' } has each substitution of the form { ''x'' ↦ ''a''⋅...⋅''a'' } as a solution in a [[semigroup]], i.e. if (⋅) is considered [[associative]]; the same problem, viewed in an [[abelian group]], where  (⋅) is considered also [[commutative]], has any substitution at all as a solution.
The singleton set { ''a'' = ''y''(''x'') } is a syntactic second-order unification problem, since ''y'' is a function variable.
One solution is { ''x'' ↦ ''a'', ''y'' ↦ ([[identity function]]) }; another one is { ''y'' ↦ ([[constant function]] mapping each value to ''a''), ''x'' ↦ ''(any value)'' }.

The first formal investigation of unification can be attributed to [[J. Alan Robinson|John Alan Robinson]],&lt;ref name="Robinson.1965"&gt;{{cite journal | author=J.A. Robinson | title=A Machine-Oriented Logic Based on the Resolution Principle | journal=Journal of the ACM | volume=12 | number=1 | pages=23–41 |date=Jan 1965 | doi=10.1145/321250.321253}}; Here: sect.5.8, p.32&lt;/ref&gt;&lt;ref&gt;{{cite journal | author=J.A. Robinson | title=Computational logic: The unification computation | journal=Machine Intelligence | volume=6 | pages=63–72 | url=http://aitopics.org/sites/default/files/classic/Machine%20Intelligence%206/MI6-Ch4-Robinson.pdf | year=1971 }}&lt;/ref&gt; who used first-order syntactical unification as a basic building block of his [[Resolution (logic)|resolution]] procedure for first-order logic, a great step forward in [[automated reasoning]] technology, as it eliminated one source of combinatorial explosion: searching for instantiation of terms. Today, automated reasoning is still the main application area of unification.
Syntactical first-order unification is used in [[logic programming]] and programming language [[type system]] implementation, especially in [[Hindley–Milner]] based [[type inference]] algorithms.
Semantic unification is used in [[SMT solver]]s, [[term rewriting]] algorithms and [[cryptographic protocol]] analysis.
Higher-order unification is used in proof assistants, for example [[Isabelle (theorem prover)|Isabelle]] and [[Twelf]], and restricted forms of higher-order unification ('''higher-order pattern unification''') are used in some programming language implementations, such as [[lambdaProlog]], as higher-order patterns are expressive, yet their associated unification procedure retains theoretical properties closer to first-order unification.

==Common formal definitions==

===Prerequisites===

Formally, a unification approach presupposes
* An infinite set &lt;math&gt;V&lt;/math&gt; of '''variables'''. For higher-order unification, it is convenient to choose &lt;math&gt;V&lt;/math&gt; disjoint from the set of [[Lambda term#Lambda terms|lambda-term bound variables]].
* A set &lt;math&gt;T&lt;/math&gt; of '''terms''' such that &lt;math&gt;V \subseteq T&lt;/math&gt;. For first-order unification and higher-order unification, &lt;math&gt;T&lt;/math&gt; is usually the set of [[Term (first-order logic)#Terms|first-order terms]] (terms built from variable and function symbols) and [[Lambda term#Lambda terms|lambda terms]] (terms containing some higher-order variables), respectively.
* A mapping ''vars'': &lt;math&gt;T \rightarrow&lt;/math&gt; [[power set|ℙ]]&lt;math&gt;(V)&lt;/math&gt;, assigning to each term &lt;math&gt;t&lt;/math&gt; the set &lt;math&gt;\text{vars}(t) \subsetneq V&lt;/math&gt; of '''free variables''' occurring in &lt;math&gt;t&lt;/math&gt;.
* An '''[[equivalence relation]]''' &lt;math&gt;\equiv&lt;/math&gt; on &lt;math&gt;T&lt;/math&gt;, indicating which terms are considered equal. For higher-order unification, usually &lt;math&gt;t\equiv u&lt;/math&gt; if &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;u&lt;/math&gt; are [[Lambda term#Alpha equivalence|alpha equivalent]]. For first-order E-unification, &lt;math&gt;\equiv&lt;/math&gt; reflects the background knowledge about certain function symbols; for example, if &lt;math&gt;\oplus&lt;/math&gt; is considered commutative, &lt;math&gt;t\equiv u&lt;/math&gt; if &lt;math&gt;u&lt;/math&gt; results from &lt;math&gt;t&lt;/math&gt; by swapping the arguments of &lt;math&gt;\oplus&lt;/math&gt; at some (possibly all) occurrences. &lt;ref group=note&gt;E.g. ''a'' ⊕ (''b'' ⊕ ''f''(''x'')) ≡ ''a'' ⊕ (''f''(''x'') ⊕ ''b'') ≡ (''b'' ⊕ ''f''(''x'')) ⊕ ''a'' ≡ (''f''(''x'') ⊕ ''b'') ⊕ ''a''&lt;/ref&gt; If there is no background knowledge at all, then only literally, or syntactically, identical terms are considered equal; in this case, ≡ is called the '''[[free theory]]''' (because it is a [[free object]]), the '''[[empty theory]]''' (because the set of equational [[sentence (mathematical logic)|sentences]], or the background knowledge, is empty), the '''theory of [[uninterpreted function]]s''' (because unification is done on uninterpreted [[term (logic)|terms]]), or the '''theory of [[Algebraic specification|constructors]]''' (because all function symbols just build up data terms, rather than operating on them).

===First-order term===
{{main|Term (logic)}}
Given a set &lt;math&gt;V&lt;/math&gt; of variable symbols, a set &lt;math&gt;C&lt;/math&gt; of constant symbols and sets &lt;math&gt;F_n&lt;/math&gt; of ''n''-ary function symbols, also called operator symbols, for each natural number &lt;math&gt;n \geq 1&lt;/math&gt;, the set of (unsorted first-order) terms &lt;math&gt;T&lt;/math&gt; is [[recursive definition|recursively defined]] to be the smallest set with the following properties:&lt;ref&gt;{{cite book| author1=C.C. Chang |author1link= Chen Chung Chang|author2= H. Jerome Keisler| author2link=Howard Jerome Keisler| title=Model Theory| year=1977| volume=73| publisher=North Holland|  series=Studies in Logic and the Foundation of Mathematics}}; here: Sect.1.3&lt;/ref&gt;
* every variable symbol is a term: &lt;math&gt;V \subseteq T&lt;/math&gt;,
* every constant symbol is a term: &lt;math&gt;C \subseteq T&lt;/math&gt;,
* from every ''n'' terms &lt;math&gt;t_1, ... t_n&lt;/math&gt;, and every ''n''-ary function symbol &lt;math&gt;f \in F_n&lt;/math&gt;, a larger term &lt;math&gt;f(t_1, ..., t_n)&lt;/math&gt; can be built.
For example, if &lt;math&gt;x\in V&lt;/math&gt; is a variable symbol, &lt;math&gt;1\in C&lt;/math&gt; is a constant symbol, and &lt;math&gt;\text{add} \in F_2&lt;/math&gt; is a binary function symbol, then &lt;math&gt;x\in T, 1\in T&lt;/math&gt;, and (hence) &lt;math&gt;\text{add}(x, 1) \in T&lt;/math&gt; by the first, second, and third term building rule, respectively. The latter term is usually written as &lt;math&gt;x+1&lt;/math&gt;, using [[infix notation]] and the more common operator symbol + for convenience.
&lt;!---move to main article:
Often mathematicians fix the arity (number of arguments) of a function symbol (see [[Signature]]) while typically in syntactic unification problems
a function symbol may have any (finite) number of arguments, and possibly may have different numbers of arguments in different contexts. 
e.g. f(f(a),f(x,y,z)) is a well formed term for unification problems.
---&gt;

===Higher-order term===
{{main|Lambda calculus}}

===Substitution===
{{main|Substitution (logic)}}
A '''substitution''' is a mapping &lt;math&gt;\sigma: V\rightarrow T&lt;/math&gt; from variables to terms; the notation &lt;math&gt; \{x_1\mapsto t_1, ..., x_k \mapsto t_k\}&lt;/math&gt; refers to a substitution mapping each variable &lt;math&gt;x_i&lt;/math&gt; to the term &lt;math&gt;t_i&lt;/math&gt;, for &lt;math&gt;i=1,...,k&lt;/math&gt;, and every other variable to itself. '''Applying''' that substitution to a term &lt;math&gt;t&lt;/math&gt; is written in [[postfix notation]] as &lt;math&gt;t \{x_1 \mapsto t_1, ..., x_k \mapsto t_k\}&lt;/math&gt;; it means to (simultaneously) replace every occurrence of each variable &lt;math&gt;x_i&lt;/math&gt; in the term &lt;math&gt;t&lt;/math&gt; by &lt;math&gt;t_i&lt;/math&gt;. The result &lt;math&gt;t\tau&lt;/math&gt; of applying a substitution &lt;math&gt;\tau&lt;/math&gt; to a term &lt;math&gt;t&lt;/math&gt; is called an '''instance''' of that term &lt;math&gt;t&lt;/math&gt;.
As a first-order example, applying the substitution {{math|{{mset| ''x'' ↦ ''h''(''a'',''y''), ''z'' ↦ ''b'' }}}} to the term 
{|
|-
|
| &lt;math&gt;f(&lt;/math&gt;
| align="center" | &lt;math&gt;\textbf{x}&lt;/math&gt;
| &lt;math&gt;, a, g(&lt;/math&gt;
| &lt;math&gt;\textbf{z}&lt;/math&gt;
| &lt;math&gt; ), y)&lt;/math&gt;
|-
| yields &amp;nbsp;
|-
|
| &lt;math&gt;f(&lt;/math&gt;
| &lt;math&gt;\textbf{h}(\textbf{a}, \textbf{y})&lt;/math&gt;
| &lt;math&gt;, a, g(&lt;/math&gt;
| &lt;math&gt;\textbf{b}&lt;/math&gt;
| &lt;math&gt;), y).&lt;/math&gt;
|}

===Generalization, specialization===

If a term &lt;math&gt;t&lt;/math&gt; has an instance equivalent to a term &lt;math&gt;u&lt;/math&gt;, that is, if &lt;math&gt;t\sigma \equiv u&lt;/math&gt; for some substitution &lt;math&gt;\sigma&lt;/math&gt;, then &lt;math&gt;t&lt;/math&gt; is called '''more general''' than &lt;math&gt;u&lt;/math&gt;, and &lt;math&gt;u&lt;/math&gt; is called '''more special''' than, or '''subsumed''' by, &lt;math&gt;t&lt;/math&gt;. For example, &lt;math&gt;x\oplus a&lt;/math&gt; is more general than &lt;math&gt;a\oplus b&lt;/math&gt; if ⊕ is [[Commutative property|commutative]], since then &lt;math&gt;(x\oplus a) \{x\mapsto b\} = b\oplus a\equiv a\oplus b&lt;/math&gt;.

If ≡ is literal (syntactic) identity of terms, a term may be both more general and more special than another one only if both terms differ just in their variable names, not in their syntactic structure; such terms are called '''variants''', or '''renamings''' of each other.
For example, 
&lt;math&gt;f(x_1, a, g(z_1), y_1)&lt;/math&gt;
is a variant of 
&lt;math&gt;f(x_2, a, g(z_2), y_2)&lt;/math&gt;,
since 

&lt;!---Templates apparently don't accept "}" and "=" in its argument---&gt;
&lt;div style="text-align: center"&gt;
&lt;math&gt;f(x_1, a, g(z_1), y_1) \{x_1 \mapsto x_2, y_1 \mapsto y_2, z_1 \mapsto z_2\} = f(x_2, a, g(z_2), y_2) &lt;/math&gt;
&lt;/div&gt;
and 
&lt;div style="text-align: center"&gt;
&lt;math&gt;f(x_2, a, g(z_2), y_2) \{x_2 \mapsto x_1, y_2 \mapsto y_1, z_2 \mapsto z_1\} = f(x_1, a, g(z_1), y_1)&lt;/math&gt;.
&lt;/div&gt;
However, &lt;math&gt;f(x_1, a, g(z_1), y_1)&lt;/math&gt; is ''not'' a variant of  &lt;math&gt;f(x_2, a, g(x_2), x_2)&lt;/math&gt;, since no substitution can transform the latter term into the former one.
The latter term is therefore properly more special than the former one.

For arbitrary &lt;math&gt;\equiv&lt;/math&gt;, a term may be both more general and more special than a structurally different term.
For example, if ⊕ is [[idempotent]], that is, if always &lt;math&gt;x \oplus x \equiv x&lt;/math&gt;, then the term &lt;math&gt;x\oplus y&lt;/math&gt; is more general than &lt;math&gt;z&lt;/math&gt;,&lt;ref group=note&gt;since &lt;math&gt;(x\oplus y) \{x\mapsto z, y \mapsto z\} = z\oplus z \equiv z&lt;/math&gt;&lt;/ref&gt; and vice versa,&lt;ref group=note&gt;since {{math|1=''z'' {{mset|''z'' ↦ ''x'' ⊕ ''y''}} = ''x'' ⊕ ''y''}}&lt;/ref&gt; although &lt;math&gt;x\oplus y&lt;/math&gt; and &lt;math&gt;z&lt;/math&gt; are of different structure.

A substitution &lt;math&gt;\sigma&lt;/math&gt; is '''more special''' than, or '''subsumed''' by, a substitution &lt;math&gt;\tau&lt;/math&gt; if &lt;math&gt;t\sigma&lt;/math&gt; is more special than &lt;math&gt;t\tau&lt;/math&gt; for each term &lt;math&gt;t&lt;/math&gt;.  We also say that &lt;math&gt;\tau&lt;/math&gt; is more general than &lt;math&gt;\sigma&lt;/math&gt;.
For instance &lt;math&gt; \{x \mapsto a, y \mapsto a \}&lt;/math&gt; is more special than &lt;math&gt;\tau = \{x\mapsto y\}&lt;/math&gt;,
but 
&lt;math&gt;\sigma = \{x\mapsto a\}&lt;/math&gt; is not,
as &lt;math&gt;f(x, y)\sigma = f(a, y)&lt;/math&gt; is not more special than
&lt;math&gt;f(x, y) \tau = f(y, y)&lt;/math&gt;.&lt;ref&gt;K.R. Apt. "From Logic Programming to Prolog", p. 24.  Prentice Hall, 1997.&lt;/ref&gt;

===Unification problem, solution set===

A '''unification problem''' is a finite set {{math|{{mset| ''l''&lt;sub&gt;1&lt;/sub&gt; ≐ ''r''&lt;sub&gt;1&lt;/sub&gt;, ..., ''l''&lt;sub&gt;''n''&lt;/sub&gt; ≐ ''r''&lt;sub&gt;''n''&lt;/sub&gt; }}}} of potential equations, where {{math|''l''&lt;sub&gt;''i''&lt;/sub&gt;, ''r''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''T''}}.
A substitution σ is a '''solution''' of that problem if {{math|''l''&lt;sub&gt;''i''&lt;/sub&gt;σ ≡ ''r''&lt;sub&gt;''i''&lt;/sub&gt;σ}} for &lt;math&gt;i = 1, ..., n&lt;/math&gt;. Such a substitution is also called a '''unifier''' of the unification problem.
For example, if ⊕ is [[Associative property|associative]], the unification problem { ''x'' ⊕ ''a'' ≐ ''a'' ⊕ ''x'' } has the solutions {''x'' ↦ ''a''}, {''x'' ↦ ''a'' ⊕ ''a''}, {''x'' ↦ ''a'' ⊕ ''a'' ⊕ ''a''}, etc., while the problem { ''x'' ⊕ ''a'' ≐ ''a'' } has no solution.

For a given unification problem, a set ''S'' of unifiers is called '''complete''' if each solution substitution is subsumed by some substitution σ ∈ ''S''; the set ''S'' is called '''minimal''' if none of its members subsumes another one.

==Syntactic unification of first-order terms==

[[File:Triangle diagram of syntactic unification svg.svg|thumb|Schematic triangle diagram of syntactically unifying terms ''t''&lt;sub&gt;1&lt;/sub&gt; and ''t''&lt;sub&gt;2&lt;/sub&gt; by a substitution σ]]
''Syntactic unification of first-order terms'' is the most widely used unification framework.
It is based on ''T'' being the set of ''first-order terms'' (over some given set ''V'' of variables, ''C'' of constants and ''F''&lt;sub&gt;''n''&lt;/sub&gt; of ''n''-ary function symbols) and on ≡ being ''syntactic equality''.
In this framework, each solvable unification problem {{math|{{mset|''l''&lt;sub&gt;1&lt;/sub&gt; ≐ ''r''&lt;sub&gt;1&lt;/sub&gt;, ..., ''l''&lt;sub&gt;''n''&lt;/sub&gt; ≐ ''r''&lt;sub&gt;''n''&lt;/sub&gt;}}}} has a complete, and obviously minimal, [[Singleton (mathematics)|singleton]] solution set {{math|1={{mset|''σ''}}}}.
Its member {{mvar|σ}} is called the '''most general unifier''' ('''mgu''') of the problem.
The terms on the left and the right hand side of each potential equation become syntactically equal when the mgu is applied i.e. {{math|1=''l''&lt;sub&gt;1&lt;/sub&gt;''σ'' = ''r''&lt;sub&gt;1&lt;/sub&gt;''σ'' ∧ ... ∧ ''l''&lt;sub&gt;''n''&lt;/sub&gt;''σ'' = ''r''&lt;sub&gt;''n''&lt;/sub&gt;''σ''}}.
Any unifier of the problem is subsumed&lt;ref group=note&gt;formally: each unifier τ satisfies {{math|1=∀''x'': ''xτ'' = (''xσ'')''ρ''}} for some substitution ρ&lt;/ref&gt; by the mgu {{mvar|σ}}.
The mgu is unique up to variants: if ''S''&lt;sub&gt;1&lt;/sub&gt; and ''S''&lt;sub&gt;2&lt;/sub&gt; are both complete and minimal solution sets of the same syntactical unification problem, then ''S''&lt;sub&gt;1&lt;/sub&gt; = { ''σ''&lt;sub&gt;1&lt;/sub&gt; } and ''S''&lt;sub&gt;2&lt;/sub&gt; = { ''σ''&lt;sub&gt;2&lt;/sub&gt; } for some substitutions {{math|1=''σ''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|1=''σ''&lt;sub&gt;2&lt;/sub&gt;,}} and {{math|1=''xσ''&lt;sub&gt;1&lt;/sub&gt;}} is a variant of {{math|1=''xσ''&lt;sub&gt;2&lt;/sub&gt;}} for each variable ''x'' occurring in the problem.

For example, the unification problem { ''x'' ≐ ''z'', ''y'' ≐ ''f''(''x'') } has a unifier { ''x'' ↦ ''z'', ''y'' ↦ ''f''(''z'') }, because
:{|
|-
| align="right" | ''x''
| { ''x'' ↦ ''z'', ''y'' ↦ ''f''(''z'') }
| =
| align="center" | ''z''
| =
| align="right" | ''z''
| { ''x'' ↦ ''z'', ''y'' ↦ ''f''(''z'') }
|, and
|-
| align="right" | ''y''
| { ''x'' ↦ ''z'', ''y'' ↦ ''f''(''z'') }
| =
| align="center" | ''f''(''z'')
| =
| align="right" | ''f''(''x'')
| { ''x'' ↦ ''z'', ''y'' ↦ ''f''(''z'') }
| .
|}

This is also the most general unifier.
Other unifiers for the same problem are e.g. { ''x'' ↦ ''f''(''x''&lt;sub&gt;1&lt;/sub&gt;), ''y'' ↦ ''f''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;)), ''z'' ↦ ''f''(''x''&lt;sub&gt;1&lt;/sub&gt;) }, { ''x'' ↦ ''f''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;)), ''y'' ↦ ''f''(''f''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;))), ''z'' ↦ ''f''(''f''(''x''&lt;sub&gt;1&lt;/sub&gt;)) }, and so on; there are infinitely many similar unifiers.

As another example, the problem ''g''(''x'',''x'') ≐ ''f''(''y'') has no solution with respect to ≡ being literal identity, since any substitution applied to the left and right hand side will keep the outermost ''g'' and ''f'', respectively, and terms with different outermost function symbols are syntactically different.

===A unification algorithm===

{{Quote box|title=Robinson's 1965 unification algorithm
|quote={{hidden begin}}
Symbols are ordered such that variables precede function symbols.
Terms are ordered by increasing written length; equally long terms 
are ordered [[lexicographic order|lexicographically]].{{refn|Robinson (1965);&lt;ref name="Robinson.1965"/&gt; nr.2.5, 2.14, p.25}} For a set ''T'' of terms, its disagreement 
path ''p'' is the lexicographically least path where two member terms   
of ''T'' differ. Its disagreement set is the set of [[term (logic)#Operations with terms|subterms starting at ''p'']], 
formally: {{math|{ ''t''[[term (logic)#Operations with terms|{{pipe}}&lt;sub&gt;''p''&lt;/sub&gt;]] : &lt;math&gt;t\in T&lt;/math&gt; }}}.{{refn|Robinson (1965);&lt;ref name="Robinson.1965"/&gt; nr.5.6, p.32}}

'''Algorithm:'''{{refn|Robinson (1965);&lt;ref name="Robinson.1965"/&gt; nr.5.8, p.32}}

 Given a set ''T'' of terms to be unified
 Let &lt;math&gt;\sigma&lt;/math&gt; initially be the [[substitution (logic)#First-order logic|identity substitution]]
 
 '''do''' '''forever'''
   '''if''' &lt;math&gt;T\sigma&lt;/math&gt; is a [[singleton set]] '''then'''
     '''return''' &lt;math&gt;\sigma&lt;/math&gt;
   '''fi''' 
   
   let ''D'' be the disagreement set of &lt;math&gt;T\sigma&lt;/math&gt;
   let ''s'', ''t'' be the two lexicographically least terms in ''D''
   
   '''if''' ''s'' is not a variable '''or''' ''s'' occurs in ''t'' '''then'''
     '''return''' "NONUNIFIABLE"
   '''fi''' 
   &lt;math&gt;\sigma := \sigma \{ s \mapsto t \}&lt;/math&gt;
 '''done'''
{{hidden end}}
}}
The first algorithm given by Robinson (1965) was rather inefficient; cf. box.
The following faster algorithm originated from Martelli, Montanari (1982).&lt;ref&gt;Alg.1, p.261. Their rule '''(a)''' corresponds to rule '''swap''' here, '''(b)''' to '''delete''', '''(c)''' to both '''decompose''' and '''conflict''', and '''(d)''' to both '''eliminate''' and '''check'''.&lt;/ref&gt;
This paper also lists preceding attempts to find an efficient syntactical unification algorithm,&lt;ref&gt;{{cite report | author=Lewis Denver Baxter | title=A practically linear unification algorithm | publisher=Univ. of Waterloo, Ontario | type=Res. Report | volume=CS-76-13 | url=https://cs.uwaterloo.ca/research/tr/1976/CS-76-13.pdf |date=Feb 1976 }}&lt;/ref&gt;&lt;ref&gt;{{cite thesis | author=[[Gérard Huet]] | title=Resolution d'Equations dans des Langages d'Ordre 1,2,...ω | publisher=Universite de Paris VII | type=These d'etat |date=Sep 1976 }}&lt;/ref&gt;&lt;ref name="Martelli.Montanari.1976"&gt;{{cite report |author1=Alberto Martelli  |author2=Ugo Montanari  |lastauthoramp=yes | title=Unification in linear time and space: A structured presentation | publisher=Consiglio Nazionale delle Ricerche, Pisa | type=Internal Note | volume=IEI-B76-16 | url=http://puma.isti.cnr.it/publichtml/section_cnr_iei/cnr_iei_1976-B4-041.html |date=Jul 1976 }}&lt;/ref&gt;&lt;ref name="Paterson.Wegman.1978"&gt;{{cite journal | author=[[Michael Stewart Paterson]] and M.N. Wegman | title=Linear unification | journal=J. Comput. Syst. Sci. | volume=16 | number=2 | pages=158–167 | url=http://www.sciencedirect.com/science/article/pii/0022000078900430/pdf?md5=404ce04b363525aef2a1277b2ec249d1&amp;pid=1-s2.0-0022000078900430-main.pdf |date=Apr 1978 | doi = 10.1016/0022-0000(78)90043-0 }}&lt;/ref&gt;&lt;ref&gt;{{cite book | author=[[J.A. Robinson]] |chapter= Fast unification | editor= [[Woodrow W. Bledsoe]], Michael M. Richter| title=Proc. Theorem Proving Workshop Oberwolfach | publisher= | series=Oberwolfach Workshop Report | volume=1976/3 | url= http://oda.mfo.de/bsz325106819.html |date=Jan 1976 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | author=M. Venturini-Zilli | title=Complexity of the unification algorithm for first-order expressions |journal= Calcolo | volume=12 |number=4 |pages= 361–372 |date= Oct 1975 |url=https://link.springer.com/article/10.1007/BF02575754 | doi=10.1007/BF02575754}}&lt;/ref&gt; and states that linear-time algorithms were discovered independently by Martelli, Montanari (1976)&lt;ref name="Martelli.Montanari.1976"/&gt; and Paterson, Wegman (1978).&lt;ref name="Paterson.Wegman.1978"/&gt;{{refn|See Martelli, Montanari (1982),&lt;ref name="Martelli.Montanari.1982"/&gt; sect.1, p.259. Paterson's and Wegman's paper is dated 1978; however, the journal publisher received it in Sep.1976.}}

Given a finite set &lt;math&gt;G = \{ s_1 \doteq t_1, ..., s_n \doteq t_n \}&lt;/math&gt; of potential equations,
the algorithm applies rules to transform it to an equivalent set of equations of the form
{ ''x''&lt;sub&gt;1&lt;/sub&gt; ≐ ''u''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''m''&lt;/sub&gt; ≐ ''u''&lt;sub&gt;''m''&lt;/sub&gt; }
where ''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''m''&lt;/sub&gt; are distinct variables and ''u''&lt;sub&gt;1&lt;/sub&gt;, ..., ''u''&lt;sub&gt;''m''&lt;/sub&gt; are terms containing none of the ''x''&lt;sub&gt;''i''&lt;/sub&gt;.
A set of this form can be read as a substitution.
If there is no solution the algorithm terminates with ⊥; other authors use "Ω", "{}", or "''fail''" in that case.
The operation of substituting all occurrences of variable ''x'' in problem ''G'' with term ''t'' is denoted ''G'' {''x'' ↦ ''t''}.
For simplicity, constant symbols are regarded as function symbols having zero arguments.

:{|
| align="right" | &lt;math&gt;G \cup \{ t \doteq t \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt;
| &lt;math&gt;G&lt;/math&gt;
|
| &amp;nbsp; &amp;nbsp; '''delete'''
|-
| align="right" | &lt;math&gt;G \cup \{ f(s_0, ..., s_k) \doteq f(t_0, ..., t_k) \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt; 
| &lt;math&gt;G \cup \{ s_0 \doteq t_0, ..., s_k \doteq t_k \}&lt;/math&gt;
|
| &amp;nbsp; &amp;nbsp; '''decompose'''
|-
| align="right" | &lt;math&gt;G \cup \{ f(s_0, \ldots,s_k) \doteq g(t_0,...,t_m) \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt;
| &lt;math&gt;\bot&lt;/math&gt;
| align="right" | if &lt;math&gt;f \neq g&lt;/math&gt; or &lt;math&gt;k \neq m&lt;/math&gt;
| &amp;nbsp; &amp;nbsp; '''conflict'''
|-
| align="right" | &lt;math&gt;G \cup \{ f(s_0,...,s_k) \doteq x \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt;
| &lt;math&gt;G \cup \{ x \doteq f(s_0,...,s_k) \}&lt;/math&gt;
|
| &amp;nbsp; &amp;nbsp; '''swap'''
|-
| align="right" | &lt;math&gt;G \cup \{ x \doteq t \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt;
| &lt;math&gt;G\{x \mapsto t\} \cup \{ x \doteq t \}&lt;/math&gt;
| align="right" | if &lt;math&gt;x \not\in \text{vars}(t)&lt;/math&gt; and &lt;math&gt;x \in \text{vars}(G)&lt;/math&gt;
| &amp;nbsp; &amp;nbsp; '''eliminate'''&lt;ref group="note"&gt;Although the rule keeps ''x''\doteq''t'' in ''G'', it cannot loop forever since its precondition ''x''∈''vars''(''G'') is invalidated by its first application. More generally, the algorithm is guaranteed to terminate always, see [[#Proof of termination|below]].&lt;/ref&gt;
|-
| align="right" | &lt;math&gt;G \cup \{ x \doteq f(s_0,...,s_k) \}&lt;/math&gt;
| &lt;math&gt;\Rightarrow&lt;/math&gt;
| &lt;math&gt;\bot&lt;/math&gt;
| align="right" | if &lt;math&gt;x \in \text{vars}(f(s_0,...,s_k))&lt;/math&gt;
| &amp;nbsp; &amp;nbsp; '''check'''
|}

====Occurs check====
{{main|Occurs check}}
An attempt to unify a variable ''x'' with a term containing ''x'' as a strict subterm ''x'' ≐ ''f''(..., ''x'', ...) would lead to an infinite term as solution for ''x'', since ''x'' would occur as a subterm of itself.
In the set of (finite) first-order terms as defined above, the equation ''x'' ≐ ''f''(..., ''x'', ...) has no solution; hence the ''eliminate'' rule may only be applied if ''x'' ∉ ''vars''(''t'').
Since that additional check, called ''occurs check'', slows down the algorithm, it is omitted e.g. in most Prolog systems.
From a theoretical point of view, omitting the check amounts to solving equations over infinite trees, see [[#Unification of infinite terms|below]].

====Proof of termination====
For the proof of termination of the algorithm consider a triple &lt;math&gt;\langle n_{var}, n_{lhs}, n_{eqn}\rangle&lt;/math&gt;
where {{math|''n''&lt;sub&gt;''var''&lt;/sub&gt;}} is the number of variables that occur more than once in the equation set, {{math|''n''&lt;sub&gt;''lhs''&lt;/sub&gt;}} is the number of function symbols and constants
on the left hand sides of potential equations, and {{math|''n''&lt;sub&gt;''eqn''&lt;/sub&gt;}} is the number of equations.
When rule ''eliminate'' is applied, {{math|''n''&lt;sub&gt;''var''&lt;/sub&gt;}} decreases, since ''x'' is eliminated from ''G'' and kept only in { ''x'' ≐ ''t'' }.
Applying any other rule can never increase {{math|''n''&lt;sub&gt;''var''&lt;/sub&gt;}} again.
When rule ''decompose'', ''conflict'', or ''swap'' is applied, {{math|''n''&lt;sub&gt;''lhs''&lt;/sub&gt;}} decreases, since at least the left hand side's outermost ''f'' disappears.
Applying any of the remaining rules ''delete'' or ''check'' can't increase {{math|''n''&lt;sub&gt;''lhs''&lt;/sub&gt;}}, but decreases {{math|''n''&lt;sub&gt;''eqn''&lt;/sub&gt;}}.
Hence, any rule application decreases the triple &lt;math&gt;\langle n_{var}, n_{lhs}, n_{eqn}\rangle&lt;/math&gt; with respect to the [[lexicographical order]], which is possible only a finite number of times.

[[Conor McBride]] observes&lt;ref&gt;{{cite journal|last=McBride|first=Conor|title=First-Order Unification by Structural Recursion|journal=Journal of Functional Programming|date=October 2003|volume=13|issue=6|pages=1061–1076|doi=10.1017/S0956796803004957|url=http://strictlypositive.org/unify.ps.gz|accessdate=30 March 2012|issn=0956-7968}}&lt;/ref&gt; that “by expressing the structure which unification exploits” in a [[Dependent type|dependently typed]] language such as [[Epigram (programming language)|Epigram]], [[John Alan Robinson|Robinson]]'s algorithm can be made [[Structural induction|recursive on the number of variables]], in which case a separate termination proof becomes unnecessary.

===Examples of syntactic unification of first-order terms===
In the Prolog syntactical convention a symbol starting with an upper case letter is a variable name; a symbol that starts with a lowercase letter is a function symbol; the comma is used as the logical ''and'' operator.
For mathematical notation, ''x,y,z'' are used as variables, ''f,g'' as function symbols, and ''a,b'' as constants.
{| class="wikitable"
|-
! Prolog notation !! Mathematical notation !! Unifying substitution !! Explanation
|-
| &lt;code&gt; a = a &lt;/code&gt; || { ''a'' = ''a'' } ||  {}  || Succeeds. ([[Tautology (logic)|tautology]])
|-
| &lt;code&gt; a = b &lt;/code&gt; || { ''a'' = ''b'' }  || ⊥ || ''a'' and ''b'' do not match
|-
| &lt;code&gt; X = X &lt;/code&gt; || { ''x'' = ''x'' } || {} || Succeeds. ([[Tautology (logic)|tautology]])
|-
| &lt;code&gt; a = X &lt;/code&gt; || { ''a'' = ''x'' }  || { ''x'' ↦ ''a'' } || ''x'' is unified with the constant ''a''
|-
| &lt;code&gt; X = Y &lt;/code&gt; || { ''x'' = ''y'' }  || { ''x'' ↦ ''y'' } || ''x'' and ''y'' are aliased
|-
| &lt;code&gt; f(a,X) = f(a,b) &lt;/code&gt; || { ''f''(''a'',''x'') = ''f''(''a'',''b'') } ||  { ''x'' ↦ ''b'' } || function and constant symbols match, ''x'' is unified with the constant ''b''
|-
| &lt;code&gt; f(a) = g(a) &lt;/code&gt; || { ''f''(''a'') = ''g''(''a'') }  || ⊥ || ''f'' and ''g'' do not match
|-
| &lt;code&gt; f(X) = f(Y) &lt;/code&gt; || { ''f''(''x'') = ''f''(''y'') } || { ''x'' ↦ ''y'' } || ''x'' and ''y'' are aliased
|-
| &lt;code&gt; f(X) = g(Y) &lt;/code&gt; || { ''f''(''x'') = ''g''(''y'') } || ⊥ || ''f'' and ''g'' do not match
|-
| &lt;code&gt; f(X) = f(Y,Z) &lt;/code&gt; || { ''f''(''x'') = ''f''(''y'',''z'') } || ⊥ || Fails. The ''f'' function symbols have different arity
|-
| &lt;code&gt; f(g(X)) = f(Y) &lt;/code&gt; || { ''f''(''g''(''x'')) = ''f''(''y'') } || { ''y'' ↦ ''g''(''x'') } || Unifies ''y'' with the term {{tmath|g(x)}}
|-
| &lt;code&gt; f(g(X),X) = f(Y,a) &lt;/code&gt; || { ''f''(''g''(''x''),''x'') = ''f''(''y'',''a'') } || { ''x'' ↦ ''a'', ''y'' ↦ ''g''(''a'') } || Unifies ''x'' with constant ''a'', and ''y'' with the term {{tmath|g(a)}}
|-
| &lt;code&gt; X = f(X) &lt;/code&gt; || { ''x'' = ''f''(''x'') } || should be ⊥ || Returns ⊥ in first-order logic and many modern Prolog dialects (enforced by the ''[[occurs check]]'').
Succeeds in traditional Prolog and in Prolog II, unifying ''x'' with infinite term &lt;code&gt;x=f(f(f(f(...))))&lt;/code&gt;.
|-
| &lt;code&gt; X = Y, Y = a &lt;/code&gt; || { ''x'' = ''y'', ''y'' = ''a'' } || { ''x'' ↦ ''a'', ''y'' ↦ ''a'' } || Both ''x'' and ''y'' are unified with the constant ''a''
|-
| &lt;code&gt; a = Y, X = Y &lt;/code&gt; || { ''a'' = ''y'', ''x'' = ''y'' } || { ''x'' ↦ ''a'', ''y'' ↦ ''a'' } || As above (order of equations in set doesn't matter)
|-
| &lt;code&gt; X = a, b = X &lt;/code&gt; || { ''x'' = ''a'', ''b'' = ''x'' }  || ⊥ || Fails. ''a'' and ''b'' do not match, so ''x'' can't be unified with both
|}

[[File:Unification exponential blow-up svg.svg|thumb|Two terms with an exponentially larger tree for their least common instance. Its [[directed acyclic graph|dag]] representation (rightmost, orange part) is still of linear size.]]
The most general unifier of a syntactic first-order unification problem of [[Term (logic)#Operations with terms|size]] {{mvar|n}} may have a size of {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}}. For example, the problem {{tmath| (((a*z)*y)*x)*w \doteq w*(x*(y*(z*a))) }} has the most general unifier {{tmath| z \mapsto a,  y \mapsto a*a,  x \mapsto (a*a)*(a*a),  w \mapsto ((a*a)*(a*a))*((a*a)*(a*a)) }}, cf. picture. In order to avoid exponential time complexity caused by such blow-up, advanced unification algorithms work on [[directed acyclic graph]]s (dags) rather than trees.{{refn|e.g. Paterson, Wegman (1978),&lt;ref name="Paterson.Wegman.1978"/&gt; sect.2, p.159}}

===Application: unification in logic programming===

The concept of unification is one of the main ideas behind [[logic programming]], best known through the language [[Prolog]]. It represents the mechanism of binding the contents of variables and can be viewed as a kind of one-time assignment. In Prolog, this operation is denoted by the equality symbol &lt;code&gt;=&lt;/code&gt;, but is also done when instantiating variables (see below). It is also used in other languages by the use of the equality symbol &lt;code&gt;=&lt;/code&gt;, but also in conjunction with many operations including &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;. [[Type inference]] algorithms are typically based on unification.

In Prolog:
# A [[variable (programming)|variable]] which is uninstantiated—i.e. no previous unifications were performed on it—can be unified with an atom, a term, or another uninstantiated variable, thus effectively becoming its alias. In many modern Prolog dialects and in [[first-order logic]], a variable cannot be unified with a term that contains it; this is the so-called ''[[occurs check]]''.
# Two atoms can only be unified if they are identical.
# Similarly, a term can be unified with another term if the top function symbols and [[Arity|arities]] of the terms are identical and if the parameters can be unified simultaneously. Note that this is a recursive behavior.

=== Application: type inference ===

Unification is used during type inference, for instance in the functional programming language [[Haskell (programming language)|Haskell]]. On one hand, the programmer does not need to provide type information for every function, on the other hand it is used to detect typing errors. The Haskell expression &lt;code&gt;True : ['a', 'b', 'c']&lt;/code&gt; is not correctly typed. The list construction function &lt;code&gt;(:)&lt;/code&gt; is of type &lt;code&gt;a -&gt; [a] -&gt; [a]&lt;/code&gt;, and for the first argument &lt;code&gt;True&lt;/code&gt; the polymorphic type variable &lt;code&gt;a&lt;/code&gt; has to be unified with &lt;code&gt;True&lt;/code&gt;'s type, &lt;code&gt;Bool&lt;/code&gt;. The second argument, &lt;code&gt;['a', 'b', 'c']&lt;/code&gt;, is of type &lt;code&gt;[Char]&lt;/code&gt;, but &lt;code&gt;a&lt;/code&gt; cannot be both &lt;code&gt;Bool&lt;/code&gt; and &lt;code&gt;Char&lt;/code&gt; at the same time.

Like for Prolog, an algorithm for type inference can be given:

# Any type variable unifies with any type expression, and is instantiated to that expression.  A specific theory might restrict this rule with an occurs check.
# Two type constants unify only if they are the same type.
# Two type constructions unify only if they are applications of the same type constructor and all of their component types recursively unify.

Due to its declarative nature, the order in a sequence of unifications is (usually) unimportant.

Note that in the terminology of [[first-order logic]], an atom is a basic proposition and is unified similarly to a Prolog term.

==Order-sorted unification==
''[[Many-sorted logic#Order-sorted logic|Order-sorted logic]]'' allows one to assign a ''sort'', or ''type'', to each term, and to declare a sort ''s''&lt;sub&gt;1&lt;/sub&gt; a ''subsort'' of another sort ''s''&lt;sub&gt;2&lt;/sub&gt;, commonly written as ''s''&lt;sub&gt;1&lt;/sub&gt; ⊆ ''s''&lt;sub&gt;2&lt;/sub&gt;. For example, when reаsoning about biological creatures, it is useful to declare a sort ''dog'' to be a subsort of a sort ''animal''. Wherever a term of some sort ''s'' is required, a term of any subsort of ''s'' may be supplied instead.
For example, assuming a function declaration ''mother'': ''animal'' → ''animal'', and a constant declaration ''lassie'': ''dog'', the term  ''mother''(''lassie'') is perfectly valid and has the sort ''animal''. In order to supply the information that the mother of a dog is a dog in turn, another declaration ''mother'': ''dog'' → ''dog'' may be issued; this is called ''function overloading'', similar to [[Overloading (programming)|overloading in programming languages]].

[[Christoph Walther|Walther]] gave a unification algorithm for terms in order-sorted logic, requiring for any two declared sorts ''s''&lt;sub&gt;1&lt;/sub&gt;, ''s''&lt;sub&gt;2&lt;/sub&gt; their intersection ''s''&lt;sub&gt;1&lt;/sub&gt; ∩ ''s''&lt;sub&gt;2&lt;/sub&gt; to be declared, too: if ''x''&lt;sub&gt;1&lt;/sub&gt; and ''x''&lt;sub&gt;2&lt;/sub&gt; is a variable of sort ''s''&lt;sub&gt;1&lt;/sub&gt; and ''s''&lt;sub&gt;2&lt;/sub&gt;, respectively, the equation ''x''&lt;sub&gt;1&lt;/sub&gt; ≐ ''x''&lt;sub&gt;2&lt;/sub&gt; has the solution { ''x''&lt;sub&gt;1&lt;/sub&gt; = ''x'', ''x''&lt;sub&gt;2&lt;/sub&gt; = ''x'' }, where ''x'': ''s''&lt;sub&gt;1&lt;/sub&gt; ∩ ''s''&lt;sub&gt;2&lt;/sub&gt;.
&lt;ref&gt;{{cite journal|first1=Christoph|last1=Walther|authorlink=Christoph Walther|title=A Mechanical Solution of Schubert's Steamroller by Many-Sorted Resolution|journal=Artif. Intell.|volume=26|number=2|pages=217–224|url=http://www.inferenzsysteme.informatik.tu-darmstadt.de/media/is/publikationen/Schuberts_Steamroller_by_Many-Sorted_Resolution-AIJ-25-2-1985.pdf|year=1985|doi=10.1016/0004-3702(85)90029-3}}&lt;/ref&gt;
After incorporating this algorithm into a clause-based automated theorem prover, he could solve a benchmark problem by translating it into order-sorted logic, thereby boiling it down an order of magnitude, as many unary predicates turned into sorts.

Smolka generalized order-sorted logic to allow for [[parametric polymorphism]].
&lt;ref&gt;{{cite conference|first1=Gert|last1=Smolka|title=Logic Programming with Polymorphically Order-Sorted Types|conference=Int. Workshop Algebraic and Logic Programming|publisher=Springer|series=LNCS|volume=343|pages=53–70|date=Nov 1988|url=https://link.springer.com/content/pdf/10.1007/3-540-50667-5_58.pdf}}&lt;/ref&gt;
In his framework, subsort declarations are propagated to complex type expressions.
As a programming example, a parametric sort ''list''(''X'') may be declared (with ''X'' being a type parameter as in a [[Template (C++)#Function templates|C++ template]]), and from a subsort declaration ''int'' ⊆ ''float'' the relation ''list''(''int'') ⊆ ''list''(''float'') is automatically inferred, meaning that each list of integers is also a list of floats.

Schmidt-Schauß generalized order-sorted logic to allow for term declarations.
&lt;ref&gt;{{cite book|first1=Manfred|last1=Schmidt-Schauß|title=Computational Aspects of an Order-Sorted Logic with Term Declarations|publisher=Springer|series=LNAI|volume=395|date=Apr 1988}}&lt;/ref&gt;
As an example, assuming subsort declarations ''even'' ⊆ ''int'' and ''odd'' ⊆ ''int'', a term declaration like ∀ ''i'' : ''int''. (''i'' + ''i'') : ''even'' allows to declare a property of integer addition that could not be expressed by ordinary overloading.

==Unification of infinite terms==

Background on infinite trees:
* {{cite journal| author=B. Courcelle| authorlink=Bruno Courcelle| title=Fundamental Properties of Infinite Trees| journal=Theoret. Comput. Sci.| year=1983| volume=25| number=| pages=95–169| url=http://www.diku.dk/hjemmesider/ansatte/henglein/papers/courcelle1983.pdf| doi=10.1016/0304-3975(83)90059-2| access-date=2013-06-28| archive-url=https://web.archive.org/web/20140421082433/http://www.diku.dk/hjemmesider/ansatte/henglein/papers/courcelle1983.pdf| archive-date=2014-04-21| dead-url=yes| df=}}
* {{cite book| author=Michael J. Maher| chapter=Complete Axiomatizations of the Algebras of Finite, Rational and Infinite Trees| title=Proc. IEEE 3rd Annual Symp. on Logic in Computer Science, Edinburgh|date=Jul 1988| pages=348–357}}
* {{cite journal|author1=Joxan Jaffar |author2=Peter J. Stuckey | title=Semantics of Infinite Tree Logic Programming| journal=Theoretical Computer Science| year=1986| volume=46| pages=141–158| doi=10.1016/0304-3975(86)90027-7}}

Unification algorithm, Prolog II:
* {{cite book| author=A. Colmerauer| authorlink=Alain Colmerauer|title=Prolog and Infinite Trees| year=1982| pages=| publisher=Academic Press|editor1=K.L. Clark |editor2=S.-A. Tarnlund }}
* {{cite book| author=Alain Colmerauer| chapter=Equations and Inequations on Finite and Infinite Trees| title=Proc. Int. Conf. on Fifth Generation Computer Systems| year=1984| pages=85–99| editor=ICOT}}

Applications:
* {{cite journal|author1=Francis Giannesini |author2=Jacques Cohen | title=Parser Generation and Grammar Manipulation using Prolog's Infinite Trees| journal=J. Logic Programming| year=1984| volume=3| pages=253–265|url=http://www.sciencedirect.com/science/article/pii/074310668490013X| doi=10.1016/0743-1066(84)90013-X}}

==E-unification==

'''E-unification''' is the problem of finding solutions to a given set of [[equations]],
taking into account some equational background knowledge ''E''.
The latter is given as a set of universal [[Equality (mathematics)|equalities]].
For some particular sets ''E'', equation solving [[algorithms]] (a.k.a. ''E-unification algorithms'') have been devised;
for others it has been proven that no such algorithms can exist.

For example, if {{mvar|a}} and {{mvar|b}} are distinct constants,
the [[equation]] {{tmath|x * a \doteq y * b}} has no solution
with respect to purely [[Unification (computer science)#Syntactic unification problem on first-order terms|syntactic unification]],
where nothing is known about the operator {{tmath|*}}.
However, if the {{tmath|*}} is known to be [[Commutativity|commutative]],
then the substitution {{math|{{mset|''x'' ↦ ''b'', ''y'' ↦ ''a''}}}} solves the above equation,
since
:{|
|
| {{tmath|x * a}}
| {{math|{{mset|''x'' ↦ ''b'', ''y'' ↦ ''a''}}}}
|-
| {{=}}
| {{tmath|b * a}}
|
| by [[Unification (computer science)#Substitution|substitution application]]
|-
| {{=}}
| {{tmath|a * b}}
|
| by commutativity of {{tmath|*}}
|-
| {{=}}
| {{tmath|y * b}}
| {{math|{{mset|''x'' ↦ ''b'', ''y'' ↦ ''a''}}}}
| by (converse) substitution application
|}
The background knowledge ''E'' could state the commutativity of {{tmath|*}} by the universal equality
"{{tmath|1=u * v = v * u}} for all {{math|''u'', ''v''}}".

===Particular background knowledge sets E===

{|
|+ '''Used naming conventions'''
| {{math|∀ ''u'',''v'',''w'':}}
| align="right" | {{tmath|u*(v*w)}}
| {{=}}
| {{tmath|(u*v)*w}}
| align="center" | '''{{mvar|A}}'''
| Associativity of {{tmath|*}}
|-
| {{math|∀ ''u'',''v'':}}
| align="right" | {{tmath|u*v}}
| =
| {{tmath|v*u}}
| align="center" | '''{{mvar|C}}'''
| Commutativity of {{tmath|*}}
|-
| {{math|∀ ''u'',''v'',''w'':}}
| align="right" | {{tmath|u*(v+w)}}
| {{=}}
| {{tmath|u*v+u*w}}
| align="center" | '''{{mvar|D&lt;sub&gt;l&lt;/sub&gt;}}'''
| Left distributivity of {{tmath|*}} over {{tmath|+}}
|-
| {{math|∀ ''u'',''v'',''w'':}}
| align="right" | {{tmath|(v+w)*u}}
| {{=}}
| {{tmath|v*u+w*u}}
| align="center" | '''{{mvar|D&lt;sub&gt;r&lt;/sub&gt;}}'''
| Right distributivity of {{tmath|*}} over {{tmath|+}}
|-
| {{math|∀ ''u'':}}
| align="right" | {{tmath|u*u}}
| {{=}}
| {{mvar|u}}
| align="center" | '''{{mvar|I}}'''
| Idempotence of {{tmath|*}}
|-
| {{math|∀ ''u'':}}
| align="right" | {{tmath|n*u}}
| {{=}}
| {{mvar|u}}
| align="center" | '''{{mvar|N&lt;sub&gt;l&lt;/sub&gt;}}'''
| Left neutral element {{mvar|n}} with respect to {{tmath|*}}
|-
| {{math|∀ ''u'':}}
| align="right" | {{tmath|u*n}}
| {{=}}
| {{mvar|u}}
| align="center" | &amp;nbsp; &amp;nbsp; '''{{mvar|N&lt;sub&gt;r&lt;/sub&gt;}}''' &amp;nbsp; &amp;nbsp;
| Right neutral element {{mvar|n}} with respect to {{tmath|*}}
|}

It is said that ''unification is decidable'' for a theory, if a unification algorithm has been devised for it that terminates for ''any'' input problem.
It is said that ''unification is [[Decidable problem#Decidability|semi-decidable]]'' for a theory, if a unification algorithm has been devised for it that terminates for any ''solvable'' input problem, but may keep searching forever for solutions of an unsolvable input problem.

'''Unification is decidable''' for the following theories:
* '''{{mvar|A}}'''&lt;ref&gt;[[Gordon D. Plotkin]], ''Lattice Theoretic Properties of Subsumption'', Memorandum MIP-R-77, Univ. Edinburgh, Jun 1970&lt;/ref&gt;
* '''{{mvar|A}}''','''{{mvar|C}}'''&lt;ref&gt;[[Mark E. Stickel]], ''A Unification Algorithm for Associative-Commutative Functions'', J. Assoc. Comput. Mach., vol.28, no.3, pp. 423–434, 1981&lt;/ref&gt;
* '''{{mvar|A}}''','''{{mvar|C}}''','''{{mvar|I}}'''&lt;ref name="Fages.1987"&gt;F. Fages, ''Associative-Commutative Unification'', J. Symbolic Comput., vol.3, no.3, pp. 257–275, 1987&lt;/ref&gt;
* '''{{mvar|A}}''','''{{mvar|C}}''','''{{mvar|N&lt;sub&gt;l&lt;/sub&gt;}}'''&lt;ref group=note name="LRequivC"&gt;in the presence of equality '''{{mvar|C}}''', equalities '''{{mvar|N&lt;sub&gt;l&lt;/sub&gt;}}''' and '''{{mvar|N&lt;sub&gt;r&lt;/sub&gt;}}''' are equivalent, similar for '''{{mvar|D&lt;sub&gt;l&lt;/sub&gt;}}''' and '''{{mvar|D&lt;sub&gt;r&lt;/sub&gt;}}'''&lt;/ref&gt;&lt;ref name="Fages.1987"/&gt;
* '''{{mvar|A}}''','''{{mvar|I}}'''&lt;ref&gt;Franz Baader, ''Unification in Idempotent Semigroups is of Type Zero'', J. Automat. Reasoning, vol.2, no.3, 1986&lt;/ref&gt;
* '''{{mvar|A}}''','''{{mvar|N&lt;sub&gt;l&lt;/sub&gt;}}'''{{mvar|,}}'''{{mvar|N&lt;sub&gt;r&lt;/sub&gt;}}''' (monoid)&lt;ref&gt;J. Makanin, ''The Problem of Solvability of Equations in a Free Semi-Group'', Akad. Nauk SSSR, vol.233, no.2, 1977&lt;/ref&gt;
* '''{{mvar|C}}'''&lt;ref&gt;{{cite journal| author=F. Fages| title=Associative-Commutative Unification| journal=J. Symbolic Comput.| year=1987| volume=3| number=3| pages=257–275| doi=10.1016/s0747-7171(87)80004-4}}&lt;/ref&gt;
* [[Boolean ring]]s&lt;ref&gt;{{cite book| author=Martin, U., Nipkow, T.| chapter=Unification in Boolean Rings| title=Proc. 8th CADE| year=1986| volume=230| pages=506–513| publisher=Springer| editor=Jörg H. Siekmann| series=LNCS}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=A. Boudet |author2=J.P. Jouannaud |author3=M. Schmidt-Schauß | title=Unification of Boolean Rings and Abelian Groups| journal=Journal of Symbolic Computation| year=1989| volume=8| pages=449–477 |url=http://www.sciencedirect.com/science/article/pii/S0747717189800549/pdf?md5=713ed362e4b6f2db53923cc5ed47c818&amp;pid=1-s2.0-S0747717189800549-main.pdf| doi=10.1016/s0747-7171(89)80054-9}}&lt;/ref&gt;
* [[Abelian group]]s, even if the signature is expanded by arbitrary additional symbols (but not axioms)&lt;ref name="Baader and Snyder 2001, p. 486"&gt;Baader and Snyder (2001), p. 486.&lt;/ref&gt;
* [[Kripke semantics#Correspondence and completeness|K4]] [[modal algebra]]s&lt;ref&gt;F. Baader and S. Ghilardi, ''[https://pdfs.semanticscholar.org/492e/9f03ab7abd043ed0167dc7309552d21a88ef.pdf Unification in modal and description logics]'', Logic Journal of the IGPL 19 (2011), no.&amp;nbsp;6, pp.&amp;nbsp;705–730.&lt;/ref&gt;

'''Unification is semi-decidable''' for the following theories:
* '''{{mvar|A}}''','''{{mvar|D&lt;sub&gt;l&lt;/sub&gt;}}'''{{mvar|,}}'''{{mvar|D&lt;sub&gt;r&lt;/sub&gt;}}'''&lt;ref&gt;P. Szabo, ''Unifikationstheorie erster Ordnung'' (''First Order Unification Theory''), Thesis, Univ. Karlsruhe, West Germany, 1982&lt;/ref&gt;
* '''{{mvar|A}}''','''{{mvar|C}}''','''{{mvar|D&lt;sub&gt;l&lt;/sub&gt;}}'''&lt;ref group=note name="LRequivC"/&gt;&lt;ref&gt;Jörg H. Siekmann, ''Universal Unification'', Proc. 7th Int. Conf. on Automated Deduction, Springer LNCS vol.170, pp. 1–42, 1984&lt;/ref&gt;
* [[Commutative ring]]s&lt;ref name="Baader and Snyder 2001, p. 486"/&gt;

===One-sided paramodulation===

If there is a [[Term rewriting#Termination and convergence|convergent term rewriting system]] ''R'' available for ''E'',
the '''one-sided paramodulation''' algorithm&lt;ref&gt;N. Dershowitz and G. Sivakumar, ''Solving Goals in Equational Languages'', Proc. 1st Int. Workshop on Conditional Term Rewriting Systems, Springer LNCS vol.308, pp. 45–55, 1988&lt;/ref&gt;
can be used to enumerate all solutions of given equations.

{| style="border: 1px solid darkgray;"
|+ One-sided paramodulation rules
|- border="0"
| align="right" | ''G'' ∪ { ''f''(''s''&lt;sub&gt;1&lt;/sub&gt;,...,''s''&lt;sub&gt;''n''&lt;/sub&gt;) ≐ ''f''(''t''&lt;sub&gt;1&lt;/sub&gt;,...,''t''&lt;sub&gt;''n''&lt;/sub&gt;) }
| ; ''S''
| ⇒
| align="right" | ''G'' ∪ { ''s''&lt;sub&gt;1&lt;/sub&gt; ≐ ''t''&lt;sub&gt;1&lt;/sub&gt;, ..., ''s''&lt;sub&gt;''n''&lt;/sub&gt; ≐ ''t''&lt;sub&gt;''n''&lt;/sub&gt; }
| ''; ''S''
|
| &amp;nbsp; &amp;nbsp; '''decompose'''
|-
| align="right" | ''G'' ∪ { ''x'' ≐ ''t'' }
| ; ''S''
| ⇒
| align="right" | ''G'' { ''x'' ↦ ''t'' }
|; ''S''{''x''↦''t''} ∪ {''x''↦''t''}
| align="right" | if the variable ''x'' doesn't occur in ''t''
| &amp;nbsp; &amp;nbsp; '''eliminate'''
|-
| align="right" | ''G'' ∪ { ''f''(''s''&lt;sub&gt;1&lt;/sub&gt;,...,''s''&lt;sub&gt;''n''&lt;/sub&gt;) ≐ ''t'' }
| ; ''S''
| ⇒
| align="right" | ''G'' ∪ { ''s''&lt;sub&gt;1&lt;/sub&gt; ≐ u&lt;sub&gt;1&lt;/sub&gt;, ..., ''s''&lt;sub&gt;''n''&lt;/sub&gt; ≐ u&lt;sub&gt;''n''&lt;/sub&gt;, ''r'' ≐ ''t'' }
| ; ''S''
| align="right" | &amp;nbsp; &amp;nbsp; if ''f''(''u''&lt;sub&gt;1&lt;/sub&gt;,...,''u''&lt;sub&gt;''n''&lt;/sub&gt;) → ''r'' is a rule from ''R''
| &amp;nbsp; &amp;nbsp; '''mutate'''
|-
| align="right" | ''G'' ∪ { ''f''(''s''&lt;sub&gt;1&lt;/sub&gt;,...,''s''&lt;sub&gt;''n''&lt;/sub&gt;) ≐ ''y'' }
| ; ''S''
|⇒
| align="right" | ''G'' ∪ { ''s''&lt;sub&gt;1&lt;/sub&gt; ≐ ''y''&lt;sub&gt;1&lt;/sub&gt;, ..., ''s''&lt;sub&gt;''n''&lt;/sub&gt; ≐ ''y''&lt;sub&gt;''n''&lt;/sub&gt;, ''y'' ≐ ''f''(''y''&lt;sub&gt;1&lt;/sub&gt;,...,''y''&lt;sub&gt;''n''&lt;/sub&gt;) }
| ; ''S''
| align="right" | if ''y''&lt;sub&gt;1&lt;/sub&gt;,...,''y''&lt;sub&gt;''n''&lt;/sub&gt; are new variables
| &amp;nbsp; &amp;nbsp; '''imitate'''
|}

Starting with ''G'' being the unification problem to be solved and ''S'' being the identity substitution, rules are applied nondeterministically until the empty set appears as the actual ''G'', in which case the actual ''S'' is a unifying substitution. Depending on the order the paramodulation rules are applied, on the choice of the actual equation from ''G'', and on the choice of ''R''’s rules in ''mutate'', different computations paths are possible. Only some lead to a solution, while others end at a ''G'' ≠ {} where no further rule is applicable (e.g. ''G'' = { ''f''(...) ≐ ''g''(...) }).

{| style="border: 1px solid darkgray;"
|+ Example term rewrite system ''R''
|- border="0"
| '''1'''
| ''app''(''nil'',''z'')
| → ''z''
|-
|'''2''' &amp;nbsp; &amp;nbsp;
| ''app''(''x''.''y'',''z'')
| → ''x''.''app''(''y'',''z'')
|}

For an example, a term rewrite system ''R'' is used defining the ''append'' operator of lists built from ''cons'' and ''nil''; where ''cons''(''x'',''y'') is written in infix notation as ''x''.''y'' for brevity; e.g. ''app''(''a''.''b''.''nil'',''c''.''d''.''nil'') → ''a''.''app''(''b''.''nil'',''c''.''d''.''nil'') → ''a''.''b''.''app''(''nil'',''c''.''d''.''nil'') → ''a''.''b''.''c''.''d''.''nil'' demonstrates the concatenation of the lists ''a''.''b''.''nil'' and ''c''.''d''.''nil'', employing the rewrite rule 2,2, and 1. The equational theory ''E'' corresponding to ''R'' is the [[Closure (mathematics)#P closures of binary relations|congruence closure]] of ''R'', both viewed as binary relations on terms.
For example, ''app''(''a''.''b''.''nil'',''c''.''d''.''nil'') ≡ ''a''.''b''.''c''.''d''.''nil'' ≡ ''app''(''a''.''b''.''c''.''d''.''nil'',''nil''). The paramodulation algorithm enumerates solutions to equations with respect to that ''E'' when fed with the example ''R''.

A successful example computation path for the unification problem { ''app''(''x'',''app''(''y'',''x'')) ≐ ''a''.''a''.''nil'' } is shown below. To avoid variable name clashes, rewrite rules are consistently renamed each time before their use by rule ''mutate''; ''v''&lt;sub&gt;2&lt;/sub&gt;, ''v''&lt;sub&gt;3&lt;/sub&gt;, ... are computer-generated variable names for this purpose. In each line, the chosen equation from ''G'' is highlighted in red. Each time the ''mutate'' rule is applied, the chosen rewrite rule (''1'' or ''2'') is indicated in parentheses. From the last line, the unifying substitution ''S'' = { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' } can be obtained. In fact,
''app''(''x'',''app''(''y'',''x'')) {''y''↦''nil'', ''x''↦ ''a''.''nil'' } = ''app''(''a''.''nil'',''app''(''nil'',''a''.''nil'')) ≡ ''app''(''a''.''nil'',''a''.''nil'') ≡ ''a''.''app''(''nil'',''a''.''nil'') ≡ ''a''.''a''.''nil'' solves the given problem.
A second successful computation path, obtainable by choosing "mutate(1), mutate(2), mutate(2), mutate(1)" leads to the substitution ''S'' = { ''y'' ↦ ''a''.''a''.''nil'', ''x'' ↦ ''nil'' }; it is not shown here. No other path leads to a success.

{| class="wikitable"
|+ Example unifier computation
|-
! Used rule !!  !! ''G'' !! ''S''
|-
| ||
| { {{color|red|''app''(''x'',''app''(''y'',''x'')) ≐ ''a''.''a''.''nil''}} }
| {}
|-
| mutate(2) || ⇒
| { ''x'' ≐ ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;, ''app''(''y'',''x'') ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, {{color|red|''v''&lt;sub&gt;2&lt;/sub&gt;.''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''a''.''nil''}} }
| {}
|-
| decompose || ⇒
| { {{color|red|''x'' ≐ ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;}}, ''app''(''y'',''x'') ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt; ≐ ''a'', ''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil'' }
| {}
|-
| eliminate || ⇒
| { ''app''(''y'',''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;) ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, {{color|red|''v''&lt;sub&gt;2&lt;/sub&gt; ≐ ''a''}}, ''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil'' }
| { ''x'' ↦  ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| eliminate || ⇒
| { {{color|red|''app''(''y'',''a''.''v''&lt;sub&gt;3&lt;/sub&gt;) ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;}}, ''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil'' }
| { ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| mutate(1) || ⇒
| { ''y'' ≐ ''nil'', ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''v''&lt;sub&gt;5&lt;/sub&gt;, {{color|red|''v''&lt;sub&gt;5&lt;/sub&gt; ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;}}, ''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil'' }
| { ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| eliminate || ⇒
| { {{color|red|''y'' ≐ ''nil''}}, ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, ''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil'' }
| { ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| eliminate || ⇒
| { ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, {{color|red|''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''v''&lt;sub&gt;4&lt;/sub&gt;) ≐ ''a''.''nil''}} }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| mutate(1) || ⇒
| { ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, ''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''nil'', {{color|red|''v''&lt;sub&gt;4&lt;/sub&gt; ≐ ''v''&lt;sub&gt;6&lt;/sub&gt;}}, ''v''&lt;sub&gt;6&lt;/sub&gt; ≐ ''a''.''nil'' }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| eliminate || ⇒
| { ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, {{color|red|''v''&lt;sub&gt;3&lt;/sub&gt; ≐ ''nil''}}, ''v''&lt;sub&gt;4&lt;/sub&gt; ≐ ''a''.''nil'' }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''v''&lt;sub&gt;3&lt;/sub&gt; }
|-
| eliminate || ⇒
| { ''a''.''nil'' ≐ ''v''&lt;sub&gt;4&lt;/sub&gt;, {{color|red|''v''&lt;sub&gt;4&lt;/sub&gt; ≐ ''a''.''nil''}} }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' }
|-
| eliminate || ⇒
| { {{color|red|''a''.''nil'' ≐ ''a''.''nil''}} }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' }
|-
| decompose || ⇒
| { {{color|red|''a'' ≐ ''a''}}, ''nil'' ≐ ''nil'' }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' }
|-
| decompose || ⇒
| { {{color|red|''nil'' ≐ ''nil''}} }
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' }
|-
| decompose &amp;nbsp; &amp;nbsp; || ⇒ &amp;nbsp; &amp;nbsp;
| {}
| { ''y'' ↦ ''nil'', ''x'' ↦  ''a''.''nil'' }
|}

===Narrowing===

[[File:Triangle diagram of narrowing step svg.svg|thumb|Triangle diagram of narrowing step ''s'' ~› ''t'' at position ''p'' in term ''s'', with unifying substitution σ (bottom row), using a rewrite rule {{math|1=''l'' → ''r''}} (top row)]]
If ''R'' is a [[Term rewriting#Termination and convergence|convergent term rewriting system]] for ''E'',
an approach alternative to the previous section consists in successive application of "'''narrowing steps'''";
this will eventually enumerate all solutions of a given equation.
A narrowing step (cf. picture) consists in
* choosing a nonvariable subterm of the current term,
* [[#Syntactic unification of first-order terms|syntactically unifying]] it with the left hand side of a rule from ''R'', and
* replacing the instantiated rule's right hand side into the instantiated term.
Formally, if {{math|''l'' → ''r''}} is a [[Term (logic)#Structural equality|renamed copy]] of a rewrite rule from ''R'', having no variables in common with a term ''s'', and the [[Term (logic)#Operations with terms|subterm]] {{math|''s''{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}} is not a variable and is unifiable with {{mvar|l}} via the [[#Syntactic unification of first-order terms|mgu]] {{mvar|σ}}, then {{mvar|s}} can be '''narrowed''' to the term {{math|1=''t'' = ''sσ''[''rσ'']&lt;sub&gt;''p''&lt;/sub&gt;}}, i.e. to the term {{mvar|sσ}}, with the subterm at ''p'' [[Term (logic)#Operations with terms|replaced]] by {{mvar|rσ}}. The situation that ''s'' can be narrowed to ''t'' is commonly denoted as ''s'' ~› ''t''.
Intuitively, a sequence of narrowing steps ''t''&lt;sub&gt;1&lt;/sub&gt; ~› ''t''&lt;sub&gt;2&lt;/sub&gt; ~› ... ~› ''t''&lt;sub&gt;''n''&lt;/sub&gt; can be thought of as a sequence of rewrite steps ''t''&lt;sub&gt;1&lt;/sub&gt; → ''t''&lt;sub&gt;2&lt;/sub&gt; → ... → ''t''&lt;sub&gt;''n''&lt;/sub&gt;, but with the initial term ''t''&lt;sub&gt;1&lt;/sub&gt; being further and further instantiated, as necessary to make each of the used rules applicable.

The [[#One-sided paramodulation|above]] example paramodulation computation corresponds to the following narrowing sequence ("↓" indicating instantiation here):

{|
|-
| ''app''( || ''x'' || ,''app''(''y'', || ''x'' || ))
|-
|     ||  ↓  ||  ||  ↓  ||   ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ||  ''x'' ↦ ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;
|-
| ''app''( || ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt; || ,''app''(''y'', || ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt; || ))  ||  →  ||  ''v''&lt;sub&gt;2&lt;/sub&gt;.''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''app''( || ''y'' || ,''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;))
|-
|     ||         ||         ||         ||     ||                   ||                   ||  ↓  ||  ||  ||  ||  ||  ||  ||  ||    ||  ||  ''y'' ↦ ''nil''
|-
|     ||         ||         ||         ||     ||                   ||  ''v''&lt;sub&gt;2&lt;/sub&gt;.''app''(''v''&lt;sub&gt;3&lt;/sub&gt;,''app''( || ''nil'' || ,''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;3&lt;/sub&gt;))  ||  →  ||  ''v''&lt;sub&gt;2&lt;/sub&gt;.''app''( || ''v''&lt;sub&gt;3&lt;/sub&gt; || ,''v''&lt;sub&gt;2&lt;/sub&gt;. || ''v''&lt;sub&gt;3&lt;/sub&gt; || )
|-
|     ||         ||         ||         ||     ||                   ||                   ||     ||             ||                   ||           ||  ↓  ||   ||  ↓  ||  ||  ||  ||  ''v''&lt;sub&gt;3&lt;/sub&gt; ↦ ''nil''
|-
|     ||         ||         ||         ||     ||                   ||                   ||     ||             ||                   ||  ''v''&lt;sub&gt;2&lt;/sub&gt;.''app''( || ''nil'' || ,''v''&lt;sub&gt;2&lt;/sub&gt;. || ''nil'' || )  ||  →  ||  ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;2&lt;/sub&gt;.''nil''
|}

The last term, ''v''&lt;sub&gt;2&lt;/sub&gt;.''v''&lt;sub&gt;2&lt;/sub&gt;.''nil'' can be syntactically unified with the original right hand side term ''a''.''a''.''nil''.

The ''narrowing lemma''&lt;ref&gt;{{cite book| author=Fay| chapter=First-Order Unification in an Equational Theory| title=Proc. 4th Workshop on Automated Deduction| year=1979| pages=161–167}}&lt;/ref&gt; ensures that whenever an instance of a term ''s'' can be rewritten to a term ''t'' by a convergent term rewriting system, then ''s'' and ''t'' can be narrowed and rewritten to a term {{math|1=''s''’}} and {{math|1=''t''’}}, respectively, such that {{math|1=''t''’}} is an instance of {{math|1=''s''’}}.

Formally: whenever {{math|1=''sσ'' {{underset|&amp;lowast;|&amp;rarr;}} ''t''}} holds for some substitution σ, then there exist terms {{math|''s''’, ''t''’}} such that {{math|''s'' {{underset|&amp;lowast;|~›}} ''s''’}} and {{math|''t'' {{underset|&amp;lowast;|&amp;rarr;}} ''t''’}} and {{math|1=''s''’''τ'' = ''t''’}} for some substitution τ.

==Higher-order unification==

Many applications require one to consider the unification of typed lambda-terms instead of first-order terms.  Such unification is often called ''higher-order unification''.  A well studied branch of higher-order unification is the problem of unifying simply typed lambda terms modulo the equality determined by αβη conversions.  Such unification problems do not have most general unifiers.  While higher-order unification is [[Undecidable problem|undecidable]],&lt;ref&gt;{{cite journal| author=Warren D. Goldfarb| authorlink=Warren D. Goldfarb| title=The Undecidability of the Second-Order Unification Problem| journal=TCS| year=1981| volume=13| pages=225–230| url=http://www.sciencedirect.com/science/article/pii/0304397581900402/pdf?md5=ebe7687d034498bb76c4ea9c5df56f84&amp;pid=1-s2.0-0304397581900402-main.pdf| doi=10.1016/0304-3975(81)90040-2}}&lt;/ref&gt;&lt;ref&gt;{{cite journal| author=Gérard P. Huet| title=The Undecidability of Unification in Third Order Logic| journal=Information and Control| year=1973| volume=22| pages=257–267 |url=http://www.sciencedirect.com/science/article/pii/S001999587390301X/pdf?md5=0833289609c3d777bdec01d5d6ced2aa&amp;pid=1-s2.0-S001999587390301X-main.pdf |doi=10.1016/S0019-9958(73)90301-X}}&lt;/ref&gt;&lt;ref&gt;Claudio Lucchesi: The Undecidability of the Unification Problem for Third Order Languages (Research Report CSRR 2059; Department of Computer Science, University of Waterloo, 1972)&lt;/ref&gt; [[Gérard Huet]] gave a [[semi-decidable]] (pre-)unification algorithm&lt;ref&gt;Gérard Huet: A Unification Algorithm for typed Lambda-Calculus []&lt;/ref&gt; that allows a systematic search of the space of unifiers (generalizing the unification algorithm of Martelli-Montanari&lt;ref name="Martelli.Montanari.1982"/&gt; with rules for terms containing higher-order variables) that seems to work sufficiently well in practice.  Huet&lt;ref&gt;[http://portal.acm.org/citation.cfm?id=695200 Gérard Huet: Higher Order Unification 30 Years Later]&lt;/ref&gt; and Gilles Dowek&lt;ref&gt;Gilles Dowek: Higher-Order Unification and Matching. Handbook of Automated Reasoning 2001: 1009–1062&lt;/ref&gt; have written articles surveying this topic.

[[Dale Miller (computer scientist)|Dale Miller]] has described what is now called ''higher-order pattern unification''.&lt;ref&gt;{{cite journal|first1=Dale|last1=Miller|title=A Logic Programming Language with Lambda-Abstraction, Function Variables, and Simple Unification|journal=Journal of Logic and Computation|year=1991|pages=497–536|url=http://www.lix.polytechnique.fr/Labo/Dale.Miller/papers/jlc91.pdf}}&lt;/ref&gt; This subset of higher-order unification is decidable and solvable unification problems have most-general unifiers.  Many computer systems that contain higher-order unification, such as the higher-order logic programming languages [[λProlog]] and [[Twelf]], often implement only the pattern fragment and not full higher-order unification.

In computational linguistics, one of the most influential theories of [[Elliptical construction|ellipsis]] is that ellipses are represented by free variables whose values are then determined using Higher-Order Unification (HOU). For instance, the semantic representation of "Jon likes Mary and Peter does too" is  {{math| like(''j'', ''m'') &amp;and; R(''p'') }} and the value of R (the semantic representation of the ellipsis) is determined by the equation {{math| like(''j'', ''m'') {{=}} R(''j'')  }}. The process of solving such equations is called Higher-Order Unification.&lt;ref&gt;{{cite book| first1 = Claire | last1 = Gardent | first2 = Michael | last2 = Kohlhase | first3 = Karsten | last3 = Konrad | author2link=Michael Kohlhase| chapter=A Multi-Level, Higher-Order Unification Approach to Ellipsis| title=Submitted to European [[Association for Computational Linguistics]] (EACL)&lt;!---according to http://page.mi.fu-berlin.de/cbenzmueller/papers/R8.pdf---&gt;| year=1997| volume=| pages=| publisher=| editor=| series=|citeseerx = 10.1.1.55.9018}}&lt;/ref&gt;

For example, the unification problem { ''f''(''a'',  ''b'', ''a'') ≐ ''d''(''b'', ''a'', ''c'') }, where the only variable is ''f'', has the
solutions {''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''y'', ''x'', ''c'')  }, {''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''y'', ''z'', ''c'')  },
{''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''y'', ''a'', ''c'')  }, {''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''b'', ''x'', ''c'')  },
{''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''b'', ''z'', ''c'')  } and {''f'' ↦ λ''x''.λ''y''.λ''z''.''d''(''b'', ''a'', ''c'')  }.

[[Wayne Snyder]] gave a generalization of both higher-order unification and E-unification, i.e. an algorithm to unify lambda-terms modulo an equational theory.&lt;ref&gt;{{cite book | author=Wayne Snyder | contribution=Higher order E-unification | title=Proc. 10th [[Conference on Automated Deduction]] | publisher=Springer | series=LNAI | volume=449 | pages=573–587 |date=Jul 1990 }}&lt;/ref&gt;

==See also==
*[[Rewriting]]
*[[Admissible rule]]
*[[Explicit substitution]] in [[lambda calculus]]
* Mathematical [[equation solving]]
* [[Dis-unification (computer science)|Dis-unification]]: solving inequations between symbolic expression
* [[Anti-unification (computer science)|Anti-unification]]: computing a least general generalization (lgg) of two terms, dual to computing a most general instance (mgu)
* [[Ontology alignment]] (use ''unification'' with [[semantic equivalence]])

==Notes==
{{Reflist|group=note}}

==References==
{{reflist}}

== Further reading ==
* [[Franz Baader]] and [[Wayne Snyder]] (2001). [http://www.cs.bu.edu/~snyder/publications/UnifChapter.pdf "Unification Theory"]. In [[John Alan Robinson]] and [[Andrei Voronkov]], editors, ''[[Handbook of Automated Reasoning]]'', volume I, pages 447–533. Elsevier Science Publishers.
* [[Gilles Dowek]] (2001). [https://who.rocq.inria.fr/Gilles.Dowek/Publi/unification.ps "Higher-order Unification and Matching"]{{Dead link|date=July 2018 |bot=InternetArchiveBot |fix-attempted=no }}. In ''Handbook of Automated Reasoning''.
* Franz Baader and [[Tobias Nipkow]] (1998). [http://www.in.tum.de/~nipkow/TRaAT/ ''Term Rewriting and All That'']. Cambridge University Press.
* Franz Baader and {{ill|Jörg H. Siekmann|de}} (1993). "Unification Theory". In ''Handbook of Logic in Artificial Intelligence and Logic Programming''.
* Jean-Pierre Jouannaud and [[Claude Kirchner]] (1991). "Solving Equations in Abstract Algebras: A Rule-Based Survey of Unification". In ''Computational Logic: Essays in Honor of Alan Robinson''.
* [[Nachum Dershowitz]] and [[Jean-Pierre Jouannaud]], ''Rewrite Systems'', in: [[Jan van Leeuwen]] (ed.), ''[[Handbook of Theoretical Computer Science]]'', volume B ''Formal Models and Semantics'', Elsevier, 1990, pp.&amp;nbsp;243–320
* Jörg H. Siekmann (1990). "Unification Theory". In [[Claude Kirchner]] (editor) ''Unification''. Academic Press.
* {{cite journal| author=Kevin Knight| title=Unification: A Multidisciplinary Survey| journal=ACM Computing Surveys|date=Mar 1989| volume=21| number=1| pages=93–124| url=http://www.isi.edu/natural-language/people/unification-knight.pdf| doi=10.1145/62029.62030}}
* [[Gérard Huet]] and [[Derek C. Oppen]] (1980). [http://infolab.stanford.edu/pub/cstr/reports/cs/tr/80/785/CS-TR-80-785.pdf "Equations and Rewrite Rules: A Survey"]. Technical report. Stanford University.
* {{cite journal | last1 = Raulefs | first1 = Peter | last2 = Siekmann | first2 = Jörg | last3 = Szabó | first3 = P. | last4 = Unvericht | first4 = E. | year = 1979 | title = A short survey on the state of the art in matching and unification problems | url = http://dl.acm.org/citation.cfm?id=1089210 | journal = ACM SIGSAM Bulletin | volume = 13 | issue = 2 }}
* Claude Kirchner and Hélène Kirchner. ''Rewriting, Solving, Proving''. In preparation.

[[Category:Automated theorem proving]]
[[Category:Logic programming]]
[[Category:Rewriting systems]]
[[Category:Logic in computer science]]
[[Category:Type theory]]
[[Category:Unification (computer science)| ]]</text>
      <sha1>kaug1zpeeke9jqovhham9l4dit12c58</sha1>
    </revision>
  </page>
  <page>
    <title>Vector notation</title>
    <ns>0</ns>
    <id>5959843</id>
    <revision>
      <id>840567795</id>
      <parentid>810884863</parentid>
      <timestamp>2018-05-10T18:20:01Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* Polar vectors */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20562">{|align=right  style="clear:right;"
|-
! style="color:#black; background:#dddddd; font-size:100%; text-align:center;" colspan="2"|Vector notation
|-
|
&lt;gallery&gt;
Image:vector from A to B.svg|Vector arrow&lt;br /&gt;&lt;small&gt;Pointing from ''A'' to ''B''&lt;/small&gt;
File:Vector components.svg|[[Vector component]]s&lt;br /&gt;&lt;small&gt;Describing an arrow vector '''v''' by its coordinates ''x'' and ''y'' yields an [[isomorphism]] of vector spaces.&lt;/small&gt;
&lt;/gallery&gt;
|-
|
&lt;gallery&gt;
File:Dot Product.svg|[[Scalar product]]&lt;br /&gt;&lt;small&gt;Two equal-length sequences of coordinate vectors and returns a single number&lt;/small&gt;
Image:Cross product vector.svg|[[Vector product]]&lt;br /&gt;&lt;small&gt;The cross-product in respect to a right-handed coordinate system&lt;/small&gt;
&lt;/gallery&gt;
|}

'''Vector notation'''&lt;ref&gt;{{cite book |title=Principles and Applications of Mathematics for Communications-electronics |page=123 |url=https://books.google.com/books?id=yNUXAAAAYAAJ&amp;pg=PA123 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Notes on fundamentals of telephone transmission |publisher=American Telephone and Telegraph Company. Dept. of development and research |page=50 |url=https://books.google.com/books?id=WmdMAAAAMAAJ&amp;pg=PA50 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Electrical World |volume=57 |publisher=McGraw-Hill |year=1911 |page=705 |url=https://books.google.com/books?id=NHYfAQAAMAAJ&amp;pg=PA705 }}&lt;/ref&gt; is a commonly used [[mathematical notation]] for working with mathematical vectors,&lt;ref&gt;{{cite book |title=Vector Analysis |first=Joseph George |last=Coffin |authorlink=Joseph George Coffin |url=https://books.google.com/books?id=7agAAAAAMAAJ }}&lt;/ref&gt; which may be [[vector (geometric)|geometric vectors]] or [[Element (mathematics)|member]]s of [[vector space]]s.

For representing a vector,&lt;ref&gt;[[Oliver Heaviside]], The Electrical Journal, Volume 28. James Gray, 1892. [https://books.google.com/books?id=we4fAQAAMAAJ&amp;pg=PA109 109] ([https://books.google.com/books?id=nRJbAAAAYAAJ&amp;pg=PA109 alt])&lt;/ref&gt;&lt;ref&gt;[[Charles Proteus Steinmetz]], Theory and Calculation of Alternating Current Phenomena.&lt;/ref&gt; the common [[typographic|typographic convention]]  is lower case, upright boldface type, as in &lt;math&gt;\mathbf{v}&lt;/math&gt; for a vector named ‘v’.  The [[International Organization for Standardization]] (ISO) recommends either bold italic serif, as in &lt;span style="font-family: serif; font-size: normal; font-weight: bold; font-style: italic"&gt;v&lt;/span&gt; or &lt;span style="font-family: serif; font-size: normal; font-weight: bold; font-style: italic"&gt;a&lt;/span&gt;, or non-bold italic serif accented by a right arrow, as in [[Velocity|&lt;math&gt;\vec{v}&lt;/math&gt;]] or [[Acceleration|&lt;math&gt;\vec{a}&lt;/math&gt;]].&lt;ref&gt;{{cite web |url=http://www.iso.org/iso/home/store/catalogue_tc/catalogue_detail.htm?csnumber=31887 |title=ISO 80000-2:2009 Quantities and Units—Part 2: Mathematical signs and symbols to be used in the natural sciences and technology |date=2009-12-01 |publisher=International Organization for Standardization}}&lt;/ref&gt; This arrow notation for vectors is commonly used in handwriting, where boldface is impractical. The arrow represents [[Euclidean vector|right-pointing arrow notation or harpoons]]. [[Shorthand|Shorthand notation]]s include [[tildes]] and [[Macron (diacritic)|straight line]]s placed respectively, below or above the name of a vector.

Between 1880 and 1887, [[Oliver Heaviside]] developed [[operator theory|operational calculus]],&lt;ref&gt;[http://www.quadritek.com/bstj/vol01-1922/articles/bstj1-2-43.pdf The Heaviside Operational Calculus] www.quadritek.com/bstj/vol01-1922/articles/bstj1-2-43.pdf&lt;/ref&gt;&lt;ref&gt;Involving the ''D'' notation for the [[differential operator]], which he is credited with creating.&lt;/ref&gt; a method of solving differential equations by transforming them into ordinary [[algebraic equation]]s which caused much controversy when introduced because of the lack of [[rigour]] in its derivation.&lt;ref&gt;He famously said, "Mathematics is an [[experimental science]], and [[Elementary definition|definitions]] do not come first, but later on."  He was replying to criticism over his use of [[Operator (mathematics)|operators]] that were [[Elementary sentence|not clearly defined]]. On another occasion he stated somewhat more defensively, "I do not refuse my dinner simply because I do not understand the process of digestion."&lt;/ref&gt; After the turn of the 20th century, [[Josiah Willard Gibbs]] would in [[physical chemistry]] supply notation for the [[scalar product]] and [[vector product]]s, which was introduced in ''[[Vector Analysis (Gibbs/Wilson)|Vector Analysis]]''.

==Rectangular vectors==
[[File:Rectangle Geometry Vector.svg|thumb|Rectangle]]
[[File:Cuboid simple.svg|thumb|Rectangular cuboid]]
A rectangular vector is a [[coordinate vector]] specified by components that define a [[rectangle]] (or [[rectangular prism]] in three dimensions, and similar shapes in greater dimensions).  The starting point and terminal point of the vector lie at opposite ends of the rectangle (or prism, etc.).

===Ordered set notation===
A rectangular vector in [[real coordinate space|&lt;math&gt;\mathbb{R}^n&lt;/math&gt;]] can be specified using an ordered [[Set (mathematics)|set]] of components, enclosed in either parentheses or angle brackets.

In a general sense, an ''n''-dimensional vector '''v''' can be specified in either of the following forms:

*&lt;math&gt;\mathbf{v} = (v_1, v_2, \dots, v_{n - 1}, v_n)&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \langle v_1, v_2, \dots, v_{n - 1}, v_n \rangle&lt;/math&gt;

Where ''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, …, ''v''&lt;sub&gt;''n''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;, ''v''&lt;sub&gt;''n''&lt;/sub&gt; are the components of '''v'''.

===Matrix notation===
A rectangular vector in &lt;math&gt;\mathbb{R}^n&lt;/math&gt; can also be specified as a row or column [[matrix (mathematics)|matrix]] containing the ordered set of components.  A vector specified as a row matrix is known as a [[row vector]]; one specified as a column matrix is known as a [[column vector]].

Again, an ''n''-dimensional vector &lt;math&gt;\mathbf{v}&lt;/math&gt; can be specified in either of the following forms using matrices:

*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} v_1 &amp; v_2 &amp; \cdots &amp; v_{n - 1} &amp; v_n \end{matrix} \right] = \left( \begin{matrix} v_1 &amp; v_2 &amp; \cdots &amp; v_{n - 1} &amp; v_n \end{matrix} \right)&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} v_1 \\ v_2 \\ \vdots \\ v_{n - 1} \\ v_n \end{matrix} \right]= \left( \begin{matrix} v_1 \\ v_2 \\ \vdots \\ v_{n - 1} \\ v_n \end{matrix} \right)&lt;/math&gt;

Where ''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, …, ''v''&lt;sub&gt;''n''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;, ''v''&lt;sub&gt;''n''&lt;/sub&gt; are the components of '''v'''. In some advanced contexts, a row and a column vector have different meaning; see [[covariance and contravariance of vectors]].

===Unit vector notation===
A rectangular vector in &lt;math&gt;\mathbb{R}^3&lt;/math&gt; (or fewer dimensions, such as &lt;math&gt;\mathbb{R}^2&lt;/math&gt; where ''v''&lt;sub&gt;''z''&lt;/sub&gt; below is zero) can be specified as the sum of the scalar multiples of the components of the vector with the members of the standard [[Basis (linear algebra)|basis]] in &lt;math&gt;\mathbb{R}^3&lt;/math&gt;.  The basis is represented with the [[unit vector]]s &lt;math&gt;\boldsymbol{\hat{\imath}} = (1, 0, 0)&lt;/math&gt;, &lt;math&gt;\boldsymbol{\hat{\jmath}} = (0, 1, 0)&lt;/math&gt;, and &lt;math&gt;\boldsymbol{\hat{k}} = (0, 0, 1)&lt;/math&gt;.

A three-dimensional vector '''v''' can be specified in the following form, using unit vector notation:

*&lt;math&gt;\mathbf{v} = v_x \boldsymbol{\hat{\imath}} + v_y \boldsymbol{\hat{\jmath}} + v_z \boldsymbol{\hat{k}}&lt;/math&gt;

Where ''v''&lt;sub&gt;''x''&lt;/sub&gt;, ''v''&lt;sub&gt;''y''&lt;/sub&gt;, and ''v''&lt;sub&gt;''z''&lt;/sub&gt; are the scalar components of '''v'''.  Scalar components may be positive or negative; the absolute value of a scalar component is a magnitude.

==Polar vectors==
{{distinguish|text=[[Polar vector]], a true vector, in a context where pseudo vectors or axial vectors are considered}} 
[[Image:CircularCoordinates.svg|thumb|250px|Points in the polar coordinate system with pole ''O'' and polar axis ''L''. In green, the point with radial coordinate 3 and angular coordinate 60 degrees, or (3,60°). In blue, the point (4,210°).]]
The two [[polar coordinates]] of a point in a plane may be considered as a two dimensional vector. Such a 
''polar vector'' consists of a [[Magnitude (mathematics)|magnitude]] (or length) and a direction (or angle). The magnitude, typically represented as ''r'', is the distance from a starting point, the [[origin (geometry)|origin]], to the point which is represented. The angle, typically represented as ''θ'' (the [[Greek alphabet|Greek]] letter [[theta]]), is the angle between the a fixed direction, typically that of the ''x''-axis, and the direction from the origin to the point. The angle is typically reduced to lie within the range &lt;math&gt;0 \le \theta &lt; 2\pi&lt;/math&gt; radians or &lt;math&gt;0 \le \theta &lt; 360^{\circ}&lt;/math&gt;.

It must be emphasized that a ''polar vector'' is not really a [[vector (mathematics)|vector]], since the [[addition]] of two polar vectors is not defined.

===Ordered set and matrix notations===
Polar vectors can be specified using either ordered pair notation (a subset of ordered set notation using only two components) or matrix notation, as with rectangular vectors.  In these forms, the first component of the vector is ''r'' (instead of ''v''&lt;sub&gt;1&lt;/sub&gt;) and the second component is ''θ'' (instead of ''v''&lt;sub&gt;2&lt;/sub&gt;).  To differentiate polar vectors from rectangular vectors, the angle may be prefixed with the angle symbol, &lt;math&gt;\angle&lt;/math&gt;.

A two-dimensional polar vector ''v'' can be represented as any of the following, using either ordered pair or matrix notation:

*&lt;math&gt;\mathbf{v} = (r, \angle \theta)&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \langle r, \angle \theta \rangle&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} r &amp; \angle \theta \end{matrix} \right]&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} r \\ \angle \theta \end{matrix} \right]&lt;/math&gt;

Where ''r'' is the magnitude, ''θ'' is the angle, and the angle symbol (&lt;math&gt;\angle&lt;/math&gt;) is optional.

===Direct notation===
Polar vectors can also be specified using simplified autonomous equations that define ''r'' and ''θ'' explicitly.  This can be unwieldy, but is useful for avoiding the confusion with two-dimensional rectangular vectors that arises from using ordered pair or matrix notation.

A two-dimensional vector whose magnitude is 5 units and whose direction is ''π''/9 radians (20°) can be specified using either of the following forms:

*&lt;math&gt;r=5, \  \theta={\pi \over 9}&lt;/math&gt;
*&lt;math&gt;r=5, \  \theta=20^{\circ}&lt;/math&gt;

==Cylindrical vectors==
[[Image:Coord system CY 1.svg|thumb|240px|A cylindrical coordinate system with origin ''O'', polar axis ''A'', and longitudinal axis ''L''. The dot is the point with radial distance ''ρ''&amp;nbsp;=&amp;nbsp;4, angular coordinate ''φ''&amp;nbsp;=&amp;nbsp;130°, and height ''z''&amp;nbsp;=&amp;nbsp;4.]]
A cylindrical vector is an extension of the concept of polar vectors into three dimensions.  It is akin to an arrow in the [[cylindrical coordinate system]].  A cylindrical vector is specified by a distance in the ''xy''-plane, an angle, and a distance from the ''xy''-plane (a height).  The first distance, usually represented as ''r'' or ''ρ'' (the Greek letter [[rho]]), is the magnitude of the projection of the vector onto the ''xy''-plane.  The angle, usually represented as ''θ'' or ''φ'' (the Greek letter [[phi]]), is measured as the offset from the line collinear with the ''x''-axis in the positive direction; the angle is typically reduced to lie within the range &lt;math&gt;0 \le \theta &lt; 2\pi&lt;/math&gt;.  The second distance, usually represented as ''h'' or ''z'', is the distance from the ''xy''-plane to the endpoint of the vector.

===Ordered set and matrix notations===
Cylindrical vectors are specified like polar vectors, where the second distance component is [[Concatenation|concatenated]] as a third component to form ordered triplets (again, a subset of ordered set notation) and matrices.  The angle may be prefixed with the angle symbol (&lt;math&gt;\angle&lt;/math&gt;); the distance-angle-distance combination distinguishes cylindrical vectors in this notation from spherical vectors in similar notation.

A three-dimensional cylindrical vector ''v'' can be represented as any of the following, using either ordered triplet or matrix notation:

*&lt;math&gt;\mathbf{v} = (r, \angle \theta, h)&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \langle r, \angle \theta, h \rangle&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} r &amp; \angle \theta &amp; h \end{matrix} \right]&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} r \\ \angle \theta \\ h \end{matrix} \right]&lt;/math&gt;

Where ''r'' is the magnitude of the projection of '''v''' onto the ''xy''-plane, ''θ'' is the angle between the positive ''x''-axis and '''v''', and ''h'' is the height from the ''xy''-plane to the endpoint of ''v''.  Again, the angle symbol (&lt;math&gt;\angle&lt;/math&gt;) is optional.

===Direct notation===
A cylindrical vector can also be specified directly, using simplified autonomous equations that define ''r'' (or ''ρ''), ''θ'' (or ''φ''), and ''h'' (or ''z'').  Consistency should be used when choosing the names to use for the variables; ''ρ'' should not be mixed with ''θ'' and so on.

A three-dimensional vector, the magnitude of whose projection onto the ''xy''-plane is 5 units, whose angle from the positive ''x''-axis is ''π''/9 radians (20°), and whose height from the ''xy''-plane is 3 units can be specified in any of the following forms:

*&lt;math&gt;r=5, \  \theta={\pi \over 9}, \  h=3&lt;/math&gt;
*&lt;math&gt;r=5, \  \theta=20^{\circ}, \  h=3&lt;/math&gt;
*&lt;math&gt;\rho=5, \  \phi={\pi \over 9}, \  z=3&lt;/math&gt;
*&lt;math&gt;\rho=5, \  \phi=20^{\circ}, \  z=3&lt;/math&gt;

==Spherical vectors==
[[File:3D Spherical 2.svg|thumb|240px|right|Spherical coordinates (''r'', ''θ'', ''φ'') as often used in ''mathematics'': radial distance ''r'', azimuthal angle ''θ'', and polar angle ''φ''. The meanings of ''θ'' and ''φ'' have been swapped compared to the physics convention.]]
A spherical vector is another method for extending the concept of polar vectors into three dimensions.  It is akin to an arrow in the [[spherical coordinate system]].  A spherical vector is specified by a magnitude, an azimuth angle, and a zenith angle.  The magnitude is usually represented as ''ρ''.  The azimuth angle, usually represented as ''θ'', is the offset from the line collinear with the ''x''-axis in the positive direction.  The zenith angle, usually represented as ''φ'', is the offset from the line collinear with the ''z''-axis in the positive direction.  Both angles are typically reduced to lie within the range from zero (inclusive) to 2''π'' (exclusive).

===Ordered set and matrix notations===
Spherical vectors are specified like polar vectors, where the zenith angle is concatenated as a third component to form ordered triplets and matrices.  The azimuth and zenith angles may be both prefixed with the angle symbol (&lt;math&gt;\angle&lt;/math&gt;); the prefix should be used consistently to produce the distance-angle-angle combination that distinguishes spherical vectors from cylindrical ones.

A three-dimensional spherical vector ''v'' can be represented as any of the following, using either ordered triplet or matrix notation:

*&lt;math&gt;\mathbf{v} = (\rho, \angle \theta, \angle \phi)&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \langle \rho, \angle \theta, \angle \phi \rangle&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} \rho &amp; \angle \theta &amp; \angle \phi \end{matrix} \right]&lt;/math&gt;
*&lt;math&gt;\mathbf{v} = \left[ \begin{matrix} \rho \\ \angle \theta \\ \angle \phi \end{matrix} \right]&lt;/math&gt;

Where ''ρ'' is the magnitude, ''θ'' is the azimuth angle, and ''φ'' is the zenith angle.

===Direct notation===
Like polar and cylindrical vectors, spherical vectors can be specified using simplified autonomous equations, in this case for ''ρ'', ''θ'', and ''φ''.

A three-dimensional vector whose magnitude is 5 units, whose azimuth angle is ''π''/9 radians (20°), and whose zenith angle is ''π''/4 radians (45°) can be specified as:

*&lt;math&gt;\rho=5, \  \theta={\pi \over 9}, \  \phi={\pi \over 4}&lt;/math&gt;
*&lt;math&gt;\rho=5, \  \theta=20^{\circ}, \  \phi=45^{\circ}&lt;/math&gt;

==Operations==
In any given [[vector space]], the operations of vector addition and scalar multiplication are defined.  [[Normed vector space]]s also define an operation known as the [[Norm (mathematics)|norm]] (or determination of magnitude).  [[Inner product space]]s also define an operation known as the inner product.  In [[Real coordinate space|&lt;math&gt;\mathbb{R}^n&lt;/math&gt;]], the inner product is known as the [[dot product]].  In &lt;math&gt;\mathbb{R}^3&lt;/math&gt; and &lt;math&gt;\mathbb{R}^7&lt;/math&gt;, an additional operation known as the [[cross product]] is also defined.

===Vector addition===
[[Euclidean vector#Addition and subtraction|Vector addition]] is represented with the plus sign used as an operator between two vectors.  The sum of two vectors '''u''' and '''v''' would be represented as:

:&lt;math&gt;\mathbf{u} + \mathbf{v}&lt;/math&gt;

===Scalar multiplication===
[[Scalar multiplication]] is represented in the same manners as algebraic multiplication.  A scalar beside a vector (either or both of which may be in parentheses) implies scalar multiplication.  The two common operators, a dot and a rotated cross, are also acceptable (although the rotated cross is almost never used), but they risk confusion with dot products and cross products, which operate on two vectors.  The product of a scalar ''c'' with a vector '''v''' can be represented in any of the following fashions:

*&lt;math&gt;c \mathbf{v}&lt;/math&gt;
*&lt;math&gt;c \cdot \mathbf{v}&lt;/math&gt;
*&lt;math&gt;c \times \mathbf{v}&lt;/math&gt;

====Vector subtraction and scalar division====
Using the algebraic properties of subtraction and division, along with scalar multiplication, it is also possible to “subtract” two vectors and “divide” a vector by a scalar.

Vector subtraction is performed by adding the scalar multiple of −1 with the second vector operand to the first vector operand.  This can be represented by the use of the minus sign as an operator.   The difference between two vectors '''u''' and '''v''' can be represented in either of the following fashions:

*&lt;math&gt;\mathbf{u} + -\mathbf{v}&lt;/math&gt;
*&lt;math&gt;\mathbf{u} - \mathbf{v}&lt;/math&gt;

Scalar division is performed by multiplying the vector operand with the numeric inverse of the scalar operand.  This can be represented by the use of the fraction bar or division signs as operators.  The quotient of a vector '''v''' and a scalar ''c'' can be represented in any of the following forms:

*&lt;math&gt;{1 \over c} \mathbf{v}&lt;/math&gt;
*&lt;math&gt;{\mathbf{v} \over c}&lt;/math&gt;
*&lt;math&gt;{\mathbf{v} \div c}&lt;/math&gt;

===Norm===
The [[norm (mathematics)|norm]] of a vector is represented with double bars on both sides of the vector.  The norm of a vector '''v''' can be represented as:
:&lt;math&gt;\|\mathbf{v}\|&lt;/math&gt;

The norm is also sometimes represented with single bars, like &lt;math&gt;|\mathbf{v}|&lt;/math&gt;, but this can be confused with [[absolute value]] (which is a type of norm).

===Inner product===
The [[inner product space|inner product]] (also known as the scalar product, not to be confused with scalar multiplication) of two vectors is represented as an ordered pair enclosed in angle brackets.  The inner product of two vectors '''u''' and '''v''' would be represented as:

:&lt;math&gt;\langle \mathbf{u}, \mathbf{v} \rangle&lt;/math&gt;

====Dot product====
In &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, the inner product is also known as the [[dot product]].  In addition to the standard inner product notation, the dot product notation (using the dot as an operator) can also be used (and is more common).  The dot product of two vectors '''u''' and '''v''' can be represented as:

:&lt;math&gt;\mathbf{u} \cdot \mathbf{v}&lt;/math&gt;

In some older literature, the dot product is implied between two vectors written side-by-side. This notation can be confused with the [[dyadic product]] between two vectors.

===Cross product===
The [[cross product]] of two vectors (in &lt;math&gt;\mathbb{R}^3&lt;/math&gt;) is represented using the rotated cross as an operator.  The cross product of two vectors '''u''' and '''v''' would be represented as:

:&lt;math&gt;\mathbf{u} \times \mathbf{v}&lt;/math&gt;

In some older literature, the following notation is used for the cross product between '''u''' and '''v''':

:&lt;math&gt;[\mathbf{u},\mathbf{v}]&lt;/math&gt;

==See also==
* [[ISO 31-11#Vectors and tensors]]
* [[Phasor]]

==References==
{{reflist|30em}}

{{Linear algebra}}

{{DEFAULTSORT:Vector Notation}}
[[Category:Mathematical notation]]
[[Category:Vectors (mathematics and physics)]]</text>
      <sha1>2nqbjxhz4wa0tcky5e4275udiqnl9gp</sha1>
    </revision>
  </page>
</mediawiki>
