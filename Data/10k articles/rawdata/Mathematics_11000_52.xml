<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>(ε, δ)-definition of limit</title>
    <ns>0</ns>
    <id>19216956</id>
    <revision>
      <id>869949133</id>
      <parentid>869401202</parentid>
      <timestamp>2018-11-21T11:47:14Z</timestamp>
      <contributor>
        <username>Mathwriter2718</username>
        <id>33708583</id>
      </contributor>
      <comment>/* Example 1 */Fixed punctuation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24663">[[File:Límite 01.svg|thumb|right|Whenever a point ''x'' is within δ units of ''c'', ''f''(''x'') is within ε units of ''L'']]

In [[calculus]], the '''(ε,&amp;nbsp;δ)-definition of limit''' ("[[epsilon]]–[[delta (letter)|delta]] definition of limit") is a formalization of the notion of [[Limit of a function|limit]]. The concept is due to [[Augustin-Louis Cauchy]], who never gave an (&lt;math&gt;\varepsilon,\delta&lt;/math&gt;) definition of limit in his ''[[Cours d'Analyse]]'', but occasionally used &lt;math&gt;\varepsilon,\delta&lt;/math&gt; arguments in proofs. It was first given as a formal definition by [[Bernard Bolzano]] in 1817, and the definitive modern statement was ultimately provided by [[Karl Weierstrass]].&lt;ref name="grabiner"&gt;
{{citation
 |title=Who Gave You the Epsilon? Cauchy and the Origins of Rigorous Calculus 
 |first=Judith V. 
 |last=Grabiner 
 |journal=The American Mathematical Monthly 
 |date=March 1983 
 |volume=90 
 |pages=185–194 
 |url=http://www.mr-ideahamster.com/classes/assets/a_evepsilon.pdf 
 |archiveurl=https://www.webcitation.org/5gVUmZmxc?url=http://www.maa.org/pubs/Calc_articles/ma002.pdf 
 |archivedate=2009-05-04 
 |deadurl=no 
 |accessdate=2009-05-01 
 |doi=10.2307/2975545 
 |issue=3 
 |publisher=Mathematical Association of America 
 |jstor=2975545 
 |df= 
}}&lt;/ref&gt;&lt;ref&gt;{{citation
 |first       = A.-L.
 |last        = Cauchy
 |author-link = Augustin Louis Cauchy
 |title       = Résumé des leçons données à l’école royale polytechnique sur le calcul infinitésimal
 |place       = Paris
 |year        = 1823
 |url         = http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0
 |chapter     = Septième Leçon - Valeurs de quelques expressions qui se présentent sous les formes indéterminées &lt;math&gt;\frac{\infty}{\infty}, \infty^0, \ldots&lt;/math&gt; Relation qui existe entre le rapport aux différences finies et la fonction dérivée
 |chapter-url = http://gallica.bnf.fr/ark:/12148/bpt6k90196z/f45n5.capture
 |postscript  = , [http://gallica.bnf.fr/ark:/12148/bpt6k90196z.image.f47 p. 44].
 |archiveurl  = https://www.webcitation.org/5gVUmywgY?url=http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0
 |archivedate = 2009-05-04
 |deadurl     = yes
 |accessdate  = 2009-05-01
 |df          = 
}}. Accessed 2009-05-01.&lt;/ref&gt;  It makes rigorous the following informal notion: the dependent expression ''f''(''x'') approaches the value ''L'' as the variable ''x'' approaches the value ''c'' if ''f''(''x'') can be made as close as desired to ''L'' by taking ''x'' sufficiently close to ''c''.

==History==

Although the Greeks examined limiting process, such as the [[Babylonian method]], they probably had no concept similar to the modern limit.&lt;ref&gt;{{cite book|last1=Stillwell|first1=John|title=Mathematics and its history|date=1989|publisher=Springer-Verlag|location=New York|isbn=978-1-4899-0007-4|pages=38–39}}&lt;/ref&gt; The need for the concept of a limit came into force in the 17th century when [[Pierre de Fermat]] attempted to find the [[slope]] of the [[tangent]] line at a point &lt;math&gt;x&lt;/math&gt; of a function such as &lt;math&gt;f(x)=x^{2}&lt;/math&gt;. Using a non-zero, but almost zero quantity, &lt;math&gt;E&lt;/math&gt;, Fermat performed the following calculation:

:&lt;math&gt;
\begin{align}
\mathrm{slope} &amp; = \frac{f(x+E)-f(x)}{E} \\
&amp; = \frac{(x+E)^2-x^2}{E}\\
&amp; = \frac{x^2+2xE+E^2-x^2}{E} \\
&amp; = \frac{2xE+E^2}{E} = 2x+E = 2x.\\
\end{align}
&lt;/math&gt;

The key to the above calculation is that since &lt;math&gt;E&lt;/math&gt; is non-zero one can divide &lt;math&gt;f(x+E)-f(x)&lt;/math&gt; by &lt;math&gt;E&lt;/math&gt;, but since &lt;math&gt;E&lt;/math&gt; is close to 0, &lt;math&gt;2x+E&lt;/math&gt; is essentially &lt;math&gt;2x&lt;/math&gt;.&lt;ref&gt;{{cite book|last1=Stillwell|first1=John|title=Mathematics and its history|date=1989|publisher=Springer-Verlag|location=New York|isbn=978-1-4899-0007-4|pages=104}}&lt;/ref&gt; Quantities such as &lt;math&gt;E&lt;/math&gt; are called [[infinitesimal]]s. The problem with this calculation is that mathematicians of the era were unable to rigorously define a quantity with properties of &lt;math&gt; E&lt;/math&gt;&lt;ref&gt;{{cite book|last1=Stillwell|first1=John|title=Mathematics and its history|date=1989|publisher=Springer-Verlag|location=New York|isbn=978-1-4899-0007-4|pages=106}}&lt;/ref&gt; although it was common practice to 'neglect' higher power infinitesimals and this seemed to yield correct results.

This problem reappeared later in the 1600s at the center of the development of [[calculus]] because calculations such as Fermat's are important to the calculation of [[derivative]]s. [[Isaac Newton]] first developed calculus via an infinitesimal quantity called a [[Method of Fluxions|fluxion]]. He developed them in reference to the idea of an "infinitely small moment in time..."&lt;ref name="ReferenceA"&gt;{{cite book|last1=Buckley|first1=Benjamin Lee|title=The continuity debate : Dedekind, Cantor, du Bois-Reymond and Peirce on continuity and infinitesimals|date=2012|isbn=9780983700487|page=31}}&lt;/ref&gt; However, Newton later rejected fluxions in favor of a theory of ratios that is close to the modern &lt;math&gt;\epsilon -\delta &lt;/math&gt; definition of the limit.&lt;ref name="ReferenceA"/&gt; Moreover, Newton was aware that the limit of the ratio of vanishing quantities was ''not'' itself a ratio, as he wrote:
:Those ultimate ratios ... are not actually ratios of ultimate quantities, but limits ... which they can approach so closely that their difference is less than any given quantity...
Additionally, Newton occasionally explained limits in terms similar to the epsilon–delta definition.&lt;ref&gt;{{citation|title=Newton and the Notion of Limit| first1=B.|last1=Pourciau|journal=Historia Mathematica|volume=28|issue=1|year=2001|doi=10.1006/hmat.2000.2301 }}&lt;/ref&gt; [[Gottfried Wilhelm Leibniz]] developed an infinitesimal of his own and tried to provide it with a rigorous footing, but it was still greeted with unease by some mathematicians and philosophers.&lt;ref&gt;{{cite book|last1=Buckley|first1=Benjamin Lee|title=The continuity debate : Dedekind, Cantor, du Bois-Reymond and Peirce on continuity and infinitesimals|date=2012|isbn=9780983700487|page=32}}&lt;/ref&gt;

[[Augustin-Louis Cauchy]] gave a definition of limit in terms of a more primitive notion he called a ''variable quantity''.  He never gave an epsilon–delta definition of limit (Grabiner 1981).  Some of Cauchy's proofs contain indications of the epsilon–delta method.  Whether or not his foundational approach can be considered a harbinger of Weierstrass's is a subject of scholarly dispute.  Grabiner feels that it is, while Schubring (2005) disagrees.{{dubious|date=December 2011}}&lt;ref name="grabiner" /&gt; Nakane concludes that Cauchy and Weierstrass gave the same name to different notions of limit.&lt;ref&gt;Nakane, Michiyo. Did Weierstrass's differential calculus have a limit-avoiding character? His definition of a limit in ε−δ  style. BSHM Bull.  29  (2014),  no. 1, 51–59.&lt;/ref&gt;{{Unreliable source?|date=April 2015}}

Eventually, Weierstrass and Bolzano are credited with providing a rigorous footing for calculus in the form of the modern &lt;math&gt;\epsilon-\delta&lt;/math&gt; definition of the limit.
&lt;ref name="grabiner"/&gt;&lt;ref&gt;{{citation
 |first       = A.-L.
 |last        = Cauchy
 |author-link = Augustin Louis Cauchy
 |title       = Résumé des leçons données à l’école royale polytechnique sur le calcul infinitésimal
 |place       = Paris
 |year        = 1823
 |url         = http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0
 |chapter     = Septième Leçon - Valeurs de quelques expressions qui se présentent sous les formes indéterminées &lt;math&gt;\frac{\infty}{\infty}, \infty^0, \ldots&lt;/math&gt; Relation qui existe entre le rapport aux différences finies et la fonction dérivée
 |chapter-url = http://gallica.bnf.fr/ark:/12148/bpt6k90196z/f45n5.capture
 |postscript  = , [http://gallica.bnf.fr/ark:/12148/bpt6k90196z.image.f47 p. 44].
 |archiveurl  = https://www.webcitation.org/5gVUmywgY?url=http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0
 |archivedate = 2009-05-04
 |deadurl     = yes
 |accessdate  = 2009-05-01
 |df          = 
}}.&lt;/ref&gt; The need for reference to an infinitesimal &lt;math&gt;E&lt;/math&gt; was then removed &lt;ref&gt;{{cite book|last1=Buckley|first1=Benjamin Lee|title=The continuity debate : Dedekind, Cantor, du Bois-Reymond and Peirce on continuity and infinitesimals|date=2012|isbn=9780983700487|page=33}}&lt;/ref&gt;   and Fermat's computation turned into the computation of the following limit:

:&lt;math&gt;
\begin{align}
\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}.\\
\end{align} 
&lt;/math&gt;

This is not to say that the limiting definition was free of problems as, although it removed the need for infinitesimals, it did require the construction of the [[real number]]s by [[Richard Dedekind]].&lt;ref&gt;{{cite book|last1=Buckley|first1=Benjamin Lee|title=The continuity debate : Dedekind, Cantor, du Bois-Reymond and Peirce on continuity and infinitesimals|date=2012|isbn=9780983700487|pages=32–35}}&lt;/ref&gt; This is also not to say that infinitesimals have no place in modern mathematics as later mathematicians were able to rigorously create infinitesimal quantities as part of the [[hyperreal number]] or [[surreal number]] systems. Moreover, it is possible to rigorously develop calculus with these quantities and they have other mathematical uses.&lt;ref&gt;{{cite book|last1=Tao|first1=Terence|title=Structure and randomness : pages from year one of a mathematical blog|date=2008|publisher=American Mathematical Society|location=Providence, R.I.|isbn=978-0-8218-4695-7|pages=95–110}}&lt;/ref&gt;

==Informal statement==
A viable intuitive or provisional definition is that a "[[Function (mathematics)|function]] ''f'' approaches the limit ''L'' near ''a'' (symbolically, &lt;math&gt; \lim_{x \to a}f(x) = L \, &lt;/math&gt;) if we can make ''f(x)'' as close as we like to ''L'' by requiring that ''x'' be sufficiently close to, but unequal to, ''a''."&lt;ref&gt;{{cite book|last1=Spivak|first1=Michael|title=Calculus|date=2008|publisher=Publish or Perish|location=Houston, Tex.|isbn=978-0914098911|page=90|edition=4th}}&lt;/ref&gt;

When we say that two things are close (such as ''f(x)'' and ''L'' or ''x'' and ''a'') we mean that the [[distance]] between them is small. When ''f(x)'', ''L'', ''x'', and ''a'' are [[real number]]s, the distance between two numbers is the [[absolute value]] of the [[Subtraction|difference]] of the two. Thus, when we say ''f(x)'' is close to ''L'' we mean &lt;math&gt;|f(x)-L|&lt;/math&gt; is small. When we say that ''x'' and ''a'' are close, we mean that &lt;math&gt; |x-a|&lt;/math&gt; is small.&lt;ref name="Calculus"&gt;{{cite book|last1=Spivak|first1=Michael|title=Calculus|date=2008|publisher=Publish or Perish|location=Houston, Tex.|isbn=978-0914098911|page=96|edition=4th}}&lt;/ref&gt;

When we say that we can make ''f(x)'' as close as we like to ''L'', we mean that for '''all''' non-zero distances, &lt;math&gt;\epsilon&lt;/math&gt;, we can make the distance between ''f(x)'' and ''L'' smaller than &lt;math&gt;\epsilon&lt;/math&gt;.&lt;ref name="Calculus"/&gt;

When we say that we can make ''f(x)'' as close as we like to ''L'' by requiring that ''x'' be sufficiently close to, but, unequal to, ''a'', we mean that for every non-zero distance &lt;math&gt;\epsilon &lt;/math&gt;, there is some non-zero distance &lt;math&gt;\delta &lt;/math&gt; such that if the distance between ''x'' and ''a'' is less than &lt;math&gt;\delta &lt;/math&gt; then the distance between ''f(x)'' and ''L'' is smaller than &lt;math&gt;\epsilon &lt;/math&gt;.&lt;ref name="Calculus"/&gt;

The aspect that must be grasped is that the definition requires the following conversation. One is provided with any challenge &lt;math&gt; \epsilon &gt; 0 &lt;/math&gt; for a given ''f'',''a'', and ''L''. One must answer with a &lt;math&gt; \delta &gt; 0 &lt;/math&gt; such that &lt;math&gt; 0 &lt; |x-a | &lt; \delta &lt;/math&gt; implies that &lt;math&gt; |f(x)-L| &lt; \epsilon &lt;/math&gt;. If one can provide an answer for any challenge, one has proven that the limit exists.

==Precise statement and related statements==

===Precise statement for real valued functions===
The &lt;math&gt;(\varepsilon, \delta)&lt;/math&gt; definition of the [[limit of a function]] is as follows:&lt;ref name="Calculus"/&gt;

Let &lt;math&gt;f&lt;/math&gt; be a [[real-valued function]]  defined on a subset &lt;math&gt;D&lt;/math&gt; of the [[real number]]s. Let &lt;math&gt;c&lt;/math&gt; be a [[limit point]] of &lt;math&gt;D&lt;/math&gt; and let &lt;math&gt;L&lt;/math&gt; be a real number. We say that

: &lt;math&gt; \lim_{x\to c}f(x) = L &lt;/math&gt;

if for every &lt;math&gt; \epsilon &gt; 0 &lt;/math&gt; there exists a &lt;math&gt; \delta &lt;/math&gt; such that, for all &lt;math&gt;x\in D&lt;/math&gt;, if &lt;math&gt; 0 &lt; |x-c| &lt; \delta &lt;/math&gt;, then &lt;math&gt; |f(x)-L| &lt; \epsilon&lt;/math&gt;.

Symbolically:
:&lt;math&gt; \lim_{x \to c} f(x) = L  \iff  (\forall \varepsilon &gt; 0,\,\exists \ \delta &gt; 0,\,\forall x \in D,\,0 &lt; |x - c | &lt; \delta \ \Rightarrow \ |f(x) - L| &lt; \varepsilon)&lt;/math&gt;

If &lt;math&gt;D=[a,b]&lt;/math&gt; or &lt;math&gt;D=\mathbb{R}&lt;/math&gt;, then the condition that &lt;math&gt; c&lt;/math&gt; is a limit point is automatically met because closed [[Interval (mathematics)|real intervals]] and the entire real line are [[perfect set]]s.

===Precise statement for functions between metric spaces===

The definition can be generalized to functions that map between [[metric space]]s. These spaces come with a function, called a metric, that takes two points in the space and returns a real number that represents the distance between the two points.&lt;ref name="Rudin, Walter 1976 30"&gt;{{cite book|author=Rudin, Walter|title=Principles of Mathematical Analysis|publisher= McGraw-Hill Science/Engineering/Math |year=1976|isbn= 978-0070542358 |page=30|url=https://books.google.com/books?id=kwqzPAAACAAJ}}&lt;/ref&gt; The generalized definition is as follows:&lt;ref&gt;{{cite book|author=Rudin, Walter|title=Principles of Mathematical Analysis|publisher= McGraw-Hill Science/Engineering/Math |year=1976|isbn= 978-0070542358 |page=83|url=https://books.google.com/books?id=kwqzPAAACAAJ}}&lt;/ref&gt;

Suppose &lt;math&gt;f&lt;/math&gt; is defined on a subset &lt;math&gt;D&lt;/math&gt; of a metric space &lt;math&gt;X&lt;/math&gt; with a metric &lt;math&gt; d_{X}(x,y)&lt;/math&gt; and maps into a metric space &lt;math&gt;Y&lt;/math&gt; with a metric &lt;math&gt; d_{Y}(x,y)&lt;/math&gt;. Let &lt;math&gt;c&lt;/math&gt; be a limit point of &lt;math&gt;D&lt;/math&gt; and let &lt;math&gt;L&lt;/math&gt; be a point of &lt;math&gt;Y&lt;/math&gt;.

We say that

: &lt;math&gt; \lim_{x\to c}f(x) = L &lt;/math&gt;

if for every &lt;math&gt; \epsilon &gt; 0 &lt;/math&gt; there exists a &lt;math&gt; \delta &lt;/math&gt; such that, for all &lt;math&gt;x\in D&lt;/math&gt;, if &lt;math&gt; 0 &lt; d_{X}(x,c) &lt; \delta &lt;/math&gt;, then &lt;math&gt; d_{Y}(f(x),L) &lt; \epsilon&lt;/math&gt;.

Since &lt;math&gt;d(x,y) = |x-y|&lt;/math&gt; is a metric on the real numbers, one can show that this definition generalizes the first definition for real functions.&lt;ref&gt;{{cite book|author=Rudin, Walter|title=Principles of Mathematical Analysis|publisher= McGraw-Hill Science/Engineering/Math |year=1976|isbn= 978-0070542358 |page=84|url=https://books.google.com/books?id=kwqzPAAACAAJ}}&lt;/ref&gt;

===Negation of the precise statement===

The negation of the definition is a follows:&lt;ref&gt;{{cite book|last1=Spivak|first1=Michael|title=Calculus|date=2008|publisher=Publish or Perish|location=Houston, Tex.|isbn=978-0914098911|page=97|edition=4th}}&lt;/ref&gt;

Suppose &lt;math&gt;f&lt;/math&gt; is defined on a subset &lt;math&gt;D&lt;/math&gt; of a metric space &lt;math&gt;X&lt;/math&gt; with a metric &lt;math&gt; d_{X}(x,y)&lt;/math&gt; and maps into a metric space &lt;math&gt;Y&lt;/math&gt; with a metric &lt;math&gt; d_{Y}(x,y)&lt;/math&gt;. Let &lt;math&gt;c&lt;/math&gt; be a limit point of &lt;math&gt;D&lt;/math&gt; and let &lt;math&gt;L&lt;/math&gt; be a point of &lt;math&gt;Y&lt;/math&gt;.

We say that

: &lt;math&gt; \lim_{x\to c}f(x) \neq L &lt;/math&gt;

if there exists an &lt;math&gt; \epsilon &gt; 0 &lt;/math&gt; such that for all &lt;math&gt; \delta &gt; 0 &lt;/math&gt; there is an &lt;math&gt;x\in D&lt;/math&gt; such that &lt;math&gt; 0 &lt; d_{X}(x,c) &lt; \delta &lt;/math&gt; and  &lt;math&gt; d_{Y}(f(x),L) &gt; \epsilon&lt;/math&gt;.

We say that &lt;math&gt; \lim_{x\to c}f(x) &lt;/math&gt; does not exist if for all &lt;math&gt;L\in Y&lt;/math&gt;, &lt;math&gt; \lim_{x\to c}f(x) \neq L &lt;/math&gt;.

For the negation of a real valued function defined on the real numbers, simply set &lt;math&gt;d_{Y}(x,y) = d_{X}(x,y)= |x-y|&lt;/math&gt;.

===Precise statement for limits at infinity===
The precise statement for limits at infinity is as follows:&lt;ref name="Rudin, Walter 1976 30"/&gt;

Suppose &lt;math&gt;f&lt;/math&gt; is defined on a subset &lt;math&gt;D&lt;/math&gt; of a metric space &lt;math&gt;X&lt;/math&gt; with a metric &lt;math&gt; d_{X}(x,y)&lt;/math&gt; and maps into a metric space &lt;math&gt;Y&lt;/math&gt; with a metric &lt;math&gt; d_{Y}(x,y)&lt;/math&gt;. Let &lt;math&gt;L\in Y&lt;/math&gt;.

We say that

: &lt;math&gt; \lim_{x\to\infty}f(x) = L &lt;/math&gt;

if for every &lt;math&gt;\epsilon &gt; 0&lt;/math&gt;, there is a real number &lt;math&gt;N &gt; 0 &lt;/math&gt; such that there is an &lt;math&gt;x\in D&lt;/math&gt; where &lt;math&gt;d_{X}(x,0) &gt; N&lt;/math&gt; and such that if &lt;math&gt;d_{X}(x,0) &gt; N&lt;/math&gt; and &lt;math&gt;x\in D&lt;/math&gt;, then &lt;math&gt;d_{Y}(f(x),L) &lt; \epsilon&lt;/math&gt;.

==Worked examples==
===Example 1===
We will show that

: &lt;math&gt;\lim_{x\to 0} x\sin{\left(\frac{1}{x}\right)} = 0
&lt;/math&gt;.

We let &lt;math&gt;\epsilon &gt; 0&lt;/math&gt; be given. We need to find a &lt;math&gt;\delta &gt;0 &lt;/math&gt; such that &lt;math&gt;|x-0| &lt; \delta &lt;/math&gt; implies &lt;math&gt;\left|x\sin{\left(\frac{1}{x}\right)} - 0\right| &lt; \epsilon &lt;/math&gt;.

Since [[sine]] is bounded above by 1 and below by -1,

&lt;math&gt;
\begin{align}
\left|x\sin{\left(\frac{1}{x}\right)} - 0\right| &amp;= \left|x\sin{\left(\frac{1}{x}\right)}\right|\\
                           &amp;= |x|\left|\sin{\left(\frac{1}{x}\right)}\right| \\
                           &amp;\leq |x|.
\end{align}
&lt;/math&gt;

Thus, if we take &lt;math&gt;\delta = \epsilon&lt;/math&gt;, then &lt;math&gt;|x| =|x-0| &lt; \delta&lt;/math&gt; implies &lt;math&gt;\left|x\sin{\left(\frac{1}{x}\right)} - 0\right| \leq |x| &lt; \epsilon &lt;/math&gt;, which completes the proof.

===Example 2===
Let us prove the statement that

: &lt;math&gt; \lim_{x\to a} x^2 = a^2&lt;/math&gt;
for any real number &lt;math&gt;a&lt;/math&gt;.

Let &lt;math&gt;\epsilon&gt;0&lt;/math&gt; be given. We will find a &lt;math&gt;\delta &gt; 0 &lt;/math&gt; such that &lt;math&gt;|x-a|&lt;\delta&lt;/math&gt; implies &lt;math&gt;|x^2-a^2|&lt;\epsilon &lt;/math&gt;.

We start by factoring:

: &lt;math&gt; |x^2-a^2| = |(x-a)(x+a)|=|x-a||x+a|.&lt;/math&gt;

We recognize that &lt;math&gt;|x-a|&lt;/math&gt; is the term bounded by &lt;math&gt;\delta&lt;/math&gt; so we can presuppose a bound of 1 and later pick something smaller than that for &lt;math&gt;\delta&lt;/math&gt;.&lt;ref&gt;{{cite book|last1=Spivak|first1=Michael|title=Calculus|date=2008|publisher=Publish or Perish|location=Houston, Tex.|isbn=978-0914098911|page=95|edition=4th}}&lt;/ref&gt;

So we suppose &lt;math&gt; |x-a| &lt; 1 &lt;/math&gt;. Since &lt;math&gt; |x| - |y| \leq |x-y| &lt;/math&gt; holds in general for real numbers &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;, we have

: &lt;math&gt; |x| - |a| \leq |x-a| &lt; 1.&lt;/math&gt;

Thus,

: &lt;math&gt; |x| &lt; 1 + |a|.&lt;/math&gt;

Thus via the [[triangle inequality]],

: &lt;math&gt; |x+a| \leq |x| + |a| &lt; 2|a| + 1.&lt;/math&gt;

Thus, if we further suppose that

:&lt;math&gt; |x-a| &lt; \frac{\epsilon}{2|a| +1}&lt;/math&gt;

then

:&lt;math&gt;|x^2-a^2| &lt;\epsilon &lt;/math&gt;.

In summary, we set
: &lt;math&gt; \delta = \min{\left(1,\frac{\epsilon}{2|a| +1}\right)}&lt;/math&gt;.

So, if &lt;math&gt; |x-a|&lt;\delta&lt;/math&gt;, then

: &lt;math&gt;
\begin{align}
|x^2-a^2| &amp;= |x-a||x+a| \\
          &amp;&lt;  \frac{\epsilon}{2|a| +1}(|x+a|)\\
           &amp;&lt; \frac{\epsilon}{2|a| +1}(2|a|+1)\\
          &amp;=\epsilon\\
\end{align}
&lt;/math&gt;

Thus, we have found a &lt;math&gt;\delta&lt;/math&gt; such that &lt;math&gt; |x-a| &lt; \delta&lt;/math&gt; implies &lt;math&gt;|x^2-a^2|  &lt;\epsilon &lt;/math&gt;. Thus, we have shown that
: &lt;math&gt; \lim_{x\to a} x^2 = a^2&lt;/math&gt;
for any real number &lt;math&gt;a&lt;/math&gt;.

===Example 3===
Let us prove the statement that

: &lt;math&gt;\lim_{x \to 5} (3x - 3) = 12.&lt;/math&gt;

This is easily shown through graphical understandings of the limit, and as such serves as a strong basis for introduction to proof. According to the formal definition above, a limit statement is correct if and only if confining &lt;math&gt;x&lt;/math&gt; to &lt;math&gt;\delta&lt;/math&gt; units of &lt;math&gt;c&lt;/math&gt; will inevitably confine &lt;math&gt;f(x)&lt;/math&gt; to &lt;math&gt;\varepsilon&lt;/math&gt; units of &lt;math&gt;L&lt;/math&gt;. In this specific case, this means that the statement is true if and only if confining &lt;math&gt;x&lt;/math&gt; to &lt;math&gt;\delta&lt;/math&gt; units of 5 will inevitably confine

:&lt;math&gt;3x - 3&lt;/math&gt;

to &lt;math&gt;\varepsilon&lt;/math&gt; units of 12. The overall key to showing this implication is to demonstrate how &lt;math&gt;\delta&lt;/math&gt; and &lt;math&gt;\varepsilon&lt;/math&gt; must be related to each other such that the implication holds. Mathematically, we want to show that

:&lt;math&gt; 0 &lt; | x - 5 | &lt; \delta \ \Rightarrow \ | (3x - 3) - 12 | &lt; \varepsilon . &lt;/math&gt;

Simplifying, factoring, and dividing 3 on the right hand side of the implication yields

:&lt;math&gt; | x - 5 | &lt; \varepsilon / 3 ,&lt;/math&gt;

which immediately gives the required result if we choose

:&lt;math&gt; \delta = \varepsilon / 3 .&lt;/math&gt;

Thus the proof is completed. The key to the proof lies in the ability of one to choose boundaries in &lt;math&gt;x&lt;/math&gt;, and then conclude corresponding boundaries in &lt;math&gt;f(x)&lt;/math&gt;, which in this case were related by a factor of 3, which is entirely due to the slope of 3 in the line

:&lt;math&gt; y = 3x - 3 .&lt;/math&gt;

==Continuity==
A function ''f'' is said to be [[continuous function|continuous]] at ''c'' if it is both defined at ''c'' and its value at ''c'' equals the limit of ''f'' as ''x'' approaches ''c'':

: &lt;math&gt;\lim_{x\to c} f(x) = f(c).&lt;/math&gt;
If the condition 0&amp;nbsp;&lt;&amp;nbsp;|''x''&amp;nbsp;−&amp;nbsp;''c''| is left out of the definition of limit, then requiring ''f''(''x'') to have a limit at ''c'' would be the same as requiring ''f''(''x'') to be continuous at ''c''.

''f'' is said to be continuous on an interval ''I'' if it is continuous at every point ''c'' of ''I''.

==Comparison with infinitesimal definition==
[[Howard Jerome Keisler|Keisler]] proved that a [[hyperreal numbers|hyperreal]] [[Non-standard calculus#Limit|definition of limit]] reduces the quantifier complexity by two quantifiers.&lt;ref&gt;{{citation|last1=Keisler|first1=H. Jerome|chapter=Quantifiers in limits|title=Andrzej Mostowski and foundational studies|pages=151–170|publisher=IOS, Amsterdam|year=2008|contribution-url=http://www.math.wisc.edu/~keisler/limquant7.pdf}}&lt;/ref&gt; Namely, &lt;math&gt;f(x)&lt;/math&gt; converges to a limit ''L'' as &lt;math&gt;x&lt;/math&gt; tends to ''a'' if and only if for every infinitesimal ''e'', the value &lt;math&gt;f(x+e)&lt;/math&gt; is infinitely close to ''L''; see [[microcontinuity]] for a related definition of continuity, essentially due to [[Augustin-Louis Cauchy|Cauchy]].  Infinitesimal calculus textbooks based on [[Abraham Robinson|Robinson]]'s approach provide definitions of continuity, derivative, and integral at standard points in terms of infinitesimals.  Once notions such as continuity have been thoroughly explained via the approach using microcontinuity, the epsilon–delta approach is presented as well. [[Karel Hrbáček]] argues that the definitions of continuity, derivative, and integration in Robinson-style non-standard analysis must be grounded in the ε–δ method in order to cover also non-standard values of the input.&lt;ref&gt;{{citation|last1=Hrbacek|first1=K.|editor-last=Van Den Berg|editor-first=I.|editor2-last=Neves|editor2-first=V.| chapter=Stratified Analysis?|title=The Strength of Nonstandard Analysis|publisher=Springer|year=2007}}&lt;/ref&gt; Błaszczyk et al. argue that [[microcontinuity]] is useful in developing a transparent definition of uniform continuity, and characterize the criticism by Hrbáček as a "dubious lament".&lt;ref&gt;{{citation
 | last1 = Błaszczyk | first1 = Piotr
 | author1-link =
 | last2 = Katz | first2 = Mikhail
 | author2-link = Mikhail Katz
 | last3 = Sherry | first3 = David
 | author3-link = 
 | arxiv = 1202.4153
 | doi = 10.1007/s10699-012-9285-8
 | issue = 
 | journal = [[Foundations of Science]]
 | pages = 
 | title = Ten misconceptions from the history of analysis and their debunking
 | volume = 
 | year = 2012}}&lt;/ref&gt;  Hrbáček proposes an alternative non-standard analysis, which (unlike Robinson's) has many "levels" of infinitesimals, so that limits at one level can be defined in terms of infinitesimals at the next level.&lt;ref&gt;{{cite journal|last1=Hrbacek|first1=K.|title=Relative set theory: Internal view|journal=Journal of Logic and Analysis|year=2009|volume=1|url=http://logicandanalysis.org/index.php/jla/article/view/25/17}}&lt;/ref&gt;

==See also==
* [[Continuous function]]
* [[Limit of a sequence]]
* [[List of calculus topics]]

==References==
{{reflist|30em}}

==Further reading==
* {{cite book |last=Grabiner |first=Judith V. |title=The Origins of Cauchy's Rigorous Calculus |publisher=Courier Corporation |year=1982 |isbn=978-0-486-14374-3 |url=https://books.google.com/books?id=XuFcx-laQmIC }}
* {{cite book |title=Conflicts Between Generalization, Rigor, and Intuition: Number Concepts Underlying the Development of Analysis in 17th–19th Century France and Germany |first=Gert |last=Schubring |edition=illustrated |publisher=Springer |year=2005 |isbn=0-387-22836-5 |page= |url=https://books.google.com/books?id=rMWe3okqPOcC }}

{{DEFAULTSORT:E, Delta}}
[[Category:Limits (mathematics)]]
[[Category:Quantification]]</text>
      <sha1>cyiqgl4o9i5lxqy158rpfqx44m2yqnv</sha1>
    </revision>
  </page>
  <page>
    <title>115 (number)</title>
    <ns>0</ns>
    <id>498590</id>
    <revision>
      <id>857798914</id>
      <parentid>857798789</parentid>
      <timestamp>2018-09-03T02:46:13Z</timestamp>
      <contributor>
        <username>Mfb</username>
        <id>19550900</id>
      </contributor>
      <comment>Undid revision 857798789 by [[Special:Contributions/Mfb|Mfb]] ([[User talk:Mfb|talk]]) no, both links are not good</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2540">{{Infobox number
| number = 115
| divisor = 1, 5, 23, 115
}}
'''115 (one hundred [and] fifteen)''' is the [[natural number]] following [[114 (number)|114]] and preceding [[116 (number)|116]].

==In mathematics==
115 has a [[square number|square]] sum of divisors:&lt;ref&gt;{{Cite OEIS|A006532|name=Numbers n such that sum of divisors of n is a square}}&lt;/ref&gt;
:&lt;math&gt;\sigma(115)=1+5+23+115=144=12^2.&lt;/math&gt;

There are 115 different [[rooted tree]]s with exactly eight nodes,&lt;ref&gt;{{Cite OEIS|A000081|name=Number of rooted trees with n nodes (or connected functions with a fixed point)}}&lt;/ref&gt; 115 inequivalent ways of placing six [[Rook (chess)|rooks]] on a 6&amp;nbsp;&amp;times;&amp;nbsp;6 [[chess board]] in such a way that no two of the rooks attack each other,&lt;ref&gt;{{Cite OEIS|A000903|name=Number of inequivalent ways of placing n nonattacking rooks on n X n board}}&lt;/ref&gt; and 115 solutions to the [[Map folding|stamp folding problem]] for a strip of seven stamps.&lt;ref&gt;{{Cite OEIS|A002369|name=Number of ways of folding a strip of n rectangular stamps}}&lt;/ref&gt;

115 is also a [[heptagonal pyramidal number]].&lt;ref&gt;{{Cite OEIS|A002413|name=Heptagonal (or 7-gonal) pyramidal numbers: n*(n+1)*(5*n-2)/6}}&lt;/ref&gt; The 115th [[Woodall number]],
:&lt;math&gt;115\cdot 2^{115}-1=4\;776\;913\;109\;852\;041\;418\;248\;056\;622\;882\;488\;319,&lt;/math&gt;
is a [[prime number]].&lt;ref&gt;{{Cite OEIS|A002234|name=Numbers n such that the Woodall number n*2^n - 1 is prime}}&lt;/ref&gt;

==In science==
* The [[atomic number]] of the element [[Moscovium]]

==In other fields==
'''115''' is also the fire service emergency number in [[Mauritius]]&lt;ref&gt;{{citation|title=CultureShock! Mauritius: A Survival Guide to Customs and Etiquette|first=Roseline Ng|last=Cheong-Lum|publisher=Marshall Cavendish International Asia Pte Ltd|year=2009|isbn=9789814435604|page=287|url=https://books.google.com/books?id=WR6JAAAAQBAJ&amp;pg=PA287}}.&lt;/ref&gt; and [[Italy]],&lt;ref&gt;{{citation|title=DK Eyewitness Travel Guide: Italy|publisher=Penguin|year=2013|isbn=9781465414946|page=619|url=https://books.google.com/books?id=HavTAAAAQBAJ&amp;pg=PA619}}.&lt;/ref&gt;
and the ambulance emergency number in [[Vietnam]].&lt;ref&gt;{{citation|title=The Rough Guide to Southeast Asia On A Budget|publisher=Penguin|year=2014|isbn=9780241012727|page=1286|url=https://books.google.com/books?id=kVE8BAAAQBAJ&amp;pg=PT1286}}.&lt;/ref&gt;

==See also==
* [[List of highways numbered 115]]

==References==
{{reflist}}

{{Integers|1}}

{{DEFAULTSORT:115 (Number)}}
[[Category:Integers]]
[[Category:Communications in Mauritius]]

{{Use dmy dates|date=June 2013}}</text>
      <sha1>rem5rmgmdz3gn6te9gujqhk12lioub4</sha1>
    </revision>
  </page>
  <page>
    <title>Analyst's traveling salesman theorem</title>
    <ns>0</ns>
    <id>28177884</id>
    <revision>
      <id>845119661</id>
      <parentid>823438756</parentid>
      <timestamp>2018-06-09T14:34:39Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5860">The '''analyst's traveling salesman problem''' is an analog of the [[traveling salesman problem]] in [[combinatorial optimization]]. In its simplest and original form, it asks under what conditions may a set ''E'' in two-dimensional [[Euclidean space]] &lt;math&gt;\mathbb{R}^2&lt;/math&gt; be contained inside a [[curve|rectifiable curve]] of finite length. So while in the original traveling salesman problem, one asks for the shortest way to visit every vertex in a graph with a discrete path, this analytical version requires the curve to visit perhaps infinitely many points.

==β-numbers==

A posteriori, for ''E'' to be contained in a rectifiable curve Γ, since Γ has [[tangent]]s at ''H''&lt;sup&gt;1&lt;/sup&gt;-almost every point in Γ (where ''H''&lt;sup&gt;1&lt;/sup&gt; denotes one-dimensional [[Hausdorff measure]]), ''E'' must look ''flat'' when you zoom in on points in ''E''. This suggests that a condition that would tell us whether a set could be contained in a curve must somehow incorporate information about how flat ''E'' is when we zoom in on points of ''E'' at different scales.

This discussion motivates the definition of the following quantity: 
:&lt;math&gt;\beta_{E}(Q)=\frac{1}{\ell(Q)}\inf\{\delta:\text{ there is a line }L\text{ so that for every }x\in E\cap Q, \; \text{dist}(x,L)&lt;\delta\},&lt;/math&gt;

Where ''Q'' is any square, &lt;math&gt;\ell(Q)&lt;/math&gt; is the sidelength of ''Q'', and dist(''x'',&amp;nbsp;''L'') measures the distance from ''x'' to the line ''L''. Intuitively, &lt;math&gt;2\beta_E(Q)\ell(Q)&lt;/math&gt; is the width of the smallest rectangle containing the portion of ''E'' inside ''Q'', and hence &lt;math&gt;\beta_E(Q)&lt;/math&gt; gives us a scale invariant notion of ''flatness''.

==Jones' traveling salesman theorem in R&lt;sup&gt;2&lt;/sup&gt;==

Let Δ denote the collection of dyadic squares, that is,

: &lt;math&gt;\Delta=\{[i2^{k},(i+1)2^{k}]\times[j2^{k},(j+1)2^{k}]: i,j,k\in\mathbb{Z}\},&lt;/math&gt;

where &lt;math&gt;\mathbb{Z}&lt;/math&gt; denotes the set of integers. For a set &lt;math&gt;E\subseteq\mathbb{R}^2&lt;/math&gt;, define

:&lt;math&gt;\beta(E)=\text{diam} E+ \sum_{Q\in\Delta}\beta_{E}(3Q)^2 \ell(Q)&lt;/math&gt;

where diam ''E'' is the [[diameter]] of ''E''. Then Peter Jones'&lt;ref&gt;{{cite journal
  | last = Jones | first = Peter | authorlink = Peter Jones (mathematician)
  | title = Rectifiable sets and the Traveling Salesman Problem
  | journal =Inventiones Mathematicae | volume = 102 | pages = 1–15 | year = 1990 | doi=10.1007/BF01233418
| bibcode = 1990InMat.102....1J}}&lt;/ref&gt; analyst's traveling salesman theorem may be stated as follows:

* There is a number ''C''&amp;nbsp;&gt;&amp;nbsp;0 such that whenever ''E'' is a set with such that ''β''(''E'')&amp;nbsp;&lt;&amp;nbsp;∞, ''E'' can be contained in a curve with length no more than ''Cβ''(''E'').
* Conversely (and substantially more difficult to prove), if Γ is a rectifiable curve, then ''β''(Γ)&amp;nbsp;&lt;&amp;nbsp;CH&lt;sup&gt;1&lt;/sup&gt;(Γ).

==Generalizations and Menger curvature==

===Euclidean space and Hilbert space===
The Traveling Salesman Theorem was shown to hold in general Euclidean spaces by Kate Okikiolu,&lt;ref&gt;{{cite journal
  | last = Okikiolu | first = Kate | authorlink = Kate Okikiolu
  | title =  Characterization of subsets of rectifiable curves in Rn
  | journal =[[Journal of the London Mathematical Society]]| volume = 46 | pages = 336–348 | year = 1992 | doi=10.1112/jlms/s2-46.2.336
}}&lt;/ref&gt; that is, the same theorem above holds for sets &lt;math&gt;E\subseteq\mathbb{R}^d&lt;/math&gt;, ''d''&amp;nbsp;&gt;&amp;nbsp;1, where Δ is now the collection of dyadic cubes in &lt;math&gt;\mathbb{R}^d&lt;/math&gt; defined in a similar way as dyadic squares. In her proof, the constant ''C'' grows exponentially with the dimension&amp;nbsp;''d''.

With some slight modifications to the definition of ''β''(''E''), Raanan Schul&lt;ref&gt;{{cite journal
  | last = Schul | first = Raanan | authorlink = Raanan Schul
  | title =  Subsets of Rectifiable curves in Hilbert Space—The Analyst's TSP
  | journal =Journal d'Analyse Mathématique| volume = 103 | pages = 331–375 | year = 2007 | doi=10.1007/s11854-008-0011-y
| arxiv =math/0602675}}&lt;/ref&gt; showed Traveling Salesman Theorem also holds for sets ''E'' that lie in any [[Hilbert Space]], and in particular, implies the theorems of Jones and Okikiolu, where now the constant ''C'' is independent of dimension. (In particular, this involves using ''β''-numbers of balls instead of cubes).

===Menger curvature and metric spaces===
Hahlomaa&lt;ref&gt;{{cite journal
  | last = Hahlomaa | first = Immo | authorlink = Immo Hahlomaa
  | title =  Menger curvature and Lipschitz parametrizations in metric spaces
  | journal =Fund. Math.| volume = 185 | pages = 143–169 | year = 2005 | doi=10.4064/fm185-2-3
}}&lt;/ref&gt; further adjusted the definition of ''β''(''E'') to get a condition for when a set ''E'' of an arbitrary [[metric space]] may be contained in the [[Lipschitz continuity|Lipschitz]]-image of a subset &lt;math&gt;A\subseteq\mathbb{R}&lt;/math&gt; of positive measure. For this, he had to redefine the definition of the ''β''-numbers using [[menger curvature]] (since in a metric space there isn't necessarily a notion of a cube or a straight line).

[[Menger curvature]], as in the previous example, can be used to give numerical estimates that determine whether a set contains a rectifiable subset, and the proofs of these results frequently depend on ''β''-numbers.

=== Denjoy–Riesz theorem ===
The [[Denjoy–Riesz theorem]] gives general conditions under which a point set can be covered by the homeomorphic image of a curve. This is true, in particular, for every compact [[totally disconnected]] subset of the Euclidean plane. However, it may be necessary for such an arc to have infinite length, failing to meet the conditions of the analyst's traveling salesman theorem.

==References==
{{Reflist|30em}}

[[Category:Harmonic analysis]]
[[Category:Real analysis]]
[[Category:Geometry]]
[[Category:Theorems in discrete mathematics]]</text>
      <sha1>hkpd84b9b0exkpxq31yy3hkpfpm82fo</sha1>
    </revision>
  </page>
  <page>
    <title>Analytical mechanics</title>
    <ns>0</ns>
    <id>454450</id>
    <revision>
      <id>865968049</id>
      <parentid>865967976</parentid>
      <timestamp>2018-10-27T10:43:19Z</timestamp>
      <contributor>
        <username>Jackfork</username>
        <id>3430766</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/91.232.101.52|91.232.101.52]] ([[User talk:91.232.101.52|talk]]) to last revision by Acanith. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32877">{{Classical mechanics|cTopic=Formulations}}

In [[theoretical physics]] and [[mathematical physics]], '''analytical mechanics''', or '''theoretical mechanics''' is a collection of closely related alternative formulations of [[classical mechanics]]. It was developed by many scientists and mathematicians during the 18th century and onward, after [[Newtonian mechanics]]. Since Newtonian mechanics considers [[Euclidean vector|vector]] quantities of motion, particularly [[acceleration]]s, [[momenta]], [[force]]s, of the constituents of the system, an alternative name for the mechanics governed by [[Newton's laws]] and [[Euler's laws]] is ''vectorial mechanics''.

By contrast, analytical mechanics uses ''[[Scalar (physics)|scalar]]'' properties of motion representing the system as a whole—usually its total [[kinetic energy]] and [[potential energy]]—not Newton's vectorial forces of individual particles.&lt;ref name=Lanczos&gt;{{cite book |title=The variational principles of mechanics |last=Lanczos |first=Cornelius |page=Introduction, pp. xxi–xxix |edition=4th |publisher=Dover Publications Inc. |location= New York |isbn=0-486-65067-7 |year=1970 |url=https://books.google.com/books?id=ZWoYYr8wk2IC&amp;pg=PR4&amp;dq=isbn=0486650677#PPR21,M1 |nopp=true}}&lt;/ref&gt; A scalar is a quantity, whereas a vector is represented by quantity and direction.  The [[equations of motion]] are derived from the scalar quantity by some underlying principle about the scalar's [[calculus of variations|variation]].

Analytical mechanics takes advantage of a system's ''constraints'' to solve problems. The constraints limit the [[Degrees of freedom (physics and chemistry)|degrees of freedom]] the system can have, and can be used to reduce the number of coordinates needed to solve for the motion. The formalism is well suited to arbitrary choices of coordinates, known in the context as [[generalized coordinates]]. The kinetic and potential energies of the system are expressed using these generalized coordinates or momenta, and the equations of motion can be readily set up, thus analytical mechanics allows numerous mechanical problems to be solved with greater efficiency than fully vectorial methods. It does not always work for non-[[conservative force]]s or dissipative forces like [[friction]], in which case one may revert to Newtonian mechanics or use the [[Udwadia–Kalaba equation]].

Two dominant branches of analytical mechanics are [[Lagrangian mechanics]] (using generalized coordinates and corresponding generalized velocities in [[Configuration space (physics)|configuration space]]) and [[Hamiltonian mechanics]] (using coordinates and corresponding momenta in [[phase space]]). Both formulations are equivalent by a [[Legendre transformation#Hamilton–Lagrange mechanics|Legendre transformation]] on the generalized coordinates, velocities and momenta, therefore both contain the same information for describing the dynamics of a system. There are other formulations such as [[Hamilton–Jacobi theory]], [[Routhian mechanics]], and [[Appell's equation of motion]]. All equations of motion for particles and fields, in any formalism, can be derived from the widely applicable result called the [[principle of least action]]. One result is [[Noether's theorem]], a statement which connects [[conservation law]]s to their associated [[Symmetry (physics)|symmetries]].

Analytical mechanics does not introduce new physics and is not more general than Newtonian mechanics. Rather it is a collection of equivalent formalisms which have broad application. In fact the same principles and formalisms can be used in [[relativistic mechanics]] and [[general relativity]], and with some modification, [[quantum mechanics]] and [[quantum field theory]].

Analytical mechanics is used widely, from fundamental physics to [[applied mathematics]], particularly [[chaos theory]].

The methods of analytical mechanics apply to discrete particles, each with a finite number of degrees of freedom. They can be modified to describe continuous fields or fluids, which have infinite degrees of freedom. The definitions and equations have a close analogy with those of mechanics.

==Intrinsic motion==

;[[Generalized coordinates]] and constraints

In [[Newtonian mechanics]], one customarily uses all three [[Cartesian coordinates]], or other 3D [[coordinate system]], to refer to a body's [[position (vector)|position]] during its motion.  In physical systems, however, some structure or other system usually constrains the body's motion from taking certain directions and pathways.  So a full set of Cartesian coordinates is often unneeded, as the constraints determine the evolving relations among the coordinates, which relations can be modeled by equations corresponding to the constraints.  In the Lagrangian and Hamiltonian formalisms, the constraints are incorporated into the motion's geometry, reducing the number of coordinates to the minimum needed to model the motion.  These are known as ''generalized coordinates'', denoted ''q&lt;sub&gt;i&lt;/sub&gt;'' (''i'' = 1, 2, 3...).&lt;ref&gt;''The Road to Reality'', Roger Penrose, Vintage books, 2007, {{ISBN|0-679-77631-1}}&lt;/ref&gt;

'''Difference between [[Curvilinear coordinates|curvillinear]] and [[generalized coordinates]]'''

Generalized coordinates incorporate constraints on the system. There is one generalized coordinate ''q&lt;sub&gt;i&lt;/sub&gt;'' for each [[Degrees of freedom (physics and chemistry)|degree of freedom]] (for convenience labelled by an index ''i'' = 1, 2...''N''), i.e. each way the system can change its [[Configuration space (physics)|configuration]]; as curvilinear lengths or angles of rotation. Generalized coordinates are not the same as curvilinear coordinates. The number of ''curvilinear'' coordinates equals the [[dimension]] of the position space in question (usually 3 for 3d space), while the number of ''generalized'' coordinates is not necessarily equal to this dimension; constraints can reduce the number of degrees of freedom (hence the number of generalized coordinates required to define the configuration of the system), following the general rule:&lt;ref name="autogenerated1"&gt;''Analytical Mechanics'', L.N. Hand, J.D. Finch, Cambridge University Press, 2008, {{ISBN|978-0-521-57572-0}}&lt;/ref&gt;

:''['''dimension of position space''' (usually 3)] × [number of '''constituents''' of system ("particles")] − (number of '''constraints''')''
:''= (number of '''degrees of freedom''') = (number of '''generalized coordinates''')''

For a system with ''N'' degrees of freedom, the generalized coordinates can be collected into an ''N''-[[tuple]]:

:&lt;math&gt;\mathbf{q} = (q_1,q_2,\cdots q_N) &lt;/math&gt;

and the [[time derivative]] (here denoted by an overdot) of this tuple give the ''generalized velocities'':

:&lt;math&gt;\frac{d\mathbf{q}}{dt} = \left(\frac{dq_1}{dt},\frac{dq_2}{dt},\cdots \frac{dq_N}{dt}\right) \equiv \mathbf{\dot{q}} = (\dot{q}_1,\dot{q}_2,\cdots \dot{q}_N) &lt;/math&gt;.

;[[D'Alembert's principle]]

The foundation which the subject is built on is ''D'Alembert's principle''.

This principle states that infinitesimal ''[[virtual work]]'' done by a force across reversible displacements is zero, which is the work done by a force consistent with ideal constraints of the system. The idea of a constraint is useful - since this limits what the system can do, and can provide steps to solving for the motion of the system. The equation for D'Alembert's principle is:

:&lt;math&gt;\delta W = \boldsymbol{\mathcal{Q}}\cdot\delta\mathbf{q} = 0 \,,&lt;/math&gt;

where

:&lt;math&gt;\boldsymbol{\mathcal{Q}} = (\mathcal{Q}_1,\mathcal{Q}_2,\cdots \mathcal{Q}_N)&lt;/math&gt;

are the [[generalized forces]] (script Q instead of ordinary Q is used here to prevent conflict with canonical transformations below) and '''q''' are the generalized coordinates. This leads to the generalized form of [[Newton's laws]] in the language of analytical mechanics:

:&lt;math&gt;\boldsymbol{\mathcal{Q}} = \frac{\mathrm{d}}{\mathrm{d}t} \left ( \frac {\partial T}{\partial \mathbf{\dot{q}}} \right ) - \frac {\partial T}{\partial \mathbf{q}}\,,&lt;/math&gt;

where ''T'' is the total [[kinetic energy]] of the system, and the notation

:&lt;math&gt;\frac {\partial }{\partial \mathbf{q}}=\left(\frac{\partial }{\partial q_1},\frac{\partial }{\partial q_2},\cdots \frac{\partial }{\partial q_N}\right)&lt;/math&gt;

is a useful shorthand (see [[matrix calculus#Scalar-by-vector|matrix calculus]] for this notation).
 
'''[[Holonomic constraints]]'''

If the curvilinear coordinate system is defined by the standard [[position vector]] '''r''', and if the position vector can be written in terms of the generalized coordinates '''q''' and time ''t'' in the form:

:&lt;math&gt;\mathbf{r} = \mathbf{r}(\mathbf{q}(t),t)&lt;/math&gt;
and this relation holds for all times ''t'', then '''q''' are called ''Holonomic constraints''.&lt;ref&gt;McGraw Hill Encyclopaedia of Physics (2nd Edition), C.B. Parker, 1994, {{ISBN|0-07-051400-3}}&lt;/ref&gt; Vector '''r''' is explicitly dependent on ''t'' in cases when the constraints vary with time, not just because of '''q'''(''t''). For time-independent situations, the constraints are also called '''[[Scleronomous|scleronomic]]''', for time-dependent cases they are called '''[[Rheonomous|rheonomic]]'''.&lt;ref name="autogenerated1"/&gt;

==Lagrangian mechanics==

'''[[Lagrangian mechanics|Lagrangian]] and [[Euler–Lagrange equations]]'''

The introduction of generalized coordinates and the fundamental Lagrangian function:

:&lt;math&gt;L(\mathbf{q},\mathbf{\dot{q}},t) = T(\mathbf{q},\mathbf{\dot{q}},t) - V(\mathbf{q},\mathbf{\dot{q}},t)&lt;/math&gt;

where ''T'' is the total [[kinetic energy]] and ''V'' is the total [[potential energy]] of the entire system, then either following the [[calculus of variations]] or using the above formula - lead to the [[Euler–Lagrange equations]];

:&lt;math&gt;\frac{d}{dt}\left(\frac{\partial L}{\partial \mathbf{\dot{q}}}\right) = \frac{\partial L}{\partial \mathbf{q}} \,,&lt;/math&gt;

which are a set of ''N'' second-order [[ordinary differential equation]]s, one for each ''q&lt;sub&gt;i&lt;/sub&gt;''(''t'').

This formulation identifies the actual path followed by the motion as a selection of the path over which the [[time integral]] of [[kinetic energy]] is least, assuming the total energy to be fixed, and imposing no conditions on the time of transit.

'''[[Configuration space (physics)|Configuration space]]'''

The Lagrangian formulation uses the configuration space of the system, the [[set (mathematics)|set]] of all possible generalized coordinates:

:&lt;math&gt;\mathcal{C} = \{ \mathbf{q} \in \mathbb{R}^N \}\,,&lt;/math&gt;

where &lt;math&gt;\mathbb{R}^N&lt;/math&gt; is ''N''-dimensional [[real number|real]] space (see also [[set-builder notation]]). The particular solution to the Euler–Lagrange equations is called a ''(configuration) path or trajectory'', i.e. one particular '''q'''(''t'') subject to the required [[initial conditions]]. The general solutions form a set of possible configurations as functions of time:

:&lt;math&gt;\{ \mathbf{q}(t) \in \mathbb{R}^N \,:\,t\ge 0,t\in \mathbb{R}\}\subseteq\mathcal{C}\,,&lt;/math&gt;

The configuration space can be defined more generally, and indeed more deeply, in terms of [[topology|topological]] [[manifold]]s and the [[tangent bundle]].

==Hamiltonian mechanics==

'''[[Hamiltonian mechanics|Hamiltonian and Hamilton's equations]]'''

The [[Legendre transformation]] of the Lagrangian replaces the generalized coordinates and velocities ('''q''', '''q̇''') with ('''q''', '''p'''); the generalized coordinates and the ''[[Canonical coordinates|generalized momenta]]'' conjugate to the generalized coordinates:

:&lt;math&gt;\mathbf{p} = \frac{\partial L}{\partial \mathbf{\dot{q}}} = \left(\frac{\partial L}{\partial \dot{q}_1},\frac{\partial L}{\partial \dot{q}_2},\cdots \frac{\partial L}{\partial \dot{q}_N}\right) = (p_1, p_2\cdots p_N)\,,&lt;/math&gt;

and introduces the Hamiltonian (which is in terms of generalized coordinates and momenta):

:&lt;math&gt;H(\mathbf{q},\mathbf{p},t) = \mathbf{p}\cdot\mathbf{\dot{q}} - L(\mathbf{q},\mathbf{\dot{q}},t)&lt;/math&gt;

where '''•''' denotes the [[dot product]], also leading to [[Hamiltonian mechanics|Hamilton's equations]]:

:&lt;math&gt;\mathbf{\dot{p}} = - \frac{\partial H}{\partial \mathbf{q}}\,,\quad \mathbf{\dot{q}} = + \frac{\partial H}{\partial \mathbf{p}} \,,&lt;/math&gt;

which are now a set of 2''N'' first-order ordinary differential equations, one for each ''q&lt;sub&gt;i&lt;/sub&gt;''(''t'') and ''p&lt;sub&gt;i&lt;/sub&gt;''(''t''). Another result from the Legendre transformation relates the time derivatives of the Lagrangian and Hamiltonian:

:&lt;math&gt;\frac{dH}{dt}=-\frac{\partial L}{\partial t}\,,&lt;/math&gt;

which is often considered one of Hamilton's equations of motion additionally to the others. The generalized momenta can be written in terms of the generalized forces in the same way as Newton's second law:

:&lt;math&gt;\mathbf{\dot{p}} = \boldsymbol{\mathcal{Q}}\,.&lt;/math&gt;

'''Generalized [[momentum space]]'''

Analogous to the configuration space, the set of all momenta is the ''momentum space'' (technically in this context; ''generalized momentum space''):

:&lt;math&gt;\mathcal{M} = \{ \mathbf{p}\in\mathbb{R}^N \}\,.&lt;/math&gt;

"Momentum space" also refers to "'''k'''-space"; the set of all [[wave vector]]s (given by [[De Broglie relation]]s) as used in quantum mechanics and theory of [[wave]]s: this is not referred to in this context.

'''[[Phase space]]'''

The set of all positions and momenta form the ''phase space'';

:&lt;math&gt;\mathcal{P} = \mathcal{C}\times\mathcal{M} = \{ (\mathbf{q},\mathbf{p})\in\mathbb{R}^{2N} \} \,,&lt;/math&gt;

that is, the [[Cartesian product]] × of the configuration space and generalized momentum space.

A particular solution to Hamilton's equations is called a ''[[Phase portrait|phase path]]'', a particular curve ('''q'''(''t''),'''p'''(''t'')) subject to the required initial conditions. The set of all phase paths, the general solution to the differential equations, is the ''[[phase portrait]]'':

:&lt;math&gt;\{ (\mathbf{q}(t),\mathbf{p}(t))\in\mathbb{R}^{2N}\,:\,t\ge0, t\in\mathbb{R} \} \subseteq \mathcal{P}\,,&lt;/math&gt;

;The [[Poisson bracket]]

All dynamical variables can be derived from position '''r''', momentum '''p''', and time ''t'', and written as a function of these: ''A'' = ''A''('''q''', '''p''', ''t''). If ''A''('''q''', '''p''', ''t'') and ''B''('''q''', '''p''', ''t'') are two scalar valued dynamical variables, the ''Poisson bracket'' is defined by the generalized coordinates and momenta:

:&lt;math&gt;
\begin{align}
\{A,B\}  \equiv \{A,B\}_{\mathbf{q},\mathbf{p}} &amp; = \frac{\partial A}{\partial \mathbf{q}}\cdot\frac{\partial B}{\partial \mathbf{p}} - \frac{\partial A}{\partial \mathbf{p}}\cdot\frac{\partial B}{\partial \mathbf{q}}\\
&amp; \equiv \sum_k \frac{\partial A}{\partial q_k}\frac{\partial B}{\partial p_k} - \frac{\partial A}{\partial p_k}\frac{\partial B}{\partial q_k}\,,
\end{align}&lt;/math&gt;

Calculating the [[total derivative]] of one of these, say ''A'', and substituting Hamilton's equations into the result leads to the time evolution of ''A'':

:&lt;math&gt; \frac{dA}{dt} = \{A,H\} + \frac{\partial A}{\partial t}\,. &lt;/math&gt;

This equation in ''A'' is closely related to the equation of motion in the [[Heisenberg picture]] of [[quantum mechanics]], in which classical dynamical variables become [[operator (physics)|quantum operators]] (indicated by hats (^)), and the Poisson bracket is replaced by the [[commutator]] of operators via Dirac's [[canonical quantization]]:

:&lt;math&gt;\{A,B\} \rightarrow \frac{1}{i\hbar}[\hat{A},\hat{B}]\,.&lt;/math&gt;

==Properties of the Lagrangian and Hamiltonian functions==

Following are overlapping properties between the Lagrangian and Hamiltonian functions.&lt;ref name="autogenerated1"/&gt;&lt;ref&gt;''Classical Mechanics'', T.W.B. Kibble, European Physics Series, McGraw-Hill (UK), 1973, {{ISBN|0-07-084018-0}}&lt;/ref&gt;

* All the individual generalized coordinates ''q&lt;sub&gt;i&lt;/sub&gt;''(''t''), velocities ''q̇&lt;sub&gt;i&lt;/sub&gt;''(''t'') and momenta ''p&lt;sub&gt;i&lt;/sub&gt;''(''t'') for every degree of freedom are mutually independent. Explicit time-dependence of a function means the function actually includes time ''t'' as a variable in addition to the '''q'''(''t''), '''p'''(''t''), not simply as a parameter through '''q'''(''t'') and '''p'''(''t''), which would mean explicit time-independence.
* The Lagrangian is invariant under addition of the ''[[total derivative|total]]'' [[time derivative]] of any function of '''q''' and ''t'', that is:

::&lt;math&gt;L' = L +\frac{d}{dt}F(\mathbf{q},t) \,,&lt;/math&gt;

:so each Lagrangian ''L'' and ''L''' describe ''exactly the same motion''. In other words, the Lagrangian of a system is not unique.

* Analogously, the Hamiltonian is invariant under addition of the ''[[partial derivative|partial]]'' time derivative of any function of '''q''', '''p''' and ''t'', that is:

::&lt;math&gt;K = H + \frac{\partial}{\partial t}G(\mathbf{q},\mathbf{p},t) \,,&lt;/math&gt;

:(''K'' is a frequently used letter in this case). This property is used in [[canonical transformations]] (see below).

*If the Lagrangian is independent of some generalized coordinates, then the generalized momenta conjugate to those coordinates are [[Constant of motion|constants of the motion]], i.e. are [[conserved quantity|conserved]], this immediately follows from Lagrange's equations:

::&lt;math&gt;\frac{\partial L}{\partial q_j }=0\,\rightarrow \,\frac{dp_j}{dt} = \frac{d}{dt} \frac{\partial L}{\partial \dot{q}_j}=0 &lt;/math&gt;

:Such coordinates are "[[Lagrangian mechanics|cyclic]]" or "ignorable". It can be shown that the Hamiltonian is also cyclic in exactly the same generalized coordinates.

*If the Lagrangian is time-independent the Hamiltonian is also time-independent (i.e. both are constant in time).
*If the kinetic energy is a [[homogeneous function]] of degree 2 of the generalized velocities, ''and'' the Lagrangian is explicitly time-independent, then:

::&lt;math&gt;T((\lambda \dot{q}_i)^2, (\lambda \dot{q}_j \lambda \dot{q}_k), \mathbf{q}) = \lambda^2 T((\dot{q}_i)^2, \dot{q}_j\dot{q}_k, \mathbf{q})\,,\quad L(\mathbf{q},\mathbf{\dot{q}})\,,&lt;/math&gt;

:where ''λ'' is a constant, then the Hamiltonian will be the ''total conserved energy'', equal to the total kinetic and potential energies of the system:

::&lt;math&gt;H=T+V=E\,.&lt;/math&gt;

:This is the basis for the [[Schrödinger equation]], inserting [[operators (physics)|quantum operators]] directly obtains it.

==Principle of least action==

[[File:Least action principle.svg|250px|thumb|As the system evolves, '''q''' traces a path through [[configuration space (physics)|configuration space]] (only some are shown). The path taken by the system (red) has a stationary action (δ''S'' = 0) under small changes in the configuration of the system (δ'''q''').&lt;ref&gt;{{cite book |last=Penrose |first=R.| title=[[The Road to Reality]]| publisher= Vintage books| year=2007 | page = 474|isbn=0-679-77631-1}}&lt;/ref&gt;]]

[[Action (physics)|Action]] is another quantity in analytical mechanics defined as a [[Functional (mathematics)|functional]] of the Lagrangian:

:&lt;math&gt;\mathcal{S} = \int_{t_1}^{t_2} L(\mathbf{q},\mathbf{\dot{q}},t) dt \,.&lt;/math&gt;

A general way to find the equations of motion from the action is the ''[[principle of least action]]'':&lt;ref&gt;Encyclopaedia of Physics (2nd Edition), R.G. Lerner, G.L. Trigg, VHC publishers, 1991, ISBN (Verlagsgesellschaft) 3-527-26954-1, ISBN (VHC Inc.) 0-89573-752-3&lt;/ref&gt;

:&lt;math&gt;\delta\mathcal{S} = \delta\int_{t_1}^{t_2} L(\mathbf{q},\mathbf{\dot{q}},t) dt = 0\,,&lt;/math&gt;

where the departure ''t''&lt;sub&gt;1&lt;/sub&gt; and arrival ''t''&lt;sub&gt;2&lt;/sub&gt; times are fixed.&lt;ref name=Lanczos/&gt; The term "path" or "trajectory" refers to the [[time evolution]] of the system as a path through configuration space &lt;math&gt;\mathcal{C}&lt;/math&gt;, in other words '''q'''(''t'') tracing out a path in &lt;math&gt;\mathcal{C}&lt;/math&gt;. The path for which action is least is the path taken by the system.

From this principle, ''all'' [[equations of motion]] in classical mechanics can be derived. This approach can be extended to fields rather than a system of particles (see below), and underlies the [[path integral formulation]] of [[quantum mechanics]],&lt;ref name="autogenerated2004"&gt;''Quantum Mechanics'', E. Abers, Pearson Ed., Addison Wesley, Prentice Hall Inc, 2004, {{ISBN|978-0-13-146100-0}}&lt;/ref&gt;&lt;ref name="autogenerated3"&gt;Quantum Field Theory, D. McMahon, Mc Graw Hill (US), 2008, {{ISBN|978-0-07-154382-8}}&lt;/ref&gt; and is used for calculating [[geodesic]] motion in [[general relativity]].&lt;ref&gt;''Relativity, Gravitation, and Cosmology'', R.J.A. Lambourne, Open University, Cambridge University Press, 2010, {{ISBN|978-0-521-13138-4}}&lt;/ref&gt;

==Hamiltonian-Jacobi mechanics==

;[[Canonical transformations]]

The invariance of the Hamiltonian (under addition of the partial time derivative of an arbitrary function of '''p''', '''q''', and ''t'') allows the Hamiltonian in one set of coordinates '''q''' and momenta '''p''' to be transformed into a new set '''Q''' = '''Q'''('''q''', '''p''', ''t'') and '''P''' = '''P'''('''q''', '''p''', ''t''), in four possible ways:

:&lt;math&gt;\begin{align}
&amp; K(\mathbf{Q},\mathbf{P},t) = H(\mathbf{q},\mathbf{p},t) + \frac{\partial }{\partial t}G_1 (\mathbf{q},\mathbf{Q},t)\\
&amp; K(\mathbf{Q},\mathbf{P},t) = H(\mathbf{q},\mathbf{p},t) + \frac{\partial }{\partial t}G_2 (\mathbf{q},\mathbf{P},t)\\
&amp; K(\mathbf{Q},\mathbf{P},t) = H(\mathbf{q},\mathbf{p},t) + \frac{\partial }{\partial t}G_3 (\mathbf{p},\mathbf{Q},t)\\
&amp; K(\mathbf{Q},\mathbf{P},t) = H(\mathbf{q},\mathbf{p},t) + \frac{\partial }{\partial t}G_4 (\mathbf{p},\mathbf{P},t)\\
\end{align}&lt;/math&gt;

With the restriction on '''P''' and '''Q''' such that the transformed Hamiltonian system is:

:&lt;math&gt;\mathbf{\dot{P}} = - \frac{\partial K}{\partial \mathbf{Q}}\,,\quad \mathbf{\dot{Q}} = + \frac{\partial K}{\partial \mathbf{P}} \,,&lt;/math&gt;

the above transformations are called ''canonical transformations'', each function ''G&lt;sub&gt;n&lt;/sub&gt;'' is called a [[Generating function (physics)|generating function]] of the "''n''th kind" or "type-''n''". The transformation of coordinates and momenta can allow simplification for solving Hamilton's equations for a given problem.

The choice of '''Q''' and '''P''' is completely arbitrary, but not every choice leads to a canonical transformation. One simple criterion for a transformation '''q''' → '''Q''' and '''p''' → '''P''' to be canonical is the Poisson bracket be unity,

:&lt;math&gt;\{Q_i,P_i\} = 1&lt;/math&gt;

for all ''i'' = 1, 2,...''N''. If this does not hold then the transformation is not canonical.&lt;ref name="autogenerated1"/&gt;

;The [[Hamilton–Jacobi equation]]

By setting the canonically transformed Hamiltonian ''K'' = 0, and the type-2 generating function equal to '''Hamilton's principal function''' (also the action &lt;math&gt;\mathcal{S}&lt;/math&gt;) plus an arbitrary constant ''C'':

:&lt;math&gt;G_2(\mathbf{q},t) = \mathcal{S}(\mathbf{q},t) + C\,,&lt;/math&gt;

the generalized momenta become:

:&lt;math&gt;\mathbf{p} = \frac{\partial\mathcal{S}}{\partial \mathbf{q}}&lt;/math&gt;

and '''P''' is constant, then the Hamiltonian-Jacobi equation (HJE) can be derived from the type-2 canonical transformation:

:&lt;math&gt;H = - \frac{\partial\mathcal{S}}{\partial t}&lt;/math&gt;

where ''H'' is the Hamiltonian as before:

:&lt;math&gt;H = H(\mathbf{q},\mathbf{p},t) = H\left(\mathbf{q},\frac{\partial\mathcal{S}}{\partial \mathbf{q}},t\right)&lt;/math&gt;

Another related function is '''Hamilton's characteristic function'''

:&lt;math&gt;W(\mathbf{q})=\mathcal{S}(\mathbf{q},t) + Et &lt;/math&gt;

used to solve the HJE by [[separation of variables|additive separation of variables]] for a time-independent Hamiltonian ''H''.

The study of the solutions of the Hamilton–Jacobi equations leads naturally to the study of [[symplectic manifold]]s and [[symplectic topology]].&lt;ref name=Arnold&gt;{{cite book |title=Mathematical methods of classical mechanics |last=Arnolʹd |first=VI |year=1989 |publisher=Springer |edition=2nd |page= Chapter 8 |isbn=978-0-387-96890-2 |url=https://books.google.com/books?id=Pd8-s6rOt_cC&amp;printsec=frontcover&amp;dq=isbn=9780387968902#PPT18,M1 |nopp=true}}&lt;/ref&gt;&lt;ref name=Doran&gt;{{cite book |title=Geometric algebra for physicists |last1=Doran |first1=C |last2=Lasenby |first2=A |publisher=Cambridge University Press |page=§12.3, pp. 432–439 |isbn=978-0-521-71595-9 |year=2003 |url=http://www.worldcat.org/search?q=9780521715959&amp;qt=owc_search}}&lt;/ref&gt;  In this formulation, the solutions of the Hamilton–Jacobi equations are the [[integral curve]]s of [[Hamiltonian vector field]]s.

==Routhian mechanics==

'''[[Routhian mechanics]]''' is a hybrid formulation of Lagrangian and Hamiltonian mechanics, not often used but especially useful for removing cyclic coordinates. If the Lagrangian of a system has ''s'' cyclic coordinates '''q''' = ''q''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;2&lt;/sub&gt;, ... ''q&lt;sub&gt;s&lt;/sub&gt;'' with conjugate momenta '''p''' = ''p''&lt;sub&gt;1&lt;/sub&gt;, ''p''&lt;sub&gt;2&lt;/sub&gt;, ... ''p&lt;sub&gt;s&lt;/sub&gt;'', with the rest of the coordinates non-cyclic and denoted '''ζ''' = ''ζ''&lt;sub&gt;1&lt;/sub&gt;, ''ζ''&lt;sub&gt;1&lt;/sub&gt;, ..., ''ζ&lt;sub&gt;N − s&lt;/sub&gt;'', they can be removed by introducing the ''Routhian'':

:&lt;math&gt;R=\mathbf{p}\cdot\mathbf{\dot{q}} - L(\mathbf{q}, \mathbf{p}, \boldsymbol{\zeta}, \dot{\boldsymbol{\zeta}})\,,&lt;/math&gt;

which leads to a set of 2''s'' Hamiltonian equations for the cyclic coordinates '''q''',

:&lt;math&gt;\dot{\mathbf{q}} = +\frac{\partial R}{\partial \mathbf{p}}\,,\quad \dot{\mathbf{p}} = -\frac{\partial R}{\partial \mathbf{q}}\,,&lt;/math&gt;

and ''N'' − ''s'' Lagrangian equations in the non cyclic coordinates '''ζ'''.

:&lt;math&gt;\frac{d}{dt}\frac{\partial R }{\partial\dot{\boldsymbol{\zeta}}} = \frac{\partial R}{\partial \boldsymbol{\zeta}}\,.&lt;/math&gt;

Set up in this way, although the Routhian has the form of the Hamiltonian, it can be thought of a Lagrangian with ''N'' − ''s'' degrees of freedom.

The coordinates '''q''' do not have to be cyclic, the partition between which coordinates enter the Hamiltonian equations and those which enter the Lagrangian equations is arbitrary. It is simply convenient to let the Hamiltonian equations remove the cyclic coordinates, leaving the non cyclic coordinates to the Lagrangian equations of motion.

==Appellian mechanics==

'''[[Appell's equation of motion]]''' involve generalized accelerations, the second time derivatives of the generalized coordinates:

:&lt;math&gt;\alpha_r = \ddot{q}_r = \frac{d^2 q_r}{dt^2}\,,&lt;/math&gt;

as well as generalized forces mentioned above in D'Alembert's principle. The equations are

:&lt;math&gt;\mathcal{Q}_{r} = \frac{\partial S}{\partial \alpha_{r}}\,, \quad S = \frac{1}{2} \sum_{k=1}^{N} m_{k} \mathbf{a}_{k}^{2}\,,&lt;/math&gt;

where

:&lt;math&gt;\mathbf{a}_k = \ddot{\mathbf{r}}_k = \frac{d^2 \mathbf{r}_k}{dt^2}&lt;/math&gt;

is the acceleration of the ''k'' particle, the second time derivative of its position vector. Each acceleration '''a'''&lt;sub&gt;''k''&lt;/sub&gt; is expressed in terms of the generalized accelerations ''α&lt;sub&gt;r&lt;/sub&gt;'', likewise each '''r'''&lt;sub&gt;k&lt;/sub&gt; are expressed in terms the generalized coordinates ''q&lt;sub&gt;r&lt;/sub&gt;''.

==Extensions to classical field theory==

;[[Lagrangian field theory]]

Generalized coordinates apply to discrete particles. For ''N'' [[scalar field]]s ''φ&lt;sub&gt;i&lt;/sub&gt;''('''r''', ''t'') where ''i'' = 1, 2, ... ''N'', the '''[[Lagrangian density]]''' is a function of these fields and their space and time derivatives, and possibly the space and time coordinates themselves:

&lt;math&gt;\mathcal{L} = \mathcal{L}(\phi_1, \phi_2, \ldots \nabla\phi_1, \nabla\phi_2, \ldots \partial\phi_1/\partial t, \partial\phi_2/\partial t, \ldots  \mathbf{r}, t)\,.&lt;/math&gt;

and the Euler–Lagrange equations have an analogue for fields:

:&lt;math&gt;\partial_\mu\left(\frac{\partial \mathcal{L}}{\partial(\partial_\mu \phi_i)}\right) = \frac{\partial \mathcal{L}}{\partial \phi_i}\,,&lt;/math&gt;

where ''∂&lt;sub&gt;μ&lt;/sub&gt;'' denotes the [[4-gradient]] and the [[summation convention]] has been used. For ''N'' scalar fields, these Lagranian field equations are a set of ''N'' second order partial differential equations in the fields, which in general will be coupled and nonlinear.

This scalar field formulation can be extended to [[vector field]]s, [[tensor field]]s, and [[spinor field]]s.

The Lagrangian is the [[volume integral]] of the Lagrangian density:&lt;ref name="autogenerated3"/&gt;&lt;ref&gt;Gravitation, J.A. Wheeler, C. Misner, K.S. Thorne, W.H. Freeman &amp; Co, 1973, {{ISBN|0-7167-0344-0}}&lt;/ref&gt;

:&lt;math&gt;L = \int_\mathcal{V} \mathcal{L} \, dV \,.&lt;/math&gt;

Originally developed for classical fields, the above formulation is applicable to all physical fields in classical, quantum, and relativistic situations: such as [[Newton's law of universal gravitation|Newtonian gravity]], [[classical electromagnetism]], [[general relativity]], and [[quantum field theory]]. It is a question of determining the correct Lagrangian density to generate the correct field equation.

;[[Hamiltonian field theory]]

The corresponding "momentum" field densities conjugate to the ''N'' scalar fields ''φ&lt;sub&gt;i&lt;/sub&gt;''('''r''', ''t'') are:&lt;ref name="autogenerated3"/&gt;

:&lt;math&gt;\pi_i(\mathbf{r},t) = \frac{\partial \mathcal{L}}{\partial \dot{\phi}_i}\,\quad\dot{\phi}_i\equiv \frac{\partial \phi_i}{\partial t}.&lt;/math&gt;

where in this context the overdot denotes a partial time derivative, not a total time derivative. The '''Hamiltonian density''' &lt;math&gt;\mathcal{H}&lt;/math&gt; is defined by analogy with mechanics:

:&lt;math&gt;\mathcal{H}(\phi_1, \phi_2,\ldots, \pi_1, \pi_2, \ldots,\mathbf{r},t) = \sum_{i=1}^N \dot{\phi}_i(\mathbf{r},t)\pi_i(\mathbf{r},t) - \mathcal{L}\,.&lt;/math&gt;

The equations of motion are:

:&lt;math&gt;\dot{\phi}_i = +\frac{\delta\mathcal{H}}{\delta \pi_i}\,,\quad \dot{\pi}_i = - \frac{\delta\mathcal{H}}{\delta \phi_i} \,, &lt;/math&gt;

where the [[variational derivative]]

:&lt;math&gt;\frac{\delta}{\delta \phi_i} = \frac{\partial}{\partial \phi_i} - \partial_\mu \frac{\partial }{\partial (\partial_\mu \phi_i)} &lt;/math&gt;

must be used instead of merely partial derivatives. For ''N'' fields, these Hamiltonian field equations are a set of 2''N'' first order partial differential equations, which in general will be coupled and nonlinear.

Again, the volume integral of the Hamiltonian density is the Hamiltonian

:&lt;math&gt;H = \int_\mathcal{V} \mathcal{H} \, dV \,.&lt;/math&gt;

==Symmetry, conservation, and Noether's theorem==

;[[symmetry (physics)|Symmetry transformations]] in classical space and time

Each transformation can be described by an operator (i.e. function acting on the position '''r''' or momentum '''p''' variables to change them). The following are the cases when the operator does not change '''r''' or '''p''', i.e. symmetries.&lt;ref name="autogenerated2004"/&gt;

:{| class="wikitable"
|-
! Transformation 
! Operator
! Position
! Momentum
|-
| [[Translational symmetry]] 
| &lt;math&gt;X(\mathbf{a})&lt;/math&gt;
| &lt;math&gt;\mathbf{r}\rightarrow \mathbf{r} + \mathbf{a}&lt;/math&gt;
| &lt;math&gt;\mathbf{p}\rightarrow \mathbf{p}&lt;/math&gt;
|-
| [[Time translation]]
| &lt;math&gt;U(t_0)&lt;/math&gt;
| &lt;math&gt;\mathbf{r}(t)\rightarrow \mathbf{r}(t+t_0)&lt;/math&gt;
| &lt;math&gt;\mathbf{p}(t)\rightarrow \mathbf{p}(t+t_0)&lt;/math&gt;
|-
| [[Rotational invariance]] 
| &lt;math&gt;R(\mathbf{\hat{n}},\theta)&lt;/math&gt;
| &lt;math&gt;\mathbf{r}\rightarrow R(\mathbf{\hat{n}},\theta)\mathbf{r}&lt;/math&gt;
| &lt;math&gt;\mathbf{p}\rightarrow R(\mathbf{\hat{n}},\theta)\mathbf{p}&lt;/math&gt;
|- 
| [[Galilean transformation]]s
| &lt;math&gt;G(\mathbf{v})&lt;/math&gt;
| &lt;math&gt;\mathbf{r}\rightarrow \mathbf{r} + \mathbf{v}t&lt;/math&gt;
| &lt;math&gt;\mathbf{p}\rightarrow \mathbf{p} + m\mathbf{v}&lt;/math&gt;
|-
| [[Parity (physics)|Parity]]
| &lt;math&gt;P&lt;/math&gt;
| &lt;math&gt;\mathbf{r}\rightarrow -\mathbf{r}&lt;/math&gt;
| &lt;math&gt;\mathbf{p}\rightarrow -\mathbf{p}&lt;/math&gt;
|-
| [[T-symmetry]]
| &lt;math&gt;T&lt;/math&gt;
| &lt;math&gt;\mathbf{r}\rightarrow \mathbf{r}(-t)&lt;/math&gt;
| &lt;math&gt;\mathbf{p}\rightarrow -\mathbf{p}(-t)&lt;/math&gt;
|}

where ''R''('''n̂''', θ) is the [[rotation matrix]] about an axis defined by the [[unit vector]] '''n̂''' and angle θ.

;[[Noether's theorem]]

Noether's theorem states that a [[continuous variable|continuous]] symmetry transformation of the action corresponds to a [[Conservation law (physics)|conservation law]], i.e. the action (and hence the Lagrangian) doesn't change under a transformation parameterized by a [[parameter]] ''s'':

:&lt;math&gt;L[q(s,t), \dot{q}(s,t)] = L[q(t), \dot{q}(t)] &lt;/math&gt;

the Lagrangian describes the same motion independent of ''s'', which can be length, angle of rotation, or time. The corresponding momenta to ''q'' will be conserved.&lt;ref name="autogenerated1"/&gt;

==See also==

*[[Udwadia–Kalaba equation]]
*[[Applied mechanics]]
*[[Classical mechanics]]
*[[Analytical dynamics|Dynamics]]
*[[Hamilton–Jacobi equation]]
*[[Hamilton's principle]]
*[[Kinematics]]
*[[Kinetics (physics)]]
*[[Non-autonomous mechanics]]

==References and notes==
&lt;references/&gt;

{{Physics-footer}}

{{Authority control}}

{{DEFAULTSORT:Analytical Mechanics}}
[[Category:Theoretical physics]]
[[Category:Dynamical systems]]</text>
      <sha1>ajbqf6g4vfhsmer8pmd8tuwfp3tr8ot</sha1>
    </revision>
  </page>
  <page>
    <title>Atiyah–Jones conjecture</title>
    <ns>0</ns>
    <id>34995804</id>
    <revision>
      <id>870911681</id>
      <parentid>870907397</parentid>
      <timestamp>2018-11-27T19:19:28Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: bibcode. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:Headbomb|Headbomb]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2366">In [[mathematics]], the '''Atiyah–Jones conjecture''' is a [[conjecture]] about the [[Homology (mathematics)|homology]] of the [[moduli space]] of [[instantons]] over a [[Sphere (geometry)|sphere]]. It was introduced by {{harvs|txt | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Jones | first2=John D. S. | title=Topological aspects of Yang-Mills theory | url=http://projecteuclid.org/getRecord?id=euclid.cmp/1103904210 | mr=503187  | year=1978 | journal=[[Communications in Mathematical Physics]] | issn=0010-3616 | volume=61 | issue=2 | pages=97–118}} and proved by {{harvs|txt| last1=Boyer | first1=Charles P. | last2=Hurtubise | first2=Jacques C. |author2-link=Jacques Hurtubise (mathematician)| last3=Mann | first3=Benjamin M. | last4=Milgram | first4=R. James |  year1=1992|year2=1993 |}}.

==References==

*{{Citation | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Jones | first2=John D. S. | title=Topological aspects of Yang-Mills theory | url=http://projecteuclid.org/getRecord?id=euclid.cmp/1103904210 | mr=503187  | year=1978 | journal=[[Communications in Mathematical Physics]] | issn=0010-3616 | volume=61 | issue=2 | pages=97–118 | doi=10.1007/bf01609489|bibcode = 1978CMaPh..61...97A }}
*{{Citation | last1=Boyer | first1=Charles P. | last2=Hurtubise | first2=Jacques C.|author2-link=Jacques Hurtubise (mathematician) | last3=Mann | first3=Benjamin M. | last4=Milgram | first4=R. James | title=The Atiyah–Jones conjecture | doi=10.1090/S0273-0979-1992-00286-0 | mr=1130447  | year=1992 | journal=[[Bulletin of the American Mathematical Society]] |series=New Series | issn=0002-9904 | volume=26 | issue=2 | pages=317–321| arxiv=math/9204226 | bibcode=1994BAMaS..30..205W }}
*{{Citation | last1=Boyer | first1=Charles P. | last2=Hurtubise | first2=Jacques C. |author2-link=Jacques Hurtubise (mathematician)| last3=Mann | first3=Benjamin M. | last4=Milgram | first4=R. James | title=The topology of instanton moduli spaces. I. The Atiyah–Jones conjecture | mr=1217348 | year=1993 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=137 | issue=3 | pages=561–609|jstor=2946532 | doi=10.2307/2946532}}

{{DEFAULTSORT:Atiyah-Jones conjecture}}
[[Category:Topology]]
[[Category:Quantum chromodynamics]]
[[Category:Conjectures that have been proved]]</text>
      <sha1>kxa883e1kjrhgp3ei1sj508gv6l6dlh</sha1>
    </revision>
  </page>
  <page>
    <title>Bernstein–Zelevinsky classification</title>
    <ns>0</ns>
    <id>32295384</id>
    <revision>
      <id>811794321</id>
      <parentid>570457328</parentid>
      <timestamp>2017-11-24T00:58:16Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Annales Scientifiques de l'École Normale Supérieure. Quatrième Série → Annales Scientifiques de l'École Normale Supérieure |series=Série 4 (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2025">In mathematics, the '''Bernstein–Zelevinsky classification''', introduced by {{harvs|txt|author1-link=Joseph Bernstein|last=Bernstein|last2=Zelevinsky|author2-link=Andrei Zelevinsky|year=1977}} and {{harvtxt|Zelevinsky|1980}},  classifies the irreducible complex [[smooth representation]]s of a [[general linear group]] over a [[local field]] in terms of [[cuspidal representation]]s.

==References==

*{{citation|first=J.|last= Bernstein
|title=Representations of p-adic groups
|series=Lectures by Joseph Bernstein. Written by Karl E. Rumelhart
|place=Harvard University|year= 1992|url=http://www.math.tau.ac.il/~bernstei/Publication_list/publication_texts/Bernst_Lecture_p-adic_repr.pdf}} 
*{{Citation | last1=Bernšteĭn | first1=I. N. | last2=Zelevinskiĭ | first2=A. V. | title=Representations of the group GL(n,F), where F is a local non-Archimedean field | url=http://www.math.tau.ac.il/~bernstei/Publication_list/publication_texts/B-Zel-RepsGL-Usp.pdf | series=Translation in Russian mathematical Surveys | mr=0425030 | year=1976 | journal=Akademiya Nauk SSSR i Moskovskoe Matematicheskoe Obshchestvo. Uspekhi Matematicheskikh Nauk | issn=0042-1316 | volume=31 | issue=3 | pages=5–70}}
*{{Citation | last1=Bernstein | first1=I. N. | last2=Zelevinsky | first2=A. V. | title=Induced representations of reductive p-adic groups. I | url=http://www.numdam.org/item?id=ASENS_1977_4_10_4_441_0 | mr=0579172 | year=1977 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 4 | issn=0012-9593 | volume=10 | issue=4 | pages=441–472}}
*{{Citation | last1=Zelevinsky | first1=A. V. | title=Induced representations of reductive p-adic groups. II. On irreducible representations of GL(n) | url=http://www.numdam.org/item?id=ASENS_1980_4_13_2_165_0 | mr=584084 | year=1980 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 4 | issn=0012-9593 | volume=13 | issue=2 | pages=165–210}}

{{DEFAULTSORT:Bernstein-Zelevinsky classification}}
[[Category:Representation theory]]</text>
      <sha1>hpqmznibt8ngxi2fucbuy9fnfnar2qo</sha1>
    </revision>
  </page>
  <page>
    <title>Caterpillar tree</title>
    <ns>0</ns>
    <id>27258886</id>
    <revision>
      <id>811320318</id>
      <parentid>791615512</parentid>
      <timestamp>2017-11-20T21:46:30Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* Computational complexity */Rep [[typographic ligature]] "ﬁ" with plain text; possible ref cleanup; [[WP:GenFixes]] on, replaced: ﬁ → fi (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8934">{{about|graph theory|the shrub|Plumeria alba}}
[[File:Caterpillar tree.svg|thumb|300px|A caterpillar]]
In [[graph theory]], a '''caterpillar''' or '''caterpillar tree''' is a [[tree (graph theory)|tree]] in which all the vertices are within distance 1 of a central path.

Caterpillars were first studied in a series of papers by Harary and Schwenk. The name was suggested by [[Arthur Hobbs (mathematician)|A. Hobbs]].&lt;ref name="hs73"/&gt;&lt;ref name="eb87"/&gt; As {{harvtxt|Harary|Schwenk|1973}} colorfully write, "A caterpillar is a tree which metamorphoses into a path when its cocoon of endpoints is removed."&lt;ref name="hs73"&gt;{{citation
 | last1 = Harary | first1 = Frank | author1-link = Frank Harary
 | last2 = Schwenk | first2 = Allen J.
 | issue = 4
 | journal = Discrete Mathematics
 | pages = 359–365
 | title = The number of caterpillars
 | volume = 6
 | year = 1973 | doi=10.1016/0012-365x(73)90067-8}}.&lt;/ref&gt;

==Equivalent characterizations==
The following characterizations all describe the caterpillar trees:
*They are the trees for which removing the leaves and incident edges produces a [[path graph]].&lt;ref name="eb87"/&gt;&lt;ref name="hs71"/&gt;
*They are the trees in which there exists a path that contains every vertex of degree two or more.
*They are the trees in which every vertex of degree at least three has at most two non-leaf neighbors.
*They are the trees that do not contain as a subgraph the graph formed by replacing every edge in the [[star graph]] ''K''&lt;sub&gt;1,3&lt;/sub&gt; by a path of length two.&lt;ref name="hs71"/&gt;
*They are the connected graphs that can be [[graph drawing|drawn]] with their vertices on two parallel lines, with edges represented as non-crossing line segments that have one endpoint on each line.&lt;ref name="hs71"/&gt;&lt;ref&gt;{{citation
 | last1 = Harary | first1 = Frank | author1-link = Frank Harary
 | last2 = Schwenk | first2 = Allen J.
 | journal = Utilitas Math.
 | pages = 203–209
 | title = A new crossing number for bipartite graphs
 | volume = 1
 | year = 1972}}.&lt;/ref&gt;
*They are the trees whose [[Glossary of graph theory#Distance|square]] is a [[Hamiltonian graph]]. That is, in a caterpillar, there exists a cyclic sequence of all the vertices in which each adjacent pair of vertices in the sequence is at distance one or two from each other, and trees that are not caterpillars do not have such a sequence. A cycle of this type may be obtained by drawing the caterpillar on two parallel lines and concatenating the sequence of vertices on one line with the reverse of the sequence on the other line.&lt;ref name="hs71"&gt;{{citation
 | last1 = Harary | first1 = Frank | author1-link = Frank Harary
 | last2 = Schwenk | first2 = Allen J.
 | doi = 10.1112/S0025579300008494
 | journal = Mathematika
 | pages = 138–140
 | title = Trees with Hamiltonian square
 | volume = 18
 | year = 1971}}.&lt;/ref&gt;
*They are the trees whose [[line graph]]s contain a [[Hamiltonian path]]; such a path may be obtained by the ordering of the edges in a two-line drawing of the tree. More generally the number of edges that need to be added to the line graph of an arbitrary tree so that it contains a Hamiltonian path (the size of its [[Hamiltonian completion]]) equals the minimum number of edge-disjoint caterpillars that the edges of the tree can be decomposed into.&lt;ref&gt;{{citation
 | last = Raychaudhuri | first = Arundhati
 | doi = 10.1016/0020-0190(95)00163-8
 | issue = 6
 | journal = [[Information Processing Letters]]
 | pages = 299–306
 | title = The total interval number of a tree and the Hamiltonian completion number of its line graph
 | volume = 56
 | year = 1995}}.&lt;/ref&gt;
*They are the connected graphs of [[pathwidth]] one.&lt;ref name="pt99"/&gt;
*They are the connected [[triangle-free graph|triangle-free]] [[interval graph]]s.&lt;ref&gt;{{citation
 | last = Eckhoff | first = Jürgen
 | doi = 10.1002/jgt.3190170112
 | issue = 1
 | journal = Journal of Graph Theory
 | pages = 117–127
 | title = Extremal interval graphs
 | volume = 17
 | year = 1993}}.&lt;/ref&gt;

==Generalizations==
A [[k-tree|''k''-tree]] is a [[chordal graph]] with exactly {{nowrap|''n'' &amp;minus; ''k''}} [[maximal clique]]s, each containing {{nowrap|''k'' + 1}} vertices; in a ''k''-tree that is not itself a {{nowrap|(''k'' + 1)-clique}}, each maximal clique either separates the graph into two or more components, or it contains a single leaf vertex, a vertex that belongs to only a single maximal clique. A ''k''-path is a ''k''-tree with at most two leaves, and a ''k''-caterpillar is a ''k''-tree that can be partitioned into a ''k''-path and some ''k''-leaves, each adjacent to a [[vertex separator|separator]] ''k''-clique of the ''k''-path. In this terminology, a 1-caterpillar is the same thing as a caterpillar tree, and ''k''-caterpillars are the edge-maximal graphs with [[pathwidth]] ''k''.&lt;ref name="pt99"&gt;{{citation
 | last1 = Proskurowski | first1 = Andrzej
 | last2 = Telle | first2 = Jan Arne
 | journal = Discrete Mathematics and Theoretical Computer Science
 | pages = 167–176
 | title = Classes of graphs with restricted interval models
 | url = http://www.emis.ams.org/journals/DMTCS/volumes/abstracts/pdfpapers/dm030404.pdf
 | volume = 3
 | year = 1999}}.&lt;/ref&gt;

A '''lobster''' graph is a [[tree (graph theory)|tree]] in which all the vertices are within distance&amp;nbsp;2 of a central [[path (graph theory)|path]].&lt;ref&gt;{{mathworld|urlname=LobsterGraph|title=Lobster graph}}&lt;/ref&gt;

==Enumeration==
Caterpillars provide one of the rare [[graph enumeration]] problems for which a precise formula can be given: when ''n''&amp;nbsp;≥&amp;nbsp;3, the number of caterpillars with ''n'' unlabeled vertices is &lt;ref name="hs73"/&gt;
:&lt;math&gt;2^{n-4}+2^{\lfloor (n-4)/2\rfloor}.&lt;/math&gt;
For ''n'' = 1, 2, 3, ... the numbers of ''n''-vertex caterpillars are
:1, 1, 1, 2, 3, 6, 10, 20, 36, 72, 136, 272, 528, 1056, 2080, 4160, ... {{OEIS|A005418}}.

==Computational complexity==
Finding a spanning caterpillar in a graph is [[NP-complete]]. A related optimization problem is the Minimum Spanning Caterpillar Problem (MSCP), where a graph has dual costs over its edges and the goal is to find a caterpillar tree that spans the input graph and has the smallest overall cost. Here the cost of the caterpillar is defined as the sum of the costs of its edges, where each edge takes one of the two costs based on its role as a leaf edge or an internal one.  There is no f(n)-[[approximation algorithm]] for the MSCP unless [[P = NP]].  Here f(n) is any polynomial-time computable function of n, the number of vertices of a graph.&lt;ref name="mk11"/&gt;

There is a parametrized algorithm that finds an optimal solution for the MSCP in bounded [[treewidth]] graphs. So both the Spanning Caterpillar Problem and the MSCP have linear time algorithms if a graph is an outerplanar, a series-parallel, or a [[Halin graph]].&lt;ref name="mk11"&gt;{{cite thesis |type=Ph.D. |first=Masoud |last=Khosravani |title=Searching for optimal caterpillars in general and bounded treewidth graphs |publisher=University of Auckland |year=2011| url = https://researchspace.auckland.ac.nz/handle/2292/8360?show=full}}&lt;/ref&gt;

==Applications==
Caterpillar trees have been used in [[chemical graph theory]] to represent the structure of [[benzenoid]] [[hydrocarbon]] molecules. In this representation, one forms a caterpillar in which each edge corresponds to a 6-carbon ring in the molecular structure, and two edges are incident at a vertex whenever the corresponding rings belong to a sequence of rings connected end-to-end in the structure. {{harvtxt|El-Basil|1987}} writes, "It is amazing that nearly all graphs that played an important role in what is now called "chemical graph theory" may be related to caterpillar trees." In this context, caterpillar trees are also known as '''benzenoid trees''' and '''Gutman trees''', after the work of Ivan Gutman in this area.&lt;ref name="eb87"&gt;{{citation
 | last = El-Basil | first = Sherif
 | doi = 10.1007/BF01205666
 | issue = 2
 | journal = Journal of Mathematical Chemistry
 | pages = 153–174
 | title = Applications of caterpillar trees in chemistry and physics
 | volume = 1
 | year = 1987}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Gutman | first = Ivan
 | doi = 10.1007/BF00554539
 | issue = 4
 | journal = Theoretica Chimica Acta
 | pages = 309–315
 | title = Topological properties of benzenoid systems
 | volume = 45
 | year = 1977}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = El-Basil | first = Sherif
 | contribution = Caterpillar (Gutman) trees in chemical graph theory
 | doi = 10.1007/3-540-51505-4_28
 | editor1-last = Gutman | editor1-first = I.
 | editor2-last = Cyvin | editor2-first = S. J.
 | pages = 273–289
 | series = Topics in Current Chemistry
 | title = Advances in the Theory of Benzenoid Hydrocarbons
 | volume = 153
 | year = 1990}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*{{mathworld|urlname=Caterpillar|title=Caterpillar}}

[[Category:Trees (graph theory)]]
[[Category:Mathematical chemistry]]</text>
      <sha1>5sa999fj4d2hu88rrglo3p2lobk00xk</sha1>
    </revision>
  </page>
  <page>
    <title>Caucher Birkar</title>
    <ns>0</ns>
    <id>36465461</id>
    <revision>
      <id>870066764</id>
      <parentid>868242245</parentid>
      <timestamp>2018-11-22T04:32:52Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13155">{{Infobox scientist
| name = Caucher Birkar
| native_name = 
| native_name_lang = 
| image = &lt;!--(as myimage.jpg, no 'File:')--&gt;
| image_size = 
| alt = 
| caption = 
| birth_name = Faraydoun Derakhshani&lt;ref&gt;{{Cite web|url=https://ir.voanews.com/a/fields-medal/4509546.html|title=جایزه معادل «نوبل ریاضی» به یک کرد ایرانی پناهنده به بریتانیا رسید|last=|first=|date=1 August 2018|website=VoA|language=Persian|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.bbc.com/persian/blog-viewpoints-45034870|title=چرا مریم میرزاخانی و کوچر بیرکار مهاجرت کردند؟|last=|first=|date=3 August 2018|website=BBC|language=Persian|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;
| birth_date = {{bya|1978}} &lt;!-- {{Birth date|1978|07|DD}} --&gt;
| birth_place = [[Ney, Iran|Ney]], [[Marivan County]], [[Iran]]
| citizenship = [[Iranian nationality law|Iran]], [[British nationality law|Britain]]
| fields = {{unbulleted list|[[Algebraic geometry]]|[[Birational geometry]]}}
| workplaces = [[University of Cambridge]]
| alma_mater = [[University of Tehran]]&lt;br&gt; [[University of Nottingham]]
| thesis_title = Topics in Modern Algebraic Geometry
| thesis_url = http://www.dpmms.cam.ac.uk/~cb496/finalthesis.pdf
| thesis_year = 2004
| doctoral_advisor = {{unbulleted list|[[Ivan Fesenko]]|[[Vyacheslav Shokurov]]}}
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| influences = 
| influenced = 
| awards = [[Leverhulme Prize]] (2010)&lt;br&gt;Prize of the FSMP (2010)&lt;br&gt; AMS Moore Prize (2016)&lt;br&gt;[[Fields Medal]] (2018)
| signature = &lt;!--(filename only)--&gt;
| signature_alt = 
| website = [https://www.dpmms.cam.ac.uk/~cb496/ Caucher Birkar Website]
| footnotes = 
| spouse = 
| children = 
}}

'''Caucher Birkar''' ({{lang-ku|کۆچەر بیرکار/Koçer Bîrkar|lit=migrant mathematician}}; born '''Faraydoun Derakhshani''' ({{lang-fa|فریدون درخشانی}}); July 1978, in [[Marivan County]], [[Kurdistan Province]], [[Iran]]) is a [[UK]]-based [[Kurds in Iran|Kurdish-Iranian]] mathematician and a professor at the [[University of Cambridge]]. 

Birkar is an important contributor to modern [[birational geometry]].&lt;ref&gt;{{Cite web|url=https://www.mathunion.org/fileadmin/IMU/Prizes/Fields/2018/Birkar-Citation.pdf|title=Birkar Citation|last=|first=|date=|year=2018|website=International Mathematical Union|publisher=International Mathematical Union|page=2|others=Birkar long citation.|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; In 2010 he received the [[Leverhulme Prize]] in mathematics and statistics for his contributions to [[algebraic geometry]],&lt;ref name="auto"&gt;{{cite web |url=http://www.leverhulme.ac.uk/news/awards/plp.cfm |title=Archived copy |accessdate=2012-12-30 |deadurl=yes |archiveurl=https://web.archive.org/web/20130610153414/http://www.leverhulme.ac.uk/news/awards/plp.cfm |archivedate=2013-06-10 |df= }}&lt;/ref&gt; and in 2016, the AMS Moore Prize for the article "Existence of minimal models for varieties of log general type", ''Journal of the AMS'' (2010) (joint with P. Cascini, C. Hacon and J. McKernan).&lt;ref&gt;{{cite web|url=http://www.ams.org/news?news_id=2873|title=American Mathematical Society|author=|date=|website=www.ams.org|accessdate=1 August 2018}}&lt;/ref&gt; He was awarded the [[Fields Medal]] in 2018, "for his proof of boundedness of [[Fano varieties]] and contributions to the minimal model problem".&lt;ref name=":0"&gt;{{Cite news|url=https://www.theguardian.com/science/2018/aug/01/former-refugee-among-winners-of-fields-medal-the-nobel-prize-for-maths|title=Former refugee among winners of Fields medal – the 'Nobel prize for maths'}}&lt;/ref&gt;

==Early life and education==
Birkar is [[Kurdish people|Kurdish]], and was born in 1978 in [[Marivan County]], [[Kurdistan Province]], Iran, on a subsistence farm, and raised during the [[Iran-Iraq War]]&lt;ref&gt;{{Cite news|url=https://www.quantamagazine.org/caucher-birkar-who-fled-war-and-found-asylum-wins-fields-medal-20180801/|title=Quanta Magazine - Illuminating Science {{!}} Quanta Magazine|work=Quanta Magazine|access-date=2018-08-07}}&lt;/ref&gt;. He studied mathematics at the [[University of Tehran]] where he received his bachelor's degree. He was awarded the third prize in the [[International Mathematics Competition for University Students]] in 2000 &lt;ref&gt;{{cite web|url=http://www.ucl.ac.uk/~ucahjej/imc/imc2000/results.html|title=IMC - International Mathematics Competition for University Students|first=C|last=Draganova|date=|website=www.ucl.ac.uk|accessdate=2 August 2018}}&lt;/ref&gt; and, shortly after, while still studying in the University, relocated to the UK as a [[refugee]] and asked for [[political asylum]]&lt;ref name=BBCFields&gt;[https://www.bbc.com/news/science-environment-45032422 Fields medal: UK refugee wins 'biggest maths prize'], by Paul Rincon, at [[BBC.co.uk]]; published August 1, 2018; retrieved August 1, 2018&lt;/ref&gt;. In 2001–2004 Birkar was a PhD student at the [[University of Nottingham]]. In 2003 he was awarded the Cecil King Travel Scholarship by the [[London Mathematical Society]] as the most promising PhD student.&lt;ref&gt;{{cite web|url=https://www.lms.ac.uk/prizes/cecil-king-travel-scholarship|title=Cecil King Travel Scholarship in Mathematics|accessdate=3 August 2018}}&lt;/ref&gt; 

Upon emigrating to the UK he changed his name to Caucher Birkar, which means "migrant mathematician" in [[Kurdish language|Kurdish]].&lt;ref&gt;{{Cite news|url=https://kayhan.london/fa/1397/05/11/%D9%85%D8%AF%D8%A7%D9%84-%D9%81%DB%8C%D9%84%D8%AF%D8%B2-%DA%A9%D9%88%DA%86%D8%B1-%D8%A8%DB%8C%D8%B1%DA%A9%D8%A7%D8%B1-%D8%B1%DB%8C%D8%A7%D8%B6%DB%8C%D8%AF%D8%A7%D9%86-%D8%A8%D9%87-%D8%B3|title=مدال «فیلدز» کوچر بیرکار ریاضیدان به سرقت رفت اما افتخارش برای ایرانیان ماندنی است|last=لندن|first=کیهان|date=2018-08-02|access-date=2018-08-07|language=fa-IR}}&lt;/ref&gt;

==Research==
&lt;!-- Birkar's main area of interest is [[algebraic geometry]], in particular, higher dimensional [[birational geometry]]. He studied fundamental aspects of key problems in modern mathematics such as [[Minimal model program|minimal models]], [[Fano varieties]], [[Singular point of an algebraic variety|singularities]], and [[Linear system of divisors|linear systems]]. His theories provided solutions of various long-standing conjectures.{{fact|date=August 2018}} --&gt;

Together with Paolo Cascini, [[Christopher Hacon]] and [[James McKernan]], Birkar settled several conjectures including existence of log [[Flip (mathematics)|flips]], finite generation of log [[canonical ring]]s, and existence of minimal models for varieties of log general type, building upon earlier work of [[Vyacheslav Shokurov]] and of Hacon and McKernan.&lt;ref&gt;C. Birkar, P. Cascini, C. Hacon, J. McKernan [http://www.ams.org/journals/jams/2010-23-02/S0894-0347-09-00649-3, Existence of minimal models for varieties of log general type], J. Amer. Math. Soc. 23 (2010), 405–468.&lt;/ref&gt; &lt;!-- He also showed that the minimal model conjecture follows from the [[abundance conjecture]] and established links between the former conjecture and various other notions such as log canonical thresholds and [[Oscar Zariski|Zariski]] decompositions.{{fact|date=August 2018}} --&gt;

In the setting of [[log canonical singularity|log canonical singularities]], he proved existence of log flips along with key cases of the minimal model and abundance conjectures.  (This was also proved independently by Hacon and [[Chenyang Xu]].)&lt;ref&gt;C. Birkar, [https://link.springer.com/article/10.1007/s10240-012-0039-5  Existence of log canonical flips and a special LMMP], Pub. Math. IHES 115 (2012), Issue 1, 325–368.&lt;/ref&gt;

In a different direction, he studied the old problem of [[Iitaka]] on effectivity of Iitaka fibrations induced by pluri-canonical systems on varieties of non-negative [[Kodaira dimension]]. The problem consists of two halves: one related to general fibres of the fibration and one related to the base of the fibration. Birkar and Zhang co-solved the second half of the problem, hence essentially reducing Iitaka's problem to the special case of Kodaira dimension zero.&lt;ref&gt;C. Birkar, D.-Q. Zhang, Effectivity of Iitaka fibrations and pluricanonical systems of polarized pairs. To appear in Pub. Math IHES.&lt;/ref&gt;

In more recent work, Birkar studied Fano varieties and singularities of linear systems. He proved several fundamental problems such as Shokurov's conjecture on boundedness of complements and Borisov–Alexeev–Borisov conjecture on boundedness of Fano varieties.&lt;ref&gt;C. Birkar, [https://arxiv.org/abs/1603.05765  Anti-pluricanonical systems on Fano varieties.] arXiv:1603.05765&lt;/ref&gt;&lt;ref&gt;C. Birkar, [https://arxiv.org/abs/1609.05543  Singularities of linear systems and boundedness of Fano varieties.] arXiv:1609.05543.&lt;/ref&gt; &lt;!-- This direction is viewed to have fundamental applications in birational geometry. Birkar answered a question of [[Gang Tian]] on alpha-invariants and answered a question of [[Jean-Pierre Serre]] on Jordan property of [[Cremona group]]s building on the work of [[Yuri Gennadyevich Prokhorov|Yuri Prokhorov]] and [[Constantin Shramov]].{{fact|date=August 2018}} --&gt;In 2018, Birkar was given the [[Fields Medal]] for his [[Fano varieties]] and his other contributions the minimal model problem.&lt;ref name=":0" /&gt; In a video made available by the [[Simons Foundation]], Birkar expressed hope that his Fields Medal will put “just a little smile on the lips” of the world’s estimated 40 million Kurds.&lt;ref&gt;{{Cite journal|last=Castelvecchi|first=Davide|date=1 August 2018|title=Number-theory prodigy among winners of most coveted prize in mathematics|url=https://www.nature.com/articles/d41586-018-05864-w|journal=Nature|volume=560|pages=152-153|via=}}&lt;/ref&gt; Birkar's Fields Medal was stolen on the same day it was awarded to him.&lt;ref&gt;{{cite web|url=https://www.theguardian.com/world/2018/aug/01/fields-medal-award-stolen-brazil-maths-prize|title=World's most prestigious maths medal is stolen alongside his wallet minutes after professor wins it|last=Phillips|first=Dom|date=1 August 2018|website=The Guardian}}&lt;/ref&gt; In a special ceremony at ICM 2018, Birkar was presented with a replacement medal.&lt;ref&gt;{{cite|url=http://www.icm2018.org/wp/2018/08/04/im-more-famous-now-than-i-would-be-jokes-birkar/|title=“I’m more famous now than I would be”, jokes Birkar|website=ICM 2018|date=August 4, 2018}}&lt;/ref&gt;

Birkar is also active in the field of birational geometry over fields of positive characteristic. His work together with work of Hacon-Xu nearly completes the minimal model program for 3-folds over fields of characteristic at least 7.&lt;ref&gt;C. Birkar, [http://smf4.emath.fr/Publications/AnnalesENS/4_49/html/ens_ann-sc_49_169-212.php Existence of flips and minimal models for 3-folds in char p.] Annales scientifiques de l’ENS 49 (2016), 169-212.&lt;/ref&gt;

==Awards==
* 2010 [[Leverhulme Prize]] in mathematics and statistics for "his outstanding contributions to fundamental research in algebraic geometry"&lt;ref name="auto"/&gt;&lt;ref&gt;{{cite web|url=http://burttotaro.wordpress.com/2010/11/22/caucher-birkar-awarded-2010-philip-leverhulme-prize/|title=Caucher Birkar has been awarded 2010 Philip Leverhulme prize|author=|date=22 November 2010|website=wordpress.com|accessdate=1 August 2018}}&lt;/ref&gt;
* 2010 Prize of the [[Fondation Sciences Mathématiques de Paris]]&lt;ref&gt;{{Cite web |url=http://www.sciencesmaths-paris.fr/en/Researchers%20and%20Students-285.htm |title=Archived copy |access-date=2013-06-01 |archive-url=https://web.archive.org/web/20140317002744/http://www.sciencesmaths-paris.fr/en/Researchers%20and%20Students-285.htm# |archive-date=2014-03-17 |dead-url=yes |df= }}&lt;/ref&gt;
* 2016 AMS Moore Prize &lt;ref&gt;{{cite web|url=http://www.ams.org/news?news_id=2873|title=American Mathematical Society|author=|date=|website=www.ams.org|accessdate=2 August 2018}}&lt;/ref&gt;
* 2018 [[Fields Medal]].&lt;ref name=":0" /&gt;

==References==
{{Reflist}}

==Further reading==
*Kevin Hartnett (1 August 2018), "[https://www.quantamagazine.org/caucher-birkar-who-fled-war-and-found-asylum-wins-fields-medal-20180801/ An innovator who brings order to an infinitude of equations]", ''[[Quanta Magazine]]''.

==External links==
*[https://www.dpmms.cam.ac.uk/~cb496/research.html Some of his papers]
*{{MathGenealogy}}
*{{Scopus id}}

{{Fields medalists}}

{{Authority control}}
{{DEFAULTSORT:Birkar, Caucher}}
[[Category:Fields Medalists]]
[[Category:Kurdish mathematicians]]
[[Category:Living people]]
[[Category:People from Kurdistan Province]]
[[Category:Iranian Kurdish people]]
[[Category:Iranian emigrants to the United Kingdom]]
[[Category:British people of Kurdish descent]]
[[Category:Iranian mathematicians]]
[[Category:University of Tehran alumni]]
[[Category:Alumni of the University of Nottingham]]
[[Category:British mathematicians]]
[[Category:Iranian refugees]]
[[Category:Refugees in the United Kingdom]]
[[Category:British people of Iranian descent]]
[[Category:Cambridge mathematicians]]</text>
      <sha1>3xlu8idigkgiejgi28okgllni9dcusf</sha1>
    </revision>
  </page>
  <page>
    <title>Centralizer and normalizer</title>
    <ns>0</ns>
    <id>145661</id>
    <revision>
      <id>868138535</id>
      <parentid>868086862</parentid>
      <timestamp>2018-11-10T06:58:16Z</timestamp>
      <contributor>
        <username>YiFeiBot</username>
        <id>19090830</id>
      </contributor>
      <minor/>
      <comment>Bot: Migrating 1 langlinks, now provided by [[d:|Wikidata]] on [[d:q190629]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9960">{{Redirect|Normalizer|the process of increasing audio amplitude|Audio normalization}}
{{Redirect|Centralizer|centralizers of Banach spaces|Multipliers and centralizers (Banach spaces)}}
In mathematics, especially [[group theory]], the '''centralizer''' (also called '''commutant'''&lt;ref name="O'MearaClark2011"&gt;{{cite book|author1=Kevin O'Meara|author2=John Clark|author3=Charles Vinsonhaler|title=Advanced Topics in Linear Algebra: Weaving Matrix Problems Through the Weyr Form|url=https://books.google.com/books?id=HLiWsnzJe6MC&amp;pg=PA65|year=2011|publisher= [[Oxford University Press]]|isbn=978-0-19-979373-0|page=65}}&lt;/ref&gt;&lt;ref name="HofmannMorris2007"&gt;{{cite book|author1=Karl Heinrich Hofmann|author2=Sidney A. Morris|title=The Lie Theory of Connected Pro-Lie Groups: A Structure Theory for Pro-Lie Algebras, Pro-Lie Groups, and Connected Locally Compact Groups|url=https://books.google.com/books?id=fJyqSkEexNgC&amp;pg=PA30|year=2007|publisher= [[European Mathematical Society]]|isbn=978-3-03719-032-6|page=30}}&lt;/ref&gt;) of a [[subset]] ''S'' of a [[group (mathematics)|group]] ''G'' is the set of elements of ''G'' that [[commutativity|commute]] with each element of ''S'', and the '''normalizer''' of ''S'' are elements that satisfy a weaker condition. The centralizer and normalizer of ''S'' are [[subgroup]]s of ''G'', and can provide insight into the structure of ''G''.

The definitions also apply to [[monoid]]s and [[semigroup]]s.

In [[ring theory]], the '''centralizer of a subset of a [[ring (mathematics)|ring]]''' is defined with respect to the semigroup (multiplication) operation of the ring. The centralizer of a subset of a ring ''R'' is a subring of ''R''. This article also deals with centralizers and normalizers in [[Lie algebra]].

The [[idealizer]] in a semigroup or ring is another construction that is in the same vein as the centralizer and normalizer.

==Definitions==
===Group and semigroup===
The '''centralizer''' of a subset ''S'' of group (or semigroup) ''G'' is defined to be&lt;ref&gt;Jacobson (2009), p. 41&lt;/ref&gt;

:&lt;math&gt;\mathrm{C}_G(S)=\{g\in G\mid gs=sg \text{ for all } s\in S\}&lt;/math&gt;

Sometimes if there is no ambiguity about the group in question, the ''G'' is suppressed from the notation entirely. When ''S''&amp;nbsp;=&amp;nbsp;{''a''} is a singleton set, then C&lt;sub&gt;''G''&lt;/sub&gt;({''a''}) can be abbreviated to C&lt;sub&gt;''G''&lt;/sub&gt;(''a''). Another less common notation for the centralizer is Z(''a''), which parallels the notation for the [[center of a group]].  With this latter notation, one must be careful to avoid confusion between the center of a group ''G'', Z(''G''), and the ''centralizer'' of an ''element'' ''g'' in ''G'', given by Z(''g'').

The '''normalizer''' of ''S'' in the group (or semigroup) ''G'' is defined to be

:&lt;math&gt;\mathrm{N}_G(S)=\{ g \in G \mid gS=Sg \}&lt;/math&gt;

The definitions are similar but not identical. If ''g'' is in the centralizer of ''S'' and ''s'' is in ''S'', then it must be that {{nowrap|1=''gs'' = ''sg''}}, however if ''g'' is in the normalizer, {{nowrap|1=''gs'' = ''tg''}} for some ''t'' in ''S'', potentially different from ''s''. The same conventions mentioned previously about suppressing ''G'' and suppressing braces from singleton sets also apply to the normalizer notation. The normalizer should not be confused with the [[conjugate closure|normal closure]].

===Ring, algebra over a field, Lie ring, and Lie algebra===
If ''R'' is a ring or an [[algebra over a field]], and ''S'' is a subset of ''R'', then the centralizer of ''S'' is exactly as defined for groups, with ''R'' in the place of ''G''.

If &lt;math&gt;\mathfrak{L}&lt;/math&gt; is a [[Lie algebra]] (or [[Lie ring]]) with Lie product [''x'',''y''], then the centralizer of a subset ''S'' of &lt;math&gt;\mathfrak{L}&lt;/math&gt; is defined to be{{sfn|Jacobson|1979|loc=p.28}}

:&lt;math&gt;\mathrm{C}_{\mathfrak{L}}(S)=\{ x \in \mathfrak{L} \mid [x,s]=0 \text{ for all } s\in S \}&lt;/math&gt;
The definition of centralizers for Lie rings is linked to the definition for rings in the following way. If ''R'' is an associative ring, then ''R'' can be given the [[commutator#(ring theory)|bracket product]] {{nowrap|1=[''x'',''y''] = ''xy'' − ''yx''}}. Of course then {{nowrap|1=''xy'' = ''yx''}} if and only if {{nowrap|1=[''x'',''y''] = 0}}. If we denote the set ''R'' with the bracket product as L&lt;sub&gt;''R''&lt;/sub&gt;, then clearly the ''ring centralizer'' of ''S'' in ''R'' is equal to the ''Lie ring centralizer'' of ''S''  in L&lt;sub&gt;''R''&lt;/sub&gt;.

The normalizer of a subset ''S'' of a Lie algebra (or Lie ring) &lt;math&gt;\mathfrak{L}&lt;/math&gt; is given by{{sfn|Jacobson|1979|loc=p.28}}
:&lt;math&gt;\mathrm{N}_{\mathfrak{L}}(S)=\{ x \in \mathfrak{L} \mid [x,s]\in S \text{ for all } s\in S \}&lt;/math&gt;
While this is the standard usage of the term "normalizer" in Lie algebra, this construction is actually the [[idealizer]] of the set ''S'' in &lt;math&gt;\mathfrak{L}&lt;/math&gt;. If ''S'' is an additive subgroup of &lt;math&gt;\mathfrak{L}&lt;/math&gt;, then &lt;math&gt;\mathrm{N}_{\mathfrak{L}}(S)&lt;/math&gt; is the largest Lie subring (or Lie subalgebra, as the case may be) in which ''S'' is a Lie [[ideal (ring theory)|ideal]].{{sfn|Jacobson|1979|loc=p.57}}

==Properties==
===Semigroups===
Let &lt;math&gt;S'&lt;/math&gt; denote the centralizer of &lt;math&gt;S&lt;/math&gt; in the semigroup &lt;math&gt;A&lt;/math&gt;, i.e. &lt;math&gt;S'=\{x\in A: sx=xs\ \mbox{for}\ \mbox{every}\ s\in S\}.&lt;/math&gt; Then:
* &lt;math&gt;S'&lt;/math&gt; forms a [[subsemigroup]].
* &lt;math&gt;S' = S''' = S'''''&lt;/math&gt; —i.e. a commutant is its own [[bicommutant]].

===Groups===
Source:{{sfn|Isaacs|2009|loc=Chapters 1−3}}
* The centralizer and normalizer of ''S'' are both subgroups of ''G''.
* Clearly, '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'')&amp;nbsp;⊆&amp;nbsp;'''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''S''). In fact, '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') is always a [[normal subgroup]] of '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'').
* '''C'''&lt;sub&gt;''G''&lt;/sub&gt;('''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'')) contains ''S'', but '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') need not contain ''S''. Containment will occur if ''st''=''ts'' for every ''s'' and ''t'' in ''S''. Naturally then if ''H'' is an abelian subgroup of ''G'', '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(H) contains ''H''.
* If ''H'' is a subgroup of ''G'', then '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''H'') contains ''H''.
* If ''H'' is a subgroup of ''G'', then the largest subgroup in which ''H'' is normal is the subgroup '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(H).
* A subgroup ''H'' of a group ''G'' is called a '''{{visible anchor|self-normalizing subgroup}}''' of ''G'' if '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''H'') = ''H''.
* The center of ''G'' is exactly  '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(G) and ''G'' is an [[abelian group]] if and only if '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(G)=Z(''G'') = ''G''.
* For singleton sets, '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''a'')='''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''a'').
* By symmetry, if ''S'' and ''T'' are two subsets of ''G'', ''T''&amp;nbsp;⊆&amp;nbsp;'''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') if and only if ''S''&amp;nbsp;⊆&amp;nbsp;'''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''T'').
* For a subgroup ''H'' of group ''G'', the '''N/C theorem''' states that the [[factor group]] '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''H'')/'''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''H'') is [[group isomorphism|isomorphic]] to a subgroup of Aut(''H''), the group of [[automorphism]]s of ''H''. Since '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''G'') = ''G'' and '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''G'') = Z(''G''), the N/C theorem also implies that ''G''/Z(''G'') is isomorphic to Inn(''G''), the subgroup of Aut(''G'') consisting of all [[inner automorphism]]s of ''G''.
* If we define a [[group homomorphism]] ''T'' : ''G'' → Inn(''G'') by ''T''(''x'')(''g'') = ''T''&lt;sub&gt;''x''&lt;/sub&gt;(''g'') = ''xgx''&lt;sup&gt;&amp;nbsp;−1&lt;/sup&gt;, then we can describe '''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') and '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') in terms of the [[group action]] of Inn(''G'') on ''G'': the stabilizer of ''S'' in Inn(''G'') is ''T''('''N'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'')), and the subgroup of Inn(''G'') fixing ''S'' is ''T''('''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'')).
* A subgroup ''H'' of a group ''G'' is said to be '''C-closed''' or '''self-bicommutant''' if ''H'' = '''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''S'') for some subset ''S''&amp;nbsp;⊆&amp;nbsp;''G''. If so, then in fact, ''H'' = '''C'''&lt;sub&gt;''G''&lt;/sub&gt;('''C'''&lt;sub&gt;''G''&lt;/sub&gt;(''H'')).

===Rings and algebras over a field===
Source:{{sfn|Jacobson|1979|loc=p.28}}
* Centralizers in rings and in algebras over a field are subrings and subalgebras over a field, respectively; centralizers in Lie rings and in Lie algebras are Lie subrings and Lie subalgebras, respectively.
* The normalizer of ''S'' in a Lie ring contains the centralizer of ''S''.
* '''C'''&lt;sub&gt;''R''&lt;/sub&gt;('''C'''&lt;sub&gt;''R''&lt;/sub&gt;(''S'')) contains ''S'' but is not necessarily equal. The [[double centralizer theorem]] deals with situations where equality occurs.
* If ''S'' is an additive subgroup of a Lie ring ''A'', then '''N'''&lt;sub&gt;''A''&lt;/sub&gt;(''S'') is the largest Lie subring of ''A'' in which ''S'' is a Lie ideal.
* If ''S'' is a Lie subring of a Lie ring ''A'', then ''S''&amp;nbsp;⊆&amp;nbsp;'''N'''&lt;sub&gt;''A''&lt;/sub&gt;(''S'').

==See also==
* [[Commutator]]
* [[Double centralizer theorem]]
* [[Idealizer]]
* [[Multipliers and centralizers (Banach spaces)]]
* [[Stabilizer subgroup]]

==Notes==
&lt;references/&gt;

==References==
*{{citation |last=Isaacs |first=I. Martin |title=Algebra: a graduate course |series=[[Graduate Studies in Mathematics]] |volume=100 |edition=reprint of the 1994 original |publisher= [[American Mathematical Society]] |place=Providence, RI |year=2009 |isbn=978-0-8218-4799-2 |mr=2472787 |doi=10.1090/gsm/100}}
*{{Citation |last=Jacobson |first=Nathan |author-link=Nathan Jacobson |year=2009 |title=Basic Algebra |edition=2 |volume=1 |series= |publisher= [[Dover Publications]] |isbn=978-0-486-47189-1}}
*{{citation|last=Jacobson |first=Nathan |title=Lie Algebras |edition=republication of the 1962 original |publisher= [[Dover Publications]] |year=1979  |isbn=0-486-63832-4  |mr=559927}}

{{DEFAULTSORT:Centralizer And Normalizer}}
[[Category:Abstract algebra]]
[[Category:Group theory]]
[[Category:Ring theory]]
[[Category:Lie algebras]]</text>
      <sha1>etv8cisdhrcbbe4o1692ikz71dqonpw</sha1>
    </revision>
  </page>
  <page>
    <title>Circumscribed sphere</title>
    <ns>0</ns>
    <id>991784</id>
    <revision>
      <id>744286989</id>
      <parentid>721388370</parentid>
      <timestamp>2016-10-14T08:51:19Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3823">[[File:Вписанный куб.gif|right|thumb|Circumscribed sphere of a [[cube]]]]
In [[geometry]], a '''circumscribed sphere''' of a [[polyhedron]] is a [[sphere]] that contains the polyhedron and touches each of the polyhedron's vertices.&lt;ref&gt;{{citation|title=The Mathematics Dictionary|first=R. C.|last=James|publisher=Springer|year=1992|isbn=9780412990410|page=62|url=https://books.google.com/books?id=UyIfgBIwLMQC&amp;pg=PA62}}.&lt;/ref&gt;  The word '''circumsphere''' is sometimes used to mean the same thing.&lt;ref&gt;{{citation|title=Divided Spheres: Geodesics and the Orderly Subdivision of the Sphere|first=Edward S.|last=Popko|publisher=CRC Press|year=2012|isbn=9781466504295|page=144|url=https://books.google.com/books?id=WLAFlr1_2S4C&amp;pg=PA144}}.&lt;/ref&gt; As in the case of two-dimensional [[circumscribed circle]]s, the radius of a sphere circumscribed around a polyhedron ''P'' is called the [[circumradius]] of ''P'',&lt;ref&gt;{{citation|title=Methods of Geometry|first=James T.|last=Smith|publisher=John Wiley &amp; Sons|year=2011|isbn=9781118031032|page=419|url=https://books.google.com/books?id=B0khWEZmOlwC&amp;pg=PA419}}.&lt;/ref&gt; and the center point of this sphere is called the [[circumcenter]] of&amp;nbsp;''P''.&lt;ref&gt;{{citation|title=Modern pure solid geometry|first=Nathan|last=Altshiller-Court|edition=2nd|publisher=Chelsea Pub. Co.|year=1964|page=57}}.&lt;/ref&gt;

==Existence and optimality==
When it exists, a circumscribed sphere need not be the [[Smallest-circle problem|smallest sphere containing the polyhedron]]; for instance, the tetrahedron formed by a vertex of a [[cube]] and its three neighbors has the same circumsphere as the cube itself, but can be contained within a smaller sphere having the three neighboring vertices on its equator. However, the smallest sphere containing a given polyhedron is always the circumsphere of the [[convex hull]] of a subset of the vertices of the polyhedron.&lt;ref name="fgk"&gt;{{citation
 | last1 = Fischer | first1 = Kaspar
 | last2 = Gärtner | first2 = Bernd
 | last3 = Kutz | first3 = Martin
 | contribution = Fast smallest-enclosing-ball computation in high dimensions
 | doi = 10.1007/978-3-540-39658-1_57
 | pages = 630–641
 | publisher = Springer
 | series = [[Lecture Notes in Computer Science]]
 | title = Algorithms - ESA 2003: 11th Annual European Symposium, Budapest, Hungary, September 16-19, 2003, Proceedings
 | volume = 2832
 | year = 2003}}.&lt;/ref&gt;

==Related concepts==
The circumscribed sphere is the three-dimensional analogue of the [[circumscribed circle]].
All [[regular polyhedra]] have circumscribed spheres, but most irregular polyhedra do not have one, since in general not all vertices lie on a common sphere. The circumscribed sphere (when it exists) is an example of a [[bounding sphere]], a sphere that contains a given shape. It is possible to define the smallest bounding sphere for any polyhedron, and compute it in [[linear time]].&lt;ref name="fgk"/&gt;

Other spheres defined for some but not all polyhedra include a [[midsphere]], a sphere tangent to all edges of a polyhedron, and an [[inscribed sphere]], a sphere tangent to all faces of a polyhedron. In the [[regular polyhedra]], the inscribed sphere, midsphere, and circumscribed sphere all exist and are [[Concentric spheres|concentric]].&lt;ref&gt;{{citation|last=Coxeter|first=H. S. M.|authorlink=Harold Scott MacDonald Coxeter|title=[[Regular Polytopes (book)|Regular Polytopes]]|edition=3rd|year=1973|publisher=Dover|isbn=0-486-61480-8|pages=16–17|contribution=2.1 Regular polyhedra; 2.2 Reciprocation|contribution-url=https://books.google.com/books?id=iWvXsVInpgMC&amp;lpg=PP1&amp;pg=PA16}}.&lt;/ref&gt;

==References==
{{reflist|30em}}

==External links==
{{commonscat|Circumscribed spheres}}
* {{mathworld | urlname = Circumsphere | title = Circumsphere}}

[[Category:Elementary geometry]]
[[Category:Spheres]]</text>
      <sha1>gpld67f4k2q08fk2fk3ppyt30rnsudu</sha1>
    </revision>
  </page>
  <page>
    <title>Cofinal (mathematics)</title>
    <ns>0</ns>
    <id>1633290</id>
    <revision>
      <id>837861215</id>
      <parentid>791131076</parentid>
      <timestamp>2018-04-23T13:46:44Z</timestamp>
      <contributor>
        <ip>151.100.50.6</ip>
      </contributor>
      <comment>/* Related Notions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4111">In [[mathematics]], let ''A'' be a set and let ≤ be a [[binary relation]] on ''A''.  Then a [[subset]] ''B'' of ''A'' is said to be '''cofinal''' if it satisfies the following condition:
:For every ''a''&amp;nbsp;&amp;isin;&amp;nbsp;''A'', there exists some ''b''&amp;nbsp;&amp;isin;&amp;nbsp;''B'' such that ''a''&amp;nbsp;&amp;le;&amp;nbsp;''b''.
This definition is most commonly applied when ''A'' is a [[partially ordered set]] or [[directed set]] under the relation ≤.

Cofinal subsets are very important in the theory of directed sets and [[net (mathematics)|nets]], where “[[subnet (mathematics)|cofinal subnet]]” is the appropriate generalization of “[[subsequence]]”.  They are also important in [[order theory]], including the theory of [[cardinal numbers]], where the minimum possible [[cardinality]] of a cofinal subset of ''A'' is referred to as the [[cofinality]] of ''A''.

A subset ''B'' of ''A'' is said to be '''coinitial''' (or '''dense''' in the sense of [[Forcing (mathematics)|forcing]]) if it satisfies the following condition:
:For every ''a''&amp;nbsp;&amp;isin;&amp;nbsp;''A'', there exists some ''b''&amp;nbsp;&amp;isin;&amp;nbsp;''B'' such that ''b''&amp;nbsp;&amp;le;&amp;nbsp;''a''.
This is the [[Duality (order theory)|order-theoretic dual]] to the notion of cofinal subset.

Note that cofinal and coinitial subsets are both dense in the sense of appropriate (right- or left-) [[order topology]].

== Properties ==

The cofinal relation over partially ordered sets ("[[Partially ordered set|poset]]") is [[reflexive relation|reflexive]]: every poset is cofinal in itself. It is also [[transitive relation|transitive]]: if ''B'' is a cofinal subset of a poset ''A'', and ''C'' is a cofinal subset of ''B'' (with the partial ordering of ''A'' applied to ''B''), then ''C'' is also a cofinal subset of ''A''.

For a partially ordered set with [[maximal element]]s, every cofinal subset must contain all [[maximal element]]s, otherwise a maximal element which is not in the subset would fail to be ''less than'' any element of the subset, violating the definition of cofinal. For a partially ordered set with a [[greatest element]], a subset is cofinal if and only if it contains that greatest element (this follows, since a greatest element is necessarily a maximal element). Partially ordered sets without greatest element or maximal elements admit disjoint cofinal subsets. For example, the even and odd [[natural number]]s form disjoint cofinal subsets of the set of all natural numbers.

If a partially ordered set ''A'' admits a [[totally ordered]] cofinal subset, then we can find a subset ''B'' which is [[well-ordered]] and cofinal in ''A''.

== Cofinal set of subsets ==

A particular but important case is given if ''A'' is a subset of the [[power set]] ''P''(''E'') of some set ''E'', ordered by reverse inclusion (⊃). Given this ordering of ''A'', a subset ''B'' of ''A'' is cofinal in ''A'' if for every ''a''&amp;nbsp;∈&amp;nbsp;''A'' there is a ''b''&amp;nbsp;∈&amp;nbsp;''B'' such that ''a''&amp;nbsp;⊃&amp;nbsp;''b''.

For example, let ''E'' be a group and let ''A'' be the set of [[normal subgroup]]s of finite [[index of a subgroup|index]]. The [[profinite group|profinite completion]] of ''E'' is defined to be the [[inverse limit]] of the [[inverse system]] of finite quotients of ''E'' (which are parametrized by the set ''A''). 
In this situation, every cofinal subset of ''A'' is sufficient to construct and describe the profinite completion of ''E''.

== Related Notions ==

A [[function (mathematics)|map]] f:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;''A'' between two directed sets is said to be '''final''' &lt;ref name=bredon93&gt;{{cite book|last=Bredon|first=Glen|author-link=Glen Bredon|title=Topology and Geometry|year=1993|publisher=Springer|page=16}}&lt;/ref&gt; if the [[range (mathematics)|range]] f(''X'') of f is a cofinal subset of ''A''.

== See also ==
* [[cofinite]]
* [[cofinality]]
* [[Upper set]] – a subset ''U'' of a partially ordered set (''P'',≤) that contains every element ''y'' of ''P'' for which there is an ''x'' in ''U'' with ''x'' ≤ ''y''

==References==

{{reflist}}

* {{Lang Algebra|edition=3}}

[[Category:Order theory]]</text>
      <sha1>gp2ncvv5vovhtsj2toczni7lkuxp50d</sha1>
    </revision>
  </page>
  <page>
    <title>Construct validity</title>
    <ns>0</ns>
    <id>794342</id>
    <revision>
      <id>870416216</id>
      <parentid>868021940</parentid>
      <timestamp>2018-11-24T17:31:58Z</timestamp>
      <contributor>
        <ip>2601:248:C101:9496:BD1C:E55A:F2B7:7637</ip>
      </contributor>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23137">'''Construct validity''' is "the degree to which a test measures what it claims, or purports, to be measuring."&lt;ref&gt;{{cite book |last=Brown |first=J. D. |year=1996 |title=Testing in language programs |publisher=Upper Saddle River, NJ: Prentice Hall Regents |url=http://jalt.org/test/bro_8.htm}}&lt;/ref&gt;&lt;ref name="Cronbach55"&gt;{{cite journal|last=Cronbach |first=L. J. |last2= Meehl |first2=P.E. |year=1955 |title=Construct Validity in Psychological Tests |journal=Psychological Bulletin |volume=52 |pages=281–302. |url=http://psychclassics.yorku.ca/Cronbach/construct.htm |doi=10.1037/h0040957 |pmid=13245896 |issue=4}}&lt;/ref&gt;&lt;ref name="Polit"&gt;Polit DF Beck CT (2012). Nursing Research: Generating and Assessing Evidence for Nursing Practice, 9th ed. Philadelphia, USA: Wolters Klower Health, Lippincott Williams &amp; Wilkins&lt;/ref&gt; In the classical model of [[test validity]], construct validity is one of three main types of validity evidence, alongside [[content validity]] and [[criterion validity]].&lt;ref name="guion1980"&gt;{{cite journal |last=Guion |first=R. M. |year=1980 |title=On trinitarian doctrines of validity |journal=[[Professional Psychology]] |volume= 11 |pages=385–398 |doi=10.1037/0735-7028.11.3.385}}&lt;/ref&gt;&lt;ref name="Brown86"&gt;{{cite book|last= Brown |first=J. D. |year=1996 |title=Testing in language programs |publisher=Upper Saddle River, NJ: Prentice Hall Regents}}&lt;/ref&gt; Modern validity theory defines construct validity as the overarching concern of validity research, subsuming all other types of validity evidence.&lt;ref name="messick1995"&gt;{{cite journal |last=Messick |first=S. |year=1995 |title=Validity of psychological assessment: Validation of inferences from persons’ responses and performances as scientific inquiry into score meaning |journal=American Psychologist |volume=50 |pages=741–749 |doi=10.1037/0003-066x.50.9.741}}&lt;/ref&gt;&lt;ref name="Schotte97"&gt;{{cite journal |last=Schotte |first=C. K. W. |last2=Maes |first2=M. |last3=Cluydts |first3=R. |last4=De Doncker |first4=D. |last5=Cosyns |first5=P. |year=1997 |title= Construct validity of the Beck Depression Inventory in a depressive population |journal=Journal of Affective Disorders |volume=46 |issue=2 |pages=115–125. |doi=10.1016/s0165-0327(97)00094-3}}&lt;/ref&gt;

Construct validity is the appropriateness of inferences made on the basis of observations or measurements (often test scores), specifically whether a test measures the intended [[Construct (Philosophy of Science)|construct]]. Constructs are abstractions that are deliberately created by researchers in order to conceptualize the [[latent variable]], which is correlated with scores on a given measure (although it is not directly observable). Construct validity examines the question: Does the measure behave like the theory says a measure of that construct should behave?

Construct validity is essential to the perceived overall validity of the test. Construct validity is particularly important in the [[social sciences]], [[psychology]], [[psychometrics]] and language studies.

Psychologists such as [[Samuel Messick]] (1998) have pushed for a unified view of construct validity "...as an integrated evaluative judgment of the degree to which empirical evidence and theoretical rationales support the adequacy and appropriateness of inferences and actions based on test scores..."&lt;ref name="Messick"&gt;{{cite journal |last=Messick |first=Samuel |year=1998 |title=Test validity: A matter of consequence |journal= Social Indicators Research |volume= 45 |issue=1-3 |pages= 35–44|doi=
10.1023/a:1006964925094 }}&lt;/ref&gt; Key to construct validity are the theoretical ideas behind the trait under consideration, i.e. the concepts that organize how aspects of [[personality]], [[intelligence]], etc. are viewed.&lt;ref name="Pennington"&gt;{{cite book |last=Pennington |first=Donald |year=2003 |title=Essential Personality. |publisher=Arnold. |ISBN= 0-340-76118-0}}&lt;/ref&gt; [[Paul Meehl]] states that, "The best construct is the one around which we can build the greatest number of inferences, in the most direct fashion."&lt;ref name="Cronbach55" /&gt;

Scale purification, i.e. "the process of eliminating items from multi-item scales" (Wieland et al., 2017) can influence construct validity. A framework presented by Wieland et al. (2017) highlights that both statistical and judgmental criteria need to be taken under consideration when making scale purification decision.&lt;ref&gt;Wieland, A., Durach, C.F., Kembro, J. &amp; Treiblmaier, H. (2017), Statistical and judgmental criteria for scale purification, Supply Chain Management: An International Journal, Vol. 22, No. 4, https://doi.org/10.1108/SCM-07-2016-0230&lt;/ref&gt;

== History ==
Throughout the 1940s scientists had been trying to come up with ways to validate experiments prior to publishing them. The result of this was a myriad of different validities ([[intrinsic validity]], [[face validity]], [[logical validity]], [[empirical validity]], etc.). This made it difficult to tell which ones were actually the same and which ones were not useful at all. Until the middle of the 1950s there were very few universally accepted methods to validate psychological experiments. The main reason for this was because no one had figured out exactly which qualities of the experiments should be looked at before publishing. Between 1950 and 1954 the APA Committee on Psychological Tests met and discussed the issues surrounding the validation of psychological experiments.&lt;ref name="Cronbach55"/&gt;

Around this time the term construct validity was first coined by [[Paul Meehl]] and [[Lee Cronbach]] in their seminal article "  [[Construct Validity In Psychological Tests]]". They noted the idea that construct validity was not new at that point. Rather, it was a combinations of many different types of validity dealing with theoretical concepts. They proposed the following three steps to evaluate construct validity:
# articulating a set of theoretical concepts and their interrelations
# developing ways to measure the hypothetical constructs proposed by the theory
# empirically testing the hypothesized relations&lt;ref name="Cronbach55"/&gt;

Many psychologists note that an important role of construct validation in [[psychometrics]] was that it place more emphasis on theory as opposed to validation. The core issue with validation was that a test could be validated, but that did not necessarily show that it measured the theoretical construct it purported to measure. Construct validity has three aspects or components: the substantive component, structural component, and external component.&lt;ref name= "Loevinger"&gt;{{cite journal | author = Loevinger J | year = 1957 | title = Objective Tests As Instruments Of Psychological Theory: Monograph Supplement 9 | url = | journal = Psychological Reports | volume = 3 | issue = 3| pages = 635–694 | doi=10.2466/pr0.1957.3.3.635}}&lt;/ref&gt; They are related close to three stages in the test construction process: constitution of the pool of items, analysis and selection of the internal structure of the pool of items, and correlation of test scores with criteria and other variables.

In the 1970s there was growing debate between theorist who began to see construct validity as the dominant model pushing towards a more unified theory of validity and those who continued to work from multiple validity frameworks.&lt;ref name="Kane06"&gt;{{cite journal |last=Kane |first=M. T. |year=2006 |title= Validation. |journal=Educational measurement |volume=4 |pages=17–64.}}&lt;/ref&gt;  Many psychologists and education researchers saw "predictive, concurrent, and content validities as essentially ''ad hoc'', construct validity was the whole of validity from a scientific point of view"&lt;ref name="Loevinger"/&gt; In the 1974 version of ''The [[Standards for Educational and Psychological Testing]]'' the inter-relatedness of the three different aspects of validity was recognized: "These aspects of validity can be discussed independently, but only for convenience. They are interrelated operationally and logically; only rarely is one of them alone important in a particular situation".

In 1989 Messick presented a new conceptualization of construct validity as a unified and multi-faceted concept.&lt;ref name="Messick89"&gt;{{cite book |last=Messick, |first=S. |year=1989 | chapter=Validity. |editor=R. L. Linn (Ed.), |title=Educational Measurement (3rd ed., pp. 13-103). |publisher=New York: American Council on Education/Macmillan}}&lt;/ref&gt; Under this framework, all forms of validity are connected to and are dependent on the quality of the construct. He noted that a unified theory was not his own idea, but rather the culmination of debate and discussion within the scientific community over the preceding decades. There are six aspects of construct validity in Messick's unified theory of construct validity.&lt;ref name="Messick95"&gt;{{cite journal |last=Messick, |first=S. |year=1995 |title=Standards of validity and the validity of standards in performance assessment. |journal=Educational Measurement: Issues and Practice |volume=14 |issue=4, |pages=5–8. |doi=10.1111/j.1745-3992.1995.tb00881.x}}&lt;/ref&gt; They examine six items that measure the quality of a test's construct validity:

#'''Consequential''' – What are the potential risks if the scores are, in actuality, invalid or inappropriately interpreted? Is the test still worthwhile given the risks?
#'''Content''' – Do test items appear to be measuring the construct of interest?
#'''Substantive''' – Is the theoretical foundation underlying the construct of interest sound?
#'''Structural''' – Do the interrelationships of dimensions measured by the test correlate with the construct of interest and test scores?
#'''External''' – Does the test have convergent, discriminant, and predictive qualities?
#'''Generalizability''' – Does the test generalize across different groups, settings and tasks?

How construct validity should be properly viewed is still a subject of debate for validity theorists. The core of the difference lies in an [[epistemology|epistemological]] difference between [[positivist]] and [[postpositivist]] theorists.

== Evaluation ==
Evaluation of construct validity requires that the correlations of the measure be examined in regard to variables that are known to be related to the construct (purportedly measured by the instrument being evaluated or for which there are theoretical grounds for expecting it to be related). This is consistent with the [[multitrait-multimethod matrix]] (MTMM) of examining construct validity described in Campbell and Fiske's landmark paper (1959).&lt;ref name="Campbell"/&gt; There are other methods to evaluate construct validity besides MTMM. It can be evaluated through different forms of [[factor analysis]], [[structural equation modeling]] (SEM), and other statistical evaluations.&lt;ref name="Hammond96"&gt;Hammond, K. R., Hamm, R. M., &amp; Grassia, J. (1986). Generalizing over conditions by combining the multitrait multimethod matrix and the representative design of experiments (No. CRJP-255A). Colorado University At Boulder Center For Research On Judgment And Policy.&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Westen Drew |author2=Rosenthal Robert | year = 2003 | title = Quantifying construct validity: Two simple measures | url = | journal = Journal of Personality and Social Psychology | volume = 84 | issue = 3| pages = 608–618 | doi=10.1037/0022-3514.84.3.608}}&lt;/ref&gt; It is important to note that a single study does not prove construct validity. Rather it is a continuous process of evaluation, reevaluation, refinement, and development. Correlations that fit the expected pattern contribute evidence of construct validity. Construct validity is a judgment based on the accumulation of correlations from numerous studies using the instrument being evaluated.&lt;ref&gt;Peter, J. P. (1981). Construct validity: a review of basic issues and marketing practices. Journal of Marketing Research, 133-145.&lt;/ref&gt;

Most researchers attempt to test the construct validity before the main research. To do this [[pilot studies]] may be utilized. Pilot studies are small scale preliminary studies aimed at testing the feasibility of a full-scale test. These pilot studies establish the strength of their research and allow them to make any necessary adjustments. Another method is the known-groups technique, which involves administering the measurement instrument to groups expected to differ due to known characteristics. Hypothesized relationship testing involves logical analysis based on theory or prior research.&lt;ref name="Polit"/&gt; [[Intervention studies]] are yet another method of evaluating construct validity. Intervention studies where a group with low scores in the construct is tested, taught the construct, and then re-measured can demonstrate a test's construct validity. If there is a significant difference pre-test and post-test, which are analyzed by statistical tests, then this may demonstrate good construct validity.&lt;ref&gt;{{cite journal |author1=Dimitrov D. M. |author2=Rumrill Jr P. D. | year = 2003 | title = Pretest-posttest designs and measurement of change | url = | journal = Work: A Journal of Prevention, Assessment and Rehabilitation | volume = 20 | issue = 2| pages = 159–165 }}&lt;/ref&gt;

===Convergent and discriminant validity===
{{Main| convergent validity| discriminant validity }}
Convergent and discriminant validity are the two subtypes of validity that make up construct validity. Convergent validity refers to the degree to which two measures of constructs that theoretically should be related, are in fact related. In contrast discriminant validity tests whether concepts or measurements that are supposed to be unrelated are, in fact, unrelated.&lt;ref name="Campbell"&gt;{{cite journal | author = Campbell D. T. | year = 1959 | title = Convergent and discriminant validation by the multitrait-multimethod matrix | url = | journal = Psychological Bulletin | volume = 56 | issue = | pages = 81–105 | doi=10.1037/h0046016}}&lt;/ref&gt; Take, for example, a construct of general happiness. If a measure of general happiness had convergent validity, then constructs similar to happiness (satisfaction, contentment, cheerfulness, etc.) should relate closely to the measure of general happiness. If this measure has discriminate validity, then constructs that are not supposed to be related to general happiness (sadness, depression, despair, etc.) should not relate to the measure of general happiness. Measures can have one of the subtypes of construct validity and not the other. Using the example of general happiness, a researcher could create an inventory where there is a very high positive correlation between general happiness and contentment, but if there is also a significant positive correlation between happiness and depression, then the measure's construct validity is called into question. The test has convergent validity but not discriminant validity.

=== Nomological network ===
{{Main|nomological network}}
Lee Cronbach and Paul Meehl (1955)&lt;ref name="Cronbach55"/&gt; proposed that the development of a nomological net was essential to measurement of a test's construct validity. A [[nomological network]] defines a construct by illustrating its relation to other constructs and behaviors. It is a representation of the concepts (constructs) of interest in a study, their observable manifestations and the interrelationship among them. It examines whether the relationships between similar construct are considered with relationships between the observed measures of the constructs. Thorough observation of constructs relationships to each other it can generate new constructs. For example, [[intelligence]] and [[working memory]] are considered highly related constructs. Through the observation of their underlying components psychologists developed new theoretical constructs such as: controlled attention&lt;ref&gt;Engle, R. W., Kane, M. J., &amp; Tuholski, S. W. (1999). Individual differences in working memory capacity and what they tell us about controlled attention, general fluid intelligence, and functions of the prefrontal cortex. In A. Miyake, &amp; P. Shah (Eds.),Models of working memory (pp. 102−134). Cambridge: Cambridge University Press.&lt;/ref&gt; and short term loading.&lt;ref&gt;{{cite journal |author1=Ackerman P. L. |author2=Beier M. E. |author3=Boyle M. O. | year = 2002 | title = Individual differences in working memory within a nomological network of cognitive and perceptual speed abilities | url = | journal = Journal of Experimental Psychology: General | volume = 131 | issue = | pages = 567–589 | doi=10.1037/0096-3445.131.4.567}}&lt;/ref&gt; Creating a nomological net can also make the observation and measurement of existing constructs more efficient by pinpointing errors.&lt;ref name="Cronbach55"/&gt; Researchers have found that studying the bumps on the human skull ([[phrenology]]) are not indicators of intelligence, but volume of the brain is. Removing the theory of phrenology from the nomological net of intelligence and adding the theory of brain mass evolution, constructs of intelligence are made more efficient and more powerful. The weaving of all of these interrelated concepts and their observable traits creates a "net" that supports their theoretical concept. For example, in the nomological network for academic achievement, we would expect observable traits of academic achievement (i.e. GPA, SAT, and ACT scores) to relate to the observable traits for studiousness (hours spent studying, attentiveness in class, detail of notes). If they do not then there is a problem with measurement (of [[academic achievement]] or studiousness), or with the purported theory of achievement. If they are indicators of one another then the nomological network, and therefore the constructed theory, of academic achievement is strengthened. Although the nomological network proposed a theory of how to strengthen constructs, it doesn't tell us how we can assess the construct validity in a study.

=== Multitrait-multimethod matrix ===
{{Main|Multitrait-multimethod matrix}}
The [[multitrait-multimethod matrix]] (MTMM) is an approach to examining construct validity developed by Campbell and Fiske (1959).&lt;ref name="Campbell"/&gt; This model examines convergence (evidence that different measurement methods of a construct give similar results) and discriminability (ability to differentiate the construct from other related constructs). It measures six traits: the evaluation of convergent validity, the evaluation of discriminant (divergent) validity, trait-method units, multitrait-multimethods, truly different methodologies, and trait characteristics. This design allows investigators to test for: "convergence across different measures...of the same ‘thing’...and for divergence between measures...of related but conceptually distinct 'things'.&lt;ref&gt;{{cite book |author1=Cook T. D. |author2=Campbell D. T. | year = 1979 | title = Quasi-experimentation. |location=Boston|publisher= Houghton Mifflin. }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | author = Edgington, E. S. |date=1974 | title =  A new tabulation of statistical procedures used in APA journals | url = | journal = American Psychologist | volume = 29 | issue = | page = 61 | doi = 10.1037/h0035846 }}&lt;/ref&gt;

==Threats to construct validity==
Apparent construct validity can be misleading due to a range of problems in hypothesis  formulation and experimental design.
* &lt;u&gt;Hypothesis guessing&lt;/u&gt;: If the participant knows, or guesses, the desired end-result, the participant's actions may change.&lt;ref&gt;McCroskey, J. C., Richmond, V. P., &amp; McCroskey, L. L. (2006). An introduction to communication in the classroom: The role of communication in teaching and training. Boston: Allyn &amp; Bacon&lt;/ref&gt; An example is the [[Hawthorne effect]]: in a 1925 industrial ergonomics study conducted at the Hawthorne Works factory outside Chicago, experimenters observed that both lowering &lt;u&gt;and&lt;/u&gt; brightening the ambient light levels improved worker productivity. They eventually determined the basis for this paradoxical result: workers who were aware of being observed worked harder no matter what the change in the environment.
*&lt;u&gt;Bias in experimental design&lt;/u&gt; (intentional or unintentional). An example of this is provided in [[Stephen Jay Gould]]'s 1981 book, "[[The Mismeasure of Man]]".&lt;ref&gt;Gould, S. J. (1996). The Mismeasure of Man. 2nd edition. New York: W. W. Norton &amp; Company.&lt;/ref&gt; Among the questions used around the time of World War I in the battery used to measure intelligence was, "In which city do the Dodgers play?" (they were then based in Brooklyn). Recent immigrants to the USA from Eastern Europe unfamiliar with the sport of baseball got the answer wrong, and this was used to infer that Eastern Europeans had lower intelligence. The question did not measure intelligence: it only measured how long one had lived in the USA and become accultured to a popular pastime.
*&lt;u&gt;Researcher expectations &lt;/u&gt; may be communicated unintentionally to the participants non-verbally, eliciting the desired effect. To control for this possibility, [[double-blind]] experimental designs should be used where possible. That is, the evaluator of a particular participant should be unaware of what intervention has been performed on that particular participant, or should be independent of the experimenter.
* &lt;u&gt;Defining predicted outcome too narrowly&lt;/u&gt;.&lt;ref&gt;{{cite journal | author = MacKenzie S. B. | year = 2003 | title = The dangers of poor construct conceptualization | url = | journal = Journal of the Academy of Marketing Science | volume = 31 | issue = 3| pages = 323–326 | doi=10.1177/0092070303031003011}}&lt;/ref&gt; For instance, using only [[job satisfaction]] to measure happiness will exclude relevant information from outside the workplace. 
* &lt;u&gt;[[Confounding|Confounding variables]]&lt;/u&gt; (covariates): The root cause for the observed effects may be due to variables that have not been considered or measured.&lt;ref&gt;{{cite journal |author1=White D. |author2=Hultquist R. A. | year = 1965 | title = Construction of confounding plans for mixed factorial designs | url = | journal = The Annals of Mathematical Statistics | volume = 36| issue = | pages = 1256–1271 | doi=10.1214/aoms/1177699997}}&lt;/ref&gt;

An in-depth exploration of the threats to construct validity is presented in Trochim.&lt;ref name="Trochim, William M."&gt;[http://www.socialresearchmethods.net/kb/consthre.php Threats to Construct Validity], Trochim, William M. The Research Methods Knowledge Base, 2nd Edition.&lt;/ref&gt;

== See also ==
*[[Statistical conclusion validity]]
*[[Internal validity]]
*[[Ecological validity]]
*[[Content validity]]
*[[External validity]]
*[[Reliability (psychometrics)]]
*[[Face validity]]
*[[Logical validity]]
*[[Lee J. Cronbach]]
*[[Paul E. Meehl]]

== References ==
{{Reflist}}

== External links ==
* [http://art.unt.edu/designresearchcenter/sites/default/files/articles/research_v2_ryan_gupta_hermosillo.pdf/ Useful reference guide for research terms]
* [http://www.socialresearchmethods.net/kb/nomonet.php/ Provides a visual representation of the nomological network]

[[Category:Validity (statistics)]]</text>
      <sha1>nk3tiuopi3h4bigu2b0jcosvknbchbe</sha1>
    </revision>
  </page>
  <page>
    <title>Curve</title>
    <ns>0</ns>
    <id>89246</id>
    <revision>
      <id>869120055</id>
      <parentid>869111641</parentid>
      <timestamp>2018-11-16T15:11:33Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Pssolanki111|Pssolanki111]] ([[User talk:Pssolanki111|talk]]): Awful duplication of the second paragraph of the section. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21164">{{other uses}}
[[File:Parabola.svg|right|thumb|A [[parabola]], a simple example of a curve]]

In [[mathematics]], a '''curve''' (also called a '''curved line''' in older texts) is, generally speaking, an object similar to a [[line (geometry)|line]] but that need not be [[Linearity|straight]]. Thus, a curve is a generalization of a line, in that its [[curvature]] need not be zero.{{efn|In current mathematical usage, a line is straight. Previously{{when?|date=December 2017}} lines could be either curved or straight.{{cn|date=December 2017}}}}

Various disciplines within mathematics have given the term different meanings depending on the area of study, so the precise meaning depends on context. However, many of these meanings are special instances of the definition which follows. A curve is a [[topological space]] which is locally [[homeomorphic]] to a line. In everyday language, this means that a curve is a set of points which, near each of its points, looks like a line, up to a deformation.  A simple example of a curve is the [[parabola]], shown to the right. A [[list of curves|large number of other curves]] have been studied in multiple mathematical fields.

A '''closed curve''' is a curve that forms a [[path (topology)|path]] whose starting point is also its ending point—that is, a path from any of its points to the same point.

Closely related meanings include the [[graph of a function]] (for example, [[Phillips curve]]) and a [[two-dimensional graph]].

==History==
[[File:Newgrange Entrance Stone.jpg|thumb|225px|[[Megalithic art]] from Newgrange showing an early interest in curves]]
Interest in curves began long before they were the subject of mathematical study.  This can be seen in numerous examples of their decorative use in art and on everyday objects dating back to prehistoric
times.&lt;ref name="Lockwood"&gt;Lockwood p. ix&lt;/ref&gt; Curves, or at least their graphical representations, are simple to create, for example by a stick in the sand on a beach.

Historically, the term "line" was used in place of the more modern term "curve". Hence the phrases "straight line" and "right line" were used to distinguish what are today called lines from "curved lines". For example, in Book I of [[Euclid's Elements]], a line is defined as a "breadthless length" (Def. 2), while a ''straight'' line is defined as "a line that lies evenly with the points on itself" (Def. 4). Euclid's idea of a line is perhaps clarified by the statement "The extremities of a line are points," (Def. 3).&lt;ref&gt;Heath p. 153&lt;/ref&gt; Later commentators further classified lines according to various schemes. For example:&lt;ref&gt;Heath p. 160&lt;/ref&gt;
*Composite lines (lines forming an angle)
*Incomposite lines
**Determinate (lines that do not extend indefinitely, such as the circle)
**Indeterminate (lines that extend indefinitely, such as the straight line and the parabola)

[[File:Conic sections with plane.svg|thumb|225px|The curves created by slicing a cone ([[conic section]]s) were among the curves studied in ancient Greece.]]
The Greek [[geometers]] had studied many other kinds of curves. One reason was their interest in solving geometrical problems that could not be solved using standard [[compass and straightedge]] construction.
These curves include:
*The [[conic section]]s, deeply studied by [[Apollonius of Perga]]
*The [[cissoid of Diocles]], studied by [[Diocles (mathematician)|Diocles]] and used as a method to [[doubling the cube|double the cube]].&lt;ref&gt;Lockwood p. 132&lt;/ref&gt;
*The [[conchoid of Nicomedes]], studied by [[Nicomedes (mathematician)|Nicomedes]] as a method to both double the cube and to [[angle trisection|trisect an angle]].&lt;ref&gt;Lockwood p. 129&lt;/ref&gt;
*The [[Archimedean spiral]], studied by [[Archimedes]] as a method to trisect an angle and [[Squaring the circle|square the circle]].&lt;ref&gt;{{MacTutor|class=Curves|id=Spiral|title=Spiral of Archimedes}}&lt;/ref&gt;
*The [[spiric section]]s, sections of [[torus|tori]] studied by [[Perseus (geometer)|Perseus]] as sections of cones had been studied by Apollonius.

[[File:Folium Of Descartes.svg|thumb|225px|left|Analytic geometry allowed curves, such as the [[Folium of Descartes]], to be defined using equations instead of geometrical construction.]]
A fundamental advance in the theory of curves was the advent of [[analytic geometry]] in the seventeenth century. This enabled a curve to be described using an equation rather than an elaborate geometrical construction. This not only allowed new curves to be defined and studied, but it enabled a formal distinction to be made between curves that can be defined using [[algebraic equation]]s, [[algebraic curve]]s, and those that cannot, [[transcendental curve]]s. Previously, curves had been described as "geometrical" or "mechanical" according to how they were, or supposedly could be, generated.&lt;ref name="Lockwood" /&gt;

Conic sections were applied in [[astronomy]] by [[Johannes Kepler|Kepler]].
Newton also worked on an early example in the [[calculus of variations]]. Solutions to variational problems, such as the [[brachistochrone]] and [[tautochrone]] questions, introduced properties of curves in new ways (in this case, the [[cycloid]]). The [[catenary]] gets its name as the solution to the problem of a hanging chain, the sort of question that became routinely accessible by means of [[differential calculus]].

In the eighteenth century came the beginnings of the theory of plane algebraic curves, in general. Newton had studied the [[cubic curve]]s, in the general description of the real points into 'ovals'. The statement of [[Bézout's theorem]] showed a number of aspects which were not directly accessible to the geometry of the time, to do with singular points and complex solutions.

Since the nineteenth century there has not been a separate theory of curves, but rather the appearance of curves as the one-dimensional aspect of [[projective geometry]], and [[differential geometry]]; and later [[topology]], when for example the [[Jordan curve theorem]] was understood to lie quite deep, as well as being required in [[complex analysis]]. The era of the [[space-filling curve]]s finally provoked the modern definitions of curve.

=={{anchor|Definitions}} Definition==
[[File:Mandelbrot Components.svg|250px|right|thumb|Boundaries of hyperbolic components of [[Mandelbrot set]] as closed curves]]

In general, a '''curve''' is defined through a [[continuous function (topology)|continuous function]] &lt;math&gt;\gamma \colon I \rightarrow X&lt;/math&gt; from an [[Interval (mathematics)|interval]] {{mvar|I}} of the [[real number]]s into a [[topological space]] {{mvar|X}}. Depending on the context, it is either &lt;math&gt;\gamma&lt;/math&gt; or its image &lt;math&gt;\gamma(I)&lt;/math&gt; which is called a curve.

In [[general topology]], when non-[[differentiable function]]s are considered, it is the map &lt;math&gt;\gamma&lt;/math&gt;, which is called a curve, because its image may look very differently from what is commonly called a curve. For example, the image of the [[Peano curve]] completely fills the square. On the other hand, when one considers curves defined by a [[differentiable function]] (or, at least, a [[piecewise differentiable]] function), this is commonly the image of the function which is called a curve.

*The curve is said to be '''simple''', or a '''Jordan arc''', if &lt;math&gt;\gamma&lt;/math&gt; is [[injective]], i.e. if for all &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt; in &lt;math&gt;I&lt;/math&gt;, we have &lt;math&gt;\gamma(x) = \gamma(y)&lt;/math&gt; implies &lt;math&gt;x = y&lt;/math&gt;.   If &lt;math&gt;I&lt;/math&gt; is a closed bounded interval &lt;math&gt;[a, b]&lt;/math&gt;, we also allow the possibility &lt;math&gt;\gamma(a) = \gamma(b)&lt;/math&gt; (this convention makes it possible to talk about "closed" simple curves, see below). In other words, this curve "does not cross itself and has no missing points".&lt;ref&gt;{{cite web|url=http://dictionary.reference.com/browse/jordan%20arc |title=Jordan arc definition at Dictionary.com. Dictionary.com Unabridged. Random House, Inc |publisher=[[Dictionary.reference.com]] |date= |accessdate=2012-03-14}}&lt;/ref&gt;
*If &lt;math&gt;\gamma(x)=\gamma(y)&lt;/math&gt; for some &lt;math&gt;x\ne y&lt;/math&gt; (other than the extremities of &lt;math&gt;I&lt;/math&gt;), then &lt;math&gt;\gamma(x)&lt;/math&gt; is called a '''double''' (or '''multiple''') '''point''' of the curve. This is a special case of a [[singular point of a curve]].
*A curve &lt;math&gt;\gamma&lt;/math&gt; is said to be '''closed''' or '''a loop''' if &lt;math&gt;I = [a,
b]&lt;/math&gt; and if &lt;math&gt;\gamma(a) = \gamma(b)&lt;/math&gt;.  A closed curve is thus the image of a continuous mapping of the circle &lt;math&gt;S^1&lt;/math&gt;; a '''simple closed curve''' is also called a '''Jordan curve'''. The [[Jordan curve theorem]] states that such curves divide the plane into an "interior" and an "exterior".

{{anchor|Space curve}}
A '''[[plane curve]]''' is a curve for which &lt;math&gt;X&lt;/math&gt; is the [[Euclidean plane]]&amp;mdash;these are the examples first encountered&amp;mdash;or in some cases the [[projective plane]]. A '''space curve''' is a curve for which &lt;math&gt;X&lt;/math&gt; is of three dimensions, usually [[Euclidean space]]; a '''skew curve''' {{anchor|skew curve}} is a space curve which lies in no plane. These definitions of plane, space and skew curves apply also to [[real algebraic geometry|real algebraic curve]]s, although the above definition of a curve does not apply (a real algebraic curve may be [[connected space|disconnected]]).

This definition of curve captures our intuitive notion of a curve as a connected, continuous geometric figure that is "like" a line, without thickness and drawn without interruption, although it also includes figures that can hardly be called curves in common usage. For example, the image of a curve can cover a [[Square (geometry)|square]] in the plane ([[space-filling curve]]). The image of simple plane curve can have [[Hausdorff dimension]] bigger than one (see [[Koch snowflake]]) and even [[positive number|positive]] [[Lebesgue measure]]&lt;ref&gt;{{cite journal|last=Osgood|first=William F.| authorlink1=William Fogg Osgood |date=January 1903|title=A Jordan Curve of Positive Area|journal=Transactions of the American Mathematical Society|publisher=[[American Mathematical Society]]|volume=4|issue=1|pages=107–112|doi=10.2307/1986455|issn=0002-9947|jstor=1986455}}&lt;!--|accessdate=2008-06-04--&gt;&lt;/ref&gt; (the last example can be obtained by small variation of the [[Peano curve]] construction). The [[dragon curve]] is another unusual example.

==Differentiable curve==
Roughly speaking a '''differentiable curve''' is a curve that is defined as being locally the image of an injective [[differentiable function]] &lt;math&gt;\gamma \colon I \rightarrow X&lt;/math&gt; from an [[Interval (mathematics)|interval]] {{mvar|I}} of the [[real number]]s into a [[differentiable manifold]] {{mvar|X}}, often &lt;math&gt;\mathbb{R}^n.&lt;/math&gt;

More precisely, a differentiable curve is a subset {{mvar|C}} of {{mvar|X}} where every point of {{mvar|C}} has a neighborhood {{mvar|U}} such that &lt;math&gt;C\cap U&lt;/math&gt; is [[diffeomorphism|diffeomorphic]] to an interval of the real numbers. In other words, a differentiable curve is a differentiable manifold of dimension one.

==Length of a curve==
{{main|Arc length}}

If &lt;math&gt; X = \mathbb{R}^{n} &lt;/math&gt; is the &lt;math&gt; n &lt;/math&gt;-dimensional [[Euclidean space]], and if &lt;math&gt; \gamma: [a,b] \to \mathbb{R}^{n} &lt;/math&gt; is an injective and continuously [[differentiable function]], then the '''length''' of &lt;math&gt; \gamma &lt;/math&gt; is defined as the quantity
:&lt;math&gt;
\operatorname{Length}(\gamma) ~ \stackrel{\text{df}}{=} ~ \int_{a}^{b} |\gamma\,'(t)| ~ \mathrm{d}{t}.
&lt;/math&gt;
The length of a curve is independent of the [[parametrization]] &lt;math&gt; \gamma &lt;/math&gt;.

In particular, the length &lt;math&gt; s &lt;/math&gt; of the [[graph of a function|graph]] of a continuously differentiable function &lt;math&gt; y = f(x) &lt;/math&gt; defined on a closed interval &lt;math&gt; [a,b] &lt;/math&gt; is
:&lt;math&gt;
s = \int_{a}^{b} \sqrt{1 + [f'(x)]^{2}} ~ \mathrm{d}{x}.
&lt;/math&gt;

More generally, if &lt;math&gt; X &lt;/math&gt; is a [[metric space]] with metric &lt;math&gt; d &lt;/math&gt;, then we can define the length of a curve &lt;math&gt; \gamma: [a,b] \to X &lt;/math&gt; by
:&lt;math&gt;
\operatorname{Length}(\gamma)
~ \stackrel{\text{df}}{=} ~
\sup \!
\left( \left\{
\sum_{i = 1}^{n} d(\gamma(t_{i}),\gamma(t_{i - 1})) ~ \Bigg| ~ n \in \mathbb{N} ~ \text{and} ~ a = t_{0} &lt; t_{1} &lt; \ldots &lt; t_{n} = b
\right\} \right),
&lt;/math&gt;
where the supremum is taken over all &lt;math&gt; n \in \mathbb{N} &lt;/math&gt; and all partitions &lt;math&gt; t_{0} &lt; t_{1} &lt; \ldots &lt; t_{n} &lt;/math&gt; of &lt;math&gt; [a, b] &lt;/math&gt;.

A '''rectifiable curve''' is a curve with [[wiktionary:finite|finite]] length. A curve &lt;math&gt; \gamma: [a,b] \to X &lt;/math&gt; is called '''natural''' (or '''unit-speed''' or '''parametrized by arc length''') if for any &lt;math&gt; t_{1},t_{2} \in [a,b] &lt;/math&gt; such that &lt;math&gt; t_{1} \leq t_{2} &lt;/math&gt;, we have
:&lt;math&gt;
\operatorname{Length} \! \left( \gamma|_{[t_{1},t_{2}]} \right) = t_{2} - t_{1}.
&lt;/math&gt;

If &lt;math&gt; \gamma: [a,b] \to X &lt;/math&gt; is a [[Lipschitz continuity|Lipschitz-continuous]] function, then it is automatically rectifiable. Moreover, in this case, one can define the '''speed''' (or [[metric derivative]]) of &lt;math&gt; \gamma &lt;/math&gt; at &lt;math&gt; t \in [a,b] &lt;/math&gt; as
:&lt;math&gt;
{\operatorname{Speed}_{\gamma}}(t) ~ \stackrel{\text{df}}{=} ~ \limsup_{[a,b] \ni s \to t} \frac{d(\gamma(s),\gamma(t))}{|s - t|}
&lt;/math&gt;
and then show that
:&lt;math&gt;
\operatorname{Length}(\gamma) = \int_{a}^{b} {\operatorname{Speed}_{\gamma}}(t) ~ \mathrm{d}{t}.
&lt;/math&gt;

==Differential geometry==
{{main|Differential geometry of curves}}
While the first examples of curves that are met are mostly plane curves (that is, in everyday words, ''curved lines'' in ''two-dimensional space''), there are obvious examples such as the [[helix]] which exist naturally in three dimensions. The needs of geometry, and also for example [[classical mechanics]] are to have a notion of curve in space of any number of dimensions. In [[general relativity]], a [[world line]] is a curve in [[spacetime]].

If &lt;math&gt;X&lt;/math&gt; is a [[differentiable manifold]], then we can define the notion of ''differentiable curve'' in &lt;math&gt;X&lt;/math&gt;. This general idea is enough to cover many of the applications of curves in mathematics. From a local point of view one can take &lt;math&gt;X&lt;/math&gt; to be [[Euclidean space]]. On the other hand, it is useful to be more general, in that (for example) it is possible to define the [[Differential geometry of curves|tangent vector]]s to &lt;math&gt;X&lt;/math&gt; by means of this notion of curve.

If &lt;math&gt;X&lt;/math&gt; is a [[smooth manifold]], a ''smooth curve'' in &lt;math&gt;X&lt;/math&gt; is a [[smooth map]]

:&lt;math&gt;\gamma \colon I \rightarrow X&lt;/math&gt;.

This is a basic notion. There are less and more restricted ideas, too. If &lt;math&gt;X&lt;/math&gt; is a &lt;math&gt;C^k&lt;/math&gt; manifold (i.e., a manifold whose [[chart (topology)|charts]] are &lt;math&gt;k&lt;/math&gt; times [[continuously differentiable]]), then a &lt;math&gt;C^k&lt;/math&gt; curve in &lt;math&gt;X&lt;/math&gt; is such a curve which is only assumed to be &lt;math&gt;C^k&lt;/math&gt; (i.e. &lt;math&gt;k&lt;/math&gt; times continuously differentiable).  If &lt;math&gt;X&lt;/math&gt; is an [[manifold|analytic manifold]] (i.e. infinitely differentiable and charts are expressible as [[power series]]), and &lt;math&gt;\gamma&lt;/math&gt; is an analytic map, then &lt;math&gt;\gamma&lt;/math&gt; is said to be an ''analytic curve''.

A differentiable curve is said to be ''regular'' if its [[derivative]] never vanishes. (In words, a regular curve never slows to a stop or backtracks on itself.)  Two &lt;math&gt;C^k&lt;/math&gt; differentiable curves

:&lt;math&gt;\gamma_1 \colon I \rightarrow X&lt;/math&gt; and

:&lt;math&gt;\gamma_2 \colon J \rightarrow X&lt;/math&gt;

are said to be ''equivalent'' if there is a [[bijection|bijective]] &lt;math&gt;C^k&lt;/math&gt; map

:&lt;math&gt;p \colon J \rightarrow I&lt;/math&gt;

such that the [[inverse map]]

:&lt;math&gt;p^{-1} \colon I \rightarrow J&lt;/math&gt;

is also &lt;math&gt;C^k&lt;/math&gt;, and

:&lt;math&gt;\gamma_{2}(t) = \gamma_{1}(p(t))&lt;/math&gt;

for all &lt;math&gt;t&lt;/math&gt;.  The map &lt;math&gt;\gamma_2&lt;/math&gt; is called a ''reparametrisation'' of &lt;math&gt;\gamma_1&lt;/math&gt;; and this makes an [[equivalence relation]] on the set of all &lt;math&gt;C^k&lt;/math&gt; differentiable curves in &lt;math&gt;X&lt;/math&gt;.  A &lt;math&gt;C^k&lt;/math&gt; ''arc'' is an [[equivalence class]] of &lt;math&gt;C^k&lt;/math&gt; curves under the relation of reparametrisation.

==Algebraic curve==
{{main|Algebraic curve}}
Algebraic curves are the curves considered in [[algebraic geometry]]. A plane algebraic curve is the [[set (mathematics)|set]] of the points of coordinates ''x'', ''y'' such that ''f''(''x'', ''y'') = 0, where ''f'' is a polynomial in two variables defined over some field ''F''. Algebraic geometry normally looks not only on points with coordinates in ''F'' but on all the points with coordinates in an [[algebraically closed field]] ''K''. If ''C'' is a curve defined by a polynomial ''f'' with coefficients in ''F'', the curve is said to be '''defined''' over ''F''. The points of the curve ''C'' with coordinates in a field ''G'' are said to be '''rational''' over ''G'' and can be denoted ''C''(''G'')). When ''G'' is the field of the [[rational number]]s, one simply talks of ''rational points''. For example, [[Fermat's Last Theorem]] may be restated as: ''For n'' &gt; 2, ''every rational point of the [[Fermat curve]] of degree n has a zero coordinate''.

Algebraic curves can also be space curves, or curves in a space of higher dimension, say {{math|''n''}}. They are defined as [[algebraic varieties]] of [[dimension of an algebraic variety|dimension]] one. They may be obtained as the common solutions of at least {{math|''n''–1}} polynomial equations in {{math|''n''}} variables. If {{math|''n''–1}} polynomials are sufficient to define a curve in a space of dimension {{math|''n''}}, the curve is said to be a [[complete intersection]]. By eliminating variables (by any tool of [[elimination theory]]), an algebraic curve may be projected onto a [[plane algebraic curve]], which however may introduce new singularities such as [[cusp (singularity)|cusp]]s or [[double point]]s.

A plane curve may also be completed in a curve in the [[projective plane]]: if a curve is defined by a polynomial ''f'' of total degree ''d'', then ''w''&lt;sup&gt;''d''&lt;/sup&gt;''f''(''u''/''w'', ''v''/''w'') simplifies to a [[homogeneous polynomial]] ''g''(''u'', ''v'', ''w'') of degree ''d''. The values of ''u'', ''v'', ''w'' such that ''g''(''u'', ''v'', ''w'') = 0 are the homogeneous coordinates of the points of the completion of the curve in the projective plane and the points of the initial curve are those such ''w'' is not zero. An example is the [[Fermat curve]] ''u''&lt;sup&gt;''n''&lt;/sup&gt; + ''v''&lt;sup&gt;''n''&lt;/sup&gt; = ''w''&lt;sup&gt;''n''&lt;/sup&gt;, which has an affine form ''x''&lt;sup&gt;''n''&lt;/sup&gt; + ''y''&lt;sup&gt;''n''&lt;/sup&gt; = 1. A similar process of homogenization may be defined for curves in higher dimensional spaces

Important examples of algebraic curves are the [[conic]]s, which are nonsingular curves of degree two and [[genus (mathematics)|genus]] zero, and [[elliptic curve]]s, which are nonsingular curves of genus one studied in [[number theory]] and which have important applications to [[cryptography]].  Because algebraic curves in fields of [[characteristic (algebra)|characteristic]] zero are most often studied over the [[complex number]]s, algebraic curves in algebraic geometry may be considered as [[real number|real]] surfaces.  In particular, the nonsingular complex projective algebraic curves are called [[Riemann surface]]s.

==See also==
{{Div col|colwidth=20em}}
*[[Coordinate curve]]
*[[Curve orientation]]
*[[Curve sketching]]
*[[Differential geometry of curves]]
*[[Gallery of curves]]
*[[Implicit curve]]
*[[List of curves topics]]
*[[List of curves]]
*[[Osculating circle]]
*[[Parametric surface]]
*[[Path (topology)]]
*[[Position vector]]
*[[Vector-valued function]]
*[[Curve fitting]]
*[[Winding number]]
{{div col end}}

==Notes==
{{notelist}}

==References==
{{reflist|2}}

* {{springer|author=A.S. Parkhomenko|id=l/l059020|title=Line (curve)}}
* {{springer|author=B.I. Golubov|id=r/r080130|title=Rectifiable curve}}
* [[Euclid]], commentary and trans. by [[T. L. Heath]] ''Elements'' Vol. 1 (1908 Cambridge) [https://books.google.com/books?id=UhgPAAAAIAAJ Google Books]
* E. H. Lockwood ''A Book of Curves'' (1961 Cambridge)

==External links==
{{Commons category|Curves}}
*[https://web.archive.org/web/20040609111105/http://www-gap.dcs.st-and.ac.uk/~history/Curves/Curves.html Famous Curves Index], School of Mathematics and Statistics, University of St Andrews, Scotland
*[http://www.2dcurves.com/ Mathematical curves] A collection of 874 two-dimensional mathematical curves
*[http://faculty.evansville.edu/ck6/Gallery/Introduction.html Gallery of Space Curves Made from Circles, includes animations by Peter Moses]
*[http://faculty.evansville.edu/ck6/GalleryTwo/Introduction2.html Gallery of Bishop Curves and Other Spherical Curves, includes animations by Peter Moses]
* The Encyclopedia of Mathematics article on [http://www.encyclopediaofmath.org/index.php/Line_(curve) lines].
* The Manifold Atlas page on [http://www.map.mpim-bonn.mpg.de/1-manifolds 1-manifolds].

{{Curves}}

{{Authority control}}

[[Category:Curves| ]]
[[Category:Metric geometry]]
[[Category:Topology]]
[[Category:General topology]]</text>
      <sha1>e7ixi954je34oscy63b3m9r4yvr5bl7</sha1>
    </revision>
  </page>
  <page>
    <title>Diplomatic bag</title>
    <ns>0</ns>
    <id>580297</id>
    <revision>
      <id>866395374</id>
      <parentid>865229919</parentid>
      <timestamp>2018-10-30T02:07:37Z</timestamp>
      <contributor>
        <ip>24.156.181.89</ip>
      </contributor>
      <comment>waybackmachine for dead link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9244">A '''diplomatic bag''', also known as a '''diplomatic pouch''', is a container with certain legal protections used for carrying official correspondence or other items between a [[diplomatic mission]] and its home government or other diplomatic, consular, or otherwise official entity.&lt;ref name="Boczek"&gt;{{cite book   
  | last = Boczek
  | first = Boleslaw Adam 
  | authorlink = 
  | coauthors = 
  | title = International Law: A Dictionary
  | publisher = Scarecrow Press
  | year = 2005
  | location = 
  | pages = 51–52
  | url = https://books.google.com/books?id=NR7mFXCB-wgC&amp;pg=PA51&amp;dq=%22diplomatic+bag%22+definition&amp;hl=en&amp;sa=X&amp;ei=ggzqToqfPI7IsQL8g5jOCQ&amp;ved=0CFAQ6AEwAQ#v=onepage&amp;q=%22diplomatic%20bag%22%20definition&amp;f=false
  | doi = 
  | id = 
  | isbn = 0-8108-5078-8}}&lt;/ref&gt;   The physical concept of a "diplomatic bag" is flexible and therefore can take many forms (e.g., a [[cardboard box]], [[briefcase]], [[duffel bag]], large [[suitcase]], [[crate]] or even a [[shipping container]]).&lt;ref name="Boczek" /&gt; 

Additionally, a diplomatic bag usually has some form of lock and/or [[tamper-evident]] seal attached to it in order to deter or detect interference by unauthorized third parties. The most important point is that as long as it is externally marked to show its status, the "bag" has [[diplomatic immunity]] from search or seizure,&lt;ref name=BBC&gt;{{cite news |url=http://news.bbc.co.uk/1/hi/uk/672786.stm |title=Diplomatic bag: The inside story |publisher=BBC News |date=March 10, 2000 |accessdate=2008-10-05}}&lt;/ref&gt; as codified in article 27 of the 1961 [[Vienna Convention on Diplomatic Relations]].&lt;ref name=UN&gt;{{cite web |url=http://legal.un.org/ilc/texts/instruments/english/conventions/9_1_1961.pdf |format=PDF|title=Vienna Convention on Diplomatic Relations 1961 |publisher=United Nations |accessdate=2008-10-05}}, p. 8&lt;/ref&gt; It may only contain articles intended for official use.&lt;ref name=UN/&gt;  It is often escorted by a [[diplomatic courier]], who is similarly immune from arrest and detention.&lt;ref name=BBC/&gt;&lt;ref name=UN/&gt;

== Cryptography ==
In discussions of [[cryptography]], the diplomatic bag is conventionally used as an example of the ultimate [[secure channel]] used to exchange [[key (cryptography)|keys]], [[codebook]]s, and other necessarily secret materials. In contemporary practice, diplomatic bags are indeed used for exactly this purpose.{{cn|date=October 2018}}

==Noteworthy shipments==

* During [[World War II]], [[Winston Churchill]] reportedly received shipments of [[Cuban Cigars|Cuban cigars]] by this means.&lt;ref name=BBC/&gt;
* [[Triplex (espionage)|Triplex]] was a British espionage operation in World War II which involved secretly copying the contents of diplomatic pouches of neutral countries.
* In 1964, a Moroccan-born [[Israel]]i double agent named Mordechai Ben Masoud Louk (also known as Josef Dahan) was drugged, bound, and placed in a diplomatic mailing crate at the [[Egypt]]ian Embassy in [[Rome]], but was rescued by Italian authorities.&lt;ref name=ISP&gt;{{cite book |url=https://books.google.com/books?id=es9Sunv_y2MC&amp;pg=PA128&amp;lpg=PA128&amp;dq=Dikko+incident&amp;source=web&amp;ots=XtR_bnof9H&amp;sig=KPPxCrPRBZkOwjoYGMLuANZAdCk&amp;hl=en&amp;sa=X&amp;oi=book_result&amp;resnum=3&amp;ct=result |title=''Islamic State Practices, International Law and the Threat from Terrorism'' |author=Javaid Rehman |publisher=Hart Publishing |accessdate=2008-10-05}}&lt;/ref&gt; The box that he had been sealed into "had almost certainly been used before for human cargo,"&lt;ref&gt;{{cite web|title=Kidnapped by Egypt: The Spy In The Air Express Trunk—It's Fact, Not Fiction—And It Has Happened Before|url=http://pgnewspapers.pgpl.ca/fedora/repository/pgc:1964-11-18/-/Prince%20George%20Citizen%20-%20November%2018,%201964|work=Prince George (B.C.) Citizen (p. 1)|date=November 18, 1964}}&lt;/ref&gt; including possibly for an Egyptian military official who had defected to Italy several years before but then disappeared without a trace before reappearing under Egyptian custody and facing trial.
* During the 1982 [[Falklands War]], the Argentine government used a diplomatic bag to smuggle several [[limpet mine]]s to their embassy in Spain, to be used in the covert [[Operation Algeciras]], in which Argentine agents were to blow up a British warship in the [[Royal Navy Dockyard]] at [[Gibraltar]]. The plot was uncovered and stopped by the Spanish police before the explosives could be set.&lt;ref&gt;{{cite news|url=http://www.chronicle.gi/headlines_details.php?id=27328 |title=Argentina's 1982 attempt on Gibraltar |publisher=Gibraltar Chronicle |date=December 28, 2012 |accessdate=December 1, 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20131203011748/http://www.chronicle.gi/headlines_details.php?id=27328 |archivedate=December 3, 2013 |df= }}&lt;/ref&gt;
* In the 1984 [[Dikko Affair]], a former [[Nigeria]]n government minister, [[Umaru Dikko]], was kidnapped and placed in a shipping crate in an attempt to transport him from the United Kingdom back to Nigeria for trial.&lt;ref name=ISP/&gt; However, it was not marked as a diplomatic bag, which allowed British customs to open it.&lt;ref name=ISP/&gt; 
* In 1984, the [[Sterling submachine gun]] used to shoot dead WPC [[Murder of Yvonne Fletcher|Yvonne Fletcher]] from inside the [[Libya]]n Embassy in London was smuggled out of the [[UK]] in one of 21 diplomatic bags.&lt;ref&gt;{{cite news| url=https://www.telegraph.co.uk/news/worldnews/africaandindianocean/libya/6345907/Yvonne-Fletcher-Libya-and-betrayal-of-justice-timeline.html | location=London | work=The Daily Telegraph | first=Gordon | last=Rayner | title=Yvonne Fletcher, Libya and betrayal of justice: timeline | date=2009-10-16}}&lt;br/&gt;{{cite news| url=https://www.telegraph.co.uk/news/uknews/terrorism-in-the-uk/6341458/WPc-Yvonne-Fletcher-We-have-guns-and-there-will-be-fighting.html | location=London | work=The Daily Telegraph | first1=Gordon | last1=Rayner | first2=Christopher | last2=Hope | title=WPc Yvonne Fletcher: 'We have guns and there will be fighting' | date=2009-10-16}}&lt;br/&gt;http://hansard.millbanksystems.com/commons/1984/may/15/searching-of-diplomatic-bags&lt;br/&gt;{{cite news| url=http://news.bbc.co.uk/onthisday/hi/dates/stories/april/27/newsid_2502000/2502565.stm | work=BBC News | title=1984: Libyan embassy siege ends | date=1984-04-27}}&lt;/ref&gt;
* In March 2000 [[Zimbabwe]] was the object of political interest internationally when it opened a British diplomatic shipment.&lt;ref name=BBC/&gt;
* In May 2008, a replacement pump for the toilet on the [[International Space Station]] was sent in a diplomatic pouch from Russia to the United States in order to arrive before liftoff of the next shuttle mission.&lt;ref&gt;{{cite web
 | url = http://www.redorbit.com/news/space/1407194/space_station_toilet_parts_set_for_liftoff 
 | deadurl = yes
 | archiveurl = https://web.archive.org/web/20121001090819/http://www.redorbit.com/news/space/1407194/space_station_toilet_parts_set_for_liftoff/
 | archivedate = 2012-10-01
 | title = Space Station Toilet Parts Set for Liftoff}}&lt;/ref&gt;
* In 2012, a 16&amp;nbsp;kg shipment of cocaine was sent to the United Nations in New York in a bag masquerading as a diplomatic pouch.&lt;ref&gt;Associated Press, [https://www.theguardian.com/world/2012/jan/27/cocaine-seized-un-new-york Cocaine seized at UN in New York], 26 January 2012&lt;/ref&gt;
* In January 2012, Italy detected 40 kilograms of cocaine smuggled in a diplomatic pouch from Ecuador, arresting five. Ecuador insisted it had inspected the shipment for drugs at the foreign ministry before it was sent to Milan.&lt;ref&gt;http://www.starpoly.com/comunicado/&lt;/ref&gt;
*In November 2013, the UK government alleged that a British diplomatic bag had been opened by the [[Guardia Civil]] at the [[Disputed status of Gibraltar|Gibraltar-Spanish border]], sparking a formal diplomatic protest.&lt;ref&gt;{{cite news|url=https://www.bbc.co.uk/news/uk-25100083|work=BBC News|title=UK protest at Gibraltar diplomatic bag opening|date=2013-11-26}}&lt;/ref&gt; The Spanish government responded that the bag, being transported from the [[Governor of Gibraltar]] by a courier company within a mailbag containing other packages, did not meet the criteria of being in transit between a diplomatic mission and a home government.&lt;ref&gt;{{cite news |url=https://www.telegraph.co.uk/news/worldnews/europe/gibraltar/10477856/Spain-dismisses-Gibraltar-diplomatic-bag-incident.html |title=Spain dismisses Gibraltar diplomatic bag incident |author=Fiona Govan |newspaper=Daily Telegraph |date=27 November 2013 |accessdate=4 December 2013}}&lt;/ref&gt;&lt;ref&gt;http://www.rtve.es/noticias/20131126/reino-unido-protesta-ante-espana-apertura-valija-diplomatica-gibraltar/802621.shtml {{es icon}}&lt;/ref&gt;

==See also==
* [[Military mail]]
* [[Diplomatic cable]]

== References ==
{{Reflist}}

== External links ==
* [http://www.ediplomat.com/nd/glossary.htm eDiplomat.com: Glossary of Diplomatic Terms]
* {{cite web |url=http://www.straightdope.com/mailbag/mdiplomaticpouch.html |title=Is there such a thing as a diplomatic pouch? |date=December 20, 2005 |publisher=''[[Straight Dope]]'' |accessdate=September 23, 2012}} article with extensive detailed references.

{{Bags}}

{{Diplomacy}}

[[Category:Bags]]
[[Category:Cryptography]]
[[Category:Diplomacy]]
[[Category:Diplomatic immunity and protection]]</text>
      <sha1>ihjmlcx0fidbncpatf2judla38bi9cy</sha1>
    </revision>
  </page>
  <page>
    <title>Edge covering number</title>
    <ns>0</ns>
    <id>1652062</id>
    <redirect title="Edge cover" />
    <revision>
      <id>313413946</id>
      <parentid>272991283</parentid>
      <timestamp>2009-09-12T18:45:46Z</timestamp>
      <contributor>
        <username>Miym</username>
        <id>8436643</id>
      </contributor>
      <minor/>
      <comment>cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#redirect [[Edge cover]]
[[Category:Graph invariants]]</text>
      <sha1>8zkk858fzrwnnc0e2wg6ddgh11gmskd</sha1>
    </revision>
  </page>
  <page>
    <title>Electromagnetic wave equation</title>
    <ns>0</ns>
    <id>2924436</id>
    <revision>
      <id>814382408</id>
      <parentid>812186397</parentid>
      <timestamp>2017-12-08T13:39:22Z</timestamp>
      <contributor>
        <username>Reyk</username>
        <id>378651</id>
      </contributor>
      <minor/>
      <comment>reduce verbosity</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20311">The '''electromagnetic wave equation''' is a second-order [[partial differential equation]] that describes the propagation of [[electromagnetic wave]]s through a [[Medium (optics)|medium]] or in a [[vacuum]].  It is a [[Wave equation#Scalar wave equation in three space dimensions|three-dimensional form of the wave equation]]. The [[Homogeneous differential equation|homogeneous]] form of the equation, written in terms of either the [[electric field]] {{math|'''E'''}} or the [[magnetic field]] {{math|'''B'''}}, takes the form:

:&lt;math&gt;\begin{align}
\left(v_{ph}^2\nabla^2 - \frac{\partial^2}{\partial t^2} \right) \mathbf{E} &amp;= \mathbf{0} \\
\left(v_{ph}^2\nabla^2 - \frac{\partial^2}{\partial t^2} \right) \mathbf{B} &amp;= \mathbf{0}
\end{align}&lt;/math&gt;

where 

:&lt;math&gt; v_{ph} = \frac{1}{\sqrt {\mu\varepsilon}} &lt;/math&gt; 

is the [[speed of light]] (i.e. [[phase velocity]]) in a medium with [[Permeability (electromagnetism)|permeability]] {{mvar|μ}}, and [[permittivity]] {{mvar|ε}}, and {{math|∇&lt;sup&gt;2&lt;/sup&gt;}} is the [[Vector Laplacian|Laplace operator]].  In a vacuum, {{math|v&lt;sub&gt;ph&lt;/sub&gt; {{=}} ''c&lt;sub&gt;0&lt;/sub&gt;'' {{=}} 299,792,458}} meters per second, a fundamental [[physical constant]].&lt;ref&gt;Current practice is to use {{math|''c''&lt;sub&gt;0&lt;/sub&gt;}} to denote the speed of light in vacuum according to [[ISO 31]]. In the original Recommendation of 1983, the symbol {{mvar|c}} was used for this purpose. See [http://physics.nist.gov/Pubs/SP330/sp330.pdf NIST ''Special Publication 330'', Appendix 2, p. 45 ]&lt;/ref&gt;  The electromagnetic wave equation derives from [[Maxwell's equations]]. In most older literature, {{math|'''B'''}} is called the ''magnetic flux density'' or ''magnetic induction''.

==The origin of the electromagnetic wave equation==
[[File:Postcard-from-Maxwell-to-Tait.jpg|thumb|right|175px|A postcard from Maxwell to [[Peter Guthrie Tait|Peter Tait]].]]

In his 1865 paper titled [[A Dynamical Theory of the Electromagnetic Field]], Maxwell utilized the correction to Ampère's circuital law that he had made in part III of his 1861 paper [[On Physical Lines of Force]]. In ''Part VI'' of his 1864 paper titled ''Electromagnetic Theory of Light'',&lt;ref&gt;[[Media:A Dynamical Theory of the Electromagnetic Field.pdf|Maxwell 1864]], page 497.&lt;/ref&gt; Maxwell combined displacement current with some of the other equations of electromagnetism and he obtained a wave equation with a speed equal to the speed of light. He commented:

&lt;blockquote&gt;''The agreement of the results seems to show that light and magnetism are affections of the same substance, and that light is an electromagnetic disturbance propagated through the field according to electromagnetic laws.''&lt;ref&gt;See [[Media:A Dynamical Theory of the Electromagnetic Field.pdf|Maxwell 1864]], page 499.&lt;/ref&gt;&lt;/blockquote&gt; 

Maxwell's derivation of the electromagnetic wave equation has been replaced in modern physics education by a much less cumbersome method involving combining the corrected version of Ampère's circuital law with [[Faraday's law of induction]].

To obtain the electromagnetic wave equation in a vacuum using the modern method, we begin with the modern ''''Heaviside' form of Maxwell's equations'''. In a vacuum- and charge-free space, these equations are:

:&lt;math&gt;\begin{align}
 \nabla \cdot \mathbf{E}  &amp;= 0 \\
 \nabla \times \mathbf{E} &amp;= -\frac{\partial \mathbf{B}} {\partial t}\\
 \nabla \cdot \mathbf{B}  &amp;= 0 \\
 \nabla \times \mathbf{B} &amp;= \mu_0 \varepsilon_0 \frac{ \partial \mathbf{E}} {\partial t}\\
\end{align}&lt;/math&gt;

These are the general Maxwell's equations specialized to the case with charge and current both set to zero.
Taking the curl of the curl equations gives:

:&lt;math&gt;\begin{align}
\nabla \times \left(\nabla \times \mathbf{E} \right) &amp;= -\frac{\partial}{\partial t} \nabla \times \mathbf{B} = -\mu_0 \varepsilon_0 \frac{\partial^2 \mathbf{E}}{\partial t^2} \\
\nabla \times \left(\nabla \times \mathbf{B} \right) &amp;= \mu_0 \varepsilon_0 \frac{\partial}{\partial t} \nabla \times \mathbf{E} = -\mu_0 \varepsilon_0 \frac{\partial^2 \mathbf{B}}{\partial t^2}
\end{align}&lt;/math&gt;

We can use the vector identity

:&lt;math&gt;\nabla \times \left( \nabla \times \mathbf{V} \right) = \nabla \left( \nabla \cdot \mathbf{V} \right) - \nabla^2 \mathbf{V}&lt;/math&gt;

where {{math|'''V'''}} is any vector function of space. And

:&lt;math&gt;\nabla^2 \mathbf{V} = \nabla \cdot \left( \nabla \mathbf{V} \right)&lt;/math&gt;

where {{math|∇'''V'''}} is a [[Dyadics|dyadic]] which when operated on by the divergence operator {{math|∇ ⋅}} yields a vector. Since  

:&lt;math&gt;\begin{align}
\nabla \cdot \mathbf{E}  &amp;= 0\\
\nabla \cdot \mathbf{B}  &amp;= 0
\end{align}&lt;/math&gt;

then the first term on the right in the identity vanishes and we obtain the wave equations:

:&lt;math&gt;\begin{align}
\frac{1}{c_0^2} \frac{\partial^2 \mathbf{E}}{\partial t^2} - \nabla^2 \mathbf{E} &amp;= 0\\
\frac{1}{c_0^2} \frac{\partial^2 \mathbf{B}}{\partial t^2} - \nabla^2 \mathbf{B} &amp;= 0
\end{align}&lt;/math&gt;

where 

:&lt;math&gt;c_0 = \frac{1}{\sqrt{\mu_0 \varepsilon_0}} = 2.99792458 \times 10^8\;\textrm{m/s}&lt;/math&gt;

is the speed of light in free space.

==Covariant form of the homogeneous wave equation==
[[File:Time dilation02.gif|right|frame|Time dilation in transversal motion. The requirement that the speed of light is constant in every [[inertial frame|inertial reference frame]] leads to the [[Special relativity|theory of Special Relativity]].]]
These [[Formulation of Maxwell's equations in special relativity|relativistic equations]] can be written in [[Covariance and contravariance of vectors|contravariant]] form as

:&lt;math&gt;\Box A^{\mu} = 0&lt;/math&gt;

where the [[electromagnetic four-potential]] is

:&lt;math&gt;A^{\mu}= \left ( \frac{\phi}{c}, \mathbf{A} \right )&lt;/math&gt;

with the [[Lorenz gauge condition]]:

:&lt;math&gt;\partial_{\mu} A^{\mu} = 0,&lt;/math&gt;

and where

:&lt;math&gt;-\Box = \nabla^2 - \frac{1}{c^2} \frac{\partial^2}{\partial t^2}&lt;/math&gt;

is the [[d'Alembert operator]].

==Homogeneous wave equation in curved spacetime==
{{main|Maxwell's equations in curved spacetime}}

The electromagnetic wave equation is modified in two ways, the derivative is replaced with the [[covariant derivative]] and a new term that depends on the curvature appears.

:&lt;math&gt; -{A^{\alpha ; \beta}}_{; \beta} + {R^{\alpha}}_{\beta} A^{\beta} = 0 &lt;/math&gt;

where &lt;math&gt; \scriptstyle {R^\alpha}_\beta &lt;/math&gt; is the [[Ricci curvature tensor]] and the semicolon indicates covariant differentiation.

The generalization of the [[Lorenz gauge condition]] in curved spacetime is assumed:

:&lt;math&gt; {A^\mu}_{; \mu} = 0. &lt;/math&gt;

==Inhomogeneous electromagnetic wave equation==
{{main| Inhomogeneous electromagnetic wave equation }}

Localized time-varying charge and current densities can act as sources of electromagnetic waves in a vacuum. Maxwell's equations can be written in the form of a wave equation with sources. The addition of sources to the wave equations makes the [[partial differential equations]] inhomogeneous.

== Solutions to the homogeneous electromagnetic wave equation ==
&lt;!-- [[Thumb right|This 3D diagram shows a plane linearly polarized wave propagating from left to right with the same wave equations where {{math|'''E''' {{=}} ''E''&lt;sub&gt;0&lt;/sub&gt; sin(-''ωt'' + '''k''' ⋅ '''r''')}} and {{math|'''B''' {{=}} ''B''&lt;sub&gt;0&lt;/sub&gt; sin(-''ωt'' + '''k''' ⋅ '''r''')}}]] --&gt;

{{main|Wave equation }}
The general solution to the electromagnetic wave equation is a [[Superposition principle|linear superposition]] of waves of the form

:&lt;math&gt; \mathbf{E}( \mathbf{r}, t ) = g(\phi( \mathbf{r}, t )) = g( \omega t - \mathbf{k} \cdot \mathbf{r} ) &lt;/math&gt;
:&lt;math&gt; \mathbf{B}( \mathbf{r}, t ) = g(\phi( \mathbf{r}, t )) = g( \omega t - \mathbf{k} \cdot \mathbf{r} ) &lt;/math&gt;

for virtually ''any'' well-behaved function {{mvar|g}} of dimensionless argument {{mvar|φ}}, where {{mvar|ω}} is the [[angular frequency]] (in radians per second), and {{math|'''k''' {{=}} (''k&lt;sub&gt;x&lt;/sub&gt;'', ''k&lt;sub&gt;y&lt;/sub&gt;'', ''k&lt;sub&gt;z&lt;/sub&gt;'')}} is the [[wave vector]] (in radians per meter).

Although the function {{mvar|g}} can be and often is a monochromatic [[sine wave]], it does not have to be sinusoidal, or even periodic. In practice, {{mvar|g}} cannot have infinite periodicity because any real electromagnetic wave must always have a finite extent in time and space. As a result, and based on the theory of [[Fourier transform|Fourier decomposition]], a real wave must consist of the superposition of an infinite set of sinusoidal frequencies.

In addition, for a valid solution, the wave vector and the angular frequency are not independent; they must adhere to the [[dispersion relation]]:

:&lt;math&gt; k = | \mathbf{k} | = { \omega \over c } =  { 2 \pi \over \lambda } &lt;/math&gt;

where {{mvar|k}} is the [[wavenumber]] and {{mvar|λ}} is the [[wavelength]]. The variable {{mvar|c}} can only be used in this equation when the electromagnetic wave is in a vacuum.

===Monochromatic, sinusoidal steady-state===
The simplest set of solutions to the wave equation result from assuming sinusoidal waveforms of a single frequency in separable form:

:&lt;math&gt;\mathbf{E} ( \mathbf{r}, t ) = \Re \left \{ \mathbf{E}(\mathbf{r}) e^{i \omega t} \right \}&lt;/math&gt;

where
:{{mvar|i}} is the [[imaginary unit]],
:{{math|''ω'' {{=}} 2''π''&amp;thinsp;''f''&amp;thinsp;}} is the [[angular frequency]] in [[radians per second]],
:{{math|&amp;thinsp;''f''&amp;thinsp;}} is the''' [[frequency]] in [[hertz]], and
:&lt;math&gt; \scriptstyle e^{i \omega t} = \cos(\omega t) + i \sin(\omega t)&lt;/math&gt; is [[Euler's formula]].

===Plane wave solutions===
{{main|Sinusoidal plane-wave solutions of the electromagnetic wave equation}}
Consider a plane defined by a unit normal vector 

:&lt;math&gt; \mathbf{n} = { \mathbf{k} \over k }. &lt;/math&gt;

Then planar traveling wave solutions of the wave equations are

:&lt;math&gt; \mathbf{E}(\mathbf{r}) = \mathbf{E}_0 e^{ -i \mathbf{k} \cdot \mathbf{r} } &lt;/math&gt;
:&lt;math&gt; \mathbf{B}(\mathbf{r}) = \mathbf{B}_0 e^{ -i \mathbf{k} \cdot \mathbf{r} } &lt;/math&gt;

where {{math|'''r''' {{=}} (''x'', ''y'', ''z'')}} is the position vector (in meters).

These solutions represent planar waves traveling in the direction of the normal vector {{math|'''n'''}}.  If we define the z direction as the direction of {{math|'''n'''}}. and the x direction as the direction of {{math|'''E'''}}, then by Faraday's Law the magnetic field lies in the y direction and is related to the electric field by the relation 

:&lt;math&gt;c^2{\partial B \over \partial z} = {\partial E \over \partial t}.&lt;/math&gt;

Because the divergence of the electric and magnetic fields are zero, there are no fields in the direction of propagation.

This solution is the linearly [[polarization (waves)|polarized]] solution of the wave equations. There are also circularly polarized solutions in which the fields rotate about the normal vector.

===Spectral decomposition===
Because of the linearity of Maxwell's equations in a vacuum, solutions can be decomposed into a superposition of [[sine|sinusoids]]. This is the basis for the [[Fourier transform]] method for the solution of differential equations. The sinusoidal solution to the electromagnetic wave equation takes the form

:&lt;math&gt; \mathbf{E} ( \mathbf{r}, t ) = \mathbf{E}_0 \cos( \omega t - \mathbf{k} \cdot \mathbf{r} + \phi_0 ) &lt;/math&gt;
:&lt;math&gt; \mathbf{B} ( \mathbf{r}, t ) = \mathbf{B}_0 \cos( \omega t - \mathbf{k} \cdot \mathbf{r} + \phi_0 ) &lt;/math&gt;

where
:{{mvar|t}} is time (in seconds),
:{{mvar|ω}} is the [[angular frequency]] (in radians per second),
:{{math|'''k''' {{=}} (''k&lt;sub&gt;x&lt;/sub&gt;'', ''k&lt;sub&gt;y&lt;/sub&gt;'', ''k&lt;sub&gt;z&lt;/sub&gt;'')}} is the [[wave vector]] (in radians per meter), and
:&lt;math&gt; \scriptstyle \phi_0 &lt;/math&gt; is the [[phase angle]] (in radians).
The wave vector is related to the angular frequency by

:&lt;math&gt; k = | \mathbf{k} | = { \omega \over c } =  { 2 \pi \over \lambda } &lt;/math&gt;

where {{mvar|k}} is the [[wavenumber]] and {{mvar|λ}} is the [[wavelength]].

The [[electromagnetic spectrum]] is a plot of the field magnitudes (or energies) as a function of wavelength.

===Multipole expansion===
Assuming monochromatic fields varying in time as &lt;math&gt;e^{-i \omega t}&lt;/math&gt;, if one uses Maxwell's Equations to eliminate {{math|'''B'''}}, the electromagnetic wave equation reduces to the [[Helmholtz Equation]] for {{math|'''E'''}}:

:&lt;math&gt; (\nabla^2 + k^2)\mathbf{E} = 0,\, \mathbf{B} = -\frac{i}{k} \nabla \times \mathbf{E},&lt;/math&gt;

with ''k = &amp;omega;/c'' as given above. Alternatively, one can eliminate {{math|'''E'''}} in favor of {{math|'''B'''}} to obtain:

:&lt;math&gt; (\nabla^2 + k^2)\mathbf{B} = 0,\, \mathbf{E} = -\frac{i}{k} \nabla \times \mathbf{B}.&lt;/math&gt;

A generic electromagnetic field with frequency {{mvar|ω}} can be written as a sum of solutions to these two equations. The [[Helmholtz equation#Three-dimensional solutions|three-dimensional solutions of the Helmholtz Equation]] can be expressed as expansions in [[spherical harmonics]] with coefficients proportional to the [[spherical Bessel functions]]. However, applying this expansion to each vector component of {{math|'''E'''}} or {{math|'''B'''}} will give solutions that are not generically divergence-free ({{math|'''∇''' · '''E''' {{=}} '''∇''' · '''B''' {{=}} 0}}), and therefore require additional restrictions on the coefficients.

The multipole expansion circumvents this difficulty by expanding not {{math|'''E'''}} or {{math|'''B'''}}, but {{math|'''r · E'''}} or {{math|'''r · B'''}} into spherical harmonics. These expansions still solve the original Helmholtz equations for {{math|'''E'''}} and {{math|'''B'''}} because for a divergence-free field {{math|'''F'''}}, {{math|∇&lt;sup&gt;2&lt;/sup&gt; ('''r · F''') {{=}} '''r ·''' (∇&lt;sup&gt;2&lt;/sup&gt; '''F''')}}. The resulting expressions for a generic electromagnetic field are:

:&lt;math&gt;\mathbf{E} = e^{-i \omega t} \sum_{l,m} \sqrt{l(l+1)} \left[ a_E(l,m) \mathbf{E}_{l,m}^{(E)} + a_M(l,m) \mathbf{E}_{l,m}^{(M)} \right]&lt;/math&gt;
:&lt;math&gt;\mathbf{B} = e^{-i \omega t} \sum_{l,m} \sqrt{l(l+1)} \left[ a_E(l,m) \mathbf{B}_{l,m}^{(E)} + a_M(l,m) \mathbf{B}_{l,m}^{(M)} \right]&lt;/math&gt;,

where &lt;math&gt;\mathbf{E}_{l,m}^{(E)}&lt;/math&gt; and &lt;math&gt;\mathbf{B}_{l,m}^{(E)}&lt;/math&gt; are the ''electric multipole fields of order (l, m)'', and &lt;math&gt;\mathbf{E}_{l,m}^{(M)}&lt;/math&gt; and &lt;math&gt;\mathbf{B}_{l,m}^{(M)}&lt;/math&gt; are the corresponding ''magnetic multipole fields'', and {{math|''a&lt;sub&gt;E&lt;/sub&gt;''(''l'', ''m'')}} and {{math|''a&lt;sub&gt;M&lt;/sub&gt;''(''l'', ''m'')}} are the coefficients of the expansion. The multipole fields are given by

:&lt;math&gt;\mathbf{B}_{l,m}^{(E)} = \sqrt{l(l+1)} \left[B_l^{(1)} h_l^{(1)}(kr) + B_l^{(2)} h_l^{(2)}(kr)\right] \mathbf{\Phi}_{l,m}&lt;/math&gt;
:&lt;math&gt;\mathbf{E}_{l,m}^{(E)} = \frac{i}{k} \nabla \times \mathbf{B}_{l,m}^{(E)}&lt;/math&gt;
:&lt;math&gt;\mathbf{E}_{l,m}^{(M)} = \sqrt{l(l+1)} \left[E_l^{(1)} h_l^{(1)}(kr) + E_l^{(2)} h_l^{(2)}(kr)\right] \mathbf{\Phi}_{l,m}&lt;/math&gt;
:&lt;math&gt;\mathbf{B}_{l,m}^{(M)} = -\frac{i}{k} \nabla \times \mathbf{E}_{l,m}^{(M)}&lt;/math&gt;,

where ''h&lt;sub&gt;l&lt;/sub&gt;&lt;sup&gt;(1,2)&lt;/sup&gt;(x)'' are the [[Spherical Bessel function#Spherical Hankel functions|spherical Hankel functions]], ''E&lt;sub&gt;l&lt;/sub&gt;&lt;sup&gt;(1,2)&lt;/sup&gt;'' and ''B&lt;sub&gt;l&lt;/sub&gt;&lt;sup&gt;(1,2)&lt;/sup&gt;'' are determined by boundary conditions, and 

:&lt;math&gt;\mathbf{\Phi}_{l,m} = \frac{1}{\sqrt{l(l+1)}}(\mathbf{r} \times \nabla) Y_{l,m}&lt;/math&gt; 

are [[vector spherical harmonics]] normalized so that

:&lt;math&gt;\int \mathbf{\Phi}^*_{l,m} \cdot \mathbf{\Phi}_{l', m'} d\Omega = \delta_{l,l'} \delta_{m, m'}.&lt;/math&gt;

The multipole expansion of the electromagnetic field finds application in a number of problems involving spherical symmetry, for example antennae [[radiation pattern]]s, or nuclear [[gamma decay]]. In these applications, one is often interested in the power radiated in the [[Near and far field#Radiation zone, including radiating far-field|far-field]]. In this regions, the {{math|'''E'''}} and {{math|'''B'''}} fields asymptote to

:&lt;math&gt;\mathbf{B} \approx \frac{e^{i (kr-\omega t)}}{kr} \sum_{l,m} (-i)^{l+1} \left[a_E(l,m) \mathbf{\Phi}_{l,m} + a_M(l,m) \mathbf{\hat{r}} \times \mathbf{\Phi}_{l,m} \right]&lt;/math&gt;
:&lt;math&gt;\mathbf{E} \approx \mathbf{B} \times \mathbf{\hat{r}}.&lt;/math&gt;

The angular distribution of the time-averaged radiated power is then given by

:&lt;math&gt;\frac{dP}{d\Omega} \approx \frac{1}{2k^2} \left| \sum_{l,m} (-i)^{l+1} \left[ a_E(l,m) \mathbf{\Phi}_{l,m} \times \mathbf{\hat{r}} + a_M(l,m) \mathbf{\Phi}_{l,m} \right] \right|^2.&lt;/math&gt;

==See also==

===Theory and experiment===
{{Col-begin}}
{{Col-break}}
* [[Maxwell's equations]]
* [[Wave equation]]
* [[Partial Differential Equations]]
* [[Electromagnetic modeling]]
* [[Electromagnetic radiation]]
* [[Charge conservation]]
* [[Light]]
* [[Electromagnetic spectrum]]
* [[Optics]]
{{Col-break}}
* [[Special relativity]]
* [[General relativity]]
* [[Inhomogeneous electromagnetic wave equation]]
* [[Photon polarization]]
* [[Larmor formula|Larmor power formula]]
* [[Theoretical and experimental justification for the Schrödinger equation]]
{{col-end}}

===Applications===
{{Col-begin}}
{{Col-break}}
* [[Rainbow]]
* [[Cosmic microwave background radiation]]
* [[Laser]]
* [[Laser fusion]]
* [[Photography]]
* [[X-ray]]
* [[X-ray crystallography]]
* [[Radar]]
{{Col-break}}
* [[Radio waves]]
* [[Optical computing]]
* [[Microwave]]
* [[Holography]]
* [[Microscope]]
* [[Telescope]]
* [[Gravitational lens]]
* [[Black body radiation]]
{{col-end}}

===Biographies===
{{Col-begin}}
{{Col-break}}
* [[André-Marie Ampère]]
* [[Albert Einstein]]
* [[Michael Faraday]]
* [[Heinrich Hertz]]
* [[Oliver Heaviside]]
* [[James Clerk Maxwell]]
{{col-end}}

==Notes==
&lt;references/&gt;

== Further reading ==

===Electromagnetism===

====Journal articles====
*  Maxwell, James Clerk, "''[[Media:A Dynamical Theory of the Electromagnetic Field.pdf|A Dynamical Theory of the Electromagnetic Field]]''", Philosophical Transactions of the Royal Society of London 155, 459-512 (1865). (This article accompanied a December 8, 1864 presentation by Maxwell to the Royal Society.)

====Undergraduate-level textbooks====
*{{cite book | author=Griffiths, David J.|title=Introduction to Electrodynamics (3rd ed.)| publisher=Prentice Hall |year=1998 |isbn=0-13-805326-X}}
*{{cite book | author=Tipler, Paul | title=Physics for Scientists and Engineers: Electricity, Magnetism, Light, and Elementary Modern Physics (5th ed.) | publisher=W. H. Freeman | year=2004 | isbn=0-7167-0810-8}}
* Edward M. Purcell, ''Electricity and Magnetism'' (McGraw-Hill, New York, 1985). {{ISBN|0-07-004908-4}}.
* Hermann A. Haus and James R. Melcher, ''Electromagnetic Fields and Energy'' (Prentice-Hall, 1989) {{ISBN|0-13-249020-X}}.
* Banesh Hoffmann, ''Relativity and Its Roots'' (Freeman, New York, 1983). {{ISBN|0-7167-1478-7}}.
* David H. Staelin, Ann W. Morgenthaler, and Jin Au Kong, ''Electromagnetic Waves'' (Prentice-Hall, 1994) {{ISBN|0-13-225871-4}}.
* Charles F. Stevens, ''The Six Core Theories of Modern Physics'', (MIT Press, 1995) {{ISBN|0-262-69188-4}}.
* Markus Zahn, ''Electromagnetic Field Theory: a problem solving approach'', (John Wiley &amp; Sons, 1979) {{ISBN|0-471-02198-9}}

====Graduate-level textbooks====
*{{cite book |author=Jackson, John D.|title=Classical Electrodynamics (3rd ed.)|publisher=Wiley|year=1998|isbn=0-471-30932-X}}
* [[Lev Davidovich Landau|Landau, L. D.]],  ''The Classical Theory of Fields'' ([[Course of Theoretical Physics]]: Volume 2),  (Butterworth-Heinemann: Oxford, 1987). {{ISBN|0-08-018176-7}}.
*{{cite book | author=Maxwell, James C. | title=A Treatise on Electricity and Magnetism | publisher=Dover | year=1954 | isbn=0-486-60637-6}}
* Charles W. Misner, [[Kip Thorne|Kip S. Thorne]], [[John Archibald Wheeler]], ''Gravitation'', (1970) W.H. Freeman, New York; {{ISBN|0-7167-0344-0}}. ''(Provides a treatment of Maxwell's equations in terms of differential forms.)''

===Vector calculus===
*P. C. Matthews ''Vector Calculus'', Springer 1998, {{ISBN|3-540-76180-2}}
*H. M. Schey, ''Div Grad Curl and all that:  An informal text on vector calculus'', 4th edition (W. W. Norton &amp; Company, 2005) {{ISBN|0-393-92516-1}}.

{{Physics-footer}}

[[Category:Electrodynamics]]
[[Category:Electromagnetic radiation]]
[[Category:Electromagnetism]]
[[Category:Partial differential equations]]
[[Category:Mathematical physics]]
[[Category:Equations of physics]]</text>
      <sha1>2a6fnjqfsl0bza1yj5a393zeuba7pob</sha1>
    </revision>
  </page>
  <page>
    <title>Finite thickness</title>
    <ns>0</ns>
    <id>1309542</id>
    <revision>
      <id>727832274</id>
      <parentid>727832218</parentid>
      <timestamp>2016-07-01T14:30:16Z</timestamp>
      <contributor>
        <username>Frietjes</username>
        <id>13791031</id>
      </contributor>
      <comment>/* The related notion of M-finite thickness */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3171">In [[formal language theory]], in particular in [[algorithmic learning theory]], a class ''C'' of [[formal language#Definition|languages]] has '''finite thickness''' if every string is contained in at most finitely many languages in ''C''. This condition was introduced by [[Dana Angluin]] as a [[sufficient condition]] for ''C'' being [[language identification in the limit#Finite thickness|identifiable in the limit]].
&lt;ref&gt;{{cite journal| author=Dana Angluin| title=Inductive Inference of Formal Languages from Positive Data| journal=Information and Control| year=1980| volume=45| issue=2| pages=117–135|url=http://www-personal.umich.edu/~yinw/papers/Angluin80.pdf| doi=10.1016/s0019-9958(80)90285-5}} ([http://citeseer.ist.psu.edu/context/14508/0 citeseer.ist.psu.edu]); here: Condition 3, p.123 mid. Angluin's original requirement (every non-empty string ''set'' be contained in at most finitely many languages) is equivalent.&lt;/ref&gt;

==The related notion of M-finite thickness==

Given a language ''L'' and an indexed class ''C'' = { ''L''&lt;sub&gt;1&lt;/sub&gt;, ''L''&lt;sub&gt;2&lt;/sub&gt;, ''L''&lt;sub&gt;3&lt;/sub&gt;, ... } of languages, a member language ''L''&lt;sub&gt;''j''&lt;/sub&gt; ∈ ''C'' is called a '''minimal concept''' of ''L'' within ''C'' if ''L'' ⊆ ''L''&lt;sub&gt;''j''&lt;/sub&gt;, but not ''L'' ⊊ ''L''&lt;sub&gt;''i''&lt;/sub&gt; ⊆ ''L''&lt;sub&gt;''j''&lt;/sub&gt; for any ''L''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''C''.&lt;ref&gt;{{cite book|author1=Andris Ambainis |author2=Sanjay Jain |author3=Arun Sharma | chapter=Ordinal mind change complexity of language identification| title=Computational Learning Theory| year=1997| volume=1208| pages=301–315| publisher=Springer| series=LNCS| url=http://www.comp.nus.edu.sg/~sanjay/paps/efs2.pdf}}; here: Definition 25&lt;/ref&gt;
The class ''C'' is said to satisfy the '''MEF-condition''' if every finite subset ''D'' of a member language ''L''&lt;sub&gt;''i''&lt;/sub&gt; ∈ ''C'' has a minimal concept ''L''&lt;sub&gt;''j''&lt;/sub&gt; ⊆ ''L''&lt;sub&gt;''i''&lt;/sub&gt;. Symmetrically, ''C'' is said to satisfy the '''MFF-condition''' if every nonempty finite set ''D'' has at most finitely many minimal concepts in ''C''. Finally, ''C'' is said to have '''M-finite thickness''' if it satisfies both the MEF- and the MFF-condition.
&lt;ref&gt;Ambainis et al. 1997, Definition 26&lt;/ref&gt;
&lt;!---commented-out former, unsourced definitions:---
We say that &lt;math&gt;\mathcal L&lt;/math&gt; satisfies the '''MEF-condition''' if for each string s and each consistent language L in the class, there is a minimal consistent language in &lt;math&gt;\mathcal L&lt;/math&gt;, which is a sublanguage of L. Symmetrically, we say that &lt;math&gt;\mathcal L&lt;/math&gt; satisfies the '''MFF-condition''' if for every string s there are only finitely many minimal consistent languages in &lt;math&gt;\mathcal L&lt;/math&gt;.
---&gt;

Finite thickness implies M-finite thickness.&lt;ref&gt;Ambainis et al. 1997, Corollary 29&lt;/ref&gt; However, there are classes that are of M-finite thickness but not of finite thickness (for example, any class of languages ''C'' = { ''L''&lt;sub&gt;1&lt;/sub&gt;, ''L''&lt;sub&gt;2&lt;/sub&gt;, ''L''&lt;sub&gt;3&lt;/sub&gt;, ... } such that ''L''&lt;sub&gt;1&lt;/sub&gt; ⊆ ''L''&lt;sub&gt;2&lt;/sub&gt; ⊆ ''L''&lt;sub&gt;3&lt;/sub&gt; ⊆  ...).

== References ==
{{reflist}}

[[Category:Formal languages]]


{{comp-sci-theory-stub}}</text>
      <sha1>08675rxivf0n0ne33lcnwb2e0lckkw8</sha1>
    </revision>
  </page>
  <page>
    <title>Five lemma</title>
    <ns>0</ns>
    <id>138214</id>
    <revision>
      <id>871050996</id>
      <parentid>821908867</parentid>
      <timestamp>2018-11-28T16:41:31Z</timestamp>
      <contributor>
        <ip>2A01:CB1D:1CC:3700:C066:B37F:70A6:12AC</ip>
      </contributor>
      <comment>/* Proof */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6745">In [[mathematics]], especially [[homological algebra]] and other applications of [[abelian category]] theory, the '''five lemma''' is an important and widely used [[lemma (mathematics)|lemma]] about [[commutative diagram]]s.
The five lemma is not only valid for abelian categories but also works in the [[category of groups]], for example.

The five lemma can be thought of as a combination of two other theorems, the '''four lemmas''', which are [[duality (category theory)|dual]] to each other.

==Statements==
Consider the following [[commutative diagram]] in any [[abelian category]] (such as the category of [[abelian group]]s or the category of [[vector space]]s over a given [[field (algebra)|field]]) or in the category of [[group (mathematics)|group]]s.

[[file:5 lemma.svg]]

The five lemma states that, if the rows are [[exact sequence|exact]], ''m'' and ''p'' are [[isomorphism]]s, ''l'' is an [[epimorphism]], and ''q'' is a [[monomorphism]], then ''n'' is also an isomorphism.

The two four-lemmas state:&lt;br&gt;
'''(1)''' If the rows in the commutative diagram

[[file:4 lemma right.svg]]

are exact and ''m'' and ''p'' are epimorphisms and ''q'' is a monomorphism, then ''n'' is an epimorphism.

'''(2)''' If the rows in the commutative diagram

[[file:4 lemma left.svg]]

are exact and ''m'' and ''p'' are monomorphisms and ''l'' is an epimorphism, then ''n'' is a monomorphism.

==Proof==
The method of proof we shall use is commonly referred to as [[diagram chasing]].&lt;ref&gt;{{cite book|author=Massey |title=A basic course in algebraic topology|year=1991|url={{Google books|plainurl=y|id=svbU9nxi2xQC|page=184|text=diagram chasing}}|page=184}}&lt;/ref&gt;  We shall prove the five lemma by individually proving each of the two four lemmas.

To perform diagram chasing, we assume that we are in a category of [[module (mathematics)|modules]] over some [[ring (mathematics)|ring]], so that we may speak of ''elements'' of the objects in the diagram and think of the morphisms of the diagram as ''[[function (mathematics)|function]]s'' (in fact, [[homomorphism]]s) acting on those elements.
Then a morphism is a monomorphism [[if and only if]] it is [[injective]], and it is an epimorphism if and only if it is [[surjective]].
Similarly, to deal with exactness, we can think of [[kernel (algebra)|kernel]]s and [[image (function)|image]]s in a function-theoretic sense.
The proof will still apply to any (small) abelian category because of [[Mitchell's embedding theorem]], which states that any small abelian category can be represented as a category of modules over some ring.
For the category of groups, just turn all additive notation below into multiplicative notation, and note that commutativity of abelian group is never used.

So, to prove (1), assume that ''m'' and ''p'' are surjective and ''q'' is injective.
[[File:Four lemma epic and zero.gif|thumb|500x500px|A proof of (1) in the case where &lt;math&gt;t(c')=0&lt;/math&gt;.]]
[[File:Four lemma epic nonzero case.gif|thumb|500x500px|A proof of (1) in the case where &lt;math&gt;t(c')\neq 0&lt;/math&gt;.]]
:[[file:4 lemma right.svg]]
* Let ''c&amp;prime;'' be an element of ''C&amp;prime;''.
* Since ''p'' is surjective, there exists an element ''d'' in ''D'' with ''p''(''d'') =  ''t''(''c&amp;prime;'').
* By commutativity of the diagram, ''u''(''p''(''d'')) = ''q''(''j''(''d'')).
* Since im ''t'' = ker ''u'' by exactness, 0 = ''u''(''t''(''c&amp;prime;'')) = ''u''(''p''(''d'')) = ''q''(''j''(''d'')).
* Since ''q'' is injective, ''j''(''d'') = 0, so ''d'' is in ker ''j'' = im ''h''.
* Therefore, there exists ''c'' in ''C'' with ''h''(''c'') = ''d''.
* Then ''t''(''n''(''c'')) = ''p''(''h''(''c'')) = ''t''(''c&amp;prime;'').  Since ''t'' is a homomorphism, it follows that ''t''(''c&amp;prime;'' &amp;minus; ''n''(''c'')) = 0.
* By exactness, ''c&amp;prime;'' &amp;minus; ''n''(''c'') is in the image of ''s'', so there exists ''b&amp;prime;'' in ''B&amp;prime;'' with ''s''(''b&amp;prime;'') = ''c&amp;prime;'' &amp;minus; ''n''(''c'').
* Since ''m'' is surjective, we can find ''b'' in ''B'' such that ''b&amp;prime;'' = ''m''(''b'').
* By commutativity, ''n''(''g''(''b'')) = ''s''(''m''(''b'')) = ''c&amp;prime;'' &amp;minus; ''n''(''c'').
* Since ''n'' is a homomorphism, ''n''(''g''(''b'') + ''c'') = ''n''(''g''(''b'')) + ''n''(''c'') = ''c&amp;prime;'' &amp;minus; ''n''(''c'') + ''n''(''c'') = ''c&amp;prime;''.
* Therefore, ''n'' is surjective.

Then, to prove (2), assume that ''m'' and ''p'' are injective and {{math|size=100%|1=''l''}} is surjective.
[[File:Four lemma monic case.gif|thumb|500x500px|A proof of (2).]]
:[[file:4 lemma left.svg]]
* Let ''c'' in ''C'' be such that ''n''(''c'') = 0.
* ''t''(''n''(''c'')) is then 0.
* By commutativity, ''p''(''h''(''c'')) = 0.
* Since ''p'' is injective, ''h''(''c'') = 0.
* By exactness, there is an element ''b'' of ''B'' such that ''g''(''b'') = ''c''.
* By commutativity, ''s''(''m''(''b'')) = ''n''(''g''(''b'')) = ''n''(''c'') = 0.
* By exactness, there is then an element ''a&amp;prime;'' of ''A&amp;prime;'' such that ''r''(''a&amp;prime;'') = ''m''(''b'').
* Since {{math|size=100%|1=''l''}} is surjective, there is ''a'' in ''A'' such that {{math|size=100%|1=''l''(''a'') = ''a&amp;prime;''}}.
* By commutativity, {{math|size=100%|1=''m''(''f''(''a'')) = ''r''(''l''(''a'')) = ''m''(''b'')}}.
* Since ''m'' is injective, ''f''(''a'') = ''b''.
* So ''c'' = ''g''(''f''(''a'')).
* Since the composition of ''g'' and ''f'' is trivial, ''c'' = 0.
* Therefore, ''n'' is injective.

Combining the two four lemmas now proves the entire five lemma.

==Applications==
The five lemma is often applied to [[long exact sequence]]s: when computing [[homology (mathematics)|homology]] or cohomology of a given object, one typically employs a simpler subobject whose homology/cohomology is known, and arrives at a long exact sequence which involves the unknown homology groups of the original object. This alone is often not sufficient to determine the unknown homology groups, but if one can compare the original object and sub object to well-understood ones via morphisms, then a morphism between the respective long exact sequences is induced, and the five lemma can then be used to determine the unknown homology groups.

==See also==
*[[Short five lemma]], a special case of the five lemma for [[short exact sequence]]s
*[[Snake lemma]], another lemma proved by diagram chasing
*[[Nine lemma]]

==Notes==
{{Reflist}}

==References==
* W. R. Scott: ''Group Theory'', Prentice Hall, 1964.
* {{Citation| last=Massey| first=William S.| author-link=William S. Massey| date=1991| title=A basic course in algebraic topology| edition=3rd| volume = 127 | series=Graduate texts in mathematics | publisher=Springer | isbn = 978-0-387-97430-9}}

[[Category:Homological algebra]]
[[Category:Lemmas]]
[[Category:Articles containing proofs]]</text>
      <sha1>gv79kobnformg3z3kvsnr6kybaegp7a</sha1>
    </revision>
  </page>
  <page>
    <title>Free Poisson distribution</title>
    <ns>0</ns>
    <id>25116039</id>
    <revision>
      <id>794362538</id>
      <parentid>794361883</parentid>
      <timestamp>2017-08-07T14:58:20Z</timestamp>
      <contributor>
        <ip>37.230.25.253</ip>
      </contributor>
      <comment>I switched Cauchy transform and Stieltjes transformation, in accordance with the reference.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2987">{{expert|Probability|date=November 2009}}

In the mathematics of [[free probability]] theory, the '''free Poisson distribution''' is a counterpart of the [[Poisson distribution]] in conventional probability theory.

==Definition==
The free Poisson distribution&lt;ref&gt;Free Random Variables by D. Voiculescu, K. Dykema, A. Nica,  CRM Monograph Series, American Mathematical Society, Providence RI, 1992&lt;/ref&gt; with jump size &lt;math&gt;\alpha&lt;/math&gt; and rate &lt;math&gt;\lambda&lt;/math&gt; arises in [[free probability]] theory as the limit of repeated [[free convolution]]

: &lt;math&gt;
\left( \left(1-\frac{\lambda}{N}\right)\delta_0 + \frac{\lambda}{N}\delta_\alpha\right)^{\boxplus N}&lt;/math&gt;

as ''N''&amp;nbsp;→&amp;nbsp;∞.

In other words, let &lt;math&gt;X_N&lt;/math&gt; be random variables so that &lt;math&gt;X_N&lt;/math&gt; has value &lt;math&gt;\alpha&lt;/math&gt; with probability &lt;math&gt;\frac{\lambda}{N}&lt;/math&gt; and value 0 with the remaining probability.  Assume also that the family &lt;math&gt;X_1,X_2,\ldots&lt;/math&gt; are [[free independence|freely independent]].  Then the limit as &lt;math&gt;N\to\infty&lt;/math&gt; of the law of &lt;math&gt;X_1+\cdots +X_N&lt;/math&gt;
is given by the Free Poisson law with parameters &lt;math&gt;\lambda,\alpha&lt;/math&gt;.

This definition is analogous to one of the ways in which the classical [[Poisson distribution]] is obtained from a (classical) Poisson process. 

The measure associated to the free Poisson law is given by&lt;ref&gt;James A. Mingo, Roland Speicher: Free Probability and Random Matrices. Fields Institute Monographs, Vol. 35, Springer, New York, 2017.&lt;/ref&gt;

:&lt;math&gt;\mu=\begin{cases} (1-\lambda) \delta_0 + \nu,&amp; \text{if }  0\leq \lambda \leq 1 \\
\nu, &amp; \text{if }\lambda &gt;1,
\end{cases}
&lt;/math&gt;

where

: &lt;math&gt;\nu  = \frac{1}{2\pi\alpha t}\sqrt{4\lambda \alpha^2 - ( t - \alpha (1+\lambda))^2} \, dt&lt;/math&gt;

and has support &lt;math&gt;[\alpha (1-\sqrt{\lambda})^2,\alpha (1+\sqrt{\lambda})^2]&lt;/math&gt;.

This law also arises in [[random matrix]] theory as the [[Marchenko&amp;ndash;Pastur law]]. Its [[free cumulants]] are equal to &lt;math&gt;\kappa_n=\lambda\alpha^n&lt;/math&gt;.

==Some transforms of this law==
We give values of some important transforms of the free Poisson law; the computation can be found in e.g. in the book ''Lectures on the Combinatorics of Free Probability'' by A. Nica and R. Speicher&lt;ref&gt;Lectures on the Combinatorics of Free Probability by A. Nica and R. Speicher, pp. 203&amp;ndash;204, Cambridge Univ. Press 2006&lt;/ref&gt;

The [[R-transform]] of the free Poisson law is given by

: &lt;math&gt;R(z)=\frac{\lambda \alpha}{1-\alpha z}. &lt;/math&gt;

The [[Cauchy transform]] (which is the negative of the [[Stieltjes transformation]]) is given by

: &lt;math&gt;
G(z) = \frac{ z + \alpha - \lambda \alpha - \sqrt{ (z-\alpha (1+\lambda))^2 - 4 \lambda \alpha^2}}{2\alpha z}
&lt;/math&gt;

The [[S-transform]] is given by

: &lt;math&gt;
S(z) = \frac{1}{z+\lambda}
&lt;/math&gt;

in the case that &lt;math&gt;\alpha=1&lt;/math&gt;.

==References==
{{Reflist}}

[[Category:Poisson distribution]]
[[Category:Functional analysis]]
[[Category:Free probability theory]]</text>
      <sha1>sluahwak4i7qsrgzigsnsmw901vbs09</sha1>
    </revision>
  </page>
  <page>
    <title>Fuzzy extractor</title>
    <ns>0</ns>
    <id>35690430</id>
    <revision>
      <id>862192777</id>
      <parentid>849504565</parentid>
      <timestamp>2018-10-02T19:16:27Z</timestamp>
      <contributor>
        <ip>131.155.229.97</ip>
      </contributor>
      <comment>/* Lemma 1 (fuzzy extractors from sketches) */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27367">{{multiple issues|{{technical|date=January 2014}}
{{inline|date=January 2018}}}}
'''Fuzzy extractors''' are a method that allows to use [[Biometrics|biometric]] data as inputs to standard [[Cryptography|cryptographic]] techniques for biometric security.  "Fuzzy", in this context, refers to the fact that the fixed values required for [[cryptography]] will be extracted from values close but not identical to the original one, without compromising the security required. One application is to [[Encryption|encrypt]] and [[Authentication|authenticate]] users records, using the biometric inputs of the user as a key.

Fuzzy extractors are a biometric tool that allows to authenticate a user using for the key a biometric template constructed from his biometric data.  They extract a uniform and random string &lt;math&gt; R &lt;/math&gt; from an input &lt;math&gt; w &lt;/math&gt; with a tolerance for noise.  If the input changes to &lt;math&gt; w' &lt;/math&gt; but is still close to &lt;math&gt; w &lt;/math&gt;, the same string &lt;math&gt; R &lt;/math&gt; will be re-constructed.  To achieve this, during the initial computation of &lt;math&gt; R &lt;/math&gt; the process also outputs a helper string &lt;math&gt; P &lt;/math&gt;which will be stored to recover &lt;math&gt; R &lt;/math&gt; later and can be made public without compromising the security of &lt;math&gt; R &lt;/math&gt;.  The security of the process is ensured also when an adversary modifies &lt;math&gt; P &lt;/math&gt;. Once the fixed string &lt;math&gt; R &lt;/math&gt;has been calculated, it can be used for example for key agreement between a user and a server based only on a biometric input.

Historically, the first biometric system of this kind was designed by Juels and Wattenberg and was called "Fuzzy commitment", where the cryptographic key is decommitted using biometric data. Later, Juels and [[Madhu Sudan|Sudan]] came up with [https://wiki.cse.buffalo.edu/cse545/content/fuzzy-vault Fuzzy vault] schemes which are order invariant for the fuzzy commitment scheme but uses a [[Reed–Solomon error correction|Reed–Solomon]] [[code]].  Codeword is evaluated by [[polynomial]] and the secret message is inserted as the coefficients of the polynomial. The polynomial is evaluated for different values of a set of features of the biometric data.  So Fuzzy commitment and Fuzzy Vault were precursors to Fuzzy extractors.

This description is based on the papers "[http://www.cs.bu.edu/~reyzin/fuzzysurvey.html Fuzzy Extractors: A Brief Survey of Results from 2004 to 2006]" and "[http://www.cs.ucla.edu/~rafail/PUBLIC/89.pdf Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data]" by Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin and Adam Smith

==Motivation==
In order for fuzzy extractors to generate strong keys from Biometrics and other Noisy Data, [[cryptography]] paradigms will be applied to this biometric data which means they must be allow to 

(1) Limit the number of assumptions required about the content of the biometric data (these data comes from a variety of sources and in order to avoid an adversary to exploit them, it's best to assume the input is unpredictable) 

(2) Apply usual cryptographic techniques from the input. (for this fuzzy extractors convert biometric data into  secret, uniformly random and reliably reproducible random string).

The paper "[http://www.cs.ucla.edu/~rafail/PUBLIC/89.pdf Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data]" by Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin and Adam Smith shows that these techniques can also have other broader applications for other type of noisy inputs such as approximative data from human [[memory]], images used as passwords, keys from quantum channel.  According to the [[Differential privacy|Differential Privacy]] paper by Cynthia Dwork (ICALP 2006), fuzzy extractors also have applications in the [[proof of impossibility]] of the strong notions of privacy for statistical databases.

== Basic definitions==
===Predictability===
Predictability indicates the probability that adversary can guess a secret key.  Mathematically speaking, the predictability of a random variable &lt;math&gt; A &lt;/math&gt; is &lt;math&gt;\max_{\mathrm{a}}P[A = a]&lt;/math&gt;.

For example, given a pair of random variable &lt;math&gt; A &lt;/math&gt; and &lt;math&gt; B &lt;/math&gt;, if the adversary knows &lt;math&gt; b &lt;/math&gt; of &lt;math&gt; B &lt;/math&gt;, then the predictability of &lt;math&gt; A &lt;/math&gt; will be &lt;math&gt;\max_{\mathrm{a}}P[A = a | B = b]&lt;/math&gt;.  So, an adversary can predict &lt;math&gt; A &lt;/math&gt; with  &lt;math&gt; E_{b \leftarrow B}[\max_{\mathrm{a}} P[A = a | B = b]]&lt;/math&gt;.  We use the average over &lt;math&gt; B &lt;/math&gt; as it is not under adversary control, but since knowing &lt;math&gt; b &lt;/math&gt; makes the prediction of &lt;math&gt; A &lt;/math&gt; adversarial, we take the worst case over &lt;math&gt; A &lt;/math&gt;.

===Min-entropy===
[[Min-entropy]] indicates the worst-case entropy.  Mathematically speaking, it is defined as &lt;math&gt;H_\infty(A)  = - \log(\max_{\mathrm{a}}P[A = a])&lt;/math&gt; .

A random variable with a min-entropy at least of &lt;math&gt; m &lt;/math&gt; is called a &lt;math&gt; m &lt;/math&gt;-source.

===Statistical distance===
[[Statistical distance]] is a measure of distinguishability.  Mathematically speaking, it is expressed for two probability distributions &lt;math&gt; A &lt;/math&gt; and &lt;math&gt; B &lt;/math&gt; as &lt;math&gt; SD[A,B] &lt;/math&gt; = &lt;math&gt;\frac{1}{2}\sum_{\mathrm{v}} | P[A  = v] - P[B = v] |&lt;/math&gt;.  In any system, if &lt;math&gt; A &lt;/math&gt; is replaced by &lt;math&gt; B &lt;/math&gt;, it will behave as the original system with a probability at least of &lt;math&gt; 1 - SD[A,B] &lt;/math&gt;.

===Definition 1 (strong extractor)===
Setting &lt;math&gt;  M &lt;/math&gt; as a [[Randomness extractor|strong randomness extractor]]. The randomized function Ext:  &lt;math&gt;M \rightarrow \{0,1\}^l&lt;/math&gt; with randomness of length &lt;math&gt; r&lt;/math&gt; is a &lt;math&gt;(m,l,\epsilon)&lt;/math&gt; strong extractor if for all &lt;math&gt; m &lt;/math&gt;-sources &lt;math&gt; W &lt;/math&gt; on &lt;math&gt; M (Ext(W;I), I) \approx_\epsilon (U_l, U_r), &lt;/math&gt; where &lt;math&gt; I = U_r &lt;/math&gt; is independent of &lt;math&gt; W &lt;/math&gt;.  

The output of the extractor is a key generated from &lt;math&gt; w \leftarrow W&lt;/math&gt; with the seed  &lt;math&gt; i \leftarrow I  &lt;/math&gt;.   It behaves independently of other parts of the system with the probability of &lt;math&gt;1 - \epsilon  &lt;/math&gt;.  Strong extractors can extract at most  &lt;math&gt; l = m - 2 log \frac {1} {\epsilon} + O(1) &lt;/math&gt; bits from an arbitrary &lt;math&gt;m&lt;/math&gt;-source.

===Secure sketch===
Secure sketch makes it possible to reconstruct noisy input, so that if the input is &lt;math&gt; w &lt;/math&gt; and the sketch is &lt;math&gt; s &lt;/math&gt;, given &lt;math&gt; s &lt;/math&gt; and a value &lt;math&gt; w' &lt;/math&gt;close to &lt;math&gt; w &lt;/math&gt;, &lt;math&gt; w &lt;/math&gt; can be recovered.  But the sketch &lt;math&gt; s &lt;/math&gt; must not reveal information about &lt;math&gt; w &lt;/math&gt;, in order to keep it secure.

If &lt;math&gt; \mathbb{M} &lt;/math&gt; is a metric space with the distance function dis, Secure sketch recovers the string &lt;math&gt; w  \in \mathbb{M} &lt;/math&gt; from any close string &lt;math&gt; w' \in \mathbb{M} &lt;/math&gt; without disclosing &lt;math&gt; w &lt;/math&gt;.

===Definition 2 (secure sketch)===
An &lt;math&gt; (m,\tilde{m},t) &lt;/math&gt; secure sketch is a pair of efficient randomized procedures (the Sketch noted SS, the Recover noted Rec)  such that : 

(1) The sketching procedure SS applied on input &lt;math&gt; w \in \mathbb{M} &lt;/math&gt; returns a string &lt;math&gt; s \in {\{0,1\}^*} &lt;/math&gt;.

The recovery procedure Rec uses as input two elements &lt;math&gt; w' \in \mathbb{M}&lt;/math&gt; and &lt;math&gt;s \in {\{0,1\}^*} &lt;/math&gt;.

(2) Correctness:  If  &lt;math&gt; dis(w,w') \leq  t &lt;/math&gt; then &lt;math&gt; Rec(w',SS(w)) = w &lt;/math&gt;.

(3) Security:  For any &lt;math&gt; m &lt;/math&gt;-source over &lt;math&gt; M &lt;/math&gt;, the min-entropy of &lt;math&gt; W &lt;/math&gt; given &lt;math&gt; s &lt;/math&gt; is high: 

for any &lt;math&gt; (W,E) &lt;/math&gt;, if &lt;math&gt;\tilde{H}_{\mathrm{\infty}}(W|E) \geq m &lt;/math&gt;, then &lt;math&gt;\tilde{H}_{\mathrm{\infty}}(W|SS(W),E) \geq \tilde{m} &lt;/math&gt;.

===Fuzzy extractor===
Fuzzy extractors do not recover the original input but generate a string &lt;math&gt; R &lt;/math&gt; (which is close to uniform) from &lt;math&gt; w &lt;/math&gt; and allow its subsequent reproduction (using helper string &lt;math&gt; P &lt;/math&gt;) given any &lt;math&gt; w' &lt;/math&gt; close to &lt;math&gt; w &lt;/math&gt;.  Strong extractors are a special case of fuzzy extractors when &lt;math&gt; t &lt;/math&gt; = 0 and &lt;math&gt; P = I &lt;/math&gt;.

===Definition 3 (fuzzy extractor)===
An  &lt;math&gt; (m,l, t, \epsilon) &lt;/math&gt; fuzzy extractor is a pair of efficient randomized procedures (Gen – Generate and Rep – Reproduce) such that:

(1) Gen, given &lt;math&gt; w \in \mathbb{M} &lt;/math&gt;, outputs an extracted string &lt;math&gt; R \in {\mathbb\{0,1\}^l} &lt;/math&gt; and a helper string &lt;math&gt; P \in {\mathbb\{0,1\}^*} &lt;/math&gt;.

(2) Correctness: If   &lt;math&gt; dis(w,w') \leq  t&lt;/math&gt; and &lt;math&gt;(R,P) \leftarrow Gen(w)  &lt;/math&gt;, then &lt;math&gt; Rep(w',P) = R &lt;/math&gt;.

(3) Security: For all m-sources &lt;math&gt; W &lt;/math&gt; over &lt;math&gt; M &lt;/math&gt;, the string &lt;math&gt; R &lt;/math&gt; is nearly uniform even given &lt;math&gt; P &lt;/math&gt;, So  &lt;math&gt;\tilde{H}_{\mathrm{\infty}}(W|E) \geq m&lt;/math&gt;, then &lt;math&gt;(R,P,E) \approx ( U_{\mathrm{l}}, P, E) &lt;/math&gt;.

So Fuzzy extractors output almost uniform random sequences of bits which are a prerequisite for using cryptographic applications (as secret keys).  Since the output bits are slightly non-uniform, there's a risk of a decreased security,  but the distance from an uniform distribution is no more than &lt;math&gt; \epsilon &lt;/math&gt; and as long as this distance is sufficiently small, the security will remains adequate.

===Secure sketches and fuzzy extractors===
Secure sketches can be used to construct fuzzy extractors.  Like applying SS to &lt;math&gt; w &lt;/math&gt; to obtain &lt;math&gt; s &lt;/math&gt; and strong extractor Ext with randomness &lt;math&gt; x &lt;/math&gt; to &lt;math&gt; w &lt;/math&gt; to get &lt;math&gt; R &lt;/math&gt;.  &lt;math&gt; (s,x) &lt;/math&gt; can be stored as helper string &lt;math&gt; P &lt;/math&gt;.  &lt;math&gt; R &lt;/math&gt; can be reproduced by &lt;math&gt; w' &lt;/math&gt; and &lt;math&gt; P = (s,x) &lt;/math&gt;.  &lt;math&gt; Rec (w',s) &lt;/math&gt; can recover &lt;math&gt; w &lt;/math&gt; and &lt;math&gt; Ext(w,x) &lt;/math&gt; can reproduce &lt;math&gt; R &lt;/math&gt;.
Following Lemma formalize this.

===Lemma 1 (fuzzy extractors from sketches)===
Assume (SS,Rec) is an &lt;math&gt; (M,m,\tilde{m},t) &lt;/math&gt; secure sketch and let Ext be an average-case &lt;math&gt; (n,\tilde{m},l,\epsilon) &lt;/math&gt; strong extractor.  Then the following (Gen, Rep) is an &lt;math&gt; (M,m,l,t,\epsilon) &lt;/math&gt; fuzzy extractor:
(1) Gen &lt;math&gt; (w,r,x)&lt;/math&gt;: set &lt;math&gt;P = (SS(w;r),x),R = Ext(w;x), &lt;/math&gt; and output &lt;math&gt; (R,P) &lt;/math&gt;.
(2) Rep &lt;math&gt; (w',(s,x)) &lt;/math&gt;: recover &lt;math&gt; w = Rec(w',s) &lt;/math&gt; and output &lt;math&gt; R = Ext(w;x) &lt;/math&gt;.

Proof: From the definition of secure sketch (Definition 2), 
&lt;math&gt;H_\infty(W | SS(W)) \geq \tilde{m} &lt;/math&gt;. And since Ext is an average-case &lt;math&gt; (n,m,l, \epsilon)&lt;/math&gt;-strong extractor.  &lt;math&gt; SD (( Ext(W;X),SS(W),X),(U_l,SS(W),X)) = SD((R,P),(U_l,P)) \leq \epsilon. &lt;/math&gt;

===Corollary 1===
If (SS,Rec) is an  &lt;math&gt; (M,m,\tilde{m},t) &lt;/math&gt; secure sketch and Ext is an &lt;math&gt; (n,\tilde{m}-log(\frac {1} {\delta}),l,\epsilon) &lt;/math&gt; strong extractor, then the above construction (Gen,Rep) is a &lt;math&gt; (M,m,l,t,\epsilon + \delta) &lt;/math&gt; fuzzy extractor.

The reference paper "Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data"  by Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin and Adam Smith (2008) includes many generic combinatorial bounds on secure sketches and fuzzy extractors

==Basic constructions==
Due to their error tolerant properties, a secure sketches can be treated, analyzed, and constructed like a &lt;math&gt;(n,k,d)_{\mathcal{F}}&lt;/math&gt; general [[Forward error correction|error correcting code]] or &lt;math&gt;[n,k,d]_{\mathcal{F}}&lt;/math&gt; for [[Linear code|linear]] codes, where &lt;math&gt;n&lt;/math&gt; is the length of codewords, &lt;math&gt;k&lt;/math&gt; is the length of the message to be codded, &lt;math&gt;d&lt;/math&gt; is the distance between codewords, and &lt;math&gt;\mathcal{F}&lt;/math&gt; is the alphabet.  If &lt;math&gt;\mathcal{F}^n&lt;/math&gt; is the universe of possible words then it may be possible to find an error correcting code &lt;math&gt;C \in \mathcal{F}^n&lt;/math&gt; that has a unique codeword &lt;math&gt;c \in C&lt;/math&gt; for every &lt;math&gt;w \in \mathcal{F}^n&lt;/math&gt; and have a [[Hamming distance]] of &lt;math&gt;dis_{Ham}(c,w) \leq (d-1)/2&lt;/math&gt;.  The first step for constructing a secure sketch is determining the type of errors that will likely occur and then choosing a distance to measure.

[[File:Secure Sketch Constructions.PNG|thumb|Red is the code-offset construction, blue is the syndrome construction, green represents edit distance and other complex constructions.]]

===Hamming distance constructions===
When there is no risk of data being deleted and only of it being corrupted then the best measurement to use for error correction is the Hamming distance.  There are two common constructions for correcting Hamming errors depending on whether the code is linear or not.  Both constructions start with an error correcting code that has a distance of &lt;math&gt;2t+1&lt;/math&gt; where &lt;math&gt;{t}&lt;/math&gt; is the number of tolerated errors.

====Code-offset construction====
When using a &lt;math&gt;(n,k,2t+1)_{\mathcal{F}}&lt;/math&gt; general code, assign a uniformly random codeword &lt;math&gt;c \in C&lt;/math&gt; to each &lt;math&gt;w&lt;/math&gt;, then let &lt;math&gt;SS(w)=s=w-c&lt;/math&gt; which is the shift needed to change &lt;math&gt;c&lt;/math&gt; into &lt;math&gt;w&lt;/math&gt;.  To fix errors in &lt;math&gt;w'&lt;/math&gt; subtract &lt;math&gt;s&lt;/math&gt; from &lt;math&gt;w'&lt;/math&gt; then correct the errors in the resulting incorrect codeword to get &lt;math&gt;c&lt;/math&gt; and finally add &lt;math&gt;s&lt;/math&gt; to &lt;math&gt;c&lt;/math&gt; to get &lt;math&gt;w&lt;/math&gt;.  This means &lt;math&gt;Rec(w',s)=s+dec(w'-s)=w&lt;/math&gt;.  This construction can achieve the best possible tradeoff between error tolerance and entropy loss when &lt;math&gt;\mathcal{F} \geq  n&lt;/math&gt; and a [[Reed–Solomon error correction|Reed–Solomon code]] is used resulting in an entropy loss of &lt;math&gt;2t\log(\mathcal{F})&lt;/math&gt;. The only way to improve upon would be to find a code better than Reed–Solomon.

====Syndrome construction====
When using a &lt;math&gt;[n,k,2t+1]_{\mathcal{F}}&lt;/math&gt; linear code  let the &lt;math&gt;SS(w)=s&lt;/math&gt; be the [[Syndrome decoding#Syndrome decoding|syndrome]] of &lt;math&gt;w&lt;/math&gt;.  To correct &lt;math&gt;w'&lt;/math&gt; find a vector &lt;math&gt;e&lt;/math&gt; such that &lt;math&gt;syn(e)=syn(w')-s&lt;/math&gt;, then &lt;math&gt;w=w'-e&lt;/math&gt;.

===Set difference constructions===
When working with a very large alphabet or very long strings resulting in a very large universe &lt;math&gt;\mathcal{U}&lt;/math&gt;, it may be more efficient to treat &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;w'&lt;/math&gt; as sets and look at [[Set difference#Relative complement|set differences]] to correct errors.  To work with a large set &lt;math&gt;w&lt;/math&gt; it is useful to look at its characteristic vector &lt;math&gt;x_w&lt;/math&gt;, which is a binary vector of length &lt;math&gt;n&lt;/math&gt; that has a value of 1 when an element &lt;math&gt;a \in \mathcal{U}&lt;/math&gt; and &lt;math&gt;a \in w&lt;/math&gt;, or 0 when &lt;math&gt;a \notin w&lt;/math&gt;.  The best way to decrease the size of a secure sketch when &lt;math&gt;n&lt;/math&gt; is large is make &lt;math&gt;k&lt;/math&gt; large since the size is determined by &lt;math&gt;n-k&lt;/math&gt;.  A good code to base this construction on is a &lt;math&gt;[n,n-t\alpha,2t+1]_{2}&lt;/math&gt; [[BCH codes|BCH code]] where &lt;math&gt;n=2^{\alpha}-1&lt;/math&gt; and &lt;math&gt;t \ll n&lt;/math&gt; so &lt;math&gt;k \leq n-log{n \choose{t}}&lt;/math&gt;, it is also useful that BCH codes can be decode in sub-linear time.

====Pin sketch construction====
Let &lt;math&gt;SS(w)=s=syn(x_w)&lt;/math&gt;.  To correct &lt;math&gt;w'&lt;/math&gt; first find &lt;math&gt;SS(w')=s'=syn(x_w')&lt;/math&gt;, then find a set v where &lt;math&gt;syn(x_v)=s'-s&lt;/math&gt;, finally compute the [[symmetric difference]] to get &lt;math&gt;Rec(w',s)=w' \triangle v=w&lt;/math&gt;.  While this is not the only construction than can be used to set the difference, it is the easiest one.

===Edit distance constructions===
When data can be corrupted or deleted, the best measurement to use is [[Levenshtein distance|edit distance]].  To make a construction based on edit distance, the easiest is to start with a construction for set difference or hamming distance as an intermediate correction step and then build the edit distance construction around that.

===Other distance measure constructions===
There are many other types of errors and distances that can be used to model other situations.  Most of these other possible constructions are built upon simpler constructions, like edit distance constructions.

==Improving error-tolerance via relaxed notions of correctness==
It can be shown that the error-tolerance of a secure sketch can be improved by applying a [[probabilistic method]] to error correction and only requesting errors to be correctable with a high probability.  This allows to exceed the [[Plotkin bound]] which limits to correcting &lt;math&gt;n/4&lt;/math&gt; errors, and to approach [[Noisy channel coding theorem|Shannon’s bound]] allowing for nearly &lt;math&gt;n/2&lt;/math&gt; corrections. To achieve this enhanced error correction, a less restrictive error distribution model must be used.

===Random errors===
For this most restrictive model use a [[Binary symmetric channel|BSC]]&lt;math&gt;_{p}&lt;/math&gt; to create a &lt;math&gt;w'&lt;/math&gt; that a probability &lt;math&gt;p&lt;/math&gt; at each position in &lt;math&gt;w'&lt;/math&gt; that the bit received is wrong.  This model can show that entropy loss is limited to &lt;math&gt;nH(p)-o(n)&lt;/math&gt;, where &lt;math&gt;H&lt;/math&gt; is the [[binary entropy function]], and if min-entropy &lt;math&gt;m \geq n(H(\frac{1}{2} - \gamma)) + \varepsilon&lt;/math&gt; then &lt;math&gt;n(\frac{1}{2} - \gamma)&lt;/math&gt; errors can be tolerated, for some constant &lt;math&gt;\gamma &gt; 0&lt;/math&gt;.

===Input-dependent errors===
For this model errors do not have a known distribution and can be from an adversary, the only constraints are &lt;math&gt;dis_\text{err} \leq t&lt;/math&gt; and that a corrupted word depends only on the input &lt;math&gt;w&lt;/math&gt; and not on the secure sketch.  It can be shown for this error model that there will never be more than &lt;math&gt;t&lt;/math&gt; errors since this model can account for all complex noise processes, meaning that Shannon’s bound can be reached, to do this a random permutation is prepended to the secure sketch that will reduce entropy loss.

===Computationally bounded errors===
This differs from the input dependent model by having errors that depend on both the input &lt;math&gt;w&lt;/math&gt; and the secure sketch, and an adversary is limited to polynomial time algorithms for introducing errors.  Since algorithms that can run in better than polynomial time are not currently feasible in the real world, then a positive result using this error model would guarantee that any errors can be fixed.  This is the least restrictive model the only known way to approach Shannon’s bound is to use [[List decoding|list-decodable codes]] although this may not always be useful in practice since returning a list instead of a single codeword may not always be acceptable.

==Privacy guarantees==

In general a secure system attempts to leak as little information as possible to an [[Adversary (cryptography)|adversary]]. In the case of biometrics if information about the biometric reading is leaked the adversary may be able to learn personal information about a user. For example an adversary notices that there is a certain pattern in the helper strings that implies the ethnicity of the user. We can consider this additional information a function &lt;math&gt;f(W)&lt;/math&gt;. If an adversary were to learn a helper string, it must be ensured that, from this data he can not infer any data about the person from which the biometric reading was taken.

===Correlation between helper string and biometric input===

Ideally the helper string &lt;math&gt;P&lt;/math&gt; would reveal no information about the biometric input &lt;math&gt;w&lt;/math&gt;. This is only possible when every subsequent biometric reading &lt;math&gt;w'&lt;/math&gt; is identical to the original &lt;math&gt;w&lt;/math&gt;. In this case there is actually no need for the helper string, so it is easy to generate a string that is in no way correlated to &lt;math&gt;w&lt;/math&gt;. 

Since it is desirable to accept biometric input &lt;math&gt;w'&lt;/math&gt; similar to &lt;math&gt;w&lt;/math&gt; the helper string &lt;math&gt;P&lt;/math&gt; must be somehow correlated. The more different &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;w'&lt;/math&gt; are allowed to be, the more correlation there will be between &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;w&lt;/math&gt;, the more correlated they are the more information &lt;math&gt;P&lt;/math&gt; reveals about &lt;math&gt;w&lt;/math&gt;. We can consider this information to be a function &lt;math&gt;f(W)&lt;/math&gt;. The best possible solution is to make sure the adversary can't learn anything useful from the helper string.

===Gen(''W'') as a probabilistic map===

A probabilistic map &lt;math&gt; Y() &lt;/math&gt; hides the results of functions with a small amount of leakage &lt;math&gt;\epsilon&lt;/math&gt;. The leakage is the difference in probability two adversaries have of guessing some function when one knows the probabilistic map and one does not. Formally:

: &lt;math&gt;|Pr[A_1(Y(W)) = f(W)] - Pr[A_2() = f(W)]| \leq \epsilon &lt;/math&gt;

If the function &lt;math&gt;Gen(W)&lt;/math&gt; is a probabilistic map, then even if an adversary knows both the helper string &lt;math&gt;P&lt;/math&gt; and the secret string &lt;math&gt; R &lt;/math&gt; they are only negligibly more likely figure something out about the subject as if they knew nothing. The string &lt;math&gt;R&lt;/math&gt; is supposed to kept secret, so even if it is leaked (which should be very unlikely) the adversary can still figure out nothing useful about the subject, as long as &lt;math&gt; \epsilon &lt;/math&gt; is small. We can consider &lt;math&gt; f(W) &lt;/math&gt; to be any correlation between the biometric input and some physical characteristic of the person. Setting &lt;math&gt; Y = Gen(W) = R, P &lt;/math&gt; in the above equation changes it to:

: &lt;math&gt;|\Pr[A_1(R, P) = f(W)] - \Pr[A_2() = f(W)]| \leq \epsilon &lt;/math&gt;

This means that if one adversary &lt;math&gt;A_1&lt;/math&gt; has &lt;math&gt; (R,P) &lt;/math&gt; and a second adversary &lt;math&gt;A_2&lt;/math&gt; knows nothing, their best guesses at &lt;math&gt; f(W) &lt;/math&gt; are only &lt;math&gt; \epsilon &lt;/math&gt; apart.

===Uniform fuzzy extractors===

Uniform fuzzy extractors are a special case of fuzzy extractors, where the output &lt;math&gt;(R,P)&lt;/math&gt; of &lt;math&gt;Gen(W)&lt;/math&gt; are negligibly different from strings picked from the uniform distribution, i.e. &lt;math&gt;(R, P) \approx_\epsilon (U_\ell, U_{|P|}) &lt;/math&gt;

===Uniform secure sketches===

Since secure sketches imply fuzzy extractors, constructing a uniform secure sketch allows for the easy construction of a uniform fuzzy extractor. In a uniform secure sketch the sketch procedure &lt;math&gt;SS(w)&lt;/math&gt; is a [[randomness extractor]] &lt;math&gt;Ext(w;i)&lt;/math&gt;. Where &lt;math&gt;w&lt;/math&gt; is the biometric input and &lt;math&gt;i&lt;/math&gt; is the [[random seed]]. Since randomness extractors output a string that appears to be from a uniform distribution they hide all the information about their input.

===Applications===

Extractor sketches can be used to construct &lt;math&gt;(m, t, \epsilon)&lt;/math&gt;-fuzzy perfectly one-way hash functions. When used as a hash function the input &lt;math&gt;w&lt;/math&gt; is the object you want to hash. The &lt;math&gt;P, R&lt;/math&gt; that &lt;math&gt;Gen(w)&lt;/math&gt; outputs is the hash value. If one wanted to verify that a &lt;math&gt;w'&lt;/math&gt; within &lt;math&gt; t &lt;/math&gt; from the original &lt;math&gt; w &lt;/math&gt;, they would verify that &lt;math&gt;Rep(w', P) = R&lt;/math&gt;. &lt;math&gt;(m, t, \epsilon)&lt;/math&gt;-fuzzy perfectly one-way hash functions are special [[Hash function (cryptography)|hash functions]] where they accept any input with at most &lt;math&gt;t&lt;/math&gt; errors, compared to traditional hash functions which only accept when the input matches the original exactly. Traditional cryptographic hash functions attempt to guarantee that is it is computationally infeasible to find two different inputs that hash to the same value. Fuzzy perfectly one-way hash functions make an analogous claim. They make it computationally infeasible two find two inputs, that are more than &lt;math&gt;t&lt;/math&gt; [[Hamming distance]] apart and hash to the same value.

==Protection against active attacks==
An active attack could be one where the adversary can modify the helper string &lt;math&gt;P&lt;/math&gt;. If the adversary is able to change &lt;math&gt;P&lt;/math&gt; to another string that is also acceptable to the reproduce function &lt;math&gt;Rep(W, P)&lt;/math&gt;, it causes &lt;math&gt;Rep(W, P)&lt;/math&gt; to output an incorrect secret string &lt;math&gt;\tilde{R}&lt;/math&gt;. Robust fuzzy extractors solve this problem by allowing the reproduce function to fail, if a modified helper string is provided as input.

===Robust fuzzy extractors===
One method of constructing robust fuzzy extractors is to use [[Hash function (cryptography)|hash functions]]. This construction requires two hash functions &lt;math&gt;H_1&lt;/math&gt; and &lt;math&gt;H_2&lt;/math&gt;.  The &lt;math&gt;Gen(W)&lt;/math&gt; functions produces the helper string &lt;math&gt;P&lt;/math&gt; by appending the output of a secure sketch &lt;math&gt;s = SS(w)&lt;/math&gt; to the hash of both the reading &lt;math&gt;w&lt;/math&gt; and secure sketch &lt;math&gt;s&lt;/math&gt;. It generates the secret string &lt;math&gt;R&lt;/math&gt; by applying the second hash function to &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt;. Formally:
&lt;math&gt; Gen(w): s = SS(w), return: P = (s, H_1(w,s)), R = H_2(w,s) &lt;/math&gt;
[[File:FuzzyExtGen.png|thumb|right]]
The reproduce function &lt;math&gt;Rep(W, P)&lt;/math&gt; also makes use of the hash functions &lt;math&gt;H_1&lt;/math&gt; and &lt;math&gt;H_2&lt;/math&gt;. In addition to verifying the biometric input is similar enough to the one recovered using the &lt;math&gt;Rec(W,S)&lt;/math&gt; function, it also verifies that hash in the second part of &lt;math&gt;P&lt;/math&gt; was actually derived from &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt;. If both of those conditions are met it returns &lt;math&gt;R&lt;/math&gt; which is itself the second hash function applied to &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt;. Formally:

&lt;math&gt;Rep(w',\tilde{P}): &lt;/math&gt; Get &lt;math&gt;\tilde{s} &lt;/math&gt; and &lt;math&gt; \tilde{h} &lt;/math&gt; from &lt;math&gt;\tilde{P};   \tilde{w} = Rec(w',\tilde{s}).&lt;/math&gt;
If &lt;math&gt;\Delta(\tilde{w}, w') \leq t &lt;/math&gt; and &lt;math&gt;\tilde{h} = H_1(\tilde{w},\tilde{s})&lt;/math&gt; then &lt;math&gt; return: H_2(\tilde{w}, \tilde{s}) &lt;/math&gt; else &lt;math&gt; return: fail&lt;/math&gt;
[[File:Rep.png|thumb|right]]

If &lt;math&gt;P&lt;/math&gt; has been tampered with it will be obvious because, &lt;math&gt;Rep&lt;/math&gt; will output fail with very high probability. To cause the algorithm accept a different &lt;math&gt;P&lt;/math&gt; an adversary would have to find a &lt;math&gt;\tilde{w}&lt;/math&gt; such that &lt;math&gt;H_1(w, s) = H_1(\tilde{w},\tilde{s}) &lt;/math&gt;. Since hash function are believed to be [[one way function]]s, it is computationally infeasible to find such a &lt;math&gt;\tilde{w}&lt;/math&gt;.
Seeing &lt;math&gt;P&lt;/math&gt; would provide the adversary with no useful information. Since, again, hash function are one way functions, it is computationally infeasible for the adversary to reverse the hash function and figure out &lt;math&gt;w&lt;/math&gt;. Part of &lt;math&gt;P&lt;/math&gt; is the secure sketch, but by definition the sketch reveals negligible information about its input. Similarly seeing &lt;math&gt;R&lt;/math&gt;(even though it should never see it) would provide the adversary with no useful information as the adversary wouldn't be able to reverse the hash function and see the biometric input.

==References==
{{reflist}}
* [http://www.cs.bu.edu/~reyzin/fuzzysurvey.html Fuzzy Extractors: A Brief Survey of Results from 2004 to 2006]
* [http://www.cs.ucla.edu/~rafail/PUBLIC/89.pdf Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data]
* [http://digital.csic.es/bitstream/10261/15966/1/SAM3262.pdf Biometric Fuzzy Extractor Scheme for Iris Templates]
* [http://people.csail.mit.edu/madhu/papers/2002/ari-journ.pdf A Fuzzy Vault Scheme]

[[Category:Biometrics]]
[[Category:Coding theory]]
[[Category:Cryptographic algorithms]]</text>
      <sha1>bgcafmtcze5giiwbwnptcp6masa5keg</sha1>
    </revision>
  </page>
  <page>
    <title>Geometric analysis</title>
    <ns>0</ns>
    <id>4325474</id>
    <revision>
      <id>727608738</id>
      <parentid>720411832</parentid>
      <timestamp>2016-06-30T02:37:15Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* References */Rem stub tag(s) (class = non-stub &amp; non-list) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1860">[[File:Saddle Tower Minimal Surfaces.png|thumb|[[Saddle tower]] minimal surface. [[Minimal surface]]s are among the objects of study in geometric analysis.]]

'''Geometric analysis''' is a [[mathematics|mathematical]] discipline at the interface of [[differential geometry]] and [[differential equations]].

==Scope==
It includes both the use of geometrical methods in the study of [[partial differential equation]]s (when it is also known as "geometric PDE"), and the application of the theory of partial differential equations to geometry. It incorporates problems involving curves and surfaces, or domains with curved boundaries, but also the study of [[Riemannian manifold]]s in arbitrary dimension.  The [[calculus of variations]] is sometimes regarded as part of geometric analysis, because differential equations arising from [[variational principle]]s have a strong geometric content. Geometric analysis also includes [[global analysis]], which concerns the study of differential equations on [[manifold]]s, and the relationship between differential equations and [[topology]].

==References==
*{{cite book|title=Riemannian geometry and Geometric Analysis |first=Jürgen|last=Jost|authorlink=Jürgen Jost|edition=4th|year=2005|publisher=Springer|isbn= 978-3-540-25907-7}}
*{{cite book|title=Groups and Geometric Analysis (Integral Geometry, Invariant Differential Operators and Spherical Functions) |first=Sigurdur|last=Helgason|authorlink=Sigurdur Helgason (mathematician)|edition=2nd|year=2000|publisher=[[American Mathematical Society]]|isbn= 978-0-8218-2673-7}}
*{{cite book|title=Geometric Analysis on Symmetric Spaces |first=Sigurdur|last=Helgason |edition=2nd|year=2008|publisher=American Mathematical Society|isbn= 978-0-8218-4530-1}}

[[Category:Differential geometry| ]]
[[Category:Calculus of variations]]
[[Category:Differential equations]]</text>
      <sha1>jftbo62mscvclwgea4x21ahpb17o90b</sha1>
    </revision>
  </page>
  <page>
    <title>Hamburger moment problem</title>
    <ns>0</ns>
    <id>3216491</id>
    <revision>
      <id>807582774</id>
      <parentid>807582702</parentid>
      <timestamp>2017-10-28T21:48:06Z</timestamp>
      <contributor>
        <ip>68.170.77.93</ip>
      </contributor>
      <comment>Fixed mislink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7462">In [[mathematics]], the '''Hamburger [[moment problem]]''', named after [[Hans Hamburger|Hans Ludwig Hamburger]], is formulated as follows: given a sequence {&amp;nbsp;''m&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;:&amp;nbsp;''n''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;...&amp;nbsp;}, does there exist a positive [[Borel measure]] ''μ'' (for instance, the [[cumulative distribution function]] of a [[random variable]]) on the real line such that

:&lt;math&gt;m_n = \int_{-\infty}^\infty x^n\,d \mu(x)\  ?&lt;/math&gt;

In other words, an affirmative answer to the problem means that {&amp;nbsp;''m&lt;sub&gt;n&lt;/sub&gt;''&amp;nbsp;:&amp;nbsp;''n''&amp;nbsp;=&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...&amp;nbsp;} is the sequence of [[moment (mathematics)|moments]] of some positive Borel measure&amp;nbsp;''μ''.

The [[Stieltjes moment problem]], [[Vorobyev moment problem]], and the [[Hausdorff moment problem]] are similar but replace the real line by &lt;math&gt;[0,+\infty)&lt;/math&gt; (Stieltjes and Vorobyev; but Vorobyev formulates the problem in the terms of matrix theory), or a bounded interval (Hausdorff).

== Characterization ==

The Hamburger moment problem is solvable (that is, {''m&lt;sub&gt;n&lt;/sub&gt;''} is a sequence of [[moment (mathematics)|moments]]) if and only if the corresponding Hankel kernel on the nonnegative integers

:&lt;math&gt;
A =
\left(\begin{matrix}
m_0 &amp; m_1 &amp; m_2 &amp; \cdots     \\
m_1 &amp; m_2 &amp; m_3 &amp; \cdots  \\
m_2 &amp; m_3 &amp; m_4 &amp; \cdots  \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots  \\
\end{matrix}\right)&lt;/math&gt;

is [[positive definite kernel|positive definite]], i.e.,

:&lt;math&gt; \sum_{j,k\ge0}m_{j+k}c_j\bar c_k\ge0
&lt;/math&gt;

for an arbitrary sequence {''c&lt;sub&gt;j&lt;/sub&gt;''}&lt;sub&gt;''j'' ≥ 0&lt;/sub&gt; of complex numbers with finite support (i.e. 
''c&lt;sub&gt;j&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;0 except for finitely many values of&amp;nbsp;''j'').

For the "only if" part of the claims simply note that

:&lt;math&gt; \sum_{j,k\ge0}m_{j+k}c_j\bar c_k= \int_{-\infty}^\infty \left|\sum_{j\geq 0} c_j x^j\right|^2\,d \mu(x) &lt;/math&gt;

which is non-negative if &lt;math&gt; \mu &lt;/math&gt; is non-negative.

We sketch an argument for the converse. Let '''Z'''&lt;sup&gt;+&lt;/sup&gt; be the nonnegative integers and ''F''&lt;sub&gt;0&lt;/sub&gt;('''Z'''&lt;sup&gt;+&lt;/sup&gt;) denote the family of complex valued sequences with finite support.  The positive Hankel kernel ''A'' induces a (possibly degenerate) [[sesquilinear]] product on the family of complex valued sequences with finite support.  This in turn gives a [[Hilbert space]]

:&lt;math&gt;(\mathcal{H}, \langle, \; \rangle)&lt;/math&gt;

whose typical element is an equivalence class denoted by&amp;nbsp;[''f''].

Let ''e&lt;sub&gt;n&lt;/sub&gt;'' be the element in ''F''&lt;sub&gt;0&lt;/sub&gt;('''Z'''&lt;sup&gt;+&lt;/sup&gt;) defined by ''e&lt;sub&gt;n&lt;/sub&gt;''(''m'') = [[Kronecker delta|''&amp;delta;&lt;sub&gt;nm&lt;/sub&gt;'']]. One notices that

:&lt;math&gt;\langle [e_{n+1}], [e_m] \rangle = A_{m,n+1} = m_{m+n+1} = \langle [e_n], [e_{m+1}]\rangle.&lt;/math&gt;

Therefore, the [[shift operator|"shift" operator]] ''T'' on &lt;math&gt;\mathcal{H}&lt;/math&gt;, with ''T''[''e&lt;sub&gt;n&lt;/sub&gt;'']&amp;nbsp;=&amp;nbsp;[''e''&lt;sub&gt;''n''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt;], is [[symmetric operator|symmetric]].

On the other hand, the desired expression

:&lt;math&gt;m_n = \int_{-\infty}^\infty x^n\,d \mu(x).&lt;/math&gt;
 
suggests that ''μ'' is the [[spectral measure]] of a [[self-adjoint operator]]. (More precisely stated, ''μ'' is the spectral measure for an operator &lt;math&gt; \bar{T} &lt;/math&gt; defined below and the vector [1], {{harv|Reed|Simon|1975|p=145}}).  If we can find a "function model" such that the symmetric operator ''T'' is [[multiplication operator|multiplication by&amp;nbsp;''x'']], then the spectral resolution of a [[extensions of symmetric operators|self-adjoint extension]] of ''T'' proves the claim.

A function model is given by the natural isomorphism from ''F''&lt;sub&gt;0&lt;/sub&gt;('''Z'''&lt;sup&gt;+&lt;/sup&gt;) to the family of polynomials, in one single real variable and complex coefficients: for ''n''&amp;nbsp;≥&amp;nbsp;0, identify ''e&lt;sub&gt;n&lt;/sub&gt;'' with ''x&lt;sup&gt;n&lt;/sup&gt;''. In the model, the operator ''T'' is multiplication by ''x'' and a densely defined symmetric operator. It can be shown that ''T'' always has self-adjoint extensions. Let

:&lt;math&gt; \bar{T} &lt;/math&gt;

be one of them and ''μ'' be its spectral measure. So

:&lt;math&gt;\langle \bar{T}^n [1], [1] \rangle = \int x^n d \mu(x).&lt;/math&gt;

On the other hand,

:&lt;math&gt; \langle \bar{T}^n [1], [1] \rangle =  \langle T^n [e_0], [e_0] \rangle = m_n. &lt;/math&gt;

For an alternative proof of the existence that only uses Stieltjes integrals, see also {{sfn|Chihara|1978|p=56}}, in particular theorem 3.2.  

=== Uniqueness of solutions ===

The solutions form a convex set, so the problem has either infinitely many solutions or a unique solution.

Consider the (''n''&amp;nbsp;+&amp;nbsp;1)&amp;times;(''n''&amp;nbsp;+&amp;nbsp;1) [[Hankel matrix]]

:&lt;math&gt;\Delta_n=\left[\begin{matrix}
m_0 &amp; m_1 &amp; m_2 &amp; \cdots &amp; m_{n}    \\
m_1 &amp; m_2 &amp; m_3 &amp; \cdots &amp; m_{n+1} \\
m_2 &amp; m_3 &amp; m_4 &amp; \cdots &amp; m_{n+2} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
m_{n} &amp; m_{n+1} &amp; m_{n+2} &amp; \cdots &amp; m_{2n}
\end{matrix}\right].&lt;/math&gt;

Positivity of ''A'' means that for each ''n'', det(Δ&lt;sub&gt;''n''&lt;/sub&gt;)&amp;nbsp;≥&amp;nbsp;0. If det(Δ&lt;sub&gt;''n''&lt;/sub&gt;)&amp;nbsp;=&amp;nbsp;0, for some&amp;nbsp;''n'', then

:&lt;math&gt;(\mathcal{H}, \langle, \; \rangle)&lt;/math&gt;

is finite-dimensional and ''T'' is self-adjoint. So in this case the solution to the Hamburger moment problem is unique and ''μ'', being the spectral measure of ''T'', has finite support.

More generally, the solution is unique if there are constants ''C'' and ''D'' such that for all ''n'', |m&lt;sub&gt;''n''&lt;/sub&gt;|≤ ''CD''&lt;sup&gt;''n''&lt;/sup&gt;''n''! {{harv|Reed|Simon|1975|p=205}}. This follows from the more general [[Carleman's condition]].

There are examples where the solution is not unique, see e.g. {{sfn|Chihara|1978|p=73}}.

== Further results ==
{{Expand section|date=June 2008}}
One can see that the Hamburger moment problem is intimately related to [[orthogonal polynomials]] on the real line.  The [[Gram–Schmidt]] procedure gives a basis of orthogonal polynomials in which the operator: &lt;math&gt; \bar{T}  &lt;/math&gt; has a tridiagonal ''Jacobi matrix representation''.  This in turn leads to a ''tridiagonal model'' of positive Hankel kernels.

An explicit calculation of the [[Cayley transform]] of ''T'' shows the connection with what is called the ''[[Nevanlinna class]]'' of analytic functions on the left half plane.  Passing to the non-commutative setting, this motivates ''Krein's formula'' which parametrizes the extensions of partial isometries.

The cumulative distribution function and the probability density function can often be found by applying the inverse [[Laplace transform]] to the moment generating function
:&lt;math&gt;m(t)=\sum_{n=0}m_n\frac{t^n}{n!},&lt;/math&gt;
provided that this function converges.

== References ==
*{{citation|first=T.S.|last=Chihara|title=An Introduction to Orthogonal Polynomials|year=1978|ISBN=0-677-04150-0|publisher=Gordon and Breach, Science Publishers}}
*{{citation|first=Michael|last=Reed|first2=Barry|last2=Simon|title=Fourier Analysis, Self-Adjointness|year=1975|ISBN=0-12-585002-6|series=Methods of modern mathematical physics|volume=2|publisher=Academic Press|pages=145, 205}}
* {{citation|last=Shohat|first= J. A.|last2= Tamarkin|first2= J. D.|title=The Problem of Moments|publisher =American mathematical society|publication-place= New York|year= 1943|isbn=0-8218-1501-6}}.

{{DEFAULTSORT:Hamburger Moment Problem}}
[[Category:Probability problems]]
[[Category:Measure theory]]
[[Category:Functional analysis]]
[[Category:Moment (mathematics)]]
[[Category:Mathematical problems]]</text>
      <sha1>f4feihq9zslczhyquzghnqqcgjb2ulm</sha1>
    </revision>
  </page>
  <page>
    <title>Horizontal line test</title>
    <ns>0</ns>
    <id>56874</id>
    <revision>
      <id>789185882</id>
      <parentid>789185442</parentid>
      <timestamp>2017-07-05T21:46:23Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>/* See also */ a more appropriate link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2995">In [[mathematics]], the '''horizontal line test''' is a test used to determine whether a [[function (mathematics)|function]] is [[injective]] (i.e., one-to-one).&lt;ref name="Stewart"&gt;{{cite book|last=Stewart|first=James|title=Single Variable Calculus: Early Transcendentals|year=2003|publisher=Brook/Cole|location=Toronto ON|isbn=0-534-39330-6|pages=64|url=http://www.stewartcalculus.com/media/8_home.php|edition=5th.|authorlink=James Stewart (mathematician)|accessdate=15 July 2012|quote=Therefore, we have the following geometric method for determining whether a function is one-to-one.}}&lt;/ref&gt;

==In calculus==
A ''horizontal line'' is a straight, flat line that goes from left to right. Given a function &lt;math&gt;f \colon \mathbb{R} \to \mathbb{R}&lt;/math&gt; (i.e. from the [[real numbers]] to the real numbers), we can decide if it is [[injective]] by looking at horizontal lines that intersect the function's [[graph of a function|graph]]. If any horizontal line &lt;math&gt;y=c&lt;/math&gt;  intersects the graph in more than one point, the function is not injective. To see this, note that the points of intersection have the same y-value (because they lie on the line &lt;math&gt;y=c&lt;/math&gt;) but different x values, which by definition means the function cannot be injective.&lt;ref name="Stewart"/&gt;

{| border="1"
|-
| align="center"|[[Image:Horizontal-test-ok.png]]&lt;br&gt;
Passes the test (injective)
| align="center"|[[Image:Horizontal-test-fail.png]]&lt;br&gt;
Fails the test (not injective)
|}

Variations of the horizontal line test can be used to determine whether a function is [[surjective]] or [[bijective]]:
*The function ''f'' is surjective (i.e., onto) [[if and only if]] its graph intersects any horizontal line at '''least''' once.
*''f'' is bijective if and only if any horizontal line will intersect the graph '''exactly''' once.

==In set theory==
Consider a function &lt;math&gt;f \colon X \to Y&lt;/math&gt; with its corresponding [[graph of a function|graph]] as a subset of the [[Cartesian product]] &lt;math&gt;X \times Y&lt;/math&gt;. Consider the horizontal lines in &lt;math&gt;X \times Y&lt;/math&gt; :&lt;math&gt;\{(x,y_0) \in X \times Y: y_0 \text{ is constant}\} = X \times \{y_0\}&lt;/math&gt;. The function ''f'' is [[injective]] [[if and only if]] each horizontal line intersects the graph at most once. In this case the graph is said to pass the horizontal line test. If any horizontal line intersects the graph more than once, the function fails the horizontal line test and is not injective.&lt;ref&gt;{{cite book|last=Zorn|first=Arnold Ostebee, Paul|title=Calculus from graphical, numerical, and symbolic points of view|year=2002|publisher=Brooks/Cole/Thomson Learning|location=Australia|isbn=0-03-025681-X|pages=185|url=https://books.google.com/books?id=D48RplvmxVUC&amp;q=horizontal+line+test#search_anchor|edition=2nd|quote=No horizontal line crosses the f-graph more than once.}}&lt;/ref&gt;

== See also ==
*[[Vertical line test]]
*[[Inverse function]]
*[[Monotonic function]]

==References==
{{reflist}}

[[Category:Basic concepts in set theory]]</text>
      <sha1>bojx51yarc8xbvmph3rg5iljshdgg1f</sha1>
    </revision>
  </page>
  <page>
    <title>Kneser's theorem (combinatorics)</title>
    <ns>0</ns>
    <id>36237048</id>
    <revision>
      <id>858678027</id>
      <parentid>857017472</parentid>
      <timestamp>2018-09-08T22:23:57Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>/* References */ [[József Solymosi]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2524">In mathematics, '''Kneser's theorem''' is an [[Inequality (mathematics)|inequality]] among the sizes of certain [[sumset]]s in [[abelian group]]s. It belongs to the field of [[additive combinatorics]], and is named after [[Martin Kneser]], who published it in 1953.&lt;ref&gt;{{cite journal | first=Martin | last=Kneser | title=Abschätzungen der asymptotischen Dichte von Summenmengen | language=German | journal=[[Math. Z.]] | volume=58 | year=1953 | pages=459–484 | zbl=0051.28104 }}
&lt;/ref&gt;  It may be regarded as an extension of the [[Cauchy–Davenport theorem]], which also concerns sumsets in groups but is restricted to groups whose [[Order (group theory)|order]] is a [[prime number]].&lt;ref name=GR143&gt;{{harvtxt|Geroldinger|Ruzsa|2009|p=143}}&lt;/ref&gt;

==Statement==
Let ''G'' be an [[abelian group]] and ''A'', ''B'' finite non-empty subsets.  If |''A''| + |''B''| ≤ |''G''| then there is a finite subgroup ''H'' of ''G'' such that&lt;ref&gt;{{harvnb|Tao|Vu|2010|loc=pg. 200, Theorem 5.5}}&lt;/ref&gt;

:&lt;math&gt;\begin{align} |A+B| &amp;\ge |A+H| + |B+H| - |H| \\ &amp;\ge |A| + |B| - |H|. \end{align} &lt;/math&gt;

The subgroup ''H'' can be taken to be the ''stabiliser''&lt;ref name=GR143/&gt; of ''A''+''B''

:&lt;math&gt; H = \lbrace  g \in G : g + (A+B) = (A+B) \rbrace. &lt;/math&gt;

==Notes==
{{reflist}}

==References==
* {{cite book | editor1-last=Geroldinger | editor1-first=Alfred | editor2-last=Ruzsa | editor2-first=Imre Z. | editor2-link = Imre Z. Ruzsa | others=Elsholtz, C.; Freiman, G.; Hamidoune, Y. O.; Hegyvári, N.; Károlyi, G.; Nathanson, M.; [[József Solymosi|Solymosi, J.]]; Stanchescu, Y. With a foreword by Javier Cilleruelo, Marc Noy and Oriol Serra (Coordinators of the DocCourse) | title=Combinatorial number theory and additive group theory | series=Advanced Courses in Mathematics CRM Barcelona | location=Basel | publisher=Birkhäuser | year=2009 | isbn=978-3-7643-8961-1 | zbl=1177.11005|ref=harv }}
* {{cite book | first=Melvyn B. | last=Nathanson | authorlink = Melvyn B. Nathanson | title=Additive Number Theory: Inverse Problems and the Geometry of Sumsets | volume=165 | series=[[Graduate Texts in Mathematics]] | publisher=[[Springer-Verlag]] | year=1996 | isbn=0-387-94655-1 | zbl=0859.11003 | pages=109–132 }}
* {{citation | first1=Terence | last1=Tao | author1-link=Terence Tao | first2=Van H. | last2=Vu | title=Additive Combinatorics | year=2010 | publisher=[[Cambridge University Press]] | place=[[Cambridge]] | isbn=978-0-521-13656-3 | zbl=1179.11002 }}

[[Category:Theorems in combinatorics]]
[[Category:Sumsets]]</text>
      <sha1>r3mcv0c6y9dbpc5vlaprvizi9jcvejc</sha1>
    </revision>
  </page>
  <page>
    <title>Limit of a sequence</title>
    <ns>0</ns>
    <id>285773</id>
    <revision>
      <id>852390054</id>
      <parentid>852390014</parentid>
      <timestamp>2018-07-28T17:19:18Z</timestamp>
      <contributor>
        <username>JC7V7DC5768</username>
        <id>34198373</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/103.1.30.51|103.1.30.51]] ([[User talk:103.1.30.51|talk]]): Rv test. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15116">{{refimprove|date=May 2017}}

[[File:Archimedes pi.svg|350px|right|thumb|alt=diagram of a hexagon and pentagon circumscribed outside a circle|The sequence given by the perimeters of regular ''n''-sided [[polygon]]s that circumscribe the [[unit circle]] has a limit equal to the perimeter of the circle, i.e. &lt;math&gt;2\pi r&lt;/math&gt;. The corresponding sequence for inscribed polygons has the same limit.]]
&lt;div class="thumb tright"&gt;
&lt;div class="thumbinner" style="width:252px;"&gt;
&lt;div  style="width:240px; font-family:arial; font-size:12px; font-weight:bold; background:#fff;"&gt;
{| class="wikitable" style="width:100%;"
|-
!''n''!!''n''&amp;nbsp;sin(1/''n'')
|-
|1||0.841471
|-
|2||0.958851
|-
|colspan="2"|...
|-
|10||0.998334
|-
|colspan="2"|...
|-
|100||0.999983
|}
&lt;/div&gt;
&lt;div class="thumbcaption"&gt;
As the positive [[integer]] &lt;math&gt;n&lt;/math&gt; becomes larger and larger, the value &lt;math&gt;n\cdot \sin\bigg(\frac1{n}\bigg)&lt;/math&gt; becomes arbitrarily close to &lt;math&gt;1&lt;/math&gt;. We say that "the limit of the sequence &lt;math&gt;n\cdot \sin\bigg(\frac1{n}\bigg)&lt;/math&gt; equals &lt;math&gt;1&lt;/math&gt;."
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

In [[mathematics]], the '''limit of a sequence''' is the value that the terms of a [[sequence]] "tend to".&lt;ref name="Courant (1961), p. 29"&gt;Courant (1961), p. 29.&lt;/ref&gt;  If such a limit exists, the sequence is called '''convergent'''. A sequence which does not converge is said to be '''divergent'''.&lt;ref&gt;Courant (1961), p. 39.&lt;/ref&gt; The limit of a sequence is said to be the fundamental notion on which the whole of [[Mathematical analysis|analysis]] ultimately rests.&lt;ref name="Courant (1961), p. 29"/&gt;

Limits can be defined in any [[metric space|metric]] or [[topological space]], but are usually first encountered in the [[real number]]s.

==History==
The Greek philosopher [[Zeno of Elea]] is famous for formulating [[Zeno's paradoxes|paradoxes that involve limiting processes]].

[[Leucippus]], [[Democritus]], [[Antiphon (person)|Antiphon]], [[Eudoxus of Cnidus|Eudoxus]] and [[Archimedes]] developed the [[method of exhaustion]], which uses an infinite sequence of approximations to determine an area or a volume. Archimedes succeeded in summing what is now called a [[geometric series]].

[[Isaac Newton|Newton]] dealt with series in his works on ''Analysis with infinite series'' (written in 1669, circulated in manuscript, published in 1711), ''Method of fluxions and infinite series'' (written in 1671, published in English translation in 1736, Latin original published much later) and ''Tractatus de Quadratura Curvarum'' (written in 1693, published in 1704 as an Appendix to his ''Optiks''). In the latter work, Newton considers the binomial expansion of (''x''&amp;nbsp;+&amp;nbsp;''o'')&lt;sup&gt;''n''&lt;/sup&gt; which he then linearizes by ''taking limits'' (letting ''o''&amp;nbsp;→&amp;nbsp;0).

In the 18th century, [[mathematician]]s such as [[Leonhard Euler|Euler]] succeeded in summing some ''divergent'' series by stopping at the right moment; they did not much care whether a limit existed, as long as it could be calculated. At the end of the century, [[Joseph Louis Lagrange|Lagrange]] in his ''Théorie des fonctions analytiques'' (1797) opined that the lack of rigour precluded further development in calculus. [[Carl Friedrich Gauss|Gauss]] in his etude of [[hypergeometric series]] (1813) for the first time rigorously investigated under which conditions a series converged to a limit.

The modern definition of a limit (for any ε there exists an index ''N'' so that ...) was given by [[Bernhard Bolzano]] (''Der binomische Lehrsatz'', Prague 1816, little noticed at the time) and by [[Karl Weierstrass]] in the 1870s.

==Real numbers==
[[File:Converging Sequence example.svg|320px|thumb|The plot of a convergent sequence {''a&lt;sub&gt;n&lt;/sub&gt;''} is shown in blue. Visually we can see that the sequence is converging to the limit 0 as ''n'' increases.]]

In the [[real numbers]], a number &lt;math&gt;L&lt;/math&gt; is the '''limit''' of the [[sequence]] &lt;math&gt;(x_n)&lt;/math&gt; if the numbers in the sequence become closer and closer to &lt;math&gt;L&lt;/math&gt; and not to any other number.

===Examples===
*If &lt;math&gt;x_n = c&lt;/math&gt; for constant ''c'', then &lt;math&gt;x_n \to c&lt;/math&gt;.&lt;ref group=proof&gt;''Proof'': choose &lt;math&gt;N = 1&lt;/math&gt;. For every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;|x_n - c| = 0 &lt; \epsilon&lt;/math&gt;&lt;/ref&gt;
*If &lt;math&gt;x_n = \frac1{n}&lt;/math&gt;, then &lt;math&gt;x_n \to 0&lt;/math&gt;.&lt;ref group=proof&gt;''Proof'': choose &lt;math&gt;N = \left\lfloor\frac1{\epsilon}\right\rfloor&lt;/math&gt; + 1 (the [[Floor and ceiling functions|floor function]]). For every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;|x_n - 0| \le x_N = \frac1{\lfloor1/\epsilon\rfloor + 1} &lt; \epsilon&lt;/math&gt;.&lt;/ref&gt;
*If &lt;math&gt;x_n = 1/n&lt;/math&gt; when &lt;math&gt;n&lt;/math&gt; is even, and &lt;math&gt;x_n = \frac1{n^2}&lt;/math&gt; when &lt;math&gt;n&lt;/math&gt; is odd, then &lt;math&gt;x_n \to 0&lt;/math&gt;. (The fact that &lt;math&gt;x_{n+1} &gt; x_n&lt;/math&gt; whenever &lt;math&gt;n&lt;/math&gt; is odd is irrelevant.)
*Given any real number, one may easily construct a sequence that converges to that number by taking decimal approximations. For example, the sequence &lt;math&gt;0.3, 0.33, 0.333, 0.3333, ...&lt;/math&gt; converges to &lt;math&gt;1/3&lt;/math&gt;. Note that the [[decimal representation]] &lt;math&gt;0.3333...&lt;/math&gt; is the ''limit'' of the previous sequence, defined by
:&lt;math&gt; 0.3333...\triangleq\lim_{n\to\infty} \sum_{i=1}^n \frac{3}{10^i}&lt;/math&gt;.

*Finding the limit of a sequence is not always obvious. Two examples are &lt;math&gt;\lim_{n\to\infty}\left(1 + \frac1{n}\right)^n&lt;/math&gt; (the limit of which is the [[e (mathematical constant)|number ''e'']]) and the [[Arithmetic–geometric mean]].   The [[squeeze theorem]] is often useful in such cases.

===Formal definition===
We call &lt;math&gt;x&lt;/math&gt; the '''limit''' of the [[sequence]] &lt;math&gt;(x_n)&lt;/math&gt; if the following condition holds:
:*For each [[real number]] &lt;math&gt;\epsilon &gt; 0&lt;/math&gt;, there exists a [[natural number]] &lt;math&gt;N&lt;/math&gt; such that, for every natural number &lt;math&gt;n \geq N&lt;/math&gt;, we have &lt;math&gt;|x_n - x| &lt; \epsilon&lt;/math&gt;.
In other words, for every measure of closeness &lt;math&gt;\epsilon&lt;/math&gt;, the sequence's terms are eventually that close to the limit.  The sequence &lt;math&gt;(x_n)&lt;/math&gt; is said to '''converge to''' or '''tend to''' the limit &lt;math&gt;x&lt;/math&gt;, written &lt;math&gt;x_n \to x&lt;/math&gt; or &lt;math&gt;\lim_{n\to\infty}x_n = x&lt;/math&gt;.

Symbolically, this is:
:* &lt;math&gt;\forall \varepsilon &gt; 0(\exists N \in \mathbb{N}(\forall n \in \mathbb{N}(n \geq N \implies |x_n - x| &lt; \varepsilon ))). &lt;/math&gt;

If a sequence converges to some limit, then it is '''convergent'''; otherwise it is '''divergent'''.

=== Illustration ===
&lt;gallery widths="350" heights="200"&gt;
File:Folgenglieder im KOSY.svg|Example of a sequence which converges to the limit &lt;math&gt;a&lt;/math&gt;.
File:Epsilonschlauch.svg|Regardless which &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt; we have, there is an index &lt;math&gt;N_0&lt;/math&gt;, so that the sequence lies afterwards completely in the epsilon tube &lt;math&gt;(a-\varepsilon,a+\varepsilon)&lt;/math&gt;.
File:Epsilonschlauch klein.svg|There is also for a smaller &lt;math&gt;\epsilon_1 &gt; 0&lt;/math&gt; an index &lt;math&gt;N_1&lt;/math&gt;, so that the sequence is afterwards inside the epsilon tube &lt;math&gt;(a-\varepsilon_1,a+\varepsilon_1)&lt;/math&gt;.
File:Epsilonschlauch2.svg|For each &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt; there are only finitely many sequence members outside the epsilon tube.
&lt;/gallery&gt;

===Properties===
Limits of sequences behave well with respect to the usual [[Arithmetic#Arithmetic operations|arithmetic operations]].  If &lt;math&gt;a_n \to a&lt;/math&gt; and &lt;math&gt;b_n \to b&lt;/math&gt;, then &lt;math&gt;a_n+b_n \to a+b&lt;/math&gt;, &lt;math&gt;a_n\cdot b_n \to ab&lt;/math&gt; and, if neither ''b'' nor any &lt;math&gt;b_n&lt;/math&gt; is zero, &lt;math&gt;\frac{a_n}{b_n} \to \frac{a}{b}&lt;/math&gt;.

For any [[continuous function]] ''f'', if &lt;math&gt;x_n \to x&lt;/math&gt; then &lt;math&gt;f(x_n) \to f(x)&lt;/math&gt;. In fact, any real-valued [[function (mathematics)|function]] ''f'' is continuous if and only if it preserves the limits of sequences (though this is not necessarily true when using more general notions of continuity).

Some other important properties of limits of real sequences include the following (provided, in each equation below, that the limits on the right exist).

*The limit of a sequence is unique.
*&lt;math&gt;\lim_{n\to\infty} (a_n \pm b_n) =  \lim_{n\to\infty} a_n \pm \lim_{n\to\infty} b_n&lt;/math&gt;
*&lt;math&gt;\lim_{n\to\infty} c a_n =  c \cdot \lim_{n\to\infty} a_n&lt;/math&gt;
*&lt;math&gt;\lim_{n\to\infty} (a_n \cdot b_n) =  (\lim_{n\to\infty} a_n)\cdot( \lim_{n\to\infty} b_n)&lt;/math&gt;
*&lt;math&gt;\lim_{n\to\infty} \left(\frac{a_n}{b_n}\right) = \frac{\lim\limits_{n\to\infty} a_n}{\lim\limits_{n\to\infty} b_n}&lt;/math&gt; provided &lt;math&gt;\lim_{n\to\infty} b_n \ne 0&lt;/math&gt;
*&lt;math&gt;\lim_{n\to\infty} a_n^p =  \left[ \lim_{n\to\infty} a_n \right]^p&lt;/math&gt;
*If &lt;math&gt;a_n \leq b_n&lt;/math&gt; for all &lt;math&gt;n&lt;/math&gt; greater than some &lt;math&gt;N&lt;/math&gt;, then &lt;math&gt;\lim_{n\to\infty} a_n \leq \lim_{n\to\infty} b_n &lt;/math&gt;
*([[Squeeze theorem]]) If &lt;math&gt;a_n \leq c_n \leq b_n&lt;/math&gt; for all &lt;math&gt;n &gt; N&lt;/math&gt;, and &lt;math&gt;\lim_{n\to\infty} a_n = \lim_{n\to\infty} b_n = L&lt;/math&gt;, {{pad|.5em}} then &lt;math&gt;\lim_{n\to\infty} c_n = L&lt;/math&gt;.
*If a sequence is [[#Bounded|bounded]] and [[#Increasing and decreasing|monotonic]] then it is convergent.
*A sequence is convergent if and only if every subsequence is convergent.

These properties are extensively used to prove limits without the need to directly use the cumbersome formal definition. Once proven that 
&lt;math&gt;\frac{1}{n} \to 0&lt;/math&gt; it becomes easy to show that &lt;math&gt;\frac{a}{b+\frac{c}{n}} \to \frac{a}{b}&lt;/math&gt;, (&lt;math&gt;b \ne 0&lt;/math&gt;), using the properties above.

===Infinite limits===

A sequence &lt;math&gt;(x_n)&lt;/math&gt; is said to '''tend to infinity''', written &lt;math&gt;x_n \to \infty&lt;/math&gt; or &lt;math&gt;\lim_{n\to\infty}x_n = \infty&lt;/math&gt;  if, for every ''K'', there is an ''N'' such that, for every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;x_n &gt; K&lt;/math&gt;; that is, the sequence terms are eventually larger than any fixed ''K''.  Similarly, &lt;math&gt;x_n \to -\infty&lt;/math&gt; if, for every ''K'', there is an ''N'' such that, for every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;x_n &lt; K&lt;/math&gt;. If a sequence tends to infinity, or to minus infinity, then it is divergent  (however, a divergent sequence need not tend to plus or minus infinity: take for example &lt;math&gt;x_n=(-1)^n&lt;/math&gt;).

==Metric spaces==

===Definition===

A point &lt;math&gt;x&lt;/math&gt; of the [[metric space]] &lt;math&gt;(X, d)&lt;/math&gt; is the '''limit''' of the [[sequence]] &lt;math&gt;(x_n)&lt;/math&gt; if, for all &lt;math&gt;\epsilon &gt; 0&lt;/math&gt;, there is an &lt;math&gt;N&lt;/math&gt; such that, for every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;d(x_n, x) &lt; \epsilon&lt;/math&gt;.  This coincides with the definition given for real numbers when &lt;math&gt;X = \mathbb{R}&lt;/math&gt; and &lt;math&gt;d(x, y) = |x-y|&lt;/math&gt;.

===Properties===

For any [[continuous function]] ''f'', if &lt;math&gt;x_n \to x&lt;/math&gt; then &lt;math&gt;f(x_n) \to f(x)&lt;/math&gt;.  In fact, a [[function (mathematics)|function]] ''f'' is continuous if and only if it preserves the limits of sequences.

Limits of sequences are unique when they exist, as distinct points are separated by some positive distance, so for &lt;math&gt;\epsilon&lt;/math&gt; less than half this distance, sequence terms cannot be within a distance &lt;math&gt;\epsilon&lt;/math&gt; of both points.

==Topological spaces==

===Definition===

A point ''x'' of the topological space (''X'', &amp;tau;) is a '''limit''' of the [[sequence]] (''x&lt;sub&gt;n&lt;/sub&gt;'') if, for every [[topological neighbourhood|neighbourhood]] ''U'' of ''x'', there is an ''N'' such that, for every &lt;math&gt;n \geq N&lt;/math&gt;, &lt;math&gt;x_n \in U&lt;/math&gt;.  This coincides with the definition given for metric spaces if (''X'',''d'') is a metric space and &lt;math&gt;\tau&lt;/math&gt; is the topology generated by ''d''.

A limit of a sequence of points &lt;math&gt;\left(x_n:n\in \mathbb{N}\right)\;&lt;/math&gt; in a topological space ''T'' is a special case of a [[Limit of a function#Functions on topological spaces|limit of a function]]: the domain is &lt;math&gt;\mathbb{N}&lt;/math&gt; in the space &lt;math&gt;\mathbb{N} \cup \lbrace +\infty \rbrace&lt;/math&gt; with the [[induced topology]] of the [[affinely extended real number system]], the range is ''T'', and the function argument ''n'' tends to +∞, which in this space is a [[limit point]] of &lt;math&gt;\mathbb{N}&lt;/math&gt;.

===Properties===

If ''X'' is a [[Hausdorff space]] then limits of sequences are unique where they exist. Note that this need not be the case in general; in particular, if two points ''x'' and ''y'' are [[topologically indistinguishable]], any sequence that converges to ''x'' must converge to ''y'' and vice versa.

==Cauchy sequences==
{{main|Cauchy sequence}}

[[File:Cauchy sequence illustration.svg|350px|thumb| The plot of a Cauchy sequence (''x&lt;sub&gt;n&lt;/sub&gt;''), shown in blue, as ''x&lt;sub&gt;n&lt;/sub&gt;'' versus ''n''. Visually, we see that the sequence appears to be converging to a limit point as the terms in the sequence become closer together as ''n'' increases. In the [[real numbers]] every Cauchy sequence converges to some limit.]]

A Cauchy sequence is a sequence whose terms ultimately become arbitrarily close together, after sufficiently many initial terms have been discarded. The notion of a Cauchy sequence is important in the study of sequences in [[metric spaces]], and, in particular, in [[real analysis]]. One particularly important result in real analysis is the ''Cauchy criterion for convergence of sequences'': A sequence of real numbers is convergent if and only if it is a Cauchy sequence. This remains true in other [[complete metric space|complete metric spaces]].

==Definition in hyperreal numbers==
The definition of the limit using the [[hyperreal numbers]] formalizes the intuition that for a "very large" value of the index, the corresponding term is "very close" to the limit.  More precisely, a real sequence &lt;math&gt;(x_n)&lt;/math&gt; tends to ''L'' if for every infinite [[hypernatural]] ''H'', the term ''x''&lt;sub&gt;''H''&lt;/sub&gt; is infinitely close to ''L'', i.e., the difference  ''x''&lt;sub&gt;''H''&lt;/sub&gt;&amp;nbsp;−&amp;nbsp;''L'' is [[infinitesimal]].  Equivalently, ''L'' is the [[Standard part function|standard part]] of ''x''&lt;sub&gt;''H''&lt;/sub&gt;

:&lt;math&gt; L = {\rm st}(x_H).\,&lt;/math&gt;

Thus, the limit can be defined by the formula

:&lt;math&gt;\lim_{n \to \infty} x_n= {\rm st}(x_H),&lt;/math&gt;

where the limit exists if and only if the righthand side is independent of the choice of an infinite ''H''.

==See also==
*[[Limit of a function]]
*[[Net (mathematics)#Limits of nets|Limit of a net]] &amp;mdash; A [[net (mathematics)|net]] is a topological generalization of a sequence.
*[[Modes of convergence]]
*[[Shift rule]]

== Notes ==
{{Reflist}}

===Proofs===
{{Reflist|group=proof}}

==References==
* [[Richard Courant|Courant, Richard]] (1961). "Differential and Integral Calculus Volume I", Blackie &amp; Son, Ltd., Glasgow.
* [[Frank Morley]] and [[James Harkness]] [https://archive.org/details/treatiseontheory00harkuoft A treatise on the theory of functions]  (New York: Macmillan, 1893)

==External links==
* {{springer|title=Limit|id=p/l058820}}
* [https://web.archive.org/web/20040905075957/http://www-gap.dcs.st-and.ac.uk/~history/HistTopics/The_rise_of_calculus.html ''A history of the calculus'', including limits]

[[Category:Limits (mathematics)]]
[[Category:Sequences and series]]</text>
      <sha1>lbf894wfv92itc0redvnhp9oyon5tpj</sha1>
    </revision>
  </page>
  <page>
    <title>List of International Congresses of Mathematicians Plenary and Invited Speakers</title>
    <ns>0</ns>
    <id>47738065</id>
    <revision>
      <id>870550446</id>
      <parentid>867576753</parentid>
      <timestamp>2018-11-25T15:34:49Z</timestamp>
      <contributor>
        <ip>46.86.37.12</ip>
      </contributor>
      <comment>/* 1936, Oslo */ fix typo in name</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="123193">This is a '''list of [[International Congress of Mathematicians|International Congresses of Mathematicians]] Plenary and Invited Speakers'''. Being invited to talk at an ICM has been called "the equivalent, in this community, of an induction to a hall of fame."&lt;ref&gt;{{cite journal|author=Castelvecchi, Davide|title=The biggest mystery in mathematics: Shinichi Mochizuki and the impenetrable proof|journal=Nature|date=7 October 2015|volume=526|url=http://www.nature.com/news/the-biggest-mystery-in-mathematics-shinichi-mochizuki-and-the-impenetrable-proof-1.18509|doi=10.1038/526178a|pages=178–181|pmid=26450038}}&lt;/ref&gt; (The current list of Plenary and Invited Speakers presented here is based on the ICM's post-WW II terminology, in which the one-hour speakers in the morning sessions are called "Plenary Speakers" and the other speakers (in the afternoon sessions) whose talks are included in the ICM published proceedings are called "Invited Speakers". In the pre-WW II congresses the Plenary Speakers were called "Invited Speakers". 

;See also
* [[:ru:Список пленарных докладов на Международных конгрессах математиков|Plenary Speakers]] {{link language|ru}}, contribution titles, and URLs
* [https://www.mathunion.org/icm/proceedings International Mathematical Union: Proceedings 1893-2014]


==Speakers by year of congress==

===1897, Zürich===
[[File:Felix Klein.jpeg|thumb|Felix Klein]]
{{div col|colwidth=12em}}
*[[Jules Andrade]]
*[[Léon Autonne]]
*[[Émile Borel]]
*[[Nikolai Bugaev|N. V. Bougaïev]]
*[[Francesco Brioschi]]
*[[Hermann Brunn]]
*[[Cesare Burali-Forti]]
*[[Charles Jean de la Vallée Poussin]]
*[[Gustaf Eneström]]
*[[Federigo Enriques]]
*[[Gino Fano]]
*[[Zoel García de Galdeano]]
*[[Francesco Gerbaldi]]
*[[Paul Gordan]]
*[[Jacques Hadamard]]
*[[Adolf Hurwitz]]
*[[Felix Klein]]
*[[Gino Loria]]
*[[Wilhelm Franz Meyer]]
*[[Giuseppe Peano]]
*[[Ivan Pervushin]]
*[[Émile Picard]]
*[[Salvatore Pincherle]]
*[[Henri Poincaré]]
*[[Gusztáv Rados]]
*{{ill|Carl Reuschle|de|Karl Reuschle}}
*[[Theodor Reye]]
*[[Ernst Schröder]]
*[[Cyparissos Stephanos]]
*[[Ludwig Stickelberger]]
*[[Aurel Stodola]]
*[[Heinrich Martin Weber|H. Weber]]
*[[Hieronymus Georg Zeuthen]]
*[[Nikolay Yegorovich Zhukovsky]]
{{div col end}}

===1900, Paris===
[[File:David Hilbert, c. 1900.png|thumb|David Hilbert]]
During the 1900 Congress in Paris, France, David Hilbert ''(pictured)'' announced his famous list of [[Hilbert's problems]].&lt;ref&gt;{{cite journal|author=Scott, Charlotte Angas|authorlink=Charlotte Angas Scott|title=The International Congress of Mathematicians in Paris|journal=Bull. Amer. Math. Soc.|year=1900|volume=7|issue=2|pages=57–79|url=http://www.ams.org/journals/bull/1900-07-02/S0002-9904-1900-00768-3/S0002-9904-1900-00768-3.pdf|doi=10.1090/s0002-9904-1900-00768-3}}&lt;/ref&gt;
{{div col|colwidth=12em}}
*[[Federico Amodeo]]
*[[Léon Autonne]]
*[[Ivar Otto Bendixson]]
*[[Giovanni Boccardi (astronomer)|Jean Boccardi]]
*[[Émile Borel]]
*[[Moritz Cantor]]
*[[Alfredo Capelli]]
*[[Élie Cartan]]
*[[Philbert Maurice d'Ocagne]]
*[[Zoel García de Galdeano]]
*[[Leonard Eugene Dickson]]
*[[Jules Drach]]
*[[Erik Ivar Fredholm]]
*[[Rikitaro Fujisawa]]
*[[Ángel Gallardo]]
*[[Jacques Hadamard]]
*[[Harris Hancock]]
*[[David Hilbert]]
*[[Pierre Adolphe Issaly]]
*[[Eugen Jahnke]]
*[[Victor Jamet]]
*[[Léopold Leau]]
*[[Edgar Odell Lovett]]
*[[Charles Méray]]
*[[Alexander Macfarlane]]
*{{ill|Edmond Maillet|fr|Edmond Maillet}}
*[[Artemas Martin]]
*[[Gösta Mittag-Leffler]]
*[[Henri Padé]]
*[[Alessandro Padoa]]
*[[Raoul Perrin]]
*[[Henri Poincaré]]
*[[Cyparissos Stephanos]]
*[[Irving Stringham]]
*{{Interlanguage link multi|G. K. Suslov|ru|3=Суслов, Гавриил Константинович}}
*{{ill|Matvej Tichomandrickij|ru|Тихомандрицкий, Матвей Александрович}}
*[[F. J. Vaes]]
*[[Giuseppe Veronese]]
*[[Vito Volterra]]
*[[Helge von Koch]]
{{div col end}}

{{clear}}&lt;!---keep the following ((div col)) spreading over the full page width---&gt;
===1904, Heidelberg===
[[File:Emile Borel-1932.jpg|thumb|Emile Borel]]
[[File:ETH-BIB-Weber, Heinrich (1842-1913)-Portrait-Portr 09008.tif (cropped).jpg|thumb|Heinrich Weber]]

In 1904, in Heidelberg, the 69 invited speakers included Borel, Hadamard, Hilbert, Klein, Levi-Civita, Minkowski, Mittag-Leffler, and Sommerfeld.
{{div col|colwidth=12em}}
*[[Jules Andrade]]
*[[Léon Autonne]]
*[[Anton Börsch]]
*[[Émile Borel]]
*[[Pierre Boutroux]]
*[[Max Brückner]]
*[[Anton von Braunmühl]]
*[[Alexander von Brill]]
*[[Moritz Cantor]]
*[[Alfredo Capelli]]
*[[Nikolai Borisovich Delone (aviation pioneer)|Nikolai Delaunay]]
*[[Samuel Dickstein (mathematician)|Samuel Dickstein]]
*[[Gustaf Eneström]]
*[[Henri Fehr]]
*[[Johannes Finsterbusch]]
*[[Sebastian Finsterwalder]]
*[[Robert Fricke]]
*[[Robert William Genese]]
*[[Paul Gordan]]
*[[Alfred George Greenhill]]
*{{illm|Claude Guichard|fr|Claude Guichard (mathématicien)}}
*[[Alf Victor Guldberg]]
*[[August Gutzmer]]
*[[Jacques Hadamard]]
*[[David Hilbert]]
*[[Franc Hočevar]]
*[[Gyula Kőnig]] (Julius König)
*[[Alfred Kempe]]
*[[Felix Klein]]
*{{ill|Johannes Knoblauch|de}}
*[[Leo Königsberger]]
*[[Tullio Levi-Civita]]
*{{ill|Reinhold von Lilienthal|de}}
*[[Alfred Loewy]]
*[[Gino Loria]]
*[[Francis Sowerby Macaulay]]
*[[Wilhelm Franz Meyer]]
*[[Hermann Minkowski]]
*[[Gösta Mittag-Leffler]]
*[[Emil Müller (mathematician)|Emil Müller]]
*[[Paul Painlevé]]
*[[Ludwig Prandtl]]
*[[Karl Rohn]]
*[[Georg Scheffers]]
*[[Ludwig Schlesinger]]
*[[Arthur Moritz Schoenflies]]
*[[Heinrich Schotten]]
*[[Corrado Segre]]
*[[Max Simon (mathematician)|Maximilian Simon]]
*[[Arnold Sommerfeld]]
*[[Antonín Václav Šourek]]
*[[Paul Stäckel]]
*[[Cyparissos Stéphanos]]
*[[Eduard Study]]
*[[Heinrich Suter]]
*[[Paul Tannery]]
*{{ill|Hermann Thieme|de}}
*[[Giovanni Vailati]]
*[[Vito Volterra]]
*[[Georgy Voronoy]]
*[[Heinrich Martin Weber]]
*[[Julius Weingarten]]
*[[Hermann Wiener]]
*[[Ernest Julius Wilczynski]]
*[[Edwin Bidwell Wilson]]
*[[Anders Wiman]]
*[[Wilhelm Wirtinger]]
*[[Hieronymus Georg Zeuthen]]
*{{ill|Konrad Zindler|de}}
{{div col end}}

{{clear}}&lt;!---keep the following ((div col)) spreading over the full page width---&gt;
===1908, Rome===
[[File:Levi-civita.jpg|thumb|Tullio Levi-Civita]]
The 1908 ICM in Rome had 121 invited speakers included Bernstein, Borel, Brückner, Brouwer, Darboux, Dickson, Fubini, Hadamard, Levi-Civita, Lorenz, Macfarlane, Mittag-Leffler, E.H. Moore, M. Noether, Picard, Poincaré, F. Rietz, Severi, Sommerfeld, and Zermelo.  Robert Genese spoke again, this time on "The Method of Reciprocal Polars Applied to Forces in Space" (page 145 of the proceedings). 
{{div col|colwidth=12em}}
*[[Max Abraham]]
*[[Federico Amodeo]]
*[[Jules Andrade]]
*[[Friedrich Simon Archenhold]]
*[[Léon Autonne]]
*[[Giuseppe Bagnera (mathematician)|Giuseppe Bagnera]]
*[[Emanuel Beke]]
*[[Felix Bernstein (mathematician)|Felix Bernstein]]
*[[Luigi Bianchi]]
*[[Giovanni Boccardi (astronomer)|Giovanni Boccardi]]
*[[Tommaso Boggio]]
*[[Georg Bohlmann]]
*[[Émile Borel]]
*[[Pierre Boutroux]]
*[[Max Brückner]]
*[[L. E. J. Brouwer]]
*[[George H. Bryan]]
*[[Silvio Canevazzi]]
*[[Alfredo Capelli]]
*[[Giuseppe Casazza]]
*[[Thomas Claxton Fidler]]
*[[Alberto Conti (mathematician)|Alberto Conti]]
*[[Robert d'Adhémar]]
*[[Maurice d'Ocagne]]
*[[Gaston Darboux]]
*[[George Darwin]]
*[[Miles Menander Dawson]]
*[[Michele de Franchis]]
*[[Zoel García de Galdeano]]
*[[Fernando de Helguero]]
*[[Leonard Eugene Dickson]]
*[[Friedrich Dingeldey]]
*[[Pierre Duhem]]
*[[Walther von Dyck]]
*[[William Palin Elderton]]
*[[Arnold Emch]]
*[[Federigo Enriques]]
*[[Henri Fehr]]
*[[Johannes Finsterbusch]]
*[[Andrew Forsyth]]
*[[Giovanni Frattini]]
*[[Ivar Fredholm]]
*[[Guido Fubini]]
*[[Generoso Gallucci]]
*[[Antonio Garbasso]]
*[[Robert William Genese]]
*[[Raffaele Giacomelli]]
*[[Corrado Gini]]
*[[Paul Gordan]]
*[[George Greenhill]]
*[[August Gutzmer]]
*[[Jacques Hadamard]]
*[[Gerhard Hessenberg]]
*[[Gregorius Itelson]]
*[[Paul Koebe]]
*[[G. V. Kolosoff]]
*[[Arthur Korn]]
*[[Traian Lalesco]]
*[[Horace Lamb]]
*[[Giuseppe Lauricella]]
*[[Charles Lembourg]]
*[[Beppo Levi]]
*[[Tullio Levi-Civita]]
*[[Hendrik Lorentz]]
*[[Gino Loria]]
*[[Luigi Luiggi]]
*[[Alexander Macfarlane]]
*[[Lucien March]]
*[[Roberto Marcolongo]]
*[[Gösta Mittag-Leffler]]
*{{ill|Domenico Montesano|it}}
*[[Robert de Montessus de Ballore]]
*[[E. H. Moore]]
*[[Simon Newcomb]]
*[[Onorato Nicoletti]]
*[[Max Noether]]
*[[Luciano Orlando]]
*[[Marino Pannelli]]
*{{ill|Ernesto Pascal|it}}
*[[Annibale Pastore]]
*[[Mihailo Petrović]]
*[[Georgii Yurii Pfeiffer|Georgii Pfeiffer]]
*[[Émile Picard]]
*[[Georg Pick]]
*[[Salvatore Pincherle]]
*[[Laura Pisati]]
*[[Giulio Pittarelli]]
*[[Paolo Pizzetti]]
*[[Henri Poincaré]]
*[[John Henry Poynting]]
*[[Giuseppe Pucciano]]
*[[Albert Quiquet]]
*[[Gusztáv Rados]]
*[[Georges Rémoundos]]
*[[Frigyes Riesz]]
*{{ill|Nikolai Saltykow|ru|Салтыков,_Николай_Николаевич}}
*[[Ludwig Schlesinger]]
*[[Corrado Segre]]
*[[Francesco Severi]]
*[[Carlo Severini]]
*[[Maximilian Simon]]
*[[David Eugene Smith]]
*[[Carlo Somigliana]]
*[[Arnold Sommerfeld]]
*[[Cyparissos Stéphanos]]
*[[Carl Størmer]]
*{{ill|Richard Suppantschitsch|sl|Rihard Zupančič}}
*[[George F. Swain]]
*[[Orazio Tedone]]
*[[Guido Toja]]
*[[Gheorghe Tzitzéica]]
*[[Giovanni Vailati]]
*[[Vladimir Varićak]]
*[[Giuseppe Veronese]]
*[[Vito Volterra]]
*[[William Henry Young]]
*[[Stanisław Zaremba (mathematician)|Stanisław Zaremba]]
*[[Ernst Zermelo]]
*{{Interlanguage link multi|Panagiotis Zervos|el|3=Παναγιώτης Ζερβός}}
*[[Hieronymus Georg Zeuthen]]
{{div col end}}

===1912, Cambridge (UK)===
[[File:Ghhardy@72.jpg|thumb|G. H. Hardy]]
[[File:PSM V70 D187 Edward Kasner.jpg|thumb|Edward Kasner]]
[[File:J.J Thomson.jpg|thumb|J. J. Thomson]]

The 1912 ICM in Cambridge had 103 invited speakers, among them Bateman, Bernstein, Borel, Brouwer, Fehr, Fields, Grossman, Hadamard, Hardy, von Koch, Landau, Littlewood, Love, Macfarlane, E.H. Moore, Morley, Peano, Runge, Thomon, Volterra, Whitehead, and Zermelo.
{{div col|colwidth=12em}}
*[[Max Abraham]]
*[[Luigi Amoroso]]
*[[Maxime Bôcher]]
*[[Harry Bateman]]
*[[Hans Albrecht von Beckh-Widmanstetter]]
*[[Geoffrey Thomas Bennett]]
*[[Sergei Natanovich Bernstein]]
*[[Wilhelm Blaschke]]
*[[Otto Blumenthal]]
*[[Enrico Bompiani]]
*[[Émile Borel]]
*[[Max Brückner]]
*[[Selig Brodetsky]]
*[[Thomas John I'Anson Bromwich]]
*[[L. E. J. Brouwer]]
*[[Ernest William Brown]]
*[[George Edward St. Lawrence Carson]]
*[[Henry Louis Le Châtelier]]
*{{ill|Alfred Denizot|pl}}
*[[John Dougall (mathematician)|John Dougall]]
*[[Jules Drach]]
*[[Walther von Dyck]]
*[[Francis Ysidro Edgeworth]]
*[[Luther P. Eisenhart]]
*[[Edwin Bailey Elliott]]
*[[Gustaf Eneström]]
*[[Federigo Enriques]]
*[[Paul Peter Ewald]]
*[[Ludwig Föppl]]
*[[Henri Fehr]]
*[[John Charles Fields]]
*[[Johannes Finsterbusch]]
*[[André Gérardin]]
*[[Marcel Grossmann]]
*[[Jacques Hadamard]]
*[[Johann Georg Hagen]]
*[[Percy John Harding]]
*[[G. H. Hardy]]
*[[Nikolaos J. Hatzidakis]]
*[[Micaiah John Muller Hill]]
*{{ill|Bohuslav Hostinský|cs}}
*[[Hilda Phoebe Hudson]]
*[[Edward Vermilye Huntington]]
*[[Gregorius Itelson]]
*[[Zygmunt Janiszewski]]
*[[Philip Jourdain]]
*[[Theodore von Kármán]]
*[[Dénes Kőnig]]
*[[József Kürschák]]
*[[Edward Kasner]]
*[[Helge von Koch]]
*[[Horace Lamb]]
*[[Joseph Larmor]]
*[[Edmund Landau]]
*[[Robert Alfred Lehfeldt]]
*[[Armin Otto Leuschner]]
*[[John Edensor Littlewood]]
*[[Gino Loria]]
*[[Augustus Edward Hough Love]]
*[[Alexander Macfarlane]]
*[[E. H. Moore]]
*[[Frank Morley]]
*[[Forest Ray Moulton]]
*[[Robert Franklin Muirhead]]
*[[Eric Harold Neville]]
*[[Thomas Percy Nunn]]
*[[Alessandro Padoa]]
*[[Giuseppe Peano]]
*[[William Peddie]]
*[[Johannes Hendrikus Peek]]
*[[Mihailo Petrovitch]]
*[[Albert Quiquet]]
*[[Georges Rémoundos]]
*[[Ferdinand Rudio]]
*[[Carl David Tolmé Runge]]
*[[Nikolai Saltykow]]
*[[Ralph Allen Sampson]]
*[[Ludwig Schlesinger]]
*[[Pieter Hendrik Schoute]]
*[[William Fleetwood Sheppard]]
*[[Ludwik Silberstein]]
*[[David Eugene Smith]]
*[[Marian Smoluchowski]]
*[[Carlo Somigliana]]
*[[Duncan Sommerville]]
*[[Johan Frederik Steffensen]]
*[[Cyparissos Stéphanos]]
*{{ill|Robert von Sterneck the Younger|de|Robert Daublebsky von Sterneck der Jüngere|lt=Robert von Sterneck}}
*[[Eduard Study]]
*{{ill|Richard Suppantschitsch|sl|Rihard Zupančič}}
*[[Esteban Terrades]]
*[[J. J. Thomson]]
*[[Herbert Hall Turner]]
*[[Gheorghe Tzitzéica]]
*[[Giovanni Vacca (mathematician)|Giovanni Vacca]]
*[[Vito Volterra]]
*[[Roland Weitzenböck]]
*[[Alfred North Whitehead]]
*[[E. T. Whittaker]]
*[[Michael Marlow Umfreville Wilkinson]]
*[[Ernst Zermelo]]
*{{ill|Panagiotis Zervos|el|Παναγιώτης Ζερβός}}
{{div col end}}

===1920, Strasbourg===
[[File:Hadamard2.jpg|thumb|Jacques Hadamard]]
The 1920 congress in Strasbourg had only 56 invited speakers, among them Cartan, Dickson, Grossman, Hadamard, Jordan, Lefschetz, Takagi, de la Vallée Poussin, Volterra, and Wiener.
{{div col|colwidth=12em}}
*[[Johan Antony Barrau]]
*[[Giovanni Boccardi (astronomer)|Jean Boccardi]]
*{{ill|Farid Boulad Bey|fr}}
*[[Pierre Boutroux]]
*[[Louis Marcel Brillouin]]
*[[Henri Brocard]]
*[[Bohumil Bydzowsky]]
*[[Élie Cartan]]
*[[Albert Châtelet]]
*[[Percy John Daniell]]
*[[Maurice d'Ocagne]]
*[[Théophile de Donder]]
*[[Arnaud Denjoy]]
*[[Jacques Deruyts]]
*[[Leonard Eugene Dickson]]
*[[Jules Drach]]
*[[L. Gustave du Pasquier]]
*[[Luther P. Eisenhart]]
*[[Rudolf Fueter]]
*[[André Gérardin]]
*[[Alfred George Greenhill]]
*[[Marcel Grossmann]]
*[[Édouard Guillaume]]
*[[Alf Victor Guldberg]]
*[[Jacques Hadamard]]
*[[Nikolaos J. Hatzidakis]]
*{{ill|Bohuslav Hostinský|cs}}
*[[Camille Jordan]]
*[[Gabriel Koenigs]]
*[[Joseph Larmor]]
*[[Solomon Lefschetz]]
*[[Louis Maillard (astronomer)|Louis Maillard]]
*[[Niels Erik Nørlund]]
*[[Kinnosuke Ogura]]
*[[František Rádl]]
*[[Georges Rémoundos]]
*[[Julio Rey Pastor]]
*[[Dimitri Riabouchinsky]]
*{{ill|Nilos Sakellariou|el|Νείλος Σακελλαρίου}}
*[[Émile Schwoerer]]
*{{ill|Jan Sobotka (mathematician)|cs|Jan Sobotka (matematik)|lt=Jan Sobotka}}
*[[Carl Størmer]]
*[[Simion Stoilow]]
*[[Teiji Takagi]]
*{{ill|Alfred Ungerer|de}}
*[[Georges Valiron]]
*[[Charles Jean de la Vallée-Poussin]]
*[[Theodoros Varopoulos]]
*[[Vito Volterra]]
*[[Joseph Leonard Walsh]]
*[[Rolin Wavre]]
*[[Pierre Weiss]]
*[[Norbert Wiener]]
*[[William Henry Young]]
*[[Stanisław Zaremba (mathematician)|Stanisław Zaremba]]
*{{ill|Panagiotis Zervos|el|Παναγιώτης Ζερβός}}
{{div col end}}

===1924, Toronto===
[[File:Arthur Stanley Eddington.jpg|thumb|Arthur Eddington]]

The 1924 ICM in Toronto had 180 invited speakers, including Bell, Besicovitch, Cartan, Coats, Coker, Dickson, Eddington, Fehr, Fisher, Fréchet, Fubini, Hedrick, Hille, Morley, Ore, Peano, Plancherel, Ricci-Curbastro, H. Rietz, Severi, Sierpiński, Uspensky, and Zaremba.
{{div col|colwidth=12em}}
*[[Jules Andrade]]
*[[Robert W. Angus]]
*[[Richard William Bailey|R. W. Bailey]]
*[[Johan Antony Barrau]]
*[[Louis Agricola Bauer]]
*[[Eric Temple Bell]]
*[[Benjamin Abram Bernstein]]
*[[Abram Samoilovitch Besicovitch|Abram Besicovitch]]
*[[Richard Birkeland]]
*[[Vilhelm Bjerknes]]
*[[Gilbert Ames Bliss]]
*[[Tommy Bonnesen]]
*[[Ettore Bortolotti]]
*[[Arthur Lyon Bowley]]
*[[Louis Charles Breguet]]
*[[Lyman James Briggs]]
*[[Léon Brillouin]]
*[[Ernest William Brown]]
*[[Daniel Buchanan (mathematician)|Daniel Buchanan]]
*[[Bohumil Bydzovsky]]  	
*[[Florian Cajori]]
*[[George Ashley Campbell]]
*[[John Renshaw Carson]]
*[[Élie Cartan]]
*[[Sydney Chapman (mathematician)|Sydney Chapman]]
*[[Prosper Charbonnier]]
*[[Jean Chazy]]
*[[Robert H. Coats]]
*[[Arthur Byron Coble]]
*[[Boris Koyalovich|B. M. Coïalowitsch]]
*[[Ernest George Coker]]
*[[Arthur W. Conway]]
*[[Patrick Peter Cormack]]
*[[Francisco Miranda da Costa Lobo]]
*[[Louis Crelier|Louis Jacques Crelier]]
*[[Louise Duffield Cummings]]
*[[David Raymond Curtiss]]
*[[Haroutune Mugurditch Dadourian]]
*[[Boris Delaunay]]
*{{ill|Alphonse Demoulin|fr}}
*[[Leonard Eugene Dickson]]
*[[Alfred Cardew Dixon]]
*[[Jules Drach]]
*[[L. Gustave du Pasquier]]
*[[Herbert Bristol Dwight]]
*[[Arthur Eddington]]
*[[John Arndt Eiesland]]
*[[William Palin Elderton]]
*[[Alfred Errera]]
*[[Griffith Conrad Evans]]
*[[Henri Fehr]]
*[[Grigorii Fichtenholz]]
*[[John Charles Fields]]
*[[Ronald Fisher]]
*[[Arthur Percy Morris Fleming]]
*[[Walter Burton Ford]]
*[[R. M. Foster]]
*[[Ralph H. Fowler]]
*[[Maurice Fréchet]]
*[[Thornton Carle Fry]]
*[[Guido Fubini]]
*[[Rudolf Fueter]]
*[[William Frederick Gerhardt]]
*{{ill|Giuseppe Gianfranceschi|de}}
*[[Albert Henry Stewart Gillson]]
*[[Corrado Gini]]
*[[Giovanni Giorgi]]
*[[Oliver Edmunds Glenn]]
*[[James Waterman Glover]]
*[[Lucien Godeaux]]
*[[James Gray (mathematician)|James Gordon Gray]]
*[[Alfred George Greenhill]]
*[[Jules Haag]]
*[[Bernard Parker Haigh]]
*[[Mellen Woodman Haskell]]
*[[Olive Clio Hazlett]]
*[[Nicholas Hunter Heck]]
*[[Earle Raymond Hedrick]]
*[[James Blacklock Henderson]]
*[[Robert Henderson (mathematician)|Robert Henderson]]
*[[Einar Hille]]
*[[George William Osborn Howe|G. W. O. Howe]]
*[[William Jackson Humphreys]]
*[[F. R. W. Hunt]]
*[[John Irwin Hutchinson]]
*[[Samuel Jacob Jacobsohn]]
*[[Maurice Janet]]
*[[Charles Frewen Jenkin]]
*{{ill|Miloš Kössler|cs}}
*{{ill|Willem Kapteyn|de}}
*[[Louis Charles Karpinski]]
*[[Arthur Edwin Kennelly]]
*[[Cassius Jackson Keyser]]
*[[Louis Vessot King]]
*[[Gabriel Koenigs]]
*[[Alfred Korzybski]]
*{{ill|Vladimir Aleksandrovich Kostitzin|ru|Костицын, Владимир Александрович}}
*[[Mikhail Kravchuk]]
*[[Nikolay Mitrofanovich Krylov]]
*[[Joseph Larmor]]
*[[Jean-Marie Le Roux]]
*[[Horace Clifford Levinson]]
*{{ill|Cristóbal de Losada y Puga|es}}
*[[Murdoch Campbell MacLean]]
*[[Percy Alexander MacMahon]]
*[[Lucien March]]
*[[George Francis McEwen]]
*[[Émile Merlin]]
*[[George Abram Miller]]
*[[Edward C. Molina]]
*[[Frank Morley]]
*[[Francis Dominic Murnaghan (mathematician)|Francis Dominic Murnaghan]]
*[[Forrest Hamilton Murray]]
*[[Øystein Ore]]
*[[Charles Algernon Parsons]]
*[[John Patterson (meteorologist)|John Patterson]]
*[[Giuseppe Peano]]
*[[Mihailo Petrovitch]]
*[[Lars Edvard Phragmén]]
*[[James P. Pierpont]]
*[[Salvatore Pincherle]]
*[[Michel Plancherel]]
*[[Henry Crozier Plummer]]
*[[Jean-Baptiste Pomey]]
*[[Gorakh Prasad]]
*[[Umberto Puppini]]
*[[C. V. Raman]]
*[[Andrea Razmadze]]
*[[Lowell J. Reed]]
*[[Gregorio Ricci-Curbastro]]
*[[Paul Reece Rider]]
*[[Henry Louis Rietz]]
*[[René Risser]]
*[[Joseph Fels Ritt]]
*[[William Henry Roever]]
*[[James Harvey Rogers]]
*[[Thomas Reeve Rosebrugh]]
*[[Charles Edward St. John]]
*[[Frey Samsioe|Axel Frey Samsioe]]
*[[Pio Scatizzi]]
*[[Clément Servais]]
*[[Francesco Severi]]
*[[Napier Shaw]]
*[[William Fleetwood Sheppard]]
*[[James Alexander Shohat]]
*[[Wacław Sierpiński]]
*[[Ludwik Silberstein]]
*[[Chester Snow]]
*[[Carl Størmer]]
*[[Johan Frederik Steffensen]]
*[[Vladimir Steklov (mathematician)|Vladimir Steklov]]
*[[Charles Thompson Sullivan]]
*[[William Francis Gray Swann]]
*[[John Lighton Synge]]
*[[Jacob Tamarkin]]
*[[D'Arcy Wentworth Thompson]]
*[[Leonida Tonelli]]
*[[Jacques Touchard]]
*[[Gheorghe Tzitzéica]]
*[[J. V. Uspensky]]
*[[Willem van der Woude]]
*[[Henri Louis Vanderlinden]]
*[[Harry Schultz Vandiver]]
*[[Theodoros Varopoulos]]
*[[John Alexander Low Waddell]]
*[[James Henry Weaver]]
*[[A. Harry Wheeler]]
&lt;!-- T. T. Whitehead, Maths Master at Burnley Grammar School, might be Thomas Tennison Whitehead (1874–1950). --&gt;
*[[Albert Wurts Whitney]]
*[[Raymond Louis Wilder]]
*[[Thomas Russell Wilkins]]
*[[Walter Francis Willcox]]
*[[William Lloyd Garrison Williams]]
*[[Edwin Bidwell Wilson]]
*[[Hugh Herbert Wolfenden]]
*[[Julius Wolff (mathematician)|Julius Wolff]]
*[[William Henry Young]]
*[[George Udny Yule]]
*[[Stanisław Zaremba (mathematician)|Stanisław Zaremba]]
{{div col end}}

===1928, Bologna===
[[File:George David Birkhoff 1.jpg|thumb|George David Birkhoff]]
[[File:عالم الرياضيات البولندى ستيفان بناخ.jpg|thumb|Stefan Banach]]
[[File:Noether.jpg|thumb|Emmy Noether]]
[[File:Hermann Weyl ETH-Bib Portr 00890.jpg|thumb|Hermann Weyl]]
[[File:Guido Fubini.jpg|thumb|Guido Fubini]]

The 1928 Bologna ICM had 265 invited speakers , including Banach, Bernstein, G.D. Birkhoff, Bompiana, Borel, Cartan, Čech, Courant, Fano, Fields, Fisher, Fréchet, Fubini, Haar, Hadamard, Hilbert, Julia, Lévy, Levi-Civita, Menger, Milne-Thomson, Mordell, Nevanlinna, Neyman, Nikodym, E. Noether,  Ore, Plancherel, Pólya, Rademacher, Reidemeister, F. Rietz, Segre, Severi, Sierpiński, Steinhaus, Tarski, Veblen, Vitali, Volterra, Weyl, Whittaker, Zariski, and Zygmund.
{{div col|colwidth=12em}}
*[[Giacomo Albanese]]
*[[Giuseppe Albenga]]
*[[Pavel Alexandrov]]
*[[Luigi Amoroso]]
*{{ill|Dániel Arany|eo}}
*[[Raymond Clare Archibald]]
*[[Emilio Artom]]
*[[José Babini]]
*[[Richard Baldus]]
*[[Stefan Banach]]
*[[Paul Jean Joseph Barbarin]]
*[[Nina Bary]]
*[[Sergei Natanovich Bernstein]]
*[[Ludwig Berwald]]
*[[Cornelis Benjamin Biezeno]]
*{{ill|Anton Bilimovič|sr|Антон_Билимовић}}
*[[George David Birkhoff]]
*[[Juan Blaquier]]
*[[Wilhelm Blaschke]]
*[[André Blondel]]
*[[Harald Bohr]]
*[[Enrico Bompiani]]
*[[Tommy Bonnesen]]
*[[Émile Borel]]
*{{ill|Enea Bortolotti|it}}
*[[Ettore Bortolotti]]
*{{ill|Farid Boulad Bey|fr}}
*[[Max Brückner]]
*[[Louis Marcel Brillouin]]
*{{ill|Ugo Broggi|it|Ugo Napoleone Giuseppe Broggi}}
*[[Thomas John I'Anson Bromwich]]
*[[Daniel Buchanan (mathematician)|Daniel Buchanan]]
*[[Adolphe Buhl]]
*{{ill|Pietro Burgatti|it}}
*[[Bohumil Bydzowsky]]
*[[Angelina Cabras]]
*[[Renato Caccioppoli]]
*[[Giacomo Candido]]
*[[Francesco Paolo Cantelli]]
*[[Élie Cartan]]
*[[Giuseppe Casazza]]
*{{ill|Ugo Cassina|it}}
*[[Guido Castelnuovo]]
*[[Ettore Cavalli]]
*[[Eduard Čech]]
*[[Jean Chazy]]
*{{ill|Salvatore Cherubino|it}}
*[[P'ei-Yuan Chou]]
*[[Leon Chwistek]]
*[[Louis Crelier]]
*[[Stephan Cohn-Vossen]]
*[[Richard Courant]]
*[[Georges Darmois]]
*[[Boris Delaunay]]
*[[Bruno de Finetti]]
*[[Béla Kerékjártó]]
*[[Paul Clément Delens]]
*{{ill|Alfred Denizot|pl}}
*[[Alfred Cardew Dixon]]
*[[Wilhelm Dobbernack]]
*[[Jules Drach]]
*[[L. Gustave du Pasquier]]
*{{ill|Karel Dusl|sk}}
*[[Arnold Emch]]
*[[Federigo Enriques]]
*[[Gino Fano]]
*[[Luigi Fantappiè]]
*[[John Charles Fields]]
*[[Ronald Fisher]]
*[[Paul Flamant]]
*[[Maurice Fréchet]]
*[[Abraham Fraenkel]]
*[[Guido Fubini]]
*[[Rudolf Fueter]]
*[[André Gérardin]]
*{{ill|Harald Geppert|it}}
*{{ill|Giuseppe Gianfranceschi|de}}
*[[Oliver Edmunds Glenn]]
*[[Lucien Godeaux]]
*[[Stanisław Gołąb]]
*[[Ferdinand Gonseth]]
*[[Aleksander Grużewski]]
*[[Alf Victor Guldberg]]
*[[Emil Julius Gumbel]]
*[[Nikolai Günther]]
*[[Alfréd Haar]]
*[[Jacques Hadamard]]
*[[Hasso Härlen]]
*[[Karl-Gustav Hagstroem]]
*[[Mellen Woodman Haskell]]
*[[Nikolaos J. Hatzidakis]]
*[[Olive Hazlett]]
*[[Poul Heegaard]]
*[[Heinrich Hencky]]
*[[David Hilbert]]
*[[Václav Hlavatý]]
*{{ill|Bohuslav Hostinský|cs}}
*[[William Hovgaard]]
*[[Pierre Humbert (mathematician)|Pierre Humbert]]
*{{ill|Károly Jordan|de}}
*[[Christian Juel]]
*[[Gaston Maurice Julia]]
*[[Gustave Juvet]]
*[[Theodore von Kármán]]
*[[Gottfried Köthe]]
*[[Stefan Kaczmarz]]
*[[Sōichi Kakeya]]
*[[Joseph Kampé de Fériet]]
*[[Jovan Karamata]]
*[[Louis Charles Karpinski]]
*[[Edward Kasner]]
*[[Bronislaw Knaster]]
*[[Paul Koebe]]
*[[G. V. Kolosoff]]
*[[Mikhail Kravchuk]]
*[[Nikolay Mitrofanovich Krylov]]
*[[Rodion Kuzmin]]
*[[Paul Pierre Lévy]]
*[[Joseph Larmor]]
*[[Mikhail Lavrentieff]]
*[[Franciszek Leja]]
*[[Marcello Lelli]]
*[[Josef Lennertz]]
*[[Jean-Marie Le Roux]]
*[[Tullio Levi-Civita]]
*[[Harry Levy]]
*[[Hans Lewy]]
*[[Leon Lichtenstein]]
*{{ill|Antonio Loperfido|it}}
*[[Gino Loria]]
*[[Jan Łukasiewicz]]
*[[Nicolas Lusin]]
*[[Lazar Aronovich Lusternik]]
*[[Giorgina Madia]]
*{{ill|Gian Antonio Maggi|it}}
*[[Szolem Mandelbrojt]]
*[[Lucien March]]
*[[Roberto Marcolongo]]
*[[Arturo Maroni]]
*[[Pierre Massé]]
*[[Stefan Mazurkiewicz]]
*[[Albert Joseph McConnell]]
*[[Birger Meidell]]
*{{ill|Ernst Meissner|de}}
*[[Karl Menger]]
*[[Dmitrii Menshov]]
*[[Paul Mentré]]
*[[Augustin Mesnage]]
*[[Wilhelm Franz Meyer]]
*[[Gaspare Mignosi]]
*[[L. M. Milne-Thomson]]
*[[Edward Charles Molina]]
*[[Johannes Mollerup]]
*[[Louis J. Mordell]]
*[[Francis Dominic Murnaghan (mathematician)|Francis D. Murnaghan]]
*[[Pekka Juhana Myrberg]]
*[[Trygve Nagell]]
*[[Pia Nalli]]
*[[Otto E. Neugebauer]]
*[[Rolf Nevanlinna]]
*[[Jerzy Neyman]]
*{{ill|Władysław Nikliborc|pl}}
*[[Otto M. Nikodym]]
*[[Vittorio Nobile]]
*[[Emmy Noether]]
*[[Niels Erik Norlund]]
*[[Nikola Obrechkoff]]
*[[Octav Onicescu]]
*[[Øystein Ore]]
*[[Alessandro Padoa]]
*[[Konstantinos Papaioannou|C. Papaioannou]]
*{{ill|Nikolai Nikolaevich Parfentiev|ru|Парфентьев, Николай Николаевич}}
*[[Mario Pascal]]
*[[Oskar Perron]]
*[[Mihailo Petrovitch]]
*[[Georgii Yurii Pfeiffer|Georgii Pfeiffer]]
*[[Mauro Picone]]
*[[Salvatore Pincherle]]
*{{ill|Enrico Pistolesi|it}}
*[[Michel Plancherel]]
*[[George Arthur Plimpton]]
*[[George Pólya]]
*{{ill|Kyrille Popoff|es|Kiril Popov}}
*{{ill|Constantin C. Popovici|ro}}
*[[Umberto Puppini]]
*[[Gorakh Prasad]]
*[[Albert Quiquet]]
*[[Tibor Radó]]
*[[Hans Rademacher]]
*[[George Yuri Rainich]]
*[[Kurt Reidemeister]]
*[[Julio Rey Pastor]]
*[[Dimitri Riabouchinsky]]
*[[Frigyes Riesz]]
*[[René Risser]]
*[[Vsevolod Ivanovich Romanovsky]]
*{{ill|Alfred Rosenblatt|es}}
*[[Alberto E. Sagastume Berra]]
*[[Nilos Sakellariou]]
*[[Stanislaw Saks]]
*[[Gustavo Sannia]]
*[[Giovanni Sansone]]
*[[Francesco Sbrana]]
*[[Gerrit Schaake]]
*[[Emil Schoenbaum]]
*[[Jan Arnoldus Schouten]]
*[[Beniamino Segre]]
*[[Francesco Severi]]
*{{ill|Filippo Sibirani|it}}
*[[Wacław Sierpiński]]
*[[Louis Lazarus Silverman]]
*[[Charles Herschel Sisam]]
*[[Eugen Slutsky]]
*[[James John Smith (electrical engineer)|James John Smith]]
*{{ill|Alexander Smurov|ru|Александр Антонович Смуров}}
*[[Virgil Snyder]]
*[[Carlo Somigliana]]
*[[Andreas Speiser]]
*{{ill|Luigi Stabilini|it}}
*[[Hugo Steinhaus]]
*[[Alexander William Stern]]
*[[Simion Stoilow]]
*[[Ellis Bagley Stouffer]]
*[[Paolo Straneo]]
*{{ill|Giulio Supino|it}}
*{{ill|Richard Suppantschitsch|sl|Rihard Zupančič}}
*[[Otto Szász]]
*[[Ralph Tambs Lyche]]
*[[Alfred Tarski]]
*{{ill|Alessandro Terracini|it}}
*[[Gerhard Thomsen]]
*[[Georges César Tiercy]]
*[[Stephen Timoshenko]]
*[[Sebastiano Timpanaro (physicist)|Sebastanio Timpanaro]]
*[[Leonida Tonelli]]
*[[Antonio Torroja Miret]]
*[[Francesco Tricomi]]
*[[Herbert Westren Turnbull]]
*[[Friedrich Maria Urban]]
*[[R. Vaidyanathaswamy]]
*[[Georges Valiron]]
*[[Henri Louis Vanderlinden]]
*[[Vladimir Varićak]]
*[[Oswald Veblen]]
*[[Quido Vetter]]
*[[Tirukkannapuram Vijayaraghavan]]
*[[Giuseppe Vitali]]
*{{ill|Otto Volk|de}}
*[[Vito Volterra]]
*{{ill|Jacob Evert de Vos van Steenwijk|nl}}
*[[Gheorghe Vranceanu]]
*{{ill|Alwin Walther|de}}
*[[Gleb Wataghin]]
*[[Rolin Wavre]]
*[[Alexander Weinstein]]
*[[Hermann Weyl]]
*[[E. T. Whittaker]]
*[[Sven Dag Wicksell]]
*[[Dorothy Wrinch]]
*[[William Henry Young]]
*[[Oscar Zariski]]
*{{ill|Panagiotis Zervos|el|Παναγιώτης Ζερβός}}
*[[Ziauddin Ahmad]]
*{{ill|Rihard Zupančič|sl}}
*[[Antoni Zygmund]]
*[[Eustachy Żyliński|Eustachy Karol Żyliński]]
{{div col end}}

===1932, Zürich===
[[File:ETH-BIB-Internationaler Mathematikerkongress, Zürich 1932-Portrait-Portr 10680-C-FL.tif|thumb|500px|Participants Zürich 1932]]
The 1932 ICM in Zürich had 258 invited speakers, including Ahlfors, Alexandroff, Bernays, Bernstein, Bieberbach, Borsuk, Carathéodory, both Cartans, Čech, Cesari, de Rham, Delsarte, Fehr, Fraenkel, Hadamard, Hardy, Hasse, Hille, Hopf, Hurewicz, Julia, Krull, Kuratowski, Lévy, Littlewood, Menger, Milne-Thomson, Mordell, Morse, Nevanlinna, E. Noether, Ore, Pauli, Pontryagin, F. Rietz, Seifert, Severi, Sierpiński, Ulam, Volterra, Whitehead, Wiener, Zaremba, and Zygmund.&lt;ref&gt;{{cite journal|author=Richardson, R. G. D.|title=International Congress of Mathematicians, Zurich, 1932|journal=Bull. Amer. Math. Soc.|volume=38|year=1932|pages=769–774|doi=10.1090/S0002-9904-1932-05491-X}}&lt;/ref&gt;
{{clear}}&lt;!---keep the following ((div col)) spreading over the full page width---&gt;
{{div col|colwidth=12em}}
*[[Clarence Raymond Adams]]
*[[Lars Valerian Ahlfors]]
*M. Akimoff
*[[James Waddell Alexander]]&lt;ref name=Inv1934&gt;{{cite journal|author=Richardson, R. G. D.|title=International Congress of Mathematicians, Zurich, 1932|journal=Bull. Amer. Math. Soc.|volume=38|year=1932|pages=769–774|doi=10.1090/S0002-9904-1932-05491-X}}&lt;/ref&gt;
*[[Pavel Alexandrov|P. Alexandroff]]
*[[Franz Alt (mathematician)|Franz Alt]]
*[[Luigi Amoroso]]
*Arschanikoff
*{{ill|Radu Bădescu|ro}}
*{{ill|Séverin Bays|de}}
*[[Giuseppe Belardinelli]]
*C. Belhôte
*[[Maurits Joost Belinfante]]
*[[Stefan Bergman]]
*[[Paul Bernays]]
*[[Sergei Bernstein]]&lt;ref name=Inv1934/&gt;
*[[Ludwig Berwald]]
*[[Ludwig Bieberbach]]&lt;ref name=Inv1934/&gt;
*[[Mieczysław Biernacki]]
*[[Anton Bilimovič|Antoine Bilimovitch]]
*[[Karl Bögel]]
*[[Nicolas Bogoliúboff]]
*[[Harald Bohr]]&lt;ref name=Inv1934/&gt;
*[[Karol Borsuk]]
*{{ill|Farid Boulad Bey|fr}}
*[[Heinrich Brandt]]
*[[Adolphe Buhl]]
*[[Giacomo Candido]]
*[[Constantin Carathéodry]]&lt;ref name=Inv1934/&gt;
*[[Torsten Carleman]]&lt;ref name=Inv1934/&gt;
*[[Sauveur Carrus]]
*[[Élie Cartan]]&lt;ref name=Inv1934/&gt;
*[[Henri Cartan]]
*[[Mary Lucy Cartwright]]
*[[Giuseppe Casazza]]
*[[Wilhelm Cauer]]
*[[Eduard Cech]]
*Georges Cerf
*[[Lamberto Cesari]]
*[[Ljubomir Chakaloff]]&lt;!--- written 'Tschakaloff' (1932) and 'Tchakaloff' (1936) in http://www.mathunion.org/db/ICM/Speakers/SortedByCongress.php data base---&gt;
*[[Marie Charpentier]]
*[[Jules Chuard]]
*{{ill|Silvio Cinquini|it}}
*[[James Andrew Clarkson]]
*{{ill|Annibale Comessatti|it}}
*[[Arthur William Conway]]
*[[Elizabeth Buchanan Cowley]]
*{{ill|Hubert Cremer|de}}
*{{ill|Umberto Crudeli|it}}
*[[Louise Duffield Cummings]]
*{{ill|Karl Dürr|de}}
*[[Robert d'Adhémar]]
*[[Francisco Miranda da Costa Lobo]]
*[[David van Dantzig]]
*[[Georges de Rham]]
*Adolfo Del Chiaro
*[[Paul Delens]]
*[[Jean Delsarte]]
*Basile Demtchenko
*[[Michel-Louis Guérard des Lauriers|L. Des Lauriers]]
*[[Max Deuring]]
*Jacques Devisme
*Odette Mongeaud-Devisme
*[[Lloyd Lyne Dines]]
*Pierre Dive
*[[Gustav Doetsch]]
*[[Jules Drach]]
*[[Paul Drumaux]]
*[[L. Gustave du Pasquier]]
*[[Samuel Dumas]]
*{{ill|Karel Dusl|sk}}
*[[Alfred Errera]]
*A. Establier
*[[Luigi Fantappiè]]
*[[Henri Fehr]]
*[[Lucien Féraud]]
*[[Bruno Finzi]]
*{{ill|Jonas Ekman Fjeldstad|nn}}
*[[Alfred Leon Foster]]
*[[Adolf Fraenkel]]
*[[Rudolf Fueter]]&lt;ref name=Inv1934/&gt;
*[[Godofredo Garcia]]
*{{ill|Harald Geppert|it}}
*[[André Gérardin]]
*[[Giovanni Giambelli]]
*[[Giovanni Giorgi]]
*[[Oliver Edmunds Glenn]]
*[[Lucien Godeaux]]
*[[Stanislaw Golab]]
*Karl Goldziher
*[[Ferdinand Gonseth]]
*[[Édouard Guillaume]]
*[[Alf Victor Guldberg]]
*[[Nikolai Günther|N. Gunther]]
*[[Max Gut]]
*[[Jules Haag]]
*[[Jacques Hadamard]]
*[[Hans Ludwig Hamburger]]
*[[Georg Hamel]]
*[[G. H. Hardy]]
*[[Helmut Hasse]]
*[[Nikolaos J. Hatzidakis]]
*[[Arend Heyting]]
*[[Einar Hille]]
*[[Nikolaus Hofreiter]]
*[[Temple Rice Hollcroft]]
*[[Heinz Hopf]]
*[[Zdeněk Horák]]
*{{ill|Hans Hornich|de}}
*{{ill|Gustav Hössjer|sv}}
*{{ill|Bohuslav Hostinský|cs}}
*[[Witold Hurewicz]]
*[[Édouard Husson (mathematician)|Édouard Husson]]
*[[Filadelfo Insolera]]
*Alexandre Ivanoff
*[[Maurice Janet]]
*[[Wenceslas S. Jardetzky]]
*[[Vojtěch Jarník]]
*[[Børge Jessen]]
*[[Ingebrigt Johansson]]
*[[Gaston Julia]]&lt;ref name=Inv1934/&gt;
*[[Gustave Juvet]]
*[[László Kalmár]]
*[[Joseph Kampé de Fériet]]
*[[Jovan Karamata]]
*[[Edward Kasner]]
*[[Boris Kaufmann]]
*[[Alfred Kienast]]
*[[Ludwig Friedrich Wilhelm August Kiepert]]
*[[Bronislaw Knaster]]
*[[Ervand Kogbetliantz]]
*[[Ernst Kolman]]
*[[Arthur Korn]]
*[[Gottfried Köthe]]
*M. Kourensky
*{{ill|Giulio Krall|de}}
*[[Mikhail Kravchuk]]
*H. Krebs
*[[Wolfgang Krull]]
*[[Nikolay Mitrofanovich Krylov]]
*[[Casimir Kuratowski]]
*L. Laboccetta
*[[Jean-Marie Le Roux|J. Le Roux]]
*[[Franciszek Leja]]
*[[Josef Lense]]
*[[Paul Lévy (mathematician)|Paul Lévy]]
*[[Edward Hubert Linfoot]]
*[[John Edensor Littlewood]]
*M. Long
*[[Gino Loria]]
*[[Irmgard Flügge-Lotz|Irmgard Lotz]]
*[[Kurt Mahler]]
*[[Wilhelm Erwin Otto Maier]]
*{{ill|Lucien Malavard|fr}}
*[[Szolem Mandelbrojt]]
*A. Marchand
*[[Karl Menger]]&lt;ref name=Inv1934/&gt;
*[[Paul Mentré]]
*A. Meyer-Jaccoud
*[[Henri Milloux]]
*[[L. M. Milne-Thomson]]
*Yukio Mimura
*[[Silvio Minetti]]
*[[Richard von Mises]]
*[[Edward Charles Molina]]
*[[Charles Napoleon Moore]]
*[[Louis J. Mordell]]
*[[Marston Morse]]&lt;ref name=Inv1934/&gt;
*[[Christian Moser (mathematician)|Christian Moser]]
*[[Ali Moustafa Mosharafa]]
*[[Otto Mühlendyck]]
*[[Wilhelm Müller (physicist)|Wilhelm Müller]]
*[[Chaim Herman Müntz]]
*[[Trygve Nagell]]
*[[Rolf Nevanlinna]]&lt;ref name=Inv1934/&gt;
*[[Eric Harold Neville]]
*[[Miron Nicolesco]]
*[[Emmy Noether]]&lt;ref name=Inv1934/&gt;
*[[Øystein Ore]]
*[[Raymond Edward Alan Christopher Paley]]
*[[Konstantinos Papaioannou|C.P. Papaïoannou]]
*[[Wolfgang Pauli]]&lt;ref name=Inv1934/&gt;
*[[Joseph Pérès]]
*[[Hans Petersson]]
*[[Mihailo Petrovitch]]
*[[Georgii Yurii Pfeiffer|Georgii Pfeiffer]]
*[[Sophie Piccard]]
*[[Mauro Picone]]
*[[Rózsa Politzer]]
*[[Hilda Pollaczek-Geiringer]]
*[[Lev Pontrjagin]]
*[[Kyrille Popoff]]
*[[Rodolphe Nicolas Raclis]]
*H. Rafael
*[[George Yuri Rainich]]
*[[Franz Rellich]]
*[[Arnold Reymond]]
*[[Dimitri Riabouchinsky]]
*[[Carlo Luigi Ricci]]
*Giovanni Ricci
*{{ill|Paul Riebesell|de}}
*[[Frédéric Riesz]]&lt;ref name=Inv1934/&gt;
*[[René Risser]]
*[[Vsevolod Romanovsky]]
*{{ill|Alfred Rosenblatt|es}}
*[[Charles Henry Rowe]]
*{{ill|Edgar Bonsak Schieldrop|no|Edgar B. Schieldrop}}
*[[Hermann Schlichting]]
*[[Harry Schmidt (mathematician)|Harry Schmidt]]
*[[Jan Arnoldus Schouten]]
*[[Günther Schulz]]
*[[Herbert Seifert]]
*{{ill|Petre Sergescu|ro}}
*[[Francesco Severi]]&lt;ref name=Inv1934/&gt;
*[[Wacław Sierpiński]]&lt;ref name=Inv1934/&gt;
*[[David Eugene Smith]]
*[[James John Smith (electrical engineer)|J.J. Smith]]
*[[Virgil Snyder]]
*[[Andreas Speiser]]
*{{ill|Julius Stenzel|de}}&lt;ref name=Inv1934/&gt;
*{{ill|Wolfgang Sternberg|de}}
*[[Carl Størmer]]
*[[Ellis Bagley Stouffer]]
*[[Paolo Straneo]]
*{{ill|Karl Strubecker|de}}
*[[John Lighton Synge]]
*[[Jacob David Tamarkin]]
*[[Gerhard Thomsen]]
*[[William Threlfall]]
*[[Georges Tiercy]]
*[[Leonida Tonelli]]
*{{ill|Angelo Tonolo|it}}
*[[Francesco Tricomi]]
*[[Ljubomir Chakaloff|L. Tschakaloff]]
*[[Sergey Chaplygin|S. Tschapligin]]
*[[:en:Nikolai Chebotaryov|N. Tschebotaröw]]&lt;ref name=Inv1934/&gt;
*[[Georges Tzitzéica]]
*[[Stanislaw Ulam]]
*{{ill|Egon Ullrich|de}}
*[[Georges Valiron]]&lt;ref name=Inv1934/&gt;
*{{ill|Quido Vetter|de}}
*[[Paul Félix Vincensini]]
*[[Tullio Viola]]
*[[Enrico Volterra]]
*[[Gheorghe Vrânceanu]]
*[[G. N. Watson]]
*[[Rolin Wavre]]&lt;ref name=Inv1934/&gt;
*[[Ernst August Weiss]]
*[[Rudolf Weyrich]]
*[[J. H. C. Whitehead]]
*[[Norbert Wiener]]
*{{ill|Witold Wilkosz|pl}}
*C.E. Winn
*[[Julius Wolff (mathematician)|Julius Wolff]]
*[[Dorothy Wrinch]]
*[[Alexander Wundheiler]]
*[[Stanisław Zaremba (mathematician)|Stanisław Zaremba]]
*Marie Zervos
*[[Antoni Zygmund]]
{{div col end}}

===1936, Oslo===
There were 191 invited speakers at the 1936 congress in Oslo, among them Ahlfors, Banach, Bateman, both Birkhoffs, Borel, Borsuk, Cartan, Cartwright, Courant, Cramér, Eilenberg, Erdős, Feller, Fréchet, Gelfond, Hesse, Hecke, Hurewicz, Lemaître, McShane, Menger, Mordell, Morley, Morse, both Newmans, Ore, Pólya, Rado, M. Riesz, Selberg, Siegel, Sierpinski, Skolem, Stone, Taussky, Veblen, Whitehead, and Wiener.
[[File:Samuel Eilenberg MFO.jpeg|thumb|Samuel Eilenberg]]
[[File:Erich Hecke.jpg|thumb|Erich Hecke]]
[[File:OswaldVeblen1915.jpg|thumb|Oswald Veblen]]

{{div col|colwidth=12em}}
*[[Leifur Asgeirsson]]
*[[Lars Valerian Ahlfors]]&lt;ref name=Inv&gt;Morse, Marston. "The international Congress in Oslo." Bulletin of the American Mathematical Society 42, no. 11 (1936): 777–781. {{doi|10.1090/S0002-9904-1936-06421-9}}&lt;/ref&gt;
*[[Franz Alt (mathematician)|Franz Alt]]
*[[Raymond Clare Archibald]]
*{{ill|Radu Bădescu|ro}}
*[[Stefan Banach]]&lt;ref name=Inv/&gt;
*[[Dan Barbilian]]
*[[Isaac Albert Barnett]]
*[[Harry Bateman]]
*[[Heinrich Adolph Behnke]]
*[[Harald Bergström]]
*[[George David Birkhoff]]&lt;ref name=Inv/&gt;
*[[Garrett Birkhoff]]
*[[Vilhelm Bjerknes]]&lt;ref name=Inv/&gt;
*[[Wilhelm Blaschke]]
*[[Carl Böhm]]
*[[Émile Borel]]
*[[Karol Borsuk]]
*{{ill|Farid Boulad Bey|fr}}
*[[Arthur Lyon Bowley]]
*{{ill|Marcel Brelot|fr}}
*[[Hendrik Bremekamp]]
*[[Viggo Brun]]
*[[Bohumil Bydžovský]]
*[[Élie Cartan]]&lt;ref name=Inv/&gt;
*[[Mary Lucy Cartwright]]
*[[Jean Cavaillès]]
*[[Arthur William Conway]]
*[[Arthur Herbert Copeland]]
*[[Johannes van der Corput]]&lt;ref name=Inv/&gt;
*[[Richard Courant]]
*[[Harald Cramér]]
*[[David van Dantzig]]
*[[Jules Drach]]
*[[Paul Drumaux]]
*{{ill|Karel Dusl|sk}}
*[[Samuel Eilenberg]]
*[[Paul Erdős]]
*[[Alfred Errera]]
*[[Robert Arthur Fairthorne]]
*[[Willy Feller]]
*[[Werner Fenchel]]
*[[Paul Flamant]]
*[[Maurice Fréchet]]&lt;ref name=Inv/&gt;
*[[Hans Freudenthal]]
*[[Ragnar Frisch]]
*[[Otto Frostman]]
*[[Rudolf Fueter]]&lt;ref name=Inv/&gt;
*[[Matsusaburo Fujiwara|Fujiwara Matsusaburo]]
*[[Solomon Gandz]]
*[[Alexander Gelfond]]&lt;ref name=Inv/&gt;
*{{ill|Harald Geppert|it}}
*[[Joseph E. Gillis]]
*[[Wallace Givens]]
*[[Lucien Godeaux]]
*[[Stanislaw Golab]]
*[[Rolf Harald Gran Olsson]]
*[[Emil Julius Gumbel]]
*[[Max Gut]]
*{{ill|Johannes Haantjes|de}}
*{{ill|Gerhard Haenzel|de}}
*[[Georg Hamel]]
*[[Douglas Rayner Hartree]]
*[[Helmut Hasse]]&lt;ref name=Inv/&gt;
*[[Erich Hecke]]&lt;ref name=Inv/&gt;
*[[Poul Heegaard]]
*[[Kurt August Hirsch]]
*[[Václav Hlavatý]]
*[[Nikolaus Hofreiter]]
*[[Zdeněk Horák]]
*[[Witold Hurewicz]]
*[[Maurice Janet]]
*[[Vojtěch Jarník]]
*{{ill|József Jelitai|hu|Jelitai József}}
*{{ill|Arvo Junnila|fi}}
*[[Gottfried Köthe]]
*[[Stefan Kaczmarz]]
*[[Jovan Karamata]]
*[[Boris Kaufmann]]
*[[Béla Kerékjártó]]
*[[Aleksandr Khinchin]]&lt;ref name=Inv/&gt;
*{{ill|Vladimir Kořínek|cs|Vladimír Kořínek (matematik)}}
*[[Ervand Kogbetliantz]]
*[[Maurice Kraitchik]]
*[[Franciszek Leja]]
*[[Georges Lemaître]]
*[[Théophile Lepage]]
*{{ill|Arthur Linder|de}}
*[[Louis Locher]]
*{{ill|Salomon Lubelski|pl}}
*[[Eugene Lukacs]]
*[[Kurt Mahler]]
*[[Szolem Mandelbrojt]]
*[[Frédéric Marty]]
*[[Karl Mayr (mathematician)|Karl Mayr]]
*[[Stanislaw Mazur]]
*[[William Hunter McCrea]]
*[[Edward James McShane]]
*[[Birger Meidell]]
*[[Clifford William Mendel]]
*[[Karl Menger]]
*[[Émile Merlin]]
*{{ill|Albert Metral|es}}
*[[Henri Milloux]]
*[[Edward Arthur Milne]]
*[[Edward Charles Molina]]
*[[Louis Joel Mordell]]&lt;ref name=Inv/&gt;
*[[Robert Edouard Moritz]]
*[[Frank Morley]]
*[[Marston Morse]]
*[[Theodore Motzkin]]
*[[Hugh P. Mulholland]]
*[[John Rogers Musselman]]
*[[Trygve Nagell]]
*[[Paul Nemenyi]]
*[[Otto E. Neugebauer]]&lt;ref name=Inv/&gt;
*[[Bernhard Hermann Neumann]]
*[[M. H. A. Newman]]
*[[Jakob Nielsen (mathematician)|Jakob Nielsen]]&lt;ref name=Inv/&gt;
*[[Fritz Noether]]
*{{ill|Evert Johannes Nyström|fi|E. J. Nyström}}
*[[Nikola Obrechkoff]]
*[[Albert Cyril Offord]]
*[[Rufus Oldenburger]]
*[[Octav Onicescu]]
*[[Øystein Ore]]&lt;ref name=Inv/&gt;
*[[Wladyslaw Roman Orlicz]]
*[[Carl Wilhelm Oseen]]&lt;ref name=Inv/&gt;
*[[Rózsa Péter]]
*[[George Pólya]]
*{{ill|Veikko Paatero|fi}}
*[[Konstantinos Papaioannou|C. P. Papaioannou]]
*{{ill|Alexandru Pantazi|ro}}
*[[Fred William Perkins, Jr.]]
*[[Ernst Peschl]]
*[[Sophie Piccard]]
*[[José María Planas Corbella]]
*[[Lev Semyonovich Pontrjagin]]
*{{ill|Maurice Potron|fr}}
*[[Hans Przibram]]
*[[Rodolphe Raclis]]
*[[Richard Rado]]
*{{ill|Erich Reissner|de}}
*{{ill|Tonio Rella|de|Anton Rella}}
*[[Paul Reece Rider]]
*{{ill|Paul Riebesell|de}}
*[[Marcel Riesz]]
*[[Harold Stanley Ruse]]
*[[Nilos Sakellariou]]
*[[Ricardo San Juan]]
*[[Juliusz Schauder]]
*[[Jan Arnoldus Schouten]]
*[[Henrik Selberg]]
*[[Muhammad Raziuddin Siddiqui|Raziuddin Siddiqui]]
*[[Carl Ludwig Siegel]]&lt;ref name=Inv/&gt;
*[[Waclaw Sierpinski]]
*[[Avadhesh Narayan Singh]]
*[[Thoralf Albert Skolem]]
*[[Virgil Snyder]]
*[[Andreas Speiser]]
*{{ill|Otto Spiess|de}}
*[[Carl Størmer]]&lt;ref name=Inv/&gt;
*{{ill|Wolfgang Sternberg|de}}
*[[Simion Stoilow]]
*[[Marshall Harvey Stone]]
*[[John Lighton Synge]]
*[[Edward Szpilrajn]]
*[[Sven Magnus Täcklind]]
*[[Ralph Tambs-Lyche]]
*[[Olga Taussky-Todd]]
*[[Ljubomir Chakaloff|L. Tchakaloff]]
*[[Victor Thébault]]
*[[John Todd (computer scientist)|John Todd]]
*[[Charles Chapman Torrance]]
*[[Gheorghe Tzitzéica]]
*{{ill|Egon Ullrich|de}}
*[[Victor Vâlcovici]]
*[[Manuel Sandoval Vallarta]]
*[[Oswald Veblen]]&lt;ref name=Inv/&gt;
*[[Kurt Vogel (historian)|Kurt Vogel]]
*[[Buzz M. Walker]]
*[[Rolin Wavre]]
*[[Tadeusz Wazewski]]
*[[Alexander Weinstein]]
*[[Hermann Weyl]]
*[[J. H. C. Whitehead]]
*[[David Vernon Widder]]
*[[Norbert Wiener]]&lt;ref name=Inv/&gt;
*[[Herman Wold]]
*[[Laurence Chisholm Young]]
*[[Kazimierz Zarankiewicz]]
{{div col end}}

===1950, Cambridge (USA)===
[[File:Eberhard Hopf.jpg|thumb|Eberhard Hopf]]
[[File:Shiing-Shen Chern.jpg|thumb|Shiing-Shen Chern]]
{{div col|colwidth=12em}}
*{{ill|Pedro Abellanas|es}}
*[[Abraham Adrian Albert]]
*[[Howard Wright Alexander]]
*[[Aldo Andreotti]]
*[[Richard Arens]]
*[[Cahit Arf]]
*[[Iacopo Barsotti]]
*[[Stefan Bergman]]
*[[Peter Gabriel Bergmann]]
*[[Harald Bergström]]
*[[Arne Beurling]]
*[[R. H. Bing]]
*[[Garrett Birkhoff]]
*[[Salomon Bochner]]
*[[Harald Bohr]]
*[[Raj Chandra Bose]]
*[[Alfred T. Brauer]]
*[[Florent Bureau]]
*[[Alberto Pedro Calderon]]
*[[Henri Cartan]]
*[[Mary Lucy Cartwright]]
*[[Richard Eliot Chamberlin]]
*[[Shiing Shen Chern]]
*[[Sarvadaman Chowla]]
*[[Alfred Hoblitzelle Clifford]]
*[[Edward Foyle Collingwood]]
*[[Charles Galton Darwin]]
*[[Harold Davenport]]
*[[Arnaud Denjoy]]
*[[Richard James Duffin]]
*{{ill|Albert Edrei|de}}
*[[Paul Erdős]]
*[[Gaetano Fichera]]
*[[Nathan Jacob Fine]]
*[[Ronald Martin Foster]]
*[[Ralph Fox]]
*[[Kurt Gödel]]
*[[Abe Gelbart]]
*[[Dario Graffi]]
*[[Jacques Hadamard]]
*[[Fritz Herzog]]
*[[Edwin Hewitt]]
*[[Kurt August Hirsch]]
*[[W. V. D. Hodge]]
*[[Eberhard Hopf]]
*[[Heinz Hopf]]
*[[Sze-Tsen Hu]]
*[[Witold Hurewicz]]
*[[Kenkichi Iwasawa]]
*[[Shizuo Kakutani]]
*[[Stephen Cole Kleene]]
*[[Hendrik Douwe Kloosterman]]
*[[Paul Lévy (mathematician)|Paul Lévy]]
*[[Hans Lewy]]
*[[Kurt Mahler]]
*[[Szolem Mandelbrojt]]
*[[Marston Morse]]
*[[George Polya]]
*[[Hans Rademacher]]
*[[Franz Rellich]]
*[[Joseph Fels Ritt]]
*[[Abraham Robinson]]
*[[Adolphe Rome]]
*[[Samarendra Nath Roy]]
*[[Luis Antonio Santalo]]
*[[Laurent Schwartz]]
*[[Beniamino Segre]]
*[[Atle Selberg]]
*[[Thoralf Skolem]]
*[[Alfred Tarski]]
*[[John von Neumann]]
*[[Abraham Wald]]
*[[André Weil]]
*[[Hassler Whitney]]
*[[Norbert Wiener]]
*[[Raymond Louis Wilder]]
*[[Oscar Zariski]]
{{div col end}}

===1954, Amsterdam===
[[File:Weil.jpg|thumb|André Weil]]


At the 1954 Congress of Mathematicians in Amsterdam, [[Richard Brauer]] announced his program for the [[classification of finite simple groups]].&lt;ref name="BoyerMerzbach2011"&gt;{{cite book|author1=[[Carl B. Boyer]]|author2=[[Uta C. Merzbach]]|title=A History of Mathematics|url=https://atiekubaidillah.files.wordpress.com/2013/03/a-history-of-mathematics-3rded.pdf|date=25 January 2011|publisher=John Wiley &amp; Sons|isbn=978-0-470-63056-3|page=592}}&lt;/ref&gt;

{{div col|colwidth=12em}}
*[[P. S. Alexandrov]]
*[[J. Barkley Rosser]]
*[[Heinrich Adolph Louis Behnke]]
*[[David Blackwell]]
*[[Karol Borsuk]]
*[[Richard Brauer]]
*[[Florent Bureau]]
*[[Mary Lucy Cartwright]]
*[[Lamberto Cesari]]
*[[K. Chandrasekharan]]
*[[Lothar Collatz]]
*[[H. S. M. Coxeter]]
*[[Harold Davenport]]
*[[Jean Dieudonné]]
*[[Joseph L. Doob]]
*[[Beno Eckmann]]
*[[Paul Erdős]]
*[[Arthur Erdélyi]]
*[[Gaetano Fichera]]
*[[Robert Fortet]]
*[[Hans Freudenthal]]
*[[Israel Gelfand]]
*[[Sydney Goldstein]]
*[[Harish Chandra]]
*[[Walter Kurt Hayman]]
*[[Magnus Rudolph Hestenes]]
*[[Einar Hille]]
*[[Edmund Hlawka]]
*[[Nathan Jacobson]]
*[[Børge Jessen]]
*[[Joseph Kampé de Fériet]]
*[[Kunihiko Kodaira]]
*[[A. N. Kolmogorov]]
*[[Đuro Kurepa]]
*[[André Lichnerowicz]]
*[[Paul Lorenzen]]
*[[Deane Montgomery]]
*[[Andrzej Mostowski]]
*[[Pekka Juhana Myrberg]]
*[[André Néron]]
*[[Jerzy Neyman]]
*[[S. M. Nikolskii]]
*[[Douglas Geoffrey Northcott]]
*{{ill|Christian Yvon Pauc|de}}
*[[Franz Rellich]]
*[[Beniamino Segre]]
*[[Jean-Pierre Serre]]
*[[Eduard Stiefel]]
*[[James Johnston Stoker]]
*[[Alfred Tarski]]
*[[Edward Charles Titchmarsh]]
*[[David van Dantzig]]
*[[John von Neumann]]
*[[Tadeusz Wazewski]]
*[[André Weil]]
*[[Alexander Weinstein]]
*[[Kentaro Yano (mathematician)|Kentaro Yano]]
*[[Kosaku Yosida]]
*[[Antoni Zygmund]]
{{div col end}}

===1958, Edinburgh===
[[Alexander Grothendieck]] ''(pictured)'' in his plenary lecture at the 1958 Congress outlined his programme "to create arithmetic geometry via a (new) reformulation of algebraic geometry, seeking maximal generality."&lt;ref&gt;{{Citation
 |authorlink    = Pierre Cartier (mathematician)
 |last          = Cartier
 |first         = Pierre
 |date          = 2004
 |chapter       = Un pays dont on ne connaîtrait que le nom (Grothendieck et les " motifs ")
 |chapter-url   = http://www.math.jussieu.fr/~leila/grothendieckcircle/cartier.pdf
 |language      = French
 |title         = Réel en mathématiques-psychanalyse et mathématiques
 |editor1-last  = Cartier
 |editor1-first = Pierre
 |editor2-last  = Charraud
 |editor2-first = Nathalie
 |publisher     = Editions Agalma
 |postscript    = , English translation: [http://xahlee.info/math/i/Alexander_Grothendieck_cartier.pdf A country of which nothing is known but the name: Grothendieck and "motives" ].
 |deadurl       = yes
 |archiveurl    = https://web.archive.org/web/20131029225443/http://www.math.jussieu.fr/~leila/grothendieckcircle/cartier.pdf
 |archivedate   = 2013-10-29
 |df            = 
}}&lt;/ref&gt;
[[File:Alexander Grothendieck.jpg|thumb|right|Alexander Grothendieck]]

{{div col|colwidth=12em}}
*[[A. D. Alexandrov]]
*[[V. I. Arnold]]
*[[Lipman Bers]]
*[[Evert Willem Beth]]
*[[N. N. Bogolyubov]]
*[[Raoul Bott]]
*[[Henri Cartan]]
*[[S. S. Chern]]
*[[Claude Chevalley]]
*[[Kai Lai Chung]]
*[[Max Deuring]]
*[[Samuel Eilenberg]]
*[[William Feller]]
*[[Lars Gårding]]
*[[B. V. Gnedenko]]
*[[Hans Grauert]]
*[[Alexander Grothendieck]]
*[[Maurice Heins]]
*[[Graham Higman]]
*[[Friedrich Hirzebruch]]
*[[Joseph Ehrenfried Hofmann]]
*[[Stephen Cole Kleene]]
*[[Antoni Kosinski]]
*[[Georg Kreisel]]
*[[Đuro Kurepa]]
*[[Cornelius Lanczos]]
*[[Derrick Henry Lehmer]]
*[[Yuri Linnik]]
*[[Jacques-Louis Lions]]
*[[A. A. Markov]]
*[[Teruhisa Matsusaka]]
*[[Dmitrii Menshov]]
*[[John Willard Milnor]]
*[[Subbaramiah Minakshisundaram]]
*[[Masayoshi Nagata]]
*[[Albert Nijenhuis]]
*[[C. D. Papakyriakopoulos]]
*[[L. S. Pontryagin]]
*[[Alfréd Rényi]]
*[[Peter Roquette]]
*[[Klaus Friedrich Roth]]
*[[Heinz Rutishauser]]
*[[Pierre Samuel]]
*[[Leonard Jimmie Savage]]
*[[Menahem Max Schiffer]]
*[[Beniamino Segre]]
*[[Goro Shimura]]
*[[Norman Earl Steenrod]]
*[[Béla Szőkefalvi-Nagy]]
*[[George Frederick James Temple]]
*[[René Thom]]
*[[G. E. Uhlenbeck]]
*[[Adriaan van Wijngaarden]]
*[[V. S. Vladimirov]]
*[[Hsien Chung Wang]]
*[[Helmut Wielandt]]
{{div col end}}

===1962, Stockholm===
At the 1962 Congress in Stockholm [[Kiyosi Ito]] (pictured) lectured on how to combine [[differential geometry]] and [[stochastic analysis]], and this led to major advances in the 60s and 70s.&lt;ref name="Pier2000"&gt;{{cite book|author=Jean-Paul Pier|title=Development of Mathematics 1950-2000|url=https://books.google.com/books?id=rB7BjYsD2j4C&amp;pg=PA437|date=September 2000|publisher=Springer Science &amp; Business Media|isbn=978-3-7643-6280-5|page=437}}&lt;/ref&gt;
[[File:Kiyosi Ito.jpg|thumb|right|Kiyosi Ito]]

{{div col|colwidth=12em}}
*[[John Frank Adams]]
*[[Shmuel Agmon]]
*[[Aldo Andreotti]]
*[[Michael Francis Atiyah]]
*[[Maurice Auslander]]
*{{ill|Walter Baily|de}}
*[[Marcel Berger]]
*[[R. H. Bing]]
*[[Armand Borel]]
*[[Lennart Carleson]]
*[[J. W. S. Cassels]]
*[[Gustave Choquet]]
*[[Alonzo Church]]
*[[Paul Joseph Cohen]]
*[[Albrecht Dold]]
*[[Bernard Dwork]]
*[[E. B. Dynkin]]
*[[Beno Eckmann]]
*[[Leon Ehrenpreis]]
*[[Edwin E. Floyd]]
*[[Tudor Ganea]]
*[[I. M. Gelfand]]
*[[Harold Grad]]
*[[Hans Grauert]]
*[[Peter K. Henrici]]
*[[Heisuke Hironaka]]
*[[Lars Hörmander]]
*[[Gilbert Agnew Hunt]]
*[[Jun Igusa]]
*[[Kiyosi Ito]]
*{{ill|James Allister Jenkins|de}}
*[[Jean-Pierre Kahane]]
*[[Miroslav Katetov]]
*[[Michel André Kervaire]]
*[[Martin Kneser]]
*[[A. N. Kolmogorov]]
*[[A. I. Kostrikin]]
*[[Masatake Kuranishi]]
*[[Jean Leray]]
*[[Yuri Linnik]]
*[[Paul Malliavin]]
*[[John Milnor]]
*[[Jürgen Moser]]
*[[David Mumford]]
*[[Leopoldo Nachbin]]
*[[Rangaswamy Narasimhan]]
*[[M. H. A. Newman]]
*[[Louis Nirenberg]]
*[[P. S. Novikov]]
*[[I. I. Pjateckii-Sapiro]]
*[[Andrzej Pliś]]
*[[Valentin Poénaru]]
*[[I. R. Shafarevich]]
*[[Dana Scott]]
*[[Atle Selberg]]
*[[Jean-Pierre Serre]]
*[[G. E. Silov]]
*[[Yakov Sinai]]
*[[Stephen Smale]]
*[[John Robert Stallings, Jr.]]
*[[Guido Stampacchia]]
*[[Elias M. Stein]]
*[[Michio Suzuki]]
*[[Béla Szőkefalvi-Nagy]]
*[[John Tate]]
*[[John Griggs Thompson]]
*[[Jacques Tits]]
*[[John Wermer]]
*[[G. W. Whitehead]]
*[[Arthur Strong Wightman]]
{{div col end}}

===1966, Moscow===
[[File:John Griggs Thompson.jpg|thumb|John Griggs Thompson]]
[[File:Stephen Smale2.jpg|thumb|Stephen Smale]]
[[File:Carleson cropped.jpg|thumb|Lennart Carleson]]

There were thirty-one Invited Addresses (eight in Abstract) at the 1966 congress.&lt;ref&gt;{{cite book|title=Thirty-one Invited Address (eight in Abstract) at the International Congress of Mathematicians in Moscow, 1966|series=American Mathematical Society Translations - Series 2|url=https://books.google.com/books?id=f36tjwEACAAJ|year=1968|publisher=American Mathematical Society}}&lt;/ref&gt;
{{div col|colwidth=12em}}
*[[Shreeram Shankar Abhyankar]]
*[[John Frank Adams]]
*[[Mark Aronovich Aizerman]]
*[[D. V. Anosov]]
*[[V. I. Arnold]]
*[[Michael Artin]]
*[[Michael Francis Atiyah]]
*[[Hyman Bass]]
*[[Richard Bellman]]
*[[Bryan John Birch]]
*[[Errett Albert Bishop]]
*[[Aleksandr Alekseevich Borovkov|A. A. Borovkov]]
*[[William Browder (mathematician)|William Browder]]
*[[Alberto Pedro Calderon]]
*[[Lennart Carleson]]
*[[Jean Cerf]]
*[[Paul Joseph Cohen]]
*[[Ennio De Giorgi]]
*[[Jacques Dixmier]]
*[[Adrien Douady]]
*[[N. V. Efimov]]
*[[Peter Elias]]
*[[Ju. L. Ersov]]
*[[Paul R. Garabedian]]
*[[Frederick William Gehring]]
*[[V. M. Glushkov]]
*[[E. S. Golod]]
*[[Andrey Aleksandrovich Gonchar|A. A. Goncar]]
*{{ill|Mark Iosifovich Graev|ru|Граев, Марк Иосифович}}
*[[Hans Grauert]]
*[[Ulf Grenander]]
*[[André Haefliger]]
*[[Jack K. Hale]]
*[[Harish-Chandra]]
*[[Morris William Hirsch]]
*[[Ildar Abdulovich Ibragimov|I. A. Ibragimov]]
*[[Fritz John]]
*[[Adolph P. Yushkevich|Adolf P. Juskevic]]
*[[Wilhelm Klingenberg]]
*[[Joseph John Kohn]]
*[[Ellis Robert Kolchin]]
*[[M. G. Krein]]
*[[Olga Ladyzhenskaya]]
*[[Peter David Lax]]
*[[Olli Lehto]]
*[[Bernard Malgrange]]
*[[Anatoly Maltsev|A. I. Malzev]]
*[[Yuri I. Manin]]
*[[G. I. Marchuk]]
*[[Louis Michel (physicist)|Louis Michel]]
*[[Boris Mityagin|B. S. Mitjagin]]
*[[N. N. Moiseev]]
*[[André Néron]]
*[[Sergei P. Novikov]]
*[[Takashi Ono (mathematician)|T. Ono]]
*[[Victor Pavlovich Palamodov|V. P. Palamodov]]
*{{ill|Georges Papy|fr}}
*[[Aleksander Pełczyński|A. Pelczinsky]]
*[[Ilya Piatetski-Shapiro]]
*[[Vladimir Ivanovich Ponomarev|V. I. Ponomarev]]
*[[Aleksei Georgievich Postnikov]]
*[[Reinhold Remmert]]
*[[Hugo E. Rossi]]
*[[Johann Schröder (mathematician)|J. Schröder]]
*[[Kurt Schütte]]
*[[Irving Ezra Segal]]
*[[Goro Shimura]]
*{{ill|A. B. Sĭdlovsky|ru|Шидловский, Андрей Борисович}}
*[[Stephen Smale]]
*[[Sergei L. Sobolev]]
*[[Charles M. Stein]]
*[[Robert Steinberg]]
*[[Volker Strassen]]
*[[John Trevor Stuart]]
*[[John Griggs Thompson]]
*[[A. N. Tikhonov]]
*[[V. A. Toponogov]]
*[[Gregory S. Tseytin]]
*[[Kazimierz Urbanik]]
*[[Robert Lawson Vaught]]
*[[Edoardo Vesentini]]
*[[I. M. Vinogradov]]
*[[M. I. Vishik]]
*[[A. G. Vitushkin]]
*[[C. T. C. Wall]]
*[[James Hardy Wilkinson]]
*[[Erik Christopher Zeeman]]
{{div col end}}

===1970, Nice===
[[File:Michael Artin.jpg|thumb|Michael Artin]]
[[File:Philip Griffiths.jpeg|thumb|Philip Griffiths]]
[[File:David Mumford.jpg|thumb|David Mumford]]
[[File:Deligne.jpg|thumb|Pierre Deligne]]
[[File:John H Conway 2005 (cropped).jpg|thumb|John Horton Conway]]
[[File:Alan-Baker.jpg|thumb|Alan-Baker]]

{{div col|colwidth=12em}}
*[[S. I. Adjan]]
*[[Shmuel Agmon]]
*[[Vladimir Mikhailovich Alekseev]]
*[[Frederick J. Almgren, Jr.]]
*[[S. A. Amitsur]]
*[[Donald Werner Anderson]]
*[[Richard Davis Anderson]]
*[[Michel André (mathematician)|Michel André]]
*[[Aldo Andreotti]]
*[[Anatoli N. Andrianov]]
*[[N. U. Arakelyan]]
*[[Huzihiro Araki]]
*[[Alexander Arhangelskii]]
*[[Michael Artin]]
*[[Michael Francis Atiyah]]
*[[James Ax]]
*[[Alan Baker (mathematician)|Alan Baker]]
*[[Michael Barr (mathematician)|Michael Barr]]
*[[Oleg V. Besov]]
*[[A. V. Bitsadze]]
*[[Jean-Michel Bony]]
*[[Raoul Bott]]
*[[Louis Boutet de Monvel]]
*[[Richard Brauer]]
*[[Egbert Brieskorn]]
*[[Felix E. Browder]]
*[[William Browder (mathematician)|William Browder]]
*[[François Bruhat]]
*[[Donald L. Burkholder]]
*[[Pierre Cartier (mathematician)|Pierre Cartier]]
*[[J. W. S. Cassels]]
*[[A. V. Cernavskii]]
*[[Rafael Van Severen Chacon]]
*[[Shiing-Shen Chern]]
*[[Nikolai Chudakov]]
*[[Kai Lai Chung]]
*[[Paul Moritz Cohn]]
*[[Charles Cameron Conley]]
*[[John Horton Conway]]
*{{ill|Ivan Ilich Danilyuk|ru|Данилюк, Иван Ильич}}
*[[Pierre Deligne]]
*[[Aryeh Dvoretzky]]
*[[Eugene Dynkin]]
*[[David Gregory Ebin]]
*[[David Albert Edwards]]
*[[James Eells]]
*[[Yurii Vladimirovich Egorov|J. V. Egorov]]
*[[Kenneth David Elworthy]]
*[[Ju. L. Ersov]]
*[[F. Thomas Farrell]]
*[[Solomon Feferman]]
*[[Walter Feit]]
*[[James Michael Gardner Fell|J. M. G. Fell]]
*[[Ciprian Foias]]
*[[Frank Forelli]]
*{{ill|Otto Forster|de}}
*[[Bent Fuglede]]
*[[Harry Furstenberg]]
*[[Lars Gårding]]
*[[Israel Gelfand]]
*[[Ronald Kay Getoor]]
*[[Jean Giraud (mathematician)|Jean Giraud]]
*[[George Glauberman]]
*[[Daniel Gorenstein]]
*[[Phillip Griffiths]]
*[[Pierre Grisvard]]
*[[Detlef Gromoll]]
*[[M. L. Gromov]]
*[[Alexander Grothendieck]]
*[[Victor Vasilievich Grushin]]
*[[Victor Guillemin]]
*[[Robert Clifford Gunning]]
*[[Lars Hörmander]]
*[[Günter Harder]]
*[[Walter Kurt Hayman]]
*[[Sigurdur Helgason (mathematician)|Sigurdur Helgason]]
*[[Henry Helson]]
*[[Donald Gordon Higman]]
*[[Peter Hilton]]
*[[Heisuke Hironaka]]
*[[Wu-Chung Hsiang]]
*[[Richard Allen Hunt]]
*[[Yasutaka Ihara]]
*[[Kenkichi Iwasawa]]
*[[Zvonimir Janko]]
*[[Richard V. Kadison]]
*[[Max Karoubi]]
*[[Tosio Kato]]
*[[Nicholas Michael Katz]]
*[[Howard Jerome Keisler]]
*[[Harry Kesten]]
*[[Reinhardt Kiehl]]
*[[Robion Cromwell Kirby]]
*[[Steven Lawrence Kleiman]]
*[[Shoshichi Kobayashi]]
*[[Max Koecher]]
*[[Bertram Kostant]]
*[[A. I. Kostrikin]]
*[[Tomio Kubota]]
*[[Nicolaas Hendrik Kuiper]]
*[[Masatake Kuranishi]]
*[[Shige Toshi Kuroda]]
*[[Robert Phelan Langlands]]
*[[Richard Lashof]]
*[[Francis William Lawvere]]
*[[Peter David Lax]]
*[[Jerome Paul Levine]]
*[[B. M. Levitan]]
*[[Joram Lindenstrauss]]
*[[Jacques-Louis Lions]]
*[[Stanislaw Lojasiewicz]]
*[[Santiago Lopez de Medrano]]
*[[Ian G. Macdonald]]
*[[George Whitelaw Mackey]]
*[[Yuri I. Manin]]
*[[G. I. Marchuk]]
*[[Jerrold Eldon Marsden]]
*[[André Martineau]]
*[[Yu. V. Matijasevic]]
*[[Yves Meyer]]
*[[V. M. Millionščikov]]
*[[Mario Miranda]]
*[[B. G. Moishezon]]
*[[Gabriel Mokobodzki]]
*[[Paul Monsky]]
*[[John Coleman Moore]]
*[[Charles B. Morrey, Jr.]]
*[[George Daniel Mostow]]
*[[David Mumford]]
*[[Béla Szőkefalvi-Nagy]]
*[[M. A. Naimark]]
*[[M. S. Narasimhan]]
*[[Bernhard Hermann Neumann]]
*[[Sergei P. Novikov]]
*[[Olga Oleinik]]
*[[Donald S. Ornstein]]
*[[Richard Sheldon Palais]]
*[[Aleksei Nikolaevich Parshin|A. N. Paršin]]
*[[Bill Parry (mathematician)|Bill Parry]]
*{{ill|Jaak Peetre|et}}
*[[Franklin Paul Peterson]]
*[[Albrecht Pfister (mathematician)|Albrecht Pfister]]
*[[Frédéric Pham]]
*[[Ralph Saul Phillips]]
*[[A. V. Pogorelov]]
*[[Lev Pontryagin]]
*[[Charles C. Pugh]]
*[[Lajos Pukánszky]]
*[[Daniel Quillen]]
*[[Helmut Röhrl]]
*[[Michael Oser Rabin]]
*[[M. S. Raghunathan]]
*[[Michel Raynaud]]
*[[Daniel Rider]]
*[[Abraham Robinson]]
*[[Colin P. Rourke]]
*[[Walter Rudin]]
*[[Gerald Enoch Sacks]]
*[[Mikio Sato]]
*[[Vyacheslav Vasilievich Sazonov|V. V. Sazonov]]
*[[Andrzej Schinzel]]
*[[Wolfgang M. Schmidt]]
*[[Robert Thomas Seeley]]
*[[G. B. Segal]]
*[[I. E. Segal]]
*[[James Serrin]]
*[[C. S. Seshadri]]
*[[Igor Shafarevich]]
*[[Goro Shimura]]
*[[A. N. Shiryayev]]
*[[Laurent Siebenmann]]
*[[Yakov Sinai]]
*[[Maurice Sion]]
*[[Donald Clayton Spencer]]
*[[Vladimir Gennadievich Sprindzuk|V. G. Sprindzuk]]
*[[John R. Stallings]]
*[[Guido Stampacchia]]
*[[Harold Mead Stark]]
*[[Elias M. Stein]]
*[[Anatoly Mikhailovich Stepin]]
*[[Dennis Sullivan]]
*[[Michio Suzuki]]
*[[Richard G. Swan]]
*[[Masamichi Takesaki]]
*[[John Tate]]
*[[René Thom]]
*[[John Griggs Thompson]]
*[[Jacques Tits]]
*[[Jean-Claude Tougeron]]
*[[François Trèves]]
*[[Paul Turán]]
*[[Pyotr Lavrentyevich Ulyanov|P. L. Uljanov]]
*[[Nina Uraltseva]]
*[[Nicholas Varopoulos]]
*[[Petr Vopěnka]]
*[[C. T. C. Wall]]
*[[Robert Fones Williams]]
*[[Zvonimir Janko]]
{{div col end}}

===1974, Vancouver===
[[File:Jacques Tits (2008).jpg|thumb|Jacques Tits]]
[[File:Alain Connes.jpg|thumb|Alain Connes]]
[[File:William Thurston.jpg|thumb|William Thurston]]

{{div col|colwidth=12em}}
*[[Norbert A'Campo]]
*[[William K. Allard]]
*[[R. V. Ambartzumian]]
*[[D. V. Anosov]]
*[[S. J. Arakelov]]
*[[V. I. Arnold]]
*[[Claudio Baiocchi]]
*[[M. Salah Baouendi]]
*[[Wolf Barth]]
*[[Kenneth Jon Barwise]]
*[[Ja. M. Barzdin]]
*[[Hyman Bass]]
*[[Heinz Bauer]]
*[[Alain Bensoussan]]
*[[George Mark Bergman]]
*{{ill|Mikhail Shlemovich Birman|ru|Бирман, Михаил Шлёмович}}
*[[Enrico Bombieri]]
*[[Armand Borel]]
*[[Rufus Bowen]]
*[[James Henry Bramble]]
*[[Haim Brezis]]
*[[Victor Buchstaber]]
*[[Thomas Ashland Chapman]]
*[[Jeff Cheeger]]
*[[E. W. Cheney]]
*[[Zbigniew Ciesielski]]
*[[Herbert Clemens|Charles Herbert Clemens]]
*[[Alfred Hoblitzelle Clifford]]
*[[Jean-Michel Combes]]
*[[Alain Connes]]
*[[Michael Grain Crandall]]
*[[Gerard Debreu]]
*[[Pierre Deligne]]
*[[Vladimir F. Demyanov]]
*[[Roland Dobrushin]]
*[[Richard Mansfield Dudley]]
*[[G. F. D. Duff]]
*[[Michel Duflo]]
*[[J. J. Duistermaat]]
*[[E. B. Dynkin]]
*[[Mkhitar Djrbashian|M. M. Dzrbasjan]]
*[[David Eisenbud]]
*[[Per Enflo]]
*[[Jacques Faraut]]
*[[Charles Fefferman]]
*[[V. V. Filippov]]
*[[William J. Firey]]
*[[A. T. Fomenko]]
*[[Albrecht Fröhlich]]
*[[Eberhard Freitag]]
*[[Avner Friedman]]
*[[Harvey Friedman]]
*[[Howard Garland]]
*[[Frederick William Gehring]]
*[[S. M. Gersten]]
*[[James Glimm]]
*[[B. V. Gnedenko]]
*[[András Hajnal]]
*[[Thomas W. Hawkins Jr.|Thomas Hawkins]]
*[[Henry Hermes]]
*[[Horst Herrlich]]
*[[Alan J. Hoffman]]
*[[Christopher Hooley]]
*[[Roger Evans Howe]]
*[[Wu-Yi Hsiang]]
*[[Peter J. Huber]]
*[[Masahisa Inoue]]
*[[Bjarni Jónsson]]
*[[Hervé Jacquet]]
*[[A. A. Karacuba]]
*[[David Kazhdan]]
*[[David Kinderlehrer]]
*[[Victor Klee]]
*[[Daniel J. Kleitman]]
*[[Anthony W. Knapp]]
*{{ill|Nikolai Pavlovich Korneichuk|ru|Корнейчук, Николай Павлович}}
*[[Heinz-Otto Kreiss]]
*[[Wolfgang Krieger]]
*[[Harold J. Kushner]]
*[[Oscar Lanford]]
*[[H. Blaine Lawson]]
*[[Jacqueline Lelong-Ferrand]]
*[[A. F. Leontiev]]
*[[Elliott H. Lieb]]
*[[Rolf Lindner]]
*[[Jacques-Louis Lions]]
*[[George Lusztig]]
*[[G. A. Margulis]]
*[[Lawrence Markus]]
*[[André Martin]]
*[[Bernard Maskit]]
*[[John N. Mather]]
*[[Geoffrey Matthews]]
*[[Bernard Maurey]]
*[[Barry Mazur]]
*[[Victor Mazurov|V. D. Mazurov]]
*[[Kevin McCrimmon]]
*[[Peter McMullen]]
*[[Albert R. Meyer]]
*[[R. James Milgram]]
*[[Eric Charles Milner]]
*[[Hugh Lowell Montgomery]]
*[[P. A. P. Moran]]
*[[Yiannis N. Moschovakis]]
*[[Nikolay Nekhoroshev|N. N. Nehorosev]]
*[[Edward Nelson]]
*[[Jacques Neveu]]
*[[Louis Nirenberg]]
*[[Michael Stewart Paterson]]
*[[V. K. Patodi]]
*[[Mauricio Matos Peixoto]]
*[[Ted Petrie]]
*[[Vladimir Petrovich Platonov]]
*[[Daniel Quillen]]
*[[Richard Rado]]
*[[C. R. Rao]]
*[[John Robert Ringrose]]
*[[Claude Ambrose Rogers]]
*[[H. L. Royden]]
*[[Mary Ellen Rudin]]
*{{ill|S. S. Ryshkov|ru|Рышков, Сергей Сергеевич}}
*[[Alexander Andreevich Samarskii|A. A. Samarski]]
*{{ill|Winfried Scharlau|de|Winfried Scharlau (Mathematiker)}}
*[[Wolfgang M. Schmidt]]
*[[Paul A. Schweitzer]]
*[[Saharon Shelah]]
*[[Jack Silver]]
*[[Barry Simon]]
*[[Isadore Manuel Singer]]
*[[Andrei Alekseevich Slavnov|Andrei A. Slavnov]]
*[[Frank Spitzer]]
*{{ill|A. G. Sveshnikov|ru|Свешников, Алексей Георгиевич}}
*[[Erling Størmer]]
*{{ill|Vytautas Statulevičius|lt|Vytautas Statulevičius}}
*[[Sergei Aleksandrovich Stepanov|S. A. Stepanov]]
*[[Hans Jörg Stetter|Hans J. Stetter]]
*[[Gilbert Strang]]
*[[Volker Strassen]]
*[[Kurt Strebel]]
*{{ill|A. I. Subbotin|ru|Субботин, Андрей Измайлович}}
*[[Dennis Sullivan]]
*[[Moss Eisenberg Sweedler]]
*[[Endre Szemerédi]]
*[[Joseph L. Taylor]]
*[[William Thurston]]
*[[Jacques Tits]]
*[[Clifford Truesdell]]
*[[John Wilder Tukey]]
*[[V. S. Varadarajan]]
*[[A. N. Varchenko]]
*[[Anatoly Vershik]]
*[[M. I. Vishik]]
*[[A. G. Vitushkin]]
*[[Valentin Evgenyevich Voskresenskii]]
*[[Bertram Walsh]]
*[[John Walsh (mathematician)|John Walsh]]
*[[Benjamin Weiss]]
*[[James Hardy Wilkinson]]
*[[Philip Wolfe (mathematician)|Philip Wolfe]]
*[[C. E. Mike Yates]]
*[[Vladimir E. Zakharov]]
*[[Erik Christopher Zeeman]]
*[[D. P. Zhelobenko]]
{{div col end}}

===1978, Helsinki===
[[File:Roger Penrose at Festival della Scienza Oct 29 2011.jpg|thumb|Roger Penrose]]
[[File:Langlands2.jpg|thumb|Robert Langlands]]
[[File:Shing-Tung Yau at Harvard.jpg|thumb|Shing-Tung Yau]]

{{div col|colwidth=12em}}
*[[Lars Valerian Ahlfors]]
*[[Frederick J. Almgren, Jr.]]
*[[Huzihiro Araki]]
*[[Michael Aschbacher]]
*[[Michael Francis Atiyah]]
*[[Robert J. Aumann]]
*[[Albert Baernstein II]]
*[[Thomas Francis Banchoff]]
*[[William Beckner (mathematician)|William Beckner]]
*[[Irwin Bernstein]]
*[[Spencer Bloch]]
*[[F. A. Bogomolov]]
*[[O. I. Bogoyavlensky]]
*[[Jerry Bona]]
*[[A. A. Borovkov]]
*[[Kenneth Stephen Brown]]
*[[A. D. Bruno]]
*[[Pavol Brunovsky]]
*[[Alberto Pedro Calderon]]
*[[James Weldon Cannon]]
*[[Sylvain Edward Cappell]]
*[[William Casselman (mathematician)|William Casselman]]
*[[A. J. Casson]]
*[[G. V. Chudnovsky]]
*[[Francis H. Clarke]]
*[[John H. Coates]]
*[[Robert Connelly]]
*[[Alain Connes]]
*[[John Horton Conway]]
*[[Carl R. de Boor]]
*[[Claude Dellacherie]]
*[[Jacques Dixmier]]
*[[Manfredo P. do Carmo]]
*[[Roland Dobrushin]]
*[[Ronald George Douglas]]
*[[V. G. Drinfeld]]
*[[Robert Duncan Edwards]]
*[[Ivar Ekeland]]
*[[L. D. Faddeev]]
*[[Bernd Fischer (mathematician)|Bernd Fischer]]
*[[Ciprian Foias]]
*[[Jürg Fröhlich]]
*[[Dmitry Fuchs|Dmitry Fuks]]
*[[Masatoshi Fukushima]]
*[[Adriano Mario Garsia]]
*[[David Gieseker]]
*[[Daniel Gorenstein]]
*[[Phillip A. Griffiths]]
*[[M. L. Gromov]]
*[[Wolfgang Haken]]
*[[Leo Harrington]]
*[[Allen Edward Hatcher]]
*[[Michael Robert Herman]]
*[[Melvin Hochster]]
*[[Yulij Ilyashenko|Ju. S. Ilyashenko]]
*[[Victor Ivrii]]
*[[Henryk Iwaniec]]
*[[Sergey Yablonsky|S. V. Jablonskii]]
*[[Arthur Jaffe]]
*[[V. G. Kac]]
*[[Masaki Kashiwara]]
*[[Nicholas Michael Katz]]
*[[George Kempf]]
*[[Viatcheslav M. Kharlamov|V. M. Kharlamov]]
*[[A. A. Kirillov]]
*[[Boris Korenblum]]
*[[Nikolai N. Krasovskii]]
*[[Nicolai V. Krylov]]
*[[R. P. Langlands]]
*[[David G. Larman]]
*[[James Lepowsky]]
*[[Eduard Looijenga]]
*[[Ib Madsen]]
*{{ill|G. S. Makanin|ru|Маканин, Геннадий Семёнович}}
*[[John Mallet-Paret]]
*[[Yuri I. Manin]]
*[[Sibe Mardesic]]
*{{ill|A. I. Markushevich|ru|Маркушевич, Алексей Иванович}}
*[[Donald A. Martin]]
*[[Richard McGehee]]
*[[Henry P. McKean]]
*[[Richard Burt Melrose]]
*[[Jürgen Moser]]
*[[E. M. Nikishin]]
*[[Nikolai Kapitonovich Nikolski|N. K. Nikolskii]]
*[[Joachim A. Nitsche]]
*[[Sergei P. Novikov]]
*[[Robert Osserman]]
*[[Jacob Palis]]
*[[Roger Penrose]]
*[[Ilya Piatetski-Shapiro]]
*[[V. P. Platonov]]
*[[Claudio Procesi]]
*[[Paul H. Rabinowitz]]
*[[S. Ramanan]]
*[[Douglas Conner Ravenel]]
*[[P. A. Raviart]]
*[[Pal Revesz]]
*[[Andrei Vladimirovich Roiter]] &lt;!-- Ройтер, Андрей Владимирович --&gt;
*[[Gian-Carlo Rota]]
*[[Grzegorz Rozenberg]]
*[[Shoichiro Sakai]]
*[[Aleksandr Andreyevich Samarsky|A. A. Samarski]]
*[[Wilfried Schmid]]
*[[Goro Shimura]]
*[[Katsuhiro Shiohama]]
*[[A. N. Shiryayev]]
*[[Charles Coffin Sims]]
*[[Yakov Sinai]]
*[[Yum-Tong Siu]]
*[[Johannes Sjöstrand]]
*[[Henri Skoda]]
*[[Robert Irving Soare]]
*[[Andrei Suslin]]
*[[H. J. Sussmann]]
*[[Vidar Thomee]]
*[[William Paul Thurston]]
*[[Robert Tijdeman]]
*[[Kenji Ueno]]
*[[Dietmar Uhlig]]
*[[Jussi Vaisala]]
*[[Wilberd van der Kallen]]
*[[S. R. S. Varadhan]]
*[[Robert Charles Vaughan]]
*[[Nolan Russell Wallach]]
*[[André Weil]]
*[[Alexander Weinstein]]
*[[Alexander D. Wentzell]]
*[[J. E. West]]
*[[Shing-Tung Yau]]
*[[Gregg Jay Zuckerman]]
{{div col end}}

===1983, Warsaw===
[[File:René Thom.jpeg|thumb|René Thom]]
[[File:EfimIZelmanov.jpg|thumb|Efim Zelmanov]]
[[File:Pierre-Louis Lions par Philippe Binant.jpg|thumb|Pierre-Louis Lions]]
[[File:Jean Bourgain.jpg|thumb|Jean Bourgain]]

{{div col|colwidth=12em}}
*[[Michael Aizenman]]
*[[Antonio Ambrosetti]]
*[[Anatoli N. Andrianov]]
*[[V. I. Arnold]]
*[[James Arthur (mathematician)|James Arthur]]
*[[Richard Askey]]
*[[John MacLeod Ball]]
*[[Wolf Barth]]
*[[Alexander Beilinson]]
*[[Jean-Michel Bony]]
*[[Jean Bourgain]]
*[[David R. Brillinger]]
*[[Roger Ware Brockett]]
*[[V. S. Buslaev]]
*[[Luis Caffarelli]]
*[[Shiu-Yuen Cheng]]
*[[Gregory L. Cherlin]]
*[[D. M. Chibisov]]
*[[Frederick Ronald Cohen]]
*[[Ralph Louis Cohen]]
*[[B. E. J. Dahlberg]]
*[[Simon Kirwan Donaldson]]
*[[Bjorn Engquist]]
*[[Paul Erdős]]
*[[Gregory Eskin]]
*[[Tadeusz Figiel]]
*[[Wendell Helms Fleming]]
*[[Dominique Foata]]
*[[Jean-Marc Fontaine]]
*[[John Erik Fornaess]]
*[[Michael Hartley Freedman]]
*[[Hans Freudenthal]]
*[[William Fulton (mathematician)|William Fulton]]
*[[Jean-Yves Girard]]
*[[Roland Glowinski]]
*[[Gene Howard Golub]]
*[[R. L. Graham]]
*[[Robert Griess]]
*[[M. L. Gromov]]
*[[Joe Harris (mathematician)|Joe Harris]]
*[[D. R. Heath-Brown]]
*[[Gennadi M. Henkin]]
*[[Nigel James Hitchin]]
*[[Christopher Hooley]]
*[[Wu-Chung Hsiang]]
*[[Shigeru Iitaka]]
*[[V. A. Iskovskih]]
*[[R. S. Ismagilov]]
*[[Tadeusz Iwaniec]]
*[[Jens Carsten Jantzen]]
*[[Peter Wilcox Jones]]
*[[Anthony Joseph]]
*[[Feng Kang]]
*[[Richard Karp]]
*{{ill|B. S. Kašin|ru|Кашин, Борис Сергеевич}}
*[[G. G. Kasparov]]
*[[Anatole Katok]]
*[[Steven Paul Kerckhoff]]
*[[Harry Kesten]]
*[[L. G. Khachiyan]]
*[[A. G. Khovanskii]]
*[[Sergiu Klainerman]]
*[[Hans-Wilhelm Knobloch]]
*[[Nancy Kopell]]
*[[A. B. Kurzanskii]]
*[[Yuri A. Kuznetsov]]
*[[Olga Ladyzhenskaya]]
*[[Andrzej Lasota]]
*[[Peter David Lax]]
*{{ill|A. A. Letichevsky|ru|Летичевский, Александр Адольфович}}
*[[Wen-Hsiung Lin]]
*[[Pierre-Louis Lions]]
*[[Peter Albert Loeb]]
*[[László Lovász]]
*[[George Lusztig]]
*[[Wilhelm Müller]]
*[[Robert Duncan MacPherson]]
*[[Andrew Majda]]
*[[Paul Malliavin]]
*[[Benoit B. Mandelbrot]]
*[[Petr Mandl]]
*[[Ricardo Mane]]
*[[V. P. Maslov]]
*[[David William Masser]]
*[[Barry Mazur]]
*[[Yves Meyer]]
*[[Charles Anthony Micchelli]]
*[[Michal Misiurewicz]]
*[[Shigefumi Mori]]
*[[Arthur Ogus]]
*[[Alexander Yu. Olshanskii]]
*[[Toshio Oshima]]
*[[Konrad Osterwalder]]
*[[Rajagopalan Parthasarathy]]
*{{ill|Boris Pavlov (mathematician)|ru|Павлов, Борис Сергеевич}}
*[[Aleksander Pelczynski]]
*[[Sergey Pinchuk]]
*[[Gilles Pisier]]
*[[Gordon Plotkin]]
*[[A. V. Pogorelov]]
*[[M. J. D. Powell]]
*[[Michael O. Rabin]]
*[[Kenneth Alan Ribet]]
*[[Claus Michael Ringel]]
*[[R. T. Rockafellar]]
*[[David Ruelle]]
*[[Mikio Sato]]
*[[Wolfgang M. Schmidt]]
*[[Richard M. Schoen]]
*[[George Roger Sell]]
*[[James Serrin]]
*[[Julius L. Shaneson]]
*[[Saharon Shelah]]
*[[Richard Arnold Shore]]
*[[Yum-Tong Siu]]
*[[A. O. Slisenko]]
*[[Christophe Soulé]]
*[[Richard P. Stanley]]
*[[Daniel W. Stroock]]
*[[Yuri M. Svirezhev]]
*[[Leon Takhtajan]]
*[[Robert Tarjan]]
*[[Bernard Teissier]]
*[[René Thom]]
*[[Karen Uhlenbeck]]
*[[Leslie Gabriel Valiant]]
*[[J. H. van Lint]]
*[[Pierre van Moerbeke]]
*[[Alexei Venkov|A. B. Venkov]]
*[[Michèle Vergne]]
*[[E. B. Vinberg]]
*[[Oleg Yanovich Viro]]
*[[Dan-Virgil Voiculescu]]
*[[Jean-Loup Waldspurger]]
*[[Shinzo Watanabe]]
*[[S. L. Woronowicz]]
*[[Jerzy Zabczyk]]
*[[Vladimir E. Zakharov]]
*[[Efim Zelmanov]]
*[[Boris Zilber|B. I. Zilber]]
{{div col end}}

===1986, Berkeley===
[[File:Gerd Faltings MFO.jpg|thumb|Gerd Faltings]]
[[File:Edward Witten.jpg|thumb|Edward Witten]]

{{div col|colwidth=12em}}
*[[Alexei Borisovich Aleksandrov|A. B. Aleksandrov]]
*[[Hans Wilhelm Alt]]
*[[Taivo Arak]]
*[[Enrico Arbarello]]
*[[Maurice Auslander]]
*[[Tadeusz Balaban]]
*[[Hans Werner Ballmann]]
*[[Isabella Bashmakova]]
*[[Arnaud Beauville]]
*[[József Beck]]
*[[G. V. Belyi]]
*[[Jean-Michel Bismut]]
*[[Anders Björner]]
*[[Manuel Blum]]
*[[Walter Borho]]
*[[Mikhail V. Borovoi]]
*[[H. J. M. Bos]]
*[[Jean Bourgain]]
*[[Franco Brezzi]]
*[[Michel Broué]]
*[[Robert Bryant (mathematician)|Robert Bryant]]
*[[Gunnar Carlsson]]
*[[A. J. Casson]]
*[[David Catlin]]
*[[Sun-Yung Alice Chang]]
*[[Jeff Cheeger]]
*[[Alexandre Joel Chorin]]
*[[Herbert Clemens]]
*[[Laurent Clozel]]
*[[Yves Colin de Verdière]]
*[[Jean-Louis Colliot-Thelene]]
*[[Alain Connes]]
*[[Germund Dahlquist]]
*[[Guy David]]
*[[Alexander Munro Davie]]
*[[M. H. A. Davis]]
*[[Louis de Branges]]
*[[Corrado De Concini]]
*[[Ronald J. DiPerna]]
*[[Simon Kirwan Donaldson]]
*[[Adrien Douady]]
*[[V. G. Drinfeld]]
*[[Jean-Pierre Eckmann]]
*[[Edward George Effros]]
*[[Georgy Petrovich Egorychev|G. P. Egorychev]]
*[[Yakov Eliashberg]]
*[[Lawrence Craig Evans]]
*[[Gerd Faltings]]
*[[Jürg Fröhlich]]
*[[Péter Frankl]]
*[[Igor Frenkel]]
*[[Pierre Gabriel]]
*[[Giovanni Gallavotti]]
*[[John B. Garnett]]
*[[Krzysztof Gawedzki]]
*[[Frederick William Gehring]]
*[[Stuart Geman]]
*[[Mariano Giaquinta]]
*[[Vitaly Ginzburg]]
*[[Efim D. Gluskin]]
*[[S. K. Godunov]]
*[[Dorian Goldfeld]]
*[[Andrey Aleksandrovich Gonchar|A. A. Gonchar]]
*[[J. V. Grabiner]]
*[[Christine Graffigne]]
*[[D. Yu. Grigor'ev]]
*[[M. L. Gromov]]
*[[Benedict Hyman Gross]]
*[[Uffe Haagerup]]
*[[Richard S. Hamilton]]
*[[Robert Miller Hardt|R. M. Hardt]]
*[[Thomas W. Hawkins, Jr.]]
*[[Dennis Arnold Hejhal]]
*[[Haruzo Hida]]
*[[Werner Hildenbrand]]
*[[Alexander Holevo]]
*[[Victor Ivrii]]
*[[Henryk Iwaniec]]
*[[M. V. Jakobson]]
*[[V. F. R. Jones]]
*[[Jürgen Jost]]
*[[Jean-Pierre Kahane]]
*[[Narendra Karmarkar]]
*[[David Kazhdan]]
*[[Alexander S. Kechris]]
*[[Carlos Eduardo Kenig]]
*[[Helmut Koch (mathematician)|H. V. Koch]]
*{{ill|V. V. Kozlov|ru|Козлов,_Валерий_Васильевич}}
*[[Rafail Krichevskii|R. E. Krichevsky]]
*[[N. G. Kruzhilin]]
*{{ill|A. V. Kryazhimskii|ru|Кряжимский, Аркадий Викторович}}
*[[Nicolai V. Krylov]]
*[[Hiroshi Kunita]]
*[[Ivan A. K. Kupka]]
*[[Philip Caesar Kutzko]]
*[[Alistair H. Lachlan]]
*[[Oscar Lanford]]
*[[László Lempert]]
*[[Hendrik Willem Lenstra]]
*[[Thomas Milton Liggett]]
*[[Menachem Magidor]]
*[[Nikolai Georgievich Makarov|Nikolai G. Makarov]]
*[[Yuri I. Manin]]
*[[John N. Mather]]
*[[William Hamilton Meeks, III]]
*[[Alexander Merkurjev]]
*[[Jean-François Mertens]]
*[[Haynes Miller]]
*[[Vitali Milman]]
*[[Tetsuji Miwa]]
*[[John Willard Morgan]]
*[[V. V. Nikulin]]
*[[Andrew Michael Odlyzko]]
*[[Steven Alan Orszag]]
*[[George C. Papanicolaou]]
*[[L. A. Pastur]]
*[[Mikhail G. Peretyatkin]]
*[[Yakov Pesin]]
*[[Nicholas Pippenger]]
*[[Vladimir L. Popov]]
*[[Frank Quinn (mathematician)|Frank Quinn]]
*[[A. A. Razborov]]
*[[John Rinzel]]
*[[Ernst Alfred Ruh]]
*[[Arnold Schönhage]]
*[[Vladimir Scheffer]]
*[[Richard Melvin Schoen]]
*[[Alexander Schrijver]]
*[[Jacob T. Schwartz]]
*[[Zbigniew Semadeni]]
*[[Caroline Series]]
*[[Paul D. Seymour]]
*[[Peter B. Shalen]]
*[[Adi Shamir]]
*[[Micha Sharir]]
*[[Saharon Shelah]]
*[[V. V. Shokurov]]
*[[A. V. Skorokhod]]
*[[Stephen Smale]]
*{{ill|V. A. Solonnikov|ru|Солонников, Всеволод Алексеевич}}
*[[Thomas Spencer (mathematical physicist)|Thomas Spencer]]
*[[Elias M. Stein]]
*[[Charles Joel Stone]]
*[[Dennis Sullivan]]
*[[A. A. Suslin]]
*[[Floris Takens]]
*[[Clifford Taubes]]
*[[Tammo tom Dieck|Tammo Tom Dieck]]
*[[Anthony Joseph Tromba]]
*[[Nina Uraltseva]]
*[[Eckart Viehweg]]
*[[David Alexander Vogan]]
*[[Gisbert Wüstholz]]
*[[Henry Christian Wente]]
*[[Alex Wilkie]]
*[[R. L. Wilson]]
*[[Edward Witten]]
*[[Thomas Hartwig Wolff]]
*[[Scott Andrew Wolpert]]
*[[W. Hugh Woodin]]
*[[Wu Wen-Tsun]]
*[[Victor Yakhot]]
*[[Don Zagier]]
*[[Eduard Zehnder]]
*[[Robert Jeffrey Zimmer]]
{{div col end}}

===1990, Kyoto===
[[File:Grigorji Margulis.jpg|thumb|Grigorji Margulis]]
[[File:Vaughan Jones p1190550.jpg|thumb|Vaughan Jones]]
[[File:Curtis T. McMullen.jpg|thumb|Curtis T. McMullen]]
[[File:Jean-Christophe Yoccoz.jpg|thumb|Jean-Christophe Yoccoz]]
[[File:Shigefumi Mori.jpg|thumb|Shigefumi Mori]]

{{div col|colwidth=12em}}
*[[Noga Alon]]
*[[Marcel Bökstedt]]
*[[László Babai]]
*[[Dan Barbasch]]
*[[Martin T. Barlow]]
*[[Rodney James Baxter]]
*[[Eric Douglas Bedford]]
*[[Spencer Bloch]]
*[[Lenore Blum]]
*[[Francis Bonahon]]
*[[César Camacho]]
*[[Peter J. Cameron]]
*[[Lennart Carleson]]
*[[Jon F. Carlson]]
*[[Alexandre L. Chistov]]
*[[Michael Christ]]
*[[Demetrios Christodoulou]]
*[[Ronald Raphael Coifman]]
*[[Stephen Arthur Cook]]
*[[Jean-Michel Coron]]
*[[Joachim Cuntz]]
*[[Persi Diaconis]]
*[[Roland L. Dobrushin]]
*[[Sergio Doplicher]]
*[[Richard Timothy Durrett]]
*[[Jean Écalle]]
*[[Boris L. Feigin]]
*[[Joel Feldman]]
*[[Andreas Floer]]
*[[Kenji Fukaya]]
*[[Hillel Furstenberg]]
*[[Matthias Günther]]
*[[David Gabai]]
*[[Étienne Ghys]]
*[[Henri Gillet]]
*[[Shafi Goldwasser]]
*[[Thomas G. Goodwillie]]
*[[Cameron Gordon (mathematician)|Cameron Gordon]]
*[[Rostislav Grigorchuk]]
*[[Karsten Grove]]
*[[Günter Harder]]
*[[Ami Harten]]
*[[Helmut Hofer]]
*[[Philip Holmes]]
*[[Annick Horiuchi]]
*[[Ehud Hrushovski]]
*[[Craig Huneke]]
*[[Martin Huxley]]
*[[Kiyoshi Igusa]]
*[[Yasutaka Ihara]]
*[[Mitsuru Ikawa]]
*[[Yulij Ilyashenko|Ju. S. Ilyashenko]]
*[[Alexander A. Ivanov]]
*[[Michio Jimbo]]
*[[Lowell E. Jones]]
*[[Vaughan F. R. Jones]]
*[[William Morton Kahan]]
*[[Alexander V. Karzanov]]
*[[Masaki Kashiwara]]
*[[Kazuya Kato]]
*[[Yujiro Kawamata]]
*[[Alexander R. Kemer]]
*[[János Kollár]]
*[[Victor Kolyvagin]]
*[[Shinichi Kotani]]
*[[Robert Krasny]]
*[[Igor Krichever]]
*[[Peter B. Kronheimer]]
*[[Antti Kupiainen]]
*[[Shigeo Kusuoka]]
*[[Jesper Lützen]]
*[[Gérard Laumon]]
*[[Robert Kendall Lazarsfeld]]
*[[Lucien Marie Le Cam]]
*[[Gilles Lebeau]]
*[[Fang-Hua Lin]]
*[[Pierre-Louis Lions]]
*[[László Lovász]]
*[[George Lusztig]]
*[[Colette Moeglin]]
*[[Andrew Joseph Majda]]
*[[Yuri I. Manin]]
*[[Grigory Margulis]]
*[[Olivier Mathieu]]
*[[Toshihiko Matsuki]]
*[[Dusa McDuff]]
*[[Curt McMullen]]
*[[Richard Burt Melrose]]
*[[Yves F. Meyer]]
*[[John J. Millson]]
*[[Masayasu Mimura]]
*[[Stanislav A. Molchanov]]
*[[Masatake Mori]]
*[[Shigefumi Mori]]
*[[Shigeyuki Morita]]
*[[Henri Moscovici]]
*[[Takafumi Murai]]
*[[Haruo Murakami]]
*[[Anatoly I. Neishtadt]]
*[[Yuri Valentinovich Nesterenko]]
*[[Sheldon E. Newhouse]]
*[[Adrian Ocneanu]]
*[[Takeo Ohsawa]]
*[[Michael V. Pimsner]]
*[[Sorin Popa]]
*[[Gopal Prasad]]
*[[David Preiss]]
*[[Vojtěch Rödl]]
*[[Stephen Rallis]]
*[[Mary Rees]]
*[[James Renegar]]
*[[Nicolai Reshetikhin]]
*[[Paul Calvin Roberts]]
*[[Klaus Wilhelm Roggenkamp]]
*[[Kyoji Saito]]
*[[Morihiko Saito]]
*[[Leslie Saper]]
*[[Peter Clive Sarnak]]
*[[Pierre Schapira (mathematician)|Pierre Schapira]]
*[[Albert Schwarz]]
*[[Graeme Segal]]
*[[Tetsuji Shioda]]
*[[Eugenii I. Shustin]]
*[[Nessim Sibony]]
*[[Israel Michael Sigal]]
*[[Carlos Tschudi Simpson]]
*[[Yakov Sinai]]
*[[Georges Skandalis]]
*[[Theodore Allen Slaman]]
*[[John R. Steel]]
*[[Joseph H. M. Steenbrink]]
*[[Michael Struwe]]
*[[Toshikazu Sunada]]
*[[Kanehisa Takasaki]]
*[[Michel Talagrand]]
*[[Éva Tardos]]
*[[Luc Tartar]]
*[[Michael E. Taylor]]
*[[Robert W. Thomason]]
*[[Carsten Thomassen]]
*[[Gang Tian]]
*[[Akihiro Tsuchiya]]
*[[Vladimir Turaev]]
*[[Karen Uhlenbeck]]
*[[Lou van den Dries]]
*[[Alexandre Varchenko]]
*[[Nicholas Theodore Varopoulos]]
*[[Paul Vojta]]
*[[Alexander Volberg]]
*[[Avi Wigderson]]
*[[S. L. Woronowicz]]
*[[Jean-Christophe Yoccoz]]
*[[Marc Yor]]
*[[Efim Zelmanov]]
{{div col end}}

===1994, Zürich===
[[File:Andrew wiles1-3.jpg|thumb|Andrew Wiles]]
[[File:Perelman, Grigori (1966).jpg|thumb|Grigori Perelman]]
[[File:Richard Borcherds.jpg|thumb|Richard Borcherds]]
[[File:MaximKontsevich.jpg|thumb|Maxim Kontsevich]]

{{div col|colwidth=12em}}
*[[Jeffrey Adams (mathematician)|Jeffrey Adams]]
*[[Andrei A. Agrachev]]
*[[Henning Haahr Andersen]]
*[[Michael T. Anderson]]
*[[Marco Avellaneda]]
*[[László Babai]]
*[[Victor Bangert]]
*[[Richard F. Bass]]
*[[James E. Baumgartner]]
*[[J. Thomas Beale]]
*[[Jean Bellissard]]
*[[A. A. Bolibruch]]
*[[Sergey V. Bolotin]]
*[[Richard Ewen Borcherds]]
*[[Jean Bourgain]]
*[[Michel Brion]]
*[[Marc Burger]]
*[[Colin J. Bushnell]]
*[[Kung Ching Chang]]
*[[Jean-Yves Chemin]]
*[[Fan R. K. Chung]]
*[[Philippe G. Ciarlet]]
*[[Phillip Colella]]
*[[Peter Constantin]]
*[[John Horton Conway]]
*[[Kevin Corlette]]
*[[Constantine Michael Dafermos]]
*[[Wolfgang Dahmen]]
*[[S. G. Dani]]
*[[Ingrid Daubechies]]
*[[Donald Andrew Dawson]]
*[[Jean-Pierre Demailly]]
*[[David L. Donoho]]
*[[David Drasin]]
*[[Noam Elkies]]
*[[George A. Elliott]]
*[[Gerd Faltings]]
*[[Giovanni Felder]]
*[[Hans Föllmer]]
*[[Jürg Fröhlich]]
*[[John Franks (mathematician)|John Franks]]
*[[Edward Frenkel]]
*[[John B. Friedlander]]
*[[Zoltán Füredi]]
*[[Jürgen Gärtner]]
*[[Alexander Givental]]
*[[Oded Goldreich]]
*[[Gene H. Golub]]
*[[Robert Ernest Gompf]]
*[[Alexander Goncharov]]
*[[William Timothy Gowers]]
*[[Andrew Granville]]
*[[Manoussos G. Grillakis]]
*[[David Harbater]]
*[[Jan P. Hogendijk]]
*[[Michael Jerome Hopkins]]
*[[Deborah Hughes Hallett]]
*[[Uwe Jannsen]]
*[[David Jerison]]
*[[Mark Jerrum]]
*[[Jeffry Kahn]]
*[[Gil Kalai]]
*[[Nikolaos Kapouleas]]
*[[Joseph B. Keller]]
*[[Eugene Khruslov]]
*[[Eberhard Kirchberg]]
*[[Frances Kirwan]]
*[[Maxim Kontsevich]]
*[[Olga Ladyzhenskaya]]
*[[Jean Lannes]]
*[[H. Blaine Lawson]]
*[[Claude LeBrun]]
*[[François Ledrappier]]
*[[Tom Leighton]]
*[[Leonid Levin]]
*[[Jian-Shu Li]]
*[[Jun Li (mathematician)|Jun Li]]
*[[Elliott H. Lieb]]
*[[Pierre-Louis Lions]]
*[[Peter Littelmann]]
*[[Roberto Longo]]
*[[Alain Louveau]]
*[[Alexander Lubotzky]]
*[[John Luecke]]
*[[Mikhail Lyubich]]
*[[Zhi-Ming Ma]]
*[[Ricardo Mane]]
*[[Howard Masur]]
*[[Hiroshi Matano]]
*[[David W. McLaughlin]]
*[[Joyce R. McLaughlin]]
*[[Jean-François Mestre]]
*[[Yoichi Miyaoka]]
*[[Ngaiming Mok]]
*[[Greg Moore (physicist)]]
*[[David R. Morrison (mathematician)|David R. Morrison]]
*[[Tomasz Mrowka]]
*[[Charles M. Newman]]
*[[Noam Nisan]]
*[[Madhav Vithal Nori]]
*[[Edward Wilfred Odell, Jr.]]
*[[Stanley Osher]]
*[[George Oster]]
*[[Étienne Pardoux]]
*[[Raman Parimala]]
*[[Karen Hunger Parshall]]
*[[K. R. Parthasarathy (probabilist)]]
*[[Grigori Perelman]]
*[[Edwin Arend Perkins]]
*[[Bernadette Perrin-Riou]]
*[[Benoit Perthame]]
*[[Duong Hong Phong]]
*[[Anand Pillay]]
*[[Carl Pomerance]]
*[[Pavel Pudlak]]
*[[Jean-Pierre Quadrat]]
*[[Michael Rapoport]]
*[[Marina Ratner]]
*[[Eliyahu Rips]]
*[[Raoul Robert]]
*[[Vladimir Rokhlin, Jr.]]
*[[Joachim H. Rubinstein]]
*[[Alexei N. Rudakov]]
*[[Dietmar Arno Salamon]]
*[[Jesús María Sanz-Serna]]
*[[Joel Schneider]]
*[[Erhard Scholz]]
*[[Gerald W. Schwarz]]
*[[Stephen W. Semmes]]
*[[Paul Seymour (mathematician)|Paul Seymour]]
*[[Julius L. Shaneson]]
*[[Jalal Shatah]]
*[[Mitsuhiro Shishikura]]
*[[Gordon Douglas Slade]]
*[[Wolfgang Soergel]]
*[[Christopher Donald Sogge]]
*[[Eduardo D. Sontag]]
*[[Panagiotis E. Souganidis]]
*[[Joel Spencer]]
*[[Joel Spruck]]
*[[John Stillwell]]
*[[Stephan Stolz]]
*[[Andrei Suslin]]
*[[Vladimir Sverak]]
*[[Hiroshi Tanaka]]
*[[Clifford Taubes]]
*[[Richard Taylor (mathematician)|Richard Taylor]]
*[[Eugene Trubowitz]]
*[[Pekka Tukia]]
*[[Michel Van den Bergh]]
*[[S. R. S. Varadhan]]
*[[Victor A. Vassiliev]]
*[[Anatoly M. Vershik]]
*[[Marcelo Viana]]
*[[Claude Viterbo]]
*[[Dan-Virgil Voiculescu]]
*[[Claire Voisin]]
*[[Jean-Loup Waldspurger]]
*[[Antony Wassermann]]
*[[Sidney M. Webster]]
*[[Shmuel Weinberger]]
*[[Andrew Wiles]]
*[[Mariusz Wodzicki]]
*[[Jean-Christophe Yoccoz]]
*[[Lai-Sang Young]]
{{div col end}}

===1998, Berlin===
[[File:Laurent Lafforgue.png|thumb|Laurent Lafforgue]]
[[File:VladimirVoevodsky.jpg|thumb|Vladimir Voevodsky]]

[[File:Michael Freedman 2010.jpg|thumb|Michael Freedman]]
[[File:Simon Donaldson.jpg|thumb|Simon Donaldson]]

{{div col|colwidth=12em}}
*[[Miklós Ajtai]]
*[[David Aldous]]
*[[George Andrews (mathematician)|George E. Andrews]]
*[[James Arthur (mathematician)|James Arthur]]
*[[Michèle Artigue]]
*[[Paul S. Aspinwall]]
*[[Kari Astala]]
*[[Marco Avellaneda (mathematician)|Marco Avellaneda]]
*[[Victor V. Batyrev]]
*[[Bonnie Berger]]
*[[Vladimir G. Berkovich]]
*[[Joseph Bernstein]]
*[[Fabrice Bethuel]]
*[[Gregory Beylkin]]
*[[Jean-Michel Bismut]]
*[[Eugene Bogomolny]]
*[[Béla Bollobás]]
*[[Maury Bramson]]
*[[Detlev Buchholz]]
*[[Dmitri Burago]]
*[[Maria G. Bartolini Bussi]]
*[[Jennifer Tour Chayes]]
*[[Karine Chemla]]
*[[Ivan Cherednik]]
*[[F. Michael Christ]]
*[[Tobias Colding]]
*[[Pierre Collet (physicist)|Pierre Collet]]
*[[Pierre Colmez]]
*[[William Cook (computer scientist)|William Cook]]
*[[Maurizio Cornalba]]
*[[Joseph Dauben]]
*[[Miguel De Guzman]]
*[[Aise Johan de Jong]]
*[[Welington de Melo]]
*[[Percy Deift]]
*[[Christopher Deninger]]
*[[Persi Diaconis]]
*[[Robbert Dijkgraaf]]
*[[Simon Donaldson]]
*[[A.N. Dranishnikov]]
*[[Andreas Dress]]
*[[Boris Dubrovin]]
*[[William Duke (mathematician)|William Duke]]
*[[William Gerard Dwyer|William G. Dwyer]]
*[[Yakov Eliashberg]]
*[[Håkan Eliasson|L. Håkan Eliasson]]
*[[Björn Engquist]]
*[[Alex Eskin]]
*[[Joan Feigenbaum]]
*[[Ronald Fintushel]]
*[[Matthew Foreman]]
*[[András Frank]]
*[[Michael Freedman]]
*[[Mark Freidlin]]
*[[Eric Friedlander]]
*[[Giovanni Gallavotti]]
*[[Sylvestre Gallot]]
*[[Jayanta Ghosh]]
*[[Antonio Giorgilli]]
*[[Michel Goemans]]
*[[Friedrich Götze]]
*[[Yury Grabovsky]]
*[[Gian Michele Graf]]
*[[François Gramain]]
*[[Jeremy Gray]]
*[[Mark Green (mathematician)|Mark Green]]
*[[Leslie Greengard]]
*[[Ulf Grenander]]
*[[Wolfgang Hackbusch]]
*[[Peter Gavin Hall|Peter Hall]]
*[[Johan Håstad]]
*[[Shuhei Hayashi]]
*[[Frédéric Hélein]]
*[[Michael Herman (mathematician)|Michael Herman]]
*[[Nigel Higson]]
*[[Greg Hjorth]]
*[[Bernard R. Hodgson]]
*[[Helmut Hofer]]
*[[Frank Hoppensteadt]]
*[[Thomas Hou]]
*[[Ehud Hrushovski]]
*[[Gerhard Huisken]]
*[[Gérard Iooss]]
*[[Sergei V. Ivanov (mathematician)|Sergei V. Ivanov]]
*[[Robert R. Jensen]]
*[[Iain M. Johnstone]]
*[[Dominic Joyce]]
*[[William Kantor]]
*[[Mikhail Kapranov]]
*[[Yuri Kifer]]
*[[Robert Kottwitz]]
*[[Sergei B. Kuksin]]
*[[Krystyna Kuperberg]]
*[[François Labourie]]
*[[Michael Lacey]]
*[[Laurent Lafforgue]]
*[[Alain Lascoux]]
*[[Jean-François Le Gall]]
*[[Donald John Lewis]]
*[[Hans Lindblad]]
*[[Joachim Lohkamp]]
*[[Ian G. Macdonald]]
*[[Matei Machedon]]
*[[Mark Mahowald]]
*[[Stéphane Mallat]]
*[[Gunter Malle]]
*[[Jiří Matoušek (mathematician)|Jiří Matoušek]]
*[[Pertti Mattila]]
*[[Barry M. McCoy]]
*[[Dusa McDuff]]
*[[Curtis T. McMullen]]
*[[Loïc Merel]]
*[[Frank Merle (mathematician)|Frank Merle]]
*[[Vitali Milman]]
*[[Graeme Milton]]
*[[Tetsuji Miwa]]
*[[Shinichi Mochizuki]]
*[[Cathleen Synge Morawetz]]
*[[Jürgen Moser]]
*[[Shahar Mozes]]
*[[Detlef Müller (mathematician)|Detlef Müller]]
*[[Stefan Müller (mathematician)|Stefan Müller]]
*[[Ludomir Newelski]]
*[[Harald Niederreiter]]
*[[Mogens Niss]]
*[[Jorge Nocedal]]
*[[Tomotada Ohtsuki]]
*[[Hisashi Okamoto]]
*[[Bob Oliver (mathematician)|Bob Oliver]]
*[[George C. Papanicolaou|George Papanicolaou]]
*[[Charles S. Peskin]]
*[[Sergey Pinchuk]]
*[[Ulrich Pinkall]]
*[[Gilles Pisier]]
*[[Toniann Pitassi]]
*[[Leonid Polterovich]]
*[[Gustavo Ponce]]
*[[Aleksandr V. Pukhlikov]]
*[[William R. Pulleyblank]]
*[[Rolf Rannacher]]
*[[Idun Reiten]]
*[[Jeremy Rickard]]
*[[Aline Robert]]
*[[Yongbin Ruan]]
*[[Mikhail V. Safonov]]
*[[Peter Sarnak]]
*[[Hans Peter Schlickewei]]
*[[Roberto H. Schonmann]]
*[[Alexander Schrijver]]
*[[Kristian Seip]]
*[[Vera Serganova]]
*[[Aner Shalev]]
*[[Peter Shor]]
*[[David Siegmund]]
*[[Karl Sigmund]]
*[[Neil Sloane]]
*[[Feodor A. Smirnov]]
*[[David A. Smith (mathematician)|David A. Smith]]
*[[Hart F. Smith]]
*[[Hans-Georg Steiner]]
*[[Ronald J. Stern]]
*[[James Stigler]]
*[[Jan-Olov Strömberg]]
*[[Madhu Sudan]]
*[[Grzegorz Swiatek]]
*[[Alain-Sol Sznitman]]
*[[Michel Talagrand]]
*[[Clifford Taubes]]
*[[Joseph A. Thas]]
*[[Stevo Todorčević]]
*[[Nicole Tomczak-Jaegermann]]
*[[Lloyd N. Trefethen]]
*[[Boris Tsirelson]]
*[[Takeshi Tsuji]]
*[[Gunther Uhlmann]]
*[[Cumrun Vafa]]
*[[Marcelo Viana]]
*[[Vinicio Villani]]
*[[Kari Vilonen]]
*[[Vladimir Voevodsky]]
*[[Stephen Wainger]]
*[[Minoru Wakimoto]]
*[[Emo Welzl]]
*[[Alex Wilkie]]
*[[Jan Camiel Willems]]
*[[Ruth J. Williams]]
*[[Zhihong Xia]]
*[[Dmitri Yafaev]]
*[[Horng-Tzer Yau]]
*[[Andrei Zelevinsky]]
*[[Shou-Wu Zhang]]
*[[Joachem Zowe]]
{{div col end}}

===2002, Beijing===
{{div col|colwidth=12em}}
*[[Semyon Alesker]]
*[[Noga Alon]]
*[[Luigi Ambrosio]]
*[[Ben Andrews (mathematician)|Ben Andrews]]
*[[Douglas N. Arnold]]
*[[Sanjeev Arora]]
*[[Hajer Bahouri]]
*[[Deborah Loewenberg Ball]]
*[[Imre Bárány]]
*[[Robert Bartnik]]
*[[Gérard Ben Arous]]
*[[Michael Benedicks]]
*[[Jean Bertoin]]
*[[Mladen Bestvina]]
*[[Philippe Biane]]
*[[Peter J. Bickel]]
*[[Stephen Bigelow]]
*[[Paul Biran]]
*[[Dietmar Bisch]]
*[[Aart Blokhuis]]
*[[Erwin Bolthausen]]
*[[Christian Bonatti]]
*[[Alexei Bondal]]
*[[Umberto Bottazzini]]
*[[Elisabeth Bouscaren]]
*[[Hubert Bray]]
*[[Yann Brenier]]
*[[Alberto Bressan]]
*[[Jean Bricmont]]
*[[Lawrence D. Brown]]
*[[Luis Caffarelli]]
*[[Sun-Yung Alice Chang]]
*[[Yu. V. Chekanov]]
*[[Jean-Yves Chemin]]
*[[Mu-Fa Chen]]
*[[Xiuxioung Chen]]
*[[Alain Chenciner]]
*[[James W. Cogdell]]
*[[Albert Cohen (mathematician)|Albert Cohen]]
*[[Henri Cohen (number theorist)|Henri Cohen]]
*[[Gérard Cornuéjols]]
*[[Patrick Delorme]]
*[[James Demmel]]
*[[Jan Denef]]
*[[Weiyue Ding]]
*[[David Donoho]]
*[[Jean-Luc Dorier]]
*[[Michael R. Douglas]]
*[[Weinan E]]
*[[Jean-Pierre Eckmann]]
*[[Moritz Epple]]
*[[Alexandre Eremenko]]
*[[Hélène Esnault]]
*[[Pavel Etingof]]
*[[Ludvig Faddeev]]
*[[Uriel Feige]]
*[[Eduard Feireisl]]
*[[Bernold Fiedler]]
*[[Philippe Flajolet]]
*[[Jean-Marc Fontaine]]
*[[Giovanni Forni (mathematician)|Giovanni Forni]]
*[[Dan Freed]]
*[[Mikio Furuta]]
*[[Dennis Gaitsgory]]
*[[Liming Ge]]
*[[Emmanuel Giroux]]
*[[Moti Gitik]]
*[[Shafi Goldwasser]]
*[[Lothar Göttsche]]
*[[Lei Guo]]
*[[Uffe Haagerup]]
*[[Thomas Callister Hales|Thomas Hales]]
*[[Vagn Lunsgaard Hansen]]
*[[Michael Harris (mathematician)|Michael Harris]]
*[[Juha Heinonen]]
*[[Lars Hesselholt]]
*[[Jiaxing Hong]]
*[[Michael J. Hopkins|Michael Hopkins]]
*[[Kentaro Hori]]
*[[Celia Hoyles]]
*[[Hesheng Hu]]
*[[Annette Huber-Klawitter|A. Huber]]
*[[Russell Impagliazzo]]
*[[Eleny-Nicole Ionel]]
*[[Hans Niels Jahnke]]
*[[Svetlana Jitomirskaya]]
*[[Kurt Johannson (mathematician)|Kurt Johansson]]
*[[Victor Kac]]
*[[Gabriele Kaiser]]
*[[Ravindran Kannan]]
*[[Nicole El Karoui]]
*[[Kazuya Kato]]
*[[Carlos E. Kenig]]
*[[Harry Kesten]]
*[[Tero Kilpelainen]]
*[[Guido Kings]]
*[[Frances Kirwan]]
*[[Alexander Klyachko]]
*[[Toshiyuki Kobayashi]]
*[[Nancy Kopell]]
*[[Stephen S. Kudla]]
*[[Laurent Lafforgue]]
*[[Vincent Lafforgue]]
*[[Daniel Lascar]]
*[[Rafael Latala]]
*[[Greg Lawler]]
*[[Nicolas Lerner]]
*[[Frederick Leung]]
*[[Marc Levine (mathematician)|Marc Levine]]
*[[Peter Wai-Kwong Li]]
*[[YanYan Li]]
*[[Nati Linial]]
*[[Kefeng Liu]]
*[[Tai-Ping Liu]]
*[[Yiming Long]]
*[[Mitchell Luskin]]
*[[Vladimir Mazya]]
*[[Michael Liam McQuillan]]
*[[Vikram Bhagvandas Mehta]]
*[[Eckhard Meinrenken]]
*[[Alexander Mielke]]
*[[Nitsa Movshovitz-Hadar]]
*[[Shigeru Mukai]]
*[[David Mumford]]
*[[Bruno Nachtergaele]]
*[[Hiraku Nakajima]]
*[[Maxim Nazarov]]
*[[Nikita A. Nekrasov]]
*[[Masatoshi Noumi]]
*{{ill|Dmitri Olegovich Orlov|ru|Орлов, Дмитрий Олегович}}
*[[Felix Otto (mathematician)|Felix Otto]]
*[[Rahul Pandharipande]]
*[[Yuval Peres]]
*[[Anton Petrunin]]
*[[Ilya Piatetski-Shapiro]]
*[[Richard Pink (mathematician)|Richard Pink]]
*[[Agoston Pisztora]]
*[[Cheryl Praeger]]
*[[Enrique Pujals]]
*[[Anjing Qu]]
*[[Alfio Quarteroni]]
*[[Rolf Rannacher]]
*[[Ran Raz]]
*[[Bruce Reed (mathematician)|Bruce Reed]]
*[[Miles Reid]]
*[[Y. Ritov]]
*[[Tristan Joel Riviere]]
*[[Tom Romberg]]
*[[Xiaochun Rong]]
*[[Markus Rost]]
*[[Karl Rubin]]
*[[Daniel J. Rudolph]]
*[[Tobias Rydén]]
*[[Vadim Schechtman]]
*[[Christoph Schwab]]
*[[Richard Schwartz (mathematician)|Richard Schwartz]]
*[[Paul Seidel]]
*[[Zlil Sela]]
*[[James Sethian]]
*[[Freydoon Shahidi]]
*[[Leonid Pavlovich Shilnikov]]
*[[Yum-Tong Siu]]
*[[John Smillie (mathematician)|John Smillie]]
*[[Terry Speed]]
*[[Daniel Spielman]]
*[[John Tobias Stafford|J.T. Stafford]]
*[[Eitan Tadmor]]
*[[Dmitry Tamarkin]]
*[[Daniel Tătaru]]
*[[Richard Taylor (mathematician)|Richard Taylor]]
*[[Peter Teichner]]
*[[Christian Thiele]]
*[[Gang Tian]]
*[[Ulrike Tillmann]]
*[[Burt Totaro]]
*[[Craig A. Tracy]]
*[[D. Treschev]]
*[[Emmanuel Ullmo]]
*[[Marie-France Vignéras]]
*[[Schicheng Wang]]
*[[Xu-Jia Wang]]
*[[Brian White (mathematician)|Brian Cabell White]]
*[[Peter Winkler]]
*[[Edward Witten]]
*[[Maciej P. Wojtkowski]]
*[[W. Hugh Woodin]]
*[[Trevor Wooley]]
*[[Sijue Wu]]
*[[Shutie Xiao]]
*[[Zhouping Xin]]
*[[Jia-An Yan]]
*[[Ivan Yaschenko]]
*[[A. Yu. Zaitsev]]
*[[Ofer Zeitouni]]
*[[Steve Zelditch]]
*[[Weiping Zhang]]
*[[Xiangyu Zhou]]
*[[Günter M. Ziegler]]
*[[Maciej Zworski]]
{{div col end}}

===2006, Madrid===
[[File:Alice Guionnet.jpg|thumb|Alice Guionnet]]
[[File:Ttao2006.jpg|thumb|Terence Tao]]
[[File:Wendelin Werner.jpg|thumb|Wendelin Werner]]
[[File:Elon Lindenstrauss MFO.jpg|thumb|Elon Lindenstrauss]]
[[File:Stanislav Smirnov2.jpg|thumb|Stanislav Smirnov]]
[[File:Cedric Villani at his office 2015 n3.jpg|thumb|Cedric Villani]]

The 1006 ICM in Madrid attracted several thousand mathematicians.&lt;ref&gt;[http://www.ams.org/notices/200611/comm-icm.pdf International Congress of Mathematicians 2006]&lt;/ref&gt;

{{div col|colwidth=12em}}
*[[Oleg N. Ageev]]
*[[Ian Agol]]
*[[Manindra Agrawal]]
*[[Valery Alexeev (mathematician)|Valery Alexeev]]
*[[Michèle Artigue]]
*[[Franck Barthe]]
*[[Alexander Barvinok]]
*[[Vitaly Bergelson]]
*[[Roman Bezrukavnikov]]
*[[Manjul Bhargava]]
*[[Stefano Bianchini]]
*[[Mario Bonk]]
*[[Vivek Borkar]]
*[[Jean-Benoît Bost]]
*[[Mireille Bousquet-Mélou]]
*[[Anton Bovier]]
*[[Stephen P. Boyd]]
*[[Alexander Braverman]]
*[[Simon Brendle]]
*[[Tom Bridgeland]]
*[[Martin Bridson]]
*[[Russel E. Caflisch]]
*[[Emmanuel Candès]]
*[[Vicent Caselles]]
*[[Alberto S. Cattaneo]]
*[[Raphaël Cerf]]
*[[Ching-Li Chai]]
*[[Zhiming Chen]]
*[[Shiu-Yuen Cheng]]
*[[Yvonne Choquet-Bruhat]]
*[[Leo Corry]]
*[[William Crawley-Boevey]]
*[[Henri Darmon]]
*[[Rafael de la Llave]]
*[[Jan de Lange]]
*[[Ehud de Shalit]]
*[[Percy Deift]]
*[[Jean-Pierre Demailly]]
*[[Amir Dembo]]
*[[Bernard Derrida]]
*[[Ronald DeVore]]
*[[Dmitry Dolgopyat]]
*[[Peter Donnelly]]
*[[Rod Downey]]
*[[Marcus du Sautoy]]
*[[Ricardo G. Durán]]
*[[Nira Dyn]]
*[[Lawrence Ein]]
*[[Yakov Eliashberg]]
*[[K. David Elworthy]]
*[[Oleg Yu. Emanouilov]]
*[[Jianqing Fan]]
*[[Kazuhiro Fujiwara]]
*[[Patrick Gérard]]
*[[Bert Gerards]]
*[[Robert Ghrist]]
*[[Étienne Ghys]]
*[[François Golse]]
*[[Martin Grötschel]]
*[[Tom Graber]]
*[[Gian Michele Graf]]
*[[Ben Green (mathematician)|Ben Green]]
*[[Michael Griebel]]
*[[Ian Grojnowski]]
*[[Fritz Grunewald]]
*[[Niccolò Guicciardini]]
*[[Alice Guionnet]]
*[[Max Gunzburger]]
*[[Matthew Gursky]]
*[[Mark Haiman]]
*[[Richard S. Hamilton]]
*[[Guy Henniart]]
*[[Steve Hofmann]]
*[[Alexander Holevo]]
*[[Ko Honda]]
*[[Jun-Muk Hwang]]
*[[Hitoshi Ishii]]
*[[Henryk Iwaniec]]
*[[Iain M. Johnstone]]
*[[Vadim Kaloshin]]
*[[Michael Kapovich]]
*[[Kazuya Kato]]
*[[Bernhard Keller]]
*{{ill|Petar Kenderov|bg|Петър Кендеров}}
*[[Mikhail Khovanov]]
*[[Jeong Han Kim]]
*[[Boáz Klartag]]
*[[Jon Kleinberg]]
*[[Bruce Kleiner]]
*[[Robert V. Kohn]]
*[[Sergei Konyagin]]
*[[Bryna Kra]]
*[[Steven Lalley]]
*[[François Lalonde]]
*[[Gérard Laumon]]
*[[Claude Le Bris]]
*[[Patrice Le Calvez]]
*[[Yves Le Jan]]
*[[Peng Yee Lee]]
*[[Randall J. LeVeque]]
*[[David Levermore]]
*[[Elon Lindenstrauss]]
*[[Xiaobo Liu (mathematician)|Xiaobo Liu]]
*[[Tomasz Łuczak]]
*[[Toshiki Mabuchi]]
*[[Yvon Maday]]
*[[Ib Madsen]]
*[[Jean-Michel Maillet]]
*[[Marcos Marito]]
*[[Peter McCullagh]]
*[[Philippe Michel]]
*[[Grigory Mikhalkin]]
*[[William Minicozzi II]]
*[[Yair Minsky]]
*[[Nicolas Monod]]
*[[Fabien Morel]]
*[[Bienvenido Nebres]]
*[[Itay Neeman]]
*[[Arkadi Nemirovski]]
*[[Ngô Bảo Châu]]
*[[Wiesława Nizioł]]
*[[Martin Nowak]]
*[[David Nualart]]
*[[Yong-Geun Oh]]
*[[Andrei Okounkov]]
*[[Kaoru Ono (mathematician)|Kaoru Ono]]
*[[E.M. Opdam]]
*[[Konrad Osterwalder]]
*[[Narutaka Ozawa]]
*[[Peter Ozsváth]]
*[[Dominique Picard]]
*[[Sorin Popa]]
*[[Mario Pulvirenti]]
*[[Alfio Quarteroni]]
*[[Anthony Ralston]]
*[[Michael Rathjen]]
*[[Omer Reingold]]
*[[Igor Rodnianski]]
*[[Mikael Rordam]]
*[[Antonio Ros]]
*[[Linda Preiss Rothschild]]
*[[Tim Roughgarden]]
*[[Raphaël Rouquier]]
*[[Ronitt Rubinfeld]]
*[[Imre Z. Ruzsa]]
*[[Francisco Santos Leal|Francisco Santos]]
*[[Mark Sapir]]
*[[Ovidiu Savin]]
*[[T. M. Scanlon|Thomas Scanlon]]
*[[William Schmidt (mathematician)|William Schmidt]]
*[[Peter Schneider (mathematician)|Peter Schneider]]
*[[Oded Schramm]]
*[[Christoph Schweigert]]
*[[Akos Seress]]
*[[Sylvia Serfaty]]
*[[Yehuda Shalom]]
*[[Michael Shub]]
*[[Alan Siegel]]
*[[Christopher Skinner]]
*[[Stanislav Smirnov]]
*[[Agata Smoktunowicz]]
*[[Avraham Soffer]]
*[[David Soudry]]
*[[Birgit Speh]]
*[[T. A. Springer]]
*[[Olof Staffans]]
*[[Richard P. Stanley]]
*[[Emil Straube]]
*[[Endre Süli]]
*[[Zoltán Szabó (mathematician)|Zoltán Szabó]]
*[[Stanisław Szarek]]
*[[Anders Szepessy]]
*[[Terence Tao]]
*[[Vladimir Temlyakov]]
*[[Tomohide Terasoma]]
*[[Chuu-Lian Terng]]
*[[Robin Thomas (mathematician)|Robin Thomas]]
*[[Simon Thomas (mathematician)|Simon Thomas]]
*[[Xavier Tolsa]]
*[[Luca Trevisan]]
*[[Neil Trudinger]]
*[[Yuri Tschinkel]]
*[[Eric Urban]]
*[[Juan Luis Vázquez Suárez|Juan Luis Vázquez]]
*[[Arjan Van der Schaft]]
*[[Vinayak Vatsal]]
*[[Luis Vega (mathematician)|Luis Vega]]
*[[Juan L. Veläzquez]]
*[[Michèle Vergne]]
*[[Cédric Villani]]
*[[Karen Vogtmann]]
*[[Wendelin Werner]]
*[[Paul Wiegmann]]
*[[Avi Wigderson]]
*[[Burhard Wilking]]
*[[Jaroslaw Wlodarczyk]]
*[[Hung-Hsi Wu]]
*[[Guoliang Yu]]
*[[Anton Zorich]]
*[[Enrique Zuazua]]
{{div col end}}

===2010, Hyderabad===
[[File:Artur Ávila.jpg|thumb|Artur Ávila]]
[[File:Ngo Bau Chau MFO.jpg|thumb|Ngô Bảo Châu]]
[[File:Srinivasa Varadhan Heidelberg.JPG|thumb|S. R. Srinivasa Varadhan]]
[[File:Maryam Mirzakhani in Seoul 2014.jpg|thumb|Maryam Mirzakhani]]

{{div col|colwidth=12em}}
*[[Jill Adler]]
*[[Dorit Aharonov]]
*[[David Aldous]]
*[[Marie-Claude Arnaud]]
*{{ill|Denis Auroux|de}}
*[[Artur Avila]]
*{{ill|Peter Bürgisser|de}}
*[[Ellen Baake]]
*[[Ramachandran Balasubramanian]]
*[[Paul Balmer]]
*[[Prakash Belkale]]
*[[Itai Benjamini]]
*[[David J Benson]]
*[[Patrick Bernard]]
*[[Louis Billera]]
*[[Alexei Borodin]]
*[[Arup Bose]]
*[[Christophe Breuil]]
*[[Xavier Buff]]
*{{ill|Nicolas Burq|de}}
*[[Probal Chaudhuri]]
*[[Shuxing Chen]]
*[[Chong-Qing Cheng]]
*[[Arnaud Chéritat]]
*[[Bernardo Cockburn]]
*[[Fernando Codá Marques]]
*[[Henry Cohn]]
*[[Gonzalo Contreras (mathematician)|Gonzalo Contreras]]
*[[Jean-Michel Coron]]
*[[Kevin Costello]]
*[[Marianna Csörnyei]]
*[[Edward Norman Dancer|E.N. Dancer]]
*[[Camillo De Lellis]]
*[[Manuel del Pino]]
*[[Freddy Delbaen]]
*[[Frank den Hollander]]
*[[Nils Dencker]]
*[[Irit Dinur]]
*[[Cynthia Dwork]]
*[[Manfred Einsiedler]]
*[[Anna Erschler]]
*[[Alex Eskin]]
*[[Steven Neil Evans]]
*[[Isabel Fernández]]
*[[Sergey Fomin]]
*[[Hélène Frankowska]]
*[[Jixiang Fu]]
*[[Hillel Furstenberg]]
*[[Nicola Fusco]]
*[[David Gabai]]
*[[Damien Gaboriau]]
*[[Sara van de Geer]]
*[[William Goldman (mathematician)|William Goldman]]
*[[Iain Gordon]]
*[[Ralph Greenberg]]
*[[Jesper Grodal]]
*[[Venkatesan Guruswami]]
*[[Larry Guth]]
*[[Christopher Hacon]]
*[[Ursula Hamenstädt]]
*[[Roger Heath-Brown]]
*[[Thomas J.R. Hughes]]
*[[Michael Hutchings (mathematician)|Michael Hutchings]]
*[[Daniel Huybrechts]]
*[[Alexander R. Its]]
*[[Sergei Ivanov (mathematician)|Sergei Ivanov]]
*[[Satoru Iwata (mathematician)|Satoru Iwata]]
*[[Masaki Izumi]]
*{{ill|Lech Tadeusz Januszkiewicz|pl}}
*[[Peter Jones (mathematician)|Peter Jones]]
*{{ill|Dmitry Kaledin|ru|Каледин, Дмитрий Борисович}}
*[[Anton Kapustin]]
*[[Nikita Karpenko]]
*[[Kiran Kedlaya]]
*[[Carlos Kenig]]
*[[Chandrashekhar Khare]]
*[[Subhash Khot]]
*[[Mark Kisin]]
*[[Tinne Hoff Kjeldsen]]
*[[Pekka Koskela (mathematician)|Pekka Koskela]]
*[[Arno Kuijlaars]]
*[[Shrawan Kumar]]
*[[Karl Kunisch]]
*[[Antti Kupiainen]]
*[[Wolfgang Lück]]
*[[Marc Lackenby]]
*[[Sergey Lando]]
*[[Erez Lapid]]
*[[Yoram Last]]
*[[Bernard Leclerc (mathematician)|Bernard Leclerc]]
*[[Chiu-Chu Melissa Liu]]
*[[Ivan Losev (mathematician)|Ivan Losev]]
*[[Jacob Lurie]]
*[[Xiaonan Ma]]
*[[Philip K. Maini]]
*[[Matilde Marcolli]]
*[[Peter A. Markowich]]
*[[Gaven Martin]]
*[[Vieri Mastropietro]]
*[[Brendan McKay]]
*[[James McKernan]]
*[[Pablo Mira]]
*[[Maryam Mirzakhani]]
*[[Justin Tatch Moore]]
*[[Sophie Morel]]
*[[Alexander Nabutovsky]] 
*{{Interlanguage link multi|Nikolai Nadirashvili|de|3=Nikolai Semjonowitsch Nadiraschwili}}
*[[Assaf Naor]]
*[[Fedor Nazarov]]
*[[Jaroslav Nešetřil]]
*[[Yurii Nesterov]]
*[[Claudia Neuhauser]]
*[[Ngô Bảo Châu]]
*[[Andre Nies]]
*[[Ricardo Horatio Nochetto]]
*[[Hee Oh]]
*[[Stanley Osher]]
*[[Frank Pacard]]
*[[Raman Parimala]]
*[[Jongil Park]]
*[[Pablo A. Parrilo]]
*[[Aleksei Nikolaevich Parshin|A.N. Parshin]]
*[[Mihai Paun]]
*[[Peng Shige]]
*[[Ya'acov Peterzil]]
*[[Kim Plofker]]
*[[Jeremy Quastel]]
*[[Eric Rains]]
*[[Zinovy Reichstein]]
*[[Idun Reiten]]
*[[Nicolai Reshetikhin]]
*[[Oliver Riordan]]
*[[Federico Rodriguez Hertz]]
*[[Mark Rudelson]]
*[[Shuji Saito]]
*[[Takeshi Saito (mathematician)|Takeshi Saito]]
*[[Omri Sarig]]
*{{ill|Norbert Schappacher|de}}
*[[Richard Schoen]]
*[[Frank-Olaf Schreyer]]
*[[Christof Schuette]]
*[[Gregory Seregin]]
*[[Nimish A. Shah]]
*[[Qi-Man Shao]]
*[[Alexander Shapiro (mathematician)|Alexander Shapiro]]
*[[Scott Sheffield]]
*[[Zuowei Shen]]
*[[Dimitri Shlyakhtenko]]
*[[Alexander Shnirelman]]
*[[Mikhail Sodin]]
*[[Kannan Soundararajan]]
*[[Daniel Spielman]]
*[[Herbert Spohn]]
*[[Vasudevan Srinivas]]
*[[Sergei Starchenko]]
*[[Andrys Stipsicz]]
*[[Catharina Stroppel]]
*[[Benny Sudakov]]
*[[Suresh Venapally]]
*[[Richard Thomas (mathematician)|Richard Thomas]]
*[[Tatiana Toro]]
*[[Nizar Touzi]]
*[[Dmitry Turaev]]
*[[Salil Vadhan]]
*[[Stefaan Vaes]]
*[[Benno Van Dalen]]
*[[Aad Van der Vaart]]
*[[S. R. Srinivasa Varadhan]]
*[[T. N. Venkataramana]]
*[[Akshay Venkatesh]]
*[[Roman Vershynin]]
*[[Claire Voisin]]
*[[Robert Weismantel]]
*[[Jean-Yves Welschinger]]
*[[Katrin Wendland]]
*[[Mary Wheeler]]
*[[Amie Wilkinson]]
*[[Jean-Pierre Wintenberger]]
*[[W. Hugh Woodin]]
*[[Jinchao Xu]]
*[[Zongben Xu]]
*[[Takao Yamaguchi]]
*[[Xu Zhang]]
*[[Xunyu Zhou]]
{{div col end}}

===2014, Seoul===
[[File:Professor Martin Hairer FRS.jpg|thumb|Martin Hairer]]
[[File:Alessio Figalli (cropped).jpg|thumb|Alessio Figalli]]
[[File:Peter Scholze (cropped).jpg|thumb|Peter Scholze]]
[[File:John Milnor.jpg|thumb|John Milnor]]
[[File:Manjul Bhargava.jpg|thumb|Manjul Bhargava]]

{{div col|colwidth=12em}}
*[[Rémi Abgrall]]
*{{ill|Mohammed Abouzaid|de}}
*[[Ian Agol]]
*[[Anton Alekseev (mathematician)|Anton Alekseev]]
*[[Nicolás Andruskiewitsch]]
*[[Konstantin Ardakov]]
*[[James Arthur (mathematician)|James Arthur]]
*[[Joseph Ayoub]]
*[[Viviane Baladi]]
*[[Weizhu Bao]]
*[[Boaz Barak]]
*[[Kai Behrend]]
*[[Mikhail Belolipetsky]]
*[[Georgia Benkart]]
*[[Yves Benoist]]
*[[Manjul Bhargava]]
*[[Olivier Biquard]]
*[[Alexei Borodin]]
*[[Andrea Braides]]
*[[Mark Braverman (mathematician)|Mark Braverman]]
*[[Emmanuel Breuillard]]
*[[Franco Brezzi]]
*{{ill|Francis Brown (mathematician)|de|Francis Brown|lt=Francis Brown}}
*[[Jonathan Brundan]]
*[[Annalisa Buffa]]
*[[Andrei Bulatov (mathematician)|Andrei Bulatov]]
*[[Eric Cances]]
*[[Emmanuel Candès]]
*[[Sourav Chatterjee]]
*[[Zoé Chatzidakis]]
*[[Luigi Chierchia]]
*[[Demetrios Christodoulou]]
*[[Maria Chudnovsky]]
*[[Julia Chuzhoy]]
*[[David Conlon]]
*[[Guillermo Cortinas]]
*[[Ivan Corwin]]
*[[Sylvain Crovisier]]
*[[Mihalis Dafermos]]
*[[Panagiota Daskalopoulos]]
*[[Bertrand Duplantier]]
*[[Yalchin Efendiev]]
*[[Friedrich Eisenbrand]]
*[[Matthew Emerton]]
*[[Michael Entov]]
*{{ill|László Erdős|de}}
*[[Bertrand Eynard]]
*[[Fuquan Fang]]
*[[Ilijas Farah]]
*[[Benson Farb]]
*[[Albert Fathi]]
*[[Alessio Figalli]]
*[[Vladimir Fock (mathematician)|Vladimir Fock]]
*[[Jacob Fox]]
*[[Alan M. Frieze]]
*[[Alexander Furman]]
*[[Søren Galatius]]
*[[Isabelle Gallagher]]
*[[Wee Teck Gan]]
*[[Craig Gentry (computer scientist)|Craig Gentry]]
*[[Anton Gerasimov]]
*[[Étienne Ghys]]
*[[Anna C. Gilbert]]
*[[Daniel Goldston]]
*[[Ben Green (mathematician)|Ben Green]]
*[[Geoffrey Grimmett]]
*[[Mark Gross (mathematician)|Mark Gross]]
*[[Robert Guralnick]]
*[[Seung-Yeal Ha]]
*[[Martin Hairer]]
*[[Michael Harris (mathematician)|Michael Harris]]
*[[Harald Helfgott]]
*[[Michael Hill (mathematician)|Michael Hill]]
*[[Nancy Hingston]]
*[[Kengo Hirachi]]
*[[Jun-Muk Hwang]]
*[[Tuomas Hytönen]]
*[[Robert Jerrard]]
*[[Jeremy Kahn]]
*[[Seok-Jin Kang]]
*[[Martin Kassabov]]
*[[Nets Katz]]
*[[Rinat Kedem]]
*[[Olga Kharlampovich]]
*[[Bumsig Kim]]
*[[Byunghan Kim]]
*[[Alexander Kleshchev]]
*[[János Kollár]]
*[[Michael Krivelevich]]
*[[Daniela Kühn]]
*[[Takashi Kumagai]]
*[[Alexander Kuznetsov (mathematician)|Alexander Kuznetsov]]
*[[Izabella Łaba]]
*[[Kenneth Lange]]
*[[Monique Laurent]]
*[[Jean-François Le Gall]]
*[[Michel Ledoux]]
*[[Ki-Ahm Lee]]
*[[Adrian Lewis (mathematician)|Adrian Lewis]]
*[[Tao Li (mathematician)|Tao Li]]
*[[Chang-Shou Lin]]
*[[François Loeser]]
*[[Russell Lyons]]
*[[Terry Lyons (mathematician)|Terry Lyons]]
*[[Mikhail Lyubich]]
*[[Andrea Malchiodi]]
*[[Adam W. Marcus]]
*[[Jens Marklof]]
*[[Vladimir Markovic]]
*[[Fernando Codá Marques]]
*[[Davesh Maulik]]
*[[Robert J. McCann (mathematician)|Robert J. McCann]]
*[[Frank Merle (mathematician)|Frank Merle]]
*[[Alexei Miasnikov]]
*[[John Milnor]]
*[[Maryam Mirzakhani]]
*[[Takurō Mochizuki]]
*[[Antonio Montalbán]]
*[[Carlos Gustavo Moreira]]
*[[Jean-Michel Morel]]
*[[Mircea Mustaţă]]
*[[Aaron Naber]]
*[[André Neves]]
*[[Barbara Niethammer]]
*[[Marc Noy]]
*[[Ryan O'Donnell (mathematician)|Ryan O'Donnell]]
*[[Keiji Oguiso]]
*[[Grigori Olshanski]]
*[[Hinke Osinga]]
*[[Deryk Osthus]]
*[[Victor Ostrik]]
*[[Yaron Ostrover]]
*[[János Pach]]
*[[Sandrine Péché]]
*[[Benoit Perthame]]
*[[Jonathan Pila]]
*[[János Pintz]]
*[[Gabriella Pinzari]]
*[[Jill Pipher]]
*[[Mark Pollicott]]
*[[Han Qi (mathematician)|Han Qi]]
*[[Pierre Raphael]]
*[[Andrei S. Rapinchuk]]
*[[Batmanathan Dayanand Reddy]]
*[[Bertrand Rémy]]
*[[Nicolas Ressayre]]
*[[Charles Rezk]]
*[[Hans Ringström]]
*[[Luc Robbiano]]
*[[Vojtěch Rödl]]
*[[John Rognes (mathematician)|John Rognes]]
*[[Pierre Rouchon]]
*[[Zeev Rudnick]]
*[[Laure Saint-Raymond]]
*[[Tom Sanders (mathematician)|Tom Sanders]]
*[[Thomas Schick]]
*[[Wilhelm Schlag]]
*[[Peter Scholze]]
*[[Robert Seiringer]]
*[[Timo Seppäläinen]]
*[[Vera Serganova]]
*[[Nataša Šešum]]
*[[Samson Shatashvili]]
*[[Weixiao Shen]]
*[[Chi-Wang Shu]]
*[[Vladas Sidoravicius]]
*[[Bernd Siebert]]
*[[Reinhard Siegmund-Schultze]]
*[[Luis Silvestre]]
*[[Karen E. Smith]]
*[[Sasha Sodin]]
*[[Slawomir Solecki]]
*[[Roland Speicher]]
*[[Daniel Spielman]]
*[[Nikhil Srivastava]]
*[[Angelika Steger]]
*[[Andrew M. Stuart|Andrew Stuart]]
*[[Jeremie Szeftel]]
*[[Gábor Székelyhidi]]
*[[László Székelyhidi]]
*[[Denis Talay]]
*[[Constantin Teleman]]
*[[Jörg Teschner]]
*[[Yukinobu Toda]]
*[[Bertrand Toën]]
*[[Peter Topping]]
*[[Dominique Tournes]]
*[[Masato Tsujii]]
*[[Alexandre Tsybakov]]
*[[Sebastian van Strien]]
*[[Michela Varagnolo]]
*[[Eric Vasserot]]
*[[Andras Vasy]]
*[[Misha Verbitsky|Mikhail Verbitsky]]
*[[Bálint Virág]]
*[[Van H. Vu]]
*[[Martin Wainwright (mathematician)|Martin Wainwright]]
*[[Jean-Loup Waldspurger]]
*[[Juncheng Wei]]
*[[Stefan Wenger]]
*[[Ryan Williams (computer scientist)|Ryan Williams]]
*[[Daniel Wise (mathematician)|Daniel Wise]]
*[[Trevor Wooley]]
*[[Sergey Yekhanin]]
*[[Cem Yıldırım]]
*[[Jiongmin Yong]]
*[[Shih-Hsien Yu]]
*[[Ya-xiang Yuan]]
*[[Umberto Zannier]]
*[[Thaleia Zariphopoulou]]
*[[Yitang Zhang]]
*[[Günter M. Ziegler]]
*[[Tamar Ziegler]]
{{div col end}}

===2018, Rio de Janeiro===
[[File:Andrei Okounkov.jpg|thumb|Andrei Okounkov]]
[[File:Laszlo Babai.jpg|thumb|Laszlo Babai]]
[[File:James Maynard MFO 2013.jpg|thumb|James Maynard]]
[[File:Maryna Vazovska MFO 2013 crop.jpg|thumb|Maryna Vazovska]]
[[File:Kgethi.jpg|thumb|Mamokgethi Phakeng]]
[[File:Gil Kalai 2007.jpg|thumb|Gil Kalai]]

{{div col|colwidth=12em}}
*[[Dan Abramovich]]
*[[Andris Ambainis]]
*[[Luigi Ambrosio]]
*[[Nalini Anantharaman]]
*[[Fabrizio Andreatta]]
*[[Yves André]]
*[[Tomoyuki Arakawa]]
*[[Carolina Araujo (mathematician)|Carolina Araujo]]
*[[Spiros Argyros]]
*[[Sanjeev Arora]]
*[[Matthias Aschenbrenner]]
*[[László Babai]]
*[[József Balogh (mathematician)|József Balogh]]
*[[Arthur Bartels]]
*[[Alexander Belavin]]
*[[Nicolas Bergeron]]
*[[Bo Berndtsson]]
*[[Andrea Bertozzi]]
*[[Caucher Birkar]]
*[[Christopher J. Bishop]]
*[[Jairo Bochi]]
*[[Marianna Bosch]]
*[[Sem Borst]]
*[[Sébastien Boucksom]]
*[[Paul Bourgade]]
*[[Lewis Bowen]]
*[[Peter Bühlmann]]
*[[Raimund Bürger]]
*[[Serge Cantat]]
*[[Lucia Caporaso]]
*[[Manuel Castro]]
*[[Dmitry Chelkak]]
*[[Jungkai Alfred Chen]]
*[[Meng Chen]]
*[[Ronald Coifman]]
*[[Diego Córdoba]]
*[[Pierre Degond]]
*[[Jean-Marc Delort]]
*[[Laura DeMarco]]
*[[Ciprian Demeter]]
*[[Lorenzo J. Díaz]]
*[[Simon Donaldson]]
*[[Lou van den Dries]]
*[[Qiang Du]]
*[[Hugo Duminil-Copin]]
*[[Tobias Ekholm]]
*[[Selim Esedoglu]]
*[[María J. Esteban]]
*[[Ruy Exel]]
*[[Mouhamed Moustapha Fall]]
*[[Bassam Fayad]]
*[[Laurent Fargues]]
*[[Michael Finkelberg]]
*[[Philippe Di Francesco]]
*[[Koji Fujiwara]]
*[[Vyacheslav Futorny]]
*[[Josselin Garnier]]
*[[Christof Geiß]]
*[[Tsachik Gelander]]
*[[Yoshikazu Giga]]
*[[Mike Giles]]
*[[Catherine Goldstein]]
*[[Sébastien Gouezel]]
*[[Massimiliano Gubinelli]]
*[[Colin Guillarmou]]
*[[Paul Hacking]]
*[[Richard Haydon]]
*[[Xuhua He]]
*[[Joris van der Hoeven]]
*[[Michael Hochman]]
*[[Umberto Hryniewicz]]
*[[June Huh]]
*[[Piotr Indyk]]
*[[Adrian Ioana]]
*[[Adrian Iovita]]
*[[Osamu Iyama]]
*[[Pierre-Emmanuel Jabin]]
*[[Steve Jackson (mathematician)|Stephen Jackson]]
*[[Richard James (mathematician)|Richard James]]
*[[Shi Jin (mathematician)|Shi Jin]]
*[[William B. Johnson (mathematician)|Bill Johnson]]
*[[Bernardo Uribe Jongbloed]]
*[[Michael I. Jordan]]
*[[Gil Kalai]]
*[[Yael Tauman Kalai]]
*[[Noureddine El Karoui]]
*[[Rinat Kashaev]]
*[[Fanny Kassel]]
*[[Neeraj Kayal]]
*[[Yasuyuki Kawahigashi]]
*[[Sean Keel]]
*[[Peter Keevash]]
*[[Richard Kenyon]]
*[[Moritz Kerz]]
*[[Jong Hae Keum]]
*[[Konstantin Khanin]]
*[[Alexander Kiselev (mathematician)|Alexander Kiselev]]
*[[Jochen Koenigsmann]]
*[[Ulrich Kohlenbach]]
*[[Vladimir Koltchinskii]]
*[[Andrés Koropecki]]
*[[Raphael Krikorian]]
*[[Peter B. Kronheimer]]
*[[Wojciech Kucharz]]
*[[Krzysztof Kurdyka]]
*[[Vincent Lafforgue]]
*[[Claudio Landim]]
*[[Matti Lassas]]
*[[Jean Bernard Lasserre]]
*[[Greg Lawler]]
*[[Elizaveta Levina]]
*[[Robert Lipshitz]]
*[[Carlangelo Liverani]]
*[[Aleksandr Logunov (mathematician)|Alexander Logunov]]
*[[Helena J. Nussenzveig Lopes]]
*[[Christian Lubich]]
*[[Alexander Lubotzky]]
*[[Aleksander Madry]]
*[[Mohamed Majdoub]]
*[[Eugenia Malinnikova]]
*[[Maryanthe Malliaris]]
*[[Ciprian Manolescu]]
*[[Yvan Martel]]
*[[Nader Masmoudi]]
*[[András Mathé]]
*[[Kaisa Matomäki]]
*[[James Maynard (mathematician)|James Maynard]]
*[[Svitlana Mayboroda]]
*[[Jason P. Miller]]
*[[Siddhartha Mishra]]
*[[Mahan Mj]]
*[[Martin Möller]]
*[[Andrea Montanari (mathematician)|Andrea Montanari]]
*[[Carlos Gustavo Moreira]]
*[[Robert Morris (mathematician)|Robert Morris]]
*[[Clément Mouhot]]
*[[Tomasz Mrowka]]
*[[Ritabrata Munshi]]
*[[Emmy Murphy]]
*[[Assaf Naor]]
*[[Meysam Nassiri]]
*[[Sonia Natale]]
*[[Andrés Navas]]
*[[András Némethi]]
*[[Stéphane Nonnenmacher]]
*[[Andrei Okounkov]]
*[[Denis Osin]]
*[[Igor Pak]]
*[[Rahul Pandharipande]]
*[[Ivan Panin (mathematician)|Ivan Panin]]
*[[Georgios Pappas]]
*[[John Pardon]]
*[[Byeong U. Park]]
*[[Stefanie Petermichl]]
*[[Mamokgethi Phakeng]]
*[[Guido De Philippis]]
*[[Vincent Pilloni]]
*[[Jan von Plato]]
*[[Alexei Poltoratski]]
*[[Bjorn Poonen]]
*[[Mihnea Popa]]
*[[Alexander Postnikov (mathematician)|Alexander Postnikov]]
*[[Rafael Potrie]]
*[[Dipendra Prasad]]
*[[Feliks Przytycki]]
*[[Luis Radford]]
*[[Maksym Radziwill]]
*[[Prasad Raghavendra]]
*[[Alan Reid (mathematician)|Alan Reid]]
*[[Benjamin Rossman]]
*[[Tatiana Roque]]
*[[David E. Rowe]]
*[[Claudia Sagastizábal]]
*[[Pedro Salomão]]
*[[Sucharit Sarkar]]
*[[Olivier Schiffmann]]
*[[Benjamin Schlein]]
*[[Peter Scholze]]
*[[Sylvia Serfaty]]
*[[Mariya Shcherbina]]
*[[Amit Singer]]
*[[Allan Sly (mathematician)|Allan Sly]]
*[[Ivan Smith (mathematician)|Ivan Smith]]
*[[David Steurer]]
*[[Song Sun]]
*[[Balázs Szegedy]]
*[[Yūji Tachikawa]]
*[[Tao Tang]]
*[[Gábor Tardos]]
*[[Jonathan Taylor (mathematician)|Jonathan Taylor]]
*[[Andreas Thom (mathematician)|Andreas Thom]]
*[[Rekha R. Thomas]]
*[[Jack Thorne (mathematician)|Jack Thorne]]
*[[Dinh Tien-Cuong]]
*[[Pham Huu Tiep]]
*[[Philippe Toint]]
*[[Fabio Toninelli]]
*[[Anna-Karin Tornberg]]
*[[Bálint Tóth]]
*[[Emmanuel Trélat]]
*[[Jacob Tsimerman]]
*[[Virginia Vassilevska Williams]]
*[[Akshay Venkatesh]]
*[[Maryna Viazovska]]
*[[Eva Viehmann]]
*[[Miguel Walsh]]
*[[Simone Warzel]]
*[[Anna Wienhard]]
*[[Geordie Williamson]]
*[[Thomas Willwacher]]
*[[Wilhelm Winter]]
*[[Barbara Wohlmuth]]
*[[Nick Wormald]]
*[[Chenyang Xu]]
*[[Jiangong You]]
*[[Lai-Sang Young]]
*[[Zhiwei Yun]]
*[[Pingwen Zhang]]
*[[Wei Zhang (mathematician)|Wei Zhang]]
{{div col end}}

==The most invited speakers==
This list inventories the mathematicians who were the most invited to speak to an ICM.

{| class="wikitable sortable centre"
!Rank
!Name
!#
!Years
!Nationality
|-
|1
|''[[Jacques Hadamard]]''
|9
|[[#1897,_Zürich|1897]], [[#1900,_Paris|1900]], [[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1920,_Strasbourg|1920]], [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]], [[#1950,_Cambridge|1950]]
|{{flagcountry|France}}
|-
|2
|''[[Émile Borel]]''
|7
|[[#1897,_Zürich|1897]], [[#1900,_Paris|1900]], [[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1928,_Bologna|1928]], [[#1936,_Oslo|1936]]
|{{flagcountry|France}}
|-
|2
|''[[Jules Drach]]''
|7
|[[#1900,_Paris|1900]], [[#1912,_Cambridge|1912]], [[#1920,_Strasbourg|1920]], [[#1924,_Toronto|1924]], [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]], [[#1936,_Oslo|1936]]
|{{flagcountry|France}}
|-
|4
|''[[Elie Cartan]]''
|6
||[[#1900,_Paris|1900]], [[#1920,_Strasbourg|1920]], [[#1924,_Toronto|1924]], [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]], [[#1936,_Oslo|1936]]
|{{flagcountry|France}}
|-
|4
|''[[Gino Loria]]''
|6
|[[#1897,_Zürich|1897]], [[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]]
|{{flagcountry|Italy}}
|-
|4
|''[[Vito Volterra]]''
|6
|[[#1900,_Paris|1900]], [[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1920,_Strasbourg|1920]], [[#1928,_Bologna|1928]]
|{{flagcountry|Italy}}
|-
|7
|''[[Henri Fehr]]''
|5
|[[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1924,_Toronto|1924]], [[#1932,_Zürich|1932]]
|{{flagcountry|Switzerland}}
|-
|7
|''[[Rudolf Fueter]]''
|5
|[[#1920,_Strasbourg|1920]], [[#1924,_Toronto|1924]] , [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]], [[#1936,_Oslo|1936]]
|{{flagcountry|Switzerland}}
|-
|7
|''[[Yuri Manin]]''
|5
|[[#1966,_Moscow|1966]], [[#1970,_Nice|1970]] , [[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Russia}} {{flagcountry|Germany}}
|-
|7
|''[[Mihailo Petrović]]''
|5
|[[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1924,_Toronto|1924]] , [[#1928,_Bologna|1928]], [[#1932,_Zürich|1932]]
|{{flagcountry|Serbia}}
|-
|7
|''[[Cyparissos Stephanos]]''
|5
|[[#1897,_Zürich|1897]], [[#1900,_Paris|1900]], [[#1904,_Heidelberg|1904]], [[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]]
|{{flagcountry|Greece}}
|-
|7
|''[[Carl Størmer]]''
|5
|[[#1908,_Rome|1908]],[[#1920,_Strasbourg|1920]], [[#1924,_Toronto|1924]], [[#1932,_Zürich|1932]], [[#1936,_Oslo|1936]]
|{{flagcountry|Norway}}
|-
|7
|''[[Gheorghe Țițeica]]''
|5
|[[#1908,_Rome|1908]], [[#1912,_Cambridge|1912]], [[#1924,_Toronto|1924]], [[#1932,_Zürich|1932]], [[#1936,_Oslo|1936]]
|{{flagcountry|Romania}}
|-
|}

==The most invited speakers after 1950==
This list inventories the mathematicians who were the most invited to speak to an ICM '''after 1950'''.

{| class="wikitable sortable centre"
!Rank
!Name
!#
!Years
!Nationality
|-
|1
|''[[Yuri Manin]]''
|5
|[[#1966,_Moscow|1966]], [[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Russia}} {{flagcountry|Germany}}
|-
|2
|''[[Vladimir Arnold]]''
|4
|[[#1958,_Edinburgh|1958]], [[#1966,_Moscow|1966]], [[#1974,_Vancouver|1974]], [[#1983,_Warsaw|1983]]
|{{flagcountry|Russia}}
|-
|2
|''[[Michael Atiyah]]''
|4
|[[#1962,_Stockholm|1962]], [[#1966,_Moscow|1966]], [[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]]
|{{flagcountry|United Kingdom}}
|-
|2
|''[[Simon Donaldson]]''
|4
|[[#1983,_Warsaw|1983]], [[#1986,_Berkeley|1986]], [[#1998,_Berlin|1998]], [[#2018,_Rio de Janeiro|2018]]
|{{flagcountry|UK}}
|-
|2
|''[[Mikhail Leonidovich Gromov|Mikhail Gromov]]''
|4
|[[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]], [[#1983,_Warsaw|1983]], [[#1986,_Berkeley|1986]]
|{{flagcountry|Russia}} {{flagcountry|France}} 
|-
|2
|''[[Goro Shimura]]''
|4
|[[#1958,_Edinburgh|1958]], [[#1966,_Moscow|1966]], [[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]]
|{{flagcountry|Japan}}
|-
|2
|''[[Yakov Sinai]]''
|4
|[[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Russia}} {{flagcountry|USA}}
|-
|8
|''[[Paul Erdős]]''
|3 (4)
|([[#1936, Oslo|1936]],) [[#1950,_Cambridge|1950]], [[#1954,_Amsterdam|1954]], [[#1983,_Warsaw|1983]]
|{{flagcountry|Hungary}}
|-
|8
|''[[Beniamino Segre]]''
|3 (4)
|([[#1928, Oslo|1928]],) [[#1950,_Cambridge|1950]], [[#1954,_Amsterdam|1954]], [[#1958,_Edinburgh|1958]]
|{{flagcountry|Italy}}
|-
|10
|''[[Aldo Andreotti]]''
|3
|[[#1950,_Cambridge|1950]], [[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]]
|{{flagcountry|Italy}}
|-
|10
|''[[James Arthur (mathematician)|James Arthur]]''
|3
|[[#1983,_Warsaw|1983]], [[#1998,_Berlin|1998]], [[#2014,_Seoul|2014]]
|{{flagcountry|Canada}}
|-
|10
|''[[László Babai]]''
|3
|[[#1990,_Kyoto|1990]], [[#1994,_Zürich|1994]], [[#2018,_Rio de Janeiro|2018]]
|{{flagcountry|Hungary}}
|-
|10
|''[[Jean Bourgain]]''
|3
|[[#1983,_Warsaw|1983]], [[#1986,_Berkeley|1986]], [[#1994,_Zürich|1994]]
|{{flagcountry|Belgium}}
|-
|10
|''[[Alberto Calderón]]''
|3
|[[#1950,_Cambridge|1950]], [[#1966,_Moscow|1966]], [[#1978,_Helsinki|1978]]
|{{flagcountry|Argentina}}
|-
|10
|''[[Lennart Carleson]]''
|3
|[[#1962,_Stockholm|1962]], [[#1966,_Moscow|1966]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Sweden}}
|-
|10
|''[[Shiing-Shen Chern]]''
|3
|[[#1950,_Cambridge|1950]], [[#1958,_Edinburgh|1958]], [[#1970,_Nice|1970]]
|{{flagcountry|China}} {{flagcountry|USA}}
|-
|10
|''[[Alain Connes]]''
|3
|[[#1974,_Vancouver|1974]], [[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]]
|{{flagcountry|France}}
|-
|10
|''[[John Horton Conway|John Conway]]''
|3
|[[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]], [[#1994,_Zürich|1994]]
|{{flagcountry|UK}}
|-
|10
|''[[Roland Dobrushin]]''
|3
|[[#1974,_Vancouver|1974]], [[#1978,_Helsinki|1978]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Russia}}
|-
|10
|''[[Eugene Dynkin]]''
|3
|[[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]], [[#1974,_Vancouver|1974]]
|{{flagcountry|USSR}} {{flagcountry|USA}}
|-
|10
|''[[Yakov Eliashberg]]''
|3
|[[#1986,_Berkeley|1986]], [[#1998,_Berlin|1998]], [[#2006,_Madrid|2006]]
|{{flagcountry|USA}}
|-
|10
|''[[Jürg Fröhlich]]''
|3
|[[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]], [[#1994,_Zürich|1994]]
|{{flagcountry|Switzerland}}
|-
|10
|''[[Frederick Gehring]]''
|3
|[[#1966,_Moscow|1966]], [[#1974,_Vancouver|1974]], [[#1986,_Berkeley|1986]]
|{{flagcountry|USA}}
|-
|10
|''[[Israel Gelfand]]''
|3
|[[#1954,_Amsterdam|1954]], [[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]]
|{{flagcountry|Russia}}
|-
|10
|''[[Étienne Ghys]]''
|3
|[[#1990,_Kyoto|1990]], [[#2006,_Madrid|2006]], [[#2014,_Seoul|2014]]
|{{flagcountry|France}}
|-
|10
|''[[Hans Grauert]]''
|3
|[[#1958,_Edinburgh|1958]], [[#1962,_Stockholm|1962]], [[#1966,_Moscow|1966]]
|{{flagcountry|Germany}}
|-
|10
|''[[Henryk Iwaniec]]''
|3
|[[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]], [[#2006,_Madrid|2006]]
|{{flagcountry|Poland}} {{flagcountry|USA}}
|-
|10
|''[[Kazuya Kato]]''
|3
|[[#1990,_Kyoto|1990]], [[#2002,_Beijing|2002]], [[#2006,_Madrid|2006]]
|{{flagcountry|Japan}}
|-
|10
|''[[Carlos Kenig]]''
|3
|[[#1986,_Berkeley|1986]], [[#2002,_Beijing|2002]], [[#2010,_Hyderabad|2010]]
|{{flagcountry|Argentina}} {{flagcountry|USA}}
|-
|10
|''[[Harry Kesten]]''
|3
|[[#1970,_Nice|1970]], [[#1983,_Warsaw|1983]], [[#2002,_Beijing|2002]]
|{{flagcountry|USA}}
|-
|10
|''[[Olga Ladyzhenskaya]]''
|3
|[[#1966,_Moscow|1966]], [[#1983,_Warsaw|1983]], [[#1994,_Zürich|1994]]
|{{flagcountry|Russia}}
|-
|10
|''[[Peter Lax]]''
|3
|[[#1966,_Moscow|1966]], [[#1970,_Nice|1970]], [[#1983,_Warsaw|1983]]
|{{flagcountry|USA}}
|-
|10
|''[[Jacques-Louis Lions]]''
|3
|[[#1958,_Edinburgh|1958]], [[#1970,_Nice|1970]], [[#1974,_Vancouver|1974]]
|{{flagcountry|France}}
|-
|10
|''[[Pierre-Louis Lions]]''
|3
|[[#1983,_Warsaw|1983]], [[#1990,_Kyoto|1990]], [[#1994,_Zürich|1994]]
|{{flagcountry|France}}
|-
|10
|''[[George Lusztig]]''
|3
|[[#1974,_Vancouver|1974]], [[#1983,_Warsaw|1983]], [[#1990,_Kyoto|1990]]
|{{flagcountry|Romania}} {{flagcountry|USA}}
|-
|10
|''[[Yves Meyer]]''
|3
|[[#1970,_Nice|1970]], [[#1983,_Warsaw|1983]], [[#1990,_Kyoto|1990]]
|{{flagcountry|France}}
|-
|10
|''[[John Milnor]]''
|3
|[[#1958,_Edinburgh|1958]], [[#1962,_Stockholm|1962]], [[#2014,_Seoul|2014]]
|{{flagcountry|USA}}
|-
|10
|''[[Jürgen Moser]]''
|3
|[[#1962,_Stockholm|1962]], [[#1978,_Helsinki|1978]], [[#1998,_Berlin|1998]]
|{{flagcountry|Germany}} {{flagcountry|USA}}
|-
|10
|''[[David Mumford]]''
|3
|[[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]], [[#2002,_Beijing|2002]]
|{{flagcountry|USA}}
|-
|10
|''[[Sergei Novikov (mathematician)|Sergei Novikov]]''
|3
|[[#1966,_Moscow|1966]], [[#1970,_Nice|1970]], [[#1978,_Helsinki|1978]]
|{{flagcountry|Russia}}
|-
|10
|''[[Ilya Piatetski-Shapiro]]''
|3
|[[#1966,_Moscow|1966]], [[#1978,_Helsinki|1978]], [[#2002,_Beijing|2002]]
|{{flagcountry|Russia}} {{flagcountry|Israel}}
|-
|10
|''[[Wolfgang M. Schmidt]]''
|3
|[[#1970,_Nice|1970]], [[#1974,_Vancouver|1974]], [[#1983,_Warsaw|1983]]
|{{flagcountry|Austria}}
|-
|10
|''[[Richard Schoen]]''
|3
|[[#1983,_Warsaw|1983]], [[#1986,_Berkeley|1986]], [[#2010,_Hyderabad|2010]]
|{{flagcountry|USA}}
|-
|10
|''[[Saharon Shelah]]''
|3
|[[#1974,_Vancouver|1974]], [[#1983,_Warsaw|1983]], [[#1986,_Berkeley|1986]]
|{{flagcountry|Israel}}
|-
|10
|''[[Yum-Tong Siu]]''
|3
|[[#1978,_Helsinki|1978]], [[#1983,_Warsaw|1983]], [[#2002,_Beijing|2002]]
|{{flagcountry|China}}
|-
|10
|''[[Stephen Smale]]''
|3
|[[#1962,_Stockholm|1962]], [[#1966,_Moscow|1966]], [[#1986,_Berkeley|1986]]
|{{flagcountry|USA}}
|-
|10
|''[[Daniel Spielman]]''
|3
|[[#2002,_Beijing|2002]], [[#2010,_Hyderabad|2010]], [[#2014,_Seoul|2014]]
|{{flagcountry|USA}}
|-
|10
|''[[Elias M. Stein]]''
|3
|[[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]], [[#1986,_Berkeley|1986]]
|{{flagcountry|USA}}
|-
|10
|''[[Dennis Sullivan]]''
|3
|[[#1970,_Nice|1970]], [[#1986,_Berkeley|1986]], [[#1974,_Vancouver|1974]]
|{{flagcountry|USA}}
|-
|10
|''[[Andrei Suslin]]''
|3
|[[#1978,_Helsinki|1978]], [[#1986,_Berkeley|1986]], [[#1994,_Zürich|1994]]
|{{flagcountry|Russia}}
|-
|10
|''[[Clifford Taubes]]''
|3
|[[#1986,_Berkeley|1986]], [[#1994,_Zürich|1994]], [[#1998,_Berlin|1998]]
|{{flagcountry|USA}}
|-
|10
|''[[René Thom]]''
|3
|[[#1958,_Edinburgh|1958]], [[#1970,_Nice|1970]], [[#1983,_Warsaw|1983]]
|{{flagcountry|France}}
|-
|10
|''[[John G. Thompson]]''
|3
|[[#1962,_Stockholm|1962]], [[#1966,_Moscow|1966]], [[#1970,_Nice|1970]]
|{{flagcountry|USA}}
|-
|10
|''[[Jacques Tits]]''
|3
|[[#1962,_Stockholm|1962]], [[#1970,_Nice|1970]], [[#1974,_Vancouver|1974]]
|{{flagcountry|Belgium}} {{flagcountry|France}}
|-
|10
|''[[S. R. Srinivasa Varadhan]]''
|3
|[[#1978,_Helsinki|1978]], [[#1994,_Zürich|1994]], [[#2010,_Hyderabad|2010]]
|{{flagcountry|USA}}
|-
|10
|''[[Jean-Loup Waldspurger]]''
|3
|[[#1983,_Warsaw|1983]], [[#1994,_Zürich|1994]], [[#2014,_Seoul|2014]]
|{{flagcountry|France}}
|-
|10
|''[[André Weil]]''
|3
|[[#1950,_Cambridge|1950]], [[#1954,_Amsterdam|1954]], [[#1978,_Helsinki|1978]]
|{{flagcountry|France}}
|-
|}

==References==
{{reflist|30em}}

==External links==
*{{cite web|url=http://www.mathunion.org/db/ICM/Speakers/SortedByCongress.php|title=International Mathematical Union (IMU)|publisher=mathunion.org|accessdate=2015-09-06}}
*{{cite web|url=http://www-history.mcs.st-and.ac.uk/Societies/ICM.html|title=ICM Main invited speakers|publisher=www-history.mcs.st-and.ac.uk|accessdate=2015-09-06}}

[[Category:International Congress of Mathematicians]]
[[Category:Lists of mathematicians|International Congress of Mathematicians]]</text>
      <sha1>tldpuqyym6o1n1gonmmev0u0l26u87s</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Stefan Banach</title>
    <ns>0</ns>
    <id>49593538</id>
    <revision>
      <id>858655060</id>
      <parentid>772271069</parentid>
      <timestamp>2018-09-08T18:57:36Z</timestamp>
      <contributor>
        <username>Staszek Lem</username>
        <id>12536756</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1169">[[Stefan Banach]] was a Polish mathematician who made key contributions to mathematics. This article contains some of the things named in his memory.

==Mathematics==
* [[Banach algebra]]
** [[Amenable Banach algebra]]
*[[ Banach Jordan algebra]]
** [[Banach function algebra]]
**[[Banach *-algebra]]
**[[Banach algebra cohomology]]
* [[Banach bundle]]
**[[Banach bundle (non-commutative geometry)]]
*[[Banach fixed-point theorem]]
*[[Banach game]]
*[[Banach lattice]]
* [[Banach limit]]
*[[Banach–Mazur compactum]]
* [[Banach manifold]]
* [[Banach measure]]
*Banach norm, see Banach space
* [[Banach space]]
*[[ Banach–Alaoglu theorem]]
*[[Banach–Mazur compactum]]
*[[Banach–Mazur game]]
*Banach–Ruziewicz problem, see [[Ruziewicz problem]]
*[[Banach-Saks theorem]]
*[[ Banach-Schauder theorem]]
*[[Banach–Steinhaus theorem]]
*[[Banach–Stone theorem]]
* [[Banach–Tarski paradox]]
* [[Banach's matchbox problem]]
* [[Hahn–Banach theorem]]

==Other==
* [[16856 Banach]]
*[[Banach Journal of Mathematical Analysis ]]
*[[International Stefan Banach Prize]]

==See also==
*{{intitle|Banach}}

[[Category:Lists of things named after mathematicians|Banach]]</text>
      <sha1>3wemslnmc2c65qhdqe5dj8274xumbvx</sha1>
    </revision>
  </page>
  <page>
    <title>Madhava series</title>
    <ns>0</ns>
    <id>26149716</id>
    <revision>
      <id>840527887</id>
      <parentid>835647187</parentid>
      <timestamp>2018-05-10T13:32:52Z</timestamp>
      <contributor>
        <username>LilHelpa</username>
        <id>8024439</id>
      </contributor>
      <minor/>
      <comment>typo in title, added url</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30550">In [[mathematics]], a  '''Leibniz or Madhava series''' is any one of the series in a collection of [[infinite series]] expressions all of which are believed to have been discovered by [[Madhava of Sangamagrama]] (c.&amp;nbsp;1350 – c.&amp;nbsp;1425), the founder of the [[Kerala school of astronomy and mathematics]] and later by [[Gottfried Wilhelm Leibniz]], among others. These expressions are the [[Maclaurin series]] expansions of the trigonometric [[sine]], [[cosine]] and [[arctangent]] [[Function (mathematics)|functions]], and the special case of the power series expansion of the arctangent function yielding a formula for computing π. The power series expansions of sine and cosine functions are respectively called ''Madhava's sine series'' and ''Madhava's cosine series''.  The power series expansion of the arctangent function is sometimes called ''Madhava–Gregory series''&lt;ref&gt;Reference to Gregory–Madhava series: {{Cite web|url=http://www.luigigobbi.com/EarliestKnownUsesOfSomeOfTheWordsOfMathematics/G-K.htm|title=Earliest Known Uses of Some of the Words of Mathematics|accessdate=11 February 2010}}&lt;/ref&gt;&lt;ref&gt;Reference to Gregory–Madhava series: {{Cite web|url=http://www.mat.uc.pt/~jaimecs/pessoal/hpm.html|title=History of Mathematics in the classroom|last=Jaime Carvalho e Silva|date = July 1994|accessdate=15 February 2010}}&lt;/ref&gt; or ''Gregory–Madhava series''. These power series are also collectively called  ''Taylor–Madhava series''.&lt;ref&gt;{{Cite journal|title=Topic entry on complex analysis : Introduction|publisher=PlanetMath.org|url=http://planetmath.org/encyclopedia/ComplexAnalytic2.html|accessdate=10 February 2010}}&lt;/ref&gt; The formula for π is  referred to as ''Madhava–[[Isaac Newton|Newton]] series'' or ''Madhava–[[Gottfried Leibniz|Leibniz]] series'' or [[Leibniz formula for pi]] or Leibnitz–Gregory–Madhava series.&lt;ref&gt;{{Cite journal|last=Pascal Sebah|author2=Xavier Gourdon|year=2004|title=Collection of series for pi|url=http://math.bu.edu/people/tkohl/teaching/spring2008/piSeries.pdf|accessdate=10 February 2010}}&lt;/ref&gt;  These further names for the various series are reflective of the names of the [[Western world|Western]] discoverers or popularizers of the respective series.

The derivations use many calculus related concepts such as summation, rate of change, and interpolation, which suggests that Indian mathematicians had a solid understanding of the basics of calculus long before it was developed in Europe. There is no evidence, however, that any of his ideas went out of Kerala. The [[calculus]] was still in its primitive stages and it would remain so until [[Isaac Newton|Newton]] and [[Leibniz]] entered the scene. Even though they had very basic ideas on the infinite series, Indian Mathematicians were not able to convert calculus to the modern problem solving tool that it is today.
No surviving works of Madhava contain explicit statements regarding the expressions which are now referred to as Madhava series. However, in the writing of later members of the [[Kerala school of astronomy and mathematics]] like [[Nilakantha Somayaji]] and [[Jyeshthadeva]] one can find unambiguous attributions of these series to Madhava. It is also in the works of these later astronomers and mathematicians one can trace the Indian proofs of these series expansions. These proofs provide enough indications about the approach Madhava had adopted to arrive at his series expansions.

Unlike most previous cultures, which had been rather nervous about the concept of infinity, Madhava was more than happy to play around with infinity, particularly infinite series. He showed how, although one can be approximated by adding a half plus a quarter plus an eighth plus a sixteenth, etc., (as even the ancient Egyptians and Greeks had known), the exact total of one can only be achieved by adding up infinitely many fractions. But Madhava went further and linked the idea of an infinite series with geometry and trigonometry. He realized that, by successively adding and subtracting different odd number fractions to infinity, he could home in on an exact formula for π (this was two centuries before Leibniz was to come to the same conclusion in Europe).&lt;ref&gt;{{cite book |title=How Mechanics Shaped the Modern World |edition=illustrated |first1=David |last1=Allen |publisher=Springer Science &amp; Business Media |year=2013 |isbn=978-3-319-01701-3 |page=156 |url=https://books.google.com/books?id=wRm4BAAAQBAJ}} [https://books.google.com/books?id=wRm4BAAAQBAJ&amp;pg=PA156 Extract of page 156]&lt;/ref&gt;

==Madhava's series in modern notations==
In the writings of the mathematicians and astronomers of the [[Kerala school of astronomy and mathematics|Kerala school]], Madhava's series are described couched in the terminology and concepts fashionable at that time. When we translate these ideas into the notations and concepts of modern-day mathematics, we obtain the current equivalents of Madhava's series. These present-day counterparts of the infinite series expressions discovered by Madhava are the following:

&lt;center&gt;
{| class="wikitable"
|-
! No.
! Series
! Name
! Western discoverers of the series&lt;br&gt;and approximate dates of discovery&lt;ref&gt;{{Cite book|last=Charles Henry Edwards|title=The historical development of the calculus|publisher=Springer|year=1994|edition=3|series=Springer Study Edition Series|page=205|isbn=978-0-387-94313-8}}&lt;/ref&gt;
|-
| style="text-align:center;"|1
| style="padding:0 1ex;"|sin ''x'' = ''x'' &amp;minus; {{sfrac|''x''&lt;sup&gt;3&lt;/sup&gt;|3!}} + {{sfrac|''x''&lt;sup&gt;5&lt;/sup&gt;|5!}} &amp;minus; {{sfrac|''x''&lt;sup&gt;7&lt;/sup&gt;|7!}} + ...
| style="padding:0 1ex;"|Madhava's sine series
| style="padding:0 1ex;"|Isaac Newton (1670) and Wilhelm Leibniz (1676)
|-
| style="text-align:center;"|2
| style="padding:0 1ex;"|cos ''x'' = 1 &amp;minus; {{sfrac|''x''&lt;sup&gt;2&lt;/sup&gt;|2!}} + {{sfrac|''x''&lt;sup&gt;4&lt;/sup&gt;|4!}} &amp;minus; {{sfrac|''x''&lt;sup&gt;6&lt;/sup&gt;|6!}} + ...
| style="padding:0 1ex;"|Madhava's cosine series
| style="padding:0 1ex;"|Isaac Newton (1670) and Wilhelm Leibniz (1676)
|-
| style="text-align:center;"|3
| style="padding:0 1ex;"|arctan ''x'' = ''x'' &amp;minus; {{sfrac|''x''&lt;sup&gt;3&lt;/sup&gt;|3}} + {{sfrac|''x''&lt;sup&gt;5&lt;/sup&gt;|5}} &amp;minus; {{sfrac|''x''&lt;sup&gt;7&lt;/sup&gt;|7}} + ...
| style="padding:0 1ex;"|Madhava's series for arctangent
| style="padding:0 1ex;"|James Gregory (1671) and Wilhelm Leibniz (1676)
|-
| style="text-align:center;"|4
| style="padding:0 1ex;"|[[Leibniz formula for π|{{sfrac|{{pi}}|4}} = 1 &amp;minus; {{sfrac|1|3}} + {{sfrac|1|5}} &amp;minus; {{sfrac|1|7}} + ...]]
| style="padding:0 1ex;"|Madhava's formula for {{pi}}
| style="padding:0 1ex;"|James Gregory (1671) and Wilhelm Leibniz (1676)
|}
&lt;/center&gt;

==Madhava series in "Madhava's own words"==
None of Madhava's works, containing any of the series expressions attributed to him, have survived. These series expressions are found in the writings of the followers of Madhava in the [[Kerala school of astronomy and mathematics|Kerala school]]. At many places these authors have clearly stated that these are "as told by Madhava". Thus the enunciations of the various series found in [[Tantrasamgraha]] and its commentaries can be safely assumed to be in "Madhava's own words". The translations of the relevant verses as given in the ''Yuktidipika'' commentary of [[Tantrasamgraha]]  (also known as ''Tantrasamgraha-vyakhya'') by [[Sankara Variar]] (circa. 1500 - 1560 CE)  are reproduced below. These are then rendered in current mathematical notations.&lt;ref&gt;{{Cite journal|last=A.K. Bag|year=1975|title=Madhava's sine and cosine series|journal=Indian Journal of History of Science|volume=11|issue=1|pages=54–57|url=http://www.new.dli.ernet.in/rawdataupload/upload/insa/INSA_1/20005af4_54.pdf|accessdate=11 February 2010|deadurl=yes|archiveurl=https://web.archive.org/web/20100214195826/http://www.new.dli.ernet.in/rawdataupload/upload/insa/INSA_1/20005af4_54.pdf|archivedate=14 February 2010|df=dmy-all}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=C.K. Raju|title=Cultural Foundations of Mathematics : Nature of Mathematical Proof and the Transmission of the Calculus from India to Europe in the 16 c. CE|url=https://books.google.com/books/about/Cultural_Foundations_of_Mathematics.html?id=jza_cNJM6fAC|publisher=Centre for Studies in Civilistaion|location=New Delhi|year=2007|series=History of Science, Philosophy and Culture in Indian Civilisation|volume=X Part 4|pages=114–120|isbn=81-317-0871-3}}&lt;/ref&gt;

==Madhava's sine series==

===In Madhava's own words===

Madhava's sine series is stated in verses 2.440 and 2.441 in ''Yukti-dipika'' commentary (''Tantrasamgraha-vyakhya'') by [[Sankara Variar]]. A translation of the verses follows.

''Multiply the arc by the square of the arc, and take the result of repeating that (any number of times). Divide (each of the above numerators)  by the squares of the successive even numbers increased by that number and multiplied by the square of the radius.  Place the arc and the successive results so obtained one below the other, and subtract each from the one above. These together give the jiva, as collected together in the verse beginning with "vidvan" etc. ''

===Rendering in modern notations===

Let ''r'' denote the radius of the circle and ''s'' the arc-length.

*The following numerators are formed first:
:: &lt;math&gt;s \cdot s^2 ,\qquad s \cdot s^2 \cdot s^2 , \qquad s \cdot s^2 \cdot s^2 \cdot s^2, \qquad \cdots&lt;/math&gt;
*These are then divided by quantities specified in the verse.
:: &lt;math&gt;s\cdot \frac{s^2}{(2^2+2)r^2}, \qquad s\cdot \frac{s^2}{(2^2+2)r^2}\cdot \frac{s^2}{(4^2+4)r^2},\qquad s\cdot \frac{s^2}{(2^2+2)r^2}\cdot \frac{s^2}{(4^2+4)r^2}\cdot \frac{s^2}{(6^2+6)r^2}, \qquad \cdots &lt;/math&gt;
*Place the arc and the successive results so obtained one below the other, and subtract each from the one above to get ''jiva'':
::&lt;math&gt; \text{jiva}= s - \left [ s\cdot \frac{s^2}{(2^2+2)r^2} - \left [ s\cdot \frac{s^2}{(2^2+2)r^2}\cdot \frac{s^2}{(4^2+4)r^2} -\left [ s\cdot \frac{s^2}{(2^2+2)r^2}\cdot \frac{s^2}{(4^2+4)r^2}\cdot \frac{s^2}{(6^2+6)r^2}-\cdots\right]\right]\right] &lt;/math&gt;

===Transformation to current notation===

Let θ be the angle subtended by the arc ''s'' at the centre of the circle. Then ''s'' = ''r θ'' and ''jiva'' = ''r'' sin ''θ''. Substituting these in the last expression and simplifying we get
:&lt;math&gt;\sin \theta = \theta - \frac{\theta^3}{3!} + \frac{\theta^5}{5!} - \frac{\theta^7}{7!} + \quad \cdots &lt;/math&gt;
which is the infinite power series expansion of the sine function.

===Madhava's reformulation for numerical computation===
The last line in the verse &amp;prime;''as collected together in the verse beginning with "vidvan" etc.''&amp;prime; is a reference to a reformulation of the series introduced by Madhava himself to make it convenient for easy computations for specified values of the arc and the radius.
For such a reformulation, Madhava considers a circle one-quarter of which measures 5400 minutes (say ''C'' minutes) and develops a scheme for the easy computations of the ''jiva''&amp;prime;s of the various arcs of such a circle. Let ''R'' be the radius of a circle one-quarter of which measures C.
Madhava had already computed the value of π using his series formula for π.&lt;ref name="Raju"&gt;{{Cite book|last=C.K. Raju|title=Cultural foundations of mathematics: The nature of mathematical proof and the transmission of calculus from India to Europe in the 16 thc. CE|publisher=Centre for Studies in Civilizations|location=Delhi|year=2007|series=History of Philosophy, Science and Culture in Indian Civilization|volume=X Part 4|page=119}}&lt;/ref&gt; Using this value of π, namely  3.1415926535922, the radius ''R'' is computed as follows:
Then

:''R'' = 2 &amp;times; 5400 / &amp;pi; = 3437.74677078493925 = 3437 [[arcminute]]s 44 [[arcsecond]]s  48 sixtieths of an [[arcsecond]] = 3437&amp;prime;  44&amp;prime;&amp;prime;  48&amp;prime;&amp;prime;&amp;prime;.

Madhava's  expression for ''jiva'' corresponding to any arc ''s'' of a circle of radius ''R'' is equivalent to the following:

:&lt;math&gt;\begin{align}
\text{jiva } &amp; = s - \frac{s^3}{R^2(2^2+2)} + \frac{s^5}{R^4(2^2+2)(4^2+4)}- \cdots \\[6pt]
&amp; = s  - \left(\frac{s}{C}\right)^3 \left [   \frac{R \left(\frac{\pi}{2}\right)^3}{3!} 
- \left(\frac{s}{C}\right)^2 \left [  \frac{R \left(\frac{\pi}{2}\right)^5}{5!}
 - \left(\frac{s}{C}\right)^2 \left [  \frac{R \left(\frac{\pi}{2}\right)^7}{7!} - \cdots  \right ]\right]\right].
\end{align}&lt;/math&gt;

Madhava now  computes the following values:

&lt;center&gt;
{| class="wikitable"
|-
! No.
! Expression
! Value
! Value in [[Katapayadi system]]
|-
| &amp;nbsp;&amp;nbsp; 1 &amp;nbsp;&amp;nbsp;
| &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;3&lt;/sup&gt; / 3! &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 2220&amp;prime; &amp;nbsp; 39&amp;prime;&amp;prime; &amp;nbsp;  40&amp;prime;&amp;prime;&amp;prime;  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; ni-rvi-ddhā-nga-na-rē-ndra-rung &amp;nbsp;&amp;nbsp;
|-
| &amp;nbsp;&amp;nbsp;  2 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;5&lt;/sup&gt; / 5!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 273&amp;prime; &amp;nbsp; 57&amp;prime;&amp;prime; &amp;nbsp; 47&amp;prime;&amp;prime;&amp;prime;  &amp;nbsp;&amp;nbsp;
| &amp;nbsp;&amp;nbsp;  sa-rvā-rtha-śī-la-sthi-ro &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 3 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;7&lt;/sup&gt; / 7!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 16&amp;prime; &amp;nbsp; 05&amp;prime;&amp;prime; &amp;nbsp;  41&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; ka-vī-śa-ni-ca-ya &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 4 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;9&lt;/sup&gt; / 9!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 33&amp;prime;&amp;prime; &amp;nbsp; 06&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; tu-nna-ba-la &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 5 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;11&lt;/sup&gt; / 11!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 44&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; vi-dvān &amp;nbsp;&amp;nbsp;
|-
|}
&lt;/center&gt;

The ''jiva'' can now be computed using the following scheme:

:''jiva'' = ''s'' &amp;minus; (''s'' / ''C'')&lt;sup&gt;3&lt;/sup&gt; [ (2220&amp;prime; 39&amp;prime;&amp;prime;   40&amp;prime;&amp;prime;&amp;prime;) &amp;minus;  (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt; [ (273&amp;prime;  57&amp;prime;&amp;prime;  47&amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt; [ (16&amp;prime; 05&amp;prime;&amp;prime;  41&amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt;[ (33&amp;prime;&amp;prime; 06&amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt;  (44&amp;prime;&amp;prime;&amp;prime; ) ] ] ] ].

This gives an approximation of ''jiva'' by its Taylor polynomial of the 11'th order. It involves one division, six multiplications and five subtractions only. Madhava prescribes this numerically efficient computational scheme in the following words (translation of verse 2.437 in ''Yukti-dipika''):

''vi-dvān, tu-nna-ba-la, ka-vī-śa-ni-ca-ya, sa-rvā-rtha-śī-la-sthi-ro, ni-rvi-ddhā-nga-na-rē-ndra-rung . Successively multiply these five numbers in order by the square of the arc divided by the quarter of the circumference (5400&amp;prime;), and subtract from the next number. (Continue this process with the result so obtained and the next number.) Multiply the final result by the cube of the arc divided by quarter of the circumference and subtract from the arc.''

==Madhava's cosine series==

===In Madhava's own words===

Madhava's cosine series is stated in verses 2.442 and 2.443 in ''Yukti-dipika'' commentary (''Tantrasamgraha-vyakhya'') by [[Sankara Variar]]. A translation of the verses follows.

''Multiply the square of the arc by the unit (i.e. the radius) and take the result of repeating that (any number of times). Divide (each of the above numerators) by the square of the successive even numbers decreased by that number and multiplied by the square of the radius. But the first term is (now)(the one which is) divided by twice the radius. Place the successive results so obtained one below the other and subtract each from the one above. These together give the śara as collected together in the verse beginning with stena, stri, etc. ''

===Rendering in modern notations===

Let ''r'' denote the radius of the circle and ''s'' the arc-length.

*The following numerators are formed first:
:: &lt;math&gt;r \cdot s^2 ,\qquad r \cdot s^2 \cdot s^2 , \qquad r \cdot s^2 \cdot s^2 \cdot s^2 , \qquad \cdots &lt;/math&gt;
*These are then divided by quantities specified in the verse.
:: &lt;math&gt;r\cdot \frac{s^2}{(2^2 - 2)r^2}, \qquad r\cdot \frac{s^2}{(2^2 - 2)r^2}\cdot \frac{s^2}{(4^2-4)r^2},\qquad r\cdot \frac{s^2}{(2^2-2)r^2}\cdot \frac{s^2}{(4^2-4)r^2}\cdot \frac{s^2}{(6^2-6)r^2}, \qquad \cdots &lt;/math&gt;
*Place the arc and the successive results so obtained one below the other, and subtract each from the one above to get ''śara'':
:: &lt;math&gt; \text{sara}=   r\cdot \frac{s^2}{(2^2 - 2)r^2} - \left [ r\cdot \frac{ s^2}{(2^2-2)r^2}\cdot \frac{s^2}{(4^2-4)r^2} -\left [ r\cdot \frac{ s^2}{(2^2-2)r^2}\cdot \frac{s^2}{(4^2-4)r^2}\cdot \frac{s^2}{(6^2-6)r^2}-\cdots\right]\right] &lt;/math&gt;

===Transformation to current notation===

Let ''θ'' be the angle subtended by the arc ''s'' at the centre of the circle. Then ''s'' = ''rθ'' and ''śara'' = ''r''(1 − cos ''θ''). Substituting these in the last expression and simplifying we get
:&lt;math&gt;1 - \cos \theta = \frac{\theta^2}{2!}  -  \frac{\theta^4}{4!} + \frac{\theta^6}{6!} + \quad \cdots &lt;/math&gt;
which gives  the infinite power series expansion of the cosine function.

===Madhava's reformulation for numerical computation===

The last line in the verse &amp;prime;''as collected together in the verse beginning with stena, stri, etc.''&amp;prime; is a reference to a reformulation introduced  by Madhava himself to make the series convenient for easy computations for specified values of the arc and the radius.
As in the case of the sine series, Madhava considers a circle one quarter of which measures 5400 minutes (say ''C'' minutes) and develops a scheme for the easy computations of the ''śara''&amp;prime;s of the various arcs of such a circle. Let ''R'' be the radius of a circle one quarter of which measures C. Then, as in the case of the sine series, Madhava gets
''R'' = 3437&amp;prime;  44&amp;prime;&amp;prime;  48&amp;prime;&amp;prime;&amp;prime;.

Madhava's  expression for ''śara'' corresponding to any arc ''s'' of a circle of radius ''R'' is equivalent to the following:

:&lt;math&gt;
\begin{align}
\text{jiva } &amp; = R\cdot \frac{s^2}{R^2(2^2-2)} - R\cdot \frac{s^4}{R^4(2^2-2)(4^2-4)}- \cdots \\
&amp; = \left(\frac{s}{C}\right)^2 \left[   \frac{R \left(\frac{\pi}{2}\right)^2}{2!} 
- \left(\frac{s}{C}\right)^2 \left[  \frac{R \left(\frac{\pi}{2}\right)^4}{4!}
 - \left(\frac{s}{C}\right)^2 \left[  \frac{R \left(\frac{\pi}{2}\right)^6}{6!} - \cdots  \right]\right]\right]
\end{align}
&lt;/math&gt;

Madhava now  computes the following values:

&lt;center&gt;
{| class="wikitable"
|-
! No.
! Expression
! Value
! Value in [[Katapayadi system]]
|-
| &amp;nbsp;&amp;nbsp; 1 &amp;nbsp;&amp;nbsp;
| &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;2&lt;/sup&gt; / 2! &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 4241&amp;prime; &amp;nbsp; 09&amp;prime;&amp;prime; &amp;nbsp;  00&amp;prime;&amp;prime;&amp;prime;  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; u-na-dha-na-krt-bhu-re-va &amp;nbsp;&amp;nbsp;
|-
| &amp;nbsp;&amp;nbsp;  2 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;4&lt;/sup&gt; / 4!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 872&amp;prime; &amp;nbsp; 03&amp;prime;&amp;prime; &amp;nbsp; 05 &amp;prime;&amp;prime;&amp;prime;  &amp;nbsp;&amp;nbsp;
| &amp;nbsp;&amp;nbsp; mī-nā-ngo-na-ra-sim-ha &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 3 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;6&lt;/sup&gt; / 6!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 071&amp;prime; &amp;nbsp; 43&amp;prime;&amp;prime; &amp;nbsp;  24&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; bha-drā-nga-bha-vyā-sa-na &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 4 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;8&lt;/sup&gt; / 8!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 03&amp;prime; &amp;nbsp; 09&amp;prime;&amp;prime; &amp;nbsp; 37&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; su-ga-ndhi-na-ga-nud  &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 5 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;10&lt;/sup&gt; / 10!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 05&amp;prime;&amp;prime; &amp;nbsp; 12&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; strī-pi-śu-na  &amp;nbsp;&amp;nbsp;
|-
|  &amp;nbsp;&amp;nbsp; 6 &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; R &amp;times; (π / 2)&lt;sup&gt;12&lt;/sup&gt; / 12!  &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; 06&amp;prime;&amp;prime;&amp;prime; &amp;nbsp;&amp;nbsp;
|  &amp;nbsp;&amp;nbsp; ste-na &amp;nbsp;&amp;nbsp;
|-
|}
&lt;/center&gt;

The ''śara'' can now be computed using the following scheme:

:''śara'' = (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt; [ (4241&amp;prime;  09&amp;prime;&amp;prime;   00&amp;prime;&amp;prime;&amp;prime;) &amp;minus;  (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt; [ (872&amp;prime; 03&amp;prime;&amp;prime; 05 &amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt; [  (071&amp;prime; 43&amp;prime;&amp;prime; 24&amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt;[ (03&amp;prime; 09&amp;prime;&amp;prime; 37&amp;prime;&amp;prime;&amp;prime;) &amp;minus; (''s'' / ''C'')&lt;sup&gt;2&lt;/sup&gt;  [(05&amp;prime;&amp;prime; 12&amp;prime;&amp;prime;&amp;prime;) − (s / C)&lt;sup&gt;2&lt;/sup&gt; (06&amp;prime;&amp;prime;&amp;prime;) ] ] ] ] ]

This gives an approximation of ''śara'' by its Taylor polynomial of the 12'th order. This also involves one division, six multiplications and five subtractions only. Madhava prescribes this numerically efficient computational scheme in the following words (translation of verse 2.438 in ''Yukti-dipika''):

''The six stena, strīpiśuna, sugandhinaganud, bhadrāngabhavyāsana, mīnāngonarasimha, unadhanakrtbhureva. Multiply by the square of the arc  divided by the quarter of the circumference and subtract from the next number. (Continue with the result and the next number.) Final result will be [[utkrama-jya]] (R versed sign).''

==Madhava's arctangent series==

===In Madhava's own words===

Madhava's arctangent series is stated in verses 2.206 &amp;ndash; 2.209 in ''Yukti-dipika'' commentary (''Tantrasamgraha-vyakhya'') by [[Sankara Variar]]. A translation of the verses is given below.&lt;ref&gt;{{Cite book|last=C.K. Raju|title=Cultural Foundations of Mathematics : Nature of Mathematical Proof and the Transsmission of the Calculus from India to Europe in the 16 c. CE|publisher=Centre for Studies in Civilistaion|location=New Delhi|year=2007|series=History of Science, Philosophy and Culture in Indian Civilisation|volume=X Part 4|page=231|isbn=81-317-0871-3}}&lt;/ref&gt;
[[Jyesthadeva]] has also given a description of this series in [[Yuktibhasa]].&lt;ref&gt;{{Cite web|url=http://www-gap.dcs.st-and.ac.uk/~history/Biographies/Madhava.html|archive-url=https://web.archive.org/web/20060514012903/http://www-gap.dcs.st-and.ac.uk/~history/Biographies/Madhava.html|dead-url=yes|archive-date=2006-05-14|title=Madhava of Sangamagramma|author1=J J O'Connor|author2=E F Robertson|lastauthoramp=yes|date=November 2000|publisher=School of Mathematics and Statistics University of St Andrews, Scotland|accessdate=14 February 2010}}&lt;/ref&gt;
&lt;ref&gt;R.C. Gupta, The Madhava-Gregory series, Math. Education 7 (1973), B67-B70.&lt;/ref&gt;
&lt;ref&gt;[[K.V. Sarma]], A History of the Kerala School of Hindu Astronomy (Hoshiarpur, 1972).&lt;/ref&gt;

''Now, by just the same argument, the determination of the arc of a desired sine can be (made). That is as follows: The first result is the product of the desired sine and the radius divided by the cosine of the arc. When one has made the square of the sine the multiplier and the square of the cosine the divisor, now a group of results is to be determined from the (previous) results beginning from the first.  When these are divided in order by the odd numbers 1, 3, and so forth, and when one has subtracted the sum of the even(-numbered) results from the sum of the odd (ones), that should be the arc. Here the smaller of the sine and cosine is required to be considered as the desired (sine). Otherwise, there would be no termination of results even if repeatedly (computed).''

''By means of the same argument, the circumference can be computed in another way too. That is as (follows): The first result should by the square root of the square of the diameter multiplied by twelve. From then on, the result should be divided by three (in) each successive (case). When these are divided in order by the odd numbers, beginning with 1, and when one has subtracted the (even) results from the sum of the odd, (that) should be the circumference.''

===Rendering in modern notations===

Let ''s'' be the arc of the desired sine (''[[jya]]'' or ''jiva'') ''y''. Let ''r'' be the radius  and ''x'' be the cosine (''[[kojya|kotijya]]'').

*The first result is &lt;math&gt;\tfrac{y \cdot r}{x}&lt;/math&gt;.
*Form the multiplier and divisor &lt;math&gt;\tfrac{y^2}{x^2}&lt;/math&gt;.
*Form the group pf results: 
::&lt;math&gt;\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}, \qquad \frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}, \qquad \cdots&lt;/math&gt;
*These are divided in order by the numbers 1, 3, and so forth:
:: &lt;math&gt; \frac{1}{1}\frac{y \cdot r}{x}, \qquad \frac{1}{3}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}, \qquad \frac{1}{5}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}, \qquad \cdots&lt;/math&gt;
*Sum of odd-numbered  results: 
::&lt;math&gt;\frac{1}{1}\frac{y \cdot r}{x} + \frac{1}{5}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}+\cdots&lt;/math&gt;
*Sum of even-numbered results:  
::&lt;math&gt;\frac{1}{3}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2} + \frac{1}{7}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}+\cdots&lt;/math&gt;
*The arc is now given by
::&lt;math&gt;s = \left(\frac{1}{1}\frac{y \cdot r}{x} + \frac{1}{5}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}+\cdots\right) - \left(\frac{1}{3}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2} + \frac{1}{7}\frac{y \cdot r}{x}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}\cdot\frac{y^2}{x^2}+\cdots\right)&lt;/math&gt;

===Transformation to current notation===

Let θ be the angle subtended by the arc ''s'' at the centre of the circle. Then ''s'' = ''r''&amp;theta;,  ''x'' = ''[[kotijya]]'' = ''r'' cos &amp;theta; and ''y'' = ''[[jya]]'' = ''r'' sin θ.
Then ''y'' / ''x'' = tan θ. Substituting these in the last expression and simplifying we get
*&lt;math&gt;\theta = \tan \theta - \frac{\tan^3 \theta}{3} + \frac{\tan^5\theta}{5} - \frac{\tan^7 \theta}{7} + \quad \cdots &lt;/math&gt;.
Letting tan θ = ''q'' we finally have

*&lt;math&gt; \tan^{-1} q = q - \frac{q^3}{3} + \frac{q^5}{5} - \frac{q^7}{7} +  \quad \cdots &lt;/math&gt;

===Another formula for the circumference of a circle===

The second part of the quoted text specifies another formula for the computation of the circumference ''c'' of a circle having diameter ''d''. This is as follows.

:&lt;math&gt; 
c= \sqrt{12 d^2} - \frac{\sqrt{12 d^2}}{3\cdot 3} + \frac{\sqrt{12 d^2}}{3^2 \cdot 5} - \frac{\sqrt{12 d^2}}{3^3 \cdot 7}+ \quad \cdots
&lt;/math&gt;

Since  ''c'' =  &amp;pi; ''d'' this can be reformulated as a formula to compute π as follows.

:&lt;math&gt; 
\pi = \sqrt{12}\left( 1 - \frac{1}{3\cdot3}+\frac{1}{3^2\cdot 5} -\frac{1}{3^3\cdot 7} +\quad \cdots\right) 
&lt;/math&gt;

This is obtained by substituting ''q'' = &lt;math&gt;1/\sqrt{3}&lt;/math&gt; (therefore ''θ'' = &amp;pi; / 6) in the power series expansion for tan&lt;sup&gt;−1&lt;/sup&gt; ''q'' above.

{{comparison_pi_infinite_series.svg|400px{{!}}none|two Madhava series (the one with {{radic|12}} in dark blue) and}}

==See also==
*[[Madhava of Sangamagrama]]
*[[Madhava's sine table]]
*[[Padé approximant]]
*[[Taylor Series]]
*[[Laurent series]]
*[[Puiseux series]]

==References==
{{Reflist|colwidth=30em}}

==Further reading==
{{Refbegin|colwidth=60em}}
*{{Cite book|last=Joseph|first=George Gheverghese|origyear=1991|date=October 2010|title=The Crest of the Peacock: Non-European Roots of Mathematics|edition=3rd|publisher=[[Princeton University Press]]|isbn=978-0-691-13526-7|url=http://press.princeton.edu/titles/9308.html}}
*[[K. V. Sarma]], A History of the Kerala School of Hindu Astronomy (Hoshiarpur, 1972).
*A. K. Bag, Madhava's sine and cosine series, Indian J. History Sci. 11 (1) (1976), 54–57.
*D. Gold and D Pingree, A hitherto unknown Sanskrit work concerning Madhava's derivation of the power series for sine and cosine, Historia Sci. No. 42 (1991), 49–65.
*R. C. Gupta, Madhava's and other medieval Indian values of pi, Math. Education 9 (3) (1975), B45–B48.
*R. C. Gupta, Madhava's power series computation of the sine, Ganita 27 (1–2) (1976), 19–24.
*R. C. Gupta, On the remainder term in the Madhava–Leibniz's series, Ganita Bharati 14 (1–4) (1992), 68–71.
*R. C. Gupta, The Madhava–Gregory series, Math. Education 7 (1973), B67–B70.
*T. Hayashi, T. Kusuba and M. Yano, The correction of the Madhava series for the circumference of a circle, Centaurus 33 (2–3) (1990), 149–174.
*R. C. Gupta, The Madhava–Gregory series for tan&lt;sup&gt;&amp;minus;1&lt;/sup&gt;''x'', Indian Journal of Mathematics Education, 11(3), 107–110, 1991.
*{{Cite book|last=[[Kim Plofker]]|title=Mathematics in India  |publisher=Princeton University Press|location=Princeton|year=2009|pages=217–254|isbn=978-0-691-12067-6}}
*"The discovery of the series formula for &amp;pi; by Leibniz, Gregory, and Nilakantha" by Ranjan Roy in : &amp;nbsp;{{Cite book|title=Sherlock Holmes in Babylon and other tales of mathematical history|editor1=Marlow Anderson |editor2=Victor Katz |editor3=Robin Wilson |publisher=[[The Mathematical Association of America]]|year=2004|pages=111–121|isbn=0-88385-546-1}}
*"Ideas of calculus in Islam and India" by Victor J Katz in : &amp;nbsp;{{Cite book|title=Sherlock Holmes in Babylon and other tales of mathematical history|editor1=Marlow Anderson |editor2=Victor Katz |editor3=Robin Wilson |publisher=The Mathematical Association of America|year=2004|pages=122–130|isbn=0-88385-546-1}}
*"Was calculus invented in India?" by David Bressoud in : &amp;nbsp;{{Cite book|title=Sherlock Holmes in Babylon and other tales of mathematical history|editor1=Marlow Anderson |editor2=Victor Katz |editor3=Robin Wilson |publisher=The Mathematical Association of America|year=2004|pages=131–137|isbn=0-88385-546-1}}
*{{Cite book|title=The mathematics of Egypt, Mesopotemia, China, India and Islam: A source book|editor=Victor J Katz|publisher=Princeton University Press|location=Princeton|year=2007|pages=480–495|chapter=Chapter 4 : Mathematics in India IV. Kerala School|isbn=978-0-691-11485-9}}
*{{Cite book|last=Glen Van Brummelen|title=The mathematics of the heavens and the earth : the early history of trigonometry|publisher=Princeton University Press |location=Princeton|year=2009|pages=113–120|isbn=978-0-691-12973-0}}
*D. Pouvreau, Trigonométrie et "développements en séries" en Inde médiévale, I.R.E.M. de l'Université de Toulouse III (2003), 162 pages. {{oclc|758823300}}
*D. Pouvreau, "Sur l'accélération de la convergence de la série de Madhava-Leibniz", Quadrature, n°97 (2015), pp.&amp;nbsp;17–25. {{ISBN|978-2-7598-0528-0}}
{{Refend}}
{{Use dmy dates|date=September 2010}}

{{DEFAULTSORT:Madhava Series}}
[[Category:Mathematical series]]
[[Category:History of mathematics]]
[[Category:Kerala school]]
[[Category:Series expansions]]
[[Category:Indian mathematics]]</text>
      <sha1>o46p8qgnucebmvs9t4jct8hxhrxykgg</sha1>
    </revision>
  </page>
  <page>
    <title>National Centre for Excellence in the Teaching of Mathematics</title>
    <ns>0</ns>
    <id>9057460</id>
    <revision>
      <id>833078480</id>
      <parentid>800724089</parentid>
      <timestamp>2018-03-29T15:16:08Z</timestamp>
      <contributor>
        <username>GiantSnowman</username>
        <id>1005449</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/194.61.223.53|194.61.223.53]] ([[User talk:194.61.223.53|talk]]) to last version by John of Reading</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6585">{{Infobox organization
|name                = National Centre for Excellence in Teaching Mathematics
|image               = 
|size                = 
|caption             = 
|abbreviation        = NCETM
|formation           = 2006
|status              = Government agency
|purpose             = Maths education training
|location            = [[Sheffield]], [[United Kingdom|UK]]
|coords              = {{coord|53.373|-1.47|display=inline, title}}
|region_served       = England
|membership          = 
|leader_title        = Director
|leader_name         = Charlie Stripp
|affiliations        = DfE
|website             = [http://www.ncetm.org.uk NCETM]
}}

The '''National Centre for Excellence in the Teaching of Mathematics''' ('''NCETM''') is an institution set up in the wake of the [[Adrian Smith (academic)|Smith Report]] to improve [[Mathematics education in the United Kingdom|mathematics teaching in England]].

It provides strategic leadership for mathematics-specific CPD and aims to raise the professional status of all those engaged in the teaching of mathematics so that the mathematical potential of learners will be fully realised.

'''Please note:''' some of the content on this page is now out of date. For an up-to-date view of the NCETM's work, please go to the Centre's [https://www.ncetm.org.uk/ website].

==Structure==
Its Director until March 2013 was [[Celia Hoyles|Dame Celia Hoyles]], Professor of Mathematics Education at the [[Institute of Education]], University of London and former chief adviser on mathematics education for the government.&lt;ref&gt;[http://www.mei.org.uk/files/pdf/MEA_CAS_Report_v1a.pdf] Report of the invitation MEI seminars&lt;/ref&gt; She was succeeded by the current Director, Charlie Stripp.

An innovative NCETM development is the [http://www.ncetm.org.uk/Default.aspx?page=22 MatheMaPedia] project, masterminded by [[John Mason (maths educator)|John Mason]], which is a "maths teaching [[wiki]]".

Initially headquartered in London, it is headquartered in the south of Sheffield city centre opposite [[St Mary's Church, Bramall Lane]] on part of the [[A61 road|A61]] dual-carriageway ([[Sheffield Inner Ring Road]]), east of the [[Velocity Tower]], near the [[Bramall Lane]] Roundabout; it is the headquarters of Tribal Education.

It is run by [[Mathematics in Education and Industry]] (MEI) and Tribal Education.

==Improvements to maths teaching==
The NCETM's [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=4445 Evidence Bulletin] [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=4467], available only to those logged into the site, asks "How can you use research evidence to enhance your mathematics teaching?" It covers themes such as the following:

* How can we encourage students to work hard?
* How to build on intuitive ways of working
* What makes some teachers more effective than others?
* How to encourage effective discussion.
* How can [[whiteboard]]s make learning interactive?
* [[Gaze aversion]] and teaching.

Emphases of the NCETM include:
* [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=11588 Continual Professional Development] ([[Collaborative Professional Development|CPD]])
* [http://www.ncetm.org.uk/Default.aspx?page=12&amp;module=news&amp;mode=100&amp;newsid=7267 Mathematics teaching and learning].

==Extensive website==
The website, which anyone can join, offers special areas dedicated to [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=5726 early years], [http://www.coxhoe.durham.sch.uk/Curriculum/Numeracy.htm primary] [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=5731 secondary], [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=5712 post-16] and [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=11929 new approaches to teaching and learning]. Members can create their own [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=9570 personalised learning space] within a social networking site, where they can share ideas with others and ask for inspiration.

The NCETM hosts [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=5865 online courses] as well as real-world [http://www.ncetm.org.uk/coursesandevents] and workshops

===Online discussions===
Special online events have included the world’s first online discussion of [[Mathematical proof|proof]], the launch of ground-breaking report [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=12491 Mathematics Matters], led by Malcolm Swan at the [[University of Nottingham]], and videos of [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=9448 Teachers Talking Theory]: in Action, a new professional development resource created by and featuring primary and secondary teachers in the South West of England.
 
Discussion forums track [[Information communication technology|ICT]] in mathematics teaching and the [http://www.bowlandmaths.org.uk/ Bowland] case studies, newly in schools from September 2008 to enliven the teaching of key "stage 3 mathematics."

==Annual conference==
At the [http://www.ncetm.org.uk/Default.aspx?page=13&amp;module=res&amp;mode=100&amp;resid=4925 NCETM annual conference 2008], [[Sir Peter Williams]] launched [http://www.standards.dcsf.gov.uk/primary/mathematicsreview the Review of Primary Mathematics], which called for a mathematics specialist in every primary school by 2015, amounting to improved and ongoing training for 13,000 primary teachers. [[Lord Adonis]], representing the government, welcomed the report and agreed to its implementation.

==See also==
* [[Count On]] - maths education initiative
* [[Mathematics education]]
* [[International Congress on Mathematical Education]]

==References==
{{Reflist}}

==External links==
* [http://www.ncetm.org.uk NCETM]
* [http://www.mathshubs.org.uk Maths Hubs]
* [http://www.tribalgroup.com/Pages/default.aspx Tribal Group]

===News items===
* [https://www.theguardian.com/education/2008/jan/22/highereducation.academicexperts Celia Hoyles in 2008]

{{DEFAULTSORT:National Centre For Excellence In Teaching Mathematics}}
[[Category:Department for Education]]
[[Category:Education in Sheffield]]
[[Category:Educational organisations based in the United Kingdom]]
[[Category:Mathematics education in the United Kingdom]]
[[Category:Mathematics education reform]]
[[Category:Mathematics organizations]]
[[Category:Mathematics websites]]
[[Category:Organisations based in Sheffield]]
[[Category:Organizations established in 1996]]</text>
      <sha1>4gpdgzejwhq067ugjf87zuw5uitd1p9</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical linear algebra</title>
    <ns>0</ns>
    <id>7330660</id>
    <revision>
      <id>859232661</id>
      <parentid>850027823</parentid>
      <timestamp>2018-09-12T17:22:00Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <minor/>
      <comment>{{linear-algebra-stub}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2864">{{no footnotes|date=July 2018}}
'''Numerical linear algebra''' is the study of [[algorithms]] for performing [[linear algebra]] computations, most notably [[Matrix (mathematics)|matrix]] operations, on [[computer]]s. It is often a fundamental part of [[engineering]] and [[computational science]] problems, such as [[image processing|image]] and [[signal processing]], [[telecommunication]], [[computational finance]], [[materials science]] simulations, [[structural biology]], [[data mining]], [[bioinformatics]], [[fluid dynamics]], and many other areas.  Such software relies heavily on the development, analysis, and implementation of state-of-the-art algorithms for solving various numerical linear algebra problems, in large part because of the role of matrices in [[finite difference method|finite difference]] and [[finite element method]]s.

Common problems in numerical linear algebra include computing the following: [[LU decomposition]], [[QR decomposition]], [[singular value decomposition]], [[eigenvalue]]s.

== See also ==
*[[Iterative methods]]
*[[Numerical analysis]], of which numerical linear algebra is a subspecialty
*[[Numerical methods for linear least squares]]
*[[Gaussian elimination]], an important algorithm in numerical linear algebra
*[[BLAS]] and [[LAPACK]], highly optimized computer libraries which implement most basic algorithms in numerical linear algebra
*[[List of numerical analysis software]]
*[[List of numerical libraries]]

== References ==
*{{cite book |last=Leader |first=Jeffery J. | authorlink=Jeffery J. Leader|title=Numerical Analysis and Scientific Computation |year=2004 |publisher=Addison Wesley |location= |isbn= 0-201-73499-0 }}
* {{Cite book | last1=Bau III | first1=David | last2=Trefethen | first2=Lloyd N. | author2-link=Lloyd N. Trefethen | title=Numerical linear algebra | publisher=Society for Industrial and Applied Mathematics | location=Philadelphia | isbn=978-0-89871-361-9 | year=1997 | postscript=&lt;!--None--&gt;}}
* [[James H. Wilkinson|J. H. Wilkinson]] and C. Reinsch, "Linear Algebra, volume II of Handbook for Automatic Computation" SIAM Review 14, 658 (1972).
* [[Gene H. Golub|Golub, Gene H.]]; [[Charles F. Van Loan|van Loan, Charles F.]] (1996), Matrix Computations, 3rd edition, Johns Hopkins University Press, {{isbn|978-0-8018-5414-9}}
* Åke Björck, ''Numerical Methods in Matrix Computations'', Springer, 2014.

==External links==
{{Commonscat}}
*[http://www.netlib.org/utk/people/JackDongarra/la-sw.html Freely available software for numerical algebra on the web], composed by Jack Dongarra and Hatem Ltaief, University of Tennessee
*[http://www.nag.co.uk/numeric/fl/nagdoc_fl24/html/F/fconts.html NAG Library of numerical linear algebra routines]

{{Numerical linear algebra}}
{{linear-algebra-stub}}
[[Category:Numerical linear algebra| ]]
[[Category:Computational fields of study]]</text>
      <sha1>mrn90n0313m6emauj3zjg3ylg8f3h97</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical semigroup</title>
    <ns>0</ns>
    <id>31434142</id>
    <revision>
      <id>852098921</id>
      <parentid>841537463</parentid>
      <timestamp>2018-07-26T16:29:53Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted 'interestingly' - see [[Wikipedia:Manual_of_Style/Words_to_watch#Editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12773">In mathematics, a '''numerical semigroup''' is a special kind of a [[semigroup]]. Its underlying [[Set (mathematics)|set]] is the set of all nonnegative [[integer]]s except a [[finite set|finite]] number  and the [[binary operation]] is the operation of  [[addition]] of integers. Also, the integer [[0 (number)|0]] must be an element of the semigroup. For example, while the set {0, 2, 3, 4, 5, 6, ...} is a numerical semigroup, the set {0, 1, 3, 5, 6, ...} is not because 1 is in the set and 1 + 1 = 2 is not in the set. Numerical semigroups are [[commutative]] [[monoids]] and are also known as '''numerical monoids'''.&lt;ref&gt;{{cite web|last=Garcia-Sanchez|first=P.A.|title=Numerical semigroups minicourse|url=http://cmup.fc.up.pt/cmup/v2/include/filedb.php?id=117&amp;table=publicacoes&amp;field=file|accessdate=6 April 2011}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last=Finch|first=Steven|title=Monoids of Natural Numbers|url=http://algo.inria.fr/csolve/mnd.pdf|publisher=INRIA Algorithms Project|accessdate=7 April 2011}}&lt;/ref&gt; 

The definition of numerical semigroup is intimately related to the problem of determining nonnegative integers that can be expressed in the form ''x''&lt;sub&gt;1&lt;/sub&gt;''n''&lt;sub&gt;1&lt;/sub&gt; + ''x''&lt;sub&gt;2&lt;/sub&gt; ''n''&lt;sub&gt;2&lt;/sub&gt; + ... + ''x''&lt;sub&gt;''r''&lt;/sub&gt; ''n''&lt;sub&gt;''r''&lt;/sub&gt; for a given set {''n''&lt;sub&gt;1&lt;/sub&gt;, ''n''&lt;sub&gt;2&lt;/sub&gt;, ..., ''n''&lt;sub&gt;''r''&lt;/sub&gt;} of positive integers and for arbitrary nonnegative integers ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''r''&lt;/sub&gt;. This problem had been considered by several mathematicians like [[Ferdinand Georg Frobenius|Frobenius]] (1849 – 1917) and [[James Joseph Sylvester|Sylvester]] (1814 – 1897) at the end of the 19th century.&lt;ref name=Rosales&gt;{{cite book|last=J.C. Rosales and P.A. Garcia-Sanchez|title=Numerical Semigroups|year=2009|publisher=Springer|isbn=978-1-4419-0159-0}}&lt;/ref&gt; During the second half of the twentieth century, interest in the study of numerical semigroups resurfaced because of their applications in [[algebraic geometry]].&lt;ref&gt;{{cite journal|last=V. Barucci, et. al.|title=Maximality properties in numerical semigroups and applications to one-dimensional analytically irreducible local domains|journal=Memoirs of the Amer. Math. Soc.|year=1997|volume=598}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|title = On the variety of linear recurrences and numerical semigroups|url = https://link.springer.com/article/10.1007/s00233-013-9551-2|journal = [[Semigroup Forum]]|date = 2013-11-14|issn = 0037-1912|pages = 569–574|volume = 88|issue = 3|doi = 10.1007/s00233-013-9551-2|language = en|first = Ivan|last = Martino|first2 = Luca|last2 = Martino|arxiv = 1207.0111}}&lt;/ref&gt;

== Definition and examples==
===Definition===

Let ''N'' be the set of nonnegative integers. A subset ''S'' of ''N'' is called a numerical semigroup if the following conditions are satisfied.

#0 is an element of ''S''
#''N'' &amp;minus; ''S'', the complement of ''S'' in ''N'', is finite.
#If ''x'' and ''y'' are in ''S'' then ''x + y'' is also in ''S''.

There is a simple method to construct numerical semigroups. Let ''A'' = {''n''&lt;sub&gt;1&lt;/sub&gt;, ''n''&lt;sub&gt;2&lt;/sub&gt;, ..., ''n''&lt;sub&gt;''r''&lt;/sub&gt;} be a nonempty set of positive integers. The set of all integers of the form ''x''&lt;sub&gt;1&lt;/sub&gt; ''n''&lt;sub&gt;1&lt;/sub&gt; + ''x''&lt;sub&gt;2&lt;/sub&gt; ''n''&lt;sub&gt;2&lt;/sub&gt; + ... + ''x''&lt;sub&gt;''r''&lt;/sub&gt; ''n''&lt;sub&gt;''r''&lt;/sub&gt; is the subset of ''N'' generated by ''A'' and is denoted by &amp;lang; ''A'' &amp;rang;. The following theorem fully characterizes numerical semigroups.

===Theorem===

Let ''S'' be the subsemigroup of ''N'' generated by ''A''. Then ''S'' is a numerical semigroup if and only if [[Greatest common divisor|gcd]] (''A'') = 1. Moreover, every numerical semigroup arises in this way.&lt;ref&gt;{{cite book|last1=García-Sánchez|first1=J.C. Rosales, P.A.|title=Numerical semigroups|date=2009|publisher=Springer|location=New York|isbn=978-1-4419-0160-6|pages=7|edition=First.}}&lt;/ref&gt;

===Examples===

The following subsets of ''N'' are numerical semigroups.
#&amp;lang; 1 &amp;rang; = {0, 1, 2, 3, ...}
#&amp;lang; 1, 2 &amp;rang; = {0, 1, 2, 3, ...}
#&amp;lang; 2, 3 &amp;rang; = {0, 2, 3, 4, 5, 6, ...}
#Let ''a'' be a positive integer. &amp;lang; ''a'', ''a'' + 1, ''a'' + 2, ... , 2''a'' - 1  &amp;rang; = {0, ''a'', ''a'' + 1, ''a'' + 2, ''a'' + 3, ...}.
#Let ''b'' be an odd integer greater than 1. Then &amp;lang; 2, ''b'' &amp;rang; = {0, 2, 4, . . . , ''b'' − 3 , ''b'' − 1, ''b'', ''b'' + 1, ''b'' + 2, ''b'' + 3 , ...}.

==Embedding dimension, multiplicity==

The set ''A'' is a set of generators of the numerical semigroup &amp;lang; ''A'' &amp;rang;. A set of generators of a numerical semigroup is a minimal system
of generators if none of its proper subsets generates the numerical semigroup. It is known that 
every numerical semigroup ''S'' has a unique minimal system of generators and also that this minimal system of generators is finite. The cardinality of the minimal set of generators is called the ''[[embedding dimension]]'' of the numerical semigroup ''S'' and is denoted by ''e''(''S''). The smallest member in the minimal system of generators is called the ''multiplicity'' of the numerical semigroup ''S'' and is denoted by ''m''(''S'').

==Frobenius number and genus==
There are several notable numbers associated with a numerical semigroup ''S''.
# The set ''N'' &amp;minus; ''S'' is called the set of gaps in ''S'' and is denoted by ''G''(''S'').
# The number of elements in the set of gaps ''G''(''S'') is called the genus of ''S'' (or, the degree of singularity of ''S'') and is denoted by ''g''(''S'').
# The greatest element in ''G''(''S'') is called the [[Frobenius number]] of ''S'' and is denoted by ''F''(''S'').
===Examples===

Let ''S'' =  &amp;lang; 5, 7, 9 &amp;rang;. Then we have:
* The set of elements in ''S'' :  ''S'' = {0, 5, 7, 9, 10, 12, 14, ...}.
* The minimal set of generators of ''S'' : {5, 7, 9}.
* The embedding dimension of ''S'' : ''e''(''S'') = 3.
* The multiplicity of ''S'' : ''m''(''S'') = 5.
* The set of gaps in ''S'' : ''G''(''S'') = {1, 2, 3, 4, 6, 8, 11, 13}. 
* The Frobenius number of ''S'' : ''F''(''S'') = 13.
* The genus of ''S'' : ''g''(''S'') = 8.

&lt;center&gt;
'''Numerical semigroups  with small Frobenius number or genus'''
{| class="wikitable"
|-
! &amp;nbsp;&amp;nbsp;  ''n''  &amp;nbsp;&amp;nbsp; !!Semigroup ''S'' &lt;br&gt;  &amp;nbsp;&amp;nbsp; with ''F''(''S'') = ''n'' &amp;nbsp;&amp;nbsp;  !!Semigroup  ''S'' &lt;br&gt;  &amp;nbsp;&amp;nbsp;  with ''g''(''S'') = ''n''  &amp;nbsp;&amp;nbsp; 
|-
|  &amp;nbsp;&amp;nbsp; 1  || &amp;nbsp;&amp;nbsp;  &amp;lang; 2, 3 &amp;rang; ||  &amp;nbsp;&amp;nbsp;  &amp;lang; 2, 3  &amp;rang;
|-
|  &amp;nbsp;&amp;nbsp; 2 || &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 4, 5  &amp;rang; || &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 4, 5  &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp; &amp;lang; 2, 5  &amp;rang;
|-
|  &amp;nbsp;&amp;nbsp;  3 || &amp;nbsp;&amp;nbsp;  &amp;lang; 4, 5, 6, 7 &amp;rang;  &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang; 2, 5  &amp;rang;  ||  &amp;nbsp;&amp;nbsp;  &amp;lang; 4, 5, 6, 7, &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 5, 7  &amp;rang; &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 4 &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp; &amp;lang; 2, 7 &amp;rang;
|-
| &amp;nbsp;&amp;nbsp;  4 ||   &amp;nbsp;&amp;nbsp; &amp;lang; 5, 6, 7, 8, 9  &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp; &amp;lang; 3, 5, 7  &amp;rang; ||  &amp;nbsp;&amp;nbsp; &amp;lang; 5, 6, 7, 8, 9  &amp;rang; &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang; 4, 6, 7, 9   &amp;rang; &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 7, 8  &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp; &amp;lang;  4, 5, 7  &amp;rang; &lt;br&gt;  &amp;nbsp;&amp;nbsp; &amp;lang; 4, 5, 6  &amp;rang; &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang; 3, 5, &amp;rang; &lt;br&gt; &amp;nbsp;&amp;nbsp;  &amp;lang;  2, 9 &amp;rang;
|}
&lt;/center&gt;

==Computation of Frobenius number==

===Numerical semigroups with embedding dimension two===


The following general results were known to Sylvester.&lt;ref&gt;{{cite journal|last=J. J. Sylvester|title=Mathematical questions with their solutions|journal=Educational Times|year=1884|volume=41|issue=21}}&lt;/ref&gt;{{badref|date=June 2016}}  Let ''a'' and ''b'' be positive integers such that [[Greatest common divisor|gcd]] (''a'', ''b'') = 1. Then 
*''F''(&amp;lang; ''a'', ''b'' &amp;rang;) = (''a'' &amp;minus; 1) (''b'' &amp;minus; 1) − 1 = ''ab'' &amp;minus; (''a'' + ''b'').
*''g''(&amp;lang; ''a'', ''b'' &amp;rang;) =  (''a'' &amp;minus; 1)(''b'' &amp;minus; 1) / 2.

===Numerical semigroups with embedding dimension three===


There is no known general formula to compute the Frobenius number of numerical semigroups having embedding dimension three or more. No polynomial formula can be found to compute the Frobenius number or genus of a numerical semigroup with embedding dimension three.&lt;ref&gt;{{cite journal|last=F. Curtis|title=On formulas for the Frobenius number of a numerical semigroup|journal=[[Mathematica Scandinavica]]|year=1990|volume=67|issue=2|pages=190–192|url=http://www.mscand.dk/article.php?id=1278|accessdate=8 April 2011}}&lt;/ref&gt; Every positive integer is the Frobenius number of some numerical semigroup with embedding dimension three.&lt;ref&gt;{{cite journal|last=J. C. Rosales, et. al.|title=Every positive integer is the Frobenius number of a numerical semigroup with three generators|journal=[[Mathematica Scandinavica]]|year=2004|volume=94|pages=5–12|url=http://www.mscand.dk/article/view/14427/12424|accessdate=14 March 2015}}&lt;/ref&gt;

===Rödseth's algorithm===


The following algorithm, known as Rödseth's algorithm,&lt;ref&gt;{{cite book|last=J.L. Ramírez Alfonsín|title=The Diophantine Frobenius Problem|year=2005|publisher=Oxford University Press|isbn=978-0-19-856820-9|pages=4–6}}&lt;/ref&gt;
&lt;ref&gt;{{cite journal|last=Ö.J. Rödseth|title=On a linear Diophantine problem of Frobenius|journal=[[J. Reine Angew. Math.]]|year=1978|volume=301|pages=171–178}} &lt;/ref&gt; 
can be used to compute the Frobenius number of a numerical semigroup ''S'' generated by {''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ''a''&lt;sub&gt;3&lt;/sub&gt;} where  ''a''&lt;sub&gt;1&lt;/sub&gt; &lt; ''a''&lt;sub&gt;2&lt;/sub&gt; &lt; ''a''&lt;sub&gt;3&lt;/sub&gt;   and       [[Greatest common divisor|gcd]] ( ''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ''a''&lt;sub&gt;3&lt;/sub&gt;) = 1.  Its worst-case complexity is not as good as Greenberg's algorithm
&lt;ref&gt;{{cite journal|last=Harold Greenberg|title=Solution to a linear Diophantine equation for non-negative integers|journal=Journal of Algorithms|year=1988|volume=9|pages=343–353|doi=10.1016/0196-6774(88)90025-9}} &lt;/ref&gt;
but it is much simpler to describe.
*Let ''s''&lt;sub&gt;0&lt;/sub&gt; be the unique integer such that ''a''&lt;sub&gt;2&lt;/sub&gt;''s''&lt;sub&gt;0&lt;/sub&gt; ≡ ''a''&lt;sub&gt;3&lt;/sub&gt; mod ''a''&lt;sub&gt;1&lt;/sub&gt;, 0 ≤ ''s''&lt;sub&gt;0&lt;/sub&gt; &lt; ''a''&lt;sub&gt;1&lt;/sub&gt;.
*The continued fraction algorithm is applied to the ratio ''a''&lt;sub&gt;1&lt;/sub&gt;/''s''&lt;sub&gt;0&lt;/sub&gt;:
**''a''&lt;sub&gt;1&lt;/sub&gt; = ''q''&lt;sub&gt;1&lt;/sub&gt;''s''&lt;sub&gt;0&lt;/sub&gt; − ''s''&lt;sub&gt;1&lt;/sub&gt;, 0 ≤ ''s''&lt;sub&gt;1&lt;/sub&gt; &lt; ''s''&lt;sub&gt;0&lt;/sub&gt;,
**''s''&lt;sub&gt;0&lt;/sub&gt; = ''q''&lt;sub&gt;2&lt;/sub&gt;''s''&lt;sub&gt;1&lt;/sub&gt; − ''s''&lt;sub&gt;2&lt;/sub&gt;, 0 ≤ ''s''&lt;sub&gt;2&lt;/sub&gt; &lt; ''s''&lt;sub&gt;1&lt;/sub&gt;,
**''s''&lt;sub&gt;1&lt;/sub&gt; = ''q''&lt;sub&gt;3&lt;/sub&gt;''s''&lt;sub&gt;2&lt;/sub&gt; − ''s''&lt;sub&gt;3&lt;/sub&gt;, 0 ≤ ''s''&lt;sub&gt;3&lt;/sub&gt; &lt; ''s''&lt;sub&gt;2&lt;/sub&gt;,
**...
**''s''&lt;sub&gt;''m''−1&lt;/sub&gt; = ''q''&lt;sub&gt;''m''+1&lt;/sub&gt;''s''&lt;sub&gt;''m''&lt;/sub&gt;,
**''s''&lt;sub&gt;''m''+1&lt;/sub&gt; = 0,
:where ''q''&lt;sub&gt;i&lt;/sub&gt; ≥ 2, ''s''&lt;sub&gt;i&lt;/sub&gt; ≥ 0 for all i.
*Let ''p''&lt;sub&gt;−1&lt;/sub&gt; = 0, ''p''&lt;sub&gt;0&lt;/sub&gt; = 1, ''p''&lt;sub&gt;''i''+1&lt;/sub&gt; = ''q''&lt;sub&gt;''i''+1&lt;/sub&gt;''p''&lt;sub&gt;i&lt;/sub&gt; − ''p''&lt;sub&gt;''i''−1&lt;/sub&gt; and ''r''&lt;sub&gt;i&lt;/sub&gt; = (''s''&lt;sub&gt;''i''&lt;/sub&gt;''a''&lt;sub&gt;2&lt;/sub&gt; − ''p''&lt;sub&gt;''i''&lt;/sub&gt;''a''&lt;sub&gt;3&lt;/sub&gt;)/''a''&lt;sub&gt;1&lt;/sub&gt;.
*Let ''v'' be the unique integer number such that ''r''&lt;sub&gt;''v''+1&lt;/sub&gt; ≤ 0 &lt; ''r''&lt;sub&gt;''v''&lt;/sub&gt;, or equivalently, the unique integer such 
**''s''&lt;sub&gt;''v''+1&lt;/sub&gt;/''p''&lt;sub&gt;''v''+1&lt;/sub&gt; ≤ ''a''&lt;sub&gt;3&lt;/sub&gt;/''a''&lt;sub&gt;2&lt;/sub&gt; &lt;  ''s''&lt;sub&gt;''v''&lt;/sub&gt;/''p''&lt;sub&gt;''v''&lt;/sub&gt;·
*Then, ''F''(''S'') = &amp;minus;''a''&lt;sub&gt;1&lt;/sub&gt; + ''a''&lt;sub&gt;2&lt;/sub&gt;(''s''&lt;sub&gt;''v''&lt;/sub&gt; &amp;minus; 1) + ''a''&lt;sub&gt;3&lt;/sub&gt;(''p''&lt;sub&gt;''v''+1&lt;/sub&gt; − 1) − min{''a''&lt;sub&gt;2&lt;/sub&gt;''s''&lt;sub&gt;''v''+1&lt;/sub&gt;, ''a''&lt;sub&gt;3&lt;/sub&gt;''p''&lt;sub&gt;''v''&lt;/sub&gt;}.

==Special classes of numerical semigroups==
An ''irreducible numerical semigroup'' is a numerical semigroup  such that it cannot be written as the intersection of two numerical semigroups properly containing it. A numerical semigroup ''S'' is irreducible if and only if ''S'' is maximal, with respect to set inclusion,  in the collection of all numerical semigroups  with Frobenius number ''F''(''S''). 

A numerical semigroup ''S '' is ''symmetric'' if it is irreducible and its Frobenius number ''F''(''S'') is  odd.  We say that ''S'' is ''pseudo-symmetric'' provided that ''S'' is irreducible and F(S) is even. Such numerical semigroups have simple characterizations in terms of Frobenius number and genus:
*A numerical semigroup ''S'' is symmetric if and only if ''g''(''S'') = (''F''(''S'') + 1)/2.
*A numerical semigroup ''S'' is pseudo-symmetric if and only if ''g''(''S'') = (''F''(''S'') + 2)/2.

==See also==
*[[Frobenius number]]
*[[Special classes of semigroups]]
*[[Semigroup]]
*[[Sylver coinage]]

==References==
{{reflist}}

[[Category:Semigroup theory]]
[[Category:Algebraic structures]]
[[Category:Number theory]]</text>
      <sha1>9iyzwx5n0vt7c85udl52mo1svaucwp4</sha1>
    </revision>
  </page>
  <page>
    <title>OBJ (programming language)</title>
    <ns>0</ns>
    <id>1063976</id>
    <revision>
      <id>837476374</id>
      <parentid>782353925</parentid>
      <timestamp>2018-04-21T02:21:16Z</timestamp>
      <contributor>
        <username>Dgpop</username>
        <id>96647</id>
      </contributor>
      <comment>/* top */ removed adjective</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1703">'''OBJ''' is a [[programming language]] family introduced by [[Joseph Goguen]] in 1976.

It is a family of [[declarative programming|declarative]] "ultra high-level" languages. It features [[Abstract data type|abstract types]], [[generic module]]s, [[subsort]]s (subtypes with [[multiple inheritance]]), [[pattern matching|pattern-matching]] modulo equations, E-strategies (user control over [[lazy evaluation|laziness]]), module expressions (for combining modules), theories and views (for describing [[module interface]]s) for the massively parallel RRM ([[rewrite rule machine]]).
 
Members of the OBJ family of languages include [[CafeOBJ]], [[Eqlog]], [[FOOPS]], [[Kumo (OBJ)|Kumo]], [[Maude system|Maude]] and [[OBJ3]].

==OBJ3==
'''OBJ3''' is a version of OBJ based on [[Order theory|order]]-sorted [[rewriting]]. OBJ3 is [[Intelligent agent|agent]]-oriented and runs on [[Kyoto Common Lisp]] AKCL.

==See also==
* [[Automated theorem proving]]
* [[Formal methods]]

==References==
* J. A. Goguen, [http://cseweb.ucsd.edu/~goguen/pps/utyop.ps Higher-Order Functions Considered Unnecessary for Higher-Order Programming]. In ''Research Topics in Functional Programming''.

{{FOLDOC}}

==External links==
*[http://vl.fmnet.info/obj/ The OBJ archive]
*[http://www.cs.ucsd.edu/users/goguen/sys/obj.html The OBJ family]
*[http://www-cse.ucsd.edu/users/goguen/pps/iobj.ps Information and OBJ3 manual], [[PostScript]] format

[[Category:Academic programming languages]]
[[Category:Functional languages]]
[[Category:Logic in computer science]]
[[Category:Formal specification languages]]
[[Category:Theorem proving software systems]]
[[Category:Term-rewriting programming languages]]


{{compu-lang-stub}}</text>
      <sha1>iqrcuzryf9qmlzv4fufll6f85dkob1e</sha1>
    </revision>
  </page>
  <page>
    <title>Philosophy of statistics</title>
    <ns>0</ns>
    <id>19634230</id>
    <revision>
      <id>861243172</id>
      <parentid>861243131</parentid>
      <timestamp>2018-09-26T03:06:12Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6526">{{More footnotes|date=November 2010}}

The '''philosophy of statistics''' involves the [[Meaning (philosophy of language)|meaning]], [[Theory of justification|justification]], [[utility]], use and abuse of [[statistics]] and its [[methodology]], and [[ethical]] and [[epistemological]] issues involved in the consideration of choice and interpretation of data and methods of [[statistics]].&lt;ref&gt;{{cite web |first=Jan-Willem |last=Romijn |year=2014 |title=Philosophy of statistics |publisher=Stanford Encyclopedia of Philosophy |url=http://plato.stanford.edu/entries/statistics/}}&lt;/ref&gt;

==Topics of interest==
* [[Foundations of statistics]] involves issues in [[theoretical statistics]], its goals and [[Optimization (mathematics)|optimization]] methods to meet these goals, [[Parametric statistics|parametric]] assumptions or lack thereof considered in [[nonparametric statistics]], [[model selection]] for the underlying [[probability distribution]], and interpretation of the meaning of inferences made using statistics, related to the [[philosophy of probability]] and the [[philosophy of science]]. Discussion of the selection of the goals and the meaning of optimization, in foundations of statistics, are the subject of the philosophy of statistics.  Selection of distribution models, and of the means of selection, is the subject of the philosophy of statistics, whereas the mathematics of optimization is the subject of nonparametric statistics.
* [[Sir David Cox (statistician)|David Cox]] makes the point {{Citation needed|date=July 2016}} that any kind of interpretation of evidence is in fact a statistical model, although it is known through Ian Hacking's work {{Citation needed|reason=Which of Hacking's works are being referred to here|date=July 2016}} that many are ignorant of this subtlety.
* Issues arise involving [[sample size]], such as cost and efficiency, are common, such as in polling and pharmaceutical research.
* Extra-mathematical considerations in the design of experiments and accommodating these issues arise in most actual experiments.{{elucidate|date=July 2016}}
* The motivation and justification of [[data analysis]] and [[experimental design]], as part of the [[scientific method]] are considered.
* Distinctions between [[inductive reasoning|induction]] and [[logical deduction]] relevant to inferences from [[data]] and [[evidence]] arise, such as when [[frequentist]] interpretations are compared with [[Confidence Interval|degrees of certainty]] derived from [[Bayesian inference]]. However, the difference between induction and ordinary reasoning is not generally appreciated.{{sfn|Hacking|2006}}
* Leo Breiman exposed the diversity of thinking in his article on 'The Two Cultures', making the point that statistics has several kinds of inference to make, modelling and prediction amongst them.{{sfn|Breiman|2001}}
* Issues in the philosophy of statistics arise throughout the [[history of statistics]].  [[Causality]] considerations arise with interpretations of, and definitions of, [[correlation]], and in the [[theory of measurement]].
* Objectivity in statistics is often confused with truth whereas it is better understood as replicability, which then needs to be defined in the particular case. [[Theodore Porter]] develops this as being the path pursued when trust has evaporated, being replaced with criteria.{{sfn|Porter|1995}}
* [[Ethics]] associated with [[epistemology]] and [[medical]] applications arise from potential abuse of statistics, such as selection of method or [[Data transformation (statistics)|transformations]] of the data to arrive at different probability conclusions for the same data set.  For example, the meaning of applications of a [[statistical inference]] to a single person, such as one single cancer patient, when there is no frequentist interpretation for that patient to adopt.
* Campaigns for [[statistical literacy]] must wrestle with the problem that most interesting questions around individual risk are very difficult to determine or interpret, even with the computer power currently available.

==Notes==
{{reflist}}

== Further reading ==
{{refbegin}}
*{{cite journal |last=Breiman |first=Leo |title=Statistical Modeling: The Two Cultures |journal=Statistical Science |volume=16 |issue=3 |pages=199–231 |year=2001 |doi=10.1214/ss/1009213726 |ref=harv}}
*{{cite magazine |last1=Efron |first1=Bradley |author1link=Bradley Efron |last2=Morris |first2=Carl |year=1977 |title=Stein's Paradox in Statistics |url=http://www-stat.stanford.edu/~ckirby/brad/other/Article1977.pdf |magazine=[[Scientific American]] |volume=236 |issue=5 |pages=119&amp;ndash;127}}
*{{cite journal |last=Efron |first=Bradley |year=1979 |title=Computer and the Theory of Statistics: Thinking the Unthinkable |journal=[[SIAM Review]] |volume=21 |issue=4 |pages=460&amp;ndash;480 |doi=10.1137/1021092}}
*{{cite journal |last=Good |first=Irving J. |authorlink=I. J. Good |year=1988 |title=The Interface Between Statistics and Philosophy of Science |journal=[[Statistical Science]] |volume=3 |issue=4 |pages=386&amp;ndash;397 |jstor=2245388 |doi=10.1214/ss/1177012754}}
*{{cite book |last=Hacking |first=Ian |authorlink=Ian Hacking |year=2006 |title=The Emergence of Probability |publisher=Cambridge University Press |isbn=0-521-68557-5 |edition=2nd |ref=harv}}
*{{cite journal |last=Hacking |first=Ian |year=1964 |title=On the Foundations of Statistics |journal=The British Journal for the Philosophy of Science |volume=15 |issue=57 |pages=1&amp;ndash;26 |jstor=685624 |doi=10.1093/bjps/xv.57.1}}
*{{cite book |last=Hacking |first=Ian |year=1990 |title=The Taming of Chance |publisher=Cambridge University Press |isbn=0-521-38884-8}}
*{{cite book |last=Mayo |first=Deborah |year=1996 |title=Error and the growth of experimental knowledge |publisher=University of Chicago Press |isbn=0-226-51198-7}}
*{{cite book |last=Porter |first=Theodore |year=1995 |title=Trust in Numbers |publisher=Princeton University Press |isbn=0-691-03776-0 |ref=harv}}
*{{cite book |last=Savage |first=Leonard J. |authorlink=Leonard Jimmie Savage |year=1972 |title=The Foundations of Statistics |publisher=Dover |isbn=0-486-62349-1 |edition=2003}}
*{{cite book |last=Vallverdu |first=Jordi |year=2016 |title=Bayesians Versus Frequentists. A Philosophical Debate on Statistical Reasoning |publisher=Springer |isbn=978-3-662-48638-2 |url=https://www.springer.com/us/book/9783662486368}}
{{refend}}

[[Category:Philosophy of statistics| ]]
[[Category:Ethics and statistics]]
[[Category:Applied philosophy]]</text>
      <sha1>aitddjxrrmcimfp9ai4nfuxiuvnba6p</sha1>
    </revision>
  </page>
  <page>
    <title>Pincherle polynomials</title>
    <ns>0</ns>
    <id>33013769</id>
    <revision>
      <id>626764142</id>
      <parentid>622261413</parentid>
      <timestamp>2014-09-23T13:55:32Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* References */replace jfm template with jfm parameter in CS1 templates; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="847">In [[mathematics]], the '''Pincherle polynomials''' P&lt;sub&gt;''n''&lt;/sub&gt;(''x'') are [[polynomials]] introduced by {{harvs|txt|first=S.|last=Pincherle|year=1891|authorlink=S. Pincherle}} given by the [[generating function]]

:&lt;math&gt;\displaystyle (1-3xt+t^3)^{-1/2}=\sum^\infty
_{n=0}P_n(x)t^n&lt;/math&gt;

[[Humbert polynomials]] are a generalization of Pincherle polynomials

==References==

*{{Citation | last1=Humbert | first1=Pierre | title=Some extensions of Pincherle's Polynomials | doi=10.1017/S0013091500035756 | year=1921 | journal=Proceedings of the Edinburgh mathematics society | volume=39 | pages=21–24}}
*{{citation|last=Pincherle|first=Salvatore|year=1891|title=Una nuova estensione delle funzioni sferiche| language=Italian|journal=Memorie della accademia R. di Bologna|volume=I|pages=337–369|jfm=23.0514.01}}

[[Category:Polynomials]]</text>
      <sha1>nhbp6oye8pbp1d3lau8sky3jbpqf6yj</sha1>
    </revision>
  </page>
  <page>
    <title>Polar point group</title>
    <ns>0</ns>
    <id>41321254</id>
    <revision>
      <id>853277594</id>
      <parentid>835317126</parentid>
      <timestamp>2018-08-03T16:20:52Z</timestamp>
      <contributor>
        <ip>128.135.148.85</ip>
      </contributor>
      <comment>/* Polar crystallographic point group */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3048">In geometry,  a '''polar point group''' is a [[point group]] in which there is more than one point that every [[symmetry operation]] leaves unmoved.&lt;ref name="uol"&gt;{{cite web 
|title=Polar Point Groups |authors=Jeremy Karl Cockcroft, Huub Driessen, David Moss, Ian Tickle 
|publisher=University of London |year=2006
|url=http://pd.chem.ucl.ac.uk/pdnn/symm2/polar1.htm |accessdate=2013-12-09  
}}&lt;/ref&gt; Therefore, a point group with more than one axis of rotation or a mirror plane perpendicular to the axis of rotation cannot be polar.

A straight line joining unmoved points defines a unique axis of rotation, unless symmetry operations do not allow any rotation at all, such as mirror symmetry, in which case, the polar direction must be parallel to any mirror planes.

== Polar crystallographic point group ==
Of the 32 [[crystallographic point group]]s, 10 are polar:&lt;ref&gt;{{cite book | last = Kasap | first = Safa O. | title = Principles of electronic materials and devices | publisher = McGraw-Hill | location = Boston | year = 2006 | isbn = 9780073104645}}&lt;/ref&gt;

{| class="wikitable" border="1" style="text-align: center;"
|+Polar crystallographic point groups
! rowspan=2 | [[Crystal system]]
! colspan=8 | Polar point groups
|-
| colspan=2 | [[Schönflies notation|&amp;nbsp;&amp;nbsp; Schönflies &amp;nbsp;&amp;nbsp;]] 
| colspan=2 | [[Hermann–Mauguin notation|Hermann–Mauguin]]
| colspan=2 | [[Orbifold notation|Orbifold]]
| colspan=2 | [[Coxeter notation|Coxeter]]
|-
| [[Triclinic]] || colspan=2 | C&lt;sub&gt;1&lt;/sub&gt; || colspan=2 | 1 || 11|| || colspan=2 | [&amp;nbsp;]&lt;sup&gt;+&lt;/sup&gt;
|-
| [[Monoclinic]] || C&lt;sub&gt;2&lt;/sub&gt; || C&lt;sub&gt;s&lt;/sub&gt; || 2 || m || 22 || * || [2]&lt;sup&gt;+&lt;/sup&gt; || [&amp;nbsp;]
|-
| [[Orthorhombic]] || colspan=2 | C&lt;sub&gt;2v&lt;/sub&gt; || colspan=2 |  mm2 || ||  *22  || || [2]
|-
| [[Trigonal]] || C&lt;sub&gt;3&lt;/sub&gt; || C&lt;sub&gt;3v&lt;/sub&gt; || 3 || 3m || 33 || *33 || [3]&lt;sup&gt;+&lt;/sup&gt; || [3]
|-
| [[Tetragonal]] || C&lt;sub&gt;4&lt;/sub&gt; || C&lt;sub&gt;4v&lt;/sub&gt; ||4 ||4mm || 44 || *44 || [4]&lt;sup&gt;+&lt;/sup&gt; || [4]
|-
| [[Hexagonal]] || C&lt;sub&gt;6&lt;/sub&gt; || C&lt;sub&gt;6v&lt;/sub&gt; || 6 || 6mm || 66 || *66 || [6]&lt;sup&gt;+&lt;/sup&gt; || [6]
|-
| [[Cubic crystal system|Cubic]] || colspan=8 | (none) 
|}
        
The [[space group]]s associated with a polar point group do not have their origins uniquely determined by symmetry elements.&lt;ref name="uol"/&gt;
  
When materials having a polar point group crystal structure are heated or cooled, they may temporarily generate a voltage called [[pyroelectricity]].

Molecular crystals that occupy polar space groups will exhibit [[triboluminescence]].&lt;ref name="tribo"&gt;{{cite journal|last1=Zink|first1=Jeffery|title=Triboluminescence-Structure Relations in Polymorphs of Hexaphenylcarbodiphosphorane and Anthranilic Acid, Molecular Crystals, and Salts|journal=J. Am. Chem. Soc.|date=1981|volume=103|pages=1074–1079|doi=10.1021/ja00395a014}}&lt;/ref&gt; A common example of this is sucrose, demonstrated by smashing a wintergreen lifesaver in a darkened room.

==References==
{{reflist}}

[[Category:Symmetry]]
[[Category:Crystallography]]
[[Category:Group theory]]</text>
      <sha1>jzufnr0adyo8tvbkwcob1wu82ar3yo2</sha1>
    </revision>
  </page>
  <page>
    <title>Poussin proof</title>
    <ns>0</ns>
    <id>5445552</id>
    <revision>
      <id>601710599</id>
      <parentid>554740532</parentid>
      <timestamp>2014-03-28T20:58:20Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes + other fixes using [[Project:AWB|AWB]] (10065)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1761">{{multiple issues|
{{Orphan|date=February 2013}}
{{Context|date=October 2009}}
}}

In [[number theory]], the '''Poussin proof''' is the proof of an identity related to the fractional part of a ratio.

In 1838, [[Peter Gustav Lejeune Dirichlet]] proved an approximate formula for the average number of divisors of all the numbers from 1 to η:

:&lt;math&gt;\frac{\sum_{k=1}^\eta d(k)}{\eta} \approx \ln \eta + 2\gamma - 1,&lt;/math&gt;

where ''d'' represents the [[divisor function]], and γ represents the [[Euler-Mascheroni constant]].

In 1898, [[Charles Jean de la Vallée-Poussin]] proved that if a large number η is divided by all the primes up to η, then the average fraction by which the quotient falls short of the next whole number is γ:
:&lt;math&gt;\frac{\sum_{p \leq \eta}\left \{ \frac{\eta}{p} \right \}}{\pi(\eta)} \approx1- \gamma,&lt;/math&gt;
where {''x''} represents the [[fractional part]] of ''x'', and π represents the [[prime-counting function]].
For example, if we divide 29 by 2, we get 14.5, which falls short of 15 by 0.5.

==References==
*Dirichlet, G. L. "[http://gdz.sub.uni-goettingen.de/no_cache/en/dms/load/img/?IDDOC=268296 Sur l'usage des séries infinies dans la théorie des nombres]", ''Journal für die reine und angewandte Mathematik'' '''18''' (1838), pp.&amp;nbsp;259–274. Cited in MathWorld article "Divisor Function" below.
*de la Vallée Poussin, C.-J. Untitled communication. ''Annales de la Societe Scientifique de Bruxelles'' '''22''' (1898), pp.&amp;nbsp;84–90. Cited in MathWorld article "Euler-Mascheroni Constant" below.

==External links==
*{{MathWorld|urlname=DivisorFunction|title=Divisor Function}}
*{{MathWorld|urlname=Euler-MascheroniConstant|title=Euler-Mascheroni Constant}}

[[Category:Number theory]]


{{numtheory-stub}}</text>
      <sha1>shdwwzv20vadydc20pded31o915b2tt</sha1>
    </revision>
  </page>
  <page>
    <title>Ramism</title>
    <ns>0</ns>
    <id>1691461</id>
    <revision>
      <id>858427832</id>
      <parentid>858182635</parentid>
      <timestamp>2018-09-07T03:12:53Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38065">:''Ramist redirects here. It may also refer to followers of the composer [[Jean-Philippe Rameau]].''
{{17th Century Scholasticism}}
{{use dmy dates|date=March 2018}}
{{refimprove|date=March 2018}}
'''Ramism''' was a collection of theories on [[rhetoric]], [[logic]], and [[pedagogy]] based on the teachings of [[Petrus Ramus]], a French academic, philosopher, and [[Huguenot]] convert, who was murdered during the [[St. Bartholomew's Day massacre]] in August 1572.{{fact|date=March 2018}}

According to British historian [[Jonathan Israel]]:

&lt;blockquote&gt;"[Ramism], despite its crudity, enjoyed vast popularity in late sixteenth-century Europe, and at the outset of the seventeenth, providing as it did a method of systematizing all branches of knowledge, emphasizing the relevance of theory to practical applications [...]"&lt;ref&gt;[[Jonathan Israel|Israel, Jonathan]] (1995). ''The Dutch Republic: Its Rise, Greatness and Fall 1477–1806'' (1995), p. 582.&lt;/ref&gt;&lt;/blockquote&gt;

==Development==
Audomarus Talaeus ([[Omer Talon]]) was an early French disciple and writer on Ramism.&lt;ref&gt;[http://xtf.lib.virginia.edu/xtf/view?docId=DicHist/uvaGenText/tei/DicHist4.xml;chunk.id=dv4-06 Virginia.edu]&lt;/ref&gt; The work of Ramus gained early international attention, with [[Roger Ascham]] corresponding about him with [[Johann Sturm]], teacher of Ramus and collaborator with Ascham; Ascham supported his stance on [[Joachim Perion]], one early opponent, but also expressed some reservations. Later Ascham found Ramus's lack of respect for [[Cicero]], rather than extreme proponents, just unacceptable.&lt;ref&gt;Lawrence V. Ryan, ''Roger Ascham'' (1963), pp. 147–8, p. 269.&lt;/ref&gt;

After Ramus died, his ideas had influence in some (but not all) parts of Protestant Europe. His influence was strong in Germany and the Netherlands, and on [[Puritan]] and [[Calvinist]] theologians of England, Scotland, and New England. He had little effect on mainstream Swiss Calvinists, and was largely ignored in Catholic countries.&lt;ref&gt;''Cambridge History of Renaissance Philosophy'' (1988), pp. 51–52.&lt;/ref&gt; The progress of Ramism in the half-century roughly 1575 to 1625 was closely related to, and mediated by, university education: the religious factor came in through the different reception in Protestant and Catholic universities, all over Europe.&lt;ref&gt;[[Bryan S. Turner (sociologist)|Bryan S. Turner]], ''Max Weber: Critical Responses'' (1999), p. 198.&lt;/ref&gt; The works of Ramus reached [[New England]] on the ''[[Mayflower]]''.&lt;ref&gt;Robert Mandrou, ''From Humanism to Science 1480–1700'' (1978 translation), p. 177.&lt;/ref&gt;

Ramus was killed in 1572, and a biography by Banosius (Théophile de Banos) appeared by 1576.&lt;ref&gt;With the posthumous ''Commentariorum de religione Christiana libri quatuor, nunquam antea editi'' (Frankfort, 1576); http://www.ccel.org/s/schaff/encyc/encyc09/htm/iv.vii.xxxiv.htm.&lt;/ref&gt; His status as [[Huguenot]] martyr certainly had something to do with the early dissemination of his ideas.&lt;ref&gt;{{Fr icon}} Kees Meerhoff, ''Rhétorique et poétique au XVIe siècle en France: Du Bellay, Ramus et les autres'' (1986), p. 317.&lt;/ref&gt; Outside France, for example, there was the 1574 English translation by the Scot Roland MacIlmaine of the [[University of St Andrews]].&lt;ref name="yba.llgc.org.uk"&gt;[http://yba.llgc.org.uk/en/s-PERR-HEN-1560.html LLGC.org.uk]&lt;/ref&gt;&lt;ref&gt;[[William Kneale]] and Martha Kneale, ''The Development of Logic'' (1962), p. 302.&lt;/ref&gt; Ramus's works and influence then appeared in the logical textbooks of the [[Scotland|Scottish]] universities, and equally he had followers in England.{{fact|date=March 2018}}

As late as 1626, [[Francis Burgersdyk]] divides the logicians of his day into the Aristotelians, the Ramists and the Semi-Ramists.&lt;ref&gt;Michael Losonsky, ''Language and Logic'', in Donald Rutherford (editor), ''The Cambridge Companion to Early Modern Philosophy'' (2006), p. 170.&lt;/ref&gt;&lt;ref&gt;William Kneale and Martha Kneale, ''The Development of Logic'' (1962), p. 305.&lt;/ref&gt; These last endeavoured, like [[Rudolph Goclenius]] of [[Marburg]] and [[Amandus Polanus]] of [[Basel]], to mediate between the contending parties. Ramism was closely linked to systematic [[Calvinism]], but the hybrid [[Philippo-Ramism]] (which is where the Semi-Ramists fit in) arose as a blend of Ramus with the logic of [[Philipp Melanchthon]].&lt;ref&gt;Michael Losonsky, ''Language and Logic'', in Donald Rutherford (editor), ''The Cambridge Companion to Early Modern Philosophy'' (2006), p. 178.&lt;/ref&gt;

==Opposition==
Ramism, while in fashion, met with considerable hostility. The [[Jesuits]] were completely opposed.&lt;ref&gt;Marc Fumaroli, ''Renaissance Rhetoric: The Jesuit Case'', in John W. O'Malley, Gauvin Alexander Bailey, Steven Harris, T. Frank Kennedy (editors), ''The Jesuits: Cultures, Sciences, and the Arts, 1540–1773'' (1999), p. 91.&lt;/ref&gt; The Calvinist Aristotelian [[Theodore Beza]] was also a strong opponent of Ramism.&lt;ref&gt;Charles B. Schmitt, [[Quentin Skinner]] (editors), ''The Cambridge History of Renaissance Philosophy'' (1990), p. 52.&lt;/ref&gt; Similarly the leading Lutheran Aristotelian philosopher [[Jakob Schegk]] resolutely rejected Ramus and opposed his visit to [[Tübingen]].&lt;ref&gt;*Howard Hotson, ''Commonplace Learning: Ramism and its German Ramifications, 1543–1630'' (2007) pp. 22, 102.&lt;/ref&gt; In [[Heidelberg]] the efforts of [[Giulio Pace]] to teach Ramist dialectic to Polish private students were forbidden.&lt;ref&gt;Howard Hotson, ''Commonplace Learning: Ramism and its German ramifications, 1543-1630'' (2007), p. 24; [https://books.google.co.uk/books?id=hWs_9bDishYC&amp;pg=PA24 Google Books].&lt;/ref&gt;

Where universities were open to Ramist teaching, there still could be dislike and negative reactions, stemming from the perceived personality of Ramus (arrogant, a natural polemicist), or of that of his supporters (young men in a hurry). There was tacit adoption of some of the techniques such as the epitome, without acceptance of the whole package of reform including junking Aristotle in favour of the new textbooks, and making Ramus an authoritative figure. [[John Rainolds]] at Oxford was an example of an older academic torn by the issue; his follower [[Richard Hooker]] was firmly against "Ramystry".&lt;ref&gt;Mordechai Feingold, pp. 289–293 in Nicholas Tyacke (editor), ''The History of the University of Oxford: Volume IV: Seventeenth-Century Oxford'' (1984).&lt;/ref&gt;

[[Gerhard Johann Vossius]] at [[Leiden]] wrote massive works on classical rhetoric and opposed Ramism. He defended and enriched the Aristotelian tradition for the seventeenth century.&lt;ref&gt;George Alexander Kennedy, ''Classical Rhetoric &amp; Its Christian &amp; Secular Tradition from Ancient to Modern Times'' (1999), p. 254.&lt;/ref&gt; He was a representative Dutch opponent; Ramism did not take permanent hold in the universities of the Netherlands, and once [[William Ames]] had died, it declined.&lt;ref&gt;Willem Frijhoff, Marijke Spies, ''Dutch Culture in a European Perspective'' (2004), p. 287.&lt;/ref&gt;

Mid-century, Ramism was still under attack, from Cartesians such as [[Johannes Clauberg]], who defended Aristotle against Ramus.&lt;ref&gt;Edward Craig, ''Routledge Encyclopedia of Philosophy'' (1998), p. 380.&lt;/ref&gt;

==Placing Ramism==
[[Frances Yates]] proposed a subtle relationship of Ramism to the legacy of [[Lullism]], the [[art of memory]], and Renaissance [[hermetism]]. She considers that Ramism drew on Lullism, but is more superficial; was opposed to the classical art of memory; and moved in an opposite direction to the occult (reducing rather than increasing the role of images).&lt;ref&gt;[[Frances Yates]], ''The Art of Memory'' (1992 edition), pp. 234–5.&lt;/ref&gt;  He "abandoned imagery and the creative imagination".&lt;ref&gt;Peter French, ''John Dee'' (1972), p. 148.&lt;/ref&gt; [[Mary Carruthers]] referred back to [[Albertus Magnus]] and [[Thomas Aquinas]]:

&lt;blockquote&gt;"It is one of those ironies of history that Peter Ramus, who, in the sixteenth century, thought he was reacting against [[Aristotelianism]] by taking ''[[memoria]]'' from rhetoric and making it part of dialectic, was essentially remaking a move made 300 years before by two [[Dominican Order|Dominican]] professors who were attempting to reshape memorial study in conformity with Aristotle."&lt;ref&gt;Carruthers, Mary (1990). ''The Book of Memory. A Study of Memory in Medieval Culture'' (1990), p. 153.&lt;/ref&gt;&lt;/blockquote&gt;

An alternative to this aspect of Ramism, as belated and diminishing, is the discussion initiated by [[Walter Ong]] of Ramus in relation to several evolutionary steps. Ong's position, on the importance of Ramus as historical figure and [[Renaissance Humanism|humanist]], has been summed up as ''the center of controversies about method (both in teaching and in scientific discovery) and about rhetoric and logic and their role in communication''.&lt;ref&gt;Peter Sharratt, ''Peter Ramus, Walter Ong, and the Tradition of Humanistic Learning'', Oral Tradition, 2/1 (1987) pp. 172–87, at p. 173; [http://journal.oraltradition.org/files/articles/2i/12_sharratt.pdf PDF].&lt;/ref&gt;

The best known of Ong's theses is Ramus the post-[[Johannes Gutenberg|Gutenberg]] writer, in other words the calibration of the indexing and schematics involved in Ramism to the transition away from written manuscripts, and the spoken word.&lt;ref&gt;Jack Goody, ''The Domestication of the Savage Mind'' (1977), p. 71.&lt;/ref&gt; Extensive charts were instead used, drawing on the resources of typography, to organise material, from left to right across a printed page, particularly in theological treatises.&lt;ref&gt;Gordon Campbell, ''The Source of Bunyan's Mapp of Salvation'', Journal of the Warburg and Courtauld Institutes, Vol. 44, (1981), pp. 240–241.&lt;/ref&gt; The cultural impact of Ramism depended on the nexus of printing (trees regularly laid out with [[curly bracket|braces]]) and rhetoric, forceful and persuasive at least to some [[Protestants]]; and it had partly been anticipated in cataloguing and indexing knowledge and its encyclopedism by [[Conrad Gesner]].&lt;ref&gt;Mario Carpo, ''Architecture in the Age of Printing: Orality, Writing, Typography, and Printed Images in the History of Architectural Theory'' (2001 translation), p. 110.&lt;/ref&gt; The term ''Ramean tree'' became standard in logic books, applying to the classical [[Porphyrian tree]], or any [[binary tree]], without clear distinction between the underlying structure and the way of displaying it; now scholars use the clearer term ''Ramist epitome'' to signify the structure. Ong argued that, a chart being a visual aid and logic having come down to charts, the role of voice and [[dialogue]] is placed squarely and rigidly in the domain of rhetoric, and in a lower position.&lt;ref&gt;James Crosswhite, ''The Rhetoric of Reason: Writing and the Attractions of Argument'' (1996), p. 235.&lt;/ref&gt;

Two other theses of Ong on Ramism are: the end of ''copia'' or profuseness for its own sake in writing, making Ramus an opponent of the [[Erasmus]] of ''[[Copia: Foundations of the Abundant Style]]''; and the beginning of the later [[Cartesianism|Cartesian]] emphasis on clarity. Ong, though, consistently argues that Ramus is thin, insubstantial as a scholar, a beneficiary of fashion supported by the new medium of printing, as well as a transitional figure.&lt;ref&gt;Alan Richardson, Ellen Spolsky, ''The Work of Fiction: Cognition, Culture, and Complexity'' (2004), p. 121.&lt;/ref&gt;

These ideas, from the 1950s and 1960s onwards, have been reconsidered. [[Brian Vickers (academic)|Brian Vickers]] summed up the view a generation or so later: dismissive of Yates, he notes that bracketed tables existed in older manuscripts, and states that Ong's emphases are found unconvincing. Further, ''methodus'', the Ramists' major slogan, was specific to [[figures of speech]], deriving from [[Hermogenes of Tarsus]] via [[George of Trebizond]]. And the particular moves used by Ramus in the reconfiguration of rhetoric were in no sense innovative by themselves.&lt;ref&gt;[[Brian Vickers (academic)|Brian Vickers]], ''In Defence of Rhetoric'' (1988), note p. 65, and pp. 475–7.&lt;/ref&gt; [[Lisa Jardine]] agrees with Ong that he was not a first-rank innovator, more of a successful textbook writer adapting earlier insights centred on [[topics-logic]], but insists on his importance and influence in ''humanistic logic''. She takes the Ramean tree to be a "voguish" pedagogic advance.&lt;ref&gt;[[Lisa Jardine]], ''Humanistic Logic'', p. 184–6, in Charles B. Schmitt, Quentin Skinner (editors), ''The Cambridge History of Renaissance Philosophy'' (1990), p. 52.&lt;/ref&gt;

It has been said that:

&lt;blockquote&gt;Puritans believed the maps proved well suited to rationalize and order the Christian view of revealed truth and the language and knowledge of the [[new learning]], specifically the scientific and philosophical paradigms arising out of the Renaissance.&lt;ref&gt;Douglas McKnight, ''Schooling, the Puritan Imperative, and the Molding of an American National Identity: Education's "errand Into the Wilderness"'' (2003), p. 53.&lt;/ref&gt;&lt;/blockquote&gt;

==Disciplines and demarcations==
Donald R. Kelley writes of the "new learning" (''nova doctrina'') or opposition in Paris to traditional [[scholasticism]] as a "trivial revolution", i.e. growing out of specialist teachers of the ''[[trivium (education)|trivium]]''. He argues that:

&lt;blockquote&gt;''The aim was a fundamental change of priorities, the transformation of hierarchy of disciplines into a 'circle' of learning, an 'encyclopedia' embracing human culture in all of its richness and concreteness and organized for persuasive transmission to society as a whole. This was the rationale of the Ramist method, which accordingly emphasized mnemonics and pedagogical technique at the expense of discovery and the advancement of learning.&lt;ref&gt;Donald R. Kelley, ''The Beginning of Ideology: Consciousness and society in the French Reformation'' (1981), p. 141.&lt;/ref&gt;&lt;/blockquote&gt;

The need for demarcation was seen in "redundancies and overlapping categories".&lt;ref&gt;[[Quentin Skinner]], ''Reason and Rhetoric in the Philosophy of Hobbes'' (1996), p. 59.&lt;/ref&gt;

This was taken to the lengths where it could be mocked in the ''[[Port-Royal Logic]]'' (1662). There the authors claimed that "everything that is useful to logic belongs to it", with a swipe at the "torments" the Ramists put themselves through.&lt;ref&gt;Jill Vance Burojker (translator and editor), ''Logic or the Art of Thinking'' by [[Antoine Arnauld]] and [[Pierre Nicole]] (1996), p. 12.&lt;/ref&gt;

The method of demarcation was applied within the ''trivium'', made up of [[grammar]], [[logic]] (for which Ramists usually preferred a traditional name, ''dialectic''), and [[rhetoric]]. Logic falls, according to Ramus, into two parts: invention (treating of the notion and definition) and judgment (comprising the judgment proper, syllogism and method). In this he was influenced by [[Rodolphus Agricola]].&lt;ref&gt;{{Citation | url = http://plato.stanford.edu/entries/ramus/ |title=Petreus ramus}}. of Philosophy)]&lt;/ref&gt;  What Ramus does here in fact redefines rhetoric. There is a new configuration, with logic and rhetoric each having two parts: rhetoric was to cover ''elocutio'' (mainly figures of speech) and ''pronuntiatio'' (oratorical delivery). In general, Ramism liked to deal with [[binary tree]]s as method for organising knowledge.&lt;ref&gt;Michael Losonsky, ''Language and Logic'', in Donald Rutherford (editor), ''The Cambridge Companion to Early Modern Philosophy'' (2006), p. 176.&lt;/ref&gt;

Rhetoric, traditionally, had had five parts, of which ''inventio'' (invention) was the first. Two others were ''dispositio'' (arrangement) and ''memoria'' (memory). Ramus proposed transferring those back to the realm of ''dialectic'' (logic); and merging them under a new heading, renaming them as ''iudicium'' (judgment).&lt;ref&gt;Paolo Rossi, ''Logic and the Art of Memory'' (2000 translation), pp. 99–102.&lt;/ref&gt; This was the final effect: as an intermediate ''memoria'' was left with rhetoric.{{fact|date=March 2018}}

==Laws and method==
In the end the art of memory was diminished in Ramism, displaced by an idea of "method": better mental organisation would be more methodical, and mnemonic techniques drop away. This was a step in the direction of [[Descartes]]. The construction of disciplines, for Ramus, was subject to some laws, his ''methodus''. There were three, with clear origins in Aristotle, and his ''[[Posterior Analytics]]''.{{fact|date=March 2018}}

They comprised the ''lex veritatis'' (French ''du tout'', law of truth), ''lex justitiae'' (''par soi'', law of justice), and ''lex sapientiae'' (''universalité'', or law of wisdom). The third was in the terms of Ramus "universel premièrement", or to make the universal the first instance. The "wisdom" is therefore to start with the universal, and set up a ramifying binary tree by subdivision.&lt;ref&gt;[http://www.science.uva.nl/~seop/entries/ramus/ UVA.nl]&lt;/ref&gt;&lt;ref&gt;Denis Hollier, R. Howard Bloch, ''A New History of French Literature'' (1994), pp. 281–2.&lt;/ref&gt;

As Ramism evolved, these characteristic binary trees, set up rigidly, were treated differently in various fields. In theology, for example, this procedure was turned on its head, since the search for God, the universal, would appear as the goal rather than the starting point.&lt;ref&gt;Brian Cummings, ''The Literary Culture of the Reformation: Grammar and Grace'' (2007), p. 258.&lt;/ref&gt;

[[Émile Bréhier]] wrote that after Ramus, "order" as a criterion of the methodical had become commonplace; Descartes needed only to supply to method the idea of relation, exemplified by the idea of a [[mathematical sequence]] based on a [[functional relationship]] of an element to its successor.&lt;ref&gt;[[Émile Bréhier]], ''The History of Philosophy: The Seventeenth Century'' (1966 translation), p. 54.&lt;/ref&gt; Therefore, for Cartesians, the Ramist insights were quite easily absorbed.{{fact|date=March 2018}}

For the [[Baconian method]], on the other hand, the rigidity of Ramist distinctions was a serious criticism. [[Francis Bacon]], a Cambridge graduate, was early aware of Ramism, but the near-equation of ''dispositio'' with method was unsatisfactory, for Baconians, because arrangement of material was seen to be inadequate for research. The ''[[Novum Organum]]'' implied in its title a further reform of Aristotle, and its aphorism viii of Book I made this exact point.&lt;ref&gt;Brian Vickers, ''Francis Bacon: The Major Works'' (2002), p. 342.&lt;/ref&gt;

==At Cambridge==
A Ramist tradition took root in [[Christ's College, Cambridge]] in the 1570s, when [[Laurence Chaderton]] became the leading Ramist, and [[Gabriel Harvey]] lectured on the rhetoric of Ramus.&lt;ref&gt;[[Joan Simon]], ''Education and Society in Tudor England'' (1979), p. 319.&lt;/ref&gt;&lt;ref name="Brian Cummings 2007 p. 255"&gt;Brian Cummings, ''The Literary Culture of the Reformation: Grammar and Grace'' (2007), p. 255.&lt;/ref&gt; [[Marshall McLuhan]]'s dissertation on [[Thomas Nashe]] (via the [[classical trivium]]), who was involved in a high-profile literary quarrel with Harvey, was shaped by his interest in aligning Harvey with dialectic and the plain style (logic in the sense of Ramus), and Nashe with the full resources of Elizabethan rhetoric.&lt;ref&gt;[http://www.chass.toronto.edu/mcluhan-studies/v1_iss1/1_1art6.htm Toronto.edu]{{dead link|date=April 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; After Chaderton, there was a succession of important theologians using Ramist logic, including [[William Perkins (Puritan)|William Perkins]],&lt;ref&gt;[[Andrew Pyle (philosopher)|Andrew Pyle]] (editor), ''Dictionary of Seventeenth Century British Philosophers'' (2000), article on Perkins, pp. 650.&lt;/ref&gt; and [[William Ames]] (Amesius),&lt;ref&gt;[[Andrew Pyle (philosopher)|Andrew Pyle]] (editor), ''Dictionary of Seventeenth Century British Philosophers'' (2000), article on Ames, pp. 21–2.&lt;/ref&gt; who made Ramist dialectic integral to his approach.{{fact|date=March 2018}}

[[William Temple (scholar)|William Temple]] annotated a 1584 reprint of the ''Dialectics'' in Cambridge.&lt;ref&gt;''Concise Dictionary of National Biography''&lt;/ref&gt; Known as an advocate of Ramism, and involved in controversy with [[Everard Digby (scholar)|Everard Digby]] of Oxford,&lt;ref&gt;Nancy S. Struever, ''Theory as Practice: Ethical Inquiry in the Renaissance'' (1992), p. 135.&lt;/ref&gt; he became secretary to [[Sir Philip Sidney]] about a year later, in 1585.&lt;ref&gt;[http://www.bartleby.com/214/1407.html Bartleby.com]&lt;/ref&gt; Temple was with Sidney when he died in 1586, and wrote a Latin Ramist commentary on ''[[An Apology for Poetry]]''.&lt;ref&gt;Roger Howell, ''Sir Philip Sidney: The Shepherd Knight'' (1698), p. 113.&lt;/ref&gt; Sidney himself is supposed to have learned Ramist theory from [[John Dee]], and was the dedicatee of the biography by Banosius, but was not in any strict sense a Ramist.&lt;ref&gt;Peter French, ''John Dee'' (1972), p. 143.&lt;/ref&gt;

This Ramist school was influential:
{{cquote|The Ramist system was introduced into Cambridge University by Sir William Temple, in 1580, and contributed to the growth of [[Cambridge Platonism]]. It became the basis of Congregational apologetics. The Cambridge Puritans were represented by [[Alexander Richardson (Puritan)|Alexander Richardson]], [[George Downame]], [[Anthony Wotton]], and especially by William Ames, whose writings became the favorite philosophy texts of early New England. In 1672, the same year in which Ames's edition of Ramus's Dialectics with Commentary appeared, Milton published his Institutions of the Art of Logic Based on the Method of Peter Ramus. Other Puritan divines who popularized the Ramist philosophy and [[Covenant Theology]] were William Perkins, [[John Preston (clergyman)|John Preston]], and [[Thomas Hooker]].&lt;ref&gt;Herbert W. Schneider, ''A History Of American Philosophy'' (1946), p. 6.&lt;/ref&gt;}}

[[Christopher Marlowe]] encountered Ramist thought as a student at Cambridge (B.A. in 1584), and made Peter Ramus a character in ''[[The Massacre at Paris]]''. He also cited Ramus in ''[[Doctor Faustus (play)|Dr. Faustus]]'': ''Bene disserere est finis logices'' is a line given to Faustus, who states it is from [[Aristotle]], when it is from the ''Dialecticae'' of Ramus.&lt;ref&gt;{{Citation | url = http://extra.shu.ac.uk/emls/si-16/duxfdrfs.htm |title=Doctor Faustus and the Failure to Unify |publisher = SHU | place = [[United Kingdom|UK]]}}.&lt;/ref&gt;&lt;ref&gt;Robert A. Logan. ''Shakespeare's Marlowe: The Influence of Christopher Marlowe on Shakespeare's Artistry'' (2007), p. 208.&lt;/ref&gt;

There is a short treatise by [[John Milton]], who was a student at Christ's from 1625, published two years before his death, called ''Artis Logicae Plenior Institutio ad Petri Rami Methodum concinnata''.&lt;ref&gt;Milton's ''Logic'' has been translated by Walter J. Ong and Charles J. Ermatinger in [[Yale University|Yale's]] ''Complete Prose Works of John Milton'' (1982, 8: 206–408), with an introduction by Ong (144–205).&lt;/ref&gt; It was one of the last commentaries on Ramist logic.&lt;ref&gt;William Bridges Hunter, ''A Milton Encyclopedia'' (1978), article ''Logic and Rhetoric'', p. 33.&lt;/ref&gt; Although composed in the 1640s, it was not published until 1672. Milton, whose first tutor at Christ's [[William Chappell (bishop)|William Chappell]] used Ramist method,&lt;ref&gt;{{ODNBweb|id=5129|title=Chappell, William|first=Alan|last=Ford}}&lt;/ref&gt;  can take little enough credit for the content. Most of the text proper is adapted from the 1572 edition of Ramus's logic; most of the commentary is adapted from [[George Downham]]'s ''Commentarii in P. Rami Dialecticam'' (1601)&lt;ref&gt;Elizabeth Skerpan-Wheeler, "John Milton (9 December 1608–8? November 1674)," ''British Rhetoricians and Logicians, 1500–1660, Second Series'', volume 281 in the ''[[Dictionary of Literary Biography]]'' series, Detroit: Thomson Gale, 2003, pp. 188–200 at 195&lt;/ref&gt;—Downham, also affiliated with Christ's, was a professor of logic at Cambridge.&lt;ref&gt;{{ODNBweb|id=7977|first=Kenneth|last=Gibson|title=Downham, George}}&lt;/ref&gt; The biography of Ramus is a cut-down version of that of [[Johann Thomas Freigius]] (1543–83).&lt;ref&gt;{{ODNBweb|id=18800|title=Milton, John|first=Gordon|last=Campbell}}&lt;/ref&gt;

==At Herborn==
[[Herborn Academy]] in Germany was founded in 1584, as a Protestant university, and initially was associated with a group of Reformed theologians who developed [[covenant theology]]. It was also a centre of Ramism, and in particular of its encyclopedic form. In turn, it was the birthplace of [[pansophism]].&lt;ref&gt;Leroy E. Loemker, ''Leibniz and the Herborn Encyclopedists'', Journal of the History of Ideas, Vol. 22, No. 3 (Jul.–Sep., 1961), pp. 323–338.&lt;/ref&gt; [[Heinrich Alsted]] taught there, and [[John Amos Comenius]] studied with him.{{fact|date=March 2018}}

Ramism was built into the curriculum, with the professors required to give Ramist treatments of the ''trivium''. [[Johannes Piscator]] anticipated the foundation in writing introductory Ramist texts, [[Johannes Althusius]] and [[Lazarus Schöner]] likewise wrote respectively on social science topics and mathematics, and Piscator later produced a Ramist theology text.&lt;ref&gt;{{Cite web |url=http://faculty.ed.uiuc.edu/westbury/textcol/HAMILTO1.html |title=UIUC.edu |access-date=10 November 2008 |archive-url=https://web.archive.org/web/20081013083842/http://faculty.ed.uiuc.edu/westbury/textcol/HAMILTO1.html |archive-date=13 October 2008 |dead-url=yes |df=dmy-all }}&lt;/ref&gt;

==In literature==
Brian Vickers argues that the Ramist influence did add something to rhetoric: it concentrated more on the remaining aspect of ''elocutio'' or effective use of language, and emphasised the role of vernacular European languages (rather than Latin). The outcome was that rhetoric was applied in literature.&lt;ref&gt;Brian Vickers, ''In Defence of Rhetoric'' (1988), p. 206.&lt;/ref&gt;

In 1588 [[Abraham Fraunce]], a protégé of Philip Sidney, published ''Arcadian Rhetorike'', a Ramist-style rhetoric book cut down largely to a discussion of figures of speech (in prose and verse), and referring by its title to Sidney's ''[[Countess of Pembroke's Arcadia|Arcadia]]''. It was based on a translation of Talon's ''Rhetoricae'', and was a companion to ''The Lawiers Logike'' of 1585, an adapted translation of the ''Dialecticae'' of Ramus. Through it, Sidney's usage of figures was disseminated as the Ramist "Arcadian rhetoric" of standard English literary components and ornaments, before the source ''Arcadia'' had been published. It quickly lent itself to floridity of style. [[William Kurtz Wimsatt, Jr.|William Wimsatt]] and [[Cleanth Brooks]] consider that the Ramist reform at least created a tension between the ornamented and the plain style (of preachers and scientific scholars), into the seventeenth century, and contributed to the emergence of the latter.&lt;ref&gt;[[William Kurtz Wimsatt, Jr.|William Wimsatt]] and [[Cleanth Brooks]], ''Literary Criticism: A Short History'' (1957), pp. 224–6.&lt;/ref&gt; With the previous work of [[Dudley Fenner]] (1584), and the later book of [[Charles Butler (beekeeper)|Charles Butler]] (1598), Ramist rhetoric in Elizabethan England accepts the reduction to ''elocutio'' and ''pronuntiatio'', puts all the emphasis on the former, and reduces its scope to the [[Trope (literature)|trope]].&lt;ref&gt;[[Quentin Skinner]], ''Reason and Rhetoric in the Philosophy of Hobbes'' (1996), p. 62.&lt;/ref&gt;

[[Geoffrey Hill]] classified [[Robert Burton (scholar)|Robert Burton]]'s ''[[Anatomy of Melancholy]]'' (1621) as a "post-Ramist [[anatomy (genre)|anatomy]]". It is a work (he says against Ong) of a rooted scholar with a "method" but turning Ramism back on itself.&lt;ref&gt;[[Geoffrey Hill]], ''Collected Critical Writings'' (2008), editor Kenneth Haynes, p. 298 and p. 332.&lt;/ref&gt;

==Ramists==

===Danish===
* [[Andreas Krag]]&lt;ref&gt;W. J. Ong, ''Ramus, Method and the Decay of Dialogue'', Cambridge, MA: [[Harvard University Press]], 1958, p. 305&lt;/ref&gt;

===Dutch===
* [[Jacobus Arminius]]&lt;ref&gt;{{Citation | url = http://encyclopedia.jrank.org/APO_ARN/ARMINIUS_JACOBUS_1560_1609_.html | publisher = J rank | title = Encyclopedia | contribution = Arminius, Jacobus, 1560–1609}}.&lt;/ref&gt;
* [[Isaac Beeckman]], [[Rudolf Snellius]], [[Willebrord Snellius]]&lt;ref&gt;Willem Frijhoff, Marijke Spies, ''Dutch Culture in a European Perspective'' (2004), p. 313.&lt;/ref&gt;
* [[Justus Lipsius]], wrote his ''Politicorum sive Civilis doctrinae'' on a strict Ramist scheme.&lt;ref&gt;{{Citation | url = http://plato.stanford.edu/entries/justus-lipsius/ |title=Justus Lipsius}}.&lt;/ref&gt;

===Scottish===
* [[Roland MacIlmaine]] (University of St Andrews) published {{Citation | title = The Logike of the Moste Excellent Philosopher P. Ramus, Martyr}}, and a Latin edition of this work in 1574.&lt;ref&gt;Neil Rhodes, 'From Rhetoric to Composition' in ''The Scottish Invention of English Literature'', ed. Robert Crawford, p. 25.&lt;/ref&gt;

===English===
* [[John Barton (c. 1605-1675)]]&lt;ref&gt;K. R. Narveson, "John Barton (circa 1610–1675)," ''British Rhetoricians and Logicians, 1500–1660, First Series'', volume 236 in the ''Dictionary of Literary Biography'' series, Detroit: Thomson Gale, 2001, pp. 40–46&lt;/ref&gt;&lt;ref&gt;{{ODNBweb|id=74234|title=Barton, John|last=Malone|first=Edward A.}}&lt;/ref&gt;
* [[Nathaniel Baxter]]&lt;ref&gt;Kees Meerhoff, ''Bartholomew Keckerman and the Anti-Ramist Tradition'', in Christoph Strohm, Joseph S. Freedman, H. J. Selderhuis (editors), ''Späthumanismus und reformierte Konfession: Theologie, Jurisprudenz und Philosophie in Heidelberg an der Wende zum 17. Jahrhundert'' (2006), p. 191.&lt;/ref&gt;
* [[Charles Butler (beekeeper)|Charles Butler]]&lt;ref&gt;Victor W. Cook, "Charles Butler (circa 1560–29 March 1647)," ''British Rhetoricians and Logicians, 1500–1660, First Series'', volume 236 in the Dictionary of Literary Biography series, Detroit: Thomson Gale, 2001, pp. 81–90&lt;/ref&gt;
* [[George Downame]]&lt;ref name=Toons&gt;{{Citation | url = http://www.anglicanbooksrevitalized.us/Peter_Toons_Books_Online/History/hypercal1.htm | title = History | publisher = Anglican books revitalized | deadurl = yes | archiveurl = https://web.archive.org/web/20090226001003/http://www.anglicanbooksrevitalized.us/Peter_Toons_Books_Online/History/hypercal1.htm | archivedate = 26 February 2009 | df = dmy-all }}.&lt;/ref&gt;
* [[Dudley Fenner]]&lt;ref&gt;Stephen Collins, "Dudley Fenner (1558?–1587)," ''British Rhetoricians and Logicians, 1500–1660, First Series'', volume 236 in the Dictionary of Literary Biography series, Detroit: Thomson Gale, 2001, pp. 117–125&lt;/ref&gt;
* [[Henry Finch]], jurist, attempted in ''Nomotexnia'' to arrange [[common law]] along Ramist lines&lt;ref&gt;C. W. Brooks. ''Lawyers, Litigation, and English Society Since 1450'' (1998), p. 207.&lt;/ref&gt;
* [[William Gouge]]&lt;ref name = Hill&gt;[[Christopher Hill (historian)|Christopher Hill]], ''Intellectual Origins of the English Revolution'' (1965), p. 308.&lt;/ref&gt;
* [[Thomas Granger (clergyman)|Thomas Granger]]&lt;ref name="Brian Cummings 2007 p. 255"/&gt;&lt;ref&gt;Shawn Smith, "Thomas Granger (March 1578 – June 1627)," ''British Rhetoricians and Logicians, 1500–1660, Second Series'', volume 281 in the Dictionary of Literary Biography series, Detroit: Thomson Gale, 2003, pp. 105–117&lt;/ref&gt;&lt;ref&gt;{{ODNBweb|id=66966|title=Granger, Thomas|last=Morgan|first=John}}&lt;/ref&gt;
* [[John Rainolds]]&lt;ref name = Hill /&gt;
* [[Alexander Richardson (Puritan)|Alexander Richardson]]&lt;ref name = Toons/&gt;&lt;ref&gt;{{ODNBweb|id=66371|title=Richardson, Alexander|last=Hall|first=Roland}}&lt;/ref&gt;
* [[John Udall (Puritan)|John Udall]]&lt;ref&gt;{{Citation | url = http://journal.oraltradition.org/files/articles/2i/13_rechtien.pdf | title = Rechtien | format = [[PDF]] | journal = Oral tradition}}.&lt;/ref&gt;

===French===
* [[Guy de Brues]]&lt;ref&gt;[[Richard H. Popkin]], ''The History of Scepticim from Erasmus to Spinoza'' (1979), p. 32.&lt;/ref&gt;
* [[Pierre Gassendi]] in writing on logic.&lt;ref&gt;{{Citation | url = http://plato.stanford.edu/entries/gassendi/ |title=Pierre Gassendi}}.&lt;/ref&gt;

===German===
* [[Johann Heinrich Alsted]], "the culmination of the Ramist tradition", but also a critic of naive Ramism&lt;ref&gt;Howard Hotson, ''Johann Heinrich Alsted, 1588–1638: Between Renaissance, Reformation, and Universal Reform'' (2000), p. 10.&lt;/ref&gt;
* [[Johannes Althusius]] organised his ''Politics'' in accordance with Ramist logic
* [[Bartholomäus Keckermann]], constructed a modified Ramist logic.&lt;ref&gt;Graeme Murdock, ''Calvinism on the Frontier, 1600–1660: International Calvinism and the Reformed Church in Hungary and Transylvania'' (2000), p. 86.&lt;/ref&gt;
* [[Johannes Piscator]]&lt;ref name = Toons/&gt;
* [[Caspar Schoppe]]&lt;ref&gt;R. J. W. Evans, ''Rudolf II and His World'' (1973), p. 21.&lt;/ref&gt;

===Hungarian===
* [[János Apáczai Csere]], encyclopedist.&lt;ref&gt;[http://www.phil-inst.hu/tudrend/PalloAeginart.htm Phil-inst.hu] {{webarchive|url=https://web.archive.org/web/20110526092649/http://www.phil-inst.hu/tudrend/PalloAeginart.htm |date=26 May 2011 }}&lt;/ref&gt;

===Scottish===
* [[James Martin (philosopher)|James Martin]] has been classified as a Ramist he was a writer against Aristotle, but the classification is disputed.&lt;ref&gt;{{ODNBweb|id=18187|title=Martin, James|first=Jill|last=Kraye}}&lt;/ref&gt;
* [[Andrew Melville]]&lt;ref&gt;{{cite EB1911 |wstitle=Melville, Andrew |volume=18 |pages=101–102}}&lt;/ref&gt;
* Roland MacIlmaine.&lt;ref&gt;*T. A. Goeglein, "Roland MacIlmaine (fl. 1574)," ''British Rhetoricians and Logicians, 1500–1660, Second Series'', volume 281 in the Dictionary of Literary Biography series, Detroit: Thomson Gale, 2003, pp. 173–177&lt;/ref&gt;

===Swedish===
* [[Paulinus Gothus]].&lt;ref&gt;Jerzy Dobrzycki, ''The Reception of Copernicus' Heliocentric Theory: Proceedings of a Symposium Organized by the Nicolas Copernicus Committee of the International Union of the History and Philosophy of Science'' (Toruń, Poland, 1973), p. 243.&lt;/ref&gt;

===Swiss===
* [[Johannes Wolleb]]&lt;ref name = Toons/&gt;

===Welsh===
* [[Henry Perri]].&lt;ref name="yba.llgc.org.uk"/&gt;&lt;ref&gt;William Kneale and Martha Kneale, ''The Development of Logic'' (1962), p. 306.&lt;/ref&gt;&lt;ref&gt;*A. Breeze, "Henry Perri or Perry (1561–1617)," ''British Rhetoricians and Logicians, 1500–1660, First Series'', volume 236 in the Dictionary of Literary Biography series, Detroit: Thomson Gale, 2001, pp. 202–209&lt;/ref&gt;

==References==
{{Reflist}}

==Bibliography==
* J. C. Adams, "Ramus, Illustrations, and the Puritan Movement," ''Journal of Medieval and Renaissance Studies'', vol. 17, 1987, pp.&amp;nbsp;195–210
* N. Bruyere, ''Méthode et dialectique dans l'oeuvre de La Ramée'', Paris: Vrin 1984
* N. Bruyere-Robinet, "Le statut de l'invention dans l'oeuvre de La Ramee," ''Revue des sciences philosophiques et theologiques'', vol. 70, 1986, pp.&amp;nbsp;15–24
* M. Feingold, J. S. Freedman, and W. Rother (editors), ''The Influence of Petrus Ramus: Studies in Sixteenth and Seventeenth Century Philosophy and Sciences'', Basel, Schwabe &amp; Co., 2001
* J. S. Freedman, "The Diffusion of the Writings of Petrus Ramus in Central Europe, c.1570–c.1630," ''Renaissance Quarterly'', vol. 46, 1993, pp.&amp;nbsp;98–152
* [https://books.google.com/books?id=0D0RAAAAYAAJ F. P. Graves, ''Peter Ramus and the Educational Reformation of the Sixteenth Century'', New York: Macmillan, 1912.]*Howard Hotson, ''Commonplace Learning: Ramism and its German Ramifications, 1543–1630'' (2007)
* H. Hotson, ''Commonplace Learning: Ramism and Its German Ramifications, 1543-1630'', New York: Oxford University Press, 2007
* W. S. Howell, ''Logic and Rhetoric in England, 1500-1700'', Princeton: Princeton UP, 1956.
* R. Kennedy and T. Knoles, [http://www.americanantiquarian.org/proceedings/44525172.pdf "Increase Mather's 'Catechismus Logicus': A Translation and an Analysis of the Role of a Ramist Catechism at Harvard,"] ''Proceedings of the American Antiquarian Society'', vol. 109, no. 1, 2001, pp.&amp;nbsp;183–223
* K. Meerhoff and J. Moisan, eds. ''Autour de Ramus: Texte, Theorie, Commentaire'', Quebec: Nuit Blanche, 1997
* K. Meerhoff, ''Rhétorique et Poétique au XVle siècle en France'', Leiden: Brill 1986, pp.&amp;nbsp;175–330
* J. J. Murphy, ed., ''Peter Ramus's Attack on Cicero: Text and Translation of Ramus's Brutinae Quaestiones'', Davis, CA: Hermagoras Press, 1992
* [[W. J. Ong]], ''A Ramus and Talon Inventory'', Cambridge, MA: Harvard UP, 1958
* W. J. Ong, ''Ramus, Method and the Decay of Dialogue'', Cambridge, MA: Harvard UP, 1958
* W. J. Ong, Introduction to Peter Ramus's ''Scholae in liberales artes'', Hildesheim: Olms, 1970
* W. J. Ong, Introduction to Peter Ramus's ''Collectaneae praefationes, epistolae, orationes'', Hildesheim: Olms, 1969
* S. J. Reid and E. A. Wilson (eds.), ''Ramus, Pedagogy and the Liberal Arts: Ramism in Britain and the Wider World'', Burlington: Ashgate, 2011
* P. Sharratt, "The Present State of Studies on Ramus," ''Studi Francesi'', vol. 47/48, 1972, pp.&amp;nbsp;201–203
* {{Citation | first = P | last = Sharratt | title = Recent Works on Peter Ramus (1970–1986) | journal = Rhetorica | volume = 5 | number = 1 | year = 1987 | pages = 7–58 | author-mask = 3 | doi=10.1525/rh.1987.5.1.7}}.
* {{Citation |first= P |last= Sharratt |contribution= The First French Logic |title = Mélanges a la mémoire de Franco Simone |volume= IV |trans-title= Varieties in memory of Franco Simone |place= Geneva |publisher= Slatkine |year= 1983 |pages= 205–19 | author-mask = 3}}
* {{Citation | first = P | last = Sharratt | title = Peter Ramus and the Reform of the University | journal = French Renaissance Studies, 1540–1570 | place = Edinburgh | publisher = Edinburgh UP | year = 1976 | pages = 4–20 | author-mask = 3}}.
* {{Citation | first = P | last = Sharratt | title = Ramus 2000 | journal = Rhetorica | volume = 18 | number = 4 | year = 2000 | pages = 399–455 | author-mask = 3 | doi=10.1525/rh.2000.18.4.399}}.
* P. Sharratt, ed., ''Ramus'', a special issue of ''Argumentation'', vol. 5, no. 4, 1991, pp.&amp;nbsp;335–446

==External links==
* [https://www.st-andrews.ac.uk/ramus/bibliography.html Peter Ramus Conference 2008]

[[Category:Renaissance philosophy]]
[[Category:History of logic]]
[[Category:Theories of deduction]]</text>
      <sha1>kcfqmek42fnv2n4v2wenxt52yosycx1</sha1>
    </revision>
  </page>
  <page>
    <title>Rickart space</title>
    <ns>0</ns>
    <id>30727109</id>
    <revision>
      <id>841148812</id>
      <parentid>814475500</parentid>
      <timestamp>2018-05-14T08:53:13Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <comment>/* References */ doi=10.2307/1969091</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1191">In mathematics, a '''Rickart space''' (after [[Charles Earl Rickart]]), also called a '''basically disconnected space''', is a [[topological space]] in which open σ-compact subsets have [[compact space|compact]] open closures. {{harvtxt|Grove|Pedersen|1984}} named them after {{harvs|txt|first=C. E. |last=Rickart|year=1946}}, who  showed that Rickart spaces are related to monotone σ-complete [[C*-algebra]]s in the same way that  [[Stonean space]]s are related to [[AW*-algebra]]s.

Rickart spaces are [[totally disconnected]] and [[sub-Stonean space]]s.

==References==
*{{Citation | last1=Grove | first1=Karsten | last2=Pedersen | first2=Gert Kjærgård | title=Sub-Stonean spaces and corona sets | doi=10.1016/0022-1236(84)90028-4 | mr=735707 | year=1984 | journal=Journal of Functional Analysis | issn=0022-1236 | volume=56 | issue=1 | pages=124–143}}
*{{Citation | last1=Rickart | first1=C. E. | title=Banach algebras with an adjoint operation | jstor=1969091 | mr=0017474 | year=1946 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=47 | pages=528–550 | doi=10.2307/1969091}}

[[Category:Properties of topological spaces]]


{{topology-stub}}</text>
      <sha1>r5mqkysialxn21w72kx0q2lcovmkrcc</sha1>
    </revision>
  </page>
  <page>
    <title>Signal-flow graph</title>
    <ns>0</ns>
    <id>15175696</id>
    <revision>
      <id>846451326</id>
      <parentid>843164080</parentid>
      <timestamp>2018-06-18T21:26:32Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="77031">{{Redirect|Mason graph|other flow graphs|Flow graph (mathematics)}}

A '''signal-flow graph''' or '''signal-flowgraph''' ('''SFG'''), invented by [[Claude Shannon]],&lt;ref name =Shannon/&gt; but often called a '''Mason graph''' after [[Samuel Jefferson Mason]] who coined the term,&lt;ref name=Mason/&gt; is a specialized [[Flow graph (mathematics)|flow graph]], a [[directed graph]] in which nodes represent system variables, and branches (edges, arcs, or arrows) represent functional connections between pairs of nodes. Thus, signal-flow graph theory builds on that of [[directed graph]]s (also called [[Digraph (mathematics)|digraph]]s), which includes as well that of [[Orientation (graph theory)#Oriented graphs|oriented graph]]s. This mathematical theory of digraphs exists, of course, quite apart from its applications.&lt;ref name=Gutin&gt;
{{cite book |title=Digraphs |url=https://books.google.com/books?id=5GdXCWhE4-MC&amp;printsec=frontcover |author1=Jørgen Bang-Jensen |author2=Gregory Z. Gutin |year=2008 |publisher=Springer |isbn=9781848009981}}
&lt;/ref&gt;&lt;ref name=Bollobas&gt;
{{cite book |title=Modern graph theory  |url=https://books.google.com/books?id=JeIlBQAAQBAJ&amp;pg=PA8 |page=8 |author=Bela Bollobas  |publisher=Springer Science &amp; Business Media   |year=1998 |isbn= 9781461206194}}i
&lt;/ref&gt;

SFGs are most commonly used to represent signal flow in a [[physical systems|physical system]] and its controller(s), forming a [[cyber-physical system]].  Among their other uses are the representation of signal flow in various electronic networks and amplifiers, [[digital filter]]s, state-variable filters and some other types of analog filters.  In nearly all literature, a signal-flow graph is associated with a set of linear equations.

== History ==
Wai-Kai Chen wrote: "The concept of a signal-flow graph was originally worked out by [[Claude Shannon|Shannon]] [1942]&lt;ref name=Shannon&gt;
{{cite journal |author =CE Shannon |title=The theory and design of linear differential equation machines |date=January 1942 |publisher=Fire Control of the US National Defense Research Committee: Report 411, Section D-2}} Reprinted in {{cite book |title=Claude E. Shannon: Collected Papers |editor1=N. J. A. Sloane |editor2=Aaron D. Wyner |publisher=Wiley IEEE Press |year=1993 |page=514 |isbn=978-0-7803-0434-5 |url=https://books.google.com/books?ei=2BmsVK7hL4bWoATFi4KQCQ&amp;id=wbLuAAAAMAAJ&amp;dq=isbn%3A9780780304345&amp;focus=searchwithinvolume&amp;q=Theory+and+Design+of+Linear+Differential+Equation+Machines.}}
&lt;/ref&gt; 
in dealing with analog computers. The greatest credit for the formulation of signal-flow graphs is normally extended to [[Samuel Jefferson Mason|Mason]] [1953],&lt;ref name=Mason&gt;
{{cite journal|last=Mason|first=Samuel J. |date=September 1953|title=Feedback Theory - Some Properties of Signal Flow Graphs|journal=Proceedings of the IRE |pages=1144–1156 |doi=10.1109/jrproc.1953.274449 |url=http://ecee.colorado.edu/~ecen5014/Mason-IRE-1953.pdf |quote=The flow graph may be interpreted as a signal transmission system in which each node is a tiny repeater station. The station receives signals via the incoming branches, combines the information in some manner, and then transmits the results along each outgoing branch. |volume=41}}
&lt;/ref&gt; [1956].&lt;ref name=Mason2&gt;
{{cite journal |title=Feedback Theory-Further Properties of Signal Flow Graphs |author=SJ Mason |doi=10.1109/JRPROC.1956.275147 |date=July 1956 |volume=44 |issue=7 |journal=Proceedings of the IRE |pages=920–926 }} On-line version found at [http://dspace.mit.edu/bitstream/handle/1721.1/4778/RLE-TR-303-15342712.pdf?sequence=1 MIT Research Laboratory of Electronics].
&lt;/ref&gt; He showed how to use the signal-flow graph technique to solve some difficult electronic problems in a relatively simple manner. The term '''signal flow graph''' was used because of its original application to electronic problems and the association with electronic signals and flowcharts of the systems under study."&lt;ref&gt;{{cite book|last=Chen|first=Wai-Kai|date=1976|title= Applied Graph Theory : Graphs and Electrical Networks |publisher=[[Elsevier]]|url=https://books.google.com/books?id=wYqjBQAAQBAJ&amp;pg=PA167 |isbn=9781483164151}}{{Harv|WKC|1976|p=167}}&lt;/ref&gt;

Lorens wrote: "Previous to [[Samuel Jefferson Mason|Mason]]'s work, [[Claude Shannon|C. E. Shannon]]&lt;ref name="Shannon"/&gt;  worked out a number of the properties of what are now known as flow graphs. Unfortunately, the paper originally had a restricted classification and very few people had access to the material."&lt;ref&gt;
{{Citation
| last  = Lorens
| first = Charles Stanton
| date = July 15, 1956
| editor-last  = Vogel
| editor-first = Dan
| title  = Technical Report 317 - Theory and applications of flow graphs
| publisher = Research Laboratory of Electronics, MIT
| url = http://dspace.mit.edu/bitstream/handle/1721.1/4765/rle-tr-317-04734656.pdf?sequence=1
}}&lt;/ref&gt;

"The rules for the evaluation of the graph determinant of a Mason Graph were first given and proven by Shannon [1942] using mathematical induction. His work remained essentially unknown even after Mason published his classical work in 1953. Three years later, Mason [1956] rediscovered the rules and proved them by considering the value of a determinant and how it changes as variables are added to the graph. [...]"&lt;ref&gt;{{Harv|WKC|1976|p=169}}&lt;/ref&gt;

== Domain of application ==
Robichaud ''et al.'' identify the domain of application of SFGs as follows:&lt;ref name=Robichaud&gt;
{{cite book |title=Signal flow graphs and applications |author1=Louis PA Robichaud |author2=Maurice Boisvert |author3=Jean Robert |year=1962 |publisher=Prentice Hall |url=http://babel.hathitrust.org/cgi/pt?id=uc1.b4338380;view=1up;seq=8 |asin=B0000CLM1G |chapter = Preface |page=''x''}}
&lt;/ref&gt;
:"All the physical systems analogous to these networks [constructed of ideal transformers, active elements and gyrators] constitute the domain of application of the techniques developed [here]. Trent&lt;ref name=Trent&gt;
{{cite journal |author=Horace M Trent |title=Isomorphisms between Oriented Linear Graphs and Lumped Physical Systems |journal=Journal of the Acoustical Society of America |volume=27 |issue=3 |pages=500 ''ff'' |year=1955 |url=https://dx.doi.org/10.1121/1.1907949 |doi=10.1121/1.1907949}}
&lt;/ref&gt; has shown that all the physical systems which satisfy the following conditions fall into this category.
# The finite lumped system is composed of a number of simple parts, each of which has known dynamical properties which can be defined by equations using two types of scalar variables and parameters of the system. Variables of the first type represent quantities which can be measured, at least conceptually, by attaching an indicating instrument to two connection points of the element. Variables of the second type characterize quantities which can be measured by connecting a meter in series with the element. Relative velocities and positions, pressure differentials and voltages are typical quantities of the first class, whereas electric currents, forces, rates of heat flow, are variables of the second type. Firestone has been the first to distinguish these two types of variables with the names ''across variables'' and ''through variables''.
# Variables of the first type must obey a mesh law, analogous to Kirchhoff's voltage law, whereas variables of the second type must satisfy an incidence law analogous to Kirchhoff's current law.
# Physical dimensions of appropriate products of the variables of the two types must be consistent. For the systems in which these conditions are satisfied, it is possible to draw a linear graph isomorphic with the dynamical properties of the system as described by the chosen variables. The techniques [...] can be applied directly to these linear graphs as well as to electrical networks, to obtain a signal flow graph of the system."

== Basic flow graph concepts ==
The following illustration and its meaning were introduced by Mason to illustrate basic concepts:&lt;ref name=Mason/&gt;
[[File:Flow graphs.svg|thumb|400px|right|(a) Simple flow graph, (b) The arrows of (a) incident on node 2 (c) The arrows of (a) incident on node 3]]
In the simple flow graphs of the figure, a functional dependence of a node is indicated by an incoming arrow, the node originating this influence is the beginning of this arrow, and in its most general form the signal flow graph indicates by incoming arrows only those nodes that influence the processing at the receiving node, and at each node, ''i'', the incoming variables are processed according to a function associated with that node, say ''F&lt;sub&gt;i&lt;/sub&gt;''. The flowgraph in (a) represents a set of explicit relationships:
:&lt;math&gt;\begin{align}
 x_\mathrm{1} &amp;= \text{an independent variable} \\
 x_\mathrm{2} &amp;= F_2(x_\mathrm{1}, x_\mathrm{3})\\
 x_\mathrm{3} &amp;= F_3(x_\mathrm{1}, x_\mathrm{2}, x_\mathrm{3})\\
\end{align}&lt;/math&gt;
Node ''x&lt;sub&gt;1&lt;/sub&gt;'' is an isolated node because no arrow is incoming; the equations for ''x&lt;sub&gt;2&lt;/sub&gt;'' and ''x&lt;sub&gt;3&lt;/sub&gt;'' have the graphs shown in parts (b) and (c) of the figure.

These relationships define for every node a function that processes the input signals it receives. Each non-source node combines the input signals in some manner, and broadcasts a resulting signal along each outgoing branch. "A flow graph, as defined originally by Mason, implies a set of functional relations, linear or not."&lt;ref name=Robichaud/&gt;

However, the commonly used Mason graph is more restricted, assuming that each node simply sums its incoming arrows, and that each branch involves only the initiating node involved. Thus, in this more restrictive approach, the node ''x&lt;sub&gt;1&lt;/sub&gt;'' is unaffected while:
:&lt;math&gt;x_2=f_{21}(x_1)+f_{23}(x_3) &lt;/math&gt;
:&lt;math&gt;x_3=f_{31}(x_1)+f_{32}(x_2)+f_{33}(x_3) \ ,&lt;/math&gt;

and now the functions ''f&lt;sub&gt;ij&lt;/sub&gt;'' can be associated with the signal-flow branches ''ij'' joining the pair of nodes ''x&lt;sub&gt;i&lt;/sub&gt;, x&lt;sub&gt;j&lt;/sub&gt;'', rather than having general relationships associated with each node. A contribution by a node to itself like ''f&lt;sub&gt;33&lt;/sub&gt;'' for ''x&lt;sub&gt;3&lt;/sub&gt;''  is called a ''self-loop''. Frequently these functions are simply multiplicative factors (often called ''transmittances'' or ''gains''), for example, ''f&lt;sub&gt;ij&lt;/sub&gt;(x&lt;sub&gt;j&lt;/sub&gt;)=c&lt;sub&gt;ij&lt;/sub&gt;x&lt;sub&gt;j&lt;/sub&gt;'', where ''c'' is a scalar, but possibly a function of some parameter like the Laplace transform variable ''s''. Signal-flow graphs are very often used with Laplace-transformed signals, and in this case the transmittance, ''c(s)'', often is called a [[transfer function]].

=== Choosing the variables ===
{{quote|In general, there are several ways of choosing the variables in a complex system. Corresponding to each choice, a [[system of equations]] can be written and each system of equations can be represented in a graph. This formulation of the equations becomes direct and automatic if one has at his disposal techniques which permit the drawing of a graph directly from the [[schematic diagram]] of the system under study. The structure of the graphs thus obtained is related in a simple manner to the [[topology]] of the [[schematic diagram]], and it becomes unnecessary to consider the [[equations]], even implicitly, to obtain the graph. In some cases, one has simply to imagine the flow graph in the schematic diagram and the desired answers can be obtained without even drawing the flow graph.|Robichaud&lt;ref&gt;{{harv|Robichaud|1962|p=ix}}&lt;/ref&gt;}}

=== Non-uniqueness ===
Robichaud et al. wrote: "The signal flow graph contains the same information as the equations from which it is derived; but there does not exist a one-to-one correspondence between the graph and the system of equations. One system will give different graphs according to the order in which the equations are used to define the variable written on the left-hand side."&lt;ref name=Robichaud /&gt; If all equations relate all dependent variables, then there are ''n!'' possible SFGs to choose from.&lt;ref name=Deo2&gt;{{cite book |title=Graph Theory with Applications to Engineering and Computer Science |author=Narsingh Deo |url=https://books.google.com/books?id=Yr2pJA950iAC&amp;pg=PA418&amp;dq=%22set+of+n+equations+we+can+obtain%22&amp;hl=en&amp;sa=X&amp;ei=buTgVLC8AoqrogSO54GQCA&amp;ved=0CB8Q6AEwAA#v=onepage&amp;q=%22set%20of%20n%20equations%20we%20can%20obtain%22&amp;f=false |page=418 |isbn=9788120301450 |year=2004 |publisher=PHI Learning Pvt. Ltd}}&lt;/ref&gt;

== Linear signal-flow graphs ==
Linear signal-flow graph methods only apply to [[linear time-invariant system]]s, as studied by [[LTI system theory|their associated theory]].  When modeling a system of interest, the first step is often to determine the equations representing the system's operation without assigning causes and effects (this is called acausal modeling).&lt;ref&gt;{{Citation
 |last        = Kofránek
 |first       = J
 |last2       = Mateják
 |first2      = M
 |last3       = Privitzer
 |first3      = P
 |last4       = Tribula
 |first4      = M
 |title       = Causal or acausal modeling: labour for humans or labour for machines
 |series      = Technical Computing Prague 2008. Conference Proceedings.
 |place       = Prague
 |pages       = 16
 |date        = 2008
 |url         = http://www2.humusoft.cz/kofranek/058_Kofranek.pdf
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20091229065507/http://www2.humusoft.cz/kofranek/058_Kofranek.pdf
 |archivedate = 2009-12-29
 |df          = 
}}&lt;/ref&gt; A SFG is then derived from this system of equations.

A linear SFG consists of nodes indicated by dots and weighted directional branches indicated by arrows. The nodes are the variables of the [[system of linear equations|equations]] and the branch weights are the coefficients. Signals may only traverse a branch in the direction indicated by its arrow.  The elements of a SFG can only represent the operations of multiplication by a coefficient and addition, which are sufficient to represent the constrained equations. When a signal traverses a branch in its indicated direction, the signal is multiplied the weight of the branch. When two or more branches direct into the same node, their outputs are added.

For systems described by linear algebraic or differential equations, the signal-flow graph is mathematically equivalent to the system of equations describing the system, and the equations governing the nodes are discovered for each node by summing incoming branches to that node. These incoming branches convey the contributions of the other nodes, expressed as the connected node value multiplied by the weight of the connecting branch, usually a real number or function of some parameter (for example a [[Laplace transform]] variable ''s'').

For linear active networks, Choma writes:&lt;ref name=Choma&gt;
{{cite journal |title=Signal flow analysis of feedback networks |author=J Choma, Jr |journal=IEEE Trans Circuits &amp; Systems |volume=37 |issue=4 |date=April 1990 |pages=455–463 |url=http://wenku.baidu.com/view/e046d9d528ea81c758f578c7.html |doi=10.1109/31.52748}}
&lt;/ref&gt; "By a 'signal flow representation' [or 'graph', as it is commonly referred to] we mean a diagram that, by displaying the algebraic relationships among relevant branch variables of network, paints an unambiguous picture of the way an applied input signal ‘flows’ from input-to-output ... ports."

A motivation for a SFG analysis is described by Chen:&lt;ref name=ChenWK&gt;
{{cite book |title=Applied graph theory |author=Wai-Kai Chen |page=140 |chapter=Chapter 3: Directed graph solutions of linear algebraic equations |isbn=978-0444101051 |publisher=North-Holland Pub. Co |year=1971 }} Partly accessible using [https://www.amazon.com/Applied-North-Holland-applied-mathematics-mechanics/dp/0444101055/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1420123975&amp;sr=1-1&amp;keywords=9780444101051#reader_0444101055 Amazon's look-inside feature].
&lt;/ref&gt;
:"The analysis of a linear system reduces ultimately to the solution of a system of linear algebraic equations. As an alternative to conventional algebraic methods of solving the system, it is possible to obtain a solution by considering the properties of certain directed graphs associated with the system." [See subsection: [[#Solving linear equations|Solving linear equations]].] "The unknowns of the equations correspond to the nodes of the graph, while the linear relations between them appear in the form of directed edges connecting the nodes. ...The associated directed graphs in many cases can be set up directly by inspection of the physical system without the necessity of first formulating the →associated equations..."

===Basic components===
[[File:Elements of a signal flow graph.png|thumb|Elements and constructs of a signal flow graph.]]

A linear signal flow graph is related to a system of linear equations&lt;ref name=Ogata&gt;
See, for example, {{cite book |url=https://books.google.com/books?id=pdtRBgAAQBAJ&amp;pg=PA106 |pages= 106 ''ff'' |chapter=Chapter 3-9: Signal flow graph representation of linear systems |title=Modern Control Engineering |year=2004 |edition=4th |author=Katsuhiko Ogata |publisher=Prentice Hall |isbn= 978-0130609076}} However, there is not a one-to-one correspondence: {{cite book |url=https://books.google.com/books?id=Yr2pJA950iAC&amp;pg=PA418 |page=418 |author=Narsingh Deo |title=Graph Theory with Applications to Engineering and Computer Science |year=2004 |isbn=9788120301450 |publisher=PHI Learning Pvt. Ltd.}}
&lt;/ref&gt; of the following form:
:&lt;math&gt;\begin{align}
 x_\mathrm{j} &amp;= \sum_{\mathrm{k}=1}^{\mathrm{N}} t_\mathrm{jk} x_\mathrm{k}
\end{align}&lt;/math&gt;
::where &lt;math&gt;t_{jk}&lt;/math&gt; = transmittance (or gain) from &lt;math&gt;x_k&lt;/math&gt; to &lt;math&gt;x_j&lt;/math&gt;.

The figure to the right depicts various elements and constructs of a signal flow graph (SFG).&lt;ref name="Kuo, 2nd ed, p 59"&gt;{{cite book|last=Kuo|first= Benjamin C. |year= 1967 |title=Automatic Control Systems |edition=2nd |publisher= Prentice-Hall |isbn= |doi= |pp=59–60}}&lt;/ref&gt;

:Exhibit (a) is a node.  In this case, the node is labeled &lt;math&gt;x&lt;/math&gt;. A node is a vertex representing a variable or signal. 
::A ''source'' node has only outgoing branches (represents an independent variable). As a special case, an ''input'' node is characterized by having one or more attached arrows pointing away from the node and &lt;u&gt;no&lt;/u&gt; arrows pointing into the node.  Any open, complete SFG will have at least one input node. 
::An ''output'' or ''sink'' node has only incoming branches (represents a dependent variable). Although any node can be an output, explicit output nodes are often used to provide clarity.  Explicit output nodes are characterized by having one or more attached arrows pointing into the node and &lt;u&gt;no&lt;/u&gt; arrows pointing away from the node.  Explicit output nodes are not required. 
::A ''mixed'' node has both incoming and outgoing branches.

:Exhibit (b) is a branch with a multiplicative gain of &lt;math&gt;m&lt;/math&gt;.  The meaning is that the output, at the tip of the arrow, is &lt;math&gt;m&lt;/math&gt; times the input at the tail of the arrow.  The gain can be a simple constant or a function (for example: a function of some transform variable such as &lt;math&gt;s&lt;/math&gt;, &lt;math&gt;\omega&lt;/math&gt;, or &lt;math&gt;z&lt;/math&gt;, for Laplace, Fourier or Z-transform relationships).

:Exhibit (c) is a branch with a multiplicative gain of one.  When the gain is omitted, it is assumed to be unity.

:Exhibit (d) &lt;math&gt;V_{in}&lt;/math&gt; is an input node.  In this case, &lt;math&gt;V_{in}&lt;/math&gt; is multiplied by the gain &lt;math&gt;m&lt;/math&gt;.

:Exhibit (e) &lt;math&gt;I_{out}&lt;/math&gt; is an explicit output node; the incoming edge has a gain of &lt;math&gt;m&lt;/math&gt;.
  
:Exhibit (f) depicts addition.  When two or more arrows point into a node, the signals carried by the edges are added.

:Exhibit (g) depicts a simple loop.  The loop gain is &lt;math&gt;A \times m&lt;/math&gt;.

:Exhibit (h) depicts the expression &lt;math&gt;Z =  aX + bY&lt;/math&gt;.

Terms used in linear SFG theory also include:&lt;ref name="Kuo, 2nd ed, p 59"/&gt;

*'''Path.''' A path is a continuous set of branches traversed in the direction indicated by the branch arrows. 
** '''Open path.''' If no node is re-visited, the path is open. 
** '''Forward path.''' A path from an input node (source) to an output node (sink) that does not re-visit any node.
*'''Path gain''': the product of the gains of all the branches in the path.
* '''Loop.''' A closed path. (it originates and ends on the same node, and no node is touched more than once).
*'''Loop gain''': the product of the gains of all the branches in the loop.
* '''Non-touching loops.''' Non-touching loops have no common nodes.
* '''Graph reduction.''' Removal of one or more nodes from a graph using graph transformations.
** '''Residual node.''' In any contemplated process of graph reduction, the nodes to be retained in the new graph are called residual nodes.&lt;ref name=Mason/&gt;
* '''Splitting a node.''' Splitting a node corresponds to splitting a node into two half nodes, one being a sink and the other a source.&lt;ref name=Robichaud2&gt;
{{cite book |title=Signal flow graphs and applications |author1=Louis PA Robichaud |author2=Maurice Boisvert |author3=Jean Robert |year=1962 |publisher=Prentice Hall |url=http://babel.hathitrust.org/cgi/pt?id=uc1.b4338380;view=1up;seq=8 |asin=B0000CLM1G |chapter = §1-4: Definitions and terminology |page=8}}
&lt;/ref&gt;
* '''Index''': The index of a graph is the minimum number of nodes which have to be split in order to remove all the loops in a graph.
** '''Index node.''' The nodes that are split to determine the index of a graph are called ''index'' nodes, and in general they are not unique.

=== Systematic reduction to sources and sinks ===
A signal-flow graph may be simplified by graph transformation rules.&lt;ref name= Abrahams&gt;
{{cite book |title=Signal Flow Analysis: The Commonwealth and International Library |author1=J. R. Abrahams |author2=G. P. Coverley |chapter=Chapter 2: Operations with a flow graph |pages=21 ''ff'' |url=https://books.google.com/books?id=C4ujBQAAQBAJ&amp;pg=PA21 |isbn=9781483180700 |year=2014 |publisher=Elsevier}}
&lt;/ref&gt;&lt;ref name=Horowitz&gt;
{{cite book |title=Synthesis of Feedback Systems |author=Isaac M. Horowitz |url=https://books.google.com/books?id=qykSBQAAQBAJ&amp;pg=PA18 |pages=18 ''ff'' |chapter=Reduction of signal-flow graphs |isbn=9781483267708 |year=2013 |publisher=Elsevier}}
&lt;/ref&gt;&lt;ref&gt;{{harv|Ogata|2002|pp=68, 106}}&lt;/ref&gt;  These simplification rules are also referred to as ''signal-flow graph algebra''.&lt;ref&gt;{{harv|Ogata|2002|pp=105, 106}}&lt;/ref&gt;
The purpose of this reduction is to relate the dependent variables of interest (residual nodes, sinks) to its independent variables (sources).

The systematic reduction of a linear signal-flow graph is a graphical method equivalent to the [[Gaussian elimination|Gauss-Jordan elimination]] method for solving linear equations.&lt;ref name="Henley 1973 12"&gt;{{harv|Henley|1973|p=12}}&lt;/ref&gt;

The rules presented below may be applied over and over until the signal flow graph is reduced to its "minimal residual form".  Further reduction can require loop elimination or the use of a "reduction formula" with the goal to directly connect sink nodes representing the dependent variables to the source nodes representing the independent variables. By these means, any signal-flow graph can be simplified by successively removing internal nodes until only the input and output and index nodes remain.&lt;ref&gt;{{harv|Phang|2001|p=37}}&lt;/ref&gt;&lt;ref&gt;Examples of the signal-flow graph reduction can be found in {{harv|Robichaud|1962|p=186, Sec. 7-3 Algebraic reduction of signal flow graphs}}&lt;/ref&gt; Robichaud described this process of systematic flow-graph reduction:

{{Quotation|The reduction of a graph proceeds by the elimination of certain nodes to obtain a residual graph showing only the variables of interest. This elimination of nodes is called "'''node absorption'''". This method is close to the familiar process of successive eliminations of undesired variables in a system of equations. One can eliminate a variable by removing the corresponding node in the graph. If one reduces the graph sufficiently, it is possible to obtain the solution for any variable and this is the objective which will be kept in mind in this description of the different methods of reduction of the graph. In practice, however, the techniques of reduction will be used solely to transform the graph to a residual graph expressing some fundamental relationships. Complete solutions will be more easily obtained by application of [[Mason's gain formula|Mason's rule]].&lt;ref name="Robichaud 1962 9–10, Sec. 1–5: Reduction of the flow graph"&gt;{{harv|Robichaud|1962|pp=9–10, Sec. 1–5: Reduction of the flow graph}}&lt;/ref&gt;

The graph itself programs the reduction process. Indeed a simple inspection of the graph readily suggests the different steps of the reduction which are carried out by elementary transformations, by loop elimination, or by the use of a reduction formula.&lt;ref name="Robichaud 1962 9–10, Sec. 1–5: Reduction of the flow graph"/&gt;|Robichaud|Signal flow graphs and applications, 1962}}

For digitally reducing a flow graph using an algorithm, Robichaud extends the notion of a simple flow graph to a ''generalized'' flow graph:
{{Quotation|Before describing the process of reduction...the correspondence between the graph and a system of linear equations ... must be generalized...''The generalized graphs will represent some operational relationships between groups of variables''...To each branch of the generalized graph is associated a matrix giving the relationships between the variables represented by the nodes at the extremities of that branch...&lt;ref&gt;{{harv|Robichaud|1962|pp=182, 183 Sec. 7-1, 7-2 of Chapter 7: Algebraic reduction of signal flow graphs using a digital computer}}&lt;/ref&gt;

The elementary transformations [defined by Robichaud in his Figure 7.2, p. 184] and the loop reduction permit the elimination of any node ''j'' of the graph by the ''reduction formula'':[described in Robichaud's Equation 7-1]. With the reduction formula, it is always possible to reduce a graph of any order... [After reduction] the final graph will be a cascade graph in which the variables of the sink nodes are explicitly expressed as functions of the sources. This is the only method for reducing the generalized graph since Mason's rule is obviously inapplicable.&lt;ref&gt;{{harv|Robichaud|1962|p=185, Sec. 7-2: Generalization of flow graphs}}&lt;/ref&gt;|Robichaud|Signal flow graphs and applications, 1962}}

The definition of an '''elementary transformation''' varies from author to author:
* Some authors only consider as elementary transformations the summation of parallel-edge gains and the multiplication of series-edge gains, but not the elimination of self-loops&lt;ref name="Henley 1973 12"/&gt;&lt;ref&gt;{{harv|Robichaud|1962|pp=9, Sec. 1–5 REDUCTION OF THE FLOW GRAPH}}&lt;/ref&gt;
* Other authors consider the elimination of a self-loop as an elementary transformation&lt;ref&gt;{{Cite book|title = Design of Analog Circuits Through Symbolic Analysis|last = Fakhfakh|first = Mourad|publisher = Bentham Science Publishers|year = 2012|isbn = 978-1-60805-425-1|location = |pages = 418|chapter = Section 4.1.2 Signal flow graphs algebra|last2 = Tlelo-Cuautle|first2 = Esteban|last3 = V. Fernández|first3 = Francisco|editor-last = Fakhfakh}}&lt;/ref&gt;

'''Parallel edges. '''Replace parallel edges with a single edge having a gain equal to the sum of original gains.{{br}}
[[File:Signal-Flow-Graph-Refactoring 01 parallel.svg|upright|Signal flow graph refactoring rule: replacing parallel edges with a single edge with a gain set to the sum of original gains.]]{{br}}
The graph on the left has parallel edges between nodes. On the right, these parallel edges have been replaced with a single edge having a gain equal to the sum of the gains on each original edge.{{br}}
The equations corresponding to the reduction between '''N''' and node '''I&lt;sub&gt;1&lt;/sub&gt;''' are:
:&lt;math&gt;\begin{align}
 N &amp;= I_\mathrm{1} f_\mathrm{1} + I_\mathrm{1}f_\mathrm{2} + I_\mathrm{1} f_\mathrm{3} + ...\\
 N &amp;= I_\mathrm{1} (f_\mathrm{1} +  f_\mathrm{2} +  f_\mathrm{3} ) + ...\\
\end{align}&lt;/math&gt;

'''Outflowing edges. '''Replace outflowing edges with edges directly flowing from the node's sources.{{br}}
[[File:Signal-Flow-Graph-Refactoring 03 outflowing.svg|upright|Signal flow graph refactoring rule: replacing outflowing edges with direct flows from inflowing sources.]]{{br}}
The graph on the left has an intermediate node '''N''' between nodes from which it has inflows, and nodes to which it flows out.
The graph on the right shows direct flows between these node sets, without transiting via '''N'''.
For the sake of simplicity, '''N''' and its inflows are not represented. The outflows from '''N''' are eliminated.{{br}}
The equations corresponding to the reduction directly relating '''N''''s input signals to its output signals are:
:&lt;math&gt;\begin{align}
 N &amp;= I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3} \\
 O_\mathrm{1} &amp;= g_\mathrm{1} N \\
 O_\mathrm{2} &amp;= g_\mathrm{2} N \\
 O_\mathrm{3} &amp;= g_\mathrm{3} N \\
 O_\mathrm{1} &amp;= g_\mathrm{1} (I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3}) \\
 O_\mathrm{2} &amp;= g_\mathrm{2} (I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3}) \\
 O_\mathrm{3} &amp;= g_\mathrm{3} (I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3}) \\
 O_\mathrm{1} &amp;= I_\mathrm{1} f_\mathrm{1}g_\mathrm{1} + I_\mathrm{2} f_\mathrm{2}g_\mathrm{1} + I_\mathrm{3} f_\mathrm{3}g_\mathrm{1} \\
 O_\mathrm{2} &amp;= I_\mathrm{1} f_\mathrm{1}g_\mathrm{2} + I_\mathrm{2} f_\mathrm{2}g_\mathrm{2} + I_\mathrm{3} f_\mathrm{3}g_\mathrm{2} \\
 O_\mathrm{3} &amp;= I_\mathrm{1} f_\mathrm{1}g_\mathrm{3} + I_\mathrm{2} f_\mathrm{2}g_\mathrm{3} + I_\mathrm{3} f_\mathrm{3}g_\mathrm{3} \\

\end{align}&lt;/math&gt;

'''Zero-signal nodes.'''
Eliminate outflowing edges from a node determined to have a value of zero.{{br}}
[[File:Signal-Flow-Graph-Refactoring 04 from zero-signal node.svg|upright|Signal flow graph refactoring rule: eliminating outflowing edges from a node known to have a value of zero.]]{{br}}
If the value of a node is zero, its outflowing edges can be eliminated.

'''Nodes without outflows.'''
Eliminate a node without outflows.{{br}}
[[File:Signal-Flow-Graph-Refactoring 05 don't care.svg|upright|Signal flow graph refactoring rule: a node that is not of interest can be eliminated provided that it has no outgoing edges.]]{{br}}
In this case, '''N''' is not a variable of interest, and it has no outgoing edges; therefore, '''N''', and its inflowing edges, can be eliminated.

'''Self-looping edge. '''Replace looping edges by adjusting the gains on the incoming edges.{{br}}
[[File:Signal-Flow-Graph-Refactoring 02 self-loop.svg|upright|Signal flow graph refactoring rule: a looping edge at node N is eliminated and inflow gains are multiplied by an adjustment factor.]]{{br}}The graph on the left has a looping edge at node '''N''', with a gain of  '''g'''. On the right, the looping edge has been eliminated, and all inflowing edges have their gain divided by '''(1-g)'''.{{br}}The equations corresponding to the reduction between '''N''' and all its input signals are:
:&lt;math&gt;\begin{align}
 N &amp;= I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3} + N  g \\
 N  - N  g &amp;= I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3}f_\mathrm{3} \\
 N (1-g) &amp;= I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3} \\
 N  &amp;= (I_\mathrm{1} f_\mathrm{1} + I_\mathrm{2} f_\mathrm{2} + I_\mathrm{3} f_\mathrm{3}) \div  (1-g) \\
 N  &amp;= I_\mathrm{1} f_\mathrm{1}\div  (1-g) + I_\mathrm{2} f_\mathrm{2}\div  (1-g) + I_\mathrm{3} f_\mathrm{3} \div  (1-g) \\
\end{align}&lt;/math&gt;

==== Implementations ====
The above procedure for building the SFG from an acausal system of equations and for solving the SFG's gains have been implemented&lt;ref&gt;Labrèche P., [https://www.researchgate.net/publication/266391592_1977_Labreche_-_LINEAR_ELECTRICAL_CIRCUITS_SYMBOLIC_NETWORK_ANALYSIS presentation: Linear Electrical Circuits:Symbolic Network Analysis], 1977.&lt;/ref&gt; as an add-on to [[MATHLAB 68]],&lt;ref&gt;Carl Engelman, '''The legacy of MATHLAB 68''', published in Proceeding SYMSAC '71 Proceedings of the second ACM symposium on Symbolic and algebraic manipulation, pages 29-41  [http://dl.acm.org/citation.cfm?id=806265]&lt;/ref&gt; an on-line [[Computer algebra system|system providing machine aid for the mechanical symbolic processes encountered in analysis]].

=== Solving linear equations ===

Signal flow graphs can be used to solve sets of simultaneous linear equations.&lt;ref name="Deo page 416"&gt;"... solving a set of simultaneous, linear algebraic equations.  This problem, usually solved by matrix methods, can also be solved via graph theory. " {{cite book| last=Deo|first= Narsingh | year= 1974|title=Graph Theory with Applications to Engineering and Computer Science |edition= |publisher= Prentice-Hall of India |isbn= 81-203-0145-5 | p=416}} also on-line at [https://books.google.com/books?id=Yr2pJA950iAC&amp;pg=PA417&amp;dq=%22THe+signal-flow+graph+representing+Eqs.+%2815-2%29%22&amp;hl=en&amp;sa=X&amp;ei=z1iwVNXZFs3WoASYj4D4DQ&amp;ved=0CB8Q6AEwAA#v=onepage&amp;q=%22THe%20signal-flow%20graph%20representing%20Eqs.%20(15-2)%22&amp;f=false]&lt;/ref&gt; The set of equations must be consistent and all equations must be linearly independent.

==== Putting the equations in "standard form" ====
[[File:Flow graph for three linear equations.png|300px|thumb|Flow graph for three simultaneous equations. The edges incident on each node are colored differently just for emphasis. Rotating the figure by 120° simply permutes the indices.
&lt;math&gt;x_1= \left( c_{11} +1 \right) x_1 +c_{12} x_2 +c_{13} x_3 - y_1 \ ,&lt;/math&gt;
&lt;math&gt;x_2= c_{21} x_1 +\left( c_{22} +1 \right) x_2 +c_{23} x_3 - y_2 \ ,&lt;/math&gt;
&lt;math&gt;x_3= c_{31} x_1 +c_{32} x_2 + \left( c_{33} +1 \right) x_3 - y_3 \ .&lt;/math&gt;
]]
For M equations with N unknowns where each y&lt;sub&gt;j&lt;/sub&gt; is a known value and each x&lt;sub&gt;j&lt;/sub&gt; is an unknown value, there is equation for each known of the following form.
:&lt;math&gt;\begin{align}
\sum_{\mathrm{k}=1}^\mathrm{N} c_\mathrm{jk} x_\mathrm{k}  &amp;=  y_\mathrm{j} 
\end{align}&lt;/math&gt; ; the usual form for simultaneous linear equations with 1 ≤ j ≤ M

Although it is feasible, particularly for simple cases, to establish a signal flow graph using the equations in this form, some rearrangement allows a general procedure that works easily for any set of equations, as now is presented. To proceed, first the equations are rewritten as

:&lt;math&gt;\begin{align}
\sum_{\mathrm{k}=1}^{\mathrm{N}} c_{\mathrm{jk}} x_\mathrm{k}  -  y_\mathrm{j} &amp;= 0 \end{align} &lt;/math&gt;

and further rewritten as
:&lt;math&gt;\begin{align}
\sum_\mathrm{k=1}^\mathrm{N} c_\mathrm{jk} x_\mathrm{k} +x_\mathrm{j}  -  y_\mathrm{j} &amp;= x_\mathrm{j} \end{align} &lt;/math&gt;

and finally rewritten as 
:&lt;math&gt;\begin{align}
\sum_\mathrm{k=1}^\mathrm{N} ( c_\mathrm{jk} + \delta_\mathrm{jk}) x_\mathrm{k} -  y_\mathrm{j} &amp;= x_\mathrm{j} \end{align} &lt;/math&gt;   ; form suitable to be expressed as a signal flow graph.

::where δ&lt;sub&gt;kj&lt;/sub&gt; = [[Kronecker delta]]

The signal-flow graph is now arranged by selecting one of these equations and addressing the node on the right-hand side. This is the node for which the node connects to itself with the branch of weight including a '+1', making a ''self-loop'' in the flow graph. The other terms in that equation connect this node first to the source in this equation and then to all the other branches incident on this node. Every equation is treated this way, and then each incident branch is joined to its respective emanating node. For example, the case of three variables is shown in the figure, and the first equation is:
:&lt;math&gt;x_1= \left( c_{11} +1 \right) x_1 +c_{12} x_2 +c_{13} x_3 - y_1 \ , &lt;/math&gt;

where the right side of this equation is the sum of the weighted arrows incident on node ''x&lt;sub&gt;1&lt;/sub&gt;''.

As there is a basic symmetry in the treatment of every node, a simple starting point is an arrangement of nodes with each node at one vertex of a regular polygon. When expressed using the general coefficients {''c&lt;sub&gt;in&lt;/sub&gt;''}, the environment of each node is then just like all the rest apart from a permutation of indices. Such an implementation for a set of three simultaneous equations is seen in the figure.&lt;ref name="Deo page 417"&gt;{{cite book| last=Deo|first= Narsingh | year= 1974|title=Graph Theory with Applications to Engineering and Computer Science |edition= |publisher= Prentice-Hall of India |isbn= 81-203-0145-5 | p=417}} also on-line at [https://books.google.com/books?id=Yr2pJA950iAC&amp;pg=PA417&amp;dq=%22THe+signal-flow+graph+representing+Eqs.+%2815-2%29%22&amp;hl=en&amp;sa=X&amp;ei=z1iwVNXZFs3WoASYj4D4DQ&amp;ved=0CB8Q6AEwAA#v=onepage&amp;q=%22THe%20signal-flow%20graph%20representing%20Eqs.%20(15-2)%22&amp;f=false]&lt;/ref&gt;

Often the known values, y&lt;sub&gt;j&lt;/sub&gt; are taken as the primary causes and the unknowns values, x&lt;sub&gt;j&lt;/sub&gt; to be effects, but regardless of this interpretation, the last form for the set of equations can be represented as a signal-flow graph. This point is discussed further in the subsection [[#Interpreting 'causality'|Interpreting 'causality']].

==== Applying Mason's gain formula ====
{{details|Mason's gain formula}}
In the most general case, the values for all the x&lt;sub&gt;k&lt;/sub&gt; variables can be calculated by computing Mason's gain formula for the path from each y&lt;sub&gt;j&lt;/sub&gt; to each x&lt;sub&gt;k&lt;/sub&gt; and using superposition.
:&lt;math&gt;\begin{align} x_\mathrm{k} &amp;=  \sum_{\mathrm{j}=1}^{\mathrm{M}} ( G_\mathrm{kj} ) y_\mathrm{j}  \end{align} &lt;/math&gt;

::where G&lt;sub&gt;kj&lt;/sub&gt; = the sum of Mason's gain formula computed for all the paths from input y&lt;sub&gt;j&lt;/sub&gt; to variable x&lt;sub&gt;k&lt;/sub&gt;.

In general, there are N-1 paths from y&lt;sub&gt;j&lt;/sub&gt; to variable x&lt;sub&gt;k&lt;/sub&gt; so the computational effort to calculated G&lt;sub&gt;kj&lt;/sub&gt; is proportional to N-1.
Since there are M values of y&lt;sub&gt;j&lt;/sub&gt;, G&lt;sub&gt;kj&lt;/sub&gt; must be computed M times for a single value of x&lt;sub&gt;k&lt;/sub&gt;.  The computational effort to calculate a single x&lt;sub&gt;k&lt;/sub&gt; variable is proportional to (N-1)(M).  The effort to compute all the x&lt;sub&gt;k&lt;/sub&gt; variables is proportional to (N)(N-1)(M).  If there are N equations and N unknowns, then the computation effort is on the order of N&lt;sup&gt;3&lt;/sup&gt;.

== Relation to block diagrams ==
[[File:Block-diagram Signal-flow graph.svg|thumb|upright=1.5|Example: Block diagram and two equivalent signal-flow graph representations.]]

For some authors, a linear signal-flow graph is more constrained than a [[block diagram]],&lt;ref name="Kuo, 6th ed, p77"&gt;
"A signal flow graph may be regarded as a simplified version of a block diagram. ... for cause and effect ... of linear systems ...we may regard the signal-flow graphs to be constrained by more rigid mathematical rules, whereas the usage of the block-diagram notation is less stringent." {{cite book| last=Kuo|first= Benjamin C. | year= 1991|title=Automatic Control Systems |edition=6th |publisher= Prentice-Hall |isbn= 0-13-051046-7 | p=77}}&lt;/ref&gt; in that the SFG rigorously describes linear algebraic equations represented by a directed graph.

For other authors, linear block diagrams and linear signal-flow graphs are equivalent ways of depicting a system, and either can be used to solve the gain.&lt;ref name=Franklin&gt;
{{cite book |title=Feedback Control of Dynamic Systems|author= Gene F. Franklin|chapter= Appendix W.3 Block Diagram Reduction|page= |isbn= |date= Apr 29, 2014 |publisher= Prentice Hall|url=|display-authors=etal}}
&lt;/ref&gt;

A tabulation of the comparison between block diagrams and signal-flow graphs is provided by Bakshi &amp; Bakshi,&lt;ref name=Bakshi&gt;
{{cite book |title=Control Engineering |author=V.U.Bakshi U.A.Bakshi |chapter=Table 5.6: Comparison of block diagram and signal flow graph methods |page=120 |isbn=9788184312935 |year=2007 |publisher=Technical Publications |url=https://books.google.com/books?id=MRPJlb9MSuIC&amp;pg=PA120}}
&lt;/ref&gt; and another tabulation by Kumar.&lt;ref name=Kumar&gt;
{{cite book |title=Control Systems |author= A Anand Kumar |url=https://books.google.com/books?id=sJBeBAAAQBAJ&amp;pg=PA165 |page=165 |chapter=Table: Comparison of block diagram and signal flow methods |isbn=9788120349391 |year=2014 |edition=2nd |publisher=PHI Learning Pvt. Ltd}}
&lt;/ref&gt;  According to Barker ''et al.'':&lt;ref name=Barker&gt;
{{cite book |chapter=Algorithms for transformations between block diagrams and digital flow graphs |author1=HA Barker |author2=M Chen |author3=P. Townsend |url=https://books.google.com/books?id=I9bSBQAAQBAJ&amp;pg=PA281  |pages=281 ''ff'' |title= Computer Aided Design in Control Systems 1988: Selected Papers from the 4th IFAC Symposium, Beijing, PRC, 23-25, August 1988 |publisher=Elsevier |year=2014}}
&lt;/ref&gt;
:"The signal flow graph is the most convenient method for representing a dynamic system. The topology of the graph is compact and the rules for manipulating it are easier to program than the corresponding rules that apply to block diagrams."

In the figure, a simple block diagram for a [[feedback]] system is shown with two possible interpretations as a signal-flow graph. The input ''R(s)'' is the Laplace-transformed input signal; it is shown as a source node in the signal-flow graph (a source node has no input edges). The output signal ''C(s)'' is the Laplace-transformed output variable. It is represented as a sink node in the flow diagram (a sink has no output edges). ''G(s)'' and ''H(s)'' are transfer functions, with ''H(s)'' serving to feed back a modified version of the output to the input, ''B(s)''. The two flow graph representations are equivalent.

== Interpreting 'causality' ==
The term "cause and effect" was applied by Mason to SFGs:&lt;ref name=Mason/&gt; 
:"The process of constructing a graph is one of tracing a succession of cause and effects through the physical system. One variable is expressed as an explicit effect due to certain causes; they in turn, are recognized as effects due to still other causes." 
:::— S.J. Mason: Section IV: ''Illustrative applications of flow graph technique''

and has been repeated by many later authors:&lt;ref name=Mutambara&gt;
For example, see {{cite book |author= Arthur G.O. Mutambara |title=Design and Analysis of Control Systems |url=https://books.google.com/books?id=VSlHxALK6OoC&amp;pg=PA238 |page=238 |publisher=CRC Press |year=1999 |isbn=9780849318986}}
&lt;/ref&gt;
:"The ''signal flow graph'' is another visual tool for representing causal relationships between components of the system. It is a simplified version of a block diagram introduced by S.J. Mason as a cause-and-effect representation of linear systems." 
:::— Arthur G.O. Mutambara: ''Design and Analysis of Control Systems'', p.238

However, Mason's paper is concerned to show in great detail how a ''set of equations'' is connected to an SFG, an emphasis unrelated to intuitive notions of "cause and effect". Intuitions can be helpful for arriving at an SFG or for gaining insight from an SFG, but are inessential to the SFG. The essential connection of the SFG is to its own set of equations, as described, for example, by Ogata:&lt;ref name=OgataK&gt;
{{cite book |title=Modern Control Engineering |author=Katsuhiko Ogata |page =104 |chapter=Signal flow graphs |edition=4th |publisher=Prentice Hall |year=1997 |isbn=0130432458 |url=https://books.google.com/books?id=pdtRBgAAQBAJ&amp;pg=PA104}}
&lt;/ref&gt;
:"A signal-flow graph is a diagram that represents a set of simultaneous algebraic equations. When applying the signal flow graph method to analysis of control systems, we must first transform linear differential equations into algebraic equations in [the [[Laplace transform]] variable] ''s''.." 
:::— Katsuhiko Ogata: ''Modern Control Engineering'', p. 104

There is no reference to "cause and effect" here, and as said by Barutsky:&lt;ref name=Barutsky&gt;
{{cite book |title=Bond Graph Methodology: Development and Analysis of Multidisciplinary Dynamic System Models |author=Wolfgang Borutzky |url=https://books.google.com/books?id=TUlPJ5M7jIUC&amp;pg=PA10#v=onepage&amp;q&amp;f=false |isbn=9781848828827 |year=2009 |publisher=Springer Science &amp; Business Media |page=10}}
&lt;/ref&gt;
:"Like block diagrams, signal flow graphs represent the computational, not the physical structure of a system."  
:::— Wolfgang Borutzky, ''Bond Graph Methodology'', p. 10

The term "cause and effect" may be misinterpreted as it applies to the SFG, and taken incorrectly to suggest a system view of causality,&lt;ref name=Callahan&gt;
{{cite book |title=The Geometry of Spacetime: An Introduction to Special and General Relativity |author=James J. Callahan |url=https://books.google.com/books?id=UMDurS6HSl4C&amp;pg=PA76&amp;dq=%22The+causal+past+of+%22+%22The+causal+future+of+an+event+%22&amp;hl=en&amp;sa=X&amp;ei=Lx7qVLOHHYufoQS2qoL4Dg&amp;ved=0CB8Q6AEwAA#v=onepage&amp;q=%22The%20causal%20past%20of%20%22%20%22The%20causal%20future%20of%20an%20event%20%22&amp;f=false |chapter=Causality: Definition 2.10  |isbn=9780387986418 |year=2000 |publisher= Springer Science &amp; Business Media |page=76}}
&lt;/ref&gt; rather than a ''computationally'' based meaning. To keep discussion clear, it may be advisable to use the term "computational causality",  as is suggested for [[bond graphs]]:&lt;ref name=Vichnevetsky&gt;
{{cite book |title=IMACS '91, Proceedings of the 13th IMACS World Congress on Computation and Applied Mathematics: July 22-26, 1991, Trinity College, Dublin, Ireland |author1=John JH Miller |author2=Robert Vichnevetsky |editor1=John JH Miller |editor2=Robert Vichnevetsky |date=July 22–26, 1991 |publisher=International Association for Mathematics and Computers in Simulation |url=https://www.google.com/search?tbo=p&amp;tbm=bks&amp;q=%22Bond-graph+literature+uses+the+term+computational+causality,+indicating+the+order+of+calculation+in+a+simulation,+in+order+to+avoid+any+interpretation+in+the+sense+of+intuitive+causality.+%22&amp;num=10&amp;gws_rd=ssl}} 
&lt;/ref&gt;
:"Bond-graph literature uses the term computational causality, indicating the order of calculation in a simulation, in order to avoid any interpretation in the sense of intuitive causality."

The term "computational causality" is explained using the example of current and voltage in a resistor:&lt;ref name=Cellier&gt;
{{cite book |title= Continuous System Simulation |author1=François E. Cellier |author2=Ernesto Kofman |url=https://www.google.com/search?tbo=p&amp;tbm=bks&amp;q=%22physical+laws+can+therefor+not+be+predetermined%22&amp;num=10&amp;gws_rd=ssl#tbm=bks&amp;q=%22physical+laws+can+therefore+not+be+predetermined%22 |year=2006 |page=15 |isbn=9780387261027 |publisher=Springer Science &amp;  Business Media}}
&lt;/ref&gt;
:"The ''computational causality'' of physical laws can therefore not be predetermined, but depends upon the particular use of that law. We cannot conclude whether it is the current flowing through a resistor that causes a voltage drop, or whether it is the difference in potentials at the two ends of the resistor that cause current to flow. Physically these are simply two concurrent aspects of one and the same physical phenomenon. Computationally, we may have to assume at times one position, and at other times the other."  
:::— François Cellier &amp; Ernesto Kofman: §1.5 ''Simulation software today and tomorrow'', p. 15

A computer program or algorithm can be arranged to solve a set of equations using various strategies. They differ in how they prioritize finding some of the variables in terms of the others, and these algorithmic decisions, which are simply about solution strategy, then set up the variables expressed as dependent variables earlier in the solution to be "effects", determined by the remaining variables that now are "causes", in the sense of "computational causality".

Using this terminology, it is ''computational'' causality, not ''system'' causality, that is relevant to the SFG. There exists a wide-ranging philosophical debate, not concerned specifically with the SFG, over connections between computational causality and system causality.&lt;ref name= Lewandowsky&gt;See, for example, {{cite book |title=Computational Modeling in Cognition: Principles and Practice |author1=Stephan Lewandowsky |author2=Simon Farrell |url=https://books.google.com/books?id=Jva6smQTUW4C&amp;printsec=frontcover |isbn=9781452236193 |year=2010 |publisher=SAGE Publications}} 
&lt;/ref&gt;

== Signal-flow graphs for analysis and design ==

Signal-flow graphs can be used for analysis, that is for understanding a model of an existing system, or for synthesis, that is for determining the properties of a design alternative.

=== Signal-flow graphs for dynamic systems analysis ===
When building a model of a dynamic system, a list of steps is provided by Dorf &amp; Bishop:&lt;ref&gt;{{cite book|title = Modern Control Systems|last = Dorf|first = Richard C.|publisher = Prentice Hall|year = 2001|isbn = 0-13-030660-6|location = |chapter = Chap 2.-1: Introduction |page=2 |last2 = Bishop,|first2 = Robert H.|url = https://www.site.uottawa.ca/~rhabash/ELG4152LN02.pdf}}&lt;/ref&gt;
* Define the system and its components.
* Formulate the mathematical model and list the needed assumptions.
* Write the differential equations describing the model.
* Solve the equations for the desired output variables.
* Examine the solutions and the assumptions.
* If needed, reanalyze or redesign the system.
::—RC Dorf and RH Bishop, ''Modern Control Systems'', Chapter 2, p. 2 
In this workflow, equations of the physical system's mathematical model are used to derive the signal-flow graph equations.

=== Signal-flow graphs for design synthesis ===
Signal-flow graphs have been used in [[Design Space Exploration|Design Space Exploration (DSE)]], as an intermediate representation towards a physical implementation.  The DSE process seeks a suitable solution among different alternatives. In contrast with the typical analysis workflow, where a system of interest is first modeled with the physical equations of its components, the specification for synthesizing a design could be a desired transfer function. For example, different strategies would create different signal-flow graphs, from which implementations are derived.&lt;ref&gt;{{Cite journal|url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=386223|title = ARCHGEN: Automated synthesis of analog systems|last = Antao|first = B. A. A.|date = June 1995|journal = Very Large Scale Integration (VLSI) Systems, IEEE Transactions on|doi = 10.1109/92.386223|pmid = |access-date = |volume = 3|issue = 2|pages = 231–244|last2 = Brodersen|first2 = A.J.}}&lt;/ref&gt;
Another example uses an annotated SFG as an expression of the continuous-time behavior, as input to an architecture generator&lt;ref&gt;{{Cite journal|url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=856026|title = A heuristic technique for system-level architecture generation from signal-flow graph representations of analog systems|last = Doboli|first = A.|date = May 2000|doi = 10.1109/ISCAS.2000.856026|pmid = |access-date = |series = Circuits and Systems, 2000. Proceedings. ISCAS 2000 Geneva. The 2000 IEEE International Symposium on|last2 = Dhanwada|first2 = N.|last3 = Vemuri|first3 = R.}}&lt;/ref&gt;

== Shannon and Shannon-Happ formulas ==
Shannon's formula is an analytic expression for calculating the gain of an interconnected set of amplifiers in an analog computer.  During World War II, while investigating the functional operation of an analog computer, Claude Shannon developed his formula.  Because of wartime restrictions, Shannon's work was not published at that time, and, in 1952, [[Samuel Jefferson Mason|Mason]] rediscovered the same formula.

Happ generalized the Shannon formula for topologically closed systems.&lt;ref name=Happ66&gt;{{Cite journal|url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4501761|title = Flowgraph Techniques for Closed Systems|last = Happ|first = William W.|date = 1966|journal = IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS|doi = 10.1109/TAES.1966.4501761|pmid = |access-date = 2015-01-27|pages = 252–264|volume=AES-2}}&lt;/ref&gt; The Shannon-Happ formula can be used for deriving transfer functions, sensitivities, and error functions.&lt;ref name=Potash /&gt;

For a consistent set of linear unilateral relations, the Shannon-Happ formula expresses the solution using direct substitution (non-iterative).&lt;ref name=Potash&gt;{{cite journal |title =Application of unilateral and graph techniques to analysis of linear circuits: Solution by non-iterative methods|last =Potash|first = Hanan|first2 = Lawrence P.|last2 = McNamee|publisher = ACM|year =1968 |journal=Proceedings, ACM National Conference|isbn = |location = University of California Los Angeles, California|pages=367–378 |url =https://www.deepdyve.com/lp/association-for-computing-machinery/application-of-unilateral-and-graph-techniques-to-analysis-of-linear-b8r753Bq03  |doi=10.1145/800186.810601}}&lt;/ref&gt;&lt;ref name=NASAP-70&gt;{{Cite book|title = NASAP-70 User's and Programmer's manual|last = Okrent|first = Howard|publisher = School of Engineering and Applied Science, University of California at Los Angeles|year = 1970|isbn = |location = Los Angeles, California|pages = 3–9|first2 = Lawrence P.|last2 = McNamee|url = https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19710025849.pdf|chapter = 3. 3 Flowgraph Theory}}&lt;/ref&gt;

NASA's electrical circuit software NASAP is based on the Shannon-Happ formula.&lt;ref name=Potash /&gt;&lt;ref name=NASAP-70 /&gt;

== Linear signal-flow graph examples ==

===Simple voltage amplifier===
[[File:Sfg simple amplifier.svg|thumbnail|upright=1.0|Figure 1: SFG of a simple amplifier]]
The amplification of a signal ''V&lt;sub&gt;1&lt;/sub&gt;'' by an amplifier with gain ''a&lt;sub&gt;12&lt;/sub&gt;'' is described mathematically by

::&lt;math&gt;V_2 = a_{12}V_1 \,.&lt;/math&gt;

This relationship represented by the signal-flow graph of Figure 1. is that V&lt;sub&gt;2&lt;/sub&gt; is dependent on V&lt;sub&gt;1&lt;/sub&gt; but it implies no dependency of V&lt;sub&gt;1&lt;/sub&gt; on V&lt;sub&gt;2&lt;/sub&gt;.  See Kou page 57.&lt;ref&gt;{{Harvtxt|Kou|1967|p=57}}&lt;/ref&gt;

=== Ideal negative feedback amplifier ===
[[File:Modified SFG for feedback amplifier.PNG|thumbnail| thumb|upright=1.0|Figure 3: A possible signal-flow graph for the [[asymptotic gain model]]]]
[[File:Control parameter.PNG|thumbnail| thumb|upright=1.0|Figure 4: A different signal-flow graph for the [[asymptotic gain model]] ]]
[[File:Signal flow graph for feedback amplifier.png|thumb|upright=1.0 |A signal flow graph for a nonideal [[negative feedback amplifier]] based upon a control variable ''P'' relating two internal variables: ''x&lt;sub&gt;j&lt;/sub&gt;=Px&lt;sub&gt;i&lt;/sub&gt;''. Patterned after D.Amico ''et al.''&lt;ref name=Damico&gt;
{{cite journal |title=Resistance of Feedback Amplifiers: A novel representation |author=Arnaldo D’Amico, Christian Falconi, Gianluca Giustolisi, Gaetano Palumbo |journal=IEEE Trans Circuits &amp; Systems - II Express Briefs |url=http://piezonanodevices.uniroma2.it/wp-content/uploads/2013/04/Rosenstark.pdf |date=April 2007 |volume=54 |issue=4 |pages=298 ''ff'' |doi=10.1109/tcsii.2006.889713}}
&lt;/ref&gt;]]
A possible SFG for the [[asymptotic gain model]] for a [[negative feedback amplifier]] is shown in Figure 3, and leads to the equation for the gain of this amplifier as

:&lt;math&gt;G = \frac {y_2}{x_1}&lt;/math&gt; &lt;math&gt; = G_{\infty} \left( \frac{T}{T + 1} \right) + G_0 \left( \frac{1}{T + 1} \right) \ .&lt;/math&gt;

The interpretation of the parameters is as follows: ''T'' = [[return ratio]], ''G&lt;sub&gt;&amp;infin;&lt;/sub&gt;'' = direct amplifier gain, ''G&lt;sub&gt;0&lt;/sub&gt;'' = feedforward (indicating the possible [[Electronic amplifier#Unilateral or bilateral|bilateral]] nature of the feedback, possibly deliberate as in the case of feedforward [[Lead-lag compensator|compensation]]). Figure 3 has the interesting aspect that it resembles Figure 2 for the two-port network with the addition of the extra ''feedback relation'' ''x&lt;sub&gt;2&lt;/sub&gt; =  T y&lt;sub&gt;1&lt;/sub&gt;''.

From this gain expression an interpretation of the parameters ''G&lt;sub&gt;0&lt;/sub&gt;'' and ''G&lt;sub&gt;&amp;infin;&lt;/sub&gt;'' is evident, namely:

:&lt;math&gt;G_{\infty} = \lim_{T \to \infty }G\ ; \ G_{0} = \lim_{T \to 0 }G \ . &lt;/math&gt;

There are many possible SFG's associated with any particular gain relation. Figure 4 shows another SFG for the asymptotic gain model that can be easier to interpret in terms of a circuit. In this graph, parameter  β is interpreted as a feedback factor and ''A'' as a "control parameter", possibly related to a dependent source in the circuit. Using this graph, the gain is

:&lt;math&gt;G = \frac {y_2}{x_1}&lt;/math&gt; &lt;math&gt; = G_{0} +  \frac {A} {1 - \beta A} \ .&lt;/math&gt;

To connect to the asymptotic gain model, parameters ''A'' and β cannot be arbitrary circuit parameters, but must relate to the return ratio ''T'' by:

:&lt;math&gt; T = - \beta A \ , &lt;/math&gt;

and to the asymptotic gain as:

:&lt;math&gt; G_{\infty} = \lim_{T \to \infty }G = G_0 - \frac {1} {\beta} \ .&lt;/math&gt;

Substituting these results into the gain expression,

:&lt;math&gt;G =  G_{0} + \frac {1} {\beta} \frac {-T} {1 +T} &lt;/math&gt;
::&lt;math&gt; = G_0 + (G_0 - G_{\infty} ) \frac {-T} {1 +T} &lt;/math&gt;
::&lt;math&gt; = G_{\infty} \frac {T} {1 +T} + G_0 \frac {1}{1+T}  \ ,&lt;/math&gt;

which is the formula of the asymptotic gain model.

===Electrical circuit containing a two-port network===
[[File:Circuit with two port and equivalent signal flow graph.png|lrft|thumb|400px|alt=A simple schematic containing a two-port and it's equivalent signal flow graph. | Signal flow graph of a circuit containing a two port.  The forward path from input to output is shown in a different color.  The dotted line rectangle encloses the portion of the SFG that constitutes the two-port.]]

The figure to the right depicts a circuit that contains a [[Two-port network#Admittance parameters .28y-parameters.29|''y''-parameter two-port network]]. V&lt;sub&gt;in&lt;/sub&gt; is the input of the circuit and V&lt;sub&gt;2&lt;/sub&gt; is the output.  The two-port equations impose a set of linear constraints between its port voltages and currents.  The terminal equations impose other constraints.  All these constraints are represented in the SFG (Signal Flow Graph) below the circuit.  There is only one path from input to output which is shown in a different color and has a (voltage) gain of -R&lt;sub&gt;L&lt;/sub&gt;y&lt;sub&gt;21&lt;/sub&gt;.  There are also three loops: -R&lt;sub&gt;in&lt;/sub&gt;y&lt;sub&gt;11&lt;/sub&gt;, -R&lt;sub&gt;L&lt;/sub&gt;y&lt;sub&gt;22&lt;/sub&gt;, R&lt;sub&gt;in&lt;/sub&gt;y&lt;sub&gt;21&lt;/sub&gt;R&lt;sub&gt;L&lt;/sub&gt;y&lt;sub&gt;12&lt;/sub&gt;. Sometimes a loop indicates intentional feedback but it can also indicate a constraint on the relationship of two variables.  For example, the equation that describes a resistor says that the ratio of the voltage across the resistor to the current through the resistor is a constant which is called the resistance.  This can be interpreted as the voltage is the input and the current is the output, or the current is the input and the voltage is the output, or merely that the voltage and current have a linear relationship.  Virtually all passive two terminal devices in a circuit will show up in the SFG as a loop.

The SFG and the schematic depict the same circuit, but the schematic also suggests the circuit's purpose.  Compared to the schematic, the SFG is awkward but it does have the advantage that the input to output gain can be written down by inspection using [[Mason's rule]].

=== Mechatronics :  Position servo with multi-loop feedback ===
[[File:Position servo and signal flow graph.png|right|alt=A depiction of a telescope controller and its signal flow graph|thumb|800px| Angular position servo and signal flow graph.  θ&lt;sub&gt;C&lt;/sub&gt; = desired angle command, θ&lt;sub&gt;L&lt;/sub&gt; = actual load angle, K&lt;sub&gt;P&lt;/sub&gt; = position loop gain, V&lt;sub&gt;ωC&lt;/sub&gt; = velocity command, V&lt;sub&gt;ωM&lt;/sub&gt; = motor velocity sense voltage, K&lt;sub&gt;V&lt;/sub&gt; = velocity loop gain, V&lt;sub&gt;IC&lt;/sub&gt; = current command, V&lt;sub&gt;IM&lt;/sub&gt; = current sense voltage, K&lt;sub&gt;C&lt;/sub&gt; = current loop gain, V&lt;sub&gt;A&lt;/sub&gt; = power amplifier output voltage, L&lt;sub&gt;M&lt;/sub&gt; = motor inductance, V&lt;sub&gt;M&lt;/sub&gt; = voltage across motor inductance, I&lt;sub&gt;M&lt;/sub&gt; = motor current, R&lt;sub&gt;M&lt;/sub&gt; = motor resistance, R&lt;sub&gt;S&lt;/sub&gt; = current sense resistance, K&lt;sub&gt;M&lt;/sub&gt; = motor torque constant (Nm/amp), T = torque, M = moment of inertia of all rotating components α = angular acceleration, ω = angular velocity, β = mechanical damping, G&lt;sub&gt;M&lt;/sub&gt; = motor back EMF constant, G&lt;sub&gt;T&lt;/sub&gt; = tachometer conversion gain constant,.  There is one forward path (shown in a different color) and six feedback loops.  The drive shaft assumed to be stiff enough to not treat as a spring.  Constants are shown in black and variables in purple.]]

This example is representative of a SFG (signal-flow graph) used to represent a servo control system and illustrates several features of SFGs.  Some of the loops (loop 3, loop 4 and loop 5) are extrinsic intentionally designed feedback loops.  These are shown with dotted lines.  There are also intrinsic loops (loop 0, loop1, loop2) that are not intentional feedback loops, although they can be analyzed as though they were.  These loops are shown with solid lines.  Loop 3 and loop 4 are also known as minor loops because they are inside a larger loop.

*The forward path begins with '''θ'''&lt;sub&gt;C&lt;/sub&gt;, the desired position command.  This is multiplied by K&lt;sub&gt;P&lt;/sub&gt; which could be a constant or a function of frequency.  K&lt;sub&gt;P&lt;/sub&gt; incorporates the conversion gain of the DAC and any filtering on the DAC output.  The output of K&lt;sub&gt;P&lt;/sub&gt; is the velocity command '''V'''&lt;sub&gt;ωC&lt;/sub&gt; which is multiplied by K&lt;sub&gt;V&lt;/sub&gt; which can be a constant or a function of frequency.  The output of K&lt;sub&gt;V&lt;/sub&gt; is the current command, '''V'''&lt;sub&gt;IC&lt;/sub&gt; which is multiplied by K&lt;sub&gt;C&lt;/sub&gt; which can be a constant or a function of frequency.  The output of K&lt;sub&gt;C&lt;/sub&gt; is the amplifier output voltage, '''V'''&lt;sub&gt;A&lt;/sub&gt;. The current, '''I'''&lt;sub&gt;M&lt;/sub&gt;, though the motor winding is the integral of the voltage applied to the inductance.  The motor produces a torque, '''T''', proportional to '''I'''&lt;sub&gt;M&lt;/sub&gt;.  Permanent magnet motors tend to have a linear current to torque function.  The conversion constant of current to torque is K&lt;sub&gt;M&lt;/sub&gt;.  The torque, '''T''', divided by the load moment of inertia, M, is the acceleration, '''α''', which is integrated to give the load velocity '''ω''' which is integrated to produce the load position, '''θ'''&lt;sub&gt;LC&lt;/sub&gt;.
*The forward path of loop 0 asserts that acceleration is proportional to torque and the velocity is the time integral of acceleration.  The backward path says that as the speed increases there is a friction or drag that counteracts the torque.  Torque on the load decreases proportionately to the load velocity until the point is reached that all the torque is used to overcome friction and the acceleration drops to zero. Loop 0 is intrinsic.
*Loop1 represents the interaction of an inductor's current with its internal and external series resistance.  The current through an inductance is the time integral of the voltage across the inductance.  When a voltage is first applied, all of it appears across the inductor.  This is shown by the forward path through &lt;math&gt; \frac {1} {s \mathrm{L}_\mathrm{M}} \, &lt;/math&gt;.  As the current increases, voltage is dropped across the inductor internal resistance R&lt;sub&gt;M&lt;/sub&gt; and the external resistance R&lt;sub&gt;S&lt;/sub&gt;.  This reduces the voltage across the inductor and is represented by the feedback path -(R&lt;sub&gt;M&lt;/sub&gt; + R&lt;sub&gt;S&lt;/sub&gt;).  The current continues to increase but at a steadily decreasing rate until the current reaches the point at which all the voltage is dropped across (R&lt;sub&gt;M&lt;/sub&gt; + R&lt;sub&gt;S&lt;/sub&gt;). Loop 1 is intrinsic.
*Loop2 expresses the effect of the motor back EMF.  Whenever a permanent magnet motor rotates, it acts like a generator and produces a voltage in its windings.  It does not matter whether the rotation is caused by a torque applied to the drive shaft or by current applied to the windings.  This voltage is referred to as back EMF.  The conversion gain of rotational velocity to back EMF is G&lt;sub&gt;M&lt;/sub&gt;.  The polarity of the back EMF is such that it diminishes the voltage across the winding inductance. Loop 2 is intrinsic.
*Loop 3 is extrinsic.  The current in the motor winding passes through a sense resister.  The voltage, '''V'''&lt;sub&gt;IM&lt;/sub&gt;, developed across the sense resister is fed back to the negative terminal of the power amplifier K&lt;sub&gt;C&lt;/sub&gt;.  This feedback causes the voltage amplifier to act like a voltage controlled current source.  Since the motor torque is proportional to motor current, the sub-system '''V'''&lt;sub&gt;IC&lt;/sub&gt; to the output torque acts like a voltage controlled torque source.  This sub-system may be referred to as the "current loop" or "torque loop".  Loop 3 effectively diminishes the effects of loop 1 and loop 2.
*Loop 4 is extrinsic.  A tachometer (actually a low power dc generator) produces an output voltage '''V'''&lt;sub&gt;ωM&lt;/sub&gt; that is proportional to is angular velocity.  This voltage is fed to the negative input of K&lt;sub&gt;V&lt;/sub&gt;.  This feedback causes the sub-system from '''V'''&lt;sub&gt;ωC&lt;/sub&gt; to the load angular velocity to act like a voltage to velocity source.  This sub-system may be referred to as the "velocity loop".  Loop 4 effectively diminishes the effects of loop 0 and loop 3.
*Loop 5 is extrinsic.  This is the overall position feedback loop.  The feedback comes from an angle encoder that produces a digital output.  The output position is subtracted from the desired position by digital hardware which drives a DAC which drives K&lt;sub&gt;P&lt;/sub&gt;.  In the SFG, the conversion gain of the DAC is incorporated into K&lt;sub&gt;P&lt;/sub&gt;.

See [[Mason's rule]] for development of Mason's Gain Formula for this example.

== Terminology and classification of signal-flow graphs ==
There is some confusion in literature about what a signal-flow graph is; [[Henry Paynter]], inventor of [[bond graphs]], writes: "But much of the decline of signal-flow graphs [...] is due in part to the mistaken notion that the branches must be linear and the nodes must be summative. Neither assumption was embraced by Mason, himself !"&lt;ref name=Paynter&gt;{{cite journal|last=Paynter|first=Henry |date=1992|title=An Epistemic Prehistory of Bond Graphs|journal=|pages=10, 15 pages |url=https://www.me.utexas.edu/~longoria/paynter/hmp/BGprehistory.pdf |quote=}}&lt;/ref&gt;

=== Standards covering signal-flow graphs ===
* IEEE Std 155-1960,  IEEE Standards on Circuits: Definitions of Terms for Linear Signal Flow Graphs, 1960.  
: This IEEE standard defines a '''signal-flow graph''' as a ''network'' of ''directed branches'' representing dependent and independent ''signals'' as ''nodes''.  Incoming branches carry ''branch signals'' to the dependent node signals. A ''dependent node'' signal is the algebraic sum of the incoming branch signals at that node, i.e. nodes are summative.

=== State transition signal-flow graph ===
[[File:State transition SFG.svg|thumb|upright=1|State transition signal-flow graph.  Each initial condition is considered as a source (shown in blue).]]
A '''state transition SFG''' or '''state diagram''' is a simulation diagram for a system of equations, including the initial conditions of the states.&lt;ref&gt;{{Cite book|title = Linear Control System Analysis and Design with MATLAB®, Sixth Edition|last = Houpis|first = Constantine H.|publisher = CRC press|year = 2013|isbn = 9781466504264|location = Boca Raton, FL|pages = 171–172|last2 = Sheldon|first2 = Stuart N.|chapter = section 8.8}}&lt;/ref&gt;

=== Closed flowgraph ===
[[File:Source-R-C-Closed-FG.svg|thumb|A simple RC system and its closed flowgraph.  A "dummy" transmittance Z(s) is introduced to close the system.&lt;ref name=Happ66 /&gt;]] Closed flowgraphs describe closed systems and have been utilized to provide a rigorous theoretical basis for topological techniques of circuit analysis.&lt;ref name=Happ66 /&gt;
* Terminology for closed flowgraph theory includes:
** '''Contributive node.'''  Summing point for two or more incoming signals resulting in only one outgoing signal.
** '''Distributive node.''' Sampling point for two or more outgoing signals resulting from only one incoming signal.
** '''Compound node.''' Contraction of a contributive node and a distributive node.
** '''Strictly dependent &amp; strictly independent node.''' A strictly independent node represent s an independent source; a strictly dependent node represents a meter.
** '''Open &amp; Closed Flowgraphs.''' An open flowgraph contains strictly dependent or strictly independent nodes; otherwise it is a closed flowgraph.

== Nonlinear flow graphs ==
Mason introduced both nonlinear and linear flow graphs.  To clarify this point, Mason wrote : "A linear flow graph is one whose associated equations are linear."&lt;ref name=Mason /&gt;

=== Examples of nonlinear branch functions ===
It we denote by '''x&lt;sub&gt;j&lt;/sub&gt;''' the signal at node '''j''', the following are examples of node functions that do not pertain to a [[linear time-invariant system]]:
:&lt;math&gt;\begin{align}
 x_\mathrm{j} &amp;= x_\mathrm{k} \times  x_\mathrm{l} \\
 x_\mathrm{k} &amp;= abs(x_\mathrm{j})\\
 x_\mathrm{l} &amp;= \log(x_\mathrm{k})\\
 x_\mathrm{m} &amp;= t \times x_\mathrm{j} \text{ ,where } t \text{ represents time} \\
\end{align}&lt;/math&gt;

=== Examples of nonlinear signal-flow graph models ===
* Nonlinear signal-flow graphs can be found in electrical engineering literature.&lt;ref&gt;For example: {{Citation
 | first =Thomas A.
 | last =Baran
 | author-link =
 | first2 =Alan V.
 | last2 =Oppenhiem
 | author2-link =
 | title= INVERSION OF NONLINEAR AND TIME-VARYING SYSTEMS
 | contribution =
 | contribution-url =
 | series =Digital Signal Processing Workshop and IEEE Signal Processing Education Workshop (DSP/SPE)
 | year =  2011 
 | pages =
 | place =
 | publisher =IEEE
 | url =
 | doi =10.1109/DSP-SPE.2011.5739226
 | id = }}&lt;/ref&gt;&lt;ref name=Guilherme/&gt;
* Nonlinear signal-flow graphs can also be found in life sciences, for example, Dr [[Arthur Guyton]]'s computer [http://ajpregu.physiology.org/content/ajpregu/287/5/R1009/F2.large.jpg model of the cardiovascular system].

== Applications of SFG techniques in various fields of science ==
* [[Electronic circuits]]
** Characterizing sequential circuits of the [[Moore state machine|Moore]] and [[Mealy state machine|Mealy]] type, obtaining [[Regular Expressions|regular expressions]] from [[state diagram]]s.&lt;ref&gt;{{Cite book|title = Signal Flow Graph Techniques for Sequential Circuit State Diagrams|last = BRZOZOWSKI|first = J.A.|publisher = IEEE|year = 1963|isbn = |location = |pages = 97|last2 = McCLUSKEY|first2 = E. J.|series = IEEE Transactions on Electronic Computers}}&lt;/ref&gt;
** Synthesis of non-linear data converters&lt;ref name=Guilherme&gt;{{Cite book|title = SYMBOLIC SYNTHESIS OF NON-LINEAR DATA CONVERTERS|last = Guilherme|first = J.|publisher = |year = 1999|isbn = |location = |pages = |url = http://orion.ipt.pt/~jorge/Docs/Artigos/icecs.pdf|last2 = Horta|first2 = N. C.|last3 = Franca|first3 = J. E.}}&lt;/ref&gt;
** Control and network theory
** Stochastic signal processing.&lt;ref name=Barry&gt;
{{cite book 
|author=Barry, J. R., Lee, E. A., &amp; Messerschmitt, D. G.
|title=Digital communication
|page=86
|year= 2004
|publisher=Springer 
|location=New York
|edition=Third
|isbn=0-7923-7548-3 
|url=https://books.google.com/books?id=hPx70ozDJlwC&amp;pg=PA86&amp;dq=signal+flow+graph&amp;lr=&amp;as_brr=0&amp;sig=eJKxBTbiY3FtT8zx2Ltm2Mk0LZ4#PPA86,M1}}
&lt;/ref&gt;
** Reliability of electronic systems&lt;ref&gt;{{Cite journal|url = |title = Application of flowgraph techniques to the solution of reliability problems|last = Happ|first = William W.|date = 1964|doi = 10.1109/IRPS.1963.362257|pmid = |access-date = |journal = Physics of Failure in Electronics|editor-last = Goldberg|editor-first = M. F.|publisher = Dept. of Commerce, Office of Technical Services|issue = AD434/329|location = Washington, D. C.|pages = 375–423}}&lt;/ref&gt;
* [[Physiology]] and [[biophysics]]
** Cardiac output regulation&lt;ref&gt;{{Cite journal|url = http://ajpregu.physiology.org/content/ajpregu/287/5/R1009.full.pdf|title = The pioneering use of systems analysis to study cardiac output regulation|last = Hall|first = John E.|date = August 23, 2004|journal = Am J Physiol Regul Integr Comp Physiol|doi = 10.1152/classicessays.00007.2004|pmid = |access-date = 2015-01-20|volume=287|pages=R1009–R1011}}&lt;/ref&gt;
* [[Simulation]]
** Simulation on analog computers&lt;ref&gt;{{harv|Robichaud|1962|loc=chapter 5 Direct Simulation on Analog Computers Through Signal Flow Graphs}}&lt;/ref&gt;

==See also==
* [[Asymptotic gain model]]
* [[Bond graphs]]
* [[Coates graph]]
* [[Wikibooks:Control Systems/Signal Flow Diagrams|Control Systems/Signal Flow Diagrams]] in the Control Systems [[Wikibooks|Wikibook]]
* [[Flow graph (mathematics)]]
* [[Leapfrog filter]] for an example of filter design using a signal flow graph
* [[Mason's gain formula]]
* [[Minor loop feedback]]
* [[Noncommutative signal-flow graph]]

== Notes ==
{{Reflist|2}}

==References==

* {{cite book|ref=harv|author1=Ernest J. Henley  |author2=R. A. Williams |lastauthoramp=yes |title=Graph theory in modern engineering; computer aided design, control, optimization, reliability analysis|year=1973|publisher=Academic Press|isbn=978-0-08-095607-7}} Book almost entirely devoted to this topic.
*{{Citation |last=Kou|first= Benjamin C. |year= 1967 |title= Automatic Control Systems|publisher= Prentice Hall |isbn= |doi=}}
*{{cite book|ref=harv|last=Robichaud|first=Louis P.A. |author2= Maurice Boisvert|author3= Jean Robert|year= 1962 |title=Signal flow graphs and applications |pages=xiv, 214 p. |publisher= Prentice Hall|location=Englewood Cliffs, N.J.|isbn= |doi=|url=http://babel.hathitrust.org/cgi/pt?id=uc1.b4338380}}
*{{Citation |last=Deo|first=Narsingh |year= 1974|title= Graph Theory with Applications to Engineering and Computer Science|pages= 418|publisher= PHI Learning Pvt. Ltd.|location=|isbn= 81-203-0145-5|doi=|url=https://books.google.com/books?id=Yr2pJA950iAC&amp;printsec=frontcover&amp;hl=fr#v=onepage&amp;q&amp;f=false}}
*{{cite book |title=Graphs: Theory and algorithms |author1=K Thulasiramen |author2=MNS Swarmy |chapter=§6.11 The Coates and Mason graphs |pages=163 ''ff'' |url=https://books.google.com/books?id=rFH7eQffQNkC&amp;pg=PA163 |publisher=John Wiley &amp; Sons |year=2011 |isbn=9781118030257}}
*{{cite book|ref=harv|last=Ogata|first=Katsuhiko  |year= 2002|title= Modern Control Engineering 4th Edition|publisher= Prentice-Hal |chapter=Section 3-9 Signal Flow Graphs|isbn=0-13-043245-8|doi=}}
* {{Cite thesis |last= Phang |first= Khoman |title= CMOS Optical Preamplifier Design Using Graphical Circuit Analysis|type= |chapter= ''2.5 An overview of Signal-flow graphs'' |url= http://www.eecg.toronto.edu/~kphang/papers/PhDthesis.pdf|date= 2000-12-14 |year= 2001 |publisher= Department of Electrical and Computer Engineering, University of Toronto|access-date= |docket= |oclc= }} © Copyright by Khoman Phang 2001

==Further reading==
* {{cite book|author=Wai-Kai Chen|title=Applied Graph Theory|publisher=North Holland Publishing Company|year=1976|isbn=0720423627}} Chapter 3 for the essentials, but applications are scattered throughout the book.
* {{cite web |author=Wai-Kai Chen |title=Some applications of linear graphs |url=http://www.dtic.mil/cgi-bin/GetTRDoc?AD=AD0601623 |publisher=Coordinated Science Laboratory, University of Illinois, Urbana |date=May 1964 |work=Contract DA-28-043-AMC-00073 (E)}}
* {{cite book|author1=K. Thulasiraman  |author2=M. N. S. Swamy |lastauthoramp=yes |title= Graphs: Theory and Algorithms|year=1992|isbn=0-471-51356-3|at=6.10-6.11 for the essential mathematical idea}}
* {{cite book|editor=Richard C. Dorf|title=Circuits, Signals, and Speech and Image Processing|year=2006|publisher=CRC Press|isbn=978-1-4200-0308-6|author=Shu-Park Chan|chapter=Graph theory|at=§ 3.6|edition=3rd}} Compares Mason and Coates graph approaches with Maxwell's k-tree approach.
* {{cite book |author=RF Hoskins |chapter=Flow-graph and signal flow-graph analysis of linear systems |url=https://books.google.com/books?id=6DeoBQAAQBAJ&amp;pg=PA156 |editor=SR Deards |title=Recent Developments in Network Theory: Proceedings of the Symposium Held at the College of Aeronautics, Cranfield, September 1961 |year=2014 |publisher=Elsevier |isbn=9781483223568}} A comparison of the utility of the [[Coates graph|Coates flow graph]] and the Mason flow graph.

==External links==
{{Wikibooks |Control Systems|Signal Flow Diagrams |Electrical engineering: Construction of a flow graph for a RC circuit}}
{{Wikibooks |Control Systems|Signal Flow Diagrams |Examples of systematic reduction}}
* [https://web.archive.org/web/20040325002849/http://www.apl.jhu.edu/Classes/Notes/Penn/EE774/Chap_03r.pdf M. L. Edwards: ''S-parameters, signal flow graphs, and other matrix representations'' ] All Rights Reserved
* [https://tube.switch.ch/channels/d206c96c H Schmid: ''Signal-Flow Graphs in 12 Short Lessons'' ]
* {{wikibooks-inline|Control Systems/Signal Flow Diagrams}}
* {{commons category inline|Signal flow graphs}}

[[Category:Classical control theory]]
[[Category:Graphs]]
[[Category:Signal processing]]
[[Category:Application-specific graphs]]
[[Category:Linear algebra]]</text>
      <sha1>cge1qoxuo4kus48ynbojy9rvtq94q0e</sha1>
    </revision>
  </page>
  <page>
    <title>South (disambiguation)</title>
    <ns>0</ns>
    <id>2628786</id>
    <revision>
      <id>867707563</id>
      <parentid>867707530</parentid>
      <timestamp>2018-11-07T14:04:38Z</timestamp>
      <contributor>
        <username>Shantavira</username>
        <id>23736</id>
      </contributor>
      <minor/>
      <comment>/* Recordings and releases */  no redlinks on disambig pages</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2667">{{wiktionary|south}}
'''[[South]]''' is a cardinal direction or compass point.
{{TOC right}}

'''South''' or '''The South''' may also refer to:

==Geography==
* [[Global South]], the developing nations of the world
* [[South (lunar crater)]]
* [[South (Martian crater)]]
* [[Southern United States]] ("The South")

==Films, books, music and other media==
===Books and written media===
* [[The South (novel)|''The South'' (novel)]], by Colm Tóibín
* [[The South (short story)|"The South" (short story)]], by Jorge Luis Borges
* [[South magazine|''South'' magazine]], a bi-monthly magazine published in Savannah, Georgia
* ''South: A Memoir of the Endurance Voyage'' by [[Ernest Shackleton|Sir Ernest Shackleton]]
* [[El Sur (newspaper)|''El Sur'' (newspaper)]], a Chilean newspaper

===Film and television titles===
* [[The South (film)|''The South'' (film)]], by Victor Erice

===Music groups===
&lt;!-- South (band) redirects here --&gt;
* [[South (British band)]], a British rock band from London, England
* The South, a band composed of members formerly of [[The Beautiful South]]
* South, duo composed of songwriter [[Fred Burch]] and pianist Don Hill, 1969
* South, project of [[Lonnie Mack]] and Ed Labunski, 1978

===Recordings and releases===
* [[South (Heather Nova album)|''South'' (Heather Nova album)]]
* [[South (Shona Laing album)|''South'' (Shona Laing album)]]
* [[South (EP)|''South'' (EP)]], an album by Ego Likeness
* [[South (composition)]], a jazz composition written by and made popular by Bennie Moten's Kansas City Orchestra
* "South", a song by Karate from the album ''[[Some Boots]]''
* [[The South (song)|"The South" (song)]], a 2013 single by The Cadillac Three
* ''South'' (EP), an album by [[Hippo Campus]]

==Other uses==
* [[South (surname)]], list of people with the surname South
* [[South River (disambiguation)]]
* [[South (European Parliament constituency)]], in Republic of Ireland
* [[South Melbourne FC]], a soccer club
* [[South of Scotland rugby union team]]
* [[the South (Freemasonry)]] the social phase of a meeting, with food

==See also==
* [[Southern (disambiguation)]]
* [[Southern (country subdivision)]]
* [[Souths (disambiguation)]]
* [[Sud (disambiguation)]], French for south
* [[Sur (disambiguation)]], Spanish for south
* {{intitle|south|All articles with "South" in the title}}
* {{intitle|south (university OR college OR school)|All articles with "South" and "University/College/School" in the title}}
* {{intitle|south (region OR district OR province)|All articles with "South" and "Region/District/Province" in the title}}

{{CandODirections}}
{{disambiguation|geo|surname}}

[[Category:Orientation (geometry)]]</text>
      <sha1>hhh2ct68xe1oyw4qy94z4uoefdm128x</sha1>
    </revision>
  </page>
  <page>
    <title>Space-filling tree</title>
    <ns>0</ns>
    <id>26173821</id>
    <revision>
      <id>818125160</id>
      <parentid>811634704</parentid>
      <timestamp>2018-01-01T19:08:39Z</timestamp>
      <contributor>
        <ip>2601:445:437F:FE66:D898:AFAF:FDDF:B1C</ip>
      </contributor>
      <comment>copy-editing, mostly of math notation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6085">'''Space-filling trees''' are geometric constructions that are analogous to [[space-filling curve]]s,&lt;ref&gt;Sagan, H. and J. Holbrook: "Space-filling curves", Springer-Verlag, New York, 1994&lt;/ref&gt; but have a branching, tree-like structure and are rooted.  A space-filling tree is defined by an incremental process that results in a tree for which every point in the space has a finite-length path that converges to it. In contrast to [[space-filling curve]]s, individual paths in the tree are short, allowing any part of the space to be quickly reached from the root.
&lt;ref&gt;Kuffner, J. J. and S. M. LaValle: ''Space-filling Trees'', The Robotics Institute, Carnegie Mellon University, CMU-RI-TR-09-47, 2009.&lt;/ref&gt;&lt;ref&gt;Kuffner, J. J.; LaValle, S.M.; “Space-filling trees: A new perspective on incremental search for motion planning,” Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on , vol., no., pp.2199-2206, 25-30 Sept. 2011&lt;/ref&gt; The simplest examples of space-filling trees have a regular, self-similar, [[fractal]] structure, but can be generalized to non-regular and even [[randomized]]/[[Monte Carlo method|Monte-Carlo]] variants (see [[Rapidly exploring random tree]]).  Space-filling trees have interesting parallels in nature, including [[fluid distribution system]]s, [[vascular network]]s, and [[fractal]] plant growth, and many interesting connections to [[L-system]]s in computer science.

==Definition==

A space-filling tree is defined by an iterative process whereby a single point in a [[continuity (topology)|continuous]] space is connected via a continuous path to every other point in the space by a path of [[Wikt:finite|finite]] length, and for every point in the space, there is at least one path that [[Limit of a sequence|converges]] to it.

The term "space-filling tree" in this sense was created in a 2009 tech report &lt;ref&gt;Kuffner, J. J. and S. M. LaValle: ''Space-filling Trees'', The Robotics Institute, Carnegie Mellon University, CMU-RI-TR-09-47, 2009.&lt;/ref&gt; that defines "space-filling" and "tree" differently than their traditional definitions in mathematics.  As explained in the [[space-filling curve]] article, in 1890, Peano found the first space-filling curve, and by [[Camille Jordan|Jordan's]] 1887 definition, which is now standard, a curve is a single function, not a sequence of functions.  The curve is "space filling" because it is "a curve whose range contains the entire 2-dimensional unit square" (as explained in the first sentence of [[space-filling curve]]).

In contrast, a space-filling tree, as defined in the tech report, is not a single tree. It is only a sequence of trees. The paper says "A space-filling tree is actually defined as an infinite sequence of trees". It defines &lt;math&gt;T_\text{square}&lt;/math&gt; as a "sequence of trees", then states "&lt;math&gt;T_\text{square}&lt;/math&gt; is a space-filling tree".  It is not space-filling in the standard sense of including the entire 2-dimensional unit square.  Instead, the paper defines it as having trees in the sequence coming arbitrarily close to every point.  It states "A tree sequence T is called 'space filling' in a space ''X'' if for every ''x''&amp;nbsp;&amp;isin;&amp;nbsp;''X'', there exists a path in the tree that starts at the root and converges to&amp;nbsp;''x''.".  The standard term for this concept is that it includes a set of points that is  [[dense set|dense everywhere]] in the unit square.

==Examples==
The simplest example of a space-filling tree is one that fills a [[square (geometry)|square]] planar region. The images illustrate the construction for the planar region &lt;math&gt;[0,1]^2 \subset \mathbb{R}^2&lt;/math&gt;. At each iteration, additional branches are added to the existing trees.

&lt;gallery perrow="3"&gt;
Image:Space_Filling_Tree_Square1.png|Square space-filling tree (Iteration 1)
Image:Space_Filling_Tree_Square2.png|Square space-filling tree (Iteration 2)
Image:Space_Filling_Tree_Square3.png|Square space-filling tree (Iteration 3)
Image:Space_Filling_Tree_Square4.png|Square space-filling tree (Iteration 4)
Image:Space_Filling_Tree_Square5.png|Square space-filling tree (Iteration 5)
Image:Space_Filling_Tree_Square6.png|Square space-filling tree (Iteration 6)
&lt;/gallery&gt;

Space-filling trees can also be defined for a variety of other shapes and volumes.
Below is the subdivision scheme used to define a space-filling for a triangular region.
At each iteration, additional branches are added to the existing trees connecting the center of each [[triangle]] to the centers of the four subtriangles.

&lt;gallery widths="500px" heights = "150px"&gt;
Image:Space_Filling_Tree_Tri_iter_1_2_3.png|Subdivision scheme for the first three iterations of the triangle space-filling tree
 &lt;/gallery&gt;

The first six iterations of the triangle space-filling tree are illustrated below:

&lt;gallery perrow="3"&gt;
Image:Space_Filling_Tree_Tri1.png|Triangle space-filling tree (Iteration 1)
Image:Space_Filling_Tree_Tri2.png|Triangle space-filling tree (Iteration 2)
Image:Space_Filling_Tree_Tri3.png|Triangle space-filling tree (Iteration 3)
Image:Space_Filling_Tree_Tri4.png|Triangle space-filling tree (Iteration 4)
Image:Space_Filling_Tree_Tri5.png|Triangle space-filling tree (Iteration 5)
Image:Space_Filling_Tree_Tri6.png|Triangle space-filling tree (Iteration 6)
&lt;/gallery&gt;

Space-filling trees can also be constructed in higher dimensions.  The simplest examples are [[cube]]s in &lt;math&gt;\mathbb{R}^3&lt;/math&gt; and [[hypercubes]] in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;.
A similar sequence of iterations used for the [[square (geometry)|square]] space-filling tree can be used for hypercubes.  The third iteration of such a space-filling tree in &lt;math&gt;\mathbb{R}^3&lt;/math&gt; is illustrated below:

&lt;gallery widths="300px" heights="300px"&gt;
Image:Space_Filling_Tree_Cube3.png|Cube space-filling tree (Iteration 3)
&lt;/gallery&gt;

==See also {{anchor|see also}}==
:*[[H tree]]
:*[[Space-filling curve]]
:*[[Rapidly exploring random tree]] (RRTs)
:*[[Binary space partitioning]]

==References {{anchor|Notes|References|Notes or references}}==
&lt;references/&gt;

[[Category:Fractals]]</text>
      <sha1>6kpkp9tw2fpxtr6th9knfjqq7ahmtke</sha1>
    </revision>
  </page>
  <page>
    <title>Spectral density</title>
    <ns>0</ns>
    <id>202672</id>
    <revision>
      <id>867334213</id>
      <parentid>851825921</parentid>
      <timestamp>2018-11-05T02:29:38Z</timestamp>
      <contributor>
        <username>Waylah</username>
        <id>11001076</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30760">{{about|signal processing and relation of spectra to time-series|further applications in the physical sciences|Spectrum (disambiguation)#Physical science}}
{{distinguish-redirect|Spectral power density|Spectral power}}
[[File:Fluorescent lighting spectrum peaks labelled.svg|thumb|right|The spectral density of a [[fluorescent light]] as a function of optical wavelength shows peaks at atomic transitions, indicated by the numbered arrows.]]
[[File:Voice waveform and spectrum.png|thumb|right|The voice waveform over time (left) has a broad audio power spectrum (right).]]

The power spectrum &lt;math&gt;S_{xx}(f)&lt;/math&gt; of a [[time series]] &lt;math&gt;x(t)&lt;/math&gt; describes 
the distribution of [[Power (physics)|power]] into frequency components composing that signal.&lt;ref&gt;{{cite web
 | url = http://user.it.uu.se/~ps/SAS-new.pdf
 | title = Spectral Analysis of Signals
 |author1=[[Peter Stoica|P Stoica]]  |author2=R Moses
  |lastauthoramp=yes | year = 2005
 }}&lt;/ref&gt;  
According to [[Fourier analysis]], any physical signal can be decomposed into a number of discrete frequencies, or a spectrum of frequencies over a continuous range. The statistical average of a certain signal or sort of signal (including [[Noise (electronics)|noise]]) as analyzed in terms of its frequency content, is called its [[spectrum]].

When the energy of the signal is concentrated around a finite time interval, especially if its total energy is finite, one may compute the '''energy spectral density'''. More commonly used is the '''power spectral density''' (or simply  '''power spectrum'''), which applies to signals existing over ''all'' time, or over a time period large enough (especially in relation to the duration of a measurement) that it could as well have been over an infinite time interval. The power spectral density (PSD) then refers to the spectral energy distribution that would be found per unit time, since the total energy of such a signal over all time would generally be infinite. Summation or integration of the spectral components yields the total power (for a physical process) or variance (in a statistical process), identical to what would be obtained by integrating &lt;math&gt;x^2(t)&lt;/math&gt; over the time domain, as dictated by [[Parseval's theorem]].&lt;ref&gt;{{cite web
 | url = http://user.it.uu.se/~ps/SAS-new.pdf
 | title = Spectral Analysis of Signals
 |author1=[[Peter Stoica|P Stoica]]  |author2=R Moses
  |lastauthoramp=yes | year = 2005
 }}&lt;/ref&gt;

The spectrum of a physical process &lt;math&gt;x(t)&lt;/math&gt; often contains essential  information about the nature of &lt;math&gt;x&lt;/math&gt;. For instance, the [[Pitch (music)|pitch]] and [[timbre]] of a musical instrument are immediately determined from a spectral analysis. The [[color]] of a light source is determined by the spectrum of the electromagnetic wave's electric field &lt;math&gt;E(t)&lt;/math&gt; as it fluctuates at an extremely high frequency. Obtaining a spectrum from time series such as these involves the [[Fourier transform]], and generalizations based on Fourier analysis. In many cases the time domain is not specifically employed in practice, such as when a dispersive prism is used to obtain a spectrum of light in a [[spectrograph]], or when a sound is perceived through its effect on the auditory receptors of the inner ear, each of which is sensitive to a particular frequency.
 
However this article concentrates on situations in which the time series is known (at least in a statistical sense) or directly measured (such as by a microphone sampled by a computer). The power spectrum is important in [[statistical signal processing]] and in the statistical study of [[stochastic process]]es, as well as in many other branches of [[physics]] and [[engineering]]. Typically the process is a function of time, but one can similarly discuss data in the spatial domain being decomposed in terms of [[spatial frequency]].&lt;ref&gt;{{cite web
 | url = http://user.it.uu.se/~ps/SAS-new.pdf
 | title = Spectral Analysis of Signals
 |author1=[[Peter Stoica|P Stoica]]  |author2=R Moses
  |lastauthoramp=yes | year = 2005
 }}&lt;/ref&gt;

== Explanation ==
{{further|Spectrum}}
Any signal that can be represented as a variable that varies in time has a corresponding frequency spectrum. This includes familiar entities such as [[visible light]] (perceived as [[color]]), musical notes (perceived as [[Pitch (music)|pitch]]), [[radio frequency|radio/TV]] (specified by their frequency, or sometimes wavelength) and even the regular rotation of the earth. When these signals are viewed in the form of a frequency spectrum, certain aspects of the received signals or the underlying processes producing them are revealed. In some cases the frequency spectrum may include a distinct peak corresponding to a [[sine wave]] component. And additionally there may be peaks corresponding to [[harmonics]] of a fundamental peak, indicating a periodic signal which is ''not'' simply sinusoidal. Or a continuous spectrum may show narrow frequency intervals which are strongly enhanced corresponding to resonances, or frequency intervals containing almost zero power as would be produced by a [[notch filter]].

In [[physics]], the signal might be a wave, such as an [[electromagnetic wave]], an [[sound wave|acoustic wave]], or the vibration of a mechanism. The ''power spectral density'' (PSD) of the signal describes the [[power (physics)|power]] present in the signal as a function of frequency, per unit frequency. Power spectral density is commonly expressed in [[watt]]s per [[hertz]] (W/Hz).&lt;ref&gt;{{cite book
 | title = VSAT Networks
 | author = Gérard Maral
 | publisher = John Wiley and Sons
 | year = 2003
 | ISBN = 0-470-86684-5
 | url = https://books.google.com/books?id=CMx5HQ1Mr_UC&amp;pg=PR20&amp;dq=%22power+spectral+density%22+W/Hz&amp;lr=&amp;as_brr=0&amp;ei=VYwvSImyA4L4sQPxxJXzAg&amp;sig=-bko0DhmJwzISN6PcHszF9E3qUE#PPR20,M1
 }}&lt;/ref&gt;

When a signal is defined in terms only of a [[voltage]], for instance, there is no unique power associated with the stated amplitude. In this case "power" is simply reckoned in terms of the square of the signal, as this would always be ''proportional'' to the actual power delivered by that signal into a given [[Electrical impedance|impedance]]. So one might use units of V&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;Hz&lt;sup&gt;−1&lt;/sup&gt; for the PSD and V&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;s&amp;nbsp;Hz&lt;sup&gt;−1&lt;/sup&gt; for the ESD (''energy spectral density'')&lt;ref&gt;{{cite book
 | title = Fundamentals of Noise and Vibration Analysis for Engineers
 |author1=Michael Peter Norton  |author2=Denis G. Karczub
  |lastauthoramp=yes | publisher = [[Cambridge University Press]]
 | year = 2003
 | isbn = 0-521-49913-5
 | url = https://books.google.com/books?id=jDeRCSqtev4C&amp;pg=PA352&amp;dq=%22power+spectral+density%22+%22energy+spectral+density%22&amp;lr=&amp;as_brr=3&amp;ei=i3IvSLL6H4-KsgPfze13&amp;sig=RJgA8uGocYf5d6mC6rKKS-X_2bc
 }}&lt;/ref&gt; even though no actual "power" or "energy" is specified.

Sometimes one encounters an ''amplitude spectral density'' (ASD), which is the square root of the PSD; the ASD of a voltage signal has units of V&amp;nbsp;Hz&lt;sup&gt;−1/2&lt;/sup&gt;.&lt;ref&gt;{{cite web
 | url = http://www.lumerink.com/courses/ece697/docs/Papers/The%20Fundamentals%20of%20FFT-Based%20Signal%20Analysis%20and%20Measurements.pdf
 | title = The Fundamentals of FFT-Based Signal Analysis and Measurement
 |author1=Michael Cerna  |author2=Audrey F. Harvey
  |lastauthoramp=yes | year = 2000
 }}&lt;/ref&gt; This is useful when the ''shape'' of the spectrum is rather constant, since variations in the ASD will then be proportional to variations in the signal's voltage level itself. But it is mathematically preferred to use the PSD, since only in that case is the area under the curve meaningful in terms of actual power over all frequency or over a specified bandwidth.

For random vibration analysis, units of ''g''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;Hz&lt;sup&gt;−1&lt;/sup&gt; are frequently used for the PSD of [[acceleration]]. Here ''g'' denotes the [[g-force]].&lt;ref&gt;{{cite book
 | title = Reliability Engineering
 | author = Alessandro Birolini
 | publisher = Springer
 | year = 2007
 | isbn = 978-3-540-49388-4
 | page = 83
 | url = https://books.google.com/books?id=xPIW3AI9tdAC&amp;pg=PA83&amp;dq=acceleration-spectral-density+g+hz&amp;as_brr=3&amp;ei=q24xSpKOBZXkzASPrs39BQ
 }}&lt;/ref&gt;

Mathematically, it is not necessary to assign physical dimensions to the signal or to the independent variable. In the following discussion the meaning of ''x(t)'' will remain unspecified, but the independent variable will be assumed to be that of time.

== Definition ==

=== Energy spectral density{{Anchor|Energy}} ===
{{distinguish-redirect|Energy spectral density|Energy spectrum}}

Energy spectral density describes how the [[Energy (signal processing)|energy]] of a signal or a [[time series]] is distributed with frequency. Here, the term [[Energy (signal processing)|energy]] is used in the generalized sense of signal processing;&lt;ref name="oppenheim"&gt;{{cite book|last1=Oppenheim|last2=Verghese|title=Signals, Systems, and Inference|pages=32–4}}&lt;/ref&gt; that is, the energy &lt;math&gt;E&lt;/math&gt; of a signal &lt;math&gt;x(t)&lt;/math&gt; is

:&lt;math&gt; E =\int_{-\infty}^\infty |x(t)|^2\, dt.&lt;/math&gt;

The energy spectral density is most suitable for transients—that is, pulse-like signals—having a finite total energy. In this case, [[Parseval's theorem]] &lt;ref name="Stein"&gt;{{cite book| last=Stein |first=Jonathan Y.|title=Digital Signal Processing: A Computer Science Perspective|page=115|publisher=Wiley|year=2000}}&lt;/ref&gt; gives us an alternate expression for the energy of the signal:

:&lt;math&gt;\int_{-\infty}^\infty |x(t)|^2\, dt = \int_{-\infty}^\infty |\hat{x}(f)|^2\, df,&lt;/math&gt;

where

:&lt;math&gt;\hat{x}(f)=\int_{-\infty}^\infty e^{-2\pi ift}x(t) \, dt,&lt;/math&gt;

is the [[Fourier transform]] of the signal and &lt;math&gt;f&lt;/math&gt; is the [[frequency]] in Hz, i.e., cycles per second. Often used is the [[angular frequency]] &lt;math&gt;\omega=2\pi f&lt;/math&gt;. Since the integral on the right-hand side is the energy of the signal, the integrand &lt;math&gt;\left |\hat{x}(f) \right |^2&lt;/math&gt; can be interpreted as a [[density function]] describing the energy per unit frequency contained in the signal at the frequency &lt;math&gt;f&lt;/math&gt;. In light of this, the energy spectral density of a signal &lt;math&gt;x(t)&lt;/math&gt; is defined as&lt;ref name="Stein"/&gt;
:&lt;math&gt; S_{xx}(f) = \left |\hat{x}(f) \right |^2 &lt;/math&gt;

As a physical example of how one might measure the energy spectral density of a signal, suppose &lt;math&gt;V(t)&lt;/math&gt; represents the [[electric potential|potential]] (in [[volt]]s) of an electrical pulse propagating along a [[transmission line]] of [[Electrical impedance|impedance]] &lt;math&gt;Z&lt;/math&gt;, and suppose the line is terminated with a [[impedance matching|matched]] resistor (so that all of the pulse energy is delivered to the resistor and none is reflected back). By [[Ohm's law]], the power delivered to the resistor at time &lt;math&gt;t&lt;/math&gt; is equal to &lt;math&gt;V(t)^2/Z&lt;/math&gt;, so the total energy is found by integrating &lt;math&gt;V(t)^2/Z&lt;/math&gt; with respect to time over the duration of the pulse. To find the value of the energy spectral density &lt;math&gt;S_{xx}(f)&lt;/math&gt; at frequency &lt;math&gt;f&lt;/math&gt;, one could insert between the transmission line and the resistor a [[bandpass filter]] which passes only a narrow range of frequencies (&lt;math&gt;\Delta f&lt;/math&gt;, say) near the frequency of interest and then measure the total energy &lt;math&gt;E(f)&lt;/math&gt; dissipated across the resistor. The value of the energy spectral density at &lt;math&gt;f&lt;/math&gt; is then estimated to be &lt;math&gt;E(f)/\Delta f&lt;/math&gt;. In this example, since the power &lt;math&gt;V(t)^2/Z&lt;/math&gt; has units of V&lt;sup&gt;2&lt;/sup&gt; Ω&lt;sup&gt;−1&lt;/sup&gt;, the energy &lt;math&gt;E(f)&lt;/math&gt; has units of V&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;s&amp;nbsp;Ω&lt;sup&gt;−1&lt;/sup&gt;&amp;nbsp;= J, and hence the estimate &lt;math&gt;E(f)/\Delta  f&lt;/math&gt; of the energy spectral density has units of J&amp;nbsp;Hz&lt;sup&gt;−1&lt;/sup&gt;, as required. In many situations, it is common to forgo the step of dividing by &lt;math&gt;Z&lt;/math&gt; so that the energy spectral density instead has units of V&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;s&amp;nbsp;Hz&lt;sup&gt;−1&lt;/sup&gt;.

This definition generalizes in a straightforward manner to a discrete signal with an infinite number of values &lt;math&gt;x_n&lt;/math&gt; such as a signal sampled at discrete times &lt;math&gt;x_n=x(n\Delta t)&lt;/math&gt;:

:&lt;math&gt;S_{xx}(f) = (\Delta t)^2\left|\sum_{n=-\infty}^\infty x_n e^{-2\pi i f n \Delta t}\right|^2= \hat x_d(f)\hat x_d^*(f),&lt;/math&gt;

where &lt;math&gt;\hat x_d(f)&lt;/math&gt; is the [[discrete Fourier transform]] of &lt;math&gt;x_n &lt;/math&gt; and &lt;math&gt;\hat x_d^*(f)&lt;/math&gt; is the [[complex conjugate]] of &lt;math&gt;\hat x_d(f).&lt;/math&gt; The sampling interval &lt;math&gt;\Delta t&lt;/math&gt; is needed to keep the correct physical units and to ensure that we recover the continuous case in the limit &lt;math&gt;\Delta t\to 0&lt;/math&gt;; however, in the mathematical sciences, the interval is often set to 1.

=== Power spectral density ===
{{distinguish|Spectral power distribution}}

The above definition of energy spectral density is suitable for transients (pulse-like signals) whose energy is concentrated around one time window; then the Fourier transforms of the signals generally exist. For continuous signals over all time, such as [[stationary process]]es, one must rather define the ''power spectral density'' (PSD); this describes how [[power (physics)|power]] of a signal or time series is distributed over frequency, as in the simple example given previously.  Here, power can be the actual physical power, or more often, for convenience with abstract signals, is simply identified with the squared value of the signal. For example, statisticians study the variance of a function over time &lt;math&gt;x(t)&lt;/math&gt; (or over another independent variable), and using an analogy with electrical signals (among other physical processes), it is customary to refer to it as the ''power spectrum'' even when there is no physical power involved. If one were to create a physical [[voltage]] source which followed &lt;math&gt;x(t)&lt;/math&gt; and applied it to the terminals of a 1 [[ohm]] [[resistor]], then indeed the instantaneous power dissipated in that resistor would be given by  ''x&lt;sup&gt;2&lt;/sup&gt;'' [[watt]]s.

The average power ''P'' of a signal &lt;math&gt;x(t)&lt;/math&gt; over all time is therefore given by the following time average:

: &lt;math&gt; P = \lim_{T\to \infty} \frac 1 {T} \int_{0}^T |x(t)|^2\,dt.&lt;/math&gt;

Note that a  [[stationary process]], for instance, may have a finite power but an infinite energy. After all, energy is the integral of power, and the stationary signal continues over an infinite time. That is the reason that we cannot use the energy spectral density as defined above in such cases.

In analyzing the frequency content of the signal &lt;math&gt;x(t)&lt;/math&gt;, one might like to compute the ordinary Fourier transform &lt;math&gt;\hat{x}(\omega)&lt;/math&gt;; however, for many signals of interest the Fourier transform does not formally exist.{{#tag:ref|Some authors (e.g. Risken&lt;ref&gt;{{cite book | title = The Fokker–Planck Equation: Methods of Solution and Applications | edition = 2nd | author = Hannes Risken | publisher = Springer | year = 1996 | isbn = 9783540615309 | page = 30 | url = https://books.google.com/books?id=MG2V9vTgSgEC&amp;pg=PA30 }}&lt;/ref&gt;) still use the non-normalized Fourier transform in a formal way to formulate a definition of the power spectral density

:&lt;math&gt; \langle \hat x(\omega) \hat x^\ast(\omega') \rangle = 2\pi f(\omega) \delta(\omega-\omega')&lt;/math&gt;,

where &lt;math&gt; \delta(\omega-\omega')&lt;/math&gt; is the [[Dirac delta function]]. Such formal statements may sometimes be useful to guide the intuition, but should always be used with utmost care.|group="N"}} Because of this complication one can as well work with a truncated Fourier transform where the signal is integrated only over a finite interval [0,&amp;nbsp;''T'']:

:&lt;math&gt; \hat{x}(\omega) = \frac{1}{\sqrt{T}} \int_0^T x(t) e^{-i\omega t}\, dt.&lt;/math&gt;

This is the amplitude spectral density. Then the power spectral density can be defined as&lt;ref&gt;{{cite book | title = Spikes: Exploring the Neural Code (Computational Neuroscience) |author1=Fred Rieke |author2=William Bialek | author3=David Warland |last-author-amp=yes | publisher = [[MIT Press]] | year = 1999 | isbn = 978-0262681087 }}&lt;/ref&gt;&lt;ref name="millers370"&gt;{{cite book | title = Probability and random processes | author1=Scott Millers  |author2=Donald Childers  |lastauthoramp=yes | publisher = [[Academic Press]] | year = 2012 | pages = 370–5 }}&lt;/ref&gt;

:&lt;math&gt; S_{xx}(\omega) = \lim_{T \to \infty} \mathbf{E} \left[ \left | \hat{x}(\omega) \right |^ 2 \right]. &lt;/math&gt;

Here &lt;math display="inline"&gt;\mathbf{E}&lt;/math&gt; denotes the [[expected value]]; explicitly, we have&lt;ref name="millers370" /&gt;

:&lt;math&gt; \mathbf{E} \left[ \left  | \hat{x}(\omega) \right |^2 \right] = \mathbf{E} \left[ \frac{1}{T} \int_0^T x^*(t) e^{i\omega t}\, dt \int_0^T x(t') e^{-i\omega t'}\, dt' \right] = \frac{1}{T} \int_0^T \int_0^T \mathbf{E}\left[x^*(t) x(t')\right] e^{i\omega (t-t')}\, dt\, dt'.&lt;/math&gt;

In the latter form (for a [[stationary process|stationary random process]]), one can make the change of variables &lt;math&gt;\Delta t = t-t'&lt;/math&gt; and with the limits of integration (rather than [0,T]) approaching infinity, the resulting power spectral density &lt;math&gt;S_{xx}(\omega)&lt;/math&gt; and the [[autocorrelation function]] of this signal are seen to be Fourier transform pairs ([[Wiener–Khinchin theorem]]). The autocorrelation function is a statistic defined as

:&lt;math&gt; \gamma(\tau)=\langle X(t) X(t+\tau)\rangle =  \mathbf{E}[X(t)X(t+\tau)]&lt;/math&gt;

or more generally as

:&lt;math&gt; \gamma(\tau)=\langle X(t) X(t-\tau)^*\rangle =\langle X(t)^* X(t+\tau)\rangle&lt;/math&gt;

in the case that ''X(t)'' is complex-valued. Provided that &lt;math&gt; \gamma(\tau) &lt;/math&gt; is absolutely integrable (which is not always true){{#tag:ref|The [[Wiener–Khinchin theorem]] makes sense of this formula for any [[wide-sense stationary process]] under weaker hypotheses: &lt;math&gt; \gamma &lt;/math&gt;  does not need to be absolutely integrable, it only needs to exist.  But the integral can no longer be interpreted as usual.  The formula also makes sense if interpreted as involving [[Distribution (mathematics)|distributions]] (in the sense of [[Laurent Schwartz]], not in the sense of a statistical [[Cumulative distribution function]]) instead of functions.  If &lt;math&gt; \gamma &lt;/math&gt; is continuous, [[Bochner's theorem]] can be used to prove that its Fourier transform exists as a positive [[Measure (mathematics)|measure]], whose distribution function is F (but not necessarily as a function and not necessarily possessing a probability density).}},

: &lt;math&gt;S_{xx}(\omega)=\int_{-\infty}^\infty \gamma(\tau) e^{-i\omega\tau}\,d \tau=\hat \gamma(\omega). &lt;/math&gt;

Many authors use this equality to actually ''define'' the power spectral density.&lt;ref&gt;{{cite book|title = Echo Signal Processing| author = Dennis Ward Ricker | publisher = Springer | year = 2003 | ISBN = 1-4020-7395-X | url = https://books.google.com/books?id=NF2Tmty9nugC&amp;pg=PA23&amp;dq=%22power+spectral+density%22+%22energy+spectral+density%22&amp;lr=&amp;as_brr=3&amp;ei=HZMvSPSWFZyStwPWsfyBAw&amp;sig=1ZZcHwxXkErvNXtAHv21ijTXoP8#PPA23,M1 }}&lt;/ref&gt;

The power of the signal in a given frequency band &lt;math&gt;[f_1, f_2]&lt;/math&gt; (or &lt;math&gt;[\omega_1,\omega_2]&lt;/math&gt;) can be calculated by integrating over frequency. Since &lt;math&gt;S_{xx}(-\omega) = S_{xx}(\omega)&lt;/math&gt;, an equal amount of power can be attributed to positive and negative frequencies, which accounts for the factor of 2 in the following form (such trivial factors dependent on conventions used):

: &lt;math&gt; P_\mathsf{bandlimited} = 2 \int_{f_1}^{f_2} S_{xx}(2\pi \! f) \, df = \frac{1}{\pi} \int_{\omega_1}^{\omega_2} S_{xx}(\omega) d\omega&lt;/math&gt;

More generally, similar techniques may be used to estimate a time-varying spectral density. In this case the truncated Fourier transform defined above over the finite time interval ''(0, T)'' is ''not'' evaluated in the limit of ''T'' approaching infinity. This results in decreased spectral coverage and resolution since frequencies of less than ''1/T'' are not sampled, and results at frequencies which are not an integer multiple of ''1/T'' are not independent. Just using a single such time series, the estimated power spectrum will be very "noisy", however this can be alleviated if it is possible to evaluate the expected value (in the above equation) using a large (or infinite) number of short-term spectra corresponding to [[statistical ensemble]]s of realizations of ''x(t)'' evaluated over the specified time window.

This definition of the power spectral density can be generalized to [[discrete time]] variables &lt;math&gt;x_n&lt;/math&gt;. As above we can consider a ''finite'' window of &lt;math&gt;1\le n\le N&lt;/math&gt; with the signal sampled at discrete times &lt;math&gt;x_n=x(n\Delta t)&lt;/math&gt; for a total measurement period &lt;math&gt;T=N \Delta t&lt;/math&gt;. Then a single estimate of the PSD can be obtained through summation rather than integration:

:&lt;math&gt;\tilde{S}_{xx}(\omega)=\frac{(\Delta t)^2}{T}\left|\sum_{n=1}^N x_n e^{-i\omega n \Delta t}\right|^2&lt;/math&gt;.

As before, the actual PSD is achieved when ''N'' (and thus ''T'') approach infinity and the expected value is formally applied. In a real-world application, one would typically average this single-measurement PSD over many trials to obtain a more accurate estimate of the theoretical PSD of the physical process underlying the individual measurements.  This computed PSD is sometimes called a [[periodogram]]. This periodogram converges to the true PSD as the number of estimates as well as the averaging time interval ''T'' approach infinity (Brown &amp; Hwang&lt;ref&gt;{{cite book | title = Introduction to Random Signals and Applied Kalman Filtering |author1=Robert Grover Brown  |author2=Patrick Y.C. Hwang  |lastauthoramp=yes | publisher = [[John Wiley &amp; Sons]] | year = 1997 | ISBN = 0-471-12839-2 }}&lt;/ref&gt;).

If two signals both possess power spectral densities, then the [[#Cross-spectral density]] can similarly be calculated; as the PSD is related to the autocorrelation, so is the cross-spectral density related to the [[cross-correlation]].

==== Properties of the power spectral density ====

Some properties of the PSD include:&lt;ref&gt;{{Cite book
| publisher = Cambridge University Press
| isbn = 0-521-01230-9
| last = Storch
| first = H. Von
|author2=F. W Zwiers
 | title = Statistical analysis in climate research
| year = 2001
}}&lt;/ref&gt;

* The spectrum of a real valued process (or even a complex process using the above definition) is real and an [[even function]] of frequency: &lt;math&gt;S_{xx}(-\omega) = S_{xx}(\omega)&lt;/math&gt;.
* If the process is continuous and purely indeterministic{{clarify|date=December 2015}}, the autocovariance function can be reconstructed by using the [[Inverse Fourier transform]]
* The PSD can be used to compute the [[variance]] (net power) of a process by integrating over frequency:
:: &lt;math&gt;\text{Var}(X_n) = \gamma_0 = \frac{1}{\pi} \int_0^{\infty}\! S_{xx}(\omega) \, d\omega.&lt;/math&gt;
* Being based on the fourier transform, the PSD is a linear function of the autocovariance function in the sense that if &lt;math&gt;\gamma&lt;/math&gt; is decomposed into two functions &lt;math&gt;\gamma(\tau) = \alpha_1 \gamma_1(\tau) + \alpha_2 \gamma_2(\tau)&lt;/math&gt;, then
:: &lt;math&gt;f = \alpha_1 S_{xx,1} + \alpha_2 S_{xx,2}.&lt;/math&gt;

The ''integrated spectrum'' or ''power spectral distribution'' &lt;math&gt;F(\omega)&lt;/math&gt; is defined as{{dubious|reason=Who uses a distribution over all positive and negative frequency starting from -∞? If anything one would want zero to infinity (times 2)|date=December 2015}}&lt;ref&gt;An Introduction to the Theory of Random Signals and Noise, Wilbur B. Davenport and Willian L. Root, IEEE Press, New York, 1987, {{isbn|0-87942-235-1}}&lt;/ref&gt;

: &lt;math&gt;F(\omega)=  \int _{-\infty}^\omega S_{xx}(\omega')\, d\omega'. &lt;/math&gt;

=== Cross-spectral density ===
{{See also|Coherence (signal processing)}}

Given two signals &lt;math&gt;x(t)&lt;/math&gt; and &lt;math&gt;y(t)&lt;/math&gt;, each of which possess power spectral densities &lt;math&gt;S_{xx}(\omega)&lt;/math&gt; and &lt;math&gt;S_{yy}(\omega)&lt;/math&gt;, it is possible to define a ''cross-spectral density'' (CSD) given by

:&lt;math&gt;S_{xy}(\omega) = \lim_{T\to\infty} \mathbf{E}\left[\left(F_x^T(\omega)\right)^*F_y^T(\omega)\right].&lt;/math&gt;

The cross-spectral density (or 'cross power spectrum') is thus the Fourier transform of the [[cross-correlation]] function.

:&lt;math&gt;S_{xy}(\omega) = \int_{-\infty}^{\infty} R_{xy}(t) e^{-j \omega t} dt = \int_{-\infty}^{\infty} \left[ \int_{-\infty}^{\infty} x(\tau) \cdot y(\tau+t) d\tau \right] e^{-j \omega t} dt,&lt;/math&gt;

where &lt;math&gt;R_{xy}(t)&lt;/math&gt; is the [[cross-correlation]] of &lt;math&gt;x(t)&lt;/math&gt; and &lt;math&gt;y(t)&lt;/math&gt;.

By an extension of the Wiener–Khinchin theorem, the Fourier transform of the cross-spectral density &lt;math&gt;S_{xy}(\omega)&lt;/math&gt; is the [[Cross-covariance#Signal processing|cross-covariance]] function.&lt;ref&gt;{{cite web
 | url = http://www.fil.ion.ucl.ac.uk/~wpenny/course/course.html
 | title = Signal Processing Course, chapter 7
 | year = 2009
 | author = William D Penny
 }}&lt;/ref&gt; In light of this, the PSD is seen to be a special case of the CSD for &lt;math&gt;x(t) = y(t)&lt;/math&gt;.

For discrete signals ''x&lt;sub&gt;n&lt;/sub&gt;'' and ''y&lt;sub&gt;n&lt;/sub&gt;'', the relationship between the cross-spectral density and the cross-covariance is
: &lt;math&gt;S_{xy}(\omega)=\frac{1}{2\pi}\sum_{n=-\infty}^\infty R_{xy}(n)e^{-j\omega n}&lt;/math&gt;

== Estimation ==
{{main|Spectral density estimation}}

The goal of spectral density estimation is to [[estimation theory|estimate]] the spectral density of a [[random signal]] from a sequence of time samples. Depending on what is known about the signal, estimation techniques can involve [[parametric statistics|parametric]] or [[non-parametric statistics|non-parametric]] approaches, and may be based on time-domain or frequency-domain analysis. For example, a common parametric technique involves fitting the observations to an [[autoregressive model]]. A common non-parametric technique is the [[periodogram]].

The spectral density is usually estimated using [[Fourier transform]] methods (such as the [[Welch method]]), but other techniques such as the [[Maximum entropy spectral estimation|maximum entropy]] method can also be used.

== Properties ==

* The spectral density of &lt;math&gt;f(t)&lt;/math&gt; and the [[autocorrelation]] of &lt;math&gt;f(t)&lt;/math&gt; form a Fourier transform pair (for PSD versus ESD, different definitions of autocorrelation function are used). This result is known as [[Wiener–Khinchin theorem]].
* One of the results of Fourier analysis is [[Parseval's theorem]] which states that the area under the energy spectral density curve is equal to the area under the square of the magnitude of the signal, the total energy:

::&lt;math&gt;\int_{-\infty}^\infty \left| f(t) \right|^2\, dt = \int_{-\infty}^\infty ESD(\omega)\, d\omega.&lt;/math&gt;

:The above theorem holds true in the discrete cases as well. A similar result holds for power: the area under the power spectral density curve is equal to the total signal power, which is &lt;math&gt; R(0) &lt;/math&gt;, the autocorrelation function at zero lag. This is also (up to a constant which depends on the normalization factors chosen in the definitions employed) the variance of the data comprising the signal.

== Related concepts ==
{{distinguish|Spectral density (physical science)}}

* The [[spectral centroid]] of a signal is the midpoint of its spectral density function, i.e. the frequency that divides the distribution into two equal parts.
* The [[spectral edge frequency]] of a signal is an extension of the previous concept to any proportion instead of two equal parts.
* The spectral density is a function of frequency, not a function of time. However, the spectral density of small windows of a longer signal may be calculated, and plotted versus time associated with the window. Such a graph is called a ''[[spectrogram]]''. This is the basis of a number of spectral analysis techniques such as the [[short-time Fourier transform]] and [[wavelets]].
* {{anchor|Phase spectrum}} A "spectrum" generally means the power spectral density, as discussed above, which depicts the distribution of signal content over frequency. This is not to be confused with the [[frequency response]] of a [[transfer function]] which also includes a phase (or equivalently, a real and imaginary part as a function of frequency). For transfer functions, (e.g., [[Bode plot]], [[Chirp#Relation to an impulse signal|chirp]]) the complete frequency response may be graphed in two parts, amplitude versus frequency and [[phase (waves)|phase]] versus frequency (or less commonly, as real and imaginary parts of the transfer function). The [[impulse response]] (in the time domain) &lt;math&gt;h(t)&lt;/math&gt;, cannot generally be uniquely recovered from the amplitude spectral density part alone without the phase function. Although these are also fourier transform pairs, there is no symmetry (as there is for the autocorrelation) forcing the fourier transform to be real-valued. See [[spectral phase]] and [[phase noise]].

== Applications ==

=== Electrical engineering ===

[[File:Spectrogram-fm-radio.png|thumb|right|Spectrogram of an [[FM radio]] signal with frequency on the horizontal axis and time increasing upwards on the vertical axis.]]
The concept and use of the power spectrum of a signal is fundamental in [[electrical engineering]], especially in [[communication systems|electronic communication system]]s, including [[radio communication]]s, [[radar]]s, and related systems, plus passive [[remote sensing]] technology. Electronic instruments called [[spectrum analyzer]]s are used to observe and measure the '''''power spectra''''' of signals.

The spectrum analyzer measures the magnitude of the [[short-time Fourier transform]] (STFT) of an input signal. If the signal being analyzed can be considered a stationary process, the STFT is a good smoothed estimate of its power spectral density.

=== Cosmology ===
[[Primordial fluctuations]], density variations in the early universe, are quantified by a power spectrum which gives the power of the variations as a function of spatial scale.

== See also ==
* [[Noise spectral density]]
* [[Spectral density estimation]]
* [[Spectral efficiency]]
* [[Spectral power distribution]]
* [[Brightness temperature]]
* [[Colors of noise]]
* [[Spectral leakage]]
* [[Window function]]
* [[Bispectrum]]
* [[Whittle likelihood]]

== Notes ==

{{reflist|group="N"}}

== References ==

{{Reflist}}

== External links ==
* [http://vibrationdata.wordpress.com/category/power-spectral-density/ Power Spectral Density Matlab scripts]

{{decibel}}

{{DEFAULTSORT:Spectral Density}}
[[Category:Frequency-domain analysis]]
[[Category:Signal processing]]
[[Category:Waves]]
[[Category:Spectroscopy]]
[[Category:Scattering]]
[[Category:Fourier analysis]]
[[Category:Radio spectrum]]</text>
      <sha1>svjcfb8mhtjp25r4jfeg3zebpc4hgob</sha1>
    </revision>
  </page>
  <page>
    <title>Steiner chain</title>
    <ns>0</ns>
    <id>18866777</id>
    <revision>
      <id>864719094</id>
      <parentid>859181560</parentid>
      <timestamp>2018-10-19T00:43:57Z</timestamp>
      <contributor>
        <username>Tosha</username>
        <id>37304</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20333">[[File:Stejner's porizm.svg|thumb|right|300px]]

In [[geometry]], a '''Steiner chain''' is a set of ''n'' circles, all of which are tangent to two given non-intersecting circles (blue and red in Figure 1), where ''n'' is finite and each circle in the chain is tangent to the previous and next circles in the chain. In the usual ''closed'' Steiner chains, the first and last (''n''&lt;sup&gt;th&lt;/sup&gt;) circles are also tangent to each other; by contrast, in ''open'' Steiner chains, they need not be. The given circles ''α'' and ''β'' do not intersect, but otherwise are unconstrained; the smaller circle may lie completely inside or outside of the larger circle. In these cases, the centers of Steiner-chain circles lie on an [[ellipse]] or a [[hyperbola]], respectively.

Steiner chains are named after [[Jakob Steiner]], who defined them in the 19th century and discovered many of their properties. A fundamental result is ''Steiner's [[porism]]'', which states:

::If at least one closed Steiner chain of ''n'' circles exists for two given circles ''α'' and ''β'', then there is an infinite number of closed Steiner chains of ''n'' circles; and any circle tangent to ''α'' and ''β'' in the same way is a member of such a chain.

"Tangent in the same way" means that the arbitrary circle is internally or externally tangent in the same way as a circle of the original Steiner chain. A porism is a type of theorem relating to the number of solutions and the conditions on it. Porisms often describe a geometrical figure that cannot exist unless a condition is met, but otherwise may exist in infinite number; another example is [[Poncelet's porism]].

The method of [[circle inversion]] is helpful in treating Steiner chains. Since it preserves tangencies, angles and circles, inversion transforms one Steiner chain into another of the same number of circles. One particular choice of inversion transforms the given circles ''α'' and ''β'' into concentric circles; in this case, all the circles of the Steiner chain have the same size and can "roll" around in the [[annulus (mathematics)|annulus]] between the circles similar to [[ball bearing]]s. This standard configuration allows several properties of Steiner chains to be derived, e.g., its points of tangencies always lie on a circle. Several generalizations of Steiner chains exist, most notably [[Soddy's hexlet]] and [[Pappus chain]]s.&lt;ref&gt;Ogilvy, p. 60.&lt;/ref&gt;

==Definitions and types of tangency==
&lt;center&gt;
&lt;gallery caption="Steiner chains with different internal/external tangencies" perrow=5&gt;
Image:Steiner_chain_7mer.svg|The 7 circles of this Steiner chain (black) are externally tangent to the inner given circle (red) but internally tangent to the outer given circle (blue).
Image:Steiner_chain_7mer_all_external.svg|The 7 circles of this Steiner chain (black) are externally tangent to both given circles (red and blue), which lie outside one another.
Image:Steiner_chain_8mer_all_but_one_external.svg|Seven of the 8 circles of this Steiner chain (black) are externally tangent to both given circles (red and blue); the 8th circle is internally tangent to both.
&lt;/gallery&gt;
&lt;/center&gt;

The two given circles ''α'' and ''β'' cannot intersect; hence, the smaller given circle must lie inside or outside the larger. The circles are usually shown as an [[Annulus (mathematics)|annulus]], i.e., with the smaller given circle inside the larger one. In this configuration, the Steiner-chain circles are externally tangent to the inner given circle and internally tangent to the outer circle. However, the smaller circle may also lie completely outside the larger one (Figure 2). The black circles of Figure 2 satisfy the conditions for a closed Steiner chain: they are all tangent to the two given circles and each is tangent to its neighbors in the chain. In this configuration, the Steiner-chain circles have the same type of tangency to both given circles, either externally or internally tangent to both. If the two given circles are tangent at a point, the Steiner chain becomes an infinite [[Pappus chain]], which is often discussed in the context of the [[arbelos]] (''shoemaker's knife''), a geometric figure made from three circles. There is no general name for a sequence of circles tangent to two given circles that intersect at two points.

==Closed, open and multi-cyclic==
&lt;center&gt;
&lt;gallery width="250px" caption="Closed, open and multi-cyclic Steiner chains"&gt;
Image:Steiner_chain_9mer_annular.svg|Closed Steiner chain of nine circles. The 1st and 9th circles are tangent.
Image:Steiner_chain_open_9mer.svg|Open Steiner chain of nine circles. The 1st and 9th circles overlap.
Image:Steiner_chain_double_17mer.svg|Multicyclic Steiner chain of 17 circles in 2 wraps. The 1st and 17th circles touch.
&lt;/gallery&gt;
&lt;/center&gt;

The two given circles ''α'' and ''β'' touch the ''n'' circles of the Steiner chain, but each circle ''C''&lt;sub&gt;''k''&lt;/sub&gt; of a Steiner chain touches only four circles: ''α'', ''β'', and its two neighbors, ''C''&lt;sub&gt;''k''&amp;minus;1&lt;/sub&gt; and ''C''&lt;sub&gt;''k''+1&lt;/sub&gt;. By default, Steiner chains are assumed to be ''closed'', i.e., the first and last circles are tangent to one another. By contrast, an ''open'' Steiner chain is one in which the first and last circles, ''C''&lt;sub&gt;1&lt;/sub&gt; and ''C''&lt;sub&gt;''n''&lt;/sub&gt;, are not tangent to one another; these circles are tangent only to ''three'' circles. Multicyclic Steiner chains wrap around the inner circle several times before closing, i.e., before being tangent to the initial circle.

==Annular case and feasibility criterion==
&lt;center&gt;
&lt;gallery caption="Annular Steiner chains" perrow=5&gt;
Image:Steiner_chain_3mer_annular.svg|{{nowrap|''n'' {{=}} 3}}
Image:Steiner_chain_6mer_annular.svg|{{nowrap|''n'' {{=}} 6}}
Image:Steiner_chain_9mer_annular.svg|{{nowrap|''n'' {{=}} 9}}
Image:Steiner_chain_12mer_annular.svg|{{nowrap|''n'' {{=}} 12}}
Image:Steiner_chain_20mer_annular.svg|{{nowrap|''n'' {{=}} 20}}
&lt;/gallery&gt;
&lt;/center&gt;

[[File:Steiner chain annular angle.svg|thumb|250px|right|The radius of the Steiner circles is ρ, whereas those of the inner and outer given circles are ''r'' and ''R'', respectively. The distance from the center of the inner circle to the center of a Steiner circle is {{nowrap|''r'' + ρ}} (orange line segment).]]

The simplest type of Steiner chain is a closed chain of ''n'' circles of equal size surrounding an inscribed circle of radius ''r''; the chain of circles is itself surrounded by a circumscribed circle of radius ''R''. The inscribed and circumscribed given circles are concentric, and the Steiner-chain circles lie in the [[annulus (mathematics)|annulus]] between them. By symmetry, the angle 2θ between the centers of the Steiner-chain circles is 360°/''n''. Because Steiner chain circles are tangent to one another, the distance between their centers equals the sum of their radii, here twice their radius ''ρ''. The bisector (green in Figure) creates two right triangles, with a central angle of {{nowrap|''θ'' {{=}} 180°/''n''}}. The [[sine]] of this angle can be written as the length of its opposite segment, divided by the hypotenuse of the right triangle

:&lt;math&gt;
\sin \theta = \frac{\rho}{r + \rho}
&lt;/math&gt;

Since ''θ'' is known from ''n'', this provides an equation for the unknown radius ''ρ'' of the Steiner-chain circles

:&lt;math&gt;
\rho = \frac{r \sin\theta}{1 - \sin\theta}
&lt;/math&gt;

The tangent points of a Steiner chain circle with the inner and outer given circles lie on a line that pass through their common center; hence, the outer radius {{nowrap|''R'' {{=}} ''r'' + 2ρ}}.

These equations provide a criterion for the feasibility of a Steiner chain for two given concentric circles. A closed Steiner chain of ''n'' circles requires that the ratio of radii ''R''/''r'' of the given circles equal exactly

:&lt;math&gt;
\frac{R}{r} = 1 + \frac{2 \sin\theta}{1 - \sin\theta} = \frac{1 + \sin\theta}{1 - \sin\theta} = \left[ \sec \theta + \tan \theta \right]^{2}
&lt;/math&gt;

As shown below, this ratio-of-radii criterion for concentric given circles can be extended to all types of given circles by the [[inversive distance]] ''δ'' of the two given circles. For concentric circles, this distance is defined as a logarithm of their ratio of radii

:&lt;math&gt;
\delta = \ln \frac{R}{r}
&lt;/math&gt;

Using the solution for concentric circles, the general criterion for a Steiner chain of ''n'' circles can be written

:&lt;math&gt;
\delta = 2 \ln \left( \sec\theta + \tan\theta \right).
&lt;/math&gt;

If a multicyclic annular Steiner chain has ''n'' total circles and wraps around ''m'' times before closing, the angle between Steiner-chain circles equals

:&lt;math&gt;
\theta = \frac{m}{n} 180^{\circ}
&lt;/math&gt;

In other respects, the feasibility criterion is unchanged.

==Properties under inversion==
&lt;center&gt;
&lt;gallery caption="Inversive properties of Steiner chains" perrow="5"&gt;
File:Steiner chain 9mer annular angle2.svg|Two circles (pink and cyan) that are internally tangent to both given circles and whose centers are collinear with the center of the given circles intersect at the angle 2θ.
File:Steiner chain 9mer annular angle4.svg|Under inversion, these lines and circles become circles with the same intersection angle, 2θ. The gold circles intersect the two given circles at right angles, i.e., orthogonally.
File:Steiner chain 6mer tangent circles.svg|The circles passing through the mutual tangent points of the Steiner-chain circles are orthogonal to the two given circles and intersect one another at multiples of the angle 2θ.
File:Steiner chain 6mer orthogonal circles.svg|The circles passing through the tangent points of the Steiner-chain circles with the two given circles are orthogonal to the latter and intersect at multiples of the angle 2θ.
&lt;/gallery&gt;
&lt;/center&gt;

[[Circle inversion]] transforms one Steiner chain into another with the same number of circles.

In the transformed chain, the tangent points between adjacent circles of the Steiner chain all lie on a circle, namely the concentric circle midway between the two fixed concentric circles. Since tangencies and circles are preserved under inversion, this property of all tangencies lying on a circle is also true in the original chain. This property is also shared with the [[Pappus chain]] of circles, which can be construed as a special limiting case of the Steiner chain.

In the transformed chain, the tangent lines from '''O''' to the Steiner chain circles are separated by equal angles. In the original chain, this corresponds to equal angles between the tangent circles that pass through the center of inversion used to transform the original circles into a concentric pair.

In the transformed chain, the ''n'' lines connecting the pairs of tangent points of the Steiner circles with the concentric circles all pass through '''O''', the common center. Similarly, the ''n'' lines tangent to each pair of adjacent circles in the Steiner chain also pass through '''O'''. Since lines through the center of inversion are invariant under inversion, and since tangency and concurrence are preserved under inversion, the 2''n'' lines connecting the corresponding points in the original chain also pass through a single point, '''O'''.

==Infinite family==
[[File:Steiner chain animation-50dpi.gif|thumb|300px|If even one closed Steiner chain is possible for two given circles (blue), then infinitely many Steiner chains are possible, all related by rotation. Their points of tangency always fall on a circle (orange). If the two given circles are nested, one inside the other, the centers of the Steiner chain circles (black) fall on an [[ellipse]] (red); otherwise, they fall on a [[hyperbola]].]]

A Steiner chain between two non-intersecting circles can always be transformed into another Steiner chain of equally sized circles sandwiched between two concentric circles. Therefore, any such Steiner chain belongs to an infinite family of Steiner chains related by rotation of the transformed chain about '''O''', the common center of the transformed bounding circles.

==Elliptical/hyperbolic locus of centers==
The centers of the circles of a Steiner chain lie on a [[conic section]]. For example, if the smaller given circle lies within the larger, the centers lie on an [[ellipse]]. This is true for any set of circles that are internally tangent to one given circle and externally tangent to the other; such systems of circles appear in the [[Pappus chain]], the [[problem of Apollonius]], and the three-dimensional [[Soddy's hexlet]]. Similarly, if some circles of the Steiner chain are externally tangent to both given circles, their centers must lie on a hyperbola, whereas those that are internally tangent to both lie on a different hyperbola.

The circles of the Steiner chain are tangent to two fixed circles, denoted here as α and β, where β is enclosed by α. Let the radii of these two circles be denoted as ''r''&lt;sub&gt;α&lt;/sub&gt; and ''r''&lt;sub&gt;β&lt;/sub&gt;, respectively, and let their respective centers be the points '''A''' and '''B'''. Let the radius, diameter and center point of the ''k''&lt;sup&gt;th&lt;/sup&gt; circle of the Steiner chain be denoted as ''r''&lt;sub&gt;''k''&lt;/sub&gt;, ''d''&lt;sub&gt;''k''&lt;/sub&gt; and '''P'''&lt;sub&gt;''k''&lt;/sub&gt;, respectively.

All the centers of the circles in the Steiner chain are located on a common [[ellipse]], for the following reason.&lt;ref&gt;Ogilvy, p. 57.&lt;/ref&gt; The sum of the distances from the center point of the ''k''&lt;sup&gt;th&lt;/sup&gt; circle of the Steiner chain to the two centers '''A''' and '''B''' of the fixed circles equals a constant

:&lt;math&gt;
\overline{\mathbf{P}_{k}\mathbf{A}} + \overline{\mathbf{P}_{k}\mathbf{B}} =
\left( r_{\alpha} - r_{k} \right) + \left( r_{\beta} + r_{k} \right) = r_{\alpha} + r_{\beta}
&lt;/math&gt;

Thus, for all the centers of the circles of the Steiner chain, the sum of distances to '''A''' and '''B''' equals the same constant, ''r''&lt;sub&gt;α&lt;/sub&gt;+''r''&lt;sub&gt;β&lt;/sub&gt;. This defines an ellipse, whose two [[Focus (geometry)|foci]] are the points '''A''' and '''B''', the centers of the circles, α and β, that sandwich the Steiner chain of circles.

The sum of distances to the foci equals twice the [[semi-major axis]] ''a'' of an ellipse; hence,

:&lt;math&gt;
2a = r_{\alpha} + r_{\beta}
&lt;/math&gt;

Let ''p'' equal the distance between the foci, '''A''' and '''B'''. Then, the [[eccentricity (mathematics)|eccentricity]] ''e'' is defined by 2 ''ae'' = ''p'', or

:&lt;math&gt;
e = \frac{p}{2a} = \frac{p}{r_{\alpha} + r_{\beta}}
&lt;/math&gt;

From these parameters, the [[semi-minor axis]] ''b'' and the [[semi-latus rectum]] ''L'' can be determined

:&lt;math&gt;
b^{2} = a^{2} \left( 1 - e^{2} \right) = a^{2} - \frac{p^{2}}{4}
&lt;/math&gt;

:&lt;math&gt;
L = \frac{b^{2}}{a} = a - \frac{p^{2}}{4a}
&lt;/math&gt;

Therefore, the ellipse can be described by an equation in terms of its distance ''d'' to one focus

:&lt;math&gt;
d = \frac{L}{1 - e \cos \theta}
&lt;/math&gt;

where θ is the angle with the line joining the two foci.

==Conjugate chains==
&lt;center&gt;
&lt;gallery caption="Conjugate Steiner chains with ''n''&amp;nbsp;=&amp;nbsp;4" &gt;
Image:Steiner_chain_4mer_outside3.svg|Steiner chain with the two given circles shown in red and blue.
Image:Steiner_chain_4mer_outside2.svg|Same set of circles, but with a different choice of given circles.
Image:Steiner_chain_4mer_outside.svg|Same set of circles, but with yet another choice of given circles.
&lt;/gallery&gt;
&lt;/center&gt;

If a Steiner chain has an even number of circles, then any two diametrically opposite circles in the chain can be taken as the two given circles of a new Steiner chain to which the original circles belong. If the original Steiner chain has ''n'' circles in ''m'' wraps, and the new chain has ''p'' circles in ''q'' wraps, then the equation holds

:&lt;math&gt;
\frac{m}{n} + \frac{p}{q} = \frac{1}{2}.
&lt;/math&gt;

A simple example occurs for Steiner chains of four circles (''n''&amp;nbsp;=&amp;nbsp;4) and one wrap (''m''&amp;nbsp;=&amp;nbsp;1). In this case, the given circles and the Steiner-chain circles are equivalent in that both types of circles are tangent to four others; more generally, Steiner-chain circles are tangent to four circles, but the two given circles are tangent to ''n'' circles. In this case, any pair of opposite members of the Steiner chain may be selected as the given circles of another Steiner chain that involves the original given circles. Since ''m''&amp;nbsp;=&amp;nbsp;''p''&amp;nbsp;=&amp;nbsp;1 and ''n''&amp;nbsp;=&amp;nbsp;''q''&amp;nbsp;=&amp;nbsp;4, Steiner's equation is satisfied:

:&lt;math&gt;
\frac{1}{4} + \frac{1}{4} = \frac{1}{2}.
&lt;/math&gt;

==Generalizations==
[[File:Rotating hexlet equator opt.gif|thumb|right|300px|[[Soddy's hexlet]] is a three-dimensional analog of the Steiner chain.]]

The simplest generalization of a Steiner chain is to allow the given circles to touch or intersect one another. In the former case, this corresponds to a [[Pappus chain]], which has an infinite number of circles.

[[Soddy's hexlet]] is a three-dimensional generalization of a Steiner chain of six circles. The centers of the six spheres (the ''hexlet'') travel along the same ellipse as do the centers of the corresponding Steiner chain. The envelope of the hexlet spheres is a [[Dupin cyclide]], the inversion of a [[torus]]. The six spheres are not only tangent to the inner and outer sphere, but also to two other spheres, centered above and below the plane of the hexlet centers.

Multiple rings of Steiner chains are another generalization. An ordinary Steiner chain is obtained by inverting an annular chain of tangent circles bounded by two concentric circles. This may be generalized to inverting three or more concentric circles that sandwich annular chains of tangent circles.

Hierarchical Steiner chains are yet another generalization. If the two given circles of an ordinary Steiner chain are nested, i.e., if one lies entirely within the other, then the larger given circle circumscribes the Steiner-chain circles. In a hierarchical Steiner chain, each circle of a Steiner chain is itself the circumscribing given circle of another Steiner chain within it; this process may be repeated indefinitely, forming a [[fractal]].

==See also==
*[[Poncelet porism]]

==References==
{{reflist|1}}

==Bibliography==
* {{Cite book| last = Ogilvy | first = C. S. | authorlink = C. Stanley Ogilvy | year = 1990| title = Excursions in Geometry| publisher = Dover| isbn = 0-486-26530-7| pages = 51–54| postscript = &lt;!--None--&gt;}}
* {{cite book| title = Geometry Revisited| author1-link = Harold Scott MacDonald Coxeter | last1=Coxeter | first1=H.S.M. | author2-link=S. L. Greitzer | last2=Greitzer | first2=S.L. | year = 1967| publisher = [[Mathematical Association of America|MAA]]| location = [[Washington, D.C.|Washington]] | series=New Mathematical Library | volume=19 | isbn = 978-0-88385-619-2| zbl=0166.16402 | pages = 123–126, 175–176, 180}}
* {{cite book| author = Johnson RA| year = 1960| title = Advanced Euclidean Geometry: An elementary treatise on the geometry of the triangle and the circle| edition = reprint of 1929 edition by Houghton Miflin| publisher = Dover Publications| location = New York| isbn = 978-0-486-46237-0| pages = 113–115}}
* {{cite book| author = Wells D| year = 1991| title = The Penguin Dictionary of Curious and Interesting Geometry| publisher = Penguin Books| location = New York| isbn = 0-14-011813-6| pages = 244–245}}

==Further reading==
* {{cite book| author = Eves H| year = 1972| title = A Survey of Geometry| edition = revised| publisher = Allyn and Bacon| location = Boston| isbn = 978-0-205-03226-6| pages = 134–135}}
* {{cite book| author = [[Daniel Pedoe|Pedoe D]]| year = 1970| title = A Course of Geometry for Colleges and Universities| publisher = Cambridge University Press| isbn = 978-0-521-07638-8| pages = 97–101}}
* {{cite book| author = Coolidge JL| year = 1916| title = A Treatise on the Circle and the Sphere| publisher = Clarendon Press| location = Oxford| pages = 31–37}}

==External links==
{{commons category|Steiner chains}}

*{{mathworld|urlname=SteinerChain|title=Steiner Chain}}
*[http://codepen.io/yukulele/pen/OVOEdX/ Interactive animation of a Steiner chain], [[CodePen]]
*[http://tube.geogebra.org/m/3599 Interactive Applet] by Michael Borcherds showing an animation of Steiner's Chain with a variable number of circles made with [http://www.geogebra.org/ GeoGebra].

[[Category:Circles]]
[[Category:Inversive geometry]]</text>
      <sha1>qpbsxatrbte53sidp2h7jgi2kqg6061</sha1>
    </revision>
  </page>
  <page>
    <title>Subtractor</title>
    <ns>0</ns>
    <id>8453671</id>
    <revision>
      <id>857817756</id>
      <parentid>850550208</parentid>
      <timestamp>2018-09-03T06:30:08Z</timestamp>
      <contributor>
        <ip>182.75.45.1</ip>
      </contributor>
      <comment>/* Full subtractor */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5986">{{Refimprove|date=December 2009}}

In [[electronics]], a '''subtractor''' can be designed using the same approach as that of an [[adder (electronics)|adder]]. The [[binary numeral system|binary]] subtraction process is summarized below. As with an adder, in the general case of calculations on multi-bit numbers, three [[bit]]s are involved in performing the subtraction for each bit of the [[Difference (mathematics)|difference]]: the [[minuend]] (&lt;math&gt;X_{i}&lt;/math&gt;), [[subtrahend]] (&lt;math&gt;Y_{i}&lt;/math&gt;), and a borrow in from the previous (less significant) bit order position (&lt;math&gt;B_{i}&lt;/math&gt;). The outputs are the difference bit (&lt;math&gt;D_{i}&lt;/math&gt;) and borrow bit &lt;math&gt;B_{i+1}&lt;/math&gt;. The subtractor is best understood by considering that the subtrahend and both borrow bits have negative weights, whereas the X and D bits are positive. The operation performed by the subtractor is to rewrite &lt;math&gt;X_{i}-Y_{i}-B_{i}&lt;/math&gt; (which can take the values -2, -1, 0, or 1) as the sum &lt;math&gt;-2B_{i+1}+D_{i}&lt;/math&gt;.

:&lt;math&gt; D_{i} = X_{} \oplus Y_{i} \oplus B_{i}&lt;/math&gt;
:&lt;math&gt; B_{i+1} = X_{i} &lt; (Y_{i} + B_{i})&lt;/math&gt;

Subtractors are usually implemented within a binary adder for only a small cost when using the standard [[two's complement]] notation, by providing an addition/subtraction selector to the carry-in and to invert the second operand.

:&lt;math&gt;-B = \bar{B} + 1&lt;/math&gt; (definition of two's complement notation)

:&lt;math&gt;\begin{alignat}{2}
A - B &amp; = A + (-B) \\
&amp; = A + \bar{B} + 1 \\
\end{alignat}&lt;/math&gt;

==Half subtractor==
[[File:Half subtractor corrected.png|thumbnail|Logic diagram for a half subtractor]]
The half subtractor is a [[logic circuit|combinational circuit]] which is used to perform subtraction of two bits. It has two inputs, the [[minuend]] &lt;math&gt;X&lt;/math&gt; and [[subtrahend]] &lt;math&gt;Y&lt;/math&gt; and two outputs the difference &lt;math&gt;D&lt;/math&gt; and borrow out &lt;math&gt;B_\text{out}&lt;/math&gt;. The borrow out signal is set when the subtractor needs to borrow from the next digit in a multi-digit subtraction. That is, &lt;math&gt;B_{\text{out}} = 1&lt;/math&gt; when &lt;math&gt;X &lt; Y&lt;/math&gt;. Since &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are bits, &lt;math&gt;B_\text{out} = 1&lt;/math&gt; if and only if &lt;math&gt;X = 0&lt;/math&gt; and &lt;math&gt;Y = 1&lt;/math&gt;. An important point worth mentioning is that the half subtractor diagram aside implements &lt;math&gt;X - Y&lt;/math&gt; and not &lt;math&gt;Y-X&lt;/math&gt; since &lt;math&gt;B_\text{out}&lt;/math&gt; on the diagram is given by
:&lt;math&gt;B_{\text{out}} = \overline{X} \cdot Y&lt;/math&gt;.
This is an important distinction to make since subtraction itself is not [[commutative]], but the difference bit &lt;math&gt;D&lt;/math&gt; is calculated using an [[XOR gate]] which is commutative.
[[File:Half subtractor using NAND.jpg|alt=Half-subtractor using NAND gate only.|thumb|333x333px|Half-subtractor using NAND gate only.]]
The [[truth table]] for the half subtractor is:

{| class="wikitable" style="text-align:center"
|-
!colspan="2"|Inputs
!colspan="2"|Outputs
|-
|-
! ''X''
! ''Y''
! ''D''
! ''B''&lt;sub&gt;out&lt;/sub&gt;
|-
| 0
| 0
| 0
| 0
|-
| 0
| 1
| 1
| 1
|-
| 1
| 0
| 1
| 0
|-
| 1
| 1
| 0
| 0
|-
|}

Using the table above and a [[Karnaugh map]], we find the following logic equations for &lt;math&gt;D&lt;/math&gt; and &lt;math&gt;B_\text{out}&lt;/math&gt;:

:&lt;math&gt;D = X \oplus Y&lt;/math&gt;
:&lt;math&gt;B_\text{out} = \overline X \cdot Y&lt;/math&gt;.

Consequently, a simplified half-subtract circuit, advantageously avoiding crossed traces in particular as well as a negate gate is:
&lt;pre&gt;
      X ── XOR ─┬─────── |X-Y|,  is 0 if X equals Y, 1 otherwise
         ┌──┘   └──┐  
      Y ─┴─────── AND ── borrow, is 1 if Y &gt; X, 0 otherwise
&lt;/pre&gt; 
where lines to the right are outputs and others (from the top, bottom or left) are inputs.

==Full subtractor==
The full subtractor is a [[logic circuit|combinational circuit]] which is used to perform subtraction of three input [[bit]]s: the minuend &lt;math&gt;X&lt;/math&gt;, subtrahend &lt;math&gt;Y&lt;/math&gt;, and borrow in &lt;math&gt;B_\text{in}&lt;/math&gt;. The full subtractor generates two output bits: the difference &lt;math&gt;D&lt;/math&gt; and borrow out &lt;math&gt;B_\text{out}&lt;/math&gt;. &lt;math&gt;B_\text{in}&lt;/math&gt; is set when the previous digit is borrowed from &lt;math&gt;X&lt;/math&gt;. Thus, &lt;math&gt;B_\text{in}&lt;/math&gt; is also subtracted from &lt;math&gt;X&lt;/math&gt; as well as the subtrahend &lt;math&gt;Y&lt;/math&gt;. Or in symbols: &lt;math&gt;X - Y - B_\text{in}&lt;/math&gt;. Like the half subtractor, the full subtractor generates a borrow out when it needs to borrow from the next digit. Since we are subtracting &lt;math&gt;X&lt;/math&gt; by &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;B_\text{in}&lt;/math&gt;, a borrow out needs to be generated when &lt;math&gt;X &lt; Y + B_\text{in}&lt;/math&gt;. When a borrow out is generated, 2 is added in the current digit. (This is similar to the subtraction algorithm in decimal. Instead of adding 2, we add 10 when we borrow.) Therefore, &lt;math&gt;D = X - Y - B_\text{in} + 2B_\text{out}&lt;/math&gt;.
[[File:Full subtractor circuit .jpg|alt=Full subtractor circuit|thumb|473x473px|Full subtractor circuit]]
The truth table for the full subtractor is:

{| class="wikitable" style="text-align:center"
|-
!colspan="3"| Inputs 
!colspan="2"| Outputs
|-
! ''X''
! ''Y''
! ''B''&lt;sub&gt;in&lt;/sub&gt;
! ''D''
! ''B''&lt;sub&gt;out&lt;/sub&gt;
|-
| 0 || 0 || 0 || 0 || 0
|-
| 0 || 0 || 1 || 1 || 1
|-
| 0 || 1 || 0 || 1 || 1
|-
| 0 || 1 || 1 || 0 || 1
|-
| 1 || 0 || 0 || 1 || 0
|-
| 1 || 0 || 1 || 0 || 0
|-
| 1 || 1 || 0 || 0 || 0
|-
| 1 || 1 || 1 || 1 || 1
|}

Therefore the equation is D=X⊕Y⊕B&lt;sub&gt;in&lt;/sub&gt; and ''B''&lt;sub&gt;out&lt;/sub&gt;=X'B&lt;sub&gt;in&lt;/sub&gt;+X'Y+YB&lt;sub&gt;in&lt;/sub&gt;

==See also==
* [[Adder (electronics)]]
* [[Carry-lookahead adder]]
* [[Carry-save adder]]
* [[Adding machine]]
* [[Adder-subtractor]]

==References==
{{Reflist}}
* Foundations Of Digital Electronics by Elijah Mwangi

== External links ==
* [http://www.fullchipdesign.com/binary_adder_subtractor.htm N bit Binary addition or subtraction using single circuit.]

[[Category:Computer arithmetic]]
[[Category:Binary logic]]
[[Category:Adders (electronics)|4]]
[[Category:Subtraction]]</text>
      <sha1>dy9oc00taimilrzu6skc5v9wjwqqhoc</sha1>
    </revision>
  </page>
  <page>
    <title>Symbolic simulation</title>
    <ns>0</ns>
    <id>5575498</id>
    <revision>
      <id>383882013</id>
      <parentid>366079073</parentid>
      <timestamp>2010-09-09T18:44:29Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes +genfixes using [[Project:AWB|AWB]] (7105)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1472">{{Unreferenced|date=June 2008}}

In computer science, a [[simulation]] is a computation of the execution of some appropriately modelled state-transition system. Typically this process models the complete state of the system at individual points in a discrete linear time frame, computing each state sequentially from its predecessor. Models for computer programs or VLSI logic designs can be very easily simulated, as they often have an [[operational semantics]] which can be used directly for simulation.

'''Symbolic simulation''' is a form of simulation where many possible executions of a system are considered simultaneously. This is typically achieved by augmenting the domain over which the simulation takes place. A symbolic [[Variable (programming)|variable]] can be used in the simulation state representation in order to index multiple executions of the system. For each possible valuation of these variables, there is a concrete system state that is being indirectly simulated.

Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems. Techniques such as [[symbolic trajectory evaluation]] (STE) and [[generalized symbolic trajectory evaluation]] (GSTE) are based on this idea of symbolic simulation.

== See also ==
* [[Symbolic execution]]
* [[Symbolic computation]]

{{DEFAULTSORT:Symbolic Simulation}}
[[Category:Electronic design automation]]
[[Category:Formal methods]]</text>
      <sha1>t7ncahk2fyitec7pv0859ketf9l21yx</sha1>
    </revision>
  </page>
  <page>
    <title>Tally marks</title>
    <ns>0</ns>
    <id>47962742</id>
    <revision>
      <id>868850107</id>
      <parentid>865336981</parentid>
      <timestamp>2018-11-14T21:14:54Z</timestamp>
      <contributor>
        <username>Tuvalkin</username>
        <id>7661541</id>
      </contributor>
      <minor/>
      <comment>/* Writing systems */ typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7284">{{refimprove|date=August 2012}}
[[File:Hanakapiai Beach Warning Sign Only.jpg|150px|right|thumb|Counting using tally marks at [[Hanakapiai Beach]]. The number shown is 82.]]
[[Image:Indian numerals 100AD.svg|frame|[[Brahmi numeral]]s (lower row) in India in the 1st century CE. Note the similarity of the first three numerals to the [[Chinese characters]] for one through three (一 二 三), plus the resemblance of both sets of numerals to horizontal tally marks.]]

'''Tally marks''', also called '''hash marks''', are a [[unary numeral system]]. They are a form of [[numeral system|numeral]] used for [[counting]]. They are most useful in [[counting]] or tallying ongoing results, such as the [[score (game)|score]] in a game or sport, as no intermediate results need to be erased or discarded.

However, because of the length of large numbers, tallies are not commonly used for static text. Notched sticks, known as [[tally stick]]s, were also historically used for this purpose.

==Early history==
{{main|Prehistoric numerals}}
Counting aids other than body parts appear in the [[Upper Paleolithic]]. The oldest [[tally stick]]s date to between 35,000 and 25,000 years ago, in the form of notched bones found in the context of the [[European Stone Age|European]] [[Aurignacian]] to [[Gravettian]] and in Africa's [[Late Stone Age]].

The so-called ''[[Wolf bone]]'' is a prehistoric artifact discovered in 1937 in [[Czechoslovakia]] during excavations at [[Dolní Věstonice (archaeology)|Vestonice]], [[Moravia]], led by [[Karel Absolon|Karl Absolon]]. Dated to the [[Aurignacian]], approximately 30,000 years ago, the bone is marked with 55 marks which may be [[tally mark]]s. The head of an ivory [[Venus figurine]] was excavated close to the bone.&lt;ref&gt;*Graham Flegg, ''Numbers: their history and meaning'', Courier Dover Publications, 2002 {{ISBN|978-0-486-42165-0}}, pp.&amp;nbsp;41-42.&lt;/ref&gt;

The [[Ishango bone]], found in the [[Ishango]] region of the present-day [[Democratic Republic of Congo]], is dated to over 20,000 years old. Upon discovery, it was thought to portray a series of [[prime number]]s. In the book ''How Mathematics Happened: The First 50,000 Years'', Peter Rudman argues that the development of the concept of prime numbers could only have come about after the concept of division, which he dates to after [[10,000 BC]], with prime numbers probably not being understood until about 500 BC. He also writes that "no attempt has been made to explain why a tally of something should exhibit multiples of two, [[prime numbers]] between 10 and 20, and some numbers that are almost multiples of 10."&lt;ref&gt;{{cite book|last=Rudman|first=Peter Strom|title=How Mathematics Happened: The First 50,000 Years|year=2007|publisher=Prometheus Books|isbn=978-1-59102-477-4|page=64}}&lt;/ref&gt; [[Alexander Marshack]] examined the Ishango bone microscopically, and concluded that it may represent a six-month [[lunar calendar]].&lt;ref name=Marshack&gt;Marshack, Alexander (1991): ''The Roots of Civilization'', Colonial Hill, Mount Kisco, NY.&lt;/ref&gt;

==Clustering==
[[File:Unary8.svg|thumb|upright|150px|Various ways to cluster the number 8. The first or fifth mark in each group may be written at an angle to the others for easier distinction. In the fourth example, the fifth stroke "closes out" a group of five, forming a "herringbone". In the fifth row (used in [[Brazil]], [[France]], and the [[United States]]) the fifth mark crosses diagonally, forming a "five-bar gate".]]

Tally marks are typically clustered in groups of five for legibility. The cluster size 5 has the advantages of (a) easy conversion into decimal for higher arithmetic operations and (b) avoiding error, as humans can far more easily correctly identify a cluster of 5 than one of 10.

&lt;gallery&gt;
File:Tally marks.svg|Tally marks used in most of [[Europe]], [[Zimbabwe]], [[Australia]], [[New Zealand]] and [[North America]].&lt;br&gt;In some variants, the diagonal/horizontal slash is used on its own when five or more units are added at once.
File:Tally marks 3.svg|Cultures using [[Chinese characters]] tally by forming the character [[wikt:正|正]], which consists of five [[stroke (CJKV character)|stroke]]s.&lt;ref&gt;Hsieh, Hui-Kuang (1981) "Chinese tally mark", ''The American Statistician'', '''35''' (3), p. 174, {{doi|10.2307/2683999}}&lt;/ref&gt;&lt;ref name="Lunde 2016-2"&gt;Ken Lunde, Daisuke Miura, [https://www.unicode.org/L2/L2016/16046-ideo-tally-marks.pdf ''L2/16-046: Proposal to encode five ideographic tally marks''], 2016&lt;/ref&gt;
File:Tally marks 2.png|Tally marks used in [[France]], [[Spain]], their former colonies and [[Brazil]]. 1 to 5 and so on. These are most commonly used for registering scores in [[card game]]s, like [[Truco]]
File:Dot and line tally marks.jpg|In the dot and line (or dot-dash) tally, dots represent counts from 1 to 4, lines 5 to 8, and diagonal lines 9 and 10. This method is commonly used in [[forestry]] and related fields.&lt;ref&gt;[https://books.google.com/books?id=TvYGAQAAIAAJ&amp;pg=RA3-PA47&amp;lpg=RA3-PA47&amp;dq=dot+tally+forest+mensuration&amp;source=bl&amp;ots=TfcR_abJ-A&amp;sig=NqWZ8GJCKnz0NegNB0nBklDMXZk&amp;hl=en&amp;sa=X&amp;ei=9Jg_UNSEDaaUywHUlIHgCQ&amp;ved=0CDsQ6AEwAg#v=onepage&amp;q=dot%20tally%20forest%20mensuration&amp;f=false Schenck, Carl A. (1898) Forest mensuration. The University Press.] (Note: The linked reference appears to actually be "Bulletin of the Ohio Agricultural Experiment Station", Number 302, August 1916)&lt;/ref&gt;
File:Indian numerals 100AD.svg|[[Brahmi numeral]]s (lower row) in India in the 1st century CE
&lt;/gallery&gt;

==Writing systems==
[[Roman numerals]], the [[Chinese numerals]] for one through three (一 二 三), and [[counting rods|rod numerals]] were derived from tally marks, as possibly was the [[ogham]] script.&lt;ref&gt;Macalister, R. A. S.,  ''Corpus Inscriptionum Insularum Celticarum'' Vol. I and II, Dublin: Stationery Office (1945).&lt;/ref&gt;

[[Base 1]] arithmetic [[notation system]] is an [[unary  system|unary]] [[positional system]] similar to tally marks. It is rarely used as a practical base for [[counting]] due to its difficult readability. It is made by the concatenation of [[zero]].

The numbers 1, 2, 3, 4, 5, ... would be represented in this system as&lt;ref&gt;{{citation|page=33|title=Programming Structures: Machines and programs|volume=1|series=Programming Structures|first=Jan|last=Hext|publisher=Prentice Hall|year=1990|isbn=9780724809400}}.&lt;/ref&gt;
:0, 00, 000, 0000, 00000, ...

Base 1 notation is widely used in [[flour#Type numbers|type numbers]] of flour, the higher number represents a higher grind.

==See also==
{{columns-list|colwidth=30em|
* [[History of writing ancient numbers]]
* [[Abacus]]
* [[Australian Aboriginal enumeration]]
* [[Timber framing#Carpenters marks|Carpenters marks]]
* ''[[Cherty i rezy]]''
* [[Chuvash numerals]]
* [[Counting rods]]
* [[Finger counting]]
* [[Hangman (game)]]
* [[History of communication]]
* [[History of mathematics]]
* [[Lebombo bone]]
* [[List of international common standards]]
* [[Paleolithic tally sticks]]
* [[Prehistoric numerals]]
* [[Quipu]]
* [[Roman numerals]]
* [[Tally stick]]
}}{{Commons category|Unary numeral}}

==References==
{{Reflist|30em}}

[[Category:Elementary mathematics]]
[[Category:Mathematical notation]]
[[Category:Numeral systems]]
[[Category:Numerals]]
[[Category:Korean language]]</text>
      <sha1>dm7rsytfok6ja587679m5o6b40w8634</sha1>
    </revision>
  </page>
  <page>
    <title>Tarski's undefinability theorem</title>
    <ns>0</ns>
    <id>583785</id>
    <revision>
      <id>862710629</id>
      <parentid>854098864</parentid>
      <timestamp>2018-10-06T05:29:32Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11544">'''Tarski's undefinability theorem''', stated and proved by [[Alfred Tarski]] in 1936, is an important limitative result in [[mathematical logic]], the [[foundations of mathematics]], and in formal [[semantics]]. Informally, the theorem states that ''arithmetical truth cannot be defined in arithmetic''.

The theorem applies more generally to any sufficiently strong [[formal system]], showing that truth in the standard model of the system cannot be defined within the system.

== History ==
In 1931, [[Kurt Gödel]] published the [[Gödel's incompleteness theorems|incompleteness theorems]], which he proved in part by showing how to represent the syntax of formal logic within [[first-order arithmetic]]. Each expression of the formal language of arithmetic is assigned a distinct number. This procedure is known variously as [[Gödel numbering]], ''coding'' and, more generally, as arithmetization. In particular, various ''sets'' of expressions are coded as sets of numbers. It turns out that for various syntactic properties (such as ''being a formula'', ''being a sentence'', etc.), these sets are [[computable set|computable]]. Moreover, any computable set of numbers can be defined by some arithmetical formula. For example, there are formulas in the language of arithmetic defining the set of codes for arithmetic sentences, and for provable arithmetic sentences.

The undefinability theorem shows that this encoding cannot be done for [[semantic]] concepts such as truth. It shows that no sufficiently rich interpreted language can represent its own semantics. A corollary is that any [[metalanguage]] capable of expressing the semantics of some [[object language]] must have expressive power exceeding that of the object language. The metalanguage includes primitive notions, axioms, and rules absent from the object language, so that there are theorems provable in the metalanguage not provable in the object language.

The undefinability theorem is conventionally attributed to [[Alfred Tarski]]. Gödel also discovered the undefinability theorem in 1930, while proving his incompleteness theorems published in 1931, and well before the 1936 publication of Tarski's work (Murawski 1998). While Gödel never published anything bearing on his independent discovery of undefinability, he did describe it in a 1931 letter to [[John von Neumann]]. Tarski had obtained almost all results of his 1936 paper ''Der Wahrheitsbegriff in den formalisierten Sprachen'' between 1929 and 1931, and spoke about them to Polish audiences.  However, as he emphasized in the paper, the undefinability theorem was the only result he did not obtain earlier. According to the footnote of the undefinability theorem (Satz I) of the 1936 paper, the theorem and the sketch of the proof were added to the paper only after the paper was sent to print. When he presented the paper to the Warsaw Academy of Science on March 21, 1931, he wrote only some conjectures instead of the results after his own investigations and partly after Gödel's short report on the incompleteness theorems "Einige metamathematische Resultate über Entscheidungsdefinitheit und Widerspruchsfreiheit", Akd. der Wiss. in Wien, 1930.

== Statement of the theorem ==
We will first state a simplified version of Tarski's theorem, then state and prove in the next section the theorem Tarski actually proved in 1936.
Let ''L'' be the language of [[first-order arithmetic]], and let ''N'' be the standard [[structure (mathematical logic)|structure]] for ''L''. Thus (''L'', ''N'') is the "interpreted first-order language of arithmetic."  Each sentence ''x'' in ''L'' has a [[Gödel number]] ''g''(''x''). Let ''T'' denote the set of  ''L''-sentences true in ''N'', and ''T''* the set of Gödel numbers of the sentences in ''T''. The following theorem answers the question: Can ''T''* be defined by a formula of first-order arithmetic?

''Tarski's undefinability theorem'':  There is no ''L''-formula [[Truth predicate|''True''(''n'')]] that defines ''T''*.
That is, there is no ''L''-formula ''True''(''n'') such that for every ''L''-formula ''A'', ''True''(''g''(''A'')) ↔ ''A'' holds.

Informally, the theorem says that given some formal arithmetic, the concept of truth in that arithmetic is not definable using the expressive means that that arithmetic affords. This implies a major limitation on the scope of "self-representation." It ''is'' possible to define a formula ''True''(''n'') whose extension is ''T''*, but only by drawing on a [[metalanguage]] whose expressive power goes beyond that of ''L''. For example, a [[truth predicate]] for first-order arithmetic can be defined in [[second-order arithmetic]]. However, this formula would only be able to define a truth predicate for sentences in the original language ''L''. To define a truth predicate for the metalanguage would require a still higher "metametalanguage", and so on.

The theorem just stated is a corollary of [[Post's theorem]] about the [[arithmetical hierarchy]], proved some years after Tarski (1936).  A semantic proof of Tarski's theorem from Post's theorem is obtained by [[reductio ad absurdum]] as follows. Assuming  ''T''* is arithmetically definable, there is a natural number ''n'' such that ''T''* is definable by a formula at level &lt;math&gt;\Sigma^0_n&lt;/math&gt; of the [[arithmetical hierarchy]].  However, ''T''* is &lt;math&gt;\Sigma^0_k&lt;/math&gt;-hard for all ''k''.  Thus the arithmetical hierarchy collapses at level ''n'', contradicting Post's theorem.

== General form of the theorem ==
Tarski proved a stronger theorem than the one stated above, using an entirely syntactical method. The resulting theorem applies to any formal language with [[negation]], and with sufficient capability for [[self-reference]] that the [[diagonal lemma]] holds. First-order arithmetic satisfies these preconditions, but the theorem applies to much more general formal systems.

''Tarski's undefinability theorem (general form)'': Let (''L'',''N'') be any interpreted formal language which includes negation and has a Gödel numbering ''g''(''x'') such that for every ''L''-[[Formal language#Words over an alphabet|formula]] ''A''(''x'') there is a formula ''B'' such that ''B'' ↔ ''A''(''g''(''B'')) holds in ''N''. Let ''T''* be the set of Gödel numbers of ''L''-sentences true in ''N''.  Then there is no ''L''-formula ''True''(''n'') which defines ''T''*. That is, there is no ''L''-formula ''True''(''n'') such that for every ''L''-formula ''A'', ''True''(''g''(''A'')) ↔ ''A'' is itself true in ''N''.

The proof of Tarski's undefinability theorem in this form is again by [[reductio ad absurdum]]. Suppose that an ''L''- formula ''True''(''n'') defines ''T''*. In particular, if ''A'' is a sentence of arithmetic then ''True''(''g''(''A'')) holds in ''N'' if and only if ''A'' is true in ''N''. Hence for all ''A'', the Tarski ''T''-sentence ''True''(''g''(''A'')) ↔ ''A'' is true in ''N''. But the diagonal lemma yields a counterexample to this equivalence, by giving a "Liar" sentence ''S'' such that ''S'' ↔ ¬''True''(''g''(''S'')) holds in ''N''. Thus no ''L''-formula ''True''(''n'') can define ''T''*. QED.

The formal machinery of this proof is wholly elementary except for the diagonalization that the diagonal lemma requires. The proof of the diagonal lemma is likewise surprisingly simple; for example, it does not invoke [[recursion#Functional recursion|recursive function]]s in any way. The proof does assume that every ''L''-formula has a [[Gödel number]], but the specifics of a coding method are not required. Hence Tarski's theorem is much easier to motivate and prove than the more celebrated [[Gödel's incompleteness theorems|theorems of Gödel]] about the metamathematical properties of [[Peano arithmetic|first-order arithmetic]].

==Discussion==
[[Raymond Smullyan|Smullyan]] (1991, 2001) has argued forcefully that Tarski's undefinability theorem deserves much of the attention garnered by [[Gödel's incompleteness theorem]]s. That the latter theorems have much to say about all of mathematics and more controversially, about a range of philosophical issues (e.g., [[John Lucas (philosopher)|Lucas]] 1961) is less than evident. Tarski's theorem, on the other hand, is not directly about mathematics but about the inherent limitations of any formal language sufficiently expressive to be of real interest. Such languages are necessarily capable of enough [[self-reference]] for the diagonal lemma to apply to them. The broader philosophical import of Tarski's theorem is more strikingly evident.

An interpreted language is ''strongly-semantically-self-representational'' exactly when the language contains [[Predicate (grammar)|predicates]] and [[function symbol]]s defining all the [[semantic]] concepts specific to the language. Hence the required functions include the "semantic valuation function" mapping a formula ''A'' to its [[truth value]] ||''A''||, and the "semantic denotation function" mapping a term ''t'' to the object it denotes. Tarski's theorem then generalizes as follows: ''No sufficiently powerful language is strongly-semantically-self-representational''.

The undefinability theorem does not prevent truth in one theory from being defined in a stronger theory. For example, the set of (codes for) formulas of first-order [[Peano arithmetic]] that are true in ''N'' is definable by a formula in [[second order arithmetic]]. Similarly, the set of true formulas of the standard model of second order arithmetic (or ''n''-th order arithmetic for any ''n'') can be defined by a formula in first-order [[Zermelo–Fraenkel set theory|ZFC]].

== References ==
* J.L. Bell, and M. Machover, 1977. ''A Course in Mathematical Logic''. North-Holland.
* [[George Boolos|G. Boolos]], [[John P. Burgess|J. Burgess]], and [[Richard Jeffrey|R. Jeffrey]], 2002. ''Computability and Logic'', 4th ed. Cambridge University Press.
* [[John Lucas (philosopher)|J.R. Lucas]], 1961. "[http://users.ox.ac.uk/~jrlucas/Godel/mmg.html Mind, Machines, and Gödel]". Philosophy 36: 112–27. 
* R. Murawski, 1998. [https://web.archive.org/web/20110608131053/http://www.staff.amu.edu.pl/~rmur/hpl1.ps Undefinability of truth. The problem of the priority: Tarski vs. Gödel]. History and Philosophy of Logic 19, 153–160
* [[Raymond Smullyan|R. Smullyan]], 1991. ''Godel's Incompleteness Theorems''. Oxford Univ. Press.
* [[Raymond Smullyan|R. Smullyan]], 2001. "Gödel’s Incompleteness Theorems".  In L. Goble, ed., ''The Blackwell Guide to Philosophical Logic'', Blackwell, 72–89.
* {{cite journal| author=[[Alfred Tarski|A. Tarski]]| title=Der Wahrheitsbegriff in den formalisierten Sprachen| journal=Studia Philosophica| year=1936| volume=1| pages=261–405| url=http://www.ifispan.waw.pl/studialogica/s-p-f/volumina_i-iv/I-07-Tarski-small.pdf| accessdate=26 June 2013| deadurl=yes| archiveurl=https://web.archive.org/web/20140109135345/http://www.ifispan.waw.pl/studialogica/s-p-f/volumina_i-iv/I-07-Tarski-small.pdf| archivedate=9 January 2014| df=}}
* [[Alfred Tarski|A. Tarski]], tr J.H. Woodger, 1983. "The Concept of Truth in Formalized Languages". [http://www.thatmarcusfamily.org/philosophy/Course_Websites/Readings/Tarski%20-%20The%20Concept%20of%20Truth%20in%20Formalized%20Languages.pdf English translation of Tarski's 1936 article].  In A. Tarski, ed. J. Corcoran, 1983, ''Logic, Semantics, Metamathematics'', Hackett.

{{Theories of truth}}

[[Category:Mathematical logic]]
[[Category:Theories of truth]]
[[Category:Metatheorems]]
[[Category:Philosophy of logic]]</text>
      <sha1>6rsuxy62hgqriqj4j5swqbvfw14ddwx</sha1>
    </revision>
  </page>
  <page>
    <title>Tetracoordinate</title>
    <ns>0</ns>
    <id>8776733</id>
    <revision>
      <id>657001582</id>
      <parentid>657001504</parentid>
      <timestamp>2015-04-18T06:31:48Z</timestamp>
      <contributor>
        <username>Officer781</username>
        <id>5336741</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="545">{{Unreferenced|date=January 2007}}
'''Tetracoordinate''' in [[coordination chemistry]] generally refers to four [[ligand]]s or atomic attachments to a single metal centre.  Tetracoordinate species can form [[tetrahedral molecular geometry|tetrahedral]], [[square planar molecular geometry|square planar]] or [[trigonal pyramid (chemistry)|pyramidal]] geometries.  This is usually dictated by [[lone pair|lone electron pairs]] on the metal centre.

{{MolecularGeometry}}
[[Category:Molecular geometry]]
[[Category:Stereochemistry]]

{{Chem-stub}}</text>
      <sha1>khefb5y6jfo5w0o4mgjwwtnvt0aol8a</sha1>
    </revision>
  </page>
  <page>
    <title>Turán graph</title>
    <ns>0</ns>
    <id>360581</id>
    <revision>
      <id>853004700</id>
      <parentid>853004588</parentid>
      <timestamp>2018-08-01T19:52:26Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9610">{{infobox graph
 | name = Turán graph
 | image = [[Image:Turan 13-4.svg|180px]]
 | image_caption = The Turán graph T(13,4)
 | namesake = [[Pál Turán]]
 | vertices = ''n''
 | edges = ~&lt;math&gt;\frac{(r - 1) n^2}{2 r}&lt;/math&gt;
 | radius = &lt;math&gt;\left\{\begin{array}{ll}\infty &amp; r = 1\\ 2 &amp; r \le n/2\\ 1 &amp; \text{otherwise}\end{array}\right.&lt;/math&gt;
 | diameter = &lt;math&gt;\left\{\begin{array}{ll}\infty &amp; r = 1\\ 1 &amp; r = n\\ 2 &amp; \text{otherwise}\end{array}\right.&lt;/math&gt;
 | girth = &lt;math&gt;\left\{\begin{array}{ll}\infty &amp; r = 1 \vee (n \le 3 \wedge r \le 2)\\ 4 &amp; r = 2\\ 3 &amp; \text{otherwise}\end{array}\right.&lt;/math&gt;
 | chromatic_number = ''r''
 | chromatic_index =
 | notation = ''T''(''n'',''r'')
}}
The '''Turán graph''' ''T''(''n'',''r'') is a [[complete multipartite graph]] formed by partitioning a set of ''n'' vertices into ''r'' subsets, with sizes as equal as possible, and connecting two vertices by an edge if and only if they belong to different subsets.  The graph will have &lt;math&gt;(n\,\bmod\,r)&lt;/math&gt; subsets of size &lt;math&gt;\lceil n/r\rceil&lt;/math&gt;, and &lt;math&gt;r-(n\,\bmod\,r)&lt;/math&gt; subsets of size &lt;math&gt;\lfloor n/r\rfloor&lt;/math&gt;. That is, it is a complete ''r''-partite graph
:&lt;math&gt;K_{\lceil n/r\rceil, \lceil n/r\rceil, \ldots, \lfloor n/r\rfloor, \lfloor n/r\rfloor}.&lt;/math&gt;
Each vertex has degree either &lt;math&gt;n-\lceil n/r\rceil&lt;/math&gt; or &lt;math&gt;n-\lfloor n/r\rfloor&lt;/math&gt;. The number of edges is
:&lt;math&gt;\frac{1}{2}(n^2 - (n\,\bmod\,r)\lceil n/r\rceil^2 - (r-(n\,\bmod\,r))\lfloor n/r\rfloor^2) \leq \left(1-\frac1r\right)\frac{n^2}{2}.&lt;/math&gt;

It is a [[regular graph]], if ''n'' is divisible by ''r''.

==Turán's theorem==
Turán graphs are named after [[Pál Turán]], who used them to prove [[Turán's theorem]], an important result in [[extremal graph theory]].

By the pigeonhole principle, every set of ''r''&amp;nbsp;+&amp;nbsp;1 vertices in the Turán graph includes two vertices in the same partition subset; therefore, the Turán graph does not contain a [[Clique (graph theory)|clique]] of size&amp;nbsp;''r''&amp;nbsp;+&amp;nbsp;1. According to Turán's theorem, the Turán graph has the maximum possible number of edges among all (''r''&amp;nbsp;+&amp;nbsp;1)-clique-free graphs with ''n''&amp;nbsp;vertices. Keevash and Sudakov (2003) show that the Turán graph is also the only (''r''&amp;nbsp;+&amp;nbsp;1)-clique-free graph of order ''n'' in which every subset of &amp;alpha;''n'' vertices spans at least &lt;math&gt;\frac{r\,{-}\,1}{2r}(2\alpha -1)n^2&lt;/math&gt; edges, if α is sufficiently close to 1. The [[Erdős–Stone theorem]] extends Turán's theorem by bounding the number of edges in a graph that does not have a fixed Turán graph as a subgraph. Via this theorem, similar bounds in extremal graph theory can be proven for any excluded subgraph, depending on the [[chromatic number]] of the subgraph.

==Special cases==
[[File:Complex tripartite graph octahedron.svg|thumb|150px|The [[octahedron]], a 3-[[cross polytope]] whose edges and vertices form ''K''&lt;sub&gt;2,2,2&lt;/sub&gt;, a Turán graph ''T''(6,3). Unconnected vertices are given the same color in this face-centered projection.]]
Several choices of the parameter ''r'' in a Turán graph lead to notable graphs that have been independently studied.

The Turán graph ''T''(2''n'',''n'') can be formed by removing a [[perfect matching]] from a [[complete graph]] ''K''&lt;sub&gt;2''n''&lt;/sub&gt;. As {{harvtxt|Roberts|1969}} showed, this graph has [[boxicity]] exactly ''n''; it is sometimes known as the ''Roberts graph''. This graph is also the 1-[[Skeleton (topology)|skeleton]] of an ''n''-dimensional [[cross-polytope]]; for instance, the graph ''T''(6,3)&amp;nbsp;=&amp;nbsp;''K''&lt;sub&gt;2,2,2&lt;/sub&gt; is the '''octahedral graph''', the graph of the regular [[octahedron]]. If ''n'' couples go to a party, and each person shakes hands with every person except his or her partner, then this graph describes the set of handshakes that take place; for this reason it is also called the '''cocktail party graph'''.

The Turán graph ''T''(''n'',2) is a [[complete bipartite graph]] and, when ''n'' is even, a [[Moore graph]]. When ''r'' is a divisor of ''n'', the Turán graph is [[Symmetric graph|symmetric]] and [[Strongly regular graph|strongly regular]], although some authors consider Turán graphs to be a trivial case of strong regularity and therefore exclude them from the definition of a strongly regular graph.

The Turán graph &lt;math&gt;T(n,\lceil n/3\rceil)&lt;/math&gt; has 3&lt;sup&gt;''a''&lt;/sup&gt;2&lt;sup&gt;''b''&lt;/sup&gt; [[maximal clique]]s, where
3''a''&amp;nbsp;+&amp;nbsp;2''b''&amp;nbsp;=&amp;nbsp;''n'' and ''b''&amp;nbsp;≤&amp;nbsp;2; each maximal clique is formed by choosing one vertex from each partition subset. This is the largest number of maximal cliques possible among all ''n''-vertex graphs regardless of the number of edges in the graph (Moon and Moser 1965); these graphs are sometimes called '''Moon–Moser graphs'''.

==Other properties==
Every Turán graph is a [[cograph]]; that is, it can be formed from individual vertices by a sequence of [[disjoint union]] and [[complement (graph theory)|complement]] operations. Specifically, such a sequence can begin by forming each of the independent sets of the Turán graph as a disjoint union of isolated vertices. Then, the overall graph is the complement of the disjoint union of the complements of these independent sets.

Chao and Novacky (1982) show that the Turán graphs are ''chromatically unique'': no other graphs have the same [[chromatic polynomial]]s. Nikiforov (2005) uses Turán graphs to supply a lower bound for the sum of the ''k''th [[eigenvalue]]s of a graph and its complement.

Falls, Powell, and Snoeyink develop an efficient algorithm for finding clusters of orthologous groups of genes in genome data, by representing the data as a graph and searching for large Turán subgraphs.

Turán graphs also have some interesting properties related to [[geometric graph theory]]. Pór and Wood (2005) give a lower bound of Ω((''rn'')&lt;sup&gt;3/4&lt;/sup&gt;) on the volume of any three-dimensional [[Graph drawing|grid embedding]] of the Turán graph. Witsenhausen (1974) conjectures that the maximum sum of squared distances, among ''n'' points with unit diameter in '''R'''&lt;sup&gt;''d''&lt;/sup&gt;, is attained for a configuration formed by embedding a Turán graph onto the vertices of a regular simplex.

An ''n''-vertex graph ''G'' is a [[Glossary of graph theory#Subgraphs|subgraph]] of a Turán graph ''T''(''n'',''r'') if and only if ''G'' admits an [[equitable coloring]] with ''r'' colors. The partition of the Turán graph into independent sets corresponds to the partition of ''G'' into color classes. In particular, the Turán graph is the unique maximal ''n''-vertex graph with an ''r''-color equitable coloring.

== References ==
* {{cite journal
  |author1=Chao, C. Y. |author2=Novacky, G. A. | title = On maximally saturated graphs
  | journal = Discrete Mathematics
  | volume = 41
  | pages = 139–143
  | year = 1982
  | doi = 10.1016/0012-365X(82)90200-X
  | ref = harv
  | issue = 2}}
* {{cite journal
  | title = Computing high-stringency COGs using Turán type graphs
  |author1=Falls, Craig |author2=Powell, Bradford |author3=Snoeyink, Jack | url = http://www.cs.unc.edu/~snoeyink/comp145/cogs.pdf
  | ref = harv}}
* {{cite journal
  | title = Local density in graphs with forbidden subgraphs
  |author1=Keevash, Peter |author2=Sudakov, Benny | journal = [[Combinatorics, Probability and Computing]]
  | year = 2003
  | volume = 12
  | pages = 139–153
  | doi = 10.1017/S0963548302005539
  | ref = harv
  | issue = 2|url=http://www.math.princeton.edu/~bsudakov/localdensity.pdf}}
* {{Cite journal
  | last1 = Moon | first1 = J. W. | last2 = Moser | first2 = L. | authorlink2 = Leo Moser
  | title = On cliques in graphs
  | journal = Israel Journal of Mathematics
  | volume = 3
  | pages = 23–28
  | year = 1965
  | doi = 10.1007/BF02760024
  | ref = harv}}
* {{cite arxiv
  | author = Nikiforov, Vladimir
  | title = Eigenvalue problems of Nordhaus-Gaddum type
  | year = 2005
  | ref = harv
  | eprint = math.CO/0506260}}
* {{cite conference
  | title = No-three-in-line-in-3D
  |author1=Pór, Attila |author2=Wood, David R. | booktitle = [[International Symposium on Graph Drawing|Proc. Int. Symp. Graph Drawing (GD 2004)]]
  | publisher = Lecture Notes in Computer Science no. 3383, Springer-Verlag
  | year = 2005
  | pages = 395–402
  | doi = 10.1007/b105810}}
*{{Cite journal
 | last = Roberts | first = F. S. | authorlink = Fred S. Roberts
 | editor-last = Tutte
 | editor-first = W.T.
 | title = On the boxicity and cubicity of a graph
 | journal = Recent Progress in Combinatorics
 | year = 1969 | pages = 301–310
 | ref = harv}}
* {{cite journal
  | author = Turán, P. | authorlink = Pál Turán
  | title = Egy gráfelméleti szélsőértékfeladatról (On an extremal problem in graph theory)
  | journal = Matematikai és Fizikai Lapok
  | volume = 48
  | year = 1941
  | pages = 436–452
  | ref = harv}}
* {{cite journal
  | author = Witsenhausen, H. S.
  | title = On the maximum of the sum of squared distances under a diameter constraint
  | year = 1974
  | journal = [[American Mathematical Monthly]]
  | pages = 1100–1101
  | volume = 81
  | doi = 10.2307/2319046
  | issue = 10
  | ref = harv
  | jstor = 2319046}}

== External links ==
{{commons category|Turán graphs}}
* {{mathworld | urlname = CocktailPartyGraph | title = Cocktail Party Graph}}
* {{mathworld | urlname = OctahedralGraph | title = Octahedral Graph}}
* {{mathworld | urlname = TuranGraph | title = Turán Graph}}

{{DEFAULTSORT:Turan graph}}
[[Category:Parametric families of graphs]]
[[Category:Extremal graph theory]]</text>
      <sha1>jsqml95izpc8xlne37507plkgfbzegl</sha1>
    </revision>
  </page>
  <page>
    <title>Viral dynamics</title>
    <ns>0</ns>
    <id>45391102</id>
    <revision>
      <id>846305238</id>
      <parentid>842591834</parentid>
      <timestamp>2018-06-17T21:16:13Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3856">{{Orphan|date=July 2016}}

'''Viral dynamics''' is a field of [[applied mathematics]] concerned with describing the progression of viral infections within a host organism.&lt;ref name="VDbook" &gt;{{cite book |last1=Nowak |first1=Martin |last2=May |first2=Robert |date=2001 |title=Virus Dynamics: mathematical principles of immunology and virology | url=https://books.google.ca/books?id=Kixhc3IiCy4C&amp;printsec=frontcover&amp;dq=virus+dynamics&amp;hl=en&amp;sa=X&amp;ei=9yXeVIHfH4a8yQTipIGYBA&amp;redir_esc=y#v=onepage&amp;q=virus%20dynamics&amp;f=false}}&lt;/ref&gt; It employs a family of [[mathematical model]]s that describe changes over time in the populations of cells targeted by the virus and the [[viral load]]. These equations may also track competition between different viral strains and the influence of immune responses. The original viral dynamics models were inspired by compartmental [[epidemic model]]s (e.g. the SI model), with which they continue to share many common mathematical features, such as the concept of the [[basic reproduction number|basic reproductive ratio]] (''R''&lt;sub&gt;0&lt;/sub&gt;). The major distinction between these fields is in the scale at which the models operate: while epidemiological models track the spread of infection between individuals within a population (i.e. "between host"), viral dynamics models track the spread of infection between cells within an individual (i.e. "within host"). Analyses employing viral dynamic models have been used extensively to study [[HIV]],&lt;ref name="VDbook" /&gt;&lt;ref&gt;{{cite journal|last1=Perelson|first1=Alan S|last2=Ribeiro|first2=Ruy M|title=Modeling the within-host dynamics of HIV infection|journal=BMC Biology|date=2013|volume=11|issue=1|page=96|doi=10.1186/1741-7007-11-96|url=http://www.biomedcentral.com/1741-7007/11/96/abstract}}&lt;/ref&gt; [[hepatitis B virus]],&lt;ref&gt;{{cite journal|last1=Nowak|first1=MA|last2=Bonhoeffer|first2=S|last3=Hill|first3=AM|last4=Boehme|first4=R|last5=Thomas|first5=HC|last6=McDade|first6=H|title=Viral dynamics in hepatitis B virus infection|journal=Proceedings of the National Academy of Sciences|date=1996|volume=93|pages=4398–4402| url=http://www.pnas.org/content/93/9/4398.short|doi=10.1073/pnas.93.9.4398|pmc=39549}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Ciupe|first1=SM|last2=Ribeiro|first2=RM|last3=Nelson|first3=PW|last4=Perelson|first4=AS|title=Modeling the mechanisms of acute hepatitis B virus infection|journal=Journal of Theoretical Biology|date=2007|volume=247|issue=1|pages=23–35|doi=10.1016/j.jtbi.2007.02.017|url=http://www.sciencedirect.com/science/article/pii/S0022519307000938|pmc=1994818}}&lt;/ref&gt; and [[hepatitis C virus]],&lt;ref&gt;{{cite journal|last1=Neumann|first1=A|last2=Lam|first2=NP|last3=Dahari|first3=H|last4=Gretch|first4=DR|last5=Wiley|first5=TE|last6=Layden|first6=TJ|last7=Perelson|first7=AS|title=Hepatitis C Viral Dynamics in Vivo and the Antiviral Efficacy of Interferon-α Therapy|journal=Science|date=1998|volume=282|issue=5386|pages=103–107|doi=10.1126/science.282.5386.103|url=http://www.sciencemag.org/content/282/5386/103}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Chatterjee|first1=A|last2=Smith|first2=PF|last3=Perelson|first3=AS|title=Hepatitis C Viral Kinetics: The Past, Present, and Future|journal=Clinics in Liver Disease|date=2013|volume=17|issue=1|pages=13–26|doi=10.1016/j.cld.2012.09.003|url=http://www.sciencedirect.com/science/article/pii/S1089326112000992|pmc=3584572}}&lt;/ref&gt; among other infections

==References==
{{Reflist}}

==External links==
* [http://depts.washington.edu/cfar/discover-cfar/cores-and-programs/viral-dynamics-mathematical-modeling-training Viral Dynamics Mathematical Modeling Training], Center for AIDS Research, University of Washington

[[Category:Evolutionary dynamics]]
[[Category:Evolutionary biology]]
[[Category:Virology]]
[[Category:Immunology]]
[[Category:Applied mathematics]]
[[Category:Mathematical modeling| ]]</text>
      <sha1>9x65posbd7f4oo4v67tkq2rb6817ps4</sha1>
    </revision>
  </page>
</mediawiki>
