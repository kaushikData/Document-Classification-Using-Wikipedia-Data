<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>154 (number)</title>
    <ns>0</ns>
    <id>2034838</id>
    <revision>
      <id>863025007</id>
      <parentid>863019872</parentid>
      <timestamp>2018-10-08T06:57:04Z</timestamp>
      <contributor>
        <username>Gap9551</username>
        <id>8367391</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/182.50.67.186|182.50.67.186]] ([[User talk:182.50.67.186|talk]]) to last version by Arthur Rubin</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4424">{{example farm|date=July 2012}}
{{Infobox number
| number = 154
| divisor=1, 2, 7, 11, 14, 22, 77, 154
}}

'''154''' ('''one hundred [and] fifty-four''') is the [[natural number]] following [[153 (number)|153]] and preceding [[155 (number)|155]].

==In mathematics==
154 is a [[nonagonal number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A001106|title=Sloane's A001106 : 9-gonal (or enneagonal or nonagonal) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt; Its factorization makes 154 a [[sphenic number]]

There is no integer with exactly 154 coprimes below it, making 154 a [[noncototient]], nor is there, in base 10, any integer that added up to its own digits yields 154, making 154 a [[self number]]

154 is the sum of the first six [[factorial]]s, if one starts with &lt;math&gt;0!&lt;/math&gt; and assumes that &lt;math&gt;0!=1&lt;/math&gt;.

With just 17 cuts, a pancake can be cut up into 154 pieces ([[Lazy caterer's sequence]]).&lt;ref&gt;{{Cite web|url=https://oeis.org/A000124|title=Sloane's A000124 : Central polygonal numbers (the Lazy Caterer's sequence)|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt;

The distinct prime factors of 154 add up to 20, and so do the ones of 153, hence the two form a [[Ruth-Aaron pair]]. 154! + 1 is a [[factorial prime]].

==In music==
* [[154 (album)|154]] is an album by [[Wire (band)|Wire]], named for the number of live gigs Wire had performed at that time&lt;ref&gt;{{cite web
 |url=http://www.allmusic.com/album/154-mw0000192482
 |title=154 - Wire
 |publisher=[[Allmusic]]
 |accessdate=14 February 2013}}&lt;/ref&gt;

==In the military==
* {{USS|Bauxite|IX-154}} was a United States Navy ''Trefoil''-class concrete barge during World War II
* {{USS|Candid|AM-154}} was a United States Navy ''Admirable''-class minesweeper during World War II
* {{USS|Ellis|DD-154}} was a United States Navy ''Wickes''-class destroyer during World War II
* {{USS|General LeRoy Eltinge|AP-154}} was a United States Navy ''General G. O. Squier''-class transport during World War II
* {{USS|Lowndes|APA-154}} was a United States Navy ''Haskell''-class attack transport during World War II
* {{USS|Sims|DE-154}} was a United States Navy ''Buckley''-class destroyer escort ship during World War II
* [[VFA-154|Strike Fighter Squadron 154 (VFA-154)]] is a United States Navy strike fighter squadron stationed at Naval Air Station Lemoore
* [[Convoy ON-154]] was a convoy of ships in December 1942 during World War II

==In sports==

* [[Major League Baseball]] teams played 154 games a season prior to expansion in 1961
* Golfer [[Jack Nicklaus]] played in a record 154 consecutive major championships from the [[1957 U.S. Open (golf)|1957 U.S. Open]] to the [[1998 U.S. Open (golf)|1998 U.S. Open]]

==In transportation==
* [https://web.archive.org/web/20021002191224/http://transit.metrokc.gov/tops/bus/schedules/s154_0_.html Seattle Bus Route 154]
* The [[Maserati Tipo 154]] racecar, also known as 151/4, was produced in 1965

==In other fields==
'''154''' is also:
* The year [[154|AD 154]] or [[154 BC]]
* 154 AH is a year in the [[Islamic calendar]] that corresponds to that corresponds to [[770]] &amp;ndash; [[771]] [[Common Era|AD]]
*[[154 Bertha]] is a dark outer [[Asteroid belt|Main belt]] [[asteroid]]
* [[Ross 154]] is a [[red dwarf]] [[star]] near the southern constellation Sagittarius
* [[Psalms 152–155|Psalm 154]]
* [[Shakespeare]]’s 154 sonnets, the last being [[Sonnet 154]]
* Elcapo No. 154, Saskatchewan is a [[rural municipality]] in [[Saskatchewan]], [[Canada]]
* The [[atomic number]] of an element temporarily called [http://www.flw.com/datatools/periodic/001.php?id=154 Unpentquadium]
* In the [[United Kingdom]], 154 is the telephone number used to report Business Faults with telephone provider [[British Telecom|BT]]

==See also==
* [[List of highways numbered 154]]
* [[United Nations Security Council Resolution 154]]
* [[List of United States Supreme Court cases, volume 154|United States Supreme Court cases, Volume 154]]

==References==
{{reflist}}
* Wells, D. ''[[The Penguin Dictionary of Curious and Interesting Numbers]]'' London: Penguin Group. (1987): 140 - 141

==External links==
{{Commons category|154 (number)}}
* [http://www.virtuescience.com/154.html Virtual Science: Number 154]

{{Integers|1}}

[[Category:Integers]]</text>
      <sha1>jnqnmwgvut8zuu9eqb2gf58yaqzih7a</sha1>
    </revision>
  </page>
  <page>
    <title>Algebraic structure</title>
    <ns>0</ns>
    <id>106364</id>
    <revision>
      <id>841346984</id>
      <parentid>826057229</parentid>
      <timestamp>2018-05-15T08:48:47Z</timestamp>
      <contributor>
        <username>Conclusio99</username>
        <id>16785092</id>
      </contributor>
      <minor/>
      <comment>added a space</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21001">{{Algebraic structures}}

In [[mathematics]], and more specifically in [[abstract algebra]], an '''algebraic structure''' on a [[Set (mathematics)|set]] ''A'' (called '''carrier set''' or '''underlying set''') is a collection of [[finitary]] [[operation (mathematics)|operation]]s on ''A''; the set ''A'' with this [[Structure (mathematical logic)|structure]] is also called an '''algebra'''.&lt;ref&gt;P.M. Cohn. (1981) ''Universal Algebra'', Springer, p. 41.&lt;/ref&gt;

Examples of algebraic structures include [[group (mathematics)|groups]], [[ring (mathematics)|rings]], [[field (mathematics)|fields]], and [[lattice (order)|lattices]]. More complex structures can be defined by introducing multiple operations, different underlying sets, or by altering the defining axioms. Examples of more complex algebraic structures include [[vector space]]s, [[Module (mathematics)|modules]], and [[Algebra (ring theory)|algebras]].

The properties of specific algebraic structures are studied in abstract algebra.  The general theory of algebraic structures has been formalized in [[universal algebra]]. The language of [[category theory]] is used to express and study relationships between different classes of algebraic and non-algebraic objects. This is because it is sometimes possible to find strong connections between some classes of objects, sometimes of different kinds. For example, [[Galois theory]] establishes a connection between certain fields and groups: two algebraic structures of different kinds.

== Introduction ==

Addition and multiplication on numbers are the prototypical example of an operation that combines two elements of a set to produce a third. These operations obey several algebraic laws. For example, ''a'' + (''b'' + ''c'') = (''a'' + ''b'') + ''c'' and ''a''(''bc'') = (''ab'')''c'', both examples of the ''associative law''. Also ''a'' + ''b'' = ''b'' + ''a'', and ''ab'' = ''ba'', the ''commutative law.'' Many systems studied by mathematicians have operations that obey some, but not necessarily all, of the laws of ordinary arithmetic. For example, rotations of objects in three-dimensional space can be combined by performing the first rotation and then applying the second rotation to the object in its new orientation. This operation on rotations obeys the associative law, but can fail the commutative law.

Mathematicians give names to sets with one or more operations that obey a particular collection of laws, and study them in the abstract as algebraic structures. When a new problem can be shown to follow the laws of one of these algebraic structures, all the work that has been done on that category in the past can be applied to the new problem.

In full generality, algebraic structures may involve an arbitrary number of sets and operations that can combine more than two elements (higher [[arity]]), but this article focuses on binary operations on one or two sets. The examples here are by no means a complete list, but they are meant to be a representative list and include the most common structures. Longer lists of algebraic structures may be found in the external links and within ''[[:Category:Algebraic structures]].'' Structures are listed in approximate order of increasing complexity.

== Examples ==

=== One set with operations ===

'''Simple structures''': '''no''' [[binary operation]]:

* [[Set (mathematics)|Set]]: a degenerate algebraic structure ''S''   having no operations.
* [[Pointed set]]: ''S'' has one or more distinguished elements, often 0, 1, or both.
* {{anchor|unary system}}Unary system: ''S'' and a single [[unary operation]] over ''S''.
* {{vanchor|Pointed unary system}}: a unary system with ''S'' a pointed set.

'''Group-like structures''': '''one''' binary operation. The binary operation can be indicated by any symbol, or with no symbol (juxtaposition) as is done for ordinary multiplication of real numbers.

* [[Magma (algebra)|Magma or groupoid]]: ''S'' and a single binary operation over ''S''.
* [[Semigroup]]: an [[associative]] magma.
* [[Monoid]]: a semigroup with [[Identity element|identity]].
* [[Group (mathematics)|Group]]: a monoid with a unary operation (inverse), giving rise to [[inverse element]]s.
* [[Abelian group]]: a group whose binary operation is [[commutative]].
* [[Semilattice]]: a semigroup whose operation is [[idempotence|idempotent]] and commutative. The binary operation can be called either [[meet (mathematics)|meet]] or [[join (mathematics)|join]].
* [[Quasigroup]]: a magma obeying the [[latin square property]]. A quasigroup may also be represented using three binary operations.&lt;ref&gt;{{cite book

  | title =An Introduction to Quasigroups and Their Representations
  | author =Jonathan D. H. Smith
  | publisher =Chapman &amp; Hall
  | url =https://books.google.com/books?id=NfWlUZSOwSkC&amp;printsec=frontcover&amp;dq=quasigroups&amp;source=bl&amp;ots=8ZOf4xvSh6&amp;sig=MyWk4X7vHJL3WkJtPq-Rq3NhLns&amp;hl=en&amp;sa=X&amp;ei=F9caUMjEG4eb1AWAhYGQAw&amp;redir_esc=y#v=onepage&amp;q=quasigroups&amp;f=false
  | accessdate = 2012-08-02 }}&lt;/ref&gt;

* [[Loop (mathematics)|Loop]]: a quasigroup with [[Identity element|identity]].

'''Ring-like structures''' or '''Ringoids''': '''two''' binary operations, often called [[addition]] and [[multiplication]], with multiplication [[distributivity|distributing]] over addition.

* [[Semiring]]: a ringoid such that ''S'' is a monoid under each operation. Addition is typically assumed to be commutative and associative, and the monoid product is assumed to distribute over the addition on both sides, and the additive identity satisfies 0&amp;#8239;''x'' = 0 for all ''x''.
* [[Near-ring]]: a semiring whose additive monoid is a (not necessarily abelian) group.
* [[Ring (mathematics)|Ring]]: a semiring whose additive monoid is an abelian group.
* [[Lie ring]]: a ringoid whose additive monoid is an abelian group, but whose multiplicative operation satisfies the [[Jacobi identity]] rather than associativity.
* [[Boolean ring]]: a commutative ring with idempotent multiplication operation.
* [[field (mathematics)|Field]]: a commutative ring which contains a multiplicative inverse for every nonzero element
* [[Kleene algebra]]s: a semiring with idempotent addition and a unary operation, the [[Kleene star]], satisfying additional properties.
* [[*-algebra]]: a ring with an additional unary operation (*) satisfying additional properties.

'''Lattice structures''': '''two''' or more binary operations, including operations called [[meet and join]], connected by the [[absorption law]].&lt;ref&gt;Ringoids and [[Lattice (order)|lattice]]s can be clearly distinguished despite both having two defining binary operations. In the case of ringoids, the two operations are linked by the [[distributive law]]; in the case of lattices, they are linked by the [[absorption law]]. Ringoids also tend to have numerical [[model theory|model]]s, while lattices tend to have [[set theory|set-theoretic]] models.
&lt;/ref&gt;

* [[Complete lattice]]: a lattice in which arbitrary [[meet and join]]s exist.
* [[Bounded lattice]]: a lattice with a [[greatest element]] and least element.
* [[Complemented lattice]]: a bounded lattice with a unary operation, complementation, denoted by [[reverse Polish notation|postfix]] &lt;sup&gt;[[⊥]]&lt;/sup&gt;&lt;!-- or [[prefix notation|prefix]] [[¬]] --&gt;. The join of an element with its complement is the greatest element, and the meet of the two elements is the least element.
* [[Modular lattice]]: a lattice whose elements satisfy the additional ''modular identity''.
* [[Distributive lattice]]: a lattice in which each of meet and join [[distributive lattice|distributes]] over the other. Distributive lattices are modular, but the converse does not hold.
* [[Boolean algebra (structure)|Boolean algebra]]: a complemented distributive lattice. Either of meet or join can be defined in terms of the other and complementation. This can be shown to be equivalent with the ring-like structure of the same name above.
* [[Heyting algebra]]: a bounded distributive lattice with an added binary operation, [[relative pseudo-complement]], denoted by [[infix]] →, and governed by the axioms ''x''&amp;#8239;→&amp;#8239;''x'' = 1, ''x''&amp;#8239;(''x''&amp;#8239;→&amp;#8239;''y'') = ''x&amp;#8239;y'', ''y''&amp;#8239;(''x''&amp;#8239;→&amp;#8239;''y'') = ''y'', ''x''&amp;#8239;→&amp;#8239;(''y&amp;#8239;z'') = (''x''&amp;#8239;→&amp;#8239;''y'')&amp;#8239;(''x''&amp;#8239;→&amp;#8239;''z'').

'''Arithmetics''': '''two''' [[binary operation]]s, addition and multiplication. ''S'' is an [[infinite set]]. Arithmetics are pointed unary systems, whose [[unary operation]] is [[injective]] [[successor function|successor]], and with distinguished element 0.

* [[Robinson arithmetic]]. Addition and multiplication are [[Recursion|recursively]] defined by means of successor. 0 is the identity element for addition, and annihilates multiplication. Robinson arithmetic is listed here even though it is a variety, because of its closeness to Peano arithmetic.
* [[Peano arithmetic]]. Robinson arithmetic with an [[axiom schema]] of [[mathematical induction|induction]]. Most ring and field axioms bearing on the properties of addition and multiplication are theorems of Peano arithmetic or of proper extensions thereof.

=== Two sets with operations ===

'''[[module (mathematics)|Module]]-like structures:''' composite systems involving two sets and employing at least two binary operations.

* [[Group with operators]]: a group ''G'' with a set Ω and a binary operation Ω&amp;#8239;×&amp;#8239;''G'' → ''G'' satisfying certain axioms.
* [[module (mathematics)|Module]]: an abelian group ''M'' and a ring ''R'' acting as operators on ''M''. The members of ''R'' are sometimes called [[scalar (mathematics)|scalar]]s, and the binary operation of ''scalar multiplication'' is a function ''R''&amp;#8239;×&amp;#8239;''M'' → ''M'', which satisfies several axioms. Counting the ring operations these systems have at least three operations.
* [[Vector space]]: a module where the ring ''R'' is a [[division ring]] or [[field (mathematics)|field]].
* [[Graded vector space]]: a vector space with a [[Direct sum of modules|direct sum]] decomposition breaking the space into "grades".
* [[Quadratic space]]: a vector space ''V'' over a field ''F'' with a function from ''V'' into ''F'' satisfying certain properties. Every quadratic space is also an inner product space (see below).

'''[[algebra (ring theory)|Algebra]]-like structures''': composite system defined over two sets, a ring ''R'' and a ''R'' module ''M'' equipped with an operation called multiplication. This can be viewed as a system with five binary operations: two operations on ''R'', two on ''M'' and one involving both ''R'' and ''M''.

* [[Algebra over a ring]] (also ''R-algebra''): a module over a [[commutative ring]] ''R'', which also carries a multiplication operation that is compatible with the module structure. This includes distributivity over addition and [[Bilinear map|linearity]] with respect to multiplication by elements of ''R''. The theory of an [[algebra over a field]] is especially well developed.
* [[Associative algebra]]: an algebra over a ring such that the multiplication is [[associative property|associative]].
* [[Nonassociative algebra]]: a module over a commutative ring, equipped with a ring multiplication operation that is not necessarily associative. Often associativity is replaced with a different identity, such as [[alternative algebra|alternation]], the [[Jacobi identity]], or the [[Jordan identity]].
* [[Coalgebra]]: a vector space with a "comultiplication" defined dually to that of associative algebras.
* [[Lie algebra]]: a special type of nonassociative algebra whose product satisfies the [[Jacobi identity]].
* [[Lie coalgebra]]: a vector space with a "comultiplication" defined dually to that of Lie algebras.
* [[Graded algebra]]: a graded vector space with an algebra structure compatible with the grading. The idea is that if the grades of two elements ''a'' and ''b'' are known, then the grade of ''ab'' is known, and so the location of the product ''ab'' is determined in the decomposition.
* [[Inner product space]]: an ''F'' vector space ''V'' with a sesquilinear binary operation {{nowrap|''V'' × ''V'' → ''F''}}.

'''Four''' or more binary operations:

* [[Bialgebra]]: an associative algebra with a compatible coalgebra structure.
* [[Lie bialgebra]]: a Lie algebra with a compatible bialgebra structure.
* [[Hopf algebra]]: a bialgebra with a connection axiom (antipode).
* [[Clifford algebra]]: a graded associative algebra equipped with an [[exterior product]] from which may be derived several possible inner products.  [[Exterior algebra]]s and [[geometric algebra]]s are special cases of this construction.

== Hybrid structures ==

Algebraic structures can also coexist with added structure of non-algebraic nature, such as [[Partially ordered set#Formal definition|partial order]] or a [[topology]]. The added structure must be compatible, in some sense, with the algebraic structure.

* [[Topological group]]: a group with a topology compatible with the group operation.
* [[Lie group]]: a topological group with a compatible smooth [[manifold]] structure.
* [[Ordered group]]s, [[ordered ring]]s and [[ordered field]]s: each type of structure with a compatible [[partial order]].
* [[Archimedean group]]: a linearly ordered group for which the [[Archimedean property]] holds.
* [[Topological vector space]]: a vector space whose ''M'' has a compatible topology.
* [[Normed vector space]]: a vector space with a compatible [[norm (mathematics)|norm]]. If such a space is [[complete metric space|complete]] (as a metric space) then it is called a [[Banach space]].
* [[Hilbert space]]: an inner product space over the real or complex numbers whose inner product gives rise to a Banach space structure.
* [[Vertex operator algebra]]
* [[Von Neumann algebra]]: a *-algebra of operators on a Hilbert space equipped with the [[weak operator topology]].

== Universal algebra ==
{{main | Universal algebra}}
Algebraic structures are defined through different configurations of [[axiom]]s. [[Universal algebra]] abstractly studies such objects. One major dichotomy is between structures that are axiomatized entirely by ''identities'' and structures that are not. If all axioms defining a class of algebras are identities, then the class of objects is a [[variety (universal algebra)|variety]] (not to be confused with [[algebraic variety]] in the sense of [[algebraic geometry]]).

Identities are equations formulated using only the operations the structure allows, and variables that are tacitly [[universal quantifier|universally quantified]] over the relevant [[universe (mathematics)|universe]]. Identities contain no [[Logical connective|connectives]], [[Quantification (science)|existentially quantified variables]], or [[finitary relation|relations]] of any kind other than the allowed operations. The study of varieties is an important part of [[universal algebra]]. An algebraic structure in a variety may be understood as the [[quotient algebra]] of term algebra (also called "absolutely  [[free object|free algebra]]") divided by the equivalence relations generated by a set of identities.  So, a collection of functions with given [[signature (logic)|signatures]] generate a free algebra, the [[term algebra]] ''T''. Given a set of equational identities (the axioms), one may consider their symmetric, transitive closure ''E''.  The [[quotient algebra]] ''T''/''E'' is then the algebraic structure or variety.  Thus, for example, groups have a signature containing two operators: the multiplication operator ''m'', taking two arguments, and the inverse operator ''i'', taking one argument, and the identity element ''e'', a constant, which may be considered an operator that takes zero arguments.  Given a (countable) set of variables ''x'', ''y'', ''z'', etc. the term algebra is the collection of all possible [[term (mathematics)|terms]] involving ''m'', ''i'', ''e'' and the variables; so for example, ''m(i(x), m(x,m(y,e)))'' would be an element of the term algebra. One of the axioms defining a group is the identity ''m(x, i(x)) = e''; another is ''m(x,e) = x''. The axioms can be represented as [http://ncatlab.org/nlab/show/variety+of+algebras#examples_4 trees]. These equations induce [[equivalence class]]es on the free algebra; the quotient algebra then has the algebraic structure of a group.

Several non-variety structures fail to be varieties, because either:

# It is necessary that 0&amp;nbsp;≠&amp;nbsp;1, 0 being the additive [[identity element]] and 1 being a multiplicative identity element, but this is a nonidentity;
# Structures such as fields have some axioms that hold only for nonzero members of ''S''. For an algebraic structure to be a variety, its operations must be defined for ''all'' members of ''S''; there can be no partial operations.

Structures whose axioms unavoidably include nonidentities are among the most important ones in mathematics, e.g., [[Field (mathematics)|field]]s and [[division ring]]s. Although structures with nonidentities retain an undoubted algebraic flavor, they suffer from defects varieties do not have. For example, the product of two [[field (mathematics)|field]]s is not a field.

== Category theory ==

[[Category theory]] is another tool for studying algebraic structures (see, for example, Mac Lane 1998). A category is a collection of ''objects'' with associated ''morphisms.'' Every algebraic structure has its own notion of [[homomorphism]], namely any [[function (mathematics)|function]] compatible with the operation(s) defining the structure. In this way, every algebraic structure gives rise to a [[category theory|category]]. For example, the [[category of groups]] has all [[Group (mathematics)|groups]] as objects and all [[group homomorphism]]s as morphisms. This [[concrete category]] may be seen as a [[category of sets]] with added category-theoretic [[structure (category theory)|structure]]. Likewise, the category of [[topological group]]s (whose morphisms are the continuous group homomorphisms) is a [[category of topological spaces]] with extra structure. A [[forgetful functor]] between categories of algebraic structures "forgets" a part of a structure.

There are various concepts in category theory that try to capture the algebraic character of a context, for instance

* [[algebraic category]]
* [[essentially algebraic category]]
* [[presentable category]]
* [[locally presentable category]]
* [[Monad (category theory)|monadic]] functors and categories
* [[universal property]].

== Different meanings of "structure" ==

In a slight [[abuse of notation]], the word "structure" can also refer to just the operations on a structure, instead of the underlying set itself. For example, the sentence, "We have defined a ring ''structure'' on the set &lt;math&gt;A&lt;/math&gt;," means that we have defined [[ring (mathematics)|ring]] ''operations'' on the set &lt;math&gt;A&lt;/math&gt;. For another example, the group &lt;math&gt;(\mathbb Z, +)&lt;/math&gt; can be seen as a set &lt;math&gt;\mathbb Z&lt;/math&gt; that is equipped with an ''algebraic structure,'' namely the ''operation'' &lt;math&gt;+&lt;/math&gt;.

== See also ==
{{Portal|Mathematics}}

* [[Free object]]
* [[List of algebraic structures]]
* [[Mathematical structure]]
* [[Signature (logic)]]
* [[Structure (mathematical logic)]]

== Notes ==
{{reflist}}

== References ==

* {{Citation | last1=Mac Lane | first1=Saunders | author1-link=Saunders Mac Lane | last2=Birkhoff | first2=Garrett | author2-link=Garrett Birkhoff | title=Algebra | publisher=AMS Chelsea | edition=2nd | isbn=978-0-8218-1646-2 | year=1999}}
* {{Citation | last1=Michel | first1=Anthony N. | last2=Herget | first2=Charles J. | title=Applied Algebra and Functional Analysis | publisher=[[Dover Publications]] | location=New York | isbn=978-0-486-67598-5 | year=1993}}
* {{Citation | last1=Burris | first1=Stanley N. | last2=Sankappanavar | first2=H. P. | title=A Course in Universal Algebra | url=http://www.thoralf.uwaterloo.ca/htdocs/ualg.html | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-3-540-90578-3 | year=1981}}
; Category theory
* {{Citation | last1=Mac Lane | first1=Saunders | author1-link=Saunders Mac Lane | title=[[Categories for the Working Mathematician]] | publisher=Springer-Verlag | location=Berlin, New York | edition=2nd | isbn=978-0-387-98403-2 | year=1998}}
* {{Citation | last1=Taylor | first1=Paul | title=Practical foundations of mathematics | publisher=[[Cambridge University Press]] | isbn=978-0-521-63107-5 | year=1999}}

== External links ==

* [http://math.chapman.edu/~jipsen/structures/doku.php Jipsen's algebra structures.] Includes many structures not mentioned here.
* [http://mathworld.wolfram.com/topics/Algebra.html Mathworld] page on abstract algebra.
* [[Stanford Encyclopedia of Philosophy]]: [http://plato.stanford.edu/entries/algebra/ Algebra] by [[Vaughan Pratt]].

[[Category:Abstract algebra]]
[[Category:Algebraic structures| ]]
[[Category:Mathematical structures]]</text>
      <sha1>4mzlmy0elj6tmzae4uhlpe1hxtesqw5</sha1>
    </revision>
  </page>
  <page>
    <title>Berge's lemma</title>
    <ns>0</ns>
    <id>22577850</id>
    <revision>
      <id>845115318</id>
      <parentid>823425632</parentid>
      <timestamp>2018-06-09T13:55:12Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6334">In [[graph theory]], '''Berge's lemma''' states that a [[Matching (graph theory)|matching]] ''M'' in a [[Graph (discrete mathematics)|graph]] ''G'' is '''maximum''' (contains the largest possible number of edges) if and only if there is no '''augmenting path''' (a path that starts and ends on free (unmatched) vertices, and alternates between edges in and not in the matching) with ''M''.

It was proven by French mathematician [[Claude Berge]] in 1957 (though already observed by [[Julius Petersen|Petersen]] in 1891 and [[Dénes Kőnig|Kőnig]] in 1931).

== Proof ==
To prove Berge's lemma, we first need another [[Lemma (mathematics)|lemma]].  Take a [[Graph (discrete mathematics)|graph]] ''G'' and let ''M'' and ''M&amp;prime;'' be two [[Matching (graph theory)|matchings]] in ''G''.  Let ''G&amp;prime;'' be the resultant [[Graph (discrete mathematics)|graph]] from taking the [[symmetric difference]] of ''M'' and ''M&amp;prime;''; i.e. (''M'' - ''M&amp;prime;'') ∪ (''M&amp;prime;'' - ''M'').  ''G&amp;prime;'' will consist of connected components that are one of the following:
# An isolated [[Vertex (graph theory)|vertex]].
# An even [[Cycle (graph theory)|cycle]] whose edges alternate between ''M'' and ''M&amp;prime;''.
# A [[Path (graph theory)|path]] whose edges alternate between ''M'' and ''M&amp;prime;'', with distinct endpoints.

The [[Lemma (mathematics)|lemma]] can be proven by observing that each [[Vertex (graph theory)|vertex]] in ''G&amp;prime;'' can be incident to at most 2 edges: one from ''M'' and one from ''M&amp;prime;''.  Graphs where every vertex has degree less than or equal to 2 must consist of either isolated [[Vertex (graph theory)|vertices]], [[Cycle (graph theory)|cycles]], and [[Path (graph theory)|paths]].  Furthermore, each path and cycle in ''G&amp;prime;'' must alternate between ''M'' and ''M&amp;prime;''.  In order for a [[Cycle (graph theory)|cycle]] to do this, it must have an equal number of edges from ''M'' and ''M&amp;prime;'', and therefore be of even length.

Let us now prove the [[contrapositive]] of Berge's lemma: ''G'' has a [[Matching (graph theory)|matching]] larger than ''M'' if and only if ''G'' has an augmenting path. Clearly, an augmenting path ''P'' of ''G'' can be used to produce a [[Matching (graph theory)|matching]] ''M&amp;prime;'' that is larger than ''M'' — just take ''M&amp;prime;'' to be the [[symmetric difference]] of ''P'' and ''M'' (''M&amp;prime;'' contains exactly those edges of ''G'' that appear in exactly one of ''P'' and ''M''). Hence, the reverse direction follows.

For the forward direction, let ''M&amp;prime;'' be a [[Matching (graph theory)|matching]] in ''G'' larger than ''M''. Consider ''D'', the symmetric difference of ''M'' and ''M&amp;prime;''. Observe that ''D'' consists of paths and even [[Cycle (graph theory)|cycles]] (as observed by the earlier [[Lemma (mathematics)|lemma]]). Since ''M&amp;prime;'' is larger than ''M'', ''D'' contains a component that has more edges from ''M&amp;prime;'' than ''M''. Such a component is a path in ''G'' that starts and ends with an edge from ''M&amp;prime;'', so it is an augmenting path.

== Corollaries ==
=== Corollary 1 ===
Let ''M'' be a maximum matching and consider an alternating chain such that the edges in the path alternates between being and not being in ''M''.  If the alternating chain is a [[Cycle (graph theory)|cycle]] or a [[Path (graph theory)|path]] of even length, then a new maximum matching ''M&amp;prime;'' can be found by interchanging the edges found in ''M'' and not in ''M''.  For example, if the alternating chain is (''m''&lt;sub&gt;1&lt;/sub&gt;, ''n''&lt;sub&gt;1&lt;/sub&gt;, ''m''&lt;sub&gt;2&lt;/sub&gt;, ''n''&lt;sub&gt;2&lt;/sub&gt;, ...), where ''m''&lt;sub&gt;i&lt;/sub&gt; &amp;isin; ''M'' and ''n''&lt;sub&gt;i&lt;/sub&gt; &amp;notin; ''M'', interchanging them would make all ''n''&lt;sub&gt;i&lt;/sub&gt; part of the new matching and make all ''m''&lt;sub&gt;i&lt;/sub&gt; not part of the matching.

=== Corollary 2 ===
An edge is considered "free" if it belongs to a maximum matching  but does not belong to all maximum matchings.  An edge ''e'' is free if and only if, in an arbitrary maximum matching ''M'', edge ''e'' belongs to an even alternating path starting at an unmatched vertex or to an alternating [[Cycle (graph theory)|cycle]].  By the first corollary, if edge ''e'' is part of such an alternating chain, then a new maximum matching, ''M&amp;prime;'', must exist and ''e'' would exist either in ''M'' or ''M&amp;prime;'', and therefore be free.  Conversely, if edge ''e'' is free, then ''e'' is in some maximum matching ''M'' but not in ''M&amp;prime;''.  Since ''e'' is not part of both ''M'' and ''M&amp;prime;'', it must still exist after taking the [[symmetric difference]] of ''M'' and ''M&amp;prime;''.  The [[symmetric difference]] of ''M'' and ''M&amp;prime;'' results in a [[Graph (discrete mathematics)|graph]] consisting of isolated vertices, even alternating cycles, and alternating paths.  Suppose to the contrary that ''e'' belongs to some odd-length path component.  But then one of ''M'' and ''M&amp;prime;'' must have one fewer edge than the other in this component, meaning that the component as a whole is an augmenting path with respect to that matching.  By the original lemma, then, that matching (whether ''M'' or ''M&amp;prime;'') cannot be a maximum matching, which contradicts the assumption that both ''M'' and ''M&amp;prime;'' are maximum.  So, since ''e'' cannot belong to any odd-length path component, it must either be in an alternating cycle or an even-length alternating path.

== References ==
* {{Citation
 | first = Claude
 | last = Berge
 | author-link = Claude Berge
 | journal = [[Proceedings of the National Academy of Sciences of the United States of America]]
 | pages = 842–844
 | title = Two theorems in graph theory
 | volume = 43
 | issue = 9
 | date = September 15, 1957
 | url = http://www.pnas.org/content/43/9/842.full.pdf
 | doi=10.1073/pnas.43.9.842| pmc = 534337
 }}.
* {{Citation
 | first = Douglas B.
 | last = West
 | author-link = Douglas West (mathematician)
 | year = 2001
 | title = Introduction to Graph Theory
 | edition = 2nd
 | publisher = Pearson Education, Inc.
 | isbn = 81-7808-830-4
 | pages = 109–110}}.
* {{Citation
 | first = Claude
 | last = Berge
 | author-link = Claude Berge
 | year = 1973
 | title = Graphs and Hypergraphs
 | publisher = North-Holland Publishing Company
 | isbn = 0-444-10399-6
 | pages = 122–125}}.

[[Category:Matching]]
[[Category:Lemmas]]</text>
      <sha1>m7y3tzggy6zn2m0heq0i2dectqcveu0</sha1>
    </revision>
  </page>
  <page>
    <title>Cartan's lemma</title>
    <ns>0</ns>
    <id>27440323</id>
    <revision>
      <id>790696335</id>
      <parentid>692570054</parentid>
      <timestamp>2017-07-15T13:41:29Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; (5) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2447">In [[mathematics]], '''Cartan's lemma''' refers to a number of results named after either [[Élie Cartan]] or his son [[Henri Cartan]]:
* In [[exterior algebra]]:&lt;ref&gt;*{{cite book | last = Sternberg | first = S. | year = 1983 | title = Lectures on Differential Geometry | edition = (2nd ed.) | publisher = Chelsea Publishing Co. | location = New York | isbn = 0-8218-1385-4 | oclc = 43032711 | page=18}}&lt;/ref&gt; Suppose that ''v''&lt;sub&gt;1&lt;/sub&gt;, ..., ''v''&lt;sub&gt;''p''&lt;/sub&gt; are linearly independent elements of a vector space ''V'' and ''w''&lt;sub&gt;1&lt;/sub&gt;, ..., ''w''&lt;sub&gt;''p''&lt;/sub&gt; are such that
::&lt;math&gt;v_1\wedge w_1 + \cdots + v_p\wedge w_p = 0&lt;/math&gt;
:in &amp;Lambda;''V''.  Then there are scalars ''h''&lt;sub&gt;''ij''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;''ji''&lt;/sub&gt; such that
::&lt;math&gt;w_i = \sum_{j=1}^p h_{ij}v_j.&lt;/math&gt;

* In [[several complex variables]]:&lt;ref&gt;{{cite book
 | author = [[Robert C. Gunning]] and [[Hugo Rossi]]
 | title = Analytic Functions of Several Complex Variables
 | publisher = Prentice-Hall
 | year = 1965|pages= 199}}&lt;/ref&gt; Let {{nowrap|''a''&lt;sub&gt;1&lt;/sub&gt; &lt; ''a''&lt;sub&gt;2&lt;/sub&gt; &lt; ''a''&lt;sub&gt;3&lt;/sub&gt; &lt; ''a''&lt;sub&gt;4&lt;/sub&gt;}} and {{nowrap|''b''&lt;sub&gt;1&lt;/sub&gt; &lt; ''b''&lt;sub&gt;2&lt;/sub&gt;}} and define rectangles in the complex plane '''C''' by
::&lt;math&gt;\begin{align}
K_1 &amp;= \{ z_1=x_1+iy_1 | a_2 &lt; x_1 &lt; a_3, b_1 &lt; y_1 &lt; b_2\} \\
K_1' &amp;= \{ z_1=x_1+iy_1 | a_1 &lt; x_1 &lt; a_3, b_1 &lt; y_1 &lt; b_2\} \\
K_1'' &amp;= \{ z_1=x_1+iy_1 | a_2 &lt; x_1 &lt; a_4, b_1 &lt; y_1 &lt; b_2\}
\end{align}&lt;/math&gt;
:so that &lt;math&gt;K_1 = K_1'\cap K_1''&lt;/math&gt;.  Let ''K''&lt;sub&gt;2&lt;/sub&gt;, ..., ''K''&lt;sub&gt;''n''&lt;/sub&gt; be simply connected domains in '''C''' and let
::&lt;math&gt;\begin{align}
K &amp;= K_1\times K_2\times\cdots \times K_n\\
K' &amp;= K_1'\times K_2\times\cdots \times K_n\\
K'' &amp;= K_1''\times K_2\times\cdots \times K_n
\end{align}&lt;/math&gt;
:so that again &lt;math&gt;K = K'\cap K''&lt;/math&gt;.  Suppose that ''F''(''z'') is a complex analytic matrix-valued function on a rectangle ''K'' in '''C'''&lt;sup&gt;''n''&lt;/sup&gt; such that ''F''(''z'') is an invertible matrix for each ''z'' in ''K''.  Then there exist analytic functions &lt;math&gt;F'&lt;/math&gt; in &lt;math&gt;K'&lt;/math&gt; and &lt;math&gt;F''&lt;/math&gt; in  &lt;math&gt;K''&lt;/math&gt; such that
::&lt;math&gt;F(z) = F'(z)F''(z)&lt;/math&gt;
:in ''K''.

* In [[potential theory]], a result that estimates the [[Hausdorff measure]] of the set on which a logarithmic [[Newtonian potential]] is small.  See [[Cartan's lemma (potential theory)]].

==References==

{{reflist}}


[[Category:Lemmas]]
{{SIA|mathematics}}</text>
      <sha1>ne5051h4c1jxpeqq3uhzaubp263r8nk</sha1>
    </revision>
  </page>
  <page>
    <title>Central moment</title>
    <ns>0</ns>
    <id>19983</id>
    <revision>
      <id>866322488</id>
      <parentid>866322354</parentid>
      <timestamp>2018-10-29T17:30:03Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Multivariate moments */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7465">{{Refimprove|date=September 2014}}
In [[probability theory]] and [[statistics]], a '''central moment''' is a [[moment (mathematics)|moment]] of a [[probability distribution]] of a [[random variable]] about the random variable's [[mean]]; that is, it is the [[expected value]] of a specified integer power of the deviation of the random variable from the mean. The various moments form one set of values by which the properties of a probability distribution can be usefully characterised. Central moments are used in preference to ordinary moments, computed in terms of deviations from the mean instead of from zero, because the higher-order central moments relate only to the spread and shape of the distribution, rather than also to its [[location parameter|location]].

Sets of central moments can be defined for both univariate and multivariate distributions.

==Univariate moments==

The ''n''th [[moment (mathematics)|moment]] about the [[mean]] (or ''n''th '''central moment''') of a real-valued [[random variable]] ''X'' is the quantity ''μ''&lt;sub&gt;''n''&lt;/sub&gt; := E[(''X''&amp;nbsp;&amp;minus;&amp;nbsp;E[''X''])&lt;sup&gt;''n''&lt;/sup&gt;], where E is the [[expected value|expectation operator]]. For a [[continuous probability distribution|continuous]] [[univariate]] [[probability distribution]] with [[probability density function]] ''f''(''x''), the ''n''th moment about the mean ''μ'' is
:&lt;math&gt; \mu_n = \operatorname{E} \left[ ( X - \operatorname{E}[X] )^n \right]  = \int_{-\infty}^{+\infty} (x - \mu)^n f(x)\,\mathrm{d} x. &lt;/math&gt;&lt;ref name="ProbRand"&gt;{{cite book | title=Probability and Random Processes | publisher=Oxford University Press |author1=Grimmett, Geoffrey  |author2=Stirzaker, David | year=2009 | location=Oxford, England | isbn=978 0 19 857222 0}}&lt;/ref&gt;

For random variables that have no mean, such as the [[Cauchy distribution]], central moments are not defined.

The first few central moments have intuitive interpretations:
* The "zeroth" central moment ''μ''&lt;sub&gt;0&lt;/sub&gt; is 1.
* The first central moment ''μ''&lt;sub&gt;1&lt;/sub&gt; is 0 (not to be confused with the first [[raw moment]]s or the [[expected value]] ''μ'').
* The second central moment ''μ''&lt;sub&gt;2&lt;/sub&gt; is called the [[variance]], and is usually denoted ''σ''&lt;sup&gt;2&lt;/sup&gt;, where σ represents the [[standard deviation]].
* The third and fourth central moments are used to define the [[standardized moment]]s which are used to define [[skewness]] and [[kurtosis]], respectively.

===Properties===
The ''n''th central moment is translation-invariant, i.e. for any random variable ''X'' and any constant ''c'', we have

:&lt;math&gt;\mu_n(X+c)=\mu_n(X).\,&lt;/math&gt;

For all ''n'', the ''n''th central moment is [[Homogeneous function|homogeneous]] of degree ''n'':

:&lt;math&gt;\mu_n(cX)=c^n\mu_n(X).\,&lt;/math&gt;

''Only'' for ''n'' such that n equals 1, 2, or 3 do we have an additivity property for random variables ''X'' and ''Y'' that are [[statistical independence|independent]]:

:&lt;math&gt;\mu_n(X+Y)=\mu_n(X)+\mu_n(Y)\,&lt;/math&gt; provided ''n'' ∈ {{math|{1, 2, 3}}}.

A related functional that shares the translation-invariance and homogeneity properties with the ''n''th central moment, but continues to have this additivity property even when ''n''&amp;nbsp;≥&amp;nbsp;4 is the ''n''th [[cumulant]] κ&lt;sub&gt;''n''&lt;/sub&gt;(''X'').  For ''n''&amp;nbsp;=&amp;nbsp;1, the ''n''th cumulant is just the [[expected value]]; for ''n''&amp;nbsp;= either 2 or 3, the ''n''th cumulant is just the ''n''th central moment; for ''n''&amp;nbsp;≥&amp;nbsp;4, the ''n''th cumulant is an ''n''th-degree monic polynomial in the first ''n'' moments (about zero), and is also a (simpler) ''n''th-degree polynomial in the first ''n'' central moments.

===Relation to moments about the origin===
Sometimes it is convenient to convert moments about the origin to moments about the mean. The general equation for converting the ''n''th-order moment about the origin to the moment about the mean is

:&lt;math&gt;
\mu_n = \operatorname{E}\left[\left(X - \operatorname{E}[X]\right)^n\right] = \sum_{j=0}^n {n \choose j} (-1) ^{n-j} \mu'_j \mu^{n-j},
&lt;/math&gt;

where ''μ'' is the mean of the distribution, and the moment about the origin is given by

:&lt;math&gt;
\mu'_m = \int_{-\infty}^{+\infty} x^m f(x)\,dx = \operatorname{E}[X^m] = \sum_{j=0}^m {m \choose j}  \mu_j \mu^{m-j}.
&lt;/math&gt;

For the cases ''n'' = 2, 3, 4 — which are of most interest because of the relations to [[variance]], [[skewness]], and [[kurtosis]], respectively — this formula becomes (noting that &lt;math&gt;\mu = \mu'_1&lt;/math&gt; and &lt;math&gt;\mu'_0=1&lt;/math&gt;):,

:&lt;math&gt;\mu_2 = \mu'_2 - \mu^2\,&lt;/math&gt; which is commonly [[Algebraic formula for the variance|referred to]] as &lt;math&gt; \operatorname{Var}(X) = \operatorname{E}[X^2] - \left(\operatorname{E}[X]\right)^2&lt;/math&gt;

:&lt;math&gt;\mu_3 = \mu'_3 - 3 \mu \mu'_2 +2 \mu^3\,&lt;/math&gt;

:&lt;math&gt;\mu_4 = \mu'_4 - 4 \mu \mu'_3 + 6 \mu^2 \mu'_2 - 3 \mu^4.\,&lt;/math&gt;

... and so on,&lt;ref&gt;http://mathworld.wolfram.com/CentralMoment.html&lt;/ref&gt; following [[Pascal's triangle]], i.e.

:&lt;math&gt;\mu_5 = \mu'_5 - 5 \mu \mu'_4 + 10 \mu^2 \mu'_3 - 10 \mu^3 \mu'_2 + 4 \mu^5.\,&lt;/math&gt;

because &lt;math&gt; 5\mu^4\mu'_1 - \mu^5 \mu'_0 = 5\mu^4\mu - \mu^5 = 5 \mu^5 - \mu^5 = 4 \mu^5&lt;/math&gt;

The following sum is a stochastic variable having a '''''compound distribution'''''

:&lt;math&gt;W = \sum_{i=1}^M Y_i, &lt;/math&gt;

where the &lt;math&gt;Y_i&lt;/math&gt; are mutually independent random variables sharing the same common distribution and &lt;math&gt;M&lt;/math&gt; a random integer variable independent of the &lt;math&gt;Y_k&lt;/math&gt; with its own distribution. The moments of &lt;math&gt;W&lt;/math&gt; are obtained as &lt;ref&gt;{{cite journal
| last1 = Grubbström | first1 = Robert W.
| last2 = Tang | first2 = Ou
| doi = 10.1016/j.ejor.2004.06.012
| title = The moments and central moments of a compound distribution
| journal = European Journal of Operational Research
| volume = 170
| pages = 106–119
| year = 2006}}&lt;/ref&gt;

:&lt;math&gt;\operatorname{E}[W^n]= \sum_{i=0}^n\operatorname{E}\left[{M \choose i}\right]\sum_{j=0}^i {i \choose j}(-1)^{i-j}\operatorname{E} \left[ \left(\sum_{k=1}^j Y_k\right)^n \right],         &lt;/math&gt;

where &lt;math&gt;\operatorname{E} \left[ \left(\sum_{k=1}^j Y_k\right)^n\right] &lt;/math&gt; is defined as zero for &lt;math&gt;j=0&lt;/math&gt;.

===Symmetric distributions===

In a [[symmetric distribution]] (one that is unaffected by being [[reflection (mathematics)|reflected]] about its mean), all odd central moments equal zero, because in the formula for the ''n''th moment, each term involving a value of ''X'' less than the mean by a certain amount exactly cancels out the term involving a value of ''X'' greater than the mean by the same amount.

==Multivariate moments==

For a [[continuous probability distribution|continuous]] [[Joint probability distribution|bivariate]] [[probability distribution]] with [[probability density function]] ''f''(''x'',''y'') the (''j'',''k'') moment about the mean ''μ''&amp;nbsp;=&amp;nbsp;(''μ''&lt;sub&gt;''X''&lt;/sub&gt;,&amp;nbsp;''μ''&lt;sub&gt;''Y''&lt;/sub&gt;) is
:&lt;math&gt; \mu_{j,k} = \operatorname{E} \left[ ( X - \operatorname{E}[X] )^j ( Y - \operatorname{E}[Y] )^k \right]  = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} (x - \mu_X)^j (y - \mu_Y)^k f(x,y )\,dx \,dy. &lt;/math&gt;

==See also==
*[[Standardized moment]]
*[[Image moment]]
*[[Normal distribution#Moments]]

==References==
{{Reflist}}

{{Theory of probability distributions}}

{{DEFAULTSORT:Central Moment}}
[[Category:Statistical deviation and dispersion]]
[[Category:Moment (mathematics)]]

[[fr:Moment (mathématiques)#Moment centré]]</text>
      <sha1>bb2b9p0g2sm21zu34np70u8jxjow3dn</sha1>
    </revision>
  </page>
  <page>
    <title>Christos Papadimitriou</title>
    <ns>0</ns>
    <id>3509428</id>
    <revision>
      <id>869179233</id>
      <parentid>867687851</parentid>
      <timestamp>2018-11-16T22:33:22Z</timestamp>
      <contributor>
        <ip>216.38.141.242</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11587">{{for|the Greek footballer|Christos Papadimitriou (footballer)}}
{{Infobox scientist
| name        = Christos Papadimitriou
| native_name_lang =
| image       =   Christos Papadimitriou mg 7721-b.cr2.jpg
| imagesize   =
| alt         =
| caption     =
| birth_name = {{Plainlist|
* Christos Harilaos Papadimitriou
* [[Greek language|Greek]]: Χρήστος Χαρίλαος Παπαδημητρίου}}
| birth_date  =   {{birth date and age|1949|08|16}}
| birth_place = [[Athens]]
| death_date  =   &lt;!--{{death date and age |2015|03|03 |1948|08|16}} (death date then birth date)--&gt;
| resting_place =
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names =
| residence   =
| citizenship =
| nationality =
| fields      = {{Plainlist|
* [[Algorithm]]s
*  [[Computational complexity theory|Complexity]]
* [[Game theory]]
* [[Education]]
* [[Evolution]]&lt;ref name=googlescholar/&gt;}}
| workplaces  = {{Plainlist|
* [[University of California, Berkeley]]
* [[Columbia University]]&lt;ref&gt;{{cite web
 | url=http://www.cs.columbia.edu/people/faculty/
 | title=Columbia Faculty
 | accessdate=2017-08-05}}&lt;/ref&gt;
* [[Harvard University]]
*  [[Massachusetts Institute of Technology|MIT]]
* [[National Technical University of Athens|Athens Polytechnic]]
* [[Stanford University]]
* [[University of California, San Diego|UCSD]]}}
| patrons     =
| alma_mater  = {{Plainlist|
* [[National Technical University of Athens|Athens Polytechnic]] (BS) 
* [[Princeton University]] (PhD)}}
| thesis_title =  The Complexity of Combinatorial Optimization Problems
| thesis_url  =   http://dl.acm.org/citation.cfm?id=908113
| thesis_year =   1972
| doctoral_advisor = [[Kenneth Steiglitz]]&lt;ref name=mathgene&gt;{{MathGenealogy|id=46289}}&lt;/ref&gt;
| academic_advisors =
| doctoral_students = {{Plainlist|
* [[Constantinos Daskalakis]]
* [[Paris Kanellakis]]
* [[:de:Elias Koutsoupias|Elias Koutsoupias]]
* [[Joseph S. B. Mitchell|Joseph Mitchell]]
* [[Chris Umans|Christopher Umans]]
&lt;!--* [[Aviad Rubinstein]]--&gt;
}}
| notable_students =
| known_for   =
| influences  =
| influenced  =
| awards      = {{Plainlist|
* [[IEEE John von Neumann Medal|Von Neumann Medal]] (2016)
* [[EATCS Award]] (2015)
* [[Gödel Prize]] (2012)
* [[International Parallel and Distributed Processing Symposium#IEEE Computer Society Charles Babbage Award|IEEE Computer Society Charles Babbage Award]] (2004)
* [[Knuth Prize]] (2002)}}
| signature   =   &lt;!--(filename only)--&gt;
| signature_alt =
| website     =   {{URL|http://www.cs.berkeley.edu/~christos}}
| footnotes   =
| spouse      =   &lt;!--(or | spouses = )--&gt;
| children    =
| education   =
| partner     =   &lt;!--(or | partners = )--&gt;
}}

'''Christos Harilaos Papadimitriou''' ([[Greek language|Greek]]: Χρήστος Χαρίλαος Παπαδημητρίου; born August 16, 1949) is a [[Greeks|Greek]] theoretical computer scientist, and professor of Computer Science at [[University of California, Berkeley]].&lt;ref name=googlescholar&gt;{{GoogleScholar|ZDvxbWYAAAAJ}}&lt;/ref&gt;&lt;ref name=acm&gt;{{ACMPortal|id=81100635501}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | pmid = 25349396
| pmc = 4234580
| year = 2014
| author1 = Ahmed
| first1 = F
| title = Profile of Christos Papadimitriou
| journal = Proceedings of the National Academy of Sciences
| doi = 10.1073/pnas.1405579111
 | volume=111
 | issue = 45
| pages=15858–60
}}&lt;/ref&gt;&lt;ref name=dblp&gt;{{DBLP|name=Christos H. Papadimitriou}}&lt;/ref&gt;&lt;ref name=scopus&gt;{{Scopus|id=35597590700}}&lt;/ref&gt;

==Education==
Papadimitriou studied at the [[National Technical University of Athens]], where in 1972 he received his [[Bachelor of Arts]] degree in [[Electrical Engineering]]. He continued to study at [[Princeton University]], where he received his [[Master of Science|MS]] in Electrical Engineering in 1974 and his [[PhD]] in Electrical Engineering and [[Computer Science]] in 1976.

==Career==
Papadimitriou has taught at [[Harvard]], [[MIT]], the [[National Technical University of Athens]], [[Stanford]], [[UCSD]], [[University of California, Berkeley]] and is currently the Donovan Family Professor of Computer Science at Columbia University.

Papadimitriou co-authored a paper on [[pancake sorting]] with [[Bill Gates]], then a Harvard undergraduate.  Papadimitriou recalled "Two years later, I called to tell him our paper had been accepted to a fine math journal. He sounded eminently disinterested. He had moved to Albuquerque, New Mexico to run [[Microsoft|a small company writing code for microprocessors]], of all things. I remember thinking: 'Such a brilliant kid. What a waste.'"&lt;ref&gt;{{Cite news|url=http://www.businessinsider.com/a-story-about-bill-gatess-intelligence-2015-11|title=Professor who knew Bill Gates as a student at Harvard: He was the smartest person I've ever met|work=Business Insider|access-date=2018-05-06}}&lt;/ref&gt;

In 2001, Papadimitriou was inducted as a [[Fellow]] of the [[Association for Computing Machinery]] and in 2002 he was awarded the [[Knuth Prize]]. He became fellow of the U.S. [[National Academy of Engineering]] for contributions to complexity theory, database theory, and combinatorial optimization.&lt;ref&gt;{{cite web
 | url=https://www.nae.edu/MembersSection/MemberDirectory/30537.aspx
 | title=Member Directory at NAE Website
 | accessdate=2017-07-22}}&lt;/ref&gt;  In 2009 he was elected to the US [[United States National Academy of Sciences|National Academy of Sciences]]. During the 36th [[International Colloquium on Automata, Languages and Programming]] (ICALP 2009), there was a special event honoring Papadimitriou's contributions to computer science.&lt;ref&gt;{{cite web
 | url=http://icalp09.cti.gr/index.php/Main/SpecialEvents
 | title=Special Events: Honoring Christos Papadimitriou Scientific Contribution to Computer Science
 | work=ICALP 2009 – 36th International Colloquium on Automata, Languages and Programming
 | deadurl=yes
 | archiveurl=https://web.archive.org/web/20120306104025/http://icalp09.cti.gr/index.php/Main/SpecialEvents
 | archivedate=March 6, 2012
 | df=
 }}  &lt;/ref&gt; In 2012, he, along with Elias Koutsoupias, was awarded the [[Gödel Prize]] for their joint work on the concept of the [[price of anarchy]].&lt;ref name=SIGACT-Godel&gt;{{cite news|title=Three Papers Cited for Laying Foundation of Growth in Algorithmic Game Theory|url=http://www.acm.org/press-room/news-releases/2012/goedel-prize-2012|accessdate=16 May 2012|date=16 May 2012|deadurl=yes|archiveurl=https://web.archive.org/web/20130718154540/http://www.acm.org/press-room/news-releases/2012/goedel-prize-2012|archivedate=18 July 2013|df=}}&lt;/ref&gt;

Papadimitriou is the author of the textbook ''Computational Complexity'', one of the most widely used textbooks in the field of [[computational complexity theory]]. He has also co-authored the textbook ''Algorithms'' (2006) with Sanjoy Dasgupta and [[Umesh Vazirani]], and the graphic novel ''[[Logicomix]]'' (2009)&lt;ref&gt;[http://www.logicomix.com/en Logicomix]&lt;/ref&gt; with [[Apostolos Doxiadis]].

His name was listed in the 19th position on the [[CiteSeer]] search engine academic database and digital library{{citation needed|reason=This claim needs a source|date=January 2017}}.

==Honors and awards==
In 1997, Papadimitriou received a [[Doctorate honoris causa|doctorate ''honoris causa'']] from the [[ETH Zurich]].&lt;ref&gt;{{cite web|title=Honorary Doctorates, Department of Computer Science|url=https://www.inf.ethz.ch/people/honorary-doctors.html|accessdate= 2017-07-22}}&lt;/ref&gt;

In 2011, Papadimitriou received a [[Doctorate honoris causa|doctorate ''honoris causa'']] from the [[National Technical University of Athens]].&lt;ref&gt;{{cite web|title=Live feed from the Award Ceremony of an honorary doctorate from the NTUA to the UC Berkeley Professor Chr. Papadimitriou|url=http://live.grnet.gr/papadimitriou_ntua-20110524/|accessdate=2014-06-17|deadurl=yes|archiveurl=https://web.archive.org/web/20160303215224/http://live.grnet.gr/papadimitriou_ntua-20110524/|archivedate=2016-03-03|df=}}&lt;/ref&gt;

In 2013, Papadimitriou received a [[Doctorate honoris causa|doctorate ''honoris causa'']] from the [[École polytechnique fédérale de Lausanne|École polytechnique fédérale de Lausanne (EPFL)]].

Papadimitriou was awarded the [[IEEE John von Neumann Medal]] in 2016, the  [[EATCS Award]] in 2015, the [[Gödel Prize]] in 2012, the [[International Parallel and Distributed Processing Symposium#IEEE Computer Society Charles Babbage Award|IEEE Computer Society Charles Babbage Award]] in 2004, and the [[Knuth Prize]] in 2002.

==Publications==
* ''Elements of the Theory of Computation'' (with [[Harry R. Lewis]]). [[Prentice-Hall]], 1982; second edition September 1997. [https://archive.is/20130107155418/http://www.kritiki.gr/lewis_papadimitriou greek edition]
* ''Combinatorial Optimization: Algorithms and Complexity'' (with [[Kenneth Steiglitz]]).  Prentice-Hall, 1982; second edition, Dover, 1998.
* ''The Theory of Database Concurrency Control''. CS Press, 1986.
* ''Computational Complexity''. [[Addison Wesley]], 1994.
* ''Turing (a Novel about Computation).'' [[MIT Press]], November 2003.
* ''Life Sentence to Hackers?'' (in Greek). Kastaniotis Editions, 2004. A compilation of articles written for the Greek newspaper [[To Vima]].
* ''Algorithms'' (coauthored with Sanjoy Dasgupta and [[Umesh Vazirani]]). [[McGraw-Hill]], September 2006
* ''[[Logicomix]], An Epic Search for Truth'' (coauthored with [[Apostolos Doxiadis]], with artwork by Alecos Papadatos and Annie di Donna). [[Bloomsbury Publishing]] and Bloomsbury USA, September 2009.
* He co-authored a paper with [[Bill Gates]], co-founder of [[Microsoft]], on [[pancake sorting]].&lt;ref&gt;Gates W.H.; Papadimitriou, C.H. [https://dx.doi.org/10.1016/0012-365X(79)90068-2 Bounds for sorting by prefix reversal]. ''Discrete Math.'' 27 (1979), 47–57.&lt;/ref&gt;

==Personal life==
At UC Berkeley, in 2006, he joined a professor-and-graduate-student band called Lady X and The Positive Eigenvalues.&lt;ref&gt;{{Cite web|url=http://www.coe.berkeley.edu/engnews/Spring07/EN04S/band.html |title=Engineers rock — Out of the EECS department comes a hot new band |accessdate=2013-12-29 |deadurl=yes |archiveurl=https://web.archive.org/web/20130531004254/http://coe.berkeley.edu/engnews/Spring07/EN04S/band.html |archivedate=May 31, 2013 }}&lt;/ref&gt;

==References==
{{Reflist|2}}

{{Commons category|Christos Papadimitriou}}

{{Knuth Prize laureates}}
{{Gödel winners}}

{{Authority control}}

{{DEFAULTSORT:Papadimitriou, Christos}}
[[Category:American computer scientists]]
[[Category:Greek computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:1949 births]]
[[Category:Living people]]
[[Category:American technology writers]]
[[Category:American writers of Greek descent]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Gödel Prize laureates]]
[[Category:Knuth Prize laureates]]
[[Category:Harvard University faculty]]
[[Category:Stanford University School of Engineering faculty]]
[[Category:University of California, San Diego faculty]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:University of California, Berkeley College of Engineering faculty]]
[[Category:Greek emigrants to the United States]]
[[Category:Scientists from California]]
[[Category:National Technical University of Athens alumni]]
[[Category:Princeton University alumni]]
[[Category:20th-century American scientists]]
[[Category:21st-century American scientists]]
[[Category:Game theorists]]</text>
      <sha1>k0bgg1l8aign75lr91v4k4jw4adee3f</sha1>
    </revision>
  </page>
  <page>
    <title>Circuit rank</title>
    <ns>0</ns>
    <id>1483049</id>
    <revision>
      <id>841428033</id>
      <parentid>828875688</parentid>
      <timestamp>2018-05-15T19:48:38Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11774">[[File:6n-graf.svg|thumb|upright=1.3|This graph has circuit rank {{math|1=''r'' = 2}} because it can be made into a tree by removing two edges, for instance the edges 1–2 and 2–3, but removing any one edge leaves a cycle in the graph.]]
In [[graph theory]], a branch of [[mathematics]], the '''circuit rank''', '''cyclomatic number''', '''cycle rank''', or '''nullity''' of an [[undirected graph]] is the minimum number of  edges that must be removed from the graph to break all its [[cycle (graph theory)|cycles]], making it into a [[tree (graph theory)|tree]] or forest. Alternatively, it can be interpreted as the number of independent cycles in the graph. Unlike the corresponding [[feedback arc set]] problem for [[directed graph]]s, the circuit rank {{mvar|r}} is easily computed using the formula
:&lt;math&gt;r = m - n + c&lt;/math&gt;,
where {{mvar|m}} is the number of edges in the given graph, {{mvar|n}} is the number of [[vertex (graph theory)|vertices]], and {{mvar|c}} is the number of [[Connected component (graph theory)|connected components]].
&lt;ref name="berge"&gt;{{citation|title=The Theory of Graphs|first=Claude|last=Berge|authorlink=Claude Berge|publisher=Courier Dover Publications|year=2001|isbn=9780486419756|pages=27–30|contribution=Cyclomatic number|url=https://books.google.com/books?id=h5BjnaoKyOwC&amp;pg=PA27}}.&lt;/ref&gt; It is also possible to construct a minimum-size set of edges that breaks all cycles efficiently, either using a [[greedy algorithm]] or by complementing a [[spanning forest]].

The circuit rank can be explained in terms of [[algebraic graph theory]] as the dimension of the [[cycle space]] of a graph, in terms of [[matroid theory]] as the corank of a [[graphic matroid]], and in terms of [[topology]] as one of the [[Betti number]]s of a topological space derived from the graph. It counts the ears in an [[ear decomposition]] of the graph, forms the basis of [[parameterized complexity]] on almost-trees, and has been applied in [[software metric]]s as part of the definition of [[cyclomatic complexity]] of a piece of code. Under the name of cyclomatic number, the concept was introduced by [[Gustav Kirchhoff]].&lt;ref name="Kotiuga2010"&gt;{{cite book|author=Peter Robert Kotiuga|title=A Celebration of the Mathematical Legacy of Raoul Bott|url=https://books.google.com/books?id=mqLXi0FRIZwC&amp;pg=PA20|year=2010|publisher=American Mathematical Soc.|isbn=978-0-8218-8381-5|page=20}}&lt;/ref&gt;&lt;ref name="Hage1996"&gt;{{cite book|author=Per Hage|title=Island Networks: Communication, Kinship, and Classification Structures in Oceania|url=https://books.google.com/books?id=ZBdLknuP0BYC&amp;pg=PA48|year=1996|publisher=Cambridge University Press|isbn=978-0-521-55232-5|page=48}}&lt;/ref&gt;

==Matroid rank and construction of a minimum feedback edge set==
The circuit rank of a graph {{mvar|G}} may be described using [[matroid theory]] as the [[matroid rank|corank]] of the [[graphic matroid]] of {{mvar|G}}.&lt;ref&gt;{{citation|title=Graphs and Hypergraphs|volume=6|series=North-Holland Mathematical Library|first=Claude|last=Berge|authorlink=Claude Berge|publisher=Elsevier|year=1976|isbn=9780720424539|page=477|url=https://books.google.com/books?id=Wy2mhanRnk4C&amp;pg=PA477}}.&lt;/ref&gt; Using the greedy property of matroids, this means that one can find a minimum set of edges that breaks all cycles using a [[greedy algorithm]] that at each step chooses an edge that belongs to at least one cycle of the remaining graph.

Alternatively, a minimum set of edges that breaks all cycles can be found by constructing a [[spanning forest]] of {{mvar|G}} and choosing the [[Complement (set theory)|complementary]] set of edges that do not belong to the spanning forest.

==The number of independent cycles==
In [[algebraic graph theory]], the circuit rank is also the dimension of the [[cycle space]] of &lt;math&gt;G&lt;/math&gt;. Intuitively, this can be explained as meaning that the circuit rank counts the number of independent cycles in the graph, where a collection of cycles is independent if it is not possible to form one of the cycles as the [[symmetric difference]] of some subset of the others.&lt;ref name="berge"/&gt;

This count of independent cycles can also be explained using [[homology theory]], a branch of [[topology]]. Any graph {{mvar|G}} may be viewed as an example of a 1-dimensional [[simplicial complex]], a type of [[topological space]] formed by representing each graph edge by a [[line segment]] and gluing these line segments together at their endpoints.
The cyclomatic number is the [[Rank of an abelian group|rank]] of the first (integer) [[homology group]] of this complex,&lt;ref&gt;{{citation|title=Trees|first=Jean-Pierre|last=Serre|authorlink=Jean-Pierre Serre|page=23|publisher=Springer|series=Springer Monographs in Mathematics|year=2003|url=https://books.google.com/books?id=MOAqeoYlBMQC&amp;pg=PA23}}.&lt;/ref&gt;
:&lt;math&gt;r = \operatorname{rank}\left[H_1(G,\Z)\right].&lt;/math&gt;
Because of this topological connection, the cyclomatic number of a graph {{mvar|G}} is also called the '''first [[Betti number]]''' of {{mvar|G}}.&lt;ref name="BerkolaikoKuchment2013"&gt;{{cite book|author1=Gregory Berkolaiko|author2=Peter Kuchment|title=Introduction to Quantum Graphs|url=https://books.google.com/books?id=QAs8tiBsvEoC&amp;pg=PA4|year=2013|publisher=American Mathematical Soc.|isbn=978-0-8218-9211-4|pages=4}}&lt;/ref&gt; More generally, the first Betti number of any topological space, defined in the same way, counts the number of independent cycles in the space.

==Applications==
===Meshedness coefficient===
A variant of the circuit rank for [[planar graph]]s, normalized by dividing by the maximum possible circuit rank of any planar graph with the same vertex set, is called the [[meshedness coefficient]]. For a connected planar graph with {{mvar|m}} edges and {{mvar|n}} vertices, the meshedness coefficient can be computed by the formula&lt;ref&gt;{{citation
 | last1 = Buhl | first1 = J.
 | last2 = Gautrais | first2 = J.
 | last3 = Sole | first3 = R.V.
 | last4 = Kuntz | first4 = P.
 | last5 = Valverde | first5 = S.
 | last6 = Deneubourg | first6 = J.L.
 | last7 = Theraulaz | first7 = G.
 | doi = 10.1140/epjb/e2004-00364-9
 | issue = 1
 | journal = The European Physical Journal B
 | pages = 123–129
 | publisher = Springer-Verlag
 | title = Efficiency and robustness in ant networks of galleries
 | volume = 42
 | year = 2004}}.&lt;/ref&gt;
:&lt;math&gt;\frac{m-n+1}{2n-5}.&lt;/math&gt;
Here, the numerator &lt;math&gt;m-n+1&lt;/math&gt; of the formula is the circuit rank of the given graph, and the denominator &lt;math&gt;2n-5&lt;/math&gt; is the largest possible circuit rank of an {{mvar|n}}-vertex planar graph. The meshedness coefficient ranges between 0 for trees and 1 for [[maximal planar graph]]s.

===Ear decomposition===
The circuit rank controls the number of ears in an [[ear decomposition]] of a graph, a partition of the edges of the graph into paths and cycles that is useful in many graph algorithms.
In particular, a graph is [[k-vertex-connected graph|2-vertex-connected]] if and only if it has an open ear decomposition. This is a sequence of subgraphs, where the first subgraph is a simple cycle, the remaining subgraphs are all simple paths, each path starts and ends on vertices that belong to previous subgraphs,
and each internal vertex of a path appears for the first time in that path. In any biconnected graph with circuit rank &lt;math&gt;r&lt;/math&gt;, every open ear decomposition has exactly &lt;math&gt;r&lt;/math&gt; ears.&lt;ref&gt;{{citation
 | last = Whitney | first = H. | authorlink = Hassler Whitney
 | journal = [[Transactions of the American Mathematical Society]]
 | pages = 339–362
 | title = Non-separable and planar graphs
 | volume = 34
 | year = 1932
 | doi=10.2307/1989545| pmc = 1076008}}. See in particular Theorems 18 (relating ear decomposition to circuit rank) and 19 (on the existence of ear decompositions).&lt;/ref&gt;

===Almost-trees===
A graph with cyclomatic number &lt;math&gt;r&lt;/math&gt; is also called a '''''r''-almost-tree''', because only ''r'' edges need to be removed from the graph to make it into a tree or forest.  A 1-almost-tree is a  '''near-tree''': a connected near-tree is a [[pseudoforest|pseudotree]], a cycle with a (possibly trivial) tree rooted at each vertex.&lt;ref name=CMC349&gt;{{citation | last=Brualdi | first=Richard A. | title=Combinatorial Matrix Classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86565-4 | zbl=1106.05001 | page=349}}&lt;/ref&gt;

Several authors have studied the [[parameterized complexity]] of graph algorithms on ''r''-near-trees, parameterized by &lt;math&gt;r&lt;/math&gt;.&lt;ref&gt;{{citation
 | last1 = Coppersmith | first1 = Don | author1-link = Don Coppersmith
 | last2 = Vishkin | first2 = Uzi | author2-link = Uzi Vishkin
 | doi = 10.1016/0166-218X(85)90057-5 | zbl=0573.68017
 | issue = 1
 | journal = Discrete Applied Mathematics
 | pages = 27–45
 | title = Solving NP-hard problems in 'almost trees': Vertex cover
 | volume = 10
 | year = 1985}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Fiala | first1 = Jiří
 | last2 = Kloks | first2 = Ton
 | last3 = Kratochvíl | first3 = Jan
 | doi = 10.1016/S0166-218X(00)00387-5 | zbl=0982.05085
 | issue = 1
 | journal = Discrete Applied Mathematics
 | pages = 59–72
 | title = Fixed-parameter complexity of λ-labelings
 | volume = 113
 | year = 2001}}.&lt;/ref&gt;

===Generalizations to directed graphs===
The [[cycle rank]] is an invariant of [[directed graph]]s that measures the level of nesting of cycles in the graph. It has a more complicated definition than circuit rank  (closely related to the definition of [[tree-depth]] for undirected graphs) and is more difficult to compute. Another problem for directed graphs related to the circuit rank is the minimum [[feedback arc set]], the smallest set of edges whose removal breaks all directed cycles. Both cycle rank and the minimum feedback arc set are [[NP-hard]] to compute.

It is also possible to compute a simpler invariant of directed graphs by ignoring the directions of the edges and computing the circuit rank of the underlying undirected graph. This principle forms the basis of the definition of [[cyclomatic complexity]], a software metric for estimating how complicated a piece of computer code is.

===Computational chemistry===
In the fields of [[chemistry]] and [[cheminformatics]], the circuit rank of a [[molecular graph]] is sometimes referred to as the '''Frèrejacque number''' and is the number of number of [[ring (chemistry)|rings]] in the [[Smallest set of smallest rings]] (SSSR).&lt;ref&gt;{{cite journal|last1=May|first1=John W.|last2=Steinbeck|first2=Christoph|title=Efficient ring perception for the Chemistry Development Kit|journal=[[Journal of Cheminformatics]]|volume=6|issue=3|year=2014|doi=10.1186/1758-2946-6-3|pmid=24479757|pmc=3922685}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Downs|first1=G.M.|last2=Gillet|first2=V.J.|last3=Holliday|first3=J.D.|last4=Lynch|first4=M.F.|year=1989|title=A review of ''Ring Perception Algorithms for Chemical Graphs''|journal=[[J. Chem. Inf. Comput. Sci.]]|volume=29|issue=3|pages=172–187|doi=10.1021/ci00063a007}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|first1=Marcel|last1=Frèrejacque|title=No. 108-Condensation d'une molecule organique|trans-title=Condenstation of an organic molecule|journal=[[Bull. Soc. Chim. Fr.]]|volume=5|pages=1008–1011|year=1939}}&lt;/ref&gt;

==Related concepts==
Other numbers defined in terms of edge deletion from undirected graphs include the [[edge connectivity]], the minimum number of edges to delete in order to disconnect the graph, and [[matching preclusion]], the minimum number of edges to delete in order to prevent the existence of a [[perfect matching]].

==References==
{{reflist}}

[[Category:Graph invariants]]
[[Category:Matroid theory]]
[[Category:Spanning tree]]</text>
      <sha1>baptrshkyvta1sp6ihxmt8vfjjudhcb</sha1>
    </revision>
  </page>
  <page>
    <title>Disentanglement puzzle</title>
    <ns>0</ns>
    <id>211757</id>
    <revision>
      <id>861148864</id>
      <parentid>861071214</parentid>
      <timestamp>2018-09-25T12:58:49Z</timestamp>
      <contributor>
        <username>Doniago</username>
        <id>7021758</id>
      </contributor>
      <minor/>
      <comment>[[Help:Reverting|Reverted]] edits by [[Special:Contributions/70.89.176.249|70.89.176.249]] ([[User talk:70.89.176.249|talk]]) to last version by Orenburg1 source?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6359">[[File:Hlavolam_cinka.jpg|thumb|upright=1.2|A disentanglement puzzle]]
{{Puzzles |Types}}
'''Disentanglement puzzles''' (also called '''tanglement puzzles''',  '''tavern puzzles''' or '''topological puzzles''')&lt;ref name="jstor"/&gt; are a type of [[mechanical puzzle]] that involves disentangling one piece or set of pieces from another piece or set of pieces. The reverse problem of reassembling the puzzle can be as hard as&amp;mdash;or even harder than&amp;mdash;disentanglement.  There are several different kinds of disentanglement puzzles, though a single puzzle may incorporate several of these features.

==Wire-and-string puzzles==
[[image:Staircasepuzzle-disentanglement-2branchesandmerge-buildyourown.jpg|thumb|upright=1.2|A complex ''Baguenaudier'' puzzle. The goal is to free the string.]]
[[File:Mini rope bridge puzzle (showing the solution).jpg|thumb|upright=1.2|The "Mini rope bridge puzzle". The goal is to remove the two rings. (solution shown).]]
'''Wire-and-string puzzles''' usually consist of: 
* one piece of string, ribbon or similar, which may form a closed loop or which may have other pieces like balls fixed to its end.
* one or several pieces of stiff wire
* sometimes additional pieces like wooden ball through which the string is threaded.

One can distinguish three subgroups of wire-and-string puzzles:
* '''Closed string subgroup:''' The pieces of string consist of one closed loop, as in the ''[[Baguenaudier]]'' puzzle. Usually the string has to be disentangled from the wire.
* '''Unclosed loose string subgroup:''' The pieces of string are not closed, and are not attached to the wire. In this case the ends of the string are fitted with a ball, cube or similar which stops the string from slipping out too easily. Usually the string has to be disentangled from the wire. Sometimes other tasks have to be completed instead, such as shifting a ring or ball from one end of the string to another end.
* '''Unclosed fixed string subgroup:''' The pieces of string are not closed, but are somewhere on its length attached to the wire.  In these puzzles the string is not to be disentangled from the wire. One possible task may be to shift a ring or ball from one end of the string to another end.

One particularly difficult puzzle was designed by R. Boomhower in 1966 and has been modified into different designs (but [[Topology|topologically]] similar). Different versions include a paddle-shaped design, a vertical beam on a wood support, and two vertical beams on a wood support. Variations also have the string passing through the slot once or two times. Names have included the Boomhower puzzle, T-Bar puzzle, Wit's End puzzle, and the Mini Rope Bridge puzzle. Some sources identify a topologically-equivalent puzzle called the Mystery Key issued by the Peter Pan company in the 1950s.&lt;ref&gt;(YouTube). [https://www.youtube.com/watch?v=NA1ftUpW3Nc "Solution for Eureka from Puzzle Master Wood Puzzles"]. Puzzle Master (April 20, 2010).&lt;/ref&gt;&lt;ref&gt;(YouTube). [https://www.youtube.com/watch?v=akigl5acZ_c&amp;t=1s The Eureka (Wit's End) Disentanglement Puzzle]. FLEB (February 18, 2017).&lt;/ref&gt;&lt;ref&gt;[https://www.puzzlemaster.ca/solutions/2063-mini-rope-bridge "Puzzle Solution for Mini Rope Bridge"]. Puzzle Master (1999-2018).&lt;/ref&gt;&lt;ref&gt;[http://www.robspuzzlepage.com/tanglement.htm "Robs Puzzle Page"]. Tanglement puzzles.&lt;/ref&gt;&lt;ref&gt;Q. Pisano. [https://www.flickr.com/photos/147202588@N02/27766256339/ "The mini-rope bridge puzzle"]. (January 6, 2018).&lt;/ref&gt;

==Wire puzzles==
[[File:Hlavolam srdce.jpg|thumb|upright=1.2|A wire puzzle]]
'''Wire puzzles''' consist of two or more entangled pieces of more or less stiff [[wire]]. 
The pieces may or may not be closed loops. The closed pieces might be simple rings or have more complex shapes.  Normally the puzzle must be solved by disentangling the two pieces without bending or cutting the wires. 

Early wire puzzles were made from [[horseshoe]]s and similar material.

==Plate-and-ring puzzles==
A '''plate-and-ring puzzle''' usually consists of three pieces:

* one plate or similar displaying many holes and/or indentations 
* a closed or nearly closed ring or a similar item. 

The plate as well as the ring are usually made from [[metal]]. The ring has to be disentangled from the plate. 

==Puzzles with no solution==
Some puzzles have been created which may appear deceptively simple, but are actually impossible to solve. One such puzzle is the "Notorious Figure Eight Puzzle" (also called the "Figure Eight Puzzle, or "Possibly Impossible"). It is sometimes sold with instructions giving hints as to its level of difficulty, and a "solution" is provided but is vague and impossible to follow, but the puzzle is actually impossible to solve.&lt;ref&gt;[http://sma.epfl.ch/~ojangure/Notes.pdf http://sma.epfl.ch/Notes.pdf] A Topological Puzzle, Inta Bertuccioni, December 2003.&lt;/ref&gt;&lt;ref&gt;[https://www.futilitycloset.com/2012/06/23/the-figure-8-puzzle/ https://www.futilitycloset.com/the-figure-8-puzzle] The Figure Eight Puzzle, Science and Math, June 2012.&lt;/ref&gt;

==Mathematical modeling==
Most puzzle solvers try to solve such puzzles by mechanical manipulation, but some branches of [[mathematics]] can be used to create a model of disentanglement puzzles. Applying a [[Configuration space (physics)|configuration space]] with a [[Topology|topological framework]] is an analytical method to gain insight into the properties and solution of some disentanglement puzzles. However, some mathematicians have stated that capturing the important aspects of many such puzzles can often be difficult, and there is no universal algorithm that will provide the solution generally to such puzzles.&lt;ref name="jstor"&gt;[https://www.jstor.org/stable/27642974 https://www.jstor.org/stable/27642974] Disentangling Topological Puzzles by Using Knot Theory, Mathew Horak; Mathematics Magazine, December 2006.&lt;/ref&gt;

==See also==
{{commonscat|Disentanglement puzzles}}
* [[Borromean rings]], a method of linking three closed loops which is found in some disentanglement puzzles
* [[Human knot]]
* [[Unknotting problem]]
* [[Unlink]]

==References==
&lt;references /&gt;

[[Category:Mechanical puzzles]]
[[Category:Recreational mathematics]] 

&lt;!-- Note that some languages may have more than one interwiki link.  This is because some of the sub-types of puzzles have their own articles on another language. --&gt;</text>
      <sha1>pejxjtqrr6uyl9k9vxij54tc887e3so</sha1>
    </revision>
  </page>
  <page>
    <title>East Journal on Approximations</title>
    <ns>0</ns>
    <id>10986849</id>
    <revision>
      <id>807606289</id>
      <parentid>593835594</parentid>
      <timestamp>2017-10-29T01:06:27Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>East J. Approx.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="677">{{Infobox Journal
| cover	=	
| discipline	=	[[mathematics]]
| abbreviation	=	East J. Approx.
| publisher	=	DARBA
| country	=	[[Bulgaria]]
| ISSN	= 1310-6236
| history	=	1995 to present
| website	=	http://www.darba-eja.com/
}}

The '''East Journal on Approximations''' is a journal about [[approximation theory]] published in [[Sofia]], [[Bulgaria]].&lt;ref&gt;{{cite web | url = http://www.darba-eja.com | title = DARBA-EJA | accessdate=2007-04-30}}&lt;/ref&gt;

==External links==
* [http://www.darba-eja.com/ East Journal on Approximations web site]

== References ==
&lt;references /&gt;

[[Category:Mathematics journals]]
[[Category:Publications established in 1995]]


{{math-journal-stub}}</text>
      <sha1>jsi5es7pfhmh56h3w25y2eimmaj1n0v</sha1>
    </revision>
  </page>
  <page>
    <title>El Nombre</title>
    <ns>0</ns>
    <id>3951378</id>
    <revision>
      <id>866904653</id>
      <parentid>866873784</parentid>
      <timestamp>2018-11-02T09:34:32Z</timestamp>
      <contributor>
        <username>Materialscientist</username>
        <id>7852030</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/61.69.33.42|61.69.33.42]] identified as test/vandalism using [[WP:STiki|STiki]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19269">{{Use British English|date=July 2014}}
{{Use dmy dates|date=November 2012}}
{{Infobox television
| show_name          = El Nombre
| genre              = Educational [[animation]]
| runtime            = 5 minutes
| creator            = [[Christopher Lillicrap]]
| writer             = Christopher Lillicrap
| developer          = [[Geoff Walker (television program developer)|Geoff Walker]]
| composer           = Christopher Lillicrap&lt;br&gt;[[Steve Marshall (composer)|Steve Marshall]]
| producer           = [[Jilly Joseph]]&lt;br&gt;[[Richard Randolph]]
| executive_producer = [[Theresa Plummer-Andrews]]
| director           = [[Chris Mendham]]&lt;br&gt;Geoff Walker
| starring           = [[Steve Steen]]&lt;br&gt;[[Sophie Aldred]]&lt;br&gt;[[Kate Robbins]]&lt;br&gt;[[Janet Ellis]]
| language         = [[English language|English]]
| country            = [[United Kingdom]]
| network            = [[BBC One]] (Series 1), [[CBeebies]] (Series 2)
| num_series         = 2
| num_episodes       = 26
| first_aired        = 5 January 2001
| last_aired         = 29 November 2003
}}
'''''El Nombre''''' is an [[anthropomorphism|anthropomorphic]] [[Mexico|Mexican]] [[gerbil]] character, originally from a series of educational sketches on ''[[Numbertime]]'', the [[BBC]] schools programme about [[mathematics]]. He was also the only character to appear in all ''Numbertime'' episodes. His voice was provided by [[Steve Steen]], while the other characters' voices were provided by [[Sophie Aldred]], [[Kate Robbins]], and (from 1999) former ''[[Blue Peter]]'' host [[Janet Ellis]]. For the ninth (and final) series of ''Numbertime'' in 2001, [[Michael Fenton-Stevens]] also provided voices of certain other characters in the ''El Nombre'' sketches.

The character's name means "The Name" in Spanish, not "The Number", which would be "El Número".

==Setting==
''El Nombre'' is set in the fictional town of Santa Flamingo (originally known as Santo Flamingo), home of Little Juan, his Mama, Pedro Gonzales, Juanita Conchita, Maria Consuela Tequila Chiquita, Little Pepita Consuela Tequila Chiquita, Tanto the tarantula, Señor Gelato the ice-cream seller, Leonardo de Sombrero the pizza delivery boy, Señor Calculo the bank manager, Señor Manuel the greengrocer, Miss Constanza Bonanza the school teacher, Señora Fedora the balloon seller and mayor, Señor Loco the steam engine driver, Señor Chipito the carpenter and the local bandit Don Fandango (although it was not actually given a name until the fifth series of ''Numbertime'' premiered in January 1998); whenever he was needed, El Nombre swung into action to solve the townspeople's simple mathematical problems, usually talking in rhyme. His character was a parody of the fictional hero [[Zorro]], wearing a similar black cowl mask and huge sombrero, appearing unexpectedly to save the townsfolk from injustice, and generally swinging around on his bullwhip - however, unlike Zorro, he was often quite inept (in fact, on one occasion, Tanto tipped a bucket of water onto him after he made him reenact the ''[[Incy Wincy Spider]]'' rhyme).

When El Nombre first appeared on ''Numbertime'' in 1993, his purpose was merely to write numbers in the desert sand and demonstrate the correct ways to form them as his four-piece mariachi band played ''[[The Mexican Hat Dance]]'' (and said "Again!" once he had finished, as it gave them an excuse to play again); this was shot from an angle directly overhead leaving El Nombre almost completely eclipsed by his large sombrero. His appeal was instant and his success prompted rapid development of his role in the series (as from the second series in 1995, he was given ''two'' sketches per episode) - and since his basic beginning, El Nombre went on to appear in a total of 79 (89, if counting those from the "revised" version of the first series) sketches on ''Numbertime'' before gaining a series of his own, acquiring dramatic storylines and a full cast of characters, while continuing to demonstrate mathematical concepts, albeit in a dramatic and entertaining way. The stories moved away from solving simple mathematical equations to fighting petty crime, unrelated to the number-solving which made his name and for which he was created.

As well as being popular with schoolchildren, ''El Nombre'' also developed a cult following amongst students and parents, because of the many references to classic spaghetti Westerns; indeed, his popularity grew so much that in March 2004, the BBC released a 3-minute ''El Nombre'' theme song as a single.

==Characters==
*'''El Nombre''': The eponymous main character of the ''Numbertime'' sketches, and the spin-off series they began, El Nombre started his life as an adaptation of ''[[Words and Pictures (TV series)|Words and Pictures]]''&lt;nowiki&gt;'&lt;/nowiki&gt; ''Magic Pencil'' (in the sense of showing the viewer how to write numbers as opposed to letters); after showing Juan how to draw from one to ten, he went on to show him how to identify (and draw) shapes, as well as teach him about instances of space and position, addition and subtraction, time and money in his everyday life.
*'''Little Juan''': A young gerbil whose name was a pun on "little one", Juan started his life being upset about not being able to write numbers and cried until El Nombre arrived to show him how to do it; after learning to draw from one to ten, he could not identify shapes and was despondent about it until El Nombre arrived (first to show him instances of the shapes around the town and second to draw them). He and his friends then got themselves into various dilemmas in their everyday lives, which El Nombre was called on to help them out of.
*'''Mama''': Little Juan's mother, who usually could not assist Juan with his various mathematical dilemmas until El Nombre had arrived.
*'''Pedro Gonzales &amp; Juanita Conchita''': Two of Juan's friends, who first appeared in the second series of ''Numbertime'', but were not named until the third; on one occasion in the third series, Pedro professed to be "the greatest goalkeeper in the world" when Juan could not score past him, and on one occasion in the fourth series, Juan accidentally blew up Juanita's balloon ten times causing it to burst.
*'''Señor Chipito''': The town carpenter who first appeared in the second series of ''Numbertime'' as the owner of The Maggot and Cactus Saloon, but was not named and given his present occupation until the sixth; on one occasion in that series, Juan and Pedro had to take a wheel from Señor Gelato's ice-cream tricycle to him for repairs, as it struck a three-legged table that they were already taking to him.
*'''Señor Manuel''': The town greengrocer, who first appeared in the second series of ''Numbertime'' but was not named until the fourth; the store he ran was called "Hurrell's" (which was an inside reference to the BBC's then-current education officer in 1995, Su Hurrell).
*'''Tanto''': Little Juan's pet tarantula spider, who was introduced in the third series of ''Numbertime''; he communicated by mumbling, and on one occasion in the fifth series, Pedro bet Juan he could find a spider who was faster than him (the one he found was mechanical, reflected by the key for winding on its back) and challenged him to a race around the then-newly named town against it, which Tanto won.
*'''Maria Consuela Tequila Chiquita''': Another of Juan's friends, who was introduced in the third series of ''Numbertime'', and did not appear in as many sketches as Pedro or Juanita; in the seventh series, her younger sister (named Pepita) started at San Flamingo School.
*'''Señora Fedora''': The town balloon seller, who was introduced at the end of the fourth series of ''Numbertime'', but was later shown to be its mayor as well in the seventh one after she opened its fifteenth annual Egg Festival and chose Mama to make its giant omelette.
*'''Miss Constanza Bonanza''': The teacher for San Flamingo School, who was introduced in the fifth series of ''Numbertime'' (as was the school itself); in the eighth series she got married and Juan was responsible for the school collection with which to buy her a present.
*'''Delietta Smith''': A television cook who was introduced in the fifth series of ''Numbertime''; known as ''The Great Delietta'' and a spoof of [[Delia Smith]], Mama once tried to make her omelette with red and green peppers (but could not, so El Nombre had to help her).
*'''Señor Gelato''': The town ice-cream seller, who was introduced in the sixth series of ''Numbertime''; on one occasion in that series he swerved on his tricycle to avoid striking Juan and Pedro (who were playing football), and crashed into Señor Manuel's tomato display.
*'''Señor Calculo &amp; Don Fandango''': The town bank manager and bandit, who were introduced in the sixth series of ''Numbertime''; on one occasion in that series, Don Fandango stole twenty gold coins from the bank (but Tanto bit a hole in his bag, causing them to fall out).
*'''Pepita Consuela Tequila Chiquita''': Maria's younger sister who started San Flamingo School in the seventh series of ''Numbertime''.
*'''Leonardo de Sombrero''': The town pizza delivery boy, who was introduced in the eighth series of ''Numbertime''; his name is a spoof on that of [[Leonardo da Vinci]], and once, he delivered a pizza to Juan and his friends when they were having a horror movie sleepover.
*'''Señor Loco''': The town's steam engine driver, who was introduced in the eighth series of ''Numbertime''; his name is a reference to the fact "loco" is short for [[locomotive]], and once, he took Juan's class to the Santo &lt;!-- Note: The town's name had not yet been changed to "Santa" at the time the eighth series was produced; please leave as "Santo". --&gt; Flamingo National Park to see the Giant Cactus.
*'''Señor Singalotti''': A famous opera singer (who only appeared in the fourteenth episode of the spin-off series, "Going for a Song").
*'''El Presidente''': The president (who visited the town in the twenty-fifth episode of the spin-off series, "A Very Important Visit").

A gerbil named '''Pablo''' also appeared in the ninth series of ''Numbertime'' after Juan entered a competition on Radio Flamingo to win a holiday to the seaside resort of Costa Fortuna and won; Juan, Mama, Pedro, Juanita and Maria met him when they arrived at the resort's hotel (because he was their guide to it), and he went on to front a ring-toss stall when they visited its fairground the following week.

==Episode list &lt;!-- Do *not* delete any of the information in this section of the page, or either of the two subsections below it. --&gt;==
Although none of the ''El Nombre'' sketches on ''Numbertime'' ever had a specific title, those of the first series were introduced by an announcer as "Episodes 1-10" (and they were slightly lengthened for the "revised" edition of that series, in September 1998; the third line of the opening song and his farewell catchphrase were also changed several times, to reflect the series' focus). All twenty-six episodes of the spin-off ''El Nombre'' series (thirteen in 2001 and a further thirteen in 2003), however, were titled - and their names are listed here.

===Series 1 (2001)===
The first six episodes of the first series were aired on BBC One as double bills in the [[CBBC]] strand on Fridays at 3:45 pm, while the next seven were aired individually on Wednesdays in the same timeslot; three episodes were later repeated on BBC Two as part of the CBBC Breakfast Show on 1 June, 19 July and 20 July 2001, but neither they, or the other ten episodes of the series, were repeated after that.
 
{| class="wikitable"
|-
! Episode number !! Episode name !! Air date
|-
| 1 || ''Where's That Spider?'' || 5 January 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-01-05|title=BBC One London - 5 January 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 2 || ''Free as a Bird'' || 5 January 2001 
|-
| 3 || ''Sports Day'' || 12 January 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-01-12|title=BBC One London - 12 January 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 4 || ''All the Fun of the Fair'' || 12 January 2001
|-
| 5 || ''The Phantom Tanto'' || 19 January 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-01-19|title=BBC One London - 19 January 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 6 || ''The Missing Birthday Cake'' || 19 January 2001
|-
| 7 || ''The Great Train Robbery'' || 24 January 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-01-24|title=BBC One London - 24 January 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 8 || ''The Giant Cactus'' || 31 January 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-01-31|title=BBC One London - 31 January 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 9 || ''The Great Custard Pie Fight'' || 14 February 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-02-14|title=BBC One London - 14 February 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 10 || ''When the Balloon Goes Up'' || 7 March 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-03-07|title=BBC One London - 7 March 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 11 || ''The Great Escape'' || 14 March 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-03-07|title=BBC One London - 7 March 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 12 || ''The Ghost of Santo &lt;!-- Note: The town's name had not yet been changed to "Santa" at the time this series was produced; please leave as "Santo". --&gt; Flamingo'' || 21 March 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-03-21|title=BBC One London - 21 March 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 13 || ''Match of the Day'' || 28 March 2001&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/bbcone/london/2001-03-28|title=BBC One London - 28 March 2001 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|}

===Series 2 (2003)===
The second series was aired as double bills on the CBeebies Channel on Saturdays and Sundays at 3:30 pm; after the last episode aired on 29 November, the first one was immediately repeated again, and the series concluded its second consecutive run in the same timeslot on 4 January 2004. All thirteen episodes were later repeated on BBC Two in the CBeebies strand on Wednesdays from 7 January to 31 March 2004.
 
{| class="wikitable"
|-
! Episode number !! Episode name !! Air date
|-
| 14 || ''Going for a Song'' || 8 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-08|title=CBeebies - 8 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 15 || ''Runaway Train'' || 8 November 2003
|-
| 16 || ''The Tent'' || 9 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-09|title=CBeebies - 9 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 17 || ''Stuck at the Top'' || 9 November 2003
|-
| 18 || ''The Great Bank Robbery'' || 15 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-15|title=CBeebies - 15 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 19 || ''The Great Sand Race'' || 15 November 2003
|-
| 20 || ''The Lemon Tree'' || 16 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-16|title=CBeebies - 16 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 21 || ''Beside the Sea'' || 16 November 2003
|-
| 22 || ''The Last Dance'' || 22 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-22|title=CBeebies - 22 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 23 || ''Saved by the Whale'' || 22 November 2003
|-
| 24 || ''Up, Up and Away'' || 23 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-23|title=CBeebies - 23 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|-
| 25 || ''A Very Important Visit'' || 23 November 2003
|-
| 26 || ''Winter Wonderland'' || 29 November 2003&lt;ref&gt;{{cite web|url=http://genome.ch.bbc.co.uk/schedules/cbeebies/2003-11-29|title=CBeebies - 29 November 2003 - BBC Genome|website=genome.ch.bbc.co.uk}}&lt;/ref&gt;
|}

==DVD release==
In October 2005, all twenty-six episodes were released on [[DVD]] by Maverick Entertainment; the first ten were previously released on a [[VHS]] entitled ''El Nombre to the Rescue'' by [[BBC Worldwide]] in 2001, which also featured an exclusive short (entitled ''Learn Your Numbers With Little Juan'', and edited together from the ''El Nombre'' sketches of the "original" first series of ''Numbertime'').&lt;ref&gt;{{cite web|url=https://www.amazon.co.uk/El-Nombre-DVD/dp/B000B3MIU6|title=El Nombre|date=10 October 2005|publisher=|via=Amazon}}&lt;/ref&gt; Some of the ''El Nombre'' (and cell-animated) sketches of the "revised" first, second and fifth, and fourth series of ''Numbertime'' were also released by BBC Active in 2009 on three DVDs entitled ''Fun with Numbers'' - which all came with accompanying books featuring the characters, and were subtitled ''Counting 1 to 10'', ''Shapes and Time'' (the featured sketches were mostly from the second series), and ''Adding and Taking Away'' respectively.&lt;ref&gt;{{cite web|url=https://www.amazon.co.uk/Fun-Numbers-Counting-Watch-Learn/dp/1406650536|title=Fun with Numbers: Counting 1 to 10 Pack: Counting Pack|date=1 April 2009|publisher=BBC Active|via=Amazon}}&lt;/ref&gt;

==Credits==
*'''Writer''': Christopher Lillicrap
*'''Original designs''': Ealing Animation
*'''Voices''': Steven Steen, Kate Robbins, Sophie Aldred, Janet Ellis
*'''Models''': Fin Leadbitter, Humphrey Leadbitter, Katy Maxwell 
*'''Props''': Graeme Owen, Fin Leadbitter, Sophie Brown, Katy Maxwell
*'''Sets''': Graeme Owen, Colin Armitage, Sophie Brown, Humphrey Leadbitter
*'''Animation''': Humphrey Leadbitter, Tim Allen, Chris Mendham, Dan Sharp
*'''Editing and special effects''': David Brylewski
*'''Facilities''': Oasis Television 
*'''Theme tune composer''': Christopher Lillicrap 
*'''Music and effects''': Steve Marshall 
*'''Sound''': Adrian Sear
*'''Executive producer''': Theresa Plummer-Andrews 
*'''Producer''': Jilly Joseph, Richard Randolph
*'''Director''': Chris Mendham, Geoff Walker

==References==
{{reflist}}

==External links==
*{{IMDb title|id=5108148|title=El Nombre}}
*[http://www.toonhound.com/elnombre.htm ''El Nombre'' at Toonhound.com]

{{DEFAULTSORT:Nombre}}
[[Category:2001 British television programme debuts]]
[[Category:2003 British television programme endings]]
[[Category:2000s British children's television series]]
[[Category:BBC children's television programmes]]
[[Category:2000s British animated television series]]
[[Category:British television programmes for schools]]
[[Category:Mathematics education television series]]
[[Category:British stop-motion animated television series]]
[[Category:British animated television programmes featuring anthropomorphic characters]]
[[Category:Television spin-offs]]
[[Category:English-language television programs]]</text>
      <sha1>crb1rc6trzqhq23lqmgelgzly8mrxz9</sha1>
    </revision>
  </page>
  <page>
    <title>Emil Grosswald</title>
    <ns>0</ns>
    <id>21442284</id>
    <revision>
      <id>862031806</id>
      <parentid>861808835</parentid>
      <timestamp>2018-10-01T18:35:42Z</timestamp>
      <contributor>
        <username>Fishhead2100</username>
        <id>567263</id>
      </contributor>
      <comment>removed [[Category:People from Pennsylvania]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11193">{{Infobox scientist
|name              = Emil Grosswald
|image             = Emil Grosswald MFO.jpg
|image_size        = 
|caption           = 
|birth_date        = {{birth date|1912|12|15}}
|birth_place       = [[Bucharest]], [[Romania]]
|death_date        = {{dda|1989|4|11|1912|12|15}}
|death_place       = 
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = [[Jewish]]
|fields            = [[Mathematics]]
|workplaces        = [[University of Pennsylvania]]&lt;br /&gt;[[Temple University]]
|alma_mater        = [[University of Bucharest]]&lt;br /&gt;[[University of Pennsylvania]]
|doctoral_advisor  = [[Hans Rademacher]]
|academic_advisors = 
|doctoral_students = [[David Bressoud]]&lt;br /&gt;[[Jean-Marie De Koninck]]
|notable_students  = 
|known_for         = 
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = 
|awards            = 
|religion          = 
|signature         =  &lt;!--(filename only)--&gt;
|footnotes         = 
}}

'''Emil Grosswald''' (December 15, 1912 – April 11, 1989) was a [[mathematician]] who worked primarily in [[number theory]].

== Life and education ==
[[File:Fred van der Blij.jpg|thumb|left|Emil Grosswald (right) and [[Fred van der Blij]] in 1968.]]
Grosswald was born on December 15, 1912 in [[Bucharest]], [[Romania]]. He received a [[Master's degree]] in both [[mathematics]] and [[electrical engineering]] from the [[University of Bucharest]] in 1933, spent 6 months in [[Italy]] and then received a Diplôme from [[Supélec|École supérieure d'électricité]] in [[Paris]].&lt;ref name="UTexas"&gt;{{cite web |url=http://www.lib.utexas.edu/taro/utcah/00224/cah-00224.html |title=A Guide to the Emil Grosswald Papers, 1942–1988 |accessdate=2009-02-06 |work= |publisher=University of Texas |date= }}&lt;/ref&gt;

Grosswald was [[Jews|Jewish]]. When war broke out, he fled from Paris in June, 1940 to the [[University of Montpellier]], where he began doctoral studies in [[mathematics]].  He fled at the end of 1941, through [[Spain]] and [[Lisbon]] to [[Cuba]].  He moved to [[Puerto Rico]] in 1946 and then to the [[United States]] in 1948. He received his [[Ph.D.]] under [[Hans Rademacher]] from the [[University of Pennsylvania]] in 1950.&lt;ref name="NAMS obit"&gt;
{{cite journal |last=Knopp |first=Marvin I. |author-link=Marvin Knopp| date=July–August 1989 |title=Emil Grosswald 1912–1989 |journal=[[Notices of the American Mathematical Society]] |volume=36 |issue=6 |pages=685–686 |id= |url=http://www.numbertheory.org/obituaries/OTHERS/grosswald.jpg |accessdate=2009-02-06 |quote= }}&lt;/ref&gt;  He was Visiting Professor at the University of Paris in 1964–1965 and his book, ''The Theory of Numbers'' was written that year.

He met his wife Elisabeth (Lissy) Rosenthal in Cuba, probably in 1941 or 1942. They were married in 1950 in [[Saskatoon]], [[Canada]], where he had his first teaching position after receiving his Ph.D. They spent two years at the [[Institute for Advanced Studies]] in [[Princeton, New Jersey]] in 1951 and 1959. During their first stay, they met [[Albert Einstein]], with whom Emil had a correspondence, later bequeathed to the University of Texas, and formed many friendships, among others with the physicist [[Freeman Dyson]]. Emil and Lissy had two daughters, Blanche, who became a professor of Social Work at [[Rutgers University]] but died in 2003 at the age of 50, and [http://law.pitt.edu/people/vivian-curran Vivian], a professor of law at the [[University of Pittsburgh]]. Vivian was decorated in 2007 by the [[Austria|Republic of Austria]] for her work as the United States appointee to the Austrian General Settlement Fund Committee for Nazi-era property compensation, and in 2013 by the government of France for her services in promotion of the French language and culture in the United States. Emil is the uncle of [[Pamela Ronald]], whose father Robert Ronald (né Rosenthal) describes the family’s escape from the Nazis in his memoir, {{cite web|url=https://www.amazon.com/Last-train-freedom-Holocaust-survivors/dp/0966067703|title=Last Train to Freedom}} The son of Lissy’s second cousin ([[Ernest Beutler]]) is 2011 [[Nobel Prize|Nobel]] Laureate [[Bruce Beutler]]. Emil was also the nephew of the French musician [[Marcel Mihalovici]], who arrived in Paris in the 1920s with [[George Enescu]].

Grosswald died April 11, 1989 in [[Narberth, Pennsylvania]].&lt;ref name="UTexas" /&gt;

== Career ==

Grosswald's first three scientific papers, written while he was in [[Cuba]], were published under the pseudonym E. G. Garnea.&lt;ref name="Tribute"&gt;
{{cite book | editor1-first = Marvin Isadore | editor1-last = Knopp | editor1-link=Marvin Knopp| editor2-first = Mark | editor2-last = Sheingorn | title = A Tribute to Emil Grosswald: Number Theory and Related Analysis | publisher = American Mathematical Society | location = Providence | year = 1993 | url = https://books.google.com/books?id=nzxTVb0k8rIC | accessdate=2009-02-06 | isbn = 978-0-8218-5155-5 }}&lt;/ref&gt;{{Rp|11}}  He published articles in [[English language|English]], [[German language|German]], [[French language|French]], [[Spanish language|Spanish]] and [[Italian language|Italian]].

After receiving his [[PhD]] in 1950, Grosswald taught at the [[University of Pennsylvania]] from 1952 to 1968 and then moved to [[Temple University]] and stayed until his retirement in 1980. He also held positions at the [[University of Saskatchewan]] (1950), [[Institute for Advanced Study]] (1951 and 1959), the [[Technion]] (1980–1981), [[Swarthmore College]] (1982), and the [[University of Pennsylvania]] (1984).&lt;ref name="UTexas" /&gt;

Grosswald completed some works of his teacher [[Hans Rademacher]], who died in 1969. Rademacher had prepared notes for an [[Earle Raymond Hedrick]] Lecture in [[Boulder, Colorado]] in 1963 on [[Dedekind sum]]s, but fell ill, and Grosswald gave the lecture for him.&lt;ref name="Rademacher collection"&gt;{{cite web|url=http://www.amphilsoc.org/library/mole/r/rademacher.pdf |format=PDF |title=Hans Rademacher Collection 1942–1963 |accessdate=2009-02-07 |work= |publisher=American Philosophical Society |date=2003-08-07 |deadurl=yes |archiveurl=https://web.archive.org/web/20071015034200/http://www.amphilsoc.org/library/mole/r/rademacher.pdf |archivedate=October 15, 2007 }}&lt;/ref&gt;
After Rademacher's death, Grosswald edited and completed the notes and published them in the [[Carus Mathematical Monographs]] series as ''Dedekind Sums''.&lt;ref name="Rademacher obit"&gt;
{{cite journal |last=Berndt |first=Bruce C. |authorlink=Bruce C. Berndt |year=1992 |title=Hans Rademacher (1892–1969) |journal=Acta Arithmetica |volume=61 |pages=209–231 |id= |url=http://matwbn.icm.edu.pl/ksiazki/aa/aa61/aa6131.pdf |format=PDF |accessdate=2009-02-07 |quote= }}&lt;/ref&gt;{{Rp|214}}
He also edited for publication Rademacher's posthumous textbook ''Topics in Analytic Number Theory''.&lt;ref name="UTexas" /&gt;

Grosswald was elected to the Board of Governors of the [[Mathematical Association of America]] for 1965–1968.&lt;ref name="AMM Governors"&gt;
{{cite journal |last=Hailpern |first=Raoul |authorlink= |date=August–September 1965 |title=New Sectional Governors of the Association  |journal=American Mathematical Monthly |volume=72 |issue=7 |pages=813 | jstor = 2314478 }}&lt;/ref&gt; [[Temple University]]'s Mathematics Department annually sponsors the Emil Grosswald Memorial Lectures.&lt;ref name="Grosswald Lectures"&gt;
{{cite web
 |url         = http://math.temple.edu/events/grosswald/
 |title       = Department of Mathematics : Grosswald Lectures
 |accessdate  = 2009-02-07
 |work        = 
 |publisher   = Temple University
 |date        = 2010-04-20
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20090501131444/http://www.math.temple.edu/events/grosswald/
 |archivedate = 2009-05-01
 |df          = 
}}&lt;/ref&gt;

== Selected publications ==
* {{cite book | first1 = Emil | last1 = Grosswald | first2 = Hans | last2 = Rademacher | authorlink2 = Hans Rademacher| title = Dedekind Sums | publisher = Mathematical Association of America | location = Washington, DC | year = 1972 |series=Carus Mathematical Monographs |volume=16 | isbn = 978-0-88385-016-9 }}
* {{cite book | last = Rademacher | first = Hans | authorlink = Hans Rademacher | editor1-first=Emil | editor1-last = Grosswald | editor2-first=Joseph | editor2-last = Lehner | editor3-first=Morris | editor3-last = Newman |title = Topics in Analytic Number Theory | publisher = Springer-Verlag | location = Berlin | year = 1973 | series = Grundlehren der mathematischen Wissenschaften | volume=169 | isbn = 978-0-387-05447-6 }}
* {{cite book | last = Rademacher | first = Hans | authorlink = Hans Rademacher | editor1-first=Emil | editor1-last = Grosswald | title = Collected Papers of Hans Rademacher | volume=vol. 1|publisher = MIT Press | location = Cambridge | year = 1974 | isbn = 978-0-262-07055-3 }}{{cite book|title=(View 2nd volume.)|volume=vol. 2|url=https://books.google.com/books?isbn=0262070553|isbn=0-262-07055-3}}
* {{cite book | last = Grosswald | first = Emil | title = Bessel Polynomials | publisher = Springer-Verlag | location = Berlin | year = 1978 | isbn = 978-0-387-09104-4}}&lt;ref&gt;{{cite journal|last=Boas | first= Ralph P.|authorlink=Ralph P. Boas Jr.| title=Review: Emil Grosswald, ''Bessel polynomials''|journal=[[Bulletin of the American Mathematical Society]] (N.S.)|year=1979|volume=1| issue=5|pages=799–800| url=http://projecteuclid.org/euclid.bams/1183544728|doi=10.1090/s0273-0979-1979-14678-0}}&lt;/ref&gt;
* {{cite book | last = Grosswald | first = Emil | title = Topics from the Theory of Numbers | publisher = Birkhäuser Boston | location = Cambridge | year = 2008 |origyear=1984|edition=2nd | isbn = 978-0-8176-4837-4 }}
* {{cite book | last = Grosswald | first = Emil | title = Representations of Integers as Sums of Squares | publisher = Springer-Verlag | location = Berlin | year = 1985 | isbn = 978-0-387-96126-2 }}

== Notes ==
{{reflist}}

== Further reading ==
* {{cite book | editor1-first = Marvin | editor1-last = Knopp | editor2-first = Mark | editor2-last = Sheingorn | title =
A Tribute to Emil Grosswald | publisher = American Mathematical Society | location = Providence | year = 1993 | url = https://commons.wikimedia.org/wiki/File%3AA_Tribute_to_Emil_Grosswald.pdf | accessdate=2009-02-06 | isbn = 978-0-8218-5155-5 | author = American Mathematical Society. Marvin Knopp ..., ed. }} A set of papers in honor of Grosswald; includes reminiscences, list of PhD students, and a list of papers and books.

== External links ==
* {{MathGenealogy|7521}}
* {{MacTutor Biography|id=Grosswald}}

{{Authority control}}

{{DEFAULTSORT:Grosswald, Emil}}
[[Category:20th-century American mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Number theorists]]
[[Category:People from Bucharest]]
[[Category:Romanian Jews]]
[[Category:American people of Romanian-Jewish descent]]
[[Category:Temple University faculty]]
[[Category:University of Bucharest alumni]]
[[Category:University of Pennsylvania alumni]]
[[Category:University of Pennsylvania faculty]]
[[Category:1912 births]]
[[Category:1989 deaths]]
[[Category:Mathematicians from Pennsylvania]]
[[Category:Supélec alumni]]</text>
      <sha1>kgdvza3viwvs9nf0kul47d67lmwaomm</sha1>
    </revision>
  </page>
  <page>
    <title>Entropic uncertainty</title>
    <ns>0</ns>
    <id>857780</id>
    <revision>
      <id>867238712</id>
      <parentid>852431758</parentid>
      <timestamp>2018-11-04T15:03:05Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13836">In [[Uncertainty principle#Quantum_entropic_uncertainty_principle|quantum mechanics]], [[information theory]], and [[Fourier analysis]], the '''entropic uncertainty''' or '''Hirschman uncertainty''' is defined as the sum of the temporal and spectral [[Shannon entropy|Shannon entropies]].  It turns out that Heisenberg's [[uncertainty principle]] can be expressed as a lower bound on the sum of these entropies.  This is ''stronger'' than the usual statement of the uncertainty principle in terms of the product of standard deviations.

In 1957,&lt;ref name=Hirschman&gt;{{Citation |first=I. I., Jr. |last=Hirschman |title=A note on entropy |journal=[[American Journal of Mathematics]] |year=1957 |volume=79 |issue=1 |pages=152–156 |doi=10.2307/2372390 |postscript=. |jstor=2372390 }}&lt;/ref&gt; [[Isidore Isaac Hirschman, Jr.|Hirschman]] considered a function ''f'' and its [[Fourier transform]] ''g'' such that
:&lt;math&gt;g(y) \approx \int_{-\infty}^\infty \exp (-2\pi ixy) f(x)\, dx,\qquad f(x) \approx \int_{-\infty}^\infty \exp (2\pi ixy) g(y)\, dy  ~,&lt;/math&gt;
where the   "≈" indicates convergence in {{mvar|L}}&lt;sup&gt;2&lt;/sup&gt;, and normalized so that (by [[Plancherel theorem|Plancherel's theorem]]),
:&lt;math&gt; \int_{-\infty}^\infty |f(x)|^2\, dx = \int_{-\infty}^\infty |g(y)|^2 \,dy = 1~.&lt;/math&gt;

He showed that for any such functions the sum of the Shannon entropies is non-negative,
:&lt;math&gt; H(|f|^2) + H(|g|^2) \equiv - \int_{-\infty}^\infty |f(x)|^2 \log |f(x)|^2\, dx - \int_{-\infty}^\infty |g(y)|^2 \log |g(y)|^2 \,dy \ge 0. &lt;/math&gt;

A tighter bound,
{{Equation box 1
|indent =:
|equation =  &lt;math&gt; H(|f|^2) + H(|g|^2) \ge \log \frac e 2   ~,&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
was conjectured by Hirschman&lt;ref name=Hirschman/&gt; and [[Hugh Everett|Everett]],&lt;ref&gt;[[Hugh Everett]], III.  The Many-Worlds Interpretation of Quantum Mechanics: the theory of the universal wave function. [https://www.pbs.org/wgbh/nova/manyworlds/pdf/dissertation.pdf Everett's Dissertation]&lt;/ref&gt; proven in 1975 by [[William Beckner (mathematician)|W. Beckner]]&lt;ref name="Beckner"&gt;{{Citation |first=W. |last=Beckner |title=Inequalities in Fourier analysis |journal=[[Annals of Mathematics]] |volume=102 |issue=6 |year=1975 |pages=159–182 |doi=10.2307/1970980 |postscript=. |jstor=1970980 }}&lt;/ref&gt;
and in the same year interpreted by as a generalized quantum mechanical uncertainty principle by [[:pl:Iwo Białynicki-Birula|Białynicki-Birula]] and Mycielski.&lt;ref name="BBM"&gt;{{Citation |first=I. |last=Bialynicki-Birula|last2= Mycielski|first2=J.|title=Uncertainty Relations for Information Entropy in Wave Mechanics|journal=[[Communications in Mathematical Physics]] |volume=44 |year=1975 |pages=129 |doi=10.1007/BF01608825 |issue=2|bibcode = 1975CMaPh..44..129B }}&lt;/ref&gt;
The equality holds in the case of [[Gaussian distribution]]s.&lt;ref&gt;{{cite journal |last1=Ozaydin |first1=Murad |last2=Przebinda |first2=Tomasz |year=2004 |title=An Entropy-based Uncertainty Principle for a Locally Compact Abelian Group |journal=Journal of Functional Analysis |volume=215 |issue=1 |pages=241–252  |publisher=Elsevier Inc.|doi= 10.1016/j.jfa.2003.11.008|url=http://redwood.berkeley.edu/w/images/9/95/2002-26.pdf |accessdate=2011-06-23 }}&lt;/ref&gt;

Note, however, that the above entropic uncertainty function is distinctly ''different'' from the quantum [[Von Neumann entropy]] represented in [[phase space]].

==Sketch of proof==
The proof of this tight inequality depends on the so-called '''(''q'',&amp;nbsp;''p'')-norm''' of the Fourier transformation.  (Establishing this norm is the most difficult part of the proof.)

From this norm, one is able to establish a lower bound on the sum of the (differential) [[Rényi entropy|Rényi entropies]], {{math| ''H&lt;sub&gt;α&lt;/sub&gt;({{!}}f{{!}}²)+H&lt;sub&gt;β&lt;/sub&gt;({{!}}g{{!}}²)'' }}, where {{math|''1/α + 1/β'' {{=}} 2}}, which generalize the Shannon entropies.  For simplicity, we consider this inequality only in one dimension; the extension to multiple dimensions is straightforward and can be found in the literature cited.

===Babenko–Beckner inequality===
The '''(''q'',&amp;nbsp;''p'')-norm''' of the Fourier transform is defined to be&lt;ref name=Bialynicki&gt;{{Cite journal | doi = 10.1103/PhysRevA.74.052101| title = Formulation of the uncertainty relations in terms of the Rényi entropies| journal = Physical Review A| volume = 74| issue = 5| year = 2006| last1 = Bialynicki-Birula | first1 = I. |arxiv = quant-ph/0608116 |bibcode = 2006PhRvA..74e2101B }}&lt;/ref&gt;

:&lt;math&gt;\|\mathcal F\|_{q,p} = \sup_{f\in L^p(\mathbb R)} \frac{\|\mathcal Ff\|_q}{\|f\|_p},&lt;/math&gt;   where &lt;math&gt;1 &lt; p \le 2~,&lt;/math&gt; &amp;nbsp; and &lt;math&gt;\frac 1 p + \frac 1 q = 1.&lt;/math&gt;

In 1961, Babenko&lt;ref&gt;K.I. Babenko.  ''An inequality in the theory of Fourier integrals.'' Izv. Akad. Nauk SSSR, Ser. Mat. '''25''' (1961) pp. 531&amp;ndash;542 English transl., Amer. Math. Soc. Transl. (2) '''44''', pp. 115-128&lt;/ref&gt; found this norm for ''even'' integer values of ''q''.  Finally, in 1975,
using [[Hermite functions]] as eigenfunctions of the Fourier transform, Beckner&lt;ref name=Beckner/&gt; proved that the value of this norm (in one dimension) for all ''q''  ≥  2  is
:&lt;math&gt;\|\mathcal F\|_{q,p} = \sqrt{p^{1/p}/q^{1/q}}.&lt;/math&gt;
Thus we have the '''[[Babenko–Beckner inequality]]''' that
:&lt;math&gt;\|\mathcal Ff\|_q \le \left(p^{1/p}/q^{1/q}\right)^{1/2} \|f\|_p.&lt;/math&gt;

===Rényi entropy bound===
From this inequality, an expression of the uncertainty principle in terms of the [[Rényi entropy]] can be derived.&lt;ref name=Bialynicki/&gt;&lt;ref&gt;H.P. Heinig and M. Smith, ''Extensions of the Heisenberg–Weil inequality.'' Internat. J. Math. &amp; Math. Sci., Vol. 9, No. 1 (1986) pp. 185&amp;ndash;192. [http://www.hindawi.com/GetArticle.aspx?doi=10.1155/S0161171286000212]&lt;/ref&gt;

Letting &lt;math&gt;g=\mathcal Ff&lt;/math&gt;,  2''α''=''p'',  and 2''β''=''q'',   so that  {{math|''1/α + 1/β'' {{=}} 2}}  and   1/2&lt;''α''&lt;1&lt;''β'',  we have
:&lt;math&gt;\left(\int_{\mathbb R} |g(y)|^{2\beta}\,dy\right)^{1/2\beta}
       \le \frac{(2\alpha)^{1/4\alpha}}{(2\beta)^{1/4\beta}}
       \left(\int_{\mathbb R} |f(x)|^{2\alpha}\,dx\right)^{1/2\alpha}.
&lt;/math&gt;
Squaring both sides and taking the logarithm, we get
:&lt;math&gt;\frac 1\beta \log\left(\int_{\mathbb R} |g(y)|^{2\beta}\,dy\right)
       \le \frac 1 2 \log\frac{(2\alpha)^{1/\alpha}}{(2\beta)^{1/\beta}}
       + \frac 1\alpha \log \left(\int_{\mathbb R} |f(x)|^{2\alpha}\,dx\right).
&lt;/math&gt;

Multiplying both sides by 
:&lt;math&gt;\frac{\beta}{1-\beta}=-\frac{\alpha}{1-\alpha}&lt;/math&gt; 
reverses the sense of the inequality,
:&lt;math&gt;\frac {1}{1-\beta} \log\left(\int_{\mathbb R} |g(y)|^{2\beta}\,dy\right)
       \ge \frac\alpha{2(\alpha-1)}\log\frac{(2\alpha)^{1/\alpha}}{(2\beta)^{1/\beta}}
       - \frac{1}{1-\alpha} \log \left(\int_{\mathbb R} |f(x)|^{2\alpha}\,dx\right) ~.
&lt;/math&gt;

Rearranging terms, finally yields  an inequality in terms of the sum of the Rényi entropies,
:&lt;math&gt;\frac{1}{1-\alpha} \log \left(\int_{\mathbb R} |f(x)|^{2\alpha}\,dx\right)
       + \frac {1}{1-\beta} \log\left(\int_{\mathbb R} |g(y)|^{2\beta}\,dy\right)
       \ge \frac\alpha{2(\alpha-1)}\log\frac{(2\alpha)^{1/\alpha}}{(2\beta)^{1/\beta}};
&lt;/math&gt;
:&lt;math&gt; H_\alpha(|f|^2) + H_\beta(|g|^2) \ge \frac 1 2 \left(\frac{\log\alpha}{\alpha-1}+\frac{\log\beta}{\beta-1}\right) - \log 2     ~.&lt;/math&gt;

Note that this inequality is symmetric with respect to  {{mvar|α}}  and {{mvar|β}}:  One no longer need assume that {{math|'' α&lt;β''}};  only that they are positive and not both one, and that  ''1/α + 1/β''   = 2.    To see this symmetry, simply exchange the rôles of  ''i''  and −''i''  in the Fourier transform.

===Shannon entropy bound===
Taking the limit of this last inequality as ''α, β''  → 1 yields the less general Shannon entropy inequality,
:&lt;math&gt;H(|f|^2) + H(|g|^2) \ge \log\frac e 2,\quad\textrm{where}\quad g(y) \approx \int_{\mathbb R} e^{-2\pi ixy}f(x)\,dx~,&lt;/math&gt;
valid for any base of logarithm, as long as we choose an appropriate unit of information, [[bit]], [[Nat (unit)|nat]], etc.

The constant will be different, though, for a different normalization of the Fourier transform, (such as is usually used in physics, with normalizations chosen so that ''ħ''=1 ), i.e.,
:&lt;math&gt;H(|f|^2) + H(|g|^2) \ge \log(\pi e)\quad\textrm{for}\quad g(y) \approx \frac 1{\sqrt{2\pi}}\int_{\mathbb R} e^{-ixy}f(x)\,dx~.&lt;/math&gt;
In this case, the dilation of the Fourier transform absolute squared by a factor of 2{{mvar|π}}  simply adds log(2{{mvar|π}}) to its entropy.

==Entropy versus variance bounds==
The Gaussian or [[normal probability distribution]] plays an important role in the relationship between [[variance]] and [[Differential entropy|entropy]]:  it is a problem of the [[calculus of variations]] to show that this distribution maximizes entropy for a given variance, and at the same time minimizes the variance for a given entropy.  In fact, for any probability density function  ''φ'' on the real line, Shannon's entropy inequality specifies:
:&lt;math&gt;H(\phi) \le \log \sqrt {2\pi eV(\phi)},&lt;/math&gt;
where ''H'' is the Shannon entropy and ''V'' is the variance, an inequality that is saturated only in the case of a [[normal distribution]].

Moreover, the Fourier transform of a Gaussian probability amplitude function is also Gaussian—and the absolute squares of both of these are Gaussian, too.  This  can then be used to derive the usual Robertson variance uncertainty inequality from the above entropic inequality, enabling ''the latter to be tighter than the former''. That is (for ''ħ''=1), exponentiating the Hirschman inequality and using Shannon's expression above, 
:&lt;math&gt;1/2 \le \exp (H(|f|^2)+H(|g|^2))         /(2e\pi)    \le \sqrt {V(|f|^2)V(|g|^2)}~.&lt;/math&gt;

Hirschman&lt;ref name=Hirschman/&gt; explained that entropy—his version of entropy was the negative of Shannon's—is a "measure of the concentration of [a probability distribution] in a set of small measure."  Thus ''a low or large negative Shannon entropy means that a considerable mass of the probability distribution is confined to a set of small measure''.

Note that this set of small measure need not be contiguous; a probability distribution can have several concentrations of mass in intervals of small measure, and the entropy may still be low no matter how widely scattered those intervals are.  This is not the case with the variance:  variance measures the concentration of mass about the mean of the distribution, and a low variance means that a considerable mass of the probability distribution is concentrated in a ''contiguous interval'' of small measure.

To formalize this distinction,  we say that two probability density functions  ''φ''&lt;sub&gt;1&lt;/sub&gt;  and ''φ''&lt;sub&gt;2&lt;/sub&gt; are '''equimeasurable''' if
:&lt;math&gt;\forall \delta &gt; 0,\,\mu\{x\in\mathbb R|\phi_1(x)\ge\delta\} = \mu\{x\in\mathbb R|\phi_2(x)\ge\delta\},&lt;/math&gt;
where {{mvar|μ}}  is the [[Lebesgue measure]].  Any two equimeasurable probability density functions have the same Shannon entropy, and in fact the same Rényi entropy, of any order.  The same is not true of variance, however.  Any probability density function has a radially decreasing equimeasurable "rearrangement" whose variance is less (up to translation) than any other rearrangement of the function; and there exist rearrangements of arbitrarily high variance, (all having the same entropy.)

==See also==
* [[Inequalities in information theory]]
* [[Uncertainty principle]]
* [[Riesz–Thorin theorem]]
* [[Fourier Transform]]

==References==
&lt;references/&gt;

==Further reading==
* Jizba, P.; Ma,Y.; Hayes, A.; Dunningham, J.A. (2016). "One-parameter class of uncertainty relations based on entropy power". ''Phys. Rev. E'' '''93''' (6): 060104(R). [https://journals.aps.org/pre/abstract/10.1103/PhysRevE.93.060104 doi:10.1103/PhysRevE.93.060104]. 
* {{Cite journal | last1 = Zozor | first1 = S. | last2 = Vignat | first2 = C. | doi = 10.1016/j.physa.2006.09.019 | title = On classes of non-Gaussian asymptotic minimizers in entropic uncertainty principles | journal = Physica A: Statistical Mechanics and its Applications | volume = 375 | issue = 2 | pages = 499 | year = 2007 | pmid =  | pmc = |arxiv = math/0605510 |bibcode = 2007PhyA..375..499Z }}    [https://arxiv.org/abs/math/0605510v1 arXiv:math/0605510v1]
* {{Cite journal | last1 = Maassen | first1 = H. | last2 = Uffink | first2 = J. | doi = 10.1103/PhysRevLett.60.1103 | title = Generalized entropic uncertainty relations | journal = Physical Review Letters | volume = 60 | issue = 12 | pages = 1103–1106 | year = 1988 | pmid =  10037942| pmc = |bibcode = 1988PhRvL..60.1103M | url = https://pure.uva.nl/ws/files/2210736/46650_28y.pdf }}
* {{Cite journal | doi = 10.1103/PhysRevA.75.022319| title = Entropic uncertainty relations and locking: Tight bounds for mutually unbiased bases| journal = Physical Review A| volume = 75| issue = 2| year = 2007| last1 = Ballester | first1 = M. | last2 = Wehner | first2 = S. |arxiv = quant-ph/0606244 |bibcode = 2007PhRvA..75b2319B }}
* {{Cite journal | doi = 10.1016/j.physleta.2003.08.029| title = An optimal entropic uncertainty relation in a two-dimensional Hilbert space| journal = Physics Letters A| volume = 317| pages = 32| year = 2003| last1 = Ghirardi | first1 = G. | last2 = Marinatto | first2 = L. | last3 = Romano | first3 = R. |arxiv = quant-ph/0310120 |bibcode = 2003PhLA..317...32G }}
* {{Cite journal | doi = 10.1023/A:1007464229188| title = Minimum uncertainty for antisymmetric wave functions| journal = Letters of Mathematical Physics| volume = 43| pages = 233| year = 1998| last1 = Salcedo | first1 = L. L. |arxiv = quant-ph/9706015 |bibcode = 1997quant.ph..6015S}}
{{DEFAULTSORT:Hirschman Uncertainty}}
[[Category:Quantum mechanical entropy]]
[[Category:Information theory]]
[[Category:Concepts in physics]]
[[Category:Inequalities]]</text>
      <sha1>f9e7hgr9tctdyn5zabk1trgvaepl85f</sha1>
    </revision>
  </page>
  <page>
    <title>Forward volatility</title>
    <ns>0</ns>
    <id>23265069</id>
    <revision>
      <id>789003729</id>
      <parentid>631466449</parentid>
      <timestamp>2017-07-04T19:06:50Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3560">'''Forward volatility''' is a measure of the [[implied volatility]] of a financial instrument over a period in the future, extracted from the term structure of volatility (which refers to how implied volatility differs for related financial instruments with different maturities).

==Underlying principle==
The variance is the [[Square (algebra)|square]] of differences of measurements from the [[mean]] divided by the number of samples. The [[standard deviation]] is the [[square root]] of the [[variance]]. 
The standard deviation of the continuously compounded returns of a [[financial instrument]]  is called [[Volatility (finance)|volatility]].

The (yearly) volatility in a given asset price or rate over a term that starts from &lt;math&gt;t_0=0&lt;/math&gt; corresponds to the spot volatility for that underlying, for the specific term. A collection of such volatilities forms a volatility term structure, similar to the [[yield curve]]. Just as [[forward rate]]s can be derived from a yield curve, forward volatilities can be derived from a given term structure of volatility.

==Derivation==
Given that the underlying [[random variable]]s for non overlapping time intervals are [[Independence (probability theory)|independent]], the variance is additive (see [[variance]]). So for yearly time slices we have the annualized volatility as

&lt;math&gt;\begin{align}
\sigma_{0,j}^2
&amp;= \frac{1}{j}(\sigma_{0,1}^2 + \sigma_{1,2}^2 + \cdots  + \sigma_{j-2,j-1}^2 + \sigma_{j-1,j}^2)\\
\Rightarrow \sigma_{j-1,j}
&amp;=\sqrt{j\sigma_{0,j}^2-\sum_{k=1}^{j-1}\sigma_{k-1,k}^2},
\end{align}
&lt;/math&gt;

where

:&lt;math&gt;j=1,2,\ldots&lt;/math&gt; is the number of years and the factor &lt;math&gt;\frac{1}{j}&lt;/math&gt; scales the variance so it is a yearly one

:&lt;math&gt;\sigma_{i,\,j}&lt;/math&gt; is the current (at time 0) forward volatility for the period &lt;math&gt;[i,\,j]&lt;/math&gt;

:&lt;math&gt;\sigma_{0,\,j}&lt;/math&gt; the spot volatility for maturity &lt;math&gt;j&lt;/math&gt;.

To ease computation and get a non-recursive representation, we can also express the forward volatility directly in terms of spot volatilities:&lt;ref&gt;Taleb, Nassim Nicholas (1997). Dynamic Hedging: 
Managing Vanilla and Exotic Options. New York: John Wiley &amp; Sons. {{ISBN|0-471-15280-3}}, pg 154&lt;/ref&gt;

&lt;math&gt;\begin{align}
\sigma_{0,j}^2
&amp;= \frac{1}{j}(\sigma_{0,1}^2 + \sigma_{1,2}^2 + \cdots  + \sigma_{j-1,j}^2)\\
&amp;= \frac{j-1}{j}\cdot\frac{1}{j-1}(\sigma_{0,1}^2 + \sigma_{1,2}^2 + \cdots  + \sigma_{j-2,j-1}^2) + \frac{1}{j}\sigma_{j-1,j}^2\\
&amp;= \frac{j-1}{j}\,\sigma_{0,j-1}^2 + \frac{1}{j}\sigma_{j-1,j}^2 \\
\Rightarrow \sigma_{j-1,j}
&amp;=\sqrt{j\sigma_{0,j}^2-(j-1)\sigma_{0,j-1}^2}
\end{align}
&lt;/math&gt;

Following the same line of argumentation we get in the general case with &lt;math&gt;t_0&lt;t&lt;T&lt;/math&gt; for the forward volatility seen at time &lt;math&gt;t_0&lt;/math&gt;:

&lt;math&gt;\sigma_{t,T}=\sqrt{\frac{(T-t_0)\sigma_{t_0,T}^2-(t-t_0)\sigma_{t_0,t}^2}{T-t}}&lt;/math&gt;,

which simplifies in the case of &lt;math&gt;t_0=0&lt;/math&gt; to

&lt;math&gt;\sigma_{t,T}=\sqrt{\frac{T\sigma_{0,T}^2-t\sigma_{0,t}^2}{T-t}}&lt;/math&gt;.

==Example==

The volatilities in the market for 90 days are 18% and for 180 days 16.6%. In our notation we have &lt;math&gt;\sigma_{0,\,0.25}&lt;/math&gt; = 18% and &lt;math&gt;\sigma_{0,\,0.5}&lt;/math&gt; = 16.6% (treating a year as 360 days). 
We want to find the forward volatility for the period starting with day 91 and ending with day 180. Using the above formular and setting &lt;math&gt;t_0=0&lt;/math&gt; we get

&lt;math&gt;\sigma_{0.25,\,0.5}=\sqrt{\frac{0.5\cdot 0.166^2-0.25\cdot 0.18^2}{0.25}}=0.1507\approx 15.1\%&lt;/math&gt;.

==References==

&lt;references/&gt;

[[Category:Mathematical finance]]</text>
      <sha1>8mvycjvi6ltjzi8wvjafzd83ywurpib</sha1>
    </revision>
  </page>
  <page>
    <title>Geometric class field theory</title>
    <ns>0</ns>
    <id>51692308</id>
    <revision>
      <id>740508913</id>
      <parentid>740494844</parentid>
      <timestamp>2016-09-21T14:17:37Z</timestamp>
      <contributor>
        <username>Jakob.scholbach</username>
        <id>1935000</id>
      </contributor>
      <minor/>
      <comment>cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="894">In mathematics, '''geometric class field theory''' is an extension of [[class field theory]] to higher-dimensional geometrical objects: much the same way as class field theory describes the [[abelianization]] of the [[Galois group]] of a [[local field|local]] or [[global field]], geometric class field theory describes the abelianized [[fundamental group]] of higher dimensional [[scheme (mathematics)|schemes]] in terms of data related to [[algebraic cycle]]s.

==References==

* {{cite book |last=Schmidt |first=Alexander |editor-first1=Stéphane|editor1=Ballet|editor-first2=Marc|editor2=Perret|editor-first3=Alexey|editor3= Zaytsev|title=Algorithmic arithmetic, geometry, and coding theory|publisher=Amer. Math. Soc. |date=2015 |pages=301–306 |chapter=A survey on class field theory for varieties|isbn=978-1-4704-1461-0 }}

[[Category:Class field theory]]
[[Category:Algebraic geometry]]</text>
      <sha1>aszk749qw5u3murdirpvkvbw2b273qv</sha1>
    </revision>
  </page>
  <page>
    <title>Hatching</title>
    <ns>0</ns>
    <id>1980381</id>
    <revision>
      <id>862178118</id>
      <parentid>857420970</parentid>
      <timestamp>2018-10-02T17:26:46Z</timestamp>
      <contributor>
        <username>YuriNikolai</username>
        <id>27925711</id>
      </contributor>
      <comment>added [[Category:Technical drawing]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3974">{{about||the emergence of young from an egg|Egg|the "crosshatch" symbol|Number sign|cross-hatching in writing|Crossed letter}}
{{multiple image
|align=right|total_width=500
|title=''Veronica''
|width1=952|height1=685|image1=Veronica.jpg|caption1=[[Albrecht Dürer]], ''Veronica'', [[engraving]], 1513. Example of hatching (e.g., background) and cross-hatching in many darker areas (visible if viewed at full size).|alt1=
|width2=229|height2=229|image2=Veronica detail.jpg|caption2=Detail of ''Veronica''|alt2=}}

'''Hatching''' (''hachure'' in [[French language|French]]) is an artistic technique used to create tonal or shading effects by [[drawing]] (or painting or scribing) closely spaced parallel lines. (It is also used in [[monochromatic]] [[heraldic]] representations to indicate what the [[Tincture (heraldry)|tincture]] of a "full-colour" [[Blazon|emblazon]] would be.) When lines are placed at an angle to one another, it is called '''cross-hatching'''.

Hatching is especially important in essentially linear media, such as drawing, and many forms of [[printmaking]], such as [[engraving]], [[etching]] and [[woodcut]]. In Western art, hatching originated in the [[Middle Ages]], and developed further into cross-hatching, especially in the [[old master print]]s of the fifteenth century. [[Master ES]] and [[Martin Schongauer]] in engraving and [[Erhard Reuwich]] and [[Michael Wolgemut]] in woodcut were pioneers of both techniques, and [[Albrecht Dürer]] in particular perfected the technique of crosshatching in both media.

Artists use the technique, varying the [[length]], [[angle]], closeness and other qualities of the lines, most commonly in drawing, linear painting and engraving.

==Technique==
The main concept is that the quantity, thickness and spacing of the lines will affect the brightness of the overall image, and emphasize forms creating the illusion of [[volume]]. Hatching lines should always follow (i.e. wrap around) the form. By increasing quantity, thickness and closeness, a darker area will result.

An area of shading next to another area which has lines going in another direction is often used to create [[Contrast (vision)|contrast]].

Line work can be used to represent colours, typically by using the same type of hatch to represent particular [[Tints and shades|tones]]. For example, red might be made up of lightly spaced lines, whereas green could be made of two layers of [[perpendicular]] dense lines, resulting in a realistic image.
{{clear}}

===Variations===

{{definition list}}

{{term|Linear hatching}}
{{defn|Hatching in parallel lines.  Normally the lines follow the direction of the described plane.{{sfn|South|2009|p=132}} }}

{{term|Crosshatching}}
{{defn|Layers of hatching applied at different angles to create different textures and darker tones.  At its simplest, a layer of linear hatching is laid over another layer at a 90° angle, to which further diagonal layers may be added.  Other methods include layering arbitrary intersecting patches.{{sfn|South|2009|p=132}}  Crosshatching in which layers intersect at slight angles can create a rippled [[moiré pattern|moiré]] effect.{{sfn|South|2009|p=133}}}}

{{term|Contoured hatching}}
{{defn|Hatching using curved lines to describe light and form of contours.{{sfn|South|2009|p=133}} }}

{{definition list end}}

==See also==
{{Portal|Visual arts}}
* [[Stippling]]
* [[Dip pen]]
* [[Printmaking]]
* [[hatching system|Hatching system (heraldry)]]

==References==

{{reflist}}

===Works cited===

{{Refbegin}}

{{cite book
|ref       = harv
|last      = South
|first     = Helen
|title     = The Everything Drawing Book
|url       = https://books.google.com/books?id=XycC6WY0C5AC
|year      = 2009
|publisher = Everything Books
|isbn      = 978-1-60550-446-9}}

{{Refend}}

==External links==
* [http://www.artlex.com/ArtLex/H.html#anchor4980622 "hatching" article in ArtLex Art Dictionary]

[[Category:Artistic techniques]]
[[Category:Technical drawing]]</text>
      <sha1>ljwrt9szjqswkv2m4ti3yxocrkfkyie</sha1>
    </revision>
  </page>
  <page>
    <title>Hybrid system</title>
    <ns>0</ns>
    <id>564719</id>
    <revision>
      <id>863121641</id>
      <parentid>863121443</parentid>
      <timestamp>2018-10-08T21:03:15Z</timestamp>
      <contributor>
        <username>Nahabedere</username>
        <id>199641</id>
      </contributor>
      <comment>/* Hybrid Systems Verification */ more precise formulation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11357">A '''hybrid system''' is a [[dynamical system]] that exhibits both continuous and discrete dynamic behavior&amp;nbsp;– a system that can both ''flow'' (described by a [[differential equation]]) and ''jump'' (described by a [[Finite-state machine|state machine]] or [[Automata theory|automaton]]).  Often, the term "hybrid dynamical system" is used, to distinguish over hybrid systems such as those that combine [[neural net]]s and [[fuzzy logic]], or electrical and mechanical drivelines.  A hybrid system has the benefit of encompassing a larger class of systems within its structure, allowing for more flexibility in modeling dynamic phenomena.

In general, the ''state'' of a hybrid system is defined by the values of the ''continuous variables'' and a discrete ''mode''. The state changes either continuously, according to a ''[[flow conditioning|flow condition]]'', or discretely according to a ''control graph''.  Continuous flow is permitted as long as so-called ''invariants'' hold, while discrete transitions can occur as soon as given ''jump conditions'' are satisfied. Discrete transitions may be associated with ''events''.

==Examples==

Hybrid systems have been used to model several cyber-physical systems, including [[physical system]]s with ''impact'', logic-dynamic [[Controller (control theory)|controllers]], and even [[Internet]] congestion.

===Bouncing ball===
A canonical example of a hybrid system is the [[bouncing ball]], a physical system with impact.  Here, the ball (thought of as a point-mass) is dropped from an initial height and bounces off the ground, dissipating its energy with each bounce.  The ball exhibits continuous dynamics between each bounce; however, as the ball impacts the ground, its velocity undergoes a discrete change modeled after an [[inelastic collision]].  A mathematical description of the bouncing ball follows.  Let &lt;math&gt;x_1&lt;/math&gt; be the height of the ball and &lt;math&gt;x_2&lt;/math&gt; be the velocity of the ball.  A hybrid system describing the ball is as follows:

When &lt;math&gt;x \in C = \{x_1 &gt; 0\}&lt;/math&gt;, flow is governed by
&lt;math&gt;
\dot{x_1} = x_2,
\dot{x_2} = -g
&lt;/math&gt;,
where &lt;math&gt;g&lt;/math&gt; is the acceleration due to gravity.  These equations state that when the ball is above ground, it is being drawn to the ground by gravity.

When &lt;math&gt;x \in D = \{x_1 = 0\}&lt;/math&gt;, jumps are governed by
&lt;math&gt;
x_1^+ = x_1,
x_2^+ = -\gamma x_2
&lt;/math&gt;,
where &lt;math&gt;0 &lt; \gamma &lt; 1&lt;/math&gt; is a dissipation factor.  This is saying that when the height of the ball is zero (it has impacted the ground), its velocity is reversed and decreased by a factor of &lt;math&gt;\gamma&lt;/math&gt;.  Effectively, this describes the nature of the inelastic collision.

The bouncing ball is an especially interesting hybrid system, as it exhibits [[Zeno of Elea|Zeno]] behavior.  Zeno behavior has a strict mathematical definition, but can be described informally as the system making an ''infinite'' number of jumps in a ''finite'' amount of time.  In this example, each time the ball bounces it loses energy, making the subsequent jumps (impacts with the ground) closer and closer together in time.

It is noteworthy that the dynamical model is complete if and only if one adds the contact force between the ground and the ball. Indeed, without forces, one cannot properly define the bouncing ball and the model is, from a mechanical point of view, meaningless. The simplest contact model that represents the interactions between the ball and the ground, is the complementarity relation between the force and the distance (the gap) between the ball and the ground. This is written as
&lt;math&gt;
0 \leq \lambda \perp x_1 \geq 0
&lt;/math&gt;
Such a contact model does not incorporate magnetic forces, nor gluing effects. When the complementarity relations are in, one can continue to integrate the system after the impacts have accumulated and vanished: the equilibrium of the system is well-defined as the static equilibrium of the ball on the ground, under the action of gravity compensated by the contact force &lt;math&gt;\lambda&lt;/math&gt;. One also notices from basic convex analysis that the complementarity relation can equivalently be rewritten as the inclusion into a normal cone, so that the bouncing ball dynamics is a differential inclusion into a normal cone to a convex set. See Chapters 1, 2 and 3 in Acary-Brogliato's book cited below (Springer LNACM 35, 2008). See also the other references on non-smooth mechanics.

== Hybrid Systems [[Formal verification|Verification]] ==
There are approaches to automatically proving properties of hybrid systems (e.g., some of the tools mentioned below). Common techniques for proving safety of hybrid systems are computation of reachable sets, [[Abstraction_model_checking|abstraction refinement]], and [[barrier certificate]]s.

Most verification tasks are undecidable,&lt;ref&gt;Thomas A. Henzinger, Peter W. Kopke, Anuj Puri, and Pravin Varaiya: What's Decidable about Hybrid Automata, Journal of Computer and System Sciences, 1998&lt;/ref&gt; making general verification algorithms impossible. Instead, the tools are analyzed for their capabilities on benchmark problems. A possible theoretical characterization of this is algorithms that succeed with hybrid systems verification in all robust cases&lt;ref&gt;Martin Fränzle: Analysis of Hybrid Systems: An ounce of realism can save an infinity of states, Springer LNCS 1683&lt;/ref&gt; implying that many problems for hybrid systems, while undecidable, are at least quasi-decidable.&lt;ref&gt;Stefan Ratschan: Safety verification of non-linear hybrid systems is quasi-decidable, Formal Methods in System Design, volume 44, pp. 71-90, 2014, {{doi|10.1007/s10703-013-0196-2}}&lt;/ref&gt;

==Other modeling approaches==
Two basic hybrid system modeling approaches can be classified, an implicit and an explicit one. The explicit approach is often represented by a [[hybrid automaton]], a [http://symbolaris.com/info/KeYmaera-guide.html#HP hybrid program] or a hybrid [[Petri net]]. The implicit approach is often represented by guarded equations to result in systems of [[differential algebraic equation]]s (DAEs) where the active equations may change, for example by means of a [[hybrid bond graph]].

As a unified simulation approach for hybrid system analysis, there is a method based on [[DEVS]] formalism in which integrators for differential equations are quantized into atomic [[DEVS]] models. These methods generate traces of system behaviors in discrete event system manner which are different from discrete time systems. Detailed of this approach can be found in references [Kofman2004] [CF2006] [Nutaro2010] and the software tool [[PowerDEVS]].

==Tools==
* [http://www.ariadne-cps.org Ariadne]: A C++ library for (numerically rigorous) reachability analysis of nonlinear hybrid systems
* [https://publish.illinois.edu/c2e2-tool/ C2E2]: Nonlinear hybrid system verifier
* [http://www.i6.in.tum.de/Main/SoftwareCORA CORA]: A MATLAB Toolbox for reachability analysis of cyber-physical systems, including hybrid systems
* [http://flowstar.org Flow*]: A tool for reachability analysis of nonlinear hybrid systems
* [http://stanleybak.com/projects/hycreate/hycreate.html HyCreate]: A Tool for Overapproximating Reachability of Hybrid Automata
* [http://www.mathworks.com/videos/hyeq-a-toolbox-for-simulation-of-hybrid-dynamical-systems-81992.html HyEQ]: A Hybrid System Solver for Matlab
* [https://ths.rwth-aachen.de/research/projects/hypro/ HyPro]: A C++ library for state set representations for hybrid systems reachability analysis
* [http://hsolver.sourceforge.net/ HSolver]: Verification of Hybrid Systems
* [http://embedded.eecs.berkeley.edu/research/hytech// HyTech]: A Model Checker for Hybrid Systems
* [http://symbolaris.com/info/KeYmaera.html KeYmaera]: A Hybrid Theorem Prover for Hybrid Systems
* [http://www-verimag.imag.fr/~frehse/phaver_web/ PHAVer]: Polyhedral Hybrid Automaton Verifier
* [[PowerDEVS]]: A general-purpose software tool for DEVS modeling and simulation oriented to the simulation of hybrid systems
* [http://spaceex.imag.fr/ SpaceEx]: State-Space Explorer
* [https://sites.google.com/a/asu.edu/s-taliro/s-taliro S-TaLiRo]: A MATLAB Toolbox for verification of Hybrid Systems with respect to Temporal Logic Specifications

==See also==
* [[Sliding mode control]]
* [[Variable structure system]]
* [[Variable structure control]]
* [[Joint spectral radius]]
* [[Cyber-physical system]]
* [[Behavior trees (artificial intelligence, robotics and control)]]
&lt;!--
*[[Hybrid Systems Visual Modeler]]
--&gt;

==Further reading==
* {{citation
 |last1=Henzinger 
 |first1=Thomas A. 
 |contribution=The Theory of Hybrid Automata 
 |title=11th Annual Symposium on Logic in Computer Science (LICS) 
 |series=IEEE Computer Society Press 
 |year=1996 
 |pages=278–292 
 |url=http://www.eecs.berkeley.edu/~tah/Publications/the_theory_of_hybrid_automata.html 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20100127162228/http://www.eecs.berkeley.edu/~tah/Publications/the_theory_of_hybrid_automata.html 
 |archivedate=2010-01-27 
 |df= 
}}
* {{citation
 |doi=10.1016/0304-3975(94)00202-T 
 |first1=Rajeev 
 |last1=Alur 
 |first2=Costas 
 |last2=Courcoubetis 
 |first3=Nicolas 
 |last3=Halbwachs 
 |first4=Thomas A. 
 |last4=Henzinger 
 |first5=Pei-Hsin 
 |last5=Ho 
 |first6=Xavier 
 |last6=Nicollin 
 |first7=Alfredo 
 |last7=Olivero 
 |first8=Joseph 
 |last8=Sifakis 
 |first9=Sergio 
 |last9=Yovine 
 |title=The algorithmic analysis of hybrid systems 
 |journal=Theoretical Computer Science 
 |volume=138 
 |issue=1 
 |pages=3–34 
 |year=1995 
 |url=http://www.eecs.berkeley.edu/~tah/Publications/the_algorithmic_analysis_of_hybrid_systems.html 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20100127162221/http://www.eecs.berkeley.edu/~tah/Publications/the_algorithmic_analysis_of_hybrid_systems.html 
 |archivedate=2010-01-27 
 |df= 
}}
* {{citation
    |last1=Goebel
    |first1=Rafal
    |last2=Sanfelice
    |first2=Ricardo G.
    |last3=Teel
    |first3=Andrew R.
    |title=Hybrid dynamical systems
    |journal=IEEE Control Systems Magazine
    |year=2009
    |volume=29
    |issue=2
    |pages=28–93
    |doi=10.1109/MCS.2008.931718}}
* {{citation
    |last1=Acary
    |first1=Vincent
    |last2=Brogliato
    |first2=Bernard
    |title=Numerical Methods for Nonsmooth Dynamical Systems
    |journal=Lecture Notes in Applied and Computational Mechanics
    |year=2008
    |volume=35 }}
* [Kofman2004] {{citation
    |doi=10.1137/S1064827502418379
    |last1=Kofman
    |first1=E
    |title=Discrete Event Simulation of Hybrid Systems
    |journal=SIAM Journal on Scientific Computing
    |year=2004
    |volume=25
    |issue=5
    |pages=1771–1797
|citeseerx=10.1.1.72.2475
    }}
* [CF2006] {{Citation|author = Francois E. Cellier and Ernesto Kofman| year = 2006| title = Continuous System Simulation| publisher = Springer| isbn = 978-0-387-26102-7 |edition=first}}
* [Nutaro2010] {{Citation|author = James Nutaro| year = 2010| title = Building Software for Simulation: Theory, Algorithms, and Applications in C++| publisher = Wiley|edition=first}}

==External links==
*[http://www.ieeecss.org/technical-activities/hybrid-systems IEEE CSS Committee on Hybrid Systems]

== References ==
{{Reflist}}

[[Category:Systems theory]]
[[Category:Differential equations]]
[[Category:Dynamical systems]]
[[Category:Control theory]]</text>
      <sha1>2nh9h9tvoa1sstkgkgitzv0uduqs4r4</sha1>
    </revision>
  </page>
  <page>
    <title>Induction-recursion</title>
    <ns>0</ns>
    <id>38365576</id>
    <revision>
      <id>844876509</id>
      <parentid>825448311</parentid>
      <timestamp>2018-06-07T19:40:49Z</timestamp>
      <contributor>
        <username>MusikBot</username>
        <id>24684472</id>
      </contributor>
      <minor/>
      <comment>Removing protection templates from unprotected page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6659">In [[intuitionistic type theory]] (ITT), a discipline within [[mathematical logic]], '''induction-recursion''' is a feature for simultaneously declaring a type and function on that type.  It allows the creation of larger types, such as universes, than [[Intuitionistic type theory#Inductive types|inductive types]].  The types created still remain [[Predicativity|predicative]] inside ITT.

An [[inductive definition]] is given by rules for generating elements of a type. One can then define functions from that type by induction on the way the elements of the type are generated. Induction-recursion generalizes this situation since one can ''simultaneously'' define the type and the function, because the rules for generating elements of the type are allowed to refer to the function.&lt;ref name=Dybjer&gt;{{cite journal|last=Dybjer|first=Peter|title=A general formulation of simultaneous inductive-recursive definitions in type theory|journal=Journal of Symbolic Logic|volume=65|issue=2|date=June 2000|pages=525–549|url=http://www.cse.chalmers.se/~peterd/papers/Inductive_Recursive.pdf|doi=10.2307/2586554}}&lt;/ref&gt;

Induction-recursion can be used to define large types including various universe constructions. It increases the proof-theoretic strength of type theory substantially. Nevertheless, inductive-recursive recursive definitions are still considered [[Impredicativity|predicative]].

==Background==

Induction-Recursion came out of investigations to the rules of Martin-Löf's [[intuitionistic type theory]].  The type theory has a number of "type formers" and four kinds of rules for each one.  Martin-Löf had hinted that the rules for each type former followed a pattern, which preserved the properties of the type theory (e.g., [[Normalization property (abstract rewriting)|strong normalization]], [[Impredicativity|predicativity]]).  Researchers started looking for the most general description of the pattern, since that would tell what kinds of type formers could be added (or not added!) to extend the type theory.

The "universe" type former was the most interesting, because when the rules were written "à la  Tarski", they simultaneously defined the "universe type" ''and ''a function that operated on it.  This eventually lead Dybjer to Induction-Recursion.

Dybjer's initial papers called Induction-Recursion a "schema" for rules.  It stated what type formers could be added to the type theory.  Later, he and Setzer would write a new type former with rules that allowed new Induction-Recursion definitions to be made inside the type theory.&lt;ref name=DybjerSetzer&gt;{{cite journal|last=Dybjer|first=Peter|title=A finite axiomatization of inductive-recursive definitions|journal=Lecture Notes in Computer Science|volume=1581|year=1999|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.219.2442}}&lt;/ref&gt;  This was added to the Half proof assistant (a variant of [[ALF (proof assistant)|Alf]]).

==The idea==

Before covering Inductive-Recursive types, the simpler case is Inductive Types.  Constructors for Inductive types can be self-referential, but in a limited way.  The constructor's parameters must be "positive":  
* not refer to the type being defined
* be exactly the type being defined, or
* be a function that returns the type being defined.

With Inductive types, a parameter's type can depend on earlier parameters, but they cannot refer to ones of the type being defined.  Inductive-Recursive types go further and parameter's types ''can'' refer to earlier parameters that use the type being defined.  These must be "half-positive":
* be a function depending on an earlier parameter '''if''' that parameter is wrapped in the function being defined.

So, if &lt;math&gt;D&lt;/math&gt; is the type being defined and &lt;math&gt;f&lt;/math&gt; is the function being (simultaneously) defined, these parameter declarations are positive:
* &lt;math&gt;a:A&lt;/math&gt;
* &lt;math&gt;d:D&lt;/math&gt;
* &lt;math&gt;g:A \to Type&lt;/math&gt;
* &lt;math&gt;h:A \to D&lt;/math&gt;
* &lt;math&gt;i:A \to B \to D&lt;/math&gt;
* &lt;math&gt;j: g\ a&lt;/math&gt;  (Depends on earlier parameters, none of which are type &lt;math&gt;D&lt;/math&gt;.)

This is half-positive:
* &lt;math&gt;k : (f\ d) \to D &lt;/math&gt;  (Depends on parameter &lt;math&gt;d&lt;/math&gt; of type &lt;math&gt;D&lt;/math&gt; but only through call to &lt;math&gt;f&lt;/math&gt;.)

These are '''not''' positive nor half-positive:
* &lt;math&gt;k: D \to A&lt;/math&gt;  (&lt;math&gt;D&lt;/math&gt; is a parameter to the function.)
* &lt;math&gt;l: (A \to D) \to A&lt;/math&gt;  (The parameter takes a function that returns &lt;math&gt;D&lt;/math&gt;, but returns &lt;math&gt;A&lt;/math&gt; itself.)
* &lt;math&gt;m: z\ d&lt;/math&gt;  (Depends on &lt;math&gt;d&lt;/math&gt; of type &lt;math&gt;D&lt;/math&gt;, but not through the function &lt;math&gt;f&lt;/math&gt;.)

== Universe example ==

A simple common example is the Universe à la  Tarski type former.  It creates a type &lt;math&gt;U&lt;/math&gt; and a function &lt;math&gt;T&lt;/math&gt;.  There is an element of &lt;math&gt;U&lt;/math&gt; for every type in the type theory (except &lt;math&gt;U&lt;/math&gt; itself!).  The function &lt;math&gt;T&lt;/math&gt; maps the elements of &lt;math&gt;U&lt;/math&gt; to the associated type.

The type &lt;math&gt;U&lt;/math&gt; has a constructor (or introduction rule) for each type former in the type theory.  The one for dependent functions would be:

&lt;math&gt;constructor_\Pi (u:U) (u' : (x: T(u)) U) : U&lt;/math&gt;

That is, it takes an element &lt;math&gt;u&lt;/math&gt; of type &lt;math&gt;U&lt;/math&gt; that will map to the type of the parameter and an element &lt;math&gt;u'&lt;/math&gt; that will map to the return type of the function (which is dependent on the value of the parameter).  (The final &lt;math&gt;:U&lt;/math&gt; says that the result of the constructor is an element of type &lt;math&gt;U&lt;/math&gt;.)

The reduction (or computation rule) says that

&lt;math&gt;T(constructor_\Pi(u, u'))&lt;/math&gt; becomes &lt;math&gt;\Pi( T(u), (x) T(u'(x)) )&lt;/math&gt;

After reduction, the function &lt;math&gt;T&lt;/math&gt; is operating on a smaller part of the input.  If that holds when &lt;math&gt;T&lt;/math&gt; is applied to any constructor, then &lt;math&gt;T&lt;/math&gt; will always terminate.  Without going into the details, Induction-Recursion states what kinds of definitions (or rules) can be added to the theory such that the function calls will always terminate.

==Usage==

Induction-Recursion is implemented in [[Agda (programming language)|Agda]] and [[Idris (programming language)|Idris]].

==See also==
* [[Induction-induction]] - further work that defines a type and family-of-types at the same time

==References==
{{reflist}}

== External links ==
*[http://www.cse.chalmers.se/~peterd/papers/inductive.html A list of Peter Dybjer's publications on induction and induction-recursion]
*[http://www.cs.swan.ac.uk/~csetzer/slides/dybjer60thBirthdayGothenburgJune2013/dybjer60thBirthdayGothenburgJune2013.pdf Slides covering Induction-Recursion and its derivatives]

[[Category:Type theory]]</text>
      <sha1>kb43unkqn1aoroipa5smrm5a77whsfz</sha1>
    </revision>
  </page>
  <page>
    <title>Integer points in convex polyhedra</title>
    <ns>0</ns>
    <id>25292663</id>
    <revision>
      <id>806735592</id>
      <parentid>786017858</parentid>
      <timestamp>2017-10-23T20:58:51Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* top */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2927">[[File:IP polytope with LP relaxation.png|right|thumb|300px|The red dots are the integer lattice points within the blue polygon, the latter representing a two-dimensional [[linear program]] ]]
The study of '''integer points in convex polyhedra'''&lt;ref&gt;In some contexts convex polyhedra are called simply "polyhedra".&lt;/ref&gt; is motivated by questions such as "how many nonnegative [[integer]]-valued solutions does a [[system of linear equations]] with nonnegative coefficients have" or "how many solutions does an [[integer linear program]] have". Counting integer points in [[polyhedra]] or other questions about them arise in [[representation theory]], [[commutative algebra]], [[algebraic geometry]],  [[statistics]], and [[computer science]].&lt;ref&gt;[http://math.sfsu.edu/beck/src06.html Integer points in polyhedra. Geometry, Number Theory, Representation Theory, Algebra, Optimization, Statistics], ACM--SIAM Joint Summer Research Conference, 2006&lt;/ref&gt;

The set of integer points, or, more generally, the set of points of an [[affine lattice]],  in a polyhedron is called '''Z-polyhedron''',&lt;ref&gt;The term "Z-polyhedron" is also used as a synonym to [[convex lattice polytope]], the [[convex hull]] of finitely many points in an affine lattice.&lt;/ref&gt; from the mathematical notation &lt;math&gt;\mathbb{Z}&lt;/math&gt; or '''Z''' for the set of integer numbers.&lt;ref&gt;"Computations on Iterated Spaces" in: The Compiler Design Handbook: Optimizations and Machine Code Generation, [[CRC Press]] 2007, 2nd edition, {{ISBN|1-4200-4382-X}}, [https://books.google.com/books?id=1kqAv-uDEPEC&amp;pg=PT465&amp;dq=%22Z-polyhedron%22#v=onepage&amp;q=%22Z-polyhedron%22&amp;f=false p.15-7]&lt;/ref&gt;

==Properties==
For a lattice &amp;Lambda;, [[Minkowski's theorem]] relates the number d(&amp;Lambda;) and the volume of a symmetric [[convex set]] ''S'' to the number of lattice points contained in ''S''.

The number of lattice points contained in a [[polytope]] all of whose vertices are elements of the lattice is described by the polytope's [[Ehrhart polynomial]]. Formulas for some of the coefficients of this polynomial involve d(&amp;Lambda;) as well.

==Applications==

===Loop optimization===
In certain approaches to [[loop optimization]], the set of the executions of the loop body is viewed as the set of integer points in a polyhedron defined by loop constraints.

==See also==
*[[Convex lattice polytope]]
*[[Pick's theorem]]

==References and notes==
{{reflist}}

==Further reading==
*"Integer Points In Polyhedra: Geometry, Number Theory, Algebra, Optimization: Proceedings of an AMS-IMS-SIAM Joint Summer Research Conference on Integer Points in Polyhedra, 2003 (''[[Contemporary Mathematics]]'' series, v. 374), 2005, {{ISBN|0-8218-3459-2}}   
*[[Alexander Barvinok]], ''Integer Points in Polyhedra'', 2008, {{ISBN|3-03719-052-3}}

[[Category:Lattice points]]
[[Category:Linear algebra]]
[[Category:Linear programming]]
[[Category:Polyhedra| ]]
[[Category:Polytopes]]</text>
      <sha1>lu50iovx3fz90o5ey961r417yf1r02h</sha1>
    </revision>
  </page>
  <page>
    <title>Johannes Hjelmslev</title>
    <ns>0</ns>
    <id>30961758</id>
    <revision>
      <id>789940273</id>
      <parentid>724262874</parentid>
      <timestamp>2017-07-10T16:08:27Z</timestamp>
      <contributor>
        <username>Mr KEBAB</username>
        <id>28161599</id>
      </contributor>
      <comment>it's a diphthong</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2584">'''Johannes Trolle Hjelmslev''' ({{IPA-da|ˈjɛlˀmslew|lang}}; 7 April 1873 –  16 February 1950) was a mathematician from [[Hørning]], [[Denmark]]. Hjelmslev worked in [[geometry]] and [[history of geometry]]. He was the discoverer and eponym of  the [[Hjelmslev transformation]], a method for [[Map (mathematics)|mapping]] an entire [[Hyperbolic space|hyperbolic plane]] into a [[circle]] with a finite [[radius]].
He was the father of [[Louis Hjelmslev]].

== Publications ==
*Johannes Hjelmslev, ''Grundprinciper for den infinitesimale Descriptivgeometri med Anvendelse paa Læren om variable Figurer. Afhandling for den philosophiske Doctorgrad'', 1897
*Johannes Hjelmslev, ''Deskriptivgeometri: Grundlag for Forelæsninger paa Polyteknisk Læreanstalt'', Jul. Gjellerup 1904
*Johannes Hjelmslev, [https://archive.org/details/geometriskeekspe00hjeluoft ''Geometriske Eksperimenter''], Jul. Gjellerup 1913
*Johannes Hjelmslev, [http://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=ACV4859 ''Darstellende Geometrie'', Teubner 1914]
*Johannes Hjelmslev, ''Geometrische Experimente'', Teubner 1915
*Johannes Hjelmslev, ''Lærebog i Geometri til Brug ved den Polytekniske Læreanstalt'', Jul. Gjellerup 1918
*Johannes Hjelmslev, [http://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=AJU1142 ''Die natürliche Geometrie- vier Vorträge'', Hamburger Mathematische Einzelschriften 1923]
*Johannes Hjelmslev, Om et af den danske matematiker Georg Mohr udgivet skrift ''Euclides Danicus', udkommet i Amsterdam i 1672", ''Matematisk Tidsskrift''  B, 1928, pp 1-7
*Johannes Hjelmslev, Grundlagen der projektiven Geometrie, 1929
*Johannes Hjelmslev, Beiträge zur Lebensbeschreibung von Georg Mohr, Det Kongelige Danske Videnskabernes Selskab, Math.-Fys. Meddelelser, Bd.11, 1931, Nr.4
*Johannes Hjelmslev, ''Grundlag for den projektive Geometri'', Gyldendal 1943

== See also ==
*[[Hjelmslev's theorem]]

== References ==
*{{MathGenealogy|id=21669}}
*Gottwald, Ilgauds, Schlote ''Lexikon bedeutender Mathematiker'', Leipzig 1990

==External links==
*''Salmonsens Konversationsleksikon'', [http://runeberg.org/salmonsen/2/11/0531.html]
*''Salmonsens Konversationsleksikon'', [http://runeberg.org/salmonsen/2/26/0514.html]

{{Authority control}}
{{DEFAULTSORT:Hjelmslev, Johannes Trolle}}
[[Category:1873 births]]
[[Category:1950 deaths]]
[[Category:20th-century mathematicians]]
[[Category:Danish mathematicians]]
[[Category:Geometers]]
[[Category:People from Aarhus]]
[[Category:University of Copenhagen faculty]]
[[Category:Rectors of the University of Copenhagen]]</text>
      <sha1>sgxdlzsmd9dq8ffwfq94mbo4dfjyvs3</sha1>
    </revision>
  </page>
  <page>
    <title>Joseph Bernstein</title>
    <ns>0</ns>
    <id>5815383</id>
    <revision>
      <id>862898418</id>
      <parentid>842799373</parentid>
      <timestamp>2018-10-07T12:10:46Z</timestamp>
      <contributor>
        <ip>2601:18C:600:1710:D1A4:C462:9698:628E</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5263">{{Dablink|For the Soviet spy see [[Joseph Milton Bernstein]].}}
{{Infobox scientist
| name              = Joseph Bernstein
| image             = Joseph Bernstein.jpg
| caption           = Joseph Bernstein&lt;br&gt;(picture from MFO)
| birth_date        = {{birth date and age|1945|04|18|df=y}}
| birth_place       = [[Moscow]], [[Russian SFSR]], [[Soviet Union]]
| death_date        = 
| death_place       = 
| nationality       = [[Israel]]i
| fields            = [[Mathematics]]
| workplaces        = [[Tel Aviv University]]&lt;br&gt;[[Harvard University]]
| alma_mater        = [[Moscow State University]]
| doctoral_advisor  = [[Israil Gelfand]]
| doctoral_students = [[Roman Bezrukavnikov]]&lt;br&gt;[[Alexander Braverman]]&lt;br&gt;[[Dennis Gaitsgory]]&lt;br&gt;[[Edward Frenkel]]
| known_for         = [[Bernstein–Sato polynomial]]; [[D-modules]]; Bernstein inequality; Bernstein–Gelfand–Gelfand resolution; proof of [[Kazhdan–Lusztig conjectures]]; [[perverse sheaves]]; [[Alexander Beilinson|Beilinson]]-Bernstein localization
| awards            = [[Israel Prize]] (2004)
}}
'''Joseph Bernstein''' (sometimes spelled '''I. N. Bernshtein'''; {{lang-he|יוס(י)ף נאומוביץ ברנשטיין}}; {{lang-ru|Иосиф Наумович Бернштейн}}, ''Iosif Naumovič Bernštejn''; born 18 April 1945) is an Soviet-born Israeli [[mathematician]] working at [[Tel Aviv University]]. He works in [[algebraic geometry]], [[representation theory]], and [[number theory]].

==Biography==
He got first prize in 1962 [[International Mathematical Olympiad]].&lt;ref&gt;https://www.imo-official.org/year_individual_r.aspx?year=1962&amp;column=total&amp;order=desc&amp;gender=hide&amp;nameform=western&lt;/ref&gt; Bernstein received his [[Doctor of Philosophy|Ph.D.]] in 1972 under [[Israel Gelfand]] at [[Moscow State University]], and moved to [[Harvard University|Harvard]] in 1983 due to growing [[anti-semitism]] in the Soviet Union.&lt;ref&gt;[http://www.thecrimson.com/article/1983/2/25/a-refugee-at-harvard-psoviet-mathematician/ ''A Refugee at Harvard — Harvard's Scientific Minds: Soviet Researcher Joins the Math Department''], The Harvard Crimson, February 25, 1983.&lt;/ref&gt; He was a visiting scholar at the [[Institute for Advanced Study]] in 1985-86 and again in 1997-98.&lt;ref&gt;[http://www.ias.edu/people/cos/ Institute for Advanced Study: A Community of Scholars]&lt;/ref&gt;

==Awards and honors==
Bernstein was elected to the [[Israel Academy of Sciences and Humanities]] in 2002 and was elected to the [[United States National Academy of Sciences]] in 2004.
In 2004, Bernstein was awarded the [[Israel Prize]] for mathematics.&lt;ref&gt;{{Cite web| title = Israel Prize Official Site (in Hebrew) – Recipient’s C.V. | url = http://cms.education.gov.il/EducationCMS/Units/PrasIsrael/Tashsad/YosefBernstein/KorotHaimYosefBernstain.htm}}&lt;/ref&gt;&lt;ref&gt;{{Cite web| title = Israel Prize Official Site (in Hebrew) – Judges' Rationale for Grant to Recipient | url = http://cms.education.gov.il/EducationCMS/Units/PrasIsrael/Tashsad/YosefBernstein/NimokyHsoftim.htm}}&lt;/ref&gt;
In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-10.&lt;/ref&gt;

==Publications==
* [http://www.math.tau.ac.il/~bernstei/Publication_list/Publication_list.html Publication list]
* [https://web.archive.org/web/20080926200045/http://www.math.uchicago.edu/~arinkin/langlands/Bernstein/ Some pdf files of papers by Bernstein] including [https://web.archive.org/web/20090530094129/http://www.math.uchicago.edu/~arinkin/langlands/Bernstein/Bernstein-dmod.pdf    Algebraic theory of D-modules] and his notes on ''Meromorphic continuation of Eisenstein series''
* Beilinson, A. A.; Bernstein, J.; Deligne, P. ''Faisceaux pervers.'' ([[Perverse sheaf|Perverse sheaves]]) Analysis and topology on singular spaces, I (Luminy, 1981), 5-171, Astérisque, 100, Soc. Math. France, Paris, 1982.

==See also==
* [[Bernstein–Sato polynomial]]
* [[BGG resolution]]
* [[Bernstein inequality for D modules]]
* [[Bernstein Center]]

==References==
{{Reflist}}

==External links==
* [http://www.math.tau.ac.il/~bernstei/ Bernstein's home page]
* {{MathGenealogy|id=18743}}

{{Authority control}}

{{DEFAULTSORT:Bernstein, Joseph}}
[[Category:1945 births]]
[[Category:Living people]]
[[Category:20th-century Russian mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Israeli mathematicians]]
[[Category:Russian emigrants to Israel]]
[[Category:Russian Jews]]
[[Category:Israeli Jews]]
[[Category:Jewish scientists]]
[[Category:Algebraic geometers]]
[[Category:Group theorists]]
[[Category:Number theorists]]
[[Category:Israel Prize in mathematics recipients]]
[[Category:EMET Prize recipients in the Exact Sciences]]
[[Category:Moscow State University alumni]]
[[Category:Tel Aviv University faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Members of the Israel Academy of Sciences and Humanities]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Soviet Jews]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:International Mathematical Olympiad participants]]


{{Russia-mathematician-stub}}
{{Israel-scientist-stub}}</text>
      <sha1>64vnrvv9bhib9w5xbj982qd3scgrps9</sha1>
    </revision>
  </page>
  <page>
    <title>Josephine D. Edwards</title>
    <ns>0</ns>
    <id>58612227</id>
    <revision>
      <id>862872515</id>
      <parentid>862475210</parentid>
      <timestamp>2018-10-07T07:42:13Z</timestamp>
      <contributor>
        <username>Afasmit</username>
        <id>560336</id>
      </contributor>
      <comment>defaultsort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4142">{{Infobox scientist
| honorific_prefix  = 
| name              = Josephine D. Edwards
| honorific_suffix  = 
| native_name       = 
| native_name_lang  = 
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = 
| birth_name        = Josephine Dianne Edwards&lt;!-- if different from "name" --&gt;
| birth_date        = {{Birth date|1942|08|18}}
| birth_place       = [[Oxford, England|Oxford]], [[England]], [[United Kingdom]]
| death_date        = {{death date and age |1985|05|25|1942|08|18}}
| death_place       = [[Canberra]], [[Australia]]
| death_cause       = 
| resting_place     = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| home_town         =
| other_names       = 
| pronounce         =
| residence         = 
| citizenship       = Australia
| nationality       = English
| fields            = Mathematics
| workplaces        = 
| patrons           = 
| education         = 
| alma_mater        = [[University of Oxford]]
| thesis_title      = &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor  = &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| known_for         = Founder of the [[Australian Mathematics Competition]]
| influences        = 
| influenced        = 
| awards            = BH Neumann Award
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse            = John Pulley&lt;!--(or | spouses = )--&gt;
| partner           = &lt;!--(or | partners = )--&gt;
| children          = 
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| website           = &lt;!--{{URL|www.example.com}}--&gt;
| footnotes         = 
}}
'''Josephine Dianne Edwards''' (18 August 1942 &amp;ndash; 25 May 1985) was an [[Australia]]n mathematician and [[mathematics education|mathematics educator]] who founded the [[Australian Mathematics Competition]].

She was born in [[Oxford]] and was educated at the [[Brentwood Ursuline Convent High School|Ursuline School]] in [[Brentwood, Essex|Brentwood]]. She went on to study mathematics at the [[University of Oxford]]. In 1964, Edwards moved to [[Canberra]]. She taught mathematics at [[secondary school]]s in the [[Australian Capital Territory]]. In 1979, she joined the faculty at the [[College of Advanced Education]] in Canberra, later the [[University of Canberra]]. For eighteen years, she was a member of the Canberra Mathematical Association, also serving as its vice-president, president and secretary.&lt;ref name=times/&gt;

She helped establish and run the [[Australian Mathematics Competition]], serving as chair of its founding committee, as a member of its board of governors from 1977 to 1985 and as editor for its publications from 1979. She was also an associate editor for the American publication ''[[The College Mathematics Journal]]''. Her articles on teaching mathematics appeared in journals in Australia, Canada and France.&lt;ref name=times/&gt;

She was married to John Pulley; the couple had three children as well as three children from Pulley's prior marriage.&lt;ref name=times/&gt;

Edwards died in Canberra at the age of 42.&lt;ref name=times&gt;{{cite news |url=https://sites.google.com/site/pjt154/home/a4-life-tributes/edwards-jd |title=Obituary: Josephine Dianne Edwards |newspaper=Canberra Times |date=29 May 1985}}&lt;/ref&gt;

In 1996, she was awarded a BH Neumann Award.&lt;ref&gt;{{cite web |url=https://www.amt.edu.au/about-amt/awards-bios/1996-bh-neumann-awards/ |title=1996 BH Neumann Awards |publisher=Australian Mathematics Trust}}&lt;/ref&gt;

== References ==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Edwards, Josephine D.}}
[[Category:1942 births]]
[[Category:1985 deaths]]
[[Category:Australian mathematicians]]
[[Category:Australian schoolteachers]]
[[Category:Women mathematicians]]
[[Category:Alumni of the University of Oxford]]

{{mathematician-stub}}
{{Australia-academic-bio-stub}}</text>
      <sha1>61effwhunuf4061b0g1kkoeupa087cj</sha1>
    </revision>
  </page>
  <page>
    <title>Kato's conjecture</title>
    <ns>0</ns>
    <id>3543381</id>
    <revision>
      <id>839968028</id>
      <parentid>839967397</parentid>
      <timestamp>2018-05-06T21:59:25Z</timestamp>
      <contributor>
        <username>Donutmug</username>
        <id>33608720</id>
      </contributor>
      <minor/>
      <comment>corrected malformed code</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1757">'''Kato's conjecture''' is a [[mathematical problem]] named after [[mathematician]] [[Tosio Kato]], of the [[University of California, Berkeley]]. Kato initially posed the problem in 1953.&lt;ref&gt;{{cite journal | first=Tosio | last=Kato | title=Integration of the equation of evolution in a Banach space | journal= J. Math. Soc. Japan | volume=5 | year=1953 | pages=208–234 | mr=0058861 | doi=10.2969/jmsj/00520208}}&lt;/ref&gt;

Kato asked whether the square root of certain [[elliptic operator]]s, defined via [[functional calculus]], are [[analytic function|analytic]]. The full statement of the problem as given by Auscher et. al. is: "the domain of the square root of a uniformly complex elliptic operator L =-div (AV) with bounded measurable coefficients in '''R'''&lt;sup&gt;n&lt;/sup&gt; is the Sobolev space ''H''&lt;sup&gt;1&lt;/sup&gt;('''R'''&lt;sup&gt;n&lt;/sup&gt;) in any dimension with the estimate &lt;math&gt;||\sqrt{L}f||_{2} \sim ||\nabla f||_{2}&lt;/math&gt;". &lt;ref name=":0" /&gt;

The problem remained unresolved for nearly a half-century, until it was jointly solved in 2001 by [[Pascal Auscher]], [[Steve Hofmann]], [[Michael Lacey]], [[Alan McIntosh]], and [[Philippe Tchamitchian]].&lt;ref name=":0"&gt;{{cite journal | first1=Pascal | last1=Auscher | first2=Steve | last2=Hofmann | first3=Michael | last3=Lacey | first4=Alan | last4=McIntosh | first5=Philippe | last5=Tchamitchian | title=The solution of the Kato square root problem for second order elliptic operators on '''R'''&lt;sup&gt;''n''&lt;/sup&gt; | journal=[[Annals of Mathematics]] | volume=156 | issue=2 | pages=633&amp;ndash;654 | year=2002 | doi=10.2307/3597201 | mr=1933726}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==

{{mathanalysis-stub}}
[[Category:Differential operators]]
[[Category:Operator theory]]
[[Category:Conjectures]]</text>
      <sha1>3uo0vkeqeqmug59mihyighc4hmp718a</sha1>
    </revision>
  </page>
  <page>
    <title>Leveler</title>
    <ns>0</ns>
    <id>2697574</id>
    <revision>
      <id>774174867</id>
      <parentid>774174797</parentid>
      <timestamp>2017-04-06T18:55:20Z</timestamp>
      <contributor>
        <username>Excirial</username>
        <id>5499713</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/69.177.92.242|69.177.92.242]] ([[User talk:69.177.92.242|talk]]) ([[WP:HG|HG]]) (3.1.22)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1000">{{For|the August Burns Red album|Leveler (album)}}
{{otheruses|Levellers (disambiguation)}}
{{unreferenced|date=August 2015}}
A '''leveler''' performs an [[Audio signal processing|audio process]] similar to [[Dynamic range compression (audio)|compression]], which is used to reduce the [[dynamic range]] of a signal, so that the quietest portion of the signal is loud enough to hear and the loudest portion is not too loud. A leveler is different from a compressor in that the ratio and threshold are controlled with a single control. Levelers work especially well with vocals, as there are huge dynamic differences in the [[human voice]] and levelers work in such a way as to sound very natural, letting the character of the sound change with the different levels but still maintaining a predictable and usable dynamic range.

==External links==
* [http://www.summitaudio.com/tla100_specs.html Summit Audio TLA-100 Tube Levelling Amplifier]
[[Category:Signal processing]]

{{Signal-processing-stub}}</text>
      <sha1>6wj4x2at94x8ciey3v1v1r1rrccnfil</sha1>
    </revision>
  </page>
  <page>
    <title>Levi graph</title>
    <ns>0</ns>
    <id>1396888</id>
    <revision>
      <id>830935160</id>
      <parentid>821886747</parentid>
      <timestamp>2018-03-17T20:02:42Z</timestamp>
      <contributor>
        <username>Rich Farmbrough</username>
        <id>82835</id>
      </contributor>
      <minor/>
      <comment>Spell out American postal abbreviations (Florida) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5410">{{Infobox graph
 | name     = Levi graph
 | image    = [[File:Levi graph of Pappus Configuration.png|frameless]]
 | image_caption = The [[Pappus graph]], a Levi graph with 18 vertices formed from the [[Pappus configuration]]. Vertices labeled with single letters correspond to points in the configuration; vertices labeled with three letters correspond to lines through three points.
 | namesake =
 | vertices =
 | edges    =
 | radius   =
 | diameter =
 | girth    = ≥ 6
 | chromatic_number =
 | chromatic_index  =
 | properties =
}}
In [[combinatorics|combinatorial mathematics]], a '''Levi graph''' or '''incidence graph''' is a [[bipartite graph]] associated with an [[incidence structure]].&lt;ref name="bg"&gt;{{citation
 | last = Grünbaum | first = Branko | author-link = Branko Grünbaum
 | contribution = Configurations of points and lines
 | location = Providence, RI
 | mr = 2209028
 | pages = 179–225
 | publisher = American Mathematical Society
 | title = The Coxeter Legacy
 | year = 2006}}. See in particular [https://books.google.com/books?id=cKpBGcqpspIC&amp;pg=PA181 p. 181].&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Polster | first = Burkard |author-link=Burkard Polster
 | doi = 10.1007/978-1-4419-8526-2
 | isbn = 0-387-98437-2
 | location = New York
 | mr = 1640615
 | page = 5
 | publisher = Springer-Verlag
 | series = Universitext
 | title = A Geometrical Picture Book
 | url = https://books.google.com/books?id=2PtPG4qjfZAC&amp;pg=PA5
 | year = 1998}}.&lt;/ref&gt; From a collection of points and lines in an [[incidence geometry]] or a [[projective configuration]], we form a graph with one vertex per point, one vertex per line, and an edge for every incidence between a point and a line. They are named for [[F. W. Levi]], who wrote about them in 1942.&lt;ref name="bg"/&gt;&lt;ref&gt;{{citation
 | last = Levi | first = F. W. | author-link = Friedrich Wilhelm Levi
 | location = Calcutta
 | mr = 0006834
 | publisher = University of Calcutta
 | title = Finite Geometrical Systems
 | year = 1942}}.&lt;/ref&gt;

The Levi graph of a system of points and lines usually has [[girth (graph theory)|girth]] at least six: Any 4-[[Cycle graph|cycles]] would correspond to two lines through the same two points. Conversely any bipartite graph with girth at least six can be viewed as the Levi graph of an abstract incidence structure.&lt;ref name="bg"/&gt; Levi graphs of configurations are [[biregular graph|biregular]], and every biregular graph with girth at least six can be viewed as the Levi graph of an abstract configuration.&lt;ref&gt;{{citation
 | last = Gropp | first = Harald
 | editor1-last = Colbourn | editor1-first = Charles J.
 | editor2-last = Dinitz | editor2-first = Jeffrey H.
 | contribution = VI.7 Configurations
 | edition = Second
 | pages = 353–355
 | publisher = Chapman &amp; Hall/CRC, Boca Raton, Florida
 | series = Discrete Mathematics and its Applications (Boca Raton)
 | title = Handbook of combinatorial designs
 | year = 2007}}.&lt;/ref&gt;

Levi graphs may also be defined for other types of incidence structure, such as the incidences between points and planes in [[Euclidean space]]. For every Levi graph, there is an equivalent [[hypergraph]], and vice versa.

== Examples ==
* The [[Desargues graph]] is the Levi graph of the [[Desargues configuration]], composed of 10 points and  10 lines. There are 3 points on each line, and 3 lines passing through each point. The Desargues graph can also be viewed as the [[generalized Petersen graph]] G(10,3) or the [[Kneser graph|bipartite Kneser graph]] with parameters 5,2. It is 3-regular with 20 vertices.
* The [[Heawood graph]] is the Levi graph of the [[Fano plane]]. It is also known as the (3,6)-[[cage (graph theory)|cage]], and is 3-regular with 14 vertices.
* The [[Möbius–Kantor graph]] is the Levi graph of the [[Möbius–Kantor configuration]], a system of 8 points and 8 lines that cannot be realized by straight lines in the Euclidean plane. It is 3-regular with 16 vertices.
* The [[Pappus graph]] is the Levi graph of the [[Pappus configuration]], composed of 9 points and 9 lines. Like the Desargues configuration there are 3 points on each line and 3 lines passing through each point. It is 3-regular with 18 vertices.
* The [[Gray graph]] is the Levi graph of a configuration that can be realized in '''R'''&lt;sup&gt;3&lt;/sup&gt; as a 3×3×3 grid of 27 points and the 27 orthogonal lines through them.
* The [[Tutte eight-cage]] is the Levi graph of the [[Cremona–Richmond configuration]]. It is also known as the (3,8)-cage, and is 3-regular with 30 vertices.
* The four-dimensional [[hypercube graph]] ''Q''&lt;sub&gt;4&lt;/sub&gt; is the Levi graph of the [[Möbius configuration]] formed by the points and planes of two mutually incident tetrahedra.
* The [[Ljubljana graph]] on 112 vertices is the Levi graph of the Ljubljana configuration.&lt;ref name="LUB"&gt;{{citation
 | last1 = Conder | first1 = M.
 | last2 = Malnič | first2 = A.
 | last3 = Marušič | first3 = D.
 | last4 = Pisanski | first4 = T. | author4-link = Tomaž Pisanski
 | last5 = Potočnik | first5 = P.
 | publisher = University of Ljubljana Department of Mathematics
 | series = IMFM Preprint 40-845
 | title = The Ljubljana Graph
 | url = http://www.imfm.si/preprinti/PDF/00845.pdf
 | year = 2002}}.&lt;/ref&gt;

== References ==
{{reflist}}

==External links==
*{{MathWorld|urlname=LeviGraph|title=Levi Graph}}

[[Category:Set families]]
[[Category:Configurations]]
[[Category:Geometric graphs]]</text>
      <sha1>d954foycgbkjrcgfvfdaie6zvcktqgt</sha1>
    </revision>
  </page>
  <page>
    <title>Littlewood's three principles of real analysis</title>
    <ns>0</ns>
    <id>1882363</id>
    <revision>
      <id>674719226</id>
      <parentid>631532756</parentid>
      <timestamp>2015-08-05T18:11:19Z</timestamp>
      <contributor>
        <username>BattyBot</username>
        <id>15996738</id>
      </contributor>
      <minor/>
      <comment>fixed citation template(s) to remove page from [[:Category:CS1 maint: Extra text]] &amp; [[WP:AWB/GF|general fixes]] using [[Project:AWB|AWB]] (11334)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2958">'''Littlewood's three principles of [[real analysis]]''' are [[heuristics]] of [[J. E. Littlewood]] to help teach the essentials of [[measure theory]] in [[mathematical analysis]].

==The principles==

Littlewood stated the principles in his 1944 ''Lectures on the Theory of Functions''
&lt;ref&gt;
{{cite book
|last=Littlewood
|first=J. E.
|authorlink=John Edensor Littlewood
|title=Lectures on the Theory of Functions
|year=1944
|publisher=Oxford University Press
|oclc=297140
|page=26
}}
&lt;/ref&gt;
as:
{{quote|There are three principles, roughly expressible in the following terms: Every ([[measurable set|measurable]]) set is nearly a finite sum of intervals; every function (of class ''L''&lt;sup&gt;p&lt;/sup&gt;) is nearly [[Continuous function|continuous]]; every [[Limit of a sequence|convergent]] sequence of functions is nearly [[uniformly convergent]].}}

The first principle is based on the fact that the [[inner measure]] and [[outer measure]] are equal for measurable sets, the second is based on [[Lusin's theorem]], and the third is based on [[Egorov's theorem]].

==Example==

Littlewood's three principles are quoted in several real analysis texts, for example Royden,&lt;ref name="Royden"&gt;
{{cite book 
| last = Royden 
| first = H. L.
| title = Real Analysis 
| publisher = Macmillan 
| location = New York 
| edition=3rd
| year = 1988 
| isbn = 978-0-02-404151-7
| page=72 }}
&lt;/ref&gt;
Bressoud,&lt;ref&gt;
{{cite book | last = Bressoud | first = David |authorlink=David Bressoud| title = A Radical Approach to Lebesgue's Theory of Integration | publisher = Cambridge University Press | location = Cambridge | year = 2008 | isbn = 978-0-521-88474-7 | page=191 }}
&lt;/ref&gt;
and Stein &amp; Shakarchi.&lt;ref&gt;
{{cite book 
| last = Stein 
| first = Elias 
| authorlink = Elias M. Stein
|author2=Rami Shakarchi
 | title = Real Analysis: Measure Theory, Integration, and Hilbert Spaces
| url = http://press.princeton.edu/chapters/s8008.pdf
| format = PDF
| accessdate = 2008-07-03
| publisher = Princeton University Press 
| location = Princeton 
| year = 2005 
| isbn = 978-0-691-11386-9
| page=33 }}
&lt;/ref&gt;

Royden&lt;ref&gt;Royden (1988), p. 84&lt;/ref&gt; gives the [[bounded convergence theorem]] as an application of the third principle. The theorem states that if a uniformly bounded sequence of functions converges pointwise, then their integrals on a set of finite measure converge to the integral of the limit function. If the convergence were uniform this would be a trivial result, and Littlewood's third principle tells us that the convergence is almost uniform, that is, uniform outside of a set of arbitrarily small measure. Because the sequence is bounded, the contribution to the integrals of the small set can be made arbitrarily small, and the integrals on the remainder converge because the functions are uniformly convergent there.

==Notes==
&lt;references /&gt;

[[Category:Real analysis]]
[[Category:Heuristics]]
[[Category:Measure theory]]
[[Category:Mathematical principles]]</text>
      <sha1>qa9ec2ngsmx27uyaaewmps206vyx5hx</sha1>
    </revision>
  </page>
  <page>
    <title>Luca Incurvati</title>
    <ns>0</ns>
    <id>26959564</id>
    <revision>
      <id>718057753</id>
      <parentid>717438177</parentid>
      <timestamp>2016-05-01T08:56:33Z</timestamp>
      <contributor>
        <username>KasparBot</username>
        <id>24420788</id>
      </contributor>
      <comment>migrating [[Wikipedia:Persondata|Persondata]] to Wikidata, [[toollabs:kasparbot/persondata/|please help]], see [[toollabs:kasparbot/persondata/challenge.php/article/Luca Incurvati|challenges for this article]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="948">'''Luca Incurvati''' is currently an Assistant Professor at the [[University of Amsterdam]] and formerly a  lecturer at the [[University of Cambridge]]. He was awarded the [[Matthew Buncombe Prize]] for his masters thesis in 2005. He earned his PhD in philosophy at St John's College, Cambridge under the supervision of Michael Potter and Peter Smith. He has served as Director of Studies at Fitzwilliam, Gonville and Caius and Magdalene colleges at Cambridge.

==External links ==
*[http://sites.google.com/site/lucaincurvati/home Personal webpage]
*[http://philpapers.org/autosense.pl?searchStr=Luca%20Incurvati Papers by Incurvati at PhilPapers]

{{DEFAULTSORT:Incurvati, Luca}}
[[Category:Philosophers of mathematics]]
[[Category:Contemporary philosophers]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:Fellows of Fitzwilliam College, Cambridge]]
[[Category:Fellows of Magdalene College, Cambridge]]
[[Category:Living people]]</text>
      <sha1>3q0zb7bx6iar7dfsghtixkzi7o45r0g</sha1>
    </revision>
  </page>
  <page>
    <title>Malleability (cryptography)</title>
    <ns>0</ns>
    <id>87027</id>
    <revision>
      <id>840230042</id>
      <parentid>840228882</parentid>
      <timestamp>2018-05-08T15:15:17Z</timestamp>
      <contributor>
        <username>Jhertel</username>
        <id>119408</id>
      </contributor>
      <comment>/* Complete non-malleability */ Added missing citation.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6484">'''Malleability''' is a property of some [[cryptography|cryptographic]] [[algorithm]]s.&lt;ref&gt;{{cite journal
 | first1 = Danny 
 | last1 = Dolev
 | author2-link = Cynthia Dwork
 | first2 = Cynthia
 | last2 = Dwork
 | author3-link = Moni Naor
 | first3 = Moni
 | last3 = Naor
 | title = Nonmalleable Cryptography
 | journal = [[SIAM Journal on Computing]]
 | volume = 30
 | issue = 2
 | pages = 391–437
 | year = 2000
 | doi = 10.1137/S0097539795291562
}}&lt;/ref&gt; An encryption algorithm is "malleable" if it is possible to transform a [[ciphertext]] into another ciphertext which decrypts to a related [[plaintext]]. That is, given an encryption of a plaintext &lt;math&gt;m&lt;/math&gt;, it is possible to generate another ciphertext which decrypts to &lt;math&gt;f(m)&lt;/math&gt;, for a known function &lt;math&gt;f&lt;/math&gt;, without necessarily knowing or learning &lt;math&gt;m&lt;/math&gt;.

Malleability is often an undesirable property in a general-purpose cryptosystem, since it allows an attacker to modify the contents of a message.  For example, suppose that a bank uses a stream cipher to hide its financial information, and a user sends an encrypted message containing, say, "&lt;tt&gt;TRANSFER $0000100.00 TO ACCOUNT #199&lt;/tt&gt;."  If an attacker can modify the message on the wire, and can guess the format of the unencrypted message, the attacker could be able to change the amount of the transaction, or the recipient of the funds, e.g.  "&lt;tt&gt;TRANSFER $0100000.00 TO ACCOUNT #227&lt;/tt&gt;". Malleability does not refer to the attacker's ability to read the encrypted message. Both before and after tampering, the attacker cannot read the encrypted message.

On the other hand, some cryptosystems are malleable by design. In other words, in some circumstances it may be viewed as a feature that anyone can transform an encryption of &lt;math&gt;m&lt;/math&gt; into a valid encryption of &lt;math&gt;f(m)&lt;/math&gt;  (for some restricted class of functions &lt;math&gt;f&lt;/math&gt;) without necessarily learning &lt;math&gt;m&lt;/math&gt;. Such schemes are known as [[homomorphic encryption]] schemes.

A cryptosystem may be [[Semantic security|semantically secure]] against [[chosen plaintext attack]]s or even non-adaptive [[chosen ciphertext attack]]s (CCA1) while still being malleable. However, security against [[adaptive chosen ciphertext attack]]s (CCA2) is equivalent to non-malleability.&lt;ref name=":0"&gt;{{Cite book|url=https://link.springer.com/chapter/10.1007/BFb0055718 |work= Advances in Cryptology — CRYPTO '98 |title= Relations among notions of security for public-key encryption schemes |last=Bellare |first=Mihir |last2=Desai |first2=Anand |last3= Pointcheval |first3=David |last4=Rogaway |first4=Phillip |date= 1998-08-23 |publisher= Springer Berlin Heidelberg |isbn= 978-3540648925 |editor-last= Krawczyk |editor-first= Hugo |series= Lecture Notes in Computer Science |pages= 26–45 |language=en |doi= 10.1007/bfb0055718}}&lt;/ref&gt;

==Example malleable cryptosystems==
In a [[stream cipher]], the ciphertext is produced by taking the [[exclusive or]] of the plaintext and a [[pseudorandom]] stream based on a secret key &lt;math&gt;k&lt;/math&gt;, as &lt;math&gt;E(m) = m \oplus S(k)&lt;/math&gt;. An adversary can construct an encryption of &lt;math&gt;m \oplus t&lt;/math&gt; for any &lt;math&gt;t&lt;/math&gt;, as &lt;math&gt;E(m) \oplus t = m \oplus t \oplus S(k) = E(m \oplus t)&lt;/math&gt;.

In the [[RSA (algorithm)|RSA]] cryptosystem, a plaintext &lt;math&gt;m&lt;/math&gt; is encrypted as &lt;math&gt;E(m) = m^e \bmod n&lt;/math&gt;, where &lt;math&gt;(e,n)&lt;/math&gt; is the public key. Given such a ciphertext, an adversary can construct an encryption of &lt;math&gt;mt&lt;/math&gt; for any &lt;math&gt;t&lt;/math&gt;, as &lt;math display="inline"&gt;E(m) \cdot t^e \bmod n = (mt)^e \bmod n = E(mt)&lt;/math&gt;. For this reason, RSA is commonly used together with [[padding (cryptography)|padding]] methods such as [[Optimal Asymmetric Encryption Padding|OAEP]] or PKCS1.

In the [[ElGamal]] cryptosystem, a plaintext &lt;math&gt;m&lt;/math&gt; is encrypted as &lt;math&gt;E(m) = (g^b, m A^b)&lt;/math&gt;, where &lt;math&gt;(g,A)&lt;/math&gt; is the public key. Given such a ciphertext &lt;math&gt;(c_1, c_2)&lt;/math&gt;, an adversary can compute &lt;math&gt;(c_1, t \cdot c_2)&lt;/math&gt;, which is a valid encryption of &lt;math&gt;tm&lt;/math&gt;, for any &lt;math&gt;t&lt;/math&gt;.
In contrast, the [[Cramer-Shoup system]] (which is based on ElGamal) is not malleable.

In the [[Paillier cryptosystem|Paillier]], [[ElGamal]], and [[RSA (algorithm)|RSA]] cryptosystems, it is also possible to combine ''several'' ciphertexts together in a useful way to produce a related ciphertext. In Paillier, given only the public key and an encryption of &lt;math&gt;m_1&lt;/math&gt; and &lt;math&gt;m_2&lt;/math&gt;, one can compute a valid encryption of their sum &lt;math&gt;m_1+m_2&lt;/math&gt;. In ElGamal and in RSA, one can combine encryptions of &lt;math&gt;m_1&lt;/math&gt; and &lt;math&gt;m_2&lt;/math&gt; to obtain a valid encryption of their product &lt;math&gt;m_1 m_2&lt;/math&gt;.

Block ciphers in the [[cipher block chaining]] mode of operation, for example, are partly malleable: flipping a bit in a ciphertext block will completely mangle the plaintext it decrypts to, but will result in the same bit being flipped in the plaintext of the next block. This allows an attacker to 'sacrifice' one block of plaintext in order to change some data in the next one, possibly managing to maliciously alter the message. This is essentially the core idea of the [[padding oracle attack]] on [[Cipher Block Chaining|CBC]], which allows the attacker to decrypt almost an entire ciphertext without knowing the key. For this and many other reasons, using [[message authentication codes]] is needed to guard against any method of tampering.

== Complete non-malleability ==
Fischlin, in 2005, defined the notion of complete non-malleability as the ability of the system to remain [[Non-Malleable Codes|non-malleable]] while giving the adversary additional power to choose a new public key which could be a function of the original public key.&lt;ref&gt;{{Cite journal|last=Fischlin|first=Marc|date=2005-07-11|title=Completely Non-malleable Schemes|url=https://link.springer.com/chapter/10.1007/11523468_63|journal=Automata, Languages and Programming|series=Lecture Notes in Computer Science|language=en|publisher=Springer, Berlin, Heidelberg|pages=779–790|doi=10.1007/11523468_63|isbn=9783540275800}}&lt;/ref&gt; In other words, the adversary shouldn't be able to come up with a ciphertext whose underlying plaintext is related to the original message through a relation that also takes public keys into account.

==See also==
{{Portal|Cryptography}}
* [[Homomorphic encryption]]

== References ==
{{reflist}}

[[Category:Cryptography]]</text>
      <sha1>dxuxg6uq54cbig96dgsomad8267swdr</sha1>
    </revision>
  </page>
  <page>
    <title>Mary Celine Fasenmyer</title>
    <ns>0</ns>
    <id>7409868</id>
    <revision>
      <id>870337112</id>
      <parentid>866163805</parentid>
      <timestamp>2018-11-24T03:09:35Z</timestamp>
      <contributor>
        <username>Jessicapierce</username>
        <id>2003421</id>
      </contributor>
      <minor/>
      <comment>minor copy edits, fixed reflist</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4344">'''Mary Celine Fasenmyer''' (October 4, 1906, [[Crown, Pennsylvania]] – December 27, 1996, [[Erie, Pennsylvania]]) was an American [[mathematician]]. She is most noted for her work on [[hypergeometric function]]s and [[linear algebra]].&lt;ref name="rosen_2000"&gt;Rosen, KH and Michaels, JG (2000) ''Handbook of Discrete and Combinatorial Mathematics'', [[CRC Press]].&lt;/ref&gt;

==Life==
Fasenmyer grew up in [[Pennsylvania]]'s oil country, and displayed mathematical talent in high school. For ten years after her graduation she taught and studied at [[Mercyhurst College]] in [[Erie, Pennsylvania|Erie]], where she joined the [[Sisters of Mercy]]. The [[religious sister]] pursued her mathematical studies in Pittsburgh and the [[University of Michigan]], obtaining her [[doctorate]] in 1946 under the direction of [[Earl D. Rainville|Earl Rainville]], with a dissertation entitled ''Some Generalized Hypergeometric Polynomials''.&lt;ref name="murray_2001"&gt;Murray, MAM (2001) ''Women Becoming Mathematicians: Creating a Professional Identity in Post-World War II America'', [[MIT Press]].&lt;/ref&gt;

After earning her Ph.D., Fasenmyer published two papers which expanded on her doctorate work. These would be further elaborated by [[Doron Zeilberger]] and [[Herbert Wilf]] into "[[WZ theory]]", which allowed computerized proof of many [[combinatorics|combinatorial identities]]. After this, she returned to Mercyhurst to teach and did not engage in further research.

=="Sister Celine's" method==
Fasenmyer is most remembered for the method that bears her name, first described in her Ph.D. thesis concerning recurrence relations in hypergeometric series.&lt;ref name="rosen_2000"/&gt; The thesis demonstrated a purely algorithmic method to find recurrence relations satisfied by sums of terms of a hypergeometric polynomial, and requires only the series expansions of the polynomial. The beauty of her method is that it lends itself readily to computer automation. The work of Wilf and Zeilberger generalized the algorithm and established its correctness.

The hypergeometric polynomials she studied are called [[Sister Celine's polynomials]].

== References ==
{{reflist}}

==Publications==

*{{Citation | last1=Fasenmyer | first1=Mary Celine | title=Some generalized hypergeometric polynomials | url=http://www.ams.org/journals/bull/1947-53-08/S0002-9904-1947-08893-5/home.html | doi=10.1090/S0002-9904-1947-08893-5  | mr=0022276 | zbl=0032.15402| year=1947 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=53 | issue=8 | pages=806–812|series=(1945 University of Michigan PhD thesis)}}
*{{Citation | last1=Fasenmyer | first1=Mary Celine | title=A note on pure recurrence relations | jstor=2305810 | mr=0030044 | zbl= 0032.41002 | year=1949 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 | volume=56 | issue=1 | pages=14–17}}

==External links==
*{{MacTutor|id=Fasenmyer}}
*{{cite web|url=http://www.uwstout.edu/rs/uwsjsr/sister_celine.pdf |title=Sister Celine's Methods, Theorems, and Demonstrations |deadurl=yes |archiveurl=https://web.archive.org/web/20100601175545/http://www.uwstout.edu/rs/uwsjsr/sister_celine.pdf |archivedate=2010-06-01 |df= }}&amp;nbsp;{{small|(251&amp;nbsp;KB)}}
* {{MathWorld | urlname=SisterCelinesMethod | title=Sister Celine's Method}}
*{{cite book |author=[[Marko Petkovsek]], [[Herbert Wilf]] and [[Doron Zeilberger]] |title=A=B |publisher=AK Peters |year=1996 |isbn=1-56881-063-6 |url=http://www.math.upenn.edu/~wilf/AeqB.html|pages=57–58}}
*[http://www.vimeo.com/5381704 Herbert Wilf and Lily Yen talk to Sister Celine (1993)]
*{{MathGenealogy|id=5171}}
*[http://www.agnesscott.edu/lriddle/women/celine.htm "Sister Mary Celine Fasenmyer", Biographies of Women Mathematicians], [[Agnes Scott College]]

{{authority control}}

{{DEFAULTSORT:Fasenmyer, Mary Celine}}
[[Category:1906 births]]
[[Category:1996 deaths]]
[[Category:20th-century American educators]]
[[Category:20th-century American mathematicians]]
[[Category:American Roman Catholic religious sisters and nuns]]
[[Category:Mathematical analysts]]
[[Category:Mercyhurst University alumni]]
[[Category:People from Erie, Pennsylvania]]
[[Category:Sisters of Mercy]]
[[Category:University of Michigan alumni]]
[[Category:Women mathematicians]]
[[Category:Catholics from Pennsylvania]]</text>
      <sha1>g28lh75rm7tywa1doc3n2ofmdsi4ze9</sha1>
    </revision>
  </page>
  <page>
    <title>Matroid parity problem</title>
    <ns>0</ns>
    <id>56069479</id>
    <revision>
      <id>817719326</id>
      <parentid>816421740</parentid>
      <timestamp>2017-12-30T04:35:20Z</timestamp>
      <contributor>
        <username>Spintendo</username>
        <id>3465809</id>
      </contributor>
      <comment>Fixing style/layout errors [[Wikipedia:WikiProject Fix common mistakes/be be|WikiProject be/be]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19985">[[File:Graphic matroid parity.svg|thumb|upright=1.35|An instance of the matroid parity problem on a [[graphic matroid]]: given a graph with colored edges, having exactly two edges per color, find as large a forest as possible that again has exactly two edges per color.]]
In [[combinatorial optimization]], the '''matroid parity problem''' is a problem of finding the largest independent set of paired elements in a [[matroid]].{{r|cll}} The problem was formulated by {{harvtxt|Lawler|1976}} as a common generalization of [[graph matching]] and [[matroid intersection]].{{r|cll|el}} It is also known as [[polymatroid]] matching, or the '''matchoid problem'''.{{r|ll}}

Matroid parity can be solved in [[polynomial time]] for [[linear matroid]]s. However, it is [[NP-hard]] for certain compactly-represented matroids, and requires more than a polynomial number of steps in the [[matroid oracle]] model.{{r|cll|jk}}

Applications of matroid parity algorithms include finding [[planarization|large planar subgraphs]]{{r|cffk}} and finding [[graph embedding]]s of [[Xuong tree|maximum genus]].{{r|fgm}} These algorithms can also be used to find [[connected dominating set]]s and [[feedback vertex set]]s in graphs of maximum degree three.{{r|ukg}}

==Formulation==
A [[matroid]] can be defined from a [[finite set]] of elements and from a notion of what it means for subsets of elements to be independent, subject to the following constraints:
*Every subset of an independent set should be independent.
*If &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt; are independent sets, with &lt;math&gt;|T|&gt;|S|&lt;/math&gt;, then there exists an element &lt;math&gt;t\in T&lt;/math&gt; such that &lt;math&gt;S\cup\{t\}&lt;/math&gt; is independent.{{r|cll}}

Examples of matroids include the [[linear matroid]]s (in which the elements are vectors in a [[vector space]], with [[linear independence]]), the [[graphic matroid]]s (in which the elements are edges in an [[undirected graph]], independent when they contain no [[Cycle (graph theory)|cycle]]), and the [[partition matroid]]s (in which the elements belong to a family of [[disjoint sets]], and are independent when they contain at most one element in each set). Graphic matroids and partition matroids are special cases of linear matroids.{{r|cll}}

In the matroid parity problem, the input consists of a matroid together with a pairing on its elements, so that each element belongs to one pair. The goal is to find a subset of the pairs, as large as possible, so that the union of the pairs in the chosen subset is independent.{{r|cll|el}} Another seemingly more general variation, in which the allowable pairs form a graph rather than having only one pair per element, is equivalent: an element appearing in more than one pair could be replaced by multiple copies of the element, one per pair.{{r|lsv}}

==Algorithms==
The matroid parity problem for linear matroids can be solved by a [[randomized algorithm]] in time &lt;math&gt;O(nr^{\omega-1})&lt;/math&gt;, where &lt;math&gt;n&lt;/math&gt; is the number of elements of the matroid, &lt;math&gt;r&lt;/math&gt; is its [[Matroid rank|rank]] (the size of the largest independent set), and &lt;math&gt;\omega&lt;/math&gt; is the exponent in the time bounds for [[fast matrix multiplication]].{{r|cll}}
In particular, using a matrix multiplication algorithm of Le Gall,{{r|lg}} it can be solved in time &lt;math&gt;O(nr^{1.3729})&lt;/math&gt;.
Without using fast matrix multiplication, the linear matroid parity problem can be solved in time &lt;math&gt;O(nr^2)&lt;/math&gt;.{{r|cll}}

These algorithms are based on a [[linear algebra]] formulation of the problem by {{harvtxt|Geelen|Iwata|2005}}. Suppose that an input to the problem consists of &lt;math&gt;m&lt;/math&gt; pairs of &lt;math&gt;r&lt;/math&gt;-dimensional vectors (arranged as [[column vector]]s in a [[Matrix (mathematics)|matrix]] &lt;math&gt;M&lt;/math&gt; of size &lt;math&gt;r\times 2m&lt;/math&gt;). Then the number of pairs in the optimal solution is

:&lt;math&gt;\frac{1}{2}\operatorname{rank}\begin{pmatrix}0&amp;M\\M^T&amp;T\end{pmatrix} -m,&lt;/math&gt;

where &lt;math&gt;T&lt;/math&gt; is a [[block diagonal matrix]] whose blocks are &lt;math&gt;2\times 2&lt;/math&gt; submatrices of the form

:&lt;math&gt;\begin{pmatrix}0&amp;t_i\\-t_i&amp;0\end{pmatrix}&lt;/math&gt;

for a sequence of variables &lt;math&gt;t_1,\dots t_m&lt;/math&gt;.{{r|gi}} The [[Schwartz–Zippel lemma]] can be used to test whether this matrix has full rank or not (that is, whether the solution has size &lt;math&gt;r/2&lt;/math&gt; or not), by assigning random values to the variables &lt;math&gt;t_i&lt;/math&gt; and testing whether the resulting matrix has [[determinant]] zero. By applying a [[greedy algorithm]] that removes pairs one at a time by setting their indeterminates to zero as long as the matrix remains of full rank (maintaining the inverse matrix using the [[Sherman–Morrison formula]] to check the rank after each removal), one can find a solution whenever this test shows that it exists. Additional methods extend this algorithm to the case that the optimal solution to the matroid parity problem has fewer than &lt;math&gt;r/2&lt;/math&gt; pairs.{{r|cll}}

For graphic matroids, more efficient algorithms are known, with running time &lt;math&gt;O(mn\log^6 n)&lt;/math&gt; on graphs with &lt;math&gt;m&lt;/math&gt; vertices and &lt;math&gt;n&lt;/math&gt; edges.{{r|gs}}
For [[simple graph]]s, &lt;math&gt;m&lt;/math&gt; is &lt;math&gt;O(n^2)&lt;/math&gt;, but for [[multigraph]]s, it may be larger, so it is also of interest to have algorithms with smaller or no dependence on &lt;math&gt;m&lt;/math&gt; and worse dependence on &lt;math&gt;n&lt;/math&gt;. In these cases, it is also possible to solve the graphic matroid parity problem in randomized expected time &lt;math&gt;O(n^4)&lt;/math&gt;, or in time &lt;math&gt;O(n^3)&lt;/math&gt; when each pair of edges forms a path.{{r|cll}}

Although the matroid parity problem is [[NP-hard]] for arbitrary matroids, it can still be approximated efficiently. Simple [[Local search (optimization)|local search algorithm]]s provide a [[polynomial-time approximation scheme]] for this problem, and find solutions whose size, as a fraction of the optimal solution size, is arbitrarily close to one. The algorithm starts with the [[empty set]] as its solution, and repeatedly attempts to increase the solution size by one by removing at most a constant number &lt;math&gt;C&lt;/math&gt; of pairs from the solution and replacing them by a different set with one more pair. When no more such moves are possible, the resulting solution is returned as the approximation to the optimal solution. To achieve an approximation ratio of &lt;math&gt;1-\epsilon&lt;/math&gt;, it suffices to choose &lt;math&gt;C&lt;/math&gt; to be approximately &lt;math&gt;5^{\lceil 1/2\epsilon\rceil}&lt;/math&gt;.{{r|lsv}}

==Applications==
Many other optimization problems can be formulated as linear matroid parity problems, and solved in polynomial time using this formulation.

{{glossary}}

{{term|Graph matching}}
{{defn|A [[maximum matching]] in a graph is a subset of edges, no two sharing an endpoint, that is as large as possible. It can be formulated as a matroid parity problem in a partition matroid that has an element for each vertex-edge incidence in the graph. In this matroid, two elements are paired if they are the two incidences for the same edge as each other. A subset of elements is independent if it has at most one incidence for each vertex of the graph. The pairs of elements in a solution to the matroid parity problem for this matroid are the incidences between edges in a maximum matching and their endpoints.{{r|el}}}}

{{term|Matroid intersection}}
{{defn|An instance of the matroid intersection problem consists of two matroids on the same set of elements; the goal is to find a subset of the elements that is as large as possible and is independent in both matroids. To formulate matroid intersection as a matroid parity problem, construct a new matroid whose elements are the disjoint union of two copies of the given elements, one for each input matroid. In the new matroid, a subset is independent if its restriction to each of the two copies is independent in each of the two matroids, respectively. Pair the elements of the new matroid so that each element is paired with its copy. The pairs of elements in a solution to the matroid parity problem for this matroid are the two copies of each element in a solution to the matroid intersection problem.{{r|el}}}}

{{term|Large planar subgraphs}}
{{defn|&lt;p&gt;In an arbitrary graph, the problem of finding the largest set of triangles in a given graph, with no cycles other than the chosen triangles, can be formulated as a matroid parity problem on a graphic matroid whose elements are edges of the graph, with one pair of edges per triangle (duplicating edges if necessary when they belong to more than one triangle). The pairs of elements in a solution to the matroid parity problem for this matroid are the two edges in each triangle of an optimal set of triangles.
The same problem can also be described as one of finding the largest [[Hypergraph|Berge-acyclic]] sub-hypergraph of a 3-uniform [[hypergraph]]. In the hypergraph version of the problem, the hyper-edges are the triangles of the given graph.{{r|ll}}&lt;/p&gt;

&lt;p&gt;A [[cactus graph]] is a graph in which each two cycles have at most one vertex in common. As a special case, the graphs in which each cycle is a triangle are necessarily cactus graphs. The largest triangular cactus in the given graph
can then be found by adding additional edges from a [[spanning tree]], without creating any new cycles, so that the resulting subgraph has the same [[connected component (graph theory)|connected components]] as the original graph. Cactus graphs are automatically [[planar graph]]s, and the problem of finding triangular cactus graphs forms the basis for the best known [[approximation algorithm]] to the problem of finding the largest planar subgraph of a given graph, an important step in [[planarization]]. The largest triangular cactus always has at least 4/9 the number of edges of the largest planar subgraph, improving the 1/3 approximation ratio obtained by using an arbitrary spanning tree.{{r|cffk}}&lt;/p&gt;}}

{{term|Combinatorial rigidity}}
{{defn|A framework of rigid bars in the [[Euclidean plane]], connected at their endpoints at flexible joints, can be fixed into a single position in the plane by pinning some of its joints to points of the plane. The minimum number of joints that need to be pinned to fix the framework is called its pinning number. It can be computed from a solution to an associated matroid parity problem.{{r|ll}}}}

{{term|Maximum-genus embeddings}}
{{defn|[[File:Xuong tree.svg|thumb|A [[Xuong tree]]]]
&lt;p&gt;A [[graph embedding|cellular embedding]] of a given graph onto a surface of the maximum possible [[genus (mathematics)|genus]] can be obtained from a [[Xuong tree]] of the graph. This is a spanning tree with the property that, in the subgraph of edges not in the tree, the number of [[Connected component (graph theory)|connected components]] with an odd number of edges is as small as possible.&lt;/p&gt;

&lt;p&gt;To formulate the problem of finding a Xuong tree as a matroid parity problem, first subdivide each edge &lt;math&gt;e&lt;/math&gt; of the given graph into a path, with the length of the path equal to the number of other edges incident to &lt;math&gt;e&lt;/math&gt;. Then, pair the edges of the subdivided graph, so that each pair of edges in the original graph is represented by a single pair of edges in the subdivided graph, and each edge in the subdivided graph is paired exactly once. Solve a matroid parity problem with the paired edges of the subdivided graph, using its cographic matroid (a linear matroid in which a subset of edges is independent if its removal does not separate the graph). Any spanning tree of the original graph that avoids the edges used in the matroid parity solution is necessarily a Xuong tree.{{r|fgm}}&lt;/p&gt;}}

{{term|Connected domination}}
{{defn|A [[connected dominating set]] in a graph is a subset of vertices whose [[induced subgraph]] is connected, adjacent to all other vertices.
It is NP-hard to find the smallest connected dominating set in arbitrary graphs,
but can be found in polynomial time for graphs of maximum degree three.
In a [[cubic graph]], one can replace each vertex by a two-edge path connected to the ends of its three endpoints, and formulate a matroid parity problem on the pairs of edges generated in this way, using the cographic matroid of the expanded graph. The vertices whose paths are not used in the solution form a minimum connected dominating set. In a graph of maximum degree three, some simple additional transformations reduce the problem to one on a cubic graph.{{r|ukg}}}}

{{term|Feedback vertex set}}
{{defn|A [[feedback vertex set]] in a graph is a subset of vertices that touches all cycles. In cubic graphs, there is a linear equation relating the number of vertices, [[cyclomatic number]], number of connected components, size of a minimum connected dominating set, and size of a minimum feedback vertex set.{{r|ds}} It follows that the same matroid parity problem used to find connected dominating sets can also be used to find feedback vertex sets in graphs of maximum degree three.{{r|ukg}}}}

{{glossary end}}

==Hardness==
The [[clique problem]], of finding a &lt;math&gt;k&lt;/math&gt;-vertex [[Clique (graph theory)|complete subgraph]] in a given &lt;math&gt;n&lt;/math&gt;-vertex graph &lt;math&gt;G&lt;/math&gt;, can be transformed into an instance of matroid parity as follows.
Construct a [[paving matroid]] on &lt;math&gt;2n&lt;/math&gt; elements, paired up so that there is one pair of elements per pair of vertices. Define a subset &lt;math&gt;S&lt;/math&gt; of these elements to be independent if it satisfies any one of the following three conditions:
*&lt;math&gt;S&lt;/math&gt; has fewer than &lt;math&gt;2k&lt;/math&gt; elements.
*&lt;math&gt;S&lt;/math&gt; has exactly &lt;math&gt;2k&lt;/math&gt; elements, but is not the union of &lt;math&gt;k&lt;/math&gt; pairs of elements.
*&lt;math&gt;S&lt;/math&gt; is the union of &lt;math&gt;k&lt;/math&gt; pairs of elements that form a clique in &lt;math&gt;G&lt;/math&gt;.
Then there is a solution to the matroid parity problem for this matroid, of size &lt;math&gt;2k&lt;/math&gt;, if and only if &lt;math&gt;G&lt;/math&gt; has a clique of size &lt;math&gt;k&lt;/math&gt;. Since finding cliques of a given size is NP-complete, it follows that determining whether this type of matrix parity problem has a solution of size &lt;math&gt;2k&lt;/math&gt; is also NP-complete.{{r|js}}

This problem transformation does not depend on the structure of the clique problem in any deep way, and would work for any other problem of finding size-&lt;math&gt;k&lt;/math&gt; subsets of a larger set that satisfy a computable test. By applying it to a randomly-permuted graph that contains exactly one clique of size &lt;math&gt;k&lt;/math&gt;, one can show that any deterministic or randomized algorithm for matroid parity that accesses its matroid only by independence tests needs to make an exponential number of tests.{{r|jk}}

==References==
{{reflist|refs=

&lt;ref name=cffk&gt;{{citation
 | last1 = Călinescu | first1 = Gruia
 | last2 = Fernandes | first2 = Cristina G.
 | last3 = Finkler | first3 = Ulrich
 | last4 = Karloff | first4 = Howard
 | doi = 10.1006/jagm.1997.0920
 | issue = 2
 | journal = Journal of Algorithms
 | mr = 1622397
 | pages = 269–302
 | title = A better approximation algorithm for finding planar subgraphs
 | volume = 27
 | year = 1998}}.&lt;/ref&gt;
 
&lt;ref name=cll&gt;{{citation
 | last1 = Cheung | first1 = Ho Yee
 | last2 = Lau | first2 = Lap Chi
 | last3 = Leung | first3 = Kai Man
 | doi = 10.1145/2601066
 | issue = 3
 | journal = [[ACM Transactions on Algorithms]]
 | mr = 3233690
 | pages = 10:1–10:26
 | title = Algebraic algorithms for linear matroid parity problems
 | url = https://cs.uwaterloo.ca/~lapchi/papers/parity.pdf
 | volume = 10
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=ds&gt;{{citation
 | last = Speckenmeyer | first = E.
 | contribution = Bounds on feedback vertex sets of undirected cubic graphs
 | mr = 875903
 | pages = 719–729
 | publisher = North-Holland | location = Amsterdam
 | series = Colloquia Mathematica Societatis János Bolyai
 | title = Algebra, Combinatorics and Logic in Computer Science, Vol. I, II (Győr, 1983)
 | volume = 42
 | year = 1986}}&lt;/ref&gt;

&lt;ref name=el&gt;{{citation
 | last = Lawler | first = Eugene L. | authorlink = Eugene Lawler
 | contribution = Chapter 9: The Matroid Parity Problem
 | contribution-url = https://books.google.com/books?id=MTuoAAAAQBAJ&amp;pg=PA356
 | location = New York
 | mr = 0439106
 | pages = 356–367
 | publisher = Holt, Rinehart and Winston
 | title = Combinatorial Optimization: Networks and Matroids
 | year = 1976}}&lt;/ref&gt;

&lt;ref name=fgm&gt;{{citation
 | last1 = Furst | first1 = Merrick L.
 | last2 = Gross | first2 = Jonathan L.
 | last3 = McGeoch | first3 = Lyle A.
 | doi = 10.1145/44483.44485
 | issue = 3
 | journal = [[Journal of the ACM]]
 | mr = 963159
 | pages = 523–534
 | title = Finding a maximum-genus graph imbedding
 | volume = 35
 | year = 1988}}&lt;/ref&gt;

&lt;ref name=gi&gt;{{citation
 | last1 = Geelen | first1 = James | author1-link = Jim Geelen
 | last2 = Iwata | first2 = Satoru
 | doi = 10.1007/s00493-005-0013-7
 | issue = 2
 | journal = [[Combinatorica]]
 | mr = 2127610
 | pages = 187–215
 | title = Matroid matching via mixed skew-symmetric matrices
 | volume = 25
 | year = 2005}}&lt;/ref&gt;

&lt;ref name=gs&gt;{{citation
 | last1 = Gabow | first1 = Harold N.
 | last2 = Stallmann | first2 = Matthias
 | editor-last = Brauer | editor-first = Wilfried
 | contribution = Efficient algorithms for graphic matroid intersection and parity (extended abstract)
 | doi = 10.1007/BFb0015746
 | location = Berlin
 | mr = 819256
 | pages = 210–220
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = 12th International Colloquium on Automata, Languages, and Programming (ICALP), Nafplion, Greece, July 15–19, 1985
 | volume = 194
 | year = 1985}}&lt;/ref&gt;

&lt;ref name=jk&gt;{{citation
 | last1 = Jensen | first1 = Per M.
 | last2 = Korte | first2 = Bernhard | author2-link = Bernhard Korte
 | doi = 10.1137/0211014
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | mr = 646772
 | pages = 184–190
 | title = Complexity of matroid property algorithms
 | volume = 11
 | year = 1982}}&lt;/ref&gt;

&lt;ref name=js&gt;{{citation
 | last = Soto | first = José A.
 | arxiv = 1102.3491
 | doi = 10.1016/j.dam.2012.10.019
 | issue = part 2
 | journal = [[Discrete Applied Mathematics]]
 | mr = 3159127
 | pages = 406–412
 | title = A simple PTAS for weighted matroid matching on strongly base orderable matroids
 | volume = 164
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=lg&gt;{{citation
 | last = Le Gall | first = François
 | contribution = Powers of tensors and fast matrix multiplication
 | doi = 10.1145/2608628.2608664
 | location = New York
 | mr = 3239939
 | pages = 296–303
 | publisher = ACM
 | title = Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation (ISSAC 2014)
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=ll&gt;{{citation
 | last = Lovász | first = L. | authorlink = László Lovász
 | doi = 10.1016/0095-8956(80)90066-0
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 572475
 | pages = 208–236
 | series = Series B
 | title = Matroid matching and some applications
 | volume = 28
 | year = 1980}}&lt;/ref&gt;

&lt;ref name=lsv&gt;{{citation
 | last1 = Lee | first1 = Jon
 | last2 = Sviridenko | first2 = Maxim
 | last3 = Vondrák | first3 = Jan
 | doi = 10.1137/11083232X
 | issue = 1
 | journal = [[SIAM Journal on Computing]]
 | mr = 3033132
 | pages = 357–379
 | title = Matroid matching: the power of local search
 | volume = 42
 | year = 2013}}&lt;/ref&gt;

&lt;ref name=ukg&gt;{{citation
 | last1 = Ueno | first1 = Shuichi
 | last2 = Kajitani | first2 = Yoji
 | last3 = Gotoh | first3 = Shin'ya
 | department = Proceedings of the First Japan Conference on Graph Theory and Applications (Hakone, 1986)
 | doi = 10.1016/0012-365X(88)90226-9
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 975556
 | pages = 355–360
 | title = On the nonseparating independent set problem and feedback set problem for graphs with no vertex degree exceeding three
 | volume = 72
 | year = 1988}}&lt;/ref&gt;

}}

[[Category:Combinatorial optimization]]
[[Category:Matroid theory|Intersection]]</text>
      <sha1>7b9ktql4qei6ih5k0v21voomq71bx5r</sha1>
    </revision>
  </page>
  <page>
    <title>Micromagnetics</title>
    <ns>0</ns>
    <id>4153112</id>
    <revision>
      <id>866105962</id>
      <parentid>808323990</parentid>
      <timestamp>2018-10-28T08:31:48Z</timestamp>
      <contributor>
        <username>Marchitelli</username>
        <id>11251957</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15122">'''Micromagnetics''' is a field of [[physics]] dealing with the prediction of magnetic behaviors at sub-micrometer length scales. The length scales considered are large enough for the atomic structure of the material to be ignored (the [[Continuum mechanics|continuum approximation]]), yet small enough to resolve magnetic structures such as [[Domain wall (magnetism)|domain walls]] or vortices.

Micromagnetics can deal with static [[Mechanical equilibrium|equilibria]], by minimizing the magnetic energy, and with dynamic behavior, by solving the time-dependent dynamical equation.

==History==
Micromagnetics as a field (''i.e.'', that deals specifically with the behaviour of (ferro)magnetic materials at sub-micrometer length scales) was introduced in 1963 when [[William Fuller Brown, Jr.]] published a paper on antiparallel domain wall structures. Until comparatively recently computational micromagnetics has been prohibitively expensive in terms of computational power, but smaller problems are now solvable on a modern desktop [[personal computer|PC]].

== Static micromagnetics ==
The purpose of static micromagnetics is to solve for the spatial distribution of the magnetization '''M''' at equilibrium. In most cases, as the temperature is much lower than the [[Curie temperature]] of the material considered, the modulus |'''M'''| of the magnetization is assumed to be everywhere equal to the [[saturation magnetization]] ''M''&lt;sub&gt;s&lt;/sub&gt;. The problem then consists in finding the spatial orientation of the magnetization, which is given by the ''magnetization direction vector'' '''m''' = '''M'''/''M''&lt;sub&gt;s&lt;/sub&gt;, also called ''reduced magnetization''.

The static equilibria are found by minimizing the magnetic energy,
:&lt;math&gt;E = E_\text{exch} + E_\text{anis} + E_\text{Z} + E_\text{demag}+E_\text{m-e}&lt;/math&gt;,
subject to the constraint |'''M'''|=''M''&lt;sub&gt;s&lt;/sub&gt; or |'''m'''|=1.

The contributions to this energy are the following:

=== Exchange energy ===
The exchange energy is a phenomenological continuum description of the quantum-mechanical [[exchange interaction]]. It is written as:

:&lt;math&gt;E_\text{exch} = A \int_V \left((\nabla m_x)^2 + (\nabla m_y)^2 + (\nabla m_z)^2\right) \mathrm{d}V&lt;/math&gt;

where ''A'' is the ''exchange constant''; ''m''&lt;sub&gt;x&lt;/sub&gt;, ''m''&lt;sub&gt;y&lt;/sub&gt; and ''m''&lt;sub&gt;z&lt;/sub&gt; are the components of '''m''';
and the integral is performed over the volume of the sample.

The exchange energy tends to favor configurations where the magnetization varies only slowly across the sample. This energy is minimized when the magnetization is perfectly uniform.

=== Anisotropy energy ===
{{Main|Magnetic anisotropy|Anisotropy energy|Magnetocrystalline anisotropy}}

Magnetic anisotropy arises due to a combination of [[crystal structure]] and [[spin-orbit interaction]]. It can be generally written as:

:&lt;math&gt;E_\text{anis} = \int_V F_\text{anis}(\mathbf{m}) \mathrm{d}V&lt;/math&gt;

where ''F''&lt;sub&gt;anis&lt;/sub&gt;, the anisotropy energy density, is a function of the orientation of the magnetization. Minimum-energy directions for ''F''&lt;sub&gt;anis&lt;/sub&gt; are called ''easy axes''.

[[Time-reversal symmetry]] ensures that ''F''&lt;sub&gt;anis&lt;/sub&gt; is an even function of '''m'''. The simplest such function is
:&lt;math&gt;F_\text{anis}(\mathbf{m}) = -K m_z^2&lt;/math&gt;.
where ''K'' is called the ''anisotropy constant''. In this approximation, called ''uniaxial anisotropy'', the easy axis is the ''z'' direction.

The anisotropy energy favors magnetic configurations where the magnetization is everywhere aligned along an easy axis.

=== Zeeman energy ===
{{Main|Zeeman energy}}

The Zeeman energy is the interaction energy between the magnetization and any externally applied field. It's written as:

:&lt;math&gt;E_\text{Z} = -\mu_0 \int_V \mathbf{M}\cdot\mathbf{H}_\text{a} \mathrm{d}V&lt;/math&gt;

where '''H'''&lt;sub&gt;a&lt;/sub&gt; is the applied field and µ&lt;sub&gt;0&lt;/sub&gt; is the [[vacuum permeability]].

The Zeeman energy favors alignment of the magnetization parallel to the applied field.

=== Energy of the demagnetizing field ===
[[File:Micromagnetics by Zureks.svg|thumb|upright|Example of micromagnetic configuration. Compared to a uniform state, the flux closure structure lowers the energy of the demagnetizing field, at the expense of some exchange energy.]]

{{Main|Demagnetizing field}}

The demagnetizing field is the magnetic field created by the magnetic sample upon itself. The associated energy is:

:&lt;math&gt;E_\text{demag} = -\frac{\mu_0}{2} \int_V \mathbf{M}\cdot\mathbf{H}_\text{d} \mathrm{d}V&lt;/math&gt;

where '''H'''&lt;sub&gt;d&lt;/sub&gt; is the [[demagnetizing field]]. This field depends on the magnetic configuration itself, and it can be found by solving:

:&lt;math&gt;\nabla\cdot\mathbf{H}_\text{d} = -\nabla\cdot\mathbf{M}&lt;/math&gt;

:&lt;math&gt;\nabla\times\mathbf{H}_\text{d} = 0&lt;/math&gt;

where −∇·'''M''' is sometimes called ''magnetic charge density''. The solution of these equations (c.f. [[magnetostatics]]) is:

:&lt;math&gt;\mathbf{H}_\text{d} = -\frac{1}{4\pi} \int_V \nabla\cdot\mathbf{M} \frac{\mathbf{r}}{r^3} \mathrm{d}V&lt;/math&gt;

where '''r''' is the vector going from the current integration point to the point where '''H'''&lt;sub&gt;d&lt;/sub&gt; is being calculated.

It is worth noting that the magnetic charge density can be infinite at the edges of the sample, due to '''M''' changing discontinuously from a finite value inside to zero outside of the sample. This is usually dealt with by using suitable [[boundary condition]]s on the edge of the sample.

The energy of the demagnetizing field favors magnetic configurations that minimize magnetic charges. In particular, on the edges of the sample, the magnetization tends to run parallel to the surface. In most cases it is not possible to minimize this energy term at the same time as the others. The static equilibrium then is a compromise that minimizes the total magnetic energy, although it may not minimize individually any particular term.

=== Magnetoelastic Energy  ===
The magnetoelastic energy describes the energy storage due to elastic lattice distortions. It may be neglected if magnetoelastic coupled effects are neglected.
There exists a preferred local distortion of the crystalline solid associated with the magnetization director '''m''', . 
For a simple model, one can assume this strain to be isochoric and fully
isotropic in the lateral direction, yielding the deviatoric ansatz

&lt;math&gt; \mathbf{\varepsilon}_0(\mathbf{m}) = \frac{3}{2} E\, [\mathbf{m}\otimes \mathbf{m} - \frac{1}{3}\mathbf{1}]&lt;/math&gt;

where the material parameter ''E &gt; 0'' is the magnetostrictive
constant. Clearly, ''E'' is the strain induced by the magnetization in
the direction '''m'''. With this ansatz at hand, we consider the elastic
energy density to be a function of the elastic, stress-producing
strains &lt;math&gt; \mathbf{\varepsilon}_e := \mathbf{\varepsilon} -\mathbf{\varepsilon}_0&lt;/math&gt;. A quadratic form for the magnetoelastic energy is

&lt;math&gt; E_\text{m-e} = \frac{1}{2} [\mathbf{\varepsilon} -\mathbf{\varepsilon}_0(\mathbf{m})] : \mathbb{C} :
[\mathbf{\varepsilon} -\mathbf{\varepsilon}_0(\mathbf{m})] &lt;/math&gt;

where &lt;math&gt;\mathbb{C} :=\lambda \mathbf{1}\otimes \mathbf{1} + 2\mu \mathbb{I}&lt;/math&gt;
is the fourth-order elasticity tensor. Here the elastic response is assumed to be isotropic (based on 
the two Lamé constants λ and μ).
Taking into account the constant length of '''m''', we obtain the invariant-based representation

&lt;math&gt;
E_\text{m-e}= 
\frac{\lambda}{2} \mbox{tr}^2[\mathbf{\varepsilon}] 
+ \mu \, \mbox{tr}[\mathbf{\varepsilon}^2] 
- 3\mu E \big\{ \mbox{tr}[\mathbf{\varepsilon}(\mathbf{m}\otimes\mathbf{m})] 
- \frac{1}{3}\mbox{tr}[\mathbf{\varepsilon}] \big\} .
&lt;/math&gt;

This energy term contributes to magnetostriction.

== Dynamic micromagnetics ==
The purpose of dynamic micromagnetics is to predict the time evolution of the magnetic configuration of a sample subject to some non-steady conditions such as the application of a field pulse or an AC field. This is done by solving the [[Landau-Lifshitz-Gilbert equation]], which is a [[partial differential equation]] describing the evolution of the magnetization in term of the local ''effective field'' acting on it.

=== Effective field ===
The '''effective field''' is the local field ''felt'' by the magnetization. It can be described informally as the derivative of the magnetic energy density with respect to the orientation of the magnetization, as in:

:&lt;math&gt;\mathbf{H}_\mathrm{eff} = - \frac{1}{\mu_0 M_s} \frac{\mathrm{d}^2 E}{\mathrm{d}\mathbf{m}\mathrm{d}V}&lt;/math&gt;

where d''E''/d''V'' is the energy density. In [[Calculus of variations|variational]] terms, a change d'''m''' of the magnetization and the associated change d''E'' of the magnetic energy are related by:

:&lt;math&gt;\mathrm{d}E = -\mu_0 M_s \int_V (\mathrm{d}\mathbf{m})\cdot\mathbf{H}_\text{eff}\,\mathrm{d}V&lt;/math&gt;

It should be noted that, since '''m''' is a unit vector, d'''m''' is always perpendicular to '''m'''. Then the above definition leaves unspecified the component of '''H'''&lt;sub&gt;eff&lt;/sub&gt; that is parallel to '''m'''. This is usually not a problem, as this component has no effect on the magnetization dynamics.

From the expression of the different contributions to the magnetic energy, the effective field can be found to be:

:&lt;math&gt;\mathbf{H}_\mathrm{eff} = \frac{2A}{\mu_0 M_s} \nabla^2 \mathbf{m} - \frac{1}{\mu_0 M_s} \frac{\partial
F_\text{anis}}{\partial \mathbf{m}} + \mathbf{H}_\text{a} + \mathbf{H}_\text{d}&lt;/math&gt;

=== Landau-Lifshitz-Gilbert equation ===
[[File:Damped Magnetization Precession.jpg|thumb|upright|The terms of the Landau-Lifshitz-Gilbert equation: precession (red) and damping (blue). The trajectory of the magnetization (dotted spiral) is drawn under the simplifying assumption that the effective field '''H'''&lt;sub&gt;eff&lt;/sub&gt; is constant.]]

{{Main|Landau-Lifshitz-Gilbert equation}}

This is the equation of motion of the magnetization. It describes a [[Larmor precession]] of the magnetization around the effective field, with an additional [[damping]] term arising from the coupling of the magnetic system to the environment. The equation can be written in the so-called ''Gilbert form'' (or implicit form) as:

:&lt;math&gt;\frac{\partial \mathbf m}{\partial t} = - |\gamma| \mathbf{m} \times \mathbf{H}_\mathrm{eff} + \alpha \mathbf{m}\times\frac{\partial \mathbf{m}} {\partial t}&lt;/math&gt;

where γ is the electron gyromagnetic ratio and α the Gilbert damping constant.

It can be shown that this is mathematically equivalent to the following ''Landau-Lifshitz'' (or explicit) form:

:&lt;math&gt;\frac{\partial\mathbf m}{\partial t} = - \frac{|\gamma|}{1+\alpha^2} \mathbf{m} \times \mathbf{H}_\mathrm{eff} - \frac{\alpha|\gamma|}{1+\alpha^2} \mathbf{m}\times(\mathbf{m}\times\mathbf{H}_\text{eff})&lt;/math&gt;

{{Clear}}

==Applications==
The interaction of micromagnetics with mechanics is also of interest in the context of industrial applications that deal with magneto-acoustic resonance such as in hypersound speakers, high frequency magnetostrictive transducers etc. 
FEM simulations taking into account the effect of magnetostriction into micromagnetics are of importance. Such simulations use models described above within a finite element framework.&lt;ref&gt;
{{cite journal
| last         = Miehe
| first        = Christian
| last2        = Ethiraj
| first2       = Gautam
| date         = 2011-10-15
| title        = A geometrically consistent incremental variational formulation for phase field models in micromagnetics
| url          = http://www.sciencedirect.com/science/article/pii/S0045782512000977
| journal      = Computer Methods in Applied Mechanics and Engineering
| publisher    = Elsevier
| volume       = 245–246
| issue        =
| pages        = 331–347
| doi          = 10.1016/j.cma.2012.03.021
| accessdate   =
|bibcode = 2012CMAME.245..331M }}&lt;/ref&gt;

Apart from conventional magnetic domains and domain-walls, the theory also treats the statics and dynamics of topological line and point configurations, e.g. magnetic [[vortex]] and antivortex states;&lt;ref&gt;{{cite arXiv |last=Komineas |first=Stavros|author2=Papanicolaou, Nikos |authorlink= |eprint=0712.3684v1 |title=Dynamics of vortex-antivortex pairs in ferromagnets |class=cond-mat.mtrl-sci |year=2007}}&lt;/ref&gt; or even 3d-Bloch points,&lt;ref&gt;{{cite journal|last=Thiaville|first=André|author2=García, José |author3=Dittrich, Rok |author4=Miltat, Jacques |author5= Schrefl, Thomas |title=Micromagnetic study of Bloch-point-mediated vortex core reversal|journal=Physical Review B|date=March 2003|volume=67|issue=9|doi=10.1103/PhysRevB.67.094410|bibcode = 2003PhRvB..67i4410T |url=https://digital.csic.es/bitstream/10261/25225/1/Thiaville%2c%20A.%20et%20al%20Phys.Rev.B_67_2003.pdf}}&lt;/ref&gt;&lt;ref name="Döring"&gt;{{cite journal|last=Döring|first=W.|title=Point Singularities in Micromagnetism|journal=Journal of Applied Physics|year=1968|volume=39|issue=2|pages=1006|doi=10.1063/1.1656144|bibcode = 1968JAP....39.1006D }}&lt;/ref&gt; where, for example, the magnetization leads radially into all directions from the origin, or into  topologically equivalent configurations. Thus in space, and also in time, nano- (and even pico-)scales are used.

The corresponding topological quantum numbers&lt;ref name="Döring" /&gt; are thought to be used as information carriers, to apply the most recent, and already studied, propositions in [[information technology]].

==See also==
* [[Magnetism]]

==Footnotes and references==
&lt;references /&gt;

==Further reading==
{{Refbegin}}
* {{cite book|first=William Fuller, Jr.|last=Brown|title=Micromagnetics|place=New York|publisher=Wiley|year=1963|isbn=0-88275-665-6}}
* {{cite journal|last=Gilbert|first=Thomas L.|title=A Phenomenological Theory of Damping in Ferromagnetic Materials|journal=IEEE Transactions on Magnetics|volume=40|issue=6|pages=3443–3449|year=2004|issn=0018-9464|doi=10.1109/TMAG.2004.836740|bibcode = 2004ITM....40.3443G }}
* {{cite journal|last=Kruzik Martin|first=Prohl Andreas |title=Recent Developments in the Modeling, Analysis, and Numerics of Ferromagnetism|journal=SIAM Review|volume=48|issue=3|pages=439–483|year=2006|doi=10.1137/S0036144504446187 |bibcode = 2006SIAMR..48..439K }}
*{{cite book|last=Maugin|first=Gérard A.|title=Continuum mechanics of electromagnetic solids|year=1988|publisher=North-Holland|location=Amsterdam|isbn=978-0444703996}} 
*{{cite book|last=Pohl|first=Andreas|title=Computational micromagnetism|year=2001|publisher=Teubner|location=Stuttgart|isbn=9783519003588|edition=1. Aufl.}}
*{{cite journal|last=Tiersten|first=H. F.|title=Coupled Magnetomechanical Equations for Magnetically Saturated Insulators|journal=Journal of Mathematical Physics|year=1964|volume=5|issue=9|pages=1298|doi=10.1063/1.1704239|bibcode = 1964JMP.....5.1298T }} 
{{Refend}}

==External links==
* [http://www.ctcms.nist.gov/mumag/mumag.org.html µMAG -- Micromagnetic Modeling Activity Group].
* [http://math.nist.gov/oommf OOMMF -- Micromagnetic Modeling Tool].
* [https://mumax.github.io MuMax -- GPU-accelerated Micromagnetic Modeling Tool].

[[Category:Dynamical systems]]
[[Category:Magnetic ordering]]
[[Category:Magnetostatics]]</text>
      <sha1>7mc3vfx49jo442nww4a8mma7tuclig9</sha1>
    </revision>
  </page>
  <page>
    <title>Ménage problem</title>
    <ns>0</ns>
    <id>21068755</id>
    <revision>
      <id>865481556</id>
      <parentid>865475265</parentid>
      <timestamp>2018-10-24T06:50:54Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2409:4072:6018:900:D7DD:59CC:F810:D86F|2409:4072:6018:900:D7DD:59CC:F810:D86F]] ([[User talk:2409:4072:6018:900:D7DD:59CC:F810:D86F|talk]]) to last version by Onel5969</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15679">[[File:Wedding Banquet setting.jpeg|thumb|240px|A table with ten place settings. There are 3120 different ways in which five male-female couples can sit at this table such that men and women alternate and nobody sits next to their partner.]]
In [[combinatorics|combinatorial mathematics]], the '''ménage problem''' or '''problème des ménages'''&lt;ref&gt;"Ménage" is the [[French language|French]] word for "household" (referring here to a male-female couple).&lt;/ref&gt; asks for the number of different ways in which it is possible to seat a set of male-female couples at a dining table so that men and women alternate and nobody sits next to his or her partner. This problem was formulated in 1891 by [[Édouard Lucas]] and independently, a few years earlier, by [[Peter Guthrie Tait]] in connection with [[knot theory]].&lt;ref&gt;{{harvtxt|Dutka|1986}}.&lt;/ref&gt; For a number of couples equal to 3, 4, 5, ... the number of seating arrangements is
:12, 96, 3120, 115200, 5836320, 382072320, 31488549120, ... {{OEIS|id=A059375}}.
Mathematicians have developed formulas and [[recurrence equation]]s for computing these numbers and related sequences of numbers. Along with their applications to etiquette and knot theory, these numbers also have a [[graph theory|graph theoretic]] interpretation: they count the numbers of [[Matching (graph theory)|matchings]] and [[Hamiltonian cycle]]s in certain families of graphs.

==Touchard's formula==
Let ''M''&lt;sub&gt;''n''&lt;/sub&gt; denote the number of seating arrangements for ''n'' couples. {{harvtxt|Touchard|1934}} derived the formula
:&lt;math&gt;M_n = 2 \cdot n! \sum_{k=0}^n (-1)^k \frac{2n}{2n-k} {2n-k\choose k} (n-k)!.&lt;/math&gt;
Much subsequent work has gone into alternative proofs for this formula and into generalized versions of the problem that count seating arrangements in which some couples are permitted to sit next to each other. A different formula for ''M''&lt;sub&gt;''n''&lt;/sub&gt; involving [[Chebyshev polynomial]]s was given by {{harvtxt|Wyman|Moser|1958}}.

==Ménage numbers and ladies-first solutions==
Until the work of {{harvtxt|Bogart|Doyle|1986}}, solutions to the ménage problem took the form of first finding all seating arrangements for the women and then counting, for each of these partial seating arrangements, the number of ways of completing it by seating the men away from their partners. However, as Bogart and Doyle showed, Touchard's formula may be derived directly by considering all seating arrangements at once rather than by factoring out the participation of the women.&lt;ref&gt;{{harvtxt|Gleick|1986}}.&lt;/ref&gt;

There are 2×''n''! ways of seating the women: there are two sets of seats that can be arranged for the women, and there are ''n''! ways of seating them at a particular set of seats. For each seating arrangement for the women, there are
:&lt;math&gt;A_n=\sum_{k=0}^n (-1)^k \frac{2n}{2n-k} {2n-k\choose k} (n-k)!&lt;/math&gt;
ways of seating the men; this formula simply omits the 2×''n''! factor from Touchard's formula. The resulting smaller numbers (again, starting from ''n''&amp;nbsp;=&amp;nbsp;3),
:1, 2, 13, 80, 579, 4738, 43387, 439792, ... {{OEIS|id=A000179}}
are called the '''ménage numbers'''. They satisfy the [[recurrence relation]]&lt;ref&gt;{{harvtxt|Muir|1882}}; {{harvtxt|Laisant|1891}}. More complicated recurrences had been described previously by Cayley and {{harvtxt|Muir|1878}}.&lt;/ref&gt;
:&lt;math&gt;A_n = n A_{n-1} + \frac{n}{n-2} A_{n-2} + \frac{4(-1)^{n-1}}{n-2}&lt;/math&gt;
and the simpler four-term recurrence&lt;ref&gt;{{harvtxt|Muir|1882}}; {{harvtxt|Canfield|Wormald|1987}}.&lt;/ref&gt;
:&lt;math&gt;\displaystyle A_n = n A_{n-1} + 2 A_{n-2} - (n-4)A_{n-3} - A_{n-4},&lt;/math&gt;
from which the ménage numbers themselves can easily be calculated.

==Graph-theoretical interpretations==
[[File:Crown graphs.svg|thumb|300px|Crown graphs with six, eight, and ten vertices. The outer cycle of each graph forms a Hamiltonian cycle; the eight and ten-vertex graphs also have other Hamiltonian cycles.]]
Solutions to the ménage problem may be interpreted in [[graph theory|graph-theoretic]] terms, as [[directed graph|directed]] [[Hamiltonian cycle]]s in [[crown graph]]s. A crown graph is formed by removing a [[perfect matching]] from a [[complete bipartite graph]] ''K&lt;sub&gt;n,n&lt;/sub&gt;''; it has 2''n'' vertices of two colors, and each vertex of one color is connected to all but one of the vertices of the other color. In the case of the ménage problem, the vertices of the graph represent men and women, and the edges represent pairs of men and women who are allowed to sit next to each other. This graph is formed by removing the perfect matching formed by the male-female couples from a complete bipartite graph that connects every man to every woman. Any valid seating arrangement can be described by the sequence of people in order around the table, which forms a Hamiltonian cycle in the graph. However, two Hamiltonian cycles are considered to be equivalent if they connect the same vertices in the same cyclic order regardless of the starting vertex, while in the ménage problem the starting position is considered significant: if, as in [[Alice's Adventures in Wonderland|Alice]]'s tea party, all the guests shift their positions by one seat, it is considered a different seating arrangement even though it is described by the same cycle. Therefore, the number of oriented Hamiltonian cycles in a crown graph is smaller by a factor of 2''n'' than the number of seating arrangements,&lt;ref&gt;{{harvtxt|Passmore|2005}}.&lt;/ref&gt; but larger by a factor of (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)! than the ménage numbers. The sequence of numbers of cycles in these graphs (as before, starting at ''n''&amp;nbsp;=&amp;nbsp;3) is
:2, 12, 312, 9600, 416880, 23879520, 1749363840, ... {{OEIS|id=A094047}}.

A second graph-theoretic description of the problem is also possible. Once the women have been seated, the possible seating arrangements for the remaining men can be described as [[perfect matching]]s in a graph formed by removing a single Hamiltonian cycle from a complete bipartite graph; the graph has edges connecting open seats to men, and the removal of the cycle corresponds to forbidding the men to sit in either of the open seats adjacent to their wives. The problem of counting matchings in a bipartite graph, and therefore ''a fortiori'' the problem of computing ménage numbers, can be solved using the [[Permanent (mathematics)|permanent]]s of certain 0-1 [[Matrix (mathematics)|matrices]]. In the case of the ménage problem, the matrices arising from this view of the problem are [[circulant matrix|circulant matrices]].&lt;ref&gt;{{harvtxt|Muir|1878}}; {{harvtxt|Eades|Praeger|Seberry|1983}}; {{harvtxt|Kräuter|1984}}; {{harvtxt|Henderson|1975}}.&lt;/ref&gt;

==Knot theory==
Tait's motivation for studying the ménage problem came from trying to find a complete listing of [[Knot (mathematics)|mathematical knot]]s with a given [[Crossing number (knot theory)|number of crossings]], say ''n''. In [[Dowker notation]] for knot diagrams, an early form of which was used by Tait, the 2''n'' points where a knot crosses itself, in consecutive order along the knot, are labeled with the 2''n'' numbers from 1 to 2''n''. In a reduced diagram, the two labels at a crossing cannot be consecutive, so the set of pairs of labels at each crossing, used in Dowker notation to represent the knot, can be interpreted as a perfect matching in a graph that has a vertex for every number in the range from 1 to 2''n'' and an edge between every pair of numbers that has different parity and are non-consecutive modulo 2''n''. This graph is formed by removing a Hamiltonian cycle (connecting consecutive numbers) from a complete bipartite graph (connecting all pairs of numbers with different parity), and so it has a number of matchings equal to a ménage number. For [[alternating knot]]s, this matching is enough to describe the knot diagram itself; for other knots, an additional positive or negative sign needs to be specified for each crossing pair to determine which of the two strands of the crossing lies above the other strand.

However, the knot listing problem has some additional symmetries not present in the ménage problem: one obtains different Dowker notations for the same knot diagram if one begins the labeling at a different crossing point, and these different notations should all be counted as representing the same diagram. For this reason, two matchings that differ from each other by a [[cyclic permutation]] should be treated as equivalent and counted only once. {{harvtxt|Gilbert|1956}} solved this modified enumeration problem, showing that the number of different matchings is
:1, 2, 5, 20, 87, 616, 4843, 44128, 444621, ... {{OEIS|id=A002484}}.

==See also==
*[[Oberwolfach problem]], a different mathematical problem involving the arrangement of diners at tables

==Notes==
{{reflist|colwidth=30em}}

==References==
{{refbegin|colwidth=30em}}
*{{citation
 | doi = 10.2307/2323022
 | last1 = Bogart | first1 = Kenneth P.
 | last2 = Doyle | first2 = Peter G.
 | issue = 7
 | journal = [[American Mathematical Monthly]]
 | mr = 0856291
 | pages = 514–519
 | title = Non-sexist solution of the ménage problem
 | url = http://www.math.dartmouth.edu/~doyle/docs/menage/menage/menage.html
 | volume = 93
 | year = 1986
 | jstor = 2323022}}.
*{{citation
 | last = Bong | first = Nguyen-Huu
 | doi = 10.1080/0020739980290502
 | issue = 5
 | journal = International Journal of Mathematical Education in Science and Technology
 | mr = 1649926
 | pages = 647–661
 | title = Lucas numbers and the menage problem
 | volume = 29
 | year = 1998}}.
*{{citation
 | last1 = Canfield | first1 = E. Rodney
 | last2 = Wormald | first2 = Nicholas C.
 | doi = 10.1016/0012-365X(87)90002-1
 | issue = 2–3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 0885491
 | pages = 117–129
 | title = Ménage numbers, bijections and P-recursiveness
 | volume = 63
 | year = 1987}}.
*{{citation
 | last = Dörrie | first = Heinrich
 | contribution = Lucas' Problem of the Married Couples
 | isbn = 978-0-486-61348-2
 | pages = 27–33
 | publisher = Dover
 | title = 100 Great Problems of Elementary Mathematics
 | year = 1965}}. Translated by David Antin.
*{{citation
 | doi = 10.1007/BF03025785
 | last = Dutka | first = Jacques
 | journal = [[The Mathematical Intelligencer]]
 | mr = 0846991
 | pages = 18–33
 | title = On the problème des ménages
 | issue = 3
 | volume = 8
 | year = 1986}}.
*{{citation
 | last1 = Eades | first1 = Peter | author1-link = Peter Eades
 | last2 = Praeger | first2 = Cheryl E. | author2-link = Cheryl Praeger
 | last3 = Seberry | first3 = Jennifer R. | author3-link = Jennifer Seberry
 | journal = Utilitas Mathematica
 | mr = 0703136
 | pages = 145–159
 | title = Some remarks on the permanents of circulant (0,1) matrices
 | volume = 23
 | year = 1983}}.
*{{citation
 | last = Gilbert | first = E. N. | authorlink = Edgar Gilbert
 | journal = [[Scripta Mathematica]]
 | mr = 0090568
 | pages = 228–233
 | title = Knots and classes of ménage permutations
 | volume = 22
 | year = 1956}}.
*{{citation
 | last = Gleick | first = James | author-link = James Gleick
 | date = October 28, 1986
 | journal = [[New York Times]]
 | title = Math + Sexism: A Problem
 | url = https://query.nytimes.com/gst/fullpage.html?sec=health&amp;res=9A0DEEDB153BF93BA15753C1A960948260}}.
*{{citation
 | doi = 10.4153/CMB-1975-064-6
 | last = Henderson | first = J. R.
 | issue = 3
 | journal = Canadian Mathematical Bulletin
 | mr = 0399127
 | pages = 353–358
 | title = Permanents of (0,1)-matrices having at most two zeros per line
 | volume = 18
 | year = 1975}}.
*{{citation
 | last = Holst | first = Lars
 | doi = 10.1016/0167-7152(91)90147-J
 | issue = 3
 | journal = Statistics and Probability Letters
 | mr = 1097978
 | pages = 225–231
 | title = On the ‘problème des ménages’ from a probabilistic viewpoint
 | volume = 11
 | year = 1991}}.
*{{citation
 | last = Kaplansky | first = Irving | authorlink = Irving Kaplansky
 | doi = 10.1090/S0002-9904-1943-08035-4
 | journal = [[Bulletin of the American Mathematical Society]]
 | mr = 0009006
 | pages = 784–785
 | title = Solution of the problème des ménages
 | issue = 10
 | volume = 49
 | year = 1943}}.
*{{citation
 | last1 = Kaplansky | first1 = Irving | author1-link = Irving Kaplansky
 | last2 = Riordan | first2 = J. | author2-link = John Riordan (mathematician)
 | journal = [[Scripta Mathematica]]
 | mr = 0019074
 | pages = 113–124
 | title = The problème des ménages
 | volume = 12
 | year = 1946}}.
*{{citation
 | last = Kräuter | first = Arnold Richard
 | journal = [[Séminaire Lotharingien de Combinatoire]]
 | language = German
 | title = Über die Permanente gewisser zirkulanter Matrizen und damit zusammenhängender Toeplitz-Matrizen
 | url = http://www.mat.univie.ac.at/~slc/opapers/s11kraeu.html
 | volume = B11b
 | year = 1984}}.
*{{citation
 | last = Laisant | first = Charles-Ange | author-link = Charles-Ange Laisant
 | journal = Bulletin de la Société Mathématique de France
 | language = French
 | pages = 105–108
 | title = Sur deux problèmes de permutations
 | department = Vie de la société
 | url = http://www.numdam.org/item?id=BSMF_1891__19__93_1
 | volume = 19
 | year = 1891}}.
*{{citation
 | last = Lucas | first = Édouard | author-link = Édouard Lucas
 | location = Paris
 | pages = 491–495
 | publisher = Gauthier-Villars
 | title = Théorie des Nombres
 | year = 1891}}.
*{{citation
 | last = Muir | first = Thomas | author-link = Thomas Muir (mathematician)
 | journal = Proceedings of the Royal Society of Edinburgh
 | pages = 382–391
 | title = On Professor Tait's problem of arrangement
 | volume = 9
 | year = 1878}}. Includes (pp.&amp;nbsp;388–391) an addition by [[Arthur Cayley]].
*{{citation
 | last = Muir | first = Thomas | author-link = Thomas Muir (mathematician)
 | journal = Proceedings of the Royal Society of Edinburgh
 | pages = 187–190
 | title = Additional note on a problem of arrangement
 | volume = 11
 | year = 1882}}.
*{{citation
 | last = Passmore | first = Amanda F.
 | title = An elementary solution to the ménage problem
 | year = 2005
 |citeseerx= 10.1.1.96.8324}}.
*{{citation
 | last = Riordan | first = John | authorlink = John Riordan (mathematician)
 | doi = 10.1215/S0012-7094-52-01904-2
 | journal = Duke Mathematical Journal
 | mr = 0045680
 | pages = 27–30
 | title = The arithmetic of ménage numbers
 | issue = 1
 | volume = 19
 | year = 1952}}.
*{{citation
 | last = Takács | first = Lajos | authorlink = Lajos Takács
 | doi = 10.1016/S0012-365X(81)80024-6
 | issue = 3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 0675360
 | pages = 289–297
 | title = On the "problème des ménages"
 | volume = 36
 | year = 1981}}.
*{{citation
 | last = Touchard | first = J. | authorlink = Jacques Touchard
 | issue = 631–633
 | journal = [[Comptes rendus de l'Académie des sciences|C. R. Acad. Sci. Paris]]
 | title = Sur un problème de permutations
 | volume = 198
 | year = 1934}}.
*{{citation
 | last1 = Wyman | first1 = Max
 | last2 = Moser | first2 = Leo | author2-link = Leo Moser
 | issue = 3
 | journal = Canadian Journal of Mathematics
 | mr = 0095127
 | pages = 468–480
 | title = On the problème des ménages
 | volume = 10
 | year = 1958 | doi=10.4153/cjm-1958-045-6}}.
{{refend}}

==External links==
*{{mathworld|title=Married Couples Problem|urlname=MarriedCouplesProblem}}
*{{mathworld|title=Laisant's Recurrence Formula|urlname=LaisantsRecurrenceFormula}}

{{DEFAULTSORT:Menage problem}}
[[Category:Permutations]]
[[Category:Integer sequences]]
[[Category:Recurrence relations]]
[[Category:Knot theory]]</text>
      <sha1>qlw5ncoujvxa81dvttk8hkb4p9248l4</sha1>
    </revision>
  </page>
  <page>
    <title>Noisy text</title>
    <ns>0</ns>
    <id>17193739</id>
    <revision>
      <id>815546721</id>
      <parentid>813138006</parentid>
      <timestamp>2017-12-15T14:20:02Z</timestamp>
      <contributor>
        <username>JHunterJ</username>
        <id>842922</id>
      </contributor>
      <comment>clean up</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2756">'''Noisy text''' is text with differences between the surface form of a coded representation of the [[plain text|text]] and the intended, correct, or original text.&lt;ref&gt;{{cite journal| title=Special Issue on Noisy Text Analytics|author=Knoblock, C., Lopresti, D., Roy, S., Subramaniam, L. V.|journal=International Journal on Document Analysis and Recognition|year=2007}}&lt;/ref&gt; The [[noise]] may be due to [[typographic error]]s or [[colloquialism]]s always present in [[natural language]] and usually lowers the [[data quality]] in a way that makes the text less accessible to automated processing by computers, including [[natural language processing]]. The noise may also have been introduced through an extraction process (e.g., [[Transcription (linguistics)|transcription]] or [[optical character recognition|OCR]]) from media other than original [[electronic text]]s.&lt;ref&gt;{{cite journal|doi=10.1109/TPAMI.2005.248 |title=Noisy text categorization|year=2005|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence Volume|last=Vinciarelli|first=A.|volume=27|issue=12}}&lt;/ref&gt; 

Language usage over computer mediated discourses, like [[chatroom|chats]], [[email]]s and [[SMS]] texts, significantly differs from the standard form of the language. An urge towards shorter message length facilitating [[typing speed|faster typing]] and the need for [[semantic]] clarity, shape the structure of this text used in such discourses.

Various business analysts estimate that [[unstructured data]] constitutes around 80% of the whole [[Enterprise data management|enterprise data]]. A great proportion of this data comprises chat transcripts, emails and other informal and semi-formal internal and external communications. Usually such text is meant for human consumption, but – given the amount of data – manual processing and evaluation of those resources is not practically feasible anymore. This raises the need for robust [[text mining]] methods.&lt;ref&gt;{{cite conference|author=Subramaniam, L. V., Roy, S., Faruquie, T. A., Negi, S.|title=A survey of types of text noise and techniques to handle noisy text|conference=Third Workshop on Analytics for Noisy Unstructured Text Data (AND)|year=2009}}&lt;/ref&gt;

==Techniques for noise reduction==
{{unreferenced section|date=December 2017}}
The use of [[spell checker]]s and [[grammar checker]]s  can reduce the amount of noise in typed text. Many [[word processor]]s include this in the editing tool. Online, [[Google search]] includes a search term suggestion engine to guide users when they make mistakes with their queries.

==See also==
*[[Data corruption]]
*[[Jargon]]
*[[Leet speak]]
*[[Natural language understanding]]
*[[Noisy channel]]

==References==
{{reflist}}

[[Category:Coding theory]]</text>
      <sha1>36gg1nwdx52xvtl8lj2r1m8050akjg8</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical weather prediction</title>
    <ns>0</ns>
    <id>1505381</id>
    <revision>
      <id>871279925</id>
      <parentid>870224869</parentid>
      <timestamp>2018-11-30T01:00:20Z</timestamp>
      <contributor>
        <username>Bcxfu75k</username>
        <id>15467411</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="67961">{{broader|Atmospheric model}}
{{duplication|dupe=Atmospheric model|date=June 2016|discuss=Talk:Atmospheric model#Duplication}}

[[File:AtmosphericModelSchematic.png|thumb|300px|right|Weather models use systems of [[differential equations]] based on the laws of [[physics]], which are in detail [[Fluid dynamics|fluid motion]], [[Thermodynamics|thermodynamics]], [[Radiative transfer|radiative transfer]], and [[chemistry]], and use a coordinate system which divides the planet into a 3D grid.  [[Winds]], [[heat transfer]], [[solar radiation]], [[relative humidity]],  [[Phase transition|phase changes of water]] and surface [[hydrology]] are calculated within each grid cell, and the interactions with neighboring cells are used to calculate atmospheric properties in the future.|alt=A grid for a numerical weather model is shown. The grid divides the surface of the Earth along meridians and parallels, and simulates the thickness of the atmosphere by stacking grid cells away from the Earth's center. An inset shows the different physical processes analyzed in each grid cell, such as advection, precipitation, solar radiation, and terrestrial radiative cooling.]]

'''Numerical weather prediction''' ('''NWP''') uses  [[mathematical model]]s of the atmosphere and oceans to [[weather forecasting|predict the weather]] based on current weather conditions. Though first attempted in the 1920s, it was not until the advent of [[computer simulation]] in the 1950s that numerical weather predictions produced realistic results.  A number of global and regional forecast models are run in different countries worldwide, using current weather observations relayed from [[radiosonde]]s, [[weather satellites]] and other observing systems as inputs.

Mathematical models based on the same physical principles can be used to generate either short-term weather forecasts or longer-term climate predictions; the latter are widely applied for understanding  and projecting [[climate change]]. The improvements made to regional models have allowed for significant improvements in [[Tropical cyclone track forecasting|tropical cyclone track]] and [[air quality]] forecasts; however, atmospheric models perform poorly at handling processes that occur in a relatively constricted area, such as [[wildfire]]s.

Manipulating the vast datasets and performing the complex calculations necessary to modern numerical weather prediction requires some of the most powerful [[supercomputer]]s in the world.  Even with the increasing power of supercomputers, the [[forecast skill]] of numerical weather models extends to only about six days. Factors affecting the accuracy of numerical predictions include the density and quality of observations used as input to the forecasts, along with deficiencies in the numerical models themselves.  Post-processing techniques such as [[model output statistics]] (MOS) have been developed to improve the handling of errors in numerical predictions.

A more fundamental problem lies in the [[Chaos theory|chaotic]] nature of the [[partial differential equation]]s that govern the atmosphere. It is impossible to solve these equations exactly, and small errors grow with time (doubling about every five days). Present understanding is that this chaotic behavior limits accurate forecasts to about 14 days even with perfectly accurate input data and a flawless model.  In addition, the partial differential equations used in the model need to be supplemented with [[Parametrization (climate)|parameterizations]] for [[solar radiation]], [[moist processes]] (clouds and [[precipitation (meteorology)|precipitation]]), [[heat transfer|heat exchange]], soil, vegetation, surface water, and the effects of terrain.  In an effort to quantify the large amount of inherent uncertainty remaining in numerical predictions, [[ensemble forecasting|ensemble forecasts]] have been used since the 1990s to help gauge the confidence in the forecast, and to obtain useful results farther into the future than otherwise possible. This approach analyzes multiple forecasts created with an individual forecast model or multiple models.

== History ==
{{Main|History of numerical weather prediction}}
[[File:Two women operating ENIAC.gif|thumb|280px|The ENIAC main control panel at the [[Moore School of Electrical Engineering]] operated by [[Jean Bartik|Betty Jennings]] and [[Frances Spence|Frances Bilas]].]]
The [[history of numerical weather prediction]] began in the 1920s through the efforts of [[Lewis Fry Richardson]], who used procedures originally developed by [[Vilhelm Bjerknes]]&lt;ref name="Lynch JCP"/&gt; to produce by hand a six-hour forecast for the state of the atmosphere over two points in central Europe, taking at least six weeks to do so.&lt;ref name="Lynch JCP"&gt;{{cite journal|last=[[Peter Lynch (meteorologist)|Lynch]]|first=Peter|title=The origins of computer weather prediction and climate modeling|journal=[[Journal of Computational Physics]]|date=March 2008|volume=227|issue=7|pages=3431–44|doi=10.1016/j.jcp.2007.02.034|bibcode=2008JCoPh.227.3431L|publisher=[[University of Miami]]|url=http://www.rsmas.miami.edu/personal/miskandarani/Courses/MPO662/Lynch,Peter/OriginsCompWF.JCP227.pdf|accessdate=2010-12-23|deadurl=yes|archiveurl=https://web.archive.org/web/20100708191309/http://www.rsmas.miami.edu/personal/miskandarani/Courses/MPO662/Lynch,Peter/OriginsCompWF.JCP227.pdf|archivedate=2010-07-08|df=}}&lt;/ref&gt;&lt;ref name="Lynch Ch1"&gt;{{cite book|last=Lynch|first=Peter|title=The Emergence of Numerical Weather Prediction|year=2006|publisher=[[Cambridge University Press]]|isbn=978-0-521-85729-1|pages=1–27|chapter=Weather Prediction by Numerical Process}}&lt;/ref&gt;  It was not until the advent of the computer and [[computer simulation]]s that computation time was reduced to less than the forecast period itself. The [[ENIAC]] was used to create the first weather forecasts via computer in 1950, based on a highly simplified approximation to the atmospheric governing equations.&lt;ref name="Charney 1950"/&gt;&lt;ref&gt;{{cite book|title=Storm Watchers|page=208|year=2002|author=Cox, John D.|publisher=John Wiley &amp; Sons, Inc.|isbn=0-471-38108-X}}&lt;/ref&gt; In 1954, [[Carl-Gustav Rossby]]'s group at the [[Swedish Meteorological and Hydrological Institute]] used the same model to produce the first operational forecast (i.e., a routine prediction for practical use).&lt;ref name="Harper BAMS"&gt;{{cite journal|last=Harper|first=Kristine|author2=Uccellini, Louis W. |author3=Kalnay, Eugenia |author4=Carey, Kenneth |author5= Morone, Lauren |title=2007: 50th Anniversary of Operational Numerical Weather Prediction|journal=[[Bulletin of the American Meteorological Society]]|date=May 2007|volume=88|issue=5|pages=639–650|doi=10.1175/BAMS-88-5-639|bibcode=2007BAMS...88..639H}}&lt;/ref&gt; Operational numerical weather prediction in the United States began in 1955 under the Joint Numerical Weather Prediction Unit (JNWPU), a joint project by the [[U.S. Air Force]], [[U.S. Navy|Navy]] and [[U.S. Weather Bureau|Weather Bureau]].&lt;ref&gt;{{cite web|author=American Institute of Physics|date=2008-03-25|url=http://www.aip.org/history/sloan/gcm/ |title=Atmospheric General Circulation Modeling|accessdate=2008-01-13 |archiveurl = https://web.archive.org/web/20080325084036/http://www.aip.org/history/sloan/gcm/ |archivedate = 2008-03-25}}&lt;/ref&gt;  In 1956, [[Norm Phillips|Norman Phillips]] developed a mathematical model which could realistically depict monthly and seasonal patterns in the troposphere; this became the first successful [[climate model]].&lt;ref name="Phillips"&gt;{{cite journal|last=Phillips|first=Norman A.|title=The general circulation of the atmosphere: a numerical experiment|journal=Quarterly Journal of the [[Royal Meteorological Society]]|date=April 1956|volume=82|issue=352|pages=123–154|doi=10.1002/qj.49708235202|bibcode=1956QJRMS..82..123P}}&lt;/ref&gt;&lt;ref name="Cox210"&gt;{{cite book|title=Storm Watchers|page=210|year=2002|author=Cox, John D.|publisher=John Wiley &amp; Sons, Inc.|isbn=0-471-38108-X}}&lt;/ref&gt; Following Phillips' work, several groups began working to create [[general circulation model]]s.&lt;ref name="Lynch Ch10"&gt;{{cite book|last=Lynch|first=Peter|title=The Emergence of Numerical Weather Prediction|year=2006|publisher=[[Cambridge University Press]]|isbn=978-0-521-85729-1|pages=206–208|chapter=The ENIAC Integrations}}&lt;/ref&gt;  The first general circulation climate model that combined both oceanic and atmospheric processes was developed in the late 1960s at the [[NOAA]] [[Geophysical Fluid Dynamics Laboratory]].&lt;ref&gt;{{cite web|url=http://celebrating200years.noaa.gov/breakthroughs/climate_model/welcome.html|title=The First Climate Model|author=[[National Oceanic and Atmospheric Administration]]|date=2008-05-22|accessdate=2011-01-08}}&lt;/ref&gt;

As computers have become more powerful, the size of the initial data sets has increased and [[Atmospheric model#Types|newer atmospheric models]] have been developed to take advantage of the added available computing power. These newer models include more physical processes in the simplifications of the [[Navier–Stokes equations|equations of motion]] in numerical simulations of the atmosphere.&lt;ref name="Harper BAMS"/&gt;  In 1966, [[West Germany]] and the United States began producing operational forecasts based on [[primitive equations|primitive-equation models]], followed by the United Kingdom in 1972 and Australia in 1977.&lt;ref name="Lynch JCP"/&gt;&lt;ref name="Leslie BOM"&gt;{{cite journal|last=Leslie|first=L.M.|author2=Dietachmeyer, G.S. |title=Real-time limited area numerical weather prediction in Australia: a historical perspective|journal=Australian Meteorological Magazine|date=December 1992|volume=41|issue=SP|pages=61–77|url=http://www.bom.gov.au/amoj/docs/1992/leslie2.pdf|accessdate=2011-01-03|publisher=[[Bureau of Meteorology]]}}&lt;/ref&gt;  The development of limited area (regional) models facilitated advances in forecasting the tracks of [[tropical cyclone]]s as well as [[air quality]] in the 1970s and 1980s.&lt;ref name="Shuman W&amp;F"&gt;{{cite journal|last=Shuman|first=Frederick G.|authorlink=Frederick Gale Shuman|title=History of Numerical Weather Prediction at the National Meteorological Center|journal=[[Weather and Forecasting]]|date=September 1989|volume=4|issue=3|pages=286–296|doi=10.1175/1520-0434(1989)004&lt;0286:HONWPA&gt;2.0.CO;2|bibcode=1989WtFor...4..286S}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Air pollution modeling and its application VIII, Volume 8|author=Steyn, D. G.|publisher=Birkhäuser|year=1991|pages=241–242|isbn=978-0-306-43828-8}}&lt;/ref&gt;  By the early 1980s models began to include the interactions of soil and vegetation with the atmosphere, which led to more realistic forecasts.&lt;ref&gt;{{cite journal|url=http://www.geog.ucla.edu/~yxue/pdf/1996jgr.pdf |title=Impact of vegetation properties on U. S. summer weather prediction |page=7419 |author1=Xue, Yongkang |author2=Fennessey, Michael J. |journal=[[Journal of Geophysical Research]] |volume=101 |issue=D3 |date=1996-03-20 |accessdate=2011-01-06 |publisher=[[American Geophysical Union]] |doi=10.1029/95JD02169 |bibcode=1996JGR...101.7419X |deadurl=yes |archiveurl=https://web.archive.org/web/20100710080304/http://www.geog.ucla.edu/~yxue/pdf/1996jgr.pdf |archivedate=2010-07-10 |df= }}&lt;/ref&gt;

The output of forecast models based on [[atmospheric dynamics]] is unable to resolve some details of the weather near the Earth's surface. As such, a statistical relationship between the output of a numerical weather model and the ensuing conditions at the ground was developed in the 1970s and 1980s, known as [[model output statistics]] (MOS).&lt;ref name="MOS"/&gt;&lt;ref&gt;{{cite book|title=Air Weather Service Model Output Statistics Systems|author1=Best, D. L. |author2=Pryor, S. P. |year=1983|pages=1–90|publisher=Air Force Global Weather Central}}&lt;/ref&gt;  Starting in the 1990s, model ensemble forecasts have been used to help define the forecast uncertainty and to extend the window in which numerical weather forecasting is viable farther into the future than otherwise possible.&lt;ref name="Toth"/&gt;&lt;ref name="ECens"/&gt;&lt;ref name="RMS"/&gt;

==Initialization==
[[File:Lockheed WP-3D Orion.jpg|280px|thumb|right|Weather reconnaissance aircraft, such as this [[WP-3D Orion]], provide data that is then used in numerical weather forecasts.|alt=A [[WP-3D Orion]] weather reconnaissance aircraft in flight.]]
The [[atmosphere]] is a [[fluid]]. As such, the idea of numerical weather prediction is to sample the state of the fluid at a given time and use the equations of [[fluid dynamics]] and [[thermodynamics]] to estimate the state of the fluid at some time in the future.  The process of entering observation data into the model to generate [[initial value problem|initial conditions]] is called ''initialization''. On land, terrain maps available at resolutions down to {{convert|1|km|mi|1|sp=us}} globally are used to help model atmospheric circulations within regions of rugged topography, in order to better depict features such as downslope winds, [[Lee wave|mountain wave]]s and related cloudiness that affects incoming solar radiation.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=lMXSpRwKNO8C&amp;pg=PA56&amp;dq=radiation+mountain+parameterization+book#v=onepage&amp;q=radiation%20mountain%20parameterization%20book&amp;f=false|title=Parameterization schemes: keys to understanding numerical weather prediction models|author=Stensrud, David J.|page=56|year=2007|publisher=Cambridge University Press|accessdate=2011-02-15|isbn=978-0-521-86540-1}}&lt;/ref&gt;  The main inputs from country-based weather services are observations from devices (called [[radiosonde]]s) in weather balloons  that measure  various atmospheric parameters and transmits them to a fixed receiver, as well as from [[weather satellite]]s. The [[World Meteorological Organization]] acts to standardize the instrumentation, observing practices and timing of these observations worldwide. Stations either report hourly in [[METAR]] reports,&lt;ref&gt;{{cite web|title=Key to METAR Surface Weather Observations|url=http://www.ncdc.noaa.gov/oa/climate/conversion/swometardecoder.html|publisher=[[National Oceanic and Atmospheric Administration]]|accessdate=2011-02-11|author=[[National Climatic Data Center]]|date=2008-08-20}}&lt;/ref&gt; or every six hours in [[SYNOP]] reports.&lt;ref&gt;{{cite web|title=SYNOP Data Format (FM-12): Surface Synoptic Observations|publisher=[[UNISYS]]|archiveurl=https://web.archive.org/web/20071230100059/http://weather.unisys.com/wxp/Appendices/Formats/SYNOP.html|archivedate=2007-12-30|date=2008-05-25|url=http://weather.unisys.com/wxp/Appendices/Formats/SYNOP.html}}&lt;/ref&gt; These observations are irregularly spaced, so they are processed by [[data assimilation]] and objective analysis methods, which perform quality control and obtain values at locations usable by the model's mathematical algorithms.&lt;ref name="Krishnamurti Annu Rev FM"&gt;{{cite journal|last=Krishnamurti|first=T. N.|title=Numerical Weather Prediction|journal=[[Annual Reviews (publisher)|Annual Review of Fluid Mechanics]]|date=January 1995|volume=27|issue=1|pages=195–225|doi=10.1146/annurev.fl.27.010195.001211|bibcode=1995AnRFM..27..195K}}&lt;/ref&gt;  The data are then used in the model as the starting point for a forecast.&lt;ref&gt;{{cite web|title=The WRF Variational Data Assimilation System (WRF-Var)|publisher=[[University Corporation for Atmospheric Research]]|archiveurl=https://web.archive.org/web/20070814044336/http://www.mmm.ucar.edu/wrf/WG4/wrfvar/wrfvar-tutorial.htm|archivedate=2007-08-14|date=2007-08-14|url=http://www.mmm.ucar.edu/wrf/WG4/wrfvar/wrfvar-tutorial.htm}}&lt;/ref&gt;
 
A variety of methods are used to gather observational data for use in numerical models. Sites launch radiosondes in weather balloons which rise through the [[troposphere]] and well into the [[stratosphere]].&lt;ref&gt;{{cite web|last=Gaffen|first=Dian J.|title=Radiosonde Observations and Their Use in SPARC-Related Investigations|archiveurl=https://web.archive.org/web/20070607142822/http://www.aero.jussieu.fr/~sparc/News12/Radiosondes.html|archivedate=2007-06-07|date=2007-06-07|url=http://www.aero.jussieu.fr/~sparc/News12/Radiosondes.html}}&lt;/ref&gt; Information from weather satellites is used where traditional data sources are not available.  Commerce provides [[pilot report]]s along aircraft routes&lt;ref&gt;{{cite journal|last=Ballish|first=Bradley A.|author2=V. Krishna Kumar |title=Systematic Differences in Aircraft and Radiosonde Temperatures|journal=[[Bulletin of the American Meteorological Society]]|date=November 2008|volume=89|issue=11|pages=1689–1708|doi=10.1175/2008BAMS2332.1|bibcode=2008BAMS...89.1689B|accessdate=2011-02-16|url=http://amdar.noaa.gov/docs/bams_ballish_kumar.pdf}}&lt;/ref&gt; and ship reports along shipping routes.&lt;ref&gt;{{cite web|author=National Data Buoy Center|url=http://www.vos.noaa.gov/vos_scheme.shtml|title=The WMO Voluntary Observing Ships (VOS) Scheme|accessdate=2011-02-15|date=2009-01-28|publisher=[[National Oceanic and Atmospheric Administration]]}}&lt;/ref&gt;  Research projects use [[weather reconnaissance|reconnaissance aircraft]] to fly in and around weather systems of interest, such as [[tropical cyclone]]s.&lt;ref name="Hurricane Hunters"&gt;{{cite web|year=2011|author=403rd Wing|url=http://www.hurricanehunters.com|title=The Hurricane Hunters|publisher=[[Hurricane Hunters|53rd Weather Reconnaissance Squadron]]|accessdate=2006-03-30}}&lt;/ref&gt;&lt;ref name="SunHerald"&gt;{{cite journal|author=Lee, Christopher|title=Drone, Sensors May Open Path Into Eye of Storm|url=https://www.washingtonpost.com/wp-dyn/content/article/2007/10/07/AR2007100700971_pf.html|journal=The Washington Post|accessdate=2008-02-22|date=2007-10-08}}&lt;/ref&gt;  Reconnaissance aircraft are also flown over the open oceans during the cold season into systems which cause significant uncertainty in forecast guidance, or are expected to be of high impact from three to seven days into the future over the downstream continent.&lt;ref&gt;{{cite web|url=http://www.noaanews.noaa.gov/stories2010/20100112_plane.html|title=NOAA Dispatches High-Tech Research Plane to Improve Winter Storm Forecasts|date=2010-11-12|accessdate=2010-12-22|author=[[National Oceanic and Atmospheric Administration]]}}&lt;/ref&gt;  Sea ice began to be initialized in forecast models in 1971.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=lMXSpRwKNO8C&amp;pg=PA137&amp;dq=sea+ice+use+numerical+weather+prediction+book#v=onepage&amp;q=sea%20ice%20use%20numerical%20weather%20prediction%20book&amp;f=false|author=Stensrud, David J.|page=137|title=Parameterization schemes: keys to understanding numerical weather prediction models|publisher=[[Cambridge University Press]]|year=2007|accessdate=2011-01-08|isbn=978-0-521-86540-1}}&lt;/ref&gt;  Efforts to involve [[sea surface temperature]] in model initialization began in 1972 due to its role in modulating weather in higher latitudes of the Pacific.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=SV04AAAAIAAJ&amp;pg=PA38&amp;dq=sea+surface+temperature+importance+use+numerical+weather+prediction+book#v=onepage&amp;q=sea%20surface%20temperature%20importance%20use%20numerical%20weather%20prediction%20book&amp;f=false|pages=49–50|title=The Global Climate|author=Houghton, John Theodore|publisher=Cambridge University Press archive|year=1985|accessdate=2011-01-08|isbn=978-0-521-31256-1}}&lt;/ref&gt;

==Computation==
{{Main|Atmospheric model}}
[[File:GFS 850 MB.PNG|right|280px|thumb|A [[prognostic chart]] of the 96-hour forecast of 850 [[millibar|mbar]] [[geopotential height]] and [[temperature]] from the [[Global Forecast System]]|alt=A prognostic chart of the North American continent provides geopotential heights, temperatures, and wind velocities at regular intervals. The values are taken at the altitude corresponding to the 850-millibar pressure surface.]]

An atmospheric model is a computer program that produces [[meteorological]] information for future times at given locations and altitudes.  Within any modern model is a set of equations, known as the [[primitive equations]], used to predict the future state of the atmosphere.&lt;ref&gt;{{cite book|last=Pielke|first=Roger A.|title=Mesoscale Meteorological Modeling|year=2002|publisher=[[Academic Press]]|isbn=0-12-554766-8|pages=48–49}}&lt;/ref&gt;  These equations—along with the [[ideal gas law]]—are used to evolve the [[density]], [[pressure]], and [[potential temperature]] [[scalar field]]s and the air [[velocity]] (wind) [[vector field]] of the atmosphere through time. Additional transport equations for pollutants and other [[aerosol]]s are included in some primitive-equation high-resolution models as well.&lt;ref&gt;{{cite book|last=Pielke|first=Roger A.|title=Mesoscale Meteorological Modeling|year=2002|publisher=[[Academic Press]]|isbn=0-12-554766-8|pages=18–19}}&lt;/ref&gt; The equations used are [[nonlinear system|nonlinear]] partial differential equations which are impossible to solve exactly through analytical methods,&lt;ref name="finite"&gt;{{cite book|url=https://books.google.com/?id=SH8R_flZBGIC&amp;pg=PA165&amp;lpg=PA165&amp;dq=numerical+weather+prediction+partial+differential+equations+book#v=onepage&amp;q=numerical%20weather%20prediction%20partial%20differential%20equations%20book&amp;f=false|title=Finite difference schemes and partial differential equations|author=Strikwerda, John C.|pages=165–170|year=2004|publisher=SIAM|isbn=978-0-89871-567-5|accessdate=2010-12-31}}&lt;/ref&gt; with the exception of a few idealized cases.&lt;ref&gt;{{cite book|last=Pielke|first=Roger A.|title=Mesoscale Meteorological Modeling|year=2002|publisher=[[Academic Press]]|isbn=0-12-554766-8|page=65}}&lt;/ref&gt; Therefore, numerical methods obtain approximate solutions.  Different models use different solution methods: some global models and almost all regional models use [[finite difference method]]s for all three spatial dimensions, while other global models and a few regional models use [[spectral method]]s for the horizontal dimensions and  finite-difference methods in the vertical.&lt;ref name="finite"/&gt;

These equations are initialized from the analysis data and rates of change are determined.  These rates of change predict the state of the atmosphere a short time into the future; the time increment for this prediction is called a ''time step''.  This future atmospheric state is then used as the starting point for another application of the predictive equations to find new rates of change, and these new rates of change predict the atmosphere at a yet further time step into the future.  This time stepping is repeated until the solution reaches the desired forecast time.  The length of the time step chosen within the model is related to the distance between the points on the computational grid, and is chosen to maintain [[numerical stability]].&lt;ref&gt;{{cite book|last=Pielke|first=Roger A.|title=Mesoscale Meteorological Modeling|year=2002|publisher=[[Academic Press]]|isbn=0-12-554766-8|pages=285–287}}&lt;/ref&gt;  Time steps for global models are on the order of tens of minutes,&lt;ref&gt;{{cite book|url=https://books.google.com/?id=JZikIbXzipwC&amp;pg=PA131&amp;lpg=PA131&amp;dq=time+step+numerical+weather+prediction#v=onepage&amp;q=time%20step%20numerical%20weather%20prediction&amp;f=false|page=132|title=Computational Science – ICCS 2005: 5th International Conference, Atlanta, GA, USA, May 22–25, 2005, Proceedings, Part 1|author1=Sunderam, V. S. |author2=van Albada, G. Dick |author3=Peter, M. A. |author4=Sloot, J. J. Dongarra |year=2005|accessdate=2011-01-02|publisher=Springer|isbn=978-3-540-26032-5}}&lt;/ref&gt; while time steps for regional models are between one and four minutes.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=UV6PnF2z5_wC&amp;pg=PA276&amp;dq=time+step+WRF+weather#v=onepage&amp;q=time%20step%20WRF%20weather&amp;f=false|page=276|title=Developments in teracomputing: proceedings of the ninth ECMWF Workshop on the Use of High Performance Computing in Meteorology|author=Zwieflhofer, Walter; Kreitz, Norbert; European Centre for Medium Range Weather Forecasts|year=2001|accessdate=2011-01-02|publisher=World Scientific|isbn=978-981-02-4761-4}}&lt;/ref&gt;  The global models are run at varying times into the future.  The [[UKMET]] [[Unified Model]] is run six days into the future,&lt;ref name="models"&gt;{{cite book|pages=295–296|url=https://books.google.com/?id=6gFiunmKWWAC&amp;pg=PA297&amp;dq=hours+time+used+to+run+ECMWF+model#v=onepage&amp;q=hours%20time%20used%20to%20run%20ECMWF%20model&amp;f=false|title=Global Perspectives on Tropical Cyclones: From Science to Mitigation|author1=Chan, Johnny C. L.  |author2=Jeffrey D. Kepert |lastauthoramp=yes |year=2010|publisher=World Scientific|isbn=978-981-4293-47-1|accessdate=2011-02-24}}&lt;/ref&gt; while the [[European Centre for Medium-Range Weather Forecasts]]' [[Integrated Forecast System]] and [[Environment Canada]]'s [[Global Environmental Multiscale Model]] both run out to ten days into the future,&lt;ref&gt;{{cite book|url=https://books.google.com/?id=fhW5oDv3EPsC&amp;pg=PA474&amp;dq=time+used+to+run+ECMWF+model#v=onepage&amp;q&amp;f=false|page=480|author=Holton, James R.|title=An introduction to dynamic meteorology, Volume 1|year=2004|publisher=Academic Press|accessdate=2011-02-24|isbn=978-0-12-354015-7}}&lt;/ref&gt; and the [[Global Forecast System]] model run by the [[Environmental Modeling Center]] is run sixteen days into the future.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=mTZvR3R6YdkC&amp;pg=PA121&amp;dq=how+long+does+it+take+to+run+the+GFS+global+weather+model+book#v=onepage&amp;q&amp;f=false|page=121|title=Famine early warning systems and remote sensing data|author=Brown, Molly E.|publisher=Springer|year=2008|accessdate=2011-02-24|isbn=978-3-540-75367-4}}&lt;/ref&gt; The visual output produced by a model solution is known as a [[prognostic chart]], or ''prog''.&lt;ref&gt;{{cite book|author=Ahrens, C. Donald|page=244|isbn=978-0-495-11558-8|year=2008|publisher=Cengage Learning|title=Essentials of meteorology: an invitation to the atmosphere|url=https://books.google.com/?id=2Yn29IFukbgC&amp;pg=PA244&amp;lpg=PA244&amp;dq=regional+weather+forecast+model+characteristics+book#v=onepage&amp;q&amp;f=false|accessdate=2011-02-11}}&lt;/ref&gt;

== Parameterization ==
[[File:GoldenMedows.jpg|thumb|right|Field of [[cumulus cloud]]s, which are parameterized since they are too small to be explicitly included within numerical weather prediction]]
{{Main|Parametrization (climate)}}
Some meteorological processes are too small-scale or too complex to be explicitly included in numerical weather prediction models. ''[[Parameterization]]'' is a procedure for representing these processes by relating them to variables on the scales that the model resolves. For example, the gridboxes in weather and climate models have sides that are between {{convert|5|km|mi|0|sp=us}} and {{convert|300|km|mi|-2|sp=us}} in length.  A typical [[cumulus cloud]] has a scale of less than {{convert|1|km|mi|1|sp=us}}, and would require a grid even finer than this to be represented physically by the equations of fluid motion.  Therefore, the processes that such [[cloud]]s represent are parameterized, by processes of various sophistication.  In the earliest models, if a column of air within a model gridbox was conditionally unstable (essentially, the bottom was warmer and moister than the top) and the water vapor content at any point within the column became saturated then it would be overturned (the warm, moist air would begin rising), and the air in that vertical column mixed.  More sophisticated schemes recognize that only some portions of the box might [[convection|convect]] and that [[Entrainment (meteorology)|entrainment]] and other processes occur.  Weather models that have gridboxes with sizes between {{convert|5|and|25|km|mi|0|sp=us}} can explicitly represent convective clouds, although they need to parameterize [[cloud microphysics]] which occur at a smaller scale.&lt;ref&gt;{{cite journal|url=http://ams.confex.com/ams/pdfpapers/126017.pdf|title=3.7 Improving Precipitation Forecasts by the Operational Nonhydrostatic Mesoscale Model with the Kain-Fritsch Convective Parameterization and Cloud Microphysics|author1=Narita, Masami  |author2=Shiro Ohmori |lastauthoramp=yes |date=2007-08-06|accessdate=2011-02-15|publisher=[[American Meteorological Society]]|journal=12th Conference on Mesoscale Processes}}&lt;/ref&gt;  The formation of large-scale ([[stratus cloud|stratus]]-type) clouds is more physically based; they form when the [[relative humidity]] reaches some prescribed value.  Sub-grid scale processes need to be taken into account.  Rather than assuming that clouds form at 100% relative humidity, the [[cloud fraction]] can be related to a critical value of relative humidity less than 100%,&lt;ref&gt;{{cite web|url=http://www.atmos.washington.edu/~dargan/591/diag_cloud.tech.pdf |pages=4–5 |title=The Diagnostic Cloud Parameterization Scheme |author=Frierson, Dargan |publisher=[[University of Washington]] |date=2000-09-14 |accessdate=2011-02-15 |deadurl=yes |archiveurl=https://web.archive.org/web/20110401013742/http://www.atmos.washington.edu/~dargan/591/diag_cloud.tech.pdf |archivedate=2011-04-01 |df= }}&lt;/ref&gt; reflecting the sub grid scale variation that occurs in the real world.

The amount of solar radiation reaching the ground, as well as the formation of cloud droplets occur on the molecular scale, and so they must be parameterized before they can be included in the model.  [[Drag (physics)|Atmospheric drag]] produced by mountains must also be parameterized, as the limitations in the resolution of [[elevation]] contours produce significant underestimates of the drag.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=lMXSpRwKNO8C&amp;pg=PA56&amp;dq=radiation+mountain+parameterization+book#v=onepage&amp;q=radiation%20mountain%20parameterization%20book&amp;f=false|title=Parameterization schemes: keys to understanding numerical weather prediction models|author=Stensrud, David J.|page=6|year=2007|publisher=Cambridge University Press|accessdate=2011-02-15|isbn=978-0-521-86540-1}}&lt;/ref&gt;  This method of parameterization is also done for the surface flux of energy between the ocean and the atmosphere, in order to determine realistic sea surface temperatures and type of sea ice found near the ocean's surface.&lt;ref&gt;{{cite book|page=188|title=A climate modelling primer|author1=McGuffie, K.  |author2=A. Henderson-Sellers |lastauthoramp=yes |publisher=John Wiley and Sons|year=2005|isbn=978-0-470-85751-9}}&lt;/ref&gt;  Sun angle as well as the impact of multiple cloud layers is taken into account.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=vdg5BgBmMkQC&amp;pg=PA226&amp;lpg=PA226&amp;dq=radiation+parameterization+book#v=onepage&amp;q=radiation%20parameterization%20book&amp;f=false|author1=Melʹnikova, Irina N.  |author2=Alexander V. Vasilyev |lastauthoramp=yes |pages=226–228|title=Short-wave solar radiation in the earth's atmosphere: calculation, oberservation, interpretation|year=2005|publisher=Springer|isbn=978-3-540-21452-6}}&lt;/ref&gt;  Soil type, vegetation type, and soil moisture all determine how much radiation goes into warming and how much moisture is drawn up into the adjacent atmosphere, and thus it is important to parameterize their contribution to these processes.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=lMXSpRwKNO8C&amp;pg=PA56&amp;dq=radiation+mountain+parameterization+book#v=onepage&amp;q=radiation%20mountain%20parameterization%20book&amp;f=false|title=Parameterization schemes: keys to understanding numerical weather prediction models|author=Stensrud, David J.|pages=12–14|year=2007|publisher=Cambridge University Press|accessdate=2011-02-15|isbn=978-0-521-86540-1}}&lt;/ref&gt;  Within air quality models, parameterizations take into account atmospheric emissions from multiple relatively tiny sources (e.g. roads, fields, factories) within specific grid boxes.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=wh-Xf0WZQlMC&amp;pg=PA11&amp;lpg=PA11&amp;dq=model+parameterization+air+quality+book#v=onepage&amp;q=model%20parameterization%20air%20quality%20book&amp;f=false|pages=11–12|title=Meteorological and Air Quality Models for Urban Areas|author=Baklanov, Alexander, Sue Grimmond, Alexander Mahura|accessdate=2011-02-24|year=2009|publisher=Springer|isbn=978-3-642-00297-7}}&lt;/ref&gt;

==Domains==
[[File:Sigma-z-coordinates.svg|thumb|280px|A cross-section of the atmosphere over terrain with a sigma-coordinate representation shown. Mesoscale models divide the atmosphere vertically using representations similar to the one shown here.|alt=A sigma coordinate system is shown. The lines of equal sigma values follow the terrain at the bottom, and gradually smoothen towards the top of the atmosphere.]]
The horizontal [[Domain of a function|domain of a model]] is either ''global'', covering the entire Earth, or ''regional'', covering only part of the Earth. Regional models (also known as ''limited-area'' models, or LAMs) allow for the use of finer grid spacing than global models because the available computational resources are focused on a specific area instead of being spread over the globe. This allows regional models to resolve explicitly smaller-scale meteorological phenomena that cannot be represented on the coarser grid of a global model.  Regional models use a global model to specify conditions at the edge of their domain ([[boundary condition]]s) in order to allow systems from outside the regional model domain to move into its area.  Uncertainty and errors within regional models are introduced by the global model used for the boundary conditions of the edge of the regional model, as well as errors attributable to the regional model itself.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=6RQ3dnjE8lgC&amp;pg=PA261&amp;dq=use+of+ensemble+forecasts+book#v=onepage&amp;q=use%20of%20ensemble%20forecasts%20book&amp;f=false|title=Numerical Weather and Climate Prediction|author=Warner, Thomas Tomkins |publisher=[[Cambridge University Press]]|year=2010|isbn=978-0-521-51389-0|page=259|accessdate=2011-02-11}}&lt;/ref&gt;

==Coordinate systems==

===Horizontal coordinates===
Horizontal position may be expressed directly in [[geographic coordinates]] ([[latitude]] and [[longitude]]) for global models or in a [[map projection]] [[planar coordinates]] for regional models. The german weather service is using for its global [https://www.dwd.de/EN/research/weatherforecasting/num_modelling/01_num_weather_prediction_modells/icon_description.html ICON model] (icosahedral non-hydrostatic global circulation model) a grid based on an [[Icosahedron|regular Icosahedron]]. Basic cells in this grid are triangles instead of the four corner cells in a traditional latitude-longitude grid.
The advantage is that, different from a latitude-longitude cells are everywhere on the globe the same size. Disadvantage is that equations in this non rectangular grid are more complicated.

===Vertical coordinates===
The vertical coordinate is handled in various ways. Lewis Fry Richardson's 1922 model used geometric height (&lt;math&gt;z&lt;/math&gt;) as the vertical coordinate. Later models substituted the geometric &lt;math&gt;z&lt;/math&gt; coordinate with a pressure coordinate system, in which the [[geopotential height]]s of constant-pressure surfaces become [[dependent variable]]s, greatly simplifying the primitive equations.&lt;ref name="Lynch Ch2"&gt;{{cite book|last=Lynch|first=Peter|title=The Emergence of Numerical Weather Prediction|year=2006|publisher=[[Cambridge University Press]]|isbn=978-0-521-85729-1|pages=45–46|chapter=The Fundamental Equations}}&lt;/ref&gt;  This correlation between coordinate systems can be made since pressure decreases with height through the [[Earth's atmosphere]].&lt;ref&gt;{{cite book|author=Ahrens, C. Donald|page=10|isbn=978-0-495-11558-8|year=2008|publisher=Cengage Learning|title=Essentials of meteorology: an invitation to the atmosphere|url=https://books.google.com/?id=2Yn29IFukbgC&amp;pg=PA244&amp;lpg=PA244&amp;dq=regional+weather+forecast+model+characteristics+book#v=onepage&amp;q&amp;f=false|accessdate=2011-02-11}}&lt;/ref&gt; The first model used for operational forecasts, the single-layer barotropic model, used a single pressure coordinate at the 500-millibar (about {{convert|5500|m|ft|abbr=on}}) level,&lt;ref name="Charney 1950"&gt;{{cite journal|last1=Charney|first1=Jule|last2=Fjørtoft|first2=Ragnar|last3=von Neumann|first3=John|title=Numerical Integration of the Barotropic Vorticity Equation|journal=Tellus|date=November 1950|volume=2|issue=4|bibcode=1950Tell....2..237C |doi=10.1111/j.2153-3490.1950.tb00336.x|authorlink1=Jule Charney|authorlink2=Ragnar Fjørtoft|authorlink3=John von Neumann|pages=237}}&lt;/ref&gt; and thus was essentially two-dimensional. High-resolution models—also called ''mesoscale models''—such as the [[Weather Research and Forecasting model]] tend to use normalized pressure coordinates referred to as [[sigma coordinates]].&lt;ref&gt;{{cite web|last=Janjic |first=Zavisa |title=Scientific Documentation for the NMM Solver |url=http://nldr.library.ucar.edu/collections/technotes/asset-000-000-000-845.pdf |publisher=[[National Center for Atmospheric Research]] |accessdate=2011-01-03 |author2=Gall, Robert |author3=Pyle, Matthew E. |pages=12–13 |date=February 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20110823082059/http://nldr.library.ucar.edu/collections/technotes/asset-000-000-000-845.pdf |archivedate=2011-08-23 |df= }}&lt;/ref&gt;  This coordinate system receives its name from the [[independent variable]] &lt;math&gt;\sigma&lt;/math&gt; used to [[nondimensionalization|scale]] atmospheric pressures with respect to the pressure at the surface, and in some cases also with the pressure at the top of the domain.&lt;ref&gt;{{cite book|last=Pielke|first=Roger A.|title=Mesoscale Meteorological Modeling|year=2002|publisher=[[Academic Press]]|isbn=0-12-554766-8|pages=131–132}}&lt;/ref&gt;

==Model output statistics==
{{Main|Model output statistics}}
Because forecast models based upon the equations for atmospheric dynamics do not perfectly determine weather conditions, statistical methods have been developed to attempt to correct the forecasts.  Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations.  These statistical models are collectively referred to as [[model output statistics]] (MOS),&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=blEMoIKX_0IC&amp;pg=PA188#v=onepage&amp;q&amp;f=false|page=189|title=When nature strikes: weather disasters and the law|author=Baum, Marsha L.|publisher=Greenwood Publishing Group|year=2007|isbn=978-0-275-22129-4|accessdate=2011-02-11}}&lt;/ref&gt; and were developed by the [[National Weather Service]] for their suite of weather forecasting models in the late 1960s.&lt;ref name="MOS"&gt;{{cite book|title=Model output statistics forecast guidance|first=Harry | last=Hughes|publisher=United States Air Force Environmental Technical Applications Center|year=1976|pages=1–16}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Glahn|first=Harry R.|author2=Lowry, Dale A. |title=The Use of Model Output Statistics (MOS) in Objective Weather Forecasting|journal=[[Journal of Applied Meteorology]]|date=December 1972|volume=11|issue=8|pages=1203–1211|doi=10.1175/1520-0450(1972)011&lt;1203:TUOMOS&gt;2.0.CO;2|bibcode=1972JApMe..11.1203G}}&lt;/ref&gt;

Model output statistics differ from the ''perfect prog'' technique, which assumes that the output of numerical weather prediction guidance is perfect.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=QwzHZ-wV-BAC&amp;pg=PA1144|page=1144|title=Fog and boundary layer clouds: fog visibility and forecasting|author=Gultepe, Ismail|publisher=Springer|year=2007|isbn=978-3-7643-8418-0|accessdate=2011-02-11}}&lt;/ref&gt;  MOS can correct for local effects that cannot be resolved by the model due to insufficient grid resolution, as well as model biases.  Because MOS is run after its respective global or regional model, its production is known as post-processing.  Forecast parameters within MOS include maximum and minimum temperatures, percentage chance of rain within a several hour period, precipitation amount expected, chance that the precipitation will be frozen in nature, chance for thunderstorms, cloudiness, and surface winds.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=Xs9LiGpNX-AC&amp;pg=PA171|page=172|author1=Barry, Roger Graham |author2=Chorley, Richard J. |title=Atmosphere, weather, and climate|publisher=Psychology Press|year=2003|accessdate=2011-02-11|isbn=978-0-415-27171-4}}&lt;/ref&gt;

==Ensembles==
{{main|Ensemble forecasting}}
[[File:WRF rita spread2.jpg|thumb|280px|''Top'': [[Weather Research and Forecasting model]] (WRF) simulation of [[Hurricane Rita]] (2005) tracks. ''Bottom'': The spread of NHC multi-model ensemble forecast.|alt=Two images are shown. The top image provides three potential tracks that could have been taken by Hurricane Rita. Contours over the coast of Texas correspond to the sea-level air pressure predicted as the storm passed. The bottom image shows an ensemble of track forecasts produced by different weather models for the same hurricane.]]
In 1963, [[Edward Lorenz]] discovered the [[chaos theory|chaotic nature]] of the [[fluid dynamics]] equations involved in weather forecasting.&lt;ref name="Cox"&gt;{{cite book|title=Storm Watchers|pages=222–224|year=2002|author=Cox, John D.|publisher=John Wiley &amp; Sons, Inc.|isbn=0-471-38108-X}}&lt;/ref&gt;  Extremely small errors in temperature, winds, or other initial inputs given to numerical models will amplify and double every five days,&lt;ref name="Cox" /&gt; making it impossible for long-range forecasts—those made more than two weeks in advance—to predict the state of the atmosphere with any degree of [[forecast skill]].  Furthermore, existing observation networks have poor coverage in some regions (for example, over large bodies of water such as the Pacific Ocean), which introduces uncertainty into the true initial state of the atmosphere.  While a set of equations, known as the [[Liouville's theorem (Hamiltonian)|Liouville equations]], exists to determine the initial uncertainty in the model initialization, the equations are too complex to run in real-time, even with the use of supercomputers.&lt;ref name="HPCens"/&gt;  These uncertainties limit forecast model accuracy to about five or six days into the future.&lt;ref name="Klaus"&gt;{{cite web|last=Weickmann|first=Klaus|author2=Jeff Whitaker |author3=Andres Roubicek |author4= Catherine Smith  |date=2001-12-01 | url=http://www.esrl.noaa.gov/psd/spotlight/12012001/ | title = The Use of Ensemble Forecasts to Produce Improved Medium Range (3–15&amp;nbsp;days) Weather Forecasts. | publisher=[[Climate Diagnostics Center]] | accessdate=2007-02-16}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Chakraborty|first=Arindam|title=The Skill of ECMWF Medium-Range Forecasts during the Year of Tropical Convection 2008|journal=Monthly Weather Review|date=October 2010|volume=138|issue=10|pages=3787–3805|doi=10.1175/2010MWR3217.1|bibcode=2010MWRv..138.3787C}}&lt;/ref&gt;

[[Edward Epstein (meteorologist)|Edward Epstein]] recognized in 1969 that the atmosphere could not be completely described with a single forecast run due to inherent uncertainty, and proposed using an [[Ensemble (fluid mechanics)|ensemble]] of [[stochastic process|stochastic]] [[Monte Carlo method|Monte Carlo simulations]] to produce [[arithmetic mean|means]] and [[variance]]s for the state of the atmosphere.&lt;ref&gt;{{cite journal|last=Epstein|first=E.S.|title=Stochastic dynamic prediction|journal=[[Tellus A]]|date=December 1969|volume=21|issue=6|pages=739–759|doi=10.1111/j.2153-3490.1969.tb00483.x|bibcode=1969Tell...21..739E}}&lt;/ref&gt; Although this early example of an ensemble showed skill, in 1974 [[Cecil Leith]] showed that they produced adequate forecasts only when the ensemble [[probability distribution]] was a representative sample of the probability distribution in the atmosphere.&lt;ref&gt;{{cite journal|last=Leith|first=C.E.|title=Theoretical Skill of Monte Carlo Forecasts|journal=[[Monthly Weather Review]]|date=June 1974|volume=102|issue=6|pages=409–418|doi=10.1175/1520-0493(1974)102&lt;0409:TSOMCF&gt;2.0.CO;2|bibcode=1974MWRv..102..409L}}&lt;/ref&gt;

Since the 1990s, ''ensemble forecasts'' have been used operationally (as routine forecasts) to account for the stochastic nature of weather processes &amp;ndash; that is, to resolve their inherent uncertainty.  This method involves analyzing multiple forecasts created with an individual forecast model by using different physical [[parametrization (climate)|parametrizations]] or varying initial conditions.&lt;ref name="HPCens"&gt;{{cite web|url=http://www.wpc.ncep.noaa.gov/ensembletraining|author=Manousos, Peter|publisher=[[Hydrometeorological Prediction Center]]|date=2006-07-19|accessdate=2010-12-31|title=Ensemble Prediction Systems}}&lt;/ref&gt; Starting in 1992 with [[Ensemble forecasting|ensemble forecasts]] prepared by the [[European Centre for Medium-Range Weather Forecasts]] (ECMWF) and the [[National Centers for Environmental Prediction]], model ensemble forecasts have been used to help define the forecast uncertainty and to extend the window in which numerical weather forecasting is viable farther into the future than otherwise possible.&lt;ref name="Toth"/&gt;&lt;ref name="ECens"/&gt;&lt;ref name="RMS"/&gt; The ECMWF model, the Ensemble Prediction System,&lt;ref name="ECens"&gt;{{cite web | url=http://ecmwf.int/products/forecasts/guide/The_Ensemble_Prediction_System_EPS_1.html &lt;!--Added by H3llBot--&gt; | title=The Ensemble Prediction System (EPS) | publisher=[[ECMWF]] | accessdate=2011-01-05 | archiveurl=https://web.archive.org/web/20101030055238/http://ecmwf.int/products/forecasts/guide/The_Ensemble_Prediction_System_EPS_1.html &lt;!--Added by H3llBot--&gt; | archivedate=2010-10-30}}&lt;/ref&gt; uses [[Singular value decomposition|singular vectors]] to simulate the initial [[probability density function|probability density]], while the NCEP ensemble, the Global Ensemble Forecasting System, uses a technique known as [[Bred vector|vector breeding]].&lt;ref name="Toth"&gt;{{cite journal|last=Toth|first=Zoltan|author2=Kalnay, Eugenia |title=Ensemble Forecasting at NCEP and the Breeding Method |journal=[[Monthly Weather Review]]|date=December 1997|volume=125|issue=12|pages=3297–3319|doi=10.1175/1520-0493(1997)125&lt;3297:EFANAT&gt;2.0.CO;2|bibcode=1997MWRv..125.3297T}}&lt;/ref&gt;&lt;ref name="RMS"&gt;{{cite journal|title=The ECMWF Ensemble Prediction System: Methodology and validation|journal=Quarterly Journal of the [[Royal Meteorological Society]]|date=January 1996|volume=122|issue=529|pages=73–119|doi=10.1002/qj.49712252905|bibcode=1996QJRMS.122...73M|author1=Molteni, F. |author2=Buizza, R. |author3=Palmer, T.N. |author4=Petroliagis, T. }}&lt;/ref&gt; The UK [[Met Office]] runs global and regional ensemble forecasts where perturbations to initial conditions are produced using a [[Kalman filter]].&lt;ref name="The Met Office ensemble system- MOGREPS"&gt;{{cite web | url=http://www.metoffice.gov.uk/research/areas/data-assimilation-and-ensembles/ensemble-forecasting/MOGREPS | title=MOGREPS | publisher=[[Met Office]] | accessdate=2012-11-01 | deadurl=yes | archiveurl=https://web.archive.org/web/20121022215636/http://www.metoffice.gov.uk/research/areas/data-assimilation-and-ensembles/ensemble-forecasting/MOGREPS | archivedate=2012-10-22 | df= }}&lt;/ref&gt; There are 24 ensemble members in the Met Office Global and Regional Ensemble Prediction System (MOGREPS).

In a single model-based approach, the ensemble forecast is usually evaluated in terms of an average of the individual forecasts concerning one forecast variable, as well as the degree of agreement between various forecasts within the ensemble system, as represented by their overall spread.  Ensemble spread is diagnosed through tools such as [[spaghetti plot|spaghetti diagrams]], which show the dispersion of one quantity on prognostic charts for specific time steps in the future.  Another tool where ensemble spread is used is a [[meteogram]], which shows the dispersion in the forecast of one quantity for one specific location.  It is common for the ensemble spread to be too small to include the weather that actually occurs, which can lead to forecasters misdiagnosing model uncertainty;&lt;ref name="ensbook"/&gt; this problem becomes particularly severe for forecasts of the weather about ten days in advance.&lt;ref&gt;{{cite journal|last=Palmer |first=T.N. |first2=G.J. |last2=Shutts |first3=R. |last3=Hagedorn |first4=F.J. |last4=Doblas-Reyes |first5=T. |last5=Jung |first6=M. |last6=Leutbecher|title=Representing Model Uncertainty in Weather and Climate Prediction|journal=[[Annual Review of Earth and Planetary Sciences]]|date=May 2005|volume=33|pages=163–193|doi=10.1146/annurev.earth.33.092203.122552|bibcode=2005AREPS..33..163P|url=http://www.annualreviews.org/doi/pdf/10.1146/annurev.earth.33.092203.122552|accessdate=2011-02-09}}&lt;/ref&gt; When ensemble spread is small and the forecast solutions are consistent within multiple model runs, forecasters perceive more confidence in the ensemble mean, and the forecast in general.&lt;ref name="ensbook"&gt;{{cite book|url=https://books.google.com/books?id=6RQ3dnjE8lgC&amp;pg=PA261#v=onepage&amp;q&amp;f=false|title=Numerical Weather and Climate Prediction|author=Warner, Thomas Tomkins |publisher=[[Cambridge University Press]]|year=2010|isbn=978-0-521-51389-0|pages=266–275|accessdate=2011-02-11}}&lt;/ref&gt;  Despite this perception, a ''spread-skill relationship'' is often weak or not found, as spread-error [[Correlation and dependence#Correlation and linearity|correlations]] are normally less than 0.6, and only under special circumstances range between 0.6&amp;ndash;0.7.&lt;ref&gt;{{cite web|url=http://www.atmos.washington.edu/~ens/pdf/WEM_WKSHP_2004.epgrimit.pdf|title=Redefining the Ensemble Spread-Skill Relationship from a Probabilistic Perspective|author1=Grimit, Eric P. |author2=Mass, Clifford F. |publisher=[[University of Washington]]|date=October 2004|accessdate=2010-01-02}}&lt;/ref&gt;  The relationship between ensemble spread and [[forecast skill]] varies substantially depending on such factors as the forecast model and the region for which the forecast is made.

In the same way that many forecasts from a single model can be used to form an ensemble, multiple models may also be combined to produce an ensemble forecast. This approach is called ''multi-model ensemble forecasting'', and it has been shown to improve forecasts when compared to a single model-based approach.&lt;ref&gt;{{cite journal|url=http://www.emc.ncep.noaa.gov/mmb/SREF/2222289_WAF_Feb-2010.official.PDF|title=Fog Prediction From a Multimodel Mesoscale Ensemble Prediction System|author1=Zhou, Binbin |author2=Du, Jun |volume=25|date=February 2010|accessdate=2011-01-02|journal=[[Weather and Forecasting]]|publisher=[[American Meteorological Society]]|page=303|doi=10.1175/2009WAF2222289.1|bibcode=2010WtFor..25..303Z}}&lt;/ref&gt;  Models within a multi-model ensemble can be adjusted for their various biases, which is a process known as ''superensemble forecasting''.  This type of forecast significantly reduces errors in model output.&lt;ref&gt;{{cite journal|url=http://www.nat-hazards-earth-syst-sci.net/10/265/2010/nhess-10-265-2010.pdf|title=Multimodel SuperEnsemble technique for quantitative precipitation forecasts in Piemonte region|author1=Cane, D. |author2=Milelli, M. |date=2010-02-12|accessdate=2011-01-02|journal=Natural Hazards and Earth System Sciences|doi=10.5194/nhess-10-265-2010|bibcode=2010NHESS..10..265C|volume=10|page=265|issue=2}}&lt;/ref&gt;

== Applications ==

===Air quality modeling===
{{see also|Atmospheric dispersion modeling}}
[[Air quality]] forecasting attempts to predict when the concentrations of pollutants will attain levels that are hazardous to public health.  The concentration of pollutants in the atmosphere is determined by their ''transport'', or [[Arithmetic mean|mean]] velocity of movement through the atmosphere, their [[diffusion]], [[chemical transformation]], and ground [[Deposition (aerosol physics)|deposition]].&lt;ref&gt;{{cite book|url=http://www.envirocomp.org/books/chapters/2aap.pdf|page=16|title=Ambient Air Pollution|author1=Daly, Aaron  |author2=Paolo Zannetti |lastauthoramp=yes |publisher=The Arab School for Science and Technology and The EnviroComp Institute|year=2007|accessdate=2011-02-24}}&lt;/ref&gt;  In addition to pollutant source and terrain information, these models require data about the state of the [[fluid flow]] in the atmosphere to determine its transport and diffusion.&lt;ref name="Baklanov"&gt;{{cite journal|last=Baklanov|first=Alexander|author2=Rasmussen, Alix |author3=Fay, Barbara |author4=Berge, Erik |author5= Finardi, Sandro  |title=Potential and Shortcomings of Numerical Weather Prediction Models in Providing Meteorological Data for Urban Air Pollution Forecasting|journal=Water, Air, &amp; Soil Pollution: Focus|date=September 2002|volume=2|issue=5|pages=43–60|doi=10.1023/A:1021394126149}}&lt;/ref&gt;  Meteorological conditions such as [[thermal inversion]]s can prevent surface air from rising, trapping pollutants near the surface,&lt;ref&gt;{{cite book|last=Marshall|first=John|title=Atmosphere, ocean, and climate dynamics: an introductory text|year=2008|publisher=Elsevier Academic Press|location=Amsterdam|isbn=978-0-12-558691-7|pages=44–46|author2=Plumb, R. Alan }}&lt;/ref&gt; which makes accurate forecasts of such events crucial for air quality modeling. Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts.&lt;ref name="Baklanov"/&gt;

===Climate modeling===
{{See also|Global climate model}}
A General Circulation Model (GCM) is a [[mathematical model]] that can be used in computer simulations of the global circulation of a planetary [[atmosphere]] or ocean.  An atmospheric general circulation model (AGCM) is essentially the same as a global numerical weather prediction model, and some (such as the one used in the UK Unified Model) can be configured for both short-term weather forecasts and longer-term climate predictions.  Along with [[sea ice]] and land-surface components, AGCMs and oceanic GCMs (OGCM) are key components of global climate models, and are widely applied for understanding the [[climate]] and projecting [[climate change]].  For aspects of climate change, a range of man-made chemical emission scenarios can be fed into the climate models to see how an enhanced [[greenhouse effect]] would modify the Earth's climate.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=Pzx_Nz1qgd8C&amp;pg=PA40|author=Australian Bureau of Statistics|title=Year book, Australia, Issue 87|page=40|year=2005|accessdate=2011-02-18}}&lt;/ref&gt;  Versions designed for climate applications with time scales of decades to centuries were originally created in 1969 by [[Syukuro Manabe]] and [[Kirk Bryan (oceanographer)|Kirk Bryan]] at the [[Geophysical Fluid Dynamics Laboratory]] in [[Princeton, New Jersey]].&lt;ref&gt;{{cite web |url=http://celebrating200years.noaa.gov/breakthroughs/climate_model/welcome.html |title=The First Climate Model |author=[[National Oceanic and Atmospheric Administration]] 200th Celebration |publisher=[[National Oceanic and Atmospheric Administration]]|date=2008-05-22 |accessdate=2010-04-20 }}&lt;/ref&gt;  When run for multiple decades, computational limitations mean that the models must use a coarse grid that leaves smaller-scale interactions unresolved.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=bV3C5VCC-0EC&amp;pg=PA282|pages=284–289|title=The global climate system: patterns, processes, and teleconnections|author=Bridgman, Howard A., John E. Oliver, Michael H. Glantz|year=2006|publisher=Cambridge University Press|isbn=978-0-521-82642-6|accessdate=2011-02-18}}&lt;/ref&gt;

===Ocean surface modeling===
[[File:NOAA Wavewatch III Sample Forecast.gif|right|thumb|280px|NOAA Wavewatch III 120-hour wind and wave forecast for the North Atlantic|alt=A wind and wave forecast for the North Atlantic Ocean. Two areas of high waves are identified: One west of the southern tip of Greenland, and the other in the North Sea. Calm seas are forecast for the Gulf of Mexico. Wind barbs show the expected wind strengths and directions at regularly spaced intervals over the North Atlantic.]]
{{main|Marine weather forecasting|Ocean dynamics|Wind wave model}}
The transfer of energy between the wind blowing over the surface of an ocean and the ocean's upper layer is an important element in wave dynamics.&lt;ref&gt;{{cite journal|last=Chalikov|first=D. V.|title=The numerical simulation of wind-wave interaction|journal=[[Journal of Fluid Mechanics]]|date=August 1978|volume=87|issue=3|pages=561–82|doi=10.1017/S0022112078001767|bibcode=1978JFM....87..561C}}&lt;/ref&gt;  The [[spectral wave transport equation]] is used to describe the change in wave spectrum over changing topography.  It simulates wave generation, wave movement (propagation within a fluid), [[wave shoaling]], [[refraction]], energy transfer between waves, and wave dissipation.&lt;ref&gt;{{cite book|page=270|url=https://books.google.com/?id=yBtOwfUG6cgC&amp;printsec=frontcover&amp;dq=spectral+wave+transport+equation#v=onepage&amp;q=wave%20spectral%20transport%20equation&amp;f=false|title=Numerical modeling of water waves|author=Lin, Pengzhi|publisher=Psychology Press|year=2008|isbn=978-0-415-41578-1}}&lt;/ref&gt;  Since surface winds are the primary forcing mechanism in the spectral wave transport equation, ocean wave models use information produced by numerical weather prediction models as inputs to determine how much energy is transferred from the atmosphere into the layer at the surface of the ocean. Along with dissipation of energy through [[Wind wave|whitecaps]] and [[resonance]] between waves, surface winds from numerical weather models allow for more accurate predictions of the state of the sea surface.&lt;ref&gt;{{cite journal|last=Bender|first=Leslie C.|title=Modification of the Physics and Numerics in a Third-Generation Ocean Wave Model|journal=[[Journal of Atmospheric and Oceanic Technology]]|date=January 1996|volume=13|issue=3|pages=726 |doi=10.1175/1520-0426(1996)013&lt;0726:MOTPAN&gt;2.0.CO;2|bibcode=1996JAtOT..13..726B}}&lt;/ref&gt;

===Tropical cyclone forecasting===
{{see also|Tropical cyclone forecast model}}
Tropical cyclone forecasting also relies on data provided by numerical weather models. Three main classes of [[Tropical cyclone forecast model|tropical cyclone guidance models]] exist: Statistical models are based on an analysis of storm behavior using climatology, and correlate a storm's position and date to produce a forecast that is not based on the physics of the atmosphere at the time. Dynamical models are numerical models that solve the governing equations of fluid flow in the atmosphere; they are based on the same principles as other limited-area numerical weather prediction models but may include special computational techniques such as refined spatial domains that move along with the cyclone. Models that use elements of both approaches are called statistical-dynamical models.&lt;ref&gt;{{cite web|title=Technical Summary of the National Hurricane Center Track and Intensity Models|url=http://www.nhc.noaa.gov/pdf/model_summary_20090724.pdf|publisher=National Oceanic and Atmospheric Administration|accessdate=2011-02-19|author=[[National Hurricane Center]]|date=July 2009}}&lt;/ref&gt;

In 1978, the first [[tropical cyclone forecast model|hurricane-tracking model]] based on [[Atmospheric dynamics#Dynamic meteorology|atmospheric dynamics]]—the movable fine-mesh (MFM) model—began operating.&lt;ref name="Shuman W&amp;F"/&gt;  Within the field of [[tropical cyclone track forecasting]], despite the ever-improving dynamical model guidance which occurred with increased computational power, it was not until the 1980s when numerical weather prediction showed [[Forecast skill|skill]], and until the 1990s when it consistently outperformed [[statistical model|statistical]] or simple dynamical models.&lt;ref&gt;{{cite web|url=http://www.nhc.noaa.gov/verification/verify6.shtml|publisher=[[National Hurricane Center]]|date=2010-04-20|accessdate=2011-01-02|author=Franklin, James|title=National Hurricane Center Forecast Verification|authorlink=James Franklin (meteorologist)}}&lt;/ref&gt; Predictions of the intensity of a tropical cyclone based on numerical weather prediction continue to be a challenge, since statistical methods continue to show higher skill over dynamical guidance.&lt;ref&gt;{{cite journal|author=Rappaport, Edward N. |author2=Franklin, James L. |author3=Avila, Lixion A. |author4=Baig, Stephen R. |author5=Beven II, John L. |author6=Blake, Eric S. |author7=Burr, Christopher A. |author8=Jiing, Jiann-Gwo |author9=Juckins, Christopher A. |author10=Knabb, Richard D. |author11=Landsea, Christopher W. |author12=Mainelli, Michelle |author13=Mayfield, Max |author14=McAdie, Colin J. |author15=Pasch, Richard J. |author16=Sisko, Christopher |author17=Stewart, Stacy R. |author18=Tribble, Ahsha N.|title=Advances and Challenges at the National Hurricane Center|journal=[[Weather and Forecasting]]|date=April 2009|volume=24|issue=2|pages=395–419|doi=10.1175/2008WAF2222128.1|bibcode=2009WtFor..24..395R}}&lt;/ref&gt;

===Wildfire modeling===
{{See also|Wildfire modeling}}
[[File:Propagation model wildfire (English).svg|thumb|280px|right|A simple wildfire propagation model]]
On a molecular scale, there are two main competing reaction processes involved in the degradation of [[cellulose]], or wood fuels, in [[wildfire]]s.  When there is a low amount of moisture in a cellulose fiber, [[volatilization]] of the fuel occurs; this process will generate intermediate gaseous products that will ultimately be the source of [[combustion]].  When moisture is present—or when enough heat is being carried away from the fiber, [[charring]] occurs. The [[chemical kinetics]] of both reactions indicate that there is a point at which the level of moisture is low enough—and/or heating rates high enough—for combustion processes become self-sufficient. Consequently, changes in wind speed, direction, moisture, temperature, or [[lapse rate]] at different levels of the atmosphere can have a significant impact on the behavior and growth of a wildfire. Since the wildfire acts as a heat source to the atmospheric flow, the wildfire can modify local [[advection]] patterns, introducing a [[Feedback|feedback loop]] between the fire and the atmosphere.&lt;ref name="Sullivan wildfire"&gt;{{cite journal|last=Sullivan|first=Andrew L.|title=Wildland surface fire spread modelling, 1990–2007. 1: Physical and quasi-physical models|journal=International Journal of Wildland Fire|date=June 2009|volume=18|issue=4|page=349|doi=10.1071/WF06143|arxiv=0706.3074}}&lt;/ref&gt;

A simplified two-dimensional model for the spread of wildfires that used [[convection]] to represent the effects of wind and terrain, as well as [[Thermal radiation|radiative heat transfer]] as the dominant method of heat transport led to [[reaction-diffusion system]]s of [[partial differential equation]]s.&lt;ref name="Asensio-2002-WFM"&gt;{{cite journal|author1=Asensio, M. I.   |author2=L. Ferragut |lastauthoramp=yes |title=On a wildland fire model with radiation|journal=International Journal for Numerical Methods in Engineering|volume=54|pages=137–157|year=2002|doi=10.1002/nme.420|bibcode = 2002IJNME..54..137A }}&lt;/ref&gt;&lt;ref name="Mandel-2008-WMD"&gt;{{cite journal|author=Mandel, Jan, Lynn S. Bennethum, Jonathan D. Beezley, Janice L. Coen, Craig C. Douglas, Minjeong Kim, and Anthony Vodacek|title=A wildfire model with data assimilation|journal=Mathematics and Computers in Simulation|volume=79|pages=584–606|year=2008|doi=10.1016/j.matcom.2008.03.015|arxiv=0709.0086|bibcode=2007arXiv0709.0086M|issue=3}}&lt;/ref&gt; More complex models join numerical weather models or [[computational fluid dynamics]] models with a wildfire component which allow the feedback effects between the fire and the atmosphere to be estimated.&lt;ref name="Sullivan wildfire"/&gt;  The additional complexity in the latter class of models translates to a corresponding increase in their computer power requirements. In fact, a full three-dimensional treatment of [[combustion]] via [[direct numerical simulation]] at scales relevant for atmospheric modeling is not currently practical because of the excessive computational cost such a simulation would require.  Numerical weather models have limited forecast skill at spatial resolutions under {{convert|1|km|mi|1|sp=us}}, forcing complex wildfire models to parameterize the fire in order to calculate how the winds will be modified locally by the wildfire, and to use those modified winds to determine the rate at which the fire will spread locally.&lt;ref name="Clark-1996-CAFb"&gt;{{cite journal|author=Clark, T. L., M. A. Jenkins, J. Coen, and David Packham|title=A coupled atmospheric-fire model: Convective Froude number and dynamic fingering|journal=International Journal of Wildland Fire|volume=6|pages=177–190|year=1996|doi=10.1071/WF9960177|issue=4}}&lt;/ref&gt;&lt;ref name="Clark-1996-CAF"&gt;{{cite journal|author=Clark, Terry L., Marry Ann Jenkins, Janice Coen, and David Packham|title=A coupled atmospheric-fire model: Convective feedback on fire line dynamics|journal=Journal of Applied Meteorology|volume=35|pages=875–901|year=1996|doi=10.1175/1520-0450(1996)035&lt;0875:ACAMCF&gt;2.0.CO;2|bibcode=1996JApMe..35..875C|issue=6}}&lt;/ref&gt;&lt;ref name="Rothermel-1972-MMP"&gt;{{cite web|author=Rothermel, Richard C.|title=A mathematical model for predicting fire spread in wildland fires|publisher=[[United States Forest Service]]|date=January 1972|url=http://www.fs.fed.us/rm/pubs_int/int_rp115.pdf|accessdate=2011-02-28}}&lt;/ref&gt;  Although models such as [[Los Alamos National Laboratory|Los Alamos]]' FIRETEC solve for the concentrations of fuel and [[oxygen]], the computational grid cannot be fine enough to resolve the combustion reaction, so approximations must be made for the temperature distribution within each grid cell, as well as for the combustion reaction rates themselves.

== See also ==
* [[Atmospheric physics]]
* [[Atmospheric thermodynamics]]
* [[Tropical cyclone forecast model]]
* [[Atmospheric model#Types|Types of atmospheric models]]

== References ==
{{Reflist|30em}}

==Further reading==
{{Refbegin}}
*{{cite book |last=Beniston |first=Martin |title=From Turbulence to Climate: Numerical Investigations of the Atmosphere with a Hierarchy of Models |location=Berlin |publisher=Springer |year=1998 |isbn=3-540-63495-9 }}
*{{cite book |last=Kalnay |first=Eugenia |title=Atmospheric Modeling, Data Assimilation and Predictability |publisher=Cambridge University Press |year=2003 |isbn=0-521-79629-6 |author-link=Eugenia Kalnay}}
* {{cite book |author1=Roulstone, Ian  |author2=Norbury, John  |lastauthoramp=yes |title=Invisible in the Storm: the role of mathematics in understanding weather |url=https://books.google.com/?id=qnMrFEHMrWwC|year=2013 |publisher=Princeton University Press|isbn=0691152721 }}
*{{cite book |last=Thompson |first=Philip |title=Numerical Weather Analysis and Prediction |location=New York |publisher=The Macmillan Company |year=1961 |isbn= }}
*{{cite book |editor1=U.S. Department of Commerce |editor2=National Oceanic |editor3=Atmospheric Administration |editor4=National Weather Service |title=National Weather Service Handbook No. 1 – Facsimile Products |location=Washington, DC |publisher=Department of Commerce |year=1979 |isbn= }}
{{Refend}}

==External links==
* [https://www.noaa.gov/media-release/noaa-kicks-off-2018-with-massive-supercomputer-upgrade NOAA Supercomputer upgrade]
* [http://www.noaanews.noaa.gov/stories2005/s2387.htm NOAA Supercomputers]
* [http://ready.arl.noaa.gov/READYcmet.php Air Resources Laboratory]
* [http://www.usno.navy.mil/FNMOC/ Fleet Numerical Meteorology and Oceanography Center]
* [http://www.ecmwf.int/ European Centre for Medium-Range Weather Forecasts]
* [http://www.metoffice.gov.uk/research/modelling-systems/unified-model/weather-forecasting UK Met Office]

{{Atmospheric, Oceanographic and Climate Models}}

{{featured article}}

{{Authority control}}

{{DEFAULTSORT:Numerical Weather Prediction}}
[[Category:Climate modeling]]
[[Category:Computational science]]
[[Category:Numerical climate and weather models]]
[[Category:Applied mathematics]]
[[Category:Weather prediction]]
[[Category:Computational fields of study]]</text>
      <sha1>gxsj8hkhubvc3g8kke4v7wr44f1ydgu</sha1>
    </revision>
  </page>
  <page>
    <title>Oscar H. Ibarra</title>
    <ns>0</ns>
    <id>47943370</id>
    <revision>
      <id>859090166</id>
      <parentid>859089769</parentid>
      <timestamp>2018-09-11T17:03:53Z</timestamp>
      <contributor>
        <username>Maxal</username>
        <id>237258</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4883">{{Infobox scientist
|name              = Oscar H Ibarra
|image             = Ibarra_in_20015.JPG
|caption           = Prof. Oscar H. Ibarra in 2015.
|birth_date        = {{b-da|September 29, 1941}}
|work_institutions = [[University of California-Santa Barbara]], [[University of Minnesota]], [[University of California, Berkeley]] 
|alma_mater        = [[University of the Philippines]], [[University of California, Berkeley]]
|doctoral_advisor  = [[Michael A. Harrison]]
|doctoral_students = 
|known_for         = [[automata theory]], [[formal languages]], [[computational complexity theory]], design and analysis of algorithms
|prizes            = Guggenheim Fellow (1984),&lt;br&gt; [[ACM Fellow]] (1995),&lt;br&gt; [[Harry H. Goode Memorial Award]] (2001),&lt;br&gt; [[Blaise Pascal Medal]] (2007)
}}

'''Oscar H. Ibarra''' (born September 29, 1941 in [[Negros Occidental]], [[Philippines]]&lt;ref&gt;{{cite web|url=http://www.cise.ufl.edu/~sahni/papers/faultDetection.pdf |title=Polynomially Complete Fault Detection Problems |author1=Ibarra, Oscar H.  |author2=Sahni, Sartaj K.  |lastauthoramp=yes |publisher=[[Institute of Electrical and Electronics Engineers]] |accessdate=10 November 2015}}&lt;/ref&gt;) is a Filipino-American theoretical [[computer scientist]], prominent for work in [[automata theory]], [[formal languages]], design and analysis of algorithms and [[computational complexity theory]]. He was a Professor of the Department of Computer Science at the [[University of California-Santa Barbara]] until his retirement in 2011. Previously, he was on the faculties of [[UC Berkeley]] (1967-1969) and the [[University of Minnesota]] (1969-1990). As of 2015, Ibarra was Professor Emeritus and Research Professor at UCSB.&lt;ref name="UCSB"&gt;http://www.cs.ucsb.edu/~ibarra/&lt;/ref&gt;&lt;ref name="Philippine Science Letters"&gt;{{cite web|last1=Palis|first1=Michael A.|title=Oscar H. Ibarra: Computer Scientist Par Excellence|url=http://www.philsciletters.org/pdf/20101.pdf|website=Philippine Science Letters|publisher=Philippine Science Letters|accessdate=27 October 2015}}&lt;/ref&gt;

==Life and career==
Ibarra received a BS degree in Electrical Engineering from the [[University of the Philippines]] and MS and PhD degrees, also in Electrical Engineering, from the [[University of California, Berkeley]] in 1965 and 1967, respectively.&lt;ref name="UCSB" /&gt;&lt;ref name="Philippine Science Letters" /&gt;

Ibarra was awarded a [[John Simon Guggenheim Memorial Foundation Fellowship]] in 1984. In 1993, he was elected a Fellow of the [[American Association for the Advancement of Science]]. He is a Fellow of the [[Institute of Electrical and Electronics Engineers]] and the [[Association for Computing Machinery]]. In 2001, he received the IEEE Computer Society's [[Harry H. Goode Memorial Award]]. He was elected member of the [[European Academy of Sciences]] (EAS) in 2003. He was awarded the Blaise Pascal Medal&lt;ref name="BPM"&gt;http://www.eurasc.org/medals/pb_medals_07.asp&lt;/ref&gt; in Computer Science from EAS in 2007, and in 2008 he was elected a Foreign Member of [[Academia Europaea]] in the Informatics Section. In 2008, he was awarded a Distinguished Visiting Fellowship from the UK [[Royal Academy of Engineering]]. In July 2015, during the 40th anniversary celebration of the journal, [[Theoretical Computer Science (journal)|Theoretical Computer Science]], Ibarra was named the most prolific author in its 40-year history. He was listed in the [[Institute for Scientific Information]] (ISI) database of Highly Cited Researchers in Computer Science in 2003 and in the Computer Science Bibliography DBLP.&lt;ref name="UCSB" /&gt;&lt;ref name="Philippine Science Letters" /&gt;&lt;ref&gt;http://www.computer.org/web/awards/goode-oscar-ibarra&lt;/ref&gt;&lt;ref name="DBLP"&gt;http://dblp.uni-trier.de/pers/hd/i/Ibarra:Oscar_H=&lt;/ref&gt;

== References ==
{{Reflist}}

==Selected bibliography==
*Ibarra, O. H., "A Note Concerning Nondeterministic Tape Complexities",  J. ACM 19(4): 608-612 (1972).
*Ibarra, O. H., "On Two-way Multihead Automata",  J. Comput. Syst. Sci. 7(1): 28-36 (1973).
*Ibarra, O. H. and Chul E. Kim, "Fast Approximation Algorithms for the Knapsack and Sum of Subset Problems",  J. ACM 22(4): 463-468 (1975).
*Ibarra, O. H., "Reversal-Bounded Multicounter Machines and Their Decision Problems", J. ACM 25(1): 116-133 (1978).
*Ibarra, O. H., "Some Computational Issues in Membrane Computing",  MFCS 2005: 39-5.

==External links==
* {{MathGenealogy|id=143213}}

{{Authority control}}

{{DEFAULTSORT:Ibarra, Oscar H.}}
[[Category:Articles created via the Article Wizard]]
[[Category:Theoretical computer scientists]]
[[Category:Living people]]
[[Category:University of California, Santa Barbara faculty]]
[[Category:University of the Philippines alumni]]
[[Category:University of California, Berkeley alumni]]
[[Category:1941 births]]
[[Category:Filipino emigrants to the United States]]
[[Category:People from Negros Occidental]]</text>
      <sha1>debj6ye9rwftuzpi0j82awcca36ol4s</sha1>
    </revision>
  </page>
  <page>
    <title>Prescribed scalar curvature problem</title>
    <ns>0</ns>
    <id>15901488</id>
    <revision>
      <id>788826376</id>
      <parentid>474519559</parentid>
      <timestamp>2017-07-03T18:26:02Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>/* top */replaced: well-understood → well understood using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1615">In [[Riemannian geometry]], a branch of [[mathematics]], the '''prescribed scalar curvature problem''' is as follows: given a [[closed manifold|closed]], [[smooth manifold]] ''M'' and a smooth, real-valued function ''&amp;fnof;'' on ''M'', construct a [[Riemannian metric]] on ''M'' whose [[scalar curvature]] equals ''&amp;fnof;''.  Due primarily to the work of [[Jerry Kazdan|J. Kazdan]] and F. Warner in the 1970s, this problem is well understood.

== The solution in higher dimensions ==
If the dimension of ''M'' is three or greater, then any smooth function ''&amp;fnof;'' which takes on a negative value somewhere is the scalar curvature of some Riemannian metric.  The assumption that ''&amp;fnof;'' be negative somewhere is needed in general, since not all manifolds admit metrics which have strictly positive scalar curvature.  (For example, the three-dimensional [[torus]] is such a manifold.)  However, Kazdan and Warner proved that if ''M'' does admit some metric with strictly positive scalar curvature, then any smooth function ''&amp;fnof;'' is the scalar curvature of some Riemannian metric.

== See also ==
* [[Prescribed Ricci curvature problem]]
* [[Yamabe problem]]

==References==
*Aubin, Thierry. ''Some nonlinear problems in Riemannian geometry.''  Springer Monographs in Mathematics, 1998.
*Kazdan, J., and Warner F. ''Scalar curvature and conformal deformation of Riemannian structure.'' Journal of Differential Geometry. '''10''' (1975). 113&amp;ndash;134.

[[Category:Riemannian geometry]]
[[Category:Mathematical problems]]
[[Category:Curvature (mathematics)|Scalar curvature]]


{{differential-geometry-stub}}</text>
      <sha1>fi4v1c5nwm2hk1gcryx55vfdsppsbo8</sha1>
    </revision>
  </page>
  <page>
    <title>Proof of knowledge</title>
    <ns>0</ns>
    <id>6527939</id>
    <revision>
      <id>870693298</id>
      <parentid>870693060</parentid>
      <timestamp>2018-11-26T13:01:54Z</timestamp>
      <contributor>
        <username>Jackzhp</username>
        <id>1093843</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8623">In [[cryptography]], a '''proof of knowledge''' is an [[interactive proof system|interactive proof]] in which the prover succeeds in 'convincing' a verifier that the prover knows something. What it means for a [[abstract machine|machine]] to 'know something' is defined in terms of computation. A machine 'knows something', if this something can be computed, given the machine as an input. As the program of the prover does not necessarily spit out the knowledge itself (as is the case for [[zero-knowledge proofs]]&lt;ref&gt;[[Shafi Goldwasser]], [[Silvio Micali]], and [[Charles Rackoff]]. [http://portal.acm.org/citation.cfm?id=63434 The knowledge complexity of interactive proof-systems]. ''Proceedings of 17th Symposium on the Theory of Computation'', Providence, Rhode Island. 1985. Draft. [http://theory.lcs.mit.edu/~cis/pubs/shafi/1985-stoc.pdf Extended abstract]&lt;/ref&gt;) a machine with a different program, called the knowledge extractor is introduced to capture this idea. We are mostly interested in what can be proven by [[polynomial time]] bounded machines. In this case the set of knowledge elements is limited to a set of witnesses of some [[formal language|language]] in [[NP (complexity)|NP]].

Let &lt;math&gt;x&lt;/math&gt; be a statement of language &lt;math&gt;L&lt;/math&gt; in NP, and &lt;math&gt;W(x)&lt;/math&gt; the set of witnesses for x that should be accepted in the proof. This allows us to define the following relation: &lt;math&gt;R= \{(x,w): x \in L, w \in W(x)\}&lt;/math&gt;.

A proof of knowledge for relation &lt;math&gt;R&lt;/math&gt; with knowledge error &lt;math&gt;\kappa&lt;/math&gt; is a two
party protocol with a prover &lt;math&gt;P&lt;/math&gt; and a verifier &lt;math&gt;V&lt;/math&gt; with the following two properties:

# '''Completeness''': if &lt;math&gt;(x,w) \in R&lt;/math&gt;, the prover P who knows witness &lt;math&gt;w&lt;/math&gt; for &lt;math&gt;x&lt;/math&gt; succeeds in convincing the verifier &lt;math&gt;V&lt;/math&gt; of his knowledge. More formally: &lt;math&gt;\Pr(P(x,w)\leftrightarrow V(x) \rightarrow 1) =1&lt;/math&gt;, i.e. given the interaction between the prover P and the verifier V, the probability that the verifier is convinced is 1.
# '''Validity''': Validity requires that the success probability of a knowledge extractor &lt;math&gt;E&lt;/math&gt; in extracting the witness, given oracle access to a possibly malicious prover &lt;math&gt;\tilde P&lt;/math&gt;, must be at least as high as the success probability of the prover &lt;math&gt;\tilde P&lt;/math&gt; in convincing the verifier. This Property guarantees that no prover that doesn't know the witness can succeed in convincing the verifier.

==Details on the definition==

This is a more rigorous definition of '''Validity''':&lt;ref name="odpk"&gt;[[Mihir Bellare]], Oded Goldreich: [http://www-cse.ucsd.edu/~mihir/papers/pok.ps On Defining Proofs of Knowledge]. [[CRYPTO]] 1992: 390–420&lt;/ref&gt;

Let &lt;math&gt;R&lt;/math&gt; be a witness relation, &lt;math&gt;W(x)&lt;/math&gt; the set of all witnesses for public value &lt;math&gt;x&lt;/math&gt;, and &lt;math&gt;\kappa&lt;/math&gt; the knowledge error.
A proof of knowledge is &lt;math&gt;\kappa&lt;/math&gt;-valid if there exists a polynomial-time machine &lt;math&gt;E&lt;/math&gt;, given oracle access to &lt;math&gt;\tilde P&lt;/math&gt;,  such that for every &lt;math&gt;\tilde P&lt;/math&gt;, it is the case that &lt;math&gt;E^{\tilde P(x)}(x) \in W(x) \cup \{ \bot \}&lt;/math&gt; and &lt;math&gt;\Pr(E^{\tilde P(x)}(x) \in W(x)) \geq \Pr(\tilde P(x)\leftrightarrow V(x) \rightarrow 1) - \kappa(x).&lt;/math&gt;

The result &lt;math&gt;\bot&lt;/math&gt; signifies that the Turing machine &lt;math&gt;E&lt;/math&gt; did not come to a conclusion.

The knowledge error &lt;math&gt;\kappa(x)&lt;/math&gt; denotes the probability that the verifier &lt;math&gt;V&lt;/math&gt; might accept &lt;math&gt;x&lt;/math&gt;, even though the prover does in fact not know a witness &lt;math&gt;w&lt;/math&gt;. The knowledge extractor &lt;math&gt;E&lt;/math&gt; is used to express what is meant by the knowledge of a [[Turing machine]]. If &lt;math&gt;E&lt;/math&gt; can extract &lt;math&gt;w&lt;/math&gt; from &lt;math&gt;\tilde P&lt;/math&gt;, we say that &lt;math&gt;\tilde P&lt;/math&gt; knows the value of &lt;math&gt;w&lt;/math&gt;.

This definition of the validity property is a combination of the validity and strong validity properties in.&lt;ref name="odpk"/&gt; For small knowledge errors &lt;math&gt;\kappa(x)&lt;/math&gt;, such as e.g. &lt;math&gt;2^{-80}&lt;/math&gt; or &lt;math&gt;1/\mathrm{poly}(|x|)&lt;/math&gt; it can be seen as being stronger than the '''[[Soundness (interactive proof)|soundness]]''' of ordinary [[Interactive proof system|interactive proofs]].

==Relation to general interactive proofs==

In order to define a specific proof of knowledge, one need not only define the language, but also the witnesses the verifier should know. In some cases proving membership in a language may be easy, while computing a specific witness may be hard. This is best explained using an example:

Let &lt;math&gt;\langle g \rangle&lt;/math&gt; be a [[cyclic group]] with generator &lt;math&gt;g&lt;/math&gt; in which solving the [[discrete logarithm]] problem is believed to be hard. Deciding membership of the language &lt;math&gt;L=\{x \mid g^w=x \}&lt;/math&gt; is trivial, as every &lt;math&gt;x&lt;/math&gt; is in &lt;math&gt;\langle g \rangle&lt;/math&gt;. However, finding the witness &lt;math&gt;w&lt;/math&gt; such that &lt;math&gt;g^w=x&lt;/math&gt; holds corresponds to solving the discrete logarithm problem.

==Protocols==

===Schnorr protocol===

One of the simplest and frequently used proofs of knowledge, the ''proof of knowledge of a [[discrete logarithm]]'', is due to Schnorr.&lt;ref&gt;[[Claus P. Schnorr|C P Schnorr]], Efficient identification and signatures for smart cards, in G Brassard, ed. Advances in Cryptology – [[Crypto (journal)|Crypto]] '89, 239–252, [[Springer-Verlag]], 1990. Lecture Notes in Computer Science, nr 435&lt;/ref&gt; The protocol is defined for a [[cyclic group]] &lt;math&gt;G_q&lt;/math&gt; of order &lt;math&gt;q&lt;/math&gt; with generator &lt;math&gt;g&lt;/math&gt;.

In order to prove knowledge of &lt;math&gt;x=\log_g y&lt;/math&gt;, the prover interacts with the verifier as follows:

# In the first round the prover commits himself to randomness &lt;math&gt;r&lt;/math&gt;; therefore the first message &lt;math&gt;t=g^r&lt;/math&gt; is also called ''commitment''. 
# The verifier replies with a ''challenge'' &lt;math&gt;c&lt;/math&gt; chosen at random.
# After receiving &lt;math&gt;c&lt;/math&gt;, the prover sends the third and last message (the ''response'') &lt;math&gt;s=r+cx&lt;/math&gt;.

The verifier accepts, if &lt;math&gt;g^s = t y^{c}&lt;/math&gt;.

===Sigma protocols===

Protocols which have the above three-move structure (commitment, challenge and response) are called ''sigma protocols''{{Citation needed|date=June 2017}}. The Greek letter &lt;math&gt;\Sigma&lt;/math&gt; visualizes the flow of the protocol. Sigma protocols exist for proving various statements, such as those pertaining to discrete logarithms. Using these proofs, the prover can not only prove the knowledge of the discrete logarithm, but also that the discrete logarithm is of a specific form. For instance, it is possible to prove that two logarithms of &lt;math&gt;y_1&lt;/math&gt; and &lt;math&gt;y_2&lt;/math&gt; with respect to bases &lt;math&gt;g_1&lt;/math&gt; and &lt;math&gt;g_2&lt;/math&gt; are equal or fulfill some other [[linear]] [[Relation (mathematics)|relation]]. For ''a'' and ''b'' elements of &lt;math&gt;Z_q&lt;/math&gt;, we say that the prover proves knowledge of &lt;math&gt;x_1&lt;/math&gt; and &lt;math&gt;x_2&lt;/math&gt; such that &lt;math&gt;y_1= g_1^{x_1} \land y_2=g_2^{x_2}&lt;/math&gt; and &lt;math&gt;x_2 = a x_1 + b&lt;/math&gt;. Equality corresponds to the special case where ''a''&amp;nbsp;=&amp;nbsp;1 and ''b''&amp;nbsp;=&amp;nbsp;0. As &lt;math&gt;x_2&lt;/math&gt; can be [[trivial (mathematics)|trivially]] computed from &lt;math&gt;x_1&lt;/math&gt; this is equivalent to proving knowledge of an ''x'' such that &lt;math&gt;y_1= g_1^{x} \land y_2={(g_2^a)}^{x} g_2^b&lt;/math&gt;.

This is the intuition behind the following notation{{Citation needed|reason=This notation is rather standard, but where was it introduced? It was introduced in J. Camenisch and M. Stadler. Efficient group signature schemes for large groups|date=June 2017}}, which is commonly used to express what exactly is proven by a proof of knowledge.

: &lt;math&gt;PK\{(x): y_1= g_1^{x} \land y_2={(g_2^a)}^{x} g_2^b \},&lt;/math&gt;

states that the prover knows an ''x'' that fulfills the relation above.

==Applications==

Proofs of knowledge are useful tool for the construction of identification protocols, and in their non-interactive variant, signature schemes. Such schemes are:

* [[Schnorr signature]]

They are also used in the construction of [[group signature]] and [[digital credential|anonymous digital credential]] systems.

==See also==
* [[Cryptographic protocol]]
* [[Zero-knowledge proof]]
* [[interactive proof system]]
* [[Topics in cryptography]]
* [[Zero-knowledge password proof]]
* [[Soundness (interactive proof)]]

==References==
&lt;references/&gt;

==External links==
* [http://www.cs.ut.ee/~lipmaa/crypto/link/zeroknowledge/pok.php Helger Lipmaa's cryptology pointers]



[[Category:Computational complexity theory]]
[[Category:Cryptography]]</text>
      <sha1>h8g0kyla9hpz20u6ux0dw2ztx182fyw</sha1>
    </revision>
  </page>
  <page>
    <title>Pseudorandom noise</title>
    <ns>0</ns>
    <id>41593</id>
    <revision>
      <id>836706905</id>
      <parentid>836695943</parentid>
      <timestamp>2018-04-16T11:36:47Z</timestamp>
      <contributor>
        <username>Sjö</username>
        <id>202394</id>
      </contributor>
      <comment>fewer line breaks, no change in wording</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4350">In [[cryptography]], '''pseudorandom noise''' ('''PRN''' &lt;ref&gt;{{cite web |url=http://www.gps.gov/technical/icwg/meetings/2011/09/13/WAS-IS-FINAL_PRN_Expansion_4May2011.pdf |title=Change Topic: Pseudorandom Noise (PRN) Expansion |publisher=GPS.GOV |accessdate=13 July 2011 }}&lt;/ref&gt;) is a [[Signalling (telecommunication)|signal]] similar to [[noise (physics)|noise]] which satisfies one or more of the standard tests for [[statistical randomness]]. Although it seems to lack any definite [[pattern]], pseudorandom noise consists of a deterministic [[sequence]] of [[Pulse (signal processing)|pulses]] that will repeat itself after its period.&lt;ref&gt;{{FS1037C MS188}}&lt;/ref&gt; 

In [[cryptography|cryptographic device]]s, the pseudorandom noise pattern is determined by a [[key (cryptography)|key]] and the repetition period can be very long, even millions of digits.

Pseudorandom noise is used in some [[synthesizer|electronic musical instruments]], either by itself or as an input to [[subtractive synthesis]], and in many [[white noise machine]]s.

In [[spread-spectrum]] systems, the receiver [[correlation|correlates]] a locally generated signal with the received [[signal (information theory)|signal]]. Such spread-spectrum systems require a set of one or more "codes" or "sequences" such that
* Like random noise, the local sequence has a very low correlation with any other sequence in the set, or with the same sequence at a significantly different time offset, or with narrow band interference, or with thermal noise.
* Unlike random noise, it must be easy to generate exactly the same sequence at both the transmitter and the receiver, so the receiver's locally generated sequence has a very high correlation with the transmitted sequence.

In a [[direct-sequence spread spectrum]] system, each bit in the [[pseudorandom binary sequence]] is known as a ''[[Chip (CDMA)|chip]]'' and the ''inverse'' of its period as ''[[chip rate]]''; ''compare [[bit rate]] and [[symbol rate]].''

In a [[frequency-hopping spread spectrum]] sequence, each value in the pseudorandom sequence is known as a ''channel number'' and the ''inverse'' of its period as the ''hop rate''. [[FCC Part 15]] mandates at least 50 different channels and at least a 2.5&amp;nbsp;Hz hop rate for narrow band frequency-hopping systems.

GPS satellites broadcast data at a rate of 50 data bits per second &amp;ndash; each satellite modulates its data with one PN bit stream at 1.023 million [[chips per second]] and the same data with another PN bit stream at 10.23 million chips per second.
[[GPS]] receivers correlate the received PN bit stream with a local reference to measure distance. GPS is a receive-only system that uses relative timing measurements from several satellites (and the known positions of the satellites) to determine receiver position.

Other [[range-finding]] applications involve two-way transmissions. A local station generates a pseudorandom bit sequence and transmits it to the remote location (using any modulation technique). Some object at the remote location echoes this PN signal back to the location station &amp;ndash; either passively, as in some kinds of radar and sonar systems, or using an active transponder at the remote location, as in the Apollo [[Unified S-band]] system.&lt;ref&gt;[http://www.ab9il.net/aviation/apollo-s-band.html "The Apollo Unified S Band System"]
&lt;/ref&gt; By correlating a (delayed version of) the transmitted signal with the received signal, a precise round trip time to the remote location can be determined and thus the distance.

==PN code==
{{main|Pseudorandom binary sequence}}
A '''pseudo-noise code''' ('''PN code''') or '''pseudo-random-noise code''' ('''PRN code''') is one that has a spectrum similar to a [[algorithmically random sequence|random sequence]] of bits but is [[Deterministic computation|deterministically]] generated. The most commonly used sequences in [[direct-sequence spread spectrum]] systems are [[maximal length sequence]]s, [[Gold code]]s, [[Kasami code]]s, and [[Barker code]]s.&lt;ref&gt;[http://www-mobile.ecs.soton.ac.uk/bjc97r/pnseq.old/node1.html]&lt;/ref&gt;

==See also==
* [[Gold code|Gold Codes]]
* [[Maximum length sequence]]
* [[Pseudorandom number generator]]
* [[Pseudorandomness]]
* [[White noise]]

==References==
{{Reflist}}

{{Cdma}}

[[Category:Noise (electronics)]]
[[Category:Pseudorandomness]]</text>
      <sha1>3dkjqnuippokddsefssmg26mly6uxqx</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum knots</title>
    <ns>0</ns>
    <id>54511709</id>
    <revision>
      <id>862145449</id>
      <parentid>862145341</parentid>
      <timestamp>2018-10-02T13:21:10Z</timestamp>
      <contributor>
        <username>MaoGo</username>
        <id>14660971</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1062">{{Multiple issues|{{unreferenced|date=July 2017}}{{confusing|date=July 2017|reason=Incomprehensible english &amp; needs breaking into sentences}}{{expert needed|date=July 2017|reason=Clarify the article}}
}}

{{Quantum mechanics|cTopic=Background}}
'''Quantum knots''' is a branch of [[quantum mechanics]] that connects [[quantum computing]] with [[Knot theory]].

While resisting the [[electron]] with [[Lorentz force]] it gets divided into three particles called [[quasiparticle]] along with an amount of energy from the electron. These quasiparticles tightly coupled by a knot like structure similar to the needle with a thread. If an electron from other orbit interact with this knot make other knot, by applying the knot position, the [[quantum states]] can be easily determined and it will solve the [[quantum superposition]] problems in [[quantum computing]]

== External links ==
* [https://www.youtube.com/watch?v=hKFecm9NKbM] at Institute for Quantum Information and Matter.

[[Category:Quantum mechanics]]
[[Category:Quantum computing]]


{{quantum-stub}}</text>
      <sha1>jrcmuh40f5w9ren8zwqsj50cbildhl4</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum metrology</title>
    <ns>0</ns>
    <id>3975868</id>
    <revision>
      <id>847997794</id>
      <parentid>845695358</parentid>
      <timestamp>2018-06-29T04:44:18Z</timestamp>
      <contributor>
        <username>Michael Devore</username>
        <id>44833</id>
      </contributor>
      <minor/>
      <comment>/* Relation to quantum information science */ typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4957">'''Quantum metrology''' is the study of making high-resolution and highly sensitive  measurements of physical parameters using quantum theory to describe the physical systems,&lt;ref&gt;[https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.72.3439 S. L. Braunstein and C. M. Caves,  Phys. Rev. Lett. 72 (1994) 3439]&lt;/ref&gt; particularly exploiting [[quantum entanglement]] and quantum squeezing. This field promises to develop measurement techniques that give better precision than the same measurement performed in a classical framework.

== Examples ==
One example of note is the use of the [[NOON state]] in a [[Mach-Zender interferometer]] to perform accurate phase measurements.&lt;ref&gt;[http://www.iop.org/EJ/abstract/1464-4266/6/8/029 P.Kok et al., J. Opt. B 6 (2004) S811].&lt;/ref&gt;  A similar effect can be produced using less exotic states such as [[squeezed state]]s. In atomic ensembles, [[Spin squeezing|spin squeezed states]] can be used for phase measurements.

== Applications ==
An important application of particular note is the detection of [[gravitational radiation]] with projects such as [[LIGO]].  Here high precision distance measurements must be made of two widely separated masses.  However, currently the measurements described by quantum metrology are usually not used as they are very difficult to implement and there are many other sources of noise which prohibit the detection of gravity waves which must be overcome first. Nevertheless, plans may call for the use of quantum metrology in LIGO.&lt;ref&gt;[http://link.aps.org/abstract/PRD/v65/e022002 H.J.Kimble, et al., Phys. Rev. D 65 (2001) 022002].&lt;/ref&gt;

== Scaling and the effect of noise ==
A central question of quantum metrology, how the precision, i.e., the variance of the parameter estimation, scales with the number of particles. Classical interferometers cannot overcome the shot-noise limit &lt;math&gt;(\Delta \theta)^2\ge \tfrac{1}{N},&lt;/math&gt; where is &lt;math&gt;N&lt;/math&gt; the number of particles. Quantum metrology can reach the Heisenberg limit given by &lt;math&gt;(\Delta \theta)^2\ge \tfrac{1}{N^2}.&lt;/math&gt;

However, if uncorrelated local noise is present, then for large particle numbers the scaling of the precision returns to shot-noise scaling &lt;math&gt;(\Delta \theta)^2\sim \tfrac{1}{N}.&lt;/math&gt;&lt;ref&gt;{{Cite journal|last=Demkowicz-Dobrzański|first=Rafał|last2=Kołodyński|first2=Jan|last3=Guţă|first3=Mădălin|date=2012-09-18|title=The elusive Heisenberg limit in quantum-enhanced metrology|url=https://www.nature.com/articles/ncomms2067|journal=Nature Communications|volume=3|pages=1063|doi=10.1038/ncomms2067|arxiv=1201.3940|bibcode=2012NatCo...3E1063D}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Escher|first=B. M.|last2=Filho|first2=R. L. de Matos|last3=Davidovich|first3=L.|date=May 2011|title=General framework for estimating the ultimate precision limit in noisy quantum-enhanced metrology|url=http://www.nature.com/articles/nphys1958|journal=Nature Physics|volume=7|issue=5|pages=406–411|doi=10.1038/nphys1958|issn=1745-2481|arxiv=1201.1693|bibcode=2011NatPh...7..406E}}&lt;/ref&gt;

== Relation to quantum information science ==
There are strong links between quantum metrology and quantum information science. It has been shown that [[quantum entanglement]] is needed to outperform classical interferometry in magnetrometry with a fully polarized ensemble of spins.&lt;ref&gt;{{Cite journal|last=Sørensen|first=Anders S.|date=2001|title=Entanglement and Extreme Spin Squeezing|url=https://link.aps.org/doi/10.1103/PhysRevLett.86.4431|journal=Physical Review Letters|volume=86|issue=20|pages=4431–4434|doi=10.1103/physrevlett.86.4431|arxiv=quant-ph/0011035|bibcode=2001PhRvL..86.4431S}}&lt;/ref&gt; It has been proved that a similar relation is generally valid for any linear interferometer, independent of the details of the scheme.&lt;ref&gt;{{Cite journal|last=Pezzé|first=Luca|date=2009|title=Entanglement, Nonlinear Dynamics, and the Heisenberg Limit|url=https://link.aps.org/doi/10.1103/PhysRevLett.102.100401|journal=Physical Review Letters|volume=102|issue=10|doi=10.1103/physrevlett.102.100401|arxiv=0711.4840|bibcode=2009PhRvL.102j0401P}}&lt;/ref&gt; Moreover, higher and higher levels of multipartite entanglement is needed to achieve a better and better accuracy in parameter estimation.&lt;ref&gt;{{Cite journal|last=Hyllus|first=Philipp|date=2012|title=Fisher information and multiparticle entanglement|url=https://link.aps.org/doi/10.1103/PhysRevA.85.022321|journal=Physical Review A|volume=85|issue=2|doi=10.1103/physreva.85.022321|arxiv=1006.4366|bibcode=2012PhRvA..85b2321H}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Tóth|first=Géza|date=2012|title=Multipartite entanglement and high-precision metrology|url=https://link.aps.org/doi/10.1103/PhysRevA.85.022322|journal=Physical Review A|volume=85|issue=2|doi=10.1103/physreva.85.022322|arxiv=1006.4368|bibcode=2012PhRvA..85b2322T}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Quantum information science]]
[[Category:Quantum mechanics]]


{{quantum-stub}}</text>
      <sha1>59kqn79xghgfwrcd122euvxscwsr9cz</sha1>
    </revision>
  </page>
  <page>
    <title>Race condition</title>
    <ns>0</ns>
    <id>475952</id>
    <revision>
      <id>870679378</id>
      <parentid>866263921</parentid>
      <timestamp>2018-11-26T10:51:45Z</timestamp>
      <contributor>
        <username>Zazpot</username>
        <id>632368</id>
      </contributor>
      <minor/>
      <comment>Wikilink [[David A. Huffman]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19437">{{Refimprove|date=July 2010}}
[[File:Race condition.svg|frame|Race condition in a logic circuit. Here, ∆''t''&lt;sub&gt;1&lt;/sub&gt; and ∆''t''&lt;sub&gt;2&lt;/sub&gt; represent the [[propagation delay]]s of the logic elements. When the input value ''A'' changes from low to high, the circuit outputs a short spike of duration (∆''t''&lt;sub&gt;1&lt;/sub&gt; + ∆''t''&lt;sub&gt;2&lt;/sub&gt;) − ∆''t''&lt;sub&gt;2&lt;/sub&gt; = ∆''t''&lt;sub&gt;1&lt;/sub&gt;.]]

A '''race condition''' or '''race hazard''' is the behavior of an [[electronics]], [[software]], or other [[system]] where the output is dependent on the sequence or timing of other uncontrollable events. It becomes a [[software bug|bug]] when events do not happen in the order the programmer intended.

The term '''race condition''' was already in use by 1954, for example in [[David A. Huffman]]'s doctoral thesis "The synthesis of sequential switching circuits". &lt;ref&gt;Huffman, David A. "The synthesis of sequential switching circuits." (1954).&lt;/ref&gt;

Race conditions can occur especially in [[logic gate|logic circuits]], [[thread (computing)|multithreaded]] or [[distributed computing|distributed]] software programs.

==Electronics==
A typical example of a race condition may occur when a [[logic gate]] combines signals that have traveled along different paths from the same source. The inputs to the gate can change at slightly different times in response to a change in the source signal. The output may, for a brief period, change to an unwanted state before settling back to the designed state. Certain systems can tolerate such [[glitch]]es but if this output functions as a [[clock signal]] for further systems that contain memory, for example, the system can rapidly depart from its designed behaviour (in effect, the temporary glitch becomes a permanent glitch).

Consider, for example, a two-input [[AND gate]] fed with a logic signal A on one input and its negation, NOT A, on another input. In theory the output (A AND NOT A) should never be true. If, however, changes in the value of A take longer to propagate to the second input than the first when A changes from false to true then a brief period will ensue during which both inputs are true, and so the gate's output will also be true.&lt;ref&gt;{{cite journal |first=S.H. |last=Unger |title=Hazards, Critical Races, and Metastability |journal=IEEE Transactions on Computers |volume=44 |issue=6 |pages=754–768 |date=June 1995 |doi=10.1109/12.391185 |url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=391185}}&lt;/ref&gt;

Design techniques such as [[Karnaugh map]]s encourage designers to recognize and eliminate race conditions before they cause problems. Often [[logic redundancy]] can be added to eliminate some kinds of races.

As well as these problems, some logic elements can enter [[metastability (electronics)|metastable states]], which create further problems for circuit designers.

===Critical and non-critical forms===
A ''critical race condition'' occurs when the order in which internal variables are changed determines the eventual state that the [[finite-state machine|state machine]] will end up in.

A ''non-critical race condition'' occurs when the order in which internal variables are changed does not determine the eventual state that the state machine will end up in.

===Static, dynamic, and essential forms===
A ''static race condition'' occurs when a signal and its complement are combined together.

A ''dynamic race condition'' occurs when it results in multiple transitions when only one is intended. They are due to interaction between gates. It can be eliminated by using no more than two levels of gating.

An ''essential race condition'' occurs when an input has two transitions in less than the total feedback propagation time. Sometimes they are cured using inductive [[analog delay line|delay line]] elements to effectively increase the time duration of an input signal.

==Software==
Race conditions arise in software when an application depends on the sequence or timing of [[process (computing)|processes]] or [[thread (computing)|threads]] for it to operate properly. As with electronics, there are critical race conditions that result in invalid execution and [[software bug|bugs]]. Critical race conditions often happen when the processes or threads depend on some shared state. Operations upon shared states are [[critical section]]s that must be [[mutual exclusion|mutually exclusive]]. Failure to obey this rule opens up the possibility of corrupting the shared state.

The [[memory model (programming)|memory model]] defined in the [[C11 (C standard revision)|C11]] and [[C++11]] standards uses the term "data race" for a race condition caused by potentially concurrent operations on a shared memory location, of which at least one is a write. A C or C++ program containing a data race has [[undefined behavior]].&lt;ref&gt;{{cite web|url=http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=57853 |title=ISO/IEC 9899:2011 - Information technology - Programming languages - C |publisher=Iso.org |date= |accessdate=2018-01-30}}&lt;/ref&gt;&lt;ref&gt;{{cite web |authorlink= ISO |title= ISO/IEC 14882:2011 |publisher= ISO |date= 2 September 2011 |url= http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=50372 |accessdate= 3 September 2011}}&lt;/ref&gt;

Race conditions have a reputation of being difficult to reproduce and debug, since the end result is [[nondeterministic algorithm|nondeterministic]] and depends on the relative timing between interfering threads. Problems occurring in production systems can therefore disappear when running in debug mode, when additional logging is added, or when attaching a debugger, often referred to as a "[[Heisenbug]]". It is therefore better to avoid race conditions by careful software design rather than attempting to fix them afterwards.

===Example===
As a simple example, let us assume that two threads want to increment the value of a global integer variable by one. Ideally, the following sequence of operations would take place:

{| class="wikitable" style="text-align: center;"
|-
! Thread 1 !! Thread 2 !! !! Integer value
|-
|   ||   ||  || 0
|-
| read value ||   || ← || 0
|-
| style="background: wheat;" | increase value ||  || || 0
|-
| write back ||  || → || 1
|-
| || read value   || ← || 1
|-
| || style="background: wheat;" | increase value || || 1
|-
| || write back || → || 2
|}

In the case shown above, the final value is 2, as expected. However, if the two threads run simultaneously without locking or synchronization, the outcome of the operation could be wrong. The alternative sequence of operations below demonstrates this scenario:

{| class="wikitable" style="text-align: center;"
|-
! Thread 1 !! Thread 2 !! !! Integer value
|-
|   ||   ||  || 0
|-
| read value ||   || ← || 0
|-
| || read value || ← || 0
|-
| style="background: wheat;" | increase value ||  ||  || 0
|-
| || style="background: wheat;" | increase value  ||  || 0
|-
| write back ||  || → || 1
|-
| || write back || → || 1
|}

In this case, the final value is 1 instead of the expected result of 2. This occurs because here the increment operations are not [[mutually exclusive]]. Mutually exclusive operations are those that cannot be interrupted while accessing some resource such as a memory location.

===Computer security===
Many software race conditions have associated [[computer security]] implications. A race condition allows an attacker with access to a shared resource to cause other actors that utilize that resource to malfunction, resulting in effects including [[Denial-of-service attack|denial of service]]&lt;ref name="CVE-2015-8461"&gt;{{cite web|url=https://kb.isc.org/article/AA-01319/0/CVE-2015-8461%3A-A-race-condition-when-handling-socket-errors-can-lead-to-an-assertion-failure-in-resolver.c.html|title=CVE-2015-8461: A race condition when handling socket errors can lead to an assertion failure in resolver.c|accessdate=5 June 2017|publisher=[[Internet Systems Consortium]]}}&lt;/ref&gt; and [[privilege escalation]].&lt;ref name="CVE-2017-6512" /&gt;&lt;ref name="lighttpd-issue-2724"&gt;{{cite web|url=https://redmine.lighttpd.net/issues/2724|publisher=[[lighttpd]]|accessdate=5 June 2017|title=security: stat cache *very large* race condition if caching when follow_symlink disabled}}&lt;/ref&gt;

A specific kind of race condition involves checking for a predicate (e.g. for [[authentication]]), then acting on the predicate, while the state can change between the ''time of check'' and the ''time of use''. When this kind of [[computer bug|bug]] exists in security-sensitive code, a [[security vulnerability]] called a [[time-of-check-to-time-of-use]] (''TOCTTOU'') bug is created.

Race conditions are also intentionally used to create [[hardware random number generator]]s and [[physically unclonable function]]s.{{Citation needed|date=February 2018}} PUFs can be created by designing circuit topologies with identical paths to a node and relying on manufacturing variations to randomly determine which paths will complete first. By measuring each manufactured circuit's specific set of race condition outcomes, a profile can be collected for each circuit and kept secret in order to later verify a circuit's identity.

===File systems===
Two or more programs may collide in their attempts to modify or access a file system, which can result in data corruption or privilege escalation.&lt;ref name="CVE-2017-6512"&gt;{{cite web|url=https://rt.cpan.org/Public/Bug/Display.html?id=121951|accessdate=5 June 2017|title=Vulnerability in rmtree() and remove_tree(): CVE-2017-6512|publisher=[[CPAN]]}}&lt;/ref&gt; [[File locking]] provides a commonly used solution. A more cumbersome remedy involves organizing the system in such a way that one unique process (running a [[daemon (computing)|daemon]] or the like) has exclusive access to the file, and all other processes that need to access the data in that file do so only via interprocess communication with that one process. This requires synchronization at the process level.

A different form of race condition exists in file systems where unrelated programs may affect each other by suddenly using up available resources such as disk space, memory space, or processor cycles. Software not carefully designed to anticipate and handle this race situation may then become unpredictable. Such a risk may be overlooked for a long time in a system that seems very reliable. But eventually enough data may accumulate or enough other software may be added to critically destabilize many parts of a system. An example of this occurred with the near loss of the [[Spirit (rover)#Sol 17 (January 21, 2004) flash memory management anomaly|Mars Rover "Spirit"]] not long after landing. A solution is for software to request and reserve all the resources it will need before beginning a task; if this request fails then the task is postponed, avoiding the many points where failure could have occurred. Alternatively, each of those points can be equipped with error handling, or the success of the entire task can be verified afterwards, before continuing. A more common approach is to simply verify that enough system resources are available before starting a task; however, this may not be adequate because in complex systems the actions of other running programs can be unpredictable.

===Networking===
In networking, consider a distributed chat network like [[IRC]], where a user who starts a channel automatically acquires channel-operator privileges. If two users on different servers, on different ends of the same network, try to start the same-named channel at the same time, each user's respective server will grant channel-operator privileges to each user, since neither server will yet have received the other server's signal that it has allocated that channel. (This problem has been largely [[Internet Relay Chat#Abuse prevention|solved]] by various IRC server implementations.)

In this case of a race condition, the concept of the "[[shared resource]]" covers the state of the network (what channels exist, as well as what users started them and therefore have what privileges), which each server can freely change as long as it signals the other servers on the network about the changes so that they can update their conception of the state of the network. However, the [[latency (engineering)|latency]] across the network makes possible the kind of race condition described. In this case, heading off race conditions by imposing a form of control over access to the shared resource—say, appointing one server to control who holds what privileges—would mean turning the distributed network into a centralized one (at least for that one part of the network operation).

Race conditions can also exist when a computer program is written with [[Berkeley sockets#Blocking vs. non-blocking mode|non-blocking sockets]], in which case the performance of the program can be dependent on the speed of the network link.

===Life-critical systems===
Software flaws in [[life-critical system]]s can be disastrous. Race conditions were among the flaws in the [[Therac-25]] [[radiation therapy]] machine, which led to the death of at least three patients and injuries to several more.&lt;ref&gt;{{cite web |url=http://courses.cs.vt.edu/~cs3604/lib/Therac_25/Therac_1.html |title=An Investigation of Therac-25 Accidents — I |publisher=Courses.cs.vt.edu |date= |accessdate=2011-09-19}}&lt;/ref&gt;

Another example is the Energy Management System provided by [[GE Energy]] and used by [[Ohio]]-based [[FirstEnergy Corp]] (among other power facilities). A race condition existed in the alarm subsystem; when three sagging power lines were tripped simultaneously, the condition prevented alerts from being raised to the monitoring technicians, delaying their awareness of the problem. This software flaw eventually led to the [[2003 North America blackout|North American Blackout of 2003]].&lt;ref&gt;{{cite web |author=Kevin Poulsen |url=http://www.securityfocus.com/news/8412 |title=Tracking the blackout bug |publisher=Securityfocus.com |date=2004-04-07 |accessdate=2011-09-19}}&lt;/ref&gt; GE Energy later developed a software patch to correct the previously undiscovered error.

==Examples outside of computing==

===Biology===
{{Expand section|date=October 2016}}

Neuroscience is demonstrating that race conditions can occur in mammal (rat) brains as well.&lt;ref&gt;{{cite web |date=2013-08-03 |title=How Brains Race to Cancel Errant Movements |publisher=Discover Magazine blogs |url=https://blogs.discovermagazine.com/neuroskeptic/2013/08/03/the-race-to-stop-an-errant-movement/}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |doi= 10.1038/nn.3456|title= Canceling actions involves a race between basal ganglia pathways|year= 2013|last1= Schmidt|first1= Robert|last2= Leventhal|first2= Daniel K|last3= Mallet|first3= Nicolas|last4= Chen|first4= Fujun|last5= Berke|first5= Joshua D|journal= Nature Neuroscience|volume= 16|issue= 8|pages= 1118–24|pmid= 23852117|pmc= 3733500}}&lt;/ref&gt;

==Tools==

Many software tools exist to help detect race conditions in software. They can be largely categorized into two groups: [[static program analysis|static analysis]] tools and [[dynamic program analysis|dynamic analysis]] tools.

Thread Safety Analysis is a static analysis tool for annotation-based intra-procedural static analysis, originally implemented as a branch of gcc, and now reimplemented in [[Clang]], supporting PThreads.&lt;ref&gt;{{cite web |title=Thread Safety Analysis|url=http://clang.llvm.org/docs/ThreadSafetyAnalysis.html}}&lt;/ref&gt;{{Primary source inline|date=December 2016}}

Dynamic analysis tools include: [[Intel Inspector]], a memory and thread checking and debugging tool to increase the reliability, security, and accuracy of C/C++ and Fortran applications; [[Intel Advisor]], a sampling based, SIMD vectorization optimization and shared memory threading assistance tool for C, C++, C#, and Fortran software developers and architects; ThreadSanitizer, which uses binary ([[Valgrind]]-based) or source, [[LLVM]]-based instrumentation, and supports PThreads);&lt;ref&gt;{{cite web |title=THREADSANITIZER|url=http://clang.llvm.org/docs/ThreadSanitizer.html}}&lt;/ref&gt;{{Primary source inline|date=December 2016}} and Helgrind, a [[Valgrind]] tool for detecting synchronisation errors in C, C++ and Fortran programs that use the POSIX pthreads threading primitives.&lt;ref&gt;{{cite web |title=Helgrind: a thread error detector|url=http://valgrind.org/docs/manual/hg-manual.html}}&lt;/ref&gt;{{Primary source inline|date=December 2016}}

==See also==
{{Portal|Software testing}}
* [[Call collision]]
* [[Concurrency control]]
* [[Deadlock]]
* [[Hazard (logic)]] (near-duplicate article)
* [[Linearizability]]
* [[Racetrack problem]]
* [[Synchronization (computer science)]]
* [[Time of check to time of use]]

==References==
{{Reflist}}

==External links==
* {{cite journal |first1=G.M. |last1=Karam |first2=R.J.A. |last2=Buhr |title=Starvation and Critical Race Analyzers for Ada |journal=[[IEEE Transactions on Software Engineering]] |volume=16 |issue=8 |pages=829–843 |date=August 1990 |doi=10.1109/32.57622 |url=http://doi.ieeecomputersociety.org/10.1109/32.57622}}
* {{cite book |last1=Fuhrer |first1=R.M. |last2=Lin |first2=B. |last3=Nowick |first3=S.M. |author3-link=Steven M. Nowick |chapter=Algorithms for the optimal state assignment of asynchronous state machines |chapterurl=http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=515611 |title=Advanced Research in VLSI, 1995. Proceedings., 16th Conference on |date=March 1995 |isbn=0-8186-7047-9 |pages=59–75 |doi=10.1109/ARVLSI.1995.515611}} [http://www.cs.columbia.edu/~rmf/arvlsi-95.pdf as PDF]
* Paper "[http://citeseer.ist.psu.edu/11804.html A Novel Framework for Solving the State Assignment Problem for Event-Based Specifications]" by [[Luciano Lavagno]], [[Cho W. Moon]], [[Robert K. Brayton]], and [[Alberto Sangiovanni-Vincentelli]]
* {{cite web |first=David A. |last=Wheeler |title=Secure programmer: Prevent race conditions—Resource contention can be used against you |date=7 October 2004 |work=IBM developerWorks |url=http://www-128.ibm.com/developerworks/linux/library/l-sprace.html |archive-date= Nov 14, 2013 |archive-url= http://www.ida.liu.se/~TDDC90/literature/papers/SP-race-conditions.pdf |format= PDF}}
* Chapter "[http://www.dwheeler.com/secure-programs/Secure-Programs-HOWTO/avoid-race.html Avoid Race Conditions]" (Secure Programming for Linux and Unix HOWTO)
* [https://web.archive.org/web/20070926215258/http://chiralsoftware.com/blog/Race-condition-vulnerability-in-syscall-wrappers-fa3e57c594119803.html Race conditions, security, and immutability in Java], with sample source code and comparison to C code, by Chiral Software
* {{cite web |first=Andrey |last=Karpov |title=Interview with Dmitriy Vyukov — the author of Relacy Race Detector (RRD) |date=11 April 2009 |work=Intel Software Library Articles |url=http://software.intel.com/en-us/articles/interview-with-dmitriy-vyukov-the-author-of-relacy-race-detector-rrd/}}
* [http://support.microsoft.com/kb/317723 Microsoft Support description]

{{Concurrent computing}}
{{DEFAULTSORT:Race condition}}
[[Category:Anti-patterns]]
[[Category:Computer security exploits]]
[[Category:Concurrency (computer science)]]
[[Category:Distributed computing problems]]
[[Category:Logic gates]]
[[Category:Logic in computer science]]
[[Category:Software bugs]]
[[Category:Timing in electronic circuits]]</text>
      <sha1>omk0h3xenlqnxlp5xaks45uu64heo1y</sha1>
    </revision>
  </page>
  <page>
    <title>Seidel's algorithm</title>
    <ns>0</ns>
    <id>55206702</id>
    <revision>
      <id>829638701</id>
      <parentid>829638685</parentid>
      <timestamp>2018-03-09T21:21:04Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: class, year. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5020">'''Seidel's algorithm''' is an algorithm designed by [[Raimund Seidel]] in 1992 for the [[Shortest path problem#All-pairs shortest paths|all-pairs-shortest-path problem]] for undirected, unweighted, connected graphs.&lt;ref name="paper"&gt;{{cite journal|url=https://doi.org/10.1006/jcss.1995.1078|title=On the All-Pairs-Shortest-Path Problem in Unweighted Undirected Graphs|first=R.|last=Seidel|publisher=|journal=Journal of Computer and System Sciences|volume=51|issue=3|pages=400–403|doi=10.1006/jcss.1995.1078|year=1995}}&lt;/ref&gt; It solves the problem in &lt;math&gt;O(V^\omega \log V)&lt;/math&gt; expected time for a graph with &lt;math&gt;V&lt;/math&gt; vertices, where &lt;math&gt;\omega &lt; 2.373&lt;/math&gt; is the exponent in the complexity &lt;math&gt;O(n^\omega)&lt;/math&gt; of &lt;math&gt;n \times n&lt;/math&gt; [[Matrix Multiplication|matrix multiplication]]. If only the distances between each pair of vertices are sought, the same time bound can be achieved in the worst case. Note that even though the algorithm is designed for connected graphs, it can be applied individually to each [[Connected component (graph theory)|connected component]] of a graph with the same running time overall. Note also that there is an exception to the expected running time given above for computing the paths: if &lt;math&gt;\omega = 2&lt;/math&gt; the expected running time becomes &lt;math&gt;O(V^2 \log^2 V)&lt;/math&gt;.

== Details of the implementation ==

The core of the algorithm is a procedure that computes the length of the shortest-paths between any pair of vertices.
This can be done in &lt;math&gt;O(V^\omega \log V)&lt;/math&gt; time in the worst case. Once the lengths are computed, the paths can be reconstructed using a [[Las Vegas algorithm]] whose expected running time is &lt;math&gt;O(V^\omega \log V)&lt;/math&gt; for &lt;math&gt;\omega &gt; 2&lt;/math&gt; and &lt;math&gt;O(V^2 \log^2 V)&lt;/math&gt; for &lt;math&gt;\omega = 2&lt;/math&gt;.

=== Computing the shortest-paths lengths ===

The python code below assumes the input graph is given as a &lt;math&gt;n\times n&lt;/math&gt; &lt;math&gt;0&lt;/math&gt;-&lt;math&gt;1&lt;/math&gt; adjacency matrix &lt;math&gt;A&lt;/math&gt; with zeros on the diagonal. It defines the function APD which returns a matrix with entries &lt;math&gt;D_{i,j}&lt;/math&gt; such that &lt;math&gt;D_{i,j}&lt;/math&gt; is the length of the shortest path between the vertices &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;. The matrix class used can be any matrix class implementation supporting the multiplication, exponentiation, and indexing operators (for example [https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html numpy.matrix]).

&lt;syntaxhighlight lang="python"&gt;
def APD ( A , n ):
    if all( A[i][j] for i in range(n) for j in range(n) if i != j ): return A
    Z = A**2
    B = matrix( [
        [ 1 if i != j and ( A[i][j] == 1 or Z[i][j] &gt; 0 ) else 0 for j in range(n) ]
    for i in range(n) ] )
    T = APD( B , n )
    X = T*A
    degree = [ sum( A[i][j] for j in range(n) ) for i in range(n) ]
    D = matrix( [
        [ 2 * T[i][j] if X[i][j] &gt;= T[i][j] * degree[j] else 2 * T[i][j] - 1 for j in range(n) ]
    for i in range(n) ] )
    return D
&lt;/syntaxhighlight&gt;

The base case tests whether the input adjacency matrix describes a complete graph, in which case all shortest paths have length &lt;math&gt;1&lt;/math&gt;.

== Graphs with weights from finite universes ==

Algorithms for undirected and directed graphs with weights from a finite universe &lt;math&gt;\{1,\ldots,M,+\infty\}&lt;/math&gt; also exist. The best known algorithm for the directed case is in time &lt;math&gt;\tilde{O}(M^{1/(4-\omega)} V^{2+1/(4-\omega)})&lt;/math&gt; by Zwick in 1998.&lt;ref&gt;{{cite web|url=http://ieeexplore.ieee.org:80/document/743464/?reload=true|title=All pairs shortest paths in weighted directed graphs-exact and almost exact algorithms|first=U.|last=Zwick|date=1 November 1998|publisher=|pages=310–319|via=IEEE Xplore|doi=10.1109/SFCS.1998.743464}}&lt;/ref&gt; This algorithm uses rectangular matrix multiplication instead of square matrix multiplication. Better upper bounds can be obtained if one uses the best rectangular matrix multiplication algorithm available instead of achieving rectangular multiplication via multiple square matrix multiplications. The best known algorithm for the undirected case is in time &lt;math&gt;\tilde{O}(MV^\omega)&lt;/math&gt; by Shoshan and Zwick in 1999.&lt;ref&gt;{{cite web|url=http://ieeexplore.ieee.org:80/document/814635/?reload=true|title=All pairs shortest paths in undirected graphs with integer weights|first1=A.|last1=Shoshan|first2=U.|last2=Zwick|date=15 February 1999|publisher=|pages=605–614|via=IEEE Xplore|doi=10.1109/SFFCS.1999.814635}}&lt;/ref&gt; The original implementation of this algorithm was erroneous and has been corrected by Eirinakis, Williamson, and Subramani in 2016.&lt;ref&gt;{{cite arxiv|title=On the Shoshan-Zwick Algorithm for the All-Pairs Shortest Path Problem|first1=Pavlos|last1=Eirinakis|first2=Matthew|last2=Williamson|first3=K.|last3=Subramani|date=28 March 2016|publisher=|eprint=1603.08627|class=cs.DS}}&lt;/ref&gt;

== Notes ==
{{reflist|1}}

[[Category:Algorithms]]
[[Category:Polynomial-time problems]]
[[Category:Computational problems in graph theory]]</text>
      <sha1>acwrj6gjb3fj8mlkvosh6gpnphmc5m7</sha1>
    </revision>
  </page>
  <page>
    <title>Simultaneous game</title>
    <ns>0</ns>
    <id>23992863</id>
    <revision>
      <id>859109216</id>
      <parentid>845838222</parentid>
      <timestamp>2018-09-11T19:38:45Z</timestamp>
      <contributor>
        <username>Cmglee</username>
        <id>414836</id>
      </contributor>
      <comment>/* top */ Fix diagonal split header</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3052">[[File:Roshambo-Laos.jpg|thumb|upright=1.2|[[Rock–paper–scissors]] is an example of a simultaneous game.]]
In [[game theory]], a '''simultaneous game''' is a game where each player chooses his action without knowledge of the actions chosen by other players.&lt;ref&gt;[http://www-bcf.usc.edu/~brocas/Research/simseq.pdf http://www-bcf.usc.edu] The Path to Equilibrium in Sequential and Simultaneous Games (Brocas, Carrillo, Sachdeva; 2016).&lt;/ref&gt; Simultaneous games contrast with [[sequential game]]s, which are played by the players taking turns (moves alternate between players). [[Normal form game|Normal form]] representations are usually used for simultaneous games.{{citation needed|date=October 2017}}

[[Rock-paper-scissors]], a widely played hand game, is an example of a simultaneous game. Both players make a decision without knowledge of the opponent's decision, and reveal their hands at the same time. There are two players in this game and each of them has three different strategies to make their decision; the combination of strategy profiles forms a 3×3 table. We will display Player 1’s strategies as rows and Player 2’s strategies as columns. In the table, the numbers in red represent the payoff to Player 1, the numbers in blue represent the payoff to Player 2. Hence, the pay off for a 2 player game in rock-paper-scissors will look like this:
{| class="wikitable" style="margin-left: auto; margin-right: auto; border: none;"
! width="90px" {{diagonal split header|&lt;br /&gt;Player 1|Player 2}}
! width="50px"| Rock
! width="50px"| Paper
! width="50px"| Scissors
|-
!Rock
|{{diagonal split header|{{red|0}} | {{blue|0}} |transparent}}
|{{diagonal split header|{{red|-1}}| {{blue|1}} |transparent}}
|{{diagonal split header|{{red|1}} | {{blue|-1}}|transparent}}
|-
!Paper
|{{diagonal split header|{{red|1}} | {{blue|-1}}|transparent}}
|{{diagonal split header|{{red|0}} | {{blue|0}} |transparent}}
|{{diagonal split header|{{red|-1}}| {{blue|1}} |transparent}}
|-
!Scissors
|{{diagonal split header|{{red|-1}}| {{blue|1}} |transparent}}
|{{diagonal split header|{{red|1}} | {{blue|-1}}|transparent}}
|{{diagonal split header|{{red|0}} | {{blue|0}} |transparent}}
|}

The [[prisoner's dilemma]] is also an example of a simultaneous game. Some variants of chess that belong to this class of games include Synchronous chess {{sfnp |Pritchard |2007 |p=100 |ps=}} and Parity chess.&lt;ref&gt;{{cite web |url=http://paritychess.blogspot.com/ |title=Parity Chess |last=A V|first=Murali |publisher=''[[Blogger]]'' |date=2014-10-07 |accessdate=2017-01-15}}&lt;/ref&gt;

==See also==
*[[Sequential game]]
*[[Simultaneous action selection]]

==References==
{{reflist}}

'''Bibliography'''
*{{cite book
 |last=Pritchard 
 |first=D. B. 
 |authorlink=David Pritchard (chess player)
 |editor-last=Beasley
 |editor-first=John
 |title=The Classified Encyclopedia of Chess Variants
 |publisher=John Beasley 
 |year=2007
 |isbn=978-0-9555168-0-1}}

{{Game theory}}

{{DEFAULTSORT:Simultaneous Game}}
[[Category:Game theory game classes]]
[[Category:Game theory]]</text>
      <sha1>07pooxe2hawgxfipuxz89ea5pv4gfhb</sha1>
    </revision>
  </page>
  <page>
    <title>Structured derivations</title>
    <ns>0</ns>
    <id>28795896</id>
    <revision>
      <id>645802801</id>
      <parentid>631487374</parentid>
      <timestamp>2015-02-05T21:38:14Z</timestamp>
      <contributor>
        <username>Wavelength</username>
        <id>271168</id>
      </contributor>
      <comment>inserting 1 [[hyphen]]: —&gt; "three-year-long" [1 instance]—[[WP:HYPHEN]], sub-subsection 3, points 3 and 8</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9352">{{Orphan|date=September 2010}}

'''Structured derivations (SD)'''&lt;ref&gt;Ralph-Johan Back. Structured derivations: a unified proof style for teaching mathematics. Formal aspects of computing, vol. 22, n. 5, 2010, pp. 629&amp;ndash;661.&lt;/ref&gt; is a logic-based format for presenting mathematical solutions and proofs created by Prof.  [[Ralph-Johan Back]] and Joakim von Wright at [[Åbo Akademi University]], [[Turku]], [[Finland]]. The format was originally introduced as a way for presenting proofs in programming logic, but was later adapted to provide a practical approach to presenting proofs and derivations in mathematics education including exact formalisms. A structured derivation has a precise mathematical interpretation, and the syntax and the layout are precisely defined. The standardized syntax renders the format suitable for presenting and manipulating mathematics digitally.

SD is a further development of the calculational proof format introduced by [[Edsger W. Dijkstra]] and others in the early 1990s. In essence, three main extensions have been made. First, a mechanism for decomposing proofs through the use of subderivations has been added. The calculational approach is limited to writing proof fragments, and longer derivations are commonly decomposed into several separate subproofs. Using SD with subderivations, on the other hand, the presentation of a complete proof or solution is kept together, as subproofs can be presented exactly where they are needed. In addition, SD makes it possible to handle assumptions and observations in proofs. As such, the format can be seen as combining the benefits of the calculational style with the decomposition facilities of natural deduction.

==Examples==
The following three examples will be used to illustrate the most central features of structured derivations.

===A simple equation===
Solving a simple equation illustrates the basic structure of a structured derivation. The start of the solution is indicated by a bullet (&lt;math&gt;\bullet&lt;/math&gt;)  followed by the task we are to solve (in this case the equation &lt;math&gt;3x+6=16-x&lt;/math&gt;).
{|style="border:1px dashed #ddd;" cellspacing="20"
|-
| &lt;math&gt;\bullet&lt;/math&gt;  ||&lt;math&gt;3x+6=16-x&lt;/math&gt;
|-
| &lt;math&gt;\Leftrightarrow&lt;/math&gt;  ||{ Subtract 6 from both sides }
|-
|   || &lt;math&gt;3x+6-6=16-x-6&lt;/math&gt;
|-
|  &lt;math&gt;\Leftrightarrow&lt;/math&gt; ||{ Add x to both sides }
|-
|  ||&lt;math&gt;3x+6-6+x=16-x-6+x&lt;/math&gt;
|-
|  &lt;math&gt;\Leftrightarrow&lt;/math&gt;  ||{ Add similar terms }
|-
| || &lt;math&gt;4x=10&lt;/math&gt;
|-
|  &lt;math&gt;\Leftrightarrow&lt;/math&gt;  ||{ Divide both sides with 4 }
|-
| || &lt;math&gt;x=2.5&lt;/math&gt;
|-
| &lt;math&gt;\square&lt;/math&gt;||
|}

Each step in the solution consists of two terms, a relation and a justification that explains why the relationship between the two terms hold. The justifications are given equal amount of space as the mathematical terms in order to indicate the importance of explanations in mathematics.

===Assumptions and observations===
Specifications of mathematical problems commonly contain information that can be used in the solution. When writing a proof or a solution as a structured derivation, all known information is listed in the beginning as ''assumptions''. These assumptions can be used to create new information that will be useful for solving the problem. This information can be added as ''observations'' that build on the assumptions. The following example uses two assumptions ((a)&amp;ndash;(b)) and two observations ([1]&amp;ndash;[2]). The introductory part of the solution (the task, assumptions and observations) is separated from the proof part by the &lt;math&gt;\Vdash&lt;/math&gt;-symbol, denoting logical provability.

''Sea water, where the mass-volume percentage of salt is 4.0%, is vaporized in a pool until its mass has decreased by 28%. What is the concentration of salt after the vaporization?''

{|style="border:1px dashed #ddd;" cellspacing="20"
|-
| &lt;math&gt;\bullet&lt;/math&gt; || || Calculate the concentration of salt ''s'' after the vaporization when
|-
| (a) || || the original salt concentration was 4.0%
|-
| (b) || || the mass of seawater left after the vaporization is 28% less than the original mass ''m''.
|-
| [1] || || {The amount of salt after the vaporization is the same as originally (a), since only water is vaporized }
|-
| || || The amount of salt is &lt;math&gt;0.04m&lt;/math&gt;
|-
| [2] || || {According to (b) the remaining water mass is 72% (100%&amp;nbsp;&amp;minus;&amp;nbsp;28%) of the original mass }
|-
| || || The remaining water mass is &lt;math&gt;0.72m&lt;/math&gt;
|-
| &lt;math&gt;\Vdash&lt;/math&gt; || || s
|-
| &lt;math&gt;=&lt;/math&gt; || || { The salt concentration is the salt mass divided by the total mass }
|-
|   || || &lt;math&gt;\dfrac {0.04m}{0.72m}&lt;/math&gt;
|-
| &lt;math&gt;=&lt;/math&gt; || || { Simplify }
|-
| || || &lt;math&gt;\dfrac{1}{18}&lt;/math&gt;
|-
| &lt;math&gt;=&lt;/math&gt; || || { Calculate and convert to percentage }
|-
|&lt;math&gt;\approx&lt;/math&gt; || || &lt;math&gt; 5.6\%&lt;/math&gt;
|-
| &lt;math&gt;\square&lt;/math&gt;||||
|}

===Subderivations===
When solving a mathematical problem or constructing a proof, there is often a need to solve smaller problems in order to solve the entire problem. These subsolutions or subproofs are commonly written as fragments on the paper. SD introduces a mechanism for handling this type of subsolutions in a way that keeps these together with the remaining solution in one single chain. These ''subderivations'' are indented and the return to the original level is indicated with an ellipsis (&lt;math&gt;\ldots&lt;/math&gt;). The following example is the same as the one above; here, however, the information given as observations above is given in subderivations instead.

{|style="border:1px dashed #ddd;" cellspacing="20"
|-
| &lt;math&gt;\bullet&lt;/math&gt; || Calculate the concentration of salt ''s'' after the vaporization when
|-
| (a) || the original salt concentration was 4.0%
|-
| (b) || the mass of seawater left after the vaporization is 28% less than the original mass ''m''.
|-
| &lt;math&gt;\Vdash&lt;/math&gt; || s
|-
| &lt;math&gt;=&lt;/math&gt; || { The salt concentration is the salt mass divided by the total mass }
|-
| || &lt;math&gt;\dfrac{\text{salt mass}}{\text{total mass}}&lt;/math&gt; ||
|-
| &lt;math&gt;=&lt;/math&gt; || { Calculate salt mass }
|-
| || &lt;math&gt;\bullet&lt;/math&gt;    &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;        Salt mass
|-
| || &lt;math&gt;=&lt;/math&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; { The amount of salt after the vaporization is the same as originally (a), since only water is vaporized }
|-
| ||   &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&lt;math&gt;0.04m&lt;/math&gt;
|-
|&lt;math&gt;\ldots&lt;/math&gt; ||  &lt;math&gt;\dfrac{0.04m}{\text{total mass}}&lt;/math&gt;
|-
| &lt;math&gt;=&lt;/math&gt; || { Calculate total mass }
|-
| || &lt;math&gt;\bullet&lt;/math&gt;    &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;        Total mass
|-
| || &lt;math&gt;=&lt;/math&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; { According to (b) the remaining water mass is 28% less than the original mass  }
|-
| ||   &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&lt;math&gt;(100-28\%)\cdot m&lt;/math&gt;
|-
| || &lt;math&gt;=&lt;/math&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; { Simplify, 72%&amp;nbsp;=&amp;nbsp;0.72 }
|-
| ||   &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&lt;math&gt;0.72m&lt;/math&gt;
|-
|&lt;math&gt;\ldots&lt;/math&gt; ||  &lt;math&gt;\dfrac{0.04m}{0.72m}&lt;/math&gt;
|-
| &lt;math&gt;=&lt;/math&gt; || { Simplify }
|-
| ||  &lt;math&gt;\dfrac{1}{18}&lt;/math&gt;
|-
| &lt;math&gt;\approx&lt;/math&gt;|| { Calculate and convert to percentage }
|-
|  || &lt;math&gt; 5.6\%&lt;/math&gt;
|-
| &lt;math&gt;\square&lt;/math&gt;||
|}

==Teaching experience==
Starting in 2001, SD has been empirically evaluated at different education levels with students aged 15–24. The most extensive study so far was a three-year-long quasi experiment conducted at a Finnish high school, where the test  group was taught the compulsory mathematics courses using SD and the control group studied according to the traditional approach.&lt;ref&gt;Mia Peltomäki and Ralph-Johan Back. An Empirical Evaluation of Structured Derivations in High School Mathematics. In ICMI 19: 19th ICMI Study Conference on Proof and Proving in Mathematics Education, 2009.&lt;/ref&gt; The results indicate that the students in the test group performed better in all courses and the matriculation examination, even when potentially influencing factors have been taken into account. Other studies have indicated that students learn to justify their solutions during one single course &lt;ref&gt;Ralph-Johan Back, Linda Mannila, and Solveig Wallin. Student justifications in high-school mathematics. In CERME 6: Sixth Conference of European Research in Mathematics Education, Lyon, France, 2009.&lt;/ref&gt;&lt;ref&gt;Linda Mannila and Solveig Wallin. Promoting students’ justification skills using structured derivations. In ICMI 19: 19th ICMI Study Conference on Proof and Proving in Mathematics Education, Taiwan, May 2009.&lt;/ref&gt; and that students appreciate the new approach to writing mathematics.&lt;ref&gt;Ralph-Johan Back, Linda Mannila, and Solveig Wallin. "It takes me longer, but I understand better" &amp;ndash; Student feedback on structured derivations", International Journal of Mathematical Education in Science and Technology, Volume 41, Issue 5 January 2010 , pages 575&amp;ndash;593.&lt;/ref&gt;

==References==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

==External links==
* http://www.imped.fi

{{DEFAULTSORT:Structured Derivations}}
[[Category:Mathematics education]]</text>
      <sha1>lgxlywy220gv7ljjv857v976wy9u2ym</sha1>
    </revision>
  </page>
  <page>
    <title>Tree traversal</title>
    <ns>0</ns>
    <id>597584</id>
    <revision>
      <id>871262158</id>
      <parentid>871262122</parentid>
      <timestamp>2018-11-29T22:34:53Z</timestamp>
      <contributor>
        <ip>107.77.231.139</ip>
      </contributor>
      <comment>/* Pre-order */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17923">{{Redirect-distinguish|Tree search|Search tree}}
{{refimprove|date=May 2009}}
{{graph search algorithm}}

In [[computer science]], '''tree traversal''' (also known as '''tree search''') is a form of [[graph traversal]] and refers to the process of visiting (checking and/or updating) each node in a [[Tree (data structure)|tree data structure]], exactly once. Such traversals are classified by the order in which the nodes are visited. The following algorithms are described for a [[binary tree]], but they may be generalized to other trees as well.

==Types==
Unlike [[linked list]]s, one-dimensional [[Array data structure|arrays]] and other [[List of data structures#Linear data structures|linear data structures]], which are canonically traversed in linear order, trees may be traversed in multiple ways. They may be traversed in depth-first or breadth-first order. There are three common ways to traverse them in depth-first order: in-order, pre-order and post-order.&lt;ref name="holtenotes"&gt;{{cite web|url=http://webdocs.cs.ualberta.ca/~holte/T26/tree-traversal.html|title=Lecture 8, Tree Traversal|publisher=|accessdate=2 May 2015}}&lt;/ref&gt; Beyond these basic traversals, various more complex or hybrid schemes are possible, such as [[depth-limited search]]es like [[iterative deepening depth-first search]].

===Data structures for tree traversal===
{{Unreferenced section|date=October 2016}}
Traversing a tree involves iterating over all nodes in some manner. Because from a given node there is more than one possible next node (it is not a linear data structure), then, assuming sequential computation (not parallel), some nodes must be deferred—stored in some way for later visiting. This is often done via a [[Stack (abstract data type)|stack]] (LIFO) or [[Queue (abstract data type)|queue]] (FIFO). As a tree is a self-referential (recursively defined) data structure, traversal can be defined by [[recursion]] or, more subtly, [[corecursion]], in a very natural and clear fashion; in these cases the deferred nodes are stored implicitly in the [[call stack]].

Depth-first search is easily implemented via a stack, including recursively (via the call stack), while breadth-first search is easily implemented via a queue, including corecursively.

===Depth-first search===
{{main|Depth-first search}}
These searches are referred to as ''depth-first search'' (DFS), as the search tree is deepened as much as possible on each child before going to the next sibling. For a binary tree, they are defined as display operations recursively at each node, starting with the root, whose algorithm is as follows:&lt;ref&gt;http://www.cise.ufl.edu/~sahni/cop3530/slides/lec216.pdf&lt;/ref&gt;
&lt;ref&gt;{{cite web|url=http://www.programmerinterview.com/index.php/data-structures/preorder-traversal-algorithm/|title=Preorder Traversal Algorithm|publisher=|accessdate=2 May 2015}}&lt;/ref&gt;

The general recursive pattern for traversing a (non-empty) binary tree is this: At node N do the following:

(L) Recursively traverse its left subtree. This step is finished at the node N again.

(R) Recursively traverse its right subtree. This step is finished at the node N again.

(N) Process N itself.

These steps can be done ''&lt;u&gt;in any order&lt;/u&gt;''. If (L) is done before (R), the process is called left-to-right traversal, otherwise it is called right-to-left traversal. The following methods show left-to-right traversal:

====Pre-order (NLR)====
[[File:Sorted binary tree preorder.svg|thumb|Pre-order: F, B, A, D, C, E, G, I, H.]]
# Check if the current node is empty or null.
# Display the data part of the root (or current node).
# Traverse the left subtree by recursively calling the pre-order function.
#Traverse the right subtree by recursively calling the pre-order function.

{{clear}}

The pre-order traversal is a [[Topological_sorting|topologically sorted]] one, because a parent node is processed before any of its child nodes is done.

====In-order (LNR)====
[[File:Sorted binary tree inorder.svg|thumb|In-order: A, B, C, D, E, F, G, H, I.]]
# Check if the current node is empty or null.
# Traverse the left subtree by recursively calling the in-order function.
# Display the data part of the root (or current node).
# Traverse the right subtree by recursively calling the in-order function.

In a [[binary search tree]], in-order traversal retrieves data in sorted order.&lt;ref&gt;{{cite web |url=http://www.math.ucla.edu/~wittman/10b.1.10w/Lectures/Lec18.pdf |website=[[UCLA]] Math |last=Wittman |first=Todd |accessdate=January 2, 2016 |title=Tree Traversal |format=PDF |deadurl=yes |archiveurl=https://web.archive.org/web/20150213195803/http://www.math.ucla.edu/~wittman/10b.1.10w/Lectures/Lec18.pdf |archivedate=February 13, 2015 |df= }} &lt;/ref&gt;
{{clear}}

====Post-order (LRN)====
[[File:Sorted binary tree postorder.svg|thumb|Post-order: A, C, E, D, B, H, I, G, F.]]
# Check if the current node is empty or null.
# Traverse the left subtree by recursively calling the post-order function.
# Traverse the right subtree by recursively calling the post-order function.
# Display the data part of the root (or current node).

The trace of a traversal is called a sequentialisation of the tree. The traversal trace is a list of each visited root. No one sequentialisation according to pre-, in- or post-order describes the underlying tree uniquely. Given a tree with distinct elements, either pre-order or post-order paired with in-order is sufficient to describe the tree uniquely. However, pre-order with post-order leaves some ambiguity in the tree structure.&lt;ref&gt;{{cite web|url=http://cs.stackexchange.com/questions/439/which-combinations-of-pre-post-and-in-order-sequentialisation-are-unique|title=Algorithms, Which combinations of pre-, post- and in-order sequentialisation are unique?, Computer Science Stack Exchange|publisher=|accessdate=2 May 2015}}&lt;/ref&gt;
{{clear}}

====Generic tree====
To traverse any tree with depth-first search, perform the following operations recursively at each node:
# Perform pre-order operation.
# For each ''i'' from 1 to the number of children do:
## Visit ''i''-th, if present.
## Perform in-order operation.
# Perform post-order operation.
Depending on the problem at hand, the pre-order, in-order or post-order operations may be void, or you may only want to visit a specific child, so these operations are optional. Also, in practice more than one of pre-order, in-order and post-order operations may be required. For example, when inserting into a ternary tree, a pre-order operation is performed by comparing items. A post-order operation may be needed afterwards to re-balance the tree.

===Breadth-first search===
[[File:Sorted binary tree breadth-first traversal.svg|thumb|Level-order: F, B, G, A, D, I, C, E, H.]]
{{main|Breadth-first search}}
Trees can also be traversed in ''level-order'', where we visit every node on a level before going to a lower level. This search is referred to as ''breadth-first search'' (BFS), as the search tree is broadened as much as possible on each depth before going to the next depth.

===Other types===
There are also tree traversal algorithms that classify as neither depth-first search nor breadth-first search. One such algorithm is [[Monte Carlo tree search]], which concentrates on analyzing the most promising moves, basing the expansion of the [[search tree]] on [[Monte Carlo method|random sampling]] of the search space.

==Applications==
Pre-order traversal while duplicating nodes and edges can make a complete duplicate of a [[binary tree]]. It can also be used to make a prefix expression ([[Polish notation]]) from [[Parse tree|expression trees]]: traverse the expression tree pre-orderly.

In-order traversal is very commonly used on [[binary search tree]]s because it returns values from the underlying set in order, according to the comparator that set up the binary search tree (hence the name).

Post-order traversal while deleting or freeing nodes and values can delete or free an entire binary tree. It can also generate a [[Reverse Polish notation|postfix]] representation of a binary tree.

==Implementations==
{{unreferenced section|date=June 2013}}
===Depth-first search===
====Pre-order====
{|
|-valign="top"
|
 '''preorder'''(node)
   '''if''' (node = '''null''')
     '''return'''
   visit(node)
   preorder(node.left)
   preorder(node.right)
|
 '''iterativePreorder'''(node)
   '''if''' (node = '''null''')
     '''return'''
   s ← '''empty stack'''
   s.push(node)
   '''while''' ('''not''' s.isEmpty())
     node ← s.pop()
     visit(node)
     //right child is pushed first so that left is processed first
     '''if''' (node.right ≠ '''null''')
       s.push(node.right)
     '''if''' (node.left ≠ '''null''')
       s.push(node.left)
|}

====In-order====
{|
|-valign="top"
|
 '''inorder'''(node)
   '''if''' (node = '''null''')
     '''return'''
   inorder(node.left)
   visit(node)
   inorder(node.right)
|
 '''iterativeInorder'''(node)
   s ← '''empty stack'''
   '''while''' ('''not''' s.isEmpty() '''or''' node ≠ '''null''')
     '''if''' (node ≠ '''null''')
       s.push(node)
       node ← node.left
     '''else'''
       node ← s.pop()
       visit(node)
       node ← node.right
|}

====Post-order====
{|
|- style="vertical-align:top"
|
 '''postorder'''(node)
   '''if''' (node = '''null''')
     '''return'''
   postorder(node.left)
   postorder(node.right)
   visit(node)
|
 '''iterativePostorder'''(node)
   s ← '''empty stack'''
   lastNodeVisited ← '''null'''
   '''while''' ('''not''' s.isEmpty() '''or''' node ≠ '''null''')
     '''if''' (node ≠ '''null''')
       s.push(node)
       node ← node.left
     '''else'''
       peekNode ← s.peek()
       // if right child exists and traversing node
       // from left child, then move right
       '''if''' (peekNode.right ≠ '''null''' '''and''' lastNodeVisited ≠ peekNode.right)
         node ← peekNode.right
       '''else'''
         visit(peekNode)
         lastNodeVisited ← s.pop()
|}

All the above implementations require stack space proportional to the height of the tree which is a [[call stack]] for the recursive and a parent stack for the iterative ones. In a poorly balanced tree, this can be considerable. With the iterative implementations we can remove the stack requirement by maintaining parent pointers in each node, or by [[#Morris in-order traversal using threading|threading the tree]] (next section).

====Morris in-order traversal using threading====
{{main|Threaded binary tree}}
A binary tree is threaded by making every left child pointer (that would otherwise be null) point to the in-order predecessor of the node (if it exists) and every right child pointer (that would otherwise be null) point to the in-order successor of the node (if it exists).

Advantages:
# Avoids recursion, which uses a call stack and consumes memory and time.
# The node keeps a record of its parent.

Disadvantages:
# The tree is more complex.
# We can make only one traversal at a time.
# It is more prone to errors when both the children are not present and both values of nodes point to their ancestors.

Morris traversal is an implementation of in-order traversal that uses threading:&lt;ref&gt;{{Cite journal | doi = 10.1016/0020-0190(79)90068-1| title = Traversing binary trees simply and cheaply| journal = [[Information Processing Letters]]| volume = 9| issue = 5| year = 1979| last1 = Morris | first1 = Joseph M.}}&lt;/ref&gt;
# Create links to the in-order successor.
# Print the data using these links.
# Revert the changes to restore original tree.

===Breadth-first search===
Also, listed below is pseudocode for a simple [[queue (data structure)|queue]] based level-order traversal, and will require space proportional to the maximum number of nodes at a given depth. This can be as much as the total number of nodes / 2. A more space-efficient approach for this type of traversal can be implemented using an [[iterative deepening depth-first search]].

 '''levelorder'''(root)
   q ← '''empty queue'''
   q.enqueue(root)
   '''while''' ('''not''' q.isEmpty())
     node ← q.dequeue()
     visit(node)
     '''if''' (node.left ≠ '''null''')
       q.enqueue(node.left)
     '''if''' (node.right ≠ '''null''')
       q.enqueue(node.right)

==Infinite trees==
While traversal is usually done for trees with a finite number of nodes (and hence finite depth and finite [[branching factor]]) it can also be done for infinite trees. This is of particular interest in [[functional programming]] (particularly with [[lazy evaluation]]), as infinite data structures can often be easily defined and worked with, though they are not (strictly) evaluated, as this would take infinite time. Some finite trees are too large to represent explicitly, such as the [[game tree]] for [[chess]] or [[Go (game)|go]], and so it is useful to analyze them as if they were infinite.

A basic requirement for traversal is to visit every node eventually. For infinite trees, simple algorithms often fail this. For example, given a binary tree of infinite depth, a depth-first search will go down one side (by convention the left side) of the tree, never visiting the rest, and indeed a pre-order or post-order traversal will never visit ''any'' nodes, as it has not reached a leaf (and in fact never will). By contrast, a breadth-first (level-order) traversal will traverse a binary tree of infinite depth without problem, and indeed will traverse any tree with bounded branching factor.

On the other hand, given a tree of depth 2, where the root has infinitely many children, and each of these children has two children, a depth-first search will visit all nodes, as once it exhausts the grandchildren (children of children of one node), it will move on to the next (assuming it is not post-order, in which case it never reaches the root). By contrast, a breadth-first search will never reach the grandchildren, as it seeks to exhaust the children first.

A more sophisticated analysis of running time can be given via infinite [[ordinal number]]s; for example, the breadth-first search of the depth 2 tree above will take [[Ordinal number#Ordinals extend the natural numbers|ω]]·2 steps: ω for the first level, and then another ω for the second level.

Thus, simple depth-first or breadth-first searches do not traverse every infinite tree, and are not efficient on very large trees. However, hybrid methods can traverse any (countably) infinite tree, essentially via a [[Diagonal argument (disambiguation)|diagonal argument]] ("diagonal"—a combination of vertical and horizontal—corresponds to a combination of depth and breadth).

Concretely, given the infinitely branching tree of infinite depth, label the root (), the children of the root (1), (2), …, the grandchildren (1, 1), (1, 2), …, (2, 1), (2, 2), …, and so on. The nodes are thus in a [[bijection|one-to-one]] correspondence with finite (possibly empty) sequences of positive numbers, which are countable and can be placed in order first by sum of entries, and then by [[lexicographic order]] within a given sum (only finitely many sequences sum to a given value, so all entries are reached—formally there are a finite number of [[Composition (number theory)|compositions]] of a given natural number, specifically 2&lt;sup&gt;''n''−1&lt;/sup&gt; compositions of {{nowrap|1=''n'' ≥ 1}}), which gives a traversal. Explicitly:

 0: ()
 1: (1)
 2: (1, 1) (2)
 3: (1, 1, 1) (1, 2) (2, 1) (3)
 4: (1, 1, 1, 1) (1, 1, 2) (1, 2, 1) (1, 3) (2, 1, 1) (2, 2) (3, 1) (4)

etc.

This can be interpreted as mapping the infinite depth binary tree onto this tree and then applying breadth-first search: replace the "down" edges connecting a parent node to its second and later children with "right" edges from the first child to the second child, from the second child to the third child, etc. Thus at each step one can either go down (append a (, 1) to the end) or go right (add one to the last number) (except the root, which is extra and can only go down), which shows the correspondence between the infinite binary tree and the above numbering; the sum of the entries (minus one) corresponds to the distance from the root, which agrees with the 2&lt;sup&gt;''n''−1&lt;/sup&gt; nodes at depth {{nowrap|''n'' − 1}} in the infinite binary tree (2 corresponds to binary).

==References==
{{reflist}}
; General
* Dale, Nell. Lilly, Susan D. "Pascal Plus Data Structures". D. C. Heath and Company. Lexington, MA. 1995. Fourth Edition.
* Drozdek, Adam. "Data Structures and Algorithms in C++". Brook/Cole. Pacific Grove, CA. 2001. Second edition.
* http://www.math.northwestern.edu/~mlerma/courses/cs310-05s/notes/dm-treetran

==External links==
* [http://www.sitepoint.com/hierarchical-data-database/ Storing Hierarchical Data in a Database] with traversal examples in PHP
* [https://web.archive.org/web/20110606032941/http://dev.mysql.com/tech-resources/articles/hierarchical-data.html Managing Hierarchical Data in MySQL]
* [http://www.artfulsoftware.com/mysqlbook/sampler/mysqled1ch20.html Working with Graphs in MySQL]
* [http://code.google.com/p/treetraversal/ Sample code for recursive and iterative tree traversal implemented in C.]
* [http://arachnode.net/blogs/programming_challenges/archive/2009/09/25/recursive-tree-traversal-orders.aspx Sample code for recursive tree traversal in C#.]
* [http://rosettacode.org/wiki/Tree_traversal See tree traversal implemented in various programming language] on [[Rosetta Code]]
* [http://www.perlmonks.org/?node_id=600456 Tree traversal without recursion]

{{DEFAULTSORT:Tree Traversal}}
[[Category:Trees (data structures)]]
[[Category:Articles with example Haskell code]]
[[Category:Articles with example Java code]]
[[Category:Articles with example pseudocode]]
[[Category:Graph algorithms]]
[[Category:Recursion]]
[[Category:Iteration in programming]]

[[de:Binärbaum#Traversierung]]
[[ja:木構造 (データ構造)]]</text>
      <sha1>6x5cbitrqwj7zbmpwxbtebb612dzb8h</sha1>
    </revision>
  </page>
  <page>
    <title>Trivial Graph Format</title>
    <ns>0</ns>
    <id>19363223</id>
    <revision>
      <id>719697287</id>
      <parentid>692915317</parentid>
      <timestamp>2016-05-11T07:02:11Z</timestamp>
      <contributor>
        <username>Joey-das-WBF</username>
        <id>753209</id>
      </contributor>
      <minor/>
      <comment>Changed description of a link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1392">{{multiple issues|
{{Refimprove|date=October 2008}}
{{Notability|date=October 2008}}
}}

'''Trivial Graph Format''' ('''TGF''') is a simple text-based file format for describing [[Graph theory|graphs]].  It consists of a list of [[Vertex (graph theory)|node]] definitions, which map node IDs to labels, followed by a list of edges, which specify node pairs and an optional edge label.  Node IDs can be arbitrary identifiers, whereas labels for both nodes and edges are plain strings.

The graph may be interpreted as a directed or undirected graph.  For directed graphs, to specify the concept of bi-directionality in an edge, one may either specify two edges (forward and back) or differentiate the edge by means of a label.  For more powerful specification of graphs, see the other graph file formats below.

==Example==
A simple graph with 2 nodes and 1 edge might look like this:
&lt;pre&gt;
1 First node
2 Second node
#
1 2 Edge between the two
&lt;/pre&gt;

The # sign marks the end of the node list and the start of the edge list.

==See also==
*[[yEd]], a graph editor that can handle TGF file format.

==External links==
*[http://docs.yworks.com/yfiles/doc/developers-guide/tgf.html Using TGF in the yFiles Graph Drawing library]
*[http://reference.wolfram.com/mathematica/ref/format/TGF.html Using TGF in Wolfram Mathematica]


{{Graph representations}}
[[Category:Graph description languages]]</text>
      <sha1>endttdkjzz5ms85csz8g8u6kcz2thge</sha1>
    </revision>
  </page>
  <page>
    <title>Turing machine equivalents</title>
    <ns>0</ns>
    <id>6263864</id>
    <revision>
      <id>856201313</id>
      <parentid>851379794</parentid>
      <timestamp>2018-08-23T15:37:05Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Other equivalent machines and methods */[[User:JCW-CleanerBot#Logic|task]], replaced: Annals of Math → Annals of Mathematics (2), Annals of Mathematicsematics → Annals of Mathematics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18248">{{turing}}
A [[Turing machine]] is a hypothetical computing device, first conceived by [[Alan Turing]] in 1936. Turing machines manipulate symbols on a potentially infinite strip of tape according to a finite table of rules, and they provide the theoretical underpinnings for the notion of a computer algorithm.

While none of the following models have been shown to have more power than the single-tape, one-way infinite, multi-symbol Turing-machine model, their authors defined and used them to investigate questions and solve problems more easily than they could have if they had stayed with Turing's ''a''-machine model.

== Machines equivalent to the Turing machine model ==

'''Turing equivalence'''

Many machines that might be thought to have more computational capability than a simple universal Turing machine can be shown to have no more power.&lt;ref&gt;{{cite book|author = [[John Hopcroft]] and [[Jeffrey Ullman]] | year = 1979| title = Introduction to Automata Theory, Languages and Computation| publisher = Addison–Wesley, Reading Mass| edition = 1st | isbn = 0-201-02988-X}}&lt;/ref&gt; They might compute faster, perhaps, or use less memory, or their instruction set might be smaller, but they cannot compute more powerfully (i.e. more mathematical functions). (The [[Church–Turing thesis]] ''hypothesizes'' this to be true: that anything that can be “computed” can be computed by some Turing machine.)

'''The sequential-machine models'''

All of the following are called "sequential machine models" to distinguish them from "parallel machine models".&lt;ref name="Boas"&gt;[[Peter van Emde Boas]], ''Machine Models and Simulations''; [[Jan van Leeuwen]], ed. ''Handbook of Theoretical Computer Science. Volume A: Algorithms and Complexity'', p. 3-66, The MIT Press/Elsevier, 1990. {{ISBN|0-262-72014-0}} (volume A). QA76.H279 1990.&lt;/ref&gt;

== Tape-based Turing machines ==

'''Turing's ''a''-machine model'''

Turing's a-machine (as he called it) was left-ended, right-end-infinite. He provided symbols '''əə''' to mark the left end. Any of finite number of tape symbols were permitted. The instructions (if a universal machine), and the "input" and "out" were written only on "F-squares", and markers were to appear on "E-squares". In essence he divided his machine into two tapes that always moved together. The instructions appeared in a tabular form called "5-tuples" and were not executed sequentially.

=== Single-tape machines with restricted symbols and/or restricted instructions ===
The following models are single tape Turing machines but restricted with (i) restricted tape symbols { mark, blank }, and/or (ii) sequential, computer-like instructions, and/or (iii) machine-actions fully atomized.

==== Post's "Formulation 1" model of computation ====
{{details|Post–Turing machine}}

[[Emil Post]] in an independent description of a computational process, reduced the symbols allowed to the equivalent binary set of marks on the tape { "mark", "blank"=not_mark }. He changed the notion of "tape" from 1-way infinite to the right to an infinite set of rooms each with a sheet of paper in both directions. He atomized the Turing 5-tuples into 4-tuples—motion instructions separate from print/erase instructions. Although his 1936 model is ambiguous about this, Post's 1947 model did not require sequential instruction execution.

His extremely simple model can emulate any Turing machine, and although his 1936 ''Formulation 1'' does not use the word "program" or "machine", it is effectively a formulation of a very primitive programmable computer and associated [[programming language]], with the boxes acting as an unbounded bitstring memory, and the set of instructions constituting a program.

==== Wang machines ====
{{details|Wang B-machine}}

In an influential paper, [[Hao Wang (academic)|Hao Wang]] reduced Post's "[[Post–Turing machine#1936: Post model|formulation 1]]" to machines that still use a two-way infinite binary tape, but whose instructions are simpler — being the "atomic" components of Post's instructions — and are by default executed sequentially (like a "computer program").  His stated principal purpose was to offer, as an alternative to Turing's theory, one that "is more economical in the basic operations".  His results were "program formulations" of a variety of such machines, including the 5-instruction Wang W-machine with the instruction-set

: { SHIFT-LEFT, SHIFT-RIGHT, MARK-SQUARE, ERASE-SQUARE, JUMP-IF-SQUARE-MARKED-to xxx }

and his most-severely reduced 4-instruction [[Wang B-machine]] ("B" for "basic") with the instruction-set
 
: { SHIFT-LEFT, SHIFT-RIGHT, MARK-SQUARE, JUMP-IF-SQUARE-MARKED-to xxx }

which has not even an ERASE-SQUARE instruction.

Many authors later introduced variants of the machines discussed by Wang:

Minsky evolved Wang's notion with his version of the (multi-tape) "counter machine" model that allowed SHIFT-LEFT and SHIFT-RIGHT motion of the separate heads but no printing at all.&lt;ref name="Marvin" /&gt; In this case the tapes would be left-ended, each end marked with a single "mark" to indicate the end. He was able to reduce this to a single tape, but at the expense of introducing multi-tape-square motion equivalent to multiplication and division rather than the much simpler { SHIFT-LEFT = DECREMENT, SHIFT-RIGHT = INCREMENT }.

Davis, adding an explicit HALT instruction to one of the machines discussed by Wang, used a model with the instruction-set

: { SHIFT-LEFT, SHIFT-RIGHT, ERASE, MARK, JUMP-IF-SQUARE-MARKED-to xxx, JUMP-to xxx, HALT }

and also considered versions with tape-alphabets of size larger than 2.

====Böhm's theoretical machine language P"====
{{details|P"}}
In keeping with Wang's project to seek a Turing-equivalent theory "economical in the basic operations", and wishing to avoid unconditional jumps, a notable theoretical language is the 4-instruction language [[P"]] introduced by [[Corrado Böhm]] in 1964 — the first "GOTO-less" imperative "[[structured programming]]" language to be proved [[Turing-complete]].

=== Multi-tape Turing machines ===
{{details|Multitape Turing machine}}

In practical analysis, various types of multi-tape Turing machines are often used.  Multi-tape machines are similar to single-tape machines, but there is some constant ''k'' number of independent tapes.

===Deterministic and non-deterministic Turing machines===
{{details|non-deterministic Turing machine}}

If the action table has at most one entry for each combination of symbol and state then the machine is a "deterministic Turing machine" (DTM).  If the action table contains multiple entries for a combination of symbol and state then the machine is a "non-deterministic Turing machine" (NDTM). '''The two are computationally equivalent, that is, it is possible to turn any NDTM into a DTM (and ''vice versa'').''' This can be proved via construction.

=== Oblivious Turing machines ===

An oblivious Turing machine is a Turing machine where movement of the various heads are fixed functions of time, independent of the input.  In other words, there is a predetermined sequence in which the various tapes are scanned, advanced, and written to.  Pippenger and Fischer showed that any computation that can be performed by a multi-tape Turing machine in ''n'' steps can be performed by an oblivious two-tape Turing machine in {{tmath|O(n \log n)}} steps.&lt;ref&gt;{{Citation|first=Nicholas|last=Pippenger|authorlink=Nick Pippenger|first2=Michael J.|last2=Fischer|authorlink2=Michael J. Fischer|title=Relations Among Complexity Measures|journal=J ACM|year=1979|volume=26|issue=3|pages=361–381|doi=10.1145/322123.322138}}
&lt;/ref&gt;

== Register machine models ==
{{details|Register machine}}

[[Peter van Emde Boas]] includes all machines of this type in one class, "the register machine".&lt;ref name="Boas" /&gt; However, historically the literature has also called the most primitive member of this group i.e. "the counter machine" -- "the register machine". And the most primitive embodiment of a "counter machine" is sometimes called the "Minsky machine".

=== The "counter machine", also called a "register machine" model ===
{{details|Counter machine}}

The primitive model register machine is, in effect, a multitape 2-symbol Post–Turing machine with its behavior restricted so its tapes act like simple "counters".

By the time of Melzak, Lambek, and Minsky the notion of a "computer program" produced a different type of simple machine with many left-ended tapes cut from a Post–Turing tape. In all cases the models permit only two tape symbols { mark, blank }.&lt;ref name="Marvin" /&gt;

Some versions represent the positive integers as only a strings/stack of marks allowed in a "register" (i.e. left-ended tape), and a blank tape represented by the count "0". Minsky eliminated the PRINT instruction at the expense of providing his model with a mandatory single mark at the left-end of each tape.&lt;ref name="Marvin" /&gt;

In this model the single-ended tapes-as-registers are thought of as "counters", their instructions restricted to only two (or three if the TEST/DECREMENT instruction is atomized). Two common instruction sets are the following:
:(1): { INC ( r ), DEC ( r ), JZ ( r,z ) }, i.e.
::{ INCrement contents of register #r; DECrement contents of register #r; IF contents of #r=Zero THEN Jump-to Instruction #z}
:(2): { CLR ( r ); INC ( r ); JE ( r&lt;sub&gt;i&lt;/sub&gt;, r&lt;sub&gt;j&lt;/sub&gt;, z ) }, i.e.
::{ CLeaR contents of register r; INCrement contents of r; compare contents of r&lt;sub&gt;i&lt;/sub&gt; to r&lt;sub&gt;j&lt;/sub&gt; and if Equal then Jump to instruction z}

Although his model is more complicated than this simple description, the Melzak "pebble" model extended this notion of "counter" to permit multi-
pebble adds and subtracts.

=== The random-access machine (RAM) model ===
{{details|Random-access machine}}
 
Melzak recognized a couple serious defects in his register/counter-machine model:&lt;ref&gt;[[Z. A. Melzak]], ''An informal Arithmetical Approach to Computability and Computation'', Canadian Mathematical Bulletin, vol. 4, no. 3. September 1961 pages 279-293.&lt;/ref&gt; (i) Without a form of indirect addressing he would not be able to "easily" show the model is [[Turing completeness|Turing equivalent]], (ii) The program and registers were in different "spaces", so self-modifying programs would not be easy. When Melzak added indirect addressing to his model he created a random access machine model.

(However, with [[Gödel numbering]] of the instructions Minsky offered a proof that with such numbering the general [[recursion (computer science)|recursive function]]s were indeed possible; he offers proof that [[μ recursion]] is indeed possible&lt;ref name="Marvin"&gt;[[Marvin Minsky]], ''Computation: Finite and Infinite Machines'', Prentice–Hall, Inc., N.J., 1967. See Chapter 8, Section 8.2 "Unsolvability of the Halting Problem."&lt;/ref&gt;).

Unlike the RASP model, the RAM model does not allow the machine's actions to modify its instructions. Sometimes the model works only register-to-register with no accumulator, but most models seem to include an accumulator.

van Emde Boas divides the various RAM models into a number of sub-types:&lt;ref name="Boas" /&gt;
* SRAM, the "successor RAM" with only one arithmetic instruction, the successor (INCREMENT h). The others include "CLEAR h", and an IF equality-between-register THEN jump-to xxx.
* RAM: the standard model with addition and subtraction
* MRAM: the RAM agumented with multiplication and division
* BRAM, MBRAM: Bitwise Boolean versions of the RAM  and MRAM
* N****: Non-deterministic versions of any of the above with an N before the name

=== The random-access stored program (RASP) machine model ===
{{details|Random-access stored-program machine}}

The RASP is a RAM with the instructions stored together with their data in the same 'space' -- i.e. sequence of registers. The notion of a RASP was described at least as early as Kiphengst. His model had a "mill"—an accumulator, but now the instructions were in the registers with the data—the so-called [[von Neumann architecture]]. When the RASP has alternating even and odd registers—the even holding the "operation code" (instruction) and the odd holding its "operand" (parameter), then indirect addressing is achieved by simply modifying an instruction's operand.&lt;ref&gt;[[Stephen Cook|Stephen A. Cook]] and Robert A. Reckhow (1972), ''Time-bounded random access machines'', Journal of Computer Systems Science 7 (1973), 354-375.&lt;/ref&gt;

The original RASP model of Elgot and Robinson had only three instructions in the fashion of the register-machine model,&lt;ref&gt;[[Calvin Elgot]] and [[Abraham Robinson]] (1964), ''Random-Access Stored-Program Machines, an Approach to Programming Languages'', Journal of the Association for Computing Machinery, Vol. 11, No. 4 (October, 1964), pp. 365-399.&lt;/ref&gt; but they placed them in the register space together with their data. (Here COPY takes the place of CLEAR when one register e.g. "z" or "0" starts with and always contains 0. This trick is not unusual. The unit 1 in register "unit" or "1" is also useful.) 
: { INC ( r ), COPY ( r&lt;sub&gt;i&lt;/sub&gt;, r&lt;sub&gt;j&lt;/sub&gt; ),  JE ( r&lt;sub&gt;i&lt;/sub&gt;, r&lt;sub&gt;i&lt;/sub&gt;, z ) }

The RASP models allow indirect as well as direct-addressing; some allow "immediate" instructions too, e.g. "Load accumulator with the constant 3". The instructions may be of a highly restricted set such as the following 16 instructions of Hartmanis.&lt;ref&gt;[[J. Hartmanis]] (1971), "Computational Complexity of Random Access Stored Program Machines," Mathematical Systems Theory 5, 3 (1971) pp. 232-245.&lt;/ref&gt; This model uses an accumulator A. The mnemonics are those that the authors used (their CLA is "load accumulator" with constant or from register; STO is "store accumulator"). Their syntax is the following, excepting the jumps: "n, &lt;n&gt;, &lt;&lt;n&gt;&gt;" for "immediate", "direct" and "indirect"). Jumps are via two "Transfer instructions" TRA—unconditional jump by directly "n" or indirectly "&lt; n &gt;" jamming contents of register n into the instruction counter, TRZ (conditional jump if Accumulator is zero in the same manner as TRA): 
:{ ADD n , ADD &lt; n &gt;, ADD &lt;&lt; n &gt;&gt;, SUB n, SUB &lt; n &gt;, SUB &lt;&lt; n &gt;&gt;, CLA n, CLA &lt; n &gt;, CLA &lt;&lt; n &gt;&gt;, STO &lt; n &gt;, STO &lt;&lt; n &gt;&gt;, TRA n, TRA &lt; n &gt;, TRZ n, TRA &lt; n &gt;, HALT }

=== The Pointer machine model ===
{{details|Pointer machine}}

A relative late-comer is Schönhage's Storage Modification Machine or [[pointer machine]]. Another version is the Kolmogorov-Uspensii machine, and the Knuth "linking automaton" proposal. (For references see [[pointer machine]]). Like a state-machine diagram, a node emits at least two labelled "edges" (arrows) that point to another node or nodes which in turn point to other nodes, etc. The outside world points at the center node.

==Machines with input and output==
Any of the above tape-based machines can be equipped with input and output tapes; any of the above register-based machines can be equipped with dedicated input and output registers. For example, the Schönhage pointer-machine model has two instructions called "''input'' ''λ''&lt;sub&gt;0&lt;/sub&gt;,''λ''&lt;sub&gt;1&lt;/sub&gt;" and "''output'' ''β''".

It is difficult to study [[sublinear]] [[space complexity]] on multi-tape machines with the traditional model, because an input of size ''n'' already takes up space ''n''.  Thus, to study small [[DSPACE]] classes, we must use a different model.  In some sense, if we never "write to" the input tape, we don't want to charge ourself for this space.  And if we never "read from" our output tape, we don't want to charge ourself for this space.

We solve this problem by introducing a ''k''-string Turing machine with input and output.  This is the same as an ordinary ''k''-string Turing machine, except that the transition function {{mvar|&amp;delta;}} is restricted so that the input tape can never be changed, and so that the output head can never move left.  This model allows us to define deterministic space classes smaller than linear.  Turing machines with input-and-output also have the same time complexity as other Turing machines; in the words of Papadimitriou 1994 Prop 2.2:

:For any ''k''-string Turing machine ''M'' operating within time bound {{tmath|f(n)}} there is a {{tmath|(k+2)}}-string Turing machine ''M''’ with input and output, which operates within time bound {{tmath|O(f(n))}}.

''k''-string Turing machines with input and output can be used in the formal definition of the complexity resource [[DSPACE]].&lt;ref&gt;{{cite book|author = [[Christos Papadimitriou]] | year = 1993 | title = Computational Complexity | publisher = Addison Wesley | edition = 1st | isbn = 0-201-53082-1}} Chapter 2: Turing machines, pp.&amp;nbsp;19–56.&lt;/ref&gt;

== Other equivalent machines and methods ==

* Multidimensional Turing machine: For example, a model by Schönhage uses the four head-movement commands { '''N'''orth, '''S'''outh, '''E'''ast, '''W'''est }.&lt;ref name="Schonage80"&gt;A. [[Schōnhage]] (1980), ''Storage Modification Machines'', Society for Industrial and Applied Mathematics, SIAM J. Comput. Vol. 9, No. 3, August 1980.&lt;/ref&gt;
* Single-tape, multi-head Turing machine: In an undecidability proof of the "problem of tag", Minsky and Shepherdson and Sturgis described machines with a single tape that could write along the tape with one head and read further along the tape with another.&lt;ref&gt;{{cite journal|author=[[Marvin Minsky]]
 |title=Recursive Unsolvability of Post's Problem of 'Tag' and Other Topics in Theory of Turing Machines
 |journal=Annals of Mathematics
 |date=1961, received August 15, 1960
 |volume=74
 |pages=437&amp;ndash;455
 |doi=10.2307/1970290|issue=3|publisher=Annals of Mathematics|jstor=1970290
}}&lt;/ref&gt;&lt;ref&gt;[[John C. Shepherdson]] and [[H. E. Sturgis]] received December 1961 ''Computability of Recursive Functions'', Journal of the Association of Computing Machinery (JACM) 10:217-255, 1963&lt;/ref&gt;  
 
* [[Markov algorithm]] is another remarkably simple computational model, based on string rewriting, equivalent to the Turing machines.
* [[Lambda calculus]]
* [[Queue automaton]]

== References ==
{{reflist}}

{{DEFAULTSORT:Turing Machine Equivalents}}
[[Category:Turing machine]]
[[Category:Theory of computation]]
[[Category:Models of computation]]</text>
      <sha1>c4zwlkilx0czzuf3jlnfeftq3g8bo8l</sha1>
    </revision>
  </page>
  <page>
    <title>Undecidable problem</title>
    <ns>0</ns>
    <id>15631055</id>
    <revision>
      <id>860377968</id>
      <parentid>860350581</parentid>
      <timestamp>2018-09-20T07:51:18Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Partially undid revision 860350581 by [[Special:Contributions/Tsmackinlay|Tsmackinlay]] ([[User talk:Tsmackinlay|talk]]) for clarification: for the layman, "impossible" may mean that one do not know any algorithm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11863">In [[computability theory]] and [[computational complexity theory]], an '''undecidable problem''' is a [[decision problem]] for which it is proved to be impossible to construct an [[algorithm]] that always leads to a correct yes-or-no answer. The [[halting problem]] is an example: there is no algorithm that correctly determines whether arbitrary programs eventually halt when run. 

== Background ==
A decision problem is any arbitrary yes-or-no question on an infinite set of inputs.  Because of this, it is traditional to define the decision problem equivalently as the set of inputs for which the problem returns ''yes''. These inputs can be natural numbers, but also other values of some other kind, such as [[string (computer science)|string]]s of a [[formal language]]. Using some encoding, such as a [[Gödel numbering]], the strings can be encoded as natural numbers.  Thus, a decision problem informally phrased in terms of a formal language is also equivalent to a set of [[natural numbers]].  To keep the formal definition simple, it is phrased in terms of subsets of the natural numbers.

Formally, a decision problem is a subset of the natural numbers. The corresponding informal problem is that of deciding whether a given number is in the set. A decision problem ''A'' is called decidable or effectively solvable if ''A'' is a [[recursive set]]. A problem is called partially decidable, '''semi-decidable''', solvable, or provable if ''A'' is a [[recursively enumerable set]]. This means that there exists an algorithm that halts eventually when the answer is ''yes'' but may run for ever if the answer is ''no''. Partially decidable problems and any other problems that are not decidable are called undecidable.

==Example: the halting problem in computability theory==
In [[computability theory]], the [[halting problem]] is a [[decision problem]] which can be stated as follows:

:Given the description of an arbitrary [[computer program|program]] and a finite input, decide whether the program finishes running or will run forever.

[[Alan Turing]] proved in 1936 that a general [[algorithm]] running on a [[Turing machine]] that solves the halting problem for ''all'' possible program-input pairs necessarily cannot exist. Hence, the halting problem is ''undecidable'' for Turing machines.

==Relationship with Gödel's incompleteness theorem==
The concepts raised by [[Gödel's incompleteness theorem]]s are very similar to those raised by the halting problem, and the proofs are quite similar. In fact, a weaker form of the First Incompleteness Theorem is an easy consequence of the undecidability of the halting problem. This weaker form differs from the standard statement of the incompleteness theorem by asserting that a complete, [[Consistency proof|consistent]] and [[Soundness|sound]] [[axiomatization]] of all statements about natural numbers is unachievable. The "sound" part is the weakening: it means that we require the axiomatic system in question to prove only ''true'' statements about natural numbers. It is important to observe that the statement of the standard form of Gödel's First Incompleteness Theorem is completely unconcerned with the question of truth, but only concerns the issue of whether it can be [[mathematical proof|proven]].

The weaker form of the theorem can be proved from the undecidability of the halting problem as follows. Assume that we have a consistent and complete [[axiomatization]] of all true [[first-order logic]] statements about [[natural number]]s. Then we can build an algorithm that enumerates all these statements. This means that there is an algorithm ''N''(''n'') that, given a natural number ''n'', computes a true first-order logic statement about natural numbers such that, for all the true statements, there is at least one ''n'' such that ''N''(''n'') yields that statement. Now suppose we want to decide if the algorithm with representation ''a'' halts on input ''i''.  We know that this statement can be expressed with a first-order logic statement, say ''H''(''a'', ''i'').  Since the axiomatization is complete it follows that either there is an ''n'' such that ''N''(''n'') =  ''H''(''a'', ''i'') or there is an ''n&amp;#39;'' such that ''N''(''n&amp;#39;'') = ¬ ''H''(''a'', ''i'').  So if we [[iterate]] over all ''n'' until we either find ''H''(''a'', ''i'') or its negation, we will always halt. This means that this gives us an algorithm to decide the halting problem. Since we know that there cannot be such an algorithm, it follows that the assumption that there is a consistent and complete axiomatization of all true first-order logic statements about natural numbers must be false.

==Examples of undecidable problems==
{{main|List of undecidable problems}}
Undecidable problems can be related to different topics, such as [[logic]], [[abstract machine]]s or [[topology]]. Note that since there are [[uncountable set|uncountably]] many undecidable problems, any list, even one of [[countably infinite|infinite length]], is necessarily incomplete.

==Examples of undecidable statements==
{{See also|List of statements independent of ZFC|Independence (mathematical logic)}}

There are two distinct senses of the word "undecidable" in contemporary use. The first of these is the sense used in relation to Gödel's theorems, that of a statement being neither provable nor refutable in a specified [[deductive system]]. The second sense is used in relation to [[computability theory]] and applies not to statements but to [[decision problem]]s, which are countably infinite sets of questions each requiring a yes or no answer. Such a problem is said to be undecidable if there is no [[computable function]] that correctly answers every question in the problem set.  The connection between these two is that if a decision problem is undecidable (in the recursion theoretical sense) then there is no consistent, effective [[formal system]] which proves for every question ''A'' in the problem either "the answer to ''A'' is yes" or "the answer to ''A'' is no".

Because of the two meanings of the word undecidable, the term [[independence (mathematical logic)|independent]] is sometimes used instead of undecidable for the "neither provable nor refutable" sense. The usage of "independent" is also ambiguous, however. It can mean just "not provable", leaving open whether an independent statement might be refuted.

Undecidability of a statement in a particular deductive system does not, in and of itself, address the question of whether the [[truth value]] of the statement is well-defined, or whether it can be determined by other means. Undecidability only implies that the particular deductive system being considered does not prove the truth or falsity of the statement. Whether there exist so-called "absolutely undecidable" statements, whose truth value can never be known or is ill-specified, is a controversial point among various [[philosophy of mathematics|philosophical schools]].

One of the first problems suspected to be undecidable, in the second sense of the term, was the [[word problem for groups]], first posed by [[Max Dehn]] in 1911, which asks if there is a finitely presented [[group (mathematics)|group]] for which no algorithm exists to determine whether two words are equivalent.  This was shown to be the case in 1952.

The combined work of Gödel and [[Paul Cohen (mathematician)|Paul Cohen]] has given two concrete examples of undecidable statements (in the first sense of the term): The [[continuum hypothesis]] can neither be proved nor refuted in [[ZFC]] (the standard axiomatization of [[set theory]]), and the [[axiom of choice]] can neither be proved nor refuted in [[Zermelo-Fraenkel set theory|ZF]] (which is all the ZFC axioms ''except'' the axiom of choice).  These results do not require the incompleteness theorem.   Gödel proved in 1940 that neither of these statements could be disproved in ZF or ZFC set theory. In the 1960s, Cohen proved that neither is provable from ZF, and the continuum hypothesis cannot be proven from ZFC.

In 1970, Russian mathematician [[Yuri Matiyasevich]] showed that [[Hilbert's tenth problem|Hilbert's Tenth Problem]], posed in 1900 as a challenge to the next century of mathematicians, cannot be solved.    Hilbert's challenge sought an algorithm which finds all solutions of a [[Diophantine equation]].  A Diophantine equation is a more general case of [[Fermat's Last Theorem]]; we seek the [[integer number|integer root]]s of a [[polynomial]] in any number of variables with integer coefficients.  Since we have only one equation but ''n'' variables, infinitely many solutions exist (and are easy to find) in the [[complex plane]]; however, the problem becomes impossible if solutions are constrained to integer values only.  Matiyasevich showed this problem to be unsolvable by mapping a Diophantine equation to a [[recursively enumerable set]] and invoking Gödel's Incompleteness Theorem.&lt;ref&gt;{{cite journal| last=Matiyasevich | first=Yuri | authorlink=Yuri Matiyasevich | year=1970 | script-title=ru:Диофантовость перечислимых множеств |trans-title=Enumerable sets are Diophantine | journal=[[Doklady Akademii Nauk SSSR]] | volume=191 | pages=279–282 | language=Russian}}&lt;/ref&gt;

In 1936, [[Alan Turing]] proved that the [[halting problem]]—the question of whether or not a [[Turing machine]] halts on a given program—is undecidable, in the second sense of the term. This result was later generalized by [[Rice's theorem]].

In 1973, [[Saharon Shelah]] showed the [[Whitehead problem]] in [[group theory]] is undecidable, in the first sense of the term, in standard set theory.

In 1977, Paris and Harrington proved that the [[Paris-Harrington theorem|Paris-Harrington principle]], a version of the [[Ramsey theorem]], is undecidable in the axiomatization of arithmetic given by the Peano axioms but can be proven to be true in the larger system of [[second-order arithmetic]].

[[Kruskal's tree theorem]], which has applications in computer science, is also undecidable from the Peano axioms but provable in set theory. In fact Kruskal's tree theorem (or its finite form) is undecidable in a much stronger system codifying the principles acceptable on basis of a philosophy of mathematics called predicativism.

[[Goodstein's theorem]] is a statement about the [[Ramsey theory]] of the natural numbers that Kirby and Paris showed is undecidable in Peano arithmetic.

[[Gregory Chaitin]] produced undecidable statements in [[algorithmic information theory]] and proved another incompleteness theorem in that setting. Chaitin's theorem states that for any theory that can represent enough arithmetic, there is an upper bound ''c'' such that no specific number can be proven in that theory to have [[Kolmogorov complexity]] greater than ''c''. While Gödel's theorem is related to the [[liar paradox]], Chaitin's result is related to [[Berry's paradox]].

In 2007, researchers Kurtz and Simon, building on earlier work by [[John Horton Conway|J.H. Conway]] in the 1970s, proved that a natural generalization of the [[Collatz problem]] is undecidable.&lt;ref&gt;Kurtz, Stuart A.; Simon, Janos, [https://books.google.com/books?id=mhrOkx-xyJIC&amp;lpg=PA542&amp;dq=Kurtz%20collatz%20problem&amp;pg=PA542#v=onepage&amp;q=&amp;f=false "The Undecidability of the. Generalized Collatz Problem"], in Proceedings of the 4th International Conference on Theory and Applications of Models of Computation, TAMC 2007, held in Shanghai, China in May 2007. {{isbn|3-540-72503-2}}. {{doi|10.1007/978-3-540-72504-6_49}}&lt;/ref&gt;

==See also==
* [[Decidability (logic)]]
* [[Entscheidungsproblem]]
* [[Proof of impossibility]]
* [[Wicked problem]]

==References==
&lt;references responsive="0" /&gt;

[[Category:Logic in computer science]]
[[Category:Computability theory]]
[[Category:Undecidable problems| ]]</text>
      <sha1>es1uqv07g9yz8ayk5tzyvo914doch3m</sha1>
    </revision>
  </page>
  <page>
    <title>Universally measurable set</title>
    <ns>0</ns>
    <id>2231292</id>
    <revision>
      <id>858042707</id>
      <parentid>742692344</parentid>
      <timestamp>2018-09-04T18:16:04Z</timestamp>
      <contributor>
        <ip>148.252.128.246</ip>
      </contributor>
      <comment>/* Example contrasting with Lebesgue measurability */   Followed Tashiro's suggestion for fix, and tried to make other paragraph easier to understand.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4761">In [[mathematics]], a [[subset]] &lt;math&gt;A&lt;/math&gt; of a [[Polish space]] &lt;math&gt;X&lt;/math&gt; is '''universally measurable''' if it is [[measurable set|measurable]] with respect to every [[complete measure|complete]] [[probability measure]] on &lt;math&gt;X&lt;/math&gt; that measures all [[Borel set|Borel]] subsets of &lt;math&gt;X&lt;/math&gt;.  In particular, a universally measurable set of [[real number|real]]s is necessarily [[Lebesgue measurable]] (see [[#Finiteness condition]] below).

Every [[analytic set]] is universally measurable.  It follows from [[projective determinacy]], which in turn follows from sufficient [[large cardinal]]s, that every [[projective set]] is universally measurable.

==Finiteness condition==
The condition that the measure be a [[probability measure]]; that is, that the measure of &lt;math&gt;X&lt;/math&gt; itself be 1, is less restrictive than it may appear. For example, Lebesgue measure on the reals is not a probability measure, yet every universally measurable set is Lebesgue measurable. To see this, divide the real line into countably many intervals of length 1; say, ''N''&lt;sub&gt;0&lt;/sub&gt;=&lt;nowiki&gt;[0,1)&lt;/nowiki&gt;, ''N''&lt;sub&gt;1&lt;/sub&gt;=&lt;nowiki&gt;[1,2)&lt;/nowiki&gt;, ''N''&lt;sub&gt;2&lt;/sub&gt;=&lt;nowiki&gt;[-1,0)&lt;/nowiki&gt;, ''N''&lt;sub&gt;3&lt;/sub&gt;=&lt;nowiki&gt;[2,3)&lt;/nowiki&gt;, ''N''&lt;sub&gt;4&lt;/sub&gt;=&lt;nowiki&gt;[-2,-1)&lt;/nowiki&gt;, and so on. Now letting &amp;mu; be Lebesgue measure, define a new measure &amp;nu; by
: &lt;math&gt;\nu(A)=\sum_{i=0}^\infty \frac{1}{2^{n+1}}\mu(A\cap N_i)&lt;/math&gt;
Then easily &amp;nu; is a probability measure on the reals, and a set is &amp;nu;-measurable if and only if it is Lebesgue measurable. More generally a universally measurable set must be measurable with respect to every [[sigma-finite]] measure that measures all Borel sets.

== Example contrasting with Lebesgue measurability ==
Suppose &lt;math&gt;A&lt;/math&gt; is a subset of [[Cantor space]] &lt;math&gt;2^\omega&lt;/math&gt;; that is, &lt;math&gt;A&lt;/math&gt; is a set of infinite [[sequence]]s of zeroes and ones.  By putting a binary point before such a sequence, the sequence can be viewed as a [[real number]] between 0 and 1 (inclusive), with some unimportant ambiguity.  Thus we can think of &lt;math&gt;A&lt;/math&gt; as a subset of the interval &lt;nowiki&gt;[0,1]&lt;/nowiki&gt;, and evaluate its [[Lebesgue measure]], if that is defined.  That value  is sometimes called the '''coin-flipping measure''' of &lt;math&gt;A&lt;/math&gt;, because it is the [[probability]] of producing a sequence of heads and tails that is an element of &lt;math&gt;A&lt;/math&gt; upon flipping a fair coin infinitely many times.

Now it follows from the [[axiom of choice]] that there are some such &lt;math&gt;A&lt;/math&gt; without a well-defined Lebesgue measure (or coin-flipping measure).  That is, for such an &lt;math&gt;A&lt;/math&gt;, the probability that the sequence of flips of a fair coin will wind up in &lt;math&gt;A&lt;/math&gt; is not well-defined.  This is a pathological property of &lt;math&gt;A&lt;/math&gt; that says that &lt;math&gt;A&lt;/math&gt; is "very complicated" or "ill-behaved".

From such a set &lt;math&gt;A&lt;/math&gt;, form a new set &lt;math&gt;A'&lt;/math&gt; by performing the following operation on each sequence in &lt;math&gt;A&lt;/math&gt;:  Intersperse a 0 at every even position in the sequence, moving the other bits to make room.  Although &lt;math&gt;A'&lt;/math&gt; is not intuitively any "simpler" or "better-behaved" than &lt;math&gt;A&lt;/math&gt;, the probability that the sequence of flips of a fair coin will be in &lt;math&gt;A'&lt;/math&gt; is well-defined. Indeed, to be in &lt;math&gt;A'&lt;/math&gt;, the coin must come up tails on every even-numbered flip, which happens with probability zero.

However &lt;math&gt;A'&lt;/math&gt; is ''not'' universally measurable. To see that, we can test it against a ''biased'' coin that always comes up tails on even-numbered flips, and is fair on odd-numbered flips. For a set of sequences to be ''universally'' measurable, an arbitrarily ''biased'' coin may be used (even one that can "remember" the sequence of flips that has gone before) and the probability that the sequence of its flips ends up in the set must be well-defined. However, when &lt;math&gt;A'&lt;/math&gt; is tested by the coin we mentioned (the one  that always comes up tails on even-numbered flips, and is fair on odd-numbered flips), the propability to hit &lt;math&gt;A'&lt;/math&gt; is not well defined (for the same reason why &lt;math&gt;A&lt;/math&gt; cannot be tested by the fair coin). Thus the &lt;math&gt;A'&lt;/math&gt; is ''not'' universally measurable.

== References ==
* {{citation
 | author = Alexander Kechris 
 | title = Classical Descriptive Set Theory
 | publisher = Springer
 | series = Graduate Texts in Mathematics
 | volume = 156
 | year = 1995
 | isbn = 0-387-94374-9
}}
* {{citation
 |  author = Nishiura Togo 
 | title = Absolute Measurable Spaces 
 | publisher= Cambridge University Press
 | year= 2008
 | isbn =  0-521-87556-0
}}

[[Category:Descriptive set theory]]
[[Category:Determinacy]]
[[Category:Measure theory]]</text>
      <sha1>2orkd6hw9f9zum28v393ln4gh06rvy8</sha1>
    </revision>
  </page>
  <page>
    <title>Vincent's theorem</title>
    <ns>0</ns>
    <id>35623596</id>
    <revision>
      <id>871363951</id>
      <parentid>871361269</parentid>
      <timestamp>2018-11-30T15:31:45Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Essay-like}} {{Technical}} {{Coi}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="63427">{{multiple issues|
{{coi|date=November 2018}}
{{essay-like|date=November 2018}}
{{technical|date=November 2018}}
}}
In mathematics, '''Vincent's theorem'''—named after [[Alexandre Joseph Hidulphe Vincent]]—is a theorem that isolates the real roots of polynomials with rational coefficients.

Even though Vincent's theorem is the basis of the fastest method for the isolation of the real roots of polynomials, it was almost totally forgotten, having been overshadowed by [[Sturm's theorem]]; consequently, it does not appear in any of the classical books on the theory of equations (of the 20th century), except for [[J. V. Uspensky|Uspensky]]'s book. Two variants of this theorem are presented, along with several (continued fractions and bisection) real root isolation methods derived from them.

==Sign variation==
:Let ''c''&lt;sub&gt;0&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt;, ''c''&lt;sub&gt;2&lt;/sub&gt;, ... be a finite or infinite sequence of real numbers. Suppose ''l'' &lt; ''r'' and the following conditions hold:
# If ''r'' = ''l''+1 the numbers ''c&lt;sub&gt;l&lt;/sub&gt;'' and ''c&lt;sub&gt;r&lt;/sub&gt;'' have opposite signs.
# If ''r'' ≥ ''l''+2 the numbers ''c''&lt;sub&gt;''l''+1&lt;/sub&gt;, ..., ''c''&lt;sub&gt;''r''−1&lt;/sub&gt; are all zero and the numbers ''c&lt;sub&gt;l&lt;/sub&gt;'' and ''c&lt;sub&gt;r&lt;/sub&gt;'' have opposite signs.
: This is called a ''sign variation'' or ''sign change'' between the numbers ''c&lt;sub&gt;l&lt;/sub&gt;'' and ''c&lt;sub&gt;r&lt;/sub&gt;''. 
: When dealing with the polynomial ''p''(''x'') in one variable, one defines the number of '''sign variations of ''p''(''x'')''' as the number of sign variations in the sequence of its coefficients.

Two versions of this theorem are presented: the ''[[continued fractions]]'' version due to Vincent,&lt;ref name="paper_18342"&gt;{{cite journal|last=Vincent|first=Alexandre Joseph Hidulphe|year=1834|title=Mémoire sur la résolution des équations numériques|url=http://gallica.bnf.fr/ark:/12148/bpt6k57787134/f4.image.r=Agence%20Rol.langEN|journal=Mémoires de la Société Royale des Sciences, de l' Agriculture et des Arts, de Lille|pages=1–34}}&lt;/ref&gt;&lt;ref name="paper_18362"&gt;{{cite journal|last=Vincent|first=Alexandre Joseph Hidulphe|date=|year=1836|title=Note sur la résolution des équations numériques|url=http://sites.mathdoc.fr/JMPA/PDF/JMPA_1836_1_1_A28_0.pdf|journal=Journal de Mathématiques Pures et Appliquées|volume=1|pages=341–372|via=}}&lt;/ref&gt;&lt;ref name="paper_18382"&gt;{{cite journal|last=Vincent|first=Alexandre Joseph Hidulphe|year=1838|title=Addition à une précédente note relative à la résolution des équations numériques|url=http://math-doc.ujf-grenoble.fr/JMPA/PDF/JMPA_1838_1_3_A19_0.pdf|journal=Journal de Mathématiques Pures et Appliquées|volume=3|pages=235–243}}&lt;/ref&gt;  and the ''[[Bisection method|bisection]]'' version due to Alesina and Galuzzi.&lt;ref name=AG_1998&gt;{{cite journal|last=Alesina|first=Alberto|author2=Massimo Galuzzi |title=A new proof of Vincent's theorem|url=http://retro.seals.ch/cntmng?type=pdf&amp;rid=ensmat-001:1998:44::149&amp;subp=hires|journal=L'Enseignement Mathématique|year=1998|volume=44|number=3-4|pages=219–256}}&lt;/ref&gt;&lt;ref name=AG_2000&gt;{{cite journal|last=Alesina|first=Alberto|author2=Massimo Galuzzi |title=Vincent's Theorem from a Modern Point of View|url=http://inf-server.inf.uth.gr/~akritas/Alessina_Galuzzi_b.pdf|journal=Categorical Studies in Italy 2000, Rendiconti del Circolo Matematico di Palermo, Serie II, n. 64|year=2000|pages=179–191}}&lt;/ref&gt;

This statement of the ''[[continued fractions]]'' version can be found also in the Wikipedia article [[Budan's theorem#Vincent's theorem (1834 and 1836)|Budan's theorem]].

===Vincent's theorem: Continued fractions version (1834 and 1836)===
If in a polynomial equation with rational coefficients and without multiple roots, one makes successive transformations of the form

: &lt;math&gt;x = a_1 + \frac{1}{x'},\quad x' = a_2 + \frac{1}{x''},\quad x'' = a_3 + \frac{1}{x'''}, \ldots&lt;/math&gt;

where &lt;math&gt;a_1, a_2, a_3,\ldots &lt;/math&gt; are any positive numbers greater than or equal to one, then after a number of such transformations, the resulting transformed equation either has zero [[Vincent's theorem#Sign variation|sign variation]]s or it has a single [[Vincent's theorem#Sign variation|sign variation]]. In the first case there is no root, whereas in the second case there is a single positive real root. Furthermore, the corresponding root of the proposed equation is approximated by the finite continued fraction:&lt;ref name="paper_18342" /&gt;&lt;ref name="paper_18362" /&gt;&lt;ref name="paper_18382" /&gt;

: &lt;math&gt;a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3 + \cfrac{1}{\ddots}}} &lt;/math&gt;

Moreover, if infinitely many numbers &lt;math&gt;a_1, a_2, a_3,\ldots &lt;/math&gt; satisfying this property can be found, then the root is represented by the (infinite) corresponding continued fraction.

The above statement is an exact translation of the theorem found in Vincent's original papers;&lt;ref name="paper_18342" /&gt;&lt;ref name="paper_18362" /&gt;&lt;ref name="paper_18382" /&gt; however, the following remarks are needed for a clearer understanding:
*If &lt;math&gt;f_n(x)&lt;/math&gt; denotes the polynomial obtained after ''n'' substitutions (and after removing the denominator), then there exists ''N'' such that for all &lt;math&gt;n\ge N&lt;/math&gt; either &lt;math&gt;f_n(x)&lt;/math&gt; has no sign variation or it has one sign variation. In the latter case &lt;math&gt;f_n(x)&lt;/math&gt; has a single positive real root for all &lt;math&gt;n\ge N&lt;/math&gt;.
* The continued fraction represents a positive root of the original equation, and the original equation may have more than one positive root. Moreover, assuming &lt;math&gt;a_1 \ge 1&lt;/math&gt;, we can only obtain a root of the original equation that is &gt; 1. To obtain an arbitrary positive root we need to assume that &lt;math&gt;a_1 \ge 0&lt;/math&gt;.
* Negative roots are obtained by replacing ''x'' by −''x'', in which case the negative roots become positive.

===Vincent's theorem: Bisection version (Alesina and Galuzzi 2000)===
Let ''p''(''x'') be a real polynomial of degree deg(''p'') that has only simple roots. It is possible to determine a positive quantity δ so that for every pair of positive real numbers ''a'', ''b'' with &lt;math&gt;|b-a| &lt; \delta&lt;/math&gt;, every transformed polynomial of the form

{{NumBlk|:|&lt;math&gt;f(x) = (1+x)^{\deg(p)}p \left (\frac{a+bx}{1+x} \right )&lt;/math&gt;|{{EquationRef|1}}}}

has exactly 0 or 1 [[Vincent's theorem#Sign variation|sign variation]]s. The second case is possible if and only if  ''p''(''x'') has a single root within (''a'', ''b'').

====The Alesina–Galuzzi "a_b roots test"====

From equation ({{EquationNote|1}}) the following criterion is obtained for determining whether a polynomial has any roots in the interval (''a'', ''b''):

Perform on ''p''(''x'') the substitution

:&lt;math&gt;x \leftarrow \frac{a+bx}{1+x} &lt;/math&gt;

and count the number of [[Vincent's theorem#Sign variation|sign variations]] in the sequence of coefficients of the transformed polynomial; this number gives an ''upper bound'' on the number of real roots ''p''(''x'') has inside the open interval (''a'', ''b''). More precisely, the number ''ρ''&lt;sub&gt;''ab''&lt;/sub&gt;(''p'') of real roots in the open interval (''a'', ''b'')—multiplicities counted—of the polynomial ''p''(''x'') in '''R'''[''x''], of degree deg(''p''), is bounded above by the number of [[Vincent's theorem#Sign variation|sign variations]] ''var''&lt;sub&gt;''ab''&lt;/sub&gt;(''p''), where

:&lt;math&gt;\operatorname{var}_{ab}(p) = \operatorname{var} \left ((1+x)^{\deg(p)}p\left (\frac{a+bx}{1+x} \right ) \right ),&lt;/math&gt;
:&lt;math&gt;\operatorname{var}_{ab}(p) = \operatorname{var}_{ba}(p) \ge \rho_{ab}(p).&lt;/math&gt;

As in the case of [[Descartes' rule of signs]] if var&lt;sub&gt;''ab''&lt;/sub&gt;(''p'') = 0 it follows that ρ&lt;sub&gt;''ab''&lt;/sub&gt;(''p'') = 0 and if var&lt;sub&gt;''ab''&lt;/sub&gt;(''p'') = 1 it follows that ρ&lt;sub&gt;''ab''&lt;/sub&gt;(''p'') = 1.

A special case of the Alesina–Galuzzi '''"a_b roots test"''' is [[Budan's theorem#Early applications of Budan's theorem|Budan's '''"0_1 roots test"''']].

===Sketch of a proof===
A detailed discussion of Vincent's theorem, its extension, the geometrical interpretation of the transformations involved and three different proofs can be found in the work by Alesina and Galuzzi.&lt;ref name="AG_1998"/&gt;&lt;ref name="AG_2000"/&gt; A fourth proof is due to [[Alexander Ostrowski|Ostrowski]]&lt;ref name=O_1950&gt;{{cite journal |last=Ostrowski|first=A. M.|title=Note on Vincent's theorem|jstor=10.2307/1969443|journal=Annals of Mathematics | series = Second Series |year=1950 |volume=52 |number=3|pages=702–707 |doi=10.2307/1969443}}&lt;/ref&gt; who rediscovered a special case of a theorem stated by [[Nikola Obreshkov|Obreschkoff]],&lt;ref name=Obr_1920&gt;{{cite book |last=Obreschkoff |first=Nikola|title=Verteilung und Berechnung der Nullstellen reeller Polynome|publisher=[[VEB Deutscher Verlag der Wissenschaften]] |year=1963 |location=Berlin}}&lt;/ref&gt; p.&amp;nbsp;81, in 1920–1923.

To prove (both versions of) Vincent's theorem Alesina and Galuzzi show that after a series of transformations mentioned in the theorem, a polynomial with one positive root eventually has one sign variation. To show this, they use the following corollary to the theorem by [[Nikola Obreshkov|Obreschkoff]] of 1920–1923 mentioned earlier; that is, the following corollary gives the necessary conditions under which a polynomial with one positive root has exactly one sign variation in the sequence of its coefficients; see also the corresponding figure.

:'''Corollary.''' ([[Nikola Obreshkov|Obreschkoff]]'s cone or sector theorem, 1920–1923&lt;ref name="Obr_1920"/&gt; p.&amp;nbsp;81): If a real polynomial has one simple root {{math|''x''&lt;sub&gt;0&lt;/sub&gt;}}, and all other (possibly multiple) roots lie in the sector
::&lt;math&gt;S_{\sqrt{3}}= \left \{x = -\alpha+i\beta \ : \  |\beta| \le \sqrt{3} |\alpha|, \alpha&gt;0 \right \}&lt;/math&gt;
:then the sequence of its coefficients has exactly one sign variation.

[[File:Sketch of proof.jpg|thumb|x220px|center|[[Nikola Obreshkov|Obreschkoff]]'s &lt;math&gt;S_{\sqrt{3}}&lt;/math&gt; sector and his famous eight-shaped figure (of circles).]]

Consider now the [[Möbius transformation]] 
:&lt;math&gt;M(x)=\frac{ax+b}{cx+d}, \qquad a,b,c,d \in \mathbb{Z}_{&gt;0}&lt;/math&gt; 
and the three circles shown in the corresponding figure; assume that {{math|&amp;thinsp;{{sfrac|''a''|''c''}} &lt; {{sfrac|''b''|''d''}}.}}

*The (yellow) circle 
::&lt;math&gt;\left |x-\tfrac{1}{2}\left(\tfrac{a}{c} + \tfrac{b}{d} \right ) \right |=\tfrac{1}{2}\left (\tfrac{b}{d} - \tfrac{a}{c} \right )&lt;/math&gt; 
:whose diameter lies on the real axis, with endpoints {{math|{{sfrac|''a''|''c''}} }} and {{math|{{sfrac|''b''|''d''}},}} is mapped by the inverse Möbius transformation 
::&lt;math&gt;M^{-1}(x)=\frac{dx-b}{-cx+a}&lt;/math&gt; 
:onto the imaginary axis. For example the point 
::&lt;math&gt;\tfrac{1}{2}\left(\tfrac{a}{c} + \tfrac{b}{d} \right )+\tfrac{i}{2}\left (\tfrac{b}{d} - \tfrac{a}{c} \right )&lt;/math&gt; 
:gets mapped onto the point {{math|−''i''&amp;thinsp;{{sfrac|''d''|''c''}}.}} The exterior points get mapped onto the half-plane with {{math|Re(''x'') &lt; 0}}.

*The two circles (only their blue crescents are visible) with center 
::&lt;math&gt;\tfrac{1}{2}\left(\tfrac{a}{c} + \tfrac{b}{d} \right ) \pm \tfrac{i}{2\sqrt{3}} \left (\tfrac{b}{d} - \tfrac{a}{c} \right )&lt;/math&gt; 
:and radius 
::&lt;math&gt;\tfrac{1}{\sqrt{3}} \left ( \tfrac{b}{d}-\tfrac{a}{c} \right )&lt;/math&gt; 
:are mapped by the inverse Möbius transformation 
::&lt;math&gt;M^{-1}(x)=\frac{dx-b}{-cx+a}&lt;/math&gt; 
:onto the lines {{math|Im(''x'') {{=}} ±{{sqrt|3}} Re(''x'')}}. For example the point 
::&lt;math&gt;\tfrac{1}{2} \left(\tfrac{a}{c} + \tfrac{b}{d} \right )-\tfrac{3i}{2\sqrt{3}} \left (\tfrac{b}{d} - \tfrac{a}{c} \right )&lt;/math&gt; 
:gets mapped to the point 
::&lt;math&gt;\tfrac{-d}{2c}\left (1-i\sqrt{3} \right ).&lt;/math&gt;
:The exterior points (those outside the eight-shaped figure) get mapped onto the &lt;math&gt;S_{\sqrt{3}}&lt;/math&gt; sector.

From the above it becomes obvious that if a polynomial has a single positive root inside the eight-shaped figure and all other roots are outside of it, it presents one sign variation in the sequence of its coefficients. This also guarantees the termination of the process.

==Historical background==

===Early applications of Vincent's theorem===
In his fundamental papers,&lt;ref name="paper_18342" /&gt;&lt;ref name="paper_18362" /&gt;&lt;ref name="paper_18382" /&gt; Vincent presented examples that show precisely how to use his theorem to [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|isolate real roots]] of polynomials with [[continued fractions]]. However the resulting method had [[Exponential time#Exponential time|exponential]] computing time, a fact that mathematicians must have realized then, as was realized by [[J. V. Uspensky|Uspensky]]&lt;ref name=Uspensky&gt;{{cite book|last=Uspensky|first=James Victor|title=Theory of Equations|year=1948|publisher=McGraw–Hill Book Company|location=New York|url=http://www.google.com/search?q=uspensky+theory+of+equations&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1}}&lt;/ref&gt; p.&amp;nbsp;136, a century later.

[[File:Vincent method.jpg|thumb|Vincent's search for a root (applying Budan's theorem)|right|450px]]

The [[Exponential time#Exponential time|exponential]] nature of Vincent's algorithm is due to the way the partial [[Continued fractions#Notations for continued fractions|quotient]]s ''a&lt;sub&gt;i&lt;/sub&gt;'' (in [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]]) are computed. That is, to compute each partial [[Continued fractions#Notations for continued fractions|quotient]] ''a&lt;sub&gt;i&lt;/sub&gt;'' (that is,  to locate where the roots lie on the ''x''-axis) Vincent uses [[Budan's theorem]] as a [[Budan's theorem#Early applications of Budan's theorem|"no roots test"]]; in other words, to find the integer part of a root Vincent performs successive substitutions of the form ''x'' ← ''x''+1 and stops only when the polynomials ''p''(''x'') and ''p''(''x''+1) differ in the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of their coefficients (i.e. when the number of [[Vincent's theorem#Sign variation|sign variation]]s of ''p''(''x''+1) is decreased).

See the corresponding diagram where the root lies in the interval (5, 6). It can be easily inferred that, if the root is far away from the origin, it takes a lot of time to find its integer part this way, hence the [[Exponential time#Exponential time|exponential]] nature of Vincent's method. [[Vincent's theorem#Vincent–Akritas–Strzeboński (VAS, 2005)|Below]] there is an explanation of how this drawback is overcome.

===Disappearance of Vincent's theorem===
Vincent was the last author in the 19th century to use his theorem for the [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|isolation of the real roots]] of a polynomial.

The reason for that was the appearance of [[Budan's theorem#Disappearance of Budan's theorem|Sturm's theorem]] in 1827, which solved the [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|real root isolation problem]] in [[Exponential time#Polynomial time|polynomial]] time, by defining the precise number of real roots a polynomial has in a  real open interval (''a'', ''b''). The resulting (Sturm's) method for computing the real roots of polynomials has been the only one widely known and used ever since—up to about 1980, when it was replaced (in almost all [[computer algebra system]]s) by [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|methods derived from Vincent's theorem]], the fastest one being the [[Vincent's theorem#Vincent–Akritas–Strzeboński (VAS, 2005)|Vincent–Akritas–Strzeboński]] (VAS) method.&lt;ref name=VAS&gt;{{cite journal|last=Akritas|first=Alkiviadis G. |author2=A.W. Strzeboński |author3=P.S. Vigklas|title=Improving the performance of the continued fractions method using new bounds of positive roots|journal=Nonlinear Analysis: Modelling and Control|year=2008|volume=13|pages=265–279|url=http://www.lana.lt/journal/30/Akritas.pdf}}&lt;/ref&gt;

Serret included in his Algebra,&lt;ref name=Serret&gt;{{cite book|last=Serret|first=Joseph A.|title=Cours d'algèbre supérieure. Tome I|year=1877|publisher=Gauthier-Villars|url=https://archive.org/details/coursdalgbresu01serruoft}}&lt;/ref&gt; pp 363–368, [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]] along with its proof and directed all interested readers to Vincent's papers for examples on how it is used. Serret was the last author to mention [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]] in the 19th century.

===Comeback of Vincent's theorem===
In the 20th century [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]] cannot be found in any of the theory of equations books; the only exceptions are the books by [[J. V. Uspensky|Uspensky]]&lt;ref name="Uspensky"/&gt; and [[Nikola Obreshkov|Obreschkoff]],&lt;ref name="Obr_1920"/&gt; where in the second there is just the statement of the theorem.

It was in [[J. V. Uspensky|Uspensky]]'s book&lt;ref name="Uspensky"/&gt; that Akritas found [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]] and made it the topic of his Ph.D. Thesis "Vincent's Theorem in Algebraic Manipulation", [[North Carolina State University|North Carolina State University, USA]], 1978.  A major achievement at the time was getting hold of Vincent's original paper of 1836, something that had eluded [[J. V. Uspensky|Uspensky]]—resulting thus in a [[Budan's theorem#Uspensky's implementation of Vincent's theorem|great misunderstanding]].  Vincent's original paper of 1836 was made available to Akritas through the commendable efforts (interlibrary loan) of a librarian in the Library of the [[University of Wisconsin–Madison|University of Wisconsin–Madison, USA]].

==Real root isolation methods derived from Vincent's theorem==
'''Isolation of the real roots''' of a polynomial is the process of finding open disjoint intervals such that each contains exactly one real root and every real root is contained in some interval. According to the French school of mathematics of the 19th century, this is the first step in computing the real roots, the second being their '''approximation''' to any degree of accuracy; moreover, the focus is on the '''positive''' roots, because to isolate the '''negative''' roots of the polynomial ''p''(''x'') replace ''x'' by −''x'' (''x'' ← −''x'') and repeat the process.

The [[continued fractions]] version of [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]] can be used to isolate the positive roots of a given polynomial ''p''(''x'') of degree deg(''p''). To see this, represent by the [[Möbius transformation]] 
:&lt;math&gt;M(x)=\frac{ax+b}{cx+d}, \qquad a,b,c,d \in \mathbb{N}&lt;/math&gt; 
the continued fraction that leads to a transformed polynomial {{NumBlk|:|&lt;math&gt;f(x) = (cx+d)^{\deg(p)}p \left (\frac{ax+b}{cx+d} \right )&lt;/math&gt;|{{EquationRef|2}}}} with one [[Vincent's theorem#Sign variation|sign variation]]  in the sequence of its coefficients. Then, the single positive root of ''f''(''x'') (in the interval (0, ∞)) corresponds to ''that'' positive root of ''p''(''x'') that is in the open interval with endpoints &lt;math&gt;\frac{b}{d}&lt;/math&gt; and &lt;math&gt;\frac{a}{c}&lt;/math&gt;. These endpoints are ''not'' ordered and correspond to ''M''(0) and ''M''(∞) respectively.

Therefore, to isolate the positive roots of a polynomial, all that must be done is to compute—for ''each'' root—the variables ''a'', ''b'', ''c'', ''d'' of the corresponding [[Möbius transformation]] 
:&lt;math&gt;M(x)=\frac{ax+b}{cx+d}&lt;/math&gt; 
that leads to a transformed polynomial as in equation ({{EquationNote|2}}), with one [[Vincent's theorem#Sign variation|sign variation]] in the sequence of its coefficients.

'''Crucial Observation:''' The variables ''a'', ''b'', ''c'', ''d'' of a [[Möbius transformation]] 
:&lt;math&gt;M(x)=\frac{ax+b}{cx+d}&lt;/math&gt; 
(in [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]]) leading to a transformed polynomial—as in equation ({{EquationNote|2}})—with one [[Vincent's theorem#Sign variation|sign variation]] in the sequence of its coefficients can be computed:
*either by ''[[continued fractions]]'', leading to the ''[[Vincent's theorem#Vincent–Akritas–Strzeboński (VAS, 2005)|Vincent–Akritas–Strzebonski (VAS)]]'' continued fractions method,&lt;ref name="VAS"/&gt;
*or by ''[[Bisection method|bisection]]'', leading to (among others) the ''[[Vincent's theorem#Vincent–Collins–Akritas (VCA, 1976)|Vincent–Collins–Akritas (VCA)]]'' bisection method.&lt;ref name=CA&gt;{{cite book|last=Collins|first=George E.|author2=Alkiviadis G. Akritas |title =Polynomial Real Root Isolation Using Descartes' Rule of Signs|year = 1976|pages=272–275|series = SYMSAC '76, Proceedings of the third ACM symposium on Symbolic and algebraic computation|publisher = ACM|location = Yorktown Heights, NY, USA|url=http://doi.acm.org/10.1145/800205.806346}}&lt;/ref&gt;

The "bisection part" of this all important observation appeared as a special [[Vincent's theorem#Vincent's theorem: Bisection version (Alesina and Galuzzi 2000)|theorem]] in the papers by Alesina and Galuzzi.&lt;ref name="AG_1998"/&gt;&lt;ref name="AG_2000"/&gt;

All methods described below (see the article on [[Budan's theorem]] for their historical background) need to compute (once) an upper bound, ''ub'', on the values of the positive roots of the polynomial under consideration. Exception is the [[Vincent's theorem#Vincent–Akritas–Strzeboński (VAS, 2005)|VAS]] method where additionally lower bounds, ''lb'', must be computed at almost every cycle of the main loop. To compute the lower bound ''lb'' of the polynomial ''p''(''x'') compute the upper bound ''ub'' of the polynomial &lt;math&gt;x^{\deg(p)}p\left (\frac{1}{x} \right )&lt;/math&gt; and set &lt;math&gt;lb = \frac{1}{ub}&lt;/math&gt;.

Excellent (upper and lower) bounds on the values of just the positive roots of polynomials have been developed by Akritas, Strzeboński and Vigklas based on previous work by Doru Stefanescu. They are described in P. S. Vigklas' Ph.D. Thesis&lt;ref name="Panos"&gt;{{cite book|url=http://www.e-ce.uth.gr/wp-content/uploads/formidable/phd_thesis_vigklas.pdf|title=Upper bounds on the values of the positive roots of polynomials|last=Vigklas|first=Panagiotis, S.|publisher=Ph. D. Thesis, University of Thessaly, Greece|year=2010}}&lt;/ref&gt; and elsewhere.&lt;ref name=bounds&gt;{{cite journal|last=Akritas|first=Alkiviadis, G.|title=Linear and Quadratic Complexity Bounds on the Values of the Positive Roots of Polynomials|journal=Journal of Universal Computer Science|year=2009|volume=15|number=3 |pages=523–537 | url=http://www.jucs.org/jucs_15_3/linear_and_quadratic_complexity}}&lt;/ref&gt; These bounds have already been implemented in the [[computer algebra system]]s  [[Mathematica]], [[SageMath]], [[SymPy]], [[Xcas]] etc.

All three methods described below follow the excellent presentation of François Boulier,&lt;ref name=FB&gt;{{cite book|last=Boulier|first=François|title=Systèmes polynomiaux : que signifie " résoudre " ?|url=http://www.lifl.fr/~boulier/polycopies/resoudre.pdf|year=2010|publisher=Université Lille 1}}&lt;/ref&gt; p.&amp;nbsp;24.

==Continued fractions method==
Only one [[continued fractions]] method derives from [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]]. As stated [[Vincent's theorem#Early applications of Vincent's theorem|above]], it started in the 1830s when Vincent presented, in the papers&lt;ref name="paper_18342" /&gt;&lt;ref name="paper_18362" /&gt;&lt;ref name="paper_18382" /&gt; several examples that show how to use his theorem to [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|isolate the real roots]] of polynomials with [[continued fractions]]. However the resulting method had [[Exponential time#Exponential time|exponential]] computing time. Below is an explanation of how this method evolved.

===Vincent–Akritas–Strzeboński (VAS, 2005)===
This is the second method (after [[Vincent's theorem#Vincent–Collins–Akritas (VCA, 1976)|VCA]]) developed to handle the [[Exponential time#Exponential time|exponential]] behavior of Vincent's method.

The VAS continued fractions method is a ''direct'' implementation of Vincent's theorem. It was originally presented by Vincent from 1834 to 1938 in the papers &lt;ref name="paper_18342" /&gt;&lt;ref name="paper_18362" /&gt;&lt;ref name="paper_18382" /&gt; in a exponential form; namely, Vincent computed each partial [[Continued fractions#Notations for continued fractions|quotient]] ''a&lt;sub&gt;i&lt;/sub&gt;'' by a series of ''unit'' increments ''a&lt;sub&gt;i&lt;/sub&gt;'' ← ''a&lt;sub&gt;i&lt;/sub&gt;'' + 1, which are equivalent to substitutions of the form ''x'' ← ''x'' + 1.

Vincent's method was converted into its [[Exponential time#Polynomial time|polynomial]] complexity form by Akritas, who in his 1978 Ph.D. Thesis (''Vincent's theorem in algebraic manipulation'', North Carolina State University, USA) computed each partial [[Continued fractions#Notations for continued fractions|quotient]] ''a&lt;sub&gt;i&lt;/sub&gt;'' as the lower bound, ''lb'', on the values of the positive roots of a polynomial. This is called the ''ideal'' positive lower root bound that computes the integer part of the smallest positive root (see the corresponding figure). To wit, now set ''a&lt;sub&gt;i&lt;/sub&gt;'' ← ''lb'' or, equivalently, perform the substitution ''x'' ← ''x'' + ''lb'', which takes about the same time as the substitution ''x'' ← ''x'' + 1.

[[File:VAS method example.jpg|x220px|thumb|center|VAS searching for a root: The ''ideal'' lower bound is 5, hence ''x'' ← ''x'' + 5.]]

Finally, since the ideal positive lower root bound does not exist, Strzeboński&lt;ref name=AS&gt;{{cite journal|last=Akritas|first=Alkiviadis G.|author2=Adam W. Strzeboński |title=A Comparative Study of Two Real Root Isolation Methods|journal=Nonlinear Analysis: Modelling and Control|year=2005|volume=10|number=4|pages=297–304|url=http://www.lana.lt/journal/19/Akritas.pdf}}&lt;/ref&gt; introduced in 2005 the substitution &lt;math&gt;x \leftarrow lb_{computed}*x&lt;/math&gt;, whenever &lt;math&gt;lb_{computed}&gt;16&lt;/math&gt;; in general &lt;math&gt;lb &gt; lb_{computed}&lt;/math&gt; and the value 16 was determined experimentally. Moreover, it has been shown&lt;ref name="AS"/&gt; that the VAS ([[continued fractions]]) method is faster than the fastest implementation of the VCA (bisection) method,&lt;ref name=RZ&gt;{{cite journal |last=Rouillier |first=F.|author2=P. Zimmerman |title=Efficient isolation of polynomial's real roots|journal=Journal of Computational and Applied Mathematics| volume=162| pages=33–50| year=2004| url=http://dl.acm.org/citation.cfm?id=972166| doi=10.1016/j.cam.2003.08.015}}&lt;/ref&gt; a fact that was confirmed&lt;ref name=TE&gt;{{cite journal|last=Tsigaridas, P.E.|author2=I.Z. Emiris|title=Univariate polynomial real root isolation: Continued fractions revisited |journal=LNCS |year=2006 |volume=4168 |pages=817–828| url=http://www.springerlink.com/content/c70468755x403481/ |doi=10.1007/11841036_72|arxiv=cs/0604066}}&lt;/ref&gt; independently; more precisely, for the Mignotte polynomials of high degree VAS is about 50,000 times faster than the fastest implementation of VCA.

In 2007, Sharma&lt;ref name=VS&gt;{{cite book|last=Sharma|first=Vikram|title=Complexity Analysis of Algorithms in Algebraic Computation| year=2007| publisher=Ph.D. Thesis, Courant Institute of Mathematical Sciences, New York University,USA|url=http://www.cs.nyu.edu/web/Research/Theses/sharma_vikram.pdf}}&lt;/ref&gt; removed the hypothesis of the ideal positive lower bound and proved that VAS is still [[Exponential time#Polynomial time|polynomial]] in time.

VAS is the default algorithm for root isolation in [[Mathematica]], [[SageMath]], [[SymPy]], [[Xcas]].

For a comparison between Sturm's method and VAS use the functions realroot(poly) and time(realroot(poly)) of [[Xcas]]. By default, to isolate the real roots of poly realroot uses the VAS method; to use Sturm's method write realroot(sturm, poly). See also the [[Vincent's theorem#External links|External links]] for an application by A. Berkakis for Android devices that does the same thing.

Here is how VAS(''p'', ''M'') works, where for simplicity Strzeboński's contribution is not included: 
*Let ''p''(''x'') be  a polynomial of degree deg(''p'') such that ''p''(0) ≠ 0. To isolate its positive roots, associate with ''p''(''x'') the [[Möbius transformation]] ''M''(''x'') = ''x'' and repeat the following steps while there are pairs {''p''(''x''), ''M''(''x'')} to be processed.
*Use [[Descartes' rule of signs]] on ''p''(''x'') to compute, if possible, (using the number ''var'' of [[Vincent's theorem#Sign variation|sign variations]] in the sequence of its coefficients) the number of its roots inside the interval (0, ∞). If there are no roots return the empty set, ∅ whereas if there is one root return the interval (''a'', ''b''), where ''a'' = min(''M''(0), ''M''(∞)), and ''b'' = max(''M''(0), ''M''(∞)); if ''b'' = ∞ set ''b'' = ''ub'', where ''ub'' is an upper bound on the values of the positive roots of ''p''(''x'').&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt;
*If there are two or more sign variations [[Descartes' rule of signs]] implies that there may be zero, one or more real roots inside the interval (0, ∞); in this case consider separately the roots of ''p''(''x'') that lie inside the interval (0, 1) from those inside the interval (1, ∞). A special test must be made for 1.
**To guarantee that there are roots inside the interval (0, 1) the ideal lower bound, ''lb'' is used; that is the integer part of the smallest positive root is computed with the help of the lower bound,&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt; &lt;math&gt;lb_{computed} &lt;/math&gt;, on the values of the positive roots of ''p''(''x''). If &lt;math&gt;lb_{computed}&gt;1 &lt;/math&gt;, the substitution &lt;math&gt;x \leftarrow x+lb_{computed}&lt;/math&gt; is performed to ''p''(''x'') and ''M''(''x''), whereas if &lt;math&gt;lb_{computed} \le 1&lt;/math&gt; use substitution(s) ''x'' ← ''x''+1 to find the integer part of the root(s).
**To compute the roots inside the interval (0, 1) perform the substitution &lt;math&gt;x \leftarrow \frac{1}{1+x}&lt;/math&gt; to ''p''(''x'') and ''M''(''x'') and process the pair 
:::&lt;math&gt;\left \{(1+x)^{\deg(p)}p\left (\tfrac{1}{1+x} \right ), M(\tfrac{1}{1+x}) \right\},&lt;/math&gt; 
::whereas to compute the roots in the interval (1, ∞) perform the substitution ''x'' ← ''x'' + 1 to ''p''(''x'') and ''M''(''x'') and process the pair {''p''(1 + ''x''), ''M''(1 + ''x'')}. It may well turn out that 1 is a root of ''p''(''x''), in which case, ''M''(1) is a root of the original polynomial and the isolation interval reduces to a point.

Below is a [[Recursion#Recursion in computer science|recursive]] presentation of VAS(''p'', ''M'').

&lt;blockquote&gt;'''VAS'''('''''p''''', '''''M'''''):&lt;br&gt;

'''Input''': A univariate, square-free polynomial &lt;math&gt;p(x) \in \mathbb{Z}[x], p(0) \neq 0&lt;/math&gt;, of degree deg(''p''), and the [[Möbius transformation]] 
:&lt;math&gt;M(x)= \frac{ax+b}{cx+d}=x, \qquad a, b, c, d \in \mathbb{N}.&lt;/math&gt;
'''Output''': A list of isolating intervals of the positive roots of ''p''(''x'').&lt;br&gt;

&lt;code&gt;
1 ''var'' ← the number of [[Vincent's_theorem#Sign_variation|sign variations]] of ''p''(''x'') // [[Descartes' rule of signs]];&lt;br&gt;
2 '''if''' ''var'' = 0 then '''RETURN''' ∅;&lt;br&gt;
3 '''if''' ''var'' = 1 then '''RETURN''' {(''a'', ''b'')} // ''a'' = min(''M''(0), ''M''(∞)), ''b'' = max(''M''(0), ''M''(∞)), but if ''b'' = ∞ set ''b'' = ''ub'', where ''ub'' is an upper bound on the values of the positive roots of ''p''(''x'');&lt;br&gt;
4 ''lb'' ← the ''ideal'' lower bound on the positive roots of ''p''(''x'');&lt;br&gt;
5 '''if''' ''lb'' ≥ 1 '''then''' ''p'' ← ''p''(''x'' + ''lb''), ''M'' ← ''M''(''x'' + ''lb'');&lt;br&gt;
6 ''p''&lt;sub&gt;01&lt;/sub&gt; ← (''x'' + 1)&lt;sup&gt;deg(''p'')&lt;/sup&gt; ''p''({{sfrac|1|''x'' + 1}}), ''M''&lt;sub&gt;01&lt;/sub&gt; ← ''M''({{sfrac|1|''x'' + 1}}) // Look for real roots in (0, 1);&lt;br&gt;
7 ''m'' ← ''M''(1) // Is 1 a root?&lt;br&gt;
8 ''p''&lt;sub&gt;1∞&lt;/sub&gt; ← ''p''(''x'' + 1), ''M''&lt;sub&gt;1∞&lt;/sub&gt; ← ''M''(''x'' + 1) // Look for real roots in (1, ∞);&lt;br&gt;
9 '''if''' ''p''(1) ≠ 0  '''then'''&lt;br&gt;
10 '''RETURN''' VAS(''p''&lt;sub&gt;01&lt;/sub&gt;, ''M''&lt;sub&gt;01&lt;/sub&gt;) ∪ VAS(''p''&lt;sub&gt;1∞&lt;/sub&gt;, ''M''&lt;sub&gt;1∞&lt;/sub&gt;)&lt;br&gt;
11 '''else''' &lt;br&gt;
12 '''RETURN''' VAS(''p''&lt;sub&gt;01&lt;/sub&gt;, ''M''&lt;sub&gt;01&lt;/sub&gt;) ∪ {[''m'', ''m'']} ∪ VAS(''p''&lt;sub&gt;1∞&lt;/sub&gt;, ''M''&lt;sub&gt;1∞&lt;/sub&gt;)&lt;br&gt;
13 '''end'''&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

'''Remarks'''
*For simplicity Strzeboński's contribution is not included.
*In the above algorithm with each polynomial there is associated a [[Möbius transformation]] ''M''(''x'').
*In line 1 [[Descartes' rule of signs]] is applied.
*If lines 4 and 5 are removed from VAS(''p'', ''M'') the resulting algorithm is Vincent's exponential one.
*Any substitution performed on the polynomial ''p''(''x'') is also performed on the associated [[Möbius transformation]] ''M''(''x'') (lines 5 6 and 8).
*The isolating intervals are computed from the [[Möbius transformation]] in line 3, except for integer roots computed in line 7 (also 12).

===Example of VAS(''p'', ''M'')===
We apply the VAS method to {{math|''p''(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7}} (note that: {{math|''M''(''x'') {{=}} ''x''}}).

====Iteration 1====
&lt;blockquote&gt;&lt;code&gt;
VAS(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, ''x'')&lt;br&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7&lt;br&gt;
4 ''lb'' ← 1 // the ideal lower bound—found using ''lb&lt;sub&gt;computed&lt;/sub&gt;'' and substitution(s) ''x'' ← ''x'' + 1&lt;br&gt;
5 ''p'' ← ''x''&lt;sup&gt;3&lt;/sup&gt; + 3''x''&lt;sup&gt;2&lt;/sup&gt; − 4''x'' + 1, ''M'' ← ''x'' + 1&lt;br&gt;
6 ''p''&lt;sub&gt;01&lt;/sub&gt; ← ''x''&lt;sup&gt;3&lt;/sup&gt; − ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' + 1, ''M''&lt;sub&gt;01&lt;/sub&gt; ← {{sfrac|''x'' + 2|''x'' + 1}}&lt;br&gt;
7 ''m'' ← 1&lt;br&gt;
8 ''p''&lt;sub&gt;1∞&lt;/sub&gt; ← ''x''&lt;sup&gt;3&lt;/sup&gt; + 6''x''&lt;sup&gt;2&lt;/sup&gt; + 5''x'' + 1, ''M''&lt;sub&gt;1∞&lt;/sub&gt; ← ''x'' + 2&lt;br&gt;
10          '''RETURN''' VAS(''x''&lt;sup&gt;3&lt;/sup&gt; − ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' + 1, {{sfrac|''x'' + 2|''x'' + 1}}) ∪ VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + 6''x''&lt;sup&gt;2&lt;/sup&gt; + 5''x'' + 1, ''x'' + 2)&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''M''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{x^3-x^2-2x+1,\tfrac{x+2}{x+1} \right \}, \{x^3+6x^2+5x+1,x+2\} \right \}.&lt;/math&gt;
Remove the first and process it.

====Iteration 2====
&lt;blockquote&gt;&lt;code&gt;
VAS(''x''&lt;sup&gt;3&lt;/sup&gt; − ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' + 1, {{sfrac|''x'' + 2|''x'' + 1}})&lt;br&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; − ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' + 1&lt;br&gt;
4 ''lb'' ← 0 // the ideal lower bound—found using ''lb&lt;sub&gt;computed&lt;/sub&gt;'' and substitution(s) ''x'' ← ''x'' + 1&lt;br&gt;
6 ''p''&lt;sub&gt;01&lt;/sub&gt; ← ''x''&lt;sup&gt;3&lt;/sup&gt; + ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' − 1, ''M''&lt;sub&gt;01&lt;/sub&gt; ← {{sfrac|2''x'' + 3|''x'' + 1}}&lt;br&gt;
7 ''m'' ← {{sfrac|3|2}}&lt;br&gt;
8 ''p''&lt;sub&gt;1∞&lt;/sub&gt; ← ''x''&lt;sup&gt;3&lt;/sup&gt; + 2''x''&lt;sup&gt;2&lt;/sup&gt; − ''x'' − 1, ''M''&lt;sub&gt;1∞&lt;/sub&gt; ← {{sfrac|''x'' + 3|''x'' + 2}}&lt;br&gt;
10          '''RETURN''' VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' − 1, {{sfrac|2''x'' + 3|''x'' + 2}}) ∪ VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + 2''x''&lt;sup&gt;2&lt;/sup&gt; − ''x'' − 1, {{sfrac|''x'' + 3|''x'' + 2}})&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''M''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{x^3+x^2-2x-1,\tfrac{2x+3}{x+2} \right \}, \left \{x^3+2x^2-x-1,\tfrac{x+3}{x+2} \right \}, \{x^3+6x^2+5x+1,x+2\} \right\}.&lt;/math&gt; 
Remove the first and process it.

====Iteration 3 ====
&lt;blockquote&gt;&lt;code&gt;
VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' − 1, {{sfrac|2''x'' + 3|''x'' + 2}})&lt;br&gt;
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; + ''x''&lt;sup&gt;2&lt;/sup&gt; − 2''x'' − 1&lt;br&gt;
3          '''RETURN''' {({{sfrac|3|2}}, 2)} &lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{({{sfrac|3|2}}, 2)}.}}

List of pairs {{math|{''p'', ''M''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{x^3+2x^2-x-1,\tfrac{x+3}{x+2} \right \},\{x^3+6x^2+5x+1,x+2\} \right \}.&lt;/math&gt;
Remove the first and process it.

====Iteration 4 ====
&lt;blockquote&gt;&lt;code&gt;
VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + 2''x''&lt;sup&gt;2&lt;/sup&gt; − ''x'' − 1, {{sfrac|''x'' + 3|''x'' + 2}})&lt;br&gt;
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; + 2''x''&lt;sup&gt;2&lt;/sup&gt; − ''x'' − 1 &lt;br&gt;
3          '''RETURN''' {(1, {{sfrac|3|2}})}&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.}}

List of pairs {{math|{''p'', ''M''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{x^3+6x^2+5x+1,x+2 \right \} \right \}.&lt;/math&gt; 
Remove the first and process it.

====Iteration 5 ====
&lt;blockquote&gt;&lt;code&gt;
VAS(''x''&lt;sup&gt;3&lt;/sup&gt; + 6''x''&lt;sup&gt;2&lt;/sup&gt; + 5''x'' + 1, ''x'' + 2) &lt;br&gt;
1 ''var'' ← 0 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; + 6''x''&lt;sup&gt;2&lt;/sup&gt; + 5''x'' + 1&lt;br&gt;
2          '''RETURN''' ∅&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.}}

List of pairs {{math|{''p'', ''M''} }}to be processed: {{math|∅}}.

Finished.

====Conclusion====
Therefore, the two positive roots of the polynomial {{math|''p''(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7}} lie inside the isolation intervals {{math|(1, {{sfrac|3|2}})}} and {{math|({{sfrac|3|2}}, 2)}}}. Each root can be approximated by (for example) bisecting the isolation interval it lies in until the difference of the endpoints is smaller than {{math|10&lt;sup&gt;−6&lt;/sup&gt;}}; following this approach, the roots turn out to be {{math|''ρ''&lt;sub&gt;1&lt;/sub&gt; {{=}} 1.3569}} and {{math|''ρ''&lt;sub&gt;2&lt;/sub&gt; {{=}} 1.69202}}.

==Bisection methods==
There are various [[bisection method]]s derived from [[Vincent's theorem#Vincent's theorem: Bisection version (Alesina and Galuzzi 2000)|Vincent's theorem]]; they are all presented and compared elsewhere.&lt;ref name=ASV_2008&gt;{{cite journal|last=Akritas|first=Alkiviadis G.|author2=Adam W. Strzeboński |author3=Panagiotis S. Vigklas |title=On the Various Bisection Methods Derived from Vincent's Theorem|url=http://sci-gems.math.bas.bg:8080/jspui/handle/10525/376|journal=Serdica Journal of Computing|year=2008|volume=2|number=1|pages=89–104}}&lt;/ref&gt; Here the two most important of them are described, namely, the [[Vincent's theorem#Vincent–Collins–Akritas (VCA, 1976)|Vincent–Collins–Akritas (VCA)]] method and the [[Vincent's theorem#Vincent–Alesina–Galuzzi (VAG, 2000)|Vincent–Alesina–Galuzzi (VAG)]] method.

The [[Vincent's theorem#Vincent–Alesina–Galuzzi (VAG, 2000)|Vincent–Alesina–Galuzzi (VAG)]] method is the simplest of all methods derived from Vincent's theorem but has the most time consuming test (in line 1) to determine if a polynomial has roots in the interval of interest; this makes it the slowest of the methods presented in this article.
  
By contrast, the [[Vincent's theorem#Vincent–Collins–Akritas (VCA, 1976)|Vincent–Collins–Akritas (VCA)]] method is more complex but uses a simpler test (in line 1) than [[Vincent's theorem#Vincent–Alesina–Galuzzi (VAG, 2000)|VAG]]. This along with certain improvements&lt;ref name="RZ"/&gt; have made [[Vincent's theorem#Vincent–Collins–Akritas (VCA, 1976)|VCA]] the fastest bisection method.

===Vincent–Collins–Akritas (VCA, 1976)===
This was the first method developed to overcome the [[Exponential time#Exponential time|exponential]] nature of Vincent's [[Vincent's theorem#Continued fractions method|original approach]], and has had quite an interesting history as far as its name is concerned. This method, which isolates the real roots, using Descartes' rule of signs and [[Vincent's theorem#Vincent's theorem: Continued fractions version (1834 and 1836)|Vincent's theorem]], had been originally called ''modified Uspensky's algorithm'' by its inventors Collins and Akritas.&lt;ref name="CA"/&gt; After going through names like "Collins–Akritas method" and "Descartes' method" (too confusing if ones considers Fourier's article&lt;ref name=Fourier&gt;{{cite journal|last=Fourier|first=Jean Baptiste Joseph|title=Sur l'usage du théorème de Descartes dans la recherche des limites des racines|year=1820|journal=Bulletin des Sciences, par la Société Philomatique de Paris|pages=156–165 | url=https://archive.org/details/bulletindesscien20soci}}&lt;/ref&gt;), it was finally François Boulier, of Lille University, who gave it the name ''Vincent–Collins–Akritas'' (VCA) method,&lt;ref name="FB"/&gt; p.&amp;nbsp;24, based on the fact that "Uspensky's method" does not exist&lt;ref name="akritas"&gt;{{cite book|last=Akritas|first=Alkiviadis G.|title=There's no "Uspensky's Method"|url=http://dl.acm.org/citation.cfm?id=32457|year=1986|publisher=In: Proceedings of the fifth ACM Symposium on Symbolic and Algebraic Computation (SYMSAC '86, Waterloo, Ontario, Canada), pp. 88–90}}&lt;/ref&gt; and neither does "Descartes' method".&lt;ref name=noDec&gt;{{cite book|last=Akritas|first=Alkiviadis G.|title=There is no "Descartes' method"|url=https://books.google.com/books?id=SJR2ybQdZFgC&amp;lpg=PR1&amp;pg=PR1#v=onepage&amp;q&amp;f=false |year=2008|publisher=In: M.J.Wester and M. Beaudin (Eds), Computer Algebra in Education, AullonaPress, USA, pp. 19–35}}&lt;/ref&gt; The best implementation of this method is due to Rouillier and Zimmerman,&lt;ref name="RZ"/&gt; and  to this date, it is the fastest bisection method. It has the same worst case [[Computational complexity theory|complexity]] as Sturm's algorithm, but is almost always much faster. It has been implemented in [[Maple (software)|Maple]]'s RootFinding package.

Here is how VCA(''p'', (''a'', ''b'')) works:

*Given a polynomial ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') of degree deg(''p''), such that ''p''&lt;sub&gt;orig&lt;/sub&gt;(0) ≠ 0, whose positive roots must be isolated, first compute an upper bound,&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt; ''ub'' on the values of these positive roots and set ''p''(''x'') = ''p''&lt;sub&gt;orig&lt;/sub&gt;(''ub'' * ''x'') and (''a'', ''b'') = (0, ''ub''). The positive roots of ''p''(''x'') all lie in the interval (0, 1) and there is a [[bijection]] between them and the roots of ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x''), which all lie in the interval (''a'', ''b'') = (0, ''ub'') (see the corresponding figure); this [[bijection]] is expressed by ''α''&lt;sub&gt;(''a'',''b'')&lt;/sub&gt; = ''a'' +''α''&lt;sub&gt;(0,1)&lt;/sub&gt;(''b'' − ''a''). Likewise, there is a [[bijection]] between the intervals (0, 1) and (0, ''ub'').

[[File:VCA Algorithm.jpg|x220px|thumb|center|[[Bijection]] between the roots of ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') and ''p''(''x'').]]

*Repeat the following steps while there are pairs {''p''(''x''), (''a'', ''b'')} to be processed.
*Use Budan's [[Budan's theorem#Early applications of Budan's theorem|"'''0_1 roots test'''"]] on ''p''(''x'') to compute (using the number ''var'' of [[Budan's theorem#Sign variation|sign variations]] in the sequence of its coefficients) the number of its roots inside the interval (0, 1). If there are no roots return the empty set, ∅ and if there is one root return the interval (''a'', ''b'').
*If there are two or more sign variations Budan's [[Budan's theorem#Early applications of Budan's theorem|"'''0_1 roots test'''"]] implies that there may be zero, one, two or more real roots inside the interval (0, 1). In this case cut it in half and consider separately the roots of ''p''(''x'') inside the interval (0, {{sfrac|1|2}})—and that correspond to the roots of ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') inside the interval (''a'', {{sfrac|1|2}}(''a'' + ''b'')) from those inside the interval ({{sfrac|1|2}}, 1) and correspond to the roots of ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') inside the interval ({{sfrac|1|2}}(''a'' + ''b''), ''b''); that is, process, respectively, the pairs

::&lt;math&gt;\left \{2^{\deg(p)}p(\tfrac{x}{2}), (a, \tfrac{1}{2}(a+b)) \right \}, \quad \left \{2^{\deg(p)}p(\tfrac{1}{2} (x+1)), (\tfrac{1}{2}(a+b), b) \right \}&lt;/math&gt;

:(see the corresponding figure). It may well turn out that {{sfrac|1|2}} is a root of ''p''(''x''), in which case {{sfrac|1|2}}(''a'' + ''b'') is a root of ''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') and the isolation interval reduces to a point.

[[File:VCA Example.jpg|x220px|thumb|center|[[Bijection]]s between the roots of ''p''(''x'') and those of ''p''({{sfrac|''x''|2}}) and ''p''({{sfrac|''x'' + 1|2}}).]]

Below is a [[Recursion#Recursion in computer science|recursive]] presentation of the original algorithm VCA(''p'', (''a'', ''b'')).

&lt;blockquote&gt;'''VCA'''('''''p''''', ('''''a''''', '''''b'''''))&lt;br&gt;

'''Input''': A univariate, square-free polynomial ''p''(''ub'' * ''x'') ∈ '''Z'''[''x''], ''p''(0) ≠ 0 of degree deg(''p''), and the open
interval (''a'', ''b'') = (0, ''ub''), where ''ub'' is an upper bound on the values of the positive
roots of ''p''(''x''). (The positive roots of ''p''(''ub'' * ''x'') are all in the open interval (0, 1)).&lt;br&gt;
'''Output''': A list of isolating intervals of the positive roots of ''p''(''x'')&lt;br&gt;

&lt;code&gt;
1 ''var'' ← the number of [[Vincent's theorem#Sign variation|sign variation]]s of (''x'' + 1)&lt;sup&gt;deg(''p'')&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) // Budan's [[Budan's theorem#Early applications of Budan's theorem|"'''0_1 roots test'''"]];&lt;br&gt;
2 '''if''' ''var'' = 0 '''then RETURN''' ∅;&lt;br&gt;
3 '''if''' ''var'' = 1 '''then RETURN''' {(''a'', ''b'')};&lt;br&gt;
4 ''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt; ← 2&lt;sup&gt;deg(''p'')&lt;/sup&gt;''p''({{sfrac|''x''|2}}) // Look for real roots in (0, {{sfrac|1|2}});&lt;br&gt;
5 ''m'' ← {{sfrac|1|2}}(''a'' + ''b'') // Is {{sfrac|1|2}} a root? &lt;br&gt;
6 ''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt; ← 2&lt;sup&gt;deg(''p'')&lt;/sup&gt;''p''({{sfrac|''x'' + 1|2}}) // Look for real roots in ({{sfrac|1|2}}, 1);&lt;br&gt;
7 '''if''' ''p''({{sfrac|1|2}}) ≠ 0 '''then'''&lt;br&gt;
8         '''RETURN''' VCA (''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt;, (''a'', ''m'')) ∪ VCA (''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt;, (''m'', ''b''))&lt;br&gt;
9 '''else'''&lt;br&gt;
10        '''RETURN''' VCA (''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt;, (''a'', ''m'')) ∪ {[''m'', ''m'']} ∪ VCA (''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt;, (''m'', ''b''))&lt;br&gt;
11 '''end'''
&lt;/code&gt;&lt;/blockquote&gt;

'''Remark'''
*In the above algorithm with each polynomial there is associated an interval (''a'', ''b''). As shown elsewhere,&lt;ref name="noDec"/&gt; p.&amp;nbsp;11, a [[Möbius transformation]] can also be associated with each polynomial in which case VCA looks more like [[Vincent's theorem#Example of VCA(p, (a,b))|VAS]].
*In line 1 Budan's [[Budan's theorem#Early applications of Budan's theorem|"'''0_1 roots test'''"]] is applied.

===Example of VCA(''p'', (''a'',''b''))===
Given the polynomial {{math|''p''&lt;sub&gt;orig&lt;/sub&gt;(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7}} and considering as an upper bound&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt; on the values of the positive roots {{math|''ub'' {{=}} 4}} the arguments of the VCA method are: {{math|''p''(''x'') {{=}} 64''x''&lt;sup&gt;3&lt;/sup&gt; − 28''x'' + 7}} and {{math|(''a'', ''b'') {{=}} (0, 4)}}.

====Iteration 1====
&lt;blockquote&gt;&lt;code&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 7''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x''&lt;sup&gt;2&lt;/sup&gt; − 35''x'' + 43&lt;br&gt;
4 ''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; − 112''x'' + 56&lt;br&gt;
5 ''m'' ← 2&lt;br&gt;
6 ''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; + 80''x'' + 8&lt;br&gt;
7 ''p''({{sfrac|1|2}}) = 1&lt;br&gt;
8          '''RETURN''' VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; − 112''x'' + 56, (0, 2)) ∪ VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; + 80''x'' + 8, (2, 4))&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{64x^3-112x+56,(0,2) \right \}, \left \{64x^3+192x^2+80x+8,(2,4) \right\} \right\}.&lt;/math&gt;

Remove the first and process it.

====Iteration 2====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; − 112''x'' + 56, (0, 2)) &lt;br&gt; 
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 56''x''&lt;sup&gt;3&lt;/sup&gt; + 56''x''&lt;sup&gt;2&lt;/sup&gt; − 56''x'' + 8&lt;br&gt;
4 ''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; − 448''x'' + 448&lt;br&gt;
5 ''m'' ← 1&lt;br&gt;
6 ''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; − 256''x'' + 64&lt;br&gt;
7 ''p''({{sfrac|1|2}}) = 8&lt;br&gt;
8          '''RETURN''' VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; − 448''x'' + 448, (0, 1)) ∪ VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; − 256''x'' + 64, (1, 2))&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''I''} }}to be processed:
:&lt;math&gt;\left \{ \left \{64x^3-448x+448,(0,1) \right \}, \left \{64x^3+192x^2-256x+64,(1,2) \right \}, \left \{64x^3+192x^2+80x+8,(2,4)\right\} \right\}.&lt;/math&gt;

Remove the first and process it.

====Iteration 3====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; − 448''x'' + 448, (0, 1)) &lt;br&gt;
1 ''var'' ← 0 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 448''x''&lt;sup&gt;3&lt;/sup&gt; + 896''x''&lt;sup&gt;2&lt;/sup&gt; + 448''x'' + 64&lt;br&gt;
2          '''RETURN''' ∅ &lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{64x^3+192x^2-256x+64,(1,2) \right \}, \left \{64x^3+192x^2+80x+8,(2,4) \right \} \right \}.&lt;/math&gt;

Remove the first and process it.

====Iteration 4====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; − 256''x'' + 64, (1, 2)) &lt;br&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 64''x''&lt;sup&gt;3&lt;/sup&gt; − 64''x''&lt;sup&gt;2&lt;/sup&gt; − 128''x'' + 64&lt;br&gt;
4 ''p''&lt;sub&gt;0{{sfrac|1|2}}&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; + 384''x''&lt;sup&gt;2&lt;/sup&gt; − 1024''x'' + 512&lt;br&gt;
5 ''m'' ← {{sfrac|3|2}} &lt;br&gt;
6 ''p''&lt;sub&gt;{{sfrac|1|2}}1&lt;/sub&gt; ← 64''x''&lt;sup&gt;3&lt;/sup&gt; + 576''x''&lt;sup&gt;2&lt;/sup&gt; − 64''x'' + 64&lt;br&gt;
7 ''p''({{sfrac|1|2}}) = −8 &lt;br&gt;
8 '''RETURN''' VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 384''x''&lt;sup&gt;2&lt;/sup&gt; − 1024''x'' + 512, (1, {{sfrac|3|2}})) ∪ VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 576''x''&lt;sup&gt;2&lt;/sup&gt; − 64''x'' − 64, ({{sfrac|3|2}}, 2))&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{ }.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{64x^3+384x^2-1024x+512, \left (1,\tfrac{3}{2} \right ) \right \}, \left \{64x^3+576x^2-64x-64, \left(\tfrac{3}{2},2 \right ) \right \}, \left \{64x^3+192x^2+80x+8,(2,4) \right \} \right \}.&lt;/math&gt;

Remove the first and process it.

====Iteration 5====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 384''x''&lt;sup&gt;2&lt;/sup&gt; − 1024''x'' + 512, (1, {{sfrac|3|2}})) &lt;br&gt;
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 512''x''&lt;sup&gt;3&lt;/sup&gt; + 512''x''&lt;sup&gt;2&lt;/sup&gt; − 128''x'' − 64&lt;br&gt;
3 '''RETURN''' {(1, {{sfrac|3|2}})}&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{(1, {{sfrac|3|2}})}.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{64x^3+576x^2-64x-64, \left (\tfrac{3}{2},2 \right ) \right \}, \left \{64x^3+192x^2+80x+8, (2,4) \right \} \right \}.&lt;/math&gt;

Remove the first and process it.

====Iteration 6====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 576''x''&lt;sup&gt;2&lt;/sup&gt; − 64''x'' − 64, ({{sfrac|3|2}}, 2)) &lt;br&gt; 
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = −64''x''&lt;sup&gt;3&lt;/sup&gt; − 256''x''&lt;sup&gt;2&lt;/sup&gt; + 256''x'' + 512 &lt;br&gt;
3 '''RETURN''' {({{sfrac|3|2}}, 2)}&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: 
:&lt;math&gt;\left \{ \left \{64x^3+192x^2+80x+8, (2,4) \right\} \right\}.&lt;/math&gt;

Remove the first and process it.

====Iteration 7====
&lt;blockquote&gt;&lt;code&gt;
VCA(64''x''&lt;sup&gt;3&lt;/sup&gt; + 192''x''&lt;sup&gt;2&lt;/sup&gt; + 80''x'' + 8, (2, 4)) &lt;br&gt; 
1 ''var'' ← 0 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|1|''x'' + 1}}) = 8''x''&lt;sup&gt;3&lt;/sup&gt; + 104''x''&lt;sup&gt;2&lt;/sup&gt; + 376''x'' + 344 &lt;br&gt;
2 '''RETURN''' ∅&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {{math|{(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.}}

List of pairs {{math|{''p'', ''I''} }}to be processed: {{math|∅}}.

Finished.

====Conclusion====
Therefore, the two positive roots of the polynomial {{math|''p''(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7}} lie inside the isolation intervals {{math|(1, {{sfrac|3|2}})}} and {{math|({{sfrac|3|2}}, 2)}}}. Each root can be approximated by (for example) bisecting the isolation interval it lies in until the difference of the endpoints is smaller than {{math|10&lt;sup&gt;−6&lt;/sup&gt;}}; following this approach, the roots turn out to be {{math|''ρ''&lt;sub&gt;1&lt;/sub&gt; {{=}} 1.3569}} and {{math|''ρ''&lt;sub&gt;2&lt;/sub&gt; {{=}} 1.69202}}.

===Vincent–Alesina–Galuzzi (VAG, 2000)===
This was developed last and is the simplest [[Vincent's theorem#Real root isolation methods derived from Vincent's theorem|real root isolation method]] derived from [[Vincent's theorem#Vincent's theorem: Bisection version (Alesina and Galuzzi 2000)|Vincent's theorem]].

Here is how VAG(''p'', (''a'', ''b'')) works: 
*Given a polynomial ''p''(''x'') of degree deg(''p''), such that ''p''(0) ≠ 0, whose positive roots must be isolated, first compute an upper bound,&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt; ''ub'' on the values of these positive roots and set (''a'', ''b'') = (0, ''ub''). The positive roots of ''p''(''x'') all lie in the interval (''a'', ''b'').
*Repeat the following steps while there are intervals (''a'', ''b'') to be processed; in this case the polynomial ''p''(''x'') stays the same.
*Use the Alesina–Galuzzi [[Vincent's theorem#The Alesina–Galuzzi "a b roots test"|"'''a_b roots test'''"]]  on ''p''(''x'') to compute (using the number ''var'' of [[Vincent's theorem#Sign variation|sign variations]] in the sequence of its coefficients) the number of its roots inside the interval (''a'', ''b''). If there are no roots return the empty set, ∅ and if there is one root return the interval (''a'', ''b'').
*If there are two or more sign variations the Alesina–Galuzzi [[Vincent's theorem#The Alesina–Galuzzi "a b roots test"|"'''a_b roots test'''"]] implies that there may be zero, one, two or more real roots inside the interval (''a'', ''b''). In this case cut it in half and consider separately the roots of ''p''(''x'') inside the interval (''a'', {{sfrac|1|2}}(''a'' + ''b'')) from those inside the interval ({{sfrac|1|2}}(''a'' + ''b''), ''b''); that is, process, respectively, the intervals (''a'', {{sfrac|1|2}}(''a'' + ''b'')) and ({{sfrac|1|2}}(''a'' + ''b''), ''b''). It may well turn out that {{sfrac|1|2}}(''a'' + ''b'') is a root of ''p''(''x''), in which case the isolation interval reduces to a point.

Below is a [[Recursion#Recursion in computer science|recursive]] presentation of VAG(''p'', (''a'', ''b'')).

&lt;blockquote&gt;'''VAG'''('''''p''''', ('''''a''''', '''''b'''''))&lt;br&gt;
'''Input''': A univariate, square-free polynomial ''p''(''x'') ∈ '''Z'''[''x''], ''p''(0) ≠ 0 of degree deg(''p'') and the open interval (''a'', ''b'') = (0, ''ub''), where ''ub'' is an upper bound on the values of the positive roots of ''p''(''x''). &lt;br&gt;
'''Output''': A list of isolating intervals of the positive roots of ''p''(''x'').&lt;br&gt;

&lt;code&gt;
1 ''var'' ← the number of [[Vincent's theorem#Sign variation|sign variation]]s of (''x'' + 1)&lt;sup&gt;deg(''p'')&lt;/sup&gt; ''p''({{sfrac|''a'' + ''bx''|1 + ''x''}}) // The Alesina–Galuzzi [[Vincent's theorem#The Alesina–Galuzzi "a_b roots test"|"'''a_b roots test'''"]];&lt;br&gt;
2 '''if''' ''var'' = 0 '''then RETURN''' ∅;&lt;br&gt;
3 '''if''' ''var'' = 1 '''then RETURN''' {(''a'', ''b'')};&lt;br&gt;
4 ''m'' ← {{sfrac|1|2}}(''a'' + ''b'') // Subdivide the interval (''a'', ''b'') in two equal parts;&lt;br&gt;
5 '''if''' ''p''(''m'') ≠ 0 '''then'''&lt;br&gt;
6        '''RETURN''' VAG(''p'', (''a'', ''m'')) ∪ VAG(''p'', (''m'', ''b''))&lt;br&gt;
7 '''else'''&lt;br&gt;
8        '''RETURN''' VAG(''p'', (''a'', ''m'')) ∪  {[''m'', ''m'']} ∪ VAG(''p'', (''m'', ''b''))&lt;br&gt;
9 '''end'''&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

'''Remarks'''
*Compared to [[Vincent's theorem#Example of VCA(p, (a,b))|VCA]] the above algorithm is extremely simple; by contrast, VAG uses the time consuming '''[[Vincent's theorem#The Alesina–Galuzzi "a b roots test"|"a_b roots test"]]''' and that makes it much slower than [[Vincent's theorem#Example of VCA(p, (a,b))|VCA]].&lt;ref name="ASV_2008"/&gt;
*As Alesina and Galuzzi point out,&lt;ref name="AG_2000"/&gt; p.&amp;nbsp;189, there is a variant of this algorithm due to Donato Saeli. Saeli suggested that the ''[[Mediant (mathematics)|mediant]]'' of the endpoints be used instead of their midpoint {{math|{{sfrac|1|2}}(''a'' + ''b'')}}. However, it has been shown&lt;ref name="ASV_2008"/&gt; that using the [[Mediant (mathematics)|mediant]] of the endpoints is in general much slower than the "mid-point" version.

===Example of VAG(''p'', (''a'',''b''))===
Given the polynomial ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7 and considering as an upper bound&lt;ref name="Panos"/&gt;&lt;ref name="bounds"/&gt; on the values of the positive roots ''ub'' = 4 the arguments of VAG are: ''p''(''x'') = ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7 and (''a'', ''b'') = (0, 4).

====Iteration 1 ====
&lt;blockquote&gt;&lt;code&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|4''x''|''x'' + 1}}) = 43''x''&lt;sup&gt;3&lt;/sup&gt; − 35''x''&lt;sup&gt;2&lt;/sup&gt; − 7''x'' + 7&lt;br&gt;
4 ''m'' ← {{sfrac|1|2}}(0 + 4) = 2&lt;br&gt;
5 ''p''(''m'') = 1&lt;br&gt;
8          '''RETURN''' VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (0, 2)) ∪ VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (2, 4)&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {}.

List of intervals to be processed: {(0, 2), (2, 4)}.

Remove the first and process it.

====Iteration 2====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (0, 2)) &lt;br&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|2''x''|''x'' + 1}}) = ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x''&lt;sup&gt;2&lt;/sup&gt; + 7''x'' + 7&lt;br&gt;
4 ''m'' ← {{sfrac|1|2}}(0 + 2) = 1&lt;br&gt;
5 ''p''(''m'') = 1&lt;br&gt;
8          '''RETURN''' VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (0, 1)) ∪ VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (1, 2)&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {}.

List of intervals to be processed: {(0, 1), (1, 2), (2, 4)}.

Remove the first and process it.

====Iteration 3====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (0, 1)) &lt;br&gt;
1 ''var'' ← 0 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|''x''|''x'' + 1}}) = ''x''&lt;sup&gt;3&lt;/sup&gt; + 7''x''&lt;sup&gt;2&lt;/sup&gt; + 14''x'' + 7&lt;br&gt;
2          '''RETURN''' ∅
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {}.

List of intervals to be processed: {(1, 2), (2, 4)}.

Remove the first and process it.

====Iteration 4====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (1, 2)) &lt;br&gt;
1 ''var'' ← 2 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|2''x'' + 1|''x'' + 1}}) = ''x''&lt;sup&gt;3&lt;/sup&gt; − 2''x''&lt;sup&gt;2&lt;/sup&gt; − ''x'' + 1&lt;br&gt;
4 ''m'' ← {{sfrac|1|2}}(1 + 2) = {{sfrac|3|2}}&lt;br&gt;
5 ''p''(''m'') = −{{sfrac|1|8}}&lt;br&gt;
8          '''RETURN''' VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (1, {{sfrac|3|2}})) ∪ VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, ({{sfrac|3|2}}, 2))&lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {}.

List of intervals to be processed: {(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2), (2, 4)}.

Remove the first and process it.

====Iteration 5 ====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (1, {{sfrac|3|2}})) &lt;br&gt;
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of 2&lt;sup&gt;3&lt;/sup&gt;(''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|{{sfrac|3|2}}''x'' + 1|''x'' + 1}}) = ''x''&lt;sup&gt;3&lt;/sup&gt; + 2''x''&lt;sup&gt;2&lt;/sup&gt; − 8''x'' − 8&lt;br&gt;
3          '''RETURN''' (1, {{sfrac|3|2}}) &lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {(1, {{sfrac|3|2}})}.

List of intervals to be processed: {({{sfrac|3|2}}, 2), (2, 4)}.

Remove the first and process it.

====Iteration 6====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, ({{sfrac|3|2}}, 2)) &lt;br&gt;
1 ''var'' ← 1 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of 2&lt;sup&gt;3&lt;/sup&gt;(''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|2''x'' + {{sfrac|3|2}}|''x'' + 1}}) = 8''x''&lt;sup&gt;3&lt;/sup&gt; + 4''x''&lt;sup&gt;2&lt;/sup&gt; − 4''x'' − 1&lt;br&gt;
3          '''RETURN''' ({{sfrac|3|2}}, 2) &lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.

List of intervals to be processed: {(2, 4)}.

Remove the first and process it.

====Iteration 7====
&lt;blockquote&gt;&lt;code&gt;
VAG(''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7, (2, 4)) &lt;br&gt;
1 ''var'' ← 0 // the number of [[Vincent's theorem#Sign variation|sign variation]]s in the sequence of coefficients of (''x'' + 1)&lt;sup&gt;3&lt;/sup&gt;''p''({{sfrac|4''x'' + 2|''x'' + 1}}) = 344''x''&lt;sup&gt;3&lt;/sup&gt; + 376''x''&lt;sup&gt;2&lt;/sup&gt; + 104''x'' + 8&lt;br&gt;
2          '''RETURN''' ∅ &lt;br&gt;
&lt;/code&gt;&lt;/blockquote&gt;

List of isolation intervals: {(1, {{sfrac|3|2}}), ({{sfrac|3|2}}, 2)}.

List of intervals to be processed: ∅.

Finished.

====Conclusion====
Therefore, the two positive roots of the polynomial {{math|''p''(''x'') {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; − 7''x'' + 7}} lie inside the isolation intervals {{math|(1, {{sfrac|3|2}})}} and {{math|({{sfrac|3|2}}, 2)}}}. Each root can be approximated by (for example) bisecting the isolation interval it lies in until the difference of the endpoints is smaller than {{math|10&lt;sup&gt;−6&lt;/sup&gt;}}; following this approach, the roots turn out to be {{math|''ρ''&lt;sub&gt;1&lt;/sub&gt; {{=}} 1.3569}} and {{math|''ρ''&lt;sub&gt;2&lt;/sub&gt; {{=}} 1.69202}}.

==See also==
*[[Properties of polynomial roots]]
*[[Root-finding algorithm]]
*[[Vieta's formulas]]
*[[Newton's method]]

==References==
{{reflist}}

==External links==
* Berkakis, Antonis: RealRoots, a free App for Android devices to compare Sturm's method and VAS
* https://play.google.com/store/apps/details?id=org.kde.necessitas.berkakis.realroots

[[Category:Mathematical theorems]]</text>
      <sha1>30ugp9igscr336u49q7v189fhd6fkl3</sha1>
    </revision>
  </page>
  <page>
    <title>Yair Minsky</title>
    <ns>0</ns>
    <id>46905726</id>
    <revision>
      <id>854702962</id>
      <parentid>839237619</parentid>
      <timestamp>2018-08-13T05:55:55Z</timestamp>
      <contributor>
        <username>Hmains</username>
        <id>508734</id>
      </contributor>
      <minor/>
      <comment>standard quote handling in WP;standard Apostrophe/quotation marks in WP; MOS general fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3897">[[File:Minsky yair.jpg|thumb|Yair Minsky, in [[Mathematical Research Institute of Oberwolfach|Oberwolfach]] (2004)]]

'''Yair Nathan Minsky''' (born in 1962) is an [[Israel]]i-[[United States|American]] [[mathematician]] whose research concerns [[Low-dimensional topology#Three dimensions|three-dimensional topology]], [[differential geometry]], [[group theory]] and [[holomorphic dynamics]]. He is a professor at [[Yale University]].&lt;ref&gt;[http://users.math.yale.edu/~yhm3/ Minsky's home page at Yale University]&lt;/ref&gt; He is known for having proved [[William Thurston|Thurston]]'s [[ending lamination conjecture]] and as a pioneer in the study of [[Curve complex|curve complex geometry]].

==Biography==

Minsky obtained his Ph.D. from [[Princeton University]] in 1989 under the supervision of [[William Thurston|William Paul Thurston]], with the thesis ''Harmonic Maps and Hyperbolic Geometry''.&lt;ref name="MGP"&gt;{{MathGenealogy|id=25191|title=Yair Nathan Minsky}}&lt;/ref&gt;

His Ph.D. students include [[Jason Behrstock]], [[Erica Klarreich]], [[Hossein Namazi]] and [[Kasra Rafi]].&lt;ref name="MGP" /&gt;

==Honors and awards==
He received a [[Sloan Fellowship]] in 1995.&lt;ref&gt;[http://www.sloan.org/sloan-research-fellowships/past-fellows/?tx_sloangrants_sloanfellows%5Baction%5D=list&amp;tx_sloangrants_sloanfellows%5Bcontroller%5D=Fellows&amp;cHash=8f53adde7b4458aff6de5c2679773fee Alfred P. Sloan Foundation]&lt;/ref&gt;&lt;ref&gt;[http://www.stonybrook.edu/commcms/provost/faculty/awards/awards-fellowships.html Stony Brook University]&lt;/ref&gt;

He was a speaker at the [[International Congress of Mathematicians|ICM]] (Madrid) 2006.

==Selected invited talks==
*Coxeter lectures ([[Fields Institute]]) 2006
*Mallat Lectures (Technion) 2008

==Selected publications==
*with [[Howard Masur]]: "Geometry of the complex of curves I: Hyperbolicity", ''[[Inventiones mathematicae]]'', '''138''' (1), 103–149.
*with Howard Masur: "Geometry of the complex of curves II: Hierarchical structure", ''[[Geometric and Functional Analysis]]'', '''10''' (4), 902–974.
*"The classification of Kleinian surface groups, I: Models and bounds", ''[[Annals of Mathematics]]'', '''171''' (2010), 1–107.
*with Jeffrey Brock, and [[Richard Canary]]: "The classification of Kleinian surface groups, II: The ending lamination conjecture", ''Annals of Mathematics'', '''176''' (2012), 1–149.
*with [[Jason Behrstock]]: "Dimension and rank for mapping class groups", ''Annals of Mathematics'' (2) 167 (2008), no. 3, 1055–1077.
*"The classification of punctured-torus groups", ''Annals of Mathematics'', '''149''' (1999), 559–626.
*"On rigidity, limit sets, and end invariants of hyperbolic 3-manifolds", ''[[Journal of the American Mathematical Society]]'', '''7''' (3), 539–588.

==See also==
*[[Ending lamination theorem]]
*[[Curve complex]]

==Quotes==
* "When [[William Thurston|Thurston]] proposed it, the [[Virtually Haken conjecture|virtual Haken conjecture]] seemed like a small question, but it hung on stubbornly, shining a spotlight on how little we knew about the field."&lt;ref&gt;{{citation|url=https://www.quantamagazine.org/20121002-getting-into-shapes-from-hyperbolic-geometry-to-cube-complexes-and-back/|title=Getting Into Shapes: From Hyperbolic Geometry to Cube Complexes and Back|date=2 October 2012|first=Erica|last=Klarreich|magazine=Quanta Magazine}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://users.math.yale.edu/~yhm3/ Minsky's home page at Yale University]
*[https://scholar.google.com/citations?user=XV4YuVwAAAAJ Minsky's profile at Google Scholar]

{{Authority control}}

{{DEFAULTSORT:Minsky, Yair}}
[[Category:American mathematicians]]
[[Category:1962 births]]
[[Category:Princeton University alumni]]
[[Category:Yale University faculty]]
[[Category:Sloan Research Fellows]]
[[Category:Topologists]]
[[Category:Geometers]]
[[Category:Living people]]
[[Category:University of Michigan faculty]]</text>
      <sha1>reamny30bujvgoran9f0j5aydpgtd8y</sha1>
    </revision>
  </page>
</mediawiki>
