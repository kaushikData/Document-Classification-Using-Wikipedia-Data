<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>7825 (number)</title>
    <ns>0</ns>
    <id>53587502</id>
    <revision>
      <id>841786662</id>
      <parentid>841774972</parentid>
      <timestamp>2018-05-18T01:47:48Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>Partially Undid revision 841774972 by [[Special:Contributions/BradRaiche|BradRaiche]] ([[User talk:BradRaiche|talk]]) and is sometimes used</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1475">{{Infobox number|number=7825|cardinal=seven thousand, eight hundred [and] twenty-five|ordinal=7825th|ordinal text=seven thousand, eight hundred [and] twenty-fifth|numeral=|factorization=}}'''7825''' ('''seven thousand, eight hundred [and] twenty-five''') is the [[natural number]] following 7824 and preceding 7826.

== In mathematics ==
* 7825 is the smallest number when it is impossible for every [[Pythagorean triple]] to be multicolored. The 200-terabyte proof to verify this is the largest ever made.&lt;ref&gt;{{Cite journal|last=Lamb|first=Evelyn|date=2016-06-02|title=Two-hundred-terabyte maths proof is largest ever|url=http://www.nature.com/news/two-hundred-terabyte-maths-proof-is-largest-ever-1.19990|journal=Nature|language=en|volume=534|issue=7605|pages=17–18|doi=10.1038/nature.2016.19990|bibcode=2016Natur.534...17L}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Heule|first=Marijn J. H.|last2=Kullmann|first2=Oliver|last3=Marek|first3=Victor W.|date=2016-01-01|arxiv=1605.00723 |volume=9710|pages=228–245|doi=10.1007/978-3-319-40970-2_15|chapter=Solving and Verifying the Boolean Pythagorean Triples Problem via Cube-and-Conquer|title=Theory and Applications of Satisfiability Testing – SAT 2016|series=Lecture Notes in Computer Science|isbn=978-3-319-40969-6}}&lt;/ref&gt;
* 7825 is a [[magic constant]] of ''n'' × ''n'' normal [[magic square]] and [[Eight queens puzzle|n-Queens Problem]] for ''n'' = 25.

== References ==
&lt;references /&gt;

[[Category:Integers]]


{{Number-stub}}</text>
      <sha1>7i1zyq9nq1zd0bahow04l6l80zax75k</sha1>
    </revision>
  </page>
  <page>
    <title>Algebraic combinatorics</title>
    <ns>0</ns>
    <id>14835582</id>
    <revision>
      <id>863506656</id>
      <parentid>846480084</parentid>
      <timestamp>2018-10-11T06:13:20Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10474">[[File:fano plane.svg|thumb|The Fano [[matroid]], derived from the [[Fano plane]]. Matroids are one of many areas studied in '''algebraic combinatorics'''.]]

'''Algebraic combinatorics''' is an area of [[mathematics]] that employs methods of [[abstract algebra]], notably [[group theory]] and [[representation theory]], in various [[combinatorics|combinatorial]] contexts and, conversely, applies combinatorial techniques to problems in [[abstract algebra|algebra]].

==History==
Through the early or mid-1990s, typical combinatorial objects of interest in algebraic combinatorics either admitted a lot of [[symmetry (mathematics)|symmetries]] ([[association scheme]]s, [[strongly regular graph]]s, posets with a [[group action]]) or possessed a rich algebraic structure, frequently of representation theoretic origin ([[symmetric function]]s, [[Young tableaux]]). This period is reflected in the area 05E, ''Algebraic combinatorics'', of the [[American Mathematical Society|AMS]] [[Mathematics Subject Classification]], introduced in 1991.

==Scope==
Algebraic combinatorics has come to be seen more expansively as an area of mathematics where the interaction of combinatorial and algebraic methods is particularly strong and significant. Thus the combinatorial topics may be [[enumerative combinatorics|enumerative]] in nature or involve [[matroid]]s, [[polytope]]s, [[partially ordered set]]s, or [[finite geometry|finite geometries]]. On the algebraic side, besides group and representation theory, [[lattice theory]] and [[commutative algebra]] are common.

==Important topics==

===Symmetric functions===
{{main|Ring of symmetric functions}}
The [[ring of symmetric functions]] is a specific limit of the rings of [[symmetric polynomial]]s in ''n'' indeterminates, as ''n'' goes to infinity. This ring serves as universal structure in which relations between symmetric polynomials can be expressed in a way independent of the number ''n'' of indeterminates (but its elements are neither polynomials nor functions). Among other things, this ring plays an important role in the [[representation theory of the symmetric group]]s.

===Association schemes===
{{main|Association scheme}}

An [[association scheme]] is a collection of [[binary relation]]s satisfying certain compatibility conditions. Association schemes provide a unified approach to many topics, for example [[combinatorial design]]s and [[coding theory]].&lt;ref&gt;{{harvnb|Bannai|Ito|1984}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Godsil|1993}}&lt;/ref&gt; In algebra, association schemes generalize [[group (mathematics)|group]]s, and the theory of association schemes generalizes the [[group character|character theory]] of [[group representation|linear representations]] of groups.&lt;ref&gt;{{harvnb|Bailey|2004|loc=pg. 387}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Zieschang|2005b}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Zieschang|2005a}}&lt;/ref&gt;

===Strongly regular graphs===
{{main|Strongly regular graph}}
A [[strongly regular graph]] is defined as follows.  Let ''G'' = (''V'',''E'') be a [[regular graph]] with ''v'' vertices and degree ''k''.  ''G'' is said to be '''strongly regular''' if there are also [[integer]]s λ and μ such that:

* Every two [[adjacent vertices]] have λ common neighbours.
* Every two non-adjacent vertices have μ common neighbours.

A graph of this kind is sometimes said to be an srg(''v'', ''k'', λ, μ).

Some authors exclude graphs which satisfy the definition trivially, namely those graphs which are the disjoint union of one or more equal-sized [[complete graph]]s,&lt;ref&gt;{{Cite web |url=http://homepages.cwi.nl/~aeb/math/ipm.pdf |title=Brouwer, Andries E; Haemers, Willem H. ''Spectra of Graphs''. p. 101 |access-date=2014-10-10 |archive-url=https://web.archive.org/web/20120316102909/http://homepages.cwi.nl/~aeb/math/ipm.pdf |archive-date=2012-03-16 |dead-url=yes |df= }}&lt;/ref&gt;&lt;ref&gt;Godsil, Chris; Royle, Gordon. ''Algebraic Graph Theory''. Springer-Verlag New York, 2001, p. 218.&lt;/ref&gt; and their [[complement graph|complements]], the [[Turán graph]]s.

===Young tableaux===
{{main|Young tableau}}
A [[Young tableau]] (pl.: ''tableaux'') is a [[combinatorics|combinatorial]] object useful in [[representation theory]] and [[Schubert calculus]]. It provides a convenient way to describe the [[group representation]]s of the [[symmetric group|symmetric]] and [[general linear group|general linear]] groups and to study their properties. Young tableaux were introduced by [[Alfred Young]], a [[mathematician]] at [[University of Cambridge|Cambridge University]], in 1900. They were then applied to the study of the symmetric group by [[Georg Frobenius]] in 1903. Their theory was further developed by many mathematicians, including [[Percy MacMahon]], [[W. V. D. Hodge]], [[Gilbert de Beauregard Robinson|G. de B. Robinson]], [[Gian-Carlo Rota]], [[Alain Lascoux]], [[Marcel-Paul Schützenberger]] and [[Richard P. Stanley]].

===Matroids===
{{main|Matroid}}
A [[matroid]] is a structure that captures and generalizes the notion of [[linear independence]] in [[vector space]]s. There are many equivalent ways to define a matroid, the most significant being in terms of independent sets, bases, circuits, closed sets or flats, closure operators, and rank functions.

Matroid theory borrows extensively from the terminology of [[linear algebra]] and [[graph theory]], largely because it is the abstraction of various notions of central importance in these fields. Matroids have found applications in geometry, [[topology]], [[combinatorial optimization]], [[network theory]] and [[coding theory]].&lt;ref name=Neel2009&gt;{{cite journal|last1=Neel|first1=David L.|last2=Neudauer|first2=Nancy Ann|title=Matroids you have known|journal=Mathematics Magazine|date=2009|volume=82|issue=1|pages=26–41|url=http://www.maa.org/sites/default/files/pdf/shortcourse/2011/matroidsknown.pdf|accessdate=4 October 2014|doi=10.4169/193009809x469020}}&lt;/ref&gt;&lt;ref name=Kashyap2009&gt;{{cite web|last1=Kashyap|first1=Navin|last2=Soljanin|first2=Emina|last3=Vontobel|first3=Pascal|title=Applications of Matroid Theory and Combinatorial Optimization to Information and Coding Theory|url=https://www.birs.ca/workshops/2009/09w5103/report09w5103.pdf|website=www.birs.ca|accessdate=4 October 2014}}&lt;/ref&gt;

===Finite geometries===
{{main|Finite geometry}}
A [[finite geometry]] is any [[geometry|geometric]] system that has only a [[finite set|finite]] number of [[point (geometry)|points]].
The familiar [[Euclidean geometry]] is not finite, because a Euclidean line contains infinitely many points. A geometry based on the graphics displayed on a computer screen, where the [[pixel]]s are considered to be the points, would be a finite geometry. While there are many systems that could be called finite geometries, attention is mostly paid to the finite [[projective space|projective]] and [[affine space]]s because of their regularity and simplicity.  Other significant types of finite geometry are finite [[Möbius plane|Möbius or inversive plane]]s and [[Laguerre plane]]s, which are examples of a general type called [[Benz plane]]s, and their higher-dimensional analogs such as higher finite [[inversive geometry|inversive geometr]]ies.

Finite geometries may be constructed via [[linear algebra]], starting from [[vector space]]s over a [[finite field]]; the affine and [[projective plane]]s so constructed are called [[Galois geometry|Galois geometries]].  Finite geometries can also be defined purely axiomatically. Most common finite geometries are Galois geometries, since any finite [[projective space]] of dimension three or greater is [[isomorphism|isomorphic]] to a projective space over a finite field (that is, the projectivization of a vector space over a finite field). However, dimension two has affine and projective planes that are not isomorphic to Galois geometries, namely the [[non-Desarguesian plane]]s.  Similar results hold for other kinds of finite geometries.

== See also ==

*[[Algebraic graph theory]]
*[[Combinatorial commutative algebra]]
*''[[Journal of Algebraic Combinatorics]]''
*[[Polyhedral combinatorics]]

== References ==
{{reflist}}

==Further reading==
*{{ cite book | last1=Bannai | first1=Eiichi | &lt;!-- authorlink1=Eiichi Bannai | authorlink2= Tatsuro Ito --&gt; | last2=Ito | first2=Tatsuro | title=Algebraic combinatorics I: Association schemes |  publisher=The Benjamin/Cummings Publishing Co., Inc. | location=Menlo Park, CA | year=1984 | pages=xxiv+425 | isbn=0-8053-0490-8 | mr=0882540 }}
* {{cite book|editor-first1=Louis J. |editor-last1=Billera|editor1-link=Louis Billera|editor-first2= Anders|editor-last2= Björner|editor2-link=Anders Björner|editor-first3= Curtis|editor-last3= Greene|editor3-link=Curtis Greene | editor-first4= Rodica|editor-last4= Simion|editor4-link=Rodica Simion|editor-first5=Richard P.|editor-last5= Stanley | editor5-link=Richard P. Stanley |url=http://library.msri.org/books/Book38/index.html|title=New Perspectives in Algebraic Combinatorics|series= MSRI Publications|volume= 38|publisher= 
[[Cambridge University Press]]|year= 1999}}
*{{cite book|first=Chris D.| last=Godsil|authorlink = Chris Godsil|title=Algebraic Combinatorics|publisher=Chapman and Hall|year=1993|location=New York|ISBN=0-412-04131-6 | mr=1220704 }}
* Takayuki Hibi, ''Algebraic combinatorics on convex polytopes'', Carslaw Publications, Glebe, Australia, 1992
*[[Melvin Hochster]], ''Cohen-Macaulay rings, combinatorics, and simplicial complexes''. Ring theory, II (Proc. Second Conf., Univ. Oklahoma, Norman, Okla., 1975), pp.&amp;nbsp;171–223. Lecture Notes in Pure and Appl. Math., vol. 26, Dekker, New York, 1977.
* Ezra Miller, [[Bernd Sturmfels]], ''Combinatorial commutative algebra'', [[Graduate Texts in Mathematics]], vol. 227, Springer-Verlag, New York, NY, 2005.  {{ISBN|0-387-22356-8}}
*[[Richard P. Stanley|Richard Stanley]], ''Combinatorics and commutative algebra''. Second edition, Progress in Mathematics, vol. 41. Birkhäuser, Boston, MA, 1996. {{ISBN|0-8176-3836-9}}
* {{cite book|first=Bernd|last=Sturmfels|authorlink=Bernd Sturmfels|title=Gröbner bases and convex polytopes|series=University Lecture Series|volume=8|publisher= [[American Mathematical Society]]|location= Providence, RI|year= 1996|isbn=0-8218-0487-1}}
*[[Doron Zeilberger]], [http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimPDF/enuPCM.pdf Enumerative and Algebraic Combinatorics], in ''[[The Princeton Companion to Mathematics]]'', 2008.

==External links==
*{{Commonscat-inline}}

[[Category:Algebraic combinatorics| ]]</text>
      <sha1>k3e179wj91kypq43p0kpoj1pdyz4i4c</sha1>
    </revision>
  </page>
  <page>
    <title>Alice Silverberg</title>
    <ns>0</ns>
    <id>44807694</id>
    <revision>
      <id>871758865</id>
      <parentid>868293961</parentid>
      <timestamp>2018-12-03T06:42:10Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>1958</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3019">'''Alice Silverberg''' (born 1958)&lt;ref&gt;Birth year from [http://www.isni.org/isni/0000000028856928 ISNI authority control file], retrieved 2018-12-02.&lt;/ref&gt; is professor of Mathematics and Computer Science at the [[University of California, Irvine]].&lt;ref name="cv"&gt;[http://www.math.uci.edu/~asilverb/cv/index.html curriculum vitae], retrieved 2014-12-22.&lt;/ref&gt; Her research concerns [[number theory]] and [[cryptography]]. With [[Karl Rubin]], she introduced the [[CEILIDH]] system for [[torus-based cryptography]] in 2003.&lt;ref&gt;{{citation|title=Advances in Cryptology - CRYPTO 2003|series=Lecture Notes in Computer Science|volume=2729|year=2003|pages=349–365|publisher=Springer|contribution=Torus-based cryptography|first1=Karl|last1=Rubin|author1-link=Karl Rubin|first2=Alice|last2=Silverberg|doi=10.1007/978-3-540-45146-4_21}}.&lt;/ref&gt;

Silverberg graduated from [[Harvard University]] in 1979,&lt;ref name="cv"/&gt; and received her Ph.D. from [[Princeton University]] in 1984 under the supervision of [[Goro Shimura]].&lt;ref&gt;{{MathGenealogy|id=41540|title=Alice Silverberg}}&lt;/ref&gt; She joined the [[Ohio State University]] faculty in the same year, and moved to Irvine in 2004.&lt;ref name="cv"/&gt;

In 2012, Silverberg became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society]&lt;/ref&gt; She is part of the 2019 class of fellows of the [[Association for Women in Mathematics]].&lt;ref&gt;{{citation|url=https://sites.google.com/site/awmmath/awm-fellows|title=2019 Class of AWM Fellows|publisher=[[Association for Women in Mathematics]]|accessdate=2018-10-07}}&lt;/ref&gt;

In 2017, Silverberg began a blog entitled ''Alice's Adventures in Numberland'', which humorously discusses issues surrounding [[sexism in academia]].  This is a topic which she has previously discussed in interviews,&lt;ref&gt;{{cite web|title=Interview with Alice Silverberg|url=https://www.maa.org/news/distinguished-lecture-series-8|website=Mathematical Association of America|accessdate=10 October 2017}}&lt;/ref&gt; and has been quoted on.&lt;ref&gt;{{cite book|last1=Fine|first1=Cordelia|title=Delusions of gender: The real science behind sex differences|date=2005|publisher=Icon Books Ltd}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
*[http://www.math.uci.edu/~asilverb/ Home page]
*[https://sites.google.com/site/numberlandadventures/ Alice's Adventures in Numberland]

{{authority control}}

{{DEFAULTSORT:Silverberg, Alice}}
[[Category:Living people]]
[[Category:1958 births]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Number theorists]]
[[Category:Harvard University alumni]]
[[Category:Princeton University alumni]]
[[Category:Ohio State University faculty]]
[[Category:University of California, Irvine faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Association for Women in Mathematics]]


{{US-mathematician-stub}}</text>
      <sha1>aiy4q1ye4r79dxkn1zrzq9rnxroqnd9</sha1>
    </revision>
  </page>
  <page>
    <title>Anviksiki</title>
    <ns>0</ns>
    <id>52385740</id>
    <revision>
      <id>865271119</id>
      <parentid>800541422</parentid>
      <timestamp>2018-10-22T21:07:00Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed grandparent category of [[Category:Hindu philosophical concepts]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4464">'''Ānvīkṣikī''' is a term in [[Sanskrit]] denoting roughly the "science of inquiry" and it should have been recognized in India as a distinct branch of learning as early as 650 BCE.&lt;ref name=Satis&gt;{{cite book|last1=Satischandra Vidyabhusana|title=A History of Indian Logic|date=1920|publisher=Motilal Banarsidass|location=Delhi|page=5}}&lt;/ref&gt; However, over the centuries its meaning and import have undergone considerable variations. In the earliest period, the term was used to denote Atma-vidya, the science of the soul, in contrast to Adhyatma-vidya, the spiritual science, or Brahma-vidya, the divine science.&lt;ref name=Satis/&gt; In [[Manu Smriti]] the term  Ānvīkṣikī has been used as equivalent to Atma-vidya and it has been described as a branch of the [[Vedas]].&lt;ref name=Satis/&gt; In the fourth century BCE, [[Kautilya]] in his [[Arthashastra]] recognised it as a distinct branch of learning different from Vedas and other disciplines. Kautilya classifies all disciplines into four categories: scripture (the three Vedas, ''trayi''), agriculture and commerce (''varta''), politics and public administration (''danda-niti''), and ''Ānvīkṣikī'', the investigative reflective science.&lt;ref name=Satis/&gt; The distinction between Atma-vidya and Ānvīkṣikī is that while the former embodied certain dogmatic assertions about the nature of the [[soul]], the latter contained reasons supporting those assertions. Thus Ānvīkṣikī dealt with two subjects, namely, ''[[Ātman (Hinduism)|atma]]'', soul, and ''hetu'', theory of reasons. The [[Samkhya]], [[Yoga]],  and [[Lokayata]], in so far as they treated of reasons affirming or denying the existence of soul, were included by Kautilya in the Ānvīkṣikī.&lt;ref name=Satis2/&gt; Of the two subjects studied in the ambit of Ānvīkṣikī, the study of soul later developed and matured into a separate independent study described by the term ''Darsanas'' (meaning philosophy), and the theory  of    reasons was developed into an independent branch of study referred to as ''Nyaya'' or logic. This bifurcation of Ānvīkṣikī into philosophy and logic must have had its beginning in around 550 BCE with the exposition of the logical side of Ānvīkṣikī by [[Indian logic|Medhatithi Gautama]].&lt;ref name=Satis2&gt;{{cite book|last1=Satischandra Vidyabhusana|title=A History of Indian Logic|date=1920|publisher=Motilal Banarsidass|location=Delhi|page=6}}&lt;/ref&gt; However the term Ānvīkṣikī has been in use in the general sense of a science embracing both the science of soul and the theory of reasons.

It is interesting to observe that when the part of Ānvīkṣikī dealing with the theory of reasons developed into logic, the term Ānvīkṣikī began to be used to denote in this exclusive sense also. For example, [[Manusamhita]] has used this term in this special sense of logic.&lt;ref name=Satis3&gt;{{cite book|last1=Satischandra Vidyabhusana|title=A History of Indian Logic|date=1920|publisher=Motilal Banarsidass|location=Delhi|page=7}}&lt;/ref&gt; Gautama-dharma-sutra, [[Ramayana]], [[Mahabharata]] all have used the term Ānvīkṣikī in this special sense. Ānvīkṣikī in this special sense has also been called by several other names, namely, ''Hetu-sastra'', ''Hetu-vidya'', ''Tarka-sastra'', ''Vada-vidya'', and also by [[Nyaya|Nyaya-sastra]].

==Teachers of Ānvīkṣikī==
There are a few great teachers who wrote about and taught the doctrines of Ānvīkṣikī in the earliest sense of the term, that is, as a study of both philosophy  and logic. [[Charvaka]] (c. 650 BCE), known for his materialistic doctrine, [[Kapila]] (c.  650–575 BCE), known for his doctrine of matter and soul, [[Dattatreya]] (c. 650 BCE), known for his parable of a tree, Punarvasu Atreya (c. 550 BCE), known for his dissertation on senses, Sulabha (c. 550 BCE), a lady ascetic known for canons of speech, [[Ashtavakra]] (c. 550–500 BCE) known as a violent debater, and Medhatithi Gautama (c. 550 BCE), known as the founder of Indian logic, are some of these great teachers.
&lt;ref name=Satis4&gt;{{cite book|last1=Satischandra Vidyabhusana|title=A History of Indian Logic|date=1920|publisher=Motilal Banarsidass|location=Delhi|pages=9–21}}&lt;/ref&gt;

==References==
{{reflist}}

{{Hindudharma}}
{{Indian Philosophy}}
{{Philosophy topics}}
{{Logic|state=collapsed}}

[[Category:Movements in ancient Indian philosophy]]
[[Category:Hindu philosophical concepts]]
[[Category:History of logic]]
[[Category:Nyaya|!]]</text>
      <sha1>kbuivw4kblzfebgady831bpl0rqxg9g</sha1>
    </revision>
  </page>
  <page>
    <title>Binary scaling</title>
    <ns>0</ns>
    <id>7207827</id>
    <revision>
      <id>849921387</id>
      <parentid>849863412</parentid>
      <timestamp>2018-07-12T09:38:04Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>/* Application of binary scaling techniques */ CE</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8848">{{Refimprove|date=December 2009}}
'''Binary scaling''' is a [[computer programming]] technique used typically in embedded [[C (programming language)|C]], [[Digital signal processing|DSP]] and [[assembly language|assembler]] programs to implement [[floating point]] operations by using the native [[integer]] arithmetic of the processor.{{Inconsistent|reason=According to the description below, this does not seem to implement floating point, but fixed point.|date=July 2018}}

==Overview==
A representation of a floating point value using binary scaling is more precise than a floating point representation occupying the same number of bits, but cannot represent values beyond the range that it represents, thus more easily leading to [[arithmetic overflow]] during computation.  Implementation of operations using integer arithmetic instructions is often (but not always) faster than the corresponding floating point instructions.

A position for the 'binary point' is chosen for each variable to be represented, and binary shifts associated with arithmetic operations are adjusted accordingly.

To give an example, a common way to use [[Arbitrary-precision arithmetic|integer arithmetic]] to simulate floating point, using 32 bit numbers, is to multiply the coefficients by 65536.

Using [[binary scientific notation]], this will place the binary point at B16.  That is to say, the most significant 16 bits represent the integer part the remainder are represent the fractional part.  This means, as a signed two's complement integer B16 number can hold a highest value of &lt;math&gt; \approx 32767.9999847 &lt;/math&gt; and a lowest value of −32768.0. Put another way, the B number, is the number of integer bits used to represent the number which defines its value range. Remaining low  bits (i.e. the non-integer bits) are used to store fractional quantities and supply more accuracy.

For instance, to represent 1.2 and 5.6 as B16 one multiplies them by 2&lt;sup&gt;16&lt;/sup&gt;, giving 78643 and 367001.

Multiplying these together gives

 28862059643

To convert it back to B16, divide it by 2&lt;sup&gt;16&lt;/sup&gt;.

This gives 440400B16, which when converted back to a floating point number (by dividing again by 2&lt;sup&gt;16&lt;/sup&gt;, but holding the result as floating point) gives 6.71999.  The correct floating point result is 6.72.

==Re-scaling after multiplication==
The example above for a B16 multiplication is a simplified example. Re-scaling depends on both the B scale value and the word size. B16 is often used in 32 bit systems because it works simply by multiplying and dividing by 65536 (or shifting 16 bits).

Consider the Binary Point in a signed 32 bit word thus:

 0 1 2 3 4 5 6 7 8 9
  S X X X X X X X   X X X X X X X X   X X X X X X X X   X X X X X X X X

where S is the sign bit and X are the other bits.

Placing the binary point at
* 0 gives a range of −1.0 to 0.999999.
* 1 gives a range of −2.0 to 1.999999
* 2 gives a range of −4.0 to 3.999999 and so on.

When using different B scalings and/or word sizes the complete B scaling conversion formula must be used.

Consider a 32 bit word size, and two variables, one with a B scaling of 2 and the other with a scaling of 4.

 1.4 @ B2 is 1.4 * (2 ^ (wordsize-2-1)) == 1.4 * 2 ^ 29 == 0x2CCCCCCD

Note that here the 1.4 values is very well represented with 30 fraction bits. A 32 bit [[IEEE floating-point standard|floating-point number]] has 23 bits to store the fraction in. This is why B scaling is always more accurate than floating point of the same word size.
This is especially useful in [[integrator]]s or repeated summing of small quantities where [[rounding error]] can be a subtle but very dangerous problem when using floating point.

Now a larger number 15.2 at B4.

 15.2 @ B4 is 15.2 * (2 ^ (wordsize-4-1)) == 15.2 * 2 ^ 27 == 0x7999999A

The number of bits to store the fraction is 28 bits.
Multiplying these 32 bit numbers give the 64 bit result {{mono|0x1547AE14A51EB852}}

This result is in B7 in a 64 bit word. Shifting it down by 32 bits gives the result in B7 in 32 bits.

 0x1547AE14

To convert back to floating point, divide this by {{code|1=(2^(wordsize-7-1)) == 21.2800000099}}

Various scalings may be used. B0 for instance can be used to represent any number between -1 and 0.999999999.

=={{anchor|BAM}}Binary angles==
&lt;!-- Binary angle (computing), Binary Angular Measurement System, and Binary radian redirect here --&gt;
[[Image:Binary angles.svg|360px|thumb|Binary scaling (B0) Representation of angles. &lt;span style="color:black"&gt;Black&lt;/span&gt; is traditional degrees representation, &lt;span style="color:green"&gt;green&lt;/span&gt; is floating point representation and &lt;span style="color:red"&gt;red&lt;/span&gt; is [[hexadecimal]] 32-bit representation.]]

Binary angles are mapped using B0, with 0 as 0 degrees, 0.5 as 90° (or &lt;math&gt;\frac{\pi}{2}&lt;/math&gt;), &amp;minus;1.0 or 0.9999999 as 180° (or π) and &amp;minus;0.5 as 270° (or &lt;math&gt;\frac{3\pi}{2}&lt;/math&gt;). When these binary angles are added using normal [[two's complement]] mathematics, the rotation of the angles is correct, even when crossing the sign boundary (this of course does away with checks for angle ≥ 360° when handling normal degrees&lt;ref&gt;[http://blogs.msdn.com/shawnhar/archive/2010/01/04/angles-integers-and-modulo-arithmetic.aspx Angles, integers, and modulo arithmetic] Shawn Hargreaves, ''blogs.msdn.com''&lt;/ref&gt;).

The terms '''binary angular measurement''' ('''BAM''')&lt;ref name="ship"&gt;{{cite web |url=http://www.tpub.com/content/fc/14100/css/14100_314.htm |title=Binary angular measurement |archive-url=https://web.archive.org/web/20091221160257/http://www.tpub.com/content/fc/14100/css/14100_314.htm |archive-date=2009-12-21}}&lt;/ref&gt; and '''binary angular measurement system''' ('''BAMS''')&lt;ref&gt;{{cite web |url=http://acronyms.thefreedictionary.com/Binary+Angular+Measurement+System |title=Binary Angular Measurement System |work=acronyms.thefreedictionary}}&lt;/ref&gt; as well as '''brads''' ('''binary radians''' or '''binary degree''') refer to implementations of binary angles. They find use in robotics, navigation,&lt;ref&gt;[http://www.globalspec.com/reference/14722/160210/Chapter-7-5-3-Binary-Angular-Measure  Real-Time Systems Design and Analysis] Chapter 7.5.3, Binary Angular Measure , Phillip A. LaPlante, page via ''www.globalspec.com''&lt;/ref&gt; computer games,&lt;ref&gt;[http://fabiensanglard.net/doomIphone/doomClassicRenderer.php Doom 1993 code review] Fabien Sanglard, section "Walls", 13/1/2010, ''fabiensanglard.net''&lt;/ref&gt; and digital sensors.&lt;ref&gt;[http://www.hobbyengineering.com/specs/PX-29123.pdf Hitachi HM55B Compass Module (#29123)] {{webarchive |url=https://web.archive.org/web/20110711172521/http://www.hobbyengineering.com/specs/PX-29123.pdf |date=July 11, 2011 }} pdf via ''www.parallax.com'' via ''www.hobbyengineering.com''&lt;/ref&gt;

No matter what bit-pattern is stored in a binary angle, when it is multiplied by 180° (or π) using standard signed [[fixed-point arithmetic]], the result is always a valid angle in the range of −180° [[degree (angle)|degree]]s (−π [[radian]]s) to +180° degrees (+π radians).
In some cases, it is convenient to use unsigned multiplication (rather than signed multiplication) on a binary angle, which gives the correct angle in the range of 0 to +360° degrees (+2π radians or +1 [[turn (geometry)|turn]]).
Compared to storing angles in a binary angle format, storing angles in any other format inevitably results in some bit patterns giving "angles" outside that range, requiring extra steps to [[trigonometric functions#Computation|range-reduce]] the value to the desired range, or results in some bit patterns that are not valid angles at all ([[NaN]]), or both.

==Application of binary scaling techniques==
Binary scaling techniques were used in the 1970s and 1980s for real-time computing that was mathematically intensive, such as [[flight simulation]]. The code was often commented with the binary scalings of the intermediate results of equations.

Binary scaling is still used in many [[digital signal processing|DSP]] applications and custom made microprocessors are usually based on binary scaling techniques.

Binary scaling is currently used in the [[Discrete cosine transform|DCT]] used to compress [[JPEG]] images in utilities such as [[GIMP]].

Although floating point has taken over to a large degree, where speed and extra accuracy are required, binary scaling works on simpler hardware and is more accurate when the range of values is known in advance.{{Clarify|date=March 2016|post-text=→[[Talk:Binary_scaling#Comparison_with_Floating_Point |talk]]}}

==See also==
{{Portal|Computer Science}}
* [[Libfixmath]] – a library written in C for fixed-point math
* [[Q (number format)]]
* [[Minifloat]]
* [[Block floating-point scaling]]

==References==
{{Reflist}}

{{DEFAULTSORT:Binary Scaling}}
[[Category:Binary arithmetic|Scaling]]</text>
      <sha1>2h0lnq9cnydhqtk1uohj990xhc8xdco</sha1>
    </revision>
  </page>
  <page>
    <title>Bing's recognition theorem</title>
    <ns>0</ns>
    <id>15894497</id>
    <revision>
      <id>455610640</id>
      <parentid>339555228</parentid>
      <timestamp>2011-10-14T23:26:45Z</timestamp>
      <contributor>
        <username>Geometry guy</username>
        <id>3483166</id>
      </contributor>
      <comment>subcat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="677">In [[topology]], a branch of mathematics, '''Bing's recognition theorem''', named for [[R. H. Bing]], asserts that a necessary and sufficient condition for a [[3-manifold]] ''M'' to be [[homeomorphism|homeomorphic]] to the [[3-sphere]] is that every [[Jordan curve]] in ''M'' be contained within a topological [[ball (mathematics)|ball]].

==References==
* {{cite journal|last=Bing|first=R. H.|title=Necessary and sufficient condition that the 3-manifold be ''S''&lt;sup&gt;3&lt;/sup&gt;|journal=[[Annals of Mathematics]]|year=1958|volume=68|issue=1|doi=10.2307/1970041|pages=17}}
{{topology-stub}}
[[Category:3-manifolds]]
[[Category:Geometric topology]]
[[Category:Theorems in topology]]</text>
      <sha1>7rkwj734b75rrdc8vnubiljtyl004i6</sha1>
    </revision>
  </page>
  <page>
    <title>Carolyn Mahoney</title>
    <ns>0</ns>
    <id>45467085</id>
    <revision>
      <id>838027207</id>
      <parentid>804463136</parentid>
      <timestamp>2018-04-24T13:54:10Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5944">{{Infobox person
|occupation=mathematician
|employer=[[Lincoln University (Missouri)|Lincoln University of Missouri]]
|birth_date=1946
|birth_place=Memphis, Tennessee}}
'''Carolyn Ray Boone Mahoney''' (born 1946) is an American mathematician who served as president of [[Lincoln University (Missouri)|Lincoln University of Missouri]].&lt;ref name="bwm"/&gt; Her research interests include [[combinatorics]], [[graph theory]], and [[matroid]]s.&lt;ref name="Warren"/&gt;

==Early life and education==
Carolyn Mahoney was born the sixth of thirteen children in 1946 in Memphis, Tennessee to Stephen and Myrtle Boone.  Her grandmother cared for the children while her mother worked.  Mahoney attended Catholic schools where she was encouraged in her interest in mathematics by the nuns.  As a teenager, Mahoney's parents separated due to her father's drinking and gambling and the family was forced to move to a lower-class neighborhood.  Mahoney and her siblings were known for being smart in their neighborhood.  She graduated from Father Bertrand High School in 1964.&lt;ref name=Warren&gt;{{cite book|last1=Warren|first1=Wini|title=Black women scientists in the United States|date=1999|publisher=Indiana University Press|location=Bloomington, Ind. [u.a.]|isbn=0253336031|pages=181–185}}&lt;/ref&gt;

Mahoney attended Mount St. Scholastica College, a Catholic, all-female college in Kansas for three years before finishing her degree in mathematics at [[Siena College (Tennessee)|Siena College]] in [[Memphis, Tennessee]] in 1970.&lt;ref name="Warren" /&gt;  She then earned her master's degree in mathematics in 1972 and a doctorate in 1983, both from [[Ohio State University]].  Her doctorate involved [[matroid]] theory and [[enumerative combinatorics]], and was supervised by Thomas Allan Dowling.  Mahoney says she felt like a foreign student in graduate school because she was in a severe minority.&lt;ref name=Warren/&gt;&lt;ref&gt;{{mathgenealogy|id=10712}}&lt;/ref&gt; She was only the 25th black woman to earn a Ph.D. in mathematics in the U.S.&lt;ref name="owhf"&gt;[http://www.odjfs.state.oh.us/women/halloffame/bio.asp?ID=192 Carolyn Mahoney], [[Ohio Women's Hall of Fame]], retrieved 2015-02-21.&lt;/ref&gt;

==Career==
After earning her doctorate, Mahoney taught first at [[Denison University]] from 1984 to 1989, then at Ohio State for two years.  She also served on the test development committee for the [[College Board]] from 1986 to 1989.  In 1989, Mahoney was the first mathematicians to be selected for the faculty at [[California State University at San Marcos]],&lt;ref name=Warren/&gt; and was one of twelve founding faculty of the San Marcos campus.&lt;ref name="bwm"&gt;[http://www.math.buffalo.edu/mad/PEEPS/mahoney_carolyn.html Carolyn Mahoney], Black Women in Mathematics, Scott W. Williams, State University of New York at Buffalo, retrieved 2015-02-15.&lt;/ref&gt;

In 1994 and 1995, Mahoney served as a program director at the [[National Science Foundation]], and she later worked as an administrator at [[Elizabeth City State University]] in [[North Carolina]].
In 2005, Mahoney was named president of [[Lincoln University (Missouri)|Lincoln University of Missouri]].&lt;ref name="bwm"/&gt; She retired in 2012.&lt;ref&gt;{{citation|url=http://kbia.org/post/lincoln-university-president-retire|title=Lincoln University President to retire|publisher=[[KBIA]]|first=Ryan|last=Fabuliner|date=April 24, 2012}}.&lt;/ref&gt;

==Contributions==
Mahoney's research has focused largely on open problems in graph theory and combinatorics. As well as her thesis work on matroids, she has also published research on the [[Hadwiger–Nelson problem]] concerning the [[chromatic number]] of [[unit distance graph]]s.&lt;ref&gt;{{citation
 | last1 = Chilakamarri | first1 = Kiran B.
 | last2 = Mahoney | first2 = Carolyn R.
 | doi = 10.1007/BF01831139
 | issue = 1-2
 | journal = [[Aequationes Mathematicae]]
 | mr = 1372782
 | pages = 48–67
 | title = Unit-distance graphs, graphs on the integer lattice and a Ramsey type result
 | volume = 51
 | year = 1996}}.&lt;/ref&gt;

She believes that she has had a hard time finding collaborators due to the fact that she is a Black female in mathematics.  She is also a proponent of educational reform, especially supporting cultural diversity in university faculty.  She believes that through the efforts of organizations such as the [[Mathematical Association of America]] and the [[Association for Women in Mathematics]] the environment for women in mathematics has improved.&lt;ref name=Warren/&gt;

==Awards and honors==
In 1989, Mahoney was inducted into the [[Ohio Women's Hall of Fame]].&lt;ref name="owhf"/&gt;

A scholarship at CSU San Marcos&lt;ref&gt;[https://csusm.academicworks.com/opportunities/319 Carolyn Mahoney scholarship], CSU San Marcos, retrieved 2015-02-21.&lt;/ref&gt; and a walking trail at Lincoln University&lt;ref&gt;{{citation|url=http://www.newstribune.com/news/2012/aug/16/lu-celebrates-mahoney-retirement-leadership/ |title=LU celebrates Mahoney retirement, leadership: Curators name portion of Greenway trail in her honor |newspaper=News-Tribune |date=August 16, 2012 |first=Bob |last=Watson |deadurl=yes |archiveurl=https://web.archive.org/web/20150222114202/http://www.newstribune.com/news/2012/aug/16/lu-celebrates-mahoney-retirement-leadership/ |archivedate=2015-02-22 |df= }}.&lt;/ref&gt; have been named in her honor.

==References==
{{Reflist}}

{{Lincoln University (Missouri) presidents}}
{{Ohio Women's Hall of Fame}}
{{Authority control}}

{{DEFAULTSORT:Mahoney, Carolyn}}
[[Category:1946 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:African-American mathematicians]]
[[Category:Ohio State University alumni]]
[[Category:California State University faculty]]
[[Category:Elizabeth City State University faculty]]
[[Category:Presidents of Lincoln University (Missouri)]]
[[Category:Graph theorists]]
[[Category:Mathematicians from Tennessee]]</text>
      <sha1>3vg3d8rdgnvkrudyjs64sb86x2cab54</sha1>
    </revision>
  </page>
  <page>
    <title>Central Council of Church Bell Ringers</title>
    <ns>0</ns>
    <id>34686184</id>
    <revision>
      <id>861476581</id>
      <parentid>857064613</parentid>
      <timestamp>2018-09-27T18:18:31Z</timestamp>
      <contributor>
        <username>Wire723</username>
        <id>7957594</id>
      </contributor>
      <comment>Cleanup 'See also', minor copyedit throughout</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14575">The '''Central Council of Church Bell Ringers''' ('''CCCBR''') is an organisation founded in 1891 which represents ringers of [[church bells]] in the [[Full circle ringing|English style]].&lt;ref&gt;{{cite web|url=https://www.telegraph.co.uk/news/religion/12161771/Ding-dong-for-bell-ringers-as-row-breaks-out-over-bid-to-be-classed-as-a-sport.html|title=Ding-dong for bell ringers as row breaks out over bid to be classed as a sport|date=17 February 2016|work=Telegraph.co.uk}}&lt;/ref&gt;

It acts as a co-ordinating body for education, publicity and codifying [[change ringing]] rules, also for advice on maintaining and restoring full-circle bells. Within England, where the vast majority of English-style rings are located, most towers are affiliated through local ringing associations.

The Central Council also publishes the bell ringers' weekly journal ''The Ringing World''.

==Origins==
Change ringing had developed rapidly in the nineteenth century helped by the formation of the many local ringing associations which had sprung up. However, the need to have a national body with general oversight was increasingly debated, and discussions took place in 1883 about forming one. The eminent ringer, the Revd F.E. Robinson, advocated a National Association to connect the many ringing associations and collect and publish ringing information and performances, but this did not gather much support.&lt;ref name =CFMEW2016/&gt;

However, the bell ringing aristocrat [[Arthur Heywood|Sir Arthur P. Heywood]] still saw the need for standardisation of phraseology and change ringing methods and rules, in addition to representing the interests of ringers as a whole. He saw an alternative solution, which was to have a central "advisory" body.&lt;ref name ="CFMEW2016"&gt;Sir Arthur Percival Heywood and the Central Council of Church Bell Ringers by Chris Mew, CC President.  The Ringing World 22nd April 2016&lt;/ref&gt;

Heywood contrived in 1890 to organise a dinner in Birmingham for the 80th birthday of the noted ringer Henry Johnson, to which representatives of ringing associations from around the country were invited to attend as a “national gathering”. At the dinner he proposed a meeting of representatives from each association to discuss “matters of consequence”.&lt;ref name =CFMEW2016/&gt;

Heywood's ideas of the aims of the prospective Council were:
#To promote the "Exercise" (as change ringing was referred to then) 
#Maintain ringing as organised church work
#Developing the Art (of change ringing)
#To arbitrate on ringing rules

==Early activities==
At the exploratory gathering in 1890 there was strong support for the concept of a central advisory and coordinating body, and the first formal meeting of the new Council took place the following year on Easter Tuesday, 28 March 1891, at the Inns of Court Hotel, London. 74 representatives were present from 33 different societies, and Sir Arthur was elected as the  Council’s first President.

Two Initial Committees were appointed; one to liaise with the Church Congress and a second for bells &amp; fittings. The first meeting debated the definition of [[peal]]s which was a strong current topic, and which has been debated at intervals ever since. Further debate took place in 1892 with general agreement on rules for ringing on 8, 10 and 12 bells but there was divided opinion on ringing on 5 &amp; 6 bells. Such was the dissent that the subject of peal “Decisions” was dropped in 1897 and not raised again until 1911.&lt;ref name =CFMEW2016/&gt;

===Other initiatives===
In 1903 the Church Press Committee was formed to compile biographies of ringers, this was a forerunner of the present-day Biographies Committee. Over the period 1899-1900 a survey was made of the condition of bells across the country. One aspect of interest in towers were experiments in tower movement measurement, another aspect of work which today rests with the Towers &amp; Belfries Committee.&lt;ref name =CFMEW2016/&gt;

===Railway travel===
Amongst the seemingly more unusual committees formed was that seeking concessionary fares upon the railways which were the only form of long distance transport to get to meetings, peals and other ringing events. Concessions were sometimes granted and bell ringers were included along with theatre companies and other groups qualifying for reductions right up until the early 1960s.&lt;ref name =CFMEW2016/&gt;

===The roll of honour===
At the London meeting in 1921 the names of over 1,000 ringers who had perished in the War was read out. The Council instituted the first volume of Rolls of Honour which has been followed on to this day with much modern research.&lt;ref name =CFMEW2016/&gt;

===Broadcasting===
It was the start of radio broadcasts in 1925 which prompted interest in seeing that properly considered broadcasts of ringing came across.This was followed by television and now social media all of which are part and parcel of the Public Relations Committee work. This does of course extend to public awareness and campaigns to ringing for special occasions particularly those with national importance like HM Queen’s 90th birthday.&lt;ref name =CFMEW2016/&gt;

===Library and publications ===
The Central Council Library is an important collection of books on bell ringing and campanology.

In 1916 Sir A.P. Heywood died, and left his ringing books to the Cambridge University Guild which decided to donate them as the basis of a library for the Central Council in 1920.

The Rev. C.W.O. Jenkyn was the first librarian. He was succeeded as librarian by the Rev. Bernard Tyrwhitt-Drake of Walsoken, then by Wilfrid J. Hooton, and in 1953, Frederick Sharpe F.S.A. well known as a writer on historical aspects of bells and ringing. In 1958 Frank Perrens of Coventry was appointed until 1968.

in 1976, when William T. Cook was elected, and with his appointment the rate of accessions increased, and at the time of his death in 1992 there were over 2,000 catalogue entries, some of which represent multiple items. Thus, for instance, a set of Guild or Association reports, perhaps over 100 in number, is represented by a single catalogue number. The present incumbent is  Dr. John C. Eisel,  although his title is now that of Steward of the Library.&lt;ref&gt;History of the library of the Central Council. Central Council of Church Bell Ringers. Retrieved March 2017&lt;/ref&gt;

==Present-day operation==
The Council meets annually at Spring Bank Holiday weekend in various parts of the UK. Major policy decisions are discussed and the reports of the many committees are received. However,much of the Council's work is done in committee.

===Committees===
Most of the committees are concerned with the normal minutiae of an organisation: administration, various records/archives.  However, there are some highly esoteric committees such as [[Method ringing|Methods]], which is concerned with defining and recording methods and principles. It lays down the criteria for accepting peals, including quarter and half peals, which was a topic of the early council meetings, and still excites debate today.&lt;ref&gt;{{cite web|url=http://www.chardandilminsternews.co.uk/news/village_news/13889864.World_record_for_South_Petherton_bell_ringers/|title=World record for South Petherton bell ringers|work=Chard &amp; Ilminster News}}&lt;/ref&gt;

The current (2016) committees are:&lt;ref name="Ringing world 6th May 2016"&gt;Ringing world 6th May 2016&lt;/ref&gt;

* Administrative
* Methods
* Peal records
* Public relations
* Publications
* Ringing Centres
* Ringing trends
* Towers and belfries
* Tower Stewardship
* Bell restoration
* Biographies
* Compositions
* Education
* Information and communications technology
* Library

==''The Ringing World''==
''The Ringing World'' is a weekly journal devoted entirely to bell ringing and is the official journal of the Central Council for Church Bell Ringers. It is published in the UK as a paper periodical and an online edition. It records notable ringing performances, carries features on bells, change ringing, bell towers and ringers, it is a platform for correspondence, and advertises ringing events and publishes obituaries. It is the "journal of record for performances" in ringing, and peals must be published in it.&lt;ref name=Harrison&gt;{{Cite book|last=Harrison|first=John|title=Bells and Bellringing|publisher=Bloomsbury Publishing|year=2016|ISBN=978-0-74781-433-7}}&lt;/ref&gt;

It was first published in 1911 from [[Guildford]] as a weekly periodical to report ringing news and details of [[peal]]s and quarter peals rung around the world. Its founder and first editor was John Sparkes Goldsmith, who was born at [[Lewes|Southover, Lewes]], on 13 January 1878 and died on 1 June 1942.&lt;ref&gt;John Eisel 25 March 2011 "John Sparkes Goldsmith" ''The Ringing World'', Andover Issue No 5213 25 March 2011 pp273-275&lt;/ref&gt; Following his death the Central Council guaranteed the publications against losses, until in 1945 it was decided to acquire it. Subsequently, from 1983 the journal would be constituted as a self-standing charitable body but still answerable to Council members.

In 2011, celebrations of the 100 year anniversary of the magazine were held nationally, with open ringing round London churches, and a service at [[Westminster Abbey]].&lt;ref&gt;{{cite web|title=Centenary of The Ringing World celebrated at Westminster Abbey|url=http://www.westminster-abbey.org/press/news/2011/march/centenary-of-the-ringing-world-celebrated-at-westminster-abbey|website=www.westminster-abbey.org|accessdate=7 June 2016}}&lt;/ref&gt;

In 2016 readers of the magazine wrote to insist that bell ringing was "an art and a sport", as demonstrated by regular "striking competitions." It was suggested that classification of change ringing as a sport by [[Sport England]] could save it from becoming obsolete. But the Central Council of Church Bell Ringers opposed the move, suggesting that it would jeopardise its relationship with church bodies, since bell ringing should be seen as part of [[Christian worship]], not exercise. The council's president, Chris Mew, said: "Where is the glamour of the sports field and where are the David Beckhams of the belfry?"&lt;ref&gt;{{cite web|last=Jamieson |first=Sophie |url=https://www.telegraph.co.uk/news/religion/12161771/Ding-dong-for-bell-ringers-as-row-breaks-out-over-bid-to-be-classed-as-a-sport.html |title=Ding-dong for bell ringers as row breaks out over bid to be classed as a sport |publisher=''[[The Daily Telegraph]]'' |date=19 February 2014 |accessdate=19 February 2016}}&lt;/ref&gt;

== Membership ==
The members of the CCCBR are either representative, life members or co-opted. There are representatives for 65 affiliated organisations from the British Isles and territorial organisations throughout the world who serve for a three-year term.  The council may itself elect both members and life members for past services to ringing.

As of May 2016 there are: life members – 6, additional members – 10, ex-officio members – 7.&lt;ref name="Ringing world 6th May 2016"/&gt;

===List of affiliated ringing societies===
As of March 2017,&lt;ref&gt;Retrieved from Central Council website March 2017&lt;/ref&gt; the following 67 societies are affiliated members of the Central Council.

* [[Ancient Society of College Youths]] (4 CC Reps),
* [[The Australian and New Zealand Association of Bellringers|Australian and New Zealand Association]] (4 CC Reps),
* Barrow and District Society (1 CC Reps),
* Bath and Wells Diocesan Association (5 CC Reps),
* Bedfordshire Association (3 CC Reps),
* Beverley and District Society (2 CC Reps),
* Cambridge University Guild (2 CC Reps),
* Carlisle Diocesan Guild (2 CC Reps),
* Chester Diocesan Guild (4 CC Reps),
* Coventry Diocesan Guild (4 CC Reps),
* Derby Diocesan Association (4 CC Reps),
* Devon Association (2 CC Reps),
* Devonshire Guild (4 CC Reps),
* Dorset County Association (2 CC Reps),
* Durham and Newcastle Diocesan Association (4 CC Reps),
* Durham University Society (1 CC Reps),
* East Derbyshire &amp; West Nottinghamshire Association (1 CC Reps),
* East Grinstead and District Guild (1 CC Reps),
* Ely Diocesan Association (4 CC Reps),
* Essex Association (5 CC Reps),
* Four Shires Guild (2 CC Reps),
* Gloucester and Bristol Diocesan Association (5 CC Reps),
* Guildford Diocesan Guild (4 CC Reps),
* Hereford Diocesan Guild (4 CC Reps),
* Hertford County Association (4 CC Reps),
* Irish Association (3 CC Reps),
* Kent County Association (5 CC Reps),
* Ladies' Guild (3 CC Reps),
* Lancashire Association (5 CC Reps),
* Leeds University Society (1 CC Reps),
* Leicester Diocesan Guild (4 CC Reps),
* Lichfield &amp; Walsall Archdeaconry Society (3 CC Reps),
* Lincoln Diocesan Guild (4 CC Reps),
* Liverpool Universities Society (1 CC Reps),
* Llandaff and Monmouth Diocesan Association (3 CC Reps),
* Middlesex County Association &amp; London Diocesan Guild (4 CC Reps)
* National Police Guild (1 CC Reps),
* North American Guild (4 CC Reps),
* North Staffordshire Association (2 CC Reps),
* North Wales Association (2 CC Reps),
* Norwich Diocesan Association (4 CC Reps),
* Oxford Diocesan Guild (6 CC Reps),
* Oxford Society (1 CC Reps),
* Oxford University Society (1 CC Reps),
* Peterborough Diocesan Guild (4 CC Reps),
* Salisbury Diocesan Guild (5 CC Reps),
* Scottish Association (2 CC Reps),
* Shropshire Association (2 CC Reps),
* Society of Royal Cumberland Youths (3 CC Reps),
* Society of Sherwood Youths (1 CC Reps),
* South African Guild (1 CC Reps),
* Southwell and Nottingham Diocesan Guild (4 CC Reps),
* St Agatha's Guild (1 CC Reps),
* St David's Diocesan Guild (1 CC Reps),
* St Martin's Guild for the Diocese of Birmingham (2 CC Reps)
* Suffolk Guild (4 CC Reps),
* Surrey Association (4 CC Reps),
* Sussex County Association (5 CC Reps),
* Swansea and Brecon Diocesan Guild (2 CC Reps),
* Truro Diocesan Guild (5 CC Reps),
* University of Bristol Society (2 CC Reps),
* University of London Society (1 CC Reps),
* Veronese, Associazione Suonatori di Campane a Sistema (Italy) (2 CC Reps),
* Winchester and Portsmouth Diocesan Guild (5 CC Reps),
* Worcestershire and Districts Association (4 CC Reps),
* Yorkshire Association (5 CC Reps),

== See also ==

* [[Dove's Guide for Church Bell Ringers]]

==References==
{{reflist}}

== External links ==
*{{Official website}}
* [http://bb.ringingworld.co.uk/ Bellboard - online update on current change ringing performances.]
*[http://www.methods.org.uk/archive/ccdecs.htm Central Council decisions] – includes the Council's definition of a peal
{{Bells}}

[[Category:Bell ringing organisations]]
[[Category:Permutations]]
[[Category:Music organisations based in the United Kingdom]]</text>
      <sha1>0fsomswh0d0glbsx9bgjqj6z0nmbtbf</sha1>
    </revision>
  </page>
  <page>
    <title>Coarse function</title>
    <ns>0</ns>
    <id>28119956</id>
    <revision>
      <id>840691545</id>
      <parentid>475217425</parentid>
      <timestamp>2018-05-11T14:38:23Z</timestamp>
      <contributor>
        <username>Bear-rings</username>
        <id>28216728</id>
      </contributor>
      <comment>/* See also */ - link in article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="720">{{One source|date=July 2010}}
In mathematics, '''coarse functions''' are [[Function (mathematics)|functions]] that may appear to be continuous at a distance, but in reality are not necessarily continuous.&lt;ref name="coarsepdf"&gt;Chul-Woo Lee and Jared Duke (2007), [http://www.rose-hulman.edu/mathjournal/archives/2007/vol8-n2/paper4/v8n2-4pd.pdf Coarse Function Value Theorems]. ''Rose-Hulman Undergraduate Mathematics Journal'' '''8''' (2)&lt;/ref&gt; Although [[continuous function]]s are usually observed on a small scale, coarse functions are usually observed on a large scale.&lt;ref name="coarsepdf" /&gt;

== See also ==
* [[Coarse structure]]

== References ==

{{Reflist}}

[[Category:Types of functions]]


{{geometry-stub}}</text>
      <sha1>drboypj3awc4en8nnnwevwyp7wz8jg9</sha1>
    </revision>
  </page>
  <page>
    <title>Deep belief network</title>
    <ns>0</ns>
    <id>41416740</id>
    <revision>
      <id>867968241</id>
      <parentid>867895105</parentid>
      <timestamp>2018-11-09T03:50:17Z</timestamp>
      <contributor>
        <username>Davemck</username>
        <id>326639</id>
      </contributor>
      <minor/>
      <comment>rmv duplicate parm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9708">[[Image:Deep belief net.svg|thumb|Schematic overview of a deep belief net. Arrows represent directed connections in the [[graphical model]] that the net represents.]]
{{machine learning bar}}

In [[machine learning]], a '''deep belief network''' ('''DBN''') is a [[generative model|generative]] [[graphical model]], or alternatively a class of [[deep learning|deep]] [[artificial neural network|neural network]], composed of multiple layers of [[latent variables]] ("hidden units"), with connections between the layers but not between units within each layer.&lt;ref name="scholar"&gt;{{Cite journal | vauthors = Hinton G | title = Deep belief networks | doi = 10.4249/scholarpedia.5947 | journal = Scholarpedia | volume = 4 | issue = 5 | pages = 5947 | year = 2009 | pmid = | url = http://www.scholarpedia.org/article/Deep_belief_networks}}&lt;/ref&gt;

When trained on a [[training set|set of examples]] [[Unsupervised learning|without supervision]], a DBN can learn to probabilistically reconstruct its inputs. The layers then act as [[Feature learning|feature detector]]s.&lt;ref name="scholar" /&gt; After this learning step, a DBN can be further trained with [[supervised learning|supervision]] to perform [[Statistical classification|classification]].&lt;ref name="hinton06"/&gt;

DBNs can be viewed as a composition of simple, unsupervised networks such as [[restricted Boltzmann machine]]s (RBMs)&lt;ref name="scholar"/&gt; or [[autoencoder]]s,&lt;ref&gt;{{cite conference | first1 = Yoshua | last1 = Bengio | first2 = Pascal | last2 = Lamblin | first3 = Dan | last3 = Popovici | first4 = Hugh | last4 = Larochelle | name-list-format = vanc |title=Greedy Layer-Wise Training of Deep Networks |conference=[[Conference on Neural Information Processing Systems|NIPS]] |year=2007 |url=http://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf}}&lt;/ref&gt; where each sub-network's hidden layer serves as the visible layer for the next. An RBM is an [[Undirected graph|undirected]], generative energy-based model with a "visible" input layer and a hidden layer and connections between but not within layers. This composition leads to a fast, layer-by-layer unsupervised training procedure, where [[contrastive divergence]] is applied to each sub-network in turn, starting from the "lowest" pair of layers (the lowest visible layer is a [[training set]]).

The observation&lt;ref name="hinton06"&gt;{{cite journal | vauthors = Hinton GE, Osindero S, Teh YW | title = A fast learning algorithm for deep belief nets | journal = Neural Computation | volume = 18 | issue = 7 | pages = 1527–54 | date = July 2006 | pmid = 16764513 | doi = 10.1162/neco.2006.18.7.1527 | url = http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf | authorlink1 = Geoff Hinton }}&lt;/ref&gt; that DBNs can be trained [[greedy algorithm|greedily]], one layer at a time, led to one of the first effective [[deep learning]] algorithms.&lt;ref&gt;{{Cite journal | last1 = Bengio | first1 = Y. | doi = 10.1561/2200000006 | title = Learning Deep Architectures for AI | journal = Foundations and Trends in Machine Learning | volume = 2 | pages = | year = 2009 | pmid =  | url = http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf}}&lt;/ref&gt;{{rp|6}} Overall, there are many attractive implementations and uses of DBNs in real-life applications and scenarios (e.g., [[electroencephalography]]&lt;ref&gt;{{cite journal | vauthors = Movahedi F, Coyle JL, Sejdic E | title = Deep Belief Networks for Electroencephalography: A Review of Recent Contributions and Future Outlooks | language = en-US | journal = IEEE Journal of Biomedical and Health Informatics | volume = 22 | issue = 3 | pages = 642–652 | date = May 2018 | pmid = 28715343 | pmc = 5967386 | doi = 10.1109/jbhi.2017.2727218 | url = https://ieeexplore.ieee.org/document/7981315/ }}&lt;/ref&gt;, [[drug discovery]]&lt;ref&gt;{{cite journal |last1=Ghasemi  |first1=Pérez-Sánchez|last2=Mehri |first2= Pérez-Garrido |year=2018 |title= Neural network and deep-learning algorithms used in QSAR studies: merits and drawbacks |journal=Drug Discovery Today |volume=23 |issue=10 |pages=1784-1790 |doi=10.1016/j.drudis.2018.06.016}}&lt;/ref&gt; &lt;ref&gt;{{cite journal |last1=Ghasemi  |first1=Pérez-Sánchez|last2=Mehri |first2= fassihi |title= The Role of Different Sampling Methods in Improving Biological Activity Prediction Using Deep Belief Network |journal=Journal of Computational Chemistry|year=2016 |issue=10 |pages=1-8 |doi=10.1002/jcc.24671}}&lt;/ref&gt; &lt;ref&gt;{{cite journal | vauthors = Gawehn E, Hiss JA, Schneider G | title = Deep Learning in Drug Discovery | journal = Molecular Informatics | volume = 35 | issue = 1 | pages = 3–14 | date = January 2016 | pmid = 27491648 | doi = 10.1002/minf.201501008 | url = http://doi.wiley.com/10.1002/minf.201501008 }}&lt;/ref&gt;). 

== Training ==
[[File:Restricted_Boltzmann_machine.svg|link=https://en.wikipedia.org/wiki/File:Restricted_Boltzmann_machine.svg|thumb|A [[restricted Boltzmann machine]] (RBM) with fully connected visible and hidden units. Note there are no hidden-hidden or visible-visible connections.]]
The training method for RBMs proposed by [[Geoffrey Hinton]] for use with training "Product of Expert" models is called [[contrastive divergence]] (CD).&lt;ref name="POE"&gt;{{cite journal | vauthors = Hinton GE | url = http://www.cs.toronto.edu/~fritz/absps/nccd.pdf | title = Training Product of Experts by Minimizing Contrastive Divergence | journal = Neural Computation | volume = 14 | pages = 1771–1800 | date = 2002 }}&lt;/ref&gt; CD provides an approximation to the [[maximum likelihood]] method that would ideally be applied for learning the weights.&lt;ref name="RBMTRAIN2"&gt;{{Cite journal | vauthors = Hinton GE |date=2010|title=A Practical Guide to Training Restricted Boltzmann Machines|url=https://www.researchgate.net/publication/221166159_A_brief_introduction_to_Weightless_Neural_Systems|journal=Tech. Rep. UTML TR 2010-003,|volume=|pages=|via=}}&lt;/ref&gt;&lt;ref name="RBMTutorial"&gt;{{cite journal | vauthors = Fischer A, Igel C |year=2014|title=Training Restricted Boltzmann Machines: An Introduction|url=http://image.diku.dk/igel/paper/TRBMAI.pdf|format=PDF|journal=Pattern Recognition|volume=47|issue=|pages=25–39|doi=10.1016/j.patcog.2013.05.025 }}&lt;/ref&gt; In training a single RBM, weight updates are performed with [[gradient descent]] via the following equation: &lt;math&gt; w_{ij}(t+1) = w_{ij}(t) + \eta\frac{\partial \log(p(v))}{\partial w_{ij}} &lt;/math&gt;

where, &lt;math&gt;p(v)&lt;/math&gt; is the probability of a visible vector, which is given by &lt;math&gt;p(v) = \frac{1}{Z}\sum_he^{-E(v,h)}&lt;/math&gt;. &lt;math&gt; Z &lt;/math&gt; is the partition function (used for normalizing) and &lt;math&gt;E(v,h)&lt;/math&gt; is the energy function assigned to the state of the network. A lower energy indicates the network is in a more "desirable" configuration. The gradient &lt;math&gt;\frac{\partial \log(p(v))}{\partial w_{ij}}&lt;/math&gt; has the simple form &lt;math&gt;\langle v_ih_j\rangle_\text{data} - \langle v_ih_j\rangle_\text{model}&lt;/math&gt; where &lt;math&gt;\langle\cdots\rangle_p&lt;/math&gt; represent averages with respect to distribution &lt;math&gt;p&lt;/math&gt;. The issue arises in sampling &lt;math&gt;\langle v_ih_j\rangle_\text{model}&lt;/math&gt; because this requires extended alternating [[Gibbs sampling]]. CD replaces this step by running alternating Gibbs sampling for &lt;math&gt;n&lt;/math&gt; steps (values of &lt;math&gt;n = 1&lt;/math&gt; perform well). After &lt;math&gt;n&lt;/math&gt; steps, the data are sampled and that sample is used in place of &lt;math&gt;\langle v_ih_j\rangle_\text{model}&lt;/math&gt;. The CD procedure works as follows:&lt;ref name="RBMTRAIN2" /&gt;
# Initialize the visible units to a training vector.
# Update the hidden units in parallel given the visible units: &lt;math&gt;p(h_j = 1 \mid \textbf{V}) = \sigma(b_j + \sum_i v_iw_{ij})&lt;/math&gt;. &lt;math&gt;\sigma&lt;/math&gt; is the [[sigmoid function]] and &lt;math&gt;b_j&lt;/math&gt; is the bias of &lt;math&gt;h_j&lt;/math&gt;.
# Update the visible units in parallel given the hidden units: &lt;math&gt;p(v_i = 1 \mid \textbf{H}) = \sigma(a_i + \sum_j h_jw_{ij})&lt;/math&gt;. &lt;math&gt;a_i&lt;/math&gt; is the bias of &lt;math&gt;v_i&lt;/math&gt;. This is called the "reconstruction" step.
# Re-update the hidden units in parallel given the reconstructed visible units using the same equation as in step 2.
# Perform the weight update: &lt;math&gt;\Delta w_{ij} \propto \langle v_ih_j\rangle_\text{data} - \langle v_ih_j\rangle_\text{reconstruction}&lt;/math&gt;.
Once an RBM is trained, another RBM is "stacked" atop it, taking its input from the final trained layer. The new visible layer is initialized to a training vector, and values for the units in the already-trained layers are assigned using the current weights and biases. The new RBM is then trained with the procedure above. This whole process is repeated until the desired stopping criterion is met.&lt;ref name="BENGIODEEP"&gt;{{cite journal|last=Bengio|first=Yoshua | name-list-format = vanc |year=2009|title=Learning Deep Architectures for AI |url= http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20%282009%29.pdf |journal=Foundations and Trends in Machine Learning|volume=2|issue=1|pages=1–127|doi=10.1561/2200000006}}&lt;/ref&gt;

Although the approximation of CD to maximum likelihood is crude (does not follow the gradient of any function), it is empirically effective.&lt;ref name="RBMTRAIN2" /&gt;

== See also ==
* [[Bayesian network]]
* [[Deep learning]]

== References ==
{{reflist}}

== External links ==
* {{cite web |title=Deep Belief Networks |website=Deep Learning Tutorials |url=http://deeplearning.net/tutorial/DBN.html}}
* {{cite web |title=Deep Belief Network Example |website=Deeplearning4j Tutorials |url=http://deeplearning4j.org/deepbeliefnetwork.html}}

[[Category:Artificial neural networks]]
[[Category:Probabilistic models]]</text>
      <sha1>f4g78u5eq9earro5jn0yiqvjrc247hr</sha1>
    </revision>
  </page>
  <page>
    <title>Dirichlet series</title>
    <ns>0</ns>
    <id>393258</id>
    <revision>
      <id>862708765</id>
      <parentid>852435045</parentid>
      <timestamp>2018-10-06T05:15:40Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19075">In [[mathematics]], a '''Dirichlet series''' is any [[series (mathematics)|series]] of the form

:&lt;math&gt;\sum_{n=1}^\infty \frac{a_n}{n^s},&lt;/math&gt;

where ''s'' is [[Complex number|complex]], and &lt;math&gt;a_n&lt;/math&gt; is a complex [[sequence]]. It is a special case of [[general Dirichlet series]].

Dirichlet series play a variety of important roles in [[analytic number theory]]. The most usually seen definition of the [[Riemann zeta function]] is a Dirichlet series, as are the [[Dirichlet L-function]]s. It is conjectured that the [[Selberg class]] of series obeys the [[generalized Riemann hypothesis]]. The series is named in honor of [[Peter Gustav Lejeune Dirichlet]].

==Combinatorial importance==
Dirichlet series can be used as generating series for counting weighted sets of objects with respect to a weight which is combined multiplicatively when taking Cartesian products.

Suppose that ''A'' is a set with a function ''w'': ''A'' → '''N''' assigning a weight to each of the elements of ''A'', and suppose additionally that the [[Fiber (mathematics)|fibre]] over any natural number under that weight is a finite set. (We call such an arrangement (''A'',''w'') a weighted set.) Suppose additionally that ''a&lt;sub&gt;n&lt;/sub&gt;'' is the number of elements of ''A'' with weight ''n''. Then we define the formal Dirichlet generating series for ''A'' with respect to ''w'' as follows:

:&lt;math&gt;\mathfrak{D}^A_w(s) = \sum_{a \in A} \frac 1 {w(a)^s} = \sum_{n=1}^\infty \frac{a_n}{n^s}&lt;/math&gt;

Note that if ''A'' and ''B'' are disjoint subsets of some weighted set (''U'', ''w''), then the Dirichlet series for their (disjoint) union is equal to the sum of their Dirichlet series:

:&lt;math&gt;\mathfrak{D}^{A\uplus B}_w(s) = \mathfrak{D}^A_w(s) + \mathfrak{D}^B_w(s).&lt;/math&gt;

Moreover, if (''A'', ''u'') and (''B'', ''v'') are two weighted sets, and we define a weight function ''w'': ''A'' × ''B'' → '''N''' by

:&lt;math&gt;w(a,b) = u(a) v(b),&lt;/math&gt;

for all ''a'' in ''A'' and ''b'' in ''B'', then we have the following decomposition for the Dirichlet series of the Cartesian product:

:&lt;math&gt;\mathfrak{D}^{A\times B}_w(s) = \mathfrak{D}^{A}_u(s) \cdot \mathfrak{D}^{B}_v(s).&lt;/math&gt;

This follows ultimately from the simple fact that &lt;math&gt;n^{-s} \cdot m^{-s} = (nm)^{-s}.&lt;/math&gt;

==Examples==
The most famous of Dirichlet series is

: &lt;math&gt;\zeta(s)=\sum_{n=1}^\infty \frac 1 {n^s},&lt;/math&gt;

which is the [[Riemann zeta function]].

Treating these as formal Dirichlet series for the time being in order to be able to ignore matters of convergence, note that we have:

: &lt;math&gt;
\begin{align}
\zeta(s) &amp;= \mathfrak{D}^{\mathbb{N}}_{\operatorname{id}}(s) = \prod_{p\text{ prime}} \mathfrak{D}^{\{p^n : n \in \mathbb{N}\}}_{\operatorname{id}}(s) = \prod_{p\text{ prime}} \sum_{n \in \mathbb{N}}  \mathfrak{D}^{\{p^n\}}_{\operatorname{id}}(s) \\
&amp; = \prod_{p\text{ prime}} \sum_{n \in \mathbb{N}} \frac{1}{(p^n)^s} = \prod_{p\text{ prime}} \sum_{n \in \mathbb{N}} \left(\frac{1}{p^s}\right)^n = \prod_{p\text{ prime}} \frac{1}{1-p^{-s}}
\end{align},
&lt;/math&gt;

as each natural number has a unique multiplicative decomposition into powers of primes. It is this bit of combinatorics which inspires the [[Riemann zeta function#Euler product formula|Euler product formula]].

Another is:

:&lt;math&gt;\frac{1}{\zeta(s)}=\sum_{n=1}^\infty \frac{\mu(n)}{n^s}&lt;/math&gt;

where ''μ''(''n'') is the [[Möbius function]]. This and many of the following series may be obtained by applying [[Möbius inversion]] and [[Dirichlet convolution]] to known series. For example, given a [[Dirichlet character]] ''χ''(''n'') one has

:&lt;math&gt;\frac 1 {L(\chi,s)}=\sum_{n=1}^\infty \frac{\mu(n)\chi(n)}{n^s}&lt;/math&gt;

where ''L''(''χ'', ''s'') is a [[Dirichlet L-function]].

Other identities include

:&lt;math&gt;\frac{\zeta(s-1)}{\zeta(s)}=\sum_{n=1}^{\infty} \frac{\varphi(n)}{n^s}&lt;/math&gt;

where &lt;math&gt;\varphi&lt;/math&gt;(''n'') is the [[totient function]],

:&lt;math&gt;\frac{\zeta(s-k)}{\zeta(s)} = \sum_{n=1}^\infty \frac{J_k(n)}{n^s}&lt;/math&gt;

where ''J&lt;sub&gt;k&lt;/sub&gt;'' is the [[Jordan's totient function|Jordan function]], and

:&lt;math&gt;
\begin{align}
&amp; \zeta(s) \zeta(s-a)=\sum_{n=1}^\infty \frac{\sigma_{a}(n)}{n^s} \\[6pt]
&amp; \frac{\zeta(s)\zeta(s-a)\zeta(s-2a)}{\zeta(2s-2a)} = \sum_{n=1}^\infty \frac{\sigma_a(n^2)}{n^s} \\[6pt]
&amp; \frac{\zeta(s)\zeta(s-a)\zeta(s-b)\zeta(s-a-b)}{\zeta(2s-a-b)} = \sum_{n=1}^\infty \frac{\sigma_a(n)\sigma_b(n)}{n^s}
\end{align}
&lt;/math&gt;

where σ&lt;sub&gt;''a''&lt;/sub&gt;(''n'') is the [[divisor function]]. By specialisation to the divisor function ''d''&amp;nbsp;=&amp;nbsp;''σ''&lt;sub&gt;0&lt;/sub&gt; we have

:&lt;math&gt;
\begin{align}
\zeta^2(s) &amp; =\sum_{n=1}^\infty \frac{d(n)}{n^s} \\[6pt]
\frac{\zeta^3(s)}{\zeta(2s)} &amp; =\sum_{n=1}^\infty \frac{d(n^2)}{n^s} \\[6pt]
\frac{\zeta^4(s)}{\zeta(2s)} &amp; =\sum_{n=1}^\infty \frac{d(n)^2}{n^s}.
\end{align}
&lt;/math&gt;

The logarithm of the zeta function is given by

:&lt;math&gt;\log \zeta(s)=\sum_{n=2}^\infty \frac{\Lambda(n)}{\log(n)}\,\frac{1}{n^s}&lt;/math&gt;

for Re(''s'')&amp;nbsp;&gt;&amp;nbsp;1. 
Similarly, we have that

:&lt;math&gt;-\zeta^{\prime}(s) = \sum_{n=2}^{\infty} \frac{\log(n)}{n^s},\ \Re(s) &gt; 1.&lt;/math&gt;

Here, Λ(''n'') is the [[von Mangoldt function]].  The [[logarithmic derivative]] is then

:&lt;math&gt;\frac {\zeta^\prime(s)}{\zeta(s)} = -\sum_{n=1}^\infty \frac{\Lambda(n)}{n^s}.&lt;/math&gt;

These last three are special cases of a more general relationship for derivatives of Dirichlet series, given below.

Given the [[Liouville function]] ''λ''(''n''), one has

:&lt;math&gt;\frac {\zeta(2s)}{\zeta(s)} = \sum_{n=1}^\infty \frac{\lambda(n)}{n^s}.&lt;/math&gt;

Yet another example involves [[Ramanujan's sum]]:

:&lt;math&gt;\frac{\sigma_{1-s}(m)}{\zeta(s)}=\sum_{n=1}^\infty\frac{c_n(m)}{n^s}.&lt;/math&gt;

Another pair of examples involves the [[Möbius function]] and the [[prime omega function]]]:&lt;ref&gt;The formulas for both series are given in Section 27.4 of the [https://dlmf.nist.gov/27.4  NIST Handbook of Mathematical Functions]/&lt;/ref&gt;

:&lt;math&gt; \frac{\zeta(s)}{\zeta(2s)} = \sum_{n=1}^\infty \frac{|\mu(n)|}{n^s} \equiv \sum_{n=1}^\infty \frac{\mu^2(n)}{n^s}. &lt;/math&gt;
:&lt;math&gt; \frac{\zeta^2(s)}{\zeta(2s)} = \sum_{n=1}^\infty \frac{2^{\omega(n)}}{n^s} \equiv \sum_{n=1}^\infty \frac{\mu^2(n)}{n^s}. &lt;/math&gt;

&lt;!-- 
('''Possible error:  It seems that these last 2 examples cannot both be correct?''' No these look correct to me. Observe that the Dirichlet series of a Dirichlet convolution is the product of Dirichlet series, and that the Dirichlet series of &lt;math&gt;(f \ast 1)(n)&lt;/math&gt; is the Dirichlet series product &lt;math&gt; \zeta(s) \sum_{n \geq 1} \frac{f(n)}{n^s}.&lt;/math&gt; Then since &lt;math&gt;2^{\omega(n)} = (|\mu| \ast 1)(n)&lt;/math&gt;, these two Dirichlet series identities should make sense.)
 --&gt;

== Analytic properties of Dirichlet series==
Given a sequence {''a''&lt;sub&gt;''n''&lt;/sub&gt;}&lt;sub&gt;''n'' ∈ '''N'''&lt;/sub&gt; of complex numbers we try to consider the value of

:&lt;math&gt; f(s) = \sum_{n=1}^\infty \frac{a_n}{n^s} &lt;/math&gt;

as a function of the [[complex number|complex]] variable ''s''. In order for this to make sense, we need to consider the convergence properties of the above infinite series:

If {''a''&lt;sub&gt;''n''&lt;/sub&gt;}&lt;sub&gt;''n'' ∈ '''N'''&lt;/sub&gt; is a [[bounded sequence]] of complex numbers, then the corresponding Dirichlet series ''f'' converges [[absolute convergence|absolutely]] on the open half-plane of ''s'' such that Re(''s'') &gt; 1. In general, if ''a''&lt;sub&gt;''n''&lt;/sub&gt; = O(''n''&lt;sup&gt;''k''&lt;/sup&gt;), the series converges absolutely in the half plane Re(''s'')&amp;nbsp;&gt;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1.

If the set of sums ''a''&lt;sub&gt;''n''&lt;/sub&gt; + ''a''&lt;sub&gt;''n'' + 1&lt;/sub&gt; + ... + ''a''&lt;sub&gt;''n'' + ''k''&lt;/sub&gt; is bounded for ''n'' and ''k'' ≥ 0, then the above infinite series converges on the open half-plane of ''s'' such that Re(''s'') &gt; 0.

In both cases ''f'' is an [[analytic function]] on the corresponding open half plane.

In general the '''abscissa of convergence''' of a Dirichlet series is the intercept on the real axis of the vertical line in the complex plane such that there is convergence to the right of it, and divergence to the left. This is the analogue for Dirichlet series of the [[radius of convergence]] for [[power series]]. The Dirichlet series case is more complicated, though: [[absolute convergence]] and [[uniform convergence]] may occur in distinct half-planes.

In many cases, the analytic function associated with a Dirichlet series has an analytic extension to a larger domain.

=== Abscissa of convergence ===
Assume that &lt;math&gt;\textstyle\sum_{n=1}^\infty a_n n^{-s_0} &lt;/math&gt; converges for some &lt;math&gt;\textstyle s_0 \in \mathbb{C}, \operatorname{Re}(s_0) &gt; 0&lt;/math&gt;.
* Then  &lt;math&gt;\textstyle A(N) = \sum_{n=1}^N a_n = o(N^{s_0})&lt;/math&gt;.   ''Proof'': note that &lt;math&gt; \textstyle (n+1)^s-n^s =\int_n^{n+1} s x^{s-1} \, dx = \mathcal{O}(n^{s-1})&lt;/math&gt;. Let &lt;math&gt;\textstyle B(N) = \sum_{n=1}^N \frac{a_n}{n^{s_0}} = \ell+o(1)&lt;/math&gt; where &lt;math&gt;\ell=\sum_{n=1}^\infty a_n n^{-s_0}&lt;/math&gt;, by [[summation by parts]] we have

:: &lt;math&gt;
\begin{align}
&amp; A(N) = \sum_{n=1}^N \frac{a_n}{n^{s_0}} n^{s_0} = B(N)N^{s_0} + \sum_{n=1}^{N-1}  B(n) (n^{s_0}-(n+1)^{s_0})\\
= {} &amp; (B(N)-L)N^{s_0} + \sum_{n=1}^{N-1}  (B(n)-L) (n^{s_0}-(n+1)^{s_0}) \\
= {} &amp; o(N^{s_0})+\sum_{n=1}^{N-1} \mathcal{o}(n^{s_0-1}) =  o(N^{s_0})
\end{align}
&lt;/math&gt;
* Let &lt;math&gt;L = \sum_{n=1}^\infty a_n &lt;/math&gt; if it converges, &lt;math&gt;L=0&lt;/math&gt; otherwise. Then the number &lt;math&gt;\sigma = \lim \sup_{N \to \infty} \frac{\ln |A(N)-L|}{\ln N}= \inf \left\{\sigma, A(N)-L = \mathcal{O}(N^\sigma)\right\}&lt;/math&gt; is called the ''abscissa of convergence'' of the Dirichlet series  :  &lt;center&gt;&lt;math&gt;\sum_{n=1}^\infty a_n n^{-s}&lt;/math&gt; converges for &lt;math&gt;\operatorname{Re}(s) &gt; \sigma&lt;/math&gt; and diverges for &lt;math&gt;\operatorname{Re}(s) &lt; \sigma&lt;/math&gt;&lt;/center&gt; From the definition &lt;math&gt;\forall \varepsilon &gt; 0&lt;/math&gt;, &lt;math&gt;\textstyle A(N)-L = \mathcal{O}(N^{\sigma+\varepsilon})&lt;/math&gt; so that

:: &lt;math&gt;
\begin{align}
\sum_{n=1}^N a_n n^{-s} &amp; = A(N) N^{-s} + \sum_{n=1}^{N-1} A(n) (n^{-s} -(n+1)^{-s}) \\
&amp; = (A(N)-L) N^{-s} + \sum_{n=1}^{N-1} (A(n)-L) (n^{-s} -(n+1)^{-s}) \\
&amp; =\mathcal{O}(N^{\sigma+\varepsilon-s}) + \sum_{n=1}^{N-1} \mathcal{O}(n^{\sigma+\varepsilon-s-1})
\end{align}
&lt;/math&gt;
: which converges as &lt;math&gt;\textstyle N \to \infty&lt;/math&gt; whenever &lt;math&gt;\textstyle \operatorname{Re}(s) &gt; \sigma&lt;/math&gt;. Hence, for every &lt;math&gt;s&lt;/math&gt; such that &lt;math&gt;\sum_{n=1}^\infty a_n n^{-s}&lt;/math&gt;  diverges, we have &lt;math&gt;\sigma \ge \operatorname{Re}(s)&lt;/math&gt;, and this finishes the proof.
* If &lt;math&gt;\sum_{n=1}^\infty a_n&lt;/math&gt; converges then &lt;math&gt;f(\sigma+it)= o\left(\frac 1 \sigma\right)&lt;/math&gt; as &lt;math&gt;\sigma \to 0^+&lt;/math&gt; and where it is meromorphic &lt;math&gt;f(s)&lt;/math&gt; has no poles on &lt;math&gt;\operatorname{Re}(s) = 0&lt;/math&gt;
  {{Hidden &lt;!--(omit for initial hidden state)--&gt;
| style = border:1px solid black; text-align:middle;width: 90%;
| multiline=
| headerstyle = text-align:left;
| header = Proof
| contentstyle = text-align:left;
| content =

Since &lt;math&gt;n^{-s} - (n+1)^{-s} = sn^{-s-1}+O(n^{-s-2})&lt;/math&gt; and &lt;math&gt;A(N) - f(0) \to 0&lt;/math&gt; we have by summation by parts, for &lt;math&gt;\operatorname{Re}(s) &gt; 0&lt;/math&gt; :
: &lt;math&gt;
\begin{align}
f(s) &amp; = \lim_{N \to \infty} \sum_{n=1}^N a_n n^{-s} \\
&amp; =\lim_{N \to \infty} A(N) N^{-s} + \sum_{n=1}^{N-1} A(n) (n^{-s}-(n+1)^{-s}) \\
&amp; = s\sum_{n=1}^\infty A(n) n^{-s-1}+\underbrace{\mathcal{O} \left( \sum_{n=1}^\infty A(n) n^{-s-2} \right) }_{= \mathcal{O}(1)}
\end{align}
&lt;/math&gt;

Now find ''N'' such that for ''n''&amp;nbsp;&gt;&amp;nbsp;''N'', &lt;math&gt;|A(n)-f(0)| &lt; \varepsilon&lt;/math&gt;
: &lt;math&gt;
\begin{align}
&amp; s\sum_{n=1}^\infty A(n) n^{-s-1} \\
= {} &amp; \underbrace{s f(0) \zeta(s+1)+s\sum_{n=1}^N (A(n)-f(0)) n^{-s-1}}_{\textstyle=\mathcal{O}(1)} \\[6pt]
&amp; {}\quad + \quad \overbrace{s\sum_{n=N+1}^\infty (A(n)-f(0)) n^{-s-1}}^{\textstyle &lt; \varepsilon |s| \int_N^\infty x^{-\operatorname{Re}(s)-1} \, dx}
\end{align}
&lt;/math&gt;

and hence, for every &lt;math&gt;\varepsilon &gt;0&lt;/math&gt; there is a &lt;math&gt;C&lt;/math&gt; such that  for &lt;math&gt;\sigma &gt; 0&lt;/math&gt; : &lt;math&gt;|f(\sigma+it)| &lt; C+\varepsilon |\sigma+it|\frac{1}{\sigma}&lt;/math&gt;
}}

{{cite journal
 | author = Hardy 
 | title = the general theory of dirichlet series
 | year = 1914
 | url = http://www.plouffe.fr/simon/math/Dirichlet%20Series%20de%20Hardy.pdf
}}

==Formal Dirichlet series==
A formal Dirichlet series over a ring ''R'' is associated to a function ''a'' from the positive integers to ''R''

:&lt;math&gt; D(a,s) = \sum_{n=1}^\infty a(n) n^{-s} \  &lt;/math&gt;

with addition and multiplication defined by

:&lt;math&gt; D(a,s) + D(b,s) = \sum_{n=1}^\infty (a+b)(n) n^{-s} \  &lt;/math&gt;
:&lt;math&gt; D(a,s) \cdot D(b,s) = \sum_{n=1}^\infty (a*b)(n) n^{-s} \  &lt;/math&gt;

where

:&lt;math&gt; (a+b)(n) = a(n)+b(n) \ &lt;/math&gt;

is the [[pointwise]] sum and

:&lt;math&gt; (a*b)(n) = \sum_{k\mid n} a(k)b(n/k) \ &lt;/math&gt;

is the [[Dirichlet convolution]] of ''a'' and ''b''.

The formal Dirichlet series form a ring Ω, indeed an ''R''-algebra, with the zero function as additive zero element and the function δ defined by ''δ''(1)&amp;nbsp;=&amp;nbsp;1, ''δ''(''n'')&amp;nbsp;=&amp;nbsp;0 for ''n''&amp;nbsp;&gt;&amp;nbsp;1 as multiplicative identity.  An element of this ring is invertible if ''a''(1) is invertible in ''R''.  If ''R'' is commutative, so is Ω; if ''R'' is an integral domain, so is Ω.  The non-zero multiplicative functions form a subgroup of the group of units of Ω.

The ring of formal Dirichlet series over '''C''' is isomorphic to a ring of formal power series in countably many variables.&lt;ref&gt;{{cite journal | last1=Cashwell | first=E.D. | last2=Everett | first2=C.J. | title=The ring of number-theoretic functions | journal=Pacific J. Math. | volume=9 | pages=975–985 | year=1959 | issn=0030-8730 | url=http://projecteuclid.org/euclid.pjm/1103038878 | zbl=0092.04602 | mr=0108510 | doi=10.2140/pjm.1959.9.975}}&lt;/ref&gt;

==Derivatives==
Given

:&lt;math&gt;F(s) =\sum_{n=1}^\infty \frac{f(n)}{n^s}&lt;/math&gt;

it is possible to show that

:&lt;math&gt;F'(s) =-\sum_{n=1}^\infty \frac{f(n)\log(n)}{n^s}&lt;/math&gt;

assuming the right hand side converges. For a [[completely multiplicative function]] ƒ(''n''), and assuming the series converges for Re(''s'')&amp;nbsp;&gt;&amp;nbsp;σ&lt;sub&gt;0&lt;/sub&gt;, then one has that

:&lt;math&gt;\frac {F^\prime(s)}{F(s)} = - \sum_{n=1}^\infty \frac{f(n)\Lambda(n)}{n^s}&lt;/math&gt;

converges for Re(''s'')&amp;nbsp;&gt;&amp;nbsp;σ&lt;sub&gt;0&lt;/sub&gt;. Here, Λ(''n'') is the [[von Mangoldt function]].

== Products==
Suppose

:&lt;math&gt; F(s)= \sum_{n=1}^\infty f(n)n^{-s} &lt;/math&gt;

and

:&lt;math&gt; G(s)= \sum_{n=1}^\infty g(n)n^{-s}. &lt;/math&gt;

If both ''F''(''s'') and ''G''(''s'') are [[absolutely convergent]] for ''s'' &gt; ''a'' and ''s'' &gt; ''b'' then we have

:&lt;math&gt; \frac 1 {2T}\int_{-T}^T \,F(a+it)G(b-it)\,dt= \sum_{n=1}^\infty f(n)g(n)n^{-a-b} \text{ as }T \sim \infty. &lt;/math&gt;

If ''a'' = ''b'' and ''ƒ''(''n'') = ''g''(''n'') we have

: &lt;math&gt; \frac 1 {2T}\int_{-T}^T |F(a+it)|^2 \, dt= \sum_{n=1}^\infty [f(n)]^2 n^{-2a} \text{ as } T \sim \infty. &lt;/math&gt;

==Integral and series transformations==
The [[Mellin inversion theorem|inverse Mellin transform]] of a Dirichlet series, divided by s, is given by [[Perron's formula]]. 
Additionally, if &lt;math&gt;F(z) := \sum_{n \geq 0} f_n z^n&lt;/math&gt; is the (formal) ordinary [[generating function]] of the sequence of &lt;math&gt;\{f_n\}_{n \geq 0}&lt;/math&gt;, 
then an integral representation for the Dirichlet series of the generating function sequence, &lt;math&gt;\{f_n z^n\}_{n \geq 0}&lt;/math&gt;, is given by 
&lt;ref&gt;{{cite journal|last1=Borwein, Borwein, and Girgensohn|title=Explicit evaluation of Euler sums|date=1994|url=http://docserver.carma.newcastle.edu.au/58/2/93_001-Borwein-Borwein-Girgensohn.pdf}}&lt;/ref&gt;

:&lt;math&gt;\sum_{n \geq 0} \frac{f_n z^n}{(n+1)^s} = \frac{(-1)^{s-1}}{(s-1)!} \int_0^1 \log^{s-1}(t) F(tz) dt,\ s \geq 1. &lt;/math&gt;

Another class of related derivative and series-based [[Generating function transformation#Derivative transformations|generating function transformations]] on the ordinary generating function of a sequence which effectively produces the left-hand-side expansion in the previous equation are respectively defined in.&lt;ref&gt;{{cite journal|last1=Schmidt|first1=M. D.|title=Zeta series generating function transformations related to polylogarithm functions and the k-order harmonic numbers|journal=Online Journal of Analytic Combinatorics|date=2017|issue=12|url=http://web.math.rochester.edu/misc/ojac/vol12/137.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last1=Schmidt|first1=M. D.|title=Zeta Series Generating Function Transformations Related to Generalized Stirling Numbers and Partial Sums of the Hurwitz Zeta Function|arxiv=1611.00957}}&lt;/ref&gt;

==Relation to power series==
The sequence ''a&lt;sub&gt;n&lt;/sub&gt;'' generated by a Dirichlet series generating function corresponding to:

:&lt;math&gt;\zeta(s)^m = \sum_{n=1}^\infty \frac{a_n}{n^s}&lt;/math&gt;

where ''ζ''(''s'') is the [[Riemann zeta function]], has the ordinary generating function:

: &lt;math&gt;
\begin{align}
&amp; \sum_{n=1}^\infty a_nx^n \\
= {} &amp; x + {m \choose 1}\sum_{a=2}^\infty x^a + {m \choose 2} \sum_{a=2}^\infty \sum_{b=2}^\infty x^{ab} \\
&amp; {} + {m \choose 3} \sum_{a=2}^\infty \sum \limits_{b=2}^\infty \sum_{c=2}^\infty x^{abc} + {m \choose 4} \sum_{a=2}^\infty \sum_{b=2}^\infty \sum \limits_{c=2}^\infty \sum_{d=2}^\infty x^{abcd} +\cdots
\end{align}
&lt;/math&gt;

== See also ==
* [[General Dirichlet series]]
* [[Zeta function regularization]]
* [[Euler product]]

==References==
{{reflist}}
* {{Apostol IANT}}
* {{cite book
|first1=G.H.
|last1=Hardy
|author-link=G. H. Hardy
|first2=Marcel
|last2=Riesz
|title=The general theory of Dirichlet's series
|series=Cambridge Tracts in Mathematics
|volume=18
|publisher=Cambridge University Press
|year=1915
}}
*[http://historical.library.cornell.edu/cgi-bin/cul.math/docviewer?did=01480002&amp;seq=7  The general theory of Dirichlet's series ] by G. H. Hardy. Cornell University Library Historical Math Monographs.   {Reprinted by} [https://www.amazon.com/general-theory-Dirichlet-s-G-Hardy/dp/1429704527/ Cornell University Library Digital Collections]
* {{cite journal
 |first1      = Henry W.
 |last1       = Gould
 |first2      = Temba
 |last2       = Shonhiwa
 |title       = A catalogue of interesting Dirichlet series
 |journal     = Miss. J. Math. Sci.
 |volume      = 20
 |issue       = 1
 |year        = 2008
 |url         = http://www.math-cs.ucmo.edu/~mjms/2008-1p.html
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20111002201720/http://www.math-cs.ucmo.edu/~mjms/2008-1p.html
 |archivedate = 2011-10-02
 |df          = 
}}&lt;-link dead
* {{cite arXiv
|first1=Richard J.
|last1=Mathar
|title=Survey of Dirichlet series of multiplicative arithmetic functions
|year=2011
|eprint=1106.4038
|class=math.NT
}}
* {{cite book | title=Introduction to Analytic and Probabilistic Number Theory | volume=46 | series=Cambridge Studies in Advanced Mathematics | first=Gérald | last=Tenenbaum | authorlink=Gérald Tenenbaum | publisher=[[Cambridge University Press]] | year=1995 | isbn=0-521-41261-7 | zbl=0831.11001 }}
* {{planetmath reference|title=Dirichlet series|id=4764}}

{{Authority control}}

[[Category:Zeta and L-functions]]
[[Category:Mathematical series]]
[[Category:Series expansions]]</text>
      <sha1>r8plybkz623w0jmlsxmgb0pmkqymupi</sha1>
    </revision>
  </page>
  <page>
    <title>Discontinuous linear map</title>
    <ns>0</ns>
    <id>3531066</id>
    <revision>
      <id>869641589</id>
      <parentid>786518791</parentid>
      <timestamp>2018-11-19T21:32:12Z</timestamp>
      <contributor>
        <ip>2605:E000:141B:C18C:B5FF:B27B:7B17:9DA9</ip>
      </contributor>
      <comment>/* Closed operators */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14755">In [[mathematics]], [[linear map]]s form an important class of "simple" [[function (mathematics)|functions]] which preserve the algebraic structure of [[linear space]]s and are often used as approximations to more general functions (see [[linear approximation]]).  If the spaces involved are also [[topological space]]s (that is, [[topological vector space]]s), then it makes sense to ask whether all linear maps are [[continuous map|continuous]]. It turns out that for maps defined on infinite-[[dimension (linear algebra)|dimensional]] topological vector spaces (e.g., infinite-dimensional [[normed space]]s), the answer is generally no: there exist '''discontinuous linear maps'''.  If the domain of definition is [[complete space|complete]], it is trickier; such maps can be proven to exist, but the proof relies on the [[axiom of choice]] and does not provide an explicit example.

== A linear map from a finite-dimensional space is always continuous ==

Let ''X'' and ''Y'' be two normed spaces and ''f'' a linear map from ''X'' to ''Y''. If ''X'' is [[finite-dimensional]], choose a basis (''e''&lt;sub&gt;1&lt;/sub&gt;, ''e''&lt;sub&gt;2&lt;/sub&gt;, …, ''e''&lt;sub&gt;''n''&lt;/sub&gt;) in ''X'' which may be taken to be unit vectors. Then,
:&lt;math&gt;f(x)=\sum^n_{i=1}x_if(e_i),&lt;/math&gt;
and so by the [[triangle inequality]], 
:&lt;math&gt;\|f(x)\|= \left\|\sum^n_{i=1}x_if(e_i)\right\| \le \sum^n_{i=1} |x_i|\|f(e_i)\|.&lt;/math&gt;
Letting 
:&lt;math&gt;M=\sup_i \{\|f(e_i)\|\},&lt;/math&gt;
and using the fact that
:&lt;math&gt;\sum^n_{i=1}|x_i|\le C \|x\|&lt;/math&gt;
for some ''C''&gt;0 which follows from the fact that [[Norm (mathematics)#Properties|any two norms on a finite-dimensional space are equivalent]], one finds 
:&lt;math&gt;\|f(x)\|\le \left(\sum^n_{i=1}|x_i|\right)M\le CM\|x\|.&lt;/math&gt;
Thus, ''f'' is a [[bounded linear operator]] and so is continuous.

If ''X'' is infinite-dimensional, this proof will fail as there is no guarantee that the [[supremum]] ''M'' exists.  If ''Y'' is the zero space {0}, the only map between ''X'' and ''Y'' is the zero map which is trivially continuous. In all other cases, when ''X'' is infinite-dimensional and ''Y'' is not the zero space, one can find a discontinuous map from ''X'' to ''Y''.

== A concrete example ==

Examples of discontinuous linear maps are easy to construct in spaces that are not complete; on any Cauchy sequence of independent vectors which does not have a limit, a linear operator may grow without bound.{{clarify|reason=This is not a proof nor even clear statement of anything, yet later in the article it is treated as an established principle.|date=May 2015}}  In a sense, the linear operators are not continuous because the space has "holes".

For example, consider the space ''X'' of real-valued [[smooth function]]s on the interval [0, 1] with the [[uniform norm]], that is, 
: &lt;math&gt;\|f\|=\sup_{x\in [0, 1]}|f(x)|.&lt;/math&gt;
The ''[[derivative]]-at-a-point'' map, given by

:&lt;math&gt;T(f)=f'(0)\,&lt;/math&gt;

defined on ''X'' and with real values, is linear, but not continuous. Indeed, consider the sequence

:&lt;math&gt;f_n(x)=\frac{\sin (n^2 x)}{n} &lt;/math&gt;

for ''n''≥1. This sequence converges uniformly to the constantly zero function, but

:&lt;math&gt;T(f_n)=\frac{n^2\cos(n^2 \cdot 0)}{n}=n\to \infty&lt;/math&gt;

as ''n''→∞ instead of  &lt;math&gt;T(f_n)\to T(0)=0&lt;/math&gt; which would hold for a continuous map.  Note that ''T'' is real-valued, and so is actually a [[linear functional]] on ''X'' (an element of the algebraic [[dual space]] ''X''&lt;sup&gt;*&lt;/sup&gt;).  The linear map ''X'' → ''X'' which assigns to each function its derivative is similarly discontinuous.  Note that although the derivative operator is not continuous, it is [[closed operator|closed]].

The fact that the domain is not complete here is important.  Discontinuous operators on complete spaces require a little more work.

== A nonconstructive example ==

An algebraic basis for the [[real number]]s as a vector space over the [[rationals]] is known as a [[Hamel basis]] (note that some authors use this term in a broader sense to mean an algebraic basis of ''any'' vector space).  Note that any two [[commensurability (mathematics)|noncommensurable]] numbers, say 1 and π, are linearly independent.  One may find a Hamel basis containing them, and define a map ''f'' from '''R''' to '''R''' so that ''f''(π) = 0, ''f'' acts as the identity on the rest of the Hamel basis, and extend to all of '''R''' by linearity.  Let {''r''&lt;sub&gt;''n''&lt;/sub&gt;}&lt;sub&gt;''n''&lt;/sub&gt; be any sequence of rationals which converges to π.  Then lim&lt;sub&gt;''n''&lt;/sub&gt; ''f''(''r''&lt;sub&gt;''n''&lt;/sub&gt;) = π, but ''f''(π) = 0.  By construction, ''f'' is linear over '''Q''' (not over '''R'''), but not continuous.  Note that ''f'' is also not [[measurable function|measurable]]; an [[Additive map|additive]] real function is linear if and only if it is measurable, so for every such function there is a [[Vitali set]].  The construction of ''f'' relies on the axiom of choice.

This example can be extended into a general theorem about the existence of discontinuous linear maps on any infinite-dimensional normed space (as long as the codomain is not trivial).

== General existence theorem ==

Discontinuous linear maps can be proven to exist more generally even if the space is complete.{{clarify|reason=A general "constructive" proof in the incomplete case was not given above, so this contrast seems kind of hand-wavey.|date=May 2015}}  Let ''X'' and ''Y'' be [[normed space]]s over the field ''K'' where ''K'' = '''R''' or ''K'' = '''C'''. Assume that ''X'' is infinite-dimensional and ''Y'' is not the zero space. We will find a discontinuous linear map ''f'' from ''X'' to ''K'', which will imply the existence of a discontinuous linear map ''g'' from ''X'' to ''Y'' given by the formula ''g''(''x'') = ''f''(''x'')''y''&lt;sub&gt;0&lt;/sub&gt; where ''y''&lt;sub&gt;0&lt;/sub&gt; is an arbitrary nonzero vector in ''Y''.

If ''X'' is infinite-dimensional, to show the existence of a linear functional which is not continuous then amounts to constructing ''f'' which is not bounded. For that, consider a [[sequence]] (''e''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sub&gt;''n''&lt;/sub&gt; (''n'' ≥ 1) of [[linearly independent]] vectors in ''X''. Define

:&lt;math&gt;T(e_n)=n\|e_n\|\,&lt;/math&gt;

for each ''n'' = 1, 2, ... Complete this sequence of linearly independent vectors to a [[basis (vector space)|vector space basis]] of ''X'', and define ''T'' at the other vectors in the basis to be zero. ''T'' so defined will extend uniquely to a linear map on ''X'', and since it is clearly not bounded, it is not continuous.

Notice that by using the fact that any set of linearly independent vectors can be completed to a basis, we implicitly used the axiom of choice, which was not needed for the concrete example in the previous section but one.

== Role of the axiom of choice ==

As noted above, the [[axiom of choice]] (AC) is used in the general existence theorem of discontinuous linear maps.  In fact, there are no constructive examples of discontinuous linear maps with complete domain (for example, [[Banach space]]s).  In analysis as it is usually practiced by working mathematicians, the axiom of choice is always employed (it is an axiom of [[ZFC]] [[set theory]]); thus, to the analyst, all infinite-dimensional topological vector spaces admit discontinuous linear maps.

On the other hand, in 1970 [[Robert M. Solovay]] exhibited a [[model (model theory)|model]] of [[set theory]] in which every set of reals is measurable.&lt;ref&gt;{{citation
 | last = Solovay | first = Robert M. | authorlink = Robert M. Solovay
 | journal = [[Annals of Mathematics]]
 | mr = 0265151
 | pages = 1–56
 | series = Second Series
 | title = A model of set-theory in which every set of reals is Lebesgue measurable
 | volume = 92
 | year = 1970
 | doi=10.2307/1970696}}.&lt;/ref&gt;  This implies that there are no discontinuous linear real functions. Clearly AC does not hold in the model.

Solovay's result shows that it is not necessary to assume that all infinite-dimensional vector spaces admit discontinuous linear maps, and there are schools of analysis which adopt a more [[constructivism (mathematics)|constructivist]] viewpoint.  For example, H. G. Garnir, in searching for so-called "dream spaces" (topological vector spaces on which every linear map into a normed space is continuous), was led to adopt ZF + [[dependent choice|DC]] + [[Baire property|BP]] (dependent choice is a weakened form and the [[Baire property]] is a negation of strong AC) as his axioms to prove the [[Garnir–Wright closed graph theorem]] which states, among other things, that any linear map from an [[F-space]] to a TVS is continuous.  Going to the extreme of [[Constructivism (mathematics)|constructivism]], there is [[Ceitin's theorem]], which states that ''every'' function is continuous (this is to be understood in the terminology of constructivism, according to which only representable functions are considered to be functions).&lt;ref&gt;{{citation|title=Handbook of Analysis and Its Foundations|first=Eric|last=Schechter|publisher=Academic Press|year=1996|isbn=9780080532998|page=136|url=https://books.google.com/books?id=eqUv3Bcd56EC&amp;pg=PA136}}.&lt;/ref&gt;  Such stances are held by only a small minority of working mathematicians.

The upshot is that the existence of discontinuous linear maps depends on AC; it is consistent with set theory without AC that there are no discontinuous linear maps on complete spaces.  In particular, no concrete construction such as the derivative can succeed in defining a discontinuous linear map everywhere on a complete space.

== Closed operators ==

Many naturally occurring linear discontinuous operators are [[closed operator|closed]], a class of operators which share some of the features of continuous operators. It makes sense to ask which linear operators on a given space are closed.  The [[closed graph theorem]] asserts that an ''everywhere-defined'' closed operator on a complete domain is continuous, so to obtain a discontinuous closed operator, one must permit operators which are not defined everywhere.
 
To be more concrete, let &lt;math&gt;T&lt;/math&gt; be a map from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt; with domain &lt;math&gt;\operatorname{Dom}(T)&lt;/math&gt;, written &lt;math&gt;T: \operatorname{Dom}(T)\subseteq X\to Y&lt;/math&gt;. We don't lose much if we replace ''X'' by the closure of &lt;math&gt;\operatorname{Dom}(T)&lt;/math&gt;. That is, in studying operators that are not everywhere-defined, one may restrict one's attention to [[densely defined operator]]s without loss of generality.

If the graph &lt;math&gt;\Gamma(T)&lt;/math&gt; of &lt;math&gt;T&lt;/math&gt; is closed in ''X'' ×''Y'', we call ''T'' ''closed''. Otherwise, consider its closure &lt;math&gt;\overline{\Gamma(T)}&lt;/math&gt; in ''X'' ×''Y''. If &lt;math&gt;\overline{\Gamma(T)}&lt;/math&gt; is itself the graph of some operator &lt;math&gt;\overline{T}&lt;/math&gt;, &lt;math&gt;T&lt;/math&gt; is called ''closable'', and &lt;math&gt;\overline{T}&lt;/math&gt; is called the ''closure'' of &lt;math&gt;T&lt;/math&gt;.

So the natural question to ask about linear operators that are not everywhere-defined is whether they are closable.  The answer is, "not necessarily"; indeed, every infinite-dimensional normed space admits linear operators that are not closable. As in the case of discontinuous operators considered above, the proof requires the axiom of choice and so is in general nonconstructive, though again, if ''X'' is not complete, there are constructible examples.

In fact, there is even an example of a linear operator whose graph has closure ''all'' of ''X'' ×''Y''.  Such an operator is not closable.  Let ''X''  be the space of [[polynomial function]]s from [0,1] to '''R''' and ''Y'' the space of polynomial functions from [2,3] to '''R'''.  They are subspaces of ''C''([0,1]) and ''C''([2,3]) respectively, and so normed spaces.  Define an operator ''T'' which takes the polynomial function ''x'' ↦ ''p''(''x'') on [0,1] to the same function on [2,3].  As a consequence of the [[Stone–Weierstrass theorem]], the graph of this operator is dense in ''X''×''Y'', so this provides a sort of maximally discontinuous linear map (confer [[nowhere continuous function]]).  Note that ''X'' is not complete here, as must be the case when there is such a constructible map.

== Impact for dual spaces ==

The [[dual space]] of a topological vector space is the collection of continuous linear maps from the space into the underlying field.  Thus the failure of some linear maps to be continuous for infinite-dimensional normed spaces implies that for these spaces, one needs to distinguish the algebraic dual space from the continuous dual space which is then a proper subset.  It illustrates the fact that an extra dose of caution is needed in doing analysis on infinite-dimensional spaces as compared to finite-dimensional ones.

== Beyond normed spaces ==

The argument for the existence of discontinuous linear maps on normed spaces can be generalized to all metrisable topological vector spaces, especially to all Fréchet-spaces, but there exist infinite-dimensional locally convex topological vector spaces such that every functional is continuous.&lt;ref&gt;For example, the weak topology w.r.t. the space of all (algebraically) linear functionals.&lt;/ref&gt; On the other hand, the [[Hahn–Banach theorem]], which applies to all locally convex spaces, guarantees the existence of many continuous linear functionals, and so a large dual space.  In fact, to every convex set, the [[Minkowski gauge]] associates a continuous [[linear functional]].  The upshot is that spaces with fewer convex sets have fewer functionals, and in the worst-case scenario, a space may have no functionals at all other than the zero functional. This is the case for the [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt;('''R''',''dx'')]] spaces with 0&amp;nbsp;&lt;&amp;nbsp;''p''&amp;nbsp;&lt;&amp;nbsp;1, from which it follows that these spaces are nonconvex. Note that here is indicated the [[Lebesgue measure]] on the real line.  There are other ''L''&lt;sup&gt;''p''&lt;/sup&gt; spaces with 0&amp;nbsp;&lt;&amp;nbsp;''p''&amp;nbsp;&lt;&amp;nbsp;1 which do have nontrivial dual spaces.

Another such example is the space of real-valued [[measurable function]]s on the unit interval with [[quasinorm]] given by 
:&lt;math&gt;||f|| = \int_I \frac{|f(x)|}{1+|f(x)|}dx.&lt;/math&gt;
This non-locally convex space has a trivial dual space.

One can consider even more general spaces.  For example, the existence of a homomorphism between complete separable metric [[group (mathematics)|group]]s can also be shown nonconstructively.

==Notes==
{{reflist}}

==References==
* Constantin Costara, Dumitru Popa, ''Exercises in Functional Analysis'', Springer, 2003. {{isbn|1-4020-1560-7}}.
* Schechter, Eric, ''Handbook of Analysis and its Foundations'', Academic Press, 1997. {{isbn|0-12-622760-8}}.

{{Functional Analysis}}

[[Category:Functional analysis]]
[[Category:Functions and mappings]]</text>
      <sha1>cvb3pixlvth3c7zhn63zptywrmuwap9</sha1>
    </revision>
  </page>
  <page>
    <title>Elliptic divisibility sequence</title>
    <ns>0</ns>
    <id>21298611</id>
    <revision>
      <id>864992973</id>
      <parentid>843964709</parentid>
      <timestamp>2018-10-20T23:43:28Z</timestamp>
      <contributor>
        <ip>97.118.121.73</ip>
      </contributor>
      <comment>/* Examples */ Fixed reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11275">In mathematics, an '''elliptic divisibility sequence (EDS)''' is a sequence of integers satisfying a nonlinear recursion relation arising from [[division polynomial]]s on [[elliptic curve]]s.  EDS were first defined, and their arithmetic properties studied, by [[Morgan Ward]]&lt;ref name="Ward"&gt;Morgan Ward, Memoir on elliptic divisibility sequences, ''Amer. J. Math.'' '''70''' (1948), 31&amp;ndash;74.&lt;/ref&gt; 
in the 1940s. They attracted only sporadic attention until around 2000, when EDS were taken up as a class of nonlinear recurrences that are more amenable to analysis than most such sequences. This tractability is due primarily to the close connection between EDS and elliptic curves.  In addition to the intrinsic interest that EDS have within number theory, EDS have applications to other areas of mathematics including [[logic]] and [[cryptography]].

== Definition ==
A (nondegenerate) ''elliptic divisibility sequence'' (EDS) is a sequence of integers {{math|(&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;)&lt;sub&gt;&lt;var&gt;n&lt;/var&gt; &amp;ge; 1&lt;/sub&gt;}}
defined recursively by four initial values 
{{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;}}, {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;2&lt;/sub&gt;}}, {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;3&lt;/sub&gt;}}, {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;4&lt;/sub&gt;}}, 
with {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;3&lt;/sub&gt;}} ≠ 0 and with subsequent values determined by the formulas

:&lt;math&gt;
  \begin{align}
  W_{2n+1}W_1^3 &amp;= W_{n+2}W_n^3 - W_{n+1}^3W_{n-1},\qquad n \ge 2, \\
  W_{2n}W_2W_1^2 &amp;= W_{n+2}W_n W_{n-1}^2 - W_n W_{n-2}W_{n+1}^2,\qquad n\ge 3,\\
  \end{align}
&lt;/math&gt;

It can be shown that if {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;}} divides each of {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;2&lt;/sub&gt;}}, {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;3&lt;/sub&gt;}}, {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;4&lt;/sub&gt;}} and if further {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;2&lt;/sub&gt;}} divides {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;4&lt;/sub&gt;}}, then every term {{math|&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}} in the sequence is an integer.

== Divisibility property ==
An EDS is a [[divisibility sequence]] in the sense that
:&lt;math&gt;
  m \mid n \Longrightarrow W_m \mid W_n.
&lt;/math&gt;
In particular, every term in an EDS is divisible by {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;}}, so
EDS are frequently ''normalized'' to have {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;}} = 1 by dividing every term by the initial term.

Any three integers {{math|&lt;var&gt;b&lt;/var&gt;}},  {{math|&lt;var&gt;c&lt;/var&gt;}},  {{math|&lt;var&gt;d&lt;/var&gt;}}
with  {{math|&lt;var&gt;d&lt;/var&gt;}} divisible by  {{math|&lt;var&gt;b&lt;/var&gt;}} lead to a normalized EDS on setting 
:&lt;math&gt;
  W_1 = 1,\quad W_2 = b,\quad W_3 = c,\quad W_4 = d.
&lt;/math&gt;
It is not obvious, but can be proven, that the condition  {{math|&lt;var&gt;b&lt;/var&gt;}} | {{math|&lt;var&gt;d&lt;/var&gt;}} suffices to ensure that every term
in the sequence is an integer.

== General recursion ==
A fundamental property of elliptic divisibility sequences
is that they satisfy the general recursion relation
:&lt;math&gt;
  W_{n+m}W_{n-m}W_r^2 = W_{n+r}W_{n-r}W_m^2 - W_{m+r}W_{m-r}W_n^2
  \quad\text{for all}\quad n &gt; m &gt; r.
&lt;/math&gt;
(This formula is often applied with {{math|&lt;var&gt;r&lt;/var&gt;}} = 1 and {{math|&lt;var&gt;W&lt;/var&gt;&lt;sub&gt;1&lt;/sub&gt;}} = 1.)

== Nonsingular EDS ==
The ''discriminant'' of a normalized EDS is the quantity
:&lt;math&gt;
  \Delta = 
  W_4W_2^{15} - W_3^3W_2^{12} + 3W_4^2W_2^{10} - 20W_4W_3^3W_2^7 +
  3W_4^3W_2^5 + 16W_3^6W_2^4 + 8W_4^2W_3^3W_2^2 + W_4^4.
&lt;/math&gt;
An EDS is ''nonsingular'' if its discriminant is nonzero.

== Examples ==
A simple example of an EDS is the sequence of natural numbers 1, 2, 3,… . Another interesting example is {{OEIS|id=A006709}} 1, 3, 8, 21, 55, 144, 377, 987,… consisting of every other term in the  [[Fibonacci sequence]], starting with the second term. However, both of these sequences satisfy a linear recurrence and both are singular EDS. An example of a nonsingular EDS is {{OEIS|id=A006769}}
:&lt;math&gt;
  \begin{align}
    &amp;1,\, 1,\, -1,\, 1,\, 2,\, -1,\, -3,\, -5,\, 7,\, -4,\, -23,\,
    29,\, 59,\, 129,\\
    &amp;-314,\, -65,\, 1529,\, -3689,\, -8209,\, -16264,\dots.\\
  \end{align}
&lt;/math&gt;

== Periodicity of EDS ==
A sequence {{math|(&lt;var&gt;A&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;)&lt;sub&gt;&lt;var&gt;n&lt;/var&gt; &amp;ge; 1&lt;/sub&gt;}} is said to be ''periodic''
if there is a number {{math|&lt;var&gt;N&lt;/var&gt; &amp;ge; 1}} so
that {{math|&lt;var&gt;A&lt;sub&gt;n+N&lt;/sub&gt;&lt;/var&gt;}} = {{math|&lt;var&gt;A&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}} for every {{math|&lt;var&gt;n&lt;/var&gt;}} ≥ 1.
If a nondegenerate EDS {{math|(&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;)&lt;sub&gt;&lt;var&gt;n&lt;/var&gt; &amp;ge; 1&lt;/sub&gt;}}
is periodic, then one of its terms vanishes. The smallest {{math|&lt;var&gt;r&lt;/var&gt;}} ≥ 1 with {{math|&lt;var&gt;W&lt;sub&gt;r&lt;/sub&gt;&lt;/var&gt;}} = 0 is called the ''rank of apparition'' of the EDS. A deep theorem of Mazur&lt;ref name="Mazur"&gt;
  B. Mazur.
  Modular curves and the Eisenstein ideal,
  ''Inst. Hautes Études Sci. Publ. Math.'' 47:33&amp;ndash;186, 1977.
&lt;/ref&gt;
implies that if the rank of apparition of an EDS is finite, then it satisfies {{math|&lt;var&gt;r&lt;/var&gt;}} ≤ 10 or {{math|&lt;var&gt;r&lt;/var&gt;}} = 12.

== Elliptic curves and points associated to EDS ==
Ward proves that associated to any nonsingular EDS ({{math|&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}})
is an elliptic curve {{math|&lt;var&gt;E&lt;/var&gt;}}/'''Q''' and a point
{{math|&lt;var&gt;P&lt;/var&gt;}} ε {{math|&lt;var&gt;E&lt;/var&gt;}}('''Q''') such that
:&lt;math&gt;
  W_n = \psi_n(P)\qquad\text{for all}~n \ge 1.
&lt;/math&gt;
Here ψ{{math|&lt;var&gt;&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}} is the 
[[division polynomial|{{math|&lt;var&gt;n&lt;/var&gt;}} division polynomial]]
of {{math|&lt;var&gt;E&lt;/var&gt;}}; the roots of ψ{{math|&lt;var&gt;&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}} are the
nonzero points of order {{math|&lt;var&gt;n&lt;/var&gt;}} on {{math|&lt;var&gt;E&lt;/var&gt;}}. There is
a complicated formula&lt;ref name="SilvermanStephens"&gt;
  This formula is due to Ward. See  the appendix to J. H. Silverman and N. Stephens. 
  The sign of an elliptic divisibility sequence. ''J. Ramanujan Math. Soc.'', 21(1):1&amp;ndash;17, 2006.
&lt;/ref&gt;
for {{math|&lt;var&gt;E&lt;/var&gt;}}  and {{math|&lt;var&gt;P&lt;/var&gt;}} in terms of {{math|&lt;var&gt;W&lt;sub&gt;1&lt;/sub&gt;&lt;/var&gt;}}, {{math|&lt;var&gt;W&lt;sub&gt;2&lt;/sub&gt;&lt;/var&gt;}}, {{math|&lt;var&gt;W&lt;sub&gt;3&lt;/sub&gt;&lt;/var&gt;}}, and {{math|&lt;var&gt;W&lt;sub&gt;4&lt;/sub&gt;&lt;/var&gt;}}.

There is an alternative definition of EDS that directly uses elliptic curves and yields a sequence which, up to sign, almost satisfies the EDS recursion. This definition starts with an elliptic curve {{math|&lt;var&gt;E&lt;/var&gt;}}/'''Q''' given by a Weierstrass equation and a nontorsion point {{math|&lt;var&gt;P&lt;/var&gt;}} ε {{math|&lt;var&gt;E&lt;/var&gt;}}('''Q'''). One writes the {{math|&lt;var&gt;x&lt;/var&gt;}}-coordinates of the multiples of {{math|&lt;var&gt;P&lt;/var&gt;}} as 
:&lt;math&gt;
  x(nP) = \frac{A_n}{D_n^2} \quad \text{with}~\gcd(A_n,D_n)=1~\text{and}~D_n \ge 1.
&lt;/math&gt;
Then the sequence ({{math|&lt;var&gt;D&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}}) is also called an '''elliptic divisibility sequence'''. It is a divisibility sequence, and there exists an integer {{math|&lt;var&gt;k&lt;/var&gt;}} so that the subsequence ( ±{{math|&lt;var&gt;D&lt;sub&gt;nk&lt;/sub&gt;&lt;/var&gt;}} )&lt;sub&gt;{{math|&lt;var&gt;n&lt;/var&gt;}} ≥ 1&lt;/sub&gt; (with an appropriate choice of signs) is an EDS in the earlier sense.

== Growth of EDS ==
Let {{math|(&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;)&lt;sub&gt;&lt;var&gt;n&lt;/var&gt; &amp;ge; 1&lt;/sub&gt;}} be a nonsingular EDS
that is not periodic. Then the sequence grows quadratic exponentially in the sense that there is
a positive constant {{math|&lt;var&gt;h&lt;/var&gt;}} such that
:&lt;math&gt;
  \lim_{n\to\infty} \frac{\log |W_n|}{n^2} = h &gt; 0.
&lt;/math&gt;
The number {{math|&lt;var&gt;h&lt;/var&gt;}} is the [[canonical height]] of the point on 
the elliptic curve associated to the EDS.

== Primes and primitive divisors in EDS ==
It is conjectured that a nonsingular EDS contains only finitely many 
primes&lt;ref name="Einsiedler"&gt;
M. Einsiedler, G. Everest, and T. Ward. Primes in elliptic divisibility sequences.
''LMS J. Comput. Math.'', 4:1&amp;ndash;13 (electronic), 2001.
&lt;/ref&gt;
However, all but finitely many terms in a nonsingular EDS admit a primitive prime 
divisor.&lt;ref name="Silverman"&gt;
J. H. Silverman. Wieferich's criterion and the ''abc''-conjecture.
''J. Number Theory'', 30(2):226&amp;ndash;237, 1988.
&lt;/ref&gt;
Thus for all but finitely many {{math|&lt;var&gt;n&lt;/var&gt;}}, 
there is a prime {{math|&lt;var&gt;p&lt;/var&gt;}} such that {{math|&lt;var&gt;p&lt;/var&gt;}} divides {{math|&lt;var&gt;W&lt;sub&gt;n&lt;/sub&gt;&lt;/var&gt;}}, but {{math|&lt;var&gt;p&lt;/var&gt;}} does not divide {{math|&lt;var&gt;W&lt;sub&gt;m&lt;/sub&gt;&lt;/var&gt;}} for all {{math|&lt;var&gt;m&lt;/var&gt;}} &amp;lt; {{math|&lt;var&gt;n&lt;/var&gt;}}. This statement is an analogue of [[Zsigmondy's theorem]].

== EDS over finite fields ==
An EDS over a finite field '''F'''&lt;sub&gt;{{math|&lt;var&gt;q&lt;/var&gt;}}&lt;/sub&gt;, or more generally over any field, is a sequence of elements of that field satisfying the EDS recursion. An EDS over a finite field is always periodic, and thus has a rank of apparition {{math|&lt;var&gt;r&lt;/var&gt;}}. The period of an EDS over '''F'''&lt;sub&gt;{{math|&lt;var&gt;q&lt;/var&gt;}}&lt;/sub&gt; then has the form {{math|&lt;var&gt;rt&lt;/var&gt;}}, where {{math|&lt;var&gt;r&lt;/var&gt;}} and {{math|&lt;var&gt;t&lt;/var&gt;}} satisfy
:&lt;math&gt;
  r \le \left(\sqrt q+1\right)^2 \quad\text{and}\quad t \mid q-1.
&lt;/math&gt;
More precisely, there are elements {{math|&lt;var&gt;A&lt;/var&gt;}} and {{math|&lt;var&gt;B&lt;/var&gt;}} in '''F'''&lt;sub&gt;{{math|&lt;var&gt;q&lt;/var&gt;}}&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; such that
:&lt;math&gt;
  W_{ri+j} = W_j\cdot A^{ij} \cdot B^{j^2}
  \quad\text{for all}~i \ge 0~\text{and all}~j \ge 1.
&lt;/math&gt;
The values of {{math|&lt;var&gt;A&lt;/var&gt;}} and {{math|&lt;var&gt;B&lt;/var&gt;}} are related to the
[[Tate pairing]] of the point on the associated elliptic curve.

== Applications of EDS ==
[[Bjorn Poonen]]&lt;ref&gt;
  B. Poonen. Using elliptic curves of rank one towards the undecidability of
  Hilbert's tenth problem over rings of algebraic integers.
  In ''Algorithmic number theory (Sydney, 2002)'', volume 2369 of
  ''Lecture Notes in Comput. Sci.'', pages 33&amp;ndash;42. Springer, Berlin, 2002.
&lt;/ref&gt;
has applied EDS to logic. He uses the existence of primitive divisors in EDS on elliptic curves of rank one to prove the undecidability of [[Hilbert's tenth problem]] over certain rings of integers.

[[Katherine Stange]]&lt;ref name="Stange"&gt;
  K. Stange. The Tate pairing via elliptic nets.
  In ''Pairing-Based Cryptography (Tokyo, 2007)'', volume 4575 of
  ''Lecture Notes in Comput. Sci.'' Springer, Berlin, 2007.
&lt;/ref&gt;
has applied EDS and their higher rank generalizations called [[elliptic nets]]
to cryptography. She shows how EDS can be used to compute the value
of the [[Weil pairing|Weil and Tate pairings]] on elliptic curves over finite
fields. These pairings have numerous applications in [[pairing-based cryptography]].

==References==
{{reflist}}

== Further material ==

* G. Everest, A. van der Poorten, I. Shparlinski, and T. Ward. ''Recurrence sequences'', volume 104 of ''Mathematical Surveys and Monographs''. American Mathematical Society, Providence, RI, 2003. {{ISBN|0-8218-3387-1}}. (Chapter 10 is on EDS.)
* R. Shipsey. [http://homepages.gold.ac.uk/rachel/rachthesis.ps.gz ''Elliptic divisibility sequences''].   PhD thesis, Goldsmith's College (University of London), 2000.
* K. Stange. ''Elliptic nets''. PhD thesis, Brown University, 2008.
* C. Swart. [http://www.isg.rhul.ac.uk/files/alumni/thesis/swart_c.pdf ''Sequences related to elliptic curves''].   PhD thesis, Royal Holloway (University of London), 2003.

== External links ==
* [http://www.mth.uea.ac.uk/%7Eh090/EDS.html Graham Everest's EDS web page.]
* [http://www.mth.uea.ac.uk/~h090/primeEDS.html Prime Values of Elliptic Divisibility Sequences.]
* [http://www.math.brown.edu/~jhs/Presentations/ICMSEDSLecture.pdf Lecture on ''p''-adic Properites of Elliptic Divisibility Sequences.]

[[Category:Number theory]]
[[Category:Integer sequences]]</text>
      <sha1>8rj1kvpqcj7nj3mw8mjgqgcwtzlys5s</sha1>
    </revision>
  </page>
  <page>
    <title>Extremally disconnected space</title>
    <ns>0</ns>
    <id>5783949</id>
    <revision>
      <id>862247020</id>
      <parentid>799539427</parentid>
      <timestamp>2018-10-03T03:32:02Z</timestamp>
      <contributor>
        <username>RobertFurber</username>
        <id>34801684</id>
      </contributor>
      <comment>/* Examples */ It's important that the space X be compact and Hausdorff, as well as extremally disconnected</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2206">In mathematics, a [[topological space]] is termed '''extremally disconnected''' if the closure of every open set in it is open. (The term "extremally disconnected" is correct, even though the word "extremally" does not appear in most dictionaries.&lt;ref&gt;[http://dictionary.oed.com/cgi/entry/50081102?nearest_to=extremally "extremally" in the O.E.D.]&lt;/ref&gt; The term ''extremely disconnected'' is sometimes used, but it is incorrect.)

An extremally disconnected space that is also [[compact space|compact]] and [[Hausdorff space|Hausdorff]] is sometimes called a '''Stonean space'''. (Note that this is different from a [[Stone space]], which is usually a [[totally disconnected]] compact Hausdorff space.) A theorem due to [[Andrew Gleason]] says that the [[projective object]]s of the category of compact Hausdorff spaces are exactly the extremally disconnected compact Hausdorff spaces. In the duality between Stone spaces and [[Boolean algebra (structure)|Boolean algebra]]s, the Stonean spaces correspond to the [[complete Boolean algebra]]s. 

An extremally disconnected [[first-countable space|first-countable]] [[collectionwise Hausdorff space]] must be discrete. In particular, for [[metric space]]s, the property of being extremally disconnected (the closure of every open set is open) is equivalent to the property of being discrete (every set is open).

==Examples==
* Every [[discrete space]] is extremally disconnected.
* The [[Stone–Čech compactification]] of a discrete space is extremally disconnected.
* The spectrum of an [[abelian von Neumann algebra]] is extremally disconnected.
* Any commutative [[AW*-algebra]] is isomorphic to &lt;math&gt;C(X)&lt;/math&gt; where &lt;math&gt;X&lt;/math&gt; is extremally disconnected, compact and Hausdorff.
* Any set with the [[cofinite topology]] is extremally disconnected, but if the set is infinite this space is connected.

==References==
{{reflist}}
*{{springer|id=E/e037240|title=Extremally-disconnected space|author=A. V. Arkhangelskii}}
*{{cite book| last = Johnstone
  | first = Peter T
  | title = Stone spaces
  | publisher = Cambridge University Press
  | date = 1982
  | isbn =0-521-23893-5}}

{{topology-stub}}
[[Category:Properties of topological spaces]]</text>
      <sha1>idzeg38277vj8asok2zojlczatlyhyi</sha1>
    </revision>
  </page>
  <page>
    <title>FORM (symbolic manipulation system)</title>
    <ns>0</ns>
    <id>27046554</id>
    <revision>
      <id>846587395</id>
      <parentid>798726750</parentid>
      <timestamp>2018-06-19T17:54:20Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4056">{{Other uses2|Form}}
{{Infobox Software
| name = FORM 
| developer = Jos Vermaseren, et al. 
| released =1989
| latest_release_version = 4.2
| status = Active
| programming language = [[C (programming language)|C]] 
| operating_system = [[Linux]], [[Mac OS X]], [[Windows]]
| genre = [[Mathematical software]] 
| license = [[GNU General Public License|GPLv3]] 
| website = {{URL|http://www.nikhef.nl/~form/}}}}

'''FORM''' is a symbolic manipulation system. It reads text files containing definitions of mathematical expressions as well as statements that tell it how to manipulate these expressions. Its original author is Jos Vermaseren of [[NIKHEF|Nikhef]], the Dutch institute for subatomic physics.
It is widely used in the theoretical particle physics community, but it is not restricted to applications in this specific field.&lt;ref&gt;[http://inspirehep.net/search?p=find+c+math-ph/0010025] Some citations of '''FORM''' in the [[INSPIRE-HEP]] Literature Database&lt;/ref&gt;

==Features==
*Definition of mathematical expressions containing various objects (symbols, functions, indices, ...) with elementary arithmetic operations
*Arbitrary long mathematical expressions (limited only by disk space)
*Multi-threaded execution, parallelized version for [[computer cluster]]s
*Powerful pattern matching and replacing
*Fast trace calculation especially of [[gamma matrices]]
*Built-in mathematical functions
*Output into various formats (plain text, '''[[Fortran]]''' code, '''[[Mathematica]]''' code)
*External communication with other software programs

==Example usage==
A text file containing

&lt;code&gt;
   Symbol x,y;
 
   Local myexpr = (x+y)^3;
 
   Id y = x;
   Print;
 
   .end
&lt;/code&gt;

would tell '''FORM''' to create an expression named ''myexpr'', replace therein the symbol ''y'' by ''x'', and print the result on the screen. The result would be given like

&lt;code&gt;
   myexpr =
      8*x^3;
&lt;/code&gt;

==History==
'''FORM''' was started in 1984 as a successor to [[Schoonschip]], an algebra engine developed by
[[Veltman|M. Veltman]]. It was initially coded in '''[[FORTRAN 77]]''', but rewritten in '''[[C (programming language)|C]]''' before the release of version 1.0 in 1989.
Version 2.0 was released in 1991. The version 3.0 of '''FORM''' has been publicized in 2000. It has been made open-source on August 27, 2010 under the [[GPL]] license.

== Applications in high-energy physics and other fields ==
*'''Mincer''': A software package using '''FORM''' to compute [[Feynman diagram|massless propagator diagrams]] with up to three loops.
*'''FORM''' has been the essential tool to calculate the higher-order [[Quantum chromodynamics|QCD]] [[Beta function (physics)|beta function]].
*The mathematical structure of [[multiple zeta values]] has been researched with dedicated '''FORM''' programs.&lt;ref&gt;{{cite journal|doi=10.1016/j.cpc.2009.11.007 | volume=181 | title=The Multiple Zeta Value data mine | year=2010 | journal=Computer Physics Communications | pages=582–625 | last1 = Blümlein | first1 = J. | last2 = Broadhurst | first2 = D.J. | last3 = Vermaseren | first3 = J.A.M.|arxiv=0907.2557| bibcode=2010CoPhC.181..582B }}&lt;/ref&gt;
*The software package [http://www.feynarts.de/formcalc/ FormCalc] which is widely used in the physics community to calculate Feynman diagrams is built on top of '''FORM'''.

==References==
{{Reflist}}

==External links==
*{{Official website|www.nikhef.nl/~form/}}
*[http://www.nikhef.nl/~form/maindir/documentation/reference/online/online.html The FORM online manual]
*[http://packages.debian.org/form Debian &amp;mdash; Details of package form]
*Linux packages: [https://aur.archlinux.org/packages/form-git/ ArchLinux], [http://packages.debian.org/form Debian], [https://packages.gentoo.org/packages/sci-mathematics/form Gentoo], [http://packages.ubuntu.com/form Ubuntu]

{{Computer algebra systems}}

[[Category:Computer algebra systems]]
[[Category:Free computer algebra systems]]
[[Category:Free software programmed in C]]
[[Category:Mathematical software]]
[[Category:Physics software]]
[[Category:Science software]]</text>
      <sha1>dk1iiwc4bpjv74v54t79mjwnko5heok</sha1>
    </revision>
  </page>
  <page>
    <title>Fiber derivative</title>
    <ns>0</ns>
    <id>10605275</id>
    <revision>
      <id>864349789</id>
      <parentid>601738783</parentid>
      <timestamp>2018-10-16T16:58:33Z</timestamp>
      <contributor>
        <ip>213.144.153.250</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="901">{{multiple issues|
{{Orphan|date=February 2013}}
{{unreferenced|date=August 2012}}
}}

In the context of [[Lagrangian Mechanics]] the '''fiber derivative''' is used to convert between the Lagrangian and [[Hamiltonian Mechanics|Hamiltonian]] forms.  In particular, if &lt;math&gt;Q&lt;/math&gt; is the configuration manifold then the Lagrangian &lt;math&gt;L&lt;/math&gt; is defined on the [[tangent bundle]] &lt;math&gt;TQ&lt;/math&gt; and the Hamiltonian is defined on the [[cotangent bundle]] &lt;math&gt;T^* Q&lt;/math&gt;—the fiber derivative is a map &lt;math&gt;\mathbb{F}L:TQ \rightarrow T^* Q&lt;/math&gt; such that

:&lt;math&gt;\mathbb{F}L(v) \cdot w = \left. \frac{d}{ds} \right|_{s=0} L(v+sw)&lt;/math&gt;,

where &lt;math&gt;v&lt;/math&gt; and &lt;math&gt;w&lt;/math&gt; are vectors from the same tangent space.  When restricted to a particular point, the fiber derivative is a [[Legendre transformation]].

[[Category:Lagrangian mechanics]]


{{applied-math-stub}}
{{physics-stub}}</text>
      <sha1>4a23a70dejal1gwogn2uhurtre8c6a5</sha1>
    </revision>
  </page>
  <page>
    <title>Finger binary</title>
    <ns>0</ns>
    <id>2266631</id>
    <revision>
      <id>841412761</id>
      <parentid>841412661</parentid>
      <timestamp>2018-05-15T17:58:12Z</timestamp>
      <contributor>
        <username>Lord Belbury</username>
        <id>32990417</id>
      </contributor>
      <comment>add lead image</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11118">{{No footnotes|date=January 2009}}
[[File:I love you in Sign Language or the number 19 in Finger Binary.jpg|thumb|19 in finger binary: the pinkie finger is 16, added to the 2 of the index finger and the 1 of the thumb]]
'''Finger binary''' is a system for [[Finger counting|counting]] and displaying [[Binary numeral system|binary numbers]] on the [[finger]]s of one or more [[hand]]s. It is possible to count from 0 to 31 (2&lt;sup&gt;5&lt;/sup&gt;&amp;minus;1) using the fingers of a single hand, or from 0 through 1023 (2&lt;sup&gt;10&lt;/sup&gt;&amp;minus;1) if both hands are used.

== Mechanics ==
{{see|Binary numeral system}}

In the binary number system, each [[numerical digit]] has two possible states (0 or 1) and each successive digit represents an increasing [[power of two]].

Note: What follows is but one of several possible schemes for assigning the values 1, 2, 4, 8, 16, etc. to fingers, not necessarily the best. (see below the illustrations.): The rightmost digit represents two to the [[zeroth power]] (i.e., it is the "ones digit"); the digit to its left represents two to the first power (the "twos digit"); the next digit to the left represents two to the second power (the "fours digit"); and so on.  (The [[decimal|decimal number system]] is essentially the same, only that powers of ten are used: "ones digit", "tens digit" "hundreds digit", etc.)

It is possible to use [[digit (anatomy)|anatomical digits]] to represent [[numerical digit]]s by using a raised finger to represent a binary digit in the "1" state and a lowered finger to represent it in the "0" state. Each successive finger represents a higher power of two.

With palms oriented toward the counter's face, the values for when only the right hand is used are:

{| class="wikitable" style="text-align:center"
|-
! !![[little finger|Pinky]] !![[ring finger|Ring]] !![[middle finger|Middle]] !![[index finger|Index]] !![[Thumb]] 
|-
!Power of two
|2&lt;sup&gt;4&lt;/sup&gt; || 2&lt;sup&gt;3&lt;/sup&gt; || 2&lt;sup&gt;2&lt;/sup&gt; || 2&lt;sup&gt;1&lt;/sup&gt; || 2&lt;sup&gt;0&lt;/sup&gt;
|-
!Value
| [[16 (number)|16]] || [[8 (number)|8]] || [[4 (number)|4]] || [[2 (number)|2]] || [[1 (number)|1]]
|}

When only the left hand is used:

{| class="wikitable" style="text-align:center"
|-
! !![[Thumb]] !![[index finger|Index]] !![[middle finger|Middle]] !![[ring finger|Ring]] !![[little finger|Pinky]] 
|-
!Power of two
|2&lt;sup&gt;4&lt;/sup&gt; || 2&lt;sup&gt;3&lt;/sup&gt; || 2&lt;sup&gt;2&lt;/sup&gt; || 2&lt;sup&gt;1&lt;/sup&gt; || 2&lt;sup&gt;0&lt;/sup&gt;
|-
!Value
| [[16 (number)|16]] || [[8 (number)|8]] || [[4 (number)|4]] || [[2 (number)|2]] || [[1 (number)|1]]
|}

When both hands are used:

{| class="wikitable" style="text-align:center"
|-
!rowspan=2|
!colspan=5| Left hand
!colspan=5| Right hand
|-
!Thumb !!Index !!Middle !!Ring !!Pinky
!Pinky !!Ring !!Middle !!Index !!Thumb
|-
!Power of two
|2&lt;sup&gt;9&lt;/sup&gt; || 2&lt;sup&gt;8&lt;/sup&gt; || 2&lt;sup&gt;7&lt;/sup&gt; || 2&lt;sup&gt;6&lt;/sup&gt; || 2&lt;sup&gt;5&lt;/sup&gt; || 2&lt;sup&gt;4&lt;/sup&gt; || 2&lt;sup&gt;3&lt;/sup&gt; || 2&lt;sup&gt;2&lt;/sup&gt; || 2&lt;sup&gt;1&lt;/sup&gt; || 2&lt;sup&gt;0&lt;/sup&gt;
|-
!Value
| 512 || 256 || 128 || 64 || 32 || 16 || 8 || 4 || 2 || 1
|}

And, alternately, with the palms oriented away from the counter:

{| class="wikitable" style="text-align:center"
|-
!rowspan=2|
!colspan=5| Left hand
!colspan=5| Right hand
|-
!Pinky !!Ring !!Middle !!Index !!Thumb
!Thumb !!Index !!Middle !!Ring !!Pinky
|-
!Power of two
|2&lt;sup&gt;9&lt;/sup&gt; || 2&lt;sup&gt;8&lt;/sup&gt; || 2&lt;sup&gt;7&lt;/sup&gt; || 2&lt;sup&gt;6&lt;/sup&gt; || 2&lt;sup&gt;5&lt;/sup&gt; || 2&lt;sup&gt;4&lt;/sup&gt; || 2&lt;sup&gt;3&lt;/sup&gt; || 2&lt;sup&gt;2&lt;/sup&gt; || 2&lt;sup&gt;1&lt;/sup&gt; || 2&lt;sup&gt;0&lt;/sup&gt;
|-
!Value
| 512 || 256 || 128 || 64 || 32 || 16 || 8 || 4 || 2 || 1
|}
The values of each raised finger are added together to arrive at a total number. In the one-handed version, all fingers raised is thus '''31''' (16 + 8 + 4 + 2 + 1), and all fingers lowered (a fist) is 0. In the two-handed system, all fingers raised is '''1,023''' (512 + 256 + 128 + 64 + 32 + 16 + 8 + 4 + 2 + 1) and two fists (no fingers raised) represents 0.

It is also possible to have each hand represent an independent number between 0 and 31; this can be used to represent various types of paired numbers, such as [[month]] and [[day]], X-Y [[coordinate]]s, or sports scores (such as for [[table tennis]] or [[baseball]]).

=== Examples ===
==== Right hand ====
&lt;gallery&gt;
File:LSQ a.jpg|'''0''' = [[empty sum]]
File:Thumbs up.JPG|'''1''' = 1
File:D@InForward.jpg|'''2''' = 2
Middle_finger_3_(mirrored).JPG|'''4''' = 4 
File:LSQ v.jpg|'''6''' = 4 + 2
File:Tri prsta.jpg|'''7''' = 4 + 2 + 1
File:LSQ 6.jpg|'''14''' = 8 + 4 + 2
File:LSQ i.jpg|'''16''' = 16
File:I love you in Sign Language or the number 19 in Finger Binary.jpg|'''19''' = 16 + 2 + 1
File:LSQ 8.jpg|'''26''' = 16 + 8 + 2
File:LSQ 9.jpg|'''28''' = 16 + 8 + 4
File:LSQ 4.jpg|'''30''' = 16 + 8 + 4 + 2
File:LSQ 5.jpg|'''31''' = 16 + 8 + 4 + 2 + 1
&lt;/gallery&gt;

==== Left hand ====
When used in addition to the right.
&lt;gallery&gt;
Image:Thumbs up.jpg|'''512''' = 512
Image:Chinesische.Zahl.Eins.jpg|'''256''' = 256
Image:Chinesische.Zahl.Acht.jpg|'''768''' = 512 + 256
Image:Chinesische.Zahl.Drei.jpg|'''448''' = 256 + 128 + 64
Image:Chinesische.Zahl.Sechs.jpg|'''544''' = 512 + 32
Image:Chinesische.Zahl.Vier.jpg|'''480''' = 256 + 128 + 64 + 32
Image:Chinesische.Zahl.Fuenf.jpg|'''992''' = 512 + 256 + 128 + 64 + 32
&lt;/gallery&gt;

== Negative numbers and non-integers ==

{{more|Binary numeral system#Representing real numbers}}

Just as fractional and negative numbers can be represented in binary, they can be represented in finger binary.  

=== Negative numbers ===

Representing negative numbers is extremely simple, by using the leftmost finger as a [[sign bit]]: raised means the number is negative, in a [[sign-magnitude]] system. Anywhere between -511 and +511 can be represented this way, using two hands. Note that, in this system, both a positive and a negative zero may be represented.

If a convention were reached on palm up/palm down or fingers pointing up/down representing positive/negative, you could maintain 2&lt;sup&gt;10&lt;/sup&gt; - 1 in both positive and negative numbers (-1023 to +1023, with positive and negative zero still represented).

=== Fractions ===

There are multiple ways of representing fractions in finger binary.

==== Dyadic fractions ====

Fractions can be stored natively in a binary format by having each finger represent a fractional power of two: &lt;math&gt;\tfrac{1}{2^x}&lt;/math&gt;.  (These are known as [[dyadic fraction]]s.)

Using the left hand only:

{| class="wikitable" style="text-align:center"
!
!Pinky !! Ring !! Middle !! Index !! Thumb
|-
!Value
|1/2 || 1/4 || 1/8 || 1/16 || 1/32
|}

Using two hands:

{| class="wikitable" style="text-align:center"
|-
!colspan=5| &lt;big&gt;Left hand&lt;/big&gt;
!colspan=5| &lt;big&gt;Right hand&lt;/big&gt;
|-
!Pinky !!Ring !!Middle !!Index !!Thumb
!Thumb !!Index !!Middle !!Ring !!Pinky
|-
|1/2 || 1/4 || 1/8 || 1/16 || 1/32 || 1/64 || 1/128 || 1/256 || 1/512 || 1/1024
|}{{clear}}

[[File:Chinesische.Zahl.Acht.jpg|thumb|right|3/4, in fractional finger binary]]
The total is calculated by adding all the values in the same way as regular (non-fractional) finger binary, then dividing by the largest fractional power being used (32 for one-handed fractional binary, 1024 for two-handed), and [[Equivalent fractions|simplifying the fraction]] as necessary.

For example, with thumb and index finger raised on the left hand and no fingers raised on the right hand, this is (512 + 256)/1024 = 768/1024 = 3/4. If using only one hand (left or right), it would be (16 + 8)/32 = 24/32 = 3/4 also.

The simplification process can itself be greatly simplified by performing a [[bit shift]] operation: all digits to the right of the rightmost raised finger (i.e., all trailing zeros) are discarded and the rightmost raised finger is treated as the ones digit. The digits are added together using their now-shifted values to determine the [[numerator]] and the rightmost finger's original value is used to determine the [[denominator]].

For instance, if the thumb and index finger on the left hand are the only raised digits, the rightmost raised finger (the index finger) becomes "1". The thumb, to its immediate left, is now the 2s digit; added together, they equal 3. The index finger's original value (1/4) determines the denominator: the result is 3/4.

==== Rational numbers ====

Combined [[integer]] and fractional values (i.e., [[rational number]]s) can be represented by setting a [[radix point]] somewhere between two fingers (for instance, between the left and right pinkies). All digits to the left of the radix point are integers; those to the right are fractional.

=== Decimal fractions and vulgar fractions ===

[[Dyadic fraction]]s, explained above, unfortunately have limited use in a society based around decimal figures. A simple non-dyadic fraction such as 1/3 can be approximated as 341/1024 (0.3330078125), but the conversion between dyadic and [[decimal fraction|decimal]] (0.333) or [[vulgar fraction|vulgar]] (1/3) forms is complicated.  

Instead, either decimal or vulgar fractions can be represented natively in finger binary. Decimal fractions can be represented by using regular integer binary methods and dividing the result by 10, 100, 1000, or some other power of ten. Numbers between 0 and 102.3, 10.23, 1.023, etc. can be represented this way, in increments of 0.1, 0.01, 0.001, etc.

[[Vulgar fraction]]s can be represented by using one hand to represent the [[numerator]] and one hand to represent the [[denominator]]; a spectrum of rational numbers can be represented this way, ranging from 1/31 to 31/1 (as well as 0).

== Finger ternary ==

In theory, it is possible to use other positions of the fingers to represent more than two states (0 and 1); for instance, a [[ternary numeral system]] ([[number base|base]] 3) could be used by having a fully raised finger represent 2, fully lowered represent 0, and "curled" (half-lowered) represent 1. This would make it possible to count up to 59,048 (3&lt;sup&gt;10&lt;/sup&gt;&amp;minus;1) on two hands. In practice, however, many people will find it difficult to hold all fingers independently (especially the middle and ring fingers) in more than two distinct positions.

==See also==
*[[Chisanbop]]
*[[Senary#Finger counting]]

==References==
* {{cite book|last=Pohl|first=Frederik|title=Chasing Science|publisher=Macmillan|date=2003|edition=reprint, illustrated|page=304|isbn=978-0-7653-0829-0|url=https://books.google.com/books?id=XsLXJMagfmUC&amp;pg=PA187&amp;dq=fingers+binary+1023#PPA187,M1}}
* {{cite book|last=Pohl|first=Frederik|title=The Best of Frederik Pohl|publisher=Sidgwick &amp; Jackson|date=1976|page=363|url=https://books.google.com/books?id=fDxbAAAAMAAJ&amp;q=fingers+binary+1023&amp;dq=fingers+binary+1023&amp;pgis=1}}
* {{cite book|last=Fahnestock|first=James D.|title=Computers and how They Work|publisher=Ziff-Davis Pub. Co.|date=1959|page=228|url=https://books.google.com/books?id=j_0mAAAAMAAJ&amp;q=fingers+binary+1023&amp;dq=fingers+binary+1023&amp;pgis=1}}

==External links==
&lt;!-- * [http://www.intuitor.com/counting/ How to count to 1,023 on your fingers] --&gt;
* [http://www.instructables.com/id/Binary-Counting/ Binary Counting]

{{Gestures}}

[[Category:Finger-counting|Binary]]
[[Category:Elementary arithmetic]]
[[Category:Binary arithmetic]]</text>
      <sha1>n3sayfvd89nn2263j49mqf4nlbezgyt</sha1>
    </revision>
  </page>
  <page>
    <title>Fischer's inequality</title>
    <ns>0</ns>
    <id>58550416</id>
    <revision>
      <id>871404681</id>
      <parentid>869812016</parentid>
      <timestamp>2018-11-30T20:55:02Z</timestamp>
      <contributor>
        <ip>70.67.116.78</ip>
      </contributor>
      <comment>/* Improvements */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5601">{{about|determinants of positive-definite matrices|statistical block design theory|Fisher's inequality}}
{{short description|mathematical bound}}

In [[mathematics]], '''Fischer's inequality''' gives an upper bound for the [[determinant]] of a [[Positive-definite matrix | positive-semidefinite matrix]] whose entries are complex numbers in terms of the determinants of its principal diagonal blocks. 
Suppose ''A'', ''C'' are respectively ''p''&amp;times;''p'', ''q''&amp;times;''q'' positive-semidefinite complex matrices and ''B'' is a ''p''&amp;times;''q'' complex matrix.
Let 
:&lt;math&gt;M := \left[\begin{matrix} A &amp; B \\ B^* &amp; C \end{matrix}\right]&lt;/math&gt; 
so that ''M'' is a (''p''+''q'')&amp;times;(''p''+''q'') matrix.

Then Fischer's inequality states that 
:&lt;math&gt; \det (M) \le \det(A) \det(C).&lt;/math&gt; 
If ''M'' is positive-definite, equality is achieved in Fischer's inequality if and only if all the entries of ''B'' are 0. Inductively one may conclude that a similar inequality holds for a block decomposition of ''M'' with multiple principal diagonal blocks. Considering 1&amp;times;1 blocks, a corollary is [[Hadamard's inequality]].

==Proof==
Assume that ''A'' and ''C'' are positive-definite. We have &lt;math&gt;A^{-1}&lt;/math&gt; and &lt;math&gt;C^{-1}&lt;/math&gt; are positive-definite. Let 
:&lt;math&gt;D := \left[\begin{matrix} A &amp; 0 \\ 0 &amp; C \end{matrix}\right].&lt;/math&gt; 
We note that
:&lt;math&gt;D^{-\frac{1}{2}} M D^{-\frac{1}{2} } = \left[\begin{matrix} A^{-\frac{1}{2}} &amp; 0 \\ 0 &amp; C^{-\frac{1}{2}} \end{matrix}\right] \left[\begin{matrix} A &amp; B \\ B^* &amp; C \end{matrix}\right] \left[\begin{matrix} A^{-\frac{1}{2}} &amp; 0 \\ 0 &amp; C^{-\frac{1}{2}} \end{matrix}\right] = \left[\begin{matrix} I_{p} &amp; A^{\frac{1}{2}} BC^{-\frac{1}{2}} \\ C^{-\frac{1}{2}}B^*A^{-\frac{1}{2}} &amp; I_{q}\end{matrix}\right]&lt;/math&gt;
Applying the [[inequality of arithmetic and geometric means | AM-GM inequality]] to the eigenvalues of &lt;math&gt;D^{-\frac{1}{2}} M D^{-\frac{1}{2} }&lt;/math&gt;, we see
:&lt;math&gt;\det (D^{-\frac{1}{2}} M D^{-\frac{1}{2}}) \le \left({1 \over p + q} \mathrm{tr} (D^{-\frac{1}{2}} M D^{-\frac{1}{2}}) \right)^{p+q} = 1^{p+q} = 1.&lt;/math&gt;
By multiplicativity of [[determinant]], we have 
:&lt;math&gt;
\begin{align}
\det(D^{-\frac{1}{2}} ) \det(M) \det(D^{-\frac{1}{2}} ) \le 1 \\
\Longrightarrow \det(M) \le \det(D) = \det(A) \det(C).
\end{align}&lt;/math&gt;
In this case, equality holds if and only if ''M'' = ''D'' that is, all entries of ''B'' are 0.

For &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt;, as &lt;math&gt;A + \varepsilon I_p&lt;/math&gt; and &lt;math&gt;C + \varepsilon I_q&lt;/math&gt; are positive-definite, we have 
:&lt;math&gt;\det(M+ \varepsilon I_{p+q}) \le \det(A + \varepsilon I_p) \det(C + \varepsilon I_q).&lt;/math&gt;

Taking the limit as &lt;math&gt;\varepsilon \rightarrow 0&lt;/math&gt; proves the inequality. From the inequality we note that if ''M'' is invertible, then both ''A'' and ''C'' are invertible and we get the desired equality condition.

== Improvements ==
If ''M'' can be partitioned in square blocks ''M&lt;sub&gt;ij&lt;/sub&gt;'', then the following inequality by Thompson is valid:&lt;ref&gt;{{Cite journal|last=Thompson|first=R. C.|title=A determinantal inequality for positive definite matrices|url=https://doi.org/10.4153/cmb-1961-010-9|journal=Canadian Mathematical Bulletin|volume=4|issue=0|pages=57–62|doi=10.4153/cmb-1961-010-9}}&lt;/ref&gt;

: &lt;math&gt;\det(M) \le \det([\det(M_{ij})])  &lt;/math&gt;

where [det(''M&lt;sub&gt;ij&lt;/sub&gt;'')] is the matrix whose (''i'',''j'') entry is det(''M&lt;sub&gt;ij&lt;/sub&gt;'').

In particular, if the block matrices ''B'' and ''C'' are also square matrices, then the following inequality by Everett is valid:&lt;ref&gt;{{Cite journal|last=Everitt|first=W. N.|title=A note on positive definite matrices|url=https://www.cambridge.org/core/journals/glasgow-mathematical-journal/article/note-on-positive-definite-matrices/B3561E2DD3457ADF41C49D744AA9F089|journal=Glasgow Mathematical Journal|volume=3|issue=4|pages=173–175|doi=10.1017/S2040618500033670|issn=2051-2104}}&lt;/ref&gt;

: &lt;math&gt;\det(M) \le \det \begin{bmatrix} \det(A) &amp;&amp; \det(B) \\ \det(B^*) &amp;&amp; \det(D) \end{bmatrix}&lt;/math&gt;

Thompson's inequality can also be generalized by an inequality in terms of the coefficients of the [[characteristic polynomial]] of the block matrices. Expressing the characteristic polynomial of the matrix ''A'' as

: &lt;math&gt;p_A (t) = \sum_{k=0}^n t^{n-k} (-1)^k \operatorname{tr}(\Lambda^k A)&lt;/math&gt;

and supposing that the blocks ''M&lt;sub&gt;ij&lt;/sub&gt;'' are ''m'' x ''m'' matrices, the following inequality by Lin and Zhang is valid:&lt;ref&gt;{{Cite journal|last=Lin|first=Minghua|last2=Zhang|first2=Pingping|title=Unifying a result of Thompson and a result of Fiedler and Markham on block positive definite matrices|url=https://doi.org/10.1016/j.laa.2017.07.032|journal=Linear Algebra and its Applications|volume=533|pages=380–385|doi=10.1016/j.laa.2017.07.032}}&lt;/ref&gt;

: &lt;math&gt;\det(M) \le \left(\frac{\det([\operatorname{tr}(\Lambda^r M_{ij}]))}{ \binom{m}r} \right)^{\frac{m}{r}},\quad r=1, \ldots, m&lt;/math&gt;

Note that if ''r'' = ''m'', then this inequality is identical to Thompson's inequality.

==See also==
* [[Hadamard's inequality]]
* [[Koteljanskii's inequality]]

== Notes ==
{{Reflist}}

==References==

* {{citation
 | last = Fischer | first = Ernst | authorlink = Ernst Sigismund Fischer
 | journal = Arch. Math. u. Phys. (3)
 | pages = 32–40
 | title = &amp;Uuml;ber den Hadamardschen Determinentsatz
 | volume = 13
 | year = 1907}}.
* {{citation
 | last = Horn | first = Roger A. | last2 = Johnson | first2 = Charles R.
 | title=Matrix Analysis
 | url=https://doi.org/10.1017/cbo9781139020411}}.

{{DEFAULTSORT:Fischer's Inequality}}
[[Category:Inequalities]]
[[Category:Determinants]]</text>
      <sha1>ru20assq3ue350wsvx9tzaa7rfd24xc</sha1>
    </revision>
  </page>
  <page>
    <title>Galerkin method</title>
    <ns>0</ns>
    <id>2664839</id>
    <revision>
      <id>871411544</id>
      <parentid>858484791</parentid>
      <timestamp>2018-11-30T21:47:03Z</timestamp>
      <contributor>
        <ip>50.234.189.5</ip>
      </contributor>
      <comment>caps</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8589">{{technical|date=March 2014}}

In [[mathematics]], in the area of [[numerical analysis]], '''Galerkin methods''' are a class of methods for converting a continuous operator problem (such as a [[differential equation]]) to a discrete problem. In principle, it is the equivalent of applying the method of [[variation of parameters]] to a function space, by converting the equation to a [[weak formulation]].  Typically one then applies some constraints on the function space to characterize the space with a finite set of basis functions.

The approach is usually credited to [[Boris Galerkin]] but the method was discovered by [[Walther Ritz]],&lt;ref&gt;"Le destin douloureux de Walther Ritz (1878-1909)", (Jean-Claude Pont, editor), Cahiers de Vallesia, 24, (2012), {{ISBN|978-2-9700636-5-0}}&lt;/ref&gt; to whom Galerkin refers. Often when referring to a Galerkin method, one also gives the name along with typical approximation methods used, such as Bubnov–Galerkin method (after [[Ivan Bubnov]]), [[Petrov–Galerkin method]] (after Georgii I. Petrov&lt;ref name=Mikhlin&gt;S. G. Mikhlin, "Variational methods in Mathematical Physics", Pergamon Press, 1964&lt;/ref&gt;&lt;ref name="Birthday"&gt;"Georgii Ivanovich Petrov (on his 100th birthday)", Fluid Dynamics, May 2012, Volume 47, Issue 3, pp 289-291, DOI 10.1134/S0015462812030015&lt;/ref&gt;) or [[Ritz–Galerkin method]]&lt;ref name=ErnGuermond&gt;A. Ern, J.L. Guermond, ''Theory and practice of finite elements'', Springer, 2004, {{ISBN|0-387-20574-8}}&lt;/ref&gt; (after [[Walther Ritz]]).

Examples of Galerkin methods are:
* the [[Method of mean weighted residuals|Galerkin method of weighted residuals]], the most common method of calculating the global [[stiffness matrix]] in the [[finite element method]],&lt;ref name=BrennerScott&gt;S. Brenner, R. L. Scott, ''The Mathematical Theory of Finite Element Methods'', 2nd edition, Springer, 2005, {{ISBN|0-387-95451-1}}&lt;/ref&gt;&lt;ref name=Ciarlet&gt;P. G. Ciarlet, ''The Finite Element Method for Elliptic Problems'', North-Holland, 1978, {{ISBN|0-444-85028-7}}&lt;/ref&gt;
* the [[boundary element method]] for solving integral equations,
* [[Krylov subspace method]]s.&lt;ref name=Saad&gt;[[Yousef Saad|Y. Saad]], ''Iterative Methods for Sparse Linear Systems'', 2nd edition, SIAM, 2003, {{ISBN|0-89871-534-2}}&lt;/ref&gt;

==Introduction with an abstract problem==

===A problem in weak formulation===
Let us introduce Galerkin's method with an abstract problem posed as a [[weak formulation]] on a [[Hilbert space]] &lt;math&gt;V&lt;/math&gt;, namely,
: find &lt;math&gt;u\in V&lt;/math&gt; such that for all &lt;math&gt;v\in V, a(u,v) = f(v)&lt;/math&gt;.

Here, &lt;math&gt;a(\cdot,\cdot)&lt;/math&gt; is a [[bilinear form]] (the exact requirements on &lt;math&gt;a(\cdot,\cdot)&lt;/math&gt; will be specified later) and &lt;math&gt;f&lt;/math&gt; is a bounded linear functional on &lt;math&gt;V&lt;/math&gt;.

===Galerkin dimension reduction===
Choose a subspace &lt;math&gt;V_n \subset V&lt;/math&gt; of dimension ''n'' and solve the projected problem:
: Find &lt;math&gt;u_n\in V_n&lt;/math&gt; such that for all &lt;math&gt;v_n\in V_n, a(u_n,v_n) = f(v_n)&lt;/math&gt;.

We call this the '''Galerkin equation'''. Notice that the equation has remained unchanged and only the spaces have changed.
Reducing the problem to a finite-dimensional vector subspace allows us to numerically compute &lt;math&gt; u_n &lt;/math&gt; as a finite linear combination of the basis vectors in &lt;math&gt; V_n &lt;/math&gt;.

===Galerkin orthogonality===
The key property of the Galerkin approach is that the error is orthogonal to the chosen subspaces. Since  &lt;math&gt;V_n \subset V&lt;/math&gt;, we can use &lt;math&gt;v_n&lt;/math&gt; as a test vector in the original equation. Subtracting the two, we get the Galerkin orthogonality relation for the error, &lt;math&gt;\epsilon_n = u-u_n&lt;/math&gt; which is the error between the solution of the original problem, &lt;math&gt;u&lt;/math&gt;, and the solution of the Galerkin equation, &lt;math&gt;u_n&lt;/math&gt;

:&lt;math&gt; a(\epsilon_n, v_n) = a(u,v_n) - a(u_n, v_n) = f(v_n) - f(v_n) = 0.&lt;/math&gt;

===Matrix form===
Since the aim of Galerkin's method is the production of a [[system of linear equations|linear system of equations]], we build its matrix form, which can be used to compute the solution by a computer program.

Let &lt;math&gt;e_1, e_2,\ldots,e_n&lt;/math&gt; be a [[basis (linear algebra)|basis]] for &lt;math&gt;V_n&lt;/math&gt;. Then, it is sufficient to use these in turn for testing the Galerkin equation, i.e.: find &lt;math&gt;u_n \in V_n&lt;/math&gt; such that

:&lt;math&gt;a(u_n, e_i) = f(e_i) \quad i=1,\ldots,n.&lt;/math&gt;

We expand &lt;math&gt;u_n&lt;/math&gt; with respect to this basis, &lt;math&gt;u_n = \sum_{j=1}^n u_je_j&lt;/math&gt; and insert it into the equation above, to obtain

:&lt;math&gt;a\left(\sum_{j=1}^n u_je_j, e_i\right) = \sum_{j=1}^n u_j a(e_j, e_i) = f(e_i) \quad i=1,\ldots,n.&lt;/math&gt;

This previous equation is actually a linear system of equations &lt;math&gt;Au=f&lt;/math&gt;, where

:&lt;math&gt;A_{ij} = a(e_j, e_i), \quad f_i = f(e_i).&lt;/math&gt;

====Symmetry of the matrix====
Due to the definition of the matrix entries, the matrix of the Galerkin equation is [[symmetric matrix|symmetric]] if and only if the bilinear form &lt;math&gt;a(\cdot,\cdot)&lt;/math&gt; is symmetric.

==Analysis of Galerkin methods==
Here, we will restrict ourselves to symmetric [[bilinear form]]s, that is

:&lt;math&gt;a(u,v) = a(v,u).&lt;/math&gt;

While this is not really a restriction of Galerkin methods, the application of the standard theory becomes much simpler. Furthermore, a [[Petrov–Galerkin method]] may be required in the nonsymmetric case.

The analysis of these methods proceeds in two steps. First, we will show that the Galerkin equation is a [[well-posed problem]] in the sense of [[Hadamard]] and therefore admits a unique solution. In the second step, we study the quality of approximation of the Galerkin solution &lt;math&gt;u_n&lt;/math&gt;.

The analysis will mostly rest on two properties of the [[bilinear form]], namely
* Boundedness: for all &lt;math&gt;u,v\in V&lt;/math&gt; holds
*:&lt;math&gt;a(u,v) \le C \|u\|\, \|v\|&lt;/math&gt; for some constant &lt;math&gt;C&gt;0&lt;/math&gt;
* Ellipticity: for all &lt;math&gt;u\in V&lt;/math&gt; holds
*:&lt;math&gt;a(u,u) \ge c \|u\|^2&lt;/math&gt; for some constant &lt;math&gt;c&gt;0.&lt;/math&gt;
By the Lax-Milgram theorem (see [[weak formulation]]), these two conditions imply well-posedness of the original problem in weak formulation. All norms in the following sections will be norms for which the above inequalities hold (these norms are often called an energy norm).

===Well-posedness of the Galerkin equation===
Since &lt;math&gt;V_n \subset V&lt;/math&gt;, boundedness and ellipticity of the bilinear form apply to &lt;math&gt;V_n&lt;/math&gt;. Therefore, the well-posedness of the Galerkin problem is actually inherited from the well-posedness of the original problem.

===Quasi-best approximation (Céa's lemma)===
{{main|Céa's lemma}}
The error &lt;math&gt;u-u_n&lt;/math&gt; between the original and the Galerkin solution admits the estimate

:&lt;math&gt;\|u-u_n\| \le \frac{C}{c} \inf_{v_n\in V_n} \|u-v_n\|.&lt;/math&gt;

This means, that up to the constant &lt;math&gt;C/c&lt;/math&gt;, the Galerkin solution &lt;math&gt;u_n&lt;/math&gt;
is as close to the original solution &lt;math&gt;u&lt;/math&gt; as any other vector in &lt;math&gt;V_n&lt;/math&gt;. In particular, it will be sufficient to study approximation by spaces &lt;math&gt;V_n&lt;/math&gt;, completely forgetting about the equation being solved.

====Proof====
Since the proof is very simple and the basic principle behind all Galerkin methods, we include it here:
by ellipticity and boundedness of the bilinear form (inequalities) and Galerkin orthogonality (equals sign in the middle), we have for arbitrary &lt;math&gt;v_n\in V_n&lt;/math&gt;:

:&lt;math&gt;c\|u-u_n\|^2 \le a(u-u_n, u-u_n) = a(u-u_n, u-v_n) \le C \|u-u_n\| \, \|u-v_n\|.&lt;/math&gt;

Dividing by &lt;math&gt;c \|u-u_n\|&lt;/math&gt; and taking the infimum over all possible &lt;math&gt;v_n&lt;/math&gt; yields the lemma.

== See also ==
* [[Ritz method]]

==References==
&lt;!--
&lt;ref name=ErnGuermond&gt; A. Ern, J.L. Guermond, ''Theory and practice of finite elements'', Springer, 2004, ISBN 0-387-20574-8 &lt;/ref&gt;
&lt;ref name=BrennerScott&gt; S. Brenner, R. L. Scott, ''The Mathematical Theory of Finite Element Methods'', 2nd edition, Springer, 2005, ISBN 0-387-95451-1 &lt;/ref&gt;
&lt;ref name=Ciarlet&gt; P. G. Ciarlet, ''The Finite Element Method for Elliptic Problems'', North-Holland, 1978, ISBN 0-444-85028-7 &lt;/ref&gt;
&lt;ref name=Saad&gt; Y. Saad, ''Iterative Methods for Sparse Linear Systems'', 2nd edition, SIAM, 2003, ISBN 0-89871-534-2 &lt;/ref&gt;
--&gt;
&lt;references /&gt;

== External links ==
* {{Springer |title=Galerkin method |id=p/g043040}}
* [http://mathworld.wolfram.com/GalerkinMethod.html Galerkin Method from MathWorld]

{{Numerical PDE}}

{{Authority control}}

{{DEFAULTSORT:Galerkin Method}}
[[Category:Numerical analysis]]
[[Category:Numerical differential equations]]
[[Category:Articles containing proofs]]</text>
      <sha1>7dyezqjnuafikhmuk4vfmsbb7rqkxg0</sha1>
    </revision>
  </page>
  <page>
    <title>Greenwood Book</title>
    <ns>0</ns>
    <id>32828844</id>
    <redirect title="Isaac Greenwood" />
    <revision>
      <id>446137798</id>
      <parentid>446137698</parentid>
      <timestamp>2011-08-22T11:57:05Z</timestamp>
      <contributor>
        <username>Icairns</username>
        <id>64875</id>
      </contributor>
      <comment>+categ</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="71">#REDIRECT [[Isaac Greenwood]]

[[Category:Mathematics books|Greenwood]]</text>
      <sha1>bpvmednv6a243v786qv292pwdmrbu0h</sha1>
    </revision>
  </page>
  <page>
    <title>History of information theory</title>
    <ns>0</ns>
    <id>5642452</id>
    <revision>
      <id>796122108</id>
      <parentid>796121710</parentid>
      <timestamp>2017-08-18T16:43:29Z</timestamp>
      <contributor>
        <username>BarrelProof</username>
        <id>13560851</id>
      </contributor>
      <comment>The article is not unsourced, as it very explicitly refers to papers by Shannon, Nyquist, and Hartley. It doesn't use the usual citation format of Wikipedia, but it is not unsourced.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8293">{{refimprove|date=August 2017}}

The decisive event which established the discipline of '''[[information theory]]''', and brought it to immediate worldwide attention, was the publication of [[Claude E. Shannon]]'s classic paper "[[A Mathematical Theory of Communication]]" in the ''[[Bell System Technical Journal]]'' in July and October 1948.

In this revolutionary and groundbreaking paper, the work for which Shannon had substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion that 
:"The fundamental problem of communication is that of reproducing at one point, either exactly or approximately, a message selected at another point."

With it came the ideas of 
* the [[information entropy]] and [[redundancy (information theory)|redundancy]] of a source, and its relevance through the [[Shannon's source coding theorem|source coding theorem]];
* the [[mutual information]], and the [[channel capacity]] of a noisy channel, including the promise of perfect loss-free communication given by the [[noisy-channel coding theorem]];
* the practical result of the [[Shannon–Hartley theorem|Shannon–Hartley law]] for the channel capacity of a Gaussian channel; and of course
* the [[bit]] - a new way of seeing the most fundamental unit of information.

==Before 1948==

=== Early telecommunications ===

Some of the oldest methods of instant [[telecommunication]]s implicitly use many of the ideas that would later be quantified in information theory.  Modern [[telegraphy]], starting in the 1830s, used [[Morse code]], in which [[Letter frequencies|more common letters]] (like "E", which is expressed as one "dot") are transmitted more quickly than less common letters (like "J", which is expressed by one "dot" followed by three "dashes").  The idea of encoding information in this manner is the cornerstone of [[lossless data compression]].  A hundred years later, [[frequency modulation]] illustrated that [[Bandwidth (signal processing)|bandwidth]] can be considered merely another degree of freedom.  The [[vocoder]], now largely looked at as an audio engineering curiosity, was originally designed in 1939 to use less bandwidth than that of an original message, in much the same way that [[mobile phone]]s now trade off voice quality with bandwidth.

===Quantitative ideas of information===
The most direct antecedents of Shannon's work were two papers published in the 1920s by [[Harry Nyquist]] and [[Ralph Hartley]], who were both still research leaders at Bell Labs when Shannon arrived in the early 1940s.

Nyquist's 1924 paper, "Certain Factors Affecting Telegraph Speed", is mostly concerned with some detailed engineering aspects of telegraph signals. But a more theoretical section discusses quantifying "intelligence" and the "line speed" at which it can be transmitted by a communication system, giving the relation

:&lt;math&gt;W = K \log m \,&lt;/math&gt;

where ''W'' is the speed of transmission of intelligence, ''m'' is the number of different voltage levels to choose from at each time step, and ''K'' is a constant.

Hartley's 1928 paper, called simply "Transmission of Information", went further by using the word ''information'' (in a technical sense), and making explicitly clear that information in this context was a measurable quantity, reflecting only the receiver's ability to distinguish that one sequence of symbols had been intended by the sender rather than any other—quite regardless of any associated meaning or other psychological or semantic aspect the symbols might represent. This amount of information he quantified as

:&lt;math&gt;H = \log S^n \,&lt;/math&gt;

where ''S'' was the number of possible symbols, and ''n'' the number of symbols in a transmission. The natural unit of information was therefore the decimal digit, much later renamed the [[Hartley (unit)|hartley]] in his honour as a unit or scale or measure of information. The [[Hartley information]], ''H''&lt;sub&gt;0&lt;/sub&gt;, is still used as a quantity for the logarithm of the total number of possibilities.

A similar unit of log&lt;sub&gt;10&lt;/sub&gt; probability, the ''ban'', and its derived unit the [[ban (unit)|deciban]] (one tenth of a ban), were introduced by [[Alan Turing]] in 1940 as part of the statistical analysis of the breaking of the German second world war [[Cryptanalysis of the Enigma|Enigma]] cyphers. The ''decibannage'' represented the reduction in (the logarithm of) the total number of possibilities (similar to the change in the Hartley information); and also the [[log-likelihood ratio]] (or change in the [[weight of evidence]]) that could be inferred for one hypothesis over another from a set of observations. The expected change in the weight of evidence is equivalent to what was later called the Kullback [[Kullback–Leibler divergence#Discrimination information|discrimination information]].

But underlying this notion was still the idea of equal a-priori probabilities, rather than the information content of events of unequal probability; nor yet any underlying picture of questions regarding the communication of such varied outcomes.

===Entropy in statistical mechanics===
One area where unequal probabilities were indeed well known was statistical mechanics, where [[Ludwig Boltzmann]] had, in the context of his [[H-theorem]] of 1872, first introduced the quantity

: &lt;math&gt;H = - \sum f_i \log f_i &lt;/math&gt;

as a measure of the breadth of the spread of states available to a single particle in a gas of like particles, where ''f'' represented the relative [[frequency distribution]] of each possible state. Boltzmann argued mathematically that the effect of collisions between the particles would cause the ''H''-function to inevitably increase from any initial configuration until equilibrium was reached; and further identified it as an underlying microscopic rationale for the macroscopic [[Entropy (classical thermodynamics)|thermodynamic entropy]] of [[Clausius]].

Boltzmann's definition was soon reworked by the American mathematical physicist [[J. Willard Gibbs]] into a general formula for statistical-mechanical entropy, no longer requiring identical and non-interacting particles, but instead based on the probability distribution ''p&lt;sub&gt;i&lt;/sub&gt;'' for the complete microstate ''i'' of the total system:

: &lt;math&gt;S = -k_\text{B} \sum p_i \ln p_i \,&lt;/math&gt;

This (Gibbs) entropy, from statistical mechanics, can be found to directly correspond to the Clausius's classical thermodynamic [[Entropy (classical thermodynamics)|definition]].

Shannon himself was apparently not particularly aware of the [[Entropy in thermodynamics and information theory|close similarity]] between his new measure and earlier work in thermodynamics, but [[John von Neumann]] was. It is said that, when Shannon was deciding what to call his new measure and fearing the term 'information' was already over-used, von Neumann told him firmly: "You should call it entropy, for two reasons. In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one really knows what entropy really is, so in a debate you will always have the advantage."

(Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by [[Rolf Landauer]] in the 1960s, are explored further in the article ''[[Entropy in thermodynamics and information theory]]'').

==Development since 1948==
{{Expand section|date=June 2008}}
The publication of Shannon's 1948 paper, "[[A Mathematical Theory of Communication]]", in the ''Bell System Technical Journal'' was the founding of information theory as we know it today. Many developments and applications of the theory have taken place since then, which have made many modern devices for data communication and storage such as [[CD-ROM]]s and [[mobile phone]]s possible.  Notable developments are listed in a [[timeline of information theory]].

==See also==
* [[Timeline of information theory]]
* [[Claude Shannon]]
* [[Ralph Hartley]]
* [[H-theorem]]

{{DEFAULTSORT:History Of Information Theory}}
[[Category:Information theory]]</text>
      <sha1>ikr0j7tm0w1zumdheif63yrok3a58oa</sha1>
    </revision>
  </page>
  <page>
    <title>Homothetic transformation</title>
    <ns>0</ns>
    <id>386138</id>
    <revision>
      <id>828858984</id>
      <parentid>809322466</parentid>
      <timestamp>2018-03-05T04:44:16Z</timestamp>
      <contributor>
        <ip>206.87.84.135</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4314">[[Image:Geom podobnost stejnolehlest.svg|thumb|right|334px|Two similar geometric figures related by a homothetic transformation with respect to a [[homothetic center]] '''S'''. The angles at corresponding points are the same and have the same sense; for example, the angles ABC and A'B'C' are both clockwise and equal in magnitude.]]

In [[mathematics]], a '''homothety''' (or '''homothecy''', or '''homogeneous dilation''') is a [[Transformation (mathematics)|transformation]] of an [[affine space]] determined by a point ''S'' called its ''center'' and a nonzero number ''λ'' called its ''ratio'', which sends
:&lt;math&gt; M \mapsto S + \lambda \overrightarrow{SM}, &lt;/math&gt;
in other words it fixes ''S'', and sends any ''M'' to another point ''N'' such that the segment ''SN'' is on the same line as ''SM'', but scaled by a factor ''λ''.&lt;ref&gt;{{harvtxt|Hadamard|p=145}}&lt;/ref&gt; In [[Euclidean geometry]] homotheties are the [[Similarity (geometry)|similarities]] that fix a point and either preserve (if {{nowrap|''λ'' &amp;gt; 0}}) or reverse (if {{nowrap|''λ'' &amp;lt; 0}}) the direction of all vectors. Together with the [[Translation (geometry)|translations]], all homotheties of an affine (or Euclidean) space form a [[group (mathematics)|group]], the group of '''dilations''' or '''homothety-translations'''. These are precisely the [[affine transformation]]s with the property that the image of every line ''L'' is a line [[parallel (geometry)|parallel]] to ''L''.

In [[projective geometry]], a homothetic transformation is a similarity transformation (i.e., fixes a given elliptic involution) that leaves the line at infinity pointwise [[invariant (mathematics)|invariant]].&lt;ref&gt;{{harvtxt|Tuller|p=119}}&lt;/ref&gt;

In Euclidean geometry, a homothety of ratio ''λ'' multiplies distances between points by |''λ''| and all areas by ''λ''&lt;sup&gt;2&lt;/sup&gt;.  The first number is called the ''ratio of magnification'' or ''dilation factor'' or ''scale factor'' or ''similitude ratio''. Such a transformation can be called an '''enlargement''' if the scale factor exceeds&amp;nbsp;1. The above-mentioned fixed point ''S'' is called ''[[homothetic center]]'' or ''center of similarity'' or ''center of similitude''.

==Homothety and uniform scaling==
If the [[homothetic center]] ''S'' happens to coincide with the [[Origin (mathematics)|origin]] ''O'' of the vector space (''S'' ≡ ''O''), then every homothety with scale factor ''λ'' is equivalent to a [[uniform scaling]] by the same factor, which sends

:&lt;math&gt; \overrightarrow{OM} \mapsto \lambda \overrightarrow{OM}. &lt;/math&gt;

As a consequence, in the specific case in which ''S'' ≡ ''O'', the homothety becomes a [[linear transformation]], which preserves not only the collinearity of points (straight lines are mapped to straight lines), but also vector addition and scalar multiplication.

The image of a point (''x'', ''y'') after a homothety with center (''a'', ''b'') and scale factor ''λ'' is given by (''a'' + ''λ''(''x'' − ''a''), ''b'' + ''λ''(''y'' − ''b'')).

==See also==
*[[Scaling (geometry)]] a similar notion in vector spaces
*[[Homothetic center]], the center of a homothetic transformation taking one of a pair of shapes into the other
*The [[Hadwiger conjecture (combinatorial geometry)|Hadwiger conjecture]] on the number of strictly smaller homothetic copies of a convex body that may be needed to cover it
*[[Homothetic function (economics)]], a function of the form ''f''(''U''(''y'')) in which ''U'' is a [[homogeneous function]] and ''f'' is a [[monotonic function|monotonically increasing function]].

== Notes ==
&lt;references/&gt;

==References==
* {{ citation | first1 = J. | last1 = Hadamard | title = Lessons in Plane Geometry }}.
* {{ citation | first1 = Bruce E. | last1 = Meserve | year =1955 | title = Fundamental Concepts of Geometry | chapter = Homothetic transformations | pages = 166–169 | publisher = [[Addison-Wesley]] }}.
* {{ citation | last1 = Tuller | first1 =  Annita | title = A Modern Introduction to Geometries | date=1967 | location=Princeton, NJ | publisher=D. Van Nostrand Co. | series=University Series in Undergraduate Mathematics}}.

==External links==
* [http://www.cut-the-knot.org/Curriculum/Geometry/Homothety.shtml Homothety], interactive applet from [[Cut-the-Knot]].

[[Category:Transformation (function)]]</text>
      <sha1>s08zl1fssn9isv58js2wbvmaxf5la07</sha1>
    </revision>
  </page>
  <page>
    <title>Hypergeometric identity</title>
    <ns>0</ns>
    <id>693848</id>
    <revision>
      <id>790710381</id>
      <parentid>776405812</parentid>
      <timestamp>2017-07-15T15:47:10Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Definition */LaTeX spacing clean up, replaced: \,&lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2839">{{For|identities satisfied by the hypergeometric function|List of hypergeometric identities}}
In [[mathematics]], '''hypergeometric identities''' are equalities involving sums over hypergeometric terms, i.e. the coefficients occurring in [[hypergeometric series]]. These [[Identity (mathematics)|identities]] occur frequently in solutions to [[combinatorial]] problems, and also in the [[analysis of algorithms]]. 

These identities were traditionally found 'by hand'. There exist now several algorithms which can find and ''prove'' all hypergeometric identities.

== Examples ==
: &lt;math&gt; \sum_{i=0}^{n} {n \choose i} = 2^{n} &lt;/math&gt;

: &lt;math&gt; \sum_{i=0}^{n} {n \choose i}^2 = {2n \choose n} &lt;/math&gt;

: &lt;math&gt; \sum_{k=0}^{n} k {n \choose k} = n2^{n-1} &lt;/math&gt;

: &lt;math&gt; \sum_{i=n}^{N} i{i \choose n} = (n+1){N+2\choose n+2}-{N+1\choose n+1}       &lt;/math&gt;

== Definition ==
There are two definitions of hypergeometric terms, both used in different cases as explained below. See also [[hypergeometric series]].

A term ''t&lt;sub&gt;k&lt;/sub&gt;'' is a hypergeometric term if
: &lt;math&gt;\frac{t_{k+1}}{t_k} &lt;/math&gt;

is a [[rational function]] in ''k''.

A term ''F(n,k)'' is a hypergeometric term if
: &lt;math&gt;\frac{F(n,k+1)}{F(n,k)} &lt;/math&gt;

is a rational function in ''k''.

There exist two types of sums over hypergeometric terms, the definite and indefinite sums. A definite sum is of the form
: &lt;math&gt; \sum_{k} t_k.&lt;/math&gt;

The indefinite sum is of the form
: &lt;math&gt; \sum_{k=0}^{n} F(n,k).&lt;/math&gt;

== Proofs ==
Although in the past one{{who?|date=December 2016}} has found proofs of certain identities{{vague|date=December 2016}} there exist several algorithms{{vague|date=December 2016}} to find and prove identities. These algorithms first find a ''simple expression'' for a sum over hypergeometric terms and then provide a certificate which anyone could use to easily check and prove the correctness of the identity.

For each of the hypergeometric sum types there exist one or more methods to find a ''simple expression''. These methods also provide a certificate to easily check the proof of an identity:
* ''Definite sums'': Sister Celine's Method, Zeilberger's algorithm
* ''Indefinite sums'': [[Gosper's algorithm]]

A book named '''A = B''' has been written by [[Marko Petkovšek]], [[Herbert Wilf]] and [[Doron Zeilberger]] describing the three main approaches described above.

==See also==
* [[Table of Newtonian series]]

== External links ==
* [http://www.math.upenn.edu/~wilf/AeqB.html The book "A = B"], this book is freely downloadable from the internet.
* [http://www.exampleproblems.com/wiki/index.php?title=Special_Functions Special-functions examples] at exampleproblems.com

[[Category:Factorial and binomial topics]]
[[Category:Hypergeometric functions]]
[[Category:Mathematical identities]]
[[fr:Identités hypergéométriques]]</text>
      <sha1>2bcz68ilns5dk155p1y74jxot9aeuql</sha1>
    </revision>
  </page>
  <page>
    <title>Ideal point</title>
    <ns>0</ns>
    <id>4995922</id>
    <revision>
      <id>865883104</id>
      <parentid>865189876</parentid>
      <timestamp>2018-10-26T20:08:07Z</timestamp>
      <contributor>
        <username>Cewbot</username>
        <id>23646674</id>
      </contributor>
      <minor/>
      <comment>bot: Convert [[Ferdinand Karl Schweikart]] to wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6632">{{About |ideal points in [[hyperbolic geometry]]|similar points in other geometries|Point at infinity}}

[[Image:Ideal circles.svg|thumb|right|200px|Three [[Ideal triangle]]s in the [[Poincaré disk model]], the '''[[vertex (geometry)|vertices]]''' are '''ideal points''']]

In [[hyperbolic geometry]], an '''ideal point''', '''omega point'''&lt;ref&gt;{{cite book |last1=Sibley |first1=Thomas Q. |title=The geometric viewpoint : a survey of geometries |date=1998 |publisher=Addison-Wesley |location=Reading, Mass. |isbn=0-201-87450-4 |page=109 |url=http://www.employees.csbsju.edu/tsibley/textbook.htm}}&lt;/ref&gt; or '''point at infinity''' is a [[well defined]] point outside the hyperbolic plane or space.
Given a line ''l'' and a point ''P'' not on ''l'', right- and left-[[limiting parallel]]s to ''l'' through ''P'' [[Convergence (mathematics)|converge]] to ''l'' at ''ideal points''.

Unlike the projective case, ideal points form a [[manifold with boundary|boundary]], not a submanifold. So, these lines do not ''intersect'' at an ideal point and such points, although [[well defined]], do not belong to the hyperbolic space itself.

The ideal points together form the [[Cayley absolute]] or boundary of a [[hyperbolic geometry]]. 
For instance, the [[unit circle]] forms the Cayley absolute of the [[Poincaré disk model]] and the [[Klein disk model]].
While the real line forms the Cayley absolute of the [[Poincaré half-plane model]] .&lt;ref&gt;{{Citation | last1=Struve | first1=Horst | last2=Struve | first2=Rolf | title=Non-euclidean geometries: the Cayley-Klein approach |doi=10.1007/s00022-010-0053-z | mr=2739193 | year=2010 | journal=Journal of Geometry | issn=0047-2468 | volume=89 | issue=1 | pages=151–170}}&lt;/ref&gt;

[[Pasch's axiom]] and the [[exterior angle theorem]] still hold for an omega triangle, defined by two points in hyperbolic space and an omega point.&lt;ref&gt;{{cite book|last =Hvidsten|first =Michael|title = Geometry with Geometry Explorer|publisher = McGraw-Hill|year = 2005 | location = New York, NY |pages = 276–283 | isbn = 0-07-312990-9}}&lt;/ref&gt;

==Properties==

* The hyperbolic distance between an ideal point and any other point or ideal point is infinite.
* The centres of [[horocycle]]s and [[horoball]]s are ideal points; two [[horocycle]]s are [[concentric]] when they have the same centre.

==Polygons with ideal vertices==

===Ideal triangles===
{{main article|Ideal triangle}}

if all vertices of a [[hyperbolic triangle|triangle]] are ideal points the triangle is an [[ideal triangle]].

Ideal triangles have a number of interesting properties:

* All ideal triangles are congruent. 
* The interior angles of an ideal triangle are all zero.
* Any ideal triangle has an infinite perimeter.
* Any ideal triangle has area &lt;math&gt; \pi / -K &lt;/math&gt; where K is the (negative) curvature of the plane.&lt;ref name="Thurston 2012"&gt;{{cite web | url=http://math.berkeley.edu/~qchu/Notes/274/Lecture5.pdf | title=274 Curves on Surfaces, Lecture 5 | date=Fall 2012 | accessdate=23 July 2013 | author=Thurston, Dylan}}&lt;/ref&gt;

===Ideal quadrilaterals===

if all vertices of a [[quadrilateral]] are ideal points the quadrilateral is an ideal quadrilateral.

While all ideal triangles are congruent, not all quadrilaterals are, the diagonals can make different angles with each other resulting in noncongruent quadrilaterals
having said this:

* The interior angles of an ideal quadrilateral are all zero.
* Any ideal quadrilateral has an infinite perimeter.
* Any ideal [[convex polygon|(convex non intersecting)]] quadrilateral has area &lt;math&gt; 2 \pi / -K &lt;/math&gt; where K is the (negative) curvature of the plane.

===Ideal square===
The ideal quadrilateral where the two diagonals are [[perpendicular]] to each other form an ideal square.

It was use by [[Ferdinand Karl Schweikart]] in his memorandum on what he called "astral geometry", one of the first publications acknowledging the possibility of [[hyperbolic geometry]].&lt;ref&gt;{{cite book|last1=Bonola|first1=Roberto|title=Non-Euclidean geometry : a critical and historical study of its developments|date=1955|publisher=Dover|location=New York, NY|isbn=0486600270|pages=75–77|edition=Unabridged and unaltered republ. of the 1. English translation 1912.}}&lt;/ref&gt;

===Ideal ''n''-gons===
An ideal ''n''-gon can be subdivided into {{nowrap|(''n'' − 2)}} ideal triangles, with area {{nowrap|(''n'' − 2)}} times the area of an ideal triangle.

==Representations in models of hyperbolic geometry==

In the [[Klein disk model]] and the [[Poincaré disk model]] of the hyperbolic plane. In both disk models the '''ideal points''' are on the [[unit circle]] (hyperbolic plane)  or [[unit sphere]] (higher dimensions)  which is the unreachable boundary of the hyperbolic plane. 
 		  
When projecting the same hyperbolic line to the [[Klein disk model]] and the [[Poincaré disk model]] both lines go through the same two ideal points.(the ideal points in both models are on the same spot).

===Klein disk model ===

Given two distinct points ''p'' and ''q'' in the open unit disk the unique straight line connecting them intersects the unit circle in two '''ideal points''', ''a'' and ''b'', labeled so that the points are, in order, ''a'', ''p'', ''q'', ''b'' so that |aq| &gt; |ap| and |pb| &gt; |qb|. Then the hyperbolic distance between ''p'' and ''q'' is expressed as

:&lt;math&gt;d(p,q) = \frac{1}{2} \log \frac{ \left| qa \right| \left| bp \right| }{ \left| pa \right| \left| bq \right| } ,&lt;/math&gt;

=== Poincaré disk model ===

Given two distinct points ''p'' and ''q'' in the open unit disk then the unique circle [[arc (geometry)|arc]] orthogonal to the boundary  connecting them intersects the unit circle in two '''ideal points''', ''a'' and ''b'', labeled so that the points are, in order, ''a'', ''p'', ''q'', ''b'' so that |aq| &gt; |ap| and |pb| &gt; |qb|. Then the hyperbolic distance between ''p'' and ''q'' is expressed as

:&lt;math&gt;d(p,q) =  \log \frac{ \left| qa \right| \left| bp \right| }{ \left| pa \right| \left| bq \right| } ,&lt;/math&gt;

Where the distances are measured along the (straight line) segments aq, ap, pb and qb.

===Poincaré half-plane model===
In the [[Poincaré half-plane model]] the  '''ideal points''' are the points on the boundary axis. There is also another ideal point that is not represented in the half-plane model (but rays parallel to the positive y-axis approach it).

===Hyperboloid model===
In the [[hyperboloid model]] there are no '''ideal points'''.

== See also == 
* [[Ideal triangle]] 
* [[Points at infinity]] for uses in other geometries.

==References==

{{reflist}}

[[Category:Hyperbolic geometry]]
[[Category:Infinity]]</text>
      <sha1>d5ilzfxcawhi5lifzslvxhw9lqjxr2a</sha1>
    </revision>
  </page>
  <page>
    <title>Implicational propositional calculus</title>
    <ns>0</ns>
    <id>5795043</id>
    <revision>
      <id>859144893</id>
      <parentid>798294979</parentid>
      <timestamp>2018-09-12T01:08:44Z</timestamp>
      <contributor>
        <username>JRSpriggs</username>
        <id>1026643</id>
      </contributor>
      <comment>/* Proof */ simplify the second half of the completeness proof</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21117">In [[mathematical logic]], the '''implicational propositional calculus''' is a version of [[classical logic|classical]] [[propositional calculus]] which uses only one [[logical connective|connective]], called [[material conditional|implication or conditional]]. In [[formula]]s, this [[binary operation]] is indicated by "implies", "if ..., then ...", "→", "&lt;math&gt;\rightarrow &lt;/math&gt;", etc..

==Virtual completeness as an operator==
Implication alone is not [[Functional completeness|functionally complete]] as a [[logical operator]] because one cannot form all other two-valued [[truth function]]s from it. However, if one has a [[propositional formula]] which is known to be [[False (logic)|false]] and uses that as if it were a nullary connective for falsity, then one can define all other truth functions. So implication is virtually complete as an operator. If ''P'',''Q'', and ''F'' are propositions and ''F'' is known to be false, then:
*¬''P'' is [[logical equivalence|equivalent]] to ''P'' → ''F''
*''P'' ∧ ''Q'' is equivalent to (''P'' → (''Q'' → ''F'')) → ''F''
*''P'' ∨ ''Q'' is equivalent to (''P'' → ''Q'') → ''Q''
*''P'' ↔ ''Q'' is equivalent to ((''P'' → ''Q'') → ((''Q'' → ''P'') → ''F'')) → ''F''

More generally, since the above operators are known to be functionally complete, it follows that any truth function can be expressed in terms of "→" and "''F''", if we have a proposition ''F'' which is known to be false.

It is worth noting that ''F'' is not definable from → and arbitrary sentence variables: any formula constructed from → and propositional variables must receive the value true when all of its variables are evaluated to true.
It follows as a corollary that {→} is not functionally complete.  It cannot, for example, be used to define the two-place truth function that always returns ''false''.

==Axiom system==
The following statements are considered [[Tautology (logic)|tautologies]] (irreducible and intuitively true, by definition).
*[[Axiom schema]] 1 is ''P'' → (''Q'' → ''P'').
*Axiom schema 2 is (''P'' → (''Q'' → ''R'')) → ((''P'' → ''Q'') → (''P'' → ''R'')).
*Axiom schema 3 ([[Peirce's law]]) is ((''P'' → ''Q'') → ''P'') → ''P''.
*The one non-nullary [[rule of inference]] ([[modus ponens]]) is: from ''P'' and ''P'' → ''Q'' infer ''Q''.
Where in each case, ''P'', ''Q'', and ''R'' may be replaced by any formulas which contain only "→" as a connective. If Γ is a set of formulas and ''A'' a formula, then &lt;math&gt;\Gamma\vdash A&lt;/math&gt; means that ''A'' is derivable using the axioms and rules above and formulas from Γ as additional hypotheses.

Łukasiewicz (1948) found an axiom system for the implicational calculus, which replaces the schemas 1–3 above with a single schema
*((''P'' → ''Q'') → ''R'') → ((''R'' → ''P'') → (''S'' → ''P'')).
He also argued that there is no shorter axiom system.

==Basic properties of derivation==
Since all axioms and rules of the calculus are schemata, derivation is closed under [[substitution (logic)|substitution]]:

:If &lt;math&gt;\Gamma\vdash A,&lt;/math&gt; then &lt;math&gt;\sigma(\Gamma)\vdash\sigma(A),&lt;/math&gt;

where σ is any substitution (of formulas using only implication).

The implicational propositional calculus also satisfies the [[deduction theorem]]:

:If &lt;math&gt;\Gamma,A\vdash B&lt;/math&gt;, then &lt;math&gt;\Gamma\vdash A\to B.&lt;/math&gt;

As explained in the [[deduction theorem]] article, this holds for any axiomatic extension of the system containing axiom schemas 1 and 2 above and modus ponens.

==Completeness==
The implicational propositional calculus is [[completeness (logic)|semantically complete]] with respect to the usual two-valued semantics of classical propositional logic. That is, if Γ is a set of implicational formulas, and ''A'' is an implicational formula [[entailment|entailed]] by Γ, then &lt;math&gt;\Gamma\vdash A&lt;/math&gt;.

===Proof===
A proof of the completeness theorem is outlined below. First, using the [[compactness theorem]] and the deduction theorem, we may reduce the completeness theorem to its special case with empty Γ, i.e., we only need to show that every tautology is derivable in the system.

The proof is similar to completeness of full propositional logic, but it also uses the following idea to overcome the functional incompleteness of implication. If ''A'' and ''F'' are formulas, then {{math|''A'' → ''F''}} is equivalent to {{math|(¬''A*'') ∨ ''F'',}} where ''A*'' is the result of replacing in ''A'' all, some, or none of the occurrences of ''F'' by falsity. Similarly, {{math|(''A'' → ''F'') → ''F''}} is equivalent to {{math|''A*'' ∨ ''F''.}} So under some conditions, one can use them as substitutes for saying ''A*'' is false or ''A*'' is true respectively.

We first observe some basic facts about derivability:
{{NumBlk|:|&lt;math&gt;A\to B,B\to C\vdash A\to C&lt;/math&gt;|{{EquationRef|1}}}}
::Indeed, we can derive ''A'' → (''B'' → ''C'') using Axiom 1, and then derive ''A'' → ''C'' by modus ponens (twice) from Ax. 2.
{{NumBlk|:|&lt;math&gt;A\to B\vdash(B\to C)\to(A\to C)&lt;/math&gt;|{{EquationRef|2}}}}
::This follows from ({{EquationNote|1}}) by the deduction theorem.
{{NumBlk|:|&lt;math&gt;A\to C,(A\to B)\to C\vdash C&lt;/math&gt;|{{EquationRef|3}}}}
::If we further assume ''C'' → ''B'', we can derive {{math|''A'' → ''B''}} using ({{EquationNote|1}}), then we derive ''C'' by modus ponens. This shows &lt;math&gt;A\to C,(A\to B)\to C,C\to B\vdash C&lt;/math&gt;, and the deduction theorem gives &lt;math&gt;A\to C,(A\to B)\to C\vdash(C\to B)\to C&lt;/math&gt;. We apply Ax. 3 to obtain ({{EquationNote|3}}).

Let ''F'' be an arbitrary fixed formula. For any formula ''A'', we define {{math|''A''&lt;sup&gt;0&lt;/sup&gt; {{=}} (''A'' → ''F'')}} and {{math|''A''&lt;sup&gt;1&lt;/sup&gt; {{=}} ((''A'' → ''F'') → ''F'').}} Let us consider only formulas in propositional variables ''p''&lt;sub&gt;1&lt;/sub&gt;, ..., ''p&lt;sub&gt;n&lt;/sub&gt;''. We claim that for every formula ''A'' in these variables and every [[Valuation (logic)|truth assignment]] ''e'',
{{NumBlk|:|&lt;math&gt;p_1^{e(p_1)},\dots,p_n^{e(p_n)}\vdash A^{e(A)}.&lt;/math&gt;|{{EquationRef|4}}}}
We prove ({{EquationNote|4}}) by induction on ''A''. The base case ''A'' = ''p&lt;sub&gt;i&lt;/sub&gt;'' is trivial. Let {{math|''A'' {{=}} (''B'' → ''C'').}} We distinguish three cases:
#''e''(''C'') = 1. Then also ''e''(''A'') = 1. We have
#::&lt;math&gt;(C\to F)\to F\vdash((B\to C)\to F)\to F&lt;/math&gt;
#:by applying ({{EquationNote|2}}) twice to the axiom {{math|''C'' → (''B'' → ''C'').}} Since we have derived {{math|(''C'' → ''F'') → ''F''}} by the induction hypothesis, we can infer {{math|((''B'' → ''C'') → ''F'') → ''F''.}}
#''e''(''B'') = 0. Then again ''e''(''A'') = 1. The deduction theorem applied to ({{EquationNote|3}}) gives
#::&lt;math&gt;B\to F\vdash((B\to C)\to F)\to F.&lt;/math&gt;
#:Since we have derived {{math|''B'' → ''F''}} by the induction hypothesis, we can infer {{math|((''B'' → ''C'') → ''F'') → ''F''.}}
#''e''(''B'') = 1 and ''e''(''C'') = 0. Then ''e''(''A'') = 0. We have
#::&lt;math&gt;\begin{align}(B\to F)\to F,C\to F,B\to C&amp;\vdash B\to F&amp;&amp;\text{by (1)}\\&amp;\vdash F&amp;&amp;\text{by modus ponens,}\end{align}&lt;/math&gt;
#:thus &lt;math&gt;(B\to F)\to F,C\to F\vdash(B\to C)\to F&lt;/math&gt; by the deduction theorem. We have derived {{math|(''B'' → ''F'') → ''F''}} and {{math|''C'' → ''F''}} by the induction hypothesis, hence we can infer {{math|(''B'' → ''C'') → ''F''.}} This completes the proof of ({{EquationNote|4}}).
Now let ''F'' be a tautology in variables ''p''&lt;sub&gt;1&lt;/sub&gt;, ..., ''p&lt;sub&gt;n&lt;/sub&gt;''. We will prove by reverse induction on ''k'' = ''n'',...,0 that for every assignment ''e'',
{{NumBlk|:|&lt;math&gt;p_1^{e(p_1)},\dots,p_k^{e(p_k)}\vdash F.&lt;/math&gt;|{{EquationRef|5}}}}
The base case ''k'' = ''n'' follows from a special case of ({{EquationNote|4}}) using
:&lt;math&gt; F^{e(F)} = F^1 = ((F \to F) \to F)&lt;/math&gt;
and the fact that ''F''→''F'' is a theorem by the deduction theorem.

Assume that ({{EquationNote|5}}) holds for ''k'' + 1, we will show it for ''k''. By applying deduction theorem to the induction hypothesis, we obtain
:&lt;math&gt;\begin{align}p_1^{e(p_1)},\dots,p_k^{e(p_k)}&amp;\vdash(p_{k+1}\to F)\to F,\\
p_1^{e(p_1)},\dots,p_k^{e(p_k)}&amp;\vdash((p_{k+1}\to F)\to F)\to F,\end{align}&lt;/math&gt;
by first setting ''e''(''p''&lt;sub&gt;''k''+1&lt;/sub&gt;) = 0 and second setting ''e''(''p''&lt;sub&gt;''k''+1&lt;/sub&gt;) = 1. From this we derive ({{EquationNote|5}}) using modus ponens.

For ''k'' = 0 we obtain that the tautology ''F'' is provable without assumptions. This is what was to be proved.

This proof is constructive. That is, given a tautology, one could actually follow the instructions and create a proof of it from the axioms. However, the length of such a proof increases exponentially with the number of propositional variables in the tautology, hence it is not a practical method for any but the very shortest tautologies.

== The Bernays–Tarski axiom system ==
The Bernays–Tarski axiom system is often used. In particular, Łukasiewicz's paper derives the Bernays–Tarski axioms from Łukasiewicz's sole axiom as a means of showing its completeness.&lt;br&gt;
It differs from the axiom schemas above by replacing axiom schema 2, (''P''→(''Q''→''R''))→((''P''→''Q'')→(''P''→''R'')), with
* Axiom schema 2': (''P''→''Q'')→((''Q''→''R'')→(''P''→''R''))
which is called ''[[hypothetical syllogism]]''.
This makes derivation of the deduction meta-theorem a little more difficult, but it can still be done.

We show that from ''P''→(''Q''→''R'') and ''P''→''Q'' one can derive ''P''→''R''. This fact can be used in lieu of axiom schema 2 to get the meta-theorem.
# ''P''→(''Q''→''R'') given
# ''P''→''Q'' given
# (''P''→''Q'')→((''Q''→''R'')→(''P''→''R'')) ax 2'
# (''Q''→''R'')→(''P''→''R'') mp 2,3
# (''P''→(''Q''→''R''))→(((''Q''→''R'')→(''P''→''R''))→(''P''→(''P''→''R''))) ax 2'
# ((''Q''→''R'')→(''P''→''R''))→(''P''→(''P''→''R'')) mp 1,5
# ''P''→(''P''→''R'') mp 4,6
# (''P''→(''P''→''R''))→(((''P''→''R'')→''R'')→(''P''→''R'')) ax 2'
# ((''P''→''R'')→''R'')→(''P''→''R'') mp 7,8
# (((''P''→''R'')→''R'')→(''P''→''R''))→(''P''→''R'') ax 3
# ''P''→''R'' mp 9,10 qed

== Testing whether a formula of the implicational propositional calculus is a tautology ==
{{ main | Tautology (logic)#Efficient verification and the Boolean satisfiability problem | Boolean satisfiability problem#Algorithms for solving SAT }}
In this case, a useful technique is to presume that the formula is not a tautology and attempt to find a valuation which makes it false. If one succeeds, then it is indeed not a tautology. If one fails, then it is a tautology.

'''Example of a non-tautology''':

Suppose [(''A''→''B'')→((''C''→''A'')→''E'')]→([''F''→((''C''→''D'')→''E'')]→[(''A''→''F'')→(''D''→''E'')]) is false.

Then (''A''→''B'')→((''C''→''A'')→''E'') is true; ''F''→((''C''→''D'')→''E'') is true; ''A''→''F'' is true; ''D'' is true; and ''E'' is false.

Since ''D'' is true, ''C''→''D'' is true. So the truth of ''F''→((''C''→''D'')→''E'') is equivalent to the truth of ''F''→''E''.

Then since ''E'' is false and ''F''→''E'' is true, we get that ''F'' is false.

Since ''A''→''F'' is true, ''A'' is false. Thus ''A''→''B'' is true and (''C''→''A'')→''E'' is true.

''C''→''A'' is false, so ''C'' is true.

The value of ''B'' does not matter, so we can arbitrarily choose it to be true.

Summing up, the valuation which sets ''B'', ''C'' and ''D'' to be true and ''A'', ''E'' and ''F'' to be false will make [(''A''→''B'')→((''C''→''A'')→''E'')]→([''F''→((''C''→''D'')→''E'')]→[(''A''→''F'')→(''D''→''E'')]) false. So it is not a tautology.

'''Example of a tautology''':

Suppose ((''A''→''B'')→''C'')→((''C''→''A'')→(''D''→''A'')) is false.

Then (''A''→''B'')→''C'' is true; ''C''→''A'' is true; ''D'' is true; and ''A'' is false.

Since ''A'' is false, ''A''→''B'' is true. So ''C'' is true. Thus ''A'' must be true, contradicting the fact that it is false.

Thus there is no valuation which makes ((''A''→''B'')→''C'')→((''C''→''A'')→(''D''→''A'')) false. Consequently, it is a tautology.

== Adding an axiom schema ==
What would happen if another axiom schema were added to those listed above? There are two cases: (1) it is a tautology; or (2) it is not a tautology.

If it is a tautology, then the set of theorems remains the set of tautologies as before. However, in some cases it may be possible to find significantly shorter proofs for theorems. Nevertheless, the minimum length of proofs of theorems will remain unbounded, that is, for any natural number ''n'' there will still be theorems which cannot be proved in ''n'' or fewer steps.

If the new axiom schema is not a tautology, then every formula becomes a theorem (which makes the concept of a theorem useless in this case). What is more, there is then an upper bound on the minimum length of a proof of every formula, because there is a common method for proving every formula. For example, suppose the new axiom schema were ((''B''→''C'')→''C'')→''B''. Then ((''A''→(''A''→''A''))→(''A''→''A''))→''A'' is an instance (one of the new axioms) and also not a tautology. But [((''A''→(''A''→''A''))→(''A''→''A''))→''A'']→''A'' is a tautology and thus a theorem due to the old axioms (using the completeness result above). Applying modus ponens, we get that ''A'' is a theorem of the extended system. Then all one has to do to prove any formula is to replace ''A'' by the desired formula throughout the proof of ''A''. This proof will have the same number of steps as the proof of ''A''.

== An alternative axiomatization ==
The axioms listed above primarily work through the deduction metatheorem to arrive at completeness. Here is another axiom system which aims directly at completeness without going through the deduction metatheorem.

First we have axiom schemas which are designed to efficiently prove the subset of tautologies which contain only one propositional variable.
* aa 1: ꞈ''A''→''A''
* aa 2: (''A''→''B'')→ꞈ(''A''→(''C''→''B''))
* aa 3: ''A''→((''B''→''C'')→ꞈ((''A''→''B'')→''C''))
* aa 4: ''A''→ꞈ(''B''→''A'')
The proof of each such tautology would begin with two parts (hypothesis and conclusion) which are the same. Then insert additional hypotheses between them. Then insert additional tautological hypotheses (which are true even when the sole variable is false) into the original hypothesis. Then add more hypotheses outside (on the left). This procedure will quickly give every tautology containing only one variable. (The symbol "ꞈ" in each axiom schema indicates where the conclusion used in the completeness proof begins. It is merely a comment, not a part of the formula.)

Consider any formula &amp;Phi; which may contain ''A'', ''B'', ''C''&lt;sub&gt;1&lt;/sub&gt;, ..., ''C''&lt;sub&gt;''n''&lt;/sub&gt; '''and ends with ''A'' ''' as its final conclusion. Then we take
* aa 5: &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt;→(&amp;Phi;&lt;sub&gt;+&lt;/sub&gt;→ꞈ&amp;Phi;)
as an axiom schema where &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt; is the result of replacing ''B'' by ''A'' throughout &amp;Phi; and &amp;Phi;&lt;sub&gt;+&lt;/sub&gt; is the result of replacing ''B'' by (''A''→''A'') throughout &amp;Phi;. This is a schema for axiom schemas since there are two level of substitution: in the first &amp;Phi; is substituted (with variations); in the second, any of the variables (including both ''A'' and ''B'') may be replaced by arbitrary formulas of the implicational propositional calculus. This schema allows one to prove tautologies with more than one variable by considering the case when ''B'' is false &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt; and the case when ''B'' is true &amp;Phi;&lt;sub&gt;+&lt;/sub&gt;.

If the variable which is the final conclusion of a formula takes the value true, then the whole formula takes the value true regardless of the values of the other variables. Consequently if ''A'' is true, then &amp;Phi;, &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt;, &amp;Phi;&lt;sub&gt;+&lt;/sub&gt; and &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt;→(&amp;Phi;&lt;sub&gt;+&lt;/sub&gt;→&amp;Phi;) are all true. So without loss of generality, we may assume that ''A'' is false. Notice that &amp;Phi; is a tautology if and only if both &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt; and &amp;Phi;&lt;sub&gt;+&lt;/sub&gt; are tautologies. But while &amp;Phi; has ''n''+2 distinct variables, &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt; and &amp;Phi;&lt;sub&gt;+&lt;/sub&gt; both have ''n''+1. So the question of whether a formula is a tautology has been reduced to the question of whether certain formulas with one variable each are all tautologies. Also notice that &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt;→(&amp;Phi;&lt;sub&gt;+&lt;/sub&gt;→&amp;Phi;) is a tautology regardless of whether &amp;Phi; is, because if &amp;Phi; is false then either &amp;Phi;&lt;sub&gt;&amp;minus;&lt;/sub&gt; or &amp;Phi;&lt;sub&gt;+&lt;/sub&gt; will be false depending on whether ''B'' is false or true.

Examples:

Deriving Peirce's law
# [((''P''→''P'')→''P'')→''P'']→([((''P''→(''P''→''P''))→''P'')→''P'']→[((''P''→''Q'')→''P'')→''P'']) aa 5
# ''P''→''P'' aa 1
# (''P''→''P'')→((''P''→''P'')→(((''P''→''P'')→''P'')→''P'')) aa 3
# (''P''→''P'')→(((''P''→''P'')→''P'')→''P'') mp 2,3
# ((''P''→''P'')→''P'')→''P'' mp 2,4
# [((''P''→(''P''→''P''))→''P'')→''P'']→[((''P''→''Q'')→''P'')→''P''] mp 5,1
# ''P''→(''P''→''P'') aa 4
# (''P''→(''P''→''P''))→((''P''→''P'')→(((''P''→(''P''→''P''))→''P'')→''P'')) aa 3
# (''P''→''P'')→(((''P''→(''P''→''P''))→''P'')→''P'') mp 7,8
# ((''P''→(''P''→''P''))→''P'')→''P'' mp 2,9
# ((''P''→''Q'')→''P'')→''P'' mp 10,6 qed

Deriving Łukasiewicz' sole axiom
# [((''P''→''Q'')→''P'')→((''P''→''P'')→(''S''→''P''))]→([((''P''→''Q'')→(''P''→''P''))→(((''P''→''P'')→''P'')→(''S''→''P''))]→[((''P''→''Q'')→''R'')→((''R''→''P'')→(''S''→''P''))]) aa 5
# [((''P''→''P'')→''P'')→((''P''→''P'')→(''S''→''P''))]→([((''P''→(''P''→''P''))→''P'')→((''P''→''P'')→(''S''→''P''))]→[((''P''→''Q'')→''P'')→((''P''→''P'')→(''S''→''P''))]) aa 5
# ''P''→(''S''→''P'') aa 4
# (''P''→(''S''→''P''))→(''P''→((''P''→''P'')→(''S''→''P''))) aa 2
# ''P''→((''P''→''P'')→(''S''→''P'')) mp 3,4
# ''P''→''P'' aa 1
# (''P''→''P'')→((''P''→((''P''→''P'')→(''S''→''P'')))→[((''P''→''P'')→''P'')→((''P''→''P'')→(''S''→''P''))]) aa 3
# (''P''→((''P''→''P'')→(''S''→''P'')))→[((''P''→''P'')→''P'')→((''P''→''P'')→(''S''→''P''))] mp 6,7
# ((''P''→''P'')→''P'')→((''P''→''P'')→(''S''→''P'')) mp 5,8
# [((''P''→(''P''→''P''))→''P'')→((''P''→''P'')→(''S''→''P''))]→[((''P''→''Q'')→''P'')→((''P''→''P'')→(''S''→''P''))] mp 9,2
# ''P''→(''P''→''P'') aa 4
# (''P''→(''P''→''P''))→((''P''→((''P''→''P'')→(''S''→''P'')))→[((''P''→(''P''→''P''))→''P'')→((''P''→''P'')→(''S''→''P''))]) aa 3
# (''P''→((''P''→''P'')→(''S''→''P'')))→[((''P''→(''P''→''P''))→''P'')→((''P''→''P'')→(''S''→''P''))] mp 11,12
# ((''P''→(''P''→''P''))→''P'')→((''P''→''P'')→(''S''→''P'')) mp 5,13
# ((''P''→''Q'')→''P'')→((''P''→''P'')→(''S''→''P'')) mp 14,10
# [((''P''→''Q'')→(''P''→''P''))→(((''P''→''P'')→''P'')→(''S''→''P''))]→[((''P''→''Q'')→''R'')→((''R''→''P'')→(''S''→''P''))] mp 15,1
# (''P''→''P'')→((''P''→(''S''→''P''))→[((''P''→''P'')→''P'')→(''S''→''P'')]) aa 3
# (''P''→(''S''→''P''))→[((''P''→''P'')→''P'')→(''S''→''P'')] mp 6,17
# ((''P''→''P'')→''P'')→(''S''→''P'') mp 3,18
# (((''P''→''P'')→''P'')→(''S''→''P''))→[((''P''→''Q'')→(''P''→''P''))→(((''P''→''P'')→''P'')→(''S''→''P''))] aa 4
# ((''P''→''Q'')→(''P''→''P''))→(((''P''→''P'')→''P'')→(''S''→''P'')) mp 19,20
# ((''P''→''Q'')→''R'')→((''R''→''P'')→(''S''→''P'')) mp 21,16 qed

Using a truth table to verify Łukasiewicz' sole axiom would require consideration of 16=2&lt;sup&gt;4&lt;/sup&gt; cases since it contains 4 distinct variables. In this derivation, we were able to restrict consideration to merely 3 cases: ''R'' is false and ''Q'' is false, ''R'' is false and ''Q'' is true, and ''R'' is true. However because we are working within the formal system of logic (instead of outside it, informally), each case required much more effort.

==See also==
*[[Deduction theorem]]
*[[List of logic systems#Implicational propositional calculus]]
*[[Peirce's law]]
*[[Propositional calculus]]
*[[Tautology (logic)]]
*[[Truth table]]
*[[Valuation (logic)]]

==References==
* Mendelson, Elliot (1997) [http://worldcat.org/oclc/259359 ''Introduction to Mathematical Logic'', 4th ed.] London: Chapman &amp; Hall.
* Łukasiewicz, Jan (1948) [https://www.jstor.org/stable/20488489 ''The shortest axiom of the implicational calculus of propositions''], Proc. Royal Irish Academy, vol. 52, sec. A, no. 3, pp.&amp;nbsp;25–33.

[[Category:Systems of formal logic]]
[[Category:Propositional calculus]]
[[Category:Articles containing proofs]]
[[Category:Conditionals]]</text>
      <sha1>nnv7tgvmiykx8ist2uzu3euvi11wqiu</sha1>
    </revision>
  </page>
  <page>
    <title>Insurance cycle</title>
    <ns>0</ns>
    <id>12870767</id>
    <revision>
      <id>833019440</id>
      <parentid>813279169</parentid>
      <timestamp>2018-03-29T07:00:58Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category Insurance terms to [[:Category:Insurance]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories_for_discussion/Log/2018_February_11]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9264">{{Use dmy dates|date=December 2013}}
{{multiple issues|
{{Notability|October 2009|date=October 2009}}
{{Refimprove|date=October 2009}}
}}

The tendency of the [[Insurance|insurance industry]] to swing between profitable and unprofitable periods over time is commonly known as the underwriting or '''insurance cycle'''.

== Definition ==

The underwriting cycle is the tendency of [[property insurance|property]] and [[casualty insurance]] [[insurance|premiums]], [[Profit (accounting)|profits]], and availability of coverage to rise and fall with some regularity over time. A cycle begins when insurers tighten their [[underwriting]] standards and sharply raise premiums after a period of severe underwriting losses or negative stocks to [[Financial capital|capital]] (e.g., investment losses). Stricter standards and higher premium rates lead to an increase in profits and accumulation of capital. The increase in underwriting capacity increases [[competition]], which in turn drives premium rates down and relaxes underwriting standards, thereby causing underwriting losses and setting the stage for the cycle to begin again.&lt;ref name="columbia industry study two"&gt;"Analysis and Valuation Of Insurance Companies." Center For Excellence in Accounting and Security Analysis: Industry Study Two 2 (2003). http://www.columbia.edu/~dn75/Analysis%20and%20Valuation%20of%20Insurance%20Companies%20-%20Final.pdf (accessed 31 October 2012).&lt;/ref&gt; For example, Lloyd's Franchise Performance Director Rolf Tolle stated in 2007 that "mitigating the insurance cycle was the "biggest challenge" facing managing agents in the next few years".&lt;ref&gt;Rolf Tolle, The cycle challenge - 12 July 2007, http://www.lloyds.com/News_Centre/Features_from_Lloyds/The_cycle_challenge.htm (accessed 21 August 2007)&lt;/ref&gt;

All industries experience cycles of growth and decline, 'boom and bust'. These cycles are particularly important in the insurance and [[Reinsurance|re-insurance]] industry as they are especially unpredictable.

[[Lloyd's of London]] research in 2006 revealed, for the second year running, that Lloyd’s underwriters see managing the insurance cycle as the top challenge for the [[insurance industry]], and nearly two-thirds believe that the industry at large is not doing enough to respond to the challenge.&lt;ref&gt;Lloyd's Annual Underwriter Survey, 2006 http://www.lloyds.com/News_Centre/360_risk_project/Managing_the_cycle.htm (accessed 21 August 2007)&lt;/ref&gt;

The Insurance Cycle affects all areas of insurance except [[life insurance]], where there is enough data and a large base of similar risks (i.e. people) to accurately predict claims, and therefore minimise the risk that the cycle poses to business.

== History ==

The insurance cycle is a phenomenon that has been understood since at least the 1920s. Since then it has been considered an insurance 'fact of life'. Most commentators believe that underwriting cycles are inevitable, primarily "because the uncertainty inherent in matching insurance prices to [future] losses creates an environment in which the motivations, ambitions, and fears of a complex cast of characters can play out."&lt;ref&gt;Fitzpatrick, Sean, [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=690316 Fear is the Key: A Behavioral Guide to Underwriting Cycles], 10 Conn. Ins. L.J. 255 (2004).&lt;/ref&gt;  Lloyd's counters that this has become "a self-fulfilling prophecy".&lt;ref&gt;Lloyd’s, Managing the Cycle&amp;nbsp;– How the Market can Take Control http://www.lloyds.com/NR/rdonlyres/A27B9CEB-6F19-4364-BD0A-02AA92384544/0/360_ManagingtheCycle06_12_06.pdf (accessed 21 August 2007).&lt;/ref&gt;

More recently, insurers have attempted to model the cycle and base their policy pricing and risk exposure accordingly.

== Description ==

For the sake of argument &lt;ref&gt;The cycle has no start. It is a cycle. Obviously.&lt;/ref&gt; let's start from a 'soft' period in the cycle, that is a period in which premiums are low, capital base is high and competition is high. Premiums continue to fall as naive insurers offer cover at unrealistic rates, and established businesses are forced to compete or risk losing business in the long term.

The next stage is precipitated by a catastrophe or similar significant loss, for example [[Hurricane Andrew]] or the attacks on the [[World Trade Center (1973–2001)|World Trade Center]]. The graph below shows the effect that these two events had on insurance premiums.

[[File:Myinsurancecycle.JPG]]

After a major claims burst, less stable companies are driven out of the market which decreases competition. In addition to this, large claims have left even larger companies with less capital. Therefore, premiums rise rapidly. The market hardens, and [[underwriter]]s are less likely to take on risks.

In turn, this lack of competition and high rates looks suddenly very profitable, and more companies join the market whilst existing business begin to lower rates to compete. This causes a [[market saturation]] and Insurance Cycle begins again.

== Dealing with the insurance cycle ==

While many underwriters believe that the cycle is out of their hands, Lloyd’s is trying to push for more proactive management of [[wikt:ups and downs|the ups and downs]] of the industry. In 2006 they published their ‘Seven Steps’ to managing the insurance cycle:

1.	'''Don’t follow the herd'''. Insurers need to be prepared to walk away from markets when prices fall below a prudent, risk-based premium.

2.	'''Invest in the latest risk management tools'''. Insurers must push for continuous improvement of these tools based on the latest science around issues such as [[climate change]], and make full use of them to communicate their pricing and coverage decisions.

3.	'''Don’t let surplus capital dictate your underwriting'''. An excess of capital available for underwriting can easily push an insurer to deploy the capital in unsustainable ways, rather than having that capital migrate to other uses such as [[hedge fund]]s and equities, or returning it to shareholders.

4.	'''Don’t be dazzled by higher investment returns'''. Don’t let higher investment returns replace disciplined underwriting as base rates creep up on both sides of the Atlantic. Notionally, splitting the business into insurance and [[Investment management|asset management]] operations, and monitoring each separately, is one way to achieve this.

5.	'''Don’t rely on "the big one" to push prices upwards'''. The spectacular insured loss should not be used as an excuse to raise prices in unrelated lines of business. Regulators, rating agencies, and analysts&amp;nbsp;– not to mention insurance buyers&amp;nbsp;– are increasingly resisting such behaviour.

6.	'''Redeploy capital from lines where margins are unsustainable'''. There is little that individual insurers can do to alter overall [[Supply and demand|supply-and-demand]] conditions. But insurers can set up internal monitoring systems to ensure that they scale back in lines in which margins have become unsustainable and migrate to other lines.

7.	'''Get smarter with underwriter and manager incentives'''. Incentives for key staff should be structured to reward efficient deployment of capital, linking such rewards to target shareholder returns rather than volume growth.&lt;ref&gt;Lloyd’s, Seven steps to managing the cycle, http://www.lloyds.com/News_Centre/Press_releases/Seven_steps_to_managing_the_cycle.htm (accessed 21 August)&lt;/ref&gt;

The Lloyd’s Managing Cycle report has several problems. It focuses on the industry as a whole being able to work together to reduce the effect of market fluctuations. However, this is somewhat unrealistic, as if underwriters do not write business in a soft market (i.e. at cheap prices for the customer), it will be hard to win this business back in a hard market due to loyalty issues.

[[Rolf Tolle]] asserts that "There is nothing complex about the cycle. It is about having the courage of your convictions to act with strength.".&lt;ref&gt;Todd, Cycle Challenge&lt;/ref&gt; Swiss Re argue that instead of ‘beating’ the cycle, insurers should learn to anticipate its fluctuations. "Cycle management is essentially proper timing. Monitoring the market, predicting [[market trends]] and accurately assessing prices play an important role".&lt;ref&gt;Swiss Re, The insurance cycle as an entrepreneurial challenge, http://media.swissre.com/documents/pub_the_insurance_cycle_as_an_entrepreneurial_challenge_en.pdf Accessed 21 August 2007&lt;/ref&gt;

[[Swiss Re]] gave several examples of potential business strategies. One is to write risks at a roughly fixed rate. This is clearly not practical as it does not allow for the cyclical nature of the market. Another is to fail to react fast enough to changes in the market, which leaves a company even more exposed. The recommended strategy is one that relies on prediction of the business cycle and setting premiums based on models and experience.

== The future of the insurance cycle ==

The unpredictable nature of the insurance industry makes it very unlikely that the cycle can be eliminated. For several years Lloyd's have been urging caution in soft periods and restraint in hard periods.

== Notes ==
{{reflist}}

{{DEFAULTSORT:Insurance Cycle}}
[[Category:Actuarial science]]
[[Category:Insurance]]</text>
      <sha1>nbpfsocva2m6mzb2apb55vytzgphgbe</sha1>
    </revision>
  </page>
  <page>
    <title>Interpretation (model theory)</title>
    <ns>0</ns>
    <id>17135554</id>
    <revision>
      <id>604304885</id>
      <parentid>578952902</parentid>
      <timestamp>2014-04-15T14:15:53Z</timestamp>
      <contributor>
        <ip>82.91.106.185</ip>
      </contributor>
      <comment>/* Bi-interpretability */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6049">{{otheruses|Interpretation (disambiguation)}}

In [[model theory]], '''interpretation''' of a [[structure (mathematical logic)|structure]] ''M'' in another structure ''N'' (typically of a different [[signature (logic)|signature]]) is a technical notion that approximates the idea of representing ''M'' inside ''N''. For example every [[reduct]] or definitional expansion of a structure ''N'' has an interpretation in ''N''.

Many model-theoretic properties are preserved under interpretability. For example if the theory of ''N'' is [[stable theory|stable]] and ''M'' is interpretable in ''N'', then the theory of ''M'' is also stable.

==Definition==
An '''interpretation''' of ''M'' in ''N'' '''with parameters''' (or '''without parameters''', respectively)
is a pair &lt;math&gt;(n,f)&lt;/math&gt; where
''n'' is a natural number and &lt;math&gt;f&lt;/math&gt; is a surjective [[Map (mathematics)|map]] from a subset of
''N&lt;sup&gt;n&lt;/sup&gt;'' onto ''M''
such that the &lt;math&gt;f&lt;/math&gt;-preimage (more precisely the &lt;math&gt;f^k&lt;/math&gt;-preimage) of every set ''X''&amp;nbsp;⊆&amp;nbsp;''M&lt;sup&gt;k&lt;/sup&gt;'' [[Definable set|definable]] in ''M'' by a [[First-order_logic#Formation_rules|first-order formula]] without parameters
is definable (in ''N'') by a first-order formula with parameters (or without parameters, respectively).
Since the value of ''n'' for an interpretation &lt;math&gt;(n,f)&lt;/math&gt; is often clear from context, the map &lt;math&gt;f&lt;/math&gt; itself is also called an interpretation.

To verify that the preimage of every definable (without parameters) set in ''M'' is definable in ''N'' (with or without parameters), it is sufficient to check the preimages of the following definable sets:
* the domain of ''M'';
* the [[Diagonal#Geometry|diagonal]] of ''M'';
* every relation in the signature of ''M'';
* the [[graph of a function|graph]] of every function in the signature of ''M''.

In [[model theory]] the term ''definable'' often refers to definability with parameters; if this convention is used, definability without parameters is expressed by the term ''0-definable''. Similarly, an interpretation with parameters may be referred to as simply an interpretation, and an interpretation without parameters as a '''0-interpretation'''.

==Bi-interpretability==
If ''L, M'' and ''N'' are three structures, ''L'' is interpreted in ''M,''
and ''M'' is interpreted in ''N,'' then one can naturally construct a composite interpretation of ''L'' in ''N.''
If two structures ''M'' and ''N'' are interpreted in each other, then by combining the interpretations in two possible ways, one obtains an interpretation of each of the two structures in itself.
This observation permits one to define an equivalence relation among structures, reminiscent of the [[homotopy equivalence]] among topological spaces.

Two structures ''M'' and ''N'' are '''bi-interpretable''' if there exists an interpretation of ''M'' in ''N'' and an interpretation of ''N'' in ''M'' such that the composite interpretations of ''M'' in itself and of ''N'' in itself are definable in ''M'' and in ''N'', respectively (the composite interpretations being viewed as operations on ''M'' and on ''N'').

==Example==
The partial map ''f'' from '''Z'''&amp;nbsp;&amp;times;&amp;nbsp;'''Z''' onto '''Q''' which maps (''x'',&amp;nbsp;''y'') to ''x''/''y'' provides an interpretation of the field '''Q''' of rational numbers in the ring '''Z''' of integers (to be precise, the interpretation is (2,&amp;nbsp;''f'')).
In fact, this particular interpretation is often used to ''define'' the rational numbers.
To see that it is an interpretation (without parameters), one needs to check the following preimages of definable sets in '''Q''':
* the preimage of '''Q''' is defined by the formula φ(''x'',&amp;nbsp;''y'') given by ¬&amp;nbsp;(''y''&amp;nbsp;=&amp;nbsp;0);
* the preimage of the diagonal of '''Q''' is defined by the formula {{nobr|φ(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}} given by {{nobr|''x''&lt;sub&gt;1&lt;/sub&gt; &amp;times; ''y''&lt;sub&gt;2&lt;/sub&gt;}} = {{nobr|''x''&lt;sub&gt;2&lt;/sub&gt; &amp;times; ''y''&lt;sub&gt;1&lt;/sub&gt;}};
* the preimages of 0 and 1 are defined by the formulas φ(''x'',&amp;nbsp;''y'') given by ''x''&amp;nbsp;=&amp;nbsp;0 and ''x''&amp;nbsp;=&amp;nbsp;''y'';
* the preimage of the graph of addition is defined by the formula {{nobr|φ(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;, ''x''&lt;sub&gt;3&lt;/sub&gt;, ''y''&lt;sub&gt;3&lt;/sub&gt;)}} given by {{nobr|''x''&lt;sub&gt;1&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;2&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;3&lt;/sub&gt; + ''x''&lt;sub&gt;2&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;1&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;3&lt;/sub&gt;}} = {{nobr|''x''&lt;sub&gt;3&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;1&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;2&lt;/sub&gt;}};
* the preimage of the graph of multiplication is defined by the formula {{nobr|φ(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;, ''x''&lt;sub&gt;3&lt;/sub&gt;, ''y''&lt;sub&gt;3&lt;/sub&gt;)}} given by {{nobr|''x''&lt;sub&gt;1&lt;/sub&gt;&amp;times;''x''&lt;sub&gt;2&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;3&lt;/sub&gt;}} = {{nobr|''x''&lt;sub&gt;3&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;1&lt;/sub&gt;&amp;times;''y''&lt;sub&gt;2&lt;/sub&gt;}}.

==References==

{{Portal|Logic}}
* {{Citation | last1=Ahlbrandt | first1=Gisela | last2=Ziegler | first2=Martin | title=Quasi finitely axiomatizable totally categorical theories | url=http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6TYB-45SJDHX-8&amp;_user=10&amp;_coverDate=01%2F31%2F1986&amp;_rdoc=4&amp;_fmt=high&amp;_orig=browse&amp;_srch=doc-info(%23toc%235614%231986%23999699998%23315074%23FLP%23display%23Volume)&amp;_cdi=5614&amp;_sort=d&amp;_docanchor=&amp;_ct=6&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=dcedb9ab7620fe68560a9f68b586152f | year=1986 | journal=Annals of Pure and Applied Logic | volume=30 | pages=63–82 | doi=10.1016/0168-0072(86)90037-0}}
* {{Citation | last1=Hodges | first1=Wilfrid | author1-link=Wilfrid Hodges | title=A shorter model theory | publisher= [[Cambridge University Press]]| location=Cambridge | isbn=978-0-521-58713-6 | year=1997}} (Section&amp;nbsp;4.3)
* {{ Citation | last=Poizat | first=Bruno | publisher=[[Springer Science+Business Media|Springer]] | title=A Course in Model Theory | year=2000 | isbn=0-387-98655-3 }} (Section&amp;nbsp;9.4)

{{Logic}}

[[Category:Model theory]]</text>
      <sha1>t41lsj6xasb6bgbms6zb8kie02neesv</sha1>
    </revision>
  </page>
  <page>
    <title>Key signature (cryptography)</title>
    <ns>0</ns>
    <id>1595662</id>
    <revision>
      <id>633686746</id>
      <parentid>603517174</parentid>
      <timestamp>2014-11-13T16:53:06Z</timestamp>
      <contributor>
        <username>Hannasnow</username>
        <id>21169805</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="785">In [[cryptography]], a '''key signature''' is the result of a third-party applying a cryptographic signature to a representation of a cryptographic key. This is usually done as a form of assurance or verification: If "Alice" has signed "Bob's" key, it can serve as an assurance to another party, say "Eve", that the key actually belongs to Bob, and that Alice has personally checked and attested to this.

The representation of the key that is signed is usually shorter than the key itself, because most public-key signature schemes can only encrypt or sign short lengths of data. Some derivative of the [[public key fingerprint]] may be used, i.e. via [[hash function]]s.

==See also==

*[[Key (cryptography)]]
*[[Public key certificate]]

{{crypto-stub}}

[[Category:Key management]]</text>
      <sha1>enqfrqtkz8fj7o6u8kdvzm8pqvfqopr</sha1>
    </revision>
  </page>
  <page>
    <title>Kmc-Subset137</title>
    <ns>0</ns>
    <id>49927590</id>
    <revision>
      <id>859948097</id>
      <parentid>775021753</parentid>
      <timestamp>2018-09-17T10:28:11Z</timestamp>
      <contributor>
        <username>Zullinux</username>
        <id>27687499</id>
      </contributor>
      <minor/>
      <comment>Updated no longer existing reference link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1278">{{Multiple issues|{{refimprove|date=March 2016}}{{technical|date=March 2016}}}}

The open-source '''Kmc-Subset137 Project''' implements the protocol described in "[[ERTMS]]/[[Elementary cognitive task|ECTS]]; On-line Key Management FFFIS" UNISIG SUBSET-137&lt;ref&gt;https://www.era.europa.eu/filebrowser/download/542_en&lt;/ref&gt; ver1.0.0.

It covers the on-line distribution of cryptographic keys among the [[key management]] Centres authoritative in their respective domains. It also deals with the exchange between a key management center and its own domain KMAC entities. The open source library provides a simple [[C language]] application programming interface (API) to access and parse UNISIG SUBSET 137 messages.

For the cryptographic part of the protocol it relies on the open source GnuTLS library (or alternatively, but discouraged, on the OpenSSL library).

The library is open-source and is licensed under the GNU General Public License version 3.0.

== References ==
{{reflist}}
* * [[File:CC-BY-SA icon.svg|50px]] Prose in this article was copied from [http://www.kmc-subset137.eu/ Kmc-Subset137 Project] at Neat Embedded Computing, which is available under a Creative Commons Attribution-ShareAlike 3.0 unported license.
{{cryptography-stub}}
[[Category:Key management]]</text>
      <sha1>9b78b44c8ea9x4tv3fx5h8uje57ph38</sha1>
    </revision>
  </page>
  <page>
    <title>Life annuity</title>
    <ns>0</ns>
    <id>8928339</id>
    <revision>
      <id>842850855</id>
      <parentid>842850776</parentid>
      <timestamp>2018-05-25T02:56:20Z</timestamp>
      <contributor>
        <username>Malik Shabazz</username>
        <id>3020778</id>
      </contributor>
      <comment>/* History */  + Wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17877">{{See also| Pension}}

A ''' life annuity''' is an [[annuity]], or series of payments at fixed intervals, paid while the purchaser (or annuitant) is alive. A life annuity is an [[insurance]] product typically sold or issued by life insurance companies. Life annuities may be sold in exchange for the immediate payment of a lump sum (single-payment annuity) or a series of regular payments (flexible payment annuity), prior to the onset of the annuity.

The payment stream from the issuer to the annuitant has an unknown duration based principally upon the date of death of the annuitant. At this point the contract will terminate and the remainder of the fund accumulated is forfeited unless there are other annuitants or beneficiaries in the contract. Thus a life annuity is a form of [[longevity insurance]], where the uncertainty of an individual's lifespan is transferred from the individual to the insurer, which reduces its own uncertainty by pooling many clients. Annuities can be purchased to provide an income during retirement, or originate from a ''[[structured settlement]]'' of a personal injury [[lawsuit]].

==History==
The instrument's evolution has been long and continues as part of [[actuarial science]].&lt;ref&gt;{{cite web|url=http://www.act.ku.dk/ |title=Laboratory of Actuarial Mathematics |publisher=Act.ku.dk |accessdate=2012-12-10}}&lt;/ref&gt;

[[Ulpian]] is credited with generating an actuarial life annuity table between AD 211 and 222.&lt;ref&gt;{{cite book| title=A History of Probability and Statistics and Their Applications before 1750|last=Hald|first=Anders|year=2005|publisher=John Wiley &amp; Sons|pages=608}}&lt;/ref&gt;
Medieval German and Dutch cities and monasteries raised money by the sale of life annuities, and it was recognized that pricing them was difficult.&lt;ref&gt;J. Franklin, ''The Science of Conjecture: Evidence and Probability Before Pascal'' (Baltimore: Johns Hopkins University Press, 2001), 269-272.&lt;/ref&gt; The early practice for selling this instrument did not consider the age of the nominee, thereby raising interesting concerns.&lt;ref name="Europe"&gt;"[http://www.bus.sfu.ca/homes/poitras/FIN_HIS3.pdf From Commercial Arithmetic to Life Annuities: The Early History of Financial Economics, 1478-1776]" Goeffrey Poitras, Simon Fraser University&lt;/ref&gt; These concerns got the attention of several prominent [[mathematicians]]&lt;ref&gt;[http://www.fields.utoronto.ca/programs/cim/financial_math/finance_seminar/06-07/ Seminar Series on Quantitative Finance] The Fields Institute&lt;/ref&gt; over the years, such as [[Christiaan Huygens|Huygens]], [[Nicolaus I Bernoulli|Bernoulli]], [[de Moivre]] and others:&lt;ref name="Europe" /&gt; even [[Carl Friedrich Gauss|Gauss]] and [[Laplace]] had an interest in matters pertaining to this instrument.&lt;ref&gt;[[Stephen Hawking]] ''[[God Created the Integers|God Created the Integers: The Mathematical Breakthroughs That Changed History]]'', Running Press, 2005 {{ISBN|0-7624-1922-9}}&lt;/ref&gt;

It seems that [[Johan de Witt]] was the first writer to compute the value of a life annuity as the sum of expected discounted future payments, while  [[Edmond Halley|Halley]] used the first mortality table drawn from experience for that calculation. Meanwhile, the [[Hôtel-Dieu de Paris|Paris Hôtel-Dieu]] offered some fairly priced annuities that roughly fit the [[Antoine Deparcieux|Deparcieux]] table discounted at 5%.&lt;ref&gt;Pierre-Charles Pradier, « Les bénéfices terrestres de la charité. Les rentes viagères des Hôpitaux parisiens 1660-1690 » Histoire &amp; mesure (décembre 2011, à paraître).&lt;/ref&gt;

Continuing practice is an everyday occurrence with [[Actuarial present value#Life annuity|well-known theory]] founded on robust mathematics, as witnessed by the hundreds of millions worldwide who receive regular remuneration via [[pension]] or the like. The modern approach to resolving the difficult problems related to a larger scope for this instrument applies many advanced mathematical approaches, such as [[Stochastic process|stochastic]] methods, game theory, and other tools of [[financial mathematics]].

== Types ==

=== Defined benefit pension plans ===
[[Defined benefit pension plans]] are a form of life annuity typically provided by employers or governments (such as [[Social Security (United States)|Social Security]] in the United States). The size of payouts is usually determined based on the employee's years of service, age, and salary.

=== Individual annuity ===
Individual annuities are insurance products marketed to individual consumers. With the complex selection of options available, consumers can find it difficult to decide rationally on the right type of annuity product for their circumstances.&lt;ref name="missing"&gt;[http://wwwdocs.fce.unsw.edu.au/actuarial/research/papers/2006/Longevity%20Insurance%20-%20A%20Missing%20Market_28Aug_JP_Final.pdf Longevity Insurance: A Missing Market] Adam Creighton, et al. University of New South Wales AU&lt;/ref&gt;

==== Deferred annuity ====
There are two phases for a deferred annuity:

* the ''accumulation'' or ''deferral'' ''phase'' in which the customer deposits (or pays premiums) and accumulates money into an account;
* the ''distribution'' or ''annuitization'' ''phase'' in which the insurance company makes income payments until the death of the annuitants named in the contract
Deferred annuities grow capital by investment in the accumulation phase (or deferral phase) and make payments during the distribution phase. A ''single premium deferred annuity'' (SPDA) allows a single deposit or premium at the issue of the annuity with only investment growth during the accumulation phase. A ''flexible premium deferred annuity'' (FPDA) allows additional payments or premiums following the initial premium during the accumulation phase.

The phases of an annuity can be combined in the fusion of a retirement savings and retirement payment plan: the annuitant makes regular contributions to the annuity until a certain date and then receives regular payments from it until death. Sometimes there is a life insurance component added so that if the annuitant dies before annuity payments begin, a beneficiary gets either a lump sum or annuity payments.

==== Immediate annuity ====
An annuity with only a distribution phase is an ''immediate annuity, single premium immediate annuity'' (SPIA), ''payout annuity'', or ''income annuity''. Such a contract is purchased with a single payment and makes payments until the death of the annuitant(s).

====Fixed and variable annuity====
Annuities that make payments in fixed amounts or in amounts that increase by a fixed percentage are called fixed annuities. Variable annuities, by contrast, pay amounts that vary according to the investment performance of a specified set of investments, typically bond and equity [[mutual funds]].

Variable annuities are used for many different objectives. One common objective is deferral of the recognition of [[tax]]able gains. Money deposited in a variable annuity grows on a tax-deferred basis, so that taxes on investment gains are not due until a withdrawal is made. Variable annuities offer a variety of funds ("subaccounts") from various [[Investment management|money managers]]. This gives investors the ability to move between subaccounts without incurring additional fees or sales charges.

Variable annuities have been criticized for their high commissions, contingent deferred sale charges, tax deferred growth, high taxes on profits, and high annual costs. Sales abuses became so prevalent that in November 2007, the [[Securities and Exchange Commission]] approved FINRA Rule 2821&lt;ref&gt;"[https://www.finra.org/newsroom/2007/finra-publishes-guidance-text-new-rule-governing-deferred-variable-annuity "FINRA Publishes Guidance, Text for New Rule Governing Deferred Variable Annuity Transactions"] Financial Industry Regulatory Authority, Inc, November 6, 2007&lt;/ref&gt; requiring brokers to determine specific suitability criteria when recommending the purchase or exchange (but not the surrender) of deferred variable annuities.

====Guaranteed annuity====
A pure life annuity ceases to make payments on the death of the annuitant. A ''guaranteed annuity'' or ''life and certain annuity'', makes payments for at least a certain number of years (the "period certain"); if the annuitant outlives the specified period certain, annuity payments then continue until the annuitant's death, and if the annuitant dies before the expiration of the period certain, the annuitant's estate or beneficiary is entitled to collect the remaining payments certain. The tradeoff between the pure life annuity and the life-with-period-certain annuity is that in exchange for the reduced risk of loss, the annuity payments for the latter will be smaller.

====Joint annuity====
''Joint-life'' and ''joint-survivor'' annuities make payments until the death of one or both of the annuitants respectively. For example, an annuity may be structured to make payments to a married couple, such payments ceasing on the death of the second spouse. In joint-survivor annuities, sometimes the instrument reduces the payments to the second annuitant after death of the first.

====Impaired life annuity====
There has also been a significant growth in the development of ''impaired life'' annuities. These involve improving the terms offered due to a medical diagnosis which is severe enough to reduce life expectancy. A process of medical underwriting is involved and the range of qualifying conditions has increased substantially in recent years. Both conventional annuities and Purchase Life Annuities can qualify for impaired terms.

== Valuation ==
{{See also|Actuarial present value#Life annuity}}

[[Valuation (finance)|Valuation]] is the calculation of economic value or worth. Valuation of an annuity is calculated as the [[actuarial present value]] of the annuity, which is dependent on the [[probability]] of the annuitant living to each future payment period, as well as the interest rate and timing of future payments. [[Life table]]s provide the probabilities of survival necessary for such calculations.

==Annuities by region==

===United States===
{{further|Annuity (US financial products)}}

With a "single premium" or "immediate" annuity, the "annuitant" pays for the annuity with a single lump sum. The annuity starts making regular payments to the annuitant within a year. A common use of a single premium annuity is as a destination for roll-over retirement savings upon retirement. In such a case, a retiree withdraws all of the money he/she has saved during working life in, for example, an [[Individual retirement account|Individual Retirement Account (IRA)]], and uses some or all of the money to buy an annuity whose payments will replace the retiree's wage payments for the rest of his/her life. The advantage of such an annuity is that the annuitant has a guaranteed income for life, whereas if the retiree were instead to withdraw money regularly from the retirement account (income drawdown), he/she might run out of money before death, or alternatively not have as much to spend while alive as could have been possible with an annuity purchase. Another common use for an income annuity is to pay recurring expenses, such as assisted living expenses, mortgage or insurance premiums.

The disadvantage of such an annuity is that the election is irrevocable and, because of inflation, a guaranteed income for life is not the same thing as guaranteeing a comfortable income for life.

===United Kingdom===
In the United Kingdom conversion of pension income into an annuity was compulsory by the age of 75 until new legislation was introduced by the coalition government in April 2011.&lt;ref&gt;"[http://www.bankingtimes.co.uk/2010/12/10/finance-bill-to-scrap-compulsory-annuity-age/ "Finance Bill to scrap compulsory annuity age"] Banking Times, December 10, 2010&lt;/ref&gt; The new rules allow individuals to delay the decision to purchase an annuity indefinitely.

In the UK there are a large market of annuities of different types. The most common are those where the source of the funds required to buy the annuity is from a pension scheme. Examples of these types of annuity, often referred to as a Compulsory Purchase Annuity, are conventional annuities, with profit annuities and unit linked, or "third way" annuities. Annuities purchased from savings (i.e. not from a pension scheme) are referred to as Purchase Life Annuities and Immediate Vesting Annuities. In October 2009, the [http://www.ilcuk.org.uk International Longevity Centre-UK] published a report on Purchased Life Annuities (Time to Annuitise). 
In the UK it has become common for life companies to base their annuity rates on an individual's location. Legal &amp; General were the first company to do this in 2007.&lt;ref name=Cannon&gt;{{cite book|last=Cannon|first=Edmund|title=Annuity Markets|year=2008|publisher=Oxford University Press|location=Oxford|isbn=978-0-19-921699-4|page=260|url=http://ukcatalogue.oup.com/product/9780199216994.do|author2=Ian Tonks }}&lt;/ref&gt;

===Canada===
In Canada the most common type of annuity is the life annuity, which is normally purchased by persons at their retirement age with tax-sheltered funds or with savings funds. The monthly payments from annuities with tax-sheltered funds are fully taxable when withdrawn as neither the capital or return thereon has been taxed in any way. Conversely income from annuities purchased with savings funds is divided between the return of capital and interest earned, with only the latter being taxable.
 
An annuity can be a single life annuity or a joint life annuity where the payments are guaranteed until the death of the second annuitant. It is regarded as ideal for retirees as it is the only income of any financial product that is fully guaranteed. In addition, while the monthly payments are for the upkeep and enjoyment of the annuitants, any guaranteed payments on non-registered annuities are continued to beneficiaries after the second death. This way the balance of the guaranteed payments supports family members and becomes a two-generation income.

===Internationally===
Some countries developed more options of value for this type of instrument than others. However, a 2005 study reported that some of the risks related to [[longevity]] are poorly managed "practically everywhere" due to governments backing away from defined benefit promises and insurance companies being reluctant to sell genuine life annuities because of fears that life expectancy will go up.&lt;ref name="missing"/&gt; [[Longevity insurance]] is now becoming more common in the UK and the U.S. (see Future of annuites, below) while Chile, in comparison to the U.S., has had a very large life annuity market for 20 years.&lt;ref&gt;"[http://www.insurancenewsnet.com/article.asp?a=top_news&amp;id=30974 NCPA: Baby Boom Retirement Could Cause Annuity Market Explosion] {{webarchive|url=https://web.archive.org/web/20070928095029/http://www.insurancenewsnet.com/article.asp?a=top_news&amp;id=30974 |date=2007-09-28 }}" Insurance Newsnet, 12/9/2004&lt;/ref&gt;

==Future of annuities==
It is expected that the aging of the [[baby boomer]] generation in the US will increase the demand for this type of instrument and for it to be optimized for the annuitant.&lt;ref&gt;"[https://finance.yahoo.com/focus-retirement/article/105678/An-Income-Stream-to-Last-a-Lifetime?mod=retirement-post-spending An Income Stream to Last a Lifetime]" Anne Kates Smith, Kiplinger&lt;/ref&gt; This growing market will drive improvements necessitating more [[Life table#The mathematics|research and development of instruments]] and increase insight into the mechanics involved on the part of the buying public. An example of increased scrutiny and discussion is that related to [[privatization]] of part of the U.S. [[Social Security Trust Fund]].

In late  2010, discussions related to cutting Federal taxes raised anew the following concern: how much would an annuity cost a retiree if he or she had to replace his or her Social Security income? Assuming that the average benefit from Social Security is $14,000 per year, the replacement cost would be about $250,000 for a 66-year-old individual. The figures are based upon the individual receiving an inflation-adjusted stream that would pay for life and be insured.&lt;ref&gt;"[https://finance.yahoo.com/focus-retirement/article/111640/could-you-retire-without-social-security;_ylt=AhYu.6rAp1KSabILrbNr.sy7YWsA;_ylu=X3oDMTE1azk4N240BHBvcwMzBHNlYwNmaWRlbGl0eUZQBHNsawNjb3VsZHlvdWFmZm8-?mod=fidelity-readytoretire&amp;cat=fidelity_2010_getting_ready_to_retire Could you retire without Social Security?] Bret Arends, WSJ&lt;/ref&gt;

==European Court of Justice ruling==

In March 2011 a European Court of Justice ruling was made that prevents annuity providers from setting different premiums for men and women. Annuity rates for men are generally higher than those for women because they have shorter life expectancies. The change means that either annuity rates for men will fall or annuity rates for women will rise.

In the UK any annuities that are taken out after 21 December 2012 will have to comply with the ruling.{{Citation needed|date=March 2011}}

==See also==
*[[Actuarial present value]]
*[[Annuity (European financial arrangements)#Life annuity]]
*[[Certificate of life]]
*[[Pension]]
*[[Life estate]]

==References==
{{reflist}}

== External links ==
* [http://www.retailinvestor.org/annuity.html Math and spreadsheet for purchase and deferral decision]
* [http://www.financeinformar.info/annuities/ various kinds of annuities]
* [http://www.lawyersandsettlements.com/articles/variable-annuity/interview-variable-annuities-annuity-19074.html Variable Annuities Interview- Legal Perspective]

[[Category:Retirement]]
[[Category:Annuities]]
[[Category:Actuarial science]]

[[de:Leibrente]]
[[fr:Rente viagère]]
[[nl:Lijfrente]]
[[pl:Umowa renty]]
[[fi:Elinkorko]]</text>
      <sha1>msokh7yp0damu6acxmqx0upnyq18l2j</sha1>
    </revision>
  </page>
  <page>
    <title>Liénard equation</title>
    <ns>0</ns>
    <id>4135185</id>
    <revision>
      <id>835531083</id>
      <parentid>835530934</parentid>
      <timestamp>2018-04-09T07:19:51Z</timestamp>
      <contributor>
        <username>RydinG</username>
        <id>32614391</id>
      </contributor>
      <minor/>
      <comment>English language improvements</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3890">In [[mathematics]], more specifically in the study of [[dynamical system]]s and [[differential equation]]s, a '''Liénard equation'''&lt;ref&gt;Liénard, A. (1928) "Etude des oscillations entretenues," ''Revue générale de l'électricité'' '''23''', pp. 901–912 and 946–954.&lt;/ref&gt; is a second order differential equation, named after the French physicist [[Alfred-Marie Liénard]].

During the development of [[radio]] and [[vacuum tube]] technology, Liénard equations were intensely studied as they can be used to model [[oscillating circuit]]s. Under certain additional assumptions '''Liénard's theorem''' guarantees the uniqueness and existence of a [[limit cycle]] for such a system.

==Definition==

Let ''f'' and ''g'' be two [[continuously differentiable]] functions on '''R''', with ''g'' an [[odd function]] and ''f'' an [[even function]]. Then the second order [[ordinary differential equation]] of the form

:&lt;math&gt;{d^2x \over dt^2}+f(x){dx \over dt}+g(x)=0&lt;/math&gt;

is called the '''Liénard equation'''.

==Liénard system==

The equation can be transformed into an equivalent two-dimensional [[system of ordinary differential equation]]s. We define 
:&lt;math&gt;F(x) := \int_0^x f(\xi) d\xi&lt;/math&gt;
:&lt;math&gt;x_1:= x&lt;/math&gt; 
:&lt;math&gt;x_2:={dx \over dt} + F(x)&lt;/math&gt; 
then

:&lt;math&gt;
\begin{bmatrix} 
\dot{x}_1 \\
\dot{x}_2 
\end{bmatrix}
= 
\mathbf{h}(x_1, x_2) 
:= 
\begin{bmatrix} 
x_2 - F(x_1) \\
-g(x_1)
\end{bmatrix}
&lt;/math&gt;

is called a '''Liénard system'''.

Alternatively, since Liénard equation itself is also an [[autonomous differential equation]], the substitution &lt;math&gt;v = {dx \over dt}&lt;/math&gt; leads the Liénard equation to become a [[first order differential equation]]:

:&lt;math&gt;v{dv \over dx}+f(x)v+g(x)=0&lt;/math&gt;

which belongs to [[Abel equation of the second kind]].&lt;ref&gt;[http://eqworld.ipmnet.ru/en/solutions/ode/ode0317.pdf Liénard equation] at [[eqworld]].&lt;/ref&gt;&lt;ref&gt;[http://eqworld.ipmnet.ru/en/solutions/ode/ode0125.pdf Abel equation of the second kind] at [[eqworld]].&lt;/ref&gt;

==Example==

The [[Van der Pol oscillator]]

:&lt;math&gt;{d^2x \over dt^2}-\mu(1-x^2){dx \over dt} +x= 0&lt;/math&gt;

is a Liénard equation. The solution of a Van der Pol oscillator has a limit cycle. Such cycle has a solution of a Liénard equation with negative &lt;math&gt;f(x)&lt;/math&gt; at small &lt;math&gt;|x|&lt;/math&gt; and positive &lt;math&gt;f(x)&lt;/math&gt; otherwise. The Van der Pol equation has no exact, analytic solution. Such solution for a limit cycle exists if &lt;math&gt;f(x)&lt;/math&gt; is a constant piece-wise function.&lt;ref&gt;Pilipenko A. M., and Biryukov V. N. «Investigation of Modern Numerical Analysis Methods of Self-Oscillatory Circuits Efficiency», Journal of Radio Electronics, No 9, (2013). http://jre.cplire.ru/jre/aug13/9/text-engl.html&lt;/ref&gt;

==Liénard's theorem==

A Liénard system has a unique and [[Stability theory|stable]] [[limit cycle]] surrounding the origin if it satisfies the following additional properties:&lt;ref&gt;For a proof, see {{cite book |first=Lawrence |last=Perko |title=Differential Equations and Dynamical Systems |location=New York |publisher=Springer |year=1991 |edition=Third |isbn=0-387-97443-1 |pages=254–257 |url=https://books.google.com/books?id=xftQAAAAMAAJ&amp;pg=PA254 }}&lt;/ref&gt;
* ''g''(''x'') &gt; 0 for all ''x'' &gt; 0;
* &lt;math&gt;\lim_{x \to \infty} F(x) := \lim_{x \to \infty} \int_0^x f(\xi) d\xi\ = \infty;&lt;/math&gt;
* ''F''(''x'') has exactly one positive root at some value ''p'', where ''F''(''x'') &lt; 0 for 0 &lt; ''x'' &lt; ''p'' and ''F''(''x'') &gt; 0 and monotonic for ''x'' &gt; ''p''.

==See also==
*[[Autonomous differential equation]]
*[[Abel equation of the second kind]]

==Footnotes==

{{reflist}}

==External links==
* {{springer|title=Liénard equation|id=p/l058790}}
* {{PlanetMath|title=LienardSystem|urlname=LienardSystem}}

{{DEFAULTSORT:Lienard equation}}
[[Category:Dynamical systems]]
[[Category:Differential equations]]
[[Category:Theorems in dynamical systems]]</text>
      <sha1>fc8mspa3fl0bgmwowe10flqmr6rs0u3</sha1>
    </revision>
  </page>
  <page>
    <title>Mehler kernel</title>
    <ns>0</ns>
    <id>31393808</id>
    <revision>
      <id>848437071</id>
      <parentid>839636776</parentid>
      <timestamp>2018-07-01T21:59:26Z</timestamp>
      <contributor>
        <username>A. Pichler</username>
        <id>994972</id>
      </contributor>
      <minor/>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10680">== Mehler's formula ==
{{harvs|txt|last=Mehler|authorlink=Gustav Ferdinand Mehler|year=1866}} defined a function&lt;ref&gt;{{Citation | last1=Mehler | first1=F. G. | title=Ueber die Entwicklung einer Function von beliebig vielen Variabeln nach Laplaceschen Functionen höherer Ordnung | url=http://resolver.sub.uni-goettingen.de/purl?GDZPPN002152975 | language=German |id={{ERAM|066.1720cj}} | year=1866 | journal=Journal für die Reine und Angewandte Mathematik | issn=0075-4102 | issue=66 | pages=161–176}} (cf.  p 174, eqn (18)  &amp; p 173, eqn (13) )&lt;/ref&gt;
{{Equation box 1
|indent =::
|equation =  &lt;math&gt;E(x,y) =\frac 1{\sqrt{1-\rho^2}}\exp\left(-\frac{\rho^2 (x^2+y^2)- 2\rho xy}{(1-\rho^2)}\right)~, &lt;/math&gt;
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
and showed, in modernized notation,&lt;ref&gt;{{citation|first=Arthur|last= Erdélyi|authorlink1=Arthur Erdélyi|first2= Wilhelm |last2=Magnus|authorlink2=Wilhelm Magnus|first3= Fritz|last3= Oberhettinger|first4=Francesco G.|last4= Tricomi|authorlink4=Francesco Tricomi|title= Higher transcendental functions. Vol. II|publisher= McGraw-Hill| year=1955}} ([http://www.nr.com/legacybooks scan]:  &amp;nbsp;    [http://apps.nrbook.com/bateman/Vol2.pdf p.194 10.13 (22)])&lt;/ref&gt; that it can be expanded in terms of [[Hermite polynomials]] {{mvar|H}}(.) based on weight function exp(−{{mvar|x}}²) as
:&lt;math&gt;E(x,y) = \sum_{n=0}^\infty \frac{(\rho/2)^n}{n!} ~ \mathit{H}_n(x)\mathit{H}_n(y) ~.&lt;/math&gt;

This result is useful, in modified form, in quantum physics, probability theory, and harmonic analysis.

== Physics version ==
In physics, the [[fundamental solution]], ([[Green's function]]), or [[Propagator#Basic Examples: Propagator of Free Particle and Harmonic Oscillator|propagator]] of the Hamiltonian for the [[quantum harmonic oscillator]] is called the '''Mehler kernel'''.  It provides the [[fundamental solution]]---the most general solution&lt;ref&gt;[[Wolfgang Pauli|Pauli, W.]],   ''Wave Mechanics: Volume 5 of Pauli Lectures on Physics'' (Dover Books on Physics, 2000) {{ISBN|0486414620}} ; See section 44.&lt;/ref&gt; {{math|''φ''(''x'',''t'')}}   to 
:&lt;math&gt;\frac{\partial \varphi}{\partial t} = \frac{\partial^2 \varphi}{\partial x^2}-x^2\varphi \equiv D_x \varphi ~.&lt;/math&gt;

The orthonormal eigenfunctions of the operator {{mvar|D}} are the [[Hermite polynomials#Hermite functions|Hermite functions]],
:&lt;math&gt;\psi_n = \frac{H_n(x) \exp(-x^2/2)}{\sqrt{2^n n! \sqrt{\pi}}},&lt;/math&gt;
with corresponding eigenvalues (2{{mvar|n}}+1), furnishing particular solutions
: &lt;math&gt; \varphi_n(x, t)= e^{-(2n+1)t} ~H_n(x) \exp(-x^2/2) ~.&lt;/math&gt;

The general solution is then a linear combination of these; when fitted to the initial condition {{math|''φ(x,0)''}}, the general solution reduces to
: &lt;math&gt;\varphi(x,t)= \int K(x,y;t) \varphi(y,0) dy ~,&lt;/math&gt;
where the kernel {{mvar|K}} has the separable representation
:&lt;math&gt;K(x,y;t)\equiv\sum_{n\ge 0} \frac {e^{-(2n+1)t}}{\sqrt\pi  2^n  n!} ~ H_n(x)H_n(y)\exp(-(x^2+y^2)/2)~.&lt;/math&gt;

Utilizing Mehler's formula then yields 
:&lt;math&gt;\displaystyle{\sum_{n\ge 0} \frac {(\rho/2)^n}{n!} H_n(x)H_n(y) \exp(-(x^2+y^2)/2) = {1\over \sqrt{(1-\rho^2)}} \exp {4xy\rho - (1+\rho^2)(x^2+y^2)\over 2(1-\rho^2)}}~.&lt;/math&gt;

On substituting this in the expression for {{mvar|K}} with the value exp(−2{{mvar|t}}) for {{mvar|ρ}}, Mehler's kernel finally reads
{{Equation box 1
|indent =::
|equation =  &lt;math&gt;K(x,y;t)= \frac{1}{\sqrt{2\pi\sinh(2t)}}~\exp\Bigl(-\coth(2t)~(x^2+y^2)/2 + \text{cosech}(2t)~xy\Bigr).&lt;/math&gt;
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}

When {{mvar|t}} = 0, variables {{mvar|x}} and {{mvar|y}} coincide, resulting in the limiting formula necessary by the initial condition,
::&lt;math&gt;K(x,y;0)= \delta(x-y)~. &lt;/math&gt;
As a fundamental solution, the kernel is additive,
:&lt;math&gt;\int dy K(x,y;t) K(y,z;t') = K(x,z;t+t')  ~.&lt;/math&gt;

This is further related to the symplectic rotation structure of the kernel  {{mvar|K}}.&lt;ref&gt;The [[quadratic form]] in its exponent, up to a factor of −1/2, involves the simplest (unimodular, symmetric) [[symplectic matrix]] in Sp(2,ℝ). That is, 
:&lt;math&gt; (x,y) {\mathbf M} \begin{pmatrix}{x}\\{y}\end{pmatrix} ~,~&lt;/math&gt; &amp;nbsp; where
:&lt;math&gt; {\mathbf M} \equiv\text{cosech} (2t) \begin{pmatrix} \cosh (2t) &amp;-1\\-1&amp;\cosh (2t)\end{pmatrix} ~,&lt;/math&gt;
so it preserves the symplectic metric,
:&lt;math&gt; {\mathbf M}^\text{T} ~ \begin{pmatrix}  0 &amp;1\\-1&amp;0\end{pmatrix} ~ {\mathbf M} = \begin{pmatrix}  0 &amp;1\\-1&amp;0\end{pmatrix}  ~.&lt;/math&gt;&lt;/ref&gt;

== Probability version ==
The result of Mehler can also be linked  to probability. For this, the variables should be rescaled as {{math|''x'' → ''x''/{{radic|2}}}}, {{math|''y'' → ''y''/{{radic|2}}}}, so as to change from the 'physicist's' Hermite polynomials {{mvar|H}}(.) (with weight function exp(−{{mvar|x}}²)) to "probabilist's" Hermite polynomials {{math|''He''}}(.) (with weight function exp(−{{mvar|x}}²/2)). Then, {{mvar|E}} becomes
:&lt;math&gt; 
\frac 1{\sqrt{1-\rho^2}}\exp\left(-\frac{\rho^2 (x^2+y^2)- 2\rho xy}{2(1-\rho^2)}\right)
 = \sum_{n=0}^\infty \frac{\rho^n}{n!} ~ \mathit{He}_n(x)\mathit{He}_n(y) ~.&lt;/math&gt;

The left-hand side here is ''p(x,y)/p(x)p(y)'' where ''p(x,y)'' is the   [[Multivariate normal distribution#Non-degenerate case|bivariate Gaussian probability density]] function for variables {{math|''x,y''}} having zero means and unit variances: 
:&lt;math&gt;p(x,y) =
\frac 1{2\pi \sqrt{1-\rho^2}}\exp\left(-\frac{(x^2+y^2)- 2\rho xy}{2(1-\rho^2)}\right) ~,
&lt;/math&gt;
and {{math|''p(x), p(y)''}} are the corresponding probability densities of {{mvar|x}} and {{mvar|y}}.

There follows the usually quoted form of the result (Kibble 1945)&lt;ref&gt;{{Citation | last1=Kibble | first1=W. F. | title=An extension of a theorem of Mehler's on Hermite polynomials | doi=10.1017/S0305004100022313  | mr=0012728 | year=1945 | journal=Proc. Cambridge Philos. Soc. | volume=41 | pages=12–15}}&lt;/ref&gt;
:&lt;math&gt;p(x,y) = p(x) p(y)\sum_{n=0}^\infty \frac{\rho^n}{n!} ~ \mathit{He}_n(x)\mathit{He}_n(y) ~.&lt;/math&gt;

This expansion is most easily derived by using the two-dimensional Fourier transform of {{math|''p(x,y)''}}, which is
:&lt;math&gt; c(iu_1, iu_2) = \exp (- (u_1^2 + u_2^2 - 2 \rho u_1 u_2)/2)~.&lt;/math&gt;

This may be expanded as
:&lt;math&gt; \exp( -(u_1^2 + u_2^2)/2 ) \sum_{n=0}^\infty \frac {\rho^n}{n!} (u_1 u_2)^n ~.  &lt;/math&gt;
The Inverse Fourier transform then immediately yields the above expansion formula.

This result can be extended to the multidimensional case (Kibble 1945, Slepian 1972,&lt;ref&gt;{{Citation | last1=Slepian | first1=David | title=On the symmetrized Kronecker power of a matrix and extensions of Mehler's formula for Hermite polynomials | doi=10.1137/0503060 | mr=0315173 | year=1972 | journal=SIAM Journal on Mathematical Analysis | issn=0036-1410 | volume=3 | pages=606–616}}&lt;/ref&gt; Hörmander 1985 &lt;ref&gt;{{Cite journal|
journal=Mathematische Zeitschrift |
date=1995 |
volume =219 |
pages=413–449 |
title=Symplectic classification of quadratic forms, and general Mehler formulas |
author= Hörmander, Lars | doi = 10.1007/BF02572374}}&lt;/ref&gt;).

==Fractional Fourier transform==
{{main|Fractional Fourier transform}}
Since Hermite functions {{math|''ψ&lt;sub&gt;n&lt;/sub&gt;''}} are orthonormal [[Fourier transform#Eigenfunctions|eigenfunctions of the Fourier transform]],
:&lt;math&gt;\mathcal{F} [\psi_n](y)=(-i)^n \psi_n(y) ~,&lt;/math&gt; 
in [[harmonic analysis]] and [[signal processing]], they diagonalize the Fourier operator,
:&lt;math&gt;\mathcal{F}[f](y) =\int dx f(x) \sum_{n\geq 0} (-i)^n   \psi_n(x)  \psi_n(y) ~.  &lt;/math&gt;

Thus, the continuous generalization for  [[real number|real]] angle {{mvar|α}} can be readily defined ([[Norbert Wiener|Wiener]], 1929;&lt;ref&gt;[[Norbert Wiener|Wiener]], N (1929), "Hermitian Polynomials and Fourier Analysis",  ''Journal of Mathematics and Physics'' '''8''': 70-73.&lt;/ref&gt;  [[Edward Condon|Condon]],  1937&lt;ref&gt;[[Edward Condon|Condon, E. U.]]  (1937). "Immersion of the Fourier transform in a continuous group of functional transformations", ''Proc. Natl. Acad. Sci. USA''  '''23''', 158–164. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1076889/pdf/pnas01779-0028.pdf online]&lt;/ref&gt;),  the [[fractional Fourier transform]] (FrFT), with kernel
:&lt;math&gt;\mathcal{F}_\alpha = \sum_{n\geq 0} (-i)^{2\alpha n/\pi}   \psi_n(x)  \psi_n(y) ~.  &lt;/math&gt;

This is a ''continuous family of linear transforms generalizing the [[Fourier transform]]'', such that, for  {{math|''α'' {{=}} ''π''/2}}, it reduces to  the standard Fourier transform, and for  {{math|''α'' {{=}} −''π''/2}} to the inverse Fourier transform.

The Mehler formula,  for {{mvar|ρ}} = exp(−i{{mvar|α}}),  thus directly provides
:&lt;math&gt;\mathcal{F}_\alpha[f](y) = 
\sqrt{\frac{1-i\cot(\alpha)}{2\pi}} ~ e^{i \frac{\cot(\alpha)}{2} y^2} 
\int_{-\infty}^\infty 
e^{-i\left(\csc(\alpha)~ y x - \frac{\cot(\alpha)}{2} x^2\right )} f(x)\, \mathrm{d}x ~. 
&lt;/math&gt;
The square root is defined such that the argument of the result lies in the interval [−''π'' /2, ''π'' /2].

If {{mvar|α}} is an integer multiple of {{mvar|π}}, then the above  [[cotangent]] and [[cosecant]] functions diverge.  In the  [[limit of a function|limit]], the kernel goes to a [[Dirac delta function]] in the integrand, {{mvar|''δ(x−y)''}} or {{mvar|δ(x+y)}}, for   {{mvar|α}} an  [[Even and odd numbers|even or odd]] multiple of  {{mvar|π}}, respectively. Since &lt;math&gt;\mathcal{F}^2&lt;/math&gt;[{{mvar|f}} ] = {{mvar|f}}(−{{mvar|x}}), &lt;math&gt;\mathcal{F}_\alpha&lt;/math&gt;[{{mvar|f}} ] must be simply {{math|''f''(''x'')}}  or {{math|''f''(−''x'')}} for  {{mvar|α}}  an even or odd multiple of  {{mvar|π}}, respectively.

==See also==
*[[Oscillator representation#Harmonic oscillator and Hermite functions]]
* [[Heat kernel]]
* [[Hermite polynomials]]
* [[Parabolic cylinder function]]s
* [[Laguerre polynomial#Hardy-Hille formula]]

==References==
&lt;references/&gt;
* Nicole Berline, Ezra Getzler, and Michèle Vergne (2013). ''Heat Kernels and Dirac Operators'',  (Springer: Grundlehren Text Editions) Paperback  {{ISBN|3540200622}}
* {{Cite journal|author=Louck, J. D.| journal=Advances in Applied Mathematics|
volume =2 | date= 1981| pages= 239–249| title=Extension of the Kibble-Slepian formula for Hermite polynomials using boson operator methods | doi = 10.1016/0196-8858(81)90005-1}}
* H. M. Srivastava and J. P. Singhal (1972). "Some extensions of the Mehler formula", ''Proc. Amer. Math. Soc.''  '''31''': 135-141. ([http://www.ams.org/journals/proc/1972-031-01/S0002-9939-1972-0285738-4/S0002-9939-1972-0285738-4.pdf online])

[[Category:Parabolic partial differential equations]]
[[Category:Orthogonal polynomials]]
[[Category:Mathematical physics]]
[[Category:Multivariate continuous distributions]]</text>
      <sha1>1ptngg1oxzblmfank8cjkzpdiezh4mx</sha1>
    </revision>
  </page>
  <page>
    <title>Microlocal analysis</title>
    <ns>0</ns>
    <id>6108841</id>
    <revision>
      <id>786692382</id>
      <parentid>544480568</parentid>
      <timestamp>2017-06-21T01:11:26Z</timestamp>
      <contributor>
        <username>Kobeyamate</username>
        <id>19504959</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1020">In [[mathematical analysis]], '''microlocal analysis''' comprises techniques developed from the 1950s onwards based on [[Fourier transform]]s related to the study of variable-coefficients-linear and nonlinear [[partial differential equation]]s.  This includes [[generalized function]]s, [[pseudo-differential operator]]s, [[wave front set]]s, [[Fourier integral operator]]s, [[oscillatory integral operator]]s, and [[paradifferential operator]]s. 

The term ''microlocal'' implies localisation not only with respect to location in the space, but also with respect to [[cotangent space]] directions at a given point. This gains in importance on [[manifold]]s of [[dimension]] greater than one. 

==See also==
*[[Algebraic analysis]]

==External links==
*[http://www-math.mit.edu/~rbm/iml90.pdf lecture notes by Richard Melrose] 
*[http://math.mit.edu/~rbm/18.157-F09/18.157-F09.html newer lecture notes by Richard Melrose]

[[Category:Fourier analysis]]
[[Category:Microlocal analysis]]
[[Category:Generalized functions]]</text>
      <sha1>ifgssjt5q66he106jm8lhvd797ozmg7</sha1>
    </revision>
  </page>
  <page>
    <title>Orientability</title>
    <ns>0</ns>
    <id>187446</id>
    <revision>
      <id>870248973</id>
      <parentid>870248700</parentid>
      <timestamp>2018-11-23T13:57:27Z</timestamp>
      <contributor>
        <username>Jean Raimbault</username>
        <id>27087074</id>
      </contributor>
      <comment>/* Orientability of manifolds */ made citation look like the other one of same bk</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25573">{{For|orientation of vector spaces|orientation (mathematics)}}
{{Other uses|Orientation (disambiguation)}}

[[File:Torus.png|right|thumb|A [[torus]] is an orientable surface]]
[[File:Fiddler crab mobius strip.gif|right|thumb|The [[Möbius strip]] is a non-orientable surface. Note that the fiddler crab moving around it has left and right flipped with every complete circulation. This would not happen if the crab were on the torus.]]
[[File:Steiner's Roman Surface.gif|right|thumb|The [[Roman surface]] is non-orientable]]

In [[mathematics]], '''orientability''' is a property of [[Surface (topology)|surface]]s in [[Euclidean space]] that measures whether it is possible to make a consistent choice of [[surface normal]] [[vector (mathematics)|vector]] at every point.  A choice of surface normal allows one to use the [[right-hand rule]] to define a "clockwise" direction of loops in the surface, as needed by [[Stokes' theorem]] for instance.  More generally, orientability of an abstract surface, or [[manifold]], measures whether one can consistently choose a "clockwise" orientation for all loops in the manifold.  Equivalently, a surface is '''orientable''' if a two-dimensional figure such as [[File:Small pie.svg|20px]] in the space cannot be moved (continuously) around the space and back to where it started so that it looks like its own mirror image [[File:pie 2.svg|20px]].

The notion of orientability can be generalised to higher-dimensional [[manifold]]s as well.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?redir_esc=y&amp;id=9MQ-AAAAIAAJ&amp;focus=searchwithinvolume&amp;q=oriented+manifold|title=Modern multidimensional calculus|last=Munroe|first=Marshall Evans|date=1963|publisher=Addison-Wesley Pub. Co.|language=en|page=263}}&lt;/ref&gt; A manifold is orientable if it has a consistent choice of [[orientation (mathematics)|orientation]], and a [[connected space|connected]] orientable manifold has exactly two different possible orientations.  In this setting, various equivalent formulations of orientability can be given, depending on the desired application and level of generality.  Formulations applicable to general topological manifolds often employ methods of [[homology theory]], whereas for [[differentiable manifolds]] more structure is present, allowing a formulation in terms of [[differential form]]s.  An important generalization of the notion of orientability of a space is that of orientability of a family of spaces parameterized by some other space (a [[fiber bundle]]) for which an orientation must be selected in each of the spaces which varies continuously with respect to changes in the parameter values.

==Orientable surfaces==
[[File:Surface orientation.gif|thumb|300px|right|In this animation, a simple analogy is made using a gear that rotates according to the right-hand rule on a surface's normal vector. The orientation of the curves given by the boundaries is given by the direction in which the dots move as they are pushed by the moving gear. On a non-orientable surface, such as the Möbius strip, the boundary would have to move in both directions at once, which is not possible.]]

A surface ''S'' in the [[Euclidean space]] '''R'''&lt;sup&gt;3&lt;/sup&gt; is orientable if a two-dimensional figure (for example, [[File:Small pie.svg|20px]]) cannot be moved around the surface and back to where it started so that it looks like its own mirror image ([[File:pie 2.svg|20px]]). Otherwise the surface is '''non-orientable'''.  An abstract surface (i.e., a two-dimensional [[manifold]]) is orientable if a consistent concept of clockwise rotation can be defined on the surface in a continuous manner.  That is to say that a loop going around one way on the surface can never be continuously deformed (without overlapping itself) to a loop going around the opposite way. This turns out to be equivalent to the question of whether the surface contains no subset that is  [[homeomorphic]] to the [[Möbius strip]].  Thus, for surfaces, the Möbius strip may be considered the source of all non-orientability.

For an orientable surface, a consistent choice of "clockwise" (as opposed to counter-clockwise) is called an '''orientation''', and the surface is called '''oriented'''.  For surfaces embedded in Euclidean space, an orientation is specified by the choice of a continuously varying [[surface normal]] '''n''' at every point.  If such a normal exists at all, then there are always two ways to select it: '''n''' or &amp;minus;'''n'''.  More generally, an orientable surface admits exactly two orientations, and the distinction between an orient''ed'' surface and an orient''able'' surface is subtle and frequently blurred. An orientable surface is an abstract surface that admits an orientation, while an oriented surface is a surface that is abstractly orientable, and has the additional datum of a choice of one of the two possible orientations.

;Examples
Most surfaces we encounter in the physical world are orientable.  [[Sphere]]s, [[plane (mathematics)|planes]], and [[torus|tori]] are orientable, for example.  But [[Möbius strip]]s, [[real projective plane]]s, and [[Klein bottle]]s are non-orientable. They, as visualized in 3-dimensions, all have just one side.  The real projective plane and Klein bottle cannot be embedded in '''R'''&lt;sup&gt;3&lt;/sup&gt;, only [[immersion (mathematics)|immersed]] with nice intersections.

Note that locally an embedded surface always has two sides, so a near-sighted ant crawling on a one-sided surface would think there is an "other side".  The essence of one-sidedness is that the ant can crawl from one side of the surface to the "other" without going through the surface or flipping over an edge, but simply by crawling far enough.

In general, the property of being orientable is not equivalent to being two-sided; however, this holds when the ambient space (such as '''R'''&lt;sup&gt;3&lt;/sup&gt;  above) is orientable. For example, a torus embedded in 
:&lt;math&gt;K^2 \times S^1&lt;/math&gt;

can be one-sided, and a Klein bottle in the same space can be two-sided; here &lt;math&gt;K^2&lt;/math&gt; refers to the Klein bottle.

;Orientation by triangulation
Any surface has a [[triangulation (topology)|triangulation]]: a decomposition into triangles such that each edge on a triangle is glued to at most one other edge. Each triangle is oriented by choosing a direction around the perimeter of the triangle, associating a direction to each edge of the triangle.  If this is done in such a way that, when glued together, neighboring edges are pointing in the opposite direction, then this determines an orientation of the surface.  Such a choice is only possible if the surface is orientable, and in this case there are exactly two different orientations.

If the figure [[File:Small pie.svg|20px]] can be consistently positioned at all points of the surface without turning into its mirror image, then this will induce an orientation in the above sense on each of the triangles of the triangulation by selecting the direction of each of the triangles based on the order red-green-blue of colors of any of the figures in the interior of the triangle.

This approach generalizes to any ''n''-manifold having a triangulation.  However,  some 4-manifolds do not have a triangulation, and in general for ''n'' &gt; 4  some ''n''-manifolds have triangulations that are inequivalent.

;Orientability and homology

If ''H''&lt;sub&gt;1&lt;/sub&gt;(''S'') denotes the first [[Homology (mathematics)|homology]] group of a surface ''S'', then ''S'' is orientable if and only if ''H''&lt;sub&gt;1&lt;/sub&gt;(''S'') has a trivial [[torsion subgroup]]. More precisely, if ''S'' is orientable then ''H''&lt;sub&gt;1&lt;/sub&gt;(''S'') is a [[free abelian group]], and if not then ''H''&lt;sub&gt;1&lt;/sub&gt;(''S'') = ''F'' + '''Z'''/2'''Z''' where ''F'' is free abelian, and the '''Z'''/2'''Z''' factor is generated by the middle curve in a [[Möbius band]] embedded in ''S''.

==Orientability of manifolds==

Let ''M'' be a connected topological ''n''-[[manifold (mathematics)|manifold]].  There are several possible definitions of what it means for ''M'' to be orientable.  Some of these definitions require that ''M'' has extra structure, like being differentiable.  Occasionally, {{math|1=''n'' = 0}} must be made into a special case.  When more than one of these definitions applies to ''M'', then ''M'' is orientable under one definition if and only if it is orientable under the others.&lt;ref&gt;{{Cite book | last1=Spivak | first1=Michael | author1-link=Michael Spivak | title=Calculus on Manifolds | publisher=[[HarperCollins]] | isbn=978-0-8053-9021-6 | year=1965}}&lt;/ref&gt;&lt;ref&gt;{{Cite book | last1=Hatcher | first1=Allen | author1-link=Allen Hatcher | title=Algebraic Topology | publisher=[[Cambridge University Press]] | isbn=978-0521795401 | year=2001}}&lt;/ref&gt;

===Orientability of differentiable manifolds===

The most intuitive definitions require that ''M'' be a differentiable manifold.  This means that the transition functions in the atlas of ''M'' are ''C''&lt;sup&gt;1&lt;/sup&gt;-functions.  Such a function admits a [[Jacobian determinant]].  When the Jacobian determinant is positive, the transition function is said to be '''orientation preserving'''.  An '''oriented atlas''' on ''M'' is an atlas for which all transition functions are orientation preserving.  ''M'' is '''orientable''' if it admits an oriented atlas.  When {{math|''n'' &amp;gt; 0}}, an '''orientation''' of ''M'' is a maximal oriented atlas.  (When {{math|1=''n'' = 0}}, an orientation of ''M'' is a function {{math|''M'' → {±1}}}.)

Orientability and orientations can also be expressed in terms of the tangent bundle.  The tangent bundle is a [[vector bundle]], so it is a [[fiber bundle]] with [[structure group]] {{math|GL(''n'', '''R''')}}.  That is, the transition functions of the manifold induce transition functions on the tangent bundle which are fiberwise linear transformations.  If the structure group can be reduced to the group {{math|GL&lt;sup&gt;+&lt;/sup&gt;(''n'', '''R''')}} of positive determinant matrices, or equivalently if there exists an atlas whose transition functions determine an orientation preserving linear transformation on each tangent space, then the manifold ''M'' is orientable.  Conversely, ''M'' is orientable if and only if the structure group of the tangent bundle can be reduced in this way.  Similar observations can be made for the frame bundle.

Another way to define orientations on a differentiable manifold is through [[volume form]]s.  A volume form is a nowhere vanishing section ''&amp;omega;'' of {{math|&amp;#x22c0;{{sup|''n''}} ''T''{{i sup|∗}}''M''}}, the top exterior power of the cotangent bundle of ''M''.  For example, '''R'''&lt;sup&gt;''n''&lt;/sup&gt; has a standard volume form given by {{math|''dx''&lt;sup&gt;1&lt;/sup&gt; ∧ ... ∧ ''dx''&lt;sup&gt;''n''&lt;/sup&gt;}}.  Given a volume form on ''M'', the collection of all charts {{math|''U'' → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} for which the standard volume form pulls back to a positive multiple of ''&amp;omega;'' is an oriented atlas.  The existence of a volume form is therefore equivalent to orientability of the manifold.

Volume forms and tangent vectors can be combined to give yet another description of orientability.  If {{math|''X''&lt;sub&gt;1&lt;/sub&gt;, ..., ''X''&lt;sub&gt;''n''&lt;/sub&gt;}} is a basis of tangent vectors at a point ''p'', then the basis is said to be '''right-handed''' if {{math|&amp;omega;(''X''&lt;sub&gt;1&lt;/sub&gt;, ..., ''X''&lt;sub&gt;''n''&lt;/sub&gt;) &amp;gt; 0}}.  A transition function is orientation preserving if and only if it sends right-handed bases to right-handed bases.  The existence of a volume form implies a reduction of the structure group of the tangent bundle or the frame bundle to {{math|GL&lt;sup&gt;+&lt;/sup&gt;(''n'', '''R''')}}.  As before, this implies the orientability of ''M''.  Conversely, if ''M'' is orientable, then local volume forms can be patched together to create a global volume form, orientability being necessary to ensure that the global form is nowhere vanishing.

===Homology and the orientability of general manifolds===

At the heart of all the above definitions of orientability of a differentiable manifold is the notion of an orientation preserving transition function.  This raises the question of what exactly such transition functions are preserving.  They cannot be preserving an orientation of the manifold because an orientation of the manifold is an atlas, and it makes no sense to say that a transition function preserves or does not preserve an atlas of which it is a member.

This question can be resolved by defining local orientations.  On a one-dimensional manifold, a local orientation around a point ''p'' corresponds to a choice of left and right near that point.  On a two-dimensional manifold, it corresponds to a choice of clockwise and counter-clockwise.  These two situations share the common feature that they are described in terms of top-dimensional behavior near ''p'' but not at ''p''.  For the general case, let ''M'' be a topological ''n''-manifold.  A '''local orientation''' of ''M'' around a point ''p'' is a choice of generator of the group
:&lt;math&gt;H_n(M, M \setminus \{p\}; \mathbf{Z}).&lt;/math&gt;
To see the geometric significance of this group, choose a chart around ''p''.  In that chart there is a neighborhood of ''p'' which is an open ball ''B'' around the origin ''O''.  By the [[excision theorem]], &lt;math&gt;H_n(M, M \setminus \{p\}; \mathbf{Z})&lt;/math&gt; is isomorphic to &lt;math&gt;H_n(B, B \setminus \{O\}; \mathbf{Z})&lt;/math&gt;.  The ball ''B'' is contractible, so its homology groups vanish except in degree zero, and the space {{math|''B'' \ ''O''}} is an {{math|(''n'' − 1)}}-sphere, so its homology groups vanish except in degrees {{math|''n'' − 1}} and {{math|0}}.  A computation with the [[long exact sequence]] in [[relative homology]] shows that the above homology group is isomorphic to &lt;math&gt;H_{n-1}(S^{n-1}; \mathbf{Z}) \cong \mathbf{Z}&lt;/math&gt;.  A choice of generator therefore corresponds to a decision of whether, in the given chart, a sphere around ''p'' is positive or negative.  A reflection of {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} through the origin acts by negation on &lt;math&gt;H_{n-1}(S^{n-1}; \mathbf{Z})&lt;/math&gt;, so the geometric significance of the choice of generator is that it distinguishes charts from their reflections.

On a topological manifold, a transition function is '''orientation preserving''' if, at each point ''p'' in its domain, it fixes the generators of &lt;math&gt;H_n(M, M \setminus \{p\}; \mathbf{Z})&lt;/math&gt;.  From here, the relevant definitions are the same as in the differentiable case.  An '''oriented atlas''' is one for which all transition functions are orientation preserving, ''M'' is '''orientable''' if it admits an oriented atlas, and when {{math|''n'' &amp;gt; 0}}, an '''orientation''' of ''M'' is a maximal oriented atlas.

Intuitively, an orientation of ''M'' ought to define a unique local orientation of ''M'' at each point.  This is made precise by noting that any chart in the oriented atlas around ''p'' can be used to determine a sphere around ''p'', and this sphere determines a generator of &lt;math&gt;H_n(M, M \setminus \{p\}; \mathbf{Z})&lt;/math&gt;.  Moreover any other chart around ''p'' is related to the first chart by an orientation preserving transition function, and this implies that the two charts yield the same generator, whence the generator is unique.

Purely homological definitions are also possible.  Assuming that ''M'' is closed and connected, ''M'' is '''orientable''' if and only if the ''n''th homology group &lt;math&gt;H_n(M; \mathbf{Z})&lt;/math&gt; is isomorphic to the integers '''Z'''.  An '''orientation''' of ''M'' is a choice of generator {{math|&amp;alpha;}} of this group.  This generator determines an oriented atlas by fixing a generator of the infinite cyclic group &lt;math&gt;H_n(M ; \mathbf{Z})&lt;/math&gt; and taking the oriented charts to be those for which {{math|&amp;alpha;}} pushes forward to the fixed generator. Conversely, an oriented atlas determines such a generator as compatible local orientations can be glued together to give a generator for the homology group &lt;math&gt;H_n(M ; \mathbb Z)&lt;/math&gt;&lt;ref&gt;{{Cite book | last1=Hatcher | first1=Allen | author1-link=Allen Hatcher | title=Algebraic Topology | publisher=[[Cambridge University Press]] | isbn=978-0521795401 | year=2001}}, Theorem 3.26(a) on p. 236&lt;/ref&gt;.

===The orientation double cover===

Around each point of ''M'' there are two local orientations.  Intuitively, there is a way to move from a local orientation at a point {{math|''p''}} to a local orientation at a nearby point {{math|''p''&amp;prime;}}: when the two points lie in the same coordinate chart {{math|''U'' → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}, that coordinate chart defines compatible local orientations at {{math|''p''}} and {{math|''p''&amp;prime;}}.  The set of local orientations can therefore be given a topology, and this topology makes it into a manifold.

More precisely, let ''O'' be the set of all local orientations of ''M''.  To topologize ''O'' we will specify a subbase for its topology.  Let ''U'' be an open subset of ''M'' chosen such that &lt;math&gt;H_n(M, M \setminus U; \mathbf{Z})&lt;/math&gt; is isomorphic to '''Z'''.  Assume that &amp;alpha; is a generator of this group.  For each ''p'' in ''U'', there is a pushforward function &lt;math&gt;H_n(M, M \setminus U; \mathbf{Z}) \to H_n(M, M \setminus \{p\}; \mathbf{Z})&lt;/math&gt;.  The codomain of this group has two generators, and &amp;alpha; maps to one of them.  The topology on ''O'' is defined so that
:&lt;math&gt;\{\text{Image of } \alpha \text{ in } H_n(M, M \setminus \{p\}; \mathbf{Z}) \colon p \in U\}&lt;/math&gt;
is open.

There is a canonical map {{math|&amp;pi; : ''O'' → ''M''}} that sends a local orientation at ''p'' to ''p''.  It is clear that every point of ''M'' has precisely two preimages under {{math|&amp;pi;}}.  In fact, {{math|&amp;pi;}} is even a local homeomorphism, because the preimages of the open sets ''U'' mentioned above are homeomorphic to the disjoint union of two copies of ''U''.  If ''M'' is orientable, then ''M'' itself is one of these open sets, so ''O'' is the disjoint union of two copies of ''M''.  If ''M'' is non-orientable, however, then ''O'' is connected and orientable.  The manifold ''O'' is called the '''orientation double cover'''.

===Manifolds with boundary===

If ''M'' is a manifold with boundary, then an orientation of ''M'' is defined to be an orientation of its interior.  Such an orientation induces an orientation of ∂''M''.  Indeed, suppose that an orientation of ''M'' is fixed.  Let {{math|''U'' → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;&lt;sub&gt;+&lt;/sub&gt;}} be a chart at a boundary point of ''M'' which, when restricted to the interior of ''M'', is in the chosen oriented atlas.  The restriction of this chart to ∂''M'' is a chart of ∂''M''.  Such charts form an oriented atlas for ∂''M''.

When ''M'' is smooth, at each point ''p'' of ∂''M'', the restriction of the tangent bundle of ''M'' to ∂''M'' is isomorphic to {{math|''T''&lt;sub&gt;''p''&lt;/sub&gt;∂''M'' ⊕ '''R'''}}, where the factor of '''R''' is described by the inward pointing normal vector.  The orientation of ''T''&lt;sub&gt;''p''&lt;/sub&gt;∂''M'' is defined by the condition that a basis of ''T''&lt;sub&gt;''p''&lt;/sub&gt;∂''M'' is positively oriented if and only if it, when combined with the inward pointing normal vector, defines a positively oriented basis of ''T''&lt;sub&gt;''p''&lt;/sub&gt;''M''.

==Orientable double cover==
[[File:Orientation cover of Mobius strip.webm|thumb|450px|right|Animation of the Orientable double cover of the [[Möbius strip]].]]
A closely related notion uses the idea of [[covering space]]. For a connected manifold ''M'' take ''M''{{sup|∗}}, the set of pairs (''x'',&amp;nbsp;o)  where ''x'' is a point of ''M'' and ''o'' is an orientation at ''x''; here we assume ''M'' is either smooth so we can choose an orientation on the tangent space at a point or we use [[singular homology]] to define orientation.  Then for every open, oriented subset of ''M'' we consider the corresponding set of pairs and define that to be an open set of ''M''{{sup|∗}}.  This gives ''M''{{sup|∗}} a topology and the projection sending (''x'',&amp;nbsp;o) to ''x'' is then a 2-to-1 covering map.  This covering space is called the '''orientable double cover''', as it is orientable.  ''M''{{sup|∗}} is connected if and only if ''M'' is not orientable.

Another way to construct this cover is to divide the loops based at a basepoint into either orientation-preserving or orientation-reversing loops.  The orientation preserving loops generate a subgroup of the fundamental group which is either the whole group or of [[Index of a subgroup|index]] two.  In the latter case (which means there is an orientation-reversing path), the subgroup corresponds to a connected double covering; this cover is orientable by construction.  In the former case, one can simply take two copies of ''M'', each of which corresponds to a different orientation.

==Orientation of vector bundles==
{{main|orientation of a vector bundle}}

A real [[vector bundle]], which ''a priori'' has a [[GL(n)]] [[structure group]], is called ''orientable'' when the [[structure group]] may be [[Reduction of the structure group|reduced]] to &lt;math&gt;GL^{+}(n)&lt;/math&gt;, the group of [[matrix (mathematics)|matrices]] with positive [[determinant]].  For the [[tangent bundle]], this reduction is always possible if the underlying base manifold is orientable and in fact this provides a convenient way to define the orientability of a [[smooth function|smooth]] real [[manifold]]: a smooth manifold is defined to be orientable if its [[tangent bundle]] is orientable (as a vector bundle).  Note that as a manifold in its own right, the tangent bundle is ''always'' orientable, even over nonorientable manifolds.

{{See also|Euler class}}

==Related concepts==

===Linear algebra===
{{main|Orientation (mathematics)}}
The notion of orientability is essentially derived from the topology of the real [[general linear group]] 
:&lt;math&gt;\operatorname{GL}(n,\mathbf{R})&lt;/math&gt;, specifically that the lowest [[homotopy group]] is &lt;math&gt;\pi_0(\operatorname{GL}(n,\mathbf{R}))=\mathbf{Z}/2&lt;/math&gt;

an invertible transform of a real vector space is either orientation-preserving or orientation-reversing.

This holds not only for differentiable manifolds but for topological manifolds, as the space of self-[[homotopy equivalence]]s of a sphere also has two [[Connected component (topology)|connected components]], which can be denoted the "orientation-preserving" and "orientation-reversing" maps.

The analogous notion for the [[symmetric group]] is the [[alternating group]] of [[Even and odd permutations|even permutations]].

===Lorentzian geometry===

In [[Lorentzian geometry]], there are two kinds of orientability: [[space orientability]] and [[time orientability]].  These play a role in the [[causal structure]] of spacetime.&lt;ref&gt;{{cite book | author=[[Stephen Hawking|S.W. Hawking]], [[George Francis Rayner Ellis|G.F.R. Ellis]], | title=[[The Large Scale Structure of Space-Time]] | location=Cambridge | publisher=Cambridge University Press | year=1973 | isbn=0-521-20016-4}}&lt;/ref&gt;  In the context of [[general relativity]], a [[spacetime]] manifold is space orientable if, whenever two right-handed observers head off in rocket ships starting at the same spacetime point, and then meet again at another point, they remain right-handed with respect to one another.  If a spacetime is time-orientable then the two observers will always agree on the direction of time at both points of their meeting.  In fact, a spacetime is time-orientable if and only if any two observers can agree which of the two meetings preceded the other.&lt;ref&gt;Mark J. Hadley (2002) [http://www.iop.org/EJ/article/0264-9381/19/17/308/q21708.pdf?request-id=49d1e985-bf89-4203-b020-48367545e3c0 The Orientability of Spacetime], [[Classical and Quantum Gravity]] 19: 4565-4571 [https://arxiv.org/abs/gr-qc/0202031v4 arXiv:gr-qc/0202031v4]&lt;/ref&gt;

Formally, the pseudo-orthogonal group O(''p'',''q'') has a pair of [[character theory|characters]]: the space orientation character &amp;sigma;&lt;sub&gt;+&lt;/sub&gt; and the time orientation character &amp;sigma;&lt;sub&gt;&amp;minus;&lt;/sub&gt;,
:&lt;math&gt;\sigma_{\pm} : \operatorname{O}(p,q)\to \{-1,+1\}.&lt;/math&gt;
Their product &amp;sigma;&amp;nbsp;=&amp;nbsp;&amp;sigma;&lt;sub&gt;+&lt;/sub&gt;&amp;sigma;&lt;sub&gt;&amp;minus;&lt;/sub&gt; is the determinant, which gives the orientation character.  A space-orientation of a pseudo-Riemannian manifold is identified with a [[section (fiber bundle)|section]] of the [[associated bundle]]
:&lt;math&gt;\operatorname{O}(M) \times_{\sigma_+} \{-1,+1\}&lt;/math&gt;
where O(''M'') is the bundle of pseudo-orthogonal frames.  Similarly, a time orientation is a section of the associated bundle
:&lt;math&gt;\operatorname{O}(M) \times_{\sigma_-} \{-1,+1\}.&lt;/math&gt;

==See also==
* [[Curve orientation]]
* [[Orientation sheaf]]

==References==
&lt;references /&gt;

== External links ==
*[http://www.map.mpim-bonn.mpg.de/Orientation_of_manifolds Orientation of manifolds] at the Manifold Atlas.
*[http://www.map.mpim-bonn.mpg.de/Orientation_covering Orientation covering] at the Manifold Atlas.
*[http://www.map.mpim-bonn.mpg.de/Orientation_of_manifolds_in_generalized_cohomology_theories Orientation of manifolds in generalized cohomology theories] at the Manifold Atlas.
* The Encyclopedia of Mathematics article on [https://web.archive.org/web/20131103040036/http://www.encyclopediaofmath.org/index.php/Orientation Orientation].
&lt;!--[[Category:Orientation]] No.  Look at the cat before adding this.--&gt;

[[Category:Differential topology]]
[[Category:Surfaces]]

[[Category:Articles containing video clips]]

[[de:Orientierung (Mathematik)#Orientierung einer Mannigfaltigkeit]]</text>
      <sha1>nazegssdsj7azpbp5tcmy4h0sozhnwl</sha1>
    </revision>
  </page>
  <page>
    <title>Partial group algebra</title>
    <ns>0</ns>
    <id>29168254</id>
    <revision>
      <id>410900870</id>
      <parentid>410783377</parentid>
      <timestamp>2011-01-30T04:51:27Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <minor/>
      <comment>/* References */ endash</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="809">A '''partial group algebra''' is an [[associative algebra]] related to the [[partial representation]]s of a [[group (mathematics)|group]].

== Examples ==
* The partial group algebra &lt;math&gt;\mathbb{C}_{\text{par}}\left(\mathbb{Z}_4\right)&lt;/math&gt; is isomorphic to the direct sum:&lt;ref&gt;R. Exel (1998)&lt;/ref&gt;
*: &lt;math&gt;\mathbb{C}\oplus \mathbb{C}\oplus\mathbb{C}\oplus\mathbb{C}\oplus\mathbb{C}\oplus\mathbb{C}\oplus\mathbb{C}\oplus M_2\left(\mathbb{C}\right) \oplus M_3\left(\mathbb{C}\right)&lt;/math&gt;

== See also ==
* [[Group algebra]]
* [[Group representation]]

== Notes ==
&lt;references/&gt;

== References ==
* R. Exel. ''Partial Actions of Groups and Actions of Semigroups''. Proc. Am. Math. Soc. 126 no. 12 (1998), 3481–3494.

[[Category:Algebras]]
[[Category:Representation theory of groups]]


{{algebra-stub}}</text>
      <sha1>mporgyv4ssz66y048pb9zx8fbz8x4y0</sha1>
    </revision>
  </page>
  <page>
    <title>Plate notation</title>
    <ns>0</ns>
    <id>15882673</id>
    <revision>
      <id>776481996</id>
      <parentid>768972780</parentid>
      <timestamp>2017-04-21T07:47:42Z</timestamp>
      <contributor>
        <username>SJ Defender</username>
        <id>19403234</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Bugs]] (link changed to [[Bayesian inference using Gibbs sampling]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5420">In [[Bayesian inference]], '''plate notation''' is a method of representing variables that repeat in a [[graphical model]].  Instead of drawing each repeated variable individually, a plate or rectangle is used to group variables into a subgraph that repeat together, and a number is drawn on the plate to represent the number of repetitions of the subgraph in the plate.&lt;ref&gt;{{cite speech
 | title = Graphical models
 | first = Zoubin
 | last = Ghahramani
 | date = August 2007
 | location = Tübingen, Germany
 | url = http://videolectures.net/mlss07_ghahramani_grafm/
 | accessdate = 21 February 2008
}}&lt;/ref&gt;  The assumptions are that the subgraph is duplicated that many times, the variables in the subgraph are indexed by the repetition number, and any links that cross a plate boundary are replicated once for each subgraph repetition.&lt;ref&gt;{{cite journal
  | last = Buntine
  | first = Wray L.
  | title = Operations for Learning with Graphical Models
  | journal = [[Journal of Artificial Intelligence Research]]
  | volume = 2
  | pages = 159–225
  | publisher = AI Access Foundation
  | date = December 1994
  | url = http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume2/buntine94a.pdf
  | format = [[PDF]]
  | issn =  	1076-9757
  | accessdate = 21 February 2008 }}&lt;/ref&gt;

==Example==
[[Image:Latent Dirichlet allocation.svg|thumb|right|300px|Plate notation for [[Latent Dirichlet allocation]]]]

In this example, we consider [[Latent Dirichlet allocation]], a [[Bayesian network]] that models how documents in a corpus are topically related.  There are two variables not in any plate; ''α'' is the parameter of the uniform [[Dirichlet distribution|Dirichlet]] prior on the per-document topic distributions, and ''β'' is the parameter of the uniform Dirichlet prior on the per-topic word distribution.

The outermost plate represents all the variables related to a specific document, including &lt;math&gt;\theta_i&lt;/math&gt;, the topic distribution for document ''i''.  The ''M'' in the corner of the plate indicates that the variables inside are repeated ''M'' times, once for each document.  The inner plate represents the variables associated with each of the &lt;math&gt;N_i&lt;/math&gt; words in document ''i'': &lt;math&gt;z_{ij}&lt;/math&gt; is the topic for the ''j''th word in document ''i'', and &lt;math&gt;w_{ij}&lt;/math&gt; is the actual word used.

The ''N'' in the corner represents the repetition of the variables in the inner plate &lt;math&gt;N_i&lt;/math&gt; times, once for each word in document ''i''.  The circle representing the individual words is shaded, indicating that each &lt;math&gt;w_{ij}&lt;/math&gt; is [[observable variable|observable]], and the other circles are empty, indicating that the other variables are [[latent variable]]s.  The directed edges between variables indicate dependencies between the variables: for example, each &lt;math&gt;w_{ij}&lt;/math&gt; depends on &lt;math&gt;z_{ij}&lt;/math&gt; and ''β''.

{{clear}}

==Extensions==
[[File:bayesian-gaussian-mixture-vb.svg|right|300px|thumb|Bayesian [[multivariate normal distribution|multivariate Gaussian]] [[mixture model]] using plate notation.  Smaller squares indicate fixed parameters; larger circles indicate random variables.  Filled-in shapes indicate known values.  The indication [K] means a vector of size ''K''; [D,D] means a matrix of size ''D''&amp;times;''D''; K alone means a [[categorical variable]] with ''K'' outcomes.  The squiggly line coming from ''z'' ending in a crossbar indicates a ''switch'' — the value of this variable selects, for the other incoming variables, which value to use out of the size-''K'' array of possible values.]]

A number of extensions have been created by various authors to express more information than simply the conditional relationships.  However, few of these have become standard.  Perhaps the most commonly used extension is to use rectangles in place of circles to indicate non-random variables—either parameters to be computed, [[hyperparameter]]s given a fixed value (or computed through [[empirical Bayes]]), or variables whose values are computed deterministically from a random variable.

The diagram on the right shows a few more non-standard conventions used in some articles in Wikipedia (e.g. [[variational Bayes]]):
*Variables that are actually [[random vector]]s are indicated by putting the vector size in brackets in the middle of the node.
*Variables that are actually [[random matrices]] are similarly indicated by putting the matrix size in brackets in the middle of the node, with commas separating row size from column size.
*[[Categorical variable]]s are indicated by placing their size (without a bracket) in the middle of the node.
*Categorical variables that act as "switches", and which pick one or more other random variables to condition on from a large set of such variables (e.g. mixture components), are indicated with a special type of arrow containing a squiggly line and ending in a T junction.
*Boldface is consistently used for vector or matrix nodes (but not categorical nodes).

==Software implementation==
Plate notation has been implemented in various [[TeX]]/[[LaTeX]] drawing packages, but also as part of graphical user interfaces to Bayesian statistics programs such as [[Bayesian inference using Gibbs sampling|BUGS]] and [[BayesiaLab]].

==References==
&lt;references /&gt;

{{DEFAULTSORT:Plate Notation}}
[[Category:Graphical models]]
[[Category:Bayesian networks]]
[[Category:Mathematical notation]]</text>
      <sha1>9fh82meld2rwe259gxbzdvrt1k9tq1g</sha1>
    </revision>
  </page>
  <page>
    <title>Present value</title>
    <ns>0</ns>
    <id>63218</id>
    <revision>
      <id>857742364</id>
      <parentid>857593241</parentid>
      <timestamp>2018-09-02T18:42:17Z</timestamp>
      <contributor>
        <username>Malik Shabazz</username>
        <id>3020778</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/2405:204:70CD:5F73:EFF0:EF75:EC34:D0BE|2405:204:70CD:5F73:EFF0:EF75:EC34:D0BE]] ([[User talk:2405:204:70CD:5F73:EFF0:EF75:EC34:D0BE|talk]]): No Need For Capitalization. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23257">{{refimprove|date=March 2012}}
In [[economics]] and [[finance]], '''present value''' ('''PV'''), also known as '''present discounted value''', is the value of an expected income stream determined as of the date of valuation. The present value is always less than or equal to the future value because money has [[interest]]-earning potential, a characteristic referred to as the [[time value of money]], except during times of negative interest rates, when the present value will be more than the future value.&lt;ref name="Moyer"/&gt; Time value can be described with the simplified phrase, "A dollar today is worth more than a dollar tomorrow". Here, 'worth more' means that its value is greater. A dollar today is worth more than a dollar tomorrow because the dollar can be invested and earn a day's worth of interest, making the total accumulate to a value more than a dollar by tomorrow. Interest can be compared to rent.&lt;ref name="Broverman"/&gt; Just as rent is paid to a landlord by a tenant, without the ownership of the asset being transferred, interest is paid to a lender by a borrower who gains access to the money for a time before paying it back. By letting the borrower have access to the money, the lender has sacrificed the exchange value of this money, and is compensated for it in the form of interest. The initial amount of the borrowed funds (the present value) is less than the total amount of money paid to the lender.

Present value calculations, and similarly [[future value]] calculations, are used to value [[loans]], [[mortgages]], [[annuity (finance theory)|annuities]], [[sinking fund]]s, [[perpetuities]], [[Bond (finance)|bonds]], and more. These calculations are used to make comparisons between cash flows that don’t occur at simultaneous times,&lt;ref name="Moyer"/&gt; since time dates must be consistent in order to make comparisons between values. When deciding between projects in which to invest, the choice can be made by comparing respective present values of such projects by means of discounting the expected income streams at the corresponding project interest rate, or rate of return. The project with the highest present value, i.e. that is most valuable today, should be chosen.

==Years' purchase==
The traditional method of valuing future income streams as a present capital sum is to multiply the average expected annual cash-flow by a multiple, known as "years' purchase". For example, in selling to a third party a property leased to a tenant under a 99-year lease at a rent of $10,000 per annum, a deal might be struck at "20 years' purchase", which would value the lease at 20 * $10,000, i.e. $200,000. This equates to a present value discounted in perpetuity at 5%. For a riskier investment the purchaser would demand to pay a lower number of years' purchase. This was the method used for example by the English crown in setting re-sale prices for manors seized at the [[Dissolution of the Monasteries]] in the early 16th century. The standard usage was 20 years' purchase.&lt;ref&gt;Youings, Joyce, "Devon Monastic Lands: Calendar of Particulars for Grants 1536–1558", Devon &amp; Cornwall Record Society, ''New Series'', Vol.1, 1955&lt;/ref&gt;

==Background==
If offered a choice between $100 today or $100 in one year, and there is a positive real interest rate throughout the year, ''[[ceteris paribus]]'', a rational person will choose $100 today. This is described by economists as [[time preference]]. Time preference can be measured by auctioning off a risk free security—like a US Treasury bill. If a $100 note with a zero coupon, payable in one year, sells for $80 now, then $80 is the present value of the note that will be worth $100 a year from now. This is because money can be put in a bank account or any other (safe) investment that will return interest in the future.

An investor who has some money has two options: to spend it right now or to save it. But the financial compensation for saving it (and not spending it) is that the money value will accrue through the [[compound interest]] that he will receive from a borrower (the bank account on which he has the money deposited).

Therefore, to evaluate the real value of an amount of money today after a given period of time, economic agents compound the amount of money at a given (interest) rate. Most actuarial calculations use the [[risk-free interest rate]] which corresponds to the minimum guaranteed rate provided by a bank's saving account for example, assuming no risk of default by the bank to return the money to the account holder on time. To compare the change in purchasing power, the [[real interest rate]] ([[nominal interest rate]] minus [[inflation]] rate) should be used.

The operation of evaluating a present value into the [[future value]] is called a capitalization (how much will $100 today be worth in 5 years?). The reverse operation—evaluating the present value of a future amount of money—is called a discounting (how much will $100 received in 5 years—at a lottery for example—be worth today?).

It follows that if one has to choose between receiving $100 today and $100 in one year, the rational decision is to choose the $100 today. If the money is to be received in one year and assuming the savings account interest rate is 5%, the person has to be offered at least $105 in one year so that the two options are equivalent (either receiving $100 today or receiving $105 in one year). This is because if $100 is deposited in a savings account, the value will be $105 after one year, again assuming no risk of losing the initial amount through bank default.

==Interest rates==
Interest is the additional amount of money gained between the beginning and the end of a time period. Interest represents the [[time value of money]], and can be thought of as rent that is required of a borrower in order to use money from a lender.&lt;ref name=Broverman/&gt;&lt;ref name=Ross/&gt; For example, when an individual takes out a bank loan, they are charged interest. Alternatively, when an individual deposits money into a bank, their money earns interest. In this case, the bank is the borrower of the funds and is responsible for crediting interest to the account holder. Similarly, when an individual invests in a company (through [[corporate bond]]s, or through [[stock]]), the company is borrowing funds, and must pay interest to the individual (in the form of coupon payments, [[dividend]]s, or stock price appreciation).&lt;ref name=Moyer/&gt;
The interest rate is the change, expressed as a percentage, in the amount of money during one compounding period. A compounding period is the length of time that must transpire before interest is credited, or added to the total.&lt;ref name=Broverman/&gt; For example, interest that is compounded annually is credited once a year, and the compounding period is one year. Interest that is compounded quarterly is credited four times a year, and the compounding period is three months. A compounding period can be any length of time, but some common periods are annually, semiannually, quarterly, monthly, daily, and even continuously.

There are several types and terms associated with [[interest]] rates:
*[[Compound interest]], interest that increases exponentially over subsequent periods,
*[[Simple interest]], additive interest that does not increase
*[[Effective interest rate]], the effective equivalent compared to multiple compound interest periods
*[[Nominal annual interest]], the simple annual interest rate of multiple interest periods
*[[Discount window|Discount rate]], an inverse interest rate when performing calculations in reverse
*[[Continuously compounded interest]], the [[mathematical limit]] of an interest rate with a period of zero time.
*[[Real interest rate]], which accounts for inflation.

==Calculation==
The operation of evaluating a present sum of money some time in the future is called a capitalization (how much will 100 today be worth in 5 years?). The reverse operation—evaluating the present value of a future amount of money—is called discounting (how much will 100 received in 5 years be worth today?).&lt;ref name=Ross&gt;{{cite book|last=Ross|first=Stephen|title=Fundamentals of Corporate Finance|year=2010|publisher=McGraw-Hill|location=New York|isbn=9780077246129|pages=145–287|edition=9|author2=Randolph W. Westerfield |author3=Bradford D. Jordan }}&lt;/ref&gt;

Spreadsheets commonly offer functions to compute present value. In Microsoft Excel, there are present value functions for single payments - "=NPV(...)", and series of equal, periodic payments - "=PV(...)". Programs will calculate present value flexibly for any cash flow and interest rate, or for a schedule of different interest rates at different times.

===Present value of a lump sum===
The most commonly applied model of present valuation uses [[compound interest]]. The standard formula is:

:&lt;math&gt;PV = \frac{C}{(1+i)^n} \,&lt;/math&gt;

Where &lt;math&gt;\,C\,&lt;/math&gt; is the future amount of money that must be discounted, &lt;math&gt;\,n\,&lt;/math&gt; is the number of compounding periods between the present date and the date where the sum is worth &lt;math&gt;\,C\,&lt;/math&gt;, &lt;math&gt;\,i\,&lt;/math&gt; is the interest rate for one compounding period (the end of a compounding period is when interest is applied, for example, annually, semiannually, quarterly, monthly, daily). The interest rate, &lt;math&gt;\,i\,&lt;/math&gt;, is given as a percentage, but expressed as a decimal in this formula.

Often, &lt;math&gt;v^{n} = \,(1 + i)^{-n}&lt;/math&gt; is referred to as the Present Value Factor &lt;ref name=Broverman&gt;{{cite book|last=Broverman|first=Samuel|title=Mathematics of Investment and Credit|year=2010|publisher=ACTEX Publishers|location=Winsted|isbn=9781566987677|pages=4–229}}&lt;/ref&gt;

This is also found from the [[Future value#Compound interest|formula for the future value]] with negative time.

For example, if you are to receive $1000 in 5 years, and the effective annual interest rate during this period is 10% (or 0.10), then the present value of this amount is

:&lt;math&gt;PV = \frac{\$1000}{(1+0.10)^{5}} = \$620.92 \, &lt;/math&gt;

The interpretation is that for an effective annual interest rate of 10%, an individual would be indifferent to receiving $1000 in 5 years, or $620.92 today.&lt;ref name="Moyer"/&gt;

The [[purchasing power]] in today's money of an amount &lt;math&gt;\,C\,&lt;/math&gt; of money, &lt;math&gt;\,n\,&lt;/math&gt; years into the future, can be computed with the same formula, where in this case &lt;math&gt;\,i\,&lt;/math&gt; is an assumed future [[inflation rate]].

===Net present value of a stream of cash flows===
A cash flow is an amount of money that is either paid out or received, differentiated by a negative or positive sign, at the end of a period. Conventionally, cash flows that are received are denoted with a positive sign (total cash has increased) and cash flows that are paid out are denoted with a negative sign (total cash has decreased). The cash flow for a period represents the net change in money of that period.&lt;ref name=Ross/&gt; Calculating the net present value, &lt;math&gt;\,NPV\,&lt;/math&gt;, of a stream of cash flows consists of discounting each cash flow to the present, using the present value factor and the appropriate number of compounding periods, and combining these values.&lt;ref name=Moyer&gt;{{cite book|last=Moyer|first=Charles|title=Contemporary Financial Management|year=2011|publisher=South-Western Publishing Co|location=Winsted|isbn=9780538479172|pages=147–498|edition=12|author2=William Kretlow |author3=James McGuigan }}&lt;/ref&gt;

For example, if a stream of cash flows consists of +$100 at the end of period one, -$50 at the end of period two, and +$35 at the end of period three, and the interest rate per compounding period is 5% (0.05) then the present value of these three Cash Flows are

:&lt;math&gt;PV_{1} = \frac{\$100}{(1.05)^{1}} = \$95.24 \, &lt;/math&gt;
:&lt;math&gt;PV_{2} = \frac{-\$50}{(1.05)^{2}} = -\$45.35 \, &lt;/math&gt;
:&lt;math&gt;PV_{3} = \frac{\$35}{(1.05)^{3}} = \$30.23 \, &lt;/math&gt;    respectively

Thus the net present value would be

:&lt;math&gt;NPV = PV_{1}+PV_{2}+PV_{3} = \frac{100}{(1.05)^{1}} + \frac{-50}{(1.05)^{2}} + \frac{35}{(1.05)^{3}} = 95.24 - 45.35 + 30.23 = 80.12, &lt;/math&gt;

There are a few considerations to be made.
* The periods might not be consecutive. If this is the case, the exponents will change to reflect the appropriate number of periods
* The interest rates per period might not be the same. The cash flow must be discounted using the interest rate for the appropriate period: if the interest rate changes, the sum must be discounted to the period where the change occurs using the second interest rate, then discounted back to the present using the first interest rate.&lt;ref name="Broverman" /&gt; For example, if the cash flow for period one is $100, and $200 for period two, and the interest rate for the first period is 5%, and 10% for the second, then the net present value would be:

:&lt;math&gt;NPV = 100\,(1.05)^{-1} + 200\,(1.10)^{-1}\,(1.05)^{-1} = \frac{100}{(1.05)^{1}} + \frac{200}{(1.10)^{1}(1.05)^{1}} = \$95.24 + \$173.16 = \$268.40 &lt;/math&gt;
* The interest rate must necessarily coincide with the payment period. If not, either the payment period or the interest rate must be modified. For example, if the interest rate given is the effective annual interest rate, but cash flows are received (and/or paid) quarterly, the interest rate per quarter must be computed. This can be done by converting effective annual interest rate, &lt;math&gt;\, i \, &lt;/math&gt;, to nominal annual interest rate compounded quarterly:
:&lt;math&gt; (1+i) = \left(1+\frac{i^{4}}{4}\right)^4 &lt;/math&gt;&lt;ref name="Broverman"/&gt;

Here, &lt;math&gt; i^{4} &lt;/math&gt; is the nominal annual interest rate, compounded quarterly, and the interest rate per quarter is &lt;math&gt;\frac{i^{4}}{4}&lt;/math&gt;

====Present value of an annuity====
{{See also|Annuity#Valuation}}
Many financial arrangements (including bonds, other loans, leases, salaries, membership dues, annuities including annuity-immediate and annuity-due, straight-line depreciation charges) stipulate structured payment schedules; payments of the same amount at regular time intervals. Such an arrangement is called an [[annuity]]. The expressions for the present value of such payments are [[summation]]s of [[geometric series]].

There are two types of annuities: an annuity-immediate and annuity-due. For an annuity immediate, &lt;math&gt;\, n \, &lt;/math&gt; payments are received (or paid) at the end of each period, at times 1 through &lt;math&gt;\, n \, &lt;/math&gt;, while for an annuity due, &lt;math&gt;\, n \, &lt;/math&gt; payments are received (or paid) at the beginning of each period, at times 0 through &lt;math&gt;\, n-1 \, &lt;/math&gt;.&lt;ref name="Ross"/&gt; This subtle difference must be accounted for when calculating the present value.

An annuity due is an annuity immediate with one more interest-earning period. Thus, the two present values differ by a factor of &lt;math&gt;(1+i)&lt;/math&gt;:

:&lt;math&gt; PV_\text{annuity due} = PV_\text{annuity immediate}(1+i) \,\!&lt;/math&gt;&lt;ref name="Broverman"/&gt;

The present value of an annuity immediate is the value at time 0 of the stream of cash flows:

:&lt;math&gt;PV = \sum_{k=1}^{n} \frac{C}{(1+i)^{k}} = C\left[\frac{1-(1+i)^{-n}}{i}\right], \qquad (1) &lt;/math&gt;

where:

:&lt;math&gt;\, n \, &lt;/math&gt; = number of periods,

:&lt;math&gt;\, C \, &lt;/math&gt; = amount of cash flows,

:&lt;math&gt;\, i \, &lt;/math&gt; = effective periodic interest rate or rate of return.

====An approximation  for annuity and loan calculations====
The above formula (1) for annuity immediate calculations offers little insight for the average user and requires the use of some form of computing machinery. There is an approximation which is less intimidating, easier to compute and offers some insight for the non-specialist. It is given by &lt;ref&gt;Swingler, D. N., (2014), "A Rule of Thumb approximation for  time value of money calculations", ''Journal of Personal Finance'', Vol. 13,Issue 2, pp.57-61&lt;/ref&gt;
:: &lt;math&gt;C \approx  PV \left( \frac {1}{n} + \frac {2}{3} i \right) &lt;/math&gt;
Where, as above, C is annuity payment, PV is principal, n is number of payments, starting at end of first period, and i is interest rate per period. Equivalently  C  is the periodic  loan repayment for a loan of PV extending over n periods at interest rate,  i. The formula is valid (for positive n, i) for ni≤3. For completeness, for ni≥3 the approximation is &lt;math&gt; C \approx PV  i&lt;/math&gt;.

The formula can, under some circumstances, reduce the calculation to one of mental arithmetic alone. For example, what are the (approximate) loan repayments for a loan of PV= $10,000 repaid annually for n= 10 years at 15% interest (i=0.15)?  The applicable approximate  formula is  C ≈10,000*(1/10 + (2/3) 0.15) =10,000*(0.1+0.1) =10,000*0.2 =$2000 pa by mental arithmetic alone. The true answer is $1993, very close.

The overall approximation is accurate to within ±6% (for all n≥1)  for interest rates 0≤ i≤0.20 and within ±10% for interest rates 0.20≤i≤0.40. It is, however,  intended only for "rough" calculations.

====Present value of a perpetuity====
A [[perpetuity]] refers to periodic payments, receivable indefinitely, although few such instruments exist. The present value of a perpetuity can be calculated by taking the limit of the above formula as ''n'' approaches infinity.

:&lt;math&gt;PV\,=\,\frac{C}{i}. \qquad (2)&lt;/math&gt;

Formula (2) can also be found by subtracting from (1) the present value of a perpetuity delayed n periods, or directly by summing the present value of the payments

:&lt;math&gt;PV = \sum_{k=1}^\infty \frac{C}{(1+i)^{k}} = \frac{C}{i}, \qquad i &gt; 0,&lt;/math&gt;

which form a [[geometric series]].

Again there is a distinction between a perpetuity immediate – when payments received at the end of the period – and a perpetuity due – payment received at the beginning of a period. And similarly to annuity calculations, a perpetuity due and a perpetuity immediate differ by a factor of &lt;math&gt;(1+i) &lt;/math&gt;:

:&lt;math&gt; PV_\text{perpetuity due} = PV_\text{perpetuity immediate}(1+i) \,\!&lt;/math&gt;&lt;ref name="Broverman"/&gt;

====PV of a bond====
A corporation issues a [[Bond (finance)|bond]], an interest earning debt security, to an investor to raise funds.&lt;ref name=Ross/&gt; The bond has a face value, &lt;math&gt; F &lt;/math&gt;, coupon rate, &lt;math&gt; r &lt;/math&gt;, and maturity date which in turn yields the number of periods until the debt matures and must be repaid. A bondholder will receive coupon payments semiannually (unless otherwise specified) in the amount of &lt;math&gt; Fr &lt;/math&gt;, until the bond matures, at which point the bondholder will receive the final coupon payment and the face value of a bond, &lt;math&gt; F(1+r) &lt;/math&gt;. The present value of a bond is the purchase price.&lt;ref name="Broverman"/&gt; The purchase price is equal to the bond's face value if the coupon rate is equal to the current interest rate of the market, and in this case, the bond is said to be sold 'at par'. If the coupon rate is less than the market interest rate, the purchase price will be less than the bond's face value, and the bond is said to have been sold 'at a discount', or below par. Finally, if the coupon rate is greater than the market interest rate, the purchase price will be greater than the bond's face value, and the bond is said to have been sold 'at a premium', or above par.&lt;ref name="Ross"/&gt; The purchase price can be computed as:

:&lt;math&gt;PV = \left[\sum_{k=1}^{n} Fr(1+i)^{-k}\right]&lt;/math&gt; &lt;math&gt; + F(1+i)^{-n} &lt;/math&gt;

====Technical details====
Present value is [[Additive inverse|additive]]. The present value of a bundle of [[cash flow]]s is the sum of each one's present value.

In fact, the present value of a cashflow at a constant interest rate is mathematically one point in the [[Laplace transform]] of that cashflow, evaluated with the transform variable (usually denoted "s") equal to the interest rate.  The full Laplace transform is the curve of all present values, plotted as a function of interest rate. For discrete time, where payments are separated by large time periods, the transform reduces to a sum, but when payments are ongoing on an almost continual basis, the mathematics of continuous functions can be used as an approximation.

These calculations must be applied carefully, as there are underlying assumptions:
* That it is not necessary to account for price [[inflation]], or alternatively, that the cost of inflation is incorporated into the interest rate.
* That the likelihood of receiving the payments is high—or, alternatively, that the [[default risk]] is incorporated into the interest rate.

See [[time value of money]] for further discussion.

===Variants/approaches===
There are mainly two flavors of Present Value. Whenever there will be uncertainties in both timing and amount of the cash flows, the expected present value approach will often be the appropriate technique. 
* '''Traditional Present Value Approach''' – in this approach a single set of estimated cash flows and a single interest rate (commensurate with the risk, typically a weighted average of cost components) will be used to estimate the fair value.
* '''Expected Present Value Approach''' – in this approach multiple cash flows scenarios with different/expected probabilities and a credit-adjusted risk free rate are used to estimate the fair value.

===Choice of interest rate===
The interest rate used is the [[risk-free interest rate]] if there are no risks involved in the project. The rate of return from the project must equal or exceed this rate of return or it would be better to invest the capital in these risk free assets. If there are risks involved in an investment this can be reflected through the use of a [[risk premium]]. The risk premium required can be found by comparing the project with the rate of return required from other projects with similar risks. Thus it is possible for investors to take account of any uncertainty involved in various investments.

==Present value method of valuation==
An investor, the lender of money, must decide the financial project in which to invest their money, and present value offers one method of deciding.&lt;ref name=Moyer/&gt;
A financial project requires an initial outlay of money, such as the price of stock or the price of a corporate bond. The project claims to return the initial outlay, as well as some surplus (for example, interest, or future cash flows). An investor can decide which project to invest in by calculating each projects’ present value (using the same interest rate for each calculation) and then comparing them. The project with the smallest present value – the least initial outlay – will be chosen because it offers the same return as the other projects for the least amount of money.&lt;ref name=Broverman/&gt;

==See also==
* [[Capital budgeting]]
* [[Lifetime value]]
* [[Liquidation]]
* [[Net present value]]

==References==
{{reflist}}

==Further reading==
* {{cite encyclopedia |last1=Henderson |first1=David R.|authorlink1=David R. Henderson  |encyclopedia=[[Concise Encyclopedia of Economics]] |title=Present Value |url=http://www.econlib.org/library/Enc/PresentValue.html |year=2008 |edition= 2nd |publisher=[[Library of Economics and Liberty]] |location=Indianapolis |isbn=978-0865976658 |oclc=237794267}}

{{DEFAULTSORT:Present Value}}
[[Category:Income]]
[[Category:Mathematical finance]]

[[fr:Valeur actuelle]]</text>
      <sha1>893vqu6bkkikvstdnr0vja3n5611vnz</sha1>
    </revision>
  </page>
  <page>
    <title>Publicationes Mathematicae Debrecen</title>
    <ns>0</ns>
    <id>22963939</id>
    <revision>
      <id>852501427</id>
      <parentid>506278100</parentid>
      <timestamp>2018-07-29T12:15:18Z</timestamp>
      <contributor>
        <username>Tudor987</username>
        <id>19636086</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="568">'''''Publicationes Mathematicae Debrecen''''' is a Hungarian mathematical journal, edited and published in [[Debrecen]], at the Mathematical Institute of the [[University of Debrecen]]. It was founded by [[Alfréd Rényi]], [[Tibor Szele]], and [[Ottó Varga]] in 1950. The current editor-in-chief is [[Lajos Tamássy]].

==External links==
* The journal's [http://www.math.klte.hu/publi/index.php?p=1 homepage]
* [http://www.math.klte.hu/publi/contents.php On-line papers]

[[Category:Mathematics journals]]
[[Category:University of Debrecen]]


{{math-journal-stub}}</text>
      <sha1>3cz9snua0k7qhpsegd214jrdnln6e20</sha1>
    </revision>
  </page>
  <page>
    <title>Rational trigonometry</title>
    <ns>0</ns>
    <id>2696396</id>
    <revision>
      <id>870703381</id>
      <parentid>870702266</parentid>
      <timestamp>2018-11-26T14:34:18Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/207.206.238.18|207.206.238.18]] ([[User talk:207.206.238.18|talk]]) to last revision by Michael Hardy. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="43126">'''Rational trigonometry''' is a proposed reformulation of [[metric space|metrical]] [[plane geometry|planar]] and [[solid geometry|solid geometries]] (which includes [[trigonometry]]) by Canadian mathematician Norman J. Wildberger, currently a professor of mathematics at the [[University of New South Wales]]. His ideas are set out in his 2005 book ''Divine Proportions: Rational Trigonometry to Universal Geometry''.&lt;ref name="Wildberger_2005"&gt;{{cite book |first=Norman John |last=Wildberger |author-link=Norman John Wildberger |title=Divine Proportions: Rational Trigonometry to Universal Geometry |publisher=Wild Egg Pty Ltd |location=Australia |date=2005 |edition=1 |isbn=0-9757492-0-X |url=https://www.researchgate.net/publication/266738365_Divine_Proportions_Rational_Trigonometry_to_Universal_geometry |access-date=2015-12-01}}&lt;/ref&gt; According to ''[[New Scientist]]'', part of his motivation for an alternative to traditional trigonometry was to avoid some problems that he claims occur when infinite series are used in mathematics.  Rational trigonometry avoids direct use of [[transcendental function]]s like [[sine]] and [[cosine]] by substituting their squared equivalents.&lt;ref name="Gefter1"&gt;"[https://www.newscientist.com/article/mg21929300-700-infinitys-end-time-to-ditch-the-never-ending-story/ Infinity's end: Time to ditch the never-ending story?]" by Amanda Gefter, New Scientist, 15 August 2013&lt;/ref&gt; Wildberger draws inspiration from mathematicians predating [[Georg Cantor]]'s [[Georg Cantor#Set theory|infinite set-theory]], like [[Gauss]] and [[Euclid]], who he claims were far more wary of using infinite sets than modern mathematicians.&lt;ref name="Gefter1"/&gt;&lt;ref group="nb"&gt;For Wildberger's views on the history of infinity, see the Gefter New Scientist article, but also see Wildberger's History of Mathematics and Math Foundations lectures, University of New South Wales, circa 2009–2014 in more than 120 videos and lectures, available online @youtube&lt;/ref&gt; To date, rational trigonometry is largely unmentioned in mainstream mathematical literature.

==Approach==
Rational trigonometry follows an approach built on the methods of [[linear algebra]] to the topics of elementary (high school level) geometry. [[Distance]] is replaced with its squared value ('''quadrance''') and '[[angle]]' is replaced with the squared value of the usual [[sine]] ratio ('''spread''') associated to either angle between two lines. (The [[Angle#complementary_angle|complement]] of Spread, known as '''cross''', also corresponds to a scaled form of the [[inner product]] between line segments taken as [[vector (geometric)|vector]]s). The three main laws in trigonometry – [[Pythagoras's theorem]], the [[sine law]] and the [[cosine law]] – are given in rational (square-equivalent) form, and are augmented by two further laws – the [[#Triple quad formula|triple quad formula]] (relating the quadrances of three collinear points) and the [[#Triple spread formula|triple spread formula]] (relating the spreads of three concurrent lines) –, giving the [[#Laws of rational trigonometry|five main laws]] of the subject.{{citation needed|date=November 2013}}

Rational trigonometry is otherwise broadly based on Cartesian analytic geometry, with ''a point'' defined as an ordered pair of [[rational number]]s
:&lt;math&gt;(x,y)&lt;/math&gt;

and ''a line'' 
:&lt;math&gt;ax + by + c = 0,&lt;/math&gt;

as a general [[linear equation]] with rational coefficients {{mvar|a}}, {{mvar|b}} and {{mvar|c}}.

By avoiding calculations that rely on [[square root]] operations giving only ''approximate'' distances between points, or standard trigonometric functions (and their inverses), giving only truncated [[polynomial]] ''approximations'' of angles (or their projections) geometry becomes entirely algebraic. There is no assumption, in other words, of the existence of [[real number]] solutions to problems, with results instead given over the field of rational numbers, their [[algebraic field extension]]s, or [[finite field]]s. Following this, it is claimed, makes many [[Mathematical theorem|classical results]] of [[Euclidean geometry]] applicable in ''rational'' form (as quadratic analogs) over any field not of [[Characteristic (algebra)|characteristic]] two.{{citation needed|date=November 2013}}

The book ''Divine Proportions'' shows the application of calculus using rational trigonometric functions, including three-dimensional volume calculations. It also deals with rational trigonometry's application to situations involving irrationals, such as the proof that Platonic Solids all have rational 'spreads' between their faces.&lt;ref group="nb"&gt;See ''Divine Proportions'' for numerous examples of calculus done with rational trigonometric functions, as well as problems involving the application of rational trigonometry to situations containing irrationals.&lt;/ref&gt;

==Notability and criticism==
Rational trigonometry (''RT'') is mentioned in only a modest number of mathematical publications besides Wildberger's own articles and book. ''Divine Proportions'' was dismissed by reviewer Paul J. Campbell, in the ''[[Mathematics Magazine]]'' of the [[Mathematical Association of America]] (MAA): "the author claims that this new theory will take 'less than half the usual time to learn'; but I doubt it. and it would still have to be interfaced with the traditional concepts and notation." Reviewer William Barker, Isaac Henry Wing Professor of Mathematics at [[Bowdoin College]], also writing for the MAA, was more approving: "''Divine Proportions'' is unquestionably a valuable addition to the mathematics literature. It carefully develops a thought provoking, clever, and useful alternate approach to trigonometry and Euclidean geometry. It would not be surprising if some of its methods ultimately seep into the standard development of these subjects. However, unless there is an unexpected shift in the accepted views of the foundations of mathematics, there is not a strong case for rational trigonometry to replace the classical theory" &lt;ref&gt;http://www.maa.org/publications/maa-reviews/divine-proportions-rational-trigonometry-to-universal-geometry&lt;/ref&gt; ''[[New Scientist]]'''s Amanda Gefter described the approach of Wildberger as an example of [[finitism]].&lt;ref name="Gefter1"/&gt; [[James Franklin (philosopher)|James Franklin]] in the ''[[Mathematical Intelligencer]]'' argued that the book deserved careful consideration.&lt;ref&gt;J. Franklin, [http://web.maths.unsw.edu.au/~jim/wildbergerrev.pdf Review of ''Divine Proportions''], ''Mathematical Intelligencer'' 28 (3) (2006), 73-4.&lt;/ref&gt;

An analysis by Michael Gilsdorf of the example problems given by Wildberger in an early paper disputed the claim that ''RT'' required fewer steps to solve ''most'' problems, if free selection of classical methods (such as the '[[shoelace formula]]' for the area of a triangle from the coordinates of its vertices or applying a [[Apollonius's theorem|special case of Stewart's theorem]] directly to a triangle with a median) is allowed to optimize the solution of problems. Concerning pedagogy, and whether using the quadratic quantities introduced by ''RT'' offers real benefits over traditional learning, the author observed that classical trigonometry was not initially based on use of [[Taylor series]] to approximate angles at all, but rather on measurements of [[chord (trigonometry)|chord]] (twice the sine of an angle) and thus with a proper understanding students could reap continued advantages from use of linear measurement without the claimed ''logical'' inconsistencies when circular parametrization by angle is subsequently introduced.&lt;ref name="web.maths.unsw.edu.au"&gt;http://web.maths.unsw.edu.au/~norman/papers/TrigComparison.pdf&lt;/ref&gt;

==Quadrance==
&lt;!-- Linked to from redirects and from inside this article --&gt;
Quadrance and distance (as its square root) both measure separation of points in Euclidean space.&lt;ref name="Horizons"/&gt; Following Pythagoras's theorem, the quadrance of two points {{math|''A''&lt;sub&gt;1&lt;/sub&gt; {{=}} (''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;)}} and {{math|''A''&lt;sub&gt;2&lt;/sub&gt; {{=}} (''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}} in a plane is therefore defined as the sum of squares of differences in the &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; coordinates:

: &lt;math&gt;Q(A_1, A_2) = (x_2 - x_1)^2 + (y_2 - y_1)^2.&lt;/math&gt;

The [[triangle inequality]] &lt;math&gt; d_3 \leq d_1 + d_2 &lt;/math&gt; is expressed under rational trigonometry as &lt;math&gt; (Q_3 - Q_1 - Q_2)^2 \leq 4 Q_1 Q_2 &lt;/math&gt;.

==Spread==
&lt;!-- Linked to from redirects --&gt;
[[Image:Spread as ratio.svg|thumb|left|Suppose {{math|''l''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''l''&lt;sub&gt;2&lt;/sub&gt;}} intersect at the point {{mvar|A}}. Let {{mvar|C}} be the foot of the perpendicular from {{mvar|B}} to {{math|''l''&lt;sub&gt;2&lt;/sub&gt;}}. Then the spread is {{math|''s'' {{=}} {{sfrac|''Q''|''R''}}}}.]]

[[Image:Spread_(sin%5E2(theta))_measured_for_a_unit_circle_4.0.svg|right|]]

Spread gives one measure to the separation of two lines as a single [[dimensionless number]] in the range {{math|[0,1]}} (from ''parallel'' to ''perpendicular'') for Euclidean geometry. It replaces the concept of (and has several differences from) angle discussed in the section below. Descriptions of spread may include:
 
*'''Trigonometric''' (most elementary): the ''sine ratio'' of quadrances in a right triangle, equivalent to the square of the sine of the angle (''left'').&lt;ref name="Horizons"/&gt; By extending adjacent side {{mvar|AC}} to form part of the ''unit'' diameter in a circle and considering similar triangles (''right''), spread may be measured as the ''length'' (or ''ratio'' to diameter) of the exterior segment - more tradtionally equal to one half times (1 minus the [[cosine]] of [[central angle|twice the angle at {{mvar|A}}]]) or [[haversine]].

*'''Vector''': as a rational function of the ''slopes'' (and ''relative'' ''direction)'' of a pair of lines where they meet.

*'''Cartesian''': as a rational function of ''three'' co-ordinates used to ascribe ''two'' vectors.

*'''Linear algebra''' (from the ''dot product''): a normalized rational function: the ''square of'' the [[determinant]] of two vectors (or pair of intersecting lines) forming a [[Matrix (mathematics)|matrix]] divided by the product of their ''quadrances''.

===Calculating spread===
==== Trigonometric ====
Suppose two lines, {{math|''l''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''l''&lt;sub&gt;2&lt;/sub&gt;}}, intersect at the point {{mvar|A}} as shown at right. Choose a point {{math|''B'' ≠ ''A''}} on {{math|''l''&lt;sub&gt;1&lt;/sub&gt;}} and let {{mvar|C}} be the foot of the perpendicular from {{mvar|B}} to {{math|''l''&lt;sub&gt;2&lt;/sub&gt;}}. Then the spread {{mvar|s}} is&lt;ref name="Horizons"/&gt;

: &lt;math&gt;s(\ell_1, \ell_2) = \frac{Q(B, C)}{Q(A, B)} = \frac{Q}{R}.&lt;/math&gt;

==== Vector/slope (two-variable) ====
Like angle, spread depends only on the relative slopes of two lines (constant terms being eliminated) and is invariant under translation (i.e. it is preserved when lines are moved keeping parallel with themselves). So given two lines whose equations are

:&lt;math&gt;a_1x + b_1y= \text{constant} \qquad \text{and} \qquad a_2x + b_2y= \text{constant}&lt;/math&gt;

we may rewrite them as two lines which meet at the origin {{math|(0, 0)}} with equations

:&lt;math&gt;a_1x + b_1y= 0 \qquad \text{and} \qquad a_2x + b_2y= 0&lt;/math&gt;

In this position the point {{math|(−''b''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;1&lt;/sub&gt;)}} satisfies the first equation and {{math|(−''b''&lt;sub&gt;2&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;)}} satisfies the second and the three points {{math|(0, 0)}}, {{math|(−''b''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;1&lt;/sub&gt;)}} and {{math|(−''b''&lt;sub&gt;2&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;)}} forming the spread will give three quadrances:

:&lt;math&gt;\begin{align}
Q_1&amp;=\left(b_1^2+a_1^2\right),\\
Q_2&amp;=\left(b_2^2+a_2^2\right),\\
Q_3&amp;=\left(b_1-b_2\right)^2+\left(a_1-a_2\right)^2
\end{align}&lt;/math&gt;

The ''cross law'' – see below – in terms of spread is

:&lt;math&gt;1-s = \frac{(Q_1+Q_2-Q_3)^2}{4Q_1Q_2}.&lt;/math&gt;

which becomes:

:&lt;math&gt;1-s=\frac{\left(a_1^2+a_2^2+b_1^2+b_2^2-(b_1-b_2)^2-(a_1-a_2)^2\right)^2}{4\left(a_1^2+b_1^2\right)\left(a_2^2+b_2^2\right)}.&lt;/math&gt;

This simplifies, in the numerator, to {{math|(2''a''&lt;sub&gt;1&lt;/sub&gt;''a''&lt;sub&gt;2&lt;/sub&gt; + 2''b''&lt;sub&gt;1&lt;/sub&gt;''b''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}}, giving:

:&lt;math&gt;1-s=\frac{\left(a_1a_2+b_1b_2\right)^2}{\left(a_1^2+b_1^2\right)\left(a_2^2+b_2^2\right)}.&lt;/math&gt;

(Note: {{math|1 − ''s''}}  is the expression for the '''cross''', the square of the cosine of either angle between a pair of lines or vectors, that gives its name to the ''cross law''.)

Then, using the [[Brahmagupta–Fibonacci identity]]

: &lt;math&gt;\left(a_2b_1-a_1b_2\right)^2+\left(a_1a_2+b_1b_2\right)^2=\left(a_1^2+b_1^2\right)\left(a_2^2+b_2^2\right),&lt;/math&gt;

the standard expression for spread in terms of slopes (or directions) of two lines becomes

: &lt;math&gt;s = \frac{\left(a_1 b_2 - a_2 b_1\right)^2}{\left(a_1^2 + b_1^2\right)\left(a_2^2 + b_2^2\right)}.&lt;/math&gt;

In this form (and in its Cartesian equivalent that follows) a spread is the ratio of the square of a determinant of two vectors (numerator) to the product of their quadrances (denominator)

==== Cartesian (three-variable) ====
This replaces {{math|(−''b''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;1&lt;/sub&gt;)}} with {{math|(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;)}}, {{math|(−''b''&lt;sub&gt;2&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;)}} with {{math|(''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}} and the origin {{math|(0, 0)}}, as the point of intersection of two lines, with {{math|(''x''&lt;sub&gt;3&lt;/sub&gt;, ''y''&lt;sub&gt;3&lt;/sub&gt;)}} in the previous result:

: &lt;math&gt;s = \frac{\bigl((y_1 - y_3) (x_2 - x_3) - (y_2 - y_3) (x_1 - x_3)\bigr)^2}{\bigl((y_1 - y_3)^2 + (x_1 - x_3)^2\bigr)\bigl((y_2 - y_3)^2 + (x_2 - x_3)^2\bigr)}.&lt;/math&gt;

=== Spread compared to angle ===
[[Image:Spread between two lines.svg|thumb|right|The spread of two lines can be measured in four equivalent positions.]]
Unlike angle, which can define a relationship between ''rays'' emanating from a point, by an  [[Angle#Measuring angles| arc measurement]] parametrization, and where a pair of lines can be considered four pairs of rays, forming four angles, 'spread' is more fundamental in rational trigonometry, describing ''two lines'' by a single measure of a rational function (see above).&lt;ref name="Horizons"/&gt; Being equivalent to the ''square'' of a [[sine]] of the corresponding angle {{mvar|θ}} (and to the [[haversine]] of the [[chord (trigonometry)|chord]]-based double-angle {{math|Δ {{=}} 2''θ''}}), the spread of both an angle and its [[supplementary angle]] are equal.

{|class = wikitable style="text-align:center;"
|-
! Spread !! colspan="5"|[[Angle]] ({{mvar|θ}}) || Quantity
|-
! {{math|sin&lt;sup&gt;2&lt;/sup&gt;(''θ'')}} !! [[Quadrant (circle)|Quadrants]] !! [[Turn (angle)|Turns]] !! [[Radians]] !! [[Degree (angle)|Degrees]] !! [[Gon (angle)|Gons]] !! Unit
|-
| '''0''' || 0 || 0 || 0 || 0° || 0&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''{{sfrac|1|4}}''' || {{sfrac|1|3}} || {{sfrac|1|12}} || {{sfrac|{{pi}}|6}} || 30° || {{sfrac|33|1|3}}&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''{{sfrac|1|2}}''' || {{sfrac|1|2}} || {{sfrac|1|8}} || {{sfrac|{{pi}}|4}} || 45° || 50&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''{{sfrac|3|4}}''' || {{sfrac|2|3}} || {{sfrac|1|6}} || {{sfrac|{{pi}}|3}} || 60° || {{sfrac|66|2|3}}&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''1''' || 1 || {{sfrac|1|4}} || {{sfrac|{{pi}}|2}} || 90° || 100&lt;sup&gt;g&lt;/sup&gt; || orthogonal lines
|-
| '''{{sfrac|3|4}}''' || {{sfrac|1|1|3}} || {{sfrac|1|3}} || {{sfrac|2{{pi}}|3}} || 120° || {{sfrac|133|1|3}}&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''{{sfrac|1|2}}''' || {{sfrac|1|1|2}} || {{sfrac|3|8}} || {{sfrac|3{{pi}}|4}} || 135° || 150&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''{{sfrac|1|4}}''' || {{sfrac|1|2|3}} || {{sfrac|5|12}} || {{sfrac|5{{pi}}|6}} || 150° || {{sfrac|166|2|3}}&lt;sup&gt;g&lt;/sup&gt; || 
|-
| '''0''' || 2 || {{sfrac|1|2}} || {{pi}} || 180° || 200&lt;sup&gt;g&lt;/sup&gt; || 
|}

Spread is not proportional, however, to the separation between lines as angle would be; with spreads of 0, {{sfrac|1|4}}, {{sfrac|1|2}}, {{sfrac|3|4}}, and 1 corresponding to unevenly spaced angles 0°, 30°, 45°, 60° and 90°.

Instead, (recalling the supplementary property) two equal, co-terminal spreads determine a third spread, whose value will be a solution of the triple spread formula for a triangle (or three concurrent lines) having spreads of {{mvar|s}}, {{mvar|s}} and {{mvar|r}}:

:&lt;math&gt;\begin{align}
(2s + r)^2 &amp;= 2\left(2s^2 + r^2\right) + 4s^2r\\
4s^2 + 4sr + r^2 &amp;= 4s^2 + 2r^2 + 4s^2r
\end{align}&lt;/math&gt;

giving the quadratic polynomial (in {{mvar|s}}):

:&lt;math&gt;\begin{align}
r^2 + 4s^2r - 4sr &amp;= 0\\
r^2 - 4s(1-s)r &amp;= 0
\end{align}&lt;/math&gt;

and solutions

:&lt;math&gt;r = 0 \quad(\text{trivial}) \qquad\text{or}\qquad r = 4s(1-s)&lt;/math&gt;

This is equivalent to the trigonometric identity :

:&lt;math&gt;\sin^2(2\theta)=4\sin^2\theta \left(1-\sin^2\theta\right)&lt;/math&gt;

of the angles {{mvar|θ}}, {{mvar|θ}} and {{math|180° − 2''θ''}} of a triangle, using

:&lt;math&gt;S_2(s)=S_2\left(\sin^2\theta\right)=\sin^2(2\theta)=r(s)&lt;/math&gt;

to denote a ''second'' [[spread polynomial]] in {{mvar|s}}.

Finding the triple of a spread likewise makes use of the triple spread formula as a quadratic equation in the unknown third spread {{mvar|t}} treating the known spreads {{mvar|s}} and {{mvar|r}} (the previous solution) as constants. This turns out (after eliminating the 'smaller' solution {{mvar|s}}) to be:

:&lt;math&gt;S_3(s)=s(3-4s)^2=t(s)&lt;/math&gt;

Further multiples of any basic spread of lines can either be generated by continuing use of the triple spread formula in this way, or by use of a recursion formula (see below) which applies it indirectly. Wheras any multiple of a spread that is rational will be polynomial in that spread (and therefore rational), the converse does not apply. For example, by the [[half-angle formula]], two lines meeting at a 15° (or 165°) angle have spread of:

:&lt;math&gt;\operatorname{hav}\left(30^\circ\right) = \sin^2 \left(\frac{30^\circ}{2}\right) = \frac{1-\cos 30^\circ}{2} = \frac{1 - \frac{\sqrt 3}{2}}{2} = \frac{2-\sqrt 3}{4} \approx 0.0667.&lt;/math&gt;

and thus exists by algebraic extension of the rational numbers.

==={{anchor|Turn|Coturn}}Turn and coturn===
{{See also|Turn (geometry)}}
{{Empty section|date=December 2015}}
&lt;!-- Please explain the terms "turn" and "coturn" in the context of rational trigonometry (per Wildberger's book) here. Is his definition conflictive with the established definition of "[[turn (angle)]]" as an angular unit and concept in geometry? Please explain similarities/differences. --&gt;

===Twist===
&lt;!-- Section title used in redirects to this article--&gt;
{{See also|Twist (mathematics)}}
{{Empty section|date=December 2015}}
&lt;!-- Please explain the term "twist" in the context of rational trigonometry (per Wildberger's book) here and point out similarities/differences to the established term "twist" in mathematics and [[screw theory]] here. --&gt;

==Spread polynomials==
As seen for double and triple spreads, an {{mvar|n}}th multiple of any spread, {{mvar|s}} gives a polynomial in that spread, denoted {{mvar|''S&lt;sub&gt;n&lt;/sub&gt;''(''s'')}}, as one solution to the triple spread formula.

In the conventional language of [[circular functions]], these {{mvar|n}}th-degree ''spread polynomials'', for {{math|''n'' {{=}} 0, 1, 2, ...}}, can be characterized by the identity:{{Citation needed|date=November 2013}}

:&lt;math&gt;\sin^2(n\theta) = S_n\left(\sin^2\theta\right).&lt;/math&gt;

===Identities===

====Explicit formulas====
*&lt;math&gt;S_n(s) = s\sum_{k=0}^{n-1} \frac{n}{n - k} \binom{2n-1-k}{k} (-4s)^{n-1-k}.&lt;/math&gt; (Michael Hirschhorn, Shuxiang Goh)&lt;ref name="Wildberger_2005"/&gt;
*&lt;math&gt;S_n(s) = \tfrac{1}{2} - \tfrac{1}{4} \left ( 1-2s+2 \sqrt {s^2 -s} \right )^n - \tfrac{1}{4} \left ( 1-2s-2 \sqrt {s^2 -s} \right )^n.&lt;/math&gt; (M. Hovdan)
*&lt;math&gt;S_n(s) = - \tfrac{1}{4} \left ( \left ( \sqrt {1 -s} +i\sqrt {s} \right )^{2n}-1 \right )^2 \left ( \sqrt {1 -s} -i\sqrt {s} \right )^{2n}.&lt;/math&gt; (M. Hovdan)

From the definition it immediately follows that

:&lt;math&gt;S_n(s) = \sin^2\left(n\arcsin\left(\sqrt{s}\right)\right).&lt;/math&gt;{{Citation needed|date=November 2013}}

====Recursion formula====
Since the triple spread formula &lt;math&gt;(s_1 + s_2 + s_3)^2 = 2\left(s_1^2 + s_2^2 + s_3^2\right) + 4s_1 s_ 2 s_ 3 &lt;/math&gt; is an equation whose entries can be spread polynomials of the form :&lt;math&gt;s&lt;/math&gt;,  &lt;math&gt;S_{n}(s)&lt;/math&gt; and &lt;math&gt;S_{n+1}(s)&lt;/math&gt;,

taking the difference of the expressions 

:&lt;math&gt;(s + S_{n}(s) + S_{n+1}(s))^2 = 2\left(s^2 + S_{n}(s)^2 + S_{n+1}^2\right) + 4s S_{n}(s) S_{n+1} &lt;/math&gt;  and  

:&lt;math&gt;(s + S_{n}(s) + S_{n-1}(s))^2 = 2\left(s^2 + S_{n}(s)^2 + S_{n-1}^2\right) + 4s S_{n}(s) S_{n-1} &lt;/math&gt;

and rearranging, gives a recursive relation:

:&lt;math&gt;S_{n+1}(s) = 2(1-2s) S_n(s) - S_{n-1}(s) + 2s.&lt;/math&gt;&lt;ref name="Wildberger_2005"/&gt;

====Relation to Chebyshev polynomials====
The spread polynomials are related to the [[Chebyshev polynomials]] of the first kind, {{math|''T''&lt;sub&gt;''n''&lt;/sub&gt;}}, by the identity

:&lt;math&gt;1 - 2S_n(s) = T_n(1 - 2s).&lt;/math&gt;

This implies&lt;ref name="Wildberger_2005"/&gt;

:&lt;math&gt;S_n(s) = \frac{1 - T_n(1 - 2s)}{2} = 1 - T_n^2\left(\sqrt{1-s}\right).&lt;/math&gt;

The second equality above follows from the identity

:&lt;math&gt;2T_n^2(x) - 1 = T_{2n}(x) &lt;/math&gt;

on Chebyshev polynomials.{{Citation needed|date=November 2013}}

====Composition====
The spread polynomials satisfy the composition identity&lt;ref name="Wildberger_2005"/&gt;

:&lt;math&gt;S_n\bigl(S_m(s)\bigr) = S_{nm}(s).&lt;/math&gt;

====Coefficients in finite fields====
When the coefficients are taken to be members of the [[finite field]] {{math|''F''&lt;sub&gt;''p''&lt;/sub&gt;}}, then the sequence {{math|{''S''&lt;sub&gt;''n''&lt;/sub&gt;}&lt;sub&gt;''n'' {{=}} 0, 1, 2,...&lt;/sub&gt;}} of spread polynomials is periodic with period {{math|{{sfrac|''p''&lt;sup&gt;2&lt;/sup&gt; − 1|2}}}}. In other words, if {{math|''k'' {{=}} {{sfrac|''p''&lt;sup&gt;2&lt;/sup&gt; − 1|2}}}}, then {{math|''S''&lt;sub&gt;''n'' + ''k''&lt;/sub&gt; {{=}} ''S''&lt;sub&gt;''n''&lt;/sub&gt;}}, for all&amp;nbsp;{{mvar|n}}.{{Citation needed|date=November 2013}}

====Orthogonality====
When the coefficients are taken to be [[real number|real]], then for {{math|''n'' ≠ ''m''}}, we have&lt;ref name="Wildberger_2005"/&gt;

:&lt;math&gt;\int_0^1 \left(S_n(s) - \tfrac12 \right) \left(S_m(s) - \tfrac12 \right)\frac{ds}{\sqrt{s(1-s)}}=0.&lt;/math&gt;

For {{math|''n'' {{=}} ''m''}}, the integral is {{sfrac|{{pi}}|8}} unless {{math|''n'' {{=}} ''m'' {{=}} 0}}, in which case it is&amp;nbsp;{{sfrac|{{pi}}|4}}.{{Citation needed|date=November 2013}}

====Generating functions====
The ordinary [[generating function]] is

:&lt;math&gt;\sum_{n=1}^\infty S_n(s)x^n = \frac{sx(1+x)}{(1-x)^3 + 4sx(1-x)}.&lt;/math&gt; (Michael Hirschhorn)&lt;ref name="Wildberger_2005"/&gt;

The exponential generating function is

:&lt;math&gt;\sum_{n=1}^\infty \frac{S_n(s)}{n!} x^n = \tfrac12 e^x \left ( 1-e^{-2sx} \cos\left (2x \sqrt{s(1-s)}\right )\right ) .&lt;/math&gt;{{Citation needed|date=November 2013}}

====Differential equation====
{{math|''S''&lt;sub&gt;''n''&lt;/sub&gt;(''s'')}} satisfies the second-order linear nonhomogeneous differential equation{{Citation needed|date=November 2013}}

:&lt;math&gt;s(1-s)y'' + \left(\tfrac{1}{2}-s\right)y' + n^2\left(y-\tfrac{1}{2}\right) = 0.&lt;/math&gt;

==Spread periodicity theorem==
For every [[integer]] {{mvar|n}} and every [[prime]] {{mvar|p}}, there is a [[natural number]] {{mvar|m}} such that {{math|''S''&lt;sub&gt;''n''&lt;/sub&gt;(''s'')}} is divisible by {{mvar|p}} precisely when {{mvar|m}} divides {{mvar|n}}. This number {{mvar|m}} is a divisor of either {{math|''p'' − 1}} or {{math|''p'' + 1}}. The proof of this number theoretical property was first given in a paper by Shuxiang Goh and N. J. Wildberger.&lt;ref&gt;{{Cite journal | arxiv = 0911.1025 | postscript = | title = Spread polynomials, rotations and the butterfly effect | author = Shuxiang Goh, N. J. Wildberger | date = November 5, 2009| bibcode = 2009arXiv0911.1025G}}&lt;/ref&gt; It involves considering the projective analogue to [[#Quadrance|quadrance]] in the [[Projective line#For a finite field|finite projective line]] {{math|'''P'''&lt;sup&gt;1&lt;/sup&gt;(''F''&lt;sub&gt;''p''&lt;/sub&gt;)}}.

===Table of spread polynomials, with factorizations===
The first several spread polynomials are as follows:
:&lt;math&gt;
\begin{align}
S_0(s) = {} &amp; 0 \\[10pt]
S_1(s) = {} &amp; s \\[10pt]
S_2(s) = {} &amp; 4s-4s^2 \\
= {} &amp; 4s(1-s) \\[10pt]
S_3(s) = {} &amp; 9s-24s^2+16s^3 \\
= {} &amp; s(3-4s)^2 \\[10pt]
S_4(s) = {} &amp; 16s-80s^2+128s^3-64s^4 \\
= {} &amp; 16s(1-s)(1-2s)^2 \\[10pt]
S_5(s) = {} &amp; 25s-200s^2+560s^3-640s^4+256s^5 \\
= {} &amp; s\left(5-20s+16s^2\right)^2 \\[10pt]
S_6(s) = {} &amp; 36s-420s^2+1792s^3-3456s^4+3072s^5-1024s^6 \\
= {} &amp; 4s(1-s)(1-4s)^2(3-4s)^2 \\[10pt]
S_7(s) = {} &amp; 49s-784s^2+4704s^3-13440s^4+19712s^5-14336s^6+4096s^7 \\
= {} &amp; s\left(7-56s+112s^2-64s^3\right)^2 \\[10pt]
S_8(s) = {} &amp; 64s-1344s^2+10752s^3-42240s^4+90112s^5-106496s^6 \\
&amp; {} + 65536s^7-16384s^8 \\
= {} &amp; 64s(s-1)(1-2s)^2\left(1-8s+8s^2\right)^2 \\[10pt]
S_9(s) = {} &amp; 81s - 2160s^2 + 22176s^3 - 114048s^4 + 329472s^5 - 559104s^6 \\
&amp; {} + 552960s^7 - 294912s^8 + 65536s^9 \\
= {} &amp; s(-3+4s)^2\left(-3+36s-96s^2+64s^3\right)^2 \\[10pt]
S_{10}(s) = {} &amp; 100s - 3300s^2 + 42240s^3 - 274560s^4 + 1025024s^5 \\
&amp; {} - 2329600s^6 + 3276800s^7 - 2785280s^8 + 1310720s^9 - 262144s^{10} \\
= {} &amp; 4s(1-s)\left(5 - 20s+16s^2\right)^2\left(1-12s+16s^2\right)^2\\[10pt]
S_{11}(s) = {} &amp; 121s - 4840s^2 + 75504s^3 - 604032s^4 + 2818816s^5 \\
&amp; {} -8200192s^6 + 15319040s^7 - 18382848s^8 + 13697024s^9 -5767168s^{10} + 1048576s^{11}\\
= {} &amp; s\left(11 -220s + 1232s^2 -2816s^3 +2816s^4 -1024s^5\right)^2
\end{align}
&lt;/math&gt;&lt;!-- only for S_0(s) to S_7(s): &lt;ref name="Wildberger_2005"/&gt; --&gt;

==Laws of rational trigonometry==
&lt;!-- Linked to from inside this article --&gt;
Wildberger states that there are five basic laws in rational trigonometry. He also states that these laws can be verified using high-school level mathematics. Some are equivalent to standard trigonometrical formulae with the variables expressed as quadrance and spread.&lt;ref name="Horizons"/&gt;

In the following five formulae, we have a triangle made of three points {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;}}. The spreads of the angles at those points are {{math|''s''&lt;sub&gt;1&lt;/sub&gt;, ''s''&lt;sub&gt;2&lt;/sub&gt;, ''s''&lt;sub&gt;3&lt;/sub&gt;}}, and {{math|''Q''&lt;sub&gt;1&lt;/sub&gt;, ''Q''&lt;sub&gt;2&lt;/sub&gt;, ''Q''&lt;sub&gt;3&lt;/sub&gt;}}, are the quadrances of the triangle sides opposite {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;}}, respectively. As in classical trigonometry, if we know three of the six elements {{math|''s''&lt;sub&gt;1&lt;/sub&gt;, ''s''&lt;sub&gt;2&lt;/sub&gt;, ''s''&lt;sub&gt;3&lt;/sub&gt;}}, {{math|''Q''&lt;sub&gt;1&lt;/sub&gt;, ''Q''&lt;sub&gt;2&lt;/sub&gt;, ''Q''&lt;sub&gt;3&lt;/sub&gt;}}, and these three are not the three {{mvar|s}}, then we can compute the other three.

===Triple quad formula===
&lt;!-- Linked to from inside this article --&gt;
The three points {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;}} are [[collinear]] if and only if:

: &lt;math&gt;(Q_1 + Q_2 + Q_3)^2 = 2\left(Q_1^2 + Q_2^2 + Q_3^2\right)&lt;/math&gt;

where {{math|''Q''&lt;sub&gt;1&lt;/sub&gt;, ''Q''&lt;sub&gt;2&lt;/sub&gt;, ''Q''&lt;sub&gt;3&lt;/sub&gt;}} represent the quadrances between {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;}} respectively. It can either be proved by [[analytic geometry]] (the preferred means within rational trigonometry) or derived from [[Heron's formula]], using the condition for collinearity that the triangle formed by the three points has zero area.

{{Hidden begin|title=Proof (click at right to show/hide)}}
[[Image:TripleQuadProofIllustration.png|thumbnail|300px|right|Illustration of nomenclature used in the proof.]]
The line {{mvar|AB}} has the general form:

:&lt;math&gt;ax + by + c = 0&lt;/math&gt;

where the (non-unique) parameters {{math|''a'', ''b'', ''c''}} can be expressed in terms of the coordinates of points {{mvar|A}} and {{mvar|B}} as:

:&lt;math&gt;\begin{align}
a &amp;= A_y - B_y\\
b &amp;= B_x - A_x\\
c &amp;= A_xB_y - A_yB_x
\end{align}&lt;/math&gt;

so that, everywhere on the line:

:&lt;math&gt;\left(A_y - B_y\right)x + \left(B_x - A_x\right)y + \left(A_xB_y - A_yB_x\right) = 0.&lt;/math&gt;

But the line can also be specified by two simultaneous equations in a parameter {{mvar|t}}, where {{math|''t'' {{=}} 0}} at point {{mvar|A}} and {{math|''t'' {{=}} 1}} at point {{mvar|B}}:

:&lt;math&gt;\begin{align}
x &amp;= (B_x - A_x)t + A_x,\\
y &amp;= (B_y - A_y)t + A_y,
\end{align}&lt;/math&gt;

or, in terms of the original parameters:

:&lt;math&gt;\begin{align}
x &amp;= bt + A_x,\\
y &amp;= -at + A_y.
\end{align}&lt;/math&gt;

If the point {{mvar|C}} is collinear with points {{mvar|A}} and {{mvar|B}}, there exists some value of {{mvar|t}} (for distinct points, not equal to 0 or 1), call it {{mvar|λ}}, for which these two equations are simultaneously satisfied at the coordinates of the point {{mvar|C}}, such that:

:&lt;math&gt;\begin{align}
C_x &amp;= b\lambda + A_x. \\
C_y &amp;= -a\lambda + A_y.
\end{align}&lt;/math&gt;

Now, the quadrances of the three line segments are given by the squared differences of their coordinates, which can be expressed in terms of {{mvar|λ}}:

:&lt;math&gt;\begin{align}
Q(AB) &amp; \equiv (B_x - A_x)^2 + (B_y - A_y)^2 \\
&amp; = b^2 + (-a)^2 \\
&amp; = a^2 + b^2\\[10pt]

Q(BC) &amp; \equiv (C_x - B_x)^2 + (C_y - B_y)^2 \\
&amp; = \bigl((b\lambda + A_x) -B_x\bigr)^2 + \bigl((-a\lambda + A_y) - B_y\bigr)^2 \\
&amp; = \bigl(b\lambda + (A_x -B_x)\bigr)^2 + \bigl(-a\lambda + (A_y - B_y)\bigr)^2 \\
&amp; = \bigl(b\lambda + (-b)\bigr)^2 + (-a\lambda + a)^2 \\
&amp; = b^2(\lambda - 1)^2 + a^2(-\lambda + 1)^2 \\
&amp; = b^2(\lambda - 1)^2 + a^2(\lambda - 1)^2 \\
&amp; = \left(a^2 + b^2\right)(\lambda - 1)^2 \\[10pt]

Q(AC) &amp; \equiv (C_x - A_x)^2 + (C_y - A_y)^2 \\
&amp; = \bigl((b\lambda + A_x) - A_x\bigr)^2 + \bigl((-a\lambda + A_y) - A_y\bigr)^2 \\
&amp; = (b\lambda + A_x - A_x)^2 + (-a\lambda + A_y - A_y)^2 \\
&amp; = (b\lambda)^2 + (-a\lambda)^2 \\
&amp; = b^2\lambda^2 + (-a)^2\lambda^2 \\
&amp; = b^2\lambda^2 + a^2\lambda^2 \\
&amp; = \left(a^2 + b^2\right)\lambda^2
\end{align}&lt;/math&gt;

where use was made of the fact that {{math|(−''λ'' + 1)&lt;sup&gt;2&lt;/sup&gt; {{=}} (''λ'' − 1)&lt;sup&gt;2&lt;/sup&gt;}}.

Substituting these quadrances into the equation to be proved:

:&lt;math&gt;\begin{align}
\bigl(Q(AB) + Q(BC) + Q(AC)\bigr)^2 &amp;= 2\left(Q(AB)^2 + Q(BC)^2 + Q(AC)^2\right) \\
\left(\left(a^2 + b^2\right) + \left(a^2 + b^2\right)(\lambda - 1)^2 + \left(a^2 + b^2\right)\lambda^2\right)^2 &amp;= 2\left(\left(a^2 + b^2\right)^2 + \left(\left(a^2 + b^2\right)(\lambda - 1)^2\right)^2 + \left(\left(a^2 + b^2\right)\lambda^2\right)^2\right)\\
\left(a^2 + b^2\right)^2\left(1 + (\lambda - 1)^2 + \lambda^2\right)^2 &amp;= 2\left(a^2 + b^2\right)^2\left(1 + \left((\lambda - 1)^2\right)^2 + \left(\lambda^2\right)^2\right)
\end{align}&lt;/math&gt;

Now, if {{mvar|A}} and {{mvar|B}} represent distinct points, such that {{math|''a''&lt;sup&gt;2&lt;/sup&gt; + ''b''&lt;sup&gt;2&lt;/sup&gt; ≠ 0}}, we may divide both sides by {{math|''Q''(''AB'')&lt;sup&gt;2&lt;/sup&gt; {{=}} (''a''&lt;sup&gt;2&lt;/sup&gt; + ''b''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;2&lt;/sup&gt;}}:

:&lt;math&gt;\begin{align}
\left(1 + \lambda^2 -2\lambda + 1 + \lambda^2\right)^2 &amp;= 2\left(1 + \left(\lambda^2 -2\lambda + 1\right)^2 + \lambda^4\right)\\
\left(2\lambda^2 - 2\lambda + 2\right)^2 &amp;= 2\left(1 + \lambda^4 - 2\lambda^3 + \lambda^2 - 2\lambda^3 + 4\lambda^2 - 2\lambda + \lambda^2 - 2\lambda + 1 + \lambda^4\right)\\
4\left(\lambda^2 - \lambda + 1\right)^2 &amp;= 2\left(2\lambda^4 - 4\lambda^3 + 6\lambda^2 - 4\lambda + 2\right)\\
4\left(\lambda^4 - \lambda^3 + \lambda^2 - \lambda^3 + \lambda^2 - \lambda + \lambda^2 - \lambda + 1\right) &amp;= 4\left(\lambda^4 - 2\lambda^3 + 3\lambda^2 - 2\lambda + 1\right)\\
\lambda^4 - 2\lambda^3 + 3\lambda^2 - 2\lambda + 1 &amp;= \lambda^4 - 2\lambda^3 + 3\lambda^2 - 2\lambda + 1
\end{align}&lt;/math&gt;
{{hidden end}}

===Pythagoras's theorem===
The lines {{math|''A''&lt;sub&gt;1&lt;/sub&gt;''A''&lt;sub&gt;3&lt;/sub&gt;}} (of quadrance {{math|''Q''&lt;sub&gt;1&lt;/sub&gt;}}) and {{math|''A''&lt;sub&gt;2&lt;/sub&gt;''A''&lt;sub&gt;3&lt;/sub&gt;}} (of quadrance {{math|''Q''&lt;sub&gt;2&lt;/sub&gt;}}) are perpendicular (their spread is 1) if and only if:

: &lt;math&gt;Q_1 + Q_2 = Q_3.&lt;/math&gt;

where {{math|''Q''&lt;sub&gt;3&lt;/sub&gt;}} is the quadrance between {{math|''A''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''A''&lt;sub&gt;2&lt;/sub&gt;}}.

This is equivalent to the [[Pythagorean theorem]] (and its converse).

There are many classical proofs of [[Pythagoras's theorem]]; this one is framed in the terms of rational trigonometry.

The ''spread'' of an angle is the square of its [[sine]]. Given the triangle {{math|△''ABC''}} with a spread of 1 between sides {{mvar|AB}} and {{mvar|AC}},

:&lt;math&gt;Q(AB) + Q(AC) = Q(BC)&lt;/math&gt;

where {{mvar|Q}} is the "quadrance", i.e. the square of the distance.

{{Hidden begin|title=Proof}}
[[Image:PythagoreanTheoremProofIllustration.svg|thumbnail|250px|right|Illustration of nomenclature used in the proof.]]
Construct a line {{mvar|AD}} dividing the spread of 1, with the point {{mvar|D}} on line {{mvar|BC}}, and making a spread of 1 with {{mvar|DB}} and {{mvar|DC}}. The triangles {{math|△''ABC''}}, {{math|△''DBA''}} and {{math|△''DAC''}} are similar (have the same spreads but not the same quadrances).

This leads to two equations in ratios, based on the spreads of the sides of the triangle:

:&lt;math&gt;\begin{align}
s_C &amp;= \frac{Q(AB)}{Q(BC)} &amp;&amp;= \frac{Q(BD)}{Q(AB)} &amp;&amp;= \frac{Q(AD)}{Q(AC)}.\\
s_B &amp;= \frac{Q(AC)}{Q(BC)} &amp;&amp;= \frac{Q(DC)}{Q(AC)} &amp;&amp;= \frac{Q(AD)}{Q(AB)}.\end{align}&lt;/math&gt;

Now in general, the two spreads resulting from dividing a spread into two parts, as line {{mvar|AD}} does for spread {{mvar|CAB}}, do not add up to the original spread since spread is a non-linear function. So we first prove that dividing a spread of 1, results in two spreads that do add up to the original spread of 1.

For convenience, but with no loss of generality, we orient the lines intersecting with a spread of 1 to the coordinate axes, and label the dividing line with coordinates {{math|(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;)}} and {{math|(''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;)}}. Then the two spreads are given by:

:&lt;math&gt;\begin{align}
s_1 &amp;= \frac{(x_2 - x_2)^2 + (y_2 - y_1)^2}{(x_2 - x_1)^2 + (y_2 - y_1)^2}
&amp;&amp;= \frac{(y_2 - y_1)^2}{(x_2 - x_1)^2 + (y_2 - y_1)^2},\\
s_2 &amp;= \frac{(x_2 - x_1)^2 + (y_2 - y_2)^2}{(x_2 - x_1)^2 + (y_2 - y_1)^2}
&amp;&amp;= \frac{(x_2 - x_1)^2}{(x_2 - x_1)^2 + (y_2 - y_1)^2}.
\end{align}&lt;/math&gt;

Hence
:&lt;math&gt;s_1 + s_ 2 = \frac{(x_2 - x_1)^2 + (y_2 - y_1)^2}{(x_2 - x_1)^2 + (y_2 - y_1)^2} = 1,&lt;/math&gt;

so that

:&lt;math&gt;s_C + s_B = 1.&lt;/math&gt;

Using the first two ratios from the first set of equations, this can be rewritten:

:&lt;math&gt;\frac{Q(AB)}{Q(BC)} + \frac{Q(AC)}{Q(BC)} = 1.&lt;/math&gt;

Multiplying both sides by {{math|''Q''(''BC'')}}:

:&lt;math&gt;Q(AB) + Q(AC) = Q(BC).&lt;/math&gt;

[[Q.E.D.]]
{{hidden end}}

===Spread law===
For any triangle {{math|△''A''&lt;sub&gt;1&lt;/sub&gt;''A''&lt;sub&gt;2&lt;/sub&gt;''A''&lt;sub&gt;3&lt;/sub&gt;}} with nonzero quadrances:&lt;ref name="Wildberger_2005"/&gt;

: &lt;math&gt;\frac{s_1}{Q_1}=\frac{s_2}{Q_2}=\frac{s_3}{Q_3}.&lt;/math&gt;

This is the [[law of sines]], just squared.

===Cross law===
For any triangle {{math|△''A''&lt;sub&gt;1&lt;/sub&gt;''A''&lt;sub&gt;2&lt;/sub&gt;''A''&lt;sub&gt;3&lt;/sub&gt;}},&lt;ref name="Wildberger_2005"/&gt;

: &lt;math&gt;(Q_1 + Q_2 - Q_3)^2 = 4Q_1 Q_2 (1-s_3).&lt;/math&gt;

This is analogous to the [[law of cosines]]. It is called the 'cross law' because {{math|(1 − ''s''&lt;sub&gt;3&lt;/sub&gt;)}}, the square of the cosine of the angle, is called the 'cross'.

===Triple spread formula===
&lt;!-- Linked to from inside this article --&gt;
For any triangle {{math|△''A''&lt;sub&gt;1&lt;/sub&gt;''A''&lt;sub&gt;2&lt;/sub&gt;''A''&lt;sub&gt;3&lt;/sub&gt;}},&lt;ref name="Wildberger_2005"/&gt;

: &lt;math&gt;(s_1 + s_2 + s_3)^2 = 2\left(s_1^2 + s_2^2 + s_3^2\right) + 4s_1 s_ 2 s_ 3 .&lt;/math&gt;

This relation can be derived from the formula for the [[Trigonometric identity#Angle sum and difference identities|sine of a compound angle]]: in a triangle (whose three angles sum to 180°) we have,

:&lt;math&gt;\sin (a)=\sin (b+c)=\sin (b)\cos (c) + \sin (c)\cos (b)&lt;/math&gt;.

Equivalently, it describes the relationship between the spreads of three concurrent lines, as spread (like angle) is unaffected when the sides of a triangle are moved parallel to themselves to meet in a common point.

Knowing two spreads allows the third to be calculated by solving the associated quadratic formula but, since two solutions are possible, further ''triangle spread rules'' must be used to select the appropriate one. (The compexity of this method contrasts with obtaining a supplementary angle directly by subtracting.)

==Trigonometry over arbitrary fields==
As the laws of rational trigonometry give algebraic (and not transcendental) relations, they apply in generality to algebraic number fields beyond the rational numbers. Specifically, any finite field which does not have [[characteristic (algebra)|characteristic]] 2 reproduces a form of these laws, and thus a [[Finite geometry|finite field geometry]].&lt;ref&gt;{{Cite journal | arxiv = 0807.2692 | postscript = | title = Explicit tough Ramsey graphs | author = Le Anh Vinh, Dang Phuong Dung | date = July 17, 2008 | bibcode = 2008arXiv0807.2692V }}, page 1. Another version of this article is at Le Anh Vinh, Dang Phuong Dung (2008), "[http://www.math.harvard.edu/~vinh/rogics_final.pdf Explicit tough Ramsey Graphs] {{webarchive|url=https://web.archive.org/web/20121011020814/http://www.math.harvard.edu/~vinh/rogics_final.pdf |date=2012-10-11 }}", ''Proceedings of International Conference on Relations, Orders and Graphs: Interaction with Computer Science 2008'', Nouha Editions, 139–146. &lt;/ref&gt; The 'plane' formed by a finite field {{math|''F&lt;sub&gt;p&lt;/sub&gt;''}} is the [[cartesian product]] {{math|''F&lt;sub&gt;p&lt;/sub&gt;'' × ''F&lt;sub&gt;p&lt;/sub&gt;''}} of all ordered pairs of field elements, with opposite edges identified forming the surface topologically equivalent to a discretized [[Torus (mathematics)|torus]]. Individual elements correspond to standard 'points' and 'lines' to sets of no more than &lt;math&gt;p&lt;/math&gt; points related by incidence (an initial point) plus direction or slope given in lowest terms (say all points '2 over and 1 up') that 'wrap' the plane before repeating.

===Example: (verify the spread law in {{math|''F''&lt;sub&gt;13&lt;/sub&gt;}})===
The figure (right) shows a ''triangle'' of three such lines in the finite field setting {{math|''F''&lt;sub&gt;13&lt;/sub&gt; × ''F''&lt;sub&gt;13&lt;/sub&gt;}}:

Each line has its own symbol and the intersections of lines (''vertices'') is marked by ''two'' symbols present at points:[[Image:Triangle in Z13.svg|thumb|right|A triangle through the points {{math|(2, 8)}}, {{math|(9, 9)}}, and {{math|(10, 0)}} of the [[finite field]]-plane {{math|''F''&lt;sub&gt;13&lt;/sub&gt; × ''F''&lt;sub&gt;13&lt;/sub&gt;}}.|278x278px]]

: (2, 8), (9, 9) and (10, 0).

Using ''Pythagoras's theorem'' with arithmetic [[modular arithmetic|modulo]] 13, we find these sides have quadrances of:

: (9 − 2)&lt;sup&gt;2&lt;/sup&gt; + (9 − 8)&lt;sup&gt;2&lt;/sup&gt; = 50 ≡ 11 mod 13

: (9 − 10)&lt;sup&gt;2&lt;/sup&gt; + (9 − 0)&lt;sup&gt;2&lt;/sup&gt; = 82 ≡ 4 mod 13

: (10 − 2)&lt;sup&gt;2&lt;/sup&gt; + (0 − 8)&lt;sup&gt;2&lt;/sup&gt; = 128 ≡ 11 mod 13

Rearranging the cross law as 
:&lt;math&gt;s_3 = 1 - \frac{(Q_1 + Q_2 - Q_3)^2}{4Q_1 Q_2}&lt;/math&gt;
gives separate expressions for each spread, in terms of the three quadrances:

: 1 − {{sfrac|('''4 + 11 − 11''')&lt;sup&gt;2&lt;/sup&gt;|4 × '''4''' × '''11'''}} = 1 − {{sfrac|3|7}} ≡ 8 mod 13

: 1 − {{sfrac|('''11 + 11 − 4''')&lt;sup&gt;2&lt;/sup&gt;|4 × '''11''' × '''11'''}} = 1 − {{sfrac|12|3}} ≡ 10 mod 13
 
: 1 − {{sfrac|('''4 + 11 − 11''')&lt;sup&gt;2&lt;/sup&gt;|4 × '''4''' × '''11'''}} = 1 − {{sfrac|3|7}} ≡ 8 mod 13

In turn we note these ratios are all equal – as per the spread law (at least in mod&amp;nbsp;13):

: {{sfrac|8|11}} : {{sfrac|10|4}} : {{sfrac|8|11}}

Since first and last ratios match (making the triangle ''isosceles'') we just cross multiply, and take differences, to show equality with the middle ratio also:

: 11 × 10 − 8 × 4 = 78 ≡ 0 mod 13

Otherwise, the standard Euclidean plane is taken to consist of just rational points, {{math|ℚ × ℚ}}, omitting any non-algebraic numbers as solutions. Properties like incidence of objects, representing the solutions or 'content' of geometric theorems, therefore follow a number theoretic approach that differs and is more restrictive than one allowing real numbers. For instance, ''not all'' lines passing through a circle's centre are considered to meet the circle at its circumference. To be incident such lines must be of the form
:&lt;math&gt;\begin{align}ax + by &amp;= 0 \\ a^2 + b^2 &amp;= c^2 \end{align}\quad a,b,c \in \Q&lt;/math&gt;
and necessarily meet the circle in a ''rational'' point.

==Computation – complexity and efficiency==
Rational trigonometry makes nearly all problems solvable with only addition, subtraction, multiplication or division, as trigonometric functions (of angle) are purposefully avoided in favour of trigonometric ratios in quadratic form.&lt;ref name="Horizons"&gt;{{Cite journal | first = Norman J. | last = Wildberger | title = A Rational Approach to Trigonometry | journal = Math Horizons | volume = November 2007 | pages = 16–20| publisher = Mathematical Association of America| location = Washington, DC| year = 2007| issn = 1072-4117| postscript =}}&lt;/ref&gt; At most, therefore, results required as distance (or angle) can be approximated from an exact-valued rational equivalent of quadrance (or spread) after these simpler operations have been carried out. To make use of this advantage however, each problem must either be given, or set up, in terms of prior quadrances and spreads, which entails additional work.&lt;ref&gt;Olga Kosheleva (2008), "[http://web.maths.unsw.edu.au/~norman/papers/Kosheleva.pdf Rational trigonometry: computational viewpoint]", Geombinatorics, Vol. 1, No. 1, pp. 18–25.&lt;/ref&gt;

The laws of rational trigonometry, being algebraic and 'exact-valued', introduce subtleties into the solutions of problems, such as the non-additivity of quadrances of collinear points (in the case of the triple quad formula) or the spreads of concurrent lines (in the case of the triple spread formula) absent from the classical subject, where linearity is incorporated into distance and circular measure of angles, albeit 'transcendental' techniques, necessitating approximation in results.

==See also==
* [[Finitism]]
* [[Ultrafinitism]]
* [[Universal hyperbolic geometry]]
* [[History of trigonometry]]

==Notes==
&lt;references group="nb"/&gt;

==References==
{{Reflist}}
==General References==
* [http://web.maths.unsw.edu.au/%7Enorman/papers/TrigComparison.pdf A comparison of classical and rational trigonometry]
* [http://web.ist.utl.pt/ist152027/content/tfc/files/paper.pdf Rational Trigonometry Applied to Robotics], by João Pequito Almeida
* [http://web.maths.unsw.edu.au/~norman/papers/Trisection.pdf The Impossibility of Trisecting and Angle with Straightedge and Compass: An Approach Using Rational Trigonometry], by David G. Poole
* [http://www.austms.org.au/Publ/Gazette/2007/Sep07/Gazette34(4)WebVersion.pdf#page=33 How to multiply and divide triangles], by Maurice Craig

==External links==
* [http://web.maths.unsw.edu.au/~norman/Rational1.htm Wildberger's rational trigonometry site], including downloadable papers and sections of his book
* [https://arxiv.org/abs/0911.1025 Spread polynomials, rotations and the butterfly effect]
* [http://euler.rene-grothmann.de/Programs/Examples/Rational%20Trigonometry.html Euler Math Toolbox implementation of Rational Trigonometry]

[[Category:Trigonometry]]
[[Category:Articles containing proofs]]</text>
      <sha1>bk75j4323au5y7htajpna6pw08360ot</sha1>
    </revision>
  </page>
  <page>
    <title>Series acceleration</title>
    <ns>0</ns>
    <id>8737421</id>
    <revision>
      <id>846760865</id>
      <parentid>824450008</parentid>
      <timestamp>2018-06-20T18:45:18Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 1 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7612">In [[mathematics]], '''series acceleration''' is one of a collection of [[sequence transformation]]s for improving the [[rate of convergence]] of a [[series (mathematics)|series]]. Techniques for series acceleration are often applied in [[numerical analysis]], where they are used to improve the speed of [[numerical integration]]. Series acceleration techniques may also be used, for example, to obtain a variety of identities on [[special functions]]. Thus, the [[Euler transform]] applied to the [[hypergeometric series]] gives some of the classic, well-known hypergeometric series identities.

== Definition ==
Given a [[sequence]] 

:&lt;math&gt;S=\{ s_n \}_{n\in\N}&lt;/math&gt;

having a limit

:&lt;math&gt;\lim_{n\to\infty} s_n = \ell,&lt;/math&gt;

an accelerated series is a second sequence 

:&lt;math&gt;S'=\{ s'_n \}_{n\in\N}&lt;/math&gt;

which '''converges faster''' to &lt;math&gt;\ell&lt;/math&gt; than the original sequence, in the sense that 

:&lt;math&gt;\lim_{n\to\infty} \frac{s'_n-\ell}{s_n-\ell} = 0.&lt;/math&gt;

If the original sequence is [[Divergent series|divergent]], the [[sequence transformation]] acts as an [[extrapolation method]] to the [[antilimit]] &lt;math&gt;\ell&lt;/math&gt;.

The mappings from the original to the transformed series may be linear (as defined in the article [[sequence transformation]]s), or non-linear. In general, the non-linear sequence transformations tend to be more powerful.

== Overview ==
Two classical techniques for series acceleration are [[Euler's transformation of series]]&lt;ref&gt;{{AS ref|3, eqn 3.6.27|16}}&lt;/ref&gt; and [[Kummer's transformation of series]].&lt;ref&gt;{{AS ref|3, eqn 3.6.26|16}}&lt;/ref&gt; A variety of much more rapidly convergent and special-case tools have been developed in the 20th century, including [[Richardson extrapolation]], introduced by [[Lewis Fry Richardson]] in the early 20th century but also known and used by [[Takebe Kenko|Katahiro Takebe]] in 1722, the [[Aitken delta-squared process]], introduced by [[Alexander Aitken]] in 1926 but also known and used by [[Takakazu Seki]] in the 18th century, the [http://mathworld.wolfram.com/WynnsEpsilonMethod.html epsilon method] given by [[Peter Wynn (mathematician)|Peter Wynn]] in 1956, the [[Levin u-transform]], and the Wilf-Zeilberger-Ekhad method or [[WZ theory|WZ method]].

For alternating series, several powerful techniques, offering convergence rates  from &lt;math&gt;5.828^{-n}&lt;/math&gt; all the way to &lt;math&gt;17.93^{-n}&lt;/math&gt; for a summation of &lt;math&gt;n&lt;/math&gt; terms, are described by Cohen ''et al.''.&lt;ref&gt;[[Henri Cohen (number theorist)|Henri Cohen]], Fernando Rodriguez Villegas, and [[Don Zagier]],
"[http://people.mpim-bonn.mpg.de/zagier/files/exp-math-9/fulltext.pdf Convergence Acceleration of Alternating Series]", ''Experimental Mathematics'', '''9''':1 (2000) page 3.&lt;/ref&gt;

==Euler's transform==
A basic example of a [[linear sequence transformation]], offering improved convergence, is Euler's transform. It is intended to be applied to an alternating series; it is given by 

:&lt;math&gt;\sum_{n=0}^\infty (-1)^n a_n = \sum_{n=0}^\infty (-1)^n 
\frac {\Delta^n a_0} {2^{n+1}}&lt;/math&gt;

where &lt;math&gt;\Delta&lt;/math&gt; is the [[forward difference operator]]:

:&lt;math&gt;\Delta^n a_0 = \sum_{k=0}^n (-1)^k {n \choose k} a_{n-k}.&lt;/math&gt;

If the original series, on the left hand side, is only slowly converging, the forward differences will tend to become small quite rapidly; the additional power of two further improves the rate at which the right hand side converges.

A particularly efficient numerical implementation of the Euler transform is the [[van Wijngaarden transformation]].&lt;ref&gt;William H. Press, ''et al.'', ''Numerical Recipes in C'', (1987) Cambridge University Press, {{isbn|0-521-43108-5}} (See section 5.1).&lt;/ref&gt;

==Conformal mappings==
A series

:&lt;math&gt;S=\sum_{n=0}^{\infty} a_n&lt;/math&gt;

can be written as f(1), where the function f(z) is defined as

:&lt;math&gt;f(z) = \sum_{n=0}^{\infty} a_n z^{n}&lt;/math&gt;

The function f(z) can have singularities in the complex plane (branch point singularities, poles or essential singularities), which limit the radius of convergence of the series. If the point z = 1 is close to or on the boundary of the disk of convergence, the series for S will converge very slowly. One can then improve the convergence of the series by means of a conformal mapping that moves the singularities such that the point that is mapped to z = 1, ends up deeper in the new disk of convergence.

The conformal transform &lt;math&gt;z = \Phi(w)&lt;/math&gt; needs to be chosen such that &lt;math&gt;\Phi(0)=0&lt;/math&gt;, and one usually chooses a function that has a finite derivative at w = 0. One can assume that &lt;math&gt;\Phi(1)=1&lt;/math&gt; without loss of generality, as one can always rescale w to redefine &lt;math&gt;\Phi&lt;/math&gt;. We then consider the function

:&lt;math&gt;g(w)= f\left(\Phi(w)\right)&lt;/math&gt;

Since &lt;math&gt;\Phi(1)=1&lt;/math&gt;, we have f(1) = g(1). We can obtain the series expansion of g(w) by putting &lt;math&gt;z=\Phi(w)&lt;/math&gt; in the series expansion of f(z) because &lt;math&gt;\Phi(0)=0&lt;/math&gt;; the first n terms of the series expansion for f(z) will yield the first n terms of the series expansion for g(w) if &lt;math&gt;\Phi'(0)\neq 0&lt;/math&gt;. Putting w = 1 in that series expansion will thus yield a series such that if it converges, it will converge to the same value as the original series.

==Non-linear sequence transformations==

Examples of such nonlinear sequence transformations are [[Padé approximant]]s, the [[Shanks transformation]], and [[Levin-type sequence transformation]]s.

Especially nonlinear sequence transformations often provide  powerful numerical methods for the [[summation]] of [[divergent series]] or [[asymptotic series]] that arise for instance in [[perturbation theory]], and may be used as  highly effective [[extrapolation method]]s.

===Aitken method===
{{main article|Aitken's delta-squared process}}
A simple nonlinear sequence transformation is the Aitken extrapolation or delta-squared method,

:&lt;math&gt;\mathbb{A} : S \to S'=\mathbb{A}(S) = {(s'_n)}_{n\in\N}&lt;/math&gt;

defined by 

:&lt;math&gt;s'_n = s_{n+2} - \frac{(s_{n+2}-s_{n+1})^2}{s_{n+2}-2s_{n+1}+s_n}.&lt;/math&gt;

This transformation is commonly used to improve the [[rate of convergence]] of a slowly converging sequence; heuristically, it eliminates the largest part of the [[absolute error]].

== See also ==
* [[Minimum polynomial extrapolation]]
* [[Van Wijngaarden transformation]]
==External Links==
* [http://numbers.computation.free.fr/Constants/Miscellaneous/seriesacceleration.html Convergence acceleration of series]
* [https://www.gnu.org/software/gsl/manual/html_node/Series-Acceleration.html GNU Scientific Library, Series Acceleration]
* [http://dlmf.nist.gov/3.9 Digital Library of Mathematical Functions]
==References==
&lt;references/&gt;
* C. Brezinski and M. Redivo Zaglia, ''Extrapolation Methods. Theory and Practice'', North-Holland, 1991.
* G. A. Baker, Jr. and P. Graves-Morris, ''Padé  Approximants'', Cambridge U.P., 1996.
* {{mathworld|urlname=ConvergenceImprovement|title=Convergence Improvement}}
* Herbert H. H. Homeier, ''Scalar Levin-Type Sequence Transformations'', Journal of Computational and Applied Mathematics, vol. 122, no. 1-2, p 81 (2000). {{Cite journal | last1 = Homeier | first1 = H. H. H. | doi = 10.1016/S0377-0427(00)00359-9 | title = Scalar Levin-type sequence transformations | journal = Journal of Computational and Applied Mathematics | volume = 122 | pages = 81 | year = 2000 | pmid =  | pmc = | arxiv = math/0005209 | bibcode = 2000JCoAM.122...81H }}, {{arxiv|math/0005209}}.

[[Category:Numerical analysis]]
[[Category:Asymptotic analysis]]
[[Category:Summability methods]]
[[Category:Perturbation theory]]</text>
      <sha1>95k48wd3iuiihskd46mx6z4dubn2rue</sha1>
    </revision>
  </page>
  <page>
    <title>Seven states of randomness</title>
    <ns>0</ns>
    <id>29329597</id>
    <revision>
      <id>828050358</id>
      <parentid>827761448</parentid>
      <timestamp>2018-02-28T07:43:34Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>/* Concentration in probability */Typo fixing, replaced: Spliting → Splitting using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12605">[[File:Stable motion blue.jpeg|thumb|right|350px|Stochastic process with random increments from a symmetric [[stable distribution]] with&amp;nbsp;''α''&amp;nbsp;=&amp;nbsp;1.7. Notice the discontinuous changes.]]
[[File:Brow motion blue.jpeg|thumb|right|350px|Stochastic process with random increments from a standard [[normal distribution]].]]

The '''seven states of randomness''' in [[probability theory]], [[fractals]] and [[Probabilistic risk assessment|risk analysis]] are extensions of the concept of [[randomness]] as modeled by the [[normal distribution]]. These seven states were first introduced by [[Benoît Mandelbrot]] in his 1997 book ''Fractals and Scaling in Finance'', which applied [[fractal analysis]] to the study of risk and randomness.&lt;ref name=Mandelbrot1977 &gt;[[Benoît Mandelbrot]] (1997) ''Fractals and scaling in finance''  {{isbn|0-387-98363-5}} pages 136–142 https://books.google.com/books/about/Fractals_and_Scaling_in_Finance.html?id=6KGSYANlwHAC&amp;redir_esc=y&lt;/ref&gt; This classification builds upon the three main states of randomness: mild, slow, and wild.

The importance of '''seven states of randomness''' classification for [[mathematical finance]] is that methods such as [[Modern portfolio theory#Mathematical model|Markowitz mean variance portfolio]] and [[Black–Scholes model]] may be invalidated as the tails of the distribution of returns are [[Fat tail|fattened]]: the former relies on finite [[standard deviation]] ([[Volatility (finance)|volatility]]) and stability of [[correlation]], while the latter is constructed upon [[Brownian motion]].

==History==

These seven states build on earlier work of Mandelbrot in 1963: "The variations of certain speculative prices"&lt;ref&gt;B. Mandelbrot, The variation of certain Speculative Prices, The Journal of Business 1963 [http://web.williams.edu/Mathematics/sjmiller/public_html/341Fa09/econ/Mandelbroit_VariationCertainSpeculativePrices.pdf]&lt;/ref&gt; and "New methods in statistical economics"&lt;ref&gt;B. Mandelbrot, New methods in statistical economics, The Journal of Political Economy 1963 https://www.jstor.org/stable/1829014&lt;/ref&gt; in which he argued that most [[statistical model]]s approached only a first stage of dealing with [[indeterminism]] in science, and that they ignored many aspects of real world [[turbulence]], in particular, most cases of [[financial modelling]].&lt;ref&gt;Benoit Mandelbrot, F.J. Damerau, M. Frame, and K. McCamy (2001) ''Gaussian Self-Affinity and Fractals''  {{isbn|0-387-98993-5}} page 20&lt;/ref&gt;&lt;ref&gt;Philip Mirowski (2004) ''The effortless economy of science?''  {{isbn|0-8223-3322-8}} page 255&lt;/ref&gt; This was then presented by Mandelbrot in the International Congress for Logic (1964) in an address titled "The Epistemology of Chance in Certain Newer Sciences"&lt;ref name="users.math.yale.edu"&gt;B. Mandelbrot, Toward a second stage of indeterminism in Science, Interdisciplinary Science Reviews 1987 [http://users.math.yale.edu/mandelbrot/web_pdfs/indeterminismInScience.pdf]&lt;/ref&gt;

Intuitively speaking, Mandelbrot argued&lt;ref name="users.math.yale.edu"/&gt; that the traditional normal distribution does not properly capture empirical and "real world" distributions and there are other forms of randomness that can be used to model extreme changes in risk and randomness. He observed that randomness can become quite "wild" if the requirements regarding finite [[mean]] and [[variance]] are abandoned. Wild randomness corresponds to situations in which a single observation, or a particular outcome can impact the total in a very disproportionate way.

[[File:Exponential simulation.jpeg|thumb|Random draws from an [[exponential distribution]] with mean&amp;nbsp;=&amp;nbsp;1. (Borderline mild randomness)]]
[[File:Lognormal simulation.jpeg|thumb|right|Random draws from a [[lognormal distribution]] with mean&amp;nbsp;=&amp;nbsp;1. (Slow randomness with finite and localized moments)]]
[[File:Pareto simulation.jpeg|thumb|right|Random draws from a [[Pareto distribution]] with mean&amp;nbsp;=&amp;nbsp;1 and ''α''&amp;nbsp;=&amp;nbsp;1.5 (Wild randomness)]]

The classification was formally introduced in his 1997 book ''Fractals and Scaling in Finance'',&lt;ref name=Mandelbrot1977 /&gt; as a way to bring insight into the three main states of randomness: mild, slow, and wild . Given ''N'' [[addends]], ''portioning'' concerns the relative contribution of the addends to their sum. By ''even'' portioning, Mandelbrot meant that the addends were of same [[order of magnitude]], otherwise he considered the portioning to be ''concentrated''. Given the [[Moment (mathematics)#Significance of the moments|moment]] of order ''q'' of a [[random variable]], Mandelbrot called the root of degree ''q'' of such moment the ''scale factor'' (of order ''q'').

The seven states are:

# Proper mild randomness: short-run portioning is even for ''N''&amp;nbsp;=&amp;nbsp;2, e.g. the [[normal distribution]]
# Borderline mild randomness: short-run portioning is concentrated for ''N''&amp;nbsp;=&amp;nbsp;2, but eventually becomes even as ''N'' grows, e.g. the [[exponential distribution]] with rate ''λ''&amp;nbsp;=&amp;nbsp;1 (and so with expected value&amp;nbsp;1/''λ''&amp;nbsp;=&amp;nbsp;1)
# Slow randomness with finite delocalized moments: scale factor increases faster than ''q'' but no faster than &lt;math&gt;\sqrt[w]{q}&lt;/math&gt;, ''w''&amp;nbsp;&lt;&amp;nbsp;1
# Slow randomness with finite and localized moments: scale factor increases faster than any power of ''q'', but remains finite, e.g. the [[lognormal]] distribution
# Pre-wild randomness: scale factor becomes infinite for ''q''&amp;nbsp;&gt;&amp;nbsp;2, e.g. the [[Pareto distribution]] with ''α''&amp;nbsp;=&amp;nbsp;2.5
# Wild randomness: infinite second moment, but finite moment of some positive order, e.g. the [[Pareto distribution]] with ''α''&amp;nbsp;=&amp;nbsp;1.5
# Extreme randomness: all moments are infinite, e.g. the [[Pareto distribution]] with &lt;math&gt;\alpha\le 1&lt;/math&gt;

Wild randomness has applications outside financial markets, e.g. it has been used in the analysis of turbulent situations such as wild [[forest fire]]s.&lt;ref&gt;''The Economics of Forest Disturbances: Wildfires, Storms and Invasive Species'' by Thomas P. Holmes, Jeffrey P. Prestemon, and Karen L. Abt. 2008. Springer: Dordrecht, The Netherlands. 422 p. {{isbn|978-1-4020-4369-7}}&lt;/ref&gt;

Using elements of this distinction, in March 2006, a year before the [[Financial crisis of 2007–2010]], and four years before the [[2010 Flash Crash|Flash crash]] of May 2010, during which the [[Dow Jones Industrial Average]] had a 1,000 point [[intraday]] swing within minutes,&lt;ref&gt;[https://www.wsj.com/articles/SB10001424052748704370704575227754131412596?mod=rss_com_mostcommentart ''Wall Street Journal'' May 11, 2010]&lt;/ref&gt; Mandelbrot and [[Nassim Taleb]] published an article in the ''[[Financial Times]]'' arguing that the traditional "bell curves" that have been in use for over a century are inadequate for measuring risk in financial markets, given that such curves disregard the possibility of sharp jumps or discontinuities. Contrasting this approach with the traditional approaches based on [[random walk]]s, they stated:&lt;ref&gt;Benoît Mandelbrot and Nassim Taleb (23 March 2006), "[http://www.ft.com/cms/s/2/5372968a-ba82-11da-980d-0000779e2340.html A focus on the exceptions that prove the rule]", ''Financial Times''.&lt;/ref&gt; 
&lt;blockquote&gt;
We live in a world primarily driven by random jumps, and tools designed for random walks address the wrong problem.
&lt;/blockquote&gt;

Mandelbrot and Taleb pointed out that although one can assume that the odds of finding a person who is several miles tall are extremely low, similar excessive observations can not be excluded in other areas of application. They argued that while traditional bell curves may provide a satisfactory representation of height and weight in the population, they do not provide a suitable modeling mechanism for market risks or returns, where just ten trading days represent 63 per cent of the returns of the past 50 years.

==Definitions==

===Doubling convolution===

If the probability density of &lt;math&gt;U=U'+U''&lt;/math&gt; is denoted &lt;math&gt;p_{2} (u)&lt;/math&gt;, then it can be obtained by the double convolution &lt;math&gt;p_{2}(x)=\int p(u) p(x-u)du&lt;/math&gt;.

===Short run portioning ratio===

When u is known, the conditional probability density of u' is given by the portioning ratio:

:&lt;math&gt;\frac{p(u')p(u-u')}{p_{2}(u)}&lt;/math&gt;

===Concentration in mode===

In many important cases, the maximum of p(u')p(u-u') occurs near u'=u/2, or near u'=0 and u'=u. Take the logarithm of p(u')p(u-u') and write:

&lt;math&gt;\Delta(u)=2 \log p(u/2)-[\log p(0) +\log p(u)]&lt;/math&gt;

*If log p(u) is [[concave function|cap-convex]], the portioning ratio is maximum for u'=u/2
*If log p(u) is straight, the portioning ratio is a constant
*If log p(u) is [[convex function|cup-convex]], the portioning ratio is minimum for u'=u/2

===Concentration in probability===

Splitting the doubling convolution in 3 parts gives:

:&lt;math&gt;p_{2}(x)=\int_{0}^{x} p(u)p(x-u)du=\left \{ \int_{0}^{\tilde x} + \int_{\tilde x}^{x- \tilde x} + \int_{x- \tilde x}^{x} \right \} p(u)p(x-u)du=I_{L}+I_{0}+I_{R}&lt;/math&gt;

p(u) is short-run concentrated in probability if it is possible to select &lt;math&gt;\tilde u(u)&lt;/math&gt; so that the middle interval of (&lt;math&gt;\tilde u, u-\tilde u&lt;/math&gt;) has the following two properties as u→∞:

* I&lt;sub&gt;0&lt;/sub&gt;/p&lt;sub&gt;2&lt;/sub&gt;(u) → 0
* &lt;math&gt;(u-2 \tilde u) u&lt;/math&gt; does not → 0

===Localized and delocalized moments===

Consider the formula &lt;math&gt;\operatorname{E}[U^{q}] = \int_{0}^\infty u^{q} p(u) du&lt;/math&gt;, if p(u) is the [[Power law|scaling distribution]] the integrand is maximum at 0 and ∞, on other cases the integrand may have a sharp global maximum for some value &lt;math&gt;\tilde u_{q}&lt;/math&gt; defined by the following equation:

:&lt;math&gt;0=\frac{d}{du} (q \log u + \log p(u))=\frac{q}{u}-|\frac{d \log p(u)}{du}|&lt;/math&gt;

One must also know &lt;math&gt;u^{q}p(u)&lt;/math&gt; in the neighborhood of &lt;math&gt;\tilde u_{q}&lt;/math&gt;. The function &lt;math&gt;u^{q}p(u)&lt;/math&gt; often admits a "Gaussian" approximation given by:

:&lt;math&gt;\log[u^{q}p(u)]=\log p(u) +qu=constant-(u-\tilde u_{q})^{2}\tilde \sigma^{-2/2}_{q}&lt;/math&gt;

When &lt;math&gt;u^{q}p(u)&lt;/math&gt; is well-approximated by a Gaussian density, the bulk of &lt;math&gt;\operatorname{E}[U^{q}]&lt;/math&gt; originates in the "q-interval" defined as
&lt;math&gt;[\tilde u_{q}-\tilde \sigma_{q},\tilde u_{q}+\tilde \sigma_{q}]&lt;/math&gt;. The Gaussian q-intervals greatly overlap for all values of &lt;math&gt;\sigma&lt;/math&gt;. The Gaussian moments are called ''delocalized''. The lognormal's q-intervals are uniformly spaced and their width is independent of q; therefore if the log-normal is sufficiently skew, the q-interval and (q+1)-interval do not overlap. The lognormal moments are called ''uniformly localized''. In other cases, neighboring q-intervals cease to overlap for sufficiently high q, such moments are called ''asymptotically localized''.

==The seven states of randomness==

*Proper mild randomness: Short-run portioning is even for N=2.
*Borderline mild randomness: Short-run portioning is concentrated for N=2, but becomes even when N exceeds some finite threshold.
*Slow randomness with finite and delocalized moments: loosely characterized by either &lt;math&gt;P^{-1}&lt;/math&gt; increasing faster than &lt;math&gt;|\log x|&lt;/math&gt; but no faster than &lt;math&gt;|\log x|^{1/w}&lt;/math&gt;, with w&lt;1 or by &lt;math&gt;\operatorname[{E}U^{q}]^{1/q}&lt;/math&gt; increasing faster than q but no faster than a power of &lt;math&gt;q^{1/w}&lt;/math&gt;.
*Slow randomness with finite and localized moments: loosely characterized by either &lt;math&gt;P^{-1}&lt;/math&gt; increasing faster than any power &lt;math&gt;|\log x|^{1/2}&lt;/math&gt; but less rapidly than any function of the form &lt;math&gt;e^{|\log x|^{\gamma}}&lt;/math&gt; with γ&lt;1, or by &lt;math&gt;\operatorname[{E}U^{q}]^{1/q}&lt;/math&gt; increasing faster than any power of q, but remaining finite.
*Pre-wild randomness: loosely characterized by &lt;math&gt;P^{-1}&lt;/math&gt; increasing more rapidly than any functions of the form &lt;math&gt;e^{|\log x|^{\gamma}}&lt;/math&gt; with γ&lt;1 but less rapidly than &lt;math&gt;x^{-1/2}&lt;/math&gt; or by &lt;math&gt;\operatorname[{E}U^{q}]^{1/q}&lt;/math&gt; being infinite when q≥α≥2.
*Wild randomness: characterized by &lt;math&gt;\operatorname[{E}U]^{2}=\infty&lt;/math&gt;, but &lt;math&gt;\operatorname[{E}U]^{q}&lt;\infty&lt;/math&gt; for some q&gt;0, however small.
*Extreme randomness: characterized by &lt;math&gt;\operatorname[{E}U]^{q}=\infty&lt;/math&gt; for all q&gt;0.

==See also==
* [[History of randomness]]
* [[Random sequence]]
* [[Fat-tailed distribution]]
* [[Heavy-tailed distribution]]
* [[Daubechies wavelet]] for a system based on infinite moments (chaotic waves)

==References==
{{Reflist}}

[[Category:Fractals]]
[[Category:Statistical randomness]]</text>
      <sha1>nzgt3di65ao28uxgt3bglkylxfg9cc8</sha1>
    </revision>
  </page>
  <page>
    <title>Sheila Greibach</title>
    <ns>0</ns>
    <id>532678</id>
    <revision>
      <id>853755959</id>
      <parentid>835734363</parentid>
      <timestamp>2018-08-06T20:23:31Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:Women in technology]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10841">{{multiple issues|
{{Like resume|date=January 2014}}
{{BLP sources|date=January 2014}}
{{Citation style|date=January 2014}}
}}

{{Infobox scientist 
|name = Sheila Greibach
|birth_date = {{Birth date and age|1939|10|6|mf=y}} 
|birth_place = [[New York City]], [[New York (state)|New York]], [[United States]]
|residence = [[California]], [[United States]] 
|death_date = 
|death_place = 
|field = [[Theoretical computer science|Theoretical Computer Science]] &lt;br&gt; [[Formal language]] in Computing &lt;br&gt;[[Automata]] &lt;br&gt; [[Computational complexity theory|Computational Complexity]] &lt;br&gt; [[Compiler| Compiler Theory]] 
|work_institution = [[University of California, Los Angeles]]&lt;br&gt;[[Harvard University]] 
|alma_mater = [[Radcliffe College]] &lt;br/&gt; [[Harvard University]] 
|doctoral_advisor = Anthony Oettinger
|doctoral_students = [[Ronald V. Book]],  [[Michael J. Fischer]], [[Jean Gallier]]
|known_for = [[Greibach normal form]], [[Greibach's theorem]]
|prizes =
|religion =
|footnotes = 
}}

'''Sheila Adele Greibach''' (born 6 October 1939 in New York City) is a researcher in [[formal language]]s in computing, [[automata]], [[compiler]] theory (in particular), and [[computer science]]. She is an Emeritus Professor of [[Computer Science]] at the [[UCLA|University of California, Los Angeles]], and has worked with [[Seymour Ginsburg]] and [[Michael A. Harrison]] in [[context-sensitive grammar|context-sensitive parsing]] using the [[stack automaton]] model.

Besides establishing the normal form ([[Greibach normal form]]) for [[context-free grammar]]s, in 1965, she also investigated properties 
of [[W-grammar]]s, [[pushdown automata]], and [[decidability problems]].

==Early career==
Greibach earned in 1960 her A.B. degree from [[Radcliffe College]] in [[linguistics]] and [[applied mathematics]] ([[summa cum laude]]), and her A.M. degree in 1962 also from there. In 1963, she achieved her PhD at [[Harvard University]], advised by Anthony Oettinger.&lt;ref name="mathgene"&gt;{{MathGenealogy|id=25274}}&lt;/ref&gt; The title of her PhD thesis is "Inverses of Phrase Structure Generators".

She continued to work at Harvard at the Division of Engineering and Applied Physics, until 1969 when she moved to the [[University of California in Los Angeles|UCLA]], where she has been professor since 1970 until present (as of March 2014).

==Work and contributions==

Among her students were [[Ronald V. Book]] and [[Michael J. Fischer]].
The following list indicates some of her work. The top portion of the list is from the [http://www.acm.org/dl ACM Digital Library] and the remainder from the [https://web.archive.org/web/20040404040851/http://theory.lcs.mit.edu/~dmjones/FOCS/ FOCS Bibliography] by David M. Jones.

===From ACM Digital Library===

"Jump PDA's, deterministic context-free languages, principal AFDLs and polynomial time recognition (Extended Abstract)," Proceedings of the fifth annual ACM symposium on Theory of Computing, April 1973

:Every [[deterministic context-free language]] can be accepted by a deterministic finite delay [[Pushdown automaton|pda]] with jumps. Increasing the number of types or occurrences of jumps increases the family of languages accepted with finite delay. Hence the family of deterministic context-free language is a principal AFDL; there is a context-free language &lt;math&gt;L_0&lt;/math&gt; such that every context-free language is an inverse [[Generalized sequential machine|gsm]] image of &lt;math&gt;L_0&lt;/math&gt; or &lt;math&gt;L_0 - \{e\}&lt;/math&gt;.

"Some restrictions on W-grammars"
Proceedings of the sixth annual ACM symposium on Theory of computing, April 1974

:The effect of some restrictions on [[W-grammar]]s (the formalization of the syntax of [[ALGOL 68]]) are explored. Two incomparable families examined at length are WRB (languages generated by normal regular-based W-grammars) and WS (languages generated by simple W-grammars). Both properly contain the context-free languages and are properly contained in the family of quasirealtime languages. In addition, WRB is closed under nested iterate ...

"An Infinite Hierarchy of Context-Free Languages," ''[[Journal of the ACM]],''  Volume 16 Issue 1, January 1969

"A New Normal-Form Theorem for Context-Free Phrase Structure Grammars," ''[[Journal of the ACM|JACM]],''  Volume 12 Issue 1, January 1965

"The Unsolvability of the Recognition of Linear Context-Free Languages," ''[[Journal of the ACM|JACM]],''  Volume 13 Issue 4, October 1966
:The problem of whether a given context-free language is linear is shown to be recursively undecidable.

====Co-authored works====

"Multitape AFA," co-authored with Seymour Ginsburg, ''[[Journal of the ACM]]'',  Volume 19 Issue 2, April 1972

"Superdeterministic PDAs: A Subcase with a Decidable Inclusion problem", co-authored with E. P. Friedman, "[[Journal of the ACM|JACM]]", October 1980, Volume 27 Issue 4

"Stack automata and compiling," co-authored with Seymour Ginsburg and Michael A. Harrison, "[[Journal of the ACM|JACM]]", January 1967, Volume 14 Issue 1

:Compilation consists of two parts, recognition and translation. A mathematical model is presented which embodies salient features of many modern compiling techniques. The model, called the stack automaton, has the desirable feature of being deterministic in nature. This deterministic device is generalized to a nondeterministic device (nondeterministic stack automaton) and particular instances of this more general device are noted. Sets accepted by nondeterministic stack automata are recursi ...

"Quasi-realtime languages (Extended Abstract)," co-authored with Ronald V. Book, Proceedings of the first annual ACM symposium on Theory of Computing, May 1969

:Quasi-realtime languages are the languages accepted by nondeterministic multitape [[Turing machine]]s in real time. The family of quasi-realtime languages forms an abstract family of languages closed under intersection, linear erasing, and reversal. It is identical with the family of languages accepted by nondeterministic multitape Turing machines in linear time. Every quasi-realtime language can be accepted in real time by a non-deterministic one stack, one pushdown store machine, and can be e ...

"One-way stack automata," co-authored with Seymour Ginsburg and Michael A. Harrison, "[[Journal of the ACM|JACM]]", April 1967, Volume 14 Issue 2

:A number of operations which either preserve sets accepted by one-way stack automata or preserve sets accepted by deterministic one-way stack automata are presented. For example, sequential transduction preserves the former; set complementation, the latter. Several solvability questions are also considered.

"Tape- and time-bounded Turing acceptors and AFLs (Extended Abstract)"
co-authored with Ronald V. Book and Ben Wegbreit, Proceedings of the second annual ACM symposium on Theory of computing, May 1970

:Complexity classes of formal languages defined by time- and tape-bounded Turing acceptors are studied with the aim of showing sufficient conditions for these classes to be AFLs and to be principal AFLs.

"Uniformly erasable AFL", co-authored with Seymour Ginsburg and Jonathan Goldstine, Proceedings of the fourth annual ACM symposium on Theory of computing, May 1972

:This paper showed that a number of well-known families have property (*). In particular, the authors proved that the family of context-free languages does indeed have this property. In addition, we show that several familiar subfamilies of the context-free languages, such as the [[one-counter language]]s, have property (*). Finally, we show that there are families satisfying (*) which are not subfamilies of the context-free languages, for we prove that any family generated from one-let ...{{Clarify|date=March 2013}}

;'''Formal parsing systems'''
:Sheila A. Greibach
:August 1964
:Communications of the ACM,  Volume 7 Issue 8

:Automatic syntactic analysis has recently become important for both [[natural language]] data processing and [[Syntax-directed translation|syntax-directed]] compilers. A formal parsing system G = (V, &amp;mu;, T, R) consists of two finite disjoint vocabularies, V and T, a many-many map, &amp;mu;, from V onto T, and a recursive set R of strings in T called syntactic sentence classes ...

===From FOCS Bibliography===

:Seymour Ginsburg and Sheila Greibach.
:Deterministic context free languages.
:In Proceedings of the Sixth Annual [[Symposium on Switching Circuit Theory and Logical Design]], pages 203-220. IEEE, 1965.

:Seymour Ginsburg, Sheila A. Greibach, and Michael A. Harrison.
:One-way stack automata (extended abstract).
:In Conference Record of 1966 Seventh Annual [[Symposium on Switching and Automata Theory]], pages 47-52, Berkeley, California, 26–28 October 1966. IEEE.

:Sheila A. Greibach.
:An infinite hierarchy of context-free languages.
:In Conference Record of 1967 Eighth Annual Symposium on Switching and Automata Theory, pages 32-36, Austin, Texas, 18–20 October 1967. IEEE.

:Seymour Ginsburg and Sheila Greibach.
:Abstract families of languages.
:In Conference Record of 1967 Eighth Annual Symposium on Switching and Automata Theory, pages 128-139, Austin, Texas, 18–20 October 1967. IEEE. Citations.

:Sheila Greibach.
:Checking automata and one-way stack languages (extended abstract).
:In Conference Record of 1968 Ninth Annual Symposium on Switching and Automata Theory, pages 287-291, Schenectady, New York, 15–18 October 1968. IEEE. Citations.

:Sheila A. Greibach.
:Full AFLs and nested iterated substitution.
:In Conference Record of 1969 Tenth Annual Symposium on Switching and Automata Theory, pages 222-230, Waterloo, Ontario, Canada, 15–17 October 1969. IEEE.

:J. W. Carlyle, S. A. Greibach, and A. Paz.
:A two-dimensional generating system modeling growth by binary cell division (preliminary report).
:In 15th Annual Symposium on Switching and Automata Theory, pages 1-12, The University of New Orleans, 14–16 October 1974. IEEE.

:S. A. Greibach.
:Formal languages: Origins and directions.
:In 20th Annual [[Symposium on Foundations of Computer Science]], pages 66-90, San Juan, Puerto Rico, 29–31 October 1979. IEEE.

===Others===
:Ronald Book, Shimon Even, Sheila Greibach and Gene Ott.
:Ambiguity in Graphs and Expressions.
:IEEE Transactions on Computers, vol. c-20, No. 2, February 1971. IEEE.

==See also==
*[[Greibach normal form]]
*[[Abstract family of acceptors]]
*[[Greibach's theorem]]

== References ==
{{reflist}}

== External links ==

* [http://www.cs.ucla.edu/sheila-greibach/ Sheila Greibach's Home page at UCLA]

{{Authority control}}

{{DEFAULTSORT:Greibach, Sheila}}
[[Category:1939 births]]
[[Category:Living people]]
[[Category:University of California, Los Angeles faculty]]
[[Category:Theoretical computer scientists]]
[[Category:Women computer scientists]]
[[Category:Radcliffe College alumni]]
[[Category:Harvard University alumni]]</text>
      <sha1>9ts3m7b90gdcggdy1msg4mmdjjaeq9u</sha1>
    </revision>
  </page>
  <page>
    <title>Shigefumi Mori</title>
    <ns>0</ns>
    <id>794811</id>
    <revision>
      <id>847400200</id>
      <parentid>847391989</parentid>
      <timestamp>2018-06-25T02:47:26Z</timestamp>
      <contributor>
        <username>Galoisfka</username>
        <id>33688401</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4178">{{Infobox scientist
|name              = Shigefumi Mori
|image             = Shigefumi_Mori.jpg
|image_size       = 224px
|caption           = Shigefumi Mori
|birth_date        = {{birth date and age|1951|02|23}}
|birth_place       = [[Nagoya]], [[Japan]]
|death_date        = 
|death_place       = 
|nationality       = [[Japan]]ese
|field             = [[Mathematician]]
|work_institutions = [[Kyoto University]]
|alma_mater        = [[Kyoto University]]
|doctoral_advisor  = [[Masayoshi Nagata]]
|doctoral_students = 
|known_for         = [[Algebraic geometry]]
|awards            = [[Fields Medal]] (1990)&lt;br&gt;[[Cole Prize]] (1990)
}}
{{nihongo|'''Shigefumi Mori'''|森 重文|Mori Shigefumi|extra=born February 23, 1951}} is a [[Japan]]ese [[mathematician]], known for his work in [[algebraic geometry]], particularly in relation to the classification of [[three-fold]]s.

He generalized the classical approach to the classification of [[algebraic surfaces]] to the classification of algebraic [[three-folds]]. The classical approach used the concept of [[minimal model (birational geometry)|minimal model]]s of [[algebraic surfaces]]. He found that the concept of [[minimal model (birational geometry)|minimal models]] can be applied to [[three-folds]] as well if we allow some [[Singularity (mathematics)|singularities]] on them.

The extension of Mori’s results to dimensions higher than three is called the [[Mori program]] and, as of 2006, is an active area of [[algebraic geometry]].

He was awarded the [[Fields Medal]] in 1990 at the [[International Congress of Mathematicians]].

He was visiting professor at [[Harvard University]] during 1977–1980, the [[Institute for Advanced Study]] in 1981–82, [[Columbia University]] 1985–87 and the [[University of Utah]] for periods during 1987–89 and again during 1991–92. He has been a professor at [[Kyoto University]] since 1990.

He has been elected president of the [[International Mathematical Union]], becoming the first head of the group from East Asia.&lt;ref&gt;http://www.japantimes.co.jp/news/2014/08/12/national/kyoto-university-professor-elected-head-international-mathematical-union/&lt;/ref&gt;

== Selected publications ==
* {{cite journal
 | last = Mori
 | first = Shigefumi
 | title = Projective manifolds with ample tangent bundles
 | journal = [[Ann. of Math.]]
 | volume = 110
 | year = 1979
 | pages = 593–606
 | doi = 10.2307/1971241
 | issue = 3
 | jstor = 1971241
 | mr = 0554387
}}
* {{cite journal
 | last = Mori
 | first = Shigefumi
 | title = Threefolds whose canonical bundles are not numerically effective
 | journal = [[Ann. of Math.]]
 | volume = 116
 | year = 1982
 | pages = 133–176
 | doi = 10.2307/2007050
 | issue = 1
 | jstor = 2007050
 | mr = 0662120
| pmc = 349565
 }}
* {{cite journal
 | last = Mori
 | first = Shigefumi
 | title = Flip theorem and existence of minimal models for 3-folds
 | journal = [[J. Amer. Math. Soc.]]
 | volume = 1
 | year = 1988
 | pages = 117–253
 | doi = 10.2307/1990969
 | issue = 1
 | jstor = 1990969
 | mr = 924704
}}

==See also==
*[[Keel–Mori theorem]]

==References==
{{Reflist}}
*{{MacTutor Biography|id=Mori}}
*{{MathGenealogy|id=100894}}
*[[Heisuke Hironaka]], [https://books.google.com/books?id=q6eSjV-0egUC&amp;pg=PA487 The work of Shigefumi Mori.] Fields Medallists Lectures, Michael F. Atiyah (Editor), Daniel Iagolnitzer (Editor); [[World Scientific Publishing]], 2007. {{isbn|981-02-3117-2}}

==External links==
{{Fields medalists}}

{{Authority control}}

{{DEFAULTSORT:Mori, Shigefumi}}
[[Category:1951 births]]
[[Category:Living people]]
[[Category:20th-century Japanese mathematicians]]
[[Category:21st-century Japanese mathematicians]]
[[Category:Fields Medalists]]
[[Category:Algebraic geometers]]
[[Category:People from Nagoya]]
[[Category:Kyoto University alumni]]
[[Category:Kyoto University faculty]]
[[Category:Nagoya University faculty]]
[[Category:Foreign Members of the Russian Academy of Sciences]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Persons of Cultural Merit]]
[[Category:University of Utah faculty]]
[[Category:Columbia University faculty]]
[[Category:Harvard University faculty]]</text>
      <sha1>ej2660gya4kndduotb0rh309k4oq7l6</sha1>
    </revision>
  </page>
  <page>
    <title>Steven Matheson</title>
    <ns>0</ns>
    <id>6319281</id>
    <revision>
      <id>871728407</id>
      <parentid>860266500</parentid>
      <timestamp>2018-12-03T02:09:18Z</timestamp>
      <contributor>
        <ip>92.13.218.155</ip>
      </contributor>
      <comment>/* Reception */Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22599">{{Use dmy dates|date=May 2011}}
{{Use Australian English|date=May 2011}}
{{Infobox soap character
| series         = Home and Away
| name           = Steven Matheson
| image          = Steven Matheson.jpg
| imagesize      = 200px
| portrayer      = [[Adam Willits]]   
| introducer     = Alan Bateman (1988) &lt;br /&gt; John Holmes (1995, 2000) &lt;br /&gt; Julie McGauran (2002, 2003) &lt;br /&gt; [[Cameron Welsh]] (2008)    
| first          = 17 January 1988
| last           = 3 April 2008
| years          = 1988–1991, 1995–1998, 2000, 2002, 2003, 2008 
| occupation     = Student at Summer Bay High (1988–1990) &lt;br /&gt; Teacher at Summer Bay High (1995–1996) &lt;br /&gt; Computer Technician (1997–)
| classification = [[List of past Home and Away characters|Former; regular]]
| born           = 22 March 1973 &lt;!-- Steven celebrated his 15th birthday on 22 March 1988 (episode 47) --&gt;
| father         = Brett Matheson 
| mother         =  Martha Matheson 
| wife           = [[Selina Roberts]] 
| uncles         = [[Philip Matheson]] 
| kids           = 2 unknown 
| books          = ''The Steven Matheson Story''&lt;br /&gt;''Summer Bay Blues''&lt;br /&gt;''Scandal at Summer Bay''
}}
'''Steven Matheson''' is a [[character (arts)|fictional character]] from the Australian [[Seven Network|Channel Seven]] [[soap opera]] ''[[Home and Away]]'', played by [[Adam Willits]]. Steven was created by Alan Bateman as one of the serial's original characters and he first appeared in the pilot episode. Willits received the role after being one of over three hundred actors to audition for the roles of the serial's foster children. He was a regular cast member from 1988 to 1991 and again between 1995 and 1996. He has continued to make guest appearances in from 1997 until 2008. Steven is characterised in his early years by his quiet and studious persona, he later becomes problematic as he grows older. His main storylines have focused on his early tragedies in which his family die, bullying, his first kiss with [[Narelle Smart]] (Amanda Newman-Phillips) and his on/off relationship with [[Selina Roberts]] ([[Tempany Deckert]]). Critics of the serial have favoured his appearance and have subsequently branded him a "heart-throb" because of his good looks. Others have commented that he grew up quickly on-screen and eventually become a problematic character.

==Casting==
In 1987 over three hundred actors auditioned for the roles of the Fletcher's foster children.&lt;ref&gt;[[#reforam|Oram 1989]], p.15.&lt;/ref&gt; Eventually sixteen-year-old Adam Willits was offered the part of Steven. Prior to the role Willits had gained a fair amount of experience as a child actor.&lt;ref name=nine&gt;[[#reforam|Oram 1989]], p.97.&lt;/ref&gt; In 1989 Willits confirmed in the ''"Home and Away Annual"'' that he was happy to stay with the serial and watch Steven develop.&lt;ref name=fotty/&gt; In 1990, Willits decided to leave the serial to pursue other projects but remained on-screen until the following year.&lt;ref&gt;[[#refnicholls|Kesta and Nicholls 1992]], p.21.&lt;/ref&gt;

Willits returned to ''Home and Away'' in 1995-1996, and returned for an additional stint in 1997.&lt;ref&gt;{{cite journal|title=Twenty years of Home and Away Part one 1988–1997|journal=[[TV Week]]|date=12–18 January 2008|pages=2–11|publisher=[[ACP Magazines]]}}&lt;/ref&gt; In 1998 Willits filmed a conclusion to Steven's storyline on location in the UK.&lt;ref&gt;{{cite journal|title=Twenty years of Home and Away Part two 1998–2007|journal=[[TV Week]]|date=19–25 January 2008|pages=2|publisher=[[ACP Magazines]]}}&lt;/ref&gt; In 2002 Willits returned alongside numerous ex-cast members to film a special storyline for the "150th anniversary" of Summer Bay.&lt;ref&gt;{{cite web|last=Hooks|first=Barbara|title=Networking|url=http://newsstore.fairfax.com.au/apps/viewDocument.ac?page=1&amp;sy=nstore&amp;kw=adam+willits&amp;pb=all_ffx&amp;dt=selectRange&amp;dr=entire&amp;so=relevance&amp;sf=text&amp;sf=headline&amp;rc=10&amp;rm=200&amp;sp=nrm&amp;clsPage=1&amp;docID=AGE0205099MO9415ELKU|work=[[The Age]]|publisher=([[Fairfax Media]])|accessdate=16 December 2011|date=9 May 2002}}&lt;/ref&gt;

==Character development==
In the 1989 edition of the ''"Home and Away Annual"'', Steven is described in his years as being "quiet and studious, but with an inventive mind. When he came to the Flectchers, he was disturbed, and was having terrible nightmares about his parents' death." They also add "Steven is liable to become a wonderfully caring and informed person, or a pompous brat."&lt;ref name=fott&gt;[[#refjclayden|J Clayden 1989]], p.20.&lt;/ref&gt; In the ''"Home and Away Annual"'' he is described as having the life of any average teenager.&lt;ref&gt;[[#refdesmond|Desmond 1990]], p.9.&lt;/ref&gt; Willits described Steven stating: "A nice guy, not very trendy though".&lt;ref name=fott/&gt; Willits has also stated it's a challenge to play Steven because he is so different from him, so much so he did not relate to him, he also branded Steven as "not very outgoing".&lt;ref name=fotty/&gt; After two years of playing the role, Willits said that Steven "started off as a bit of a bookworm but as he has grown up he has found distractions more engaging than academia!"&lt;ref name=stevoo&gt;[[#refdesmond|Desmond 1990]], p.12.&lt;/ref&gt; Willits added that Steven is "not the trendiest guy in the world, but thankfully as time passes he gets a bit more wayward."&lt;ref&gt;[[#refdesmond|Desmond 1990]], p.55.&lt;/ref&gt; In another interview he states: "I love to get out of his character when shooting is finished, and to ruffle up my hair which is all brushed like Steven's."&lt;ref name=nine/&gt; While interviewed by Clive Hopwood for the book ''Home and Away Special'', Willits said that Steven's development was slow because he remained "a bit of a dork". He added that Steven was destined for "exciting things".&lt;ref&gt;[[#refhopwood|Hopwood 1990]], p.45.&lt;/ref&gt;

Steven's first kiss is with fellow character [[Narelle Smart]] (Amanda Newman-Phillips), who is three years older than he is (being seventeen at the time). Of this Willits states: "I'd go for an older woman, if Steven can, I certainly can."&lt;ref name=fotty&gt;[[#refjclayden|J Clayden 1989]], p.21.&lt;/ref&gt; Discussing the scenes and Steven's reasons, Willits states: "In the script he had this plan to get Narelle to kiss me, because he has done a survey and he's a pretty hot kisser. It wasn't as though they were in love though." He also named it as one of Steven's greatest moments during the early years.&lt;ref name=stevoo/&gt; Newman-Phillips describes the filming of the storyline stating: "Narelle seduces Steven and when it came to the kissing scene we were both very nervous. It was the first for both of us and we just couldn't get the scene right, so we did some extra rehearsing. The kiss only lasted a minute, but in the end it took us a couple of hours to get it perfect for the cameras."&lt;ref name=even&gt;{{cite news|last=Clifford|first=Murray|title=Soap stars describe the terror of stardom - The price of fame|url=https://news.google.com/newspapers?id=VtdAAAAAIBAJ&amp;sjid=e6YMAAAAIBAJ&amp;pg=7206,2525747&amp;dq=adam+willits&amp;hl=en|accessdate=2011-02-08|newspaper=[[Evening Times]]|date=11 June 1990|agency=([[Newsquest]]&lt;!-- |archiveurl=http://www.webcitation.org/5wKpb33Cu|archivedate=8 February 2011--&gt;)}}&lt;/ref&gt; Whilst interviewed by ''[[TV Week]]'', Willits stated: "When you consider rehearsals and retakes, we kissed a hell of a lot. It was great. She gave me all the pointers".&lt;ref&gt;[[#reforam|Oram 1989]], p.98.&lt;/ref&gt; The serial later cast [[Kate Raison]] to play artist [[Jennifer Atkinson]], a new love interest for Steven. In the ''Home and Away Annual Authorised Edition'', Kesta Desmond said that their romance would develop into a "torrid affair" and that it could "all end in tears".&lt;ref&gt;[[#refnicholls|Kesta and Nicholls 1992]], p.60.&lt;/ref&gt;

In another storyline school secretary [[Joanne Brennan]] ([[Kimberley Joseph]]) starts up an obsessive campaign to seduce Steven.&lt;ref name=Malins&gt;{{Cite news|author= Malins, Sue|url=http://www.thefreelibrary.com/I've+had+fun+being+a+bitch%3b+Kimberley+Joseph.-a061322974|title= I've had fun being a bitch|work= [[Daily Mirror]]|publisher=[[Trinity Mirror]]|date= 26 April 1996|accessdate=2011-03-07}}&lt;/ref&gt; Steven does not show any interest in return. Joseph said "She goes out of her way to wreck any other romance he has - and ends up stalking him."&lt;ref name=Malins/&gt; Joanne continues her "bitchy" campaign until she departs.&lt;ref name=Malins/&gt; Steven had a drawn out relationship with his student [[Selina Roberts]] ([[Tempany Deckert]]), their relationship takes many "twists" along the way.&lt;ref name=twisted/&gt; Selina leaves Steven on their wedding day. Deckert said it was a "typical soap wedding" with many mishappenings.&lt;ref&gt;{{cite interview |last=Deckert |first=Tempany |subjectlink=Tempany Deckert |interviewer=[[Mel and Sue|Mel Giedroyc and Sue Perkins]] |publisher =[[Channel 4]] |date=20 November 1997 |work=[[Light Lunch]]}}&lt;/ref&gt; The conclusion to their storyline before Steven's final departure of the nineties, was filmed in [[Ironbridge, Shropshire]].&lt;ref name=shrop&gt;{{cite web|title=Australian soap - English water|url=http://www.thefreelibrary.com/Australian+soap+-+English+water.-a060850871|work=[[Birmingham Post]]|publisher=([[Trinity Mirror]])|accessdate=2011-03-07|date=10 January 1998}}&lt;/ref&gt; It was the first ever episode to be filmed abroad for the serial.&lt;ref name=twisted/&gt; 

When Steven returned to the show in 2002, it was revealed that he had been living in Hong Kong with Selina and taken a job as a IT consultant.&lt;ref&gt;{{cite journal |title=Many unhappy returns |journal=[[Inside Soap]] |date=15-28 March 2003 |issue=227 |pages=28-29 |publisher=([[Hachette Filipacchi UK]])}}&lt;/ref&gt;

==Storylines==

===Backstory===
Steven was born in 1973 in [[Hornsby, New South Wales]] as the only son of Brett and Martha Matheson. One night in 1987, while Steven was staying over at his friend, Danny's house, he heard sirens belonging to fire engines and discovered that the family home was on fire and Brett and Martha were trapped. The Mathesons had put bars on the windows previously so escape was impossible. Brett and Martha died in the blaze and Steven, with no available extended family, was placed into a temporary care home until [[Tom Fletcher (Home and Away)|Tom]] ([[Roger Oakley]]) and [[Pippa Fletcher]] ([[Vanessa Downing]]) fostered him.

===1988-91===
Steven first appears on screen in the pilot when he and his foster family sit down to celebrate Tom's 40th birthday. Later, when Tom announces to the family that he is being retrenched, Steven offers to live elsewhere as he feels the Fletchers will be unable to afford looking after him. The family eventually relocate from The city to country town [[Summer Bay]]. Early into the Fletchers' arrival Steven manages to win the approval of foster brother [[Frank Morgan (Home and Away)|Frank Morgan]] ([[Alex Papps]]), who has been suspicious of him since his arrival. Steven also manages to befriend local tomboy [[Bobby Simpson (Home and Away)|Bobby Simpson]] ([[Nicolle Dickson]]), who later joins the family. Steven asks Frank for advice, he believes no one sees him as a grown up and just as a boy, he starts shaving and trying new things to look older. Steven starts feeling an attraction for Narelle, who is three years older than he is, they later kiss, Steven sees it as a big moment as it's the first time he's kissed a girl. Steven gets his first taste of a real romance when classmate, [[Sandra Barlow]] (Catherine McColl-Jones) shows an interest him. Unfortunately, Sandra's abusive father, [[Sam Barlow (Home and Away)|Sam Barlow]]) (Jeff Truman) takes an immediate dislike to Steven and warns him off. Steven and Sandra continue seeing each other secretly until Sam's behavior culminates in him accidentally shooting his wife and Sandra's mother, Kerry dead. Sandra later leaves the area to stay with a foster family in the city. Steven later has several run-ins with P.E. teacher [[Jeff Samuels]] (Alex Petersons) whose training regimes do not sit well with Steven, the Fletchers or many other people in Summer Bay. Steven is overjoyed when his uncle [[Philip Matheson]] (John Morris), his only living relative arrives in Summer Bay. Philip is later killed in an arson attack on the general store at the hands of [[Dodge (Home and Away)|Brian "Dodge" Forbes]] (Kelly Dingwall), who has a grudge against the owner [[Celia Stewart]] ([[Fiona Spence]]). Steven is devastated and begins having nightmares and flashbacks to his parents' deaths in the fire.

Dodge becomes Tom and Pippa's latest foster child, he strikes up a friendship with Steven and winds him up on multiple occasions about not being macho. Dodge enjoys using Steven to do his essays and he later fools Steven into turning on his former geeky friends over a money dispute. Dodge had in fact, being bullying one of them, when they all attack him, Steven decides to attempt to attack the lads. They are shocked and tell him he's a better person than that. Dodge has a grudge against [[Ruth Stewart (Home and Away)|Roo Stewart's]] ([[Justine Clark]]) boyfriend [[Simon Yates (Home and Away)|Simon Yates]] (Christopher Saunders), who he tries to pin the blame on over the arson attack. He manipulates Steven into attacking him on the beach and vowing revenge. Dodge steals a car and crashes it, Steven takes the blame to protect him, but Dodge reveals it was him and vows to change. Just as everyone trusts him again, he drunkenly confesses to setting the fire that killed Phillip, enraged Steven tries to attack him before he is charged with murder. Steven later leaves to go to university.

===1995-2008===

In 1995, Steven returns and gets a job at Summer Bay High as a teacher, much to [[Donald Fisher (Home and Away)|Donald Fisher's]] ([[Norman Coburn]]) surprise. Everyone is delighted to have him back and he settles back into life with family around. When [[Marilyn Chambers (Home and Away)|Marilyn Chambers]] ([[Emily Symons]]) returns they become better friends and eventually start a relationship, it proves short lived however and they decide it's best to be friends again. Later his student, Selina falls in love with Steven, he tells her they cannot be together because of his job and age difference. However Steven later gives in to his feelings and starts an affair with her, but they later decide to end things. Selina's stalker [[Jeremy Riggs]] (David Stanley) finds out about her and Steven so tries to black mail them, but he hangs himself in the school toilets and [[Irene Roberts]] ([[Lynne McGranger]]) finds out the truth, she files a complaint which sees Steven sacked from his job and everyone in town is shocked to learn about their affair.

Dodge is released from prison and returns to Summer Bay, wanting revenge on Steven. Dodge hides jelly beans in Steven's house and black mails him by stating he will go to the police and tell them he has illegal drugs in his property. Scared Steven becomes extremely affected by his presence, but is happy to find out they're not drugs. Steven and [[Kelly Watson]] (Katrina Hobbs) have an affair behind [[Travis Nash|Travis Nash's]] ([[Nic Testoni]]) back, although Kelly later decides it isn't a good idea and ends things. Kelly helps him set Dodge up for theft. Whilst out on a cruise, Dodge jumps overboard and is presumed dead. The police start a murder investigation with Steven as their prime suspect. Dodge later turns up alive and kidnaps Kelly, when Steven tracks them down they start fighting on the edge of a cliff. In the end they both roll over the edge of the cliff, Steven survives but Dodge remained unfound. After alienating himself from most of the Bay's residents and annoying Pippa when he shows no interest in his foster sister [[Sally Fletcher|Sally Fletcher's]] ([[Kate Ritchie]]) abduction, he decides to rethink his place in the town. Sally is found and goes to hospital and waits for Steven. Steven leaves Pippa a note and flees the town, without saying goodbye to his closest family member Sally.

One year later he returns feeling in a better place. He starts to fall for Selina again, delighted they resume their relationship. This time more people approve and they decide to get married. On their wedding day however, Selina seemingly jilts Steven. She is actually being held hostage by cult leader [[Saul Bennett]] (David Ritchie), later she escapes and Steven is relieved to have her back. She shocks him by telling him she no longer wants to marry him after her ordeal. He leaves the bay once more. After another year passes Marilyn and Irene decide to head overseas to, Ironbridge when Selina is severely ill, they arrange for Steven to come and look after her. When he arrives he proposes to Selina, who gladly accepts. They leave the bay together this time. Steven returns in 2000 for Sally's wedding to [[Kieran Fletcher]] ([[Spencer McLaren]]), he reveals that he and Selina still haven't got married. After Keiran's infedelity is discovered, Steven beats him up on the beach which Steven should have been arrested and spent time in prison for. Steven returns again later and reveals he and Selina have married, he returns again the following year and announces he and Selina broke up and he was with someone new. In 2008 he returns when Sally decides to leave Summer Bay, after [[Ric Dalby]] ([[Mark Furze]]) gets in touch with him, he reveals he and Selina got back together. Pippa and Carly also join him, He tells Sally how much she deserves her big send off and they reminisce about the old days when they first moved into the house on the caravan park. After Sally leaves, Steven is not seen on-screen again.

==Reception==
In his book, ''Super Aussie Soaps'', Andrew Mercado describes the moment Steven decides to marry Selina as a scandal because she was his student.&lt;ref&gt;[[#refmercado|Mercado 2004]], p.261.&lt;/ref&gt; In her book ''"Soapbox"'', Hilary Kingsley brands Steven the quietest foster child of Pippa and Tom.&lt;ref&gt;[[#refkingsley|Kingsley 1989]], p.214.&lt;/ref&gt; In the book ''"Home and Away: behind the scenes"'', James Oram comments on Steven's young heart-throb status, stating: "Those who concern themselves with such matters as heart-throbs suggest he is well on his way to joining that select circle. He could be the youngest heart-throb in history, or at least since Romeo caused Juliet's heart to flutter."&lt;ref&gt;[[#reforam|Oram 1989]], p.96.&lt;/ref&gt; He also added that whilst the serial followed the tradition of many other soaps, through Steven and Frank they portrayed many real issues.&lt;ref name=nine/&gt; Jan Moir writing for the ''[[Evening Times]]'' states: "He was orphaned when his parents were killed in a fire and is fast becoming the problem kid on the block."&lt;ref name=lobs&gt;{{cite news|last=Moir|first=Jan|title=The Aussie show that's putting Ramsay Street off the map|url=https://news.google.com/newspapers?id=_-FAAAAAIBAJ&amp;sjid=z6YMAAAAIBAJ&amp;pg=4242,3856601&amp;dq=adam+willits&amp;hl=en|accessdate=2011-02-08|newspaper=[[Evening Times]]|date=13 December 1989|agency=([[Newsquest]]&lt;!-- |archiveurl=http://www.webcitation.org/5wKtaYEgf|archivedate=8 February 2011--&gt;)}}&lt;/ref&gt; The ''[[Birmingham Post]]'' observed Steven's relationship with Selina as a "tale of twists" becoming more "twisted" with time.&lt;ref name=twisted&gt;{{cite web|title=More away than home for TV soap star bride Selina|url=http://www.thefreelibrary.com/More+away+than+home+for+TV+soap+star+bride+Selina.-a060847938|work=[[Birmingham Post]]|publisher=([[Trinity Mirror]])|accessdate=2011-03-07|date=13 January 1998}}&lt;/ref&gt; A columnist for ''[[The Newcastle Herald]]'' chose Steven and Selina's 1998 return episode as one of their "TV Highlights".&lt;ref&gt;{{cite web|title=TV Highlights|url=http://newsstore.fairfax.com.au/apps/viewDocument.ac?page=1&amp;sy=nstore&amp;kw=adam+willits&amp;pb=all_ffx&amp;dt=selectRange&amp;dr=entire&amp;so=relevance&amp;sf=text&amp;sf=headline&amp;rc=10&amp;rm=200&amp;sp=nrm&amp;clsPage=1&amp;docID=news980330_0122_3125|work=[[The Newcastle Herald]]|publisher=([[Fairfax Media]])|accessdate=16 December 2011|date=27 March 1998}}&lt;/ref&gt;

Analysing Steven's early characterisation, a columnist for ''[[Inside Soap]]'' said "once the school swat and a bit of a square, he grew up into an egghead who couldn't get a girl. Duller than one of Alf Stewart's bowling club cheese and wine parties, quiet Steven Matheson seemed destined to stay single." They opined that upon his return in 1995, Steven no longer had trouble finding a partner but had a "problem" finding one his own age.&lt;ref&gt;{{cite journal|date=6–19 April 1996|title=Sexy Stevo!|journal=[[Inside Soap]]|publisher=Attic Futura UK Ltd|page=19|issue=46}}&lt;/ref&gt; Their colleague opined that Steven was the "brightest foster kid" that Pippa had ever fostered.&lt;ref&gt;{{cite journal|title=Pippa's flock!|journal=[[Inside Soap]]|date=27 July – 9 August 1996|issue=54|pages=16|publisher=Attic Futura (UK) Ltd}}&lt;/ref&gt; While another opined that "there was never any doubt that the quiet and studious Steven would end up at uni - even if a passionate fling with an older woman made him think twice about going. Steven passed his HSC with flying colours."&lt;ref&gt;{{cite journal|title=Soap's swots|journal=[[Inside Soap]]|date=December 1992|issue=3|pages=11|publisher=Attic Futura (UK) Ltd}}&lt;/ref&gt;

==References==
{{Reflist}}

==Bibliography==
*{{cite book|last=Desmond|first=Kesta|title=Home and Away Annual|year=1990|publisher=Grandreams Ltd|isbn=0-86227-787-6|ref=refdesmond}}
*{{cite book|last=Desmond|first=Kesta|title=Home and Away Annual Authorised Edition|year=1992|publisher=Grandreams Ltd|isbn=0-86227-863-5|author2=Nicholls, David|ref=refnicholls}}
*{{cite book|last=Hopwood|first=Clive|title=Home and Away Special|year=1990|publisher=World International Publishing LTD|isbn=0-7235-6899-5|ref=refhopwood}}
*{{cite book|last=J Clayden|first=Melanie|title=Home and Away Annual|year=1989|publisher=Grandreams Ltd|isbn=0-86227-687-X|ref=refjclayden}}
*{{cite book|last=Kingsley|first=Hilary|title=Soapbox|year=1989|publisher=Sun Books|location=Pennsylvania|isbn=0-7251-0573-9|ref=refkingsley}}
*{{cite book|last=Mercado|first=Andrew|title=Super Aussie soaps: behind the scenes of Australia's best loved TV shows|year=2004|publisher=Pluto Press Australia|isbn=1-86403-191-3|ref=refmercado}}
*{{cite book|last=Oram|first=James|title=Home and away: behind the scenes|year=1989|publisher=Angus &amp; Robertson|isbn=0-207-16315-4|ref=reforam}}

{{Home and Away characters}}

{{DEFAULTSORT:Matheson, Steven}}
[[Category:Home and Away characters]]
[[Category:Fictional characters introduced in 1988]]
[[Category:Fictional schoolteachers]]
[[Category:Fictional mathematicians]]
[[Category:Fictional karateka]]
[[Category:Fictional orphans]]</text>
      <sha1>mxrmwu4dwweng3b6ag067ole8mw7qxs</sha1>
    </revision>
  </page>
  <page>
    <title>Subspace theorem</title>
    <ns>0</ns>
    <id>8830237</id>
    <revision>
      <id>814475806</id>
      <parentid>787013078</parentid>
      <timestamp>2017-12-09T01:28:45Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=[[Annals of Mathematics|Annals of Mathematics. Second Series]] → journal=[[Annals of Mathematics]] |series=Second Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3390">In mathematics, the '''subspace theorem''' is a result obtained by {{harvs|txt|authorlink=Wolfgang M. Schmidt|first=Wolfgang M. |last=Schmidt|year= 1972}}. It states that if ''L''&lt;sub&gt;1&lt;/sub&gt;,...,''L''&lt;sub&gt;''n''&lt;/sub&gt; are [[linear independence|linearly independent]] [[linear]] [[algebraic form|forms]] in ''n'' variables with [[algebraic number|algebraic]] coefficients and if ε&gt;0 is any given real number, then
the non-zero integer points ''x'' with
:&lt;math&gt;|L_1(x)\cdots L_n(x)|&lt;|x|^{-\epsilon}&lt;/math&gt;
lie in a finite number of [[linear subspace|proper subspaces]] of '''Q'''&lt;sup&gt;''n''&lt;/sup&gt;.

A quantitative form of the theorem, in which the number of subspaces containing all solutions, was also obtained by Schmidt, and the theorem was generalised by {{harvtxt|Schlickewei|1977}} to allow more general [[absolute value (algebra)|absolute values]] on [[number field]]s.

The theorem may be used to obtain results on [[Diophantine equation]]s such as [[Siegel's theorem on integral points]] and solution of the [[S-unit equation]].

==A corollary on Diophantine approximation==
The following corollary to the subspace theorem is often itself referred to as the ''subspace theorem''.
If ''a''&lt;sub&gt;1&lt;/sub&gt;,...,''a''&lt;sub&gt;''n''&lt;/sub&gt; are algebraic such that 1,''a''&lt;sub&gt;1&lt;/sub&gt;,...,''a''&lt;sub&gt;''n''&lt;/sub&gt; are linearly independent over '''Q''' and ε&gt;0 is any given real number, then there are only finitely many rational ''n''-tuples (''x''&lt;sub&gt;1&lt;/sub&gt;/y,...,''x''&lt;sub&gt;''n''&lt;/sub&gt;/y) with
:&lt;math&gt;|a_i-x_i/y|&lt;y^{-(1+1/n+\epsilon)},\quad i=1,\ldots,n.&lt;/math&gt;

The specialization ''n'' = 1 gives the [[Thue–Siegel–Roth theorem]]. One may also note that the exponent 1+1/''n''+ε is best possible by [[Dirichlet's theorem on diophantine approximation]].

==References==
* {{cite book | first1=Enrico | last1=Bombieri | authorlink1=Enrico Bombieri | first2=Walter | last2=Gubler | title=Heights in Diophantine Geometry | series=New Mathematical Monographs | volume=4 | publisher=[[Cambridge University Press]] | location=Cambridge | year=2006 | isbn=978-0-521-71229-3 | zbl=1130.11034 | doi=10.2277/0521846153 | mr=2216774}}
* {{cite journal | last=Schlickewei | first=Hans Peter | title=On norm form equations | journal=[[J. Number Theory]] | doi=10.1016/0022-314X(77)90072-5 | year=1977 | volume=9 | issue=3 | pages=370–380 | mr=0444562 | ref=harv}}
* {{cite journal | last1=Schmidt | first1=Wolfgang M. | authorlink=Wolfgang M. Schmidt | title=Norm form equations | mr=0314761 | year=1972 | journal=[[Annals of Mathematics]] |series=Second Series | volume=96 | pages=526–551 | issue=3 | doi=10.2307/1970824 | ref=harv}}
* {{cite book | last=Schmidt | first=Wolfgang M. | authorlink=Wolfgang M. Schmidt | title=Diophantine approximation | series=Lecture Notes in Mathematics | volume=785 | publisher=[[Springer-Verlag]] | year=1980 | edition=1996 with minor corrections | zbl=0421.10019  | mr=568710 | doi=10.1007/978-3-540-38645-2 | isbn=3-540-09762-7 | location=Berlin}}
* {{cite book | last=Schmidt | first=Wolfgang M. | authorlink=Wolfgang M. Schmidt | title=Diophantine approximations and Diophantine equations | series=Lecture Notes in Mathematics | volume=1467 | publisher=[[Springer-Verlag]] | year=1991 | location=Berlin | isbn=3-540-54058-X | zbl=0754.11020 | mr=1176315 | doi=10.1007/BFb0098246}}

[[Category:Diophantine approximation]]
[[Category:Theorems in number theory]]</text>
      <sha1>b93g10wvu7eqosccjkmgnqinp9ikzap</sha1>
    </revision>
  </page>
  <page>
    <title>Tail value at risk</title>
    <ns>0</ns>
    <id>14530635</id>
    <revision>
      <id>871783816</id>
      <parentid>845439221</parentid>
      <timestamp>2018-12-03T11:51:52Z</timestamp>
      <contributor>
        <ip>169.202.235.2</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5698">{{Redirect-synonym|TVAR|[[Time variance]]}}

'''Tail value at risk''' ('''TVaR'''), also known as '''tail conditional expectation''' ('''TCE''') or '''conditional tail expectation''' ('''CTE'''), is a [[risk measure]] associated with the more general [[value at risk]]. It quantifies the expected value of the loss given that an event outside a given probability level has occurred.

==Background==

There are a number of related, but subtly different, formulations for TVaR in the literature. A common case in literature is to define TVaR and [[average value at risk]] as the same measure.&lt;ref name=Bar/&gt;  Under some formulations, it is only equivalent to [[expected shortfall]] when the underlying [[cumulative distribution function|distribution function]] is [[continuous function|continuous]] at &lt;math&gt;\operatorname{VaR}_{\alpha}(X)&lt;/math&gt;, the value at risk of level &lt;math&gt;\alpha&lt;/math&gt;.&lt;ref name=web1/&gt; Under some other settings, TVaR is the conditional expectation of loss above a given value, whereas the expected shortfall is the product of this value with the probability of it occurring.&lt;ref name = "Sweeting"/&gt; The former definition may not be a [[coherent risk measure]] in general, however it is coherent if the underlying distribution is continuous.&lt;ref name=Acerbi/&gt; The latter definition is a coherent risk measure.&lt;ref name = "Sweeting" /&gt; TVaR accounts for the severity of the failure, not only the chance of failure.  The TVaR is a measure of the [[Expected value|expectation]] only in the tail of the distribution.

==Mathematical definition==
The canonical tail value at risk is the left-tail (large negative values) in some disciplines and the right-tail (large positive values) in other, such as [[actuarial science]]. This is usually due to the differing conventions of treating losses as large negative or positive values. Using the negative value convention, Artzner and others define the tail value at risk as:

Given a [[random variable]] &lt;math&gt;X&lt;/math&gt; which is the payoff of a portfolio at some future time and given a parameter &lt;math&gt;0 &lt; \alpha &lt; 1&lt;/math&gt; then the tail value at risk is defined by&lt;ref name=Artzner/&gt;&lt;ref name=Landsman/&gt;&lt;ref name=Landsman2/&gt;&lt;ref name=Valdez/&gt;
: &lt;math&gt;\operatorname{TVaR}_{\alpha}(X) = \operatorname{E} [-X|X \leq -\operatorname{VaR}_{\alpha}(X)] =  \operatorname{E} [-X | X \leq x^{\alpha}] ,&lt;/math&gt;

where &lt;math&gt;x^{\alpha}&lt;/math&gt; is the upper &lt;math&gt;\alpha&lt;/math&gt;-[[quantile]] given by &lt;math&gt;x^{\alpha} = \inf\{x \in \mathbb{R}: \Pr(X \leq x) &gt; \alpha\}&lt;/math&gt;.  Typically the payoff random variable &lt;math&gt;X&lt;/math&gt; is in some [[Lp space|L&lt;sup&gt;p&lt;/sup&gt;-space]] where &lt;math&gt;p \geq 1&lt;/math&gt; to guarantee the existence of the expectation.

==References==
{{Reflist|refs=

&lt;ref name=Bar&gt;{{cite journal|last=Bargès|author2=Cossette, Marceau |title=TVaR-based capital allocation with copulas|journal=Insurance: Mathematics and Economics|year=2009|volume=45|pages=348–361|url=http://www.sciencedirect.com/science/article/pii/S0167668709000912|accessdate=20 July 2012|doi=10.1016/j.insmatheco.2009.08.002}}&lt;/ref&gt;

&lt;ref name=web1&gt;{{cite web|url=https://statistik.ets.kit.edu/download/doc_secure1/7_StochModels.pdf|title=Average Value at Risk|format=pdf|accessdate=February 2, 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20110719222242/https://statistik.ets.kit.edu/download/doc_secure1/7_StochModels.pdf|archivedate=July 19, 2011|df=}}&lt;/ref&gt;

&lt;ref name = "Sweeting"&gt;{{cite book
| last          = Sweeting
| first         = Paul
| title         = Financial Enterprise Risk Management
| series        = International Series on Actuarial Science
| year          = 2011
| publisher     = [[Cambridge University Press]]
| isbn          = 978-0-521-11164-5
| lccn          = 2011025050
| pages         = 397–401
| chapter       = 15.4 Risk Measures
}}&lt;/ref&gt;

&lt;ref name=Acerbi&gt;{{cite journal|first1=Carlo|last1=Acerbi|first2=Dirk|last2= Tasche|title=On the coherence of Expected Shortfall|year=2002|journal=Journal of Banking and Finance|volume=26|number=7|pages=1487–1503|url=https://arxiv.org/pdf/cond-mat/0104295%22%20/|format=pdf|accessdate=April 25, 2012|doi=10.1016/s0378-4266(02)00283-2|arxiv=cond-mat/0104295}}&lt;/ref&gt;

&lt;ref name=Artzner&gt;{{cite journal|last=Artzner|first=Philippe|last2=Delbaen|first2=Freddy|last3=Eber|first3=Jean-Marc|last4=Heath|first4=David|year=1999|title=Coherent Measures of Risk|journal=Mathematical Finance|volume=9|issue=3|pages=203–228|url=http://www.math.ethz.ch/~delbaen/ftp/preprints/CoherentMF.pdf|format=pdf|accessdate=February 3, 2011|doi=10.1111/1467-9965.00068}}&lt;/ref&gt;
&lt;ref name=Landsman&gt;{{cite journal|first1=Zinoviy|last1=Landsman|first2=Emiliano|last2=Valdez|title=Tail Conditional Expectations for Exponential Dispersion Models|date=February 2004|url=http://www.actuaries.org/ASTIN/Colloquia/Bergen/Landsman_Valdez.pdf|format=pdf|accessdate=February 3, 2011}}&lt;/ref&gt;
&lt;ref name=Landsman2&gt;{{cite journal|first1=Zinoviy|last1=Landsman|first2=Udi|last2=Makov|first3=Tomer|last3=Shushi|title=Tail Conditional Expectations for Generalized Skew - Elliptical distributions |date=July 2013|ssrn=2298265|format=pdf}}&lt;/ref&gt;
&lt;ref name=Valdez&gt;{{cite journal|first=Emiliano|last=Valdez|title=The Iterated Tail Conditional Expectation for the Log-Elliptical Loss Process|date=May 2004|url=http://www.asb.unsw.edu.au/schools/actuarialstudies/Documents/E.A.%20Valdez%20-%20The%20Iterated%20Tail%20Conditional%20Expectation%20for%20the%20Log-Elliptical%20Loss%20Process.pdf|format=pdf|accessdate=February 3, 2010}}&lt;/ref&gt;
}}

{{DEFAULTSORT:Tail Value At Risk}}
[[Category:Actuarial science]]
[[Category:Financial risk modeling]]
[[Category:Monte Carlo methods in finance]]

{{Econ-stub}}
{{Finance-stub}}</text>
      <sha1>hpsi7rbl3fjzzaus5hzpqna11xercwi</sha1>
    </revision>
  </page>
  <page>
    <title>Taro Morishima</title>
    <ns>0</ns>
    <id>7372292</id>
    <revision>
      <id>845719902</id>
      <parentid>706235767</parentid>
      <timestamp>2018-06-13T17:31:18Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2207">{{nihongo|'''Taro Morishima'''|森嶋 太郎|Morishima Tarō|1903 – 1989}} was a [[Japanese people|Japanese]] [[mathematician]] specializing in [[algebra]] who attended [[University of Tokyo]] in [[Japan]]. Morishima published at least thirteen papers, including his work on [[Fermat's Last Theorem]].&lt;ref&gt;{{cite journal
|last=Morishima
|first=Taro
|date=January 1952
|title=On Fermat's Last Theorem (Thirteenth Paper)
|journal=Transactions of the American Mathematical Society|volume=72
|issue=1
|pages=67–81
|doi=10.2307/1990655
|jstor=1990655}}&lt;/ref&gt; and a collected works volume published in 1990 after his death.&lt;ref&gt;{{cite book
  | last =Morishima
  | first =Taro
  |author2=Y Karamatsu
   | title =Collected papers of Taro Morishima
  | publisher =Queens University
  | year =1990
  | location =Kingston, Ontario, Canada}}&lt;/ref&gt; He also corresponded several times with [[United States|American]] mathematician [[Harry Vandiver|H. S. Vandiver]].&lt;ref&gt;{{cite web|url=http://www.lib.utexas.edu/taro/utcah/00303/cah-00303.html|title=A Guide to the H. S. Vandiver Papers, 1889-1977|publisher=The Center for American History at the University of Texas at Austin|accessdate=2006-11-28}}&lt;/ref&gt;

== Morishima's Theorem on FLT ==

:Let m be a prime number not exceeding 31. Let ''p'' be prime, and let ''x'', ''y'', ''z'' be [[integer]]s such that ''x''&lt;sup&gt;''p''&lt;/sup&gt; + ''y''&lt;sup&gt;''p''&lt;/sup&gt; + ''z''&lt;sup&gt;''p''&lt;/sup&gt; = 0. Assume that ''p'' does not divide the [[product (mathematics)|product]] ''xyz''. Then, ''p''² must  divide  m&lt;sup&gt;''p'' &amp;minus; 1&lt;/sup&gt;-1.

==Review==
Granville wrote that Morishima's proof could not be accepted. [http://www.ams.org/journals/tran/1988-306-01/S0002-9947-1988-0927694-5/S0002-9947-1988-0927694-5.pdf]

==References==
{{reflist}}

==External links==
*[https://web.archive.org/web/20061104001238/http://www.campusbookstore.com/index.cfm?index=GENERALBOOKS%2FWBSDETAILS&amp;isbn=QPPAM84&amp;group=QPPAM Collected papers at Queen's University]

{{Authority control}}


{{DEFAULTSORT:Morishima, Taro}}
[[Category:1903 births]]
[[Category:1989 deaths]]
[[Category:20th-century Japanese mathematicians]]
[[Category:Algebraists]]


{{asia-mathematician-stub}}
{{Japan-scientist-stub}}</text>
      <sha1>rdohjzqv8mtxdmral8jvt448lndhocm</sha1>
    </revision>
  </page>
  <page>
    <title>The Foundations of Arithmetic</title>
    <ns>0</ns>
    <id>8983001</id>
    <revision>
      <id>865822102</id>
      <parentid>857320861</parentid>
      <timestamp>2018-10-26T11:43:05Z</timestamp>
      <contributor>
        <username>Pirhayati</username>
        <id>16750284</id>
      </contributor>
      <comment>removed [[Category:Philosophy of mathematics]]; added [[Category:Philosophy of mathematics literature]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13690">{{Italic title}}
{{Infobox book
| name = The Foundations of Arithmetic
| title_orig = Die Grundlagen der Arithmetik. Eine logisch-mathematische Untersuchung über den Begriff der Zahl
| translator = [[J. L. Austin]]
| author = [[Gottlob Frege]]
| image = Title page of Die Grundlagen der Arithmetik.jpg{{!}}border
| caption = Title page of the original 1884 edition
| country = Germany
| language = German
| subject = [[Philosophy of mathematics|Philosophy of Mathematics]]
| genre =
| published = 1884
| pages = 119 (original German)
| isbn=0810106051 |dewey= |congress= |oclc=650
}}
'''''The Foundations of Arithmetic''''' ({{lang-de|Die Grundlagen der Arithmetik}}) is a book by [[Gottlob Frege]], published in 1884, which investigates the [[Philosophy|philosophical]] foundations of [[arithmetic]]. Frege refutes other theories of [[number]] and develops his own theory of numbers.  The ''Grundlagen'' also helped to motivate Frege's later works in [[logicism]]. The book was not well received and was not read widely when it was published. It did, however, draw the attentions of [[Bertrand Russell]] and [[Ludwig Wittgenstein]], who were both heavily influenced by Frege's philosophy. An English translation was published (Oxford, 1950) by [[J. L. Austin]], with a second edition in 1960.{{sfn|Frege|1960}}

==Criticisms of predecessors==

===Psychologistic accounts of mathematics===
Frege objects to any account of mathematics based on [[psychologism]], that is the view that math and numbers are relative to the subjective thoughts of the people who think of them. According to Frege, psychological accounts appeal to what is subjective, while mathematics is purely objective: mathematics are completely independent from human thought. Mathematical entities, according to Frege, have objective [[Property|properties]] regardless of humans thinking of them: it is not possible to think of mathematical statements as something that evolved naturally through human history and [[evolution]]. He sees a fundamental distinction between [[logic]] (and its extension, according to Frege, math) and psychology. Logic explains necessary facts, whereas psychology studies certain thought processes in individual minds.{{sfn|Frege|loc=§27}}

===Kant===
Frege greatly appreciates the work of [[Immanuel Kant]]. He criticizes him mainly on the grounds that numerical statements are not [[Analytic–synthetic distinction|synthetic]]-[[A priori and a posteriori|a priori]], but rather analytic-a priori.{{sfn|Frege|loc=§12|ps=: "But an intuition in this [Kant's] sense cannot serve as ground of our knowledge of the laws of arithmetic."}}
Kant claims that 7+5=12 is an unprovable synthetic statement.{{sfn|Frege|loc=§5|ps=: "Kant declares [statements such as 2 + 3 = 5] to be unprovable and synthetic, but hesitates to call them axioms because they are not general and because the number of them is infinite. Hankel justifiably calls this conception of infinitely numerous unprovable primitive truths incongruous and paradoxical."}} No matter how much we analyze the idea of 7+5 we will not find there the idea of 12. We must arrive at the idea of 12 by application to objects in the intuition. Kant points out that this becomes all the more clear with bigger numbers. Frege, on this point precisely, argues towards the opposite direction. Kant wrongly assumes that in a proposition containing "big" numbers we must count points or some such thing to assert their [[truth value]]. Frege argues that without ever having any intuition toward any of the numbers in the following equation: 654,768+436,382=1,091,150 we nevertheless can assert it is true. This is provided as evidence that such a proposition is analytic. While Frege agrees that geometry is indeed synthetic a priori, arithmetic must be analytic.{{sfn|Frege|loc=§14|ps=: "The fact that [denying the [[parallel postulate]]] is possible shows that the axioms of geometry are independent of one another and of the primitive laws of logic, and consequently are synthetic. Can the same be said of the fundamental propositions of the science of number? Here, we have only to try denying any one of them, and complete confusion ensues."}}

===Mill===
Frege roundly criticizes the [[empiricism]] of [[John Stuart Mill]].{{sfn|Frege|1960|p=9-12}}{{sfn|Shapiro|2000|p=96|ps=: "Frege's ''Foundations of Arithmetic'' contains a sustained, bitter assault on Mill's account of arithmetic"}} He claims that Mill's idea that numbers correspond to the various ways of splitting collections of objects into subcollections is inconsistent with confidence in calculations involving large numbers.{{sfn|Frege|1960|p=10|ps=: "If the definition of each individual number did really assert a special physical fact, then we should never be able to sufficiently admire, for his knowledge of nature, a man who calculates with nine-figure numbers."}}{{sfn|Shapiro|2000|p=98|ps=: "Frege also takes Mill to task concerning large numbers."}} He also denies that Mill's philosophy deals adequately with the concept of [[0|zero]].{{sfn|Frege|1960|p=11|ps=: "[...] the number 0 would be a puzzle; for up to now no one, I take it, has ever seen or touched 0 pebbles."}} He goes on to argue that the operation of addition cannot be understood as referring to physical quantities, and that Mill's confusion on this point is a symptom of a larger problem of confounding the applications of arithmetic for arithmetic itself.

==Development of Frege's own view of a number==
{{See also|Frege's theorem}}

Frege makes a distinction between particular numerical statements such as 1+1=2, and general statements such as a+b=b+a. The latter are statements true of numbers just as well as the former. Therefore, it is necessary to ask for a definition of the concept of number itself. 
Frege investigates the possibility that number is determined in external things. He demonstrates how numbers function in natural language just as adjectives. "This desk has 5 drawers" is similar in form to "This desk has green drawers". The drawers being green is an objective fact, grounded in the external world. But this is not the case with 5. Frege argues that each drawer is on its own green, but not every drawer is 5.{{sfn|Frege|loc=§22|ps=: "Is it not in totally different senses that we speak of a tree having 1000 leaves and again as having green leaves? The green colour we ascribe to each single leaf, but not the number 1000."}}
Frege urges us to remember that from this it does not follow that numbers may be subjective. Indeed, numbers are similar to colors  at least in that both are wholly objective.  
Frege tells us that we can convert number statements where number words appear adjectivally (e.g., 'there are four horses') into statements where number terms appear as singular terms ('the number of horses is four').{{sfn|Frege|loc=§57|ps=: "For example, the proposition 'Jupiter has four moons' can be converted into 'the number of Jupiter's moons is four'"}}  Frege recommends such translations because he takes numbers to be objects.  It makes no sense to ask whether any objects fall under 4. After Frege gives some reasons for thinking that numbers are objects, he concludes that statements of numbers are assertions about concepts.

Frege takes this observation to be the fundamental thought of ''Grundlagen''.  For example,  the sentence "the number of horses in the barn is four" means that four objects fall under the concept ''horse in the barn''.  Frege attempts to explain our grasp of numbers through a contextual definition of the cardinality operation ('the number of...', or &lt;math&gt; Nx: Fx &lt;/math&gt;).  He attempts to construct the content of a judgment involving numerical identity by relying on [[Hume's principle]] (which states that the number of Fs equals the number of Gs if and only if F and G are [[Equinumerosity|equinumerous]], i.e. in one-one correspondence).{{sfn|Frege|loc=§63|ps=: "Hume long ago expressed such a means: 'When two numbers are so combined as that one has always a unit answering to every unit of the other, we pronounce them equal'"}} He rejects this definition because it doesn't fix the truth value of identity statements when a singular term not of the form 'the number of Fs' flanks the identity sign.  Frege goes on to give an explicit definition of number in terms of extensions of concepts, but expresses some hesitation.

===Frege's definition of a number===

Frege argues that numbers are objects and assert something about a concept.    Frege defines numbers as extensions of concepts.  'The number of F's' is defined as the extension of the concept ''G is a concept that is equinumerous to F''.   The concept in question leads to an equivalence class of all concepts that have the number of F (including F).  Frege defines 0 as the extension of the concept ''being non self-identical''. So, the number of this concept is the extension of the concept of all concepts that have no objects falling under them. The number 1 is the extension of being identical with 0.{{sfn|Boolos|1998|p=154|ps=: "Frege defines 0 as the number of the concept: ''being non-self-identical''. Since everything is self-identical, no object falls under this concept. Frege defines 1 as the number of the concept ''being identical with the number zero''. 0 and 0 alone falls under this latter concept."}}

== Legacy ==

The book was fundamental in the development of two main disciplines, the foundations of mathematics and philosophy. Although Bertrand Russell later found a major flaw in Frege's work (this flaw is known as [[Russell's paradox]], which is resolved by [[axiomatic set theory]]), the book was influential in subsequent developments, such as ''[[Principia Mathematica]]''. The book can also be considered the starting point in analytic philosophy, since it revolves mainly around the analysis of language, with the goal of clarifying the concept of number. Frege's views on mathematics are also a starting point on the philosophy of mathematics, since it introduces an innovative account on the epistemology of numbers and math in general, known as logicism.

== Contents ==
The text is divided into five chapters, which are further divided into certain headings or topics (phrased as questions or statements), and then these into 109 sections.

# Views of certain writers on the nature of arithmetical propositions.
## Are numerical formulae provable? (§5-8)
## Are the law of arithmetic inductive truths (§9-11)
## Are the laws of arithmetic synthetic a priori or analytic? (§12-17)
# Views of certain writers on the concept of Number. (§18-20)
## Is Number a property of external things? (§21-25)
## Is number something subjective? (§26-27)
## The set theory of Number (§28)
# Views on unity and one.
## Does the word "one" express a property of objects? (§29-33)
## Are units identical with one another? (§34-39)
## Attempts to overcome the difficulty. (§40-44)
## Solution of the difficulty. (§45-54)
# The Concept of Number
## Every individual number is a self-subsistent object. (§55-61)
## To obtain the concept of Number, we must fix the sense of a numerical identity. (§62-69)
## Our definition completed and its worth proved (§71-83)
## Infinite Numbers. (§84-86)
# Conclusion (§87-91)
## Other numbers. (§92-109)

==See also==
* [[Basic Law V]]
* [[Foundationalism]]
* [[Linguistic turn]]
* [[Psychologism dispute]]

==Editions==
* {{cite book | url= | author=Gottlob Frege | editor= | title=Die Grundlagen der Arithmetik. Eine logisch-mathematische Untersuchung über den Begriff der Zahl | location=Breslau | publisher=Verlage Wilhelm Koebner | year=1884}}

==References==
{{Reflist}}

==Sources==
* ''[http://explore.bl.uk/primo_library/libweb/action/display.do?tabs=moreTab&amp;ct=display&amp;fn=search&amp;doc=BLL01001320611 The Foundations of Arithmetic. A logico-mathematical enquiry into the concept of number]'' (Oxford: Basil Blackwell, 1950) by Gottlob Frege, translated by [[J. L. Austin]].
* {{Cite book|url=https://www.worldcat.org/oclc/650|title=The foundations of arithmetic; a logico-mathematical enquiry into the concept of number|last=Frege|first=Gottlob|date=1960|publisher=Northwestern University Press|isbn=0810106051|edition=2nd|location=[[Evanston, Illinois]]|oclc=650|translator-last=Austin|translator-first=J. L.|translator-link=J. L. Austin|ref=harv}}
* {{Cite book|url=https://www.worldcat.org/oclc/37509971|title=Logic, logic, and logic|last=Boolos|first=George|authorlink=George Boolos|date=1998|publisher=Harvard University Press|others=Edited by Richard C. Jeffrey, introduction by John P. Burgess |isbn=9780674537675|location=Cambridge, Mass|oclc=37509971|chapter=Chapter 9: Gottlob Frege and the Foundations of Arithmetic}}
* On Frege's criticism of Mill: {{Cite book|url=https://www.worldcat.org/oclc/43864339|title=Thinking about mathematics: the philosophy of mathematics|last=Shapiro|first=Stewart|date=2000|publisher=Oxford University Press|isbn=9780192893062|location=New York|oclc=43864339|pages=95-98}}

==External links==
*{{Gutenberg|no=48312|name=Die Grundlagen der Arithmetik}}
:Free, full-text German edition
*[[Stanford Encyclopedia of Philosophy]]: [https://plato.stanford.edu/entries/frege-theorem/ "Frege's Theorem and Foundations for Arithmetic"] by [[Edward Zalta]].
*{{SpringerEOM| title=Number | id=Number | oldid=11869 | first=V.I. | last=Nechaev }}
*[[Peter Suber]], [http://nrs.harvard.edu/urn-3:HUL.InstRepos:4725028 Geometry and Arithmetic are Synthetic], 2002.

{{DEFAULTSORT:Foundations Of Arithmetic, The}}
[[Category:1884 books]]
[[Category:Books by Gottlob Frege]]
[[Category:Logic books]]
[[Category:Philosophy of mathematics literature]]</text>
      <sha1>l9oics1vblh47rnmn325euakp4xmmvf</sha1>
    </revision>
  </page>
  <page>
    <title>The Taming of Chance</title>
    <ns>0</ns>
    <id>41530846</id>
    <revision>
      <id>869070938</id>
      <parentid>865822225</parentid>
      <timestamp>2018-11-16T06:04:03Z</timestamp>
      <contributor>
        <username>FreeKnowledgeCreator</username>
        <id>8971613</id>
      </contributor>
      <comment>rm unused citation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4915">{{Infobox book 
| name          = The Taming of Chance
| image         = File:The Taming of Chance.jpg
| caption       = Cover of the first edition
| author        = [[Ian Hacking]]
| illustrator   = 
| cover_artist  = 
| country       =
| language      = English
| series        = 
| subject       = [[History of probability]]
| published     = 1990
| media_type    = Print ([[Hardcover]] and [[Paperback]])
| pages         = 282
| isbn          = 978-0521388849
| dewey= 
| congress=
| oclc=
| preceded_by   = 
| followed_by   = 
}}
'''''The Taming of Chance''''' is a 1990 book about the [[history of probability]] by the philosopher [[Ian Hacking]]. It is a sequel to his earlier ''[[The Emergence of Probability]]'' (1975). The book received both positive and mixed reviews.

==Reception==
''The Taming of Chance'' has been described as ground-breaking.&lt;ref&gt;[[#Mac05|Macintosh 2005]]. p. 357.&lt;/ref&gt; [[Dennis Lindley|D. V. Lindley]] reviewed the book in ''[[Nature (journal)|Nature]]''.&lt;ref&gt;[[#Lin91|Lindley 1991]]. p. 202.&lt;/ref&gt; M. Schabas reviewed the book in ''[[Science (journal)|Science]]''.&lt;ref&gt;[[#Sch91|Schabas 1991]]. p. 1373.&lt;/ref&gt; [[Stephen Park Turner|Stephen P. Turner]] reviewed the book positively in the ''[[American Journal of Sociology]]'', writing that it was useful for both sociologists of science and historians of social science, and that while Hacking's arguments were open to objections, Hacking was "too sophisticated" to be caught by them.&lt;ref&gt;[[#Tur91|Turner 1991]]. pp. 551-553.&lt;/ref&gt; The historian of science [[Theodore M. Porter]] reviewed the book in ''[[American Scientist]]''.&lt;ref&gt;[[#Por92|Porter 1992]]. p. 90.&lt;/ref&gt;

Bruce Kurlick gave ''The Taming of Chance'' a mixed review in ''[[American Historical Review]]'', noting that it was a sequel to Hacking's earlier ''The Emergence of Probability''. Kurlick praised Hacking for the "richness of his ideas" and credited him with mastering complicated literature in several languages and "meticulous scholarship" superior to that of [[Michel Foucault]], to whom Hacking was indebted. However, he considered the book a "strain to understand" and criticized Hacking for giving insufficient emphasis to the role of the hospital in "acclimating the public to chance and probability", and for his "penchant for irrelevant anecdotes" and poor judgment about how to write about the past.&lt;ref&gt;[[#Kur92|Kurlick 1992]]. p. 157.&lt;/ref&gt; Timothy L. Alborn reviewed ''The Taming of Chance'' positively in ''[[Isis (journal)|Isis]]'', writing that Hacking had a "vibrant writing style" and presented a "wealth of material". However, he also wrote that Hacking's book left many questions unanswered.&lt;ref&gt;[[#Alb92|Alborn 1992]]. pp. 366-367.&lt;/ref&gt;

==References==

===Footnotes===
{{reflist|20em}}

===Bibliography===
;Books
{{refbegin}}
* {{cite book |author=Macintosh, Jack |editor=Honderich, Ted |title=The Oxford Companion to Philosophy |publisher=Oxford University Press |location=Oxford |year=2005 |isbn=0-19-926479-1 |oclc= |doi= |accessdate=}}
* {{cite book |author=Smith, Roger |title=The Norton History of the Human Sciences |publisher=W. W. Norton &amp; Company |location=New York |year=1997 |isbn=0-393-31733-1 |oclc= |doi= |accessdate=}}
{{refend}}

;Journals
{{refbegin}}
* {{cite journal |title=Book reviews: Sociology &amp; philosophy of science |author=Alborn, Timothy L. |journal=Isis |volume=83 |issue=2 |year=1992 |doi=10.1086/356189}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
* {{cite journal |title=Reviews of books: General |author=Kurlick, Bruce |journal=American Historical Review |volume=97 |issue=1 |year=1992 |doi=}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
* {{cite journal |title=Umbugology and ditchwateristics |author=Lindley, D. V. |journal=Nature |volume=349 |issue=6306 |year=1991 |doi=}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
* {{cite journal |title=The Taming of Chance (Book) |author=Porter, Theodore M. |journal=American Scientist |volume=80 |issue=1 |year=1992 |doi=}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
* {{cite journal |title=The idea of the normal |author=Schabas, M. |journal=Science |volume=251 |issue=4999 |year=1991 |doi=10.1126/science.251.4999.1373}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
* {{cite journal |title=The Taming of Chance (Book) |author=Turner, Stephen P. |journal=American Journal of Sociology |volume=97 |issue=2 |year=1991 |doi=}} {{subscription needed|via=[https://www.ebsco.com EBSCO]'s Academic Search Complete}}
{{refend}}

{{DEFAULTSORT:Taming of Chance, The}}
[[Category:1990 books]]
[[Category:Books by Ian Hacking]]
[[Category:Contemporary philosophical literature]]
[[Category:English-language books]]
[[Category:Philosophy of mathematics literature]]</text>
      <sha1>3p3tyfupt0u3cj91fpwsdy1owi4gdpj</sha1>
    </revision>
  </page>
  <page>
    <title>Van Genuchten–Gupta model</title>
    <ns>0</ns>
    <id>54863674</id>
    <revision>
      <id>857220147</id>
      <parentid>857217968</parentid>
      <timestamp>2018-08-30T09:46:15Z</timestamp>
      <contributor>
        <username>Salton Sea</username>
        <id>31625758</id>
      </contributor>
      <comment>/* Alternative 2 */ explanation added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2691">{{more citations needed|date=February 2018}}

{{lowercase title}}
The '''van Genuchten–Gupta model''' is an inverted [[Sigmoid function|S-curve]] applicable to [[crop yield]] and [[soil salinity]] relations.&lt;ref&gt;M. Th. van Genuchten and S.K. Gupta, 1993. '''USDA-ARS, U.S. Salinity Laboratory 4500 Glenwood Drive, Riverside, California, USA, 92501.''' ''A reassessment of the Crop Tolerance Response Function.'' Journal of the Indian Society of Soil Science, Vol. 41, No. 4, pp 730–737.&lt;/ref&gt;

[[File:Van Genugten-Gupta model.png|thumb|300px|Van Genuchten-Gupta model for crop response to soil salinity.]]

==Equation==

The mathematical expression is:

: Y = Ym &lt;big&gt;/&lt;/big&gt; [ 1 + {C / C&lt;sub&gt;50&lt;/sub&gt;} &lt;sup&gt;&lt;big&gt;P&lt;/big&gt;&lt;/sup&gt; ]

where Y = yield, Ym = maximum yield of the model, C = salt concentration of the soil, C&lt;sub&gt;50&lt;/sub&gt; = C value at 50% yield, P = an exponent to be found by [[optimization]] and maximizing the model's [[goodness of fit]] to the data.

In the figure: Ym = 3.1, C&lt;sub&gt;50&lt;/sub&gt; = 12.4, P = 3.75

==Alternative 1==
[[File:S-curve model.png|thumb|300px|Logistic S-curve model for the relation between crop yield and soil salinity]]

As an alternative, the '''[[Logistic function|logistic S-function]]''' can be used.

The mathematical expression is:

: Y&lt;big&gt;^&lt;/big&gt; = 1 &lt;big&gt;/&lt;/big&gt; { 1 + &lt;big&gt;e&lt;/big&gt;&lt;sup&gt;&lt;big&gt; (A.X&lt;big&gt;&lt;sup&gt;C&lt;/sup&gt;&lt;/big&gt; + B)&lt;/big&gt;&lt;/sup&gt; }

where:

: Y&lt;big&gt;^&lt;/big&gt; = (Y - Yn) &lt;big&gt;/&lt;/big&gt; (Ym - Yn)

with Y =Yield, Yn = minimum Y, Ym = maximum Y, X = salt concentration of the soil, while A, B and C are constants to be determined by [[optimization]] and maximizing the model's [[goodness of fit]] to the data.

If the minimum Yn=0 then the expression can be simplified to:

: Y = Ym &lt;big&gt;/&lt;/big&gt; { 1 + &lt;big&gt;e&lt;/big&gt;&lt;sup&gt;&lt;big&gt; (A.X&lt;big&gt;&lt;sup&gt;C&lt;/sup&gt;&lt;/big&gt; + B)&lt;/big&gt;&lt;/sup&gt; }

In the figure: Ym = 3.43, Yn = 0.47, A = 0.112, B = -3.16, C = 1.42.

==Alternative 2==
[[File:Cubic regression.png|thumb|300px|Cubic regression to find the relation between crop yield and soil salinity]]

The third degree or '''[[Polynomial regression|cubic regression]]''' also offers a useful alternative.

The equation reads:

: Y = A.X&lt;sup&gt;3&lt;/sup&gt; + B.X&lt;sup&gt;2&lt;/sup&gt; + C.X + D

with Y =Yield, X = salt concentration of the soil, while A, B, C and D are constants to be determined by the regression.

In the figure: A = 0.0017, B = 0.0604, C=0.3874, D = 2.3788. These values were calculated with [[Microsoft Excel]]

The curvature is more pronounced than in the other models.

==See also==
*[[Maas–Hoffman model]]

==References==
{{reflist}}

{{DEFAULTSORT:Van Genuchten Gupta model}}
[[Category:Soil science]]
[[Category:Mathematical modeling]]
[[Category:Crops]]</text>
      <sha1>9gq2qcc9c3qt5uue0nh87mrfrbcfkr9</sha1>
    </revision>
  </page>
</mediawiki>
