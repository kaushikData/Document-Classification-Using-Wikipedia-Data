<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>180 (number)</title>
    <ns>0</ns>
    <id>454987</id>
    <revision>
      <id>865930388</id>
      <parentid>865864652</parentid>
      <timestamp>2018-10-27T03:27:30Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/41.210.155.40|41.210.155.40]] ([[User talk:41.210.155.40|talk]]) to last revision by TwoTwoHello. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3850">{{about|the number|other uses|180 (disambiguation)}}
{{Refimprove|date=May 2010}}
{{Infobox number
| number = 180
| divisor = 1, 2, 3, 4, 5, 6, 9, 10, 12, 15, 18, 20, 30, 36, 45, 60, 90, 180
}}
'''180''' ('''one hundred [and] eighty''') is the [[natural number]] following [[179 (number)|179]] and preceding [[181 (number)|181]].

==In mathematics==
180 is an [[abundant number]], with its proper divisors summing up to 366.&lt;ref&gt;{{cite web|title=Positive Integers: 180|url=http://www.positiveintegers.org/180}}&lt;/ref&gt;&lt;ref name=VirtueScience&gt;{{cite web|title=The Number 180|url=http://www.virtuescience.com/180.html|publisher=VirtueScience.com}}
&lt;/ref&gt; 180 is also a [[highly composite number]], a positive integer with more divisors than any smaller positive integer. One of the consequences of 180 having so many divisors is that it is a [[practical number]], meaning that any positive number smaller than 180 that is not a divisor of 180 can be expressed as the sum of some of 180's divisors. 180 is a [[refactorable number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A033950|title=Refactorable numbers|last=|first=|date=2016-04-18|website=On-Line Encyclopedia of Integer Sequences|publisher=The OEIS Foundation|access-date=2016-04-18}}&lt;/ref&gt;

180 is the [[Summation|sum]] of two [[square number]]s: 12&lt;sup&gt;2&lt;/sup&gt; + 6&lt;sup&gt;2&lt;/sup&gt;. It can be expressed as either the sum of six consecutive [[prime number]]s: [[19 (number)|19]] + [[23 (number)|23]] + [[29 (number)|29]] + [[31 (number)|31]] + [[37 (number)|37]] + [[41 (number)|41]], or the sum of eight consecutive [[prime number]]s: [[11 (number)|11]] + [[13 (number)|13]] + [[17 (number)|17]] + [[19 (number)|19]] + [[23 (number)|23]] + [[29 (number)|29]] + [[31 (number)|31]] + [[37 (number)|37]]. 180 is an [[Ulam numbers|Ulam number]], which can be expressed as a sum of earlier terms in the Ulam sequence only as 177 + 3.&lt;ref&gt;{{Cite web|url=https://oeis.org/A002858|title=Ulam numbers|last=|first=|date=2016-04-18|website=On-Line Encyclopedia of Integer Sequences|publisher=The OEIS Foundation|access-date=2016-04-18}}&lt;/ref&gt;

180 is a 61-[[Polygonal number|gonal]] number.&lt;ref name=VirtueScience/&gt;

Half a [[circle]] has 180 degrees.&lt;ref&gt;{{cite book |first=D. |last=Wells|title=[[The Penguin Dictionary of Curious and Interesting Numbers]]| publisher=Penguin Group |year=1987 |location=London| page=142 |isbn=0-14-026149-4}}&lt;/ref&gt;

Summing [[Euler's totient function]] φ(''x'') over the first + [[24 (number)|24]] integers gives 180.

180 is a [[Harshad number]] in base 10, and in [[binary numeral system|binary]] it is a digitally balanced number, since its binary representation has the same number of zeros as ones (10110100).

==In religion==
The [[Book of Genesis]] says that [[Isaac]] died at the age of 180.&lt;ref&gt;{{bibleverse||Genesis|35:28-29|NIV}}&lt;/ref&gt;

==In sports==
* The maximum possible score in one turn at [[darts]] (three triple 20s).
* In [[archery]] the gent's [[Clout archery|clout]] shooting distance is 180 yards.&lt;ref&gt;{{cite web|title=Grand National Archery Society Rules of Shooting April 2008|url=http://www.sportfocus.com/reguser/dynabizinfo/download.cfm?number=2908|author=GNAS|year=2008}}&lt;/ref&gt;

==See also==
* [[List of highways numbered 180]]
* [[United Nations Security Council Resolution 180]]
* [[List of United States Supreme Court cases, volume 180|United States Supreme Court cases, Volume 180]]
* [[Pennsylvania House of Representatives, District 180]]

==References==
{{Reflist}}

==External links==
{{Commons category|180 (number)}}
* {{cite web|title=180|url=http://www.numdic.com/180|publisher=The Number Dictionary}}
* {{cite web|title=Prime curiosities: 180|url=http://primes.utm.edu/curios/page.php/180.html|author=G. L. Honaker, Jr|publisher=[[University of Tennessee at Martin|UTM]]}}

{{Integers|1}}

{{DEFAULTSORT:180 (Number)}}
[[Category:Integers]]</text>
      <sha1>6xyvyc8qthyb1uxdx0nscktltip3ymx</sha1>
    </revision>
  </page>
  <page>
    <title>Anatoly Vershik</title>
    <ns>0</ns>
    <id>9036441</id>
    <revision>
      <id>710161572</id>
      <parentid>708725235</parentid>
      <timestamp>2016-03-15T09:18:58Z</timestamp>
      <contributor>
        <username>KasparBot</username>
        <id>24420788</id>
      </contributor>
      <comment>migrating [[Wikipedia:Persondata|Persondata]] to Wikidata, [[toollabs:kasparbot/persondata/|please help]], see [[toollabs:kasparbot/persondata/challenge.php/article/Anatoly Vershik|challenges for this article]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2560">[[File:Vershik3.jpg|200px|thumb|right|Anatoly M. Vershik.]]

'''Anatoly Moiseevich Vershik''' ({{lang-ru|Анато́лий Моисе́евич Ве́ршик}}; born on 28 December 1933 in [[Saint Petersburg|Leningrad]]) is a [[USSR|Soviet]] and [[Russia]]n [[mathematician]].  He is most famous for his joint work with [[Sergei Kerov|Sergey V. Kerov]] on [[representation theory|representations]] of [[infinity|infinite]] [[symmetric group]]s and applications to the [[longest increasing subsequence]]s.

Vershik studied at [[Saint Petersburg State University|Leningrad State University]], receiving his doctoral degree in 1974; his advisor was [[Vladimir Rokhlin (Soviet mathematician)|Vladimir Rokhlin]].&lt;ref&gt;{{MathGenealogy|id=19387}}&lt;/ref&gt;

He works at the [[Steklov Institute of Mathematics]] and at [[Saint Petersburg State University]].  In 1998–2008 he was the president of the [[St. Petersburg Mathematical Society]].

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-08-29.&lt;/ref&gt; His doctoral students include [[Alexander Barvinok]], [[Anna Erschler]] and [[Sergey Fomin]].

==See also==
*[[Bratteli–Vershik diagram]]

==References==
{{reflist}}
* [[Vladimir Arnold]], Mikhail Sh. Birman, [[Israel Gelfand]], et al., "Anatolii Moiseevich Vershik (on the occasion of his sixtieth birthday", ''Russian Math. Surveys'' '''49:3''' (1994), 207–221. 
* Anatoly Vershik, [http://www.3038.org/press/vershik.pdf Admission to the mathematics faculty in Russia in the 1970s and 1980s], ''[[Mathematical Intelligencer]]'' vol. 16, No. 4, (1994), 4–5.

==External links==
* [http://www.pdmi.ras.ru/~vershik/ Personal home page] at [[St. Petersburg Department of Steklov Institute of Mathematics of Russian Academy of Sciences|Petersburg Department of the Mathematical Institute]]
** [http://www.pdmi.ras.ru/~vershik/cv.html Vershik's CV]
*{{MathGenealogy |id=19387}}

{{Authority control}}
{{DEFAULTSORT:Vershik, Anatoly}}
[[Category:1933 births]]
[[Category:Living people]]
[[Category:Russian mathematicians]]
[[Category:Soviet mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:People from Saint Petersburg]]
[[Category:Saint Petersburg State University faculty]]
[[Category:Combinatorialists]]
[[Category:Alexander von Humboldt Fellows]]
[[Category:Fellows of the American Mathematical Society]]

{{Russia-mathematician-stub}}
{{Russia-scientist-stub}}</text>
      <sha1>f6n8g9ldrq90yxvanuue72xk1k28hgz</sha1>
    </revision>
  </page>
  <page>
    <title>Belief propagation</title>
    <ns>0</ns>
    <id>800010</id>
    <revision>
      <id>867276230</id>
      <parentid>866784538</parentid>
      <timestamp>2018-11-04T19:31:27Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25010">{{Use dmy dates|date=June 2013}}
{{More footnotes|date=April 2009}}
'''Belief propagation''', also known as '''sum-product message passing''', is a message-passing [[algorithm]] for performing [[inference]] on [[graphical model]]s, such as [[Bayesian network]]s and [[Markov random field]]s. It calculates the [[marginal distribution]] for each unobserved node, conditional on any observed nodes. Belief propagation is commonly used in [[artificial intelligence]] and [[information theory]] and has demonstrated empirical success in numerous applications including [[low-density parity-check codes]], [[turbo codes]], [[Thermodynamic free energy|free energy]] approximation, and [[satisfiability]].&lt;ref name="Sat"/&gt;

The algorithm was first proposed by [[Judea Pearl]] in 1982,&lt;ref name="Pearl-1982"&gt;
{{cite conference|last=Pearl |first=Judea |authorlink=Judea Pearl
 |year=1982
 |title=Reverend Bayes on inference engines:  A distributed hierarchical approach
 |booktitle=Proceedings of the Second National Conference on Artificial Intelligence
 |conference=AAAI-82: Pittsburgh, PA
 |conferenceurl=http://www.aaai.org/Library/AAAI/aaai82contents.php
 |publisher=AAAI Press |location=Menlo Park, California
 |pages=133&amp;ndash;136
 |url=https://www.aaai.org/Papers/AAAI/1982/AAAI82-032.pdf |accessdate=2009-03-28
}}
&lt;/ref&gt; who formulated it as an exact inference algorithm on [[Tree (graph theory)|tree]]s, which was later extended to [[polytree]]s.&lt;ref name="KimPearl-1983"&gt;{{cite conference|last = Kim|first = Jin H.|author2 = Pearl, Judea|authorlink2 = Judea Pearl|year = 1983|title = A computational model for combined causal and diagnostic reasoning in inference systems|booktitle = Proceedings of the Eighth International Joint Conference on Artificial Intelligence|conference = IJCAI-83: Karlsruhe, Germany|conferenceurl = http://www.ijcai.org/proceedings/1983-1|volume = 1|pages = 190&amp;ndash;193|url = http://www.ijcai.org/Proceedings/83-1/Papers/041.pdf|accessdate = 2016-03-20}}
&lt;/ref&gt; While it is not exact on general graphs anymore, it has been shown to be a useful approximate algorithm.&lt;ref name="Pearl-88"&gt;
{{Cite book
 |last1=Pearl |first1=Judea |authorlink1=Judea Pearl
 |year=1988
 |title=Probabilistic Reasoning in Intelligent Systems:  Networks of Plausible Inference
 |edition=2nd
 |location=San Francisco, CA |publisher=Morgan Kaufmann
 |isbn=1-55860-479-0
}}
&lt;/ref&gt;

If ''X''={''X''&lt;sub&gt;''i''&lt;/sub&gt;} is a set of [[Discrete probability distribution|discrete]] [[random variable]]s with a [[joint distribution|joint]] [[Probability mass function|mass function]] ''p'', the [[marginal distribution]] of a single ''X''&lt;sub&gt;''i''&lt;/sub&gt; is simply the summation of ''p'' over all other variables:

:&lt;math&gt;p_{X_i}(x_i) = \sum_{\mathbf{x}': x'_i \neq x_i} p(\mathbf{x}').&lt;/math&gt;

However, this quickly becomes computationally prohibitive: if there are 100 binary variables, then one needs to sum over 2&lt;sup&gt;99&lt;/sup&gt;&amp;nbsp;≈&amp;nbsp;6.338&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;29&lt;/sup&gt; possible values. By exploiting the polytree structure, belief propagation allows the marginals to be computed much more efficiently.
==Description of the sum-product algorithm==
Variants of the belief propagation algorithm  exist for several types of graphical models ([[Bayesian networks]] and [[Markov random fields]] &lt;ref name = "yedidia2003"&gt;{{Cite book
 |last1=Yedidia |first1=J.S.
 |last2=Freeman |first2=W.T. |last3=Y.
 |chapterurl=http://www.merl.com/publications/TR2001-022/  |accessdate=2009-03-30
 |chapter=Understanding Belief Propagation and Its Generalizations
 |title=Exploring Artificial Intelligence in the New Millennium
 |isbn=1-55860-811-7
 |pages=239&amp;ndash;236
 |date=January 2003
 |publisher=Morgan Kaufmann
 |editor1-first=Gerhard |editor1-last=Lakemeyer
 |editor2-first=Bernhard |editor2-last=Nebel
}}&lt;/ref&gt; in particular). We describe here the variant that operates on a [[factor graph]]. A factor graph is a [[bipartite graph]] containing nodes corresponding to variables ''V'' and factors ''F'', with edges between variables and the factors in which they appear. We can write the joint mass function:

:&lt;math&gt;p(\mathbf{x}) = \prod_{a \in F} f_a (\mathbf{x}_a)&lt;/math&gt;

where '''x'''&lt;sub&gt;''a''&lt;/sub&gt; is the vector of neighboring variable nodes to the factor node ''a''. Any [[Bayesian network]] or [[Markov random field]] can be represented as a factor graph.

The algorithm works by passing real valued functions called ''messages'' along with the edges between the hidden nodes. More precisely, if ''v'' is a variable node and ''a'' is a factor node connected to ''v'' in the factor graph, the messages from ''v'' to ''a'', (denoted by &lt;math&gt;\mu_{v \to a}&lt;/math&gt;) and from ''a'' to ''v'' (&lt;math&gt;\mu_{a \to v}&lt;/math&gt;), are real-valued functions whose domain is Dom(''v''), the set of values that can be taken by the random variable associated with ''v''. These messages contain the "influence" that one variable exerts on another. The messages are computed differently depending on whether the node receiving the message is a variable node or a factor node. Keeping the same notation:
* A message from a variable node ''v'' to a factor node ''a'' is the product of the messages from all other neighboring factor nodes (except the recipient; alternatively one can say the recipient sends as message the constant function equal to "1"):

:&lt;math&gt;\forall x_v\in Dom(v),\; \mu_{v \to a} (x_v) = \prod_{a^* \in N(v)\setminus\{a\} } \mu_{a^* \to v} (x_v).&lt;/math&gt;

:where ''N''(''v'') is the set of neighboring (factor) nodes to ''v''. If &lt;math&gt;N(v)\setminus\{a\}&lt;/math&gt; is empty, then &lt;math&gt;\mu_{v \to a}(x_v)&lt;/math&gt; is set to the uniform distribution.

* A message from a factor node ''a'' to a variable node ''v'' is the product of the factor with messages from all other nodes, marginalized over all variables except the one associated with ''v'':

:&lt;math&gt;\forall x_v\in Dom(v),\; \mu_{a \to v} (x_v) = \sum_{\mathbf{x}'_a: x'_v = x_v } f_a (\mathbf{x}'_a) \prod_{v^* \in N(a) \setminus \{v\}} \mu_{v^* \to a} (x'_{v^*}).&lt;/math&gt;

:where ''N''(''a'') is the set of neighboring (variable) nodes to ''a''. If &lt;math&gt;N(a) \setminus \{v\}&lt;/math&gt; is empty then &lt;math&gt;\mu_{a \to v} (x_v) = f_a(x_v)&lt;/math&gt;, since in this case &lt;math&gt; x_v = x_a &lt;/math&gt;.
As shown by the previous formula: the complete marginalization is reduced to a sum of products of simpler terms than the ones appearing in the full joint distribution. This is the reason why it is called the sum-product algorithm.

In a typical run, each message will be updated iteratively from the previous value of the neighboring messages. Different scheduling can be used for updating the messages. In the case where the graphical model is a tree, an optimal scheduling allows to reach convergence after computing each messages only once (see next sub-section).  When the factor graph has cycles, such an optimal scheduling does not exist, and a typical choice is to update all messages simultaneously at each iteration.

Upon convergence (if convergence happened), the estimated marginal distribution of each node is proportional to the product of all messages from adjoining factors (missing the normalization constant):

:&lt;math&gt; p_{X_v} (x_v) \propto \prod_{a \in N(v)} \mu_{a \to v} (x_v). &lt;/math&gt;

Likewise, the estimated joint marginal distribution of the set of variables belonging to one factor is proportional to the product of the factor and the messages from the variables:

:&lt;math&gt; p_{X_a} (\mathbf{x}_a) \propto f_a(\mathbf{x}_a) \prod_{v \in N(a)} \mu_{v \to a} (x_v). &lt;/math&gt;

In the case where the factor graph is acyclic (i.e. is a tree or a forest), these estimated marginal actually converge to the true marginals in a finite number of iterations. This can be shown by [[mathematical induction]].

==Exact algorithm for trees==

In the case when the [[factor graph]] is a [[tree (graph theory)|tree]], the belief propagation algorithm will compute the exact marginals. Furthermore, with proper scheduling of the message updates, it will terminate after 2 steps. This optimal scheduling can be described as follows:

Before starting, the graph is oriented by designating one node as the ''root''; any non-root node which is connected to only one other node is called a ''leaf''.

In the first step, messages are passed inwards: starting at the leaves, each node passes a message along the (unique) edge towards the root node. The tree structure guarantees that it is possible to obtain messages from all other adjoining nodes before passing the message on. This continues until the root has obtained messages from all of its adjoining nodes.

The second step involves passing the messages back out: starting at the root, messages are passed in the reverse direction. The algorithm is completed when all leaves have received their messages.

==Approximate algorithm for general graphs==

Curiously, although it was originally designed for acyclic graphical models, it was found that the Belief Propagation algorithm can be used in general [[Graph (discrete mathematics)|graph]]s. The algorithm is then sometimes called "loopy" belief propagation, because graphs typically contain [[cycle (graph theory)|cycle]]s, or loops.  The initialization and scheduling of message updates must be adjusted slightly  (compared with the previously described schedule for acyclic graphs) because graphs might not contain any leaves.  Instead, one initializes all variable messages to 1 and uses the same message definitions above, updating all messages at every iteration (although messages coming from known leaves or tree-structured subgraphs may no longer need updating after sufficient iterations).  It is easy to show that in a tree, the message definitions of this modified procedure will converge to the set of message definitions given above within a number of iterations equal to the [[Diameter (graph theory)|diameter]] of the tree.

The precise conditions under which loopy belief propagation will converge are still not well understood; it is known that on graphs containing a single loop it converges in most cases, but the probabilities obtained might be incorrect.&lt;ref&gt;
{{Cite journal
 |last=Weiss |first=Yair
 |title=Correctness of Local Probability Propagation in Graphical Models with Loops
 |journal=[[Neural Computation (journal)|Neural Computation]]
 |year=2000
 |volume=12 |issue=1 |pages=1&amp;ndash;41
 |doi=10.1162/089976600300015880
}}
&lt;/ref&gt; Several sufficient (but not necessary) conditions for convergence of loopy belief propagation to a unique fixed point exist.&lt;ref&gt;
{{Cite journal
 |last1=Mooij |first1=J
 |last2=Kappen |first2=H
 |title=Sufficient Conditions for Convergence of the Sum–Product Algorithm
 |journal=[[IEEE Transactions on Information Theory]]
 |volume=53 |issue=12 |pages=4422&amp;ndash;4437 |year=2007
 |doi=10.1109/TIT.2007.909166
|arxiv=cs/0504030}}
&lt;/ref&gt; There exist graphs which will fail to converge, or which will oscillate between multiple states over repeated iterations.  Techniques like [[EXIT chart]]s can provide an approximate visualization of the progress of belief propagation and an approximate test for convergence.

There are other approximate methods for marginalization including [[Variational Bayesian methods|variational method]]s and [[Monte Carlo method]]s.

One method of exact marginalization in general graphs is called the [[junction tree algorithm]], which is simply belief propagation on a modified graph guaranteed to be a tree.  The basic premise is to eliminate cycles by clustering them into single nodes.

==Related algorithm and complexity issues==
A similar algorithm is commonly referred to as the [[Viterbi algorithm]], but also known as a special case of the max-product or min-sum algorithm, which solves the related problem of maximization, or most probable explanation.  Instead of attempting to solve the marginal, the goal here is to find the  values &lt;math&gt;\mathbf{x}&lt;/math&gt; that maximizes the global function (i.e. most probable values in a probabilistic setting), and it can be defined using the [[arg max]]:

:&lt;math&gt;\operatorname*{\arg\max}_{\mathbf{x}} g(\mathbf{x}).&lt;/math&gt;

An algorithm that solves this problem is nearly identical to belief propagation, with the sums replaced by maxima in the definitions.&lt;ref&gt;
{{Cite journal
 |last=Löliger |first=Hans-Andrea
 |title=An Introduction to Factor Graphs
 |journal=[[IEEE Signal Processing Magazine]]
 |year=2004
 |volume=21 |pages=28&amp;ndash;41
 |doi=10.1109/msp.2004.1267047
|bibcode=2004ISPM...21...28L}}
&lt;/ref&gt;

It is worth noting that [[inference]] problems like marginalization and maximization are [[NP-hard]] to solve exactly and approximately (at least for [[approximation error|relative error]]) in a graphical model.  More precisely, the marginalization problem defined above is [[Sharp-P-complete|#P-complete]] and maximization is [[NP-complete]].

The memory usage of belief propagation can be reduced through the use of the [[Island algorithm]] (at a small cost in time complexity).

==Relation to free energy==
The sum-product algorithm is related to the calculation of [[Thermodynamic free energy|free energy]] in [[thermodynamics]]. Let ''Z'' be the [[partition function (mathematics)|partition function]]. A probability distribution

:&lt;math&gt;P(\mathbf{X}) = \frac{1}{Z} \prod_{f_j} f_j(x_j)&lt;/math&gt;

(as per the factor graph representation) can be viewed as a measure of the [[internal energy]] present in a system, computed as

:&lt;math&gt;E(\mathbf{X}) = \log \prod_{f_j} f_j(x_j).&lt;/math&gt;

The free energy of the system is then

:&lt;math&gt;F = U - H = \sum_{\mathbf{X}} P(\mathbf{X}) E(\mathbf{X}) + \sum_{\mathbf{X}}  P(\mathbf{X}) \log P(\mathbf{X}).&lt;/math&gt;

It can then be shown that the points of convergence of the sum-product algorithm represent the points where the free energy in such a system is minimized.  Similarly, it can be shown that a fixed point of the iterative belief propagation algorithm in graphs with cycles is a stationary point of a free energy approximation.&lt;ref name="GBP-2005"&gt;
{{Cite journal
 |last1=Yedidia |first1=J.S.
 |last2=Freeman |first2=W.T.
 |last3=Weiss |last4=Y.
 |title=Constructing free-energy approximations and generalized belief propagation algorithms
 |journal=[[IEEE Transactions on Information Theory]]
 |volume=51 |issue=7 |pages=2282&amp;ndash;2312 |date=July 2005
 |doi=10.1109/TIT.2005.850085
 |url=http://www.merl.com/publications/TR2004-040/ |accessdate=2009-03-28
 |first3=Y.
}}
&lt;/ref&gt;

==Generalized belief propagation (GBP)==
Belief propagation algorithms are normally presented as message update equations on a factor graph, involving messages between variable nodes and their neighboring factor nodes and vice versa. Considering messages between ''regions'' in a graph is one way of generalizing the belief propagation algorithm.&lt;ref name="GBP-2005" /&gt; There are several ways of defining the set of regions in a graph that can exchange messages. One method uses ideas introduced by [[Ryoichi Kikuchi|Kikuchi]] in the physics literature&lt;ref&gt;{{Cite journal|last=Kikuchi|first=Ryoichi|date=1951-03-15|title=A Theory of Cooperative Phenomena|url=https://link.aps.org/doi/10.1103/PhysRev.81.988|journal=Physical Review|volume=81|issue=6|pages=988–1003|doi=10.1103/PhysRev.81.988|bibcode=1951PhRv...81..988K}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kurata|first=Michio|last2=Kikuchi|first2=Ryoichi|last3=Watari|first3=Tatsuro|date=1953|title=A Theory of Cooperative Phenomena. III. Detailed Discussions of the Cluster Variation Method|url=http://aip.scitation.org/doi/abs/10.1063/1.1698926|journal=The Journal of Chemical Physics|volume=21|pages=434-448|via=AIP|bibcode=1953JChPh..21..434K|doi=10.1063/1.1698926}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kikuchi|first=Ryoichi|last2=Brush|first2=Stephen G.|date=1967|title=Improvement of the Cluster‐Variation Method|url=http://aip.scitation.org/doi/abs/10.1063/1.1711845|journal=The Journal of Chemical Physics|volume=47|pages=195-203|via=AIP|bibcode=1967JChPh..47..195K|doi=10.1063/1.1711845}}&lt;/ref&gt;, and is known as Kikuchi's [[cluster variation method]] &lt;ref&gt;{{Cite journal|last=Pelizzola|first=Alessandro|date=2005|title=Cluster variation method in statistical physics and probabilistic graphical models|url=http://stacks.iop.org/0305-4470/38/i=33/a=R01|journal=Journal of Physics A: Mathematical and General|language=en|volume=38|issue=33|pages=R309|doi=10.1088/0305-4470/38/33/R01|issn=0305-4470|arxiv=cond-mat/0508216|bibcode=2005JPhA...38R.309P}}&lt;/ref&gt;.

Improvements in the performance of belief propagation algorithms are also achievable by breaking the replicas symmetry in the distributions of the fields (messages). This generalization leads to a new kind of algorithm called [[survey propagation]] (SP), which have proved to be very efficient in [[NP-complete]] problems like [[satisfiability]]&lt;ref name="Sat"&gt;
{{Cite journal
 |last1=Braunstein |first1=A.
 |last2=Mézard |first2=M. 
 |last3=Zecchina
 |title=Survey propagation: An algorithm for satisfiability
 |journal=Random Structures &amp; Algorithms
 |volume=27 |issue=2 |pages=201&amp;ndash;226 |year=2005
 |doi=10.1002/rsa.20057
 |first3=R.
|arxiv=cs/0212002}}
&lt;/ref&gt;
and [[graph coloring]].

The cluster variational method and the survey propagation algorithms are two different improvements to belief propagation. The name [[generalized survey propagation]] (GSP) is waiting to be assigned to the algorithm that merges both generalizations.

==Gaussian belief propagation (GaBP)==
Gaussian belief propagation is a variant of the belief propagation algorithm when the underlying [[normal distribution|distributions are Gaussian]].  The first work analyzing this special model was the seminal work of Weiss and Freeman.&lt;ref name="GPbA"&gt;
{{Cite journal
 |last1=Weiss |first1=Yair
 |last2=Freeman |first2=William T.
 |title=Correctness of Belief Propagation in Gaussian Graphical Models of Arbitrary Topology
 |journal=[[Neural Computation (journal)|Neural Computation]]
 |volume=13 |issue=10 |pages=2173&amp;ndash;2200 |date=October 2001
 |doi=10.1162/089976601750541769
 |pmid=11570995
}}
&lt;/ref&gt;

The GaBP algorithm solves the following marginalization problem:

:&lt;math&gt; P(x_i) = \frac{1}{Z} \int_{j \ne i} \exp(-1/2x^TAx + b^Tx)\,dx_j&lt;/math&gt;

where Z is a normalization constant, ''A'' is a symmetric [[Positive-definite matrix|positive definite matrix]] (inverse covariance matrix a.k.a. precision matrix) and ''b'' is the shift vector.

Equivalently, it can be shown that using the Gaussian model, the solution of the marginalization problem is equivalent to the [[Maximum A Posteriori|MAP]] assignment problem:

: &lt;math&gt;\underset{x}{\operatorname{argmax}}\  P(x) = \frac{1}{Z} \exp(-1/2x^TAx + b^Tx).&lt;/math&gt;

This problem is also equivalent to the following minimization problem of the quadratic form:

: &lt;math&gt; \underset{x}{\operatorname{min}}\ 1/2x^TAx - b^Tx.&lt;/math&gt;

Which is also equivalent to the linear system of equations

: &lt;math&gt; Ax = b.&lt;/math&gt;

Convergence of the GaBP algorithm is easier to analyze (relatively to the general BP case) and there are two known sufficient convergence conditions.  The first one was formulated by Weiss et al. in the year 2000, when the information matrix A is [[diagonally dominant]]. The second convergence condition was formulated by Johnson et al.&lt;ref name="johnson"&gt;
{{Cite journal
 |first1=Dmitry M. |last1=Malioutov
 |first2=Jason K. |last2=Johnson
 |first3=Alan S. |last3=Willsky
 |title=Walk-sums and belief propagation in Gaussian graphical models
 |journal=[[Journal of Machine Learning Research]]
 |volume=7 |pages=2031–2064 |date=October 2006
 |url=http://jmlr.csail.mit.edu/papers/v7/malioutov06a.html |accessdate=2009-03-28
}}
&lt;/ref&gt; in 2006, when the [[spectral radius]] of the matrix

:&lt;math&gt;\rho (I - |D^{-1/2}AD^{-1/2}|) &lt; 1 \, &lt;/math&gt;

where ''D'' = diag(''A''). Later, Su and Wu established the necessary and sufficient convergence conditions for synchronous GaBP and damped GaBP, as well as another sufficient convergence condition for asynchronous GaBP.  For each case, the convergence condition involves verifying 1) a set (determined by A) being non-empty, 2) the spectral radius of a certain matrix being smaller than one, and 3) the singularity issue (when converting BP message into belief) does not occur.&lt;ref name = "su and wu"&gt;{{Cite journal
|first1 = Qinliang | last1=Su
|first2 = Yik-Chung | last2=Wu
|title = On convergence conditions of Gaussian belief propagation
|journal=[[IEEE Trans. Signal Process.]]
|volume=63 |issue = 5 |pages=1144–1155 |date= March 2015
|doi = 10.1109/TSP.2015.2389755
|url=http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7004066
|bibcode=2015ITSP...63.1144S}}
&lt;/ref&gt;

The GaBP algorithm was linked to the linear algebra domain,&lt;ref name="Bickson"&gt;Gaussian belief propagation solver for systems of linear equations. By O. Shental, D. Bickson, P. H. Siegel, J. K. Wolf, and D. Dolev, IEEE Int. Symp. on Inform. Theory (ISIT), Toronto, Canada, July 2008. http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ {{Webarchive|url=https://web.archive.org/web/20110614012544/http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ |date=14 June 2011 }}&lt;/ref&gt; and it was shown that the GaBP algorithm can be
viewed as an iterative algorithm for solving the linear system of equations
''Ax'' = ''b'' where ''A'' is the information matrix and ''b'' is the shift vector. Empirically, the GaBP algorithm is shown to converge faster than classical iterative methods like the Jacobi method, the [[Gauss&amp;ndash;Seidel method]], [[successive over-relaxation]], and others.&lt;ref name="Bickson2"&gt;Linear Detection via Belief Propagation. Danny Bickson, Danny Dolev, Ori Shental, Paul H. Siegel and Jack K. Wolf. In the 45th Annual Allerton Conference on Communication, Control, and Computing, Allerton House, Illinois, 7 Sept.. http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ {{Webarchive|url=https://web.archive.org/web/20110614012544/http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ |date=14 June 2011 }}&lt;/ref&gt; Additionally, the GaBP algorithm is shown to be immune to numerical problems of the preconditioned [[Conjugate gradient method|conjugate gradient]] method &lt;ref name="Bickson3"&gt;Distributed large scale network utility maximization. D. Bickson, Y. Tock, A. Zymnis, S. Boyd and D. Dolev. In the International symposium on information theory (ISIT), July 2009. http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ {{Webarchive|url=https://web.archive.org/web/20110614012544/http://www.cs.huji.ac.il/labs/danss/p2p/gabp/ |date=14 June 2011 }}&lt;/ref&gt;

==References==
{{Reflist}}

==Further reading==
* Bickson, Danny. (2009). [http://www.cs.cmu.edu/~bickson/gabp/index.html''Gaussian Belief Propagation Resource Page''] —Webpage containing recent publications as well as Matlab source code.
* {{Cite book
 |last=Bishop |first=Christopher M.
 |title=Pattern Recognition and Machine Learning
 |chapterurl=http://research.microsoft.com/en-us/um/people/cmbishop/prml/pdf/Bishop-PRML-sample.pdf |accessdate=2014-03-20
 |chapter=Chapter 8: Graphical models
 |isbn=0-387-31073-8
 |publisher=Springer
 |year=2006
 |pages=359&amp;ndash;418
}}
* Coughlan, James. (2009). [http://computerrobotvision.org/2009/tutorial_day/crv09_belief_propagation_v2.pdf''A Tutorial Introduction to Belief Propagation''].
* {{cite journal | last1 = Löliger | first1 = Hans-Andrea | year = 2004 | title = An Introduction to Factor Graphs | url = http://ieeexplore.ieee.org/document/1267047/ | journal = IEEE Signal Proc. Mag. | volume = 21 | issue = | pages = 28–41 }}
* Mackenzie, Dana (2005). "[https://www.newscientist.com/article/mg18725071-400-communication-speed-nears-terminal-velocity/ Communication Speed Nears Terminal Velocity]", ''[[New Scientist]]''. 9 July 2005. Issue 2507 (Registration required)
* {{Cite book
    | last = Wymeersch
    | first = Henk
    | title = Iterative Receiver Design
    | year = 2007
    | publisher = Cambridge University Press
    | url = http://www.cambridge.org/us/catalogue/catalogue.asp?isbn=9780521873154
    | isbn = 0-521-87315-0 }}
* {{Cite book
 |last1=Yedidia |first1=J.S.
 |last2=Freeman |first2=W.T. 
 |last3=Weiss   |first3=Y.
 |chapterurl=http://www.merl.com/publications/TR2001-022/  |accessdate=2009-03-30
 |chapter=Understanding Belief Propagation and Its Generalizations
 |title=Exploring Artificial Intelligence in the New Millennium
 |isbn=1-55860-811-7
 |pages=239&amp;ndash;269
 |date=January 2003
 |publisher=Morgan Kaufmann
 |editor1-first=Gerhard |editor1-last=Lakemeyer
 |editor2-first=Bernhard |editor2-last=Nebel
}}
* {{Cite journal
 |last1=Yedidia |first1=J.S.
 |last2=Freeman |first2=W.T.
 |last3=Weiss |first3=Y.
 |title=Constructing free-energy approximations and generalized belief propagation algorithms
 |journal=[[IEEE Transactions on Information Theory]]
 |volume=51 |issue=7 |pages=2282&amp;ndash;2312 |date=July 2005
 |doi=10.1109/TIT.2005.850085
 |url=http://www.merl.com/publications/TR2004-040/ |accessdate=2009-03-28
}}

{{DEFAULTSORT:Belief Propagation}}
[[Category:Graph algorithms]]
[[Category:Graphical models]]
[[Category:Coding theory]]</text>
      <sha1>2a9qzkrni2mn2oonn8jx6kpq6kqrbtw</sha1>
    </revision>
  </page>
  <page>
    <title>Brown measure</title>
    <ns>0</ns>
    <id>58559351</id>
    <revision>
      <id>861002154</id>
      <parentid>860993815</parentid>
      <timestamp>2018-09-24T14:32:47Z</timestamp>
      <contributor>
        <username>CASSIOPEIA</username>
        <id>31051948</id>
      </contributor>
      <comment>expert needed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1514">{{expert needed|mathematics|reason=review the article}}
In [[mathematics]], the '''Brown measure''' of an operator in a finite [[Von Neumann algebra#Factors|factor]] is a probability measure on the complex plane which may be viewed as an analog of the spectral counting measure (based on [[Eigenvalues and eigenvectors#algebraic multiplicity|algebraic multiplicity]]) of matrices. 

==Definition==
Let &lt;math&gt;\mathcal{M}&lt;/math&gt; be a finite factor with the canonical normalized trace &lt;math&gt;\tau&lt;/math&gt;. For every operator &lt;math&gt;A \in \mathcal{M}&lt;/math&gt;, the function

:&lt;math&gt;\lambda \mapsto \tau(\log \left|A-\lambda I\right|), \; \lambda \in \mathbb{C},&lt;/math&gt;

is [[Subharmonic function|subharmonic]] and its [[Laplacian]] in the [[Distribution (mathematics)|distributional]] sense is a probability measure on &lt;math&gt;\mathbb{C}&lt;/math&gt; which is called the Brown measure of &lt;math&gt;A&lt;/math&gt;.

==References==
* {{citation
 | last = Brown | first = Lawrence
 | journal = Pitman Res. Notes Math. Ser.
 | pages = 1-35
 | title = Lidskii's theorem in the type &lt;math&gt;II&lt;/math&gt; case
 | volume = 123
 | publisher = Longman Sci. Tech., Harlow
 | year = 1986}}. Geometric methods in operator algebras (Kyoto, 1983).

* {{citation
 | last1 = Haagerup | first1 = Uffe
 | last2 = Schultz | first2 = Hanne
 | journal = Publ. Math. Inst. hautes Etudes Sci.
 | pages = 19-111
 | title = Brown measures of unbounded operators in a general &lt;math&gt;II_1&lt;/math&gt; factor
 | volume = 109
 | year = 2009}}.

[[Category:Mathematical terminology]]</text>
      <sha1>ts91ajuk60xmm3og52vdd42izji95yz</sha1>
    </revision>
  </page>
  <page>
    <title>Chemical graph theory</title>
    <ns>0</ns>
    <id>14222708</id>
    <revision>
      <id>810194564</id>
      <parentid>798010738</parentid>
      <timestamp>2017-11-13T21:36:02Z</timestamp>
      <contributor>
        <username>Dragonflare82</username>
        <id>1351782</id>
      </contributor>
      <minor/>
      <comment>Topological indices are interesting constructs in chemical graph theory that weren't mentioned.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2330">'''Chemical graph theory''' is the [[topology (chemistry)|topology]] branch of [[mathematical chemistry]] which applies [[graph theory]] to [[mathematical modelling]] of chemical phenomena.&lt;ref&gt;Danail Bonchev, D.H. Rouvray (eds.) (1991) "Chemical Graph Theory: Introduction and Fundamentals", {{ISBN|0-85626-454-7}}&lt;/ref&gt;
The pioneers of the chemical graph theory are [[Alexandru Balaban]], [[Ante Graovac]], [[Ivan Gutman]], [[Haruo Hosoya]], [[Milan Randić]] and [[Nenad Trinajstić]]&lt;ref&gt;[http://public.carnet.hr/ccacaa/CCA-PDF/cca2004/v77-n1_n2/CCA_77_2004_1-15_randic.pdf Nenad Trinajstic – Pioneer of Chemical Graph Theory] {{webarchive|url=https://web.archive.org/web/20090718185836/http://public.carnet.hr/ccacaa/CCA-PDF/cca2004/v77-n1_n2/CCA_77_2004_1-15_randic.pdf |date=2009-07-18 }}, by [[Milan Randić]]&lt;/ref&gt; (also [[Wiener index|Harry Wiener]] and others).
In 1988, it was reported that several hundred researchers worked in this area producing about 500 articles annually. A number of monographs have been written in the area, including the two-volume comprehensive text by Trinajstic, ''Chemical Graph Theory'', that summarized the field up to mid-1980s.&lt;ref&gt;[https://www.jstor.org/stable/2030836 A review] of the book by Ivan Gutman, Oskar E. Polansky, "Mathematical Concepts in Organic Chemistry" in ''[[SIAM Review]]'' Vol. 30, No. 2 (1988), pp. 348-350&lt;/ref&gt;

The adherents of the theory maintain that the properties of a [[chemical graph]] (i.e., a graph-theoretical representation of a [[molecule]]) give valuable insights into the chemical phenomena. The opponents contend that graphs play only a fringe role in chemical research.&lt;ref&gt;D.H. Rouvray, "Combinatorics in Chemistry", pp. 1955-1982, in: [[Ronald Graham]], [[Martin Grötschel]], [[László Lovász]] (Eds.) (1996) ''[[Handbook of Combinatorics]],'' vol. II, {{ISBN|0-262-07169-X}}&lt;/ref&gt; One variant of the theory is the representation of materials as infinite [[Euclidean graph]]s, particularly crystals by [[Periodic Graphs (Crystallography)|periodic graphs]].

==See also==
* [[Molecule mining]]
* [[MATH/CHEM/COMP]]
* [[Mathematical chemistry]]
* [[Topological index]]

==References==
&lt;references/&gt;

[[Category:Theoretical chemistry]]
[[Category:Mathematical chemistry]]
[[Category:Application-specific graphs]]


{{theoretical-chem-stub}}</text>
      <sha1>9483rmo37tpsqkopb80y1hsah2hfi6f</sha1>
    </revision>
  </page>
  <page>
    <title>Coding gain</title>
    <ns>0</ns>
    <id>8975663</id>
    <revision>
      <id>630173324</id>
      <parentid>630173256</parentid>
      <timestamp>2014-10-19T00:09:09Z</timestamp>
      <contributor>
        <ip>2601:2:4D00:27B:C7D:48C0:2D67:6B1D</ip>
      </contributor>
      <comment>/* Bandwidth-limited regime */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5169">{{No footnotes|date=January 2013}}
{{Cleanup|reason = poor formatting, only a single source, and extremely difficult to read|date = October 2014}}

In [[coding theory]] and related engineering problems, '''coding gain''' is the measure in the difference between the [[signal-to-noise ratio]] (SNR) levels between the uncoded system and coded system required to reach the same [[bit error rate]] (BER) levels when used with the [[error correcting code]] (ECC).

==Example==
If the uncoded [[BPSK]] system in [[AWGN]] environment has a [[bit error rate]] (BER) of 10&lt;sup&gt;−2&lt;/sup&gt; at the SNR level 4&amp;nbsp;[[decibel|dB]], and the corresponding coded (e.g., [[BCH code|BCH]]) system has the same BER at an SNR of 2.5&amp;nbsp;dB, then we say the ''coding gain'' = {{nowrap|1=4 dB − 2.5 dB = 1.5 dB}}, due to the code used (in this case BCH).

==Power-limited regime==
In the ''power-limited regime'' (where the nominal [[spectral efficiency]] &lt;math&gt;\rho \le 2&lt;/math&gt; [b/2D or b/s/Hz], ''i.e.'' the domain of binary signaling), the effective coding gain &lt;math&gt;\gamma_\mathrm{eff}(A)&lt;/math&gt; of a signal set &lt;math&gt;A&lt;/math&gt; at a given target error probability per bit &lt;math&gt;P_b(E)&lt;/math&gt; is defined as the difference in dB between the &lt;math&gt;E_b/N_0&lt;/math&gt; required to achieve the target &lt;math&gt;P_b(E)&lt;/math&gt; with &lt;math&gt;A&lt;/math&gt; and the &lt;math&gt;E_b/N_0&lt;/math&gt; required to achieve the target &lt;math&gt;P_b(E)&lt;/math&gt; with 2-[[Pulse-amplitude modulation|PAM]] or (2&amp;times;2)-[[Quadrature amplitude modulation|QAM]] (''i.e.'' no coding). The nominal coding gain &lt;math&gt;\gamma_c(A)&lt;/math&gt; is defined as

: &lt;math&gt;\gamma_c(A) = \frac{d^2_{\min}(A)}{4E_b}.&lt;/math&gt;

This definition is normalized so that &lt;math&gt;\gamma_c(A) = 1&lt;/math&gt; for 2-PAM or (2&amp;times;2)-QAM. If the average number of nearest neighbors per transmitted bit &lt;math&gt;K_b(A)&lt;/math&gt; is equal to one, the effective coding gain &lt;math&gt;\gamma_\mathrm{eff}(A)&lt;/math&gt; is approximately equal to the nominal coding gain &lt;math&gt;\gamma_c(A)&lt;/math&gt;. However, if &lt;math&gt;K_b(A)&gt;1&lt;/math&gt;, the effective coding gain &lt;math&gt;\gamma_\mathrm{eff}(A)&lt;/math&gt; is less than the nominal coding gain &lt;math&gt;\gamma_c(A)&lt;/math&gt; by an amount which depends on the steepness of the &lt;math&gt;P_b(E)&lt;/math&gt; ''vs.'' &lt;math&gt;E_b/N_0&lt;/math&gt; curve at the target &lt;math&gt;P_b(E)&lt;/math&gt;. This curve can be plotted using the [[union bound]] estimate (UBE)

: &lt;math&gt;P_b(E) \approx K_b(A)Q\sqrt{\frac{2\gamma_c(A)E_b}{N_0}},&lt;/math&gt;

where ''Q'' is the [[error function|Gaussian probability-of-error function]].

For the special case of a binary [[linear block code]] &lt;math&gt;C&lt;/math&gt; with parameters &lt;math&gt;(n,k,d)&lt;/math&gt;, the nominal spectral efficiency is &lt;math&gt;\rho = 2k/n &lt;/math&gt; and the nominal coding gain is&amp;nbsp;''kd''/''n''.

==Example==
The table below lists the nominal spectral efficiency, nominal coding gain and effective coding gain at &lt;math&gt;P_b(E) \approx 10^{-5}&lt;/math&gt; for [[Reed–Muller code]]s of length &lt;math&gt;n \le 64&lt;/math&gt;:

{| class="wikitable"
 ! Code !! &lt;math&gt;\rho&lt;/math&gt; !! &lt;math&gt;\gamma_c&lt;/math&gt; !! &lt;math&gt;\gamma_c&lt;/math&gt; (dB) !! &lt;math&gt;K_b&lt;/math&gt; !! &lt;math&gt;\gamma_\mathrm{eff}&lt;/math&gt; (dB)
 |-
 | [8,7,2] || 1.75 || 7/4 || 2.43 || 4 || 2.0
 |-
 | [8,4,4] || 1.0 || 2 || 3.01 || 4 || 2.6
 |-
 | [16,15,2] || 1.88 || 15/8 || 2.73 || 8 || 2.1
 |-
 | [16,11,4] || 1.38 || 11/4 || 4.39 || 13 || 3.7
 |-
 | [16,5,8] || 0.63 || 5/2 || 3.98 || 6 || 3.5
 |-
 | [32,31,2] || 1.94 || 31/16 || 2.87 || 16 || 2.1
 |-
 | [32,26,4] || 1.63 || 13/4 || 5.12 || 48 || 4.0
 |-
 | [32,16,8] || 1.00 || 4 || 6.02 || 39 || 4.9
 |-
 | [32,6,16] || 0.37 || 3 || 4.77 || 10 || 4.2
 |-
 | [64,63,2] || 1.97 || 63/32 || 2.94 || 32 || 1.9
 |-
 | [64,57,4] || 1.78 || 57/16 || 5.52 || 183 || 4.0
 |-
 | [64,42,8] || 1.31 || 21/4 || 7.20 || 266 || 5.6
 |-
 | [64,22,16] || 0.69 || 11/2 || 7.40 || 118 || 6.0
 |-
 | [64,7,32] || 0.22 || 7/2 || 5.44 || 18 || 4.6
 |-
 |}

==Bandwidth-limited regime==
In the ''bandwidth-limited regime'' (&lt;math&gt;\rho &gt; 2b/2D&lt;/math&gt;, ''i.e.'' the domain of non-binary signaling), the effective coding gain &lt;math&gt;\gamma_\mathrm{eff}(A)&lt;/math&gt; of a signal set &lt;math&gt;A&lt;/math&gt; at a given target error rate &lt;math&gt;P_s(E)&lt;/math&gt; is defined as the difference in dB between the &lt;math&gt;SNR_\mathrm{norm}&lt;/math&gt; required to achieve the target &lt;math&gt;P_s(E)&lt;/math&gt; with &lt;math&gt;A&lt;/math&gt; and the &lt;math&gt;SNR_\mathrm{norm}&lt;/math&gt; required to achieve the target &lt;math&gt;P_s(E)&lt;/math&gt; with M-[[Pulse-amplitude modulation|PAM]] or (M&amp;times;M)-[[Quadrature amplitude modulation|QAM]] (''i.e.'' no coding). The nominal coding gain &lt;math&gt;\gamma_c(A)&lt;/math&gt; is defined as

: &lt;math&gt;\gamma_c(A) = {(2^\rho - 1)d^2_{\min} (A) \over 6E_s}.&lt;/math&gt;

This definition is normalized so that &lt;math&gt;\gamma_c(A) = 1&lt;/math&gt; for M-PAM or (''M''&amp;times;''M'')-QAM. The UBE becomes

: &lt;math&gt;P_s(E) \approx K_s(A)Q\sqrt{3\gamma_c(A)SNR_\mathrm{norm}},&lt;/math&gt;

where &lt;math&gt;K_s(A)&lt;/math&gt; is the average number of nearest neighbors per two dimensions.

==See also==
*[[Channel capacity]]
*[[Eb/N0]]

==References==
[http://ocw.mit.edu MIT OpenCourseWare], 6.451 Principles of Digital Communication II, Lecture Notes sections 5.3, 5.5, 6.3, 6.4

[[Category:Coding theory]]
[[Category:Error detection and correction]]</text>
      <sha1>o1b98rp6wh36se39hn3jlom7dkznpwj</sha1>
    </revision>
  </page>
  <page>
    <title>Controlled grammar</title>
    <ns>0</ns>
    <id>26358420</id>
    <revision>
      <id>858281263</id>
      <parentid>736696062</parentid>
      <timestamp>2018-09-06T02:55:01Z</timestamp>
      <contributor>
        <username>Shenme</username>
        <id>101696</id>
      </contributor>
      <minor/>
      <comment>not a typo|aaabbbccc</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33723">{{underlinked|date=November 2012}}
'''Controlled grammars'''&lt;ref name="dassow_et_al1997"&gt;Dassow, J., Pǎun, Gh., and Salomaa, A. Grammars with Controlled Derivations. In G. Rozenberg and A. Salomaa (Eds.) ''Handbook of Formal Languages'', Vol. 2, Ch. 3.&lt;/ref&gt; are a class of grammars that extend, usually, the [[context-free grammar]]s with additional controls on the derivations of a sentence in the language. A number of different kinds of controlled grammars exist, the four main divisions being [[Indexed grammar]]s, grammars with prescribed derivation sequences, grammars with contextual conditions on rule application, and grammars with parallelism in rule application. Because indexed grammars are so well established in the field, this article will address only the latter three kinds of controlled grammars.

==Control by prescribed sequences==
Grammars with prescribed sequences are grammars in which the sequence of rule application is constrained in some way. There are four different versions of prescribed sequence grammars: language controlled grammars (often called just controlled grammars), matrix grammars, vector grammars, and programmed grammars.

In the standard context-free grammar formalism, a grammar itself is viewed as a 4-tuple, &lt;math&gt;G = (N, T, S, P)&lt;/math&gt;, where ''N'' is a set of non-terminal/phrasal symbols, ''T'' is a disjoint set of terminal/word symbols, ''S'' is a specially designated start symbol chosen from ''N'', and ''P'' is a set of production rules like &lt;math&gt;X \to \alpha&lt;/math&gt;, where ''X'' is some member of ''N'', and &lt;math&gt;\alpha&lt;/math&gt; is some member of &lt;math&gt;(N \cup T)^{*}&lt;/math&gt;.

Productions over such a grammar are sequences of rules in ''P'' that, when applied in order of the sequence, lead to a terminal string. That is, one can view the set of imaginable derivations in ''G'' as the set &lt;math&gt;\{ p_1 p_2 ... p_n : n \geq 0 \}&lt;/math&gt;, and the language of ''G'' as being the set of terminal strings &lt;math&gt;L(G) = \{ w \in T^{*} : S \Rightarrow_{p_1} ... \Rightarrow_{p_n} w \}&lt;/math&gt;. Control grammars take seriously this definition of the language generated by a grammar, concretizing the set-of-derivations as an aspect of the grammar. Thus, a prescribed sequence controlled grammar is at least approximately a 5-tuple &lt;math&gt;G = (N, T, S, P, R)&lt;/math&gt; where everything except ''R'' is the same as in a CFG, and ''R'' is an infinite set of valid derivation sequences &lt;math&gt;p_1 p_2 ... p_n&lt;/math&gt;.

The set ''R'', due to its infinitude, is almost always (though not necessarily) described via some more convenient mechanism, such as a grammar (as in language controlled grammars), or a set of matrices or vectors (as in matrix and vector grammars). The different variations of prescribed sequence grammars thus differ by how the sequence of derivations is defined on top of the context-free base. Because matrix grammars and vector grammars are essentially special cases of language controlled grammars, examples of the former two will not be provided below.

===Language controlled grammars===
Language controlled grammars are grammars in which the production sequences constitute a well-defined language of arbitrary nature, usually though not necessarily regular, over a set of (again usually though not necessarily) context-free production rules. They also often have a sixth set in the grammar tuple, making it &lt;math&gt;G = (N, T, S, P, R, F)&lt;/math&gt;, where ''F'' is a set of productions that are allowed to apply vacuously. This version of language controlled grammars, ones with what is called "appearance checking", is the one henceforth.

====Proof-theoretic description====
We let a regularly controlled context-free grammar with appearance checking be a 6-tuple &lt;math&gt;G = (N, T, S, P, R, F)&lt;/math&gt; where ''N'', ''T'', ''S'', and ''P'' are defined as in CFGs, ''R'' is a subset of ''P*'' constituting a regular language over ''P'', and ''F'' is some subset of ''P''. We then define the immediately derives relation &lt;math&gt;\Rightarrow_{p_i}&lt;/math&gt; as follows:

Given some strings ''x'' and ''y'', both in &lt;math&gt;(N \cup T)^{*}&lt;/math&gt;, and some rule &lt;math&gt;p = A \to w \in P&lt;/math&gt;,

: &lt;math&gt;x \Rightarrow^{ac}_{p} y&lt;/math&gt;

holds if either

: &lt;math&gt;x = x_{1}Ax_{2}&lt;/math&gt; and &lt;math&gt;y = y_{1}wy_{2}&lt;/math&gt;, or
: &lt;math&gt;x = y&lt;/math&gt; and &lt;math&gt;p \in F&lt;/math&gt;

Intuitively, this simply spells out that a rule can apply to a string if the rule's left-hand-side appears in that string, or if the rule is in the set of "vacuously applicable" rules which can "apply" to a string without changing anything. This requirement that the non-vacuously applicable rules must apply is the appearance checking aspect of such a grammar. The language for this kind of grammar is then simply set of terminal strings &lt;math&gt;L(G) = \{ w \in T^{*} : S \Rightarrow^{ac}_{p_1} w_{1} \Rightarrow^{ac}_{p_2} w_{2} \Rightarrow^{ac}_{p_3} ... \Rightarrow^{ac}_{p_n} w,\ for\ some\ p_1 p_2 ... p_n \in R \}&lt;/math&gt;.

====Example====
Let's consider a simple (though not the simplest) context-free grammar that generates the language &lt;math&gt;\{ a^n : n \geq 1 \}&lt;/math&gt;:

Let &lt;math&gt; G = (\{S, A, X\}, \{a\}, S, \{f,g,h,k,l\})&lt;/math&gt;, where

: &lt;math&gt;f: S \to AA&lt;/math&gt;
: &lt;math&gt;g: S \to X&lt;/math&gt;
: &lt;math&gt;h: A \to S&lt;/math&gt;
: &lt;math&gt;k: A \to X&lt;/math&gt;
: &lt;math&gt;l: S \to a&lt;/math&gt;

In language controlled form, this grammar is simply &lt;math&gt;G^{\prime} = (\{S, A, X\}, \{a\}, S, \{f, g, h, k, l\}, (f|g|h|k|l)^{*}, \{f, g, h, k, l\})&lt;/math&gt; (where &lt;math&gt;(f|g|h|k|l)^{*}&lt;/math&gt; is a regular expression denoting the set of all sequences of production rules). A simple modification to this grammar, changing is control sequence set ''R'' into the set &lt;math&gt;(f^{*}gh^{*}k)^{*}l^{*}&lt;/math&gt;, and changing its vacuous rule set ''F'' to &lt;math&gt;\{g, k\}&lt;/math&gt;, yields a grammar which generates the non-CF language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;. To see how, let's consider the general case of some string with ''n'' instances of ''S'' in it, i.e. &lt;math&gt;S^n&lt;/math&gt; (the special case &lt;math&gt;S^1&lt;/math&gt; trivially derives the string ''a'' which is &lt;math&gt;a^{2^0}&lt;/math&gt;, an uninteresting fact).

If we chose some arbitrary production sequence &lt;math&gt;f^u g h^v k ...&lt;/math&gt;, we can consider three possibilities: &lt;math&gt;n = u&lt;/math&gt;, &lt;math&gt;n &lt; u&lt;/math&gt;, and &lt;math&gt;n &gt; u&lt;/math&gt; When &lt;math&gt;n = u&lt;/math&gt; we rewrite all ''n'' instances of ''S'' as ''AA'', by applying rule ''f'' to the string ''u'' times, and proceed to apply ''g'', which applies vacuously (by virtue of being in ''F'') . When &lt;math&gt;n &lt; u&lt;/math&gt;, we rewrite all ''n'' instances of ''S'' as ''AA'', and then try to perform the ''n+1'' rewrite using rule ''f'', but this fails because there are no more ''S''s to rewrite, and ''f'' is not in ''F'' and so cannot apply vacuously, thus when &lt;math&gt;n &lt; u&lt;/math&gt;, the derivation fails. Lastly, then &lt;math&gt;n &gt; u&lt;/math&gt;, we rewrite ''u'' instances of ''S'', leaving at least one instance of ''S'' to be rewritten by the subsequent application of ''g'', rewriting ''S'' as ''X''. Given that no rule of this grammar ever rewrites ''X'', such a derivation is destined to never produce a terminal string. Thus only derivations with &lt;math&gt;n = u&lt;/math&gt; will ever successfully rewrite the string &lt;math&gt;S^n&lt;/math&gt;. Similar reasoning holds of the number of ''A''s and ''v''. In general, then, we can say that the only valid derivations have the structure &lt;math&gt;S^n \Rightarrow_{f} ... \Rightarrow_{f} A^{2n} \Rightarrow{g} A^{2n} \Rightarrow{h} ... \Rightarrow{h} S^{2n} \Rightarrow{k} S^{2n}&lt;/math&gt; will produce terminal strings of the grammar. The ''X'' rules, combined with the structure of the control, essentially force all ''S''s to be rewritten as ''AA''s prior to any ''A''s being rewritten as ''S''s, which again is forced to happen prior to all still later iterations over the ''S-to-AA'' cycle. Finally, the ''S''s are rewritten as ''a''s. In this way, the number of ''S''s doubles each for each instantiation of &lt;math&gt;f^{8} g h^{*} k&lt;/math&gt; that appears in a terminal-deriving sequence.

Choosing two random non-terminal deriving sequences, and one terminal-deriving one, we can see this in work:

Let &lt;math&gt;s_1 = ffghkll&lt;/math&gt;, then we get the failed derivation:

: &lt;math&gt;S \Rightarrow^{ac}_{f} AA \Rightarrow^{ac}_{f} \text{failure: f cannot apply, no S to rewrite}&lt;/math&gt;

Let &lt;math&gt;s_2 = fghhhkll&lt;/math&gt;, then we get the failed derivation:

: &lt;math&gt;S \Rightarrow^{ac}_{f} AA \Rightarrow^{ac}_{g} AA \Rightarrow^{ac}_{h} SA \Rightarrow^{ac}_{h} SS \Rightarrow^{ac}_{h} \text{failure: h cannot apply, no A to rewrite}&lt;/math&gt;

Let &lt;math&gt;s_3 = fghhkll&lt;/math&gt;, then we get the successful derivation:

: &lt;math&gt;S \Rightarrow^{ac}_{f} AA \Rightarrow^{ac}_{g} AA \Rightarrow^{ac}_{h} SA \Rightarrow^{ac}_{h} SS \Rightarrow^{ac}_{k} SS \Rightarrow^{ac}_{l} aS \Rightarrow^{ac}_{l} aa&lt;/math&gt;

Similar derivations with a second cycle of &lt;math&gt;f^{*}gh^{*}k&lt;/math&gt; produce only ''SSSS''. Showing only the (continued) successful derivation:

: &lt;math&gt;... \Rightarrow SS \Rightarrow^{ac}_{f} AAS \Rightarrow^{ac}_{f} AAAA \Rightarrow^{ac}_{g} AAAA&lt;/math&gt;

:: &lt;math&gt;\Rightarrow^{ac}_{h} SAAA \Rightarrow^{ac}_{h} SSAA \Rightarrow^{ac}_{h} SSSA \Rightarrow^{ac}_{h} SSSS \Rightarrow^{ac}_{k} SSSS&lt;/math&gt;

:: &lt;math&gt;\Rightarrow^{ac}_{l} aSSS \Rightarrow^{ac}_{l} aaSS \Rightarrow^{ac}_{l} aaaS \Rightarrow^{ac}_{l} aaaa&lt;/math&gt;

===Matrix grammars===
Matrix grammars (expanded on in their own [[Matrix grammar|article]]) are a special case of regular controlled context-free grammars, in which the production sequence language is of the form &lt;math&gt;(m_1|m_2|...|m_n)^{*}&lt;/math&gt;, where each "matrix" &lt;math&gt;m_i&lt;/math&gt; is a single sequence. For convenience, such a grammar is not represented with a grammar over ''P'', but rather with just a set of the matrices in place of both the language and the production rules. Thus, a matrix grammar is the 5-tuple &lt;math&gt;G = (N, T, M, S, F)&lt;/math&gt;, where ''N'', ''T'', ''S'', and ''F'' are defined essentially as previously done (with ''F'' a subset of ''M'' this time), and ''M'' is a set of matrices &lt;math&gt;m_i = p_{i,1} p_{i,2} ... p_{i,n_i}&lt;/math&gt; where each &lt;math&gt;p_{i,j}&lt;/math&gt; is a context-free production rule.

The derives relation in a matrix grammar is thus defined simply as:

Given some strings ''x'' and ''y'', both in &lt;math&gt;(N \cup T)^{*}&lt;/math&gt;, and some matrix &lt;math&gt;m = p_1 p_2 ... p_n \in M&lt;/math&gt;,

: &lt;math&gt;x \Rightarrow^{ac}_{m} y&lt;/math&gt;

holds if either

: &lt;math&gt;x = x_{1}Ax_{2}&lt;/math&gt;, &lt;math&gt;y = y_{1}wy_{2}&lt;/math&gt;, and &lt;math&gt;A \Rightarrow^{ac}_{p_1} w_1 \Rightarrow^{ac}_{p_2} w_2 \Rightarrow^{ac}_{p_3} ... \Rightarrow^{ac}_{p_n} w&lt;/math&gt;, or
: &lt;math&gt;x = y&lt;/math&gt; and &lt;math&gt;m \in F&lt;/math&gt;

Informally, a matrix grammar is simply a grammar in which during each rewriting cycle, a particular sequence of rewrite operations must be performed, rather than just a single rewrite operation, i.e. one rule "triggers" a cascade of other rules. Similar phenomena can be performed in the standard context-sensitive idiom, as done in rule-based phonology and earlier [[Transformational grammar]], by what are known as "feeding" rules, which alter a derivation in such a way as to provide the environment for a non-optional rule that immediately follows it.

===Vector grammars===
Vector grammars are closely related to matrix grammars, and in fact can be seen as a special class of matrix grammars, in which if &lt;math&gt;m \in M&lt;/math&gt;, then so are all of its permutations &lt;math&gt;p(m)&lt;/math&gt;. For convenience, however, we will define vector grammars as follows: a vector grammar is a 5-tuple &lt;math&gt;G = (N, T, M, S, F)&lt;/math&gt;, where ''N'', ''T'', and ''F'' are defined previously (''F'' being a subset of ''M'' again), and where ''M'' is a set of vectors &lt;math&gt;m_i = \{ p_1, p_2, ..., p_n \}&lt;/math&gt;, each vector being a set of context free rules.

The derives relation in a vector grammar is then:

Given some strings ''x'' and ''y'', both in &lt;math&gt;(N \cup T)^{*}&lt;/math&gt;, and some matrix &lt;math&gt;m = \{ p_1, p_2, ..., p_n \} \in M&lt;/math&gt;,

: &lt;math&gt;x \Rightarrow^{ac}_{m} y&lt;/math&gt;

holds if either

: &lt;math&gt;x = x_{1}Ax_{2}&lt;/math&gt;, &lt;math&gt;y = y_{1}wy_{2}&lt;/math&gt;, and &lt;math&gt;A \Rightarrow^{ac}_{p_{i_1}} w_1 \Rightarrow^{ac}_{p_{i_2}} w_2 \Rightarrow^{ac}_{p_{i_3}} ... \Rightarrow^{ac}_{p_{i_n}} w&lt;/math&gt;, where &lt;math&gt;m = \{p_{i_1}, p_{i_2}, ..., p_{i_n}\}&lt;/math&gt;, or
: &lt;math&gt;x = y&lt;/math&gt; and &lt;math&gt;m \in F&lt;/math&gt;

Notice that the number of production rules used in the derivation sequence, ''n'', is the same as the number of production rules in the vector. Informally, then, a vector grammar is one in which a set of productions is applied, each production applied exactly once, in arbitrary order, to derive one string from another. Thus vector grammars are almost identical to matrix grammars, minus the restriction on the order in which the productions must occur during each cycle of rule application.

===Programmed grammars===
Programmed grammars are relatively simple extensions to context-free grammars with rule-by-rule control of the derivation. A programmed grammar is a 4-tuple &lt;math&gt;G = (N, T, S, P)&lt;/math&gt;, where ''N'', ''T'', and ''S'' are as in a context-free grammar, and ''P'' is a set of tuples &lt;math&gt;(p, \sigma, \phi)&lt;/math&gt;, where ''p'' is a context-free production rule, &lt;math&gt;\sigma&lt;/math&gt; is a subset of ''N'' (called the success field), and &lt;math&gt;\phi&lt;/math&gt; is a subset of ''N'' (called the failure field). If the failure field of every rule in ''P'' is empty, the grammar lacks appearance checking, and if at least one failure field is not empty, the grammar has appearance checking. The derivation relation on a programmed grammar is defined as follows:

Given two strings &lt;math&gt;x, y \in (N \cup T)^{*}&lt;/math&gt;, and some rule &lt;math&gt;p = (A \to w, \sigma, \phi) \in P&lt;/math&gt;,

: &lt;math&gt;x \Rightarrow_{p} y&lt;/math&gt; and &lt;math&gt;x = x'Ax'', y = x'wx''&lt;/math&gt;, or
: &lt;math&gt;x = y&lt;/math&gt; and A does not appear in x.

The language of a programmed grammar ''G'' is defined by constraining the derivation rule-wise, as &lt;math&gt;L(G) = \{ w \in (N \cup T)^{*} : S \Rightarrow_{p_1} w_1 \Rightarrow_{p_2} ... \Rightarrow_{p_n} w \}&lt;/math&gt;, where for each &lt;math&gt;p_i = (A_i \to v_i, \sigma_i, \phi_i)&lt;/math&gt;, either &lt;math&gt;w_{i-1} = x_{i-1} A x'_{i-1}, w_i = x_{i-1} v_i x'_{i-1},\ and\ p_{i+1} \in \sigma_i&lt;/math&gt; or &lt;math&gt;w_{i-1} = w_i, p_{i+1} \in \phi_i&lt;/math&gt;.

Intuitively, when applying a rule ''p'' in a programmed grammar, the rule can either succeed at rewriting a symbol in the string, in which case the subsequent rule must be in ''p''s success field, or the rule can fail to rewrite a symbol (thus applying vacuously), in which case the subsequent rule must be in ''p''s failure field. The choice of which rule to apply to the start string is arbitrary, unlike in a language controlled grammar, but once a choice is made the rules that can be applied after it constrain the sequence of rules from that point on.

====Example====
As with so many controlled grammars, programmed grammars can generate the language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;:

Let &lt;math&gt;G = (\{S, A\}, \{a\}, S, \{r_1,r_2,r_3\})&lt;/math&gt;, where

: &lt;math&gt;r_1 = (S \to AA, \{r_1\}, \{r_2\})&lt;/math&gt;
: &lt;math&gt;r_2 = (A \to S, \{r_2\}, \{r_1, r_3\})&lt;/math&gt;
: &lt;math&gt;r_3 = (S \to a, \{r_3\}, \emptyset)&lt;/math&gt;

The derivation for the string ''{{not a typo|aaaa}}'' is as follows:

: &lt;math&gt;S \Rightarrow_{r_1} AA \Rightarrow_{r_1} AA \Rightarrow_{r_2} SA \Rightarrow_{r_2} SS \Rightarrow_{r_2} SS&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_1} AAS \Rightarrow_{r_1} AAAA \Rightarrow_{r_1} AAAA&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_2} SAAA \Rightarrow_{r_2} SSAA \Rightarrow_{r_2} SSSA \Rightarrow_{r_2} SSSS \Rightarrow_{r_2} SSSS&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_3} aSSS \Rightarrow_{r_3} aaSS \Rightarrow_{r_3} aaaS \Rightarrow_{r_3} aaaa \Rightarrow_{r_3} aaaa&lt;/math&gt;

As can be seen from the derivation and the rules, each time &lt;math&gt;r_1&lt;/math&gt; and &lt;math&gt;r_2&lt;/math&gt; succeed, they feed back to themselves, which forces each rule to continue to rewrite the string over and over until it can do so no more. Upon failing, the derivation can switch to a different rule. In the case of &lt;math&gt;r_1&lt;/math&gt;, that means rewriting all ''S''s as ''AA''s, then switching to &lt;math&gt;r_2&lt;/math&gt;. In the case of &lt;math&gt;r_2&lt;/math&gt;, it means rewriting all ''A''s as ''S''s, then switching either to &lt;math&gt;r_1&lt;/math&gt;, which will lead to doubling the number of ''S''s produced, or to &lt;math&gt;r_3&lt;/math&gt; which converts the ''S''s to ''a''s then halts the derivation. Each cycle through &lt;math&gt;r_1&lt;/math&gt; then &lt;math&gt;r_2&lt;/math&gt; therefore either doubles the initial number of ''S''s, or converts the ''S''s to ''a''s. The trivial case of generating ''a'', in case it is difficult to see, simply involves vacuously applying &lt;math&gt;r_1&lt;/math&gt;, thus jumping straight to &lt;math&gt;r_2&lt;/math&gt; which also vacuously applies, then jumping to &lt;math&gt;r_3&lt;/math&gt; which produces ''a''.

==Control by context conditions==
Unlike grammars controlled by prescribed sequences of production rules, which constrain the space of valid derivations but do not constrain the sorts of sentences that a production rule can apply to, grammars controlled by context conditions have no sequence constraints, but permit constraints of varying complexity on the sentences to which a production rule applies. Similar to grammars controlled by prescribed sequences, there are multiple different kinds of grammars controlled by context conditions: conditional grammars, semi-conditional grammars, random context grammars, and ordered grammars.

===Conditional grammars===
Conditional grammars are the simplest version of grammars controlled by context conditions. The structure of a conditional grammar is very similar to that of a normal rewrite grammar: &lt;math&gt;G = (N, T, S, P)&lt;/math&gt;, where ''N'', ''T'', and ''S'' are as defined in a context-free grammar, and ''P'' is a set of pairs of the form &lt;math&gt;(p, R)&lt;/math&gt; where ''p'' is a production rule (usually context-free), and ''R'' is a language (usually regular) over &lt;math&gt;N \cup T&lt;/math&gt;. When ''R'' is regular, ''R'' can just be expressed as a regular expression.

====Proof-theoretic definition====
With this definition of a conditional grammar, we can define the derives relation as follows:

Given two strings &lt;math&gt;x, y \in (N \cup T)^{*}&lt;/math&gt;, and some production rule &lt;math&gt;p = (A \to w, R) \in P&lt;/math&gt;,

: &lt;math&gt;x \Rightarrow_{p} y&lt;/math&gt; if and only if &lt;math&gt;x = x' A x''&lt;/math&gt;, &lt;math&gt;y = x' w x''&lt;/math&gt;, and &lt;math&gt;x \in R&lt;/math&gt;

Informally then, the production rule for some pair in ''P'' can apply only to strings that are in its context language. Thus, for example, if we had some pair &lt;math&gt;(S \to x, a^{*}Sb^{*})&lt;/math&gt;, we can only apply this to strings consisting of any number of ''a''s followed by exactly only ''S'' followed by any number of ''b''s, i.e. to sentences in &lt;math&gt;\{ a^m A b^n : m, n \geq 0 \}&lt;/math&gt;, such as the strings ''S'', ''aSb'', ''{{not a typo|aaaS}}'', ''{{not a typo|aSbbbbbb}}'', etc. It cannot apply to strings like ''xSy'', ''{{not a typo|aaaSxbbb}}'', etc.

====Example====
Conditional grammars can generate the context-sensitive language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;.

Let &lt;math&gt;G = (\{S, S'\}, \{a\}, \{ f, g, h \}, S)&lt;/math&gt;, where

: &lt;math&gt;f = (S \to AA, A^{*}S^{+})&lt;/math&gt;
: &lt;math&gt;g = (A \to B, B^{*}A^{+})&lt;/math&gt;
: &lt;math&gt;h = (B \to S, S^{*}B^{+})&lt;/math&gt;
: &lt;math&gt;k = (S \to a, a^{*}S^{+})&lt;/math&gt;

We can then generate the sentence ''{{not a typo|aaaa}}'' with the following derivation:

: &lt;math&gt;S \Rightarrow_{f} AA \Rightarrow_{g} BA \Rightarrow_{g} BB&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{h} SB \Rightarrow_{h} SS \Rightarrow_{f} AAS \Rightarrow_{f} AAAA&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{g} BAAA \Rightarrow_{g} BBAA \Rightarrow_{g} BBBA \Rightarrow_{g} BBBB&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{h} SBBB \Rightarrow_{h} SSBB \Rightarrow_{h} SSSB \Rightarrow_{h} SSSS&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{k} aSSS \Rightarrow_{k} aaSS \Rightarrow_{k} aaaS \Rightarrow_{k} aaaa&lt;/math&gt;

===Semi-conditional grammars===
A semi-conditional grammar is very similar to a conditional grammar, and technically the class of semi-conditional grammars are a subset of the conditional grammars. Rather than specifying what the whole of the string must look like for a rule to apply, semi-conditional grammars specify that a string must have as substrings all of some set of strings, and none of another set, in order for a rule to apply. Formally, then, a semi-conditional grammar is a tuple &lt;math&gt;G = (N, T, S, P)&lt;/math&gt;, where, ''N'', ''T'', and ''S'' are defined as in a CFG, and ''P'' is a set of rules like &lt;math&gt;(p, R, Q)&lt;/math&gt; where ''p'' is a (usually context-free) production rule, and ''R'' and ''Q'' are finite sets of strings. The derives relation can then be defined as follows.

For two strings &lt;math&gt;xAx', xwx' \in (N \cup T)^{*}&lt;/math&gt;, and some rule &lt;math&gt;p = (A \to w, R, Q) \in P&lt;/math&gt;,

: &lt;math&gt;xAx' \Rightarrow_{p} xwx'&lt;/math&gt; if and only if every string in ''R'' is a substring of &lt;math&gt;xAx'&lt;/math&gt;, and no string in ''Q'' is a substring of &lt;math&gt;xAx'&lt;/math&gt;

The language of a semi-conditional grammar is then trivially the set of terminal strings &lt;math&gt;L(G) = \{ w \in T^{*} : S \Rightarrow^{*} w \}&lt;/math&gt;.

An example of a semi-conditional grammar is given below also as an example of random context grammars.

===Random context grammars===
A random context grammar is a semi-conditional grammar in which the ''R'' and ''Q'' sets are all subsets of ''N''. Because subsets of ''N'' are finite sets over &lt;math&gt;(N \cup T)^{*}&lt;/math&gt;, it is clear that random context grammars are indeed kinds of semi-conditional grammars.

====Example====
Like conditional grammars, random context grammars (and thus semi-conditional grammars) can generate the language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;. One grammar which can do this is:

Let &lt;math&gt;G = (\{S, X, Y, A\}, \{a\}, S, \{r_1, r_2, r_3, r_4, r_5\})&lt;/math&gt;, where

: &lt;math&gt;r_1 = (S \to X X, \emptyset, \{Y, A\})&lt;/math&gt;
: &lt;math&gt;r_2 = (X \to Y, \emptyset, \{S\})&lt;/math&gt;
: &lt;math&gt;r_3 = (Y \to S, \emptyset, \{X\})&lt;/math&gt;
: &lt;math&gt;r_4 = (S \to A, \emptyset, \{X\})&lt;/math&gt;
: &lt;math&gt;r_5 = (A \to a, \emptyset, \{S\})&lt;/math&gt;

Consider now the production for ''{{not a typo|aaaa}}'':

: &lt;math&gt;S \Rightarrow_{r_1} X X \Rightarrow_{r_2} Y X \Rightarrow_{r_2} Y Y \Rightarrow_{r_3} S Y \Rightarrow_{r_3} S S&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_1} X X S \Rightarrow_{r_1} X X X X \Rightarrow_{r_2} Y X X X \Rightarrow_{r_2} Y Y X X \Rightarrow_{r_2} Y Y Y X \Rightarrow_{r_2} Y Y Y Y&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_3} S Y Y Y \Rightarrow_{r_3} S S Y Y \Rightarrow_{r_3} S S S Y \Rightarrow_{r_3} S S S S&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_4} A S S S \Rightarrow_{r_4} A A S S \Rightarrow_{r_4} A A A S \Rightarrow_{r_4} A A A A&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{r_5} a A A A \Rightarrow_{r_5} a a A A \Rightarrow_{r_5} a a a A \Rightarrow_{r_5} a a a a&lt;/math&gt;

The behavior of the ''R'' sets here is trivial: any string can be rewritten according to them, because they do not require any substrings to be present. The behavior of the ''Q'' sets, however, are more interesting. In &lt;math&gt;r_1&lt;/math&gt;, we are forced by the ''Q'' set to rewrite an ''S'', thus beginning an ''S''-doubling process, only when no ''Y''s or ''A''s are present in the string, which means only when a prior ''S''-doubling process has been fully initiated, eliminating the possibility of only doubling some of the ''S''s. In &lt;math&gt;r_2&lt;/math&gt;, which moves the ''S''-doubling process into its second stage, we cannot begin this process until the first stage is complete and there are no more ''S''s to try to double, because the ''Q'' set prevents the rule from applying if there is an ''S'' symbol still in the string. In &lt;math&gt;r_3&lt;/math&gt;, we complete the doubling stage by introducing the ''S''s back only when there are no more ''X''s to rewrite, thus when the second stage is complete. We can cycle through these stages as many times as we want, rewriting all ''S''s to ''XX''s before then rewriting each ''X'' to a Y, and then each ''Y'' to an ''S'', finally ending by replacing each ''S'' with an ''A'' and then an ''a''. Because the rule for replacing ''S'' with ''A'' prohibits application to a string with an ''X'' in it, we cannot apply this in the middle of the first stage of the ''S''-doubling process, thus again preventing us from only doubling some ''S''s.

===Ordered grammars===
Ordered grammars are perhaps one of the simpler extensions of grammars into the controlled grammar domain. An ordered grammar is simply a tuple &lt;math&gt;G = (N, T, S, P)&lt;/math&gt; where ''N'', ''T'', and ''S'' are identical to those in a CFG, and ''P'' is a set of context-free rewrite rules with a partial ordering &lt;math&gt;&lt;&lt;/math&gt;. The partial ordering is then used to determine which rule to apply to a string, when multiple rules are applicable. The derives relation is then:

Given some strings &lt;math&gt;xAx', xwx' \in (N \cup T)^{*}&lt;/math&gt; and some rule &lt;math&gt;p = A \to w \in P&lt;/math&gt;,

: &lt;math&gt;xAx' \Rightarrow_{p} xwx'&lt;/math&gt; if and only if there is no rule &lt;math&gt;p' = A \to w' \in P&lt;/math&gt; such that &lt;math&gt;p &lt; p'&lt;/math&gt;.

====Example====
Like many other contextually controlled grammars, ordered grammars can enforce the application of rules in a particular order. Since this is the essential property of previous grammars that could generate the language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;, it should be no surprise that a grammar that explicitly uses rule ordering, rather than encoding it via string contexts, should similarly be able to capture that language. And as it turns out, just such an ordered grammar exists:

Let &lt;math&gt;G = (\{S, X, Y, Z, A\}, \{a\}, S, P)&lt;/math&gt;, where ''P'' is the partially ordered set described by the [[Hasse diagram]]

: [[Image:Ordered_grammar.svg]]

The derivation for the string ''{{not a typo|aaaa}}'' is simply:

: &lt;math&gt;S \Rightarrow_{S \to XX}\  XX \ \Rightarrow_{X \to Y}\  YX \ \Rightarrow_{X \to Y}\  YY \ \Rightarrow_{Y \to S}\  SY \ \Rightarrow_{Y \to S}\  YY&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{S \to XX}\  XXS \ \Rightarrow_{S \to XX}\  XXXX&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{X \to Y}\  YXXX \ \Rightarrow_{X \to Y}\  YYXX \ \Rightarrow_{X \to Y}\  YYYX \ \Rightarrow_{X \to Y}\  YYYY&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{Y \to S}\  SYYY \ \Rightarrow_{Y \to S}\  SSYY \ \Rightarrow_{Y \to S}\  SSSY \ \Rightarrow_{Y \to S}\  SSSS&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{S \to A}\  ASSS \ \Rightarrow_{S \to A}\  AASS \ \Rightarrow_{S \to A}\  AAAS \ \Rightarrow_{S \to A}\  AAAA&lt;/math&gt;
:: &lt;math&gt;\Rightarrow_{A \to a}\  aAAA \ \Rightarrow_{A \to a}\  aaAA \ \Rightarrow_{A \to a}\  aaaA \ \Rightarrow_{A \to a}\  aaaa&lt;/math&gt;

At each step of the way, the derivation proceeds by rewriting in cycles. Notice that if at the fifth step ''SY'', we had four options: &lt;math&gt;Y \to Z, S \to Z, Y \to S, S \to A&lt;/math&gt;, the first two of which halt the derivation, as ''Z'' cannot be rewritten. In the example, we used &lt;math&gt;Y \to S&lt;/math&gt; to derive ''SS'', but consider if we had chosen &lt;math&gt;S \to A&lt;/math&gt; instead. We would have produced the string ''AS'', the options for which are &lt;math&gt;Y \to Z&lt;/math&gt; and &lt;math&gt;A \to Z&lt;/math&gt;, both of which halt the derivation. Thus with the string ''SY'', and conversely with ''YS'', we must rewrite the ''Y'' to produce ''SS''. The same hold for other combinations, so that overall, the ordering forces the derivation to halt, or else proceed by rewriting all ''S''s to ''XX''s, then all ''X''s to ''Y''s, then all ''Y''s to ''S''s, and so on, then finally all ''S''s to ''A''s then all ''A''s to ''a''s. In this way, a string &lt;math&gt;S^n&lt;/math&gt; can only ever be rewritten as &lt;math&gt;A^n&lt;/math&gt; which produces ''a''s, or as &lt;math&gt;S^{2n}&lt;/math&gt;. Starting with ''n = 0'', it should be clear that this grammar only generates the language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;.

==Grammars with parallelism==
A still further class of controlled grammars is the class of grammars with parallelism in the application of a rewrite operation, in which each rewrite step can (or must) rewrite more than one non-terminal simultaneously. These, too, come in several flavors: Indian parallel grammars, k-grammars, scattered context grammars, unordered scattered context grammars, and k-simple matrix grammars. Again, the variants differ in how the parallelism is defined.

===Indian parallel grammars===
An Indian parallel grammar is simply a CFG in which to use a rewrite rule, all instances of the rules non-terminal symbol must be rewritten simultaneously. Thus, for example, given the string ''aXbYcXd'', with two instances of ''X'', and some rule &lt;math&gt;X \to w&lt;/math&gt;, the only way to rewrite this string with this rule is to rewrite it as ''awbYcwd''; neither ''awbYcXd'' nor ''aXbYcwd'' are valid rewrites in an Indian parallel grammar, because they did not rewrite all instances of ''X''.

Indian parallel grammars can easily produce the language &lt;math&gt;\{ ww : w \in \{a,b\}^{*}\}&lt;/math&gt;:

Let &lt;math&gt;G = (\{S, A\}, \{a,b\}, S, \{f,g,h,k\})&lt;/math&gt;, where

: &lt;math&gt;f = S \to AA&lt;/math&gt;
: &lt;math&gt;g = A \to aA&lt;/math&gt;
: &lt;math&gt;h = A \to bA&lt;/math&gt;
: &lt;math&gt;k = A \to \epsilon&lt;/math&gt;

Generating ''aabaab'' then is quite simple:

: &lt;math&gt;S \Rightarrow_{f} AA \Rightarrow_{g} aAaA \Rightarrow_{g} aaAaaA \Rightarrow_{h} aabAaabA \Rightarrow_{k} aabaab&lt;/math&gt;

The language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt; is even simpler:

Let &lt;math&gt;G = (\{S\}, \{a\}, S, P)&lt;/math&gt;, where ''P'' consists of

: &lt;math&gt;S \to SS&lt;/math&gt;
: &lt;math&gt;S \to a&lt;/math&gt;

It should be obvious, just from the first rule, and the requirement that all instances of a non-terminal are rewritten simultaneously with the same rule, that the number of ''S''s doubles on each rewrite step using the first rule, giving the derivation steps &lt;math&gt;S \Rightarrow S^2 \Rightarrow S^4 \Rightarrow S^8 \Rightarrow ...&lt;/math&gt;. Final application of the second rule replaces all the ''S''s with ''a''s, thus showing how this simple language can produce the language &lt;math&gt;\{ a^{2^n} : n \geq 0 \}&lt;/math&gt;.

===K-grammars===
A k-grammar is yet another kind of parallel grammar, very different from an Indian parallel grammar, but still with a level of parallelism. In a k-grammar, for some number ''k'', exactly ''k'' non-terminal symbols must be rewritten at every step (except the first step, where the only symbol in the string is the start symbol). If the string has less than ''k'' non-terminals, the derivation fails.

A 3-grammar can produce the language &lt;math&gt;\{ a^n b^n c^n : n \geq 0 \}&lt;/math&gt;, as can be seen below:

Let &lt;math&gt;G = (\{S,A,B,C\}, \{a,b,c\}, S, P)&lt;/math&gt;, where ''P'' consists of:

: &lt;math&gt;S \to ABC&lt;/math&gt;
: &lt;math&gt;A \to aA&lt;/math&gt;
: &lt;math&gt;A \to a&lt;/math&gt;
: &lt;math&gt;B \to bB&lt;/math&gt;
: &lt;math&gt;B \to b&lt;/math&gt;
: &lt;math&gt;C \to cC&lt;/math&gt;
: &lt;math&gt;C \to c&lt;/math&gt;

With the following derivation for ''{{not a typo|aaabbbccc}}'':

: &lt;math&gt;S \Rightarrow ABC \Rightarrow aAbBcC \Rightarrow aaAbbBccC \Rightarrow aaabbbccc&lt;/math&gt;

At each step in the derivation except the first and last, we used the self-recursive rules &lt;math&gt;A \to aA, B \to bB, C \to cC&lt;/math&gt;. If we had not use the recursive rules, instead using, say, &lt;math&gt;A \to a, B \to bB, C \to cC&lt;/math&gt;, where one of the rules is not self-recursive, the number of non-terminals would have decreased to 2, thus making the string unable to be derived further because it would have too few non-terminals to be rewritten.

===Russian parallel grammars===
Russian parallel grammars&lt;ref name="dassow1984"&gt;Dassow, J. 1984. ''On some extensions of russian parallel context free grammars''. Acta Cybernetica 6, pp. 355-360.&lt;/ref&gt; are somewhere between Indian parallel grammars and k-grammars, defined as &lt;math&gt;G = (N,T,S,P)&lt;/math&gt;, where ''N'', ''T'', and ''S'' are as in a context-free grammar, and ''P'' is a set of pairs &lt;math&gt;(A \to w, k)&lt;/math&gt;, where &lt;math&gt;A \to w&lt;/math&gt; is a context-free production rule, and ''k'' is either 1 or 2. Application of a rule &lt;math&gt;p = (A \to w, k)&lt;/math&gt; involves rewriting ''k'' occurrences of ''A'' to ''w'' simultaneously.

===Scattered context grammars===
A scattered context grammar is a 4-tuple &lt;math&gt;G = (N, T, S, P)&lt;/math&gt; where ''N'', ''T'', and ''S'' are defined as in a context-free grammar, and ''P'' is a set of tuples called matrixes &lt;math&gt;p = (A_1 \to w_1, ..., A_n \to w_n)&lt;/math&gt;, where &lt;math&gt;n &gt; 0&lt;/math&gt; can vary according to the matrix. The derives relation for such a grammar is

: &lt;math&gt;x \Rightarrow_{p} y&lt;/math&gt; if and only if
:: &lt;math&gt;p = (A_1 \to w_1, ..., A_n \to w_n)\in P&lt;/math&gt;, and
:: &lt;math&gt;x = x_1 A_1 x_2 ... x_n A_n x_{n+1}, y = x_1 w_1 x_2 ... x_n w_n x_{n+1}&lt;/math&gt;, for &lt;math&gt;x_i \in (N \cup T)^{*}&lt;/math&gt;

Intuitively, then, the matrixes in a scattered context grammar provide a list of rules which must each be applied to non-terminals in a string, where those non-terminals appear in the same linear order as the rules that rewrite them.

An unordered scattered context grammar is a scattered context grammar in which, for every rule in ''P'', each of its permutations is also in ''P''. As such, a rule and its permutations can instead be represented as a set rather than as tuples.

====Example====
Scattered context grammars are capable of describing the language &lt;math&gt;\{ a^n b^n c^n : n \geq 0 \}&lt;/math&gt; quite easily.

Let &lt;math&gt;G = (\{S,A,B,C\}, \{a,b,c\}, S, \{r_1, r_2, r_3\})&lt;/math&gt;, where

: &lt;math&gt;r_1 = (S \to ABC)&lt;/math&gt;
: &lt;math&gt;r_2 = (A \to aA, B \to bB, C \to cC)&lt;/math&gt;
: &lt;math&gt;r_3 = (A \to \epsilon,B \to \epsilon,C \to \epsilon)&lt;/math&gt;

Deriving ''{{not a typo|aaabbbccc}}'' then is trivial:

: &lt;math&gt;S \Rightarrow_{r_1} ABC \Rightarrow_{r_2} aAbBcC \Rightarrow_{r_2} aaAbbBccC \Rightarrow_{r_2} aaaAbbbBcccC \Rightarrow_{r_3} aaabbbccc&lt;/math&gt;

==References==
{{reflist}}

{{Formal languages and grammars}}

[[Category:Formal languages]]
[[Category:Grammar frameworks]]</text>
      <sha1>a9w6e7dsj8sz5crp5vd6y0hysq1f4eg</sha1>
    </revision>
  </page>
  <page>
    <title>Diff-Text</title>
    <ns>0</ns>
    <id>37903530</id>
    <revision>
      <id>833784634</id>
      <parentid>830775809</parentid>
      <timestamp>2018-04-02T12:26:00Z</timestamp>
      <contributor>
        <ip>156.194.118.218</ip>
      </contributor>
      <comment>Fixed grammar &amp; added link to corresponding article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5368">{{Multiple issues|
{{primary sources|date=December 2012}}
{{advert|date=September 2016}}
}}

{{Infobox software
| name                   = Diff Text
| logo                   = DiffEngineX_Icon.png
| logo size              = 32px
| developer              = DiffEngineX LLC
| released               = Oct 29, 2012
| programming language   = [[C Sharp (programming language)|C-sharp]]
| operating system       = Any
| genre                  = [[Data comparison]]
| license                = [[Closed Source]]
| website                = [http://www.diff-text.com diff-text.com]
}}

[[File:Diff-Text.com Screenshot Showing Detection Of Moved And Reordered Text.png|thumbnail|Moved text is colored blue or gray. Re-ordered text has its background color changed to alternately light blue and yellow.]]

'''Diff-Text''' is a free software tool which finds the differences between two blocks of plain text.&lt;ref&gt;HVG Weekly [http://hvg.hu/Tudomany/20121102_Igy_hasonlithat_ossze_ket_szoveget_a_lege], 2 November 2012. Retrieved on 8 December 2012.&lt;/ref&gt;&lt;ref&gt;Bitbucket [https://bitbucket.org/diffenginex/diff-text/wiki/Home], 28 November 2012. Retrieved on 9 December 2012.&lt;/ref&gt; It takes
the form of a collection of web-pages, each one with a slightly different layout. Text to be compared is
pasted directly into the web-page. It can be used from any operating system.

Diff-Text was developed by DiffEngineX LLC and uses improved algorithms originally developed for the spreadsheet compare tool [[DiffEngineX]]

It allows the user to choose between comparing at the level of whole lines (or paragraphs), words or characters. If comparing whole lines only the fact that a line is not in the other block will be reported. Diff Text considers a paragraph to be any
line ending with a Windows, Macintosh or Unix line terminator.

The website can combine the original and modified text blocks into one pane with all differences highlighted. Alternatively the marked-up original and modified text blocks can be displayed in individual panes.

Navigation from one difference to the next is supported.

All of the above features are not unique and can be found in other text comparison tools.

The software can display just the differences, the differences with a variable amount of context on either side or the whole marked-up text.

The website supports the use of [[Transport Layer Security|SSL]] ("https") so confidential text can be compared.

The algorithm used by Diff Text is used by Selection Diff Tool, which is an app for Microsoft Word and Excel 2013.&lt;ref&gt;Office.Microsoft.com [https://store.office.com/selection-diff-tool-WA103863850.aspx?assetid=WA103863850], 26 November 2012. Retrieved on 8 December 2012.&lt;/ref&gt;{{better source|date=September 2016}}

==Limitations Of Using The Longest Common Subsequence Algorithm==
The unique feature of Diff-Text is its ability to spot text that has either been moved up or down in the document and placed into a new context. To avoid spurious similarities being flagged, the software allows the user to specify the minimum number of adjacent words or characters to be reported as a move. Text movements are reported such that the number of individual edits to transform the original text into the modified text are at a minimum.

The vast majority of text comparison software based on the [[longest common subsequence problem]] algorithm incorrectly report
moved text as unlinked additions and deletions. The algorithm only reports the longest in-order run of text between two documents. Text moved out of the longest run of similarities is missed.

[[Heuristics]] are not used. Any similarity between the two documents above the specified minimum will be reported (if detecting moves is selected). This is the main difference between Diff Text and most other text comparison algorithms. Diff Text will always match up significant similarities even if contained within non-identical or moved lines. It never resorts to guessing or the first match that happens to be found, which may result in non-optimal matches elsewhere.

Not only can Diff-Text spot whole paragraphs that have been moved up or down in a document, it can spot sentence re-ordering within a paragraph. To indicate this the background color of the text changes to light blue and yellow.

If the user specifies text movements should not be detected, its algorithm runs in (m log n) time, which is an improvement from the standard quadratic time often seen in software of this type. m and n refer to the sizes of the original and modified texts.

==Summary==
Conventional text comparison tools based on the [[longest common subsequence problem]] algorithm can potentially miss a lot of similarities between original and modified files, if blocks of text are moved around. Diff-Text is systematic and allows the user to specify the minimum number of contiguous words or characters to be considered a valid move.

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist|
}}

== External links ==
* [http://www.diff-text.com/ Official website]
* [http://download.cnet.com/Diff-Text/3000-2351_4-75805636.html On Download.com]

==See also==
*[[DiffEngineX]]

[[Category:Freeware]]
[[Category:File comparison tools]]
[[Category:Data differencing]]</text>
      <sha1>tbflsk45bo3u4fmg355lmpf47348hcp</sha1>
    </revision>
  </page>
  <page>
    <title>Domination number</title>
    <ns>0</ns>
    <id>7271835</id>
    <redirect title="Dominating set" />
    <revision>
      <id>313414109</id>
      <parentid>79275032</parentid>
      <timestamp>2009-09-12T18:46:38Z</timestamp>
      <contributor>
        <username>Miym</username>
        <id>8436643</id>
      </contributor>
      <minor/>
      <comment>cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58">#REDIRECT [[Dominating_set]]
[[Category:Graph invariants]]</text>
      <sha1>ntycyfsqmoxb1lfekmp22ctrttuch6z</sha1>
    </revision>
  </page>
  <page>
    <title>Doubly linked face list</title>
    <ns>0</ns>
    <id>12745973</id>
    <revision>
      <id>721788646</id>
      <parentid>693242878</parentid>
      <timestamp>2016-05-24T01:53:00Z</timestamp>
      <contributor>
        <username>Ushkin N</username>
        <id>28390915</id>
      </contributor>
      <comment>probably about Category:Linked lists</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1229">In [[applied mathematics]], a '''doubly linked face list''' ('''DLFL''') is an efficient [[data structure]] for storing [[Topological manifold|2-manifold]] mesh data.  The structure stores [[linked list]]s for a 3D mesh's faces, edges, vertices, and corners. The structure guarantees the preservation of the [[manifold]] property.&lt;ref&gt;{{citation
 | last = Chen | first = Jianer
 | doi = 10.1016/S0304-3975(96)00273-3
 | issue = 2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 1465274
 | pages = 247–266
 | title = Algorithmic graph embeddings
 | volume = 181
 | year = 1997}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = dos Santos | first1 = Thiago R.
 | last2 = Meinzer | first2 = Hans-Peter
 | last3 = Maier-Hein | first3 = Lena
 | doi = 10.1142/S0218195911003767
 | issue = 4
 | journal = International Journal of Computational Geometry &amp; Applications
 | mr = 2826033
 | pages = 467–494
 | title = Extending the doubly linked face list for the representation of 2-pseudomanifolds and 2-manifolds with boundaries
 | volume = 21
 | year = 2011}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:3D imaging]]
[[Category:Applied mathematics]]
[[Category:Linked lists]]


{{Applied-math-stub}}</text>
      <sha1>7oxf6yjkgj6id0h86bzvehuzkegcus0</sha1>
    </revision>
  </page>
  <page>
    <title>Euler's theorem in geometry</title>
    <ns>0</ns>
    <id>3338987</id>
    <revision>
      <id>835180084</id>
      <parentid>831338572</parentid>
      <timestamp>2018-04-07T01:40:51Z</timestamp>
      <contributor>
        <username>Bamyers99</username>
        <id>12311825</id>
      </contributor>
      <comment>Undid revision 829515246 by [[Special:Contributions/Phalkunlim|Phalkunlim]] ([[User talk:Phalkunlim|talk]]) blogs and Facebook are not acceptable references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6004">[[File:Euler theorem2.svg|thumb|right|upright=1.0|Euler's theorem:&lt;br/&gt;&lt;math&gt;d=|IO| =\sqrt{R (R-2r)}&lt;/math&gt;]]
In [[geometry]], '''Euler's theorem''' states that the distance ''d'' between the [[circumcentre]] and [[incentre]] of a [[triangle]] is given by&lt;ref name=Johnson&gt;{{citation|last=Johnson|first=Roger A.|title=Advanced Euclidean Geometry|publisher=Dover Publ.|year=2007|origyear=1929|page=186}}.&lt;/ref&gt;&lt;ref name="wlim"&gt;{{citation
 | last1 = Alsina | first1 = Claudi
 | last2 = Nelsen | first2 = Roger
 | isbn = 9780883853429
 | page = 56
 | publisher = Mathematical Association of America
 | series = Dolciani Mathematical Expositions
 | title = When Less is More: Visualizing Basic Inequalities
 | url = https://books.google.com/books?id=U1ovBsSRNscC&amp;pg=PA56
 | volume = 36
 | year = 2009}}.&lt;/ref&gt;&lt;ref name="lle"&gt;{{citation
 | last = Debnath | first = Lokenath
 | isbn = 9781848165250
 | page = 124
 | publisher = World Scientific
 | title = The Legacy of Leonhard Euler: A Tricentennial Tribute
 | url = https://books.google.com/books?id=K2liU-SHl6EC&amp;pg=PA124
 | year = 2010}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Dunham | first = William
 | isbn = 9780883855584
 | page = 300
 | publisher = Mathematical Association of America
 | series = Spectrum Series
 | title = The Genius of Euler: Reflections on his Life and Work
 | url = https://books.google.com/books?id=M4-zUnrSxNoC&amp;pg=PA300
 | volume = 2
 | year = 2007}}.&lt;/ref&gt;

:&lt;math&gt; d^2=R (R-2r) &lt;/math&gt;

or equivalently
:&lt;math&gt;\frac{1}{R-d} + \frac{1}{R+d} = \frac{1}{r},&lt;/math&gt;

where ''R'' and ''r'' denote the circumradius and inradius respectively (the radii of the [[circumscribed circle]] and [[inscribed circle]] respectively). The theorem is named for  [[Leonhard Euler]], who published it in 1767.&lt;ref&gt;{{citation
 | last = Euler | first = Leonhard | author-link = Leonhard Euler
 | journal = Novi Commentarii academiae scientiarum Petropolitanae
 | language = Latin
 | pages = 103–123
 | title = Solutio facilis problematum quorumdam geometricorum difficillimorum
 | url = http://www.math.dartmouth.edu/~euler/docs/originals/E325.pdf
 | volume = 11
 | year = 1767}}.&lt;/ref&gt; However, the same result was published earlier by William Chapple in 1746.&lt;ref&gt;{{citation
 | last = Chapple | first = William
 | journal = Miscellanea Curiosa Mathematica
 | pages = 117–124
 | title = An essay on the properties of triangles inscribed in and circumscribed about two given circles
 | url = https://books.google.com/books?id=a95JAAAAMAAJ&amp;pg=PA118-IA1
 | volume = 4
 | year = 1746}}. The formula for the distance is near the bottom of p.123.&lt;/ref&gt;

From the theorem follows the '''Euler inequality''':&lt;ref name="wlim"/&gt;&lt;ref name="lle"/&gt;
:&lt;math&gt;R \ge 2r,&lt;/math&gt;

which holds with equality only in the [[equilateral triangle|equilateral]] case.&lt;ref name=SV/&gt;{{rp|p. 198}}

==Proof==
[[Image:GeometryEulerTheorem.png|300px|thumb|Proof of Euler's theorem in geometry]]
Letting ''O'' be the circumcentre of triangle ''ABC'', and ''I'' be its incentre, the extension of ''AI'' intersects the circumcircle at ''L''. Then ''L'' is the midpoint of arc ''BC''. Join ''LO'' and extend it so that it intersects the circumcircle at ''M''. From ''I'' construct a perpendicular to AB, and let D be its foot, so ''ID'' = ''r''. It is not difficult to prove that triangle ''ADI'' is similar to triangle ''MBL'', so ''ID'' / ''BL'' = ''AI'' / ''ML'', i.e. ''ID'' × ''ML'' = ''AI'' × ''BL''. Therefore 2''Rr'' = ''AI'' × ''BL''. Join ''BI''. Because

: ∠ ''BIL'' = ∠  ''A'' / 2 + ∠  ''ABC'' / 2,

:  ∠ ''IBL'' =  ∠ ''ABC'' / 2 +  ∠ ''CBL'' =  ∠ ''ABC'' / 2 +  ∠ ''A'' / 2,

we have  ∠ ''BIL'' =  ∠ ''IBL'', so ''BL'' = ''IL'', and ''AI'' × ''IL'' = 2''Rr''. Extend ''OI'' so that it intersects the circumcircle at ''P'' and ''Q''; then ''PI'' × ''QI'' = ''AI'' × ''IL'' = 2''Rr'', so (''R''&amp;nbsp;+&amp;nbsp;''d'')(''R''&amp;nbsp;&amp;minus;&amp;nbsp;''d'') = 2''Rr'', i.e. ''d''&lt;sup&gt;2&lt;/sup&gt; = ''R''(''R''&amp;nbsp;&amp;minus;&amp;nbsp;2''r'').

==Stronger version of the inequality==

A stronger version&lt;ref name=SV&gt;{{citation|first1=Dragutin|last1=Svrtan|first2=Darko|last2=Veljan|title=Non-Euclidean versions of some classical triangle inequalities|journal=Forum Geometricorum|volume=12|year=2012|pages=197–209|url=http://forumgeom.fau.edu/FG2012volume12/FG201217index.html}}.&lt;/ref&gt;{{rp|p. 198}} is

:&lt;math&gt;\frac{R}{r} \geq \frac{abc+a^3+b^3+c^3}{2abc} \geq \frac{a}{b}+\frac{b}{c}+\frac{c}{a}-1 \geq \frac{2}{3} \left(\frac{a}{b}+\frac{b}{c}+\frac{c}{a} \right) \geq 2,&lt;/math&gt;

where ''a, b, c'' are the sidelengths of the triangle.

==Euler's theorem for the exscribed circle==

If &lt;math&gt;r_a&lt;/math&gt; and &lt;math&gt;d_a&lt;/math&gt; denote respectively the radius of the exscribed circle opposite to the vertex &lt;math&gt;A&lt;/math&gt; and the distance between its centre and the centre of 
the circumscribed circle, then &lt;math&gt;d_a^2=R(R+2r_a)&lt;/math&gt;.

==Euler's inequality in absolute geometry==

Euler's inequality, in the form stating that, for all triangles inscribed in a given circle, the maximum of the radius of the inscribed circle is reached for the equilateral triangle and only for it, is valid in [[absolute geometry]]. &lt;ref name=PS&gt;{{citation|first1=Victor|last1=Pambuccian|first2=Celia|last2=Schacht|title=Euler's inequality in absolute geoemtry|journal=Journal of Geometry|volume=109 (Art. 8)|year=2018|pages=1--11|url=https://doi-org.ezproxy1.lib.asu.edu/10.1007/s00022-018-0414-6}}.&lt;/ref&gt;

==See also==
*[[Bicentric quadrilateral#Fuss' theorem|Fuss' theorem]] for the relation among the same three variables in bicentric quadrilaterals
*[[Poncelet's closure theorem]], showing that there is an infinity of triangles with the same ''R'', ''r'', and ''d''
*[[List of triangle inequalities]]

==References==
{{reflist}}

==External links==
{{Commons category|Euler&amp;#39;s theorem in geometry}}
*{{mathworld|id=EulerTriangleFormula.html|title=Euler Triangle Formula}}

[[Category:Triangle geometry]]
[[Category:Articles containing proofs]]
[[Category:Geometric inequalities]]</text>
      <sha1>qdjitfi6sftonppsz0tlmwz4c6hd7pg</sha1>
    </revision>
  </page>
  <page>
    <title>Function (mathematics)</title>
    <ns>0</ns>
    <id>185427</id>
    <revision>
      <id>871412498</id>
      <parentid>871350901</parentid>
      <timestamp>2018-11-30T21:54:26Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* General properties */ avoid 'we'; function equality is too important to be explained en passant - inserting an small explicit subsection about it before "Function composition"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="61453">{{Functions}}

In [[mathematics]], a '''function'''&lt;ref&gt;The words '''map''', '''mapping''', '''transformation''', '''correspondence''', and '''operator''' are often used synonymously. {{harvnb |Halmos |1970 |p=30}}.&lt;/ref&gt; was originally the idealization of how a varying quantity depends on another quantity. For example, the position of a [[planet]] is a ''function'' of time. [[History of the function concept|Historically]], the concept was elaborated with the [[infinitesimal calculus]] at the end of the 17th century, and, until the 19th century, the functions that were considered were [[differentiable function|differentiable]] (that is, they had a high degree of regularity). The concept of function was formalized at the end of the 19th century in terms of [[set theory]], and this greatly enlarged the domains of application of the concept. 

A function is a process or a relation&lt;!-- Please, do not link to [[Binary relation]], this is not the technical meaning that is intended--&gt; that associates each element {{mvar|x}} of a [[set (mathematics)|set]] {{mvar|X}},  the ''domain'' of the function, to a single element {{mvar|y}} of another set {{mvar|Y}} (possibly the same set), the ''codomain'' of the function. If the function is called {{mvar|f}}, this relation is denoted {{math|1=''y'' = ''f''{{space|hair}}(''x'')}} (read {{mvar|f}} of {{mvar|x}}), the element {{mvar|x}} is the ''[[argument of a function|argument]]'' or ''input'' of the function, and {{mvar|y}} is the ''value of the function'', the ''output'', or the ''image'' of {{mvar|x}} by {{mvar|f}}.&lt;ref name=MacLane&gt;{{cite book | last = MacLane | first = Saunders | authorlink = Saunders MacLane | last2 = Birkhoff | first2 = Garrett | author2-link = Garrett Birkhoff | title = Algebra | publisher = Macmillan | edition = First | year = 1967 | location = New York | pages = 1–13 }}&lt;/ref&gt; The symbol that is used for representing the input is the [[variable (mathematics)|variable]] of the function (one often says that {{mvar|f}} is a function of the variable {{mvar|x}}).

A function is uniquely represented by its [[graph of a function|graph]] which is the set of all [[pair (mathematics)|pairs]] {{math|(''x'', ''f''{{space|hair}}(''x''))}}. When the domain and the codomain are sets of [[number]]s, each such pair may be considered as the [[Cartesian coordinates]] of a point in the plane. In general, these points form a curve, which is also called the graph of the function. This is a useful representation of the function, which is commonly used everywhere, for example in newspapers.

Functions are widely used in [[science]], and in most fields of mathematics. Their role is so important that it has been said that they are "the central objects of investigation" in most fields of mathematics.{{sfn |Spivak |2008 |p=39}}

[[File:Function machine2.svg|thumb|right|Metaphor describing a function as a "machine" or "[[black box]]" that for each input returns a corresponding output.]]
[[Image:Graph of example function.svg|thumb|right|The red curve is the [[graph of a function]], because any [[Vertical line test|vertical line]] has exactly one crossing point with the curve.]]

[[File:Function color example 3.svg|thumb|A function that associates any of the four colored shapes to its color.]]

==Definition==
{{multiple image| width = 220
| align     = right
| direction = vertical
| image1    = Injection keine Injektion 2a.svg
| caption1  = Diagram of a function, with domain ''X''={1, 2, 3} and codomain ''Y''={A, B, C, D}, which is defined by the set of ordered pairs {(1,D), (2,C), (3,C)}. The image/range is the set {C,D}.
&lt;br /&gt;&lt;hr style="height:8pt; visibility:hidden"&gt;&lt;hr&gt;&lt;hr style="height:8pt; visibility:hidden"&gt;
|
| image2    = Injection keine Injektion 1.svg
| caption2  = This diagram, representing the set of pairs {(1,D), (2,B), (2,C)}, does ''not'' define a function. One reason is that 2 is the first element in more than one ordered pair, {{nowrap|(2, B)}} and {{nowrap|(2, C)}}, of this set.  Two other reasons, also sufficient by themselves, is that neither 3 nor 4 are first elements (input) of any ordered pair therein.
}}
Intuitively, a function is a process that associates to each element of a set {{math|''X''}} a unique element of a set {{math|''Y''}}.

Formally, a function {{math|''f''}} from a set {{math|''X''}} to a set {{math|''Y''}} is defined by a set {{mvar|G}} of ordered pairs {{math|(''x'', ''y'')}} such that {{math|''x'' ∈ ''X''}}, {{math|''y'' ∈ ''Y''}}, and every element of {{math|''X''}} is the first component of exactly one ordered pair in {{mvar|G}}.&lt;ref&gt;{{cite book |last=Hamilton |first=A. G. |title=Numbers, sets, and axioms: the apparatus of mathematics |page=83 |publisher=Cambridge University Press |isbn=0-521-24509-5 |url=https://books.google.com/books?id=OXfmTHXvRXMC&amp;pg=PA83&amp;dq=%22function+is+a+relation%22}}&lt;/ref&gt; In other words, for every {{math|''x''}} in {{math|''X''}}, there is exactly one element {{math|''y''}} such that the ordered pair {{math|(''x'', ''y'')}} belongs to the set of pairs defining the function {{math|''f''}}. The set {{mvar|G}} is called the [[graph of a function|graph of the function]]. Formally speaking, it may be identified with the function, but this hides the usual interpretation of a function as a process. Therefore, in common usage, the function is generally distinguished from its graph. Functions are also called ''[[Map (mathematics)|map]]s'' or ''mappings''. However, some authors&lt;ref&gt;{{cite book|author=T. M. Apostol|title=Mathematical Analysis|year=1981|publisher=Addison-Wesley|page=35}}&lt;/ref&gt; reserve the word ''mapping'' to the case where the codomain ''Y'' belongs explicitly to the definition of the function. In this sense, the graph of the mapping recovers the function as the set of pairs.

In the definition of function, {{math|''X''}} and {{math|''Y''}} are respectively called the ''domain'' and the ''codomain'' of the function {{mvar|f}}. If {{math|(''x'', ''y'')}} belongs to the set defining {{mvar|f}}, then {{mvar|y}} is the ''image'' of {{mvar|x}} under {{mvar|f}}, or the ''value'' of {{mvar|f}} applied to the ''argument'' {{mvar|x}}. Especially in the context of numbers, one says also that {{mvar|y}} is the value of {{mvar|f}} for the ''value {{mvar|x}} of its variable'', or, still shorter, {{mvar|y}} is the ''value of'' {{mvar|f}} ''of'' {{mvar|x}}, denoted as {{math|''y'' {{=}} ''f''(''x'')}}.

The domain and codomain are not always explicitly given when a function is defined, and, without some (possibly difficult) computation, one knows only that the domain is contained in a larger set. Typically, this occurs in [[mathematical analysis]], where "a function {{nowrap|from {{mvar|X}} to {{mvar|Y}} "}} often refers to a function that may have a proper subset of {{mvar|X}} as domain. For example, a "function from the reals to the reals" may refer to a [[real-valued function|real-valued]] function of a [[function of a real variable|real variable]], and this phrase does not mean that the domain of the function is the whole set of the [[real number]]s, but only that the domain is a set of real numbers that contains a non-empty [[open interval]]. For example, if {{mvar|f}} is a function that has the real numbers as domain and codomain, then a function mapping the value {{mvar|x}} to the value &lt;math&gt;g(x)=\tfrac 1{f(x)}&lt;/math&gt; is a function {{mvar|g}} from the reals to the reals, whose domain is the set of the reals {{mvar|x}}, such that {{math|''f''(''x'') ≠ 0}}. In many cases, the exact domains are difficult to determine, but this is rarely a problem for working with such functions.

The [[range (mathematics)|range]] of a function is the set of the images of all elements in the domain. However, ''range'' is sometimes used as a synonym of codomain, generally in old textbooks.

===Relational approach===
Any subset of the Cartesian product of a domain &lt;math&gt;X&lt;/math&gt; and a codomain &lt;math&gt;Y&lt;/math&gt; is said to define a [[binary relation]] &lt;math&gt;R\subseteq (X\times Y)&lt;/math&gt; between these two sets. It is immediate that an arbitrary relation may contain pairs that violate the necessary conditions for a function, given above. 

A [[binary relation#univalent|univalent relation]] is a relation such that
:&lt;math&gt;(x,y)\in R\; \land \;(x,z) \in R\quad\Rightarrow \quad y=z.&lt;/math&gt;
Univalent relations may be identified to functions whose domain is a subset of {{mvar|X}}.

A [[binary relation#left-total|left-total relation]] is a relation such that 
:&lt;math&gt;\forall x \in X \;\exists y \in Y\colon (x,y)\in R.&lt;/math&gt;
Formal functions may be strictly identified to relations that are both univalent and left total. Violating the left-totality is similar to giving a convenient encompassing set instead of the true domain, as explained above.

Various properties of functions and function composition may be reformulated in the language of relations. For example, a function is [[injective function|injective]] if the [[converse relation]] &lt;math&gt;R^{\text{T}}\subseteq (Y\times X)&lt;/math&gt; is univalent, where the converse relation is defined as &lt;math&gt;R^{\text{T}} = \{(y,x)\colon (x,y) \in R\}.&lt;/math&gt;&lt;ref name=RM&gt;[[Gunther Schmidt]]( 2011) ''Relational Mathematics'', Encyclopedia of Mathematics and its Applications, vol. 132, sect 5.1 Functions, pages 49 to 60, [[Cambridge University Press]] {{ISBN|978-0-521-76268-7}}  [http://www.cambridge.org/us/academic/subjects/mathematics/logic-categories-and-sets/relational-mathematics?format=HB CUP blurb for ''Relational Mathematics'']&lt;/ref&gt;

==Notation==

There are various standard ways for denoting functions. The most commonly used notation is functional notation, which defines the function using an equation that gives the names of the function and the argument explicitly.  This gives rise to a subtle point, often glossed over in elementary treatments of functions: ''functions'' are distinct from their ''values''.  Thus, a function {{math|''f''}} should be distinguished from its value {{math|''f''(''x''&lt;sub&gt;0&lt;/sub&gt;)}} at the value {{math|''x''&lt;sub&gt;0&lt;/sub&gt;}} in its domain.  To some extent, even working mathematicians will conflate the two in informal settings for convenience, and to avoid the use of pedantic language.  However, strictly speaking, it is an [[abuse of notation]] to write "let &lt;math&gt;f\colon \mathbb{R}\to\mathbb{R}&lt;/math&gt; be the function {{math|1=''f''(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt;}} ", since {{math|''f''(''x'')}} and {{math|''x''&lt;sup&gt;2&lt;/sup&gt;}} should both be understood as the ''value'' of ''f'' at ''x'', rather than the function itself.  Instead, it is correct, though pedantic, to write "let &lt;math&gt;f\colon \mathbb{R}\to\mathbb{R}&lt;/math&gt; be the function defined by the equation {{math|1=''f''(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt;,}} valid for all real values of {{math|''x''}} ".  

This distinction in language and notation becomes important in cases where functions themselves serve as inputs for other functions.  (A function taking another function as an input is termed a ''[[Functional (mathematics)|functional]]''.)  Other approaches to denoting functions, detailed below, avoid this problem but are less commonly used.

===Functional notation===
First used by [[Leonhard Euler]] in 1734,&lt;ref&gt;{{citation |page=19 |title=Calculus of a Single Variable |author=Ron Larson, Bruce H. Edwards |publisher=Cengage Learning |year=2010 |isbn=9780538735520}}&lt;/ref&gt; it is often useful to use a symbol for denoting a function. This symbol consists generally of a single letter in [[italic font]], most often the lower-case letters {{math|''f'', ''g'', ''h''}}. Some widely used functions are represented by a symbol consisting of several letters (usually two or three, generally an abbreviation of their name). By convention, the symbol for standard functions is set in [[roman type]], such as "{{math|sin}}" for the [[sine function]], in contrast to functions defined on an ''ad hoc'' basis.

The notation (read: "{{mvar|y}} equals {{mvar|f}} of {{mvar|x}}")
:&lt;math&gt;y=f(x)&lt;/math&gt; 
means that the pair {{math|(''x'', ''y'')}} belongs to the set of pairs defining the function {{mvar|f}}. If {{mvar|X}} is the domain of {{mvar|f}}, the set of pairs defining the function is thus, using [[set-builder notation]],
:&lt;math&gt;\{(x, f(x))\colon x\in X\}.&lt;/math&gt;

Often, a definition of the function is given by what ''f'' does to the explicit argument ''x.''  For example, a function ''f'' can be defined by the equation

:&lt;math&gt;f(x)=\sin(x^2+1)&lt;/math&gt;

for all real numbers ''x.''  In this example, ''f'' can be thought of as the [[Function (Mathematics)#Function composition|composite]] of several simpler functions: squaring, adding 1, and taking the sine.  However, only the sine function has a common explicit symbol (sin), while the combination of squaring and then adding 1 is described by the polynomial expression &lt;math&gt;x^2+1&lt;/math&gt;.  In order to explicitly reference functions such as squaring or adding 1 without introducing new function names (e.g., by defining function ''g'' and ''h'' by &lt;math&gt;g(x)=x^2&lt;/math&gt; and &lt;math&gt;h(x)=x+1&lt;/math&gt;), one of the methods below (arrow notation or dot notation) could be used.  

Sometimes the parentheses of functional notation are omitted when the symbol denoting the function consists of several characters and no ambiguity may arise.  For example, &lt;math&gt;\sin x&lt;/math&gt; can be written instead of &lt;math&gt;\sin(x).&lt;/math&gt;

===Arrow notation===
For explicitly expressing domain {{math|''X''}} and the codomain {{math|''Y''}} of a function {{math|''f''}}, the arrow notation is often used (read: {{nowrap|"the function {{math|''f''}} from {{mvar|X}} to {{mvar|Y}}"}} or {{nowrap|"the function {{math|''f''}} mapping elements of  {{mvar|X}} to elements of {{mvar|Y}}"}}):

:&lt;math&gt;f\colon X \to Y&lt;/math&gt;
or
:&lt;math&gt;X ~ \stackrel{f}{\to} ~ Y.&lt;/math&gt;

This is often used in relation with the arrow notation for elements (read: "{{mvar|f}} maps {{mvar|x}} to {{math|''f''{{space|hair}}(''x'')}}"), often stacked immediately below the arrow notation giving the function symbol, domain, and codomain: 
:&lt;math&gt;x\mapsto f(x).&lt;/math&gt;

For example, if a multiplication is defined on a set {{mvar|X}}, then the [[square function]] &lt;math&gt;\operatorname{sqr}&lt;/math&gt; on {{mvar|X}} is unambiguously defined by (read: "the function &lt;math&gt;\operatorname{sqr}&lt;/math&gt; from {{mvar|X}} to {{mvar|X}} that maps {{mvar|x}} to {{math|''x'' ⋅ ''x''}}")
:&lt;math&gt;\begin{align}
\operatorname{sqr}\colon X &amp;\to X\\
x &amp;\mapsto x\cdot x,\end{align}&lt;/math&gt;

the latter line being more commonly written 
:&lt;math&gt;x\mapsto x^2.&lt;/math&gt;

Often, the expression giving the function symbol, domain and codomain is omitted.  Thus, the arrow notation is useful for avoiding introducing a symbol for a function that is defined, as it is often the case, by a formula expressing the value of the function in terms of its argument.  As a common application of the arrow notation, suppose &lt;math&gt;f\colon X\times X\to Y;\;(x,t) \mapsto f(x,t)&lt;/math&gt; is a two-argument function, and we want to refer to a [[Partial application|partially applied function]] &lt;math&gt;X\to Y&lt;/math&gt; produced by fixing the second argument to the value {{math|''t''&lt;sub&gt;0&lt;/sub&gt;}} without introducing a new function name.  The map in question could be denoted &lt;math&gt;x\mapsto f(x,t_0)&lt;/math&gt; using the arrow notation for elements.  Note that the expression &lt;math&gt;x\mapsto f(x,t_0)&lt;/math&gt; (read: "the map taking {{math|''x''}} to &lt;math&gt;f(x,t_0)&lt;/math&gt;") represents this new function with just one argument, whereas the expression &lt;math&gt;f(x_0,t_0)&lt;/math&gt; refers to the value of the function {{math|''f''}} at the {{nowrap|point &lt;math&gt;(x_0,t_0)&lt;/math&gt;.}}

===Index notation===

Index notation is often used instead of functional notation. That is, instead of writing {{math|''f''{{space|hair}}(''x'')}}, one writes &lt;math&gt;f_x.&lt;/math&gt; 

This is typically the case for functions whose domain is the set of the [[natural number]]s. Such a function is called a [[sequence (mathematics)|sequence]], and, in this case the element &lt;math&gt;f_n&lt;/math&gt; is called the {{mvar|n}}th element of sequence.

The index notation is also often used for distinguishing some variables called [[parameter]]s from the "true variables". In fact, parameters are specific variables that are considered as being fixed during the study of a problem.  For example, the map &lt;math&gt;x\mapsto f(x,t)&lt;/math&gt; (see above) would be denoted &lt;math&gt;f_t&lt;/math&gt; using index notation, if we define the collection of maps &lt;math&gt;f_t&lt;/math&gt; by the formula &lt;math&gt;f_t(x)=f(x,t)&lt;/math&gt; for all &lt;math&gt;x,t\in X&lt;/math&gt;.

===Dot notation===

In the notation 
&lt;math&gt;x\mapsto f(x),&lt;/math&gt;
the symbol {{mvar|x}} does not represent any value, it is simply a [[placeholder name|placeholder]] meaning that, if {{mvar|x}} is replaced by any value on the left of the arrow, it should be replaced by the same value on the right of the arrow. Therefore, {{mvar|x}} may be replaced by any symbol, often an [[interpunct]] "{{math| ⋅ }}". This may be useful for distinguishing the function {{math|''f''{{space|hair}}(⋅)}} from its value {{math|''f''{{space|hair}}(''x'')}} at {{mvar|x}}. 

For example, &lt;math&gt; a(\cdot)^2&lt;/math&gt; may stand for the function &lt;math&gt; x\mapsto ax^2&lt;/math&gt;, and &lt;math&gt;\textstyle \int_a^{\, (\cdot)} f(u)\,du&lt;/math&gt; may stand for a function defined by an integral with variable upper bound: &lt;math&gt;\textstyle x\mapsto \int_a^x f(u)\,du&lt;/math&gt;.

=== Specialized notations ===
There are other, specialized notations for functions in sub-disciplines of mathematics.  For example, in [[linear algebra]] and [[functional analysis]], [[linear form]]s and the [[Vector (mathematics and physics)|vectors]] they act upon are denoted using a [[dual pair]] to show the underlying [[Duality (mathematics)|duality]].  This is similar to the use of [[bra–ket notation]] in quantum mechanics.  In [[Mathematical logic|logic]] and the [[theory of computation]], the function notation of [[lambda calculus]] is used to explicitly express the basic notions of function [[Abstraction (computer science)|abstraction]] and [[Function application|application]].  In [[category theory]] and [[homological algebra]], networks of functions are described in terms of how they and their compositions [[Commutative property|commute]] with each other using [[commutative diagram]]s that extend and generalize the arrow notation for functions described above.

==Specifying a function==
According to the definition of a function, a specific function is, in general, defined by associating to every element of its domain one element of its codomain. When the domain and the codomain are sets of numbers, this association may take the form of a computation taking as input any element of the domain and producing an output in the codomain. This computation may be described by a formula. (This is the starting point of [[algebra]], where many similar numerical computations can be replaced by a single formula that describes these computations by means of [[variable (mathematics)|variables]] that represent computation inputs as unspecified numbers). This type of specification of a function frequently uses previously defined auxiliary functions. 

For example, the function {{mvar|f}} from the [[real number|real]]s to the reals, defined by the formula 
&lt;math&gt;f(x)=\sqrt{1+x^2},&lt;/math&gt;
employs, as auxiliary functions, the [[square function]] (mapping all the reals to the non-negative reals), the [[square root function]] (mapping the non-negative reals to the non-negative reals), and the addition of real numbers. The whole set of real numbers may be taken as the domain of {{mvar|f}}, even though the domain of the square root function is restricted to the non-negative real numbers; the image of {{mvar|f}} consists of the reals that are not less than one.

A computation that  defines a function may often be described by an [[algorithm]], and any kind of algorithm may be used. Sometimes, the definition of a function may involve elements or properties that can be defined, but not computed. For example, if one considers the set &lt;math&gt;\mathcal P&lt;/math&gt; of the programs in a given programming language that take an integer as input. The ''terminating function'' is the function that returns 1 if a program of &lt;math&gt;\mathcal P&lt;/math&gt; runs forever when executed on a given integer input, and returns 0 otherwise. It is a basic theorem of [[computability theory]] that there does not exist an algorithm for computing this function. More generally, computability theory is the study of  [[computable function]]s, that is, the functions that can  be computed by an algorithm.

The above ways of defining functions define them "pointwise", that is, each value is defined independently of the other values. This is not necessarily the case.

When the domain of a function is the set of nonnegative integers or, more generally, when the domain is a [[well order|well ordered set]], a function may be defined by [[induction (mathematics)|induction]] or [[recursion]], meaning (roughly) that the calculation of the value of the function for some given input requires values of the function for ''lesser'' inputs. For example, the [[Fibonacci sequence]] is a function from the natural numbers into themselves that is defined by two starting values and a formula, recurring to the two immediately preceding arguments (see [[Function_(mathematics)#Index notation|above]] for the use of indices for the argument of a function): 
:&lt;math&gt;F_0=0,\quad F_1=1, \quad\text{and}\quad F_n=F_{n-1}+F_{n-2}\quad \text{for } n&gt;1.&lt;/math&gt;

In [[calculus]], the usual functions considered have extensive regularities. That is, the value of the function at a point is related to the values of the function at neighboring points. This allows defining them by [[functional equation]]s (for example, the [[gamma function]] is the unique [[meromorphic function]] such that &lt;math&gt;\Gamma(1)=1&lt;/math&gt;, and &lt;math&gt;\Gamma(z+1)=z\Gamma(z)&lt;/math&gt; for any complex {{mvar|z}} that is not a non-positive integer), by [[differential equation]]s (for example, the [[natural logarithm]] is the solution of the differential equation &lt;math&gt;\frac{d(\ln x)}{dx}=\frac 1x&lt;/math&gt; such that {{math|1=ln(1) = 0}}), by [[integral equations]] or by [[analytic continuation]].

==Representing a function==

As functions may be complicated objects, it is often useful to draw the [[graph of a function]] for getting a global view of its properties. Some functions may also represented [[histogram]]s

===Graph===
{{main|Graph of a function}}

Given a function &lt;math&gt;f\colon X\to Y,&lt;/math&gt; its ''graph'' is, formally, the set 

:&lt;math&gt;G=\{(x,y)\colon x\in X \text{ and } y=f(x)\}.&lt;/math&gt;

In the frequent case where {{mvar|X}} and {{mvar|Y}} are subsets of the [[real number]]s (or may be identified to such subsets), an element &lt;math&gt;(x,y)\in G&lt;/math&gt; may be identified with the point of coordinates {{math|''x'', ''y''}} in the [[Cartesian plane]]. Marking these points provides a drawing, generally a curve, that is also called the ''graph of the function''. For example the graph of the [[square function]]

:&lt;math&gt;x\mapsto x^2&lt;/math&gt;

is a [[parabola]] that consists of all points of coordinates &lt;math&gt;(x, x^2)&lt;/math&gt; for &lt;math&gt;x\in \R.&lt;/math&gt;

It is possible to draw effectively the graph of a function only if the function is sufficiently regular, that is, either if the function is [[differentiable function|differentiable]] (or [[piecewise]] differentiable) or if its domain may be identified with the integers or a subset of the integers.

If either the domain or the codomain of the function is a subset of &lt;math&gt;\R^n,&lt;/math&gt; the graph is a subset of a [[Cartesian space]] of higher dimension, and various technics have been developed for drawing it, including the use of colors for representing one of the dimensions.{{cn|date=April 2018}}

===Histogram===
{{main|Histogram}}

Histograms are often used for representing functions whose domain is finite, or is the [[natural number]]s or the [[integer]]s. In this case, an element {{mvar|x}} of the domain is represented by an [[interval (mathematics)|interval]] of the {{mvar|x}}-axis, and a point {{math|(''x'', ''y'')}} of the graph is represented by a [[rectangle]] with basis the interval corresponding to {{mvar|x}} and height {{mvar|y}}.

In [[statistic]], histogram are often used for representing very irregular functions. For example, for representing the function that associates his weight to each member of some population, one draws the histogram of the function that associates to each weight interval the number of people, whose weights belong to this interval. 

There are many variants of this method, see [[Histogram]] for details.

==General properties==

This section describes general properties of functions, that are independent of specific properties of the domain and the codomain.

===Canonical functions===
Some functions are uniquely defined by their domain and codomain, and are sometimes called ''canonical'': {{anchor|Empty function}}

* For every set {{mvar|X}}, there is a unique function, called the '''empty function''' from the [[empty set]] to {{mvar|X}}. This function is not interesting by itself, but useful for simplifying statements, similarly as the [[empty sum]] (equal to 0) and the [[empty product]] equal to 1.
* For every set {{mvar|X}} and every [[singleton set]] {{math|{''s''}{{void}}}}, there is a unique function, called the '''canonical surjection''', from {{mvar|X}} to {{math|{''s''}{{void}}}}, which maps to {{mvar|s}} every element of {{mvar|X}}. This is a surjection (see below), except if {{mvar|X}} is the empty set.
* Given a function &lt;math&gt;f\colon X\to Y,&lt;/math&gt; the '''canonical surjection''' of {{mvar|f}} onto its ''image'' &lt;math&gt;f(X)=\{f(x)\mid x\in X\}&lt;/math&gt; is the function from {{mvar|X}} to {{math|''f''(''X'')}} that maps {{mvar|x}} to {{math|''f''(''x'')}}
* For every [[subset]] {{mvar|X}} of a set {{mvar|Y}}, the '''[[canonical injection]]''' of {{mvar|X}} into {{mvar|Y}} is the injective (see below) function that maps every element of {{mvar|X}} to itself.
* The [[identity function]] of {{mvar|X}}, often denoted by &lt;math&gt;\operatorname{id}_X&lt;/math&gt; is the canonical injection of {{mvar|X}} into itself.

===Equality of functions===
Two functions ''f'' and ''g'' are equal if their domain and codomain sets agree and their output values agree on the whole domain. Formally, ''f''=''g'' if ''f''(''x'')=''g''(''x'') for all ''x''∈''X'', where ''f'':''X''→''Y'' and ''g'':''X''→''Y''.

===Function composition===
{{Main|Function composition}}

Given two functions &lt;math&gt;f\colon X\to Y&lt;/math&gt; and &lt;math&gt;g\colon Y\to Z&lt;/math&gt; such that the domain of {{mvar|g}} is the codomain of {{mvar|f}}, their ''composition'' is the function &lt;math&gt;g \circ f\colon X \rightarrow Z&lt;/math&gt; defined by
:&lt;math&gt;(g \circ f)(x) = g(f(x)).&lt;/math&gt;

That is, the value of &lt;math&gt;g \circ f&lt;/math&gt; is obtained by first applying {{math|''f''}} to {{math|''x''}} to obtain {{math|1=''y'' =''f''(''x'')}} and then applying {{math|''g''}} to the result {{mvar|y}} to obtain {{math|1=''g''(''y'') = ''g''(''f''(''x''))}}. In the notation the function that is applied first is always written on the right.

The composition &lt;math&gt;g\circ f&lt;/math&gt; is an [[operation (mathematics)|operation]] on functions that is defined only if the codomain of the first function is the domain of the second one. Even when both &lt;math&gt;g \circ f&lt;/math&gt; and &lt;math&gt;f \circ g&lt;/math&gt; satisfy these conditions, the composition is not necessarily [[commutative property|commutative]], that is, the functions &lt;math&gt;g \circ f&lt;/math&gt; and &lt;math&gt; f \circ g&lt;/math&gt; need not be equal, but may deliver different values for the same argument. For example, let {{math|1=''f''(''x'') = ''x''&lt;sup&gt;2&lt;/sup&gt;}} and {{math|1=''g''(''x'') = ''x'' + 1}}, then &lt;math&gt;g(f(x))=x^2+1&lt;/math&gt; and &lt;math&gt; f(g(x)) = (x+1)^2&lt;/math&gt; agree just for &lt;math&gt;x=0.&lt;/math&gt;

The function composition is [[associative property|associative]] in the sense that, if one of &lt;math&gt;(h\circ g)\circ f&lt;/math&gt; and &lt;math&gt;h\circ (g\circ f)&lt;/math&gt; is defined, then the other is also defined, and they are equal. Thus, one writes 
:&lt;math&gt;h\circ g\circ f = (h\circ g)\circ f = h\circ (g\circ f).&lt;/math&gt;

The [[identity function]]s &lt;math&gt;\operatorname{id}_X&lt;/math&gt; and &lt;math&gt;\operatorname{id}_Y&lt;/math&gt; are respectively a [[right identity]] and a [[left identity]] for functions from {{mvar|X}} to {{mvar|Y}}. That is, if {{mvar|f}} is a function with domain {{mvar|X}}, and codomain {{mvar|Y}}, one has 
&lt;math&gt;f\circ \operatorname{id}_X = \operatorname{id}_Y \circ f = f.&lt;/math&gt;

&lt;gallery widths="250" heights="300"&gt;
File:Function machine5.svg|A composite function ''g''(''f''(''x'')) can be visualized as the combination of two "machines". 
File:Example for a composition of two functions.svg|A simple example of a function composition
File:Compfun.svg|Another composition. In this example, {{math|1=(''g'' ∘ ''f'' )(c) = #}}.
&lt;/gallery&gt;

===Image and preimage===
{{Main|Image (mathematics)}}
Let &lt;math&gt;f\colon X\to Y.&lt;/math&gt; The ''image'' by {{mvar|f}} of an element {{mvar|x}} of the domain {{mvar|X}} is {{math|''f''(''x'')}}. If {{math|''A''}} is any subset of {{math|''X''}}, then the ''image'' of {{mvar|A}} by {{mvar|f}}, denoted {{math|''f''(''A'')}} is the subset of the codomain {{math|''Y''}} consisting of all images of elements of {{mvar|A}}, that is,
:&lt;math&gt;f(A)=\{f(x)\mid x\in A\}.&lt;/math&gt;

The ''image'' of {{math|''f''}} is the image of the whole domain, that is {{math|''f''(''X'')}}. It is also called the [[range (mathematics)|range]] of {{mvar|f}}, although the term may also refer to the codomain.&lt;ref name = "standard"&gt;''Quantities and Units - Part 2: Mathematical signs and symbols to be used in the natural sciences and technology'', page 15.  ISO 80000-2 (ISO/IEC 2009-12-01)&lt;/ref&gt;

On the other hand, the ''[[inverse image]]'', or ''[[preimage]]'' by {{mvar|f}} of a subset {{math|''B''}} of the codomain {{math|''Y''}} is the subset of the domain {{math|''X''}} consisting of all elements of {{math|''X''}} whose images belong to {{math|''B''}}. It is denoted by &lt;math&gt;f^{-1}(B).&lt;/math&gt;  That is 
:&lt;math&gt;f^{-1}(B) = \{x \in X \mid f(x) \in B\}.&lt;/math&gt;
For example, the preimage of {4, 9} under the [[square function]] is the set {−3,−2,2,3}. 

By definition of a function, the image of an element {{math|''x''}} of the domain is always a single element of the codomain. However, the preimage of a single element {{mvar|y}}, denoted &lt;math&gt;f^{-1}(x),&lt;/math&gt; may be [[empty set|empty]] or contain any number of elements. For example, if {{mvar|f}} is the function from the integers to themselves that map every integer to 0, then {{math|1=''f''&lt;sup&gt;−1&lt;/sup&gt;(0) = '''Z'''}}. 

If &lt;math&gt;f\colon X\to Y&lt;/math&gt; is a function, {{math|''A''}} and {{math|''B''}} are subsets of {{math|''X''}}, and {{math|''C''}} and {{math|''D''}} are subsets of {{math|''Y''}}, then one has the following properties:
* &lt;math&gt;A\subseteq B \Longrightarrow f(A)\subseteq f(B)&lt;/math&gt;
* &lt;math&gt;C\subseteq D \Longrightarrow f^{-1}(C)\subseteq f^{-1}(D)&lt;/math&gt;
* &lt;math&gt;A \subseteq f^{-1}(f(A))&lt;/math&gt;
* &lt;math&gt;C \supseteq f(f^{-1}(C))&lt;/math&gt;
* &lt;math&gt;f(f^{-1}(f(A)))=f(A)&lt;/math&gt;
* &lt;math&gt;f^{-1}(f(f^{-1}(C)))=f^{-1}(C)&lt;/math&gt;

The preimage by {{mvar|f}} of an element {{mvar|y}} of the codomain is sometimes called, in some contexts, the [[fiber (mathematics)|fiber]] of {{math|''y''}} under {{mvar|''f''}}.  

If a function {{mvar|f}} has an inverse (see below), this inverse is denoted &lt;math&gt;f^{-1}.&lt;/math&gt; In this case &lt;math&gt;f^{-1}(C)&lt;/math&gt; may denote either the image by &lt;math&gt;f^{-1}&lt;/math&gt; or the preimage by {{mvar|f}} of {{mvar|C}}. This is not a problem, as these sets are equal. The notation &lt;math&gt;f(A)&lt;/math&gt; and &lt;math&gt;f^{-1}(C)&lt;/math&gt; may be ambiguous in the case of sets that contain some subsets as elements, such as &lt;math&gt;\{x, \{x\}\}.&lt;/math&gt; In this case, some care may be needed, for example, by using square brackets &lt;math&gt;f[A], f^{-1}[C]&lt;/math&gt; for images and preimages of subsets, and ordinary parentheses for images and preimages of elements.

===Injective, surjective and bijective functions===

Let &lt;math&gt;f\colon X\to Y&lt;/math&gt; be a function.

The function {{mvar|f}} is ''[[injective function|injective]]'' (or ''one-to-one'', or is an ''injection'') if {{math|''f''(''a'') &amp;ne; ''f''(''b'')}} for any two different elements {{math|''a''}} and {{mvar|''b''}} of {{mvar|X}}. Equivalently, {{mvar|f}} is injective if, for any &lt;math&gt;y\in Y,&lt;/math&gt; the preimage &lt;math&gt;f^{-1}(y)&lt;/math&gt; contains at most one element. An empty function is always injective. If {{mvar|X}} is not the empty set, and if, as usual, the [[axiom of choice]] is assumed, then {{mvar|f}} is injective if and only if there exists a function &lt;math&gt;g\colon y\to X&lt;/math&gt; such that &lt;math&gt;g\circ f=\operatorname{id}_X,&lt;/math&gt; that is, if {{mvar|f}} has a [[left inverse function|left inverse]]. The axiom of choice is needed, because, if {{mvar|f}} is injective, one defines {{mvar|g}} by &lt;math&gt;g(y)=x&lt;/math&gt; if &lt;math&gt;y=f(x),&lt;/math&gt; and by &lt;math&gt;g(y)=x_0&lt;/math&gt;, if &lt;math&gt;y\not\in f(X),&lt;/math&gt; where  &lt;math&gt;x_0&lt;/math&gt; is an ''arbitrarily chosen'' element of {{mvar|X}}.

The function {{mvar|f}} is ''[[surjective]]'' (or ''onto'', or is a ''surjection'') if the range equals the codomain, that is, if {{math|1=''f''(''X'') = ''Y''}}. In other words, the preimage &lt;math&gt;f^{-1}(y)&lt;/math&gt; of every &lt;math&gt;y\in Y&lt;/math&gt; is nonempty. If, as usual, the axiom of choice is assumed, then {{mvar|f}} is surjective if and only if there exists a function &lt;math&gt;g\colon y\to X&lt;/math&gt; such that &lt;math&gt;f\circ g=\operatorname{id}_Y,&lt;/math&gt; that is, if {{mvar|f}} has a [[left inverse function|right inverse]]. The axiom of choice is needed, because, if {{mvar|f}} is injective, one defines {{mvar|g}} by &lt;math&gt;g(y)=x,&lt;/math&gt; where &lt;math&gt;x&lt;/math&gt; is an ''arbitrarily chosen'' element of &lt;math&gt;f^{-1}(y).&lt;/math&gt;

The function {{mvar|f}} is ''[[bijective]]'' (or is ''bijection'' or a ''one-to-one correspondence'') if it is both injective and surjective. That is {{mvar|f}} is bijective if, for any &lt;math&gt;y\in Y,&lt;/math&gt; the preimage &lt;math&gt;f^{-1}(y)&lt;/math&gt; contains exactly one element. The function {{mvar|f}} is bijective if and only if it admits an [[inverse function]], that is a function &lt;math&gt;g\colon y\to X&lt;/math&gt; such that &lt;math&gt;g\circ f=\operatorname{id}_X,&lt;/math&gt; and &lt;math&gt;f\circ g=\operatorname{id}_Y.&lt;/math&gt; (Contrarily to the case of injections and surjections, this does not require the axiom of choice.)

Every function &lt;math&gt;f\colon X\to Y&lt;/math&gt; may be [[factorization|factorized]] as the composition {{math|''i'' ∘ ''s''}} of a surjection followed by an injection, where {{mvar|s}} is the canonical surjection of {{mvar|X}} onto {{math|''f''(''X'')}}, and {{mvar|i}} is the canonical injection of {{math|''f''(''X'')}} into {{mvar|Y}}. This is the ''canonical factorization'' of {{mvar|f}}.

"One-to-one" and "onto" are terms that were more common in the older English language literature; "injective", "surjective", and "bijective" were originally coined as French words in the second quarter of the 20th century by the [[Nicolas Bourbaki|Bourbaki group]] and imported into English.  As a word of caution, "a one-to-one function" is one that is injective, while a "one-to-one correspondence" refers to a bijective function.  Also, the statement "{{math|''f''}} maps {{math|''X''}} ''onto'' {{math|''Y''}}" differs from "{{math|''f''}}  maps {{math|''X''}} ''into'' {{math|''B''}}" in that the former implies that {{math|''f''}} is surjective), while the latter makes no assertion about the nature of {{math|''f''}} the mapping.  In a complicated reasoning, the one letter difference can easily be missed. Due to the confusing nature of this older terminology, these terms have declined in popularity relative to the Bourbakian terms, which have also the advantage to be more symmetrical.

===Restriction and extension{{anchor|Restrictions and extensions}}===&lt;!-- This section is linked from [[Subgroup]], [[Restriction]], [[Quadratic form]] --&gt;
{{main|Restriction (mathematics)}}
If &lt;math&gt;f\colon X\to Y&lt;/math&gt; is a function, and {{mvar|S}} is a subset of {{mvar|X}}, then the ''restriction'' of {{mvar|f}} to {{mvar|S}}, denoted {{math|''f''&lt;sub&gt;{{!}}''S''&lt;/sub&gt;}}, is the function from {{mvar|S}} to {{mvar|Y}} that is defined by 
:&lt;math&gt;f_{|S}(x)= f(x)\quad \text{for all } x\in S.&lt;/math&gt;

This often used for define partial inverse functions: if there is a subset {{mvar|S}} of a function {{mvar|f}} such that {{math|''f''&lt;sub&gt;{{!}}''S''&lt;/sub&gt;}} is injective, then the canonical surjection of {{math|''f''&lt;sub&gt;{{!}}''S''&lt;/sub&gt;}} on its image {{math|1=''f''&lt;sub&gt;{{!}}''S''&lt;/sub&gt;(''S'') = ''f''(''S'')}} is a bijection, which has an inverse function from {{math|''f''(''S'')}} to {{mvar|S}}. This is in this way that [[inverse trigonometric functions]] are defined. The [[cosine function]], for example, is injective, when restricted to the [[interval (mathematics)|interval]] {{math|(–0, {{pi}})}}; the image of this restriction is the interval {{math|(–1, 1)}}; this defines thus an inverse function from {{math|(–1, 1)}} to {{math|(–0, {{pi}})}}, which is called [[arccosine]] and denoted {{math|arccos}}.

Function restriction may also be used for "gluing" functions together: let &lt;math&gt;\textstyle X=\bigcup_{i\in I}U_i&lt;/math&gt; be the decomposition of {{mvar|X}} as a [[set union|union]] of subsets. Suppose that a function &lt;math&gt;f_i\colon U_i\to Y&lt;/math&gt; is defined on each &lt;math&gt;U_i,&lt;/math&gt; such that, for each pair of indices, the restrictions of &lt;math&gt;f_i&lt;/math&gt; and &lt;math&gt;f_j&lt;/math&gt; to &lt;math&gt;U_i\cap U_j&lt;/math&gt; are equal. Then, this defines a unique function &lt;math&gt;f\colon X\to Y&lt;/math&gt; such that &lt;math&gt;f_{|U_i} =f_i&lt;/math&gt; for every {{mvar|i}}. This is generally in this way that functions on [[manifold]]s are defined.

An ''extension'' of a  function {{mvar|f}} is a function {{mvar|g}} such that {{mvar|f}} is a restriction of {{mvar|g}}. A typical use of this concept is the process of [[analytic continuation]], that allows extending functions whose domain is a small part of the [[complex plane]] to functions whose domain is almost the whole complex plane.

Here is another classical example of a function extension that is encountered when studying [[homography|homographies]] of the [[real line]]. An ''homography'' is a function &lt;math&gt;h(x)=\frac{ax+b}{cx+d}&lt;/math&gt; such that {{math|''ad'' – ''bc'' ≠ 0}}. Its domain is the set of all [[real number]]s different from &lt;math&gt;-d/c,&lt;/math&gt; and its image is the set of all real numbers different from &lt;math&gt;a/c.&lt;/math&gt; If one extends the real line to the [[projectively extended real line]] by adding {{math|∞}} to the real numbers, one may extend {{mvar|h}} for being a bijection of the extended real line to itself, by setting &lt;math&gt;h(\infty)=a/c&lt;/math&gt; and &lt;math&gt;h(-d/c)=\infty.&lt;/math&gt;

==Multivariate function {{anchor|MULTIVARIATE_FUNCTION}}==
[[File:Binary operations as black box.svg|thumb|A binary operation is a typical example of a bivariate, function which assigns to each pair &lt;math&gt;(x, y)&lt;/math&gt; the result &lt;math&gt;x\circ y&lt;/math&gt;.]]
A '''multivariate function''', or '''function of several variables''' is a function that depends on several arguments. Such functions are commonly encountered. For example, the position of a car on a road is a function of the time and its speed.

More formally, a function of {{mvar|n}} variables is a function whose domain is a set of [[tuple|{{mvar|n}}-tuples]].
For example, multiplication of [[integer]]s is a function of two variables, or '''bivariate function''', whose domain is the set of all pairs (2-tuples) of integers, and whose codomain is the set of integers. The same is true for every [[binary operation]]. More generally, every [[mathematical operation]] is defined as a multivariate function.

The [[Cartesian product]] &lt;math&gt;X_1\times\cdots\times X_n&lt;/math&gt; of {{mvar|n}} sets &lt;math&gt;X_1, \ldots, X_n&lt;/math&gt; is the set of all {{mvar|n}}-tuples &lt;math&gt;(x_1, \ldots, x_n)&lt;/math&gt; such that &lt;math&gt;x_i\in X_i&lt;/math&gt; for every {{mvar|i}} with &lt;math&gt;1 \leq i \leq n&lt;/math&gt;. Therefore, a function of {{mvar|n}} variables is a function
:&lt;math&gt;f\colon U\to Y,&lt;/math&gt;
where the domain {{mvar|U}} has the form
:&lt;math&gt;U\subseteq X_1\times\cdots\times X_n.&lt;/math&gt;
When using function notation, one usually omits the parentheses surrounding tuples, writing &lt;math&gt;f(x_1,x_2)&lt;/math&gt; instead of &lt;math&gt;f((x_1,x_2)).&lt;/math&gt;

In the case where all the &lt;math&gt;X_i&lt;/math&gt; are equal to the set &lt;math&gt;\R&lt;/math&gt; of [[real number]]s, one has a [[function of several real variables]]. If the &lt;math&gt;X_i&lt;/math&gt; are equal to the set &lt;math&gt;\C&lt;/math&gt; of [[complex number]]s, one has a [[function of several complex variables]].

It is common to also consider functions whose codomain is a product of sets. For example, [[Euclidean division]] maps every pair {{math|(''a'', ''b'')}} of integers with {{math|''b'' ≠ 0}} to a pair of integers called the ''quotient'' and the ''remainder'':
:&lt;math&gt;\begin{align}
  \text{Euclidean division}\colon\quad \Z\times (\Z\setminus \{0\}) &amp;\to \Z\times\Z\\
  (a,b) &amp;\mapsto (\operatorname{quotient}(a,b),\operatorname{remainder}(a,b)).
 \end{align}&lt;/math&gt;
The codomain may also be a [[vector space]]. In this case, one talks of a [[vector-valued function]]. If the domain is contained in a [[Euclidean space]], or more generally a [[manifold]], a vector-valued function is often called a [[vector field]].

==In calculus==

The idea of function, starting in the 17th century, was fundamental to the new [[infinitesimal calculus]] (see [[History of the function concept]]). At that time, only [[real-valued function|real-valued]] functions of a [[function of a real variable|real variable]] were considered, and all functions were assumed to be [[smooth function|smooth]]. But the definition was soon extended to [[#Multivariate function|functions of several variables]] and to [[function of a complex variable]].  In the second half of 19th century, the mathematically rigorous definition of a function was introduced, and functions with arbitrary domains and codomains were defined. 

Functions are now used throughout all areas of mathematics.  In introductory [[calculus]], when the word ''function'' is used without qualification, it means a real-valued function of a single real variable.  The more general definition of a function is usually introduced to second or third year college students with STEM majors, and in their senior year they are introduced to calculus in a larger, more rigorous setting in courses such as [[real analysis]] and [[complex analysis]].

===Real function===
{{see also|Real analysis}}
[[File:Gerade.svg|thumb|right|Graph of a linear function]]
[[File:Polynomialdeg2.svg|thumb|right|Graph of a polynomial function, here a quadratic function.|right]]
[[File:Sine cosine one period.svg|thumb|right|Graph of two trigonometric functions: [[sine]] and [[cosine]].]]
A ''real function'' is a [[real-valued function|real-valued]] function of a [[function of a real variable|real variable]], that is, a function whose codomain is the [[real number|field of real numbers]] and whose domain is a set of [[real number]]s that contains an [[interval (mathematics)|interval]]. In this section, these functions are simply called ''functions''.

The functions that are most commonly considered in mathematics and its applications have some regularity, that is they are [[continuous function|continuous]], [[differentiable function|differentiable]], and even [[analytic function|analytic]]. This regularity insures that these functions can be visualized by their [[#graph|graphs]]. In this section, all functions are differentiable in some interval.

Functions enjoy [[pointwise operation]]s, that is, if {{mvar|f}} and {{mvar|g}} are functions, their sum, difference and product are functions defined  by 
:&lt;math&gt;\begin{align}
(f+g)(x)&amp;=f(x)+g(x)\\
(f-g)(x)&amp;=f(x)-g(x)\\
(f\cdot g)(x)&amp;=f(x)\cdot g(x)\\
\end{align}.&lt;/math&gt;
The domains of the resulting functions are the [[set intersection|intersection]] of the domains of {{mvar|f}} and {{mvar|g}}. The quotient of two functions is defined similarly by 
:&lt;math&gt;\frac fg(x)=\frac{f(x)}{g(x)},&lt;/math&gt;
but the domain of the resulting function is obtained by removing the [[zero of a function|zeros]] of {{mvar|g}} from the intersection of the domains of {{mvar|f}} and {{mvar|g}}.

The [[polynomial function]]s are defined by [[polynomial]]s, and their domain is the whole set of real numbers. They include [[constant function]]s, [[linear function]]s and [[quadratic function]]s. [[Rational function]]s are quotients of two polynomial functions, and their domain is the real numbers with a finite number of them removed to avoid [[division by zero]].  The simplest rational function is the function &lt;math&gt;x\mapsto \frac 1x,&lt;/math&gt; whose graph is an [[hyperbola]], and whose domain is the whole [[real line]] except for 0.

The [[derivative]] of a real differentiable function is a real function. An [[antiderivative]] of a continuous real function is a real function that is differentiable in any [[open interval]] in which the original function is continuous. For example, the function &lt;math&gt;x\mapsto\frac 1x&lt;/math&gt; is continuous, and even differentiable, on the positive real numbers. Thus one antiderivative, which takes the value zero for {{math|1=''x'' = 1}}, is a differentiable function called the [[natural logarithm]].

A real function {{mvar|f}} is [[monotonic function|monotonic]] in an interval if the sign of &lt;math&gt;\frac{f(x)-f(y)}{x-y}&lt;/math&gt; does not depend of the choice of {{mvar|x}} and {{mvar|y}} in the interval. If the function is differentiable in the interval, it is monotonic if the sign of the derivative is constant in the interval. If a real function {{mvar|f}} is monotonic in an interval {{mvar|I}}, it has an [[inverse function]], which is a real function with domain {{math|''f''(''I'')}} and image {{mvar|I}}. This is how [[inverse trigonometric functions]] are defined in terms of [[trigonometric functions]], where the trigonometric functions are monotonic. Another example: the natural logarithm is monotonic on the positive real numbers, and its image is the whole real line; therefore it has an inverse function that is a [[bijection]] between the real numbers and the positive real numbers. This inverse is the [[exponential function]].

Many other real functions are defined either by the [[implicit function theorem]] (the inverse function is a particular instance) or as solutions of [[differential equation]]s. For example the [[sine]] and the [[cosine]] functions are the solutions of the [[linear differential equation]] 
:&lt;math&gt;y''+y=0&lt;/math&gt;
such that 
:&lt;math&gt;\sin 0=0, \quad \cos 0=1, \quad\frac{\partial \sin x}{\partial x}(0)=1, \quad\frac{\partial \cos x}{\partial x}(0)=0.&lt;/math&gt;

===Complex function===
{{main|complex analysis}}
{{expand section|date=April 2018}}

When working with complex numbers different types of functions are used&lt;ref&gt;{{cite book|author=L. Ahlfors|title=Complex Analysis|year=1966|publisher=McGraw-Hill|page=21|edition=second}}&lt;/ref&gt;: 

* Complex-valued functions, functions that return complex values 
::&lt;math&gt;f\colon X\to\mathbb{C}&lt;/math&gt;
:for &lt;math&gt;X&lt;/math&gt; an arbitrary set, or perhaps a subset of the real numbers. 
* Or a function for which both domain and range are subsets of the complex numbers.
::&lt;math&gt;f\colon \mathbb{C}\to\mathbb{C}&lt;/math&gt;.
* Complex variable functions that return, say real numbers or other values
::&lt;math&gt;f\colon \mathbb{C}\to X&lt;/math&gt;.
The study of complex functions is a vast subject in mathematics with many applications, and that can claim&lt;ref&gt;{{cite book|author=J. B. Conway|title=Functions of one complex variable|year=1978|publisher=Springer-Verlag|page=vii|edition=second}}&lt;/ref&gt; to be an ancestor to many other areas of mathematics, like [[homotopy theory]], and [[manifolds]].

===Function of several real or complex variables===
{{main|Function of several real variables|Function of several complex variables|Scalar field}}
{{expand section|date=April 2018}}

===Vector-valued function===
{{main|Vector-valued function|Vector field}}
{{expand section|date=April 2018}}

==Function space==
{{Main|Function space|Functional analysis}}
In [[mathematical analysis]], and more specifically in [[functional analysis]], a '''function space''' is a set of [[scalar-valued function|scalar-valued]] or [[vector-valued function]]s, which share a specific property and form a [[topological vector space]]. For example, the real [[smooth function]]s with a [[compact support]] (that is, they are zero outside some [[compact set]]) form a function space that is at the basis of the theory of [[distribution (mathematics)|distributions]].

Function spaces play a fundamental role in advanced mathematical analysis, by allowing the use of their algebraic and [[topology|topological]] properties for studying properties of functions. For example, all theorems of existence and uniqueness of solutions of [[ordinary differential equation|ordinary]] or [[partial differential equation]]s result of the study of function spaces.

==Generalizations==
===Natural extension===
It is rather frequent that a function with domain {{mvar|X}} may be naturally extended to a function whose domain is a set {{mvar|Z}} that is built from {{mvar|X}}.

For example, for any set {{mvar|X}}, its [[power set]] {{math|{{mathcal|P}}(''X'')}} is the set of all subsets of {{mvar|X}}. Any function &lt;math&gt;f\colon X\to Y,&lt;/math&gt; may be extended to a function on power sets by 
:&lt;math&gt;\begin{align}
&amp;\mathcal P(X) \to \mathcal P(Y) \\
&amp;S \mapsto f(S)
\end {align}&lt;/math&gt;
where {{math|''f''{{space|hair}}(''S'')}} is the image by {{mvar|f}} of the subset {{mvar|S}} of {{mvar|X}}.

According to the definition, a function {{mvar|f}} maps each element from its domain {{mvar|X}} to some element of its codomain {{mvar|Y}}. It is often convenient to extend this meaning to apply to arbitrary subsets of the domain, which are, as immediately can be checked, mapped to subsets of the codomain, thus considering a function &lt;math&gt;\tilde f,&lt;/math&gt; mapping its domain, the powerset  {{mathcal|P}}({{mvar|X}}) of {{mvar|f}} 's domain {{mvar|X}}, to its codomain, a subset of the powerset {{mathcal|P}}({{mvar|Y}}) of {{mvar|f}} 's codomain {{mvar|Y}}.
:&lt;math&gt;\begin{align}
\mathcal P(X) \to \mathcal P(Y) \\
S \mapsto f(S).
\end {align}&lt;/math&gt;
Under slight [[abuse of notation]] this function on subsets is often denoted also by {{mvar|f}}.

Another example is the following. If the function
&lt;math&gt;f\colon R\to S&lt;/math&gt;
is a [[ring homomorphism]], it may be extended to a function on [[polynomial ring]]s
:&lt;math&gt;\begin{align}
R[x]&amp;\to S[x]\\
\sum_{i=0}^n a_ix^i&amp;\mapsto \sum _{i=0}^n f(a_i)x^i,
\end{align}
&lt;/math&gt;
which is also a ring homomorphism.

===Multi-valued functions===
{{main|Multi-valued function}}
[[File:Function with two values 1.svg|thumb|right|Together, the two square roots of all nonnegative real numbers form a single smooth curve.]]
[[File:Xto3minus3x.svg|thumb|right]]
Several methods for specifying functions of real or complex variables start from a local definition of the funcion at a point or on a [[neighbourhood (mathematics)|neighbourhood]] of a point, and then extend by continuity the function to a much larger domain. Frequently, for a starting point &lt;math&gt;x_0,&lt;/math&gt; there are several possible starting values for the function. 

For example, in defining the [[square root]] as the inverse function of the square function, for any positive real number &lt;math&gt;x_0,&lt;/math&gt; there are two choices for the value of the square root, one of which is positive and denoted &lt;math&gt;\sqrt {x_0},&lt;/math&gt; and another which is negative and denoted &lt;math&gt;-\sqrt {x_0}.&lt;/math&gt; These choices define two continuous functions, both having the nonnegative real numbers as a domain, and having either the nonnegative or the nonpositive real numbers as images. When looking at the graphs of these functions, one can see that, together, they form a single [[smooth curve]]. It is therefore often useful to consider these two square root functions as a single function that has two values for positive {{mvar|x}}, one value for 0 and no value for negative {{mvar|x}}.

In the preceding example, one choice, the positive square root, is more natural than the other. This is not the case in general. For example, let consider the [[implicit function]] that maps {{mvar|y}} to a [[root of a function|root]] {{mvar|x}} of &lt;math&gt;x^3-3x-y =0&lt;/math&gt; (see the figure on the right). For {{math|1=''y'' = 0}} one may choose either &lt;math&gt;0, \sqrt 3,\text{ or } -\sqrt 3&lt;/math&gt; for {{mvar|x.}} By the [[implicit function theorem]], each choice defines a function; for the first one, the (maximal) domain is the interval {{math|[–2, 2]}} and the image is {{math|[–1, 1]}}; for the second one, the domain is {{math|[–2, ∞)}} and the image is {{math|[1, ∞)}}; for the last one, the domain is {{math|(–∞, 2]}} and the image is {{math|(–∞, –1]}}. As the three graphs together form a smooth curve, and there is no reason for preferring one choice, these three functions are often considered as a single ''multi-valued function'' of {{mvar|y}} that has three values for {{math|–2 &lt; ''y'' &lt; 2}}, and only one value for {{math|''y'' ≤ –2}} and {{math|''y'' ≥ –2}}.

Usefulness of the concept of multi-valued functions is clearer when considering complex functions, typically [[analytic function]]s. The domain to which a complex function may be extended by [[analytic continuation]] generally consists of almost the whole [[complex plane]]. However, when extending the domain through two different paths, one often gets different values. For example, when extending the domain of the square root function, along a path of complex numbers with positive imaginary parts, one gets {{mvar|i}} for the square root of –1; while, when extending through complex numbers with negative imaginary parts, one gets {{math|–''i''}}. There are generally two ways of solving the problem. One may define a function that is not [[continuous function|continuous]] along some curve, called a [[branch cut]]. Such a function is called the [[principal value]] of the function. The other way is to consider that one has a ''multi-valued function'', which is analytic everywhere except for isolated singularities, but whose value may "jump" if one follows a closed loop around a singularity. This jump is called the [[monodromy]].

==In [[foundations of mathematics]] and [[set theory]]==

The definition of a function that is given in this article requires the concept of [[set (mathematics)|set]], since the domain and the codomain of a function must be a set. This is not a problem in usual mathematics, as it is generally not difficult to consider only functions whose domain and codomain are sets, which are well defined, even if the domain is not explicitly defined. However, it is sometimes useful to consider more general functions. 

For example the [[singleton set]] may be considered as a function &lt;math&gt;x\mapsto \{x\}.&lt;/math&gt; Its domain would include all sets, and therefore would not be a set. In usual mathematics, one avoids this kind of problem by specifying a domain, which means that one has many singleton functions. However, when establishing foundations of mathematics, one may have to use functions whose domain, codomain or both are not specified, and some authors, often logicians, give precise definition for these weakly specified functions.&lt;ref&gt;{{harvnb |Gödel |1940 |p=16}}; {{harvnb |Jech |2003 |p=11}}; {{harvnb |Cunningham |2016 |p=57}}&lt;/ref&gt;

These generalized functions may be critical in the development of a formalization of foundations of mathematics. For example, the [[Von Neumann–Bernays–Gödel set theory]], is an extension of the set theory in which the collection of all sets is a [[Class (set theory)|class]]. This theory includes the [[Von Neumann–Bernays–Gödel set theory#NBG's axiom of replacement|replacement axiom]], which may be interpreted as "if {{mvar|X}} is a set, and {{mvar|F}} is a function, then {{math|''F''[''X'']}} is a set".

==In computer science==
{{main|Function (programming)|Lambda calculus}}
{{expand section|date=April 2018}}
==See also==
===Subpages===
{{div col|colwidth=22em}}
*[[List of types of functions]]
*[[List of functions]]
*[[Function fitting]]
*[[Implicit function]]
{{div col end}}

===Generalizations===
{{div col|colwidth=22em}}
*[[Homomorphism]]
*[[Morphism]]
*[[Distribution (mathematics)|Distribution]]
*[[Functor]]
{{div col end}}

===Related topics===
{{div col|colwidth=22em}}
*[[Associative array]]
*[[Functional (mathematics)|Functional]]
*[[Functional decomposition]]
*[[Functional predicate]]
*[[Functional programming]]
*[[Parametric equation]]
{{div col end}}

==Notes==
{{Reflist|colwidth=30em}}

==References==
* {{cite book |ref=harv |last=Bartle |first=Robert |authorlink=Robert G. Bartle |title=The Elements of Real Analysis |year=1967|publisher=John Wiley &amp; Sons}}
* {{cite book |ref=harv |last=Bloch |first=Ethan D. |title=Proofs and Fundamentals: A First Course in Abstract Mathematics |publisher=Springer |year=2011|isbn=978-1-4419-7126-5 |url=https://books.google.com/books?id=QJ_537n8zKYC}}
* {{cite book |ref=harv |last=Cunningham |first=Daniel W. |title=Set theory: A First Course |publisher=Cambridge University Press |year=2016 |isbn=978-1107120327}}
* {{cite book |ref=harv |last=Gödel |first=Kurt | authorlink=Kurt Gödel|title=The Consistency of the Continuum Hypothesis |publisher=Princeton University Press |year=1940 |isbn=978-0691079271}}
* {{cite book |ref=harv |last=Halmos |first=Paul R. |authorlink=Paul Halmos |year=1970 |title=Naive Set Theory |publisher=Springer-Verlag |isbn=0-387-90092-6 |url=https://books.google.com/books?id=x6cZBQ9qtgoC}}
* {{cite book |ref=harv |last=Jech | first=Thomas| authorlink=Thomas Jech| title=Set theory| edition=Third Millennium| publisher=[[Springer-Verlag]]| year=2003| isbn=3-540-44085-2}}
* {{cite book |ref=harv |title=Calculus |first=Michael |last=Spivak |authorlink=Michael Spivak |edition=4th |year=2008 |publisher=Publish or Perish |isbn=978-0-914098-91-1 |url=https://books.google.com/books?id=7JKVu_9InRUC}}

==Further reading==
* {{Cite book |last=Anton |first=Howard |title=Calculus with Analytical Geometry |year=1980 |publisher=[[John Wiley &amp; Sons|Wiley]] |isbn=978-0-471-03248-9}}
* {{Cite book |last=Bartle |first=Robert G. |title=The Elements of Real Analysis |edition=2nd |year=1976 |publisher=Wiley |isbn=978-0-471-05464-1}}
* {{Cite book |title=The Concept of Function: Aspects of Epistemology and Pedagogy|publisher=Mathematical Association of America |year=1992 |first1=Ed |last1=Dubinsky |first2=Guershon |last2=Harel |isbn=0-88385-081-8}}
* {{Cite book |last=Hammack |first=Richard |title=Book of Proof |year=2009 |publisher=[[Virginia Commonwealth University]] |url=http://www.people.vcu.edu/~rhammack/BookOfProof/ |chapter=12. Functions |chapter-url=http://www.people.vcu.edu/~rhammack/BookOfProof/Functions.pdf |accessdate=2012-08-01}}
* {{Cite book |last=Husch |first=Lawrence S. |title=Visual Calculus |year=2001 |publisher=[[University of Tennessee]] |url=http://archives.math.utk.edu/visual.calculus/ |accessdate=2007-09-27}}
* {{Cite book |last=Katz |first=Robert |title=Axiomatic Analysis |year=1964 |publisher=[[D. C. Heath and Company]]}}
* {{Cite book |title=Evolution of the Function Concept: A Brief Survey |first=Israel |last=Kleiner |journal=The College Mathematics Journal |volume=20 |issue=4 |year=1989 |pages=282–300 |doi=10.2307/2686848|jstor=2686848 |publisher=Mathematical Association of America}}
* {{Cite book |title=The Cambridge History of Science: The modern physical and mathematical sciences |chapter=Between rigor and applications: Developments in the concept of function in mathematical analysis |first=Jesper |last=Lützen |url=https://books.google.com/books?id=B3WvWhJTTX8C&amp;pg=PA468 |editor-first=Roy|editor-last=Porter |publisher=Cambridge University Press |year=2003 |isbn=0521571995}} An approachable and diverting historical presentation.
* {{Cite book |title=Historical and pedagogical aspects of the definition of function |last=Malik |first=M. A. |journal=International Journal of Mathematical Education in Science and Technology |volume=11 |issue=4 |year=1980 |pages=489–492 |doi=10.1080/0020739800110404}}
* Reichenbach, Hans (1947) ''Elements of Symbolic Logic'', Dover Publishing Inc., New York NY, {{isbn|0-486-24004-5}}.
* {{Cite book |last=Ruthing |first=D. |title=Some definitions of the concept of function from Bernoulli, Joh. to Bourbaki, N. |journal=Mathematical Intelligencer |volume=6 |issue=4 |pages=72–77 |year=1984}}
* {{Cite book |last1=Thomas |first1=George B. |last2=Finney |first2=Ross L. |title=Calculus and Analytic Geometry |edition=9th |year=1995 |publisher=[[Addison-Wesley]] |isbn=978-0-201-53174-9}}

==External links==
{{Commonscat|Functions (mathematics)}}
* {{springer|title=Function|id=p/f041940}}
* {{MathWorld| title=Function| id=Function}}
* [http://functions.wolfram.com/ The Wolfram Functions Site] gives formulae and visualizations of many mathematical functions.
* [https://dlmf.nist.gov/ NIST Digital Library of Mathematical Functions]
{{Mathematical logic}}

{{Authority control}}

{{DEFAULTSORT:Function (Mathematics)}}
[[Category:Functions and mappings| ]]
[[Category:Basic concepts in set theory]]
[[Category:Elementary mathematics]]</text>
      <sha1>8mc2mgnpbnzutsv9k66e1hkisoe365i</sha1>
    </revision>
  </page>
  <page>
    <title>Gary Chartrand</title>
    <ns>0</ns>
    <id>22782409</id>
    <revision>
      <id>843601277</id>
      <parentid>839663508</parentid>
      <timestamp>2018-05-30T06:17:32Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4105">{{Infobox scientist
| name        = Gary Chartrand
| image       = Gary Chartrand 2.png
| birth_date  = {{birth date |1936|08|24}}
| thesis_title = Graphs and Their Associated Line-Graphs
| alma_mater  = Michigan State University
| nationality = American
| doctoral_advisor = Edward Nordhaus
| doctoral_students = [[Ortrud Oellermann]]
}}
'''Gary Theodore Chartrand''' (born 1936)  is an American-born [[mathematician]] who specializes in [[graph theory]]. He is known for his [[textbook]]s on introductory graph theory and for the concept of a
[[highly irregular graph]].

==Biography==
Gary Chartrand was born in 1936. He was raised in [[Sault Ste. Marie, Michigan]] and attended [[J. W. Sexton High School]] located in [[Lansing, Michigan]]. As an undergraduate student, he initially majored in [[chemical engineering]], but switched to mathematics in his junior year, in which he also became a member of the honorary mathematics society [[Pi Mu Epsilon]].

He earned his B. S. from [[Michigan State University]], where he majored in mathematics and minored in physical sciences and foreign languages. Michigan State University also awarded him a Master of Science and a PhD for his work in graph theory in 1964. Chartrand became the first doctoral student of Edward Nordhaus, and the first doctoral student at Michigan State University to research graph theory. His dissertation was ''Graphs and Their Associated Line-Graphs''. Chartrand worked with [[Frank Harary]] at the [[University of Michigan]], where he spent a year as a Research Associate, and the two have published numerous papers together (along with other authors).

The topic of [[highly irregular graph]]s was introduced by Chartrand, [[Paul Erdős]] and [[Ortrud Oellermann]].&lt;ref&gt;Chartrand, Gary, Paul Erdos, and Ortrud R. Oellermann (1988) [http://www.math.ucsd.edu/~ronspubs/87_03_highly_irregular.pdf How to define an irregular graph] [[The College Mathematics Journal]] 19(1): 36–42.&lt;/ref&gt;

Other contributions that Chartrand has made involve [[dominating set]]s, [[distance (graph theory)|distance]] in graphs, and [[graph coloring]]. During his career at Western Michigan University, he advised 22 doctoral students in their research on aspects of graph theory. Chartrand is currently a professor emeritus of [[mathematics]] at [[Western Michigan University]].&lt;ref&gt;{{citation|url=http://www.wmich.edu/math/emeriti%20faculty.html|title=Emeriti Faculty|publisher=Western Michigan Mathematics Dept.|archive-url=https://web.archive.org/web/20110105121343/http://www.wmich.edu/math/emeriti%20faculty.html|archive-date=2011-01-05}}&lt;/ref&gt;

==Books==
* 1977: ''Graphs as Mathematical Models'', Prindle, Weber &amp; Schmidt, {{mr|id=0490611}} reprinted 1985 as ''Introductory Graph Theory'' {{mr|id=783826}}.
* 1993: (with [[Ortrud Oellermann|Ortrud R. Oellermann]]) ''Applied and Algorithmic Graph Theory'', [[McGraw Hill]] {{mr|id=1211413}}.
* 2008: (with [[Ping Zhang (graph theorist)|Ping Zhang]]) ''Chromatic Graph Theory'', [[CRC Press]] {{mr|id=2450569}}.
* 2010: (with Linda Lesniak and Ping Zhang) ''Graphs &amp; Digraphs'', 5th edition, CRC Press {{mr|id=2766107}}.
* 2010: (with Ping Zhang) ''Discrete Mathematics'', Waveland Press.
* 2012: (with Albert D. Polimeni &amp; Ping Zhang) ''Mathematical Proofs: A Transition to Advanced Mathematics'', 3rd edition, Pearson.
* 2012: (with Ping Zhang) ''A First Course in Graph Theory'', [[Dover Publications]].
* 2015: (with [[Arthur T. Benjamin]] and Ping Zhang) ''The Fascinating World of Graph Theory'', [[Princeton University Press]] {{mr|id=3307972}}.

==References==
{{Reflist}}

==External links==
* [http://homepages.wmich.edu/~zhang/gary.html Chartrand's web page] at Western Michigan University
* {{mathgenealogy|id=233|name=Gary Theodore Chartrand}}

{{Authority control}}

{{DEFAULTSORT:Chartrand, Gary}}
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Graph theorists]]
[[Category:Michigan State University alumni]]
[[Category:Western Michigan University faculty]]
[[Category:1936 births]]</text>
      <sha1>5ceyjjw922sos3zkwoiqkxquzl0hdnm</sha1>
    </revision>
  </page>
  <page>
    <title>Gerard of Brussels</title>
    <ns>0</ns>
    <id>21630555</id>
    <revision>
      <id>868589245</id>
      <parentid>809705896</parentid>
      <timestamp>2018-11-13T04:33:29Z</timestamp>
      <contributor>
        <username>TiltuM</username>
        <id>25848390</id>
      </contributor>
      <comment>+[[Category:13th-century mathematicians]]; +[[Category:13th-century Latin writers]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2053">'''Gerard of Brussels''' ({{lang-fr|Gérard de Bruxelles}}, {{lang-la|Gerardus Bruxellensis}}) was an early thirteenth-century [[geometer]] and [[Medieval philosopher|philosopher]] known primarily for his Latin book ''Liber de motu'' (''On Motion''), which was a pioneering study in [[kinematics]], probably written between 1187 and 1260. It has been described as "the first Latin treatise that was to take the fundamental approach to kinematics that was to characterize modern kinematics."&lt;ref&gt;[[Marshall Clagett]], "The Reduction of Curvilnear Velocities to Uniform Rectilinear Velocities," ''A Source Book in Medieval Science'', ed. Edward Grant (Harvard University Press, 1974), 234.&lt;/ref&gt; He brought the works of [[Euclid]] and [[Archimedes]] back into popularity and was a direct influence on the [[Oxford Calculators]] (four kinematicists of [[Merton College]]) in the next century. Gerard is cited by [[Thomas Bradwardine]] in his ''Tractatus de proportionibus velocitatum'' (1328). His chief contribution was in moving away from [[Greek mathematics]] and closer to the notion of "a ratio of two unlike quantities such as distance and time", which is how modern physics defines [[velocity]].&lt;ref&gt;[[Joseph Mazur]] (2007), ''Zeno's Paradox: Unraveling the Ancient Mystery of the Science of Space and Time'' (London: Plame), 50&amp;ndash;51.&lt;/ref&gt; 

==Modern editions==
*[[Marshall Clagett|Clagett, Marshall]]. "The ''Liber de motu'' of Gerard of Brussels and the Origins of Kinematics in the West," ''Osiris'', 12(1956):73&amp;ndash;175.

==References==
{{reflist}}

==External links==
*[http://www.dmg-lib.org/dmglib/main/portal.jsp?mainNaviState=browsen.docum.viewer&amp;phyPageNo=1&amp;id=29389009 Kinematics in the 13th and 14th Centuries] by Teun Koetsier. Abstract: The paper deals with kinematical work by Gerard of Brussels, the [[Oxford Calculators|Merton College group]], Casali and Oresme. 

{{Authority control}}
[[Category:Medieval philosophers]]
[[Category:Geometers]]
[[Category:13th-century mathematicians]]
[[Category:13th-century Latin writers]]</text>
      <sha1>nq77q1wh7q6gvxnv4s8amvo39hkmnh7</sha1>
    </revision>
  </page>
  <page>
    <title>Gowers norm</title>
    <ns>0</ns>
    <id>38041703</id>
    <revision>
      <id>842503400</id>
      <parentid>841538250</parentid>
      <timestamp>2018-05-22T21:45:21Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6671">{{redirect|Uniformity norm|the function field norm|uniform norm|uniformity in topology|uniform space}}
In mathematics, in the field of [[additive combinatorics]], a '''Gowers norm''' or '''uniformity norm''' is a class of [[Norm (mathematics)|norm]] on functions on a finite [[Group (mathematics)|group]] or group-like object which are used in the study of arithmetic progressions in the group.  It is named after [[Timothy Gowers]], who introduced it in his work on [[Szemerédi's theorem]].&lt;ref&gt;{{cite journal|authorlink=Timothy Gowers|first=Timothy|last=Gowers|title=A new proof of Szemerédi's theorem|journal=[[Geom. Funct. Anal.]]|volume=11|issue=3|pages=465–588|url=http://www.dpmms.cam.ac.uk/~wtg10/sz898.dvi|year=2001|mr=1844079|doi=10.1007/s00039-001-0332-9}}&lt;/ref&gt;

== Definition ==

Let ''f'' be a complex-valued function on a finite Abelian group ''G'' and let ''J'' denote complex conjugation.  The Gowers ''d''-norm is

:&lt;math&gt; \Vert f \Vert_{U^d(G)}^{2^d} = \mathbf{E}_{x,h_1,\ldots,h_d \in G} \prod_{\omega_1,\ldots,\omega_d \in \{0,1\}} J^{\omega_1+\cdots+\omega_d} f\left({x + h_1\omega_1 + \cdots + h_d\omega_d}\right) \ . &lt;/math&gt;

Gowers norms are also defined for complex valued functions ''f'' on a segment ''[N]={0,1,2,...,N-1}'', where ''N'' is a positive integer. In this context, the uniformity norm is given as  &lt;math&gt; \Vert f \Vert_{U^d[N]} = \Vert \tilde{f}  \Vert_{U^d(\mathbb{Z}/\tilde{N}\mathbb{Z})}/\Vert 1_{[N]} \Vert_{U^d(\mathbb{Z}/\tilde{N}\mathbb{Z})} &lt;/math&gt;, where &lt;math&gt; \tilde N &lt;/math&gt; is a large integer, &lt;math&gt; 1_{[N]} &lt;/math&gt; denotes the indicator function of ''[N]'', and &lt;math&gt; \tilde f(x) &lt;/math&gt; is equal to &lt;math&gt; f(x) &lt;/math&gt;  for  &lt;math&gt; x \in [N] &lt;/math&gt; and &lt;math&gt; 0 &lt;/math&gt; for all other &lt;math&gt; x &lt;/math&gt;. This definition does not depend on &lt;math&gt; \tilde N &lt;/math&gt;, as long as &lt;math&gt; \tilde N &gt; 2^d N &lt;/math&gt;.

== Inverse conjectures ==

An ''inverse conjecture'' for these norms is a statement asserting that if a bounded function ''f'' has a large Gowers ''d''-norm then ''f'' correlates with a polynomial phase of degree ''d-1'' or other object with polynomial behaviour (e.g. a ''(d-1)''-step [[nilsequence]]). The precise statement depends on the Gowers norm under consideration.

The Inverse Conjecture for vector spaces over a finite field &lt;math&gt; \mathbb F &lt;/math&gt; asserts that for any &lt;math&gt; \delta &gt; 0 &lt;/math&gt; there exists a constant &lt;math&gt; c &gt; 0 &lt;/math&gt; such that for any finite dimensional vector space ''V'' over &lt;math&gt; \mathbb F &lt;/math&gt; and any complex valued function &lt;math&gt; f &lt;/math&gt; on &lt;math&gt; V &lt;/math&gt;, bounded by ''1'', such that &lt;math&gt; \Vert f \Vert_{U^{d}[V]} \geq \delta &lt;/math&gt;, there exists a polynomial sequence &lt;math&gt; P \colon V \to \mathbb{R}/\mathbb{Z} &lt;/math&gt; such that 

:&lt;math&gt; \left| \frac{1}{|V|} \sum_{x \in V} f(x) e(-P(x))\right| \geq c , &lt;/math&gt;

where &lt;math&gt; e(x) := e^{2 \pi i x} &lt;/math&gt;. This conjecture was proved to be true by Bergelson, Tao, and Ziegler.&lt;ref&gt;{{cite journal | last1=Bergelson | first1=Vitaly | last2=Tao | first2=Terence | author2-link = Terence Tao | last3=Ziegler | first3=Tamar | author3-link = Tamar Ziegler | title=An inverse theorem for the uniformity seminorms associated with the action of &lt;math&gt;\mathbb{F}_p^\infty&lt;/math&gt; | mr=2594614 | journal=[[Geom. Funct. Anal.]] | year=2010 | volume=19 | issue=6 | pages=1539–1596 | doi=10.1007/s00039-010-0051-1}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1=Tao | first1=Terence | author1-link = Terence Tao | last2=Ziegler | first2=Tamar | author2-link = Tamar Ziegler | title=The inverse conjecture for the Gowers norm over finite fields via the correspondence principle | year=2010 | journal=Analysis &amp; PDE | volume=3 | issue=1 | pages=1–20 | doi=10.2140/apde.2010.3.1 | mr=2663409| arxiv=0810.5527 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal
| doi = 10.1007/s00026-011-0124-3
| title = The Inverse Conjecture for the Gowers Norm over Finite Fields in Low Characteristic
| journal = Annals of Combinatorics
| volume = 16
| pages = 121–188
| year = 2011
| last1 = Tao | first1 = Terence | author1-link = Terence Tao
| last2 = Ziegler | first2 = Tamar | author2-link = Tamar Ziegler
| mr = 2948765
| arxiv = 1101.1469}}&lt;/ref&gt;

The Inverse Conjecture for Gowers &lt;math&gt; U^{d}[N] &lt;/math&gt; norm asserts that for any &lt;math&gt; \delta &gt; 0 &lt;/math&gt;, a finite collection of ''(d-1)''-step ''[[nilmanifolds]]'' &lt;math&gt; \mathcal{M}_\delta &lt;/math&gt; and constants &lt;math&gt; c ,C &lt;/math&gt; can be found, so that the following is true. If &lt;math&gt; N &lt;/math&gt; is a positive integer and &lt;math&gt; f\colon [N]\to \mathbb{C} &lt;/math&gt; is bounded in absolute value by ''1'' and &lt;math&gt; \Vert f \Vert_{U^{d}[N]} \geq \delta &lt;/math&gt;, then there exists a nilmanifold &lt;math&gt; G/\Gamma \in \mathcal{M}_\delta &lt;/math&gt; and a [[nilsequence]] &lt;math&gt; F(g^nx) &lt;/math&gt; where &lt;math&gt; g \in G,\ x \in G/\Gamma &lt;/math&gt; and &lt;math&gt; F\colon G/\Gamma \to \mathbb{C} &lt;/math&gt; bounded by ''1'' in absolute value and with Lipschitz constant bounded by &lt;math&gt; C &lt;/math&gt; such that:

:&lt;math&gt; \left| \frac{1}{N} \sum_{n =0}^{N-1} f(n) \overline{ F(g^nx}) \right| \geq c . &lt;/math&gt;

This conjecture was proved to be true by Green, Tao, and Ziegler.&lt;ref&gt;{{cite journal | last1 = Green | first1 = Ben | author1-link = Ben Green (mathematician)
| last2 = Tao | first2 = Terence | author2-link = Terence Tao
| last3 = Ziegler | first3 = Tamar | author3-link = Tamar Ziegler
| title = An inverse theorem for the Gowers &lt;math&gt;U^{s+1}[N]&lt;/math&gt;-norm
| journal = Electron. Res. Announc. Math. Sci.
| volume = 18
| year = 2011
| pages = 69–90
| doi = 10.3934/era.2011.18.69
| mr = 2817840
| arxiv = 1006.0205}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
| doi = 10.4007/annals.2012.176.2.11
| title = An inverse theorem for the Gowers &lt;math&gt;U^{s+1}[N]&lt;/math&gt;-norm
| journal = [[Annals of Mathematics]]
| volume = 176
| issue = 2
| pages = 1231–1372
| year = 2012
| last1 = Green | first1 = Ben | author1-link = Ben Green (mathematician)
| last2 = Tao | first2 = Terence | author2-link = Terence Tao
| last3 = Ziegler | first3 = Tamar | author3-link = Tamar Ziegler
| mr = 2950773
| arxiv = 1009.3998
}}
&lt;/ref&gt; It should be stressed that the appearance of nilsequences in the above statement is necessary. The statement is no longer true if we only consider polynomial phases. 

==References==
{{reflist}}

* {{cite book | zbl=1277.11010 | last=Tao | first=Terence | authorlink=Terence Tao | title=Higher order Fourier analysis | series=[[Graduate Studies in Mathematics]] | volume=142 | location=Providence, RI | publisher=[[American Mathematical Society]] | year=2012 | isbn=978-0-8218-8986-2 | url=http://terrytao.wordpress.com/books/higher-order-fourier-analysis/ | mr=2931680 }}

[[Category:Additive combinatorics]]</text>
      <sha1>s70i14prwam1yt2sjru7ynikibqxjpp</sha1>
    </revision>
  </page>
  <page>
    <title>Ground axiom</title>
    <ns>0</ns>
    <id>25221990</id>
    <revision>
      <id>822483895</id>
      <parentid>610751983</parentid>
      <timestamp>2018-01-26T16:59:26Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1306">{{Orphan|date=August 2011}}

In set theory, the '''ground axiom''' was introduced by {{harvtxt|Hamkins|2005}} and {{harvtxt|Reitz|2007}}. It states that the universe is not a nontrivial set [[Forcing (mathematics)|forcing]] extension of an [[inner model]].

==References==
*{{citation|first= Joel David|last= [[Joel David Hamkins|Hamkins]]|title=The Ground Axiom|journal= Oberwolfach Report |volume=55 |year=2005|pages= 3160–3162}}
*{{Citation | last1=[[Joel David Hamkins|Hamkins]] | first1=Joel David | last2=Reitz | first2=Jonas | last3=Woodin | first3=W. Hugh | title=The ground axiom is consistent with V ≠ HOD | doi=10.1090/S0002-9939-08-09285-X | mr=2399062 | year=2008 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=136 | issue=8 | pages=2943–2949}}
*{{Citation | last1=Reitz | first1=Jonas | title=The ground axiom | url=http://projecteuclid.org/getRecord?id=euclid.jsl/1203350787 | mr=2371206 | year=2007 | journal=[[Journal of Symbolic Logic]] | issn=0022-4812 | volume=72 | issue=4 | pages=1299–1317 | doi=10.2178/jsl/1203350787}}
*{{cite thesis| type=Ph.D.| author=Jonas Reitz| title=The Ground Axiom| year=2008| publisher=CUNY Graduate Center| url=https://arxiv.org/pdf/math/0609064v1}}

[[Category:Axioms of set theory]]


{{mathlogic-stub}}</text>
      <sha1>64bc8kci2ghs64lhfps5nfbfba3lopf</sha1>
    </revision>
  </page>
  <page>
    <title>Hermite's cotangent identity</title>
    <ns>0</ns>
    <id>33751809</id>
    <revision>
      <id>840584198</id>
      <parentid>703651326</parentid>
      <timestamp>2018-05-10T20:14:03Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1131">{{distinguish|text=[[Hermite's identity]], a statement about fractional parts of integer multiples of real numbers}}

In [[mathematics]], '''Hermite's cotangent identity''' is a [[trigonometric identity]] discovered by [[Charles Hermite]].&lt;ref&gt;Warren P. Johnson, "Trigonometric Identities &amp;agrave; la Hermite", ''[[American Mathematical Monthly]]'', volume 117, number 4, April 2010, pages 311&amp;ndash;327&lt;/ref&gt;  Suppose ''a''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''a''&lt;sub&gt;''n''&lt;/sub&gt; are [[complex number]]s, no two of which differ by an integer multiple of&amp;nbsp;{{pi}}.  Let

: &lt;math&gt; A_{n,k} = \prod_{\begin{smallmatrix} 1 \le j \le n \\ j \neq k \end{smallmatrix}} \cot(a_k - a_j) &lt;/math&gt;

(in particular, ''A''&lt;sub&gt;1,1&lt;/sub&gt;, being an [[empty product]], is&amp;nbsp;1).  Then

: &lt;math&gt; \cot(z - a_1)\cdots\cot(z - a_n) = \cos\frac{n\pi}{2} + \sum_{k=1}^n A_{n,k} \cot(z - a_k).&lt;/math&gt;

The simplest non-trivial example is the case&amp;nbsp;''n''&amp;nbsp;=&amp;nbsp;2:

: &lt;math&gt; \cot(z - a_1)\cot(z - a_2) = -1 + \cot(a_1 - a_2)\cot(z - a_1) + \cot(a_2 - a_1)\cot(z - a_2). \, &lt;/math&gt;

== Notes and references ==

{{reflist}}

[[Category:Trigonometry]]</text>
      <sha1>sxoprb74vr8paldbyl7xogzps74c63j</sha1>
    </revision>
  </page>
  <page>
    <title>Highly powerful number</title>
    <ns>0</ns>
    <id>56652586</id>
    <revision>
      <id>832802490</id>
      <parentid>827006212</parentid>
      <timestamp>2018-03-28T02:22:09Z</timestamp>
      <contributor>
        <username>Mberteig</username>
        <id>56601</id>
      </contributor>
      <comment>Fixed typo: "Canadiam" =&gt; "Canadian"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1598">In [[elementary number theory]], a '''highly powerful number''' is a positive integer that satisfies a property introduced by the Indo-Canadian mathematician [[Mathukumalli V. Subbarao]].&lt;ref&gt;{{cite book|author=Hardy, G. E.|author2=Subbarao, M. V.|chapter=Highly powerful numbers|title=Congr. Numer. 37|year=1983|pages=277–307}}&lt;/ref&gt; The set of highly powerful numbers is a proper subset of the set of [[powerful number]]s.

Define '''prodex'''(1) = 1. Let &lt;math&gt;n&lt;/math&gt; be a positive integer, such that &lt;math&gt;
n = \prod_{i=1}^k p_i^{E(p_i)}
&lt;/math&gt;, where &lt;math&gt;p_1, \ldots , p_k&lt;/math&gt; are &lt;math&gt;k&lt;/math&gt; distinct primes in increasing order and &lt;math&gt;E(p_i)&lt;/math&gt; is a positive integer for &lt;math&gt;i = 1, \ldots ,k&lt;/math&gt;. Define &lt;math&gt;\operatorname{prodex}(n) = \prod_{i=1}^k E(p_i)&lt;/math&gt;. The positive integer &lt;math&gt;n&lt;/math&gt; is defined to be a '''highly powerful number''' if and only if, for every positive integer &lt;math&gt;m,\, 1 \le m &lt; n&lt;/math&gt; implies that &lt;math&gt;\operatorname{prodex}(m) &lt; \operatorname{prodex}(n).&lt;/math&gt;&lt;ref&gt;{{cite journal|title=Large highly powerful numbers are cubeful|author=Lacampagne, C. B.|authorlink=Carole Lacampagne|author2=Selfridge, J. L.|authorlink2=John Selfridge|journal=Proceedings of the American Mathematical Society|volume=91|issue=2|date=June 1984|pages=173–181|doi=10.2307/2044621}}&lt;/ref&gt;

The first 25 highly powerful numbers are: 1, 4, 8, 16, 32, 64, 128, 144, 216, 288, 432, 864, 1296, 1728, 2592, 3456, 5184, 7776, 10368, 15552, 20736, 31104, 41472, 62208, 86400. {{OEIS|id=A005934}}

==References==
{{reflist}}

[[Category:Integer sequences]]</text>
      <sha1>kzl333ohwjfadlwxx4byilti7okunzf</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert–Bernays provability conditions</title>
    <ns>0</ns>
    <id>29549852</id>
    <revision>
      <id>785596791</id>
      <parentid>680546770</parentid>
      <timestamp>2017-06-14T11:41:27Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1271">In [[mathematical logic]], the '''Hilbert–Bernays provability conditions''', named after [[David Hilbert]] and [[Paul Bernays]], are a set of requirements for formalized provability predicates in formal theories of arithmetic (Smith 2007:224).

These conditions are used in many proofs of [[Kurt Gödel]]'s [[Gödel's second incompleteness theorem|second incompleteness theorem]]. They are also closely related to axioms of [[provability logic]].

== The conditions ==
Let ''T'' be a formal theory of arithmetic with a formalized provability predicate Prov(''n''), which is expressed as a formula of ''T'' with one free number variable. For each formula φ in the theory, let #(φ) be the [[Gödel number]] of φ. The Hilbert–Bernays provability conditions are:

# If ''T'' proves a sentence φ then ''T'' proves Prov(#(φ)).
# For every sentence φ, ''T'' proves Prov(#(φ)) → Prov(#(Prov(#(φ))))
# ''T'' proves that Prov(#(φ → ψ)) and Prov(#(φ)) imply Prov (#(ψ))

==References ==

* Smith, Peter (2007). ''An introduction to Gödel's incompleteness theorems''. Cambridge University Press. {{ISBN|978-0-521-67453-9}}

{{DEFAULTSORT:Hilbert-Bernays provability conditions}}
[[Category:Mathematical logic]]
[[Category:Provability logic]]


{{mathlogic-stub}}</text>
      <sha1>in9u6m3r53bnfxm2ib6dq414dbyrbgh</sha1>
    </revision>
  </page>
  <page>
    <title>Horrocks bundle</title>
    <ns>0</ns>
    <id>18731310</id>
    <revision>
      <id>626902015</id>
      <parentid>554989131</parentid>
      <timestamp>2014-09-24T14:33:38Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* References */replace mr template with mr parameter in CS1 templates; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="985">{{for|the rank 2 bundle on 4-dimensional projective space|Horrocks–Mumford bundle}}
In [[algebraic geometry]], '''Horrocks bundles''' are certain indecomposable rank 3 [[vector bundle]]s (locally free sheaves) on 5-dimensional projective space, found by {{harvtxt|Horrocks|1978}}.

==References==
*{{Citation | last1=Ancona | first1=Vincenzo | last2=Ottaviani | first2=Giorgio | title=The Horrocks bundles of rank three on P&lt;sup&gt;5&lt;/sup&gt; | doi=10.1515/crll.1995.460.69 |mr=1316572 | year=1995 | journal=[[Journal für die reine und angewandte Mathematik]] | issn=0075-4102 | volume=460 | pages=69–92}}
*{{Citation | last1=Horrocks | first1=G. | author1-link=Geoffrey Horrocks | title=Examples of rank three vector bundles on five-dimensional projective space | doi=10.1112/jlms/s2-18.1.15 |mr=502651 | year=1978 | journal=Journal of the London Mathematical Society | issn=0024-6107 | volume=18 | issue=1 | pages=15–27}}

[[Category:Algebraic geometry]]
[[Category:Vector bundles]]</text>
      <sha1>mlctkwhr5lwucb2mprpqt1775zhryzc</sha1>
    </revision>
  </page>
  <page>
    <title>Indefinite product</title>
    <ns>0</ns>
    <id>22204279</id>
    <revision>
      <id>870466291</id>
      <parentid>826919166</parentid>
      <timestamp>2018-11-25T00:43:42Z</timestamp>
      <contributor>
        <username>Smithpith</username>
        <id>5032726</id>
      </contributor>
      <comment>/* See also */Added an item.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4811">In [[mathematics]], the '''indefinite product''' operator is the inverse operator of &lt;math&gt;Q(f(x)) = \frac{f(x+1)}{f(x)}&lt;/math&gt;. It is a discrete version of the geometric integral of geometric calculus, one of the [[Multiplicative calculus#History|non-Newtonian calculi]]. Some authors use term '''discrete multiplicative integration'''&lt;ref&gt;N. Aliev, N. Azizi and M. Jahanshahi (2007) [http://www.m-hikari.com/imf-password2007/9-12-2007/jahanshahiIMF9-12-2007-1.pdf "Invariant functions for discrete derivatives and their applications to solve non-homogenous linear and non-linear difference equations".]&lt;/ref&gt;

Thus

:&lt;math&gt;Q( \prod_x f(x) )= f(x) \, .&lt;/math&gt;

More explicitly, if &lt;math&gt;\prod_x f(x) = F(x) &lt;/math&gt;, then

:&lt;math&gt;\frac{F(x+1)}{F(x)} = f(x) \, .&lt;/math&gt;

If ''F''(''x'') is a solution of this functional equation for a given ''f''(''x''), then so is ''CF''(''x'') for any constant ''C''. Therefore, each indefinite product actually represents a family of functions, differing by a multiplicative constant.

==Period rule==

If &lt;math&gt;T &lt;/math&gt; is a period of function &lt;math&gt;f(x)&lt;/math&gt; then

:&lt;math&gt;\prod _x f(Tx)=C f(Tx)^{x-1} &lt;/math&gt;

==Connection to indefinite sum==

Indefinite product can be expressed in terms of [[indefinite sum]]:

:&lt;math&gt;\prod _x f(x)= \exp \left(\sum _x \ln f(x)\right) &lt;/math&gt;

==Alternative usage==

Some authors use the phrase "indefinite product" in a slightly different but related way to describe a product in which the numerical value of the upper limit is not given.&lt;ref&gt;[http://www.risc.uni-linz.ac.at/people/mkauers/publications/kauers05c.pdf Algorithms for Nonlinear Higher Order Difference Equations], Manuel Kauers&lt;/ref&gt;  e.g.

:&lt;math&gt;\prod_{k=1}^n f(k)&lt;/math&gt;.

==Rules==
:&lt;math&gt;\prod _x f(x)g(x) = \prod _x f(x)\prod _x g(x) &lt;/math&gt;

:&lt;math&gt;\prod _x f(x)^a = \left(\prod _x f(x)\right)^a &lt;/math&gt;

:&lt;math&gt;\prod _x a^{f(x)} = a^{\sum _x f(x)} &lt;/math&gt;

==List of indefinite products==

This is a list of indefinite products &lt;math&gt;\prod _x f(x) &lt;/math&gt;. Not all functions have an indefinite product which can be expressed in elementary functions.

:&lt;math&gt;\prod _x a = C a^x &lt;/math&gt;

:&lt;math&gt;\prod _x x = C\, \Gamma (x) &lt;/math&gt;

:&lt;math&gt;\prod _x \frac{x+1}{x} = C x&lt;/math&gt;

:&lt;math&gt;\prod _x \frac{x+a}{x} = \frac{C\,\Gamma (x+a)}{\Gamma (x)}&lt;/math&gt;

:&lt;math&gt;\prod _x x^a = C\, \Gamma (x)^a &lt;/math&gt;

:&lt;math&gt;\prod _x ax = C a^x \Gamma (x) &lt;/math&gt;

:&lt;math&gt;\prod _x a^x = C a^{\frac{x}{2} (x-1)} &lt;/math&gt;

:&lt;math&gt;\prod _x a^{\frac{1}{x}} = C a^{\frac{\Gamma'(x)}{\Gamma(x)}} &lt;/math&gt;

:&lt;math&gt;\prod _x x^x= C\, e^{\zeta^\prime(-1,x)-\zeta^\prime(-1)}= C\,e^{\psi^{(-2)}(z)+\frac{z^2-z}{2}-\frac z2 \ln (2\pi)}= C\, \operatorname{K}(x)  &lt;/math&gt;

:(see [[K-function]])

:&lt;math&gt;\prod _x \Gamma(x) = \frac{C\,\Gamma(x)^{x-1}}{\operatorname{K}(x)} = C\,\Gamma(x)^{x-1} e^{\frac z2 \ln (2\pi)-\frac{z^2-z}{2}-\psi^{(-2)}(z)}= C\, \operatorname{G}(x) &lt;/math&gt;

:(see [[Barnes G-function]])

:&lt;math&gt;\prod _x \operatorname{sexp}_a(x) =  \frac{C\, (\operatorname{sexp}_a (x))'}{\operatorname{sexp}_a (x)(\ln a)^x} &lt;/math&gt;

:(see [[super-exponential function]])

:&lt;math&gt;\prod _x x+a = C\,\Gamma (x+a) &lt;/math&gt;

:&lt;math&gt;\prod _x ax+b = C\, a^x \Gamma \left(x+\frac{b}{a}\right) &lt;/math&gt;

:&lt;math&gt;\prod _x ax^2+bx = C\,a^x \Gamma (x) \Gamma \left(x+\frac{b}{a}\right) &lt;/math&gt;

:&lt;math&gt;\prod _x x^2+1 = C\, \Gamma (x-i) \Gamma (x+i) &lt;/math&gt;

:&lt;math&gt;\prod _x x+\frac {1}{x} = \frac{C\, \Gamma (x-i) \Gamma (x+i)}{\Gamma (x)}&lt;/math&gt;

:&lt;math&gt;\prod _x \csc x \sin (x+1) = C \sin x &lt;/math&gt;

:&lt;math&gt;\prod _x \sec x \cos (x+1) = C \cos x &lt;/math&gt;

:&lt;math&gt;\prod _x \cot x \tan (x+1) = C \tan x &lt;/math&gt;

:&lt;math&gt;\prod _x \tan x \cot (x+1) = C \cot x &lt;/math&gt;

==See also==

*[[Indefinite sum]]
*[[Product integral]]
*[[List of derivatives and integrals in alternative calculi]]
*[[Multiplicative calculus]]
*[[Fractal derivative]]

==References==
{{reflist}}

==Further reading==
* http://reference.wolfram.com/mathematica/ref/Product.html -Indefinite products with Mathematica
* http://www.math.rwth-aachen.de/MapleAnswers/660.html{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }} - bug in Maple V to Maple 8 handling of indefinite product
* [https://web.archive.org/web/20110617053801/http://www.math.tu-berlin.de/~mueller/HowToAdd.pdf Markus Müller. How to Add a Non-Integer Number of Terms, and How to Produce Unusual Infinite Summations]
* [https://arxiv.org/abs/math/0502109 Markus Mueller, Dierk Schleicher. Fractional Sums and Euler-like Identities]

==External links==
* [https://sites.google.com/site/nonnewtoniancalculus/ Non-Newtonian calculus website]

{{DEFAULTSORT:Indefinite Product}}
[[Category:Mathematical analysis]]
[[Category:Mathematics-related lists|Indefinite sums]]
[[Category:Mathematical tables|Indefinite sums]]
[[Category:Non-Newtonian calculus]]</text>
      <sha1>5u0gxdaxony3qcxc15yqs43x5zfdvlq</sha1>
    </revision>
  </page>
  <page>
    <title>International Centre for Mathematical Sciences</title>
    <ns>0</ns>
    <id>8298904</id>
    <revision>
      <id>784254444</id>
      <parentid>752278848</parentid>
      <timestamp>2017-06-07T08:56:55Z</timestamp>
      <contributor>
        <username>FF-UK</username>
        <id>17409382</id>
      </contributor>
      <comment>Added reference to James Clerk Maxwell Foundation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1501">{{for|establishments with a similar name|Centre for Mathematical Sciences (disambiguation)}}
{{unreferenced|date=August 2012}}
The '''International Centre for Mathematical Sciences''' ('''ICMS''') is a mathematical research centre based in [[Edinburgh]]. According to its website, the Centre is "designed to bring together mathematicians and practitioners in science, industry and commerce for research workshops and other meetings." 

The Centre was jointly established in 1990 by the [[University of Edinburgh]] and [[Heriot-Watt University]], under the supervision of Professor [[Elmer Rees]], with initial support from [[Edinburgh District Council]], the [[Scottish Development Agency]] and the [[International Centre for Theoretical Physics]]. In April 1994 the Centre moved to 14 India Street, Edinburgh, the birthplace of [[James Clerk Maxwell]] and home of the [[James Clerk Maxwell Foundation]]. In 2010 it relocated to 15 South College Street to accommodate larger events. The current scientific director (appointed in 2016) is Professor Paul Glendinning.

==See also==
*[[Edinburgh Mathematical Society]]
*[[Isaac Newton Institute]], [[University of Cambridge|Cambridge]]

==External links==
*[http://www.icms.org.uk ICMS Web Site]

{{The European Mathematical Society}}
{{coord|55|57|21|N|3|12|21|W|region:GB|display=title}}

[[Category:Mathematics education in the United Kingdom]]
[[Category:Mathematical institutes]]
[[Category:Research institutes in the United Kingdom]]

{{math-stub}}</text>
      <sha1>esu7sg254k9u23zmact5b3adhmxghuu</sha1>
    </revision>
  </page>
  <page>
    <title>Ioan James</title>
    <ns>0</ns>
    <id>1034217</id>
    <revision>
      <id>846133798</id>
      <parentid>844778932</parentid>
      <timestamp>2018-06-16T15:22:48Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Link to DAB page repaired</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4398">{{Use dmy dates|date=May 2012}}
{{Use British English|date=May 2012}}
{{Infobox scientist
|name              = Ioan James
|image             = 
|birth_date        = {{birth date and age|1928|5|23|df=y}}
|birth_place       = [[London Borough of Merton|Merton]], London, England
|death_date        = 
|death_place       = 
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = 
|field             = 
|work_institutions = 
|alma_mater        = [[St Paul's School (London)|St Paul's]], [[The Queen's College, Oxford|The Queen's, Oxford]]&lt;ref&gt;‘JAMES, Prof. Ioan Mackenzie’, Who's Who 2008, A &amp; C Black, 2008; online edn, Oxford University Press, Dec 2007 [http://www.ukwhoswho.com/view/article/oupww/whoswho/U21758, accessed 27 March 2008]&lt;/ref&gt;
|doctoral_advisor  = 
|doctoral_students = 
|known_for         =
|influences        = 
|influenced        = 
|prizes            = [[Berwick Prize]] &lt;small&gt;(1959)&lt;/small&gt;&lt;br&gt;[[Senior Whitehead Prize]] &lt;small&gt;(1978)&lt;/small&gt;
|religion          = 
|signature         =
}}
'''Ioan Mackenzie James''' [[Fellow of the Royal Society|FRS]] (born 23 May 1928) is a [[United Kingdom|British]] [[mathematician]] working in the field of [[topology]] particularly in [[homotopy theory]]. 
 
James was born in [[Croydon]], [[Surrey]], [[England]],&lt;ref&gt;GRO Register of Births: SEP 1928 2a 638 CROYDON - Ioan M. James, mmn - Surridge&lt;/ref&gt; and was educated at [[St Paul's School, London]] and [[Queen's College, Oxford]]. In 1953 He earned a [[Doctor of Philosophy|D. Phil.]] from the [[University of Oxford]] for his thesis entitled ''Some problems in algebraic topology'', written under the direction of [[J. H. C. Whitehead]]. 

In 1957 he was appointed reader in pure mathematics, a post which he held until 1969. From 1959 until 1969 he was a senior research fellow at St John's College. He held the [[Savilian chair of geometry|Savilian Chair of Geometry]] at the University of Oxford from 1970 to 1995. He is now a [[professor emeritus]]. 

He was elected a [[Fellow of the Royal Society]] in 1968.&lt;ref&gt;{{cite web |url=http://royalsociety.org/about-us/fellowship/fellows/|title= Fellows |publisher= Royal Society|accessdate= 7 November 2010}}&lt;/ref&gt; In 1978 the [[London Mathematical Society]] awarded him the [[Senior Whitehead Prize]],&lt;ref&gt;{{cite web
 |url=http://www.lms.ac.uk/activities/prizes_com/pastwinners.html#swhitehead 
 |title=List of Prizewinners 
 |author=London Mathematical Society 
 |accessdate=2007-07-08 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20070804191203/http://www.lms.ac.uk/activities/prizes_com/pastwinners.html 
 |archivedate=4 August 2007 
 |df=dmy-all 
}}&lt;/ref&gt; which was established in honour of his doctoral supervisor, Whitehead. In 1984 he became President of the [[London Mathematical Society]].

==See also==

*[[James embedding]]
*[[James reduced product]]

==Books==
*{{aut|Ioan James}}, ''Topologies and Uniformities'' (Springer Undergraduate Mathematics Series), Springer, 1999.
*{{aut|Ioan James}}, ''Remarkable Mathematicians, From Euler to von Neumann'', Cambridge University Press, 2002.
*{{aut|Ioan James}}, ''Remarkable Physicists: From Galileo to Yukawa'', Cambridge University Press, 2004.
*{{aut|Ioan James}}, '' Asperger's Syndrome And High Achievement: Some Very Remarkable People'', Jessica Kingsley Pub, 2005.
*{{aut|Ioan James, Michael Fitzgerald}}, ''The Mind of the Mathematician'', JHU Press, 2007.
*{{aut|Ioan James}}, ''Driven to Innovate: A Century of Jewish Mathematicians and Physicists'', Peter Lang Oxford, 2009.
*{{aut|Ioan James}}, ''Remarkable Biologists: From Ray to Hamilton'', Cambridge University Press, 2009.
*{{aut|Ioan James}}, ''Remarkable Engineers: From Riquet to Shannon'', Cambridge University Press, 2010.

==References==
{{reflist}}

==External links==
*{{MathGenealogy |id=22474}}
*{{MacTutor Biography|id=James}}

{{Savilian Professors of Geometry}}

{{Authority control}}
{{DEFAULTSORT:James, Ioan Mackenzie}}
[[Category:1928 births]]
[[Category:Living people]]
[[Category:English mathematicians]]
[[Category:Fellows of New College, Oxford]]
[[Category:Fellows of St John's College, Oxford]]
[[Category:Fellows of the Royal Society]]
[[Category:Historians of mathematics]]
[[Category:Historians of science]]
[[Category:Savilian Professors of Geometry]]
[[Category:Place of birth missing (living people)]]

{{UK-mathematician-stub}}</text>
      <sha1>0ugzne3b60p56394y2dfonhg4dl6gmy</sha1>
    </revision>
  </page>
  <page>
    <title>Iterated forcing</title>
    <ns>0</ns>
    <id>43053125</id>
    <revision>
      <id>814471151</id>
      <parentid>705885165</parentid>
      <timestamp>2017-12-09T00:46:29Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=Ann. of Math. (2) → journal=Ann. of Math. |series= 2 using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3498">In mathematics, '''iterated forcing''' is a method for constructing models of set theory by repeating Cohen's forcing method a transfinite number of times. Iterated forcing was introduced by {{harvs|txt|last1=Solovay|last2=Tennenbaum|year=1971}} in their construction of a model of set theory with no [[Suslin tree]]. They also showed that iterated forcing can construct models where [[Martin's axiom]] holds and the continuum is any given regular cardinal.

In iterated forcing, one has a transfinite sequence ''P''&lt;sub&gt;α&lt;/sub&gt; of forcing notions indexed by some ordinals α, which give a family of Boolean-valued models ''V''&lt;sup&gt;''P''&lt;sub&gt;α&lt;/sub&gt;&lt;/sup&gt;. If α+1 is a successor ordinal then  ''P''&lt;sub&gt;α+1&lt;/sub&gt; is often constructed from ''P''&lt;sub&gt;α&lt;/sub&gt; using a forcing notion in ''V''&lt;sup&gt;''P''&lt;sub&gt;α&lt;/sub&gt;&lt;/sup&gt;, while if α is a limit ordinal then ''P''&lt;sub&gt;α&lt;/sub&gt; is often constructed as some sort of limit (such as the direct limit) of the ''P''&lt;sub&gt;β&lt;/sub&gt; for β&lt;α.

A key consideration is that, typically, it is necessary that &lt;math&gt;\omega_1&lt;/math&gt; is not collapsed.  This is often accomplished by the use of a preservation theorem such as:

+ Finite support iteration of c.c.c. forcings (see [[countable chain condition]]) are c.c.c. and thus preserve &lt;math&gt;\omega_1&lt;/math&gt;.

+ Countable support iterations of proper forcings are proper (see [[Proper forcing axiom#The Fundamental Theorem of Proper Forcing|Fundamental Theorem of Proper Forcing]]) and thus preserve &lt;math&gt;\omega_1&lt;/math&gt;.

+ Revised countable support iterations of semi-proper forcings are semi-proper and thus preserve &lt;math&gt;\omega_1&lt;/math&gt;.

Some non-semi-proper forcings, such as Namba forcing, can be iterated with appropriate cardinal collapses while preserving &lt;math&gt;\omega_1&lt;/math&gt; using methods developed by [[Saharon Shelah]]&lt;ref&gt;Shelah, S., Proper and Improper Forcing, Springer 1992&lt;/ref&gt;&lt;ref&gt;Schlindwein, Chaz, Shelah's work on non-semiproper iterations I, Archive for Mathematical Logic (47) 2008 pp. 579 -- 606&lt;/ref&gt;&lt;ref&gt;Schlindwein, Chaz, Shelah's work on non-semiproper iterations II, Journal of Symbolic Logic (66) 2001, pp. 1865 -- 1883&lt;/ref&gt;

==References==
{{Reflist}}
*{{Citation | last1=Jech | first1=Thomas | author1-link=Thomas Jech | title=Set Theory: Millennium Edition | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Springer Monographs in Mathematics | isbn=978-3-540-44085-7 | year=2003}}
*{{Citation | last1=Kunen | first1=Kenneth | author1-link=Kenneth Kunen | title=[[Set Theory: An Introduction to Independence Proofs]] | publisher=Elsevier | isbn=978-0-444-86839-8 | year=1980}}
*{{citation|mr=1623206 
|last=Shelah|first= Saharon
|title=Proper and improper forcing 
|edition=2|series= Perspectives in Mathematical Logic|publisher= Springer-Verlag|place= Berlin|year= 1998|isbn= 3-540-51700-6 |origyear=1982}}
*{{cite journal
|title=Iterated Cohen extensions and Souslin's problem
|last=Solovay
|first=R. M.
|author2=Tennenbaum, S.
 |journal=Ann. of Math. |series= 2
|volume=94
|year=1971
|pages=201–245
|doi=10.2307/1970860
|issue=2
|publisher=Annals of Mathematics
|jstor=1970860
}}

==External links==
*{{citation|url=http://www.math.cmu.edu/~eschimme/Appalachian/EisworthMooreNotes.pdf
|title=ITERATED FORCING AND THE CONTINUUM HYPOTHESIS
|series=Appalachian Set Theory Workshop lecture notes |year=2009
|first= Todd |last=Eisworth |first2= Justin Tatch|last2= Moore
|editor-first= David |editor-last=Milovich
}}

[[Category:Forcing (mathematics)]]</text>
      <sha1>7nub67tflpba8tmynrjdpj8vlx815bq</sha1>
    </revision>
  </page>
  <page>
    <title>Katydid sequence</title>
    <ns>0</ns>
    <id>36618866</id>
    <revision>
      <id>832585014</id>
      <parentid>820360006</parentid>
      <timestamp>2018-03-26T21:21:09Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>save text from invisible. replace SloanesRef: use {{Cite OEIS}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1499">The '''Katydid sequence''' is a sequence of numbers first defined in [[Clifford A. Pickover]]'s book ''Wonders of Numbers'' (2001).

==Description==

It is the smallest sequence of integers that can be reached from 1 by a sequence of the two operations ''n''&amp;nbsp;↦&amp;nbsp;2''n''&amp;nbsp;+&amp;nbsp;2 and 7''n''&amp;nbsp;+&amp;nbsp;7 (in any order).&lt;ref name=cp&gt;{{cite book|title=Wonders of Numbers: Adventures in Mathematics, Mind, and Meaning|first=Clifford A.|last=Pickover|publisher=Oxford University Press|year=2001|isbn=9780195348002|page=330|url=https://books.google.com/books?id=52N0JJBspM0C&amp;pg=PA330}}&lt;/ref&gt; For instance, applying the first operation to 1 produces the number 4, and applying the second operation to 4 produces the number 35, both of which are in the sequence.

The first 10 elements of the sequence are:&lt;ref&gt;{{Cite OEIS|A060031|name=Katydid sequence: closed under n -&gt; 2n + 2 and 7n + 7}}&lt;/ref&gt;
:1, 4, 10, 14, 22, 30, 35, 46, 62, 72.

==Repetitions==

Pickover asked whether there exist numbers that can be reached by more than one sequence of operations.&lt;ref name=cp/&gt;
The answer is yes. For instance, 1814526 can be reached by the two sequences
1 – 4 – 10 – 22 – 46 – 329 – 660 – 4627 – 9256 – 18514 – 37030 – 259217 – 1814526 and
1 – 14 – 30 – 62 – 441 – 884 – 1770 – 3542 – 7086 – 14174 – 28350 – 56702 – 113406 – 226814 – 453630 – 907262 – 1814526

==References==
{{reflist}}

[[Category:Integer sequences]]

{{Numtheory-stub}}</text>
      <sha1>kxxk4zpgd3tw0vhocv5lbqyuxcmszju</sha1>
    </revision>
  </page>
  <page>
    <title>Lill's method</title>
    <ns>0</ns>
    <id>34589275</id>
    <revision>
      <id>829007873</id>
      <parentid>816729240</parentid>
      <timestamp>2018-03-06T02:24:31Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Description of the method */√ glyph -&gt; {{radic}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5941">In [[mathematics]], '''Lill's method''' is a visual method of finding the [[real number|real]] [[zero of a function|roots]] of [[polynomial]]s of any [[degree of a polynomial|degree]].&lt;ref&gt;{{cite book |title=Uncommon Mathematical Excursions: Polynomia and Related Realms |author=Dan Kalman |publisher=AMS |year=2009 |isbn=978-0-88385-341-2 |pages=13–22}}&lt;/ref&gt;  It was developed by Austrian engineer [[Eduard Lill]] in 1867.&lt;ref&gt;{{cite journal|title=Résolution graphique des équations numériques de tous degrés à une seule inconnue, et description d'un instrument inventé dans ce but |author= M. E. Lill |journal=[[Nouvelles Annales de Mathématiques]] |series=2 |volume=6 |year=1867 |pages=359–362}} ([https://eudml.org/doc/98167 online copy])&lt;/ref&gt;  A later paper by Lill dealt with the problem of [[complex numbers|complex]] roots.&lt;ref&gt;{{cite journal|title=Résolution graphique des équations algébriques qui ont des racines imaginaires |author= M. E. Lill|journal=[[Nouvelles Annales de Mathématiques]] |series=2 |volume=7 |year=1868 |pages=363–367}} ([https://eudml.org/doc/98262 online copy])&lt;/ref&gt;

Lill's method involves expressing the coefficients of a polynomial as magnitudes of segments at right angles to each other, starting from the origin, creating a path to a terminus, then finding a non-right angle path from the start to the terminus reflecting or refracting on the lines of the first path.

==Description of the method==
[[File:LillsMethod.svg|thumb|right|250px|Finding roots of the cubic 4''x''&lt;sup&gt;3&lt;/sup&gt;+2''x''&lt;sup&gt;2&lt;/sup&gt;−2''x''−1 using Lill's method. Roots are −1/2, −1/{{radic|2}}, 1/{{radic|2}}. Numbers on black segments are distances (coefficients in the equation), while a number shown on a colored line is the negative of the slope and hence a real root of the polynomial. ]]

To employ the method a diagram is drawn starting at the origin. A line segment is drawn rightwards by the magnitude of the first coefficient (the coefficient of the highest-power term)  (so that with a negative coefficient the segment will end left of the origin). From the end of the first segment another segment is drawn upwards by the magnitude of the second coefficient, then left by the magnitude of the third, and down by the magnitude of the fourth, and so on.  The sequence of directions (not turns) is always rightward, upward, leftward, downward, then repeating itself. Thus each turn is counterclockwise. The process continues for every coefficient of the polynomial including zeroes, with negative coefficients "walking backwards". The final point reached, at the end of the segment corresponding to the equation's constant term, is the terminus.

A line is then launched from the origin at some angle {{mvar|θ}}, reflected off of each line segment at a right angle (not necessarily the "natural" angle of reflection), and [[Refraction|refracted]] at a right angle through the line through each segment (including a line for the zero coefficients) when the angled path does not hit the line segment on that line.&lt;ref&gt;Phillips Verner Bradford, Sc.D.. ''[http://www.concentric.net/~pvb/ALG/rightpaths.html Visualizing solutions to n-th degree algebraic equations using right-angle geometric paths.]''  {{webarchive |url=https://web.archive.org/web/20100502013959/http://www.concentric.net/~pvb/ALG/rightpaths.html |date=May 2, 2010 }}&lt;/ref&gt; The vertical and horizontal lines are reflected off or refracted through in the following sequence: the line containing the segment corresponding to the coefficient of &lt;math&gt;x^{n-1},&lt;/math&gt; then of &lt;math&gt;x^{n-2},&lt;/math&gt; etc. Choosing {{mvar|θ}} so that the path lands on the terminus, the negative of the tangent of {{mvar|θ}} is a root of this polynomial. For every real zero of the polynomial there will be one unique initial angle and path that will land on the terminus. A quadratic with two real roots, for example, will have exactly two angles that satisfy the above conditions.

The construction in effect evaluates the polynomial according to [[Horner's method]]. For the polynomial &lt;math&gt;a_n x^n+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+ \cdots&lt;/math&gt; the values of &lt;math&gt;a_n x&lt;/math&gt;, &lt;math&gt;(a_n x+a_{n-1})x&lt;/math&gt;, &lt;math&gt;((a_n x+a_{n-1})x+a_{n-2})x,\ \dots&lt;/math&gt; are successively generated. A solution line giving a root is similar to the Lill's construction for the polynomial with that root removed.

In 1936 Margharita P. Beloch showed how Lill's method could be adapted to solve cubic equations using [[paper folding]].&lt;ref&gt;{{cite journal |title=Solving Cubics With Creases: The Work of Beloch and Lill |author=Thomas C. Hull|url=http://mars.wne.edu/~thull/papers/amer.math.monthly.118.04.307-hull.pdf|journal=American Mathematical Monthly |date=April 2011|pages=307–315|doi=10.4169/amer.math.monthly.118.04.307}}&lt;/ref&gt; If simultaneous folds are allowed then any ''n''th degree equation with a real root can be solved using ''n''–2 simultaneous folds.&lt;ref&gt;{{cite journal |title=One-, Two-, and Multi-Fold Origami Axioms|url=http://www.math.sjsu.edu/~alperin/AlperinLang.pdf |author1=Roger C. Alperin |author2=Robert J. Lang |journal=4OSME|publisher=A K Peters |year=2009}}&lt;/ref&gt;

== See also ==
*[[Carlyle circle]], which is based on a slightly modified version of Lill's method for a normed quadratic.

==References==
{{Reflist}}

==External links==
{{commonscat}}
*  {{cite web|last=Bradford|first=Phillips Verner|title=Extending Lill's Method of 1867|url=http://www.concentric.net/~pvb/ALG/rightpaths.html|work=Visualizing solutions to n-th degree algebraic equations using right-angle geometric paths|publisher=www.concentric.net|accessdate=3 February 2012|deadurl=yes|archiveurl=https://web.archive.org/web/20100502013959/http://www.concentric.net/~pvb/ALG/rightpaths.html|archivedate=2 May 2010|df=}}
* [http://dankalman.net/ume/lill/ Animation for Lill's Method]

[[Category:Geometry]]
[[Category:Paper folding]]
[[Category:Polynomials]]</text>
      <sha1>gzj9enatxdwxd7raprhgqgfohnw0n8j</sha1>
    </revision>
  </page>
  <page>
    <title>Linkurious</title>
    <ns>0</ns>
    <id>53723727</id>
    <revision>
      <id>860374819</id>
      <parentid>858333493</parentid>
      <timestamp>2018-09-20T07:08:02Z</timestamp>
      <contributor>
        <ip>85.119.46.8</ip>
      </contributor>
      <comment>Added Competitors section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4871">{{Infobox company
| name = Linkurious
| logo =
| logo_size =
| logo_alt =
| logo_caption =
| logo_padding =
| image =
| image_size =
| image_alt =
| image_caption =
| native_name =
| native_name_lang = &lt;!-- Use ISO 639-1 code, e.g. "fr" for French. For multiple names in different languages, use {{lang|[code]|[name]}}. --&gt;
| former_name =
| type = [[Social network analysis]] and [[graph visualization|graph data visualization]]
| industry = [[software]]
| founded = {{start date and age|2013|01|01}} in [[Paris]], France
| founder = Sébastien Heymann, David Rapin, Jean Villedieu
| hq_location = 
| hq_location_city = Paris
| hq_location_country = France
| area_served = &lt;!-- or: | areas_served = --&gt;
| key_people =
| products = 
| website = {{URL|linkurio.us}}
}}
'''Linkurious''' is a French software company that provides [[social network analysis]] primarily through [[graph visualization]].

== History ==

Linkurious was founded in 2013 by Sébastien Heymann, David Rapin and Jean Villedieu following the development of [[Gephi]], which was inspired by the prototype for [[Stanford|Stanford’s Center for Spatial and Textual Analysis]] project ''Mapping the Republic of Letters'' and looked at connections across thousands of communities in Europe and North America during [[The Enlightenment]].&lt;ref&gt;{{Cite web|url=http://news.stanford.edu/thedish/2016/06/03/visualization-tool-prototyped-by-stanford-humanities-scholars-aids-the-investigation-of-panama-papers/|title=Visualization tool prototyped by Stanford humanities scholars aids the investigation of ‘Panama Papers’ {{!}} The Dish|last=News|first=Stanford|website=news.stanford.edu|language=en|access-date=2017-04-19}}&lt;/ref&gt;

== Products ==
Linkurious Enterprise provides search and visualization capabilities for various [[graph databases]] such as [[Neo4j]], TitanDB, [[DataStax]] and [[AllegroGraph]].&lt;ref&gt;{{Cite web|url=https://www.datanami.com/2015/04/20/startup-delivers-visual-search-tool-for-neo4j-graphs/|title=Startup Delivers Visual Search Tool for Neo4j Graphs|date=2015-04-20|website=Datanami|access-date=2017-04-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://techcrunch.com/2016/04/12/datastax-adds-graph-databases-to-enterprise-cassandra-product-set/|title=DataStax adds graph databases to enterprise Cassandra product set|last=Miller|first=Ron|website=TechCrunch|access-date=2017-04-19}}&lt;/ref&gt;

Linkurious' graph visualization tool is used for [[NASA|NASA's]] Lessons Learned database, identifying connections between seemingly unlikely subjects, such as a correlation between contaminated fluid and battery fire risk.&lt;ref&gt;{{Cite web|url=https://www.fastcompany.com/3065044/nasa-is-harnessing-graph-databases-to-organize-lessons-learned-from-past-pr/|title=NASA Is Harnessing Graph Databases To Organize Lessons Learned From Past Projects|last=Melendez|first=Steven|website=FastCompany|access-date=2017-04-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://llis.nasa.gov/|title=Llis|website=llis.nasa.gov|access-date=2017-04-19}}&lt;/ref&gt;

== Panama Papers ==
The [[International Consortium of Investigative Journalists]] used a commercial version of Linkurious and [[Neo4j]] in the investigation of the [[Panama papers]], uncovering 4.8 million leaked files consisting of emails, 3 million database entries, 2.2 million PDFs, 1.2 million images, 320,000 text files, and 2242 files, evidence of money laundering, tax evasion or political corruption.&lt;ref&gt;{{cite web|url=http://www.rudebaguette.com/2016/04/07/how-tech-enabled-journalists-to-sift-through-2-6-tb-of-raw-data/|title=How France's Linkurious helped reporters use data visualization to make sense of the Panama Papers|date=7 April 2016|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://panamapapers.icij.org/blog/20160425-data-tech-team-ICIJ.html|title=Wrangling 2.6TB of data: The people and the technology behind the Panama Papers|access-date=2017-04-19}}&lt;/ref&gt;

[[International Consortium of Investigative Journalists|ICIJ]] also utilized the software during the [[Swiss Leaks]] investigation that revealed a massive tax evasion scheme in which 180.6 billion euros passed through [[HSBC]] accounts.&lt;ref&gt;{{cite web|url=https://business.lesechos.fr/entrepreneurs/communaute/021818665622-linkurious-la-pepite-revelee-grace-aux-panama-papers-209153.php|title=Linkurious, la pépite révélée grâce aux « Panama Papers »|date=5 April 2016|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.lesechos.fr/10/02/2015/lesechos.fr/0204147710591_swissleaks---on-n-a-souleve-qu-un-coin-du-tapis.htm|title=SwissLeaks : on n'a soulevé qu'un coin du tapis|date=10 February 2015|publisher=}}&lt;/ref&gt;

== Competitors ==
- [https://arcadeanalytics.com Arcade Analytics]

== References ==
{{reflist}}

[[Category:Software companies of France]]
[[Category:Graph databases]]
[[Category:Social network analysis software]]
[[Category:French companies established in 2013]]</text>
      <sha1>ei6nn35oesxbsd3k2fc2yarfz5ze6ls</sha1>
    </revision>
  </page>
  <page>
    <title>Lissajous curve</title>
    <ns>0</ns>
    <id>753756</id>
    <revision>
      <id>865455718</id>
      <parentid>863043877</parentid>
      <timestamp>2018-10-24T02:19:31Z</timestamp>
      <contributor>
        <username>Just fixing typos</username>
        <id>32321314</id>
      </contributor>
      <minor/>
      <comment>Fixed wrong link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12470">{{distinguish|text=[[spirograph]]s, which are generally enclosed by a circular boundary, whereas Lissajous curves are enclosed by rectangular boundaries}}
{{Refimprove|date=November 2010}}

[[File:Lissajous figure - sand on paper.jpg|thumb|A Lissajous figure, made by releasing sand from a container at the end a [[Harmonograph#Blackburn pendulum|double pendulum]]]]
In [[mathematics]], a '''Lissajous curve''' {{IPAc-en|ˈ|l|ɪ|s|ə|ʒ|uː}}, also known as '''Lissajous figure''' or '''Bowditch curve''' {{IPAc-en|ˈ|b|aʊ|d|ɪ|tʃ}}, is the graph of a system of [[parametric equation]]s

: &lt;math&gt;x=A\sin(at+\delta),\quad y=B\sin(bt),&lt;/math&gt;

which describe [[complex harmonic motion]]. This family of [[curve]]s was investigated by [[Nathaniel Bowditch]]  in 1815, and later in more detail by [[Jules Antoine Lissajous]] in 1857.

The appearance of the figure is highly sensitive to the ratio {{math|{{sfrac|''a''|''b''}}}}. For a ratio of 1, the figure is an [[ellipse]], with special cases including [[circles]] ({{math|1=''A'' = ''B''}}, {{math|1=''δ'' = {{sfrac|[[pi|π]]|2}}}} [[radian]]s) and [[line (mathematics)|lines]] ({{math|1=''δ'' = 0}}). Another simple Lissajous figure is the [[parabola]] ({{math|1={{sfrac|''b''|''a''}} = 2}}, {{math|1=''δ'' = {{sfrac|π|4}}}}). Other ratios produce more complicated curves, which are closed only if {{math|{{sfrac|''a''|''b''}}}} is [[rational number|rational]]. The visual form of these curves is often suggestive of a three-dimensional [[knot (mathematical)|knot]], and indeed many kinds of knots, including those known as [[Lissajous knot]]s, project to the plane as Lissajous figures.

Visually, the ratio {{math|{{sfrac|''a''|''b''}}}} determines the number of "lobes" of the figure. For example, a ratio of {{sfrac|3|1}} or {{sfrac|1|3}} produces a figure with three major lobes (see image). Similarly, a ratio of {{sfrac|5|4}} produces a figure with five horizontal lobes and four vertical lobes. Rational ratios produce closed (connected) or "still" figures, while irrational ratios produce figures that appear to rotate. The ratio {{math|{{sfrac|''A''|''B''}}}} determines the relative width-to-height ratio of the curve. For example, a ratio of {{sfrac|2|1}} produces a figure that is twice as wide as it is high. Finally, the value of {{math|''δ''}} determines the apparent "rotation" angle of the figure, viewed as if it were actually a three-dimensional curve. For example, {{math|1=''δ'' = 0}} produces {{math|''x''}} and {{math|''y''}} components that are exactly in phase, so the resulting figure appears as an apparent three-dimensional figure viewed from straight on (0°). In contrast, any non-zero {{math|''δ''}} produces a figure that appears to be rotated, either as a left–right or an up–down rotation (depending on the ratio {{math|{{sfrac|''a''|''b''}}}}).

[[Image:Lissajous-Figur 1 zu 3 (Oszilloskop).jpg|thumb|250px|right|Lissajous figure on an [[oscilloscope]], displaying a 1:3 relationship between the frequencies of the vertical and horizontal sinusoidal inputs, respectively.]]

Lissajous figures where {{math|1=''a'' = 1}}, {{math|1=''b'' = ''N''}} ({{math|''N''}} is a [[natural number]]) and

: &lt;math&gt;\delta=\frac{N-1}{N}\frac{\pi}{2} &lt;/math&gt;

are [[Chebyshev polynomials]] of the first kind of degree {{math|''N''}}. This property is exploited to produce a set of points, called [[Padua points]], at which a function may be sampled in order to compute either a bivariate interpolation or quadrature of the function over the domain {{math|[−1,1] × [−1,1]}}.

The relation of some Lissajous curves to Chebyshev polynomials is clearer to understand if the Lissajous curve which generates each of them is expressed using cosine functions rather than sine functions.

: &lt;math&gt;x=\cos(t),\quad y=\cos(Nt)&lt;/math&gt;

==Examples==
[[File:Lissajous animation.gif|thumb|upright=1.3|Animation showing curve adaptation as the ratio {{math|{{sfrac|''a''|''b''}}}} increases from 0 to 1]]

The animation shows the curve adaptation with continuously increasing {{math|{{sfrac|''a''|''b''}}}} fraction from 0 to 1 in steps of 0.01 ({{math|1=''δ'' = 0}}).

Below are examples of Lissajous figures with {{math|1=''δ'' = {{sfrac|''π''|2}}}}, an odd [[natural number]] {{math|''a''}}, an even [[natural number]] {{math|''b''}}, and {{math|1={{abs|''a'' − ''b''}} = 1}}.

&lt;gallery&gt;
Image:Lissajous_curve_1by2.svg|{{math|1=''a'' = 1}}, {{math|1=''b'' = 2}} (1:2)
Image:Lissajous_curve_3by2.svg|{{math|1=''a'' = 3}}, {{math|1=''b'' = 2}} (3:2)
Image:Lissajous_curve_3by4.svg|{{math|1=''a'' = 3}}, {{math|1=''b'' = 4}} (3:4)
Image:Lissajous_curve_5by4.svg|{{math|1=''a'' = 5}}, {{math|1=''b'' = 4}} (5:4)
&lt;/gallery&gt;

==Generation==
Prior to modern electronic equipment, Lissajous curves could be generated mechanically by means of a [[harmonograph]].

=== Practical application ===
Lissajous curves can also be generated using an [[oscilloscope]] (as illustrated). An [[Analog signature analysis|octopus circuit]] can be used to demonstrate the [[waveform]] images on an oscilloscope. Two phase-shifted sinusoid inputs are applied to the oscilloscope in X-Y mode and the phase relationship between the signals is presented as a Lissajous figure.

In the professional audio world, this method is used for realtime analysis of the phase relationship between the left and right channels of a stereo audio signal. On larger, more sophisticated audio mixing consoles an oscilloscope may be built-in for this purpose.

On an oscilloscope, we suppose {{math|''x''}} is CH1 and {{math|''y''}} is CH2, {{math|''A''}} is the amplitude of CH1 and {{math|''B''}} is the amplitude of CH2, {{math|''a''}} is the frequency of CH1 and {{math|''b''}} is the frequency of CH2, so {{math|{{sfrac|''a''|''b''}}}} is the ratio of frequencies of the two channels, and {{math|''δ''}} is the phase shift of CH1.

A purely mechanical application of a Lissajous curve with {{math|1=''a'' = 1}}, {{math|1=''b'' = 2}} is in the driving mechanism of the [[Mars Light]] type of oscillating beam lamps popular with railroads in the mid-1900s. The beam in some versions traces out a lopsided figure-8 pattern on its side.

==Application for the case of {{math|1= ''a'' = ''b''}}==
[[Image:LissajousTechnion.png|thumb|250px|right|In this figure both input frequencies are identical, but the phase variance between them creates the shape of an [[ellipse]].]]
[[File:Circular Lissajous.gif|thumb|250px|right|'''Top:''' Output signal as a function of time.&lt;br&gt;'''Middle:''' Input signal as a function of time.&lt;br&gt;'''Bottom:''' Resulting Lissajous curve when output is plotted as a function of the input.&lt;br&gt;In this particular example, because the output is 90 degrees out of phase from the input, the Lissajous curve is a circle, and is rotating counterclockwise.]]
When the input to an [[LTI system]] is sinusoidal, the output is sinusoidal with the same frequency, but it may have a different amplitude and some [[phase shift]]. Using an [[oscilloscope]] that can plot one signal against another (as opposed to one signal against time) to plot the output of an LTI system against the input to the LTI system produces an ellipse that is a Lissajous figure for the special case of {{math|1= ''a'' = ''b''}}. The [[aspect ratio]] of the resulting ellipse is a function of the phase shift between the input and output, with an aspect ratio of 1 (perfect circle) corresponding to a phase shift of ±90° and an aspect ratio of ∞ (a line) corresponding to a phase shift of 0° or 180°.&lt;ref name=Al-Khazali/&gt;

The figure below summarizes how the Lissajous figure changes over different phase shifts. The phase shifts are all negative so that [[propagation delay|delay]] [[semantics]] can be used with a [[causal system|causal]] LTI system (note that −270° is equivalent to +90°). The arrows show the direction of rotation of the Lissajous figure.&lt;ref name=Al-Khazali&gt;{{cite journal |url=http://www.iosrjen.org/Papers/vol2_issue5/G025971978.pdf |last1=Al-Khazali |first1=Hisham A. H. |last2=Askari |first2=Mohamad R. |title=Geometrical and Graphical Representations Analysis of Lissajous Figures in Rotor Dynamic System |journal=IOSR Journal of Engineering | date=May 2012 |volume=2 |issue=5 |pages=971–978}}&lt;/ref&gt;

[[Image:Lissajous phase.svg|thumb|center|600px|A pure phase shift affects the [[eccentricity (mathematics)|eccentricity]] of the Lissajous oval. Analysis of the oval allows phase shift from an [[LTI system]] to be measured..]]

==In engineering==
A Lissajous curve is used in experimental tests to determine if a device may be properly categorized as a [[Memristor#Experimental tests for memristors|memristor]].{{citation needed|date=September 2015}}

==In culture==

===In film===
[[File:Simple Lissajous Animation.ogv|thumb|100px|Science fiction style Lissajous animation]]

Lissajous figures were sometimes displayed on oscilloscopes meant to simulate high-tech equipment in science-fiction TV shows and movies in the 1960s and 1970s.&lt;ref name="Information1987"&gt;{{cite journal |title=A long way from Lissajous figures |journal=New Scientist |url=https://books.google.com/books?id=Vzni1LqxEEsC&amp;pg=PA77 |date=24 September 1987 |publisher=Reed Business Information |page=77 |issn=0262-4079}}&lt;/ref&gt;

The [[title sequence]] by [[John Whitney (animator)|John Whitney]] for [[Alfred Hitchcock]]'s 1958 film ''[[Vertigo (film)|Vertigo]]'' is based on Lissajous figures.&lt;ref&gt;{{cite web|url=http://rhizome.org/editorial/2013/may/9/did-vertigo-introduce-computer-graphics-cinema|title=Did 'Vertigo' Introduce Computer Graphics to Cinema?}}&lt;/ref&gt;

In a sequence towards the end of an episode of Columbo entitled "Make me a Perfect Murder", the detective sits watching Lissajous curves displayed to music on monitors in a TV outside broadcast van.

===Company logos===

Lissajous figures are sometimes used in [[graphic design]] as [[logotype|logo]]s. Examples include:
* The [[Australian Broadcasting Corporation]] ({{math|1=''a'' = 1}}, {{math|1=''b'' = 3}}, {{math|1=''δ'' = {{sfrac|π|2}}}})&lt;ref&gt;{{cite web|url=http://www.abc.net.au/science/holo/liss.htm|title=The ABC's of Lissajous figures}}&lt;/ref&gt;
* The [[Lincoln Laboratory]] at [[Massachusetts Institute of Technology|MIT]] ({{math|1=''a'' = 4}}, {{math|1=''b'' = 3}}, {{math|1=''δ'' = 0}})&lt;ref&gt;{{cite web|url=http://www.ll.mit.edu/about/History/logo.html|title=Lincoln Laboratory Logo|publisher=MIT Lincoln Laboratory|year=2008|accessdate=2008-04-12}}&lt;/ref&gt;
* The [[University of Electro-Communications]], Japan ({{math|1=''a'' = 5}}, {{math|1=''b'' = 6}}, {{math|1=''δ'' = {{sfrac|π|2}}}}).{{citation needed|date=September 2015}}
* Disney's [[Movies Anywhere]] streaming video application uses a stylized version of the curve

===In modern art===
{{further|Mathematics and art}}

* The [[Dadaist]] artist [[Max Ernst]] [[Mathematics and art#Analysis of art history|painted Lissajous figures]] directly by swinging a punctured bucket of paint over a canvas.&lt;ref&gt;{{cite web |url=https://www.herts.ac.uk/__data/assets/pdf_file/0013/12307/WPIAAD_vol2_king.pdf |title=From Max Ernst to Ernst Mach: epistemology in art and science. |last=King |first=M. |date=2002 |accessdate=17 September 2015}}&lt;/ref&gt;

==See also==
* [[Rose curve]]
* [[Lissajous orbit]]
* [[Blackburn pendulum]]
* [[Lemniscate of Gerono]]

==Notes==
{{More footnotes|date=November 2010}}{{Commons category|Lissajous curves}}
{{reflist}}

==External links==
* [http://mathworld.wolfram.com/LissajousCurve.html Lissajous Curve at Mathworld]

=== Interactive demos ===
* 3D Java applets depicting the construction of Lissajous curves in an oscilloscope:
** [http://www.magnet.fsu.edu/education/tutorials/java/lissajous/index.html Tutorial] from the [[NHMFL]]
** [http://phy.hk/wiki/englishhtm/Lissajous.htm Physics applet] by Chiu-king Ng
* [http://codepen.io/kotwgarnku/full/dMqKZG Detailed Lissajous figures simulation] Drawing Lissajous figures with interactive sliders in Javascript
*[http://gerdbreitenbach.de/lissajous/lissajous.html Lissajous Curves: Interactive simulation of graphical representations of musical intervals and vibrating strings ]
* [http://jsxgraph.uni-bayreuth.de/wiki/index.php/Lissajous_curves Interactive Lissajous curve generator] – Javascript applet using JSXGraph
* [http://ibiblio.org/e-notes/html5/lis/lissa5.htm Animated Lissajous figures]

{{Authority control}}

[[Category:Curves]]
[[Category:Trigonometry]]
[[Category:Articles containing video clips]]</text>
      <sha1>r6sno2d4wojtz9zawioiuyk75bjtvyy</sha1>
    </revision>
  </page>
  <page>
    <title>List of perfect numbers</title>
    <ns>0</ns>
    <id>24364843</id>
    <revision>
      <id>856243344</id>
      <parentid>856241556</parentid>
      <timestamp>2018-08-23T21:17:58Z</timestamp>
      <contributor>
        <username>Anita5192</username>
        <id>13220696</id>
      </contributor>
      <comment>Undid revision 856241556 by [[Special:Contributions/2.137.210.194|2.137.210.194]] ([[User talk:2.137.210.194|talk]])Not helpful.  This article is in English.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8804">The following is a list of the known [[perfect number]]s, and the exponents ''p'' that can be used to generate them (using the expression 2&lt;sup&gt;''p''−1&lt;/sup&gt;× (2&lt;sup&gt;''p''&lt;/sup&gt; − 1)) whenever 2&lt;sup&gt;''p''&lt;/sup&gt; − 1 is a [[Mersenne prime]]. All even perfect numbers are of this form. It is not known whether there are any odd perfect numbers.&lt;ref name="Crilly2007"&gt;{{cite book|last=Crilly|first=Tony|title=50 mathematical ideas you really need to know|year=2007|publisher=Quercus Publishing|isbn=978-1-84724-008-8|page=43}}&lt;/ref&gt;  {{As of|2018}} there are 50 known perfect numbers in total.&lt;ref name="list1"&gt;{{cite web|url=http://amicable.homepage.dk/perfect.htm|title=Known Perfect Numbers|last=Munch Pedersen|first=Jan|date=11 Sep 2006|accessdate=2009-09-16|deadurl=yes|archiveurl=https://web.archive.org/web/20090503154707/http://amicable.homepage.dk/perfect.htm|archivedate=2009-05-03|df=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://web.mit.edu/adorai/www/perfectnumbers.html|publisher=MIT|accessdate=2009-09-16|title=Perfect Numbers}}&lt;/ref&gt;&lt;ref&gt;Chris Caldwell, "[http://primes.utm.edu/mersenne/#known Mersenne Primes: History, Theorems and Lists]" at The [[Prime Pages]]. Retrieved 2018-01-03.&lt;/ref&gt; The ratio ''p'' / digits  approaches log(10) / log(4) = 1.6609640474...

{| class="wikitable"
! Rank
! ''[[Prime number|p]]''
! Perfect number
! Digits
! Year
! Discoverer
|-
|1||align="right"|2||align="right"|[[6 (number)|6]]||align="right"|1||4th century B.C.&lt;ref&gt;The Penguin's Dictionary of curious and interesting numbers&lt;/ref&gt;||[[Euclid]]
|-
|2||align="right"|3||align="right"|[[28 (number)|28]]||align="right"|2||4th century B.C.||[[Euclid]]
|-
|3||align="right"|5||align="right"|[[496 (number)|496]]||align="right"|3||4th century B.C.||[[Euclid]]
|-
|4||align="right"|7||align="right"|[[8128 (number)|8128]]||align="right"|4||4th century B.C.||[[Euclid]]
|-
|5||align="right"|13||align="right"|33550336||align="right"|8||1456||First seen in a medieval manuscript, ''Munich, Bayerische Staatsbibliothek, CLM 14908, fol. 33''&lt;ref&gt;{{cite book |title=Divisibility and primality |last=Dickson |first=Leonard Eugene |authorlink=Leonard Eugene Dickson |coauthors= |year= |publisher= |location= |isbn= 9780821819340|page=6 |pages= |url=https://books.google.com/books?id=D5GmC3zxeN0C&amp;lpg=PR1&amp;pg=PA6#v=onepage&amp;q&amp;f=false |accessdate=2011-04-13 |date=1999-05-01}}&lt;/ref&gt;
|-
|6||align="right"|17||align="right"|8589869056||align="right"|10||1588||[[Pietro Cataldi|Cataldi]]&lt;ref name="Crilly2007" /&gt;
|-
|7||align="right"|19||align="right"|137438691328||align="right"|12||1588||[[Pietro Cataldi|Cataldi]]&lt;ref name="Crilly2007" /&gt;
|-
|8||align="right"|31||align="right"|2305843008139952128||align="right"|19||1772||[[Leonhard Euler|Euler]]
|-
|9||align="right"|61||265845599156...615953842176||align="right"|37||1883||[[Ivan Mikheevich Pervushin|Pervushin]]
|-
|10||align="right"|89||191561942608...321548169216||align="right"|54||1911||[[R. E. Powers|Powers]]
|-
|11||align="right"|107||131640364585...117783728128||align="right"|65||1914||[[Ralph Ernest Powers|Powers]]
|-
|12||align="right"|127||144740111546...131199152128||align="right"|77||1876||[[Édouard Lucas|Lucas]]
|-
|13||align="right"|521||235627234572...160555646976||align="right"|314||1952||[[Raphael M. Robinson|Robinson]]
|-
|14||align="right"|607||141053783706...759537328128||align="right"|366||1952||[[Raphael M. Robinson|Robinson]]
|-
|15||align="right"|1,279||541625262843...764984291328||align="right"|770||1952||[[Raphael M. Robinson|Robinson]]
|-
|16||align="right"|2,203||108925835505...834453782528||align="right"|1,327||1952||[[Raphael M. Robinson|Robinson]]
|-
|17||align="right"|2,281||994970543370...675139915776||align="right"|1,373||1952||[[Raphael M. Robinson|Robinson]]
|-
|18||align="right"|3,217||335708321319...332628525056||align="right"|1,937||1957||[[Hans Riesel|Riesel]]
|-
|19||align="right"|4,253||182017490401...437133377536||align="right"|2,561||1961||Hurwitz
|-
|20||align="right"|4,423||407672717110...642912534528||align="right"|2,663||1961||Hurwitz
|-
|21||align="right"|9,689||114347317530...558429577216||align="right"|5,834||1963||[[Donald B. Gillies|Gillies]]
|-
|22||align="right"|9,941||598885496387...324073496576||align="right"|5,985||1963||Gillies
|-
|23||align="right"|11,213||395961321281...702691086336||align="right"|6,751||1963||Gillies
|-
|24||align="right"|19,937||931144559095...790271942656||align="right"|12,003||1971||[[Bryant Tuckerman|Tuckerman]]
|-
|25||align="right"|21,701||100656497054...255141605376||align="right"|13,066||1978||[[Landon Curt Noll|Noll]] &amp; Nickel
|-
|26||align="right"|23,209||811537765823...603941666816||align="right"|13,973||1979||Noll
|-
|27||align="right"|44,497||365093519915...353031827456||align="right"|26,790||1979||[[Harry L. Nelson|Nelson]] &amp; [[David Slowinski|Slowinski]]
|-
|28||align="right"|86,243||144145836177...957360406528||align="right"|51,924||1982||Slowinski
|-
|29||align="right"|110,503||136204582133...233603862528||align="right"|66,530||1988||Colquitt &amp; Welsh
|-
|30||align="right"|132,049||131451295454...491774550016||align="right"|79,502||1983||Slowinski
|-
|31||align="right"|216,091||278327459220...416840880128||align="right"|130,100||1985||Slowinski
|-
|32||align="right"|756,839||151616570220...600565731328||align="right"|455,663||1992||Slowinski &amp; [[Paul Gage|Gage]]
|-
|33||align="right"|859,433||838488226750...540416167936||align="right"|517,430||1994||Slowinski &amp; Gage
|-
|34||align="right"|1,257,787||849732889343...028118704128||align="right"|757,263||1996||Slowinski &amp; Gage
|-
|35||align="right"|1,398,269||331882354881...017723375616||align="right"|841,842||1996||Armengaud, [[George Woltman|Woltman]], et al.
|-
|36||align="right"|2,976,221||194276425328...724174462976||align="right"|1,791,864||1997||Spence, Woltman, et al.
|-
|37||align="right"|3,021,377||811686848628...573022457856||align="right"|1,819,050||1998||Clarkson, Woltman, Kurowski, et al.
|-
|38||align="right"|6,972,593||955176030521...475123572736||align="right"|4,197,919||1999||Hajratwala, Woltman, Kurowski, et al.
|-
|39||align="right"|13,466,917||427764159021...460863021056||align="right"|8,107,892||2001||Cameron, Woltman, Kurowski, et al.
|-
|40||align="right"|20,996,011||793508909365...578206896128||align="right"|12,640,858||2003||Shafer, Woltman, Kurowski, et al.
|-
|41||align="right"|24,036,583||448233026179...460572950528||align="right"|14,471,465||2004||Findley, Woltman, Kurowski, et al.
|-
|42||align="right"|25,964,951||746209841900...874791088128||align="right"|15,632,458||2005||Nowak, Woltman, Kurowski, et al.
|-
|43||align="right"|30,402,457||497437765459...536164704256||align="right"|18,304,103||2005||[[Curtis Cooper (mathematician)|Cooper]], Boone, Woltman, Kurowski, et al.
|-
|44||align="right"|32,582,657||775946855336...476577120256||align="right"|19,616,714||2006||Cooper, Boone, Woltman, Kurowski, et al.
|-
|45||align="right"|37,156,667||204534225534...975074480128||align="right"|22,370,543||2008||Elvenich, Woltman, Kurowski, et al.
|-
|46||align="right"|42,643,801||144285057960...837377253376||align="right"|25,674,127||2009||Strindmo, Woltman, Kurowski, et al.
|-
|47||align="right"|43,112,609||500767156849...221145378816||align="right"|25,956,377||2008||Smith, Woltman, Kurowski, et al.
|-
|48||align="right"|57,885,161||169296395301...626270130176||align="right"|34,850,340||2013||Cooper, Woltman, Kurowski, et al.
|-
|49||align="right"|74,207,281||451129962706...557930315776||align="right"|44,677,235||2016||Cooper, Woltman, Kurowski, Blosser, et&amp;nbsp;al.
|-
|50||align="right"|77,232,917||109200152134...402016301056||align="right"|46,498,850||2017||Pace, Woltman, Kurowski, Blosser, et al.
|}

The displayed ranks are among those perfect numbers which are known {{As of|2018|04|lc=y}}. Some ranks may change later if smaller perfect numbers are discovered. It is known there is no odd perfect number below 10&lt;sup&gt;1500&lt;/sup&gt;.&lt;ref&gt;Ochem, Pascal; Rao, Michael, [http://www.ams.org/journals/mcom/2012-81-279/S0025-5718-2012-02563-4/S0025-5718-2012-02563-4.pdf "Odd Perfect Numbers Are Greater Than 10^1500"], ''MATHEMATICS OF COMPUTATION'', Volume 81, Number 279, July 2012, Pages 1869–1877. S 0025-5718(2012)02563-4. Article electronically published on January 30, 2012&lt;/ref&gt; [[Great Internet Mersenne Prime Search|GIMPS]] reported that by 8 April 2018 the search for Mersenne primes (and thereby even perfect numbers) became exhaustive up to the 47th above.&lt;ref&gt;[http://www.mersenne.org/report_milestones/ "GIMPS Milestones Report"]. Retrieved 2018-08-04.&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* [http://primes.utm.edu/mersenne/index.html Mersenne Primes: History, Theorems and Lists]

{{DEFAULTSORT:Perfect numbers}}
[[Category:Mathematical tables]]
[[Category:Mathematics-related lists]]</text>
      <sha1>qh8xo3q2jcsslvljckmw782ei80rpqd</sha1>
    </revision>
  </page>
  <page>
    <title>Long division</title>
    <ns>0</ns>
    <id>313384</id>
    <revision>
      <id>869220724</id>
      <parentid>866900302</parentid>
      <timestamp>2018-11-17T05:09:52Z</timestamp>
      <contributor>
        <username>AManWithNoPlan</username>
        <id>12416903</id>
      </contributor>
      <comment>That's not a valid DOI</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22515">{{about|elementary handwritten division|mathematical definition and properties|Division (mathematics)|and|Euclidean division|software algorithms|Division algorithm|other uses}}

In [[arithmetic]], '''long division''' is a standard [[division algorithm]] suitable for dividing multidigit numbers that is simple enough to perform by hand. It breaks down a [[division (mathematics)|division]] problem into a series of easier steps. As in all division problems, one number, called the [[division (mathematics)|dividend]], is divided by another, called the [[divisor]],  producing a result called the [[quotient]]. It enables computations involving arbitrarily large numbers to be performed by following a series of simple steps.&lt;ref&gt;{{MathWorld | urlname=LongDivision | title= Long Division}}&lt;/ref&gt; The abbreviated form of long division is called [[short division]], which is almost always used instead of long division when the divisor has only one digit. [[Chunking (division)|Chunking]] (also known as the partial quotients method or the hangman method) is a less-efficient form of long division which may be easier to understand.

While related algorithms have existed since the 12th century AD,&lt;ref&gt;{{Cite web|url=http://new.math.uiuc.edu/im2008/rogers/algebra.html|title=Islamic Mathematics|website=new.math.uiuc.edu|access-date=2016-03-31}}&lt;/ref&gt; the specific algorithm in modern use was introduced by [[Henry Briggs (mathematician)|Henry Briggs]] {{Circa}} 1600 AD.&lt;ref&gt;{{Cite journal|title=Henry Briggs - Oxford Reference|url=http://www.oxfordreference.com/view/10.1093/oi/authority.20110810104516866}}&lt;/ref&gt;

== Place in education ==
Inexpensive calculators and computers have become the most common way to solve division problems, eliminating a traditional [[mathematical exercise]], and decreasing the educational opportunity to show how to do so by paper and pencil techniques. (Internally, those devices use one of a variety of [[division algorithm]]s). In the United States, long division has been especially targeted for de-emphasis, or even elimination from the school curriculum, by [[reform mathematics]], though traditionally introduced in the 4th or 5th grades.

== Method ==
In English-speaking countries, long division does not use the [[division slash]] {{angle brackets|[[∕]]}} or [[obelus]] {{angle brackets|÷}} signs but instead constructs a '''tableau'''.&lt;ref&gt;{{citation |last=Nicholson |first=W. Keith |title=Introduction to Abstract Algebra, ''4th ed.'' |publisher=John Wiley &amp; Sons |date=2012 |p=[https://books.google.co.uk/books?id=w-GaLpapRcEC&amp;pg=PA206 206] }}.&lt;/ref&gt; The [[divisor]] is separated from the [[dividend]] by a [[right parenthesis]] {{angle brackets|[[)]]}} or [[vertical bar]] {{angle brackets|[[vertical bar|{{!}}]]}}; the dividend is separated from the [[quotient]] by a [[Vinculum (symbol)|vinculum]] (i.e., [[overbar]]). The combination of these two symbols is sometimes known as a '''long division symbol''' or '''division bracket'''.&lt;ref&gt;{{citation |title=Wolfram MathWorld |contribution-url=http://mathworld.wolfram.com/LongDivisionSymbol.html |contribution=Long Division Symbol |url=http://wolfram.com |accessdate=11 February 2016 }}.&lt;/ref&gt; It developed in the 18th century from an earlier single-line notation separating the dividend from the quotient by a [[left parenthesis]].&lt;ref&gt;{{citation |contribution=Symbols of Operation |contribution-url=http://jeff560.tripod.com/operation.html |date=2010 |url=http://jeff560.tripod.com/mathsym.html |title=Earliest Uses of Various Mathematical Symbols |last=Miller |first=Jeff }}.&lt;/ref&gt;&lt;ref&gt;{{citation |last=Hill|first=John|title=Arithmetick both in the theory and practice|publisher=Straben et al.|year=1772|edition=11th|orig-year=First published 1712|place=London|url=http://digital.library.pitt.edu/cgi-bin/t/text/pageviewer-idx?c=nietz;cc=nietz;idno=00abf4892m;node=00abf4892m%3A1.11;frm=frameset;view=image;seq=3;page=root;size=s|accessdate=12 February 2016|page=200}}&lt;/ref&gt;

The process is begun by dividing the left-most digit of the dividend by the divisor.  The quotient (rounded down to an integer) becomes the first digit of the result, and the [[remainder]] is calculated (this step is notated as a subtraction).  This remainder carries forward when the process is repeated on the following digit of the dividend (notated as 'bringing down' the next digit to the remainder).  When all digits have been processed and no remainder is left, the process is complete.

An example is shown below, representing the division of 500 by 4 (with a result of 125).
     &lt;u&gt; &lt;span style="color: red;"&gt;1&lt;/span&gt;&lt;span style="color: green;"&gt;2&lt;/span&gt;&lt;span style="color: blue;"&gt;5&lt;/span&gt;&lt;/u&gt;     (Explanations)
    4)500
      &lt;u&gt;4&lt;/u&gt;        ( 4 &amp;times;  &lt;span style="color: red;"&gt;1&lt;/span&gt; =  4)
      &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;0       ( 5 -  4 =  &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;)
       &lt;u&gt;8&lt;/u&gt;       ( 4 &amp;times;  &lt;span style="color: green;"&gt;2&lt;/span&gt; =  8)
       &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;0      (10 -  8 =  &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;)
       &lt;u&gt;20&lt;/u&gt;      ( 4 &amp;times;  &lt;span style="color: blue;"&gt;5&lt;/span&gt; = 20)
        0      (20 - 20 =  0)

[[File:Long division.JPG|thumb|An example of long division performed without a calculator.]]
In the above example, the first step is to find the shortest sequence of digits starting from the left end of the dividend, 500, that the divisor 4 goes into at least once; this shortest sequence in this example is simply the first digit, 5. The largest number that the divisor 4 can be multiplied by without exceeding 5 is 1, so the digit 1 is put above the 5 to start constructing the quotient. Next, the 1 is multiplied by the divisor 4, to obtain the largest whole number (4 in this case) that is a multiple of the divisor 4 without exceeding the 5; this product of 1 times 4 is 4, so 4 is placed underneath the 5. Next the 4 under the 5 is subtracted from the 5 to get the remainder, 1, which is placed under the 4 under the 5. This remainder 1 is necessarily smaller than the divisor 4. Next the first as-yet unused digit in the dividend, in this case the first digit 0 after the 5, is copied directly underneath itself and next to the remainder 1, to form the number 10. At this point the process is repeated enough times to reach a stopping point: The largest number by which the divisor 4 can be multiplied without exceeding 10 is 2, so 2 is written above the 0 that is next to the 5&amp;nbsp;– that is, directly above the last digit in the 10. Then the latest entry to the quotient, 2, is multiplied by the divisor 4 to get 8, which is the largest multiple of 4 that does not exceed 10; so 8 is written below 10, and the subtraction 10 minus 8 is performed to get the remainder 2, which is placed below the 8. This remainder 2 is necessarily smaller than the divisor 4. The next digit of the dividend (the last 0 in 500) is copied directly below itself and next to the remainder 2, to form 20. Then the largest number by which the divisor 4 can be multiplied without exceeding 20 is ascertained; this number is 5, so 5 is placed above the last dividend digit that was brought down (i.e., above the rightmost 0 in 500). Then this new quotient digit 5 is multiplied by the divisor 4 to get 20, which is written at the bottom below the existing 20. Then 20 is subtracted from 20, yielding 0, which is written below the 20. We know we are done now because two things are true: there are no more digits to bring down from the dividend, and the last subtraction result was 0.

If the last remainder when we ran out of dividend digits had been something other than 0, there would have been two possible courses of action. (1) We could just stop there and say that the dividend divided by the divisor is the quotient written at the top with the remainder written at the bottom; equivalently we could write the answer as the quotient followed by a fraction that is the remainder divided by the divisor. Or, (2) we could extend the dividend by writing it as, say, 500.000... and continue the process (using a decimal point in the quotient directly above the decimal point in the dividend), in order to get a decimal answer, as in the following example.

     &lt;u&gt;  31.75&lt;/u&gt;     
    4)127.00
      &lt;u&gt;12&lt;/u&gt;         (12 ÷ 4 = 3)
       07        (0 [[remainder]], bring down next figure)
        &lt;u&gt;4&lt;/u&gt;        (7 ÷ 4 = 1 r 3 )                                             
        3.0      (0 is added in order to make 3 divisible by 4; the 0 is accounted for by adding a decimal point in the quotient.)
        &lt;u&gt;2.8&lt;/u&gt;      (7 &amp;times; 4 = 28)
          20     (an additional zero is brought down)
          &lt;u&gt;20&lt;/u&gt;     (5 &amp;times; 4 = 20)
           0

In this example, the decimal part of the result is calculated by continuing the process beyond the units digit, "bringing down" zeros as being the decimal part of the dividend.

This example also illustrates that, at the beginning of the process, a step that produces a zero can be omitted.  Since the first digit 1 is less than the divisor 4, the first step is instead performed on the first two digits 12.  Similarly, if the divisor were 13, one would perform the first step on 127 rather than 12 or 1.

===Basic procedure for long division of ''n'' ÷ ''m''===

# Find the location of all decimal points in the dividend ''n'' and divisor ''m''.
# If necessary, simplify the long division problem by moving the decimals of the divisor and dividend by the same number of decimal places, to the right, (or to the left) so that the decimal of the divisor is to the right of the last digit.
# When doing long division, keep the numbers lined up straight from top to bottom under the tableau.
# After each step, be sure the remainder for that step is less than the divisor. If it is not, there are three possible problems: the multiplication is wrong, the subtraction is wrong, or a greater quotient is needed.
# In the end, the remainder, ''r'', is added to the growing quotient as a [[fraction (mathematics)|fraction]],&amp;nbsp;''r''/''m''.

===Example with multi-digit divisor===

[[Image:LongDivisionAnimated.gif]]

A divisor of any number of digits can be used. In this example, 1260257 is to be divided by 37. First the problem is set up as follows:

        &lt;u&gt;       &lt;/u&gt;
     37)1260257

Digits of the number 1260257 are taken until a number greater than or equal to 37 occurs. So 1 and 12 are less than 37, but 126 is greater. Next, the greatest multiple of 37 less than or equal to 126 is computed. So 3 &amp;times; 37 = 111 &lt; 126, but 4 &amp;times; 37 &gt; 126. The multiple 111 is written underneath the 126 and the 3 is written on the top where the solution will appear:

        &lt;u&gt;  3    &lt;/u&gt;
     37)1260257
        111

Note carefully which place-value column these digits are written into. The 3 in the quotient goes in the same column (ten-thousands place) as the 6 in the dividend 1260257, which is the same column as the last digit of 111.

The 111 is then subtracted from the line above, ignoring all digits to the right:

        &lt;u&gt;  3    &lt;/u&gt;
     37)1260257
        &lt;u&gt;111&lt;/u&gt;
         15

Now the digit from the next smaller place value of the dividend is copied down appended to the result 15:

        &lt;u&gt;  3    &lt;/u&gt;
     37)1260257
        &lt;u&gt;111&lt;/u&gt;
         150

The process repeats: the greatest multiple of 37 less than or equal to 150 is subtracted. This is 148 = 4 &amp;times; 37, so a 4 is added to the solution line. Then the result of the subtraction is extended by another digit taken from the dividend:

        &lt;u&gt;  34   &lt;/u&gt;
     37)1260257
        &lt;u&gt;111&lt;/u&gt;
         150
         &lt;u&gt;148&lt;/u&gt;
           22

The greatest multiple of 37 less than or equal to 22 is 0 &amp;times; 37 = 0. Subtracting 0 from 22 gives 22, we often don't write the subtraction step. Instead, we simply take another digit from the dividend:

        &lt;u&gt;  340  &lt;/u&gt;
     37)1260257
        &lt;u&gt;111&lt;/u&gt;
         150
         &lt;u&gt;148&lt;/u&gt;
           225

The process is repeated until 37 divides the last line exactly:

        &lt;u&gt;  34061&lt;/u&gt;
     37)1260257
        &lt;u&gt;111&lt;/u&gt;
         150
         &lt;u&gt;148&lt;/u&gt;
           225
           &lt;u&gt;222&lt;/u&gt;
             37

===Mixed mode long division===
For non-decimal currencies (such as the British [[£sd]] system before 1971) and measures (such as [[avoirdupois]]) '''mixed mode''' division must be used.  Consider dividing 50 miles 600 yards into 37 pieces:

           mi -     yd -   ft -   in
       &lt;u&gt;     1 -    634      1      9 r. 15"&lt;/u&gt;
     37)   50 -    600 -    0 -    0
           &lt;u&gt;37&lt;/u&gt;    &lt;u&gt;22880&lt;/u&gt;     &lt;u&gt;66&lt;/u&gt;    &lt;u&gt;348&lt;/u&gt;
        &lt;u&gt;   13&lt;/u&gt;    23480     66    348
        17600    &lt;u&gt;222&lt;/u&gt;       &lt;u&gt;37&lt;/u&gt;    &lt;u&gt;333&lt;/u&gt;
        &lt;u&gt; 5280&lt;/u&gt;     128      &lt;u&gt;29&lt;/u&gt;     15
        22880     &lt;u&gt;111&lt;/u&gt;     348     &lt;nowiki&gt;==&lt;/nowiki&gt;
        &lt;nowiki&gt;=====&lt;/nowiki&gt;      170    &lt;nowiki&gt;===&lt;/nowiki&gt;
                   &lt;u&gt;148&lt;/u&gt;
                    &lt;u&gt;22&lt;/u&gt;
                    66
                    &lt;nowiki&gt;==&lt;/nowiki&gt;

Each of the four columns is worked in turn.  Starting with the miles: 50/37 = 1 remainder 13.  No further division is
possible, so perform a long multiplication by 1,760 to convert miles to yards, the result is 22,880 yards.  Carry this to the top of the yards column and add it to the 600 yards in the dividend giving 23,480.  Long division of 23,480 / 37 now proceeds as normal yielding 634 with remainder 22.  The remainder is multiplied by 3 to get feet and carried up to the feet column.  Long division of the feet gives 1 remainder 29 which is then multiplied by twelve to get 348 inches.  Long division continues with the final remainder of 15 inches being shown on the result line.

===Non-decimal radix===
The same method and layout can be used for, e.g., [[Binary number|binary]], [[octal]] and [[hexadecimal]] numeral systems. For example, a hexadecimal address range of 0xf412df divided into 0x12 parts is:

        &lt;u&gt;  0d8f45&lt;/u&gt; r. 5
     12 ) f412df
          &lt;u&gt;ea&lt;/u&gt;
           a1
           &lt;u&gt;90&lt;/u&gt;
           112
           &lt;u&gt;10e&lt;/u&gt;
             4d
             &lt;u&gt;48&lt;/u&gt;
              5f
              &lt;u&gt;5a&lt;/u&gt;
               5
Calculation within the binary number system is more immediate, because each digit in the course can only be 1 or 0:

         &lt;u&gt;      1110&lt;/u&gt; r. 11
     1101) 10111001
            &lt;u&gt;1101&lt;/u&gt;
            10100
             &lt;u&gt;1101&lt;/u&gt;
              1110
              &lt;u&gt;1101&lt;/u&gt;
                 11

===Interpretation of decimal results===

When the quotient is not an integer and the division process is extended beyond the decimal point, one of two things can happen. (1) The process can terminate, which means that a remainder of 0 is reached; or (2) a remainder could be reached that is identical to a previous remainder that occurred after the decimal points were written. In the latter case, continuing the process would be pointless, because from that point onward the same sequence of digits would appear in the quotient over and over. So a bar is drawn over the repeating sequence to indicate that it repeats forever.

==Notation in non-English-speaking countries==
China, Japan, Korea use the same notation as English-speaking nations including India. Elsewhere, the same general principles are used, but the figures are often arranged differently.

===Latin America===
In [[Latin America]] (except [[Argentina]], [[Bolivia]], [[Mexico]], [[Colombia]], [[Paraguay]], [[Venezuela]], [[Uruguay]] and [[Brazil]]), the calculation is almost exactly the same, but is written down differently as shown below with the same two examples used above. Usually the quotient is written under a bar drawn under the divisor. A long vertical line is sometimes drawn to the right of the calculations.

      500 ÷ 4 =  &lt;span style="color: red;"&gt;1&lt;/span&gt;&lt;span style="color: green;"&gt;2&lt;/span&gt;&lt;span style="color: blue;"&gt;5&lt;/span&gt;&lt;/u&gt;   (Explanations) 
      &lt;u&gt;4&lt;/u&gt;                ( 4 &amp;times;  &lt;span style="color: red;"&gt;1&lt;/span&gt; =  4)
      &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;0               ( 5 -  4 =  &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;)
       &lt;u&gt;8&lt;/u&gt;               ( 4 &amp;times;  &lt;span style="color: green;"&gt;2&lt;/span&gt; =  8)
       &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;0              (10 -  8 =  &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;)
       &lt;u&gt;20&lt;/u&gt;              ( 4 &amp;times;  &lt;span style="color: blue;"&gt;5&lt;/span&gt; = 20)
        0              (20 - 20 =  0)

and

      127 ÷ 4 = 31.75
      &lt;u&gt;124&lt;/u&gt;                             
        30      (a 0 is added in order to make 3 divisible by 4; the 0 is accounted for by adding a decimal point in the quotient)
        &lt;u&gt;28&lt;/u&gt;      (7 &amp;times; 4 = 28)
         20     (an additional zero is added)
         &lt;u&gt;20&lt;/u&gt;     (5 &amp;times; 4 = 20)
           0
In [[Mexico]], the US notation is used, except that only the result of the subtraction is annotated and the calculation is done mentally, as shown below:

     &lt;u&gt; &lt;span style="color: red;"&gt;1&lt;/span&gt;&lt;span style="color: green;"&gt;2&lt;/span&gt;&lt;span style="color: blue;"&gt;5&lt;/span&gt;&lt;/u&gt;     (Explanations)
    4)500
      &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;0      ( 5 -  4 = &lt;span style="color: darkorange;"&gt;1&lt;/span&gt;)
       &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;0     (10 -  8 = &lt;span style="color: darkcyan;"&gt;2&lt;/span&gt;)
        0     (20 - 20 = 0)

In [[Bolivia]], [[Brazil]], [[Paraguay]], [[Venezuela]], [[Uruguay]], [[Quebec]], [[Colombia]], and [[Peru]], the European notation (see below) is used, except that the quotient is not separated by a vertical line, as shown below:

     127|&lt;u&gt;4    &lt;/u&gt;
    −&lt;u&gt;124&lt;/u&gt; 31,75
       30
      −&lt;u&gt;28&lt;/u&gt;
        20
       −&lt;u&gt;20&lt;/u&gt;
         0

Same procedure applies in [[Mexico]] and [[Argentina]], only the result of the subtraction is annotated and the calculation is done mentally.

===Eurasia===
In Spain, Italy, France, Portugal, Lithuania, Romania, Turkey, Greece, Belgium, Belarus, Ukraine, and Russia, the divisor is to the right of the dividend, and separated by a vertical bar. The division also occurs in the column, but the quotient (result) is written below the divider, and separated by the horizontal line. The same method is used in Iran and Mongolia.

     127|&lt;u&gt;4    &lt;/u&gt;
    −&lt;u&gt;124&lt;/u&gt;|31,75
       30
      −&lt;u&gt;28&lt;/u&gt;
        20
       −&lt;u&gt;20&lt;/u&gt;
         0

In Cyprus, as well as in France, a long vertical bar separates the dividend and subsequent subtractions from the quotient and divisor, as in the [[:fr:Poser une division#Méthode classique|example]] below of 6359 divided by 17, which is 374 with a remainder of 1.

{|border ="0" cellspacing = "0" 
|- style="text-align:right"
|6||3||5|| 9||style="text-align:left;border-left:thin solid black"|17
|- style="text-align:right"
| − 5 ||1|| ||  ||style="text-align:left;border-top:thin solid black;border-left:thin solid black"|374
|- style="text-align:right"
|style="border-top:thin solid black"| 1 ||style="border-top:thin solid black"| 2||5 ||  ||style="text-align:left;border-left:thin solid black"|&amp;nbsp;
|- style="text-align:right"
| − 1 ||1 ||9 || ||style="text-align:left;border-left:thin solid black"|&amp;nbsp;
|- style="text-align:right"
|style="border-top:thin solid black"|&amp;nbsp;  ||style="border-top:thin solid black"|&amp;nbsp;  ||style="border-top:thin solid black"| 6 || 9||style="text-align:left;border-left:thin solid black"|&amp;nbsp;
|- style="text-align:right"
|  ||  −||6|| 8||style="text-align:left;border-left:thin solid black"|&amp;nbsp;
|- style="text-align:right"
|  ||  ||style="border-top:thin solid black"| &amp;nbsp; ||style="border-top:thin solid black"|1 ||style="text-align:left;border-left:thin solid black"|&amp;nbsp;
|}

Decimal numbers are not divided directly, the dividend and divisor are multiplied by a power of ten so that the division involves two whole numbers. Therefore, if one were dividing 12,7 by 0,4 (commas being used instead of decimal points), the dividend and divisor would first be changed to 127 and 4, and then the division would proceed as above.

In [[Austria]], [[Germany]] and [[Switzerland]], the notational form of a normal equation is used. &lt;dividend&gt; : &lt;divisor&gt; = &lt;quotient&gt;, with the colon ":" denoting a binary infix symbol for the division operator (analogous to "/" or "÷"). In these regions the decimal separator is written as a comma. (cf. first section of Latin American countries above, where it's done virtually the same way):

     127 : 4 = 31,75
    −&lt;u&gt;12&lt;/u&gt;
      07
      −&lt;u&gt;4&lt;/u&gt;
       30
      −&lt;u&gt;28&lt;/u&gt;
        20
       −&lt;u&gt;20&lt;/u&gt;
         0

The same notation is adopted in [[Denmark]], [[Norway]], [[Bulgaria]], [[Republic of Macedonia|Macedonia]], [[Poland]], [[Croatia]], [[Slovenia]], [[Hungary]], [[Czech Republic]], [[Slovakia]], [[Vietnam]] and in [[Serbia]].

In the [[Netherlands]], the following notation is used:

    12 / 135 \ 11,25
         &lt;u&gt;12&lt;/u&gt;
          15
          &lt;u&gt;12&lt;/u&gt;
           30
           &lt;u&gt;24&lt;/u&gt;
            60
            &lt;u&gt;60&lt;/u&gt;
             0

==Generalizations==

=== Rational numbers ===
Long division of integers can easily be extended to include non-integer dividends, as long as they are [[rational number|rational]]. This is because every rational number has a [[recurring decimal]] expansion. The procedure can also be extended to include divisors which have a finite or terminating [[decimal]] expansion (i.e. [[decimal fraction]]s). In this case the procedure involves multiplying the divisor and dividend by the appropriate power of ten so that the new divisor is an integer&amp;nbsp;– taking advantage of the fact that ''a''&amp;nbsp;÷&amp;nbsp;''b'' = (''ca'')&amp;nbsp;÷&amp;nbsp;(''cb'')&amp;nbsp;–  and then proceeding as above.

===Polynomials===
A generalised version of this method called [[polynomial long division]] is also used for dividing [[polynomial]]s (sometimes using a shorthand version called [[synthetic division]]).

==See also==
* [[Algorism]]
* [[Arbitrary-precision arithmetic]]
* [[Egyptian multiplication and division]]
* [[Elementary arithmetic]]
* [[Fourier division]]
* [[Polynomial long division]]
* [[Shifting nth root algorithm]] &amp;ndash; for finding [[square root]] or any [[nth root]] of a number

== References ==
{{reflist}}

==External links==
* [http://www.mathpath.org/Algor/algor.long.div.htm Long Division Algorithm]
* [http://www.alexpetty.com/2011/05/20/long-division-and-euclids-lemma] Long Division and Euclid’s Lemma

[[Category:Division (mathematics)]]
[[Category:Algorithms]]

[[ja:筆算#筆算による除算]]</text>
      <sha1>tjmfb8xn7saj7txabdafihs15s3z8kv</sha1>
    </revision>
  </page>
  <page>
    <title>Metric prefix</title>
    <ns>0</ns>
    <id>26874</id>
    <revision>
      <id>866080808</id>
      <parentid>864732913</parentid>
      <timestamp>2018-10-28T03:34:25Z</timestamp>
      <contributor>
        <username>Shaded0</username>
        <id>5264861</id>
      </contributor>
      <minor/>
      <comment>clean up and formatting, [[WP:AWB/T|typo(s) fixed]]: BIPM’s → BIPM's</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23249">{{Use dmy dates|date=September 2016}}
{{common metric prefixes}}
A '''metric prefix''' is a [[unit prefix]] that precedes a basic unit of measure to indicate a [[multiple (mathematics)|multiple]] or [[fraction (mathematics)|fraction]] of the unit. While all metric prefixes in common use today are [[decimal|decadic]], historically there have been a number of [[binary number|binary]] metric prefixes as well.&lt;ref name="fr"/&gt; Each prefix has a unique symbol that is prepended to the unit symbol. The prefix ''[[kilo-]]'', for example, may be added to ''gram'' to indicate ''multiplication'' by one thousand: one kilogram is equal to one thousand grams. The prefix ''[[milli-]]'', likewise, may be added to ''metre'' to indicate ''division'' by one thousand; one millimetre is equal to one thousandth of a metre.

Decimal multiplicative prefixes have been a feature of all forms of the [[metric system]], with six dating back to the system's introduction in the 1790s. Metric prefixes have even been prepended to non-metric units. The '''SI prefixes''' are standardized for use in the [[International System of Units]] (SI) by the [[International Bureau of Weights and Measures]] (BIPM) in resolutions dating from 1960 to 1991.&lt;ref&gt;{{cite web |url=http://www.bipm.org/en/si/prefixes.html |title=Four Resolutions |publisher=Bipm.org |access-date=1 March 2012}}&lt;/ref&gt; Since 2009, they have formed part of the [[International System of Quantities]].

==List of SI prefixes==
The BIPM specifies twenty prefixes for the International System of Units (SI).

{{SI prefixes (infobox)}}

Each prefix name has a symbol that is used in combination with the symbols for units of measure. For example, the symbol for ''kilo-'' is 'k', and is used to produce 'km', 'kg', and 'kW', which are the SI symbols for kilometre, kilogram, and kilowatt, respectively. Where Greek letters are unavailable, the symbol for micro 'µ' is commonly replaced by 'u'.

Prefixes corresponding to an integer power of one thousand are generally preferred. Hence ''100&amp;nbsp;m'' is preferred over ''1&amp;nbsp;hm'' (hectometre) or ''10&amp;nbsp;dam'' (decametres). The prefixes hecto, deca, deci, and centi are commonly used for everyday purposes, and the centimetre (cm) is especially common. However, some modern building codes require that the millimetre be used in preference to the centimetre, because "use of centimetres leads to extensive usage of decimal points and confusion".&lt;ref&gt;{{cite web|url=https://web.archive.org/web/20111215115519/http://wbdg.org/ccb/GSAMAN/mdg.pdf|title=Wayback Machine|author=|date=15 December 2011|website=archive.org|accessdate=21 April 2018}}&lt;/ref&gt;

Prefixes may not be used in combination. This also applies to [[mass]], for which the [[SI base unit]] (kilogram) already contains a prefix. For example, milligram (mg) is used instead of microkilogram (µkg).

In the arithmetic of measurements having units, the units are treated as multiplicative factors to values. If they have prefixes, all but one of the prefixes must be expanded to their numeric multiplier, except when combining values with identical units. Hence,
* {{val|5|u=mV}} × {{val|5|u=mA}} = {{val|5|e=-3|u=V}} × {{val|5|e=-3|u=A}} = {{val|25|e=-6|u=V⋅A}} = {{val|25|u=µW}}
* {{val|5.00|u=mV}} + {{val|10|u=µV}} = {{val|5.00|u=mV}} + {{val|0.01|u=mV}} = {{val|5.01|u=mV}}

When units occur in [[exponentiation]], for example, in square and cubic forms, the multiplication prefix must be considered part of the unit, and thus included in the exponentiation.
* 1&amp;nbsp;km&lt;sup&gt;2&lt;/sup&gt; means one [[square kilometre]], or the [[area]] of a [[Square (geometry)|square]] of {{val|1000|u=m}} by {{val|1000|u=m}} and not {{val|1000}} [[square metre]]s.
* 2&amp;nbsp;Mm&lt;sup&gt;3&lt;/sup&gt; means two cubic [[megametre]]s, or the [[volume]] of two [[cube]]s of {{val|1000000|u=m}} by {{val|1000000|u=m}} by {{val|1000000|u=m}} or {{val|2|e=18|u=m3}}, and not {{val|2000000}} [[cubic metre]]s ({{val|2|e=6|u=m3}}).

;Examples
* {{val|5|u=cm}} =&amp;nbsp;{{val|5|e=-2|u=m}} =&amp;nbsp;{{nowrap|5 × 0.01 m}} =&amp;nbsp;0.05&amp;nbsp;m
* {{val|9|u=km2}} =&amp;nbsp;{{nowrap|9 × (10&lt;sup&gt;3&lt;/sup&gt; m)&lt;sup&gt;2&lt;/sup&gt;}} =&amp;nbsp;{{nowrap|9 × (10&lt;sup&gt;3&lt;/sup&gt;)&lt;sup&gt;2&lt;/sup&gt; × m&lt;sup&gt;2&lt;/sup&gt;}} =&amp;nbsp;{{val|9|e=6|u=m2}} =&amp;nbsp;{{nowrap|9 × {{val|1000000|u=m2}}}} =&amp;nbsp;{{val|9000000|u=m2}}
* 3&amp;nbsp;MW =&amp;nbsp;{{val|3|e=6|u=W}} =&amp;nbsp;3&amp;nbsp;×&amp;nbsp;{{val|1000000|u=W}} = {{val|3000000|u=W}}

== Application to units of measurement ==
The use of prefixes can be traced back to the introduction of the metric system in the 1790s, long before the 1960 introduction of the SI. The prefixes, including those introduced after 1960, are used with any metric unit, whether officially included in the SI or not (e.g., millidynes and milligauss). Metric prefixes may also be used with non-metric units.

The choice of prefixes with a given unit is usually dictated by convenience of use. Unit prefixes for amounts that are much larger or smaller than those actually encountered are seldom used.

=== Metric units ===

==== Mass ====

In use, the [[kilogram]], [[gram]], [[milligram]], microgram, and smaller are fairly common. However, megagram (and gigagram, teragram, etc.) are rarely used; [[tonne]]s (and kilotonnes, megatonnes, etc. – although these units generally are not used as a measure of [[mass]] ''per se'', but rather [[TNT equivalent|TNT energy equivalent of a mass]]) or [[scientific notation]] are used instead. Megagram is occasionally used to disambiguate the metric tonne from the various non-metric tons. An exception is pollution emission rates, which are typically on the order of Tg/yr. Sometimes, only one element or compound is denoted for an emission, such as Tg&amp;nbsp;C/yr or Tg&amp;nbsp;N/yr.

Alone among SI units, the base unit of mass, the kilogram, already includes a prefix. The prefixes consequently do not indicate corresponding multipliers of the base unit in the case of mass; for example, a megagram is {{val|1|e=3}}&amp;nbsp;kg, whereas ''mega-'' indicates a multiplier of {{val|e=6}}.

====Volume====
The litre (equal to a cubic decimetre), millilitre (equal to a cubic centimetre), microlitre, and smaller are common. In Europe, the centilitre is often used for packaged products (such as wine) and the decilitre less frequently. (The latter two items include prefixes corresponding to an [[exponent]] that is not divisible by three.)

Larger volumes are usually denoted in kilolitres, megalitres or gigalitres, or else in cubic metres (1 cubic metre = 1 kilolitre) or cubic kilometres (1 cubic kilometre = 1 teralitre). For scientific purposes, the cubic metre is usually used.

====Length====
The kilometre, metre, centimetre, millimetre, and smaller are common. (However, the decimetre is rarely used.) The micrometre is often referred to by the non-SI term ''[[Micrometre#SI standardization|micron]]''. In some fields, such as [[chemistry]], the [[ångström]] (equal to 0.1&amp;nbsp;nm) historically competed with the nanometre. The [[femtometre]], used mainly in particle physics, is sometimes called a [[fermi (unit)|fermi]]. For large scales, megametre, gigametre, and larger are rarely used. Instead, non-metric units are used, such as [[astronomical unit]]s, [[light year]]s, and [[parsec]]s; the astronomical unit is mentioned in the SI standards as an accepted non-SI unit.

====Time and angles====
The second, millisecond, microsecond, and shorter are common. The kilosecond and megasecond also have some use, though for these and longer times one usually uses either scientific notation or minutes, hours, and so on.

Official policies about the use of these prefixes vary slightly between the Bureau International des Poids et Mesures (BIPM) and the American [[National Institute of Standards and Technology]] (NIST); and some of the policies of both bodies are at variance with everyday practice. For instance, the NIST advises that "to avoid confusion, prefix symbols (and prefix names) are not used with the time-related unit symbols (names) min (minute), h (hour), d (day); nor with the angle-related symbols (names) °&amp;nbsp;(degree), ′&amp;nbsp;(minute), and ″&amp;nbsp;(second)".&lt;ref name="Special Publication 811"&gt;{{Citation|url=http://physics.nist.gov/Pubs/SP811/sec06.html|title=Special Publication 811|edition=2008|last1=Thompson|first1=Ambler|last2=Taylor|first2=Barry N.|date=March 2008|work=NIST|access-date=2018-06-21|language=en}}&lt;/ref&gt;

The BIPM's position on the use of SI prefixes with units of time larger than the second is the same as that of the NIST, but their position with regard to angles differs: they state "However astronomers use milliarcsecond, which they denote mas, and microarcsecond, µas, which they use as units for measuring very small angles."&lt;ref&gt;{{cite web |url=http://www.bipm.org/en/publications/si-brochure/chapter3.html |title=SI Brochure: The International System of Units (SI) |publisher= International Bureau of Weights and Measures |access-date=5 March 2017}}&lt;/ref&gt; The SI unit of angle is the [[radian]], but, as mentioned above, degrees, minutes and seconds see some scientific use.

====Temperature====
Official policy also varies from common practice for the degree Celsius (°C). NIST states:&lt;ref name="Special Publication 811"/&gt; "Prefix symbols may be used with the unit symbol °C and prefix names may be used with the unit name 'degree Celsius'. For example, 12&amp;nbsp;m°C (12 millidegrees Celsius) is acceptable." In practice, it is more common for prefixes to be used with the [[kelvin]] when it is desirable to denote extremely large or small absolute temperatures or temperature differences. Thus, temperatures of star interiors may be given in units of MK (megakelvins), and molecular cooling may be described in mK (millikelvins).

====Energy====
In use the [[joule]] and kilojoule are common, with larger multiples seen in limited contexts. In addition, the [[kilowatt hour]], a composite unit formed from the kilowatt and hour, is often used for electrical energy; other multiples can be formed by modifying the prefix of watt (e.g. terawatt hour).

There exist a number of definitions for the non-SI unit, the [[calorie]]. There are gram calories and kilogram calories. One kilogram calorie, which equals one thousand gram calories, often appears capitalized and without a prefix (i.e. 'Cal') when referring to "[[Calorie|dietary calories]]" in food.&lt;ref&gt;{{cite web|url=http://www.unm.edu/~lkravitz/Article%20folder/remarkablecalorie.html|title=Remarkable Calorie|last=Conn |first=Carole |author2=Len Kravitz |publisher=University of New Mexico|accessdate=22 May 2017}}&lt;/ref&gt; It is common to apply metric prefixes to the gram calorie, but not to the kilogram calorie: thus, 1&amp;nbsp;kcal = 1000&amp;nbsp;cal = 1&amp;nbsp;Cal.

===Non-metric units===
Metric prefixes are widely used outside the system of [[metric system|metric units]]. Common examples include the [[megabyte]] and the [[decibel]]. Metric prefixes rarely appear with [[imperial units|imperial]] or [[United States customary units|US]] units except in some special cases (e.g., microinch, kilofoot, [[kilopound]] or 'kip'). They are also used with other specialized units used in particular fields (e.g., [[megaelectronvolt]], [[gigaparsec]], [[millibarn]]). They are also occasionally used with currency units (e.g., gigadollar), mainly by people who are familiar with the prefixes from scientific usage. In geology and paleontology, the [[Year#Symbols|year]], with symbol a (from the Latin ''annus''), is commonly used with metric prefixes: [[Kiloannus|ka]], Ma, and Ga.

==Presentation==

===Pronunciation===
When an SI prefix is affixed to a root word, the prefix carries the [[stress (linguistics)|stress]], while the root drops its stress but retains a full vowel in the syllable that is stressed when the root word stands alone.{{Citation needed|date=November 2013}} For example, ''[[kilobyte]]'' is {{IPAc-en|ˈ|k|ᵻ|l|ɒ|b|aɪ|t}}, with stress on the first syllable. However, words in common use outside the scientific community may follow idiosyncratic stress rules. In English speaking countries, ''kilometre'' is often pronounced {{IPAc-en|k|ᵻ|ˈ|l|ɒ|m|ᵻ|t|ər}}, with [[reduced vowel]]s on both syllables of ''metre''.

The prefix ''giga'' is usually pronounced in English as {{IPAc-en|ˈ|ɡ|ɪ|ɡ|ə}}, with hard 〈g〉 as in "get", but sometimes {{IPAc-en|ˈ|dʒ|ɪ|ɡ|ə}}, with soft 〈g〉 as in "gin".

===Typesetting===
The [[LaTeX]] typesetting system features an ''SIunitx'' package in which the units of measurement are spelled out, for example, &lt;code&gt;\SI{3}{\tera\hertz}&lt;/code&gt; formats as "3 THz".

==Non-standard prefixes==
[[File:Myriameterstein36RüdesheimRhein.JPG|250px|thumb|Distance marker on the [[Rhine]]: 36 (XXXVI) myriametres from [[Basel]]. The stated distance is 360 km; the [[decimal mark]] in [[Germany]] is a comma.]]

==={{anchor|myria|myrio|hebdo|micri|double|demi|Obsolete}}Obsolete metric prefixes===
Some of the prefixes formerly used in the metric system have fallen into disuse and were not adopted into the SI.&lt;ref&gt;{{cite web|url=http://lamar.colostate.edu/~hillger/laws/metric-act-bill.html |title=H.R. 596, An Act to authorize the use of the metric system of weights and measures |author=29th Congress of the United States, Session 1 |date=13 May 1866 |deadurl=yes |archiveurl=https://web.archive.org/web/20150705015307/http://lamar.colostate.edu/~hillger/laws/metric-act-bill.html |archivedate=5 July 2015 |df= }}&lt;/ref&gt;&lt;ref name="Brewster_1830"&gt;{{cite book |title=The Edinburgh Encyclopædia |author-first=David |author-last=Brewster |volume=12 |date=1830 |location=Edinburgh, UK |publisher=William Blackwood, John Waugh, John Murray, Baldwin &amp; Cradock, J. M. Richardson |page=494 |url=https://books.google.com/books?id=0bIkTUZAbxcC |access-date=9 October 2015}}&lt;/ref&gt;&lt;ref name="Brewster_1832"&gt;{{cite book |title=The Edinburgh Encyclopaedia |author-first=David |author-last=Brewster |volume=12 |edition=1st American |date=1832 |publisher=Joseph and Edward Parker&lt;!-- |printer=William Brows --&gt; |url=https://books.google.com/books?id=17RGAQAAIAAJ&amp;pg=PA572&amp;lpg=PA572 |access-date=9 October 2015}}&lt;/ref&gt; The decimal prefix ''[[myria-]]'' (sometimes also written as ''[[myrio-]]'') (ten thousand) as well as the [[binary prefix]]es ''double-'' and ''demi-'', denoting a factor of 2 and {{sfrac|2}} ([[one half]]), respectively, were parts of the original metric system adopted by France in 1795.&lt;ref name="fr"&gt;{{cite web |title=La Loi Du 18 Germinal An 3 - Décision de tracer le mètre, unité fondamentale, sur une règle de platine. Nomenclature des "mesures républicaines". Reprise de la triangulation. |url=http://histoire.du.metre.free.fr/fr/Pages/Sommaire/06.htm |language=French |publisher=histoire.du.metre.free.fr |access-date=12 October 2015}}&lt;/ref&gt; These were not retained when the SI prefixes were internationally adopted by the 11th [[Conférence générale des poids et mesures|CGPM conference]] in 1960.

Other metric prefixes used historically include [[hebdo-]] (10&lt;sup&gt;7&lt;/sup&gt;) and [[micri-]] (10&lt;sup&gt;−14&lt;/sup&gt;).

==={{anchor|dimi|Double prefix}}Double prefixes===
Double prefixes have been used in the past, such as ''micromillimetres'' or "millimicrons" (now [[nanometre]]s), ''micromicrofarads'' (now [[picofarad]]s), ''kilomegatons'' (now [[gigaton]]s), ''hectokilometres'' (now 100 [[kilometre]]s) and the derived adjective ''hectokilometric'' (typically used for qualifying the fuel consumption measures).&lt;ref name="Rowlett_2008_Millimicro"&gt;{{cite dictionary |title=millimicro- |encyclopedia=How Many? A Dictionary of Units of Measurement |author-first=Russ |author-last=Rowlett |publisher=[[University of North Carolina at Chapel Hill]] |date=2008 |orig-year=2000 |access-date=29 August 2016 |url=http://www.unc.edu/~rowlett/units/dictM.html |dead-url=no |archive-url=https://web.archive.org/web/20160829225351/https://www.unc.edu/~rowlett/units/dictM.html |archive-date=29 August 2016}}&lt;/ref&gt; These were disallowed with the introduction of the SI.

Other obsolete double prefixes included "decimilli-" (10&lt;sup&gt;−4&lt;/sup&gt;), which was contracted to "dimi-"&lt;ref&gt;{{cite book |title=The metric system: a critical study of its principles and practice |author-first=Maurice |author-last=Danloux-Dumesnils |publisher=The Athlone Press |date=1969 |page=34 |url=https://books.google.com/books/about/The_metric_system.html?id=ElHAAAAAIAAJ |access-date=9 October 2015}} (a translation of the French original ''Esprit et bon usage du systeme metrique'', 1965&lt;!-- or ''Étude critique du système métrique'', 1962--&gt;)&lt;/ref&gt; and standardized in France up to 1961.

==="Hella" prefix proposal===
In 2010, [[UC Davis]] student Austin Sendek started a petition to designate "[[hella]]" as the SI prefix for one octillion (Short scale; Long scale: Quadrilliard; 10&lt;sup&gt;27&lt;/sup&gt;).&lt;ref&gt;{{cite web |url=http://articles.latimes.com/2010/jul/06/local/la-me-hella-20100706 |title=Physics major has a name for a really big number |author-first=Steve |author-last=Chawkins |publisher=Los Angeles Times |date=6 July 2010}}&lt;/ref&gt; The petition gathered over 60,000 supporters by circulating through [[Facebook]] and receiving a significant amount of media coverage.&lt;ref&gt;{{cite web |url=https://www.facebook.com/pages/The-Official-Petition-to-Establish-Hella-as-the-SI-Prefix-for-1027/277479937276 |title=The Official Petition to Establish "Hella" as the SI Prefix for 10^27}}&lt;/ref&gt; Although the Consultative Committee for Units considered the proposal, it was rejected.{{why|date=May 2018}} However, ''hella'' has been adopted by certain websites, such as [[Google]] Calculator&lt;ref&gt;{{cite web |url=http://blog.sfgate.com/techchron/2010/05/24/google-gets-behind-hella-campaign/ |title=Google gets behind "hella" campaign |author-first=Ryan |author-last=Kim |publisher=SFGate}}&lt;/ref&gt; and [[Wolfram Alpha]].&lt;ref&gt;{{cite web |url=http://makehellaofficial.blogspot.com/2011/05/first-google-now-wolfram-alpha.html |title=First goes Google, now goes Wolfram Alpha |author-first=Austin |author-last=Sendek}}&lt;/ref&gt;

===X, W and V===
Brian C. Lacki&lt;ref&gt;Lacki, B. C. (2015). SETI at Planck Energy: When Particle Physicists Become Cosmic Engineers. arXiv preprint arXiv:1503.01509 [https://arxiv.org/pdf/1503.01509.pdf].&lt;/ref&gt; follows Z and Y with the adopted prefixes X, W and V to mean {{val|e=27}}, {{val|e=30}} and {{val|e=33}} respectively, thus continuing the inverse alphabetical order.

==Similar symbols and abbreviations==
In written English, the symbol ''K'' is often used informally to indicate a multiple of thousand in many contexts. For example, one may talk of a ''40K salary'' ({{gaps|40|000}}), or call the [[Year 2000 problem]] the ''Y2K problem''. In these cases, an uppercase K is often used with an implied unit (although it could then be confused with the symbol for the kelvin temperature unit if the context is unclear). This informal postfix is read or spoken as "thousand" or "grand", or just "k", but never "kilo" (despite that being the origin of the letter).

The financial and general news media mostly use m/M, b/B and t/T as abbreviations for million, billion (10&lt;sup&gt;9&lt;/sup&gt;) and trillion (10&lt;sup&gt;12&lt;/sup&gt;), respectively, for large quantities, typically currency&lt;ref&gt;{{cite news |author=The Associated Press |url=http://www.cbc.ca/news/world/story/2012/02/13/obama-budget-congress.html |title=Obama unveils $3.8T budget proposal |publisher=Cbc.ca |date=13 February 2012 |access-date=1 March 2012}}&lt;/ref&gt; and population.&lt;ref&gt;{{cite web |url=http://www.multichannel.com/article/128853-More_than_65M_Flock_to_Discovery_s_Planet_Earth.php |title=More than 65M Flock to Discovery's Planet Earth |publisher=Multichannel.com |access-date=1 March 2012}}&lt;/ref&gt;

The [[Medicine|medical]] and [[Automotive industry|automotive]] fields in the United States use the abbreviations "cc" or "ccm" for cubic centimetres. 1 [[cubic centimetre]] is equivalent to 1 [[millilitre]].

For nearly a century, the [[electrical]] [[construction industry]] used the abbreviation "MCM" to designate a "thousand [[circular mil]]s" in specifying thicknesses of large [[Electric power transmission|electrical cables]]. Since the mid-1990s, "[[kcmil]]" has been adopted as the "official" designation of a thousand circular mils, but the designation "MCM" still remains in wide use. A similar system is used in natural gas sales in the United States: m (or M) for thousands and mm (or MM) for millions of [[British thermal unit]]s or [[therm]]s, and in the oil industry,&lt;ref&gt;{{cite web |url=http://www.pesa.com.au/publications/pesa_news/june_july_07/pesanews_8830.html |title=Purcell, P (2007). ''Disambiguating M''. PESA News 88 |publisher=Pesa.com.au |access-date=1 March 2012}}&lt;/ref&gt; where 'MMbbl' is the symbol for 'millions of barrels'. This usage of the capital letter M for 'thousand' is from [[Roman numerals]], in which M means 1,000.&lt;ref&gt;{{cite web |url=https://www.reference.com/home-garden/difference-between-mcm-kcmil-32b016f3e6b497b6 |title=What is the difference between MCM and kcmil? |publisher=Reference.com |access-date=5 September 2016}}&lt;/ref&gt;

===Binary prefixes===
In some fields of information technology, it has been common to designate non-decimal multiples based on powers of 1024, rather than 1000, for some SI prefixes (kilo, mega, giga), contrary to the definitions in the [[International System of Units]] (SI). This practice was once sanctioned by some industry associations, including [[JEDEC]]. The [[International Electrotechnical Commission]] (IEC) standardized the system of [[binary prefix]]es (kibi, mebi, gibi, etc.) for this purpose.&lt;ref&gt;{{cite web |author=International Electrotechnical Commission |title=IEC 60050 - International Electrotechnical Vocabulary - Details for IEV number 112-01-27 |url=http://www.electropedia.org/iev/iev.nsf/display?openform&amp;ievref=112-01-27 |date=January 2010 |access-date=19 June 2011}}&lt;/ref&gt;&lt;ref group=Note&gt;The names and symbols of the [[binary prefix]]es proposed by the IEC include
* [[kibi (binary prefix)|kibi]] (Ki) = 2&lt;sup&gt;10&lt;/sup&gt; = {{val|1024}}
* [[mebi (binary prefix)|mebi]] (Mi) = 2&lt;sup&gt;20&lt;/sup&gt; = {{val|1024}}&lt;sup&gt;2&lt;/sup&gt; = {{val|1048576}}
* [[gibi (binary prefix)|gibi]] (Gi) = 2&lt;sup&gt;30&lt;/sup&gt; = {{val|1024}}&lt;sup&gt;3&lt;/sup&gt; = {{val|1073741824}}
etc.&lt;/ref&gt;

==See also==
{{cmn|colwidth=30em|
* [[Engineering notation]]
* [[Indian numbering system]]
* [[International vocabulary of metrology]]
* [[ISO/IEC 80000]]
* [[List of numbers in various languages]] (for comparison/etymology)
* [[Names of large numbers]]
* [[Names of small numbers]]
* [[Numeral (linguistics)|Number names]]
* [[Numeral prefix]]
* [[Order of magnitude]]
* [[RKM code]]
* [[SI base unit]]
* [[UCUM]]
}}

==Notes==
{{Reflist|group=Note}}

==References==
{{FOLDOC}}
{{Reflist}}

==External links==
* [http://www.bipm.fr/en/home/ Bureau International des Poids et Mesures] (BIPM)
* [http://www.bipm.fr/en/si/prefixes.html SI prefixes at BIPM]
* [http://physics.nist.gov/cuu/Units/prefixes.html US NIST ''Definitions of the SI units: The twenty SI prefixes'']
* [http://physics.nist.gov/cuu/Units/binary.html US NIST ''Definitions of the SI units: The binary prefixes'']

{{SI units}}
{{Orders of magnitude}}
{{Portal bar|Physics}}

[[Category:Metric prefixes| ]]
[[Category:Numeral systems]]</text>
      <sha1>o0skhpr8pyog9q7b2tya6tqlqitjvhq</sha1>
    </revision>
  </page>
  <page>
    <title>Multidimensional network</title>
    <ns>0</ns>
    <id>44342518</id>
    <revision>
      <id>868858564</id>
      <parentid>866929544</parentid>
      <timestamp>2018-11-14T22:19:34Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="63817">{{Network Science}}
'''Multidimensional networks''', a special type of ''multilayer network'', are networks with multiple kinds of relations.&lt;ref name="Coscia"&gt;{{Cite journal|last1=Coscia|first1=Michele|title="You Know Because I Know": A Multidimensional Network Approach to Human Resources Problem|journal=Advances in Social Network Analysis and Mining (ASONAM)|volume=2013|pages=434|last2=Rossetti|first2=Giulio|last3=Pennacchioli|first3=Diego|last4=Ceccarelli|first4=Damiano|last5=Giannotti|first5=Fosca|year=2013|doi=10.1145/2492517.2492537|arxiv=1305.7146|isbn=9781450322409}}&lt;/ref&gt;&lt;ref name="DeDomenico2013" /&gt;&lt;ref name="Structural measures for multiplex networks"&gt;{{Cite journal
| year = 2014
| last1= Battiston
| first1 = F.
| title = Structural measures for multiplex networks
| journal = Physical Review E
| volume = 89
| issue= 3
| pages = 032804
| last2 = Nicosia
| first2 = V.
| last3 = Latora
| first3 = V.
| doi=10.1103/PhysRevE.89.032804
| url=http://journals.aps.org/pre/pdf/10.1103/PhysRevE.89.032804
| bibcode= 2014PhRvE..89c2804B
| arxiv= 1308.3182
}}&lt;/ref&gt;&lt;ref name="Multilayer Networks"&gt;{{Cite journal | doi = 10.1093/comnet/cnu016| title = Multilayer networks| journal = Journal of Complex Networks| volume = 2| issue = 3| pages = 203–271| year = 2014| last1 = Kivela | first1 = M.| last2 = Arenas | first2 = A.| last3 = Barthelemy | first3 = M.| last4 = Gleeson | first4 = J. P.| last5 = Moreno | first5 = Y.| last6 = Porter | first6 = M. A.|url=http://comnet.oxfordjournals.org/content/2/3/203.full}}&lt;/ref&gt;&lt;ref name="The structure and dynamics of multilayer networks"&gt;{{Cite journal|last1= Boccaletti|first1= S.|title= The structure and dynamics of multilayer networks|journal= Physics Reports|volume= 544|issue= 1|pages= 1–122|last2=  Bianconi|first2= G.|last3=  Criado|first3= R.|last4=  del Genio|first4= C. I.|last5=  Gómez-Gardeñes|first5= J.|last6=  Romance|first6= M.|last7=  Sendiña-Nadal|first7= I.|last8=  Wang|first8= Z.|last9=  Zanin|first9= M.|year= 2014|doi= 10.1016/j.physrep.2014.07.001|arxiv=1407.0742|bibcode= 2014PhR...544....1B}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite journal|last=Battiston|first=Federico|last2=Nicosia|first2=Vincenzo|last3=Latora|first3=Vito|date=2017-02-01|title=The new challenges of multiplex networks: Measures and models|url=https://link.springer.com/article/10.1140/epjst/e2016-60274-8|journal=The European Physical Journal Special Topics|language=en|volume=226|issue=3|pages=401–416|doi=10.1140/epjst/e2016-60274-8|issn=1951-6355|arxiv=1606.09221|bibcode=2017EPJST.226..401B}}&lt;/ref&gt; Increasingly sophisticated attempts to model real-world systems as multidimensional networks have yielded valuable insight in the fields of [[social network analysis]],&lt;ref name="DeDomenico2013"&gt;{{Cite journal | doi = 10.1103/PhysRevX.3.041022| title = Mathematical Formulation of Multilayer Networks| journal = Physical Review X| volume = 3| issue = 4| pages = 041022| year = 2013| last1 = De Domenico | first1 = M. | last2 = Solé-Ribalta | first2 = A. | last3 = Cozzo | first3 = E. | last4 = Kivelä | first4 = M. | last5 = Moreno | first5 = Y. | last6 = Porter | first6 = M. | last7 = Gómez | first7 = S. | last8 = Arenas | first8 = A. |url=http://www.isi.it/wp-content/uploads/publication/document/physrevx_3_041022_1389284935.pdf | bibcode = 2013PhRvX...3d1022D| arxiv = 1307.4977}}&lt;/ref&gt;&lt;ref name="Structural measures for multiplex networks" /&gt;&lt;ref name="Mucha"&gt;{{Cite journal| year = 2010| last1 = Mucha| first1 = P.| title = Community structure in time-dependent, multiscale, and multiplex networks| journal = Science| volume = 328|issue=5980| pages = 876–878| displayauthors=etal|arxiv=0911.1824|url=https://people.maths.ox.ac.uk/porterm/papers/multislice.pdf|doi=10.1126/science.1184819| pmid = 20466926| bibcode = 2010Sci...328..876M}}&lt;/ref&gt;&lt;ref name="De Domenico1"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Identifying Modular Flows on Multilayer Networks Reveals Highly Overlapping Organization in Interconnected Systems
| journal = Physical Review X
| volume = 5
| pages = 011027
| last2 = Lancichinetti
| first2 = A.
| last3 = Arenas
| first3 = A.
| last4 = Rosvall
| first4 = M.
| doi=10.1103/PhysRevX.5.011027
| arxiv=1408.2925
| bibcode= 2015PhRvX...5a1027D
}}&lt;/ref&gt;&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Battiston|first=Federico|last2=Iacovacci|first2=Jacopo|last3=Nicosia|first3=Vincenzo|last4=Bianconi|first4=Ginestra|last5=Latora|first5=Vito|date=2016-01-27|title=Emergence of Multiplex Communities in Collaboration Networks|url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147451|journal=PLoS ONE|volume=11|issue=1|pages=e0147451|doi=10.1371/journal.pone.0147451|issn=1932-6203|pmc=4731389|pmid=26815700|bibcode=2016PLoSO..1147451B|arxiv=1506.01280}}&lt;/ref&gt; economics, urban and international [[transport network|transport]],&lt;ref name="Cardillo"&gt;{{Cite journal| year = 2013| last1= Cardillo| first1 = A.| title = Emergence of network features from multiplexity| journal = Scientific Reports| volume = 3| pages = 1344 | displayauthors=etal|doi=10.1038/srep01344| pmid= 23446838| pmc= 3583169|url=http://www.nature.com/articles/srep01344| bibcode= 2013NatSR...3E1344C| arxiv= 1212.2153}}&lt;/ref&gt;&lt;ref name="Gallotti"&gt;{{Cite journal
| year = 2014
| last1= Gallotti
| first1 = R.
| title = Anatomy and efficiency of urban multimodal mobility
| journal = Scientific Reports
| volume = 4
| pages = 6911
| last2 = Barthelemy
| first2 = M.
| arxiv=1411.1274
| doi=10.1038/srep06911
| pmid= 25371238
| pmc= 4220282
| url=http://www.nature.com/articles/srep06911
| bibcode= 2014NatSR...4E6911G
}}&lt;/ref&gt;&lt;ref name="DeDomenico2014"&gt;{{Cite journal
| year = 2014
| last1= De Domenico
| first1 = M.
| title = Navigability of interconnected networks under random failures
| journal = PNAS
| volume = 111
| issue= 23
| pages = 8351–8356
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Gomez
| first3 = S.
| last4 = Arenas
| first4 = A.
|doi=10.1073/pnas.1318469111
| pmid= 24912174
|url=http://www.pnas.org/content/111/23/8351.full
| bibcode= 2014PNAS..111.8351D
| pmc=4060702
}}&lt;/ref&gt; [[ecological network|ecology]],&lt;ref&gt;{{Cite journal
|last1=Stella|first1=M.
|last2=Andreazzi|first2=C.S.
|last3=Selakovic|first3=S.
|last4=Goudarzi|first4=A.
|last5=Antonioni|first5=A.
|title=Parasite spreading in spatial ecological multiplex networks
|journal=Journal of Complex Networks
|volume = 5
|issue = 3
|pages = 486–511
|doi = 10.1093/comnet/cnw028
|url = https://academic.oup.com/comnet/article-abstract/5/3/486/2557036/Parasite-spreading-in-spatial-ecological-multiplex
|year=2016|arxiv=1602.06785}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
|last1=Pilosof|first1=S.
|last2=Porter|first2=M.A.
|last3=Pascual|first3=M.
|last4=Kefi|first4=S.
|title=The Multilayer Nature of Ecological Networks
|journal=Nature Ecology &amp; Evolution
|volume = 1
|pages = 0101
|doi = 10.1038/s41559-017-0101
|url = http://www.nature.com/articles/s41559-017-0101
|year=2017|arxiv=1511.04453}}&lt;/ref&gt; psychology,&lt;ref name="Fiori"&gt;{{Cite journal
 | pmid = 18079416
| year = 2007
| last1= Fiori
| first1 = K. L.
| title = Social network types among older adults: A multidimensional approach
| journal = The Journals of Gerontology Series B
| volume = 62
| issue = 6
| pages = P322–30
| last2 = Smith
| first2 = J
| last3 = Antonucci
| first3 = T. C.
| url=http://psychsocgerontology.oxfordjournals.org/content/62/6/P322.long
 | doi=10.1093/geronb/62.6.p322
}}&lt;/ref&gt;&lt;ref name="Stella2017"&gt;{{Cite journal
 | pmid = 5402256
| year = 2017
| last1= Stella
| first1 = M.
| title = Multiplex lexical networks reveal patterns in early word acquisition in children
| journal = Scientific Reports
| issue = 7
| pages = 46730
| last2 = Beckage
| first2 = N. M.
| last3 = Brede
| first3 = M.
| url=https://www.nature.com/articles/srep46730
 | doi=10.1038/srep46730
 | volume=21
| arxiv= 1609.03207
| bibcode= 2017NatSR...746730S
}}&lt;/ref&gt; medicine, biology,&lt;ref name="De Domenico3"&gt;{{Cite journal
| year = 2015
| last= De Domenico
| first1 = M.
| title = Structural reducibility of multilayer networks
| journal = Nature Communications
| volume = 6
| pages = 6864
| last2 = Nicosia
| first2 = V.
| last3 = Arenas
| first3 = A.
| last4 = Latora
| first4 = V.
|doi=10.1038/ncomms7864 
| pmid= 25904309
|url=http://www.nature.com/ncomms/2015/150423/ncomms7864/full/ncomms7864.html
| bibcode= 2015NatCo...6E6864D
}}&lt;/ref&gt; commerce, climatology, physics,&lt;ref&gt;{{Cite journal|last=Gao|last2=Buldyrev|last3=Stanley|last4=Havlin|date=22 December 2011|title=Networks formed from interdependent networks|url=http://www.nature.com/nphys/journal/v8/n1/full/nphys2180.html|journal=Nature Physics |doi=10.1038/nphys2180|pmid=|access-date=|volume=8|pages=40–48|bibcode=2012NatPh...8...40G}}&lt;/ref&gt;&lt;ref name="spreading_review_2016"&gt;{{Cite journal|last=De Domenico|first=M.|last2=Granell|first2=C.|last3=Porter|first3=Mason A.|last4=Arenas|first4=A.|date=7 April 2016|title=The physics of spreading processes in multilayer networks|volume=12|issue=10|pages=901–906|arxiv=1604.02021|url=http://www.nature.com/nphys/journal/vaop/ncurrent/full/nphys3865.html|doi= 10.1038/nphys3865|journal=Nature Physics |bibcode=2016NatPh..12..901D}}&lt;/ref&gt; [[computational neuroscience]],&lt;ref&gt;{{Cite journal|last=Timme|first=N.|last2=Ito|first2=S.|last3=Myroshnychenko|first3=M.|last4=Yeh|first4=F.C.|last5=Hiolski|first5=E.|last6=Hottowy|first6=P.|last7=Beggs|first7=J.M.|url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115764|doi=10.1371/journal.pone.0115764|pmid=25536059|journal=PLoS ONE |volume=9|issue=12|pages=e115764|title=Multiplex Networks of Cortical and Hippocampal Neurons Revealed at Different Timescales|year=2014|bibcode=2014PLoSO...9k5764T|pmc=4275261}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=De Domenico|first=M.|last2=Sasai|first2=S.|last3=Arenas|first3=A.|url=http://journal.frontiersin.org/article/10.3389/fnins.2016.00326/full|doi=10.3389/fnins.2016.00326|journal=Frontiers in Neuroscience |volume=10|title=Mapping multiplex hubs in human functional brain networks|year=2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Battiston|first=F.|last2=Nicosia|first2=V.|last3=Chavez|first3=M.|last4=Latora|first4=V.|arxiv=1606.09115|title=Multilayer motif analysis of brain networks|year=2016|doi=10.1063/1.4979282|volume=27|journal=Chaos: An Interdisciplinary Journal of Nonlinear Science|page=047404|bibcode=2017Chaos..27d7404B}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=De Domenico|first=M.|url=https://academic.oup.com/gigascience/article-lookup/doi/10.1093/gigascience/gix004|doi=10.1093/gigascience/gix004|journal=GigaScience|volume=6|issue=5|pages=1–8|title=Multilayer modeling and analysis of human brain networks|year=2017}}&lt;/ref&gt; [[operations management]], and finance.

==Terminology==
The rapid exploration of [[complex networks]] in recent years has been dogged by a lack of standardized naming conventions, as various groups use overlapping and contradictory&lt;ref name="Bródka "&gt;{{Cite book | doi = 10.1109/ASONAM.2011.67| chapter = Shortest Path Discovery in the Multi-layered Social Network| title = 2011 International Conference on Advances in Social Networks Analysis and Mining| pages = 497–501| year = 2011| last1 = Bródka | first1 = P. | last2 = Stawiak | first2 = P. | last3 = Kazienko | first3 = P. | isbn = 978-1-61284-758-0}}&lt;/ref&gt;&lt;ref name="Taking sociality seriously: the structure of multi-dimensional social networks as a source of information for individuals"&gt;{{Cite journal | doi = 10.1098/rstb.2012.0113| title = Taking sociality seriously: The structure of multi-dimensional social networks as a source of information for individuals| journal = Philosophical Transactions of the Royal Society B | volume = 367| issue = 1599| pages = 2108–18| year = 2012| last1 = Barrett | first1 = L.| last2 = Henzi | first2 = S. P.| last3 = Lusseau | first3 = D.|pmid=22734054 |pmc=3385678 }}&lt;/ref&gt; terminology to describe specific network configurations (e.g., multiplex, multilayer, multilevel, multidimensional, multirelational, interconnected). Formally, multidimensional networks are edge-labeled [[multigraph]]s.&lt;ref name="Zignani"&gt;{{cite arXiv |eprint= 1401.3126|last1= Zignani|first1= Matteo|title= Exploiting all phone media? A multidimensional network analysis of phone users' sociality|last2= Quadri|first2= Christian|last3= Gaitto|first3= Sabrina|author4= Gian Paolo Rossi|class= cs.SI|year= 2014}}&lt;/ref&gt; The term "fully multidimensional" has also been used to refer to a [[Multipartite graph|multipartite]] edge-labeled multigraph.&lt;ref name="Contractor"&gt;{{cite journal | last1 = Contractor | first1 = Noshir | last2 = Monge | first2 = Peter | last3 = Leonardi | first3 = Paul M. | year = 2011 | title = Network Theory: Multidimensional Networks and the Dynamics of Sociomateriality: Bringing Technology Inside the Network | url = http://ijoc.org/index.php/ijoc/article/view/1131/550 | journal = International Journal of Communication | volume = 5 | issue = | page = 39 }}&lt;/ref&gt; Multidimensional networks have also recently been reframed as specific instances of multilayer networks.&lt;ref name="Multilayer Networks"/&gt;&lt;ref name="The structure and dynamics of multilayer networks"&gt;{{Cite journal|last1= Boccaletti|first1= S.|title= The structure and dynamics of multilayer networks|journal= Physics Reports|volume= 544|issue= 1|pages= 1–122|last2=  Bianconi|first2= G.|last3=  Criado|first3= R.|last4=  del Genio|first4= C. I.|last5=  Gómez-Gardeñes|first5= J.|last6=  Romance|first6= M.|last7=  Sendiña-Nadal|first7= I.|last8=  Wang|first8= Z.|last9=  Zanin|first9= M.|year= 2014|doi= 10.1016/j.physrep.2014.07.001|arxiv=1407.0742|bibcode= 2014PhR...544....1B}}&lt;/ref&gt;&lt;ref name="Magnani"&gt;{{Cite book | doi = 10.1109/ASONAM.2011.114| chapter = The ML-Model for Multi-layer Social Networks| title = 2011 International Conference on Advances in Social Networks Analysis and Mining| pages = 5| year = 2011| last1 = Magnani | first1 = M. | last2 = Rossi | first2 = L. | isbn = 978-1-61284-758-0}}&lt;/ref&gt; In this case, there are as many layers as there are dimensions, and the links between nodes within each layer are simply all the links for a given dimension.

==Definition==

===Unweighted multilayer networks===
In elementary network theory, a network is represented by a graph &lt;math&gt;G = (V,E)&lt;/math&gt; in which &lt;math&gt;V&lt;/math&gt; is the set of [[Vertex (graph theory)|nodes]] and &lt;math&gt;E&lt;/math&gt; the [[Edge (graph theory)|links]] between nodes, typically represented as a [[tuple]] of nodes &lt;math&gt;u,v\in V&lt;/math&gt;. While this basic formalization is useful for analyzing many systems, real world networks often have added complexity in the form of multiple types of relations between system elements. An early formalization of this idea came through its application in the field of social network analysis (see, e.g.,&lt;ref name="Frame analysis: an essay on the organization of experience"&gt;{{cite book |last=Goffman |title=Frame analysis: an essay on the organization of experience |isbn=9780930350918 }}&lt;/ref&gt; and papers on relational algebras in social networks) in which multiple forms of social connection between people were represented by multiple types of links.&lt;ref name="Social Network Analysis: Methods and Applications."&gt;{{Cite book|title=Social Network Analysis: Methods and Applications|isbn=9780521387071|author1=Wasserman|first1=Stanley|author-link1=Stanley Wasserman| date=1994-11-25|location=Cambridge|publisher= Cambridge University Press}}&lt;/ref&gt;

To accommodate the presence of more than one type of link, a multidimensional network is represented by a triple &lt;math&gt;G = (V,E,D)&lt;/math&gt;, where &lt;math&gt;D&lt;/math&gt; is a set of dimensions (or layers), each member of which is a different type of link, and &lt;math&gt;E&lt;/math&gt; consists of triples &lt;math&gt;(u,v,d)&lt;/math&gt; with &lt;math&gt;u,v\in V&lt;/math&gt; and &lt;math&gt;d\in D&lt;/math&gt;.&lt;ref name="The structure and dynamics of multilayer networks" /&gt;

Note that as in all [[directed graph]]s, the links &lt;math&gt;(u,v,d)&lt;/math&gt; and &lt;math&gt;(v,u,d)&lt;/math&gt; are distinct.

By convention, the number of links between two nodes in a given dimension is either 0 or 1 in a multidimensional network. However, the total number of links between two nodes across all dimensions is less than or equal to &lt;math&gt;|D|&lt;/math&gt;.

===Weighted multilayer networks===
In the case of a [[weighted network]], this triplet is expanded to a quadruplet &lt;math&gt;e = (u,v,d,w)&lt;/math&gt;, where &lt;math&gt;w&lt;/math&gt; is the weight on the link between &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; in the dimension &lt;math&gt;d&lt;/math&gt;.
[[File:MuxViz EU Airports.png|thumb|The multiplex network of European airports. Each airline denotes a different layer. Visualization made with the [http://muxviz.net muxViz software]]]Further, as is often useful in social network analysis, link weights may take on positive or negative values. Such signed networks can better reflect relations like amity and enmity in social networks.&lt;ref name="Contractor" /&gt; Alternatively, link signs may be figured as dimensions themselves,&lt;ref name="Leskovec"&gt;{{Cite journal|arxiv=1003.2429|last1=Leskovec|first1=Jure|title=Predicting Positive and Negative Links in Online Social Networks|journal=WWW : ACM WWW International conference on World Wide Web|volume=2010|issue=2010|last2=Huttenlocher|first2=Daniel|last3=Kleinberg|first3=Jon|year=2010|url=https://www.cs.cornell.edu/home/kleinber/www10-signed.pdf|doi=10.1145/1772690.1772756|pages=641–650}}&lt;/ref&gt; e.g. &lt;math&gt;G = (V,E,D)&lt;/math&gt; where &lt;math&gt;D=\{-1,0,1\}&lt;/math&gt; and &lt;math&gt;E = \{(u,v,d); u,v \in V, d \in D\}&lt;/math&gt; This approach has particular value when considering unweighted networks.
This conception of dimensionality can be expanded should attributes in multiple dimensions need specification. In this instance, links are ''n''-tuples &lt;math&gt;e = (u,v,d_1 \dots d_{n-2})&lt;/math&gt;. Such an expanded formulation, in which links may exist within multiple dimensions, is uncommon but has been used in the study of multidimensional [[time-varying network]]s.&lt;ref name="Kazienko"&gt;{{Cite book | doi = 10.1007/978-3-642-23935-9_37| chapter = Multidimensional Social Network: Model and Analysis| title = Computational Collective Intelligence. Technologies and Applications| volume = 6922| pages = 378| series = Lecture Notes in Computer Science| year = 2011| last1 = Kazienko | first1 = P. A. | last2 = Musial | first2 = K. | last3 = Kukla | first3 = E. B. | last4 = Kajdanowicz | first4 = T. | last5 = Bródka | first5 = P. | isbn = 978-3-642-23934-2}}&lt;/ref&gt;

[[File:Muxviz GlobalRisk.png|thumb|The [[World Economic Forum]] map of [[Global Risks Report|global risks]] and global trends, modeled as an interdependent network (also known as network of networks). Visualization made with the [http://muxviz.net/ muxViz software]]]

===General formulation in terms of tensors===

Whereas unidimensional networks have two-dimensional [[Adjacency matrix|adjacency matrices]] of size &lt;math&gt;V\times V&lt;/math&gt;, in a multidimensional network with &lt;math&gt;D&lt;/math&gt; dimensions, the adjacency matrix becomes a multilayer adjacency tensor, a four-dimensional matrix of size &lt;math&gt;(V\times D)\times (V\times D)&lt;/math&gt;.&lt;ref name="DeDomenico2013" /&gt; By using [[index notation]], adjacency matrices can be indicated by &lt;math&gt;A^{i}_{j}&lt;/math&gt;, to encode connections between nodes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;, whereas multilayer adjacency tensors are indicated by &lt;math&gt;M^{i\alpha}_{j\beta}&lt;/math&gt;, to encode connections between node &lt;math&gt;i&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt; and node &lt;math&gt;j&lt;/math&gt; in layer &lt;math&gt;\beta&lt;/math&gt;. As in unidimensional matrices, directed links, signed links, and weights are all easily accommodated by this framework.

In the case of multiplex networks, special types of multilayer networks where nodes can not be interconnected with other nodes in other layers, a three-dimensional matrix of size &lt;math&gt;(V\times V)\times D&lt;/math&gt; with entries &lt;math&gt;A^{\alpha}_{ij}&lt;/math&gt; is enough to represent the structure of the system&lt;ref name="Mucha"&gt;{{Cite journal| year = 2010| last1 = Mucha| first1 = P.| title = Community structure in time-dependent, multiscale, and multiplex networks| journal = Science| volume = 328|issue=5980| pages = 876–878| displayauthors=etal|arxiv=0911.1824|url=https://people.maths.ox.ac.uk/porterm/papers/multislice.pdf|doi=10.1126/science.1184819| pmid = 20466926| bibcode = 2010Sci...328..876M}}&lt;/ref&gt;&lt;ref name="Nicosia"&gt;{{Cite journal| year = 2013| last1 = Nicosia| first1 = V.| last2 = Bianconi| first2 = G.| last3 = Nicosia| first3 = V.| last4 = Barthelemy| first4 = M.| title = Growing multiplex networks| journal = Physical Review Letters| volume = 111|issue=5| pages =058701|doi= 10.1103/PhysRevLett.111.058701| pmid = 23952453| arxiv = 1302.7126| bibcode = 2013PhRvL.111e8701N}}&lt;/ref&gt; by encoding connections between nodes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt;.
[[File:Muxviz Star Wars Social Network.png|thumb|The multiplex social network of Star Wars saga. Each layer denotes a different episode and two nodes are connected each other if the corresponding characters acted together in one or more scenes. Visualization made with [http://muxviz.net muxViz software]]]

==Multidimensional network-specific definitions==

===Multi-layer neighbors===
In a multidimensional network, the neighbors of some node &lt;math&gt;v&lt;/math&gt; are all nodes connected to &lt;math&gt;v&lt;/math&gt; across dimensions.

===Multi-layer path length===
A [[Path (graph theory)|path]] between two nodes in a multidimensional network can be represented by a vector '''r''' &lt;math&gt;=(r_1, \dots r_{|D|})&lt;/math&gt; in which the &lt;math&gt;i&lt;/math&gt;th entry in '''r''' is the number of links traversed in the &lt;math&gt;i&lt;/math&gt;th dimension of &lt;math&gt;G&lt;/math&gt;.&lt;ref name="On multidimensional network measures"&gt;M. Magnani, A. Monreale, G. Rossetti, F. Giannotti: "On multidimensional network measures", SEBD 2013, Rocella Jonica, Italy&lt;/ref&gt; As with overlapping degree, the sum of these elements can be taken as a rough measure of a path length between two nodes.

===Network of layers===
The existence of multiple layers (or dimensions) allows to introduce the new concept of ''network of layers'',&lt;ref name="DeDomenico2013" /&gt; peculiar of multilayer networks. In fact, layers might be interconnected in such a way that their structure can be described by a network, as shown in the figure.
[[File:Network of layers in multilayer systems.png|thumb|Network of layers in multilayer systems]]
The network of layers is usually weighted (and might be directed), although, in general, the weights depends on the application of interest. A simple approach is, for each pair of layers, to sum all of the weights in the connections between their nodes to obtain edge weights that can be encoded into a matrix &lt;math&gt;q_{\alpha\beta}&lt;/math&gt;. The rank-2 adjacency tensor, representing the underlying network of layers in the space &lt;math&gt;\mathbb{R}^{L\times L}&lt;/math&gt; is given by

&lt;math&gt;\Psi^{\gamma}_{\delta}=\sum\limits_{\alpha,\beta=1}^{L}q_{\alpha\beta}E^{\gamma}_{\delta}(\alpha\beta)&lt;/math&gt;

where &lt;math&gt;E^{\gamma}_{\delta}(\alpha\beta)&lt;/math&gt; is the canonical matrix with all components equal to zero except for the entry corresponding to row &lt;math&gt;\alpha&lt;/math&gt; and column &lt;math&gt;\beta&lt;/math&gt;, that is equal to one. Using the tensorial notation, it is possible to obtain the (weighted) network of layers from the multilayer adjacency tensor as &lt;math&gt;\Psi^{\gamma}_{\delta}=M^{i\gamma}_{j\delta}U_{i}^{j}&lt;/math&gt;.&lt;ref name="DeDomenico2013" /&gt;

==Centrality measures==

===Degree===
In a non-interconnected multidimensional network, where interlayer links are absent, the [[Degree (graph theory)|degree]] of a node is represented by a vector of length &lt;math&gt;|D|: \mathbf{k} = (k^{1}_i,\dots k^{|D|}_i)&lt;/math&gt;. Here &lt;math&gt;|D|&lt;/math&gt; is an alternative way to denote the number of layers &lt;math&gt;L&lt;/math&gt; in multilayer networks. However, for some computations it may be more useful to simply sum the number of links adjacent to a node across all dimensions.&lt;ref name="DeDomenico2013" /&gt;&lt;ref name="Foundations of Multidimensional Network Analysis"&gt;{{Cite book | doi = 10.1109/ASONAM.2011.103| chapter = Foundations of Multidimensional Network Analysis| title = 2011 International Conference on Advances in Social Networks Analysis and Mining| pages = 485| year = 2011| last1 = Berlingerio | first1 = M. | last2 = Coscia | first2 = M. | last3 = Giannotti | first3 = F. | last4 = Monreale | first4 = A. | last5 = Pedreschi | first5 = D. | isbn = 978-1-61284-758-0|url=http://www.michelecoscia.com/wp-content/uploads/2012/08/foundations.pdf}}&lt;/ref&gt; This is the ''overlapping degree'':&lt;ref name="Structural measures for multiplex networks" /&gt; &lt;math&gt;\sum_{\alpha = 1}^{|D|} k^{\alpha}_i&lt;/math&gt;. As with unidimensional networks, distinction may similarly be drawn between incoming links and outgoing links.
If interlayer links are present, the above definition must be adapted to account for them, and the ''multilayer degree'' is given by

&lt;math&gt;k^{i}=M^{i\alpha}_{j\beta}U_{\alpha}^{\beta}u^{j}=\sum_{\alpha,\beta=1}^{L}\sum_{j=1}^{N}M^{i\alpha}_{j\beta}&lt;/math&gt;

where the tensors &lt;math&gt;U_{\alpha}^{\beta}&lt;/math&gt; and &lt;math&gt;u^{j}&lt;/math&gt; have all components equal to 1. The heterogeneity in the number of connections of a node across the different layers can be taken into account through the participation coefficient.&lt;ref name="Structural measures for multiplex networks" /&gt;

===Versatility as multilayer centrality===

When extended to interconnected multilayer networks, i.e. those systems where nodes are connected across layers, the concept of centrality is better understood in terms of versatility.&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt; Nodes that are not central in each layer might be the most important for the multilayer systems in certain scenarios. For instance, this is the case where two layers encode different networks with only one node in common: it is very likely that such a node will have the highest centrality score because it is responsible for the information flow across layers.

====Eigenvector versatility====

As for unidimensional networks, eigenvector versatility can be defined as the solution of the eigenvalue problem given by &lt;math&gt;M^{i\alpha}_{j\beta}\Theta_{i\alpha}=\lambda_{1} \Theta_{j\beta}&lt;/math&gt;, where [[Einstein summation convention]] is used for sake of simplicity. Here, &lt;math&gt;\Theta_{j\beta} = \lambda_{1}^{-1}M^{i\alpha}_{j\beta}\Theta_{i\alpha}&lt;/math&gt; gives the multilayer generalization of Bonacich's eigenvector centrality per node per layer. The overall eigenvector versatility is simply obtained by summing up the scores across layers as &lt;math&gt;\theta_{i}=\Theta_{i\alpha}u^{\alpha}&lt;/math&gt;.&lt;ref name="DeDomenico2013"&gt;{{Cite journal | doi = 10.1103/PhysRevX.3.041022| title = Mathematical Formulation of Multilayer Networks| journal = Physical Review X| volume = 3| issue = 4| pages = 041022| year = 2013| last1 = De Domenico | first1 = M. | last2 = Solé-Ribalta | first2 = A. | last3 = Cozzo | first3 = E. | last4 = Kivelä | first4 = M. | last5 = Moreno | first5 = Y. | last6 = Porter | first6 = M. | last7 = Gómez | first7 = S. | last8 = Arenas | first8 = A. |url=http://www.isi.it/wp-content/uploads/publication/document/physrevx_3_041022_1389284935.pdf | bibcode = 2013PhRvX...3d1022D| arxiv = 1307.4977}}&lt;/ref&gt;&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt;

====Katz versatility====

As for its [[Katz centrality|unidimensional counterpart]], the Katz versatility is obtained as the solution &lt;math&gt;\Phi_{j\beta}=[(\delta-aM)^{-1}]^{i\alpha}_{j\beta}U_{i\alpha}&lt;/math&gt; of the tensorial equation &lt;math&gt;\Phi_{j\beta}=aM^{i\alpha}_{j\beta}\Phi_{i\alpha}+bu_{j\beta}&lt;/math&gt;, where &lt;math&gt;\delta^{i\alpha}_{j\beta}=\delta^{i}_{j}\delta^{\alpha}_{\beta}&lt;/math&gt;, &lt;math&gt;a&lt;/math&gt; is a constant smaller than the largest eigenvalue and &lt;math&gt;b&lt;/math&gt; is another constant generally equal to 1. The overall Katz versatility is simply obtained by summing up the scores across layers as &lt;math&gt;\phi_{i}=\Phi_{i\alpha}u^{\alpha}&lt;/math&gt;.&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt;

====HITS versatility====

For unidimensional networks, the [[HITS algorithm]] has been originally introduced by [[Jon Kleinberg]] to rate Web Pages. The basic assumption of the algorithm is that relevant pages, named authorities, are pointed by special Web pages, named hubs. This mechanism can be mathematically described by two coupled equations which reduce to two eigenvalue problems. When the network is undirected, Authority and Hub centrality are equivalent to eigenvector centrality.
These properties are preserved by the natural extension of the equations proposed by Kleinberg to the case of interconnected multilayer networks, given by
&lt;math&gt;(M M^{t})^{i\alpha}_{j\beta} \Gamma_{i\alpha} = \lambda_{1} \Gamma_{j\beta}&lt;/math&gt; and &lt;math&gt;(M^{t} M)^{i\alpha}_{j\beta} \Upsilon_{i\alpha} = \lambda_{1} \Upsilon_{j\beta}&lt;/math&gt;, where &lt;math&gt;t&lt;/math&gt; indicates the transpose operator, &lt;math&gt;\Gamma_{i\alpha}&lt;/math&gt; and &lt;math&gt;\Upsilon_{i\alpha}&lt;/math&gt; indicate hub and authority centrality, respectively. By contracting the hub and authority tensors, one obtains the overall versatilities as &lt;math&gt;\gamma_{i} = \Gamma_{i\alpha}u^{\alpha}&lt;/math&gt; and &lt;math&gt;\upsilon_{i} = \Upsilon_{i\alpha}u^{\alpha}&lt;/math&gt;, respectively.&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt;

====PageRank versatility====

[[PageRank]], better known as ''Google Search Algorithm'' is another measure of centrality in complex networks, originally introduced to rank Web pages. Its extension to the case of interconnected multilayer networks can be obtained as follows.

First, it is worth remarking that [[PageRank]] can be seen as the steady-state solution of a special [[Markov process]] on the top of the network. [[Random walk]]ers explore the network according to a special [[Stochastic matrix|transition matrix]] and their dynamics is governed by a random walk [[master equation]]. It is easy to show that the solution of this equation is equivalent to the leading eigenvector of the transition matrix.

Random walks have been defined also in the case of interconnected multilayer networks&lt;ref name="DeDomenico2014" /&gt; and edge-colored multigraphs (also known as multiplex networks).&lt;ref name="BattistonWalks"&gt;{{Cite journal
| year = 2016
| last1= Battiston
| first1 = F.
| title = Efficient exploration of multiplex networks
| journal = New Journal of Physics
| volume = 18
| issue= 4
| pages = 043035
| last2 = Nicosia
| first2 = V.
| last3 = Latora
| first3 = V.
|url=http://stacks.iop.org/1367-2630/18/i=4/a=043035
| bibcode= 2016NJPh...18d3035B
| doi= 10.1088/1367-2630/18/4/043035
| arxiv= 1505.01378
}}&lt;/ref&gt; For interconnected multilayer networks, the transition tensor governing the dynamics of the random walkers within and across layers is given by &lt;math&gt;R^{i\alpha}_{j\beta} = rT^{i\alpha}_{j\beta} + \frac{(1-r)}{NL}u^{i\alpha}_{j\beta},&lt;/math&gt;, where &lt;math&gt;r&lt;/math&gt; is a constant, generally set to 0.85, &lt;math&gt;N&lt;/math&gt; is the number of nodes and &lt;math&gt;L&lt;/math&gt; is the number of layers or dimensions. Here, &lt;math&gt;R^{i\alpha}_{j\beta}&lt;/math&gt; might be named ''Google tensor'' and &lt;math&gt;u^{i\alpha}_{j\beta}&lt;/math&gt; is the rank-4 tensor with all components equal to 1.

As its unidimensional counterpart, PageRank versatility consists of two contributions: one encoding a classical random walk with rate &lt;math&gt;r&lt;/math&gt; and one encoding teleportation across nodes and layers with rate &lt;math&gt;1-r&lt;/math&gt;.

If we indicate by &lt;math&gt;\Omega_{i\alpha}&lt;/math&gt; the [[wiktionary:eigentensor|eigentensor]] of the Google tensor &lt;math&gt;R^{i\alpha}_{j\beta}&lt;/math&gt;, denoting the steady-state probability to find the walker in node &lt;math&gt;i&lt;/math&gt; and layer &lt;math&gt;\alpha&lt;/math&gt;, the multilayer PageRank is obtained by summing up over layers the eigentensor: &lt;math&gt;\omega_{i} = \Omega_{i\alpha}u^{\alpha}&lt;/math&gt;&lt;ref name="De Domenico2"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Ranking in interconnected multilayer networks reveals versatile nodes
| journal = Nature Communications
| volume = 6
| pages = 6868
| last2 = Sole-Ribalta
| first2 = A.
| last3 = Omodei
| first3 = E.
| last4 = Gomez
| first4 = S.
| last5 = Arenas
| first5 = A.
| doi=10.1038/ncomms7868
| pmid= 25904405
| bibcode= 2015NatCo...6E6868D
}}&lt;/ref&gt;

==Triadic closure and clustering coefficients==
{{see|Triadic closure}}
Like many other network statistics, the meaning of a [[clustering coefficient]] becomes ambiguous in multidimensional networks, due to the fact that triples may be closed in different dimensions than they originated.&lt;ref name="Structural measures for multiplex networks" /&gt;&lt;ref name="Cozzo" /&gt;&lt;ref name="Brodka2012" /&gt; Several attempts have been made to define local clustering coefficients, but these attempts have highlighted the fact that the concept must be fundamentally different in higher dimensions: some groups have based their work off of non-standard definitions,&lt;ref name="Brodka2012"&gt;{{Cite journal|arxiv=1207.4293|last1=Bródka|first1=Piotr|title=Analysis of Neighbourhoods in Multi-layered Dynamic Social Networks|journal=International Journal of Computational Intelligence Systems|volume=5|issue=3|pages=582–596|last2=Kazienko|first2=Przemysław|last3=Musiał|first3=Katarzyna|last4=Skibicki|first4=Krzysztof|year=2012|doi=10.1080/18756891.2012.696922}}&lt;/ref&gt; while others have experimented with different definitions of random walks and 3-cycles in multidimensional networks.&lt;ref name="Structural measures for multiplex networks" /&gt;&lt;ref name="Cozzo"&gt;{{Cite journal |journal=New Journal of Physics|volume=17|issue=7|pages=073029|last1=Cozzo|first1=Emanuele|title=Structure of triadic relations in multiplex networks|last2=Kivelä|first2=Mikko|author3=Manlio De Domenico|last4=Solé|first4=Albert|last5=Arenas|first5=Alex|last6=Gómez|first6=Sergio|last7= Porter|first7=Mason A.|last8=Moreno|first8=Yamir|year=2015|doi=10.1088/1367-2630/17/7/073029|arxiv=1307.6780|url=https://people.maths.ox.ac.uk/porterm/papers/ccmult-published.pdf|bibcode=2015NJPh...17g3029C}}&lt;/ref&gt;

==Community discovery==
While cross-dimensional structures have been studied previously,&lt;ref name="Jianyong"&gt;{{Cite book | doi = 10.1109/ICDE.2006.34| chapter = CLAN: An Algorithm for Mining Closed Cliques from Large Dense Graph Databases| title = 22nd International Conference on Data Engineering (ICDE'06)| pages = 73| year = 2006| last1 = Jianyong Wang| last2 = Zhiping Zeng| last3 = Lizhu Zhou| isbn = 0-7695-2570-9|url=http://dbgroup.cs.tsinghua.edu.cn/zengzp/pdfs/073_R23-1-161-Wang.pdf}}&lt;/ref&gt;&lt;ref name="Cai"&gt;{{Cite book | doi = 10.1007/11564126_44| chapter = Community Mining from Multi-relational Networks| title = Knowledge Discovery in Databases: PKDD 2005| volume = 3721| pages = 445| series = Lecture Notes in Computer Science| year = 2005| last1 = Cai | first1 = D. | last2 = Shao | first2 = Z. | last3 = He | first3 = X. | last4 = Yan | first4 = X. | last5 = Han | first5 = J. | isbn = 978-3-540-29244-9}}&lt;/ref&gt; they fail to detect more subtle associations found in some networks. Taking a slightly different take on the definition of "community" in the case of multidimensional networks allows for reliable identification of communities without the requirement that nodes be in direct contact with each other.&lt;ref name="DeDomenico2013" /&gt;&lt;ref name="Mucha" /&gt;&lt;ref name="De Domenico1" /&gt;&lt;ref name="Berlingerio"&gt;{{Cite journal | doi = 10.1007/s10618-013-0331-0| title = ABACUS: Frequent p ''Attern'' mining-BAsed Community discovery in m ''Ultidimensional'' networkS| journal = Data Mining and Knowledge Discovery| volume = 27| issue = 3| pages = 294–320| year = 2013| last1 = Berlingerio | first1 = M. | last2 = Pinelli | first2 = F. | last3 = Calabrese | first3 = F.|arxiv=1303.2025}}&lt;/ref&gt;
For instance, two people who never communicate directly yet still browse many of the same websites would be viable candidates for this sort of algorithm.

===Modularity maximization===

A generalization of the well-known [[Community structure|modularity maximization]] method for community discovery has been originally proposed by Mucha et al.&lt;ref name="Mucha"&gt;{{Cite journal| year = 2010| last1 = Mucha| first1 = P.| title = Community structure in time-dependent, multiscale, and multiplex networks| journal = Science| volume = 328|issue=5980| pages = 876–878| displayauthors=etal|arxiv=0911.1824|url=https://people.maths.ox.ac.uk/porterm/papers/multislice.pdf|doi=10.1126/science.1184819| pmid = 20466926| bibcode = 2010Sci...328..876M}}&lt;/ref&gt; This [[Modularity (networks)#Multiresolution methods|multiresolution method]] assumes a three-dimensional tensor representation of the network connectivity within layers, as for edge-colored multigraphs, and a three-dimensional tensor representation of the network connectivity across layers. It depends on the resolution parameter &lt;math&gt;\gamma&lt;/math&gt; and the weight &lt;math&gt;\omega&lt;/math&gt; of interlayer connections. In a more compact notation, making use of the tensorial notation, modularity can be written as &lt;math&gt;Q \propto S^{a}_{i\alpha}B^{i\alpha}_{j\beta}S^{j\beta}_{a}&lt;/math&gt;, where &lt;math&gt;B^{i\alpha}_{j\beta}=M^{i\alpha}_{j\beta} - P^{i\alpha}_{j\beta}&lt;/math&gt;, &lt;math&gt;M^{i\alpha}_{j\beta}&lt;/math&gt; is the multilayer adjacency tensor, &lt;math&gt;P^{i\alpha}_{j\beta}&lt;/math&gt; is the tensor encoding the null model and the value of components of &lt;math&gt;S^{i\alpha}_{a}&lt;/math&gt; is defined to be 1 when a node &lt;math&gt;i&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt; belongs to a particular community, labeled by index &lt;math&gt;a&lt;/math&gt;, and 0 when it does not.&lt;ref name="DeDomenico2013" /&gt;

===Tensor decomposition===

[[Non-negative matrix factorization]] has been proposed to extract the community-activity structure of temporal networks.&lt;ref&gt;{{Cite journal|last=Gauvin|first=L.|last2=Panisson|first2=A.|last3=Cattuto|first3=C.|url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0086028|doi=10.1371/journal.pone.0086028|pmid=24497935|pmc=3908891|journal=PLoS ONE |volume=9|issue=1|pages=e86028|title=Detecting the community structure and activity patterns of temporal networks: a non-negative tensor factorization approach|year=2014|bibcode=2014PLoSO...986028G|arxiv=1308.0723}}&lt;/ref&gt; The multilayer network is represented by a three-dimensional tensor &lt;math&gt;T^{\tau}_{ij}&lt;/math&gt;, like an edge-colored multigraph, where the order of layers encode the arrow of time. Tensor factorization by means of Kruskal decomposition is thus applied to &lt;math&gt;T^{\tau}_{ij}&lt;/math&gt; to assign each node to a community across time.

===Statistical inference===

Methods based on statistical inference, generalizing [[Community structure#Statistical inference|existing approaches]] introduced for unidimensional networks, have been proposed. [[Stochastic block model]] is the most used generative model, appropriately generalized to the case of multilayer networks.&lt;ref&gt;{{Cite journal | doi = 10.1103/PhysRevE.92.042807| title = Inferring the mesoscale structure of layered, edge-valued, and time-varying networks| journal = Physical Review E| volume = 92| issue = 4|pages=042807| year = 2015| last1 = Peixoto | first1 = T.P. | arxiv = 1504.02381| bibcode = 2015PhRvE..92d2807P}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | doi = 10.1103/PhysRevX.6.011036| title = Multilayer stochastic block models reveal the multilayer structure of complex networks| journal = Physical Review X| volume = 6| issue = 1|pages=011036| year = 2016| last1 = Valles-Català | first1 = T.|last2=Massucci|first2=F.|last3=Guimerà|first3=R.|last4=Sales-Pardo|first4=M.|url=http://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.011036 | bibcode = 2016PhRvX...6a1036V}}&lt;/ref&gt;

As for unidimensional networks, principled methods like [[minimum description length]] can be used for model selection in community detection methods based on information flow.&lt;ref name="De Domenico1"&gt;{{Cite journal
| year = 2015
| last1= De Domenico
| first1 = M.
| title = Identifying Modular Flows on Multilayer Networks Reveals Highly Overlapping Organization in Interconnected Systems
| journal = Physical Review X
| volume = 5
| pages = 011027
| last2 = Lancichinetti
| first2 = A.
| last3 = Arenas
| first3 = A.
| last4 = Rosvall
| first4 = M.
| doi=10.1103/PhysRevX.5.011027
| arxiv=1408.2925
| bibcode= 2015PhRvX...5a1027D
}}&lt;/ref&gt;

==Structural reducibility==

Given the higher complexity of multilayer networks with respect to unidimensional networks, an active field of research is devoted to simplify the structure of such systems by employing some kind of dimensionality reduction.&lt;ref name="De Domenico3"&gt;{{Cite journal
| year = 2015
| last= De Domenico
| first1 = M.
| title = Structural reducibility of multilayer networks
| journal = Nature Communications
| volume = 6
| pages = 6864
| last2 = Nicosia
| first2 = V.
| last3 = Arenas
| first3 = A.
| last4 = Latora
| first4 = V.
|doi=10.1038/ncomms7864 
| pmid= 25904309
|url=http://www.nature.com/ncomms/2015/150423/ncomms7864/full/ncomms7864.html
| bibcode= 2015NatCo...6E6864D
}}&lt;/ref&gt;&lt;ref name="Sanchez1"&gt;{{Cite journal
| year = 2014
| last= Sánchez-García
| first1 = R.J.
| title = Dimensionality reduction and spectral properties of multilayer networks
| journal = Physical Review E
| volume = 89.5
| issue= 5
| pages = 052815
| last2 = Cozzo
| first2 = E.
| last3 = Moreno
| first3 = Y.
|doi=10.1103/PhysRevE.89.052815
| arxiv= 1311.1759
| bibcode= 2014PhRvE..89e2815S
}}&lt;/ref&gt;

A popular method is based on the calculation of the [[Jensen–Shannon divergence|quantum Jensen-Shannon divergence]] between all pairs of layers, which is then exploited for its [[Metric (mathematics)|metric properties]] to build a distance matrix and [[Hierarchical clustering|hierarchically cluster]] the layers. Layers are successively aggregated according to the resulting hierarchical tree and the aggregation procedure is stopped when the [[Mathematical optimization|objective function]], based on the [[Braunstein-Ghosh-Severini Entropy|entropy of the network]], gets a global maximum. This greedy approach is necessary because the underlying problem would require to verify all possible layer groups of any size, requiring a huge number of possibile combinations (which is given by the [[Bell number]] and scales super-exponentially with the number of units). Nevertheless, for multilayer systems with a small number of layers, it has been shown that the method performs optimally in the majority of cases.&lt;ref name="De Domenico3"&gt;{{Cite journal
| year = 2015
| last= De Domenico
| first1 = M.
| title = Structural reducibility of multilayer networks
| journal = Nature Communications
| volume = 6
| pages = 6864
| last2 = Nicosia
| first2 = V.
| last3 = Arenas
| first3 = A.
| last4 = Latora
| first4 = V.
|doi=10.1038/ncomms7864 
| pmid= 25904309
|url=http://www.nature.com/ncomms/2015/150423/ncomms7864/full/ncomms7864.html
| bibcode= 2015NatCo...6E6864D
}}&lt;/ref&gt;

==Other multilayer network descriptors==

===Degree correlations===
The question of degree correlations in unidimensional networks is fairly straightforward: do networks of similar degree tend to connect to each other? In multidimensional networks, what this question means becomes less clear. When we refer to a node's degree, are we referring to its degree in one dimension, or collapsed over all? When we seek to probe connectivity between nodes, are we comparing the same nodes across dimensions, or different nodes within dimensions, or a combination?&lt;ref name="The structure and dynamics of multilayer networks" /&gt;  What are the consequences of variations in each of these statistics on other network properties? In one study, assortativity was found to decrease robustness in a duplex network.&lt;ref name="Assortativity decreases the robustness of interdependent networks"&gt;{{Cite journal | doi = 10.1103/PhysRevE.86.066103| title = Assortativity decreases the robustness of interdependent networks| journal = Physical Review E| volume = 86| issue = 6| pages = 066103| year = 2012| last1 = Zhou | first1 = D. | last2 = Stanley | first2 = H. E. | last3 = d’Agostino | first3 = G. | last4 = Scala | first4 = A. | bibcode = 2012PhRvE..86f6103Z| arxiv = 1203.0029}}&lt;/ref&gt;

===Path dominance===
Given two multidimensional paths, '''r''' and '''s''', we say that '''r''' ''dominates'' '''s''' if and only if: &lt;math&gt;\forall d\in \langle 1,|D|\rangle , r_l \leq s_l&lt;/math&gt; and &lt;math&gt;\exists i&lt;/math&gt; such that &lt;math&gt;r_l &lt; s_l&lt;/math&gt;.&lt;ref name="On multidimensional network measures" /&gt;

===Shortest path discovery===
Among other network statistics, many centrality measures rely on the ability to assess shortest paths from node to node. Extending these analyses to a multidimensional network requires incorporating additional connections between nodes into the algorithms currently used (e.g., [[Dijkstra's algorithm|Dijkstra's]]). Current approaches include collapsing multi-link connections between nodes in a preprocessing step before performing variations on a breadth-first search of the network.&lt;ref name="Bródka" /&gt;

===Multidimensional distance===
One way to assess the distance between two nodes in a multidimensional network is by comparing all the multidimensional paths between them and choosing the subset that we define as shortest via path dominance: let &lt;math&gt;MP(u,v)&lt;/math&gt; be the set of all paths between &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt;. Then the distance between &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; is a set of paths &lt;math&gt;P\subseteq MP&lt;/math&gt; such that &lt;math&gt;\forall p\in P, \nexists p'\in MP&lt;/math&gt; such that &lt;math&gt;p'&lt;/math&gt; dominates &lt;math&gt;p&lt;/math&gt;. The length of the elements in the set of shortest paths between two nodes is therefore defined as the ''multidimensional distance''.&lt;ref name="On multidimensional network measures"/&gt;

===Dimension relevance===
In a multidimensional network &lt;math&gt;G = (V,E,D)&lt;/math&gt;, the relevance of a given dimension (or set of dimensions) &lt;math&gt;D'&lt;/math&gt; for one node can be assessed by the ratio: &lt;math&gt;\frac{\text{Neighbors}(v,D')}{\text{Neighbors}(v,D)}&lt;/math&gt;.&lt;ref name="Foundations of Multidimensional Network Analysis"/&gt;

===Dimension connectivity===
In a multidimensional network in which different dimensions of connection have different real-world values, statistics characterizing the distribution of links to the various classes are of interest. Thus it is useful to consider two metrics that assess this: dimension connectivity and edge-exclusive dimension connectivity. The former is simply the ratio of the total number of links in a given dimension to the total number of links in every dimension: &lt;math&gt;\frac{|\{(u,v,d)\in E | u,v\in V\}|}{|E|}&lt;/math&gt;. The latter assesses, for a given dimension, the number of pairs of nodes connected only by a link in that dimension: &lt;math&gt;\frac{|\{(u,v,d)\in E | u,v\in V \wedge \forall j\in D,j\neq d: (u,v,j)\notin E\}|}{|\{(u,v,d)\in E | u,v\in V\}|}&lt;/math&gt;.&lt;ref name="Foundations of Multidimensional Network Analysis"/&gt;

===Burst detection===
[[Time-varying network#Burstiness|Burstiness]] is a well-known phenomenon in many real-world networks, e.g. email or other human communication networks. Additional dimensions of communication provide a more faithful representation of reality and may highlight these patterns or diminish them. Therefore it is of critical importance that our methods for detecting bursty behavior in networks accommodate multidimensional networks.&lt;ref name="Multidimensional Human Dynamics in Mobile Phone Communications"&gt;{{Cite journal | doi = 10.1371/journal.pone.0103183| pmid = 25068479| title = Multidimensional Human Dynamics in Mobile Phone Communications| journal = PLoS ONE| volume = 9| issue = 7| pages = e103183| year = 2014| last1 = Quadri | first1 = C. | last2 = Zignani | first2 = M. | last3 = Capra | first3 = L. | last4 = Gaito | first4 = S. | last5 = Rossi | first5 = G. P. | bibcode = 2014PLoSO...9j3183Q | pmc=4113357}}&lt;/ref&gt;

==Diffusion processes on multilayer networks==

[[File:Random walks on multilayer networks.png|thumb|Illustration of a random walk on the top of a special multilayer system, i.e. a multiplex network]]

[[Diffusion process]]es are widely used in [[Diffusion|physics]] to explore physical systems, as well as in other disciplines as social sciences, neuroscience, urban and international transportation or finance. Recently, simple and more complex diffusive processes have been generalized to multilayer networks.&lt;ref name="spreading_review_2016" /&gt;&lt;ref name="Salehi2015"&gt;{{Cite journal
| year = 2015
| last1= Salehi
| first1 = M.
| title = Spreading Processes in Multilayer Networks
| journal = IEEE Transactions on Network Science and Engineering
| volume = 2
| issue= 2
| pages = 65–83
| last2 = et al
| first2 = .
| doi=10.1109/TNSE.2015.2425961
| url=http://ieeexplore.ieee.org/xpl/abstractAuthors.jsp?arnumber=7093190
|arxiv=1405.4329
}}&lt;/ref&gt; One result common to many studies is that diffusion in multiplex networks, a special type of multilayer system, exhibits two regimes: 1) the weight of inter-layer links, connecting layers each other, is not high enough and the multiplex system behaves like two (or more) uncoupled networks; 2) the weight of inter-layer links is high enough that layers are coupled each other, raising unexpected physical phenomena.&lt;ref name="spreading_review_2016" /&gt; It has been shown that there is an abrupt transition between these two regimes.&lt;ref name="Radicchi2013"&gt;{{Cite journal
| year = 2013
| last1= Radicchi
| first1 = F.
| title = Spreading Processes in Multilayer Networks
| journal = Nature Physics
| volume = 9
| issue= 11
| pages = 717–720
| last2 = Arenas
| first2 = A.
| doi=10.1038/nphys2761
| url=http://www.nature.com/nphys/journal/v9/n11/full/nphys2761.html
|arxiv=1307.4544
| bibcode= 2013NatPh...9..717R
}}&lt;/ref&gt;

In fact, all network descriptors depending on some diffusive process, from centrality measures to community detection, are affected by the layer-layer coupling. For instance, in the case of community detection, low coupling (where information from each layer separately is more relevant than the overall structure) favors clusters within layers, whereas high coupling (where information from all layer simultaneously is more relevant than the each layer separately) favors cross-layer clusters.&lt;ref name="Mucha" /&gt;&lt;ref name="De Domenico1" /&gt;

Diffusion reaction process on a multilayer system has been studied by Lazaridis et al.&lt;ref&gt;{{Cite journal|last=Lazaridis|first=Filippos|last2=Gross|first2=Bnaya|last3=Maragakis|first3=Michael|last4=Argyrakis|first4=Panos|last5=Bonamassa|first5=Ivan|last6=Havlin|first6=Shlomo|last7=Cohen|first7=Reuven|date=2018-04-04|title=Spontaneous repulsion in the A + B → 0 reaction on coupled networks|url=https://www.researchgate.net/publication/324236713_Spontaneous_repulsion_in_the_A_B_0_reaction_on_coupled_networks|journal=Physical Review E|volume=97|doi=10.1103/PhysRevE.97.040301}}&lt;/ref&gt; It is found that for the process &lt;math&gt;A+B\rightarrow0&lt;/math&gt; where A  and B are initially in different layers there appear, due to the reaction, a kind of repulsion between A and B that delays them.

===Random walks===

As for unidimensional networks, it is possible to define random walks on the top of multilayer systems. However, given the underlying multilayer structure, random walkers are not limited to move from one node to another within the same layer (''jump''), but are also allowed to move across layers (''switch'').&lt;ref name="DeDomenico2014" /&gt;

Random walks can be used to explore a multilayer system with the ultimate goal to unravel its [[Mesoscopic physics|mesoscale organization]], i.e. to partition it in [[Community structure|communities]],&lt;ref name="Mucha" /&gt;&lt;ref name="De Domenico1" /&gt; and have been recently used to better understand navigability of multilayer networks and their resilience to random failures,&lt;ref name="DeDomenico2014" /&gt; as well as for exploring efficiently this type of topologies.&lt;ref name="Battiston2016"&gt;{{Cite journal
| year = 2016
| last1= Battiston
| first1 = F.
| title = Efficient exploration of multiplex networks
| journal = New Journal of Physics
| volume = 18
| issue= 4
| pages = 043035
| last2 = Nicosia
| first2 = V.
| last3 = Latora
| first3 = V.
| doi=10.1088/1367-2630/18/4/043035
| url=http://iopscience.iop.org/article/10.1088/1367-2630/18/4/043035/meta
|arxiv=1505.01378
| bibcode= 2016NJPh...18d3035B
}}&lt;/ref&gt;

In the case of interconnected multilayer systems, the probability to move from a node &lt;math&gt;i&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt; to node &lt;math&gt;j&lt;/math&gt; in layer &lt;math&gt;\beta&lt;/math&gt; can be encoded into the rank-4 transition tensor &lt;math&gt;T^{i\alpha}_{j\beta}&lt;/math&gt; and the discrete-time walk can be described by the master equation

&lt;math&gt;p_{j\beta}(t+1)=\sum_{\alpha=1}^{L}\sum_{i=1}^{N}T^{i\alpha}_{j\beta}p_{i\alpha}(t)=\sum_{\alpha=1}^{L}\sum_{i=1}^{N}(T^{t})^{i\alpha}_{j\beta}p_{i\alpha}(0)&lt;/math&gt;

where &lt;math&gt;p_{i\alpha}(t)&lt;/math&gt; indicates the probability of finding the walker in node &lt;math&gt;i&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt;.&lt;ref name="DeDomenico2013" /&gt;&lt;ref name="DeDomenico2014" /&gt;

There are many different types of walks that can be encoded into the transition tensor &lt;math&gt;T^{i\alpha}_{j\beta}&lt;/math&gt;, depending on how the walkers are allowed to jump and switch. For instance, the walker might either jump or switch in a single time step without distinguishing between inter- and intra-layer links (''classical random walk''), or it can choose either to stay in the current layer and jump, or to switch layer and then jump to another node in the same time step (''physical random walk''). More complicated rules, corresponding to specific problems to solve, can be found in the literature.&lt;ref name="spreading_review_2016" /&gt; In some cases, it is possible to find, analytically, the stationary solution of the master equation.&lt;ref name="DeDomenico2014" /&gt;&lt;ref name="Battiston2016" /&gt;

===Classical diffusion===

The problem of classical diffusion in complex networks is to understand how a quantity will flow through the system and how much time it will take to reach the stationary state. Classical diffusion in multiplex networks has been recently studied by introducing the concept of [[supra-adjacency matrix]],&lt;ref name="Gomez2013"&gt;{{Cite journal
| year = 2013
| last1= Gomez
| first1 = S.
| title = Diffusion dynamics on multiplex networks
| journal = Physical Review Letters
| volume = 110
| issue= 2
| pages = 028701
| last2 = et al
| first2 = .
| doi=10.1103/PhysRevLett.110.028701
| pmid= 23383947
| url=http://journals.aps.org/prl/abstract/10.1103/PhysRevLett.110.028701
|arxiv=1207.2788
| bibcode= 2013PhRvL.110b8701G
}}&lt;/ref&gt; later recognized as a special [[Matricization|flattening]] of the multilayer adjacency tensor.&lt;ref name="DeDomenico2013" /&gt; In tensorial notation, the diffusion equation on the top of a general multilayer system can be written, concisely, as

&lt;math&gt;\frac{dX_{j\beta}(t)}{dt}=-L^{i\alpha}_{j\beta}X_{i\alpha}(t)&lt;/math&gt;

where &lt;math&gt;X_{i\alpha}(t)&lt;/math&gt; is the amount of diffusing quantity at time &lt;math&gt;t&lt;/math&gt; in node &lt;math&gt;i&lt;/math&gt; in layer &lt;math&gt;\alpha&lt;/math&gt;. The rank-4 tensor governing the equation is the Laplacian tensor, generalizing the [[Laplacian matrix|combinatorial Laplacian matrix]] of unidimensional networks. It is worth remarking that in non-tensorial notation, the equation takes a more complicated form.

Many of the properties of this diffusion process are completely understood in terms of the second smallest eigenvalue of the Laplacian tensor. It is interesting that diffusion in a multiplex system can be faster than diffusion in each layer separately, or in their aggregation, provided that certain spectral properties are satisfied.&lt;ref name="Gomez2013"/&gt;

===Information and epidemics spreading===
{{see also|epidemiology}}
Recently, how information (or diseases) spread through a multilayer system has been the subject of intense research.&lt;ref&gt;{{Cite journal|last=Granell|first=Clara|last2=Gómez|first2=Sergio|last3=Arenas|first3=Alex|date=2013-09-17|title=Dynamical Interplay between Awareness and Epidemic Spreading in Multiplex Networks|url=http://link.aps.org/doi/10.1103/PhysRevLett.111.128701|journal=Physical Review Letters|volume=111|issue=12|pages=128701|doi=10.1103/PhysRevLett.111.128701|pmid=24093306|bibcode=2013PhRvL.111l8701G|arxiv=1306.4136}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Battiston|first=Federico|last2=Cairoli|first2=Andrea|last3=Nicosia|first3=Vincenzo|last4=Baule|first4=Adrian|last5=Latora|first5=Vito|date=2016-06-01|title=Interplay between consensus and coherence in a model of interacting opinions|url=http://www.sciencedirect.com/science/article/pii/S016727891500202X|journal=Physica D: Nonlinear Phenomena|series=Nonlinear Dynamics on Interconnected Networks|volume=323–324|pages=12–19|doi=10.1016/j.physd.2015.10.013|bibcode=2016PhyD..323...12B|arxiv=1506.04544}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last=Battiston|first=Federico|last2=Nicosia|first2=Vincenzo|last3=Latora|first3=Vito|last4=Miguel|first4=Maxi San|date=2016-06-17|title=Robust multiculturality emerges from layered social influence|eprint=1606.05641|class=physics.soc-ph}}&lt;/ref&gt;

=== Percolation of multilayer networks ===
Buldyrev et al&lt;ref&gt;{{Cite journal|last=Buldyrev|first=S.V.|last2=Parshani|first2=R.|last3=Paul|first3=G.|last4=Stanley|first4=H.E.|last5=Havlin|first5=S.|date=2010|title=Catastrophic cascade of failures in interdependent networks|url=|journal=Nature|volume=464|pages=08932|via=}}&lt;/ref&gt; developed a framework to study [[percolation]] in multilayer networks with dependency links between the layers. New physical phenomena has been found, including abrupt transitions and cascading failures.&lt;ref&gt;{{Cite journal|last=Gao|first=J.|last2=Buldyrev|first2=S.V.|last3=Stanley|first3=H.E.|last4=Havlin|first4=S.|date=2012|title=Networks formed from interdependent networks|url=|journal=Nature Physics|volume=8|pages=40–48|via=|doi=10.1038/nphys2180|bibcode=2012NatPh...8...40G}}&lt;/ref&gt; When the networks are embedded in space they become extremely vulnerable even for a very small fraction of dependency links&lt;ref&gt;{{Cite journal|last=Bashan|first=A.|last2=Berezin|first2=Y.|last3=Buldyrev|first3=S.V.|last4=Havlin|first4=S.|date=2013|title=The extreme vulnerability of interdependent spatially embedded networks|url=|journal=Nature Physics|volume=9|pages=667|via=|doi=10.1038/nphys2727|arxiv=1206.2062|bibcode=2013NatPh...9..667B}}&lt;/ref&gt; and for localized attacks on a zero fraction of nodes.&lt;ref&gt;{{Cite journal|last=Berezin|first=Y.|last2=Bashan|first2=A.|last3=Danziger|first3=M.M.|last4=Li|first4=D.|last5=Havlin|first5=S.|date=2015|title=Localized attacks on spatially embedded networks with dependencies|url=|journal=Scientific Reports|volume=5|pages=8934|via=|doi=10.1038/srep08934|bibcode=2015NatSR...5E8934B}}&lt;/ref&gt; When recovery of nodes is introduced a rich phase diagram is found that include multicritical points and metastable regimes.&lt;ref&gt;{{Cite journal|last=Majdandzic|first=Antonio|last2=Podobnik|first2=Boris|last3=Buldyrev|first3=Sergey V.|last4=Kenett|first4=Dror Y.|last5=Havlin|first5=Shlomo|last6=Eugene Stanley|first6=H.|date=2013-12-01|title=Spontaneous recovery in dynamical networks|url=http://www.nature.com/articles/nphys2819|journal=Nature Physics|language=En|volume=10|issue=1|pages=34–38|doi=10.1038/nphys2819|issn=1745-2473|bibcode=2014NatPh..10...34M}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Majdandzic|first=Antonio|last2=Braunstein|first2=Lidia A.|last3=Curme|first3=Chester|last4=Vodenska|first4=Irena|last5=Levy-Carciente|first5=Sary|last6=Eugene Stanley|first6=H.|last7=Havlin|first7=Shlomo|date=2016-03-01|title=Multiple tipping points and optimal repairing in interacting networks|url=https://www.nature.com/articles/ncomms10850|journal=Nature Communications|language=En|volume=7|pages=10850|doi=10.1038/ncomms10850|issn=2041-1723|arxiv=1502.00244|bibcode=2016NatCo...710850M}}&lt;/ref&gt;

==Software==
*[http://muxviz.net/ muxViz], [[Free Software|free]] and efficient framework for analysis and visualization of multilayer networks, based on R [https://github.com/manlius/muxViz] &lt;ref&gt;{{cite journal | last1 = De Domenico | first1 = M. | last2 = Porter | first2 = M. A. | last3 = Arenas | first3 = A. | year = 2015 | title = Multilayer Analysis and Visualization of Networks | url = | journal = Journal of Complex Networks | volume = 3 | issue = 2| pages = 159–176 | doi=10.1093/comnet/cnu038}}&lt;/ref&gt;
*[http://www.mkivela.com/2015/12/11/multilayer-networks-library/ Multilayer Networks Library for Python (Pymnet)] by Mikko Kivelä
*[https://github.com/KatolaZ/mammult MAMMULT] Metrics And Models for MULTilayer networks (collection of C/Python code)&lt;ref name="Structural measures for multiplex networks"&gt;{{Cite journal
| year = 2014
| last1= Battiston
| first1 = F.
| title = Structural measures for multiplex networks
| journal = Physical Review E
| volume = 89
| issue= 3
| pages = 032804
| last2 = Nicosia
| first2 = V.
| last3 = Latora
| first3 = V.
| doi=10.1103/PhysRevE.89.032804
| url=http://journals.aps.org/pre/pdf/10.1103/PhysRevE.89.032804
| bibcode= 2014PhRvE..89c2804B
| arxiv= 1308.3182
}}&lt;/ref&gt;&lt;ref name=":0" /&gt;
*[http://netwiki.amath.unc.edu/GenLouvain/GenLouvain GenLouvain] MATLAB code for community detection based on multislice modularity maximization&lt;ref name="Mucha"&gt;{{Cite journal| year = 2010| last1 = Mucha| first1 = P.| title = Community structure in time-dependent, multiscale, and multiplex networks| journal = Science| volume = 328|issue=5980| pages = 876–878| displayauthors=etal|arxiv=0911.1824|url=https://people.maths.ox.ac.uk/porterm/papers/multislice.pdf|doi=10.1126/science.1184819| pmid = 20466926| bibcode = 2010Sci...328..876M}}&lt;/ref&gt;
*[http://multilayer.it.uu.se/software.html Multinet] R and C++ library for the analysis of multilayer networks.

==References==
{{reflist|30em}}

==External links==
{{Commons category|Network Science}}

[[Category:Networks]]
[[Category:Network theory]]</text>
      <sha1>sh17es14uczekb8zp9f8tg4q1saru1q</sha1>
    </revision>
  </page>
  <page>
    <title>Notation for differentiation</title>
    <ns>0</ns>
    <id>10265555</id>
    <revision>
      <id>870077637</id>
      <parentid>869978109</parentid>
      <timestamp>2018-11-22T06:22:14Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Reverted 2 edits by [[Special:Contributions/Bfoshizzle1|Bfoshizzle1]] ([[User talk:Bfoshizzle1|talk]]): Additions aren't related to the subject of this article. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29452">{{refimprove|date=November 2015}}
{{Calculus |Differential}}

In [[differential calculus]], there is no single uniform '''notation for differentiation'''. Instead, several different notations for the [[derivative]] of a [[function (mathematics)|function]] or [[dependent variable|variable]] have been proposed by different mathematicians. The usefulness of each notation varies with the context, and it is sometimes advantageous to use more than one notation in a given context. The most common notations for differentiation (and its opposite operation, the [[antidifferentiation]] or indefinite integration) are listed below.

== Leibniz's notation ==
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; background-color:#ddddff; border:1px solid #aaaaff; font-size:300%; line-height:100%;"&gt;{{math|{{sfrac|''dy''|''dx''}}}}&lt;br/&gt;
{{math|{{sfrac|''d''{{i sup|2}}''y''|''dx''{{i sup|2}}}}}}&lt;/div&gt;

{{main|Leibniz's notation}}

The original notation employed by [[Gottfried Leibniz]] is used throughout mathematics. It is particularly common when the equation {{math|''y'' {{=}} ''f''(''x'')}} is regarded as a functional relationship between [[dependent and independent variables]] {{math|''y''}} and {{math|''x''}}. Leibniz's notation makes this relationship explicit by writing the derivative as

:&lt;math&gt;\frac{dy}{dx}.&lt;/math&gt;

The function whose value at {{math|''x''}} is the derivative of {{math|''f''}} at {{math|''x''}} is therefore written

:&lt;math&gt;\frac{df}{dx}(x)\text{ or }\frac{d f(x)}{dx}\text{ or }\frac{d}{dx} f(x).&lt;/math&gt;

Higher derivatives are written as
:&lt;math&gt;\frac{d^2y}{dx^2}, \frac{d^3y}{dx^3}, \frac{d^4y}{dx^4}, \ldots, \frac{d^ny}{dx^n}.&lt;/math&gt;
This is a suggestive notational device that comes from formal manipulations of symbols, as in,
:&lt;math&gt;\frac{d\left(\frac{d\left(\frac{dy}{dx}\right)}{dx}\right)}{dx} = \left(\frac{d}{dx}\right)^3y = \frac{d^3y}{dx^3}.&lt;/math&gt;
Logically speaking, these equalities are not theorems. Instead, they are simply definitions of notation.

The value of the derivative of ''y'' at a point {{math|''x'' {{=}} ''a''}} may be expressed in two ways using Leibniz's notation:

:&lt;math&gt;\left.\frac{dy}{dx}\right|_{x=a} = \frac{dy}{dx}(a)&lt;/math&gt;.

Leibniz's notation allows one to specify the variable for differentiation (in the denominator). This is especially helpful when considering [[partial derivative]]s.  It also makes the [[chain rule]] easy to remember and recognize:

: &lt;math&gt;\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx}.&lt;/math&gt;

Leibniz's notation for differentiation does require assigning a meaning to symbols such as ''dx'' or ''dy'' on their own, and some authors do not attempt to assign these symbols meaning.  Leibniz treated these symbols as [[infinitesimal]]s.  Later authors have assigned them other meanings, such as infinitesimals in [[non-standard analysis]] or [[exterior derivative]]s.

=== Leibniz's notation for antidifferentiation ===
&lt;div style="float:right; margin: 0 0 10px 10px; padding:20px; font-size:250%; background-color: #ffffdd; border:1px solid #aaaaff;"&gt;{{math|∫ ''y'' ''dx''}}&lt;br/&gt;
{{math|∫∫ ''y'' ''dx''{{i sup|2}}}}&lt;/div&gt;

{{for|functions of 2 or more variables|Multiple integral}}

Leibniz introduced the [[integral symbol]] {{math|∫}} in ''Analyseos tetragonisticae pars secunda'' and ''Methodi tangentium inversae exempla'' (both from 1675).  It is now the standard symbol for [[integral|integration]].
: &lt;math&gt;\begin{align}
                                                   \int y'\,dx &amp;= \int f'(x)\,dx = f(x) + C_0 = y + C_0 \\
                                                    \int y\,dx &amp;= \int f(x)\,dx = F(x) + C_1 \\
                                             \int \int y\,dx^2 &amp;= \int \left ( \int y\,dx \right ) dx = \int_{X\times X} f(x)\,dx = \int F(x)\,dx = g(x) + C_2 \\
  \underbrace{\int \dots \int}_{\!\! n} y\,\underbrace{dx \dots dx}_n &amp;= \int_{\underbrace{X\times\cdots\times X}_n} f(x)\,dx = \int s(x)\,dx = S(x) + C_n
\end{align}&lt;/math&gt;

== Lagrange's notation ==
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|''f''{{′}}(''x'')}}&lt;br/&gt;
{{math|''f''&amp;thinsp;″(''x'')}}&lt;/div&gt;

One of the most common modern notations for differentiation is due to [[Joseph Louis Lagrange]].  In Lagrange's notation, a [[prime (symbol)|prime mark]] denotes a derivative.  If ''f'' is a function, then its derivative evaluated at ''x'' is written
:&lt;math&gt;f'(x)&lt;/math&gt;.
Lagrange first used the notation in unpublished works, and it appeared in print in 1770.&lt;ref name="Lagrange"&gt;[[Joseph Louis Lagrange|Lagrange]], ''Nouvelle méthode pour résoudre les équations littérales par le moyen des séries'' (1770), p. 25-26. http://gdz.sub.uni-goettingen.de/dms/load/img/?PID=PPN308900308|LOG_0017&amp;physid=PHYS_0031&lt;/ref&gt;

Higher derivatives are indicated using additional prime marks, as in &lt;math&gt;f''(x)&lt;/math&gt; for the [[second derivative]] and &lt;math&gt;f'''(x)&lt;/math&gt; for the [[third derivative]].  The use of repeated prime marks eventually becomes unwieldy.  Some authors continue by employing [[Roman numeral]]s, as in
:&lt;math&gt;f^{\mathrm{IV}}(x), f^{\mathrm{V}}(x), f^{\mathrm{VI}}(x), \ldots,&lt;/math&gt;
to denote fourth, fifth, sixth, and higher order derivatives.  Other authors use Arabic numerals in parentheses, as in
:&lt;math&gt;f^{(4)}(x), f^{(5)}(x), f^{(6)}(x), \ldots.&lt;/math&gt;
This notation also makes it possible to describe the ''n''th derivative, where ''n'' is a variable.  This is written
:&lt;math&gt;f^{(n)}(x).&lt;/math&gt;

Unicode characters related to Lagrange's notation include
* {{unichar|2032|PRIME|cwith=&amp;#9676;|note=derivative}}
* {{unichar|2033|DOUBLE PRIME|cwith=&amp;#9676;|note=double derivative}}
* {{unichar|2034|TRIPLE PRIME|cwith=&amp;#9676;|note=third derivative}}
* {{unichar|2057|QUADRUPLE PRIME|cwith=&amp;#9676;|note=fourth derivative}}

When there are two independent variables for a function ''f''(''x'',''y''), the following convention may be followed:&lt;ref name="DeMorgan"&gt;''The Differential and Integral Calculus'' ([[Augustus De Morgan]], 1842). pp. 267-268&lt;/ref&gt;&lt;!-- appears as z(x,y) for a function φ(x,y,z) = 0 --&gt;
: &lt;math&gt;\begin{align}
          f^\prime &amp;= \frac{df}{dx} = f_x \\
          f_\prime &amp;= \frac{df}{dy} = f_y \\
  f^{\prime\prime} &amp;= \frac{d^2 f}{dx^2} = f_{xx} \\
   f_\prime^\prime &amp;= \frac{\partial ^2 f}{\partial x \partial y}\ = f_{xy} \\
  f_{\prime\prime} &amp;= \frac{d^2 f}{dy^2} = f_{yy} \,,
\end{align}&lt;/math&gt;

=== Lagrange's notation for antidifferentiation ===
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:250%; background-color:#ffffdd; border:1px solid #aaaaff;"&gt;{{math|''f''&lt;sup style{{=}}"padding-left:0.3em;"&gt;(&amp;minus;1)&lt;/sup&gt;(''x'')}}&lt;br/&gt;
{{math|''f''&lt;sup style{{=}}"padding-left:0.3em;"&gt;(&amp;minus;2)&lt;/sup&gt;(''x'')}}&lt;/div&gt;

When taking the antiderivative, Lagrange followed Leibniz's notation:&lt;ref name="Lagrange" /&gt;
:&lt;math&gt;f(x) = \int f'(x)\,dx = \int y\,dx.&lt;/math&gt;

However, because integration is the inverse of differentiation, Lagrange's notation for higher order derivatives extends to integrals as well.  Repeated integrals of ''f'' may be written as
:&lt;math&gt;f^{(-1)}(x)&lt;/math&gt; for the first integral (this is easily confused with the [[inverse function]] &lt;math&gt;f^{-1}(x)&lt;/math&gt;),
:&lt;math&gt;f^{(-2)}(x)&lt;/math&gt; for the second integral,
:&lt;math&gt;f^{(-3)}(x)&lt;/math&gt; for the third integral, and
:&lt;math&gt;f^{(-n)}(x)&lt;/math&gt; for the ''n''th integral.

== Euler's notation ==
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|''D{{sub|x}}y''}}&lt;br/&gt;
{{math|''D''{{i sup|2}}''f''}}&lt;/div&gt;

[[Leonhard Euler]]'s notation uses a [[differential operator]] suggested by [[Louis François Antoine Arbogast]], denoted as {{math|''D''}} ('''D operator''')&lt;ref&gt;{{cite web|url=http://www.codecogs.com/library/maths/calculus/differential/the-d-operator.php|title=The D operator - Differential - Calculus - Maths Reference with Worked Examples|author=|date=|website=www.codecogs.com|deadurl=no|archiveurl=https://web.archive.org/web/20160119050319/http://www.codecogs.com/library/maths/calculus/differential/the-d-operator.php|archivedate=2016-01-19|df=}}&lt;/ref&gt; or {{math|''D̃''}} ('''Newton–Leibniz operator''')&lt;ref name="EulerMathWorld"&gt;Weisstein, Eric W. "Differential Operator." From ''MathWorld''--A Wolfram Web Resource. {{cite web |url=http://mathworld.wolfram.com/DifferentialOperator.html |title=Archived copy |accessdate=2016-02-07 |deadurl=no |archiveurl=https://web.archive.org/web/20160121215815/http://mathworld.wolfram.com/DifferentialOperator.html |archivedate=2016-01-21 |df= }}&lt;/ref&gt;  When applied to a function {{math|''f''(''x'')}}, it is defined by
:&lt;math&gt;Df = \frac{df}{dx}.&lt;/math&gt;
Higher derivatives are notated as powers of ''D'', as in&lt;ref name="DeMorgan" /&gt;
:&lt;math&gt;D^2f&lt;/math&gt; for the second derivative,
:&lt;math&gt;D^3f&lt;/math&gt; for the third derivative, and
:&lt;math&gt;D^nf&lt;/math&gt; for the ''n''th derivative.

Euler's notation leaves implicit the variable with respect to which differentiation is being done.  However, this variable can also be notated explicitly.  When ''f'' is a function of a variable ''x'', this is done by writing&lt;ref name="DeMorgan"/&gt;
:&lt;math&gt;D_x f&lt;/math&gt; for the first derivative,
:&lt;math&gt;D^2_x f&lt;/math&gt; for the second derivative,
:&lt;math&gt;D^3_x f&lt;/math&gt; for the third derivative, and
:&lt;math&gt;D^n_x f&lt;/math&gt; for the ''n''th derivative.
When ''f'' is a function of several variables, it's common to use a "[[∂]]" rather than {{math|''D''}}. As above, the subscripts denote the derivatives that are being taken. For example, the second partial derivatives of a function {{math|''f''(''x'', ''y'')}} are:&lt;ref name="DeMorgan"/&gt;
:&lt;math&gt;\partial_{xx} f = \frac{\partial^2 f}{\partial x^2},&lt;/math&gt;
:&lt;math&gt;\partial_{xy} f = \frac{\partial^2 f}{\partial x\partial y},&lt;/math&gt;
:&lt;math&gt;\partial_{yx} f = \frac{\partial^2 f}{\partial y\partial x},&lt;/math&gt;
:&lt;math&gt;\partial_{yy} f = \frac{\partial^2 f}{\partial y^2}.&lt;/math&gt;
See {{section link||Partial derivatives}}.

Euler's notation is useful for stating and solving [[linear differential equation]]s, as it simplifies presentation of the differential equation, which can make seeing the essential elements of the problem easier.

=== Euler's notation for antidifferentiation ===
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:250%; background-color:#ffffdd; border:1px solid #aaaaff;"&gt;{{math|''D{{su|p=&amp;minus;1|b=x}}y''}}&lt;br/&gt;
{{math|''D''{{i sup|&amp;minus;2}}''f''}}&lt;/div&gt;

Euler's notation can be used for antidifferentiation in the same way that Lagrange's notation is.&lt;ref&gt;Weisstein, Eric W. "Repeated Integral." From ''MathWorld''--A Wolfram Web Resource. {{cite web |url=http://mathworld.wolfram.com/RepeatedIntegral.html |title=Archived copy |accessdate=2016-02-07 |deadurl=no |archiveurl=https://web.archive.org/web/20160201051403/http://mathworld.wolfram.com/RepeatedIntegral.html |archivedate=2016-02-01 |df= }}&lt;/ref&gt; as follows&lt;ref name="EulerMathWorld" /&gt;
:&lt;math&gt;D^{-1}f(x)&lt;/math&gt; for a first antiderivative,
:&lt;math&gt;D^{-2}f(x)&lt;/math&gt; for a second antiderivative, and
:&lt;math&gt;D^{-n}f(x)&lt;/math&gt; for an ''n''th antiderivative.

== Newton's notation ==
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|''ẋ''}}&lt;br/&gt;
{{math|''ẍ''}}&lt;/div&gt;

[[Isaac Newton|Newton]]'s notation for differentiation (also called the '''dot notation''' for differentiation) places a dot over the dependent variable.  That is, if ''y'' is a function of ''t'', then the derivative of ''y'' with respect to ''t'' is
:&lt;math&gt;\dot y&lt;/math&gt;
Higher derivatives are represented using multiple dots, as in
:&lt;math&gt;\ddot y, \overset{...}{y}&lt;/math&gt;
Newton extended this idea quite far:&lt;ref&gt;Newton's notation reproduced from:
* 1st to 5th derivatives: ''Quadratura curvarum'' ([[Isaac Newton|Newton]], 1704), p. 7 (p. 5r in original MS: {{cite web |url=http://cudl.lib.cam.ac.uk/view/MS-ADD-03962/9 |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20160228002251/http://cudl.lib.cam.ac.uk/view/MS-ADD-03962/9 |archivedate=2016-02-28 |df= }}).
* 1st to 7th, ''n''th and (''n''+1)th derivatives: ''Method of Fluxions'' ([[Isaac Newton|Newton]], 1736), pp. 313-318 and p. 265 (p. 163 in original MS: {{cite web |url=http://cudl.lib.cam.ac.uk/view/MS-ADD-03960/257 |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20170406183849/http://cudl.lib.cam.ac.uk/view/MS-ADD-03960/257 |archivedate=2017-04-06 |df= }})
* 1st to 5th derivatives : ''A Treatise of Fluxions'' (Colin MacLaurin, 1742), p. 613
* 1st to 4th and ''n''th derivatives: Articles "Differential" and "Fluxion", ''Dictionary of Pure and Mixed Mathematics'' (Peter Barlow, 1814)
* 1st to 4th, 10th and ''n''th derivatives: Articles 622, 580 and 579 in ''A History of Mathematical Notations'' (F .Cajori, 1929)
* 1st to 6th and ''n''th derivatives: ''The Mathematical Papers of Isaac Newton'' Vol. 7 1691-1695 (D. T. Whiteside, 1976), pp.88 and 17
* 1st to 3rd and ''n''th derivatives: ''A History of Analysis'' (Hans Niels Jahnke, 2000), pp. 84-85
The dot for ''n''th derivative may be omitted ( &lt;math&gt;\overset{\,n}{y}&lt;/math&gt; )
&lt;/ref&gt;
:&lt;math&gt;\begin{align}
                 \ddot{y} &amp;\equiv \frac{d^2y}{dt^2} = \frac{d}{dt}\left(\frac{dy}{dt}\right)  = \frac{d}{dt}\Bigl(\dot{y}\Bigr) = \frac{d}{dt}\Bigl(f'(t)\Bigr) = D_t^2 y = f''(t) = y''_t \\
         \overset{...}{y} &amp;= \dot{\ddot{y}} \equiv \frac{d^3y}{dt^3} = D_t^3 y = f'''(t) = y'''_t \\
   \overset{\,4}{\dot{y}} &amp;= \overset{....}{y} = \ddot{\ddot{y}} \equiv \frac{d^4y}{dt^4} = D_t^4 y = f^{\rm IV}(t) = y^{(4)}_t \\
   \overset{\,5}{\dot{y}} &amp;= \ddot{\overset{...}{y}} = \dot{\ddot{\ddot{y}}} = \ddot{\dot{\ddot{y}}} \equiv \frac{d^5y}{dt^5} = D_t^5 y = f^{\rm V}(t) = y^{(5)}_t \\
   \overset{\,6}{\dot{y}} &amp;= \overset{...}{\overset{...}{y}} \equiv \frac{d^6y}{dt^6} = D_t^6 y = f^{\rm VI}(t) = y^{(6)}_t \\
   \overset{\,7}{\dot{y}} &amp;= \dot{\overset{...}{\overset{...}{y}}} \equiv \frac{d^7y}{dt^7} = D_t^7 y = f^{\rm VII}(t) = y^{(7)}_t \\
  \overset{\,10}{\dot{y}} &amp;= \ddot{\ddot{\ddot{\ddot{\ddot{y}}}}} \equiv \frac{d^{10}y}{dt^{10}} = D_t^{10} y = f^{\rm X}(t) = y^{(10)}_t \\
   \overset{\,n}{\dot{y}} &amp;\equiv \frac{d^ny}{dt^n} = D_t^n y = f^{(n)}(t) = y^{(n)}_t
\end{align}&lt;/math&gt;

Unicode characters related to Newton's notation include:
* {{unichar|0307|COMBINING DOT ABOVE|cwith=&amp;#9676;|note=derivative}}
* {{unichar|0308|COMBINING DIAERESIS|cwith=&amp;#9676;|note=double derivative}}
* {{unichar|20DB|COMBINING THREE DOTS ABOVE|cwith=&amp;#9676;|note=third derivative}} ← replaced by "combining diaeresis" + "combining dot above".
* {{unichar|20DC|COMBINING FOUR DOTS ABOVE|cwith=&amp;#9676;|note=fourth derivative}} ← replaced by "combining diaeresis" twice.
* {{unichar|030D|COMBINING VERTICAL LINE ABOVE|cwith=&amp;#9676;|note=integral}}
* {{unichar|030E|COMBINING DOUBLE VERTICAL LINE ABOVE|cwith=&amp;#9676;|note=second integral}}
* {{unichar|25AD|WHITE RECTANGLE|note=integral}}
* {{unichar|20DE|COMBINING ENCLOSING SQUARE|cwith=&amp;#9676;|note=integral}}
* {{unichar|1DE0|COMBINING LATIN SMALL LETTER N|cwith=&amp;#9676;|note=''n''th derivative}}

Newton's notation is generally used when the independent variable denotes [[time]].  If location {{math|''y''}} is a function of ''t'', then &lt;math&gt;\dot y&lt;/math&gt; denotes [[velocity]]&lt;ref&gt;Weisstein, Eric W. "Overdot." From ''MathWorld''--A Wolfram Web Resource. {{cite web |url=http://mathworld.wolfram.com/Overdot.html |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20150905171914/http://mathworld.wolfram.com/Overdot.html |archivedate=2015-09-05 |df= }}&lt;/ref&gt; and &lt;math&gt;\ddot y&lt;/math&gt; denotes [[acceleration]].&lt;ref&gt;Weisstein, Eric W. "Double Dot." From ''MathWorld''--A Wolfram Web Resource. {{cite web |url=http://mathworld.wolfram.com/DoubleDot.html |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20160303174226/http://mathworld.wolfram.com/DoubleDot.html |archivedate=2016-03-03 |df= }}&lt;/ref&gt; This notation is popular in [[physics]] and [[mathematical physics]].  It also appears in areas of mathematics connected with physics such as [[differential equation]]s.  It is only popular for first and second derivatives, but in applications these are usually the only derivatives that are necessary.

When taking the derivative of a dependent variable ''y'' = ''f''(''x''), an alternative notation exists:&lt;ref&gt;Article 580 in Florian Cajori, ''A History of Mathematical Notations'' (1929), Dover Publications, Inc. New York. {{isbn|0-486-67766-4}}&lt;/ref&gt;
:&lt;math&gt;\frac{\dot{y}}{\dot{x}} = \dot{y}:\dot{x} \equiv \frac{dy}{dt}:\frac{dx}{dt} = \frac{\frac{dy}{dt}}{\frac{dx}{dt}} = \frac{dy}{dx} = \frac{d}{dt}\Bigl(f(x)\Bigr) = D y = f'(x) = y' &lt;/math&gt;

Newton developed the following partial differential operators using side-dots on a curved X ( ⵋ ). Definitions given by Whiteside are below:&lt;ref&gt;"Patterns of Mathematical Thought in the Later Seventeenth Century", ''Archive for History of Exact Sciences'' Vol. 1, No. 3 (D. T. Whiteside, 1961), pp. 179-388&lt;/ref&gt;&lt;ref&gt;S.B. Engelsman has given more strict definitions in ''Families of Curves and the Origins of Partial Differentiation'' (2000), pp. 223-226&lt;/ref&gt;

: &lt;!-- shape of X must be: ⵋ --&gt;&lt;math&gt;\begin{align}
                                                 \mathcal{X} \ &amp;=\  f(x,y) \,, \\
                                            \cdot\mathcal{X} \ &amp;=\  x\frac{\partial f}{\partial x} = xf_x\,, \\
                                            \mathcal{X}\cdot \ &amp;=\  y\frac{\partial f}{\partial y} = yf_y\,, \\
      \colon\mathcal{X}\,\text{ or }\,\cdot\colon\mathcal{X} \ &amp;=\  x^2\frac{\partial^2 f}{\partial x^2} = x^2 f_{xx}\,, \\
       \mathcal{X}\colon\,\text{ or }\,\cdot\mathcal{X}\cdot \ &amp;=\  y^2\frac{\partial^2 f}{\partial y^2} = y^2 f_{yy}\,, \\
  \cdot\mathcal{X}\cdot\,\text{ or }\,\mathcal{X}\colon\cdot \ &amp;=\  xy\frac{\partial^2 f}{\partial x\partial y} = xy f_{xy}\,,
\end{align}&lt;/math&gt;

=== Newton's notation for integration ===
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:250%; background-color:#ffffdd; border:1px solid #aaaaff;"&gt;{{math|''x̍''}}&lt;br/&gt;
{{math|''x̎''}}&lt;/div&gt;

Newton developed many different notations for [[integral|integration]] in his ''Quadratura curvarum'' (1704) and [[Method of Fluxions|later works]]: he wrote a small vertical bar or prime above the dependent variable ({{math|''y̍''}}), a prefixing rectangle ({{math|▭''y''}}), or the inclosure of the term in a rectangle (&lt;span style="border-style: solid; border-width: 1.5px 1.5px 1.5px 1.5px; padding-left: 4px; padding-right: 4px;"&gt;{{math|''y''}}&lt;/span&gt;) to denote the ''[[Method of Fluxions|fluent]]'' or time integral ([[absement]]).

: &lt;math&gt;\begin{align}
                      y &amp;= \Box \dot{y} \equiv \int \dot{y} \,dt = \int f'(t) \,dt = D_t^{-1} (D_t y) = f(t) + C_0 = y_t + C_0 \\
  \overset{\,\prime}{y} &amp;= \Box y \equiv \int y \,dt = \int f(t) \,dt = D_t^{-1} y = F(t) + C_1
\end{align}&lt;/math&gt;

To denote multiple integrals, Newton used two small vertical bars or primes ({{math|''y̎''}}), or a combination of previous symbols {{math|▭''y̍''}} &amp;ensp;&lt;span style="border-style: solid; border-width: 1.5px 1.5px 1.5px 1.5px; padding-left: 4px; padding-right: 4px;"&gt;{{math|''y̍''}}&lt;/span&gt;, to denote the second time integral ([[absity]]).

: &lt;math&gt;\overset{\,\prime\prime}{y} = \Box \overset{\,\prime}{y} \equiv \int \overset{\,\prime}{y} \,dt = \int F(t) \,dt = D_t^{-2} y = g(t) + C_2&lt;/math&gt;

Higher order time integrals were as follows:&lt;ref&gt;Newton's notation for integration reproduced from:
* 1st to 3rd integrals: ''Quadratura curvarum'' ([[Isaac Newton|Newton]], 1704), p. 7 (p. 5r in original MS: {{cite web |url=http://cudl.lib.cam.ac.uk/view/MS-ADD-03962/9 |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20160228002251/http://cudl.lib.cam.ac.uk/view/MS-ADD-03962/9 |archivedate=2016-02-28 |df= }})
* 1st to 3rd integrals: ''Method of Fluxions'' ([[Isaac Newton|Newton]], 1736), pp. 265-266 (p. 163 in original MS: {{cite web |url=http://cudl.lib.cam.ac.uk/view/MS-ADD-03960/257 |title=Archived copy |accessdate=2016-02-05 |deadurl=no |archiveurl=https://web.archive.org/web/20170406183849/http://cudl.lib.cam.ac.uk/view/MS-ADD-03960/257 |archivedate=2017-04-06 |df= }})
* 4th integrals: ''The Doctrine of Fluxions'' (James Hodgson, 1736), pp. 54 and 72
* 1st to 2nd integrals: Articles 622 and 365 in ''A History of Mathematical Notations'' (F .Cajori, 1929)
The ''n''th integral notation is deducted from the ''n''th derivative. It could be used in ''Methodus Incrementorum Directa &amp; Inversa'' (Brook Taylor, 1715)&lt;/ref&gt;
: &lt;math&gt;\begin{align}
        \overset{\,\prime\prime\prime}{y} &amp;= \Box \overset{\,\prime\prime}{y} \equiv \int \overset{\,\prime\prime}{y} \,dt = \int g(t) \,dt = D_t^{-3} y = G(t) + C_3 \\
  \overset{\,\prime\prime\prime\prime}{y} &amp;= \Box \overset{\,\prime\prime\prime}{y} \equiv \int \overset{\,\prime\prime\prime}{y} \,dt = \int G(t) \,dt = D_t^{-4} y = h(t) + C_4 \\
       \overset{\;n}\overset{\,\prime}{y} &amp;= \Box \overset{\;n-1}\overset{\,\prime}y \equiv \int \overset{\;n-1}\overset{\,\prime}y \,dt = \int s(t) \,dt = D_t^{-n} y = S(t) + C_n
\end{align}&lt;/math&gt;

This [[mathematical notation]] did not become widespread because of printing difficulties and the [[Leibniz–Newton calculus controversy]].

== Partial derivatives ==
&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|''f{{sub|x}}''}}&lt;br/&gt;
{{math|''f{{sub|xy}}''}}&lt;/div&gt;

When more specific types of differentiation are necessary, such as in [[multivariate calculus]] or [[tensor analysis]], other notations are common.

For a function ''f''(''x''), we can express the derivative using subscripts of the independent variable:

: &lt;math&gt;\begin{align}
      f_x &amp;= \frac{df}{dx} \\
  f_{x x} &amp;= \frac{d^2f}{dx^2}.
\end{align}&lt;/math&gt;

This type of notation is especially useful for taking [[partial derivatives]] of a function of several variables.

&lt;div style="float:right; margin: 0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|{{sfrac|''∂f''|''∂x''}}}}&lt;/div&gt;

Partial derivatives are generally distinguished from ordinary derivatives by replacing the differential operator ''d'' with a "[[∂]]" symbol. For example, we can indicate the partial derivative of {{nowrap|''f''(''x'', ''y'', ''z'')}} with respect to ''x'', but not to ''y'' or ''z'' in several ways:

:&lt;math&gt;\frac{\partial f}{\partial x} = f_x = \partial_x f.&lt;/math&gt;

Other notations can be found in various subfields of mathematics, physics, and engineering, see for example the [[Maxwell relations]] of [[thermodynamics]]. The symbol &lt;math&gt;\left(\frac{\partial T}{\partial V}\right)_S &lt;/math&gt; is the derivative of the temperature ''T'' with respect to the volume ''V'' while keeping constant the entropy (subscript) ''S'', while &lt;math&gt;\left(\frac{\partial T}{\partial V}\right)_P &lt;/math&gt; is the derivative of the temperature with respect to the volume while keeping constant the pressure ''P''.

Higher-order partial derivatives with respect to one variable are expressed as

:&lt;math&gt;  \frac{\partial^2f}{\partial x^2}= f_{xx} &lt;/math&gt;
:&lt;math&gt;  \frac{\partial^3f}{\partial x^3} =f_{xxx}.&lt;/math&gt;

Mixed partial derivatives can be expressed as

:&lt;math&gt;\frac{\partial^2f}{\partial y \partial x} = f_{xy}.&lt;/math&gt;

In this last case the variables are written in inverse order between the two notations, explained as follows:

:&lt;math&gt;(f_{x})_{y}=f_{xy} &lt;/math&gt;
:&lt;math&gt;\frac{\partial}{\partial y}\left(\frac{\partial f}{\partial x}\right)= \frac{\partial^2f}{\partial y \partial x}&lt;/math&gt;

== Notation in vector calculus ==

[[Vector calculus]] concerns [[derivative|differentiation]] and [[integral|integration]] of [[vector field|vector]] or [[scalar fields|scalar]] fields.  Several notations specific to the case of three-dimensional [[Euclidean space]] are common.

Assume that {{math|(''x'', ''y'', ''z'')}} is a given [[Cartesian coordinate system]], that '''A''' is a [[vector field]] with components &lt;math&gt;\mathbf{A} = (\mathbf{A}_x, \mathbf{A}_y, \mathbf{A}_z)&lt;/math&gt;, and that &lt;math&gt;\varphi = \varphi(x,y,z)&lt;/math&gt; is a [[scalar field]].

The differential operator introduced by [[William Rowan Hamilton]], written [[nabla symbol|∇]] and called [[del]] or nabla, is symbolically defined in the form of a vector,
:&lt;math&gt;\nabla = \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z} \right),&lt;/math&gt;
where the terminology ''symbolically'' reflects that the operator ∇ will also be treated as an ordinary vector.

&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|∇''φ''}}&lt;/div&gt;
* '''[[Gradient]]''': The gradient &lt;math&gt;\mathrm{grad\,} \varphi&lt;/math&gt; of the scalar field &lt;math&gt;\varphi&lt;/math&gt; is a vector, which is symbolically expressed by the [[scalar multiplication|multiplication]] of ∇ and scalar field ''&lt;math&gt;\varphi&lt;/math&gt;'',

::&lt;math&gt;\begin{align}
  \operatorname{grad} \varphi
    &amp;= \left( \frac{\partial \varphi}{\partial x}, \frac{\partial \varphi}{\partial y}, \frac{\partial \varphi}{\partial z} \right) \\
    &amp;= \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z} \right) \varphi \\
    &amp;= \nabla \varphi
\end{align}&lt;/math&gt;

&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color: #ddddff; border:1px solid #aaaaff;"&gt;{{math|∇∙'''A'''}}&lt;/div&gt;
* '''[[Divergence]]''': The divergence &lt;math&gt;\mathrm{div}\,\mathbf{A}&lt;/math&gt; of the vector field '''A''' is a scalar, which is symbolically expressed by the [[dot product]] of ∇ and the vector '''A''',

:: &lt;math&gt;\begin{align}
  \operatorname{div} \mathbf{A}
    &amp;= {\partial A_x \over \partial x} + {\partial A_y \over \partial y} + {\partial A_z \over \partial z} \\
    &amp;= \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z} \right)  \cdot \mathbf{A} \\
    &amp;= \nabla \cdot \mathbf{A}
\end{align}&lt;/math&gt;

&lt;div style="float:right; margin:0 0 0px 0px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|∇{{sup|2}}''φ''}}&lt;/div&gt;
* '''[[Laplacian]]''': The Laplacian &lt;math&gt;\operatorname{div} \operatorname{grad} \varphi&lt;/math&gt; of the scalar field &lt;math&gt;\varphi&lt;/math&gt; is a scalar, which is symbolically expressed by the scalar multiplication of ∇&lt;sup&gt;2&lt;/sup&gt; and the scalar field ''φ'',

:: &lt;math&gt;\begin{align}
  \operatorname{div} \operatorname{grad} \varphi
    &amp;= \nabla \cdot (\nabla \varphi) \\
    &amp;= (\nabla \cdot \nabla) \varphi \\
    &amp;= \nabla^2 \varphi \\
    &amp;= \Delta \varphi \\
\end{align}&lt;/math&gt;

&lt;div style="float:right; margin:0 0 10px 10px; padding:20px; font-size:300%; background-color:#ddddff; border:1px solid #aaaaff;"&gt;{{math|∇×'''A'''}}&lt;/div&gt;
* '''[[Curl (mathematics)|Rotation]]''': The rotation &lt;math&gt;\mathrm{curl}\,\mathbf{A}&lt;/math&gt;, or &lt;math&gt;\mathrm{rot}\,\mathbf{A}&lt;/math&gt;, of the vector field '''A''' is a vector, which is symbolically expressed by the [[cross product]] of ∇ and the vector '''A''',

:: &lt;math&gt;\begin{align}
  \operatorname{curl} \mathbf{A}
    &amp;= \left(
         {\partial A_z \over {\partial y} } - {\partial A_y \over {\partial z} },
         {\partial A_x \over {\partial z} } - {\partial A_z \over {\partial x} },
         {\partial A_y \over {\partial x} } - {\partial A_x \over {\partial y} }
       \right) \\
    &amp;= \left( {\partial A_z \over {\partial y} } - {\partial A_y \over {\partial z} } \right) \mathbf{i} +
       \left( {\partial A_x \over {\partial z} } - {\partial A_z \over {\partial x} } \right) \mathbf{j} +
       \left( {\partial A_y \over {\partial x} } - {\partial A_x \over {\partial y} } \right) \mathbf{k} \\
    &amp;= \begin{vmatrix}
         \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\
         \cfrac{\partial}{\partial x} &amp; \cfrac{\partial}{\partial y} &amp; \cfrac{\partial}{\partial z} \\
         A_x &amp; A_y &amp; A_z
       \end{vmatrix} \\
    &amp;= \nabla \times \mathbf{A}
\end{align}&lt;/math&gt;

Many symbolic operations of derivatives can be generalized in a straightforward manner by the gradient operator in Cartesian coordinates. For example, the single-variable [[product rule]] has a direct analogue in the multiplication of scalar fields by applying the gradient operator, as in

:&lt;math&gt;(f g)' = f' g+f g' ~~~ \Longrightarrow ~~~ \nabla(\phi \psi) = (\nabla \phi) \psi + \phi (\nabla \psi).&lt;/math&gt;

Further notations have been developed for more exotic types of spaces. For calculations in [[Minkowski space]], the [[d'Alembert operator]], also called the d'Alembertian, wave operator, or box operator is represented as &lt;math&gt;\Box&lt;/math&gt;, or as &lt;math&gt;\Delta&lt;/math&gt; when not in conflict with the symbol for the Laplacian.

==See also==
* [[Analytical Society]]
* [[Derivative]]
* [[Jacobian matrix]]
* [[Hessian matrix]]

==References==
{{reflist|2}}

==External links==
*[http://jeff560.tripod.com/calculus.html Earliest Uses of Symbols of Calculus], maintained by Jeff Miller.
{{Differential equations topics}}
[[Category:Differential calculus]]
[[Category:Mathematical notation]]</text>
      <sha1>l1l1ouh8oeabuh2ycuf17xv6nvihj92</sha1>
    </revision>
  </page>
  <page>
    <title>Orthogonal functions</title>
    <ns>0</ns>
    <id>453041</id>
    <revision>
      <id>848162873</id>
      <parentid>837706772</parentid>
      <timestamp>2018-06-30T04:37:46Z</timestamp>
      <contributor>
        <username>Myasuda</username>
        <id>1187538</id>
      </contributor>
      <minor/>
      <comment>/* See also */ added missing diacritic</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4982">In [[mathematics]], '''orthogonal functions''' belong to a [[function space]] which is a [[vector space]] that has a [[bilinear form]]. When the function space has an [[interval (mathematics)|interval]] as the [[domain of a function|domain]], the bilinear form may be the [[integral]] of the product of functions over the interval:
:&lt;math&gt; \langle f,g\rangle = \int \overline{f(x)}g(x)\,dx  .&lt;/math&gt;

The functions &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; are [[bilinear form#Reflexivity and orthogonality|orthogonal]] when this integral is zero, i.e. &lt;math&gt;\langle f, \ g \rangle = 0&lt;/math&gt; whenever &lt;math&gt;f \neq g&lt;/math&gt;. 
As with a [[basis (linear algebra)|basis]] of vectors in a finite-dimensional space, orthogonal functions can form an infinite basis for a function space.

Suppose &lt;math&gt; \{ f_0, f_1, \ldots\}&lt;/math&gt; is a sequence of orthogonal functions of nonzero [[L2-norm|''L''&lt;sup&gt;2&lt;/sup&gt;-norm]]s &lt;math&gt; \Vert f_n \Vert _2 = \sqrt{\langle f_n, f_n \rangle} = \left(\int f_n ^2 \ dx \right) ^\frac{1}{2} &lt;/math&gt;.  It follows that the sequence &lt;math&gt;\left\{ f_n / \Vert f_n \Vert _2 \right\}&lt;/math&gt; is of functions of ''L''&lt;sup&gt;2&lt;/sup&gt;-norm one, forming an [[orthonormal sequence]].  To have a defined ''L''&lt;sup&gt;2&lt;/sup&gt;-norm, the integral must be bounded, which restricts the functions to being [[square-integrable function|square-integrable]].

==Trigonometric functions==
{{Main article|Fourier series|Harmonic analysis}}
Several sets of orthogonal functions have become standard bases for approximating functions. For example, the sine functions {{nowrap|sin ''nx''}} and {{nowrap|sin ''mx''}} are orthogonal on the interval &lt;math&gt;(-\pi, \pi)&lt;/math&gt; when &lt;math&gt;m \neq n&lt;/math&gt;. For then 
:&lt;math&gt;2 \sin (mx) \sin (nx) = \cos \left((m - n)x\right) - \cos\left((m+n) x\right), &lt;/math&gt;
and the integral of the product of the two sine functions vanishes.&lt;ref&gt;[[Antoni Zygmund]] (1935) ''Trigonometrical Series'', page 6, Mathematical Seminar, University of Warsaw&lt;/ref&gt; Together with cosine functions, these orthogonal functions may be assembled into a [[trigonometric polynomial]] to approximate a given function on the interval with its [[Fourier series]].

==Polynomials==
{{main article|Orthogonal polynomials}}
If one begins with the [[monomial]] sequence &lt;math&gt; \{1, x, x^2, \dots\} &lt;/math&gt; on the interval &lt;math&gt;[-1,1]&lt;/math&gt; and applies the [[Gram–Schmidt process]], then one obtains the [[Legendre polynomial]]s. Another collection of orthogonal polynomials are the [[associated Legendre polynomials]].

The study of orthogonal polynomials involves [[weight function]]s &lt;math&gt;w(x)&lt;/math&gt; that are inserted in the bilinear form:
:&lt;math&gt; \langle f,g\rangle = \int w(x) f(x) g(x)\,dx  .&lt;/math&gt;
For [[Laguerre polynomial]]s on &lt;math&gt;(0,\infty)&lt;/math&gt; the weight function is &lt;math&gt;w(x) = e^{-x}&lt;/math&gt;.

Both physicists and probability theorists use [[Hermite polynomial]]s on &lt;math&gt;(-\infty,\infty)&lt;/math&gt;, where the weight function is &lt;math&gt;w(x) = e^{-x^2}&lt;/math&gt; or &lt;math&gt;w(x) = e^{- \frac {x^2}{2}} .&lt;/math&gt;

[[Chebyshev polynomial]]s are defined on &lt;math&gt;[-1,1]&lt;/math&gt; and use weights &lt;math&gt;w(x) = \frac{1}{\sqrt{1 - x^2}}&lt;/math&gt; or &lt;math&gt;w(x) = \sqrt{1 - x^2}&lt;/math&gt;.

[[Zernike polynomial]]s are defined on the [[unit disk]] and have orthogonality of both radial and angular parts.

==Binary-valued functions==
[[Walsh function]]s and [[Haar wavelet]]s are examples of orthogonal functions with discrete ranges.

==Rational functions==
[[File:ChebychevRational1.png|thumb|Plot of the Chebyshev rational functions of order n=0,1,2,3 and 4 between x=0.01 and 100.]]
Legendre and Chebyshev polynomials provide orthogonal families for the interval {{nowrap|[−1, 1]}} while occasionally orthogonal families are required on {{nowrap|[0, ∞)}}. In this case it is convenient to apply the [[Cayley transform#Real homography|Cayley transform]] first, to bring the argument into {{nowrap|[−1, 1]}}. This procedure results in families of [[rational function|rational]] orthogonal functions called [[Legendre rational functions]] and [[Chebyshev rational functions]].

==In differential equations==
Solutions of linear [[differential equation]]s with boundary conditions can often be written as a weighted sum of orthogonal solution functions (a.k.a. [[eigenfunction]]s), leading to [[generalized Fourier series]].

==See also==
* [[Hilbert space]]
* [[Eigenvalues and eigenvectors]]
* [[Wannier function]]
* [[Lauricella's theorem]]
* [[Karhunen–Loève theorem]]

==References==
{{reflist}}
* George B. Arfken &amp; Hans J. Weber (2005) ''Mathematical Methods for Physicists'', 6th edition, chapter 10: Sturm-Liouville Theory — Orthogonal Functions, [[Academic Press]].
* [[Giovanni Sansone]]  (translated by Ainsley H. Diamond) (1959) ''Orthogonal Functions'', [[Interscience Publishers]].  
== External links ==
* [http://mathworld.wolfram.com/OrthogonalFunctions.html Orthogonal Functions], on MathWorld.

[[Category:Functional analysis]]
[[Category:Types of functions]]</text>
      <sha1>dnfz28cvye5vr2trhiwcm8hatxhit5u</sha1>
    </revision>
  </page>
  <page>
    <title>Persistence (computer science)</title>
    <ns>0</ns>
    <id>6025550</id>
    <revision>
      <id>846026807</id>
      <parentid>838344093</parentid>
      <timestamp>2018-06-15T20:01:04Z</timestamp>
      <contributor>
        <username>Theo Mark</username>
        <id>2448142</id>
      </contributor>
      <minor/>
      <comment>/* Journals */copy edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6882">{{about|state outliving processes|immutable data structures|Persistent data structure|concepts relating to the persistence of memory|The Persistence of Memory (disambiguation)}}
{{refimprove|date=September 2014}}
In [[computer science]], '''persistence''' refers to the characteristic of [[State (computer science)|state]] that outlives the [[Process (computing)|process]] that created it. This is achieved in practice by storing the state as data in [[computer data storage]]. Programs have to transfer data to and from storage devices and have to provide mappings from the native [[Programming language|programming-language]] [[Data structure|data structures]] to the storage device data structures.&lt;ref&gt;{{Cite web|url = http://people.inf.ethz.ch/balzers/publications/contracted_persistent_object_programming.pdf|title = Contracted Persistent Object Programming|date = November 17, 2005|accessdate = September 21, 2015|website = University of Glasgow - School of CS - Research|publisher = ETH Zürich|last = Balzer|first = Stephanie}}&lt;/ref&gt;

Picture editing programs or [[Word processor|word processors]], for example, achieve [[State (computer science)|state]] persistence by saving their documents to [[computer file|files]].

== Orthogonal or transparent persistence==
Persistence is said to be "[[Orthogonality#Computer science|orthogonal]]" or "transparent" when it is implemented as an intrinsic property of the execution environment of a program. An orthogonal persistence environment does not require any specific actions by programs running in it to retrieve or save their [[State (computer science)|state]].

Non-orthogonal persistence requires data to be written and read to and from storage using specific instructions in a program, resulting in the use of ''persist'' as a transitive verb: ''On completion, the program persists the data''.

The advantage of orthogonal persistence environments is simpler and less error-prone programs.{{Citation needed|date=April 2015}}

===Adoption===
Orthogonal persistence is widely adopted in operating systems for [[Hibernation (computing)|hibernation]] and in [[platform virtualization]] systems such as [[VMware]] and [[VirtualBox]] for state saving.

Research prototype languages such as [[PS-algol]], [[Napier88]], Fibonacci and pJama, successfully demonstrated the concepts along with the advantages to programmers.

==Persistence techniques==

===System images===
{{Main|System image}}
Using [[system image]]s is the simplest persistence strategy. Notebook [[Hibernate (OS feature)|hibernation]] is an example of orthogonal persistence using a system image because it does not require any actions by the programs running on the machine. An example of non-orthogonal persistence using a system image is a simple text editing program executing specific instructions to save an entire document to a file.

'''Shortcomings''': Requires enough RAM to hold the entire system state. State changes made to a system after its last image was saved are lost in the case of a system failure or shutdown. Saving an image for every single change would be too time-consuming for most systems, so images are not used as the single persistence technique for critical systems.

===Journals===
{{Main|Journal (computing)}}
Using journals is the second simplest persistence technique. Journaling is the process of storing events in a log before each one is applied to a system. Such logs are called journals.

On startup, the journal is read and each event is reapplied to the system, avoiding data loss in the case of system failure or shutdown.

The entire "Undo/Redo" history of user commands in a picture editing program, for example, when written to a file, constitutes a journal capable of recovering the state of an edited picture at any point in time.

Journals are used by [[journaling file system]]s, [[System Prevalence|prevalent systems]] and [[database management system]]s where they are also called "transaction logs" or "redo logs".

'''Shortcomings''': Journals are often combined with other persistence techniques so that the entire (potentially large) history of all system events does not have to be reapplied on system startup.

===Dirty writes===
This technique is the writing to storage of only those portions of system state that have been modified (are dirty) since their last write. Sophisticated document editing applications, for example, will use dirty writes to save only those portions of a document that were actually changed since the last save.

'''Shortcomings:''' This technique requires state changes to be intercepted within a program. This is achieved in a non-transparent way by requiring specific storage-API calls or in a transparent way with automatic [[program transformation]]. This results in code that is slower than native code and more complicated to debug.

== Persistence layers ==
Any [[Layer (object-oriented design)|software layer]] that makes it easier for a program to persist its state is generically called a persistence layer. Most persistence layers will not achieve persistence directly but will use an underlying [[database management system]].

==System prevalence==
{{Main|System Prevalence}}
System prevalence is a technique that combines system images and transaction journals, mentioned above, to overcome their limitations.

'''Shortcomings:''' A prevalent system must have enough [[RAM]] to hold the entire system state.

== Database management systems (DBMSs) ==
{{Main|DBMS}}
[[DBMS]]s use a combination of the dirty writes and transaction journaling techniques mentioned above. They provide not only persistence but also other services such as queries, auditing and access control.

==Persistent operating systems==
Persistent operating systems are [[operating system]]s that remain persistent even after a crash or unexpected shutdown. Operating systems that employ this ability include
* [[KeyKOS]]
* [[Extremely Reliable Operating System|EROS]], the successor to KeyKOS
* [[CapROS]], revisions of EROS
* [[Coyotos]], successor to EROS
* [[Multics]] with its [[single-level store]]
* [[Phantom OS|Phantom]]
* [[IBM System/38]]
* [[Grasshopper OS]] [https://web.archive.org/web/20150704211338/http://www-os.dcs.st-and.ac.uk/GH/ ]
* [[Lua OS]]
* [[tahrpuppy-6.0.5]]

== See also==
* [[Persistent data]]
* [[Persistent data structure]]
* [[Persistent identifier]]
* [[Persistent memory]]
* [[Copy-on-write]]
* [[Create, read, update and delete|CRUD]]
* [[Java Data Objects]]
* [[Java Persistence API]]
* [[System Prevalence]]
* [[Orthogonality#Computer science|Orthogonality]]
* [[Service Data Object]]
* [[Snapshot (computer storage)]]

== References ==
&lt;references /&gt;

{{Authority control}}

{{DEFAULTSORT:Persistence (Computer Science)}}
[[Category:Persistence| ]]
[[Category:Computing terminology]]
[[Category:Computer programming]]
[[Category:Models of computation]]</text>
      <sha1>4re3fra5qy8q9wbw74u8f8hwlnbbc45</sha1>
    </revision>
  </page>
  <page>
    <title>Point-finite collection</title>
    <ns>0</ns>
    <id>9856577</id>
    <revision>
      <id>746708016</id>
      <parentid>614167886</parentid>
      <timestamp>2016-10-29T01:37:59Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1111">In [[mathematics]], a collection &lt;math&gt;\mathcal{U}&lt;/math&gt; of subsets of a [[topological space]] &lt;math&gt;X&lt;/math&gt; is said to be '''point finite''' or a '''point finite collection''' if every point of &lt;math&gt;X&lt;/math&gt; lies in only finitely many members of &lt;math&gt;\mathcal{U}&lt;/math&gt;.&lt;ref name="w"&gt;{{citation|title=General Topology|series=Dover Books on Mathematics|first=Stephen|last=Willard|publisher=Courier Dover Publications|year=2012|pages=145–152|url=https://books.google.com/books?id=UrsHbOjiR8QC&amp;pg=PA145|isbn=9780486131788}}.&lt;/ref&gt;
 
A topological space in which every [[open cover]] admits a point-finite open [[refinement (topology)|refinement]] is called [[metacompact space|metacompact]]. Every [[locally finite collection]] of subsets of a topological space is also point finite. A topological space in which every open cover admits a locally finite open refinement is called [[paracompact space|paracompact]]. Every paracompact space is metacompact.&lt;ref name="w"/&gt;

==References==
{{reflist}}


{{PlanetMath attribution|id = 8398|title = point finite}}

[[Category:General topology]]

{{topology-stub}}</text>
      <sha1>in21vnk1g56c2oxrkup5lir2b7tne2g</sha1>
    </revision>
  </page>
  <page>
    <title>Prehomogeneous vector space</title>
    <ns>0</ns>
    <id>13760785</id>
    <revision>
      <id>855766571</id>
      <parentid>842552697</parentid>
      <timestamp>2018-08-20T17:54:52Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Replaced the phrasing 'it is also interesting to study' - see [[Wikipedia:Manual_of_Style/Words_to_watch#editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17415">In mathematics, a '''prehomogeneous vector space (PVS)''' is a finite-dimensional [[vector space]] ''V'' together with a subgroup ''G'' of the [[general linear group]] GL(''V'') such that ''G'' has an open dense [[orbit (group theory)|orbit]] in ''V''. Prehomogeneous vector spaces were introduced by [[Mikio Sato]] in 1970 and have many applications in [[geometry]], [[number theory]] and [[analysis]], as well as [[representation theory]]. The irreducible PVS were classified by Sato and Tatsuo Kimura in 1977, up to a transformation known as "castling". They are subdivided into two types, according to whether the semisimple part of ''G'' acts prehomogeneously or not. If it doesn't then there is a homogeneous polynomial on ''V'' which is invariant under the semisimple part of ''G''.

==Setting==

In the setting of Sato, ''G'' is an [[algebraic group]] and ''V'' is a rational representation of ''G'' which has a (nonempty) open orbit in the [[Zariski topology]]. However, PVS can also be studied from the point of view of Lie theory: for instance, in Knapp (2002), ''G'' is a complex Lie group and ''V'' is a holomorphic representation of ''G'' with an open dense orbit. The two approaches are essentially the same, and the theory has validity over the real numbers. We assume, for simplicity of notation, that the action of ''G'' on ''V'' is a [[faithful representation]]. We can then identify ''G'' with its image in GL(''V''), although in practice it is sometimes convenient to let ''G'' be a [[covering group]].

Although prehomogeneous vector spaces do not necessarily decompose into direct sums of irreducibles, it is natural to study the irreducible PVS (i.e., when ''V'' is an irreducible representation of ''G''). In this case, a theorem of [[Élie Cartan]] shows that

:''G'' ≤ GL(''V'')

is a [[reductive group]], with a [[centre (group theory)|centre]] that is at most one-dimensional. This, together with the obvious dimensional restriction

:dim ''G'' ≥ dim ''V'',

is the key ingredient in the Sato–Kimura classification.

==Castling==

The classification of PVS is complicated by the following fact. Suppose ''m''&amp;nbsp;&gt;&amp;nbsp;''n''&amp;nbsp;&gt;&amp;nbsp;0 and ''V'' is an ''m''-dimensional representation of ''G'' over a field F. Then:
:&lt;math&gt; (G\times SL(n), V\otimes\mathbb F^n) &lt;/math&gt; is a PVS if and only if &lt;math&gt; (G\times SL(m-n), V^*\otimes \mathbb F^{m-n})&lt;/math&gt; is a PVS.
The proof is to observe that both conditions are equivalent to there being an open dense orbit of the action of ''G'' on the [[Grassmannian]] of
''n''-planes in ''V'', because this is isomorphic to the [[Grassmannian]] of (''m''-''n'')-planes in ''V''&lt;sup&gt;*&lt;/sup&gt;.

(In the case that ''G'' is reductive, the pair (''G'',''V'') is equivalent to the pair (''G'', ''V''&lt;sup&gt;*&lt;/sup&gt;) by an automorphism of ''G''.)

This transformation of PVS is called [[castling]]. Given a PVS ''V'', a new PVS can be obtained by tensoring ''V'' with F and castling. By repeating this process, and regrouping tensor products, many new examples can be obtained, which are said to be "castling-equivalent". Thus PVS can be grouped into castling equivalence classes. Sato and Kimura show that in each such class, there is essentially one PVS of minimal dimension, which they call "reduced", and they classify the reduced irreducible PVS.

==Classification==

The classification of irreducible reduced PVS (''G'',''V'') splits into two cases: those for which ''G'' is semisimple, and those for which it is reductive with one-dimensional centre. If ''G'' is semisimple, it is (perhaps a covering of) a subgroup of SL(''V''), and hence ''G''×GL(1) acts prehomogenously on ''V'', with one-dimensional centre. We exclude such trivial extensions of semisimple PVS from the PVS with one-dimensional center. In other words, in the case that ''G'' has one-dimensional center, we assume that the semisimple part does ''not'' act prehomogeneously; it follows that there is a ''relative invariant'', i.e., a function invariant under the semisimple part of ''G'', which is homogeneous of a certain degree ''d''.

This makes it possible to restrict attention to semisimple ''G'' ≤ SL(''V'') and split the classification as follows:
# (''G'',''V'') is a PVS;
# (''G'',''V'') is not a PVS, but (''G''×GL(1),''V'') is.

However, it turns out that the classification is much shorter, if one allows not just products with GL(1), but also with SL(''n'') and GL(''n''). This is quite natural in terms of the castling transformation discussed previously. Thus we wish to classify irreducible reduced PVS in terms of semisimple ''G'' ≤ SL(''V'') and ''n'' ≥ 1 such that either:
# &lt;math&gt;(G\times SL(n),V\otimes \mathbb F^n)&lt;/math&gt; is a PVS;
# &lt;math&gt;(G\times SL(n),V\otimes \mathbb F^n)&lt;/math&gt; is not a PVS, but &lt;math&gt;(G\times GL(n),V\otimes \mathbb F^n)&lt;/math&gt; is.

In the latter case, there is a [[homogeneous polynomial]] which separates the ''G''×GL(''n'') orbits into ''G''×SL(n) orbits.

This has an interpretation in terms of the grassmannian Gr&lt;sub&gt;''n''&lt;/sub&gt;(''V'') of ''n''-planes in ''V'' (at least for ''n'' ≤ dim ''V''). In both cases ''G'' acts on Gr&lt;sub&gt;''n''&lt;/sub&gt;(''V'') with a dense open orbit ''U''. In the first case the complement Gr&lt;sub&gt;''n''&lt;/sub&gt;(''V'')-''U'' has [[codimension]] ≥ 2; in the second case it is a [[divisor (algebraic geometry)|divisor]] of some degree ''d'', and the relative invariant is a homogeneous polynomial of degree ''nd''.

In the following, the classification list will be presented over the complex numbers.

===General examples===

{| class="wikitable"
|-
! G
! V
! Type 1
! Type 2
! Type 2 isotropy group
! Degree
|-
| &lt;math&gt;G \subseteq SL(m,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^m&lt;/math&gt;
| ''n'' ≥ ''m''+1
| ''n'' = ''m''
| &lt;math&gt;G&lt;/math&gt;
| ''m''
|-
| &lt;math&gt;SL(m,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^m&lt;/math&gt;
| ''m''-1 ≥ ''n'' ≥ 1&lt;sup&gt;*&lt;/sup&gt;
| 
| 
|-
| &lt;math&gt;SL(m,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\Lambda^2\mathbb C^m&lt;/math&gt;
| ''m'' odd, ''n'' = 1,2
| ''m'' even, ''n'' = 1
| &lt;math&gt;Sp(m,\mathbb C)&lt;/math&gt;
| ''m''/2
|-
| &lt;math&gt;SL(m,\mathbb C) &lt;/math&gt;
| &lt;math&gt;S^2\mathbb C^m&lt;/math&gt;
| 
| ''n'' = 1
| &lt;math&gt; SO(m,\mathbb C) &lt;/math&gt;
| ''m''
|-
| &lt;math&gt;SO(m,\mathbb C) &lt;/math&gt;
| &lt;math&gt; \mathbb C^m&lt;/math&gt;
| 
| ''m''-1 ≥ ''n'' ≥ 1&lt;sup&gt;*&lt;/sup&gt;
| &lt;math&gt;SO(n,\mathbb C)\times SO(m-n,\mathbb C)&lt;/math&gt;
| 2
|-
| &lt;math&gt;Sp(2m,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^{2m}&lt;/math&gt;
| 2''m''-1 ≥ ''n'' ≥ 1&lt;sup&gt;*&lt;/sup&gt;, ''n'' odd
| 2''m''-1 ≥ ''n'' ≥ 1&lt;sup&gt;*&lt;/sup&gt;, ''n'' even
| &lt;math&gt;Sp(n,\mathbb C)\times Sp(2m-n,\mathbb C)&lt;/math&gt;
| 1
|}
&lt;sup&gt;*&lt;/sup&gt; Strictly speaking, we must restrict to ''n'' ≤ (dim ''V'')/2 to obtain a reduced example.

===Irregular examples===

'''Type 1'''

: &lt;math&gt; Spin(10,\mathbb C) \quad\mathrm{on}\quad \mathbb C^{16}&lt;/math&gt;

'''Type 2'''

: &lt;math&gt; Sp(2m,\mathbb C)\times SO(3,\mathbb C) \quad\mathrm{on}\quad \mathbb C^{2m}\otimes\mathbb C^3&lt;/math&gt;

Both of these examples are PVS only for ''n''=1.

===Remaining examples===

The remaining examples are all type 2. To avoid discussing the finite groups appearing, the lists present the [[Lie algebra]] of the isotropy group rather than the isotropy group itself.

{| class="wikitable"
|-
! G
! V
! n
! Isotropy algebra
! Degree
|-
| &lt;math&gt; SL(2,\mathbb C)&lt;/math&gt;
| &lt;math&gt; S^3\mathbb C^2&lt;/math&gt;
| 1
| 0
| 4
|-
| &lt;math&gt; SL(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^3\mathbb C^6&lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak{sl}(3,\mathbb C)\times\mathfrak{sl}(3,\mathbb C)&lt;/math&gt;
| 4
|-
| &lt;math&gt; SL(7,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^3\mathbb C^7&lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak g_2^{\mathbb C}&lt;/math&gt;
| 7
|-
| &lt;math&gt; SL(8,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^3\mathbb C^8&lt;/math&gt;
| 1
| &lt;math&gt; \mathfrak{sl}(3,\mathbb C)&lt;/math&gt;
| 16
|-
| &lt;math&gt; SL(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt; S^2\mathbb C^3 &lt;/math&gt;
| 2
| 0
| 6
|-
| &lt;math&gt; SL(5,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^2\mathbb C^3 &lt;/math&gt;
| 3,4
| &lt;math&gt;\mathfrak{sl}(2,\mathbb C), 0&lt;/math&gt;
| 5,10
|-
| &lt;math&gt; SL(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^2\mathbb C^3 &lt;/math&gt;
| 2
| &lt;math&gt;\mathfrak{sl}(2,\mathbb C)\times\mathfrak{sl}(2,\mathbb C)\times\mathfrak{sl}(2,\mathbb C)&lt;/math&gt;
| 6
|-
| &lt;math&gt; SL(3,\mathbb C)\times SL(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^3\otimes\mathbb C^3 &lt;/math&gt;
| 2
| &lt;math&gt;\mathfrak{gl}(1,\mathbb C)\times\mathfrak{gl}(1,\mathbb C)&lt;/math&gt;
| 6
|-
| &lt;math&gt; Sp(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \Lambda^3_0\mathbb C^6 &lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak{sl}(3,\mathbb C)&lt;/math&gt;
| 4
|-
| &lt;math&gt; Spin(7,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^8 &lt;/math&gt;
| 1,2,3
|&lt;math&gt;\mathfrak{g}_2^{\mathbb C}, \mathfrak{sl}(3,\mathbb C)\times\mathfrak{so}(2,\mathbb C),
\mathfrak{sl}(2,\mathbb C)\times\mathfrak{so}(3,\mathbb C)&lt;/math&gt;
| 2,2,2
|-
| &lt;math&gt; Spin(9,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^{16} &lt;/math&gt;
| 1
| &lt;math&gt; \mathfrak{spin}(7,\mathbb C)&lt;/math&gt;
| 2
|-
| &lt;math&gt; Spin(10,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^{16} &lt;/math&gt;
| 2,3
|&lt;math&gt;\mathfrak{g}_2^{\mathbb C}\times\mathfrak{sl}(2,\mathbb C),\mathfrak{sl}(2,\mathbb C)\times\mathfrak{so}(3,\mathbb C)&lt;/math&gt;
| 2,4
|-
| &lt;math&gt; Spin(11,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^{32} &lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak{sl}(5,\mathbb C)&lt;/math&gt;
| 4
|-
| &lt;math&gt; Spin(12,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^{32} &lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak{sl}(6,\mathbb C)&lt;/math&gt;
| 4
|-
| &lt;math&gt; Spin(14,\mathbb C)&lt;/math&gt;
| &lt;math&gt; \mathbb C^{64} &lt;/math&gt;
| 1
| &lt;math&gt;\mathfrak{g}_2^{\mathbb C}\times\mathfrak{g}_2^{\mathbb C}&lt;/math&gt;
| 8
|-
| &lt;math&gt; G_2^{\mathbb C}&lt;/math&gt;
| &lt;math&gt; \mathbb C^{7} &lt;/math&gt;
| 1,2
| &lt;math&gt;\mathfrak{sl}(3,\mathbb C), \mathfrak{gl}(2,\mathbb C)&lt;/math&gt;
| 2,2
|-
| &lt;math&gt; E_6^{\mathbb C}&lt;/math&gt;
| &lt;math&gt; \mathbb C^{27} &lt;/math&gt;
| 1,2
| &lt;math&gt; \mathfrak{f}_4^{\mathbb C}, \mathfrak{so}(8,\mathbb C)&lt;/math&gt;
| 3,6
|-
| &lt;math&gt; E_7^{\mathbb C}&lt;/math&gt;
| &lt;math&gt; \mathbb C^{56} &lt;/math&gt;
| 1
| &lt;math&gt; \mathfrak{e}_6^{\mathbb C}&lt;/math&gt;
| 4
|}

Here &lt;math&gt; \Lambda^3_0\mathbb C^6\cong\mathbb C^{14} &lt;/math&gt; denotes the space of 3-forms whose contraction with the given symplectic form is zero.

==Proofs==

Sato and Kimura establish this classification by producing a list of possible irreducible prehomogeneous (''G'',''V''), using the fact that ''G'' is reductive and the dimensional restriction. They then check whether each member of this list is prehomogeneous or not.

However, there is a general explanation why most of the pairs (''G'',''V'') in the classification are prehomogeneous, in terms of isotropy representations of [[flag variety|generalized flag varieties]]. Indeed, in 1974, [[Roger Wolcott Richardson|Richardson]] observed that if ''H'' is a semisimple Lie group with a [[parabolic subgroup]] ''P'', then the action of ''P'' on the [[Nilradical of a Lie algebra|nilradical]] &lt;math&gt;\mathfrak p^\perp&lt;/math&gt; of its Lie algebra has a dense open orbit. This shows in particular (and was noted independently by [[Ernest Vinberg|Vinberg]] in 1975) that the [[Levi factor]] ''G'' of ''P'' acts prehomogeneously on &lt;math&gt;V:=\mathfrak p^\perp/[\mathfrak p^\perp,\mathfrak p^\perp]&lt;/math&gt;. Almost all of the examples in the classification can be obtained by applying this construction with ''P'' a maximal parabolic subgroup of a simple Lie group ''H'': these are classified by connected [[Dynkin diagram]]s with one distinguished node.

==Applications==

One reason that PVS are interesting is that they classify generic objects that arise in ''G''-invariant situations. For example, if ''G''=GL(7), then the above tables show that there are generic 3-forms under the action of ''G'', and the stabilizer of such a 3-form is isomorphic to the exceptional Lie group G&lt;sub&gt;2&lt;/sub&gt;.

Another example concerns the prehomogeneous vector spaces with a cubic relative invariant. By the Sato-Kimura classification, there are essentially four such examples, and they all come from complexified isotropy representations of [[hermitian symmetric space]]s for a larger group ''H'' (i.e., ''G'' is the semisimple part of the stabilizer of a point, and ''V'' is the corresponding [[tangent space|tangent]] representation).

In each case a generic point in ''V'' identifies it with the complexification of a [[Jordan algebra]] of 3 x 3 hermitian matrices (over the [[division algebra]]s '''R''', '''C''', '''H''' and '''O''' respectively) and the cubic relative invariant is identified with a suitable determinant. The isotropy algebra of such a generic point, the Lie algebra of ''G'' and the Lie algebra of ''H'' give the complexifications of the first three rows of the [[Freudenthal magic square]].

{| class="wikitable"
|-
! ''H''
! ''G''
! ''V''
! Isotropy algebra
! Jordan algebra
|-
| &lt;math&gt;\mathrm{Sp}(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt;S^2\mathbb C^3&lt;/math&gt;
| &lt;math&gt;\mathfrak{so}(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_3(\mathbb R)&lt;/math&gt;
|-
| &lt;math&gt;\mathrm{SL}(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(3,\mathbb C)\times SL(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^3\otimes\mathbb C^3&lt;/math&gt;
| &lt;math&gt;\mathfrak{sl}(3,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_3(\mathbb C)&lt;/math&gt;
|-
| &lt;math&gt;\mathrm{SO}(12,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\Lambda^2\mathbb C^6&lt;/math&gt;
| &lt;math&gt;\mathfrak{sp}(6,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_3(\mathbb H)&lt;/math&gt;
|-
| &lt;math&gt;E_7^{\mathbb C}&lt;/math&gt;
| &lt;math&gt;E_6^{\mathbb C}&lt;/math&gt;
| &lt;math&gt;\mathbb C^{27}&lt;/math&gt;
| &lt;math&gt;\mathfrak{f}_4^{\mathbb C}&lt;/math&gt;
| &lt;math&gt;J_3(\mathbb O)&lt;/math&gt;
|}

Other Hermitian symmetric spaces yields prehomogeneous vector spaces whose generic points define Jordan algebras in a similar way.
{| class="wikitable"
|-
! ''H''
! ''G''
! ''V''
! Isotropy algebra
! Jordan algebra
|-
| &lt;math&gt;\mathrm{Sp}(2n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;S^2\mathbb C^n&lt;/math&gt;
| &lt;math&gt;\mathfrak{so}(n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_n(\mathbb R)&lt;/math&gt;
|-
| &lt;math&gt;\mathrm{SL}(2n,\mathbb{C})&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(n,\mathbb C) \times \mathrm{SL}(n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^n\otimes \mathbb C^n&lt;/math&gt;
| &lt;math&gt;\mathfrak{sl}(n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_n(\mathbb C)&lt;/math&gt;
|-
| &lt;math&gt;\mathrm{SO}(4n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SL}(2n, \mathbb C)&lt;/math&gt;
| &lt;math&gt;\Lambda^2\mathbb C^{2n}&lt;/math&gt;
| &lt;math&gt;\mathfrak{sp}(2n,\mathbb C)&lt;/math&gt;
| &lt;math&gt;J_n(\mathbb H)&lt;/math&gt;
|-
| &lt;math&gt;\mathrm{SO}(m+2,\mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathrm{SO}(m, \mathbb C)&lt;/math&gt;
| &lt;math&gt;\mathbb C^m&lt;/math&gt;
| &lt;math&gt;\mathfrak{so}(m-1,\mathbb C)&lt;/math&gt;
| &lt;math&gt; J(m-1)&lt;/math&gt;
|}
The Jordan algebra ''J''(''m''&amp;minus;1) in the last row is the spin factor (which is the vector space '''R'''&lt;sup&gt;''m''&amp;minus;1&lt;/sup&gt; &amp;oplus; '''R''', with a Jordan algebra structure defined using the inner product on '''R'''&lt;sup&gt;''m''&amp;minus;1&lt;/sup&gt;). It reduces to &lt;math&gt;J_2(\mathbb R), J_2(\mathbb C), J_2(\mathbb H),J_2(\mathbb O)&lt;/math&gt;  for ''m''= 3, 4, 6 and 10 respectively.

The relation between hermitian symmetric spaces and Jordan algebras can be explained using [[Jordan triple system]]s.

==References==

*{{Citation | last1=Kimura | first1=Tatsuo | title=Introduction to prehomogeneous vector spaces | url=https://books.google.com/books?id=qYH8oIekZF4C | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Translations of Mathematical Monographs | isbn=978-0-8218-2767-3 |mr=1944442 | year=2003 | volume=215}}
* {{citation | first=Anthony | last=Knapp | title=Lie Groups Beyond an Introduction | edition=2nd | series=Progress in Mathematics | volume=140 | publisher=Birkhäuser Boston, Inc. | location=Boston, MA | mr=1920389 | isbn=0-8176-4259-5 | year=2002}} See Chapter X.
* {{citation | first1=Mikio | last1=Sato | first2=Tatsuo | last2=Kimura | title=A classification of irreducible prehomogeneous vector spaces and their relative invariants | url=http://projecteuclid.org/euclid.nmj/1118796150 | journal=Nagoya Mathematical Journal | volume=65 | year=1977 | pages=1–155 | mr=0430336 | doi=10.1017/s0027763000017633}}
* {{citation | first=Roger Wolcott, Jr. | last=Richardson | title=Conjugacy Classes in Parabolic Subgroups of Semisimple Algebraic Groups | doi=10.1112/blms/6.1.21 | journal=Bull. London Math. Soc. | volume=6 | year=1974 | pages=21–24 | mr=0330311}}
*{{Citation | last1=Sato | first1=Mikio | title=Theory of prehomogeneous vector spaces (algebraic part) — the English translation of Sato's lecture from Shintani's note | url=http://projecteuclid.org/euclid.nmj/1118782193 |mr=1086566 | year=1990 | journal=Nagoya Mathematical Journal | issn=0027-7630 | volume=120 | pages=1–34 | doi=10.1017/S0027763000003214}}
*{{Citation | last1=Sato | first1=Mikio | last2=Shintani | first2=Takuro | title=On zeta functions associated with prehomogeneous vector spaces |mr=0296079 | year=1972 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=69 | pages=1081–1082 | jstor=61638 | doi=10.1073/pnas.69.5.1081| pmc=426633 | pmid=16591979}}
*{{Citation | last1=Sato | first1=Mikio | last2=Shintani | first2=Takuro | title=On zeta functions associated with prehomogeneous vector spaces |mr=0344230 | year=1974 | journal=[[Annals of Mathematics]] |series=Second Series | issn=0003-486X | volume=100 | pages=131–170 | jstor=1970844 | doi=10.2307/1970844| pmc=426633 }}
* {{citation | first=Ernest | last=Vinberg| title=The classification of nilpotent elements of graded Lie algebras | journal=Soviet Math. Dokl. | volume=16 | issue=6 | year=1975 | pages=1517–1520 | mr=0506488}}

[[Category:Representation theory]]</text>
      <sha1>0nvbpzifuh1wxi0uwucyyv7dhzi78nn</sha1>
    </revision>
  </page>
  <page>
    <title>Ran Libeskind-Hadas</title>
    <ns>0</ns>
    <id>4720923</id>
    <revision>
      <id>859908324</id>
      <parentid>835670742</parentid>
      <timestamp>2018-09-17T02:27:07Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3616">{{missing information|early life|date=January 2011}}

'''Ran Libeskind-Hadas''' is a professor of [[Computer Science]] at [[Harvey Mudd College]]. His research interests lie in the fields of algorithm design and analysis and complexity theory, but focus more specifically on routing algorithms for optical networks and collective communication in parallel computers and networks.&lt;ref&gt;[http://portal.acm.org/citation.cfm?id=205027 Ran Libeskind-Hadas, Nimish Shrivastava, Rami G. Melhem, C. L. Liu, ''Optimal Reconfiguration Algorithms for Real-Time Fault-Tolerant Processor Arrays'' IEEE Transactions on Parallel and Distributed Systems archive, Volume 6 ,  Issue 5  (May 1995) Pages: 498 - 511], {{ISSN|1045-9219}}&lt;/ref&gt;

Libeskind-Hadas graduated from Harvard University with a degree in [[Applied Mathematics]] in 1987. He went on to complete an M.S. and Ph.D. in Computer Science at the [[University of Illinois at Urbana-Champaign]] in 1993. In August of that year he was hired into the Department of Mathematics at [[Harvey Mudd College]], a liberal arts school that focuses on science and engineering.  He has been in the Department of Computer Science since May 1994, and served as acting chair of the department in 2006-2007.

Libeskind-Hadas held the Joseph B. Platt Endowed Chair for effective teaching from 2005 to 2010. His research has been funded by the National Science Foundation.&lt;ref&gt;[http://www.hmc.edu/newsandevents/PlattChair2005.html Announcement by President Jon Strauss] {{webarchive|url=https://archive.is/20120805175653/http://www.hmc.edu/newsandevents/PlattChair2005.html |date=2012-08-05 }}, March 4, 2005&lt;/ref&gt;  Most recently, he has been the director of an NSF [[Research Experiences for Undergraduates]] (REU) site at Harvey Mudd College, which has allowed Harvey Mudd to greatly increase the number of undergraduate research students it can support during the summers, in addition to increasing cross-university interactions.&lt;ref&gt;[https://web.archive.org/web/20060813203018/http://www.cs.hmc.edu/REU/projects.html#routing 2006 Harvey Mudd College REU site], retrieved from the Internet Archive&lt;/ref&gt; Additionally, Libeskind-Hadas has been the key faculty member in encouraging a group of students to form a student chapter for the [[Association for Computing Machinery]] (ACM), which has been successfully running and helping members of the [[Claremont Colleges]] and surrounding community since the beginning of 2005.

==Module orientation problem==
Libeskind-Hadas has produced noted research in the ''module orientation problem'', a branch of computer science important in design of large scale [[integrated circuit]]s.&lt;ref&gt;[https://books.google.com/books?id=9kXM8wd8ULgC&amp;pg=PA209 Yoshiyasu Takefuji, ''Neural Network Parallel Computing''(1992) Springer Publishing] {{ISBN|0-7923-9190-X}}&lt;/ref&gt;

==Publications==
Libeskind-Hadas is a coauthor of R. Libeskind-Hadas, N. Hasan, J. Cong, P. McKinley, and [[Chung Laung Liu|C. L. Liu]]. ''Fault Covering Problems in Reconfigurable VLSI Systems. '' Kluwer Academic Publishers, 1992., and has published 16 peer reviewed papers and 20 peer-reviewed conference proceedings.

==Reference line notes==
{{reflist}}

==External links==
*[http://www.cs.hmc.edu/~hadas/ Ran Libeskind-Hadas] at the Harvey Mudd College website

{{authority control}}

{{DEFAULTSORT:Libeskind-Hadas, Ran}}
[[Category:Harvey Mudd College faculty]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Living people]]
[[Category:Harvard University alumni]]
[[Category:University of Illinois at Urbana–Champaign alumni]]</text>
      <sha1>4ps0mx789exazsggdc7qwi7dbry397u</sha1>
    </revision>
  </page>
  <page>
    <title>Sara Negri</title>
    <ns>0</ns>
    <id>56717276</id>
    <revision>
      <id>828997608</id>
      <parentid>828516065</parentid>
      <timestamp>2018-03-06T00:59:59Z</timestamp>
      <contributor>
        <ip>2001:AC8:33:1D:0:0:0:2</ip>
      </contributor>
      <comment>/* External links */ cat per article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2950">'''Sara Negri''' (born January 21, 1967){{r|hum}} is a [[mathematical logic]]ian who studies [[proof theory]].
She is Italian, but works in Finland, where she is a professor of theoretical philosophy in the [[University of Helsinki]].{{r|cv}}

Negri was born in [[Padua]],{{r|hum}} and studied at the [[University of Padua]]. She earned a master's degree there in 1991 and a Ph.D. in 1996, both in mathematics.{{r|cv}} Her dissertation, ''Dalla Topologia Formale all'Analisi'', was supervised by Giovanni Sambin.{{r|mgp}}
She came to Helsinki as a docent in 1998, and became a full professor there in 2015. She has also taken several visiting positions,{{r|cv}} including a [[Alexander von Humboldt Foundation|Humboldt Fellowship]] in 2004–2005 at the [[Ludwig Maximilian University of Munich]].{{r|cv|alone}}

Negri is the co-author, with Jan von Plato, of two books:
*''Structural Proof Theory'' (Cambridge University Press, 2001){{r|spt}}
*''Proof Analysis: A Contribution to Hilbert's Last Problem'' (Cambridge University Press, 2011){{r|pa}}

==References==
{{reflist|refs=

&lt;ref name=alone&gt;{{citation|url=https://www.humboldt-foundation.de/web/kosmos-cover-story-94-15.html|title=Alone Amongst Men|first=Sara|last=Negri|publisher=Alexander von Humboldt Foundation|magazine=Humboldt Kosmos|year=2009|accessdate=2018-02-28}}&lt;/ref&gt;

&lt;ref name=cv&gt;{{citation|url=http://www.helsinki.fi/~negri/negri_cv_9_2017.pdf|title=Curriculum vitae|date=September 2017|accessdate=2018-02-28}}&lt;/ref&gt;

&lt;ref name=hum&gt;{{citation|url=http://375humanistia.helsinki.fi/en/humanists/sara-negri|title=Sara Negri|work=375 Humanists|publisher=Faculty of Arts, University of Helsinki|accessdate=2018-02-28}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=51215}}&lt;/ref&gt;

&lt;ref name=pa&gt;Reviews of ''Proof Analysis'':
*{{citation|title=none|first=Andrzej B.|last=Indrzejczak|journal=[[Mathematical Reviews]]|mr=3136234}}
*{{citation|title=none|first=F.|last=Poggiolesi|journal=History and Philosophy of Logic|volume=34|issue=1|pages=98–99|doi=10.1080/01445340.2012.735805}}
&lt;/ref&gt;

&lt;ref name=spt&gt;Reviews of ''Structural Proof Theory'':
*{{citation|title=none|first=M.|last=Yasuhara|journal=[[Mathematical Reviews]]|year=2002|mr=1841217}}
*{{citation|title=none|first=Harold T.|last=Hodes|journal=The Philosophical Review|volume=115|issue=2|date=April 2006|pages=255–258|jstor=20446902}}
&lt;/ref&gt;

}}

==External links==
*{{Google Scholar id|vw2yWRQAAAAJ}}

{{Authority control}}
{{DEFAULTSORT:Negri, Sara}}
[[Category:1967 births]]
[[Category:Living people]]
[[Category:Italian mathematicians]]
[[Category:Italian philosophers]]
[[Category:Finnish mathematicians]]
[[Category:Finnish philosophers]]
[[Category:Women mathematicians]]
[[Category:Women philosophers]]
[[Category:Mathematical logicians]]
[[Category:University of Padua alumni]]
[[Category:Academics of the University of Helsinki]]
[[Category:Alexander von Humboldt Fellows]]
[[Category:Italian expatriates in Finland]]</text>
      <sha1>0bsl7ep20a3cd5v1x78cev9cefzfuum</sha1>
    </revision>
  </page>
  <page>
    <title>Soft configuration model</title>
    <ns>0</ns>
    <id>58486357</id>
    <revision>
      <id>869630540</id>
      <parentid>869630482</parentid>
      <timestamp>2018-11-19T20:24:42Z</timestamp>
      <contributor>
        <username>Rosguill</username>
        <id>32763026</id>
      </contributor>
      <comment>Adding [[Wikipedia:Short description|short description]]: "random graph model in applied mathematics" ([[User:Galobtter/Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5306">{{short description|random graph model in applied mathematics}}
{{Network science}}

In applied mathematics, the '''soft configuration model (SCM)''' is a [[random graph]] model subject to the [[principle of maximum entropy]] under constraints on the [[Expectation_value|expectation]] of the [[degree sequence]] of sampled [[Graph (discrete mathematics)|graphs]].&lt;ref name="van der Hoorn"&gt;{{cite news
|url=https://arxiv.org/abs/1705.10261
|title=Sparse Maximum-Entropy Random Graphs with a Given Power-Law Degree Distribution
|last=van der Hoorn
|first=Pim
|author2=Gabor Lippner
|author3=Dmitri Krioukov
|date=2017-10-10
|publisher=}}&lt;/ref&gt; Whereas the [[configuration model]] (CM) uniformly samples random graphs of a specific degree sequence, the SCM only retains the specified degree sequence on average over all network realizations; in this sense the SCM is has very relaxed constraints relative to those of the CM ("soft" rather than "sharp" constraints&lt;ref name="Diego"&gt;{{cite news
|last=Garlaschelli
|first=Diego 
|author2=Frank den Hollander
|author3=Andrea Roccaverde
|date=January 30, 2018
|title=Coviariance structure behind breaking of ensemble equivalence in random graphs
|url=http://eprints.imtlucca.it/4040/1/1711.04273.pdf}}&lt;/ref&gt;). The SCM for graphs of size &lt;math&gt;n&lt;/math&gt; has a nonzero probability of sampling any graph of size &lt;math&gt;n&lt;/math&gt;, whereas the CM is restricted to only graphs having precisely the perscribed connectivity structure.

==Model formulation==
The SCM is a [[statistical ensemble]] of random graphs &lt;math&gt;G&lt;/math&gt; having &lt;math&gt;n&lt;/math&gt; vertices (&lt;math&gt;n=|V(G)|&lt;/math&gt;) labeled &lt;math&gt;\{v_j\}_{j=1}^n=V(G)&lt;/math&gt;, producing a [[probability distribution]] on &lt;math&gt;\mathcal{G}_n&lt;/math&gt; (the set of graphs of size &lt;math&gt;n&lt;/math&gt;). Imposed on the ensemble are &lt;math&gt;n&lt;/math&gt; constraints, namely that the [[ensemble average]] of the [[Degree (graph theory)|degree]] &lt;math&gt;k_j&lt;/math&gt; of vertex &lt;math&gt;v_j&lt;/math&gt; is equal to a designated value &lt;math&gt;\widehat{k}_j&lt;/math&gt;, for all &lt;math&gt;v_j\in V(G)&lt;/math&gt;. The model is fully [[Parameterization|parameterized]] by it's size &lt;math&gt;n&lt;/math&gt; and expected degree sequence &lt;math&gt;\{\widehat{k}_j\}_{j=1}^n&lt;/math&gt;. These constraints are both local (one constraint associated with each vertex) and soft (constraints on the ensemble average of certain observable quantities), and thus yields a [[canonical ensemble]] with an [[Intensive_and_extensive_properties|extensive]] number of constraints.&lt;ref name="Diego" /&gt; The conditions &lt;math&gt;\langle k_j \rangle = \widehat{k}_j&lt;/math&gt; are imposed on the ensemble by the [[method of Lagrange multipliers]] (see [[Maximum-entropy random graph model]]).

==Derivation of the probability distribution==
The probability &lt;math&gt;\mathbb{P}_\text{SCM}(G)&lt;/math&gt; of the SCM producing a graph &lt;math&gt;G&lt;/math&gt; is determined by maximizing the [[Gibbs entropy]] &lt;math&gt;S[G]&lt;/math&gt; subject to constraints &lt;math&gt;\langle k_j \rangle = \widehat{k}_j, \ j=1,\ldots,n&lt;/math&gt; and normalization &lt;math&gt;\sum_{G\in \mathcal{G}_n}\mathbb{P}_\text{SCM}(G)=1&lt;/math&gt;. This amounts to [[optimizing]] the multi-constraint [[Lagrange_multiplier#Multiple_constraints|Lagrange function]] below:

: &lt;math&gt;
\begin{align}
&amp; \mathcal{L}\left(\alpha,\{\psi_j\}_{j=1}^n\right) \\[6pt]
= {} &amp; -\sum_{G\in\mathcal{G}_n}\mathbb{P}_\text{SCM}(G)\log\mathbb{P}_\text{SCM}(G) + \alpha\left(1-\sum_{G\in \mathcal{G}_n}\mathbb{P}_\text{SCM}(G) \right)+\sum_{j=1}^n\psi_j\left(\widehat{k}_j-\sum_{G\in\mathcal{G}_n}\mathbb{P}_\text{SCM}(G)k_j(G)\right),
\end{align}
&lt;/math&gt;

where &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\{\psi_j\}_{j=1}^n&lt;/math&gt; are the &lt;math&gt;n+1&lt;/math&gt; multipliers to be fixed by the &lt;math&gt;n+1&lt;/math&gt; constraints (normalization and the expected degree sequence). Setting to zero the derivative of the above with respect to &lt;math&gt;\mathbb{P}_\text{SCM}(G)&lt;/math&gt; for an arbitrary &lt;math&gt;G\in \mathcal{G}_n&lt;/math&gt; yields

: &lt;math&gt; 0 = \frac{\partial \mathcal{L}\left(\alpha,\{\psi_j\}_{j=1}^n\right)}{\partial \mathbb{P}_\text{SCM}(G)}= -\log \mathbb{P}_\text{SCM}(G) -1-\alpha-\sum_{j=1}^n\psi_j k_j(G) \ \Rightarrow \ \mathbb{P}_\text{SCM}(G)=\frac{1}{Z}\exp\left[-\sum_{j=1}^n\psi_jk_j(G)\right],&lt;/math&gt;

the constant &lt;math&gt;Z:=e^{\alpha+1}=\sum_{G\in\mathcal{G}_n}\exp\left[-\sum_{j=1}^n\psi_jk_j(G)\right]=\prod_{1\le i &lt; j \le n}\left(1+e^{-(\psi_i+\psi_j)}\right)&lt;/math&gt;&lt;ref name="Park"&gt;{{cite news
|url=https://arxiv.org/abs/cond-mat/0405566
|title=The statistical mechanics of networks
|last=Park
|first=Juyong
|author2=M.E.J. Newman
|date=2004-05-25
|publisher=}}&lt;/ref&gt; being the [[Partition function (mathematics)|partition function]] normalizing the distribution; the above exponential expression applies to all &lt;math&gt;G\in\mathcal{G}_n&lt;/math&gt;, and thus is the probability distribution. Hence we have an [[exponential family]] parameterized by &lt;math&gt;\{\psi_j\}_{j=1}^n&lt;/math&gt;, which are related to the expected degree sequence &lt;math&gt;\{\widehat{k}_j\}_{j=1}^n&lt;/math&gt; by the following equivalent expressions:

: &lt;math&gt; \langle k_q \rangle = \sum_{G\in \mathcal{G}_n}k_q(G)\mathbb{P}_\text{SCM}(G) = -\frac{\partial \log Z}{\partial \psi_q} =\sum_{j\ne q}\frac{1}{e^{\psi_q+\psi_j}+1} = \widehat{k}_q, \ q=1,\ldots,n.&lt;/math&gt;

==References==
{{Reflist}}

[[Category:Random graphs]]

{{improve categories|date=November 2018}}</text>
      <sha1>kjln1j4uznb6756papgou9awtc7n6pg</sha1>
    </revision>
  </page>
  <page>
    <title>Strict conditional</title>
    <ns>0</ns>
    <id>663772</id>
    <revision>
      <id>816984944</id>
      <parentid>802600366</parentid>
      <timestamp>2017-12-25T06:20:30Z</timestamp>
      <contributor>
        <username>Crito10</username>
        <id>23607440</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6245">In [[logic]], a '''strict conditional''' is a conditional governed by a [[modal operator]], that is, a [[logical connective]] of [[modal logic]]. It is [[logical equivalence|logically equivalent]] to the [[material conditional]] of classical logic, combined with the [[Logical truth|necessity]] operator from [[modal logic]]. For any two [[proposition]]s ''p'' and ''q'', the [[well-formed formula|formula]] ''p'' → ''q'' says that ''p'' [[material conditional|materially implies]] ''q'' while &lt;math&gt;\Box (p \rightarrow q)&lt;/math&gt; says that ''p'' [[logical consequence|strictly implies]] ''q''.&lt;ref&gt;Graham Priest, ''An Introduction to Non-Classical Logic: From if to is'', 2nd ed, Cambridge University Press, 2008, {{ISBN|0-521-85433-4}}, [https://books.google.com/books?id=rMXVbmAw3YwC&amp;pg=PA72 p. 72.]&lt;/ref&gt;  Strict conditionals are the result of [[Clarence Irving Lewis]]'s attempt to find a conditional for logic that can adequately express [[indicative conditional]]s in natural language.&lt;ref&gt;Nicholas Bunnin and Jiyuan Yu (eds), ''The Blackwell Dictionary of Western Philosophy'', Wiley, 2004, {{ISBN|1-4051-0679-4}}, "strict implication," [https://books.google.com/books?id=OskKWI1YA7AC&amp;pg=PA660 p. 660].&lt;/ref&gt; They have also been used in studying [[Molinism|Molinist]] theology.&lt;ref&gt;Jonathan L. Kvanvig, "Creation, Deliberation, and Molinism," in ''Destiny and Deliberation: Essays in Philosophical Theology'', Oxford University Press, 2011, {{ISBN|0-19-969657-8}}, [https://books.google.com/books?id=nQliRGPVpTwC&amp;pg=PA127 p. 127–136].&lt;/ref&gt;

==Avoiding paradoxes==
The strict conditionals may avoid [[paradoxes of material implication]]. The following statement, for example, is not correctly formalized by material implication:

: If Bill Gates had graduated in Medicine, then Elvis never died.

This condition should clearly be false: the degree of Bill Gates has nothing to do with whether Elvis is still alive. However, the direct encoding of this formula in [[classical logic]] using material implication leads to:

: Bill Gates graduated in Medicine → Elvis never died.

This formula is true because whenever the antecedent ''A'' is false, a formula ''A'' → ''B'' is true. Hence, this formula is not an adequate translation of the original sentence. An encoding using the strict conditional is:

: &lt;math&gt;\Box&lt;/math&gt; (Bill Gates graduated in Medicine → Elvis never died.)

In modal logic, this formula means (roughly) that, in every possible world in which Bill Gates graduated in Medicine, Elvis never died. Since one can easily imagine a world where Bill Gates is a Medicine graduate and Elvis is dead, this formula is false.  Hence, this formula seems to be a correct translation of the original sentence.

==Problems==
Although the strict conditional is much closer to being able to express natural language conditionals than the material conditional, it has its own problems with [[consequent]]s that are [[Logical truth|necessarily true]] (such as 2 + 2 = 4) or antecedents that are necessarily false.&lt;ref&gt;Roy A. Sorensen, ''A Brief History of the Paradox: Philosophy and the labyrinths of the mind'', Oxford University Press, 2003, {{ISBN|0-19-515903-9}}, [https://books.google.com/books?id=PB8I0kHeKy4C&amp;pg=PA105 p. 105].&lt;/ref&gt; The following sentence, for example, is not correctly formalized by a strict conditional:

: If Bill Gates graduated in Medicine, then 2 + 2 = 4.

Using strict conditionals, this sentence is expressed as:

: &lt;math&gt;\Box&lt;/math&gt; (Bill Gates graduated in Medicine → 2 + 2 = 4)

In modal logic, this formula means that, in every possible world where Bill Gates graduated in medicine, it holds that 2 + 2 = 4. Since 2 + 2 is equal to 4 in all possible worlds, this formula is true, although it does not seem that the original sentence should be. A similar situation arises with 2 + 2 = 5, which is necessarily false:

: If 2 + 2 = 5, then Bill Gates graduated in Medicine.

Some logicians view this situation as indicating that the strict conditional is still unsatisfactory. Others have noted that the strict conditional cannot adequately express [[counterfactual conditional]]s,&lt;ref&gt;Jens S. Allwood, Lars-Gunnar Andersson, and Östen Dahl, ''Logic in Linguistics'', Cambridge University Press, 1977, {{ISBN|0-521-29174-7}}, [https://books.google.com/books?id=hXIpFPttDjgC&amp;pg=PA120 p. 120].&lt;/ref&gt; and that it does not satisfy certain logical properties.&lt;ref&gt;Hans Rott and Vítezslav Horák, ''Possibility and Reality: Metaphysics and Logic'', ontos verlag, 2003, {{ISBN|3-937202-24-2}}, [https://books.google.com/books?id=ov9kN3HyltAC&amp;pg=PA271 p. 271].&lt;/ref&gt; In particular, the strict conditional is [[Transitive relation|transitive]], while the counterfactual conditional is not.&lt;ref&gt;John Bigelow and Robert Pargetter, ''Science and Necessity'', Cambridge University Press, 1990, {{ISBN|0-521-39027-3}}, [https://books.google.com/books?id=O-onBdR7TPAC&amp;pg=PA116 p. 116].&lt;/ref&gt;

Some logicians, such as [[Paul Grice]], have used [[conversational implicature]] to argue that, despite apparent difficulties, the material conditional is just fine as a translation for the natural language 'if...then...'. Others still have turned to [[relevance logic]] to supply a connection between the antecedent and consequent of provable conditionals.

==See also==
* [[Corresponding conditional]]
* [[Counterfactual conditional]]
* [[Indicative conditional]]
* [[Logical consequence]]
* [[Material conditional]]

==References==
{{reflist}}

==Bibliography==
*Edgington, Dorothy, 2001, "Conditionals," in Goble, Lou, ed., ''The Blackwell Guide to Philosophical Logic''. Blackwell.
For an introduction to non-classical logic as an attempt to find a better translation of the conditional, see:
*Priest, Graham, 2001. ''An Introduction to Non-Classical Logic''. Cambridge Univ. Press.
For an extended philosophical discussion of the issues mentioned in this article, see:
*[[Mark Sainsbury (philosopher)|Mark Sainsbury]], 2001. ''Logical Forms''. Blackwell Publishers.
*[[Jonathan Bennett (philosopher)|Jonathan Bennett]], 2003. ''A Philosophical Guide to Conditionals''. Oxford Univ. Press.

{{Logic}}

[[Category:Conditionals]]
[[Category:Logical connectives]]
[[Category:Modal logic]]
[[Category:Necessity]]</text>
      <sha1>hjkjx1o32qsk8or7a704t6lvhw3tfuf</sha1>
    </revision>
  </page>
  <page>
    <title>Studia Mathematica</title>
    <ns>0</ns>
    <id>1804931</id>
    <revision>
      <id>867870275</id>
      <parentid>867869901</parentid>
      <timestamp>2018-11-08T14:24:08Z</timestamp>
      <contributor>
        <username>PJTraill</username>
        <id>522601</id>
      </contributor>
      <minor/>
      <comment>/* Effects of the war */ Consistent style of English translations.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8940">{{italics title}}
{{Infobox journal
    |image =	&lt;!-- Image of journal's cover (e.g. abc.jpg, xpz.png, 123.gif). Does not need [[File:...]] or [[File:...]]. --&gt;
     |image_size =
     |alt =
     |caption =	Caption for image, if needed.
    |former_name =
    |abbreviation = Stud. Math. &lt;!--	The ISO 4 abbreviation for journal. Include dots (e.g. J. Phys., not J Phys). If unset, links to find out what the ISO 4 abbreviation is will be displayed. Use |abbreviation=no to hide the field. --&gt;
    |mathscinet = &lt;!--	The MathSciNet abbreviation IF different from ISO 4 abbreviation.
    |nlm =	The NLM abbreviation IF different from ISO 4 abbreviation.
    |bypass-rcheck =	Set to yes to bypass the built-in ISO 4 / bluebook redirect check until T14019 is resolved. This should only be used after the ISO 4 / bluebook redirects were created, not to get rid of the template messages. See Category:Infobox journals with bypassed redirect checking for more information. --&gt;
    |discipline = Mathematics
    |peer-reviewed = &lt;!-- Put no if journal is not peer-reviewed (in which case {{Infobox magazine}} is probably more appropriate). If the situation is complicated, put "See text" and describe it in the text. If the field is blank, omitted, or set to yes, no field is shown, and peer-review status is implied. --&gt;
    |language =	Polish
    |editor =	Adam Skalski &lt;!-- from https://www.impan.pl/en/publishing-house/journals-and-series/studia-mathematica Editorial Committee, one of two Executive Editors --&gt;
    |publisher = [[Polish Academy of Sciences]] &lt;!-- Name of publisher. This should be the name of the entity (company, university, society) that performs the actual publishing (marketing, printing, distribution, etc), possibly followed by "on behalf of ...." if there is clear evidence that the journal is owned by another organization (usually a learned society); furthermore, in case there is clear evidence that the journal is co-owned by another organization (including the publisher itself), this information can be followed with "and ..." --&gt;
    |country = Poland
    |history =	1929–present.
    |frequency = usually 3 issues / year
    |openaccess = At author's discretion (€ 300) &lt;!-- Availability of open-access content, with wikilinks if appropriate (put Yes if journal is completely open-access, or [[Delayed open access journal|Delayed]] or [[Hybrid open access journal|Hybrid]] if more appropriate) --&gt;
     |license =	&lt;!-- License for the journal's content if the previous parameter is Yes. --&gt;
    |impact-year = 2010 |impact = 0.549 
    |ISSNlabel = &lt;!-- To distinguish between ISSNs when more than one is given (use in conjunction with ISSN2label, ISSN3label, ... ISSN10label). --&gt;
    |ISSN = 0039-3223 &lt;!-- ISSN (print edition) or eISSN if electronic-only journal. If there is more than one journal, such as in European Physical Journal, use additional ISSN2, ISSN3, ... ISSN10 parameters. --&gt;
    |eISSN =	&lt;!--Same as ISSN, but for online version of paper journals. eISSN2, eISSN3, ... eISSN10 supported. --&gt;
            	&lt;!-- For eJournal in World Cat: (NL-LeOCL)844053627 ISSN:	0039-3223  OCLC Number: 	66570107 --&gt;
    |CODEN =	&lt;!--CODEN. --&gt;
    |JSTOR =	&lt;!--Journal's JSTOR number (usually its ISSN without the dash; link will be generated automatically). --&gt;
    |LCCN =	&lt;!--LCCN (link will be generated automatically). --&gt;
    |OCLC = 989577902	&lt;!--OCLC number (link will be generated automatically). --&gt;
    |website =	http://journals.impan.gov.pl/sm/
    |link1 =	http://matwbn.icm.edu.pl/spis.php?wyd=2 
    |link1-name =	Online archive
    |link2 =	|link2-name =	&lt;!-- Second additional link's URL (see below). --&gt;
    |boxwidth =	
}} 

'''''Studia Mathematica''''' is a [[Poland|Polish]] [[mathematics]] [[academic journal|journal]] published by the [[Polish Academy of Sciences]] and accepts [[academic paper|papers]] written in [[English language|English]], [[French language|French]], [[German language|German]], or [[Russian language|Russian]], primarily in [[functional analysis]], abstract methods of [[mathematical analysis]] and [[probability theory]].

== History of the journal ==
''Studia Mathematica''  was founded in 1929 by [[Stefan Banach]] and [[Hugo Steinhaus]] in [[Lwów]] and its first editors were Banach, Steinhaus and [[Herman Auerbach]].

Due to the [[Second World War]] publication stopped after volume 9 (1940) and could not be resumed until volume 10 in 1948, published in [[Breslau]] since Lwów was no longer Polish.

In 2010 the [[Impact Factor]] of the journal was 0.549; in the statistics of the [[Web of Science]] it occupied place 157 of 295 in the category ''Mathematics''.&lt;ref&gt;ISI Web of Knowledge, Journal Citation Reports Science Edition, 2012.&lt;/ref&gt;
In the [[ SCImago Journal Rank ]] of mathematical journals in 2017, ''Studia Mathematica'' was ranked 395 out of 1382 journals with a rank indicator of 0.846.&lt;ref&gt;{{ cite web
 |url= https://www.scimagojr.com/journalrank.php?area=2600&amp;type=j&amp;out=xls
 |title= SCImago Journal &amp; Country Rank (Mathematics, Journals, 2017)
 |access-date= 2018-11-08
 }}&lt;/ref&gt;&lt;ref&gt;{{ cite web
 |url= https://www.scimagojr.com/journalsearch.php?q=26945&amp;tip=sid&amp;clean=0
 |title= SCImago page for Studia Mathematica
 |access-date= 2018-11-08
 }}&lt;/ref&gt;

== Effects of the war ==
The first issues after the war display the effects of the Nazi oppression on Polish mathematics in various footnotes and posthumous publications.

In volume 10 (1948) [[Hugo Steinhaus]] writes in a footnote on [[Herman Auerbach]]:
"Ce mathématicien distingué et homme de rare qualités d'esprit et de cœur a été assassiné par les Allemands à Lwów en 1942."
(This excellent mathematician and person of rare mental and emotional qualities was assassinated in Lwów in 1942 by the Germans.)&lt;ref&gt;{{cite journal
 |author-first= Hugo |author-last= Steinhaus
 |title= Sur les fonctions indépendantes (VII) (Un essaim de points à l'intérieur d'une cube) |language= fr
 |trans-title= On independent functions (VII) (A swarm of points in the interior of a cube)
 |url= http://matwbn.icm.edu.pl/ksiazki/sm/sm10/sm1011.pdf
 |series= [[Studia Mathematica]] |volume= 10 |year= 1948 |pages= 1–20 }} (on the [[centre of mass]] of random moving bouncing points), footnote on p. 3&lt;/ref&gt;

[[Meier Eidelheit]]'s posthumously published article ''Quelques remarques sur les fonctionelles linéaires'' in volume 10 was prefaced with the following lines:
"L’auteur de ce travail a été assassiné par les Allemands en mars de 1943. Le manuscrit qu’il fut parvenir à la Rédaction en 1941 a été retrouvé récemment entre les papiers laissés par S. Banach."
(The author of this work was murdered in March 1943 by the Germans.
The manuscript, which reached the editors in 1941, was recently found among the writings left by S. Banach.)&lt;ref name="Eidelheit 1948"&gt;{{cite journal
 |author-first= M. |author-last= Eidelheit |author-link= Meier Eidelheit
 |title= Quelques remarques sur les fonctionelles linéaires |language=fr
 |trans-title= Some remarks on [[linear functionals]]
 |url= http://matwbn.icm.edu.pl/ksiazki/sm/sm10/sm10111.pdf
 |series= [[Studia Mathematica]] |volume= 10 |year= 1948 |pages= 140–147 }}&lt;/ref&gt;

In volume 11 (1950) [[Andrzej Alexiewicz]] refers as follows to his dissertation in a footnote:
"Presented with some insignificant alterations as Doctor Thesis, on March 10, 1944 to the [[ Education in Poland during World War II#Resistance: the underground education | secret university in Lwów ]], during the terror of the German occupation."&lt;ref&gt;{{cite journal
 |author-first= A.  |author-last= Alexiewicz |author-link= Andrzej Alexiewicz
 |title= On sequences of operations (I)
 |url= http://matwbn.icm.edu.pl/ksiazki/sm/sm11/sm1111.pdf
 |series= [[Studia Mathematica]] |volume= 11 |year= 1950 |pages= 1–30 }}, footnote on p. 2&lt;/ref&gt;

[[G. Sirvint]]'s posthumously published article ''Weak compactness in Banach spaces'' in volume 11 begins with the lines:
"The author was murdered by the Germans during the second world war. The present work was received by the editor in 1941 and has been prepared by A. Alexiewicz."&lt;ref&gt;{{cite journal
 |author-first= G.  |author-last= Sirvint
 |title= Weak compactness in Banach spaces
 |url= http://matwbn.icm.edu.pl/ksiazki/sm/sm11/sm1115.pdf
 |series= [[Studia Mathematica]] |volume= 11 |year= 1948 |pages= 71–94 }}&lt;/ref&gt;

== Notes ==
{{Reflist}}

== External links ==
* [http://journals.impan.gov.pl/sm/ Official site]
* [http://matwbn.icm.edu.pl/spis.php?wyd=2 Online archive of ''Studia Mathematica'']
* {{cite book |author= H. Heuser: |title= Funktionalanalysis |language=de |trans-title= Functional analysis |publisher= [[Teubner Verlag]] |year= 2006 |isbn= 3-8351-0026-2 }}, includes historical remarks.

[[Category:Mathematics journals]]
[[Category:Publications established in 1929]]
[[Category:Polish mathematics]]
[[Category:Polish-language journals]]

{{math-journal-stub}}</text>
      <sha1>jlgvo7upxgzq4hlobzjuxg37o470yd7</sha1>
    </revision>
  </page>
  <page>
    <title>Supernatural number</title>
    <ns>0</ns>
    <id>18668810</id>
    <revision>
      <id>818706941</id>
      <parentid>701667600</parentid>
      <timestamp>2018-01-05T03:25:38Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <minor/>
      <comment>/* External links */ s</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4078">In [[mathematics]], the '''supernatural numbers''', sometimes called '''generalized natural numbers''' or '''Steinitz numbers''', are a generalization of the [[natural number]]s. They were used by [[Ernst Steinitz]]&lt;ref&gt;{{cite journal |last=Steinitz |first=Ernst |authorlink=Ernst Steinitz |date=1910 |language=German |title=Algebraische Theorie der Körper |journal=Journal für die reine und angewandte Mathematik |jfm=41.0445.03 |issn=0075-4102 |volume=137 |pages=167–309 |url=http://resolver.sub.uni-goettingen.de/purl?GDZPPN002167042}}&lt;/ref&gt; in 1910 as a part of his work on [[Field theory (mathematics)|field theory]].

A supernatural number &lt;math&gt;\omega&lt;/math&gt; is a [[Formal calculation|formal]] [[Product (mathematics)|product]]:

: &lt;math&gt;\omega = \prod_p p^{n_p},&lt;/math&gt;

where &lt;math&gt;p&lt;/math&gt; runs over all [[prime number]]s, and each &lt;math&gt;n_p&lt;/math&gt; is zero, a natural number or [[infinity]]. Sometimes &lt;math&gt;v_p(\omega)&lt;/math&gt; is used instead of &lt;math&gt;n_p&lt;/math&gt;. If no &lt;math&gt;n_p = \infty&lt;/math&gt; and there are only a finite number of non-zero &lt;math&gt;n_p&lt;/math&gt; then we recover the positive integers. Slightly less intuitively, if all &lt;math&gt;n_p&lt;/math&gt; are &lt;math&gt;\infty&lt;/math&gt;, we get zero. Supernatural numbers extend beyond natural numbers by allowing the possibility of infinitely many prime factors, and by allowing any given prime to divide &lt;math&gt;\omega&lt;/math&gt; "infinitely often," by taking that prime's corresponding exponent to be the symbol &lt;math&gt;\infty&lt;/math&gt;.

There is no natural way to add supernatural numbers, but they can be multiplied, with &lt;math&gt;\prod_p p^{n_p}\cdot\prod_p p^{m_p}=\prod_p p^{n_p+m_p}&lt;/math&gt;. Similarly, the notion of divisibility extends to the supernaturals with &lt;math&gt;\omega_1\mid\omega_2&lt;/math&gt; if &lt;math&gt;v_p(\omega_1)\leq v_p(\omega_2)&lt;/math&gt; for all &lt;math&gt;p&lt;/math&gt;. The notion of the [[least common multiple]] and [[greatest common divisor]] can also be generalized for supernatural numbers, by defining

: &lt;math&gt;\displaystyle \operatorname{lcm}(\{\omega_i\}) \displaystyle =\prod_p p^{\sup(v_p(\omega_i))}&lt;/math&gt;

: &lt;math&gt;\displaystyle \operatorname{gcd}(\{\omega_i\}) \displaystyle =\prod_p p^{\inf(v_p(\omega_i))}&lt;/math&gt; 

With these definitions, the gcd or lcm of infinitely many natural numbers (or supernatural numbers) is a supernatural number.
We can also extend the usual [[p-adic number|&lt;math&gt;p&lt;/math&gt;-adic]] order functions to supernatural numbers by defining &lt;math&gt;v_p(\omega)=n_p&lt;/math&gt; for each &lt;math&gt;p&lt;/math&gt;

Supernatural numbers are used to define orders and indices of [[profinite group]]s and subgroups, in which case many of the theorems from [[finite group theory]] carry over exactly.  They are used to encode the [[algebraic extension]]s of a [[finite field]].&lt;ref&gt;Brawley &amp; Schnibben (1989) pp.25-26&lt;/ref&gt; They are also used implicitly in many [[Number theory|number-theoretical]] proofs, such as the density of the [[square-free integer]]s and bounds for odd [[perfect number]]s.{{cn|date=January 2016}}

==See also==
*[[profinite integer]]

==References==
{{reflist}}
*{{cite book |last1=Brawley |first1=Joel V. |last2=Schnibben |first2=George E. |date=1989 |title=Infinite algebraic extensions of finite fields |series=Contemporary Mathematics |zbl=0674.12009 |volume=95 |publisher=[[American Mathematical Society]] |location=Providence, RI |isbn=0-8218-5101-2 |pages=23–26}}
*{{cite book |last=Efrat |first=Ido |date=2006 |title=Valuations, orderings, and Milnor ''K''-theory |series=Mathematical Surveys and Monographs |volume=124 |publisher=[[American Mathematical Society]] |location=Providence, RI |isbn=0-8218-4041-X |zbl=1103.12002 |page=125}}
*{{cite book |last1=Fried |first1=Michael D. |last2=Jarden |first2=Moshe |date=2008 |title=Field arithmetic |edition=3rd |series=Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge |volume=11 |publisher=[[Springer-Verlag]] |isbn=978-3-540-77269-9 |zbl=1145.12001 |page=520}}

==External links==
* [http://planetmath.org/supernaturalnumber Planet Math: Supernatural number]

{{Number systems}}

[[Category:Number theory]]


{{mathlogic-stub}}</text>
      <sha1>9n2r60qlfl0iifnqg5ggf8ond545x0f</sha1>
    </revision>
  </page>
  <page>
    <title>Tangent indicatrix</title>
    <ns>0</ns>
    <id>24765100</id>
    <revision>
      <id>843538588</id>
      <parentid>790777604</parentid>
      <timestamp>2018-05-29T20:01:30Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Category:Spherical geometry]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="820">In [[differential geometry]], the '''tangent indicatrix''' of a closed [[space curve]] is a [[curve]] on the [[unit sphere]] intimately related to the curvature of the original curve. Let &lt;math&gt;\gamma(t)&lt;/math&gt; be a closed curve with nowhere-vanishing tangent vector &lt;math&gt;\dot{\gamma}&lt;/math&gt;. Then the tangent indicatrix &lt;math&gt;T(t)&lt;/math&gt; of &lt;math&gt;\gamma&lt;/math&gt; is the closed curve on the unit sphere given by &lt;math&gt;T = \frac{\dot{\gamma}}{|\dot{\gamma}|}&lt;/math&gt;.

The [[total curvature]] of &lt;math&gt;\gamma&lt;/math&gt; (the integral of curvature with respect to arc length along the curve) is equal to the [[arc length]] of &lt;math&gt;T&lt;/math&gt;.

==References==
* Solomon, B. "Tantrices of Spherical Curves." Amer. Math. Monthly 103, 30-39, 1996.

{{geometry-stub}}
[[Category:Differential geometry]]
[[Category:Spherical geometry]]</text>
      <sha1>r8jdnouh6jaooodue6uznayurhnr2sh</sha1>
    </revision>
  </page>
  <page>
    <title>Time-bin encoding</title>
    <ns>0</ns>
    <id>6748071</id>
    <revision>
      <id>664485516</id>
      <parentid>653354195</parentid>
      <timestamp>2015-05-28T22:55:18Z</timestamp>
      <contributor>
        <ip>147.83.123.130</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3514">{{No footnotes|date=April 2009}}
'''Time-bin encoding''' is a technique used in [[Quantum information science]] to encode a [[qubit]] of information on a [[photon]].  Quantum information science makes use of qubits as a basic resource similar to [[bit]]s in classical [[computing]]. Qubits are any two-level quantum mechanical system; there are many different physical implementations of qubits, one of which is time-bin encoding.

While the time-bin encoding technique is very robust against [[decoherence]], it does not allow easy interaction between the different qubits. As such, it is much more useful in [[quantum communication]] (such as [[quantum teleportation]] and [[quantum key distribution]]) than in [[quantum computation]].

==Construction of a time-bin encoded qubit==
[[Image:timebin.jpg|center]]

Time-bin encoding is done by having a single-photon go through a [[Mach-Zender interferometer]] (MZ), shown in black here. The photon coming from the left is guided through one of two paths (shown in blue and red); the guiding can be made by [[optical fiber]] or simply in free space using mirrors and [[Beam splitter|polarising cubes]]. One of the two paths is longer than the other. The difference in path length must be longer than the [[coherence length]] of the photon to make sure the path taken can be unambiguously distinguished. The interferometer has to keep a stable phase, which means that the path length difference must vary by much less than the wavelength of light during the experiment. This usually requires active temperature stabilization.

If the photon takes the short path, it is said to be in the state &lt;math&gt;|0 \rangle&lt;/math&gt;; if it takes the long path, it is said to be in the state &lt;math&gt;|1 \rangle&lt;/math&gt;. If the photon has a non-zero probability to take either path, then it is in a coherent superposition of the two states:

: &lt;math&gt;| \psi \rangle = \alpha |0 \rangle + \beta |1 \rangle,\,&lt;/math&gt;

These coherent superpositions of the two possible states are called qubits and are the basic ingredient of [[Quantum information science]].

In general, it is easy to vary the [[Phase (waves)|phase]] gained by the photon between the two paths, for example by stretching the fiber, while it is much more difficult to vary the amplitudes which are therefore fixed, typically at 50%. The created qubit is then

: &lt;math&gt;| \psi \rangle =  \frac{|0 \rangle +e^{i \phi} |1 \rangle}{\sqrt{2}},&lt;/math&gt;

which covers only a subset of all possible qubits.

[[quantum measurement|Measurement]] in the {&lt;math&gt;|0 \rangle&lt;/math&gt;,&lt;math&gt;|1 \rangle&lt;/math&gt;} basis is done by measuring the time of arrival of the photon.  Measurement in other bases can be achieved by letting the photon go through a second MZ before measurement, though, similar to the state preparation, the possible measurement setups are restricted to only a small subset of possible qubit measurements.

==Decoherence==
Time-bin qubits do not suffer from depolarization or polarization mode-dispersion, making them better suited to fiber optics applications than polarization encoding. Photon loss is easily detectable since the absence of photons does not correspond to an allowed state, making it better suited than a photon-number based encoding.

==References==
*http://arxiv.org/abs/quant-ph/0205144
*http://arxiv.org/abs/1306.1250
*http://arxiv.org/abs/1207.6586
*http://arxiv.org/abs/quant-ph/0404124
*http://physics.aps.org/articles/v6/110
*http://arxiv.org/abs/1501.03980
[[Category:Quantum information science]]</text>
      <sha1>pjo45fk3nclixccuwu2qonmd9xc55cj</sha1>
    </revision>
  </page>
  <page>
    <title>Tutte–Berge formula</title>
    <ns>0</ns>
    <id>13250641</id>
    <revision>
      <id>849874966</id>
      <parentid>838423030</parentid>
      <timestamp>2018-07-12T00:18:27Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6713">[[File:Class-2-planar-3-regular.svg|thumb|In this graph, removing one vertex in the center produces three odd components, the three five-vertex lobes of the graph. Therefore, by the Tutte–Berge formula, it has at most (1&amp;minus;3+16)/2 {{=}} 7 edges in any matching.]]
In the [[mathematical]] discipline of [[graph theory]] the '''Tutte–Berge formula''' is a characterization of the size of a [[maximum matching]] in a [[Graph (discrete mathematics)|graph]].  It is a generalization of [[Tutte's theorem]] on [[perfect matching]]s, and is named after [[W. T. Tutte]] (who proved Tutte's theorem) and [[Claude Berge]] (who proved its generalization).

==Statement==
The theorem states that the size of a maximum matching of a graph &lt;math&gt;G=(V,E)&lt;/math&gt; equals

:&lt;math&gt;\frac{1}{2} \min_{U\subseteq V}  \left(|U|-\operatorname{odd}(G-U)+|V|\right), &lt;/math&gt;

where &lt;math&gt;\operatorname{odd}(H)&lt;/math&gt; counts how many of the [[Connected component (graph theory)|connected components]] of the graph &lt;math&gt;H&lt;/math&gt; have an odd number of vertices.

==Explanation==
Intuitively, for any subset ''U'' of the vertices, the only way to completely cover an odd component of ''G''&amp;nbsp;&amp;minus;&amp;nbsp;''U'' by a matching is for one of the matched edges covering the component to be incident to ''U''. If, instead, some odd component had no matched edge connecting it to ''U'', then the part of the matching that covered the component would cover its vertices in pairs, but since the component has an odd number of vertices it would necessarily include at least one leftover and unmatched vertex. Therefore, if some choice of ''U'' has few vertices but its removal creates a large number of odd components, then there will be many unmatched vertices, implying that the matching itself will be small. This reasoning can be made precise by stating that the size of a maximum matching is at most equal to the value given by the Tutte–Berge formula.

The characterization of Tutte and Berge proves that this is the only obstacle to creating a large matching: the size of the optimal matching will be determined by the subset ''U'' with the biggest difference between its numbers of odd components outside ''U'' and vertices inside ''U''. That is, there always exists a subset ''U'' such that deleting ''U'' creates the correct number of odd components  needed to make the formula true. One way to find such a set ''U'' is to choose any maximum matching ''M'', and to let ''X'' be the set of vertices that are either unmatched in ''M'', or that can be reached from an unmatched vertex by an [[Augmenting path|alternating path]] that ends with a matched edge. Then, let ''U'' be the set of vertices that are matched by ''M'' to vertices in ''X''. No two vertices in ''X'' can be adjacent, for if they were then their alternating paths could be concatenated to give a path by which the matching could be increased, contradicting the maximality of ''M''. Every neighbor of a vertex ''x'' in ''X'' must belong to ''U'', for otherwise we could extend an alternating path to ''x'' by one more pair of edges, through the neighbor, causing the neighbor to become part of ''U''. Therefore, in ''G''&amp;nbsp;&amp;minus;&amp;nbsp;''U'', every vertex of ''X'' forms a single-vertex component, which is odd. There can be no other odd components, because all other vertices remain matched after deleting ''U''. So with this construction the size of ''U'' and the number of odd components created by deleting ''U''  are what they need to be to make the formula be true.

==Relation to Tutte's theorem==
[[Tutte's theorem]] characterizes the graphs with [[perfect matching]]s as being the ones for which deleting any subset ''U'' of vertices creates at most |''U''| odd components. (A subset ''U'' that creates at least |''U''| odd components can always be found in the [[empty set]].) In this case, by the Tutte–Berge formula, the size of the matching is |''V''|/2; that is, the maximum matching is a perfect matching. Thus, Tutte's theorem can be derived as a corollary of the Tutte–Berge formula, and the formula can be seen as a generalization of Tutte's theorem.

== See also ==
* [[Graph toughness]], a problem of creating many connected components by removing a small set of vertices without regard to the parity of the components
* [[Hall's marriage theorem]]
* [[Tutte's theorem]]

==References==
*{{cite journal|first=C.|last=Berge|authorlink=Claude Berge|title=Sur le couplage maximum d'un graphe|journal=[[Comptes rendus de l'Académie des sciences|Comptes rendus hebdomadaires des séances de l'Académie des sciences]]|volume=247|year=1958|pages=258–259}}
*{{cite book|first=C.|last=Berge|authorlink=Claude Berge|title=The Theory of Graphs|publisher=Methuen|year=1962|at=Theorem 5, p.&amp;nbsp;181}} Reprinted by Dover Publications, 2001.
*{{cite book|last1=Bondy|first1=J. A.|author1-link=John Adrian Bondy|last2=Murty|first2=U. S. R.|author2-link=U. S. R. Murty| title=Graph theory: an advanced course | series=Graduate Texts in Mathematics | publisher=[[Springer-Verlag]] | year=2007 | isbn=1-84628-969-6 | page=428 }}
*{{cite book|last1=Bondy|first1=J. A.|author1-link=John Adrian Bondy|last2=Murty|first2=U. S. R.|author2-link=U. S. R. Murty|title=Graph Theory with Applications|location=New York|publisher=North Holland|year=1976|isbn=0-444-19451-7|url=http://www.ecp6.jussieu.fr/pageperso/bondy/books/gtwa/gtwa.html|at=Exercise 5.3.4, p.&amp;nbsp;80|deadurl=yes|archiveurl=https://web.archive.org/web/20100413104345/http://www.ecp6.jussieu.fr/pageperso/bondy/books/gtwa/gtwa.html|archivedate=2010-04-13|df=}}
*{{cite book | last=Brualdi | first=Richard A. | title=Combinatorial matrix classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86565-4 | zbl=1106.05001 | page=360 }}
* {{Cite book
 | last=Lovász    | first=László | authorlink=László Lovász
 | last2=Plummer | first2=M. D.  | author2-link = Michael D. Plummer
 | title=Matching theory | year=1986 | publisher=North-Holland | location=Amsterdam | isbn=0-444-87916-1
 | pages=90–91}}
* {{cite book | last=Schrijver | first = Alexander | authorlink=Alexander Schrijver | title=Combinatorial optimization: polyhedra and efficiency | publisher=[[Springer-Verlag]] | year=2003 | isbn=3-540-44389-4 | page=413 }}
*{{cite journal|first=W. T.|last=Tutte|authorlink=W. T. Tutte|title=The factorization of linear graphs|journal=Journal of the London Mathematical Society |series=Series 1|volume=22|issue=2|doi=10.1112/jlms/s1-22.2.107|year=1947|pages=107–111}}

{{DEFAULTSORT:Tutte-Berge formula}}
[[Category:Matching]]
[[Category:Theorems in discrete mathematics]]</text>
      <sha1>78d9h6ee3f57qxleds2zpm8lcdzxjf3</sha1>
    </revision>
  </page>
  <page>
    <title>Type family</title>
    <ns>0</ns>
    <id>38573159</id>
    <revision>
      <id>813161403</id>
      <parentid>699950293</parentid>
      <timestamp>2017-12-02T04:13:07Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: Proceedings of The  → Proceedings of the  (3) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9134">{{About|the association of data types in computer science|the typesetting term|Typeface|the biological term|type (biology)}}

In [[computer science]], a '''type family''' associates [[data type]]s with other [[data type]]s, using a type-level [[function (mathematics)|function]] defined by an open-ended collection of valid instances of input types and the corresponding output types.&lt;ref name="FunWithTypeFunctions"&gt;{{cite web|title=Fun with Type Functions|year=2010|last1=Kiselyov|first1=Oleg|last2=Peyton Jones|first2=Simon|last3=Shan|first3=Chung-chieh|url=http://research.microsoft.com/~simonpj/papers/assoc-types/fun-with-type-funs/typefun.pdf}}&lt;/ref&gt;

Type families are a feature of some [[type system]]s that allow partial functions between types to be defined by [[pattern matching]]. This is in contrast to data [[type constructor]]s, which define [[injective]] functions from all types of a particular [[kind (type theory)|kind]] to a new set of types, and type synonyms (a.k.a. [[typedef]]), which define functions from all types of a particular kind to another existing set of types using a single case.

Type families and [[type class]]es are closely related: normal type classes define partial functions from types to a collection of named ''values'' by pattern matching on the input types, while type families define partial functions from types to ''types'' by pattern matching on the input types. In fact, in many uses of type families there is a single type class which logically contains both values and types associated with each instance. A type family declared inside a type class is called an '''associated type'''.&lt;ref name="AssociatedTypesWithClass"&gt;{{cite journal|title=Associated Types with Class|last1=Chakravarty|first1=Manuel M. T.|last2=Keller|first2=Gabriele|last3=Peyton Jones|first3=Simon|last4=Marlow|first4=Simon|journal=Proceedings of the 32nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages|pages=1–13|publisher=ACM Press|year=2005|url=http://www.cse.unsw.edu.au/~chak/papers/CKPM05.html}}&lt;/ref&gt;

[[Programming language]]s with support for type families or similar features include [[Haskell (programming language)|Haskell]] (with a common language extension),&lt;ref&gt;{{cite web|title=Type Functions, Type Families, and Associated Types in GHC - The Master Plan|url=http://hackage.haskell.org/trac/ghc/wiki/TypeFunctions|accessdate=23 February 2013}}&lt;/ref&gt; [[Standard ML]] (through its module system),&lt;ref&gt;{{cite journal|title=ML Modules and Haskell Type Classes: A Constructive Comparison|year=2008|last1=Wehr|first1=Stefan|last2=Chakravarty|first2=Manuel M. T.|journal=Proceedings of the Sixth ASIAN Symposium on Programming Languages and Systems|publisher=Springer-Verlag|url=http://www.cse.unsw.edu.au/~chak/papers/WC06.html}}&lt;/ref&gt; [[Scala (programming language)|Scala]] (under the name "abstract types"),&lt;ref&gt;{{cite web|title=A Tour of Scala: Abstract Types|url=http://www.scala-lang.org/node/105|accessdate=23 February 2013}}&lt;/ref&gt; and [[C++]] (through use of typedefs in templates).&lt;ref name="AssociatedTypeSynonyms" /&gt;

== Variations ==
The &lt;code&gt;TypeFamilies&lt;/code&gt; extension in the [[Glasgow Haskell Compiler]] supports both ''type synonym families'' and ''data families''. Type synonym families are the more flexible (but harder to type-check) form, permitting the types in the [[codomain]] of the type function to be any type whatsoever with the appropriate [[kind (type theory)|kind]].&lt;ref name="AssociatedTypeSynonyms"&gt;{{cite journal|title=Associated Type Synonyms|last1=Chakravarty|first1=Manuel M. T.|last2=Keller|first2=Gabriele|last3=Peyton Jones|first3=Simon|journal=Proceedings of the Tenth ACM SIGPLAN International Conference on Functional Programming|pages=241–253|publisher=ACM Press|year=2005|url=http://www.cse.unsw.edu.au/~chak/papers/CKP05.html}}&lt;/ref&gt; Data families, on the other hand, restrict the codomain by requiring each instance to define a new [[type constructor]] for the function's result. This ensures that the function is [[injective]], allowing clients' contexts to deconstruct the type family and obtain the original argument type.&lt;ref name="FunWithTypeFunctions" /&gt;

== Motivation and examples ==
Type families are useful in abstracting patterns where a common "organization" or "structure" of types is repeated, but with different specific types in each case. Typical use cases include describing [[abstract data type]]s like generic collections, or [[design pattern]]s like [[model–view–controller]].

=== Self-optimizing abstract data types ===
One of the original motivations for the introduction of associated types was to allow [[abstract data type]]s to be [[parameterized type|parameterized]] by their content type such that the [[data structure]] implementing the abstract type varies in a "self-optimizing" way.&lt;ref name="AssociatedTypesWithClass" /&gt; Normal [[algebraic data type]] parameters can only describe data structures that behave uniformly with respect to all argument types. Associated types, however, can describe a family of data structures that have a uniform interface but vary in implementation according to one or more type parameters. For example,&lt;ref name="AssociatedTypesWithClass" /&gt; using Haskell's associated types notation, we can declare a type class of valid [[Array data type|array]] element types, with an associated data family representing an array of that element type:
&lt;source lang="haskell"&gt;
class ArrayElem e where
    data Array e
    index :: Array e -&gt; Int -&gt; e
&lt;/source&gt;
Instances can then be defined for this class, which define both the data structure used and the operations on the data structure in a single location. For efficiency, we might use a packed [[bit vector]] representation for arrays of [[Boolean data type|Boolean]] values, while using a normal [[array data structure]] for integer values. The data structure for arrays of [[ordered pair]]s is defined recursively as a pair of arrays of each of the element types.
&lt;source lang="haskell"&gt;
instance ArrayElem Bool where
    data Array Bool = BoolArray BitVector
    index (BoolArray ar) i = indexBitVector ar i
instance ArrayElem Int where
    data Array Int = IntArray UIntArr
    index (IntArray ar) i = indexUIntArr ar i
instance (ArrayElem a, ArrayElem b) =&gt; ArrayElem (a, b) where
    data Array (a, b) = PairArray (Array a) (Array b)
    index (PairArray ar br) = (index ar i, index br i)
&lt;/source&gt;
With these definitions, when a client refers to an &lt;code&gt;Array (Int, Bool)&lt;/code&gt;, an implementation is automatically selected using the defined instances.

=== A class for collections ===
Inverting the previous example, we can also use type families to define a class for collection types, where the type function maps each collection type to its corresponding element type:&lt;ref name="AssociatedTypeSynonyms" /&gt;
&lt;source lang="haskell"&gt;
class Collects c where
    type Elem c
    empty :: c
    insert :: Elem c -&gt; c -&gt; c
    toList :: c -&gt; [Elem c]
instance Collects [e] where
    type Elem [e] = e
    empty = []
    insert = (:)
    toList = id
instance Ord e =&gt; Collects (Set.Set e) where
    type Elem (Set.Set e) = e
    empty = Set.empty
    insert = Set.insert
    toList = Set.toList
&lt;/source&gt;
In this example, the use of a type synonym family instead of a data family is essential, since multiple collection types may have the same element type.

== Comparison with functional dependencies ==
[[Type class#Functional dependencies|Functional dependencies]] are another type system feature that have similar uses to associated types. While an associated type adds a named type function mapping the enclosing type class's parameters to another type, a functional dependency lists the result type as another parameter of the type class and adds a constraint between the type parameters (e.g. "parameter ''a'' uniquely determines parameter ''b''", written &lt;code&gt;a -&amp;gt; b&lt;/code&gt;). The most common uses of functional dependencies can be directly converted to associated types and vice versa.&lt;ref name="AssociatedTypeSynonyms" /&gt;

Type families are regarded as being generally easier to type-check than functional dependencies. Another advantage of associated types over functional dependencies is that the latter requires clients using the type class to state all of the dependent types in their contexts, including ones they do not use; since associated types do not require this, adding another associated type to the class requires updating only the class's instances, while clients can remain unchanged. The main advantages of functional dependencies over type families are in their added flexibility in handling a few unusual cases.&lt;ref&gt;{{cite web|title=Type Families (TF) vs Functional Dependencies (FD)|url=http://hackage.haskell.org/trac/ghc/wiki/TFvsFD|accessdate=23 February 2013}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* [http://www.haskell.org/haskellwiki/GHC/Type_families Haskell Wiki documentation on using type families in GHC]

[[Category:Functional programming]]
[[Category:Type theory]]
[[Category:Data types]]
[[Category:Articles with example Haskell code]]</text>
      <sha1>n1hcjdwgwplxfv4oq2pglhqckiy1he2</sha1>
    </revision>
  </page>
  <page>
    <title>Unfolding (functions)</title>
    <ns>0</ns>
    <id>16861692</id>
    <revision>
      <id>819401995</id>
      <parentid>819400104</parentid>
      <timestamp>2018-01-09T04:42:41Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{How-to}} {{First person}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5183">{{Other uses|Unfolding (geometry)}}
{{How-to|date=January 2018}}
{{First person|date=January 2018}}

In mathematics, an '''unfolding''' of a [[function (mathematics)|function]] is a certain family of functions.

Let &lt;math&gt;M&lt;/math&gt; be a [[smooth manifold]] and consider a smooth mapping &lt;math&gt; f : M \to \mathbb{R}.&lt;/math&gt; Let us assume that for given &lt;math&gt; x_0 \in M&lt;/math&gt; and &lt;math&gt;y_0 \in \mathbb{R}&lt;/math&gt; we have &lt;math&gt; f(x_0) = y_0 &lt;/math&gt;. Let &lt;math&gt; N &lt;/math&gt; be a smooth &lt;math&gt;k&lt;/math&gt;-dimensional manifold, and consider the family of mappings (parameterised by &lt;math&gt;N&lt;/math&gt;) given by &lt;math&gt; F : M \times N \to \mathbb{R} .&lt;/math&gt; We say that &lt;math&gt;F&lt;/math&gt; is a &lt;math&gt;k&lt;/math&gt;-parameter unfolding of &lt;math&gt;f&lt;/math&gt; if &lt;math&gt;F(x,0) = f(x)&lt;/math&gt; for all &lt;math&gt;x.&lt;/math&gt; In other words the functions &lt;math&gt; f : M \to \mathbb{R} &lt;/math&gt; and &lt;math&gt; F : M \times \{0\} \to \mathbb{R}&lt;/math&gt; are the same: the function &lt;math&gt;f&lt;/math&gt; is contained in, or is unfolded by, the family &lt;math&gt;F.&lt;/math&gt;

Let &lt;math&gt; f : \mathbb{R}^2 \to \mathbb{R}&lt;/math&gt; be given by &lt;math&gt;f(x,y) = x^2 + y^5.&lt;/math&gt; An example of an unfolding of &lt;math&gt;f&lt;/math&gt; would be &lt;math&gt; F : \mathbb{R}^2 \times \mathbb{R}^3 \to \mathbb{R}&lt;/math&gt; given by 
:&lt;math&gt;F((x,y),(a,b,c)) = x^2 + y^5 + ay + by^2 + cy^3.&lt;/math&gt;
As is the case with unfoldings, &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are called variables and &lt;math&gt;a,&lt;/math&gt; &lt;math&gt;b, &lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; are called parameters – since they parameterise the unfolding.

In practice we require that the unfoldings have certain nice properties. In &lt;math&gt;\mathbb{R}&lt;/math&gt; notice that &lt;math&gt;f&lt;/math&gt; is a smooth mapping from &lt;math&gt;M&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt; and so belongs to the [[function space]] &lt;math&gt;C^{\infty}(M,\mathbb{R}).&lt;/math&gt; As we vary the parameters of the unfolding we get different elements of the function space. Thus, the unfolding induces a function &lt;math&gt;\Phi : N \to C^{\infty}(M,\mathbb{R}).&lt;/math&gt; The space &lt;math&gt; \operatorname{diff}(M) \times \operatorname{diff}(\mathbb{R}),&lt;/math&gt; where &lt;math&gt;\operatorname{diff}(M)&lt;/math&gt; denotes the [[group (mathematics)|group]] of [[diffeomorphism]]s of &lt;math&gt;M&lt;/math&gt; etc., [[group action|acts]] on &lt;math&gt;C^{\infty}(M,\mathbb{R}).&lt;/math&gt; The action is given by &lt;math&gt;(\phi,\psi) \cdot f = \psi \circ f \circ \phi^{-1}.&lt;/math&gt; If &lt;math&gt;g&lt;/math&gt; lies in the [[group orbit|orbit]] of &lt;math&gt;f&lt;/math&gt; under this action then there is a diffeomorphic change of coordinates in &lt;math&gt;M&lt;/math&gt; and &lt;math&gt;\mathbb{R}&lt;/math&gt; which takes &lt;math&gt;g&lt;/math&gt; to &lt;math&gt;f&lt;/math&gt; (and vice versa). One nice property that we may like to impose is that 
:&lt;math&gt; \operatorname{Im}(\Phi) \pitchfork \operatorname{orb}(f) &lt;/math&gt;
where "&lt;math&gt;\pitchfork&lt;/math&gt;" denotes "[[Transversality (mathematics)|transverse]] to". This property ensures that as we vary the unfolding parameters we can predict – by knowing how the orbit [[foliation|foliate]] &lt;math&gt;C^\infty (M,\mathbb{R})&lt;/math&gt; – how the resulting functions will vary.

There is an idea of a versal unfolding. Every versal unfolding has the property that 
&lt;math&gt; \operatorname{Im}(\Phi) \pitchfork \operatorname{orb}(f) &lt;/math&gt;, but the converse is false. Let &lt;math&gt;x_1,\ldots,x_n&lt;/math&gt; be local coordinates on &lt;math&gt;M&lt;/math&gt;, and let &lt;math&gt;\mathcal{O}(x_1,\ldots,x_n)&lt;/math&gt; denote the [[ring (mathematics)|ring]] of smooth functions. We define the [[Jacobian ideal]] of &lt;math&gt;f,&lt;/math&gt; denoted by &lt;math&gt;J_f&lt;/math&gt; as follows:

:&lt;math&gt; J_f := \left\langle \frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n} \right\rangle. &lt;/math&gt;

Then a [[basis (mathematics)|basis]] for a versal unfolding of &lt;math&gt;f&lt;/math&gt; is given by [[quotient ring|quotient]]

:&lt;math&gt; \frac{\mathcal{O}(x_1,\ldots,x_n)}{J_f}&lt;/math&gt;

This quotient is known as the local algebra of &lt;math&gt;f.&lt;/math&gt; The dimension of the local algebra is called the Milnor number of &lt;math&gt;f&lt;/math&gt;. The minimum number of unfolding parameters for a versal unfolding is equal to the Milnor number; that is not to say that every unfolding with that many parameters will be versal! Consider the function &lt;math&gt;f(x,y) = x^2 + y^5.&lt;/math&gt; A calculation shows that

:&lt;math&gt; \frac{\mathcal{O}(x,y)}{\langle 2x, 5y^4 \rangle} = \{y,y^2,y^3\} \ . &lt;/math&gt;

This means that &lt;math&gt;\{y,y^2,y^3\}&lt;/math&gt; give a basis for a versal unfolding, and that 

:&lt;math&gt;F((x,y),(a,b,c)) = x^2 + y^5 + ay + by^2 + cy^3&lt;/math&gt;

is a versal unfolding. A versal unfolding with the minimum possible number of unfolding parameters is called a miniversal unfolding.

Sometimes unfoldings are called deformations, versal unfoldings are called versal deformations, etc.

An important object associated to an unfolding is its bifurcation set. This set lives in the parameter space of the unfolding, and gives all parameter values for which the resulting function has degenerate singularities.

== References ==
* V. I. Arnold, S. M. Gussein-Zade &amp; A. N. Varchenko, Singularities of differentiable maps, Volume 1, Birkhäuser, (1985).
* J. W. Bruce &amp;  P. J. Giblin, Curves &amp; singularities, second edition, Cambridge University press, (1992).

[[Category:Functions and mappings]]
[[Category:Singularity theory]]</text>
      <sha1>epwbgup2tb9slpg23eeaepjjtqxc7b9</sha1>
    </revision>
  </page>
  <page>
    <title>Von Neumann–Bernays–Gödel set theory</title>
    <ns>0</ns>
    <id>528491</id>
    <revision>
      <id>866059361</id>
      <parentid>863532535</parentid>
      <timestamp>2018-10-28T00:19:00Z</timestamp>
      <contributor>
        <username>Glassices</username>
        <id>25419491</id>
      </contributor>
      <minor/>
      <comment>/* Axiom of global choice */ Small typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="92404">In the [[foundations of mathematics]], '''von Neumann–Bernays–Gödel set theory''' ('''NBG''') is an [[axiomatic set theory]] that is a [[conservative extension]] of [[Zermelo–Fraenkel set theory]] (ZFC). NBG introduces the [[Primitive notion|notion]] of [[Class (set theory)|class]], which is a collection of [[Set (mathematics)|set]]s defined by a [[Formula (mathematical logic)|formula]] whose [[Quantifier (logic)|quantifier]]s range only over sets. NBG can define classes that are larger than sets, such as the class of all sets and the class of all [[ordinal number|ordinal]]s. [[Morse–Kelley set theory]] (MK) allows classes to be defined by formulas whose quantifiers range over classes. NBG is finitely axiomatizable, while ZFC and MK are not.

A key theorem of NBG is the class existence theorem, which states that for every formula whose quantifiers range only over sets, there is a class consisting of the sets satisfying the formula. This class is built by mirroring the step-by-step construction of the formula with classes. Since all set-theoretic formulas are constructed from two kinds of [[atomic formula]]s ([[Membership (set theory)|membership]] and [[Equality (mathematics)|equality]]) and finitely many [[logical symbols]], only finitely many [[axiom]]s are needed to build the classes satisfying them. This is why NBG is finitely axiomatizable. Classes are also used for other constructions, for handling the [[Absolute infinite, well-ordering theorem, and paradoxes|set-theoretic paradoxes]], and for stating the [[axiom of global choice]], which is stronger than ZFC's [[axiom of choice]].

[[John von Neumann]] introduced classes into set theory in 1925. The [[primitive notion]]s of his theory were [[Function (set theory)|function]] and [[Argument of a function|argument]]. Using these notions, he defined class and set.&lt;ref name=VN1925def&gt;{{harvnb|von Neumann|1925|pp=221&amp;ndash;224, 226, 229}}; English translation: {{Harvnb|van&amp;nbsp;Heijenoort|2002b|pp=396&amp;ndash;398, 400, 403}}.&lt;/ref&gt; [[Paul Bernays]] reformulated von Neumann's theory by taking class and set as primitive notions.&lt;ref name=Bernays1937def&gt;{{harvnb|Bernays|1937}}, pp. 66&amp;ndash;67.&lt;/ref&gt; [[Kurt Gödel]] simplified Bernays' theory for his [[relative consistency]] proof of the [[axiom of choice]] and the [[generalized continuum hypothesis]].&lt;ref name=Godel1940&gt;{{harvnb|Gödel|1940}}.&lt;/ref&gt;

== Classes in set theory ==
=== The uses of classes ===
Classes have several uses in NBG:
* They produce a finite axiomatization of set theory.
* They are used to state a "very strong form of the [[axiom of choice]]"&lt;ref name=Godelp6&gt;{{harvnb|Gödel|1940|p=6}}.&lt;/ref&gt;—namely, the [[axiom of global choice]]: There exists a global choice function &lt;math&gt;G&lt;/math&gt; defined on the class of all nonempty sets such that &lt;math&gt;G(x) \in x&lt;/math&gt; for every nonempty set &lt;math&gt;x.&lt;/math&gt; This is stronger than ZFC's axiom of choice: For every set &lt;math&gt;s&lt;/math&gt; of nonempty sets, there exists a [[choice function]] &lt;math&gt;f&lt;/math&gt; defined on &lt;math&gt;s&lt;/math&gt; such that &lt;math&gt;f(x) \in x&lt;/math&gt; for all &lt;math&gt;x \in s.&lt;/math&gt;&lt;ref&gt;[[#Axiom of global choice]] explains why it is provably stronger.&lt;/ref&gt; 
* The [[Absolute infinite, well-ordering theorem, and paradoxes|set-theoretic paradoxes]] are handled by recognizing that some classes cannot be sets. For example, assume that the class &lt;math&gt;Ord&lt;/math&gt; of all [[Ordinal number|ordinal]]s is a set. Then &lt;math&gt;Ord&lt;/math&gt; is a [[Transitive (set theory)|transitive]] set [[well-order]]ed by &lt;math&gt;\in&lt;/math&gt;. So, by definition, &lt;math&gt;Ord&lt;/math&gt; is an ordinal. Hence, &lt;math&gt;Ord \in Ord&lt;/math&gt;, which contradicts &lt;math&gt;\in&lt;/math&gt; being a well-ordering of &lt;math&gt;Ord.&lt;/math&gt; Therefore, &lt;math&gt;Ord&lt;/math&gt; is not a set. Because a class that is not a set is called a [[proper class]], &lt;math&gt;Ord&lt;/math&gt; is a proper class.
* Proper classes are useful in constructions. In his proof of the relative consistency of the axiom of global choice and the [[generalized continuum hypothesis]], Gödel used proper classes to build the [[constructible universe]]. He constructed a function on the class of all ordinals that, for each ordinal, builds a constructible set by applying a set-building operation to previously constructed sets. The constructible universe is the [[Image (set theory)|image]] of this function.&lt;ref&gt;{{harvnb|Gödel|1940|pp=35&amp;ndash;38}}.&lt;/ref&gt;&lt;br&gt;

=== Axiom schema versus class existence theorem ===
Once classes are added to the language, it is simple to axiomatize a set theory with classes that is similar to ZFC. First, the [[axiom schema]] of class comprehension is added. This axiom schema states: For every formula &lt;math&gt;\phi(x_1, \ldots, x_n)&lt;/math&gt; that quantifies only over sets, there exists a class &lt;math&gt;A&lt;/math&gt; consisting of the {{nowrap|&lt;math&gt;n&lt;/math&gt;-[[tuple]]s}} satisfying the formula—that is, &lt;math&gt;\forall x_1 \cdots \,\forall x_n [(x_1, \ldots , x_n) \in A \iff \phi(x_1, \ldots, x_n)].&lt;/math&gt; Then the [[axiom schema of replacement]] is replaced by a [[#NBG's axiom of replacement|single axiom]] that uses a class. Finally, ZFC's [[axiom of extensionality]] is modified to handle classes: If two classes have the same elements, then they are identical. The other axioms of ZFC are not modified.

This theory is not finitely axiomatized. ZFC's replacement schema has been replaced by a single axiom, but the axiom schema of class comprehension has been introduced. 

To produce a theory with finitely many axioms, the axiom schema of class comprehension must be replaced with a class existence theorem that makes the same statement: For every formula that quantifies only over sets, there exists a class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying it. The proof of this theorem, which is [[#CET|given below]], requires only finitely many class existence axioms to translate the construction of a formula into a construction of the class satisfying the formula.

== Axiomatization of NBG ==
=== Classes and sets ===
NBG has two types of objects: classes and sets. Intuitively, every set is also a class. There are two ways to axiomatize this. Bernays used [[First-order_logic#Many-sorted_logic|many-sorted logic]] with two sorts: classes and sets. Gödel avoided sorts by introducing primitive predicates: &lt;math&gt;\mathfrak{Cls}(A)&lt;/math&gt; for "&lt;math&gt;A&lt;/math&gt; is a class" and &lt;math&gt;\mathfrak{M}(A)&lt;/math&gt; for "&lt;math&gt;A&lt;/math&gt; is a set" (in German, "set" is ''Menge''). He also introduced axioms stating that every set is a class and that if class &lt;math&gt;A&lt;/math&gt; is a member of a class, then &lt;math&gt;A&lt;/math&gt; is a set.&lt;ref name=Godel1940p3&gt;{{harvnb|Gödel|1940|p=3}}.&lt;/ref&gt; Using predicates is the standard way to eliminate sorts. [[Elliott Mendelson]] modified Gödel's approach by having everything be a class and defining the set predicate &lt;math&gt;M(A)&lt;/math&gt; as &lt;math&gt;\exists C(A \in C).&lt;/math&gt;&lt;ref&gt;{{harvnb|Mendelson|1997|pp=225&amp;ndash;226}}.&lt;/ref&gt; This modification eliminates Gödel's class predicate and his two axioms.

Bernays' two-sorted approach may appear more natural at first, but it creates a more complex theory.{{efn|The historical development suggests that the two-sorted approach does appear more natural at first. In introducing his theory, Bernays stated: "According to the leading idea of von Neumann set theory we have to deal with two kinds of individuals, which we may distinguish as ''sets'' and ''classes''." {{harv|Bernays|1937|p=66.}}}} In Bernays' theory, every set has two representations: one as a set and the other as a class. Also, there are two [[membership relation]]s: the first, denoted by "∈", is between two sets; the second, denoted by "η", is between a set and a class. This redundancy is required by many-sorted logic because variables of different sorts range over disjoint subdomains of the [[domain of discourse]].

The differences between these two approaches does not affect what can be proved, but it does affect how statements are written. In Gödel's approach, &lt;math&gt;A \in C&lt;/math&gt; where &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;C&lt;/math&gt; are classes is a valid statement. In Bernays' approach this statement has no meaning. However, if &lt;math&gt;A&lt;/math&gt; is a set, there is an equivalent statement: Define "set &lt;math&gt;a&lt;/math&gt; represents class &lt;math&gt;A&lt;/math&gt;" if they have the same sets as members—that is, &lt;math&gt;\forall x(x \in a \iff x \;\eta \;A).&lt;/math&gt; The statement &lt;math&gt;a \;\eta \;C&lt;/math&gt; where set &lt;math&gt;a&lt;/math&gt; represents class &lt;math&gt;A&lt;/math&gt; is equivalent to Gödel's &lt;math&gt;A \in C.&lt;/math&gt;&lt;ref name=Bernays1937def /&gt;

The approach adopted in this article is that of Gödel with Mendelson's modification. This means that NBG is a [[axiomatic system]] in [[first-order predicate logic]] with [[Equality in set theory|equality]], and its only [[primitive notion]]s are class and the membership relation.

=== Definitions and axioms of extensionality and pairing ===
A set is a class that belongs to at least one class: &lt;math&gt;A&lt;/math&gt; is a set if and only if &lt;math&gt;\exist C(A \in C)&lt;/math&gt;.
A class that is not a set is called a proper class: &lt;math&gt;A&lt;/math&gt; is a proper class if and only if &lt;math&gt;\forall C(A \notin C)&lt;/math&gt;.
Therefore, every class is either a set or a proper class, and no class is both (if the theory is [[consistent]]).

Gödel introduced the convention that uppercase variables range over classes, while lowercase variables range over sets.&lt;ref name=Godel1940p3 /&gt; Gödel also used names that begin with an uppercase letter to denote particular classes, including functions and [[relation (math)|relation]]s defined on the class of all sets. Gödel's convention is used in this article. It allows us to write:
{{plainlist|indent=1}}
* &lt;math&gt;\exist x\, \phi(x)&lt;/math&gt; instead of &lt;math&gt;\exist x \bigl(\exist C (x \in C) \land \phi(x)\bigr)&lt;/math&gt;
* &lt;math&gt;\forall x\, \phi(x)&lt;/math&gt; instead of &lt;math&gt;\forall x \bigl(\exist C (x \in C) \implies \phi(x)\bigr)&lt;/math&gt;
{{endplainlist}}

The following axioms and definitions are needed for the proof of the class existence theorem.

'''Axiom of extensionality.{{space|thin}}''' If two classes have the same elements, then they are identical.
:&lt;math&gt;\forall A \,\forall B \,[\forall x(x \in A \iff x \in B) \implies A = B]&lt;/math&gt;

This axiom generalizes ZFC's [[axiom of extensionality]] to classes. 

'''[[Axiom of pairing]].{{space|thin}}''' If &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are sets, then there exists a set &lt;math&gt;p&lt;/math&gt; whose only members are &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;.
:&lt;math&gt;\forall x \,\forall y \,\exists p \,\forall z \,[z \in p \iff (z = x \,\lor\, z = y)]&lt;/math&gt;

As in ZFC, the axiom of extensionality implies the uniqueness of the set &lt;math&gt;p&lt;/math&gt;, which allows us to introduce the notation &lt;math&gt;\{x, y\}&lt;/math&gt;. 

[[Ordered pair]]s are defined by: 
:&lt;math&gt;(x, y) = \{\{x\}, \{x, y\}\}&lt;/math&gt;
Tuples are defined [[Inductive definition|inductive]]ly using ordered pairs:
:&lt;math&gt;(x_1) = x_1&lt;/math&gt;
:&lt;math&gt;\text{For } n &gt; 1\!: (x_1, \ldots, x_{n-1}, x_n) = ((x_1, \ldots, x_{n-1}), x_n)&lt;/math&gt;{{efn|Gödel defined &lt;math&gt;(x_1, x_2, \ldots, x_n) = (x_1, (x_2, \ldots, x_n)).&lt;/math&gt; This affects the statements of some of his definitions, axioms, and theorems. This article uses Mendelson's definition. ({{harvnb|Gödel|1940|p=4}}; {{harvnb|Mendelson|1997|p=230}}.)}}

=== Class existence axioms and axiom of regularity ===
The class existence axioms will be used to prove the class existence theorem: For every formula in &lt;math&gt;n&lt;/math&gt; [[free variable|free set variable]]s that quantifies only over sets, there exists a class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} that satisfy it. The following example starts with two classes that are [[Function (set theory)|function]]s and builds a [[composite function]]. This example illustrates the techniques used to prove the class existence theorem, and hence the types of class existence axioms that are needed.

{{Anchor|Ex1}}
:{| class="wikitable"
|- style="text-align: left; vertical-align: top; style="background: white" 
|'''Example 1:{{space|thin}}''' If the classes &lt;math&gt;F&lt;/math&gt; and &lt;math&gt;G&lt;/math&gt; are functions, then the composite function &lt;math&gt;G \circ F&lt;/math&gt; is defined by the formula: &lt;math&gt;\exists t[(x, t) \in F \,\land\, (t, y) \in G].&lt;/math&gt; Since this formula has two free set variables, &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y,&lt;/math&gt; the class existence theorem constructs the class of ordered pairs: &lt;math&gt;G \circ F\,=\,\{(x, y): \exists t[(x, t) \in F \,\land\, (t, y) \in G]\}.&lt;/math&gt; 

Because this formula is built from simpler formulas using [[Conjunction (logic)|conjunction]] &lt;math&gt;\land&lt;/math&gt; and [[existential quantification]] &lt;math&gt;\exists&lt;/math&gt;, class [[Operation (mathematics)|operation]]s are needed that take classes representing the simpler formulas and produce classes representing the formulas with &lt;math&gt;\land&lt;/math&gt; and &lt;math&gt;\exists&lt;/math&gt;. To produce a class representing a formula with &lt;math&gt;\land&lt;/math&gt;, [[Intersection (set theory)|intersection]] used since &lt;math&gt;x \in A \cap B \iff x \in A \land x \in B.&lt;/math&gt; To produce a class representing a formula with &lt;math&gt;\exists&lt;/math&gt;, the [[Domain of a relation|domain]] is used since &lt;math&gt;x \in Dom(A) \iff \exists t[(x,t) \in A].&lt;/math&gt;

Before taking the intersection, the tuples in &lt;math&gt;F&lt;/math&gt; and &lt;math&gt;G&lt;/math&gt; need an extra component so they have the same variables. The component &lt;math&gt;y&lt;/math&gt; is added to the tuples of &lt;math&gt;F&lt;/math&gt; and &lt;math&gt;x&lt;/math&gt; is added to the tuples of &lt;math&gt;G&lt;/math&gt;: 
:&lt;math&gt;F' = \{(x, t, y): (x, t) \in F\}\,&lt;/math&gt; and &lt;math&gt;\,G' = \{(t, y, x): (t, y) \in G\}&lt;/math&gt; 
In the definition of &lt;math&gt;F',&lt;/math&gt; the variable &lt;math&gt;y&lt;/math&gt; is not restricted by the statement &lt;math&gt;(x, t) \in F,&lt;/math&gt; so &lt;math&gt;y&lt;/math&gt; ranges over the class &lt;math&gt;V&lt;/math&gt; of all sets. Similarly, in the definition of &lt;math&gt;G',&lt;/math&gt; the variable &lt;math&gt;x&lt;/math&gt; ranges over &lt;math&gt;V.&lt;/math&gt; So an axiom is needed that adds an extra component (whose values range over &lt;math&gt;V&lt;/math&gt;) to the tuples of a given class.

Next, the variables are put in the same order to prepare for the intersection: 
:&lt;math&gt;F'' = \{(x, y, t): (x, t) \in F\}\,&lt;/math&gt; and &lt;math&gt;\,G'' = \{(x, y, t): (t, y) \in G\}&lt;/math&gt;
To go from &lt;math&gt;F'&lt;/math&gt; to &lt;math&gt;F''&lt;/math&gt; and from &lt;math&gt;G'&lt;/math&gt; to &lt;math&gt;G''&lt;/math&gt; requires two different [[permutation]]s, so axioms that support permutations of tuple components are needed.

The intersection of &lt;math&gt;F''&lt;/math&gt; and &lt;math&gt;G''&lt;/math&gt; handles &lt;math&gt;\land&lt;/math&gt;:
:&lt;math&gt;F'' \cap G'' = \{(x, y, t): (x, t) \in F \,\land\, (y, t) \in G\}&lt;/math&gt;

Since &lt;math&gt;(x, y, t)&lt;/math&gt; is defined as &lt;math&gt;((x, y), t)&lt;/math&gt;, taking the domain of &lt;math&gt;F'' \cap G''&lt;/math&gt; handles &lt;math&gt;\exists t&lt;/math&gt; and produces the composite function:
:&lt;math&gt;G \circ F = Dom(F'' \cap G'') = \{(x, y): \exists t ((x, t) \in F \,\land\, (t, y) \in G)\}&lt;/math&gt;
So axioms of intersection and domain are needed.
|}

The class existence axioms are divided into two groups: axioms handling language primitives and axioms handling tuples. There are four axioms in the first group and three axioms in the second group.{{efn|Bernays' class existence axioms specify unique classes. Gödel weakened all but three of Bernays' axioms (intersection, complement, domain) by replacing [[biconditional]]s with [[Material conditional|implication]]s, which means they specify only the ordered pairs or the 3-tuples of the class. The axioms in this section are Gödel's except for Bernays' stronger [[#Product by V axiom|product by V axiom]], which specifies a unique class of ordered pairs. Bernays' axiom simplifies the proof of the [[#CET|class existence theorem]]. Gödel's axiom B6 appears as the fourth statement of the [[#Tuple lemma|tuple lemma]]. Bernays later realized that one of his axioms is redundant, which implies that one of Gödel's axioms is redundant. Using the other axioms, axiom B6 can be proved from axiom B8, and B8 can be proved from B6, so either axiom can be considered the redundant axiom. ({{harvnb|Kanamori|2009|p=56}}; {{harvnb|Bernays|1937|p=69}}; {{harvnb|Gödel|1940|pp=5, 9}}; {{harvnb|Mendelson|1997|p=231}}.) The names for the tuple-handling axioms are from the French Wikipédia article: [[:fr:Théorie des ensembles de von Neumann-Bernays-Gödel#Compréhension pour les classes|Théorie des ensembles de von Neumann]].}}

'''Axioms for handling language primitives:'''

'''Membership.{{space|thin}}''' There exists a class &lt;math&gt;E&lt;/math&gt; containing all the ordered pairs whose first component is a member of the second component.
:&lt;math&gt;\exists E \,\forall x \,\forall y \,[(x,y) \in E \iff x \in y]&lt;/math&gt;

'''Intersection (conjunction).{{space|thin}}''' For any two classes &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, there is a class &lt;math&gt;C&lt;/math&gt; consisting precisely of the sets that belong to both &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;.
:&lt;math&gt;\forall A \,\forall B \,\exists C \,\forall x \,[x \in C \iff (x \in A \,\land\, x \in B)]&lt;/math&gt;

'''[[Complement (set theory)|Complement]] (negation).{{space|thin}}''' For any class &lt;math&gt;A&lt;/math&gt;, there is a class &lt;math&gt;B&lt;/math&gt; consisting precisely of the sets not belonging to &lt;math&gt;A&lt;/math&gt;.
:&lt;math&gt;\forall A \,\exists B \,\forall x \,[x \in B \iff \neg(x \in A)]&lt;/math&gt;

'''Domain (existential quantifier).{{space|thin}}''' For any class &lt;math&gt;A&lt;/math&gt;, there is a class &lt;math&gt;B&lt;/math&gt; consisting precisely of the first components of the ordered pairs of &lt;math&gt;A&lt;/math&gt;. 
:&lt;math&gt;\forall A \,\exists B \,\forall x \,[x \in B \iff \exists y((x,y) \in A)]&lt;/math&gt; &lt;br /&gt;

By the axiom of extensionality, class &lt;math&gt;C&lt;/math&gt; in the intersection axiom and class &lt;math&gt;B&lt;/math&gt; in the complement and domain axioms are unique. They will be denoted by: &lt;math&gt;A \cap B,&lt;/math&gt; &lt;math&gt;\complement A,&lt;/math&gt; and &lt;math&gt;Dom(A),&lt;/math&gt; respectively.{{efn|name=Bourbaki|This article uses [[Nicolas Bourbaki|Bourbaki]]'s complement notation &lt;math&gt;\complement A&lt;/math&gt; and relative complement notation &lt;math&gt;\complement_X A = \complement_A \cap X&lt;/math&gt; {{harv|Bourbaki|2004|p=71}}. This prefix relative complement notation is used by the class existence theorem to [[#Mirror|mirror]] the prefix logical not (&lt;math&gt;\neg&lt;/math&gt;).}} On the other hand, extensionality is not applicable to &lt;math&gt;E&lt;/math&gt; in the membership axiom since it specifies only those sets in &lt;math&gt;E&lt;/math&gt; that are ordered pairs.   

{{Anchor|Empty class}}The first three axioms imply the existence of the empty class and the class of all sets: The membership axiom implies the existence of a class &lt;math&gt;E.&lt;/math&gt; The intersection and complement axioms imply the existence of &lt;math&gt;E \cap \complement E&lt;/math&gt;, which is empty. By the axiom of extensionality, this class is unique; it is denoted by &lt;math&gt;\empty.&lt;/math&gt; The complement of &lt;math&gt;\empty&lt;/math&gt; is the class &lt;math&gt;V&lt;/math&gt;of all sets, which is also unique by extensionality. The set predicate &lt;math&gt;M(A)&lt;/math&gt;, which was defined as &lt;math&gt;\exists C(A \in C)&lt;/math&gt;, is now redefined as &lt;math&gt;A \in V&lt;/math&gt; to avoid quantifying over classes.

'''Axioms for handling tuples:'''

{{Anchor|Product by V axiom}}'''[[Cartesian product|Product]] by &lt;math&gt;V&lt;/math&gt;.{{space|thin}}''' For any class &lt;math&gt;A&lt;/math&gt;, there is a class &lt;math&gt;B&lt;/math&gt; consisting precisely of the ordered pairs whose first component belongs to &lt;math&gt;A&lt;/math&gt;.  
:&lt;math&gt;\forall A \,\exists B \,\forall u \,[u \in B \iff \exists x \, \exists y \,(u = (x, y) \land x \in A)]&lt;/math&gt;

'''[[Circular permutation]].{{space|thin}}''' For any class &lt;math&gt;A&lt;/math&gt;, there is a class &lt;math&gt;B&lt;/math&gt; whose 3{{nbhyph}}tuples are obtained by applying the circular permutation &lt;math&gt;(y,z,x) \mapsto (x,y,z)&lt;/math&gt; to the 3{{nbhyph}}tuples of &lt;math&gt;A&lt;/math&gt;.
:&lt;math&gt;\forall A \,\exists B \,\forall x \,\forall y \,\forall z \,[(x,y,z) \in B \iff (y,z,x) \in A]&lt;/math&gt;

'''[[Transposition (mathematics)|Transposition]].{{space|thin}}''' For any class &lt;math&gt;A&lt;/math&gt;, there is a class &lt;math&gt;B&lt;/math&gt; whose 3{{nbhyph}}tuples are obtained by transposing the last two components of the 3{{nbhyph}}tuples of &lt;math&gt;A&lt;/math&gt;.
:&lt;math&gt;\forall A \,\exists B \,\forall x \,\forall y \,\forall z \,[(x,y,z) \in B \iff (x,z,y) \in A]&lt;/math&gt;

By extensionality, the product by &lt;math&gt;V&lt;/math&gt; axiom implies the existence of a unique class, which is denoted by &lt;math&gt;A \times V.&lt;/math&gt; This axiom is used to define the class &lt;math&gt;V^n&lt;/math&gt; of all {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}}: &lt;math&gt;V^1 = V&lt;/math&gt; and &lt;math&gt;V^{n+1} = V^n \times V.\,&lt;/math&gt; If &lt;math&gt;A&lt;/math&gt; is a class, extensionality implies that &lt;math&gt;A \cap V^n&lt;/math&gt; is the unique class consisting of the {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} of &lt;math&gt;A.&lt;/math&gt; For example, the membership axiom produces a class &lt;math&gt;E&lt;/math&gt; that may contain elements that are not ordered pairs, while the intersection &lt;math&gt;E \cap V^2&lt;/math&gt; contains only the ordered pairs of &lt;math&gt;E&lt;/math&gt;.

The circular permutation and transposition axioms do not imply the existence of unique classes because they specify only the 3{{nbhyph}}tuples of class &lt;math&gt;B.&lt;/math&gt; By specifying the 3{{nbhyph}}tuples, these axioms also specify the {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} for &lt;math&gt;n \ge 4&lt;/math&gt; since: &lt;math&gt;(x_1, \ldots, x_{n-2}, x_{n-1}, x_n) = ((x_1, \ldots, x_{n-2}), x_{n-1}, x_n).&lt;/math&gt; The axioms for handling tuples and the domain axiom imply the following lemma, which is used in the proof of the class existence theorem.

{{Anchor|Tuple lemma}}'''Tuple lemma.'''
# &lt;math&gt;\,\forall A \,\exists B_1 \,\forall x \,\forall y \,\forall z \,[(z,x,y) \in B_1 \iff (x,y) \in A]&lt;/math&gt;
# &lt;math&gt;\,\forall A \,\exists B_2 \,\forall x \,\forall y \,\forall z \,[(x,z,y) \in B_2 \iff (x,y) \in A]&lt;/math&gt;
# &lt;math&gt;\,\forall A \,\exists B_3 \,\forall x \,\forall y \,\forall z \,[(x,y,z) \in B_3 \iff (x,y) \in A]&lt;/math&gt;
# &lt;math&gt;\,\forall A \,\exists B_4 \,\forall x \,\forall y \,\forall z \,[(y,x) \in B_4 \iff (x,y) \in A]&lt;/math&gt;

'''Proof:'''{{space|2|thin}}Class &lt;math&gt;B_3&lt;/math&gt;: Apply product by &lt;math&gt;V&lt;/math&gt; to &lt;math&gt;A&lt;/math&gt; to produce &lt;math&gt;B_3.&lt;/math&gt;&lt;br&gt;
{{space|12}}Class &lt;math&gt;B_2&lt;/math&gt;: Apply transposition to &lt;math&gt;B_3&lt;/math&gt; to produce &lt;math&gt;B_2.&lt;/math&gt;&lt;br&gt;
{{space|12}}Class &lt;math&gt;B_1&lt;/math&gt;: Apply circular permutation to &lt;math&gt;B_3&lt;/math&gt; to produce &lt;math&gt;B_1.&lt;/math&gt;&lt;br&gt;
{{space|12}}Class &lt;math&gt;B_4&lt;/math&gt;: Apply circular permutation to &lt;math&gt;B_2&lt;/math&gt;, then apply domain to produce &lt;math&gt;B_4.&lt;/math&gt;

One more axiom is needed to prove the class existence theorem: the [[axiom of regularity]]. Since the existence of the empty class has been proved, the usual statement of this axiom is given.{{efn|Since Gödel states this axiom before he proves the existence of the empty class, he states it without using the empty class {{harv|Gödel|1940|p=6}}.}}

{{Anchor|Axiom of regularity}}'''Axiom of regularity.{{space|thin}}''' Every nonempty set has at least one element with which it has no element in common.
:&lt;math&gt;\forall a\,[a \neq \empty \implies \exists u(u \in a \land u \cap a = \empty)].&lt;/math&gt;

This axiom implies that a set cannot belong to itself: Assume that &lt;math&gt;x \in x&lt;/math&gt; and let &lt;math&gt;a = \{x\}.&lt;/math&gt; Then &lt;math&gt;x \cap a \ne \empty&lt;/math&gt; since &lt;math&gt;x \in x \cap a.&lt;/math&gt; This contradicts the axiom of regularity because &lt;math&gt;x&lt;/math&gt; is the only element in &lt;math&gt;a.&lt;/math&gt; Therefore, &lt;math&gt;x \notin x.&lt;/math&gt; The axiom of regularity also prohibits infinite descending membership sequences: &lt;math&gt;\;\;\cdots \in x_{n+1} \in x_n \in \cdots \in x_1 \in x_0.&lt;/math&gt;

Gödel stated regularity for classes rather than for sets in his 1940 monograph, which was based on lectures given in 1938.&lt;ref&gt;{{harvnb|Gödel|1940|p=6}}; {{harvnb|Kanamori|2012|p=70}}.&lt;/ref&gt; In 1939, he proved that regularity for sets implies regularity for classes.&lt;ref&gt;{{harvnb|Kanamori|2009|p=57}}; {{harvnb|Gödel|2003|p=121}}. Both references contain Gödel's proof but Kanamori is easier to follow since he uses modern terminology.&lt;/ref&gt;

=== Class existence theorem ===
{{Anchor|CET}}'''Class existence theorem.{{space|thin}}''' Let &lt;math&gt;\phi(x_1, \dots, x_n, Y_1, \dots, Y_m)&lt;/math&gt; be a formula that quantifies only over sets and contains no [[free variable]]s other than &lt;math&gt;x_1, \dots, x_n, Y_1, \dots, Y_m&lt;/math&gt; (not necessarily all of these). Then for all &lt;math&gt;Y_1, \dots, Y_m&lt;/math&gt;, there exists a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that: &lt;math&gt;\forall x_1 \cdots \,\forall x_n [(x_1, \dots , x_n) \in A \iff \phi(x_1, \dots, x_n, Y_1, \dots, Y_m)].&lt;/math&gt; The class &lt;math&gt;A&lt;/math&gt; is denoted by &lt;math&gt;\{(x_1, \dots , x_n): \phi(x_1, \dots, x_n, Y_1, \dots, Y_m)\}.&lt;/math&gt;{{efn|The proofs in this and the next section come from Gödel's proofs, which he gave at the [[Institute for Advanced Study]] where he "could count upon an audience well versed in [[mathematical logic]]" {{harv|Dawson|1997|p=134}}. To make Gödel's proofs more accessible to Wikipedia readers, a few modifications have been made. The goal in this and the next section is to prove Gödel's M4, his fourth class existence theorem. The proof in this section mostly follows the M1 proof {{harv|Gödel|1940|pp=8&amp;ndash;11}}, but it also uses techniques from the M3 and M4 proofs. The theorem is stated with class variables rather than M1's symbols for special classes (universal quantification over the class variables is equivalent to being true for any instantiation of the class variables). The major differences from the M1 proof are: unique classes of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} are generated at the end of the basis and inductive steps (which require Bernays' stronger product by &lt;math&gt;V&lt;/math&gt; axiom), and [[bound variable]]s are replaced by subscripted variables that continue the numbering of the free set variables. Since bound variables are free for part of the induction, this guarantees that, when they are free, they are treated the same as the original free variables. One of the benefits of this proof is the [[#Mirror|example output]] of the function Class, which shows that a class's construction mirrors its defining formula's construction.}}

The theorem's proof will be done in two steps:
# Transformation rules are used to transform the given formula &lt;math&gt;\phi&lt;/math&gt; into a [[logically equivalent|equivalent]] formula that simplifies the [[Mathematical induction|inductive]] part of the proof. For example, the only logical symbols in the transformed formula are &lt;math&gt;\neg&lt;/math&gt;, &lt;math&gt;\land&lt;/math&gt;, and &lt;math&gt;\exists&lt;/math&gt;, so the induction handles logical symbols with just three cases.  
# The class existence theorem is proved inductively for transformed formulas. Guided by the structure of the transformed formula, the class existence axioms are used to produce the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying the formula.

'''Transformation rules.{{space|thin}}''' In rules 1 and 2, &lt;math&gt;\Delta&lt;/math&gt; and &lt;math&gt;\Gamma&lt;/math&gt; denote set or class variables. These two rules eliminate all occurrences of class variables before an &lt;math&gt;\in&lt;/math&gt; and all occurrences of equality. Each time rule 1 or 2 is applied to a subformula, &lt;math&gt;i&lt;/math&gt; is chosen so that &lt;math&gt;z_i&lt;/math&gt; differs from the other variables in the current formula. The three rules are repeated until there are no subformulas to which they can be applied. This produces a formula that is built only with &lt;math&gt;\neg&lt;/math&gt;, &lt;math&gt;\land&lt;/math&gt;, &lt;math&gt;\exists&lt;/math&gt;, &lt;math&gt;\in&lt;/math&gt;, set variables, and class variables &lt;math&gt;Y_k&lt;/math&gt; where &lt;math&gt;Y_k&lt;/math&gt; does not appear before an &lt;math&gt;\in&lt;/math&gt;.

# &lt;math&gt;\,Y_k \in \Gamma&lt;/math&gt; is transformed into &lt;math&gt;\exists z_i(z_i = Y_k \,\land\, z_i \in \Gamma).&lt;/math&gt;
# Extensionality is used to transform &lt;math&gt;\Delta = \Gamma&lt;/math&gt; into &lt;math&gt;\forall z_i(z_i \in \Delta \iff z_i \in \Gamma).&lt;/math&gt; 
# Logical identities are used to transform subformulas containing &lt;math&gt;\lor, \implies, \iff,&lt;/math&gt; and &lt;math&gt;\forall&lt;/math&gt; to subformulas that only use &lt;math&gt;\neg, \land,&lt;/math&gt; and &lt;math&gt;\exists.&lt;/math&gt;

'''Transformation rules: [[bound variables]].{{space|thin}}''' Consider the composite function formula of [[#Ex1|example 1]] with its free set variables replaced by &lt;math&gt;x_1&lt;/math&gt; and &lt;math&gt;x_2&lt;/math&gt;: &lt;math&gt;\exists t[(x_1, t) \in F \,\land\, (t, x_2) \in G].&lt;/math&gt; The inductive proof will remove &lt;math&gt;\exists t&lt;/math&gt;, which produces the formula &lt;math&gt;(x_1, t) \in F \land (t, x_2) \in G.&lt;/math&gt; However, since the class existence theorem is stated for subscripted variables, this formula does not have the form expected by the [[induction hypothesis]]. This problem is solved by replacing the variable &lt;math&gt;t&lt;/math&gt; with &lt;math&gt;x_3.&lt;/math&gt; Bound variables within nested quantifiers are handled by increasing the subscript by one for each successive quantifier. This leads to rule 4, which must be applied after the other rules since rules 1 and 2 produce quantified variables.

# &lt;li value="4"&gt;If a formula contains no free set variables other than &lt;math&gt;x_1, \dots, x_n,&lt;/math&gt; then bound variables that are nested within &lt;math&gt;q&lt;/math&gt; quantifiers are replaced with {{nowrap|&lt;math&gt;x_{n+q}&lt;/math&gt;.}} These variables have ''(quantifier) nesting depth'' &lt;math&gt;q&lt;/math&gt;.&lt;/li&gt;  

{{Anchor|Ex2}}
:{| class="wikitable"
|- style="text-align: left; vertical-align: top; style="background: white" 
|'''Example 2:''' {{space|thin}}Rule 4 is applied to the formula &lt;math&gt;\phi(x_1)&lt;/math&gt; that defines the class consisting of all sets of the form &lt;math&gt;\{\empty, \{\empty, \dots\}, \dots\}.&lt;/math&gt; That is, sets that contain at least &lt;math&gt;\empty&lt;/math&gt; and a set containing &lt;math&gt;\empty&lt;/math&gt; — for example, &lt;math&gt;\{\empty, \{\empty, a, b, c\}, d, e\}&lt;/math&gt; where &lt;math&gt;a, b, c, d,&lt;/math&gt; and &lt;math&gt;e&lt;/math&gt; are sets.

&lt;math&gt;\begin{align}
\phi(x_1) \,&amp;=\, \exists u\;\,[\,u \in x_1 \,\land\, \neg\exists v\;\,(\;v\, \in \,u\,)] \,\land\, \,\exists w\;\bigl(w \in x_1 \,\land\, \exists y\;\,[(\;y\, \in w \;\land\; \neg\exists z\;\,(\;z\, \in \,y\,)]\bigr) \\
\phi_r(x_1) \,&amp;=\, \exists x_2[x_2 \!\in\! x_1 \,\land\, \neg\exists x_3(x_3 \!\in\! x_2)] \,\land\, \,\exists x_2\bigl(x_2 \!\in\! x_1 \,\land\, \exists x_3[(x_3 \!\in\! x_2 \,\land\, \neg\exists x_4(x_4 \!\in\! x_3)]\bigr)
\end{align}&lt;/math&gt;

Since &lt;math&gt;x_1&lt;/math&gt; is the only free variable, &lt;math&gt;n = 1.&lt;/math&gt; The quantified variable &lt;math&gt;x_3&lt;/math&gt; appears twice in &lt;math&gt;x_3 \in x_2&lt;/math&gt; at nesting depth 2. Its subscript is 3 because &lt;math&gt;n+q=1+2=3.&lt;/math&gt; If two quantifier scopes are at the same nesting depth, they are either identical or disjoint. The two occurrences of &lt;math&gt;x_3&lt;/math&gt; are in disjoint quantifier scopes, so they do not interact with each other.
|}

'''Proof of the class existence theorem.{{space|thin}}''' The proof starts by applying the transformation rules to the given formula to produce a transformed formula. Since this formula is equivalent to the given formula, the proof is completed by proving the class existence theorem for transformed formulas.

{| class="wikitable collapsible collapsed"
! style="background: #f5f5f5;" |'''Proof of the class existence theorem for transformed formulas'''
|- style="text-align: left; vertical-align: top; style="background: white" 
|The following lemma is used in the proof.

&lt;math&gt;\mathsf{Expansion\;lemma.}\,&lt;/math&gt; Let &lt;math&gt;1 \le i &lt; j \le n,&lt;/math&gt; and let &lt;math&gt;P&lt;/math&gt; be a class containing all the ordered pairs &lt;math&gt;(x_i, x_j)&lt;/math&gt; satisfying &lt;math&gt;R(x_i, x_j).&lt;/math&gt; That is, &lt;math&gt;P \supseteq \{(x_i, x_j): R(x_i, x_j)\}.&lt;/math&gt; Then &lt;math&gt;P&lt;/math&gt; can be expanded into the unique class &lt;math&gt;Q&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;R(x_i, x_j)&lt;/math&gt;. That is, &lt;math&gt;Q = \{(x_1, \ldots , x_n): R(x_i, x_j)\}.&lt;/math&gt; 

&lt;math&gt;\mathsf{Proof\!:}&lt;/math&gt;
{{plainlist|indent=0.8}}
1. If &lt;math&gt;i = 1,&lt;/math&gt; let &lt;math&gt;P_1 = P.&lt;/math&gt;&lt;br&gt;
Otherwise, &lt;math&gt;i &gt; 1,&lt;/math&gt; so components are added in front of &lt;math&gt;x_i\text{:}&lt;/math&gt; apply the [[#Tuple lemma|tuple lemma]]'s statement 1 to &lt;math&gt;P&lt;/math&gt; with &lt;math&gt;z = (x_1, \dots, x_{i-1}).&lt;/math&gt; This produces a class &lt;math&gt;P_1&lt;/math&gt; containing all the {{nowrap|&lt;math&gt;(i+1)&lt;/math&gt;-tuples}} &lt;math&gt;((x_1, \dots, x_{i-1}), x_i, x_j) = (x_1, \dots, x_{i-1}, x_i, x_j)&lt;/math&gt; satisfying &lt;math&gt;R(x_i, x_j).&lt;/math&gt;

2. If &lt;math&gt;j = i + 1,&lt;/math&gt; let &lt;math&gt;P_2 = P_1.&lt;/math&gt;&lt;br&gt; 
Otherwise, &lt;math&gt;j &gt; i + 1,&lt;/math&gt; so components are added between &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;x_j\text{:}&lt;/math&gt; add the components &lt;math&gt;x_{i+1}, \dots, x_{j-1}&lt;/math&gt; one by one using the tuple lemma's statement 2. This produces a class &lt;math&gt;P_2&lt;/math&gt; containing all the {{nowrap|&lt;math&gt;j&lt;/math&gt;-tuples}} &lt;math&gt;(((\cdots((x_1, \dots, x_i), x_{i+1}), \cdots), x_{j-1}), x_j) = (x_1, \dots, x_j)&lt;/math&gt; satisfying &lt;math&gt;R(x_i, x_j).&lt;/math&gt;

3. If &lt;math&gt;j = n,&lt;/math&gt; let &lt;math&gt;P_3 = P_2.&lt;/math&gt;&lt;br&gt;
Otherwise, &lt;math&gt;j &lt; n,&lt;/math&gt; so components are added after &lt;math&gt;x_j\text{:}&lt;/math&gt; add the components &lt;math&gt;x_{j+1}, \dots, x_n&lt;/math&gt; one by one using the tuple lemma's statement 3. This produces a class &lt;math&gt;P_3&lt;/math&gt; containing all the {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} &lt;math&gt;((\cdots((x_1, \dots, x_j), x_{j+1}), \cdots), x_n) = (x_1, \dots, x_n)&lt;/math&gt; satisfying &lt;math&gt;R(x_i, x_j).&lt;/math&gt;

4. Let &lt;math&gt;Q = P_3 \cap V^n.&lt;/math&gt; Extensionality implies that &lt;math&gt;Q&lt;/math&gt; is the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;R(x_i, x_j).&lt;/math&gt;&lt;br /&gt;&lt;br /&gt;
{{endplainlist}}

&lt;math&gt;\mathsf{Class\;existence\;theorem\;for\;transformed\;formulas.}\,&lt;/math&gt;
Let &lt;math&gt;\phi(x_1, \ldots, x_n, Y_1, \ldots, Y_m)&lt;/math&gt; be a formula that:
{{plainlist|indent=0.8}}
1. contains no free variables other than &lt;math&gt;x_1, \ldots, x_n, Y_1, \ldots, Y_m&lt;/math&gt;;&lt;br&gt;
2. contains only &lt;math&gt;\in&lt;/math&gt;, &lt;math&gt;\neg&lt;/math&gt;, &lt;math&gt;\land&lt;/math&gt;, &lt;math&gt;\exists&lt;/math&gt;, set variables, and the class variables &lt;math&gt;Y_k&lt;/math&gt; where &lt;math&gt;Y_k&lt;/math&gt; does not appear before an &lt;math&gt;\in&lt;/math&gt;{{space|hair}};&lt;br&gt; 
3. only quantifies set variables &lt;math&gt;x_{n+q}&lt;/math&gt; where &lt;math&gt;q&lt;/math&gt; is the quantifier nesting depth of the variable.  
{{endplainlist}}
Then for all &lt;math&gt;Y_1, \dots, Y_m&lt;/math&gt;, there exists a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that: 
:&lt;math&gt;\forall x_1 \cdots \,\forall x_n [(x_1, \ldots , x_n) \in A \iff \phi(x_1, \ldots, x_n, Y_1, \ldots, Y_m)].&lt;/math&gt;

&lt;math&gt;\mathsf{Proof\!:\, Basis\;step.}\,&lt;/math&gt; &lt;math&gt;\phi&lt;/math&gt; has 0 logical symbols. The theorem's hypothesis implies that &lt;math&gt;\phi&lt;/math&gt; is an atomic formula of the form &lt;math&gt;x_i \in x_j&lt;/math&gt; or &lt;math&gt;x_i \in Y_k.&lt;/math&gt;

{{plainlist|indent=0.8}}
&lt;math&gt;\mathsf{Case\, 1\!:}\,&lt;/math&gt; If &lt;math&gt;\phi&lt;/math&gt; is &lt;math&gt;x_i \in x_j&lt;/math&gt;, we build the class &lt;math&gt;E_{i,j,n} = \{(x_1, \ldots, x_{n}): x_i \in x_j\},&lt;/math&gt; the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;x_i \in x_j.&lt;/math&gt;

{{plainlist|indent=0.8}}
&lt;math&gt;\mathsf{Case\, a\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in x_j&lt;/math&gt; where &lt;math&gt;i &lt; j.&lt;/math&gt; The axiom of membership produces a class &lt;math&gt;P&lt;/math&gt; containing all the ordered pairs &lt;math&gt;(x_i, x_j)&lt;/math&gt; satisfying &lt;math&gt;x_i \in x_j.&lt;/math&gt; Apply the expansion lemma to &lt;math&gt;P&lt;/math&gt; to obtain &lt;math&gt;E_{i,j,n} = \{(x_1, \ldots, x_{n}): x_i \in x_j\}.&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, b\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in x_j&lt;/math&gt; where &lt;math&gt;i &gt; j.&lt;/math&gt; The axiom of membership produces a class &lt;math&gt;P&lt;/math&gt; containing all the ordered pairs &lt;math&gt;(x_i, x_j)&lt;/math&gt; satisfying &lt;math&gt;x_i \in x_j.&lt;/math&gt; Apply the tuple lemma's statement 4 to &lt;math&gt;P&lt;/math&gt; to obtain &lt;math&gt;P'&lt;/math&gt; containing all the ordered pairs &lt;math&gt;(x_j, x_i)&lt;/math&gt; satisfying &lt;math&gt;x_i \in x_j.&lt;/math&gt; Apply the expansion lemma to &lt;math&gt;P'&lt;/math&gt; to obtain &lt;math&gt;E_{i,j,n} = \{(x_1, \ldots, x_{n}): x_i \in x_j\}.&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, c\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in x_j&lt;/math&gt; where &lt;math&gt;i = j.&lt;/math&gt; Since this formula is false by the [[#Axiom of regularity|axiom of regularity]], no {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfy it, so &lt;math&gt;E_{i,j,n} = \empty.&lt;/math&gt;
{{endplainlist}}

&lt;math&gt;\mathsf{Case\, 2\!: }\,&lt;/math&gt; If &lt;math&gt;\phi&lt;/math&gt; is &lt;math&gt;x_i \in Y_k&lt;/math&gt;, we build the class &lt;math&gt;E_{i,Y_k,n} = \{(x_1, \ldots, x_{n}): x_i \in Y_k\},&lt;/math&gt; the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;x_i \in Y_k.&lt;/math&gt; 

{{plainlist|indent=0.8}}
&lt;math&gt;\mathsf{Case\, a\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in Y_k&lt;/math&gt; where &lt;math&gt;i &lt; n.&lt;/math&gt; Apply the axiom of product by &lt;math&gt;V&lt;/math&gt; to &lt;math&gt;Y_k&lt;/math&gt; to produce the class &lt;math&gt;P = Y_k \times V = \{(x_i, x_{i+1}): x_i \in Y_k\}.&lt;/math&gt; Apply the expansion lemma to &lt;math&gt;P&lt;/math&gt; to obtain &lt;math&gt;E_{i,Y_k,n} = \{(x_1, \ldots, x_{n}): x_i \in Y_k\}.&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, b\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in Y_k&lt;/math&gt; where &lt;math&gt;i = n &gt; 1.&lt;/math&gt; Apply the axiom of product by &lt;math&gt;V&lt;/math&gt; to &lt;math&gt;Y_k&lt;/math&gt; to produce the class &lt;math&gt;P = Y_k \times V = \{(x_i, x_{i-1}): x_i \in Y_k\}.&lt;/math&gt; Apply the tuple lemma's statement 4 to &lt;math&gt;P&lt;/math&gt; to obtain &lt;math&gt;P' = V \times Y_k = \{(x_{i-1}, x_i): x_i \in Y_k\}.&lt;/math&gt; Apply the expansion lemma to &lt;math&gt;P'&lt;/math&gt; to obtain &lt;math&gt;E_{i,Y_k,n} = \{(x_1, \ldots, x_{n}): x_i \in Y_k\}.&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, c\!: }\; \phi&lt;/math&gt; is &lt;math&gt;x_i \in Y_k&lt;/math&gt; where &lt;math&gt;i = n = 1.&lt;/math&gt; Then &lt;math&gt;E_{i,Y_k,n} = Y_k.&lt;/math&gt;
{{endplainlist}}
{{endplainlist}}

&lt;math&gt;\mathsf{Inductive\;step.}\; \phi&lt;/math&gt; has &lt;math&gt;k&lt;/math&gt; logical symbols where &lt;math&gt;k&gt;0&lt;/math&gt;. Assume the induction hypothesis that the theorem is true for all &lt;math&gt;\psi&lt;/math&gt; with less than &lt;math&gt;k&lt;/math&gt; logical symbols. We now prove the theorem for &lt;math&gt;\phi&lt;/math&gt; with &lt;math&gt;k&lt;/math&gt; logical symbols. In this proof, the list of class variables &lt;math&gt;Y_1, \dots, Y_m&lt;/math&gt; is abbreviated by &lt;math&gt;\vec{Y}&lt;/math&gt;, so a formula—such as &lt;math&gt;\phi(x_1, \dots, x_n, Y_1, \dots, Y_m)&lt;/math&gt;—can be written as &lt;math&gt;\phi(x_1, \dots, x_n, \vec{Y}).&lt;/math&gt;

{{plainlist|indent=0.8}}
&lt;math&gt;\mathsf{Case\, 1\!: }\; \phi(x_1, \ldots, x_n, \vec{Y}) = \neg \psi(x_1, \ldots, x_n, \vec{Y}).&lt;/math&gt; Since &lt;math&gt;\psi&lt;/math&gt; has &lt;math&gt;k-1&lt;/math&gt; logical symbols, the induction hypothesis implies that there is a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that:
:&lt;math&gt;\quad(x_1, \ldots , x_n) \in A \iff \psi(x_1, \ldots, x_n, \vec{Y}).&lt;/math&gt; 
By the complement axiom, there is a class &lt;math&gt;\complement A&lt;/math&gt; such that &lt;math&gt;\forall u\,[u\in \complement A \iff \neg(u \in A)].&lt;/math&gt; However, &lt;math&gt;\complement A&lt;/math&gt; contains elements other than {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} if &lt;math&gt;n &gt; 1.&lt;/math&gt; To eliminate these elements, use &lt;math&gt;\complement_{V^n} A =\, &lt;/math&gt;&lt;math&gt;\complement A \cap V^n =\,&lt;/math&gt;&lt;math&gt;V^n \setminus A,&lt;/math&gt; which is the complement relative to the class &lt;math&gt;V^n&lt;/math&gt; of all {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples.}}{{efn|name=Bourbaki}} Then, by extensionality, &lt;math&gt;\complement_{V^n} A&lt;/math&gt; is the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that:
:&lt;math&gt;\begin{alignat}{2}
\quad&amp;(x_1, \ldots, x_n) \in \complement_{V^n} A &amp;&amp;\iff \neg [(x_1, \ldots , x_n) \in A] \\
&amp; &amp;&amp;\iff \neg \psi(x_1, \ldots, x_n, \vec{Y}) \\
&amp; &amp;&amp;\iff \phi(x_1, \ldots, x_n, \vec{Y}). 
\end{alignat}&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, 2\!: }\; \phi(x_1, \ldots, x_n, \vec{Y}) = \psi_1(x_1, \ldots, x_n, \vec{Y}) \land \psi_2(x_1, \ldots, x_n, \vec{Y}).&lt;/math&gt; Since both &lt;math&gt;\psi_1&lt;/math&gt; and &lt;math&gt;\psi_2&lt;/math&gt; have less than &lt;math&gt;k&lt;/math&gt; logical symbols, the induction hypothesis implies that there are unique classes of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples,}} &lt;math&gt;A_1&lt;/math&gt; and &lt;math&gt;A_2&lt;/math&gt;, such that:
:&lt;math&gt;\begin{align}
\quad&amp;(x_1, \ldots , x_n) \in A_1 \iff \psi_1(x_1, \ldots, x_n, \vec{Y}). \\
&amp;(x_1, \ldots , x_n) \in A_2 \iff \psi_2(x_1, \ldots, x_n, \vec{Y}).
\end{align}&lt;/math&gt;
By the axioms of intersection and extensionality, &lt;math&gt;A_1 \cap A_2&lt;/math&gt; is the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that:
:&lt;math&gt;\begin{alignat}{2}
\quad&amp;(x_1, \ldots, x_n) \in A_1 \cap A_2 &amp;&amp;\iff (x_1, \ldots, x_n) \in A_1 \land (x_1, \ldots, x_n) \in A_2 \\
&amp; &amp;&amp;\iff \psi_1(x_1, \ldots, x_n, \vec{Y}) \land \psi_2(x_1, \ldots, x_n, \vec{Y}) \\
&amp; &amp;&amp;\iff  \phi(x_1, \ldots, x_n, \vec{Y}).
\end{alignat}&lt;/math&gt;

&lt;math&gt;\mathsf{Case\, 3\!: }\; \phi(x_1, \ldots, x_n, \vec{Y}) = \exists x_{n+1} \psi(x_1, \ldots, x_n, x_{n+1}, \vec{Y}).&lt;/math&gt; The quantifier nesting depth of &lt;math&gt;\psi&lt;/math&gt; is one more than that of &lt;math&gt;\phi&lt;/math&gt; and the additional free variable is &lt;math&gt;x_{n+1}.&lt;/math&gt; Since &lt;math&gt;\psi&lt;/math&gt; has &lt;math&gt;k-1&lt;/math&gt; logical symbols, the induction hypothesis implies that there is a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;(n+1)&lt;/math&gt;-tuples}} such that:
:&lt;math&gt;\quad(x_1, \ldots, x_n, x_{n+1}) \in A \iff \psi(x_1, \ldots, x_n, x_{n+1}, \vec{Y}).&lt;/math&gt; &lt;br /&gt;
By the axioms of domain and extensionality, &lt;math&gt;Dom(A)&lt;/math&gt; is the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that:{{efn|One detail has been left out of this proof. Gödel's convention is being used, so &lt;math&gt;\exist x\, \phi(x)&lt;/math&gt; is defined to be &lt;math&gt;\exist x[\exist C (x \in C) \land \phi(x)].&lt;/math&gt; Since this formula quantifies over classes, it must be replaced with the equivalent &lt;math&gt;\exist x[x \in V \land \phi(x)].&lt;/math&gt; Then the three formulas in the proof having the form &lt;math&gt;\exist x_{n+1}[x_{n+1} \land \dots]&lt;/math&gt; become &lt;math&gt;\exist x_{n+1}[x_{n+1} \in V \land \dots],&lt;/math&gt; which produces a valid proof.}}
:&lt;math&gt;\begin{alignat}{2}
\quad&amp;(x_1, \ldots, x_n) \in Dom(A) &amp;&amp;\iff \exists x_{n+1}[((x_1, \ldots, x_n), x_{n+1}) \in A] \\
&amp; &amp;&amp;\iff \exists x_{n+1}[(x_1, \ldots, x_n, x_{n+1}) \in A] \\
&amp; &amp;&amp;\iff \exists x_{n+1}\,\psi(x_1, \ldots, x_n, x_{n+1}, \vec{Y}) \\
&amp; &amp;&amp;\iff \phi(x_1, \ldots, x_n, \vec{Y}). 
\end{alignat}&lt;/math&gt;
{{endplainlist}}
|}

Gödel pointed out that the class existence theorem "is a [[metatheorem]], that is, a theorem about the system [NBG], not in the system …"&lt;ref&gt;{{harvnb|Gödel|1940|p=11}}.&lt;/ref&gt; It is a theorem about NBG because it is proved in the [[metatheory]] by induction on NBG formulas. Also, its proof—instead of invoking finitely many NBG axioms—inductively describes how to use NBG axioms to construct a class satisfying a given formula. For every formula, this description can be turned into a constructive existence proof that is in NBG. Therefore, this metatheorem can generate infinitely many NBG proofs.

A [[Recursion (computer science)|recursive]] [[computer program]] succinctly captures the construction of a class from a given formula. The definition of this program does not depend on the proof of the class existence theorem. However, this proof is needed to prove that the class constructed by the program satisfies the given formula and is built using the axioms. This program is written in [[pseudocode]] that uses a [[Pascal (programming language)|Pascal]]-style [[case statement]].{{efn|Recursive computer programs written in pseudocode have been used elsewhere in [[pure mathematics]]. For example, they have been used to prove the [[Heine-Borel theorem]] and other theorems of [[Analysis (math)|analysis]] {{harv|Gray|1991}}.}}

&lt;math&gt;\mathbf{function} \;\text{Class}(\phi, \,n)&lt;/math&gt;&lt;br&gt;
&lt;math&gt;\begin{align}
\mathbf{input}\!: \;\,&amp;\phi \text{ is a transformed formula of the form } \phi(x_1, \ldots, x_n, Y_1, \ldots, Y_m); \\
&amp;n \text{ specifies that a class of } n\text{-tuples is returned.} \\
\;\;\;\;\mathbf{output}\!: \;\,&amp;\text{class } A \text{ of } n\text{-tuples satisfying } \\
&amp;\,\forall x_1 \cdots \,\forall x_n [(x_1, \ldots , x_n) \in A \iff \phi(x_1, \ldots, x_n, Y_1, \ldots, Y_m)].
\end{align}&lt;/math&gt;&lt;br&gt;

&lt;math&gt;\mathbf{begin}&lt;/math&gt;&lt;br&gt;
:&lt;math&gt;\mathbf{case} \;\phi \;\mathbf{of}&lt;/math&gt; 
:&lt;math&gt;\begin{alignat}{2}
x_i \in x_j: \;\;&amp;\mathbf{return} \;\,E_{i,j,n}; &amp;&amp;\text{// } E_{i,j,n} \;\,= \{(x_1, \dots, x_n): x_i \in x_j\} \\
x_i \in Y_k: \;\;&amp;\mathbf{return} \;\,E_{i,Y_k,n}; &amp;&amp;\text{// } E_{i,Y_k,n} = \{(x_1, \dots, x_{n}): x_i \in Y_k\} \\
\neg\psi: \;\;&amp;\mathbf{return} \;\,\complement_{V^n}\text{Class}(\psi, \,n);  &amp;&amp;\text{// } \complement_{V^n}\text{Class}(\psi, \,n) = V^n \setminus \text{Class}(\psi, \,n) \\
\psi_1 \land \psi_2: \;\;&amp;\mathbf{return} \;\,\text{Class}(\psi_1, \,n) \cap \text{Class}(\psi_2, \,n);&amp;&amp; \\
\;\;\;\;\,\exists x_{n+1}(\psi): \;\;&amp;\mathbf{return} \;\,Dom(\text{Class}(\psi, \,n+1));  &amp;&amp;\text{// } x_{n+1} \text{ is free in } \psi; \text{ Class}(\psi, \,n+1) \\
&amp;\ &amp;&amp;\text{// returns a class of } (n+1)\text{-tuples}
\end{alignat}&lt;/math&gt;
:&lt;math&gt;\mathbf{end}&lt;/math&gt;
&lt;math&gt;\mathbf{end}&lt;/math&gt;

{{Anchor|Mirror}}Let &lt;math&gt;\phi&lt;/math&gt; be the formula of [[#Ex2|example 2]]. The function call &lt;math&gt;A = Class(\phi, 1)&lt;/math&gt; generates the class &lt;math&gt;A,&lt;/math&gt; which is compared below with &lt;math&gt;\phi.&lt;/math&gt; This shows that the construction of the class &lt;math&gt;A&lt;/math&gt; mirrors the construction of its defining formula &lt;math&gt;\phi.&lt;/math&gt;

:&lt;math&gt;\begin{alignat}{2}
&amp;\phi \;&amp;&amp;=
\;\;\exists x_2\,(x_2 \!\in\! x_1 \land \;\;\neg\;\;\;\;\exists x_3\;(x_3 \!\in\! x_2)) \,\land \;\;\,\exists x_2\,(x_2 \!\in\! x_1 \land 
\;\;\,\exists x_3\,(x_3 \!\in\! x_2 \,\land\;\;\neg\;\;\;\;\exists x_4\;(x_4 \!\in\! x_3))) \\
&amp;A \;&amp;&amp;=
Dom\,(\;E_{2,1,2}\; \cap \;\complement_{V^2}\,Dom\,(\;E_{3,2,3}\;)) \,\cap\, Dom\,(\;E_{2,1,2}\;\cap \,
Dom\,(\;\,E_{3,2,3}\; \cap \;\complement_{V^3}\,Dom\,(\;E_{4,3,4}\;)))
\end{alignat}&lt;/math&gt;

=== Extending the class existence theorem ===
Gödel extended the class existence theorem to formulas &lt;math&gt;\phi&lt;/math&gt; containing [[Finitary relation|relation]]s over classes (such as &lt;math&gt;Y_1 \subseteq Y_2&lt;/math&gt; and the [[unary relation]] &lt;math&gt;M(Y_1)&lt;/math&gt;), special classes (such as &lt;math&gt;Ord&lt;/math&gt;{{space|hair|2}}), and [[operation (mathematics)|operation]]s (such as &lt;math&gt;(x_1, x_2)&lt;/math&gt; and &lt;math&gt;x_1 \cap Y_1&lt;/math&gt;).&lt;ref&gt;{{harvnb|Gödel|1940|pp=11&amp;ndash;13}}.&lt;/ref&gt; To extend the class existence theorem, the formulas defining relations, special classes, and operations must quantify only over sets. Then &lt;math&gt;\phi&lt;/math&gt; can be transformed into an equivalent formula satisfying the [[#CET|hypothesis of the class existence theorem]].

The following definitions specify how formulas define relations, special classes, and operations:
# A relation &lt;math&gt;R&lt;/math&gt; is defined by: &lt;math&gt;R(Z_1, \dots, Z_k) \iff \psi_R(Z_1, \dots, Z_k).&lt;/math&gt;
# A special class &lt;math&gt;C&lt;/math&gt; is defined by: &lt;math&gt;u \in  C \iff \psi_C(u).&lt;/math&gt;
# An operation &lt;math&gt;P&lt;/math&gt; is defined by: &lt;math&gt;u \in P(Z_1, \dots, Z_k) \iff \psi_P(u, Z_1, \dots, Z_k).&lt;/math&gt;

A {{em|[[Term (logic)|term]]}} is defined by:
# Variables and special classes are terms.
# If &lt;math&gt;P&lt;/math&gt; is an operation with &lt;math&gt;k&lt;/math&gt; arguments and &lt;math&gt;\Gamma_1, \dots, \Gamma_k&lt;/math&gt; are terms, then &lt;math&gt;P(\Gamma_1, \dots, \Gamma_k)&lt;/math&gt; is a term. 

The following transformation rules eliminate relations, special classes, and operations. Each time rule 2b, 3b, or 4 is applied to a subformula, &lt;math&gt;i&lt;/math&gt; is chosen so that &lt;math&gt;z_i&lt;/math&gt; differs from the other variables in the current formula. The rules are repeated until there are no subformulas to which they can be applied. &lt;math&gt;\, \Gamma_1, \dots, \Gamma_k, \Gamma,&lt;/math&gt; and &lt;math&gt;\Delta&lt;/math&gt; denote terms.

{{ordered list
  |A relation &lt;math&gt;R(Z_1, \dots, Z_k)&lt;/math&gt; is replaced by its defining formula &lt;math&gt;\psi_R(Z_1, \dots, Z_k).&lt;/math&gt;
  |Let &lt;math&gt;\psi_C(u)&lt;/math&gt; be the defining formula for the special class &lt;math&gt;C.&lt;/math&gt; 
     {{ordered list|type=lower-alpha 
     |&lt;math&gt;\Delta \in C&lt;/math&gt; is replaced by &lt;math&gt;\psi_C(\Delta).&lt;/math&gt;
     |&lt;math&gt;C \in \Delta&lt;/math&gt; is replaced by &lt;math&gt;\exists z_i[z_i = C \land z_i \in \Delta].&lt;/math&gt;}}
  |Let &lt;math&gt;\psi_P(u, Z_1, \dots, Z_k)&lt;/math&gt; be the defining formula for the operation &lt;math&gt;P(Z_1, \dots, Z_k).&lt;/math&gt; 
     {{ordered list|type=lower-alpha 
     |&lt;math&gt;\Delta \in P(\Gamma_1, \dots, \Gamma_k)&lt;/math&gt; is replaced by &lt;math&gt;\psi_P(\Delta, \Gamma_1, \dots, \Gamma_k).&lt;/math&gt;
     |&lt;math&gt;P(\Gamma_1, \dots, \Gamma_k) \in \Delta&lt;/math&gt; is replaced by &lt;math&gt;\exists z_i[z_i = P(\Gamma_1, \dots, \Gamma_k) \land z_i \in \Delta].&lt;/math&gt;}} 
  |Extensionality is used to transform &lt;math&gt;\Delta = \Gamma&lt;/math&gt; into &lt;math&gt;\forall z_i(z_i \in \Delta \iff z_i \in \Gamma).&lt;/math&gt;
}}

:{| class="wikitable"
|- style="text-align: left; vertical-align: top; style="background: white" 
|'''Example 3:{{space|thin}}''' Transforming &lt;math&gt;Y_1 \subseteq Y_2.&lt;/math&gt;
&lt;math&gt;Y_1 \subseteq Y_2 \iff \forall z_1(z_1 \in Y_1 \implies z_1 \in Y_2) \quad\text{(rule 1)}&lt;/math&gt;
|}

:{| class="wikitable"
|- style="text-align: left; vertical-align: top; style="background: white" 
|'''Example 4:{{space|thin}}''' Transforming &lt;math&gt;x_1 \cap Y_1 \in x_2.&lt;/math&gt;
&lt;math&gt;\begin{alignat}{2}
x_1 \cap Y_1 \in x_2 &amp;\iff \exists z_1[z_1 = x_1 \cap Y_1 \,\land\, z_1 \in x_2] &amp;&amp;\text{(rule 3b)} \\
&amp;\iff \exists z_1[\forall z_2(z_2 \in z_1 \iff z_2 \in x_1 \cap Y_1) \,\land\, z_1 \in x_2] &amp;&amp;\text{(rule 4)} \\
&amp;\iff \exists z_1[\forall z_2(z_2 \in z_1 \iff z_2 \in x_1 \land z_2 \in Y_1) \,\land\, z_1 \in x_2] \quad&amp;&amp;\text{(rule 3a)} \\
\end{alignat}&lt;/math&gt;

This example illustrates how the transformation rules work together to eliminate an operation.
|}

'''Class existence theorem (extended version).{{space|thin}}''' Let &lt;math&gt;\phi(x_1, \dots, x_n, Y_1, \dots, Y_m)&lt;/math&gt; be a formula that quantifies only over sets, contains no free variables other than &lt;math&gt;x_1, \dots, x_n,  Y_1, \dots, Y_m&lt;/math&gt;, and may contain relations, special classes, and operations defined by formulas that quantify only over sets. Then for all &lt;math&gt;Y_1, \dots, Y_m,&lt;/math&gt; there exists a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} such that &lt;math&gt;\forall x_1 \cdots \,\forall x_n [(x_1, \dots , x_n) \in A \iff \phi(x_1, \dots, x_n, Y_1, \dots, Y_m)].&lt;/math&gt;{{efn|This theorem is Gödel's theorem M4. He proved it by first proving M1, a class existence theorem that uses symbols for special classes rather than free class variables. M1 produces a class containing all the {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;\phi&lt;/math&gt;, but which may contain elements that are not {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}}. Theorem M2 extends this theorem to formulas containing relations, special classes, and operations. Theorem M3 is obtained from M2 by replacing the symbols for special classes with free variables. Gödel used M3 to define &lt;math&gt;A \times B = \{x: \exists y \exists z[x = (y, z) \land y \in A \land z \in B]\},&lt;/math&gt; which is unique by extensionality. He used &lt;math&gt;A \times B&lt;/math&gt; to define &lt;math&gt;V^n.&lt;/math&gt; Theorem M4 is obtained from M3 by intersecting the class produced by M3 with &lt;math&gt;V^n&lt;/math&gt; to produce the unique class of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying the given formula. Gödel's approach, especially his use of M3 to define &lt;math&gt;A \times B&lt;/math&gt;, eliminates the need for Bernays' stronger form of the product by &lt;math&gt;V&lt;/math&gt; axiom. {{harv|Gödel|1940|pp=8&amp;ndash;15.}}}}

'''Proof:{{space|thin}}''' Apply the transformation rules to &lt;math&gt;\phi&lt;/math&gt; to produce an equivalent formula containing no relations, special classes, or operations. This formula satisfies the hypothesis of the class existence theorem. Therefore, for all &lt;math&gt;Y_1, \dots, Y_m,&lt;/math&gt; there is a unique class &lt;math&gt;A&lt;/math&gt; of {{nowrap|&lt;math&gt;n&lt;/math&gt;-tuples}} satisfying &lt;math&gt;\forall x_1 \cdots \,\forall x_n [(x_1, \dots, x_n) \in A \iff \phi(x_1, \dots, x_n, Y_1, \dots, Y_m)].&lt;/math&gt;

=== Set axioms ===
The axioms of pairing and regularity, which were needed for the proof of the class existence theorem, have been given above. NBG contains four other set axioms. Three of these axioms deal with class operations being applied to sets.

'''Definition.{{space|thin}}''' &lt;math&gt;F&lt;/math&gt; is a [[Function (set theory)|function]] if &lt;math&gt;F \subseteq V^2 \land \forall x\, \forall y\, \forall z\, [(x,y) \in F \,\land\, (x,z) \in F \implies y = z].&lt;/math&gt;

In set theory, the definition of a function does not require specifying the domain or codomain of the function (see [[Function (set theory)]]). NBG's definition of function generalizes ZFC's definition from a set of ordered pairs to a class of ordered pairs. 

ZFC's definitions of the set operations: [[Image (set theory)|image]], [[Union (set theory)|union]], and [[power set]] are also generalized to class operations. The image of class &lt;math&gt;A&lt;/math&gt; under the function &lt;math&gt;F&lt;/math&gt; is &lt;math&gt;F[A] = \{y: \exists x(x \in A \,\land\, (x, y) \in F)\}.&lt;/math&gt; This definition does not require that &lt;math&gt;A \subseteq Dom(F).&lt;/math&gt; The union of class &lt;math&gt;A&lt;/math&gt; is &lt;math&gt;\cup A = \{x: \exists y(x \in y\, \,\land\, y \in A)\}.&lt;/math&gt; The power class of &lt;math&gt;A&lt;/math&gt; is &lt;math&gt;\mathcal{P}(A) = \{x: x \subseteq A\}.&lt;/math&gt; The extended version of the class existence theorem implies the existence of these classes. The axioms of replacement, [[Axiom of union|union]], and [[Axiom of power set|power set]] imply that when these operations are applied to sets, they produce sets.&lt;ref&gt;{{harvnb|Gödel|1940|pp=16&amp;ndash;18}}.&lt;/ref&gt;

{{Anchor|NBG's axiom of replacement}}'''Axiom of replacement.{{space|thin}}''' If &lt;math&gt;F&lt;/math&gt; is a function and &lt;math&gt;a&lt;/math&gt; is a set, then &lt;math&gt;F[a]&lt;/math&gt;, the [[Image (set theory)|image]] of &lt;math&gt;a&lt;/math&gt; under &lt;math&gt;F&lt;/math&gt;, is a set.
:&lt;math&gt;\forall F \,\forall a \,[F \text{ is a function}\implies \exists b \,\forall y\,(y \in b \iff \exists x(x \in a \,\land\, (x, y) \in F))].&lt;/math&gt;

Not having the requirement &lt;math&gt;A \subseteq Dom(F)&lt;/math&gt; in the definition of &lt;math&gt;F[A]&lt;/math&gt; produces a stronger axiom of replacement, which is used in the following proof.
 
{{Anchor|NBG's axiom of separation}}'''Theorem (NBG's [[axiom of separation]]).{{space|thin}}''' If &lt;math&gt;A&lt;/math&gt; is a set and &lt;math&gt;B&lt;/math&gt; is a subclass of &lt;math&gt;A,&lt;/math&gt; then &lt;math&gt;B&lt;/math&gt; is a set. &lt;br&gt;
'''Proof:{{space|thin}}''' The class existence theorem constructs the [[Restriction (mathematics)|restriction]] of the [[identity function]] to &lt;math&gt;B&lt;/math&gt;: &lt;math&gt;I{\restriction_B} = \{(x_1, x_2): x_1 \in B \land x_2 = x_1\}.&lt;/math&gt; Since the image of &lt;math&gt;A&lt;/math&gt; under &lt;math&gt;I{\restriction_B}&lt;/math&gt; is &lt;math&gt;B&lt;/math&gt;, the axiom of replacement implies that &lt;math&gt;B&lt;/math&gt; is a set. This proof depends on the definition of image not having the requirement &lt;math&gt;A \subseteq Dom(F)&lt;/math&gt; since &lt;math&gt;Dom(I{\restriction_B}) = B \subseteq A&lt;/math&gt; rather than &lt;math&gt;A \subseteq Dom(I{\restriction_B}).&lt;/math&gt;

'''Axiom of union.{{space|thin}}''' If &lt;math&gt;a&lt;/math&gt; is a set, then there is a set containing &lt;math&gt;\cup a.&lt;/math&gt;
:&lt;math&gt;\forall a\, \exists b\, \forall x\,[\,\exists y(x \in y\, \,\land\, y \in a) \implies x \in b\,].&lt;/math&gt;

'''Axiom of power set.{{space|thin}}''' If &lt;math&gt;a&lt;/math&gt; is a set, then there is a set containing &lt;math&gt;\mathcal{P}(a).&lt;/math&gt;
:&lt;math&gt;\forall a\, \exists b\, \forall x\, (x \subseteq a \implies x \in b).&lt;/math&gt;{{efn|Gödel weakened Bernays' axioms of union and power set, which state the existence of these sets, to the above axioms that state there is a set containing the union and a set containing the power set ({{harvnb|Bernays|1941|p=2}}; {{harvnb|Gödel|1940|p=5}}). Bernays published his axioms after Gödel, but had sent them to Gödel in 1931 ({{harvnb|Kanamori|2009|p=48}}; {{harvnb|Gödel|2003|p=104&amp;ndash;115}}).}}

'''Theorem.{{space|thin}}''' If &lt;math&gt;a&lt;/math&gt; is a set, then &lt;math&gt;\cup a&lt;/math&gt; and &lt;math&gt;\mathcal{P}(a)&lt;/math&gt; are sets.&lt;br&gt;
'''Proof:{{space|thin}}''' The axiom of union states that &lt;math&gt;\cup a&lt;/math&gt; is a subclass of a set &lt;math&gt;b&lt;/math&gt;, so the axiom of separation implies &lt;math&gt;\cup a&lt;/math&gt; is a set. Likewise, the axiom of power set states that &lt;math&gt;\mathcal{P}(a)&lt;/math&gt; is a subclass of a set &lt;math&gt;b&lt;/math&gt;, so the axiom of separation implies that  &lt;math&gt;\mathcal{P}(a)&lt;/math&gt; is a set.

'''Axiom of infinity.{{space|thin}}''' There exists a nonempty set &lt;math&gt;a&lt;/math&gt; such that for all &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;a&lt;/math&gt;, there exists a &lt;math&gt;y&lt;/math&gt; in &lt;math&gt;a&lt;/math&gt; such that &lt;math&gt;x&lt;/math&gt; is a proper subset of &lt;math&gt;y&lt;/math&gt;.
:&lt;math&gt;\exists a\, [\exists u(u \in a) \,\land\, \forall x(x \in a \implies \exists y(y \in a \,\land\, x \subset y))].&lt;/math&gt;

The axioms of infinity and replacement prove the existence of the [[empty set]]. In the [[#Empty class|discussion of the class existence axioms]], the existence of the empty class &lt;math&gt;\empty&lt;/math&gt; was proved. We now prove that &lt;math&gt;\empty&lt;/math&gt; is a set. Let function &lt;math&gt;F = \empty&lt;/math&gt; and let &lt;math&gt;a&lt;/math&gt; be the set given by the axiom of infinity. By replacement, the image of &lt;math&gt;a&lt;/math&gt; under &lt;math&gt;F&lt;/math&gt;, which equals &lt;math&gt;\empty&lt;/math&gt;, is a set.

NBG's axiom of infinity is implied by ZFC's [[axiom of infinity]]: &lt;math&gt;\,\exists a\, [\empty \in a \,\land\, \forall x(x \in a \implies x \cup \{x\} \in a)].\,&lt;/math&gt; The first [[Conjunct (logic)|conjunct]] of ZFC's axiom, &lt;math&gt;\empty \in a&lt;/math&gt;, implies the first conjunct of NBG's axiom. The second conjunct of ZFC's axiom, &lt;math&gt;\forall x(x \in a \implies x \cup \{x\} \in a)&lt;/math&gt;, implies the second conjunct of NBG's axiom since &lt;math&gt;x \subset x \cup \{x\}.&lt;/math&gt; To prove ZFC's axiom of infinity from NBG's axiom of infinity requires some of the other NBG axioms (see [[Weak axiom of infinity]]).{{efn|Since ZFC's axiom requires the existence of the empty set, an advantage of NBG's axiom is that the axiom of the empty set is not needed. Mendelson's axiom system uses the ZFC's axiom of infinity and also has the axiom of the empty set {{harv|Mendelson|1997|pp=228, 239}}.}}

=== Axiom of global choice ===
The class concept allows NBG to have a stronger axiom of choice than ZFC. A [[choice function]] is a function &lt;math&gt;f&lt;/math&gt;, defined on a set &lt;math&gt;s&lt;/math&gt; of nonempty sets, such that &lt;math&gt;f(x) \in x&lt;/math&gt; for all &lt;math&gt;x \in s.&lt;/math&gt; ZFC's axiom of choice states that for every set of nonempty sets, there exists a choice function. A global choice function is a function &lt;math&gt;G&lt;/math&gt; defined on the class of all nonempty sets such that &lt;math&gt;G(x) \in x&lt;/math&gt; for every nonempty set &lt;math&gt;x.&lt;/math&gt; The axiom of global choice states that there exists a global choice function. This axiom implies ZFC's axiom of choice since for every set &lt;math&gt;s&lt;/math&gt; of nonempty sets, &lt;math&gt;G\vert_s&lt;/math&gt; (the [[Restriction (mathematics)|restriction]] of &lt;math&gt;G&lt;/math&gt; to &lt;math&gt;s&lt;/math&gt;) is a choice function for &lt;math&gt;s.&lt;/math&gt; In 1964, [[William Bigelow Easton|William B. Easton]] proved that global choice is stronger than the axiom of choice by using [[Forcing (mathematics)|forcing]] to construct a [[Model (mathematical logic)|model]] that satisfies the axiom of choice and all the axioms of NBG except the axiom of global choice.&lt;ref&gt;{{harvnb|Easton|1964|pp=56a&amp;ndash;64}}.&lt;/ref&gt; The axiom of global choice is equivalent to every class having a well-ordering, while ZFC's axiom of choice is equivalent to every set having a well-ordering.{{efn|For &lt;math&gt;V&lt;/math&gt; having a well-ordering implying global choice, see [[Implications of the axiom of limitation of size]]. For global choice implying the well-ordering of any class, see {{harvnb|Kanamori|2009|p=53}}.}}

'''Axiom of global choice.{{space|thin}}''' There exists a function that chooses an element from every nonempty set.
:&lt;math&gt;\exists G\,[G \text{ is a function}\, \land \forall x(x \ne \empty \implies \exists y(y \in x \land (x,y) \in G))].&lt;/math&gt;

==History==
[[File:NBG Evolution svg.svg|thumb|400px|History of approaches that led to NBG set theory]]
=== Von Neumann's 1925 axiom system ===
Von Neumann published an introductory article on his axiom system in 1925. In 1928, he provided a detailed treatment of his system.&lt;ref&gt;{{harvnb|von Neumann|1925}}, {{harvnb|von Neumann|1928}}.&lt;/ref&gt; Von Neumann based his axiom system on two domains of [[Primitive notion|primitive]] objects: functions and arguments. These domains overlap—objects that are in both domains are called argument-functions. Functions correspond to classes in NBG, and argument-functions correspond to sets. Von Neumann's primitive operation is [[function application]], denoted by [''a'',&amp;nbsp;''x''] rather than ''a''(''x'') where ''a'' is a function and ''x'' is an argument. This operation produces an argument. Von Neumann defined classes and sets using functions and argument-functions that take only two values, ''A'' and ''B''. He defined ''x''&amp;nbsp;∈&amp;nbsp;''a'' if [''a'',&amp;nbsp;''x'']&amp;nbsp;≠&amp;nbsp;''A''.&lt;ref name=VN1925def /&gt;

Von Neumann's work in set theory was influenced by [[Georg Cantor]]'s articles, [[Zermelo set theory|Ernst Zermelo's 1908 axioms for set theory]], and the 1922 critiques of [[Ernst Zermelo|Zermelo]]'s set theory that were given independently by [[Abraham Fraenkel]] and [[Thoralf Skolem]]. Both Fraenkel and Skolem pointed out that Zermelo's axioms cannot prove the existence of the set {''Z''&lt;sub&gt;0&lt;/sub&gt;,&amp;nbsp;''Z''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''Z''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...} where ''Z''&lt;sub&gt;0&lt;/sub&gt; is the set of [[natural number]]s and ''Z''&lt;sub&gt;''n''+1&lt;/sub&gt; is the [[power set]] of ''Z''&lt;sub&gt;''n''&lt;/sub&gt;. They then introduced the axiom of replacement, which would guarantee the existence of such sets.&lt;ref&gt;{{harvnb|Ferreirós|2007|p=369}}. In 1917, [[Dmitry Mirimanoff]] published a form of replacement based on cardinal equivalence {{harv|Mirimanoff|1917|p=49}}.&lt;/ref&gt; However, they were reluctant to adopt this axiom: Fraenkel stated "that Replacement was too strong an axiom for 'general set theory'", while "Skolem only wrote that 'we could introduce' Replacement".&lt;ref&gt;{{harvnb|Kanamori|2012|p=62}}.&lt;/ref&gt;

Von Neumann worked on the problems of [[Zermelo set theory]] and provided solutions for some of them:
* '''A theory of ordinals''' 
** Problem: Cantor's theory of [[ordinal number]]s cannot be developed in Zermelo set theory because it lacks the axiom of replacement.{{efn|name=ordinaltheorem|In 1928, von Neumann stated: "A treatment of ordinal number closely related to mine was known to Zermelo in 1916, as I learned subsequently from a personal communication. Nevertheless, the fundamental theorem, according to which to each well-ordered set there is a similar ordinal, could not be rigorously proved because the replacement axiom was unknown." {{harv|Hallett|1984|p=280.}}}} 
** Solution: Von Neumann recovered Cantor's theory by defining the ordinals using sets that are [[well-ordered]] by the ∈-relation,{{efn|{{harvnb|von Neumann|1923}}. Von Neumann's definition also used the theory of well-ordered sets. Later, his definition was simplified to the current one: An ordinal is a [[transitive set]] that is well-ordered by ∈ {{harv|Kunen|1980|p=16}}.}} and by using the axiom of replacement to prove key theorems about the ordinals, such as every well-ordered set is [[order-isomorphic]] with an ordinal.{{efn|name=ordinaltheorem}} In contrast to Fraenkel and Skolem, von Neumann emphasized how important the replacement axiom is for set theory: "In fact, I believe that no theory of ordinals is possible at all without this axiom."&lt;ref&gt;{{harvnb|von Neumann|1925|p=223}} (footnote); English translation: {{Harvnb|van&amp;nbsp;Heijenoort|2002b|p=398 (footnote)}}.&lt;/ref&gt;
* '''A criterion identifying classes that are too large to be sets''' 
** Problem: Zermelo did not provide such a criterion. His set theory avoids the large classes that lead to the [[Georg Cantor#Absolute infinite, well-ordering theorem, and paradoxes|paradoxes]], but it leaves out many sets, such as the one mentioned by Fraenkel and Skolem.{{efn|After introducing the [[cumulative hierarchy]], von Neumann could show that Zermelo's axioms do not prove the existence of ordinals α&amp;nbsp;≥&amp;nbsp;ω&amp;nbsp;+&amp;nbsp;ω, which include uncountably many [[hereditarily countable set]]s. This follows from Skolem's result that V&lt;sub&gt;ω+ω&lt;/sub&gt; satisfies Zermelo's axioms {{harv|Kanamori|2012|p=61}} and from α&amp;nbsp;∈&amp;nbsp;V&lt;sub&gt;β&lt;/sub&gt; implying α&amp;nbsp;&lt;&amp;nbsp;β {{harv|Kunen|1980|pp=95&amp;ndash;96}}. Kunen uses the notation R(β) instead of ''V''&lt;sub&gt;β&lt;/sub&gt;.}} 
** Solution: Von Neumann introduced the criterion: A class is too large to be a set if and only if it can be mapped [[onto]] the class ''V'' of all sets. Von Neumann realized that the set-theoretic paradoxes could be avoided by not allowing such large classes to be members of any class. Combining this restriction with his criterion, he obtained his [[axiom of limitation of size]]: A class ''C'' is not a member of any class if and only if ''C'' can be mapped onto ''V''.&lt;ref&gt;{{harvnb|Hallett|1984|pp=288&amp;ndash;290}}. Von Neumann stated his axiom in an equivalent functional form ({{harvnb|von Neumann|1925|p=225}}; English translation: {{Harvnb|van&amp;nbsp;Heijenoort|2002b|p=400}}).&lt;/ref&gt;
* '''Finite axiomatization''' 
** Problem: Zermelo had used the imprecise concept of "definite [[propositional function]]" in [[Zermelo set theory#The axioms of Zermelo set theory|his axiom of separation]].
** Solutions: Skolem introduced the [[axiom schema of separation]] that was later used in ZFC, and Fraenkel introduced an equivalent solution. However, Zermelo rejected both approaches "particularly because they implicitly involve the concept of natural number which, in Zermelo's view, should be based upon set theory."{{efn|Fraenkel, ''Historical Introduction'' in {{harvnb|Bernays|1991|p=13}}. Skolem's approach implicitly involves natural numbers because the formulas of an axiom schema are built using [[structural recursion]], which is a generalization of [[mathematical recursion]] over the natural numbers.}} Von Neumann avoided [[axiom schema]]s by formalizing the concept of "definite propositional function" with his functions, whose construction requires only finitely many axioms. This led to his set theory having finitely many axioms.&lt;ref&gt;{{harvnb|von Neumann|1925|pp=224&amp;ndash;226}}; English translation: {{Harvnb|van&amp;nbsp;Heijenoort|2002b|pp=399&amp;ndash;401}}.&lt;/ref&gt; In 1961, [[Richard Montague]] proved that ZFC cannot be finitely axiomatized.&lt;ref&gt;{{harvnb|Montague|1961}}.&lt;/ref&gt;
* '''The axiom of regularity''' 
** Problem: Zermelo set theory starts with the empty set and an infinite set, and iterates the axioms of pairing, union, power set, separation, and choice to generate new sets. However, it does not restrict sets to these. For example, it allows sets that are not [[well-founded set|well-founded]], such as a set ''x'' satisfying ''x''&amp;nbsp;∈&amp;nbsp;''x''.&lt;ref&gt;Mirimanoff defined well-founded sets in 1917 {{harv|Mirimanoff|1917|p=41}}.&lt;/ref&gt; 
** Solutions: Fraenkel introduced an axiom to exclude these sets. Von Neumann analyzed Fraenkel's axiom and stated that it was not "precisely formulated", but it would approximately say: "Besides the sets ... whose existence is absolutely required by the axioms, there are no further sets."&lt;ref&gt;{{harvnb|von Neumann|1925|pp=230&amp;ndash;232}}; English translation: {{Harvnb|van&amp;nbsp;Heijenoort|2002b|pp=404&amp;ndash;405}}.&lt;/ref&gt; Von Neumann proposed the axiom of regularity as a way to exclude non-well-founded sets, but did not include it in his axiom system. In 1930, Zermelo became the first to publish an axiom system that included regularity.{{efn|[[Akihiro Kanamori]] points out that Bernays lectured on his axiom system in 1929-1930 and states that "… he and Zermelo must have arrived at the idea of incorporating Foundation [regularity] almost at the same time." {{harv|Kanamori|2009|pp=53&amp;ndash;54}}. However, Bernays did not publish the part of his axiom system containing regularity until 1941 {{harv|Bernays|1941|p=6}}.}}

=== Von Neumann's 1929 axiom system ===
[[File:JohnvonNeumann-LosAlamos.gif|thumb|upright=0.8|John von Neumann]]

In 1929, von Neumann published an article containing the axioms that would lead to NBG. This article was motivated by his concern about the consistency of the axiom of limitation of size. He stated that this axiom "does a lot, actually too much." Besides implying the axioms of separation and replacement, and the [[well-ordering theorem]], it also implies that any class whose [[cardinality]] is less than that of ''V'' is a set. Von Neumann thought that this last implication went beyond Cantorian set theory and concluded: "We must therefore discuss whether its [the axiom's] consistency is not even more problematic than an axiomatization of set theory that does not go beyond the necessary Cantorian framework."&lt;ref&gt;{{harvnb|von Neumann|1929|p=229}}; {{harvnb|Ferreirós|2007|pp=379&amp;ndash;380}}.&lt;/ref&gt;

Von Neumann started his consistency investigation by introducing his 1929 axiom system, which contains all the axioms of his 1925 axiom system except the axiom of limitation of size. He replaced this axiom with two of its consequences, the axiom of replacement and a choice axiom. Von Neumann's choice axiom states: "Every relation ''R'' has a subclass that is a function with the same domain as ''R''."&lt;ref&gt;{{harvnb|Kanamori|2009|pp=49, 53}}.&lt;/ref&gt;

Let ''S'' be von Neumann's 1929 axiom system. Von Neumann introduced the axiom system ''S'' + Regularity (which consists of ''S'' and the axiom of regularity) to demonstrate that his 1925 system is [[relative consistency|consistent relative]] to ''S''. He proved:
# If ''S'' is consistent, then ''S'' + Regularity is consistent.
# ''S'' + Regularity implies the axiom of limitation of size. Since this is the only axiom of his 1925 axiom system that ''S'' + Regularity does not have, ''S'' + Regularity implies all the axioms of his 1925 system. 
These results imply: If ''S'' is consistent, then von Neumann's 1925 axiom system is consistent. Proof: If ''S'' is consistent, then ''S'' + Regularity is consistent (result  1). Using [[proof by contradiction]], assume that the 1925 axiom system is inconsistent, or equivalently: the 1925 axiom system implies a contradiction. Since ''S'' + Regularity implies the axioms of the 1925 system (result 2), ''S'' + Regularity also implies a contradiction. However, this contradicts the consistency of ''S'' + Regularity. Therefore, if ''S'' is consistent, then von Neumann's 1925 axiom system is consistent.

Since ''S'' is his 1929 axiom system, von Neumann's 1925 axiom system is consistent relative to his 1929 axiom system, which is closer to Cantorian set theory. The major differences between Cantorian set theory and the 1929 axiom system are classes and von Neumann's choice axiom. The axiom system ''S'' + Regularity was modified by Bernays and Gödel to produce the equivalent NBG axiom system.

=== Bernays' axiom system ===
[[File:PaulBernays 1949 MFO.jpg|thumb|upright=1.5|Paul Bernays]]
In 1929, [[Paul Bernays]] started modifying von Neumann's new axiom system by taking classes and sets as primitives. He published his work in a series of articles appearing from 1937 to 1954.&lt;ref&gt;{{harvnb|Kanamori|2009|pp=48, 58}}. Bernays' articles are reprinted in {{harvnb|Müller|1976|pp=1&amp;ndash;117}}.&lt;/ref&gt; Bernays stated that:

{{quote|The purpose of modifying the von Neumann system is to remain nearer to the structure of the original Zermelo system and to utilize at the same time some of the set-theoretic concepts of the [[Ernst Schröder#Work|Schröder logic]] and of ''[[Principia Mathematica]]'' which have become familiar to logicians. As will be seen, a considerable simplification results from this arrangement.&lt;ref&gt;{{harvnb|Bernays|1937|p=65}}.&lt;/ref&gt;}}

Bernays handled sets and classes in a [[Many-sorted first-order logic|two-sorted logic]] and introduced two membership primitives: one for membership in sets and one for membership in classes. With these primitives, he rewrote and simplified von Neumann's 1929 axioms. Bernays also included the axiom of regularity in his axiom system.&lt;ref&gt;{{harvnb|Kanamori|2009|pp=48&amp;ndash;54}}. &lt;/ref&gt;

=== Gödel's axiom system (NBG) ===
[[File:Kurt gödel.jpg|thumb|upright=0.8|Kurt Gödel]]
In 1931, Bernays sent a letter containing his set theory to [[Kurt Gödel]].&lt;ref&gt;{{harvnb|Kanamori|2009|p=48}}; {{harvnb|Gödel|2003|pp=104&amp;ndash;115}}.&lt;/ref&gt; Gödel simplified Bernays' theory by making every set a class, which allowed him to use just one sort and one membership primitive. He also weakened some of Bernays' axioms and replaced von Neumann's choice axiom with the equivalent axiom of global choice.&lt;ref&gt;{{harvnb|Kanamori|2009|p=56}}.&lt;/ref&gt;{{efn|Proof that von Neumann's axiom implies global choice: Let &lt;math&gt;R = \{(x, y): x \ne \empty \land y \in x\}.&lt;/math&gt; Von Neumann's axiom implies there is a function &lt;math&gt;G \subseteq R&lt;/math&gt; such that &lt;math&gt;Dom(G) = Dom(R).&lt;/math&gt; The function &lt;math&gt;G&lt;/math&gt; is a global choice function since for all nonempty sets &lt;math&gt;x,&lt;/math&gt; &lt;math&gt;G(x) \in x.&lt;/math&gt; Proof that global choice implies von Neumann's axiom: Let &lt;math&gt;G&lt;/math&gt; be a global choice function, and let &lt;math&gt;R&lt;/math&gt; be a relation. For &lt;math&gt;x \in Dom(R),&lt;/math&gt; let &lt;math&gt;\alpha(x) = \text{least}\,\{\alpha: \exists y[(x, y) \in R \cap V_\alpha]\}&lt;/math&gt; where &lt;math&gt;V_\alpha&lt;/math&gt; is the set of all sets having [[Rank (set theory)|rank]] less than &lt;math&gt;\alpha.&lt;/math&gt; Let &lt;math&gt;z_x = \{y: (x, y) \in R \cap V_{\alpha(x)}\}.&lt;/math&gt; Then &lt;math&gt;F = \{(x, G(z_x)): x \in Dom(R)\}&lt;/math&gt; is a function that satisfies von Neumann's axiom since &lt;math&gt;F \subseteq R&lt;/math&gt; and &lt;math&gt;Dom(F) = Dom(R).&lt;/math&gt;}} Gödel used his axioms in his 1940 monograph on the relative consistency of global choice and the generalized continuum hypothesis.&lt;ref&gt;{{harvnb|Kanamori|2009|pp=56&amp;ndash;58}}; {{harvnb|Gödel|1940}}.&lt;/ref&gt;

Several reasons have been given for Gödel choosing NBG for his monograph:{{efn|Gödel used von Neumann's 1929 axioms in his 1938 announcement of his relative consistency theorem and stated "A corresponding theorem holds if ''T'' denotes the system of ''Principia mathematica''" {{harv|Gödel|1990|p=26}}. His 1939 sketch of his proof is for Zermelo set theory and ZF {{harv|Gödel|1990|pp=28&amp;ndash;32}}. Proving a theorem in multiple [[formal systems]] was not unusual for Gödel. For example, he proved his [[incompleteness theorem]] for the system of ''Principia mathematica'', but pointed out that it "holds for a wide class of formal systems ..." {{harv|Gödel|1986|p=145}}.}}
* Gödel gave a mathematical reason—NBG's global choice produces a stronger consistency theorem: "This stronger form of the axiom [of choice], if consistent with the other axioms, implies, of course, that a weaker form is also consistent."&lt;ref name=Godelp6 /&gt;
* [[Robert Solovay]] conjectured: "My guess is that he [Gödel] wished to avoid a discussion of the technicalities involved in developing the rudiments of [[model theory]] within axiomatic set theory."{{efn|{{harvnb|Gödel|1990|p=13}}. Gödel's consistency proof builds the [[constructible universe]]. To build this in ZF requires some model theory. Gödel built it in NBG without model theory. For Gödel's construction, see {{harvnb|Gödel|1940|pp=35&amp;ndash;46}} or {{harvnb|Cohen|1966|pp=99&amp;ndash;103}}.}}
* [[Kenneth Kunen]] gave a reason for Gödel avoiding this discussion: "There is also a much more combinatorial approach to '''L''' [the [[constructible universe]]], developed by ... [Gödel in his 1940 monograph] in an attempt to explain his work to non-logicians. ... This approach has the merit of removing all vestiges of logic from the treatment of '''L'''."&lt;ref&gt;{{harvnb|Kunen|1980|p=176}}.&lt;/ref&gt;
* [[Charles Parsons (philosopher)|Charles Parsons]] provided a philosophical reason for Gödel's choice: "This view [that 'property of set' is a primitive of set theory] may be reflected in Gödel's choice of a theory with class variables as the framework for ... [his monograph]."{{efn|{{harvnb|Gödel|1990|p=108}}, footnote i. The paragraph containing this footnote discusses why Gödel considered "property of set" a primitive of set theory and how it fit into his [[ontology]]. "Property of set" corresponds to the "class" primitive in NBG.}}

Gödel's achievement together with the details of his presentation led to the prominence that NBG would enjoy for the next two decades.&lt;ref&gt;{{harvnb|Kanamori|2009|p=57}}.&lt;/ref&gt; In 1963, [[Paul Cohen (mathematician)|Paul Cohen]] proved his [[Independence (mathematical logic)|independence]] proofs for ZF with the help of some tools that Gödel had developed for his relative consistency proofs for NBG.&lt;ref&gt;{{harvnb|Cohen|1963}}.&lt;/ref&gt; Later, ZFC became more popular than NBG.  This was caused by several factors, including the extra work required to handle [[Forcing (mathematics)|forcing]] in NBG,{{efn|{{harvnb|Kanamori|2009|p=65}}: "Forcing itself went a considerable distance in downgrading any formal theory of classes because of the added encumbrance of having to specify the classes of generic extensions."}} Cohen's 1966 presentation of forcing, which used ZF,&lt;ref&gt;{{harvnb|Cohen|1966|pp=107&amp;ndash;147}}. Cohen also gave a detailed proof of Gödel's relative consistency theorems using ZF {{harv|Cohen|1966|pp=85&amp;ndash;99}}.&lt;/ref&gt; and the proof that NBG is a conservative extension of ZFC.{{efn|In the 1960s, this conservative extension theorem was proved independently by Paul Cohen, [[Saul Kripke]], and Robert Solovay. In his 1966 book, Cohen mentioned this theorem and stated that its proof requires forcing. It was also proved independently by [[Ronald Jensen]] and Ulrich Felgner, who published his proof in 1971. ({{harvnb|Ferreirós|2007|pp=381&amp;ndash;382}}; {{harvnb|Cohen|1966|p=77}}; {{harvnb|Felgner|1971}}.)}}

==NBG, ZFC, and MK==
NBG is not logically equivalent to ZFC because its language is more expressive: it can make statements about classes, which cannot be made in ZFC. However, NBG and ZFC imply the same statements about sets. Therefore, NBG is a [[conservative extension]] of ZFC. NBG implies theorems that ZFC does not imply, but since NBG is a conservative extension, these theorems must involve proper classes. For example, NBG implies that the class ''V'' of all sets can be well-ordered and that every proper class can be put into one-to-one correspondence with ''V''.{{efn|Both theorems follow from the theorem that every proper class can be put into one-to-one correspondence with the class of all ordinals. A proof of this theorem is outlined in {{harvnb|Kanamori|2009|p=53}}.}}

One consequence of conservative extension is that ZFC and NBG are [[equiconsistent]]. Proving this uses the [[principle of explosion]]: from a [[contradiction]], everything is provable. Assume that either ZFC or NBG is inconsistent. Then the inconsistent theory implies the contradictory statements ∅&amp;nbsp;=&amp;nbsp;∅ and ∅&amp;nbsp;≠&amp;nbsp;∅, which are statements about sets. By the conservative extension property, the other theory also implies these statements. Therefore, it is also inconsistent. So although NBG is more expressive, it is equiconsistent with ZFC. This result together with von Neumann's 1929 relative consistency proof implies that his 1925 axiom system with the axiom of limitation of size is equiconsistent with ZFC. This completely resolves von Neumann's concern about the relative consistency of this powerful axiom since ZFC is within the Cantorian framework.

Even though NBG is a conservative extension of ZFC, a theorem may have a shorter and more elegant proof in NBG than in ZFC (or vice versa). For a survey of known results of this nature, see {{harvnb|Pudlák|1998}}. 

[[Morse–Kelley set theory]] has an axiom schema of class comprehension that includes formulas whose quantifiers range over classes. MK is a stronger theory than NBG because MK proves the consistency of NBG,&lt;ref&gt;{{harvnb|Mostowski|1950|p=113}}, footnote 11. Footnote references [[Hao Wang (academic)|Wang]]'s NQ set theory, which later evolved into MK.&lt;/ref&gt; while [[Gödel's second incompleteness theorem]] implies that NBG cannot prove the consistency of NBG. 

For a discussion of some [[ontology|ontological]] and other philosophical issues posed by NBG, especially when contrasted with ZFC and MK, see Appendix C of {{harvnb|Potter|2004}}.

===Models=== 
ZFC, NBG, and MK have [[ Model (mathematical logic)|model]]s describable in terms of [[the cumulative hierarchy]] ''V&lt;sub&gt;α&lt;/sub&gt;''{{space|hair}} and the [[constructible hierarchy]] ''L&lt;sub&gt;α&lt;/sub&gt;''{{space|hair}}. Let  ''V'' include an [[inaccessible cardinal]] κ and let Def(''X'') denote the Δ&lt;sub&gt;0&lt;/sub&gt; definable subsets of ''X'' (see [[constructible universe]]). Then:
* ''V''&lt;sub&gt;κ&lt;/sub&gt; and ''L''&lt;sub&gt;κ&lt;/sub&gt; are models of [[ZFC]].
* Def(''V''&lt;sub&gt;κ&lt;/sub&gt;) is a model of Mendelson's version of NBG, which replaces global choice by ordinary choice. Def(''V''&lt;sub&gt;κ&lt;/sub&gt;) is not necessarily a model of NBG since global choice might fail.
* ''L''&lt;sub&gt;κ&lt;sup&gt;+&lt;/sup&gt;&lt;/sub&gt;, where κ&lt;sup&gt;+&lt;/sup&gt; is the [[successor cardinal]] of κ, is a model of NBG.
* ''V''&lt;sub&gt;κ+1&lt;/sub&gt; is a model of MK, which implies that it is also a model of NBG.

==Category theory==
The ontology of NBG provides scaffolding for speaking about "large objects" without risking paradox. For instance, in some developments of [[category theory]], a "[[large category]]" is defined as one whose [[object (category theory)|object]]s and [[morphism]]s make up a proper class. On the other hand, a "small category" is one whose objects and morphisms are members of a set. Thus, we can speak of the "[[category of all sets]]" or "[[category of all small categories]]" without risking paradox since NBG supports large categories. 

However, NBG does not support a "category of all categories" since large categories would be members of it and NBG does not allow proper classes to be members of anything. An ontological extension that enables us to talk formally about such a "category" is the [[Conglomerate (set theory)|conglomerate]], which is a collection of classes. Then the "category of all categories" is defined by its objects: the conglomerate of all categories; and its morphisms: the conglomerate of all morphisms from ''A'' to ''B'' where ''A'' and ''B'' are objects.&lt;ref&gt;{{harvnb|Adámek|Herrlich|Strecker|2004|pp=15&amp;ndash;16, 40}}.&lt;/ref&gt; On whether an ontology including classes as well as sets is adequate for category theory, see {{harvnb|Muller|2001}}.

== Notes ==
{{notelist|1}}

==References==
{{reflist|2}}

==Bibliography==
* {{Citation |last1=Adámek |first1=Jiří |last2=Herrlich |first2=Horst |last3=Strecker |first3=George E. |title=Abstract and Concrete Categories (The Joy of Cats) |edition=1st |url=http://katmat.math.uni-bremen.de/acc/ |format=PDF |year=1990 |publisher=Wiley &amp; Sons |location=New York |isbn=978-0-471-60922-3}}.
**{{Citation |last1=Adámek |first1=Jiří |last2=Herrlich |first2=Horst |last3=Strecker |first3=George E. |title=Abstract and Concrete Categories (The Joy of Cats) |edition=Dover |origyear=1990 |url=http://katmat.math.uni-bremen.de/acc/ |format=PDF |year=2004 |publisher=Dover Publications |location=New York |isbn=978-0-486-46934-8}}.
* {{Citation |last = Bernays |first = Paul |title = A System of Axiomatic Set Theory—Part I |journal = [[The Journal of Symbolic Logic]] |volume = 2 |pages = 65&amp;ndash;77 |year = 1937 |doi=10.2307/2268862 |jstor=2268862}}.
* {{Citation |last = Bernays |first = Paul |title = A System of Axiomatic Set Theory—Part II |journal = The Journal of Symbolic Logic |volume = 6 |pages = 1&amp;ndash;17 |year = 1941 |doi=10.2307/2267281 |jstor=2267281}}.
* {{Citation |last=Bernays |first=Paul |title=Axiomatic Set Theory |edition=2nd Revised |publisher=Dover Publications |year=1991 |isbn=978-0-486-66637-2}}.
* {{Citation |last=Bourbaki |first=Nicolas |title=Elements of Mathematics: Theory of Sets |publisher=Springer |year=2004 | url=https://archive.org/details/springer_10.1007-978-3-642-59309-3 |isbn=978-3-540-22525-6}}.
* {{Citation |last=Cohen |first=Paul |title=The Independence of the Continuum Hypothesis |doi=10.1073/pnas.50.6.1143 |journal=[[Proceedings of the National Academy of Sciences of the United States of America]] |volume= 50|pages=1143–1148 |year=1963 |pmid=16578557 |pmc=221287}}.
* {{Citation |last=Cohen |first=Paul |title=Set Theory and the Continuum Hypothesis |publisher=W. A. Benjamin |year=1966}}.
**{{Citation |last=Cohen |first=Paul |title=Set Theory and the Continuum Hypothesis |publisher=Dover Publications |year=2008 |url={{Google books|Z4NCAwAAQBAJ|Set Theory and the Continuum Hypothesis||plainurl=yes}} |isbn=978-0-486-46921-8}}.
* {{Citation |last=Easton |first=William B. |year=1964 |title=Powers of Regular Cardinals |type=Ph.D. thesis |publisher=Princeton University}}.
* {{Citation |last=Felgner |first=Ulrich | title=Comparison of the axioms of local and universal choice |url=http://matwbn.icm.edu.pl/ksiazki/fm/fm71/fm7113.pdf |journal=Fundamenta Mathematicae |volume=71 |pages=43-62 |year=1971}}.
* {{Citation |last=Ferreirós |first=José |title=Labyrinth of Thought: A History of Set Theory and Its Role in Mathematical Thought |place=Basel, Switzerland |publisher=Birkhäuser |year=2007 |edition=2nd revised |isbn=978-3-7643-8349-7}}.
* {{Citation |last=Gödel |first=Kurt |title=The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the Axioms of Set Theory |edition=Revised |publisher=Princeton University Press |year=1940 |isbn=978-0-691-07927-1}}.
**{{Citation |last=Gödel |first=Kurt |others=with a foreword by [[Richard Laver|Laver, Richard]] |title=The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the Axioms of Set Theory |edition=Paperback |publisher=Ishi Press |year=2008 |isbn=978-0-923891-53-4}}.
* {{Citation |last=Gödel |first=Kurt |title=Collected Works, Volume 1: Publications 1929&amp;ndash;1936 |publisher=Oxford University Press |year=1986 |isbn=978-0-19-514720-9}}.
* {{Citation |last=Gödel |first=Kurt |title=Collected Works, Volume 2: Publications 1938&amp;ndash;1974 |publisher=Oxford University Press |year=1990 |isbn=978-0-19-514721-6}}.
* {{Citation |last=Gödel |first=Kurt |title=Collected Works, Volume 4: Correspondence A&amp;ndash;G |publisher=Oxford University Press |year=2003 |isbn=978-0-19-850073-5}}.
* {{Citation |last = Gray |first = Robert |title = Computer programs and mathematical proofs |journal = [[The Mathematical Intelligencer]] |volume = 13 |pages = 45&amp;ndash;48 |year = 1991 |doi=10.1007/BF03028342}}.
* {{Citation |last=Hallett |first=Michael |title=Cantorian Set Theory and Limitation of Size |edition=Hardcover |place=Oxford |publisher=Clarendon Press |year=1984 |isbn=978-0-19-853179-1}}.
**{{Citation |last=Hallett |first=Michael |title=Cantorian Set Theory and Limitation of Size |edition=Paperback |place=Oxford |publisher=Clarendon Press |year=1986 |isbn=978-0-19-853283-5}}.
* {{Citation |last=Kanamori |first=Akihiro |authorlink=Akihiro Kanamori |title=Bernays and Set Theory |url=http://math.bu.edu/people/aki/17a.pdf |journal=[[Bulletin of Symbolic Logic]] |volume=15 |pages=43–69 |year=2009 |doi=10.2178/bsl/1231081769 |jstor=25470304}}.
* {{Citation |last=Kanamori |first=Akihiro |title=In Praise of Replacement |url=http://math.bu.edu/people/aki/20.pdf |journal=[[Bulletin of Symbolic Logic]] |volume=18 |pages=46–90 |year=2012 |doi=10.2178/bsl/1327328439 |jstor=41472440}}.
* {{Citation |last=Kunen |first=Kenneth |authorlink=Kenneth Kunen |title=[[Set Theory: An Introduction to Independence Proofs]] |edition=Hardcover |publisher=North-Holland |year=1980 |isbn=978-0-444-86839-8}}.
**{{Citation |last=Kunen |first=Kenneth |title=Set Theory: An Introduction to Independence Proofs |edition=Paperback |publisher=North-Holland |year=2012 |isbn=978-0-444-56402-3}}.
* {{Citation |last=Mendelson |first=Elliott |authorlink=Elliott Mendelson |year=1997 |title=An Introduction to Mathematical Logic |edition=4th |location=London |publisher=Chapman and Hall/CRC; |isbn=978-0-412-80830-2}}. - Pp.&amp;nbsp;225&amp;ndash;86 contain the classic textbook treatment of NBG, showing how it does what we expect of set theory, by grounding [[relation (mathematics)|relations]], [[order theory]], [[ordinal number]]s, [[transfinite number]]s, etc.
* {{Citation |last1=Mirimanoff |first1=Dmitry |title=Les antinomies de Russell et de Burali-Forti et le probleme fondamental de la theorie des ensembles|year=1917 |journal=L'Enseignement Mathématique |volume=19 |pages=37–52}}.
* {{Citation | last = Montague | first = Richard | contribution = Semantic Closure and Non-Finite Axiomatizability I | editor = [[Samuel Buss|Buss, Samuel R.]] | title = Infinitistic Methods: Proceedings of the Symposium on Foundations of Mathematics | publisher = Pergamon Press | publication-date = 1961 | pages = 45&amp;ndash;69}}.
* {{Citation |last=Mostowski |first=Andrzej |authorlink=Andrzej Mostowski |title=Some impredicative definitions in the axiomatic set theory
|url=http://matwbn.icm.edu.pl/ksiazki/fm/fm37/fm37110.pdf |journal=[[Fundamenta Mathematicae]] |volume=37 |pages=111-124 |year=1950}}.
* {{Citation |last1=Muller |first1=F. A. |date=1 September 2001 |title=Sets, classes, and categories |journal=British Journal of the Philosophy of Science |volume=52 |issue=3 |pages=539–73 |doi=10.1093/bjps/52.3.539}}.
* {{Citation |editor-last=Müller |editor-first=Gurt |title=Sets and Classes: On the Work of Paul Bernays |series=Studies in Logic and the Foundations of Mathematics Volume 84 |location=Amsterdam |publisher=North Holland |year=1976 |isbn=978-0-7204-2284-9}}.
* {{Citation |last=Potter |first=Michael |title=Set Theory and Its Philosophy: A Critical Introduction |edition=Hardcover |publisher=Oxford University Press |year=2004 |isbn=978-0-19-926973-0}}.
**{{Citation |last=Potter |first=Michael |title=Set Theory and Its Philosophy: A Critical Introduction |edition=Paperback |publisher=Oxford University Press |year=2004 |isbn=978-0-19-927041-5}}.
* {{Citation | last = Pudlák | first = Pavel | contribution = The Lengths of Proofs | contribution-url = http://users.math.cas.cz/~pudlak/length.pdf | editor = [[Samuel Buss|Buss, Samuel R.]] | title = Handbook of Proof Theory | publisher = Elsevier | publication-date = 1998 | pages = 547&amp;ndash;637 | isbn = 978-0-444-89840-1}}.
* {{Citation |last=von Neumann |first=John |title=Zur Einführung der transfiniten Zahlen |url=http://bbi-math.narod.ru/newmann/newmann.html |journal=Acta litt. Acad. Sc. Szeged X. |volume=1 |pages=199–208 |year=1923}}. 
**English translation: {{citation |last=van&amp;nbsp;Heijenoort |first=Jean |origyear=1967 |year=2002 |publisher=Harvard University Press |title=From Frege to Gödel: A Source Book in Mathematical Logic, 1879-1931 |chapter=On the introduction of transfinite numbers |edition=Fourth Printing |pages=346–354 |url={{Google books|v4tBTBlU05sC|On the introduction of transfinite numbers|page=346|plainurl=yes}} |isbn=978-0-674-32449-7 |ref={{Harvid|van&amp;nbsp;Heijenoort|2002a}} }}.
* {{Citation |last=von Neumann |first=John |title=Eine Axiomatisierung der Mengenlehre |url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN243919689_0154&amp;DMDID=DMDLOG_0025 |journal=[[Journal für die Reine und Angewandte Mathematik]] |volume=154 |pages=219–240 |year=1925}}.
**English translation: {{citation |last=van&amp;nbsp;Heijenoort |first=Jean |origyear=1967 |year=2002 |publisher=Harvard University Press |title=From Frege to Gödel: A Source Book in Mathematical Logic, 1879-1931 |chapter=An axiomatization of set theory |edition=Fourth Printing |pages=393–413 |url={{Google books|v4tBTBlU05sC|An axiomatization of set theory|page=393|plainurl=yes}} |isbn=978-0-674-32449-7 |ref={{Harvid|van&amp;nbsp;Heijenoort|2002b}} }}.
* {{Citation |last=von Neumann |first=John |title=Die Axiomatisierung der Mengenlehre |url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN266833020_0027&amp;DMDID=DMDLOG_0042 |journal=[[Mathematische Zeitschrift]] |volume=27 |pages=669–752 |year=1928 |doi=10.1007/bf01171122}}.
* {{Citation |last=von Neumann |first=John |title=Über eine Widerspruchsfreiheitsfrage in der axiomatischen Mengenlehre |url=http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN243919689_0160&amp;DMDID=DMDLOG_0019 |journal=Journal für die Reine und Angewandte Mathematik |volume=160 |pages=227–241 |year=1929}}.

==External links==
* {{planetmathref|id=4395|title= von Neumann-Bernays-Gödel set theory}}
{{Use dmy dates|date=August 2011}}
* {{MathWorld|title=von Neumann-Bernays-Gödel Set Theory |id=vonNeumann-Bernays-GoedelSetTheory |author=Szudzik, Matthew}}

{{Set theory}}
{{Mathematical logic}}

{{DEFAULTSORT:Von Neumann-Bernays-Godel set theory}}
[[Category:Foundations of mathematics]]
[[Category:John von Neumann]]
[[Category:Systems of set theory]]
[[Category:Works by Kurt Gödel]]</text>
      <sha1>t8iyeuwvd30554nvjzczcp7gv405wxs</sha1>
    </revision>
  </page>
  <page>
    <title>Walter Ledermann</title>
    <ns>0</ns>
    <id>33383638</id>
    <revision>
      <id>801153059</id>
      <parentid>773537828</parentid>
      <timestamp>2017-09-18T00:07:03Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4049">{{Use dmy dates|date=April 2017}}
{{Use British English|date=April 2017}}
{{Infobox person
|name          = Walter Ledermann
|image         =
|image_size    = 
|birth_name    = 
|birth_date    = 18 March 1911
|birth_place   = [[Berlin]], [[Germany]]
|death_date    = 22 May 2009
|death_place   = [[London]], [[England]]
|nationality   = German, British
|other_names   =
|known_for     = Mathematics
|alma_mater = [[University of St Andrews]]
}}

'''Walter Ledermann''' [[FRSE]] (18 March 1911 Berlin, Germany – 22 May 2009  London, England) was a German and British mathematician who worked on matrix theory, group theory, homological algebra,  number theory, statistics, and stochastic processes. He was elected to the [[Royal Society of Edinburgh]] in 1944.

He taught at the universities of [[University of Dundee|Dundee]], [[University of St Andrews|St Andrews]], [[University of Manchester|Manchester]], and finally [[University of Sussex|Sussex]]. At Sussex, Ledermann was appointed professor in 1965, where he continued to teach until he was 89.&lt;ref&gt;[http://www.sussex.ac.uk/staff/newsandevents/newsarchive?id=853 Obituary - Professor Walter Ledermann] on Sussex University site&lt;/ref&gt; He wrote various mathematics textbooks.

==Publications==
*{{Citation | last1=Ledermann | first1=Walter | title=Introduction to the Theory of Finite Groups | url=https://books.google.com/books?id=afFUAAAAYAAJ | publisher=Oliver and Boyd, Edinburgh and London |mr=0028309 | year=1949}}; 2nd edn. 1953; 3rd edn. 1957; 4th rev. edn. 1961
*{{Citation | last1=Ledermann | first1=Walter | authormask= 2 | title=Complex numbers | publisher=Routledge and Kegan Paul, London | series=Library of Mathematics |mr=0118652 | year=1960}}
*{{Citation | last1 =Ledermann | first1=Walter | authormask=2 | title=Integral calculus | publisher=Dover | year=1964}}
*{{Citation | last1 =Ledermann | first1=Walter | authormask=2 | title=Multiple integrals | location=London | publisher=Routledge and Paul | year=1966}}; also published 1966 (New York, Dover)
*{{Citation | last1 =Ledermann | first1=Walter | authormask=2 | title=Introduction to group theory | publisher=Oliver and Boyd | year=1973}}; 2nd edn. 1996 Addison-Wesley
*{{Citation | last1=Ledermann | first1=Walter | authormask=2 | title=Introduction to group characters | url=https://books.google.com/books?id=ly88AAAAIAAJ | publisher=[[Cambridge University Press]] | isbn=978-0-521-21486-5 |mr=0460424 | year=1977}}; 2nd edn. 1987
*{{Citation | editor=Lederman, Walter | title=Handbook of applicable mathematics | publisher=Wiley | year=1980}};&lt;ref&gt;{{cite journal|author=Gardiner, A.|authorlink=Tony Gardiner|title=Review of ''Handbook of Applicable Mathematics''; Volume I|journal=The Mathematical Gazette|date=October 1981|volume=65|issue=433|pages=225–227|jstor=3617156|doi=10.2307/3617156}}&lt;/ref&gt; 10 editions from 1980 to 1991

==References==
{{reflist}}

==Further reading==
*{{Citation | last1=Gaines | first1=Fergus J. | last2=Laffey | first2=Thomas J. | title=The mathematical work of Walter Ledermann | url=https://dx.doi.org/10.1016/0024-3795(85)90066-7 | doi=10.1016/0024-3795(85)90066-7 |mr=798363 | year=1985 | journal=Linear Algebra and its Applications | issn=0024-3795 | volume=69 | pages=iii, 1–8}}
*{{MacTutor|id=Ledermann}}
*{{MathGenealogy|id=97140}}
*{{Citation | title=Walter Ledermann 1911–2009 |mr=2560292 | year=2009 | journal=Mathematics Today | issn=1361-2042 | volume=45 | issue=4 | pages=140}}
*[http://www.gap-system.org/~history/HistTopics/Ledermann_interview.html Interview with Walter Ledermann] Gap system.org

{{Authority control}}

{{DEFAULTSORT:Ledermann, Walter}}
[[Category:20th-century German mathematicians]]
[[Category:21st-century German mathematicians]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Fellows of the Royal Society of Edinburgh]]
[[Category:1911 births]]
[[Category:Alumni of the University of St Andrews]]
[[Category:2009 deaths]]
[[Category:Holocaust survivors]]


{{mathematician-stub}}</text>
      <sha1>qfbjn0rudrfllxjwchjexz88c9yynmd</sha1>
    </revision>
  </page>
</mediawiki>
