<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Activity (UML)</title>
    <ns>0</ns>
    <id>2130559</id>
    <revision>
      <id>727556717</id>
      <parentid>589448247</parentid>
      <timestamp>2016-06-29T19:23:50Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* top */Rem stub tag(s) (class = non-stub &amp; non-list) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="894">{{Unreferenced|date=August 2008}}

An '''activity''' in [[Unified Modeling Language]] (UML) is a major task that must take place in order to fulfill an operation contract. Activities can be represented in [[activity diagram]]s

An activity can represent:
* The invocation of an operation.
* A step in a [[business process]].
* An entire business process. 
Activities can be decomposed into subactivities, until at the bottom we find [[atomic actions]]. 

The underlying conception of an activity has changed between UML 1.5 and UML 2.0. In UML 2.0 an activity is no longer based on the state-chart rather it is based on a [[Petri net]] like coordination mechanism. There the activity represents user-defined behavior coordinating actions. Actions in turn are pre-defined (UML offers a series of actions for this).


{{UML}}

{{DEFAULTSORT:Activity (Uml)}}
[[Category:Unified Modeling Language]]</text>
      <sha1>rssqc0uysprwx5ia6w6nycd0dk7rgmj</sha1>
    </revision>
  </page>
  <page>
    <title>Alexander duality</title>
    <ns>0</ns>
    <id>3108888</id>
    <revision>
      <id>862708062</id>
      <parentid>855671084</parentid>
      <timestamp>2018-10-06T05:09:41Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3729">In [[mathematics]], '''Alexander duality''' refers to a [[duality theory]] presaged by a result of 1915 by [[James Waddell Alexander II|J. W. Alexander]], and subsequently further developed, particularly by [[P. S. Alexandrov]] and [[Lev Pontryagin]]. It applies to the [[homology theory]] properties of the complement of a [[subspace topology|subspace]] ''X'' in [[Euclidean space]], a [[sphere]], or other [[manifold (mathematics)|manifold]]. It is generalized by [[Spanier-Whitehead duality]].

==Modern statement==
Let ''X'' be a [[compact space|compact]], [[locally contractible space|locally contractible]] subspace of the sphere ''S'' of dimension ''n''. Let ''Y'' be the complement of ''X'' in ''S''. Then if ''H'' stands for [[reduced homology]] or [[reduced cohomology]], with coefficients in a given [[abelian group]], there is an [[isomorphism]] between 

:''H''&lt;sub&gt;''q''&lt;/sub&gt;(''X'')

and 

:''H''&lt;sup&gt;''n'' − ''q'' − 1&lt;/sup&gt;(''Y'').

Note that we can drop [[Contractible space#Locally contractible spaces|local contractibility]] as part of the hypothesis, if we use [[Čech cohomology]], which is designed to deal with local pathologies.

==Alexander's 1915 result== 
To go back to Alexander's original work, it is assumed that ''X'' is a [[simplicial complex]]. 

Alexander had little of the modern apparatus, and his result was only for the [[Betti number]]s, with coefficients taken ''modulo'' 2. What to expect comes from examples. For example the [[Clifford torus]] construction in the [[3-sphere]] shows that the complement of a [[solid torus]] is another solid torus; which will be open if the other is closed, but this does not affect its homology. Each of the solid tori is from the [[homotopy]] point of view a [[circle]]. If we just write down the Betti numbers

:1, 1, 0, 0

of the circle (up to ''H''&lt;sub&gt;3&lt;/sub&gt;, since we are in the 3-sphere), then reverse as

:0, 0, 1, 1

and then shift one to the left to get

:0, 1, 1, 0

there is a difficulty, since we are not getting what we started with. On the other hand the same procedure applied to the ''reduced'' Betti numbers, for which the initial Betti number is decremented by 1, starts with

:0, 1, 0, 0

and gives

:0, 0, 1, 0

whence

:0, 1, 0, 0.

This ''does'' work out, predicting the complement's reduced Betti numbers.

The prototype here is the [[Jordan curve theorem]], which [[topology|topologically]] concerns the complement of a [[circle]] in the [[Riemann sphere]]. It also tells the same story. We have the honest Betti numbers

:1, 1, 0

of the circle, and therefore

:0, 1, 1

by flipping over and

:1, 1, 0

by shifting to the left. This gives back something different from what the Jordan theorem states, which is that there are two components, each [[contractible]] ([[Schoenflies theorem]], to be accurate about what is used here). That is, the correct answer in honest Betti numbers is 

:2, 0, 0.

Once more, it is the reduced Betti numbers that work out. With those, we begin with

:0, 1, 0

to finish with

:1, 0, 0.

From these two examples, therefore, Alexander's formulation can be inferred: reduced Betti numbers ''b''*&lt;sub&gt;''i''&lt;/sub&gt; are related in complements by

:''b''*&lt;sub&gt;''i''&lt;/sub&gt; → ''b''*&lt;sub&gt;''n'' − ''i'' − 1&lt;/sub&gt;.

==References==
* {{cite book |last= Hatcher|first= Allen|date= 2002|title= Algebraic Topology|location= Cambridge|publisher= Cambridge University Press|page= 254|isbn=0-521-79540-0|url= https://www.math.cornell.edu/~hatcher/AT/AT.pdf}}
* {{Springer|title = Alexander duality|id = A/a011290}}

==Further reading==
*Ezra Miller, Bernd Sturmfels, ''Combinatorial Commutative Algebra'' (2005), Ch. 5 ''Alexander Duality''

[[Category:Algebraic topology]]
[[Category:Duality theories]]</text>
      <sha1>h8idk34sp4lelo1vzixshzlre3po1rp</sha1>
    </revision>
  </page>
  <page>
    <title>Attribute domain</title>
    <ns>0</ns>
    <id>3932587</id>
    <revision>
      <id>746463033</id>
      <parentid>746462942</parentid>
      <timestamp>2016-10-27T15:20:39Z</timestamp>
      <contributor>
        <username>Ganeshbhat31055</username>
        <id>14113514</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1571">In computing, the '''attribute domain''' is the set of [[Value (computer science)|value]]s allowed in an [[Attribute (computing)|attribute]].&lt;ref&gt;{{citation|title=A Guided Tour of Relational Databases and Beyond|first1=Mark|last1=Levene|first2=George|last2=Loizou|publisher=Springer|year=1999|isbn=9781852330088|page=72|url=https://books.google.com/books?id=CkYpI7QsLlQC&amp;pg=PA72}}.&lt;/ref&gt;

For example: 
    Rooms in hotel (1-300)
    Age (1-99)
    Married (yes or no)
    Nationality (Nepalese, Indian, American, or British)
    Colors (Red, Yellow, Green)

For the [[relational model]] it is a requirement that each part of a [[tuple]] be atomic.&lt;ref&gt;{{citation|title=Database Management Systems|first=Rajesh|last=Narang|publisher=PHI Learning Pvt. Ltd.|year=2011|isbn=9788120343139|page=70|url=https://books.google.com/books?id=4TRuL7nDsj4C&amp;pg=PT89}}.&lt;/ref&gt; The consequence is that each value in the tuple must be of some basic type, like a [[String (computer science)|string]] or an [[integer]]. For the elementary type to be atomic it cannot be broken into more pieces. Alas, the domain is an elementary type, and attribute domain the domain a given attribute belongs to an abstraction belonging to or characteristic of an entity.

For example in SQL ,one can create their own domain for an attribute with the command

  CREATE DOMAIN SSN_TYPE AS CHAR(9) ;

The above command says : "Create a datatype SSN_TYPE that is of character type with size 9 "

==References==
{{reflist}}

{{DEFAULTSORT:Attribute Domain}}
[[Category:Type theory]]
[[Category:Database theory]]</text>
      <sha1>pcypk8puxxij5ctla7uftylh67aim11</sha1>
    </revision>
  </page>
  <page>
    <title>Australian Mathematics Competition</title>
    <ns>0</ns>
    <id>4607798</id>
    <revision>
      <id>796075183</id>
      <parentid>790187614</parentid>
      <timestamp>2017-08-18T09:19:30Z</timestamp>
      <contributor>
        <username>Shuetrim</username>
        <id>1582062</id>
      </contributor>
      <comment>Grammar fix.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9721">The '''Australian Mathematics Competition''' is a mathematics competition run by the '''Australian Mathematics Trust''' for students from year 3 up to year 12 in [[Australia]], and their equivalent grades in other countries. Since its inception in 1976 in the [[Australian Capital Territory]], the participation numbers have increased to around 600,000, with around 100,000 being from outside Australia, making it the world's largest mathematics competition.{{Citation needed|reason=Needs reliable source.|date=July 2013}}

== History ==
[[Image:Wales award 1978.jpg|right|thumb|230px|Wales award from 1978]]The fore-runner of the competition, first held in 1976, was open to students within the [[Australian Capital Territory]], and attracted 1200 entries. In 1976 and 1977 the outstanding entrants were awarded the Burroughs medal.&lt;ref&gt;Canberra Mathematical Association et al.: High school mathematics competition for the Burroughs medal : solutions and statistics, Canberra College of Advanced Education, 1976&lt;/ref&gt; In 1978, the competition became a nationwide event, and became known as the Australian Mathematics Competition for the Wales awards with 60,000 students from [[Australia]] and [[New Zealand]] participating. In 1983 the medals were renamed the Westpac awards following a change to the name of the title sponsor [[Westpac Banking Corporation]] (previously known as the [[Bank of New South Wales]]). Other sponsors since the inception of the competition have been the [[Canberra Mathematical Association]] and the [[University of Canberra]] (previously known as the [[Canberra College of Advanced Education]]).

The competition has since spread to countries such as [[New Zealand]], [[Singapore]], [[Fiji]], [[Taiwan]] and [[Malaysia]], which submit thousands of entries each. A [[French language|French]] translation of the paper has been available since the current competition was established in 1978, with [[Chinese language|Chinese]] translation being made available to Hong Kong ([[Traditional_Chinese_characters|Traditional Chinese Characters]]) and Taiwan ([[Traditional_Chinese_characters|Traditional Chinese Characters]]) students in 2000. Large print and [[braille]] versions are also available.

In 2004, the competition was expanded to allow two more divisions, one for year five and six students, and another for year three and four students.

In 2005, students from 38 different countries entered the competition.

==Format==
The competition paper consists of twenty-five multiple-choice questions and five integer questions, which are ordered in increasing difficulty. Students record their personal details and mark their answers by pencil on a carbon-mark answer sheet, which is marked by computer. There are five divisions in total: Senior (for years 11 and 12), Intermediate (for years 9 and 10), Junior (for years 7 and 8), Upper Primary (for years 5 and 6) and Middle Primary (for years 3 and 4). 

Students are allowed 75 minutes (60 minutes for the two primary papers) to read and answer the questions. Calculators are not permitted for secondary-level entrants, but geometrical aids such as [[ruler]]s, [[compass]]es, [[protractor]]s and paper for working are permitted. Primary-level entrants may use calculators and any aids normally found in a classroom.

The original points scheme, which was in operation from inception until 2001, consisted of three groups of ten questions. The first ten questions were worth three marks each, the next ten four marks each, and the last ten five marks each. Students were deducted a quarter of the marks for a given question if they answered incorrectly, so that a student randomly guessing the answers would gain no numerical benefit (on statistical average). Students started with 30 marks, so that a student who answered all questions incorrectly would record a total score of zero, while one who answered all questions correctly would record a score of 150.

In 2002, the format was changed so that no penalties were incurred for incorrect answers to the first twenty questions, and for each of the last ten questions, a correct answer gave eight marks, no answer gave three marks, and no marks were given for an incorrect answer; the total score remained the same at 150.

In 2005, the format was changed once more.  This time the first ten questions are still worth three marks each and the next ten are still worth four marks each, however the last ten are now once again worth 5 marks each.  To make it harder to guess the most difficult questions, the last 5 questions required integer answers between 0 and 999 inclusive.  The total score possible was thus reduced to 120. [https://web.archive.org/web/20060507004503/http://www.amt.canberra.edu.au/amcnews.html]

It has since been changed yet again. The first 25 questions have remained with the same mark allocation, however the last 5 questions have been altered. Although still requiring integer answers between 0 and 999, the mark allocation has been changed to 6 marks for Q26, 7 marks for Q27, 8 marks for Q28, 9 marks for Q29 and 10 marks for Q30, bringing the total marks to 135.

The competition is supervised by staff of the individual educational institutions, and the Australian Mathematics Trust reserves the right to conduct re-examinations in order to preserve the integrity of the competition, if it believes that students have not attempted the paper under sufficiently stringent conditions.

== Syllabus ==
There is no official declared syllabus which determines the scope of the problems presented to the students. However, all problems can be solved without the use of [[calculus]].

==Awards system==
Despite the name of the competition, students are allocated awards for their performance relative to other students in their region, of the same year level. For Australian students, this means their State or Territory, and for other students, their country. Although the personal data such as date of birth and gender are collected, this is not used in the percentile ranking, which is only determined by the raw score. The award scheme is as such
* '''Prize''' – Students above the 99.7 [[percentile]]
* '''High Distinction''' – Students between the 97 and 99.7 percentile (Between 95 and 99.7 percentile for senior division)
* '''Distinction''' -Students between the 80 and 97 percentile (Between 75 and 95 percentile for senior division)
* '''Credit''' – Students between the 45 and 80 percentile (Between 40 and 75 percentile for senior division)
* '''Proficiency''' – Students below the 45 percentile who have a satisfactory score (at least 32 but may sometimes be lower) 
* '''Participation''' – Students who have not received a higher award

Students who have won a prize may also receive a medal if they are determined to have performed outstandingly well with respect to their region and the competition as a whole. All students receive a certificate, and prizewinners are awarded an additional monetary sum or book voucher. Students who achieve the maximum score are awarded the [[Bernhard Neumann]] certificate. From 2008, this award has been renamed the Peter O'Halloran Certificate in honour of the foundation Executive Director of the Trust. In 1998, a record 10 students in Australia, and 23 in Singapore achieved the maximum attainable score. A re-examination was carried out in order to determine the Singaporean medallists. 

All students receive an analysis sheet along with their certificate, which records their answers for each question, along with the correct answers. The questions are divided into four categories: arithmetic, algebra, geometry and problem solving, and the number of questions that the student answered correctly for each category is listed along with the regional mean.

Every school receives a more comprehensive analysis, with a complete record of answers given by all students, as well as the percentage of students choosing any given answer for a given question, and a comparison to the percentage of students choosing any given answer for a given question in the whole region. Schools also receive analysis of their students by mathematical topic, compared to the entire region.

== Successful students ==
Three students have won medals on all six of their opportunities to participate:&lt;ref name="amt.edu.au"&gt;[http://www.amt.edu.au/amcprev.html Australian Mathematics Trust – AMC: Previous Results&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;
* Geoffrey Chu, [[Scotch College, Melbourne]], [[Victoria (Australia)|Victoria]] (1995–2000)
* Peter McNamara, [[Hale School]], [[Western Australia]] (1996–2001)
* Aaron Chong, [[Doncaster Secondary College]], [[Victoria (Australia)|Victoria]] (2005-2010)

Shane Booth, Wanganui Park High School, [[Shepparton]], [[Victoria (Australia)|Victoria]] was the first to win five consecutive medals (1981–1985).&lt;ref name="amt.edu.au" /&gt;

Ivan Guo, [[Sydney Boys High School]], [[New South Wales (Australia)|New South Wales]] was the first person to win three consecutive BH Neumann certificates, which are only awarded to those who achieve a perfect score.

==References==
* [https://web.archive.org/web/20060407121850/http://www.amt.edu.au/AMCFACT2006.pdf An AMC fact sheet from the Australian Mathematics Trust]
&lt;references/&gt;

==External links==
*[http://www.amt.edu.au Australian Mathematics Trust website]
*[https://sites.google.com/site/pjt154/home/early-amc History of Australian Mathematics Competition, written by Emeritus Professor Peter Taylor (Former Executive Director of AMT)]

{{Primarysources|date=December 2006}}

[[Category:Mathematics competitions]]
[[Category:Education competitions in Australia]]
[[Category:Recurring events established in 1976]]</text>
      <sha1>05rw4pg105c0jyp078h3m2udwo1za80</sha1>
    </revision>
  </page>
  <page>
    <title>Barwise compactness theorem</title>
    <ns>0</ns>
    <id>17971241</id>
    <revision>
      <id>595914993</id>
      <parentid>515348913</parentid>
      <timestamp>2014-02-17T19:12:59Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* References */Fix [[Help:CS1_errors#deprecated_params|CS1 deprecated coauthor parameter errors]] (test) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1595">In [[mathematical logic]], the '''Barwise compactness theorem''', named after [[Jon Barwise]], is a generalization of the usual [[compactness theorem]] for [[first-order logic]] to a certain class of infinitary languages.  It was stated and proved by Barwise in 1967.

==Statement of the theorem==

Let &lt;math&gt;A&lt;/math&gt; be a countable [[admissible set]]. Let &lt;math&gt;L&lt;/math&gt; be an &lt;math&gt;A&lt;/math&gt;-finite relational language. Suppose &lt;math&gt;\Gamma&lt;/math&gt; is a set of &lt;math&gt;L_A&lt;/math&gt;-sentences, where &lt;math&gt;\Gamma&lt;/math&gt; is a &lt;math&gt;\Sigma_1&lt;/math&gt; set with parameters from &lt;math&gt;A&lt;/math&gt;, and every &lt;math&gt;A&lt;/math&gt;-finite subset of &lt;math&gt;\Gamma&lt;/math&gt; is satisfiable. Then &lt;math&gt;\Gamma&lt;/math&gt; is satisfiable.

==References==
*{{ cite book | title=Infinitary Logic and Admissible Sets (Ph. D. Thesis) | author=Barwise, J. | publisher=Stanford University| year=1967}}
* {{cite book | title=Computable Structures and the Hyperarithmetic Hierarchy | author=C. J. Ash |author2=Knight, J. | publisher=[[Elsevier]] | year=2000 | isbn=0-444-50072-3 | pages=366  }}
* {{cite book | title=Model-theoretic logics | author=Jon Barwise |author2=Solomon Feferman|author3=John T. Baldwin | publisher=[[Springer-Verlag]] | year=1985 | isbn=3-540-90936-2 | pages=295 }}

==External links==
* [http://plato.stanford.edu/entries/logic-infinitary/#5] ''Stanford Encyclopedia of Philosophy'', "Infinitary Logic", Section 5, "Sublanguages of L(ω1,ω) and the Barwise Compactness Theorem"

[[Category:Theorems in the foundations of mathematics]]
[[Category:Mathematical logic]]
[[Category:Metatheorems]]


{{mathlogic-stub}}</text>
      <sha1>6l3bloho5igdn227qr41aob22ey6suu</sha1>
    </revision>
  </page>
  <page>
    <title>Beta negative binomial distribution</title>
    <ns>0</ns>
    <id>31118503</id>
    <revision>
      <id>823383647</id>
      <parentid>782786288</parentid>
      <timestamp>2018-01-31T22:59:53Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>/* top */ rm pmf recurrence relation with no context or apparent importance</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5751">{{Probability distribution
  | name       = Beta Negative Binomial
  | type       = mass
  | pdf_image  = 
  | cdf_image  = 
  | notation   = 
  | parameters = &lt;math&gt;\alpha &gt; 0&lt;/math&gt; [[shape parameter|shape]] ([[real number|real]])&lt;br /&gt;&lt;math&gt;\beta &gt; 0&lt;/math&gt; [[shape parameter|shape]] ([[real number|real]]) &lt;br&gt; &lt;math&gt;r &gt; 0&lt;/math&gt;  — number of failures until the experiment is stopped ([[integer]] but can be extended to [[real number|real]])
  | support    = ''k'' ∈ { 0, 1, 2, 3, ... }
  | pdf        = &lt;math&gt;\frac{\Gamma(r+k)}{k!\;\Gamma(r)} \frac{\mathrm{B}(\alpha+r,\beta+k)} {\mathrm{B}(\alpha,\beta)}&lt;/math&gt; 
  | cdf        = 
  | mean       = &lt;math&gt;\begin{cases}
              \frac{r\beta}{\alpha-1} &amp; \text{if}\ \alpha&gt;1    \\
              \infty &amp; \text{otherwise}\ \end{cases}&lt;/math&gt;
  | median     = 
  | mode       = 
  | variance   =  &lt;math&gt;\begin{cases}
              \frac{r(\alpha+r-1)\beta(\alpha+\beta-1)}{(\alpha-2){(\alpha-1)}^2} &amp; \text{if}\ \alpha&gt;2    \\
              \infty &amp; \text{otherwise}\ \end{cases}&lt;/math&gt;
  | skewness   =  &lt;math&gt;\begin{cases}
              \frac{(\alpha+2r-1)(\alpha+2\beta-1)}{(\alpha-3)\sqrt{\frac{r(\alpha+r-1)\beta(\alpha+\beta-1)}{\alpha-2}}} &amp; \text{if}\ \alpha&gt;3    \\
              \infty &amp; \text{otherwise}\ \end{cases}&lt;/math&gt;
  | kurtosis   = 
  | entropy    = 
  | mgf        = undefined
  | char       = &lt;math&gt; \frac{\mathrm{B}(\alpha,\beta+r)} {\mathrm{B}(\alpha,\beta)} {}_{2}F_{1}(r,\alpha;\alpha+\beta+r;e^{it})\!&lt;/math&gt; where B is the [[beta function]] and &lt;sub&gt;2&lt;/sub&gt;F&lt;sub&gt;1&lt;/sub&gt; is the [[hypergeometric function]].}}

In [[probability theory]], a '''beta negative binomial distribution''' is the [[probability distribution]] of a [[discrete probability distribution|discrete]] [[random variable]]&amp;nbsp;''X'' equal to the number of failures needed to get ''r'' successes in a sequence of [[independence (probability theory)|independent]] [[Bernoulli trial]]s where the probability ''p'' of success on each trial is constant within any given experiment but is itself a random variable following a [[beta distribution]], varying between different experiments. Thus the distribution is a [[compound probability distribution]].

This distribution has also been called both the '''inverse Markov-Pólya distribution''' and the '''generalized Waring distribution'''.&lt;ref name=Johnson&gt;Johnson et al. (1993)&lt;/ref&gt; A shifted form of the distribution has been called the '''beta-Pascal distribution'''.&lt;ref name=Johnson/&gt;

If parameters of the beta distribution are ''&amp;alpha;'' and ''&amp;beta;'', and if
:&lt;math&gt;
X \mid p \sim \mathrm{NB}(r,p),
&lt;/math&gt;
where
:&lt;math&gt;
 p \sim \textrm{B}(\alpha,\beta),
&lt;/math&gt;
then the marginal distribution of ''X'' is a beta negative binomial distribution:
:&lt;math&gt;
X \sim \mathrm{BNB}(r,\alpha,\beta).
&lt;/math&gt;

In the above, NB(''r'',&amp;nbsp;''p'') is the [[negative binomial distribution]] and B(''&amp;alpha;'',&amp;nbsp;''&amp;beta;'') is the [[beta distribution]].

==Definition==
If &lt;math&gt;r&lt;/math&gt; is an integer, then the PMF can be written in terms of the [[beta function]],:
:&lt;math&gt;f(k|\alpha,\beta,r)=\binom{r+k-1}k\frac{\Beta(\alpha+r,\beta+k)}{\Beta(\alpha,\beta)}&lt;/math&gt;.
More generally the PMF can be written 
:&lt;math&gt;f(k|\alpha,\beta,r)=\frac{\Gamma(r+k)}{k!\;\Gamma(r)}\frac{\Beta(\alpha+r,\beta+k)}{\Beta(\alpha,\beta)}&lt;/math&gt;.

===PMF expressed with Gamma===
Using the properties of the [[Beta function]], the PMF with integer &lt;math&gt;r&lt;/math&gt; can be rewritten as:
:&lt;math&gt;f(k|\alpha,\beta,r)=\binom{r+k-1}k\frac{\Gamma(\alpha+r)\Gamma(\beta+k)\Gamma(\alpha+\beta)}{\Gamma(\alpha+r+\beta+k)\Gamma(\alpha)\Gamma(\beta)}&lt;/math&gt;.

More generally, the PMF can be written as
:&lt;math&gt;f(k|\alpha,\beta,r)=\frac{\Gamma(r+k)}{k!\;\Gamma(r)}\frac{\Gamma(\alpha+r)\Gamma(\beta+k)\Gamma(\alpha+\beta)}{\Gamma(\alpha+r+\beta+k)\Gamma(\alpha)\Gamma(\beta)}&lt;/math&gt;.

===PMF expressed with the rising Pochammer symbol===
The PMF is often also presented in terms of the [[Pochammer symbol]] for integer &lt;math&gt;r&lt;/math&gt;
:&lt;math&gt;f(k|\alpha,\beta,r)=\frac{r^{(k)}\alpha^{(r)}\beta^{(k)}}{k!(\alpha+\beta)^{(r)}(r+\alpha+\beta)^{(k)}}&lt;/math&gt;

==Properties==
The beta negative binomial distribution contains the beta geometric distribution as a special case when &lt;math&gt;r=1&lt;/math&gt;. It can therefore approximate the [[geometric distribution]] arbitrarily well. It also approximates the negative binomial distribution arbitrary well for large &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt;. It can therefore approximate the [[Poisson distribution]] arbitrarily well for large &lt;math&gt;\alpha&lt;/math&gt;, &lt;math&gt;\beta&lt;/math&gt; and &lt;math&gt;r&lt;/math&gt;.

By [[Stirling's approximation]] to the beta function, it can be easily shown that
:&lt;math&gt;f(k|\alpha,\beta,r) \sim \frac{\Gamma(\alpha+r)}{\Gamma(r)\Beta(\alpha,\beta)}\frac{k^{r-1}}{(\beta+k)^{r+\alpha}}&lt;/math&gt;
which implies that the beta negative binomial distribution is [[heavy tail distribution|heavy tailed]].

==Notes==
{{reflist}}

==References==
*Jonhnson, N.L.; Kotz, S.; Kemp, A.W. (1993) ''Univariate Discrete Distributions'', 2nd edition, Wiley {{ISBN|0-471-54897-9}}   (Section 6.2.3)
*Kemp, C.D.; Kemp, A.W. (1956) "Generalized hypergeometric distributions'', ''[[Journal of the Royal Statistical Society]]'', Series B, 18, 202&amp;ndash;211 
*Wang, Zhaoliang (2011) "One mixed negative binomial distribution with application", ''Journal of Statistical Planning and Inference'', 141 (3), 1153-1160 {{DOI|10.1016/j.jspi.2010.09.020}}

==External links==
* Interactive graphic: [http://www.math.wm.edu/~leemis/chart/UDR/UDR.html Univariate Distribution Relationships]

{{ProbDistributions|discrete-infinite}}

[[Category:Discrete distributions]]
[[Category:Compound probability distributions]]
[[Category:Factorial and binomial topics]]</text>
      <sha1>03c3775rx9f7qu6gh9gsrerhf9w3xuu</sha1>
    </revision>
  </page>
  <page>
    <title>Bioinformatics Open Source Conference</title>
    <ns>0</ns>
    <id>43350772</id>
    <revision>
      <id>870957182</id>
      <parentid>796216287</parentid>
      <timestamp>2018-11-28T01:20:49Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: issue. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Bioinformatics]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3798">{{Use mdy dates|date=August 2017}}
{{Infobox recurring event
| name         = Bioinformatics Open Source Conference
| native_name  =
| logo         = BOSC_pear_logo.png
| logo_caption = BOSC Logo
| image        = 
| imagesize    =
| caption      = 
| date         =
| begins       = &lt;!--2013 date {{start date|2013|07|21}} --&gt;
| ends         = &lt;!--2013 date {{end date|2013|07|23}} --&gt;
| prev         = BOSC 2016
| next         = BOSC 2017
| frequency    = Annually
| location     = [[Orlando]], United States (2016)
| years_active = {{age|2000|08|17}}
| first        = 
| last         =
| participants = 
| attendance   = ~100&lt;ref name=bosc-2013-report /&gt;
| genre        =
| budget       =
| patron       =
| organised    = &lt;!--"organized=" also works--&gt; Peter Cock, Nomi L. Harris (2016 chairs)&lt;ref name=bosc-2015&gt;{{cite web|title=BOSC 2015 – Open Bioinformatics Foundation|url=http://www.open-bio.org/wiki/BOSC_2015|website=www.open-bio.org|accessdate=February 5, 2015}}&lt;/ref&gt;
| people       =
| member       = [[Open Bioinformatics Foundation]]
| website      = 
| footnotes    =
}}
The '''Bioinformatics Open Source Conference''' ('''BOSC''') is an [[academic conference]] on [[open-source programming]] in [[bioinformatics]] organised by the [[Open Bioinformatics Foundation]]. The conference has been held annually since 2000 and is run as a two-day satellite meeting preceding the [[Intelligent Systems for Molecular Biology]] (ISMB) conference.

== Program ==
The conference is held as a single track consisting of presentations, [[poster session]]s and two [[keynote|keynote talks]] by people of influence in open-source bioinformatics.&lt;ref name=bosc-2013-report&gt;{{cite journal|last1=Harris|first1=N. L.|last2=Cock|first2=P.|last3=Chapman|first3=B.|last4=Goecks|first4=J.|last5=Hotz|first5=H.-R.|last6=Lapp|first6=H.|title=The Bioinformatics Open Source Conference (BOSC) 2013|journal=Bioinformatics|date=July 14, 2014|pmid=25024288|doi=10.1093/bioinformatics/btu413|volume=31|issue=2|pages=299–300|pmc=4287938}}&lt;/ref&gt;

Since 2010, an informal two-day [[Codefest]] has been held directly preceding the conference.&lt;ref name=codefest&gt;{{cite web|title=Codefest - Open Bioinformatics Foundation|url=http://www.open-bio.org/wiki/Codefest|website=www.open-bio.org|accessdate=July 20, 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Möller|first1=Steffen|last2=Afgan|first2=Enis|last3=Banck|first3=Michael|last4=Cock|first4=Peter J. A.|last5=Kalas|first5=Matus|last6=Kajan|first6=Laszlo|last7=Prins|first7=Pjotr|last8=Quinn|first8=Jacqueline|last9=Sallou|first9=Olivier|last10=Strozzi|first10=Francesco|last11=Seemann|first11=Torsten|last12=Tille|first12=Andreas|last13=Valls Guimera|first13=Roman|last14=Katayama|first14=Toshiaki|last15=Chapman|first15=Brad|title=Sprints, Hackathons and Codefests as community gluons in computational biology|journal=EMBnet.journal|date=October 14, 2013|volume=19|issue=B|pages=40|doi=10.14806/ej.19.B.726}}&lt;/ref&gt;

== History ==
[[National Institutes of Health|NIH]] Associate Director for Data Science [[Philip Bourne]] and [[C. Titus Brown]] gave keynote talks at BOSC 2014.&lt;ref name=bosc-2014-schedule&gt;{{cite web|title=BOSC 2014 Schedule - Open Bioinformatics Foundations|url=http://www.open-bio.org/wiki/BOSC_2014_Schedule|website=www.open-bio.org|accessdate=July 20, 2014}}&lt;/ref&gt;

BOSC 2016 was organized in [[Orlando, Florida]] from July 8–9 before the main ISMB conference.&lt;ref&gt;{{Cite web|url=https://www.open-bio.org/wiki/BOSC_2016|title=BOSC 2016 – Open Bioinformatics Foundation|last=|first=|date=|website=|publisher=Open Bio|access-date=}}&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Bioinformatics Open Source Conference}}
[[Category:Computational science]]
[[Category:Bioinformatics]]
[[Category:Biology conferences]]


{{bioinformatics-stub}}</text>
      <sha1>rb1zpm6z1198mpgrr0b8ob93txul1la</sha1>
    </revision>
  </page>
  <page>
    <title>Björn Sandstede</title>
    <ns>0</ns>
    <id>46757894</id>
    <revision>
      <id>857347112</id>
      <parentid>712434499</parentid>
      <timestamp>2018-08-31T03:47:34Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1635">'''Björn Sandstede''' is a professor in the Division of Applied Mathematics at [[Brown University]].&lt;ref&gt;[https://www.brown.edu/academics/applied-mathematics/people/faculty Faculty listing], Division of Applied Mathematics, Brown University, retrieved 2015-05-21.&lt;/ref&gt; Sandstede earned his Ph.D. in 1993 from the [[University of Stuttgart]], under the supervision of [[Bernold Fiedler]].&lt;ref&gt;{{mathgenealogy|id=27550}}&lt;/ref&gt; In 2001 he was awarded the [[J.D. Crawford Prize]] of the [[Society for Industrial and Applied Mathematics]] for outstanding research in [[nonlinear science]].&lt;ref name=SIAM&gt;{{cite web|url=https://www.siam.org/prizes/sponsored/crawford.php|title=J.D. Crawford Prize|publisher=[[Society for Industrial and Applied Mathematics|SIAM]]|accessdate=20 May 2015}}&lt;/ref&gt; In 2014 Sandstede was awarded the [[Jack K. Hale Award]] for his contributions to partial differential equations and the study of spiral waves in reaction diffusion systems.&lt;ref name=hale&gt;[http://www.journals.elsevier.com/journal-of-differential-equations/news/inaugural-winner-of-elsevier-jack-k-hale-award/ Inaugural winner of Elsevier Jack K. Hale Award]&lt;/ref&gt;

== References==
{{reflist}}

==External links==
*[http://www.dam.brown.edu/people/sandsted/ Home page]
*[https://scholar.google.com/citations?user=hgUNujkAAAAJ&amp;hl=en&amp;oi=ao Google scholar profile]


{{authority control}}

{{DEFAULTSORT:Sandstede, Bjoern}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:German mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Brown University faculty]]


{{mathematician-stub}}</text>
      <sha1>n2unec2n6ueqoon1916h8nz1wz8zh21</sha1>
    </revision>
  </page>
  <page>
    <title>Chaos game</title>
    <ns>0</ns>
    <id>2572603</id>
    <revision>
      <id>871233432</id>
      <parentid>871233346</parentid>
      <timestamp>2018-11-29T19:45:39Z</timestamp>
      <contributor>
        <username>Rajpeaks</username>
        <id>35264701</id>
      </contributor>
      <minor/>
      <comment>/* Restricted chaos game */ Minor grammatical correction</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7671">[[File:Sierpinski chaos animated.gif|thumb|right|200px|Animated creation of a [[Sierpinski triangle]] using a chaos game method]]
[[File:Chaosgame.gif|thumb|right|200px|Animation of chaos game method]]
[[File:Sierpinski Chaos.gif|thumb|right|200px|The way the "chaos game" works is illustrated well when every path is accounted for.]]

In [[mathematics]], the term '''chaos game''' originally referred to a method of creating a [[fractal]], using a [[polygon]] and an initial point selected at random inside it.&lt;ref&gt;{{MathWorld| urlname=ChaosGame |title=Chaos Game}}&lt;/ref&gt;&lt;ref&gt;{{cite book
  | last = Barnsley
  | first = Michael
  | title = Fractals Everywhere
  | publisher = [[Morgan Kaufmann]] 
  | year = 1993
  | isbn = 978-0-12-079061-6 }}&lt;/ref&gt; The fractal is created by iteratively creating a sequence of points, starting with the initial random point, in which each point in the sequence is a given [[fraction (mathematics)|fraction]] of the distance between the previous point and one of the vertices of the polygon; the vertex is chosen at random in each iteration. Repeating this iterative process a large number of times, selecting the vertex at random on each iteration, and throwing out the first few points in the sequence, will often (but not always) produce a fractal shape. Using a regular triangle and the factor 1/2 will result in the [[Sierpinski triangle]], while creating the proper arrangement with four points and a factor 1/2 will create a display of a "Sierpinski Tetrahedron", the three-dimensional analogue of the Sierpinski triangle. As the number of points is increased to a number N, the arrangement forms a corresponding (N-1)-dimensional Sierpinski [[Simplex]]. An interactive version of the Chaos Game can be found [https://scratch.mit.edu/projects/170702288/#player here.]

The term has been generalized to refer to a method of generating the [[attractor]], or the [[Fixed point (mathematics)|fixed point]], of any [[iterated function system]] (IFS). Starting with any point x&lt;sub&gt;0&lt;/sub&gt;, successive iterations are formed as x&lt;sub&gt;k+1&lt;/sub&gt; = f&lt;sub&gt;r&lt;/sub&gt;(x&lt;sub&gt;k&lt;/sub&gt;), where f&lt;sub&gt;r&lt;/sub&gt; is a member of the given IFS randomly selected for each iteration. The iterations converge to the fixed point of the IFS. Whenever x&lt;sub&gt;0&lt;/sub&gt; belongs to the attractor of the IFS, all iterations x&lt;sub&gt;k&lt;/sub&gt; stay inside the attractor and, with probability 1, form a [[dense set]] in the latter.

The "chaos game" method plots points in random order all over the attractor. This is in contrast to other methods of drawing fractals, which test each pixel on the screen to see whether it belongs to the fractal. The general shape of a fractal can be plotted quickly with the "chaos game" method, but it may be difficult to plot some areas of the fractal in detail.

The "chaos game" method is mentioned in [[Tom Stoppard]]'s 1993 play [[Arcadia (play)|Arcadia]].&lt;ref&gt;{{Cite web |url=http://math.bu.edu/DYSYS/arcadia/sect2.html |title=Chaos, Fractals, and Arcadia |last=Devaney |first=Robert L. |authorlink=Robert L. Devaney |publisher=Department of Mathematics, Boston University}}&lt;/ref&gt;

With the aid of the "chaos game" a new fractal can be made and while making the new fractal some parameters can be obtained. These parameters are useful for applications of fractal theory such as classification and identification.&lt;ref&gt;{{Cite journal |last=Jampour |first=Mahdi |last2=Yaghoobi |first2=Mahdi |last3=Ashourzadeh |first3=Maryam |last4=Soleimani |first4=Adel |date=1 September 2010 |title=A new fast technique for fingerprint identification with fractal and chaos game theory |url=https://www.researchgate.net/publication/243541547_A_new_fast_technique_for_fingerprint_identification_with_fractal_and_chaos_game_theory |journal=[[Fractals (journal)|Fractals]] |language=en |volume=18 |issue=3 |pages=293–300 |doi=10.1142/s0218348x10005020 |issn=0218-348X |via=[[ResearchGate]]}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last=Jampour |first=Mahdi |last2=Javidi |first2=Mohammad M. |last3=Soleymani |first3=Adel |last4=Ashourzadeh |first4=Maryam |last5=Yaghoobi |first5=Mahdi |date=2010 |title=A New Technique in saving Fingerprint with low volume by using Chaos Game and Fractal Theory |journal=[[International Journal of Interactive Multimedia and Artificial Intelligence]] |language=en |volume=1 |issue=3 |pages=27 |doi=10.9781/ijimai.2010.135 |issn=1989-1660}}&lt;/ref&gt; The new fractal is self-similar to the original in some important features such as fractal dimension.

If in the "chaos game" you start at each vertex and go through all possible paths that the game can take, you will get the same image as with only taking one random path. However, taking more than one path is rarely done since the overhead for keeping track of every path makes it far slower to calculate. This method does have the advantages of illustrating how the fractal is formed more clearly than the standard method as well as being deterministic.

==Restricted chaos game==

[[File:V4 unrestrict.gif|thumb|right|200px|A point inside a square repeatedly jumps half of the distance towards a randomly chosen vertex. No fractal appears.]]

If the chaos game is run with a square, no fractal appears and the interior of the square fills evenly with points. However, if restrictions are placed on the choice of vertices, fractals will appear in the square. For example, if the current vertex cannot be chosen in the next iteration, this fractal appears:


[[File:V4 ban1.gif|A point inside a square repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be the same as the previously chosen vertex.|center|300px]]


If the current vertex cannot be one place away (anti-clockwise) from the previously chosen vertex, this fractal appears:


[[File:V4 ban1 inc1.gif|A point inside a square repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be 1 place away (anti-clockwise) from the previously chosen vertex.|center|300px]]


If the point is prevented from landing on a particular region of the square, the shape of that region will be reproduced as a fractal in other and apparently unrestricted parts of the square. Here, for example, is the fractal produced when the point cannot jump so as to land on a red [[Om]] symbol at the center of the square:


[[File:Hindu symbol fractal.gif|A fractal created by a point jumping towards a randomly chosen vertex of a square but prevented from landing on an Om symbol at the square's center|center|300px]]


{{Gallery
|title=Other restrictions create further fractals:
|align=center

|File:V4 ban1 inc2.gif|A point inside a square repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be 2 places away from the previously chosen vertex.

|File:Chaos_Game_square-EH-1.png|A point inside a square repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be 1 or 3 places, respectively away from the two previously chosen vertices.

|File:Chaos_Game_pentagon-EH-1.png|A point inside a pentagon repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be the same as the previously chosen vertex.

|File:Chaos_Game_pentagon-EH-2.png|A point inside a pentagon repeatedly jumps half of the distance towards a randomly chosen vertex, but the currently chosen vertex cannot be 1 or 4 places, respectively away from the two previously chosen vertices.
}}

==See also==
*[[Chaos theory]]

==References==
{{reflist}}

[[Category:Fractals]]
[[Category:Chaos theory]]</text>
      <sha1>2ayvtnngpbran86wu3rr4nxrauu8wy2</sha1>
    </revision>
  </page>
  <page>
    <title>Cheyette model</title>
    <ns>0</ns>
    <id>43200575</id>
    <revision>
      <id>869199682</id>
      <parentid>859970691</parentid>
      <timestamp>2018-11-17T01:28:11Z</timestamp>
      <contributor>
        <username>StraussInTheHouse</username>
        <id>32545823</id>
      </contributor>
      <minor/>
      <comment>/* top */unreferenced to refimprove</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1017">{{multiple issues|
{{refimprove|date=July 2014}}
{{Underlinked|date=September 2014}}
}}

'''Cheyette Model''' is a quasi-Gaussian quadratic volatility model of [[interest rate]]s which is aiming to overcome certain limitations of the [[Heath-Jarrow-Morton framework]].

==External links and references==
*{{cite book | title = Interest Rate Modeling in Three Volumes | author = Leif B.G. Andersen, Vladimir V. Piterbarg | year = 2010 | edition = 1st ed. 2010 | url = http://www.andersen-piterbarg-book.com | isbn = 978-0-9844221-0-4 | publisher = Atlantic Financial Press | chapter = Chapter 13 | access-date = 2018-09-17 | archive-url = https://web.archive.org/web/20110208161936/http://andersen-piterbarg-book.com/ | archive-date = 2011-02-08 | dead-url = yes | df =  }}
*[http://www.risk.net/risk-magazine/technical-paper/2277261/a-quadratic-volatility-cheyette-model Cheyette Model on Risk.net]

[[Category:Financial models]]
[[Category:Mathematical finance]]
[[Category:Fixed income analysis]]


{{finance-stub}}</text>
      <sha1>93rd0coqa8ljnh1v146my6sy2rygt4f</sha1>
    </revision>
  </page>
  <page>
    <title>Circuit quantum electrodynamics</title>
    <ns>0</ns>
    <id>31261684</id>
    <revision>
      <id>858008264</id>
      <parentid>841547181</parentid>
      <timestamp>2018-09-04T13:33:51Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9717">{{quantum mechanics}}
'''Circuit quantum electrodynamics''' ('''circuit QED''') provides a means of studying the fundamental interaction between light and matter. As in the field of [[cavity quantum electrodynamics]], a single photon within a single mode [[optical cavity|cavity]] coherently couples to a quantum object (atom). In contrast to cavity QED, the photon is stored in a one-dimensional on-chip resonator and the quantum object is no natural atom but an artificial one. These [[artificial atom]]s usually are [[Mesoscopic physics|mesoscopic]] devices which exhibit an atom-like energy spectrum.
The field of circuit QED is a prominent example for [[quantum information science|quantum information processing]] and a promising candidate for future [[quantum computer|quantum computation]].&lt;ref&gt;{{cite journal|author=Alexandre Blais|year=2004|title=Cavity quantum electrodynamics for superconducting electrical circuits: An architecture for quantum computing|journal=[[Physical Review A|Phys. Rev. A]]|volume=69|pages=062320|publisher=[[American Physical Society|APS]]|doi=10.1103/PhysRevA.69.062320|arxiv = cond-mat/0402216 |bibcode = 2004PhRvA..69f2320B |display-authors=etal}}&lt;/ref&gt;

== Resonator ==
The resonant devices used for circuit QED are [[superconductivity|superconducting]] [[coplanar waveguide]] [[microwave]] resonators,&lt;ref&gt;{{cite journal|author=Luigi Frunzio |year=2005|title=Fabrication and Characterization of Superconducting Circuit QED Devices for Quantum Computation |journal=IEEE Transactions on Applied Superconductivity|volume=15|pages=860|doi=10.1109/TASC.2005.850084|arxiv = cond-mat/0411708 |display-authors=etal|bibcode=2005ITAS...15..860F}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=M. Göppl|year=2008|title=Coplanar waveguide resonators for circuit quantum electrodynamics|journal=[[Journal of Applied Physics|J. Appl. Phys.]]|volume=104|pages=113904|publisher=[[American Institute of Physics|AIP]]|doi=10.1063/1.3010859|arxiv = 0807.4094 |bibcode = 2008JAP...104k3904G |display-authors=etal}}&lt;/ref&gt; which are two-dimensional microwave analogues of the [[Fabry–Pérot interferometer]]. Coplanar waveguides consist of a signal carrying centerline flanked by two [[ground (electricity)|grounded]] planes. This planar structure is put on a dielectric substrate by a photolithographic process. [[superconductivity|Superconducting]] materials used are mostly [[aluminium]] (Al) or [[niobium]] (Nb). Dielectrics typically used as substrates are either surface oxidized [[silicon]] (Si) or [[sapphire]] (Al&lt;sub&gt;2&lt;/sub&gt;O&lt;sub&gt;3&lt;/sub&gt;).
The [[characteristic impedance|line impedance]] is given by the geometric properties, which are chosen to match the 50 &lt;math&gt;\Omega&lt;/math&gt; of the peripheric microwave equipment to avoid partial reflection of the signal.&lt;ref&gt;{{cite book|last=Simons |first=Rainee N. |title=Coplanar Waveguide Circuits, Components, and Systems |publisher=John Wiley &amp; Sons Inc. |year=2001 |isbn=0-471-16121-7}}&lt;/ref&gt;
The electric field is basically confined between the center conductor and the ground planes resulting in a very small mode volume &lt;math&gt;V_m&lt;/math&gt; which gives rise to very high electric fields per photon &lt;math&gt;E_0&lt;/math&gt; (compared to three-dimensional cavities).

&lt;math&gt;E_0=\sqrt{\frac{\hbar\omega_r}{2 \varepsilon_0 V_m}}&lt;/math&gt;

One can distinguish between two different types of resonators: &lt;math&gt;\lambda/2&lt;/math&gt; and &lt;math&gt;\lambda/4&lt;/math&gt; resonators. Half-[[wavelength]] resonators are made by breaking the center conductor at two spots with the distance &lt;math&gt;\ell&lt;/math&gt;. The resulting piece of center conductor is in this way [[capacitor|capacitively]] coupled to the input and output and represents a resonator with &lt;math&gt;E&lt;/math&gt;-field [[antinode]]s at its ends. Quarter-wavelength resonators are short pieces of a coplanar line, which are shorted to ground on one end and capacitively coupled to a [[feed line]] on the other. The resonance frequencies are given by

&lt;math&gt;\lambda/2: \quad \nu_n=\frac{c}{\sqrt{\varepsilon_{\text{eff}}}}\frac{n}{2 \ell} \quad (n=1,2,3,\ldots) \qquad \lambda/4:\quad  \nu_n=\frac{c}{\sqrt{\varepsilon_{\text{eff}}}}\frac{2n+1}{4 \ell} \quad (n=0,1,2,\ldots)&lt;/math&gt;

with &lt;math&gt;\varepsilon_{\text{eff}}&lt;/math&gt; being the effective dielectric [[permittivity]] of the device.

== Artificial atoms, Qubits ==
The first realized artificial atom in circuit QED was the so-called Cooper-pair box.&lt;ref&gt;{{cite journal|author=[[A. Wallraff]]|year=2004|title=Strong coupling of a single photon to a superconducting qubit using circuit quantum electrodynamics|journal=[[Nature (journal)|Nature]]|volume=431|pages=162–167|publisher=[[Nature Publishing Group]]|doi=10.1038/nature02851|issue=7005|pmid=15356625|arxiv = cond-mat/0407325 |bibcode = 2004Natur.431..162W |display-authors=etal}}&lt;/ref&gt; In this device, a reservoir of [[cooper pair|Cooper-pairs]] is coupled via [[josephson effect|Josephson junctions]] to a gated superconducting island. The state of the Cooper-pair box ([[qubit]]) is given by the number of Cooper pairs on the island (&lt;math&gt;N&lt;/math&gt; Cooper pairs for the ground state &lt;math&gt;\mid g \rangle&lt;/math&gt; and &lt;math&gt;N+1&lt;/math&gt; for the excited state &lt;math&gt;\mid e \rangle&lt;/math&gt;). By controlling the [[electric potential energy|Coulomb energy]] ([[biasing|bias voltage]]) and the [[Josephson energy]] (flux bias) the transition frequency &lt;math&gt;\omega_a&lt;/math&gt; is tuned. Due to the nonlinearity of the Josephson junctions the Cooper-pair box shows an atom like energy spectrum.
Other more recent examples for qubits used in circuit QED are so called [[transmon]] qubits &lt;ref&gt;{{cite journal|author=Jens Koch|year=2007|title=Charge insensitive qubit design derived from the Cooper pair box|journal=[[Physical Review A|Phys. Rev. A]]|volume=76|pages=042319|publisher=[[American Physical Society|APS]]|doi=10.1103/PhysRevA.76.042319|bibcode = 2007PhRvA..76d2319K |display-authors=etal|arxiv=cond-mat/0703002}}&lt;/ref&gt; (more charge noise insensitive compared to the Cooper-pair box) and flux qubits (the state is given by the direction of a supercurrent in a superconducting loop intersected by Josephson junctions).
All of these devices feature very large dipole moments &lt;math&gt;d&lt;/math&gt; (up to 10&lt;sup&gt;3&lt;/sup&gt; that of large &lt;math&gt;n&lt;/math&gt; [[Rydberg atom]]s), which qualifies them as extremely suitable coupling counterparts for the light field in circuit QED.

== Theory ==
The full quantum description of matter-light interaction is given by the [[Jaynes-Cummings model]].&lt;ref&gt;{{cite journal|author=[[E. T. Jaynes]] and [[F. W. Cummings]]|year=1963|title=Comparison of Quantum and Semiclassical Radiation Theories with Application to the Beam Maser|journal=[[Proceedings of the IEEE]]|volume=51|pages=89–109|publisher=[[Institute of Electrical and Electronics Engineers|IEEE]]|doi=10.1109/proc.1963.1664}}&lt;/ref&gt; The three terms of the Jaynes-Cummings model can be ascribed to a cavity term, which is mimicked by a harmonic oscillator, an atomic term and an interaction term.

&lt;math&gt; \mathcal{H}_{\text{JC}}=\underbrace{\hbar \omega_r \left(a^\dagger a+\frac 12\right)}_{\text{cavity term}}+\underbrace{\frac 12 \hbar \omega_a \sigma_z}_{\text{atomic term}}+\underbrace{\hbar g \left(\sigma_+ a+a^\dagger \sigma_-\right)}_{\text{interaction term}}&lt;/math&gt;

In this formulation &lt;math&gt;\omega_r&lt;/math&gt; is the resonance frequency of the cavity and &lt;math&gt;a^\dagger&lt;/math&gt; and &lt;math&gt;a&lt;/math&gt; are photon creation and annihilation operators, respectively. The atomic term is given by the [[Hamiltonian (quantum mechanics)|Hamiltonian]] of a spin 1/2 system with &lt;math&gt;\omega_a&lt;/math&gt; being the transition frequency and &lt;math&gt;\sigma_z&lt;/math&gt; the [[pauli matrices|Pauli matrix]]. The operators &lt;math&gt;\sigma_\pm&lt;/math&gt; are raising and lowering operators ([[ladder operator]]s) for the atomic states.
For the case of zero detuning (&lt;math&gt;\omega_r=\omega_a&lt;/math&gt;) the interaction lifts the degeneracy of the photon number state &lt;math&gt;\mid n \rangle&lt;/math&gt; and the atomic states &lt;math&gt;\mid g \rangle&lt;/math&gt; and &lt;math&gt;\mid e \rangle&lt;/math&gt; and pairs of dressed states are formed. These new states are [[quantum superposition|superpositions]] of cavity and atom states

&lt;math&gt;\mid n,\pm \rangle=\frac 1{\sqrt 2}\left(\mid g\rangle \mid n \rangle\pm \mid e\rangle \mid n-1\rangle\right)&lt;/math&gt;

and are energetically split by &lt;math&gt;2g\sqrt n&lt;/math&gt;.
If the detuning is significantly larger than the combined cavity and atomic [[spectral linewidth|linewidth]] the cavity states are merely shifted by &lt;math&gt;\pm g^2/\Delta&lt;/math&gt; (with the detuning &lt;math&gt;\Delta=\omega_a-\omega_r&lt;/math&gt;) depending on the atomic state. This provides the possibility to read out the atomic (qubit) state by measuring the transition frequency.{{Citation needed|reason=This needs work. Needs to name the dispersive regime and clarify the readout process.|date=March 2018}}

The coupling is given by &lt;math&gt;g=E \cdot d&lt;/math&gt; (for electric dipolar coupling). If the coupling is much larger than the cavity loss rate &lt;math&gt;\kappa=\frac{\omega_r}Q&lt;/math&gt; (quality factor &lt;math&gt;Q&lt;/math&gt;; the higher &lt;math&gt;Q&lt;/math&gt;, the longer the photon remains inside the resonator) as well as the decoherence rate &lt;math&gt;\gamma&lt;/math&gt; (rate at which the qubit relaxes into modes other than the resonator mode) the strong coupling regime is reached. Due to the high fields and low losses of the coplanar resonators together with the large dipole moments and long decoherence times of the qubits, the strong coupling regime can easily be reached in the field of circuit QED. Combination of the Jaynes–Cummings model and the coupled cavities leads to the [[Jaynes-Cummings-Hubbard model]].

== References ==
{{reflist}}

{{Quantum computing}}

[[Category:Quantum information science]]</text>
      <sha1>imnyf648hfdia8jir3p060y6us86mpm</sha1>
    </revision>
  </page>
  <page>
    <title>Computability</title>
    <ns>0</ns>
    <id>442136</id>
    <revision>
      <id>826441713</id>
      <parentid>821762313</parentid>
      <timestamp>2018-02-19T03:20:17Z</timestamp>
      <contributor>
        <ip>211.211.37.77</ip>
      </contributor>
      <comment>/* Formal models of computation */Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21703">{{redirect|Computable|other uses|Computable function|and|Computability theory|and|Computation|and|Theory of computation|and|Computable number}}
'''Computability''' is the ability to solve a problem in an effective manner. It is a key topic of the field of [[computability theory]] within [[mathematical logic]] and the [[theory of computation]] within [[computer science]]. The computability of a problem is closely linked to the existence of an [[algorithm]] to solve the problem.

The most widely studied models of computability are the [[Turing-computable function|Turing-computable]] and [[μ-recursive function]]s, and the [[lambda calculus]], all of which have computationally equivalent power. Other forms of computability are studied as well: computability notions weaker than Turing machines are studied in [[automata theory]], while computability notions stronger than Turing machines are studied in the field of [[hypercomputation]].

== Problems ==

A central idea in computability is that of a ('''computational''') '''[[computational problem|problem]]''', which is a task whose computability can be explored.

There are two key types of problems:
* A [[decision problem]] fixes a set ''S'', which may be a set of strings, natural numbers, or other objects taken from some larger set ''U''. A particular '''instance''' of the problem is to decide, given an element ''u'' of ''U'', whether ''u'' is in ''S''. For example, let ''U'' be the set of natural numbers and ''S'' the set of prime numbers. The corresponding decision problem corresponds to [[primality testing]].
* A [[function problem]] consists of a function ''f'' from a set ''U'' to a set ''V''. An instance of the problem is to compute, given an element ''u'' in ''U'', the corresponding element ''f''(''u'') in ''V''.  For example, ''U'' and ''V'' may be the set of all finite binary strings, and ''f'' may take a string and return the string obtained by reversing the digits of the input (so f(0101) = 1010).
Other types of problems include [[search problem]]s and [[optimization problem]]s.

One goal of computability theory is to determine which problems, or classes of problems, can be solved in each model of computation.

== Formal models of computation ==&lt;!-- This section is linked from [[Abstract machine]] --&gt;
{{main|Model of computation}}
A [[model of computation]] is a formal description of a particular type of computational process. The description often takes the form of an [[abstract machine]] that is meant to perform the task at hand. General models of computation equivalent to a [[Turing machine]] (see [[Church–Turing thesis]]) include:

;[[Lambda calculus]]: A computation consists of an initial lambda expression (or two if you want to separate the function and its input) plus a finite sequence of lambda terms, each deduced from the preceding term by one application of [[beta reduction]].
;[[Combinatory logic]]
:A concept which has many similarities to &lt;math&gt;\lambda&lt;/math&gt;-calculus, but also important differences exist (e.g. fixed point combinator '''Y''' has normal form in combinatory logic but not in &lt;math&gt;\lambda&lt;/math&gt;-calculus). Combinatory logic was developed with great ambitions: understanding the nature of paradoxes, making foundations of mathematics more economic (conceptually), eliminating the notion of variables (thus clarifying their role in mathematics).
;[[μ-recursive function]]s: A computation consists of a μ-recursive function, i.e. its defining sequence, any input value(s) and a sequence of recursive functions appearing in the defining sequence with inputs and outputs. Thus, if in the defining sequence of a recursive function {{math|''f''(''x'')}} the functions {{math|''g''(''x'')}} and {{math|''h''(''x'',''y'')}} appear, then terms of the form {{math|''g''(5) {{=}} 7}} or {{math|''h''(3,2) {{=}} 10}} might appear.  Each entry in this sequence needs to be an application of a basic function or follow from the entries above by using [[Function composition (computer science)|composition]], [[primitive recursion]] or [[Mu-recursive function|μ-recursion]].  For instance if {{math|''f''(''x'') {{=}} ''h''(''x'',''g''(''x''))}}, then for {{math|''f''(5) {{=}} 3}} to appear, terms like {{math|''g''(5) {{=}} 6}} and {{math|''h''(3,6) {{=}} 3}} must occur above. The computation terminates only if the final term gives the value of the recursive function applied to the inputs.
;[[String rewriting system]]s: Includes [[Markov algorithm]]s, that use [[grammar]]-like rules to operate on [[string (computer science)|strings]] of symbols; also [[Post canonical system]].
;[[Register machine]]
:A theoretically interesting idealization of a computer. There are several variants. In most of them, each register can hold a natural number (of unlimited size), and the instructions are simple (and few in number), e.g. only decrementation (combined with conditional jump) and incrementation exist (and halting). The lack of the infinite (or dynamically growing) external store (seen at Turing machines) can be understood by replacing its role with [[Gödel numbering]] techniques: the fact that each register holds a natural number allows the possibility of representing a complicated thing (e.g. a sequence, or a matrix etc.) by an appropriate huge natural number — unambiguity of both representation and interpretation can be established by [[number theory|number theoretical]] foundations of these techniques.
;[[Turing machine]]: Also similar to the finite state machine, except that the input is provided on an execution "tape", which the Turing machine can read from, write to, or move back and forth past its read/write "head". The tape is allowed to grow to arbitrary size. The Turing machine is capable of performing complex calculations which can have arbitrary duration. This model is perhaps the most important model of computation in computer science, as it simulates computation in the absence of predefined resource limits.
;[[Multitape Turing machine]]: Here, there may be more than one tape; moreover there may be multiple heads per tape.  Surprisingly, any computation that can be performed by this sort of machine can also be performed by an ordinary Turing machine, although the latter may be slower or require a larger total region of its tape.
;[[P′′]]
:Like Turing machines, P′′ uses an infinite tape of symbols (without random access), and a rather minimalistic set of instructions. But these instructions are very different, thus, unlike Turing machines, P′′ does not need to maintain a distinct state, because all “memory-like” functionality can be provided only by the tape. Instead of rewriting the current symbol, it can perform a [[modular arithmetic]] incrementation on it. P′′ has also a pair of instructions for a cycle, inspecting the blank symbol. Despite its minimalistic nature, it has become the parental formal language of an implemented and (for entertainment) used programming language called [[Brainfuck]].

In addition to the general computational models, some simpler computational models are useful for special, restricted applications.  [[Regular expression]]s, for example,  specify string patterns in many contexts, from office productivity software to [[programming language]]s. Another formalism mathematically equivalent to regular expressions, [[finite-state machine|Finite automata]] are used in circuit design and in some kinds of problem-solving. [[Context-free grammar]]s  specify programming language syntax.  Non-deterministic [[pushdown automaton|pushdown automata]] are another formalism equivalent to context-free grammars.

Different models of computation have the ability to do different tasks. One way to measure the power of a computational model is to study the class of [[formal language]]s that the model can generate; in such a way is the [[Chomsky hierarchy]] of languages is obtained.

Other restricted models of computation include:
;[[Deterministic finite automaton]] (DFA): Also called a finite-state machine. All real computing devices in existence today can be modeled as a finite-state machine, as all real computers operate on finite resources. Such a machine has a set of states, and a set of state transitions which are affected by the input stream. Certain states are defined to be accepting states. An input stream is fed into the machine one character at a time, and the state transitions for the current state are compared to the input stream, and if there is a matching transition the machine may enter a new state. If at the end of the input stream the machine is in an accepting state, then the whole input stream is accepted.
;[[Nondeterministic finite automaton]] (NFA): Another simple model of computation, although its processing sequence is not uniquely determined. It can be interpreted as taking multiple paths of computation simultaneously through a finite number of states. However, it is possible to prove that any NFA is reducible to an equivalent DFA.
;[[Pushdown automaton]]: Similar to the finite state machine, except that it has available an execution stack, which is allowed to grow to arbitrary size. The state transitions additionally specify whether to add a symbol to the stack, or to remove a symbol from the stack. It is more powerful than a DFA due to its infinite-memory stack, although only the top element of the stack is accessible at any time.

== Power of automata ==
With these computational models in hand, we can determine what their limits are.  That is, what classes of [[Formal language|languages]] can they accept?

=== Power of finite-state machines ===

{{cleanup|section|date=April 2009}}

Computer scientists call any language that can be accepted by a finite-state machine a '''[[regular language]]'''.  Because of the restriction that the number of possible states in a finite state machine is finite, we can see that to find a language that is not regular, we must construct a language that would require an infinite number of states.

An example of such a language is the set of all strings consisting of the letters 'a' and 'b' which contain an equal number of the letter 'a' and 'b'.  To see why this language cannot be correctly recognized by a finite state machine, assume first that such a machine ''M'' exists.  ''M'' must have some number of states ''n''.  Now consider the string ''x'' consisting of &lt;math&gt;(n+1)&lt;/math&gt; 'a's followed by &lt;math&gt;(n+1)&lt;/math&gt; 'b's.

As ''M'' reads in ''x'', there must be some state in the machine that is repeated as it reads in the first series of 'a's, since there are &lt;math&gt;(n+1)&lt;/math&gt; 'a's and only ''n'' states by the [[pigeonhole principle]].  Call this state ''S'', and further let ''d'' be the number of 'a's that our machine read in order to get from the first occurrence of ''S'' to some subsequent occurrence during the 'a' sequence.  We know, then, that at that second occurrence of ''S'', we can add in an additional ''d'' (where &lt;math&gt;d &gt; 0&lt;/math&gt;) 'a's and we will be again at state ''S''.  This means that we know that a string of &lt;math&gt;(n+d+1)&lt;/math&gt; 'a's must end up in the same state as the string of &lt;math&gt;(n+1)&lt;/math&gt; 'a's.  This implies that if our machine accepts ''x'', it must also accept the string of &lt;math&gt;(n+d+1)&lt;/math&gt; 'a's followed by &lt;math&gt;(n+1)&lt;/math&gt; 'b's, which is not in the language of strings containing an equal number of 'a's and 'b's. In other words, ''M'' cannot correctly distinguish between a string of equal number of 'a's and 'b's and a string with &lt;math&gt;(n+d+1)&lt;/math&gt; 'a's and &lt;math&gt;n+1&lt;/math&gt; 'b's.

We know, therefore, that this language cannot be accepted correctly by any finite-state machine, and is thus not a regular language.  A more general form of this result is called the [[Pumping lemma for regular languages]], which can be used to show that broad classes of languages cannot be recognized by a finite state machine.

=== Power of pushdown automata ===
Computer scientists define a language that can be accepted by a [[pushdown automaton]] as a '''[[Context-free language]]''', which can be specified as a '''[[Context-free grammar]]'''.  The language consisting of strings with equal numbers of 'a's and 'b's, which we showed was not a regular language, can be decided by a push-down automaton.  Also, in general, a push-down automaton can behave just like a finite-state machine, so it can decide any language which is regular.  This model of computation is thus strictly more powerful than finite state machines.

However, it turns out there are languages that cannot be decided by push-down automaton either.  The result is similar to that for regular expressions, and won't be detailed here.  There exists a [[Pumping lemma for context-free languages]].  An example of such a language is the set of prime numbers.

=== Power of Turing machines ===
[[Turing machine]]s can decide any context-free language, in addition to languages not decidable by a push-down automaton, such as the language consisting of prime numbers.  It is therefore a strictly more powerful model of computation.

Because Turing machines have the ability to "back up" in their input tape, it is possible for a Turing machine to run for a long time in a way that is not possible with the other computation models previously described.  It is possible to construct a Turing machine that will never finish running (halt) on some inputs.  We say that a Turing machine can decide a language if it eventually will halt on all inputs and give an answer.  A language that can be so decided is called a '''[[recursive language]]'''.  We can further describe Turing machines that will eventually halt and give an answer for any input in a language, but which may run forever for input strings which are not in the language.  Such Turing machines could tell us that a given string is in the language, but we may never be sure based on its behavior that a given string is not in a language, since it may run forever in such a case.  A language which is accepted by such a Turing machine is called a '''[[recursively enumerable language]]'''.

The Turing machine, it turns out, is an exceedingly powerful model of automata.  Attempts to amend the definition of a Turing machine to produce a more powerful machine have surprisingly met with failure.  For example, adding an extra tape to the Turing machine, giving it a two-dimensional (or three- or any-dimensional) infinite surface to work with can all be simulated by a Turing machine with the basic one-dimensional tape.  These models are thus not more powerful.  In fact, a consequence of the [[Church–Turing thesis]] is that there is no reasonable model of computation which can decide languages that cannot be decided by a Turing machine.

The question to ask then is: do there exist languages which are recursively enumerable, but not recursive?  And, furthermore, are there languages which are not even recursively enumerable?

==== The halting problem ====
{{Main|Halting problem}}

The halting problem is one of the most famous problems in computer science, because it has profound implications on the theory of computability and on how we use computers in everyday practice.  The problem can be phrased:

: ''Given a description of a Turing machine and its initial input, determine whether the program, when executed on this input, ever halts (completes). The alternative is that it runs forever without halting.''

Here we are asking not a simple question about a prime number or a palindrome, but we are instead turning the tables and asking a Turing machine to answer a question about another Turing machine.  It can be shown (See main article: [[Halting problem]]) that it is not possible to construct a Turing machine that can answer this question in all cases.

That is, the only general way to know for sure if a given program will halt on a particular input in all cases is simply to run it and see if it halts.  If it does halt, then you know it halts.  If it doesn't halt, however, you may never know if it will eventually halt.  The language consisting of all Turing machine descriptions paired with all possible input streams on which those Turing machines will eventually halt, is not recursive.  The halting problem is therefore called non-computable or '''[[undecidable problem|undecidable]]'''.

An extension of the halting problem is called [[Rice's theorem]], which states that it is undecidable (in general) whether a given language possesses any specific nontrivial property.

==== Beyond recursively enumerable languages ====
The halting problem is easy to solve, however, if we allow that the Turing machine that decides it may run forever when given input which is a representation of a Turing machine that does not itself halt.  The halting language is therefore recursively enumerable.  It is possible to construct languages which are not even recursively enumerable, however.

A simple example of such a language is the complement of the halting language; that is the language consisting of all Turing machines paired with input strings where the Turing machines do ''not'' halt on their input.  To see that this language is not recursively enumerable, imagine that we construct a Turing machine ''M'' which is able to give a definite answer for all such Turing machines, but that it may run forever on any Turing machine that does eventually halt.  We can then construct another Turing machine &lt;math&gt;M'&lt;/math&gt; that simulates the operation of this machine, along with simulating directly the execution of the machine given in the input as well, by interleaving the execution of the two programs.  Since the direct simulation will eventually halt if the program it is simulating halts, and since by assumption the simulation of ''M'' will eventually halt if the input program would never halt, we know that &lt;math&gt;M'&lt;/math&gt; will eventually have one of its parallel versions halt.  &lt;math&gt;M'&lt;/math&gt; is thus a decider for the halting problem.  We have previously shown, however, that the halting problem is undecidable.  We have a contradiction, and we have thus shown that our assumption that ''M'' exists is incorrect.  The complement of the halting language is therefore not recursively enumerable.

== Concurrency-based models ==
A number of computational models based on [[Concurrency (computer science)|concurrency]] have been developed, including the [[parallel random-access machine]] and the [[Petri net]].  These models of concurrent computation still do not implement any mathematical functions that cannot be implemented by Turing machines.

== Stronger models of computation ==
The [[Church–Turing thesis]] conjectures that there is no effective model of computing that can compute more mathematical functions than a Turing machine. Computer scientists have imagined many varieties of '''[[hypercomputer]]s''', models of computation that go beyond Turing computability.

=== Infinite execution ===
{{Main|Zeno machine}}
Imagine a machine where each step of the computation requires half the time of the previous step (and hopefully half the energy of the previous step...). If we normalize to 1/2 time unit the amount of time required for the first step (and to 1/2 energy unit the amount of energy required for the first step...), the execution would require

:&lt;math&gt;1 = \sum_{n=1}^{\infty} \frac{1}{2^n} = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + \cdots&lt;/math&gt;

time unit (and 1 energy unit...) to run. This infinite series converges to 1, which means that this Zeno machine can execute a countably infinite number of steps in 1 time unit (using 1 energy unit...). This machine is capable of deciding the halting problem by directly simulating the execution of the machine in question. By extension, any convergent infinite [must be provably infinite] series would work. Assuming that the infinite series converges to a value ''n'', the Zeno machine would complete a countably infinite execution in ''n'' time units.

=== Oracle machines ===
{{Main|Oracle machine}}
So-called Oracle machines have access to various "oracles" which provide the solution to specific undecidable problems. For example, the Turing machine may have a "halting oracle" which answers immediately whether a given Turing machine will ever halt on a given input. These machines are a central topic of study in [[recursion theory]].

=== Limits of hyper-computation ===
Even these machines, which seemingly represent the limit of automata that we could imagine, run into their own limitations.  While each of them can solve the halting problem for a Turing machine, they cannot solve their own version of the halting problem. For example, an Oracle machine cannot answer the question of whether a given Oracle machine will ever halt.

==See also==
*[[Automata theory]]
*[[Abstract machine]]
*[[List of undecidable problems]]
*[[Computational complexity theory]]
*[[Computability logic]]
*[[Important publications in computability]]

== References ==

* {{cite book|author = [[Michael Sipser]] | year = 1997 | title = Introduction to the Theory of Computation | publisher = PWS Publishing | isbn = 0-534-94728-X}} Part Two: Computability Theory, Chapters 3–6, pp.&amp;nbsp;123–222.
* {{cite book|author = [[Christos Papadimitriou]] | year = 1993 | title = Computational Complexity | publisher = Addison Wesley | edition = 1st | isbn = 0-201-53082-1}} Chapter 3: Computability, pp.&amp;nbsp;57–70.
* {{cite book|author = [[S. Barry Cooper]] | year = 2004 | title = Computability Theory | publisher = Chapman &amp; Hall/CRC | edition = 1st | isbn = 978-1-58488-237-4}}

{{computable knowledge}}

[[Category:Computability theory| ]]
[[Category:Theory of computation| ]]</text>
      <sha1>j9qv5zkwiqe7lclmeoldhuuv0sujmvd</sha1>
    </revision>
  </page>
  <page>
    <title>Critical mathematics pedagogy</title>
    <ns>0</ns>
    <id>52098442</id>
    <revision>
      <id>828264046</id>
      <parentid>801612085</parentid>
      <timestamp>2018-03-01T14:59:04Z</timestamp>
      <contributor>
        <username>Sandstansan</username>
        <id>33203220</id>
      </contributor>
      <minor/>
      <comment>Edited minor grammatical issues in the second introductory paragraph</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20839">{{dablink|cross reference: [[critical pedagogy]], [[Anti-bias curriculum|anti-bias education]], [[Anti-racist mathematics|anti-racist mathematics education]], [[ethnomathematics]], [[mathematics education]], [[critical theory]], [[critical literacy]]}}
{{Orphan|date=April 2017}}

'''Critical mathematics pedagogy''' is an approach to [[mathematics education]] that includes a practical and philosophical commitment to [[Liberty|liberation]].&lt;ref name=":1"&gt;{{Cite journal|last=Tutak|first=Fatma Aslan|last2=Bondy|first2=Elizabeth|last3=Adams|first3=Thomasenia L.|date=2011-01-15|title=Critical pedagogy for critical mathematics education|url=https://dx.doi.org/10.1080/0020739X.2010.510221|journal=International Journal of Mathematical Education in Science and Technology|volume=42|issue=1|pages=65–74|doi=10.1080/0020739X.2010.510221|issn=0020-739X}}&lt;/ref&gt; Approaches that involve critical mathematics pedagogy give special attention to the social, political, cultural and economic contexts of [[oppression]], as they can be understood through mathematics.&lt;ref name=":5"&gt;{{Cite journal|last=Frankenstein|first=Marilyn|date=1983-01-01|title=CRITICAL MATHEMATICS EDUCATION: AN APPLICATION OF PAULO FREIRE'S EPISTEMOLOGY|jstor=42772808|journal=The Journal of Education|volume=165|issue=4|pages=315–339}}&lt;/ref&gt; They also analyze the role that mathematics plays in producing and maintaining potentially oppressive social, political, cultural or economic structures.&lt;ref name=":0"&gt;{{Cite journal|last=Skovsmose|first=Ole|title=Towards a critical mathematics education|url=https://link.springer.com/article/10.1007/BF01284527|journal=Educational Studies in Mathematics|language=en|volume=27|issue=1|pages=35–57|doi=10.1007/BF01284527|issn=0013-1954}}&lt;/ref&gt; Finally, critical mathematics pedagogy demands that critique is connected to action promoting more just and equitable social, political or economic reform.&lt;ref name=":0" /&gt;

Critical mathematics pedagogy builds on [[critical theory]] developed in the [[Post-Marxism|post-Marxist]] [[Frankfurt School]], as well as [[critical pedagogy]] developed out of critical theory by Brazilian educator and educational theorist [[Paulo Freire]]. Definitions of critical mathematics pedagogy and critical mathematics education differ among those who practice it and write about it in their work. The focus of critical mathematics pedagogy shifts between three core tenets, but always includes some attention to all three: (1) analysis of injustice and inequitable relations of power made possible through mathematics, (2) critiques of the ways in which mathematics is used to structure and maintain power, and (3) critiques toward plans of action for change and the use of mathematics to reveal and oppose injustices, as well as imagine proposals for more equitable and just relations.

==Core concepts and foundations==
===Critical theory and critical mathematics===
Those who build their critical mathematics pedagogy with close relations to critical theory, focus on the analysis of mathematics as having "formatting power"&lt;ref name=":0" /&gt; that shapes the way we understand and organize the world. The assumption underlying critical mathematics pedagogy that comes from critical theory is the notion that mathematics is not neutral. According to critical mathematics, neither mathematics itself nor the teaching or learning of mathematics can be value-neutral, or free of interpretation. The critical mathematics group (est. 1990),&lt;ref name=":2"&gt;{{Cite book|title=Teaching mathematics for social justice: Conversations with educators|last=Powell|first=Arthur|publisher=National Council of Teachers of Mathematics|year=2012|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt; one of the first groups of teachers and researchers to convene around the work of critical mathematics, state that mathematics is (1) knowledge constructed by humans, (2) the set of knowledges constructed by all groups of humans, not only the Eurocentric knowledge traditionally included in academic texts and (3) a human enterprise in which understanding results from action in social, cultural, political and economic context.&lt;ref name=":2" /&gt;

Marilyn Frankenstein, the first educator to coin the term critical mathematics pedagogy in the United States in her 1983 article "Critical Mathematics Pedagogy: An Application of Paulo Freire's Epistemology,"&lt;ref name=":5" /&gt; illustrates one way in which mathematics is not neutral using the example of the world map. She explains that in order to represent a three-dimensional object on a two dimensional surface, such as is necessary when mapping the earth, map-makers must make decisions about which types of distortions to allow. For example, the most traditionally accepted and commonly used world map is the [[Mercator projection|Mercator map]] which enlarges the size of Europe and shrinks the size of Africa. This representation can be read to suggest that certain parts of the world are larger, and therefore more important or more powerful than others via the (inaccurate) size comparison presented in the map. The decisions with regards to distortions are the result of political struggles and choices. Yet the map is most often read as a direct and neutral representation of reality.&lt;ref name=":1" /&gt;

Ole Skovsmose's first publication on critical mathematics pedagogy in Europe coincided with Marilyn Frankenstein's in the United States.&lt;ref name=":1" /&gt; It refers to "mathemacy" which would parallel [[critical literacy]] for mathematics.&lt;ref name=":0" /&gt; He explains that "mathematics colonizes part of reality and reorders it."&lt;ref name=":0" /&gt; Therefore, "the goal of mathematics education should be to understand the formatting power of mathematics and to empower people to examine this formatting power so they will not be controlled by it."&lt;ref name=":1" /&gt; According to him, mathemacy would consist of three components (1) mathematical knowing, or the skills developed in traditional mathematics classrooms, (2) technological knowing, or the ability to build models with mathematics and (3) reflective knowing, or competency in evaluating applications of mathematics.&lt;ref name=":0" /&gt; It is specifically the third component that makes this approach to mathematical literacy a critical one.

===Critical pedagogy and critical mathematics pedagogy===

Those who build their critical mathematics pedagogy out of [[critical pedagogy]] focus on [[empowerment]] of the learners as experts and actors for change in their own world. Critical mathematics pedagogy demands that students and teachers use mathematics to understand "relations of power, resource inequalities between different social groups and explicit discrimination"&lt;ref name=":1" /&gt; in order to take action for change. [[Paulo Freire|Paolo Freire]] (1921–1997), Brazilian educator and educational theorist, commonly regarded as the originator of critical pedagogy, suggests that most teaching happens in a "banking" model where teachers hold the information and students are assumed to be passive receptacles for that knowledge.&lt;ref name=":3"&gt;{{Cite book|title=Pedagogy of the Oppressed|last=Freire|first=Paulo|publisher=|year=|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt; Freire's alternative to the banking method is a "problem-posing" model of education. Through this model students and teachers participate together in a mutually humanizing process of dialogue. With the support of their teacher, students examine problems from their own lives and work collaboratively to generate solutions.&lt;ref name=":1" /&gt; One goal of critical pedagogy, according to Freire, is to develop [[critical consciousness]] or [[Conscientização|''conscientização'' (Portuguese)]].&lt;ref name=":3" /&gt; Both teachers and students are expected to challenge their own "well-established ways of thinking that frequently limit their own potential"&lt;ref name=":1" /&gt; and that of others. They are especially expected to challenge those ways of thinking that might reproduce instead of challenge oppressive ways of thinking and being. This commitment to learning and critique for the purpose of action for change is also known as [[praxis (process)|praxis]], the intersection of theory and practice, another core tenet of the critical pedagogy of Paulo Freire.

Marilyn Frankenstien argues that "most current uses of mathematics support hegemonic ideologies."&lt;ref name=":5" /&gt; In particular, she focuses on the mathematical science of statistics which supports the unquestioned acceptance of uncertain conclusions. She argues that the use of the banking model in mathematics education (memorization and procedural focus) produces "math anxiety" in many people, especially and disproportionately those in non-dominant groups (women, people of color, lower income students). This math anxiety then leads people to "not probe the mathematical mystifications"&lt;ref name=":5" /&gt; that drive industrial society.

Eric (Rico) Gutstein applies Freire's notion of the inherent connection between "reading the word and the world"&lt;ref name=":3" /&gt; to mathematical literacy.&lt;ref name=":6"&gt;{{Cite book|title=Reading and Writing the World with Mathematics: Toward a Pedagogy of Social Justice|last=Gutstein|first=Eric (Rico)|publisher=Routledge|year=2006|isbn=|location=New York and London|pages=|quote=|via=}}&lt;/ref&gt; He suggests that teaching mathematics for social justice involves both reading the world with mathematics, or more explicitly, "using mathematics to understand relations of power, resource inequalities between different social groups and explicit discrimination,"&lt;ref name=":1" /&gt; as well as writing the world with mathematics, or developing the tools of social agency in young people for acting in their own worlds. Mathematical literacy according to Gutstein must include both the capacity to "read the mathematical world," necessary for traditional academic and economic success, as well as the capacity to "read the world with mathematics," meaning the use of mathematics to understand and interrogate potentially problematic or unjust structures in their own lives.&lt;ref name=":6" /&gt;

==Critical mathematics pedagogy in action==
Because critical mathematics pedagogy is designed to be responsive to the lives of the students in a given classroom and their local context, there is no set curriculum. Some educators re-use lessons or units from year to year that may apply to multiple groups of students, while other educators develop projects that respond directly to the concerns of a particular group of students, building a project together around a problem the students have posed. Precisely for this reason it is pertinent to consider a few examples of what critical mathematics pedagogy might look like in action.

William Tate, [[Critical race theory|critical race]] theorist and promoter of [[culturally relevant teaching]], describes the work of one teacher who brought together many of the core components of critical mathematics pedagogy.&lt;ref name=":4" /&gt; This teacher elicited concerns from her students about their own neighborhood and lives, and found out that one concern was the prevalence of liquor stores in the neighborhood. Students were being harassed on their way to and from school, having to step over or walk past drunk individuals, making them feel uncomfortable and unsafe. This teacher led her students through the process of in-depth research to better understand the distribution of liquor licenses and the reasons behind the concentration in their neighborhood. The class then met with local journalists to discuss the use of different types of graphic for representing statistics to the general public. The class then considered and determined which graphics and statistical representations (decimals, fractions, percents) might be the strongest for communicating their findings. Finally, the students used their research to produce a policy solution which they presented to the local community council. The work of this group of students and their teacher succeeded in leading to the closing of two of the nearby liquor stores in the neighborhood.&lt;ref name=":4"&gt;{{Cite journal|last=Tate|first=William|year=1995|title=Returning to the Root: A Culturally Relevant Approach to Mathematics Pedagogy|url=|journal=Theory into Practice|volume=34 |issue=3|pages=166–173|via=}}&lt;/ref&gt;

Ole Skovsmose describes a classroom in Denmark in which students learned about the use of algorithms for distribution of welfare support to families by attempting to create their own algorithms. The class worked in groups, where each group came up with a family profile to serve under the supervision of the instructor. Groups then were given a budget for welfare distributions to families and had to come up with how to distribute the money among all the families in their "town" made up of all the created family profiles. The task led them to develop ways of categorizing people in families by age, and families type, by income amount and type, by labor and employment, by possible productivity to society, and more. Some groups distributed the money without building a distribution algorithm, using trial and error and attempting to balance the distribution by more intuitive means. Others built algorithms, working backwards, attempting to break down the distribution using percentages. Many groups were surprised to find that their algorithms did not function comprehensively, and did not fully distribute the amount they were budgeted, and that the outcomes by group were vastly different. Perhaps more importantly, students gained an awareness of the choices and decision making that goes into how policies such as welfare for families are complex and human-created, not simply existing structures.&lt;ref name=":0" /&gt; This project is an example of the way in which critical mathematics pedagogy can reveal the role that humans play in mathematizing the world. It is different from Tate's example because it does not explicitly include an action component.

For a collection of sample lessons that address mathematics teaching through a critical lens see the book, ''Rethinking Mathematics: Teaching Social Justice by the Numbers'' (Eds. Gutstein and Peterson, 2005).&lt;ref&gt;{{Cite book|title=Rethinking Mathematics: Teaching Social Justice by the Numbers|last=Gutstein and Peterson (Eds.)|first=|publisher=Rethinking Schools|year=2005|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt;

==Related concepts==
Other work in the field of mathematics education that often overlaps at least in part with critical mathematics pedagogy includes the work of [[ethnomathematics]], [[culturally relevant teaching]] in mathematics, and work for [[educational equity]] in mathematics.

The concept of '''ethnomathematics''' was introduced by D'Ambrosio in 1978, in response to the reliance on Eurocentric models for academic mathematics teaching to the exclusion of other cultural models. The goal of work in ethnomathematics is to de-center mathematics as a European dominated discipline by contributing research and teaching that highlights the contributions of many different cultures to mathematics as a discipline, and validating a wide range of mathematical practices. Ethnomathematics work notices, recognizes, reclaims, and celebrates the ways in which non-European communities and cultures are now and have throughout their histories been creating, using, and innovating with mathematics.&lt;ref name=":1" /&gt; It differs from critical mathematics pedagogy in that its focus is on cultural and social aspects of mathematics, where critical mathematics work also includes an explicit focus on politics and power structures.&lt;ref name=":1" /&gt; Though differences exist, those who work in either field oftentimes publish in similar publications and both consider their work mathematics for social justice.&lt;ref&gt;{{Cite book|title=Teaching Mathematics for Social Justice|last=|first=|publisher=|year=|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt;

'''Culturally relevant teaching''' '''in mathematics''' was developed initially to support the success of African-American students, frequently poorly served by the American public school system which has a long history of [[educational inequality]]. The liquor store example provided above is shared by Tate as an example of culturally relevant teaching, but might likewise be seen to embody the tenets of critical pedagogy. He cites six core practices of the teacher from the example that make her work culturally relevant: (1) communication between students, teacher, and outside entities, (2) cooperative group work, (3) investigative research throughout the learning process, (4) questioning content, people, and institutions, (5) open-ended problem solving connected to student realities, and (6) social action.&lt;ref name=":4" /&gt; While the practices listed by Tate resonate profoundly with those of critical mathematics pedagogy, the difference (if there is any) is in the goals of the two approaches. The focus of culturally relevant teaching is on the empowerment and liberation of a cultural or racial group, whereas the goals of critical pedagogy include empowerment and liberation of individuals as well as groups, in the face of any form of oppression, not only cultural or racial oppression.&lt;ref name=":1" /&gt;

The notion of '''educational equity in mathematics education''' promotes the provision of high quality mathematics education to all groups and individuals in an attempt to narrow achievement gaps, for example gaps related to race and gender. This approach does not include a critical approach to mathematics itself, or the notion that mathematics education should include the learning of mathematics for the purpose of being able to analyze and change structures of power and injustice in the world. The [[National Council of Teachers of Mathematics]], the world's largest mathematics education organization,&lt;ref&gt;{{cite web|url=http://www.nctm.org/About/ |title=National Council of Teachers of Mathematics : Overview |website=Nctm.org |accessdate=2017-03-02}}&lt;/ref&gt; has placed equity as one of its top priorities.&lt;ref&gt;{{cite web|url=http://www.nctm.org/flipbooks/standards/pssm/index.html |title=National Council of Teachers of Mathematics : Log In |website=Nctm.org |accessdate=2017-03-02}} {{Registration required|date=March 2017}}&lt;/ref&gt; However, critical mathematics educators suggest that the NCTM standards "fail to define equity in applicable terms for classroom teachers, and it overemphasized the economic aspects of equity."&lt;ref name=":1" /&gt;&lt;ref name=":6" /&gt;

==Challenges and critiques==
Logistically, implementation of critical pedagogy is a challenge because there is and can be no "how-to recipe." If the curriculum must be built out of students’ lives then it will necessarily change each year and with each group of students.

Critiques are widespread, suggesting that mathematics is unbiased and not bound to culture, society or politics and therefore should not be wrongly politicized in the classroom. It is argued that this [[politicization of science|politicization]] is a distraction from achievement and risks holding students back, most specifically those it purports to support.&lt;ref&gt;{{Cite journal|last=Joseph|first=George Gheverghese|date=1994-04-01|title=The Politics of Anti-Racist Mathematics|url=https://dx.doi.org/10.2753/EUE1056-4934260167|journal=European Education|volume=26|issue=1|pages=67–74|doi=10.2753/EUE1056-4934260167|issn=1056-4934}}&lt;/ref&gt;

==References==
{{Reflist}}

==Bibliography==
* Frankenstein, M. (1983). Critical Mathematics Education: An Application of Paulo Freire’s Epistemology. ''The Journal of Education'', ''165''(4), 315–339.
* Powell, A. (2012). The historical development of criticalmathematics education. In ''Teaching Mathematics for Social Justice: Conversations with Educators''. Eds. Anita Wager &amp; Stinson, D. Reston, VA: National Council of Teachers of Mathematics.
* Skovsmose, O. (1994). Towards a critical mathematics education. ''Educational Studies in Mathematics'', ''27''(1), 35–57. &lt;nowiki&gt;http://doi.org/10.1007/BF01284527&lt;/nowiki&gt;
* Stinson, D. &amp; Wager, A. (2012). A sojourn into the empowering uncertainties of teaching and learning mathematics for social change. In ''Teaching Mathematics for Social Justice: Conversations with Educators''. Eds. Anita Wager &amp; Stinson, D. Reston, VA: National Council of Teachers of Mathematics.
* Tate, W. F. (1995). Returning to the Root: A Culturally Relevant Approach to Mathematics Pedagogy. ''Theory into Practice'', ''34''(3), 166–173.
* Tutak, F. A., Bondy, E., &amp; Adams, T. L. (2011). Critical pedagogy for critical mathematics education. ''International Journal of Mathematics Education in Science and Technology'', ''42''(1), 65–74. &lt;nowiki&gt;http://doi.org/10.1080/0020739X.2010.510221&lt;/nowiki&gt;

[[Category:Mathematics education]]</text>
      <sha1>qg3nbu85zp5jyo5qzz1fnv1vz7dfe09</sha1>
    </revision>
  </page>
  <page>
    <title>Cyclic code</title>
    <ns>0</ns>
    <id>4706825</id>
    <revision>
      <id>855771992</id>
      <parentid>855771945</parentid>
      <timestamp>2018-08-20T18:37:00Z</timestamp>
      <contributor>
        <username>CoconutOctopus</username>
        <id>33608611</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/41.114.146.110|41.114.146.110]] ([[User talk:41.114.146.110|talk]]) to last revision by Mmeijeri. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25578">{{technical|date=March 2014}}
In [[coding theory]], a '''cyclic code''' is a [[block code]], where the [[circular shift]]s of each codeword gives another word that belongs to the code. They are [[error-correcting codes]] that have algebraic properties that are convenient for efficient [[error detection and correction]].
[[Image:Rotate right.svg|thumb|right|300px|If 00010111 is a valid codeword, applying a right circular shift gives the string 10001011. If the code is cyclic, then 10001011 is again a valid codeword. In general, applying a right circular shift moves the least significant bit (LSB) to the leftmost position, so that it becomes the most significant bit (MSB); the other positions are shifted by 1 to the right.]]

==Definition==
Let &lt;math&gt;\mathcal{C}&lt;/math&gt; be a [[linear code]] over a [[finite field]] (also called '' Galois field'') &lt;math&gt;GF(q)&lt;/math&gt; of [[block length]] ''n''. &lt;math&gt;\mathcal{C}&lt;/math&gt; is called a '''cyclic code''' if, for every [[codeword]] ''c''=(''c''&lt;sub&gt;1&lt;/sub&gt;,...,''c''&lt;sub&gt;n&lt;/sub&gt;) from ''C'', the word (''c''&lt;sub&gt;n&lt;/sub&gt;,''c''&lt;sub&gt;1&lt;/sub&gt;,...,''c''&lt;sub&gt;n-1&lt;/sub&gt;) in &lt;math&gt;GF(q)^n&lt;/math&gt; obtained by a [[circular shift|cyclic right shift]] of components is again a codeword. Because one cyclic right shift is equal to ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 cyclic left shifts, a cyclic code may also be defined via cyclic left shifts. Therefore the linear code &lt;math&gt;\mathcal{C}&lt;/math&gt; is cyclic precisely when it is invariant under all cyclic shifts.

Cyclic Codes have some additional structural constraint on the codes. They are based on [[Galois fields]] and because of their structural properties they are very useful for error controls. Their structure is strongly related to Galois fields because of which the encoding and decoding algorithms for cyclic codes are computationally efficient.

==Algebraic structure==
Cyclic codes can be linked to ideals in certain rings. Let  &lt;math&gt;R = A[x] / (x^n-1)&lt;/math&gt; be a [[polynomial ring]] over the finite field &lt;math&gt;A = GF(q)&lt;/math&gt;.   Identify the elements of the cyclic code ''C'' with polynomials in ''R'' such that 
&lt;math&gt; ( c_0, \ldots, c_{n-1} ) &lt;/math&gt; maps to the polynomial 
&lt;math&gt; c_0 + c_1x +\cdots+c_{n-1} x^{n-1} &lt;/math&gt;: thus multiplication by ''x'' corresponds to a cyclic shift. Then ''C'' is an [[Ideal (ring theory)|ideal]] in ''R'', and hence [[Principal ideal|principal]], since ''R'' is a [[principal ideal ring]].  The ideal is generated by the unique monic element in ''C'' of minimum degree, the ''generator polynomial'' ''g''.&lt;ref&gt;{{harvnb|Van Lint|1998|p=76}}&lt;/ref&gt;
This must be a divisor of &lt;math&gt;x^n-1&lt;/math&gt;. It follows that every cyclic code is a [[polynomial code]].
If the generator polynomial ''g'' has degree ''d'' then the rank of the code ''C'' is &lt;math&gt;n-d&lt;/math&gt;.

The '''idempotent''' of ''C'' is a codeword ''e'' such that ''e''&lt;sup&gt;2&lt;/sup&gt; = ''e'' (that is, ''e'' is an [[idempotent element]] of ''C'') and ''e'' is an identity for the code, that is ''e'' ''c'' = ''c'' for every codeword ''c''.  If ''n'' and ''q'' are [[coprime]] such a word always exists and is unique;&lt;ref&gt;{{harvnb|Van Lint|1998|p=80}}&lt;/ref&gt; it is a generator of the code.

An '''irreducible code''' is a cyclic code in which the code, as an ideal is irreducible, i.e. is minimal in ''R'', so that its check polynomial is an [[irreducible polynomial]].

==Examples==
For example, if ''A''=&lt;math&gt;\mathbb{F}_2&lt;/math&gt; and ''n''=3, the set of codewords contained in cyclic code generated by (1,1,0) is precisely

:&lt;math&gt;((0,0,0), (1,1,0), (0,1,1), (1,0,1))&lt;/math&gt;.

It corresponds to the ideal in &lt;math&gt;\mathbb{F}_2[x]/(x^3-1)&lt;/math&gt; generated by &lt;math&gt;(1+x)&lt;/math&gt;.

Note that &lt;math&gt;(1+x)&lt;/math&gt; is an irreducible polynomial in the polynomial ring, and hence the code is an irreducible code.

The idempotent of this code is the polynomial &lt;math&gt;x + x^2&lt;/math&gt;, corresponding to the codeword (0,1,1).

===Trivial examples===
Trivial examples of cyclic codes are ''A''&lt;sup&gt;n&lt;/sup&gt; itself and the code containing only the zero codeword.  These correspond to generators 1 and &lt;math&gt;x^n-1&lt;/math&gt; respectively: these two polynomials must always be factors of &lt;math&gt;x^n-1&lt;/math&gt;.

Over [[Galois field|GF]](2) the [[parity bit]] code, consisting of all words of even weight, corresponds to generator &lt;math&gt;x+1&lt;/math&gt;.  Again over GF(2) this must always be a factor of &lt;math&gt;x^n-1&lt;/math&gt;.

==Quasi-cyclic codes and shortened codes==

Before delving into the details of cyclic codes first we will discuss quasi-cyclic and shortened codes which are closely related to the cyclic codes and they all can be converted into each other.

===Definition===

Quasi-cyclic codes:{{cn|date=July 2016}}

An &lt;math&gt;(n,k)&lt;/math&gt; ''quasi-cyclic code'' is a linear block code such that, for some &lt;math&gt;b&lt;/math&gt; which is coprime to &lt;math&gt;n&lt;/math&gt;, the polynomial &lt;math&gt;x^bc(x)\pmod {x^n-1}&lt;/math&gt; is a ''codeword polynomial'' whenever &lt;math&gt;c(x)&lt;/math&gt; is a codeword polynomial.

Here, ''codeword polynomial'' is an element of a linear code whose [[code word]]s are polynomials that are divisible by a polynomial of shorter length called the ''generator polynomial''. Every codeword polynomial can be expressed in the form &lt;math&gt;c(x) = a(x)g(x)&lt;/math&gt;, where &lt;math&gt;g(x)&lt;/math&gt; is the generator polynomial. Any codeword &lt;math&gt;(c_0,..,c_{n-1})&lt;/math&gt; of a cyclic code &lt;math&gt;C&lt;/math&gt; can be associated with a codeword polynomial, namely, &lt;math&gt;\sum_{i=0}^{n-1} c_i*x^i &lt;/math&gt;. A quasi-cyclic code with &lt;math&gt;b&lt;/math&gt; equal to &lt;math&gt;1&lt;/math&gt; is a cyclic code.

===Definition===
Shortened codes: 

An &lt;math&gt;[n,k]&lt;/math&gt; linear code is called a ''proper shortened cyclic code'' if it can be obtained by deleting &lt;math&gt;b&lt;/math&gt; positions from an &lt;math&gt;(n+b, k+b)&lt;/math&gt; cyclic code.

In shortened codes information symbols are deleted to obtain a desired blocklength smaller than the design blocklength. The missing information symbols are usually imagined to be at the beginning of the codeword and are considered to be 0. Therefore, &lt;math&gt;n&lt;/math&gt;−&lt;math&gt;k&lt;/math&gt; is fixed, and then &lt;math&gt;k&lt;/math&gt; is decreased which eventually decreases &lt;math&gt;n&lt;/math&gt;. Note that it is not necessary to delete the starting symbols. Depending on the application sometimes consecutive positions are considered as 0 and are deleted.

All the symbols which are dropped need not be transmitted and at the receiving end can be reinserted. To convert &lt;math&gt;(n,k)&lt;/math&gt; cyclic code to &lt;math&gt;(n-b,k-b)&lt;/math&gt; shortened code, set &lt;math&gt;b&lt;/math&gt; symbols to zero and drop them from each codeword.  Any cyclic code can be converted to quasi-cyclic codes by dropping every &lt;math&gt;b&lt;/math&gt;th symbol where &lt;math&gt;b&lt;/math&gt; is a factor of &lt;math&gt;n&lt;/math&gt;. If the dropped symbols are not check symbols then this cyclic code is also a shortened code.

==Cyclic codes for correcting errors==

Now, we will begin the discussion of cyclic codes explicitly with [[error detection and correction]]. Cyclic codes can be used to correct errors, like [[Hamming code]]s as a cyclic codes can be used for correcting single error. Likewise, they are also used to correct double errors and burst errors. All types of error corrections are covered briefly in the further subsections.

The (7,4) Hamming code has a [[generator polynomial]] &lt;math&gt;g(x) = x^3 + x +1&lt;/math&gt;. This polynomial has a zero in [[Galois extension|Galois extension field]] &lt;math&gt;GF(8)&lt;/math&gt; at the primitive element &lt;math&gt;\alpha&lt;/math&gt;, and all codewords satisfy &lt;math&gt;\mathcal{C}(\alpha)=0&lt;/math&gt;. Cyclic codes can also be used to correct double errors over the field &lt;math&gt;GF(2)&lt;/math&gt;. Blocklength will be &lt;math&gt;n&lt;/math&gt; equal to &lt;math&gt;2^m -1&lt;/math&gt; and primitive elements &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\alpha^3&lt;/math&gt; as zeros in the &lt;math&gt;GF(2^m)&lt;/math&gt; because we are considering the case of two errors here, so each will represent one error.

The received word is a polynomial of degree &lt;math&gt;n - 1&lt;/math&gt; given as
&lt;math&gt;v(x) = a(x)g(x) + e(x)&lt;/math&gt;

where &lt;math&gt;e(x)&lt;/math&gt; can have at most two nonzero coefficients corresponding to 2 errors.

We define the '''Syndrome Polynomial''', &lt;math&gt;S(x)&lt;/math&gt; as the remainder of polynomial &lt;math&gt;v(x)&lt;/math&gt; when divided by the generator polynomial &lt;math&gt;g(x)&lt;/math&gt; i.e. 

&lt;math&gt;S(x) \equiv v(x) \equiv (a(x)g(x) + e(x)) \equiv e(x) \mod g(x)&lt;/math&gt; as &lt;math&gt;(a(x)g(x))\equiv 0\mod g(x)&lt;/math&gt;.

===For correcting two errors===

Let the field elements &lt;math&gt;X_1&lt;/math&gt; and &lt;math&gt;X_2&lt;/math&gt; be the two error location numbers. If only one error occurs then &lt;math&gt;X_2&lt;/math&gt; is equal to zero and if none occurs both are zero.

Let &lt;math&gt;S_1 = {v}(\alpha)&lt;/math&gt; and &lt;math&gt;S_3 = {v}(\alpha^3)&lt;/math&gt;.

These field elements are called "syndromes". Now because &lt;math&gt;g(x)&lt;/math&gt; is zero at primitive elements &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\alpha^3&lt;/math&gt;, so we can write &lt;math&gt;S_1 = e(\alpha)&lt;/math&gt; and &lt;math&gt;S_3 = e(\alpha^3)&lt;/math&gt;. If say two errors occur, then

&lt;math&gt;S_1 = \alpha^{i} + \alpha^{i'}&lt;/math&gt; and 
&lt;math&gt;S_3 = \alpha^{3i} + \alpha^{3i'}&lt;/math&gt;.

And these two can be considered as two pair of equations in &lt;math&gt;GF(2^m)&lt;/math&gt; with two unknowns and hence we can write

&lt;math&gt;S_1 = X_1 + X_2&lt;/math&gt; and 
&lt;math&gt;S_3 = (X_1)^3 + (X_2)^3&lt;/math&gt;.
 
Hence if the two pair of nonlinear equations can be solved cyclic codes can used to correct two errors.

==Hamming code==
The [[Hamming(7,4)]] code may be written as a cyclic code over GF(2) with generator &lt;math&gt;1+x+x^3&lt;/math&gt;. In fact, any binary [[Hamming code]] of the form Ham(r, 2) is equivalent to a cyclic code,&lt;ref&gt;{{harvnb|Hill|1988|pp=159-160}}&lt;/ref&gt; and any Hamming code of the form Ham(r,q) with r and q-1 relatively prime is also equivalent to a cyclic code.&lt;ref&gt;{{harvnb|Balahut|1983|loc=Theorem 5.5.1}}&lt;/ref&gt;  Given a Hamming code of the form Ham(r,2) with &lt;math&gt;r \ge 3&lt;/math&gt;, the set of even codewords forms a cyclic &lt;math&gt;[2^{r}-1,2^{r}-r-2,4]&lt;/math&gt;-code.&lt;ref&gt;{{harvnb|Hill|1988|pp=162-163}}&lt;/ref&gt;

===Hamming code for correcting single errors===

A code whose minimum distance is at least 3, have a check matrix all of whose columns are distinct and non zero. If a check matrix for a binary code has &lt;math&gt;m&lt;/math&gt; rows, then each column is an &lt;math&gt;m&lt;/math&gt;-bit binary number. There are &lt;math&gt;2^m-1&lt;/math&gt; possible columns. Therefore if a check matrix of a binary code with &lt;math&gt;d_{min}&lt;/math&gt; at least 3 has &lt;math&gt;m&lt;/math&gt; rows, then it can only have &lt;math&gt;2^m-1&lt;/math&gt; columns, not more than that. This defines a &lt;math&gt;(2^m-1, 2^m-1-m)&lt;/math&gt; code, called Hamming code.

It is easy to define Hamming codes for large alphabets of size &lt;math&gt;q&lt;/math&gt;. We need to define one '''&lt;math&gt;H&lt;/math&gt;''' matrix with linearly independent columns. For any word of size &lt;math&gt;q&lt;/math&gt; there will be columns who are multiples of each other. So, to get linear independence all non zero &lt;math&gt;m&lt;/math&gt;-tuples with one as a top most non zero element will be chosen as columns. Then two columns will never be linearly dependent because three columns could be linearly dependent with the minimum distance of the code as 3.

So, there are &lt;math&gt;(q^m-1)/(q-1)&lt;/math&gt; nonzero columns with one as top most non zero element. Therefore, Hamming code is a &lt;math&gt;[(q^m-1)/(q-1), (q^m-1)/(q-1)-m]&lt;/math&gt; code.

Now, for cyclic codes, Let &lt;math&gt;\alpha&lt;/math&gt; be primitive element in &lt;math&gt;GF(q^m)&lt;/math&gt;, and let &lt;math&gt;\beta = \alpha^{q-1}&lt;/math&gt;. Then &lt;math&gt;\beta^{(q^m-1)/(q-1)} = 1&lt;/math&gt; and thus &lt;math&gt;\beta&lt;/math&gt; is a zero of the polynomial &lt;math&gt;x^{(q^m-1)/(q-1)} - 1&lt;/math&gt; and is a generator polynomial for the cyclic code of block length &lt;math&gt;n = (q^m-1)/(q-1)&lt;/math&gt;.

But for &lt;math&gt;q = 2&lt;/math&gt;, &lt;math&gt;\alpha = \beta&lt;/math&gt;. And the received word is a polynomial of degree &lt;math&gt;n - 1&lt;/math&gt;  given as 

&lt;math&gt;v(x) = a(x)g(x) + e(x)&lt;/math&gt;

where, &lt;math&gt;e(x) = 0&lt;/math&gt; or &lt;math&gt; x^i&lt;/math&gt; where &lt;math&gt;i&lt;/math&gt; represents the error locations.

But we can also use &lt;math&gt;\alpha^i&lt;/math&gt; as an element of &lt;math&gt;GF(2^m)&lt;/math&gt; to index error location. Because &lt;math&gt;g(\alpha) = 0&lt;/math&gt;, we have &lt;math&gt;v(\alpha) = \alpha^i&lt;/math&gt; and all powers of &lt;math&gt;\alpha&lt;/math&gt; from &lt;math&gt;0&lt;/math&gt; to &lt;math&gt;2^m-2&lt;/math&gt; are distinct. Therefore we can easily determine error location &lt;math&gt;i&lt;/math&gt; from &lt;math&gt;\alpha^i&lt;/math&gt; unless &lt;math&gt;v(\alpha) = 0&lt;/math&gt; which represents no error. So, hamming code is a single error correcting code over &lt;math&gt;GF(2)&lt;/math&gt; with &lt;math&gt;n = 2^m-1&lt;/math&gt; and &lt;math&gt;k = n - m&lt;/math&gt;.

==Cyclic codes for correcting burst errors==
From [[Hamming distance]] concept, a code with minimum distance &lt;math&gt; 2t + 1&lt;/math&gt; can correct any &lt;math&gt;t&lt;/math&gt; errors. But in many channels error pattern is not very arbitrary, it occurs within very short segment of the message. Such kind of errors are called [[burst error]]s. So, for correcting such errors we will get a more efficient code of higher rate because of the less constraints. Cyclic codes are used for correcting burst error. In fact, cyclic codes can also correct cyclic burst errors along with burst errors. Cyclic burst errors are defined as

A cyclic burst of length &lt;math&gt;t&lt;/math&gt; is a vector whose nonzero components are among &lt;math&gt;t&lt;/math&gt; (cyclically) consecutive components, the first and the last of which are nonzero.

In polynomial form cyclic burst of length &lt;math&gt;t&lt;/math&gt; can be described as &lt;math&gt;e(x)=x^ib(x)\mod (x^n -1)&lt;/math&gt; with &lt;math&gt;b(x)&lt;/math&gt; as a polynomial of degree &lt;math&gt;t - 1&lt;/math&gt; with nonzero coefficient &lt;math&gt;b_0&lt;/math&gt;. Here &lt;math&gt;b(x)&lt;/math&gt; defines the pattern and &lt;math&gt;x^i&lt;/math&gt; defines the starting point of error. Length of the pattern is given by deg&lt;math&gt;b(x) + 1&lt;/math&gt;.  The syndrome polynomial is unique for each pattern and is given by 

&lt;math&gt;s(x) = e(x)\mod g(x) &lt;/math&gt;

A linear block code that corrects all burst errors of length &lt;math&gt;t&lt;/math&gt; or less must have at least &lt;math&gt;2t&lt;/math&gt; check symbols. Proof: Because any linear code that can correct burst pattern of length &lt;math&gt;t&lt;/math&gt; or less cannot have a burst of length &lt;math&gt;2t&lt;/math&gt; or less as a codeword because if it did then a burst of length &lt;math&gt;t&lt;/math&gt; could change the codeword to burst pattern of length &lt;math&gt;t&lt;/math&gt;, which also could be obtained by making a burst error of length &lt;math&gt;t&lt;/math&gt; in all zero codeword. Now, any two vectors that are non zero in the first &lt;math&gt;2t&lt;/math&gt; components must be from different co-sets of an array to avoid their difference being a codeword of bursts of length &lt;math&gt;2t&lt;/math&gt;. Therefore number of such co-sets are equal to number of such vectors which are &lt;math&gt;q^{2t}&lt;/math&gt;. Hence at least &lt;math&gt;q^{2t}&lt;/math&gt; co-sets and hence at least &lt;math&gt;2t&lt;/math&gt; check symbol.

This property is also known as Rieger bound and it is similar to the [[singleton bound]] for random error correcting.

===Fire codes as cyclic bounds===
In 1959, Philip Fire&lt;ref&gt;P. Fire, E, P. (1959). ''A class of multiple-error-correcting binary codes for non-independent errors.'' Sylvania Reconnaissance Systems Laboratory, Mountain View, CA, Rept. RSL-E-2, 1959.&lt;/ref&gt; presented a construction of cyclic codes generated by a product of a binomial and a primitive polynomial. The binomial has the form &lt;math&gt;x^c+1&lt;/math&gt; for some positive odd integer &lt;math&gt;c&lt;/math&gt;.&lt;ref&gt;Wei Zhou, Shu Lin, Khaled Abdel-Ghaffar. ''Burst or random error correction based on Fire and BCH codes.'' ITA 2014: 1-5 2013.&lt;/ref&gt; ''Fire code'' is a cyclic burst error correcting code over &lt;math&gt;GF(q)&lt;/math&gt; with the generator polynomial

&lt;math&gt;g(x)=(x^{2t-1}-1)p(x)&lt;/math&gt;

where &lt;math&gt;p(x)&lt;/math&gt; is a prime polynomial with degree &lt;math&gt;m&lt;/math&gt; not smaller than &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;p(x)&lt;/math&gt; does not divide &lt;math&gt;x^{2t-1}-1&lt;/math&gt;. Block length of the fire code is the smallest integer &lt;math&gt;n&lt;/math&gt; such that &lt;math&gt;g(x)&lt;/math&gt; divides
&lt;math&gt;x^n-1&lt;/math&gt;.

A fire code can correct all burst errors of length t or less if no two bursts &lt;math&gt;b(x)&lt;/math&gt; and &lt;math&gt;x^jb'(x)&lt;/math&gt; appear in the same co-set. This can be proved by contradiction. Suppose there are two distinct nonzero bursts &lt;math&gt;b(x)&lt;/math&gt; and &lt;math&gt;x^jb'(x)&lt;/math&gt; of length &lt;math&gt;t&lt;/math&gt; or less and are in the same co-set of the code. So, their difference is a codeword. As the difference is a multiple of &lt;math&gt;g(x)&lt;/math&gt; it is also a multiple of &lt;math&gt;x^{2t-1}-1&lt;/math&gt;. Therefore,

&lt;math&gt;b(x) = x^jb'(x)  \mod (x^{2t-1}-1)&lt;/math&gt;.

This shows that &lt;math&gt;j&lt;/math&gt; is a multiple of &lt;math&gt;2t - 1&lt;/math&gt;, So

&lt;math&gt;b(x) = x^{l(2t-1)}b'(x) &lt;/math&gt; 

for some &lt;math&gt;l&lt;/math&gt;. Now, as &lt;math&gt;l(2t-1)&lt;/math&gt; is less than &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;l&lt;/math&gt; is less than &lt;math&gt;q^m - 1&lt;/math&gt; so &lt;math&gt;(x^{l(2t - 1)} - 1)b(x)&lt;/math&gt; is a codeword. Therefore, 

&lt;math&gt;(x^{l(2t - 1)} - 1)b(x) = a(x)(x^{2t-1}- 1)p(x)&lt;/math&gt;.

Since &lt;math&gt;b(x)&lt;/math&gt; degree is less than degree of &lt;math&gt;p(x)&lt;/math&gt;,&lt;math&gt;p(x)&lt;/math&gt; cannot divide &lt;math&gt;b(x)&lt;/math&gt;. If &lt;math&gt;l&lt;/math&gt; is not zero, then &lt;math&gt;p(x)&lt;/math&gt; also cannot divide &lt;math&gt;x^{l(2t-1)} - 1&lt;/math&gt; as &lt;math&gt;l&lt;/math&gt; is less than &lt;math&gt;q^m-1&lt;/math&gt; and by definition of &lt;math&gt;m&lt;/math&gt;, &lt;math&gt;p(x)&lt;/math&gt; divides &lt;math&gt;x^{l(2t-1)} - 1&lt;/math&gt; for no &lt;math&gt;l&lt;/math&gt; smaller than &lt;math&gt;q^m-1&lt;/math&gt;. Therefore &lt;math&gt;l&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; equals to zero. That means both that both the bursts are same, contrary to assumption.  

Fire codes are the best single burst correcting codes with high rate and they are constructed analytically. They are of very high rate and when  &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;t &lt;/math&gt; are equal, redundancy is least and is equal to &lt;math&gt;3t - 1&lt;/math&gt;. By using multiple fire codes longer burst errors can also be corrected.

For error detection cyclic codes are widely used and are called &lt;math&gt;t - 1&lt;/math&gt; [[Cyclic redundancy check|cyclic redundancy codes]].

==Cyclic codes on Fourier transform==
Applications of [[Fourier transform]] are widespread in signal processing. But their applications are not limited to the complex fields only; Fourier transforms also exist in the Galois field &lt;math&gt;GF(q)&lt;/math&gt;. Cyclic codes using Fourier transform can be described in a setting closer to the signal processing.

===Fourier transform over finite fields===
[[Discrete_Fourier_transform_(general)#Finite_fields|Fourier transform over finite fields]]
   
The discrete  Fourier transform of vector &lt;math&gt;v = v_0, v_1, ...., v_{n-1}&lt;/math&gt;  is given by a vector &lt;math&gt;V = V_0, V_1,....., V_{n-1}&lt;/math&gt; where,

&lt;math&gt;V_k&lt;/math&gt; = &lt;math&gt;\Sigma_{i=0}^{n-1} e^{-j2\pi n^{-1}ik}v_i&lt;/math&gt; where,

&lt;math&gt;k = 0,....., n-1&lt;/math&gt;

where exp(&lt;math&gt;-j2\pi /n&lt;/math&gt;) is an &lt;math&gt;n&lt;/math&gt;th root of unity. Similarly in the finite field &lt;math&gt;n&lt;/math&gt;th root of unity is element &lt;math&gt;\omega&lt;/math&gt; of order &lt;math&gt;n&lt;/math&gt;. Therefore

''If &lt;math&gt;v = (v_0, v_1, ...., v_{n-1})&lt;/math&gt; is a vector over &lt;math&gt;GF(q)&lt;/math&gt;, and &lt;math&gt;\omega&lt;/math&gt; be an element of &lt;math&gt;GF(q)&lt;/math&gt; of order &lt;math&gt;n&lt;/math&gt;, then Fourier transform of the vector &lt;math&gt;v&lt;/math&gt; is the vector &lt;math&gt;V = (V_0, V_1,....., V_{n-1})&lt;/math&gt; and components are given by''

&lt;math&gt;V_j&lt;/math&gt; = &lt;math&gt;\Sigma_{i=0}^{n-1}\omega^{ij} v_i&lt;/math&gt; where,

&lt;math&gt;k = 0,....., n-1&lt;/math&gt;

Here &lt;math&gt;i&lt;/math&gt; is ''time'' index, &lt;math&gt;j&lt;/math&gt; is ''frequency'' and '''&lt;math&gt;V&lt;/math&gt;''' is the ''spectrum''. One important difference between Fourier transform in complex field and Galois field is that complex field &lt;math&gt;\omega&lt;/math&gt; exists for every value of &lt;math&gt;n&lt;/math&gt; while in Galois field &lt;math&gt;\omega&lt;/math&gt; exists only if &lt;math&gt;n&lt;/math&gt; divides &lt;math&gt;q - 1&lt;/math&gt;. In case of extension fields, there will be a Fourier transform in the extension field &lt;math&gt;GF(q^m)&lt;/math&gt;  if &lt;math&gt;n&lt;/math&gt; divides &lt;math&gt;q^m - 1&lt;/math&gt; for some &lt;math&gt;m&lt;/math&gt;.  
In Galois field time domain vector &lt;math&gt;v&lt;/math&gt; is over the field &lt;math&gt;GF(q)&lt;/math&gt; but the spectrum '''&lt;math&gt;V&lt;/math&gt;''' may be over the extension field &lt;math&gt;GF(q^m)&lt;/math&gt;.

===Spectral description of cyclic codes===
Any codeword of cyclic code of blocklength &lt;math&gt;n&lt;/math&gt; can be represented by a polynomial &lt;math&gt;c(x)&lt;/math&gt; of degree at most &lt;math&gt;n - 1&lt;/math&gt;. Its encoder can be written as &lt;math&gt;c(x) = a(x)g(x)&lt;/math&gt;. Therefore in frequency domain encoder can be written as &lt;math&gt;C_j = A_jG_j&lt;/math&gt;. Here ''codeword spectrum'' &lt;math&gt;C_j&lt;/math&gt; has a value in &lt;math&gt;GF(q^m)&lt;/math&gt; but all the components in the time domain are from &lt;math&gt;GF(q)&lt;/math&gt;. As the data spectrum &lt;math&gt;A_j&lt;/math&gt; is arbitrary, the role of &lt;math&gt;G_j&lt;/math&gt; is to specify those &lt;math&gt;j&lt;/math&gt; where &lt;math&gt;C_j&lt;/math&gt; will be zero.

Thus, cyclic codes can also be defined as 

''Given a set of spectral indices,'' &lt;math&gt;A = (j_1,...., j_{n-k})&lt;/math&gt;, '' whose elements are called check frequencies,  the cyclic code'' &lt;math&gt;C&lt;/math&gt; ''is the set of words over'' &lt;math&gt;GF(q)&lt;/math&gt; ''whose spectrum is zero in the components indexed by'' &lt;math&gt;j_1,..., j_{n-k}&lt;/math&gt;. ''Any such spectrum'' &lt;math&gt;C&lt;/math&gt; ''will have components of the form'' &lt;math&gt;A_jG_j&lt;/math&gt;.

So, cyclic codes are vectors in the field &lt;math&gt;GF(q)&lt;/math&gt; and the spectrum given by its inverse fourier transform is over the field &lt;math&gt;GF(q^m)&lt;/math&gt; and are constrained to be zero at certain components. But note that every spectrum in the field &lt;math&gt;GF(q^m)&lt;/math&gt; and zero at certain components may not have inverse transforms with components in the field &lt;math&gt;GF(q)&lt;/math&gt;. Such spectrum can not be used as cyclic codes.

Following are the few bounds on the spectrum of cyclic codes.

====BCH bound====
If &lt;math&gt;n&lt;/math&gt; be a factor of &lt;math&gt;(q^m - 1)&lt;/math&gt; for some &lt;math&gt;m&lt;/math&gt;. The only vector in &lt;math&gt;GF(q)^n&lt;/math&gt; of weight &lt;math&gt;d - 1&lt;/math&gt; or less that has &lt;math&gt;d - 1&lt;/math&gt; consecutive components of its spectrum equal to zero is all-zero vector.

====Hartmann-Tzeng bound====
If &lt;math&gt;n&lt;/math&gt; be a factor of &lt;math&gt;(q^m - 1)&lt;/math&gt; for some &lt;math&gt;m&lt;/math&gt;, and &lt;math&gt;b&lt;/math&gt; an integer that is coprime with &lt;math&gt;n&lt;/math&gt;. The only vector &lt;math&gt;v&lt;/math&gt; in &lt;math&gt;GF(q)^n&lt;/math&gt; of weight &lt;math&gt;d - 1&lt;/math&gt; or less whose spectral 
components &lt;math&gt;V_j&lt;/math&gt; equal zero for &lt;math&gt;j = \ell_1 + \ell_2b (\mod n)&lt;/math&gt;, where &lt;math&gt;\ell_1 = 0,...., d - s - 1&lt;/math&gt; and &lt;math&gt;\ell_2 = 0,...., s - 1&lt;/math&gt;, is the all zero vector.

====Roos bound====
If &lt;math&gt;n&lt;/math&gt; be a factor of &lt;math&gt;q^m - 1&lt;/math&gt; for some &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;GCD(n,b) = 1&lt;/math&gt;. The only vector in 
&lt;math&gt;GF(q)^n&lt;/math&gt; of weight &lt;math&gt;d - 1&lt;/math&gt; or less whose spectral components &lt;math&gt;V_j&lt;/math&gt; equal to zero for &lt;math&gt;j = l_1 + l_2b (\mod n)&lt;/math&gt;, where &lt;math&gt;l_1 = 0,..., d - s - 2&lt;/math&gt; and &lt;math&gt;l_2&lt;/math&gt; takes at least &lt;math&gt;s + 1&lt;/math&gt; values in the range &lt;math&gt;0,...., d - 2&lt;/math&gt;, is the all-zero vector.

===Quadratic residue codes===
When the prime &lt;math&gt;l&lt;/math&gt; is a quadratic residue modulo the prime &lt;math&gt;p&lt;/math&gt; there is a [[quadratic residue code]] which is a cyclic code of length &lt;math&gt;p&lt;/math&gt;, dimension &lt;math&gt;(p+1)/2&lt;/math&gt; and minimum weight at least &lt;math&gt;\sqrt{p}&lt;/math&gt; over &lt;math&gt;GF(l)&lt;/math&gt;.

==Generalizations==
A '''constacyclic code''' is a linear code with the property that for some constant λ if (''c''&lt;sub&gt;1&lt;/sub&gt;,c&lt;sub&gt;2&lt;/sub&gt;,...,''c''&lt;sub&gt;''n''&lt;/sub&gt;) is a codeword then so is (λ''c''&lt;sub&gt;''n''&lt;/sub&gt;,c&lt;sub&gt;1&lt;/sub&gt;,...,''c''&lt;sub&gt;''n''-1&lt;/sub&gt;).  A '''negacyclic code''' is a constacyclic code with λ=-1.&lt;ref&gt;{{harvnb|Van Lint|1998|p=75}}&lt;/ref&gt;  A '''quasi-cyclic code''' has the property that for some ''s'', any cyclic shift of a codeword by ''s'' places is again a codeword.&lt;ref name="MacWilliams and Sloane, p.506"&gt;{{harvnb|MacWilliams|Sloane|1977|p=506}}&lt;/ref&gt;  A '''double circulant code''' is a quasi-cyclic code of even length with ''s''=2.&lt;ref name="MacWilliams and Sloane, p.506"/&gt;

==See also==
* [[Cyclic redundancy check]]
* [[Polynomial code]]
* [[BCH code]]
* [[Reed–Muller code]]
* [[Binary Golay code]]
* [[Ternary Golay code]]
* [[Eugene Prange]]

==Notes==
{{reflist}}

==References==
* {{citation|last=Blahut|first=Richard E.|author-link=Richard Blahut|title=Algebraic Codes for Data Transmission|edition=2nd|publisher=[[Cambridge University Press]]|year=2003|isbn=0-521-55374-1}}
* {{citation|last=Hill|first=Raymond|title=A First Course In Coding Theory|publisher=[[Oxford University Press]]|date=1988|isbn=0-19-853803-0}}
* {{citation|first1=F. J.|last1=MacWilliams|author1-link=F. J. MacWilliams|first2=N. J. A.|last2=Sloane|author2-link=N. J. A. Sloane|title=The Theory of Error-Correcting Codes|place=New York|publisher=North-Holland Publishing|year=1977|isbn=0-444-85011-2}}
* {{citation|first=J. H.|last=Van Lint|author-link=Jack van Lint|title=Introduction to Coding Theory|edition=3rd|series=[[Graduate Texts in Mathematics]] '''86'''|publisher=[[Springer Verlag]]|year=1998|isbn=3-540-64133-5}}

==Further reading==
* [[Ranjan Bose]]'', Information theory, coding and cryptography'', {{ISBN|0-07-048297-7}}
* [[Irving S. Reed]] and Xuemin Chen, ''Error-Control Coding for Data Networks'', Boston: Kluwer Academic Publishers, 1999, {{ISBN|0-7923-8528-4}}.
* [[Scott A. Vanstone]], [[Paul C. Van Oorschot]], ''An introduction to error correcting codes with applications'', {{ISBN|0-7923-9017-2}}

==External links==
* John Gill's (Stanford) class notes &amp;ndash; [http://www.stanford.edu/class/ee387/handouts/notes3.pdf Notes #3, October 8, Handout #9], EE 387.
* Jonathan Hall's (MSU) class notes &amp;ndash; [http://www.math.msu.edu/~jhall/classes/codenotes/Cyclic.pdf Chapter 8. Cyclic codes] - pp. 100 - 123
* {{MathWorld|title=Cyclic Code|urlname=CyclicCode|author=David Terr}}

{{PlanetMath attribution|id=6978|title=cyclic code}}

[[Category:Coding theory]]
[[Category:Finite fields]]</text>
      <sha1>qkkdo6qds0r7rkdasxa5hhn3527vb06</sha1>
    </revision>
  </page>
  <page>
    <title>Differential geometry</title>
    <ns>0</ns>
    <id>8625</id>
    <revision>
      <id>866105547</id>
      <parentid>866105516</parentid>
      <timestamp>2018-10-28T08:27:30Z</timestamp>
      <contributor>
        <username>Hair444y</username>
        <id>29209706</id>
      </contributor>
      <minor/>
      <comment>Reverted 2 edits by [[Special:Contributions/171.61.27.41|171.61.27.41]] ([[User talk:171.61.27.41|talk]]) to last revision by 129.7.106.20. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24899">[[File:Hyperbolic triangle.svg|thumb|235px|right|A triangle immersed in a saddle-shape plane (a [[hyperbolic paraboloid]]), as well as two diverging [[Hyperbolic geometry#Non-intersecting / parallel lines|ultraparallel lines]].]]
{{General geometry |branches}}

'''Differential geometry''' is a [[Mathematics|mathematical]] discipline that uses the techniques of [[differential calculus]], [[integral calculus]], [[linear algebra]] and [[multilinear algebra]] to study problems in [[geometry]]. The [[Differential geometry of curves|theory of plane and space curves]] and [[Differential geometry of surfaces|surfaces]] in the three-dimensional [[Euclidean space]] formed the basis for development of differential geometry during the 18th century and the 19th century.

Since the late 19th century, differential geometry has grown into a field concerned more generally with the geometric structures on [[differentiable manifold]]s. Differential geometry is closely related to [[differential topology]] and the geometric aspects of the theory of [[differential equation]]s. The [[differential geometry of surfaces]] captures many of the key ideas and techniques endemic to this field.

== History of development ==
{{Synthesis|section|date=February 2017}}
Differential geometry arose and developed as a result of and in connection to the mathematical analysis of curves and surfaces.&lt;ref&gt;http://www.encyclopediaofmath.org/index.php/Differential_geometry be&lt;/ref&gt; Mathematical analysis of curves and surfaces had been developed to answer some of the nagging and unanswered questions that appeared in [[calculus]], like the reasons for relationships between complex shapes and curves, series and analytic functions. These unanswered questions indicated greater, hidden relationships.

The general idea of natural equations for obtaining curves from local curvature appears to have been first considered by [[Leonhard Euler]] in 1736, and many examples with fairly simple behavior were studied in the 1800s.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=1009|isbn=1-57955-008-8}}&lt;/ref&gt;

When curves, surfaces enclosed by curves, and points on curves were found to be quantitatively, and generally, related by mathematical forms, the formal study of the nature of curves and surfaces became a field of study in its own right, with [[Gaspard Monge#Work|Monge]]'s paper in 1795, and especially, with [[Carl Friedrich Gauss|Gauss]]'s publication of his article, titled 'Disquisitiones Generales Circa Superficies Curvas', in ''Commentationes Societatis Regiae Scientiarum Gottingesis Recentiores'' in 1827.&lt;ref&gt;'Disquisitiones Generales Circa Superficies Curvas' (literal translation from Latin: General Investigations of Curved Surfaces), ''Commentationes Societatis Regiae Scientiarum Gottingesis Recentiores'' (literally, Recent Perspectives, Gottingen's Royal Society of Science). Volume VI, pp. 99–146. A translation of the work, by A.M.Hiltebeitel and J.C.Morehead, titled, "General Investigations of Curved Surfaces"  was published 1965 by Raven Press, New York. A digitised version of the same is available at http://quod.lib.umich.edu/u/umhistmath/abr1255.0001.001 for free download, for non-commercial, personal use. In case of further information, the library could be contacted.

Also, the Wikipedia article on [[Carl Friedrich Gauss#Writings|Gauss's works]] in the year 1827 at could be looked at.&lt;/ref&gt;

Initially applied to the Euclidean space, further explorations led to non-Euclidean space, and metric and topological spaces.

== Branches ==
===Riemannian geometry===
{{main|Riemannian geometry}}

Riemannian geometry studies [[Riemannian manifold]]s, [[smooth manifold]]s with a ''Riemannian metric''. This is a concept of distance expressed by means of a [[Smooth function|smooth]] [[positive definite bilinear form|positive definite]] [[symmetric bilinear form]] defined on the tangent space at each point. Riemannian geometry generalizes [[Euclidean geometry]] to spaces that are not necessarily flat, although they still resemble the [[Euclidean space]] at each point infinitesimally, i.e. in the [[first order of approximation]]. Various concepts based on length, such as the [[arc length]] of [[curve]]s, [[area]] of plane regions, and [[volume]] of solids all possess natural analogues in Riemannian geometry. The notion of a [[directional derivative]] of a function from [[multivariable calculus]] is extended in Riemannian geometry to the notion of a [[covariant derivative]] of a [[tensor]]. Many concepts and techniques of analysis and differential equations have been generalized to the setting of Riemannian manifolds.

A distance-preserving [[diffeomorphism]] between Riemannian manifolds is called an [[isometry]]. This notion can also be defined ''locally'', i.e. for small neighborhoods of points. Any two regular curves are locally isometric. However, the [[Theorema Egregium]] of [[Carl Friedrich Gauss]] showed that for surfaces, the existence of a local isometry imposes strong compatibility conditions on their metrics: the [[Gaussian curvature]]s at the corresponding points must be the same. In higher dimensions, the [[Riemann curvature tensor]] is an important pointwise invariant associated with a Riemannian manifold that measures how close it is to being flat. An important class of Riemannian manifolds is the [[Riemannian symmetric space]]s, whose curvature is not necessarily constant. These are the closest analogues to the "ordinary" plane and space considered in Euclidean and [[non-Euclidean geometry]].

===Pseudo-Riemannian geometry===
[[pseudo-Riemannian manifold|Pseudo-Riemannian geometry]] generalizes Riemannian geometry to the case in which the [[metric tensor]] need not be [[Definite bilinear form|positive-definite]]. 
A special case of this is a [[Lorentzian manifold]], which is the mathematical basis of Einstein's [[General relativity|general relativity theory of gravity]].

===Finsler geometry===
{{main|Finsler manifold}}
Finsler geometry has ''Finsler manifolds'' as the main object of study. This is a differential manifold with a ''Finsler metric'', that is, a [[Banach norm]] defined on each tangent space. Riemannian manifolds are special cases of the more general Finsler manifolds. A Finsler structure on a manifold {{math|''M''}} is a function {{math|''F'' : T''M'' → [0, ∞)}} such that:
# {{math|1=''F''(''x'', ''my'') = {{abs|''m''}} ''F''(''x'', ''y'')}} for all {{math|''x'', ''y''}} in {{math|T''M''}},
# {{math|''F''}} is infinitely differentiable in {{math|T''M'' ∖ {0}{{void}}}},
# The vertical Hessian of {{math|''F''&lt;sup&gt;2&lt;/sup&gt;}} is positive definite.

===Symplectic geometry===
{{main|Symplectic geometry}}

[[Symplectic geometry]] is the study of [[symplectic manifold]]s. An '''almost symplectic manifold''' is a differentiable manifold equipped with a [[smooth function|smoothly varying]] [[non-degenerate]] [[skew-symmetric matrix|skew-symmetric]] [[bilinear form]] on each tangent space, i.e., a nondegenerate 2-[[Differential form|form]] ''ω'', called the ''symplectic form''. A symplectic manifold is an almost symplectic manifold for which the symplectic form ''ω'' is closed:  {{nowrap|1=d''ω'' = 0}}.

A [[diffeomorphism]] between two symplectic manifolds which preserves the symplectic form is called a [[symplectomorphism]]. Non-degenerate skew-symmetric bilinear forms can only exist on even-dimensional vector spaces, so symplectic manifolds necessarily have even dimension. In dimension 2, a symplectic manifold is just a [[Surface (topology)|surface]] endowed with an area form and a symplectomorphism is an area-preserving diffeomorphism. The [[phase space]] of a mechanical system is a symplectic manifold and they made an implicit appearance already in the work of [[Joseph Louis Lagrange]] on [[analytical mechanics]] and later in [[Carl Gustav Jacobi]]'s and [[William Rowan Hamilton]]'s [[Hamiltonian mechanics|formulations of classical mechanics]].

By contrast with Riemannian geometry, where the [[curvature]] provides a local invariant of Riemannian manifolds, [[Darboux's theorem]] states that all symplectic manifolds are locally isomorphic. The only invariants of a symplectic manifold are global in nature and topological aspects play a prominent role in symplectic geometry. The first result in symplectic topology is probably the [[Poincaré–Birkhoff theorem]], conjectured by [[Henri Poincaré]] and then proved by [[G.D. Birkhoff]] in 1912. It claims that if an area preserving map of an [[annulus (mathematics)|annulus]] twists each boundary component in opposite directions, then the map has at least two fixed points.&lt;ref&gt;The area preserving condition (or the twisting condition) cannot be removed. If one tries to extend such a theorem to higher dimensions, one would probably guess that a volume preserving map of a certain type must have fixed points. This is false in dimensions greater than 3.&lt;/ref&gt;

===Contact geometry===
{{main|Contact geometry}}

[[Contact geometry]] deals with certain manifolds of odd dimension. It is close to symplectic geometry and like the latter, it originated in questions of classical mechanics. A ''contact structure'' on a {{nowrap|(2''n'' + 1)}}-dimensional manifold ''M'' is given by a smooth hyperplane field ''H'' in the [[tangent bundle]] that is as far as possible from being associated with the level sets of a differentiable function on ''M'' (the technical term is "completely nonintegrable tangent hyperplane distribution"). Near each point ''p'', a hyperplane distribution is determined by a nowhere vanishing [[Differential form|1-form]] &lt;math&gt;\alpha&lt;/math&gt;, which is unique up to multiplication by a nowhere vanishing function:

: &lt;math&gt; H_p = \ker\alpha_p\subset T_{p}M.&lt;/math&gt;

A local 1-form on ''M'' is a ''contact form'' if the restriction of its [[exterior derivative]] to ''H'' is a non-degenerate two-form and thus induces a symplectic structure on ''H''&lt;sub&gt;''p''&lt;/sub&gt; at each point. If the distribution ''H'' can be defined by a global one-form &lt;math&gt;\alpha&lt;/math&gt; then this form is contact if and only if the top-dimensional form

: &lt;math&gt;\alpha\wedge (d\alpha)^n&lt;/math&gt;

is a [[volume form]] on ''M'', i.e. does not vanish anywhere. A contact analogue of the Darboux theorem holds: all contact structures on an odd-dimensional manifold are locally isomorphic and can be brought to a certain local normal form by a suitable choice of the coordinate system.

===Complex and Kähler geometry===
''Complex differential geometry'' is the study of [[complex manifolds]].
An [[almost complex manifold]] is a ''real'' manifold &lt;math&gt;M&lt;/math&gt;, endowed with a [[tensor]] of [[tensor|type]] (1, 1), i.e. a [[vector bundle|vector bundle endomorphism]] (called an ''[[almost complex structure]]'')
:&lt;math&gt; J:TM\rightarrow TM &lt;/math&gt;, such that &lt;math&gt;J^2=-1. \,&lt;/math&gt;

It follows from this definition that an almost complex manifold is even-dimensional.

An almost complex manifold is called ''complex'' if &lt;math&gt;N_J=0&lt;/math&gt;, where &lt;math&gt;N_J&lt;/math&gt; is a tensor of type (2, 1) related to &lt;math&gt;J&lt;/math&gt;, called the [[Nijenhuis tensor]] (or sometimes the ''torsion'').
An almost complex manifold is complex if and only if it admits a [[Holomorphic function|holomorphic]] [[Atlas (topology)|coordinate atlas]].
An ''[[Hermitian manifold|almost Hermitian structure]]'' is given by an almost complex structure ''J'', along with a [[Riemannian metric]] ''g'', satisfying the compatibility condition
:&lt;math&gt;g(JX,JY)=g(X,Y) \,&lt;/math&gt;.

An almost Hermitian structure defines naturally a [[differential form|differential two-form]]
:&lt;math&gt;\omega_{J,g}(X,Y):=g(JX,Y) \,&lt;/math&gt;.

The following two conditions are equivalent:

# &lt;math&gt; N_J=0\mbox{ and }d\omega=0 \,&lt;/math&gt;
# &lt;math&gt;\nabla J=0 \,&lt;/math&gt;

where &lt;math&gt;\nabla&lt;/math&gt; is the [[Levi-Civita connection]] of &lt;math&gt;g&lt;/math&gt;. In this case, &lt;math&gt;(J, g)&lt;/math&gt; is called a ''[[Kähler manifold|Kähler structure]]'', and a ''Kähler manifold'' is a manifold endowed with a Kähler structure. In particular, a Kähler manifold is both a complex and a [[symplectic manifold]]. A large class of Kähler manifolds (the class of [[Hodge manifold]]s) is given by all the smooth [[algebraic geometry|complex projective varieties]].

===CR geometry===
[[CR structure|CR geometry]] is the study of the intrinsic geometry of boundaries of domains in [[complex manifold]]s.

=== Differential topology ===
[[Differential topology]] is the study of global geometric invariants without a metric or symplectic form.

Differential topology starts from the natural operations such as [[Lie derivative]] of natural [[vector bundle]]s and [[Exterior derivative|de Rham differential]] of [[Differential form|forms]]. Beside [[Lie algebroid]]s, also [[Courant algebroid]]s start playing a more important role.

=== Lie groups ===
A [[Lie group]] is a [[Group (mathematics)|group]] in the category of smooth manifolds. Beside the algebraic properties this enjoys also differential geometric properties. The most obvious construction is that of a Lie algebra which is the tangent space at the unit endowed with the Lie bracket between left-invariant [[vector field]]s. Beside the structure theory there is also the wide field of [[representation of a Lie group|representation theory]].

== Bundles and connections ==

The apparatus of [[vector bundle]]s, [[principal bundle]]s, and [[connection (mathematics)|connection]]s on bundles plays an extraordinarily important role in modern differential geometry. A smooth manifold always carries a natural vector bundle, the [[tangent bundle]]. Loosely speaking, this structure by itself is sufficient only for developing analysis on the manifold, while doing geometry requires, in addition, some way to relate the tangent spaces at different points, i.e. a notion of [[parallel transport]]. An important example is provided by [[affine connection]]s. For a [[Surface (topology)|surface]] in '''R'''&lt;sup&gt;3&lt;/sup&gt;, tangent planes at different points can be identified using a natural path-wise parallelism induced by the ambient Euclidean space, which has a well-known standard definition of metric and parallelism. In [[Riemannian geometry]], the [[Levi-Civita connection]] serves a similar purpose. (The Levi-Civita connection defines path-wise parallelism in terms of a given arbitrary Riemannian metric on a manifold.) More generally, differential geometers consider spaces with a vector bundle and an arbitrary affine connection which is not defined in terms of a metric. In physics, the manifold may be the [[spacetime|space-time continuum]] and the bundles and connections are related to various physical fields.

== Intrinsic versus extrinsic ==

From the beginning and through the middle of the 18th century, differential geometry was studied from the ''extrinsic'' point of view: [[curve]]s and [[Surface (topology)|surface]]s were considered as lying in a [[Euclidean space]] of higher dimension (for example a surface in an [[ambient space]] of three dimensions). The simplest results are those in the [[differential geometry of curves]] and [[differential geometry of surfaces]]. Starting with the work of [[Bernhard Riemann|Riemann]], the ''intrinsic'' point of view was developed, in which one cannot speak of moving "outside" the geometric object because it is considered to be given in a free-standing way. The fundamental result here is Gauss's [[theorema egregium]], to the effect that [[Gaussian curvature]] is an intrinsic invariant.

The intrinsic point of view is more flexible. For example, it is useful in relativity where space-time cannot naturally be taken as extrinsic (what would be "outside" of it?). However, there is a price to pay in technical complexity: the intrinsic definitions of [[curvature]] and [[connection (mathematics)|connections]] become much less visually intuitive.

These two points of view can be reconciled, i.e. the extrinsic geometry can be considered as a structure additional to the intrinsic one. (See the [[Nash embedding theorem]].) In the formalism of [[geometric calculus]] both extrinsic and intrinsic geometry of a manifold can be characterized by a single bivector-valued one-form called the [[shape operator]].&lt;ref&gt;{{cite book |first=David |last=Hestenes |chapter=The Shape of Differential Geometry in Geometric Calculus |chapterurl=http://geocalc.clas.asu.edu/pdf/Shape%20in%20GC-2012.pdf |title=Guide to Geometric Algebra in Practice |editor-first=L. |editor-last=Dorst |editor2-first=J. |editor2-last=Lasenby |publisher=Springer Verlag |year=2011 |pages=393–410 }} There is also [http://staff.science.uva.nl/~leo/agacse2010/talks_world/Hestenes.pdf a pdf] available of a scientific talk on the subject&lt;/ref&gt;

== Applications ==
{{Spacetime|cTopic=Introduction}}
Below are some examples of how differential geometry is applied to other fields of science and mathematics.
*In [[physics]], differential geometry has many applications, including:
**Differential geometry is the language in which [[Einstein]]'s [[general theory of relativity]] is expressed. According to the theory, the universe is a smooth manifold equipped with a pseudo-Riemannian metric, which describes the [[curvature]] of [[space-time]]. Understanding this curvature is essential for the positioning of [[satellites]] into orbit around the earth. Differential geometry is also indispensable in the study of [[gravitational lensing]] and [[black holes]].
**[[Differential forms]] are used in the study of [[electromagnetism]].
**Differential geometry has applications to both [[Lagrangian mechanics]] and [[Hamiltonian mechanics]]. [[Symplectic manifold]]s in particular can be used to study [[Hamiltonian system]]s.
**Riemannian geometry and contact geometry have been used to construct the formalism of [[geometrothermodynamics]] which has found applications in classical equilibrium [[thermodynamics]].
*In [[chemistry]] and [[biophysics]] when modelling cell membrane structure under varying pressure.
*In [[economics]], differential geometry has applications to the field of [[econometrics]].&lt;ref&gt;{{cite book |editor-first=Paul |editor-last=Marriott |editor2-first=Mark |editor2-last=Salmon |title=Applications of Differential Geometry to Econometrics |location= |publisher=Cambridge University Press |year=2000 |isbn=0-521-65116-6 }}&lt;/ref&gt;
*[[Geometric modeling]] (including [[computer graphics]]) and [[computer-aided geometric design]] draw on ideas from differential geometry.
*In [[engineering]], differential geometry can be applied to solve problems in [[digital signal processing]].&lt;ref&gt;{{cite web |first=Jonathan H. |last=Manton |title=On the role of differential geometry in signal processing |year=2005 |doi=10.1109/ICASSP.2005.1416480|url =https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1416480 }}&lt;/ref&gt;
*In [[control theory]], differential geometry can be used to analyze nonlinear controllers, particularly [[geometric control]]&lt;ref&gt;{{cite book |first=Francesco |last=Bullo |first2=Andrew |last2=Lewis |title=Geometric Control of Mechanical Systems : Modeling, Analysis, and Design for Simple Mechanical Control Systems |location= |publisher=Springer-Verlag |year=2010 |isbn=978-1-4419-1968-7 }}&lt;/ref&gt;
* In [[probability]], [[statistics]], and [[information theory]], one can interpret various structures as Riemannian manifolds, which yields the field of [[information geometry]], particularly via the [[Fisher information metric]].
*In [[structural geology]], differential geometry is used to analyze and describe geologic structures.
*In [[computer vision]], differential geometry is used to analyze shapes.&lt;ref&gt;{{cite thesis |type=Ph.D. |date=May 2008 |first=Mario |last=Micheli |title=The Differential Geometry of Landmark Shape Manifolds: Metrics, Geodesics, and Curvature |url=http://www.math.ucla.edu/~micheli/PUBLICATIONS/micheli_phd.pdf |archivedate=June 4, 2011 |archiveurl=https://web.archive.org/web/20110604092900/http://www.math.ucla.edu/~micheli/PUBLICATIONS/micheli_phd.pdf }}&lt;/ref&gt;
*In [[image processing]], differential geometry is used to process and analyse data on non-flat surfaces.&lt;ref&gt;{{cite thesis |type=Ph.D. |first=Anand A. |last=Joshi |title=Geometric Methods for Image Processing and Signal Analysis |date=August 2008 |url=http://users.loni.ucla.edu/~ajoshi/final_thesis.pdf }}&lt;/ref&gt;
*[[Grigori Perelman]]'s proof of the [[Poincaré conjecture]] using the techniques of [[Ricci flow]]s demonstrated the power of the differential-geometric approach to questions in [[topology]] and it highlighted the important role played by its analytic methods.
* In [[wireless|wireless communications]], [[Grassmannian| Grassmannian manifolds]] are used for [[beamforming]] techniques in [[MIMO|multiple antenna]] systems.&lt;ref&gt;{{cite journal |first=David J. |last=Love |first2=Robert W., Jr. |last2=Heath |title=Grassmannian Beamforming for Multiple-Input Multiple-Output Wireless Systems |journal=IEEE Transactions on Information Theory |volume=49 |issue=10 |date=October 2003 |pages=2735–2747 |doi=10.1109/TIT.2003.817466 |url=http://users.ece.utexas.edu/~rheath/papers/2002/grassbeam/paper.pdf }}&lt;/ref&gt;

==See also==
{{div col|colwidth=15em}}
* [[Abstract differential geometry]]
* [[Affine differential geometry]]
* [[Analysis on fractals]]
* [[Basic introduction to the mathematics of curved spacetime]]
* [[Discrete differential geometry]]
* [[Gauss]]
* [[Glossary of differential geometry and topology]]
* [[List of publications in mathematics#Differential geometry|Important publications in differential geometry]]
* [[List of publications in mathematics#Differential topology|Important publications in differential topology]]
* [[Integral geometry]]
* [[List of differential geometry topics]]
* [[Noncommutative geometry]]
* [[Projective differential geometry]]
* [[Synthetic differential geometry]]
* [[Systolic geometry]]
{{div col end}}

== References ==
{{reflist|30em}}

== Further reading ==
*{{cite book |title = A First Course in Geometric Topology and Differential Geometry|first = Ethan D.|last = Bloch | year = 1996}}
*{{cite book |title = Applied Differential Geometry|first = William L.|last = Burke|year = 1985}}
*{{cite book |title = Differential Geometry of Curves and Surfaces|first = Manfredo|last = do Carmo|authorlink=Manfredo do Carmo | isbn = 0-13-212589-7 | year = 1976}} Classical geometric approach to differential geometry without tensor analysis.
*{{cite book |title = Riemannian Geometry|first=Manfredo | last = do Carmo | authorlink=Manfredo do Carmo | year = 1994}}
*{{cite book |title = The geometry of physics: an introduction |first=Theodore |last=Frankel |authorlink=Theodore Frankel |edition = 2nd |year = 2004 |isbn = 0-521-53927-7}}
*{{cite book |title = Modern Differential Geometry of Curves and Surfaces with Mathematica|edition = 2nd|first = Alfred|last = Gray| year = 1998}}
*{{cite book |title = Differential Geometry |first = Erwin |last = Kreyszig | isbn = 0-486-66721-9 | year = 1991}} Good classical geometric approach to differential geometry with tensor machinery.
*{{cite book |title = Differential Geometry: Curves – Surfaces – Manifolds |first=Wolfgang |last=Kühnel |edition = 2nd |year = 2002 |isbn = 0-8218-3988-8}}
*{{cite book |title = Geometry from a Differentiable Viewpoint|first = John |last = McCleary | year = 1994}}
*{{cite book |title = A Comprehensive Introduction to Differential Geometry (5 Volumes) |edition = 3rd |first=Michael |last=Spivak | authorlink=Michael Spivak |year=1999}}
*{{cite book |title = Front-End Vision and Multi-Scale Image Analysis| first = Bart M. |last = ter Haar Romeny |isbn = 1-4020-1507-0|year = 2003}}

== External links ==
{{Sister project links| wikt=no | commons=no | b=no | n=no | q=Differential geometry | s=no | v=no | voy=no | species=no | d=no}}

* {{Springer |title=Differential geometry |id=p/d032170}}
*[http://math.stanford.edu/~conrad/diffgeomPage/ B. Conrad. Differential Geometry handouts, Stanford University]
*[http://www.maths.adelaide.edu.au/michael.murray/teaching_old.html Michael Murray's online differential geometry course, 1996]
*[http://VirtualMathMuseum.org/Surface/a/bk/curves_surfaces_palais.pdf A Modern Course on Curves and Surface, Richard S Palais, 2003]
*[http://VirtualMathMuseum.org/ Richard Palais's 3DXM Surfaces Gallery]
*[http://www.cs.elte.hu/geometry/csikos/dif/dif.html Balázs Csikós's Notes on Differential Geometry]
*[http://www.wisdom.weizmann.ac.il/~yakov/scanlib/hicks.pdf N. J. Hicks, Notes on Differential Geometry, Van Nostrand.]
*[http://ocw.mit.edu/courses/mathematics/18-950-differential-geometry-fall-2008/ MIT OpenCourseWare: Differential Geometry, Fall 2008]

{{Areas of mathematics}}
{{tensors}}

{{Authority control}}

{{DEFAULTSORT:Differential Geometry}}
[[Category:Differential geometry| ]]
[[Category:Geometry processing]]</text>
      <sha1>dltyspktkr1kyao4rthmk7r9g3djmro</sha1>
    </revision>
  </page>
  <page>
    <title>Equational logic</title>
    <ns>0</ns>
    <id>33522862</id>
    <revision>
      <id>760394910</id>
      <parentid>760393978</parentid>
      <timestamp>2017-01-16T18:51:45Z</timestamp>
      <contributor>
        <username>InterruptorJones</username>
        <id>117876</id>
      </contributor>
      <comment>/* Syllogism */ Add "boolean" link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7045">First-order '''equational [[logic]]''' consists of [[Quantification (logic)|quantifier]]-free terms of ordinary [[first-order logic]], with equality as the only [[predicate symbol]]. The [[model theory]] of this logic was developed into [[Universal algebra]] by [[Garrett Birkhoff|Birkhoff]], Grätzer and [[Paul Cohn|Cohn]]. It was later made into a branch of [[category theory]] by [[William Lawvere|Lawvere]] ("algebraic theories").&lt;ref&gt;equational logic. (n.d.). The Free On-line Dictionary of Computing. Retrieved October 24, 2011, from Dictionary.com website: http://dictionary.reference.com/browse/equational+logic&lt;/ref&gt;
	
The terms of equational logic are built up from variables and constants using function symbols (or operations).

==Syllogism==

Here are the four [[inference rule]]s of logic &lt;math display="inline"&gt;E&lt;/math&gt;. &lt;math display="inline"&gt;P[x := E]&lt;/math&gt; denotes textual substitution of expression &lt;math display="inline"&gt;E&lt;/math&gt; for variable &lt;math display="inline"&gt;x&lt;/math&gt; in expression &lt;math display="inline"&gt;P&lt;/math&gt;. &lt;math display="inline"&gt;b = c&lt;/math&gt; denotes equality, for &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of the same type, while &lt;math display="inline"&gt;b \equiv c&lt;/math&gt;, or equivalence, is defined only for &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of type [[Boolean algebra|boolean]]. For &lt;math display="inline"&gt;b&lt;/math&gt; and &lt;math display="inline"&gt;c&lt;/math&gt; of type boolean, &lt;math display="inline"&gt;b = c&lt;/math&gt; and &lt;math display="inline"&gt;b \equiv c&lt;/math&gt; have the same meaning.

{| class="wikitable"
|-
! scope="row" style="text-align: left" | [[Substitution (logic)|Substitution]]
| If &lt;math display="inline"&gt;P&lt;/math&gt; is a theorem, then so is &lt;math display="inline"&gt;P[x := E]&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P \qquad \rightarrow \qquad \vdash P[x := E]&lt;/math&gt;
|-
! scope="row" style="text-align: left" | [[Gottfried Wilhelm Leibniz|Leibniz]]
| If &lt;math display="inline"&gt;P = Q&lt;/math&gt; is a theorem, then so is &lt;math display="inline"&gt;E[x:= P] = E[x:= Q]&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P = Q \qquad \rightarrow \qquad \vdash E[x := P] = E[x := Q]&lt;/math&gt;
|-
! scope="row" style="text-align: left" style="text-align: left" | [[Transitive relation|Transitivity]]
| If &lt;math display="inline"&gt;P = Q&lt;/math&gt; and &lt;math display="inline"&gt;Q = R&lt;/math&gt; are theorems, then so is &lt;math display="inline"&gt;P = R&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P = Q, \; \vdash Q = R \qquad \rightarrow \qquad \vdash P = R&lt;/math&gt;
|-
! scope="row" style="text-align: left" | [[Equanimity]]
| If &lt;math display="inline"&gt;P&lt;/math&gt; and &lt;math display="inline"&gt;P \equiv Q&lt;/math&gt; are theorems, then so is &lt;math display="inline"&gt;Q&lt;/math&gt;.
| &lt;math display="block"&gt;\vdash P, \; \vdash P \equiv Q \qquad \rightarrow \qquad \vdash Q&lt;/math&gt;
|}

&lt;ref name="gries"&gt;Gries, D. (2010). Introduction to equational logic . Retrieved from http://www.cs.cornell.edu/gries/logic/Equational.html&lt;/ref&gt;

==History==

Equational logic was developed over the years (beginning in the early 1980s) by researchers in the formal development of programs, who felt a need for an effective style of manipulation, of calculation. Involved were people like [[Roland Carl Backhouse]], [[Edsger W. Dijkstra]], Wim H.J. Feijen, [[David Gries]], [[Carel S. Scholten]], and Netty van Gasteren. Wim Feijen is responsible for important details of the proof format.

The axioms are similar to those use by Dijkstra and Scholten in their monograph ''Predicate calculus and program semantics'' (Springer Verlag, 1990), but our order of presentation is slightly different.

In their monograph, Dijkstra and Scholten use the three inference rules Leibniz, Substitution, and Transitivity. However, Dijkstra/Scholten system is not a logic, as logicians use the word. Some of their manipulations are based on the meanings of the terms involved, and not on clearly presented syntactical rules of manipulation. The first attempt at making a real logic out of it appeared in ''A Logical Approach to Discrete Math''. However, inference rule Equanimity is missing there, and the definition of theorem is contorted to account for it. The introduction of Equanimity and its use in the proof format is due to Gries and Schneider. It is used, for example, in the proofs of soundness and completeness, and it will appear in the second edition of ''A Logical Approach to Discrete Math''.&lt;ref name="gries" /&gt;

==Proof==
We explain how the four inference rules are used in proofs, using the proof of &lt;math display="inline"&gt;\lnot p \equiv p \equiv \bot&lt;/math&gt;. The [[List of logic symbols|logic symbols]] &lt;math display="inline"&gt;\top&lt;/math&gt; and &lt;math display="inline"&gt;\bot&lt;/math&gt; indicate "true" and "false," respectively, and &lt;math display="inline"&gt;\lnot&lt;/math&gt; indicates "not." The theorem numbers refer to theorems of ''A Logical Approach to Discrete Math''.&lt;ref name="gries" /&gt;

&lt;math display="block"&gt;
\begin{array}{lcl}
(0) &amp; &amp; \lnot p \equiv p \equiv \bot \\
(1) &amp; = &amp; \quad \left\langle\; (3.9),\; \lnot(p \equiv q) \equiv \lnot p \equiv q,\; \text{with}\ q := p \;\right\rangle \\
(2) &amp; &amp; \lnot (p \equiv p) \equiv \bot \\
(3) &amp; = &amp; \quad \left\langle\; \text{Identity of}\ \equiv (3.9),\; \text{with}\ q := p \;\right\rangle \\
(4) &amp; &amp; \lnot \top \equiv \bot &amp; (3.8)
\end{array}
&lt;/math&gt;

First, lines &lt;math display="inline"&gt;(0)&lt;/math&gt;&amp;ndash;&lt;math display="inline"&gt;(2)&lt;/math&gt; show a use of inference rule Leibniz:

&lt;math display="block"&gt;
(0) = (2)
&lt;/math&gt;

is the conclusion of Leibniz, and its premise &lt;math display="inline"&gt;\lnot(p \equiv p) \equiv \lnot p \equiv p&lt;/math&gt; is given on line &lt;math display="inline"&gt;(1)&lt;/math&gt;. In the same way, the equality on lines &lt;math display="inline"&gt;(2)&lt;/math&gt;&amp;ndash;&lt;math display="inline"&gt;(4)&lt;/math&gt; are substantiated using Leibniz.

The "hint" on line &lt;math display="inline"&gt;(1)&lt;/math&gt; is supposed to give a premise of Leibniz, showing what substitution of equals for equals is being used. This premise is theorem &lt;math display="inline"&gt;(3.9)&lt;/math&gt; with the substitution &lt;math display="inline"&gt;p := q&lt;/math&gt;, i.e.

&lt;math display="block"&gt;
(\lnot(p \equiv q) \equiv \lnot p \equiv q)[p := q]
&lt;/math&gt;

This shows how inference rule Substitution is used within hints.

From &lt;math display="inline"&gt;(0) = (2)&lt;/math&gt; and &lt;math display="inline"&gt;(2) = (4)&lt;/math&gt;, we conclude by inference rule Transitivity that &lt;math display="inline"&gt;(0) = (4)&lt;/math&gt;. This shows how Transitivity is used.

Finally, note that line &lt;math display="inline"&gt;(4)&lt;/math&gt;, &lt;math display="inline"&gt;\lnot \top \equiv \bot&lt;/math&gt;, is a theorem, as indicated by the hint to its right. Hence, by inference rule Equanimity, we conclude that line &lt;math display="inline"&gt;(0)&lt;/math&gt; is also a theorem. And &lt;math display="inline"&gt;(0)&lt;/math&gt; is what we wanted to prove.&lt;ref name="gries" /&gt;

==References==
{{reflist}}

==External links==
* [http://mathworld.wolfram.com/EquationalLogic.html Sakharov, Alex. "Equational Logic." From MathWorld--A Wolfram Web Resource, created by Eric W. Weisstein.]

[[Category:Mathematical logic]]</text>
      <sha1>diitlfoeoagzkcg4mrp8plvszpkxq75</sha1>
    </revision>
  </page>
  <page>
    <title>Fibrant object</title>
    <ns>0</ns>
    <id>1782993</id>
    <revision>
      <id>784569813</id>
      <parentid>777628998</parentid>
      <timestamp>2017-06-09T00:54:35Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1212">In [[mathematics]], specifically in [[homotopy theory]] in the context of a [[model category]] ''M'', a '''fibrant object''' ''A'' of ''M'' is an [[object (category theory)|object]] that has a [[fibration]] to the [[terminal object]] of the [[category (mathematics)|category]].

==Properties==

The fibrant objects of a [[closed model category]] are characterized by having a [[right lifting property]] with respect to any [[cofibration|trivial cofibration]] in the category.  This property makes fibrant objects the "correct" objects on which to define [[homotopy group]]s.  In the context of the theory of [[simplicial set]]s, the fibrant objects are known as '''Kan complexes''' after [[Daniel Kan]]. They are the [[Kan fibration]]s over a point.

Dually is the notion of cofibrant object, defined to be an object &lt;math&gt;c&lt;/math&gt; such that the unique morphism &lt;math&gt;\varnothing\to c&lt;/math&gt; from the initial object to &lt;math&gt;c&lt;/math&gt; is a cofibration.

==References==
*P.G. Goerss and J.F. Jardine, ''Simplicial Homotopy Theory'', Progress in Math., Vol. 174, Birkhauser, Boston-Basel-Berlin, 1999.  {{ISBN|3-7643-6064-X}}.

[[Category:Homotopy theory]]
[[Category:Objects (category theory)]]


{{geometry-stub}}</text>
      <sha1>jl2flu0zzffl6pon4o272l7mbc9rls4</sha1>
    </revision>
  </page>
  <page>
    <title>Fictitious play</title>
    <ns>0</ns>
    <id>2435876</id>
    <revision>
      <id>835782006</id>
      <parentid>835781029</parentid>
      <timestamp>2018-04-10T18:54:05Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>corrections in punctuation and mathematical notation required by [[WP:MOS]] and [[WP:MOSMATH]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4844">In [[game theory]], '''fictitious play''' is  a learning rule first introduced by [[George W. Brown (academic)|George W. Brown]].  In it, each player presumes that the opponents are playing stationary (possibly mixed) strategies. At each round, each player thus best responds to the empirical frequency of play of their opponent. Such a method is of course adequate if the opponent indeed uses a stationary strategy, while it is flawed if the opponent's strategy is non-stationary. The opponent's strategy may for example be conditioned on the fictitious player's last move.

== History ==
Brown first introduced fictitious play as an explanation for [[Nash equilibrium]] play.  He imagined that a player would "simulate" play of the game in their mind and update their future play based on this simulation; hence the name ''fictitious'' play.  In terms of current use, the name is a bit of a misnomer, since each play of the game actually occurs.  The play is not exactly fictitious.

== Convergence properties ==
In fictitious play strict [[Nash equilibria]] are [[absorbing state]]s.  That is, if at any time period all the players play a Nash equilibrium, then they will do so for all subsequent rounds.  (Fudenberg and Levine 1998, Proposition 2.1)  In addition, if fictitious play converges to any distribution, those probabilities correspond to a Nash equilibrium of the underlying game. (Proposition 2.2)

{| border="1" align=right cellpadding="4" cellspacing="0" style="margin: 1em 1em 1em 1em; background: #f9f9f9; border: 1px #aaa solid; border-collapse: collapse; font-size: 95%;text-align:center" class="wikitable"
|+ align=bottom|''Generalized Rock Paper Scissors''
|
! ''A''
! ''B''
! ''C''
|-
! ''a''
| 0, 0
| 2, 1
| 1, 2
|-
! ''b''
| 1, 2
| 0, 0
| 2, 1
|-
! ''c''
| 2, 1
| 1, 2
| 0, 0
|}
Therefore, the interesting question is, under what circumstances does fictitious play converge?  The process will converge for a 2-person game if:
# Both players have only a finite number of strategies and the game is [[zero sum]] (Robinson 1951) 
# The game is solvable by iterated elimination of [[Dominance (game theory)|strictly dominated strategies]] (Nachbar 1990)
# The game is a [[potential game]] (Monderer and  Shapley 1996-a,1996-b)
# The game has [[generic payoffs]] and is 2&amp;nbsp;×&amp;nbsp;''N'' (Berger 2005)

Fictitious play does not always converge, however.  Shapley (1964) proved that in the game pictured here (a nonzero-sum version of [[Rock, Paper, Scissors]]), if the players start by choosing ''(a, B)'', the play will cycle indefinitely.

==Terminology==
Berger (2007) states that "what modern game theorists describe as 'fictitious play' is not the learning process that George W. Brown defined in his 1951 paper": Brown's "original version differs in a subtle detail..." in  that modern usage involves the players updating their beliefs ''simultaneously'', whereas Brown described the players updating ''alternatingly''.   Berger then uses Brown's original form to present a simple and intuitive proof of convergence in the case of two-player nondegenerate ordinal [[potential game]]s.

The term "fictitious" had earlier been given another meaning in game theory. Von Neumann and Morgenstern [1944] defined a "fictitious player" as a player with only one strategy, added to an ''n''-player game to turn it into a (''n''&amp;nbsp;+&amp;nbsp;1)-player zero-sum game.

== References ==
*Berger, U. (2005) "Fictitious Play in 2xN Games", ''Journal of Economic Theory'' 120, 139–154.
*Berger, U. (2007) "Brown's original fictitious play", ''Journal of Economic Theory'' 135:572–578
*Brown, G.W. (1951) "Iterative Solutions of Games by Fictitious Play" In ''Activity Analysis of Production and Allocation'', T. C. Koopmans (Ed.),  New York: Wiley.
* Fudenberg, D. and D.K. Levine (1998) ''The Theory of Learning in Games'' Cambridge: MIT Press.
* Monderer, D., and Shapley, L.S. (1996-a) "Potential Games", ''Games and Economic Behavior'' 14, 124-143.
* Monderer, D., and Shapley, L.S. (1996-b) "Fictitious Play Property for Games with Identical Interests", ''Journal of Economic Theory'' 68, 258–265.
* Nachbar, J. (1990) "Evolutionary Selection Dynamics in Games: Convergence and Limit Properties", ''International Journal of Game Theory'' 19, 59–89.
* von Neumann and Morgenstern (1944), ''Theory of Games and Economic Behavior'', Princeton and Woodstock: Princeton University Press. 
* Robinson, J. (1951) "An Iterative Method of Solving a Game", ''Annals of Mathematics'' 54, 296–301.
* Shapley L. (1964) "Some Topics in Two-Person Games" In ''Advances in Game Theory'' M. Dresher, L.S. Shapley, and A.W. Tucker (Eds.), Princeton: Princeton University Press.

== External links ==
*[http://www.dudziak.com/poker.php Game-Theoretic Solution to Poker Using Fictitious Play]

{{Game theory}}

[[Category:Game theory]]</text>
      <sha1>oia2wojkls1fv0nnoqbneeflfqnec41</sha1>
    </revision>
  </page>
  <page>
    <title>Flag (geometry)</title>
    <ns>0</ns>
    <id>9352497</id>
    <revision>
      <id>816281872</id>
      <parentid>815894261</parentid>
      <timestamp>2017-12-20T11:01:50Z</timestamp>
      <contributor>
        <username>Maproom</username>
        <id>2524922</id>
      </contributor>
      <comment>/* top */ removed false statement (which I appear to have added myself)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2616">{{for|a comparable but different concept from [[linear algebra]]|flag (linear algebra)}}

[[File:Polytope Flag.PNG|thumb|360px|Face diagram of a square pyramid showing one of its flags]]

In (polyhedral) [[geometry]], a '''flag''' is a sequence of faces of a [[Abstract polytope|polytope]], each contained in the next, with exactly one face from each dimension. 

More formally, a '''flag''' ψ of an ''n''-polytope is a set {''F''&lt;sub&gt;&amp;minus;1&lt;/sub&gt;,  ''F''&lt;sub&gt;0&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''F''&lt;sub&gt;''n''&lt;/sub&gt;} such that ''F''&lt;sub&gt;''i''&lt;/sub&gt; ≤ ''F''&lt;sub&gt;''i''+1&lt;/sub&gt; (&amp;minus;1 ≤ ''i'' ≤ ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1) and there is precisely one ''F''&lt;sub&gt;''i''&lt;/sub&gt; in ''ψ'' for each ''i'', (&amp;minus;1 ≤ ''i'' ≤ ''n'').  Since, however, the minimal face ''F''&lt;sub&gt;&amp;minus;1&lt;/sub&gt; and the maximal face ''F''&lt;sub&gt;''n''&lt;/sub&gt; must be in every flag, they are often omitted from the list of faces, as a shorthand. These latter two are called '''improper''' faces.

For example, a flag of a polyhedron comprises one vertex, one edge incident to that vertex, and one polygonal face incident to both, plus the two improper faces.

A polytope may be regarded as regular if, and only if, its [[symmetry group]] is [[transitive group action|transitive]] on its flags. This definition excludes [[Chirality (mathematics)|chiral]] polytopes.

==Incidence geometry==
In the more abstract setting of [[incidence geometry]], which is a set having a symmetric and reflexive [[Relation (mathematics)|relation]] called ''incidence'' defined on its elements, a '''flag''' is a set of elements that are mutually incident.&lt;ref&gt;{{harvnb|Beutelspacher|Rosenbaum|1998|loc=pg. 3}}&lt;/ref&gt; This level of abstraction generalizes both the polyhedral concept given above as well as the related [[Flag (linear algebra)|flag]] concept from linear algebra.

A flag is ''maximal'' if it is not contained in a larger flag. When all maximal flags of an incidence geometry have the same size, this common value is the ''rank'' of the geometry.

==Notes==
{{reflist}}

== References ==
* {{citation|last1=Beutelspacher|first1=Albrecht|last2=Rosenbaum|first2=Ute|title=Projective Geometry: from foundations to applications|year=1998|publisher=Cambridge University Press|location=Cambridge|isbn=0-521-48277-1}}
* Peter R. Cromwell, ''Polyhedra'', Cambridge University Press 1997, {{ISBN|0-521-55432-2}}
* [[Peter McMullen]], Egon Schulte, ''Abstract Regular Polytopes'', Cambridge University Press, 2002. {{ISBN|0-521-81496-0}}


[[Category:Incidence geometry]]
[[Category:Polygons]]
[[Category:Polyhedra]]
[[Category:Polychora]]
[[Category:Polytopes]]</text>
      <sha1>hi2ewodixe5ick4qj9umhfj92taea97</sha1>
    </revision>
  </page>
  <page>
    <title>Functional renormalization group</title>
    <ns>0</ns>
    <id>26271144</id>
    <revision>
      <id>866304720</id>
      <parentid>864188362</parentid>
      <timestamp>2018-10-29T15:19:49Z</timestamp>
      <contributor>
        <username>Gehenna1510</username>
        <id>34982813</id>
      </contributor>
      <comment>CS1 error fixed [[WP:UCB|Assisted by Citation bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16865">{{Use dmy dates|date=October 2014}}
In [[theoretical physics]], '''functional renormalization group''' ('''FRG''') is an implementation of the [[renormalization group]] (RG) concept which is used in quantum and statistical field theory, especially when dealing with strongly interacting systems. The method combines functional methods of [[quantum field theory]] with the intuitive renormalization group idea of [[Kenneth G. Wilson]]. This technique allows to interpolate smoothly between the known microscopic laws and the complicated macroscopic phenomena in physical systems. In this sense, it bridges the transition from simplicity of microphysics to complexity of macrophysics. Figuratively speaking, FRG acts as a microscope with a variable resolution. One starts with a high-resolution picture of the known microphysical laws and subsequently decreases the resolution to obtain a coarse-grained picture of macroscopic collective phenomena. The method is nonperturbative, meaning that it does not rely on an expansion in a small [[coupling constant]]. Mathematically, FRG is based on an exact functional differential equation for a scale-dependent [[effective action]].

==The flow equation for the effective action ==
In [[quantum field theory]], the [[effective action]] &lt;math&gt;\Gamma&lt;/math&gt; is an analogue of the [[classical physics|classical]] [[Action (physics)|action functional]] &lt;math&gt;S&lt;/math&gt; and depends on the fields of a given theory. It includes all quantum and thermal fluctuations. Variation of &lt;math&gt;\Gamma&lt;/math&gt; yields exact quantum field equations, for example for [[cosmology]] or the [[electrodynamics]] of superconductors. Mathematically, &lt;math&gt;\Gamma&lt;/math&gt; is the generating functional of the one-particle irreducible [[Feynman diagram]]s. Interesting physics, as propagators and effective couplings for interactions, can be straightforwardly extracted from it. In a generic interacting field theory the effective action &lt;math&gt;\Gamma&lt;/math&gt;, however, is difficult to obtain. FRG provides a practical tool to calculate &lt;math&gt;\Gamma&lt;/math&gt; employing the [[renormalization group]] concept.

The central object in FRG is a scale-dependent effective action functional &lt;math&gt;\Gamma_{k}&lt;/math&gt; often called average action or flowing action. The dependence on the RG sliding scale &lt;math&gt;k&lt;/math&gt; is introduced by adding a [[Regularization (physics)|regulator]] (infrared cutoff) &lt;math&gt;R_{k}&lt;/math&gt; to the full inverse propagator &lt;math&gt;\Gamma^{(2)}_{k}&lt;/math&gt;. Roughly speaking, the regulator &lt;math&gt;R_k&lt;/math&gt; decouples slow modes with momenta &lt;math&gt;q\lesssim k&lt;/math&gt; by giving them a large mass, while high momentum modes are not affected. Thus, &lt;math&gt;\Gamma_{k}&lt;/math&gt; includes all quantum and statistical fluctuations with momenta &lt;math&gt;q\gtrsim k&lt;/math&gt;. The flowing action &lt;math&gt;\Gamma_k&lt;/math&gt; obeys the exact functional flow equation

&lt;math&gt;\partial_k \Gamma_k = \frac{1}{2} \text{STr} \,
  \partial_k R_k \, (\Gamma^{(2)}_k + R_k)^{-1},&lt;/math&gt;

derived by [[Christof Wetterich]] and [[Tim R. Morris]] in 1993. Here &lt;math&gt;\partial_k&lt;/math&gt; denotes a derivative with respect to the RG scale &lt;math&gt;k&lt;/math&gt; at fixed values of the fields.
The functional differential equation for &lt;math&gt;\Gamma_{k}&lt;/math&gt; must be supplemented with the initial condition &lt;math&gt;\Gamma_{k\to\Lambda}=S&lt;/math&gt;, where the "classical action" &lt;math&gt;S&lt;/math&gt; describes the physics at the microscopic ultraviolet scale &lt;math&gt;k=\Lambda&lt;/math&gt;. Importantly, in the [[infrared limit]] &lt;math&gt;k\to 0&lt;/math&gt; the full [[effective action]] &lt;math&gt;\Gamma=\Gamma_{k\to 0}&lt;/math&gt; is obtained. In the Wetterich equation &lt;math&gt;\text{STr}&lt;/math&gt; denotes a supertrace which sums over momenta, frequencies, internal indices, and fields (taking bosons with a plus and fermions with a minus sign). The exact flow equation for &lt;math&gt;\Gamma_k&lt;/math&gt; has a one-loop structure. This is an important simplification compared to [[perturbation theory]], where multi-loop diagrams must be included. The second functional derivative &lt;math&gt;\Gamma^{(2)}_{k}&lt;/math&gt; is the full inverse field propagator modified by the presence of the regulator &lt;math&gt;R_k&lt;/math&gt;.

The renormalization group evolution of &lt;math&gt;\Gamma_k&lt;/math&gt; can be illustrated in the theory space, which is a multi-dimensional space of all possible running couplings &lt;math&gt;\{c_{n} \}&lt;/math&gt; allowed by the symmetries of the problem. As schematically shown in the figure, at the microscopic ultraviolet scale &lt;math&gt;k=\Lambda&lt;/math&gt; one starts with the initial condition &lt;math&gt;\Gamma_{k=\Lambda}=S&lt;/math&gt;.

[[File:theoryspace.png|300px]]

As the sliding scale &lt;math&gt;k&lt;/math&gt; is lowered, the flowing action &lt;math&gt;\Gamma_k&lt;/math&gt; evolves in the theory space according to the functional flow equation. The choice of the regulator &lt;math&gt;R_k&lt;/math&gt; is not unique, which introduces some scheme dependence into the [[renormalization group]] flow. For this reason, different choices of the regulator &lt;math&gt;R_k&lt;/math&gt; correspond to the different paths in the figure. At the infrared scale &lt;math&gt;k=0&lt;/math&gt;, however, the full effective action &lt;math&gt;\Gamma_{k=0}=\Gamma&lt;/math&gt; is recovered for every choice of the cut-off &lt;math&gt;R_k&lt;/math&gt;, and all trajectories meet at the same point in the theory space.

In most cases of interest the Wetterich equation can only be solved approximately. Usually some type of expansion of &lt;math&gt;\Gamma_{k}&lt;/math&gt; is performed, which is then truncated at finite order leading to a finite system of ordinary differential equations. Different systematic expansion schemes (such as the derivative expansion, vertex expansion, etc.) were developed. The choice of the suitable scheme should be physically motivated and depends on a given problem. The expansions do not necessarily involve a small parameter (like an interaction [[coupling constant]]) and thus they are, in general, of nonperturbative nature.

==Aspects of functional renormalization==

* The Wetterich flow equation is an exact equation. However, in practice, the functional differential equation must be truncated, i.e. it must be projected to functions of a few variables or even onto some finite-dimensional sub-theory space. As in every nonperturbative method, the question of error estimate is nontrivial in functional renormalization. One way to estimate the error in FRG is to improve the truncation in successive steps, i.e. to enlarge the sub-theory space by including more and more running couplings. The difference in the flows for different truncations gives a good estimate of the error. Alternatively, one can use different regulator functions &lt;math&gt;R_k&lt;/math&gt; in a given (fixed) truncation and determine the difference of the RG flows in the infrared for the respective regulator choices. If bosonization is used, one can check the insensitivity of final results with respect to different bosonization procedures.
* In FRG, as in all RG methods, a lot of insight about a physical system can be gained from the topology of RG flows. Specifically, identification of [[Fixed point (mathematics)|fixed points]] of the renormalization group evolution is of great importance. Near fixed points the flow of running couplings effectively stops and RG &lt;math&gt;\beta&lt;/math&gt;-functions approach zero. The presence of (partially) stable infrared fixed points is closely connected to the concept of [[universality (dynamical systems)|universality]]. Universality manifests itself in the observation that some very distinct physical systems have the same critical behavior. For instance, to good accuracy, [[critical exponents]] of the liquid–gas phase transition in water and the ferromagnetic phase transition in magnets are the same. In the renormalization group language, different systems from the same universality class flow to the same (partially) stable infrared fixed point. In this way macrophysics becomes independent of the microscopic details of the particular physical model.
* Compared to the [[perturbation theory]], functional renormalization does not make a strict distinction between renormalizable and nonrenormalizable couplings. All running couplings that are allowed by symmetries of the problem are generated during the FRG flow. However, the nonrenormalizable couplings approach partial fixed points very quickly during the evolution towards the infrared, and thus the flow effectively collapses on a hypersurface of the dimension given by the number of renormalizable couplings. Taking the nonrenormalizable couplings into account allows to study nonuniversal features that are sensitive to the concrete choice of the microscopic action &lt;math&gt;S&lt;/math&gt; and the finite ultraviolet cutoff &lt;math&gt;\Lambda&lt;/math&gt;.
* The Wetterich equation can be obtained from the [[Legendre transformation]] of the Polchinski functional equation, derived by Joseph Polchinski in 1984. The concept of the effective average action, used in FRG, is, however, more intuitive than the flowing bare action in the Polchinski equation. In addition, the FRG method proved to be more suitable for practical calculations.
* Typically, low-energy physics of strongly interacting systems is described by macroscopic degrees of freedom (i.e. particle excitations) which are very different from microscopic high-energy degrees of freedom. For instance, [[quantum chromodynamics]] is a field theory of interacting quarks and gluons. At low energies, however, proper degrees of freedom are baryons and mesons. Another example is the BEC/BCS crossover problem in [[condensed matter physics]]. While the microscopic theory is defined in terms of two-component nonrelativistic fermions, at low energies a composite (particle-particle) dimer becomes an additional degree of freedom, and it is advisable to include it explicitly in the model. The low-energy composite degrees of freedom can be introduced in the description by the method of partial bosonization ([[Hubbard-Stratonovich transformation]]). This transformation, however, is done once and for all at the UV scale &lt;math&gt;\Lambda&lt;/math&gt;. In FRG a more efficient way to incorporate macroscopic degrees of freedom was introduced, which is known as flowing bosonization or rebosonization. With the help of a scale-dependent field transformation, this allows to perform the [[Hubbard-Stratonovich transformation]] continuously at all RG scales &lt;math&gt;k&lt;/math&gt;.

==Functional renormalization-group for Wick-ordered effective interaction==
Contrary to the flow equation for the effective action, this scheme is formulated for the [[effective interaction]]

&lt;math&gt;\mathcal{V}[\eta ,\eta ^{+}] =-\ln Z[G_{0}^{-1} \eta , G_{0}^{-1}\eta ^{+}]-\eta G_{0}^{-1}\eta ^{+}&lt;/math&gt;

which generates n-particle interaction vertices, amputated by the bare propagators &lt;math&gt;G_{0}&lt;/math&gt;;
&lt;math&gt;Z[\eta ,\eta ^{+}]&lt;/math&gt; is the "standard" generating functional for the n-particle Green functions.

The Wick ordering of effective interaction with respect to Green function &lt;math&gt;D&lt;/math&gt; can be defined by

&lt;math&gt;\mathcal{W}[\eta ,\eta ^{+}]=\exp(-\Delta _D)\mathcal{V}[\eta ,\eta ^{+}]&lt;/math&gt;.

where &lt;math&gt;\Delta=D \delta^2 /(\delta \eta \delta \eta^ {+})&lt;/math&gt; is the Laplacian in the field space. This operation is similar to [[Normal order]] and excludes from the interaction all possible terms, formed by a convolution of source fields with respective Green function D. Introducing some cutoff &lt;math&gt;\Lambda&lt;/math&gt; the Polchinskii equation

&lt;math&gt;\frac{\partial }{{\partial \Lambda }}{{V}_\Lambda }(\psi ) = -{\dot \Delta _{{G_{0,\Lambda }}}}{{V}_\Lambda }(\psi ) + \Delta _{{{\dot G}_{0,\Lambda }}}^{12}\mathcal {V}_\Lambda ^{(1)}\mathcal {V}_\Lambda ^{(2)}&lt;/math&gt;

takes the form of the Wick-ordered equation

&lt;math&gt;{\partial _\Lambda }{\mathcal {W}_\Lambda } = -{\Delta _{{{\dot D}_\Lambda } + {{\dot G}_{0,\Lambda }}}}{\mathcal { W}_\Lambda } + {e^{-\Delta _{{D_\Lambda }}^{12}}}\Delta _{{{\dot G}_{0,\Lambda }}}^{12}\mathcal {W}_\Lambda ^{(1)}\mathcal {W}_\Lambda ^{(2)}&lt;/math&gt;

where

&lt;math&gt;\Delta _{{{\dot G}_{0,\Lambda }}}^{12}\mathcal {V}_\Lambda ^{(1)}\mathcal {V}_\Lambda ^{(2)}=\frac{1}{2}\left( {\frac{{\delta {{V}_\Lambda }(\psi )}}{{\delta \psi }},{{\dot G}_{0,\Lambda }}\frac{{\delta {{V}_\Lambda }(\psi )}}{{\delta \psi }}} \right)&lt;/math&gt;

==Applications==

The method was applied to numerous problems in physics, e.g.: 
* In [[statistical field theory]], FRG provided a unified picture of [[phase transitions]] in classical linear &lt;math&gt;O(N)&lt;/math&gt;-symmetric scalar theories in different dimensions &lt;math&gt;d&lt;/math&gt;, including critical exponents for &lt;math&gt;d=3&lt;/math&gt; and the Berezinskii-Kosterlitz-Thouless phase transition for &lt;math&gt;d=2&lt;/math&gt;, &lt;math&gt;N=2&lt;/math&gt;.
* In gauge quantum field theory, FRG was used, for instance, to investigate the chiral phase transition and infrared properties of QCD and its large-flavor extensions.
* In [[condensed matter physics]], the method proved to be successful to treat lattice models (e.g. the [[Hubbard model]] or frustrated magnetic systems), repulsive Bose gas, BEC/BCS crossover for two-component Fermi gas, [[Kondo effect]], disordered systems and nonequlibrium phenomena.
* Application of FRG to gravity provided arguments in favor of nonperturbative renormalizability of [[quantum gravity]] in four spacetime dimensions, known as the [[asymptotic safety]] scenario.
* In mathematical physics FRG was used to prove renormalizability of different field theories.

==See also==

* [[Renormalization group]]
* [[Renormalization]]
* [[Critical phenomena]]
* [[Scale invariance]]
* [[Asymptotic safety in quantum gravity]]

== References ==

===Papers===

*{{Citation
 | last=Wetterich |first=C.
 | title= Exact evolution equation for the effective potential
 | journal=Phys. Lett. B
 | volume=301
 |issue=1
 | year=1993
 | pages=90  &lt;!--- | arxiv=gr-qc/0404018 |id=---&gt;
 | doi=10.1016/0370-2693(93)90726-X

 |bibcode = 1993PhLB..301...90W | arxiv=1710.05815}}
*{{Citation
 | last=Morris |first=T. R.
 | title= The Exact renormalization group and approximate solutions
 | journal= Int. J. Mod. Phys. A
 | volume=A
 |issue=14
 | year=1994
 | pages=2411–2449
 | arxiv=hep-ph/9308265
 | doi=10.1142/S0217751X94000972
 | bibcode = 1994IJMPA...9.2411M }}
*{{Citation
 | last=Polchinski |first=J.
 | title=  Renormalization and Effective Lagrangians
 | journal=Nucl. Phys. B
 | volume=231
 | year=1984
 | pages=269  &lt;!--- | arxiv=gr-qc/0404018 |id=---&gt;
 | doi=10.1016/0550-3213(84)90287-6
 | issue=2
 |bibcode = 1984NuPhB.231..269P }}

*{{Citation
 | last=Reuter |first=M.
 | title=   Nonperturbative evolution equation for quantum gravity
 | journal=Phys. Rev. D
 | volume=57
 | year=1998
 | pages=971–985
 | arxiv=hep-th/9605030 | doi=10.1103/PhysRevD.57.971
 | issue=2
 |bibcode = 1998PhRvD..57..971R |citeseerx=10.1.1.263.3439
 }}
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using&lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

===Pedagogic reviews===

*{{Citation
 |author1=J. Berges |author2=N. Tetradis |author3=C. Wetterich | title= Non-perturbative renormalization flow in quantum field theory and statistical mechanics
 | journal=Phys. Rep.
 | volume=363
 | year=2002
 | pages=223–386
 | arxiv=hep-ph/0005122
 | doi=10.1016/S0370-1573(01)00098-9
 | issue=4–6 |bibcode = 2002PhR...363..223B }}

*{{Citation
 | last=J. Polonyi
 | title= Lectures on the functional renormalization group method
 | journal=Central Eur. J. Phys.
 | volume=1
 | year=2003
 | pages=1–71
 | arxiv=hep-th/0110026 | doi=10.2478/BF02475552
 | first1=Janos
 |bibcode = 2003CEJPh...1....1P }}

*{{Cite book
 | last=H.Gies
 | title= Introduction to the functional RG and applications to gauge theories
 | year=2006
 | arxiv=hep-ph/0611146
 | doi=10.1007/978-3-642-27320-9_6
 | journal=Lecture Notes in Physics
 | volume= 852
 | pages=287–348| isbn= 978-3-642-27319-3
 }}

*{{Cite book
 | last=B. Delamotte
 | title= An introduction to the nonperturbative renormalization group
 | year=2007
 | arxiv=cond-mat/0702365
 | doi=10.1007/978-3-642-27320-9_2
 | journal=Lecture Notes in Physics
 | volume= 852
 | pages=49–132| isbn= 978-3-642-27319-3
 }}

*{{Citation
 | last=M. Salmhofer, and C. Honerkamp
 | title= Fermionic renormalization group flows: Technique and theory
 | journal=Prog. Theor. Phys.
 | volume=105
 | issue= 1
 | year=2001
 | pages=1
 | doi=10.1143/PTP.105.1
 | first1=Manfred
 | last2=Honerkamp
 | first2=Carsten
 |bibcode = 2001PThPh.105....1S }}

*{{cite arXiv
 | last=M. Reuter and F. Saueressig
 | title= Functional Renormalization Group Equations, Asymptotic Safety, and Quantum Einstein Gravity
 | year=2007
 | eprint=0708.1317
 | author2=Frank Saueressig }}

&lt;!---== External links ==
* [http://www.example.com/ example.com] ---&gt;

[[Category:Quantum field theory]]
[[Category:Statistical mechanics]]
[[Category:Renormalization group]]
[[Category:Scaling symmetries]]
[[Category:Fixed points (mathematics)]]</text>
      <sha1>0e03u6s2rxjglquye1362csfk1js18q</sha1>
    </revision>
  </page>
  <page>
    <title>Hans Wussing</title>
    <ns>0</ns>
    <id>34728523</id>
    <revision>
      <id>812983085</id>
      <parentid>721293125</parentid>
      <timestamp>2017-12-01T01:17:52Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.1) ([[User:Balon Greyjoy|Balon Greyjoy]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6370">[[File:Hans Wußing.jpg|thumb|Hans Wussing.]]
'''Hans-Ludwig Wußing''' (October 15, 1927 in [[Waldheim, Saxony|Waldheim]] &amp;ndash; April 26, 2011 in [[Leipzig]]) was a German [[historian of mathematics]] and [[historian of science|science]].

==Life==
Wussing graduated from high school, and from 1947 to 52 studied mathematics and physics at the [[University of Leipzig]]. [[Ernst Hölder]] was one of his teachers. In 1952 he took the state examination, and received his doctorate in 1957. His dissertation was on embedding [[finite group]]s. From 1956 to 1966 he was assistant at the Karl-Sudhoff Institute for the History of Medicine and Science at the University of Leipzig. He qualified as a professor there in 1966 with a ground-breaking work on the genesis of the abstract group concept. From 1966 to 1968 was Wußing lecturer, and from 1968 professor of [[history of mathematics]] and [[history of science|natural sciences]]. In 1969 his book ''Genesis of the Abstract Group Concept'' was published in German; it was translated by Abe Shenitzer and Hardy Grant in 1984. B.H. Newman wrote in [[Mathematical Reviews]] (see external link below) that Wussing's "main thesis, ably defended and well documented, is that the roots of the abstract notion of a group do not lie, as frequently assumed, only in the theory of algebraic equations, but they are also to be found in the geometry and in the theory of numbers at the end of the 18th and the first half of the 19th centuries". Newman comments that Wussings [[bibliography]] is "oddly arranged". Newman also notes that a broader perspective on the topic would require reading the works of [[George Abram Miller]].

Promoted from a department head at the Karl-Sudhoff Institute, he headed the institute from 1977 to 1982. In 1971 he became a corresponding member of the [[International Academy of the History of Science]], and a regular member in 1981. In 1984 he became a full member of the [[Saxon Academy of Sciences]] in Leipzig. Wussing retired in 1992.

Wussing is the author of numerous scientific historical publications, the author of many mathematicians' biographies, and co-editor of several series of publications, including biographies in the Teubner Verlag, and several volumes in the series ''Klassiker der Exakten Wissenschaften'' (Ostwald's Classics of the Exact Sciences), in particular on [[Euler]]'s work on functional theory, [[Gauss' diary]], and [[Felix Klein]]'s [[Erlangen program]].
In 1993 he was awarded the [[Kenneth O. May Prize]]. Until 1998 he was Chairman of the Commission for the History of Science at the Saxon Academy of Sciences. He was also involved in the publication of Johann Christian Poggendorff's ''Biographical and Literary Pocket Dictionary of the History of Exact Sciences.

==Writings==
* 1962: ''Mathematics in the period of slave society'', Leipzig, Teubner, and Aachen, Mayer.
* 1969: ''Die Genesis des abstrackten Gruppenbegriffes. Ein Beitrag zur Entstehungsgeschichte der abstrakten Gruppentheorie''.&lt;ref&gt;B.H. Newman (1969) [http://www.ams.org/mathscinet/pdf/282776.pdf Review of ''Genesis of the Abstract Group Concept'']{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }} in [[Mathematical Reviews]]&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Waterhouse, William C.|authorlink=William C. Waterhouse|title=Review: ''Lebesgue's Theory of Integration'', by Thomas Hawkins; ''A History of Vector Analysis'', by Michael J. Crowe; ''The Development of the Foundations of Mathematical Analysis from Euler to Riemann'', by I. Grattan-Guinness; and ''Die Genesis des abstrakten Gruppenbegriffes'', by Hans Wussing|journal=Bull. Amer. Math. Soc.|year=1972|volume=78|issue=3|pages=385–391|url=http://www.ams.org/journals/bull/1972-78-03/S0002-9904-1972-12909-4/S0002-9904-1972-12909-4.pdf|doi=10.1090/S0002-9904-1972-12909-4}}&lt;/ref&gt;
** 1984: ''The Genesis of the abstract group concept'', [[MIT Press]] 
* 1973: ''[[Nicholas Copernicus]]'', Leipzig, Urania
* 1974: ''[[Carl Friedrich Gauss]]'', Leipzig, Teubner, second Edition 1976
* 1975: (editor with Wolfgang Arnold) ''Biographien bedeutender Mathematiker – eine Sammlung von Biographien'', 4th edition, Berlin, Volk und Wissen 1989.
* 1977: ''[[Isaac Newton]]'', Leipzig, Teubner, 4th Edition 1990
* 1987: Editor: ''History of Science'', Cologne, Aulis Verlag.
* 1989: ''Vorlesungen der Geschichte der Mathematik'', [[Deutscher Verlag der Wissenschaften]].
* 1989: ''Adam Ries'', Leipzig, Teubner, 1992, 3rd, revised and expanded edition, Leipzig Edition on Gutenbergplatz 2009 (Eagle 033)&lt;ref&gt;H. Wussing (1989, 1992, 2009) [https://books.google.ca/books?id=1bsEpR6P3p8C&amp;pg=PA4 Adam Ries], [[Google Books]] preview&lt;/ref&gt;
* 1992: (editor) ''Fachlexikon ABC Forscher und Erfinder'', Frankfurt, [[Verlag Harri Deutsch]].
* 2002: ''The major renovation – on the history of the scientific revolution'', [[Birkhäuser]].
* 2003: (with H. W.Alten, A. Djafari Naini, Folkerts, H. Schlosser, K.-H. Chimneys): ''4000 years Algebra'', Springer Verlag.
* 2008,9: ''Mathematics 6000 years – a cultural and historical journey through time'', 2 vols, Springer
* 2009: Eagle Guide ''From Gauss to [[Henri Poincaré|Poincaré]] – Mathematics and [[Industrial Revolution]]'', Leipzig Edition on Gutenbergplatz (Eagle 037)
* 2010: Eagle Guide ''From [[Leonardo da Vinci]] and [[Galileo Galilei]]. Mathematics and Renaissance'', Leipzig Edition on Gutenbergplatz (Eagle 041)
* 2011: ''[[Carl Friedrich Gauss]]''. Biography and document, Leipzig Edition on Gutenbergplatz (Eagle 051)
** The 60-page appendix "CF Gauss and BG Teubner" for the 200th anniversary of its founding on February 21, 1811, in Leipzig.

==References==
{{reflist}}
* {{cite journal | last1 = Folkerts | first1 = Menso | year = 2007 | title = Hans Wussing | url = | journal = Journal of History and Ethics of Natural Sciences, Technology, and Medicine | volume = 15 | issue = 4| pages = 295–7 | doi=10.1007/s00048-007-0272-z}}

== External links==
* [http://genealogy.math.ndsu.nodak.edu/id.php?id=60103 Entry in the Mathematics Genealogy Project]

{{Kenneth O. May Prize laureates}}

{{Authority control}}

{{DEFAULTSORT:Wussing, Hans}}
[[Category:1927 births]]
[[Category:2011 deaths]]
[[Category:German schoolteachers]]
[[Category:German mathematicians]]
[[Category:Historians of mathematics]]
[[Category:Leipzig University alumni]]</text>
      <sha1>ha1co93vo1pbk70cm2iqdkw0njfkwre</sha1>
    </revision>
  </page>
  <page>
    <title>Hexadecimal</title>
    <ns>0</ns>
    <id>13263</id>
    <revision>
      <id>868317058</id>
      <parentid>867313628</parentid>
      <timestamp>2018-11-11T12:24:50Z</timestamp>
      <contributor>
        <username>Citizen Canine</username>
        <id>33426808</id>
      </contributor>
      <minor/>
      <comment>/* Etymology */ delete duplicate word</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="52930">{{redirect|Sexadecimal|base 60|Sexagesimal}}
{{Numeral systems}}
In [[mathematics]] and [[computing]], '''hexadecimal''' (also '''[[Radix|base]] {{num|16}}''', or '''hex''') is a [[positional notation|positional]] [[numeral system]] with a [[radix]], or base, of 16. It uses sixteen distinct symbols, most often the symbols '''0'''–'''9''' to represent values zero to nine, and '''A'''–'''F''' (or alternatively '''a'''–'''f''') to represent values ten to fifteen.&lt;!--YES, NOT SIXTEEN. The largest digit in base sixteen represents fifteen, just as the largest digit in base ten represents nine.--&gt;

Hexadecimal numerals are widely used by computer system designers and programmers, as they provide a more human-friendly representation of [[binary code|binary-coded]] values. Each hexadecimal digit represents four [[bit|binary digits]], also known as a [[nibble]], which is half a [[byte]]. For example, a single byte can have values ranging from 0000 0000 to 1111 1111 in binary form, which can be more conveniently represented as 00 to FF in hexadecimal.

In mathematics, a subscript is typically used to specify the [[radix]].  For example the decimal value {{val|10995|fmt=commas}} would be expressed in hexadecimal as {{hexadecimal|10995}}.  In programming, a number of notations are used to support hexadecimal representation, usually involving a prefix or suffix.  The prefix &lt;code&gt;0x&lt;/code&gt; is used in [[C (programming language)|C]] and related languages, which would denote this value by 0x{{hexadecimal|10995|no}}.

Hexadecimal is used in the transfer encoding '''Base16''', in which each byte of the plaintext is broken into two 4-bit values and represented by two hexadecimal digits.

==Representation==

===Written representation===

====Using 0–9 and A–F====
{{Hexadecimal table}}
In contexts where the [[radix|base]] is not clear, hexadecimal numbers can be ambiguous and confused with numbers expressed in other bases. There are several conventions for expressing values unambiguously. A numerical subscript (itself written in decimal) can give the base explicitly: 159&lt;sub&gt;10&lt;/sub&gt; is decimal 159; 159&lt;sub&gt;16&lt;/sub&gt; is hexadecimal 159, which is equal to 345&lt;sub&gt;10&lt;/sub&gt;. Some authors prefer a text subscript, such as 159&lt;sub&gt;decimal&lt;/sub&gt; and 159&lt;sub&gt;hex&lt;/sub&gt;, or 159&lt;sub&gt;d&lt;/sub&gt; and 159&lt;sub&gt;h&lt;/sub&gt;.

In linear text systems, such as those used in most computer programming environments, a variety of methods have arisen:&lt;!--
 * * * These are ordered from most likely to be encountered by lay people
 * * * to least likely to be encountered by lay people
 * * * --&gt;
* In [[URI]]s (including [[URL]]s), [[character encoding|character codes]] are written as hexadecimal pairs prefixed with &lt;code&gt;%&lt;/code&gt;: &lt;code&gt;&lt;nowiki&gt;http://www.example.com/name%20with%20spaces&lt;/nowiki&gt;&lt;/code&gt; where &lt;code&gt;%20&lt;/code&gt; is the [[Space (punctuation)#Space characters and digital typography|space (blank)]] character, [[ASCII]] code point 20 in hex, 32 in decimal.
* In [[XML]] and [[XHTML]], characters can be expressed as hexadecimal [[numeric character reference]]s using the notation &lt;code&gt;&amp;amp;#x''code'';&lt;/code&gt;, where the ''x'' denotes that ''code'' is a hex code point (of 1- to 6-digits) assigned to the character in the [[Unicode]] standard. Thus &lt;code&gt;&amp;amp;#x2019;&lt;/code&gt; represents the right single quotation mark (’), Unicode code point number 2019 in hex, 8217 (thus &lt;code&gt;&amp;amp;#8217;&lt;/code&gt; in decimal).&lt;ref&gt;{{cite web|url=https://www.unicode.org/charts/PDF/U2000.pdf|title=The Unicode Standard, Version 7|last=|first=|date=|website=Unicode|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;
* In the [[Unicode]] standard, a character value is represented with &lt;code&gt;U+&lt;/code&gt; followed by the hex value, e.g. &lt;code&gt;U+20AC&lt;/code&gt; is the [[Euro sign]] (€).
* [[Web colors|Color references]] in HTML, [[Cascading Style Sheets|CSS]] and [[X window system|X Window]] can be expressed with six hexadecimal digits (two each for the red, green and blue components, in that order) prefixed with &lt;code&gt;#&lt;/code&gt;: white, for example, is represented &lt;code&gt;#FFFFFF&lt;/code&gt;.&lt;ref&gt;{{cite web |url=http://www.web-colors-explained.com/hex.php |title=Hexadecimal web colors explained}}&lt;/ref&gt; CSS allows 3-hexdigit abbreviations with one hexdigit per component: #FA3 abbreviates #FFAA33 (a golden orange: {{color box|#FA3}}).
* {{anchor|_nix}}[[*nix|Unix]] (and related) shells, [[AT&amp;T Corporation|AT&amp;T]] assembly language and likewise the [[C (programming language)|C programming language]] (and its syntactic descendants such as [[C++]], [[C Sharp (programming language)|C#]], [[D (programming language)|D]], [[Java (programming language)|Java]], [[JavaScript]], [[Python (programming language)|Python]] and [[Windows PowerShell]]) use the prefix &lt;code&gt;0x&lt;/code&gt; for numeric constants represented in hex: &lt;code&gt;0x5A3&lt;/code&gt;. Character and string constants may express character codes in hexadecimal with the prefix &lt;code&gt;\x&lt;/code&gt; followed by two hex digits: &lt;code&gt;'\x1B'&lt;/code&gt; represents the [[Escape character|Esc]] control character; &lt;code&gt;"\x1B[0m\x1B[25;1H"&lt;/code&gt; is a string containing 11 characters (plus a trailing NUL to mark the end of the string) with two embedded Esc characters.&lt;ref&gt;The string &lt;code&gt;"\x1B[0m\x1B[25;1H"&lt;/code&gt; specifies the character sequence &lt;tt&gt;Esc [ 0 m Esc [ 2 5 ; 1 H Nul&lt;/tt&gt;. These are the escape sequences used on an [[ANSI escape code|ANSI terminal]] that reset the character set and color, and then move the cursor to line 25.&lt;/ref&gt; To output an integer as hexadecimal with the [[printf]] function family, the format conversion code &lt;code&gt;%X&lt;/code&gt; or &lt;code&gt;%x&lt;/code&gt; is used.
* In [[MIME]] (e-mail extensions) [[quoted-printable]] encoding, characters that cannot be represented as literal [[ASCII]] characters are represented by their codes as two hexadecimal digits (in ASCII) prefixed by an ''equal to'' sign &lt;code&gt;=&lt;/code&gt;, as in &lt;code&gt;Espa=F1a&lt;/code&gt; to send "España" (Spain). (Hexadecimal F1, equal to decimal 241, is the code number for the lower case n with tilde in the ISO/IEC 8859-1 character set.)
* In Intel-derived [[assembly language]]s and Modula-2,&lt;ref&gt;{{cite web |title=Modula-2 - Vocabulary and representation |url=http://modula2.org/reference/vocabulary.php |website=Modula -2 |access-date=1 November 2015}}&lt;/ref&gt; hexadecimal is denoted with a suffixed &lt;tt&gt;H&lt;/tt&gt; or &lt;tt&gt;h&lt;/tt&gt;: &lt;code&gt;FFh&lt;/code&gt; or &lt;code&gt;05A3H&lt;/code&gt;. Some implementations require a leading zero when the first hexadecimal digit character is not a decimal digit, so one would write &lt;code&gt;0FFh&lt;/code&gt; instead of &lt;code&gt;FFh&lt;/code&gt;
* Other assembly languages ([[MOS Technology 6502|6502]], [[Motorola]]), [[Pascal (programming language)|Pascal]], [[Object Pascal|Delphi]], some versions of [[BASIC]] ([[Commodore BASIC|Commodore]]), [[GameMaker Studio|GameMaker Language]], [[Godot (game engine)|Godot]] and [[Forth (programming language)|Forth]] use &lt;code&gt;$&lt;/code&gt; as a prefix: &lt;code&gt;$5A3&lt;/code&gt;.
* Some assembly languages (Microchip) use the notation &lt;code&gt;H'ABCD'&lt;/code&gt; (for ABCD&lt;sub&gt;16&lt;/sub&gt;). Similarly, [[Fortran 95 language features|Fortran 95]] uses Z'ABCD'.
* [[Ada (programming language)|Ada]] and [[VHDL]] enclose hexadecimal numerals in based "numeric quotes": &lt;code&gt;16#5A3#&lt;/code&gt;. For bit vector constants [[VHDL]] uses the notation &lt;code&gt;x"5A3"&lt;/code&gt;.&lt;ref&gt;The [http://www.eng.auburn.edu/department/ee/mgc/vhdl.html#numbers VHDL MINI-REFERENCE: VHDL IDENTIFIERS, NUMBERS, STRINGS, AND EXPRESSIONS]&lt;/ref&gt;
* [[Verilog]] represents hexadecimal constants in the form &lt;code&gt;8'hFF&lt;/code&gt;, where 8 is the number of bits in the value and FF is the hexadecimal constant.
* The [[Smalltalk]] language uses the prefix &lt;code&gt;16r&lt;/code&gt;: &lt;code&gt;16r5A3&lt;/code&gt;
* [[PostScript]] and the [[Bourne shell]] and its derivatives denote hex with prefix &lt;code&gt;16#&lt;/code&gt;: &lt;code&gt;16#5A3&lt;/code&gt;. For PostScript, binary data (such as image [[pixel]]s) can be expressed as unprefixed consecutive hexadecimal pairs: &lt;code&gt;AA213FD51B3801043FBC&lt;/code&gt;...
* [[Common Lisp]] uses the prefixes &lt;code&gt;#x&lt;/code&gt; and &lt;code&gt;#16r&lt;/code&gt;. Setting the variables *read-base*&lt;ref&gt;{{cite web |title=*read-base* variable in Common Lisp |url=http://www.lispworks.com/documentation/HyperSpec/Body/v_rd_bas.htm}}&lt;/ref&gt; and *print-base*&lt;ref&gt;{{cite web |title=*print-base* variable in Common Lisp |url=http://www.lispworks.com/documentation/HyperSpec/Body/v_pr_bas.htm#STprint-baseST}}&lt;/ref&gt; to 16 can also be used to switch the reader and printer of a Common Lisp system to Hexadecimal number representation for reading and printing numbers. Thus Hexadecimal numbers can be represented without the #x or #16r prefix code, when the input or output base has been changed to 16.
* [[MSX BASIC]],&lt;ref&gt;[http://www.atarimagazines.com/compute/issue56/107_1_MSX_IS_COMING.php MSX is Coming — Part 2: Inside MSX] [[Compute!]], issue 56, January 1985, p. 52&lt;/ref&gt; [[QuickBASIC]], [[FreeBASIC]] and [[Visual Basic]] prefix hexadecimal numbers with &lt;code&gt;&amp;amp;H&lt;/code&gt;: &lt;code&gt;&amp;amp;H5A3&lt;/code&gt;
* [[BBC BASIC]] and [[Locomotive BASIC]] use &lt;code&gt;&amp;amp;&lt;/code&gt; for hex.&lt;ref&gt;BBC BASIC programs are not fully portable to [[Microsoft BASIC]] (without modification) since the latter takes &lt;code&gt;&amp;amp;&lt;/code&gt; to prefix [[octal]] values. (Microsoft BASIC primarily uses &lt;code&gt;&amp;amp;O&lt;/code&gt; to prefix octal, and it uses &lt;code&gt;&amp;amp;H&lt;/code&gt; to prefix hexadecimal, but the ampersand alone yields a default interpretation as an octal prefix.&lt;/ref&gt;
* [[TI-89]] and 92 series uses a &lt;code&gt;0h&lt;/code&gt; prefix: &lt;code&gt;0h5A3&lt;/code&gt;
* [[ALGOL 68]] uses the prefix &lt;code&gt;16r&lt;/code&gt; to denote hexadecimal numbers: &lt;code&gt;16r5a3&lt;/code&gt;.  Binary, quaternary (base-4) and octal numbers can be specified similarly.
* The most common format for hexadecimal on IBM mainframes ([[zSeries]]) and midrange computers ([[IBM System i]]) running the traditional OS's ([[z/OS|zOS]], [[VSE (operating system)|zVSE]], [[z/VM|zVM]], [[Transaction Processing Facility|TPF]], [[IBM i]]) is &lt;code&gt;X'5A3'&lt;/code&gt;, and is used in Assembler, [[PL/I]], [[COBOL]], [[Job Control Language|JCL]], scripts, commands and other places. This format was common on other (and now obsolete) IBM systems as well.  Occasionally quotation marks were used instead of apostrophes.
* [[Donald Knuth]] introduced the use of a particular typeface to represent a particular radix in his book ''The TeXbook''.&lt;ref&gt;Donald E. Knuth. ''The TeXbook'' ([[Computers and Typesetting]], Volume A). Reading, Massachusetts: Addison–Wesley, 1984. {{isbn|0-201-13448-9}}. The [http://www.ctan.org/tex-archive/systems/knuth/tex/texbook.tex source code of the book in TeX] {{webarchive|url=https://web.archive.org/web/20070927224129/http://www.ctan.org/tex-archive/systems/knuth/tex/texbook.tex |date=2007-09-27 }} (and a required set of macros [ftp://tug.ctan.org/pub/tex-archive/systems/knuth/lib/manmac.tex CTAN.org]) is available online on [[CTAN]].&lt;/ref&gt; Hexadecimal representations are written there in a typewriter typeface: &lt;tt&gt;5A3&lt;/tt&gt;
* Any [[IPv6 address]] can be written as eight groups of four hexadecimal digits (sometimes called [[hextet (computing)|hextet]]s), where each group is separated by a colon (&lt;code&gt;:&lt;/code&gt;). This, for example, is a valid IPv6 address: 2001:0db8:85a3:0000:0000:8a2e:0370:7334; this can be abbreviated as 2001:db8:85a3::8a2e:370:7334. By contrast, [[IPv4 address]]es are usually written in decimal.
* [[Globally unique identifier]]s are written as thirty-two hexadecimal digits, often in unequal hyphen-separated groupings, for example &lt;code&gt;{3F2504E0-4F89-41D3-9A0C-0305E82C3301}&lt;/code&gt;.

There is no universal convention to use lowercase or uppercase for the letter digits, and each is prevalent or preferred in particular environments by community standards or convention.

===History of written representations===

[[Image:Bruce Martin hexadecimal notation proposal.png|thumb|Bruce Alan Martin's hexadecimal notation proposal&lt;ref name="Martin_1968"/&gt;]]
The use of the letters ''A'' through ''F'' to represent the digits above 9 was not universal in the early history of computers.
* During the 1950s, some installations{{which|date=August 2017}} favored using the digits 0 through 5 with an [[overline]] to denote the values 10–15 as {{overline|0}}, {{overline|1}}, {{overline|2}}, {{overline|3}}, {{overline|4}} and {{overline|5}}.
* The [[SWAC (computer)|SWAC]] (1950)&lt;ref name="Savard_2018_CA"/&gt; and [[Bendix G-15]] (1956)&lt;ref name="Bendix"/&gt;&lt;ref name="Savard_2018_CA"/&gt; computers used the lowercase letters ''u'', ''v'', ''w'', ''x'', ''y'' and ''z'' for the values 10 to 15.
* The [[ILLIAC I]] (1952) computer used the uppercase letters ''K'', ''S'', ''N'', ''J'', ''F'' and ''L'' for the values 10 to 15.&lt;ref name="Illiac-I"/&gt;&lt;ref name="Savard_2018_CA"/&gt;
* The Librascope [[LGP-30]] (1956) used the letters ''F'', ''G'', ''J'', ''K'', ''Q'' and ''W'' for the values 10 to 15.&lt;ref name="RP_1957_LGP-30"/&gt;&lt;ref name="Savard_2018_CA"/&gt;
* The [[Honeywell]] [[Datamatic D-1000]] (1957) used the lowercase letters ''b'', ''c'', ''d'', ''e'', ''f'', and ''g'' whereas the [[Elbit]]&amp;nbsp;100 (1967) used the uppercase letters ''B'', ''C'', ''D'', ''E'', ''F'' and ''G'' for the values 10 to 15.&lt;ref name="Savard_2018_CA"/&gt;
* The [[Monrobot XI]] (1960) used the letters ''S'', ''T'', ''U'', ''V'', ''W'' and ''X'' for the values 10 to 15.&lt;ref name="Savard_2018_CA"/&gt;
* The [[NEC]] [[parametron]] computer {{ill|NEAC 1103|ja|NEAC}} (1960) used the letters ''D'', ''G'', ''H'', ''J'', ''K'' (and possibly ''V'') for values 10–15.&lt;ref name="NEC_1960_NEAC-1103"&gt;{{cite book |title=NEC Parametron Digital Computer Type NEAC-1103 |publisher=[[Nippon Electric Company Ltd.]] |location=Tokyo, Japan |id=Cat. No. 3405-C |date=1960 |url=http://archive.computerhistory.org/resources/text/NEC/NEC.1103.1958102646285.pdf |access-date=2017-05-31 |dead-url=no |archive-url=https://web.archive.org/web/20170531112850/http://archive.computerhistory.org/resources/text/NEC/NEC.1103.1958102646285.pdf |archive-date=2017-05-31}}&lt;/ref&gt;
* The Pacific Data Systems&amp;nbsp;1020 (1964) used the letters ''L'', ''C'', ''A'', ''S'', ''M'' and ''D'' for the values 10 to 15.&lt;ref name="Savard_2018_CA"/&gt;
* New numeric symbols and names were introduced in the [[Bibi-binary]] notation by [[Boby Lapointe]] in 1968. This notation did not become very popular. 
* [[Bruce Alan Martin]] of [[Brookhaven National Laboratory]] considered the choice of A–F "ridiculous". In a 1968 letter to the editor of the [[Communications of the ACM|CACM]], he proposed an entirely new set of symbols based on the bit locations, which did not gain much acceptance.&lt;ref name="Martin_1968"&gt;{{cite journal | title=Letters to the editor: On binary notation | first=Bruce Alan | last=Martin | publisher=[[Associated Universities Inc.]] | work=[[Communications of the ACM]] | volume=11 | issue=10 | date=October 1968 | page=658 | doi=10.1145/364096.364107}}&lt;/ref&gt;
* Soviet [[programmable calculator]]s [[Elektronika B3-34|Б3-34]] (1980) and similar used the symbols "−", "L", "C", "Г", "E", "&amp;ensp;" (space) for the values 10 to 15 on their displays.{{cn|date=August 2017}}
* [[Seven-segment display]] decoder chips used various schemes for outputting values above nine. The [[7400 series|Texas Instruments 7446/7447/7448/7449 and 74246/74247/74248/74249]] use truncated versions of "2", "3", "4", "5" and "6" for the values 10 to 14. Value 15 (1111 binary) was blank.&lt;ref name="TI_BCD-7SEGDEC"&gt;{{cite |title=BCD-to-Seven-Segment Decoders/Drivers: SN54246/SN54247/SN54LS247, SN54LS248 SN74246/SN74247/SN74LS247/SN74LS248 |date=March 1988 |orig-year=March 1974 |id=SDLS083 |publisher=[[Texas Instruments]] |url=http://www.ralphselectronics.com/ProductImages/SEMI-SN74247N.PDF |access-date=2017-03-30 |dead-url=no |archive-url=https://web.archive.org/web/20170329223343/http://www.ralphselectronics.com/ProductImages/SEMI-SN74247N.PDF |archive-date=2017-03-29 |quote=[…] They can be used interchangeable in present or future designs to offer designers a choice between two indicator fonts. The '46A, '47A, 'LS47, and 'LS48 compose the 6 and the 9 without tails and the '246, '247, 'LS247, and 'LS248 compose the 6 and the 0 with tails. Composition of all other characters, including display patterns for BCD inputs above nine, is identical. […] Display patterns for BCD input counts above 9 are unique symbols to authenticate input conditions. […]}}&lt;/ref&gt;

===Verbal and digital representations===
There are no traditional numerals to represent the quantities from ten to fifteen – letters are used as a substitute – and most [[Europe]]an languages lack non-decimal names for the numerals above ten. Even though English has names for several non-decimal powers (''[[2 (number)|pair]]'' for the first [[binary numeral system|binary]] power, ''[[20 (number)|score]]'' for the first [[vigesimal]] power, ''[[dozen]]'', ''[[Gross (unit)|gross]]'' and ''[[great gross]]'' for the first three [[duodecimal]] powers), no English name describes the hexadecimal powers (decimal 16, 256, 4096, 65536, ...&amp;nbsp;). Some people read hexadecimal numbers digit by digit like a phone number, or using the [[ICAO spelling alphabet|NATO phonetic alphabet]], the [[Joint Army/Navy Phonetic Alphabet]], or a similar ad hoc system.

[[File:Hexadecimal-counting.jpg|right|thumb|Hexadecimal finger-counting scheme]]
Systems of counting on [[Digit (anatomy)|digits]] have been devised for both binary and hexadecimal.
[[Arthur C. Clarke]] suggested using each finger as an on/off bit, allowing finger counting from zero to 1023&lt;sub&gt;10&lt;/sub&gt; on ten fingers.&lt;ref&gt;{{cite book |last1=Clarke |first1=Arthur |last2=Pohl |first2=Frederik |title=The Last Theorem |date=2008 |publisher=Ballantine |isbn=978-0007289981 |page=91}}&lt;/ref&gt; Another system for counting up to FF&lt;sub&gt;16&lt;/sub&gt; (255&lt;sub&gt;10&lt;/sub&gt;) is illustrated on the right.

===Signs===
The hexadecimal system can express negative numbers the same way as in decimal: −2A to represent −42&lt;sub&gt;10&lt;/sub&gt; and so on.

Hexadecimal can also be used to express the exact bit patterns used in the [[central processing unit|processor]], so a sequence of hexadecimal digits may represent a [[signedness|signed]] or even a [[floating point]] value. This way, the negative number −42&lt;sub&gt;10&lt;/sub&gt; can be written as FFFF&amp;nbsp;FFD6 in a 32-bit [[Processor register|CPU register]] (in [[two's-complement]]), as C228&amp;nbsp;0000 in a 32-bit [[Floating point unit|FPU]] register or C045&amp;nbsp;0000&amp;nbsp;0000&amp;nbsp;0000 in a 64-bit FPU register (in the [[IEEE floating-point standard]]).

===Hexadecimal exponential notation===
Just as decimal numbers can be represented in [[exponential notation]], so too can hexadecimal numbers.  By convention, the letter ''P'' (or ''p'', for "power") represents ''times two raised to the power of'', whereas ''E'' (or ''e'') serves a similar purpose in decimal as part of the [[E notation]].  The number after the ''P'' is ''decimal'' and represents the ''binary'' exponent.

Usually the number is normalised so that the leading hexadecimal digit is 1 (unless the value is exactly 0).

Example: 1.3DEp42 represents {{math|1.3DE&lt;sub&gt;16&lt;/sub&gt; × 2&lt;sup&gt;42&lt;/sup&gt;}}.

Hexadecimal exponential notation is required by the [[IEEE 754-2008]] binary floating-point standard.
This notation can be used for floating-point literals in the [[C99]] edition of the [[C (programming_language)|C programming language]].&lt;ref&gt;{{cite web|url=http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=29237 |title=ISO/IEC 9899:1999 - Programming languages - C |publisher=Iso.org |date=2011-12-08 |accessdate=2014-04-08}}&lt;/ref&gt;
Using the ''%a'' or ''%A'' conversion specifiers, this notation can be produced by implementations of the ''[[printf]]'' family of functions following the C99 specification&lt;ref name="Rationale_2003_C"&gt;{{cite web |title=Rationale for International Standard - Programming Languages - C |version=5.10 |date=April 2003 |pages=52, 153–154, 159 |url=http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf |access-date=2010-10-17 |dead-url=no |archive-url=https://web.archive.org/web/20160606072228/http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf |archive-date=2016-06-06}}&lt;/ref&gt; and
[[Single UNIX Specification|Single Unix Specification]] (IEEE Std 1003.1) [[POSIX]] standard.&lt;ref name="printf_2013"&gt;{{cite web |title=dprintf, fprintf, printf, snprintf, sprintf - print formatted output |work=The Open Group Base Specifications |edition=Issue 7, IEEE Std 1003.1, 2013 |date=2013 |orig-year=2001 |author=The IEEE and The Open Group |url=http://pubs.opengroup.org/onlinepubs/9699919799/functions/printf.html |access-date=2016-06-21 |dead-url=no |archive-url=https://web.archive.org/web/20160621211105/http://pubs.opengroup.org/onlinepubs/9699919799/functions/printf.html |archive-date=2016-06-21}}&lt;/ref&gt;

==Conversion==

===Binary conversion===
Most computers manipulate binary data, but it is difficult for humans to work with the large number of digits for even a relatively small binary number. Although most humans are familiar with the base 10 system, it is much easier to map binary to hexadecimal than to decimal because each hexadecimal digit maps to a whole number of bits (4&lt;sub&gt;10&lt;/sub&gt;).
This example converts 1111&lt;sub&gt;2&lt;/sub&gt; to base ten. Since each [[Positional notation|position]] in a binary numeral can contain either a 1 or a 0, its value may be easily determined by its position from the right:
* 0001&lt;sub&gt;2&lt;/sub&gt; = 1&lt;sub&gt;10&lt;/sub&gt;
* 0010&lt;sub&gt;2&lt;/sub&gt; = 2&lt;sub&gt;10&lt;/sub&gt;
* 0100&lt;sub&gt;2&lt;/sub&gt; = 4&lt;sub&gt;10&lt;/sub&gt;
* 1000&lt;sub&gt;2&lt;/sub&gt; = 8&lt;sub&gt;10&lt;/sub&gt;
Therefore:
{|
|-
| 1111&lt;sub&gt;2&lt;/sub&gt;|| = 8&lt;sub&gt;10&lt;/sub&gt; + 4&lt;sub&gt;10&lt;/sub&gt; + 2&lt;sub&gt;10&lt;/sub&gt; + 1&lt;sub&gt;10&lt;/sub&gt;
|-
| &amp;nbsp;|| = 15&lt;sub&gt;10&lt;/sub&gt;
|}
With little practice, mapping 1111&lt;sub&gt;2&lt;/sub&gt; to F&lt;sub&gt;16&lt;/sub&gt; in one step becomes easy: see table in [[#Written representation|Written representation]]. The advantage of using hexadecimal rather than decimal increases rapidly with the size of the number. When the number becomes large, conversion to decimal is very tedious. However, when mapping to hexadecimal, it is trivial to regard the binary string as 4-digit groups and map each to a single hexadecimal digit.

This example shows the conversion of a binary number to decimal, mapping each digit to the decimal value, and adding the results.
{|
| (01011110101101010010)&lt;sub&gt;2&lt;/sub&gt;|| = 262144&lt;sub&gt;10&lt;/sub&gt; + 65536&lt;sub&gt;10&lt;/sub&gt; + 32768&lt;sub&gt;10&lt;/sub&gt; + 16384&lt;sub&gt;10&lt;/sub&gt; + 8192&lt;sub&gt;10&lt;/sub&gt; + 2048&lt;sub&gt;10&lt;/sub&gt; + 512&lt;sub&gt;10&lt;/sub&gt; + 256&lt;sub&gt;10&lt;/sub&gt; + 64&lt;sub&gt;10&lt;/sub&gt; + 16&lt;sub&gt;10&lt;/sub&gt; + 2&lt;sub&gt;10&lt;/sub&gt;
|-
| &amp;nbsp;|| = 387922&lt;sub&gt;10&lt;/sub&gt;
|}
Compare this to the conversion to hexadecimal, where each group of four digits can be considered independently, and converted directly:
{|
|-
| (01011110101101010010)&lt;sub&gt;2&lt;/sub&gt;|| = ||0101&lt;sub&gt;&amp;nbsp;&lt;/sub&gt;||1110&lt;sub&gt;&amp;nbsp;&lt;/sub&gt;||1011&lt;sub&gt;&amp;nbsp;&lt;/sub&gt;||0101&lt;sub&gt;&amp;nbsp;&lt;/sub&gt;||0010&lt;sub&gt;2&lt;/sub&gt;
|-
| &amp;nbsp;|| = || align="center" |5|| align="center" |E|| align="center" |B|| align="center" |5|| align="center" |2&lt;sub&gt;16&lt;/sub&gt;
|-
| &amp;nbsp;|| = || colspan="5" |5EB52&lt;sub&gt;16&lt;/sub&gt;
|}
The conversion from hexadecimal to binary is equally direct.

===Other simple conversions===

Although [[Quaternary numeral system|quaternary]] (base 4) is little used, it can easily be converted to and from hexadecimal or binary. Each hexadecimal digit corresponds to a pair of quaternary digits and each quaternary digit corresponds to a pair of binary digits. In the above example 5&amp;nbsp;E&amp;nbsp;B&amp;nbsp;5&amp;nbsp;2&lt;sub&gt;16&lt;/sub&gt; = 11&amp;nbsp;32&amp;nbsp;23&amp;nbsp;11&amp;nbsp;02&lt;sub&gt;4&lt;/sub&gt;.

The [[octal]] (base 8) system can also be converted with relative ease, although not quite as trivially as with bases 2 and 4. Each octal digit corresponds to three binary digits, rather than four. Therefore we can convert between octal and hexadecimal via an intermediate conversion to binary followed by regrouping the binary digits in groups of either three or four.

===Division-remainder in source base===
As with all bases there is a simple [[algorithm]] for converting a representation of a number to hexadecimal by doing integer division and remainder operations in the source base. In theory, this is possible from any base, but for most humans only decimal and for most computers only binary (which can be converted by far more efficient methods) can be easily handled with this method.

Let d be the number to represent in hexadecimal, and the series h&lt;sub&gt;i&lt;/sub&gt;h&lt;sub&gt;i−1&lt;/sub&gt;...h&lt;sub&gt;2&lt;/sub&gt;h&lt;sub&gt;1&lt;/sub&gt; be the hexadecimal digits representing the number.

# i ← 1
# h&lt;sub&gt;i&lt;/sub&gt; ← d mod 16
# d ← (d − h&lt;sub&gt;i&lt;/sub&gt;) / 16
# If d = 0 (return series h&lt;sub&gt;i&lt;/sub&gt;) else increment i and go to step 2

"16" may be replaced with any other base that may be desired.

The following is a [[JavaScript]] implementation of the above algorithm for converting any number to a hexadecimal in String representation. Its purpose is to illustrate the above algorithm. To work with data seriously, however, it is much more advisable to work with [[bitwise operators]].

&lt;source lang="javascript"&gt;
function toHex(d) {
  var r = d % 16;
  if (d - r == 0) {
    return toChar(r);
  }
  return toHex( (d - r)/16 ) + toChar(r);
}

function toChar(n) {
  const alpha = "0123456789ABCDEF";
  return alpha.charAt(n);
}
&lt;/source&gt;

===Addition and multiplication===
[[Image:Hexadecimal multiplication table.svg|right|thumb|A hexadecimal [[multiplication table]]]]
It is also possible to make the conversion by assigning each place in the source base the hexadecimal representation of its place value and then performing multiplication and addition to get the final representation.
That is, to convert the number B3AD to decimal one can split the hexadecimal number into its digits: B (11&lt;sub&gt;10&lt;/sub&gt;), 3 (3&lt;sub&gt;10&lt;/sub&gt;), A (10&lt;sub&gt;10&lt;/sub&gt;) and D (13&lt;sub&gt;10&lt;/sub&gt;), and then get the final result by multiplying each decimal representation by 16&lt;sup&gt;''p''&lt;/sup&gt;, where ''p'' is the corresponding hex digit position, counting from right to left, beginning with 0. In this case we have {{math|B3AD {{=}} (11 × 16&lt;sup&gt;3&lt;/sup&gt;) + (3 × 16&lt;sup&gt;2&lt;/sup&gt;) + (10 × 16&lt;sup&gt;1&lt;/sup&gt;) + (13 × 16&lt;sup&gt;0&lt;/sup&gt;)}}, which is 45997 base 10.

===Tools for conversion===
Most modern computer systems with [[graphical user interface]]s provide a built-in calculator utility, capable of performing conversions between various radices, in general including hexadecimal.

In [[Microsoft Windows]], the [[Calculator (Windows)|Calculator]] utility can be set to Scientific mode (called Programmer mode in some versions), which allows conversions between radix 16 (hexadecimal), 10 (decimal), 8 ([[octal]]) and 2 ([[Binary numeral system|binary]]), the bases most commonly used by programmers. In Scientific Mode, the on-screen [[numeric keypad]] includes the hexadecimal digits A through F, which are active when "Hex" is selected. In hex mode, however, the Windows Calculator supports only integers.

==Real numbers==

===Rational numbers===
As with other numeral systems, the hexadecimal system can be used to represent [[rational number]]s, although [[repeating decimal|repeating expansions]] are common since sixteen (10&lt;sub&gt;hex&lt;/sub&gt;) has only a single prime factor (two):

{| style="text-align:right;" border=0 cellspacing=0 cellpadding=3
|-
| '''1/2'''  ||style="text-align:center"| '''=''' || '''0.8'''
|-
| 1/3        ||style="text-align:center"| =       || 0.{{overline|5}}
|-
| '''1/4'''  ||style="text-align:center"| '''=''' || '''0.4'''
|-
| 1/5        ||style="text-align:center"| =       || 0.{{overline|3}}
|-
| 1/6        ||style="text-align:center"| =       || 0.2{{overline|A}}
|-
| 1/7        ||style="text-align:center"| =       || 0.{{overline|249}}
|-
| '''1/8'''  ||style="text-align:center"| '''=''' || '''0.2'''
|-
| 1/9        ||style="text-align:center"| =       || 0.{{overline|1C7}}
|-
| 1/A        ||style="text-align:center"| =       || 0.1{{overline|9}}
|-
| 1/B        ||style="text-align:center"| =       || 0.{{overline|1745D}}
|-
| 1/C        ||style="text-align:center"| =       || 0.1{{overline|5}}
|-
| 1/D        ||style="text-align:center"| =       || 0.{{overline|13B}}
|-
| 1/E        ||style="text-align:center"| =       || 0.1{{overline|249}}
|-
| 1/F        ||style="text-align:center"| =       || 0.{{overline|1}}
|-
| '''1/10''' ||style="text-align:center"| '''=''' || '''0.1'''
|-
| 1/11       ||style="text-align:center"| =       || 0.{{overline|0F}}
|}

where an [[overline#In mathematics|overline]] denotes a recurring pattern.

For any base, 0.1 (or "1/10") is always equivalent to one divided by the representation of that base value in its own number system. Thus, whether dividing one by two for [[binary numeral system|binary]] or dividing one by sixteen for hexadecimal, both of these fractions are written as &lt;code&gt;0.1&lt;/code&gt;. Because the radix 16 is a [[square number|perfect square]] (4&lt;sup&gt;2&lt;/sup&gt;), fractions expressed in hexadecimal have an odd period much more often than decimal ones, and there are no [[cyclic number]]s (other than trivial single digits). Recurring digits are exhibited when the denominator in lowest terms has a [[prime factor]] not found in the radix; thus, when using hexadecimal notation, all fractions with denominators that are not a [[power of two]] result in an infinite string of recurring digits (such as thirds and fifths). This makes hexadecimal (and binary) less convenient than [[decimal]] for representing rational numbers since a larger proportion lie outside its range of finite representation.

All rational numbers finitely representable in hexadecimal are also finitely representable in decimal, [[duodecimal]] and [[sexagesimal]]: that is, any hexadecimal number with a finite number of digits has a finite number of digits when expressed in those other bases. Conversely, only a fraction of those finitely representable in the latter bases are finitely representable in hexadecimal. For example, decimal 0.1 corresponds to the infinite recurring representation 0.199999999999... in hexadecimal. However, hexadecimal is more efficient than bases 12 and 60 for representing fractions with powers of two in the denominator (e.g., decimal one sixteenth is 0.1 in hexadecimal, 0.09 in duodecimal, 0;3,45 in sexagesimal and 0.0625 in decimal).

{|class="wikitable"
! rowspan=2 style="vertical-align:bottom;" | n
! colspan=3 | Decimal&lt;br /&gt;Prime factors of base, b = 10: {{color|Green|2}}, {{color|Green|5}}; b − 1 = 9: {{color|Blue|3}}; b + 1 = 11: {{color|Orange|11}}
! colspan=3 | Hexadecimal&lt;br/&gt;Prime factors of base, b = 16{{sub|10}} = 10: {{color|Green|2}}; b − 1 = 15{{sub|10}} = F: {{color|Blue|3, 5}}; b + 1 = 17{{sub|10}} = 11: {{color|Orange|11}}
|-
! Fraction
! Prime factors
! Positional representation
! Positional representation
! Prime factors
! Fraction(1/n)
|-
| 2
| align="center" | 1/2
| align="center" | {{color|Green|'''2'''}}
| '''0.5'''
| '''0.8'''
| align="center" | {{color|Green|'''2'''}}
| align="center" | 1/2
|-
| 3
| align="center" | 1/3
| align="center" | {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.'''3333... = '''0.'''{{overline|3}}
| bgcolor=#e4e4e4 | '''0.'''5555... = '''0.'''{{overline|5}}
| align="center" | {{color|Blue|'''3'''}}
| align="center" | 1/3
|-
| 4
| align="center" | 1/4
| align="center" | {{color|Green|'''2'''}}
| '''0.25'''
| '''0.4'''
| align="center" | {{color|Green|'''2'''}}
| align="center" | 1/4
|-
| 5
| align="center" | 1/5
| align="center" | {{color|Green|'''5'''}}
| '''0.2'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|3}}
| align="center" | {{color|Blue|'''5'''}}
| align="center" | 1/5
|-
| 6
| align="center" | 1/6
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.1'''{{overline|6}}
| bgcolor=#e4e4e4 | '''0.2'''{{overline|A}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| align="center" | 1/6
|-
| 7
| align="center" | 1/7
| align="center" | '''7'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|142857}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|249}}
| align="center" | '''7'''
| align="center" | 1/7
|-
| 8
| align="center" | 1/8
| align="center" | {{color|Green|'''2'''}}
| '''0.125'''
| '''0.2'''
| align="center" | {{color|Green|'''2'''}}
| align="center" | 1/8
|-
| 9
| align="center" | 1/9
| align="center" | {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|1}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|1C7}}
| align="center" | {{color|Blue|'''3'''}}
| align="center" | 1/9
|-
| 10
| align="center" | 1/10
| align="center" | {{color|Green|'''2'''}}, {{color|Green|'''5'''}}
| '''0.1'''
| bgcolor=#e4e4e4 | '''0.1'''{{overline|9}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''5'''}}
| align="center" | 1/A
|-
| 11
| align="center" | 1/11
| align="center" | {{color|Orange|'''11'''}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|09}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|1745D}}
| align="center" | '''B'''
| align="center" | 1/B
|-
| 12
| align="center" | 1/12
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.08'''{{overline|3}}
| bgcolor=#e4e4e4 | '''0.1'''{{overline|5}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| align="center" | 1/C
|-
| 13
| align="center" | 1/13
| align="center" | '''13'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|076923}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|13B}}
| align="center" | '''D'''
| align="center" | 1/D
|-
| 14
| align="center" | 1/14
| align="center" | {{color|Green|'''2'''}}, '''7'''
| bgcolor=#e4e4e4 | '''0.0'''{{overline|714285}}
| bgcolor=#e4e4e4 | '''0.1'''{{overline|249}}
| align="center" | {{color|Green|'''2'''}}, '''7'''
| align="center" | 1/E
|-
| 15
| align="center" | 1/15
| align="center" | {{color|Blue|'''3'''}}, {{color|Green|'''5'''}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|6}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|1}}
| align="center" | {{color|Blue|'''3'''}}, {{color|Blue|'''5'''}}
| align="center" | 1/F
|-
| 16
| align="center" | 1/16
| align="center" | {{color|Green|'''2'''}}
| '''0.0625'''
| '''0.1'''
| align="center" | {{color|Green|'''2'''}}
| align="center" | 1/10
|-
| 17
| align="center" | 1/17
| align="center" | '''17'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|0588235294117647}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|0F}}
| align="center" | {{color|Orange|'''11'''}}
| align="center" | 1/11
|-
| 18
| align="center" | 1/18
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|5}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|E38}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| align="center" | 1/12
|-
| 19
| align="center" | 1/19
| align="center" | '''19'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|052631578947368421}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|0D79435E5}}
| align="center" | '''13'''
| align="center" | 1/13
|-
| 20
| align="center" | 1/20
| align="center" | {{color|Green|'''2'''}}, {{color|Green|'''5'''}}
| '''0.05'''
| bgcolor=#e4e4e4 | '''0.0'''{{overline|C}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''5'''}}
| align="center" | 1/14
|-
| 21
| align="center" | 1/21
| align="center" | {{color|Blue|'''3'''}}, '''7'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|047619}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|0C3}}
| align="center" | {{color|Blue|'''3'''}}, '''7'''
| align="center" | 1/15
|-
| 22
| align="center" | 1/22
| align="center" | {{color|Green|'''2'''}}, {{color|Orange|'''11'''}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|45}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|BA2E8}}
| align="center" | {{color|Green|'''2'''}}, '''B'''
| align="center" | 1/16
|-
| 23
| align="center" | 1/23
| align="center" | '''23'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|0434782608695652173913}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|0B21642C859}}
| align="center" | '''17'''
| align="center" | 1/17
|-
| 24
| align="center" | 1/24
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.041'''{{overline|6}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|A}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| align="center" | 1/18
|-
| 25
| align="center" | 1/25
| align="center" | {{color|Green|'''5'''}}
| '''0.04'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|0A3D7}}
| align="center" | {{color|Blue|'''5'''}}
| align="center" | 1/19
|-
| 26
| align="center" | 1/26
| align="center" | {{color|Green|'''2'''}}, '''13'''
| bgcolor=#e4e4e4 | '''0.0'''{{overline|384615}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|9D8}}
| align="center" | {{color|Green|'''2'''}}, '''D'''
| align="center" | 1/1A
|-
| 27
| align="center" | 1/27
| align="center" | {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|037}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|097B425ED}}
| align="center" | {{color|Blue|'''3'''}}
| align="center" | 1/1B
|-
| 28
| align="center" | 1/28
| align="center" | {{color|Green|'''2'''}}, '''7'''
| bgcolor=#e4e4e4 | '''0.03'''{{overline|571428}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|924}}
| align="center" | {{color|Green|'''2'''}}, '''7'''
| align="center" | 1/1C
|-
| 29
| align="center" | 1/29
| align="center" | '''29'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|0344827586206896551724137931}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|08D3DCB}}
| align="center" | '''1D'''
| align="center" | 1/1D
|-
| 30
| align="center" | 1/30
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}, {{color|Green|'''5'''}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|3}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|8}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}, {{color|Blue|'''5'''}}
| align="center" | 1/1E
|-
| 31
| align="center" | 1/31
| align="center" | '''31'''
| bgcolor=#e4e4e4 | '''0.'''{{overline|032258064516129}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|08421}}
| align="center" | '''1F'''
| align="center" | 1/1F
|-
| 32
| align="center" | 1/32
| align="center" | {{color|Green|'''2'''}}
| '''0.03125'''
| '''0.08'''
| align="center" | {{color|Green|'''2'''}}
| align="center" | 1/20
|-
| 33
| align="center" | 1/33
| align="center" | {{color|Blue|'''3'''}}, {{color|Orange|'''11'''}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|03}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|07C1F}}
| align="center" | {{color|Blue|'''3'''}}, '''B'''
| align="center" | 1/21
|-
| 34
| align="center" | 1/34
| align="center" | {{color|Green|'''2'''}}, '''17'''
| bgcolor=#e4e4e4 | '''0.0'''{{overline|2941176470588235}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|78}}
| align="center" | {{color|Green|'''2'''}}, {{color|Orange|'''11'''}}
| align="center" | 1/22
|-
| 35
| align="center" | 1/35
| align="center" | {{color|Green|'''5'''}}, '''7'''
| bgcolor=#e4e4e4 | '''0.0'''{{overline|285714}}
| bgcolor=#e4e4e4 | '''0.'''{{overline|075}}
| align="center" | {{color|Blue|'''5'''}}, '''7'''
| align="center" | 1/23
|-
| 36
| align="center" | 1/36
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| bgcolor=#e4e4e4 | '''0.02'''{{overline|7}}
| bgcolor=#e4e4e4 | '''0.0'''{{overline|71C}}
| align="center" | {{color|Green|'''2'''}}, {{color|Blue|'''3'''}}
| align="center" | 1/24
|}

===Irrational numbers===
The table below gives the expansions of some common [[irrational number]]s in decimal and hexadecimal.
{| class="wikitable"
! rowspan=2 | Number
! colspan=2 | Positional representation
|-
! Decimal
! Hexadecimal
|-
| [[Square root of 2|{{sqrt|2}}]] {{small|(the length of the [[diagonal]] of a unit [[Square (geometry)|square]])}}
| {{val|1.414213562373095048}}...
| 1.6A09E667F3BCD...
|-
| [[Square root of 3|{{sqrt|3}}]] {{small|(the length of the diagonal of a unit [[cube]])}}
| {{val|1.732050807568877293}}...
| 1.BB67AE8584CAA...
|-
| [[Square root of 5|{{sqrt|5}}]] {{small|(the length of the [[diagonal]] of a 1×2 [[rectangle]])}}
| {{val|2.236067977499789696}}...
| 2.3C6EF372FE95...
|-
| [[Golden ratio|{{mvar|φ}}]] {{small|1=(phi, the [[golden ratio]] = {{math|(1+{{radical|5}})/2}})}}
| {{val|1.618033988749894848}}...
| 1.9E3779B97F4A...
|-
| [[Pi|{{mvar|π}}]] {{small|(pi, the ratio of [[circumference]] to [[diameter]] of a circle)}}
| {{val|3.141592653589793238462643}}&lt;br&gt;{{val|383279502884197169399375105}}...
| 3.243F6A8885A308D313198A2E0&lt;br&gt;3707344A4093822299F31D008...
|-
| [[E (mathematical constant)|{{mvar|e}}]] {{small|(the base of the [[natural logarithm]])}}
| {{val|2.718281828459045235}}...
| 2.B7E151628AED2A6B...
|-
| [[Thue–Morse constant|{{mvar|τ}}]] {{small|(the [[Thue–Morse constant]])}}
| {{val|0.412454033640107597}}...
| 0.6996 9669 9669 6996...
|-
| [[Euler-Mascheroni constant|{{mvar|γ}}]] {{small|(the limiting difference between the &lt;br/&gt;[[harmonic series (mathematics)|harmonic series]] and the natural logarithm)}}
| {{val|0.577215664901532860}}...
| 0.93C467E37DB0C7A4D1B...
|}

===Powers===
Powers of two have very simple expansions in hexadecimal. The first sixteen powers of two are shown below.
{| class="wikitable"
! 2&lt;sup&gt;''x''&lt;/sup&gt; !! Value !! Value (Decimal)
|-
| 2&lt;sup&gt;0&lt;/sup&gt; || 1 || 1
|-
| 2&lt;sup&gt;1&lt;/sup&gt; || 2 || 2
|-
| 2&lt;sup&gt;2&lt;/sup&gt; || 4 || 4
|-
| 2&lt;sup&gt;3&lt;/sup&gt; || 8 || 8
|-
| 2&lt;sup&gt;4&lt;/sup&gt; || 10&lt;sub&gt;hex&lt;/sub&gt; || 16&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;5&lt;/sup&gt; || 20&lt;sub&gt;hex&lt;/sub&gt; || 32&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;6&lt;/sup&gt; || 40&lt;sub&gt;hex&lt;/sub&gt; || 64&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;7&lt;/sup&gt; || 80&lt;sub&gt;hex&lt;/sub&gt; || 128&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;8&lt;/sup&gt; || 100&lt;sub&gt;hex&lt;/sub&gt; || 256&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;9&lt;/sup&gt; || 200&lt;sub&gt;hex&lt;/sub&gt; || 512&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;A&lt;/sup&gt; (2{{sup|10{{sub|dec}}}}) || 400&lt;sub&gt;hex&lt;/sub&gt; || 1024&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;B&lt;/sup&gt; (2{{sup|11{{sub|dec}}}}) || 800&lt;sub&gt;hex&lt;/sub&gt; || 2048&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;C&lt;/sup&gt; (2{{sup|12{{sub|dec}}}}) || 1000&lt;sub&gt;hex&lt;/sub&gt; || 4096&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;D&lt;/sup&gt; (2{{sup|13{{sub|dec}}}}) || 2000&lt;sub&gt;hex&lt;/sub&gt; || 8192&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;E&lt;/sup&gt; (2{{sup|14{{sub|dec}}}}) || 4000&lt;sub&gt;hex&lt;/sub&gt; || 16,384&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;F&lt;/sup&gt; (2{{sup|15{{sub|dec}}}}) || 8000&lt;sub&gt;hex&lt;/sub&gt; || 32,768&lt;sub&gt;dec&lt;/sub&gt;
|-
| 2&lt;sup&gt;10&lt;/sup&gt; (2{{sup|16{{sub|dec}}}}) || 10000&lt;sub&gt;hex&lt;/sub&gt; || 65,536&lt;sub&gt;dec&lt;/sub&gt;
|}

==Cultural==

===Etymology===
The word ''hexadecimal'' is composed of ''hexa-'', derived from the [[Greek language|Greek]] ἕξ (hex) for ''six'', and ''-decimal'', derived from the [[Latin]] for ''tenth''. Webster's Third New International online derives ''hexadecimal'' as an alteration of the all-Latin ''sexadecimal'' (which appears in the earlier Bendix documentation). The earliest date attested for ''hexadecimal'' in Merriam-Webster Collegiate online is 1954, placing it safely in the category of [[international scientific vocabulary]] (ISV). It is common in ISV to mix Greek and Latin [[combining form]]s freely. The word ''[[sexagesimal]]'' (for base 60) retains the Latin prefix. [[Donald Knuth]] has pointed out that the etymologically correct term is ''senidenary'' (or possibly, ''sedenary''), from the Latin term for ''grouped by 16''. (The terms ''binary'', ''ternary'' and ''quaternary'' are from the same Latin construction, and the etymologically correct terms for ''decimal'' and ''octal'' arithmetic are ''denary'' and ''octonary'', respectively.)&lt;ref&gt;Knuth, Donald. (1969). ''[[The Art of Computer Programming]], Volume 2''. {{isbn|0-201-03802-1}}. (Chapter 17.)&lt;/ref&gt; Alfred B. Taylor used ''senidenary'' in his mid-1800s work on alternative number bases, although he rejected base 16 because of its "incommodious number of digits".&lt;ref&gt;Alfred B. Taylor, [https://books.google.com/books?id=X7wLAAAAYAAJ&amp;pg=PP5 Report on Weights and Measures], Pharmaceutical Association, 8th Annual Session, Boston, Sept. 15, 1859.  See pages and 33 and 41.&lt;/ref&gt;&lt;ref&gt;Alfred B. Taylor, "Octonary numeration and its application to a system of weights and measures", [https://books.google.com/books?id=KsAUAAAAYAAJ&amp;pg=PA296 ''Proc Amer. Phil. Soc.'' Vol XXIV], Philadelphia, 1887; pages 296-366.  See pages 317 and 322.&lt;/ref&gt; Schwartzman notes that the expected form from usual Latin phrasing would be ''sexadecimal'', but computer hackers would be tempted to shorten that word to ''sex''.&lt;ref&gt;Schwartzman, S. (1994). ''The Words of Mathematics: an etymological dictionary of mathematical terms used in English''. {{isbn|0-88385-511-9}}.&lt;/ref&gt; The [[Etymology|etymologically]] proper [[Greek language|Greek]] term would be ''hexadecadic'' / ''ἑξαδεκαδικός'' / ''hexadekadikós'' (although in [[Modern Greek]], ''decahexadic'' / ''δεκαεξαδικός'' / ''dekaexadikos'' is more commonly used).

In hexadecimal, numbers with nondecreasing digits are called plaindrones, those with nonincreasing digits are called nialpdromes, those with descending digits are called katadromes, and those with ascending digits are called metadromes.&lt;ref&gt;{{Cite book|title=Martin Gardner's Sixth Book of Mathematical Diversions from "Scientific American"|last=Gardner|first=Martin|publisher=University of Chicago Press|year=1984|isbn=978-0226282503|location=|pages=105}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://mathworld.wolfram.com/Hexadecimal.html|title=Hexadecimal|last=Weisstein|first=Eric W.|date=|website=Wolfram MathWorld|archive-url=|archive-date=|dead-url=|access-date=October 27, 2018}}&lt;/ref&gt;

===Use in Chinese culture===
The traditional [[Chinese units of measurement]] were base-16. For example, one jīn&amp;nbsp;(斤) in the old system equals sixteen [[tael]]s. The [[suanpan]] (Chinese [[abacus]]) can be used to perform hexadecimal calculations.

===Primary numeral system===
As with the [[duodecimal]] system, there have been occasional attempts to promote hexadecimal as the preferred numeral system. These attempts often propose specific pronunciation and symbols for the individual numerals.&lt;ref&gt;{{cite web
 | url = http://www.hauptmech.com/base42
 | title = Base 4^2 Hexadecimal Symbol Proposal
}}&lt;/ref&gt; Some proposals unify standard measures so that they are multiples of 16.&lt;ref&gt;{{cite web|url=http://www.intuitor.com/hex/|title=Intuitor Hex Headquarters|last=|first=|date=|website=Intuitor|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://std.dkuug.dk/jtc1/sc2/wg2/docs/n2677|title=A proposal for addition of the six Hexadecimal digits (A-F) to Unicode|last=Niemietz|first=Ricardo Cancho|date=October 21, 2003|website=|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;&lt;ref name="nystrom"&gt;{{cite book|url=https://books.google.com/books?id=aNYGAAAAYAAJ|title=Project of a New System of Arithmetic, Weight, Measure and Coins: Proposed to be called the Tonal System, with Sixteen to the Base|last=Nystrom|first=John William|publisher=Lippincott|year=1862|isbn=|location=Philadelphia|pages=}}&lt;/ref&gt;

An example of unified standard measures is [[hexadecimal time]], which subdivides a day by 16 so that there are 16 "hexhours" in a day.&lt;ref name="nystrom" /&gt;

==Base16 (Transfer encoding)==
'''Base16''' (as a proper name without a space) can also refer to a [[binary to text encoding]] belonging to the same family as [[Base32]], [[Base58]], and [[Base64]].

In this case, data is broken into 4-bit sequences, and each value (between 0 and 15 inclusively) is encoded using 16 symbols from the [[ASCII]] character set. Although any 16 symbols from the ASCII character set can be used, in practice the ASCII digits '0'-'9' and the letters 'A'-'F' (or the lowercase 'a'-'f') are always chosen in order to align with standard written notation for hexadecimal numbers.

There are several advantages of Base16 encoding:
* Most programming languages already have facilities to parse ASCII-encoded hexadecimal
* Being exactly half a byte, 4-bits is easier to process than the 5 or 6 bits of Base32 and Base64 respectively
* The symbols 0-9 and A-F are universal in hexadecimal notation, so it is easily understood at a glance without needing to rely on a symbol lookup table
* Many CPU architectures have dedicated instructions that allow access to a half-byte (otherwise known as a "[[Nibble]]"), making it more efficient in hardware than Base32 and Base64

The main disadvantages of Base16 encoding are:
* Space efficiency is only 50%, since each 4-bit value from the original data will be encoded as an 8-bit byte. In contrast, Base32 and Base64 encodings have a space efficiency of 63% and 75% respectively.
* Possible added complexity of having to accept both uppercase and lowercase letters

Support for Base16 encoding is ubiquitous in modern computing. It is the basis for the [[World Wide Web Consortium|W3C]] standard for [[Percent-encoding|URL Percent Encoding]], where a character is replaced with a percent sign "%" and its Base16-encoded form. Most modern programming languages directly include support for formatting and parsing Base16-encoded numbers.

==See also==
* [[Base32]], [[Base64]] (content encoding schemes)
*[[Hexadecimal time]]
*[[IBM hexadecimal floating point]]
* [[Hex editor]]
* [[Hex dump]]
* [[Bailey–Borwein–Plouffe formula]] (BBP)

==References==
{{reflist|refs=
&lt;ref name="Savard_2018_CA"&gt;{{cite web |title=Computer Arithmetic |at=The Early Days of Hexadecimal |author-first=John J. G. |author-last=Savard |date=2018 |orig-year=2005 |work=quadibloc |url=http://www.quadibloc.com/comp/cp02.htm |access-date=2018-07-16 |dead-url=no |archive-url=https://web.archive.org/web/20180716102439/http://www.quadibloc.com/comp/cp02.htm |archive-date=2018-07-16}}&lt;/ref&gt;
&lt;ref name="Bendix"&gt;{{cite book |title=G15D Programmer's Reference Manual |chapter=2.1.3 Sexadecimal notation |date= |publisher=[[Bendix Computer]], Division of [[Bendix Aviation Corporation]] |location=Los Angeles, CA, USA |page=4 |url=http://bitsavers.trailing-edge.com/pdf/bendix/g-15/G15D_Programmers_Ref_Man.pdf |access-date=2017-06-01 |dead-url=no |archive-url=https://web.archive.org/web/20170601222212/http://bitsavers.trailing-edge.com/pdf/bendix/g-15/G15D_Programmers_Ref_Man.pdf |archive-date=2017-06-01 |quote=This base is used because a group of four bits can represent any one of sixteen different numbers (zero to fifteen). By assigning a symbol to each of these combinations we arrive at a notation called sexadecimal (usually hex in conversation because nobody wants to abbreviate sex). The symbols in the sexadecimal language are the ten decimal digits and, on the G-15 typewriter, the letters u, v, w, x, y and z. These are arbitrary markings; other computers may use different alphabet characters for these last six digits.}}&lt;/ref&gt;
&lt;ref name="Illiac-I"&gt;{{cite web |title=ILLIAC Programming - A Guide to the Preparation of Problems For Solution by the University of Illinois Digital Computer |author-first1=S. |author-last1=Gill |author-first2=R. E. |author-last2=Neagher |author-first3=D. E. |author-last3=Muller |author-first4=J. P. |author-last4=Nash |author-first5=J. E. |author-last5=Robertson |author-first6=T. |author-last6=Shapin |author-first7=D. J. |author-last7=Whesler |editor-first=J. P. |editor-last=Nash |edition=Fourth printing. Revised and corrected |date=1956-09-01 |publisher=Digital Computer Laboratory, Graduate College, [[University of Illinois]] |location=Urbana, Illinois, USA |pages=3-2 |url=http://www.textfiles.com/bitsavers/pdf/illiac/ILLIAC/ILLIAC_programming_Sep56.pdf |access-date=2014-12-18 |dead-url=no |archive-url=https://web.archive.org/web/20170531153804/http://www.textfiles.com/bitsavers/pdf/illiac/ILLIAC/ILLIAC_programming_Sep56.pdf |archive-date=2017-05-31}}&lt;/ref&gt;
&lt;ref name="RP_1957_LGP-30"&gt;{{cite book |title=ROYAL PRECISION Electronic Computer LGP - 30 PROGRAMMING MANUAL |publisher=[[Royal McBee Corporation]] |location=Port Chester, New York |date=April 1957 |url=http://ed-thelen.org/comp-hist/lgp-30-man.html#R4.13 |access-date=2017-05-31 |dead-url=no |archive-url=https://web.archive.org/web/20170531153004/http://ed-thelen.org/comp-hist/lgp-30-man.html |archive-date=2017-05-31}} (NB. This somewhat odd sequence was from the next six sequential numeric keyboard codes in the [[LGP-30]]'s 6-bit character code.)&lt;/ref&gt;
}}

&lt;!--
==External links==
 If you're here, you're probably thinking about adding an external link to an online calculator or some such. Some points to keep in mind (from the policy at [[WP:EL]], http://en.wikipedia.org/w/index.php?title=Wikipedia:External_links):

* The "External links" section should be kept to a minimum. A lack of external links ... is not a reason to add them.
* Links to be avoided:
** Any site that does not provide a unique resource beyond what the article might contain...
** Links mainly intended to promote a website
** Sites that are only indirectly related to the article's subject

Since the article is about hexadecimal representation and mentions standard tools for conversion only as a minor example, there is little any external link to an online calculator or converter could possibly add to the reader's knowledge.
--&gt;

[[Category:Binary arithmetic]]
[[Category:Hexadecimal numeral system]]
[[Category:Positional numeral systems]]</text>
      <sha1>mmtuhjtxdu1x5ow5kb6p130583fauak</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert's eighteenth problem</title>
    <ns>0</ns>
    <id>2336224</id>
    <revision>
      <id>844139035</id>
      <parentid>782274632</parentid>
      <timestamp>2018-06-02T21:46:00Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3015">'''Hilbert's eighteenth problem''' is one of the 23 [[Hilbert problems]] set out in a celebrated list compiled in 1900 by mathematician [[David Hilbert]].  It asks three separate questions about lattices and sphere packing in Euclidean space.{{sfn|Milnor|1976}}

==Symmetry groups in &lt;math&gt;n&lt;/math&gt; dimensions==
The first part of the problem asks whether there are only finitely many essentially different [[space group]]s in &lt;math&gt;n&lt;/math&gt;-dimensional [[Euclidean space]].  This was answered affirmatively by [[Ludwig Bieberbach|Bieberbach]].

==Anisohedral tiling in 3 dimensions==
The second part of the problem asks whether there exists a [[polyhedron]] which [[tessellation of space|tiles]] 3-dimensional Euclidean space but is not the [[fundamental region]] of any space group; that is, which tiles but does not admit an isohedral (tile-[[group action|transitive]]) tiling.  Such tiles are now known as [[anisohedral tiling|anisohedral]].  In asking the problem in three dimensions, Hilbert was probably assuming that no such tile exists in two dimensions; this assumption later turned out to be incorrect.

The first such tile in three dimensions was found by [[Karl Reinhardt (mathematician)|Karl Reinhardt]] in 1928.  The first example in two dimensions was found by [[Heinrich Heesch|Heesch]] in 1935.{{sfn|Edwards|2003}} The related [[einstein problem]]&lt;!-- Note: do not capitalize einstein. The name of this problem is a pun on "one stone" and Einstein's name. --&gt; asks for a shape that can tile space but not with an [[infinite cyclic group]] of symmetries.

==Sphere packing==
The third part of the problem asks for the densest [[sphere packing]] or packing of other specified shapes.  Although it expressly includes shapes other than spheres, it is generally taken as equivalent to the [[Kepler conjecture]].

In 1998 American mathematician [[Thomas Callister Hales]] gave a [[computer-aided proof]] of the Kepler conjecture. It shows that the most space-efficient way to pack spheres is in a pyramid shape.{{sfn|Hales|2005}}

==References==
{{reflist}}

*{{citation|first=Steve |last=Edwards |title=Heesch's Tiling |year=2003 |url=http://www.spsu.edu/math/tiling/17.html |deadurl=yes |archiveurl=https://web.archive.org/web/20110718054857/http://www.spsu.edu/math/tiling/17.html |archivedate=July 18, 2011 }}
*{{citation|last=Hales|first=Thomas C.|title=A proof of the Kepler conjecture|journal=Annals of Mathematics|year=2005|volume=162|issue=3|pages=1065–1185|doi=10.4007/annals.2005.162.1065|url=http://annals.math.princeton.edu/wp-content/uploads/annals-v162-n3-p01.pdf|arxiv=math/9811078}}
*{{citation | last=Milnor|first=J.|chapter=Hilbert's problem 18|editor-last=Browder|editor-first= Felix E.  | title=Mathematical developments arising from Hilbert problems |series=Proceedings of symposia in pure mathematics|volume= 28 | publisher=[[American Mathematical Society]] | year=1976 | isbn=0-8218-1428-1}}

{{Hilbert's problems}}

[[Category:Hilbert's problems|#18]]
[[Category:Tessellation]]</text>
      <sha1>tt2qnqdy49p341qhfhzldfbbsfoeae4</sha1>
    </revision>
  </page>
  <page>
    <title>Hironaka's example</title>
    <ns>0</ns>
    <id>39648291</id>
    <revision>
      <id>846633673</id>
      <parentid>841536999</parentid>
      <timestamp>2018-06-19T23:58:54Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8107">In [[geometry]], '''Hironaka's example''' is a non-Kähler complex manifold that is a [[Deformation theory|deformation]] of [[Kähler manifold]]s found by {{harvs|txt|last=Hironaka|authorlink=Heisuke Hironaka|year1=1960|year2=1962}}. Hironaka's example can be used to show that several other plausible statements holding for smooth varieties of dimension at most 2 fail for smooth varieties of dimension at least 3.

==Hironaka's example==

Take two smooth curves ''C'' and ''D'' in a smooth projective 3-fold ''P'', intersecting in two points ''c'' and ''d'' that are nodes for the reducible curve ''C''∪''D''. For some applications these should be chosen so that there is a fixed-point-free automorphism exchanging the curves ''C'' and ''D'' and also exchanging the points ''c'' and ''d''. Hironaka's example ''V'' is obtained by blowing up the curves ''C'' and ''D'', with ''C'' blown up first at the point ''c'' and ''D'' blown up first at the point ''d''. Then ''V'' has two smooth rational curves ''L'' and ''M'' lying over ''c'' and ''d'' such that ''L''+''M'' is algebraically equivalent to 0, so ''V'' cannot be projective.

For an explicit example of this configuration, take ''t'' to be a point of order 2 in an elliptic curve ''E'', take ''P'' to be ''E''×''E''/(''t'')×''E''/(''t''), take ''C'' and ''D'' to be the sets of points of the form (''x'',''x'',0) and (''x'',0,''x''), so that ''c'' and ''d'' are the points (0,0,0) and (''t'',0,0), and take the involution σ to be the one taking (''x'',''y'',''z'') to (''x''&amp;nbsp;+&amp;nbsp;''t'', ''z'',''y'').

===A complete  abstract variety that is not projective===

Hironaka's variety is a smooth 3-dimensional complete variety but is not projective as it has a non-trivial curve algebraically equivalent to 0. Any 2-dimensional smooth complete variety is projective, so 3 is the smallest possible dimension for such an example. There are plenty of 2-dimensional complex manifolds that are not algebraic, such as [[Hopf surface]]s (non Kähler) and non-algebraic tori (Kähler).

===An effective cycle algebraically equivalent to 0===

In a projective variety, a nonzero effective cycle has non-zero degree so cannot be algebraically equivalent to 0. In Hironaka's example the effective cycle consisting of the two exceptional curves is algebraically equivalent to 0.

===A deformation of Kähler manifolds that is not a Kähler manifold===

If one of the curves ''D'' in Hironaka's construction is allowed to vary in a family such that most curves of the family do not intersect ''D'', then one obtains a family of manifolds such that most are projective but one is not. Over the complex numbers this gives a deformation of smooth Kähler (in fact projective) varieties that is not Kähler. This family is trivial in the smooth category, so in particular there are Kähler and non-Kähler smooth compact 3-dimensional complex manifolds that are diffeomorphic.

===A smooth algebraic space that is not a scheme===

Choose ''C'' and ''D'' so that ''P'' has an automorphism σ of order 2 acting freely on ''P'' and exchanging ''C'' and ''D'', and also exchanging ''c'' and ''d''. Then the quotient of ''V'' by the action of σ is a smooth 3-dimensional [[algebraic space]] with an irreducible curve algebraically equivalent to 0. This means that the quotient is a smooth 3-dimensional algebraic space that is not a scheme.

===A Moishezon manifold that is not an abstract variety===

If the previous construction is done with complex manifolds rather than algebraic spaces, it gives an example of a smooth 3-dimensional compact [[Moishezon manifold]] that is not an abstract variety. A Moishezon manifold of dimension at most 2 is necessarily projective, so 3 is the minimum possible dimension for this example.

===The quotient of a scheme by a free action of a finite group need not be a scheme===

This is essentially the same as the previous two examples. The quotient does exist as a scheme if every orbit is contained in an affine open subscheme; the counterexample above shows that this technical condition cannot be dropped.

===A finite subset of a variety need not be contained in an open affine subvariety===

For quasi-projective varieties, it is obvious that any finite subset is contained in an open affine subvariety. This property fails for Hironaka's example: a two-points set consisting of a point in each of the exceptional curves is not contained in any open affine subvariety.

===A variety with no Hilbert scheme===

For Hironaka's variety ''V'' over the complex numbers with an automorphism of order 2 as above, the Hilbert functor Hilb&lt;sub&gt;''V''/'''C'''&lt;/sub&gt; of closed subschemes is not representable by a scheme, essentially because the quotient by the group of order 2 does not exist as a scheme {{harv|Nitsure|2005|loc=p.112}}. In other words, this gives an example of a smooth complete variety whose [[Hilbert scheme]] does not exist. Grothendieck showed that the Hilbert scheme always exists for projective varieties.

===Descent can fail for proper smooth morphisms of proper schemes===

Pick a non-trivial '''Z'''/2'''Z''' torsor ''B''&amp;nbsp;→&amp;nbsp;''A''; for example in characteristic not 2 one could take ''A'' and ''B'' to be the affine line minus the origin with the map from ''B'' to ''A'' given by ''x''&amp;nbsp;→&amp;nbsp;''x''&lt;sup&gt;2&lt;/sup&gt;. Think of ''B'' as an open covering of ''U'' for the étale topology. If ''V'' is a complete scheme with a fixed point free action of a group of order&amp;nbsp;2, then descent data for the map ''V''&amp;nbsp;×&amp;nbsp;''B''&amp;nbsp;→&amp;nbsp;''B'' are given by a suitable isomorphism from ''V''×''C'' to itself, where ''C''&amp;nbsp;=&amp;nbsp;''B''×&lt;sub&gt;''A''&lt;/sub&gt;''B'' =&amp;nbsp;''B''&amp;nbsp;×&amp;nbsp;'''Z'''/2'''Z'''. Such an isomorphism is given by the action of '''Z'''/2'''Z''' on ''V'' and ''C''. If this descent datum were effective then the fibers of the descent over ''U'' would give a quotient of ''V'' by the action of '''Z'''/2'''Z'''. So if this quotient does not exist as a scheme (as in the example above) then the descent data are ineffective. See {{harvs|txt|last=Vistoli|year=2005|loc=page 103}}.

===A scheme of finite type over a field such that not every line bundle comes from a divisor===

If ''X'' is a scheme of finite type over a field there is a natural map from divisors to line bundles. If ''X'' is either projective or reduced then this map is surjective. Kleiman found an example of a non-reduced  and non-projective ''X'' for which this map is not surjective as follows. Take Hironaka's example of a variety with two rational curves ''A'' and ''B'' such that ''A''+''B'' is numerically equivalent to 0. Then ''X'' is given by picking points ''a'' and ''b'' on ''A'' and ''B'' and introducing nilpotent elements at these points.

==References==

*{{citation|mr=|last=Hironaka|first= Heisuke
|title=On the theory of birational blowing-up|series=Thesis|place=Harvard|year=1960}}
*{{citation|mr=0139182|last=Hironaka|first= Heisuke
|title=An example of a non-Kählerian complex-analytic deformation of Kählerian complex structures. 
|journal=Ann. of Math. |series= 2|volume= 75 |year=1962 |pages=190–208|jstor=1970426 |doi=10.2307/1970426}}
*{{Citation | last1=Nitsure | first1=Nitin | title=Fundamental algebraic geometry | arxiv=math/0504590 | publisher=Amer. Math. Soc. | location=Providence, R.I. | series=Math. Surveys Monogr. | mr=2223407 | year=2005 | volume=123 | chapter=Construction of Hilbert and Quot schemes | pages=105–137| bibcode=2005math......4590N }}
*{{Citation | last1=Vistoli | first1=Angelo | title=Fundamental algebraic geometry | arxiv=math/0412512 | publisher=Amer. Math. Soc. | location=Providence, R.I. | series=Math. Surveys Monogr. | mr=2223406 | year=2005 | volume=123 | chapter=Grothendieck topologies, fibered categories and descent theory | pages=1–104| bibcode=2004math.....12512V }}

==External links==
*{{citation|last=Thiel|year=2007|title=Hironaka’s example of a complete but non-projective variety|url=http://www.mathematik.uni-stuttgart.de/~thiel/publications/hironakas_example.pdf}}

[[Category:Algebraic geometry]]</text>
      <sha1>7783bbsttmz121vtg7yy20rqej3v6bo</sha1>
    </revision>
  </page>
  <page>
    <title>History of calculus</title>
    <ns>0</ns>
    <id>746117</id>
    <revision>
      <id>870077283</id>
      <parentid>870076897</parentid>
      <timestamp>2018-11-22T06:16:41Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Undid revision 869921032 by [[Special:Contributions/112.79.192.64|112.79.192.64]] ([[User talk:112.79.192.64|talk]]) Not an improvement</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="40278">[[Calculus]], known in its early history as [[infinitesimal calculus]], is a mathematical discipline focused on [[limit (mathematics)|limits]], [[function (mathematics)|functions]], [[derivative]]s, [[integral]]s, and [[infinite series]]. [[Isaac Newton]] and [[Gottfried Wilhelm Leibniz]] independently discovered calculus in the mid-17th century. However, both inventors claimed that the other had stolen his work, and the [[Leibniz-Newton calculus controversy]] continued until the end of their lives.

==Pioneers of calculus==

===Ancient===
[[Image:Archimedes pi.svg|thumb|right|300px|Archimedes used the [[method of exhaustion]] to compute the area inside a circle]]
The ancient period introduced some of the ideas that led to [[integral]] calculus, but does not seem to have developed these ideas in a rigorous and systematic way.  Calculations of volumes and areas, one goal of integral calculus, can be found in the [[Egyptian mathematics|Egyptian]] [[Moscow Mathematical Papyrus|Moscow papyrus]] (c. 1820 BC), but the formulas are only given for concrete numbers, some are only approximately true, and they are not derived by deductive reasoning.&lt;ref&gt;{{cite book | first1=Morris | last1=Kline | title=Mathematical thought from ancient to modern times | volume=1 | publisher=Oxford University Press | isbn=978-0-19-506135-2 | pages=18–21 }}&lt;/ref&gt; [[Babylon]]ians may have discovered the [[trapezoidal rule]] while doing astronomical observations of [[Jupiter]].&lt;ref&gt;{{cite journal|last1=Ossendrijver|first1=Mathieu|title=Ancient Babylonian astronomers calculated Jupiter’s position from the area under a time-velocity graph|journal=[[Science (journal)|Science]]|date=29 January 2016|volume=351|issue=6272|pages=482–484|doi=10.1126/science.aad8085|url=http://science.sciencemag.org/content/351/6272/482.full|accessdate=29 January 2016|pmid=26823423}}&lt;/ref&gt;&lt;ref&gt;{{cite article |title=Signs of Modern Astronomy Seen in Ancient Babylon |journal=New York Times |year=2016 |first=Kenneth |last=Chang|url=https://www.nytimes.com/2016/01/29/science/babylonians-clay-tablets-geometry-astronomy-jupiter.html?action=click&amp;contentCollection=science&amp;region=rank&amp;module=package&amp;version=highlights&amp;contentPlacement=1&amp;pgtype=sectionfront}}&lt;/ref&gt;

From the age of [[Greek mathematics]], [[Eudoxus of Cnidus|Eudoxus]] (c. 408−355 BC) used the [[method of exhaustion]], which foreshadows the concept of the limit, to calculate areas and volumes, while [[Archimedes]] (c. 287−212 BC) [[The Method of Mechanical Theorems|developed this idea further]], inventing [[heuristics]] which resemble the methods of integral calculus.&lt;ref&gt;Archimedes, ''Method'', in ''The Works of Archimedes'' {{isbn|978-0-521-66160-7}}&lt;/ref&gt; [[Greek mathematics|Greek mathematicians]] are also credited with a significant use of [[infinitesimal]]s. [[Democritus]] is the first person recorded to consider seriously the division of objects into an infinite number of cross-sections, but his inability to rationalize discrete cross-sections with a cone's smooth slope prevented him from accepting the idea. At approximately the same time, [[Zeno of Elea]] discredited infinitesimals further by his articulation of the [[Zeno's paradoxes|paradoxes]] which they create.

Archimedes developed this method further, while also inventing heuristic methods which resemble modern day concepts somewhat in his ''[[The Quadrature of the Parabola]]'', ''[[Archimedes use of infinitesimals|The Method]]'', and ''[[On the Sphere and Cylinder]]''.&lt;ref&gt;MathPages — [http://mathpages.com/home/kmath343.htm Archimedes on Spheres &amp; Cylinders]&lt;/ref&gt;  It should not be thought that infinitesimals were put on a rigorous footing during this time, however. Only when it was supplemented by a proper geometric proof would Greek mathematicians accept a proposition as true. It was not until the 17th century that the method was formalized by [[Cavalieri]] as the [[method of Indivisibles]] and eventually incorporated by [[Isaac Newton|Newton]] into a general framework of [[integral calculus]]. Archimedes was the first to find the tangent to a curve other than a circle, in a method akin to differential calculus. While studying the spiral, he separated a point's motion into two components, one radial motion component and one circular motion component, and then continued to add the two component motions together, thereby finding the tangent to the curve.&lt;ref&gt;{{cite book|first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of Mathematics |edition=2nd |publisher=Wiley |year=1991 |isbn=0-471-54397-7 |chapter=Archimedes of Syracuse|pages=127|quote=Greek mathematics sometimes has been described as essentially static, with little regard for the notion of variability; but Archimedes, in his study of the spiral, seems to have found the tangent to a curve through kinematic considerations akin to differential calculus. Thinking of a point on the spiral 1=''r'' = ''aθ'' as subjected to a double motion — a uniform radial motion away from the origin of coordinates and a circular motion about the origin — he seems to have found (through the parallelogram of velocities) the direction of motion (hence of the tangent to the curve) by noting the resultant of the two component motions. This appears to be the first instance in which a tangent was found to a curve other than a circle.&lt;br/&gt;Archimedes' study of the spiral, a curve that he ascribed to his friend [[Conon of Samos|Conon of Alexandria]], was part of the Greek search for the solution of the three famous problems.}}&lt;/ref&gt; The pioneers of the calculus such as [[Isaac Barrow]] and [[Johann Bernoulli]] were diligent students of Archimedes; see for instance C. S. Roero (1983).

===Medieval===
The [[method of exhaustion]] was reinvented in [[Chinese mathematics|China]] by [[Liu Hui]] in the 4th century AD in order to find the area of a circle.&lt;ref&gt;{{cite journal
|series=Chinese studies in the history and philosophy of science and technology|volume=130|title=A comparison of Archimdes' and Liu Hui's studies of circles|first1=Liu|last1=Dun|first2=Dainian|last2=Fan|first3=Robert Sonné|last3=Cohen|publisher=Springer|year=1966|isbn=0-7923-3463-9|page=279|url=https://books.google.com/books?id=jaQH6_8Ju-MC}}, [https://books.google.com/books?id=jaQH6_8Ju-MC&amp;pg=PA279 Chapter , p. 279]&lt;/ref&gt; In the 5th century AD, [[Zu Chongzhi]] established a method that would later be called [[Cavalieri's principle]] to find the volume of a [[sphere]].&lt;ref&gt;{{cite book|title=Calculus: Early Transcendentals|edition=3|first1=Dennis G.|last1=Zill|first2=Scott|last2=Wright|first3=Warren S.|last3=Wright|publisher=Jones &amp; Bartlett Learning|year=2009|isbn=0-7637-5995-3|page=xxvii|url=https://books.google.com/books?id=R3Hk4Uhb1Z0C}} [https://books.google.com/books?id=R3Hk4Uhb1Z0C&amp;pg=PR27 Extract of page 27]&lt;/ref&gt; In the Middle East, [[Alhazen]] derived a formula for the sum of [[fourth power]]s. He used the results to carry out what would now be called an [[Integral|integration]], where the formulas for the sums of integral squares and fourth powers allowed him to calculate the volume of a [[paraboloid]].&lt;ref name=katz&gt;Katz, V. J.  1995.  "Ideas of Calculus in Islam and India."  ''Mathematics Magazine'' (Mathematical Association of America),  68(3):163-174.&lt;/ref&gt; In the 14th century, Indian mathematician [[Madhava of Sangamagrama]] and the [[Kerala school of astronomy and mathematics]] stated components of calculus such as the [[Taylor series]] and [[infinite series]] approximations.&lt;ref&gt;[http://www-history.mcs.st-andrews.ac.uk/HistTopics/Indian_mathematics.html Indian mathematics&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; However, they were not able to combine many differing ideas under the two unifying themes of the [[derivative]] and the [[integral]], show the connection between the two, and turn calculus into the powerful problem-solving tool we have today.&lt;ref name=katz/&gt;

The mathematical study of continuity was revived in the 14th century by the [[Oxford Calculators]] and French collaborators such as [[Nicole Oresme]]. They proved the "Merton [[mean speed theorem]]": that a uniformly accelerated body travels the same distance as a body with uniform speed whose speed is half the final velocity of the accelerated body.&lt;ref&gt;{{cite book|first=Carl B. |last=Boyer |authorlink=Carl Benjamin Boyer |title=A History of the Calculus and Its Conceptual Development |publisher=Dover |year=1959 |isbn=978-0-486-60509-8 |chapterurl=https://books.google.com/books?id=KLQSHUW8FnUC&amp;pg=PA79&amp;lpg=PP1#v=onepage&amp;q&amp;f=false  |chapter=III. Medieval Contributions |pages=79–89 |url=https://books.google.com/books?id=KLQSHUW8FnUC}}&lt;/ref&gt;

===Modern===
[[File:hyperbola E.svg|thumb|237px|right|Shaded area of one unit square measure when ''x'' = 2.71828... The discovery of [[Euler’s number]] e, and its exploitation with fuctions e&lt;sup&gt;x&lt;/sup&gt; and natural logarithm, completed integration theory for calculus of rational functions.]]
In the 17th century, European mathematicians [[Isaac Barrow]], [[René Descartes]], [[Pierre de Fermat]], [[Blaise Pascal]], [[John Wallis]] and others discussed the idea of a [[derivative]]. In particular, in ''Methodus ad disquirendam maximam et minima'' and in ''De tangentibus linearum curvarum'', Fermat developed an [[adequality]] method for determining maxima, minima, and tangents to various curves that was closely related to differentiation.&lt;ref name=Pellegrino&gt;{{cite web | last = Pellegrino | first = Dana | title=Pierre de Fermat | url=http://www.math.rutgers.edu/~cherlin/History/Papers2000/pellegrino.html| accessdate=2008-02-24}}&lt;/ref&gt; [[Isaac Newton]] would later write that his own early ideas about calculus came directly from "Fermat's way of drawing tangents."&lt;ref name=Simmons&gt;{{cite book | last = Simmons | first = George F. | title = Calculus Gems: Brief Lives and Memorable Mathematics | publisher = Mathematical Association of America | year = 2007 | page = 98 | isbn = 0-88385-561-5}}&lt;/ref&gt;

On the integral side, [[Bonaventura Cavalieri|Cavalieri]] developed his [[method of indivisibles]] in the 1630s and 1640s, providing a more modern form of the ancient Greek [[method of exhaustion]],{{Disputed inline|Two different methods|date=December 2011}} and computing [[Cavalieri's quadrature formula]], the area under the curves ''x''&lt;sup&gt;''n''&lt;/sup&gt; of higher degree, which had previously only been computed for the parabola, by Archimedes. [[Evangelista Torricelli|Torricelli]] extended this work to other curves such as the [[cycloid]], and then the formula was generalized to fractional and negative powers by Wallis in 1656.  In a 1659 treatise, Fermat is credited with an ingenious trick for evaluating the integral of any power function directly.&lt;ref name=quadrature&gt;{{Cite web | last1 = Paradís | first1 = Jaume | last2 = Pla | first2 = Josep | last3 = Viader | first3 = Pelagrí | title=Fermat’s Treatise On Quadrature: A New Reading | url=http://www.econ.upf.edu/docs/papers/downloads/775.pdf | accessdate=2008-02-24 | postscript = &lt;!--None--&gt;}}&lt;/ref&gt;  Fermat also obtained a technique for finding the centers of gravity of various plane and solid figures, which influenced further work in quadrature.  [[James Gregory (astronomer and mathematician)|James Gregory]], influenced by Fermat's contributions both to tangency and to quadrature, was then able to prove a restricted version of the second [[fundamental theorem of calculus]] in the mid-17th century.{{Citation needed|date=December 2011}} The first full proof of the [[fundamental theorem of calculus]] was given by [[Isaac Barrow]].&lt;ref&gt;{{cite book |title=The geometrical lectures of Isaac Barrow, translated, with notes and proofs, and a discussion on the advance made therein on the work of his predecessors in the infinitesimal calculus |publisher=Open Court  |location=Chicago |year=1916 |url=https://archive.org/details/geometricallectu00barruoft }}&lt;/ref&gt;

One prerequisite to the establishment of a calculus of functions of a real variable involved finding an [[antiderivative]] for the [[rational function]] &lt;math&gt;f(x) \ = \ \frac{1}{x} .&lt;/math&gt; This problem can be phrased as [[quadrature (mathematics)|quadrature]] of the rectangular hyperbola ''xy'' = 1. In 1647 [[Gregoire de Saint-Vincent]] noted that the required function ''F'' satisfied &lt;math&gt;F(st) = F(s) + F(t) ,&lt;/math&gt; so that a [[geometric sequence]] became, under ''F'', an [[arithmetic sequence]]. [[A. A. de Sarasa]] associated this feature with contemporary algorithms called ''logarithms'' that economized arithmetic by rendering multiplications into additions. So ''F'' was first known as the "hyperbolic logarithm". After [[Euler]] exploited e = 2.71828..., and ''F'' was identified as the [[inverse function]] of the [[exponential function]], it became the [[natural logarithm]], satisfying &lt;math&gt;\frac{dF}{dx} \ = \ \frac{1}{x} .&lt;/math&gt;

The first proof of [[Rolle's theorem]] was given by [[Michel Rolle]] in 1691 using methods developed by the Dutch mathematician [[Johann van Waveren Hudde]].&lt;ref&gt;{{cite book
|title=A Transition to Advanced Mathematics: A Survey Course
|first1=William
|last1=Johnston
|first2=Alex
|last2=McAllister
|publisher=Oxford University Press US
|year=2009
|isbn=0-19-531076-4
|page=333
|url=https://books.google.com/books?id=LV21vHwnkpIC}}, [https://books.google.com/books?id=LV21vHwnkpIC&amp;pg=PA333 Chapter 4, p. 333]
&lt;/ref&gt; The mean value theorem in its modern form was stated by [[Bernard Bolzano]] and [[Augustin-Louis Cauchy]] (1789–1857) also after the founding of modern calculus. Important contributions were also made by [[Isaac Barrow|Barrow]], [[Christiaan Huygens|Huygens]], and many others.

===Newton and Leibniz===
[[File:GodfreyKneller-IsaacNewton-1689.jpg|thumb|right|[[Isaac Newton]]]]
[[File:Gottfried Wilhelm Leibniz, Bernhard Christoph Francke.jpg|thumb|right|[[Gottfried Leibniz]]]]
{{See also|Leibniz–Newton calculus controversy}}

Before [[Isaac Newton|Newton]] and [[Gottfried Wilhelm Leibniz|Leibniz]], the word “calculus” referred to any body of mathematics, but in the following years, "calculus" became a popular term for a field of mathematics based upon their insights.&lt;ref&gt;{{harvnb|Reyes|2004|p=160}}&lt;/ref&gt; Newton and Leibniz, building on this work, independently developed the surrounding theory of infinitesimal calculus in the late 17th century. Also, Leibniz did a great deal of work with developing consistent and useful notation and concepts. Newton provided some of the most important applications to physics, especially of [[integral calculus]]. The purpose of this section is to examine Newton and Leibniz’s investigations into the developing field of infinitesimal calculus. Specific importance will be put on the justification and descriptive terms which they used in an attempt to understand calculus as they themselves conceived it.

By the middle of the 17th century, European mathematics had changed its primary repository of knowledge. In comparison to the last century which maintained [[Hellenistic]] mathematics as the starting point for research, Newton, Leibniz and their contemporaries increasingly looked towards the works of more modern thinkers.&lt;ref&gt;Such as Kepler, Descartes, Fermat, Pascal and Wallis. {{harvnb|Calinger|1999|p=556}}&lt;/ref&gt; Europe had become home to a burgeoning mathematical community and with the advent of enhanced institutional and organizational bases a new level of organization and academic integration was being achieved. Importantly, however, the community lacked formalism; instead it consisted of a disordered mass of various methods, techniques, [[Mathematical notation|notation]]s, [[theory|theories]], and [[paradox]]es.

Newton came to calculus as part of his investigations in [[physics]] and [[geometry]]. He viewed calculus as the scientific description of the generation of motion and [[magnitude (mathematics)|magnitude]]s. In comparison, Leibniz focused on the [[tangent problem]] and came to believe that calculus was a [[metaphysics|metaphysical]] explanation of change. Importantly, the core of their insight was the formalization of the inverse properties between the [[integral]] and the [[differential of a function]]. This insight had been anticipated by their predecessors, but they were the first to conceive calculus as a system in which new rhetoric and descriptive terms were created.&lt;ref&gt;Foremost among these was [[Isaac Barrow|Barrow]] who had created formulas for specific cases and Fermat who created a similar definition for the derivative. For more information; Boyer 184&lt;/ref&gt; Their unique discoveries lay not only in their imagination, but also in their ability to synthesize the insights around them into a universal algorithmic process, thereby forming a new mathematical system.

====Newton====
Newton completed no definitive publication formalizing his [[fluxion]]al calculus; rather, many of his mathematical discoveries were transmitted through correspondence, smaller papers or as embedded aspects in his other definitive compilations, such as the ''[[Philosophiæ Naturalis Principia Mathematica|Principia]]'' and ''[[Opticks]]''. Newton would begin his mathematical training as the chosen heir of [[Isaac Barrow]] in [[Cambridge]]. His aptitude was recognized early and he quickly learned the current theories. By 1664 Newton had made his first important contribution by advancing the [[binomial theorem]], which he had extended to include fractional and negative [[Exponentiation|exponent]]s. Newton succeeded in expanding the applicability of the binomial theorem by applying the algebra of finite quantities in an analysis of [[infinite series]]. He showed a willingness to view infinite series not only as approximate devices, but also as alternative forms of expressing a term.&lt;ref&gt;{{harvnb|Calinger|1999|p=610}}&lt;/ref&gt;

Many of Newton's critical insights occurred during the plague years of 1665–1666&lt;ref&gt;{{cite web|last=Newton|first=Isaac|title=Waste Book|url=http://cudl.lib.cam.ac.uk/view/MS-ADD-04004/|accessdate=10 January 2012}}&lt;/ref&gt;  which he later described as, "the prime of my age for invention and minded mathematics and [natural] philosophy more than at any time since." It was during his plague-induced isolation that the first written conception of [[Method of Fluxions|fluxionary calculus]] was recorded in the unpublished ''[[De analysi per aequationes numero terminorum infinitas|De Analysi per Aequationes Numero Terminorum Infinitas]]''. In this paper, Newton determined the area under a [[curve]] by first calculating a momentary rate of change and then extrapolating the total area. He began by reasoning about an indefinitely small triangle whose area is a function of ''x'' and ''y''. He then reasoned that the [[infinitesimal]] increase in the abscissa will create a new formula where {{nowrap|1=''x'' = ''x'' + ''o''}} (importantly, ''o'' is the letter, not the [[Numerical digit|digit]] 0). He then recalculated the area with the aid of the binomial theorem, removed all quantities containing the letter ''o'' and re-formed an algebraic expression for the area. Significantly, Newton would then “blot out” the quantities containing ''o'' because terms "multiplied by it will be nothing in respect to the rest".

At this point Newton had begun to realize the central property of inversion. He had created an expression for the area under a curve by considering a momentary increase at a point. In effect, the [[fundamental theorem of calculus]] was built into his calculations. While his new formulation offered incredible potential, Newton was well aware of its logical limitations at the time. He admits that "errors are not to be disregarded in mathematics, no matter how small" and that what he had achieved was “shortly explained rather than accurately demonstrated."

In an effort to give calculus a more rigorous explication and framework, Newton compiled in 1671 the ''[[Methodus Fluxionum et Serierum Infinitarum]]''. In this book, Newton's strict [[empiricism]] shaped and defined his fluxional calculus. He exploited [[instantaneous velocity|instantaneous]] [[Motion (physics)|motion]] and infinitesimals informally. He used math as a [[methodological]] tool to explain the physical world. The base of Newton’s revised calculus became continuity; as such he redefined his calculations in terms of continual flowing motion. For Newton, variable magnitudes are not aggregates of infinitesimal elements, but are generated by the indisputable fact of motion. As with many of his works, Newton delayed publication. ''Methodus Fluxionum'' was not published until 1736.&lt;ref&gt;{{cite book|last=Eves|first=Howard|title=An introduction to the history of mathematics, 6th edition|page=400}}&lt;/ref&gt;

Newton attempted to avoid the use of the infinitesimal by forming calculations based on [[ratio]]s of changes. In the ''Methodus Fluxionum'' he defined the rate of generated change as a [[fluxion]], which he represented by a dotted letter, and the quantity generated he defined as a [[fluent (mathematics)|fluent]]. For example, if &lt;math&gt;{x}&lt;/math&gt; and &lt;math&gt;{y}&lt;/math&gt; are fluents, then &lt;math&gt;\dot{x}&lt;/math&gt; and &lt;math&gt;\dot{y}&lt;/math&gt; are their respective fluxions. This revised calculus of ratios continued to be developed and was maturely stated in the 1676 text ''De Quadratura Curvarum'' where Newton came to define the present day derivative as the ultimate ratio of change, which he defined as the ratio between evanescent increments (the ratio of fluxions) purely at the moment in question. Essentially, the ultimate ratio is the ratio as the increments vanish into nothingness. Importantly, Newton explained the existence of the ultimate ratio by appealing to motion;

“For by the ultimate velocity is meant that, with which the body is moved, neither before it arrives at its last place, when the motion ceases nor after but at the very instant when it arrives... the ultimate ratio of evanescent quantities is to be understood, the ratio of quantities not before they vanish, not after, but with which they vanish”&lt;ref&gt;''Principia'', [[Florian Cajori]] 8&lt;/ref&gt;

Newton developed his fluxional calculus in an attempt to evade the informal use of infinitesimals in his calculations.

====Leibniz====
{{unreferenced section|date=March 2012}}
While Newton began development of his fluxional calculus in 1665–1666 his findings did not become widely circulated until later. In the intervening years Leibniz also strove to create his calculus. In comparison to Newton who came to math at an early age, Leibniz began his rigorous math studies with a mature intellect. He was a [[polymath]], and his intellectual interests and achievements involved [[metaphysics]], [[law]], [[economics]], [[politics]], [[logic]], and [[mathematics]]. In order to understand Leibniz’s reasoning in calculus his background should be kept in mind. Particularly, his [[metaphysics]] which described the universe as a [[Monadology]], and his plans of creating a precise formal logic whereby, "a general method in which all truths of the reason would be reduced to a kind of calculation."

In 1672 Leibniz met the mathematician [[Christiaan Huygens|Huygens]] who convinced Leibniz to dedicate significant time to the study of mathematics. By 1673 he had progressed to reading [[Blaise Pascal|Pascal]]’s ''[[Traité des Sinus du Quarte Cercle]]'' and it was during his largely [[autodidactic]] research that Leibniz said "a light turned on" {{citation needed|date=December 2012}}. Like Newton, Leibniz, saw the tangent as a ratio but declared it as simply the ratio between [[ordinate]]s and [[abscissa]]s. He continued this reasoning to argue that the [[integral]] was in fact the sum of the ordinates for infinitesimal intervals in the abscissa; in effect, the sum of an infinite number of rectangles. From these definitions the inverse relationship or differential became clear and Leibniz quickly realized the potential to form a whole new system of mathematics. Where Newton over the course of his career used several approaches in addition to an approach using [[infinitesimal]]s, Leibniz made this the cornerstone of his notation and calculus.

In the manuscripts of 25 October to 11 November 1675, Leibniz recorded his discoveries and experiments with various forms of notation. He was acutely aware of the notational terms used{{attribution needed|date=March 2012}} and his earlier plans to form a precise logical [[symbol]]ism became evident. Eventually, Leibniz denoted the infinitesimal increments of abscissas and ordinates ''dx'' and ''dy'', and the summation of infinitely many infinitesimally thin rectangles as a [[long s#Modern usage|long s]] (∫&amp;nbsp;), which became the present integral symbol &lt;math&gt;\scriptstyle\int&lt;/math&gt;.

While Leibniz's notation is used by modern mathematics, his logical base was different from our current one.{{citation needed|date=March 2012}} Leibniz embraced infinitesimals and wrote extensively so as, “not to make of the infinitely small a mystery, as had Pascal.”&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=oPrDAgAAQBAJ&amp;pg=PT207&amp;lpg=PT207&amp;dq=not+to+make+of+the+infinitely+small+a+mystery,+as+had+Pascal.&amp;source=bl&amp;ots=N2qdoknfyc&amp;sig=-kuv5JitMAQqvQecDyxfTbOECnE&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiR_JH9--PXAhVi4oMKHXc5C34Q6AEIJjAA#v=onepage&amp;q=not%20to%20make%20of%20the%20infinitely%20small%20a%20mystery%2C%20as%20had%20Pascal.&amp;f=false|title=The History of the Calculus and Its Conceptual Development|last=Boyer|first=Carl|publisher=|year=1939|isbn=9780486605098|location=|pages=}}&lt;/ref&gt; According to [[Gilles Deleuze]], Leibniz's zeroes "are nothings, but they are not absolute nothings, they are nothings respectively" (quoting Leibniz' text "Justification of the calculus of infinitesimals by the calculus of ordinary algebra").&lt;ref name=Deleuze&gt;{{cite web|last=Deleuze|first=Gilles|title=DELEUZE / LEIBNIZ Cours Vincennes - 22/04/1980|url=http://www.webdeleuze.com/php/texte.php?cle=53&amp;groupe=Leibniz&amp;langue=2|accessdate=30 April 2013}}&lt;/ref&gt;  Alternatively, he defines them as, “less than any given quantity.”{{Cite quote|date=March 2012}} For Leibniz, the world was an aggregate of infinitesimal points and the lack of scientific proof for their existence did not trouble him. Infinitesimals to Leibniz were ideal quantities of a different type from appreciable numbers. The truth of continuity was proven by existence itself. For Leibniz the principle of continuity and thus the validity of his calculus was assured. Three hundred years after Leibniz's work, [[Abraham Robinson]] showed that using infinitesimal quantities in calculus could be given a solid foundation.

====Legacy====
The rise of calculus stands out as a unique moment in mathematics. Calculus is the mathematics of motion and change, and as such, its invention required the creation of a new mathematical system. Importantly, Newton and Leibniz did not create the same calculus and they did not conceive of modern calculus. While they were both involved in the process of creating a mathematical system to deal with variable quantities their elementary base was different. For Newton, change was a variable quantity over time and for Leibniz it was the difference ranging over a sequence of infinitely close values. Notably, the descriptive terms each system created to describe change was different.

Historically, there was much debate over whether it was Newton or Leibniz who first "invented" calculus. This argument, the [[Leibniz and Newton calculus controversy]], involving Leibniz, who was German, and the Englishman Newton, led to a rift in the European mathematical community lasting over a century. Leibniz was the first to publish his investigations; however, it is well established that Newton had started his work several years prior to Leibniz and had already developed a theory of [[tangent]]s by the time Leibniz became interested in the question.
It is not known how much this may have influenced Leibniz. The initial accusations were made by students and supporters of the two great scientists at the turn of the century, but after 1711 both of them became personally involved, accusing each other of [[plagiarism]].

The priority dispute had an effect of separating English-speaking mathematicians from those in the continental Europe for many years. Only in the 1820s, due to the efforts of the [[Analytical Society]], did [[Leibnizian analytical calculus]] become accepted in England. Today, both Newton and Leibniz are given credit for independently developing the basics of calculus. It is Leibniz, however, who is credited with giving the new discipline the name it is known by today: "calculus". Newton's name for it was "the science of [[fluent (mathematics)|fluent]]s and [[Method of Fluxions|fluxion]]s".

The work of both Newton and Leibniz is reflected in the notation used today. Newton introduced the notation &lt;math&gt;\dot{f}&lt;/math&gt; for the [[derivative (mathematics)|derivative]] of a function ''f''.&lt;ref&gt;The use of prime to denote the [[derivative]], &lt;math&gt; f'\left(x\right),&lt;/math&gt; is due to Lagrange.&lt;/ref&gt; Leibniz introduced the symbol &lt;math&gt;\int&lt;/math&gt; for the [[integral]] and wrote the [[derivative]] of a function ''y'' of the variable ''x'' as &lt;math&gt;\frac{dy}{dx}&lt;/math&gt;, both of which are still in use.

Since the time of Leibniz and Newton, many mathematicians have contributed to the continuing development of calculus. One of the first and most complete works on both infinitesimal and [[integral calculus]] was written in 1748 by [[Maria Gaetana Agnesi]].
[[File:Maria Gaetana Agnesi.jpg|thumb|150px|right|[[Maria Gaetana Agnesi]]]]&lt;ref&gt;{{cite book |title=A Biography of Maria Gaetana Agnesi, an Eighteenth-century Woman Mathematician |edition=illustrated |first1=Antonella |last1=Cupillari |publisher=Edwin Mellen Press |year=2007 |isbn=978-0-7734-5226-8 |page=iii |url=https://books.google.com/books?id=urEfAQAAIAAJ&amp;q=most+complete|contributor-last=Allaire|contributor-first=Patricia R.|contribution=Foreword}}&lt;/ref&gt;&lt;ref&gt;{{cite web| url=http://www.agnesscott.edu/lriddle/women/agnesi.htm| title=Maria Gaetana Agnesi| first=Elif| last=Unlu|date=April 1995| publisher   =[[Agnes Scott College]]}}&lt;/ref&gt;

=== Operational methods ===
{{Main|Operational calculus}}
[[Antoine Arbogast]] (1800) was the first to separate the symbol of operation from that of quantity in a differential equation. [[Francois-Joseph Servois]] (1814) seem to have been the first to give correct rules on the subject. [[Charles James Hargreave]] (1848) applied these methods in his memoir on differential equations, and [[George Boole]] freely employed them. [[Hermann Grassmann]] and [[Hermann Hankel]] made great use of the theory, the former in studying [[Equation|equations]], the latter in his theory of [[Complex number|complex numbers]].

=== Calculus of variations ===
The [[calculus of variations]] may be said to begin with a problem of [[Johann Bernoulli]] (1696). It immediately occupied the attention of [[Jakob Bernoulli]] but [[Leonhard Euler]] first elaborated the subject. His contributions began in 1733, and his ''Elementa Calculi Variationum'' gave to the science its name. [[Joseph Louis Lagrange]] contributed extensively to the theory, and [[Adrien-Marie Legendre]] (1786) laid down a method, not entirely satisfactory, for the discrimination of maxima and minima. To this discrimination Brunacci (1810), [[Carl Friedrich Gauss]] (1829), [[Siméon Denis Poisson]] (1831), [[Mikhail Vasilievich Ostrogradsky]] (1834), and [[Carl Gustav Jakob Jacobi]] (1837) have been among the contributors. An important general work is that of Sarrus (1842) which was condensed and improved by [[Augustin Louis Cauchy]] (1844). Other valuable treatises and memoirs have been written by Strauch (1849), Jellett (1850), [[Otto Hesse]] (1857), [[Alfred Clebsch]] (1858), and Carll (1885), but perhaps the most important work of the century is that of [[Karl Weierstrass]]. His course on the theory may be asserted to be the first to place calculus on a firm and rigorous foundation.

==Integrals==
[[Niels Henrik Abel]] seems to have been the first to consider in a general way the question as to what [[differential expression]]s can be integrated in a finite form by the aid of ordinary functions, an investigation extended by [[Joseph Liouville|Liouville]]. [[Augustin Louis Cauchy|Cauchy]] early undertook the general theory of determining [[definite integral]]s, and the subject has been prominent during the 19th century. [[Frullani integral]], [[David Bierens de Haan]]'s work on the theory and his elaborate tables,[[Peter Gustav Lejeune Dirichlet|Lejeune Dirichlet]]'s lectures embodied in [[Friedrich Wilhelm Franz Meyer|Meyer]]'s treatise, and numerous memoirs of [[Adrien-Marie Legendre|Legendre]], [[Siméon Denis Poisson|Poisson]], [[Giovanni Antonio Amedeo Plana|Plana]], [[Joseph Ludwig Raabe|Raabe]], [[Leonhard Sohncke|Sohncke]], [[Oscar Xavier Schlömilch|Schlömilch]], [[Edwin Bailey Elliott|Elliott]], [[Charles Leudesdorf|Leudesdorf]], and [[Leopold Kronecker|Kronecker]] are among the noteworthy contributions.

[[Euler integral (disambiguation)|Eulerian integrals]] were first studied by [[Leonhard Euler|Euler]] and afterwards investigated by Legendre, by whom they were classed as Eulerian integrals of the first and second species, as follows:

:&lt;math&gt;\int_0^1 x^{n-1}(1 - x)^{n-1} \, dx&lt;/math&gt;

:&lt;math&gt;\int_0^\infty e^{-x} x^{n-1} \, dx&lt;/math&gt;

although these were not the exact forms of Euler's study.

If ''n'' is a positive integer, it follows that:
:&lt;math&gt;\int_0^\infty e^{-x}x^{n-1}dx = (n-1)!,&lt;/math&gt;
but the integral converges for all positive real &lt;math&gt;n&lt;/math&gt; and defines an [[analytic continuation]] of the [[factorial]] function to all of the [[complex plane]] except for poles at zero and the negative [[integers]]. To it Legendre assigned the symbol &lt;math&gt;\Gamma&lt;/math&gt;, and it is now called the [[gamma function]]. Besides being analytic over [[positive reals]] ℝ&lt;sup&gt;+&lt;/sup&gt;, &amp;nbsp;&lt;math&gt;\Gamma&lt;/math&gt; also enjoys the uniquely defining property that &lt;math&gt;\log \Gamma&lt;/math&gt; is [[Convex function|convex]], which aesthetically justifies this analytic continuation of the factorial function over any other analytic continuation. To the subject [[Peter Gustav Lejeune Dirichlet|Lejeune Dirichlet]] has contributed an important theorem (Liouville, 1839), which has been elaborated by [[Joseph Liouville|Liouville]], [[Eugène Charles Catalan|Catalan]], [[Leslie Ellis]], and others. On the evaluation of &lt;math&gt;\Gamma (x)&lt;/math&gt; and &lt;math&gt;\log \Gamma (x)&lt;/math&gt; [[Joseph Ludwig Raabe|Raabe]] (1843–44), Bauer (1859), and [[Christoph Gudermann|Gudermann]] (1845) have written. Legendre's great table appeared in 1816.

==Applications==
The application of the [[infinitesimal calculus]] to problems in [[physics]] and [[astronomy]] was contemporary with the origin of the science. All through the 18th century these applications were multiplied, until at its close [[Pierre-Simon Laplace|Laplace]] and [[Joseph Louis Lagrange|Lagrange]] had brought the whole range of the study of forces into the realm of analysis. To [[Joseph Louis Lagrange|Lagrange]] (1773) we owe the introduction of the theory of the potential into dynamics, although the name "[[Potential function (disambiguation)|potential function]]" and the fundamental memoir of the subject are due to [[George Green (mathematician)|Green]] (1827, printed in 1828). The name "[[potential]]" is due to [[Carl Friedrich Gauss|Gauss]] (1840), and the distinction between potential and potential function to [[Rudolf Julius Emanuel Clausius|Clausius]]. With its development are connected the names of [[Peter Gustav Lejeune Dirichlet|Lejeune Dirichlet]], [[Bernhard Riemann|Riemann]], [[John von Neumann|von Neumann]], [[Eduard Heine|Heine]], [[Leopold Kronecker|Kronecker]], [[Rudolf Lipschitz|Lipschitz]], [[Elwin Bruno Christoffel|Christoffel]], [[Gustav Kirchhoff|Kirchhoff]], [[Eugenio Beltrami|Beltrami]], and many of the leading physicists of the century.

It is impossible in this place to enter into the great variety of other applications of analysis to physical problems. Among them are the investigations of Euler on vibrating chords; [[Sophie Germain]] on elastic membranes; Poisson, [[Gabriel Lamé|Lamé]], [[Jean Claude Saint-Venant|Saint-Venant]], and [[Alfred Clebsch|Clebsch]] on the [[theory of elasticity|elasticity]] of three-dimensional bodies; [[Jean Baptiste Joseph Fourier|Fourier]] on [[heat]] diffusion; [[Augustin-Jean Fresnel|Fresnel]] on [[light]]; [[James Clerk Maxwell|Maxwell]], [[Hermann von Helmholtz|Helmholtz]], and [[Heinrich Rudolf Hertz|Hertz]] on [[electricity]]; Hansen, Hill, and [[Hugo Gyldén|Gyldén]] on [[astronomy]]; Maxwell on [[spherical harmonic]]s; [[John Strutt, 3rd Baron Rayleigh|Lord Rayleigh]] on [[acoustics]]; and the contributions of Lejeune Dirichlet, [[Wilhelm Eduard Weber|Weber]], [[Gustav Kirchhoff|Kirchhoff]], [[Franz Ernst Neumann|F. Neumann]], [[William Thomson, 1st Baron Kelvin|Lord Kelvin]], [[Rudolf Julius Emanuel Clausius|Clausius]], [[Vilhelm Bjerknes|Bjerknes]], [[James MacCullagh|MacCullagh]], and Fuhrmann to physics in general. The labors of Helmholtz should be especially mentioned, since he contributed to the theories of dynamics, electricity, etc., and brought his great analytical powers to bear on the fundamental axioms of mechanics as well as on those of pure mathematics.

Furthermore, infinitesimal calculus was introduced into the social sciences, starting with [[Neoclassical economics]]. Today, it is a valuable tool in mainstream economics.

==See also==
* [[Analytic geometry]]
* [[History of logarithms]]
* [[History of mathematics]]
* [[Multiplicative calculus|Non-Newtonian calculus]]
* [[Non-standard calculus]]

==Notes==
{{Reflist}}

==Further reading==
*{{cite book |author=Roero, C.S. |chapterurl=https://books.google.com/books?id=UdGBy8iLpocC&amp;pg=PA46#v=onepage&amp;q&amp;f=false |chapter=Gottfried Wilhelm Leibniz, first three papers on the calculus (1684, 1686, 1693) |editor=Grattan-Guinness, I. |title=Landmark writings in Western mathematics 1640–1940 |url=https://books.google.com/books?id=UdGBy8iLpocC |year=2005 |publisher=Elsevier |isbn=978-0-444-50871-3 |pages=46–58 |editor-link=Ivor Grattan-Guinness}}
*{{cite journal |author=Roero, C.S. |title=Jakob Bernoulli, attentive student of the work of Archimedes: marginal notes to the edition of Barrow |journal=Boll. Storia Sci. Mat. |volume=3 |issue=1 |pages=77–125 |year=1983 }}
*{{cite book |last=Boyer |first=Carl |author-link=Carl Benjamin Boyer |title=The History of the Calculus and its Conceptual Development |publisher=Dover Publications |location=New York |year=1959 }} Republication of a 1939 book (2nd printing in 1949) with a different title.
*{{cite book |last=Calinger |first=Ronald |title=A Contextual History of Mathematics |publisher=Prentice-Hall |location=Toronto |year=1999 |ref=harv |isbn=0-02-318285-7}}
*{{cite journal |last=Reyes |first=Mitchell |title=The Rhetoric in Mathematics: Newton, Leibniz, the Calculus, and the Rhetorical Force of the Infinitesimal |journal=[[Quarterly Journal of Speech]] |volume=90 |pages=159–184 |year=2004 |ref=harv}}
* [[Ivor Grattan-Guinness|Grattan-Guinness, Ivor]]. ''The Rainbow of Mathematics: A History of the Mathematical Sciences'', Chapters 5 and 6, W. W. Norton &amp; Company, 2000.
* [[Ruth Irene Hoffman|Hoffman, Ruth Irene]], "On the development and use of the concepts of the infinitesimal calculus before Newton and Leibniz", Thesis (M.A.), University of Colorado, 1937

==External links==
{{wikiquotes}}
* [http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/The_rise_of_calculus.html A history of the calculus in The MacTutor History of Mathematics archive], 1996.
* [http://www.economics.soton.ac.uk/staff/aldrich/Calculus%20and%20Analysis%20Earliest%20Uses.htm Earliest Known Uses of Some of the Words of Mathematics: Calculus &amp; Analysis]
* [http://cudl.lib.cam.ac.uk/collections/newton Newton Papers, Cambridge University Digital Library]
* {{en icon}} {{ar icon}} [http://www.wdl.org/en/item/4327/  The Excursion of Calculus], 1772

{{History of science}}

[[Category:Articles with inconsistent citation formats]]
[[Category:History of calculus| ]]</text>
      <sha1>80zrchgsrxk9trtcwgkj4xvxfafezc8</sha1>
    </revision>
  </page>
  <page>
    <title>James A. D. W. Anderson</title>
    <ns>0</ns>
    <id>8313563</id>
    <revision>
      <id>865205074</id>
      <parentid>862516450</parentid>
      <timestamp>2018-10-22T13:02:45Z</timestamp>
      <contributor>
        <ip>134.225.226.90</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15631">{{other people||James Anderson (disambiguation)}}
{{Use dmy dates|date=June 2013}}
{{Infobox scientist
| name              = James A. D. W. Anderson
| image             = 
| image_size        = 
| caption           = 
| birth_date        = {{birth year and age|1958}}
| birth_place       = 
| death_date        = 
| death_place       = 
| residence         =[[Reading, Berkshire]], [[United Kingdom]]
| citizenship       = 
| workplaces        = [[University of Reading]]
| alma_mater        = [[University of Reading]]
| doctoral_advisor  = Geoffrey Daniel Sullivan
| known_for         = Computer algebra&lt;br /&gt;Division by zero&lt;br /&gt;Transreal arithmetic
| awards            = 
| doctoral_students = 
}}

'''James Arthur Dean Wallace Anderson''' Known as '''James Anderson''' is an [[academic staff]] member in the School of Systems Engineering at the [[University of Reading]], England. He is currently teaching [[compilers]], [[algorithms]], and [[computer algebra]], and in the past he has taught [[Computer programming|programming]] and [[computer graphics]].&lt;ref name="reading"&gt;{{Cite web
 | url=http://www.reading.ac.uk/sse/about/staff/j-anderson.aspx
 | title=Computer Science at Reading - Dr. James Anderson
 | accessdate=28 February 2011
 | work=[[University of Reading]]
}}&lt;/ref&gt;

Anderson quickly gained publicity in December 2006 in the United Kingdom when the regional [[BBC South Today]] reported his claim of "having solved a 1200 year old problem", namely that of [[division by zero]]. However, commentators quickly responded that his ideas are just a variation of the standard [[IEEE 754]] concept of [[NaN]] (Not a Number), which has been commonly employed on [[computer]]s in [[floating point]] [[arithmetic]] for many years.&lt;ref name="Good Math, Bad Math"&gt;{{Cite web|url=http://scienceblogs.com/goodmath/2006/12/nullity_the_nonsense_number_1.php|title=Nullity: The Nonsense Number|work=Good Math, Bad Math|date=7 December 2006|author=Mark C. Chu-Carroll|accessdate=7 December 2006}}&lt;/ref&gt; Dr Anderson defended against the criticism of his claims on BBC Berkshire on 12 December 2006, saying, "If anyone doubts me I can hit them over the head with a computer that does it."&lt;ref name=BBC2&gt;{{Cite web|url=http://www.bbc.co.uk/berkshire/content/articles/2006/12/12/nullity_061212_feature.shtml|title='Nullity is a number, and that makes a difference'|accessdate=12 December 2006|date=12 December 2006|work=[[BBC News]]}}&lt;/ref&gt;

==Research and background==
Anderson is a member of the [[British Computer Society]], the British Machine Vision Association, [[Eurographics]], and the British Society for the Philosophy of Science.&lt;ref&gt;{{Cite web
 | url = http://www.api.reading.ac.uk/about.htm
 | title = About the Ambient &amp; Pervasive Intelligence Research Group
 | accessdate = 16 January 2007
 | work = [[University of Reading]]
}}&lt;/ref&gt; He is also a teacher in the Computer Science department (School of Systems Engineering) at the [[University of Reading]].&lt;ref name="reading" /&gt;  He was
a psychology graduate who worked in the Electrical and Electronic Engineering departments at the [[University of Sussex]] and Plymouth Polytechnic (now the [[University of Plymouth]]). His doctorate is from the University of Reading for (in Anderson's words) "developing a canonical description of the perspective transformations in whole numbered dimensions".

He has written two papers on [[division by zero]]&lt;ref name=BBC1&gt;{{Cite news|url=http://www.bbc.co.uk/berkshire/content/articles/2006/12/06/divide_zero_feature.shtml|title=1200-year-old problem "easy"|date=7 December 2006|author=Ben Moore|author2=Ollie Williams|work=[[BBC News]]|quote=Schoolchildren from Caversham have become the first to learn a brand new theory that dividing by zero is possible using a new number—"nullity". But the suggestion has left many mathematicians cold.}}.&lt;/ref&gt;&lt;ref name="Slashdot"&gt;{{Cite web|url=http://science.slashdot.org/article.pl?sid=06/12/07/0416223|title=Professor Comes Up With a Way to Divide by Zero|accessdate=7 December 2006|work=[[Slashdot]]}}&lt;/ref&gt; and has invented what he calls the "Perspex machine".

Anderson claims that "mathematical arithmetic is sociologically invalid" and that [[IEEE floating point standard|IEEE floating-point arithmetic]], with NaN, is also faulty.&lt;ref name ="investor presentation"&gt;{{Cite web|url=http://www.angletechnology.com/events/investorday/Dr%20James%20Anderson%20Transreal%20presentation.pdf|title=Transreal Computing Research and Portfolio — Company Showcase|author=Dr James A.D.W. Anderson|format=PDF|accessdate=11 December 2006}}&lt;/ref&gt;

==Transreal arithmetic==
{{BLP sources|date=May 2010}}
{| class="wikitable" style="margin:10px; float:right; border: inset; border-collapse:collapse;" border="2" width="15%"
|+ Zero divided by zero
|-
| In mathematical analysis, the following limits can be found:
:&lt;math&gt; \lim_{x \to 0}\frac 0 x = 0 &lt;/math&gt;
: &lt;math&gt; \lim_{x \to 0^{+}}\frac 1 x = +\infty&lt;/math&gt;
: &lt;math&gt; \lim_{x \to 0^{-}}\frac 1 x = -\infty&lt;/math&gt;
: &lt;math&gt; \lim_{x \to 0}\frac{\sin x}{x} = 1 &lt;/math&gt;
: &lt;math&gt; \lim_{x \to 0}\frac{1 - \cos x}{x} = 0 &lt;/math&gt;
&lt;math&gt;0^0&lt;/math&gt; is also an [[indeterminate form]].  See [[Exponentiation#Zero to the zero power|exponentiation]].
|-
| In IEEE floating-point arithmetic:
: &lt;math&gt; \frac{0}{0} = NaN &lt;/math&gt;
: by definition
In several computer programming languages, including [[C (programming language)|C]]'s &lt;code&gt;pow&lt;/code&gt; function, &lt;math&gt;0^0&lt;/math&gt; is defined to be &lt;math&gt;1&lt;/math&gt;, as that is the most convenient value for numerical analysis programs, since it makes &lt;math&gt;f(x) = x^0&lt;/math&gt; (and many other functions) [[continuous function|continuous]] at zero, with the notable exception of &lt;math&gt;f(x) = 0^x&lt;/math&gt;.&lt;ref&gt;{{Cite journal|title=Rationale for International Standard &amp;mdash; Programming Languages &amp;mdash; C|version=Revision 5.10|date=April 2003|author=John Benito|url=http://www.open-std.org/jtc1/sc22/wg14/www/C99RationaleV5.10.pdf|page=182}}&lt;/ref&gt;
|-
| In transreal arithmetic:
: &lt;math&gt; \frac{0}{0} = \Phi &lt;/math&gt;
: by definition
: &lt;math&gt; 0^0 = \Phi \,&lt;/math&gt;
: by Anderson's proof, reported on by the BBC, that:
: &lt;math&gt; 0^0 = \frac{0}{0} &lt;/math&gt;
|}
Anderson's transreal numbers were first mentioned in a 1997 publication,&lt;ref name=Pub1&gt;{{Cite web| url=http://adsabs.harvard.edu/abs/1997RSPTB.352.1129A|title=Representing Geometrical Knowledge}}&lt;/ref&gt; and made well-known on the [[Internet]] in 2006, but not accepted as useful by the mathematics community. These numbers are used in his concept of '''transreal arithmetic''' and the Perspex machine.  According to Anderson, transreal numbers include all of the [[real number]]s, plus three others: [[infinity]] (&lt;math&gt;\infty&lt;/math&gt;), negative infinity (&lt;math&gt;-\infty&lt;/math&gt;) and "nullity" (&lt;math&gt;\Phi&lt;/math&gt;), a numerical representation of a non-number that lies outside of the [[affinely extended real number line]].  ([[Null space|Nullity]], confusingly, has an existing mathematical meaning.)

Anderson intends the [[axiom]]s of transreal arithmetic to complement the axioms of standard arithmetic; they are supposed to produce the same result as standard arithmetic for all calculations where standard arithmetic defines a result. In addition, they are intended to define a consistent numeric result for the calculations which are undefined in standard arithmetic, such as [[division by zero]].&lt;ref name="perplex8"&gt;{{cite conference|url=http://www.bookofparagon.com/Mathematics/PerspexMachineVIII.pdf|format=PDF|title=Perspex Machine VIII: Axioms of Transreal Arithmetic|author=J A D W Anderson|year=2006|booktitle=Vision Geometry XV: Proceedings of SPIE|volume=6499|editor=[[Longin Jan Latecki]] |editor2=David M. Mount |editor2-link=David Mount|editor3=Angela Y. Wu|editor3-link=Angela Y. Wu}}&lt;/ref&gt;

===Transreal arithmetic and other arithmetics===
"Transreal arithmetic" closely resembles IEEE floating point arithmetic, a [[floating point]] arithmetic commonly used on [[computer]]s. IEEE floating point arithmetic, like transreal arithmetic, uses affine infinity (two separate infinities, one positive and one negative) rather than [[projectively extended real numbers|projective infinity]] (a single unsigned infinity, turning the number line into a loop).

The main difference is that IEEE arithmetic replaces the real (and transreal) number [[zero]] with positive and [[negative zero]]. (This is so that it can preserve the sign of a nonzero [[real number]] whose [[absolute value]] has been rounded down to zero. See also [[infinitesimal]].) Division of any non-zero finite number by zero results in either positive or negative infinity.

However, in IEEE arithmetic, division of zero by zero is still considered [[indeterminate form|indeterminate]]. The reason for this is simple: A statement about the quotient of two numbers is understood in mathematics as another statement about multiplication.  Specifically, if

&lt;math&gt;a \div b = c&lt;/math&gt;

this is understood as simply another way of saying that

&lt;math&gt;a = b \times c&lt;/math&gt;

Thus, if for some number &lt;math&gt;c&lt;/math&gt;

&lt;math&gt;0 \div 0 = c&lt;/math&gt;

then this is just another way of saying that

&lt;math&gt;0 = 0 \times c&lt;/math&gt;

But in fact this is true for '''all''' real numbers &lt;math&gt;c&lt;/math&gt;.  And that is precisely the reason that mathematicians do not assign a single value to &lt;math&gt;0 \div 0&lt;/math&gt; but rather label it "indeterminate".  Assigning a value to &lt;math&gt;0 \div 0&lt;/math&gt;, even a newly fabricated "number", misses the point entirely.

In IEEE arithmetic, the value of &lt;math&gt;0 \div 0&lt;/math&gt; is therefore represented by the symbol [[NaN|Not a Number (NaN)]] (Not a Number). NaN is '''not''' meant to be a number, but rather an error message conveying the fact that the arithmetical operation the computer just attempted cannot be assigned a single number as an answer – even if &lt;math&gt;+\infty&lt;/math&gt; and &lt;math&gt;-\infty&lt;/math&gt; are considered numbers. Because &lt;math&gt;NaN&lt;/math&gt; is an error message and not a number, it is not considered equal to anything, even itself. That is, the comparison &lt;math&gt;NaN = NaN&lt;/math&gt; evaluates to false.

Here are some [[identity (mathematics)|identities]] in transreal arithmetic with the IEEE equivalents:
{| class="wikitable" border="3"
! Transreal arithmetic !! IEEE standard floating point arithmetic
|-
| &lt;math&gt;0 \div 0 = \Phi&lt;/math&gt; || &lt;math&gt;0 \div 0 = NaN&lt;/math&gt;
|-
| &lt;math&gt;\infty \times 0 = \Phi&lt;/math&gt; || &lt;math&gt;\infty \times 0 = NaN&lt;/math&gt;
|-
| &lt;math&gt;\infty - \infty = \Phi&lt;/math&gt; || &lt;math&gt;\infty - \infty = NaN&lt;/math&gt;
|-
| &lt;math&gt;\Phi + a = \Phi \ &lt;/math&gt; || &lt;math&gt;NaN + a = NaN&lt;/math&gt;
|-
| &lt;math&gt;\Phi \times a = \Phi&lt;/math&gt; || &lt;math&gt;NaN \times a = NaN&lt;/math&gt;
|-
| &lt;math&gt;-\Phi = \Phi \ &lt;/math&gt; || &lt;math&gt;-NaN = NaN&lt;/math&gt; (i.e. applying unary negation to NaN yields NaN)
|-
| &lt;math&gt;+1 \div 0 = +\infty&lt;/math&gt; || &lt;math&gt;1 \div +0 = -1 \div -0 = +\infty&lt;/math&gt;
|-
| &lt;math&gt;-1 \div 0 = -\infty&lt;/math&gt; || &lt;math&gt;1 \div -0 = -1 \div +0 = -\infty&lt;/math&gt;
|-
| &lt;math&gt;\Phi = \Phi \Rightarrow True \ &lt;/math&gt; || &lt;math&gt;NaN = NaN \Rightarrow False &lt;/math&gt;
|}

The main difference between transreal arithmetic and IEEE floating-point arithmetic is thus that nullity compares equal to nullity, whereas NaN does not compare equal to NaN.

Anderson's analysis of the properties of transreal algebra is given in his paper on "perspex machines".&lt;ref name="perplex9"&gt;{{cite conference|url=http://www.bookofparagon.com/Mathematics/PerspexMachineIX.pdf|format=PDF|title=Perspex Machine IX: Transreal Analysis|author=J A D W Anderson|year=2006|booktitle=Vision Geometry XV: Proceedings of SPIE|volume=6499|editor=[[Longin Jan Latecki]] |editor2=David M. Mount |editor3=Angela Y. Wu.}}&lt;/ref&gt;

Due to the more expansive definition of numbers in transreal arithmetic, several identities and theorems which apply to all numbers in standard arithmetic are not universal in transreal arithmetic. For instance, in transreal arithmetic, &lt;math&gt;a-a=0&lt;/math&gt; is not true for all &lt;math&gt;a&lt;/math&gt;, since &lt;math&gt;\Phi-\Phi=\Phi&lt;/math&gt;. That problem is addressed in ref.&lt;ref name="perplex9"/&gt; pg. 7. Similarly, it is not always the case in transreal arithmetic that a number can be cancelled with its [[Multiplicative inverse|reciprocal]] to yield &lt;math&gt;1&lt;/math&gt;. Cancelling zero with its reciprocal in fact yields nullity.

Examining the [[axiom]]s provided by Anderson,&lt;ref name="perplex8"/&gt; it is easy to see that any term which contains an occurrence of the constant &lt;math&gt;\Phi&lt;/math&gt; is provably equivalent to &lt;math&gt;\Phi&lt;/math&gt;. Formally, let &lt;math&gt;t&lt;/math&gt; be any term with a sub-term &lt;math&gt;\Phi&lt;/math&gt;, then
&lt;math&gt;t=\Phi&lt;/math&gt; is a [[theorem]] of the theory proposed by Anderson.

==Media coverage==
Anderson's transreal arithmetic, and concept of "nullity" in particular, were introduced to the public by the [[BBC]] with its report in December 2006&lt;ref name=BBC1 /&gt; where Anderson was featured on a BBC television segment teaching schoolchildren about his concept of "nullity". The report implied that Anderson had ''discovered'' the solution to division by zero, rather than simply attempting to formalize it. The report also suggested that Anderson was the first to solve this problem, when in fact the result of zero divided by zero has been expressed formally in a number of different ways (for example, [[NaN]]).

The BBC was criticized for irresponsible journalism, but the producers of the segment defended the BBC, stating that the report was a light-hearted look at a mathematical problem aimed at a mainstream, regional audience for [[BBC South Today]] rather than at a global audience of mathematicians. The BBC later posted a follow-up giving Anderson's response to many claims that the theory is flawed.&lt;ref name="BBC2"/&gt;

==Applications==
Anderson has been trying to market his ideas for transreal arithmetic and "Perspex machines" to investors.  He claims that his work can produce computers which run "orders of magnitude faster than today's computers".&lt;ref name ="investor presentation" /&gt;&lt;ref name="company"&gt;{{Cite web|url=http://www.transrealcomputing.com/|title=Transreal Computing Ltd.|accessdate=12 December 2006}}&lt;/ref&gt; He has also claimed that it can help solve such problems as [[quantum gravity]],&lt;ref name ="investor presentation" /&gt; the [[mind-body connection]],&lt;ref name="paragon"&gt;http://www.bookofparagon.com/&lt;/ref&gt; [[consciousness]]&lt;ref name="paragon"/&gt; and [[free will]].&lt;ref name="paragon"/&gt;

==See also==
*[[Wheel theory]]
*[[Bottom type]] and [[bottom element]]
*[[Division by zero]]
*[[Hyperreal number]]

==References==
{{Wikinews|British computer scientist's new "nullity" idea provokes reaction from mathematicians}}
{{Reflist}}

==Further reading==
*{{Cite web|url=http://www.jgc.org/blog/2006/12/midas-number-or-why-divide-by-zero.html|title= The Midas Number (or why divide by zero?) |date=11 December 2006|author=John Graham-Cumming}}
*{{Cite web|url=http://www.1729.com/blog/ZeroDividedByZero.html|title=Zero Divided By Zero: Application to Spherical Coordinates|author=Philip Dorrell|date=16 December 2006}}

==External links==
*[http://www.reading.ac.uk/computer-science/dcs-bio-james-anderson.aspx Reading University Profile page]
*[http://www.bookofparagon.com/ Book of Paragon — personal homepage]

{{Authority control}}

{{DEFAULTSORT:Anderson, James A. D. W.}}
[[Category:Living people]]
[[Category:Alumni of the University of Reading]]
[[Category:Academics of the University of Reading]]
[[Category:English computer programmers]]
[[Category:English computer scientists]]
[[Category:Members of the British Computer Society]]
[[Category:Computer arithmetic]]
[[Category:Place of birth missing (living people)]]
[[Category:1958 births]]</text>
      <sha1>47niyla07olu56eszmai5kv4x4fk06o</sha1>
    </revision>
  </page>
  <page>
    <title>Johan Antony Barrau</title>
    <ns>0</ns>
    <id>56204268</id>
    <revision>
      <id>820848794</id>
      <parentid>818950720</parentid>
      <timestamp>2018-01-16T23:41:29Z</timestamp>
      <contributor>
        <username>Afasmit</username>
        <id>560336</id>
      </contributor>
      <comment>Category:People from Oisterwijk</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2838">'''Johan Antony Barrau''' (3 April 1873, [[Oisterwijk]] – 8 January 1953, Utrecht) was a Dutch mathematician, specializing in geometry.&lt;ref name=Bio&gt;{{cite web|title=Johan Antony Barrau|website=University of Groningen, History|url=http://www.cs.rug.nl/jbi/History/Barrau}}&lt;/ref&gt;

Barrau was educated at the [[Royal Naval College (Netherlands)|Dutch Royal Naval College]] at [[Willemsoord, Den Helder|Willemsoord]] and then at the [[University of Amsterdam]]. From 1891 to 1898, Barrau was an officer with the [[Royal Netherlands Navy]], later with the [[Netherlands Marine Corps]]. However, he left the service and became a mathematics teacher at a [[Hogere Burgerschool]] in [[Dordrecht]] until 1900, then in Amsterdam.&lt;ref name=Bio/&gt; In 1907 he obtained his PhD at the [[University of Amsterdam]] under the supervision of [[Diederik Korteweg]].&lt;ref&gt;{{MathGenealogy|id=30596}}&lt;/ref&gt; From 1908 to 1913 Barrau was a mathematics professor at the [[Delft University of Technology]]. He was a professor of synthetic, analytical and descriptive differential geometry at the [[University of Groningen]] from 1913 to 1928.&lt;ref name=Bio/&gt;. From 1928 until his retirement at age 70, he was a professor at [[Utrecht University]].&lt;ref&gt;{{cite book|author=Soifer, Alexander|title=The Scholar and the State: In Search of Van der Waerden|page=171|publisher=Springer Basel|year=2015|url=https://books.google.com/books?id=F_VWBQAAQBAJ&amp;pg=PA171}}&lt;/ref&gt; He received the military service medal consisting of the [[Expedition Cross|Expedition Cross with the Atjeh clasp]] and was named Knight of the [[Order of the Netherlands Lion]]. Barrau published a textbook on analytical geometry and various articles in national and international journals.&lt;ref name=Bio/&gt;

He was an Invited Speaker of the [[International Congress of Mathematicians|ICM]] in 1920 at Strasbourg&lt;ref&gt;{{cite book|author=Barrau, J. A.|chapter=Sur la cinématique plane|pages=590-593|chapter-url=https://babel.hathitrust.org/cgi/pt?id=msu.31293001749500;view=1up;seq=640|year=1921|title=Compte rendu du Congrès international des mathématiciens tenu à Strasbourg du 22 au 30 Septembre 1920}}&lt;/ref&gt; and in 1924 at Toronto.&lt;ref&gt;{{cite journal|title=The International Congress at Toronto|author=Dresden, Arnold|authorlink=Arnold Dresden|journal=Bull. Amer. Math. Soc.|volume=31|year=1925|pages=1–10|doi=10.1090/S0002-9904-1925-03982-8}} (See p. 6.)&lt;/ref&gt;

==References==
{{reflist}}

{{authority control}}
{{DEFAULTSORT:Barrau, Johan Antony}}
[[Category:1873 births]]
[[Category:1953 deaths]]
[[Category:20th-century Dutch mathematicians]]
[[Category:Geometers]]
[[Category:University of Amsterdam alumni]]
[[Category:University of Groningen faculty]]
[[Category:Utrecht University faculty]]
[[Category:Recipients of the Order of the Netherlands Lion]]
[[Category:People from Oisterwijk]]</text>
      <sha1>7l6x7o7x83mcvgpltxbna00w1wmju7c</sha1>
    </revision>
  </page>
  <page>
    <title>Kaplan–Meier estimator</title>
    <ns>0</ns>
    <id>3168650</id>
    <revision>
      <id>854959237</id>
      <parentid>854959076</parentid>
      <timestamp>2018-08-14T23:21:29Z</timestamp>
      <contributor>
        <ip>162.119.232.102</ip>
      </contributor>
      <comment>/* A Naive Estimator */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23422">[[File:Km plot.jpg|thumb|250px|An example of a Kaplan–Meier plot for two conditions associated with patient survival.]]

The '''Kaplan–Meier estimator''',&lt;ref&gt;{{cite journal |last=Kaplan |first=E. L. |last2=Meier |first2=P. |title=Nonparametric estimation from incomplete observations |journal=[[Journal of the American Statistical Association|J. Amer. Statist. Assoc.]] |volume=53 |issue=282 |pages=457–481 |year=1958 |jstor=2281868 |doi=10.2307/2281868}}&lt;/ref&gt;&lt;ref&gt;Kaplan, E.L. in a retrospective on the seminal paper in "This week's citation classic". ''Current Contents'' '''24''', 14 (1983). [http://www.garfield.library.upenn.edu/classics1983/A1983QS51100001.pdf Available from UPenn as PDF.]&lt;/ref&gt; also known as the '''product limit estimator''', is a [[non-parametric statistics|non-parametric]] [[statistic]] used to estimate the [[survival function]] from lifetime data.  In medical research, it is often used to measure the fraction of patients living for a certain amount of time after treatment. In other fields, Kaplan–Meier estimators may be used to measure the length of time people remain unemployed after a job loss,&lt;ref&gt;{{Cite journal | last1 = Meyer | first1 = Bruce D. | year = 1990 | title = Unemployment Insurance and Unemployment Spells | journal = [[Econometrica]] | volume = 58 | issue = 4 | pages = 757–782 | doi = 10.2307/2938349}}&lt;/ref&gt; the time-to-failure of machine parts, or how long fleshy fruits remain on plants before they are removed by [[frugivore]]s. The [[estimator]] is named after [[Edward L. Kaplan]] and [[Paul Meier (statistician)|Paul Meier]], who each submitted similar manuscripts to the ''[[Journal of the American Statistical Association]]''. The journal editor, [[John Tukey]], convinced them to combine their work into one paper, which has been cited about 50,000 times since its publication.&lt;ref&gt;{{Cite web|url=https://scholar.google.com/scholar?cites=14181649205747775124&amp;as_sdt=5,28&amp;sciodt=0,28&amp;hl=en|title=- Google Scholar|website=scholar.google.com|access-date=2017-03-04}}&lt;/ref&gt;&lt;ref&gt;{{cite news |url=http://articles.chicagotribune.com/2011-08-18/news/ct-met-meier-obit-20110818_1_clinical-trials-research-experimental-treatment |title=Paul Meier, 1924–2011 |newspaper=Chicago Tribune |date=August 18, 2011 }}&lt;/ref&gt;

The [[estimator]] is given by:

: &lt;math&gt; \widehat S(t) = \prod\limits_{i:\ t_i\le t} \left(1 - \frac{d_i}{n_i}\right),&lt;/math&gt;

with &lt;math&gt;t_i&lt;/math&gt; a time when at least one event happened, ''d''&lt;sub&gt;''i''&lt;/sub&gt; the ''number of events'' (i.e., deaths) that happened at time &lt;math&gt;t_i&lt;/math&gt; and &lt;math&gt; n_i&lt;/math&gt; the ''individuals known to survive'' (have not yet had an event or been censored) at time &lt;math&gt;t_i&lt;/math&gt;.

==Basic concepts==
A plot of the Kaplan–Meier estimator is a series of declining horizontal steps which, with a large enough sample size, approaches the true survival function for that population. The value of the survival function between successive distinct sampled observations ("clicks") is assumed to be constant.

An important advantage of the Kaplan–Meier curve is that the method can take into account some types of [[Censoring (statistics)|censored data]], particularly ''right-censoring'', which occurs if a patient withdraws from a study, is lost to follow-up, or is alive without event occurrence at last follow-up.  On the plot, small vertical tick-marks indicate individual patients whose survival times have been right-censored.  When no truncation or censoring occurs, the Kaplan–Meier curve is the complement of the [[empirical distribution function]].

In [[medical statistics]], a typical application might involve grouping patients into categories, for instance, those with Gene A profile and those with Gene B profile.  In the graph, patients with Gene B die much more quickly than those with Gene A. After two years, about 80% of the Gene A patients survive, but less than half of patients with Gene B.

In order to generate a Kaplan–Meier estimator, at least two pieces of data are required for each patient (or each subject): the status at last observation (event occurrence or right-censored) and the time to event (or time to censoring). If the survival functions between two or more groups are to be compared, then a third piece of data is required: the group assignment of each subject.&lt;ref name="km-explain"&gt;{{cite journal | journal=Otolaryngol Head Neck Surg | title=A practical guide to understanding Kaplan–Meier curves. |vauthors=Rich JT, Neely JG, Paniello RC, Voelker CC, Nussenbaum B, Wang EW | volume=143 | issue = 3 | year=2010 | pages=331–6 | doi=10.1016/j.otohns.2010.05.007 | pmid=20723767 | pmc=3932959 }}&lt;/ref&gt;

== Problem Definition ==
Let &lt;math&gt;\tau\ge 0&lt;/math&gt; be a random variable, which we think of as the time until an event of interest takes place. As indicated above, the goal is to estimate the [[survival function]] &lt;math&gt;S&lt;/math&gt; underlying &lt;math&gt;\tau&lt;/math&gt;. Recall that this function is defined as

&lt;math&gt;S(t) = \mathrm{Prob}(\tau &gt; t )&lt;/math&gt;,

where &lt;math&gt;t=0,1,\dots&lt;/math&gt;.

Let &lt;math&gt;\tau_1,\dots,\tau_n\ge 0&lt;/math&gt; be independent, identically distributed random variables, whose common distribution is that of &lt;math&gt;\tau&lt;/math&gt;: &lt;math&gt;\tau_j&lt;/math&gt; is the random time when some event &lt;math&gt;j&lt;/math&gt; happened. The data available for estimating &lt;math&gt;S&lt;/math&gt; is not &lt;math&gt;(\tau_j)_{j=1,\dots,n}&lt;/math&gt;, but the list of pairs &lt;math&gt;(\, ( \tilde \tau_j, c_j )\, )_{j=1,\dots,n}&lt;/math&gt; where for &lt;math&gt;j\in [n] := \{1,2,\dots,n\}&lt;/math&gt;,  &lt;math&gt;c_j\ge 0&lt;/math&gt; is a fixed, deterministic integer, the '''censoring time''' of event &lt;math&gt;j&lt;/math&gt; and &lt;math&gt;\tilde \tau_j = \min(\tau_j,c_j)&lt;/math&gt;. In particular, the information available about the timing of event &lt;math&gt;j&lt;/math&gt; is whether the event happened before the fixed time &lt;math&gt;c_j&lt;/math&gt; and if so, then the actual time of the event is also available. The challenge is to estimate &lt;math&gt;S(t)&lt;/math&gt; given this data.

== Derivation of the Kaplan-Meier Estimator ==
Here, we show two derivations of the Kaplan–Meier estimator. Both are based on rewriting the survival function in terms of what is sometimes called '''hazard''', or '''mortality rates'''. However, before doing this it is worthwhile to consider a naive estimator.

=== A Naive Estimator ===
To understand the power of the Kaplan–Meier estimator, it is worthwhile to first describe a naive estimator of the survival function.

Fix &lt;math&gt;k\in [n]:=\{1,\dots,n\}&lt;/math&gt; and let &lt;math&gt;t&gt;0&lt;/math&gt;. A basic argument shows that the following proposition holds:

'''Proposition 1:''' If the censoring time &lt;math&gt;c_k&lt;/math&gt; of event &lt;math&gt;k&lt;/math&gt; exceeds &lt;math&gt;t&lt;/math&gt; (&lt;math&gt;c_k\ge t&lt;/math&gt;), then &lt;math&gt;\tilde \tau_k=t&lt;/math&gt; if and only if  &lt;math&gt;\tau_k=t&lt;/math&gt;.

Let &lt;math&gt;k&lt;/math&gt; be such that &lt;math&gt;c_k\ge t&lt;/math&gt;. It follows from the above proposition that

&lt;math&gt;\mathrm{Prob}(\tau_k\ge t) = \mathrm{Prob}(\tilde \tau_k\ge t).&lt;/math&gt;

Let &lt;math&gt;
X_k = \mathbb{I}(\tilde \tau_k\ge t)
&lt;/math&gt; and consider only those &lt;math&gt;
k\in C(t) := \{ 1\le k \le n \,:\, c_k \ge t\}
&lt;/math&gt;, i.e. the events for which the outcome was not censored before time &lt;math&gt;t&lt;/math&gt;. Let &lt;math&gt;
m(t)=|C(t)| 
&lt;/math&gt; be the number of elements in &lt;math&gt;
C(t) 
&lt;/math&gt;. Note that the set &lt;math&gt;
C(t)
&lt;/math&gt; is not random and so neither is &lt;math&gt;
m(t)
&lt;/math&gt;. Furthermore, &lt;math&gt;
(X_k)_{k\in C(t)}
&lt;/math&gt; is a sequence of independent, identically distributed [[Bernoulli random variable]]&lt;nowiki/&gt;s with common parameter &lt;math&gt;
S(t-1)=\mathrm{Prob}(\tau\ge t)
&lt;/math&gt;. Assuming that &lt;math&gt;
m(t)&gt;0 
&lt;/math&gt;, this suggests to estimate &lt;math&gt;S(t-1)&lt;/math&gt; using

&lt;math&gt;
\hat S_{\mathrm{naive}}(t-1)
= \frac{1}{m(t)} \sum_{k:c_k\ge t} X_k
= \frac{|\{1\le k \le n\,:\, \tilde \tau_k\ge t\}|}{m(t)} 
&lt;/math&gt;,

where the last equality follows because &lt;math&gt;
\tilde \tau_k\ge t 
&lt;/math&gt; implies &lt;math&gt;
c_k\ge t 
&lt;/math&gt;.

The quality of this estimate is governed by the size of &lt;math&gt;m(t)&lt;/math&gt;. This can be problematic when &lt;math&gt;m(t)&lt;/math&gt; is small, which happens, by definition, when a lot of the events are censored. A particularly unpleasant property of this estimator, that suggests that perhaps it is not the "best" estimator, is that it ignores all the observations whose censoring time precedes &lt;math&gt;t&lt;/math&gt;. Intuitively, these observations still contain information about &lt;math&gt;S(t)&lt;/math&gt;: For example, when for many events with &lt;math&gt;c_k &lt; t &lt;/math&gt;, &lt;math&gt;\tilde \tau_k&lt;c_k &lt;/math&gt; also holds, we can infer that events often happen early, which implies that &lt;math&gt;\mathrm{Prob}(\tau\le t)&lt;/math&gt; is large, which, through &lt;math&gt;S(t) = 1-\mathrm{Prob}(\tau\le t)&lt;/math&gt; means that &lt;math&gt;S(t)&lt;/math&gt; must be small. However, this information is ignored by this naive estimator. The question is then whether there exists an estimator that makes a better use of all the data. This is what the Kaplan–Meier estimator accomplishes. Note that the naive estimator cannot be improved when censoring does not take place; so whether an improvement is possible critically hinges upon whether censoring is in place.

=== The Plug-In Approach ===

By elementary calculations,

&lt;math&gt; \begin{align}
S(t) &amp; = \mathrm{Prob}(\tau &gt; t|\tau &gt; t-1)\mathrm{Prob}(\tau &gt; t-1)  \\
            &amp; = (1-\mathrm{Prob}(\tau\le t|\tau &gt; t-1)) \mathrm{Prob}(\tau &gt; t-1)\\
            &amp; = (1-\mathrm{Prob}(\tau=t|\tau \ge t)) \mathrm{Prob}(\tau &gt; t-1) \\
            &amp; = q(t) S(t-1)\,,
\end{align}
&lt;/math&gt;

where the one but last equality used that &lt;math&gt;\tau&lt;/math&gt; is integer valued and for the last line we introduced

&lt;math&gt;q(t) = 1-\mathrm{Prob}(\tau=t|\tau\ge t)&lt;/math&gt;.

By a recursive expansion of the equality &lt;math&gt;S(t) = q(t) S(t-1)&lt;/math&gt;, we get

&lt;math&gt; S(t) = q(t) q(t-1) \cdots q(0). &lt;/math&gt;

Note that here &lt;math&gt;q(0) = 1-\mathrm{Prob}(\tau=0|\tau &gt; -1) = 1-\mathrm{Prob}(\tau=0)&lt;/math&gt;.

The Kaplan–Meier estimator can be seen as a "plug-in estimator" where each &lt;math&gt; q(s)
&lt;/math&gt; is estimated based on the data and the estimator of &lt;math&gt; S(t)
&lt;/math&gt; is obtained as a product of these estimates.

It remains to specify how &lt;math&gt;q(s)=1-\mathrm{Prob}(\tau=s|\tau\ge s)&lt;/math&gt; is to be estimated. By Proposition 1, for any &lt;math&gt;k\in [n]&lt;/math&gt; such that &lt;math&gt;c_k\ge s&lt;/math&gt;, &lt;math&gt;\mathrm{Prob}(\tau=s) = \mathrm{Prob}(\tilde \tau_k=s)&lt;/math&gt; and &lt;math&gt;\mathrm{Prob}(\tau\ge s) = \mathrm{Prob}(\tilde \tau_k\ge s)&lt;/math&gt; both hold. Hence, for any &lt;math&gt;
k\in [n] 
&lt;/math&gt; such that &lt;math&gt;
c_k\ge s 
&lt;/math&gt;,

&lt;math&gt; \mathrm{Prob}(\tau=s|\tau\ge s) = \mathrm{Prob}(\tilde \tau_k=s)/\mathrm{Prob}(\tilde \tau_k\ge s)
&lt;/math&gt;. By a similar reasoning that lead to the construction of the naive estimator above, we arrive at the estimator

&lt;math&gt;\hat q(s) 
= 1 - \frac{|\{1\le k\le n\,:\, c_k\ge s, \tilde \tau_k=s\}|}{|\{1\le k \le n\,:\, c_k\ge s,  \tilde \tau_k\ge s\}|}
= 1 - \frac{|\{1\le k\le n\,:\,\tilde \tau_k=s\}|}{|\{1\le k \le n\,:\, \tilde \tau_k\ge s\}|}&lt;/math&gt;

(think of estimating the numerator and denominator separately in the definition of the "hazard rate" &lt;math&gt;\mathrm{Prob}(\tau=s|\tau\ge s)&lt;/math&gt;). The Kaplan–Meier estimator is then given by

&lt;math&gt;\hat S(t) = \prod_{s=0}^t \hat q(s)&lt;/math&gt;.

The form of the estimator stated at the beginning of the article can be obtained by some further algebra. For this,  write &lt;math&gt;\hat q(s)=1-d(s)/n(s)&lt;/math&gt; where, using the actuarial science terminology,  &lt;math&gt;d(s)=|\{1\le k\le n\,:\,\tilde \tau_k=s\}|&lt;/math&gt; is the number of known deaths at time &lt;math&gt;s&lt;/math&gt;, while &lt;math&gt;n(s)=|\{1\le k \le n\,:\, \tilde \tau_k\ge s\}|&lt;/math&gt; is the number of those persons who are alive at time &lt;math&gt;s&lt;/math&gt;.

Note that if &lt;math&gt;d(s)=0&lt;/math&gt;, &lt;math&gt;\hat q(s)=1&lt;/math&gt;. This implies that we can leave out from the product defining &lt;math&gt;\hat S(t)&lt;/math&gt; all those terms where &lt;math&gt;d(s)=0&lt;/math&gt;. Then, letting &lt;math&gt;0\le t_1&lt;t_2&lt;\dots&lt;t_m&lt;/math&gt; be the times &lt;math&gt;s&lt;/math&gt; when &lt;math&gt;d(s)&gt;0&lt;/math&gt;, &lt;math&gt;d_i = d(t_i)&lt;/math&gt; and &lt;math&gt;n_i = n(t_i)&lt;/math&gt;, we arrive at the form of the Kaplan–Meier estimator given at the beginning of the article:

&lt;math&gt;\hat S(t) = \prod_{i:t_i\le t} \left(1-\frac{d_i}{n_i}\right)&lt;/math&gt;.

As opposed to the naive estimator, this estimator can be seen to use the available information more effectively: In the special case mentioned beforehand, when there are many early events recorded, the estimator will multiply many terms with a value below one and will thus take into account that the survival probability cannot be large.

=== Derivation as a maximum likelihood estimator ===
Kaplan–Meier estimator can be derived from [[maximum likelihood estimation]] of [[hazard function]].&lt;ref&gt;{{Cite web|url=https://web.stanford.edu/~lutian/coursepdf/STAT331unit3.pdf|title=|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; More specifically given &lt;math&gt;d_i&lt;/math&gt; as the number of events and &lt;math&gt; n_i&lt;/math&gt; the total individuals at risk at time&amp;nbsp;&lt;math&gt; t_i&lt;/math&gt;, discrete hazard rate &lt;math&gt; h_i&lt;/math&gt; can be defined as the probability of an individual with an event at time&amp;nbsp;&lt;math&gt; t_i&lt;/math&gt;. Then survival rate can be defined as:

&lt;math&gt; S(t) = \prod\limits_{i:\ t_i\le t} (1-h_i)&lt;/math&gt;

and the likelihood function for the hazard function up to time &lt;math&gt; t_i&lt;/math&gt; is:

&lt;math&gt; \mathcal{L}(h_{j: j\le i}|d_{j: j\le i},n_{j: j\le i}) = \prod_{j=1}^i h_j^{d_j}(1-h_j)^{n_j-d_j}&lt;/math&gt;

therefore the log likelihood will be:

&lt;math&gt; \log(\mathcal{L}) = \sum_{j=1}^i \left(d_j\log(h_j)+(n_j-d_j)\log(1-h_j)\right)&lt;/math&gt;

finding the maximum of log likelihood with respect to &lt;math&gt; h_i&lt;/math&gt; yields:

&lt;math&gt; \frac{\partial \log(\mathcal{L})}{\partial h_i} = \frac{d_i}{\widehat{h}_i}-\frac{n_i-d_i}{1-\widehat{h}_i} = 0 \Rightarrow \widehat{h}_i=\frac{d_i}{n_i} &lt;/math&gt;

where hat is used to denote maximum likelihood estimation. Given this result, we can write:

&lt;math&gt; \widehat S(t) = \prod\limits_{i:\ t_i\le t} \left(1 - \widehat{h}_i\right) = \prod\limits_{i:\ t_i\le t} \left(1 - \frac{d_i}{n_i}\right)&lt;/math&gt;

==Benefits and limitations==
The Kaplan–Meier estimator is one of the most frequently used methods of survival analysis. The estimate may be useful to examine recovery rates, the probability of death, and the effectiveness of treatment. It is limited in its ability to estimate survival adjusted for [[covariate]]s; parametric [[Survival function|survival models]] and the Cox [[proportional hazards model]] may be useful to estimate covariate-adjusted survival.

==Statistical considerations==
The Kaplan–Meier estimator is a [[statistic]], and several estimators are used to approximate its [[variance]].  One of the most common estimators is Greenwood's formula:&lt;ref&gt;{{cite journal |authorlink=Major Greenwood |last=Greenwood |first=M. |title=The natural duration of cancer |work=Reports on Public Health and Medical Subjects |location=London |publisher=Her Majesty's Stationery Office |year=1926 |volume=33 |pages=1–26 }}&lt;/ref&gt;

:&lt;math&gt; \widehat{\operatorname{Var}}( \widehat S(t) ) = \widehat S(t)^2  \sum\limits_{i:\ t_i\le t} \frac{d_i}{n_i(n_i-d_i)},&lt;/math&gt;

where &lt;math&gt; d_i &lt;/math&gt; is the number of cases and &lt;math&gt;n_i&lt;/math&gt; is the total number of observations, for &lt;math&gt;t_i &lt; t&lt;/math&gt;.

{{hidden|bg1=#f2dfce;|contentcss=border:1px #C4C3D0solid; |headercss=color:black; |header=For a mathematical derivation of the equation above, click on "show" to reveal|content=
Greenwood formula is derived&lt;ref name=":0"&gt;{{Cite web|url=https://www.math.wustl.edu/%7Esawyer/handouts/greenwood.pdf|title=|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; by noting that probability of getting &lt;math&gt;d_i&lt;/math&gt; failures out of &lt;math&gt; n_i&lt;/math&gt; cases follows a [[binomial distribution]] with failure probability &lt;math&gt;h_i&lt;/math&gt;. As a result for maximum likelihood hazard rate &lt;math&gt;\widehat{h}_i = d_i/n_i&lt;/math&gt; we have &lt;math&gt;E(\widehat{h}_i) = h_i
&lt;/math&gt; and &lt;math&gt;\operatorname{Var}(\widehat{h}_i) = h_i(1-h_i)/n_i&lt;/math&gt;. To avoid dealing with multiplicative probabilities we compute variance of logarithm of &lt;math&gt; \widehat S(t)&lt;/math&gt; and will use [[delta method]] to convert it back to the original variance:

&lt;math&gt;\begin{align}
\operatorname{Var}(\log \widehat{S}(t)) &amp;\sim \frac{1}{{\widehat{S}(t)}^2}\operatorname{Var}(\widehat{S}(t)) \Rightarrow \\
\operatorname{Var}( \widehat{S}(t)) &amp;\sim {{\widehat{S}(t)}^2}\operatorname{Var}(\log\widehat{S}(t))
\end{align}&lt;/math&gt;

using [[martingale central limit theorem]], it can be shown that the variance of the sum in the following equation is equal to the sum of variances:&lt;ref name=":0" /&gt;

&lt;math&gt; \log\widehat S(t) = \sum\limits_{i:\ t_i\le t} \log\left(1 - \widehat{h}_i\right)&lt;/math&gt;

as a result we can write:

&lt;math&gt;\begin{align}
\operatorname{Var}( \widehat{S}(t)) &amp;\sim 
{{\widehat{S}(t)}^2}\operatorname{Var}\left(\sum\limits_{i:\ t_i\le t} \log\left(1 - \widehat{h}_i\right)\right) \\
&amp;\sim 
{{\widehat{S}(t)}^2}\sum\limits_{i:\ t_i\le t} \operatorname{Var}\left(\log\left(1 - \widehat{h}_i\right)\right)
\end{align}&lt;/math&gt;

using delta method once more:

&lt;math&gt;\begin{align}
\operatorname{Var}( \widehat{S}(t)) &amp;\sim 
{{\widehat{S}(t)}^2}\sum_{i:\ t_i\le t}\left(\frac{\partial \log\left(1 - \widehat{h}_i\right)}{\partial \widehat{h}_i}\right)^2 \operatorname{Var}(\widehat{h}_i)\\
&amp;={{\widehat{S}(t)}^2}\sum_{i:\ t_i\le t}\left(\frac{1}{1-\widehat{h}_i}\right)^2\frac{\widehat{h}_i(1-\widehat{h}_i)}{n_i} \\
&amp;= {{\widehat{S}(t)}^2}\sum_{i:\ t_i\le t}\frac{\widehat{h}_i}{n_i(1-\widehat{h}_i)} \\
&amp;= {{\widehat{S}(t)}^2}\sum_{i:\ t_i\le t}\frac{d_i}{n_i(n_i-d_i)}
\end{align}&lt;/math&gt;

as desired.
----
}}
In some cases, one may wish to compare different Kaplan–Meier curves. This can be done by the [[log rank test]], and the [[proportional hazards models|Cox proportional hazards test]].

Other statistics that may be of use with this estimator are the Hall-Wellner band&lt;ref name=Hall1980&gt;Hall WJ and Wellner JA (1980) Confidence bands for a survival curve for censored data. Biometrika 69&lt;/ref&gt; and the equal-precision band.&lt;ref name=Nair1984&gt;Nair VN (1984) Confidence bands for survival functions with censored data: A comparative study. Technometrics 26: 265–275&lt;/ref&gt;

==Software==
* [[Mathematica]]: the built-in function &lt;code&gt;SurvivalModelFit&lt;/code&gt; creates survival models.&lt;ref&gt;{{Cite web|url=http://reference.wolfram.com/language/ref/SurvivalModelFit.html|title=Survival Analysis - Mathematica SurvivalModelFit|website=wolfram.com|access-date=2017-08-14}}&lt;/ref&gt;
* [[SAS (software)|SAS]]: The Kaplan–Meier estimator is implemented in the &lt;code&gt;proc lifetest&lt;/code&gt; procedure.&lt;ref&gt;[https://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_overview.htm The LIFETEST Procedure]&lt;/ref&gt;
* [[R (programming language)|R]]: the Kaplan–Meier estimator is available as part of the &lt;code&gt;survival&lt;/code&gt; package.&lt;ref&gt;{{cite web |title=survival: Survival Analysis |work=R Project |date= |url=https://cran.r-project.org/web/packages/survival/index.html }}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=Frans |last=Willekens |title=Multistate Analysis of Life Histories with R |chapter=The ''Survival'' Package |location= |publisher=Springer |year=2014 |isbn=978-3-319-08383-4 |pages=135–153 |chapterurl=https://books.google.com/books?id=Cd2CBAAAQBAJ&amp;pg=PA135 |doi=10.1007/978-3-319-08383-4_6 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=Ding-Geng |last=Chen |first2=Karl E. |last2=Peace |chapter= |title=Clinical Trial Data Analysis Using R |location= |publisher=CRC Press |year=2014 |isbn= |pages=99–108 |url=https://books.google.com/books?id=fGnRBQAAQBAJ&amp;pg=PA99 }}&lt;/ref&gt;
* [[Stata]]: the command &lt;code&gt;sts&lt;/code&gt; returns the Kaplan–Meier estimator.&lt;ref&gt;{{cite web |title=sts — Generate, graph, list, and test the survivor and cumulative hazard functions |work=Stata Manual |date= |url=https://www.stata.com/manuals13/ststs.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=Mario |last=Cleves |title=An Introduction to Survival Analysis Using Stata |location=College Station |publisher=Stata Press |edition=Second |year=2008 |isbn=1-59718-041-6 |pages=93–107 |url=https://books.google.com/books?id=xttbn0a-QR8C&amp;pg=PA93 }}&lt;/ref&gt;
* [[Python (programming language)|Python]]: the &lt;code&gt;lifelines&lt;/code&gt; package includes the Kaplan–Meier estimator.&lt;ref&gt;[https://lifelines.readthedocs.io/en/latest/ lifelines docs]&lt;/ref&gt;
* [[MATLAB]]: the &lt;code&gt;ecdf&lt;/code&gt; function with the &lt;code&gt;'function','survivor'&lt;/code&gt; arguments can calculate or plot the Kaplan–Meier estimator.&lt;ref&gt;{{Cite web|url=http://mathworks.com/help/stats/ecdf.html|title=Empirical cumulative distribution function - MATLAB ecdf|website=mathworks.com|access-date=2016-06-16}}&lt;/ref&gt;
* [[StatsDirect(software)|StatsDirect]]: The Kaplan–Meier estimator is implemented in the &lt;code&gt;Survival Analysis&lt;/code&gt; menu.&lt;ref&gt;[https://www.statsdirect.co.uk/help/Default.htm#survival_analysis/kaplan_meier.htm]&lt;/ref&gt;

==See also==
* [[Frequency of exceedance]]
* [[Median lethal dose]]
* [[Nelson–Aalen estimator]]

==References==
{{Reflist|30em}}

==Further reading==
* {{cite book |last=Aalen |first=Odd |first2=Ornulf |last2=Borgan |first3=Hakon |last3=Gjessing |title=Survival and Event History Analysis: A Process Point of View |location= |publisher=Springer |year=2008 |edition= |isbn=978-0-387-68560-1 |pages=90–104 }}
* {{cite book |last=Greene |first=William H. |authorlink=William Greene (economist) |chapter=Nonparametric and Semiparametric Approaches |title=Econometric Analysis |location= |publisher=Prentice-Hall |edition=Seventh |year=2012 |isbn=978-0-273-75356-8 |pages=909–912 |chapterurl=https://books.google.com/books?id=-WFPYgEACAAJ&amp;pg=PA909 }}
* {{cite book |last=Jones |first=Andrew M. |first2=Nigel |last2=Rice |first3=Teresa Bago |last3=D'Uva |first4=Silvia |last4=Balia |chapter=Duration Data |title=Applied Health Economics |location=London |publisher=Routledge |year=2013 |isbn=978-0-415-67682-3 |pages=139–181 |chapterurl=https://books.google.com/books?id=7tdcCol9mNEC&amp;pg=PA141 }}
* {{cite book |first=Judith B. |last=Singer |first2=John B. |last2=Willett |title=Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence |location=New York |publisher=Oxford University Press |year=2003 |isbn=0-19-515296-4 |pages=483–487 |url=https://books.google.com/books?id=PpnA1M8VwR8C&amp;pg=PA483 }}

==External links==
* {{cite web |url= http://www.cancerguide.org/scurve_km.html |title= Survival Curves: Accrual and The Kaplan-Meier Estimate |first= Steve |last= Dunn |website= Cancer Guide |series= Statistics |date= 2002 }}
* {{cite book |url= http://stat.ethz.ch/education/semesters/ss2011/seminar/contents/presentation_2.pdf |format= pdf |chapter= Kaplan–Meier Survival Curves and the Log-Rank Test |chapter-url= http://stat.ethz.ch/education/semesters/ss2011/seminar/contents/handout_2.pdf |work= Handout and presentation |series= Seminar for Statistics (SfS) |title= Survival Analysis |first1= Linda |last1= Staub |first2= Alexandros |last2= Gekenidis |date= Mar 7, 2011 |publisher= [[ETH Zurich|Eidgenössische Technische Hochschule Zürich (ETH)]] [Swiss Federal Institute of Technology Zurich] }}
* {{youtube|5C_zzD1pOAg|Three evolving Kaplan-Meier curves}}

{{Statistics|analysis}}

{{DEFAULTSORT:Kaplan-Meier estimator}}
[[Category:Estimator]]
[[Category:Actuarial science]]
[[Category:Survival analysis]]
[[Category:Reliability engineering]]</text>
      <sha1>0g2s5dbkzt37l0t4hjsjbywoniwh30i</sha1>
    </revision>
  </page>
  <page>
    <title>Lift (mathematics)</title>
    <ns>0</ns>
    <id>10504570</id>
    <revision>
      <id>865897821</id>
      <parentid>865897792</parentid>
      <timestamp>2018-10-26T22:09:42Z</timestamp>
      <contributor>
        <ip>74.104.137.240</ip>
      </contributor>
      <comment>Undid revision 865897792 by [[Special:Contributions/74.104.137.240|74.104.137.240]] ([[User talk:74.104.137.240|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2219">{{unreferenced|date=February 2016}}
[[Image:Lifting diagram.png|right|thumb|100px|Lift of ''f'' ([[commutative diagram]])]] In the branch of [[mathematics]] called [[category theory]], given a [[morphism]] ''f'' from an object ''X'' to an object ''Y'', and a morphism ''g'' from an object ''Z'' to ''Y'', a '''lift''' or '''lifting''' of ''f'' to ''Z'' is a morphism ''h'' from ''X'' to ''Z'' such that ''f'' = ''g ∘ h''. We then say that ''f'' [[List of mathematical jargon#factor through|factors through]] ''h''. 

A basic example in [[topology]] is lifting a [[path (topology)|path]] in one space to a path in a [[covering space]]. Consider, for instance, mapping opposite points on a [[sphere]] to the same point, a continuous map from the sphere covering the [[projective plane]]. A path in the projective plane is a continuous map from the unit interval, [0,1]. We can lift such a path to the sphere by choosing one of the two sphere points mapping to the first point on the path, then maintain continuity. In this case, each of the two starting points forces a unique path on the sphere, the lift of the path in the projective plane. Thus in the category of topological spaces with continuous maps as morphisms, we have
:&lt;math&gt;\begin{align}
 f\colon&amp; [0,1] \to \mathbb{RP}^2 , &amp;\qquad&amp;\text{(projective plane path)} \\
 g\colon&amp; S^2 \to \mathbb{RP}^2 , &amp;\qquad&amp;\text{(covering map)} \\
 h\colon&amp; [0,1] \to S^2 . &amp;\qquad&amp;\text{(sphere path)} 
\end{align}&lt;/math&gt;

Lifts are ubiquitous; for example, the definition of [[fibration]]s (see [[homotopy lifting property]]) and the valuative criteria of [[separated morphism|separated]] and [[proper map]]s of [[scheme (mathematics)|schemes]] are formulated in terms of existence and (in the last case) [[Uniqueness theorem|uniqueness]] of certain lifts.

In [[algebraic topology]] and [[homological algebra]], [[tensor product]] and the [[Hom functor]] are [[tensor-hom adjunction|adjoint]]; however, they might not always lift to an [[exact sequence]]. This leads to the definition of the [[Ext functor]] and the [[Tor functor]].

== See also ==
* [[Covering space]]
* [[Projective module]]

{{Category theory}}

[[Category:Category theory]]

{{categorytheory-stub}}</text>
      <sha1>jt4fdrpgfjbjrbt6l83hyeajjef2r51</sha1>
    </revision>
  </page>
  <page>
    <title>List of integrals of Gaussian functions</title>
    <ns>0</ns>
    <id>30981930</id>
    <revision>
      <id>860709668</id>
      <parentid>825298748</parentid>
      <timestamp>2018-09-22T14:46:42Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <minor/>
      <comment>/* References */minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6258">In these expressions,

:&lt;math&gt;\phi(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2} x^2}&lt;/math&gt;

is the [[standard normal]] probability density function,

:&lt;math&gt;\Phi(x) = \int_{-\infty}^x \phi(t) \, dt = \frac{1}{2}\left(1 + \operatorname{erf}\left(\frac{x}{\sqrt{2}}\right)\right)&lt;/math&gt;

is the corresponding [[cumulative distribution function]] (where '''erf''' is the [[error function]]) and

:&lt;math&gt; T(h,a) = \phi(h)\int_0^a \frac{\phi(hx)}{1+x^2} \, dx&lt;/math&gt;

is [[Owen's T function]].

Owen &lt;ref group=nb&gt;{{harvtxt|Owen|1980}}&lt;/ref&gt; has an extensive list of Gaussian-type integrals; only a subset is given below.

== Indefinite integrals ==
:&lt;math&gt;\int \phi(x) \, dx = \Phi(x) + C&lt;/math&gt;
:&lt;math&gt;\int x \phi(x) \, dx = -\phi(x) + C&lt;/math&gt;
:&lt;math&gt;\int x^2 \phi(x) \, dx  = \Phi(x) - x\phi(x) + C&lt;/math&gt;
:&lt;math&gt;\int x^{2k+1} \phi(x) \, dx = -\phi(x) \sum_{j=0}^k \frac{(2k)!!}{(2j)!!}x^{2j} + C&lt;/math&gt;&lt;ref group="nb"&gt;{{harvtxt|Patel|Read|1996}} lists this integral above without the minus sign, which is an error. See calculation by [http://www.wolframalpha.com/input/?fp=1&amp;i=D(-e^(-x^2/2)/sqrt(2pi)*Sum((2k)!!/(2j)!!*x^(2j),{j,0,k}),x)&amp;s=40&amp;incTime=true WolframAlpha]&lt;/ref&gt;
:&lt;math&gt;\int x^{2k+2} \phi(x) \, dx = -\phi(x)\sum_{j=0}^k\frac{(2k+1)!!}{(2j+1)!!}x^{2j+1} + (2k+1)!!\,\Phi(x) + C&lt;/math&gt;

In these integrals, ''n''!! is the [[double factorial]]: for even ''n'' it is equal to the product of all even numbers from 2 to ''n'', and for odd ''n'' it is the product of all odd numbers from 1 to ''n'' ; additionally it is assumed that {{nowrap|1=0!! = (−1)!! = 1}}.

: &lt;math&gt; \int \phi(x)^2 \, dx           = \frac{1}{2\sqrt{\pi}} \Phi\left(x\sqrt{2}\right) + C &lt;/math&gt;
: &lt;math&gt; \int \phi(x)\phi(a + bx) \, dx = \frac{1}{t}\phi\left(\frac{a}{t}\right)\Phi\left(tx + \frac{ab}{t}\right) + C, \qquad t = \sqrt{1+b^2}&lt;/math&gt;&lt;ref group=nb&gt;{{harvtxt|Patel|Read|1996}} report this integral with error, see [http://www.wolframalpha.com/input/?i=Integrate(1/sqrt(2pi)*e^(-x^2/2)*1/sqrt(2pi)*e^(-(a%2Bb*x)^2/2),x) WolframAlpha]&lt;/ref&gt;
: &lt;math&gt; \int x\phi(a+bx) \, dx         = -\frac{1}{b^2}\left (\phi(a+bx) + a\Phi(a+bx)\right) + C &lt;/math&gt;
: &lt;math&gt; \int x^2\phi(a+bx) \, dx       = \frac{1}{b^3} \left ((a^2+1)\Phi(a+bx) + (a-bx)\phi(a+bx) \right ) + C &lt;/math&gt;
: &lt;math&gt; \int \phi(a+bx)^n \, dx        = \frac{1}{b\sqrt{n(2\pi)^{n-1}}} \Phi\left(\sqrt{n}(a+bx)\right) + C &lt;/math&gt;
: &lt;math&gt; \int \Phi(a+bx) \, dx          = \frac{1}{b} \left ((a+bx)\Phi(a+bx) + \phi(a+bx)\right) + C &lt;/math&gt;
: &lt;math&gt; \int x\Phi(a+bx) \, dx         = \frac{1}{2b^2}\left((b^2x^2 - a^2 - 1)\Phi(a+bx) + (bx-a)\phi(a+bx)\right) + C &lt;/math&gt;
: &lt;math&gt; \int x^2\Phi(a+bx) \, dx       = \frac{1}{3b^3}\left((b^3x^3 + a^3 + 3a)\Phi(a+bx) + (b^2x^2-abx+a^2+2)\phi(a+bx)\right) + C &lt;/math&gt;
: &lt;math&gt; \int x^n \Phi(x) \, dx         = \frac{1}{n+1}\left( \left (x^{n+1}-nx^{n-1} \right )\Phi(x) + x^n\phi(x) + n(n-1)\int x^{n-2}\Phi(x)\,dx \right) + C &lt;/math&gt;
: &lt;math&gt; \int x\phi(x)\Phi(a+bx) \, dx  = \frac{b}{t}\phi\left(\frac{a}{t}\right)\Phi\left(xt + \frac{ab}{t}\right) - \phi(x)\Phi(a+bx) + C, \qquad t = \sqrt{1+b^2} &lt;/math&gt;
: &lt;math&gt; \int \Phi(x)^2 \, dx           = x \Phi(x)^2 + 2\Phi(x)\phi(x) - \frac{1}{\sqrt{\pi}}\Phi\left(x\sqrt{2}\right) + C &lt;/math&gt;
: &lt;math&gt; \int e^{cx}\phi(bx)^n \, dx = \frac{e^{\frac{c^2}{2nb^2}}}{b\sqrt{n(2\pi)^{n-1}}}\Phi \left (\frac{b^2xn-c }{b\sqrt{n}} \right ) + C, \qquad b\ne 0, n&gt;0 &lt;/math&gt;

== Definite integrals ==

: &lt;math&gt; \int_{-\infty}^\infty x^2\phi(x)^n \, dx = \frac{1}{\sqrt{n^3(2\pi)^{n-1}}} &lt;/math&gt;
: &lt;math&gt;\int_{-\infty}^0 \phi(ax)\Phi(bx)dx = \frac{1}{2\pi |a|}\left(\frac{\pi}{2}-\arctan\left(\frac{b}{|a|}\right)\right) &lt;/math&gt; 
: &lt;math&gt;\int_0^{\infty} \phi(ax)\Phi(bx) \, dx = \frac{1}{2\pi |a|}\left(\frac{\pi}{2} + \arctan\left(\frac{b}{|a|}\right)\right) &lt;/math&gt; 
: &lt;math&gt; \int_0^\infty x\phi(x)\Phi(bx) \, dx = \frac{1}{2\sqrt{2\pi}} \left( 1 + \frac{b}{\sqrt{1+b^2}} \right) &lt;/math&gt; 
: &lt;math&gt; \int_0^\infty x^2\phi(x)\Phi(bx) \, dx = \frac{1}{4} + \frac{1}{2\pi} \left(\frac{b}{1+b^2} + \arctan(b) \right) &lt;/math&gt; 
: &lt;math&gt; \int_0^\infty x \phi(x)^2\Phi(x) \, dx = \frac{1}{4\pi\sqrt{3}} &lt;/math&gt;
: &lt;math&gt; \int_0^\infty \Phi(bx)^2 \phi(x) \, dx = \frac{1}{2\pi}\left( \arctan(b) + \arctan \sqrt{1+2b^2} \right) &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^\infty \Phi(a+bx)^2 \phi(x) \,dx = \Phi\left( \frac{a}{\sqrt{1+b^2}} \right)-2T\left( \frac{a}{\sqrt{1+b^2}}, \frac{1}{\sqrt{1+2b^2}} \right) &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^{\infty} x \Phi(a+bx)^2 \phi(x) \,dx = \frac{2b}{\sqrt{1+b^2}} \phi\left(\frac{a}{t}\right) \Phi\left(\frac{a}{\sqrt{1+b^2}\sqrt{1+2b^2}}\right)&lt;/math&gt;&lt;ref group=nb&gt;{{harvtxt|Patel|Read|1996}} report this integral incorrectly by omitting ''x'' from the integrand&lt;/ref&gt;
: &lt;math&gt; \int_{-\infty}^\infty \Phi(bx)^2 \phi(x) \, dx = \frac{1}{\pi}\arctan \sqrt{1+2b^2} &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^\infty x\phi(x)\Phi(bx) \, dx = \int_{-\infty}^\infty x\phi(x)\Phi(bx)^2 \, dx = \frac{b}{\sqrt{2\pi(1+b^2)}} &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^\infty \Phi(a+bx)\phi(x) \, dx = \Phi\left(\frac{a}{\sqrt{1+b^2}}\right) &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^\infty x\Phi(a+bx)\phi(x) \, dx = \frac{b}{t}\phi\left(\frac{a}{t}\right), \qquad t = \sqrt{1+b^2} &lt;/math&gt;
: &lt;math&gt; \int_0^\infty x\Phi(a+bx)\phi(x) \, dx =\frac{b}{t}\phi\left(\frac{a}{t}\right)\Phi\left(-\frac{ab}{t}\right) + \frac{1}{\sqrt{2\pi}}\Phi(a), \qquad t = \sqrt{1+b^2}  &lt;/math&gt; 
: &lt;math&gt; \int_{-\infty}^\infty \ln(x^2) \frac{1}{\sigma}\phi\left(\frac{x}{\sigma}\right) \, dx = \ln(\sigma^2) - \gamma - \ln 2 \approx \ln(\sigma^2) - 1.27036 &lt;/math&gt;

== References ==
{{reflist|group=nb}}

* {{cite book
  | last1 = Patel | first1 = Jagdish K.
  | last2 = Read  | first2 = Campbell B.
  | year = 1996
  | title = Handbook of the normal distribution | edition = 2nd
  | publisher = CRC Press
  | isbn = 0-8247-9342-0
  | ref = harv
  }}

* {{cite article
  | last1 = Owen | first1 = D.
  | year = 1980
  | title = A table of normal integrals
  | journal = Communications in Statistics: Simulation and Computation
  | pages = 389–419
  | volume = B9
  | ref = harv
  }}

{{Lists of integrals}}

{{DEFAULTSORT:Integrals of Gaussian functions}}
[[Category:Integrals|Gaussian functions]]
[[Category:Mathematics-related lists]]
[[Category:Gaussian function]]</text>
      <sha1>eofob3174kh08h13carg844xl903fzh</sha1>
    </revision>
  </page>
  <page>
    <title>Low (computability)</title>
    <ns>0</ns>
    <id>9767106</id>
    <revision>
      <id>711626350</id>
      <parentid>657249275</parentid>
      <timestamp>2016-03-23T23:21:43Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2253">In [[recursion theory|computability theory]], a [[Turing degree]] [''X''] is '''low''' if the [[Turing jump]] [''X''&amp;prime;] is 0&amp;prime;. A set is low if it has low degree. Since every set is computable from its jump, any low set is computable in 0&amp;prime;, but the jump of sets computable in 0&amp;prime; can bound any degree r.e. in 0&amp;prime; (Schoenfield Jump Inversion).  ''X'' being low says that its jump ''X''&amp;prime; has the least possible degree in terms of [[Turing reducibility]] for the jump of a set.

A degree is ''low n'' if its n'th jump is the n'th jump of 0. A set ''X'' is ''generalized low'' if it satisfies ''X''&amp;prime; ≡&lt;sub&gt;T&lt;/sub&gt; ''X'' + 0&amp;prime;, that is: if its jump has the lowest degree possible. And a degree '''d''' is ''generalized low n'' if its n'th jump is the (n-1)'st jump of the join of '''d''' with 0&amp;prime;. More generally, properties of sets which describe their being computationally weak (when used as a Turing oracle) are referred to under the umbrella term ''lowness properties''.

By the [[Low basis theorem]] of Jockusch and Soare, any nonempty &lt;math&gt;\Pi^0_1&lt;/math&gt; class in &lt;math&gt;2^\omega&lt;/math&gt; contains a set of low degree. This implies that, although low sets are computationally weak, they can still accomplish such feats as [[PA degree|computing a completion of Peano Arithmetic]]. In practice, this allows a restriction on the computational power of objects needed for recursion theoretic constructions: for example, those used in the analyzing the [[Reverse mathematics|proof-theoretic strength]] of [[Ramsey's theorem]].

==See also==
*[[High (computability)]]
*[[Low Basis Theorem]]

== References ==
{{reflist}}
* {{cite book | first=Robert I. | last=Soare | title=Recursively enumerable sets and degrees. A study of computable functions and computably generated sets | series=Perspectives in Mathematical Logic | publisher=[[Springer-Verlag]] | location=Berlin | year=1987 | isbn=3-540-15299-7 | zbl=0667.03030 }}
* {{cite book | last=Nies | first=André | title=Computability and randomness | series=Oxford Logic Guides | volume=51 | location=Oxford | publisher=Oxford University Press | year=2009 | isbn=978-0-19-923076-1 | zbl=1169.03034 }}

[[Category:Computability theory]]


{{Mathlogic-stub}}</text>
      <sha1>brqvignjpcqbi9ye729v8g5cxf98jto</sha1>
    </revision>
  </page>
  <page>
    <title>Management science</title>
    <ns>0</ns>
    <id>20200</id>
    <revision>
      <id>860378007</id>
      <parentid>854233923</parentid>
      <timestamp>2018-09-20T07:51:49Z</timestamp>
      <contributor>
        <username>Lavidav</username>
        <id>34661654</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7594">{{for|the academic journal|Management Science (journal)}}
'''Management science''' ('''MS'''), is the broad interdisciplinary study of problem solving and decision making in human organizations, with strong links to [[management]], [[economics]], [[business]], [[engineering]], [[management consulting]], and other [[sciences]]. It uses various scientific [[research]]-based [[principles]], [[strategies]], and [[analytical method]]s including  [[mathematical model]]ing, [[statistics]] and [[numerical algorithm]]s to improve an organization's ability to enact rational and accurate [[management]] decisions by arriving at optimal or near optimal solutions to complex decision problems.  Management sciences help businesses to achieve goals using various scientific methods. 

The field was initially an outgrowth of [[applied mathematics]], where early challenges were problems relating to the [[optimization]] of systems which could be modeled linearly, i.e., determining the optima ([[Maxima and minima|maximum]] value of [[profit (accounting)|profit]], assembly line performance, [[crop yield]], bandwidth, etc. or [[Maxima and minima|minimum]] of loss, risk, costs, etc.) of some objective function. Today, management science encompasses any organizational activity for which the problem can be structured as a functional system so as to obtain a solution set with identifiable characteristics.

== Overview ==
Management science is concerned with a number of different areas of study: One is developing and applying [[scientific modeling|model]]s and [[concept]]s that may prove useful in helping to illuminate [[management]] issues and solve managerial problems. The models used can often be represented mathematically, but sometimes computer-based, [[visual]] or [[Speech|verbal]] representations are used as well or instead.&lt;ref name= "LS"&gt; [http://www.lums.lancs.ac.uk/departments/ManSci/DeptProfile/WhatisManSci/ What is Management Science?] Lancaster University, 2008. Retrieved 5 June 2008.&lt;/ref&gt; Another area is designing and developing new and better models of organizational excellence. 

Management science research can be done on three levels:&lt;ref&gt;[http://www.jbs.cam.ac.uk/programmes/mphil_mgtscience/mgtresearch.html What is Management Science Research?] University of Cambridge 2008. Retrieved 5 June 2008.&lt;/ref&gt;
* The fundamental level lies in three mathematical disciplines: [[probability]], [[Optimization (mathematics)|optimization]], and [[dynamical systems theory]].
* The modeling level is about building models, analyzing them mathematically, gathering and analyzing data, implementing models on computers, solving them, experimenting with them&amp;mdash;all this is part of management science research on the modeling level. This level is mainly instrumental, and driven mainly by [[statistics]] and [[econometrics]]. 
* The application level, just as in any other [[engineering]] and [[economics]] disciplines, strives to make a practical impact and be a driver for change in the real world.

The management scientist's mandate is to use rational, systematic, science-based techniques to inform and improve decisions of all kinds. The techniques of management science are not restricted to business applications but may be applied to [[military]], medical, [[public administration]], charitable groups, political groups or community groups.

== History ==
Its origins can be traced to [[operations research]], which made its debut during [[World War II]] when the Allied forces recruited scientists of various disciplines to assist with military operations. In these early applications, the scientists utilized simple mathematical models to make efficient use of limited technologies and resources. The application of these models within the corporate sector became known as management science.&lt;ref name="UTK"&gt; [http://bus.utk.edu/soms/information/whatis_msci.html What is Management Science?] The University of Tennessee, 2006. Retrieved 5 June 2008.&lt;/ref&gt; 

In 1967 [[Stafford Beer]] characterized the field of management science as "the business use of operations research".&lt;ref&gt;[[Stafford Beer]] (1967). ''Management Science: The Business Use of Operations Research''&lt;/ref&gt;

== Theory ==
Some of the fields that management science involves include:  
{{div col|colwidth=22em}}
* [[Data mining]]
* [[Decision analysis]] 
* [[Engineering]]
* [[Forecasting]] 
* [[Game theory]]
* [[Industrial engineering]]
* [[Logistics]]
* [[Mathematical modeling]]
* [[Optimization (mathematics)|Optimization]]
* [[Probability and statistics]]
* [[Project management]]
* [[Psychology]]
* [[Simulation]]
* [[Social network]] / [[Transportation forecasting]] models
* [[Sociology]]
* [[Supply chain management]] 
* [[Management Consulting]] 
{{div col end}}
as well as many others.

== Applications ==
Applications of management science are abundant in industry as [[airlines]], manufacturing companies, [[service organization]]s, military branches, and in [[government]]. The range of problems and issues to which management science has contributed insights and solutions is vast. It includes:.&lt;ref name= "LS"/&gt;
* [[scheduling]] airlines, both planes and crew 
* deciding the appropriate place to site new facilities such as a warehouse or factory 
* managing the flow of water from reservoirs 
* identifying possible future development paths for parts of the telecommunications industry 
* establishing the information needs and appropriate systems to supply them within the health service 
* identifying and understanding the strategies adopted by companies for their [[information system]]s

Management science  is also concerned with so-called "soft-operational analysis", which concerns methods for [[strategic planning]], strategic [[decision support]], and [[problem structuring methods]] (PSM). At this level of abstraction, mathematical modeling and simulation will not suffice. Therefore, during the past 30 years, a number of non-quantified modelling methods have been developed. These include [[morphological analysis (problem-solving)|morphological analysis]] and various forms of [[influence diagram]]s.

== See also ==
{{Wikiquote}}
{{div col}}
* [[Econometrics]]
* [[Institute for Operations Research and the Management Sciences]]
* [[John von Neumann Theory Prize]]
* [[Managerial economics]]
* [[Management engineering]]
* [[Innovation Management]]
{{div col end}}

== References ==
{{reflist}}

== Further reading ==
* Kenneth R. Baker, Dean H. Kropp (1985). ''Management Science: An Introduction to the Use of Decision Models''
* [[Stafford Beer]] (1967). ''Management Science: The Business Use of Operations Research''
* David Charles Heinze (1982). ''Management Science: Introductory Concepts and Applications''
* Lee J. Krajewski, Howard E. Thompson (1981). "Management Science: Quantitative Methods in Context"
* Thomas W. Knowles (1989). ''Management science: Building and Using Models''
* Kamlesh Mathur, Daniel Solow (1994). ''Management Science: The Art of Decision Making''
* Laurence J. Moore, Sang M. Lee, Bernard W. Taylor (1993). ''Management Science''
* William Thomas Morris (1968). ''Management Science: A Bayesian Introduction''.
* William E. Pinney, Donald B. McWilliams (1987). ''Management Science: An Introduction to Quantitative Analysis for Management''
* Gerald E. Thompson (1982). ''Management Science: An Introduction to Modern Quantitative Analysis and Decision Making. New York : McGraw-Hill Publishing Co.

[[Category:Management]]
[[category:Operations research]]
[[Category:Behavioural sciences]]
[[Category:Management science| ]]</text>
      <sha1>fvmd47ly0kk6i0fwgvobts1i3sact9w</sha1>
    </revision>
  </page>
  <page>
    <title>Math in Moscow</title>
    <ns>0</ns>
    <id>27194034</id>
    <revision>
      <id>853103612</id>
      <parentid>841276839</parentid>
      <timestamp>2018-08-02T13:06:01Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>Disambiguate [[Harvey Mudd]] to [[Harvey Mudd College]] using [[:en:Wikipedia:Tools/Navigation_popups|popups]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7634">'''Math in Moscow''' (MiM) is a one-semester study abroad program for North American and European undergraduates held at the [[Independent University of Moscow]] (IUM) in [[Moscow]], [[Russia]]. The program consists mainly of math courses that are taught in English. The program was first offered in 2001,&lt;ref&gt; Yu. S. Ilyashenko and A. B. Sossinsky: The Independent University of Moscow, [[Newsletter of the European Mathematical Society|EMS Newsletter]], March 2010, p.42 http://www.ems-ph.org/journals/newsletter/pdf/2010-03-75.pdf &lt;/ref&gt; and since 2008 has been run jointly by the [[Independent University of Moscow]], Moscow Center for Continuous Mathematical Education, and the [[Higher School of Economics]] (HSE).  

The program has hosted over 200 participants, including students from Harvard, Princeton, MIT, [[Harvey Mudd College|Harvey Mudd]], Berkeley, Cornell, Yale, McGill, Toronto and Montreal.&lt;ref&gt; The list of the MiM alumni http://www.mccme.ru/mathinmoscow/index.php?page=22 &lt;/ref&gt;&lt;ref&gt; The list of home universities http://www.mccme.ru/mathinmoscow/index.php?page=24 &lt;/ref&gt;

==Features==
The MiM semester lasts fifteen weeks with fourteen weeks of teaching and one week of exams.&lt;ref&gt; MiM schedule http://www.mccme.ru/mathinmoscow/index.php?page=9 &lt;/ref&gt; Math courses are lectured by professors of the [[Independent University of Moscow]] and the Math Department of [[National Research University Higher School of Economics]]. The cultural elements of the program include organized trips to [[Saint Petersburg]] and to the [[Golden Ring]] towns of [[Vladimir, Russia|Vladimir]] and [[Suzdal]].&lt;ref&gt; MiM picasa photoalbums https://plus.google.com/photos/101813577580794585847/albums &lt;/ref&gt;  Students live in the dormitory of the Higher School of Economics.

Each semester the [[American Mathematical Society]] offers up to five "Math in Moscow" scholarships provided by the [[National Science Foundation]] to US undergraduates,&lt;ref&gt; The AMS scholarships page http://www.ams.org/programs/travel-grants/mimoscow &lt;/ref&gt;&lt;ref&gt; Notices of the AMS, January 2012 http://www.ams.org/notices/201202/rtx120200328p.pdf&lt;/ref&gt; and the [[Canadian Mathematical Society]] offers one or two [[Natural Sciences and Engineering Research Council of Canada|NSERC]] scholarships to Canadian students.&lt;ref&gt; The CMS page about Math in Moscow scholarships http://cms.math.ca/Scholarships/Moscow/Moscow_appl.pdf&lt;/ref&gt;

The program is often reviewed favorably by North American students and their departments.&lt;ref&gt; A note about an UNC student http://www.unco.edu/news/releases.aspx?id=1229 &lt;/ref&gt;&lt;ref&gt; FIU news http://news.fiu.edu/2009/10/life-in-moscow-for-fiu-math-students/6818 &lt;/ref&gt;&lt;ref&gt; The report of an MIT student {{cite web |url=http://math.mit.edu/academics/undergrad/general/international/emma.pdf |title=Archived copy |accessdate=2012-03-10 |deadurl=yes |archiveurl=https://web.archive.org/web/20110610212938/http://math.mit.edu/academics/undergrad/general/international/emma.pdf |archivedate=2011-06-10 |df= }} &lt;/ref&gt;

==Curriculum==
The primary curriculum is entirely mathematical, drawing from every major field of mathematics. All courses are taught jointly with the Higher School of Economics, and are often attended by students from the HSE master's program. Likewise, Math in Moscow participants may attend open lectures and seminars at the Higher School of Economics. The Math in Moscow courses are formally divided into three groups according to the expected prerequisites, however admitted students may choose to attend whichever and as many courses as they wish. An incoming aptitude exam is administered to assist in advising students' course selections.&lt;ref&gt;List and contents of MiM courses http://www.mccme.ru/mathinmoscow/index.php?page=10 &lt;/ref&gt;  

All courses expect at least a semester each of analysis and linear algebra as prerequisites. Courses at the first level require no more than this basic formal background, but are generally more intensive than their equivalents at North American universities, often taught from first-year graduate texts and presenting material typically covered only at a graduate level; intermediate courses correspond to senior-level offerings at scientifically-focused American and Canadian institutions; and advanced courses are graduate-level.&lt;ref&gt;Paul D. Humke, Yulij Ilyashenko, and [[Serge Tabachnikov]], "Bringing Eastern European Mathematical Traditions to North American Students," p. 3 http://www.ams.org/notices/200310/comm-humke.pdf&lt;/ref&gt; 
;Elementary Courses
{{div col|colwidth=27em}}
* [[Combinatorics]]
* [[Theoretical computer science|Programming]]: From an Art to a Science
* [[Topology]] I
* [[Linear algebra|Advanced Linear Algebra]]
* [[Abstract algebra|Basic Algebra]]
* Geometric Foundations of Analysis
* [[Non-Euclidean geometry]]
* [[Ordinary Differential Equations]]
{{div col end}}
;Intermediate courses
{{div col|colwidth=27em}}
* Advanced Algebra
* [[Differential Geometry]]
* [[Differentiable manifold|Calculus on Manifolds]]
* [[Complex Analysis]]
* [[Ergodic theory|Ergodic Theory of Dynamical Systems]]
* [[Knot Theory]]
* [[Algebraic Number Theory]]
* Topology II: Introduction to [[Homology (mathematics)|Homology and Cohomology Theory]]
* [[Algebraic Geometry]]
* [[Representation theory|Basic Representation Theory]]
* [[Recursion theory|Computability]] and [[Computational complexity theory|Complexity]]
{{div col end}}
;Advanced courses
{{div col|colwidth=27em}}
* Equations of [[Mathematical Physics]]
* Introduction to Commutative and Homological Algebra
* [[Catastrophe theory|Mathematical Catastrophe Theory]]
* [[Riemann Surfaces]]
{{div col end}}
In addition to the mathematical curriculum, students are offered electives in Russian literature, Russia history, history of mathematics and science, and Russian language.

==Course structure==

The courses deviate in structure from standard courses in the United States, Canada, and Europe. The Russian pedagogical tradition emphasizes developing the active participation of students. Classes are designed to encourage dialogues between the students and the teacher, which is more easily achieved in the program's small classes of two to ten students. Each math course runs three hours once a week. Roughly speaking, classes devote an hour and a half of lecture and an hour and a half of exercises, although structure deviates from course to course. Students may choose any number of courses, in practice between three and six from the mathematical curriculum.  Courses are run jointly with the [[National Research University Higher School of Economics|Higher School of Economics]] M.Sc program. Most of the Math in Moscow courses are given at the building of the Independent University of Moscow, located in the center of Moscow near the historic [[Arbat]], some take place in the building of the Higher School of Economics. &lt;ref&gt; IUM contacts http://ium.mccme.ru/english/contact.html&lt;/ref&gt;

==See also==
* [[Budapest Semesters in Mathematics]] is a similar program held in [[Budapest]], [[Hungary]].

==References==
{{Reflist}}

==External links==
* [http://www.mccme.ru/mathinmoscow/index.php The home page of the program]
* [http://www.facebook.com/pages/Math-in-Moscow/141453659229591 The Facebook page of the program ]
* [https://www.youtube.com/user/MathInMoscow/videos Youtube videos of the program]
* [http://www.mccme.ru/ium/english/ The home page of the Independent University of Moscow (in English)]
* [http://cie.hse.ru/ The home page of the Center for International Education Higher School of Economics]

[[Category:Study abroad programs]]
[[Category:Mathematics education]]</text>
      <sha1>jbpknmzrx8f9afqt3izi4yood24m5q4</sha1>
    </revision>
  </page>
  <page>
    <title>Object-modeling technique</title>
    <ns>0</ns>
    <id>208502</id>
    <revision>
      <id>838933002</id>
      <parentid>787360787</parentid>
      <timestamp>2018-04-30T06:25:08Z</timestamp>
      <contributor>
        <ip>2600:1700:BA70:6BE0:A877:5055:718D:CC35</ip>
      </contributor>
      <comment>/* Further reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3849">[[Image:OMT object diagram.png|thumb|240px|OMT object diagram]]
[[Image:OMT state diagram.png|thumb|360px|OMT [[state diagram]]]]
The '''object-modeling technique''' ('''OMT''') is an [[object modeling language|object modeling]]&lt;nowiki/&gt; approach for [[Computer software|software]] modeling and designing.  It was developed around 1991 by [[James Rumbaugh|Rumbaugh]], Blaha, Premerlani, Eddy and Lorensen as a method to develop [[Object-oriented analysis and design|object-oriented systems]] and to support [[object-oriented programming]]. OMT describes object model or static structure of the system.

OMT was developed as an approach to [[software development]]. The purposes of modeling according to Rumbaugh are:&lt;ref&gt;Rumbaugh et al. (1991:15)&lt;/ref&gt;&lt;ref name="Tot97"&gt;Terje Totland (1997). [http://www.idi.ntnu.no/grupper/su/publ/html/totland/ch0527.htm 5.2.7 Object Modeling Technique (OMT)] Thesis, Norwegian University of Science and Technology (NTNU), Trondheim.&lt;/ref&gt;
* testing physical entities before building them (simulation),
* communication with customers,
* visualization (alternative presentation of information), and
* reduction of complexity.

OMT has proposed three main types of models:
* ''Object model'': The object model represents the static and most stable phenomena in the modeled domain.&lt;ref&gt;(Rumbaugh et al.,1991:21)&lt;/ref&gt; Main concepts are classes and associations with attributes and operations. Aggregation and generalization (with multiple inheritance) are predefined relationships.&lt;ref name="Tot97"/&gt;
* ''Dynamic model'': The dynamic model represents a state/transition view on the model. Main concepts are states, transitions between states, and events to trigger transitions. Actions can be modeled as occurring within states. Generalization and aggregation (concurrency) are predefined relationships.&lt;ref name="Tot97"/&gt;
* ''Functional model'': The functional model handles the process perspective of the model, corresponding roughly to data flow diagrams. Main concepts are process, data store, data flow, and actors.&lt;ref name="Tot97"/&gt;

OMT is a predecessor of the [[Unified Modeling Language]] (UML). Many OMT modeling elements are common to UML.

Functional Model in OMT:
In brief, a functional model in OMT defines the function of the whole internal processes in a model with the help of "Data Flow Diagrams (DFDs)". It details how processes are performed independently.

== References ==
{{Reflist}}

==Further reading==
*[[James Rumbaugh]], Michael Blaha, William Premerlani, Frederick Eddy, William Lorensen (1994). ''Object-Oriented Modeling and Design''. Prentice Hall. {{ISBN|0-13-629841-9}}
* Terry Quatrani, Michael Jesse Chonoles (1996). ''Succeeding With the Booch and OMT Methods: A Practical Approach''. Addison Wesley. {{ISBN|978-0-8053-2279-8}}

==External links==
*[http://marchingcubes.org/index.php/Object_Oriented_Modeling Some of the early history of OMT]
*[http://www.idi.ntnu.no/grupper/su/publ/html/totland/ch0527.htm A short introduction to OMT] 

&lt;!--Interwikies--&gt;

{{DEFAULTSORT:Object-Modeling Technique}}
&lt;!--Categories--&gt;
[[Category:Object-oriented programming]]
[[Category:Unified Modeling Language]]
The model is defined by the organization’s vision, mission, and values, as well as sets of boundaries for the organization—what products or services it will deliver, what customers or markets it will target, and what supply and delivery channels it will use. While the business model includes high-level strategies and tactical direction for how the organization will implement the model, it also includes the annual goals that set the specific steps the organization intends to undertake in the next year and the measures for their expected accomplishment. Each of these is likely to be part of internal documentation that is available to the internal auditor.

{{uml-stub}}</text>
      <sha1>khjbekoxxw0zh1f7hp4o5346oup6prp</sha1>
    </revision>
  </page>
  <page>
    <title>Omega-categorical theory</title>
    <ns>0</ns>
    <id>26628083</id>
    <revision>
      <id>841513649</id>
      <parentid>755737340</parentid>
      <timestamp>2018-05-16T09:15:00Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3860">In [[mathematical logic]], an '''omega-categorical theory''' is a [[theory (mathematical logic)|theory]] that has exactly one [[countable set|countably infinite]] [[model (logic)|model]] [[up to]] [[isomorphism]].  Omega-categoricity is the special case κ&amp;nbsp;=&amp;nbsp;&lt;math&gt;\aleph_0&lt;/math&gt;&amp;nbsp;=&amp;nbsp;ω of [[Morley's categoricity theorem|κ-categoricity]], and omega-categorical theories are also referred to as '''ω-categorical'''.  The notion is most important for countable [[first-order logic|first-order]] theories.

==Equivalent conditions for omega-categoricity==

Many conditions on a theory are equivalent to the property of omega-categoricity. In 1959 [[Erwin Engeler]], [[Czesław Ryll-Nardzewski]] and [[Lars Svenonius]], proved several independently.&lt;ref name=primer&gt;Rami Grossberg, José Iovino and Olivier Lessmann, [http://www.springerlink.com/content/hqfj5ueexbwlhtwq/ ''A primer of simple theories'']&lt;/ref&gt; Despite this, the literature still widely refers to the Ryll-Nardzewski theorem as a name for these conditions. The conditions included with the theorem vary between authors.&lt;ref name=Hodges341&gt;Hodges, Model Theory, p. 341.&lt;/ref&gt;&lt;ref name=Rothmaler&gt;Rothmaler, p. 200.&lt;/ref&gt;

Given a countable [[Complete theory|complete]] first-order theory ''T'' with infinite models, the following are equivalent:
* The theory ''T'' is omega-categorical.
* Every countable model of ''T'' has an [[Oligomorphic group|oligomorphic automorphism group]].
* Some countable model of ''T'' has an oligomorphic automorphism group.&lt;ref name=Cam30&gt;Cameron (1990) p.30&lt;/ref&gt;
* The theory ''T'' has a model which, for every natural number ''n'', realizes only finitely many ''n''-types, that is, the [[Type (model theory)#Stone spaces|Stone space]] ''S&lt;sub&gt;n&lt;/sub&gt;''(''T'') is finite.
* For every natural number ''n'', ''T'' has only finitely many ''n''-types.
* For every natural number ''n'', every ''n''-type is [[Type (model theory)|isolated]].
* For every natural number ''n'', up to equivalence modulo ''T'' there are only finitely many formulas with ''n'' free variables, in other words, for every ''n'', the ''n''th [[Lindenbaum–Tarski algebra]] of ''T'' is finite.
* Every model of ''T'' is [[Atomic model (mathematical logic)|atomic]].
* Every countable model of ''T'' is atomic.
* The theory ''T'' has a countable atomic and [[saturated model]].
* The theory ''T'' has a saturated [[prime model]].

==Notes==
&lt;references /&gt;

==References==
* {{citation | last=Cameron | first=Peter J. | authorlink=Peter Cameron (mathematician) | title=Oligomorphic permutation groups | series=London Mathematical Society Lecture Note Series | volume=152 | location=Cambridge | publisher=Cambridge University Press | year=1990 | isbn=0-521-38836-8 | zbl=0813.20002 }}
* {{Citation | last1=Chang | first1=Chen Chung | last2=Keisler | first2=H. Jerome | author2-link=Howard Jerome Keisler | title=Model Theory | origyear=1973 | publisher=Elsevier | isbn=978-0-7204-0692-4 | year=1989}}
* {{Citation | last1=Hodges | first1=Wilfrid | author1-link=Wilfrid Hodges | title=Model theory | publisher=Cambridge University Press | location=Cambridge | isbn=978-0-521-30442-9 | year=1993}}
* {{Citation | last1=Hodges | first1=Wilfrid | author1-link=Wilfrid Hodges | title=A shorter model theory | publisher=Cambridge University Press | location=Cambridge | isbn=978-0-521-58713-6 | year=1997}}
* {{Citation | last1=Poizat | first1=Bruno | title=A Course in Model Theory: An Introduction to Contemporary Mathematical Logic | publisher=Springer-Verlag | location=Berlin, New York | isbn=978-0-387-98655-5 | year=2000}}
* {{Citation | last1=Rothmaler | first1=Philipp | title=Introduction to Model Theory | publisher=Taylor &amp; Francis | location=New York | isbn=978-90-5699-313-9 | year=2000}}

[[Category:Model theory]]
[[Category:Mathematical theorems]]


{{mathlogic-stub}}</text>
      <sha1>5v7cifrd5tneq5hbg8qzfkmtvk1ub8b</sha1>
    </revision>
  </page>
  <page>
    <title>Phenomenological model</title>
    <ns>0</ns>
    <id>44903985</id>
    <revision>
      <id>824736652</id>
      <parentid>799457614</parentid>
      <timestamp>2018-02-09T04:33:45Z</timestamp>
      <contributor>
        <username>Illegitimate Barrister</username>
        <id>12006778</id>
      </contributor>
      <comment>/* Examples of Use */ typo fix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2482">A '''phenomenological model''' is a [[scientific model]] that describes the [[empirical relationship]] of [[phenomena]] to each other, in a way which is consistent with fundamental theory, but is not directly derived from theory. In other words, a phenomenological model is not derived from [[first principle]]s. A phenomenological model foregoes any attempt to explain why the variables interact the way they do, and simply attempts to describe the relationship, with the assumption that the relationship extends past the measured values.&lt;ref&gt;{{cite book|last1=Hilborn|first1=Ray|last2=Mangel|first2=Marc|title=The Ecological Detective Confronting Models with Data (MPB-28).|date=2013|publisher=Princeton University Press|location=Princeton|isbn=9781400847310|edition=Online-Ausg.}}&lt;/ref&gt;{{Page needed|date=July 2015}} [[Regression analysis]] is sometimes used to create [[statistical model]]s that serve as phenomenological models.

==Examples of use==
Phenomenological models have been characterized as being completely independent of theories,&lt;ref&gt;McMullin, Ernan (1968), “What Do Physical Models Tell Us?”, in B. van Rootselaar and J. F. Staal (eds.), Logic, Methodology and Science III. Amsterdam: North Holland, 385–396.&lt;/ref&gt; though many phenomenological models, while failing to be derivable from a theory, incorporate principles and laws associated with theories.&lt;ref&gt;{{cite encyclopedia |last1= Roman |first1= Frigg |author-link1=Roman Frigg |last2= Hartmann |first2= Stephan | author-link2= Stephan Hartmann |editor-last= Zalta |editor-first=Edward N. |editor-link= |encyclopedia= The Stanford Encyclopedia of Philosophy |title=Models in Science |trans-title= |url=http://plato.stanford.edu/archives/fall2012/entries/models-science/ |access-date=24 July 2015 |language= |edition=Fall 2012 |date= |year= |publisher= |series= |volume= |location= |id= |isbn= |oclc= |doi= |pages= |quote= |ref=}}&lt;/ref&gt; The liquid drop model of the atomic nucleus, for instance, portrays the nucleus as a liquid drop and describes it as having several properties (surface tension and charge, among others) originating in different theories (hydrodynamics and electrodynamics, respectively). Certain aspects of these theories—though usually not the complete theory—are then used to determine both the static and dynamical properties of the nucleus.

== References ==
{{Reflist}}

[[Category:Scientific modeling]]
[[Category:Statistical models]]
[[Category:Philosophy of statistics]]</text>
      <sha1>iwakp0k4kahpcd26bopvc0oknvi9peo</sha1>
    </revision>
  </page>
  <page>
    <title>Power set</title>
    <ns>0</ns>
    <id>23799</id>
    <revision>
      <id>870038118</id>
      <parentid>868621138</parentid>
      <timestamp>2018-11-21T23:55:02Z</timestamp>
      <contributor>
        <ip>62.194.145.230</ip>
      </contributor>
      <comment>/* Subsets of limited cardinality */ [S]^k is a more common notation. P^+(S) is also common.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16085">{{For|the search engine developer|Powerset (company)}}

[[Image:Hasse diagram of powerset of 3.svg|thumb|250px|The elements of the power set of the set {''x'', ''y'', ''z''}  [[order theory|ordered]] with respect to [[Inclusion (set theory)|inclusion]].]]

In [[mathematics]], the '''power set''' (or '''powerset''') of any [[Set (mathematics)|set]] {{mvar|''S''}} is the set of all [[subset]]s of {{mvar|''S''}}, including the [[empty set]] and {{mvar|S}} itself, variously denoted as {{mathcal|P}}({{mvar|S}}), 𝒫({{mvar|''S''}}), ℘({{mvar|''S''}}) (using the "[[Weierstrass p]]"), {{math|''P''(''S'')}}, {{math|ℙ(''S'')}}, or, identifying the powerset of {{mvar|''S''}} with the set of all functions from {{mvar|''S''}} to a given set of two elements, {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}}. In [[axiomatic set theory]] (as developed, for example, in the [[ZFC]] axioms), the existence of the power set of any set is [[postulated]] by the [[axiom of power set]].&lt;ref&gt;{{harvnb|Devlin|1979|page=50}}&lt;/ref&gt;

Any subset of {{mathcal|P}}({{mvar|S}}) is called a ''[[family of sets]]'' over {{mvar|''S''}}.

==Example==
If {{mvar|S}} is the set {{math|{{mset|''x'', ''y'', ''z''}}}}, then the subsets of {{mvar|S}} are

* {{math|{{mset}}}} (also denoted &lt;math&gt;\varnothing&lt;/math&gt; or &lt;math&gt;\empty&lt;/math&gt;, the  [[empty set]] or the null set)
* {{math|{{mset|''x''}}}}
* {{math|{{mset|''y''}}}}
* {{math|{{mset|''z''}}}}
* {{math|{{mset|''x'', ''y''}}}}
* {{math|{{mset|''x'', ''z''}}}}
* {{math|{{mset|''y'', ''z''}}}}
* {{math|{{mset|''x'', ''y'', ''z''}}}}
and hence the power set of {{mvar|S}} is {{math|{{mset|{{mset}},
{{mset|''x''}},
{{mset|''y''}},
{{mset|''z''}},
{{mset|''x'', ''y''}},
{{mset|''x'', ''z''}},
{{mset|''y'', ''z''}},
{{mset|''x'', ''y'', ''z''}}}}}}.&lt;ref&gt;{{harvnb|Puntambekar|2007|pages=1–2}}&lt;/ref&gt;

==Properties==
If {{mvar|''S''}} is a finite set with {{math|1={{!}}''S''{{!}} = ''n''}} elements, then the number of subsets of {{mvar|''S''}} is {{math|1={{!}}{{mathcal|P}}(''S''){{!}} = 2&lt;sup&gt;''n''&lt;/sup&gt;}}. This fact, which is the motivation for the notation {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}}, may be demonstrated simply as follows,
: First, order the elements of {{mvar|S}} in any manner. We write any subset of {{mvar|''S''}} in the format {{math|{γ&lt;sub&gt;1&lt;/sub&gt;, γ&lt;sub&gt;2&lt;/sub&gt;, ..., γ&lt;sub&gt;''n''&lt;/sub&gt; }}} where {{math|γ&lt;sub&gt;i&lt;/sub&gt; , 1 ≤ ''i'' ≤ ''n''}}, can take the value of {{math|0}} or {{math|1}}. If {{math|1=γ&lt;sub&gt;''i''&lt;/sub&gt; = 1}}, the {{mvar|i}}-th element of {{mvar|''S''}} is in the subset; otherwise, the {{mvar|i}}-th element is not in the subset. Clearly the number of distinct subsets that can be constructed this way is {{math|2&lt;sup&gt;''n''&lt;/sup&gt;}} as {{math|γ&lt;sub&gt;''i''&lt;/sub&gt; ∈ {0, 1} }}.

[[Cantor's diagonal argument#General sets|Cantor's diagonal argument]] shows that the power set of a set (whether infinite or not) always has strictly higher [[cardinality]] than the set itself (informally the power set must be larger than the original set). In particular, [[Cantor's theorem]] shows that the power set of a [[countable set|countably infinite]] set is [[uncountable|uncountably]] infinite. The power set of the set of [[natural number]]s can be put in a [[bijection|one-to-one correspondence]] with the set of [[real number]]s (see [[Cardinality of the continuum]]).

The power set of a set {{mvar|''S''}}, together with the operations of [[union (set theory)|union]], [[intersection (set theory)|intersection]] and [[complement (set theory)|complement]] can be viewed as the prototypical example of a [[Boolean algebra (structure)|Boolean algebra]]. In fact, one can show that any ''finite'' Boolean algebra is [[isomorphic]] to the Boolean algebra of the power set of a finite set. For ''infinite'' Boolean algebras this is no longer true, but every infinite Boolean algebra can be represented as a [[subalgebra]] of a power set Boolean algebra (see [[Stone's representation theorem]]).

The power set of a set {{mvar|''S''}} forms an [[abelian group]] when considered with the operation of [[symmetric difference]] (with the empty set as the identity element and each set being its own inverse) and a [[commutative]] [[monoid]] when considered with the operation of intersection. It can hence be shown (by proving the [[Distributive property|distributive laws]]) that the power set considered together with both of these operations forms a [[Boolean ring]].

==Representing subsets as functions== &lt;!-- this section is referenced forme some other place in this article, do not change its title carelessly --&gt;
In set theory, [[Function (mathematics)#Function space|{{math|''X''&lt;sup&gt;''Y''&lt;/sup&gt;}}]] is the set of all [[function (mathematics)|function]]s from {{mvar|Y}} to {{mvar|X}}.  As "2" can be defined as {{math|{{mset|0,1}}}} (see [[Natural number#A standard construction|natural number]]), {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}} (i.e., {{math|{{mset|0,1}}&lt;sup&gt;''S''&lt;/sup&gt;}}) is the set of all [[function (mathematics)|function]]s from {{mvar|''S''}} to {0,1}.  By identifying a function in {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}} with the corresponding [[preimage]] of {{math|1}}, we see that there is a [[bijection]] between {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}} and {{mathcal|P}}({{mvar|S}}), where each function is the [[indicator function|characteristic function]] of the subset in {{mathcal|P}}({{mvar|S}}) with which it is identified.  Hence {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}} and {{mathcal|P}}({{mvar|S}}) could be considered identical set-theoretically.  (Thus there are two distinct [[set notation#Metaphor in denoting sets|notational motivations]] for denoting the power set by {{math|2&lt;sup&gt;''S''&lt;/sup&gt;}}:  the fact that this function-representation of subsets makes it a special case of the {{math|''X''&lt;sup&gt;''Y''&lt;/sup&gt;}} notation and the property, [[power set#Properties|mentioned above]], that {{math|1={{abs|2&lt;sup&gt;''S''&lt;/sup&gt;}} = 2&lt;sup&gt;{{abs|''S''}}&lt;/sup&gt;}}.)

This notion can be applied to the example [[Power set#Example|above]] in which {{math|1=''S'' = {{mset|''x'', ''y'', ''z''}}}} to see the isomorphism with the binary numbers
from 0 to {{math|2&lt;sup&gt;''n''&lt;/sup&gt; − 1}} with {{mvar|n}} being the number of elements in the set.
In {{mvar|''S''}}, a "1" in the position corresponding to the location in the enumerated set {{math|1={{mset| (''x'', 0), (''y'', 1), (''z'', 2) }}}} indicates the presence of the element. So {{math|1={{mset|''x'', ''y''}} = 011&lt;sub&gt;(2)&lt;/sub&gt;}}.

For the whole power set of {{mvar|''S''}} we get:
{|class="wikitable"
|-
!scope="col"| Subset
!scope="col"| Sequence&lt;br /&gt; of digits
!scope="col"| Binary&lt;br /&gt; interpretation
!scope="col"| Decimal&lt;br /&gt; equivalent
|-
| {{math|1={{mset|                     }} }} || {{math|0, 0, 0}} || {{math|000&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|0&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset| ''x''               }} }} || {{math|0, 0, 1}} || {{math|001&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|1&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset|        ''y''        }} }} || {{math|0, 1, 0}} || {{math|010&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|2&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset| ''x'', ''y''        }} }} || {{math|0, 1, 1}} || {{math|011&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|3&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset|               ''z'' }} }} || {{math|1, 0, 0}} || {{math|100&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|4&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset| ''x'',        ''z'' }} }} || {{math|1, 0, 1}} || {{math|101&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|5&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset|        ''y'', ''z'' }} }} || {{math|1, 1, 0}} || {{math|110&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|6&lt;sub&gt;(10)&lt;/sub&gt;}}
|-
| {{math|1={{mset| ''x'', ''y'', ''z'' }} }} || {{math|1, 1, 1}} || {{math|111&lt;sub&gt;(2)&lt;/sub&gt;}} || {{math|7&lt;sub&gt;(10)&lt;/sub&gt;}}
|}

Such bijective mapping of ''S'' to integers is arbitrary, so this representation of subsets of ''S'' is not unique, but the sort order of the enumerated set does not change its cardinality.

However, such finite binary representation is only possible if ''S'' can be enumerated (this is possible even if ''S'' has an infinite cardinality, such as the set of integers or rationals, but not for example if ''S'' is the set of real numbers, in which we cannot enumerate all irrational numbers to assign them a defined finite location in an ordered set containing all irrational numbers).

==Relation to binomial theorem==
The power set is closely related to the [[binomial theorem]].  The number of subsets with {{mvar|k}} elements in the power set of a set with {{mvar|n}} elements is given by the number of [[combination]]s, {{math|C(''n'', ''k'')}}, also called [[binomial coefficient]]s.

For example, the power set of a set with three elements, has:

*C(3, 0) = 1 subset with 0 elements (the empty subset),
*C(3, 1) = 3 subsets with 1 element (the singleton subsets),
*C(3, 2) = 3 subsets with 2 elements (the complements of the singleton subsets),
*C(3, 3) = 1 subset with 3 elements (the original set itself).


Using this relationship we can compute &lt;math display="inline"&gt;\left|2^S \right|&lt;/math&gt; using the formula:

&lt;math display="block"&gt;\left|2^S \right | = \sum_{k=0}^{|S|} \binom{|S|}{k} &lt;/math&gt;

Therefore one can deduce the following identity, assuming &lt;math display="inline"&gt;|S| = n&lt;/math&gt;:

&lt;math display="block"&gt;\left |2^S \right| = 2^n = \sum_{k=0}^{n} \binom{n}{k} &lt;/math&gt;

==Algorithms==
If {{mvar|S}} is a [[finite set]], there is a [[recursive algorithm]] to calculate {{mathcal|P}}({{mvar|S}}).

Define the operation {{math|1={{mathcal|F}} (''e'', ''T'') = {''X'' ∪ {''e''} {{!}} ''X'' ∈ ''T''}}}.

In English, return the set with the element {{mvar|e}} added to each set {{mvar|X}} in {{mvar|T}}.

*If {{math|1=''S'' = { } }}, then {{math|1={{mathcal|P}}({{mvar|S}}) = { { } } }} is returned.
*Otherwise:
:*Let {{mvar|e}} be any single element of {{mvar|S}}.
:*Let {{math|1=''T'' = ''S'' \ {''e''} }}, where {{math|''S'' \ {''e''} }} denotes the [[Complement (set theory)|relative complement]] of {{mvar|e}} in {{mvar|S}}.
:*And the result: {{math|1={{mathcal|P}}(''S'') = {{mathcal|P}}(''T'') ∪ {{mathcal|F}} (''e'', {{mathcal|P}}(''T''))}} is returned.

In other words, the power set of the empty set is the set containing the empty set and the power set of any other set is all the subsets of the set containing some specific element and all the subsets of the set not containing that specific element.

==Subsets of limited cardinality==
The set of subsets of {{mvar|''S''}} of [[cardinality]] less than or equal to {{math|κ}} is sometimes denoted by {{math|{{mathcal|P}}&lt;sub&gt;κ&lt;/sub&gt;(''S'')}} or {{math|[''S'']&lt;sup&gt;κ&lt;/sup&gt;}}, and the set of subsets with cardinality strictly less than {{math|κ}} is sometimes denoted {{math|{{mathcal|P}}&lt;sub&gt;&lt; κ&lt;/sub&gt;(''S'')}} or {{math|[''S'']&lt;sup&gt;&lt;κ&lt;/sup&gt;}}. Similarly, the set of non-empty subsets of {{mvar|''S''}} might be denoted by {{math|{{mathcal|P}}&lt;sub&gt;≥ 1&lt;/sub&gt;(''S'')}} or {{math|{{mathcal|P}}&lt;sup&gt;+&lt;/sup&gt;(''S'')}}.

==Power object==
A set can be regarded as an algebra having no nontrivial operations or defining equations.  From this perspective the idea of the power set of {{mvar|''X''}} as the set of subsets of {{mvar|''X''}} generalizes naturally to the subalgebras of an [[algebraic structure]] or algebra.

Now the power set of a set, when ordered by inclusion, is always a complete atomic Boolean algebra, and every complete atomic Boolean algebra arises as the [[lattice (order)|lattice]] of all subsets of some set.  The generalization to arbitrary algebras is that the set of subalgebras of an algebra, again ordered by inclusion, is always an [[algebraic lattice]], and every algebraic lattice arises as the lattice of subalgebras of some algebra.  So in that regard subalgebras behave analogously to subsets.

However, there are two important properties of subsets that do not carry over to subalgebras in general.  First, although the subsets of a set form a set (as well as a lattice), in some classes it may not be possible to organize the subalgebras of an algebra as itself an algebra in that class, although they can always be organized as a lattice.  Secondly, whereas the subsets of a set are in bijection with the functions from that set to the set {0,1} = 2, there is no guarantee that a class of algebras contains an algebra that can play the role of 2 in this way.

Certain classes of algebras enjoy both of these properties.  The first property is more common, the case of having both is relatively rare.  One class that does have both is that of [[multigraph]]s.  Given two multigraphs {{mvar|''G''}} and {{mvar|''H''}}, a [[homomorphism]] {{math|''h'': ''G'' → ''H''}} consists of two functions, one mapping vertices to vertices and the other mapping edges to edges.  The set {{math|''H''&lt;sup&gt;''G''&lt;/sup&gt;}} of homomorphisms from {{mvar|''G''}} to {{mvar|''H''}} can then be organized as the graph whose vertices and edges are respectively the vertex and edge functions appearing in that set.  Furthermore, the subgraphs of a multigraph {{mvar|''G''}} are in bijection with the graph homomorphisms from {{mvar|''G''}} to the multigraph {{math|Ω}} definable as the [[complete graph|complete directed graph]] on two vertices (hence four edges, namely two self-loops and two more edges forming a cycle) augmented with a fifth edge, namely a second self-loop at one of the vertices.  We can therefore organize the subgraphs of {{mvar|''G''}} as the multigraph {{math|Ω&lt;sup&gt;''G''&lt;/sup&gt;}}, called the '''power object''' of {{mvar|''G''}}.

What is special about a multigraph as an algebra is that its operations are unary.  A multigraph has two sorts of elements forming a set {{mvar|''V''}} of vertices and {{mvar|''E''}} of edges, and has two unary operations {{math|''s'',''t'': ''E'' → ''V''}} giving the source (start) and target (end) vertices of each edge.  An algebra all of whose operations are unary is called a [[presheaf]].  Every class of presheaves contains a presheaf {{math|Ω}} that plays the role for subalgebras that 2 plays for subsets.  Such a class is a special case of the more general notion of elementary [[topos]] as a [[category (mathematics)|category]] that is [[closed category|closed]] (and moreover [[cartesian closed category|cartesian closed]]) and has an object {{math|Ω}}, called a [[subobject classifier]].  Although the term "power object" is sometimes used synonymously with [[exponential object]] {{math|''Y''&lt;sup&gt;''X''&lt;/sup&gt;}}, in topos theory {{mvar|''Y''}} is required to be {{math|Ω}}.

==Functors and quantifiers==
In [[category theory]] and the theory of [[elementary topos|elementary topoi]], the [[universal quantifier]] can be understood as the [[right adjoint]] of a [[functor]] between power sets, the [[inverse image]] functor of a function between sets; likewise, the [[existential quantifier]] is the [[left adjoint]].&lt;ref&gt;[[Saunders Mac Lane]], [[Ieke Moerdijk]], (1992) ''Sheaves in Geometry and Logic'' Springer-Verlag. {{isbn|0-387-97710-4}} ''See page 58''&lt;/ref&gt;

==See also==
* [[Set theory]]
* [[Axiomatic set theory]]
* [[Family of sets]]
* [[Field of sets]]

==Notes==
&lt;references/&gt;

==References==
* {{cite book | last=Devlin | first=Keith J. | authorlink=Keith Devlin | title=Fundamentals of contemporary set theory | series=Universitext | publisher=[[Springer-Verlag]] | year=1979 | isbn=0-387-90441-7 | zbl=0407.04003 }}
* {{cite book | last=Halmos | first=Paul R. | authorlink=Paul Halmos | title=Naive set theory | series=The University Series in Undergraduate Mathematics | publisher=van Nostrand Company | year=1960 | zbl=0087.04403 }}
* {{cite book |last=Puntambekar | first=A. A. | title=Theory Of Automata And Formal Languages | year=2007 | publisher=Technical Publications | isbn=978-81-8431-193-8 }}

==External links==
{{Wiktionary|power set}}
*{{mathworld|urlname=PowerSet|title=Power Set}}
*{{planetmath reference|id=136|title=Power set}}
* {{nlab|id=power+set|title=Power set}}
* {{nlab|id=power+object|title=Power object}}
* [http://www.programminglogic.com/powerset-algorithm-in-c/ Power set Algorithm] in [[C++]]

{{Mathematical logic}}
{{Set theory}}

[[Category:Abstract algebra]]
[[Category:Algebra]]
[[Category:Basic concepts in set theory]]</text>
      <sha1>e9oq15oro3bouvhupmtu5rn8k5z0w5y</sha1>
    </revision>
  </page>
  <page>
    <title>Primal ideal</title>
    <ns>0</ns>
    <id>25360385</id>
    <revision>
      <id>504983790</id>
      <parentid>504983654</parentid>
      <timestamp>2012-07-30T19:55:35Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>{{algebra-stub}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="665">In [[mathematics]], an element ''a'' of a [[commutative ring]] ''A'' is called '''(relatively) prime''' to an ideal ''Q'' if whenever ''ab'' is an element of ''Q'' then ''b'' is also an element of ''Q''.

A proper [[Ideal (ring theory)|ideal]] ''Q'' of a [[commutative ring]] ''A'' is said to be '''primal''' if the elements that are not prime to it form an ideal. 

==References==
*{{citation
 | last = Fuchs | first = Ladislas
 | doi = 10.2307/2032421
 | journal = [[Proceedings of the American Mathematical Society]]
 | mr = 0032584
 | pages = 1–6
 | title = On primal ideals
 | volume = 1
 | year = 1950}}.

[[Category:Commutative algebra]]


{{algebra-stub}}</text>
      <sha1>5e3edhnrw3jkodhtvp9m3u075iwzj5z</sha1>
    </revision>
  </page>
  <page>
    <title>Quadratic set</title>
    <ns>0</ns>
    <id>38264067</id>
    <revision>
      <id>792717507</id>
      <parentid>792717211</parentid>
      <timestamp>2017-07-28T05:56:42Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* Definition of a quadratic set */ which → that</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5732">In mathematics, a '''quadratic set''' is a set of points in a [[projective space]] that bears the same essential incidence properties as a quadric ([[conic section]] in a projective plane, [[sphere]] or [[cone]] or [[hyperboloid]] in a projective space).

== Definition of a quadratic set==
Let &lt;math&gt;\mathfrak P=({\mathcal P},{\mathcal G},\in)&lt;/math&gt; be a projective space. A '''quadratic set''' is a non-empty subset &lt;math&gt;{\mathcal Q}&lt;/math&gt; of &lt;math&gt;{\mathcal P}&lt;/math&gt; for which the following two conditions hold: 
:'''(QS1)''' Every line &lt;math&gt;g&lt;/math&gt; of &lt;math&gt;{\mathcal G}&lt;/math&gt; intersects &lt;math&gt;{\mathcal Q}&lt;/math&gt; in at most two points or is contained in &lt;math&gt;{\mathcal Q}&lt;/math&gt;.
::(&lt;math&gt;g&lt;/math&gt; is called '''exterior''' to &lt;math&gt;{\mathcal Q}&lt;/math&gt; if &lt;math&gt;|g\cap {\mathcal Q}|=0&lt;/math&gt;, '''tangent''' to &lt;math&gt;{\mathcal Q}&lt;/math&gt; if either &lt;math&gt;|g\cap {\mathcal Q}|=1&lt;/math&gt; or &lt;math&gt;g\cap {\mathcal Q}=g&lt;/math&gt;, and '''secant''' to &lt;math&gt;{\mathcal Q}&lt;/math&gt; if &lt;math&gt;|g\cap {\mathcal Q}|=2&lt;/math&gt;.) 
:'''(QS2)''' For any point &lt;math&gt;P\in {\mathcal Q}&lt;/math&gt; the union &lt;math&gt;{\mathcal Q}_P&lt;/math&gt; of all tangent lines through &lt;math&gt;P&lt;/math&gt; is a [[hyperplane]] or the entire space &lt;math&gt;{\mathcal P}&lt;/math&gt;.

A quadratic set &lt;math&gt;{\mathcal Q}&lt;/math&gt; is called '''non-degenerate''' if for every point &lt;math&gt;P\in {\mathcal Q}&lt;/math&gt;, the set &lt;math&gt;{\mathcal Q}_P&lt;/math&gt; is a hyperplane.

A '''Pappian projective space''' is a projective space in which [[Pappus's hexagon theorem]] holds.

The following result, due to [[Francis Buekenhout]], is an astonishing statement for finite projective spaces.

: '''Theorem:''' Let be &lt;math&gt;\mathfrak P_n&lt;/math&gt; a ''finite'' projective space of dimension &lt;math&gt;n\ge 3&lt;/math&gt; and &lt;math&gt;{\mathcal Q}&lt;/math&gt; a non-degenerate quadratic set that contains lines. Then: &lt;math&gt;\mathfrak P_n&lt;/math&gt; is Pappian and &lt;math&gt;{\mathcal Q}&lt;/math&gt; is a ''[[quadric]]'' with index &lt;math&gt;\ge 2&lt;/math&gt;.

==Definition of an oval and an ovoid==
Ovals and ovoids are special quadratic sets:&lt;br /&gt;
Let &lt;math&gt;\mathfrak P&lt;/math&gt; be a projective space of dimension &lt;math&gt;\ge 2&lt;/math&gt;. A non-degenerate quadratic set &lt;math&gt;\mathcal O&lt;/math&gt; that does not contain lines is called '''ovoid''' (or '''oval''' in plane case).

The following equivalent definition of an oval/ovoid are more common:

'''Definition: (oval)'''
A non-empty point set &lt;math&gt;\mathfrak o&lt;/math&gt; of a projective plane is called 
'''oval''' if the following properties are fulfilled:
:'''(o1)''' Any line meets &lt;math&gt;\mathfrak o&lt;/math&gt; in at most two points.
:('''o2)''' For any point &lt;math&gt;P&lt;/math&gt; in &lt;math&gt;\mathfrak o&lt;/math&gt; there is one and only one line &lt;math&gt;g&lt;/math&gt; such that  &lt;math&gt;g\cap \mathfrak o=\{P\}&lt;/math&gt;.
A line &lt;math&gt;g&lt;/math&gt;  is a ''exterior'' or ''tangent'' or ''secant'' line of the 
oval if &lt;math&gt;|g\cap \mathfrak o|=0&lt;/math&gt; or &lt;math&gt;|g\cap \mathfrak o|=1&lt;/math&gt; or &lt;math&gt;|g\cap \mathfrak o|=2&lt;/math&gt; respectively.

For ''finite'' planes the following theorem provides a more simple definition.

'''Theorem: (oval in finite plane) '''Let be &lt;math&gt; \mathfrak P&lt;/math&gt; a projective plane of order &lt;math&gt;n&lt;/math&gt;.
A set &lt;math&gt;\mathfrak o&lt;/math&gt; of points is an '''oval''' if &lt;math&gt;|\mathfrak o|=n+1&lt;/math&gt; and if no three points
of &lt;math&gt;\mathfrak o&lt;/math&gt; are collinear.

According to this theorem of [[Beniamino Segre]], for ''Pappian'' projective planes of ''odd'' order the ovals are just conics:
 
'''Theorem:'''
Let be &lt;math&gt; \mathfrak P&lt;/math&gt; a ''Pappian'' projective plane of ''odd'' order.
Any oval in &lt;math&gt; \mathfrak P&lt;/math&gt;  is an oval ''conic'' (non-degenerate [[quadric]]).

'''Definition: (ovoid)'''
A non-empty point set &lt;math&gt;\mathcal O&lt;/math&gt; of a projective space is called '''ovoid''' if the following properties are fulfilled:
:'''(O1)''' Any line meets &lt;math&gt;\mathcal O&lt;/math&gt; in at most two points.
:(&lt;math&gt;g&lt;/math&gt; is called '''exterior, tangent''' and  '''secant''' line if &lt;math&gt;|g\cap {\mathcal O}|=0, \ |g\cap {\mathcal O}|=1&lt;/math&gt; and &lt;math&gt;|g\cap {\mathcal O}|=2&lt;/math&gt; respectively.) 
:'''(O2)''' For any point &lt;math&gt;P\in {\mathcal O}&lt;/math&gt; the union &lt;math&gt;{\mathcal O}_P&lt;/math&gt; of all tangent lines through &lt;math&gt;P&lt;/math&gt; is a [[hyperplane]] (tangent plane at &lt;math&gt;P&lt;/math&gt;).

'''Example:'''
:a) Any sphere (quadric of index 1) is an ovoid.
:b) In case of real projective spaces one can construct ovoids by combining halves of suitable ellipsoids such that they are no quadrics.

For ''finite'' projective spaces of dimension &lt;math&gt;n&lt;/math&gt; over a [[Field (algebra)|field]] &lt;math&gt;K&lt;/math&gt; we have:&lt;br /&gt;
'''Theorem:'''
:a) In case of &lt;math&gt;|K| &lt;\infty&lt;/math&gt; an ovoid in &lt;math&gt;\mathfrak P_n(K)&lt;/math&gt; exists only if &lt;math&gt;n=2&lt;/math&gt; or &lt;math&gt;n=3&lt;/math&gt;.
:b) In case of &lt;math&gt;|K| &lt;\infty,\  \operatorname{char} K \ne 2&lt;/math&gt; an ovoid in &lt;math&gt;\mathfrak P_n(K)&lt;/math&gt; is a quadric.

Counterexamples (Tits–Suzuki ovoid) show that i.g. statement b) of the theorem above is not true for &lt;math&gt;\operatorname{char} K=2&lt;/math&gt;:

==References==
{{Reflist}}

* [[Albrecht Beutelspacher]] &amp; Ute Rosenbaum (1998) ''Projective Geometry : from foundations to applications'', Chapter 4: Quadratic Sets, pages 137 to 179, [[Cambridge University Press]] {{ISBN|978-0521482776}}
* [[Francis Buekenhout|F. Buekenhout]] (ed.) (1995) ''Handbook of [[Incidence (geometry)|Incidence Geometry]]'', [[Elsevier]] {{ISBN|0-444-88355-X}}
* P. Dembowski (1968) ''Finite Geometries'', Springer-Verlag {{ISBN|3-540-61786-8}}, p. 48

==External links==
* Eric Hartmann [http://www.mathematik.tu-darmstadt.de/~ehartmann/circlegeom.pdf Lecture Note ''Planar Circle Geometries, an Introduction to Moebius-, Laguerre- and Minkowski Planes''], from [[Technische Universität Darmstadt]]

[[Category:Geometry]]</text>
      <sha1>nq9jtinu9zzkcwvde5uyaiojs08qlfw</sha1>
    </revision>
  </page>
  <page>
    <title>Radix</title>
    <ns>0</ns>
    <id>701207</id>
    <revision>
      <id>871611743</id>
      <parentid>867429806</parentid>
      <timestamp>2018-12-02T07:56:01Z</timestamp>
      <contributor>
        <username>Aeiffert</username>
        <id>35283411</id>
      </contributor>
      <minor/>
      <comment>Added a sentence explaining the significance of each place value in different radix systems.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6041">{{other uses}}
{{Table Numeral Systems}}

In [[numeral system|mathematical numeral systems]], the '''radix''' or '''base''' is the number of unique [[numerical digit|digits]], including the digit zero, used to represent numbers in a [[positional notation|positional]] [[numeral system]]. For example, for the [[decimal]] system (the most common system in use today) the radix is ten, because it uses the ten digits from 0 through 9.

In any standard positional numeral system, a number is conventionally written as {{nowrap|(''x'')&lt;sub&gt;''y''&lt;/sub&gt;}} with ''x'' as the [[String (computer science)|string]] of digits and ''y'' as its base, although for base ten the subscript is usually assumed (and omitted, together with the pair of [[parentheses]]), as it is the most common way to express [[value (mathematics)|value]]. For example, &lt;span class="nowrap"&gt;(100)&lt;sub&gt;dec&lt;/sub&gt; = 100&lt;/span&gt; (in the decimal system) represents the number one hundred, while (100)&lt;sub&gt;2&lt;/sub&gt; (in the [[binary system (numeral)|binary system]] with base 2) represents the number four.&lt;ref name="morris_mano_p13_14"/&gt;

== Etymology ==
[[:wikt:radix|''Radix'']] is a Latin word for "root". ''Root'' can be considered a synonym for ''base'' in the arithmetical sense.

== In numeral systems ==
In the system with radix 13, for example, a string of digits such as 398 denotes the (decimal) number {{nowrap|3 × 13&lt;sup&gt;2&lt;/sup&gt; + 9 × 13&lt;sup&gt;1&lt;/sup&gt; + 8 × 13&lt;sup&gt;0&lt;/sup&gt;}} = 632. 

More generally, in a system with radix ''b'' ({{nowrap|''b'' &gt; 1}}), a string of digits {{nowrap|''d''&lt;sub&gt;1&lt;/sub&gt; … ''d&lt;sub&gt;n&lt;/sub&gt;''}} denotes the number {{nowrap|''d''&lt;sub&gt;1&lt;/sub&gt;''b''&lt;sup&gt;''n''−1&lt;/sup&gt; + ''d''&lt;sub&gt;2&lt;/sub&gt;''b''&lt;sup&gt;''n''−2&lt;/sup&gt; + … + ''d&lt;sub&gt;n&lt;/sub&gt;b''&lt;sup&gt;0&lt;/sup&gt;}}, where {{nowrap|0 ≤ ''d&lt;sub&gt;i&lt;/sub&gt;'' &lt; ''b''}}.&lt;ref name="morris_mano_p13_14"&gt;
{{cite book
 | first1=M. Morris | last1=Mano
 | first2=Charles | last2=Kime
 | title=Logic and Computer Design Fundamentals
 | date=2014
 | publisher=Pearson
 | location=Harlow
 | isbn=978-1-292-02468-4
 | pages=13–14 | edition=4th
}}&lt;/ref&gt; In contrast to decimal, or radix 10, which has a ones' place, tens' place, hundreds' place, and so on, radix ''b'' would have a ones' place, then a ''b''&lt;sup&gt;1&lt;/sup&gt;s' place, a ''b&lt;sup&gt;2&lt;/sup&gt;''s' place, etc.&lt;ref&gt;{{Cite web|url=https://experimonkey.com/readables/?aid=binary-how-do-computers-talk|title=Binary: How Do Computers Talk? {{!}} Experimonkey|website=experimonkey.com|access-date=2018-12-02}}&lt;/ref&gt;

Commonly used numeral systems include:
{| class="wikitable sortable"
! Base/radix
! Name
! Description
|-
| 2
| [[Binary numeral system]]
| Used internally by nearly all [[computer]]s, is [[base 2]]. The two digits are "0" and "1", expressed from switches displaying OFF and ON respectively. Used in most electric [[counter (digital)|counter]]s.
|-
| 8
| [[Octal|Octal system]]
| Used occasionally in computing. The eight digits are "0–7" and represent 3 bits (2&lt;sup&gt;3&lt;/sup&gt;).
|-
| 10 
| [[Decimal|Decimal system]]
| The most used system of numbers in the world, is used in arithmetic. Its ten digits are "0–9". Used in most [[mechanical counter]]s.
|-
| 12
| [[Duodecimal|Duodecimal (dozenal) system]]
| Sometimes advocated due to divisibility by 2, 3, 4, and 6. It was traditionally used as part of quantities expressed in [[dozen]]s and [[gross (unit)|grosses]].
|-
| 16
| [[Hexadecimal|Hexadecimal system]]
| Often used in computing as a more compact representation of binary (1 hex digit per 4 bits). The sixteen digits are "0–9" followed by "A–F" or "a–f".
|-
| 20
| [[Vigesimal]]
| Traditional numeral system in several cultures, still used by some for counting.
|-
| 60
| [[Sexagesimal|Sexagesimal system]]
| Originated in ancient [[Sumer]] and passed to the [[Babylonia]]ns.&lt;ref&gt;
 {{cite book
  | last1=Bertman | first1=Stephen
  | title=Handbook to Life in Ancient Mesopotamia
  | date=2005|publisher=Oxford Univ. Press
  | location=Oxford [u.a.]
  | isbn=978-019-518364-1
  | page=257
  | edition=Paperback
  | url=https://books.google.com/books?id=1C4NKp4zgIQC&amp;pg=PA257#v=onepage&amp;q&amp;f=false
 }}&lt;/ref&gt; Used today as the basis of modern [[minute of arc#Symbols and abbreviations|circular coordinate system]] (degrees, minutes, and seconds) and [[time]] measuring (minutes, and seconds) by analogy to the rotation of the Earth.
|}

{{for|a larger list|list of numeral systems}}

The octal and hexadecimal systems are often used in computing because of their ease as shorthand for binary. Every hexadecimal digit corresponds to a sequence of four binary digits, since sixteen is the fourth power of two; for example, hexadecimal 78&lt;sub&gt;16&lt;/sub&gt; is binary {{gaps|111|1000}}&lt;sub&gt;2&lt;/sub&gt;. Similarly, every octal digit corresponds to a unique sequence of three binary digits, since eight is the cube of two.

Radices are usually [[natural number]]s. However, other positional systems are possible; e.g., [[golden ratio base]] (whose radix is a non-integer [[algebraic number]]),&lt;ref&gt;
{{cite journal
 | doi=10.2307/3029218
 | last=Bergman | first=George
 | title=A Number System with an Irrational Base
 | journal=Mathematics Magazine
 | volume=31 | issue=2 | pages=98–110 | year=1957
 | jstor=3029218
 | url=https://www.jstor.org/discover/10.2307/3029218?sid=21105280456741&amp;uid=4&amp;uid=2129&amp;uid=2&amp;uid=70
}}&lt;/ref&gt; and [[negative base]] (whose radix is negative).&lt;ref&gt;
{{cite journal
 | author1=William J. Gilbert
 | title=Negative Based Number Systems
 | journal=Mathematics Magazine
 | date=September 1979 | volume=52 | issue=4 | pages=240–244
 | url=https://www.math.uwaterloo.ca/~wgilbert/Research/GilbertNegBases.pdf|accessdate=7 February 2015
}}&lt;/ref&gt;

==See also==
*[[Base (exponentiation)]]
*[[Radix economy]]
*[[Non-standard positional numeral systems]]

==References==
{{reflist|30em}}

==External links==
{{wiktionary|radix}}
*[https://baseconvert.com Base Convert, a floating-point base calculator]
*[http://mathworld.wolfram.com/Base.html MathWorld entry on base]

[[Category:Elementary mathematics]]
[[Category:Numeral systems]]</text>
      <sha1>qk2tr6el5feicc84egqkok3xcuquibv</sha1>
    </revision>
  </page>
  <page>
    <title>Random minimum spanning tree</title>
    <ns>0</ns>
    <id>1270875</id>
    <revision>
      <id>851371336</id>
      <parentid>746308409</parentid>
      <timestamp>2018-07-21T20:47:09Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>/* top */Improving links and other minor cleanup tasks using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2432">In mathematics, a '''random minimum spanning tree''' may be formed by assigning random weights from some distribution to the edges of an [[undirected graph]], and then constructing the [[minimum spanning tree]] of the graph.

When the given graph is a [[complete graph]] on {{mvar|n}} vertices, and the edge weights have a continuous [[Cumulative distribution function|distribution function]] whose derivative at zero is {{math|''D'' &gt; 0}}, then the expected weight of its random minimum spanning trees is bounded by a constant, rather than growing as a function of {{mvar|n}}. More precisely, this constant tends in the limit (as {{mvar|n}} goes to infinity) to {{math|''&amp;zeta;''(3)/''D''}}, where {{mvar|&amp;zeta;}} is the [[Riemann zeta function]] and {{math|''&amp;zeta;''(3)}} is [[Apéry's constant]]. For instance, for edge weights that are uniformly distributed on the [[unit interval]], the derivative is {{math|1=''D'' = 1}}, and the limit is just {{math|''&amp;zeta;''(3)}}.&lt;ref&gt;{{citation
 | last = Frieze | first = A. M. | authorlink = Alan M. Frieze
 | doi = 10.1016/0166-218X(85)90058-7
 | issue = 1
 | journal = [[Discrete Applied Mathematics]]
 | mr = 770868
 | pages = 47–56
 | title = On the value of a random minimum spanning tree problem
 | volume = 10
 | year = 1985}}.&lt;/ref&gt;

Random minimum spanning trees of [[grid graph]]s may be used for [[invasion percolation]] models of liquid flow through a porous medium,&lt;ref&gt;{{citation
 | last1 = Duxbury | first1 = P. M.
 | last2 = Dobrin | first2 = R.
 | last3 = McGarrity | first3 = E.
 | last4 = Meinke | first4 = J. H.
 | last5 = Donev | first5 = A.
 | last6 = Musolff | first6 = C.
 | last7 = Holm | first7 = E. A.
 | contribution = Network algorithms and critical manifolds in disordered systems
 | doi = 10.1007/978-3-642-59293-5_25
 | pages = 181–194
 | publisher = Springer-Verlag
 | series = Springer Proceedings in Physics
 | title = Computer Simulation Studies in Condensed-Matter Physics XVI: Proceedings of the Fifteenth Workshop, Athens, GA, USA, February 24–28, 2003
 | volume = 95
 | year = 2004}}.&lt;/ref&gt; and for [[maze generation]].&lt;ref&gt;{{citation|url=http://www.martinfoltin.sk/mazes/thesis.pdf|title=Automated Maze Generation and Human Interaction|first=Martin|last=Foltin|series=Diploma Thesis|publisher=Masaryk University, Faculty of Informatics|location=Brno|year=2011}}.&lt;/ref&gt;

==References==
{{reflist}}
{{Combin-stub}}
[[Category:Spanning tree]]</text>
      <sha1>08pmiyjwunlsgrs8mfx363ueqtloevp</sha1>
    </revision>
  </page>
  <page>
    <title>Simplicial localization</title>
    <ns>0</ns>
    <id>40966773</id>
    <revision>
      <id>584974132</id>
      <parentid>584249916</parentid>
      <timestamp>2013-12-07T10:13:35Z</timestamp>
      <contributor>
        <username>Malcolma</username>
        <id>320496</id>
      </contributor>
      <comment>added [[Category:Category theory]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="844">In category theory, a branch of mathematics, the '''simplicial localization''' of a [[category (mathematics)|category]] ''C'' with respect to a class ''W'' of morphisms of ''C'' is a [[Simplicially enriched category|simplicial category]] ''LC'' whose &lt;math&gt;\pi_0&lt;/math&gt; is the [[localization of a category|localization]] &lt;math&gt;C[W^{-1}]&lt;/math&gt; of ''C'' with respect to ''W''; that is, &lt;math&gt;\pi_0 LC(x, y) = C[W^{-1}](x, y)&lt;/math&gt; for any objects ''x'', ''y'' in ''C''. The notion is due to Dwyer and [[Dan Kan|Kan]].

== References ==
*W. G. Dwyer and Dan Kan, [http://www3.nd.edu/~wgd/Dvi/SimplicialLocalizations.pdf Simplicial localizations of categories]
*http://math.mit.edu/~mdono/_Juvitop.pdf

== External links ==
*{{nlab|id=simplicial+localization|title=simplicial localization}}

[[Category:Category theory]]


{{categorytheory-stub}}</text>
      <sha1>kpj996vdrv3mc7n1vjwcel21n2g4wcl</sha1>
    </revision>
  </page>
  <page>
    <title>Spanning tree</title>
    <ns>0</ns>
    <id>455770</id>
    <revision>
      <id>861787520</id>
      <parentid>821997723</parentid>
      <timestamp>2018-09-30T01:03:08Z</timestamp>
      <contributor>
        <ip>165.82.214.48</ip>
      </contributor>
      <comment>/* Applications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24931">{{about||the network protocol|Spanning Tree Protocol|other uses|}}

[[File:4x4 grid spanning tree.svg|thumb|A spanning tree (blue heavy edges) of a [[grid graph]]]]
In the [[mathematics|mathematical]] field of [[graph theory]], a '''spanning tree''' ''T'' of an [[undirected graph]] ''G'' is a subgraph that is a [[tree (graph theory)|tree]] which includes all of the [[Vertex (graph theory)|vertices]] of ''G'', with minimum possible number of edges. In general, a graph may have several spanning trees, but a graph that is not [[connected graph|connected]] will not contain a spanning tree (but see [[#Spanning forests|Spanning forests]] below). If all of the [[edge (graph theory)|edges]] of ''G'' are also edges of a spanning tree ''T'' of ''G'', then ''G'' is a tree and is identical to ''T'' (that is, a tree has a unique spanning tree and it is itself).

==Applications==

Several [[pathfinding]] algorithms, including [[Dijkstra's algorithm]] and the [[A* search algorithm]], internally build a spanning tree as an intermediate step in solving the problem.

In order to minimize the cost of power networks, wiring connections, piping, automatic speech recognition, etc., people often use algorithms that gradually build a spanning tree (or many such trees) as intermediate steps in the process of finding the [[minimum spanning tree]].&lt;ref&gt;
R. L. Graham and Pavol Hell.
[http://www.math.ucsd.edu/~ronspubs/85_07_minimum_spanning_tree.pdf "On the History of the Minimum Spanning Tree Problem"].
1985.
&lt;/ref&gt;

The Internet and many other [[telecommunications network]]s have transmission links that connect nodes together in a [[mesh topology]] that includes some loops.
In order to "avoid [[bridge loop]]s and "[[routing loop]]s", many routing protocols designed for such networks—including the [[Spanning Tree Protocol]], [[Open Shortest Path First]], [[Link-state routing protocol]], [[Augmented tree-based routing]], etc.—require each router to remember a spanning tree.

A special kind of spanning tree, the [[Xuong tree]], is used in [[topological graph theory]] to find [[graph embedding]]s with maximum [[genus (mathematics)|genus]]. A Xuong tree is a spanning tree such that, in the remaining graph, the number of connected components with an odd number of edges is as small as possible. A Xuong tree and an associated maximum-genus embedding can be found in [[polynomial time]].&lt;ref&gt;{{citation
 | last1 = Beineke | first1 = Lowell W. | author1-link = L. W. Beineke
 | last2 = Wilson | first2 = Robin J. | author2-link = Robin Wilson (mathematician)
 | doi = 10.1017/CBO9781139087223
 | isbn = 978-0-521-80230-7
 | mr = 2581536
 | page = 36
 | publisher = Cambridge University Press, Cambridge
 | series = Encyclopedia of Mathematics and its Applications
 | title = Topics in topological graph theory
 | volume = 128
 | year = 2009}}&lt;/ref&gt;

==Definitions==
A tree is a [[connected graph|connected]] [[undirected graph]] with no [[cycle (graph theory)|cycles]]. It is a spanning tree of a graph ''G'' if it spans ''G'' (that is, it includes every vertex of ''G'') and is a subgraph of ''G'' (every edge in the tree belongs to ''G''). A spanning tree of a connected graph ''G'' can also be defined as a maximal set of edges of ''G'' that contains no cycle, or as a minimal set of edges that connect all vertices.

===Fundamental cycles===
Adding just one edge to a spanning tree will create a cycle; such a cycle is called a '''fundamental cycle'''. There is a distinct fundamental cycle for each edge not in the spanning tree; thus, there is a one-to-one correspondence between fundamental cycles and  edges not in the spanning tree.  For a connected graph with ''V'' vertices, any spanning tree will have ''V''&amp;nbsp;−&amp;nbsp;1 edges, and thus, a graph of ''E'' edges and one of its spanning trees will have ''E''&amp;nbsp;−&amp;nbsp;''V''&amp;nbsp;+&amp;nbsp;1 fundamental cycles. For any given spanning tree the set of all ''E''&amp;nbsp;−&amp;nbsp;''V''&amp;nbsp;+&amp;nbsp;1 fundamental cycles forms a [[cycle basis]], a basis for the [[cycle space]].&lt;ref&gt;{{harvtxt|Kocay|Kreher|2004}}, pp.&amp;nbsp;65–67.&lt;/ref&gt;

===Fundamental cutsets===
Dual to the notion of a fundamental cycle is the notion of a '''fundamental cutset'''. By deleting just one edge of the spanning tree, the vertices are partitioned into two disjoint sets. The fundamental cutset is defined as the set of edges that must be removed from the graph ''G'' to accomplish the same partition. Thus, each spanning tree defines a set of ''V''&amp;nbsp;−&amp;nbsp;1 fundamental cutsets, one for each edge of the spanning tree.&lt;ref&gt;{{harvtxt|Kocay|Kreher|2004}}, pp.&amp;nbsp;67–69.&lt;/ref&gt;

The duality between fundamental cutsets and fundamental cycles is established by noting that cycle edges not in the spanning tree can only appear in the cutsets of the other edges in the cycle; and ''vice versa'': edges in a cutset can only appear in those cycles containing the edge corresponding to the cutset. This duality can also be expressed using the theory of [[matroid]]s, according to which a spanning tree is a base of the [[graphic matroid]], a fundamental cycle is the unique circuit within the set formed by adding one element to the base, and fundamental cutsets are defined in the same way from the [[dual matroid]].&lt;ref&gt;{{citation |title=Matroid Theory |volume=3 |series=Oxford [[Graduate Texts in Mathematics]] |first=J. G. |last=Oxley |authorlink=James Oxley |publisher=Oxford University Press |year=2006 |isbn=978-0-19-920250-8 |page=141 |url=https://books.google.com/books?id=puKta1Hdz-8C&amp;pg=PA141}}.&lt;/ref&gt;

===Spanning forests===
In graphs that are not connected, there can be no spanning tree, and one must consider '''spanning forests''' instead. Here there are two competing definitions:
*Some authors consider a spanning forest to be a maximal acyclic subgraph of the given graph, or equivalently a graph consisting of a spanning tree in each [[Connected component (graph theory)|connected component]] of the graph.&lt;ref&gt;{{citation |title=Modern Graph Theory |volume=184 |series=Graduate Texts in Mathematics |first=Béla |last=Bollobás |authorlink=Béla Bollobás |publisher=Springer |year=1998 |isbn=978-0-387-98488-9 |page=350 |url=https://books.google.com/books?id=SbZKSZ-1qrwC&amp;pg=PA350}}; {{citation |title=LEDA: A Platform for Combinatorial and Geometric Computing |first=Kurt |last=Mehlhorn |authorlink=Kurt Mehlhorn |publisher=Cambridge University Press |year=1999 |isbn=978-0-521-56329-1 |page=260 |url=https://books.google.com/books?id=Q2aXZl3fgvMC&amp;pg=PA260}}.&lt;/ref&gt;
*For other authors, a spanning forest is a forest that spans all of the vertices, meaning only that each vertex of the graph is a vertex in the forest. For this definition, even a connected graph may have a disconnected spanning forest, such as the forest in which each vertex forms a single-vertex tree.&lt;ref&gt;{{citation |title=Combinatorics: Topics, Techniques, Algorithms |first=Peter J. |last=Cameron |authorlink=Peter Cameron (mathematician) |publisher=Cambridge University Press |year=1994 |isbn=978-0-521-45761-3 |page=163 |url=https://books.google.com/books?id=_aJIKWcifDwC&amp;pg=PA163}}.&lt;/ref&gt;
To avoid confusion between these two definitions, {{harvtxt|Gross|Yellen|2005}} suggest the term "full spanning forest" for a spanning forest with the same connectivity as the given graph, while {{harvtxt|Bondy|Murty|2008}} instead call this kind of forest a "maximal spanning forest".&lt;ref&gt;{{citation |title=Graph Theory and Its Applications |edition=2nd |first1=Jonathan L. |last1=Gross |first2=Jay |last2=Yellen |publisher=CRC Press |year=2005 |isbn=978-1-58488-505-4 |page=168 |url=https://books.google.com/books?id=-7Q_POGh-2cC&amp;pg=PA168}}; {{citation |title=Graph Theory |volume=244 |series=Graduate Texts in Mathematics |first1=J. A. |last1=Bondy |first2=U. S. R. |last2=Murty |publisher=Springer |year=2008 |isbn=978-1-84628-970-5 |page=578 |url=https://books.google.com/books?id=V0gUTxkOSboC&amp;pg=PA578}}.&lt;/ref&gt;

==Counting spanning trees==
[[File:Cayley's formula 2-4.svg|thumb|[[Cayley's formula]] counts the number of spanning trees on a complete graph. There are &lt;math&gt;2^{2-2}=1&lt;/math&gt; trees in &lt;math&gt;K_2&lt;/math&gt;,
&lt;math&gt;3^{3-2}=3&lt;/math&gt; trees in &lt;math&gt;K_3&lt;/math&gt;, and &lt;math&gt;4^{4-2}=16&lt;/math&gt;
trees in &lt;math&gt;K_4&lt;/math&gt;.]]
The number ''t''(''G'') of spanning trees of a connected graph is a well-studied
[[invariant (mathematics)|invariant]].

===In specific graphs===
In some cases, it is easy to calculate ''t''(''G'') directly:
*If ''G'' is itself a tree, then {{math|1=''t''(''G'')&amp;nbsp;=&amp;nbsp;1}}.
*When ''G'' is the [[cycle graph]] ''C&lt;sub&gt;n&lt;/sub&gt;'' with ''n'' vertices, then {{math|1=''t''(''G'')&amp;nbsp;=&amp;nbsp;''n''}}.
*For a [[complete graph]]  with ''n'' vertices, [[Cayley's formula]]&lt;ref&gt;{{citation
 | last1 = Aigner | first1 = Martin | author1-link = Martin Aigner
 | last2 = Ziegler | first2 = Günter M. | author2-link = Günter M. Ziegler
 | pages = 141–146
 | publisher = [[Springer-Verlag]]
 | title = [[Proofs from THE BOOK]]
 | year = 1998}}.&lt;/ref&gt; gives the number of spanning trees as {{math|1=''n''&lt;sup&gt;''n''&amp;nbsp;−&amp;nbsp;2&lt;/sup&gt;}}.
*If ''G'' is the [[complete bipartite graph]] &lt;math&gt;K_{p,q}&lt;/math&gt;,&lt;ref&gt;{{citation |title=Pearls in Graph Theory: A Comprehensive Introduction |last1=Hartsfield |first1=Nora |author1-link=Nora Hartsfield |last2=Ringel |first2=Gerhard |author2-link=Gerhard Ringel |publisher=Courier Dover Publications |year=2003 |isbn=978-0-486-43232-8 |page=100 |url=https://books.google.com/books?id=R6pq0fbQG0QC&amp;pg=PA100}}.&lt;/ref&gt; then &lt;math&gt;t(G)=p^{q-1}q^{p-1}&lt;/math&gt;.
*For the ''n''-dimensional [[hypercube graph]] &lt;math&gt;Q_n&lt;/math&gt;,&lt;ref&gt;{{citation
 | last1 = Harary | first1 = Frank | author1-link = Frank Harary
 | last2 = Hayes | first2 = John P.
 | last3 = Wu | first3 = Horng-Jyh
 | doi = 10.1016/0898-1221(88)90213-1
 | issue = 4
 | journal = Computers &amp; Mathematics with Applications
 | mr = 949280
 | pages = 277–289
 | title = A survey of the theory of hypercube graphs
 | volume = 15
 | year = 1988}}.&lt;/ref&gt; the number of spanning trees is &lt;math&gt;t(G)=2^{2^n-n-1}\prod_{k=2}^n k^{{n\choose k}}&lt;/math&gt;.

===In arbitrary graphs===
{{main|Kirchhoff's theorem}}
More generally, for any graph ''G'', the number ''t''(''G'') can be calculated in [[polynomial time]] as the [[determinant]] of a [[matrix (mathematics)|matrix]] derived from the graph,
using [[Kirchhoff's theorem|Kirchhoff's matrix-tree theorem]].&lt;ref&gt;{{citation |title=Graphs, Algorithms, and Optimization |series=Discrete Mathematics and Its Applications |first1=William |last1=Kocay |first2=Donald L. |last2=Kreher |publisher=CRC Press |year=2004 |isbn=978-0-203-48905-5 |pages=111–116 |contribution=5.8 The matrix-tree theorem |url=https://books.google.com/books?id=zxSmHAoMiRUC&amp;pg=PA111}}.&lt;/ref&gt;

Specifically, to compute ''t''(''G''), one constructs a square matrix in which the rows and columns are both indexed by the vertices of ''G''. The entry in row ''i'' and column ''j'' is one of three values:
*The degree of vertex ''i'', if ''i''&amp;nbsp;=&amp;nbsp;''j'',
*−1, if vertices ''i'' and ''j'' are adjacent, or
*0, if vertices ''i'' and ''j'' are different from each other but not adjacent.
The resulting matrix is [[singular matrix|singular]], so its determinant is zero. However, deleting the row and column for an arbitrarily chosen vertex leads to a smaller matrix whose determinant is exactly&amp;nbsp;''t''(''G'').

===Deletion-contraction===
If ''G'' is a graph or [[multigraph]] and ''e'' is an arbitrary edge of ''G'', then the number ''t''(''G'') of spanning trees of ''G'' satisfies the ''deletion-contraction recurrence''
''t''(''G'')&amp;nbsp;=&amp;nbsp;''t''(''G''&amp;nbsp;−&amp;nbsp;''e'')&amp;nbsp;+&amp;nbsp;''t''(''G''/''e''), where ''G''&amp;nbsp;−&amp;nbsp;''e'' is the multigraph obtained by deleting ''e''
and ''G''/''e'' is the [[Edge contraction|contraction]] of ''G'' by ''e''.&lt;ref&gt;{{harvtxt|Kocay|Kreher|2004}}, p.&amp;nbsp;109.&lt;/ref&gt; The term ''t''(''G''&amp;nbsp;−&amp;nbsp;''e'') in this formula counts the spanning trees of&amp;nbsp;''G'' that do not use edge&amp;nbsp;''e'', and the term ''t''(''G''/''e'') counts the spanning trees of&amp;nbsp;''G'' that use&amp;nbsp;''e''.

In this formula, if the given graph ''G'' is a [[multigraph]], or if a contraction causes two vertices to be connected to each other by multiple edges,
then the redundant edges should not be removed, as that would lead to the wrong total. For instance a [[bond graph]] connecting two vertices by ''k'' edges has ''k'' different spanning trees, each consisting of a single one of these edges.

===Tutte polynomial===
{{main|Tutte polynomial}}
The [[Tutte polynomial]] of a graph can be defined as a sum, over the spanning trees of the graph, of terms computed from the "internal activity" and "external activity" of the tree. Its value at the arguments (1,1) is the number of spanning trees or, in a disconnected graph, the number of maximal spanning forests.&lt;ref&gt;{{harvtxt|Bollobás|1998}}, p. 351.&lt;/ref&gt;

The Tutte polynomial can also be computed using a deletion-contraction recurrence, but its [[Computational complexity theory|computational complexity]] is high: for many values of its arguments, computing it exactly is [[Sharp-P-complete|#P-complete]], and it is also hard to approximate with a guaranteed [[approximation ratio]]. The point (1,1), at which it can be evaluated using Kirchhoff's theorem, is one of the few exceptions.&lt;ref&gt;{{Citation
|last1=Goldberg | first1= L.A. | author1-link = Leslie Ann Goldberg
|last2=Jerrum | first2=  M.
|author2-link=Mark Jerrum
|title= Inapproximability of the Tutte polynomial
|journal=Information and Computation
| doi=10.1016/j.ic.2008.04.003
|year=2008
|volume=206
|pages=908–929
|issue=7
}}; {{Citation
| last1= Jaeger |first1= F.
|last2= Vertigan | first2=  D. L.
|last3= Welsh | first3  =D. J. A.|authorlink3=Dominic Welsh
| title= On the computational complexity of the Jones and Tutte polynomials
|journal=Mathematical Proceedings of the Cambridge Philosophical Society
| volume= 108|pages = 35–53
| doi= 10.1017/S0305004100068936
| year= 1990
}}.&lt;/ref&gt;

==Algorithms==
===Construction===
A single spanning tree of a graph can be found in [[linear time]] by either [[depth-first search]] or [[breadth-first search]]. Both of these algorithms explore the given graph, starting from an arbitrary vertex ''v'', by looping through the neighbors of the vertices they discover and adding each unexplored neighbor to a data structure to be explored later. They differ in whether this data structure is a  [[Stack (abstract data type)|stack]] (in the case of depth-first search) or a  [[Queue (abstract data type)|queue]] (in the case of breadth-first search). In either case, one can form a spanning tree by connecting each vertex, other than the root vertex ''v'', to the vertex from which it was discovered. This tree is known as a depth-first search tree or a breadth-first search tree according to the graph exploration algorithm used to construct it.&lt;ref&gt;{{citation |title=The Design and Analysis of Algorithms|series=Monographs in Computer Science |first=Dexter |last=Kozen |authorlink=Dexter Kozen |publisher=Springer |year=1992 |isbn=978-0-387-97687-7 |page=19 |url=https://books.google.com/books?id=L_AMnf9UF9QC&amp;pg=PA19}}.&lt;/ref&gt; Depth-first search trees are a special case of a class of spanning trees called [[Trémaux tree]]s, named after the 19th-century discoverer of depth-first search.&lt;ref&gt;{{citation
 | last1 = de Fraysseix | first1 = Hubert
 | last2 = Rosenstiehl | first2 = Pierre | author2-link = Pierre Rosenstiehl
 | contribution = A depth-first-search characterization of planarity
 | location = Amsterdam
 | mr = 671906
 | pages = 75–80
 | publisher = North-Holland
 | series = Ann. Discrete Math.
 | title = Graph theory (Cambridge, 1981)
 | volume = 13
 | year = 1982}}.&lt;/ref&gt;

Spanning trees are important in parallel and distributed computing, as a way of maintaining communications between a set of processors; see for instance the [[Spanning Tree Protocol]] used by [[Data link layer|OSI link layer]] devices or the [[Shout (protocol)]] for distributed computing. However, the depth-first and breadth-first methods for constructing spanning trees on sequential computers are not well suited for parallel and distributed computers.&lt;ref&gt;{{citation
 | last = Reif | first = John H. | authorlink = John Reif
 | doi = 10.1016/0020-0190(85)90024-9
 | issue = 5
 | journal = Information Processing Letters
 | mr = 801987
 | pages = 229–234
 | title = Depth-first search is inherently sequential
 | volume = 20
 | year = 1985}}.&lt;/ref&gt; Instead, researchers have devised several more specialized algorithms for finding spanning trees in these models of computation.&lt;ref&gt;{{citation
 | last1 = Gallager | first1 = R. G.
 | last2 = Humblet | first2 = P. A.
 | last3 = Spira | first3 = P. M.
 | doi = 10.1145/357195.357200
 | issue = 1
 | journal = ACM Transactions on Programming Languages and Systems
 | pages = 66–77
 | title = A distributed algorithm for minimum-weight spanning trees
 | volume = 5
 | year = 1983}}; {{citation
 | last = Gazit | first = Hillel
 | doi = 10.1137/0220066
 | issue = 6
 | journal = SIAM Journal on Computing
 | mr = 1135748
 | pages = 1046–1067
 | title = An optimal randomized parallel algorithm for finding connected components in a graph
 | volume = 20
 | year = 1991}}; {{citation
 | last1 = Bader | first1 = David A.
 | last2 = Cong | first2 = Guojing
 | doi = 10.1016/j.jpdc.2005.03.011
 | issue = 9
 | journal = Journal of Parallel and Distributed Computing
 | pages = 994–1006
 | title = A fast, parallel spanning tree algorithm for symmetric multiprocessors (SMPs)
 | url = http://www.cc.gatech.edu/fac/bader/papers/SpanningTree-JPDC2005.pdf
 | volume = 65
 | year = 2005}}.&lt;/ref&gt;

===Optimization===
In certain fields of graph theory it is often useful to find a [[minimum spanning tree]] of a [[weighted graph]]. Other optimization problems on spanning trees have also been studied, including the maximum spanning tree, the minimum tree that spans at least k vertices, the [[Minimum degree spanning tree|spanning tree with the fewest edges per vertex]], the [[maximum leaf spanning tree|spanning tree with the largest number of leaves]], the spanning tree with the fewest leaves (closely related to the [[Hamiltonian path problem]]), the minimum diameter spanning tree, and the minimum dilation spanning tree.&lt;ref name="sts"&gt;{{citation |last=Eppstein |first=David |authorlink=David Eppstein |contribution=Spanning trees and spanners |title=Handbook of Computational Geometry|editor1-first=J.-R.|editor1-last=Sack|editor1-link=Jörg-Rüdiger Sack|editor2-first=J.|editor2-last=Urrutia|editor2-link=Jorge Urrutia Galicia |publisher=Elsevier |year=1999 |pages=425–461 |contribution-url=http://www.ics.uci.edu/~eppstein/pubs/Epp-TR-96-16.pdf}}.&lt;/ref&gt;&lt;ref&gt;{{citation |last1=Wu |first1=Bang Ye |last2=Chao |first2=Kun-Mao |title=Spanning Trees and Optimization Problems |year=2004 |publisher=CRC Press |isbn=1-58488-436-3}}.&lt;/ref&gt;

Optimal spanning tree problems have also been studied for finite sets of points in a geometric space such as the [[Euclidean plane]]. For such an input, a spanning tree is again a tree that has as its vertices the given points. The quality of the tree is measured in the same way as in a graph, using the Euclidean distance between pairs of points as the weight for each edge. Thus, for instance, a [[Euclidean minimum spanning tree]] is the same as a graph minimum spanning tree in a [[complete graph]] with Euclidean edge weights. However, it is not necessary to construct this graph in order to solve the optimization problem; the Euclidean minimum spanning tree problem, for instance, can be solved more efficiently in ''O''(''n''&amp;nbsp;log&amp;nbsp;''n'') time by constructing the [[Delaunay triangulation]] and then applying a linear time [[planar graph]] minimum spanning tree algorithm to the resulting triangulation.&lt;ref name="sts"/&gt;

===Randomization===
A spanning tree chosen [[random]]ly from among all the spanning trees with equal probability is called a [[uniform spanning tree]]. Wilson's algorithm can be used to generate uniform spanning trees in polynomial time by a process of taking a random walk on the given graph and erasing the cycles created by this walk.&lt;ref&gt;{{citation
 | last = Wilson | first = David Bruce
 | contribution = Generating random spanning trees more quickly than the cover time
 | doi = 10.1145/237814.237880
 | mr = 1427525
 | pages = 296–303
 | title = [[Symposium on Theory of Computing|Proceedings of the Twenty-eighth Annual ACM Symposium on the Theory of Computing (STOC 1996)]]
 | year = 1996}}.&lt;/ref&gt;

An alternative model for generating spanning trees randomly but not uniformly is the [[random minimal spanning tree]]. In this model, the edges of the graph are assigned random weights and then the [[minimum spanning tree]] of the weighted graph is constructed.&lt;ref&gt;{{citation
 | last1 = McDiarmid | first1 = Colin
 | last2 = Johnson | first2 = Theodore
 | last3 = Stone | first3 = Harold S.
 | doi = 10.1002/(SICI)1098-2418(199701/03)10:1/2&lt;187::AID-RSA10&gt;3.3.CO;2-Y
 | issue = 1-2
 | journal = Random Structures &amp; Algorithms
 | mr = 1611522
 | pages = 187–204
 | title = On finding a minimum spanning tree in a network with random weights
 | url = http://www.stats.ox.ac.uk/~cstone/mst.pdf
 | volume = 10
 | year = 1997}}.&lt;/ref&gt;

===Enumeration===
Because a graph may have exponentially many spanning trees, it is not possible to list them all in [[polynomial time]]. However, algorithms are known for listing all spanning trees in polynomial time per tree.&lt;ref&gt;{{citation
 | last1 = Gabow | first1 = Harold N.
 | last2 = Myers | first2 = Eugene W. | author2-link = Eugene Myers
 | doi = 10.1137/0207024
 | issue = 3
 | journal = [[SIAM Journal on Computing]]
 | mr = 0495152
 | pages = 280–287
 | title = Finding all spanning trees of directed and undirected graphs
 | volume = 7
 | year = 1978}}&lt;/ref&gt;

==In infinite graphs==
Every finite connected graph has a spanning tree. However, for infinite connected graphs, the existence of spanning trees is equivalent to the [[axiom of choice]]. An infinite graph is connected if each pair of its vertices forms the pair of endpoints of a finite path. As with finite graphs, a tree is a connected graph with no finite cycles, and a spanning tree can be defined either as a maximal acyclic set of edges or as a tree that contains every vertex.&lt;ref name="serre"/&gt;

The trees within a graph may be partially ordered by their subgraph relation, and any infinite chain in this partial order has an upper bound (the union of the trees in the chain). [[Zorn's lemma]], one of many equivalent statements to the axiom of choice, requires that a partial order in which all chains are upper bounded have a maximal element; in the partial order on the trees of the graph, this maximal element must be a spanning tree. Therefore, if Zorn's lemma is assumed, every infinite connected graph has a spanning tree.&lt;ref name="serre"&gt;{{citation|title=Trees|first=Jean-Pierre|last=Serre|authorlink=Jean-Pierre Serre|page=23|publisher=Springer|series=Springer Monographs in Mathematics|year=2003}}.&lt;/ref&gt;

In the other direction, given a [[family of sets]], it is possible to construct an infinite graph such that every spanning tree of the graph corresponds to a [[choice function]] of the family of sets. Therefore,
if every infinite connected graph has a spanning tree, then the axiom of choice is true.&lt;ref&gt;{{citation
 | last = Soukup | first = Lajos
 | contribution = Infinite combinatorics: from finite to infinite
 | doi = 10.1007/978-3-540-77200-2_10
 | location = Berlin
 | mr = 2432534
 | pages = 189–213
 | publisher = Springer
 | series = Bolyai Soc. Math. Stud.
 | title = Horizons of combinatorics
 | volume = 17
 | year = 2008}}. See in particular Theorem 2.1, [https://books.google.com/books?id=kIKW18ENfUMC&amp;pg=PA192 pp.&amp;nbsp;192–193].&lt;/ref&gt;

==In directed multigraphs==
The idea of a spanning tree can be generalized to directed multigraphs.&lt;ref name="Levine09"&gt;{{cite journal
 | title = Sandpile groups and spanning trees of directed line graphs
 | journal = Journal of Combinatorial Theory, Series A
 | volume = 118
 | number = 2
 | pages = 350–364
 | year = 2011
 | issn = 0097-3165
 | doi = 10.1016/j.jcta.2010.04.001
 | url = http://www.sciencedirect.com/science/article/pii/S0097316510000701
 | author = "Lionel Levine"
}}&lt;/ref&gt; Given a vertex ''v'' on a directed multigraph ''G'', an ''oriented spanning tree'' ''T'' rooted at ''v'' is an acyclic subgraph of ''G'' in which every vertex other than ''v'' has outdegree 1. This definition is only satisfied when the “branches” of ''T'' point towards ''v''.

==See also==
*[[Flooding algorithm]]
*[[Good spanning tree]] - spanning tree for embedded planar graph

==References==
{{reflist|30em}}

[[Category:Spanning tree]]
[[Category:Computational problems in graph theory]]
[[Category:Axiom of choice]]</text>
      <sha1>bvj8v1hsr3ebgb8xitwv7dwuyi6pitg</sha1>
    </revision>
  </page>
  <page>
    <title>Structure theorem for Gaussian measures</title>
    <ns>0</ns>
    <id>6593472</id>
    <revision>
      <id>671981029</id>
      <parentid>610298262</parentid>
      <timestamp>2015-07-18T11:33:00Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* References */replace/remove deprecated cs1|2 parameters; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2087">In [[mathematics]], the '''structure theorem for Gaussian measures''' shows that the [[abstract Wiener space]] construction is essentially the only way to obtain a [[Strictly positive measure|strictly positive]] [[Gaussian measure]] on a [[separable space|separable]] [[Banach space]]. It was proved in the 1970s by [[Gopinath Kallianpur|Kallianpur]]&amp;ndash;Sato&amp;ndash;Stefan and [[Richard M. Dudley|Dudley]]&amp;ndash;[[Jacob Feldman|Feldman]]&amp;ndash;[[Lucien le Cam|le Cam]].&lt;!-- I don't see those papers cited here. --&gt;

There is the earlier result due to H. Satô (1969) &lt;ref&gt;[http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.nmj/1118797795 H. Satô, Gaussian Measure on a Banach Space and Abstract Wiener Measure], 1969.&lt;/ref&gt; which proves that "any Gaussian measure on a separable Banach space is an [[abstract Wiener space | abstract Wiener measure]] in the sense of [[Leonard Gross | L. Gross]]". The result by Dudley et al. generalizes this result to the setting of Gaussian measures on a general [[topological vector space]].

==Statement of the theorem==
Let ''&amp;gamma;'' be a strictly positive Gaussian measure on a separable Banach space (''E'',&amp;nbsp;||&amp;nbsp;||). Then there exists a separable [[Hilbert space]] (''H'',&amp;nbsp;&amp;lang;&amp;nbsp;,&amp;nbsp;&amp;rang;)  and a map ''i''&amp;nbsp;:&amp;nbsp;''H''&amp;nbsp;&amp;rarr;&amp;nbsp;''E'' such that ''i''&amp;nbsp;:&amp;nbsp;''H''&amp;nbsp;&amp;rarr;&amp;nbsp;''E'' is an abstract Wiener space with ''&amp;gamma;''&amp;nbsp;=&amp;nbsp;''i''&lt;sub&gt;&amp;lowast;&lt;/sub&gt;(''&amp;gamma;''&lt;sup&gt;''H''&lt;/sup&gt;), where ''&amp;gamma;''&lt;sup&gt;''H''&lt;/sup&gt; is the [[canonical form|canonical]] Gaussian [[cylinder set measure]] on ''H''.

{{Reflist}}

==References==

* {{cite journal
| last = Dudley
| first = Richard M. |author2=Feldman, Jacob |author3=Le Cam, Lucien
| title = On seminorms and probabilities, and abstract Wiener spaces
| journal = Annals of Mathematics. Second Series
| volume = 93
| year = 1971
| pages = 390&amp;ndash;408
| issn = 0003-486X
| doi=10.2307/1970780}}  {{MathSciNet|id=0279272}}

[[Category:Theorems in measure theory]]
[[Category:Probability theorems]]</text>
      <sha1>s39s5js0mr0zb6z15kfmwg9knuhh0ql</sha1>
    </revision>
  </page>
  <page>
    <title>Subclass (set theory)</title>
    <ns>0</ns>
    <id>1828474</id>
    <revision>
      <id>833190579</id>
      <parentid>827980089</parentid>
      <timestamp>2018-03-30T04:29:18Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Class (grouping) per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 March 6]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1681">In [[set theory]] and its applications throughout [[mathematics]], a '''subclass''' is a [[class (set theory)|class]] contained in some other class in the same way that a [[subset]] is a [[Set (mathematics)|set]] contained in some other set.

That is, given classes ''A'' and ''B'', ''A'' is a subclass of ''B'' [[if and only if]] every member of ''A'' is also a member of ''B''.&lt;ref name="bookofsettheory"&gt;{{cite book | url=https://books.google.fr/books?id=q1KVAwAAQBAJ&amp;pg=PA93&amp;lpg=PA93&amp;dq=subclass+set+theory&amp;source=bl&amp;ots=ckExPROxE9&amp;sig=VPof7WJVZWT5WY3OurP7Id38RU8&amp;hl=fr&amp;sa=X&amp;ei=ZDDvVJ7nEY27afylgcAM&amp;ved=0CGwQ6AEwCQ#v=onepage&amp;q=subclass%20set%20theory&amp;f=false | title=A book of set Theory | publisher=Dover Publications Inc. | author=Charles C.Pinter | year=2013 | pages=240 | isbn=978-0486497082}}&lt;/ref&gt;
If ''A'' and ''B'' are sets, then of course ''A'' is also a subset of ''B''.
In fact, when using a definition of classes that requires them to be first-order definable, it's enough that ''B'' be a set; the [[axiom of specification]] essentially says that ''A'' must then also be a set.

As with subsets, the [[empty set]] is a subclass of every class, and any class is a subclass of itself. But additionally, every class is a subclass of the class of all sets. Accordingly, the subclass relation makes the collection of all classes into a [[Boolean lattice]], which the subset relation does not do for the collection of all sets. Instead, the collection of all sets is an [[ideal (lattice theory)|ideal]] in the collection of all classes. (Of course, the collection of all classes is something larger than even a class!)

==References==
{{Reflist}}

[[Category:Set theory]]</text>
      <sha1>j10p1u3t4cua4yez9ad5vo41vpgd8tu</sha1>
    </revision>
  </page>
  <page>
    <title>Surface (topology)</title>
    <ns>0</ns>
    <id>27865</id>
    <revision>
      <id>869949581</id>
      <parentid>869869857</parentid>
      <timestamp>2018-11-21T11:52:12Z</timestamp>
      <contributor>
        <username>Mgnbar</username>
        <id>346060</id>
      </contributor>
      <comment>more links to general surface articles</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31724">{{more footnotes|date=December 2015}}
[[Image:Saddle Point.png|thumb|300px|right|An [[open surface]] with ''x''-, ''y''-, and ''z''-contours shown.]]

In [[topology]], a '''surface''' is a two-dimensional [[manifold]]. Some surfaces arise as the boundaries of three-dimensional solids; for example, the sphere is the boundary of the solid ball. Other surfaces arise as graphs of functions of two variables; see the figure at right. However, surfaces can also be defined abstractly, without reference to any ambient space. For example, the [[Klein bottle]] is a surface that cannot be [[embedding|embedded]] in three-dimensional Euclidean space.

Topological surfaces are sometimes equipped with additional information, such as a [[Riemannian metric]] or a complex structure, that connects them to other disciplines within mathematics, such as [[differential geometry]] and [[complex analysis]]. The various [[Surface (mathematics)|mathematical notions of surface]] can be used to model [[surface]]s in the physical world.

==In general==
{{further|Surface (mathematics)}}

In [[mathematics]], a '''surface''' is a geometrical shape that resembles a deformed [[plane (geometry)|plane]]. The most familiar examples arise as boundaries of solid objects in ordinary three-dimensional [[Euclidean space]] '''R'''&lt;sup&gt;3&lt;/sup&gt;, such as [[sphere]]s. The exact definition of a surface may depend on the context. Typically, in [[algebraic geometry]], a surface may cross itself (and may have other [[singular point of an algebraic variety|singularities]]), while, in [[topology]] and [[differential geometry]], it may not.

A surface is a  [[two-dimensional space]]; this means that a moving point on a surface may move in two directions (it has two [[degrees of freedom]]). In other words, around almost every point, there is a ''[[coordinate patch]]'' on which a two-dimensional [[coordinate system]] is defined. For example, the surface of the Earth resembles (ideally) a two-dimensional [[sphere]], and [[latitude]] and [[longitude]] provide two-dimensional coordinates on it (except at the poles and along the [[180th meridian]]).

The concept of surface is widely used in [[physics]], [[engineering]], [[computer graphics]], and many other disciplines, primarily in representing the surfaces of physical objects. For example, in analyzing the [[aerodynamics|aerodynamic]] properties of an [[airplane]], the central consideration is the flow of air along its surface.

==Definitions and first examples==
A ''(topological) surface'' is a [[topological space]] in which every point has an open [[topological neighbourhood|neighbourhood]] [[homeomorphism|homeomorphic]] to some [[open set|open subset]] of the Euclidean plane '''E'''&lt;sup&gt;2&lt;/sup&gt;. Such a neighborhood, together with the corresponding homeomorphism, is known as a ''(coordinate) chart''. It is through this chart that the neighborhood inherits the standard coordinates on the Euclidean plane. These coordinates are known as ''local coordinates'' and these homeomorphisms lead us to describe surfaces as being ''locally Euclidean''.

In most writings on the subject, it is often assumed, explicitly or implicitly, that as a topological space a surface is also nonempty, [[Second-countable space|second countable]], and [[Hausdorff space|Hausdorff]].  It is also often assumed that the surfaces under consideration are connected.

The rest of this article will assume, unless specified otherwise, that a surface is nonempty, Hausdorff, second countable, and connected.

More generally, a ''(topological) surface with boundary'' is a [[Hausdorff space|Hausdorff]] [[topological space]] in which every point has an open [[topological neighbourhood|neighbourhood]] [[homeomorphism|homeomorphic]] to some [[open set|open subset]] of the closure of the [[upper half-plane]] '''H'''&lt;sup&gt;2&lt;/sup&gt; in '''C'''. These homeomorphisms are also known as ''(coordinate) charts''. The boundary of the upper half-plane is the ''x''-axis. A point on the surface mapped via a chart to the ''x''-axis is termed a ''boundary point''. The collection of such points is known as the ''boundary'' of the surface which is necessarily a one-manifold, that is, the union of closed curves. On the other hand, a point mapped to above the ''x''-axis is an ''interior point''. The collection of interior points is the ''interior'' of the surface which is always non-[[empty set|empty]]. The closed [[disk (mathematics)|disk]] is a simple example of a surface with boundary. The boundary of the disc is a circle.

The term ''surface'' used without qualification refers to surfaces without boundary. In particular, a surface with empty boundary is a surface in the usual sense. A surface with empty boundary which is compact is known as a 'closed' surface. The two-dimensional sphere, the two-dimensional [[torus]], and the [[real projective plane]] are examples of closed surfaces.

The [[Möbius strip]] is a surface on which the distinction between clockwise and counterclockwise can be defined locally, but not globally. In general, a surface is said to be ''orientable'' if it does not contain a homeomorphic copy of the Möbius strip; intuitively, it has two distinct "sides". For example, the sphere and torus are orientable, while the real projective plane is not (because the real projective plane with one point removed is homeomorphic to the open Möbius strip).

In [[differential geometry|differential]] and [[algebraic geometry]], extra structure is added upon the topology of the surface. This added structures can be a smoothness structure (making it possible to define differentiable maps to and from the surface), a [[Riemannian metric]] (making it possible to define length and angles on the surface), a complex structure (making it possible to define holomorphic maps to and from the surface — in which case the surface is called a [[Riemann surface]]), or an algebraic structure (making it possible to detect [[Singular point of an algebraic variety|singularities]], such as self-intersections and cusps, that cannot be described solely in terms of the underlying topology).

==Extrinsically defined surfaces and embeddings==
[[Image:Sphere wireframe.svg|left|thumb|250px|A sphere can be defined parametrically (by ''x'' = ''r'' sin ''θ'' cos ''φ'',
''y'' = ''r'' sin ''θ'' sin ''φ'', ''z'' = ''r'' cos ''θ'') or implicitly (by {{nowrap|''x''&lt;sup&gt;2&lt;/sup&gt; + ''y''&lt;sup&gt;2&lt;/sup&gt; + ''z''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; ''r''&lt;sup&gt;2&lt;/sup&gt; {{=}} 0}}.)]]

Historically, surfaces were initially defined as subspaces of Euclidean spaces. Often, these surfaces were the [[locus (mathematics)|locus]] of [[root of a function|zeros]] of certain functions, usually polynomial functions. Such a definition considered the surface as part of a larger (Euclidean) space, and as such was termed ''extrinsic''.

In the previous section, a surface is defined as a topological space with certain properties, namely Hausdorff and locally Euclidean. This topological space is not considered a subspace of another space. In this sense, the definition given above, which is the definition that mathematicians use at present, is ''intrinsic''.

A surface defined as intrinsic is not required to satisfy the added constraint of being a subspace of Euclidean space.  It may seem possible for some surfaces defined intrinsically to not be surfaces in the extrinsic sense. However, the [[Whitney embedding theorem]] asserts every surface can in fact be embedded homeomorphically into Euclidean space, in fact into '''E'''&lt;sup&gt;4&lt;/sup&gt;: The extrinsic and intrinsic approaches turn out to be equivalent.

In fact, any compact surface that is either orientable or has a boundary can be embedded in '''E'''&lt;sup&gt;3&lt;/sup&gt;; on the other hand, the real projective plane, which is compact, non-orientable and without boundary, cannot be embedded into '''E'''&lt;sup&gt;3&lt;/sup&gt; (see Gramain). [[Steiner surface]]s, including [[Boy's surface]], the [[Roman surface]] and the [[cross-cap]], are models of the real projective plane in '''E'''&lt;sup&gt;3&lt;/sup&gt;, but only the Boy surface is an [[immersion (mathematics)|immersed surface]]. All these models are singular at points where they intersect themselves.

The [[Alexander horned sphere]] is a well-known [[pathological (mathematics)|pathological]] embedding of the two-sphere into the three-sphere.

[[Image:KnottedTorus.svg|right|thumb|A knotted torus.]]
The chosen embedding (if any) of a surface into another space is regarded as extrinsic information; it is not essential to the surface itself. For example, a torus can be embedded into '''E'''&lt;sup&gt;3&lt;/sup&gt; in the "standard" manner (which looks like a [[bagel]]) or in a [[knot (mathematics)|knotted]] manner (see figure). The two embedded tori are homeomorphic, but not [[Homotopy#Isotopy|isotopic]]: They are topologically equivalent, but their embeddings are not.

The [[image (mathematics)|image]] of a continuous, [[injection (mathematics)|injective]] function from '''R'''&lt;sup&gt;2&lt;/sup&gt; to higher-dimensional '''R'''&lt;sup&gt;n&lt;/sup&gt; is said to be a [[parametric surface]]. Such an image is so-called because the ''x''- and ''y''- directions of the domain '''R'''&lt;sup&gt;2&lt;/sup&gt; are 2 variables that parametrize the image. A parametric surface need not be a topological surface. A [[surface of revolution]] can be viewed as a special kind of parametric surface.

If ''f'' is a smooth function from '''R'''&lt;sup&gt;3&lt;/sup&gt; to '''R''' whose [[gradient]] is nowhere zero, then the [[locus (mathematics)|locus]] of [[root of a function|zeros]] of ''f'' does define a surface, known as an ''[[implicit surface]]''. If the condition of non-vanishing gradient is dropped, then the zero locus may develop singularities.
{{clear}}

==Construction from polygons==
Each closed surface can be constructed from an oriented polygon with an even number of sides, called a [[fundamental polygon]] of the surface, by pairwise identification of its edges. For example, in each polygon below, attaching the sides with matching labels (''A'' with ''A'', ''B'' with ''B''), so that the arrows point in the same direction, yields the indicated surface.

&lt;gallery&gt;
Image:SphereAsSquare.svg|[[sphere]]
Image:ProjectivePlaneAsSquare.svg|[[real projective plane]]
Image:TorusAsSquare.svg|[[torus]]
Image:KleinBottleAsSquare.svg|[[Klein bottle]]
&lt;/gallery&gt;

Any fundamental polygon can be written symbolically as follows. Begin at any vertex, and proceed around the perimeter of the polygon in either direction until returning to the starting vertex. During this traversal, record the label on each edge in order, with an exponent of -1 if the edge points opposite to the direction of traversal. The four models above, when traversed clockwise starting at the upper left, yield

* sphere: &lt;math&gt;A B B^{-1} A^{-1}&lt;/math&gt;
* real projective plane: &lt;math&gt;A B A B&lt;/math&gt;
* torus: &lt;math&gt;A B A^{-1} B^{-1}&lt;/math&gt;
* Klein bottle: &lt;math&gt;A B A B^{-1}&lt;/math&gt;.
Note that the sphere and the projective plane can both be realized as quotients of the 2-gon, while the torus and Klein bottle require a 4-gon (square).

The expression thus derived from a fundamental polygon of a surface turns out to be the sole relation in a [[presentation of a group|presentation]] of the [[fundamental group]] of the surface with the polygon edge labels as generators. This is a consequence of the [[Seifert–van Kampen theorem]].

Gluing edges of polygons is a special kind of [[Quotient space (topology)|quotient space]] process. The quotient concept can be applied in greater generality to produce new or alternative constructions of surfaces. For example, the real projective plane can be obtained as the quotient of the sphere by identifying all pairs of opposite points on the sphere. Another example of a quotient is the connected sum.

==Connected sums==
The [[connected sum]] of two surfaces ''M'' and ''N'', denoted ''M'' # ''N'', is obtained by removing a disk from each of them and gluing them along the boundary components that result. The boundary of a disk is a circle, so these boundary components are circles. The [[Euler characteristic]] &lt;math&gt;\chi&lt;/math&gt; of {{nowrap|''M'' # ''N''}} is the sum of the Euler characteristics of the summands, minus two:

:&lt;math&gt;\chi(M \mathbin{\#} N) = \chi(M) + \chi(N) - 2.\,&lt;/math&gt;

The sphere '''S''' is an [[identity element]] for the connected sum, meaning that {{nowrap|1='''S''' # ''M'' = ''M''}}. This is because deleting a disk from the sphere leaves a disk, which simply replaces the disk deleted from ''M'' upon gluing.

Connected summation with the torus '''T''' is also described as attaching a "handle" to the other summand ''M''. If ''M'' is orientable, then so is {{nowrap|'''T''' # ''M''}}. The connected sum is associative, so the connected sum of a finite collection of surfaces is well-defined.

The connected sum of two real projective planes, {{nowrap|'''P''' # '''P'''}}, is the [[Klein bottle]] '''K'''. The connected sum of the real projective plane and the Klein bottle is homeomorphic to the connected sum of the real projective plane with the torus; in a formula, {{nowrap|1='''P''' # '''K''' = '''P''' # '''T'''}}. Thus, the connected sum of three real projective planes is homeomorphic to the connected sum of the real projective plane with the torus. Any connected sum involving a real projective plane is nonorientable.

== Closed surfaces ==
{{distinguish redirect|Open surface|Free surface}}

A '''closed surface''' is a surface that is [[compact space|compact]] and without [[Boundary of a manifold|boundary]]. Examples are spaces like the [[sphere]], the [[torus]] and the [[Klein bottle]]. Examples of non-closed surfaces are: an [[disk (mathematics)|open disk]], which is a sphere with a puncture; a [[cylinder (geometry)|cylinder]], which is a sphere with two punctures; and the [[Möbius strip]].  As with any [[closed manifold]], a surface embedded in Euclidean space that is closed with respect to the inherited [[Euclidean topology]] is ''not'' necessarily a closed surface; for example, a disk embedded in &lt;math&gt; \mathbb{R}^3 &lt;/math&gt; that contains its boundary is a surface that is topologically closed, but not a closed surface.

=== Classification of closed surfaces ===
[[File:SurfacesWithAndWithoutBoundary.svg|right|thumb|200px|Some examples of orientable closed surfaces (left) and surfaces with boundary (right). Left: Some orientable closed surfaces are the surface of a sphere, the surface of a [[torus]], and the surface of a cube. (The cube and the sphere are topologically equivalent to each other.) Right: Some surfaces with boundary are the [[disk (mathematics)|disk surface]], square surface, and hemisphere surface. The boundaries are shown in red. All three of these are topologically equivalent to each other.]]

The ''classification theorem of closed surfaces'' states that any [[connected (topology)|connected]] closed surface is homeomorphic to some member of one of these three families:
# the sphere;
# the connected sum of ''g'' tori, for &lt;math&gt;g \geq 1&lt;/math&gt;;
# the connected sum of ''k'' real projective planes, for &lt;math&gt;k \geq 1&lt;/math&gt;.

The surfaces in the first two families are [[orientability|orientable]]. It is convenient to combine the two families by regarding the sphere as the connected sum of 0 tori. The number ''g'' of tori involved is called the ''genus'' of the surface. The sphere and the torus have Euler characteristics 2 and 0, respectively, and in general the Euler characteristic of the connected sum of ''g'' tori is {{nowrap|2 &amp;minus; 2''g''}}.

The surfaces in the third family are nonorientable. The Euler characteristic of the real projective plane is 1, and in general the Euler characteristic of the connected sum of ''k'' of them is {{nowrap|2 &amp;minus; ''k''}}.

It follows that a closed surface is determined, up to homeomorphism, by two pieces of information: its Euler characteristic, and whether it is orientable or not. In other words, Euler characteristic and orientability completely classify closed surfaces up to homeomorphism.

Closed surfaces with multiple [[Connected component (topology)|connected components]] are classified by the class of each of their connected components, and thus one generally assumes that the surface is connected.

=== Monoid structure ===
Relating this classification to connected sums, the closed surfaces up to homeomorphism form a [[commutative]] [[monoid]] under the operation of connected sum, as indeed do manifolds of any fixed dimension. The identity is the sphere, while the real projective plane and the torus generate this monoid, with a single relation {{nowrap|1='''P''' # '''P''' # '''P''' = '''P''' # '''T'''}}, which may also be written  {{nowrap|1='''P''' # '''K''' = '''P''' # '''T'''}}, since {{nowrap|1='''K''' = '''P''' # '''P'''}}. This relation is sometimes known as '''{{visible anchor|Dyck's theorem}}''' after [[Walther von Dyck]], who proved it in {{Harv|Dyck|1888}}, and the triple cross surface {{nowrap|'''P''' # '''P''' # '''P'''}} is accordingly called '''{{visible anchor|Dyck's surface}}'''.&lt;ref name="fw"/&gt;

Geometrically, connect-sum with a torus ({{nowrap|# '''T'''}}) adds a handle with both ends attached to the same side of the surface, while connect-sum with a Klein bottle ({{nowrap|# '''K'''}}) adds a handle with the two ends attached to opposite sides of an orientable surface; in the presence of a projective plane ({{nowrap|# '''P'''}}), the surface is not orientable (there is no notion of side), so there is no difference between attaching a torus and attaching a Klein bottle, which explains the relation.

=== Surfaces with boundary ===
[[Compact manifold|Compact]] surfaces, possibly with boundary, are simply closed surfaces with a finite number of holes (open discs that have been removed).  Thus, a connected compact surface is classified by the number of boundary components and the genus of the corresponding closed surface – equivalently, by the number of boundary components, the orientability, and Euler characteristic. The genus of a compact surface is defined as the genus of the corresponding closed surface.

This classification follows almost immediately from the classification of closed surfaces: removing an open disc from a closed surface yields a compact surface with a circle for boundary component, and removing ''k'' open discs yields a compact surface with ''k'' disjoint circles for boundary components.  The precise locations of the holes are irrelevant, because the homeomorphism group acts [[transitive action|''k''-transitively]] on any connected manifold of dimension at least 2.

Conversely, the boundary of a compact surface is a closed 1-manifold, and is therefore the disjoint union of a finite number of circles; filling these circles with disks (formally, taking the [[Cone (topology)|cone]]) yields a closed surface.

The unique compact orientable surface of genus ''g'' and with ''k'' boundary components is often denoted &lt;math&gt;\Sigma_{g,k},&lt;/math&gt; for example in the study of the [[mapping class group]].

=== Riemann surfaces ===
A [[Riemann surface]] is a complex 1-manifold. On a purely topological level, a Riemann surface is therefore also an orientable surface in the sense of this article. In fact, every compact orientable surface is realizable as a Riemann surface. Thus compact Riemann surfaces are characterized topologically by their genus: 0, 1, 2, .... On the other hand, the genus does not characterize the complex structure. For example, there uncountably many non-isomorphic compact Riemann surfaces of genus 1 (the [[Elliptic_curve#Elliptic_curves_over_the_complex_numbers|elliptic curves]]).

=== Non-compact surfaces ===
Non-compact surfaces are more difficult to classify.  As a simple example, a non-compact surface can be obtained by puncturing (removing a finite set of points from) a closed manifold.  On the other hand, any open subset of a compact surface is itself a non-compact surface; consider, for example, the complement of a [[Cantor set]] in the sphere, otherwise known as the [[Cantor tree surface]].  However, not every non-compact surface is a subset of a compact surface; two canonical counterexamples are the [[Jacob's ladder (manifold)|Jacob's ladder]] and the [[Loch Ness monster surface|Loch Ness monster]], which are non-compact surfaces with infinite genus.

A non-compact surface M has a non-empty [[End (topology)|space of ends]] E(M), which informally speaking describes the ways that the surface "goes off to infinity".  The space E(M) is always topologically equivalent to a closed subspace of the [[Cantor set]].  M may have a finite or countably infinite number N&lt;sub&gt;h&lt;/sub&gt; of handles, as well as a finite or countably infinite number N&lt;sub&gt;p&lt;/sub&gt; of [[projective plane]]s. If both N&lt;sub&gt;h&lt;/sub&gt; and N&lt;sub&gt;p&lt;/sub&gt; are finite, then these two numbers, and the topological type of space of ends, classify the surface M up to topological equivalence.  If either or both of N&lt;sub&gt;h&lt;/sub&gt; and N&lt;sub&gt;p&lt;/sub&gt; is infinite, then the topological type of M depends not only on these two numbers but also on how the infinite one(s) approach the space of ends. In general the topological type of M is determined by the four subspaces of E(M) that are limit points of infinitely many handles and infinitely many projective planes, limit points of only handles, limit points of only projective planes, and limit points of neither.

====Surfaces that are not even second countable====

If one removes the assumption of second countability from the definition of a surface, there exist (necessarily non-compact) topological surfaces having no countable base for their topology. Perhaps the simplest example is the Cartesian product of the [[long line (topology)|long line]] with the space of real numbers.

Another surface having no countable base for its topology, but ''not'' requiring the Axiom of Choice to prove its existence, is the [[Prüfer manifold]], which can be described by simple equations that show it to be a [[real analytic|real-analytic]] surface.  The Prüfer manifold may be thought of as the upper half plane together with one additional "tongue" ''T''&lt;sub&gt;''x''&lt;/sub&gt; hanging down from it directly below the point (''x'',0), for each real&amp;nbsp;''x''.

In 1925, Tibor Radó proved the [[Radó's theorem (Riemann surfaces)|theorem]] all Riemann surfaces (i.e., one-dimensional [[complex manifolds]]) are necessarily second countable. By contrast, if one replaces the real numbers in the construction of the Prüfer surface by the complex numbers, one obtains a two-dimensional complex manifold (which is necessarily a 4-dimensional real manifold) with no countable base.

=== Proof ===
The classification of closed surfaces has been known since the 1860s,&lt;ref name="fw"&gt;{{Harv|Francis|Weeks|1999}}&lt;/ref&gt; and today a number of proofs exist.

Topological and combinatorial proofs in general rely on the difficult result that every compact 2-manifold is homeomorphic to a [[simplicial complex]], which is of interest in its own right. The most common proof of the classification is {{Harv|Seifert|Threlfall|1934}},&lt;ref name="fw"/&gt; which brings every triangulated surface to a standard form. A simplified proof, which avoids a standard form, was discovered by [[John H. Conway]] circa 1992, which he called the "Zero Irrelevancy Proof" or "ZIP proof" and is presented in {{Harv|Francis|Weeks|1999}}.

A geometric proof, which yields a stronger geometric result, is the [[uniformization theorem]]. This was originally proven only for Riemann surfaces in the 1880s and 1900s by [[Felix Klein]], [[Paul Koebe]], and [[Henri Poincaré]].

==Surfaces in geometry==
{{main|Differential geometry of surfaces}}

[[Polyhedron|Polyhedra]], such as the boundary of a [[cube]], are among the first surfaces encountered in geometry. It is also possible to define ''smooth surfaces'', in which each point has a neighborhood [[diffeomorphism|diffeomorphic]] to some open set in '''E'''&lt;sup&gt;2&lt;/sup&gt;. This elaboration allows [[calculus]] to be applied to surfaces to prove many results.

Two smooth surfaces are diffeomorphic if and only if they are homeomorphic. (The analogous result does not hold for higher-dimensional manifolds.) Thus [[#Closed surface|closed surface]]s are classified up to diffeomorphism by their Euler characteristic and orientability.

Smooth surfaces equipped with [[Riemannian metric]]s are of foundational importance in [[differential geometry]]. A Riemannian metric endows a surface with notions of [[geodesic]], [[distance]], [[angle]], and area. It also gives rise to [[Gaussian curvature]], which describes how curved or bent the surface is at each point. Curvature is a rigid, geometric property, in that it is not preserved by general diffeomorphisms of the surface. However, the famous [[Gauss–Bonnet theorem]] for closed surfaces states that the integral of the Gaussian curvature ''K'' over the entire surface ''S'' is determined by the Euler characteristic:
:&lt;math&gt;\int_S K \; dA = 2 \pi \chi(S).&lt;/math&gt;
This result exemplifies the deep relationship between the geometry and topology of surfaces (and, to a lesser extent, higher-dimensional manifolds).

Another way in which surfaces arise in geometry is by passing into the complex domain. A complex one-manifold is a smooth oriented surface, also called a [[Riemann surface]]. Any complex nonsingular [[algebraic curve]] viewed as a complex manifold is a Riemann surface.

Every closed orientable surface admits a complex structure. Complex structures on a closed oriented surface correspond to [[conformally equivalent|conformal equivalence classes]] of Riemannian metrics on the surface. One version of the [[uniformization theorem]] (due to [[Henri Poincaré|Poincaré]]) states that any [[Riemannian metric]] on an oriented, closed surface is conformally equivalent to an essentially unique metric of [[constant curvature]]. This provides a starting point for one of the approaches to [[Teichmüller theory]], which provides a finer classification of Riemann surfaces than the topological one by Euler characteristic alone.

A ''complex surface'' is a complex two-manifold and thus a real four-manifold; it is not a surface in the sense of this article. Neither are algebraic curves  defined over [[field (mathematics)|field]]s other than the complex numbers,
nor are algebraic surfaces  defined over [[field (mathematics)|field]]s other than the real numbers.

==See also==
*[[Boundary (topology)]]
*[[Volume form]], for volumes of surfaces in '''E'''''&lt;sup&gt;n&lt;/sup&gt;''
*[[Poincaré metric]], for metric properties of Riemann surfaces
*[[Roman surface]]
*[[Boy's surface]]
*[[Tetrahemihexahedron]]
*[[Crumpling|Crumpled surface]], a non-differentiable surface obtained by deforming (crumpling) a differentiable surface

==Notes==
{{reflist}}

==References==
*{{Citation | first = Walther | last = Dyck | authorlink = Walther von Dyck | title = Beiträge zur Analysis situs I | journal = Math. Ann. | volume = 32 | year = 1888 | pages = 459–512 | doi=10.1007/bf01443580}}

===Simplicial proofs of classification up to homeomorphism===
*{{citation|last=Seifert|first= Herbert|last2= Threlfall|first2= William|title=A textbook of topology|series=Pure and Applied Mathematics|volume= 89|publisher= Academic Press|year= 1980|isbn= 0126348502}}, English translation of 1934 classic German textbook
*{{citation|last= Ahlfors|first= Lars V.|last2= Sario|first2= Leo|title=Riemann surfaces|series=Princeton Mathematical Series|volume= 26|publisher= Princeton University Press|year= 1960}}, Chapter I
*{{citation|last=Maunder|first=C. R. F.|title= Algebraic topology|publisher= Dover Publications|year=1996|isbn= 0486691314}}, Cambridge undergraduate course
*{{cite book| author=Massey, William S.| title=A Basic Course in Algebraic Topology| publisher=Springer-Verlag| year=1991| isbn= 0-387-97430-X}}
*{{cite book| author=Bredon, Glen E.|authorlink = Glen Bredon| title=Topology and Geometry| publisher=Springer-Verlag| year=1993| isbn= 0-387-97926-3}}
*{{citation|last=Jost|first= Jürgen|title=Compact Riemann surfaces: an introduction to contemporary mathematics|edition=3rd|publisher=Springer|year=2006|isbn=3540330658}}, for closed oriented Riemannian manifolds
===Morse theoretic proofs of classification up to diffeomorphism===
*{{citation|first=M.|last=Hirsch|title=Differential topology|year=1994|edition=2nd|publisher=Springer}}
*{{citation|last=Gauld|first= David B.|title= Differential topology: an introduction|series= Monographs and Textbooks in Pure and Applied Mathematics|volume=72| publisher=Marcel Dekker|year= 1982|isbn= 0824717090}}
*{{citation|last=Shastri|first=Anant R. |title=Elements of differential topology|publisher= CRC Press|year=2011|isbn= 9781439831601}}, careful proof aimed at undergraduates
*{{cite book| author= Gramain, André|title=Topology of Surfaces| publisher=BCS Associates| year=1984|isbn = 0-914351-01-X}} [http://www.math.u-psud.fr/~biblio/numerisation/docs/G_GRAMAIN-55/pdf/G_GRAMAIN-55.pdf (Original 1969-70 Orsay course notes in French for "Topologie des Surfaces")]
*{{citation | author=A. Champanerkar|title=Classification of surfaces via Morse Theory|url=http://www.math.csi.cuny.edu/abhijit/papers/classification.pdf | postscript=, an exposition of Gramain's notes|display-authors=etal}}
===Other proofs===
*{{citation|first=Terry |last=Lawson|title=Topology: a geometric approach|publisher=Oxford University Press|isbn=0-19-851597-9|year=2003}}, similar to Morse theoretic proof using sliding of attached handles
*{{citation | title = Conway's ZIP Proof | first1 = George K. | last1 = Francis | first2 = Jeffrey R. | last2 = Weeks | journal = [[American Mathematical Monthly]] | volume = 106 | number = 5 | date = May 1999 | doi = 10.2307/2589143 | url = http://new.math.uiuc.edu/zipproof/zipproof.pdf | postscript = , page discussing the paper: [http://new.math.uiuc.edu/zipproof/ On Conway's ZIP Proof] | deadurl = yes | archiveurl = https://web.archive.org/web/20100612090500/http://new.math.uiuc.edu/zipproof/zipproof.pdf | archivedate = 2010-06-12 | df =  }}
*{{citation|last=Thomassen|first=Carsten|title= The Jordan-Schönflies theorem and the classification of surfaces|journal= Amer. Math. Monthly|volume= 99|year=1992|
pages= 116–13|doi=10.2307/2324180}}, short elementary proof using spanning graphs
*{{citation|first=V.V.|last=Prasolov|title= Elements of combinatorial and differential topology|series= Graduate Studies in Mathematics|volume= 74|publisher= American Mathematical Society|year=2006|isbn= 0821838091}}, contains short account of Thomassen's proof

==External links==
{{wiktionary|surface}}
*[https://web.archive.org/web/20161228032041/http://mathifold.org/chapters/en/compact_surfaces.html Classification of Compact Surfaces] in [https://web.archive.org/web/20160204170745/http://mathifold.org/ Mathifold Project]
*[http://www.maths.ed.ac.uk/~aar/jordan/ The Classification of Surfaces and the Jordan Curve Theorem] in Home page of Andrew Ranicki
*[http://xahlee.org/surface/gallery.html Math Surfaces Gallery, with 60 ~surfaces and Java Applet for live rotation viewing]
*[http://wokos.nethium.pl/surfaces_en.net Math Surfaces Animation, with JavaScript (Canvas HTML) for tens surfaces rotation viewing]
*[http://www.math.ohio-state.edu/~fiedorow/math655/classification.html The Classification of Surfaces] Lecture Notes by Z.Fiedorowicz
*[http://maxwelldemon.com/2009/03/21/surfaces-1-the-ooze-of-the-past/ History and Art of Surfaces and their Mathematical Models]
*[http://www.map.mpim-bonn.mpg.de/2-manifolds 2-manifolds] at the Manifold Atlas

{{Authority control}}

[[Category:Surfaces| ]]
[[Category:Geometric topology]]
[[Category:Differential geometry of surfaces]]
[[Category:Analytic geometry]]</text>
      <sha1>axem4mz9dzqf0kpo8bhmao63fs2izot</sha1>
    </revision>
  </page>
  <page>
    <title>Third derivative</title>
    <ns>0</ns>
    <id>9092737</id>
    <revision>
      <id>861024263</id>
      <parentid>853852180</parentid>
      <timestamp>2018-09-24T17:23:33Z</timestamp>
      <contributor>
        <ip>212.237.134.207</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3577">{{one source|date=July 2013}}
{{Calculus |Differential}}

In [[calculus]], a branch of [[mathematics]], the '''third derivative''' is the rate at which the [[second derivative]], or the rate of change of the rate of change, is changing, used to define aberrancy.&lt;ref&gt;{{cite journal|last=Schot|first=Stephen|title=Aberrancy: Geometry of the Third Derivative|journal=Mathematics Magazine|date=November 1978|volume=51|series=5|pages=259–275|jstor=2690245|doi=10.2307/2690245}}&lt;/ref&gt; The third derivative of a function &lt;math&gt;f(x)=y&lt;/math&gt; can be denoted by

:&lt;math&gt;\frac{d^3y}{dx^3},\quad f'''(x),\quad\text{or }\frac{d^3}{dx^3}[f(x)].&lt;/math&gt;

Other notations can be used, but the above are the most common.

==Mathematical definitions==
Let &lt;math&gt;f(x)=x^4&lt;/math&gt;.  Then &lt;math&gt;f'(x)=4x^3&lt;/math&gt;, and &lt;math&gt;f''(x)=12x^2&lt;/math&gt;. Therefore, the third derivative of ''f''(''x'') is, in this case,

: &lt;math&gt;f'''(x)=24x&lt;/math&gt;

or, using [[Leibniz notation]],

: &lt;math&gt;\frac{d^3}{dx^3}[x^4]=24x&lt;/math&gt;

Now for a more general definition. Let &lt;math&gt;f(x)&lt;/math&gt; be any function of&amp;nbsp;''x''. Then the third derivative of &lt;math&gt;f(x)&lt;/math&gt; is given by the following:

: &lt;math&gt;\frac{d^3}{dx^3}[f(x)]=\frac{d}{dx}[f''(x)]&lt;/math&gt;

The third derivative is the rate at which the [[second derivative]] (''&lt;nowiki&gt;f''(x)&lt;/nowiki&gt;'') is changing.

==Applications in geometry==
In [[differential geometry]], the [[torsion of a curve]] — a fundamental property of curves in three dimensions — is computed using third derivatives of coordinate functions (or the position vector) describing the curve.&lt;ref&gt;{{cite book |title = Differential Geometry of Curves and Surfaces|first = Manfredo|last = do Carmo|authorlink=Manfredo do Carmo | isbn = 0-13-212589-7 | year = 1976}}&lt;/ref&gt;

==Applications in physics==
{{Main article|Jerk (physics)}}

In [[physics]], particularly [[kinematics]], '''jerk''' is defined as the third derivative of the [[position function]] of an object. It is, essentially, the rate at which [[acceleration]] changes. In mathematical terms:

: &lt;math&gt;\bold{j}(t)=\frac{d^3\bold{r}}{dt^3}&lt;/math&gt;

where '''j'''(''t'') is the jerk function with respect to time, and '''r'''(''t'') is the position function of the object with respect to time.

==Economic example==
U.S. President [[Nixon|Richard Nixon]], when campaigning for a second term in office announced that the rate of increase of inflation was decreasing, which has been noted as "the first time a sitting president used the third derivative to advance his case for reelection."&lt;ref&gt;{{cite journal|last=Rossi|first=Hugo|title=Mathematics Is an Edifice, Not a Toolbox|journal=Notices of the American Mathematical Society| date=October 1996 |volume=43|issue=10|pages=1108|url=http://www.ams.org/notices/199610/page2.pdf|accessdate=13 November 2012}}&lt;/ref&gt;  Since [[inflation]] is itself a derivative—the rate at which the purchasing power of money decreases—then the rate of increase of inflation is the derivative of inflation, or the second derivative of the function of purchasing power of money with respect to time. Stating that a function is decreasing is equivalent to stating that its derivative is negative, so Nixon's statement is that the second derivative of inflation—or the third derivative of purchasing power—is negative.

Nixon's statement allowed for the rate of inflation to increase, however, so his statement was not as indicative of stable prices as it sounds.

==See also==
*[[Derivative (mathematics)]]
*[[Second derivative]]

==References==
{{reflist}}

[[Category:Differential calculus]]</text>
      <sha1>af1hxglgkr49ckuumkrug8pjg3o698v</sha1>
    </revision>
  </page>
  <page>
    <title>Vertex (graph theory)</title>
    <ns>0</ns>
    <id>638899</id>
    <revision>
      <id>806809670</id>
      <parentid>806809636</parentid>
      <timestamp>2017-10-24T08:32:17Z</timestamp>
      <contributor>
        <ip>2001:620:417:20F1:1CDF:8B67:C7C1:217C</ip>
      </contributor>
      <comment>The example has 10 edges not 9.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6312">{{Other uses|Vertex (disambiguation)}}
{{more footnotes|date=February 2014}}

[[Image:6n-graf.svg|thumb|A graph with 6 vertices and 7 edges where the vertex number 6 on the far-left is a leaf vertex or a pendant vertex]]
In [[mathematics]], and more specifically in [[graph theory]], a '''vertex''' (plural '''vertices''') or '''node''' is the fundamental unit of which graphs are formed: an [[undirected graph]] consists of a set of vertices and a set of [[Edge (graph theory)|edges]] (unordered pairs of vertices), while a [[directed graph]] consists of a set of vertices and a set of arcs (ordered pairs of vertices).  In a diagram of a graph, a vertex is usually represented by a circle with a label, and an edge is represented by a line or arrow extending from one vertex to another.

From the point of view of graph theory, vertices are treated as featureless and indivisible objects, although they may have additional structure depending on the application from which the graph arises; for instance, a [[semantic network]] is a graph in which the vertices represent concepts or classes of objects.

The two vertices forming an edge are said to be the endpoints of this edge, and the edge is said to be incident to the vertices. A vertex ''w'' is said to be adjacent to another vertex ''v'' if the graph contains an edge (''v'',''w''). The [[neighborhood (graph theory)|neighborhood]] of a vertex ''v'' is an [[induced subgraph]] of the graph, formed by all vertices adjacent to&amp;nbsp;''v''.

==Types of vertices==
[[File:Small Network.png|alt=A small example network with 8 vertices and 10 edges.|thumb|Example network with 8 vertices (of which one is isolated) and 10 edges.]]
The [[degree (graph theory)|degree]] of a vertex, denoted 𝛿(v) in a graph is the number of edges incident to it. An '''isolated vertex''' is a vertex with degree zero; that is, a vertex that is not an endpoint of any edge (the example image illustrates one isolated vertex).&lt;ref&gt;[[:File:Small Network.png]]; example image of a network with 8 vertices and 10 edges&lt;/ref&gt; A '''leaf vertex''' (also '''pendant vertex''') is a vertex with degree one. In a directed graph, one can distinguish the outdegree (number of outgoing edges), denoted 𝛿&lt;sup&gt; +&lt;/sup&gt;(v), from the indegree (number of incoming edges), denoted 𝛿&lt;sup&gt;−&lt;/sup&gt;(v); a '''source vertex''' is a vertex with indegree zero, while a '''sink vertex''' is a vertex with outdegree zero. A '''simplicial vertex''' is one whose neighbors form a [[clique (graph theory)|clique]]: every two neighbors are adjacent. A [[universal vertex]] is a vertex that is adjacent to every other vertex in the graph.

A [[cut vertex]] is a vertex the removal of which would disconnect the remaining graph; a [[vertex separator]] is a collection of vertices the removal of which would disconnect the remaining graph into small pieces. A [[k-vertex-connected graph]] is a graph in which removing fewer than ''k'' vertices always leaves the remaining graph connected. An [[Independent set (graph theory)|independent set]] is a set of vertices no two of which are adjacent, and a [[vertex cover]] is a set of vertices that includes at least one endpoint of each edge in the graph. The [[vertex space]] of a graph is a vector space having a set of basis vectors corresponding with the graph's vertices.

A graph is [[vertex-transitive graph|vertex-transitive]] if it has symmetries that map any vertex to any other vertex. In the context of [[graph enumeration]] and [[graph isomorphism]] it is important to distinguish between '''labeled vertices''' and '''unlabeled vertices'''. A labeled vertex is a vertex that is associated with extra information that enables it to be distinguished from other labeled vertices; two graphs can be considered isomorphic only if the correspondence between their vertices pairs up vertices with equal labels. An unlabeled vertex is one that can be substituted for any other vertex based only on its [[Adjacency (graph theory)|adjacencies]] in the graph and not based on any additional information.

Vertices in graphs are analogous to, but not the same as, [[vertex (geometry)|vertices of polyhedra]]: the [[skeleton (topology)|skeleton]] of a polyhedron forms a graph, the vertices of which are the vertices of the polyhedron, but polyhedron vertices have additional structure (their geometric location) that is not assumed to be present in graph theory. The [[vertex figure]] of a vertex in a polyhedron is analogous to the neighborhood of a vertex in a graph.

==See also==

* [[Node (computer science)]]
* [[Graph theory]]
* [[Glossary of graph theory]]

==References==
{{reflist|2}}

* {{cite journal
  | last = Gallo
  | first = Giorgio
  | last2 = Pallotino
  | first2 = Stefano
  | title = Shortest path algorithms
  | journal = Annals of Operations Research
  | volume = 13
  | issue = 1
  | pages = 1–79 &lt;!-- the inline reference refers to page 4 --&gt;
  | year = 1988
  | doi = 10.1007/BF02288320
  | ref=harv
  }}
* [[Claude Berge|Berge, Claude]], ''Théorie des graphes et ses applications''. Collection Universitaire de Mathématiques, II Dunod, Paris 1958, viii+277 pp. (English edition, Wiley 1961; Methuen &amp; Co, New York 1962; Russian, Moscow 1961; Spanish, Mexico 1962; Roumanian, Bucharest 1969; Chinese, Shanghai 1963; Second printing of the 1962 first English edition. Dover, New York 2001)
* {{Cite book | last=Chartrand | first=Gary | authorlink=Gary Chartrand | title=Introductory graph theory | date=1985 | publisher=Dover | location=New York | isbn=0-486-24775-9 | pages=}}
* {{Cite book |author1=Biggs, Norman |author2=Lloyd, E. H. |author3=Wilson, Robin J. | title=Graph theory, 1736-1936 | date=1986 | publisher=Clarendon Press | location=Oxford [Oxfordshire] | isbn=0-19-853916-9 | pages=}}
* {{Cite book | last=Harary | first=Frank | authorlink=Frank Harary | title=Graph theory | date=1969 | publisher=Addison-Wesley Publishing | location=Reading, Mass. | isbn=0-201-41033-8 | pages=}}
* {{Cite book |author1=Harary, Frank |author2=Palmer, Edgar M. | title=Graphical enumeration | date=1973 | publisher=New York, Academic Press | location= | isbn=0-12-324245-2 | pages=}}

==External links==
*{{mathworld | title = Graph Vertex | urlname = GraphVertex}}

{{DEFAULTSORT:Vertex (Graph Theory)}}
[[Category:Graph theory]]</text>
      <sha1>96woksixzet5sejpbi64ukop0sgya6i</sha1>
    </revision>
  </page>
  <page>
    <title>Yael Tauman Kalai</title>
    <ns>0</ns>
    <id>58126837</id>
    <revision>
      <id>862900944</id>
      <parentid>861750205</parentid>
      <timestamp>2018-10-07T12:39:09Z</timestamp>
      <contributor>
        <username>CommonsDelinker</username>
        <id>2304267</id>
      </contributor>
      <comment>Removing [[:c:File:Yael_Tauman_Kalai_portrait-public.jpg|Yael_Tauman_Kalai_portrait-public.jpg]], it has been deleted from Commons by [[:c:User:4nn1l2|4nn1l2]] because: [[:c:COM:OTRS|No permission]] since 29 September 2018.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5121">{{Infobox scientist
| name             = Yael Tauman Kalai
| image       =
| birth_place      = [[Tel Aviv]], [[Israel]]
| death_date       =
| death_place      =
| alma_mater       = [[Massachusetts Institute of Technology]]
| workplaces      = [[Massachusetts Institute of Technology]], [[Microsoft Research]]
| fields            = [[Cryptography]], [[Computer Science]]
| doctoral_advisor       = [[Shafi Goldwasser]]
| known_for    = [[ring signature|Ring Signatures]], the insecurity of the [[Fiat–Shamir heuristic]], [[Verifiable computing|delegating computation]]
}}


'''Yael Tauman Kalai''' is a [[cryptography|cryptographer]] and [[theoretical computer science|theoretical computer scientist]] who works as a Principal Researcher at [[Microsoft Research New England]]{{r|mrne|simons}} and as an Adjunct Professor at MIT in the Computer Science and Artificial Intelligence Lab.{{r|mit}}

==Education and career==
Kalai graduated from the [[Hebrew University of Jerusalem]] in 1997. She worked with [[Adi Shamir]] at the [[Weizmann Institute of Science]], earning a master's degree there in 2001, and then moved to the [[Massachusetts Institute of Technology]], where she completed her PhD in 2006 with [[Shafi Goldwasser]] as her doctoral advisor. She did postdoctoral study at Microsoft Research and the Weizmann Institute before becoming a faculty member at the Georgia Institute of Technology. She took a permanent position at Microsoft Research in 2008.{{r|mrne|simons}}

==Contributions==
Kalai is known for co-inventing [[ring signature]]s, which has become a key component of numerous systems such as [[Cryptonote]] and [[Monero (cryptocurrency)]]. Subsequently, together with her advisor [[Shafi Goldwasser]], she demonstrated an insecurity in the widely used [[Fiat–Shamir heuristic]].  Her work on [[Verifiable computing|delegating computation]] has applications to cloud computing.{{r|cloud}}

==Recognition==
Kalai was an invited speaker on mathematical aspects of computer science at the 2018 [[International Congress of Mathematicians]].{{r|icm}}

Her master's thesis introducing [[ring signature]]s won an outstanding master's thesis award{{r|simons}} and MIT PhD dissertation was awarded the George M. Sprowls Award for Outstanding PhD Thesis in Computer Science.{{r|simons}}{{r|sprowls}}

She was co-chair of the [[Theory of Cryptography Conference]] in 2017.{{r|tcc}}
	 	
==Personal==
	
Kalai is the daughter of game theorist [[Yair Tauman]]. Her husband, Adam Tauman Kalai, also works at Microsoft Research.{{r|bliss}}

==References==
 	
{{reflist|refs=
 	
&lt;ref name=cloud&gt;{{citation|url=https://phys.org/news/2013-06-cloud-algorithm-major-problem-homomorphic.html|title=Securing the cloud: New algorithm solves major problem with homomorphic encryption|accessdate=2018-09-11|first=Larry|last=Hardesty|date=June 10, 2013|work=MIT News|publisher=Massachusetts Institute of Technology|via=[[Phys.org]]}}&lt;/ref&gt;

&lt;ref name=tcc&gt;{{citation|url=https://www.springer.com/us/book/9783319705026|accessdate=2018-09-11|title=Theory of Cryptography: Proceedings of the 15th International Conference, TCC 2017, Baltimore, MD, USA, November 12-15, 2017|publisher=Springer}}&lt;/ref&gt;

&lt;ref name=bliss&gt;{{citation|url=https://www.microsoft.com/en-us/research/blog/new-england-researcher-finds-bliss/|title=New England Researcher Finds Her Bliss|date=May 14, 2009|first=Rob|last=Knies|publisher=Microsoft}}&lt;/ref&gt;
	
&lt;ref name=mit&gt;{{citation|url=https://www.csail.mit.edu/person/yael-kalai|title=Yael Kalai, MIT CSAIL|date=September 10, 2018|publisher=Massachusetts Institute of Technology}}&lt;/ref&gt;

&lt;ref name=sprowls&gt;{{citation|url=https://eecs-newsletter.mit.edu/articles/2007-fall/awards-and-honors-2007/|title=Awards and Honors 2007|work=EECS Newsletter|date=Fall 2007|accessdate=Sep 10, 2018|publisher=Massachusetts Institute of Technology Department of Electrical Engineering and Computer Science}}&lt;/ref&gt;

&lt;ref name=icm&gt;{{citation|url=http://www.icm2018.org/portal/en/invited-section-lectures-speakers|title=Invited section lectures|work=ICM 2018|accessdate=2018-08-08}}&lt;/ref&gt;

&lt;ref name=mrne&gt;{{citation|url=https://www.microsoft.com/en-us/research/people/yael/|title=Yael Tauman Kalai, Principal Researcher|publisher=Microsoft|accessdate=2018-09-11}}&lt;/ref&gt;

&lt;ref name=simons&gt;{{citation|url=https://simons.berkeley.edu/people/yael-kalai|title=Yael Kalai, Researcher, Microsoft Research New England|publisher=Simons Institute for the Theory of Computing}}&lt;/ref&gt;

}}

==External links==
*{{Google Scholar id|cPDxYXMAAAAJ}}

{{Authority control}}
{{DEFAULTSORT:Kalai, Yael Tauman}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:American cryptographers]]
[[Category:American computer scientists]]
[[Category:Israeli cryptographers]]
[[Category:Israeli computer scientists]]
[[Category:Women computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Hebrew University of Jerusalem alumni]]
[[Category:Weizmann Institute of Science alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Georgia Institute of Technology faculty]]</text>
      <sha1>1be848acpi4l11y10atmz9unf8pi7ek</sha1>
    </revision>
  </page>
  <page>
    <title>Yang–Mills theory</title>
    <ns>0</ns>
    <id>672202</id>
    <revision>
      <id>870043555</id>
      <parentid>867161334</parentid>
      <timestamp>2018-11-22T00:46:00Z</timestamp>
      <contributor>
        <ip>2601:541:4500:1760:78EE:6D29:3613:9E67</ip>
      </contributor>
      <comment>edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20040">{{unsolved|physics|Yang–Mills theory in the non-[[Perturbation theory (quantum mechanics)|perturbative]] regime:
The equations of Yang–Mills remain unsolved at [[energy scale]]s relevant for describing [[Atomic nucleus|atomic nuclei]]. How does Yang–Mills theory give rise to the physics of [[Atomic nucleus|nuclei]] and [[hadron|nuclear constituents]]?}}
{{Quantum field theory}}
'''Yang–Mills theory''' is a [[gauge theory]] based on the [[Special unitary group|SU(''N'') group]], or more generally any [[Compact Lie algebra|compact]], [[reductive Lie algebra]]. Yang–Mills theory seeks to describe the behavior of elementary particles using these [[non-abelian group|non-abelian Lie groups]] and is at the core of the unification of the [[electromagnetic force]] and [[weak force]]s (i.e. U(1) × SU(2)) as well as [[quantum chromodynamics]], the theory of the [[strong force]] (based on SU(3)). Thus it forms the basis of our understanding of the [[Standard Model]] of particle physics.

== History and theoretical description ==
In a private correspondence, [[Wolfgang Pauli]] formulated in 1953 a six-dimensional theory of [[Einstein's field equations]] of [[general relativity]], extending the five-dimensional theory of [[Kaluza–Klein theory|Kaluza, Klein]], [[Vladimir Fock|Fock]] and others to a higher-dimensional internal space.&lt;ref name = Straumann&gt;{{cite arXiv |last=Straumann |first=N |year=2000 |title=On Pauli's invention of non-abelian Kaluza-Klein Theory in 1953 |eprint=gr-qc/0012054}}&lt;/ref&gt; However, there is no evidence that Pauli developed the [[Lagrangian (field theory)|Lagrangian]] of a [[gauge field]] or the quantization of it. Because Pauli found that his theory "leads to some rather unphysical shadow particles", he refrained from publishing his results formally.&lt;ref name=Straumann /&gt; Although Pauli did not publish his six-dimensional theory, he gave two talks about it in Zürich.&lt;ref&gt;See Abraham Pais' account of this period as well as L. Susskind's "Superstrings, Physics World on the first non-abelian gauge theory" where Susskind wrote that Yang–Mills was "rediscovered" only because Pauli had chosen not to publish.&lt;/ref&gt; Recent research shows that an extended Kaluza–Klein theory is in general not equivalent to Yang–Mills theory, as the former contains additional terms.&lt;ref name=Reifler&gt;{{cite arXiv |last=Reifler|first=N |year=2007 |title=Conditions for exact equivalence of Kaluza-Klein and Yang–Mills theories |eprint=0707.3790}}&lt;/ref&gt;

In early 1954, [[Chen Ning Yang]] and [[Robert Mills (physicist)|Robert Mills]]&lt;ref name=YM&gt;{{cite journal |authorlink1=Chen-Ning Yang |first1=C. N. |last1=Yang |authorlink2=Robert Mills (physicist) |first2=R. |last2=Mills |title=Conservation of Isotopic Spin and Isotopic Gauge Invariance |journal=[[Physical Review]] |volume=96 |issue=1 |pages=191–195 |year=1954 |doi=10.1103/PhysRev.96.191|bibcode = 1954PhRv...96..191Y }}&lt;/ref&gt; extended the concept of [[gauge theory]] for [[abelian group]]s, e.g. [[quantum electrodynamics]], to [[nonabelian group]]s to provide an explanation for strong interactions. The idea by Yang–Mills was criticized by Pauli,&lt;ref&gt;[http://universe-review.ca/R15-21-YangPauli.htm An Anecdote by C. N. Yang]&lt;/ref&gt; as the [[quantum|quanta]] of the Yang–Mills field must be massless in order to maintain [[gauge invariance]]. The idea was set aside until 1960, when the concept of particles acquiring mass through [[symmetry breaking]] in massless theories was put forward, initially by [[Jeffrey Goldstone]], [[Yoichiro Nambu]], and [[Giovanni Jona-Lasinio]].

This prompted a significant restart of Yang–Mills theory studies that proved successful in the formulation of both [[electroweak interaction|electroweak unification]] and [[quantum chromodynamics]] (QCD). The electroweak interaction is described by SU(2) × U(1) group while QCD is an [[SU(3)]] Yang–Mills theory. The electroweak theory is obtained by combining [[SU(2)]] with [[U(1)]], where quantum electrodynamics (QED) is described by a U(1) group, and is replaced in the unified electroweak theory by a U(1) group representing a weak hypercharge rather than electric charge. The massless bosons from the SU(2) × U(1) theory mix after [[spontaneous symmetry breaking]] to produce the 3 massive weak bosons, and the [[photon]] field. The [[Standard Model]] combines the [[strong interaction]] with the unified electroweak interaction (unifying the [[weak interaction|weak]] and [[electromagnetic interaction]]) through the symmetry group SU(2) × U(1) × SU(3). In the current epoch the strong interaction is not unified with the electroweak interaction, but from the observed [[Running coupling|running of the coupling]] constants it is believed {{citation needed|reason=By whom?|date=January 2016}} they all converge to a single value at very high energies.

[[Phenomenology (particle physics)|Phenomenology]] at lower energies in quantum chromodynamics is not completely understood due to the difficulties of managing such a theory with a strong coupling. This may be the reason why [[color confinement|confinement]] has not been theoretically proven, though it is a consistent experimental observation. Proof that QCD confines at low energy is a mathematical problem of great relevance, and an award has been proposed by the [[Clay Mathematics Institute]] for whoever is also able to show that the Yang–Mills theory has a [[Yang–Mills existence and mass gap|mass gap and its existence]].

== Mathematical overview ==
Yang–Mills theories are a special example of [[gauge theory]] with a [[non-abelian group|non-abelian]] symmetry group given by the [[Lagrangian (field theory)|Lagrangian]]

:&lt;math&gt;\mathcal{L}_\mathrm{gf} = -\frac{1}{2}\operatorname{Tr}(F^2)=- \frac{1}{4}F^{a\mu \nu} F_{\mu \nu}^a &lt;/math&gt;

with the generators of the [[Lie algebra]], indexed by {{mvar|a}}, corresponding to the ''F''-quantities (the [[curvature]] or field-strength form) satisfying

:&lt;math&gt;\operatorname{Tr}(T^aT^b)=\frac{1}{2}\delta^{ab},\quad [T^a,T^b]=if^{abc}T^c,&lt;/math&gt;

where the {{math|''f''&lt;sup&gt;''abc''&lt;/sup&gt;}} are [[structure constant]]s of the Lie algebra, and the [[covariant derivative]] defined as

:&lt;math&gt;D_\mu=I\partial_\mu-igT^aA^a_\mu &lt;/math&gt;

where {{mvar|I}} is the [[identity matrix]] (matching the size of the generators), &lt;math&gt;A^a_\mu&lt;/math&gt; is the [[Four-vector|vector]] potential, and ''g'' is the [[coupling constant]]. In four dimensions, the coupling constant ''g'' is a pure number and for a SU(''N'') group one has &lt;math&gt;a,b,c=1\ldots N^2-1.&lt;/math&gt;

The relation

:&lt;math&gt;F_{\mu \nu}^a = \partial_\mu A_\nu^a-\partial_\nu A_\mu^a+gf^{abc}A_\mu^bA_\nu^c &lt;/math&gt;

can be derived by the [[commutator]]

:&lt;math&gt;[D_\mu, D_\nu] = -igT^aF_{\mu\nu}^a.&lt;/math&gt;

The field has the property of being self-interacting and equations of motion that one obtains are said to be semilinear, as nonlinearities are both with and without derivatives. This means that one can manage this theory only by [[perturbation theory]], with small nonlinearities.

Note that the transition between "upper" ("contravariant") and "lower" ("covariant") vector or tensor components is trivial for ''a'' indices (e.g. &lt;math&gt;f^{abc}=f_{abc}&lt;/math&gt;), whereas for μ and ν it is nontrivial, corresponding e.g. to the usual Lorentz signature, &lt;math&gt;\eta_{\mu \nu }={\rm diag}(+---)&lt;/math&gt;.

From the given Lagrangian one can derive the equations of motion given by

:&lt;math&gt;\partial^\mu F_{\mu\nu}^a+gf^{abc}A^{\mu b}F_{\mu\nu}^c=0.&lt;/math&gt;

Putting &lt;math&gt;F_{\mu\nu}=T^aF^a_{\mu\nu}&lt;/math&gt;, these can be rewritten as

:&lt;math&gt;(D^\mu F_{\mu\nu})^a=0.&lt;/math&gt;

A [[Bianchi identity]] holds

:&lt;math&gt;(D_\mu F_{\nu \kappa})^a+(D_\kappa F_{\mu \nu})^a+(D_\nu F_{\kappa \mu})^a=0&lt;/math&gt;

which is equivalent to the [[Jacobi identity]]

:&lt;math&gt;[D_{\mu}, [D_{\nu},D_{\kappa}]]+[D_{\kappa},[D_{\mu},D_{\nu}]]+[D_{\nu},[D_{\kappa},D_{\mu}]]=0&lt;/math&gt;

since &lt;math&gt;[D_{\mu},F^a_{\nu\kappa}]=D_{\mu}F^a_{\nu\kappa}&lt;/math&gt;. Define the [[Hodge star operator|dual]] strength tensor
&lt;math&gt;\tilde{F}^{\mu\nu}=\frac{1}{2}\varepsilon^{\mu\nu\rho\sigma}F_{\rho\sigma}&lt;/math&gt;, then the Bianchi identity can be rewritten as

:&lt;math&gt;D_{\mu}\tilde{F}^{\mu\nu}=0.&lt;/math&gt;

A source &lt;math&gt;J_\mu^a&lt;/math&gt; enters into the equations of motion as

:&lt;math&gt;\partial^\mu F_{\mu\nu}^a+gf^{abc}A^{b\mu}F_{\mu\nu}^c=-J_\nu^a.&lt;/math&gt;

Note that the currents must properly change under gauge group transformations.

We give here some comments about the physical dimensions of the coupling. In ''D'' dimensions, the field scales as &lt;math&gt;[A]=[L^\frac{2-D}{2}]&lt;/math&gt;{{Citation needed|date=November 2017}} and so the coupling must scale as &lt;math&gt;[g^2]=[L^{D-4}]&lt;/math&gt;. This implies that Yang–Mills theory is not [[renormalization|renormalizable]] for dimensions greater than four. Furthermore, for ''D'' = 4, the coupling is dimensionless and both the field and the square of the coupling have the same dimensions of the field and the coupling of a massless quartic [[scalar field theory]]. So, these theories share the [[scale invariance]] at the classical level.

== Quantization ==
A method of quantizing the Yang–Mills theory is by functional methods, i.e. [[Path integral formulation|path integrals]]. One introduces a generating functional for ''n''-point functions as

:&lt;math&gt;Z[j]=\int [dA]\exp\left[- \frac{i}{2} \int d^4x\operatorname{Tr}(F^{\mu \nu} F_{\mu \nu})+i\int d^4x \, j^a_\mu(x)A^{a\mu}(x)\right] ,&lt;/math&gt;

but this integral has no meaning as it is because the potential vector can be arbitrarily chosen due to the [[gauge freedom]]. This problem was already known for [[quantum electrodynamics]] but here becomes more severe due to [[non-abelian group|non-abelian]] properties of the gauge group. A way out has been given by [[Ludvig Faddeev]] and [[Victor Popov]] with the introduction of a '''ghost field''' (see [[Faddeev–Popov ghost]]) that has the property of being unphysical since, although it agrees with [[Fermi–Dirac statistics]], it is a complex scalar field, which violates the [[spin–statistics theorem]]. So, we can write the generating functional as

:&lt;math&gt;\begin{align}
Z[j,\bar\varepsilon,\varepsilon] &amp; = \int [dA] [d\bar c] [dc] \exp\left\{iS_F[\partial A,A]+iS_{gf}[\partial A]+iS_g[\partial c,\partial\bar c,c,\bar c,A]\right\} \\
&amp;\exp\left\{i\int d^4x j^a_\mu(x)A^{a\mu}(x)+i\int d^4x[\bar c^a(x)\varepsilon^a(x)+\bar\varepsilon^a(x) c^a(x)]\right\}
\end{align}&lt;/math&gt;

being

:&lt;math&gt;S_F=- \frac{1}{2} \int  \operatorname{d}\!^4 x \operatorname{Tr}(F^{\mu \nu} F_{\mu \nu})&lt;/math&gt;

for the field,

:&lt;math&gt;S_{gf}=-\frac{1}{2\xi} \int  \operatorname{d}\!^4 x (\partial\cdot A)^2&lt;/math&gt;

for the gauge fixing and

:&lt;math&gt;S_g=-\int  \operatorname{d}\!^4 x  (\bar c^a\partial_\mu\partial^\mu c^a+g\bar c^a f^{abc}\partial_\mu A^{b\mu}c^c)&lt;/math&gt;

for the ghost. This is the expression commonly used to derive Feynman's rules (see [[Feynman diagram]]). Here we have ''c&lt;sup&gt;a&lt;/sup&gt;'' for the ghost field while ξ fixes the gauge's choice for the quantization. Feynman's rules obtained from this functional are the following

&lt;center&gt;[[File:FeynRulesEN.jpg|488px]]&lt;/center&gt;

These rules for Feynman diagrams can be obtained when the generating functional given above is rewritten as

:&lt;math&gt;\begin{align}
Z[j,\bar\varepsilon,\varepsilon] &amp;= \exp\left(-ig\int d^4x \, \frac{\delta}{i\delta\bar\varepsilon^a(x)} f^{abc}\partial_\mu\frac{i\delta}{\delta j^b_\mu(x)} \frac{i\delta}{\delta\varepsilon^c(x)}\right)\\
&amp; \qquad \times \exp\left(-ig\int d^4xf^{abc}\partial_\mu\frac{i\delta}{\delta j^a_\nu(x)}\frac{i\delta}{\delta j^b_\mu(x)}\frac{i\delta}{\delta j^{c\nu}(x)}\right)\\
&amp; \qquad \qquad \times \exp\left(-i\frac{g^2}{4}\int d^4xf^{abc}f^{ars}\frac{i\delta}{\delta j^b_\mu(x)} \frac{i\delta}{\delta j^c_\nu(x)} \frac{i\delta}{\delta j^{r\mu}(x)} \frac{i\delta}{\delta j^{s\nu}(x)}\right) \\
&amp; \qquad \qquad \qquad \times Z_0[j,\bar\varepsilon,\varepsilon]
\end{align}&lt;/math&gt;

with

:&lt;math&gt;Z_0[j,\bar\varepsilon,\varepsilon]=\exp\left(-\int d^4xd^4y\bar\varepsilon^a(x)C^{ab}(x-y)\varepsilon^b(y)\right)\exp\left(\tfrac{1}{2}\int d^4xd^4yj^a_\mu(x)D^{ab\mu\nu}(x-y)j^b_\nu(y)\right)&lt;/math&gt;

being the generating functional of the free theory. Expanding in ''g'' and computing the [[functional derivative]]s, we are able to obtain all the ''n''-point functions with perturbation theory. Using [[LSZ reduction formula]] we get from the ''n''-point functions the corresponding process amplitudes, [[Cross section (physics)|cross sections]] and [[decay rate]]s. The theory is [[renormalization|renormalizable]] and corrections are finite at any order of perturbation theory.

For quantum electrodynamics the ghost field decouples because the gauge group is abelian. This can be seen from the coupling between the gauge field and the ghost field that is &lt;math&gt;\bar c^a f^{abc}\partial_\mu A^{b\mu}c^c&lt;/math&gt;. For the abelian case, all the structure constants &lt;math&gt;f^{abc}&lt;/math&gt; are zero and so there is no coupling. In the non-abelian case, the ghost field appears as a useful way to rewrite the quantum field theory without physical consequences on the observables of the theory such as cross sections or decay rates.

One of the most important results obtained for Yang–Mills theory is [[asymptotic freedom]]. This result can be obtained by assuming that the [[coupling constant]] ''g'' is small (so small nonlinearities), as for high energies, and applying [[perturbation theory]]. The relevance of this result is due to the fact that a Yang–Mills theory that describes strong interaction and asymptotic freedom permits proper treatment of experimental results coming from [[deep inelastic scattering]].

To obtain the behavior of the Yang–Mills theory at high energies, and so to prove asymptotic freedom, one applies perturbation theory assuming a small coupling. This is verified [[a posteriori]] in the [[Ultraviolet divergence|ultraviolet limit]]. In the opposite limit, the infrared limit, the situation is the opposite, as the coupling is too large for perturbation theory to be reliable. Most of the difficulties that research meets is just managing the theory at low energies. That is the interesting case, being inherent to the description of hadronic matter and, more generally, to all the observed bound states of gluons and quarks and their confinement (see [[hadrons]]). The most used method to study the theory in this limit is to try to solve it on computers (see [[lattice gauge theory]]). In this case, large computational resources are needed to be sure the correct limit of infinite volume (smaller lattice spacing) is obtained. This is the limit the results must be compared with. Smaller spacing and larger coupling are not independent of each other, and larger computational resources are needed for each. As of today, the situation appears somewhat satisfactory for the hadronic spectrum and the computation of the gluon and ghost propagators, but the [[glueball]] and [[exotic meson|hybrids]] spectra are yet a questioned matter in view of the experimental observation of such exotic states. Indeed, the σ resonance&lt;ref name=ccl&gt;{{cite journal |first=I. |last=Caprini |first2=G. |last2=Colangelo |first3=H. |last3=Leutwyler |year=2006 |title=Mass and width of the lowest resonance in QCD |journal=[[Physical Review Letters]] |volume=96 |issue=13 |page=132001 |doi=10.1103/PhysRevLett.96.132001 |bibcode=2006PhRvL..96m2001C |arxiv = hep-ph/0512364 |pmid=16711979}}&lt;/ref&gt;&lt;ref name=ygp&gt;{{cite journal |first=F. J. |last=Yndurain |first2=R. |last2=Garcia-Martin |first3=J. R. |last3=Pelaez |title=Experimental status of the ππ isoscalar S wave at low energy: ''f''&lt;sub&gt;0&lt;/sub&gt;(600) pole and scattering length |journal=[[Physical Review D]] |volume=76 |issue=7 |page=074034 |year=2007 |doi=10.1103/PhysRevD.76.074034|arxiv = hep-ph/0701025 |bibcode = 2007PhRvD..76g4034G }}&lt;/ref&gt; is not seen in any of such lattice computations and contrasting interpretations have been put forward. This is a hotly debated issue.

== Open problems ==
Yang–Mills theories met with general acceptance in the physics community after [[Gerard 't Hooft]], in 1972, worked out their [[renormalization]], relying on a formulation of the problem worked out by his advisor [[Martinus Veltman]]. (Their work&lt;ref&gt;{{Cite journal | last1 = 't Hooft | first1 = G. | last2 = Veltman | first2 = M. | doi = 10.1016/0550-3213(72)90279-9 | title = Regularization and renormalization of gauge fields | journal = Nuclear Physics B | volume = 44 | pages = 189 | year = 1972 | pmid =  | pmc = |bibcode = 1972NuPhB..44..189T }}&lt;/ref&gt; was recognized by the 1999 [[Nobel prize]] in physics.) Renormalizability is obtained even if the gauge bosons described by this theory are massive, as in the electroweak theory, provided the mass is only an "acquired" one, generated by the [[Higgs mechanism]].

The mathematics of the Yang–Mills theory is a very active field of research, yielding e.g. invariants of differentiable structures on four-dimensional manifolds via work of [[Simon Donaldson]]. Furthermore, the field of Yang–Mills theories was included in the [[Clay Mathematics Institute]]'s list  of "[[Millennium Prize Problems]]". Here the prize-problem consists, especially, in a proof of the conjecture that the lowest excitations of a pure Yang–Mills theory (i.e. without matter fields) have a finite  mass-gap with regard to the vacuum state. Another open problem, connected with this conjecture, is a proof of the [[Color confinement|confinement]] property in the presence of additional Fermion particles.

In physics the survey of Yang–Mills theories does not usually start from perturbation analysis or analytical methods, but more recently from systematic application of numerical methods to [[lattice gauge theory|lattice gauge theories]].

== See also ==
{{div col|colwidth=30em}}

* [[Aharonov–Bohm effect]]
* [[Coulomb gauge]]
* [[Electroweak theory]]
* [[Gauge covariant derivative]]
* [[Kaluza–Klein theory]]
* [[Lattice gauge theory]]
* [[Lorenz gauge]]
* [[N = 4 supersymmetric Yang–Mills theory|''N'' = 4 supersymmetric Yang–Mills theory]]
* [[Propagator]]
* [[Quantum chromodynamics]]
* [[Quantum gauge theory]]
* [[Standard model (basic details)|Field theoretical formulation of the standard model]]
* [[Symmetry in physics]]
* [[Weyl gauge]]
* [[Yang–Mills existence and mass gap]]
* [[Yang–Mills–Higgs equations]]

{{div col end}}

== References ==
{{reflist|2}}

== Further reading ==
;Books
* {{cite book |last=Frampton |first=P. |authorlink=Paul Frampton |title=Gauge Field Theories |edition=3rd |publisher=[[Wiley-VCH]] |year=2008 |isbn=978-3-527-40835-1}}
* {{cite book |first1=T.-P. |last1=Cheng |first2=L.-F. |last2=Li |title=Gauge Theory of Elementary Particle Physics |publisher=[[Oxford University Press]] |year=1983 |isbn=0-19-851961-3 }}
* {{cite book |last='t Hooft |first=Gerardus |authorlink=Gerardus 't Hooft|title=50 Years of Yang–Mills theory |publisher=[[World Scientific]] |year=2005 |isbn=981-238-934-2}}

;Articles
* {{cite arXiv |year=1999 |eprint=math-ph/9902027 |title=Preparation for Gauge Theory |last1=Svetlichny |first1=George}}
* {{cite web |last=Gross |first=D. |authorlink=David Gross |year=1992 |url=https://scholar.google.se/scholar_url?url=http://www.colin-baxter.com/academic/bib/downloads/955.pdf&amp;hl=sv&amp;sa=X&amp;scisig=AAGBfm0MBLXQuVbYC78zgUqhhplqMGAWfw&amp;nossl=1&amp;oi=scholarr&amp;ei=-DRJVafYG8KUsgHOuIDYBQ&amp;ved=0CB8QgAMoADAA |title=Gauge theory – Past, Present and Future|accessdate=2015-05-05}}

== External links ==
{{wikiquote}}
* {{springer|title=Yang-Mills field|id=p/y099030}}
* [https://dispersivewiki.org/DispersiveWiki/index.php?title=Yang-Mills_equations Yang–Mills theory on DispersiveWiki]
* [http://www.claymath.org/ The Clay Mathematics Institute]
* [http://www.claymath.org/prizeproblems The Millennium Prize Problems]

{{Quantum field theories}}

{{DEFAULTSORT:Yang-Mills Theory}}
[[Category:Concepts in physics]]
[[Category:Gauge theories| ]]
[[Category:Symmetry]]</text>
      <sha1>bl3qj1gngfwfnhg9duvdl8vb0qpj4fr</sha1>
    </revision>
  </page>
</mediawiki>
