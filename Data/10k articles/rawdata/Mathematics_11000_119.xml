<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Arnold L. Rosenberg</title>
    <ns>0</ns>
    <id>31174000</id>
    <revision>
      <id>846490610</id>
      <parentid>749726193</parentid>
      <timestamp>2018-06-19T02:43:34Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3783">'''Arnold Leonard Rosenberg''' (born February 11, 1941) is an American [[computer scientist]]. He is a distinguished university professor [[emeritus]] at the [[University of Massachusetts Amherst]],&lt;ref name="ambio"&gt;[http://www.cs.umass.edu/faculty/faculty-directory Faculty directory], UMass Amherst CS, retrieved 2011-03-13.&lt;/ref&gt; and despite his retirement from UMass he continues to hold research positions at [[Northeastern University]]&lt;ref&gt;[http://www.ccs.neu.edu/people/faculty.html Faculty directory] {{webarchive |url=https://web.archive.org/web/20110319125143/http://www.ccs.neu.edu/people/faculty.html |date=March 19, 2011 }}, Northeastern CCS, retrieved 2011-03-13.&lt;/ref&gt; and [[Colorado State University]].&lt;ref&gt;[http://www.cs.colostate.edu/cstop/cspeople/csfacultystaff.html Faculty directory] {{webarchive |url=https://web.archive.org/web/20110628234930/http://www.cs.colostate.edu/cstop/cspeople/csfacultystaff.html |date=June 28, 2011 }}, CSU CS, retrieved 2011-03-31.&lt;/ref&gt;

Rosenberg is known, among other contributions, for formulating the [[Aanderaa–Karp–Rosenberg conjecture]] stating that many nontrivial properties in [[graph theory]] cannot be answered without testing for the presence or absence of every possible edge in a given graph.&lt;ref&gt;{{citation|arxiv=cs/0205031v1|first1=László|last1=Lovász|author1-link=László Lovász|last2=Young | first2=Neal E.|title=Lecture Notes on Evasiveness of Graph Properties|year=2002|bibcode=2002cs........5031L}}.&lt;/ref&gt;

Rosenberg did both his undergraduate and graduate studies at [[Harvard University]], receiving a bachelor's degree in 1962 and a Ph.D. in 1966 under the supervision of [[Patrick C. Fischer]].&lt;ref name="ambio"/&gt;&lt;ref&gt;{{mathgenealogy|name=Arnold Leonard Rosenberg|id=155879}}&lt;/ref&gt;
Prior to joining the UMass faculty, Rosenberg worked at the [[Thomas J. Watson Research Center]] from 1965 until 1981, and was a faculty member at [[Duke University]] from 1981 until 1985. He was elected a fellow of the [[Association for Computing Machinery]] in 1996 for his work on "[[graph theory|graph-theoretic]] [[model of computation|models of computation]], emphasizing theoretical studies of [[parallel algorithm]]s and [[parallel computing|architectures]], [[Very-large-scale integration|VLSI]] design and layout, and [[data structure]]s".&lt;ref&gt;[http://fellows.acm.org/fellow_citation.cfm?id=1037498&amp;srt=all [[List of Fellows of the Association for Computing Machinery|ACM Fellow]] citation], [[Association for Computing Machinery]], retrieved 2011-03-13.&lt;/ref&gt; In 1997, he was elected as a fellow of the [[IEEE]] "for fundamental contributions to theoretical aspects of computer science and engineering".&lt;ref&gt;[http://www.ieee.org/membership_services/membership/fellows/alphabetical/rfellows.html#Ro IEEE Fellows directory] {{webarchive |url=https://web.archive.org/web/20110312103513/http://www.ieee.org/membership_services/membership/fellows/alphabetical/rfellows.html#Ro |date=March 12, 2011 }}, retrieved 2011-03-13.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://www.cs.umass.edu/~rsnbrg/ Rosenberg's web site] at UMass Amherst
*[http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rosenberg:Arnold_L=.html DBLP listing of Rosenberg's publications]
{{authority control}}
{{DEFAULTSORT:Rosenberg, Arnold L.}}
[[Category:1941 births]]
[[Category:Living people]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Harvard University alumni]]
[[Category:Duke University faculty]]
[[Category:University of Massachusetts Amherst faculty]]
[[Category:Northeastern University faculty]]
[[Category:Colorado State University faculty]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Fellow Members of the IEEE]]</text>
      <sha1>gmxvr848vzrbaqg0om0miqibzhitg6o</sha1>
    </revision>
  </page>
  <page>
    <title>Artificial neural network</title>
    <ns>0</ns>
    <id>21523</id>
    <revision>
      <id>871768756</id>
      <parentid>871768730</parentid>
      <timestamp>2018-12-03T08:56:43Z</timestamp>
      <contributor>
        <username>Jusdafax</username>
        <id>5519174</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/213.124.60.3|213.124.60.3]] ([[User talk:213.124.60.3|talk]]): disruptive edits ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="170048">{{Machine learning bar}}
{{Use dmy dates|date=June 2013}}
[[File:Colored neural network.svg|thumb|300px|An artificial neural network is an interconnected group of nodes, akin to the vast network of [[neuron]]s in a [[brain]]. Here, each circular node represents an [[artificial neuron]] and an arrow represents a connection from the output of one artificial neuron to the input of another.]]
'''Artificial neural networks''' ('''ANN''') or '''[[Connectionism|connectionist]] systems''' are computing systems vaguely inspired by the [[biological neural network]]s that constitute animal [[brain]]s.&lt;ref&gt;{{Cite web|url=https://www.frontiersin.org/research-topics/4817/artificial-neural-networks-as-models-of-neural-information-processing|title=Artificial Neural Networks as Models of Neural Information Processing {{!}} Frontiers Research Topic|language=en|access-date=2018-02-20}}&lt;/ref&gt; The neural network itself is not an algorithm, but rather a framework for many different [[machine learning]] algorithms to work together and process complex data inputs.&lt;ref&gt;{{Cite web|url=https://deepai.org/machine-learning-glossary-and-terms/neural-network|title=Build with AI {{!}} DeepAI|website=DeepAI|access-date=2018-10-06}}&lt;/ref&gt; Such systems "learn" to perform tasks by considering examples, generally without being programmed with any task-specific rules. For example, in [[image recognition]], they might learn to identify images that contain cats by analyzing example images that have been manually [[Labeled data|labeled]] as "cat" or "no cat" and using the results to identify cats in other images. They do this without any prior knowledge about cats, for example, that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the learning material that they process.

An ANN is based on a collection of connected units or nodes called [[artificial neuron]]s, which loosely model the [[neuron]]s in a biological [[brain]]. Each connection, like the [[synapse]]s in a biological [[brain]], can transmit a signal from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it.

In common ANN implementations, the signal at a connection between artificial neurons is a [[real number]], and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called 'edges'. Artificial neurons and edges typically have a [[weight (mathematics)|weight]] that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.

The original goal of the ANN approach was to solve problems in the same way that a [[human brain]] would. However, over time, attention moved to performing specific tasks, leading to deviations from [[biology]]. Artificial neural networks have been used on a variety of tasks, including [[computer vision]], [[speech recognition]], [[machine translation]], [[social network]] filtering, [[general game playing|playing board and video games]] and [[medical diagnosis]].
{{toclimit|3}}

==History==
[[Warren McCulloch]] and [[Walter Pitts]]&lt;ref&gt;{{cite journal|last=McCulloch|first=Warren|author2=Walter Pitts|title=A Logical Calculus of Ideas Immanent in Nervous Activity|journal=Bulletin of Mathematical Biophysics|year=1943|volume=5|pages=115–133|doi=10.1007/BF02478259|issue=4}}&lt;/ref&gt; (1943) created a computational model for neural networks based on [[mathematics]] and [[algorithm]]s called threshold logic. This model paved the way for neural network research to split into two approaches. One approach focused on biological processes in the brain while the other focused on the application of neural networks to [[artificial intelligence]]. This work led to work on nerve networks and their link to [[Finite state machine|finite automata]].&lt;ref&gt;{{Cite news|url=https://www.degruyter.com/view/books/9781400882618/9781400882618-002/9781400882618-002.xml|title=Representation of Events in Nerve Nets and Finite Automata|last=Kleene|first=S.C.|date=|work=Annals of Mathematics Studies|access-date=2017-06-17|publisher=Princeton University Press|year=1956|issue=34|pages=3–41|language=en}}&lt;/ref&gt;

===Hebbian learning===

In the late 1940s, [[Donald O. Hebb|D. O. Hebb]]&lt;ref&gt;{{cite book|url={{google books |plainurl=y |id=ddB4AgAAQBAJ}}|title=The Organization of Behavior|last=Hebb|first=Donald|publisher=Wiley|year=1949|isbn=978-1-135-63190-1|location=New York|pages=}}&lt;/ref&gt; created a learning hypothesis based on the mechanism of [[Neuroplasticity|neural plasticity]] that became known as [[Hebbian learning]]. Hebbian learning is [[unsupervised learning]]. This evolved into models for [[long term potentiation]]. Researchers started applying these ideas to computational models in 1948 with [[unorganized machine|Turing's B-type machines]]. Farley and [[Wesley A. Clark|Clark]]&lt;ref&gt;{{cite journal|last=Farley|first=B.G.|author2=W.A. Clark|title=Simulation of Self-Organizing Systems by Digital Computer|journal=IRE Transactions on Information Theory|year=1954|volume=4|pages=76–84|doi=10.1109/TIT.1954.1057468|issue=4}}&lt;/ref&gt; (1954) first used computational machines, then called "calculators", to simulate a Hebbian network. Other neural network computational machines were created by [[Nathaniel Rochester (computer scientist)|Rochester]], Holland, Habit and Duda (1956).&lt;ref&gt;{{cite journal|last=Rochester|first=N. |author2=J.H. Holland |author3=L.H. Habit |author4=W.L. Duda|title=Tests on a cell assembly theory of the action of the brain, using a large digital computer|journal=IRE Transactions on Information Theory|year=1956|volume=2|pages=80–93|doi=10.1109/TIT.1956.1056810|issue=3}}&lt;/ref&gt; [[Frank Rosenblatt|Rosenblatt]]&lt;ref&gt;{{cite journal|last=Rosenblatt|first=F.|title=The Perceptron: A Probabilistic Model For Information Storage And Organization In The Brain|journal=Psychological Review|year=1958|volume=65|pages=386–408|doi=10.1037/h0042519|pmid=13602029|issue=6|citeseerx=10.1.1.588.3775}}&lt;/ref&gt; (1958) created the [[perceptron]], an algorithm for pattern recognition. With mathematical notation, Rosenblatt described circuitry not in the basic perceptron, such as the [[exclusive-or]] circuit that could not be processed by neural networks at the time.&lt;ref name="Werbos 1975"&gt;{{cite book|url={{google books |plainurl=y |id=z81XmgEACAAJ}}|title=Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences|last=Werbos|first=P.J.|publisher=|year=1975|isbn=|location=|pages=}}&lt;/ref&gt; In 1959, a biological model proposed by [[Nobel laureate]]s [[David H. Hubel|Hubel]] and [[Torsten Wiesel|Wiesel]] was based on their discovery of two types of cells in the [[primary visual cortex]]: [[simple cell]]s and [[complex cell]]s.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=8YrxWojxUA4C&amp;pg=PA106|title=Brain and visual perception: the story of a 25-year collaboration|publisher=Oxford University Press US|year=2005|isbn=978-0-19-517618-6|page=106|author=David H. Hubel and Torsten N. Wiesel}}&lt;/ref&gt; The first functional networks with many layers were published by [[Alexey Grigorevich Ivakhnenko|Ivakhnenko]] and Lapa in 1965, becoming the [[Group method of data handling|Group Method of Data Handling]].&lt;ref name="SCHIDHUB2"&gt;{{cite journal|last=Schmidhuber|first=J.|year=2015|title=Deep Learning in Neural Networks: An Overview|journal=Neural Networks|volume=61|pages=85–117|arxiv=1404.7828|doi=10.1016/j.neunet.2014.09.003|pmid=25462637}}&lt;/ref&gt;&lt;ref name="ivak1965"&gt;{{cite book|url={{google books |plainurl=y |id=FhwVNQAACAAJ}}|title=Cybernetic Predicting Devices|last=Ivakhnenko|first=A. G.|publisher=CCM Information Corporation|year=1973}}&lt;/ref&gt;&lt;ref name="ivak1967"&gt;{{cite book|url={{google books |plainurl=y |id=rGFgAAAAMAAJ}}|title=Cybernetics and forecasting techniques|last2=Grigorʹevich Lapa|first2=Valentin|publisher=American Elsevier Pub. Co.|year=1967|first1=A. G.|last1=Ivakhnenko}}&lt;/ref&gt;

Neural network research stagnated after [[machine learning]] research by [[Marvin Minsky|Minsky]] and [[Seymour Papert|Papert]] (1969),&lt;ref&gt;{{cite book|url={{google books |plainurl=y |id=Ow1OAQAAIAAJ}}|title=Perceptrons: An Introduction to Computational Geometry|last=Minsky|first=Marvin|first2=Seymour|publisher=MIT Press|year=1969|isbn=978-0-262-63022-1|location=|pages=|author2=Papert}}&lt;/ref&gt; who discovered two key issues with the computational machines that processed neural networks. The first was that basic perceptrons were incapable of processing the exclusive-or circuit. The second was that computers didn't have enough processing power to effectively handle the work required by large neural networks. Neural network research slowed until computers achieved far greater processing power. Much of [[artificial intelligence]] had focused on high-level (symbolic) models that are processed by using [[algorithms]], characterized for example by [[expert system]]s with knowledge embodied in ''if-then'' rules, until in the late 1980s research expanded to low-level (sub-symbolic) [[machine learning]], characterized by knowledge embodied in the parameters of a [[cognitive model]].{{Citation needed|date=August 2017|reason=Reliable source needed for the whole sentence}}

=== Backpropagation ===
A key trigger for renewed interest in neural networks and learning was [[Paul Werbos|Werbos]]'s (1975) [[backpropagation]] algorithm that effectively solved the exclusive-or problem by making the training of multi-layer networks feasible and efficient. Backpropagation distributed the error term back up through the layers, by modifying the weights at each node.&lt;ref name="Werbos 1975" /&gt;

In the mid-1980s, [[parallel distributed processing]] became popular under the name [[connectionism]]. [[David E. Rumelhart|Rumelhart]] and [[James McClelland (psychologist)|McClelland]] (1986) described the use of connectionism to simulate neural processes.&lt;ref&gt;{{cite book|url={{google books |plainurl=y |id=davmLgzusB8C}}|title=Parallel Distributed Processing: Explorations in the Microstructure of Cognition|last=Rumelhart|first=D.E|first2=James|publisher=MIT Press|year=1986|isbn=978-0-262-63110-5|location=Cambridge|pages=|author2=McClelland}}&lt;/ref&gt;

[[Support vector machine]]s and other, much simpler methods such as [[linear classifier]]s gradually overtook neural networks in machine learning popularity. However, using neural networks transformed some domains, such as the prediction of protein structures.&lt;ref&gt;{{cite article|id=Qian1988|title=
Predicting the secondary structure of globular proteins using neural network models. |last=Qian|first=N.|last2=Sejnowski|first2=T.J.|journal=Journal of Molecular Biology|volume=202|pages=865–884|year=1988}}&lt;/ref&gt;&lt;ref&gt;{{cite article|id=Rost1993|title=
Prediction of protein secondary structure at better than 70% accuracy |last=Rost|first=B.|last2=Sander|first2=C.|journal=Journal of Molecular Biology|volume=232|pages=584–599|year=1993}}&lt;/ref&gt;

In 1992, [[Convolutional neural network#Pooling layer|max-pooling]] was introduced to help with least shift invariance and tolerance to deformation to aid in 3D object recognition.&lt;ref name="Weng1992"&gt;J. Weng, N. Ahuja and T. S. Huang, "[http://www.cse.msu.edu/~weng/research/CresceptronIJCNN1992.pdf Cresceptron: a self-organizing neural network which grows adaptively]," ''Proc. International Joint Conference on Neural Networks'', Baltimore, Maryland, vol I, pp. 576–581, June, 1992.&lt;/ref&gt;&lt;ref name="Weng19932"&gt;J. Weng, N. Ahuja and T. S. Huang, "[http://www.cse.msu.edu/~weng/research/CresceptronICCV1993.pdf Learning recognition and segmentation of 3-D objects from 2-D images]," ''Proc. 4th International Conf. Computer Vision'', Berlin, Germany, pp. 121–128, May, 1993.&lt;/ref&gt;&lt;ref name="Weng1997"&gt;J. Weng, N. Ahuja and T. S. Huang, "[http://www.cse.msu.edu/~weng/research/CresceptronIJCV.pdf Learning recognition and segmentation using the Cresceptron]," ''International Journal of Computer Vision'', vol. 25, no. 2, pp. 105–139, Nov. 1997.&lt;/ref&gt;
In 2010, Backpropagation training through [[Convolutional neural network#Pooling layer|max-pooling]] was accelerated by GPUs and shown to perform better than other pooling variants.&lt;ref name="Scherer2010"&gt;Dominik Scherer, Andreas C. Müller, and Sven Behnke: "[https://www.ais.uni-bonn.de/papers/icann2010_maxpool.pdf Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition]," ''In 20th International Conference Artificial Neural Networks (ICANN)'', pp. 92–101, 2010. {{doi|10.1007/978-3-642-15825-4_10}}.&lt;/ref&gt;

The [[vanishing gradient problem]] affects many-layered [[Feedforward neural network|feedforward networks]] that used backpropagation and also [[recurrent neural network]]s (RNNs).&lt;ref name="HOCH19912"&gt;S. Hochreiter., "[http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf Untersuchungen zu dynamischen neuronalen Netzen]," ''Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber'', 1991.&lt;/ref&gt;&lt;ref name="HOCH2001"&gt;{{cite book|chapter-url={{google books |plainurl=y |id=NWOcMVA64aAC}}|title=A Field Guide to Dynamical Recurrent Networks|last=Hochreiter|first=S.|last2=et al.|date=15 January 2001|publisher=John Wiley &amp; Sons|isbn=978-0-7803-5369-5|location=|pages=|chapter=Gradient flow in recurrent nets: the difficulty of learning long-term dependencies|editor-last2=Kremer|editor-first2=Stefan C.|editor-first1=John F.|editor-last1=Kolen}}&lt;/ref&gt; As errors propagate from layer to layer, they shrink exponentially with the number of layers, impeding the tuning of neuron weights that is based on those errors, particularly affecting deep networks.

To overcome this problem, [[Jürgen Schmidhuber|Schmidhuber]] adopted a multi-level hierarchy of networks (1992) pre-trained one level at a time by [[unsupervised learning]] and fine-tuned by [[backpropagation]].&lt;ref name="SCHMID1992"&gt;J. Schmidhuber., "Learning complex, extended sequences using the principle of history compression," ''Neural Computation'', 4, pp. 234–242, 1992.&lt;/ref&gt; Behnke (2003) relied only on the sign of the gradient ([[Rprop]])&lt;ref&gt;{{cite book|url=http://www.ais.uni-bonn.de/books/LNCS2766.pdf|title=Hierarchical Neural Networks for Image Interpretation.|publisher=Springer|year=2003|series=Lecture Notes in Computer Science|volume=2766|author=Sven Behnke}}&lt;/ref&gt; on problems such as image reconstruction and face localization.

[[Geoffrey Hinton|Hinton]] et al. (2006) proposed learning a high-level representation using successive layers of binary or real-valued [[latent variable]]s with a [[restricted Boltzmann machine]]&lt;ref name="smolensky1986"&gt;{{cite book|chapter-url=http://portal.acm.org/citation.cfm?id=104290|title=Parallel Distributed Processing: Explorations in the Microstructure of Cognition|year=1986|editors=D. E. Rumelhart, J. L. McClelland, &amp; the PDP Research Group|volume=1|pages=194–281|chapter=Information processing in dynamical systems: Foundations of harmony theory.|last1=Smolensky|first1=P.|authorlink1=Paul Smolensky|isbn=9780262680530}}&lt;/ref&gt; to model each layer. Once sufficiently many layers have been learned, the deep architecture may be used as a [[generative model]] by reproducing the data when sampling down the model (an "ancestral pass") from the top level feature activations.&lt;ref name="hinton2006"&gt;{{cite journal|last2=Osindero|first2=S.|last3=Teh|first3=Y.|year=2006|title=A fast learning algorithm for deep belief nets|url=http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf|journal=[[Neural Computation (journal)|Neural Computation]]|volume=18|issue=7|pages=1527–1554|doi=10.1162/neco.2006.18.7.1527|pmid=16764513|last1=Hinton|first1=G. E.|authorlink1=Geoffrey Hinton|citeseerx=10.1.1.76.1541}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|year=2009|title=Deep belief networks|url=http://www.scholarpedia.org/article/Deep_belief_networks|journal=Scholarpedia|volume=4|issue=5|pages=5947|doi=10.4249/scholarpedia.5947|pmc=|pmid=|last1=Hinton|first1=G.|bibcode=2009SchpJ...4.5947H}}&lt;/ref&gt; In 2012, [[Andrew Ng|Ng]] and [[Jeff Dean (computer scientist)|Dean]] created a network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from [[YouTube]] videos.&lt;ref name="ng2012"&gt;{{cite arXiv|eprint=1112.6209|first2=Jeff|last2=Dean|title=Building High-level Features Using Large Scale Unsupervised Learning|last1=Ng|first1=Andrew|year=2012|class=cs.LG}}&lt;/ref&gt;

Earlier challenges in training deep neural networks were successfully addressed with methods such as [[unsupervised pre-training]], while available computing power increased through the use of [[GPU]]s and [[distributed computing]]. Neural networks were deployed on a large scale, particularly in image and visual recognition problems. This became known as "[[deep learning]]".{{citation needed|date=June 2018}}

===Hardware-based designs===
Computational devices were created in [[CMOS]], for both biophysical simulation and [[neuromorphic computing]]. [[Nanodevice]]s&lt;ref&gt;{{cite journal | last1 = Yang | first1 = J. J. | last2 = Pickett | first2 = M. D. | last3 = Li | first3 = X. M. | last4 = Ohlberg | first4 = D. A. A. | last5 = Stewart | first5 = D. R. | last6 = Williams | first6 = R. S. | year = 2008 | title =  Memristive switching mechanism for metal/oxide/metal nanodevices| url = | journal = Nat. Nanotechnol. | volume = 3 | issue = 7| pages = 429–433 | doi = 10.1038/nnano.2008.160 | pmid = 18654568 }}&lt;/ref&gt; for very large scale [[principal component]]s analyses and [[convolution]] may create a new class of neural computing because they are fundamentally [[Analog signal|analog]] rather than [[Digital data|digital]] (even though the first implementations may use digital devices).&lt;ref&gt;{{cite journal | last1 = Strukov | first1 = D. B. | last2 = Snider | first2 = G. S. | last3 = Stewart | first3 = D. R. | last4 = Williams | first4 = R. S. | year = 2008 | title =  The missing memristor found| url = | journal = Nature | volume = 453 | issue = 7191| pages = 80–83 | doi=10.1038/nature06932 | pmid=18451858| bibcode = 2008Natur.453...80S }}&lt;/ref&gt; Ciresan and colleagues (2010)&lt;ref name=":3"&gt;{{Cite journal|last=Cireşan|first=Dan Claudiu|last2=Meier|first2=Ueli|last3=Gambardella|first3=Luca Maria|last4=Schmidhuber|first4=Jürgen|date=2010-09-21|title=Deep, Big, Simple Neural Nets for Handwritten Digit Recognition|journal=Neural Computation|volume=22|issue=12|pages=3207–3220|doi=10.1162/neco_a_00052|pmid=20858131|issn=0899-7667|arxiv=1003.0358}}&lt;/ref&gt; in Schmidhuber's group showed that despite the vanishing gradient problem, GPUs makes [[back-propagation]] feasible for many-layered feedforward neural networks.

=== Contests ===
Between 2009 and 2012, [[recurrent neural network]]s and deep feedforward neural networks developed in [[Jürgen Schmidhuber|Schmidhuber]]'s research group won eight international competitions in [[pattern recognition]] and [[machine learning]].&lt;ref&gt;[http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions 2012 Kurzweil AI Interview] with [[Jürgen Schmidhuber]] on the eight competitions won by his Deep Learning team 2009–2012&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions|title=How bio-inspired deep learning keeps winning competitions {{!}} KurzweilAI|last=|first=|date=|website=www.kurzweilai.net|language=en-US|access-date=2017-06-16}}&lt;/ref&gt; For example, the bi-directional and multi-dimensional [[long short-term memory]] (LSTM)&lt;ref&gt;Graves, Alex; and Schmidhuber, Jürgen; ''[http://www.idsia.ch/~juergen/nips2009.pdf Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks]'', in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), ''Advances in Neural Information Processing Systems 22 (NIPS'22), 7–10 December 2009, Vancouver, BC'', Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552.
&lt;/ref&gt;&lt;ref name="graves 855" /&gt;&lt;ref name="graves20093"&gt;{{Cite journal|last2=Schmidhuber|first2=Jürgen|date=2009|editor-last=Bengio|editor-first=Yoshua|title=Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks|url=https://papers.nips.cc/paper/3449-offline-handwriting-recognition-with-multidimensional-recurrent-neural-networks|journal=Neural Information Processing Systems (NIPS) Foundation|volume=|pages=545–552|via=|editor-last2=Schuurmans|editor-first2=Dale|editor-last3=Lafferty|editor-first3=John|editor-last4=Williams|editor-first4=Chris editor-K. I.|editor-last5=Culotta|editor-first5=Aron|last1=Graves|first1=Alex|publisher=Curran Associates, Inc}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Graves|first=A.|last2=Liwicki|first2=M.|last3=Fernández|first3=S.|last4=Bertolami|first4=R.|last5=Bunke|first5=H.|last6=Schmidhuber|first6=J.|date=May 2009|title=A Novel Connectionist System for Unconstrained Handwriting Recognition|url=http://ieeexplore.ieee.org/document/4531750/|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=31|issue=5|pages=855–868|doi=10.1109/tpami.2008.137|pmid=19299860|issn=0162-8828|citeseerx=10.1.1.139.4502}}&lt;/ref&gt; of [[Alex Graves (computer scientist)|Graves]] et al. won three competitions in connected handwriting recognition at the 2009 [[International Conference on Document Analysis and Recognition]] (ICDAR), without any prior knowledge about the three languages to be learned.&lt;ref name="graves20093"/&gt;&lt;ref name="graves 855"&gt;{{cite journal|last2=Liwicki|first2=M.|last3=Fernandez|first3=S.|last4=Bertolami|first4=R.|last5=Bunke|first5=H.|last6=Schmidhuber|first6=J.|year=2009|title=A Novel Connectionist System for Improved Unconstrained Handwriting Recognition|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=31|issue=5|pages=855–868|doi=10.1109/tpami.2008.137|pmid=19299860|last1=Graves|first1=A.| url = http://www.idsia.ch/~juergen/tpami_2008.pdf | format = PDF|citeseerx=10.1.1.139.4502}}&lt;/ref&gt;

Ciresan and colleagues won [[pattern recognition]] contests, including the IJCNN 2011 Traffic Sign Recognition Competition,&lt;ref name=":72"&gt;{{Cite journal|last=Cireşan|first=Dan|last2=Meier|first2=Ueli|last3=Masci|first3=Jonathan|last4=Schmidhuber|first4=Jürgen|date=August 2012|title=Multi-column deep neural network for traffic sign classification|url=http://www.sciencedirect.com/science/article/pii/S0893608012000524|journal=Neural Networks|series=Selected Papers from IJCNN 2011|volume=32|pages=333–338|doi=10.1016/j.neunet.2012.02.023|pmid=22386783|citeseerx=10.1.1.226.8219}}&lt;/ref&gt; the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge&lt;ref name=":8"/&gt; and others. Their neural networks were the first pattern recognizers to achieve human-competitive or even superhuman performance&lt;ref name=":92"&gt;{{Cite book|last=Ciresan|first=Dan|last2=Meier|first2=U.|last3=Schmidhuber|first3=J.|date=June 2012|title=Multi-column deep neural networks for image classification|url=http://ieeexplore.ieee.org/document/6248110/|journal=2012 IEEE Conference on Computer Vision and Pattern Recognition|volume=|pages=3642–3649|doi=10.1109/cvpr.2012.6248110|via=|isbn=978-1-4673-1228-8|arxiv=1202.2745|citeseerx=10.1.1.300.3283}}&lt;/ref&gt; on benchmarks such as traffic sign recognition (IJCNN 2012), or the [[MNIST database|MNIST handwritten digits problem]].

Researchers demonstrated (2010) that deep neural networks interfaced to a [[hidden Markov model]] with context-dependent states that define the neural network output layer can drastically reduce errors in large-vocabulary speech recognition tasks such as voice search.

GPU-based implementations&lt;ref name=":6"&gt;{{Cite journal|last=Ciresan|first=D. C.|last2=Meier|first2=U.|last3=Masci|first3=J.|last4=Gambardella|first4=L. M.|last5=Schmidhuber|first5=J.|date=2011|editor-last=|title=Flexible, High Performance Convolutional Neural Networks for Image Classification|url=http://ijcai.org/papers11/Papers/IJCAI11-210.pdf|journal=International Joint Conference on Artificial Intelligence|volume=|pages=|doi=10.5591/978-1-57735-516-8/ijcai11-210|via=}}&lt;/ref&gt; of this approach won many pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition,&lt;ref name=":72"/&gt; the ISBI 2012 Segmentation of neuronal structures in EM stacks challenge,&lt;ref name=":8"&gt;{{Cite book|url=http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf|title=Advances in Neural Information Processing Systems 25|last=Ciresan|first=Dan|last2=Giusti|first2=Alessandro|last3=Gambardella|first3=Luca M.|last4=Schmidhuber|first4=Juergen|date=2012|publisher=Curran Associates, Inc.|editor-last=Pereira|editor-first=F.|pages=2843–2851|editor-last2=Burges|editor-first2=C. J. C.|editor-last3=Bottou|editor-first3=L.|editor-last4=Weinberger|editor-first4=K. Q.}}&lt;/ref&gt; the [[ImageNet Competition]]&lt;ref name="krizhevsky2012"&gt;{{cite journal|last2=Sutskever|first2=Ilya|last3=Hinton|first3=Geoffry|date=2012|title=ImageNet Classification with Deep Convolutional Neural Networks|url=https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf|journal=NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada|last1=Krizhevsky|first1=Alex}}&lt;/ref&gt; and others.

Deep, highly nonlinear neural architectures similar to the [[neocognitron]]&lt;ref name="K. Fukushima. Neocognitron 1980"&gt;{{cite journal|year=1980|title=Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position|journal=Biological Cybernetics|volume=36|issue=4|pages=93–202|doi=10.1007/BF00344251|pmid=7370364|author=Fukushima, K.}}&lt;/ref&gt; and the "standard architecture of vision",&lt;ref&gt;{{cite journal|last2=Poggio|first2=T|year=1999|title=Hierarchical models of object recognition in cortex|journal=Nature Neuroscience|volume=2|issue=11|pages=1019–1025|doi=10.1038/14819|pmid=10526343|last1=Riesenhuber|first1=M}}&lt;/ref&gt; inspired by [[Simple cell|simple]] and [[complex cell]]s, were pre-trained by unsupervised methods by Hinton.&lt;ref name=":1"&gt;{{Cite journal|last=Hinton|first=Geoffrey|date=2009-05-31|title=Deep belief networks|url=http://www.scholarpedia.org/article/Deep_belief_networks|journal=Scholarpedia|language=en|volume=4|issue=5|pages=5947|doi=10.4249/scholarpedia.5947|issn=1941-6016|bibcode=2009SchpJ...4.5947H}}&lt;/ref&gt;&lt;ref name="hinton2006" /&gt; A team from his lab won a 2012 contest sponsored by [[Merck &amp; Co.|Merck]] to design software to help find molecules that might identify new drugs.&lt;ref&gt;{{cite news|url=https://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html|title=Scientists See Promise in Deep-Learning Programs|last=Markoff|first=John|date=November 23, 2012|author=|newspaper=New York Times}}&lt;/ref&gt;

=== Convolutional networks ===
{{as of|2011}}, the state of the art in deep learning feedforward networks alternated between convolutional layers and max-pooling layers,&lt;ref name=":6" /&gt;&lt;ref name="martines2013"&gt;{{cite journal|last2=Bengio|first2=Y.|last3=Yannakakis|first3=G. N.|year=2013|title=Learning Deep Physiological Models of Affect|url=https://www.um.edu.mt/library/oar//handle/123456789/29605|journal=IEEE Computational Intelligence|volume=8|issue=2|pages=20–33|doi=10.1109/mci.2013.2247823|last1=Martines|first1=H.|type=Submitted manuscript}}&lt;/ref&gt; topped by several fully or sparsely connected layers followed by a final classification layer. Learning is usually done without unsupervised pre-training. In the convolutional layer, there are filters that are convolved with the input. Each filter is equivalent to a weights vector that has to be trained. 

Such supervised deep learning methods were the first to achieve human-competitive performance on certain tasks.&lt;ref name=":92"/&gt;

Artificial neural networks were able to guarantee shift invariance to deal with small and large natural objects in large cluttered scenes, only when invariance extended beyond shift, to all ANN-learned concepts, such as location, type (object class label), scale, lighting and others. This was realized in Developmental Networks (DNs)&lt;ref name="Weng2011"&gt;J. Weng, "[http://www.cse.msu.edu/~weng/research/WhyPass-Weng-NI-2011.pdf Why Have We Passed 'Neural Networks Do not Abstract Well'?]," ''Natural Intelligence: the INNS Magazine'', vol. 1, no.1, pp. 13–22, 2011.&lt;/ref&gt; whose embodiments are Where-What Networks, WWN-1 (2008)&lt;ref name="Weng08"&gt;Z. Ji, J. Weng, and D. Prokhorov, "[http://www.cse.msu.edu/~weng/research/ICDL08_0077.pdf Where-What Network 1: Where and What Assist Each Other Through Top-down Connections]," ''Proc. 7th International Conference on Development and Learning (ICDL'08)'', Monterey, CA, Aug. 9–12, pp. 1–6, 2008.&lt;/ref&gt; through WWN-7 (2013).&lt;ref name="Weng13"&gt;X. Wu, G. Guo, and J. Weng, "[http://www.cse.msu.edu/~weng/research/WWN7-Wu-ICBM-2013.pdf Skull-closed Autonomous Development: WWN-7 Dealing with Scales]," ''Proc. International Conference on Brain-Mind'', July 27–28, East Lansing, Michigan, pp. 1–9, 2013.&lt;/ref&gt;

==Models==
{{Confusing|section|date=April 2017}}

[[File:Neuron3.png|thumb|right|400px|Neuron and myelinated axon, with signal flow from inputs at dendrites to outputs at axon terminals]]
An ''artificial neural network'' is a network of simple elements called ''[[artificial neurons]]'', which receive input, change their internal state (''activation'') according to that input, and produce output depending on the input and activation.

An [[artificial neuron]] mimics the working of a biophysical [[neuron]] with inputs and outputs, but is not a [[biological neuron model]].

The ''network'' forms by connecting the output of certain neurons to the input of other neurons forming a [[Directed graph|directed]], [[weighted graph]]. The weights as well as the [[Activation function|functions that compute the activation]] can be modified by a process called ''learning'' which is governed by a ''[[learning rule]]''.&lt;ref name=Zell1994ch5.2&gt;{{cite book |last=Zell |first=Andreas |year=1994 |title=Simulation Neuronaler Netze |trans-title=Simulation of Neural Networks |language=German |edition=1st |publisher=Addison-Wesley  |chapter=chapter 5.2 |isbn=978-3-89319-554-1}}&lt;/ref&gt;

===Components of an artificial neural network===

====Neurons====
A neuron with label &lt;math&gt;j&lt;/math&gt; receiving an input &lt;math&gt;p_j(t)&lt;/math&gt; from predecessor neurons consists of the following components:&lt;ref name=Zell1994ch5.2 /&gt;

* an ''activation'' &lt;math&gt;a_j(t)&lt;/math&gt;, the neuron's state, depending on a discrete time parameter,
* possibly a ''threshold'' &lt;math&gt;\theta_j&lt;/math&gt;, which stays fixed unless changed by a learning function,
* an ''activation function'' &lt;math&gt;f&lt;/math&gt; that computes the new activation at a given time &lt;math&gt;t+1&lt;/math&gt; from &lt;math&gt;a_j(t)&lt;/math&gt;, &lt;math&gt;\theta_j&lt;/math&gt; and the net input &lt;math&gt;p_j(t)&lt;/math&gt; giving rise to the relation
: &lt;math&gt; a_j(t+1) = f(a_j(t), p_j(t), \theta_j) &lt;/math&gt;,
* and an ''output function'' &lt;math&gt;f_{out}&lt;/math&gt; computing the output from the activation
: &lt;math&gt; o_j(t) = f_{out}(a_j(t)) &lt;/math&gt;.
Often the output function is simply the [[Identity function]].

An ''input neuron'' has no predecessor but serves as input interface for the whole network. Similarly an ''output neuron'' has no successor and thus serves as output interface of the whole network.

====Connections, weights and biases====
The ''network'' consists of connections, each connection transferring the output of a neuron &lt;math&gt;i&lt;/math&gt; to the input of a neuron &lt;math&gt;j&lt;/math&gt;. In this sense &lt;math&gt;i&lt;/math&gt; is the predecessor of &lt;math&gt;j&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; is the successor of &lt;math&gt;i&lt;/math&gt;. Each connection is assigned a weight &lt;math&gt;w_{ij}&lt;/math&gt;.&lt;ref name=Zell1994ch5.2 /&gt; Sometimes a bias term added to total weighted sum of inputs to serve as threshold to shift the activation function.&lt;ref name="Abbod2007"&gt;{{cite journal|year=2007|title=Application of Artificial Intelligence to the Management of Urological Cancer|url=https://www.sciencedirect.com/science/article/pii/S0022534707013936|journal=The Journal of Urology|volume=178|issue=4|pages=1150–1156|doi=10.1016/j.juro.2007.05.122|pmid=17698099|last1=Abbod|first1=Maysam F}}&lt;/ref&gt;

====Propagation function====
The ''propagation function'' computes the ''input'' &lt;math&gt;p_j(t)&lt;/math&gt; to the neuron &lt;math&gt;j&lt;/math&gt; from the outputs &lt;math&gt;o_i(t)&lt;/math&gt; of predecessor neurons and typically has the form&lt;ref name=Zell1994ch5.2 /&gt;
: &lt;math&gt; p_j(t) = \sum_{i} o_i(t) w_{ij} &lt;/math&gt;. 
When a bias value added with the function, the above form changes to following &lt;ref name="DAWSON1998"&gt;{{cite journal|year=1998|title=An artificial neural network approach to rainfall-runoff modelling|journal=Hydrological Sciences Journal|volume=43|issue=1|pages=47–66|doi=10.1080/02626669809492102|last1=DAWSON|first1=CHRISTIAN W}}&lt;/ref&gt; 
: &lt;math&gt; p_j(t) = \sum_{i} o_i(t) w_{ij}+  w_{0j} &lt;/math&gt; , where &lt;math&gt;w_{0j}&lt;/math&gt; is a bias.

====Learning rule====
The ''learning rule'' is a rule or an algorithm which modifies the parameters of the neural network, in order for a given input to the network to produce a favored output. This ''learning'' process typically amounts to modifying the weights and thresholds of the variables within the network.&lt;ref name=Zell1994ch5.2 /&gt;

===Neural networks as functions===
{{See also|Graphical models}}

Neural network models can be viewed as simple mathematical models defining a function &lt;math&gt;\textstyle f : X \rightarrow Y &lt;/math&gt; or a distribution over &lt;math&gt;\textstyle X&lt;/math&gt; or both &lt;math&gt;\textstyle X&lt;/math&gt; and &lt;math&gt;\textstyle Y&lt;/math&gt;. Sometimes models are intimately associated with a particular learning rule. A common use of the phrase "ANN model" is really the definition of a ''class'' of such functions (where members of the class are obtained by varying parameters, connection weights, or specifics of the architecture such as the number of neurons or their connectivity).

Mathematically, a neuron's network function &lt;math&gt;\textstyle f(x)&lt;/math&gt; is defined as a composition of other functions &lt;math&gt;\textstyle g_i(x)&lt;/math&gt;, that can further be decomposed into other functions. This can be conveniently represented as a network structure, with arrows depicting the dependencies between functions. A widely used type of composition is the ''nonlinear weighted sum'', where &lt;math&gt;\textstyle f (x) = K \left(\sum_i w_i g_i(x)\right) &lt;/math&gt;, where &lt;math&gt;\textstyle K&lt;/math&gt; (commonly referred to as the [[activation function]]&lt;ref&gt;{{cite web|url=http://www.cse.unsw.edu.au/~billw/mldict.html#activnfn|title=The Machine Learning Dictionary}}&lt;/ref&gt;) is some predefined function, such as the [[hyperbolic function#Standard analytic expressions|hyperbolic tangent]] or [[sigmoid function]] or [[softmax function]] or [[ReLU|rectifier function]]. The important characteristic of the activation function is that it provides a smooth transition as input values change, i.e. a small change in input produces a small change in output. The following refers to a collection of functions &lt;math&gt;\textstyle g_i&lt;/math&gt; as a [[Vector (mathematics and physics)|vector]] &lt;math&gt;\textstyle g = (g_1, g_2, \ldots, g_n)&lt;/math&gt;.

[[File:Ann dependency (graph).svg|thumb|150px|ANN dependency graph]]

This figure depicts such a decomposition of &lt;math&gt;\textstyle f&lt;/math&gt;, with dependencies between variables indicated by arrows. These can be interpreted in two ways.

The first view is the functional view: the input &lt;math&gt;\textstyle x&lt;/math&gt; is transformed into a 3-dimensional vector &lt;math&gt;\textstyle h&lt;/math&gt;, which is then transformed into a 2-dimensional vector &lt;math&gt;\textstyle g&lt;/math&gt;, which is finally transformed into &lt;math&gt;\textstyle f&lt;/math&gt;. This view is most commonly encountered in the context of [[Mathematical optimization|optimization]].

The second view is the probabilistic view: the [[random variable]] &lt;math&gt;\textstyle F = f(G) &lt;/math&gt; depends upon the random variable &lt;math&gt;\textstyle G = g(H)&lt;/math&gt;, which depends upon &lt;math&gt;\textstyle H=h(X)&lt;/math&gt;, which depends upon the random variable &lt;math&gt;\textstyle X&lt;/math&gt;. This view is most commonly encountered in the context of [[graphical models]].

The two views are largely equivalent. In either case, for this particular architecture, the components of individual layers are independent of each other (e.g., the components of &lt;math&gt;\textstyle g&lt;/math&gt; are independent of each other given their input &lt;math&gt;\textstyle h&lt;/math&gt;). This naturally enables a degree of parallelism in the implementation.

[[File:Recurrent ann dependency graph.png|thumb|120px| Two separate depictions of the recurrent ANN dependency graph]]

Networks such as the previous one are commonly called [[feedforward neural network|feedforward]], because their graph is a [[directed acyclic graph]]. Networks with [[Cycle (graph theory)|cycles]] are commonly called [[Recurrent neural network|recurrent]]. Such networks are commonly depicted in the manner shown at the top of the figure, where &lt;math&gt;\textstyle f&lt;/math&gt; is shown as being dependent upon itself. However, an implied temporal dependence is not shown.

===Learning===
{{See also|Mathematical optimization|Estimation theory|Machine learning}}

The possibility of learning has attracted the most interest in neural networks. Given a specific ''task'' to solve, and a class of functions &lt;math&gt;\textstyle F&lt;/math&gt;, learning means using a set of observations to find &lt;math&gt;\textstyle  f^{*} \in F&lt;/math&gt; which solves the task in some optimal sense.

This entails defining a cost function &lt;math&gt;\textstyle C : F \rightarrow \mathbb{R}&lt;/math&gt; such that, for the optimal solution &lt;math&gt;\textstyle f^*&lt;/math&gt;, &lt;math&gt;\textstyle C(f^*) \leq C(f)&lt;/math&gt; &lt;math&gt;\textstyle \forall f \in F&lt;/math&gt;{{snd}} i.e., no solution has a cost less than the cost of the optimal solution (see [[mathematical optimization]]).

The cost function &lt;math&gt;\textstyle C&lt;/math&gt; is an important concept in learning, as it is a measure of how far away a particular solution is from an optimal solution to the problem to be solved. Learning algorithms search through the solution space to find a function that has the smallest possible cost.

For applications where the solution is data dependent, the cost must necessarily be a function of the observations, otherwise the model would not relate to the data. It is frequently defined as a [[statistic]] to which only approximations can be made. As a simple example, consider the problem of finding the model &lt;math&gt;\textstyle f&lt;/math&gt;, which minimizes &lt;math&gt;\textstyle C=E\left[(f(x) - y)^2\right]&lt;/math&gt;, for data pairs &lt;math&gt;\textstyle (x,y)&lt;/math&gt; drawn from some distribution &lt;math&gt;\textstyle \mathcal{D}&lt;/math&gt;. In practical situations we would only have &lt;math&gt;\textstyle N&lt;/math&gt; samples from &lt;math&gt;\textstyle \mathcal{D}&lt;/math&gt; and thus, for the above example, we would only minimize &lt;math&gt;\textstyle \hat{C}=\frac{1}{N}\sum_{i=1}^N (f(x_i)-y_i)^2&lt;/math&gt;. Thus, the cost is minimized over a sample of the data rather than the entire distribution.

When &lt;math&gt;\textstyle N \rightarrow \infty&lt;/math&gt; some form of [[online machine learning]] must be used, where the cost is reduced as each new example is seen. While online machine learning is often used when &lt;math&gt;\textstyle \mathcal{D}&lt;/math&gt; is fixed, it is most useful in the case where the distribution changes slowly over time. In neural network methods, some form of online machine learning is frequently used for finite datasets.

====Choosing a cost function====
While it is possible to define an [[ad hoc]] cost function, frequently a particular cost (function) is used, either because it has desirable properties (such as [[Convex function|convexity]]) or because it arises naturally from a particular formulation of the problem (e.g., in a probabilistic formulation the [[posterior probability]] of the model can be used as an inverse cost). Ultimately, the cost function depends on the task.

====Backpropagation====
{{Main|Backpropagation}}
A [[Deep neural network|DNN]] can be [[Discriminative model|discriminatively]] trained with the standard backpropagation algorithm. Backpropagation&amp;nbsp;is a method to calculate the&amp;nbsp;[[gradient]]&amp;nbsp;of the&amp;nbsp;[[loss function]]&amp;nbsp;(produces the cost associated with a given state) with respect to the weights in an&amp;nbsp;ANN.

The basics of continuous backpropagation&lt;ref name="SCHIDHUB2"/&gt;&lt;ref name="scholarpedia2"&gt;{{cite journal|year=2015|title=Deep Learning|url=http://www.scholarpedia.org/article/Deep_Learning|journal=Scholarpedia|volume=10|issue=11|page=32832|doi=10.4249/scholarpedia.32832|last1=Schmidhuber|first1=Jürgen|authorlink=Jürgen Schmidhuber|bibcode=2015SchpJ..1032832S}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{Cite journal|last=Dreyfus|first=Stuart E.|date=1990-09-01|title=Artificial neural networks, back propagation, and the Kelley-Bryson gradient procedure|journal=Journal of Guidance, Control, and Dynamics|volume=13|issue=5|pages=926–928|doi=10.2514/3.25422|issn=0731-5090|bibcode=1990JGCD...13..926D}}&lt;/ref&gt;&lt;ref name="mizutani2000"&gt;Eiji Mizutani, [[Stuart Dreyfus]], Kenichi Nishio (2000). On derivation of MLP backpropagation from the Kelley-Bryson optimal-control gradient formula and its application. Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN 2000), Como Italy, July 2000. [http://queue.ieor.berkeley.edu/People/Faculty/dreyfus-pubs/ijcnn2k.pdf Online]&lt;/ref&gt; were derived in the context of [[control theory]] by [[Henry J. Kelley|Kelley]]&lt;ref name="kelley1960"&gt;{{cite journal|year=1960|title=Gradient theory of optimal flight paths|journal=ARS Journal|volume=30|issue=10|pages=947–954|doi=10.2514/8.5282|last1=Kelley|first1=Henry J.|authorlink=Henry J. Kelley}}&lt;/ref&gt; in 1960 and by [[Arthur E. Bryson|Bryson]] in 1961,&lt;ref name="bryson1961"&gt;[[Arthur E. Bryson]] (1961, April). A gradient method for optimizing multi-stage allocation processes. In Proceedings of the Harvard Univ. Symposium on digital computers and their applications.&lt;/ref&gt; using principles of [[dynamic programming]]. In 1962, [[Stuart Dreyfus|Dreyfus]] published a simpler derivation based only on the [[chain rule]].&lt;ref name="dreyfus1962"&gt;{{cite journal|year=1962|title=The numerical solution of variational problems|url=https://www.researchgate.net/publication/256244271|journal=Journal of Mathematical Analysis and Applications|volume=5|issue=1|pages=30–45|doi=10.1016/0022-247x(62)90004-5|last1=Dreyfus|first1=Stuart|authorlink=Stuart Dreyfus}}&lt;/ref&gt; Bryson and [[Yu-Chi Ho|Ho]] described it as a multi-stage dynamic system optimization method in 1969.&lt;ref&gt;{{cite book|url={{google books |plainurl=y |id=8jZBksh-bUMC|page=578}}|title=Artificial Intelligence A Modern Approach|last2=Norvig|first2=Peter|publisher=Prentice Hall|year=2010|isbn=978-0-13-604259-4|page=578|quote=The most popular method for learning in multilayer networks is called Back-propagation.|author-link2=Peter Norvig|first1=Stuart J.|last1=Russell|author-link1=Stuart J. Russell}}&lt;/ref&gt;&lt;ref name="Bryson1969"&gt;{{cite book|url={{google books |plainurl=y |id=1bChDAEACAAJ|page=481}}|title=Applied Optimal Control: Optimization, Estimation and Control|last=Bryson|first=Arthur Earl|publisher=Blaisdell Publishing Company or Xerox College Publishing|year=1969|page=481}}&lt;/ref&gt; In 1970, [[Seppo Linnainmaa|Linnainmaa]] finally published the general method for [[automatic differentiation]] (AD) of discrete connected networks of nested [[Differentiable function|differentiable]] functions.&lt;ref name="lin1970"&gt;[[Seppo Linnainmaa]] (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 6–7.&lt;/ref&gt;&lt;ref name="lin1976"&gt;{{cite journal|year=1976|title=Taylor expansion of the accumulated rounding error|url=|journal=BIT Numerical Mathematics|volume=16|issue=2|pages=146–160|doi=10.1007/bf01931367|last1=Linnainmaa|first1=Seppo|authorlink=Seppo Linnainmaa}}&lt;/ref&gt; This corresponds to the modern version of backpropagation which is efficient even when the networks are sparse.&lt;ref name="SCHIDHUB2"/&gt;&lt;ref name="scholarpedia2"/&gt;&lt;ref name="grie2012"&gt;{{Cite journal|last=Griewank|first=Andreas|date=2012|title=Who Invented the Reverse Mode of Differentiation?|url=http://www.math.uiuc.edu/documenta/vol-ismp/52_griewank-andreas-b.pdf|journal=Documenta Matematica, Extra Volume ISMP|volume=|pages=389–400|via=|access-date=27 June 2017|archive-url=https://web.archive.org/web/20170721211929/http://www.math.uiuc.edu/documenta/vol-ismp/52_griewank-andreas-b.pdf|archive-date=21 July 2017|dead-url=yes|df=dmy-all}}&lt;/ref&gt;&lt;ref name="grie2008"&gt;{{cite book|url={{google books |plainurl=y |id=xoiiLaRxcbEC}}|title=Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation, Second Edition|last2=Walther|first2=Andrea|publisher=SIAM|year=2008|isbn=978-0-89871-776-1|first1=Andreas|last1=Griewank}}&lt;/ref&gt; In 1973, Dreyfus used backpropagation to adapt [[parameter]]s of controllers in proportion to error gradients.&lt;ref name="dreyfus1973"&gt;{{cite journal|year=1973|title=The computational solution of optimal control problems with time lag|url=|journal=IEEE Transactions on Automatic Control|volume=18|issue=4|pages=383–385|doi=10.1109/tac.1973.1100330|last1=Dreyfus|first1=Stuart|authorlink=Stuart Dreyfus}}&lt;/ref&gt; In 1974, [[Paul Werbos|Werbos]] mentioned the possibility of applying this principle to Artificial neural networks,&lt;ref name="werbos1974"&gt;[[Paul Werbos]] (1974). Beyond regression: New tools for prediction and analysis in the behavioral sciences. PhD thesis, Harvard University.&lt;/ref&gt; and in 1982, he applied Linnainmaa's AD method to neural networks in the way that is widely used today.&lt;ref name="scholarpedia2"/&gt;&lt;ref name="werbos1982"&gt;{{Cite book|url=http://werbos.com/Neural/SensitivityIFIPSeptember1981.pdf|title=System modeling and optimization|last=Werbos|first=Paul|authorlink=Paul Werbos|publisher=Springer|year=1982|isbn=|location=|pages=762–770|chapter=Applications of advances in nonlinear sensitivity analysis}}&lt;/ref&gt; In 1986, [[David E. Rumelhart|Rumelhart]], Hinton and [[Ronald J. Williams|Williams]] noted that this method can generate useful internal representations of incoming data in hidden layers of neural networks.&lt;ref name=":4"&gt;{{Cite journal|last=Rumelhart|first=David E.|last2=Hinton|first2=Geoffrey E.|last3=Williams|first3=Ronald J.|title=Learning representations by back-propagating errors|url=http://www.nature.com/articles/Art323533a0|journal=Nature|volume=323|issue=6088|pages=533–536|doi=10.1038/323533a0|year=1986|bibcode=1986Natur.323..533R}}&lt;/ref&gt; In 1993, Wan was the first&lt;ref name="SCHIDHUB2"/&gt; to win an international pattern recognition contest through backpropagation.&lt;ref name="wan1993"&gt;Eric A. Wan (1993). "Time series prediction by using a connectionist network with internal delay lines." In ''Proceedings of the Santa Fe Institute Studies in the Sciences of Complexity'', '''15''': p. 195. Addison-Wesley Publishing Co.&lt;/ref&gt;

The weight updates of backpropagation can be done via [[stochastic gradient descent]] using the following equation:
: &lt;math&gt; w_{ij}(t + 1) = w_{ij}(t) + \eta\frac{\partial C}{\partial w_{ij}} +\xi(t) &lt;/math&gt;
where, &lt;math&gt; \eta &lt;/math&gt; is the learning rate, &lt;math&gt; C &lt;/math&gt; is the cost (loss) function and &lt;math&gt;\xi(t)&lt;/math&gt; a stochastic term. The choice of the cost function depends on factors such as the learning type (supervised, unsupervised, [[Reinforcement learning|reinforcement]], etc.) and the [[activation function]]. For example, when performing supervised learning on a [[multiclass classification]] problem, common choices for the activation function and cost function are the [[Softmax activation function|softmax]] function and [[cross entropy]] function, respectively. The softmax function is defined as &lt;math&gt; p_j = \frac{\exp(x_j)}{\sum_k \exp(x_k)} &lt;/math&gt; where &lt;math&gt; p_j &lt;/math&gt; represents the class probability (output of the unit &lt;math&gt; j &lt;/math&gt;) and &lt;math&gt; x_j &lt;/math&gt; and &lt;math&gt; x_k &lt;/math&gt; represent the total input to units &lt;math&gt; j &lt;/math&gt; and &lt;math&gt; k &lt;/math&gt; of the same level respectively. Cross entropy is defined as &lt;math&gt; C = -\sum_j d_j \log(p_j) &lt;/math&gt; where &lt;math&gt; d_j &lt;/math&gt; represents the target probability for output unit &lt;math&gt; j &lt;/math&gt; and &lt;math&gt; p_j &lt;/math&gt; is the probability output for &lt;math&gt; j &lt;/math&gt; after applying the activation function.&lt;ref&gt;{{Cite journal|last=Hinton|first=G.|last2=Deng|first2=L.|last3=Yu|first3=D.|last4=Dahl|first4=G. E.|last5=Mohamed|first5=A. r|last6=Jaitly|first6=N.|last7=Senior|first7=A.|last8=Vanhoucke|first8=V.|last9=Nguyen|first9=P.|date=November 2012|title=Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups|url=http://ieeexplore.ieee.org/document/6296526/|journal=IEEE Signal Processing Magazine|volume=29|issue=6|pages=82–97|doi=10.1109/msp.2012.2205597|issn=1053-5888|bibcode=2012ISPM...29...82H}}&lt;/ref&gt;

These can be used to output object [[Minimum bounding box|bounding boxes]] in the form of a binary mask. They are also used for multi-scale regression to increase localization precision. DNN-based regression can learn features that capture geometric information in addition to serving as a good classifier. They remove the requirement to explicitly model parts and their relations. This helps to broaden the variety of objects that can be learned. The model consists of multiple layers, each of which has a [[rectified linear unit]] as its activation function for non-linear transformation. Some layers are convolutional, while others are fully connected. Every convolutional layer has an additional max pooling. The network is trained to [[Minimum mean square error|minimize]] [[L2 norm|''L''&lt;sup&gt;2&lt;/sup&gt; error]] for predicting the mask ranging over the entire training set containing bounding boxes represented as masks.

Alternatives to backpropagation include [[Extreme Learning Machines]],&lt;ref&gt;{{cite journal|last2=Zhu|first2=Qin-Yu|last3=Siew|first3=Chee-Kheong|year=2006|title=Extreme learning machine: theory and applications|url=|journal=Neurocomputing|volume=70|issue=1|pages=489–501|doi=10.1016/j.neucom.2005.12.126|last1=Huang|first1=Guang-Bin|citeseerx=10.1.1.217.3692}}&lt;/ref&gt; "No-prop" networks,&lt;ref&gt;{{cite journal|year=2013|title=The no-prop algorithm: A new learning algorithm for multilayer neural networks|url=|journal=Neural Networks|volume=37|issue=|pages=182–188|doi=10.1016/j.neunet.2012.09.020|pmid=23140797|last1=Widrow|first1=Bernard|display-authors=etal}}&lt;/ref&gt; training without backtracking,&lt;ref&gt;{{cite arXiv|eprint=1507.07680|first=Yann|last=Ollivier|first2=Guillaume|last2=Charpiat|title=Training recurrent networks without backtracking|year=2015|class=cs.NE}}&lt;/ref&gt; "weightless" networks,&lt;ref&gt;ESANN. 2009&lt;/ref&gt;&lt;ref name="RBMTRAIN"&gt;{{Cite journal|last=Hinton|first=G. E.|date=2010|title=A Practical Guide to Training Restricted Boltzmann Machines|url=https://www.researchgate.net/publication/221166159|journal=Tech. Rep. UTML TR 2010-003|volume=|pages=|via=}}&lt;/ref&gt; and [[Holographic associative memory|non-connectionist neural networks]].

===Learning paradigms===
The three major learning paradigms each correspond to a particular learning task. These are [[supervised learning]], [[unsupervised learning]] and [[reinforcement learning]].

==== Supervised learning ====
[[Supervised learning]] uses a set of example pairs &lt;math&gt; (x, y), x \in X, y \in Y&lt;/math&gt; and the aim is to find a function &lt;math&gt; f : X \rightarrow Y &lt;/math&gt; in the allowed class of functions that matches the examples. In other words, we wish to infer the mapping implied by the data; the cost function is related to the mismatch between our mapping and the data and it implicitly contains prior knowledge about the problem domain.&lt;ref&gt;{{Cite journal|last=Ojha|first=Varun Kumar|last2=Abraham|first2=Ajith|last3=Snášel|first3=Václav|date=2017-04-01|title=Metaheuristic design of feedforward neural networks: A review of two decades of research|url=http://www.sciencedirect.com/science/article/pii/S0952197617300234|journal=Engineering Applications of Artificial Intelligence|volume=60|pages=97–116|doi=10.1016/j.engappai.2017.01.013|arxiv=1705.05584}}&lt;/ref&gt;

A commonly used cost is the [[mean-squared error]], which tries to minimize the average squared error between the network's output, &lt;math&gt; f(x)&lt;/math&gt;, and the target value &lt;math&gt; y&lt;/math&gt; over all the example pairs. Minimizing this cost using [[gradient descent]] for the class of neural networks called [[multilayer perceptron]]s (MLP), produces the [[Backpropagation|backpropagation algorithm]] for training neural networks.

Tasks that fall within the paradigm of supervised learning are [[pattern recognition]] (also known as classification) and [[Regression analysis|regression]] (also known as function approximation). The supervised learning paradigm is also applicable to sequential data (e.g., for hand writing, speech and gesture recognition). This can be thought of as learning with a "teacher", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.

====Unsupervised learning====
In [[unsupervised learning]], some data &lt;math&gt;\textstyle x&lt;/math&gt; is given and the cost function to be minimized, that can be any function of the data &lt;math&gt;\textstyle x&lt;/math&gt; and the network's output, &lt;math&gt;\textstyle f&lt;/math&gt;.

The cost function is dependent on the task (the model domain) and any ''[[A priori and a posteriori|a priori]]'' assumptions (the implicit properties of the model, its parameters and the observed variables).

As a trivial example, consider the model &lt;math&gt;\textstyle f(x) = a&lt;/math&gt; where &lt;math&gt;\textstyle a&lt;/math&gt; is a constant and the cost &lt;math&gt;\textstyle C=E[(x - f(x))^2]&lt;/math&gt;. Minimizing this cost produces a value of &lt;math&gt;\textstyle a&lt;/math&gt; that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in [[Data compression|compression]] it could be related to the [[mutual information]] between &lt;math&gt;\textstyle x&lt;/math&gt; and &lt;math&gt;\textstyle f(x)&lt;/math&gt;, whereas in statistical modeling, it could be related to the [[posterior probability]] of the model given the data (note that in both of those examples those quantities would be maximized rather than minimized).

Tasks that fall within the paradigm of unsupervised learning are in general [[Approximation|estimation]] problems; the applications include [[Data clustering|clustering]], the estimation of [[statistical distributions]], [[Data compression|compression]] and [[Bayesian spam filtering|filtering]].

====Reinforcement learning====
{{See also|Stochastic control}}

In [[reinforcement learning]], data &lt;math&gt;\textstyle x&lt;/math&gt; are usually not given, but generated by an agent's interactions with the environment. At each point in time &lt;math&gt;\textstyle t&lt;/math&gt;, the agent performs an action &lt;math&gt;\textstyle y_t&lt;/math&gt; and the environment generates an observation &lt;math&gt;\textstyle x_t&lt;/math&gt; and an instantaneous cost &lt;math&gt;\textstyle c_t&lt;/math&gt;, according to some (usually unknown) dynamics. The aim is to discover a policy for selecting actions that minimizes some measure of a long-term cost, e.g., the expected cumulative cost. The environment's dynamics and the long-term cost for each policy are usually unknown, but can be estimated.

More formally the environment is modeled as a [[Markov decision process]] (MDP) with states &lt;math&gt;\textstyle {s_1,...,s_n}\in S &lt;/math&gt; and actions &lt;math&gt;\textstyle {a_1,...,a_m} \in A&lt;/math&gt; with the following probability distributions: the instantaneous cost distribution &lt;math&gt;\textstyle P(c_t|s_t)&lt;/math&gt;, the observation distribution &lt;math&gt;\textstyle P(x_t|s_t)&lt;/math&gt; and the transition &lt;math&gt;\textstyle P(s_{t+1}|s_t, a_t)&lt;/math&gt;, while a policy is defined as the conditional distribution over actions given the observations. Taken together, the two then define a [[Markov chain]] (MC). The aim is to discover the policy (i.e., the MC) that minimizes the cost.

Artificial neural networks are frequently used in reinforcement learning as part of the overall algorithm.&lt;ref&gt;{{cite conference| author = Dominic, S. |author2=Das, R. |author3=Whitley, D. |author4=Anderson, C. |date=July 1991 | title = Genetic reinforcement learning for neural networks | conference = IJCNN-91-Seattle International Joint Conference on Neural Networks | booktitle = IJCNN-91-Seattle International Joint Conference on Neural Networks | publisher = IEEE | location = Seattle, Washington, USA  | doi = 10.1109/IJCNN.1991.155315 | isbn = 0-7803-0164-1 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Hoskins |first=J.C. |author2=Himmelblau, D.M. |title=Process control via artificial neural networks and reinforcement learning |journal=Computers &amp; Chemical Engineering |year=1992 |volume=16 |pages=241–251 |doi=10.1016/0098-1354(92)80045-B |issue=4}}&lt;/ref&gt; [[Dynamic programming]] was coupled with Artificial neural networks (giving neurodynamic programming) by [[Dimitri Bertsekas|Bertsekas]] and Tsitsiklis&lt;ref&gt;{{cite book|url=https://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images|title=Neuro-dynamic programming|first=D.P.|first2=J.N.|publisher=Athena Scientific|year=1996|isbn=978-1-886529-10-6|location=|page=512|author=Bertsekas|author2=Tsitsiklis}}&lt;/ref&gt; and applied to multi-dimensional nonlinear problems such as those involved in [[vehicle routing]],&lt;ref&gt;{{cite journal |last=Secomandi |first=Nicola |title=Comparing neuro-dynamic programming algorithms for the vehicle routing problem with stochastic demands |journal=Computers &amp; Operations Research |year=2000 |volume=27 |pages=1201–1225 |doi=10.1016/S0305-0548(99)00146-X |issue=11–12|citeseerx=10.1.1.392.4034 }}&lt;/ref&gt; [[natural resource management|natural resources management]]&lt;ref&gt;{{cite conference| author = de Rigo, D. |author2=Rizzoli, A. E. |author3=Soncini-Sessa, R. |author4=Weber, E. |author5=Zenesi, P. | year = 2001 | title = Neuro-dynamic programming for the efficient management of reservoir networks | conference = MODSIM 2001, International Congress on Modelling and Simulation | conferenceurl = http://www.mssanz.org.au/MODSIM01/MODSIM01.htm | booktitle = Proceedings of MODSIM 2001, International Congress on Modelling and Simulation | publisher = Modelling and Simulation Society of Australia and New Zealand | location = Canberra, Australia | doi = 10.5281/zenodo.7481  | accessdate = 29 July 2012 | isbn = 0-867405252 }}&lt;/ref&gt;&lt;ref&gt;{{cite conference| author = Damas, M. |author2=Salmeron, M. |author3=Diaz, A. |author4=Ortega, J. |author5=Prieto, A. |author6=Olivares, G.| year = 2000 | title = Genetic algorithms and neuro-dynamic programming: application to water supply networks | conference = 2000 Congress on Evolutionary Computation | booktitle = Proceedings of 2000 Congress on Evolutionary Computation | publisher = IEEE | location = La Jolla, California, USA | doi = 10.1109/CEC.2000.870269 | isbn = 0-7803-6375-2  }}&lt;/ref&gt; or [[medicine]]&lt;ref&gt;{{Cite book |last=Deng |first=Geng |author2=Ferris, M.C. |title=Neuro-dynamic programming for fractionated radiotherapy planning |year=2008 |volume=12 |pages=47–70 |doi=10.1007/978-0-387-73299-2_3|citeseerx=10.1.1.137.8288 |series=Springer Optimization and Its Applications |isbn=978-0-387-73298-5 }}&lt;/ref&gt; because of the ability of Artificial neural networks to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of the original control problems.

Tasks that fall within the paradigm of reinforcement learning are control problems, [[game]]s and other sequential decision making tasks.

===Learning algorithms===
{{See also|Machine learning}}

Training a neural network model essentially means selecting one model from the set of allowed models (or, in a [[Bayesian probability|Bayesian]] framework, determining a distribution over the set of allowed models) that minimizes the cost. Numerous algorithms are available for training neural network models; most of them can be viewed as a straightforward application of [[Mathematical optimization|optimization]] theory and [[statistical estimation]].

Most employ some form of [[gradient descent]], using backpropagation to compute the actual gradients. This is done by simply taking the derivative of the cost function with respect to the network parameters and then changing those parameters in a [[gradient-related]] direction. Backpropagation training algorithms fall into three categories:

*[[Gradient descent|steepest descent]] (with variable learning rate and [[Gradient descent#The momentum method|momentum]], [[Rprop|resilient backpropagation]]);
* quasi-Newton ([[Broyden–Fletcher–Goldfarb–Shanno algorithm|Broyden-Fletcher-Goldfarb-Shanno]], [[Secant method|one step secant]]);
*[[Levenberg–Marquardt algorithm|Levenberg-Marquardt]] and [[Conjugate gradient method|conjugate gradient]] (Fletcher-Reeves update, Polak-Ribiére update, Powell-Beale restart, scaled conjugate gradient).&lt;ref&gt;{{cite conference|author1=M. Forouzanfar |author2=H. R. Dajani |author3=V. Z. Groza |author4=M. Bolic |author5=S. Rajan  |last-author-amp=yes |date=July 2010 | title = Comparison of Feed-Forward Neural Network Training Algorithms for Oscillometric Blood Pressure Estimation | conference = 4th Int. Workshop Soft Computing Applications | publisher = IEEE| location = Arad, Romania |url=https://www.researchgate.net/profile/Mohamad_Forouzanfar/publication/224173336_Comparison_of_Feed-Forward_Neural_Network_training_algorithms_for_oscillometric_blood_pressure_estimation/links/00b7d533829c3a7484000000.pdf?ev=pub_int_doc_dl&amp;origin=publication_detail&amp;inViewer=true&amp;msrp=TyT96%2BjWOHJo%2BVhkMF4IzwHPAImSd442n%2BAkEuXj9qBmQSZ495CpxqlaOYon%2BSlEzWQElBGyJmbBCiiUOV8ImeEqPFXiIRivcrWsWmlPBYU%3D }}&lt;/ref&gt;

[[Evolutionary methods]],&lt;ref&gt;{{cite conference| author1 = de Rigo, D. | author2 = Castelletti, A. | author3 = Rizzoli, A. E. | author4 = Soncini-Sessa, R. | author5 = Weber, E. |date=January 2005 | title = A selective improvement technique for fastening Neuro-Dynamic Programming in Water Resources Network Management | conference = 16th IFAC World Congress | conferenceurl = http://www.nt.ntnu.no/users/skoge/prost/proceedings/ifac2005/Index.html | booktitle = Proceedings of the 16th IFAC World Congress – IFAC-PapersOnLine | editor = Pavel Zítek | volume = 16 | publisher = IFAC | location = Prague, Czech Republic | url = http://www.nt.ntnu.no/users/skoge/prost/proceedings/ifac2005/Papers/Paper4269.html
 | accessdate = 30 December 2011 | doi = 10.3182/20050703-6-CZ-1902.02172 | isbn = 978-3-902661-75-3 }}&lt;/ref&gt; [[gene expression programming]],&lt;ref&gt;{{cite web|last=Ferreira|first=C.|year=2006|title=Designing Neural Networks Using Gene Expression Programming|url= http://www.gene-expression-programming.com/webpapers/Ferreira-ASCT2006.pdf|publisher= In A. Abraham, B. de Baets, M. Köppen, and B. Nickolay, eds., Applied Soft Computing Technologies: The Challenge of Complexity, pages 517–536, Springer-Verlag}}&lt;/ref&gt; [[simulated annealing]],&lt;ref&gt;{{cite conference| author = Da, Y. |author2=Xiurun, G. |date=July 2005 | title = An improved PSO-based ANN with simulated annealing technique | conference = New Aspects in Neurocomputing: 11th European Symposium on Artificial Neural Networks | conferenceurl = http://www.dice.ucl.ac.be/esann/proceedings/electronicproceedings.htm | editor = T. Villmann | publisher = Elsevier | doi = 10.1016/j.neucom.2004.07.002 }}&lt;!--| accessdate = 30 December 2011 --&gt;&lt;/ref&gt; [[expectation-maximization]], [[non-parametric methods]] and [[particle swarm optimization]]&lt;ref&gt;{{cite conference| author = Wu, J. |author2=Chen, E. |date=May 2009 | title = A Novel Nonparametric Regression Ensemble for Rainfall Forecasting Using Particle Swarm Optimization Technique Coupled with Artificial Neural Network | conference = 6th International Symposium on Neural Networks, ISNN 2009 | conferenceurl = http://www2.mae.cuhk.edu.hk/~isnn2009/ | editors = Wang, H., Shen, Y., Huang, T., Zeng, Z. | publisher = Springer | doi = 10.1007/978-3-642-01513-7-6 | isbn = 978-3-642-01215-0 }}&lt;!--| accessdate = 1 January 2012 --&gt;&lt;/ref&gt; are other methods for training neural networks.

==== Convergent recursive learning algorithm ====
This is a learning method specially designed for [[cerebellar model articulation controller]] (CMAC) neural networks. In 2004, a recursive least squares algorithm was introduced to train [[cerebellar model articulation controller|CMAC]] neural network online.&lt;ref name="Qin1"&gt;Ting Qin, et al. "A learning algorithm of CMAC based on RLS." Neural Processing Letters 19.1 (2004): 49–61.&lt;/ref&gt; This algorithm can converge in one step and update all weights in one step with any new input data. Initially, this algorithm had [[Computational complexity theory|computational complexity]] of ''O''(''N''&lt;sup&gt;3&lt;/sup&gt;). Based on [[QR decomposition]], this recursive learning algorithm was simplified to be ''O''(''N'').&lt;ref name="Qin2"&gt;Ting Qin, et al. "Continuous CMAC-QRLS and its systolic array." Neural Processing Letters 22.1 (2005): 1–16.&lt;/ref&gt;

==Optimization==
The optimization algorithm repeats a two phase cycle, propagation and weight update. When an input vector is presented to the network, it is propagated forward through the network, layer by layer, until it reaches the output layer. The output of the network is then compared to the desired output, using a [[loss function]]. The resulting error value is calculated for each of the neurons in the output layer. The error values are then propagated from the output back through the network, until each neuron has an associated error value that reflects its contribution to the original output.

Backpropagation uses these error values to calculate the gradient of the loss function. In the second phase, this gradient is fed to the optimization method, which in turn uses it to update the weights, in an attempt to minimize the loss function.

===Algorithm===
Let &lt;math&gt;N&lt;/math&gt; be a [[neural network]] with &lt;math&gt;e&lt;/math&gt; connections, &lt;math&gt;m&lt;/math&gt; inputs, and &lt;math&gt;n&lt;/math&gt; outputs.

Below, &lt;math&gt;x_1,x_2,\dots&lt;/math&gt; will denote vectors in &lt;math&gt;\mathbb{R}^m&lt;/math&gt;, &lt;math&gt;y_1,y_2,\dots&lt;/math&gt; vectors in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, and &lt;math&gt;w_0, w_1, w_2, \ldots&lt;/math&gt; vectors in &lt;math&gt;\mathbb{R}^e&lt;/math&gt;. 
These are called ''inputs'', ''outputs'' and ''weights'' respectively.

The [[neural network]] corresponds to a function &lt;math&gt;y = f_N(w, x)&lt;/math&gt; which, given a weight &lt;math&gt;w&lt;/math&gt;, maps an input &lt;math&gt;x&lt;/math&gt; to an output &lt;math&gt;y&lt;/math&gt;.

The optimization takes as input a sequence of ''training examples'' &lt;math&gt;(x_1,y_1), \dots, (x_p, y_p)&lt;/math&gt; and produces a sequence of weights &lt;math&gt;w_0, w_1, \dots, w_p&lt;/math&gt; starting from some initial weight &lt;math&gt;w_0&lt;/math&gt;, usually chosen at random.

These weights are computed in turn: first compute &lt;math&gt;w_i&lt;/math&gt; using only &lt;math&gt;(x_i, y_i, w_{i-1})&lt;/math&gt; for &lt;math&gt;i = 1, \dots, p&lt;/math&gt;. The output of the algorithm is then &lt;math&gt;w_p&lt;/math&gt;, giving us a new function &lt;math&gt;x \mapsto f_N(w_p, x)&lt;/math&gt;. The computation is the same in each step, hence only the case &lt;math&gt;i = 1&lt;/math&gt; is described.

Calculating &lt;math&gt;w_1&lt;/math&gt; from &lt;math&gt;(x_1, y_1, w_0)&lt;/math&gt; is done by considering a variable weight &lt;math&gt;w&lt;/math&gt; and applying [[gradient descent]] to the function &lt;math&gt;w\mapsto E(f_N(w, x_1), y_1)&lt;/math&gt; to find a local minimum, 
starting at &lt;math&gt;w = w_0&lt;/math&gt;.

This makes &lt;math&gt;w_1&lt;/math&gt; the minimizing weight found by gradient descent.

==Algorithm in code==
{{Tone|date=December 2016}}

To implement the algorithm above, explicit formulas are required for the gradient of the function &lt;math&gt;w \mapsto E(f_N(w, x), y)&lt;/math&gt; where the function is &lt;math&gt;E(y,y')= |y-y'|^2&lt;/math&gt;.

The learning algorithm can be divided into two phases: propagation and weight update.

===Phase 1: propagation===
Each propagation involves the following steps:

# Propagation forward through the network to generate the output value(s)
# Calculation of the cost (error term)
# Propagation of the output activations back through the network using the training pattern target to generate the deltas (the difference between the targeted and actual output values) of all output and hidden neurons.

===Phase 2: weight update===
For each weight, the following steps must be followed:

# The weight's output delta and input activation are multiplied to find the gradient of the weight.
# A ratio (percentage) of the weight's gradient is subtracted from the weight.
This ratio (percentage) influences the speed and quality of learning; it is called the ''learning rate''. The greater the ratio, the faster the neuron trains, but the lower the ratio, the more accurate the training is. The sign of the gradient of a weight indicates whether the error varies directly with, or inversely to, the weight. Therefore, the weight must be updated in the opposite direction, "descending" the gradient.

Learning is repeated (on new batches) until the network performs adequately.

===Pseudocode===
The following is [[pseudocode]] for a [[stochastic gradient descent]] algorithm for training a three-layer network (only one hidden layer):

   initialize network weights (often small random values)
   '''do'''
      '''forEach''' training example named ex
         prediction = &lt;u&gt;neural-net-output&lt;/u&gt;(network, ex)  ''// forward pass''
         actual = &lt;u&gt;teacher-output&lt;/u&gt;(ex)
         compute error (prediction - actual) at the output units
         {{nowrap|compute &lt;math&gt;\Delta w_h&lt;/math&gt; for all weights from hidden layer to output layer}}  ''// backward pass''
         {{nowrap|compute &lt;math&gt;\Delta w_i&lt;/math&gt; for all weights from input layer to hidden layer}}   ''// backward pass continued''
         update network weights ''// input layer not modified by error estimate''
   '''until''' all examples classified correctly or another stopping criterion satisfied
   '''return''' the network

The lines labeled "backward pass" can be implemented using the backpropagation algorithm, which calculates the gradient of the error of the network regarding the network's modifiable weights.&lt;ref&gt;Werbos, Paul J. (1994). ''The Roots of Backpropagation''. From Ordered Derivatives to Neural Networks and Political Forecasting. New York, NY: John Wiley &amp; Sons, Inc.&lt;/ref&gt;

==Extension==
The choice of learning rate &lt;math display="inline"&gt;\eta&lt;/math&gt; is important, since a high value can cause too strong a change, causing the minimum to be missed, while a too low learning rate slows the training unnecessarily.

Optimizations such as [[Quickprop]] are primarily aimed at speeding up error minimization; other improvements mainly try to increase reliability.

===Adaptive learning rate===
In order to avoid oscillation inside the network such as alternating connection weights, and to improve the rate of convergence, refinements of this algorithm use an adaptive learning rate.&lt;ref&gt;{{Cite book|last=Li|first=Y.|last2=Fu|first2=Y.|last3=Li|first3=H.|last4=Zhang|first4=S. W.|date=2009-06-01|title=The Improved Training Algorithm of Back Propagation Neural Network with Self-adaptive Learning Rate|url=http://ieeexplore.ieee.org/document/5231496/|journal=2009 International Conference on Computational Intelligence and Natural Computing|volume=1|pages=73–76|doi=10.1109/CINC.2009.111|isbn=978-0-7695-3645-3}}&lt;/ref&gt;

===Inertia===
By using a variable inertia term ''(Momentum)'' &lt;math display="inline"&gt;\alpha&lt;/math&gt; the gradient and the last change can be weighted such that the weight adjustment additionally depends on the previous change. If the ''Momentum'' &lt;math display="inline"&gt;\alpha&lt;/math&gt; is equal to 0, the change depends solely on the gradient, while a value of 1 will only depend on the last change.

Similar to a ball rolling down a mountain, whose current speed is determined not only by the current slope of the mountain but also by its own inertia, inertia can be added:&lt;math display="block"&gt;\Delta w_{ij} (t + 1) = (1- \alpha) \eta \delta_j o_i+\alpha\,\Delta w_{ij}(t)&lt;/math&gt;where:

: &lt;math display="inline"&gt;\Delta w_{ij} (t + 1)&lt;/math&gt; is the change in weight &lt;math display="inline"&gt;w_{ij} (t + 1)&lt;/math&gt; in the connection of neuron &lt;math display="inline"&gt;i&lt;/math&gt; to neuron &lt;math display="inline"&gt;j&lt;/math&gt; at time &lt;math display="inline"&gt;(t + 1),&lt;/math&gt;
: &lt;math display="inline"&gt;\eta&lt;/math&gt; a learning rate (&lt;math display="inline"&gt;\eta &lt; 0),&lt;/math&gt;
: &lt;math display="inline"&gt;\delta_j&lt;/math&gt; the error signal of neuron &lt;math display="inline"&gt;j&lt;/math&gt; and
: &lt;math display="inline"&gt;o_i&lt;/math&gt; the output of neuron &lt;math display="inline"&gt;i&lt;/math&gt;, which is also an input of the current neuron (neuron &lt;math display="inline"&gt;j&lt;/math&gt;),
: &lt;math display="inline"&gt;\alpha&lt;/math&gt; the influence of the inertial term &lt;math display="inline"&gt;\Delta w_{ij} (t)&lt;/math&gt; (in &lt;math display="inline"&gt;[0,1]&lt;/math&gt;). This corresponds to the weight change at the previous point in time.
Inertia makes the current weight change &lt;math display="inline"&gt;(t + 1)&lt;/math&gt; depend both on the current gradient of the error function (slope of the mountain, 1st summand), as well as on the weight change from the previous point in time (inertia, 2nd summand).

With inertia, the problems of getting stuck (in steep ravines and flat plateaus) are avoided. Since, for example, the gradient of the error function becomes very small in flat plateaus, a plateau would immediately lead to a "deceleration" of the gradient descent. This deceleration is delayed by the addition of the inertia term so that a flat plateau can be escaped more quickly. 

==Modes of learning==
Two modes of learning are available: [[stochastic gradient descent|stochastic]] and batch. In stochastic learning, each input creates a weight adjustment. In batch learning weights are adjusted based on a batch of inputs, accumulating errors over the batch. Stochastic learning introduces "noise" into the gradient descent process, using the local gradient calculated from one data point; this reduces the chance of the network getting stuck in local minima. However, batch learning typically yields a faster, more stable descent to a local minimum, since each update is performed in the direction of the average error of the batch. A common compromise choice is to use "mini-batches", meaning small batches and with samples in each batch selected stochastically from the entire data set.

== Variants ==

=== Group method of data handling ===
{{Main|Group method of data handling}}The Group Method of Data Handling (GMDH)&lt;ref name="ivak1968"&gt;{{cite journal|year=1968|title=The group method of data handling – a rival of the method of stochastic approximation|url=|journal=Soviet Automatic Control|volume=13|issue=3|pages=43–55|last1=Ivakhnenko|first1=Alexey Grigorevich|authorlink=Alexey Grigorevich Ivakhnenko|title-link=group method of data handling}}&lt;/ref&gt; features fully automatic structural and parametric model optimization. The node activation functions are [[Andrey Kolmogorov|Kolmogorov]]-Gabor polynomials that permit additions and multiplications. It used a deep feedforward multilayer perceptron with eight layers.&lt;ref name="ivak1971"&gt;{{Cite journal|last=Ivakhnenko|first=Alexey|date=1971|title=Polynomial theory of complex systems|url=|journal=IEEE Transactions on Systems, Man and Cybernetics (4)|issue=4|pages=364–378|doi=10.1109/TSMC.1971.4308320|pmid=|access-date=}}&lt;/ref&gt; It is a [[supervised learning]] network that grows layer by layer, where each layer is trained by [[regression analysis]]. Useless items are detected using a validation set, and pruned through [[Regularization (mathematics)|regularization]]. The size and depth of the resulting network depends on the task.&lt;ref name="kondo2008"&gt;{{cite journal|last2=Ueno|first2=J.|year=2008|title=Multi-layered GMDH-type neural network self-selecting optimum neural network architecture and its application to 3-dimensional medical image recognition of blood vessels|url=https://www.researchgate.net/publication/228402366|journal=International Journal of Innovative Computing, Information and Control|volume=4|issue=1|pages=175–187|via=|last1=Kondo|first1=T.}}&lt;/ref&gt;

=== Convolutional neural networks ===
{{main|Convolutional neural network}}A convolutional neural network (CNN) is a class of deep, feed-forward networks, composed of one or more [[convolution]]al layers with fully connected layers (matching those in typical Artificial neural networks) on top. It uses tied weights and pooling layers. In particular, max-pooling&lt;ref name="Weng19932"/&gt; is often structured via Fukushima's convolutional architecture.&lt;ref name="FUKU1980"&gt;{{cite journal|year=1980|title=Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position|url=|journal=Biol. Cybern.|volume=36|issue=4|pages=193–202|doi=10.1007/bf00344251|pmid=7370364|last1=Fukushima|first1=K.}}&lt;/ref&gt; This architecture allows CNNs to take advantage of the 2D structure of input data.

CNNs are suitable for processing visual and other two-dimensional data.&lt;ref name="LECUN1989"&gt;LeCun ''et al.'', "Backpropagation Applied to Handwritten Zip Code Recognition," ''Neural Computation'', 1, pp. 541–551, 1989.&lt;/ref&gt;&lt;ref name="lecun2016slides"&gt;[[Yann LeCun]] (2016). Slides on Deep Learning [https://indico.cern.ch/event/510372/ Online]&lt;/ref&gt; They have shown superior results in both image and speech applications. They can be trained with standard backpropagation. CNNs are easier to train than other regular, deep, feed-forward neural networks and have many fewer parameters to estimate.&lt;ref name="STANCNN"&gt;{{cite web|url=http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/|title=Unsupervised Feature Learning and Deep Learning Tutorial|publisher=}}&lt;/ref&gt; Examples of applications in computer vision include [[DeepDream]]&lt;ref name="deepdream"&gt;{{Cite book|last2=Liu|first2=Wei|last3=Jia|first3=Yangqing|last4=Sermanet|first4=Pierre|last5=Reed|first5=Scott|last6=Anguelov|first6=Dragomir|last7=Erhan|first7=Dumitru|last8=Vanhoucke|first8=Vincent|last9=Rabinovich|first9=Andrew|year=2014|title=Going Deeper with Convolutions|journal=Computing Research Repository|volume=|pages=1|arxiv=1409.4842|doi=10.1109/CVPR.2015.7298594|first1=Christian|last1=Szegedy|isbn=978-1-4673-6964-0}}&lt;/ref&gt; and [[robot navigation]].&lt;ref&gt;{{cite journal | last=Ran | first=Lingyan | last2=Zhang | first2=Yanning | last3=Zhang | first3=Qilin | last4=Yang | first4=Tao | title=Convolutional Neural Network-Based Robot Navigation Using Uncalibrated Spherical Images | journal=Sensors | volume=17 | issue=6 | date=2017-06-12 | issn=1424-8220 | doi=10.3390/s17061341 | pmid=28604624 | pmc=5492478 | page=1341 | url=https://qilin-zhang.github.io/_pages/pdfs/sensors-17-01341.pdf}}&lt;/ref&gt;

A recent development has been that of [[Capsule neural network|Capsule Neural Network]] (CapsNet), the idea behind which is to add structures called capsules to a CNN and to reuse output from several of those capsules to form more stable (with respect to various perturbations) representations for higher order capsules.&lt;ref&gt;{{Citation|last=Hinton|first=Geoffrey E.|title=Transforming Auto-Encoders|date=2011|work=Lecture Notes in Computer Science|pages=44–51|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/978-3-642-21735-7_6|isbn=9783642217340|last2=Krizhevsky|first2=Alex|last3=Wang|first3=Sida D.|citeseerx=10.1.1.220.5099}}&lt;/ref&gt;

=== Long short-term memory ===
{{main|Long short-term memory}}Long short-term memory (LSTM) networks are RNNs that avoid the [[vanishing gradient problem]].&lt;ref name=":03"&gt;{{Cite journal|last=Hochreiter|first=Sepp|author-link=Sepp Hochreiter|last2=Schmidhuber|first2=Jürgen|author-link2=Jürgen Schmidhuber|date=1997-11-01|title=Long Short-Term Memory|journal=Neural Computation|volume=9|issue=8|pages=1735–1780|doi=10.1162/neco.1997.9.8.1735|issn=0899-7667}}&lt;/ref&gt; LSTM is normally augmented by recurrent gates called forget gates.&lt;ref name=":10"&gt;{{Cite journal|url=https://www.researchgate.net/publication/220320057|title=Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)|journal=Crossref Listing of Deleted Dois|volume=1|language=en|access-date=2017-06-13|pp=115–143|doi=10.1162/153244303768966139|year=2000}}&lt;/ref&gt; LSTM networks prevent backpropagated errors from vanishing or exploding.&lt;ref name="HOCH19912"/&gt; Instead errors can flow backwards through unlimited numbers of virtual layers in space-unfolded LSTM. That is, LSTM can learn "very deep learning" tasks&lt;ref name="SCHIDHUB2" /&gt; that require memories of events that happened thousands or even millions of discrete time steps ago. Problem-specific LSTM-like topologies can be evolved.&lt;ref&gt;{{Cite book|last=Bayer|first=Justin|last2=Wierstra|first2=Daan|last3=Togelius|first3=Julian|last4=Schmidhuber|first4=Jürgen|date=2009-09-14|title=Evolving Memory Cell Structures for Sequence Learning|journal=Artificial Neural Networks – ICANN 2009|volume=5769|language=en|publisher=Springer, Berlin, Heidelberg|pages=755–764|doi=10.1007/978-3-642-04277-5_76|series=Lecture Notes in Computer Science|isbn=978-3-642-04276-8}}&lt;/ref&gt; LSTM can handle long delays and signals that have a mix of low and high frequency components.

Stacks of LSTM RNNs&lt;ref&gt;{{Cite journal|last=Fernández|first=Santiago|last2=Graves|first2=Alex|last3=Schmidhuber|first3=Jürgen|date=2007|title=Sequence labelling in structured domains with hierarchical recurrent neural networks|journal=In Proc. 20th Int. Joint Conf. On Artificial In℡ligence, Ijcai 2007|pages=774–779|citeseerx=10.1.1.79.1887}}&lt;/ref&gt; trained by Connectionist Temporal Classification (CTC)&lt;ref name=":12"&gt;{{Cite journal|last=Graves|first=Alex|last2=Fernández|first2=Santiago|last3=Gomez|first3=Faustino|date=2006|title=Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks|journal=In Proceedings of the International Conference on Machine Learning, ICML 2006|pages=369–376|citeseerx=10.1.1.75.6306}}&lt;/ref&gt; can find an RNN weight matrix that maximizes the probability of the label sequences in a training set, given the corresponding input sequences. CTC achieves both alignment and recognition.

In 2003, LSTM started to become competitive with traditional speech recognizers.&lt;ref name="graves2003"&gt;{{Cite web|url=Ftp://ftp.idsia.ch/pub/juergen/bioadit2004.pdf|title=Biologically Plausible Speech Recognition with LSTM Neural Nets|last=Graves|first=Alex|last2=Eck|first2=Douglas|date=2003|website=1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland|pages=175–184|access-date=|last3=Beringer|first3=Nicole|last4=Schmidhuber|first4=Jürgen|authorlink4=Jürgen Schmidhuber}}&lt;/ref&gt; In 2007, the combination with CTC achieved first good results on speech data.&lt;ref name="fernandez2007keyword"&gt;{{Cite book|last=Fernández|first=Santiago|last2=Graves|first2=Alex|last3=Schmidhuber|first3=Jürgen|date=2007|title=An Application of Recurrent Neural Networks to Discriminative Keyword Spotting|url=http://dl.acm.org/citation.cfm?id=1778066.1778092|journal=Proceedings of the 17th International Conference on Artificial Neural Networks|series=ICANN'07|location=Berlin, Heidelberg|publisher=Springer-Verlag|pages=220–229|isbn=978-3540746935}}&lt;/ref&gt; In 2009, a CTC-trained LSTM was the first RNN to win pattern recognition contests, when it won several competitions in connected [[handwriting recognition]].&lt;ref name="SCHIDHUB2" /&gt;&lt;ref name="graves20093"/&gt; In 2014, [[Baidu]] used CTC-trained RNNs to break the Switchboard Hub5'00 speech recognition benchmark, without traditional speech processing methods.&lt;ref name="hannun2014"&gt;{{cite arxiv|last=Hannun|first=Awni|last2=Case|first2=Carl|last3=Casper|first3=Jared|last4=Catanzaro|first4=Bryan|last5=Diamos|first5=Greg|last6=Elsen|first6=Erich|last7=Prenger|first7=Ryan|last8=Satheesh|first8=Sanjeev|last9=Sengupta|first9=Shubho|date=2014-12-17|title=Deep Speech: Scaling up end-to-end speech recognition|eprint=1412.5567|class=cs.CL}}&lt;/ref&gt; LSTM also improved large-vocabulary speech recognition,&lt;ref name="sak2014"&gt;{{Cite web|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf|title=Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling|last=Sak|first=Hasim|last2=Senior|first2=Andrew|date=2014|website=|access-date=|last3=Beaufays|first3=Francoise}}&lt;/ref&gt;&lt;ref name="liwu2015"&gt;{{cite arxiv|last=Li|first=Xiangang|last2=Wu|first2=Xihong|date=2014-10-15|title=Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition|eprint=1410.4281|class=cs.CL}}&lt;/ref&gt; text-to-speech synthesis,&lt;ref&gt;{{Cite journal|url=https://www.researchgate.net/publication/287741874|title=TTS synthesis with bidirectional LSTM based Recurrent Neural Networks|pages=1964–1968|last=Fan|first=Y.|last2=Qian|first2=Y.|date=2014|journal=Proceedings of the Annual Conference of the International Speech Communication Association, Interspeech|language=en|access-date=2017-06-13|last3=Xie|first3=F.|last4=Soong|first4=F. K.}}&lt;/ref&gt; for [[Google Android]],&lt;ref name="scholarpedia2"/&gt;&lt;ref name="zen2015"&gt;{{Cite web|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43266.pdf|title=Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis|last=Zen|first=Heiga|last2=Sak|first2=Hasim|date=2015|website=Google.com|publisher=ICASSP|pages=4470–4474|access-date=}}&lt;/ref&gt; and photo-real talking heads.&lt;ref name="fan2015"&gt;{{Cite journal|last=Fan|first=Bo|last2=Wang|first2=Lijuan|last3=Soong|first3=Frank K.|last4=Xie|first4=Lei|date=2015|title=Photo-Real Talking Head with Deep Bidirectional LSTM|url=https://www.microsoft.com/en-us/research/wp-content/uploads/2015/04/icassp2015_fanbo_1009.pdf|journal=Proceedings of ICASSP|volume=|pages=|via=}}&lt;/ref&gt; In 2015, Google's speech recognition experienced a 49% improvement through CTC-trained LSTM.&lt;ref name="sak2015"&gt;{{Cite web|url=http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html|title=Google voice search: faster and more accurate|last=Sak|first=Haşim|last2=Senior|first2=Andrew|date=September 2015|website=|access-date=|last3=Rao|first3=Kanishka|last4=Beaufays|first4=Françoise|last5=Schalkwyk|first5=Johan}}&lt;/ref&gt;

LSTM became popular in [[Natural Language Processing]]. Unlike previous models based on [[Hidden Markov model|HMMs]] and similar concepts, LSTM can learn to recognise [[context-sensitive languages]].&lt;ref name="gers2001"&gt;{{cite journal|last2=Schmidhuber|first2=Jürgen|year=2001|title=LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages|url=|journal=IEEE Transactions on Neural Networks|volume=12|issue=6|pages=1333–1340|doi=10.1109/72.963769|pmid=18249962|last1=Gers|first1=Felix A.|authorlink2=Jürgen Schmidhuber}}&lt;/ref&gt; LSTM improved machine translation,&lt;ref&gt;{{cite arxiv | eprint=1801.10111| last1=Schmidhuber| first1=Juergen| title=Video-based Sign Language Recognition without Temporal Segmentation| class=cs.CV| year=2018}}&lt;/ref&gt;&lt;ref name="NIPS2014"&gt;{{Cite journal|last=Sutskever|first=L.|last2=Vinyals|first2=O.|last3=Le|first3=Q.|date=2014|title=Sequence to Sequence Learning with Neural Networks|url=https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf|journal=NIPS'14 Proceedings of the 27th International Conference on Neural Information Processing Systems |volume=2 |pages=3104–3112 |bibcode=2014arXiv1409.3215S |arxiv=1409.3215 }}&lt;/ref&gt; [[language modeling]]&lt;ref name="vinyals2016"&gt;{{cite arxiv|last=Jozefowicz|first=Rafal|last2=Vinyals|first2=Oriol|last3=Schuster|first3=Mike|last4=Shazeer|first4=Noam|last5=Wu|first5=Yonghui|date=2016-02-07|title=Exploring the Limits of Language Modeling|eprint=1602.02410|class=cs.CL}}&lt;/ref&gt; and multilingual language processing.&lt;ref name="gillick2015"&gt;{{cite arxiv|last=Gillick|first=Dan|last2=Brunk|first2=Cliff|last3=Vinyals|first3=Oriol|last4=Subramanya|first4=Amarnag|date=2015-11-30|title=Multilingual Language Processing From Bytes|eprint=1512.00103|class=cs.CL}}&lt;/ref&gt; LSTM combined with CNNs improved automatic image captioning.&lt;ref name="vinyals2015"&gt;{{cite arxiv|last=Vinyals|first=Oriol|last2=Toshev|first2=Alexander|last3=Bengio|first3=Samy|last4=Erhan|first4=Dumitru|date=2014-11-17|title=Show and Tell: A Neural Image Caption Generator|eprint=1411.4555|class=cs.CV}}&lt;/ref&gt;

=== Deep reservoir computing ===
{{Main|Reservoir computing}}Deep Reservoir Computing and Deep Echo State Networks (deepESNs)&lt;ref&gt;{{Cite journal|last=Gallicchio|first=Claudio|last2=Micheli|first2=Alessio|last3=Pedrelli|first3=Luca|title=Deep reservoir computing: A critical experimental analysis|url=http://www.sciencedirect.com/science/article/pii/S0925231217307567|journal=Neurocomputing|volume=268|pages=87–99|doi=10.1016/j.neucom.2016.12.089|year=2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Gallicchio|first=Claudio|last2=Micheli|first2=Alessio|title=Echo State Property of Deep Reservoir Computing Networks|journal=Cognitive Computation|language=en|volume=9|issue=3|pages=337–350|doi=10.1007/s12559-017-9461-9|issn=1866-9956|year=2017}}&lt;/ref&gt; provide a framework for efficiently trained models&amp;nbsp;for hierarchical processing of temporal data, while enabling the investigation of the inherent role of RNN layered composition.{{clarify|date=January 2018}}

=== Deep belief networks ===
{{main|Deep belief network}}
[[File:Restricted_Boltzmann_machine.svg|thumb|A [[restricted Boltzmann machine]] (RBM) with fully connected visible and hidden units. Note there are no hidden-hidden or visible-visible connections.]]
A deep belief network (DBN) is a probabilistic, [[generative model]] made up of multiple layers of hidden units. It can be considered a [[Function composition|composition]] of simple learning modules that make up each layer.&lt;ref name="SCHOLARDBNS"&gt;{{cite journal|year=2009|title=Deep belief networks|url=|journal=Scholarpedia|volume=4|issue=5|page=5947|doi=10.4249/scholarpedia.5947|last1=Hinton|first1=G.E.|bibcode=2009SchpJ...4.5947H}}&lt;/ref&gt;

A DBN can be used to generatively pre-train a DNN by using the learned DBN weights as the initial DNN weights. Backpropagation or other discriminative algorithms can then tune these weights. This is particularly helpful when training data are limited, because poorly initialized weights can significantly hinder model performance. These pre-trained weights are in a region of the weight space that is closer to the optimal weights than were they randomly chosen. This allows for both improved modeling and faster convergence of the fine-tuning phase.&lt;ref&gt;{{Cite book|last=Larochelle|first=Hugo|last2=Erhan|first2=Dumitru|last3=Courville|first3=Aaron|last4=Bergstra|first4=James|last5=Bengio|first5=Yoshua|date=2007|title=An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation|journal=Proceedings of the 24th International Conference on Machine Learning|series=ICML '07|location=New York, NY, USA|publisher=ACM|pages=473–480|doi=10.1145/1273496.1273556|isbn=9781595937933|citeseerx=10.1.1.77.3242}}&lt;/ref&gt;

=== Large memory storage and retrieval neural networks ===
Large memory storage and retrieval neural networks (LAMSTAR)&lt;ref name="book2013"&gt;{{cite book|url={{google books |plainurl=y |id=W6W6CgAAQBAJ&amp;pg=PP1}}|title=Principles of Artificial Neural Networks|last=Graupe|first=Daniel|publisher=World Scientific|year=2013|isbn=978-981-4522-74-8|location=|pages=1–|ref=harv}}&lt;/ref&gt;&lt;ref name="GrPatent"&gt;{{Patent|US|5920852 A|D. Graupe," Large memory storage and retrieval (LAMSTAR) network, April 1996}}&lt;/ref&gt; are fast deep learning neural networks of many layers that can use many filters simultaneously. These filters may be nonlinear, stochastic, logic, [[non-stationary]], or even non-analytical. They are biologically motivated and learn continuously.

A LAMSTAR neural network may serve as a dynamic neural network in spatial or time domains or both. Its speed is provided by [[Hebbian]] link-weights&lt;ref name=book2013a&gt;D. Graupe, "Principles of Artificial Neural Networks.3rd Edition", World Scientific Publishers, 2013, pp.&amp;nbsp;203–274.&lt;/ref&gt; that integrate the various and usually different filters (preprocessing functions) into its many layers and to dynamically rank the significance of the various layers and functions relative to a given learning task. This grossly imitates biological learning which integrates various preprocessors ([[cochlea]], [[retina]], ''etc.'') and cortexes ([[Auditory cortex|auditory]], [[Visual cortex|visual]], ''etc.'') and their various regions. Its deep learning capability is further enhanced by using inhibition, correlation and its ability to cope with incomplete data, or "lost" neurons or layers even amidst a task. It is fully transparent due to its link weights. The link-weights allow dynamic determination of innovation and redundancy, and facilitate the ranking of layers, of filters or of individual neurons relative to a task.

LAMSTAR has been applied to many domains, including medical&lt;ref&gt;{{Cite journal|last=Nigam|first=Vivek Prakash|last2=Graupe|first2=Daniel|date=2004-01-01|title=A neural-network-based detection of epilepsy|journal=Neurological Research|volume=26|issue=1|pages=55–60|doi=10.1179/016164104773026534|issn=0161-6412|pmid=14977058}}&lt;/ref&gt;&lt;ref name=":11"&gt;{{Cite journal|last=Waxman|first=Jonathan A.|last2=Graupe|first2=Daniel|last3=Carley|first3=David W.|date=2010-04-01|title=Automated Prediction of Apnea and Hypopnea, Using a LAMSTAR Artificial Neural Network|journal=American Journal of Respiratory and Critical Care Medicine|volume=181|issue=7|pages=727–733|doi=10.1164/rccm.200907-1146oc|pmid=20019342|issn=1073-449X}}&lt;/ref&gt;&lt;ref name="GrGrZh"&gt;{{cite journal|last2=Graupe|first2=M. H.|last3=Zhong|first3=Y.|last4=Jackson|first4=R. K.|year=2008|title=Blind adaptive filtering for non-invasive extraction of the fetal electrocardiogram and its non-stationarities|url=|journal=Proc. Inst. Mech. Eng. H|volume=222|issue=8|pages=1221–1234|doi=10.1243/09544119jeim417|pmid=19143416|last1=Graupe|first1=D.}}&lt;/ref&gt; and financial predictions,&lt;ref name="book2013b"&gt;{{harvnb|Graupe|2013|pp=240–253}}&lt;/ref&gt; adaptive filtering of noisy speech in unknown noise,&lt;ref name="GrAbon"&gt;{{cite journal|last2=Abon|first2=J.|year=2002|title=A Neural Network for Blind Adaptive Filtering of Unknown Noise from Speech|url=https://www.tib.eu/en/search/id/BLCP:CN019373941/Blind-Adaptive-Filtering-of-Speech-from-Noise-of/|journal=Intelligent Engineering Systems Through Artificial Neural Networks|language=en|volume=12|issue=|pages=683–688|last1=Graupe|first1=D.|accessdate=2017-06-14}}&lt;/ref&gt; still-image recognition,&lt;ref name="book2013c"&gt;D. Graupe, "Principles of Artificial Neural Networks.3rd Edition", World Scientific Publishers", 2013, pp.&amp;nbsp;253–274.&lt;/ref&gt; video image recognition,&lt;ref name="Girado"&gt;{{cite journal|last2=Sandin|first2=D. J.|last3=DeFanti|first3=T. A.|year=2003|title=Real-time camera-based face detection using a modified LAMSTAR neural network system|url=|journal=Proc. SPIE 5015, Applications of Artificial Neural Networks in Image Processing VIII|volume=5015|issue=|pages=36–46|doi=10.1117/12.477405|last1=Girado|first1=J. I.|series=Applications of Artificial Neural Networks in Image Processing VIII|bibcode=2003SPIE.5015...36G}}&lt;/ref&gt; software security&lt;ref name="VenkSel"&gt;{{cite journal|last2=Selvan|first2=S.|year=2007|title=Intrusion Detection using an Improved Competitive Learning Lamstar Network|url=|journal=International Journal of Computer Science and Network Security|volume=7|issue=2|pages=255–263|last1=Venkatachalam|first1=V}}&lt;/ref&gt; and adaptive control of non-linear systems.&lt;ref&gt;{{Cite web|url=https://www.researchgate.net/publication/262316982|title=Control of unstable nonlinear and nonstationary systems using LAMSTAR neural networks|last=Graupe|first=D.|last2=Smollack|first2=M.|date=2007|website=ResearchGate|publisher=Proceedings of 10th IASTED on Intelligent Control, Sect.592,|pages=141–144|language=en|access-date=2017-06-14}}&lt;/ref&gt; LAMSTAR had a much faster learning speed and somewhat lower error rate than a CNN based on [[ReLU]]-function filters and max pooling, in 20 comparative studies.&lt;ref name="book1016"&gt;{{cite book|url={{google books |plainurl=y |id=e5hIDQAAQBAJ|page=57}}|title=Deep Learning Neural Networks: Design and Case Studies|last=Graupe|first=Daniel|date=7 July 2016|publisher=World Scientific Publishing Co Inc|isbn=978-981-314-647-1|location=|pages=57–110}}&lt;/ref&gt;

These applications demonstrate delving into aspects of the data that are hidden from shallow learning networks and the human senses, such as in the cases of predicting onset of [[sleep apnea]] events,&lt;ref name=":11" /&gt; of an electrocardiogram of a fetus as recorded from skin-surface electrodes placed on the mother's abdomen early in pregnancy,&lt;ref name="GrGrZh" /&gt; of financial prediction&lt;ref name="book2013" /&gt; or in blind filtering of noisy speech.&lt;ref name="GrAbon" /&gt;

LAMSTAR was proposed in 1996 ({{US Patent|5920852 A}}) and was further developed Graupe and Kordylewski from 1997–2002.&lt;ref&gt;{{Cite book|last=Graupe|first=D.|last2=Kordylewski|first2=H.|date=August 1996|title=Network based on SOM (Self-Organizing-Map) modules combined with statistical decision tools|url=http://ieeexplore.ieee.org/document/594203/|journal=Proceedings of the 39th Midwest Symposium on Circuits and Systems|volume=1|pages=471–474 vol.1|doi=10.1109/mwscas.1996.594203|isbn=978-0-7803-3636-0}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Graupe|first=D.|last2=Kordylewski|first2=H.|date=1998-03-01|title=A Large Memory Storage and Retrieval Neural Network for Adaptive Retrieval and Diagnosis|journal=International Journal of Software Engineering and Knowledge Engineering|volume=08|issue=1|pages=115–138|doi=10.1142/s0218194098000091|issn=0218-1940}}&lt;/ref&gt;&lt;ref name="Kordylew"&gt;{{cite journal|last2=Graupe|first2=D|last3=Liu|first3=K.|year=2001|title=A novel large-memory neural network as an aid in medical diagnosis applications|url=|journal=IEEE Transactions on Information Technology in Biomedicine|volume=5|issue=3|pages=202–209|doi=10.1109/4233.945291|last1=Kordylewski|first1=H.}}&lt;/ref&gt; A modified version, known as LAMSTAR 2, was developed by Schneider and Graupe in 2008.&lt;ref name="Schn"&gt;{{cite journal|last2=Graupe|year=2008|title=A modified LAMSTAR neural network and its applications|url=|journal=International Journal of Neural Systems|volume=18|issue=4|pages=331–337|doi=10.1142/s0129065708001634|pmid=18763732|last1=Schneider|first1=N.C.}}&lt;/ref&gt;&lt;ref name="book2013d"&gt;{{harvnb|Graupe|2013|p=217}}&lt;/ref&gt;

=== Stacked (de-noising) auto-encoders ===
The [[auto encoder]] idea is motivated by the concept of a ''good'' representation. For example, for a [[Linear classifier|classifier]], a good representation can be defined as one that yields a better-performing classifier.

An ''encoder'' is a deterministic mapping &lt;math&gt;f_\theta&lt;/math&gt; that transforms an input vector''''' x''''' into hidden representation '''''y''''', where &lt;math&gt;\theta = \{\boldsymbol{W}, b\}&lt;/math&gt;, &lt;math&gt;\boldsymbol{W}&lt;/math&gt; is the weight matrix and '''b''' is an offset vector (bias). A ''decoder'' maps back the hidden representation '''y''' to the reconstructed input '''''z''''' via &lt;math&gt;g_\theta&lt;/math&gt;. The whole process of auto encoding is to compare this reconstructed input to the original and try to minimize the error to make the reconstructed value as close as possible to the original.

In ''stacked denoising auto encoders'', the partially corrupted output is cleaned (de-noised). This idea was introduced in 2010 by Vincent et al.&lt;ref name="ref9"&gt;{{cite journal|last2=Larochelle|first2=Hugo|last3=Lajoie|first3=Isabelle|last4=Bengio|first4=Yoshua|last5=Manzagol|first5=Pierre-Antoine|date=2010|title=Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion|url=http://dl.acm.org/citation.cfm?id=1953039|journal=The Journal of Machine Learning Research|volume=11|pages=3371–3408|last1=Vincent|first1=Pascal}}&lt;/ref&gt; with a specific approach to ''good'' representation, a ''good representation'' is one that can be obtained [[Robustness (computer science)|robustly]] from a corrupted input and that will be useful for recovering the corresponding clean input''.'' Implicit in this definition are the following ideas:
* The higher level representations are relatively stable and robust to input corruption;
* It is necessary to extract features that are useful for representation of the input distribution.
The algorithm starts by a stochastic mapping of &lt;math&gt;\boldsymbol{x}&lt;/math&gt; to &lt;math&gt;\tilde{\boldsymbol{x}}&lt;/math&gt; through &lt;math&gt;q_D(\tilde{\boldsymbol{x}}|\boldsymbol{x})&lt;/math&gt;, this is the corrupting step. Then the corrupted input &lt;math&gt;\tilde{\boldsymbol{x}}&lt;/math&gt; passes through a basic auto-encoder process and is mapped to a hidden representation &lt;math&gt;\boldsymbol{y} = f_\theta(\tilde{\boldsymbol{x}}) = s(\boldsymbol{W}\tilde{\boldsymbol{x}}+b)&lt;/math&gt;. From this hidden representation, we can reconstruct &lt;math&gt;\boldsymbol{z} = g_\theta(\boldsymbol{y})&lt;/math&gt;. In the last stage, a minimization algorithm runs in order to have '''''z''''' as close as possible to uncorrupted input &lt;math&gt;\boldsymbol{x}&lt;/math&gt;. The reconstruction error &lt;math&gt;L_H(\boldsymbol{x},\boldsymbol{z})&lt;/math&gt; might be either the [[cross-entropy]] loss with an affine-sigmoid decoder, or the squared error loss with an [[Affine transformation|affine]] decoder.&lt;ref name="ref9" /&gt;

In order to make a deep architecture, auto encoders stack.&lt;ref name="ballard1987"&gt;{{Cite web|url=http://www.aaai.org/Papers/AAAI/1987/AAAI87-050.pdf|title=Modular learning in neural networks|last=Ballard|first=Dana H.|date=1987|website=Proceedings of AAAI|pages=279–284|archive-url=https://web.archive.org/web/20151016210300/http://www.aaai.org/Papers/AAAI/1987/AAAI87-050.pdf|archive-date=2015-10-16|dead-url=yes|access-date=}}&lt;/ref&gt; Once the encoding function &lt;math&gt;f_\theta&lt;/math&gt; of the first denoising auto encoder is learned and used to uncorrupt the input (corrupted input), the second level can be trained.&lt;ref name="ref9" /&gt;

Once the stacked auto encoder is trained, its output can be used as the input to a [[supervised learning]] algorithm such as [[support vector machine]] classifier or a multi-class [[logistic regression]].&lt;ref name="ref9" /&gt;

=== Deep stacking networks ===
A deep stacking network (DSN)&lt;ref name="ref17"&gt;{{cite journal|last2=Yu|first2=Dong|last3=Platt|first3=John|date=2012|title=Scalable stacking and learning for building deep architectures|url=http://research-srv.microsoft.com/pubs/157586/DSN-ICASSP2012.pdf|journal=2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|pages=2133–2136|last1=Deng|first1=Li}}&lt;/ref&gt; (deep convex network) is based on a hierarchy of blocks of simplified neural network modules. It was introduced in 2011 by Deng and Dong.&lt;ref name="ref16"&gt;{{cite journal|last2=Yu|first2=Dong|date=2011|title=Deep Convex Net: A Scalable Architecture for Speech Pattern Classification|url=http://www.truebluenegotiations.com/files/deepconvexnetwork-interspeech2011-pub.pdf|journal=Proceedings of the Interspeech|pages=2285–2288|last1=Deng|first1=Li}}&lt;/ref&gt; It formulates the learning as a [[convex optimization problem]] with a [[Closed-form expression|closed-form solution]], emphasizing the mechanism's similarity to [[Ensemble learning|stacked generalization]].&lt;ref name="ref18"&gt;{{cite journal|date=1992|title=Stacked generalization|journal=Neural Networks|volume=5|issue=2|pages=241–259|doi=10.1016/S0893-6080(05)80023-1|last1=David|first1=Wolpert|citeseerx=10.1.1.133.8090}}&lt;/ref&gt; Each DSN block is a simple module that is easy to train by itself in a [[Supervised learning|supervised]] fashion without backpropagation for the entire blocks.&lt;ref&gt;{{Cite journal|last=Bengio|first=Y.|date=2009-11-15|title=Learning Deep Architectures for AI|url=http://www.nowpublishers.com/article/Details/MAL-006|journal=Foundations and Trends® in Machine Learning|language=English|volume=2|issue=1|pages=1–127|doi=10.1561/2200000006|issn=1935-8237|citeseerx=10.1.1.701.9550}}&lt;/ref&gt;

Each block consists of a simplified [[multi-layer perceptron]] (MLP) with a single hidden layer. The hidden layer '''''h''''' has logistic [[Sigmoid function|sigmoidal]] [[Artificial neuron|units]], and the output layer has linear units. Connections between these layers are represented by weight matrix '''''U;''''' input-to-hidden-layer connections have weight matrix '''''W'''''. Target vectors '''''t''''' form the columns of matrix '''''T''''', and the input data vectors '''''x''''' form the columns of matrix '''''X.''''' The matrix of hidden units is &lt;math&gt;\boldsymbol{H} = \sigma(\boldsymbol{W}^T\boldsymbol{X})&lt;/math&gt;. Modules are trained in order, so lower-layer weights '''''W''''' are known at each stage. The function performs the element-wise [[Logistic function|logistic sigmoid]] operation. Each block estimates the same final label class ''y'', and its estimate is concatenated with original input '''''X''''' to form the expanded input for the next block. Thus, the input to the first block contains the original data only, while downstream blocks' input adds the output of preceding blocks. Then learning the upper-layer weight matrix '''''U''''' given other weights in the network can be formulated as a convex optimization problem:
: &lt;math&gt;\min_{U^T} f = ||\boldsymbol{U}^T \boldsymbol{H} - \boldsymbol{T}||^2_F,&lt;/math&gt;
which has a closed-form solution.

Unlike other deep architectures, such as DBNs, the goal is not to discover the transformed [[Feature (machine learning)|feature]] representation. The structure of the hierarchy of this kind of architecture makes parallel learning straightforward, as a batch-mode optimization problem. In purely [[Discriminative model|discriminative tasks]], DSNs perform better than conventional [[Deep belief network|DBN]]&lt;nowiki/&gt;s.&lt;ref name="ref17" /&gt;

=== Tensor deep stacking networks ===
This architecture is a DSN extension. It offers two important improvements: it uses higher-order information from [[covariance]] statistics, and it transforms the [[Convex optimization|non-convex problem]] of a lower-layer to a convex sub-problem of an upper-layer.&lt;ref name="ref19"&gt;{{cite journal|last2=Deng|first2=Li|last3=Yu|first3=Dong|date=2012|title=Tensor deep stacking networks|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=1–15|issue=8|pages=1944–1957|doi=10.1109/tpami.2012.268|last1=Hutchinson|first1=Brian}}&lt;/ref&gt; TDSNs use covariance statistics in a [[bilinear map]]ping from each of two distinct sets of hidden units in the same layer to predictions, via a third-order [[tensor]].

While parallelization and scalability are not considered seriously in conventional {{H:title|Deep neural networks|DNNs}},&lt;ref name="ref26"&gt;{{cite journal|last2=Salakhutdinov|first2=Ruslan|date=2006|title=Reducing the Dimensionality of Data with Neural Networks|journal=Science|volume=313|issue=5786|pages=504–507|doi=10.1126/science.1127647|pmid=16873662|last1=Hinton|first1=Geoffrey|bibcode=2006Sci...313..504H}}&lt;/ref&gt;&lt;ref name="ref27"&gt;{{cite journal|last2=Yu|first2=D.|last3=Deng|first3=L.|last4=Acero|first4=A.|date=2012|title=Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition|journal=IEEE Transactions on Audio, Speech, and Language Processing|volume=20|issue=1|pages=30–42|doi=10.1109/tasl.2011.2134090|last1=Dahl|first1=G.|citeseerx=10.1.1.227.8990}}&lt;/ref&gt;&lt;ref name="ref28"&gt;{{cite journal|last2=Dahl|first2=George|last3=Hinton|first3=Geoffrey|date=2012|title=Acoustic Modeling Using Deep Belief Networks|journal=IEEE Transactions on Audio, Speech, and Language Processing|volume=20|issue=1|pages=14–22|doi=10.1109/tasl.2011.2109382|last1=Mohamed|first1=Abdel-rahman|citeseerx=10.1.1.338.2670}}&lt;/ref&gt; all learning for {{H:title|Deep stacking network|DSN}}s and {{H:title|Tensor deep stacking network|TDSN}}s is done in batch mode, to allow parallelization.&lt;ref name="ref16" /&gt;&lt;ref name="ref17" /&gt; Parallelization allows scaling the design to larger (deeper) architectures and data sets.

The basic architecture is suitable for diverse tasks such as [[Statistical classification|classification]] and [[Regression analysis|regression]].

=== Spike-and-slab RBMs ===
The need for deep learning with [[Real number|real-valued]] inputs, as in Gaussian restricted Boltzmann machines, led to the ''spike-and-slab'' [[Restricted Boltzmann machine|RBM]] (''ss''[[Restricted Boltzmann machine|RBM]]), which models continuous-valued inputs with strictly [[Binary variable|binary]] [[latent variable]]s.&lt;ref name="ref30"&gt;{{cite journal|last2=Bergstra|first2=James|last3=Bengio|first3=Yoshua|date=2011|title=A Spike and Slab Restricted Boltzmann Machine|url=http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CourvilleBB11.pdf|journal=JMLR: Workshop and Conference Proceeding|volume=15|pages=233–241|last1=Courville|first1=Aaron}}&lt;/ref&gt; Similar to basic [[Restricted Boltzmann machine|RBMs]] and its variants, a spike-and-slab [[Restricted Boltzmann machine|RBM]] is a [[bipartite graph]], while like [[Restricted Boltzmann machine|GRBMs]], the visible units (input) are real-valued. The difference is in the hidden layer, where each hidden unit has a binary spike variable and a real-valued slab variable. A spike is a discrete [[probability mass]] at zero, while a slab is a [[Probability density|density]] over continuous domain;&lt;ref name="ref32"&gt;{{cite conference|last1=Courville|first1=Aaron|last2=Bergstra|first2=James|last3=Bengio|first3=Yoshua|chapter=Unsupervised Models of Images by Spike-and-Slab RBMs|title=Proceedings of the 28th International Conference on Machine Learning|volume=10|pages=1–8|date=2011|url=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Courville_591.pdf}}&lt;/ref&gt; their mixture forms a [[Prior probability|prior]].&lt;ref name="ref31"&gt;{{cite journal|last2=Beauchamp|first2=J|date=1988|title=Bayesian Variable Selection in Linear Regression|journal=Journal of the American Statistical Association|volume=83|issue=404|pages=1023–1032|doi=10.1080/01621459.1988.10478694|last1=Mitchell|first1=T}}&lt;/ref&gt;

An extension of ss[[Restricted Boltzmann machine|RBM]] called µ-ss[[Restricted Boltzmann machine|RBM]] provides extra modeling capacity using additional terms in the [[energy function]]. One of these terms enables the model to form a [[Conditional probability distribution|conditional distribution]] of the spike variables by [[marginalizing out]] the slab variables given an observation.

=== Compound hierarchical-deep models ===
Compound hierarchical-deep models compose deep networks with non-parametric [[Bayesian network|Bayesian models]]. [[Feature (machine learning)|Features]] can be learned using deep architectures such as DBNs,&lt;ref name="hinton2006" /&gt; DBMs,&lt;ref name="ref3"&gt;{{cite journal|last1=Hinton|first1=Geoffrey|last2=Salakhutdinov|first2=Ruslan|date=2009|title=Efficient Learning of Deep Boltzmann Machines|url=http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS09_SalakhutdinovH.pdf|volume=3|pages=448–455}}&lt;/ref&gt; deep auto encoders,&lt;ref name="ref15"&gt;{{cite journal|last2=Bengio|first2=Yoshua|last3=Louradour|first3=Jerdme|last4=Lamblin|first4=Pascal|date=2009|title=Exploring Strategies for Training Deep Neural Networks|url=http://dl.acm.org/citation.cfm?id=1577070|journal=The Journal of Machine Learning Research|volume=10|pages=1–40|last1=Larochelle|first1=Hugo}}&lt;/ref&gt; convolutional variants,&lt;ref name="ref39"&gt;{{cite journal|last2=Carpenter|first2=Blake|date=2011|title=Text Detection and Character Recognition in Scene Images with Unsupervised Feature Learning|url=http://www.iapr-tc11.org/archive/icdar2011/fileup/PDF/4520a440.pdf|journal=|volume=|pages=440–445|via=|last1=Coates|first1=Adam}}&lt;/ref&gt;&lt;ref name="ref40"&gt;{{Cite book|last2=Grosse|first2=Roger|date=2009|title=Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations|url=http://portal.acm.org/citation.cfm?doid=1553374.1553453|journal=Proceedings of the 26th Annual International Conference on Machine Learning|pages=1–8|last1=Lee|first1=Honglak|doi=10.1145/1553374.1553453|isbn=9781605585161|citeseerx=10.1.1.149.6800}}&lt;/ref&gt; ssRBMs,&lt;ref name="ref32" /&gt; deep coding networks,&lt;ref name="ref41"&gt;{{cite journal|last2=Zhang|first2=Tong|date=2010|title=Deep Coding Network|url=http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2010_1077.pdf|journal=Advances in Neural . . .|pages=1–9|last1=Lin|first1=Yuanqing}}&lt;/ref&gt; DBNs with sparse feature learning,&lt;ref name="ref42"&gt;{{cite journal|last2=Boureau|first2=Y-Lan|date=2007|title=Sparse Feature Learning for Deep Belief Networks|url=http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2007_1118.pdf|journal=Advances in Neural Information Processing Systems|volume=23|pages=1–8|last1=Ranzato|first1=Marc Aurelio}}&lt;/ref&gt; RNNs,&lt;ref name="ref43"&gt;{{cite journal|last2=Lin|first2=Clif|date=2011|title=Parsing Natural Scenes and Natural Language with Recursive Neural Networks|url=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Socher_125.pdf|journal=Proceedings of the 26th International Conference on Machine Learning|last1=Socher|first1=Richard}}&lt;/ref&gt; conditional DBNs,&lt;ref name="ref44"&gt;{{cite journal|last2=Hinton|first2=Geoffrey|date=2006|title=Modeling Human Motion Using Binary Latent Variables|url=http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_693.pdf|journal=Advances in Neural Information Processing Systems|last1=Taylor|first1=Graham}}&lt;/ref&gt; de-noising auto encoders.&lt;ref name="ref45"&gt;{{Cite book|last2=Larochelle|first2=Hugo|date=2008|title=Extracting and composing robust features with denoising autoencoders|url=http://portal.acm.org/citation.cfm?doid=1390156.1390294|journal=Proceedings of the 25th International Conference on Machine Learning – ICML '08|pages=1096–1103|last1=Vincent|first1=Pascal|doi=10.1145/1390156.1390294|isbn=9781605582054|citeseerx=10.1.1.298.4083}}&lt;/ref&gt; This provides a better representation, allowing faster learning and more accurate classification with high-dimensional data. However, these architectures are poor at learning novel classes with few examples, because all network units are involved in representing the input (a '''{{visible anchor|distributed representation}}''') and must be adjusted together (high [[degree of freedom]]). Limiting the degree of freedom reduces the number of parameters to learn, facilitating learning of new classes from few examples. [[Hierarchical Bayesian model|''Hierarchical Bayesian (HB)'' models]] allow learning from few examples, for example&lt;ref name="ref34"&gt;{{cite journal|last2=Perfors|first2=Amy|last3=Tenenbaum|first3=Joshua|date=2007|title=Learning overhypotheses with hierarchical Bayesian models|journal=Developmental Science|volume=10|issue=3|pages=307–21|doi=10.1111/j.1467-7687.2007.00585.x|pmid=17444972|last1=Kemp|first1=Charles|citeseerx=10.1.1.141.5560}}&lt;/ref&gt;&lt;ref name="ref37"&gt;{{cite journal|last2=Tenenbaum|first2=Joshua|date=2007|title=Word learning as Bayesian inference|journal=Psychol. Rev.|volume=114|issue=2|pages=245–72|doi=10.1037/0033-295X.114.2.245|pmid=17500627|last1=Xu|first1=Fei|citeseerx=10.1.1.57.9649}}&lt;/ref&gt;&lt;ref name="ref46"&gt;{{cite journal|last2=Polatkan|first2=Gungor|date=2011|title=The Hierarchical Beta Process for Convolutional Factor Analysis and Deep Learning|url=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Chen_251.pdf|journal=Machine Learning . . .|last1=Chen|first1=Bo}}&lt;/ref&gt;&lt;ref name="ref47"&gt;{{cite journal|last2=Fergus|first2=Rob|date=2006|title=One-shot learning of object categories|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=28|issue=4|pages=594–611|doi=10.1109/TPAMI.2006.79|pmid=16566508|last1=Fei-Fei|first1=Li|citeseerx=10.1.1.110.9024}}&lt;/ref&gt;&lt;ref name="ref48"&gt;{{cite journal|last2=Dunson|first2=David|date=2008|title=The Nested Dirichlet Process|journal=Journal of the American Statistical Association|volume=103|issue=483|pages=1131–1154|doi=10.1198/016214508000000553|last1=Rodriguez|first1=Abel|citeseerx=10.1.1.70.9873}}&lt;/ref&gt; for computer vision, [[statistics]] and cognitive science.

Compound HD architectures aim to integrate characteristics of both HB and deep networks. The compound HDP-DBM architecture is a ''[[hierarchical Dirichlet process]] (HDP)'' as a hierarchical model, incorporated with DBM architecture. It is a full [[generative model]], generalized from abstract concepts flowing through the layers of the model, which is able to synthesize new examples in novel classes that look "reasonably" natural. All the levels are learned jointly by maximizing a joint [[Log probability|log-probability]] [[Score (statistics)|score]].&lt;ref name="ref38"&gt;{{cite journal|last2=Joshua|first2=Tenenbaum|date=2012|title=Learning with Hierarchical-Deep Models|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=35|issue=8|pages=1958–71|doi=10.1109/TPAMI.2012.269|pmid=23787346|last1=Ruslan|first1=Salakhutdinov|citeseerx=10.1.1.372.909}}&lt;/ref&gt;

In a DBM with three hidden layers, the probability of a visible input '''{{mvar|&amp;nu;}}''' is:
: &lt;math&gt;p(\boldsymbol{\nu}, \psi) = \frac{1}{Z}\sum_h e^{\sum_{ij}W_{ij}^{(1)}\nu_i h_j^1 + \sum_{jl}W_{jl}^{(2)}h_j^{1}h_l^{2}+\sum_{lm}W_{lm}^{(3)}h_l^{2}h_m^{3}},&lt;/math&gt;
where &lt;math&gt;\boldsymbol{h} = \{\boldsymbol{h}^{(1)}, \boldsymbol{h}^{(2)}, \boldsymbol{h}^{(3)} \}&lt;/math&gt; is the set of hidden units, and &lt;math&gt;\psi = \{\boldsymbol{W}^{(1)}, \boldsymbol{W}^{(2)}, \boldsymbol{W}^{(3)} \} &lt;/math&gt; are the model parameters, representing visible-hidden and hidden-hidden symmetric interaction terms.

A learned DBM model is an undirected model that defines the joint distribution &lt;math&gt;P(\nu, h^1, h^2, h^3)&lt;/math&gt;. One way to express what has been learned is the [[Discriminative model|conditional model]] &lt;math&gt;P(\nu, h^1, h^2|h^3)&lt;/math&gt; and a prior term &lt;math&gt;P(h^3)&lt;/math&gt;.

Here &lt;math&gt;P(\nu, h^1, h^2|h^3)&lt;/math&gt; represents a conditional DBM model, which can be viewed as a two-layer DBM but with bias terms given by the states of &lt;math&gt;h^3&lt;/math&gt;:
: &lt;math&gt;P(\nu, h^1, h^2|h^3) = \frac{1}{Z(\psi, h^3)}e^{\sum_{ij}W_{ij}^{(1)}\nu_i h_j^1 + \sum_{jl}W_{jl}^{(2)}h_j^{1}h_l^{2}+\sum_{lm}W_{lm}^{(3)}h_l^{2}h_m^{3}}.&lt;/math&gt;

=== Deep predictive coding networks ===
A deep predictive coding network (DPCN) is a [[Predictive modelling|predictive]] coding scheme that uses top-down information to empirically adjust the priors needed for a bottom-up [[inference]] procedure by means of a deep, locally connected, [[generative model]]. This works by extracting sparse [[Feature (machine learning)|features]] from time-varying observations using a linear dynamical model. Then, a pooling strategy is used to learn invariant feature representations. These units compose to form a deep architecture and are trained by [[Greedy algorithm|greedy]] layer-wise [[unsupervised learning]]. The layers constitute a kind of [[Markov chain]] such that the states at any layer depend only on the preceding and succeeding layers.

DPCNs predict the representation of the layer, by using a top-down approach using the information in upper layer and temporal dependencies from previous states.&lt;ref name="ref56"&gt;{{cite arXiv|eprint=1301.3541|first2=Jose|last2=Principe|title=Deep Predictive Coding Networks|date=2013|last1=Chalasani|first1=Rakesh|class=cs.LG}}&lt;/ref&gt;

DPCNs can be extended to form a [[Convolutional neural network|convolutional network]].&lt;ref name="ref56" /&gt;

=== Networks with separate memory structures ===
Integrating external memory with Artificial neural networks dates to early research in distributed representations&lt;ref name="Hinton, Geoffrey E 19842"&gt;{{Cite web|url=http://repository.cmu.edu/cgi/viewcontent.cgi?article=2841&amp;context=compsci|title=Distributed representations|last=Hinton|first=Geoffrey E.|date=1984|website=|archive-url=https://web.archive.org/web/20160502213526/http://repository.cmu.edu/cgi/viewcontent.cgi?article=2841&amp;context=compsci|archive-date=2016-05-02|dead-url=yes|access-date=}}&lt;/ref&gt; and [[Teuvo Kohonen|Kohonen]]'s [[self-organizing map]]s. For example, in [[sparse distributed memory]] or [[hierarchical temporal memory]], the patterns encoded by neural networks are used as addresses for [[content-addressable memory]], with "neurons" essentially serving as address [[encoder]]s and [[Binary decoder|decoders]]. However, the early controllers of such memories were not differentiable.

==== LSTM-related differentiable memory structures ====
Apart from [[long short-term memory]] (LSTM), other approaches also added differentiable memory to recurrent functions. For example:
* Differentiable push and pop actions for alternative memory networks called neural stack machines&lt;ref name="S. Das, C.L. Giles p. 79"&gt;S. Das, C.L. Giles, G.Z. Sun, "Learning Context Free Grammars: Limitations of a Recurrent Neural Network with an External Stack Memory," Proc. 14th Annual Conf. of the Cog. Sci. Soc., p. 79, 1992.&lt;/ref&gt;&lt;ref name="Mozer, M. C. 1993 pp. 863-870"&gt;{{Cite web|url=https://papers.nips.cc/paper/626-a-connectionist-symbol-manipulator-that-discovers-the-structure-of-context-free-languages|title=A connectionist symbol manipulator that discovers the structure of context-free languages|last=Mozer|first=M. C.|last2=Das|first2=S.|date=1993|website=|publisher=NIPS 5|pages=863–870|access-date=}}&lt;/ref&gt;
* Memory networks where the control network's external differentiable storage is in the fast weights of another network&lt;ref name="ReferenceC"&gt;{{cite journal|year=1992|title=Learning to control fast-weight memories: An alternative to recurrent nets|url=|journal=Neural Computation|volume=4|issue=1|pages=131–139|doi=10.1162/neco.1992.4.1.131|last1=Schmidhuber|first1=J.}}&lt;/ref&gt;
* LSTM forget gates&lt;ref name="F. Gers, N. Schraudolph 2002"&gt;{{cite journal|last2=Schraudolph|first2=N.|last3=Schmidhuber|first3=J.|year=2002|title=Learning precise timing with LSTM recurrent networks|url=http://jmlr.org/papers/volume3/gers02a/gers02a.pdf|journal=JMLR|volume=3|issue=|pages=115–143|via=|last1=Gers|first1=F.}}&lt;/ref&gt;
* Self-referential RNNs with special output units for addressing and rapidly manipulating the RNN's own weights in differentiable fashion (internal storage)&lt;ref name="J. Schmidhuber pages 191-195"&gt;{{Cite conference|author=[[Jürgen Schmidhuber]]|title=An introspective network that can learn to run its own weight change algorithm|booktitle=In Proc. of the Intl. Conf. on Artificial Neural Networks, Brighton|pages=191–195|publisher=IEE|year=1993|url=ftp://ftp.idsia.ch/pub/juergen/iee93self.ps.gz}}&lt;/ref&gt;&lt;ref name="Hochreiter, Sepp 2001"&gt;{{cite journal|last2=Younger|first2=A. Steven|last3=Conwell|first3=Peter R.|year=2001|title=Learning to Learn Using Gradient Descent|journal=ICANN|volume=2130|issue=|pages=87–94|doi=|last1=Hochreiter|first1=Sepp|citeseerx=10.1.1.5.323}}&lt;/ref&gt;
* Learning to transduce with unbounded memory&lt;ref name="Grefenstette, Edward 1506"&gt;{{Cite arxiv |eprint = 1506.02516|last1 = Schmidhuber|first1 = Juergen|title = Learning to Transduce with Unbounded Memory|class = cs.NE|year = 2015}}&lt;/ref&gt;

===== Neural Turing machines =====
{{Main|Neural Turing machine}}Neural Turing machines&lt;ref name="Graves, Alex 14102"&gt;{{cite arxiv |eprint=1410.5401|last1=Schmidhuber|first1=Juergen|title=Neural Turing Machines|class=cs.NE|year=2014}}&lt;/ref&gt; couple LSTM networks to external memory resources, with which they can interact by attentional processes. The combined system is analogous to a [[Turing machine]] but is differentiable end-to-end, allowing it to be efficiently trained by [[gradient descent]]. Preliminary results demonstrate that neural Turing machines can infer simple algorithms such as copying, sorting and associative recall from input and output examples.

[[Differentiable neural computer]]s (DNC) are an NTM extension. They out-performed Neural turing machines, [[long short-term memory]] systems and memory networks on sequence-processing tasks.&lt;ref name=":02"&gt;{{Cite news|url=https://www.wired.co.uk/article/deepmind-ai-tube-london-underground|title=DeepMind's AI learned to ride the London Underground using human-like reason and memory|last=Burgess|first=Matt|newspaper=WIRED UK|language=en-GB|access-date=2016-10-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.pcmag.com/news/348701/deepmind-ai-learns-to-navigate-london-tube|title=DeepMind AI 'Learns' to Navigate London Tube|newspaper=PCMAG|access-date=2016-10-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://techcrunch.com/2016/10/13/__trashed-2/|title=DeepMind's differentiable neural computer helps you navigate the subway with its memory|last=Mannes|first=John|website=TechCrunch|access-date=2016-10-19}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Graves|first=Alex|last2=Wayne|first2=Greg|last3=Reynolds|first3=Malcolm|last4=Harley|first4=Tim|last5=Danihelka|first5=Ivo|last6=Grabska-Barwińska|first6=Agnieszka|last7=Colmenarejo|first7=Sergio Gómez|last8=Grefenstette|first8=Edward|last9=Ramalho|first9=Tiago|date=2016-10-12|title=Hybrid computing using a neural network with dynamic external memory|url=http://www.nature.com/nature/journal/vaop/ncurrent/full/nature20101.html|journal=Nature|language=en|volume=538|issue=7626|doi=10.1038/nature20101|issn=1476-4687|pages=471–476|pmid=27732574|bibcode=2016Natur.538..471G}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://deepmind.com/blog/differentiable-neural-computers/|title=Differentiable neural computers {{!}} DeepMind|website=DeepMind|access-date=2016-10-19}}&lt;/ref&gt;

==== Semantic hashing ====
Approaches that represent previous experiences directly and [[Instance-based learning|use a similar experience to form a local model]] are often called [[K-nearest neighbor algorithm|nearest neighbour]] or [[K-nearest neighbors algorithm|k-nearest neighbors]] methods.&lt;ref&gt;{{cite journal|last2=Schaal|first2=Stefan|year=1995|title=Memory-based neural networks for robot learning|url=|journal=Neurocomputing|volume=9|issue=3|pages=243–269|doi=10.1016/0925-2312(95)00033-6|last1=Atkeson|first1=Christopher G.}}&lt;/ref&gt; Deep learning is useful in semantic hashing&lt;ref&gt;Salakhutdinov, Ruslan, and Geoffrey Hinton. [http://www.utstat.toronto.edu/~rsalakhu/papers/sdarticle.pdf "Semantic hashing."] International Journal of Approximate Reasoning 50.7 (2009): 969–978.&lt;/ref&gt; where a deep [[graphical model]] the word-count vectors&lt;ref name="Le 2014"&gt;{{Cite arXiv|eprint=1405.4053|first=Quoc V.|last=Le|first2=Tomas|last2=Mikolov|title=Distributed representations of sentences and documents|year=2014|class=cs.CL}}&lt;/ref&gt; obtained from a large set of documents.{{Clarify|reason=verb missing|date=June 2017}} Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by accessing all the addresses that differ by only a few bits from the address of the query document. Unlike [[sparse distributed memory]] that operates on 1000-bit addresses, semantic hashing works on 32 or 64-bit addresses found in a conventional computer architecture.

==== Memory networks ====
Memory networks&lt;ref name="Weston, Jason 14102"&gt;{{cite arxiv |eprint=1410.3916|last1=Schmidhuber|first1=Juergen|title=Memory Networks|class=cs.AI|year=2014}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |eprint=1503.08895|last1=Schmidhuber|first1=Juergen|title=End-To-End Memory Networks|class=cs.NE|year=2015}}&lt;/ref&gt; are another extension to neural networks incorporating [[long-term memory]]. The long-term memory can be read and written to, with the goal of using it for prediction. These models have been applied in the context of [[question answering]] (QA) where the long-term memory effectively acts as a (dynamic) knowledge base and the output is a textual response.&lt;ref&gt;{{cite arxiv |eprint=1506.02075|last1=Schmidhuber|first1=Juergen|title=Large-scale Simple Question Answering with Memory Networks|class=cs.LG|year=2015}}&lt;/ref&gt; A team of electrical and computer engineers from UCLA Samueli School of Engineering has created a physical artificial neural network. That can analyze large volumes of data and identify objects at the actual speed of light.&lt;ref&gt;{{Cite news|url=https://www.sciencedaily.com/releases/2018/08/180802130750.htm|title=AI device identifies objects at the speed of light: The 3D-printed artificial neural network can be used in medicine, robotics and security|work=ScienceDaily|access-date=2018-08-08|language=en}}&lt;/ref&gt;

==== Pointer networks ====
Deep neural networks can be potentially improved by deepening and parameter reduction, while maintaining trainability. While training extremely deep (e.g., 1 million layers) neural networks might not be practical, [[CPU]]-like architectures such as pointer networks&lt;ref&gt;{{cite arxiv |eprint=1506.03134|last1=Schmidhuber|first1=Juergen|title=Pointer Networks|class=stat.ML|year=2015}}&lt;/ref&gt; and neural random-access machines&lt;ref&gt;{{cite arxiv |eprint=1511.06392|last1=Schmidhuber|first1=Juergen|title=Neural Random-Access Machines|class=cs.LG|year=2015}}&lt;/ref&gt; overcome this limitation by using external [[random-access memory]] and other components that typically belong to a [[computer architecture]] such as [[Processor register|registers]], [[Arithmetic logic unit|ALU]] and [[Pointer (computer programming)|pointers]]. Such systems operate on [[probability distribution]] vectors stored in memory cells and registers. Thus, the model is fully differentiable and trains end-to-end. The key characteristic of these models is that their depth, the size of their short-term memory, and the number of parameters can be altered independently – unlike models like LSTM, whose number of parameters grows quadratically with memory size.

==== Encoder–decoder networks ====
Encoder–decoder frameworks are based on neural networks that map highly [[Structured prediction|structured]] input to highly structured output. The approach arose in the context of [[machine translation]],&lt;ref&gt;{{Cite web|url=http://www.aclweb.org/anthology/D13-1176|title=Recurrent continuous translation models|last=Kalchbrenner|first=N.|last2=Blunsom|first2=P.|date=2013|website=|publisher=EMNLP'2013|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf|title=Sequence to sequence learning with neural networks|last=Sutskever|first=I.|last2=Vinyals|first2=O.|date=2014|website=|publisher=NIPS'2014|access-date=|last3=Le|first3=Q. V.}}&lt;/ref&gt;&lt;ref&gt;{{Cite arxiv |eprint=1406.1078|last1=Schmidhuber|first1=Juergen|title=Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation|class=cs.CL|year=2014}}&lt;/ref&gt; where the input and output are written sentences in two natural languages. In that work, an LSTM RNN or CNN was used as an encoder to summarize a source sentence, and the summary was decoded using a conditional RNN [[language model]] to produce the translation.&lt;ref&gt;{{Cite journal |arxiv=1507.01053|last1=Schmidhuber|first1=Juergen|last2=Courville|first2=Aaron|last3=Bengio|first3=Yoshua|title=Describing Multimedia Content using Attention-based Encoder--Decoder Networks|journal=IEEE Transactions on Multimedia|volume=17|issue=11|pages=1875–1886|year=2015|doi=10.1109/TMM.2015.2477044}}&lt;/ref&gt; These systems share building blocks: gated RNNs and CNNs and trained attention mechanisms.

=== Multilayer kernel machine ===
Multilayer kernel machines (MKM) are a way of learning highly nonlinear functions by iterative application of weakly nonlinear kernels. They use the [[kernel principal component analysis]] (KPCA),&lt;ref name="ref60"&gt;{{cite journal|last2=Smola|first2=Alexander|date=1998|title=Nonlinear component analysis as a kernel eigenvalue problem|journal=Neural Computation|volume=(44)|issue=5|pages=1299–1319|doi=10.1162/089976698300017467|last1=Scholkopf|first1=B|citeseerx=10.1.1.53.8911}}&lt;/ref&gt; as a method for the [[Unsupervised learning|unsupervised]] greedy layer-wise pre-training step of deep learning.&lt;ref name="ref59"&gt;{{cite journal|date=2012|title=Kernel Methods for Deep Learning|url=http://cseweb.ucsd.edu/~yoc002/paper/thesis_youngmincho.pdf|pages=1–9|last1=Cho|first1=Youngmin}}&lt;/ref&gt;

Layer &lt;math&gt;l+1&lt;/math&gt; learns the representation of the previous layer &lt;math&gt;l&lt;/math&gt;, extracting the &lt;math&gt;n_l&lt;/math&gt; [[Principal component analysis|principal component]] (PC) of the projection layer &lt;math&gt;l&lt;/math&gt; output in the feature domain induced by the kernel. For the sake of [[dimensionality reduction]] of the updated representation in each layer, a [[Supervised learning|supervised strategy]] selects the best informative features among features extracted by KPCA. The process is:
* rank the &lt;math&gt;n_l&lt;/math&gt; features according to their [[mutual information]] with the class labels;
* for different values of ''K'' and &lt;math&gt;m_l \in\{1, \ldots, n_l\}&lt;/math&gt;, compute the classification error rate of a ''[[K-nearest neighbor]] (K-NN)'' classifier using only the &lt;math&gt;m_l&lt;/math&gt; most informative features on a [[validation set]];
* the value of &lt;math&gt;m_l&lt;/math&gt; with which the classifier has reached the lowest error rate determines the number of features to retain.
Some drawbacks accompany the KPCA method as the building cells of an MKM.

A more straightforward way to use kernel machines for deep learning was developed for spoken language understanding.&lt;ref&gt;{{Cite journal|last=Deng|first=Li|last2=Tur|first2=Gokhan|last3=He|first3=Xiaodong|last4=Hakkani-Tür|first4=Dilek|date=2012-12-01|title=Use of Kernel Deep Convex Networks and End-To-End Learning for Spoken Language Understanding|url=https://www.microsoft.com/en-us/research/publication/use-of-kernel-deep-convex-networks-and-end-to-end-learning-for-spoken-language-understanding/|journal=Microsoft Research|language=en-US}}&lt;/ref&gt; The main idea is to use a kernel machine to approximate a shallow neural net with an infinite number of hidden units, then use [[Deep learning#Deep stacking networks|stacking]] to splice the output of the kernel machine and the raw input in building the next, higher level of the kernel machine. The number of levels in the deep convex network is a hyper-parameter of the overall system, to be determined by cross validation.

== Neural architecture search ==
{{Main|Neural architecture search}}
Neural architecture search (NAS) uses machine learning to automate the design of Artificial neural networks. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset and use the results as feedback to teach the NAS network.&lt;ref&gt;{{cite arxiv|last=Zoph|first=Barret|last2=Le|first2=Quoc V.|date=2016-11-04|title=Neural Architecture Search with Reinforcement Learning|eprint=1611.01578|class=cs.LG}}&lt;/ref&gt;

== Use ==

Using Artificial neural networks requires an understanding of their characteristics.
* Choice of model: This depends on the data representation and the application. Overly complex models slow learning.
* Learning algorithm: Numerous trade-offs exist between learning algorithms. Almost any algorithm will work well with the correct [[hyperparameter]]s for training on a particular data set. However, selecting and tuning an algorithm for training on unseen data requires significant experimentation.
* Robustness: If the model, cost function and learning algorithm are selected appropriately, the resulting ANN can become robust.
ANN capabilities fall within the following broad categories:{{Citation needed|date=June 2017}}

* [[Function approximation]], or [[regression analysis]], including [[Time series#Prediction and forecasting|time series prediction]], [[fitness approximation]] and modeling.
* [[Statistical classification|Classification]], including [[Pattern recognition|pattern]] and sequence recognition, [[novelty detection]] and sequential decision making.
* [[Data processing]], including filtering, clustering, [[blind source separation]] and compression.
* [[Robotics]], including directing manipulators and [[prosthesis|prostheses]].
* [[Control engineering|Control]], including [[computer numerical control]].

==Applications==
Because of their ability to reproduce and model nonlinear processes, Artificial neural networks have found many applications in a wide range of disciplines.

Application areas include [[system identification]] and control (vehicle control, trajectory prediction,&lt;ref&gt;{{cite journal|last1=Zissis|first1=Dimitrios|title=A cloud based architecture capable of perceiving and predicting multiple vessel behaviour|journal=Applied Soft Computing|date=October 2015|volume=35|url=http://www.sciencedirect.com/science/article/pii/S1568494615004329|doi=10.1016/j.asoc.2015.07.002|pages=652–661}}&lt;/ref&gt; [[process control]], [[natural resource management]]), [[quantum chemistry]],&lt;ref name="Balabin_2009"&gt;{{Cite journal|journal=[[J. Chem. Phys.]] |volume = 131 |issue = 7 |page = 074104 |doi=10.1063/1.3206326 |title=Neural network approach to quantum-chemistry data: Accurate prediction of density functional theory energies |year=2009 |author1=[[Roman Balabin|Roman M. Balabin]]|author2=Ekaterina I. Lomakina |pmid=19708729|bibcode = 2009JChPh.131g4104B }}&lt;/ref&gt; game-playing and [[decision making]] ([[backgammon]], [[chess]], [[poker]]), [[pattern recognition]] (radar systems, [[Facial recognition system|face identification]], signal classification,&lt;ref&gt;{{cite journal|last=Sengupta|first=Nandini|author2=Sahidullah, Md|author3=Saha, Goutam|title=Lung sound classification using cepstral-based statistical features|journal=Computers in Biology and Medicine|date=August 2016|volume=75|issue=1|pages=118–129|doi=10.1016/j.compbiomed.2016.05.013|pmid=27286184|url=http://www.sciencedirect.com/science/article/pii/S0010482516301263}}&lt;/ref&gt; object recognition and more), sequence recognition (gesture, speech, handwritten and printed text recognition), [[medical diagnosis]], finance&lt;ref&gt;{{cite journal|last1=French|first1=Jordan|title=The time traveller's CAPM|journal=Investment Analysts Journal|volume=46|issue=2|pages=81–96|doi=10.1080/10293523.2016.1255469|year=2016}}&lt;/ref&gt; (e.g. [[algorithmic trading|automated trading systems]]), [[data mining]], visualization, [[machine translation]], social network filtering&lt;ref&gt;{{Cite news|url=https://www.wsj.com/articles/facebook-boosts-a-i-to-block-terrorist-propaganda-1497546000|title=Facebook Boosts A.I. to Block Terrorist Propaganda|last=Schechner|first=Sam|date=2017-06-15|work=Wall Street Journal|access-date=2017-06-16|language=en-US|issn=0099-9660}}&lt;/ref&gt; and [[e-mail spam]] filtering.

Artificial neural networks have been used to diagnose cancers, including [[lung cancer]],&lt;ref&gt;{{cite web|last=Ganesan|first=N|title=Application of Neural Networks in Diagnosing Cancer Disease Using Demographic Data|url=http://www.ijcaonline.org/journal/number26/pxc387783.pdf|publisher=International Journal of Computer Applications}}&lt;/ref&gt; [[prostate cancer]], [[colorectal cancer]]&lt;ref&gt;{{cite web|url=http://www.lcc.uma.es/~jja/recidiva/042.pdf|title=Artificial Neural Networks Applied to Outcome Prediction for Colorectal Cancer Patients in Separate Institutions|last=Bottaci|first=Leonardo|publisher=The Lancet}}&lt;/ref&gt; and to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.&lt;ref&gt;{{cite journal|last2=Lyons|first2=Samanthe M|last3=Castle|first3=Jordan M|last4=Prasad|first4=Ashok|date=2016|title=Measuring systematic changes in invasive cancer cell shape using Zernike moments|url=http://pubs.rsc.org/en/Content/ArticleLanding/2016/IB/C6IB00100A#!divAbstract|journal=Integrative Biology|volume=8|issue=11|pages=1183–1193|doi=10.1039/C6IB00100A|pmid=27735002|last1=Alizadeh|first1=Elaheh}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|date=2016|title=Changes in cell shape are correlated with metastatic potential in murine|url=http://bio.biologists.org/content/5/3/289|journal=Biology Open|volume=5|issue=3|pages=289–299|doi=10.1242/bio.013409|pmid=26873952|pmc=4810736|last1=Lyons|first1=Samanthe}}&lt;/ref&gt; Artificial neural networks have also found use accelerating reliability analysis of infrastructures subject to natural disasters&lt;ref&gt;{{Cite journal|last=Nabian|first=Mohammad Amin|last2=Meidani|first2=Hadi|date=2017-08-28|title=Deep Learning for Accelerated Reliability Analysis of Infrastructure Networks|journal=Computer-Aided Civil and Infrastructure Engineering|volume=33|issue=6|pages=443–458|arxiv=1708.08551|doi=10.1111/mice.12359}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Nabian|first=Mohammad Amin|last2=Meidani|first2=Hadi|date=2018|title=Accelerating Stochastic Assessment of Post-Earthquake Transportation Network Connectivity via Machine-Learning-Based Surrogates|url=https://trid.trb.org/view/1496617|journal=Transportation Research Board 97th Annual Meeting|volume=|pages=|via=}}&lt;/ref&gt; and predicting foundation settlements &lt;ref&gt;{{Cite journal|last=Díaz|first=E.|last2=Brotons|first2=V.|last3=Tomás|first3=R.|date=September 2018|title=Use of artificial neural networks to predict 3-D elastic settlement of foundations on soils with inclined bedrock|url=http://dx.doi.org/10.1016/j.sandf.2018.08.001|journal=Soils and Foundations|doi=10.1016/j.sandf.2018.08.001|issn=0038-0806}}&lt;/ref&gt;. Other applications include building black-box models in [[geoscience]]: [[hydrology]],&lt;ref&gt;{{Cite journal|last=null null|date=2000-04-01|title=Artificial Neural Networks in Hydrology. I: Preliminary Concepts|journal=Journal of Hydrologic Engineering|volume=5|issue=2|pages=115–123|doi=10.1061/(ASCE)1084-0699(2000)5:2(115)|citeseerx=10.1.1.127.3861}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=null null|date=2000-04-01|title=Artificial Neural Networks in Hydrology. II: Hydrologic Applications|journal=Journal of Hydrologic Engineering|volume=5|issue=2|pages=124–137|doi=10.1061/(ASCE)1084-0699(2000)5:2(124)}}&lt;/ref&gt; ocean modelling and [[coastal engineering]],&lt;ref&gt;{{Cite journal|last=Peres|first=D. J.|last2=Iuppa|first2=C.|last3=Cavallaro|first3=L.|last4=Cancelliere|first4=A.|last5=Foti|first5=E.|date=2015-10-01|title=Significant wave height record extension by neural networks and reanalysis wind data|url=http://www.sciencedirect.com/science/article/pii/S1463500315001432|journal=Ocean Modelling|volume=94|pages=128–140|doi=10.1016/j.ocemod.2015.08.002|bibcode=2015OcMod..94..128P}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Dwarakish|first=G. S.|last2=Rakshith|first2=Shetty|last3=Natesan|first3=Usha|date=2013|title=Review on Applications of Neural Network in Coastal Engineering|url=http://www.ciitresearch.org/dl/index.php/aiml/article/view/AIML072013007|journal=Artificial Intelligent Systems and Machine Learning|language=English|volume=5|issue=7|pages=324–331}}&lt;/ref&gt; and [[geomorphology]].&lt;ref&gt;{{Cite journal|last=Ermini|first=Leonardo|last2=Catani|first2=Filippo|last3=Casagli|first3=Nicola|date=2005-03-01|title=Artificial Neural Networks applied to landslide susceptibility assessment|url=http://www.sciencedirect.com/science/article/pii/S0169555X04002272|journal=Geomorphology|series=Geomorphological hazard and human impact in mountain environments|volume=66|issue=1|pages=327–343|doi=10.1016/j.geomorph.2004.09.025|bibcode=2005Geomo..66..327E}}&lt;/ref&gt; Furthermore, artificial neural networks have found widespread use in the field of [[big data]].&lt;ref&gt;{{Cite journal|last=Xue-Wen Chen|last2=Xiaotong Lin|date=2014|title=Big Data Deep Learning: Challenges and Perspectives|url=https://ieeexplore.ieee.org/document/6817512/|journal=IEEE Access|language=en-US|volume=2|pages=514–525|doi=10.1109/access.2014.2325029|issn=2169-3536}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Zhou|first=Lina|last2=Pan|first2=Shimei|last3=Wang|first3=Jianwu|last4=Vasilakos|first4=Athanasios V.|date=May 10, 2017|title=Machine learning on big data: Opportunities and challenges|url=https://linkinghub.elsevier.com/retrieve/pii/S0925231217300577|journal=Neurocomputing|volume=237|pages=350–361|doi=10.1016/j.neucom.2017.01.026|issn=0925-2312|via=Elsevier Science Direct}}&lt;/ref&gt;

===Types of models===

Many types of models are used, defined at different levels of abstraction and modeling different aspects of neural systems. They range from models of the short-term behavior of [[biological neuron models|individual neurons]],&lt;ref&gt;{{cite journal | author=Forrest MD |title=Simulation of alcohol action upon a detailed Purkinje neuron model and a simpler surrogate model that runs &gt;400 times faster |journal= BMC Neuroscience | volume=16 |issue=27 |pages=27 | date=April 2015 |doi=10.1186/s12868-015-0162-6 |pmid=25928094 |pmc=4417229 |url=http://www.biomedcentral.com/1471-2202/16/27 }}&lt;/ref&gt; models of how the dynamics of neural circuitry arise from interactions between individual neurons and finally to models of how behavior can arise from abstract neural modules that represent complete subsystems. These include models of the long-term, and short-term plasticity, of neural systems and their relations to learning and memory from the individual neuron to the system level.

==Theoretical properties==
===Computational power===

The [[multilayer perceptron]] is a universal function approximator, as proven by the [[universal approximation theorem]]. However, the proof is not constructive regarding the number of neurons required, the network topology, the weights and the learning parameters.

A specific recurrent architecture with rational valued weights (as opposed to full precision [[real number]]-valued weights) has the full power of a [[Universal Turing Machine|universal Turing machine]],&lt;ref&gt;{{Cite journal| title =  Turing computability with neural nets | url = http://www.math.rutgers.edu/~sontag/FTPDIR/aml-turing.pdf | year = 1991 | journal = Appl. Math. Lett. | pages = 77–80 | volume = 4 | issue = 6 | last1 = Siegelmann | first1 =  H.T. | last2 =  Sontag | first2 =  E.D. | doi =  10.1016/0893-9659(91)90080-F }}&lt;/ref&gt; using a finite number of neurons and standard linear connections. Further, the use of irrational values for weights results in a machine with [[Hypercomputation|super-Turing]] power.&lt;ref&gt;{{cite journal |last1=Balcázar |first1=José |title=Computational Power of Neural Networks: A Kolmogorov Complexity Characterization |journal=Information Theory, IEEE Transactions on |date=Jul 1997 |volume=43 |issue=4 |pages=1175–1183 |doi=10.1109/18.605580 |url=http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=605580&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D605580 |accessdate=3 November 2014|citeseerx=10.1.1.411.7782 }}&lt;/ref&gt;

===Capacity===
Models' "capacity" property roughly corresponds to their ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.{{citation needed|date=February 2017}}

===Convergence===
Models may not consistently converge on a single solution, firstly because many local minima may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical. However, for [[cerebellar model articulation controller|CMAC]] neural network, a recursive least squares algorithm was introduced to train it, and this algorithm can be guaranteed to converge in one step.&lt;ref name="Qin1"/&gt;

===Generalization and statistics===
Applications whose goal is to create a system that generalizes well to unseen examples, face the possibility of over-training. This arises in convoluted or over-specified systems when the capacity of the network significantly exceeds the needed free parameters. Two approaches address over-training. The first is to use [[cross-validation (statistics)|cross-validation]] and similar techniques to check for the presence of over-training and optimally select hyperparameters to minimize the generalization error. The second is to use some form of ''[[regularization (mathematics)|regularization]]''. This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.

[[File:Synapse deployment.jpg|thumb|right|Confidence analysis of a neural network]]
Supervised neural networks that use a [[mean squared error]] (MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the [[confidence interval]] of the output of the network, assuming a [[normal distribution]]. A confidence analysis made this way is statistically valid as long as the output [[probability distribution]] stays the same and the network is not modified.

By assigning a [[softmax activation function]], a generalization of the [[logistic function]], on the output layer of the neural network (or a softmax component in a component-based neural network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is very useful in classification as it gives a certainty measure on classifications.

The softmax activation function is:

:&lt;math&gt;y_i=\frac{e^{x_i}}{\sum_{j=1}^c e^{x_j}}&lt;/math&gt;
&lt;section end="theory" /&gt;

==Criticism==

===Training issues===
A common criticism of neural networks, particularly in robotics, is that they require too much training for real-world operation.{{Citation needed|date=November 2014}} Potential solutions include randomly shuffling training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example and by grouping examples in so-called mini-batches. Improving the training efficiency and convergence capability has always been an ongoing research area for neural network. For example, by introducing a recursive least squares algorithm for [[cerebellar model articulation controller|CMAC]] neural network, the training process only takes one step to converge.&lt;ref name="Qin1"/&gt;

===Theoretical issues===

No neural network has solved computationally difficult problems such as the [[Eight queens puzzle|n-Queens]] problem, the [[travelling salesman problem]], or the problem of [[Integer factorization|factoring]] large integers.

A fundamental objection is that they do not reflect how real neurons function. Back propagation is a critical part of most artificial neural networks, although no such mechanism exists in biological neural networks.&lt;ref&gt;{{cite journal | last1 = Crick | first1 = Francis | year = 1989 | title = The recent excitement about neural networks | journal = Nature | volume = 337 | issue = 6203 | pages = 129–132 | doi = 10.1038/337129a0 | url = http://europepmc.org/abstract/med/2911347 | pmid=2911347| bibcode = 1989Natur.337..129C }}&lt;/ref&gt; How information is coded by real neurons is not known. [[Sensory neuron|Sensor neurons]] fire [[action potential]]s more frequently with sensor activation and [[muscle cell]]s pull more strongly when their associated [[motor neuron]]s receive action potentials more frequently.&lt;ref&gt;{{cite journal | last1 = Adrian | first1 = Edward D. | year = 1926 | title = The impulses produced by sensory nerve endings | journal = The Journal of Physiology | volume = 61 | issue = 1 | pages = 49–72 | doi = 10.1113/jphysiol.1926.sp002273 | pmid = 16993776 | pmc = 1514809 }}&lt;/ref&gt; Other than the case of relaying information from a sensor neuron to a motor neuron, almost nothing of the principles of how information is handled by biological neural networks is known. This is a subject of active research in [[Neural coding]].

The motivation behind Artificial neural networks is not necessarily to strictly replicate neural function, but to use biological neural networks as an inspiration. A central claim of artificial neural networks is therefore that it embodies some new and powerful general principle for processing information. Unfortunately, these general principles are ill-defined. It is often claimed that they are [[Emergent properties|emergent]] from the network itself. This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition. [[Alexander Dewdney]] commented that, as a result, artificial neural networks have a "something-for-nothing quality, one that imparts a peculiar aura of laziness and a distinct lack of curiosity about just how good these computing systems are. No human hand (or mind) intervenes; solutions are found as if by magic; and no one, it seems, has learned anything".&lt;ref&gt;{{cite book|url={{google books |plainurl=y |id=KcHaAAAAMAAJ|page=82}}|title=Yes, we have no neutrons: an eye-opening tour through the twists and turns of bad science|last=Dewdney|first=A. K.|date=1 April 1997|publisher=Wiley|isbn=978-0-471-10806-1|location=|pages=82}}&lt;/ref&gt;

Biological brains use both shallow and deep circuits as reported by brain anatomy,&lt;ref name="VanEssen1991"&gt;D. J. Felleman and D. C. Van Essen, "[http://cercor.oxfordjournals.org/content/1/1/1.1.full.pdf+html Distributed hierarchical processing in the primate cerebral cortex]," ''Cerebral Cortex'', 1, pp. 1–47, 1991.&lt;/ref&gt; displaying a wide variety of invariance. Weng&lt;ref name="Weng2012"&gt;J. Weng, "[https://www.amazon.com/Natural-Artificial-Intelligence-Introduction-Computational/dp/0985875720 Natural and Artificial Intelligence: Introduction to Computational Brain-Mind]," BMI Press, {{ISBN|978-0985875725}}, 2012.&lt;/ref&gt; argued that the brain self-wires largely according to signal statistics and therefore, a serial cascade cannot catch all major statistical dependencies.

===Hardware issues===
Large and effective neural networks require considerable computing resources.&lt;ref name=":0"&gt;{{cite journal|last1=Edwards|first1=Chris|title=Growing pains for deep learning|journal=Communications of the ACM|date=25 June 2015|volume=58|issue=7|pages=14–16|doi=10.1145/2771283}}&lt;/ref&gt; While the brain has hardware tailored to the task of processing signals through a [[Graph (discrete mathematics)|graph]] of neurons, simulating even a simplified neuron on [[von Neumann architecture]] may compel a neural network designer to fill many millions of [[database]] rows for its connections{{snd}} which can consume vast amounts of [[Random-access memory|memory]] and storage. Furthermore, the designer often needs to transmit signals through many of these connections and their associated neurons{{snd}} which must often be matched with enormous [[Central processing unit|CPU]] processing power and time.

[[Jürgen Schmidhuber|Schmidhuber]] notes that the resurgence of neural networks in the twenty-first century is largely attributable to advances in hardware: from 1991 to 2015, computing power, especially as delivered by [[General-purpose computing on graphics processing units|GPGPUs]] (on [[Graphics processing unit|GPUs]]), has increased around a million-fold, making the standard backpropagation algorithm feasible for training networks that are several layers deeper than before.&lt;ref&gt;{{cite journal |last=Schmidhuber |first=Jürgen |title=Deep learning in neural networks: An overview |journal=Neural Networks |volume=61 |year=2015 |pages=85–117 |arxiv=1404.7828 |doi=10.1016/j.neunet.2014.09.003|pmid=25462637 }}&lt;/ref&gt; The use of accelerators such as FPGAs and GPUs can reduce training times from months to days.&lt;ref&gt;"[https://www.academia.edu/37491583/A_Survey_of_FPGA-based_Accelerators_for_Convolutional_Neural_Networks A Survey of FPGA-based Accelerators for Convolutional Neural Networks]", NCAA, 2018&lt;/ref&gt;{{r|:0}}

[[Neuromorphic engineering]] addresses the hardware difficulty directly, by constructing non-von-Neumann chips to directly implement neural networks in circuitry. Another chip optimized for neural network processing is called a [[Tensor Processing Unit]], or TPU.&lt;ref&gt;{{cite news |url=https://www.wired.com/2016/05/google-tpu-custom-chips/ |author=Cade Metz |newspaper=Wired |date=May 18, 2016 |title=Google Built Its Very Own Chips to Power Its AI Bots}}&lt;/ref&gt;

===Practical counterexamples to criticisms===
Arguments against Dewdney's position are that neural networks have been successfully used to solve many complex and diverse tasks, ranging from autonomously flying aircraft&lt;ref&gt;[http://www.nasa.gov/centers/dryden/news/NewsReleases/2003/03-49.html NASA – Dryden Flight Research Center – News Room: News Releases: NASA NEURAL NETWORK PROJECT PASSES MILESTONE]. Nasa.gov. Retrieved on 2013-11-20.&lt;/ref&gt; to detecting credit card fraud to mastering the game of [[Go (game)|Go]].

Technology writer Roger Bridgman commented:

&lt;blockquote&gt;Neural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be "an opaque, unreadable table...valueless as a scientific resource".
In spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.&lt;ref&gt;{{Cite web |url=http://members.fortunecity.com/templarseries/popper.html |title=Roger Bridgman's defence of neural networks |access-date=12 July 2010 |archive-url=https://web.archive.org/web/20120319163352/http://members.fortunecity.com/templarseries/popper.html |archive-date=19 March 2012 |dead-url=yes |df=dmy-all }}&lt;/ref&gt;
&lt;/blockquote&gt;

Although it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering general principles that allow a learning machine to be successful. For example, local vs non-local learning and shallow vs deep architecture.&lt;ref&gt;{{cite web|url=http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/4|title=Scaling Learning Algorithms towards {AI} – LISA – Publications – Aigaion 2.0|publisher=}}&lt;/ref&gt;

===Hybrid approaches===
Advocates of hybrid models (combining neural networks and symbolic approaches), claim that such a mixture can better capture the mechanisms of the human mind.&lt;ref&gt;Sun and Bookman (1990)&lt;/ref&gt;&lt;ref&gt;{{Cite journal| last1 = Tahmasebi | last2 = Hezarkhani | title =  A hybrid neural networks-fuzzy logic-genetic algorithm for grade estimation | url = http://www.sciencedirect.com/science/article/pii/S0098300412000398 | year = 2012| journal = Computers &amp; Geosciences | pages = 18–27 | volume = 42| doi =  10.1016/j.cageo.2012.02.004 | pmid = 25540468 | pmc = 4268588 | bibcode = 2012CG.....42...18T }}&lt;/ref&gt;

==Types==
&lt;!-- Split to [[Types of artificial neural networks]] --&gt;
{{Main|Types of artificial neural networks}}

Artificial neural networks have many variations. The simplest, static types have one or more static components, including number of units, number of layers, unit weights and [[topology]]. Dynamic types allow one or more of these to change during the learning process. The latter are much more complicated, but can shorten learning periods and produce better results. Some types allow/require learning to be "supervised" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.

==Gallery==
&lt;gallery widths="260"&gt;
File:Single layer ann.svg|A single-layer feedforward artificial neural network. Arrows originating from &lt;math&gt;\scriptstyle x_2&lt;/math&gt; are omitted for clarity. There are p inputs to this network and q outputs. In this system, the value of the qth output, &lt;math&gt;\scriptstyle y_q&lt;/math&gt; would be calculated as &lt;math&gt;\scriptstyle y_q = K*(\sum(x_i*w_{iq})-b_q) &lt;/math&gt;
File:Two layer ann.svg|A two-layer feedforward artificial neural network.
File:Artificial neural network.svg|An artificial neural network.
File:Ann dependency (graph).svg|An ANN dependency graph.
File:Single-layer feedforward artificial neural network.png|A single-layer feedforward artificial neural network with 4 inputs, 6 hidden and 2 outputs. Given position state and direction outputs wheel based control values.
File:Two-layer feedforward artificial neural network.png|A two-layer feedforward artificial neural network with 8 inputs, 2x8 hidden and 2 outputs. Given position state, direction and other environment values outputs thruster based control values.
File:Cmac.jpg|Parallel pipeline structure of CMAC neural network. This learning algorithm can converge in one step.
&lt;/gallery&gt;

== See also ==
{{too many see alsos|date=March 2018}}
{{columns-list|colwidth=25em|
* [[Hierarchical temporal memory]]
* [[20Q]]
* [[ADALINE]]
* [[Adaptive resonance theory]]
* [[Artificial life]]
* [[Associative Memory Base|Associative memory]]
* [[Autoencoder]]
* [[BEAM robotics]]
* [[Biological cybernetics]]
* [[Biologically inspired computing]]
* [[Blue Brain Project]]
* [[Catastrophic interference]]
* [[Cerebellar Model Articulation Controller]] (CMAC)
* [[Cognitive architecture]]
* [[Cognitive science]]
* [[Convolutional neural network]] (CNN)
* [[Connectionist expert system]]
* [[Connectomics]]
* [[Cultured neuronal networks]]
* [[Deep learning]]
* [[Encog]]
* [[Fuzzy logic]]
* [[Gene expression programming]]
* [[Genetic algorithm]]
* [[Genetic programming]]
* [[Group method of data handling]]
* [[Habituation]]
* [[In Situ Adaptive Tabulation]]
* [[List of machine learning concepts|Machine learning concepts]]
* [[Models of neural computation]]
* [[Neuroevolution]]
* [[Neural coding]]
* [[Neural gas]]
* [[Neural machine translation]]
* [[Neural network software]]
* [[Neuroscience]]
* [[Nonlinear system identification]]
* [[Optical neural network]]
* [[Parallel Constraint Satisfaction Processes]]
* [[Parallel distributed processing]]
* [[Radial basis function network]]
* [[Recurrent neural networks]]
* [[Self-organizing map]]
* [[Spiking neural network]] 
* [[Systolic array]]
* [[Tensor product network]]
* [[Time delay neural network]] (TDNN)
}}

==References==
{{Reflist|30em}}

==Bibliography==
{{div col|colwidth=30em}}
* {{Cite journal| author=Bhadeshia H. K. D. H. | year=1999 |title=Neural Networks in Materials Science | journal=ISIJ International | volume=39 |pages=966–979 | doi=10.2355/isijinternational.39.966 | url=http://www.msm.cam.ac.uk/phase-trans/abstracts/neural.review.pdf| issue=10}}
* {{Cite book|title=Neural networks for pattern recognition|last=M.|first=Bishop, Christopher|date=1995|publisher=Clarendon Press|isbn=978-0198538493|oclc=33101074 }}
* {{Cite book|title=Neuro-Fuzzy-Systeme : von den Grundlagen künstlicher Neuronaler Netze zur Kopplung mit Fuzzy-Systemen|first=Christian|last=Borgelt,|year=2003|publisher=Vieweg|isbn=9783528252656|oclc=76538146}}
* {{cite book|title=Mathematics of Control, Signals, and Systems|last=Cybenko|first=G.V.|publisher=Springer International|year=2006|editor-last=van Schuppen|editor-first=Jan H.|chapter=Approximation by Superpositions of a Sigmoidal function|chapter-url={{google books |plainurl=y |id=4RtVAAAAMAAJ|page=303}}|pp=303–314|title-link=Mathematics of Control, Signals, and Systems}} [https://web.archive.org/web/20110719183058/http://actcomm.dartmouth.edu/gvc/papers/approx_by_superposition.pdf PDF]
* {{Cite book|title=Yes, we have no neutrons : an eye-opening tour through the twists and turns of bad science|last=Dewdney |first=A. K.|isbn=9780471108061|oclc=35558945|year=1997|publisher=Wiley|location=New York}}
* {{Cite book|title=Pattern classification|first=Richard O.|last=Duda|last2=Hart |first2=Peter Elliot|last3=Stork |first3=David G.|year=2001|publisher=Wiley|isbn=978-0471056690|oclc=41347061|edition=2}}
* {{Cite journal | last1=Egmont-Petersen|first1=M. |last2=de Ridder |first2=D. |last3=Handels |first3=H. | year=2002 | title=Image processing with neural networks – a review | journal=Pattern Recognition | volume=35 | pages=2279–2301 | doi = 10.1016/S0031-3203(01)00178-9 | issue=10|citeseerx=10.1.1.21.5444 }}
* {{cite web|last1=Fahlman |first1=S. |last2=Lebiere |first2=C |year=1991 |title=The Cascade-Correlation Learning Architecture|url=http://www.cs.iastate.edu/~honavar/fahlman.pdf}}
**created for [[National Science Foundation]], Contract Number EET-8716324, and [[Defense Advanced Research Projects Agency]] (DOD), ARPA Order No. 4976 under Contract F33615-87-C-1499. 
* {{Cite book|title=An introduction to neural networks|last=Gurney |first=Kevin |year=1997|publisher=UCL Press|isbn=978-1857286731|oclc=37875698}}
* {{Cite book|title=Neural networks : a comprehensive foundation|last=Haykin|first= Simon S.|year=1999|publisher=Prentice Hall|isbn=978-0132733502|oclc=38908586}}
* {{Cite book|title=Introduction to the theory of neural computation|last1=Hertz |first1=J.|last3=Krogh|first3=Anders S.|first2=Richard G.|last2=Palmer|year=1991|publisher=Addison-Wesley |isbn=978-0201515602|oclc=21522159}}
* {{Cite book|title=Information theory, inference, and learning algorithms|publisher=Cambridge University Press|isbn=9780521642989|oclc=52377690|date=2003-09-25}}
* {{Cite book|title=Computational intelligence : a methodological introduction|first1=Rudolf,|last=Kruse|first2=Christian|last2=Borgelt|first3=F.|last3=Klawonn|first4=Christian|last4=Moewes|first5=Matthias|last5=Steinbrecher|first6=Pascal|last6=Held,|year=2013|publisher=Springer|isbn=9781447150121|oclc=837524179}}
* {{Cite book|title=Introduction to neural networks : design, theory and applications|last=Lawrence|first=Jeanette|year=1994|publisher=California Scientific Software|isbn=978-1883157005|oclc=32179420}}
* {{cite book| last=MacKay | first=David, J.C.| authorlink=David J.C. MacKay|year=2003|publisher=[[Cambridge University Press]]| isbn=9780521642989|url=http://www.inference.phy.cam.ac.uk/itprnn/book.pdf|title=Information Theory, Inference, and Learning Algorithms|ref=harv}}
* {{Cite book|title=Signal and image processing with neural networks : a C++ sourcebook|first=Timothy|last=Masters,|year=1994|publisher=J. Wiley|isbn=978-0471049630|oclc=29877717}}
* {{cite book|url={{google books |plainurl=y |id=m12UR8QmLqoC}}|title=Pattern Recognition and Neural Networks|last=Ripley|first=Brian D.|authorlink=Brian D. Ripley|publisher=Cambridge University Press|year=2007|isbn=978-0-521-71770-0}}
* {{cite journal|last1=Siegelmann |first1=H.T. |first2=Eduardo D.|last2=Sontag|year=1994|title=Analog computation via neural networks |journal=Theoretical Computer Science |volume= 131 |issue= 2 |pages=331–360 |url=https://pdfs.semanticscholar.org/861e/de32115d157e1568622b153e7ed3dca28467.pdf |doi=10.1016/0304-3975(94)90178-3}} 
* {{Cite book|title=Neural networks for statistical modeling|last1=Smith |first1=Murray|date=1993|publisher=Van Nostrand Reinhold|isbn=978-0442013103|oclc=27145760}}
* {{Cite book|title=Advanced methods in neural computing|last=Wasserman |first=Philip D.|year=1993|publisher=Van Nostrand Reinhold|isbn=978-0442004613|oclc=27429729}}
{{div col end}}

==External links==
* [http://www.dkriesel.com/en/science/neural_networks A brief introduction to Neural Networks] (PDF), illustrated 250p textbook covering the common kinds of neural networks (CC license).
* [https://web.archive.org/web/20150726190848/http://deeplearning4j.org/neuralnet-overview.html An Introduction to Deep Neural Networks].
* [http://people.revoledu.com/kardi/tutorial/NeuralNetwork/index.html A Tutorial of Neural Network in Excel].
* {{youtube|id=q0pm3BrIUFo |title=MIT course on Neural Networks }}
* [https://www.academia.edu/25708860/A_Concise_Introduction_to_Machine_Learning_with_Artificial_Neural_Networks A Concise Introduction to Machine Learning with Artificial Neural Networks]
* [https://www.coursera.org/course/neuralnets Neural Networks for Machine Learning – a course by Geoffrey Hinton]
* [http://www.deeplearningbook.org/ Deep Learning]
*[https://nnplayground.com Interactive visualization of neural work]
*[https://biztechmagazine.com/article/2018/09/how-artificial-neural-network-types-can-change-business-perfcon How Artificial Neural Network Types Can Change Business]

{{CPU technologies}}

{{DEFAULTSORT:Artificial Neural Network}}
[[Category:Computational statistics]]
[[Category:Artificial neural networks| ]]
[[Category:Classification algorithms]]
[[Category:Computational neuroscience]]
[[Category:Market research]]
[[Category:Market segmentation]]
[[Category:Mathematical psychology]]
[[Category:Mathematical and quantitative methods (economics)]]</text>
      <sha1>j4plf2rua92xz9j19s773nmdi3epzul</sha1>
    </revision>
  </page>
  <page>
    <title>Bost–Connes system</title>
    <ns>0</ns>
    <id>31890842</id>
    <revision>
      <id>864885868</id>
      <parentid>864885753</parentid>
      <timestamp>2018-10-20T04:54:30Z</timestamp>
      <contributor>
        <username>Mccapra</username>
        <id>12109628</id>
      </contributor>
      <comment>Successfully deorphaned</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1996">In [[mathematics]], a '''Bost–Connes system''' is a [[Quantum statistical mechanics|quantum statistical dynamical system]] related to an [[algebraic number field]], whose [[partition function (statistical mechanics)|partition function]] is related to the [[Dedekind zeta function]] of the number field. {{harvtxt|Bost|Connes|1995}} introduced Bost–Connes systems by constructing one for the [[rational number]]s. {{harvtxt|Connes|Marcolli|Ramachandran|2005}} extended the construction to imaginary [[quadratic fields]].

Such systems have been studied for their connection with [[Hilbert's twelfth problem|Hilbert's Twelfth Problem]].  In the case of a Bost–Connes system over '''Q''', the [[absolute Galois group]] acts on the ground states of the system.

==References==
*{{Citation | last1=Bost | first1=J.-B. | author1-link=Jean-Benoît Bost | last2=Connes | first2=Alain | author2-link=Alain Connes | title=Hecke algebras, type III factors and phase transitions with spontaneous symmetry breaking in number theory | doi=10.1007/BF01589495 | mr=1366621 | year=1995 | journal=Selecta Mathematica. New Series | issn=1022-1824 | volume=1 | issue=3 | pages=411–457}}
*{{Citation | last1=Connes | first1=Alain | author1-link=Alain Connes | last2=Marcolli | first2=Matilde | author2-link=Matilde Marcolli | last3=Ramachandran | first3=Niranjan | title=KMS states and complex multiplication | doi=10.1007/s00029-005-0013-x | mr=2215258 | year=2005 | journal=Selecta Mathematica. New Series | issn=1022-1824 | volume=11 | issue=3 | pages=325–347| arxiv=math/0501424 }}
*{{Citation | last=Marcolli | first=Matilde | authorlink=Matilde Marcolli | title=Arithmetic noncommutative geometry | others=With a foreword by Yuri Manin | zbl=1081.58005 | series=University Lecture Series | volume=36 | location=Providence, RI | publisher=[[American Mathematical Society]] | isbn=0-8218-3833-4 | year=2005 }}

{{DEFAULTSORT:Bost-Connes system}}
[[Category:Number theory]]
[[Category:Dynamical systems]]</text>
      <sha1>ej03f0tg9ud1uxcqyc6gq9tcs4unygr</sha1>
    </revision>
  </page>
  <page>
    <title>Bézout's theorem</title>
    <ns>0</ns>
    <id>149217</id>
    <revision>
      <id>860584439</id>
      <parentid>841018034</parentid>
      <timestamp>2018-09-21T17:39:34Z</timestamp>
      <contributor>
        <ip>217.132.48.168</ip>
      </contributor>
      <comment>named after...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11969">{{About|Bézout's theorem in algebraic geometry|Bézout's theorem in arithmetic|Bézout's identity}}
{{distinguish|Little Bézout's theorem}}
'''Bézout's theorem''' is a statement in [[algebraic geometry]] concerning the number of common points, or intersection points, of two plane [[algebraic curve]]s which do not share a common component (that is, which do not have infinitely many common points). The theorem states that the number of common points of two such curves is at most equal to the product of their [[degree of a polynomial|degree]]s, and equality holds if one counts [[points at infinity]] and points with complex coordinates (or more generally, coordinates from the [[algebraic closure]] of the ground field), and if each point is counted with its [[intersection number|intersection multiplicity]]. It is named after [[Étienne Bézout]].

'''Bézout's theorem''' refers also to the generalization to higher dimensions: Let there be ''n'' [[homogeneous polynomial]]s in {{math|''n''+1}} variables, of degrees &lt;math&gt;d_1, \ldots, d_n&lt;/math&gt;, that define ''n'' [[hypersurface]]s in the [[projective space]] of dimension ''n''. If the number of intersection points of the hypersurfaces is finite over an algebraic closure of the ground field, then this number is &lt;math&gt;d_1 \cdots d_n,&lt;/math&gt; if the points are counted with their multiplicity.
As in the case of two variables, in the case of affine hypersurfaces, and when not counting multiplicities nor non-real points, this theorem provides only an upper bound of the number of points, which is often reached. This is often referred to as '''Bézout's bound'''.

Bézout's theorem is fundamental in [[computer algebra]] and effective [[algebraic geometry]], by showing that most problems have a [[Computational complexity theory|computational complexity]] that is at least exponential in the number of variables. It follows that in these areas, the best complexity that may be hoped for will occur in algorithms that have a complexity which is polynomial in Bézout's bound.

==Rigorous statement==
Suppose that ''X'' and ''Y'' are two plane [[projective plane|projective]] curves defined over a [[field (mathematics)|field]] ''F'' that do not have a common component (this condition means that  ''X'' and ''Y'' are defined by polynomials, whose [[polynomial greatest common divisor]] is a constant; in particular, it holds for a pair of "generic" curves). Then the total number of intersection points of ''X'' and ''Y'' with coordinates in an [[algebraically closed field]] ''E'' which contains ''F'', counted with their [[intersection number|multiplicities]], is equal to the product of the degrees of ''X'' and ''Y''.

The generalization in higher dimension may be stated as:

Let ''n'' [[projective variety|projective hypersurface]]s be given in a [[projective space]] of dimension ''n'' over an algebraic closed field, which are defined by ''n'' [[homogeneous polynomial]]s in ''n'' + 1 variables, of degrees &lt;math&gt;d_1, \ldots,d_n.&lt;/math&gt; Then either the number of intersection points is infinite, or the number of intersection points, counted with multiplicity, is equal to the product &lt;math&gt;d_1 \cdots d_n.&lt;/math&gt; If the hypersurfaces are irreducible and in relative [[general position]], then there are &lt;math&gt;d_1 \cdots d_n&lt;/math&gt; intersection points, all with multiplicity 1.

There are various proofs of this theorem. In particular, it may be deduced by applying iteratively the following generalization: if ''V'' is a [[projective algebraic set]] of dimension &lt;math&gt;\delta&lt;/math&gt; and [[degree of an algebraic variety|degree]] &lt;math&gt;d_1&lt;/math&gt;, and ''H'' is a hypersurface (defined by a polynomial) of degree &lt;math&gt;d_2&lt;/math&gt;, that does not contain any [[irreducible component]] of ''V'', then the intersection of ''V'' and ''H'' has dimension &lt;math&gt;\delta-1&lt;/math&gt; and degree &lt;math&gt;d_1d_2.&lt;/math&gt; For a (sketched) proof using the [[Hilbert series]] see [[Hilbert series and Hilbert polynomial#Degree of a projective variety and Bézout's theorem]].

Bézout's theorem has been further generalized as the so-called [[multi-homogeneous Bézout theorem]].

==History==
Bezout's theorem was essentially stated by [[Isaac Newton]] in his proof of [[Newton's theorem about ovals|lemma 28]] of volume 1 of his ''[[Philosophiæ Naturalis Principia Mathematica|Principia]]'' in 1687, where he claims that two curves have a number of intersection points given by the product of their degrees.   The theorem was later published in 1779 in [[Étienne Bézout]]'s ''Théorie générale des équations algébriques''. Bézout, who did not have at his disposal modern algebraic notation for equations in several variables, gave a proof based on manipulations with cumbersome algebraic expressions. From the modern point of view, Bézout's treatment was rather heuristic, since he did not formulate the precise conditions for the theorem to hold. This led to a sentiment, expressed by certain authors, that his proof was neither correct nor the first proof to be given.&lt;ref&gt;{{cite book | authorlink=Frances Kirwan | last=Kirwan | first=Frances | title=Complex Algebraic Curves | publisher=Cambridge University Press| location=United Kingdom | year=1992 | isbn=0-521-42353-8}}&lt;/ref&gt;

==Intersection multiplicity==
{{further|Intersection number}}
The most delicate part of Bézout's theorem and its generalization to the case of ''k'' algebraic hypersurfaces in ''k''-dimensional [[projective space]] is the procedure of assigning the proper intersection multiplicities. If ''P'' is a common point of two plane algebraic curves ''X'' and ''Y'' that is a non-singular point of both of them and, moreover, the [[tangent line]]s to ''X'' and ''Y'' at ''P'' are distinct then the intersection multiplicity is one. This corresponds to the case of "transversal intersection". If the curves ''X'' and ''Y'' have a common tangent at ''P'' then the multiplicity is at least two. See [[intersection number]] for the definition in general.

==Examples==
*Two distinct non-parallel lines (in the same plane) always meet in exactly one point. Two parallel lines intersect at a unique point that lies at infinity. To see how this works algebraically, in projective space, the lines &lt;math&gt;x+2y=3&lt;/math&gt; and &lt;math&gt;x+2y=5&lt;/math&gt; are represented by the homogeneous equations &lt;math&gt;x+2y-3z=0&lt;/math&gt; and &lt;math&gt;x+2y-5z=0&lt;/math&gt;.  Solving, we get &lt;math&gt;x= -2y&lt;/math&gt; and &lt;math&gt;z=0&lt;/math&gt;, corresponding to the point (-2:1:0) in homogeneous coordinates.  As the ''z''-coordinate is 0, this point lies on the line at infinity.
*The special case where one of the curves is a line can be derived from the [[fundamental theorem of algebra]]. In this case the theorem states that an algebraic curve of degree ''n'' intersects a given line in ''n'' points, counting the multiplicities. For example, the parabola defined by   &lt;math&gt;y - x^2 = 0&lt;/math&gt;  has degree 2; the line &lt;math&gt;y-ax=0&lt;/math&gt; has degree 1, and they meet in exactly two points when ''a'' ≠ 0 and touch at the origin (intersect with multiplicity two) when ''a'' = 0.
* Two [[conic section]]s generally intersect in four points, some of which may coincide. To properly account for all intersection points, it may be necessary to allow complex coordinates and include the points on the infinite line in the projective plane. For example:

:*Two circles never intersect in more than two points in the plane, while Bézout's theorem predicts four.  The discrepancy comes from the fact that every circle passes through the same two complex points on the line at infinity. Writing the circle
:::&lt;math&gt;(x-a)^2+(y-b)^2 = r^2&lt;/math&gt;
::in [[homogeneous coordinates]], we get
:::&lt;math&gt;(x-az)^2+(y-bz)^2 - r^2z^2 = 0,&lt;/math&gt;
::from which it is clear that the two points (1:''i'':0) and (1:-''i'':0) lie on every circle.  When two circles don't meet at all in the real plane, the two other intersections have non-zero imaginary parts, or if they are concentric then they meet at exactly the two points on the line at infinity with an intersection multiplicity of two.
:*Any conic should meet the line at infinity at two points according to the theorem. A hyperbola meets it at two real points corresponding to the two directions of the asymptotes.  An ellipse meets it at two complex points which are conjugate to one another---in the case of a circle, the points (1:''i'':0) and (1:-''i'':0).  A parabola meets it at only one point, but it is a point of tangency and therefore counts twice.
:*The following pictures show examples in which the circle ''x''&lt;sup&gt;2&lt;/sup&gt;+''y''&lt;sup&gt;2&lt;/sup&gt;-1=0 meets another ellipse in fewer intersection points because at least one of them has multiplicity greater than 1:

[[File:dbldbl.png]]
::&lt;math&gt;x^2+4y^2-1=0:\ \hbox{two intersections of multiplicity 2}&lt;/math&gt;

[[File:intersect3.png]]
::&lt;math&gt;5x^2+6xy+5y^2+6y-5=0:\ \hbox{an intersection of multiplicity 3}&lt;/math&gt;

[[File:intersect4.png]]
::&lt;math&gt;4x^2+y^2+6x+2=0:\ \hbox{an intersection of multiplicity 4}&lt;/math&gt;

==Sketch of proof==
Write the equations for ''X'' and ''Y'' in [[homogeneous coordinates]] as
:&lt;math&gt;a_0z^m + a_1z^{m-1} + \dots + a_{m-1}z + a_m = 0&lt;/math&gt;
:&lt;math&gt;b_0z^n + b_1z^{n-1} + \dots + b_{n-1}z + b_n = 0&lt;/math&gt;
where ''a&lt;sub&gt;i&lt;/sub&gt;'' and ''b&lt;sub&gt;i&lt;/sub&gt;'' are homogeneous polynomials of degree ''i'' in ''x'' and ''y''. The points of intersection of ''X'' and ''Y'' correspond to the solutions of the system of equations. Form the [[Sylvester matrix]]; in the case ''m''=4, ''n''=3 this is

:&lt;math&gt;S=\begin{pmatrix} 
a_0 &amp; a_1 &amp; a_2 &amp; a_3 &amp; a_4 &amp; 0   &amp; 0 \\
0   &amp; a_0 &amp; a_1 &amp; a_2 &amp; a_3 &amp; a_4 &amp; 0 \\
0   &amp; 0   &amp; a_0 &amp; a_1 &amp; a_2 &amp; a_3 &amp; a_4 \\
b_0 &amp; b_1 &amp; b_2 &amp; b_3 &amp; 0   &amp; 0   &amp; 0 \\
0   &amp; b_0 &amp; b_1 &amp; b_2 &amp; b_3 &amp; 0   &amp; 0 \\
0   &amp; 0   &amp; b_0 &amp; b_1 &amp; b_2 &amp; b_3 &amp; 0 \\
0   &amp; 0   &amp; 0   &amp; b_0 &amp; b_1 &amp; b_2 &amp; b_3 \\
\end{pmatrix}.&lt;/math&gt;
The [[determinant]] |''S''| of ''S'', which is also called the [[resultant]] of the two polynomials, is 0 exactly when the two equations have a common solution in ''z''. The terms of |''S''|, for example (a&lt;sub&gt;0&lt;/sub&gt;)&lt;sup&gt;n&lt;/sup&gt;(b&lt;sub&gt;n&lt;/sub&gt;)&lt;sup&gt;m&lt;/sup&gt;, all have degree ''mn'', so |''S''| is a homogeneous polynomial of degree ''mn'' in ''x'' and ''y'' (recall that ''a''&lt;sub&gt;''i''&lt;/sub&gt; and ''b''&lt;sub&gt;''i''&lt;/sub&gt; are themselves polynomials). By the [[fundamental theorem of algebra]], this can be factored into ''mn'' linear factors so there are ''mn'' solutions to the system of equations. The linear factors correspond to the lines that join the origin to the points of intersection of the curves.&lt;ref&gt;Follows [https://archive.org/details/cu31924001544216 ''Plane Algebraic Curves''] by Harold Hilton  (Oxford 1920) p. 10&lt;/ref&gt;

==See also==
*[[AF+BG theorem]]
*[[BKK theorem]]

==Notes==
&lt;references/&gt;

==References==
* {{cite book | author=William Fulton | authorlink=William Fulton (mathematician) | title=Algebraic Curves | series=Mathematics Lecture Note Series | publisher=W.A. Benjamin | year=1974 | id={{Listed Invalid ISBN|0-8053-3081-4}} | page=112 }}
*{{citation| author-link = Isaac Newton|last=Newton |first=I.| year = 1966| title = [[Philosophiæ Naturalis Principia Mathematica|Principia Vol. I The Motion of Bodies]]| edition = based on Newton's 2nd edition (1713); translated by Andrew Motte (1729) and revised by [[Florian Cajori]] (1934)| publisher = University of California Press| location = Berkeley, CA| isbn = 978-0-520-00928-8}} Alternative translation of earlier (2nd) edition of Newton's ''Principia''.
* (generalization of theorem) http://mathoverflow.net/questions/42127/generalization-of-bezouts-theorem

==External links==
* {{springer|title=Bezout theorem|id=p/b016000}}
* {{MathWorld|title=Bézout's Theorem|urlname=BezoutsTheorem}}
* [http://www.mathpages.com/home/kmath544/kmath544.htm Bezout's Theorem at MathPages]

{{DEFAULTSORT:Bezouts Theorem}}
[[Category:Theorems in plane geometry]]
[[Category:Incidence geometry]]
[[Category:Intersection theory]]
[[Category:Theorems in algebraic geometry]]</text>
      <sha1>3l3b6udsszz2pa182bj493pt66gaeqe</sha1>
    </revision>
  </page>
  <page>
    <title>Circular error probable</title>
    <ns>0</ns>
    <id>316648</id>
    <revision>
      <id>866705127</id>
      <parentid>863541929</parentid>
      <timestamp>2018-11-01T00:46:59Z</timestamp>
      <contributor>
        <ip>24.96.14.167</ip>
      </contributor>
      <comment>Changes to [[Accuracy and precision]] article broke this wikilink.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11342">{{Redirect|Circular error|the circular error of a pendulum|pendulum|and|pendulum (mathematics)}}

[[File:Circular error probable - percentage.png|thumb|CEP concept and hit probability. 0.2% outside the outmost circle.]]

In the [[military science]] of [[ballistics]], '''circular error probable''' ('''CEP''')&lt;ref&gt;Circular Error Probable (CEP), Air Force Operational Test and Evaluation Center Technical Paper 6, Ver 2, July 1987, p. 1&lt;/ref&gt; (also '''circular error probability''' &lt;ref&gt;{{Cite document | last = Nelson | first = William | year = 1988 | title = Use of Circular Error Probability in Target Detection | url = http://www.dtic.mil/dtic/tr/fulltext/u2/a199190.pdf | location = Bedford, MA | publisher = The MITRE Corporation; United States Air Force }}&lt;/ref&gt; or '''circle of equal probability''' &lt;ref&gt;{{Cite book | last = Ehrlich | first = Robert | year = 1985 | title = Waging Nuclear Peace: The Technology and Politics of Nuclear Weapons | location = Albany, NY | publisher = [[State University of New York Press]] | page = [https://books.google.com/books?id=-tEpgCSNV7sC&amp;pg=PA63 63] }}&lt;/ref&gt;) is a measure of a weapon system's [[Accuracy and precision|precision]]. It is defined as the radius of a circle, centered on the mean, whose boundary is expected to include the landing points of 50% of the rounds; said otherwise, it is the [[median]] error radius.&lt;ref&gt;Circular Error Probable (CEP), Air Force Operational Test and Evaluation Center Technical Paper 6, Ver 2, July 1987, p. 1&lt;/ref&gt;&lt;ref&gt;{{Cite book | editor-last = Payne | editor-first = Craig | year = 2006 | title = Principles of Naval Weapon Systems | location = Annapolis, MD | publisher = [[Naval Institute Press]] | page = [https://books.google.com/books?id=F3q59-hcGDoC&amp;pg=PA342&amp;dq=%22precisely+50%22 342] }}&lt;/ref&gt; That is, if a given bomb design has a CEP of {{convert|100|m}}, when 100 are targeted at the same point, 50 will fall within a 100&amp;nbsp;m circle around their average impact point. (The distance between the target point and the average impact point is referred to as [[Unbiased estimator|bias]].)

There are associated concepts, such as the DRMS (distance root mean square), which is the square root of the average squared distance error, and R95, which is the radius of the circle where 95% of the values would fall in.

The concept of CEP also plays a role when measuring the accuracy of a position obtained by a navigation system, such as [[GPS]] or older systems such as [[LORAN]] and [[Loran-C]].

==Concept==

[[File:Circular error probable - example.png|thumb|20 hits distribution example]]

The original concept of CEP was based on a [[multivariate normal distribution#Bivariate case|circular bivariate normal]] distribution (CBN) with CEP as a parameter of the CBN just as μ and σ are parameters of the [[normal distribution]]. [[Munition]]s with this distribution behavior tend to cluster around the [[mean]] impact point, with most reasonably close, progressively fewer and fewer further away, and very few at long distance. That is, if CEP is ''n'' metres, 50% of rounds land within ''n'' metres of the mean impact, 43.7% between ''n'' and ''2n'', and 6.1% between ''2n'' and ''3n'' metres, and the proportion of rounds that land farther than three times the CEP from the mean is only 0.2%.

CEP is not a good measure of accuracy when this distribution behavior is not met. [[Precision-guided munition]]s generally have more "close misses" and so are not normally distributed. Munitions may also have larger [[standard deviation]] of range errors than the standard deviation of azimuth (deflection) errors, resulting in an elliptical [[confidence region]]. Munition samples may not be exactly on target, that is, the mean vector will not be (0,0). This is referred to as [[Unbiased estimator|bias]].

To incorporate accuracy into the CEP concept in these conditions, CEP can be defined as the square root of the [[mean square error]] (MSE). The MSE will be the sum of the [[variance]] of the range error plus the variance of the azimuth error plus the [[covariance]] of the range error with the azimuth error plus the square of the bias. Thus the MSE results from pooling all these sources of error, geometrically corresponding to [[radius]] of a [[circle]] within which 50% of rounds will land.

Several methods have been introduced to estimate CEP from shot data. Included in these methods are the plug-in approach of Blischke and Halpin (1966), the Bayesian approach of Spall and Maryak (1992), and the maximum likelihood approach of Winkler and Bickert (2012). The Spall and Maryak approach applies when the shot data represent a mixture of different projectile characteristics (e.g., shots from multiple munitions types or from multiple locations directed at one target).

==Conversion between CEP, DRMS, 2DRMS, and R95==
While 50% is a very common definition for CEP, the circle dimension can be defined for percentages. [[Percentile|Percentiles]] can be determined by recognizing that the horizontal position error is defined by a 2D vector which components are two [[uncorrelated]] orthogonal [[Normal distribution|Gaussian]] [[Random variable|random variables]] (one for each axis) each having a standard deviation &lt;math&gt;\sigma&lt;/math&gt;. The distance error is the magnitude of that vector; it is a property of [[Multivariate_normal_distribution|2D Gaussian vectors]] that the magnitude follows the [[Rayleigh distribution]], with a standard deviation &lt;math&gt;\Sigma=\sigma\sqrt{2}&lt;/math&gt;, which by definition is the DRMS (distance root mean square) value. In turn, the properties of the [[Rayleigh distribution]] are, that its [[percentile]] at level &lt;math&gt;F\in[0%,100%]&lt;/math&gt; is given by the following formula:

&lt;math&gt;Q(F,\sigma)=\sigma \sqrt{-2\ln(1-F/100)}&lt;/math&gt; 

or, expressed in terms of the DRMS:

&lt;math&gt;Q(F,\Sigma)=\Sigma \frac{\sqrt{-2\ln(1-F/100)}}{\sqrt{2}}&lt;/math&gt; 

The relation between &lt;math&gt;Q&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt; are given by the following table, where the &lt;math&gt;F&lt;/math&gt; values for DRMS and 2DRMS are specific to the Rayleigh distribution and are found numerically, while the CEP and R95 values are definitions:   

{|class="wikitable"
|-
! Measure of &lt;math&gt;Q&lt;/math&gt;
! Probability &lt;math&gt;F&lt;/math&gt;(%)
|-
| Distance [[root mean square]] ("DRMS")
| 63.213...
|-
| Circular error probability ("CEP", "CEP50")
| 50
|-
| Twice the distance root mean square ("2DRMS")
| 98.169...
|-
| 95% radius ("R95")
| 95
|}

We can then derive a conversion table to convert values expressed for one percentile level, to another&lt;ref name=gps&gt;Frank van Diggelen, "[http://gpsworld.com/gps-accuracy-lies-damn-lies-and-statistics/ GPS Accuracy: Lies, Damn Lies, and Statistics]", ''GPS World'', Vol 9 No. 1, January 1998&lt;/ref&gt;&lt;ref name=gnss&gt;Frank van Diggelen, "GNSS Accuracy – Lies, Damn Lies and Statistics", ''GPS World'', Vol 18 No. 1, January 2007. Sequel to previous article with similar title [http://www.gpsworld.com/gpsgnss-accuracy-lies-damn-lies-and-statistics-1134] [http://www.frankvandiggelen.com/wp-content/uploads/2009/03/2007-gps-world-accuracy-article-0107-van-diggelen-1.pdf]&lt;/ref&gt;. Said conversion table, giving the coefficients &lt;math&gt;\alpha&lt;/math&gt; to convert &lt;math&gt;X&lt;/math&gt; into &lt;math&gt;Y=\alpha.X&lt;/math&gt;, is given by:

{|class="wikitable"
|-
! From &lt;math&gt;X \downarrow&lt;/math&gt; to &lt;math&gt;Y \rightarrow&lt;/math&gt;
! RMS (&lt;math&gt;\sigma&lt;/math&gt;)
! CEP
! DRMS (&lt;math&gt;\Sigma&lt;/math&gt;)
! R95
! 2DRMS (&lt;math&gt;2\Sigma&lt;/math&gt;)
|-
! RMS (&lt;math&gt;\sigma&lt;/math&gt;)
| -
| 1.1774
| 1.4142
| 2.4477
| 2.8284 
|-
! CEP
| 0.8493
| –
| 1.2011
| 2.0789
| 2.4022
|-
! DRMS (&lt;math&gt;\Sigma&lt;/math&gt;)
| 0.7071
| 0.8326
| –
| 1.7308
| 2
|-
! R95
| 0.4085
| 0.4810
| 0.5778
| –
| 1.1555
|-
! 2DRMS (&lt;math&gt;2\Sigma&lt;/math&gt;)
| 0.3536
| 0.4163
| 0.5
| 0.8654
| –
|}

Example: a GPS receiver having a 1.25 m DRMS error, will have a 1.25&lt;math&gt;\times&lt;/math&gt;1.73 = 2.16 m R95 radius.

'''Warning:''' often, sensor datasheets or other publications state "RMS" values which in general, ''but not always''&lt;ref&gt;For instance, the International Hydrographic Organization, in the IHO standard for hydrographic survey S-44 (fifth edition) defines "the 95% confidence level for 2D quantities (e.g. position) is defined as 2.45 x standard deviation", which is true only if we are speaking about the standard deviation of the underlying 1D variable, defined as &lt;math&gt;\sigma&lt;/math&gt; above.&lt;/ref&gt;, stand for "DRMS" values. Also, be wary of habits coming from properties of a 1D [[normal distribution]], such as the [[68–95–99.7_rule|68-95-99.7 rule]], in essence trying to say that "R95 = 2DRMS". As shown above, these properties simply ''do not'' translate to the distance errors. Finally, mind that these values are obtained for a theoretical distribution; while generally being true for real data, these may be affected by other effects, which the model does not represent.

==Use in popular culture==
The term is used in the movie [[Clear and Present Danger (film)|''Clear and Present Danger'']] when the ground team reports "Circular error probability Zero. Impact with high order detonation. Have a nice day." Here CEP is meant to convey that the bomb landed exactly on target.{{citation needed|date=August 2017}}

==See also==
* [[Hoyt distribution]]
* [[Probable error]]

==References==
{{reflist}}

== Further reading ==
{{Refbegin}}
* Blischke, W. R. and Halpin, A. H. (1966). "Asymptotic properties of some estimators of quantiles of circular error." ''Journal of the American Statistical Association'', vol. 61 (315), pp.&amp;nbsp;618–32.  [https://www.jstor.org/stable/2282775 JSTOR]
* {{Cite book | last = MacKenzie | first = Donald A. | authorlink = Donald Angus MacKenzie | year = 1990 | title = Inventing Accuracy: A Historical Sociology of Nuclear Missile Guidance | location = Cambridge, Massachusetts | publisher = [[MIT Press]] | isbn = 978-0-262-13258-9 }}
* Grubbs, F. E. (1964). "Statistical measures of accuracy for riflemen and missile engineers". Ann Arbor, ML: Edwards Brothers. [http://ballistipedia.com/images/3/33/Statistical_Measures_for_Riflemen_and_Missile_Engineers_-_Grubbs_1964.pdf Ballistipedia pdf]
* Spall, J. C. and Maryak, J. L. (1992). "A feasible Bayesian estimator of quantiles for projectile accuracy from non-iid data." ''Journal of the American Statistical Association'', vol. 87 (419), pp.&amp;nbsp;676–81. [https://www.jstor.org/stable/2290205 JSTOR pdf]
* Daniel Wollschläger (2014), "Analyzing shape, accuracy, and precision of shooting results with shotGroups". [http://cran.fhcrc.org/web/packages/shotGroups/vignettes/shotGroups.pdf  Reference manual for shotGroups]
* Winkler, V. and Bickert, B. (2012). "Estimation of the circular error probability for a Doppler-Beam-Sharpening-Radar-Mode," in EUSAR. 9th European Conference on Synthetic Aperture Radar, pp.&amp;nbsp;368–71, 23/26 April 2012. [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6217081&amp;isnumber=6215928 ieeexplore.ieee.org]
{{Refend}}

== External links ==
* [http://ballistipedia.com/index.php?title=Circular_Error_Probable Circular Error Probable] in [http://ballistipedia.com Ballistipedia]

[[Category:Applied probability]]
[[Category:Military terminology]]
[[Category:Aerial bombs]]
[[Category:Artillery operation]]
[[Category:Ballistics]]
[[Category:Weapon guidance]]
[[Category:Accuracy and precision]]
[[Category:Statistical distance]]</text>
      <sha1>jbkkh6r51k8s4hasol9kdm9tw1lh47m</sha1>
    </revision>
  </page>
  <page>
    <title>Cubical complex</title>
    <ns>0</ns>
    <id>54829672</id>
    <revision>
      <id>846304050</id>
      <parentid>811179927</parentid>
      <timestamp>2018-06-17T21:06:16Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3432">In [[mathematics]], a '''cubical complex''' or '''cubical set''' is a [[Set (mathematics)|set]] composed of [[Point (geometry)|points]], [[line segment]]s, [[square]]s, [[cube]]s, and their [[Hypercube|''n''-dimensional counterparts]]. They are used analogously to [[simplicial complex]]es and [[CW complex]]es in the computation of the [[Homology (mathematics)|homology]] of [[topological space]]s.
[[File:SimpleGraf.jpg|thumb|All [[Graph (topology)|graphs]] are ([[Homeomorphism|homeomorphic]] to) 1-dimensional cubical complexes.]]

== Definitions ==

An '''elementary interval''' is a subset &lt;math&gt;I\subsetneq\mathbf{R}&lt;/math&gt; of the form

: &lt;math&gt;I = [\ell, \ell+1]\quad\text{or}\quad I=[\ell, \ell]&lt;/math&gt;

for some &lt;math&gt;\ell\in\mathbf{Z}&lt;/math&gt;. An '''elementary cube''' &lt;math&gt;Q&lt;/math&gt; is the finite product of elementary intervals, i.e.

: &lt;math&gt;Q=I_1\times I_2\times \cdots\times I_d\subsetneq \mathbf{R}^d&lt;/math&gt;

where &lt;math&gt;I_1,I_2,\ldots,I_d&lt;/math&gt; are elementary intervals. Equivalently, an elementary cube is any translate of a unit cube &lt;math&gt;[0,1]^n&lt;/math&gt; [[Embedding|embedded]] in [[Euclidean space]] &lt;math&gt;\mathbf{R}^d&lt;/math&gt; (for some &lt;math&gt;n,d\in\mathbf{N}\cup\{0\}&lt;/math&gt; with &lt;math&gt;n\leq d&lt;/math&gt;).&lt;ref&gt;{{Cite journal|last=Werman|first=Michael|last2=Wright|first2=Matthew L.|date=2016-07-01|title=Intrinsic Volumes of Random Cubical Complexes|url=https://link.springer.com/article/10.1007/s00454-016-9789-z|journal=Discrete &amp; Computational Geometry|language=en|volume=56|issue=1|pages=93–113|doi=10.1007/s00454-016-9789-z|issn=0179-5376|arxiv=1402.5367}}&lt;/ref&gt; A set &lt;math&gt;X\subseteq\mathbf{R}^d&lt;/math&gt; is a '''cubical''' '''complex''' (or '''cubical set''') if it can be written as a union of elementary cubes (or possibly, is [[Homeomorphism|homeomorphic]] to such a set).&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/55897585|title=Computational homology|last=Tomasz,|first=Kaczynski,|date=2004|publisher=Springer|others=Mischaikow, Konstantin Michael,, Mrozek, Marian,|isbn=9780387215976|location=New York|oclc=55897585}}&lt;/ref&gt;

=== Related terminology ===
Elementary intervals of length 0 (containing a single point) are called '''degenerate''', while those of length 1 are '''nondegenerate'''. The '''dimension''' of a cube is the number of nondegenerate intervals in &lt;math&gt;Q&lt;/math&gt;, denoted &lt;math&gt;\dim Q&lt;/math&gt;. The dimension of a cubical complex &lt;math&gt;X&lt;/math&gt; is the largest dimension of any cube in &lt;math&gt;X&lt;/math&gt;.

If &lt;math&gt;Q&lt;/math&gt; and &lt;math&gt;P&lt;/math&gt; are elementary cubes and &lt;math&gt;Q\subseteq P&lt;/math&gt;, then &lt;math&gt;Q&lt;/math&gt; is a '''face''' of &lt;math&gt;P&lt;/math&gt;. If &lt;math&gt;Q&lt;/math&gt; is a face of &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q\neq P&lt;/math&gt;, then &lt;math&gt;Q&lt;/math&gt; is a '''proper face''' of &lt;math&gt;P&lt;/math&gt;. If &lt;math&gt;Q&lt;/math&gt; is a face of &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;\dim Q=\dim P-1&lt;/math&gt;, then &lt;math&gt;Q&lt;/math&gt; is a '''primary face''' of &lt;math&gt;P&lt;/math&gt;.

== Algebraic topology ==
Main article: [[Cubical homology]]

In algebraic topology, cubical complexes are often useful for concrete calculations. In particular, there is a definition of homology for cubical complexes that coincides with the [[singular homology]], but is [[Computability|computable]]. 

== See also ==
{{Portal|Topology}}
* [[Simplicial complex]]
* [[Simplicial homology]]

== References ==
{{reflist}}

{{Topology}}

[[Category:Cubes]]
[[Category:Topological spaces]]
[[Category:Algebraic topology]]
[[Category:Computational topology]]</text>
      <sha1>pkxr1bp0kuiy001eaoig8u8t3cxjotb</sha1>
    </revision>
  </page>
  <page>
    <title>Data binning</title>
    <ns>0</ns>
    <id>18614570</id>
    <revision>
      <id>866001459</id>
      <parentid>854340137</parentid>
      <timestamp>2018-10-27T16:29:41Z</timestamp>
      <contributor>
        <ip>92.3.207.36</ip>
      </contributor>
      <comment>/* Example usage */Clarity</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3240">{{Expert-subject|Statistics|date=November 2008}}

'''Data binning''' (also called '''Discrete binning''' or '''bucketing''') is a [[data pre-processing]] technique used to reduce the effects of minor observation errors. The original data values which fall in a given small interval, a bin, are replaced by a value representative of that interval, often the central value. It is a form of [[Quantization (signal processing)|quantization]].

'''Statistical data binning''' is a way to group a number of more or less continuous values into a smaller number of "bins". For example, if you have data about a group of people, you might want to arrange their ages into a smaller number of age intervals (for example, grouping every five years together). It can also be used in [[multivariate statistics]], binning in several dimensions at once.

== Image data processing ==
In the context of [[image processing]], binning is the procedure of combining a cluster of [[pixel]]s into a single pixel. As such, in 2x2 binning, an array of 4 pixels becomes a single larger pixel,&lt;ref name="theory"&gt;{{cite web|title=Small explanation of binning in image processing.|url=http://www.starrywonders.com/binning.html|publisher=Steve Cannistra|accessdate=2011-01-18}}&lt;/ref&gt; reducing the overall number of pixels.

This aggregation, although associated with loss of information, reduces the amount of data to be processed, facilitating the analysis. For instance, binning the data may also reduce the impact of read noise on the processed image (at the cost of a lower resolution).

== Example usage ==
[[Histogram]]s are an example of data binning used in order to observe underlying [[Frequency distribution|distribution]]s. They typically occur in [[one-dimensional space]] and in [[Euclidean vector#Equality|equal]] [[Interval (mathematics)|interval]]s for ease of visualization.

Data binning may be used when small instrumental shifts in the spectral dimension from [[Mass_spectrometry|mass spectrometry]] (MS) or [[Nuclear magnetic resonance|nuclear magnetic resonance]] (NMR) experiments will be falsely interpreted as representing different components, when a collection of data profiles is subjected to [[pattern recognition]] analysis. A straightforward way to cope with this problem is by using binning techniques in which the spectrum is reduced in resolution to a sufficient degree to ensure that a given peak remains in its bin despite small spectral shifts between analyses. For example, in [[NMR]] the [[chemical shift]] axis may be discretized and coarsely binned, and in [[Mass_spectrometry|MS]] the spectral accuracies may be rounded to integer [[atomic mass unit]] values.

Also, several [[digital camera]] systems incorporate an automatic pixel binning function to improve image contrast.&lt;ref name="example"&gt;{{cite web|title=Use of binning in photography.|url=http://www.microscopyu.com/tutorials/java/digitalimaging/signaltonoise/index.html|publisher=Nikon, FSU|accessdate=2011-01-18}}&lt;/ref&gt;

==See also==
* [[Histogram]]
* [[Grouped data]]
* [[Level of measurement]]
* [[Quantization (signal processing)]]
* [[Discretization of continuous features]]

==References==
{{Reflist}}

[[Category:Statistical data coding]]


{{statistics-stub}}</text>
      <sha1>epptk47twlw0u4dr9id56gf5fs4plg9</sha1>
    </revision>
  </page>
  <page>
    <title>Double limit theorem</title>
    <ns>0</ns>
    <id>31243775</id>
    <revision>
      <id>793242473</id>
      <parentid>747463892</parentid>
      <timestamp>2017-07-31T14:49:54Z</timestamp>
      <contributor>
        <username>Wikid77</username>
        <id>1403682</id>
      </contributor>
      <comment>fix broken {cite arXiv} as {cite article} &amp; pre-spaced cite bars</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2591">In [[hyperbolic geometry]], [[William Thurston|Thurston's]] '''double limit theorem''' gives condition for a sequence of [[quasi-Fuchsian group]]s to have a convergent subsequence.  It was introduced in {{harvtxt|Thurston|1998|loc=theorem 4.1}} and is a major step in Thurston's proof of the [[hyperbolization theorem]] for the case of [[manifold]]s that fiber over the circle.

==Statement==
By [[Bers's theorem]], [[quasi-Fuchsian group]]s (of some fixed [[genus (mathematics)|genus]]) are parameterized by points in ''T''&amp;times;''T'', where ''T'' is [[Teichmüller space]] of the same genus.  Suppose that there is a sequence of quasi-Fuchsian groups corresponding to points (''g''&lt;sub&gt;''i''&lt;/sub&gt;, ''h''&lt;sub&gt;''i''&lt;/sub&gt;) in ''T''&amp;times;''T''.  Also suppose that  the sequences ''g''&lt;sub&gt;''i''&lt;/sub&gt;, ''h''&lt;sub&gt;''i''&lt;/sub&gt; converge to points μ,μ&amp;prime; in the [[Thurston boundary]] of Teichmüller space of projective [[measured lamination]]s. If the points μ,μ&amp;prime; have the property that any nonzero measured lamination has positive intersection number with at least one of them, then the sequence of quasi-Fuchsian groups has a subsequence that converges algebraically.

==References==
*{{citation |first=John |last=Holt |url= http://www.cmp.caltech.edu/~dannyc/courses/geom/holt_notes.ps.gz |title=The double limit theorem |year=2001}}
*{{Citation |last1=Kapovich |first1=Michael |title= Hyperbolic manifolds and discrete groups |origyear=2001 |publisher= Birkhäuser Boston |location= Boston, MA |series= Modern Birkhäuser Classics |isbn= 978-0-8176-4912-8 |doi= 10.1007/978-0-8176-4913-5 |mr= 1792613 |year=2009}}
*{{Citation |last1=Otal |first1= Jean-Pierre |title= Le théorème d'hyperbolisation pour les variétés fibrées de dimension 3 |mr=1402300 |year=1996 |journal= Astérisque | issn=0303-1179 |issue=235}} Translated into English as {{Citation |last1=Otal |first1= Jean-Pierre | editor1-last= Kay |editor1-first= Leslie D. |title= The hyperbolization theorem for fibered 3-manifolds |origyear=1996 |url= https://books.google.com/books?id=pVObtYVehxIC |publisher=[[American Mathematical Society]] |location= Providence, R.I. |series= SMF/AMS Texts and Monographs |isbn= 978-0-8218-2153-4 | mr=1855976 | year=2001 | volume=7}}
*{{cite article |last1=Thurston |first1=William P. |author1-link= William Thurston |title= Hyperbolic Structures on 3-manifolds, II: Surface groups and 3-manifolds which fiber over the circle |origyear=1986 |eprint= math/9801045 |year=1998}}

[[Category:Kleinian groups]]
[[Category:Hyperbolic geometry]]
[[Category:Theorems in geometry]]</text>
      <sha1>c6pwmlkl4uixlgx1dycj4uloye43wa9</sha1>
    </revision>
  </page>
  <page>
    <title>EdgeRank</title>
    <ns>0</ns>
    <id>38090349</id>
    <revision>
      <id>821793277</id>
      <parentid>814001818</parentid>
      <timestamp>2018-01-22T17:37:42Z</timestamp>
      <contributor>
        <username>Dr Zimbu</username>
        <id>7198309</id>
      </contributor>
      <comment>revert content removal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3791">'''EdgeRank''' is the name commonly given to the [[algorithm]] that [[Facebook]] uses to determine what articles should be displayed in a user's [[News Feed (Facebook)|News Feed]]. As of 2011, Facebook has stopped using the EdgeRank system and uses a [[machine learning]] algorithm that, as of 2013, takes more than 100,000 factors into account.&lt;ref name=":0"&gt;{{cite web|last=McGee|first=Matt|title=EdgeRank Is Dead: Facebook’s News Feed Algorithm Now Has Close To 100K Weight Factors|url=http://marketingland.com/edgerank-is-dead-facebooks-news-feed-algorithm-now-has-close-to-100k-weight-factors-55908|accessdate=28 May 2014|date=Aug 16, 2013}}&lt;/ref&gt;

EdgeRank was developed and implemented by [[Serkan Piantino]].

== Formula and factors ==
In 2010, a simplified version of the EdgeRank algorithm was presented as:

:&lt;math&gt;\sum_{\mathrm{edges\,}e} u_e w_e d_e&lt;/math&gt;
where:
: &lt;math&gt;u_e&lt;/math&gt; is user affinity.
: &lt;math&gt;w_e&lt;/math&gt; is how the content is weighted.
: &lt;math&gt;d_e&lt;/math&gt; is a time-based decay parameter.

* User Affinity: The User Affinity part of the algorithm in Facebook's [http://www.paulramondo.com/facebook-edgerank EdgeRank] looks at the relationship and proximity of the user and the content (post/status update).&lt;ref name=":0" /&gt;
* Content Weight: What action was taken by the user on the content.&lt;ref name=":0" /&gt;
* Time-Based Decay Parameter: New or old. Newer posts tend to hold a higher place than older posts.&lt;ref name=":0" /&gt;

Some of the methods that Facebook uses to adjust the parameters are proprietary and not available to the public.&lt;ref name="techcrunch"&gt;{{cite web|url=https://techcrunch.com/2010/04/22/facebook-edgerank/ |title=EdgeRank: The Secret Sauce That Makes Facebook's News Feed Tick |publisher=techcrunch.com |date=2010-04-22 |accessdate=2012-12-08}}&lt;/ref&gt;

== Impact ==

EdgeRank and its successors have a broad impact on what users actually see out of what they ostensibly follow: for instance, the selection can produce a [[filter bubble]] (if users are exposed to updates which confirm their opinions etc.) or alter people's mood (if users are shown a disproportionate amount of positive or negative updates).&lt;ref&gt;{{cite news|first1=Dominic|last1=Rushe|title=Facebook sorry – almost – for secret psychological experiment on users|url=https://www.theguardian.com/technology/2014/oct/02/facebook-sorry-secret-psychological-experiment-users|newspaper=The Guardian|date=2014-10-02|issn=0261-3077|via=The Guardian}}&lt;/ref&gt;

As a result, for Facebook pages, the typical [[engagement rate]] is less than 1 % (or less than 0.1 % for the bigger ones)&lt;ref&gt;{{cite web|accessdate=2016-12-17|title=What is a good Facebook engagement rate? See numbers here|url=http://www.michaelleander.me/blog/facebook-engagement-rate-benchmark/|website=www.michaelleander.me}}&lt;/ref&gt; and [[organic reach]] 10 % or less for most non-profits.&lt;ref&gt;{{cite web|accessdate=2016-12-17|title=The 2016 Social Media Director’s Guide to Benchmarks &amp;#124; M+R|url=http://www.mrss.com/lab/the-2016-social-media-directors-guide-to-benchmarks/|website=www.mrss.com}}&lt;/ref&gt;

As a consequence, for pages it may be nearly impossible to reach any significant audience without paying to promote their content.&lt;ref&gt;{{cite web|accessdate=2016-12-17|title=Facebook Organic Reach Is DEAD (Here's What You Can Do About It)|url=http://www.hypebot.com/hypebot/2016/09/facebook-organic-reach-is-dead-heres-what-you-can-do-about-it.html|website=hypebot}}&lt;/ref&gt;

==See also==
* [[PageRank]], the ranking algorithm used by Google's search engine

==References==
{{Reflist}}

==External links==
* [http://edgerank.net edgerank.net]
* [http://www.facebook.com/help/327131014036297/ Facebook - How News Feed Works]

{{Facebook navbox}}

[[Category:Facebook]]
[[Category:Algorithms]]


{{Web-stub}}</text>
      <sha1>dvuexd1joc9usop8tkftlj2sdkswhii</sha1>
    </revision>
  </page>
  <page>
    <title>Essential matrix</title>
    <ns>0</ns>
    <id>7931806</id>
    <revision>
      <id>868197000</id>
      <parentid>866058271</parentid>
      <timestamp>2018-11-10T17:08:57Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */clean up, replaced: IEEE Trans. on Pattern Analysis and Machine Intelligence → IEEE Transactions on Pattern Analysis and Machine Intelligence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21348">{{Technical|date=September 2010}}&lt;!--moved from talk page--&gt;
In [[computer vision]], the '''essential matrix''' is a &lt;math&gt; 3 \times 3 &lt;/math&gt; [[Matrix (mathematics)|matrix]], &lt;math&gt; \mathbf{E} &lt;/math&gt;, with some additional properties described below, which relates corresponding points in [[Stereo vision|stereo images]] assuming that the cameras satisfy the [[pinhole camera model]].

==Function==
More specifically, if &lt;math&gt; \mathbf{y}&lt;/math&gt; and &lt;math&gt; \mathbf{y}' &lt;/math&gt; are homogeneous [[Camera matrix#Normalized camera matrix and normalized image coordinates|''normalized'' image coordinates]] in image 1 and 2, respectively, then

:&lt;math&gt; (\mathbf{y}')^\top \, \mathbf{E} \, \mathbf{y} = 0 &lt;/math&gt;

if &lt;math&gt; \mathbf{y}&lt;/math&gt; and &lt;math&gt; \mathbf{y}' &lt;/math&gt; correspond to the same 3D point in the scene.

The above relation which defines the essential matrix was published in 1981 by [[H. Christopher Longuet-Higgins]], introducing the concept to the computer vision community. [[Richard Hartley (scientist)|Richard Hartley]] and [[Andrew Zisserman]]'s book reports that an analogous matrix appeared in [[photogrammetry]] long before that. Longuet-Higgins' paper includes an algorithm for estimating &lt;math&gt; \mathbf{E} &lt;/math&gt; from a set of corresponding normalized image coordinates as well as an algorithm for determining the relative position and orientation of the two cameras given that &lt;math&gt; \mathbf{E} &lt;/math&gt; is known. Finally, it shows how the 3D coordinates of the image points can be determined with the aid of the essential matrix.

==Use==
The essential matrix can be seen as a precursor to the [[fundamental matrix (computer vision)|fundamental matrix]]. Both matrices can be used for establishing constraints between matching image points, but the essential matrix can only be used in relation to calibrated cameras since the inner camera parameters must be known in order to achieve the normalization. If, however, the cameras are calibrated the essential matrix can be useful for determining both the relative position and orientation between the cameras and the 3D position of corresponding image points.

== Derivation and definition ==
This derivation follows the paper by Longuet-Higgins.

Two normalized cameras project the 3D world onto their respective image planes. Let the 3D coordinates of a point '''P''' be &lt;math&gt; (x_1, x_2, x_3) &lt;/math&gt; and &lt;math&gt; (x'_1, x'_2, x'_3) &lt;/math&gt; relative to each camera's coordinate system. Since the cameras are normalized, the corresponding image coordinates are

:&lt;math&gt;
\begin{pmatrix} y_1 \\ y_2 \end{pmatrix} = \frac{1}{x_3} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} &lt;/math&gt; &amp;nbsp; and &amp;nbsp; &lt;math&gt; \begin{pmatrix} y'_1 \\ y'_2 \end{pmatrix} = \frac{1}{x'_3} \begin{pmatrix} x'_1 \\ x'_2 \end{pmatrix} &lt;/math&gt;

A homogeneous representation of the two image coordinates is then given by

:&lt;math&gt; \begin{pmatrix} y_1 \\ y_2 \\ 1 \end{pmatrix} = \frac{1}{x_3} \begin{pmatrix} x_1 \\ x_2 \\ x_{3} \end{pmatrix} &lt;/math&gt; &amp;nbsp; and &amp;nbsp; &lt;math&gt; \begin{pmatrix} y'_1 \\ y'_2 \\ 1 \end{pmatrix} = \frac{1}{x'_3} \begin{pmatrix} x'_1 \\ x'_2 \\ x'_{3} \end{pmatrix} &lt;/math&gt;

which also can be written more compactly as

: &lt;math&gt;
\mathbf{y} = \frac{1}{x_{3}} \, \tilde{\mathbf{x}}
&lt;/math&gt; &amp;nbsp; and &amp;nbsp; &lt;math&gt; \mathbf{y}' = \frac{1}{x'_{3}} \, \tilde{\mathbf{x}}'
&lt;/math&gt;

where &lt;math&gt; \mathbf{y} &lt;/math&gt; and &lt;math&gt; \mathbf{y}' &lt;/math&gt; are homogeneous representations of the 2D image coordinates and &lt;math&gt; \tilde{\mathbf{x}} &lt;/math&gt; and &lt;math&gt; \tilde{\mathbf{x}}' &lt;/math&gt; are proper 3D coordinates but in two different coordinate systems.

Another consequence of the normalized cameras is that their respective coordinate systems are related by means of a translation and rotation. This implies that the two sets of 3D coordinates are related as

:&lt;math&gt; \tilde{\mathbf{x}}' = \mathbf{R} \, (\tilde{\mathbf{x}} - \mathbf{t}) &lt;/math&gt;

where &lt;math&gt; \mathbf{R} &lt;/math&gt; is a &lt;math&gt; 3 \times 3 &lt;/math&gt; rotation matrix and &lt;math&gt; \mathbf{t} &lt;/math&gt; is a 3-dimensional translation vector.

The essential matrix is then defined as:

:{| style="font-size:120%; border:3px dashed red;" cellpadding="8"
|-
|&lt;math&gt; \mathbf{E} = \mathbf{R} \, [\mathbf{t}]_{\times} &lt;/math&gt;
|}

where &lt;math&gt; [\mathbf{t}]_{\times} &lt;/math&gt; is the [[Cross product#Conversion to matrix multiplication|matrix representation of the cross product]] with &lt;math&gt; \mathbf{t} &lt;/math&gt;.

To see that this definition of the essential matrix describes a constraint on corresponding image coordinates multiply &lt;math&gt; \mathbf{E} &lt;/math&gt; from left and right with the 3D coordinates of point '''P''' in the two different coordinate systems:

: &lt;math&gt; (\tilde{\mathbf{x}}')^{T} \, \mathbf{E} \, \tilde{\mathbf{x}} \, \stackrel{(1)}{=} \,(\tilde{\mathbf{x}} - \mathbf{t})^{T} \, \mathbf{R}^{T} \, \mathbf{R} \, [\mathbf{t}]_{\times} \, \tilde{\mathbf{x}} \, \stackrel{(2)}{=} \, (\tilde{\mathbf{x}} - \mathbf{t})^{T} \, [\mathbf{t}]_{\times} \, \tilde{\mathbf{x}} \, \stackrel{(3)}{=} \, 0
&lt;/math&gt;

# Insert the above relations between &lt;math&gt; \tilde{\mathbf{x}}' &lt;/math&gt; and &lt;math&gt; \tilde{\mathbf{x}} &lt;/math&gt; and the definition of &lt;math&gt; \mathbf{E} &lt;/math&gt; in terms of &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt;.
# &lt;math&gt; \mathbf{R}^{T} \, \mathbf{R} = \mathbf{I} &lt;/math&gt; since &lt;math&gt; \mathbf{R} &lt;/math&gt; is a rotation matrix.
# Properties of the [[Cross product#Conversion to matrix multiplication|matrix representation of the cross product]].

Finally, it can be assumed that both &lt;math&gt; x_{3} &lt;/math&gt; and &lt;math&gt; x'_{3} &lt;/math&gt; are &gt; 0, otherwise they are not visible in both cameras. This gives

:&lt;math&gt; 0 = (\tilde{\mathbf{x}}')^{T} \, \mathbf{E} \, \tilde{\mathbf{x}} = \frac{1}{x'_{3}} (\tilde{\mathbf{x}}')^{T} \, \mathbf{E} \, \frac{1}{x_{3}} \tilde{\mathbf{x}} = (\mathbf{y}')^{T} \, \mathbf{E} \, \mathbf{y}
&lt;/math&gt;

which is the constraint that the essential matrix defines between corresponding image points.

== Properties of the essential matrix ==
Not every arbitrary &lt;math&gt; 3 \times 3 &lt;/math&gt; matrix can be an essential matrix for some stereo cameras. To see this notice that it is defined as the matrix product of one [[rotation matrix]] and one [[skew-symmetric matrix]], both &lt;math&gt; 3 \times 3 &lt;/math&gt;.  The skew-symmetric matrix must have two [[singular values]] which are equal and another which is zero.  The multiplication of the rotation matrix does not change the singular values which means that also the essential matrix has two singular values which are equal and one which is zero.  The properties described here are sometimes referred to as ''internal constraints'' of the essential matrix.

If the essential matrix &lt;math&gt; \mathbf{E} &lt;/math&gt; is multiplied by a non-zero scalar, the result is again an essential matrix which defines exactly the same constraint as &lt;math&gt; \mathbf{E} &lt;/math&gt; does.  This means that &lt;math&gt; \mathbf{E} &lt;/math&gt; can be seen as an element of a [[projective space]], that is, two such matrices are considered equivalent if one is a non-zero scalar multiplication of the other.  This is a relevant position, for example, if &lt;math&gt; \mathbf{E} &lt;/math&gt; is estimated from image data. However, it is also possible to take the position that &lt;math&gt; \mathbf{E} &lt;/math&gt; is defined as

: &lt;math&gt; \mathbf{E} =[\mathbf{t}]_{\times} \, \mathbf{R}
&lt;/math&gt;

and then &lt;math&gt; \mathbf{E} &lt;/math&gt; has a well-defined "scaling". It depends on the application which position is the more relevant.

The constraints can also be expressed as
: &lt;math&gt; \det \mathbf{E} = 0
&lt;/math&gt;
and 
: &lt;math&gt; 2 \mathbf{E} \mathbf{E}^T \mathbf{E} - \operatorname{tr} ( \mathbf{E} \mathbf{E}^T ) \mathbf{E} = 0 .
&lt;/math&gt;
Here the last equation is matrix constraint, which can be seen as 9 constraints, one for each matrix element. 
These constraints are often used for determining the essential matrix from five corresponding point pairs.

The essential matrix has five or six degrees of freedom, depending on whether or not it is seen as a projective element. The rotation matrix &lt;math&gt; \mathbf{R} &lt;/math&gt; and the translation vector &lt;math&gt; \mathbf{t} &lt;/math&gt; have three degrees of freedom each, in total six. If the essential matrix is considered as a projective element, however, one degree of freedom related to scalar multiplication must be subtracted leaving five degrees of freedom in total.

== Estimation of the essential matrix ==

Given a set of corresponding image points it is possible to estimate an essential matrix which satisfies the defining epipolar constraint for all the points in the set.  However, if the image points are subject to noise, which is the common case in any practical situation, it is not possible to find an essential matrix which satisfies all constraints exactly.

Depending on how the error related to each constraint is measured, it is possible to determine or estimate an essential matrix which optimally satisfies the constraints for a given set of corresponding image points.  The most straightforward approach is to set up a [[total least squares]] problem, commonly known as the [[eight-point algorithm]].

== Determining R and t from E ==
Given that the essential matrix has been determined for a stereo camera pair, for example, using the estimation method above this information can be used for determining also the rotation and translation (up to a scaling) between the two camera's coordinate systems. In these derivations &lt;math&gt; \mathbf{E} &lt;/math&gt; is seen as a projective element rather than having a well-determined scaling.

The following method for determining &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt; is based on performing a [[Singular value decomposition|SVD]] of &lt;math&gt; \mathbf{E} &lt;/math&gt;, see Hartley &amp; Zisserman's book. It is also possible to determine &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt; without an SVD, for example, following Longuet-Higgins' paper.

=== Finding one solution ===
An SVD of &lt;math&gt; \mathbf{E} &lt;/math&gt; gives

:&lt;math&gt; \mathbf{E} = \mathbf{U} \, \mathbf{\Sigma} \, \mathbf{V}^{T} &lt;/math&gt;

where &lt;math&gt; \mathbf{U} &lt;/math&gt; and &lt;math&gt; \mathbf{V} &lt;/math&gt; are orthogonal &lt;math&gt; 3 \times 3 &lt;/math&gt; matrices and &lt;math&gt; \mathbf{\Sigma} &lt;/math&gt; is a &lt;math&gt; 3 \times 3 &lt;/math&gt; diagonal matrix with

:&lt;math&gt; \mathbf{\Sigma} = \begin{pmatrix} s &amp; 0 &amp; 0 \\ 0 &amp; s &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} &lt;/math&gt;

The diagonal entries of &lt;math&gt; \mathbf{\Sigma} &lt;/math&gt; are the singular values of &lt;math&gt; \mathbf{E} &lt;/math&gt; which, according to the [[#Properties of the essential matrix|internal constraints]] of the essential matrix, must consist of two identical and one zero value. Define

:&lt;math&gt; \mathbf{W} = \begin{pmatrix} 0 &amp; -1 &amp; 0 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} &lt;/math&gt; &amp;nbsp; with &amp;nbsp; &lt;math&gt; \mathbf{W}^{-1} = \mathbf{W}^{T} =\begin{pmatrix} 0 &amp; 1 &amp; 0 \\ -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} &lt;/math&gt;

and make the following [[ansatz]]

:&lt;math&gt; [\mathbf{t}]_{\times} = \mathbf{U} \, \mathbf{W} \, \mathbf{\Sigma} \, \mathbf{U}^{T} &lt;/math&gt;

:&lt;math&gt; \mathbf{R} = \mathbf{U} \, \mathbf{W}^{-1} \, \mathbf{V}^{T} &lt;/math&gt;

Since &lt;math&gt; \mathbf{\Sigma} &lt;/math&gt; may not completely fulfill the constraints when dealing with real world data (f.e. camera images), the alternative

:&lt;math&gt; [\mathbf{t}]_{\times} = \mathbf{U} \, \mathbf{Z} \, \mathbf{U}^{T} &lt;/math&gt; &amp;nbsp; with &amp;nbsp; &lt;math&gt; \mathbf{Z} = \begin{pmatrix} 0 &amp; 1 &amp; 0 \\ -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} &lt;/math&gt;

may help.

=== Showing that it is valid ===
First, these expressions for &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; [\mathbf{t}]_{\times} &lt;/math&gt; do satisfy the defining equation for the essential matrix

:&lt;math&gt; [\mathbf{t}]_{\times}\,\mathbf{R}  =  \mathbf{U} \, \mathbf{W} \, \mathbf{\Sigma} \, \mathbf{U}^{T} \mathbf{U} \, \mathbf{W}^{-1} \, \mathbf{V}^{T}\, = \mathbf{U} \, \mathbf{\Sigma} \, \mathbf{V}^{T} = \mathbf{E} &lt;/math&gt;

Second, it must be shown that this &lt;math&gt; [\mathbf{t}]_{\times} &lt;/math&gt; is a matrix representation of the cross product for some &lt;math&gt; \mathbf{t} &lt;/math&gt;. Since

:&lt;math&gt; \mathbf{W} \, \mathbf{\Sigma} = \begin{pmatrix} 0 &amp; -s &amp; 0 \\ s &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} &lt;/math&gt;

it is the case that &lt;math&gt; \mathbf{W} \, \mathbf{\Sigma} &lt;/math&gt; is skew-symmetric, i.e., &lt;math&gt; (\mathbf{W} \, \mathbf{\Sigma})^{T} = - \mathbf{W} \, \mathbf{\Sigma} &lt;/math&gt;. This is also the case for our &lt;math&gt; [\mathbf{t}]_{\times} &lt;/math&gt;, since

:&lt;math&gt; ([\mathbf{t}]_{\times})^{T} = \mathbf{U} \, (\mathbf{W} \, \mathbf{\Sigma})^{T} \, \mathbf{U}^{T} = - \mathbf{U} \, \mathbf{W} \, \mathbf{\Sigma} \, \mathbf{U}^{T} = - [\mathbf{t}]_{\times} &lt;/math&gt;

According to the general properties of the [[Cross product#Conversion to matrix multiplication|matrix representation of the cross product]] it then follows that &lt;math&gt; [\mathbf{t}]_{\times} &lt;/math&gt; must be the cross product operator of exactly one vector &lt;math&gt; \mathbf{t} &lt;/math&gt;.

Third, it must also need to be shown that the above expression for &lt;math&gt; \mathbf{R} &lt;/math&gt; is a rotation matrix. It is the product of three matrices which all are orthogonal which means that &lt;math&gt;\mathbf{R}&lt;/math&gt;, too, is orthogonal or &lt;math&gt; \det(\mathbf{R}) = \pm 1 &lt;/math&gt;. To be a proper rotation matrix it must also satisfy &lt;math&gt; \det(\mathbf{R}) = 1 &lt;/math&gt;. Since, in this case, &lt;math&gt; \mathbf{E} &lt;/math&gt; is seen as a projective element this can be accomplished by reversing the sign of &lt;math&gt; \mathbf{E} &lt;/math&gt; if necessary.

=== Finding all solutions ===
So far one possible solution for &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt; has been established given &lt;math&gt; \mathbf{E} &lt;/math&gt;. It is, however, not the only possible solution and it may not even be a valid solution from a practical point of view. To begin with, since the scaling of &lt;math&gt; \mathbf{E} &lt;/math&gt; is undefined, the scaling of &lt;math&gt; \mathbf{t} &lt;/math&gt; is also undefined. It must lie in the [[Kernel (matrix)|null space]] of &lt;math&gt; \mathbf{E} &lt;/math&gt; since

:&lt;math&gt; \mathbf{E} \, \mathbf{t} = \mathbf{R} \, [\mathbf{t}]_{\times} \, \mathbf{t} = \mathbf{0} &lt;/math&gt;

For the subsequent analysis of the solutions, however, the exact scaling of &lt;math&gt; \mathbf{t} &lt;/math&gt; is not so important as its "sign", i.e., in which direction it points. Let &lt;math&gt; \hat{\mathbf{t}} &lt;/math&gt; be normalized vector in the null space of &lt;math&gt; \mathbf{E} &lt;/math&gt;. It is then the case that both &lt;math&gt; \hat{\mathbf{t}} &lt;/math&gt; and &lt;math&gt; -\hat{\mathbf{t}} &lt;/math&gt; are valid translation vectors relative &lt;math&gt; \mathbf{E} &lt;/math&gt;. It is also possible to change &lt;math&gt; \mathbf{W} &lt;/math&gt; into &lt;math&gt; \mathbf{W}^{-1} &lt;/math&gt; in the derivations of &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt; above. For the translation vector this only causes a change of sign, which has already been described as a possibility. For the rotation, on the other hand, this will produce a different transformation, at least in the general case.

To summarize, given &lt;math&gt; \mathbf{E} &lt;/math&gt; there are two opposite directions which are possible for &lt;math&gt; \mathbf{t} &lt;/math&gt; and two different rotations which are compatible with this essential matrix. In total this gives four classes of solutions for the rotation and translation between the two camera coordinate systems. On top of that, there is also an unknown scaling &lt;math&gt; s &gt; 0 &lt;/math&gt; for the chosen translation direction.

It turns out, however, that only one of the four classes of solutions can be realized in practice. Given a pair of corresponding image coordinates, three of the solutions will always produce a 3D point which lies ''behind'' at least one of the two cameras and therefore cannot be seen. Only one of the four classes will consistently produce 3D points which are in front of both cameras. This must then be the correct solution. Still, however, it has an undetermined positive scaling related to the translation component.

It should be noted that the above determination of &lt;math&gt; \mathbf{R} &lt;/math&gt; and &lt;math&gt; \mathbf{t} &lt;/math&gt; assumes that &lt;math&gt; \mathbf{E} &lt;/math&gt; satisfy the [[#Properties of the essential matrix|internal constraints of the essential matrix]]. If this is not the case which, for example, typically is the case if &lt;math&gt; \mathbf{E} &lt;/math&gt; has been estimated from real (and noisy) image data, it has to be assumed that it approximately satisfy the internal constraints. The vector &lt;math&gt; \hat{\mathbf{t}} &lt;/math&gt; is then chosen as right singular vector of &lt;math&gt; \mathbf{E} &lt;/math&gt; corresponding to the smallest singular value.

== 3D points from corresponding image points ==
The problem to be solved there is how to compute &lt;math&gt; (x_{1}, x_{2}, x_{3}) &lt;/math&gt; given corresponding normalized image coordinates &lt;math&gt; (y_{1}, y_{2}) &lt;/math&gt; and &lt;math&gt; (y'_{1}, y'_{2}) &lt;/math&gt;. If the essential matrix is known and the corresponding rotation and translation transformations have been determined, this algorithm (described in Longuet-Higgins' paper) provides a solution.

Let &lt;math&gt; \mathbf{r}_{k} &lt;/math&gt; denote row ''k'' of the rotation matrix &lt;math&gt; \mathbf{R} &lt;/math&gt;:

:&lt;math&gt; \mathbf{R} = \begin{pmatrix} - \mathbf{r}_{1} - \\ - \mathbf{r}_{2} - \\ - \mathbf{r}_{3} - \end{pmatrix} &lt;/math&gt;

Combining the above relations between 3D coordinates in the two coordinate systems and the mapping between 3D and 2D points described earlier gives

:&lt;math&gt; y'_{1} = \frac{x'_{1}}{x'_{3}} = \frac{\mathbf{r}_{1} \cdot (\tilde{\mathbf{x}} - \mathbf{t})}{\mathbf{r}_{3} \cdot (\tilde{\mathbf{x}} - \mathbf{t})} = \frac{\mathbf{r}_{1} \cdot (\mathbf{y} - \mathbf{t}/x_{3})}{\mathbf{r}_{3} \cdot (\mathbf{y} - \mathbf{t}/x_{3})} &lt;/math&gt;

or

:&lt;math&gt;x_{3} = \frac{ (\mathbf{r}_{1} - y'_{1} \, \mathbf{r}_{3}) \cdot \mathbf{t} }{ (\mathbf{r}_{1} - y'_{1} \, \mathbf{r}_{3}) \cdot \mathbf{y} } &lt;/math&gt;

Once &lt;math&gt; x_{3} &lt;/math&gt; is determined, the other two coordinates can be computed as

:&lt;math&gt; \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = x_3 \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} &lt;/math&gt;

The above derivation is not unique. It is also possible to start with an expression for &lt;math&gt; y'_{2} &lt;/math&gt; and derive an expression for &lt;math&gt; x_{3} &lt;/math&gt; according to

:&lt;math&gt;x_{3} = \frac{ (\mathbf{r}_{2} - y'_{2} \, \mathbf{r}_{3}) \cdot \mathbf{t} }{ (\mathbf{r}_{2} - y'_{2} \, \mathbf{r}_{3}) \cdot \mathbf{y} } &lt;/math&gt;

In the ideal case, when the camera maps the 3D points according to a perfect pinhole camera and the resulting 2D points can be detected without any noise, the two expressions for &lt;math&gt; x_{3} &lt;/math&gt; are equal. In practice, however, they are not and it may be advantageous to combine the two estimates of &lt;math&gt; x_{3} &lt;/math&gt;, for example, in terms of some sort of average.

There are also other types of extensions of the above computations which are possible.  They started with an expression of the primed image coordinates and derived 3D coordinates in the unprimed system.  It is also possible to start with unprimed image coordinates and obtain primed 3D coordinates, which finally can be transformed into unprimed 3D coordinates.  Again, in the ideal case the result should be equal to the above expressions, but in practice they may deviate.

A final remark relates to the fact that if the essential matrix is determined from corresponding image coordinate, which often is the case when 3D points are determined in this way, the translation vector &lt;math&gt; \mathbf{t} &lt;/math&gt; is known only up to an unknown positive scaling. As a consequence, the reconstructed 3D points, too, are undetermined with respect to a positive scaling.

== Toolboxes ==
*[https://www.mathworks.com/matlabcentral/fileexchange/67580-essential-matrix-estimation Essential Matrix Estimation] in MATLAB (Manolis Lourakis).

== External links ==
*[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.64.7518 An Investigation of the Essential Matrix] by R.I. Hartley

== References ==
{{refbegin}}
* {{cite journal |
title=An efficient solution to the five-point relative pose problem |
author=David Nistér|
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|date=June 2004|
volume=26|
issue=6|
pages=756–777|
doi=10.1109/TPAMI.2004.17 |
pmid=18579936}}
* {{cite journal |
title=Recent Developments on Direct Relative Orientation |
author=H. Stewénius and C. Engels and D. Nistér|
journal=ISPRS Journal of Photogrammetry and Remote Sensing|date=June 2006|
volume=60|
issue=4|
pages=284–294|
doi=10.1016/j.isprsjprs.2006.03.005 |
pmid=}}
* {{cite journal |
title=A computer algorithm for reconstructing a scene from two projections |
author=H. Christopher Longuet-Higgins |
journal=Nature |date=September 1981 |
volume=293 |
pages=133–135 |
doi=10.1038/293133a0
 |issue=5828}}
* {{cite book |
author=Richard Hartley and Andrew Zisserman |
title=Multiple View Geometry in computer vision |
publisher=Cambridge University Press|
year=2003 |
isbn=978-0-521-54051-3}}
* {{cite book |
author=Yi Ma |author2=Stefano Soatto|author2-link=Stefano Soatto |author3=Jana Košecká|author3-link=Jana Košecká |author4=S. Shankar Sastry|author4-link=S. Shankar Sastry |
title=An Invitation to 3-D Vision |
publisher=Springer |
year=2004 |
isbn=0-387-00893-4}}
* {{cite book |
author=Gang Xu and Zhengyou Zhang |
title=Epipolar geometry in Stereo, Motion and Object Recognition |
publisher=Kluwer Academic Publishers |
year=1996 |
isbn=978-0-7923-4199-4}}
{{refend}}

[[Category:Geometry in computer vision]]</text>
      <sha1>j1l33n13sy0ihpq604xemvh5qoszuow</sha1>
    </revision>
  </page>
  <page>
    <title>Event calculus</title>
    <ns>0</ns>
    <id>2897680</id>
    <revision>
      <id>870616954</id>
      <parentid>870616695</parentid>
      <timestamp>2018-11-26T00:00:50Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>linking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11287">The '''event calculus''' is a [[logic]]al language for representing and reasoning about events and their effects first presented by [[Robert Kowalski]] and [[Marek Sergot]] in 1986.
It was extended by [[Murray Shanahan]] and [[Rob Miller (Computer Scientist)|Rob Miller]] in the 1990s. Similar to other languages for reasoning about change, the event calculus represents the effects of [[Action (artificial intelligence)|action]]s on [[fluent (artificial intelligence)|fluent]]s. However, [[Event (computing)|event]]s can also be external to the system. In the event calculus, one can specify the value of fluents at some given time points, the events that take place at given time points, and  their effects.

==Fluents and events==

In the event calculus, fluents are [[Reification (knowledge representation)|reified]]. This means that they are not formalized by means of [[Predicate (mathematics)|predicate]]s but by means of [[function (mathematics)|function]]s. A separate predicate {{mvar|HoldsAt}} is used to tell which fluents hold at a given time point. For example, &lt;math&gt;\mathit{HoldsAt}(on(box,table),t)&lt;/math&gt; means that the box is on the table at time {{mvar|t}}; in this formula, {{mvar|HoldsAt}} is a predicate while {{mvar|on}} is a function.

Events are also represented as terms. The effects of events are given using the predicates {{mvar|Initiates}} and {{mvar|Terminates}}. In particular, &lt;math&gt;\mathit{Initiates}(e,f,t)&lt;/math&gt; means that,
if the event represented by the term {{mvar|e}} is executed at time {{mvar|t}},
then the fluent {{mvar|f}} will be true after {{mvar|t}}.
The {{mvar|Terminates}} predicate has a similar meaning, with the only difference 
being that {{mvar|f}} will be false and not true after {{mvar|t}}.

==Domain-independent axioms==

Like other languages for representing actions, the event calculus formalizes the correct evolution of the fluent via formulae telling the value of each fluent after an arbitrary action has been performed. The event calculus solves the [[frame problem]] in a way that is similar to the [[successor state axiom]]s of the [[situation calculus]]: a fluent is true at time {{mvar|t}} if and only if it has been made true in the past and has not been made false in the meantime.
 
:&lt;math&gt;\mathit{HoldsAt}(f,t) \leftarrow
[\mathit{Happens}(e,t_1) \wedge \mathit{Initiates}(e,f,t_1) 
\wedge (t_1&lt;t) \wedge \neg \mathit{Clipped}(t_1,f,t)]&lt;/math&gt;

This formula means that the fluent represented by the term {{mvar|f}} is true at time {{mvar|t}} if:

# an event {{mvar|e}} has taken place: &lt;math&gt;\mathit{Happens}(e,t_1)&lt;/math&gt;;
# this took place in the past: &lt;math&gt;\mathit{t}_1&lt;t&lt;/math&gt;;
# this event has the fluent {{mvar|f}} as an effect: &lt;math&gt;\mathit{Initiates}(e,f,t_1)&lt;/math&gt;; 
# the fluent has not been made false in the meantime: &lt;math&gt;\mathit{Clipped}(t_1,f,t)&lt;/math&gt;

A similar formula is used to formalize the opposite case in which a fluent is false at a given time. Other formulae are also needed for correctly formalizing fluents before they have been effects of an event. These formulae are similar to the above, but &lt;math&gt;\mathit{Happens}(e,t_1) \wedge \mathit{Initiates}(e,f,t_1)&lt;/math&gt; is replaced by &lt;math&gt;\mathit{HoldsAt}(f,t_1)&lt;/math&gt;.

The {{mvar|Clipped}} predicate, stating that a fluent has been made false during an interval, can be axiomatized, or simply taken as a shorthand, as follows:

:&lt;math&gt;\mathit{Clipped}(t_1,f,t_2) \equiv
\exists e,t 
[\mathit{Happens}(e,t) \wedge (t_1 \leq t &lt; t_2) \wedge \mathit{Terminates}(e,f,t)]&lt;/math&gt;

==Domain-dependent axioms==

The axioms above relate the value of the predicates {{mvar|HoldsAt}}, {{mvar|Initiates}} and {{mvar|Terminates}}, but do not specify which fluents are known to be true and which events actually make fluents true or false. This is done by using a set of domain-dependent axioms. The known values of fluents are stated as simple literals &lt;math&gt;\mathit{HoldsAt}(f,t)&lt;/math&gt;. The effects of events are stated by formulae relating the effects of events with their preconditions. For example, if the event {{mvar|open}} makes the fluent {{mvar|isopen}} true, but only if {{mvar|haskey}} is currently true, the corresponding formula in the event calculus is:

:&lt;math&gt;\mathit{Initiates}(e,f,t) \equiv
[ e=open \wedge f=isopen \wedge \mathit{HoldsAt}(haskey, t)] \vee \cdots
&lt;/math&gt;

The right-hand expression of this equivalence is composed of a disjunction: for each event and fluent that can be made true by the event, there is a disjunct saying that {{mvar|e}} is actually that event, that {{mvar|f}} is actually that fluent, and that the precondition of the event is met.

The formula above specifies the [[truth value]] of &lt;math&gt;\mathit{Initiates}(e,f,t)&lt;/math&gt; for every possible event and fluent. As a result, all effects of all events have to be combined in a single formulae. This is a problem, because the addition of a new event requires modifying an existing formula rather than adding new ones. This problem can be solved by the application of [[Circumscription (logic)|circumscription]] to a set of formulae each specifying one effect of one event:

: &lt;math&gt;\mathit{Initiates}(open, isopen, t) \leftarrow \mathit{HoldsAt}(haskey, t)&lt;/math&gt;
: &lt;math&gt;\mathit{Initiates}(break, isopen, t) \leftarrow \mathit{HoldsAt}(hashammer, t)&lt;/math&gt;
: &lt;math&gt;\mathit{Initiates}(break, broken, t) \leftarrow \mathit{HoldsAt}(hashammer, t)&lt;/math&gt;

These formulae are simpler than the formula above, because each effect of each event can be specified separately. The single formula telling which events {{mvar|e}} and fluents {{mvar|f}} make &lt;math&gt;\mathit{Initiates}(e,f,t)&lt;/math&gt; true has been replaced by a set of smaller formulae, each one telling the effect of an event on a fluent.
 
However, these formulae are not equivalent to the formula above. Indeed, they only specify sufficient conditions for &lt;math&gt;\mathit{Initiates}(e,f,t)&lt;/math&gt; to be true, which should be completed by the fact that {{mvar|Initiates}} is false in all other cases. This fact can be formalized by simply circumscribing the predicate {{mvar|Initiates}} in the formula above. It is important to note that this circumscription is done only on the formulae specifying {{mvar|Initiates}} and not on the domain-independent axioms. The predicate {{mvar|Terminates}} can be specified in the same way {{mvar|Initiates}} is.

A similar approach can be taken for the {{mvar|Happens}} predicate. The evaluation of this predicate can be enforced by formulae specifying not only when it is true and when it is false:

:&lt;math&gt;\mathit{Happens}(e,t) \equiv
(e=open \wedge t=0) \vee (e=exit \wedge t=1) \vee \cdots&lt;/math&gt;

Circumscription can simplify this specification, as only necessary conditions can be specified:

:&lt;math&gt;\mathit{Happens}(open, 0)&lt;/math&gt;
:&lt;math&gt;\mathit{Happens}(exit, 1)&lt;/math&gt;

Circumscribing the predicate {{mvar|Happens}}, this predicate will be false at all points in which it is not explicitly specified to be true. This circumscription has to be done separately from the circumscription of the other formulae. In other words, if {{mvar|F}} is the set of formulae of the kind &lt;math&gt;\mathit{Initiates}(e,f,t) \leftarrow \cdots&lt;/math&gt;, {{mvar|G}} is the set of formulae &lt;math&gt;\mathit{Happens}(e, t)&lt;/math&gt;, and {{mvar|H}} are the domain independent axioms, the correct formulation of the domain is:

:&lt;math&gt;\mathit{Circ}(F; \mathit{Initiates}, \mathit{Terminates}) \wedge
Circ(G; Happens) \wedge H&lt;/math&gt;

==The event calculus as a logic program==

The event calculus was originally formulated as a set of [[Horn clauses]] augmented with [[negation as failure]] and could be run as a [[Prolog]] program. 
In fact, circumscription is one of the several semantics that can be given to negation as failure, and is closely related to the completion semantics (in which "if" is interpreted as "if and only if" &amp;mdash; see [[logic programming]]).

==Extensions and applications==

The original event calculus paper of Kowalski and Sergot focused on applications to database updates and narratives. Extensions of the event 
calculus can also formalize non-deterministic actions, concurrent actions, actions with delayed effects, gradual changes, actions with duration, continuous change, and non-inertial fluents.

Kave Eshghi showed how the event calculus can be used for planning, using [[Abduction (logic)|abduction]] to generate hypothetical events in [[Abductive Logic Programming|abductive logic programming]]. Van Lambalgen and Hamm showed how the event calculus can also be used to give an algorithmic semantics to tense and aspect in natural language using [[constraint logic programming]].

==Reasoning tools==

In addition to Prolog and its variants, several other tools for reasoning using the event calculus are also available:
* [http://www.doc.ic.ac.uk/~mpsha/planners.html Abductive Event Calculus Planners]
* [http://decreasoner.sourceforge.net/ Discrete Event Calculus Reasoner]
* [http://reasoning.eas.asu.edu/ecasp/ Event Calculus Answer Set Programming]
* [https://www.inf.unibz.it/~montali/tools.html Reactive Event Calculus]

==See also==

* [[First-order logic]]
* [[Frame problem]]
* [[Situation calculus]]

==References==
* Brandano, S. (2001) "[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=20130&amp;arnumber=930691&amp;count=35&amp;index=2 The Event Calculus Assessed,]" ''IEEE TIME Symposium'': 7-12.
* Eshghi, K. (1988) "[https://www.researchgate.net/profile/Kave_Eshghi/publication/220986211_Abductive_Planning_with_Event_Calculus/links/02e7e51bb699ab2b45000000.pdf Abductive Planning with Event Calculus]," ''ICLP/SLP'': 562-79.
* Kowalski, R. (1992) "[http://www.doc.ic.ac.uk/~rak/papers/database%20updates.pdf Database updates in the event calculus]," ''Journal of Logic Programming 12 (162)'': 121-46.
* -------- and M. Sergot (1986) "[http://www.doc.ic.ac.uk/~rak/papers/event%20calculus.pdf A Logic-Based Calculus of Events,]" ''New Generation Computing 4'': 67–95.
* -------- and F. Sadri (1995) "[https://www.researchgate.net/profile/Fariba_Sadri/publication/2519366_Variants_of_the_Event_Calculus/links/5412f8130cf2788c4b358a25.pdf Variants of the Event Calculus]," ''ICLP'': 67-81.
* Miller, R., and M. Shanahan (1999) "[http://www.ida.liu.se/ext/epa/ej/etai/1999/016/epapage.html The event-calculus in classical logic — alternative axiomatizations,]" ''[[Electronic Transactions on Artificial Intelligence]]'' 3(1): 77-105.
* Mueller, Erik T. (2015). ''Commonsense Reasoning: An Event Calculus Based Approach (2nd Ed.)''. Waltham, MA: Morgan Kaufmann/Elsevier. {{ISBN|978-0128014165}}. (Guide to using the event calculus)
* Shanahan, M. (1997) ''[https://books.google.com/books?id=z8zR3Ds7xKQC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Solving the frame problem: A mathematical investigation of the common sense law of inertia]''. MIT Press.
* -------- (1999) "[http://www.springerlink.com/content/1bxk8gd0n6pajxbq/?p=8f3428a89bad4589a949d74b6f0ec98d&amp;pi=0 The Event Calculus Explained,]" Springer Verlag, LNAI (1600): 409-30.
* Van Lambalgen, M., and F. Hamm (2005) ''The proper treatment of events''. Oxford and Boston: Blackwell Publishing.

[[Category:1986 introductions]]
[[Category:Logic in computer science]]
[[Category:Logic programming]]
[[Category:Knowledge representation]]
[[Category:Logical calculi]]</text>
      <sha1>1rk1e85f5aphtzrmyrb1s99fd7ws13e</sha1>
    </revision>
  </page>
  <page>
    <title>Formal ball</title>
    <ns>0</ns>
    <id>43092207</id>
    <revision>
      <id>805808957</id>
      <parentid>805449199</parentid>
      <timestamp>2017-10-17T19:36:00Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* References */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1694">{{About|the topological model|the formal dance|Ball (dance)}}
In [[topology]], a '''formal ball''' is an extension of the notion of [[Ball (mathematics)|ball]] to allow unbounded and negative radius.  The concept of formal ball was introduced by Weihrauch and Schreiber in 1981 and the negative radius case (the '''generalized formal ball''') by Tsuiki and Hattori in 2008.

Specifically, if &lt;math&gt;(X,d)&lt;/math&gt; is a [[metric space]] and &lt;math&gt;\mathbb{R}^{+}&lt;/math&gt; the nonnegative real numbers, then an element of &lt;math&gt;B^+(X,d)=X\times\mathbb{R}^{+}&lt;/math&gt; is a formal ball.  Elements of &lt;math&gt;B(X,d)=X\times\mathbb{R}&lt;/math&gt; are known as generalized formal balls.

Formal balls possess a partial order &lt;math&gt;\leq&lt;/math&gt; defined by &lt;math&gt;(x,r)\leq(y,s)&lt;/math&gt; if &lt;math&gt;d(x,y)\leq r-s&lt;/math&gt;, identical to that defined by set inclusion.

Generalized formal balls are interesting because this partial order works just as well for &lt;math&gt;B(X,d)&lt;/math&gt; as for &lt;math&gt;B^+(X,d)&lt;/math&gt;, even though a generalized formal ball with negative radius does not correspond to a subset of &lt;math&gt;X&lt;/math&gt;.

Formal balls possess the [[Lawson topology]] and the [[Martin topology]].

==References==

*K. Weihrauch and U. Schreiber 1981.  "Embedding metric spaces into CPOs".  ''Theoretical computer science'', 16:5-24.

*H. Tsuiki and Y. Hattori 2008.  "Lawson topology of the space of formal balls and the hyperbolic topology of a metric space".  ''Theoretical computer science'', 405:198-205

*Y. Hattori 2010.  "Order and topological structures of posets of the formal balls on metric spaces".  ''Memoirs of the Faculty of Science and Engineering. Shimane University. Series B'' 43:13-26

[[Category:Topology]]</text>
      <sha1>jv1ke2duut9ivpahbjikanq8kwzqj1f</sha1>
    </revision>
  </page>
  <page>
    <title>Gian-Carlo Rota</title>
    <ns>0</ns>
    <id>101891</id>
    <revision>
      <id>857359630</id>
      <parentid>847287965</parentid>
      <timestamp>2018-08-31T05:22:44Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Copying from [[Category:20th-century Italian mathematicians]] to [[Category:Italian mathematicians]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10479">&lt;!--  Commented out because image was deleted: [[Image:GCRota.jpg|350px|thumb|right|Gian-Carlo Rota]] --&gt;
{{Infobox scientist
|name              = Gian-Carlo Rota
|image             = Gian-Carlo_Rota_blackboard_Nizza_1970.jpg
|image_size       = 279px
|caption           = Rota in 1970.
|birth_date        = {{BirthDeathAge|B|1932|4|27|1999|4|18|}}
|birth_place       = [[Vigevano]], Italy
|death_date        = {{BirthDeathAge||1932|4|27|1999|4|18|}}
|death_place       = [[Cambridge, Massachusetts|Cambridge]], [[Massachusetts]], USA
|residence         = Italy, Ecuador, USA
|citizenship       = &lt;!-- don't know --&gt;
|nationality       = &lt;!-- don't know --&gt;
|ethnicity         = &lt;!-- don't know, what does it mean anyway??? --&gt;
|fields            = [[Mathematics]], [[Philosophy]]
|workplaces        = [[Massachusetts Institute of Technology]]&lt;br&gt;[[Los Alamos National Laboratory]]&lt;br&gt;[[The Rockefeller University]]
|alma_mater        = [[Princeton University]]&lt;br&gt;[[Yale University]]
|doctoral_advisor  = [[Jack Schwartz|Jacob T. Schwartz]]
|academic_advisors = &lt;!-- don't know --&gt;
|doctoral_students = &lt;!-- need to go through the list (Maths. Genealogy Project) and see who is notable --&gt;
|notable_students  = {{Plainlist|
*[[William Y.C. Chen]]
*[[Daniel I. A. Cohen]]
*[[Peter Duren]]
*[[Richard Ehrenborg]]
*[[Mark Haiman]]
*[[Patrick O'Neil]]
*[[Richard P. Stanley]]
*[[Walter Whiteley]]
*[[Catherine Yan]]
}}
|known_for         = &lt;!-- hard to tell, please help! --&gt;
|author_abbrev_bot = &lt;!--Not needed in this case. But keep as template placeholder.--&gt;
|author_abbrev_zoo = &lt;!--Not needed in this case. But keep as template placeholder.--&gt;
|influences        = &lt;!-- don't know --&gt;
|influenced        = &lt;!-- don't know --&gt;
|awards            = [[Leroy P. Steele Prize]] &lt;small&gt;(1988)&lt;/small&gt;
|religion          = &lt;!-- don't know --&gt;
|signature         = &lt;!-- none available --&gt;
|footnotes         = &lt;!--For any footnotes needed to clarify entries above--&gt;
|family            = [[Nina Rota]] (uncle)
}}
'''Gian-Carlo Rota''' (April 27, 1932 &amp;ndash; April 18, 1999) was an Italian-born American [[mathematician]] and [[philosopher]].

==Early life and education==
Rota was born in [[Vigevano]], Italy. His father, Giovanni, a prominent [[antifascist]], was the brother of the mathematician Rosetta, who was the wife of the writer [[Ennio Flaiano]].&lt;ref name="MacTutor"&gt;{{MacTutor Biography|id=Rota}}&lt;/ref&gt;&lt;ref name="palombi"&gt;{{cite book | title = The Star and the Whole: Gian-Carlo Rota on Mathematics and Phenomenology | last1 = Palombi  |first1 = Fabrizio | pages = 6–7 | publisher = [[CRC Press]] | year = 2011 | quote = His aunt, Rosetta Rota (1911–2003), was a mathematician associated with the renowned Rome university Institute of Physics in Via Panispenra… }}&lt;/ref&gt;  Gian-Carlo's family left Italy when he was 13 years old, initially going to Switzerland.

Rota attended the [[Colegio Americano de Quito]] in Ecuador, and earned degrees at [[Princeton University]] and [[Yale University]].

==Career==
Much of Rota's career was spent as a professor at the [[Massachusetts Institute of Technology]] (MIT), where he was and remains the only person ever to be appointed Professor of Applied Mathematics and Philosophy. Rota was also the [[Norbert Wiener]] Professor of Applied Mathematics.

In addition to his professorships at MIT, Rota held four honorary degrees, from the University of Strasbourg, France (1984); the [[University of L'Aquila]], Italy (1990); the [[University of Bologna]], Italy (1996); and [[Brooklyn Polytechnic|Brooklyn Polytechnic University]] (1997).
Beginning in 1966 he was a consultant at [[Los Alamos National Laboratory]], frequently visiting to lecture, discuss, and collaborate, notably with his friend [[Stanislaw Ulam]]. He was also a consultant for the [[Rand Corporation]] (1966–71) and for the [[Brookhaven National Laboratory]] (1969&amp;ndash;1973). Rota was elected to the [[National Academy of Sciences]] in 1982, was vice president of the [[American Mathematical Society]] (AMS) from 1995–97, and was a member of numerous other mathematical and philosophical organizations.&lt;ref name="web.mit.edu"&gt;{{cite news | title = MIT professor Gian-Carlo Rota, mathematician and philosopher, is dead at 66  | date = April 22, 1999 | url = http://web.mit.edu/newsoffice/1999/rota.html }}&lt;/ref&gt;

He taught a difficult but very popular course in [[probability]]. He also taught Applications of Calculus, [[differential equations]], and [[Combinatorics|Combinatorial Theory]]. His philosophy course in [[phenomenology (philosophy)|phenomenology]] was offered on Friday nights to keep the enrollment manageable. Among his many eccentricities, he would not teach without a can of [[Coca-Cola]], and handed out prizes ranging from [[Hershey bar]]s to [[pocket knives]] to students who asked questions in class or did well on tests.&lt;ref&gt;{{cite news | author = Wesley T. Chan | title = To Teach or Not To Teach: Professors Might Try a New Approach to Classes – Caring about Teaching | work = [[The Tech (newspaper)|The Tech]] | volume = 117 | issue = 63 | date = December 5, 1997 | url = http://tech.mit.edu/V117/N63/chan.63c.html | accessdate = 2008-02-10}}&lt;/ref&gt;&lt;ref&gt;{{cite news | title = Gian-Carlo Rota | work = [[The Tech (newspaper)|The Tech]] | volume = 119 | issue = 21 | date = April 23, 1999 | url = http://tech.mit.edu/V119/N21/21rota.21n.html | accessdate = 2008-02-10}}&lt;/ref&gt;

Rota began his career as a [[functional analysis|functional analyst]], but switched to become a distinguished [[combinatorics|combinatorialist]]. His series of ten papers on the "Foundations of Combinatorics" in the 1960s is credited with making it a respectable branch of modern mathematics. He said that the one combinatorial idea he would like to be remembered for is the correspondence between combinatorial problems and problems of the location of the zeroes of [[polynomial]]s.&lt;ref&gt;{{cite web |url=http://www.rota.org/hotair/rotasharp.html |title=Mathematics, Philosophy, and Artificial Intelligence: a dialogue with Gian-Carlo Rota and David Sharp |accessdate=2007-08-11 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20070811172343/http://www.rota.org/hotair/rotasharp.html |archivedate=August 11, 2007 |df= }}&lt;/ref&gt; He worked on the theory of [[incidence algebra]]s (which generalize the 19th-century theory of [[Möbius inversion formula|Möbius inversion]]) and popularized their study among combinatorialists, set the [[umbral calculus]] on a rigorous foundation, unified the theory of [[Sheffer sequence]]s and [[polynomial sequence]]s of [[binomial type]], and worked on fundamental problems in [[probability theory]]. His philosophical work was largely in the [[Phenomenology (philosophy)|phenomenology]] of [[Edmund Husserl]].

==Death==
Rota died of atherosclerotic cardiac disease, apparently in his sleep at his home in Cambridge, Massachusetts. He died just a few days short of his 67th birthday. His death was discovered after he failed to arrive in Philadelphia for lectures he had planned to present beginning on Monday 19&amp;nbsp;April 1999.&lt;ref name="web.mit.edu"/&gt;

A reading room in [[MIT Mathematics Department|MIT's Department of Mathematics]] is dedicated to Rota.

==See also==
* [[Kallman–Rota inequality]]
* [[Rota's conjecture]]
* [[Rota's basis conjecture]]
* [[Rota–Baxter algebra]]
* [[List of American philosophers]]
* [[Joint spectral radius]], introduced by Rota in the early 1960s

==Notes==
{{Reflist}}

==External links==
*{{MathGenealogy |id=7721}}
*{{MacTutor Biography|id=Rota}}
*{{cite book
  |last1 = Kung
  |first1 = Joseph
  |last2 = Rota
  |first2 = Gian-Carlo
  |last3 = Yan
  |first3 = Catherine
  |title = Combinatorics: The Rota Way
  |url = http://www.math.tamu.edu/~cyan/book.html
  |publisher = [[Cambridge University Press]]
  |series = Cambridge Mathematical Library
  |year = 2009
  |isbn = 0-521-73794-X }}
*{{webarchive |url=https://web.archive.org/web/20070630211718/http://www.rota.org/ |date=June 30, 2007 |title=The Forbidden City of Gian-Carlo Rota (a memorial site) }} This page at www.rota.org was not originally intended to be a memorial web site, but was created by Rota himself with the assistance of his friend Bill Chen in January 1999 while Rota was visiting Los Alamos National Laboratory.
*{{webarchive |url=https://web.archive.org/web/20070811172343/http://www.rota.org/hotair/rotasharp.html |date=August 11, 2007 |title=Mathematics, Philosophy, and Artificial Intelligence: a dialogue with Gian-Carlo Rota and David Sharp }}
*[https://web.archive.org/web/20150310024937/http://www.princeton.edu/~mudd/finding_aids/mathoral/pmcxrota.htm "Fine Hall in its golden age: Remembrances of Princeton in the early fifties" by Gian-Carlo Rota.]
*[http://www.math.tamu.edu/~cyan/Rota.html Tribute page by Prof. Catherine Yan (Texas A&amp;M University), a former student of Rota]
*[http://www.ellerman.org/Davids-Stuff/Maths/Rota-Baclawski-Prob-Theory-79.pdf Scanned copy of Gian-Carlo Rota's and Kenneth Baclawski's Introduction to Probability and Random Processes manuscript in its 1979 version.]
* {{Cite book |author=Gian-Carlo Rota |title=Indiscrete Thoughts |year=1996 |isbn=0-8176-3866-0 |publisher=Birkhäuser Boston |postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}, {{isbn|0-8176-3866-0}}; review at [http://mathdl.maa.org/mathDL/19/?pa=reviews&amp;sa=viewBook&amp;bookId=65811 MAA.org]
*[http://ra.crema.unimi.it/Rota2009 The Digital Footprint of Gian-Carlo Rota]: International Conference in memory of Gian-Carlo Rota, organized by Ottavio D'Antona, Vincenzo Marra and [[Ernesto Damiani]] at the [[University of Milan]] (Italy)
* [https://www.springer.com/us/book/9780817642754 Gian-Carlo Rota on Analysis and Probability], {{ISBN|978-0-8176-4275-4}}.

{{Authority control}}

{{DEFAULTSORT:Rota, Gian-Carlo}}
[[Category:1932 births]]
[[Category:1999 deaths]]
[[Category:People from Vigevano]]
[[Category:20th-century Italian mathematicians]]
[[Category:Italian mathematicians]]
[[Category:20th-century Italian philosophers]]
[[Category:20th-century American mathematicians]]
[[Category:American philosophers]]
[[Category:Combinatorialists]]
[[Category:American people of Italian descent]]
[[Category:Princeton University alumni]]
[[Category:Yale University alumni]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:Phenomenologists]]</text>
      <sha1>c70a6pw55ly2ozdbo8anw4pdrst678j</sha1>
    </revision>
  </page>
  <page>
    <title>Hairy ball theorem</title>
    <ns>0</ns>
    <id>485168</id>
    <revision>
      <id>855918461</id>
      <parentid>855906617</parentid>
      <timestamp>2018-08-21T18:12:15Z</timestamp>
      <contributor>
        <username>Tayste</username>
        <id>6531599</id>
      </contributor>
      <comment>No we don't need this hatnote here; cowlick is not a whorl</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10093">{{more footnotes|date=October 2008}}

[[File:Hairy ball.png|thumb|A failed attempt to comb a hairy 3-ball (2-sphere), leaving a tuft at each pole]]
[[File:Hairy doughnut.png|thumb|A hairy doughnut (2-torus), on the other hand, is quite easily combable.]]
[[File:Hairy ball one pole.jpg|thumb|A continuous tangent vector field on a 2-sphere with only one pole, in this case a [[dipole]] field with index 2. See also an [[:File:Hairy ball one pole animated.gif|animated version of this graphic]].]]
[[File:Baby hairy head DSCN2483.jpg|thumb|A hair whorl]]

The '''hairy ball theorem''' of [[algebraic topology]] (sometimes called the '''hedgehog theorem''' in Europe)&lt;ref name="Renteln"&gt;{{cite book
 | last1  = Renteln
 | first1 = Paul 
 | title  = Manifolds, Tensors, and Forms: An Introduction for Mathematicians and Physicists
 | publisher = Cambridge Univ. Press
 | date   = 2013
 | location = 
 | page  = 253
 | language = 
 | url    = https://books.google.com/books?id=uJWGAgAAQBAJ&amp;pg=PA253&amp;dq=hairy+ball+theorem
 | doi    = 
 | id     = 
 | isbn   = 1107659698
 }}&lt;/ref&gt; states that there is no nonvanishing [[continuous function|continuous]] tangent [[vector field]] on even-dimensional [[n‑sphere|''n''-spheres]].&lt;ref name="Burns"&gt;{{cite book
 | last1  = Burns
 | first1 = Keith
 | last2  = Gidea
 | first2 = Marian
 | title  = Differential Geometry and Topology: With a View to Dynamical Systems
 | publisher = CRC Press
 | date   = 2005
 | location = 
 | pages  = 77
 | language = 
 | url    = https://books.google.com/books?id=tV9sTDnaf40C&amp;pg=PA77&amp;dq=hairy+ball+theorem
 | doi    = 
 | id     = 
 | isbn   = 1584882530
 }}&lt;/ref&gt;&lt;ref name="Schwartz"&gt;{{cite book
 | last1  = Schwartz
 | first1 = Richard Evan 
 | title  = Mostly Surfaces
 | publisher = American Mathematical Society
 | date   = 2011
 | location = 
 | pages  = 113–114
 | language = 
 | url    = https://books.google.com/books?id=sS2IAwAAQBAJ&amp;pg=PA113&amp;dq=hairy+ball+theorem
 | doi    = 
 | id     = 
 | isbn   = 0821853686
 }}&lt;/ref&gt; For the ordinary sphere, or 2‑sphere, if ''f'' is a continuous function that assigns a [[Vector (geometric)|vector]] in '''R'''&lt;sup&gt;3&lt;/sup&gt; to every point ''p'' on a sphere such that ''f''(''p'') is always [[tangent]] to the sphere at ''p'', then there is at least one ''p'' such that ''f''(''p'') = '''[[Null vector|0]]'''. In other words, whenever one attempts to comb a hairy ball flat, there will always be at least one tuft of hair at one point on the ball. The theorem was first stated by [[Henri Poincaré]] in the late 19th century.{{citation needed|date=March 2015}}

This is famously stated as "you can't comb a hairy ball flat without creating a [[cowlick]]", "you can't comb the hair on a coconut", or sometimes "every cow must have at least one cowlick." It can also be written as, "Every [[vector field#Vector fields on manifolds|smooth vector field]] on a sphere has a singular point." It was first proven in 1912 by [[Luitzen Egbertus Jan Brouwer|Brouwer]].&lt;ref&gt;[http://dz-srv1.sub.uni-goettingen.de/sub/digbib/loader?ht=VIEW&amp;did=D28661 Georg-August-Universität Göttingen] {{webarchive|url=https://web.archive.org/web/20060526145611/http://dz-srv1.sub.uni-goettingen.de/sub/digbib/loader?ht=VIEW&amp;did=D28661 |date=2006-05-26 }}&lt;/ref&gt;

==Counting zeros==
From a more advanced point of view: every zero of a vector field has a (non-zero) "[[Vector field#Index of a vector field|index]]", and it can be shown that the sum of all of the indices at all of the zeros must be two. (This is because the [[Euler characteristic]] of the 2-sphere is two.) Therefore, there must be at least one zero. This is a consequence of the [[Poincaré–Hopf theorem]]. In the case of the [[torus]], the Euler characteristic is 0; and it ''is'' possible to "comb a hairy doughnut flat". In this regard, it follows that for any [[compact space|compact]] [[Irregularity of a surface|regular]] 2-dimensional [[manifold]] with non-zero Euler characteristic, any continuous tangent vector field has at least one zero.

==Cyclone consequences==
{{unreferenced section|date=July 2017}}
A curious meteorological application of this theorem involves considering the wind as a vector defined at every point continuously over the surface of a planet with an atmosphere. As an idealisation, take wind to be a two-dimensional vector: suppose that relative to the planetary diameter of the Earth, its vertical (i.e., non-tangential) motion is negligible.

One scenario, in which there is absolutely no wind (air movement), corresponds to a field of zero-vectors. This scenario is uninteresting from the point of view of this theorem, and physically unrealistic (there will always be wind). In the case where there is at least some wind, the Hairy Ball Theorem dictates that at all times there must be at least one point on a planet with no wind at all and therefore a tuft. This corresponds to the above statement that there will always be ''p'' such that ''f''(''p'') = '''0'''.

In a physical sense, this zero-wind point will be the center of a cyclone or anticyclone. (Like the swirled hairs on the tennis ball, the wind will spiral around this zero-wind point - under our assumptions it cannot flow into or out of the point.) In brief, then, the theorem dictates that, given at least some wind on Earth, there must at all times be a [[cyclone]] or anticyclone somewhere.

Note that the center with zero wind can be arbitrarily large or small. Mathematical consistency dictates the wind forms a cyclonic wind pattern for at least one point on the planet, but this does not require the cyclone be a violent storm.

This is not strictly true as the air above the earth has multiple layers, but for each layer there must be a point with zero horizontal windspeed.

==Application to computer graphics==
A common problem in computer graphics is to generate a non-zero vector in '''R'''&lt;sup&gt;3&lt;/sup&gt; that is orthogonal to a given non-zero one. There is no single ''continuous'' function that can do this for all non-zero vector inputs. This is a corollary of the hairy ball theorem. To see this, consider the given vector as the radius of a sphere and note that finding a non-zero vector orthogonal to the given one is equivalent to finding a non-zero vector that is tangent to the surface of that sphere where it touches the radius. However, the hairy ball theorem says there exists no ''continuous'' function that can do this for every point on the sphere (i.e. every given vector).

==Lefschetz connection==
There is a closely related argument from [[algebraic topology]], using the [[Lefschetz fixed-point theorem]]. Since the [[Betti number]]s of a 2-sphere are 1, 0, 1, 0, 0, ... the ''[[Lefschetz number]]'' (total trace on [[homology (mathematics)|homology]]) of the [[identity mapping]] is 2. By integrating a [[vector field]] we get (at least a small part of) a [[one-parameter group]] of [[diffeomorphism]]s on the sphere; and all of the mappings in it are [[homotopic]] to the identity. Therefore, they all have Lefschetz number 2, also. Hence they have fixed points (since the Lefschetz number is nonzero). Some more work would be needed to show that this implies there must actually be a zero of the vector field. It does suggest the correct statement of the more general [[Poincaré-Hopf index theorem]].

==Corollary==
A consequence of the hairy ball theorem is that any continuous [[Functions (mathematics)|function]] that maps an even-dimensional sphere [[Endomorphism|into itself]] has either a [[fixed point (mathematics)|fixed point]] or a point that maps onto its own [[antipodal point]].  This can be seen by transforming the function into a tangential vector field as follows.

Let ''s'' be the function mapping the sphere to itself, and let ''v'' be the tangential vector function to be constructed.  For each point ''p'', construct the [[stereographic projection]] of ''s''(''p'') with ''p'' as the point of tangency.  Then ''v''(''p'') is the displacement vector of this projected point relative to ''p''.  According to the hairy ball theorem, there is a ''p'' such that ''v''(''p'') = '''0''', so that ''s''(''p'') = ''p''.

This argument breaks down only if there exists a point ''p'' for which ''s''(''p'') is the antipodal point of ''p'', since such a point is the only one that cannot be stereographically projected onto the tangent plane of ''p''.

==Higher dimensions==
The connection with the [[Euler characteristic]] χ suggests the correct generalisation: the [[N-sphere|2''n''-sphere]] has no non-vanishing vector field for {{nowrap|''n'' ≥ 1}}. The difference between even and odd dimensions is that, because the only nonzero [[Betti number]]s of the ''m''-sphere are b&lt;sub&gt;0&lt;/sub&gt; and b&lt;sub&gt;m&lt;/sub&gt;, their [[alternating sum]] χ is 2 for ''m'' even, and 0 for ''m'' odd.

==See also==
{{Div col}}
*[[Fixed-point theorem]]
*[[Intermediate value theorem]]
*[[Vector fields on spheres]]
{{Div col end}}

==Notes==
{{reflist}}

==References==
* {{Citation |first1=Murray |last1=Eisenberg |first2=Robert |last2=Guy |title=A Proof of the Hairy Ball Theorem |journal=The American Mathematical Monthly |volume=86 |issue=7 |year=1979 |pages=571–574 |doi=10.2307/2320587}}

==Further reading==
* {{Citation|title=The Hairy Ball Theorem via Sperner's Lemma|last1=Jarvis|first1=Tyler|last2=Tanton|first2=James|date=2003-07-23|format=PDF|url=https://math.byu.edu/~jarvis/sperner.pdf}}
* {{Citation|last=Reich|first=Henry|year=2011|title=One-Minute Math: Why you can't comb a hairy ball|publisher=New ScientistTV|url=https://www.newscientist.com/blogs/nstv/2011/12/one-minute-math-why-you-cant-comb-a-hairy-ball.html}}
* {{Citation|last=Richeson|first=David S.|title=Euler's Gem: The Polyhedron Formula and the Birth of Topology|publisher=Princeton University Press|year=2008|pages=|isbn=0-691-12677-1}}. See Chapter 19, "Combing the Hair on a Coconut", pp.&amp;nbsp;202–218.

==External links==
*{{MathWorld|title=Hairy Ball Theorem|id=HairyBallTheorem}}

[[Category:Differential topology]]
[[Category:Fixed points (mathematics)]]
[[Category:Theorems in algebraic topology]]</text>
      <sha1>7trg7d53w5gi5xf2okgpa0jkikv3fbc</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert's twenty-third problem</title>
    <ns>0</ns>
    <id>2336108</id>
    <revision>
      <id>846633521</id>
      <parentid>808459056</parentid>
      <timestamp>2018-06-19T23:56:53Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4949">'''Hilbert's twenty-third problem''' is the last of [[Hilbert problems]] set out in a celebrated list compiled in 1900 by [[David Hilbert]].  In contrast with Hilbert's other 22 problems, his 23rd is not so much a specific "problem" as an encouragement towards further development of the [[calculus of variations]]. His statement of the problem is a summary of the state-of-the-art (in 1900) of the theory of calculus of variations, with some introductory comments decrying the lack of work that had been done of the theory in the mid to late 19th century.

==Original statement==
The problem statement begins with the following paragraph:
&lt;blockquote&gt;
So far, I have generally mentioned problems as definite and special as possible.... Nevertheless, I should like to close with a general problem, namely with the indication of a branch of mathematics repeatedly mentioned in this lecture-which, in spite of the considerable advancement lately given it by Weierstrass, does not receive the general appreciation which, in my opinion, it is due-I mean the calculus of variations.&lt;ref&gt;Hilbert, David, "Mathematische Probleme" [[Göttinger Nachrichten]], (1900), pp. 253-297, and in [[Archiv der Mathematik und Physik]], (3) '''1''' (1901), 44-63 and 213-237. Published in English translation by Dr. Maby Winton Newson, [[Bulletin of the American Mathematical Society]] '''8''' (1902), 437-479 [http://aleph0.clarku.edu/~djoyce/hilbert/problems.html#prob23] [http://www.ams.org/journals/bull/1902-08-10/S0002-9904-1902-00923-3/S0002-9904-1902-00923-3.pdf] {{doi|10.1090/S0002-9904-1902-00923-3}} . [A fuller title of the journal Göttinger Nachrichten is Nachrichten von der Königl. Gesellschaft der Wiss. zu Göttingen.]&lt;/ref&gt;
&lt;/blockquote&gt;

==Calculus of variations==
{{main article|Calculus of variations}}
Calculus of variations is a field of [[mathematical analysis]] that deals with maximizing or minimizing [[functional (mathematics)|functionals]], which are [[Map (mathematics)|mapping]]s from a set of [[Function (mathematics)|function]]s to the [[real number]]s. Functionals are often expressed as [[definite integral]]s involving  functions and their [[derivative]]s. The interest is in ''extremal'' functions that make the functional attain a maximum or minimum value &amp;ndash; or ''stationary'' functions &amp;ndash; those where the rate of change of the functional is zero.

==Progress==
Following the problem statement, [[David Hilbert]], [[Emmy Noether]], [[Leonida Tonelli]], [[Henri Lebesgue]] and [[Jacques Hadamard]] among others made significant contributions to the calculus of variations.&lt;ref name="brunt"&gt;{{cite book |last = van Brunt |first = Bruce |title = The Calculus of Variations |publisher = Springer |year = 2004  |isbn = 0-387-40247-0}}&lt;/ref&gt; [[Marston Morse]] applied calculus of variations in what is now called [[Morse theory]].&lt;ref name="ferguson"&gt;{{cite arXiv |last=Ferguson |first=James |authorlink=|eprint= math/0402357 |title=  Brief Survey of the History of the Calculus of Variations and its Applications |year=2004 }}&lt;/ref&gt; [[Lev Pontryagin]], [[R. Tyrrell Rockafellar|Ralph Rockafellar]] and F. H. Clarke developed new mathematical tools for the calculus of variations in [[optimal control theory]].&lt;ref name="ferguson" /&gt; The [[dynamic programming]] of [[Richard Bellman]] is an alternative to  the calculus of variations.&lt;ref&gt;Dimitri P Bertsekas. Dynamic programming and optimal control. Athena Scientific, 2005.&lt;/ref&gt;&lt;ref name="bellman"&gt;{{cite journal |last=Bellman |first=Richard E. |title= Dynamic Programming and a new formalism in the calculus of variations |year=1954 |journal= Proc. Natl. Acad. Sci. | issue=4 | pages=231–235|url=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC527981/pdf/pnas00731-0009.pdf |pmc=527981 |pmid=16589462 |volume=40 |doi=10.1073/pnas.40.4.231|bibcode=1954PNAS...40..231B }}&lt;/ref&gt;&lt;ref name='Kushner2004'&gt;{{cite news | first = Harold J. | last = Kushner | title = Richard E. Bellman Control Heritage Award  | year = 2004 | url = http://a2c2.org/awards/richard-e-bellman-control-heritage-award | work = American Automatic Control Council | accessdate = 2013-07-28 }} See '''2004: Harold J. Kushner''': regarding Dynamic Programming,  "The calculus of variations had related ideas (e.g., the work of Caratheodory, the Hamilton-Jacobi equation). This led to conflicts with the calculus of variations community."&lt;/ref&gt;

==References==
{{reflist}}

==Further reading==
* {{cite book | editor=Felix E. Browder | editor-link=Felix Browder | title=Mathematical Developments Arising from Hilbert Problems | series=[[Proceedings of Symposia in Pure Mathematics]] | volume=XXVIII.2 | year=1976 | publisher=[[American Mathematical Society]] | isbn=0-8218-1428-1 | pages=611–628 | first=Guido | last=Stampacchia | authorlink=Guido Stampacchia | chapter=Hilbert's Twenty-Third Problem: Extension of the Calculus of Variations }}

{{Hilbert's problems}}

[[Category:Hilbert's problems|#23]]</text>
      <sha1>ehoy9fqij8uwdlmugh1u8qfdqbzl5lm</sha1>
    </revision>
  </page>
  <page>
    <title>Howard Jerome Keisler</title>
    <ns>0</ns>
    <id>10962250</id>
    <revision>
      <id>836039435</id>
      <parentid>786562204</parentid>
      <timestamp>2018-04-12T09:31:09Z</timestamp>
      <contributor>
        <username>Myles buckley</username>
        <id>29261766</id>
      </contributor>
      <minor/>
      <comment>I added a photo of him when he was younger</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5218">{{Infobox scientist
| name = Howard Keisler
| image = H Jerome Keisler.jpg
| image_size = 
| alt = 
| birth_date = {{Birth date and age|1936|12|3}}
| birth_place = [[Seattle]], United States
| death_date = 
| death_place = 
| fields = [[Mathematics]]
| workplaces = [[University of Wisconsin-Madison]]
| alma_mater = 
| doctoral_advisor = [[Alfred Tarski]]
| doctoral_students = [[Frederick Rowbottom]]
| known_for = [[Non-standard analysis]]
| influences = 
| influenced = 
| awards = 
| signature = &lt;!--(filename only)--&gt;
| signature_alt = 
| footnotes = 
}}

'''Howard Jerome Keisler''' (born 3 December 1936) is an American [[mathematician]], currently professor emeritus at [[University of Wisconsin–Madison]]. His research has included [[model theory]] and [[non-standard analysis]].

His Ph.D. advisor was [[Alfred Tarski]] at [[University of California, Berkeley|Berkeley]]; his dissertation is ''Ultraproducts and Elementary Classes'' (1961).

Following [[Abraham Robinson]]'s work resolving what had long been thought to be inherent logical contradictions in the literal interpretation of [[Leibniz's notation]] that Leibniz himself had proposed, that is, interpreting "dx" as literally representing an [[infinitesimal]]ly small quantity, Keisler published ''[[Elementary Calculus: An Infinitesimal Approach]]'', a first-year calculus textbook conceptually centered on the use of infinitesimals, rather than the [[epsilon, delta approach]], for developing the calculus.

He is also known for extending the [[Henkin construction]] (of [[Leon Henkin]]) to what are now called [[Henkin–Keisler model]]s.&lt;ref&gt;{{springer|id=h/h110150|title=Henkin construction|author=G. Weaver}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=George Weaver|title=Henkin-Keisler models|year=1997|publisher=Springer|isbn=978-0-7923-4366-0}}&lt;/ref&gt;

He held the named chair of [[Vilas Professor of Mathematics]] at Wisconsin.

Among Keisler's graduate students, several have made notable mathematical contributions, including [[Frederick Rowbottom]] who discovered [[Rowbottom cardinal]]s.  Several others have gone on to careers in computer science research and product development, including: Michael Benedikt, a professor of computer science at the [[University of Oxford]], [[Kevin J. Compton]], a professor of computer science at the [[University of Michigan]], Curtis Tuckey, a developer of software-based collaboration environments; [[Joseph Sgro]], a neurologist and developer of [[vision processor]] hardware and software, and [[Edward L. Wimmers]], a database researcher at [[IBM Almaden Research Center]].

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-01-27.&lt;/ref&gt;

His son Jeffrey Keisler is a [[Fulbright]] Distinguished Chair.&lt;ref&gt;https://www.umb.edu/news/detail/keisler_first_umass_boston_prof_to_be_named_distinguished_fulbright_chair&lt;/ref&gt;

==Publications==
*[[Chen Chung Chang|Chang, C. C.]]; Keisler, H. J. [https://books.google.com/books/about/Continuous_Model_Theory.html?id=uTGdPSI5rI4C ''Continuous Model Theory'']. Annals of Mathematical Studies, 58, Princeton University Press, 1966. xii+165 pp.
*''Model Theory for Infinitary Logic'', North-Holland, 1971
*Chang, C. C.; Keisler, H. J. [https://books.google.com/books/about/Model_Theory.html?id=uiHq0EmaFp0C ''Model theory''. Third edition]. Studies in Logic and the Foundations of Mathematics, 73. North-Holland Publishing Co., Amsterdam, 1990. xvi+650 pp. {{ISBN|0-444-88054-2}}; 1st edition 1973;&lt;ref&gt;{{cite journal|author=Makkai, M.|authorlink=Michael Makkai|title=Review: ''Model theory'' by C. C. Chang and H. J. Keisler|journal=Bull. Amer. Math. Soc.|year=1976|volume=82|issue=3|pages=433–446|url=http://www.ams.org/journals/bull/1976-82-03/S0002-9904-1976-14035-9/S0002-9904-1976-14035-9.pdf|doi=10.1090/s0002-9904-1976-14035-9}}&lt;/ref&gt; 2nd edition 1977
*''Elementary Calculus: An Infinitesimal Approach.'' Prindle, Weber &amp; Schmidt, 1976/1986. Available online at [http://www.math.wisc.edu/~keisler/calc.html].
*''An Infinitesimal Approach to Stochastic Analysis'', American Mathematical Society Memoirs, 1984 
*Keisler, H. J.; Robbin, Joel. ''Mathematical Logic and Computability'', McGraw-Hill, 1996 
*[[Sergio Fajardo|Fajardo, Sergio]]; Keisler, H. J. ''Model Theory of Stochastic Processes'', Lecture Notes in Logic, Association for Symbolic Logic. 2002

==See also==
* [[Criticism of non-standard analysis]]
* [[Non-standard calculus]]
* ''[[Elementary Calculus: An Infinitesimal Approach]]''
* [[Influence of non-standard analysis]]

==References==
{{reflist}}

==External links==
*{{MathGenealogy|id=8426}}
*[http://www.math.wisc.edu/~keisler/ Keisler's home page]

{{authority control}}

{{DEFAULTSORT:Keisler, Howard Jerome}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Living people]]
[[Category:Model theorists]]
[[Category:University of Wisconsin&amp;ndash;Madison faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:1936 births]]
[[Category:Guggenheim Fellows]]
[[Category:Tarski lecturers]]


{{US-mathematician-stub}}</text>
      <sha1>eh1flzz9evdnl0hpts5joqpmkbk40vk</sha1>
    </revision>
  </page>
  <page>
    <title>Instantaneous phase</title>
    <ns>0</ns>
    <id>3125808</id>
    <revision>
      <id>852620699</id>
      <parentid>810489704</parentid>
      <timestamp>2018-07-30T07:17:28Z</timestamp>
      <contributor>
        <username>Jabberjaw</username>
        <id>9895903</id>
      </contributor>
      <comment>clean up; edit ref; references;  using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7698">{{inadequate lead|date=July 2013}}

'''Instantaneous phase''' and '''instantaneous frequency''' are important concepts in [[signal processing]] that occur in the context of the representation and analysis of time-varying functions.&lt;ref&gt;{{Cite journal|last=Sejdic|first=E.|last2=Djurovic|first2=I.|last3=Stankovic|first3=L.|date=August 2008|title=Quantitative Performance Analysis of Scalogram as Instantaneous Frequency Estimator|url=http://ieeexplore.ieee.org/document/4511413/|journal=IEEE Transactions on Signal Processing|volume=56|issue=8|pages=3837–3845|doi=10.1109/TSP.2008.924856|issn=1053-587X}}&lt;/ref&gt; The instantaneous phase (or "local phase" or simply "phase") of a ''complex-valued'' function ''s''(''t''), is the real-valued function:
:&lt;math&gt;\phi(t) = \arg\{s(t)\},&lt;/math&gt;
where '''arg''' is the [[Argument (complex analysis)|complex argument function]].

And for a ''real-valued'' function ''s''(''t''), it is determined from the function's [[analytic signal|analytic representation]], ''s''&lt;sub&gt;a&lt;/sub&gt;(''t''):&lt;ref&gt;{{cite book|last=Blackledge|first=Jonathan M.|title=Digital Signal Processing: Mathematical and Computational Methods, Software Development and Applications|year=2006|publisher=Woodhead Publishing|isbn=1904275265|page=134|edition=2}}&lt;/ref&gt;
:&lt;math&gt;\begin{align}
\phi(t) &amp;= \arg\{s_\mathrm{a}(t)\} \\
        &amp;= \arg\{s(t) + j \hat{s}(t)\}. \\
\end{align}&lt;/math&gt;

When ''φ''(''t'') is constrained to its [[principal value]], either the interval (-π, π] or [0, 2π), it is called ''wrapped phase''. Otherwise it is called ''unwrapped phase'', which is a continuous function of argument ''t'', assuming ''s''&lt;sub&gt;a&lt;/sub&gt;(''t'') is a continuous function of ''t''. Unless otherwise indicated, the continuous form should be inferred.

[[File:Phase vs Time, wrapped and unwrapped.jpg|thumb|400px|Instantaneous phase vs time.]]

==Examples==
===Example 1===
:&lt;math&gt;s(t) = A \cos(\omega t + \theta),&lt;/math&gt;
where ''ω'' &gt; 0.
:&lt;math&gt;s_\mathrm{a}(t) = A e^{j(\omega t + \theta)},&lt;/math&gt;
:&lt;math&gt;\phi(t) = \omega t + \theta.&lt;/math&gt;
In this simple sinusoidal example, the constant ''θ'' is also commonly referred to as ''phase'' or ''phase offset''. ''φ''(''t'') is a function of time; ''θ'' is not. In the next example, we also see that the phase offset of a real-valued sinusoid is ambiguous unless a reference (sin or cos) is specified. ''φ''(''t'') is unambiguously defined.

===Example 2===
:&lt;math&gt;s(t) = A \sin(\omega t) = A \cos(\omega t - \pi/2),&lt;/math&gt;
where ''ω'' &gt; 0.
:&lt;math&gt;s_\mathrm{a}(t) = A e^{j (\omega t - \pi/2)},&lt;/math&gt;
:&lt;math&gt;\phi(t) = \omega t - \pi/2.&lt;/math&gt;
In both examples the local maxima of ''s''(''t'') correspond to ''φ''(''t'') = 2π''N'' for integer values of ''N''. This has applications in the field of computer vision.

==Instantaneous frequency==
'''Instantaneous angular frequency''' is defined as:
:&lt;math&gt;\omega(t) = \frac{d\phi(t)}{dt},&lt;/math&gt;
and '''instantaneous (ordinary) frequency''' is defined as:
:&lt;math&gt;\begin{align}
f(t) &amp; =  \tfrac{1}{2\pi} \omega(t) \\
     &amp; = \tfrac{1}{2\pi} \frac{d\phi(t)}{dt} \\
\end{align}&lt;/math&gt;
where ''φ''(''t'') '''must''' be the ''unwrapped'' instantaneous phase angle. If ''φ''(''t'') is wrapped, discontinuities in ''φ''(''t'') will result in [[dirac delta]] impulses in ''f''(''t'').

The inverse operation, which always unwraps phase, is:
:&lt;math&gt;\begin{align}
\phi(t) &amp;= \int_{-\infty}^t \omega(\tau)\, d\tau = 2 \pi \int_{-\infty}^t f(\tau)\, d\tau\\
        &amp;= \int_{-\infty}^0 \omega(\tau)\, d\tau + \int_{0}^{t} \omega(\tau)\, d\tau\\
        &amp;= \phi(0) + \int_0^t \omega(\tau)\, d\tau.
\end{align}&lt;/math&gt;

This instantaneous frequency, ''ω''(t), can be derived directly from the [[Complex number|real and imaginary parts]] of ''s''&lt;sub&gt;a&lt;/sub&gt;(''t''), instead of the [[Argument (complex analysis)|complex arg]] without concern of phase unwrapping.

:&lt;math&gt;\begin{align}
\phi(t) &amp;= \arg\{s_\mathrm{a}(t)\} \\
        &amp;= \operatorname{atan2}(\Im\{s_\mathrm{a}(t)\},\Re\{s_\mathrm{a}(t)\}) + 2 m_1 \pi \\
        &amp;= \arctan\left( \frac{\Im\{s_\mathrm{a}(t)\}}{\Re\{s_\mathrm{a}(t)\}} \right) + m_2 \pi \\
\end{align}&lt;/math&gt;

2''m''&lt;sub&gt;1&lt;/sub&gt;π and ''m''&lt;sub&gt;2&lt;/sub&gt;π are the integer multiples of π necessary to add to unwrap the phase. At values of time, ''t'', where there is no change to integer ''m''&lt;sub&gt;2&lt;/sub&gt;, the derivative of ''φ''(''t'') is

:&lt;math&gt;\begin{align}
\omega(t) &amp;= \frac{d\phi(t)}{dt} \\
        &amp;= \frac{d}{dt} \arctan\left( \frac{\Im\{s_\mathrm{a}(t)\}}{\Re\{s_\mathrm{a}(t)\}} \right) \\
\\
        &amp;= \frac{1}{1+\left(\frac{\Im\{s_\mathrm{a}(t)\}}{\Re\{s_\mathrm{a}(t)\}} \right)^2} \frac{d}{dt} \left( \frac{\Im\{s_\mathrm{a}(t)\}}{\Re\{s_\mathrm{a}(t)\}} \right) \\
\\
        &amp;= \frac{\Re\{s_\mathrm{a}(t)\} \frac{d\Im\{s_\mathrm{a}(t)\}}{dt} - \Im\{s_\mathrm{a}(t)\} \frac{d\Re\{s_\mathrm{a}(t)\}}{dt} }{(\Re\{s_\mathrm{a}(t)\})^2 + (\Im\{s_\mathrm{a}(t)\})^2 } \\
\\
        &amp;= \frac{1}{|s_\mathrm{a}(t)|^2 } \left(\Re\{s_\mathrm{a}(t)\} \frac{d\Im\{s_\mathrm{a}(t)\}}{dt} - \Im\{s_\mathrm{a}(t)\} \frac{d\Re\{s_\mathrm{a}(t)\}}{dt} \right) \\
        &amp;= \frac{1}{(s(t))^2 + ((\hat{s}(t))^2} \left(s(t) \frac{d\hat{s}(t)}{dt} - \hat{s}(t) \frac{ds(t)}{dt} \right) \\
\end{align}&lt;/math&gt;

For discrete-time functions, this can be written as a recursion:
:&lt;math&gt;\phi[n] = \phi[n-1] + \omega[n] = \phi[n-1] + \underbrace{\arg\{s_\mathrm{a}[n]\} - \arg\{s_\mathrm{a}[n-1]\}}_{\Delta \phi[n]}.&lt;/math&gt;

Discontinuities can then be removed by adding 2π whenever Δ''φ''[''n''] ≤ −π, and subtracting 2π whenever Δ''φ''[''n''] &gt; π. That allows ''φ''[''n''] to accumulate without limit and produces an unwrapped instantaneous phase. An equivalent formulation that replaces the modulo 2π operation with a complex multiplication is:
:&lt;math&gt;\phi[n] = \phi[n-1] + \arg\{s_\mathrm{a}[n] \, s_\mathrm{a}^*[n-1]\},&lt;/math&gt;
where the asterisk denotes complex conjugate. The discrete-time instantaneous frequency (in units of radians per sample) is simply the advancement of phase for that sample
:&lt;math&gt;\omega[n] = \arg\{s_\mathrm{a}[n] \, s_\mathrm{a}^*[n-1]\}.&lt;/math&gt;

==Complex representation==
In some applications, such as averaging the values of phase at several moments of time, it may be useful to convert each value to a complex number, or vector representation:&lt;ref&gt;{{cite journal|last1=Wang|first1=S.|title=An Improved Quality Guided Phase Unwrapping Method and Its Applications to MRI|journal=Progress in Electromagnetics Research-PIER|date=2014|volume=145|pages=273–286|url=http://www.jpier.org/PIER/pier.php?paper=14021005}}&lt;/ref&gt;
:&lt;math&gt;\begin{align}
e^{i\phi(t)}
&amp;= \frac{s_\mathrm{a}(t)}{|s_\mathrm{a}(t)|}\\
&amp;= \cos(\phi(t)) + i \sin(\phi(t)).
\end{align}&lt;/math&gt;

This representation is similar to the wrapped phase representation in that it does not distinguish between multiples of 2π in the phase, but similar to the unwrapped phase representation since it is continuous. A vector-average phase can be obtained as the [[Argument (complex analysis)|arg]] of the sum of the complex numbers without concern about wrap-around.

==See also==
*[[Analytic signal]]
*[[Frequency modulation]]

==References==
{{reflist}}

==Further reading==
*{{cite book |first=Leon |last=Cohen |title=Time-Frequency Analysis |location= |publisher=Prentice Hall |year=1995 }}
*{{cite book |last=Granlund |first= |last2=Knutsson |first2= |title=Signal Processing for Computer Vision |location= |publisher=Kluwer Academic Publishers |year=1995 |isbn= }}

[[Category:Signal processing]]
[[Category:Digital signal processing]]
[[Category:Time–frequency analysis]]
[[Category:Fourier analysis]]
[[Category:Electrical engineering]]
[[Category:Audio engineering]]</text>
      <sha1>bdcohnxdrb40qb9cq58fczc6k3te5sb</sha1>
    </revision>
  </page>
  <page>
    <title>Intelligence Advanced Research Projects Activity</title>
    <ns>0</ns>
    <id>11518586</id>
    <revision>
      <id>869842737</id>
      <parentid>866370534</parentid>
      <timestamp>2018-11-20T18:55:11Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: title, template type, pages. Add: pmid, journal. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26026">* 
{{Infobox government agency
| name              = Intelligence Advanced Research Projects Activity
| logo              = Intelligence Advanced Research Projects Activity logo.svg
| formed            = 2006
| jurisdiction      = [[United States Government]]
| headquarters      = [[Riverdale Park, Maryland]]&lt;ref name=HQdedication&gt;{{cite web |url=http://www.homelandsecuritynewswire.com/iarpa-dedicates-permanent-home-campus-u-maryland |title=IARPA dedicates a permanent home on the campus of U Maryland |date=2009-04-29 |access-date=2015-12-15 |publisher=Homeland Security News Wire}}&lt;/ref&gt;
| chief1_name       = [[Jason_Gaverick_Matheny|Jason Matheny]]
| chief1_position   = Director
| chief2_name       = Stacey Dixon
| chief2_position   = Deputy Director
| parent_department =
| parent_agency     = [[Office of the Director of National Intelligence]]
| website           = {{url|iarpa.gov|IARPA.gov}}
}}

The '''Intelligence Advanced Research Projects Activity''' ('''IARPA''') is an organization within the [[Office of the Director of National Intelligence]] responsible for leading research to overcome difficult challenges relevant to the [[United States Intelligence Community]].&lt;ref name=":0"&gt;{{Cite web|url=http://www.iarpa.gov/index.php/about-iarpa|title=About IARPA|website=|publisher=IARPA|access-date=2016-03-12}}&lt;/ref&gt;  IARPA characterizes its mission as follows: "To envision and lead high-risk, high-payoff research that delivers innovative technology for future overwhelming intelligence advantage."

IARPA funds academic and industry research across a broad range of technical areas, including mathematics, computer science, physics, chemistry, biology, neuroscience, linguistics, political science, and cognitive psychology. Most IARPA research is unclassified and openly published. IARPA transfers successful research results and technologies to other government agencies. Notable IARPA investments include quantum computing,&lt;ref name="IARPAQuantum"&gt;{{cite web |url=https://www.iarpa.gov/index.php/research-programs/quantum-programs-at-iarpa |title=Quantum programs at IARPA |date= |access-date=2017-06-20 |publisher=}}&lt;/ref&gt; superconducting computing, machine learning, and forecasting tournaments.

== Mission ==
IARPA characterizes its mission as follows:

To envision and lead high-risk, high-payoff research that delivers innovative technology for future overwhelming intelligence advantage.

== History ==
In 1958, the first Advanced Research Projects Agency, or ARPA, was created in response to an unanticipated surprise—the Soviet Union's successful launch of Sputnik on October 4, 1957. The ARPA model was designed to anticipate and pre-empt technological surprise. As then-Secretary of Defense Neil McElroy said, "I want an agency that makes sure no important thing remains undone because it doesn’t fit somebody's mission." The ARPA model has been characterized by ambitious technical goals, competitively awarded research led by term-limited staff, and independent testing and evaluation.

Authorized by the [[Director of National Intelligence|ODNI]] in 2006, IARPA was modeled after [[DARPA]] but focused on national intelligence needs, rather than military needs.  The agency was a consolidation of the [[National Security Agency]]'s [[Disruptive Technology Office]], the [[National Geospatial-Intelligence Agency]]'s National Technology Alliance, and the [[Central Intelligence Agency]]'s Intelligence Technology Innovation Center.&lt;ref&gt;{{cite web |url=http://www.afcea.org/signal/articles/templates/SIGNAL_Article_Template.asp?articleid=1399 |title=Igniting a Technical Renaissance |first=Maryann |last=Lawlor |website=Signal |date=October 2007 |publisher=[[AFCEA]]}}&lt;/ref&gt; IARPA operations began on October 1, 2007 with [[Lisa Porter]] as founding Director. Its headquarters, a new building in M Square, the [[University System of Maryland|University of Maryland]]'s research park in [[Riverdale Park, Maryland]], was dedicated in April 2009.&lt;ref name="HQdedication" /&gt;

IARPA's quantum computing research was named [[Science (magazine)|''Science'' magazine]]'s Breakthrough of the Year in 2010.&lt;ref name=":8" /&gt;&lt;ref name=":9" /&gt; In 2015, IARPA was named to lead foundational research and development in the [[National Strategic Computing Initiative]].&lt;ref name=":10" /&gt; IARPA is also a part of other White House science and technology efforts, including the U.S. [[BRAIN Initiative]], and the Nanotechnology-Inspired Grand Challenge for Future Computing.&lt;ref name=":11" /&gt;&lt;ref name=":12" /&gt; In 2013, [[The New York Times|''New York Times'']] op-ed columnist [[David Brooks (journalist)|David Brooks]] called IARPA "one of the government's most creative agencies."&lt;ref&gt;{{cite news|url=https://www.nytimes.com/2013/03/22/opinion/brooks-forecasting-fox.html|title=Forecasting Fox|last=Brooks|first=David|date=2013-03-21|newspaper=The New York Times|issn=0362-4331|access-date=2016-03-12}}&lt;/ref&gt;

== Approach ==
IARPA invests in multi-year research programs, in which academic and industry teams compete to solve a well-defined set of technical problems, regularly scored on a shared set of metrics and milestones. Each program is led by an IARPA Program Manager (PM) who is a term-limited Government employee. IARPA programs are meant to enable researchers to pursue ideas that are potentially disruptive to the status quo.

Most IARPA research is unclassified and openly published.&lt;ref name="tri"&gt;{{Triangulation|276|Jason Matheny}}&lt;/ref&gt;  Current director [[Jason Gaverick Matheny|Jason Matheny]] has stated the agency's goals of openness and external engagement to draw in expertise from academia and industry, or even individuals who "might be working in their basement on some data-science project and might have an idea for how to solve an important problem".&lt;ref name=":42"&gt;{{Cite web|url=http://spectrum.ieee.org/computing/networks/iarpas-new-director-wants-you-to-surprise-him|title=IARPA's New Director Wants You to Surprise Him|last=Harbert|first=Tam|date=2015-10-19|website=IEEE Spectrum|access-date=2016-03-31}}&lt;/ref&gt; IARPA transfers successful research results and technologies to other government agencies.

== Research fields ==
IARPA is known for its programs to fund research into anticipatory intelligence, using [[data science]] to make predictions about future events ranging from political elections to disease outbreaks to cyberattacks, some of which focus on [[open-source intelligence]].&lt;ref name=":5"&gt;{{Cite web|url=http://www.federaltimes.com/story/government/interview/one-one/2015/11/02/how-iarpa-predicts-unpredictable/75040142/|title=How IARPA predicts the unpredictable|last=Corrin|first=Amber|date=2015-11-02|website=Federal Times|access-date=2016-03-31}}&lt;/ref&gt;&lt;ref name=":6"&gt;{{Cite web|url=http://www.c4isrnet.com/story/military-tech/it/2015/09/23/iarpa-anticipating-surprise/72632204/|title=IARPA's high-stakes intelligence experiment|last=Corrin|first=Amber|date=2015-09-23|website=C4ISR &amp; Networks|access-date=2016-03-31}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|url=https://www.wired.com/2010/10/u-s-spies-want-algorithms-to-spot-hot-trends/|title=U.S. Spies Want Algorithms to Spot Hot Trends|last=Drummond|first=Katie|date=2010-10-01|journal=WIRED|language=en-US|access-date=2016-03-31}}&lt;/ref&gt;  IARPA has pursued these objectives not only through traditional funding programs but also through tournaments&lt;ref name=":5" /&gt;&lt;ref name=":6" /&gt; and prizes.&lt;ref name=":42"/&gt;  c is an example of one such program.&lt;ref name=":42"/&gt;&lt;ref name=":6" /&gt;  Other projects involve analysis of images or video that lacks [[metadata]] by directly analyzing the media's content itself.  Examples given by IARPA include determining the location of an image by analyzing features such as placement of trees or a mountain skyline, or determining whether a video is of a baseball game or a traffic jam.&lt;ref name=":42"/&gt;  Another program focuses on developing [[speech recognition]] tools that can transcribe arbitrary languages.&lt;ref name=":7"&gt;{{Cite web|url=http://www.popularmechanics.com/technology/security/a17451/iarpa-americas-secret-spy-lab/|title=What They're Building Inside America's Secret Spy Lab|last=Belfiore|first=Michael|date=2015-09-23|website=Popular Mechanics|access-date=2016-03-31}}&lt;/ref&gt;

IARPA is also involved in [[high-performance computing]] and alternative computing methods.  In 2015, IARPA was named as one of two foundational research and development agencies in the [[National Strategic Computing Initiative]], with the specific charge of "future computing paradigms offering an alternative to standard semiconductor computing technologies".&lt;ref name=":10"&gt;{{Cite web|url=http://www.deltek.com/blog/home/b2g-essentials/2015/08/the-national-strategic-computing-initiative-a-not-so-new-program |title=The National Strategic Computing Initiative - A Not-So-New Program |last=Rossino |first=Alexander |date=2015-08-18 |website=B2G Essentials |publisher=Deltek |access-date=2016-03-12 |deadurl=yes |archiveurl=https://web.archive.org/web/20160312133713/http://www.deltek.com/blog/home/b2g-essentials/2015/08/the-national-strategic-computing-initiative-a-not-so-new-program |archivedate=2016-03-12 |df= }}&lt;/ref&gt;  One such approach is cryogenic [[superconducting computing]], which seeks to use [[Superconductivity|superconductors]] such as [[niobium]] rather than [[semiconductor]]s to reduce the energy consumption of future [[Exascale computing|exascale supercomputers]].&lt;ref name=":42"/&gt;&lt;ref name=":7"/&gt;

Several programs at IARPA focus on [[quantum computing]]&lt;ref name="IARPAQuantum" /&gt; and [[neuroscience]].&lt;ref&gt;{{Cite web|url=http://www.iarpa.gov/index.php/research-programs/neuroscience-programs-at-iarpa|title=Neuroscience Programs at IARPA|website=IARPA|access-date=2016-03-31}}&lt;/ref&gt;  IARPA is a major funder of quantum computing research due to its applications in [[quantum cryptography]].  As of 2009, IARPA was said to provide a large portion of quantum computing funding resources in the United States.&lt;ref&gt;{{Cite journal|last=Weinberger|first=Sharon|date=2009-06-03|title=Spooky research cuts|url=http://www.nature.com/news/2009/090603/full/459625a.html|journal=Nature|language=en|volume=459|issue=7247|pages=625|doi=10.1038/459625a|pmid=19494878}}&lt;/ref&gt;  Quantum computing research funded by IARPA was named Science Magazine's Breakthrough of the Year in 2010,&lt;ref name=":8"&gt;{{Cite web|url=https://arstechnica.com/science/2010/12/sciences-breakthrough-of-2010-a-macro-scale-quantum-device/|title=Science's breakthrough of 2010: A visible quantum device|last=Ford|first=Matt|date=2010-12-23|website=Ars Technica|access-date=2016-03-31}}&lt;/ref&gt;&lt;ref name=":9"&gt;{{Cite journal|last=O’Connell|first=A. D.|last2=Hofheinz|first2=M.|last3=Ansmann|first3=M.|last4=Bialczak|first4=Radoslaw C.|last5=Lenander|first5=M.|last6=Lucero|first6=Erik|last7=Neeley|first7=M.|last8=Sank|first8=D.|last9=Wang|first9=H.|title=Quantum ground state and single-phonon control of a mechanical resonator|journal=Nature|volume=464|issue=7289|pages=697–703|doi=10.1038/nature08967|pmid=20237473|date=April 2010}}&lt;/ref&gt; and physicist [[David J. Wineland|David Wineland]] was a winner of the 2012 [[Nobel Prize in Physics]] for quantum computing research funded by IARPA.&lt;ref name=":42"/&gt; IARPA is also involved in [[Neuromorphic engineering|neuromorphic computation]] efforts as part of the U.S. [[BRAIN Initiative]] and the [[National Nanotechnology Initiative]]'s Grand Challenge for Future Computing.  IARPA's [[MICrONS]] project seeks to [[Reverse engineering|reverse engineer]] one cubic millimeter of brain tissue and use insights from its study to improve [[machine learning]] and [[artificial intelligence]].&lt;ref name=":11"&gt;{{Cite web|url=http://www.scientificamerican.com/article/the-u-s-government-launches-a-100-million-apollo-project-of-the-brain/|title=The U.S. Government Launches a $100-Million "Apollo Project of the Brain"|last=Cepelewicz|first=Jordana|date=2016-03-08|website=Scientific American|access-date=2016-03-12}}&lt;/ref&gt;&lt;ref name=":12"&gt;{{Cite web|url=https://www.whitehouse.gov/blog/2015/10/15/nanotechnology-inspired-grand-challenge-future-computing|title=A Nanotechnology-Inspired Grand Challenge for Future Computing|last=Whitman|first=Lloyd|last2=Bryant|first2=Randy|date=2015-10-30|website=The White House|access-date=2016-05-01|last3=Kalil|first3=Tom}}&lt;/ref&gt;

== Research Programs ==
Below are some of the past and current research programs of IARPA.

=== Past research ===
* [[Aggregative Contingent Estimation (ACE) Program]] aimed "to dramatically enhance the accuracy, precision, and timeliness of intelligence forecasts for a broad range of event types, through the development of advanced techniques that elicit, weight, and combine the judgments of many intelligence analysts."&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/ace|title=ACE|website=www.iarpa.gov|language=en-gb|access-date=2017-03-12}}&lt;/ref&gt;
* ATHENA Program was a research program about cybersecurity.&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/athena|title=ATHENA|website=www.iarpa.gov|language=en-gb|access-date=2017-03-12}}&lt;/ref&gt; It aimed "to provide an early warning system for detecting precursors to cyberattacks".&lt;ref&gt;{{Cite web|url=https://lifeboat.com/blog/2016/09/iarpa-to-develop-early-warning-system-for-cyberattacks|title=Lifeboat News: The Blog|website=lifeboat.com|access-date=2017-03-12}}&lt;/ref&gt;
* [[Babel program|Babel Program]] developed "agile and robust speech recognition technology that can be rapidly applied to any human language in order to provide effective search capability for analysts to efficiently process massive amounts of real-world recorded speech".&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/babel|title=Babel|website=www.iarpa.gov|language=en-gb|access-date=2017-03-13}}&lt;/ref&gt; The program tries to develop a software that can transcribe and search among all the languages.&lt;ref&gt;{{Cite news|url=http://www.popularmechanics.com/technology/security/a17451/iarpa-americas-secret-spy-lab/|title=What They're Building Inside America's Secret Spy Lab|date=2015-09-23|work=Popular Mechanics|access-date=2017-03-13|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=http://www.defenseone.com/technology/2014/12/what-happens-when-spies-can-eavesdrop-any-conversation/100142/|title=What Happens When Spies Can Eavesdrop on Any Conversation?|work=Defense One|access-date=2017-03-13}}&lt;/ref&gt;
* Biometrics Exploitation Science &amp; Technology (BEST) Program focused on "significantly advance the state-of-the-science for biometrics technologies".&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/best|title=BEST|website=www.iarpa.gov|language=en-gb|access-date=2017-03-12}}&lt;/ref&gt; It was to discover techniques on utilising biometric from a subject in a less controlled environment which could produce a similar result to that in a controlled environment.&lt;ref&gt;{{Cite journal|date=2009-02-01|title=IARPA seeks BEST biometrics|url=http://www.sciencedirect.com/science/article/pii/S0969476509700451|journal=Biometric Technology Today|volume=17|issue=2|pages=3–4|doi=10.1016/S0969-4765(09)70045-1}}&lt;/ref&gt;

=== Current research ===
* Creation of Operationally Realistic 3-D Environments (CORE3D) aims to "develop rapid automated systems for 3-D models which are designed with complex physical properties and automated methods that will pull commercial, satellite, and airborne imagery."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1844-iarpa-launches-core3d-program-to-build-accurate-3-d-models-from-satellite-imagery|title=CORE3D|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Crowdsourcing Evidence, Argumentation, Thinking and Evaluation (CREATE) Program is about "to develop, and experimentally test, systems that use crowdsourcing and structured analytic techniques to improve analytic reasoning".&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/create|title=CREATE|website=www.iarpa.gov|language=en-gb|access-date=2017-03-13}}&lt;/ref&gt; It hopes to improve the intelligence community's ability on better understanding evidence and sources in order to produce accurate information.&lt;ref&gt;{{Cite web|url=https://gcn.com/articles/2017/02/14/iarpa-create.aspx|title=Leveraging the wisdom (and ignorance) of crowds -- GCN|website=GCN|language=en|access-date=2017-03-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.meritalk.com/articles/data-analytics-intelligence-iarpa-jason-matheny-sensors-iot/|title=Data Analytics Key to Complex Intelligence Decisions, Says IARPA Director – MeriTalk|website=www.meritalk.com|language=en-US|access-date=2017-03-13}}&lt;/ref&gt;
* Deep Intermodal Video Analytics (DIVA) aims to "advance state-of-the-art artificial visual perception, and automate video monitoring."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1834-iarpa-launches-diva-program-to-automatically-detect-complex-activities-from-video|title=DIVA|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Functional Genomic and Computational Assessment of Threats (Fun GCAT) aims to "develop next-generation biological data tools to improve DNA sequence screening, augment biodefense capabilities through the characterization of threats, and advance our understanding of the relative risks posed by unknown sequences."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1831-iarpa-launches-program-to-develop-new-biosecurity-tools|title=FunGCAT|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Hybrid Forecasting Competition (HFC) aims to "aims to improve accuracy in predicting worldwide geopolitical issues, including foreign political elections, interstate conflict, disease outbreaks, and economic indicators by leveraging the relative strengths of humans and machines."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1785-iarpa-launches-hybrid-forecasting-competition-to-improve-predictions-through-human-machine-integration|title=HFC|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Machine Translation for English Retrieval of Information in Any Language (MATERIAL) aims to "develop and deploy fully automatic systems that will allow English-only speakers to accurately and efficiently identify foreign language documents of interest."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1829-iarpa-launches-material-program|title=MATERIAL|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Molecular Analyzer for Efficient Gas-phase Low-power Interrogation (MAEGLIN) aims to "develop a compact system capable of unattended environmental sampling and chemical identification with minimal (preferably no) consumables."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1753-iarpa-launches-maeglin-program-to-develop-low-power-autonomous-chemical-identification-systems|title=MAEGLIN|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;
* Multimodal Objective Sensing to Assess Individuals with Context (MOSAIC) Program aims to develop "unobtrusive, passive, and persistent measurement to predict an individual’s job performance".&lt;ref&gt;{{Cite web|url=https://www.iarpa.gov/index.php/research-programs/mosaic|title=MOSAIC|website=www.iarpa.gov|language=en-gb|access-date=2017-03-13}}&lt;/ref&gt; It designs and tests sensors which can collect data about monitoring employees' work performance.&lt;ref&gt;{{Cite web|url=https://fcw.com/blogs/the-spec/2016/07/iarpa-sensors-evaluation.aspx|title=IC wants sensors to evaluate personnel performance -- FCW|website=FCW|language=en|access-date=2017-03-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=http://www.nextgov.com/emerging-tech/2016/06/intelligence-community-will-monitor-wearables-find-perfect-spy/129555/|title=The Intelligence Community Will Monitor Wearables to Find the Perfect Spy|work=Nextgov|access-date=2017-03-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://thestack.com/big-data/2016/10/19/u-s-government-proposes-the-permanent-job-interview/|title=U.S. government proposes the permanent job interview|date=2016-10-19|work=The Stack|access-date=2017-03-13|language=en-GB}}&lt;/ref&gt;
* Rapid Analysis of Various Emerging Nano-electronics (RAVEN) aims to "develop tools to rapidly image current and future integrated circuit chips."&lt;ref&gt;{{Cite web|url=https://www.dni.gov/index.php/newsroom/press-releases/item/1754-iarpa-launches-raven-program-to-develop-rapid-integrated-circuit-imaging-tools|title=RAVEN|website=www.dni.gov|language=en-gb|access-date=2018-04-04}}&lt;/ref&gt;

==Directors==
* [[Steven Nixon]] (acting, 2007)&lt;ref name=":2"&gt;{{Cite web|url=https://gcn.com/articles/2007/08/14/master-spy-agency-promotes-nixon.aspx|title=Master spy agency promotes Nixon|last=Dizard III|first=Wilson P.|date=2007-08-14|website=GCN|access-date=2016-03-15}}&lt;/ref&gt;
* Tim Murphy (acting, 2007–2008)&lt;ref name=":2" /&gt;&lt;ref name=":3"&gt;{{Cite web|url=https://defensesystems.com/Articles/2008/03/The-future-of-intelligence.aspx|title=The Future of Intelligence|last=Lais|first=Sami|date=2008-03-24|website=Defense Systems|access-date=2016-03-15}}&lt;/ref&gt;
* [[Lisa Porter]] (2008–2012)&lt;ref name=":3" /&gt;
* Peter Highnam (2012–2015)&lt;ref&gt;{{Cite web|url=http://fedscoop.com/highnam-named-iarpa-director/|title=Highnam named IARPA director|last=Stegon|first=David|date=2012-09-04|website=FedScoop|access-date=2016-03-15}}&lt;/ref&gt;
* [[Jason Gaverick Matheny|Jason Matheny]] (2015–present)&lt;ref name=":1"&gt;{{Cite web|url=http://www.iarpa.gov/index.php/about-iarpa/leadership|title=Leadership|website=|publisher=IARPA|access-date=2016-03-12}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://fedscoop.com/jason-matheny-named-iarpa-director|title=Jason Matheny named IARPA director|last=Otto|first=Greg|date=2015-08-03|website=FedScoop|access-date=2016-03-15}}&lt;/ref&gt;

==See also==
* [[DARPA|Defense Advanced Research Projects Agency (DARPA)]]
* [[Advanced Research Projects Agency-Energy|Advanced Research Projects Agency-Energy (ARPA-E)]] 
* [[Homeland Security Advanced Research Projects Agency|Homeland Security Advanced Research Projects Agency (HSARPA)]]

==References==
{{Reflist}}

==Further reading==
* Signal. (2015). ''[http://www.afcea.org/content/?q=Article-data-analytics-programs-help-predict-global-unrest Data Analytics Programs Help Predict Global Unrest]''. Retrieved December 1, 2015.
* CS4ISR &amp; Networks. (2015). ''[http://www.c4isrnet.com/story/military-tech/it/2015/09/23/iarpa-anticipating-surprise/72632204/ IARPA's high-stakes intelligence experiment.]'' Retrieved September 23, 2015.
* Executive Gov (2015). ''[http://www.executivegov.com/2015/10/jason-matheny-iarpa-seeks-automated-methods-to-identify-cyber-attack-indicators/ Jason Matheny: IARPA Seeks Automated Methods to Identify Cyber Attack Indicators]''[http://www.executivegov.com/2015/10/jason-matheny-iarpa-seeks-automated-methods-to-identify-cyber-attack-indicators/ .] Retrieved October 14, 2015.
* Federal Times (2015). ''[http://www.federaltimes.com/story/government/interview/one-one/2015/11/02/how-iarpa-predicts-unpredictable/75040142/ How IARPA Predicts the Unpredictable]''[http://www.federaltimes.com/story/government/interview/one-one/2015/11/02/how-iarpa-predicts-unpredictable/75040142/ .] Retrieved November 2, 2015.
* Fedscoop. (2013). ''[http://fedscoop.com/iarpa-wants-know-makes-tick/ Intelligence agency wants to know what makes you tick]''[http://fedscoop.com/iarpa-wants-know-makes-tick/ .] Retrieved January 17, 2014.
* Harvard Business Review (2015). ''[https://hbr.org/2015/10/how-a-video-game-helped-people-make-better-decisions How a Video Game Helped People Make Better Decisions]''[https://hbr.org/2015/10/how-a-video-game-helped-people-make-better-decisions .] Retrieved October 13, 2015.
* IEEE Spectrum (2015). ''[http://spectrum.ieee.org/computing/networks/iarpas-new-director-wants-you-to-surprise-him IARPA’s New Director Wants You to Surprise Him]''[http://spectrum.ieee.org/computing/networks/iarpas-new-director-wants-you-to-surprise-him .] Retrieved October 19, 2015.
* New York Times. (2013). ''[https://www.nytimes.com/2013/03/22/opinion/brooks-forecasting-fox.html?_r=2 Forecasting Fox]''. Retrieved July 11, 2014.
* Popular Mechanics. (2015). ''[http://www.popularmechanics.com/technology/security/a17451/iarpa-americas-secret-spy-lab/ What They're Building Inside America's Secret Spy Tech Lab]''[http://www.popularmechanics.com/technology/security/a17451/iarpa-americas-secret-spy-lab/ .] Retrieved September 23, 2015.
* USA Today. (2007). ''[http://usatoday30.usatoday.com/tech/news/techinnovations/2007-05-31-iarpa-spy-tools_N.htm New IARPA Agency Developing Spy Tools]''[http://usatoday30.usatoday.com/tech/news/techinnovations/2007-05-31-iarpa-spy-tools_N.htm .] Retrieved October 2, 2015. 
* Washington Post. (2013). ''[https://www.washingtonpost.com/news/monkey-cage/wp/2013/11/26/good-judgment-in-forecasting-international-affairs-and-an-invitation-for-season-3/ Good judgment in forecasting international affairs]''[https://www.washingtonpost.com/news/monkey-cage/wp/2013/11/26/good-judgment-in-forecasting-international-affairs-and-an-invitation-for-season-3/ .] Retrieved February 10, 2014.
* Wired. (2010). [https://www.wired.com/2010/10/u-s-spies-want-algorithms-to-spot-hot-trends/ U.S. ''Spies Want Algorithms to Spot Hot Trends''.] Retrieved August 13, 2014.

==External links==
* [http://www.iarpa.gov/ IARPA Homepage]
* [http://www.iarpa.gov/index.php/research-programs List of current and past research programs]
* [https://www.whitehouse.gov/the-press-office/2015/07/29/executive-order-creating-national-strategic-computing-initiative National Strategic Computing Initiative Executive Order]
* [https://www.whitehouse.gov/brain U.S. BRAIN Initiative]

{{Intelligence agencies of USA}}{{United States research agencies}}

[[Category:Agencies of the United States government]]
[[Category:United States intelligence agencies]]
[[Category:Quantum computing]]</text>
      <sha1>bttsskfetybu6n6bhlc3lgmzivi08zo</sha1>
    </revision>
  </page>
  <page>
    <title>Isolation lemma</title>
    <ns>0</ns>
    <id>27295601</id>
    <revision>
      <id>846643743</id>
      <parentid>790711783</parentid>
      <timestamp>2018-06-20T01:45:11Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14958">In [[theoretical computer science]], the term '''isolation lemma''' (or '''isolating lemma''') refers to [[randomized algorithm]]s that reduce the number of solutions to a problem to one, should a solution exist.
This is achieved by constructing random constraints such that, with non-negligible probability, exactly one solution satisfies these additional constraints if the solution space is not empty.
Isolation lemmas have important applications in computer science, such as the [[Valiant–Vazirani theorem]] and [[Toda's theorem]] in [[computational complexity theory]].

The first isolation lemma was introduced by {{harvtxt|Valiant|Vazirani|1986}}, albeit not under that name.
Their isolation lemma chooses a random number of random hyperplanes, and has the property that, with non-negligible probability, the intersection of any fixed non-empty solution space with the chosen hyperplanes contains exactly one element. This suffices to show the [[Valiant–Vazirani theorem]]:
there exists a randomized [[polynomial-time reduction]] from the [[Boolean satisfiability problem|satisfiability problem for Boolean formulas]] to the problem of detecting whether a Boolean formula has a unique solution.
{{harvtxt|Mulmuley|Vazirani|Vazirani|1987}} introduced an isolation lemma of a slightly different kind:
Here every coordinate of the solution space gets assigned a random weight in a certain range of integers, and the property is that, with non-negligible probability, there is exactly one element in the solution space that has minimum weight. This can be used to obtain a randomized parallel algorithm for the [[maximum matching]] problem.

Stronger isolation lemmas have been introduced in the literature to fit different needs in various settings.
For example, the isolation lemma of {{harvtxt|Chari|Rohatgi|Srinivasan|1993}} has similar guarantees as that of Mulmuley et al., but it uses fewer random bits.
In the context of the [[exponential time hypothesis]], {{harvtxt|Calabro|Impagliazzo|Kabanets|Paturi|2008}} prove an isolation lemma for [[Boolean satisfiability problem|k-CNF formulas]].
Noam Ta-Shma&lt;ref name="tashmaiso"&gt;Noam Ta-Shma (2015); [http://eccc.hpi-web.de/report/2015/080/ ''A simple proof of the Isolation Lemma''], in ''eccc''&lt;/ref&gt; gives an isolation lemma with slightly stronger parameters, and gives non-trivial results even when the size of the weight domain is smaller than the number of variables.

==The isolation lemma of Mulmuley, Vazirani, and Vazirani==
[[File:Linear optimization in a 2-dimensional polytope.svg|thumb|Any [[linear program]] with a randomly chosen linear cost function has a unique optimum with high probability. The isolation lemma of Mulmuley, Vazirani, and Vazirani extends this fact to ''arbitrary'' sets and a random cost function that is sampled using ''few'' random bits.]]
:'''Lemma.''' Let &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;N&lt;/math&gt; be positive integers, and let &lt;math&gt;\mathcal F&lt;/math&gt; be an arbitrary family of subsets of the universe &lt;math&gt;\{1,\dots,n\}&lt;/math&gt;. Suppose each element &lt;math&gt;x\in\{1,\dots,n\}&lt;/math&gt; in the universe receives an integer weight &lt;math&gt;w(x)&lt;/math&gt;, each of which is chosen independently and uniformly at random from &lt;math&gt;\{1,\dots,N\}&lt;/math&gt;. The weight of a set ''S'' in &lt;math&gt;\mathcal F&lt;/math&gt; is defined as
::&lt;math&gt;w(S) = \sum_{x \in S} w(x)\,.&lt;/math&gt;
:Then, with probability at least &lt;math&gt;1-n/N&lt;/math&gt;, there is a ''unique'' set in &lt;math&gt;\mathcal F&lt;/math&gt; that has the minimum weight among all sets of &lt;math&gt;\mathcal F&lt;/math&gt;.


It is remarkable that the lemma assumes nothing about the nature of the family &lt;math&gt;\mathcal F&lt;/math&gt;: for instance &lt;math&gt;\mathcal F&lt;/math&gt; may include ''all'' &lt;math&gt;2^n-1&lt;/math&gt; nonempty subsets. Since the weight of each set in &lt;math&gt;\mathcal F&lt;/math&gt; is between &lt;math&gt;1&lt;/math&gt; and &lt;math&gt;nN&lt;/math&gt; on average there will be &lt;math&gt;(2^n-1) / (nN)&lt;/math&gt; sets of each possible weight.
Still, with high probability, there is a unique set that has minimum weight.
&lt;div class="NavFrame collapsed" style="width: 50%;"&gt;
  &lt;div class="NavHead"&gt;[Mulmuley, Vazirani, and Vazirani's Proof]&lt;/div&gt;
  &lt;div class="NavContent" style="text-align:left"&gt;
Suppose we have fixed the weights of all elements except an element ''x''. Then ''x'' has a ''threshold'' weight ''α'', such that if the weight ''w''(''x'') of ''x'' is greater than ''α'', then it is not contained in any minimum-weight subset, and if &lt;math&gt;w(x) \le \alpha&lt;/math&gt;, then it is contained in some sets of minimum weight. Further, observe that if &lt;math&gt;w(x) &lt; \alpha&lt;/math&gt;, then ''every'' minimum-weight subset must contain ''x'' (since, when we decrease ''w(x)'' from ''α'', sets that do not contain ''x'' do not decrease in weight, while those that contain ''x'' do). Thus, ambiguity about whether a minimum-weight subset contains ''x'' or not can happen only when the weight of ''x'' is exactly equal to its threshold; in this case we will call ''x'' "singular". Now, as the threshold of ''x'' was defined only in terms of the weights of the ''other'' elements, it is independent of ''w(x)'', and therefore, as ''w''(''x'') is chosen uniformly from {1,&amp;nbsp;…,&amp;nbsp;''N''},

:&lt;math&gt;\Pr[x\text{ is singular}] = \Pr[w(x) = \alpha] \le 1/N&lt;/math&gt;

and the probability that ''some'' ''x'' is singular is at most&amp;nbsp;''n/N''. As there is a unique minimum-weight subset [[iff]] no element is singular, the lemma follows.

Remark: The lemma holds with  &lt;math&gt;\le&lt;/math&gt;  (rather than =) since it is possible that some ''x'' has no threshold value (i.e., ''x'' will not be in any minimum-weight subset even if ''w''(''x'') gets the minimum possible value, 1).
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class="NavFrame collapsed" style="width: 50%;"&gt;
  &lt;div class="NavHead"&gt;[Joel Spencer's Proof]&lt;/div&gt;
  &lt;div class="NavContent" style="text-align:left"&gt;
This is a restatement version of the above proof, due to [[Joel Spencer]] (1995).&lt;ref&gt;{{harvtxt|Jukna|2001}}&lt;/ref&gt;

For any element ''x'' in the set, define

:&lt;math&gt;\alpha(x) = \min_{S \in \mathcal F, x \not\in S}w(S) - \min_{S\in\mathcal F, x\in S}w(S\setminus\{x\}). &lt;/math&gt;

Observe that &lt;math&gt;\alpha(x)&lt;/math&gt; depends only on the weights of elements other than ''x'', and not on ''w''(''x'') itself. So whatever the value of &lt;math&gt;\alpha(x)&lt;/math&gt;, as ''w''(''x'') is chosen uniformly from {1,&amp;nbsp;…,&amp;nbsp;''N''}, the probability that it is equal to &lt;math&gt;\alpha(x)&lt;/math&gt; is at most&amp;nbsp;1/''N''. Thus the probability that &lt;math&gt;w(x) = \alpha(x)&lt;/math&gt; for ''some'' ''x'' is at most&amp;nbsp;''n/N''.

Now if there are two sets ''A'' and ''B'' in &lt;math&gt;\mathcal F&lt;/math&gt; with minimum weight, then, taking any ''x'' in ''A\B'', we have

:&lt;math&gt;\begin{align}
\alpha(x) &amp;= \min_{S \in \mathcal F, x \not\in S}w(S) - \min_{S\in\mathcal F, x\in S}w(S\setminus\{x\})  \\
          &amp;= w(B) - (w(A)-w(x)) \\
          &amp;= w(x),
\end{align}&lt;/math&gt;

and as we have seen, this event happens with probability at most&amp;nbsp;''n/N''.
  &lt;/div&gt;
&lt;/div&gt;

==Examples/applications==
* The original application was to minimum-weight (or maximum-weight) perfect matchings in a graph. Each edge is assigned a random weight in {1,&amp;nbsp;…,&amp;nbsp;2''m''}, and &lt;math&gt;\mathcal F&lt;/math&gt; is the set of perfect matchings, so that with probability at least&amp;nbsp;1/2, there exists a unique perfect matching. When each indeterminate &lt;math&gt;x_{ij}&lt;/math&gt; in the [[Tutte matrix]] of the graph is replaced with &lt;math&gt;2^{w_{ij}}&lt;/math&gt; where &lt;math&gt;w_{ij}&lt;/math&gt; is the random weight of the edge, we can show that the determinant of the matrix is nonzero, and further use this to find the matching.
* More generally, the paper also observed that any search problem of the form "Given a set system &lt;math&gt;(S,\mathcal F)&lt;/math&gt;, find a set in &lt;math&gt;\mathcal F&lt;/math&gt;" could be reduced to a decision problem of the form "Is there a set in &lt;math&gt;\mathcal  F&lt;/math&gt; with total weight at most ''k''?". For instance, it showed how to solve the following problem posed by Papadimitriou and Yannakakis,  for which (as of the time the paper was written) no deterministic polynomial-time algorithm is known: given a graph and a subset of the edges marked as "red", find a perfect matching with exactly ''k'' red edges.
* The [[Valiant–Vazirani theorem]], concerning unique solutions to NP-complete problems, has a simpler proof using the isolation lemma. This is proved by giving a randomized reduction from [[Clique problem|CLIQUE]] to UNIQUE-CLIQUE.&lt;ref&gt;{{harvtxt|Mulmuley|Vazirani|Vazirani|1987}}&lt;/ref&gt;
* {{harvtxt|Ben-David|Chor|Goldreich|1989}} use the proof of Valiant-Vazirani in their search-to-decision reduction for [[average-case complexity]].
* [[Avi Wigderson]] used the isolation lemma in 1994 to give a randomized reduction from [[NL (complexity)|NL]] to UL, and thereby prove that NL/poly ⊆ ⊕L/poly.&lt;ref&gt;{{harvtxt|Wigderson|1994}}&lt;/ref&gt; Reinhardt and Allender later used the isolation lemma again to prove that NL/poly = UL/poly.&lt;ref&gt;{{harvtxt|Reinhardt|Allender|2000}}&lt;/ref&gt;
* The book by Hemaspaandra and Ogihara has a chapter on the isolation technique, including generalizations.&lt;ref&gt;{{harvtxt|Hemaspaandra|Ogihara|2002}}&lt;/ref&gt;
* The isolation lemma has been proposed as the basis of a scheme for [[digital watermarking]].&lt;ref&gt;{{harvtxt|Majumdar|Wong|2001}}&lt;/ref&gt;
* There is ongoing work on derandomizing the isolation lemma in specific cases&lt;ref&gt;{{harvtxt|Arvind|Mukhopadhyay|2008}}&lt;/ref&gt; and on using it for identity testing.&lt;ref&gt;{{harvtxt|Arvind|Mukhopadhyay|Srinivasan|2008}}&lt;/ref&gt;

==Notes==
{{reflist|colwidth=25em}}

==References==
{{refbegin|colwidth=25em}}
* {{Cite conference | publisher = Springer-Verlag | isbn = 978-3-540-85362-6 | pages = 276–289
 | last1 = Arvind | first1 = V.
 | last2 = Mukhopadhyay | first2 = Partha
 | title = Derandomizing the Isolation Lemma and Lower Bounds for Circuit Size | conference = Proceedings of the 11th international workshop, APPROX 2008, and 12th international workshop, RANDOM 2008 on Approximation, Randomization and Combinatorial Optimization: Algorithms and Techniques | location = Boston, MA, USA | accessdate = 2010-05-10 | date = 2008 | url = http://portal.acm.org/citation.cfm?id=1429791.1429816
 | ref=harv|arxiv=0804.0957| bibcode = 2008arXiv0804.0957A}}
* {{Cite conference | publisher = IEEE Computer Society | isbn = 978-0-7695-3169-4 | pages = 268–279
 | last1 = Arvind | first1 = V.
 | last2 = Mukhopadhyay | first2 = Partha
 | last3 = Srinivasan | first3 = Srikanth
 | title = New Results on Noncommutative and Commutative Polynomial Identity Testing
 | conference = Proceedings of the 2008 IEEE 23rd Annual Conference on Computational Complexity | accessdate = 2010-05-10 | date = 2008 | url = http://portal.acm.org/citation.cfm?id=1380843.1380966|ref=harv|arxiv=0801.0514| bibcode = 2008arXiv0801.0514A}}
* {{Cite conference |ref=harv| last1 = Ben-David | first1 = S. | last2 = Chor | first2 = B. | last3 = Goldreich | first3 = O. | doi = 10.1145/73007.73027 | title = On the theory of average case complexity | conference = Proceedings of the twenty-first annual ACM symposium on Theory of computing  - STOC '89 | pages = 204 | year = 1989 | isbn = 0897913078 | pmid =  | pmc = }}
* {{Cite journal |ref=harv| last1 = Calabro | first1 = C. | last2 = Impagliazzo | first2 = R. | last3 = Kabanets | first3 = V. | last4 = Paturi | first4 = R. | title = The complexity of Unique k-SAT: An Isolation Lemma for k-CNFs | doi = 10.1016/j.jcss.2007.06.015 | journal = Journal of Computer and System Sciences | volume = 74 | issue = 3 | pages = 386 | year = 2008 | pmid =  | pmc = }}
* {{Cite conference |ref=harv| last1 = Chari | first1 = S. | last2 = Rohatgi | first2 = P. | last3 = Srinivasan | first3 = A. | doi = 10.1145/167088.167213 | title = Randomness-optimal unique element isolation, with applications to perfect matching and related problems | conference = Proceedings of the twenty-fifth annual ACM symposium on Theory of computing  - STOC '93 | pages = 458 | year = 1993 | isbn = 0897915917 | pmid =  | pmc = }}
* {{Cite book | year=2002 | chapter= Chapter 4. The Isolation Technique | url=http://www.cs.rochester.edu/~lane/=companion/isolation.pdf | title=The complexity theory companion | last1=Hemaspaandra | first1=Lane A. | last2=Ogihara | first2=Mitsunori | ref=harv| publisher=Springer | isbn=978-3-540-67419-1 | postscript=.}}
* {{Cite conference | publisher = ACM | doi = 10.1145/378239.378566 | isbn = 1-58113-297-2 | pages = 480–485 | last1 = Majumdar | first1 = Rupak | last2 = Wong | first2 = Jennifer L. | title = Watermarking of SAT using combinatorial isolation lemmas | conference = Proceedings of the 38th annual Design Automation Conference | location = Las Vegas, Nevada, United States | accessdate = 2010-05-10 | date = 2001 | ref=harv| url = http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.9300}}
* {{Cite journal | volume = 29 | pages = 1118 | last1 = Reinhardt | first1 = K. | last2=Allender | first2 = E. | title = Making Nondeterminism Unambiguous | journal = SIAM Journal on Computing | year = 2000| ref=harv|url=ftp://128.6.25.4/http/pub/allender/nlul.pdf | doi = 10.1137/S0097539798339041 | issue = 4}}
* {{Cite journal
| last1 = Mulmuley | first1 = Ketan | authorlink1 = Ketan Mulmuley
| last2 = Vazirani | first2 = Umesh | authorlink2 = Umesh Vazirani
| last3 = Vazirani | first3 = Vijay | authorlink3 = Vijay Vazirani
| title = Matching is as easy as matrix inversion
| journal = Combinatorica
| volume = 7| issue = 1| pages = 105–113| ref=harv
| url=http://www.springerlink.com/content/r4rw2x4l46476708/
| year = 1987
| doi = 10.1007/BF02579206}}
* {{Cite book | last=Jukna | first=Stasys | year=2001 | title=Extremal combinatorics: with applications in computer science | publisher=Springer | isbn=978-3-540-66313-3 | url=http://lovelace.thi.informatik.uni-frankfurt.de/~jukna/EC_Book/index.html | pages=147–150 | ref=harv | postscript=.}} 
* {{Cite journal|ref=harv | last1 = Valiant | first1 = L. | last2 = Vazirani | first2 = V.| doi = 10.1016/0304-3975(86)90135-0 | title = NP is as easy as detecting unique solutions | url = http://www.cs.princeton.edu/courses/archive/fall05/cos528/handouts/NP_is_as.pdf| journal = Theoretical Computer Science | volume = 47 | pages = 85–93 | year = 1986 | pmid =  | pmc = }}
* {{Cite conference| last = Wigderson| first = Avi | authorlink = Avi Wigderson | title = NL/poly ⊆ ⊕L/poly | url = http://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/W94/proc.pdf | date = 1994 | conference = Proceedings of the 9th Structures in Complexity Conference | ref=harv| pages = 59–62}}
{{refend}}

==External links==
* [http://blog.computationalcomplexity.org/2006/09/favorite-theorems-unique-witnesses.html Favorite Theorems: Unique Witnesses] by [[Lance Fortnow]]
* [http://rjlipton.wordpress.com/2009/07/01/the-isolation-lemma-and-beyond/ The Isolation Lemma and Beyond] by [[Richard J. Lipton]]

{{DEFAULTSORT:Isolation Lemma}}
[[Category:Probability theorems]]
[[Category:Combinatorics]]
[[Category:Lemmas]]</text>
      <sha1>q99iai4zsq1xzgv9ju99y877zej0qee</sha1>
    </revision>
  </page>
  <page>
    <title>John Howard Redfield</title>
    <ns>0</ns>
    <id>7095290</id>
    <revision>
      <id>857361637</id>
      <parentid>732751278</parentid>
      <timestamp>2018-08-31T05:38:57Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8323">'''John Howard Redfield''' (June 8, 1879 – April 17, 1944) was an [[United States|American]] [[mathematician]], best known for discovery of what is now called [[Pólya enumeration theorem]] (PET) in 1927,&lt;ref&gt;{{cite journal | last = Lloyd | first = E. Keith | title = Redfield's contributions to enumeration | journal = Communications in Mathematical and in Computer Chemistry | volume = 46 | year = 2002 | pages = 215–233 | mr = 1787630 }}&lt;/ref&gt; ten years ahead of similar but independent discovery made by [[George Pólya]]. Redfield was a great-grandson of [[William Charles Redfield]], one of the founders and the first president of [[American Association for the Advancement of Science|AAAS]].

== Solution to MacMahon's conjecture ==
Redfield's ability is evident in letters exchanged&lt;ref name="Lloyd1984"&gt;{{cite journal | last = Lloyd | first = E. Keith | title = J. Howard Redfield 1879-1944 | journal = [[Journal of Graph Theory]] | volume = 8 | year = 1984 | issue = 2 | pages = 195–203  | doi = 10.1002/jgt.3190080203 |mr=0742875 }}&lt;/ref&gt; among Redfield, [[Percy MacMahon]], and [[Thomas Muir (mathematician)|Sir Thomas Muir]], following the publication of Redfield's paper [1] in 1927. Apparently Redfield sent a copy of his paper to MacMahon. In reply (letter of November 19, 1927), MacMahon expresses the view that Redfield has made a valuable contribution to the subject and goes on to mention a conjecture which he himself made in his recently delivered Rouse-Ball memorial lecture.&lt;ref&gt;{{cite journal| author=MacMahon, P. A. |title=The Structure of a Determinant| journal=[[Journal of the London Mathematical Society]] |year=1927 |volume=s1-2 |issue=4 |pages=273–286|url=http://intl-jlms.oxfordjournals.org/cgi/reprint/s1-2/4/273.pdf| doi=10.1112/jlms/s1-2.4.273}}&lt;/ref&gt; He also says that it is probable that Redfield's work would lead to a proof of it. Such was the case: in a draft reply dated December 26, 1927, Redfield writes: 
: ''"I am now able to demonstrate your conjectured expression..."''.
MacMahon, who had failed to prove it himself and then put the matter before men at both Cambridge and Oxford "without effect", delightedly wrote to Redfield (letter of January 9, 1928): 
: ''"when you first wrote to me I formed the opinion that with your powerful handling of the theory of substitutions it would be childs play to you and I was right. I congratulate you and feel sure that your methods will carry you far."''
MacMahon urged Redfield to publish his new results and also informed Muir about them. In a letter to Redfield dated December 31, 1931, Muir also encourages him to publish his verification "without waiting for MacMahon's executors" and suggests the ''Journal of the London Mathematical Society'' as an appropriate medium. As far as is known, Redfield did not follow up this suggestion, but the proof of MacMahon's conjecture was included in an unpublished manuscript which appears to be a sequel to the paper [3].&lt;ref&gt;{{cite journal | last = Lloyd | first = E. Keith | title = Redfield's proofs of MacMahon's conjecture | journal = Historia Mathematica | volume = 17 | issue = 1 | year = 1990 | pages = 36–47 | doi = 10.1016/0315-0860(90)90077-Q | mr = 1045715 }}&lt;/ref&gt;

== Redfield's contemporaries on him ==
A letter from Professor Cletus Oakley to [[Frank Harary]], dated December 19, 1963, reads in part:
: ''"Howard Redfield was a graduate of Haverford College in the Class of 1899. He was a man of very broad interests and we do not have a continuous record of his doings. Directly after leaving college, he worked as a civil engineer. In college he took a lot of languages and mathematics. (There was no major department in those days.) After graduating from Haverford with a B.S. degree, he took a S.B. degree in M.I.T. and a M.A. and Ph.D. (mathematics) at Harvard. During the year 1907-1908, he studied romance philology at the University of Paris. In 1908-1909, he was an instructor in mathematics at Worcester Polytechnic Institute, Worcester, Massachusetts. In 1910-1911 he taught French at Swarthmore College and from 1912-1914 he was an assistant professor of romance languages at Princeton University. From 1916 onward until his death in 1944, he was a practicing civil engineer in Wayne, Pennsylvania. "''
: ''"I knew him from about 1938-1944. Indeed in 1940 he came to Haverford College and gave us some lectures on 'Electronic Digital Computers' (this was slightly before [[Eckert–Mauchly Computer Corporation|Eckert-Mauchly]]). Knowing him as I did in those later years, I could well understand how he would not make a great teacher. He was completely off in the clouds at all times. He never looked at you, he spoke softly with his eyes on the floor, he worked with his back to you and wrote on the board. His board work, however, was impeccable. It could have been photographed and printed by photo offset it was so perfect."''
: ''"He came to Haverford to talk to our math club many times and always had something new to say..."''

Redfield's brother, Alfred, a marine biologist-oceanographer and former Associate Director of the [[Woods Hole Oceanographic Institution]], wrote (letter to E. Keith Lloyd, September 8, 1976):&lt;ref name="Lloyd1984"/&gt;
: ''"During the later years of his life, he turned to mathematics and I usually found him working at it when I called on him. It was evident that this was his true love."''

== Publications ==
# {{cite journal
 | last = Redfield
 | first = J. Howard
 | title = The Theory of Group-Reduced Distributions
 | journal = [[American Journal of Mathematics]]
 | volume = 49
 | year = 1927
 | issue = 3
 | pages = 433–455
 | jstor = 2370675
 | doi = 10.2307/2370675
 | mr = 1506633}}
# {{cite book
 | last = Redfield
 | first = J. Howard
 | title = Music: A Science and an Art
 | year = 1935
 | publisher = Tudor Publishing Co
 | url = https://archive.org/details/musicascienceand009118mbp}}
# {{cite journal
 | last = Redfield
 | first = J. Howard
 | title = Enumeration by frame group and range groups
 | journal = [[Journal of Graph Theory]]
 | volume = 8
 | year = 1984
 | issue = 2
 | pages = 205–223
 | doi = 10.1002/jgt.3190080204
 | mr = 0742876 }} 
#: This publication is based on a manuscript discovered in Redfield's legacy by his daughter. The correspondence found with the manuscript revealed that it had been submitted for publication in the [[American Journal of Mathematics]] on October 19, 1940 and was rejected by the editors in a brief letter of January 7, 1941. Redfield answered the objections of the referee in great detail ten days later and asked specific questions, but he never received a reply to his rebuttal. Apparently it was not subsequently resubmitted elsewhere.&lt;ref&gt;{{cite journal |author1=Frank Harary |author2=Robert W. Robinson | title = The rediscovery of Redfield's papers | journal = [[Journal of Graph Theory]] | volume = 8 | year = 1984 | issue = 2 | pages = 191–193 | doi = 10.1002/jgt.3190080202}}&lt;/ref&gt; The significance of this paper is discussed in.&lt;ref&gt;{{cite journal
 |author1=J. I. Hall |author2=E. M. Palmer |author3=R. W. Robinson | title = Redfield's lost paper in a modern context
 | journal = [[Journal of Graph Theory]]
 | volume = 8
 | year = 1984
 | issue = 2
 | pages = 225–240
 | doi = 10.1002/jgt.3190080205
 | mr = 0742877 }}&lt;/ref&gt;
# {{cite journal
 | last = Redfield
 | first = J. Howard
 | title = Group theory applied to combinatory analysis
 | journal = Communications in Mathematical and in Computer Chemistry
 | volume = 41
 | year = 2000
 | pages = 7–27
 | mr = 1787629 }} 
#: This publication represents a typescript of a lecture delivered by Redfield in 1937. According to Lloyd, ''“The text of Redfield's lecture is very readable, and anyone wishing to study his work would be well advised to read the lecture before passing on to his 1927 and 1940 papers.”'' &lt;ref&gt;{{cite journal
 | last = Lloyd
 | first = E. Keith
 | title = Redfield's 1937 lecture
 | journal = Communications in Mathematical and in Computer Chemistry
 | volume = 41
 | year = 2000
 | pages = 29–41
 | mr = 1787630 }}&lt;/ref&gt;

== References ==
&lt;references/&gt;

{{authority control}}

{{DEFAULTSORT:Redfield, John Howard}}
[[Category:1879 births]]
[[Category:1944 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Combinatorialists]]</text>
      <sha1>7upjne5ykbym7frd27mc78248gxpgax</sha1>
    </revision>
  </page>
  <page>
    <title>Kleene–Rosser paradox</title>
    <ns>0</ns>
    <id>14258729</id>
    <revision>
      <id>852883677</id>
      <parentid>838365401</parentid>
      <timestamp>2018-08-01T00:56:50Z</timestamp>
      <contributor>
        <username>Eli355</username>
        <id>33551130</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1706">In [[mathematics]], the '''Kleene&amp;ndash;Rosser paradox''' is a paradox that shows that certain systems of [[formal logic]] are [[inconsistent]], in particular the version of [[Haskell Curry|Curry]]'s [[combinatory logic]] introduced in 1930, and [[Alonzo Church|Church]]'s original [[lambda calculus]], introduced in 1932&amp;ndash;1933, both originally intended as systems of formal logic. The paradox was exhibited by [[Stephen Kleene]] and [[J. B. Rosser]] in 1935.

==The paradox==
Kleene and Rosser were able to show that both systems are able to characterize and enumerate their provably total, definable number-theoretic functions, which enabled them to construct a term that essentially replicates the [[Richard paradox]] in formal language.

Curry later managed to identify the crucial ingredients of the calculi that allowed the construction of this paradox, and used this to construct a much simpler paradox, now known as [[Curry's paradox#Lambda calculus|Curry's paradox]].

==See also==
* [[List of paradoxes]]

==References==

* Andrea Cantini, "[http://plato.stanford.edu/entries/paradoxes-contemporary-logic/#IncCerForLog The inconsistency of certain formal logics]", in the ''Paradoxes and Contemporary Logic'' entry of ''Stanford Encyclopedia of Philosophy'' (2007).
*{{Cite journal |first=S. C. |last=Kleene |lastauthoramp=yes |first2=J. B. |last2=Rosser |title=The inconsistency of certain formal logics |journal=[[Annals of Mathematics]] |volume=36 |issue=3 |pages=630–636 |year=1935 |doi=10.2307/1968646 }}

{{Paradoxes}}

{{mathematics-stub}}

{{DEFAULTSORT:Kleene-Rosser paradox}}
[[Category:Lambda calculus]]
[[Category:Mathematics paradoxes]]
[[Category:Self-referential paradoxes]]</text>
      <sha1>7xbt4yoo7yvg7tvnibjzsuxu9evc8e3</sha1>
    </revision>
  </page>
  <page>
    <title>List of axioms</title>
    <ns>0</ns>
    <id>734644</id>
    <revision>
      <id>871436805</id>
      <parentid>839669362</parentid>
      <timestamp>2018-12-01T01:51:44Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>linking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2507">This is a '''list of [[axiom]]s''' as that term is understood in [[mathematics]], by Wikipedia page.  In [[epistemology]], the word ''axiom'' is understood differently; see [[axiom]] and [[self-evidence]]. Individual axioms are almost always part of a larger [[axiomatic system]].

==ZF (the [[Zermelo–Fraenkel axioms]] without the axiom of choice)==
''Together with the axiom of choice (see below), these are the'' [[de facto]] ''standard axioms for contemporary [[mathematics]] or [[set theory]]. They can be easily adapted to analogous theories, such as [[mereology]].''

* [[Axiom of extensionality]]
* [[Axiom of empty set]]
* [[Axiom of pairing]]
* [[Axiom of union]]
* [[Axiom of infinity]]
* [[Axiom schema of replacement]]
* [[Axiom of power set]]
* [[Axiom of regularity]]
* [[Axiom schema of specification]]

See also [[Zermelo set theory]].

==[[Axiom of choice]]==
''With the Zermelo–Fraenkel axioms above, this makes up the system [[Zermelo–Fraenkel set theory|ZFC]] in which most mathematics is potentially formalisable.''

===Equivalents of AC===
*[[Hausdorff maximality theorem]]
*[[Well-ordering theorem]]
*[[Zorn's lemma]]

===Stronger than AC===
*[[Axiom of global choice]]

===Weaker than AC===
*[[Axiom of countable choice]]
*[[Axiom of dependent choice]]
*[[Boolean prime ideal theorem]]
*[[Axiom of uniformization]]

===Alternates incompatible with AC===
*[[Axiom of real determinacy]]

==Other axioms of [[mathematical logic]]==

*[[Von Neumann–Bernays–Gödel axioms]]
*[[Continuum hypothesis]] and [[Continuum hypothesis#The_generalized_continuum_hypothesis|its generalization]]
*[[Freiling's axiom of symmetry]]
*[[Axiom of determinacy]]
*[[Axiom of projective determinacy]]
*[[Martin's axiom]]
*[[Axiom of constructibility]]
*[[Rank-into-rank]]
*[[Kripke–Platek axioms]]

==[[Geometry]]==

*[[Parallel postulate]]
*[[Birkhoff's axioms]]
*[[Hilbert's axioms]]
*[[Tarski's axioms]]

==Other axioms==

*[[Axiom of Archimedes]] ([[real number]])
*[[Axiom of countability]] ([[topology]])
*[[Fundamental axiom of analysis]] ([[real analysis]])
*[[Gluing axiom]] ([[sheaf theory]])
*[[Haag–Kastler axioms]] ([[quantum field theory]])
*[[Huzita's axioms]] ([[origami]])
*[[Kuratowski closure axioms]] ([[topology]])
*[[Peano's axioms]] ([[natural numbers]])
*[[Probability axioms]]
*[[Separation axiom]] ([[topology]])
*[[Wightman axioms]] ([[quantum field theory]])

{{Portal|Mathematics}}

[[Category:Mathematics-related lists|Axioms]]
[[Category:Mathematical axioms|*]]</text>
      <sha1>1lq20zjpp2ozaoxf5c0hyz4amd3cq72</sha1>
    </revision>
  </page>
  <page>
    <title>List of mathematicians (X)</title>
    <ns>0</ns>
    <id>5971841</id>
    <revision>
      <id>860504192</id>
      <parentid>860406881</parentid>
      <timestamp>2018-09-21T03:13:54Z</timestamp>
      <contributor>
        <username>Mathbot</username>
        <id>234358</id>
      </contributor>
      <comment>Daily update. See [[User:Mathbot/Changes to mathlists]] for changes.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="813">__NOTOC__
{{MathTopicTOC}}

== Xen ==

* [[Xenagoras (geometer)|Xenagoras]] (Ancient Greece, ?–?)
* [[Xenocrates]] (Ancient Greece, 390s BC–310s BC)
* [[Daoxing Xia|Xia, Daoxing]] (China, born 1930)
* [[Zhihong Xia|Xia, Zhihong]] (China, born 1962)
* [[Jia Xian|Xian, Jia]] (Medieval China, ?–?)
* [[Wang Xianghao|Xianghao, Wang]] (China, 1915–1993)
* [[Wang Xiaotong|Xiaotong, Wang]] (Medieval China, ?–640)
* [[Wang Xiaoyun|Xiaoyun, Wang]] (?, born 1966)
* [[Leonardo Ximenes|Ximenes, Leonardo]] (Italy, 1716–1786)
* [[Zhouping Xin|Xin, Zhouping]] (China, ?–?)
* [[Yi Xing|Xing, Yi]] (Medieval China, 683–727)
* [[Zhu Xiping|Xiping, Zhu]] (China, born 1962)
* [[Chenyang Xu|Xu, Chenyang]] (China, ?–?)
* [[Jinchao Xu|Xu, Jinchao]] (USA/China, born 1961)

[[Category:Mathematics-related lists]]</text>
      <sha1>7bqrl04ekbr1qf5g2mrh9de2ntywkge</sha1>
    </revision>
  </page>
  <page>
    <title>List of polygons</title>
    <ns>0</ns>
    <id>39728316</id>
    <revision>
      <id>871054731</id>
      <parentid>871054708</parentid>
      <timestamp>2018-11-28T17:10:52Z</timestamp>
      <contributor>
        <username>CLCStudent</username>
        <id>26398660</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/82.29.247.86|82.29.247.86]] ([[User talk:82.29.247.86|talk]]) to last version by CLCStudent</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15517">{{Anchor|}}[[File:Regular polygon 5 annotated.svg|thumb|A pentagon is a five sided polygon. A regular pentagon has 5 equal edges and 5 equal angles.]]
In [[geometry]], a '''polygon''' {{IPAc-en|ˈ|p|ɒ|l|ɪ|ɡ|ɒ|n}} is traditionally a [[plane (mathematics)|plane]] [[Shape|figure]] that is bounded by a finite chain of straight [[line segment]]s closing in a loop to form a [[Polygonal chain|closed chain]]. These segments are called its ''edges'' or ''sides'', and the points where two edges meet are the polygon's ''[[Vertex (geometry)|vertices]]'' (singular: vertex) or ''corners''.

The word [[polygon]] comes from [[Late Latin]] ''polygōnum'' (a noun), from [[Greek language|Greek]] πολύγωνον (''polygōnon/polugōnon''), noun use of neuter of πολύγωνος (''polygōnos/polugōnos'', the masculine adjective), meaning "many-angled". Individual polygons are named (and sometimes classified) according to the number of sides, combining a [[Greek language|Greek]]-derived [[numerical prefix]] with the suffix ''-gon'', e.g. ''[[pentagon]]'', ''[[dodecagon]]''. The [[triangle]], [[quadrilateral]] and [[nonagon]] are exceptions, although the regular forms ''trigon'', ''tetragon'', and ''enneagon'' are sometimes encountered as well.

== Greek numbers==
Polygons are primarily named by prefixes from Greek numbers.
{| class=wikitable
|+ English-Greek numbers&lt;ref&gt;{{cite web |url=http://hull-awe.org.uk/index.php?title=Greek_and_Latin_words_for_numbers|title=Greek and Latin words for numbers |website=AWE|publisher=Hull University}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Lozac'h|first1=N.|title=Extension of Rules A-1.1 and A-2.5 Concerning Numerical Terms used in Organic Chemical Nomenclature|url=https://www.iupac.org/publications/pac/pdf/1983/pdf/5509x1463.pdf|website=iupac.org|publisher=International Union of Pure and Applied Chemistry|date=1983}}&lt;/ref&gt;
!English cardinal number||English ordinal number||Greek cardinal number||Greek ordinal number
|-
||one||first||heis (fem. mia, neut. '''hen''')||protos
|-
||two||second||duo||deuteros
|-
||three||third||treis||tritos
|-
||four||fourth||tettares||tetartos
|-
||five||fifth||'''pente'''||pemptos
|-
||six||sixth||'''hex'''||hektos
|-
||seven||seventh||'''hepta'''||hebdomos
|-
||eight||eighth||'''okto'''||ogdoös
|-
||nine||ninth||'''ennea'''||enatos
|-
||ten||tenth||'''deka'''||dekatos
|-
||eleven||eleventh||'''hendeka'''||hendekatos
|-
||twelve||twelfth||'''dodeka'''||dodekatos
|-
||thirteen||thirteenth||'''triskaideka'''||dekatotritos
|-
||fourteen||fourteenth||'''tettareskaideka'''||dekatotetartos
|-
||fifteen||fifteenth||'''pentekaideka'''||dekatopemptos
|-
||sixteen||sixteenth||'''hekkaideka'''||dekatohektos
|-
||seventeen||seventeenth||'''heptakaideka'''||dekatohebdomos
|-
||eighteen||eighteenth||'''oktokaideka'''||dekatoögdoös
|-
||nineteen||nineteenth||'''enneakaideka'''||dekatoënatos
|-
||twenty||twentieth||'''eikosi'''||eikostos
|-
||twenty-one||twenty-first||heiskaieikosi||eikostoprotos
|-
||twenty-two||twenty-second||duokaieikosi||eikostodeuteros
|-
||twenty-three||twenty-third||triskaieikosi||eikostotritos
|-
||twenty-four||twenty-fourth||tetterakaieikosi||eikostotetartos
|-
||twenty-five||twenty-fifth||pentekaieikosi||eikostopemptos
|-
||twenty-six||twenty-sixth||hekkaieikosi||eikostohektos
|-
||twenty-seven||twenty-seventh||heptakaieikosi||eikostohebdomos
|-
||twenty-eight||twenty-eighth||oktokaieikosi||eikostoögdoös
|-
||twenty-nine||twenty-ninth||enneakaieikosi||eikostoënatos
|-
||thirty||thirtieth||'''triakonta'''||triakostos
|-
||thirty-one||thirty-first||heiskaitriakonta||triakostoprotos
|-
||forty||fortieth||'''tessarakonta'''||tessarakostos
|-
||fifty||fiftieth||'''pentekonta'''||pentekostos
|-
||sixty||sixtieth||'''hexekonta'''||hexekostos
|-
||seventy||seventieth||'''hebdomekonta'''||hebdomekostos
|-
||eighty||eightieth||'''ogdoëkonta'''||ogdoëkostos
|-
||ninety||ninetieth||'''enenekonta'''||enenekostos
|-
||hundred||hundredth||'''hekaton'''||hekatostos
|-
||hundred and ten||hundred and tenth||dekakaihekaton||hekatostodekatos
|-
||hundred and twenty||hundred and twentieth||ikosikaihekaton||hekatostoikostos
|-
||two hundred||two hundredth||'''diakosioi'''||diakosiostos
|-
||three hundred||three hundredth||'''triakosioi'''||triakosiostos
|-
||four hundred||four hundredth||'''tetrakosioi'''||tetrakosiostos
|-
||five hundred||five hundredth||'''pentakosioi'''||pentakosiostos
|-
||six hundred||six hundredth||'''hexakosioi'''||hexakosiostos
|-
||seven hundred||seven hundredth||'''heptakosioi'''||heptakosiostos
|-
||eight hundred||eight hundredth||'''oktakosioi'''||oktakosiostos
|-
||nine hundred||nine hundredth||'''enneakosioi'''||enneakosiostos
|-
||thousand||thousandth||'''chilioi'''||chiliostos
|-
||two thousand||two thousandth||'''dischilioi'''||dischiliostos
|-
||three thousand||three thousandth||'''trischilioi'''||trischiliostos
|-
||four thousand||four thousandth||'''tetrakischilioi'''||tetrakischiliostos
|-
||five thousand||five thousandth||'''pentakischilioi'''||pentakischiliostos
|-
||six thousand||six thousandth||'''hexakischilioi'''||hexakischiliostos
|-
||seven thousand||seven thousandth||'''heptakischilioi'''||heptakischiliostos
|-
||eight thousand||eight thousandth||'''oktakischilioi'''||oktakischiliostos
|-
||nine thousand||nine thousandth||'''enneakischilioi'''||enneakischiliostos
|-
||ten thousand||ten thousandth||'''myrioi'''||myriastos
|-
||twenty thousand||twenty thousandth||'''dismyrioi'''||dismyriastos
|-
||thirty thousand||thirty thousandth||'''trismyrioi'''||trismyriastos
|-
||forty thousand||forty thousandth||'''tetrakismyrioi'''||tetrakismyriastos
|-
||fifty thousand||fifty thousandth||'''pentakismyrioi'''||pentakismyriastos
|-
||sixty thousand||sixty thousandth||'''hexakismyrioi'''||hexakismyriastos
|-
||seventy thousand||seventy thousandth||'''heptakismyrioi'''||heptakismyriastos
|-
||eighty thousand||eighty thousandth||'''oktakismyrioi'''||oktakismyriastos
|-
||ninety thousand||ninety thousandth||'''enneakismyrioi'''||enneakismyriastos
|-
||hundred thousand||hundred thousandth||'''dekakismyrioi'''||dekakismyriastos
|-
||two hundred thousand||two hundred thousandth||'''ikosakismyrioi'''||ikosakismyriastos
|-
||three hundred thousand||three hundred thousandth||'''triakontakismyrioi'''||triakontakismyriastos
|-
||million||millionth||'''hekatontakismyrioi'''||hekatontakismyriastos
|-
||two million||two millionth||'''diakosakismyrioi'''||diakosakismyriastos
|-
||three million||three millionth||'''triakosakismyrioi'''||triakosakismyriastos
|-
||ten million||ten millionth||'''chiliakismyrioi'''||chiliakismyriastos
|-
||hundred million||hundred millionth||'''myriakismyrioi'''||myriakismyriastos
|}

== Systematic polygon names ==

To construct the name of a polygon with more than 20 and fewer than 100 edges, combine the prefixes as follows. The "kai" connector is not included by some authors.
{|class="wikitable" style="vertical-align:center;"
|- style="text-align:center;"
!colspan="2" rowspan="2" | Tens
!''and''
!colspan="2" | Ones
!final suffix
|-
!rowspan="9" | -kai-
|1
| |-hena-
!rowspan=9 | -gon
|-
|20 || icosi- (icosa- when alone) || 2 || -di-
|-
|30 || triaconta- || 3 || -tri-
|-
|40 || tetraconta-
|| 4 || -tetra-
|-
|50 || pentaconta- || 5 || -penta-

|-
|60 || hexaconta- || 6 || -hexa-
|-
|70 || heptaconta- || 7 || -hepta-
|-
|80 || octaconta- || 8 || -octa-
|-
|90 || enneaconta- || 9 || -ennea-
|}

Extending the system up to 999 is expressed with these prefixes.&lt;ref&gt;{{cite web |url=http://mathforum.org/dr.math/faq/faq.polygon.names.html |title=Naming Polygons and Polyhedra |website=The Math Forum |publisher=Drexel University}}&lt;/ref&gt;
{| class=wikitable
|+ Polygon names
!colspan=2|Ones||colspan=2|Tens||colspan=2|Twenties||colspan=2|Thirties+||colspan=2|Hundreds
|-
|||||10||deca-||20||icosa-||30||triaconta-||100||hecta-
|-
|1||hena-||11||hendeca-||21||icosi-hena-||31||triaconta-hena-||200||dihecta-
|-
|2||di-||12||dodeca-||22||icosi-di-||32||triaconta-di-||300||trihecta-
|-
|3||tri-||13|| triskaideca-||23||icosi-tri-||33||triaconta-tri-||400||tetrahecta-
|-
|4||tetra-||14||tetrakaideca-||24||icosi-tetra-||40||tetraconta-||500||pentahecta-
|-
|5||penta-||15||pentakaideca-||25||icosi-penta-||50||pentaconta-||600||hexahecta-
|-
|6||hexa-||16||hexakaideca-||26||icosi-hexa-||60||hexaconta-||700||heptahecta-
|-
|7||hepta-||17||heptakaideca-||27||icosi-hepta-||70||heptaconta-||800||octahecta-
|-
|8||octa-||18||octakaideca-||28||icosi-octa-||80||octaconta-||900||enneahecta-
|-
|9||ennea-||19||enneakaideca-||29||icosi-ennea-||90||enneaconta-|| ||
|}

== List of n-gons by Greek numerical prefixes ==
{| class=wikitable
|+ List of n-gon names &lt;ref&gt;{{cite web |url=http://mathforum.org/library/drmath/view/57666.html |title=Naming Polygons |website=The Math Forum|publisher=Drexel University}}&lt;/ref&gt;
!Sides
!colspan=4|Names
|-
|1||[[monogon]]||henagon
|-
|2||[[digon]]||
|-
|3||trigon|| [[triangle]]
|-
|4||tetragon|| [[quadrilateral]]
|-
|5||[[pentagon]]||
|-
|6||[[hexagon]]||
|-
|7||[[heptagon]]||[[septagon]]
|-
|8||[[octagon]]||
|-
|9||enneagon||[[nonagon]]
|-
!10||[[decagon]]||
|-
|11||[[hendecagon]]||undecagon
|-
|12||[[dodecagon]]||
|-
|13||trisdecagon||[[tridecagon]]
|-
|14||[[tetradecagon]]||
|-
|15||[[pentadecagon]]|| pentedecagon
|-
|16||[[hexadecagon]]|| hexdecagon
|-
|17||[[heptadecagon]]||
|-
|18||[[octadecagon]]||
|-
|19||[[enneadecagon]]||
|-
!20||[[icosagon]]||||
|-
|21||icosikaihenagon||icosihenagon||icosaisagon
|-
|22||icosikaidigon||[[icosidigon]]||icosadigon
|-
|23||icosikaitrigon||icositrigon||icosatrigon
|-
|24||icosikaitetragon||[[icositetragon]]||icosatetragon
|-
|25||icosikaipentagon||icosipentagon||icosapentagon
|-
|26||icosikaihexagon||[[icosihexagon]]||icosahexagon
|-
|27||icosikaiheptagon||icosiheptagon||icosaheptagon
|-
|28||icosikaioctagon||[[icosioctagon]]||icosaoctagon
|-
|29||icosikaienneagon||icosienneagon||icosaenneagon
|-
!30||[[triacontagon]]||||||
|-
|31||triacontakaihenagon||triacontahenagon||tricontahenagon||tricontaisagon
|-
|32||triacontakaidigon||[[triacontadigon]]||tricontadigon
|-
|33||triacontakaitrigon||triacontatrigon||tricontatrigon
|-
|34||triacontakaitetragon||[[triacontatetragon]]||tricontatetragon
|-
|35||triacontakaipentagon||triacontapentagon||tricontapentagon
|-
|36||triacontakaihexagon||triacontahexagon||tricontahexagon
|-
|37||triacontakaiheptagon||triacontaheptagon||tricontaheptagon
|-
|38||triacontakaioctagon||triacontaoctagon||tricontaoctagon
|-
|39||triacontakaienneagon||triacontaenneagon||tricontaenneagon
|-
!40||[[tetracontagon]]||||tessaracontagon
|-
|41||tetracontakaihenagon||tetracontahenagon
|-
|42||tetracontakaidigon||[[tetracontadigon]]
|-
|43||tetracontakaitrigon||tetracontatrigon
|-
|44||tetracontakaitetragon||tetracontatetragon
|-
|45||tetracontakaipentagon||tetracontapentagon
|-
|46||tetracontakaihexagon||tetracontahexagon
|-
|47||tetracontakaiheptagon||tetracontaheptagon
|-
|48||tetracontakaioctagon||[[tetracontaoctagon]]
|-
|49||tetracontakaienneagon||tetracontaenneagon
|-
!50||[[pentacontagon]]||||pentecontagon
|-
|51||pentacontakaihenagon||pentacontahenagon||pentecontahenagon
|-
|52||pentacontakaidigon||pentacontadigon||pentecontadigon
|-
|53||pentacontakaitrigon||pentacontatrigon||pentecontatrigon
|-
|54||pentacontakaitetragon||pentacontatetragon||pentecontatetragon
|-
|55||pentacontakaipentagon||pentacontapentagon||pentecontapentagon
|-
|56||pentacontakaihexagon||pentacontahexagon||pentecontahexagon
|-
|57||pentacontakaiheptagon||pentacontaheptagon||pentecontaheptagon
|-
|58||pentacontakaioctagon||pentacontaoctagon||pentecontaoctagon
|-
|59||pentacontakaienneagon||pentacontaenneagon||pentecontaenneagon
|-
!60||[[hexacontagon]]||||hexecontagon
|-
|61||hexacontakaihenagon||hexacontahenagon||hexecontahenagon
|-
|62||hexacontakaidigon||hexacontadigon||hexecontadigon
|-
|63||hexacontakaitrigon||hexacontatrigon||hexecontatrigon
|-
|64||hexacontakaitetragon||[[hexacontatetragon]]||hexecontatetragon
|-
|65||hexacontakaipentagon||hexacontapentagon||hexecontapentagon
|-
|66||hexacontakaihexagon||hexacontahexagon||hexecontahexagon
|-
|67||hexacontakaiheptagon||hexacontaheptagon||hexecontaheptagon
|-
|68||hexacontakaioctagon||hexacontaoctagon||hexecontaoctagon
|-
|69||hexacontakaienneagon||hexacontaenneagon||hexecontaenneagon
|-
!70||[[heptacontagon]]||||hebdomecontagon
|-
|71||heptacontakaihenagon||heptacontahenagon||hebdomecontahenagon
|-
|72||heptacontakaidigon||heptacontadigon||hebdomecontadigon
|-
|73||heptacontakaitrigon||heptacontatrigon||hebdomecontatrigon
|-
|74||heptacontakaitetragon||heptacontatetragon||hebdomecontatetragon
|-
|75||heptacontakaipentagon||heptacontapentagon||hebdomecontapentagon
|-
|76||heptacontakaihexagon||heptacontahexagon||hebdomecontahexagon
|-
|77||heptacontakaiheptagon||heptacontaheptagon||hebdomecontaheptagon
|-
|78||heptacontakaioctagon||heptacontaoctagon||hebdomecontaoctagon
|-
|79||heptacontakaienneagon||heptacontaenneagon||hebdomecontaenneagon
|-
!80||[[octacontagon]]||||ogdoecontagon
|-
|81||octacontakaihenagon||octacontahenagon||ogdoecontahenagon
|-
|82||octacontakaidigon||octacontadigon||ogdoecontadigon
|-
|83||octacontakaitrigon||octacontatrigon||ogdoecontatrigon
|-
|84||octacontakaitetragon||octacontatetragon||ogdoecontatetragon
|-
|85||octacontakaipentagon||octacontapentagon||ogdoecontapentagon
|-
|86||octacontakaihexagon||octacontahexagon||ogdoecontahexagon
|-
|87||octacontakaiheptagon||octacontaheptagon||ogdoecontaheptagon
|-
|88||octacontakaioctagon||octacontaoctagon||ogdoecontaoctagon
|-
|89||octacontakaienneagon||octacontaenneagon||ogdoecontaenneagon
|-
!90||[[enneacontagon]]||||enenecontagon
|-
|91||enneacontakaihenagon||enneacontahenagon||enenecontahenagon
|-
|92||enneacontakaidigon||enneacontadigon||enenecontadigon
|-
|93||enneacontakaitrigon||enneacontatrigon||enenecontatrigon
|-
|94||enneacontakaitetragon||enneacontatetragon||enenecontatetragon
|-
|95||enneacontakaipentagon||enneacontapentagon||enenecontapentagon
|-
|96||enneacontakaihexagon||[[enneacontahexagon]]||enenecontahexagon
|-
|97||enneacontakaiheptagon||enneacontaheptagon||enenecontaheptagon
|-
|98||enneacontakaioctagon||enneacontaoctagon||enenecontaoctagon
|-
|99||enneacontakaienneagon||enneacontaenneagon||enenecontaenneagon
|-
!100||[[hectogon]]|| hecatontagon||hecatogon
|-
|200||dihectagon|| ||diacosigon
|-
|300||trihectagon|| ||triacosigon
|-
|400||tetrahectagon|| ||tetracosigon
|-
|500||pentahectagon|| ||pentacosigon
|-
|600||hexahectagon|| ||hexacosigon
|-
|700||heptahectagon|| ||heptacosigon
|-
|800||octahectagon|| ||octacosigon
|-
|900||enneahectagon|| ||enacosigon
|-
!{{val|1000}}||[[chiliagon]]
|-
|{{val|2000}}||dischiliagon
|-
|{{val|3000}}||trischiliagon
|-
|{{val|4000}}||tetrakischiliagon
|-
|{{val|5000}}||pentakischiliagon
|-
|{{val|6000}}||hexakischiliagon
|-
|{{val|7000}}||heptakischiliagon
|-
|{{val|8000}}||octakischiliagon
|-
|{{val|9000}}||enakischiliagon
|-
!{{val|10000}}||[[myriagon]]
|-
!{{val|1000000}}||[[megagon]]
|-
!∞||[[apeirogon]]
|}

== See also ==
* [[Platonic solid]]
* [[Dice]]

== References==
{{reflist}}
* [http://faculty.kutztown.edu/schaeffe/Tutorials/General/Polygons.html NAMING POLYGONS]
* Benjamin Franklin Finkel, [https://books.google.com/books?id=ugBDAAAAIAAJ&amp;lpg=PA194&amp;ots=eu5YMWxvXz&amp;dq=pentecontagon&amp;pg=PA194#v=onepage&amp;q=pentecontagon&amp;f=false A Mathematical Solution Book Containing Systematic Solutions to Many of the Most Difficult Problems], 1888

{{Polygons}}

[[Category:Polygons| ]]
[[Category:Mathematics-related lists|Polygons]]</text>
      <sha1>2oeux18n2sne2x6pd0c550kuctpcg40</sha1>
    </revision>
  </page>
  <page>
    <title>List of shapes with known packing constant</title>
    <ns>0</ns>
    <id>43530822</id>
    <revision>
      <id>841536784</id>
      <parentid>825203356</parentid>
      <timestamp>2018-05-16T12:54:46Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5303">The [[packing constant]] of a geometric body is the largest average density achieved by packing arrangements of [[Congruence (geometry)|congruent]] copies of the body. For most bodies the value of the packing constant is unknown.&lt;ref name="KB10"&gt;{{cite arXiv |first=András | last=Bezdek | first2=Włodzimierz | last2=Kuperberg |eprint=1008.2398v1 |title=Dense packing of space with various convex solids |class=math.MG |year=2010}}&lt;/ref&gt; The following is a list of bodies in Euclidean spaces whose packing constant is known.&lt;ref name="KB10" /&gt; [[László Fejes Tóth|Fejes Tóth]] proved that in the plane, a [[point reflection|point symmetric]] body has a packing constant that is equal to its [[translation (geometry)|translative]] packing constant and its [[Bravais lattice|lattice]] packing constant.&lt;ref name="LFT"&gt;{{cite journal | last=Fejes Tóth | first=László | title=Some packing and covering theorems | journal=Acta Sci. Math. Szeged | volume=12 | year=1950}}&lt;/ref&gt; Therefore, any such body for which the lattice packing constant was previously known, such as any [[ellipse]], consequently has a known packing constant. In addition to these bodies, the packing constants of [[n-sphere|hyperspheres]] in 8 and 24 dimensions are almost exactly known.&lt;ref name="CohnKumar"&gt;{{cite journal | title=Optimality and uniqueness of the Leech lattice among lattices | last=Cohn | first=Henry | last2=Kumar | first2=Abhinav | pages=1003–1050 | volume=170 | year=2009 | issue=3 | journal = Annals of Mathematics | doi=10.4007/annals.2009.170.1003| arxiv=math.MG/0403263 }}&lt;/ref&gt;

{| class="wikitable" style="width:100%;border:0px;text-align:center;"
|-
! Image !! Description !! Dimension !! [[Packing constant]] || Comments
|-
| [[File:Rhombic dodecahedra.png|200px | center]] || All shapes that [[tessellation|tile]] space  || all || 1 || By definition
|-
| [[File:Circle packing (hexagonal).svg|200px | center]] || [[Circle packing|Circle]], [[Ellipse]] || 2 || {{math|''&amp;pi;''/{{sqrt|12}} ≈ 0.906900}} || Proof attributed to [[Axel Thue|Thue]]&lt;ref name=Thue&gt;{{cite arXiv |last1=Chang|first1=Hai-Chau |last2=Wang|first2=Lih-Chung |authorlink= |eprint=1009.4322v1 |title=A Simple Proof of Thue's Theorem on Circle Packing |class=math.MG |year=2010}}&lt;/ref&gt;
|-
| [[File:Smoothed Octagon Packed.svg|200px | center]] || [[Smoothed octagon]] || 2 || &lt;math&gt;\eta_{so} = \frac{ 8-4\sqrt{2}-\ln{2} }{2\sqrt{2}-1} \approx 0.902414 \, .&lt;/math&gt; ||  [[Karl Reinhardt (mathematician)|Reinhardt]]&lt;ref name="Reinhardt"&gt;{{cite journal | last=Reinhardt | first=Karl | title=Über die dichteste gitterförmige Lagerung kongruente Bereiche in der Ebene und eine besondere Art konvexer Kurven | journal=Abh. Math. Sem. Univ. Hamburg | volume=10 | pages=216–230 | year=1934 | doi=10.1007/bf02940676}}&lt;/ref&gt;
|-
| [[File:Regular decagon.svg|100px |center]] || All 2-fold symmetric convex polygons || 2 || || Linear-time (in number of vertices) algorithm given by [[David Mount|Mount]] and [[Ruth Silverman]]&lt;ref name="MountSilverman"&gt;{{cite journal | title=Packing and covering the plane with translates of a convex polygon | last=Mount | last2=Silverman | first=David M. | first2 = Ruth | doi=10.1016/0196-6774(90)90010-C | journal=Journal of Algorithms | volume=11 | issue=4 | year=1990 | pages=564–580}}&lt;/ref&gt;
|-
| [[File:FCC closed packing tetrahedron (20).jpg|200px |center]] || Sphere || 3 || {{math|''&amp;pi;''/{{sqrt|18}} ≈ 0.7404805}}   || See [[Kepler conjecture]] 
|-
| [[File:Red cylinder.svg|200px |center]] || Bi-infinite cylinder || 3 || {{math|''&amp;pi;''/{{sqrt|12}} ≈ 0.906900}} || [[András Bezdek|Bezdek]] and [[Włodzimierz Kuperberg|Kuperberg]]&lt;ref name="KB90"&gt;{{cite journal | first=András | last=Bezdek | first2=Włodzimierz | last2=Kuperberg | title=Maximum density space packing with congruent circular cylinders of infinite length | journal=Mathematika | volume=37 | year=1990 | pages=74–80 | doi=10.1112/s0025579300012808}}&lt;/ref&gt;
|-
| [[File:Small rhombicuboctahedron.png|100px|center]] [[File:Rhombic enneacontahedron.png|100px|center]] || All shapes contained in a [[rhombic dodecahedron]] whose inscribed sphere is contained in the shape || 3 || Fraction of the volume of the [[rhombic dodecahedron]] filled by the shape || Corollary of [[Kepler conjecture]]. Examples pictured: [[rhombicuboctahedron]] and [[rhombic enneacontahedron]].
|-
| || Hypersphere || 8 || &lt;math&gt;\frac{(\frac {\pi}{2})^4}{4!} \approx 0.2536695&lt;/math&gt;   || See [[Sphere packing#Hypersphere packing|Hypersphere packing]]&lt;ref name="quanta"&gt;{{citation|last1=Klarreich|first1=Erica|authorlink1=Erica Klarreich|title=Sphere Packing Solved in Higher Dimensions|url=https://www.quantamagazine.org/20160330-sphere-packing-solved-in-higher-dimensions|magazine=Quanta Magazine|date=March 30, 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv| first1 = Maryna | last1 = Viazovska |authorlink1 = Maryna Viazovska| year = 2016 | title = The sphere packing problem in dimension 8 | eprint = 1603.04246 }}&lt;/ref&gt;
|-
| || Hypersphere || 24 ||  &lt;math&gt;\frac{(\frac {\pi}{2})^{12}}{12!} \approx 0.000000471087&lt;/math&gt;  || See [[Sphere packing#Hypersphere packing|Hypersphere packing]]
|}

==References==
{{Reflist}}

[[Category:Packing problems]]
[[Category:Discrete geometry]]
[[Category:Mathematics-related lists|Shapes with known packing constant]]</text>
      <sha1>c6bj6qn5t9bm9l36ob09knkl06efcay</sha1>
    </revision>
  </page>
  <page>
    <title>Mamikon Mnatsakanian</title>
    <ns>0</ns>
    <id>29819533</id>
    <revision>
      <id>820956138</id>
      <parentid>820955227</parentid>
      <timestamp>2018-01-17T16:07:48Z</timestamp>
      <contributor>
        <username>E-Soter</username>
        <id>10113497</id>
      </contributor>
      <minor/>
      <comment>/* See also */ [[Visual calculus]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1780">'''Mamikon A. Mnatsakanian''' ({{lang-hy|Մամիկոն Մնացականյան}}) is Project Associate at [[Project Mathematics!]] at the [[California Institute of Technology]].  

He received a Ph.D. in physics in 1969 from [[Yerevan State University]], where he became professor of astrophysics. As an undergraduate he specialized in the development of geometric methods for solving calculus problems by a visual approach that makes no use of formulas, which he later developed into his system of [[visual calculus]].

In 2010 he was nominated by Caltech for the [[Viktor Hambardzumyan#Ambartsumians International Prize|Ambartsumians International Prize]], awarded annually by the [[President of Armenia]], for his contributions in the field of [[theoretical astrophysics]].&lt;ref&gt;[http://billsexcellentblog.blogspot.com/2010/07/visual-calculus-and-theoretical.html Visual Calculus and Theoretical Astrophysics]&lt;/ref&gt;

In 1959 he discovered a new proof of the [[Pythagorean theorem]].&lt;ref&gt;{{Cite web|url=http://demonstrations.wolfram.com/MamikonsProofOfThePythagoreanTheorem/|title=Mamikon's Proof of the Pythagorean Theorem|publisher=[[Wolfram Demonstrations Project]]}}&lt;/ref&gt;

==See also==
* [[Generalized conic]]
* [[Visual calculus]]

==References==
{{reflist}}

==External links==
*http://www.mamikon.com/
*http://www.its.caltech.edu/~mamikon/calculus.html (Visual Calculus)
{{authority control}}
{{DEFAULTSORT:Mnatsakanian, Mamikon}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:California Institute of Technology faculty]]
[[Category:Armenian mathematicians]]
[[Category:Yerevan State University alumni]]
[[Category:Armenian expatriates in the United States]]
[[Category:Yerevan State University faculty]]

{{mathematician-stub}}</text>
      <sha1>iq399n6h08fivhi86jfl4q5ee7ztx26</sha1>
    </revision>
  </page>
  <page>
    <title>Mapping spectrum</title>
    <ns>0</ns>
    <id>46797936</id>
    <revision>
      <id>664603483</id>
      <parentid>664603415</parentid>
      <timestamp>2015-05-29T19:28:41Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <comment>a link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="424">In [[algebraic topology]], the '''mapping spectrum''' &lt;math&gt;F(X, Y)&lt;/math&gt; of [[spectrum (topology)|spectra]] ''X'', ''Y'' is characterized by
:&lt;math&gt;[X \wedge Y, Z] = [X, F(Y, Z)].&lt;/math&gt;&lt;ref&gt;{{cite web|url=http://mathoverflow.net/questions/200422/homology-of-a-mapping-spectrum|title=homology of a mapping spectrum|work=MathOverflow}}&lt;/ref&gt;

== References ==
{{Reflist}}

{{topology-stub}}

[[Category:Algebraic topology]]</text>
      <sha1>g2ipe6ifq03p6tt8g138oo0hdk1yde7</sha1>
    </revision>
  </page>
  <page>
    <title>Max-dominated strategy</title>
    <ns>0</ns>
    <id>26015807</id>
    <revision>
      <id>868980792</id>
      <parentid>810596714</parentid>
      <timestamp>2018-11-15T17:18:50Z</timestamp>
      <contributor>
        <username>Atlantic306</username>
        <id>26386571</id>
      </contributor>
      <comment>ced</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7343">In [[game theory]] a '''max-dominated strategy''' is a [[strategy]] which is not a [[best response]] to any [[strategy profile]] of the other players. This is an extension to the notion of [[dominated strategies|strictly dominated strategies]], which are max-dominated as well.

==Definition==
===Max-dominated strategies===
A strategy &lt;math&gt;s_i\in S_i&lt;/math&gt; of player &lt;math&gt;i&lt;/math&gt; is ''max-dominated'' if for every strategy profile of the other players
&lt;math&gt;s_{-i}\in S_{-i}&lt;/math&gt; there is a strategy &lt;math&gt;s^\prime_i\in S_i&lt;/math&gt; such that &lt;math&gt; u_i(s^\prime_i,s_{-i})&gt; u_i(s_i,s_{-i})&lt;/math&gt;. This definition means that &lt;math&gt;s_i&lt;/math&gt; is not a [[best response]] to any [[strategy profile]] &lt;math&gt;s_{-i}&lt;/math&gt;, since for every such strategy profile there is another strategy &lt;math&gt;s^\prime_i&lt;/math&gt; which gives higher utility than &lt;math&gt;s_i&lt;/math&gt; for player &lt;math&gt;i&lt;/math&gt;.

It is easy to see that if a strategy &lt;math&gt;s_i\in S_i&lt;/math&gt; is '''[[dominated strategies|strictly dominated]]''' by strategy &lt;math&gt;s^\prime_i \in S_i&lt;/math&gt; then it is also '''max-dominated''', since for every strategy profile of the other players &lt;math&gt;s_{-i}\in S_{-i}&lt;/math&gt; we will pick &lt;math&gt;s^\prime_i&lt;/math&gt; to be the strategy for which &lt;math&gt; u_i(s^\prime_i,s_{-i})&gt; u_i(s_i,s_{-i})&lt;/math&gt;.

It is also notable that even if &lt;math&gt;s_i&lt;/math&gt; is strictly dominated by a mixed strategy it is also '''max-dominated'''.

===Weakly max-dominated strateges===
A strategy &lt;math&gt;s_i\in S_i&lt;/math&gt; of player &lt;math&gt;i&lt;/math&gt; is '''weakly max-dominated''' if for every strategy profile of the other players &lt;math&gt;s_{-i}\in S_{-i}&lt;/math&gt; there is a strategy &lt;math&gt;s^\prime_i\in S_i&lt;/math&gt; such that &lt;math&gt; u_i(s^\prime_i,s_{-i}) \geq u_i(s_i,s_{-i})&lt;/math&gt;. This definition means that &lt;math&gt;s_i&lt;/math&gt; is either not a [[best response]] or not the only [[best response]] to any [[strategy profile]] &lt;math&gt;s_{-i}&lt;/math&gt;, since for every such strategy profile there is another strategy &lt;math&gt;s^\prime_i&lt;/math&gt; which gives at least the same utility as &lt;math&gt;s_i&lt;/math&gt; for player &lt;math&gt;i&lt;/math&gt;.

It is easy to see that if a strategy &lt;math&gt;s_i\in S_i&lt;/math&gt; is '''[[dominated strategies|weakly dominated]]''' by strategy &lt;math&gt;s^\prime_i \in S_i&lt;/math&gt; then it is also '''weakly max-dominated''', since for every strategy profile of the other players &lt;math&gt;s_{-i}\in S_{-i}&lt;/math&gt; we will pick &lt;math&gt;s^\prime_i&lt;/math&gt; to be the strategy for which &lt;math&gt; u_i(s^\prime_i,s_{-i})\geq u_i(s_i,s_{-i})&lt;/math&gt;.

It is also notable that even if &lt;math&gt;s_i&lt;/math&gt; is weakly dominated by a mixed strategy it is also '''weakly max-dominated'''.

==Max-solvable games==
===Definition===
A game &lt;math&gt;G&lt;/math&gt; is said to be '''max-solvable''' if by [[dominance (game theory)#Iterated elimination of dominated strategies (IEDS)|iterated elimination of max-dominated strategies]] only one strategy profile is left at the end.

More formally we say that &lt;math&gt;G&lt;/math&gt; is max-solvable if there exists a sequence of games &lt;math&gt;G_0, ..., G_r&lt;/math&gt; such that:
* &lt;math&gt;G_0 = G&lt;/math&gt;
* &lt;math&gt;G_{k+1}&lt;/math&gt; is obtained by removing a single max-dominated strategy from the strategy space of a single player in &lt;math&gt;G_k&lt;/math&gt;.
* There is only one strategy profile left in &lt;math&gt;G_r&lt;/math&gt;.

Obviously every max-solvable game has a unique pure [[Nash equilibrium]] which is the strategy profile left in &lt;math&gt;G_r&lt;/math&gt;.

As in the previous part one can define respectively the notion of '''weakly max-solvable games''', which are games for which a game with a single strategy profile can be reached by eliminating '''weakly max-dominated strategies'''. The main difference would be that weakly max-dominated games may have more than one pure [[Nash equilibrium]], and that the order of elimination might result in different Nash equilibria.

===Example===
{{Payoff matrix | Name = Fig. 1: [[payoff matrix]] of the [[prisoner's dilemma]]
                | 2L = Cooperate  | 2R = Defect     |
1U = Cooperate  | UL = -1,&amp;nbsp;-1| UR = -5,&amp;nbsp;0 |
1D = Defect     | DL = 0,&amp;nbsp;-5 | DR = -3,&amp;nbsp;-3}}

The prisoner's dilemma is an example of a max-solvable game (as it is also dominance solvable). The strategy cooperate is max-dominated by the strategy defect for both players, since playing defect always gives the player a higher utility, no matter what the other player plays. To see this note that if the row player plays cooperate then the column player would prefer playing defect and go free than playing cooperate and serving one year in jail. If the row player plays defect then the column player would prefer playing defect and serve three years in jail rather than playing cooperate and serving five years in jail.

===Max-solvable games and best-reply dynamics===
In any max-solvable game, best-reply dynamics ultimately leads to the unique pure [[Nash equilibrium]] of the game. In order to see this, all we need to do is notice that if &lt;math&gt;s_1, s_2, s_3, ..., s_k&lt;/math&gt; is an elimination sequence of the game (meaning that first &lt;math&gt;s_1&lt;/math&gt; is eliminated from the strategy space of some player since it is max-dominated, then &lt;math&gt;s_2&lt;/math&gt; is eliminated, and so on), then in the best-response dynamics &lt;math&gt;s_1&lt;/math&gt; will be never played by its player after one iteration of best responses, &lt;math&gt;s_2&lt;/math&gt; will never be played by its player after two iterations of best responses and so on. The reason for this is that &lt;math&gt;s_1&lt;/math&gt; is not a best response to any strategy profile of the other players &lt;math&gt;s_{-i}&lt;/math&gt; so after one iteration of best responses its player must have chosen a different strategy. Since we understand that we will never return to &lt;math&gt;s_1&lt;/math&gt; in any iteration of the best responses, we can treat the game after one iteration of best responses as if &lt;math&gt;s_1&lt;/math&gt; has been eliminated from the game, and complete the proof by induction.

{| align=right border="1" cellpadding="4" cellspacing="0" style="margin: 1em 1em 1em 1em; background: #f9f9f9; border: 1px #aaa solid; border-collapse: collapse; font-size: 95%;"
|+ align=bottom |''A weakly max-solvable game''
|-
|align=center|1, 1
|align=center|0, 0
|-
|align=center|1, 0
|align=center|0, 1
|-
|align=center|0, 1
|align=center|1, 0
|}

It may come by surprise then that '''weakly max-solvable games''' do not necessarily converge to a pure [[Nash equilibrium]] when using the [[best response#Best response dynamics|best-reply dynamics]], as can be seen in the game on the right. If the game starts of the bottom left cell of the matrix, then the following best replay dynamics is possible: the row player moves one row up to the center row, the column player moves to the right column, the row player moves back to the bottom row, the column player moves back to the left column and so on. This obviously never converges to the unique pure Nash equilibrium of the game (which is the upper left cell in the [[payoff matrix]]).

==See also==
[[Dominance (game theory)]]

==External links and references==
* {{Citation | last1=Nisan | first1=Noam | last2=Schapira | first2=Michael | last3=Zohar | first3 = Aviv | title=Asynchronus best reply dynamics | publisher=Springer-Verlag | url=http://www.springerlink.com | year=2009 | location=Berlin}}. Asynchronus best-reply dynamics. [http://www.springerlink.com/content/m32856j7685t4552/].

[[Category:Game theory]]</text>
      <sha1>kcy3pmq7b8k90s6c1n31j8pdija0ksp</sha1>
    </revision>
  </page>
  <page>
    <title>Maximum entropy thermodynamics</title>
    <ns>0</ns>
    <id>3015758</id>
    <revision>
      <id>867160839</id>
      <parentid>863459716</parentid>
      <timestamp>2018-11-04T01:44:39Z</timestamp>
      <contributor>
        <username>Gehenna1510</username>
        <id>34982813</id>
      </contributor>
      <minor/>
      <comment>CS1 error fixed + authors replaced with author list</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27235">In [[physics]], '''maximum entropy thermodynamics''' (colloquially, ''MaxEnt'' [[thermodynamics]]) views [[equilibrium thermodynamics]] and [[statistical mechanics]] as [[Inference#Inference and uncertainty|inference]] processes. More specifically, MaxEnt applies inference techniques rooted in [[Shannon information theory]], [[Bayesian probability]], and the [[principle of maximum entropy]]. These techniques are relevant to any situation requiring prediction from incomplete or insufficient data (e.g., [[image processing|image reconstruction]], [[signal processing]], [[spectral density estimation|spectral analysis]], and [[inverse problem]]s). MaxEnt thermodynamics began with two papers by [[Edwin Thompson Jaynes|Edwin T. Jaynes]] published in the 1957 ''Physical Review''.&lt;ref&gt;{{cite journal |author=Jaynes, E.T. |title=Information theory and statistical mechanics |journal=Physical Review |volume=106 |issue=4 |pages=620–630 |year=1957 |doi=10.1103/PhysRev.106.620 |url=http://bayes.wustl.edu/etj/articles/theory.1.pdf |format=PDF |bibcode=1957PhRv..106..620J}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Jaynes, E.T. |authormask=1 |title=Information theory and statistical mechanics II |journal=Physical Review |volume=108 |issue=2 |pages=171–190 |year=1957 |doi=10.1103/PhysRev.108.171 |url=http://bayes.wustl.edu/etj/articles/theory.2.pdf |format=PDF |bibcode=1957PhRv..108..171J}}&lt;/ref&gt;

== Maximum Shannon entropy ==
Central to the MaxEnt thesis is the [[principle of maximum entropy]]. It demands as given some partly specified model and some specified data related to the model. It selects a preferred probability distribution to represent the model. The given data state "testable information"&lt;ref&gt;Jaynes, E.T. (1968), p. 229.&lt;/ref&gt;&lt;ref&gt;Jaynes, E.T. (1979), pp. 30, 31, 40.&lt;/ref&gt; about the [[probability distribution]], for example particular [[Expected value|expectation]] values, but are not in themselves sufficient to uniquely determine it. The principle states that one should prefer the distribution which maximizes the [[Shannon entropy|Shannon information entropy]].

:&lt;math&gt;S_I = - \sum p_i \ln p_i&lt;/math&gt;

This is known as the [[Gibbs algorithm]], having been introduced by [[J. Willard Gibbs]] in 1878, to set up [[statistical ensemble]]s to predict the properties of thermodynamic systems at equilibrium. It is the cornerstone of the statistical mechanical analysis of the thermodynamic properties of equilibrium systems (see [[partition function (statistical mechanics)|partition function]]).

A direct connection is thus made between the equilibrium [[Entropy (classical thermodynamics)|thermodynamic entropy]] ''S''&lt;sub&gt;Th&lt;/sub&gt;, a [[state function]] of pressure, volume, temperature, etc., and the [[information entropy]] for the predicted distribution with maximum uncertainty conditioned only on the expectation values of those variables:

:&lt;math&gt;S_{Th}(P,V,T,...)_{(eqm)} = k_B \, S_I(P,V,T,...)&lt;/math&gt;

''k&lt;sub&gt;B&lt;/sub&gt;'', [[Boltzmann's constant]], has no fundamental physical significance here, but is necessary to retain consistency with the previous historical  definition of entropy by [[Clausius]] (1865) (see [[Boltzmann's constant]]).

However, the MaxEnt school argue that the MaxEnt approach is a general technique of statistical inference, with applications far beyond this. It can therefore also be used to predict a distribution for "trajectories" Γ "over a period of time" by maximising:

:&lt;math&gt;S_I = - \sum p_{\Gamma} \ln p_{\Gamma}&lt;/math&gt;

This "information entropy" does ''not'' necessarily have a simple correspondence with thermodynamic entropy. But it can be used to predict features of [[non-equilibrium thermodynamics|nonequilibrium thermodynamic]] systems as they evolve over time.

For non-equilibrium scenarios, in an approximation that assumes [[Non-equilibrium thermodynamics#Overview#Local Equilibrium thermodynamics|local thermodynamic equilibrium]], with the maximum entropy approach, the [[Onsager reciprocal relations]] and the [[Green-Kubo relations]] fall out directly. The approach also creates a theoretical framework for the study of some very special cases of far-from-equilibrium scenarios, making the derivation of the [[fluctuation theorem|entropy production fluctuation theorem]] straightforward. For non-equilibrium processes, as is so for macroscopic descriptions, a general definition of entropy for microscopic statistical mechanical accounts is also lacking.

''Technical note'': For the reasons discussed in the article [[differential entropy]], the simple definition of Shannon entropy ceases to be directly applicable for [[random variable]]s with continuous [[probability distribution function]]s. Instead the appropriate quantity to maximise is the "relative information entropy,"

:&lt;math&gt;H_c=-\int p(x)\log\frac{p(x)}{m(x)}\,dx.&lt;/math&gt;

''H&lt;sub&gt;c&lt;/sub&gt;'' is the negative of the [[Kullback–Leibler divergence]], or discrimination information, of ''m''(''x'') from ''p''(''x''), where ''m''(''x'') is a prior [[invariant measure]] for the variable(s). The relative entropy ''H&lt;sub&gt;c&lt;/sub&gt;'' is always less than zero, and can be thought of as (the negative of) the number of [[bit]]s of uncertainty lost by fixing on ''p''(''x'') rather than ''m''(''x''). Unlike the Shannon entropy, the relative entropy ''H&lt;sub&gt;c&lt;/sub&gt;'' has the advantage of remaining finite and well-defined for continuous ''x'', and invariant under 1-to-1 coordinate transformations. The two expressions coincide for [[discrete probability distribution]]s, if one can make the assumption that ''m''(''x''&lt;sub&gt;i&lt;/sub&gt;) is uniform - i.e. the [[principle of equal a-priori probability]], which underlies statistical thermodynamics.

== Philosophical Implications ==

Adherents to the MaxEnt viewpoint take a clear position on some of the [[philosophy of thermal and statistical physics|conceptual/philosophical questions]] in thermodynamics. This position is sketched below.

=== The nature of the probabilities in statistical mechanics ===

Jaynes (1985,&lt;ref name="Jaynes 1985"&gt;Jaynes, E.T. (1985).&lt;/ref&gt; 2003,&lt;ref name="Jaynes 2003"&gt;Jaynes, E.T. (2003).&lt;/ref&gt; ''et passim'') discussed the concept of probability. According to the MaxEnt viewpoint, the probabilities in statistical mechanics are determined jointly by two factors: by respectively specified particular models for the underlying state space (e.g. Liouvillian [[phase space]]); and by respectively specified particular partial descriptions of the system (the macroscopic description of the system used to constrain the MaxEnt probability assignment). The probabilities are [[Objectivity (science)|objective]] in the sense that, given these inputs, a uniquely defined probability distribution will result, the same for every rational investigator, independent of the subjectivity or arbitrary opinion of particular persons. The probabilities are epistemic in the sense that they are defined in terms of specified data and derived from those data by definite and objective rules of inference, the same for every rational investigator.&lt;ref&gt;Jaynes, E.T. (1979), p. 28.&lt;/ref&gt; Here the word epistemic, which refers to objective and impersonal scientific knowledge, the same for every rational investigator, is used in the sense that contrasts it with opiniative, which refers to the subjective or arbitrary beliefs of particular persons; this contrast was used by [[Plato]] and [[Aristotle]], and stands reliable today.

Jaynes also used the word 'subjective' in this context because others have used it in this context. He accepted that in a sense, a state of knowledge has a subjective aspect, simply because it refers to thought, which is a mental process. But he emphasized that the principle of maximum entropy refers only to thought which is rational and objective, independent of the personality of the thinker. In general, from a philosophical viewpoint, the words 'subjective' and 'objective' are not contradictory; often an entity has both subjective and objective aspects. Jaynes explicitly rejected the criticism of some writers that, just because one can say that thought has a subjective aspect, thought is automatically non-objective. He explicitly rejected subjectivity as a basis for scientific reasoning, the epistemology of science; he required that scientific reasoning have a fully and strictly objective basis.&lt;ref&gt;Jaynes, E.T. (1968), p. 228.&lt;/ref&gt; Nevertheless, critics continue to attack Jaynes, alleging that his ideas are "subjective". One writer even goes so far as to label Jaynes' approach as "ultrasubjectivist",&lt;ref&gt;Guttmann, Y.M. (1999), pp. 28, 36, 38, 57, 61.&lt;/ref&gt; and to mention "the panic that the term subjectivism created amongst physicists".&lt;ref&gt;Guttmann, Y.M. (1999), p. 29.&lt;/ref&gt;

The probabilities represent both the degree of knowledge and lack of information in the data and the model used in the analyst's macroscopic description of the system, and also what those data say about the nature of the underlying reality.

The fitness of the probabilities depends on whether the constraints of the specified macroscopic model are a sufficiently accurate and/or complete description of the system to capture all of the experimentally reproducible behaviour.  This cannot be guaranteed, ''a priori''.  For this reason MaxEnt proponents also call the method '''predictive statistical mechanics'''. The predictions can fail. But if they do, this is informative, because it signals the presence of new constraints needed to capture reproducible behaviour in the system, which had not been taken into account.

=== Is entropy "real"? ===

The thermodynamic entropy (at equilibrium) is a function of the state variables of the model description. It is therefore as "real" as the other variables in the model description. If the model constraints in the probability assignment are a "good" description, containing all the information needed to predict reproducible experimental results, then that includes all of the results one could predict using the formulae involving entropy from classical thermodynamics. To that extent, the MaxEnt ''S&lt;sub&gt;Th&lt;/sub&gt;'' is as "real" as the entropy in classical thermodynamics.

Of course, in reality there is only one real state of the system. The entropy is not a direct function of that state. It is a function of the real state only through the (subjectively chosen) macroscopic model description.

=== Is ergodic theory relevant? ===

The Gibbsian [[statistical ensemble|ensemble]] idealises the notion of repeating an experiment again and again on ''different'' systems, not again and again on the ''same'' system. So long-term time averages and the [[ergodic hypothesis]], despite the intense interest in them in the first part of the twentieth century, strictly speaking are not relevant to the probability assignment for the state one might find the system in.

However, this changes if there is additional knowledge that the system is being prepared in a particular way some time before the measurement.  One must then consider whether this gives further information which is still relevant at the time of measurement.  The question of how 'rapidly mixing' different properties of the system are then becomes very much of interest.  Information about some degrees of freedom of the combined system may become unusable very quickly; information about other properties of the system may go on being relevant for a considerable time.

If nothing else, the medium and long-run time correlation properties of the system are interesting subjects for experimentation in themselves.  Failure to accurately predict them is a good indicator that relevant macroscopically determinable physics may be missing from the model.

=== The Second Law ===

According to [[Liouville's theorem (Hamiltonian)|Liouville's theorem]] for [[Hamiltonian dynamics]], the hyper-volume of a cloud of points in [[phase space]] remains constant as the system evolves. Therefore, the information entropy must also remain constant, if we condition on the original information, and then follow each of those microstates forward in time:

:&lt;math&gt;\Delta S_I = 0 \,&lt;/math&gt;

However, as time evolves, that initial information we had becomes less directly accessible. Instead of being easily summarisable in the macroscopic description of the system, it increasingly relates to very subtle correlations between the positions and momenta of individual molecules. (Compare to Boltzmann's [[H-theorem]].)  Equivalently, it means that the probability distribution for the whole system, in 6N-dimensional phase space, becomes increasingly irregular, spreading out into long thin fingers rather than the initial tightly defined volume of possibilities.

Classical thermodynamics is built on the assumption that entropy is a [[state function]] of the [[macroscopic variable]]s—i.e., that none of the history of the system matters, so that it can all be ignored.

The extended, wispy, evolved probability distribution, which still has the initial Shannon entropy ''S&lt;sub&gt;Th&lt;/sub&gt;&lt;sup&gt;(1)&lt;/sup&gt;'', should reproduce the expectation values of the observed macroscopic variables at time ''t&lt;sub&gt;2&lt;/sub&gt;''. However it will no longer necessarily be a maximum entropy distribution for that new macroscopic description.  On the other hand, the new thermodynamic entropy ''S&lt;sub&gt;Th&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt;'' assuredly ''will'' measure the maximum entropy distribution, by construction. Therefore, we expect:

:&lt;math&gt;{S_{Th}}^{(2)} \geq {S_{Th}}^{(1)} &lt;/math&gt;

At an abstract level, this result implies that some of the information we originally had about the system has become "no longer useful" at a macroscopic level.  At the level of the 6''N''-dimensional probability distribution, this result represents [[coarse graining]]—i.e., information loss by smoothing out very fine-scale detail.

=== Caveats with the argument ===

Some caveats should be considered with the above.

1.  Like all statistical mechanical results according to the MaxEnt school, this increase in thermodynamic entropy is only a ''prediction''. It assumes in particular that the initial macroscopic description contains all of the information relevant to predicting the later macroscopic state. This may not be the case, for example if the initial description fails to reflect some aspect of the preparation of the system which later becomes relevant. In that case the "failure" of a MaxEnt prediction tells us that there is something more which is relevant that we may have overlooked in the physics of the system.

It is also sometimes suggested that [[quantum measurement]], especially in the [[decoherence]] interpretation, may give an apparently unexpected reduction in entropy per this argument, as it appears to involve macroscopic information becoming available which was previously inaccessible. (However, the entropy accounting of quantum measurement is tricky, because to get full decoherence one may be assuming an infinite environment, with an infinite entropy).

2.  The argument so far has glossed over the question of ''fluctuations''. It has also implicitly assumed that the uncertainty predicted at time ''t&lt;sub&gt;1&lt;/sub&gt;'' for the variables at time ''t&lt;sub&gt;2&lt;/sub&gt;'' will be much smaller than the measurement error.  But if the measurements do meaningfully update our knowledge of the system, our uncertainty as to its state is reduced, giving a new ''S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt;'' which is ''less'' than ''S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(1)&lt;/sup&gt;''. (Note that if we allow ourselves the abilities of [[Laplace's demon]], the consequences of this new information can also be mapped backwards, so our uncertainty about the dynamical state at time ''t&lt;sub&gt;1&lt;/sub&gt;'' is now ''also'' reduced from ''S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(1)&lt;/sup&gt;'' to ''S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt;''&amp;nbsp;).

We know that ''S&lt;sub&gt;Th&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt; &gt; S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(2)&lt;/sup&gt;''; but we can now no longer be certain that it is greater than ''S&lt;sub&gt;Th&lt;/sub&gt;&lt;sup&gt;(1)&lt;/sup&gt; = S&lt;sub&gt;'''I'''&lt;/sub&gt;&lt;sup&gt;(1)&lt;/sup&gt;''. This then leaves open the possibility for fluctuations in ''S&lt;sub&gt;Th&lt;/sub&gt;''. The thermodynamic entropy may go "down" as well as up. A more sophisticated analysis is given by the entropy [[Fluctuation Theorem]], which can be established as a consequence of the time-dependent MaxEnt picture.

3.  As just indicated, the MaxEnt inference runs equally well in reverse. So given a particular final state, we can ask, what can we "retrodict" to improve our knowledge about earlier states?  However the Second Law argument above also runs in reverse: given macroscopic information at time ''t&lt;sub&gt;2&lt;/sub&gt;'', we should expect it too to become less useful.  The two procedures are time-symmetric. But now the information will become less and less useful at earlier and earlier times. (Compare with [[Loschmidt's paradox]].) The MaxEnt inference would predict that the most probable origin of a currently low-entropy state would be as a spontaneous fluctuation from an earlier high entropy state. But this conflicts with what we know to have happened, namely that entropy has been increasing steadily, even back in the past.

The MaxEnt proponents' response to this would be that such a systematic failing in the prediction of a MaxEnt inference is a "good" thing.&lt;ref name="Jaynes 1979"&gt;Jaynes, E.T. (1979).&lt;/ref&gt; It means that there is thus clear evidence that some important physical information has been missed in the specification the problem. If it is correct that the dynamics "are" [[T-symmetry|time-symmetric]], it appears that we need to put in by hand a [[prior probability]] that initial configurations with a low thermodynamic entropy are more likely than initial configurations with a high thermodynamic entropy. This cannot be explained by the immediate dynamics. Quite possibly, it arises as a reflection of the evident time-asymmetric evolution of the universe on a cosmological scale (see [[arrow of time]]).

== Criticisms ==

The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium.&lt;ref&gt;Kleidon, A., Lorenz, R.D. (2005).&lt;/ref&gt;

The theory has also been criticized in the grounds of internal consistency. For instance, [[Radu Balescu]] provides a strong criticism of the MaxEnt School and of Jaynes' work. Balescu states that Jaynes' and coworkers theory is based on a non-transitive evolution law that produces ambiguous results. Although some difficulties of the theory can be cured, the theory "lacks a solid foundation" and "has not led to any new concrete result".&lt;ref&gt;Balescu, R. (1997).&lt;/ref&gt;

Though the maximum entropy approach is based directly on informational entropy, it is applicable to physics only when there is a clear physical definition of entropy. There is no clear unique general physical definition of entropy for non-equilibrium systems, which are general physical systems considered during a process rather than thermodynamic systems in their own internal states of thermodynamic equilibrium.&lt;ref&gt;Lieb, E.H., Yngvason, J. (2003). The entropy of classical thermodynamics, Chapter 8 of Greven, A., Keller, G., Warnecke (editors) (2003). ''Entropy'', Princeton University Press, Princeton NJ, {{ISBN|0-691-11338-6}}, page 190.&lt;/ref&gt; It follows that the maximum entropy approach will not be applicable to non-equilibrium systems until there is found a clear physical definition of entropy. This problem is related to the fact that heat may be transferred from a hotter to a colder physical system even when local thermodynamic equilibrium does not hold so that neither system has a well defined temperature. Classical entropy is defined for a system in its own internal state of thermodynamic equilibrium, which is defined by state variables, with no non-zero fluxes, so that flux variables do not appear as state variables. But for a strongly non-equilibrium system, during a process, the state variables must include non-zero flux variables. Classical physical definitions of entropy do not cover this case, especially when the fluxes are large enough to destroy local thermodynamic equilibrium. In other words, for entropy for non-equilibrium systems in general, the definition will need at least to involve specification of the process including non-zero fluxes, beyond the classical static thermodynamic state variables. The 'entropy' that is maximized needs to be defined suitably for the problem at hand. If an inappropriate 'entropy' is maximized, a wrong result is likely. In principle, maximum entropy thermodynamics does not refer narrowly and only to classical thermodynamic entropy. It is about informational entropy applied to physics, explicitly depending on the data used to formulate the problem at hand. According to Attard, for physical problems analyzed by strongly non-equilibrium thermodynamics, several physically distinct kinds of entropy need to be considered, including what he calls second entropy. Attard writes: "Maximizing the second entropy over the microstates in the given initial macrostate gives the most likely target macrostate.".&lt;ref&gt;Attard, P. (2012). ''Non-Equilibrium Thermodynamics and Statistical Mechanics: Foundations and Applications'', Oxford University Press, Oxford UK, {{ISBN|978-0-19-966276-0}}, p. 161.&lt;/ref&gt;  The physically defined second entropy can also be considered from an informational viewpoint.

==See also==
* [[Edwin Thompson Jaynes]]
* [[First law of thermodynamics]]
* [[Second law of thermodynamics]]
* [[Principle of maximum entropy]]
* [[Principle of Minimum Discrimination Information]]
* [[Kullback–Leibler divergence]]
* [[Quantum relative entropy]]
* [[Information theory and measure theory]]
* [[Entropy power inequality]]

== References ==
{{reflist|colwidth=25em}}

===Bibliography of cited references===
*{{cite book |author=Balescu, Radu |title=Statistical Dynamics: Matter out of equilibrium |publisher=Imperial College Press |location=London |year=1997 }}
*{{cite journal
 |last1=Jaynes |first1=E.T.
 |author1-link=Edwin Thompson Jaynes
 |date=Sep 1968
 |doi=10.1109/TSSC.1968.300117
 |title=Prior Probabilities
 |url=http://bayes.wustl.edu/etj/articles/prior.pdf
 |journal=IEEE Transactions on Systems Science and Cybernetics
 |volume=SSC–4 |issue=3
 |pages=227–241
 |ref=harv
}}
*Guttmann, Y.M. (1999). ''The Concept of Probability in Statistical Physics'', Cambridge University Press, Cambridge UK, {{ISBN|978-0-521-62128-1}}.
*{{cite book |last=Jaynes |first=E.T. |authorlink=Edwin Thompson Jaynes |chapter=Where do we stand on maximum entropy? |chapterurl=http://bayes.wustl.edu/etj/articles/stand.on.entropy.pdf |editor=Levine, R. |editor2=Tribus M. |title=The Maximum Entropy Formalism |publisher=MIT Press |year=1979 |isbn=978-0-262-12080-7 |ref={{harvid|Jaynes|1979}}}}
*{{cite journal |author=Jaynes, E.T. |authorlink=Edwin Thompson Jaynes |title=Some random observations |journal=Synthese |volume=63 |pages=115–138 |year=1985 |doi=10.1007/BF00485957 }}
*{{cite book |author=Jaynes, E.T. |title=Probability Theory: The Logic of Science |editor=Bretthorst, G.L. |publisher=Cambridge University Press |location=Cambridge |year=2003 |isbn=978-0-521-59271-0 }}
*{{cite book |first1=Axel |last1=Kleidon |first2=Ralph D. |last2=Lorenz |title=Non-equilibrium thermodynamics and the production of entropy: life, earth, and beyond |url=https://books.google.com/books?id=YRjfuEP_QycC&amp;pg=PA42 |year=2005 |publisher=Springer |isbn=978-3-540-22495-2|pages=42–}}

== Further reading ==
{{refbegin}}
* {{cite journal |author=Bajkova, A.T. |title=The generalization of maximum entropy method for reconstruction of complex functions |journal=Astronomical and Astrophysical Transactions |volume=1 |issue=4 |pages=313–320 |year=1992 |doi=10.1080/10556799208230532 |bibcode = 1992A&amp;AT....1..313B }}
* {{cite book |author=Caticha, Ariel |title=''Entropic Inference and the Foundations of Physics'' |year=2012 |url=http://www.albany.edu/physics/ACaticha-EIFP-book.pdf }}
* {{cite journal |author=Dewar, R.C. |title=Information theory explanation of the fluctuation theorem, maximum entropy production and self-organized criticality in non-equilibrium stationary states |journal=J. Phys. A: Math. Gen. |volume=36 |pages=631–41 |year=2003 |arxiv=cond-mat/0005382 |doi=10.1088/0305-4470/36/3/303 |issue=3 |url=http://iopscience.iop.org/0305-4470/36/3/303|bibcode = 2003JPhA...36..631D }}
* {{cite journal |author=Dewar, R.C. |authormask=1 |title=Maximum entropy production and the fluctuation theorem |journal=J. Phys. A: Math. Gen. |volume=38 |pages=L371–81 |year=2005 |url=http://www.iop.org/EJ/abstract/0305-4470/38/21/L01/ |doi=10.1088/0305-4470/38/21/L01 |issue=21|bibcode = 2005JPhA...38L.371D }}
* {{cite journal |author1=Grinstein, G.|author2=Linsker, R. |title=Comments on a derivation and application of the 'maximum entropy production' principle |journal=J. Phys. A: Math. Theor. |volume=40 |pages=9717–20 |year=2007 |url=http://www.iop.org/EJ/abstract/1751-8121/40/31/N01/ |doi=10.1088/1751-8113/40/31/N01 |issue=31|bibcode = 2007JPhA...40.9717G }} Shows invalidity of Dewar's derivations (a) of maximum entropy production (MaxEP) from fluctuation theorem for far-from-equilibrium systems, and (b) of a claimed link between MaxEP and self-organized criticality.
* Grandy, W. T., 1987. ''Foundations of Statistical Mechanics. Vol 1: Equilibrium Theory; Vol. 2: Nonequilibrium Phenomena''. Dordrecht: D. Reidel. ''Vol. 1'': {{ISBN|90-277-2489-X}}. ''Vol. 2'': {{ISBN|90-277-2649-3}}.
* {{cite journal |author=Grandy, W.T. |authormask=1 |title=Three papers in nonequilibrium statistical mechanics |journal=Found. Phys. |volume=34 |issue=1 |pages=21–57 |year=2004 |url=http://physics.uwyo.edu/~tgrandy/Statistical_Mechanics.html|arxiv = cond-mat/0303291 |bibcode = 2004FoPh...34...21G |doi = 10.1023/B:FOOP.0000012008.36856.c1 }}
* {{cite book |author=Gull, S.F. |chapter=Some misconceptions about entropy |chapterurl=http://www.ucl.ac.uk/~ucesjph/reality/entropy/text.html |editor=Buck, B. |editor2=Macaulay, V.A. |title=Maximum Entropy in Action |publisher=Oxford University Press |year=1991 |isbn=978-0-19-853963-6 |df= }}
*{{harvnb|Jaynes|1979}}
* [http://bayes.wustl.edu/etj/node1.html Extensive archive of further papers] by E.T. Jaynes on probability and physics. Many are collected in {{cite book |editor=Rosenkrantz, R.D. |title=E.T. Jaynes — Papers on probability, statistics and statistical physics |publisher=D. Reidel. |location=Dordrecht, Netherlands |year=1983 |isbn=978-90-277-1448-0 }}
* {{cite journal |author=Lorenz, R. |title=Full steam ahead — probably |journal=Science |volume=299 |pages=837–8 |year=2003 |url=http://www.lpl.arizona.edu/~rlorenz/fullsteamahead.pdf |format=PDF |doi=10.1126/science.1081280 |issue=5608 |pmid=12574610}}
* {{cite arXiv |author=Rau, Jochen |title=Statistical Mechanics in a Nutshell |year=1998 |eprint=physics/9805024 }}
{{refend}}

[[Category:Statistical mechanics]]
[[Category:Philosophy of thermal and statistical physics]]
[[Category:Non-equilibrium thermodynamics]]
[[Category:Information theory]]
[[Category:Thermodynamics]]
[[Category:Thermodynamic entropy]]</text>
      <sha1>8lmdhknxoiabf4ymlc7ij8zem2b999j</sha1>
    </revision>
  </page>
  <page>
    <title>Meta-IV (specification language)</title>
    <ns>0</ns>
    <id>17271582</id>
    <revision>
      <id>822460839</id>
      <parentid>819780352</parentid>
      <timestamp>2018-01-26T14:20:03Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 1 as dead. #IABot (v1.6.2)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7842">{{Essay-like|date=January 2018}}
{{Orphan|date=December 2012}}

The '''Meta-IV''' (pronounced like "metaphor") was an early version of the specification language of the [[Vienna Development Method]] formal method for the development of computer-based systems.

==History==
One of the first occurrences of Meta-IV in print  appears to be
"Programming in the Meta-language: A Tutorial".&lt;ref name="Bjørner&amp;Jones-1978"&gt;Bjørner&amp;Jones 1978, p24.&lt;/ref&gt;
[[Dines Bjørner]] used it in the very beginning of his tutorial as a footnote
&lt;blockquote&gt;
This paper provides an informal introduction to the "art" of abstractly specifying software architectures using the ''VDM'' meta-language&lt;sup&gt;*&lt;/sup&gt;.&lt;ref&gt;* ''colloquially known as: META-IV'', Bjørner&amp;Jones 1978, p24.&lt;/ref&gt; A formal treatment  of the semantics, as well as a BNF-like concrete syntax, of a large subset of the meta-language is given in [Jones 78a] following this paper.
&lt;/blockquote&gt;

The spirit of the Meta-IV specification language is well captured by the following passage&lt;ref&gt;Bjørner&amp;Jones 1978, p33&lt;/ref&gt;
&lt;blockquote&gt;
We stress here... that the meta-language is to be used, not for solving algorithmic problems (on a computer), but for specifying, in an implementation-independent way, the architecture (or models) of software. Instead of using informal English mixed with technical jargon, we offer you a very-high-level 'programming' language. We do not offer an interpreter or compiler for this meta-language. And we have absolutely no intention of ever wasting our time trying to mechanize this meta-language. We wish, as we have done in the past, and as we intend to continue doing in the future, to further develop the notation and to express notions in ways for which no mechanical interpreter system can ever be provided.
&lt;/blockquote&gt;
VDM is a '''Method'''. The Meta-IV was the '''Specification language''' that accompanied the method, and the [[Vienna Development Method|VDM-SL]] is the current standardized form of that language.

Since the VDM-SL has become standardized, then one may use Meta-IV to denote the three specific Schools of
the VDM&lt;ref&gt;http://www.vdmportal.org/twiki/pub/Main/WebHome/bjorner-vdm-ipsj-20oct06.pdf&lt;/ref&gt; which existed (and to some extent still do) from the 1970s onwards:
* the Danish School — founded by [http://www2.imm.dtu.dk/~db/ Dines Bjørner]
* the English School — founded by [https://web.archive.org/web/20100731082829/http://www.cs.ncl.ac.uk/people/cliff.jones/ Cliff Jones]
* the Irish School&lt;ref&gt;[http://portal.acm.org/author_page.cfm?id=81100168285&amp;coll=GUIDE&amp;dl=GUIDE&amp;trk=0&amp;CFID=26571118&amp;CFTOKEN=15016975 Micheal Mac an Airchinnigh - ACM author profile page&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; — founded by [https://tcdlocalportal.tcd.ie/pls/webapps/cerif.cerif_cv.display_cv?p_cv_id=688 Mícheál Mac an Airchinnigh]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}

A brief account of these different Schools is given in the text "Mathematical Approaches to Software Quality".&lt;ref&gt;O'Regan 2006&lt;/ref&gt;

A comprehensive VDM Bibliography&lt;ref&gt;Gorm Larsen, Peter&lt;/ref&gt; is also available.

==The Schools of VDM==

===The Danish School===
founded by [[Dines Bjørner]]&lt;br /&gt;
To mention:
* [[Technical University of Denmark]] (DTU) in Lyngby
* [[Dansk Datamatik Center]] (DDC)

===The English School===
founded by [[Cliff Jones (computer scientist)]]&lt;br /&gt;
To mention:
* University of Manchester
* University of Newcastle

===The Irish School===
founded by Mícheál Mac an Airchinnigh&lt;br /&gt;
To mention:
* University of Dublin, Trinity College

The first appearance of the name "Irish School of the VDM" occurs in a PhD Thesis:
Mac an Airchinnigh, Mícheál. Conceptual Models and Computing.&lt;ref&gt;[https://www.cs.tcd.ie/Micheal.MacanAirchinnigh/Web%20Pages/ME_FEIN/SCRIBHNEOIREACHT/FOILSEACHAN/Master.html Foilseacháin&lt;!-- Bot generated title --&gt;] {{webarchive|url=https://web.archive.org/web/20040821230702/http://www.cs.tcd.ie/Micheal.MacanAirchinnigh/Web%20Pages/ME_FEIN/SCRIBHNEOIREACHT/FOILSEACHAN/Master.html |date=2004-08-21 }}&lt;/ref&gt; Ph.D. Thesis. University of Dublin, Trinity College, Dublin, 1990, p.&amp;nbsp;41:
&lt;blockquote&gt;
There is essential universal agreement on what constitutes the VDM. However, there are basically two major Schools of the VDM largely
distinguished by notational differences employed in the specification language ''Meta-IV'' — the Danish School and the English School."
&lt;/blockquote&gt;
and further down on the same page
&lt;blockquote&gt;
There is also the Polish School, which finds expression through the MetaSoft project (Blikle 1987, 1988, 1990). I will frequently need to distinguish between the style of notation and method that I use from those of the other Schools of the VDM. I ''presume'' to use the phrase 'the Irish School of the VDM' to draw that distinction.
&lt;/blockquote&gt;

The Thesis is available online.&lt;ref&gt;[https://www.cs.tcd.ie/Andrew.Butterfield/IrishVDM/reading/PhD-MMA.pdf Titlepage&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

Other substantial works related to the School are also online.&lt;ref&gt;[https://www.cs.tcd.ie/Andrew.Butterfield/IrishVDM/ Irish School of VDM - Home Page&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

==VDM Europe==
The three Schools were brought under a common organizational structure called VDM Europe&lt;ref&gt;[http://www.sigmod.org/dblp/db/conf/fm/vdme1987.html VDM Europe 1987&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; which held it first international conference in Brussels, Belgium, March 23–26, 1987. At the time funding was provided under the Esprit Programme of the European Union.
Meetings were mostly held in the EU Commission buildings in Brussels, Belgium.

VDM Europe eventually was dissolved&lt;ref&gt;{{cite web |url=http://www.fmeurope.org/manasite/mas/fme/meetingsitem/30556-757.pdf |title=Archived copy |accessdate=2008-05-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20080827163240/http://www.fmeurope.org/manasite/mas/fme/meetingsitem/30556-757.pdf |archivedate=2008-08-27 |df= }}&lt;/ref&gt; in favor of  [[Formal Methods Europe]], founded in 1992.&lt;ref&gt;Formal Methods Europe&lt;/ref&gt; Minutes of the first meeting of FME are available online.&lt;ref&gt;{{cite web |url=http://www.fmeurope.org/manasite/mas/fme/meetingsitem/30538-740.pdf |title=Archived copy |accessdate=2008-05-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20080827163801/http://www.fmeurope.org/manasite/mas/fme/meetingsitem/30538-740.pdf |archivedate=2008-08-27 |df= }}&lt;/ref&gt;

==Conferences==
List of the VDM and FME conferences (http://www.informatik.uni-trier.de/~ley/db/conf/fm/)

==Notes==
{{Reflist|2}}

==Reading Links==
# {{cite book | last = Bjørner | first = Dines | authorlink = |author2=Cliff B. Jones | title = The Vienna Development Method: The Meta-Language, Lecture Notes in Computer Science 61 | publisher = Springer | year = 1978 | location = Berlin, Heidelberg, New York | pages = | url = | doi = | id = | isbn = 3-540-08766-4 }}
# {{cite book | last = O'Regan | first = Gerard | authorlink = | title = Mathematical Approaches to Software Quality | publisher = Springer | year = 2006 | location = London | pages = | url = | doi = | id = | isbn = 978-1-84628-242-3 }}
# {{Cite book| editor=Cliff B. Jones | title = Programming Languages and Their Definition &amp;mdash; H. Bekič (1936-1982)| series = [[Lecture Notes in Computer Science]] | volume= 177 | publisher = Springer-Verlag | year = 1984 | location = Berlin, Heidelberg, New York, Tokyo | isbn = 978-3-540-13378-0 | url = https://link.springer.com/book/10.1007/BFb0048933 }}


==External links==
* {{cite web|url=http://liinwww.ira.uka.de/bibliography/SE/vdm.html |title=The VDM Bibliography |accessdate=2008-08-13 |last=Gorm Larsen |first=Peter }}
* {{cite web|url=http://www.fmeurope.org/ |title=Formal Methods Europe |accessdate=2008-08-13 }}

[[Category:Formal specification languages]]</text>
      <sha1>2ekx7b4p0ziavsqfqk2dg5xedawrdw4</sha1>
    </revision>
  </page>
  <page>
    <title>Nash blowing-up</title>
    <ns>0</ns>
    <id>25547443</id>
    <revision>
      <id>586967507</id>
      <parentid>563577014</parentid>
      <timestamp>2013-12-20T16:12:05Z</timestamp>
      <contributor>
        <username>Myasuda</username>
        <id>1187538</id>
      </contributor>
      <minor/>
      <comment>avoid redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2459">In [[algebraic geometry]], a '''Nash blowing-up''' is a process in which, roughly speaking, each [[Singular point of an algebraic variety|singular point]] is replaced by all the limiting positions of the [[tangent spaces]] at the non-singular points. Strictly speaking, if ''X'' is an [[algebraic variety]] of pure [[codimension]] ''r'' [[embedding|embedded]] in a [[smooth variety]] of dimension ''n'', &lt;math&gt;\text{Sing}(X)&lt;/math&gt; denotes the set of its singular points and &lt;math&gt;X_\text{reg}:=X\setminus \text{Sing}(X)&lt;/math&gt; it is possible to define a map &lt;math&gt;\tau:X_\text{reg}\rightarrow X\times G_r^n&lt;/math&gt;, where &lt;math&gt;G_{r}^{n}&lt;/math&gt; is the [[Grassmannian]] of ''r''-planes in ''n''-space, by &lt;math&gt;\tau(a):=(a,T_{X,a})&lt;/math&gt;, where &lt;math&gt;T_{X,a}&lt;/math&gt; is the tangent space of ''X'' at ''a''. Now, the closure of the image of this map together with the projection to ''X'' is called the Nash blowing-up of ''X''.

Although (to emphasize its geometric interpretation) an embedding was used to define the Nash embedding it is possible to prove that it doesn't depend on it. 

==Properties==

* The Nash blowing-up is locally a [[blowing up|monoidal transformation]].
* If ''X'' is a [[complete intersection]] defined by the vanishing of &lt;math&gt;f_1,f_2,\ldots,f_{n-r}&lt;/math&gt; then the Nash blowing-up is the blowing-up with center given by the ideal generated by the (''n''&amp;nbsp;&amp;minus;&amp;nbsp;''r'')-minors of the matrix with entries &lt;math&gt;\partial f_i/\partial x_j&lt;/math&gt;.
* For a variety over a field of characteristic zero, the Nash blowing-up is an [[isomorphism]] if and only if ''X'' is non-singular. 
* For an algebraic curve over an [[algebraically closed field]] of characteristic zero the application of Nash blowings-up leads to [[resolution of singularities|desingularization]] after a finite number of steps. 
* In characteristic ''q''&amp;nbsp;&gt;&amp;nbsp;0, for the curve &lt;math&gt;y^2-x^q=0&lt;/math&gt; the Nash blowing-up is the monoidal transformation with center given by the ideal &lt;math&gt;(x^{q})&lt;/math&gt;, for ''q''&amp;nbsp;=&amp;nbsp;2, or &lt;math&gt;(y^2)&lt;/math&gt;, for &lt;math&gt;q&gt;2&lt;/math&gt;. Since the center is a hypersurface the blowing-up is an isomorphism. Then the two previous points are not true in positive characteristic.

==See also==

* [[Blowing up]]
* [[Resolution of singularities]]

==References==
* Nobile, A. ''Some properties of the Nash blowing-up'' PACIFIC JOURNAL OF MATHEMATICS, Vol. 60, No. I, 1975

[[Category:Algebraic geometry]]

{{math-stub}}</text>
      <sha1>mpu4t93yg6nv7tjuz2y1ctsx2m51o3m</sha1>
    </revision>
  </page>
  <page>
    <title>Partition regularity</title>
    <ns>0</ns>
    <id>3999801</id>
    <revision>
      <id>810226006</id>
      <parentid>710810473</parentid>
      <timestamp>2017-11-14T01:21:14Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: J. Combinatorial Theory → Journal of Combinatorial Theory using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5574">{{refimprove|date=December 2009}}
In [[combinatorics]], a branch of [[mathematics]], '''partition regularity''' is one notion of largeness for a [[set system|collection]] of sets.

Given a set &lt;math&gt;X&lt;/math&gt;, a collection of subsets &lt;math&gt;\mathbb{S} \subset \mathcal{P}(X)&lt;/math&gt; is  called ''partition regular'' if every set ''A'' in the collection has the property that, no matter how ''A'' is partitioned into finitely many subsets, at least one of the subsets will also belong to the collection. That is,
for any &lt;math&gt;A \in \mathbb{S}&lt;/math&gt;, and any finite partition &lt;math&gt;A = C_1 \cup C_2 \cup \cdots \cup C_n&lt;/math&gt;, there exists an ''i''&amp;nbsp;&amp;le;&amp;nbsp;''n'', such that &lt;math&gt;C_i&lt;/math&gt; belongs to &lt;math&gt;\mathbb{S}&lt;/math&gt;. [[Ramsey theory]] is sometimes characterized as the  study of which collections &lt;math&gt;\mathbb{S}&lt;/math&gt; are partition regular.

== Examples ==
* the collection of all infinite subsets of an infinite set ''X'' is a prototypical example.  In this case partition regularity asserts that every finite partition of an infinite set has an infinite cell (i.e. the infinite [[pigeonhole principle]].)
* sets with positive upper density in &lt;math&gt;\mathbb{N}&lt;/math&gt;: the ''[[upper density]]'' &lt;math&gt;\overline{d}(A)&lt;/math&gt; of &lt;math&gt;A \subset \mathbb{N}&lt;/math&gt; is defined as &lt;math&gt; \overline{d}(A) = \limsup_{n \rightarrow \infty} \frac{| \{1,2,\ldots,n\} \cap A|}{n}. &lt;/math&gt;
* For any [[ultrafilter]] &lt;math&gt;\mathbb{U}&lt;/math&gt; on a set &lt;math&gt;X&lt;/math&gt;, &lt;math&gt;\mathbb{U}&lt;/math&gt; is partition regular. If &lt;math&gt;\mathbb{U} \ni A =\bigcup_1^n C_i&lt;/math&gt;, then for exactly one &lt;math&gt;i&lt;/math&gt; is &lt;math&gt;C_i \in \mathbb{U}&lt;/math&gt;.
* sets of recurrence: a set R of integers is called a ''set of recurrence'' if for any measure preserving transformation &lt;math&gt;T&lt;/math&gt; of the probability space (&amp;Omega;, &amp;beta;, &amp;mu;) and &lt;math&gt;A \in\ \beta&lt;/math&gt; of positive measure there is a nonzero &lt;math&gt;n \in R&lt;/math&gt; so that &lt;math&gt;\mu(A \cap T^{n}A) &gt; 0&lt;/math&gt;.
* Call a subset of natural numbers ''a.p.-rich'' if it contains arbitrarily long arithmetic progressions. Then the collection of a.p.-rich subsets is partition regular ([[Van der Waerden's theorem|Van der Waerden]], 1927).
* Let &lt;math&gt;[A]^n&lt;/math&gt; be the set of all ''n''-subsets of &lt;math&gt;A \subset \mathbb{N}&lt;/math&gt;. Let &lt;math&gt;\mathbb{S}^n = \bigcup^{ }_{A \subset \mathbb{N}} [A]^n&lt;/math&gt;. For each n, &lt;math&gt;\mathbb{S}^n&lt;/math&gt; is partition regular. ([[Ramsey's theorem|Ramsey]], 1930).
* For each infinite cardinal &lt;math&gt;\kappa&lt;/math&gt;, the collection of [[stationary set]]s of &lt;math&gt;\kappa&lt;/math&gt; is partition regular. More is true: if &lt;math&gt;S&lt;/math&gt; is stationary and &lt;math&gt;S=\bigcup_{\alpha &lt; \lambda} S_{\alpha}&lt;/math&gt; for some &lt;math&gt;\lambda &lt; \kappa &lt;/math&gt;, then some &lt;math&gt;S_{\alpha} &lt;/math&gt; is stationary.
* the collection of &lt;math&gt;\Delta&lt;/math&gt;-sets: &lt;math&gt;A \subset \mathbb{N}&lt;/math&gt; is a &lt;math&gt;\Delta&lt;/math&gt;-set if &lt;math&gt;A&lt;/math&gt; contains the set of differences &lt;math&gt;\{s_m - s_n : m,n \in \mathbb{N}, n&lt;m \}&lt;/math&gt; for some sequence &lt;math&gt;\langle s_n \rangle^\omega_{n=1}&lt;/math&gt;.
* the set of barriers on &lt;math&gt;\mathbb{N}&lt;/math&gt;: call a collection &lt;math&gt;\mathbb{B}&lt;/math&gt; of finite subsets of &lt;math&gt;\mathbb{N}&lt;/math&gt; a ''barrier'' if:
** &lt;math&gt;\forall X,Y \in \mathbb{B}, X \not\subset Y&lt;/math&gt; and
** for all infinite &lt;math&gt;I \subset \cup \mathbb{B}&lt;/math&gt;, there is some &lt;math&gt;X \in \mathbb{B}&lt;/math&gt; such that the elements of X are the smallest elements of I; ''i.e.'' &lt;math&gt;X \subset I&lt;/math&gt; and &lt;math&gt;\forall i \in I \setminus X, \forall x \in X, x&lt;i&lt;/math&gt;.
: This generalizes [[Ramsey's theorem]], as each &lt;math&gt;[A]^n&lt;/math&gt; is a barrier. ([[Crispin St. J. A. Nash-Williams|Nash-Williams]], 1965)

* finite products of infinite trees ([[Halpern–Läuchli theorem|Halpern–Läuchli]], 1966)
* [[piecewise syndetic|piecewise syndetic sets]] (Brown, 1968)
* Call a subset of natural numbers ''i.p.-rich'' if it contains arbitrarily large finite sets together with all their finite sums. Then the collection of i.p.-rich subsets is partition regular ([[Jon Folkman|Folkman]]–[[Richard Rado|Rado]]–Sanders, 1968).
* (''m'', ''p'', ''c'')-sets (Deuber, 1973)
* [[IP set]]s (Hindman, 1974, see also Hindman, Strauss, 1998)
* [[Milliken–Taylor theorem|MT&lt;sup&gt;''k''&lt;/sup&gt; sets]] for each ''k'', ''i.e.'' ''k''-tuples of finite sums (Milliken–Taylor, 1975)
* central sets; ''i.e.'' the members of any minimal idempotent in &lt;math&gt;\beta\mathbb{N}&lt;/math&gt;, the [[Stone–Čech compactification]] of the integers. (Furstenberg, 1981, see also Hindman, Strauss, 1998)

==References==

# [[Vitaly Bergelson]], N. Hindman [http://members.aol.com/nhfiles2/pdf/large.pdf Partition regular structures contained in large sets are abundant]  ''J. Comb. Theory A'' '''93''' (2001), 18–36.
# T. Brown, [http://projecteuclid.org/Dienst/UI/1.0/Summarize/euclid.pjm/1102971066 An interesting combinatorial method in the theory of locally finite semigroups], ''Pacific J. Math.''  '''36''', no. 2 (1971), 285–289.
# W. Deuber, Mathematische Zeitschrift '''133''', (1973) 109–123
# N. Hindman, Finite sums from sequences within cells of a partition of ''N'', ''J. Comb. Theory A'' '''17''' (1974) 1–11.
# [[Crispin St. J. A. Nash-Williams|C.St.J.A. Nash-Williams]], On well-quasi-ordering transfinite sequences, ''Proc. Camb. Phil. Soc.'' '''61''' (1965), 33–39.
# N. Hindman, D. Strauss, Algebra in the Stone–Čech compactification, De Gruyter, 1998
# J.Sanders, A Generalization of Schur's Theorem, Doctoral Dissertation, Yale University, 1968.

[[Category:Ramsey theory]]
[[Category:Set families]]</text>
      <sha1>00pyaqmba4tt7slhz2qbnryrpfs761m</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Cohen</title>
    <ns>0</ns>
    <id>22994</id>
    <revision>
      <id>860649383</id>
      <parentid>854445443</parentid>
      <timestamp>2018-09-22T04:15:14Z</timestamp>
      <contributor>
        <ip>172.220.4.42</ip>
      </contributor>
      <comment>/* Contributions to mathematics */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13228">:''For other people named Paul Cohen, see [[Paul Cohen (disambiguation)]]. Not to be confused with [[Paul Cohn]].''
{{Infobox scientist
| name = Paul J. Cohen
| image =
| image_size = 150px
| caption =
| birth_date  = {{birth date|1934|4|2|mf=y}}
| birth_place = [[Long Branch, New Jersey]]
| death_date  = {{death date and age|2007|3|23|1934|4|2|mf=y}}
| death_place = [[Stanford, California]], near [[Palo Alto, CA|Palo Alto]]
| field = [[Mathematics]]
| work_institutions = [[Stanford University]]
| alma_mater = [[Stuyvesant High School]]&lt;br&gt; [[Brooklyn College]]&lt;br&gt; [[University of Chicago]]
| doctoral_advisor = [[Antoni Zygmund]]
| doctoral_students = [[Peter Sarnak]]
| known_for = [[List of forcing notions#Cohen forcing|Cohen forcing]]&lt;br&gt;[[Continuum hypothesis]]
| prizes = [[Bôcher Memorial Prize|Bôcher Prize]] (1964)&lt;br&gt;[[Fields Medal]] (1966)&lt;br /&gt;[[National Medal of Science]] (1967)
| footnotes =
| influences       = [[Georg Cantor]], [[Kurt Gödel]]
| influenced       = [[Alain Badiou]]
}}

'''Paul Joseph Cohen''' (April 2, 1934 – March 23, 2007)&lt;ref name="Stanford_obit"&gt;{{cite news |url=http://news-service.stanford.edu/news/2007/april4/cohen-040407.html |publisher=Stanford Report |date=2007-03-28 | title=Paul Cohen, winner of world's top mathematics prize, dies at 72 |first=Dawn |last=Levy |accessdate=2007-10-31}}&lt;/ref&gt; was an [[United States|American]] [[mathematician]]. He is best known for his proofs that the [[continuum hypothesis]] and the [[axiom of choice]]  are [[independence (mathematical logic)|independent]] from [[Zermelo–Fraenkel set theory]], for which he was awarded a [[Fields Medal]].&lt;ref&gt;{{cite newspaper|url=https://www.nytimes.com/2007/04/02/us/02cohen.html?_r=0|author=Pearce, Jeremy|title=Paul J. Cohen, Mathematics Trailblazer, Dies at 72|newspaper=NY Times|date=2 April 2007}}&lt;/ref&gt;

==Early years==
Cohen was born in [[Long Branch, New Jersey]], into a [[Jewish]] family that had immigrated to the United States from what is now [[Poland]]; he grew up in [[Brooklyn]].&lt;ref&gt;Macintyre, A.J. [http://old.lms.ac.uk/newsletter/360/360_09.html "Paul Joseph Cohen"] {{webarchive|url=https://web.archive.org/web/20101225053150/http://old.lms.ac.uk/newsletter/360/360_09.html |date=2010-12-25 }}, [[London Mathematical Society]]. Accessed March 3, 2011. "Cohen's origins were humble. He was born in Long Branch, New Jersey on 2 April 1934, into a Polish immigrant family."&lt;/ref&gt;&lt;ref name="mmp"&gt;{{citation|contribution=Paul Cohen|title=More Mathematical People|editor1-first=Donald J.|editor1-last=Albers|editor2-first=Gerald L.|editor2-last=Alexanderson|editor2-link=Gerald L. Alexanderson|editor3-first=Constance|editor3-last=Reid|editor3-link=Constance Reid|publisher=Harcourt Brace Jovanovich|year=1990|pages=42–58}}.&lt;/ref&gt; He graduated in 1950, at age 16, from [[Stuyvesant High School]] in [[New York City]].&lt;ref name="Stanford_obit"/&gt;&lt;ref name="mmp"/&gt;

Cohen next studied at the [[Brooklyn College]] from 1950 to 1953, but he left without earning his [[bachelor's degree]] when he learned that he could start his graduate studies at the [[University of Chicago]] with just two years of college. At [[Chicago]], Cohen completed his master's degree in mathematics in 1954 and his [[Doctor of Philosophy]] degree in 1958, under supervision of the Professor of Mathematics, [[Antoni Zygmund]]. The title of his doctoral thesis was ''Topics in the Theory of Uniqueness of Trigonometrical Series''.&lt;ref&gt;Paul J. Cohen (1958), ''[http://www.chronomaitre.org/cohen.pdf Topics in the theory of uniqueness of trigonometrical series]''.&lt;/ref&gt;

{{blockquote|In 1957, before the award of his doctorate, Cohen was appointed as an Instructor in Mathematics at the University of Rochester for a year. He then spent the academic year 1958–59 at the Massachusetts Institute of Technology before spending 1959–61 as a fellow at the Institute for Advanced Study at Princeton. These were years in which Cohen made a number of significant mathematical breakthroughs. In ''Factorization in group algebras'' (1959) he showed that any integrable function on a locally compact group is the convolution of two such functions, solving a problem posed by [[Walter Rudin]]. In ''On a conjecture of Littlewood and idempotent measures'' (1960) Cohen made a significant breakthrough in solving the [[Littlewood conjecture|Littlewood Conjecture]].&lt;ref&gt;{{MacTutor Biography|id=Cohen|title=Paul Joseph Cohen}}&lt;/ref&gt;}} 

On June 2, 1995 Cohen received an [[Honorary degree|honorary doctorate]] from the Faculty of Science and Technology at [[Uppsala University]], [[Sweden]] &lt;ref&gt;{{cite web|url=http://www.uu.se/en/about-uu/traditions/prizes/honorary-doctorates/|title=Honorary doctorates - Uppsala University, Sweden|author=|date=|website=www.uu.se|accessdate=21 March 2018}}&lt;/ref&gt;

==Contributions to mathematics==
Cohen is noted for developing a mathematical technique called '''[[forcing (mathematics)|forcing]]''', which he used to prove that neither the [[continuum hypothesis]] (CH) nor the [[axiom of choice]] can be proved from the standard [[Zermelo–Fraenkel axioms]] (ZF) of [[set theory]]. In conjunction with the earlier work of [[Kurt Gödel|Gödel]], this showed that both of these statements are [[logical independence|logically independent]] of the ZF axioms: these statements can be neither proved nor disproved from these axioms. In this sense, the continuum hypothesis is undecidable, and it is the most widely known example of a natural statement that is independent from the standard ZF axioms of set theory.

For his result on the continuum hypothesis, Cohen won the [[Fields Medal]] in mathematics in 1966, and also the [[National Medal of Science]] in 1967.&lt;ref&gt;{{cite web|url=https://www.nsf.gov/od/nms/recip_details.cfm?recip_id=80|title=The President's National Medal of Science: Recipient Details - NSF - National Science Foundation|author=|date=|website=www.nsf.gov|accessdate=21 March 2018}}&lt;/ref&gt; The Fields Medal that Cohen won continues to be the only Fields Medal to be awarded for a work in mathematical logic, as of 2018.

Apart from his work in set theory, Cohen also made many valuable contributions to analysis. He was awarded the [[Bôcher Memorial Prize]] in [[mathematical analysis]] in 1964 for his paper "On a conjecture by [[John Edensor Littlewood|Littlewood]] and [[idempotent measure]]s",&lt;ref&gt;{{cite journal|author=Cohen, Paul J.|title=On a conjecture of Littlewood and idempotent measures|journal=Amer. J. Math.|year=1960|volume=82|pages=191–212|mr=0133397|doi=10.2307/2372731}}&lt;/ref&gt; and lends his name to the [[Cohen–Hewitt factorization theorem]].

Cohen was a full professor of mathematics at [[Stanford University]], where he supervised [[Peter Sarnak]]'s graduate research, among those of other students. Cohen was an Invited Speaker at the [[International Congress of Mathematicians|ICM]] in 1962 in Stockholm and in 1966 in Moscow.

[[Angus MacIntyre]] of the [[Queen Mary University of London]] stated about Cohen: "He was dauntingly clever, and one would have had to be naive or exceptionally altruistic to put one's 'hardest problem' to the Paul I knew in the '60s." He went on to compare Cohen to [[Kurt Gödel]], saying: "Nothing more dramatic than their work has happened in the history of the subject."&lt;ref name="chronicle"&gt;{{cite news |publisher=[[San Francisco Chronicle]] |url=http://www.sfgate.com/cgi-bin/article.cgi?f=/c/a/2007/03/30/BAG8DOUKEG1.DTL |title=Paul Cohen -- Stanford professor, acclaimed mathematician |first=Keay |last=Davidson |date=2007-03-30 |accessdate=2007-10-31}}&lt;/ref&gt; Gödel himself wrote a letter to Cohen in 1963, a draft of which stated, "Let me repeat that it is really a delight to read your proof of the ind[ependence] of the cont[inuum] hyp[othesis]. I think that in all essential respects you have given the best possible proof &amp; this does not happen frequently. Reading your proof had a similarly pleasant effect on me as seeing a really good play."&lt;ref&gt;[[Solomon Feferman]], The Gödel Editorial Project: A synopsis [http://math.stanford.edu/~feferman/papers/Goedel-Project-Synopsis.pdf] p. 11.&lt;/ref&gt;

==On the continuum hypothesis==
While studying the continuum hypothesis, Cohen is quoted as saying in 1985 that he had "had the feeling that people thought the problem was hopeless, since there was no new way of constructing models of set theory. Indeed, they thought you had to be slightly crazy even to think about the problem."&lt;ref name="nytimes"&gt;{{cite news |work=[[The New York Times]] |title=Paul J. Cohen, Mathematics Trailblazer, Dies at 72 |first=Jeremy |last=Pearce |date=2007-04-02 |url=https://www.nytimes.com/2007/04/02/us/02cohen.html?_r=1&amp;oref=slogin |accessdate=2007-10-31}}&lt;/ref&gt;

"A point of view which the author [Cohen] feels may eventually come to be accepted is that CH is obviously false. The main reason one accepts the [[axiom of infinity]] is probably that we feel it absurd to think that the process of adding only one set at a time can exhaust the entire universe. Similarly with the higher axioms of infinity. Now &lt;math&gt;\aleph_1&lt;/math&gt; is the cardinality of the set of countable ordinals, and this is merely a special and the simplest way of generating a higher cardinal. The set &lt;math&gt;C&lt;/math&gt; [the continuum] is, in contrast, generated by a totally new and more powerful principle, namely the [[axiom of power set|power set axiom]]. It is unreasonable to expect that any description of a larger cardinal which attempts to build up that cardinal from ideas deriving from the [[axiom schema of replacement|replacement axiom]] can ever reach &lt;math&gt;C&lt;/math&gt;.

Thus &lt;math&gt;C&lt;/math&gt; is greater than &lt;math&gt;\aleph_n, \aleph_\omega, \aleph_a&lt;/math&gt;, where &lt;math&gt;a = \aleph_\omega&lt;/math&gt;, etc. This point of view regards &lt;math&gt;C&lt;/math&gt; as an incredibly rich set given to us by one bold new axiom, which can never be approached by any piecemeal process of construction. Perhaps later generations will see the problem more clearly and express themselves more eloquently."&lt;ref&gt;{{cite book | author=Cohen, P. |title=Set Theory and the continuum hypothesis |pages=151}}&lt;/ref&gt;

An "enduring and powerful product" of Cohen's work on the continuum hypothesis, and one that has been used by "countless mathematicians"&lt;ref name="nytimes"/&gt; is known as [[forcing (mathematics)|"forcing"]], and it is used to construct mathematical models to test a given hypothesis for truth or falsehood.

Shortly before his death, Cohen gave a lecture describing his solution to the problem of the continuum hypothesis at the Gödel centennial conference, in Vienna in 2006. A video of this lecture is now available online.&lt;ref&gt;{{YouTube|VBFLWk7k1Zo|Paul Cohen lecture video, six parts, Gödel Centennial, Vienna 2006}}&lt;/ref&gt;

==Selected publications==
*{{cite journal|last=Cohen |first=Paul J.|title=The independence of the continuum hypothesis|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|volume=50|issue=6|pages=1143–1148|date=December 1963|doi = 10.1073/pnas.50.6.1143 |pmid=16578557|pmc=221287|bibcode=1963PNAS...50.1143C}}
*{{cite journal|last=Cohen |first=Paul J.|title=The independence of the continuum hypothesis, II|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|volume=51|issue=1|pages=105–110|date=January 1964|doi=10.1073/pnas.51.1.105 |pmid=16591132|pmc=300611|bibcode=1964PNAS...51..105C}}

==See also==

*[[Cohen algebra]]

==References==
{{Reflist|30em}}

==Further reading==
*[[Akihiro Kanamori]], "[http://math.bu.edu/people/aki/14.pdf Cohen and Set Theory]", ''The Bulletin of Symbolic Logic'', Volume 14, Number 3, Sept. 2008.
* {{cite journal |last=Sarnak |first=Peter |authorlink=Peter Sarnak |date=December 2007 |title=Remembering Paul Cohen |journal=Maa Focus |volume=27 |issue=9 |pages=21–22 |publisher=Mathematical Association of America |location=Washington, DC |issn=0731-2040 |url=http://web.math.princeton.edu/sarnak/RememberingPaulCohen.pdf |format=PDF |accessdate=2009-05-31}}

==External links==
{{wikiquote}}
* {{MacTutor Biography|id=Cohen|title=Paul Joseph Cohen}}
* {{MathGenealogy |id=6479|title=Paul Joseph Cohen}}
* [http://paulcohen.org paulcohen.org] - a commemorative website celebrating the life of Paul Cohen
* [http://news-service.stanford.edu/news/2007/april4/cohen-040407.html Stanford obituary]

{{Set theory}}

{{Fields medalists}}
{{Winners of the National Medal of Science|math-stat-comp}}

{{Authority control}}

{{DEFAULTSORT:Cohen, Paul}}
[[Category:1934 births]]
[[Category:2007 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:American people of Polish-Jewish descent]]
[[Category:Brooklyn College alumni]]
[[Category:Fields Medalists]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:National Medal of Science laureates]]
[[Category:People from Long Branch, New Jersey]]
[[Category:Set theorists]]
[[Category:Stuyvesant High School alumni]]
[[Category:University of Chicago alumni]]
[[Category:Guggenheim Fellows]]
[[Category:Members of the American Philosophical Society]]</text>
      <sha1>dwpuuv9lzvja0m54qaf282jg35djrz9</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial mapping</title>
    <ns>0</ns>
    <id>56059449</id>
    <revision>
      <id>817068559</id>
      <parentid>816220170</parentid>
      <timestamp>2017-12-25T22:28:44Z</timestamp>
      <contributor>
        <username>Rentier</username>
        <id>454738</id>
      </contributor>
      <comment>added [[Category:Algebra]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1124">In algebra, a '''polynomial mapping''' &lt;math&gt;P: V \to W&lt;/math&gt; between vector spaces over an infinite field ''k'' is a [[polynomial]] in linear functionals with coefficients in ''W''; i.e., it can be written as
:&lt;math&gt;P(v) = \sum_{i_1, \dots, i_n} L_{i_1}(v) \cdots L_{i_n}(v) w_{i_1, \dots, i_n}&lt;/math&gt;
where &lt;math&gt;L_j: V \to k&lt;/math&gt; are linear functionals. For example, if &lt;math&gt;W = k^m&lt;/math&gt;, then it can also be expressed as &lt;math&gt;P(v) = (P_1(v), \dots, P_m(v))&lt;/math&gt; where &lt;math&gt;P_i&lt;/math&gt; are (scalar-valued) [[polynomial function]]s on ''V''.

When ''V'', ''W'' are finite-dimensional vector spaces and are viewed as algebraic varieties, then a polynomial mapping is precisely a [[morphism of algebraic varieties]].

One fundamental outstanding question regarding polynomial mapping is the [[Jacobian conjecture]], which concerns the sufficiency of a polynomial mapping to be invertible.

== See also ==
*[[Polynomial functor]]

== References ==
*[[Claudio Procesi]] (2007) ''Lie Groups: an approach through invariants and representation'', Springer, {{isbn|9780387260402}}.

{{algebra-stub}}

[[Category:Algebra]]</text>
      <sha1>2tdtl72qfxp50k6q2mm0bfqlzck1tf9</sha1>
    </revision>
  </page>
  <page>
    <title>Polytope families</title>
    <ns>0</ns>
    <id>25728240</id>
    <revision>
      <id>852872475</id>
      <parentid>842852874</parentid>
      <timestamp>2018-07-31T23:19:44Z</timestamp>
      <contributor>
        <username>Christian75</username>
        <id>1306352</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8119">&lt;noinclude&gt;&lt;!-- NOTE: This page is transcluded in other pages. If you add any remarks outside of the main table, be sure to place it within one of the noinclude ... /noinclude containers. --&gt;
There are several families of symmetric [[polytope]]s with irreducible symmetry which have a member in more than one dimensionality. These are tabulated here with [[Petrie polygon]] projection graphs and [[Coxeter-Dynkin diagram]]s.
&lt;/noinclude&gt;
{| class="wikitable collapsible uncollapsed" 
!colspan=12|Table of irreducible polytope families
|-
!Family&lt;br&gt;[[Uniform polytope|n]]
! n-[[simplex]]
! n-[[hypercube]]
! n-[[orthoplex]]
! n-[[demihypercube|demicube]]
! [[Uniform 1 k2 polytope|1&lt;sub&gt;k2&lt;/sub&gt;]]
! [[Uniform 2 k1 polytope|2&lt;sub&gt;k1&lt;/sub&gt;]]
! [[Semiregular k 21 polytope|k&lt;sub&gt;21&lt;/sub&gt;]]
!colspan=2|[[pentagonal polytope]]
|-
![[Coxeter group|Group]]
!colspan=1|A&lt;sub&gt;n&lt;/sub&gt;
!colspan=2|B&lt;sub&gt;n&lt;/sub&gt;
!colspan=1|
{| width=100%
| BGCOLOR="#f0e0e0"| I&lt;sub&gt;2&lt;/sub&gt;(p)
| D&lt;sub&gt;n&lt;/sub&gt;
|}
!colspan=3|
{| width=100%
| BGCOLOR="#f0e0e0"| E&lt;sub&gt;6&lt;/sub&gt;
| BGCOLOR="#f0e0e0"| E&lt;sub&gt;7&lt;/sub&gt; 
| BGCOLOR="#f0e0e0"| E&lt;sub&gt;8&lt;/sub&gt; 
| BGCOLOR="#e0f0e0"| F&lt;sub&gt;4&lt;/sub&gt; 
| BGCOLOR="#e0e0f0"| G&lt;sub&gt;2&lt;/sub&gt;
|}
!colspan=2|H&lt;sub&gt;n&lt;/sub&gt;
|-
! [[Polygon|2]]
|align=center|[[File:2-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node}}
[[Equilateral triangle|Triangle]]
|colspan=2 align=center|[[File:2-cube.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node}}
[[Square]]
|align=center BGCOLOR="#f0e0e0"|[[File:Regular polygon 7.svg|80px]]&lt;br&gt;{{CDD|node_1|p|node}}&lt;br&gt;[[Regular polygon|p-gon]]&lt;br&gt;(example: [[Heptagon|p=7]])
|align=center colspan=3 BGCOLOR="#e0e0f0"|[[File:Regular polygon 6.svg|80px]]&lt;br&gt;{{CDD|node_1|6|node}}&lt;br&gt;[[Hexagon]]
|colspan=2 align=center|[[File:Regular polygon 5.svg|80px]]&lt;br&gt;{{CDD|node_1|5|node}}&lt;br&gt;[[Pentagon]]
|- 
! [[Polyhedron|3]]
|align=center|[[File:3-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node}}&lt;br&gt;[[Tetrahedron]]
|align=center|[[File:3-cube t0.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node}}&lt;br&gt;[[Cube]]
|align=center|[[File:3-cube t2.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|4|node}}&lt;br&gt;[[Octahedron]]
|align=center|[[File:3-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch}}&lt;br&gt;[[Tetrahedron]]
|align=center colspan=3|&amp;nbsp;
|align=center|[[File:Dodecahedron H3 projection.svg|80px]]&lt;br&gt;{{CDD|node_1|5|node|3|node}}&lt;br&gt;[[Dodecahedron]]
|align=center|[[File:Icosahedron H3 projection.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|5|node}}&lt;br&gt;[[Icosahedron]]
|-
! [[Polychoron|4]]
|align=center|[[File:4-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node}}&lt;br&gt;[[5-cell]]
|align=center|[[File:4-cube t0.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node}}
[[Tesseract]]
|align=center|[[File:4-cube t3.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|4|node}}&lt;br&gt;[[16-cell]]
|align=center|[[File:4-demicube t0 D4.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea}}
[[Demitesseract]]
|align=center colspan=3 BGCOLOR="#e0f0e0"|[[File:24-cell t0 F4.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|4|node|3|node}}&lt;br&gt;[[24-cell]]
|align=center|[[File:120-cell graph H4.svg|80px]]&lt;br&gt;{{CDD|node_1|5|node|3|node|3|node}}&lt;br&gt;[[120-cell]]
|align=center|[[File:600-cell graph H4.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|5|node}}&lt;br&gt;[[600-cell]]
|- 
! [[5-polytope|5]]
|align=center|[[File:5-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node}}&lt;br&gt;[[5-simplex]]
|align=center|[[File:5-cube graph.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node}}&lt;br&gt;[[5-cube]]
|align=center|[[File:5-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|4|node}}&lt;br&gt;[[5-orthoplex]]
|align=center|[[File:5-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea}}&lt;br&gt;[[5-demicube]]
|align=center colspan=3|&amp;nbsp;
|align=center colspan=1|&amp;nbsp;
|
|- 
! [[6-polytope|6]]
|align=center|[[File:6-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[6-simplex]]
|align=center|[[File:6-cube graph.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[6-cube]]
|align=center|[[File:6-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|4|node}}&lt;br&gt;[[6-orthoplex]]
|align=center|[[File:6-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea|3a|nodea}}&lt;br&gt;[[6-demicube]]
|align=center BGCOLOR="#f0e0e0"|[[File:Up 1 22 t0 E6.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|branch_01lr|3a|nodea|3a|nodea}}&lt;br&gt;[[Gosset 1 22 polytope|1&lt;sub&gt;22&lt;/sub&gt;]]
|colspan=2 align=center BGCOLOR="#f0e0e0"|[[File:E6 graph.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|branch|3a|nodea|3a|nodea_1}}&lt;br&gt;[[Gosset 2 21 polytope|2&lt;sub&gt;21&lt;/sub&gt;]]
|align=center colspan=1|&amp;nbsp;
|
|- 
! [[7-polytope|7]]
|align=center|[[File:7-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[7-simplex]]
|align=center|[[File:7-cube graph.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[7-cube]]
|align=center|[[File:7-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|4|node}}&lt;br&gt;[[7-orthoplex]]
|align=center|[[File:7-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea|3a|nodea|3a|nodea}}&lt;br&gt;[[7-demicube]]
|align=center BGCOLOR="#f0e0e0"|[[File:Gosset 1 32 petrie.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|nodea|3a|branch_01lr|3a|nodea|3a|nodea}}&lt;br&gt;[[Gosset 1 32 polytope|1&lt;sub&gt;32&lt;/sub&gt;]]
|align=center BGCOLOR="#f0e0e0"|[[File:Gosset 2 31 polytope.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|nodea|3a|branch|3a|nodea|3a|nodea_1}}&lt;br&gt;[[Gosset 2 31 polytope|2&lt;sub&gt;31&lt;/sub&gt;]]
|align=center BGCOLOR="#f0e0e0"|[[File:E7 graph.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|nodea|3a|nodea|3a|branch|3a|nodea|3a|nodea}}&lt;br&gt;[[Gosset 3 21 polytope|3&lt;sub&gt;21&lt;/sub&gt;]]
|align=center colspan=1|&amp;nbsp;
|
|- 
! [[8-polytope|8]]
|align=center|[[File:8-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[8-simplex]]
|align=center|[[File:8-cube.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[8-cube]]
|align=center|[[File:8-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|4|node}}&lt;br&gt;[[8-orthoplex]]
|align=center|[[File:8-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea}}&lt;br&gt;[[8-demicube]]
|align=center BGCOLOR="#f0e0e0"|[[File:Gosset 1 42 polytope petrie.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|nodea|3a|nodea|3a|branch_01lr|3a|nodea|3a|nodea}}&lt;br&gt;[[Gosset 1 42 polytope|1&lt;sub&gt;42&lt;/sub&gt;]]
|align=center BGCOLOR="#f0e0e0"|[[File:2 41 polytope petrie.svg|80px]]&lt;br&gt;{{CDD|nodea|3a|nodea|3a|nodea|3a|nodea|3a|branch|3a|nodea|3a|nodea_1}}&lt;br&gt;[[Gosset 2 41 polytope|2&lt;sub&gt;41&lt;/sub&gt;]]
|align=center BGCOLOR="#f0e0e0"|[[File:Gosset 4 21 polytope petrie.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|nodea|3a|nodea|3a|nodea|3a|branch|3a|nodea|3a|nodea}}&lt;br&gt;[[Gosset 4 21 polytope|4&lt;sub&gt;21&lt;/sub&gt;]]
|align=center colspan=1|&amp;nbsp;
|
|- 
! [[9-polytope|9]]
|align=center|[[File:9-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[9-simplex]]
|align=center|[[File:9-cube.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[9-cube]]
|align=center|[[File:9-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|3|node|4|node}}&lt;br&gt;[[9-orthoplex]]
|align=center|[[File:9-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea}}&lt;br&gt;[[9-demicube]]
|align=center colspan=5|&amp;nbsp;
|-
! [[10-polytope|10]]
|align=center|[[File:10-simplex t0.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[10-simplex]]
|align=center|[[File:10-cube.svg|80px]]&lt;br&gt;{{CDD|node_1|4|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node}}&lt;br&gt;[[10-cube]]
|align=center|[[File:10-orthoplex.svg|80px]]&lt;br&gt;{{CDD|node_1|3|node|3|node|3|node|3|node|3|node|3|node|3|node|3|node|4|node}}&lt;br&gt;[[10-orthoplex]]
|align=center|[[File:10-demicube.svg|80px]]&lt;br&gt;{{CDD|nodea_1|3a|branch|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea|3a|nodea}}&lt;br&gt;[[10-demicube]]
|align=center colspan=5|&amp;nbsp;
|}
&lt;noinclude&gt;
{{Polytopes}}

[[Category:Polytopes]]
[[Category:Multi-dimensional geometry]]
&lt;/noinclude&gt;</text>
      <sha1>5zs5hstimp5qjbrv54x0qv46awj3rwj</sha1>
    </revision>
  </page>
  <page>
    <title>Pseudoisotopy theorem</title>
    <ns>0</ns>
    <id>25051489</id>
    <revision>
      <id>850193123</id>
      <parentid>794876689</parentid>
      <timestamp>2018-07-14T08:42:26Z</timestamp>
      <contributor>
        <username>Cloudz679</username>
        <id>2126435</id>
      </contributor>
      <comment>article now exists on English Wikipedia</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1928">In [[mathematics]], the '''pseudoisotopy theorem''' is a theorem of [[Jean Cerf]]'s which refers to the connectivity of a group of diffeomorphisms of a manifold.

== Statement ==

Given a [[differentiable manifold]] ''M'' (with or without boundary), a pseudo-isotopy diffeomorphism of ''M'' is a [[diffeomorphism]] of ''M''&amp;nbsp;&amp;times;&amp;nbsp;[0,&amp;nbsp;1] which restricts to the identity on &lt;math&gt;M \times \{0\} \cup \partial M \times [0,1]&lt;/math&gt;.

Given &lt;math&gt; f : M \times [0,1] \to M \times [0,1]&lt;/math&gt; a pseudo-isotopy diffeomorphism, its restriction to &lt;math&gt;M \times \{1\}&lt;/math&gt; is a diffeomorphism &lt;math&gt;g&lt;/math&gt; of ''M''.  We say ''g'' is ''pseudo-isotopic to the identity''. One should think of a pseudo-isotopy as something that is almost an [[homotopy|isotopy]]—the obstruction to ''&amp;fnof;'' being an isotopy of ''g'' to the identity is whether or not ''&amp;fnof;'' preserves the level-sets &lt;math&gt;M \times \{t\}&lt;/math&gt; for &lt;math&gt; t \in [0,1]&lt;/math&gt;.

Cerf's theorem states that, provided ''M'' is [[Simply connected space|simply-connected]] and dim(''M'')&amp;nbsp;&amp;ge;&amp;nbsp;5, the group of pseudo-isotopy diffeomorphisms of ''M'' is connected.  Equivalently, a [[diffeomorphism]] of ''M'' is isotopic to the identity if and only if it is pseudo-isotopic to the identity.&lt;ref name="Cerf" /&gt;

== Relation to Cerf theory ==

The starting point of the proof is to think of the height function as a 1-parameter family of smooth functions on ''M'' by considering the function &lt;math&gt;\pi_{[0,1]} \circ f_t&lt;/math&gt;.  One then applies [[Cerf theory]].&lt;ref name="Cerf"&gt;{{cite journal |first=J. |last=Cerf |title=La stratification naturelle des espaces de fonctions différentiables réelles et le théorème de la pseudo-isotopie |journal=Inst. Hautes Études Sci. Publ. Math. |volume=39 |year=1970 |pages=5–173 }}&lt;/ref&gt;

== References ==
{{Reflist}}

[[Category:Theorems in differential topology]]
[[Category:Singularity theory]]</text>
      <sha1>es0hslwxe8hpopd77x4jjii7od5y4vx</sha1>
    </revision>
  </page>
  <page>
    <title>Quasi-invariant measure</title>
    <ns>0</ns>
    <id>2749048</id>
    <revision>
      <id>823928266</id>
      <parentid>696359593</parentid>
      <timestamp>2018-02-04T07:52:35Z</timestamp>
      <contributor>
        <ip>67.198.37.16</ip>
      </contributor>
      <comment>See also [[Invariant measure]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2342">{{Unreferenced|date=December 2009}}
In [[mathematics]], a '''quasi-invariant measure''' ''μ'' with respect to a transformation ''T'', from a [[measure space]] ''X'' to itself, is a [[measure (mathematics)|measure]] which, roughly speaking, is multiplied by a [[numerical function]] of ''T''. An important class of examples occurs when ''X'' is a [[smooth manifold]] ''M'', ''T'' is a [[diffeomorphism]] of ''M'', and ''μ'' is any measure that locally is a [[measure with base]] the [[Lebesgue measure]] on [[Euclidean space]]. Then the effect of ''T'' on μ is locally expressible as multiplication by the [[Jacobian matrix and determinant|Jacobian]] determinant of the derivative ([[pushforward (differential)|pushforward]]) of ''T''.

To express this idea more formally in [[measure theory]] terms, the idea is that the [[Radon–Nikodym derivative]] of the transformed measure μ&amp;prime; with respect to ''μ'' should exist everywhere; or that the two measures should be [[Equivalence (measure theory)|equivalent]] (i.e. mutually [[absolutely continuous]]):

:&lt;math&gt;\mu' = T_{*} (\mu) \approx \mu.&lt;/math&gt;

That means, in other words, that ''T'' preserves the concept of a set of [[measure zero]]. Considering the whole equivalence class of measures ''ν'', equivalent to ''μ'', it is also the same to say that ''T'' preserves the class as a whole, mapping any such measure to another such. Therefore, the concept of quasi-invariant measure is the same as ''invariant measure class''.

In general, the 'freedom' of moving within a measure class by multiplication gives rise to [[Oseledets theorem#Cocycles|cocycles]], when transformations are composed.

As an example, [[Gaussian measure]] on [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt; is not invariant under translation (like Lebesgue measure is), but is quasi-invariant under all translations.

It can be shown that if ''E'' is a [[separable space|separable]] [[Banach space]] and ''μ'' is a [[Locally finite measure|locally finite]] [[Borel measure]] on ''E'' that is quasi-invariant under all translations by elements of ''E'', then either dim(''E'')&amp;nbsp;&amp;lt;&amp;nbsp;+∞ or ''μ'' is the [[trivial measure]] ''μ''&amp;nbsp;≡&amp;nbsp;0.

== See also ==
* [[Invariant measure]]

{{DEFAULTSORT:Quasi-Invariant Measure}}
[[Category:Measures (measure theory)]]
[[Category:Dynamical systems]]</text>
      <sha1>8kx8hk51n7q7es3eb7ds4tfhtnq9mmm</sha1>
    </revision>
  </page>
  <page>
    <title>Renormalization</title>
    <ns>0</ns>
    <id>291453</id>
    <revision>
      <id>854982109</id>
      <parentid>854981328</parentid>
      <timestamp>2018-08-15T03:13:45Z</timestamp>
      <contributor>
        <username>Kprainville</username>
        <id>33747069</id>
      </contributor>
      <minor/>
      <comment>Removed an incorrect capitilization and removed a duplicated hyperlink to a term already linked in the same article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="56005">{{Renormalization and regularization}}
{{Quantum field theory|cTopic=Tools}}
'''Renormalization''' is a collection of techniques in [[quantum field theory]], the [[statistical mechanics]] of fields, and the theory of [[self-similarity|self-similar]] geometric structures, that are used to treat [[infinity|infinities]] arising in calculated quantities by altering values of quantities to compensate for effects of their '''self-interactions'''&lt;!--boldface per WP:R#PLA; 'Self-interaction' and 'Self-interactions' redirect here--&gt;. However, even if it were the case that no infinities arise in loop diagrams in quantum field theory, it can be shown that renormalization of mass and fields appearing in the original [[Lagrangian (field theory)|Lagrangian]] is necessary.&lt;ref&gt;See e.g., Weinberg vol I, chapter 10.&lt;/ref&gt;

For example, an [[electron]] theory may begin by postulating an electron with an initial mass and charge. In [[quantum field theory]] a cloud of [[Virtual particle|virtual particles]], such as [[Photon|photons]], [[Positron|positrons]], and others surrounds and interacts with the initial electron. Accounting for the interactions of the surrounding particles (e.g. collisions at different energies) shows that the electron-system behaves as if it had a different mass and charge than initially postulated. Renormalization, in this example, mathematically replaces the initially postulated mass and charge of an electron with the experimentally observed mass and charge.  Mathematics and experiments prove that positrons and more massive particles like [[Proton|protons]], exhibit ''precisely the same'' observed charge as the electron - even in the presence of much stronger interactions and more intense clouds of virtual particles. 

Renormalization specifies relationships between parameters in the theory when parameters describing large distance scales differ from parameters describing small distance scales. In high-energy particle accelerators like the [[Large Hadron Collider|CERN Large Hadron Collider]] the concept named [[Pileup (disambiguation)|pileup]] occurs when undesirable proton-proton collisions interact with data collection for simultaneous, nearby desirable measurements. Physically, the pileup of contributions from an infinity of scales involved in a problem may then result in further infinities. When describing space-time as a [[Space-time continuum|continuum]], certain statistical and quantum mechanical constructions are not [[well-defined]]. To define them, or make them unambiguous, a continuum limit must carefully remove "construction scaffolding" of lattices at various scales. Renormalization procedures are based on the requirement that certain physical quantities (such as the mass and charge of an electron) equal observed (experimental) values. That is, the experimental value of the physical quantity yields practical applications, but due to their empirical nature the observed measurement represents areas of quantum field theory that require deeper derivation from theoretical bases.

Renormalization was first developed in [[quantum electrodynamics]] (QED) to make sense of [[infinity|infinite]] integrals in [[perturbation theory]]. Initially viewed as a suspect provisional procedure even by some of its originators, renormalization eventually was embraced as an important and [[self-consistent]] actual mechanism of scale physics in several fields of [[physics]] and [[mathematics]]. 

Today, the point of view has shifted: on the basis of the breakthrough [[renormalization group]] insights of [[Nikolay Bogolyubov]] and [[Kenneth G. Wilson|Kenneth Wilson]], the focus is on variation of physical quantities across contiguous scales, while distant scales are related to each other through "effective" descriptions. ''All scales'' are linked in a broadly systematic way, and the actual physics pertinent to each is extracted with the suitable specific computational techniques appropriate for each. Wilson clarified which variables of a system are crucial and which are redundant.

Renormalization is distinct from [[Regularization (physics)|regularization]], another technique to control infinities by assuming the existence of new unknown physics at new scales.

== Self-interactions in classical physics ==
[[Image:Renormalized-vertex.png|thumbnail|300px|Figure 1. Renormalization in quantum electrodynamics: The simple electron/photon interaction that determines the electron's charge at one renormalization point is revealed to consist of more complicated interactions at another.]]
The problem of infinities first arose in the [[classical electrodynamics]] of [[Elementary particle|point particles]] in the 19th and early 20th century.

The mass of a charged particle should include the mass-energy in its electrostatic field ([[electromagnetic mass]]). Assume that the particle is a charged spherical shell of radius {{mvar|r&lt;sub&gt;e&lt;/sub&gt;}}. The mass–energy in the field is

:&lt;math&gt;m_\text{em} = \int \frac{1}{2} E^2 \, dV = \int_{r_e}^\infty \frac{1}{2} \left( \frac{q}{4\pi r^2} \right)^2 4\pi r^2 \, dr = \frac{q^2}{8\pi r_e},&lt;/math&gt;

which becomes infinite as {{math|''r''&lt;sub&gt;e&lt;/sub&gt; → 0}}. This implies that the point particle would have infinite [[inertia]], making it unable to be accelerated. Incidentally, the value of {{mvar|r&lt;sub&gt;e&lt;/sub&gt;}} that makes &lt;math&gt;m_\text{em}&lt;/math&gt; equal to the electron mass is called the [[classical electron radius]], which (setting &lt;math&gt;q = e&lt;/math&gt; and restoring factors of {{mvar|c}} and &lt;math&gt;\varepsilon_0&lt;/math&gt;) turns out to be

:&lt;math&gt;r_e = \frac{e^2}{4\pi\varepsilon_0 m_e c^2} = \alpha \frac{\hbar}{m_e c} \approx 2.8 \times 10^{-15}~\text{m},&lt;/math&gt;

where &lt;math&gt;\alpha \approx 1/137&lt;/math&gt; is the [[fine-structure constant]], and &lt;math&gt;\hbar/(m_e c)&lt;/math&gt; is the [[Compton wavelength]] of the electron.

Renormalization: The total effective mass of a spherical charged particle includes the actual bare mass of the spherical shell (in addition to the mass mentioned above associated with its electric field). If the shell's bare mass is allowed to be negative, it might be possible to take a consistent point limit.{{Citation needed|date=March 2015}} This was called ''renormalization'', and [[Hendrik Lorentz|Lorentz]] and [[Max Abraham|Abraham]] attempted to develop a classical theory of the electron this way. This early work was the inspiration for later attempts at [[regularization (physics)|regularization]] and renormalization in quantum field theory.

(See also [[regularization (physics)]] for an alternative way to remove infinities from this classical problem, assuming new physics exists at small scales.)

When calculating the [[electromagnetism|electromagnetic]] interactions of [[electric charge|charged]] particles, it is tempting to ignore the ''[[back-reaction]]'' of a particle's own field on itself. (Analogous to the [[back-EMF]] of circuit analysis.)  But this back-reaction is necessary to explain the friction on charged particles when they emit radiation. If the electron is assumed to be a point, the value of the back-reaction diverges, for the same reason that the mass diverges, because the field is [[inverse-square law|inverse-square]].

The [[Abraham–Lorentz force|Abraham–Lorentz theory]] had a noncausal "pre-acceleration." Sometimes an electron would start moving ''before'' the force is applied. This is a sign that the point limit is inconsistent.

The trouble was worse in classical field theory than in quantum field theory, because in quantum field theory a charged particle experiences [[Zitterbewegung]] due to interference with virtual particle-antiparticle pairs, thus effectively smearing out the charge over a region comparable to the Compton wavelength. In quantum electrodynamics at small coupling, the electromagnetic mass only diverges as the logarithm of the radius of the particle.

== Divergences in quantum electrodynamics ==
{{anchor|renormalization_loop_divergence}}
[[Image:vacuum polarization.svg|thumb|200px|(a) Vacuum polarization, a.k.a. charge screening. This loop has a logarithmic ultraviolet divergence.]]
[[Image:selfE.svg|thumb|200px|(b) Self-energy diagram in QED]]
[[Image:Penguin diagram.JPG|thumb|200px|(c) Example of a “penguin” diagram]]

When developing [[quantum electrodynamics]] in the 1930s, [[Max Born]], [[Werner Heisenberg]], [[Pascual Jordan]], and [[Paul Dirac]] discovered that in perturbative  corrections  many integrals were divergent (see [[The problem of infinities]]).

One way of describing the [[perturbation theory (quantum mechanics)|perturbation theory]] corrections' divergences was discovered in 1947–49 by&lt;!--in chronological order--&gt; [[Hans Kramers]]&lt;!--June 1947--&gt;,&lt;ref&gt;Kramers presented his work at the 1947 [[Shelter Island Conference]], repeated in 1948 at the [[Solvay Conference]]. The latter did not appear in print until the Proceedings of the Solvay Conference, published in 1950 (see Laurie M. Brown (ed.), ''Renormalization: From Lorentz to Landau (and Beyond)'', Springer, 2012, p. 53). Kramers' approach was [[nonrelativistic]] (see [[Jagdish Mehra]], Helmut Rechenberg, ''The Conceptual Completion and Extensions of Quantum Mechanics 1932-1941. Epilogue: Aspects of the Further Development of Quantum Theory 1942-1999: Volumes 6, Part 2'', Springer, 2001, p. 1050).&lt;/ref&gt; [[Hans Bethe]]&lt;!--August 1947--&gt;,&lt;ref&gt;{{cite journal |author=H. Bethe |authorlink=Hans Bethe |year=1947 |title=The Electromagnetic Shift of Energy Levels |journal=[[Physical Review]] |volume=72 |pages=339–341 |doi=10.1103/PhysRev.72.339 |bibcode=1947PhRv...72..339B |issue=4}}&lt;/ref&gt; 
[[Julian Schwinger]]&lt;!--February 1948--&gt;,&lt;ref&gt;{{cite journal |author=Schwinger, J. |title=On quantum-electrodynamics and the magnetic moment of the electron |journal=[[Physical Review]] |volume=73 |pages=416–417 |year=1948}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Schwinger, J. |series=Quantum Electrodynamics |title=I. A covariant formulation |journal=[[Physical Review]] |volume=74 |pages=1439–1461 |year=1948}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Schwinger, J. |series=Quantum Electrodynamics |title=II. Vacuum polarization and self-energy |journal=[[Physical Review]] |volume=75 |pages=651–679 |year=1949}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Schwinger, J. |series=Quantum Electrodynamics |title=III. The electromagnetic properties of the electron radiative corrections to scattering |journal=[[Physical Review]] |volume=76 |pages=790–817 |year=1949}}&lt;/ref&gt; [[Richard Feynman]]&lt;!--April 1948--&gt;,&lt;ref&gt;{{cite journal |first=Richard P. |last=Feynman |title=Space-time approach to non-relativistic quantum mechanics |journal=[[Reviews of Modern Physics]] |volume=20 |pages=367–387 |year=1948 |doi=10.1103/RevModPhys.20.367 |bibcode=1948RvMP...20..367F |issue=2}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Feynman  |first= Richard P. |title=A relativistic cut-off for classical electrodynamics   |journal=[[Physical Review]] |volume=74  |issue=8 |pp=939–946 |year=1948  |doi=10.1103/PhysRev.74.939 |bibcode=1948PhRv...74..939F}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |first=Richard P. |last=Feynman |title=A relativistic cut-off for quantum electrodynamics |journal=[[Physical Review]] |volume=74 |pages=1430–1438 |year=1948 |doi=10.1103/PhysRev.74.1430 |bibcode=1948PhRv...74.1430F |issue=10}}&lt;/ref&gt; and [[Shin'ichiro Tomonaga]]&lt;!--July 1948 (Koba–Tomonaga); according to S. S. Schweber, ''QED'', 1994, p. 269, Koba–Tomonaga contains the crucial calculation--&gt;,&lt;ref&gt;Tomonaga, S. (1946) "On a Relativistically Invariant Formulation of the Quantum Theory of Wave Fields." ''Prog. Theor. Phys.'' '''1''', 27–42.&lt;/ref&gt;&lt;ref&gt;Koba, Z., Tati, T. and Tomonaga, S. (1947) "On a Relativistically Invariant Formulation of the Quantum Theory of Wave Fields. II." ''Prog. Theor. Phys.'' '''2''', 101–116.&lt;/ref&gt;&lt;ref&gt; Koba, Z., Tati, T. and Tomonaga, S. (1947) "On a Relativistically Invariant Formulation of the Quantum Theory of Wave Fields. III." ''Prog. Theor. Phys.'' '''2''', 198–208.&lt;/ref&gt;&lt;ref&gt;Kanesawa, S. and Tomonaga, S. (1948) "On a Relativistically Invariant Formulation of the Quantum Theory of Wave Fields. IV." ''Prog. Theor. Phys.'' '''3''', 1–13.&lt;/ref&gt;&lt;ref&gt;Kanesawa, S. and Tomonaga, S. "On a Relativistically Invariant Formulation of the Quantum Theory of Wave Fields. V." ''Prog. Theor. Phys.'' '''3''', 101–113 (1948)&lt;/ref&gt;&lt;ref&gt;Koba, Z. and Tomonaga, S. (1948) "On Radiation Reactions in Collision Processes. I." ''Prog. Theor. Phys.'' '''3''', 290–303&lt;/ref&gt;&lt;ref&gt;Tomonaga, S. and [[J. Robert Oppenheimer|Oppenheimer, J. R.]] (1948) "On Infinite Field Reactions in Quantum Field Theory." ''Phys. Rev.'' '''74''', 224–225.&lt;/ref&gt; and systematized by [[Freeman Dyson]] in 1949.&lt;ref&gt;{{cite journal |author=Dyson, F. J. |title=The radiation theories of Tomonaga, Schwinger, and Feynman |journal=Phys. Rev. |volume=75 |pages=486–502 |year=1949|doi=10.1103/PhysRev.75.486 |issue=3 |bibcode=1949PhRv...75..486D }}&lt;/ref&gt; The divergences appear in radiative corrections  involving [[Feynman diagram]]s with closed ''loops'' of [[virtual particle]]s in them.

While virtual particles obey [[conservation of energy]] and [[momentum]], they can have any energy and momentum, even one that is not allowed by the relativistic [[energy–momentum relation]] for the observed mass of that particle (that is, &lt;math&gt;E^2 - p^2&lt;/math&gt; is not necessarily the squared mass of the particle in that process, e.g. for a photon it could be nonzero). Such a particle is called [[on shell|off-shell]]. When there is a loop, the momentum of the particles involved in the loop is not uniquely determined by the energies and momenta of incoming and outgoing particles. A variation in the energy of one particle in the loop can be balanced by an equal and opposite change in the energy of another particle in the loop, without affecting the incoming and outgoing particles. Thus many variations are possible. So to find the amplitude for the loop process, one must [[integral|integrate]] over ''all'' possible combinations of energy and momentum that could travel around the loop.

These integrals are often ''divergent'', that is, they give infinite answers.  The divergences that are significant are the "[[ultraviolet divergence|ultraviolet]]" (UV) ones. An ultraviolet divergence can be described as one that comes from
* the region in the integral where all particles in the loop have large energies and momenta,
* very short [[wavelength]]s and high-[[frequency|frequencies]] fluctuations of the fields, in the [[Path integral formulation|path integral]] for the field,
* very short proper-time between particle emission and absorption, if the loop is thought of as a sum over particle paths.

So these divergences are short-distance, short-time phenomena.

Shown in the pictures at the right margin, there are exactly three one-loop divergent loop diagrams in quantum electrodynamics:&lt;ref&gt;{{cite book |author1-link=Michael E. Peskin |first1=Michael E. |last1=Peskin |first2=Daniel V. |last2=Schroeder |title=An Introduction to Quantum Field Theory |publisher=Addison-Wesley |location=Reading, |year=1995 |at=Chapter&amp;nbsp;10}}&lt;/ref&gt;
:(a) A photon creates a virtual electron–[[positron]] pair, which then annihilates. This is a [[vacuum polarization]] diagram.
:(b) An electron quickly emits and reabsorbs a virtual photon, called a [[self-energy]].
:(c) An electron emits a photon, emits a second photon, and reabsorbs the first. This process is shown in the section below in figure&amp;nbsp;2, and it is called a ''[[vertex renormalization]]''. The Feynman diagram for this is also called a “[[penguin diagram]]” due to its shape remotely resembling a penguin (with the initial and final state electrons as the arms and legs, the second photon as the body and the first looping photon as the head).

The three divergences correspond to the three parameters in the theory under consideration:
# The field normalization Z.
# The mass of the electron.
# The charge of the electron.

The second class of divergence called an [[infrared divergence]], is due to massless particles, like the photon. Every process involving charged particles emits infinitely many coherent photons of infinite wavelength, and the amplitude for emitting any finite number of photons is zero. For photons, these divergences are well understood. For example, at the 1-loop order, the [[vertex function]] has both ultraviolet and ''infrared'' divergences. In contrast to the ultraviolet divergence, the infrared divergence does not require the renormalization of a parameter in the theory involved. The infrared divergence of the vertex diagram is removed by including a diagram similar to the vertex diagram with the following important difference: the photon connecting the two legs of the electron is cut and replaced by two [[on-shell]] (i.e. real) photons whose wavelengths tend to infinity; this diagram is equivalent to the [[bremsstrahlung]] process. This additional diagram must be included because there is no physical way to distinguish a zero-energy photon flowing through a loop as in the vertex diagram and zero-energy photons emitted through [[bremsstrahlung]]. From a mathematical point of view, the IR divergences can be regularized by assuming fractional differentiation w.r.t. a parameter, for example:

:&lt;math&gt; \left( p^2 - a^2 \right)^{\frac{1}{2}} &lt;/math&gt;

is well defined at {{math|''p'' {{=}} ''a''}} but is UV divergent; if we take the {{frac|3|2}}-th [[fractional derivative]] with respect to {{math|−''a''&lt;sup&gt;2&lt;/sup&gt;}}, we obtain the IR divergence

:&lt;math&gt; \frac{1}{p^2 - a^2},&lt;/math&gt;

so we can cure IR divergences by turning them into UV divergences.{{clarify|date=May 2012}}

=== A loop divergence ===
[[Image:Loop-diagram.png|thumbnail|250px|Figure 2. A diagram contributing to electron–electron scattering in QED. The loop has an ultraviolet divergence.]]
The diagram in Figure 2 shows one of the several one-loop contributions to electron–electron scattering in QED. The electron on the left side of the diagram, represented by the solid line, starts out with 4-momentum {{math|''p&lt;sup&gt;μ&lt;/sup&gt;''}} and ends up with 4-momentum {{math|''r&lt;sup&gt;μ&lt;/sup&gt;''}}. It emits a virtual photon carrying {{math|''r&lt;sup&gt;μ&lt;/sup&gt;'' − ''p&lt;sup&gt;μ&lt;/sup&gt;''}} to transfer energy and momentum to the other electron.  But in this diagram, before that happens, it emits another virtual photon carrying 4-momentum {{math|''q&lt;sup&gt;μ&lt;/sup&gt;''}}, and it reabsorbs this one after emitting the other virtual photon. Energy and momentum conservation do not determine the 4-momentum {{math|''q&lt;sup&gt;μ&lt;/sup&gt;''}} uniquely, so all possibilities contribute equally and we must integrate.

This diagram's amplitude ends up with, among other things, a factor from the loop of

:&lt;math&gt;-ie^3 \int \frac{d^4 q}{(2\pi)^4} \gamma^\mu \frac{i (\gamma^\alpha (r - q)_\alpha + m)}{(r - q)^2 - m^2 + i \epsilon} \gamma^\rho \frac{i (\gamma^\beta (p - q)_\beta + m)}{(p - q)^2 - m^2 + i \epsilon} \gamma^\nu \frac{-i g_{\mu\nu}}{q^2 + i\epsilon}.&lt;/math&gt;

The various {{math|''γ&lt;sup&gt;μ&lt;/sup&gt;''}} factors in this expression are [[gamma matrices]] as in the covariant formulation of the [[Dirac equation]]; they have to do with the spin of the electron. The factors of {{mvar|e}} are the electric coupling constant, while the &lt;math&gt;i\epsilon&lt;/math&gt; provide a heuristic definition of the contour of integration around the poles in the space of momenta. The important part for our purposes is the dependency on {{math|''q&lt;sup&gt;μ&lt;/sup&gt;''}} of the three big factors in the integrand, which are from the [[propagator]]s of the two electron lines and the photon line in the loop.

This has a piece with two powers of {{math|''q&lt;sup&gt;μ&lt;/sup&gt;''}} on top that dominates at large values of {{math|''q&lt;sup&gt;μ&lt;/sup&gt;''}} (Pokorski 1987, p.&amp;nbsp;122):

:&lt;math&gt;e^3 \gamma^\mu \gamma^\alpha \gamma^\rho \gamma^\beta \gamma_\mu \int \frac{d^4 q}{(2\pi)^4} \frac{q_\alpha q_\beta}{(r - q)^2 (p - q)^2 q^2}.&lt;/math&gt;

This integral is divergent and infinite, unless we cut it off at finite energy and momentum in some way.

Similar loop divergences occur in other quantum field theories.

== Renormalized and bare quantities ==
The solution was to realize that the quantities initially appearing in the theory's formulae (such as the formula for the [[Lagrangian (field theory)|Lagrangian]]), representing such things as the electron's [[electric charge]] and [[mass]], as well as the normalizations of the quantum fields themselves, did ''not'' actually correspond to the physical constants measured in the laboratory.  As written, they were ''bare'' quantities that did not take into account the contribution of virtual-particle loop effects to ''the physical constants themselves''.  Among other things, these effects would include the quantum counterpart of the electromagnetic back-reaction that so vexed classical theorists of electromagnetism.  In general, these effects would be just as divergent as the amplitudes under consideration in the first place; so finite measured quantities would, in general, imply divergent bare quantities.

To make contact with reality, then, the formulae would have to be rewritten in terms of measurable, ''renormalized'' quantities.  The charge of the electron, say, would be defined in terms of a quantity measured at a specific [[kinematics|kinematic]] ''renormalization point'' or ''subtraction point'' (which will generally have a characteristic energy, called the ''renormalization scale'' or simply the [[energy scale]]).  The parts of the Lagrangian left over, involving the remaining portions of the bare quantities, could then be reinterpreted as [[counterterm]]s, involved in divergent diagrams exactly ''canceling out'' the troublesome divergences for other diagrams.

=== Renormalization in QED ===
[[Image:Counterterm.png|thumbnail|250px|Figure 3. The vertex corresponding to the {{math|''Z''&lt;sub&gt;1&lt;/sub&gt;}} counterterm cancels the divergence in Figure 2.]]

For example, in the [[quantum electrodynamics|Lagrangian of QED]]

:&lt;math&gt;\mathcal{L}=\bar\psi_B\left[i\gamma_\mu \left (\partial^\mu + ie_BA_B^\mu \right )-m_B\right]\psi_B -\frac{1}{4}F_{B\mu\nu}F_B^{\mu\nu}&lt;/math&gt;

the fields and coupling constant are really ''bare'' quantities, hence the subscript {{mvar|B}} above. Conventionally the bare quantities are written so that the corresponding Lagrangian terms are multiples of the renormalized ones:

:&lt;math&gt;\left(\bar\psi m \psi\right)_B = Z_0 \bar\psi m \psi&lt;/math&gt;
:&lt;math&gt;\left(\bar\psi\left(\partial^\mu + ieA^\mu \right )\psi\right)_B = Z_1 \bar\psi \left (\partial^\mu + ieA^\mu \right)\psi&lt;/math&gt;
:&lt;math&gt;\left(F_{\mu\nu}F^{\mu\nu}\right)_B = Z_3\, F_{\mu\nu}F^{\mu\nu}.&lt;/math&gt;

[[Gauge invariance]], via a [[Ward–Takahashi identity]], turns out to imply that we can renormalize the two terms of the [[covariant derivative]] piece

:&lt;math&gt;\bar \psi (\partial + ieA) \psi&lt;/math&gt;

together (Pokorski 1987, p.&amp;nbsp;115), which is what happened to {{math|''Z''&lt;sub&gt;2&lt;/sub&gt;}}; it is the same as {{math|''Z''&lt;sub&gt;1&lt;/sub&gt;}}.

A term in this Lagrangian, for example, the electron-photon interaction pictured in Figure 1, can then be written

:&lt;math&gt;\mathcal{L}_I = -e \bar\psi \gamma_\mu A^\mu \psi - (Z_1 - 1) e \bar\psi \gamma_\mu A^\mu \psi&lt;/math&gt;

The physical constant {{mvar|e}}, the electron's charge, can then be defined in terms of some specific experiment:  we set the renormalization scale equal to the energy characteristic of this experiment, and the first term gives the interaction we see in the laboratory (up to small, finite corrections from loop diagrams, providing such exotica as the high-order corrections to the [[magnetic moment]]).  The rest is the counterterm.  If the theory is ''renormalizable'' (see below for more on this), as it is in QED, the ''divergent'' parts of loop diagrams can all be decomposed into pieces with three or fewer legs, with an algebraic form that can be canceled out by the second term (or by the similar counterterms that come from {{math|''Z''&lt;sub&gt;0&lt;/sub&gt;}} and {{math|''Z''&lt;sub&gt;3&lt;/sub&gt;}}).

The diagram with the {{math|''Z''&lt;sub&gt;1&lt;/sub&gt;}} counterterm's interaction vertex placed as in Figure 3 cancels out the divergence from the loop in Figure 2.

Historically, the splitting of the "bare terms" into the original terms and counterterms came before the [[renormalization group]] insight due to [[Kenneth G. Wilson|Kenneth Wilson]].&lt;ref&gt;K. G. Wilson (1975), "The renormalization group: critical phenomena and the Kondo problem," ''Rev. Mod. Phys.'' '''47''', 4, 773.&lt;/ref&gt; According to such [[renormalization group]] insights, detailed in the next section, this splitting is unnatural and actually unphysical, as all scales of the problem enter in continuous systematic ways.

=== Running couplings ===
To minimize the contribution of loop diagrams to a given calculation (and therefore make it easier to extract results), one chooses a renormalization point close to the energies and momenta exchanged in the interaction. However, the renormalization point is not itself a physical quantity: the physical predictions of the theory, calculated to all orders, should in principle be ''independent'' of the choice of renormalization point, as long as it is within the domain of application of the theory. Changes in renormalization scale will simply affect how much of a result comes from Feynman diagrams without loops, and how much comes from the remaining finite parts of loop diagrams. One can exploit this fact to calculate the effective variation of [[Coupling constant|physical constants]] with changes in scale. This variation is encoded by [[beta-function]]s, and the general theory of this kind of scale-dependence is known as the [[renormalization group]].

Colloquially, particle physicists often speak of certain physical "constants" as varying with the energy of interaction, though in fact, it is the renormalization scale that is the independent quantity.  This [[Coupling constant#Running coupling|''running'']] does, however, provide a convenient means of describing changes in the behavior of a field theory under changes in the energies involved in an interaction.  For example, since the coupling in [[quantum chromodynamics]] becomes small at large energy scales, the theory behaves more like a free theory as the energy exchanged in an interaction becomes large---a phenomenon  known as [[asymptotic freedom]].  Choosing an increasing energy scale and using the renormalization group makes this clear from simple Feynman diagrams; were this not done, the prediction would be the same, but would arise from complicated high-order cancellations.

For example,

:&lt;math&gt;I=\int_0^a \frac{1}{z}\,dz-\int_0^b \frac{1}{z}\,dz=\ln a-\ln b-\ln 0 +\ln 0&lt;/math&gt;

is ill-defined.

To eliminate the divergence, simply change lower limit of integral into {{mvar|ε&lt;sub&gt;a&lt;/sub&gt;}} and {{mvar|ε&lt;sub&gt;b&lt;/sub&gt;}}:

:&lt;math&gt;I=\ln a-\ln b-\ln{\varepsilon_a}+\ln{\varepsilon_b} = \ln \tfrac{a}{b} - \ln \tfrac{\varepsilon_a}{\varepsilon_b}&lt;/math&gt;

Making sure {{math|{{sfrac|''ε&lt;sub&gt;b&lt;/sub&gt;''|''ε&lt;sub&gt;a&lt;/sub&gt;''}} → 1}}, then {{math|''I'' {{=}} ln {{sfrac|''a''|''b''}}.}}

== Regularization ==
Since the quantity {{math|∞ − ∞}} is ill-defined, in order to make this notion of canceling divergences precise, the divergences first have to be tamed mathematically using the [[limit (mathematics)|theory of limits]], in a process known as [[regularization (physics)|regularization]] (Weinberg, 1995).

An essentially arbitrary modification to the loop integrands, or ''regulator'', can make them drop off faster at high energies and momenta, in such a manner that the integrals converge.  A regulator has a characteristic energy scale known as the [[Cutoff (physics)|cutoff]]; taking this cutoff to infinity (or, equivalently, the corresponding length/time scale to zero) recovers the original integrals.

With the regulator in place, and a finite value for the cutoff, divergent terms in the integrals then turn into finite but cutoff-dependent terms.  After canceling out these terms with the contributions from cutoff-dependent counterterms, the cutoff is taken to infinity and finite physical results recovered.  If physics on scales we can measure is independent of what happens at the very shortest distance and time scales, then it should be possible to get cutoff-independent results for calculations.

Many different types of regulator are used in quantum field theory calculations, each with its advantages and disadvantages.  One of the most popular in modern use is ''[[dimensional regularization]]'', invented by [[Gerardus 't Hooft]] and [[Martinus J. G. Veltman]],&lt;ref&gt;{{Cite journal | last1 = 't Hooft | first1 = G. | last2 = Veltman | first2 = M. | doi = 10.1016/0550-3213(72)90279-9 | title = Regularization and renormalization of gauge fields | journal = Nuclear Physics B | volume = 44 | pages = 189 | year = 1972 | pmid =  | pmc = |bibcode = 1972NuPhB..44..189T }}&lt;/ref&gt; which tames the integrals by carrying them into a space with a fictitious fractional number of dimensions.  Another is ''[[Pauli–Villars regularization]]'', which adds fictitious particles to the theory with very large masses, such that loop integrands involving the massive particles cancel out the existing loops at large momenta.

Yet another regularization scheme is the ''[[Lattice field theory|lattice regularization]]'', introduced by [[Kenneth G. Wilson|Kenneth Wilson]], which pretends that hyper-cubical lattice constructs our space-time with fixed grid size. This size is a natural cutoff for the maximal momentum that a particle could possess when propagating on the lattice. And after doing a calculation on several lattices with different grid size, the physical result is [[extrapolate]]d to grid size 0, or our natural universe. This presupposes the existence of a [[scaling limit]].

A rigorous mathematical approach to renormalization theory is the so-called [[causal perturbation theory]], where ultraviolet divergences are avoided from the start in calculations by performing well-defined mathematical operations only within the framework of [[Distribution (mathematics)|distribution]] theory. The disadvantage of the method is the fact that the approach is quite technical and requires a high level of mathematical knowledge.

=== Zeta function regularization ===
[[Julian Schwinger]] discovered a relationship{{citation needed|date=June 2012}} between [[zeta function regularization]] and renormalization, using the asymptotic relation:

:&lt;math&gt; I(n, \Lambda )= \int_0^{\Lambda }dp\,p^n \sim 1+2^n+3^n+\cdots+ \Lambda^n \to \zeta(-n)&lt;/math&gt;

as the regulator {{math|Λ → ∞}}. Based on this, he considered using the values of {{math|''ζ''(−''n'')}} to get finite results. Although he reached inconsistent results, an improved formula studied by [[Hartle]], J. Garcia, and based on the works by [[Emilio Elizalde|E. Elizalde]] includes the technique of the [[zeta regularization]] algorithm

:&lt;math&gt; I(n, \Lambda) = \frac{n}{2}I(n-1, \Lambda) + \zeta(-n) - \sum_{r=1}^{\infty}\frac{B_{2r}}{(2r)!} a_{n,r}(n-2r+1) I(n-2r, \Lambda),&lt;/math&gt;

where the ''B'''s are the [[Bernoulli number]]s and

:&lt;math&gt;a_{n,r}= \frac{\Gamma(n+1)}{\Gamma(n-2r+2)}.&lt;/math&gt;

So every {{math|''I''(''m'', Λ)}} can be written as a linear combination of {{math|''ζ''(−1), ''ζ''(−3), ''ζ''(−5), ..., ''ζ''(−''m'')}}.

Or simply using [[Abel–Plana formula]] we have for every divergent integral:

:&lt;math&gt; \zeta(-m, \beta )-\frac{\beta ^{m}}{2}-i\int_ 0 ^{\infty}dt \frac{ (it+\beta)^{m}-(-it+\beta)^{m}}{e^{2 \pi t}-1}=\int_0^\infty dp \, (p+\beta)^m &lt;/math&gt;

valid when {{math|''m'' &gt; 0}}, Here the zeta function is [[Hurwitz zeta function]] and Beta is a positive real number.

The "geometric" analogy is given by, (if we use [[rectangle method]]) to evaluate the integral so:

:&lt;math&gt; \int_0^\infty dx \, (\beta +x)^m \approx \sum_{n=0}^\infty h^{m+1} \zeta \left( \beta h^{-1} , -m \right) &lt;/math&gt;

Using Hurwitz zeta regularization plus the rectangle method with step h (not to be confused with [[Planck's constant]]).

The logarithmic divergent integral has the regularization

:&lt;math&gt; \sum_{n=0}^{\infty} \frac{1}{n+a}= - \psi (a)+log (a) &lt;/math&gt;

since for the Harmonic series &lt;math&gt; \sum_{n=0}^{\infty} \frac{1}{an+1} &lt;/math&gt; in the limit &lt;math&gt; a \to 0 &lt;/math&gt; we must recover the series &lt;math&gt; \sum_{n=0}^{\infty}1 =1/2 &lt;/math&gt;

For [[multi-loop integrals]] that will depend on several variables &lt;math&gt;k_1, \cdots, k_n&lt;/math&gt; we can make a change of variables to polar coordinates and then replace the integral over the angles &lt;math&gt;\int d \Omega&lt;/math&gt; by a sum so we have only a divergent integral, that will depend on the modulus &lt;math&gt;r^2 = k_1^2 +\cdots+k_n^2&lt;/math&gt; and then we can apply the zeta regularization algorithm, the main idea for multi-loop integrals is to replace the factor &lt;math&gt;F(q_1,\cdots,q_n)&lt;/math&gt; after a change to hyperspherical coordinates {{math|''F''(''r'', Ω)}} so the UV overlapping divergences are encoded in variable {{mvar|r}}. In order to regularize these integrals one needs a regulator, for the case of multi-loop integrals, these regulator can be taken as

:&lt;math&gt; \left (1+ \sqrt{q}_{i}q^{i} \right )^{-s} &lt;/math&gt;

so the multi-loop integral will converge for big enough {{mvar|s}} using the Zeta regularization we can analytic continue the variable {{mvar|s}} to the physical limit where {{math|''s'' {{=}} 0}} and then regularize any UV integral, by replacing a divergent integral by a linear combination of divergent series, which can be regularized in terms of the negative values of the Riemann zeta function {{math|''ζ''(−''m'')}}.

== Attitudes and interpretation ==
The early formulators of QED and other quantum field theories were, as a rule, dissatisfied with this state of affairs. It seemed illegitimate to do something tantamount to subtracting infinities from infinities to get finite answers.

[[Freeman Dyson]] argued that these infinities are of a basic nature and cannot be eliminated by any formal mathematical procedures, such as the renormalization method.&lt;ref&gt;F. J. Dyson, ''Phys. Rev.'' '''85''' (1952) 631.&lt;/ref&gt;&lt;ref&gt;A. W. Stern, ''Science'' '''116''' (1952) 493.&lt;/ref&gt;

[[Paul Dirac|Dirac]]'s criticism was the most persistent.&lt;ref&gt;P.A.M. Dirac, "The Evolution of the Physicist's Picture of Nature," in Scientific American, May 1963, p. 53.&lt;/ref&gt; As late as 1975, he was saying:&lt;ref&gt;Kragh, Helge; ''Dirac: A scientific biography'', CUP 1990, p. 184&lt;/ref&gt;

: Most physicists are very satisfied with the situation. They say: 'Quantum electrodynamics is a good theory and we do not have to worry about it any more.' I must say that I am very dissatisfied with the situation because this so-called 'good theory' does involve neglecting infinities which appear in its equations, ignoring them in an arbitrary way. This is just not sensible mathematics. Sensible mathematics involves disregarding a quantity when it is small – not neglecting it just because it is infinitely great and you do not want it!

Another important critic was [[Richard Feynman|Feynman]]. Despite his crucial role in the development of quantum electrodynamics, he wrote the following in 1985:&lt;ref&gt;Feynman, Richard P.; ''[[QED: The Strange Theory of Light and Matter]]'', Penguin 1990, p. 128&lt;/ref&gt;

: The shell game that we play is technically called 'renormalization'. But no matter how clever the word, it is still what I would call a dippy process! Having to resort to such hocus-pocus has prevented us from proving that the theory of quantum electrodynamics is mathematically self-consistent. It's surprising that the theory still hasn't been proved self-consistent one way or the other by now; I suspect that renormalization is not mathematically legitimate.

While Dirac's criticism was based on the procedure of renormalization itself, Feynman's criticism was very different. Feynman was concerned that all field theories known in the 1960s had the property that the interactions become infinitely strong at short enough distance scales. This property called a [[Landau pole]], made it plausible that quantum field theories were all inconsistent. In 1974, [[David Gross|Gross]], [[David Politzer|Politzer]] and [[Frank Wilczek|Wilczek]] showed that another quantum field theory, [[quantum chromodynamics]], does not have a Landau pole. Feynman, along with most others, accepted that QCD was a fully consistent theory.{{Citation needed|date=December 2009}}

The general unease was almost universal in texts up to the 1970s and 1980s. Beginning in the 1970s, however, inspired by work on the [[renormalization group]] and [[effective field theory]], and despite the fact that Dirac and various others—all of whom belonged to the older generation—never withdrew their criticisms, attitudes began to change, especially among younger theorists. [[Kenneth G. Wilson]] and others demonstrated that the renormalization group is useful in [[statistical mechanics|statistical]] field theory applied to [[condensed matter physics]], where it provides important insights into the behavior of [[phase transition]]s. In condensed matter physics, a ''physical'' short-distance regulator exists: [[matter]] ceases to be continuous on the scale of [[atom]]s. Short-distance divergences in condensed matter physics do not present a philosophical problem since the field theory is only an effective, smoothed-out representation of the behavior of matter anyway; there are no infinities since the cutoff is always finite, and it makes perfect sense that the bare quantities are cutoff-dependent.

If [[Quantum field theory|QFT]] holds all the way down past the [[Planck length]] (where it might yield to [[string theory]], [[causal set theory]] or something different), then there may be no real problem with short-distance divergences in [[particle physics]] either; ''all'' field theories could simply be effective field theories. In a sense, this approach echoes the older attitude that the divergences in QFT speak of human ignorance about the workings of nature, but also acknowledges that this ignorance can be quantified and that the resulting effective theories remain useful.

Be that as it may, [[Abdus Salam|Salam]]'s remark&lt;ref&gt;C. J. Isham, A. Salam, and J. Strathdee, "Infinity Suppression Gravity Modified Quantum Electrodynamics II," ''Phys. Rev.'' '''D5''', 2548 (1972)&lt;/ref&gt; in 1972 seems still relevant

: Field-theoretic infinities — first encountered in Lorentz's computation of electron self-mass — have persisted in classical electrodynamics for seventy and in quantum electrodynamics for some thirty-five years. These long years of frustration have left in the subject a curious affection for the infinities and a passionate belief that they are an inevitable part of nature; so much so that even the suggestion of a hope that they may, after all, be circumvented — and finite values for the renormalization constants computed — is considered irrational. Compare [[Bertrand Russell|Russell]]'s postscript to the third volume of his autobiography  ''The Final Years, 1944–1969'' (George Allen and Unwin, Ltd., London 1969),&lt;ref&gt;Russell, Bertrand. ''[https://books.google.com/books?id=6XmrPgAACAAJ The Autobiography of Bertrand Russell: The Final Years, 1944-1969]'' (Bantam Books, 1970)&lt;/ref&gt; p. 221:

:: In the modern world, if communities are unhappy, it is often because they have ignorances, habits, beliefs, and passions, which are dearer to them than happiness or even life. I find many men in our dangerous age who seem to be in love with misery and death, and who grow angry when hopes are suggested to them. They think hope is irrational and that, in sitting down to lazy despair, they are merely facing facts.

In QFT, the value of a physical constant, in general, depends on the scale that one chooses as the renormalization point, and it becomes very interesting to examine the renormalization group running of physical constants under changes in the energy scale.  The coupling constants in the [[Standard Model]] of particle physics vary in different ways with increasing energy scale: the coupling of [[quantum chromodynamics]] and the weak isospin coupling of the [[electroweak force]] tend to decrease, and the weak hypercharge coupling of the electroweak force tends to increase.  At the colossal energy scale of 10&lt;sup&gt;15&lt;/sup&gt; [[GeV]] (far beyond the reach of our current [[particle accelerator]]s), they all become approximately the same size (Grotz and Klapdor 1990, p.&amp;nbsp;254), a major motivation for speculations about [[grand unified theory]].  Instead of being only a worrisome problem, renormalization has become an important theoretical tool for studying the behavior of field theories in different regimes.

If a theory featuring renormalization (e.g. QED) can only be sensibly interpreted as an effective field theory, i.e. as an approximation reflecting human ignorance about the workings of nature, then the problem remains of discovering a more accurate theory that does not have these renormalization problems.  As [[Lewis Ryder]] has put it, "In the Quantum Theory, these [classical] divergences do not disappear; on the contrary, they appear to get worse.  And despite the comparative success of renormalisation theory, the feeling remains that there ought to be a more satisfactory way of doing things."&lt;ref&gt;Ryder, Lewis. ''[https://books.google.com/books?id=L9YhYS7gcXAC&amp;pg=PP1&amp;dq=%22Quantum+Field+Theory%22+and+Ryder#PPA390,M1 Quantum Field Theory]'', page 390 (Cambridge University Press 1996).&lt;/ref&gt;

== Renormalizability ==
From this philosophical reassessment, a new concept follows naturally: the notion of renormalizability.  Not all theories lend themselves to renormalization in the manner described above, with a finite supply of counterterms and all quantities becoming cutoff-independent at the end of the calculation.  If the Lagrangian contains combinations of field operators of high enough [[dimensional analysis|dimension]] in energy units, the counterterms required to cancel all divergences proliferate to infinite number, and, at first glance, the theory would seem to gain an infinite number of free parameters and therefore lose all predictive power, becoming scientifically worthless. Such theories are called ''nonrenormalizable''.

The [[Standard Model]] of particle physics contains only renormalizable operators, but the interactions of [[general relativity]] become nonrenormalizable operators if one attempts to construct a field theory of [[quantum gravity]] in the most straightforward manner (treating the metric in the [[Einstein–Hilbert Lagrangian]] as a perturbation about the [[Minkowski metric]]), suggesting that [[perturbation theory (quantum mechanics)|perturbation theory]] is useless in application to quantum gravity.

However, in an [[effective field theory]], "renormalizability" is, strictly speaking, a [[misnomer]]. In nonrenormalizable effective field theory, terms in the Lagrangian do multiply to infinity, but have coefficients suppressed by ever-more-extreme inverse powers of the energy cutoff.  If the cutoff is a real, physical quantity—that is, if the theory is only an effective description of physics up to some maximum energy or minimum distance scale—then these additional terms could represent real physical interactions.  Assuming that the dimensionless constants in the theory do not get too large, one can group calculations by inverse powers of the cutoff, and extract approximate predictions to finite order in the cutoff that still have a finite number of free parameters.  It can even be useful to renormalize these "nonrenormalizable" interactions.

Nonrenormalizable interactions in effective field theories rapidly become weaker as the energy scale becomes much smaller than the cutoff.  The classic example is the [[Fermi's interaction|Fermi theory]] of the [[weak nuclear force]], a nonrenormalizable effective theory whose cutoff is comparable to the mass of the [[W particle]].  This fact may also provide a possible explanation for ''why'' almost all of the particle interactions we see are describable by renormalizable theories.  It may be that any others that may exist at the [[Grand_Unified_Theory | GUT]] or Planck scale simply become too weak to detect in the realm we can observe, with one exception: [[gravity]], whose exceedingly weak interaction is magnified by the presence of the enormous masses of [[star]]s and [[planet]]s.{{Citation needed|date=February 2010}}

== Renormalization schemes ==
In actual calculations, the counterterms introduced to cancel the divergences in Feynman diagram calculations beyond tree level must be ''fixed'' using a set of '' renormalisation conditions''.  The common renormalization schemes in use include:
* [[Minimal subtraction scheme|Minimal subtraction (MS) scheme]] and the related modified minimal subtraction (MS-bar) scheme
* [[On shell renormalization scheme|On-shell scheme]]

== Application in statistical physics ==

A deeper understanding of the physical meaning and generalization of the
renormalization process, which goes beyond the dilatation group of conventional ''renormalizable'' theories,  came from condensed matter physics. [[Leo P. Kadanoff]]'s paper in 1966 proposed the "block-spin" renormalization group.&lt;ref&gt;[[Leo Kadanoff|L.P. Kadanoff]] (1966): "Scaling laws for Ising models near &lt;math&gt;T_c&lt;/math&gt;", ''Physics (Long Island City, N.Y.)'' '''2''', 263.&lt;/ref&gt; The ''blocking idea'' is a way to define the components of the theory at large distances as aggregates of components at shorter distances.

This approach covered the conceptual point and was given full computational substance&lt;ref&gt;[[Kenneth G. Wilson|K.G. Wilson]] (1975): "The renormalization group: critical phenomena and the Kondo problem", ''Rev. Mod. Phys.'' '''47''', 4, 773.&lt;/ref&gt; in the extensive important contributions of [[Kenneth G. Wilson|Kenneth Wilson]]. The power of Wilson's ideas was demonstrated by a constructive iterative renormalization solution of a long-standing problem, the [[Kondo effect|Kondo problem]], in 1974,  as well as the preceding seminal developments of his new method in the theory of second-order phase transitions and [[critical phenomena]] in 1971. He was awarded the Nobel prize for these decisive contributions in 1982.

In more technical terms, let us assume that we have a theory described
by a certain function &lt;math&gt;Z&lt;/math&gt; of the state variables
&lt;math&gt;\{s_i\}&lt;/math&gt; and a certain set of coupling constants
&lt;math&gt;\{J_k\}&lt;/math&gt;. This function may be a [[partition function (quantum field theory)|partition function]],
an [[Action (physics)|action]], a [[Hamiltonian (quantum mechanics)|Hamiltonian]], etc. It must contain the
whole description of the physics of the system.

Now we consider a certain blocking transformation of the state
variables &lt;math&gt;\{s_i\}\to \{\tilde s_i\}&lt;/math&gt;,
the number of &lt;math&gt;\tilde s_i&lt;/math&gt; must be lower than the number of
&lt;math&gt;s_i&lt;/math&gt;. Now let us try to rewrite the &lt;math&gt;Z&lt;/math&gt;
function ''only'' in terms of the &lt;math&gt;\tilde s_i&lt;/math&gt;. If this is achievable by a
certain change in the parameters, &lt;math&gt;\{J_k\}\to
\{\tilde J_k\}&lt;/math&gt;, then the theory is said to be
'''renormalizable'''.
The most important
information in the RG flow is its '''fixed points'''. The possible
macroscopic states of the system, at a large scale, are given by this
set of fixed points.  If these fixed points correspond to free field theory,
the theory is said to exhibit [[quantum triviality]].  Numerous fixed points appear in the study of 
[[Lattice gauge theory#Quantum triviality|lattice Higgs theories]], but the nature of the quantum field theories associated with these remains 
an open question.&lt;ref name="TrivPurs"&gt;{{cite journal| author=[[David J E Callaway|D. J. E. Callaway]] | year=1988
| title=Triviality Pursuit: Can Elementary Scalar Particles Exist?| journal=[[Physics Reports]]
|volume=167| issue=5 | pages=241–320| doi=10.1016/0370-1573(88)90008-7
|bibcode = 1988PhR...167..241C }}&lt;/ref&gt;

== See also ==
* [[History of quantum field theory]]
* [[Quantum triviality]]
* [[Zeno's paradoxes]]

== References ==
{{reflist|35em}}

== Further reading ==

=== General introduction ===
* DeDeo, Simon; [https://www.complexityexplorer.org/tutorials/67-introduction-to-renormalization ''Introduction to Renormalization''] (2017). [[Santa Fe Institute]] Complexity Explorer MOOC. Renormalization from a complex systems point of view, including Markov Chains, Cellular Automata, the real space Ising model, the Krohn-Rhodes Theorem, QED, and rate distortion theory.
* Delamotte, Bertrand; {{doi-inline|10.1119/1.1624112|''A hint of renormalization''}}, American Journal of Physics 72 (2004) pp.&amp;nbsp;170–184. Beautiful elementary introduction to the ideas, no prior knowledge of field theory being necessary. Full text available at: [https://arxiv.org/abs/hep-th/0212049 ''hep-th/0212049'']
* Baez, John; [http://math.ucr.edu/home/baez/renormalization.html ''Renormalization Made Easy''], (2005). A qualitative introduction to the subject.
* Blechman, Andrew E.; [http://www.pha.jhu.edu/~blechman/papers/renormalization/ ''Renormalization: Our Greatly Misunderstood Friend''], (2002). Summary of a lecture; has more information about specific regularization and divergence-subtraction schemes.
* Cao, Tian Yu &amp; Schweber, Silvan S.; {{doi-inline|10.1007/BF01255832|''The Conceptual Foundations and the Philosophical Aspects of Renormalization Theory''}}, Synthese, 97(1) (1993), 33–108.
* [[Dmitry Shirkov|Shirkov, Dmitry]]; ''Fifty Years of the Renormalization Group'', C.E.R.N. Courrier 41(7) (2001). Full text available at : [http://www.cerncourier.com/main/article/41/7/14 ''I.O.P Magazines''].
* E. Elizalde; ''Zeta regularization techniques with Applications''.

=== Mainly: quantum field theory ===
*[[Nikolay Bogoliubov|N. N. Bogoliubov]], [[Dmitry Shirkov|D. V. Shirkov]] (1959): ''The Theory of Quantized Fields''. New York, Interscience. The first text-book on the [[renormalization group]] theory.
* Ryder, Lewis H.; ''Quantum Field Theory '' (Cambridge University Press, 1985), {{ISBN|0-521-33859-X}} Highly readable textbook, certainly the best introduction to relativistic Q.F.T. for particle physics.
* Zee, Anthony; ''Quantum Field Theory in a Nutshell'', Princeton University Press (2003) {{ISBN|0-691-01019-6}}. Another excellent textbook on Q.F.T.
* Weinberg, Steven; ''The Quantum Theory of Fields'' (3 volumes) Cambridge University Press (1995). A monumental treatise on Q.F.T. written by a leading expert, [http://nobelprize.org/physics/laureates/1979/weinberg-lecture.html ''Nobel laureate 1979''].
* Pokorski, Stefan; ''Gauge Field Theories'', Cambridge University Press (1987) {{ISBN|0-521-47816-2}}.
* 't Hooft, Gerard; ''The Glorious Days of Physics – Renormalization of Gauge theories'', lecture given at Erice (August/September 1998) by the [http://nobelprize.org/physics/laureates/1999/thooft-autobio.html ''Nobel laureate 1999''] . Full text available at: [http://fr.arxiv.org/abs/hep-th/9812203 ''hep-th/9812203''].
* Rivasseau, Vincent; ''An introduction to renormalization'', Poincaré Seminar (Paris, Oct. 12, 2002), published in : Duplantier, Bertrand; Rivasseau, Vincent (Eds.); ''Poincaré Seminar 2002'', Progress in Mathematical Physics 30, Birkhäuser (2003) {{ISBN|3-7643-0579-7}}. Full text available in [http://www.bourbaphy.fr/Rivasseau.ps ''PostScript''].
* Rivasseau, Vincent; ''From perturbative to constructive renormalization'', Princeton University Press (1991) {{ISBN|0-691-08530-7}}. Full text available in [http://cpth.polytechnique.fr/cpth/rivass/articles/book.ps ''PostScript''].
* Iagolnitzer, Daniel &amp; Magnen, J.; ''Renormalization group analysis'', Encyclopaedia of Mathematics, Kluwer Academic Publisher (1996). Full text available in PostScript and pdf [https://web.archive.org/web/20060630015233/http://www-spht.cea.fr/articles/t96/037/ ''here''].
* Scharf, Günter; ''Finite quantum electrodynamics: The causal approach'', Springer Verlag Berlin Heidelberg New York (1995) {{ISBN|3-540-60142-2}}.
* A. S. Švarc ([[Albert Schwarz]]), Математические основы квантовой теории поля, (Mathematical aspects of quantum field theory), Atomizdat, Moscow, 1975. 368 pp.

=== Mainly: statistical physics ===
* A. N. Vasil'ev; ''The Field Theoretic Renormalization Group in Critical Behavior Theory and Stochastic Dynamics'' (Routledge Chapman &amp; Hall 2004); {{ISBN|978-0-415-31002-4}}
* [[Nigel Goldenfeld]]; ''Lectures on Phase Transitions and the Renormalization Group'', Frontiers in Physics 85, Westview Press (June, 1992) {{ISBN|0-201-55409-7}}. Covering the elementary aspects of the physics of phases transitions and the renormalization group, this popular book emphasizes understanding and clarity rather than technical manipulations.
* Zinn-Justin, Jean; ''Quantum Field Theory and Critical Phenomena'', Oxford University Press (4th edition – 2002) {{ISBN|0-19-850923-5}}. A masterpiece on applications of renormalization methods to the calculation of critical exponents in statistical mechanics, following Wilson's ideas (Kenneth Wilson was  [http://nobelprize.org/physics/laureates/1982/wilson-autobio.html ''Nobel laureate 1982'']).
* Zinn-Justin, Jean; ''Phase Transitions &amp; Renormalization Group: from Theory to Numbers'', Poincaré Seminar (Paris, Oct. 12, 2002), published in : Duplantier, Bertrand; Rivasseau, Vincent (Eds.); ''Poincaré Seminar 2002'', Progress in Mathematical Physics 30, Birkhäuser (2003) {{ISBN|3-7643-0579-7}}. Full text available in [http://parthe.lpthe.jussieu.fr/poincare/textes/octobre2002/Zinn.ps ''PostScript''].
* Domb, Cyril; ''The Critical Point: A Historical Introduction to the Modern Theory of Critical Phenomena'', CRC Press (March, 1996) {{ISBN|0-7484-0435-X}}.
* Brown, Laurie M. (Ed.); ''Renormalization: From Lorentz to Landau (and Beyond)'', Springer-Verlag (New York-1993) {{ISBN|0-387-97933-6}}.
* [[John Cardy|Cardy, John]]; ''Scaling and Renormalization in Statistical Physics'', Cambridge University Press (1996) {{ISBN|0-521-49959-3}}.

=== Miscellaneous ===
* [[Dmitry Shirkov|Shirkov, Dmitry]]; ''The Bogoliubov Renormalization Group'', JINR Communication E2-96-15 (1996). Full text available at: [https://arxiv.org/abs/hep-th/9602024 ''hep-th/9602024'']
* García Moreta, José Javier http://prespacetime.com/index.php/pst/article/view/498 The Application of Zeta Regularization Method to the Calculation of Certain Divergent Series and Integrals Refined Higgs, CMB from Planck, Departures in Logic, and GR Issues &amp; Solutions vol 4 Nº 3 prespacetime journal http://prespacetime.com/index.php/pst/issue/view/41/showToc
* Zinn-Justin, Jean; ''Renormalization and renormalization group: From the discovery of UV divergences to the concept of effective field theories'', in: de Witt-Morette C., Zuber J.-B. (eds), Proceedings of the NATO ASI on ''Quantum Field Theory: Perspective and Prospective'', June 15–26, 1998, Les Houches, France, Kluwer Academic Publishers, NATO ASI Series C 530, 375–388 (1999). Full text available in [http://www-spht.cea.fr/articles/t98/118/ ''PostScript''].
* Connes, Alain; ''Symétries Galoisiennes &amp; Renormalisation'', Poincaré Seminar (Paris, Oct. 12, 2002), published in : Duplantier, Bertrand; Rivasseau, Vincent (Eds.); ''Poincaré Seminar 2002'', Progress in Mathematical Physics 30, Birkhäuser (2003) {{ISBN|3-7643-0579-7}}. French mathematician [http://www.alainconnes.org ''Alain Connes''] (Fields medallist 1982) describe the mathematical underlying structure (the [[Hopf algebra]]) of renormalization, and its link to the Riemann-Hilbert problem. Full text (in French) available at [https://arxiv.org/pdf/math/0211199v1 ''math/0211199v1''].

[[Category:Concepts in physics]]
[[Category:Particle physics]]
[[Category:Quantum field theory]]
[[Category:Renormalization group]]
[[Category:Mathematical physics]]</text>
      <sha1>9fumvu7fiq1141fu5uee58xy132itns</sha1>
    </revision>
  </page>
  <page>
    <title>Richard Lipton</title>
    <ns>0</ns>
    <id>11532414</id>
    <revision>
      <id>846262335</id>
      <parentid>837319940</parentid>
      <timestamp>2018-06-17T14:59:37Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; remove 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13567">{{Infobox scientist
|image = 
|image_size = 150px |
|name              = Richard Lipton
|birth_name        = Richard Jay Lipton
|birth_date        = {{Birth date and age|1946|9|6}}
|birth_place       = 
|death_date        = 
|death_place       = 
|residence         = [[Atlanta, Georgia]]
|citizenship       = 
|nationality       = 
|ethnicity         = 
|field             = [[computer science]]
|work_institutions = [[Yale University|Yale]]&lt;br&gt;[[University of California, Berkeley|Berkeley]]&lt;br&gt;[[Princeton University|Princeton]]&lt;br&gt;[[Georgia Institute of Technology|Georgia Tech]]
|alma_mater        = [[Carnegie Mellon University|Carnegie Mellon]]
|doctoral_advisor  = [[David Parnas]]&lt;ref&gt;{{MathGenealogy|id=69524}}&lt;/ref&gt;
|doctoral_students = [[Dan Boneh]]&lt;br&gt;[[Avi Wigderson]]
|thesis_title = On Synchronization Primitive Systems
|thesis_year = 1973
|known_for         = [[Karp–Lipton theorem]] and [[planar separator theorem]]
|author_abbrev_bot = 
|author_abbrev_zoo = 
|prizes            = [[Knuth Prize]] (2014)
|religion          = 
|signature         =
|footnotes         = 
}}

'''Richard Jay Lipton''' (born September 6, 1946) is an [[Americans in the United Kingdom|American-British]] [[computer science|computer scientist]] who has worked in [[computer science theory]], [[cryptography]], and [[DNA computing]]. Lipton is Associate Dean of Research, Professor, and the Frederick G. Storey Chair in Computing in the College of Computing at the [[Georgia Institute of Technology]].

==Career==
In 1968, Lipton received his undergraduate degree in [[mathematics]] from [[Case Western Reserve University]].  In 1973, he received his [[Ph.D.]] from [[Carnegie Mellon University]]; his dissertation, supervised by [[David Parnas]], is entitled ''On Synchronization Primitive Systems''.  After graduating, Lipton taught at [[Yale University|Yale]] 1973&amp;ndash;1978, at [[University of California, Berkeley|Berkeley]] 1978&amp;ndash;1980, and then at [[Princeton University|Princeton]] 1980&amp;ndash;2000.  Since 2000, Lipton has been at [[Georgia Institute of Technology|Georgia Tech]].  While at Princeton, Lipton worked in the field of [[DNA computing]].  Since 1996, Lipton has been the chief consulting scientist at [[Telcordia]].

==Karp–Lipton theorem==
{{main|Karp–Lipton theorem}}
In 1980, along with [[Richard M. Karp]], Lipton proved that if [[Boolean satisfiability problem|SAT]] can be solved by [[Boolean circuit]]s with a polynomial number of [[logic gate]]s, then the [[polynomial hierarchy]] collapses to its second level.  __NOTOC__

==Parallel algorithms==
Showing that a program P has some property is a simple process if the actions inside the program are uninterruptible. However, when the action is interruptible, Lipton showed that through a type of reduction and analysis, it can be shown that the reduced program has that property if and only if the original program has the property.&lt;ref&gt;Lipton, R (1975) [http://www.cs.uoregon.edu/classes/06W/cis607atom/readings/lipton-reduction.pdf "Reduction: a method of proving properties of parallel programs"], ''Communications of the ACM'' 18(12)&lt;/ref&gt; If the reduction is done by treating interruptible operations as one large uninterruptible action, even with these relaxed conditions properties can be proven for a program P. Thus, correctness proofs of a parallel system can often be greatly simplified.

==Database security==
Lipton studied and created database security models on how and when to restrict the queries made by users of a database such that private or secret information will not be leaked.&lt;ref&gt;Lipton, R (1979) [http://www.cs.virginia.edu/papers/p97-dobkin.pdf "Secure databases: protection against user influence"], "ACM Transactions on Database Systems" 4(1)&lt;/ref&gt; Even when the user is restricted to only read operations on a database, secure information could be at risk. For example, querying a database of campaign donations could allow the user to discover the individual donations to political candidates or organizations. If given access to averages of data and unrestricted query access, a user could exploit the properties of those averages to gain illicit information. These queries are considered to have large "overlap" creating the insecurity. By bounding the "overlap" and number of queries, a secure database can be achieved.

==Online scheduling==
Richard Lipton with Andrew Tomkins introduced a randomized [[Adversary (online algorithm)|online interval scheduling algorithm]], the 2-size version being strongly competitive, and the ''k''-size version achieving O(log&lt;math&gt;\vartriangle^{1+\epsilon}&lt;/math&gt;), as well as demonstrating a theoretical lower-bound of O(log&lt;math&gt;\vartriangle&lt;/math&gt;).&lt;ref&gt;{{cite conference | last = Lipton | first = R | year = 1994 | citeseerx = 10.1.1.44.4548 | title = Online interval scheduling | journal = Symposium on Discrete Algorithms | pages = 302–311 }}&lt;/ref&gt; This algorithm uses a private-coin for randomization and a "virtual" choice to fool a [[Adversary (online algorithm)|medium adversary]].

Being presented with an event the user must decide whether or not to include the event in the schedule. The 2-size virtual algorithm is described by how it reacts to 1-interval or ''k''-intervals being presented by the adversary:
*For a 1-interval, flip a fair coin
**;Heads: Take the interval
**;Tails: "Virtually" take the interval, but do no work. Take no short interval for the next 1 unit of time.
*For a ''k''-interval, take whenever possible.

Again, this 2-size algorithm is shown to be strongly-[[Competitive analysis (online algorithm)|competitive]]. The generalized ''k''-size algorithm which is similar to the 2-size algorithm is then shown to be O(log&lt;math&gt;\vartriangle^{1+\epsilon}&lt;/math&gt;)-competitive.

==Program checking==
Lipton showed that randomized testing can be provably useful, given the problem satisfied certain properties.&lt;ref&gt;Lipton, R (1991) "New Directions in Testing", "DIMACS Distributed Computing and Cryptography" Vol. 2 page: 191&lt;/ref&gt; Proving [[program correctness|correctness of a program]] is one of the most important problems presented in computer science. Typically in randomized testing, in order to attain a 1/1000 chance of an error, 1000 tests must be run. However Lipton shows that if a problem has "easy" sub-parts, repeated black-box testing can attain ''c''&lt;sup&gt;''r''&lt;/sup&gt; error rate, with ''c'' a constant less than 1 and ''r'' being the number of tests. Therefore, the probability of error [[exponential decay|goes to zero exponentially]] fast as ''r'' grows.

This technique is useful to check the correctness of many types of problems. 
*Signal processing: [[Fast Fourier transform|fast Fourier transform (FFT)]] and other highly parallelizable functions are difficult to manually check results when written in code such as [[Fortran|FORTRAN]], so a way to quickly check correctness is greatly desired.
*Functions over finite fields and the permanent: Suppose that &lt;math&gt;f(x_1,\dots,x_n)&lt;/math&gt; is a polynomial over a finite field of size ''q'' with {{nowrap|''q'' &gt; deg(''ƒ'') + 1}}. Then ''ƒ'' is randomly testable of order {{nowrap|deg(''ƒ'') + 1}} over the function basis that includes just addition. Perhaps the most important application from this is the ability to efficiently check the correctness of the [[Permanent (mathematics)|permanent]]. Cosmetically similar to the determinant, the permanent is very difficult to check correctness, but even this type of problem satisfies the constraints. This result even led to the breakthroughs of [[interactive proof system]]s Karloff-Nisan and Shamir, including the result {{nowrap|IP {{=}} PSPACE}}.

==Games with simple strategies==
In the area of [[game theory]], more specifically on [[non-cooperative game]], Lipton together with E.Markakis and A.Mehta proved &lt;ref&gt;Richard Lipton, Evangelos Markakis, Aranyak Mehta (2007) "Playing Games with Simple Strategies", "EC '03: Proceedings of the 4th ACM conference on Electronic commerce", "ACM"&lt;/ref&gt; the existence of [[epsilon-equilibrium]] strategies with support logarithmic in the number of [[pure strategy]]. Furthermore, the payoff of such strategies can epsilon-approximate the payoffs of exact [[Nash equilibrium]]. The limited size (logarithmic) of support provides a natural quasi-polynomial algorithm of computing an [[epsilon-equilibrium]].

==Query size estimation==
Lipton and J.Naughton presented an adaptive random sampling algorithm for database querying&lt;ref&gt;Richard J. Lipton, Jeffrey F. Naughton (1990) "Query Size Estimation By Adaptive Sampling", "PODS '90: Proceedings of the ninth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems"&lt;/ref&gt;&lt;ref&gt;Richard J. Lipton, Jeffrey F. Naughton, Donovan A. Schneider (1990) "SIGMOD '90: Proceedings of the 1990 ACM SIGMOD international conference on Management of data "&lt;/ref&gt; which is applicable to any query for which answer to the query can be partitioned into disjoint subsets.  Compared with most sampling estimation algorithms that statically determines the number of samples needed, the algorithm they proposed decides the number of samples based on the size of samples and tends to keep the running time constant rather than the number of samples.

==Formal verification of programs==
[[Richard DeMillo|DeMillo]], Lipton and [[Alan Perlis|Perlis]]&lt;ref&gt;Richard A. DeMillo, Richard J. Lipton, Alan J. Perlis (1979) “Social processes and proofs of theorems and programs”, "Communications of the ACM , Volume 22 Issue 5"&lt;/ref&gt; criticized the idea of formal verification of programs and argued that
*Formal verifications in computer science will not play the same key role as proofs do in mathematics.
*Absence of continuity, the inevitability of change, and the complexity of specification of real programs will make formal verification of programs difficult to justify and manage.

==Multi-party protocols==
Chandra, Furst and Lipton&lt;ref&gt;A. K. Chandra, M. L. Furst, and R. J. Lipton (1983) "Multi-Party Protocols", "In STOC, pages 94–99. ACM, 25–2"&lt;/ref&gt; generalized the notion of two-party communication protocols to multi-party communication protocols. They proposed a model in which a collection of processes (&lt;math&gt;P_0,P_1,\ldots,P_{k-1}&lt;/math&gt;) have access to a set of integers (&lt;math&gt;a_0&lt;/math&gt;, &lt;math&gt;a_1,\ldots,a_{k-1}&lt;/math&gt;) except one of them, so that &lt;math&gt;P_i&lt;/math&gt; is denied access to &lt;math&gt;a_i&lt;/math&gt;.  These processes  are allowed to communicate in order to arrive at a consensus on a predicate. They studied this model’s communication complexity, defined as the number of bits broadcast among all the processes. As an example, they studied the complexity of a ''k''-party protocol for Exactly-''N'' (do all &lt;math&gt;a_i&lt;/math&gt;’s sum up to N?), and obtained a lower bound using the tiling method. They further applied this model to study general branching programs and obtained a time lower bound for constant-space branching programs that compute Exactly-''N''.

==Time/space SAT tradeoff==
We have no way to prove that [[Boolean satisfiability problem]] (often abbreviated as SAT), which is [[NP-complete]], requires exponential (or at least super-polynomial) time (this  is the famous [[P versus NP problem]]), or linear (or at least super-logarithmic) space to solve. However, in the context of [[space–time tradeoff]], one can prove that SAT cannot be computed if we apply constraints to both time and space. L. Fortnow, Lipton, D. van Melkebeek, and A. Viglas&lt;ref&gt;L. Fortnow, R. Lipton, D. van Melkebeek, and A. Viglas (2005) "Time-space lower bounds for satisfiability", "J. ACM, 52:835–865, 2005. Prelim version CCC ’2000"&lt;/ref&gt; proved that SAT cannot be computed by a Turing machine that takes at most O(''n''&lt;sup&gt;1.1&lt;/sup&gt;) steps and at most O(''n''&lt;sup&gt;0.1&lt;/sup&gt;) cells of its read-write tapes.

==Awards and honors==
*[[Guggenheim Fellowship|Guggenheim Fellow]], 1981
*[[Fellow]] of the [[Association for Computing Machinery]], 1997
*member of the [[National Academy of Engineering]]
*[[Knuth Prize]] winner, 2014&lt;ref&gt;{{cite web | url = http://www.acm.org/press-room/news-releases/2014/knuth-prize-2014 | archive-url = https://web.archive.org/web/20140920220414/http://www.acm.org/press-room/news-releases/2014/knuth-prize-2014 | dead-url = yes | archive-date = September 20, 2014 | title = ACM Awards Knuth Prize to Pioneer for Advances in Algorithms and Complexity Theory | publisher = Association for Computing Machinery | date = September 15, 2014 }}&lt;/ref&gt;

==See also==
*[[SL (complexity)]]
*[[Take-grant protection model]]
*[[Planar separator theorem]]

==Notes==
&lt;references/&gt;

==Further reading==
*"[https://www.nytimes.com/2016/06/05/fashion/weddings/kathryn-farley-richard-lipton.html?_r=1 Weddings: Kathryn Farley, Richard Lipton]", ''[[The New York Times]]'', 5 June 2016.

==External links==
*[http://rjlipton.wordpress.com/ His Personal Blog "Gödel`s Lost Letter and P=NP" ]

{{Knuth Prize laureates}}
{{Authority control}}

{{DEFAULTSORT:Lipton, Richard J.}}
[[Category:American computer scientists]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Guggenheim Fellows]]
[[Category:Living people]]
[[Category:Carnegie Mellon University alumni]]
[[Category:Georgia Institute of Technology faculty]]
[[Category:Theoretical computer scientists]]
[[Category:1946 births]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Knuth Prize laureates]]
[[Category:Science bloggers]]</text>
      <sha1>nd4t5z4tofo3z4lcakwfleg64om3a9y</sha1>
    </revision>
  </page>
  <page>
    <title>Sequential logic</title>
    <ns>0</ns>
    <id>89374</id>
    <revision>
      <id>851939293</id>
      <parentid>848522110</parentid>
      <timestamp>2018-07-25T15:11:17Z</timestamp>
      <contributor>
        <ip>27.34.108.3</ip>
      </contributor>
      <comment>By making the sentence less confusing.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9288">{{redirect|Sequential circuit|the synthesizer company|Sequential Circuits}}

In [[digital circuit]] theory, '''sequential logic''' is a type of [[logic circuit]] whose output depends not only on the present value of its input [[Digital signal (electronics)|signals]] but on the [[sequence]] of past inputs, the input history as well.&lt;ref name="Vai"&gt;{{cite book
 | last1  = Vai
 | first1 = M. Michael
 | title  = VLSI Design
 | publisher = CRC Press
 | date   = 2000
 | location =
 | pages  = 147
 | language =
 | url    = https://books.google.com/books?id=x9VicwHqocYC&amp;pg=PA147&amp;dq=%22sequential+logic%22+history+inputs+state
 | doi    =
 | id     =
 | isbn   = 0849318769
 }}&lt;/ref&gt;&lt;ref name="Cavanagh"&gt;{{cite book
 | last1  = Cavanagh
 | first1 = Joseph
 | title  = Sequential Logic: Analysis and Synthesis
 | publisher = CRC Press
 | date   = 2006
 | location =
 | pages  = ix
 | language =
 | url    = https://books.google.com/books?id=ryz8UbjBfWAC&amp;pg=PR11&amp;lpg=PR11&amp;dq=history+%22sequential+logic&amp;22
 | doi    =
 | id     =
 | isbn   = 0849375649
 }}&lt;/ref&gt;&lt;ref name="Lipiansky"&gt;{{cite book
 | last1  = Lipiansky
 | first1 = Ed
 | title  = Electrical, Electronics, and Digital Hardware Essentials for Scientists and Engineers
 | publisher = John Wiley and Sons
 | date   = 2012
 | location =
 | pages  = 8.39
 | language =
 | url    = https://books.google.com/books?id=oe31X8WoZnAC&amp;pg=SA8-PA39&amp;dq=%22sequential+logic%22+history+inputs
 | doi    =
 | id     =
 | isbn   = 1118414543
 }}&lt;/ref&gt;&lt;ref name="Dally"&gt;{{cite book
 | last1  = Dally
 | first1 = William J. 
 | last2  = Harting
 | first2 = R. Curtis
 | title  = Digital Design: A Systems Approach
 | publisher = Cambridge University Press
 | date   = 2012
 | location =
 | pages  = 291
 | language =
 | url    = https://books.google.com/books?id=WLoHOG0MhbIC&amp;pg=PA291&amp;dq=%22sequential+logic%22+history+inputs
 | doi    =
 | id     =
 | isbn   = 0521199506
 }}&lt;/ref&gt;  This is in contrast to ''[[combinational logic]]'', whose output is a function of only the present input.  That is, sequential logic has ''[[State (computer science)|state]]'' (''memory'') while combinational logic does not.

Sequential logic is used to construct [[finite state machine]]s, a basic building block in all digital circuitry. Virtually all circuits in practical digital devices are a mixture of combinational and sequential logic.

A familiar example of a device with sequential logic is a [[television set]] with "channel up" and "channel down" buttons.&lt;ref name="Vai" /&gt;  Pressing the "up" button gives the television an input telling it to switch to the next channel above the one it is currently receiving.  If the television is on channel 5, pressing "up" switches it to receive channel 6.  However, if the television is on channel 8, pressing "up" switches it to channel "9".  In order for the channel selection to operate correctly, the television must be aware of which channel it is currently receiving, which was determined by past channel selections.&lt;ref name="Vai" /&gt;  The television stores the current channel as part of its ''[[state (computer science)|state]]''.  When a "channel up" or "channel down" input is given to it, the sequential logic of the channel selection circuitry calculates the new channel from the input and the current channel.

Digital sequential logic circuits are divided into [[synchronous logic|synchronous]] and [[Asynchronous logic|asynchronous]] types.  In synchronous sequential circuits, the state of the device changes only at discrete times in response to a [[clock signal]].  In asynchronous circuits the state of the device can change at any time in response to changing inputs.

== Synchronous sequential logic ==
Nearly all sequential logic today is ''clocked'' or ''synchronous'' logic.  In a synchronous circuit, an [[electronic oscillator]] called a ''clock'' (or [[clock generator]]) generates a sequence of repetitive pulses called the ''[[clock signal]]'' which is distributed to all the memory elements in the circuit. The basic memory element in sequential logic is the [[Flip-flop (electronics)|flip-flop]]. The output of each flip-flop only changes when triggered by the clock pulse, so changes to the logic signals throughout the circuit all begin at the same time, at regular intervals, synchronized by the clock. 
      
The output of all the storage elements (flip-flops) in the circuit at any given time, the binary data they contain, is called the ''[[state (computer science)|state]]'' of the circuit.  The state of a synchronous circuit only changes on clock pulses.  At each cycle, the next state is determined by the current state and the value of the input signals when the clock pulse occurs.

The main advantage of synchronous logic is its simplicity.  The logic gates which perform the operations on the data require a finite amount of time to respond to changes to their inputs.  This is called ''[[propagation delay]]''.  The interval between clock pulses must be long enough so that all the logic gates have time to respond to the changes  and their outputs "settle" to stable logic values, before the next clock pulse occurs.   As long as this condition is met (ignoring certain other details) the circuit is guaranteed to be stable and reliable.  This determines the maximum operating speed of a synchronous circuit.

Synchronous logic has two main disadvantages:
* The maximum possible clock rate is determined by the slowest logic path in the circuit, otherwise known as the critical path.  Every logical calculation, from the simplest to the most complex, must complete in one clock cycle.  So logic paths that complete their calculations quickly are idle much of the time, waiting for the next clock pulse.  Therefore, synchronous logic can be slower than asynchronous logic.    One way to speed up synchronous circuits is to split complex operations into several simple operations which can be performed in successive clock cycles, a technique known as ''[[pipeline (computing)|pipelining]]''. This technique is extensively used in [[microprocessor]] design, and helps to improve the performance of modern processors.
* The clock signal must be distributed to every flip-flop in the circuit. As the clock is usually a high-frequency signal, this distribution consumes a relatively large amount of power and dissipates much heat. Even the flip-flops that are doing nothing consume a small amount of power, thereby generating [[waste heat]] in the chip.  In portable devices which have limited battery power, the clock signal goes on even when the device is not being used, consuming power.

==Asynchronous sequential logic==
{{main | asynchronous circuit }}
Asynchronous sequential logic is not synchronized by a clock signal; the outputs of the circuit change directly in response to changes in inputs.   The advantage of asynchronous logic is that it can be faster than synchronous logic, because the circuit doesn't have to wait for a clock signal to process inputs.  The speed of the device is potentially limited only by the [[propagation delay]]s of the [[logic gate]]s used.

However, asynchronous logic is more difficult to design and is subject to problems not encountered in synchronous designs.  The main problem is that digital memory elements are sensitive to the order that their input signals arrive; if two signals arrive at a [[flip-flop (electronics)|flip-flop]] or latch at almost the same time, which state the circuit goes into can depend on which signal gets to the gate first.   Therefore, the circuit can go into the wrong state, depending on small differences in the [[propagation delay]]s of the logic gates.   This is called a [[race condition]].  This problem is not as severe in synchronous circuits because the outputs of the memory elements only change at each clock pulse.  The interval between clock signals is designed to be long enough to allow the outputs of the memory elements to "settle" so they are not changing when the next clock comes.  Therefore, the only timing problems are due to "asynchronous inputs"; inputs to the circuit from other systems which are not synchronized to the clock signal.

Asynchronous sequential circuits are typically used only in a few critical parts of otherwise synchronous systems where speed is at a premium, such as parts of microprocessors and [[digital signal processing]] circuits.

The design of asynchronous logic uses different mathematical models and techniques from synchronous logic, and is an active area of research.

== See also ==
* [[Combinational logic]]
* [[Synchronous circuit]]
* [[Asynchronous circuit]]
* [[Logic design]]
* [[Asynchronous logic (algebra)]]
* [[Application-specific integrated circuit]]

==References==
{{Reflist}}
* Katz, R, and Boriello, G. ''Contemporary Logic Design''. 2nd ed. Prentice Hall. 2005. {{ISBN|0-201-30857-6}}.
* Zvi Kohavi, Niraj K. Jha. ''Switching and Finite Automata Theory''. 3rd ed. Cambridge University Press. 2009. {{ISBN|978-0-521-85748-2}}
* V. O. Vasyukevich. (2009). ''[http://asynlog.balticom.lv/Content/Files/en.pdf Asynchronous logic elements. Venjunction and sequention]'' — 118 p.

{{DEFAULTSORT:Sequential Logic}}
[[Category:Digital electronics]]
[[Category:Automata (computation)]]
[[Category:Logic in computer science]]</text>
      <sha1>0jv8tb986bdysl7zedcwf4okqy63pcr</sha1>
    </revision>
  </page>
  <page>
    <title>Simple (abstract algebra)</title>
    <ns>0</ns>
    <id>3875683</id>
    <revision>
      <id>704671572</id>
      <parentid>664455836</parentid>
      <timestamp>2016-02-12T21:49:14Z</timestamp>
      <contributor>
        <ip>129.7.128.205</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1517">In [[mathematics]], the term '''simple''' is used to describe an [[algebraic structure]] which in some sense cannot be divided by a smaller structure of the same type. Put another way, an algebraic structure is simple if the [[Kernel (algebra)|kernel]] of every homomorphism is either the whole structure or a single element. Some examples are:

* A [[group (mathematics)|group]] is called a [[simple group]] if it does not contain a nontrivial proper [[normal subgroup]].
* A [[ring (mathematics)|ring]] is called a [[simple ring]] if it does not contain a nontrivial [[two sided ideal]].
* A [[module (mathematics)|module]] is called a [[simple module]] if it does not contain a nontrivial [[submodule]].
* An [[algebra (ring theory)|algebra]] is called a [[simple algebra]] if it does not contain a nontrivial [[two sided ideal]].

The general pattern is that the structure admits no non-trivial [[Congruence_relation#Universal_algebra|congruence relations]].

The term is used differently in [[semigroup]] theory. A semigroup is said to be ''simple'' if it has no nontrivial
[[Semigroup#Subsemigroups_and_ideals|ideals]], or equivalently, if [[Green's relations|Green's relation]] ''J'' is
the universal relation. Not every congruence on a semigroup is associated with an ideal, so a simple semigroup may
have nontrivial congruences. A semigroup with no nontrivial congruences is called ''congruence simple''.

==See also==
* [[semisimple]]

{{DEFAULTSORT:Simple (Abstract Algebra)}}
[[Category:Abstract algebra]]</text>
      <sha1>n3gs3ahgch2evqhl3bm7ywuy0zsfjnn</sha1>
    </revision>
  </page>
  <page>
    <title>Simplicial manifold</title>
    <ns>0</ns>
    <id>2446477</id>
    <revision>
      <id>718994174</id>
      <parentid>718993920</parentid>
      <timestamp>2016-05-06T22:21:32Z</timestamp>
      <contributor>
        <ip>67.198.37.16</ip>
      </contributor>
      <comment>wikilink name</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1736">{{confused|Symplectic manifold}}
{{unreferenced|date=May 2014}}
In [[physics]], the term '''simplicial manifold''' commonly refers to one of several loosely defined objects, commonly appearing in the study of [[Regge calculus]]. These objects combine attributes of a [[simplex]] with those of a [[manifold]].  There is no standard usage of this term in [[mathematics]], and so the concept can refer to a [[triangulation (topology)|triangulation in topology]], or a [[piecewise linear manifold]], or one of several different [[functor]]s from either the [[category of sets]] or the category of [[simplicial set]]s to the category of [[manifold]]s.

==A manifold made out of simplices==
A simplicial manifold is a [[simplicial complex]] for which the [[geometric realization]] is [[homeomorphic]] to a [[topological manifold]].  This is essentially the concept of a [[triangulation (topology)|triangulation in topology]]. This can mean simply that a [[neighborhood (mathematics)|neighborhood]] of each vertex (i.e. the set of [[simplices]] that contain that point as a vertex) is [[homeomorphic]] to a ''n''-dimensional [[ball (mathematics)|ball]].

==A simplicial object built from manifolds==
A simplicial manifold is also a [[simplicial object]] in the [[category (mathematics)|category]] of [[manifold]]s.  This is a special case of a [[simplicial space]] in which, for each ''n'', the space of ''n''-simplices is a manifold.

For example, if ''G'' is a [[Lie group]], then the [[nerve (category theory)|simplicial nerve]] of ''G'' has the manifold &lt;math&gt;G^n&lt;/math&gt; as its space of ''n''-simplices.  More generally, ''G'' can be a [[Lie groupoid]].

[[Category:Structures on manifolds]]
[[Category:Simplicial sets]]

{{Geometry-stub}}</text>
      <sha1>5mkwjz907rm5iogrto84nz6aw0o7k4a</sha1>
    </revision>
  </page>
  <page>
    <title>Singular value decomposition</title>
    <ns>0</ns>
    <id>142207</id>
    <revision>
      <id>869792941</id>
      <parentid>869305563</parentid>
      <timestamp>2018-11-20T11:48:35Z</timestamp>
      <contributor>
        <ip>2A01:110:8012:1010:7248:28FF:2AE1:A91E</ip>
      </contributor>
      <comment>explicit types of matrices added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="80177">{{Use dmy dates|date=August 2012}}
[[File:Singular value decomposition.gif|thumb|right|280px|Visualization of the SVD of a 2D, real [[Shear mapping|shearing matrix]] {{math|'''M'''}}. First, we see the [[unit disc]] in blue together with the two [[standard basis|canonical unit vectors]]. We then see the action of {{math|'''M'''}}, which distorts the disk to an [[ellipse]]. The SVD decomposes {{math|'''M'''}} into three simple transformations: an initial [[Rotation matrix|rotation]] {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}}, a [[Scaling matrix|scaling]] {{math|'''Σ'''}} along the coordinate axes, and a final rotation {{math|'''U'''}}. The lengths {{math|''σ''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''σ''&lt;sub&gt;2&lt;/sub&gt;}} of the [[Ellipse#Elements of an ellipse|semi-axes]] of the ellipse are the [[singular value]]s of {{math|'''M'''}}, namely {{math|'''Σ'''&lt;sub&gt;1,1&lt;/sub&gt;}} and {{math|'''Σ'''&lt;sub&gt;2,2&lt;/sub&gt;}}.]]
[[File:Singular_value_decomposition_visualisation.svg|thumb|Visualisation of the matrix multiplications in singular value decomposition]]

In [[linear algebra]], the '''singular-value decomposition''' ('''SVD''') is a [[Matrix decomposition|factorization]] of a [[real number|real]] or [[complex number|complex]] [[matrix (mathematics)|matrix]].  It is the generalization of the [[eigendecomposition]] of a [[positive-semidefinite matrix|positive semidefinite]] [[normal matrix]] (for example, a [[symmetric matrix]] with positive eigenvalues) to any &lt;math&gt;m \times n&lt;/math&gt; matrix via an extension of the [[polar decomposition#Matrix polar decomposition|polar decomposition]].  It has many useful applications in [[signal processing]] and [[statistics]].

Formally, the singular-value decomposition of an &lt;math&gt;m \times n&lt;/math&gt; real or complex matrix &lt;math&gt;\mathbf{M}&lt;/math&gt; is a factorization of the form &lt;math&gt;\mathbf{U\Sigma V^*}&lt;/math&gt;, where &lt;math&gt;\mathbf{U}&lt;/math&gt; is an &lt;math&gt;m \times m&lt;/math&gt; real or complex [[unitary matrix]], &lt;math&gt;\mathbf{\Sigma}&lt;/math&gt; is an &lt;math&gt;m \times n&lt;/math&gt; [[rectangular diagonal matrix]] with non-negative real numbers on the diagonal, and &lt;math&gt;\mathbf{V}&lt;/math&gt; is an &lt;math&gt;n \times n&lt;/math&gt; real or complex unitary matrix. The diagonal entries &lt;math&gt;\sigma_i&lt;/math&gt; of &lt;math&gt;\mathbf{\Sigma}&lt;/math&gt; are known as the '''[[singular value]]s''' of &lt;math&gt;\mathbf{M}&lt;/math&gt;. The columns of &lt;math&gt;\mathbf{U}&lt;/math&gt; and the columns of &lt;math&gt;\mathbf{V}&lt;/math&gt; are called the '''left-singular vectors''' and '''right-singular vectors''' of &lt;math&gt;\mathbf{M}&lt;/math&gt;, respectively.

The singular-value decomposition can be computed using the following observations:
* The left-singular vectors of {{math|'''M'''}} are a set of [[orthonormal]] [[eigenvectors]] of {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}}.
* The right-singular vectors of {{math|'''M'''}} are a set of orthonormal eigenvectors of {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}}.
* The non-zero singular values of {{math|'''M'''}} (found on the diagonal entries of {{math|'''Σ'''}}) are the square roots of the non-zero [[eigenvalues]] of both {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}} and {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}}.

Applications that employ the SVD include computing the [[Moore–Penrose pseudoinverse|pseudoinverse]], [[least squares]] fitting of data, multivariable control, matrix approximation, and determining the [[rank of a matrix|rank]], [[range of a matrix|range]] and [[kernel (matrix)|null space]] of a matrix.

== Statement of the theorem ==
Suppose {{math|'''M'''}} is a {{math|''m'' × ''n''}} [[matrix (mathematics)|matrix]] whose entries come from the [[field (mathematics)|field]] {{mvar|K}}, which is either the field of [[real number]]s  or the field of [[complex number]]s. Then there exists a factorization, called a 'singular value decomposition' of {{math|'''M'''}}, of the form

: &lt;math&gt;\mathbf{M} = \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^*&lt;/math&gt;

where 
* {{math|'''U'''}} is an {{math|''m'' × ''m''}} [[unitary matrix]] over {{mvar|K}} (if {{math|''K'' {{=}} }}&lt;math&gt;\mathbb{R}&lt;/math&gt;, unitary matrices are [[orthogonal matrix|orthogonal matrices]]),
* {{math|'''Σ'''}} is a [[rectangular diagonal matrix|diagonal]] {{math|''m'' × ''n''}} matrix with non-negative real numbers on the diagonal,
* {{math|'''V'''}} is an {{math|''n'' × ''n''}} [[unitary matrix]] over {{mvar|K}}, and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} is the [[conjugate transpose]] of {{math|'''V'''}}.

The diagonal entries {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} of {{math|'''Σ'''}} are known as the '''[[singular value]]s''' of {{math|'''M'''}}. A common convention is to list the singular values in descending order. In this case, the diagonal matrix, {{math|'''Σ'''}}, is uniquely determined by {{math|'''M'''}} (though not the matrices {{math|'''U'''}} and {{math|'''V'''}} if {{math|'''M'''}} is not square, see below).

== Intuitive interpretations ==
[[File:Singular-Value-Decomposition.svg|thumb|{{ubl
| '''Upper left:''' The unit disc with the two canonical unit vectors.
| '''Upper right:''' Unit disc transformed with M and singular values {{math|''σ''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''σ''&lt;sub&gt;2&lt;/sub&gt;}} indicated.
| '''Lower left:''' The action of {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} on the unit disc. This is just a rotation.
| '''Lower right:''' The action of {{math|'''ΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} on the unit disc. &amp;Sigma; scales in vertically and horizontally.
}}{{paragraph}}
In this special case, the singular values are ''&amp;phi;'' and 1/''&amp;phi;'' where ''&amp;phi;'' is the [[golden ratio]]. {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} is a (counter clockwise) rotation by an angle alpha where alpha satisfies tan(''&amp;alpha;'') = −''&amp;phi;''. {{math|'''U'''}} is a rotation by an angle beta with tan(''&amp;beta;'') = ''&amp;phi;''&amp;nbsp;−&amp;nbsp;1
]]

=== Rotation, scaling ===
In the special, yet common case when {{math|'''M'''}} is an {{math|''m'' × ''m''}} real [[square matrix]] with positive [[determinant]]: {{math|'''U''', '''V'''&lt;sup&gt;∗&lt;/sup&gt;}}, and {{math|'''Σ'''}} are real {{math|''m'' × ''m''}} matrices as well. {{math|'''Σ'''}} can be regarded as a [[scaling matrix]], and {{math|'''U''', '''V'''&lt;sup&gt;∗&lt;/sup&gt;}} can be viewed as [[rotation matrix|rotation matrices]]. Thus the expression {{math|'''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} can be intuitively interpreted as a [[Function composition|composition]] of three geometrical [[Transformation (geometry)|transformations]]: a [[Coordinate rotations and reflections|rotation or reflection]], a [[Scaling (geometry)|scaling]], and another rotation or reflection. For instance, the figure explains how a [[shear matrix]] can be described as such a sequence.

Using the [[polar decomposition#Matrix polar decomposition|polar decomposition]] theorem, we can also consider {{math|'''M''' {{=}} '''RP'''}} as the composition of a stretch (positive definite matrix {{math|'''P''' {{=}} '''VΣV'''&lt;sup&gt;∗&lt;/sup&gt;}}) with eigenvalue scale factors {{math|σ&lt;sub&gt;''i''&lt;/sub&gt;}} along the orthogonal eigenvectors {{math|'''V'''&lt;sub&gt;''i''&lt;/sub&gt;}} of {{math|'''P'''}}, followed by a single rotation (unitary matrix {{math|'''R''' {{=}} '''UV'''&lt;sup&gt;∗&lt;/sup&gt;}}).  If the rotation is done first, {{math|'''M''' {{=}} '''P'''{{'}}'''R'''}}, then {{math|'''R'''}} is the same and {{math|'''P'''{{'}} {{=}} '''UΣU'''&lt;sup&gt;∗&lt;/sup&gt;}} has the same eigenvalues, but is stretched along different (post-rotated) directions.  This shows that the SVD is a generalization of the eigenvalue decomposition of pure stretches in orthogonal directions (symmetric matrix {{math|'''P'''}}) to arbitrary matrices ({{math|'''M''' {{=}} '''RP'''}}) which both stretch and rotate.

=== Singular values as semiaxis of an ellipse or ellipsoid ===
As shown in the figure, the [[singular values]] can be interpreted as the semiaxis of an [[ellipse]] in 2D. This concept can be generalized to {{mvar|n}}-dimensional [[Euclidean space]], with the singular values of any {{math|''n'' × ''n''}} [[square matrix]] being viewed as the semiaxis of an {{mvar|n}}-dimensional [[ellipsoid]]. Similarly, the singular values of any {{math|''m'' × ''n''}} matrix can be viewed as the semiaxis of an {{mvar|n}}-dimensional [[ellipsoid]] in {{mvar|m}}-dimensional space, for example as an ellipse in a (tilted) 2D plane in a 3D space. See [[#Geometric meaning|below]] for further details.

=== The columns of ''U'' and ''V'' are orthonormal bases ===
Since {{math|'''U'''}} and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} are unitary, the columns of each of them form a set of [[orthonormal vectors]], which can be regarded as [[basis vectors]]. The matrix {{math|'''M'''}} maps the basis vector {{math|'''V'''&lt;sub&gt;i&lt;/sub&gt;}} to the stretched unit vector {{math|σ&lt;sub&gt;i&lt;/sub&gt; '''U'''&lt;sub&gt;i&lt;/sub&gt;}} (see [[#Geometric meaning|below]] for further details).  By the definition of a unitary matrix, the same is true for their conjugate transposes {{math|'''U'''&lt;sup&gt;∗&lt;/sup&gt;}} and {{math|'''V'''}}, except the geometric interpretation of the singular values as stretches is lost. In short, the columns of {{math|'''U''', '''U'''&lt;sup&gt;∗&lt;/sup&gt;, '''V'''}}, and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} are [[Orthonormal basis|orthonormal bases]]. When the &lt;math&gt;\mathbf{M}&lt;/math&gt; is a [[normal matrix]], {{math|'''U'''}} and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} reduce to the unitary used to diagonalize &lt;math&gt;\mathbf{M}&lt;/math&gt;. However, when &lt;math&gt;\mathbf{M}&lt;/math&gt; is not normal but still [[diagonalizable]], its [[eigendecomposition]] and singular value decomposition are distinct.

=== Geometric meaning ===
Because {{math|'''U'''}} and {{math|'''V'''}} are unitary, we know that the columns {{math|'''U'''&lt;sub&gt;1&lt;/sub&gt;, ..., '''U'''&lt;sub&gt;''m''&lt;/sub&gt;}} of {{math|'''U'''}} yield an [[orthonormal basis]] of {{mvar|K&lt;sup&gt;m&lt;/sup&gt;}} and the columns {{math|'''V'''&lt;sub&gt;1&lt;/sub&gt;, ..., '''V'''&lt;sub&gt;''n''&lt;/sub&gt;}} of {{math|'''V'''}} yield an orthonormal basis of {{mvar|K&lt;sup&gt;n&lt;/sup&gt;}} (with respect to the standard [[scalar product]]s on these spaces).

The [[linear transformation]]

:&lt;math&gt;\begin{cases} T : K^n \to K^m \\ x \mapsto \mathbf{M}x \end{cases}&lt;/math&gt;

has a particularly simple description with respect to these orthonormal bases: we have

:&lt;math&gt;T(\mathbf{V}_i) = \sigma_i \mathbf{U}_i, \qquad i = 1, \ldots, \min(m, n),&lt;/math&gt;

where {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} is the {{mvar|i}}-th diagonal entry of {{math|'''Σ'''}}, and {{math|''T''('''V'''&lt;sub&gt;''i''&lt;/sub&gt;) {{=}} 0}} for {{math|''i'' &gt; min(''m'',''n'')}}.

The geometric content of the SVD theorem can thus be summarized as follows: for every linear map {{math|''T'' : ''K&lt;sup&gt;n&lt;/sup&gt;'' → ''K&lt;sup&gt;m&lt;/sup&gt;''}} one can find orthonormal bases of {{mvar|K&lt;sup&gt;n&lt;/sup&gt;}} and {{mvar|K&lt;sup&gt;m&lt;/sup&gt;}} such that {{mvar|T}} maps the {{mvar|i}}-th basis vector of {{mvar|K&lt;sup&gt;n&lt;/sup&gt;}} to a non-negative multiple of the {{mvar|i}}-th basis vector of {{mvar|K&lt;sup&gt;m&lt;/sup&gt;}}, and sends the left-over basis vectors to zero. With respect to these bases, the map {{mvar|T}} is therefore represented by a diagonal matrix with non-negative real diagonal entries.

To get a more visual flavour of singular values and SVD factorization — at least when working on real vector spaces — consider the sphere {{mvar|S}} of radius one in {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}. The linear map {{mvar|T}} maps this sphere onto an [[ellipsoid]] in {{math|'''R'''&lt;sup&gt;''m''&lt;/sup&gt;}}. Non-zero singular values are simply the lengths of the [[Semi-minor axis|semi-axes]] of this ellipsoid. Especially when {{math|''n'' {{=}} ''m''}}, and all the singular values are distinct and non-zero, the SVD of the linear map {{mvar|T}} can be easily analysed as a succession of three consecutive moves: consider the ellipsoid {{math|''T''(''S'')}} and specifically its axes; then consider the directions in {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} sent by {{mvar|T}} onto these axes. These directions happen to be mutually orthogonal. Apply first an isometry {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} sending these directions to the coordinate axes of {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}. On a second move, apply an [[endomorphism]] {{math|'''D'''}} diagonalized along the coordinate axes and stretching or shrinking in each direction, using the semi-axes lengths of {{math|''T''(''S'')}} as stretching  coefficients. The composition {{math|'''D''' ∘ '''V'''&lt;sup&gt;∗&lt;/sup&gt;}} then sends the unit-sphere onto an ellipsoid isometric to {{math|''T''(''S'')}}. To define the third and last move {{math|'''U'''}}, apply an isometry to this ellipsoid so as to carry it over {{math|''T''(''S'')}}. As can be easily checked, the composition {{math|'''U''' ∘ '''D''' ∘ '''V'''&lt;sup&gt;∗&lt;/sup&gt;}} coincides with {{mvar|T}}.

== Example ==
Consider the {{math|4 × 5}} matrix

:&lt;math&gt;\mathbf{M} = \begin{bmatrix}
                      1 &amp; 0 &amp; 0 &amp; 0 &amp; 2 \\
                      0 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
                      0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
                      0 &amp; 2 &amp; 0 &amp; 0 &amp; 0
                    \end{bmatrix}
&lt;/math&gt;

A singular-value decomposition of this matrix is given by {{math|'''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}}

:&lt;math&gt;\begin{align}
  \mathbf{U} &amp;= \begin{bmatrix}
                  \color{Green}0 &amp; \color{Blue}0 &amp; \color{Cyan}1 &amp; \color{Emerald}0 \\
                  \color{Green}0 &amp; \color{Blue}1 &amp; \color{Cyan}0 &amp; \color{Emerald}0 \\
                  \color{Green}0 &amp; \color{Blue}0 &amp; \color{Cyan}0 &amp; \color{Emerald}-1 \\
                  \color{Green}1 &amp; \color{Blue}0 &amp; \color{Cyan}0 &amp; \color{Emerald}0
                \end{bmatrix} \\[6pt]

  \boldsymbol{\Sigma} &amp;= \begin{bmatrix}
                           2 &amp; 0 &amp;        0 &amp;                    0  &amp; \color{Gray}\mathit{0} \\
                           0 &amp; 3 &amp;        0 &amp;                    0  &amp; \color{Gray}\mathit{0} \\
                           0 &amp; 0 &amp; \sqrt{5} &amp;                    0  &amp; \color{Gray}\mathit{0} \\
                           0 &amp; 0 &amp;        0 &amp; \color{Red}\mathbf{0} &amp; \color{Gray}\mathit{0}
                         \end{bmatrix} \\[6pt]

 \mathbf{V}^* &amp;= \begin{bmatrix}
                   \color{Violet}0 &amp; \color{Plum}1 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp;          \color{Purple}0 \\
                   \color{Violet}0 &amp; \color{Plum}0 &amp; \color{Magenta}1 &amp; \color{Orchid}0 &amp;          \color{Purple}0 \\
                   \color{Violet}\sqrt{0.2} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp; \color{Purple}\sqrt{0.8} \\
                   \color{Violet}0 &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}1 &amp;          \color{Purple}0 \\
                   \color{Violet} - \sqrt{0.8} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp; \color{Purple}\sqrt{0.2}
                 \end{bmatrix}
\end{align}&lt;/math&gt;

Notice {{math|'''Σ'''}} is zero outside of the diagonal (grey italics) and one diagonal element is zero (red bold). Furthermore, because the matrices {{math|'''U'''}} and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} are [[unitary matrix|unitary]], multiplying by their respective conjugate transposes yields [[identity matrix|identity matrices]], as shown below.  In this case, because {{math|'''U'''}} and {{math|'''V'''&lt;sup&gt;∗&lt;/sup&gt;}} are real valued, each is an [[orthogonal matrix]].

:&lt;math&gt;\begin{align}
  \mathbf{U} \mathbf{U}^\textsf{T} &amp;=
  \begin{bmatrix}
    \color{Green}0 &amp; \color{Blue}0 &amp; \color{Cyan}1 &amp;  \color{Emerald}0 \\
    \color{Green}0 &amp; \color{Blue}1 &amp; \color{Cyan}0 &amp;  \color{Emerald}0 \\
    \color{Green}0 &amp; \color{Blue}0 &amp; \color{Cyan}0 &amp; \color{Emerald}-1 \\
    \color{Green}1 &amp; \color{Blue}0 &amp; \color{Cyan}0 &amp;  \color{Emerald}0
  \end{bmatrix} \cdot
  \begin{bmatrix}
    \color{Green}0 &amp; \color{Green}0 &amp;  \color{Green}0 &amp; \color{Green}1 \\
    \color{Blue}0 &amp; \color{Blue}1 &amp;  \color{Blue}0 &amp; \color{Blue}0 \\
    \color{Cyan}1 &amp; \color{Cyan}0 &amp;  \color{Cyan}0 &amp; \color{Cyan}0 \\
    \color{Emerald}0 &amp; \color{Emerald}0 &amp; \color{Emerald}-1 &amp; \color{Emerald}0
  \end{bmatrix}  = 
  \begin{bmatrix}
    1 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix} = \mathbf{I}_4 \\[6pt]
  \mathbf{V} \mathbf{V}^\textsf{T} &amp;=
  \begin{bmatrix}
    \color{Violet}0  &amp;  \color{Violet}0 &amp; \color{Violet}\sqrt{0.2} &amp;  \color{Violet}0 &amp; \color{Violet}-\sqrt{0.8} \\
       \color{Plum}1 &amp;    \color{Plum}0 &amp;            \color{Plum}0 &amp;    \color{Plum}0 &amp;           \color{Plum}0 \\
    \color{Magenta}0 &amp; \color{Magenta}1 &amp;         \color{Magenta}0 &amp; \color{Magenta}0 &amp;           \color{Magenta}0 \\
    \color{Orchid}0  &amp;  \color{Orchid}0 &amp;          \color{Orchid}0 &amp;  \color{Orchid}1 &amp;           \color{Orchid}0 \\
    \color{Purple}0  &amp;  \color{Purple}0 &amp; \color{Purple}\sqrt{0.8} &amp;  \color{Purple}0 &amp; \color{Purple}\sqrt{0.2}
  \end{bmatrix} \cdot
  \begin{bmatrix}
                \color{Violet}0 &amp; \color{Plum}1 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp;          \color{Purple}0 \\
                \color{Violet}0 &amp; \color{Plum}0 &amp; \color{Magenta}1 &amp; \color{Orchid}0 &amp;          \color{Purple}0 \\
       \color{Violet}\sqrt{0.2} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp; \color{Purple}\sqrt{0.8} \\
                \color{Violet}0 &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}1 &amp;          \color{Purple}0 \\
    \color{Violet} - \sqrt{0.8} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}0 &amp; \color{Purple}\sqrt{0.2}
  \end{bmatrix}  =
  \begin{bmatrix}
    1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
  \end{bmatrix} = \mathbf{I}_5
\end{align}&lt;/math&gt;

This particular singular-value decomposition is not unique.  Choosing &lt;math&gt;V&lt;/math&gt; such that
:&lt;math&gt;\mathbf{V}^* = \begin{bmatrix}
            \color{Violet}0 &amp; \color{Plum}1 &amp; \color{Magenta}0 &amp;          \color{Orchid}0 &amp;           \color{Purple}0 \\
            \color{Violet}0 &amp; \color{Plum}0 &amp; \color{Magenta}1 &amp;          \color{Orchid}0 &amp;           \color{Purple}0 \\
   \color{Violet}\sqrt{0.2} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp;          \color{Orchid}0 &amp;  \color{Purple}\sqrt{0.8} \\
   \color{Violet}\sqrt{0.4} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}\sqrt{0.5} &amp; \color{Purple}-\sqrt{0.1} \\
  \color{Violet}-\sqrt{0.4} &amp; \color{Plum}0 &amp; \color{Magenta}0 &amp; \color{Orchid}\sqrt{0.5} &amp;  \color{Purple}\sqrt{0.1}
\end{bmatrix}&lt;/math&gt;

is also a valid singular-value decomposition.

== SVD and spectral decomposition ==
=== Singular values, singular vectors, and their relation to the SVD ===
A non-negative real number {{mvar|σ}} is a '''[[singular value]]''' for {{math|'''M'''}} if and only if there exist unit-length vectors &lt;math&gt;\vec{u}&lt;/math&gt; in ''K&lt;sup&gt;m&lt;/sup&gt;'' and &lt;math&gt;\vec{v}&lt;/math&gt; in ''K&lt;sup&gt;n&lt;/sup&gt;'' such that

:&lt;math&gt;\mathbf{M}\vec{v} = \sigma \vec{u} \,\text{ and } \mathbf{M}^*\vec{u} = \sigma \vec{v}&lt;/math&gt;

The vectors &lt;math&gt;\vec{u}&lt;/math&gt; and &lt;math&gt;\vec{v}&lt;/math&gt; are called '''left-singular''' and '''right-singular vectors''' for {{mvar|σ}}, respectively.

In any singular-value decomposition

:&lt;math&gt;\mathbf{M} = \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^*&lt;/math&gt;

the diagonal entries of {{math|'''Σ'''}} are equal to the singular values of {{math|'''M'''}}. The first {{math|''p'' {{=}} min(''m'', ''n'')}} columns of {{math|'''U'''}} and {{math|'''V'''}} are, respectively, left- and right-singular vectors for the corresponding singular values.  Consequently, the above theorem implies that:
* An {{math|''m'' × ''n''}} matrix {{math|'''M'''}} has at most {{math|''p''}} distinct singular values.
* It is always possible to find a [[orthogonal basis|unitary basis]] {{math|'''U'''}} for {{mvar|K&lt;sup&gt;m&lt;/sup&gt;}} with a subset of basis vectors spanning the left-singular vectors of each singular value of {{math|'''M'''}}.
* It is always possible to find a unitary basis {{math|'''V'''}} for {{mvar|K&lt;sup&gt;n&lt;/sup&gt;}} with a subset of basis vectors spanning the right-singular vectors of each singular value of {{math|'''M'''}}.

A singular value for which we can find two left (or right) singular vectors that are linearly independent is called ''degenerate''.  If &lt;math&gt;\vec{u_1}&lt;/math&gt; and &lt;math&gt;\vec{u_2}&lt;/math&gt; are two left-singular vectors which both correspond to the singular value σ, then any normalized linear combination of the two vectors is also a left-singular vector corresponding to the singular value σ.  The similar statement is true for right-singular vectors.  The number of independent left and right-singular vectors coincides, and these singular vectors appear in the same columns of {{math|'''U'''}} and {{math|'''V'''}} corresponding to diagonal elements of {{math|'''Σ'''}} all with the same value σ.

As an exception, the left and right-singular vectors of singular value 0 comprise all unit vectors in the [[Kernel (linear algebra)|kernel]] and [[cokernel]], respectively, of {{math|'''M'''}}, which by the [[rank–nullity theorem]] cannot be the same dimension if {{math|m ≠ n}}.  Even if all singular values are nonzero, if {{math|''m'' &gt; ''n''}} then the cokernel is nontrivial, in which case {{math|'''U'''}} is padded with {{math|''m'' − ''n''}} orthogonal vectors from the cokernel.  Conversely, if {{math|''m'' &lt; ''n''}}, then {{math|'''V'''}} is padded by {{math|''n'' − ''m''}} orthogonal vectors from the kernel.  However, if the singular value of 0 exists, the extra columns of {{math|'''U'''}} or {{math|'''V'''}} already appear as left or right-singular vectors.

Non-degenerate singular values always have unique left- and right-singular vectors, up to multiplication by a unit-phase factor ''e''&lt;sup&gt;'''i'''''φ''&lt;/sup&gt; (for the real case up to a sign).  Consequently, if all singular values of a square matrix {{math|'''M'''}} are non-degenerate and non-zero, then its singular value decomposition is unique, up to multiplication of a column of {{math|'''U'''}} by a unit-phase factor and simultaneous multiplication of the corresponding column of {{math|'''V'''}} by the same unit-phase factor.
In general, the SVD is unique up to arbitrary unitary transformations applied uniformly to the column vectors of both {{math|'''U'''}} and {{math|'''V'''}} spanning the subspaces of each singular value, and up to arbitrary unitary transformations on vectors of {{math|'''U'''}} and {{math|'''V'''}} spanning the kernel and cokernel, respectively, of {{math|'''M'''}}.

=== Relation to eigenvalue decomposition ===
The singular-value decomposition is very general in the sense that it can be applied to any {{math|''m'' × ''n''}} matrix whereas [[eigenvalue decomposition]] can only be applied to [[Diagonalizable matrix|diagonalizable matrices]]. Nevertheless, the two decompositions are related.

Given an SVD of {{math|'''M'''}}, as described above, the following two relations hold:

:&lt;math&gt;\begin{align}
\mathbf{M}^* \mathbf{M} &amp;= \mathbf{V} \boldsymbol{\Sigma}^* \mathbf{U}^*\, \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^* = \mathbf{V} (\boldsymbol{\Sigma}^* \boldsymbol{\Sigma}) \mathbf{V}^* \\
\mathbf{M} \mathbf{M}^* &amp;= \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^*\, \mathbf{V} \boldsymbol{\Sigma}^* \mathbf{U}^* = \mathbf{U} (\boldsymbol{\Sigma} \boldsymbol{\Sigma}^*) \mathbf{U}^*
\end{align}&lt;/math&gt;

The right-hand sides of these relations describe the eigenvalue decompositions of the left-hand sides.  Consequently:

:* The columns of {{math|'''V'''}} (right-singular vectors) are [[eigenvectors]] of {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}}.
:* The columns of {{math|'''U'''}} (left-singular vectors) are eigenvectors of {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}}.
:* The non-zero elements of {{math|'''Σ'''}} (non-zero singular values) are the square roots of the non-zero [[eigenvalues]] of {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}} or {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}}.

In the special case that {{math|'''M'''}} is a [[normal matrix]], which by definition must be square, the [[Spectral theorem#Finite-dimensional case|spectral theorem]] says that it can be [[Unitary transform|unitarily]] [[Diagonalizable matrix|diagonalized]] using a basis of [[eigenvector]]s, so that it can be written {{math|'''M''' {{=}} '''UDU'''&lt;sup&gt;∗&lt;/sup&gt;}} for a unitary matrix {{math|'''U'''}} and a diagonal matrix {{math|'''D'''}}.  When {{math|'''M'''}} is also [[Positive-definite matrix|positive semi-definite]], the decomposition {{math|'''M''' {{=}} '''UDU'''&lt;sup&gt;∗&lt;/sup&gt;}} is also a singular-value decomposition.  Otherwise, it can be recast as an SVD by moving the phase of each {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} to either its corresponding {{math|'''V'''&lt;sub&gt;i&lt;/sub&gt;}} or {{math|'''U'''&lt;sub&gt;i&lt;/sub&gt;}}.  The natural connection of the SVD to non-normal matrices is through the [[polar decomposition]] theorem:  {{math|'''M'''&amp;nbsp;{{=}}&amp;nbsp;'''SR'''}}, where {{math|'''S'''&amp;nbsp;{{=}}&amp;nbsp;'''UΣU'''&lt;sup&gt;*&lt;/sup&gt;}} is positive semidefinite and normal, and  {{math|'''R'''&amp;nbsp;{{=}}&amp;nbsp;'''UV'''&lt;sup&gt;*&lt;/sup&gt;}} is unitary.

Thus while related, the eigenvalue decomposition and SVD differ except for positive semi-definite normal matrices {{math|'''M'''}}: the eigenvalue decomposition is {{math|'''M''' {{=}} '''UDU'''&lt;sup&gt;−1&lt;/sup&gt;}} where {{math|'''U'''}} is not necessarily unitary and {{math|'''D'''}} is not necessarily positive semi-definite, while the SVD is {{math|'''M''' {{=}} '''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} where {{math|'''Σ'''}} is diagonal and positive semi-definite, and {{math|'''U'''}} and {{math|'''V'''}} are unitary matrices that are not necessarily related except through the matrix {{math|'''M'''}}.  While only [[defective matrix|non-defective]] square matrices have an eigenvalue decomposition, any &lt;math&gt;m \times n&lt;/math&gt; matrix has a SVD.

==Applications of the SVD==

===Pseudoinverse===
The singular-value decomposition can be used for computing the [[Moore–Penrose pseudoinverse|pseudoinverse]] of a matrix. Indeed, the pseudoinverse of the matrix {{math|'''M'''}} with singular-value decomposition {{math|'''M''' {{=}} '''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} is

:&lt;math&gt;\mathbf{M}^+ = \mathbf{V} \boldsymbol{\Sigma}^+ \mathbf{U}^*&lt;/math&gt;

where {{math|'''Σ'''&lt;sup&gt;+&lt;/sup&gt;}} is the pseudoinverse of {{math|'''Σ'''}}, which is formed by replacing every non-zero diagonal entry by its [[Multiplicative inverse|reciprocal]] and transposing the resulting matrix. The pseudoinverse is one way to solve [[linear least squares (mathematics)|linear least squares]] problems.

===Solving homogeneous linear equations===
A set of [[homogeneous linear equation]]s can be written as {{math|'''Ax''' {{=}} '''0'''}} for a matrix {{math|'''A'''}} and vector {{math|'''x'''}}. A typical situation is that {{math|'''A'''}} is known and a non-zero {{math|'''x'''}} is to be determined which satisfies the equation. Such an {{math|'''x'''}} belongs to {{math|'''A'''}}'s [[Kernel (matrix)|null space]] and is sometimes called a (right) null vector of {{math|'''A'''}}. The vector {{math|'''x'''}} can be characterized as a right-singular vector corresponding to a singular value of {{math|'''A'''}} that is zero. This observation means that if {{math|'''A'''}} is a [[square matrix]] and has no vanishing singular value, the equation has no non-zero {{math|'''x'''}} as a solution.  It also means that if there are several vanishing singular values, any linear combination of the corresponding right-singular vectors is a valid solution. Analogously to the definition of a (right) null vector, a non-zero {{math|'''x'''}} satisfying {{math|'''x'''&lt;sup&gt;∗&lt;/sup&gt;'''A''' {{=}} '''0'''}}, with {{math|'''x'''&lt;sup&gt;∗&lt;/sup&gt;}} denoting the conjugate transpose of {{math|'''x'''}}, is called a left null vector of {{math|'''A'''}}.

===Total least squares minimization===
A [[total least squares]] problem refers to determining the vector {{math|'''x'''}} which minimizes the [[Vector norm#p-norm|2-norm]] of a vector {{math|'''Ax'''}} under the constraint {{math|{{!!}}'''x'''{{!!}} {{=}} 1}}. The solution turns out to be the right-singular vector of {{math|'''A'''}} corresponding to the smallest singular value.

===Range, null space and rank===
Another application of the SVD is that it provides an explicit representation of the [[Column space|range]] and [[null space]] of a matrix {{math|'''M'''}}. The right-singular vectors corresponding to vanishing singular values of {{math|'''M'''}} span the null space of {{math|'''M'''}} and the left-singular vectors corresponding to the non-zero singular values of {{math|'''M'''}} span the range of {{math|'''M'''}}. E.g., in the above [[Singular value decomposition#Example|example]] the null space is spanned by the last two columns of {{math|'''V'''}} and the range is spanned by the first three columns of {{math|'''U'''}}.

As a consequence, the [[rank of a matrix|rank]] of {{math|'''M'''}} equals the number of non-zero singular values which is the same as the number of non-zero diagonal elements in {{math|'''Σ'''}}. In numerical linear algebra the singular values can be used to determine the ''effective rank'' of a matrix, as [[rounding error]] may lead to small but non-zero singular values in a rank deficient matrix. Singular values beyond a significant gap are assumed to be numerically equivalent to zero.

===Low-rank matrix approximation===
Some practical applications need to solve the problem of approximating a matrix {{math|'''M'''}} with another matrix &lt;math&gt;\tilde{\mathbf{M}}&lt;/math&gt;, said [[#Truncated SVD|truncated]], which has a specific rank {{mvar|r}}. In the case that the approximation is based on minimizing the [[Frobenius norm]] of the difference between {{math|'''M'''}} and &lt;math&gt;\tilde{\mathbf{M}}&lt;/math&gt; under the constraint that &lt;math&gt;\operatorname{rank}\left(\tilde{\mathbf{M}}\right) = r&lt;/math&gt; it turns out that the solution is given by the SVD of {{math|'''M'''}}, namely
:&lt;math&gt;\tilde{\mathbf{M}} = \mathbf{U} \tilde{\boldsymbol{\Sigma}} \mathbf{V}^*&lt;/math&gt;

where &lt;math&gt;\tilde{\boldsymbol{\Sigma}}&lt;/math&gt; is the same matrix as {{math|'''Σ'''}} except that it contains only the {{mvar|r}} largest singular values (the other singular values are replaced by zero). This is known as the '''Eckart–Young theorem''', as it was proved by those two authors in 1936 (although it was later found to have been known to earlier authors; see {{harvnb|Stewart|1993}}).

===Separable models===
The SVD can be thought of as decomposing a matrix into a weighted, ordered sum of separable matrices. By separable, we mean that a matrix {{math|'''A'''}} can be written as an [[outer product]] of two vectors {{math|'''A''' {{=}} '''u''' ⊗ '''v'''}}, or, in coordinates, &lt;math&gt;A_{ij} = u_i v_j&lt;/math&gt;. Specifically, the matrix {{math|'''M'''}} can be decomposed as:
:&lt;math&gt;\mathbf{M} = \sum_i \mathbf{A}_i = \sum_i \sigma_i \mathbf U_i \otimes \mathbf V_i&lt;/math&gt;

Here {{math|'''U'''&lt;sub&gt;''i''&lt;/sub&gt;}} and {{math|'''V'''&lt;sub&gt;''i''&lt;/sub&gt;}} are the {{mvar|i}}-th columns of the corresponding SVD matrices, {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} are the ordered singular values, and each {{math|'''A'''&lt;sub&gt;''i''&lt;/sub&gt;}} is separable. The SVD can be used to find the decomposition of an image processing filter into separable horizontal and vertical filters. Note that the number of non-zero {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} is exactly the rank of the matrix.

Separable models often arise in biological systems, and the SVD factorization is useful to analyze such systems. For example, some visual area V1 simple cells' receptive fields can be well described&lt;ref&gt;{{cite journal |doi=10.1016/0166-2236(95)94496-R |last1=DeAngelis|first1=G. C.|last2=Ohzawa|first2=I.|last3=Freeman|first3=R. D. |title=Receptive-field dynamics in the central visual pathways |journal=Trends Neurosci. |volume=18 |issue=10 |pages=451–8 |date=October 1995 |pmid=8545912 |url=http://linkinghub.elsevier.com/retrieve/pii/0166-2236(95)94496-R |ref=harv}}&lt;/ref&gt; by a [[Gabor filter]] in the space domain multiplied by a modulation function in the time domain. Thus, given a linear filter evaluated through, for example, [[Spike-triggered average|reverse correlation]], one can rearrange the two spatial dimensions into one dimension, thus yielding a two-dimensional filter (space, time) which can be decomposed through SVD. The first column of {{math|'''U'''}} in the SVD factorization is then a Gabor while the first column of {{math|'''V'''}} represents the time modulation (or vice versa). One may then define an index of separability,

:&lt;math&gt;\alpha = \frac{\sigma_1^2}{\sum_i \sigma_i^2},&lt;/math&gt;

which is the fraction of the power in the matrix M which is accounted for by the first separable matrix in the decomposition.&lt;ref&gt;{{cite journal |last1=Depireux|first1=D. A.|last2=Simon|first2=J. Z.|last3=Klein|first3=D. J.|last4=Shamma|first4=S. A. |title=Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex |journal=J. Neurophysiol. |volume=85 |issue=3 |pages=1220–34 |date=March 2001 |pmid=11247991 |url=http://jn.physiology.org/cgi/pmidlookup?view=long&amp;pmid=11247991 |ref=harv |doi=10.1152/jn.2001.85.3.1220}}&lt;/ref&gt;

===Nearest orthogonal matrix===
It is possible to use the SVD of a square matrix {{math|'''A'''}} to determine the [[orthogonal matrix]] {{math|'''O'''}} closest to {{math|'''A'''}}. The closeness of fit is measured by the [[Frobenius norm]] of {{math|'''O''' − '''A'''}}. The solution is the product {{math|'''UV'''&lt;sup&gt;∗&lt;/sup&gt;}}.&lt;ref&gt;[http://www.wou.edu/~beavers/Talks/Willamette1106.pdf The Singular Value Decomposition in Symmetric (Lowdin) Orthogonalization and Data Compression]&lt;/ref&gt; This intuitively makes sense because an orthogonal matrix would have the decomposition {{math|'''UIV'''&lt;sup&gt;∗&lt;/sup&gt;}} where {{math|'''I'''}} is the identity matrix, so that if {{math|'''A''' {{=}} '''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} then the product {{math|'''A''' {{=}} '''UV'''&lt;sup&gt;∗&lt;/sup&gt;}} amounts to replacing the singular values with ones.

A similar problem, with interesting applications in [[shape analysis (digital geometry)|shape analysis]], is the [[orthogonal Procrustes problem]], which consists of finding an orthogonal matrix {{math|'''O'''}} which most closely maps {{math|'''A'''}} to {{math|'''B'''}}. Specifically,

:&lt;math&gt;\mathbf{O} = \underset\Omega\operatorname{argmin} \|\mathbf{A}\boldsymbol{\Omega} - \mathbf{B}\|_F \quad\text{subject to}\quad \boldsymbol{\Omega}^\textsf{T}\boldsymbol{\Omega} = \mathbf{I}&lt;/math&gt;

where &lt;math&gt;\| \cdot \|_F&lt;/math&gt; denotes the Frobenius norm.

This problem is equivalent to finding the nearest orthogonal matrix to a given matrix {{math|'''M''' {{=}} '''A'''&lt;sup&gt;{{font|T}}&lt;/sup&gt;'''B'''}}.

===The Kabsch algorithm===
The [[Kabsch algorithm]] (called [[Wahba's problem]] in other fields) uses SVD to compute the optimal rotation (with respect to least-squares minimization) that will align a set of points with a corresponding set of points. It is used, among other applications, to compare the structures of molecules.

===Signal processing===
The SVD and pseudoinverse have been successfully applied to signal [[processing]]&lt;ref&gt;{{cite journal |last=Sahidullah |first=Md. |author2=Kinnunen, Tomi |title=Local spectral variability features for speaker verification |journal=Digital Signal Processing |date=March 2016 |volume=50 |pages=1–11 |doi=10.1016/j.dsp.2015.10.011 |url=http://www.sciencedirect.com/science/article/pii/S1051200415003140}}&lt;/ref&gt;, [[image processing]]&lt;ref&gt;{{cite journal |last= Rowayda A. Sadek |title= SVD Based Image Processing Applications: State of The Art, Contributions and Research Challenges | journal = IJACSA, International Journal of Advanced Computer Science and Applications|date=2012|volume=Vol. 3|issue=No. 7|pages=26-34| doi = 10.14569/IJACSA.2012.030703 | url =https://dx.doi.org/10.14569/IJACSA.2012.030703
|arxiv=1211.7102}}&lt;/ref&gt; and [[big data]], e.g., in genomic signal processing.&lt;ref&gt;{{Cite journal
 | author = O. Alter, P. O. Brown and D. Botstein
 | title = Singular Value Decomposition for Genome-Wide Expression Data Processing and Modeling
 | journal = PNAS
 | volume = 97
 | issue = 18
 | pages = 10101–10106
 | date = September 2000
 | doi = 10.1073/pnas.97.18.10101
 | url = https://dx.doi.org/10.1073/pnas.97.18.10101
 | pmc = 27718
 | bibcode = 2000PNAS...9710101A
 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | author1=O. Alter |author2=G. H. Golub
 | title = Integrative Analysis of Genome-Scale Data by Using Pseudoinverse Projection Predicts Novel Correlation Between DNA Replication and RNA Transcription
 | journal = PNAS
 | volume = 101
 | issue = 47
 | pages = 16577–16582
 | date = November 2004
 | doi = 10.1073/pnas.0406767101
 | url = https://dx.doi.org/10.1073/pnas.0406767101
 | pmid=15545604
 | pmc=534520
 | bibcode=2004PNAS..10116577A}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | author1=O. Alter  |author2=G. H. Golub
 | title = Singular Value Decomposition of Genome-Scale mRNA Lengths Distribution Reveals Asymmetry in RNA Gel Electrophoresis Band Broadening
 | journal = PNAS
 | volume = 103
 | issue = 32
 | pages = 11828–11833
 | date = August 2006
 | doi = 10.1073/pnas.0604756103
 | url = https://dx.doi.org/10.1073/pnas.0604756103
 | pmid=16877539
 | pmc=1524674
 | bibcode=2006PNAS..10311828A}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal
 | first1 = N. M.
 | last1 = Bertagnolli
 | first2 = J. A.
 | last2 = Drake
 | first3 = J. M.
 | last3 = Tennessen
 | first4 = O.
 | last4 = Alter
 | title = SVD Identifies Transcript Length Distribution Functions from DNA Microarray Data and Reveals Evolutionary Forces Globally Affecting GBM Metabolism
 | journal = PLOS ONE
 | volume = 8
 | issue = 11
 | pages = e78913
 | date = November 2013
 | doi = 10.1371/journal.pone.0078913
 | url = https://dx.doi.org/10.1371/journal.pone.0078913
 | id = [http://www.alterlab.org/research/highlights/pone.0078913_Highlight.pdf Highlight]
 | pmid=24282503
 | pmc=3839928
 | bibcode = 2013PLoSO...878913B
 }}&lt;/ref&gt;

===Other examples===
The SVD is also applied extensively to the study of linear [[inverse problem]]s, and is useful in the analysis of regularization methods such as that of [[Tikhonov regularization|Tikhonov]]. It is widely used in statistics where it is related to [[principal component analysis]] and to [[Correspondence analysis]], and in [[signal processing]] and [[pattern recognition]]. It is also used in output-only [[modal analysis]], where the non-scaled [[mode shape]]s can be determined from the singular vectors. Yet another usage is [[latent semantic indexing]] in natural language text processing.

The SVD also plays a crucial role in the field of [[quantum information]], in a form often referred to as the [[Schmidt decomposition]]. Through it, states of two quantum systems are naturally decomposed, providing a necessary and sufficient condition for them to be [[Quantum entanglement|entangled]]: if the rank of the {{math|'''Σ'''}} matrix is larger than one.

One application of SVD to rather large matrices is in [[numerical weather prediction]], where [[Lanczos algorithm|Lanczos method]]s are used to estimate the most linearly quickly growing few perturbations to the central numerical weather prediction over a given initial forward time period; i.e., the singular vectors corresponding to the largest singular values of the linearized propagator for the global weather over that time interval. 
The output singular vectors in this case are entire weather systems. These perturbations are then run through the full nonlinear model to generate an [[ensemble forecasting|ensemble forecast]], giving a handle on some of the uncertainty that should be allowed for around the current central prediction.

SVD has also been applied to reduced order modelling. The aim of reduced order modelling is to reduce the number of degrees of freedom in a complex system which is to be modelled. SVD was coupled with [[radial basis functions]] to interpolate solutions to three-dimensional unsteady flow problems.&lt;ref&gt;{{cite journal | last1 = Walton | first1 = S. | last2 = Hassan | first2 = O. | last3 = Morgan | first3 = K. | year = 2013| title = Reduced order modelling for unsteady fluid flow using proper orthogonal decomposition and radial basis functions | url = http://www.sciencedirect.com/science/article/pii/S0307904X13002771 | journal = Applied Mathematical Modelling | volume =  37| issue = | pages = 8930–8945| doi=10.1016/j.apm.2013.04.025}}&lt;/ref&gt;

Singular-value decomposition is used in [[recommender systems]] to predict people's item ratings.&lt;ref&gt;{{cite journal |last=Sarwar |first=Badrul |last2=Karypis |first2=George |last3=Konstan |first3=Joseph A. |last4=Riedl |first4=John T. |lastauthoramp=yes |year=2000 |title=Application of Dimensionality Reduction in Recommender System -- A Case Study |url=http://files.grouplens.org/papers/webKDD00.pdf |format=PDF |accessdate=May 26, 2014 |publisher=[[University of Minnesota]]}}&lt;/ref&gt; Distributed algorithms have been developed for the purpose of calculating the SVD on clusters of commodity machines.&lt;ref&gt;{{cite journal|last1=Bosagh Zadeh|first1=Reza|last2=Carlsson|first2=Gunnar|title=Dimension Independent Matrix Square Using MapReduce|url=http://stanford.edu/~rezab/papers/dimsum.pdf|accessdate=12 July 2014}}&lt;/ref&gt;

Another code implementation of the Netflix Recommendation Algorithm SVD (the third optimal algorithm in the competition conducted by Netflix to find the best collaborative filtering techniques for predicting user ratings for films based on previous reviews) in platform Apache Spark is available in the following GitHub repository &lt;ref&gt;https://github.com/it21208/SVDMovie-Lens-Parallel-Apache-Spark&lt;/ref&gt; implemented by Alexandros Ioannidis. The original SVD algorithm,&lt;ref&gt;http://www.timelydevelopment.com/demos/NetflixPrize.aspx&lt;/ref&gt; which in this case is executed in parallel encourages users of the GroupLens website, by consulting proposals for monitoring new films tailored to the needs of each user.

Low-rank SVD has been applied for hotspot detection from spatiotemporal data with application to disease [[outbreak]] detection 
.&lt;ref&gt;{{Cite journal
 |author1=Hadi Fanaee-T  |author2=João Gama
  |lastauthoramp=yes | title = Eigenspace method for spatiotemporal hotspot detection
 | journal = Expert Systems
 | pages = 1–11
 | date = September 2014
 | doi = 10.1111/exsy.12088
 | url = https://dx.doi.org/10.1111/exsy.12088
|arxiv=1406.3506}}&lt;/ref&gt; A combination of SVD and [[Higher-order singular value decomposition|higher-order SVD]] also has been applied for real time event detection from complex data streams (multivariate data with space and time dimensions) in [[Disease surveillance]].&lt;ref&gt;{{Cite journal
 |author1=Hadi Fanaee-T  |author2=João Gama
  |lastauthoramp=yes | title = EigenEvent: An Algorithm for Event Detection from Complex Data Streams in Syndromic Surveillance
 | journal = Intelligent Data Analysis
 | volume = 19
 | issue = 3
 | date = May 2015
 | arxiv = 1406.3496
 | doi=10.3233/IDA-150734}}&lt;/ref&gt;

== Existence proofs ==
An eigenvalue {{mvar|λ}} of a matrix {{math|'''M'''}} is characterized by the algebraic relation {{math|'''M'''''u'' {{=}} ''λu''}}. When {{math|'''M'''}} is [[Hermitian matrix|Hermitian]], a variational characterization is also available. Let {{math|'''M'''}} be a real {{math|''n'' × ''n''}} [[symmetric matrix]]. Define

:&lt;math&gt;\begin{cases} f : \mathbb{R}^n \to \mathbb{R} \\ f(x) = x^\textsf{T} \mathbf{M} x \end{cases}&lt;/math&gt;

By the [[extreme value theorem]], this continuous function attains a maximum at some ''u'' when restricted to the closed unit sphere {||''x''|| ≤ 1}. By the [[Lagrange multipliers]] theorem, ''u'' necessarily satisfies

:&lt;math&gt;\nabla f = \nabla x^\textsf{T} \mathbf{M} x = \lambda \cdot \nabla x^\textsf{T} x&lt;/math&gt;

where the nabla symbol, {{math|∇}}, is the [[del]] operator.

A short calculation shows the above leads to {{math|'''M'''''u'' {{=}} ''λu''}} (symmetry of {{math|'''M'''}} is needed here). Therefore, {{mvar|λ}} is the largest eigenvalue of {{math|'''M'''}}. The same calculation performed on the orthogonal complement of ''u'' gives the next largest eigenvalue and so on. The complex Hermitian case is similar; there ''f''(''x'') = ''x* M x'' is a real-valued function of {{math|2''n''}} real variables.

Singular values are similar in that they can be described algebraically or from variational principles. Although, unlike the eigenvalue case, Hermiticity, or symmetry, of {{math|'''M'''}} is no longer required.

This section gives these two arguments for existence of singular-value decomposition.

=== Based on the spectral theorem ===
Let &lt;math&gt;\mathbf{M}&lt;/math&gt; be an {{math|''m'' × ''n''}} complex matrix. Since &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; is positive semi-definite and Hermitian, by the [[spectral theorem]], there exists an {{math|''n'' × ''n''}} unitary matrix &lt;math&gt;\mathbf{V}&lt;/math&gt; such that

:&lt;math&gt;\mathbf{V}^* \mathbf{M}^* \mathbf{M} \mathbf{V} = \bar\mathbf{D} = \begin{bmatrix} \mathbf{D} &amp; 0 \\ 0 &amp; 0\end{bmatrix},&lt;/math&gt;

where &lt;math&gt;\mathbf{D}&lt;/math&gt; is diagonal and positive definite, of dimension &lt;math&gt;\ell\times \ell&lt;/math&gt;, with &lt;math&gt;\ell&lt;/math&gt; the number of non-zero eigenvalues of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; (which can be shown to verify &lt;math&gt;\ell\le\min(n,m)&lt;/math&gt;). Note that &lt;math&gt;\mathbf{V}&lt;/math&gt; is here by definition a matrix whose &lt;math&gt;i&lt;/math&gt;-th column is the &lt;math&gt;i&lt;/math&gt;-th eigenvector of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt;, corresponding to the eigenvalue &lt;math&gt;\bar{\mathbf{D}}_{ii}&lt;/math&gt;. Moreover, the &lt;math&gt;j&lt;/math&gt;-th column of &lt;math&gt;\mathbf{V}&lt;/math&gt;, for &lt;math&gt;j&gt;\ell&lt;/math&gt;, is an eigenvector of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; with eigenvalue &lt;math&gt;\bar{\mathbf{D}}_{jj}=0&lt;/math&gt;. This can be expressed by writing &lt;math&gt;\mathbf{V}&lt;/math&gt;  as &lt;math&gt;\mathbf{V}=\begin{bmatrix}\mathbf{V}_1 &amp;\mathbf{V}_2\end{bmatrix}&lt;/math&gt;, where the columns of &lt;math&gt;\mathbf{V}_1&lt;/math&gt; and &lt;math&gt;\mathbf{V}_2&lt;/math&gt; therefore contain the eigenvectors of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; corresponding to non-zero and zero eigenvalues, respectively. Using this rewriting of &lt;math&gt;\mathbf{V}&lt;/math&gt;, the equation becomes:

:&lt;math&gt;\begin{bmatrix} \mathbf{V}_1^* \\ \mathbf{V}_2^* \end{bmatrix} \mathbf{M}^* \mathbf{M} \begin{bmatrix} \mathbf{V}_1 &amp; \mathbf{V}_2 \end{bmatrix} = \begin{bmatrix} \mathbf{V}_1^* \mathbf{M}^* \mathbf{M} \mathbf{V}_1 &amp; \mathbf{V}_1^* \mathbf{M}^* \mathbf{M} \mathbf{V}_2 \\ \mathbf{V}_2^* \mathbf{M}^* \mathbf{M} \mathbf{V}_1 &amp; \mathbf{V}_2^* \mathbf{M}^* \mathbf{M} \mathbf{V}_2 \end{bmatrix} = \begin{bmatrix} \mathbf{D} &amp; 0 \\ 0 &amp; 0 \end{bmatrix}.&lt;/math&gt;

This implies that

:&lt;math&gt;\mathbf{V}_1^* \mathbf{M}^* \mathbf{M} \mathbf{V}_1 = \mathbf{D}, \qquad \mathbf{V}_2^* \mathbf{M}^* \mathbf{M} \mathbf{V}_2 = \mathbf{0}.&lt;/math&gt;

Moreover, the second equation implies &lt;math&gt;\mathbf{M}\mathbf{V}_2=\mathbf{0}&lt;/math&gt;.&lt;ref&gt;To see this, we just have to notice that &lt;math&gt;\mathbf{V}_2^* \mathbf{M}^* \mathbf{M} \mathbf{V}_2=\|\mathbf{M} \mathbf{V}_2\|^2&lt;/math&gt;, and remember that &lt;math&gt;\|A\|=0\Longleftrightarrow A=0&lt;/math&gt;&lt;/ref&gt; Finally, the unitarity of &lt;math&gt;\mathbf{V}&lt;/math&gt; translates, in terms of &lt;math&gt;\mathbf{V}_1&lt;/math&gt; and &lt;math&gt;\mathbf{V}_2&lt;/math&gt;, into the following conditions:

:&lt;math&gt;\begin{align} 
\mathbf{V}_1^* \mathbf{V}_1 &amp;= \mathbf{I_1}, \\
\mathbf{V}_2^* \mathbf{V}_2 &amp;= \mathbf{I_2}, \\
\mathbf{V}_1 \mathbf{V}_1^* + \mathbf{V}_2 \mathbf{V}_2^* &amp;= \mathbf{I_{12}},
\end{align}&lt;/math&gt;

where the subscripts on the identity matrices are used to remark that they are of different dimensions.

Let us now define

:&lt;math&gt;\mathbf{U}_1 = \mathbf{M} \mathbf{V}_1 \mathbf{D}^{-\frac{1}{2}}.&lt;/math&gt;

Then,

:&lt;math&gt;\mathbf{U}_1 \mathbf{D}^\frac{1}{2} \mathbf{V}_1^* = \mathbf{M} \mathbf{V}_1 \mathbf{D}^{-\frac{1}{2}} \mathbf{D}^\frac{1}{2} \mathbf{V}_1^* = \mathbf{M} (\mathbf{I} - \mathbf{V}_2\mathbf{V}_2^*) = \mathbf{M} - (\mathbf{M}\mathbf{V}_2)\mathbf{V}_2^* = \mathbf{M},&lt;/math&gt;

since &lt;math&gt;\mathbf{M}\mathbf{V}_2 = \mathbf{0}. &lt;/math&gt; This can be also seen as immediate consequence of the fact that &lt;math&gt;\mathbf{M}\mathbf{V}_1\mathbf{V}_1^* = \mathbf{M}&lt;/math&gt;. Note how this is equivalent to the observation that, if &lt;math&gt;\{\boldsymbol v_i\}_{i=1}^l&lt;/math&gt; if the set of eigenvectors of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; corresponding to non-vanishing eigenvalues, then &lt;math&gt;\{\mathbf M \boldsymbol v_i\}_{i=1}^l&lt;/math&gt; is a set of orthogonal vectors, and &lt;math&gt;\{\lambda^{-1/2}\mathbf M \boldsymbol v_i\}_{i=1}^l&lt;/math&gt; a (generally not complete) set of ''orthonormal'' vectors. This matches with the matrix formalism used above denoting with &lt;math&gt;\mathbf{V}_1&lt;/math&gt; the matrix whose columns are &lt;math&gt;\{\boldsymbol v_i\}_{i=1}^l&lt;/math&gt;, with &lt;math&gt;\mathbf{V}_2&lt;/math&gt; the matrix whose columns are the eigenvectors of &lt;math&gt;\mathbf{M}^* \mathbf{M}&lt;/math&gt; which vanishing eigenvalue, and &lt;math&gt;\mathbf{U}_1&lt;/math&gt; the matrix whose columns are the vectors &lt;math&gt;\{\lambda^{-1/2}\mathbf M \boldsymbol v_i\}_{i=1}^l&lt;/math&gt;.

We see that this is almost the desired result, except that &lt;math&gt;\mathbf{U}_1&lt;/math&gt; and &lt;math&gt;\mathbf{V}_1&lt;/math&gt; are in general not unitary, since they might not be square. However, we do know that the number of rows of &lt;math&gt;\mathbf{U}_1&lt;/math&gt; is no smaller than the number of columns, since the dimensions of &lt;math&gt;\mathbf{D}&lt;/math&gt; is no greater than &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt;. Also, since

:&lt;math&gt;\mathbf{U}_1^*\mathbf{U}_1 = \mathbf{D}^{-\frac{1}{2}}\mathbf{V}_1^*\mathbf{M}^*\mathbf{M} \mathbf{V}_1 \mathbf{D}^{-\frac{1}{2}}=\mathbf{D}^{-\frac{1}{2}}\mathbf{D}\mathbf{D}^{-\frac{1}{2}} = \mathbf{I_1}&lt;/math&gt;

the columns in &lt;math&gt;\mathbf{U}_1&lt;/math&gt; are orthonormal and can be extended to an orthonormal basis. This means that we can choose &lt;math&gt;\mathbf{U}_2&lt;/math&gt; such that &lt;math&gt;\mathbf{U} = \begin{bmatrix} \mathbf{U}_1 &amp; \mathbf{U}_2 \end{bmatrix}&lt;/math&gt; is unitary.

For {{math|'''V'''&lt;sub&gt;1&lt;/sub&gt;}} we already have {{math|'''V'''&lt;sub&gt;2&lt;/sub&gt;}} to make it unitary. Now, define

:&lt;math&gt;\boldsymbol{\Sigma} =
  \begin{bmatrix}
    \begin{bmatrix}
      \mathbf{D}^\frac{1}{2} &amp; 0 \\
      0                      &amp; 0
    \end{bmatrix} \\
    0
  \end{bmatrix}&lt;/math&gt;

where extra zero rows are added '''or removed''' to make the number of zero rows equal the number of columns of {{math|'''U'''&lt;sub&gt;2&lt;/sub&gt;}}, and hence the overall dimensions of &lt;math&gt;\boldsymbol{\Sigma}&lt;/math&gt; equal to &lt;math&gt;m\times n&lt;/math&gt;. Then

:&lt;math&gt; \begin{bmatrix}
    \mathbf{U}_1 &amp; \mathbf{U}_2
  \end{bmatrix}
  \begin{bmatrix}
    \begin{bmatrix}
      \mathbf{}D^\frac{1}{2} &amp; 0 \\
      0                      &amp; 0
    \end{bmatrix} \\
    0
  \end{bmatrix}
  \begin{bmatrix}
    \mathbf{V}_1 &amp; \mathbf{V}_2
  \end{bmatrix}^* =
  \begin{bmatrix}
    \mathbf{U}_1 &amp; \mathbf{U}_2
  \end{bmatrix}
  \begin{bmatrix} \mathbf{D}^\frac{1}{2} \mathbf{V}_1^* \\ 0 \end{bmatrix} =
\mathbf{U}_1 \mathbf{D}^\frac{1}{2} \mathbf{V}_1^* = \mathbf{M} &lt;/math&gt;

which is the desired result:

:&lt;math&gt;\mathbf{M} = \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^*&lt;/math&gt;

Notice the argument could begin with diagonalizing {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}} rather than {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}} (This shows directly that {{math|'''MM'''&lt;sup&gt;∗&lt;/sup&gt;}} and {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}} have the same non-zero eigenvalues).

===  Based on variational characterization ===
{{anchor|vch}}The singular values can also be characterized as the maxima of {{math|'''u'''&lt;sup&gt;{{font|T}}&lt;/sup&gt;'''Mv'''}}, considered as a function of {{math|'''u'''}} and {{math|'''v'''}}, over particular subspaces. The singular vectors are the values of {{math|'''u'''}} and {{math|'''v'''}} where these maxima are attained.

Let {{math|'''M'''}} denote an {{math|''m'' × ''n''}} matrix with real entries. Let {{math|''S''&lt;sup&gt;''m''−1&lt;/sup&gt;}} and &lt;math&gt; \mathbf{v} = \mathbf{u}^\textsf{T} \mathbf{M} \mathbf{v}, \qquad \mathbf{u} \in S^{m-1}, \mathbf{v} \in S^{n-1}.&lt;/math&gt;

Consider the function {{mvar|σ}} restricted to {{math|''S''&lt;sup&gt;''m''−1&lt;/sup&gt; × ''S''&lt;sup&gt;''n''−1&lt;/sup&gt;}}. Since both {{math|''S''&lt;sup&gt;''m''−1&lt;/sup&gt;}} and {{math|''S''&lt;sup&gt;''n''−1&lt;/sup&gt;}} are [[compact space|compact]] sets, their [[Product topology|product]] is also compact.  Furthermore, since {{mvar|σ}} is continuous, it attains a largest value for at least one pair of vectors {{math|'''u''' ∈ ''S''&lt;sup&gt;''m''−1&lt;/sup&gt;}} and {{math|'''v''' ∈ ''S''&lt;sup&gt;''n''−1&lt;/sup&gt;}}. This largest value is denoted {{math|''σ''&lt;sub&gt;1&lt;/sub&gt;}} and the corresponding vectors are denoted {{math|'''u'''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|'''v'''&lt;sub&gt;1&lt;/sub&gt;}}. Since {{math|''σ''&lt;sub&gt;1&lt;/sub&gt;}} is the largest value of {{math|''σ''('''u''', '''v''')}} it must be non-negative. If it were negative, changing the sign of either {{math|'''u'''&lt;sub&gt;1&lt;/sub&gt;}} or {{math|'''v'''&lt;sub&gt;1&lt;/sub&gt;}} would make it positive and therefore larger.

'''Statement.''' {{math|'''u'''&lt;sub&gt;1&lt;/sub&gt;, '''v'''&lt;sub&gt;1&lt;/sub&gt;}} are left and right-singular vectors of {{math|'''M'''}} with corresponding singular value ''σ''&lt;sub&gt;1&lt;/sub&gt;.

'''Proof.''' Similar to the eigenvalues case, by assumption the two vectors satisfy the Lagrange multiplier equation:

:&lt;math&gt;\nabla \sigma = \nabla \mathbf{u}^\textsf{T} \mathbf{M} \mathbf{v} - \lambda_1 \cdot \nabla \mathbf{u}^\textsf{T} \mathbf{u} - \lambda_2 \cdot \nabla \mathbf{v}^\textsf{T} \mathbf{v}&lt;/math&gt;

After some algebra, this becomes

:&lt;math&gt;\begin{align}
             \mathbf{M} \mathbf{v}_{1} &amp;= 2 \lambda_1 \mathbf{u}_1 + 0 \\
  \mathbf{M}^\textsf{T} \mathbf{u}_{1} &amp;= 0 + 2 \lambda_2 \mathbf{v}_1
\end{align}&lt;/math&gt;

Multiplying the first equation from left by &lt;math&gt;\mathbf{u}_1^\textsf{T}&lt;/math&gt; and the second equation from left by &lt;math&gt;\mathbf{v}_1^\textsf{T}&lt;/math&gt; and taking {{math|{{!!}}'''u'''{{!!}} {{=}} {{!!}}'''v'''{{!!}} {{=}} 1}}  into account gives

:&lt;math&gt;\sigma_1 = 2\lambda_1 = 2\lambda_2.&lt;/math&gt;

Plugging this into the pair of equations above, we have

:&lt;math&gt;\begin{align}
             \mathbf{M} \mathbf{v}_1 &amp;= \sigma_1 \mathbf{u}_1\\
  \mathbf{M}^\textsf{T} \mathbf{u}_1 &amp;= \sigma_1 \mathbf{v}_1
\end{align}&lt;/math&gt;

This proves the statement.

More singular vectors and singular values can be found by maximizing {{math|''σ''('''u''', '''v''')}} over normalized {{math|'''u''', '''v'''}} which are orthogonal to {{math|'''u'''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|'''v'''&lt;sub&gt;1&lt;/sub&gt;}}, respectively.

The passage from real to complex is similar to the eigenvalue case.

== Calculating the SVD ==

=== Numerical approach ===
The SVD of a matrix {{math|'''M'''}} is typically computed by a two-step procedure. In the first step, the matrix is reduced to a [[bidiagonal matrix]]. This takes [[big O notation|O]](''mn''&lt;sup&gt;2&lt;/sup&gt;) floating-point operations (flop), assuming that ''m'' ≥ ''n''. The second step is to compute the SVD of the bidiagonal matrix. This step can only be done with an [[iterative method]] (as with [[eigenvalue algorithm]]s). However, in practice it suffices to compute the SVD up to a certain precision, like the [[machine epsilon]]. If this precision is considered constant, then the second step takes O(''n'') iterations, each costing O(''n'') flops. Thus, the first step is more expensive, and the overall cost is O(''mn''&lt;sup&gt;2&lt;/sup&gt;) flops {{harv|Trefethen|Bau III|1997|loc=Lecture 31}}.

The first step can be done using [[Householder reflection]]s for a cost of 4''mn''&lt;sup&gt;2&lt;/sup&gt; − 4''n''&lt;sup&gt;3&lt;/sup&gt;/3 flops, assuming that only the singular values are needed and not the singular vectors. If ''m'' is much larger than ''n'' then it is advantageous to first reduce the matrix ''M'' to a triangular matrix with the [[QR decomposition]] and then use Householder reflections to further reduce the matrix to bidiagonal form; the combined cost is 2''mn''&lt;sup&gt;2&lt;/sup&gt; + 2''n''&lt;sup&gt;3&lt;/sup&gt; flops {{harv|Trefethen|Bau III|1997|loc=Lecture 31}}.

The second step can be done by a variant of the [[QR algorithm]] for the computation of eigenvalues, which was first described by {{harvtxt|Golub|Kahan|1965}}. The [[LAPACK]] subroutine DBDSQR&lt;ref&gt;[http://www.netlib.org/lapack/double/dbdsqr.f Netlib.org]&lt;/ref&gt; implements this iterative method, with some modifications to cover the case where the singular values are very small {{harv|Demmel|Kahan|1990}}. Together with a first step using Householder reflections and, if appropriate, QR decomposition, this forms the DGESVD&lt;ref&gt;[http://www.netlib.org/lapack/double/dgesvd.f Netlib.org]&lt;/ref&gt; routine for the computation of the singular-value decomposition.

The same algorithm is implemented in the [[GNU Scientific Library]] (GSL). The GSL also offers an alternative method, which uses a one-sided [[Jacobi orthogonalization]] in step 2 {{harv|GSL Team|2007}}. This method computes the SVD of the bidiagonal matrix by solving a sequence of 2 × 2 SVD problems, similar to how the [[Jacobi eigenvalue algorithm]] solves a sequence of 2 × 2 eigenvalue methods {{harv|Golub|Van Loan|1996|loc=§8.6.3}}. Yet another method for step 2 uses the idea of [[divide-and-conquer eigenvalue algorithm]]s {{harv|Trefethen|Bau III|1997|loc=Lecture 31}}.

There is an alternative way which is not explicitly using the eigenvalue decomposition.&lt;ref&gt;[http://www.mathworks.co.kr/matlabcentral/fileexchange/12674-simple-svd mathworks.co.kr/matlabcentral/fileexchange/12674-simple-svd]&lt;/ref&gt; Usually the singular-value problem of  a matrix {{math|'''M'''}} is converted into an equivalent symmetric eigenvalue problem such as {{math|'''M M'''&lt;sup&gt;*&lt;/sup&gt;}}, {{math|'''M'''&lt;sup&gt;*&lt;/sup&gt;'''M'''}}, or 
:&lt;math&gt; \begin{pmatrix} \mathbf{O} &amp; \mathbf{M} \\ \mathbf{M}^* &amp; \mathbf{O} \end{pmatrix}. &lt;/math&gt;
The approaches using eigenvalue decompositions are based on [[QR algorithm]] which is well-developed to be stable and fast. 
Note that the singular values are real and right- and left- singular vectors are not required to form any similarity transformation. Alternating [[QR decomposition]] and [[LQ decomposition]] can be claimed to use iteratively to find the real diagonal matrix with [[Hermitian matrix|Hermitian matrices]]. [[QR decomposition]] gives {{math|'''M''' ⇒ '''Q''' '''R'''}} and [[LQ decomposition]] of {{math|'''R'''}} gives {{math|'''R''' ⇒ '''L''' '''P'''&lt;sup&gt;*&lt;/sup&gt;}}. Thus, at every iteration, we have {{math|'''M''' ⇒ '''Q''' '''L''' '''P'''&lt;sup&gt;*&lt;/sup&gt;}}, update {{math|'''M''' ⇐ '''L'''}} and repeat the orthogonalizations.
Eventually, [[QR decomposition]] and [[LQ decomposition]] iteratively provide unitary matrices for left- and right- singular matrices, respectively. 
This approach does not come with any acceleration method such as spectral shifts and deflation as in QR algorithm. It is because the shift method is not easily defined without using similarity transformation.  But it is very simple to implement where the speed does not matter. Also it give us a good interpretation that only orthogonal/unitary transformations can obtain SVD as the [[QR algorithm]] can calculate the [[eigenvalue decomposition]].

=== Analytic result of 2 × 2 SVD ===
The singular values of a 2 × 2 matrix can be found analytically. Let the matrix be
&lt;math&gt;\mathbf{M} = z_0\mathbf{I} + z_1\sigma_1 + z_2\sigma_2 + z_3\sigma_3&lt;/math&gt;

where &lt;math&gt;z_i \in \mathbb{C}&lt;/math&gt; are complex numbers that parameterize the matrix, {{math|'''I'''}} is the identity matrix, and &lt;math&gt;\sigma_i&lt;/math&gt; denote the [[Pauli matrices]]. Then its two singular values are given by
:&lt;math&gt;\begin{align}
\sigma_\pm &amp;= \sqrt{|z_0|^2 + |z_1|^2 + |z_2|^2 + |z_3|^2 \pm \sqrt{(|z_0|^2 + |z_1|^2 + |z_2|^2 + |z_3|^2)^2 - |z_0^2 - z_1^2 - z_2^2 - z_3^2|^2}} \\
&amp;= \sqrt{|z_0|^2 + |z_1|^2 + |z_2|^2 + |z_3|^2 \pm 2\sqrt{(\operatorname{Re}z_0z_1^*)^2 + (\operatorname{Re}z_0z_2^*)^2 + (\operatorname{Re}z_0z_3^*)^2 + (\operatorname{Im}z_1z_2^*)^2 + (\operatorname{Im}z_2z_3^*)^2 + (\operatorname{Im}z_3z_1^*)^2}}
\end{align}&lt;/math&gt;

==Reduced SVDs==
In applications it is quite unusual for the full SVD, including a full unitary decomposition of the null-space of the matrix, to be required.  Instead, it is often sufficient (as well as faster, and more economical for storage) to compute a reduced version of the SVD.  The following can be distinguished for an ''m''×''n'' matrix ''M'' of rank ''r'':

===Thin SVD===
:&lt;math&gt;\mathbf{M} = \mathbf{U}_n \boldsymbol{\Sigma}_n \mathbf{V}^*&lt;/math&gt;

Only the ''n'' column vectors of ''U'' corresponding to the row vectors of ''V*'' are calculated. The remaining column vectors of ''U'' are not calculated. This is significantly quicker and more economical than the full SVD if ''n''&amp;nbsp;≪&amp;nbsp;''m''. The matrix ''U''&lt;sub&gt;'''n''&lt;/sub&gt; is thus ''m''×''n'', Σ&lt;sub&gt;''n''&lt;/sub&gt; is ''n''×''n'' diagonal, and ''V'' is ''n''×''n''.

The first stage in the calculation of a thin SVD will usually be a [[QR decomposition]] of ''M'', which can make for a significantly quicker calculation if&amp;nbsp;''n''&amp;nbsp;≪&amp;nbsp;''m''.

===Compact SVD===
:&lt;math&gt;\mathbf{M} = \mathbf{U}_r \boldsymbol{\Sigma}_r \mathbf{V}_r^*&lt;/math&gt;

Only the ''r'' column vectors of ''U'' and ''r'' row vectors of ''V*'' corresponding to the non-zero singular values Σ&lt;sub&gt;''r''&lt;/sub&gt; are calculated. The remaining vectors of ''U'' and ''V*'' are not calculated. This is quicker and more economical than the thin SVD if ''r''&amp;nbsp;≪&amp;nbsp;''n''. The matrix ''U''&lt;sub&gt;''r''&lt;/sub&gt; is thus ''m''×''r'', Σ&lt;sub&gt;''r''&lt;/sub&gt; is ''r''×''r'' diagonal, and ''V''&lt;sub&gt;''r''&lt;/sub&gt;* is ''r''×''n''.

===Truncated SVD===
:&lt;math&gt;\tilde{\mathbf{M}} = \mathbf{U}_t \boldsymbol{\Sigma}_t \mathbf{V}_t^*&lt;/math&gt;

Only the ''t'' column vectors of ''U'' and ''t'' row vectors of ''V*'' corresponding to the ''t'' largest singular values Σ&lt;sub&gt;''t''&lt;/sub&gt; are calculated. The rest of the matrix is discarded. This can be much quicker and more economical than the compact SVD if ''t''≪''r''. The matrix ''U''&lt;sub&gt;''t''&lt;/sub&gt; is thus ''m''×''t'', Σ&lt;sub&gt;''t''&lt;/sub&gt; is ''t''×''t'' diagonal, and ''V''&lt;sub&gt;''t''&lt;/sub&gt;* is ''t''×''n''.

Of course the truncated SVD is no longer an exact decomposition of the original matrix ''M'', but as discussed [[#Low-rank matrix approximation|above]], the approximate matrix &lt;math&gt;\tilde{\mathbf{M}}&lt;/math&gt; is in a very useful sense the closest approximation to ''M'' that can be achieved by a matrix of rank&amp;nbsp;''t''.

==Norms==

=== Ky Fan norms ===
The sum of the ''k'' largest singular values of ''M'' is a [[matrix norm]], the [[Ky Fan]] ''k''-norm of ''M''. &lt;ref&gt;{{Cite journal|last=Fan|first=Ky.|date=1951|title=Maximum properties and inequalities for the eigenvalues of completely continuous operators|url=http://www.pnas.org/content/37/11/760.citation|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=37|issue=11|pages=760–766|doi=10.1073/pnas.37.11.760|pmc=1063464|bibcode=1951PNAS...37..760F}}&lt;/ref&gt;

The first of the Ky Fan norms, the Ky Fan 1-norm, is the same as the [[operator norm]] of ''M'' as a linear operator with respect to the Euclidean norms of ''K''&lt;sup&gt;''m''&lt;/sup&gt; and ''K''&lt;sup&gt;''n''&lt;/sup&gt;. In other words, the Ky Fan 1-norm is the operator norm induced by the standard ''ℓ''&lt;sup&gt;2&lt;/sup&gt; Euclidean inner product. For this reason, it is also called the operator 2-norm. One can easily verify the relationship between the Ky Fan 1-norm and singular values. It is true in general, for a bounded operator ''M'' on (possibly infinite-dimensional) Hilbert spaces

:&lt;math&gt;\| \mathbf{M} \| = \| \mathbf{M}^* \mathbf{M} \|^\frac{1}{2}&lt;/math&gt;

But, in the matrix case, (''M* M'')&lt;sup&gt;½&lt;/sup&gt; is a [[normal matrix]], so ||''M* M''||&lt;sup&gt;½&lt;/sup&gt; is the largest eigenvalue of (''M* M'')&lt;sup&gt;½&lt;/sup&gt;, i.e. the largest singular value of ''M''.

The last of the Ky Fan norms, the sum of all singular values, is the [[trace class|trace norm]] (also known as the 'nuclear norm'), defined by ||''M''|| = Tr[(''M* M'')&lt;sup&gt;½&lt;/sup&gt;] (the eigenvalues of ''M* M'' are the squares of the singular values).

=== Hilbert–Schmidt norm{{Anchor|Hilbert–Schmidt norm|Hilbert-Schmidt norm|Hilbert–Schmidt|Hilbert-Schmidt}} ===
The singular values are related to another norm on the space of operators. Consider the [[Hilbert–Schmidt operator|Hilbert–Schmidt]] inner product on the {{math|''n'' × ''n''}} matrices, defined by

:&lt;math&gt;\langle \mathbf{M}, \mathbf{N} \rangle = \operatorname{trace} \left (\mathbf{N}^*\mathbf{M} \right ).&lt;/math&gt;

So the induced norm is

:&lt;math&gt;\| \mathbf{M} \| = \sqrt{\langle \mathbf{M}, \mathbf{M}\rangle} = \sqrt{\operatorname{trace} \left (\mathbf{M}^*\mathbf{M} \right )}.&lt;/math&gt;

Since the trace is invariant under unitary equivalence, this shows

:&lt;math&gt;\| \mathbf{M} \| = \sqrt{\sum_i \sigma_i ^2}&lt;/math&gt;

where {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} are the singular values of {{math|'''M'''}}. This is called the '''[[Frobenius norm]]''', '''Schatten 2-norm''', or '''Hilbert–Schmidt norm''' of {{math|'''M'''}}. Direct calculation shows that the Frobenius norm of {{math|'''M''' {{=}} (''m''&lt;sub&gt;''ij''&lt;/sub&gt;)}} coincides with:

:&lt;math&gt;\sqrt{\sum_{ij} | m_{ij} |^2}.&lt;/math&gt;

In addition, the Frobenius norm and the trace norm (the nuclear norm) are special cases of the [[Schatten norm]].

== Variations and generalizations ==

=== Mode-''k'' representation ===
&lt;math&gt;M = U S V^\textsf{T}&lt;/math&gt; can be represented using [[mode-k multiplication|mode-''k'' multiplication]] of matrix &lt;math&gt;S&lt;/math&gt; applying &lt;math&gt;\times_1 U&lt;/math&gt; then &lt;math&gt;\times_2 V&lt;/math&gt; on the result; that is &lt;math&gt;M = S \times_1 U\times_2 V&lt;/math&gt;.&lt;ref&gt;{{Cite journal|last=De Lathauwer|first=L.|last2=De Moor|first2=B.|last3=Vandewalle|first3=J.|date=2000-01-01|title=A Multilinear Singular Value Decomposition|url=http://epubs.siam.org/doi/10.1137/S0895479896305696|journal=SIAM Journal on Matrix Analysis and Applications|volume=21|issue=4|pages=1253–1278|doi=10.1137/S0895479896305696|issn=0895-4798}}&lt;/ref&gt;

=== Tensor SVD ===
Two types of tensor decompositions exist, which generalise the SVD to multi-way arrays. One of them decomposes a tensor into a sum of rank-1 tensors, which is called a [[tensor rank decomposition]]. The second type of decomposition computes the orthonormal subspaces associated with the different factors appearing in the tensor product of vector spaces in which the tensor lives. This decomposition is referred to in the literature as the [[Higher-order singular value decomposition|higher-order SVD]] (HOSVD) or [[Tucker decomposition|Tucker3/TuckerM]]. In addition, [[multilinear principal component analysis]] in [[multilinear subspace learning]] involves the same mathematical operations as Tucker decomposition, being used in a different context of [[dimensionality reduction]].

=== Scale-invariant SVD ===

The SVD singular values of a matrix ''A'' are unique and are invariant with respect to left and/or right unitary transformations of  ''A''. In other words, the singular values of ''UAV'', for unitary ''U'' and ''V'', are equal to the singular values of ''A''. This is an important property for applications in which it is necessary to preserve Euclidean distances, and invariance with respect to rotations.

The Scale-Invariant SVD, or SI-SVD,&lt;ref&gt;{{citation|last=Uhlmann |first=Jeffrey |title=A Generalized Matrix Inverse that is Consistent with Respect to Diagonal Transformations |series=SIAM Journal on Matrix Analysis (SIMAX) |year=2018 |volume=239:2 |pages=781–800}}&lt;/ref&gt; is analogous to the conventional SVD except that its uniquely-determined singular values are invariant withrespect to diagonal transformations of  ''A''. In other words, the singular values of ''DAE'', for nonsingular diagonal matrices ''D'' and ''E'', are  equal to the singular values of ''A''. This is an important property for applications for which invariance to the choice of units on variables (e.g., metric versus imperial units) is needed.

=== HOSVD of functions – numerical reconstruction – TP model transformation ===
TP model transformation numerically reconstruct the HOSVD of functions. For further details please visit:

* [[HOSVD-based canonical form of TP functions and qLPV models]]
* [[Tensor product model transformation]]
* [[TP model transformation in control theory]]

=== Bounded operators on Hilbert spaces ===
The factorization {{math|'''M''' {{=}} '''UΣV'''&lt;sup&gt;∗&lt;/sup&gt;}} can be extended to a [[bounded operator]] ''M'' on a separable Hilbert space ''H''. Namely, for any bounded operator ''M'', there exist a [[partial isometry]] ''U'', a unitary ''V'', a measure space (''X'',&amp;nbsp;''μ''), and a non-negative measurable ''f'' such that

:&lt;math&gt;\mathbf{M} = \mathbf{U} T_f \mathbf{V}^*&lt;/math&gt;

where &lt;math&gt;T_f&lt;/math&gt; is the [[multiplication operator|multiplication by ''f'']] on ''L''&lt;sup&gt;2&lt;/sup&gt;(''X'', ''μ'').

This can be shown by mimicking the linear algebraic argument for the matricial case above. ''VT''&lt;sub&gt;''f''&lt;/sub&gt; V* is the unique positive square root of ''M*M'', as given by the [[Borel functional calculus]] for [[self adjoint operator]]s. The reason why ''U'' need not be unitary is because, unlike the finite-dimensional case, given an isometry ''U''&lt;sub&gt;1&lt;/sub&gt; with nontrivial kernel, a suitable ''U''&lt;sub&gt;2&lt;/sub&gt; may not be found such that

:&lt;math&gt;\begin{bmatrix} U_1 \\ U_2 \end{bmatrix}&lt;/math&gt;

is a unitary operator.

As for matrices, the singular-value factorization is equivalent to the [[polar decomposition]] for operators: we can simply write

:&lt;math&gt;\mathbf{M} = \mathbf{U} \mathbf{V}^* \cdot \mathbf{V} T_f \mathbf{V}^*&lt;/math&gt;

and notice that ''U V*'' is still a partial isometry while ''VT''&lt;sub&gt;''f''&lt;/sub&gt; ''V''* is positive.

=== Singular values and compact operators ===
The notion of singular values and left/right-singular vectors can be extended to [[compact operator on Hilbert space]] as they have a discrete spectrum. If {{mvar|T}} is compact, every non-zero {{mvar|λ}} in its spectrum is an eigenvalue. Furthermore, a compact self adjoint operator can be diagonalized by its eigenvectors. If {{math|'''M'''}} is compact, so is {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}}. Applying the diagonalization result, the unitary image of its positive square root {{mvar|T&lt;sub&gt;f&lt;/sub&gt;&amp;nbsp;}} has a set of orthonormal eigenvectors {{math|{''e&lt;sub&gt;i&lt;/sub&gt;''} }} corresponding to strictly positive eigenvalues {{math|{''σ''&lt;sub&gt;''i''&lt;/sub&gt;}.}} For any {{math|''ψ'' ∈ ''H''}},

:&lt;math&gt;\mathbf{M} \psi = \mathbf{U} T_f \mathbf{V}^* \psi = \sum_i \left \langle \mathbf{U} T_f \mathbf{V}^* \psi, \mathbf{U} e_i \right \rangle \mathbf{U} e_i = \sum_i \sigma_i \left \langle \psi, \mathbf{V} e_i \right \rangle \mathbf{U} e_i&lt;/math&gt;

where the series converges in the norm topology on {{mvar|H}}. Notice how this resembles the expression from the finite-dimensional case. {{mvar|σ&lt;sub&gt;i&lt;/sub&gt;}} are called the singular values of {{math|'''M'''}}. {{math|{'''U'''''e&lt;sub&gt;i&lt;/sub&gt;''} }} (resp. {{math|{'''V'''''e&lt;sub&gt;i&lt;/sub&gt;''} }}) can be considered the left-singular (resp. right-singular) vectors of {{math|'''M'''}}.

Compact operators on a Hilbert space are the closure of [[finite-rank operator]]s in the uniform operator topology. The above series expression gives an explicit such representation. An immediate consequence of this is:

:'''Theorem.''' {{math|'''M'''}} is compact if and only if {{math|'''M'''&lt;sup&gt;∗&lt;/sup&gt;'''M'''}} is compact.

==History==
The singular-value decomposition was originally developed by [[differential geometry|differential geometers]], who wished to determine whether a real [[bilinear form]] could be made equal to another by independent orthogonal transformations of the two spaces it acts on. [[Eugenio Beltrami]] and [[Camille Jordan]] discovered independently, in 1873 and 1874 respectively, that the singular values of the bilinear forms, represented as a matrix, form a [[Complete set of invariants|complete set]] of [[invariant (mathematics)|invariant]]s for bilinear forms under orthogonal substitutions. [[James Joseph Sylvester]] also arrived at the singular-value decomposition for real square matrices in 1889, apparently independently of both Beltrami and Jordan. Sylvester called the singular values the ''canonical multipliers'' of the matrix ''A''. The fourth mathematician to discover the singular value decomposition independently is [[Léon Autonne|Autonne]] in 1915, who arrived at it via the [[polar decomposition]]. The first proof of the singular value decomposition for rectangular and complex matrices seems to be by [[Carl Eckart]] and Gale Young in 1936;&lt;ref&gt;{{Cite journal
 |last1=Eckart |first1=C.|authorlink1=Carl Eckart |last2=Young |first2=G. |year=1936  |title=The approximation of one matrix by another of lower rank |journal=[[Psychometrika]] |volume=1 |issue=3 |pages=211–8  |doi=10.1007/BF02288367  |ref=harv |postscript=.
}}&lt;/ref&gt; they saw it as a generalization of the [[Principal axis theorem|principal axis]] transformation for [[Hermitian matrix|Hermitian matrices]].

In 1907, [[Erhard Schmidt]] defined an analog of singular values for [[integral operator]]s (which are compact, under some weak technical assumptions); it seems he was unaware of the parallel work on singular values of finite matrices. This theory was further developed by [[Émile Picard]] in 1910, who is the first to call the numbers &lt;math&gt;\sigma_k&lt;/math&gt; ''singular values'' (or in French, ''valeurs singulières'').

Practical methods for computing the SVD date back to [[Ervand Kogbetliantz|Kogbetliantz]] in 1954, 1955 and [[Magnus Hestenes|Hestenes]] in 1958.&lt;ref&gt;{{Cite journal |first=M. R. |last=Hestenes |authorlink=Magnus Hestenes
 |title=Inversion of Matrices by Biorthogonalization and Related Results
 |journal=Journal of the Society for Industrial and Applied Mathematics
 |year=1958 |volume=6 |issue=1 |pages=51–90
 |doi=10.1137/0106005 |mr=0092215 | jstor = 2098862
 |ref=harv
 |postscript=.
}}&lt;/ref&gt; resembling closely the [[Jacobi eigenvalue algorithm]], which uses plane rotations or [[Givens rotation]]s. However, these were replaced by the method of  [[Gene H. Golub|Gene Golub]] and [[William Kahan]] published in 1965,&lt;ref&gt;{{Cite journal
 | last1=Golub | first1=G. H. | author1-link=Gene H. Golub
 | last2=Kahan | first2=W. | author2-link=William Kahan
 | title=Calculating the singular values and pseudo-inverse of a matrix
 | year=1965
 | journal=Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis
 | volume=2 | issue=2 | pages=205–224
 | doi=10.1137/0702016 |mr=0183105 | jstor = 2949777
 | ref=harv
}}&lt;/ref&gt; which uses [[Householder transformation]]s or reflections.
In 1970, Golub and Christian Reinsch&lt;ref&gt;{{Cite journal
 |title=Singular value decomposition and least squares solutions
 |first1=G. H. |last1=Golub |authorlink1=Gene H. Golub
 |first2=C. |last2=Reinsch
 |year=1970
 |journal=Numerische Mathematik
 |volume=14 |issue=5 |pages=403–420
 |doi=10.1007/BF02163027 |mr=1553974
 |ref=harv
 |postscript=.
}}&lt;/ref&gt; published a variant of the Golub/Kahan algorithm that is still the one most-used today.

==See also==
{{columns-list|colwidth=22em|
*[[Canonical correlation]]
*[[Canonical form]]
*[[Correspondence analysis]] (CA)
*[[Curse of dimensionality]]
*[[Digital signal processing]]
*[[Dimensionality reduction]]
*[[Eigendecomposition of a matrix]]
*[[Empirical orthogonal functions]] (EOFs)
*[[Fourier analysis]]
*[[Generalized singular value decomposition]]
*[[Singular_value#Inequalities_about_singular_values|Inequalities about singular values]]
*[[K-SVD]]
*[[Latent semantic analysis]]
*[[Latent semantic indexing]]
*[[Linear least squares (mathematics)|Linear least squares]]
*[[List of Fourier-related transforms]]
*[[Locality-sensitive hashing]]
*[[Low-rank approximation]]
*[[Matrix decomposition]]
*[[Multilinear principal component analysis]] (MPCA)
*[[Nearest neighbor search]]
*[[Non-linear iterative partial least squares]]
*[[Polar decomposition]]
*[[Principal component analysis]] (PCA)
*[[Schmidt decomposition]]
*[[Singular value]]
*[[Time series]]
*[[Two-dimensional singular-value decomposition]] (2DSVD)
*[[von Neumann's trace inequality]]
*[[Wavelet compression]]
}}

==Notes==
{{Reflist}}

==References==
* {{Citation | last = Banerjee | first = Sudipto | last2 = Roy | first2 = Anindya | date = 2014 | title = Linear Algebra and Matrix Analysis for Statistics | series = Texts in Statistical Science | publisher = Chapman and Hall/CRC | edition =  1st | isbn =  978-1420095388}}
* {{Cite book | last2=Bau III | first2=David | last1=Trefethen | first1=Lloyd N. | author1-link = Lloyd N. Trefethen | title=Numerical linear algebra | publisher=Society for Industrial and Applied Mathematics | location=Philadelphia | isbn=978-0-89871-361-9 | year=1997 |ref=harv}}
* {{Cite journal | last1=Demmel | first1=James | author1-link = James Demmel | last2=Kahan | first2=William | author2-link=William Kahan | title=Accurate singular values of bidiagonal matrices | doi=10.1137/0911052 | year=1990 | journal=Society for Industrial and Applied Mathematics. Journal on Scientific and Statistical Computing | volume=11 | issue=5 | pages=873–912 | citeseerx=10.1.1.48.3740 }}
* {{Cite journal | last1=Golub | first1=Gene H. | author1-link=Gene H. Golub | last2=Kahan | first2=William | author2-link=William Kahan | title=Calculating the singular values and pseudo-inverse of a matrix | jstor=2949777 | year=1965 | journal=Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis | volume=2 | issue=2 | pages=205–224 | doi=10.1137/0702016 }}
* {{Cite book | last1=Golub | first1=Gene H. | author1-link=Gene H. Golub | last2=Van Loan | first2=Charles F. | author2-link=Charles F. Van Loan | title=Matrix Computations | publisher=Johns Hopkins | edition=3rd | isbn=978-0-8018-5414-9 | year=1996 }}
* {{Cite book | last1=GSL Team | title=GNU Scientific Library. Reference Manual | year=2007 | chapter=§14.4 Singular Value Decomposition | chapterurl=https://www.gnu.org/software/gsl/manual/html_node/Singular-Value-Decomposition.html }}
* Halldor, Bjornsson and Venegas, Silvia A. (1997). [http://brunnur.vedur.is/pub/halldor/TEXT/eofsvd.html "A manual for EOF and SVD analyses of climate data"]. McGill University, CCGCR Report No. 97-1, Montréal, Québec, 52pp.
* {{Cite journal | doi = 10.1007/BF01937276 | last1 = Hansen | first1 = P. C. | year = 1987 | title = The truncated SVD as a method for regularization | journal = BIT | volume = 27 | pages = 534–553 | ref = harv }}
*{{cite book |author1=Horn, Roger A. |author2=Johnson, Charles R. |title=Matrix Analysis |publisher=Cambridge University Press |year=1985 |isbn=0-521-38632-2 |chapter=Section 7.3 }}
*{{cite book |author1=Horn, Roger A. |author2=Johnson, Charles R. |title=Topics in Matrix Analysis |publisher=Cambridge University Press |year=1991 |isbn=0-521-46713-6 |chapter=Chapter 3 }}
*{{cite book |author=Samet, H. |title=Foundations of Multidimensional and Metric Data Structures |publisher=Morgan Kaufmann |year=2006 |isbn=0-12-369446-9 }}
*{{cite book |author=Strang G. |title=Introduction to Linear Algebra |publisher=Wellesley-Cambridge Press |year=1998 |isbn=0-9614088-5-5 |edition=3rd |chapter=Section 6.7 }}
* {{Cite journal | last1=Stewart | first1=G. W. | title=On the Early History of the Singular Value Decomposition | url=http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.23.1831 | doi=10.1137/1035134 | jstor=2132388|year=1993 | journal=SIAM Review | volume=35 | issue=4 | pages=551–566 |ref=harv }}
*{{cite book |last1=Wall|first1 = Michael E.|first2 = Andreas|last2 = Rechtsteiner|first3 = Luis M.|last3 = Rocha |chapter=Singular value decomposition and principal component analysis |chapterurl=http://public.lanl.gov/mewall/kluwer2002.html |editor1=D.P. Berrar |editor2=W. Dubitzky |editor3=M. Granzow |title=A Practical Approach to Microarray Data Analysis |publisher=Kluwer |location=Norwell, MA |year=2003 |pages=91–109 }}
*{{Citation|last1=Press|first1=WH|last2=Teukolsky|first2=SA|last3=Vetterling|first3=WT|last4=Flannery|first4=BP|year=2007|title=Numerical Recipes: The Art of Scientific Computing|edition=3rd|publisher=Cambridge University Press| publication-place=New York|isbn=978-0-521-88068-8|chapter=Section 2.6|chapter-url=http://apps.nrbook.com/empanel/index.html?pg=65}}

== External links ==
*[http://engineerjs.com/doc/ejs/engine/linalg-1/_svd.html Online SVD calculator]

{{Numerical linear algebra}}
{{Functional Analysis}}

{{DEFAULTSORT:Singular Value Decomposition}}
[[Category:Singular value decomposition| ]]
[[Category:Linear algebra]]
[[Category:Numerical linear algebra]]
[[Category:Matrix theory]]
[[Category:Matrix decompositions]]
[[Category:Functional analysis]]</text>
      <sha1>678ncfktsh06paw5n6izl91m5457hjy</sha1>
    </revision>
  </page>
  <page>
    <title>Smooth algebra</title>
    <ns>0</ns>
    <id>36088541</id>
    <revision>
      <id>797945945</id>
      <parentid>635997256</parentid>
      <timestamp>2017-08-30T02:59:43Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <minor/>
      <comment>adding a link using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2891">
In [[algebra]], a commutative ''k''-algebra ''A'' is said to be '''0-smooth''' if it satisfies the following lifting property: given a ''k''-algebra ''C'', an ideal ''N'' of ''C'' whose square is zero and a ''k''-algebra map  &lt;math&gt;u: A \to C/N&lt;/math&gt;, there exists a ''k''-algebra map &lt;math&gt;v: A \to C&lt;/math&gt; such that ''u'' is ''v'' followed by the canonical map. If there exists at most one such lifting ''v'', then ''A'' is said to be '''0-unramified''' (or '''0-neat'''). ''A'' is said to be '''0-étale''' if it is '''0-smooth''' and '''0-unramified'''.

A finitely generated ''k''-algebra ''A'' is 0-smooth over ''k'' if and only if Spec ''A'' is a [[smooth scheme]] over ''k''.

A [[separable extension|separable]] algebraic field extension ''L'' of ''k'' is 0-étale over ''k''.&lt;ref&gt;{{harvnb|Matsumura|1986|loc=Theorem 25.3}}&lt;/ref&gt; The formal power series ring &lt;math&gt;k[\![t_1, \ldots, t_n]\!]&lt;/math&gt; is 0-smooth only when &lt;math&gt;\operatorname{char}k = p &gt; 0&lt;/math&gt; and &lt;math&gt;[k: k^p] &lt; \infty&lt;/math&gt; (i.e., ''k'' has a finite [[p-basis|''p''-basis]].)&lt;ref&gt;{{harvnb|Matsumura|1986|loc=pg. 215}}&lt;/ref&gt;

== ''I''-smooth ==
Let ''B'' be an ''A''-algebra and suppose ''B'' is given the ''I''-adic topology, ''I'' an ideal of ''B''. We say ''B'' is '''''I''-smooth over ''A''''' if it satisfies the lifting property: given an ''A''-algebra ''C'', an ideal ''N'' of ''C'' whose square is zero and an ''A''-algebra map  &lt;math&gt;u: B \to C/N&lt;/math&gt; that is continuous when &lt;math&gt;C/N&lt;/math&gt; is given the discrete topology, there exists an ''A''-algebra map &lt;math&gt;v: B \to C&lt;/math&gt; such that ''u'' is ''v'' followed by the canonical map. As before, if there exists at most one such lift ''v'', then ''B'' is said to be '''''I''-unramified over ''A''''' (or '''''I''-neat'''). ''B'' is said to be '''''I''-étale''' if it is '''''I''-smooth''' and '''''I''-unramified'''. If ''I'' is the zero ideal and ''A'' is a field, these notions coincide with 0-smooth etc. as defined above.

A standard example is this: let ''A'' be a ring, &lt;math&gt;B = A[\![t_1, \ldots, t_n]\!]&lt;/math&gt; and &lt;math&gt;I = (t_1, \ldots, t_n).&lt;/math&gt; Then ''B'' is ''I''-smooth over ''A''.

Let ''A'' be a noetherian local ''k''-algebra with maximal ideal &lt;math&gt;\mathfrak{m}&lt;/math&gt;. Then ''A'' is &lt;math&gt;\mathfrak{m}&lt;/math&gt;-smooth over ''k'' if and only if &lt;math&gt;A \otimes_k k'&lt;/math&gt; is a regular ring for any finite extension field &lt;math&gt;k'&lt;/math&gt; of ''k''.&lt;ref&gt;{{harvnb|Matsumura|1986|loc=Theorem 28.7}}&lt;/ref&gt;

== See also ==
*[[étale morphism]]
*[[formally smooth morphism]]
*[[Popescu’s theorem]]

== References ==
{{reflist}}
* H. Matsumura ''[https://books.google.com/books?id=yJwNrABugDEC&amp;printsec=frontcover#v=onepage&amp;q=%22smooth%20algebra%22&amp;f=false Commutative ring theory].'' Translated from the Japanese by M. Reid. Second edition. Cambridge Studies in Advanced Mathematics, 8.

[[Category:Algebra]]

{{algebra-stub}}</text>
      <sha1>rw6wyn0kp8j6jqzddj2udpxooo5ez88</sha1>
    </revision>
  </page>
  <page>
    <title>Structural proof theory</title>
    <ns>0</ns>
    <id>929998</id>
    <revision>
      <id>849816307</id>
      <parentid>828190820</parentid>
      <timestamp>2018-07-11T15:02:20Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <comment>/* Hypersequents */ 10.2307/2273495</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7434">In [[mathematical logic]], '''structural proof theory''' is the subdiscipline of [[proof theory]] that studies [[proof calculi]] that support a notion of [[analytic proof]].

==Analytic proof==
{{Main|analytic proof}}

The notion of analytic proof was introduced into proof theory by [[Gerhard Gentzen]] for the [[sequent calculus]]; the analytic proofs are those that are [[cut-elimination theorem|cut-free]]. His [[natural deduction calculus]] also supports a notion of analytic proof, as was shown by [[Dag Prawitz]]; the definition is slightly more complex&amp;mdash;the analytic proofs are the [[Natural deduction#Consistency.2C completeness.2C and normal forms|normal forms]], which are related to the notion of [[Normal form (abstract rewriting)|normal form]] in [[term rewriting]].

==Structures and connectives==
The term ''structure'' in structural proof theory comes from a technical notion introduced in the sequent calculus: the sequent calculus represents the judgement made at any stage of an inference using special, extra-logical operators called structural operators: in &lt;math&gt;A_1, \dots, A_m \vdash B_1, \dots, B_n&lt;/math&gt;, the commas to the left of the [[Turnstile (symbol)|turnstile]] are operators normally interpreted as conjunctions, those to the right as disjunctions, whilst the turnstile symbol itself is interpreted as an implication.  However, it is important to note that there is a fundamental difference in behaviour between these operators and the [[logical connective]]s they are interpreted by in the sequent calculus: the structural operators are used in every rule of the calculus, and are not considered when asking whether the subformula property applies.  Furthermore, the logical rules go one way only: logical structure is introduced by logical rules, and cannot be eliminated once created, while structural operators can be introduced and eliminated in the course of a derivation.

The idea of looking at the syntactic features of sequents as special, non-logical operators is not old, and was forced by innovations in proof theory: when the structural operators are as simple as in Getzen's original sequent calculus there is little need to analyse them, but proof calculi of [[deep inference]] such as [[display logic]] support structural operators as complex as the logical connectives, and demand sophisticated treatment.

==Cut-elimination in the sequent calculus==
{{Main|Cut-elimination}}
{{Expand section|date=December 2009}}

==Natural deduction and the formulae-as-types correspondence==
{{Main|Natural deduction}}
{{Expand section|date=December 2009}}

==Logical duality and harmony==
{{Main|Logical harmony}}
{{Expand section|date=December 2009}}

== Hypersequents ==
{{Main|Hypersequent}}

The hypersequent framework extends the ordinary [[Sequent calculus|sequent structure]] to a multiset of sequents, using an additional structural connective | (called the '''hypersequent bar''') to separate different sequents. It has been used to provide analytic calculi for, e.g., [[Modal logic|modal]], [[Intermediate logic|intermediate]] and [[Substructural logic|substructural]] logics&lt;ref&gt;{{Cite journal|last=Minc|first=G.E.|date=1971|orig-year=Originally published in Russian in 1968|title=On some calculi of modal logic|url=|journal=The Calculi of Symbolic Logic. Proceedings of the Steklov Institute of Mathematics|publisher=AMS|volume=98|pages=97–124}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite journal|last=Avron|first=Arnon|date=1996|title=The method of hypersequents in the proof theory of propositional non-classical logics|url=|journal=Logic: From Foundations to Applications: European Logic Colloquium|publisher=Clarendon Press|volume=|pages=1–32}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Pottinger|first=Garrel|date=1983|title=Uniform, cut-free formulations of T, S4, and S5|url=|journal=Journal of Symbolic Logic|volume=48|issue=3|pages=900|doi=10.2307/2273495}}&lt;/ref&gt; A '''hypersequent''' is a structure

&lt;math&gt;\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n&lt;/math&gt;

where each &lt;math&gt;\Gamma_i \vdash\Delta_i&lt;/math&gt; is an ordinary sequent, called a '''component''' of the hypersequent. As for sequents, hypersequents can be based on sets, multisets, or sequences, and the components can be single-conclusion or multi-conclusion [[Sequent|sequents]]. The '''formula interpretation''' of the hypersequents depends on the logic under consideration, but is nearly always some form of disjunction. The most common interpretations are as a simple disjunction

&lt;math&gt;(\bigwedge\Gamma_1 \rightarrow \bigvee \Delta_1) \lor \dots \lor (\bigwedge\Gamma_n \rightarrow \bigvee \Delta_n)&lt;/math&gt;

for intermediate logics, or as a disjunction of boxes

&lt;math&gt;\Box(\bigwedge\Gamma_1 \rightarrow\bigvee \Delta_1) \lor \dots \lor \Box(\bigwedge\Gamma_n \rightarrow \bigvee\Delta_n)&lt;/math&gt;

for modal logics.

In line with the disjunctive interpretation of the hypersequent bar, essentially all hypersequent calculi include the '''external structural rules''', in particular the '''external weakening rule'''

&lt;math&gt;\frac{\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n}{\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n \mid \Sigma \vdash \Pi}&lt;/math&gt;

and the '''external contraction rule'''

&lt;math&gt;\frac{\Gamma_1\vdash \Delta_1 \mid \dots \mid\Gamma_n \vdash \Delta_n \mid \Gamma_n \vdash \Delta_n}{\Gamma_1\vdash \Delta_1 \mid \dots \mid\Gamma_n \vdash \Delta_n}&lt;/math&gt;

The additional expressivity of the hypersequent framework is provided by rules manipulating the hypersequent structure. An important example is provided by the '''modalised splitting rule'''&lt;ref name=":0" /&gt;

&lt;math&gt;\frac{\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n \mid \Box \Sigma, \Omega \vdash \Box \Pi, \Theta}{\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n \mid \Box \Sigma \vdash \Box \Pi \mid \Omega \vdash \Theta}&lt;/math&gt;

for modal logic [[S5 (modal logic)|S5]], where &lt;math&gt;\Box \Sigma&lt;/math&gt; means that every formula in &lt;math&gt;\Box\Sigma&lt;/math&gt; is of the form &lt;math&gt;\Box A&lt;/math&gt;. 

Another example is given by the '''communication rule''' for intermediate logic [[Intermediate logic|LC]]&lt;ref name=":0" /&gt;

&lt;math&gt;\frac{\Gamma_1 \vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n \mid \Omega \vdash A \qquad \Sigma_1 \vdash \Pi_1 \mid \dots \mid \Sigma_m \vdash \Pi_m \mid \Theta \vdash B }{\Gamma_1\vdash \Delta_1 \mid \dots \mid \Gamma_n \vdash \Delta_n \mid \Sigma_1 \vdash \Pi_1 \mid \dots \mid \Sigma_m \vdash \Pi_m \mid \Omega \vdash B \mid \Theta \vdash A}&lt;/math&gt;

Note that in the communication rule the components are single-conclusion sequents.

==Display logic==
{{Expand section|date=December 2009}}

==Calculus of structures==
{{Main|Calculus of structures}}
{{Expand section|date=December 2009}}
==Nested sequent calculus==
{{Main|Nested sequent calculus}}
The nested sequent calculus is a formalisation that resembles a 2-sided calculus of structures.

== References ==
{{Reflist}}
* {{cite book|author1=Sara Negri|author1-link= Sara Negri |author2=Jan Von Plato|title=Structural proof theory|year=2001|publisher=Cambridge University Press|isbn=978-0-521-79307-0}}
* {{cite book|author1=[[Anne Sjerp Troelstra]]|author2=[[Helmut Schwichtenberg]]|title=Basic proof theory|year=2000|publisher=Cambridge University Press|isbn=978-0-521-77911-1|edition=2nd}}

{{DEFAULTSORT:Structural Proof Theory}}
[[Category:Proof theory]]</text>
      <sha1>9zojiinoz8zkzgg2fos5rkeatgm50ih</sha1>
    </revision>
  </page>
  <page>
    <title>Syntactic predicate</title>
    <ns>0</ns>
    <id>7400895</id>
    <revision>
      <id>857941301</id>
      <parentid>857086848</parentid>
      <timestamp>2018-09-04T01:16:48Z</timestamp>
      <contributor>
        <username>Shenme</username>
        <id>101696</id>
      </contributor>
      <comment>not a typo|aaaabbbccc  and others</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14340">A '''syntactic predicate''' specifies the syntactic validity of applying a [[Formal grammar#The syntax of grammars|production]] in a [[formal grammar]] and is analogous to a [[semantic]] [[Predicate (grammar)|predicate]] that specifies the semantic validity of applying a production.  It is a simple and effective means of dramatically improving the recognition strength of an [[LL parser]] by providing arbitrary lookahead.  In their original implementation, syntactic predicates had the form “( α )?” and could only appear on the left edge of a production. The required syntactic condition α could be any valid context-free grammar fragment.

More formally, a syntactic predicate is a form of production [[intersection (set theory)|intersection]], used in [[parsing|parser]] specifications or in [[formal grammar]]s. In this sense, the term ''predicate'' has the meaning of a mathematical [[indicator function]]. If ''p&lt;sub&gt;1&lt;/sub&gt;'' and ''p&lt;sub&gt;2,&lt;/sub&gt;'' are production rules, the [[Formal language|language]] generated by ''both'' ''p&lt;sub&gt;1&lt;/sub&gt;'' ''and'' ''p&lt;sub&gt;2&lt;/sub&gt;'' is their set intersection.

As typically defined or implemented, syntactic predicates implicitly order the productions so that predicated productions specified earlier have higher precedence than predicated productions specified later within the same decision. This conveys an ability to disambiguate ambiguous productions because the programmer can simply specify which production should match.

[[Parsing expression grammar]]s (PEGs), invented by Bryan Ford, extend these simple predicates by allowing "not predicates" and permitting a predicate to appear anywhere within a production.  Moreover, Ford invented [[packrat parsing]] to handle these grammars in linear time by employing [[memoization]], at the cost of heap space.

It is possible to support linear-time parsing of predicates as general as those allowed by PEGs, but reduce the memory cost associated with memoization by avoiding backtracking where some more efficient implementation of lookahead suffices. This approach is implemented by [[ANTLR]] version 3, which uses [[Deterministic finite automata]] for lookahead; this may require testing a predicate in order to choose between transitions of the DFA (called "pred-LL(*)" parsing).&lt;ref&gt;{{Cite book
  | last = Parr
  | first = Terence
  | authorlink = Terence Parr
  | title = The Definitive ANTLR Reference: Building Domain-Specific Languages
  | publisher = [[The Pragmatic Programmers]]
  | year = 2007
  | page = 328
  | isbn = 3-540-63293-X }}&lt;/ref&gt;

==Overview==

===Terminology===

The term ''syntactic predicate'' was coined by Parr &amp; Quong and differentiates this form of predicate from [[semantic predicate]]s (also discussed).&lt;ref name="Parr&amp;Quong1993"&gt;{{cite paper
 | last1 = Parr | first1 = Terence J. | authorlink = Terence Parr
 | last2 = Quong | first2 = Russell
 | title = Adding Semantic and Syntactic Predicates to LL(k) parsing: pred-LL(k)
 | publisher = Army High Performance Computing Research Center Preprint No. 93-096
 | date = October 1993
 | citeseerx = 10.1.1.26.427
 }}&lt;/ref&gt;

Syntactic predicates have been called ''multi-step matching'', ''parse constraints'', and simply ''predicates'' in various literature. (See References section below.) This article uses the term ''syntactic predicate'' throughout for consistency and to distinguish them from [[semantic predicate]]s.

===Formal closure properties===
[[Yehoshua Bar-Hillel|Bar-Hillel]] ''et al.''&lt;ref&gt;{{cite journal
 | last1 = Bar-Hillel | first1 = Y. | author1-link = Yehoshua Bar-Hillel
 | last2 = Perles | first2 = M.
 | last3 = Shamir | first3 = E. | author3-link = Eli Shamir
 | issue = 2
 | journal = Zeitschrift für Phonetik, Sprachwissenschaft und Kommunikationsforschung
 | pages = 143–172
 | title = On formal properties of simple phrase structure grammars
 | volume = 14
 | year = 1961}}.&lt;/ref&gt; show that the intersection of two [[regular language]]s is also a regular language, which is to say that the regular languages are [[Closure (mathematics)|closed]] under [[Intersection (set theory)|intersection]].

The intersection of a [[regular language]] and a [[context-free]] language is also closed, and it has been known at least since Hartmanis&lt;ref&gt;{{cite journal | last = Hartmanis | first = Juris | title = Context-Free Languages and Turing Machine Computations | journal = Proceedings of Symposia in Applied Mathematics | volume = 19 | series = Mathematical Aspects of Computer Science | publisher = AMS | pages = 42–51 | year = 1967 }}&lt;/ref&gt; that the intersection of two [[context-free]] languages is not necessarily a context-free language (and is thus not closed). This can be demonstrated easily using the canonical [[Chomsky hierarchy|Type 1]] language, &lt;math&gt;L = \{ a^n b^n c^n : n \ge 1 \} &lt;/math&gt;:

 Let &lt;math&gt; L_1 = \{ a^m b^n c^n : m,n \ge 1 \}&lt;/math&gt; (Type 2)
 Let &lt;math&gt; L_2 = \{ a^n b^n c^m : m,n \ge 1 \}&lt;/math&gt; (Type 2)
 Let &lt;math&gt; L_3 = L_1 \cap L_2&lt;/math&gt;

Given the [[String (computer science)|strings]] ''{{not a typo|abcc}}'', ''{{not a typo|aabbc}}'', and ''{{not a typo|aaabbbccc}}'', it is clear that the only string that belongs to both L&lt;sub&gt;1&lt;/sub&gt; '''and''' L&lt;sub&gt;2&lt;/sub&gt; (that is, the only one that produces a [[empty string|non-empty]] intersection) is ''{{not a typo|aaabbbccc}}''.

===Other considerations===
In most formalisms that use syntactic predicates, the syntax of the predicate is [[Commutative|noncommutative]], which is to say that the operation of predication is ordered. For instance, using the above example, consider the following pseudo-grammar, where ''X ::= Y PRED Z'' is understood to mean: "''Y'' produces ''X'' [[if and only if]] ''Y'' also satisfies predicate ''Z''":

 S    ::= a X
 X    ::= Y PRED Z
 Y    ::= a+ BNCN
 Z    ::= ANBN c+
 BNCN ::= b [BNCN] c
 ANBN ::= a [ANBN] b

Given the string ''{{not a typo|aaaabbbccc}}'', in the case where ''Y'' must be satisfied ''first'' (and assuming a greedy implementation), S will generate ''aX'' and ''X'' in turn will generate ''{{not a typo|aaabbbccc}}'', thereby generating ''{{not a typo|aaaabbbccc}}''. In the case where ''Z'' must be satisfied first, ANBN will fail to generate ''{{not a typo|aaaabbb}}'', and thus ''{{not a typo|aaaabbbccc}}'' is not generated by the grammar. Moreover, if either ''Y'' or ''Z'' (or both) specify any action to be taken upon reduction (as would be the case in many parsers), the order that these productions match determines the order in which those side-effects occur. Formalisms that vary over time (such as [[adaptive grammar]]s) may rely on these [[side effect (computer science)|side effects]].

===Examples of use===
;ANTLR

Parr &amp; Quong&lt;ref name="Parr&amp;Quong1995"/&gt; give this example of a syntactic predicate:

 stat: (declaration)? declaration
     | expression
     ;

which is intended to satisfy the following informally stated&lt;ref name="Stroustrup&amp;Ellis1990"&gt;{{cite book | last1 = Stroustrup | first1 = Bjarne | last2 = Ellis | first2 = Margaret A. | title = The Annotated C++ Reference Manual | publisher = Addison-Wesley | year = 1990 }}&lt;/ref&gt; constraints of [[C++]]:

# If it looks like a declaration, it is; otherwise
# if it looks like an expression, it is; otherwise
# it is a syntax error.

In the first production of rule stat, the syntactic predicate '''(declaration)?''' indicates
that declaration is the syntactic context that must be present for the rest of that production to succeed. We can interpret the use of (declaration)? as "I am not sure if
declaration will match; let me try it out and, if it does not match, I shall try the next
alternative." Thus, when encountering a valid declaration, the rule declaration will be
recognized twice—once as syntactic predicate and once during the actual parse to execute semantic actions.

Of note in the above example is the fact that any code triggered by the acceptance of the ''declaration'' production will only occur if the predicate is satisfied.

====Canonical examples====
The language &lt;math&gt;L = \{a^n b^n c^n | n \ge 1\}&lt;/math&gt; can be represented in various grammars and formalisms as follows:

;Parsing Expression Grammars

 S ← &amp;(A !b) a+ B !c
 A ← a A? b
 B ← b B? c

;§-Calculus

Using a ''bound'' predicate:

 S → {A}&lt;sup&gt;B&lt;/sup&gt;

 A → X 'c+'
 X → 'a' [X] 'b'
 B → 'a+' Y
 Y → 'b' [Y] 'c'

Using two ''free'' predicates:

 A → &lt;'a+'&gt;&lt;sub&gt;''a''&lt;/sub&gt; &lt;'b+'&gt;&lt;sub&gt;''b''&lt;/sub&gt; Ψ(''a'' ''b'')&lt;sup&gt;X&lt;/sup&gt; &lt;'c+'&gt;&lt;sub&gt;''c''&lt;/sub&gt; Ψ(''b'' ''c'')&lt;sup&gt;Y&lt;/sup&gt;

 X → 'a' [X] 'b'
 Y → 'b' [Y] 'c'

;Conjunctive Grammars

(Note: the following example actually generates &lt;math&gt;L = \{a^n b^n c^n | n \ge 0\}&lt;/math&gt;, but is included here because it is the example given by the inventor of conjunctive grammars.&lt;ref name="Okhotin2001"&gt;{{cite journal | last = Okhotin | first = Alexander | title = Conjunctive grammars | journal = Journal of Automata, Languages and Combinatorics | volume = 6 | issue = 4 | pages = 519–535 | year = 2001 }}&lt;/ref&gt;):

 S → AB&amp;DC
 A → aA | ε
 B → bBc | ε
 C → cC | ε
 D → aDb | ε

;Perl 6 rules
&lt;pre&gt;
 rule S { &lt;before &lt;A&gt; &lt;!before b&gt;&gt; a+ &amp;lt;B&amp;gt; &lt;!before c&gt; }
 rule A { a &lt;A&gt;? b }
 rule B { b &amp;lt;B&amp;gt;? c }
&lt;/pre&gt;
==Parsers/formalisms using some form of syntactic predicate==
Although by no means an exhaustive list, the following [[parsing|parsers]] and [[formal grammar|grammar]] [[Formal system|formalisms]] employ syntactic predicates:

; [[ANTLR]] (Parr &amp; Quong)
:As originally implemented,&lt;ref name="Parr&amp;Quong1993"/&gt; syntactic predicates sit on the leftmost edge of a production such that the [[Formal grammar|production]] to the right of the predicate is attempted if and only if the syntactic predicate first accepts the next portion of the input stream. Although ordered, the predicates are checked first, with parsing of a clause continuing if and only if the predicate is satisfied, and semantic actions only occurring in non-predicates.&lt;ref name="Parr&amp;Quong1995"&gt;{{cite journal | last1 = Parr | first1 = Terence | last2 = Quong | first2 = Russell | title = ANTLR: A Predicated-''LL(k)'' Parser Generator | journal = Software--Practice and Experience | volume = 25 | issue = 7 | pages = 789–810 | date = July 1995 | url = http://www.antlr2.org/article/1055550346383/antlr.pdf }}&lt;/ref&gt;
; Augmented Pattern Matcher (Balmas)
:Balmas refers to syntactic predicates as "multi-step matching" in her paper on APM.&lt;ref name="Balmas1994"&gt;{{cite conference | last = Balmas | first = Françoise | title = An Augmented Pattern Matcher as a Tool to Synthesize Conceptual Descriptions of Programs | conference = Proceedings of the Ninth Knowledged-Based Software Engineering Conference | pages = 150–157 | location = Monterey, California | date = 20–23 September 1994 }}&lt;/ref&gt; As an APM parser parses, it can bind substrings to a variable, and later check this variable against other rules, continuing to parse if and only if that substring is acceptable to further rules.
; [[Parsing expression grammar]]s (Ford)
:Ford's PEGs have syntactic predicates expressed as the ''and-predicate'' and the ''not-predicate''.&lt;ref name="Ford2002"&gt;{{cite thesis | last = Ford | first = Bryan | title = Packrat Parsing: a Practical Linear-Time Algorithm with Backtracking | degree = Master’s | publisher = Massachusetts Institute of Technology | date = September 2002 | url = http://pdos.csail.mit.edu/~baford/packrat/thesis/ }}&lt;/ref&gt;
; [[§-Calculus]] (Jackson)
:In the §-Calculus, syntactic predicates are originally called simply ''predicates'', but are later divided into ''bound'' and ''free'' forms, each with different input properties.&lt;ref name="Jackson2006"&gt;{{cite book | last = Jackson | first = Quinn Tyler | title = Adapting to Babel: Adaptivity &amp; Context-Sensitivity in Parsing | publisher = Ibis Publishing | location = Plymouth, Massachusetts | date = March 2006 }}&lt;/ref&gt;
; [[Perl 6 rules]]
:[[Perl 6]] introduces a generalized tool for describing a grammar called ''rules'', which are an extension of [[Perl]] 5's regular expression syntax.&lt;ref name="Wall2002"&gt;{{cite web | last = Wall | first = Larry | url = http://dev.perl.org/perl6/doc/design/syn/S05.html | title = Synopsis 5: Regexes and Rules | date = 2002–2006 }}&lt;/ref&gt; Predicates are introduced via a lookahead mechanism called ''before'', either with "&lt;code&gt;&lt;nowiki&gt;&lt;before ...&gt;&lt;/nowiki&gt;&lt;/code&gt;" or "&lt;code&gt;&lt;nowiki&gt;&lt;!before ...&gt;&lt;/nowiki&gt;&lt;/code&gt;" (that is: "''not'' before"). Perl 5 also has such lookahead, but it can only encapsulate Perl 5's more limited regexp features.
; ProGrammar (NorKen Technologies)
:ProGrammar's GDL (Grammar Definition Language) makes use of syntactic predicates in a form called ''parse constraints''.&lt;ref name="NorKen"&gt;{{cite web | publisher = NorKen Technologies | url = http://www.programmar.com/grammar.htm | title = Grammar Definition Language }}&lt;/ref&gt;
; [[Conjunctive grammars|Conjunctive]] and [[Boolean grammar|Boolean]] Grammars (Okhotin)
:Conjunctive grammars, first introduced by [[Alexander Okhotin|Okhotin]],&lt;ref name="Okhotin2000"&gt;{{cite journal | last = Okhotin | first = Alexander | title = On Augmenting the Formalism of Context-Free Grammars with an Intersection Operation | language = Russian | journal = Proceedings of the Fourth International Conference "Discrete Models in the Theory of Control Systems" | pages = 106–109 | year = 2000 }}&lt;/ref&gt; introduce the explicit notion of [[logical conjunction|conjunction]]-as-predication. Later treatment of conjunctive and boolean grammars&lt;ref name="Okhotin2004"&gt;{{cite thesis | last = Okhotin | first = Alexander | title = Boolean Grammars: Expressive Power and Algorithms | type = Doctoral thesis | publisher = School of Computing, Queens University | location = Kingston, Ontario | date = August 2004 }}&lt;/ref&gt; is the most thorough treatment of this formalism to date.

==References==
{{Reflist}}

==External links==
* {{official website|1=www.antlr.org|name=ANTLR site}}
* [http://users.utu.fi/aleokh/conjunctive/ Alexander Okhotin's Conjunctive Grammars Page]
* [http://users.utu.fi/aleokh/boolean/ Alexander Okhotin's Boolean Grammars Page]
* [http://pdos.csail.mit.edu/~baford/packrat/ The Packrat Parsing and Parsing Expression Grammars Page]

{{Use dmy dates|date=September 2010}}

{{DEFAULTSORT:Syntactic Predicate}}
[[Category:Parsing]]
[[Category:Formal languages]]</text>
      <sha1>6anoval07i41lfx8tmcb0gb4xk2jmr1</sha1>
    </revision>
  </page>
  <page>
    <title>Table of Clebsch–Gordan coefficients</title>
    <ns>0</ns>
    <id>2515349</id>
    <revision>
      <id>846619095</id>
      <parentid>845356512</parentid>
      <timestamp>2018-06-19T21:40:46Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; remove 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41551">&lt;!--
:''This article is incomplete due to technical limitations.''
--&gt;
This is a '''table of [[Clebsch–Gordan coefficients]]''' used for adding [[angular momentum]] values in [[quantum mechanics]]. The overall sign of the coefficients for each set of constant &lt;math&gt;j_1&lt;/math&gt;, &lt;math&gt;j_2&lt;/math&gt;, &lt;math&gt;j&lt;/math&gt; is arbitrary to some degree and has been fixed according to the Condon-Shortley and Wigner sign convention as discussed by Baird and [[Lawrence Biedenharn|Biedenharn]].&lt;ref&gt;{{cite journal |last=Baird |first=C.E. |author2=L. C. Biedenharn  |title=On the Representations of the Semisimple Lie Groups. III. The Explicit Conjugation Operation for SU&lt;sub&gt;n&lt;/sub&gt; |journal=J. Math. Phys. |volume=5 |date=October 1964 |pages=1723–1730 |doi=10.1063/1.1704095 |bibcode=1964JMP.....5.1723B}}&lt;/ref&gt;  Tables with the same sign convention may be found in the [[Particle Data Group]]'s ''Review of Particle Properties''&lt;ref&gt;{{cite journal |last=Hagiwara |first=K. |title=Review of Particle Properties |journal=Phys. Rev. D |volume=66 |date=July 2002 |pages=010001 |doi=10.1103/PhysRevD.66.010001 |url=http://pdg.lbl.gov/2002/clebrpp.pdf |format=PDF |accessdate=2007-12-20 |bibcode=2002PhRvD..66a0001H|display-authors=etal}}&lt;/ref&gt; and in online tables.&lt;ref&gt;{{cite web |last=Mathar |first=Richard J. |title=SO(3) Clebsch Gordan coefficients |date=2006-08-14 |url=http://www.mpia.de/~mathar/progs/CGord |format=text |accessdate=2012-10-15}}&lt;/ref&gt;

==Formulation==
The Clebsch–Gordan coefficients are the solutions to

:&lt;math&gt;
  |j_1,j_2;J,M\rangle = \sum_{m_1=-j_1}^{j_1} \sum_{m_2=-j_2}^{j_2}
  |j_1,m_1;j_2,m_2\rangle \langle j_1,j_2;m_1,m_2|j_1,j_2;J,M\rangle
&lt;/math&gt;

Explicitly:

:&lt;math&gt;
\begin{align}
\langle j_1,j_2;m_1,m_2|j_1,j_2;J,M\rangle = \ 
&amp;\delta_{M,m_1+m_2} \sqrt{\frac{(2J+1)(J+j_1-j_2)!(J-j_1+j_2)!(j_1+j_2-J)!}{(j_1+j_2+J+1)!}}\ \times \\
&amp;\sqrt{(J+M)!(J-M)!(j_1-m_1)!(j_1+m_1)!(j_2-m_2)!(j_2+m_2)!}\ \times \\
&amp;\sum_k \frac{(-1)^k}{k!(j_1+j_2-J-k)!(j_1-m_1-k)!(j_2+m_2-k)!(J-j_2+m_1+k)!(J-j_1-m_2+k)!}.
\end{align}
&lt;/math&gt;

The summation is extended over all integer {{mvar|k}} for which the argument of every factorial is nonnegative.&lt;ref&gt;(2.41), p. 172, ''Quantum Mechanics: Foundations and Applications'', Arno Bohm, M. Loewe, New York: Springer-Verlag, 3rd ed., 1993, {{ISBN|0-387-95330-2}}.&lt;/ref&gt;

For brevity, solutions with {{math|''M'' &lt; 0}} and {{math|''j''&lt;sub&gt;1&lt;/sub&gt; &lt; ''j''&lt;sub&gt;2&lt;/sub&gt;}} are omitted.  They may be calculated using the simple relations

:&lt;math&gt;\langle j_1,j_2;m_1,m_2|j_1,j_2;J,M\rangle=(-1)^{J-j_1-j_2}\langle j_1,j_2;-m_1,-m_2|j_1,j_2;J,-M\rangle&lt;/math&gt; .

and

:&lt;math&gt;\langle j_1,j_2;m_1,m_2|j_1,j_2;J,M\rangle=(-1)^{J-j_1-j_2} \langle j_2,j_1;m_2,m_1|j_2,j_1;J,M\rangle&lt;/math&gt; .

== Specific values ==

The Clebsch-Gordan coefficients for ''j'' values less than or equal to 5/2 are given by:&lt;ref&gt;{{cite book|last=Weissbluth|first=Mitchel|title=Atoms and molecules|year=1978|publisher=ACADEMIC PRESS|isbn=0-12-744450-5|page=28}} Table 1.4 resumes the most common.&lt;/ref&gt;

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;2&lt;/sub&gt;=0}} ===

When {{math|size=100%|1=''j''&lt;sub&gt;2&lt;/sub&gt; = 0}}, the Clebsch–Gordan coefficients are given by &lt;math&gt;\delta_{j,j_1}\delta_{m,m_1}&lt;/math&gt; .

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|1|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|1|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 1
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=-1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 1
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 1 
! 0
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=1, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|1|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! 1,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|3|2}} 
! {{sfrac|1|2}}
|----- valign="center"  align="center"
! 1,&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{3}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=1, ''j''&lt;sub&gt;2&lt;/sub&gt;=1}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2
|----- valign="center"  align="center"
! 1,&amp;nbsp;1 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2 
! 1
|----- valign="center"  align="center"
! 1,&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2 
! 1 
! 0
|----- valign="center"  align="center"
! 1,&amp;nbsp;-1 
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! -1,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|3|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|1|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2 
! 1
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\frac{1}{2}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{4}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{4}}&lt;/math&gt;
| &lt;math&gt;-\frac{1}{2}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 2 
! 1
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|3|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;=1}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|5|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}}
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;1 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}} 
! {{sfrac|3|2}} 
! {{sfrac|1|2}}
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{1}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{15}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;1
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{8}{15}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|3|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|3|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2 
! 1 
! 0
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{20}}&lt;/math&gt;
| &lt;math&gt;\frac{1}{2}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{20}}&lt;/math&gt;
| &lt;math&gt;\frac{1}{2}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{9}{20}}&lt;/math&gt;
| &lt;math&gt;\frac{1}{2}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{20}}&lt;/math&gt;
| &lt;math&gt;-\frac{1}{2}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{9}{20}}&lt;/math&gt;
| &lt;math&gt;-\frac{1}{2}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{20}}&lt;/math&gt;
| &lt;math&gt;\frac{1}{2}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{20}}&lt;/math&gt;
| &lt;math&gt;-\frac{1}{2}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{20}}&lt;/math&gt;
| &lt;math&gt;-\frac{1}{2}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=2, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|1|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|5|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{4}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{4}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! 1,&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=2, ''j''&lt;sub&gt;2&lt;/sub&gt;=1}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3
|----- valign="center"  align="center"
! 2,&amp;nbsp;1 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2
|----- valign="center"  align="center"
! 2,&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{3}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! 2,&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{1}{15}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{8}{15}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{10}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! 1,&amp;nbsp;-1 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{3}{5}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -1,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=2, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|3|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|7|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|5|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{4}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{4}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{7}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{16}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{4}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{18}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}} 
! {{sfrac|1|2}}
|----- valign="center"  align="center"
! 2,&amp;nbsp;-{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{6}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{12}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{18}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -1,&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{4}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{27}{70}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{10}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;=2, ''j''&lt;sub&gt;2&lt;/sub&gt;=2}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=4}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4
|----- valign="center"  align="center"
! 2,&amp;nbsp;2 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3
|----- valign="center"  align="center"
! 2,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;2 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2
|----- valign="center"  align="center"
! 2,&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{3}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{4}{7}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{3}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! 2,&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! -1,&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2 
! 1
! 0
|----- valign="center"  align="center"
! 2,&amp;nbsp;-2
| &lt;math&gt;\sqrt{\frac{1}{70}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 1,&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{8}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{10}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! 0,&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{18}{35}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -1,&amp;nbsp;1
| &lt;math&gt;\sqrt{\frac{8}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{10}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -2,&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{1}{70}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|5|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|1|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{6}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{5}{6}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{6}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{3}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 3 
! 2
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|5|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;=1}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|7|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;1 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|5|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{5}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{7}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{1}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{2}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{15}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;1
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{16}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{15}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-1 
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{16}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{4}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{18}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|5|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|3|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=4}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{8}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{8}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{5}{8}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{8}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{3}{28}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{12}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{15}{28}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{12}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{8}{21}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{56}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{8}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{15}{56}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{49}{120}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{42}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{15}{28}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{60}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{25}{84}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{20}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{5}{28}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{9}{20}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{28}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{20}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! 4 
! 3 
! 2 
! 1
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{10}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{14}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{10}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{5}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|5|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;=2}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|9|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|9|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;2 
| &lt;math&gt;1&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|7|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|9|2}} 
! {{sfrac|7|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;1 
| &lt;math&gt;\frac{2}{3}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{9}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;2 
| &lt;math&gt;\sqrt{\frac{5}{9}}&lt;/math&gt;
| &lt;math&gt;-\frac{2}{3}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|5|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|9|2}} 
! {{sfrac|7|2}} 
! {{sfrac|5|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;0 
| &lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;1 
| &lt;math&gt;\sqrt{\frac{5}{9}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{63}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{3}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{5}{18}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{32}{63}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{14}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|3|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|9|2}} 
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{1}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{7}}&lt;/math&gt; 
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{2}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{70}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{12}{35}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;1
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{21}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{6}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{35}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{5}{42}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{8}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{27}{70}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{35}}&lt;/math&gt;
|}

{| class="wikitable"
|+ {{math|size=100%|1=''m''={{sfrac|1|2}}}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
! {{sfrac|9|2}} 
! {{sfrac|7|2}} 
! {{sfrac|5|2}} 
! {{sfrac|3|2}}
! {{sfrac|1|2}}
|----- valign="center"  align="center"
! {{sfrac|5|2}},&amp;nbsp;-2
| &lt;math&gt;\sqrt{\frac{1}{126}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{4}{63}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{3}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{8}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|3|2}},&amp;nbsp;-1
| &lt;math&gt;\sqrt{\frac{10}{63}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{121}{315}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{6}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{105}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{15}}&lt;/math&gt;
|----- valign="center"  align="center"
! {{sfrac|1|2}},&amp;nbsp;0
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{4}{105}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{8}{35}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{35}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{5}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|1|2}},&amp;nbsp;1
| &lt;math&gt;\sqrt{\frac{20}{63}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{14}{45}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{21}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{2}{15}}&lt;/math&gt;
|----- valign="center"  align="center"
! -{{sfrac|3|2}},&amp;nbsp;2
| &lt;math&gt;\sqrt{\frac{5}{126}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{64}{315}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{27}{70}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{32}{105}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{15}}&lt;/math&gt;
|}

=== {{math|size=100%|1=&amp;nbsp;''j''&lt;sub&gt;1&lt;/sub&gt;={{sfrac|5|2}}, ''j''&lt;sub&gt;2&lt;/sub&gt;={{sfrac|5|2}}}} ===

{| class="wikitable"
|+ {{math|size=100%|1=''m''=5}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|5|2}} 
| &lt;math&gt;1&lt;/math&gt;
|}
{| class="wikitable"
|+ {{math|size=100%|1=''m''=4}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
!4
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|5|2}} 
|&lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|}
{| class="wikitable"
|+ {{math|size=100%|1=''m''=3}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
!4
!3
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;{{sfrac|1|2}} 
| &lt;math&gt;\sqrt{\frac{2}{9}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{2}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{18}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}} 
| &lt;math&gt;\sqrt{\frac{5}{9}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-{\frac{2}{3}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|5|2}}
| &lt;math&gt;\sqrt{\frac{2}{9}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{2}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{5}{18}}&lt;/math&gt;
|}
{| class="wikitable"
|+ {{math|size=100%|1=''m''=2}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
!4
!3
!2
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{1}{12}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{28}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{12}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{28}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|3|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{5}{12}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{28}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{1}{12}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{9}{28}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}}
|&lt;math&gt;\sqrt{\frac{5}{12}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{5}{28}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{12}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{28}}&lt;/math&gt;
|----- valign="center" align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|5|2}}
|&lt;math&gt;\sqrt{\frac{1}{12}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{9}{28}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{12}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{5}{28}}&lt;/math&gt;
|}
{| class="wikitable"
|+ {{math|size=100%|1=''m''=1}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
! 4 
! 3 
! 2
! 1
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{1}{42}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{5}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{30}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{7}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{8}{35}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{10}{21}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{15}}&lt;/math&gt;
| &lt;math&gt;0&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{9}{35}}&lt;/math&gt;
|----- valign="center" align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{5}{21}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{5}{14}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{30}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{8}{35}}&lt;/math&gt;
|----- valign="center" align="center"
! -{{sfrac|3|2}},&amp;nbsp;{{sfrac|5|2}}
| &lt;math&gt;\sqrt{\frac{1}{42}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{7}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{3}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{5}{14}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
|}
{| class="wikitable"
|+ {{math|size=100%|1=''m''=0}} 
|----- valign="center" 
! {{diagonal split header|{{math|size=100%|''m''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''m''&lt;sub&gt;2&lt;/sub&gt;}}|{{mvar|j}}}}
!5
! 4 
! 3 
! 2
! 1
!0
|----- valign="center" align="center"
! {{sfrac|5|2}},&amp;nbsp;-{{sfrac|5|2}}
| &lt;math&gt;\sqrt{\frac{1}{252}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{28}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{5}{36}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{25}{84}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|3|2}},&amp;nbsp;-{{sfrac|3|2}}
|&lt;math&gt;\sqrt{\frac{25}{252}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{9}{28}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{49}{180}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{84}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{9}{70}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{6}}&lt;/math&gt;
|----- valign="center" align="center"
! {{sfrac|1|2}},&amp;nbsp;-{{sfrac|1|2}}
|&lt;math&gt;\sqrt{\frac{25}{63}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{7}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{45}}&lt;/math&gt;
| &lt;math&gt;-\sqrt{\frac{4}{21}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{1}{70}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
|----- valign="center" align="center"
! -{{sfrac|1|2}},&amp;nbsp;{{sfrac|1|2}}
| &lt;math&gt;\sqrt{\frac{25}{63}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{7}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{4}{45}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{4}{21}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{70}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{6}}&lt;/math&gt;
|----- valign="center" align="center"
! -{{sfrac|3|2}},&amp;nbsp;{{sfrac|3|2}}
| &lt;math&gt;\sqrt{\frac{25}{252}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{9}{28}}&lt;/math&gt;
| &lt;math&gt;\sqrt{\frac{49}{180}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{84}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{9}{70}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{1}{6}}&lt;/math&gt;
|-
!-{{sfrac|5|2}},&amp;nbsp;{{sfrac|5|2}}
|&lt;math&gt;\sqrt{\frac{1}{252}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{28}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{5}{36}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{25}{84}}&lt;/math&gt;
|&lt;math&gt;\sqrt{\frac{5}{14}}&lt;/math&gt;
|&lt;math&gt;-\sqrt{\frac{1}{6}}&lt;/math&gt;
|}

==SU(N) Clebsch–Gordan coefficients==

Algorithms to produce Clebsch–Gordan coefficients for higher values of &lt;math&gt;j_1&lt;/math&gt; and &lt;math&gt;j_2&lt;/math&gt;, or for the su(N) algebra instead of su(2), are known.&lt;ref&gt;{{cite journal |last=Alex |first=A. |author2=M. Kalus |author3=A. Huckleberry |author4=J. von Delft |title=A numerical algorithm for the explicit calculation of SU(N) and SL(N,C) Clebsch-Gordan coefficients |journal=J. Math. Phys. |volume=82 |date=February 2011 |pages=023507 |doi=10.1063/1.3521562 |url=http://link.aip.org/link/doi/10.1063/1.3521562 |archive-url=https://archive.is/20120604045917/http://link.aip.org/link/doi/10.1063/1.3521562 |dead-url=yes |archive-date=2012-06-04 |accessdate=2011-04-13 |bibcode=2011JMP....52b3507A |arxiv=1009.0437 }}&lt;/ref&gt;
A [http://homepages.physik.uni-muenchen.de/~vondelft/Papers/ClebschGordan/ web interface for tabulating SU(N) Clebsch-Gordan coefficients] is readily available.

==References==
&lt;references/&gt;

==External links==
* Online, [[Java (programming language)|Java]]-based [http://personal.ph.surrey.ac.uk/~phs3ps/cgjava.html Clebsch-Gordan Coefficient Calculator] by Paul Stevenson
* [http://functions.wolfram.com/HypergeometricFunctions/ClebschGordan/06/01/ Other formulae] for Clebsch–Gordan coefficients.
*  [http://homepages.physik.uni-muenchen.de/~vondelft/Papers/ClebschGordan/ Web interface for tabulating SU(N) Clebsch-Gordan coefficients]

{{DEFAULTSORT:Table of Clebsch-Gordan coefficients}}
[[Category:Representation theory of Lie groups]]
[[Category:Mathematical tables|Clebsch-Gordan coefficients]]</text>
      <sha1>3p427rvo87u0qmafj0r1pzfl380wjek</sha1>
    </revision>
  </page>
  <page>
    <title>Travelling salesman problem</title>
    <ns>0</ns>
    <id>31248</id>
    <revision>
      <id>871551630</id>
      <parentid>871551591</parentid>
      <timestamp>2018-12-01T21:38:12Z</timestamp>
      <contributor>
        <username>Hummerrocket</username>
        <id>31317511</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2601:47:0:D209:5963:16F:4C69:C72E|2601:47:0:D209:5963:16F:4C69:C72E]] ([[User talk:2601:47:0:D209:5963:16F:4C69:C72E|talk]]) ([[WP:HG|HG]]) (3.4.3)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="72400">{{Use British English Oxford spelling|date=August 2016}}
{{Use dmy dates|date=July 2012}}
[[File:GLPK solution of a travelling salesman problem.svg|thumb|Solution of a travelling salesman problem: the black line shows the shortest possible loop that connects every red dot]]
The '''travelling salesman problem ''' ('''TSP''') asks the following question: "Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?" It is an [[NP-hard]] problem in [[combinatorial optimization]], important in [[operations research]] and [[theoretical computer science]].

The [[Traveling purchaser problem|travelling purchaser problem]] and the [[vehicle routing problem]] are both generalizations of TSP.

In the [[Computational complexity theory|theory of computational complexity]], the decision version of the TSP (where, given a length ''L'', the task is to decide whether the graph has any tour shorter than ''L'') belongs to the class of [[NP-complete]] problems.  Thus, it is possible that the [[Best, worst and average case|worst-case]] [[running time]] for any algorithm for the TSP increases [[Time complexity#Superpolynomial time|superpolynomially]] (but no more than [[Exponential time hypothesis|exponentially]]) with the number of cities.

The problem was first formulated in 1930 and is one of the most intensively studied problems in optimization. It is used as a [[Benchmark (computing)|benchmark]] for many optimization methods. Even though the problem is computationally difficult, a large number of [[heuristic]]s and [[exact algorithm]]s are known, so that some instances with tens of thousands of cities can be solved completely and even problems with millions of cities can be approximated within a small fraction of 1%.&lt;ref&gt;See the TSP world tour problem which has already been solved to within 0.05% of the optimal solution. [http://www.math.uwaterloo.ca/tsp/world/]&lt;/ref&gt;

The TSP has several applications even in its purest formulation, such as [[planning]], [[logistics]], and the manufacture of [[Integrated circuit|microchips]]. Slightly modified, it appears as a sub-problem in many areas, such as [[DNA sequencing]]. In these applications, the concept ''city'' represents, for example, customers, soldering points, or DNA fragments, and the concept ''distance'' represents travelling times or cost, or a [[similarity measure]] between DNA fragments. The TSP also appears in astronomy, as astronomers observing many sources will want to minimize the time spent moving the telescope between the sources. In many applications, additional constraints such as limited resources or time windows may be imposed.

== History ==

The origins of the travelling salesman problem are unclear. A handbook for travelling salesmen from 1832 mentions the problem and includes example tours through Germany and Switzerland, but contains no mathematical treatment.&lt;ref&gt;"Der Handlungsreisende – wie er sein soll und was er zu tun hat, um Aufträge zu erhalten und eines glücklichen Erfolgs in seinen Geschäften gewiß zu sein – von einem alten Commis-Voyageur" (The travelling salesman — how he must be and what he should do in order to get commissions and be sure of the happy success in his business — by an old ''commis-voyageur'')&lt;/ref&gt;

[[File:William Rowan Hamilton painting.jpg|thumb|William Rowan Hamilton]]

The travelling salesman problem was mathematically formulated in the 1800s by the Irish mathematician [[William Rowan Hamilton|W.R. Hamilton]] and by the British mathematician [[Thomas Kirkman]]. Hamilton’s [[Icosian Game]] was a recreational puzzle based on finding a [[Hamiltonian cycle]].&lt;ref&gt;A discussion of the early work of Hamilton and Kirkman can be found in Graph Theory 1736–1936&lt;/ref&gt; The general form of the TSP appears to have been first studied by mathematicians during the 1930s in Vienna and at Harvard, notably by [[Karl Menger]], who defines the problem, considers the obvious brute-force algorithm, and observes the non-optimality of the nearest neighbour heuristic:
{{Quotation|
We denote by ''messenger problem'' (since in practice this question should be solved by each postman, anyway also by many travelers) the task to find, for finitely many points whose pairwise distances are known, the shortest route connecting the points. Of course, this problem is solvable by finitely many trials. Rules which would push the number of trials below the number of permutations of the given points, are not known. The rule that one first should go from the starting point to the closest point, then to the point closest to this, etc., in general does not yield the shortest route.
&lt;ref&gt;Cited and English translation in {{harvtxt|Schrijver|2005}}. Original German: "Wir bezeichnen als ''Botenproblem'' (weil diese Frage in der Praxis von jedem Postboten, übrigens auch von vielen Reisenden zu lösen ist) die Aufgabe, für endlich viele Punkte, deren paarweise Abstände bekannt sind, den kürzesten die Punkte verbindenden Weg zu finden. Dieses Problem ist natürlich stets durch endlich viele Versuche lösbar. Regeln, welche die Anzahl der Versuche unter die Anzahl der Permutationen der gegebenen Punkte herunterdrücken würden, sind nicht bekannt. Die Regel, man solle vom Ausgangspunkt erst zum nächstgelegenen Punkt, dann zu dem diesem nächstgelegenen Punkt gehen usw., liefert im allgemeinen nicht den kürzesten Weg."&lt;/ref&gt;}}

It was first considered mathematically in the 1930s by Merrill Flood who was looking to solve a school bus routing problem.&lt;ref name="Wiley"&gt;{{cite book|last1=al.]|first1=edited by E.L. Lawler ... [et|title=The Traveling salesman problem : a guided tour of combinatorial optimization|date=1985|publisher=Wiley|location=Chichester [West Sussex]|isbn=978-0471904137|edition=Repr. with corrections.}}&lt;/ref&gt;
[[Hassler Whitney]] at [[Princeton University]] introduced the name ''travelling salesman problem'' soon after.&lt;ref&gt;A detailed treatment of the connection between Menger and Whitney as well as the growth in the study of TSP can be found in [[Alexander Schrijver]]'s 2005 paper "On the history of combinatorial optimization (till 1960). Handbook of Discrete Optimization (K. Aardal, [[George Nemhauser|G.L. Nemhauser]], R. Weismantel, eds.), Elsevier, Amsterdam, 2005, pp. 1–68.[http://homepages.cwi.nl/~lex/files/histco.ps PS],[http://homepages.cwi.nl/~lex/files/histco.pdf PDF]&lt;/ref&gt;

In the 1950s and 1960s, the problem became increasingly popular in scientific circles in Europe and the USA after the [[RAND Corporation]] in [[Santa Monica]] offered prizes for steps in solving the problem.&lt;ref name="Wiley"/&gt; Notable contributions were made by [[George Dantzig]], [[Delbert Ray Fulkerson]] and [[Selmer M. Johnson]] from the RAND Corporation, who expressed the problem as an [[integer linear program]] and developed the [[cutting plane]] method for its solution. They wrote what is considered the seminal paper on the subject in which with these new methods they solved an instance with 49 cities to optimality by constructing a tour and proving that no other tour could be shorter. Dantzig, Fulkerson and Johnson, however, speculated that given a near optimal solution we may be able to find optimality or prove optimality by adding a small amount of extra inequalities (cuts). They used this idea to solve their initial 49 city problem using a string model. They found they only needed 26 cuts to come to a solution for their 49 city problem. While this paper did not give an algorithmic approach to TSP problems, the ideas that lay within it were indispensable to later creating exact solution methods for the TSP, though it would take 15 years to find an algorithmic approach in creating these cuts.&lt;ref name="Wiley"/&gt; As well as cutting plane methods, Dantzig, Fulkerson and Johnson used [[branch and bound]] algorithms perhaps for the first time.&lt;ref name="Wiley"/&gt;

In the following decades, the problem was studied by many researchers from [[mathematics]], [[computer science]], [[chemistry]], [[physics]], and other sciences. In the 1960s however a new approach was created, that instead of seeking optimal solutions, one would produce a solution whose length is provably bounded by a multiple of the optimal length, and in doing so create lower bounds for the problem; these may then be used with branch and bound approaches. One method of doing this was to create a [[minimum spanning tree]] of the graph and then double all its edges, which produces the bound that the length of an optimal tour is at most twice the weight of a minimum spanning tree.&lt;ref name="Wiley"/&gt;

Christofides made a big advance in this approach of giving an approach for which we know the worst-case scenario. [[Christofides algorithm]] given in 1976, at worst is 1.5 times longer than the optimal solution. As the algorithm was so simple and quick, many hoped it would give way to a near optimal solution method. However, until 2011 when it was beaten by less than a billionth of a percent, this remained the method with the best worst-case scenario.&lt;ref&gt;{{Cite journal|last1=Klarreich|first1=Erica|title=Computer Scientists Find New Shortcuts for Infamous Traveling Salesman Problem|url=https://www.wired.com/2013/01/traveling-salesman-problem/|journal=WIRED|accessdate=2015-06-14|date=2013-01-30}}&lt;/ref&gt;

[[Richard M. Karp]] showed in 1972 that the [[Hamiltonian cycle]] problem was [[NP-complete]], which implies the [[NP-hard]]ness of TSP. This supplied a mathematical explanation for the apparent computational difficulty of finding optimal tours.

Great progress was made in the late 1970s and 1980, when Grötschel, Padberg, Rinaldi and others managed to exactly solve instances with up to 2392 cities, using cutting planes and [[branch-and-bound]].

In the 1990s, [[David Applegate|Applegate]],  [[Robert E. Bixby|Bixby]], [[Vašek Chvátal|Chvátal]], and [[William J. Cook|Cook]] developed the program ''Concorde'' that has been used in many recent record solutions. Gerhard Reinelt published the TSPLIB in 1991, a collection of benchmark instances of varying difficulty, which has been used by many research groups for comparing results. In 2006, Cook and others computed an optimal tour through an  85,900-city instance given by a microchip layout problem, currently the largest solved TSPLIB instance. For many other instances with millions of cities, solutions can be found that are guaranteed to be within 2-3% of an optimal tour.&lt;ref name="rggo"&gt;{{citation
 | last1 = Rego | first1 = César
 | last2 = Gamboa | first2 = Dorabela
 | last3 = Glover | first3 = Fred
 | last4 = Osterman | first4 = Colin
 | doi = 10.1016/j.ejor.2010.09.010
 | issue = 3
 | journal = European Journal of Operational Research
 | mr = 2774420
 | pages = 427–441
 | title = Traveling salesman problem heuristics: leading methods, implementations and latest advances
 | volume = 211
 | year = 2011}}.&lt;/ref&gt;

==Description==

===As a graph problem===
[[File:Weighted K4.svg|thumb|Symmetric TSP with four cities]]
TSP can be modelled as an [[Graph (discrete mathematics)|undirected weighted graph]], such that cities are the graph's [[vertex (graph theory)|vertices]], paths are the graph's [[Glossary of graph theory#Basics|edges]], and a path's distance is the edge's weight.  It is a minimization problem starting and finishing at a specified [[vertex (graph theory)|vertex]] after having visited each other [[vertex (graph theory)|vertex]] exactly once. Often, the model is a [[complete graph]] (''i.e.'' each pair of vertices is connected by an edge). If no path exists between two cities, adding an arbitrarily long edge will complete the graph without affecting the optimal tour.

===Asymmetric and symmetric===
In the ''symmetric TSP'', the distance between two cities is the same in each opposite direction, forming an [[undirected graph]]. This symmetry halves the number of possible solutions. In the ''asymmetric TSP'', paths may not exist in both directions or the distances might be different, forming a [[directed graph]]. [[Traffic collision]]s, [[one-way street]]s, and airfares for cities with different departure and arrival fees are examples of how this symmetry could break down.

===Related problems===
&lt;!-- This belongs to somewhere else--&gt;

* An equivalent formulation in terms of [[graph theory]] is: Given a [[Glossary of graph theory|complete weighted graph]] (where the vertices would represent the cities, the edges would represent the roads, and the weights would be the cost or distance of that road), find a [[Hamiltonian cycle]] with the least weight.
* The requirement of returning to the starting city does not change the [[Computational complexity theory|computational complexity]] of the problem, see [[Hamiltonian path problem]].
* Another related problem is the [[Bottleneck traveling salesman problem]] (bottleneck TSP): Find a Hamiltonian cycle in a [[glossary of graph theory|weighted graph]] with the minimal weight of the weightiest [[edge (graph theory)|edge]]. For example, avoiding narrow streets with big buses.&lt;ref&gt;[http://online.WSJ.com/public/resources/documents/print/WSJ_-A002-20170812.pdf ''How Do You Fix School Bus Routes? Call MIT'' in Wall street Journal]&lt;/ref&gt; The problem is of considerable practical importance, apart from evident transportation and logistics areas. A classic example is in [[Printed circuit board|printed circuit]] manufacturing: scheduling of a route of the [[drill]] machine to drill holes in a PCB. In robotic machining or drilling applications, the "cities" are parts to machine or holes (of different sizes) to drill, and the "cost of travel" includes time for retooling the robot (single machine job sequencing problem).&lt;ref&gt;{{Citation
| last1 = Behzad| first1 = Arash| last2 = Modarres
| first2 = Mohammad| year = 2002
| title = New Efficient Transformation of the Generalized Traveling Salesman Problem into Traveling Salesman Problem
| journal = Proceedings of the 15th International Conference of Systems Engineering (Las Vegas)}}&lt;/ref&gt; 
* The [[Set TSP problem|generalized travelling salesman problem]], also known as the "travelling politician problem", deals with "states" that have (one or more) "cities" and the salesman has to visit exactly one "city" from each "state". One application is encountered in ordering a solution to the [[cutting stock problem]] in order to minimize knife changes. Another is concerned with drilling in [[semiconductor]] manufacturing, see e.g., {{US patent|7054798}}. Noon and Bean demonstrated that the generalized travelling salesman problem can be transformed into a standard travelling salesman problem with the same number of cities, but a modified [[distance matrix]].
* The sequential ordering problem deals with the problem of visiting a set of cities where precedence relations between the cities exist.
* A common interview question at Google is how to route data among data processing nodes; routes vary by time to transfer the data, but nodes also differ by their computing power and storage, compounding the problem of where to send data.
* The [[Traveling purchaser problem|travelling purchaser problem]] deals with a purchaser who is charged with purchasing a set of products. He can purchase these products in several cities, but at different prices and not all cities offer the same products. The objective is to find a route between a subset of the cities, which minimizes total cost (travel cost + purchasing cost) and which enables the purchase of all required products.

==Integer linear programming formulation==
TSP can be formulated as an [[integer programming|integer linear program]].&lt;ref&gt;{{Citation|last=Papadimitriou|first=C.H.|last2=Steiglitz |first2=K. |title=Combinatorial optimization: algorithms and complexity|year=1998|publisher=Dover|location=Mineola, NY}}, pp.308-309.&lt;/ref&gt;&lt;ref&gt;Tucker, A. W. (1960), "On Directed Graphs and Integer Programs", IBM Mathematical research Project (Princeton University)&lt;/ref&gt;&lt;ref&gt;Dantzig, George B. (1963), ''Linear Programming and Extensions'', Princeton, NJ: PrincetonUP, pp. 545–7, {{isbn|0-691-08000-3}}, sixth printing, 1974.&lt;/ref&gt; Label the cities with the numbers 1, &amp;hellip;, ''n'' and define:

:&lt;math&gt; x_{ij} = \begin{cases} 1 &amp; \text{the path goes from city } i \text{ to city } j \\ 0 &amp; \text{otherwise} \end{cases}&lt;/math&gt;

For ''i'' = 1, &amp;hellip;, ''n'', let &lt;math&gt;u_i&lt;/math&gt; be a dummy variable, and finally take &lt;math&gt;c_{ij}&lt;/math&gt; to be the distance from city ''i'' to city ''j''. Then TSP can be written as the following integer linear programming problem:

:&lt;math&gt;\begin{align}
\min &amp;\sum_{i=1}^n \sum_{j\ne i,j=1}^nc_{ij}x_{ij}\colon &amp;&amp;  \\
     &amp; 0 \le x_{ij} \le 1  &amp;&amp; i,j=1, \ldots, n; \\
     &amp; u_{i} \in \mathbf{Z} &amp;&amp; i=1, \ldots, n; \\
     &amp; \sum_{i=1,i\ne j}^n x_{ij} = 1 &amp;&amp; j=1, \ldots, n; \\
     &amp; \sum_{j=1,j\ne i}^n x_{ij} = 1 &amp;&amp; i=1, \ldots, n; \\
     &amp; u_i-u_j +nx_{ij} \le n-1 &amp;&amp; 2 \le i \ne j \le n;  \\
     &amp; 0 \le u_i \le n-1 &amp;&amp; 2 \le i \le n.
\end{align}&lt;/math&gt;

The first set of equalities requires that each city be arrived at from exactly one other city, and the second set of equalities requires that from each city there is a departure to exactly one other city. The last constraints enforce that there is only a single tour covering all cities, and not two or more disjointed tours that only collectively cover all cities. To prove this, it is shown below (1) that every feasible solution contains only one closed sequence of cities, and (2) that for every single tour covering all cities, there are values for the dummy variables &lt;math&gt;u_i&lt;/math&gt; that satisfy the constraints.

To prove that every feasible solution contains only one closed sequence of cities, it suffices to show that every subtour in a feasible solution passes through city 1 (noting that the equalities ensure there can only be one such tour). For if we sum all the inequalities corresponding to &lt;math&gt;x_{ij}=1&lt;/math&gt; for any subtour of ''k'' steps not passing through city 1, we obtain:

:&lt;math&gt;nk \leq (n-1)k,&lt;/math&gt;

which is a contradiction.

It now must be shown that for every single tour covering all cities, there are values for the dummy variables &lt;math&gt;u_i&lt;/math&gt; that satisfy the constraints.

Without loss of generality, define the tour as originating (and ending) at city 1. Choose &lt;math&gt;u_{i}=t&lt;/math&gt; if city ''i'' is visited in step ''t'' (''i'', ''t'' = 1, 2, ..., n). Then

:&lt;math&gt;u_i-u_j\le n-1,&lt;/math&gt;

since &lt;math&gt;u_i&lt;/math&gt; can be no greater than ''n'' and &lt;math&gt;u_j&lt;/math&gt; can be no less than 1; hence the constraints are satisfied whenever &lt;math&gt;x_{ij}=0.&lt;/math&gt; For &lt;math&gt;x_{ij}=1&lt;/math&gt;, we have:

:&lt;math&gt;  u_{i} - u_{j} + nx_{ij} = (t) - (t+1) + n = n-1,&lt;/math&gt;

satisfying the constraint.

==Computing a solution==
The traditional lines of attack for the NP-hard problems are the following:
* Devising [[exact algorithm]]s, which work reasonably fast only for small problem sizes.
* Devising "suboptimal" or [[heuristic algorithm]]s, i.e., algorithms that deliver either seemingly or probably good solutions, but which could not be proved to be optimal.
* Finding special cases for the problem ("subproblems") for which either better or exact heuristics are possible.

===Exact algorithms===

The most direct solution would be to try all [[permutation]]s (ordered combinations) and see which one is cheapest (using [[brute force search]]). The running time for this approach lies within a polynomial factor of &lt;math&gt;O(n!)&lt;/math&gt;, the [[factorial]] of the number of cities, so this solution becomes impractical even for only 20 cities.

One of the earliest applications of [[dynamic programming]] is the [[Held&amp;ndash;Karp algorithm]] that solves the problem in time &lt;math&gt;O(n^2 2^n)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bellman|1960}}, {{harvtxt|Bellman|1962}}, {{harvtxt|Held|Karp|1962}}&lt;/ref&gt; This bound has also been reached by Exclusion-Inclusion in an attempt preceding the dynamic programming approach.
[[File:Bruteforce.gif|framed|right|Solution to a symmetric TSP with 7 cities using brute force search. Note: Number of permutations: (7-1)!/2 = 360]]

Improving these time bounds seems to be difficult. For example, it has not been determined whether an [[exact algorithm]] for TSP that runs in time &lt;math&gt;O(1.9999^n)&lt;/math&gt; exists.&lt;ref&gt;{{harvtxt|Woeginger|2003}}&lt;/ref&gt;

Other approaches include:
* Various [[Branch and bound|branch-and-bound]] algorithms, which can be used to process TSPs containing 40–60 cities.

[[File:Branchbound.gif|framed|right|Solution of a TSP with 7 cities using a simple Branch and bound algorithm. Note: The number of permutations is much less than Brute force search]]

* Progressive improvement algorithms which use techniques reminiscent of [[linear programming]]. Works well for up to 200 cities.
* Implementations of [[Branch and bound|branch-and-bound]] and problem-specific cut generation ([[Branch and cut|branch-and-cut]]&lt;ref&gt;{{harvtxt|Padberg|Rinaldi|1991}}&lt;/ref&gt;); this is the method of choice for solving large instances. This approach holds the current record, solving an instance with 85,900 cities, see {{harvtxt|Applegate|Bixby|Chvátal|Cook|2006}}.

An exact solution for 15,112 German towns from TSPLIB was found in 2001 using the [[cutting-plane method]] proposed by [[George Dantzig]], [[D. R. Fulkerson|Ray Fulkerson]], and [[Selmer M. Johnson]] in 1954, based on [[linear programming]]. The computations were performed on a network of 110 processors located at [[Rice University]] and [[Princeton University]] (see the Princeton external link){{citation needed|date=January 2016}}. The total computation time was equivalent to 22.6&amp;nbsp;years on a single 500&amp;nbsp;MHz [[Alpha processor]]. In May 2004, the travelling salesman problem of visiting all 24,978 towns in Sweden was solved: a tour of length approximately 72,500 kilometres was found and it was proven that no shorter tour exists.&lt;ref&gt;Work by David Applegate, AT&amp;T Labs – Research, Robert Bixby, [[ILOG]] and Rice University, Vašek Chvátal, Concordia University, William Cook, University of Waterloo, and Keld Helsgaun, Roskilde University is discussed on their project web page hosted by the University of Waterloo and last updated in June 2004, here [http://www.math.uwaterloo.ca/tsp/sweden/]&lt;/ref&gt; In March 2005, the travelling salesman problem of visiting all 33,810 points in a circuit board was solved using ''[[Concorde TSP Solver]]'': a tour of length 66,048,945 units was found and it was proven that no shorter tour exists. The computation took approximately 15.7 CPU-years&lt;!-- Is this with a 500&amp;nbsp;MHz processor. Please make clear what you mean by CPU year. --&gt; (Cook et al. 2006). In April 2006 an instance with 85,900 points was solved using ''Concorde TSP Solver'', taking over 136 CPU-years, see {{harvtxt|Applegate|Bixby|Chvátal|Cook|2006}}.

===Heuristic and approximation algorithms===
Various [[Heuristic (computer science)|heuristics]] and [[approximation algorithm]]s, which quickly yield good solutions have been devised. Modern methods can find solutions for extremely large problems (millions of cities) within a reasonable time which are with a high probability just 2–3% away from the optimal solution.&lt;ref name="rggo"/&gt;

Several categories of heuristics are recognized.

====Constructive heuristics====
[[File:Nearestneighbor.gif|393px|thumb|Nearest Neighbour algorithm for a TSP with 7 cities. The solution changes as the starting point is changed]]
The [[nearest neighbour algorithm|nearest neighbour (NN) algorithm]] (a [[greedy algorithm]]) lets the salesman choose the nearest unvisited city as his next move. This algorithm quickly yields an effectively short route. For N cities randomly distributed on a plane, the algorithm on average yields a path 25% longer than the shortest possible path.&lt;ref name=johnson/&gt; However, there exist many specially arranged city distributions which make the NN algorithm give the worst route.&lt;ref&gt;{{cite journal |last=Gutina |first=Gregory |last2=Yeob |first2=Anders |last3=Zverovich |first3=Alexey |date=15 March 2002 |title=Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP |journal=Discrete Applied Mathematics |volume=117 |pages=81–86 |doi=10.1016/S0166-218X(01)00195-0}}&gt;&lt;/ref&gt; This is true for both asymmetric and symmetric TSPs.&lt;ref&gt;{{Cite book |last=Johnson |first=David |last2=Gutin |first2=Gregory |last3=McGeoch |first3=Lyle |last4=Yeo |first4=Anders |last5=Zhang |first5=Weixiong |last6=Zverovitch |first6=Alexei |date=2007 |title=Experimental Analysis of Heuristics for the ATSP |journal=The Traveling Salesman Problem and its Variations |volume=12 |pages=445–487 |doi=10.1007/0-306-48213-4_10|series=Combinatorial Optimization |isbn=978-0-387-44459-8 |citeseerx=10.1.1.24.2386 }}&lt;/ref&gt; Rosenkrantz et al.&lt;ref&gt;{{cite conference |first=D. J. |last=Rosenkrantz |first2=R. E. |last2=Stearns |first3=P. M. |last3=Lewis |title=Approximate algorithms for the traveling salesperson problem |conference=15th Annual Symposium on Switching and Automata Theory (swat 1974) |date=14-16 October 1974 |doi=10.1109/SWAT.1974.4}}&lt;/ref&gt; showed that the NN algorithm has the approximation factor &lt;math&gt;\Theta(\log |V|)&lt;/math&gt; for instances satisfying the triangle inequality. A variation of NN algorithm, called Nearest Fragment (NF) operator, which connects a group (fragment) of nearest unvisited cities, can find shorter route with successive iterations.&lt;ref&gt;{{cite journal | last1 = Ray | first1 = S. S. | last2 = Bandyopadhyay | first2 = S. | last3 = Pal | first3 = S. K. | year = 2007 | title = Genetic Operators for Combinatorial Optimization in TSP and Microarray Gene Ordering | url = | journal = Applied Intelligence | volume = 26 | issue = 3| pages = 183–195 | doi=10.1007/s10489-006-0018-y| citeseerx = 10.1.1.151.132 }}&lt;/ref&gt; The NF operator can also be applied on an initial solution obtained by NN algorithm for further improvement in an elitist model, where only better solutions are accepted.

The [[bitonic tour]] of a set of points is the minimum-perimeter [[monotone polygon]] that has the points as its vertices; it can be computed efficiently by [[dynamic programming]].

Another [[constructive heuristic]], Match Twice and Stitch (MTS), performs two sequential [[Matching (graph theory)|matchings]], where the second matching is executed after deleting all the edges of the first matching, to yield a set of cycles. The cycles are then stitched to produce the final tour.&lt;ref&gt;{{cite journal | last1 = Kahng | first1 = A. B. | last2 = Reda | first2 = S. | year = 2004 | title = Match Twice and Stitch: A New TSP Tour Construction Heuristic | url = | journal = Operations Research Letters | volume = 32 | issue = 6| pages = 499–509 | doi = 10.1016/j.orl.2004.04.001 }}&lt;/ref&gt;

=====Christofides' algorithm for the TSP=====
The [[Christofides algorithm]] follows a similar outline but combines the minimum spanning tree with a solution of another problem, minimum-weight [[perfect matching]]. This gives a TSP tour which is at most 1.5 times the optimal.  The Christofides algorithm was one of the first [[approximation algorithm]]s, and was in part responsible for drawing attention to approximation algorithms as a practical approach to intractable problems. As a matter of fact, the term "algorithm" was not commonly extended to approximation algorithms until later; the Christofides algorithm was initially referred to as the Christofides heuristic.

This algorithm looks at things differently by using a result from graph theory which helps improve on the LB of the TSP which originated from doubling the cost of the minimum spanning tree. Given an [[Eulerian graph]] we can find an [[Eulerian tour]] in {{tmath|O(n)}} time.&lt;ref name="Wiley"/&gt; So if we had an Eulerian graph with cities from a TSP as vertices then we can easily see that we could use such a method for finding an Eulerian tour to find a TSP solution. By [[triangular inequality]] we know that the TSP tour can be no longer than the Eulerian tour and as such we have a LB for the TSP. Such a method is described below.
[[File:UbMjAyAmQrSwtP0gdeKe matchingshortcut.png|thumb|Using a shortcut heuristic on the graph created by the matching below]]
#  Find a minimum spanning tree for the problem
#  Create duplicates for every edge to create an Eulerian graph
#  Find an Eulerian tour for this graph
#  Convert to TSP: if a city is visited twice, create a shortcut from the city before this in the tour to the one after this.

To improve our lower bound, we therefore need a better way of creating an Eulerian graph. But by triangular inequality, the best Eulerian graph must have the same cost as the best travelling salesman tour, hence finding optimal Eulerian graphs is at least as hard as TSP. One way of doing this that has been proposed is by the concept of minimum weight [[Matching (graph theory)|matching]]  for the creation of which there exist algorithms of &lt;math&gt;O(n^3)&lt;/math&gt;.&lt;ref name="Wiley"/&gt;
[[File:Creating a matching.png|thumb|Creating a matching]]

To make a graph into an Eulerian graph, one starts with the minimum spanning tree. Then all the vertices of odd order must be made even. So a matching for the odd degree vertices must be added which increases the order of every odd degree vertex by one.&lt;ref name="Wiley"/&gt; This leaves us with a graph where every vertex is of even order which is thus Eulerian. Now we can adapt the above method to give Christofides' algorithm,

#  Find a minimum spanning tree for the problem
# Create a matching for the problem with the set of cities of odd order. 
# Find an Eulerian tour for this graph
# Convert to TSP using shortcuts.

====Iterative improvement====
[[File:Showing a step of the two-opt heuristic.png|thumb|right|An example of a 2-opt iteration]]

===== Pairwise exchange =====
The pairwise exchange or ''[[2-opt]]'' technique involves iteratively removing two edges and replacing these with two different edges that reconnect the fragments created by edge removal into a new and shorter tour. Similarly, the [[3-opt]] technique removes 3 edges and reconnects them to form a shorter tour. These are special cases of the ''k''-opt method. Note that the label ''Lin–Kernighan'' is an often heard misnomer for 2-opt. Lin–Kernighan is actually the more general k-opt method.

For Euclidean instances, 2-opt heuristics give on average solutions that are about 5% better than Christofides' algorithm. If we start with an initial solution made with a [[greedy algorithm]], the average number of moves greatly decreases again and is {{tmath|O(n)}}. For random starts however, the average number of moves is {{tmath|O(n  \log (n))}}. However whilst in order this is a small increase in size, the initial number of moves for small problems is 10 times as big for a random start compared to one made from a greedy heuristic. This is because such 2-opt heuristics exploit `bad' parts of a solution such as crossings. These types of heuristics are often used within [[Vehicle routing problem]] heuristics to reoptimize route solutions.&lt;ref name=johnson&gt;{{cite book |last1=Johnson|first1=D. S.|author1-link=David S. Johnson|last2=McGeoch|first2=L. A.|chapter=The Traveling Salesman Problem: A Case Study in Local Optimization|title=Local Search in Combinatorial Optimisation|editor1-first=E. H. L.|editor1-last=Aarts|editor2-first=J. K.|editor2-last=Lenstra|editor2-link=Jan Karel Lenstra|publisher=John Wiley and Sons Ltd.|date=1997 |location=London|pages=215–310 |chapter-url=https://www.cs.ubc.ca/~hutter/previous-earg/EmpAlgReadingGroup/TSP-JohMcg97.pdf}}&lt;/ref&gt;

===== ''k''-opt heuristic, or [[Lin–Kernighan]] heuristics =====
Take a given tour and delete ''k'' mutually disjoint edges. Reassemble the remaining fragments into a tour, leaving no disjoint subtours (that is, don't connect a fragment's endpoints together). This in effect simplifies the TSP under consideration into a much simpler problem. Each fragment endpoint can be connected to {{math|2''k''&amp;nbsp;−&amp;nbsp;2}} other possibilities: of 2''k'' total fragment endpoints available, the two endpoints of the fragment under consideration are disallowed. Such a constrained 2''k''-city TSP can then be solved with brute force methods to find the least-cost recombination of the original fragments. The ''k''-opt technique is a special case of the ''V''-opt or variable-opt technique. The most popular of the ''k''-opt methods are 3-opt, and these were introduced by Shen Lin of Bell Labs in 1965. There is a special case of 3-opt where the edges are not disjoint (two of the edges are adjacent to one another). In practice, it is often possible to achieve substantial improvement over 2-opt without the combinatorial cost of the general 3-opt by restricting the 3-changes to this special subset where two of the removed edges are adjacent. This so-called two-and-a-half-opt typically falls roughly midway between 2-opt and 3-opt, both in terms of the quality of tours achieved and the time required to achieve those tours.

===== ''V''-opt heuristic =====
The variable-opt method is related to, and a generalization of the ''k''-opt method. Whereas the ''k''-opt methods remove a fixed number (''k'') of edges from the original tour, the variable-opt methods do not fix the size of the edge set to remove. Instead they grow the set as the search process continues. The best known method in this family is the Lin–Kernighan method (mentioned above as a misnomer for 2-opt). [[Shen Lin]] and [[Brian Kernighan]] first published their method in 1972, and it was the most reliable heuristic for solving travelling salesman problems for nearly two decades. More advanced variable-opt methods were developed at Bell Labs in the late 1980s by David Johnson and his research team. These methods (sometimes called [[Lin–Kernighan–Johnson]]) build on the Lin–Kernighan method, adding ideas from [[tabu search]] and [[evolutionary computing]]. The basic Lin–Kernighan technique gives results that are guaranteed to be at least 3-opt. The Lin–Kernighan–Johnson methods compute a Lin–Kernighan tour, and then perturb the tour by what has been described as a mutation that removes at least four edges and reconnecting the tour in a different way, then ''V''-opting the new tour. The mutation is often enough to move the tour from the [[local minimum]] identified by Lin–Kernighan. ''V''-opt methods are widely considered the most powerful heuristics for the problem, and are able to address special cases, such as the Hamilton Cycle Problem and other non-metric TSPs that other heuristics fail on. For many years Lin–Kernighan–Johnson had identified optimal solutions for all TSPs where an optimal solution was known and had identified the best known solutions for all other TSPs on which the method had been tried.

====Randomized improvement====
Optimized [[Markov chain]] algorithms which use local searching heuristic sub-algorithms can find a route extremely close to the optimal route for 700 to 800 cities.

TSP is a touchstone for many general heuristics devised for combinatorial optimization such as [[genetic algorithm]]s, [[simulated annealing]], [[tabu search]], [[ant colony optimization]], [[river formation dynamics]] (see [[swarm intelligence]]) and the [[cross entropy method]].

=====Ant colony optimization=====
{{main|Ant colony optimization algorithms}}
[[Artificial intelligence]] researcher [[Marco Dorigo]] described in 1993 a method of heuristically generating "good solutions" to the TSP using a [[Ant colony optimization|simulation of an ant colony]] called ''ACS'' (''ant colony system'').&lt;ref&gt;Marco Dorigo. "Ant Colonies for the Traveling Salesman Problem. IRIDIA, Université Libre de Bruxelles. ''IEEE Transactions on Evolutionary Computation'', 1(1):53&amp;ndash;66. 1997. http://citeseer.ist.psu.edu/86357.html&lt;/ref&gt; It models behaviour observed in real ants to find short paths between food sources and their nest, an [[emergence|emergent]] behaviour resulting from each ant's preference to follow [[Pheromone#Trail|trail pheromones]] deposited by other ants.

ACS sends out a large number of virtual ant agents to explore many possible routes on the map. Each ant probabilistically chooses the next city to visit based on a heuristic combining the distance to the city and the amount of virtual pheromone deposited on the edge to the city. The ants explore, depositing pheromone on each edge that they cross, until they have all completed a tour. At this point the ant which completed the shortest tour deposits virtual pheromone along its complete tour route (''global trail updating''). The amount of pheromone deposited is inversely proportional to the tour length: the shorter the tour, the more it deposits.

[[File:Aco TSP.svg|600px|center]]
[[File:AntColony.gif|framed|center|Ant colony optimization algorithm for a TSP with 7 cities: Red and thick lines in the pheromone map indicate presence of more pheromone]]

==Special cases of the TSP==

===Metric TSP===
In the ''metric TSP'', also known as ''delta-TSP'' or Δ-TSP, the intercity distances satisfy the [[triangle inequality]].

A very natural restriction of the TSP is to require that the distances between cities form a [[metric (mathematics)|metric]] to satisfy the [[triangle inequality]]; that is the direct connection from ''A'' to ''B'' is never farther than the route via intermediate ''C'':
:&lt;math&gt;d_{AB} \le d_{AC} + d_{CB}&lt;/math&gt;.

The edge spans then build a [[metric space|metric]] on the set of vertices. When the cities are viewed as points in the plane, many natural [[distance function]]s are metrics, and so many natural instances of TSP satisfy this constraint.

The following are some examples of metric TSPs for various metrics.
*In the Euclidean TSP (see below) the distance between two cities is the [[Euclidean distance]] between the corresponding points.
*In the rectilinear TSP the distance between two cities is the sum of the absolute values of the differences of their ''x''- and ''y''-coordinates. This metric is often called the [[Manhattan distance]] or city-block metric.
*In the [[maximum metric]], the distance between two points is the maximum of the absolute values of differences of their ''x''- and ''y''-coordinates.

The last two metrics appear, for example, in routing a machine that drills a given set of holes in a [[printed circuit board]]. The Manhattan metric corresponds to a machine that adjusts first one co-ordinate, and then the other, so the time to move to a new point is the sum of both movements. The maximum metric corresponds to a machine that adjusts both co-ordinates simultaneously, so the time to move to a new point is the slower of the two movements.

In its definition, the TSP does not allow cities to be visited twice, but many applications do not need this constraint. In such cases, a symmetric, non-metric instance can be reduced to a metric one. This replaces the original graph with a complete graph in which the inter-city distance &lt;math&gt;d_{AB}&lt;/math&gt; is replaced by the [[shortest path]] between ''A'' and ''B'' in the original graph.

===Euclidean TSP===
When the input numbers can be arbitrary real numbers, Euclidean TSP is a particular case of metric TSP, since distances in a plane obey the triangle inequality. When the input numbers must be integers, comparing lengths of tours involves comparing sums of square-roots.

Like the general TSP, Euclidean TSP is NP-hard in either case. With rational coordinates and discretized metric (distances rounded up to an integer), the problem is NP-complete.{{sfnp|Papadimitriou|1977}} With rational coordinates and the actual Euclidean metric, Euclidean TSP is known to be in the Counting Hierarchy,&lt;ref&gt;{{harvtxt|Allender|Bürgisser|Kjeldgaard-Pedersen|Mitersen|2007}}&lt;/ref&gt; a subclass of PSPACE. With arbitrary real coordinates, Euclidean TSP cannot be in such classes, since there are uncountably many possible inputs. However, Euclidean TSP is probably the easiest version for approximation.&lt;ref&gt;{{harvtxt|Larson|Odoni|1981}}&lt;/ref&gt; For example, the minimum spanning tree of the graph associated with an instance of the Euclidean TSP is a [[Euclidean minimum spanning tree]], and so can be computed in expected O (''n'' log ''n'') time for ''n'' points (considerably less than the number of edges). This enables the simple 2-approximation algorithm for TSP with triangle inequality above to operate more quickly.

In general, for any ''c'' &gt; 0, where ''d'' is the number of dimensions in the Euclidean space, there is a polynomial-time algorithm that finds a tour of length at most (1 + 1/''c'') times the optimal for geometric instances of TSP in

:&lt;math&gt;O\left(n (\log n)^{(O(c \sqrt{d}))^{d-1}}\right),&lt;/math&gt;

time; this is called a [[polynomial-time approximation scheme]] (PTAS).{{sfnp|Arora|1998}} [[Sanjeev Arora]] and [[Joseph S. B. Mitchell]] were awarded the [[Gödel Prize]] in 2010 for their concurrent discovery of a PTAS for the Euclidean TSP.

In practice, simpler heuristics with weaker guarantees continue to be used.

===Asymmetric TSP===
In most cases, the distance between two nodes in the TSP network is the same in both directions. The case where the distance from ''A'' to ''B'' is not equal to the distance from ''B'' to ''A'' is called asymmetric TSP. A practical application of an asymmetric TSP is route optimization using street-level routing (which is made asymmetric by one-way streets, slip-roads, motorways, etc.).

====Solving by conversion to symmetric TSP====
Solving an asymmetric TSP graph can be somewhat complex. The following is a 3×3 matrix containing all possible path weights between the nodes ''A'', ''B'' and ''C''. One option is to turn an asymmetric matrix of size ''N'' into a symmetric matrix of size 2''N''.&lt;ref&gt;{{cite journal | last1 = Jonker | first1 = Roy | last2 = Volgenant | first2 = Ton | title = Transforming asymmetric into symmetric traveling salesman problems | url = | journal = [[Operations Research Letters]] | volume = 2 | issue = 161–163| page = 1983 | doi = 10.1016/0167-6377(83)90048-2 | year = 1983 }}&lt;/ref&gt;

:{| class="wikitable"
|- style="text-align:center;"
|+ Asymmetric path weights
! !! ''A'' !! ''B'' !! ''C''
|- style="text-align:center;"
! ''A''
| || 1 || 2
|- style="text-align:center;"
! ''B''
| 6 || || 3
|- style="text-align:center;"
! ''C''
| 5 || 4 ||
|}

To double the size, each of the nodes in the graph is duplicated, creating a second ''ghost node'', linked to the original node with a "ghost" edge of very low (possibly negative) weight, here denoted −''w''. (Alternatively, the ghost edges have weight 0, and weight w is added to all other edges.)  The original 3×3 matrix shown above is visible in the bottom left and the transpose of the original in the top-right. Both copies of the matrix have had their diagonals replaced by the low-cost hop paths, represented by −''w''. In the new graph, no edge directly links original nodes and no edge directly links ghost nodes.

:{| class="wikitable"
|- style="text-align:center;" class="wikitable"
|+ Symmetric path weights
! !! ''A'' !! ''B'' !! ''C'' !! ''A&amp;prime;'' !! ''B&amp;prime;'' !! ''C&amp;prime;''
|- style="text-align:center;"
! ''A''
| || || || −''w'' || 6 || 5
|- style="text-align:center;"
! ''B''
| || || || 1 || −''w'' || 4
|- style="text-align:center;"
! ''C''
| || || || 2 || 3 || −''w''
|- style="text-align:center;"
! ''A&amp;prime;''
| −''w'' || 1 || 2 || || ||
|- style="text-align:center;"
! ''B&amp;prime;''
| 6 || −''w'' || 3 || || ||
|- style="text-align:center;"
! ''C&amp;prime;''
| 5 || 4 || −''w'' || || ||
|}

The weight −''w'' of the "ghost" edges linking the ghost nodes to the corresponding original nodes must be low enough to ensure that all ghost edges must belong to any optimal symmetric TSP solution on the new graph (w=0 is not always low enough). As a consequence, in the optimal symmetric tour, each original node appears next to its ghost node (e.g. a possible path is &lt;math&gt;\mathrm{A \to A' \to C \to C' \to B \to B' \to A}&lt;/math&gt;) and by mergeing the original and ghost nodes again we get an (optimal) solution of the original asymmetric problem (in our example, &lt;math&gt;\mathrm{A \to C \to B \to A}&lt;/math&gt;).

===Analyst's travelling salesman problem===
There is an analogous problem in [[geometric measure theory]] which asks the following: under what conditions may a subset ''E'' of [[Euclidean space]] be contained in a [[rectifiable curve]] (that is, when is there a curve with finite length that visits every point in ''E'')? This problem is known as the [[analyst's traveling salesman theorem|analyst's travelling salesman problem]]

===TSP path length for random sets of points in a square===
Suppose &lt;math&gt;X_1,\ldots,X_n&lt;/math&gt; are &lt;math&gt;n&lt;/math&gt; independent random variables with uniform distribution in the square &lt;math&gt;[0,1]^2&lt;/math&gt;, and let &lt;math&gt;L^\ast_n&lt;/math&gt; be the shortest path length (i.e. TSP solution) for this set of points, according to the usual [[Euclidean distance]]. It is known&lt;ref name="Beardwood 1959"&gt;{{harvtxt|Beardwood|Halton|Hammersley|1959}}&lt;/ref&gt; that, almost surely,

::&lt;math&gt;\frac{L^*_n}{\sqrt n}\rightarrow \beta\qquad\text{when }n\to\infty,&lt;/math&gt;

where &lt;math&gt;\beta&lt;/math&gt; is a positive constant that is not known explicitly. Since &lt;math&gt;L^*_n\le2\sqrt n+2&lt;/math&gt; (see below), it follows from [[bounded convergence theorem]] that &lt;math&gt;\beta=\lim_{n\to\infty} \mathbb E[L^*_n]/\sqrt n&lt;/math&gt;, hence lower and upper bounds on &lt;math&gt;\beta&lt;/math&gt; follow from bounds on &lt;math&gt;\mathbb E[L^*_n]&lt;/math&gt;.

The almost sure limit &lt;math&gt;\frac{L^*_n}{\sqrt n}\rightarrow \beta&lt;/math&gt; as &lt;math&gt;n\to\infty&lt;/math&gt; may not exist 
if the independent locations  &lt;math&gt;X_1,\ldots,X_n&lt;/math&gt; are replaced with observations from a stationary ergodic process with uniform marginals.&lt;ref name="as2016"&gt;{{citation
 | doi = 10.1214/15-AAP1142
 | last1 = Arlotto | first1 = Alessandro
 | last2 = Steele | first2 = J. Michael | author2-link = J._Michael_Steele
 | journal = The Annals of Applied Probability 
 | pages = 2141–2168
 | title = Beardwood–Halton–Hammersley theorem for stationary ergodic sequences: a counterexample
 | volume = 26
 | issue = 4
 | year = 2016| arxiv = 1307.0221}}&lt;/ref&gt;

====Upper bound====
*One has &lt;math&gt;L^*\le 2\sqrt{n}+2&lt;/math&gt;, and therefore &lt;math&gt;\beta\leq 2&lt;/math&gt;, by using a naive path which visits monotonically the points inside each of &lt;math&gt;\sqrt n&lt;/math&gt; slices of width &lt;math&gt;1/\sqrt{n}&lt;/math&gt; in the square.
*Few &lt;ref&gt;{{cite journal|last1=Few|first1=L.|title=The shortest path and the shortest road through n points|journal=Mathematika|date=1955|volume=2|issue=2|pages=141–144|doi=10.1112/s0025579300000784 }}&lt;/ref&gt; proved &lt;math&gt;L^*_n\le\sqrt{2n}+1.75&lt;/math&gt;, hence &lt;math&gt;\beta\le\sqrt 2&lt;/math&gt;, later improved by Karloff (1987): &lt;math&gt;\beta\le0.984\sqrt2&lt;/math&gt;.
* The current &lt;ref name="ReferenceA"&gt;{{cite journal|last1=Steinerberger|first1=S.|title=New bounds for the traveling salesman constant|journal=Advances in Applied Probability|date=2015|volume=47.1}}&lt;/ref&gt; best upper bound is  &lt;math&gt;\beta\le 0.92\dots&lt;/math&gt;.

====Lower bound====
*By observing that &lt;math&gt;\mathbb E[L^*_n]&lt;/math&gt; is greater than &lt;math&gt;n&lt;/math&gt; times the distance between &lt;math&gt;X_0&lt;/math&gt; and the closest point &lt;math&gt;X_i\ne X_0&lt;/math&gt;, one gets (after a short computation)

::&lt;math&gt;\mathbb E[L^*_n]\ge\tfrac{1}{2} \sqrt{n}.&lt;/math&gt;

*A better lower bound is obtained&lt;ref name="Beardwood 1959"/&gt; by observing that &lt;math&gt;\mathbb E[L^*_n]&lt;/math&gt; is greater than &lt;math&gt;\tfrac12n&lt;/math&gt; times the sum of the distances between &lt;math&gt;X_0&lt;/math&gt; and the closest and second closest points &lt;math&gt;X_i,X_j\ne X_0&lt;/math&gt;, which gives

::&lt;math&gt;\mathbb E[L^*_n]\ge \left( \tfrac{1}{4} + \tfrac{3}{8} \right)\sqrt{n} = \tfrac{5}{8}\sqrt{n},&lt;/math&gt;

*The currently &lt;ref name="ReferenceA"/&gt; best lower bound is
::&lt;math&gt;\mathbb E[L^*_n]\ge (\tfrac{5}{8} + \tfrac{19}{5184})\sqrt{n},&lt;/math&gt;

*Held and Karp&lt;ref&gt;{{cite journal|last1=Held|first1=M.|last2=Karp|first2=R.M.|title=The Traveling Salesman Problem and Minimum Spanning Trees|journal=Operations Research|date=1970|volume=18|issue=6|pages=1138–1162|doi=10.1287/opre.18.6.1138 }}&lt;/ref&gt; gave a polynomial-time algorithm that provides numerical lower bounds for &lt;math&gt;L^*_n&lt;/math&gt;, and thus for &lt;math&gt;\beta(\simeq L^*_n/{\sqrt n})&lt;/math&gt; which seem to be good up to more or less 1%.&lt;ref&gt;{{cite journal|last1=Goemans|first1=M.|last2=Bertsimas|first2=D.|title=Probabilistic analysis of the Held and Karp lower bound for the Euclidean traveling salesman problem|journal=Mathematics of Operation Research|date=1991|volume=16|issue=1|pages=72–89|doi=10.1287/moor.16.1.72}}&lt;/ref&gt; In particular, David S. Johnson&lt;ref&gt;[http://www.research.att.com/~dsj/papers/HKsoda.pdf David S. Johnson]&lt;/ref&gt; obtained a lower bound by computer experiment:

::&lt;math&gt;L^*_n\gtrsim 0.7080\sqrt{n}+0.522,&lt;/math&gt;

where 0.522 comes from the points near square boundary which have fewer neighbours,
and Christine L. Valenzuela and Antonia J. Jones &lt;ref&gt;[http://users.cs.cf.ac.uk/Antonia.J.Jones/Papers/EJORHeldKarp/HeldKarp.pdf Christine L. Valenzuela and Antonia J. Jones] {{webarchive|url=https://web.archive.org/web/20071025205411/http://users.cs.cf.ac.uk/Antonia.J.Jones/Papers/EJORHeldKarp/HeldKarp.pdf |date=25 October 2007 }}&lt;/ref&gt; obtained the following other numerical lower bound:
::&lt;math&gt;L^*_n\gtrsim 0.7078\sqrt{n}+0.551&lt;/math&gt;.

==Computational complexity==
The problem has been shown to be [[NP-hard]] (more precisely, it is complete for the [[complexity class]] FP&lt;sup&gt;NP&lt;/sup&gt;; see [[function problem]]), and the [[decision problem]] version ("given the costs and a number ''x'', decide whether there is a round-trip route cheaper than ''x''") is [[NP-complete]]. The [[bottleneck traveling salesman problem]] is also NP-hard. The problem remains NP-hard even for the case when the cities are in the plane with [[Euclidean distance]]s, as well as in a number of other restrictive cases. Removing the condition of visiting each city "only once" does not remove the NP-hardness, since it is easily seen that in the planar case there is an optimal tour that visits each city only once (otherwise, by the [[triangle inequality]], a shortcut that skips a repeated visit would not increase the tour length).

===Complexity of approximation===

In the general case, finding a shortest travelling salesman tour is [[Optimization problem#NP optimization problem|NPO]]-complete.&lt;ref&gt;{{harvtxt|Orponen|1987}}&lt;/ref&gt;  If the distance measure is a [[metric (mathematics)|metric]] (and thus symmetric), the problem becomes [[APX]]-complete&lt;ref&gt;{{harvtxt|Papadimitriou|1983}}&lt;/ref&gt; and [[Christofides algorithm|Christofides’s algorithm]] approximates it within 1.5.&lt;ref&gt;{{harvtxt|Christofides|1976}}&lt;/ref&gt;
The best known inapproximability bound is 123/122 .&lt;ref name="KLS2015"&gt;{{harvtxt|Karpinski|Lampis|Schmied|2015}}&lt;/ref&gt;

If the distances are restricted to 1 and 2 (but still are a metric) the approximation ratio becomes 8/7.{{sfnp|Berman|Karpinski|2006}} In the asymmetric case with [[triangle inequality]], only logarithmic performance guarantees are known, the best current algorithm achieves performance ratio 0.814 log(''n'');&lt;ref&gt;{{harvtxt|Kaplan|2004}}&lt;/ref&gt; it is an open question if a constant factor approximation exists.
The best known inapproximability bound is 75/74 .&lt;ref name="KLS2015" /&gt;

The corresponding maximization problem of finding the ''longest'' travelling salesman tour is approximable within 63/38.&lt;ref&gt;{{harvtxt|Kosaraju|1994}}&lt;/ref&gt; If the distance function is symmetric, the longest tour can be approximated within 4/3 by a deterministic algorithm&lt;ref&gt;{{harvtxt|Serdyukov|1984}}&lt;/ref&gt; and within &lt;math&gt;\tfrac{1}{25}(33+\varepsilon)&lt;/math&gt; by a randomized algorithm.&lt;ref&gt;{{harvtxt|Hassin|2000}}&lt;/ref&gt;

==Human performance on TSP==
The TSP, in particular the [[Euclidean distance|Euclidean]] variant of the problem, has attracted the attention of researchers in [[cognitive psychology]]. It has been observed that humans are able to produce near-optimal solutions quickly, in a close-to-linear fashion, with performance that ranges from 1% less efficient for graphs with 10-20 nodes, and 11% more efficient for graphs with 120 nodes.&lt;ref&gt;{{citation|title=Human performance on the traveling salesman problem|first1=J. N.|last1=Macgregor|first2=T.|last2=Ormerod|journal=Perception &amp; Psychophysics|date=June 1996|volume=58|issue=4|pages=527–539|doi=10.3758/BF03213088}}.&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Dry|first=Matthew|last2=Lee|first2=Michael D.|last3=Vickers|first3=Douglas|last4=Hughes|first4=Peter|date=2006|title=Human Performance on Visually Presented Traveling Salesperson Problems with Varying Numbers of Nodes|url=https://docs.lib.purdue.edu/jps/vol1/iss1/4|journal=The Journal of Problem Solving|language=en|volume=1|issue=1|doi=10.7771/1932-6246.1004|issn=1932-6246}}&lt;/ref&gt; The apparent ease with which humans accurately generate near-optimal solutions to the problem has led researchers to hypothesize that humans use one or more heuristics, with the two most popular theories arguably being the convex-hull hypothesis and the crossing-avoidance heuristic.&lt;ref&gt;{{Cite journal|last=Rooij|first=Iris Van|last2=Stege|first2=Ulrike|last3=Schactman|first3=Alissa|date=2003-03-01|title=Convex hull and tour crossings in the Euclidean traveling salesperson problem: Implications for human performance studies|journal=Memory &amp; Cognition|language=en|volume=31|issue=2|pages=215–220|doi=10.3758/bf03194380|issn=0090-502X|citeseerx=10.1.1.12.6117}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=MacGregor|first=James N.|last2=Chu|first2=Yun|date=2011|title=Human Performance on the Traveling Salesman and Related Problems: A Review|url=https://docs.lib.purdue.edu/jps/vol3/iss2/2|journal=The Journal of Problem Solving|language=en|volume=3|issue=2|doi=10.7771/1932-6246.1090|issn=1932-6246}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=MacGregor|first=James N.|last2=Chronicle|first2=Edward P.|last3=Ormerod|first3=Thomas C.|date=2004-03-01|title=Convex hull or crossing avoidance? Solution heuristics in the traveling salesperson problem|journal=Memory &amp; Cognition|language=en|volume=32|issue=2|pages=260–270|doi=10.3758/bf03196857|issn=0090-502X}}&lt;/ref&gt; However, additional evidence suggests that human performance is quite varied, and individual differences as well as graph geometry appear to impact performance in the task.&lt;ref&gt;{{Cite journal|last=Vickers|first=Douglas|last2=Mayo|first2=Therese|last3=Heitmann|first3=Megan|last4=Lee|first4=Michael D|last5=Hughes|first5=Peter|title=Intelligence and individual differences in performance on three types of visually presented optimisation problems|url=http://linkinghub.elsevier.com/retrieve/pii/S0191886903002009|journal=Personality and Individual Differences|volume=36|issue=5|pages=1059–1071|doi=10.1016/s0191-8869(03)00200-9|year=2004}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kyritsis|first=Markos|last2=Gulliver|first2=Stephen R.|last3=Feredoes|first3=Eva|date=2017-06-12|title=Acknowledging crossing-avoidance heuristic violations when solving the Euclidean travelling salesperson problem|journal=Psychological Research|volume=82|issue=5|language=en|pages=1–13|doi=10.1007/s00426-017-0881-7|pmid=28608230|issn=0340-0727}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kyritsis|first=Markos|last2=Blathras|first2=George|last3=Gulliver|first3=Stephen|last4=Varela|first4=Vasiliki-Alexia|title=Sense of direction and conscientiousness as predictors of performance in the Euclidean travelling salesman problem|url=http://linkinghub.elsevier.com/retrieve/pii/S2405844017306072|journal=Heliyon|volume=3|issue=11|pages=e00461|doi=10.1016/j.heliyon.2017.e00461|pmid=29264418|pmc=5727545|date=2017-01-11}}&lt;/ref&gt; Nevertheless, results suggest that computer performance on the TSP may be improved by understanding and emulating the methods used by humans for these problems, and have also led to new insights into the mechanisms of human thought.&lt;ref name="hptsp"&gt;{{citation|title=Human performance on the traveling salesman and related problems: A review|first1=James N.|last1=MacGregor|first2=Yun|last2=Chu|journal=Journal of Problem Solving|volume=3|issue=2|year=2011|url=https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1090&amp;context=jps|doi=10.7771/1932-6246.1090}}.&lt;/ref&gt; The first issue of the ''Journal of Problem Solving'' was devoted to the topic of human performance on TSP,&lt;ref&gt;[https://docs.lib.purdue.edu/jps/vol1/iss1/ ''Journal of Problem Solving'' 1(1)], 2006, retrieved 2014-06-06.&lt;/ref&gt; and a 2011 review listed dozens of papers on the subject.&lt;ref name="hptsp"/&gt;

==Natural computation==

When presented with a spatial configuration of food sources, the [[Amoeba|amoeboid]] [[Physarum polycephalum]] adapts its morphology to create an efficient path between the food sources which can also be viewed as an approximate solution to TSP.&lt;ref&gt;{{citation|title=Computation of the travelling salesman problem by a shrinking blob|first1=Jeff|last1=Jones|first2=Andrew|last2=Adamatzky|journal=Natural Computing|date=2014|pages=2, 13|url=http://www.phychip.eu/wp-content/uploads/2013/03/Computation-of-the-travelling-salesman-problem-by-a-shrinking-blob.pdf}}&lt;/ref&gt; It's considered to present interesting possibilities and it has been studied in the area of [[natural computing]].

==Benchmarks==
For benchmarking of TSP algorithms, [http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/ '''TSPLIB'''] is a library of sample instances of the TSP and related problems is maintained, see the TSPLIB external reference. Many of them are lists of actual cities and layouts of actual [[Printed circuit board|printed circuits]].

== Popular culture ==
* ''[[Travelling Salesman (2012 film)|Travelling Salesman]]'', by director Timothy Lanzone, is the story of four mathematicians hired by the U.S. government to solve the most elusive problem in computer-science history: [[P vs. NP]].&lt;ref&gt;{{Cite journal|last=Geere|first=Duncan|title='Travelling Salesman' movie considers the repercussions if P equals NP|journal=Wired UK|url=https://www.wired.co.uk/news/archive/2012-04/26/travelling-salesman|accessdate=26 April 2012|date=2012-04-26}}&lt;/ref&gt;

==See also==

* [[Canadian traveller problem]]
* [[Exact algorithm]]
* [[Route inspection problem]] (also known as "Chinese postman problem")
* [[Set TSP problem]]
* [[Seven Bridges of Königsberg]]
* [[Steiner travelling salesman problem]]
* [[Subway Challenge]]
* [[Tube Challenge]]
* [[Vehicle routing problem]]
* [[Graph traversal#Graph exploration|Graph exploration]]

==Notes==

{{Reflist|30em}}

==References==

{{refbegin|2}}
*{{Citation
| last1 = Applegate
| first1 = D. L.
| last2 = Bixby
| first2 = R. M.
| last3 = Chvátal
| first3 = V.
| last4 = Cook|author4-link=William J. Cook
| year = 2006
| title = The Traveling Salesman Problem|first4 =W. J.
| isbn = 978-0-691-12993-8}}.
*{{Citation
| last1 = Allender
| first1 = Eric
| last2 = Bürgisser
| first2 = Peter
| last3 = Kjeldgaard-Pedersen
| first3 = Johan
| last4 = Mitersen
| first4 = Peter Bro
| year = 2007
| title = On the Complexity of Numerical Analysis
| url = http://www-math.uni-paderborn.de/agpb//work/submitted.july.pdf
| journal = [[SIAM J. Comput.]]
| volume=38
| issue=5
| pages = 1987–2006
| doi=10.1137/070697926
| citeseerx = 10.1.1.167.5495
}}.
*{{Citation
 | last = Arora | first = Sanjeev | author-link = Sanjeev Arora
 | doi = 10.1145/290179.290180
 | issue = 5
 | journal = [[Journal of the ACM]]
 | mr = 1668147
 | pages = 753–782
 | title = Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems
 | volume = 45
 | year = 1998| citeseerx = 10.1.1.23.6765 }}.
*{{Citation 
|last1= Beardwood
|first1=J.
|last2=Halton 
|first2=J.H. 
|last3=Hammersley
|first3=J.M.
|title=The Shortest Path Through Many Points
|journal= Proceedings of the Cambridge Philosophical Society
|volume =55
|issue=4
|pages= 299–327
|year= 1959
|doi=10.1017/s0305004100034095|bibcode=1959PCPS...55..299B
}}.
*{{Citation
|last= Bellman
|first= R.
|contribution= Combinatorial Processes and Dynamic Programming
|title=  Combinatorial Analysis, Proceedings of Symposia in Applied Mathematics 10
|editor1= Bellman, R. |editor2=Hall, M. Jr. 
|pages= 217–249
|publisher= American Mathematical Society
|year=1960 }}.
*{{Citation
|last= Bellman
|first= R.
|title= Dynamic Programming Treatment of the Travelling Salesman Problem
|journal= J. Assoc. Comput. Mach. |volume=9|pages= 61–63 |year=1962|doi=10.1145/321105.321111}}.
*{{citation
 | last1 = Berman | first1 = Piotr
 | last2 = Karpinski | first2 = Marek | author2-link = Marek Karpinski
 | contribution = 8/7-approximation algorithm for (1,2)-TSP
 | doi = 10.1145/1109557.1109627
 | id = {{ECCC|2005|05|069}}
 | pages = 641–648
 | title = Proc. 17th ACM-SIAM Symposium on Discrete Algorithms (SODA '06)
 | year = 2006
 | isbn = 978-0898716054| url = http://eccc.hpi-web.de/report/2005/069/revision/2/download/| citeseerx = 10.1.1.430.2224
 }}.
*{{Citation
|last=Christofides|first=N.|year= 1976
|title=Worst-case analysis of a new heuristic for the travelling salesman problem
|series=Technical Report 388|publisher=Graduate School of Industrial Administration, Carnegie-Mellon University, Pittsburgh}}.
*{{Citation|last1=Hassin|first1= R.|last2= Rubinstein|first2= S.|year=2000
|title=Better approximations for max TSP
|journal=Information Processing Letters|volume=75|pages=181–186|doi=10.1016/S0020-0190(00)00097-1|issue=4|citeseerx= 10.1.1.35.7209}}.
*{{Citation
| last1 = Held
| first1 = M.
| author1-link = Michael Held
| last2 = Karp
| first2 = R. M.
| author2-link = Richard Karp
| year = 1962
| title = A Dynamic Programming Approach to Sequencing Problems
| journal = Journal of the Society for Industrial and Applied Mathematics
| volume = 10
| issue = 1
| pages = 196–210
| doi = 10.1137/0110015}}.
*{{Citation |last1= Kaplan|first1=H.|last2=Lewenstein |first2=L. | last3=Shafrir|first3=N. |last4= Sviridenko|first4=M.|contribution= Approximation Algorithms for Asymmetric TSP by Decomposing Directed Regular Multigraphs
|title= In Proc. 44th IEEE Symp. on Foundations of Comput. Sci |pages= 56–65|year= 2004}}.
*{{Citation
|last1=Karpinski|first1=M.
|last2=Lampis|first2=M.
|last3=Schmied|first3=R.
|journal=Journal of Computer and System Sciences
|volume=81
|issue=8
|year=2015
|title=New Inapproximability bounds for TSP
|pages=1665–1677
|doi=10.1016/j.jcss.2015.06.003
|arxiv=1303.6437
}}
*{{Citation
|last1= Kosaraju|first1= S. R.|last2= Park|first2=J. K.
|last3= Stein|first3= C. |year=1994
|contribution=Long tours and short superstrings'
|title=Proc. 35th Ann. IEEE Symp. on Foundations of Comput. Sci
|publisher= IEEE Computer Society|pages= 166–177}}.
*{{Citation
|last1= Orponen|first1= P. | last2=Mannila |first2= H. | author2-link = Heikki Mannila
|year=1987
|title=On approximation preserving reductions: Complete problems and robust measures'
|journal= Technical Report C-1987–28, Department of Computer Science, University of Helsinki}}.
*{{Citation
| last1 = Larson
| first1 = Richard C.
| last2 = Odoni
| first2 = Amedeo R.
| year = 1981
| title = Urban Operations Research
| chapterurl = http://web.mit.edu/urban_or_book/www/book/chapter6/6.4.7.html
| chapter=6.4.7: Applications of Network Models § Routing Problems §§ Euclidean TSP
| publisher = Prentice-Hall
| isbn = 9780139394478
| oclc = 6331426
}}.
*{{Citation
|last1=Padberg|first1=M.|last2=Rinaldi|first2=G.
|title=A Branch-and-Cut Algorithm for the Resolution of Large-Scale Symmetric Traveling Salesman Problems
|journal = SIAM Review
|volume=33|year = 1991
|pages = 60–100
|doi = 10.1137/1033004|citeseerx=10.1.1.467.1903}}.
*{{citation
 | last = Papadimitriou | first = Christos H. | author-link = Christos Papadimitriou
 | issue = 3
 | journal = Theoretical Computer Science
 | mr = 0455550
 | pages = 237–244
 | title = The Euclidean traveling salesman problem is NP-complete
 | volume = 4
 | year = 1977
 | doi = 10.1016/0304-3975(77)90012-3}}.
*{{Citation
|last1=Papadimitriou|first1=C. H.|last2= Yannakakis|first2= M.
|year=1993
|title=The traveling salesman problem with distances one and two
|journal= Math. Oper. Res.|volume= 18|pages= 1–11
|doi=10.1287/moor.18.1.1}}.
*{{Citation
|last=Serdyukov|first= A. I.|year= 1984
|title=An algorithm with an estimate for the traveling salesman problem of the maximum'
|journal=Upravlyaemye Sistemy |volume= 25|pages= 80–86}}.
*{{citation
 | last = Steinerberger | first = Stefan 
 | journal = Advances in Applied Probability
 | title = New Bounds for the Traveling Salesman Constant
 | year = 2015
 | volume = 47
}}.
*{{Citation
| authorlink = Gerhard J. Woeginger |last= Woeginger|first= G.J.|contribution= Exact Algorithms for NP-Hard Problems: A Survey
|title=Combinatorial Optimization – Eureka, You Shrink! Lecture notes in computer science, vol. 2570
|pages= 185–207|publisher= Springer |year=2003 }}.
{{refend}}

==Further reading==
*{{citation|first=Leonard|last=Adleman|authorlink=Leonard Adleman|url=http://www.usc.edu/dept/molecular-science/papers/fp-sci94.pdf|title=Molecular Computation of Solutions To Combinatorial Problems|year=1994|bibcode=1994Sci...266.1021A|volume=266|pages=1021–4|journal=Science|doi=10.1126/science.7973651|pmid=7973651|issue=5187|deadurl=yes|archiveurl=https://web.archive.org/web/20050206144827/http://www.usc.edu/dept/molecular-science/papers/fp-sci94.pdf|archivedate=6 February 2005|df=dmy-all|citeseerx=10.1.1.54.2565}}
*{{citation|first=S.|last=Arora|authorlink=Sanjeev Arora|url=http://graphics.stanford.edu/courses/cs468-06-winter/Papers/arora-tsp.pdf|title=Polynomial time approximation schemes for Euclidean traveling salesman and other geometric problems|journal=Journal of the ACM|volume=45|year=1998|pages=753–782|issue=5|doi=10.1145/290179.290180|citeseerx=10.1.1.23.6765}}.
*{{citation|first1=Gilbert|last1=Babin|first2=Stéphanie|last2=Deneault|first3=Gilbert|last3=Laportey|year=2005|title=Improvements to the Or-opt Heuristic for the Symmetric Traveling Salesman Problem|series=Cahiers du GERAD|volume=G-2005-02|publisher=Group for Research in Decision Analysis|location=Montreal|citeseerx=10.1.1.89.9953}}.
*{{citation|first1=William|last1=Cook|authorlink=William J. Cook|title=In Pursuit of the Traveling Salesman: Mathematics at the Limits of Computation| year = 2011 |
publisher = Princeton University Press | isbn = 978-0-691-15270-7}}.
*{{citation|first1=William|last1=Cook|author1-link=William J. Cook|first2=Daniel|last2=Espinoza|first3=Marcos|last3=Goycoolea|title=Computing with domino-parity inequalities for the TSP|journal=INFORMS Journal on Computing|volume=19|issue=3|year=2007|pages=356–365|doi=10.1287/ijoc.1060.0204}}.
*{{citation|first1=T. H.|last1=Cormen|author1-link=Thomas H. Cormen|first2=C. E.|last2=Leiserson|author2-link=Charles E. Leiserson|first3=R. L.|last3=Rivest|author3-link=Ronald L. Rivest|first4=C.|last4=Stein|author4-link=Clifford Stein|year=2001|title=Introduction to Algorithms|edition=2nd|publisher=MIT Press and McGraw-Hill|isbn=978-0-262-03293-3|contribution=35.2: The traveling-salesman problem|pages=1027–1033|title-link=Introduction to Algorithms}}.
*{{citation|first1=G. B.|last1=Dantzig|author1-link=George Dantzig|first2=R.|last2=Fulkerson|first3=S. M.|last3=Johnson|author3-link=Selmer M. Johnson|author2-link=D. R. Fulkerson|title=Solution of a large-scale traveling salesman problem|journal=Operations Research|volume=2|year=1954|pages=393–410|doi=10.1287/opre.2.4.393|jstor=166695|issue=4|citeseerx=10.1.1.134.9319}}.
*{{citation|first1=M. R.|last1=Garey|author1-link=Michael R. Garey|first2=D. S.|last2=Johnson|author2-link=David S. Johnson | year = 1979 | title = Computers and Intractability: A Guide to the Theory of NP-Completeness | publisher = W.H. Freeman | isbn = 978-0-7167-1045-5|contribution=A2.3: ND22–24|pages=211–212}}.
*{{citation|first=D. E.|last=Goldberg|title=Genetic Algorithms in Search, Optimization &amp; Machine Learning|publisher=Addison-Wesley|location=New York|year=1989|isbn=978-0-201-15767-3|bibcode=1989gaso.book.....G|journal=Reading: Addison-Wesley}}.
*{{citation|first1=G.|last1=Gutin|first2=A.|last2=Yeo|first3=A.|last3=Zverovich|title=Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP|journal=Discrete Applied Mathematics|volume=117|year=2002|pages=81–86|issue=1–3|doi=10.1016/S0166-218X(01)00195-0}}.
*{{citation|first1 = G.|last1=Gutin|first2=A. P.|last2=Punnen | title = The Traveling Salesman Problem and Its Variations | year = 2006 | publisher = Springer | isbn = 978-0-387-44459-8}}.
*{{citation|first1=D. S.|last1=Johnson|author1-link=David S. Johnson|first2=L. A.|last2=McGeoch|contribution=The Traveling Salesman Problem: A Case Study in Local Optimization|title=Local Search in Combinatorial Optimisation|editor1-first=E. H. L.|editor1-last=Aarts|editor2-first=J. K.|editor2-last=Lenstra|editor2-link=Jan Karel Lenstra|publisher=John Wiley and Sons Ltd.|year=1997|pages=215–310|url=https://www.cs.ubc.ca/~hutter/previous-earg/EmpAlgReadingGroup/TSP-JohMcg97.pdf}}.
*{{citation|first1 = E. L.|last1=Lawler|author1-link=Eugene Lawler|first2=J. K.|last2=Lenstra|author2-link=Jan Karel Lenstra|first3=A. H. G.|last3=Rinnooy Kan|first4=D. B.|last4=Shmoys | title = The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization | year = 1985 | publisher = John Wiley &amp; Sons | isbn = 978-0-471-90413-7}}.
*{{citation|first1=J. N.|last1=MacGregor|first2=T.|last2=Ormerod|year=1996|title=Human performance on the traveling salesman problem|journal=Perception &amp; Psychophysics|volume=58|issue=4|pages=527–539|url=http://www.psych.lancs.ac.uk/people/uploads/TomOrmerod20030716T112601.pdf|doi=10.3758/BF03213088|deadurl=yes|archiveurl=https://web.archive.org/web/20091229053516/http://www.psych.lancs.ac.uk/people/uploads/TomOrmerod20030716T112601.pdf|archivedate=29 December 2009|df=dmy-all}}.
*{{citation|first=J. S. B.|last=Mitchell|authorlink=Joseph S. B. Mitchell|year=1999|url=http://citeseer.ist.psu.edu/622594.html|title=Guillotine subdivisions approximate polygonal subdivisions: A simple polynomial-time approximation scheme for geometric TSP, ''k''-MST, and related problems|journal=SIAM Journal on Computing|volume=28 |pages=1298–1309 |doi=10.1137/S0097539796309764|issue=4}}.
*{{citation|first1=S.|last1=Rao |first2=W. |last2=Smith|contribution=Approximating geometrical graphs via 'spanners' and 'banyans' |title=Proc. 30th Annual ACM Symposium on Theory of Computing |year=1998 |pages=540–550|title-link=Symposium on Theory of Computing }}.
*{{citation |first1=Daniel J. |last1=Rosenkrantz |first2=Richard E. |last2=Stearns |first3=Philip M., II |last3= Lewis |title=An Analysis of Several Heuristics for the Traveling Salesman Problem |journal=SIAM Journal on Computing |volume=6 |issue=5 |pages = 563–581 |year=1977 |doi=10.1137/0206041}}.
*{{citation |first1=D. |last1=Vickers |first2= M. |last2= Butavicius |first3= M. |last3= Lee|first4=A.|last4= Medvedev |year=2001 |title= Human performance on visually presented traveling salesman problems|journal= Psychological Research|volume=65 |pages=34–45 |doi=10.1007/s004260000031|pmid=11505612 |issue=1}}.
*{{citation |first1=Chris |last1=Walshaw |title=A Multilevel Approach to the Travelling Salesman Problem|publisher=CMS Press |year=2000}}.
*{{citation |first1=Chris |last1=Walshaw |title=A Multilevel Lin-Kernighan-Helsgaun Algorithm for the Travelling Salesman Problem |publisher=CMS Press |year=2001}}.

==External links==
{{Commons category|Traveling salesman problem}}
* {{webarchive |url=https://web.archive.org/web/20131217224319/http://www.math.uwaterloo.ca/tsp/index.html |date=* |title=Traveling Salesman Problem}} at [[University of Waterloo]]
* [http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/ TSPLIB] at the [[University of Heidelberg]]
* ''[http://demonstrations.wolfram.com/TravelingSalesmanProblem/ Traveling Salesman Problem]'' by Jon McLoone at the Wolfram Demonstrations Project

{{DEFAULTSORT:Travelling Salesman Problem}}
[[Category:Travelling salesman problem| ]]
[[Category:NP-complete problems]]
[[Category:NP-hard problems]]
[[Category:Combinatorial optimization]]
[[Category:Graph algorithms]]
[[Category:Computational problems in graph theory]]
[[Category:Hamiltonian paths and cycles]]</text>
      <sha1>2z7xi4yaagdmhxsabp62waf2awrcyyw</sha1>
    </revision>
  </page>
  <page>
    <title>Unitary method</title>
    <ns>0</ns>
    <id>18796818</id>
    <revision>
      <id>866677584</id>
      <parentid>865089501</parentid>
      <timestamp>2018-10-31T20:50:53Z</timestamp>
      <contributor>
        <username>Erik.Bjareholt</username>
        <id>15032281</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1951">

The '''unitary method''' is an [[Algebra|algebraic]] technique for solving a problem by first finding the value of a single unit, i.e., 1, (by dividing) and then finding the necessary value by multiplying the single unit value. In essence, the '''unitary method''' is used to find the value of a unit from the value of a multiple, and hence the value of a multiple. With the unitary method, it is not always necessary to find the value of single unit; let us study it with the help of examples below.

==Examples==

For example, to solve the problem: "A man walks 7 miles in 2 hours. How far does he walk in 7 hours?", one would first [[calculate]] how far the man walks in 1 hour. One can safely assume that he would walk half the distance in half the time. Therefore, dividing by 2, the man walks 3.5 miles in 1 hour. Multiplying by 7 for 7 hours, the man walks 7x3.5=24.5 miles, or let us consider the distance travelled by the man be X, then divide it given distance that is 7 (x/7). It is equal to the time taken to travel X distance that is 7 hours divided by the time taken to travel 7 miles, that is 2 hours (7/2), therefore x/7=7/2, hence X=24.5 miles.

The same method can be applied to the problem: "A man walks at 4 miles per hour. How long would it take him to cover 5 miles?". Dividing by 4 shows that the man covers 1 mile in a quarter (0.25) of an hour. Multiplying by 5 shows that the man therefore takes 1 hour and a quarter (1.25 hours) to cover 5 miles. Similarly, by the second method, we can find the value of time taken to cover 5 miles.
The 1st method is more preferable and easier.

==References==
{{Reflist}}

==External links==
* http://www.math-only-math.com/unitary-method.html
* http://thesaurus.maths.org/mmkb/entry.html?action=entryById&amp;id=4175{{dead link|date=July 2016 |bot=InternetArchiveBot |fix-attempted=yes }}
* http://tutorteddy.com/the_unitary_method.php

[[Category:Elementary algebra]]
[[Category:Algebra]]</text>
      <sha1>ag1kumf991unhewcbv81wj2oelz0eeb</sha1>
    </revision>
  </page>
  <page>
    <title>Wild problem</title>
    <ns>0</ns>
    <id>49690041</id>
    <revision>
      <id>797800893</id>
      <parentid>793889582</parentid>
      <timestamp>2017-08-29T07:29:28Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>/* top */Removed invisible unicode characters + other fixes ([[User:Yobot/55|Task 55]]), replaced: → using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1506">A mathematical problem is '''wild''' if it contains the problem of classifying pairs of [[Square matrix|square matrices]] up to simultaneous [[matrix similarity|similarity]].&lt;ref&gt;Genrich R. Belitskii, Vladimir V. Sergeichuk, Complexity of matrix problems [[arxiv:0709.2488|http://arxiv.org/abs/0709.2488]]
&lt;/ref&gt; Examples of wild problems are classifying indecomposable representations of any [[quiver (mathematics)|quiver]] that is neither a Dynkin quiver (i.e. the underlying undirected graph of the quiver is a (finite) [[Dynkin diagram]]) nor a Euclidean quiver (i.e. the underlying undirected graph of the quiver is an [[Affine Dynkin diagram]]).

Necessary and sufficient conditions have been proposed to check the simultaneously [[Block matrix#Block diagonal matrices|block triangularization and diagonalization]] of a finite set of matrices under the assumption that each matrix is [[wikipedia:Diagonalizable matrix|diagonalizable]] over the field of the complex numbers.&lt;ref&gt;{{Cite journal|last=Mesbahi|first=Afshin|last2=Haeri|first2=Mohammad|date=January 2015|title=Conditions on Decomposing Linear Systems With More Than One Matrix to Block Triangular or Diagonal Form|url=http://ieeexplore.ieee.org/document/6819395/|journal=IEEE Transactions on Automatic Control|volume=60|issue=1|pages=233–239|doi=10.1109/tac.2014.2326292|issn=0018-9286|via=}}&lt;/ref&gt;

== References  ==

&lt;references /&gt;

[[Category:Linear algebra]]
[[Category:Algebra]]
[[Category:Representation theory]]


{{Algebra-stub}}</text>
      <sha1>ge4sv0v0nst8hnuw7atkk0ejffb6efc</sha1>
    </revision>
  </page>
</mediawiki>
