<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>13 (number)</title>
    <ns>0</ns>
    <id>37231</id>
    <revision>
      <id>870436971</id>
      <parentid>870436839</parentid>
      <timestamp>2018-11-24T20:16:15Z</timestamp>
      <contributor>
        <username>Aamri2</username>
        <id>26461452</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Kurs Mark|Kurs Mark]] ([[User talk:Kurs Mark|talk]]): Irrelevant detail. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23624">{{Other uses|13 (disambiguation)}}
{{More citations needed|date = December 2008}}
{{Use mdy dates|date = February 2012}}

{{Infobox number
|number = 13
|numeral = [[Base 13|tredecimal]]
|factorization = [[Prime number|prime]]
|prime = 6th
|divisor = 1, 13
}}

'''13''' ('''thirteen''') is the [[natural number]] following [[12 (number)|12]] and preceding [[14 (number)|14]].

Strikingly folkloric aspects of the number 13 have been noted in various cultures around the world: one theory is that this is due to the cultures employing lunar-solar calendars (there are approximately 12.41 lunations per solar year, and hence 12 "true months" plus a smaller, and often portentous, thirteenth month). This can be witnessed, for example, in the "[[Twelve Days of Christmas]]" of Western European tradition.&lt;ref&gt;Frazier, King of the Bean, and the Festival of Fools. Cited in Thompson, Tok. 2002. [http://sms.zrc-sazu.si/En/SMS5/Thompson5.html The thirteenth number: Then, there/ here and now.] 'Studia Mythological Slavica'' '''5''', 145–159.&lt;/ref&gt;

==In mathematics==
The number 13 is:
*the sixth [[prime number]].
*the smallest [[emirp]] (a prime that is a different prime when its digits are reversed).&lt;ref name="Wells"&gt;Wells, D. ''[[The Penguin Dictionary of Curious and Interesting Numbers]]'', London: Penguin Group. (1987): 67–71.&lt;/ref&gt;
*one of only 3 known [[Wilson prime]]s.&lt;ref&gt;{{cite web|url=https://oeis.org/A007540|title=Sloane's A007540 : Wilson primes|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-06-01}}&lt;/ref&gt;
*a [[Fibonacci number]].
*a [[happy number]].&lt;ref&gt;{{cite web|url=https://oeis.org/A007770|title=Sloane's A007770 : Happy numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-06-01}}&lt;/ref&gt;
*the third [[centered square number]].&lt;ref&gt;{{cite web|url=https://oeis.org/A001844|title=Sloane's A001844 : Centered square numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-06-01}}&lt;/ref&gt;
*a [[lucky number]].&lt;ref&gt;{{cite web |title=A000959 Lucky numbers. (Formerly M2616 N1035) |url=https://oeis.org/A000959 |website=OEIS: The On-Line Encyclopedia of Integer Sequences |publisher=OEIS Foundation |accessdate=2018-10-31}}&lt;/ref&gt;
*equal to the sum of the squares of the digits of its own square in bases 4 and 83.

Since 5&lt;sup&gt;2&lt;/sup&gt; + 12&lt;sup&gt;2&lt;/sup&gt; = 13&lt;sup&gt;2&lt;/sup&gt;, (5, 12, 13) forms a [[Pythagorean triple]].

There are 13 [[Archimedean solid]]s, and a [[standard torus]] can be sliced into 13 pieces with just 3 plane cuts.&lt;ref name="Wells" /&gt; There are also 13 different ways for the three fastest horses in a [[horse race]] to finish, allowing for ties, a fact that can be expressed mathematically by 13 being the third [[ordered Bell number]].&lt;ref&gt;{{citation|title=Those Fascinating Numbers|first=J. M.|last=de Koninck|publisher=American Mathematical Society|year=2009|isbn=9780821886311|url=https://books.google.com/books?id=qYuC1WsDKq8C&amp;pg=PA4|page=4}}&lt;/ref&gt;

===List of basic calculations===
{| class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Multiplication]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
! style="width:5px;"|
!11
!12
!13
!14
!15
!16
!17
!18
!19
!20
! style="width:5px;"|
!21
!22
!23
!24
!25
! style="width:5px;"|
!50
!100
!1000
|-
|'''(13)''x'''
|'''13'''
|[[26 (number)|26]]
|[[39 (number)|39]]
|[[52 (number)|52]]
|[[65 (number)|65]]
|[[78 (number)|78]]
|[[91 (number)|91]]
|[[104 (number)|104]]
|[[117 (number)|117]]
|[[130 (number)|130]]
!
|[[143 (number)|143]]
|[[156 (number)|156]]
|[[169 (number)|169]]
|[[182 (number)|182]]
|[[195 (number)|195]]
|[[208 (number)|208]]
|[[221 (number)|221]]
|[[234 (number)|234]]
|[[247 (number)|247]]
|[[260 (number)|260]]
!
|[[273 (number)|273]]
|[[286 (number)|286]]
|[[299 (number)|299]]
|[[312 (number)|312]]
|[[325 (number)|325]]
!
|[[650 (number)|650]]
|[[1300 (number)|1300]]
|13000
|}

{|class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Division (mathematics)|Division]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
! style="width:5px;"|
!11
!12
!13
!14
!15
!16
|-
|'''13 ÷ ''x'''''
|'''13'''
|6.5
|4.{{overline|3}}
|3.25
|2.6
|2.1{{overline|6}}
|1.{{overline|857142}}
|1.625
|1.{{overline|4}}
|1.3
!
|1.{{overline|18}}
|1.08{{overline|3}}
|1
|0.9{{overline|285714}}
|0.8{{overline|6}}
|0.8125
|-
|'''''x'' ÷ 13'''''
|0.{{overline|076923}}
|0.{{overline|153846}}
|0.{{overline|230769}}
|0.{{overline|307692}}
|0.{{overline|384615}}
|0.{{overline|461538}}
|0.{{overline|538461}}
|0.{{overline|615384}}
|0.{{overline|692307}}
|0.{{overline|762930}}
!
|0.{{overline|846153}}
|0.{{overline|923076}}
|1
|1.{{overline|076923}}
|1.{{overline|153846}}
|1.{{overline|230769}}
|}

{|class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Exponentiation]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
! style="width:5px;"|
!11
!12
!13
|-
|'''13{{sup|''x''}}'''
|'''13'''
|169
|2197
|28561
|371293
|4826809
|62748517
|815730721
|10604499373
|137858491849
!
|1792160394037
|23298085122481
|302875106592253
|-
|'''''x''{{sup|13}}'''
|1
|8192
|1594323
|67108864
|1220703125
|13060694016
|96889010407
|549755813888
|2541865828329
|10000000000000
!
|34522712143931
|106993205379072
|302875106592253
|}

==In languages==

===Grammar===

* In all [[Germanic languages]], 13 is the first [[Compound (linguistics)|compound]] number; the numbers 11 and 12 have their own names.
* The [[Romance languages]] use different systems: In Italian, 11 is the first compound number (''undici''), as in Romanian (''unsprezece''), while in Spanish and Portuguese, the numbers up to and including 15 (Spanish ''quince'', Portuguese ''quinze''), and in French up to and including 16 (''seize'') have their own names. This is also the case in most [[Slavic languages]], Hindi-Urdu and other South Asian languages.{{Example needed}}

=== Folklore ===
In Germany, according to an old tradition, 13 (''dreizehn'') -as the first compound number- was the first number written in digits; the numbers 0 (''null'') through 12 (''zwölf'') were spelt out. The ''Duden'' (the German standard dictionary) now calls this tradition (which was actually never written down as an official rule) outdated and no longer valid, but many writers still follow it. {{citation needed|date=October 2017}}

==In religion==

=== Islam ===
In [[Shia Islam]], 13 signifies the 13th day of the month of [[Rajab]] (the Lunar calendar), which is the birth of Imam [[Ali]]. 13 also is a total of 1 Prophet and 12 Imams in the Islamic School of Thought. However, in [[Sunni Islam]], the number 13 bears no symbolic significance.

===Roman Catholicism===
The apparitions of the [[Virgin of Fátima]] in 1917 were claimed to occur on the 13th day of six consecutive months.&lt;ref&gt;Rosemary Guiley, ''The Guinness Encyclopedia of Ghosts and Spirits'', 1994, p. 215, {{ISBN|0-85112-748-7}}.&lt;/ref&gt;

In Catholic devotional practice, the number thirteen is also associated with Saint [[Anthony of Padua]], since his feast day falls on June 13. A traditional devotion called the Thirteen Tuesdays of St. Anthony&lt;ref&gt;{{cite web|url=http://www.shrineofstanthony.org/novena-to-st-anthony.htm|title=The Shrine of St. Anthony|website=shrineofstanthony.org}}&lt;/ref&gt; involves praying to the saint every Tuesday over a period of thirteen weeks. Another devotion, St. Anthony's Chaplet, consists of thirteen decades of three beads each.&lt;ref&gt;{{cite web|url=http://www.catholicculture.org/culture/liturgicalyear/prayers/view.cfm?id=1236|title=Liturgical Year: Prayers: Chaplet of St. Anthony|website=catholicculture.org}}&lt;/ref&gt;

===Sikhism===
According to famous [[Sakhi]] (Evidence) or story of [[Guru Nanak Dev Ji]], when he was an accountant at a town of [[Sultanpur Lodhi]], he was distributing groceries to people. When he gave groceries to the 13th person, he stopped because in [[Gurmukhi]] and Hindi the word 13 is called Terah, which means yours. And Guru Nanak Dev Ji kept saying, "Yours, yours, yours..." remembering God. People reported to the emperor that Guru Nanak Dev Ji was giving out free food to the people. When treasures were checked, there was more money than before.

The [[Vaisakhi]], which commemorates the creation of "[[Khalsa]]" or pure Sikh was celebrated on April 13 for many years.

===Judaism===
* In Judaism, 13 signifies the age at which a boy matures and becomes a [[Bar and Bat Mitzvah|Bar Mitzvah]], ''i.e.'', a full member of the Jewish faith (counts as a member of Minyan).
* The number of [[Jewish principles of faith|principles of Jewish faith]] according to [[Maimonides]].
* According to [[Rabbinic Judaism|Rabbinic]] commentary on the [[Torah]], God has 13 Attributes of Mercy.

===Zoroastrianism===
The number 13 had been considered sinister and wicked in ancient Iranian ([[Persia]]n) civilization and [[Zoroastrianism]]. Since beginning of the Nourooz tradition, the 13th day of each new Iranian year is called [[Sizdah Be-dar]], and this tradition is still alive among Iranian people both within  Iran and abroad. Since [[Sizdah Be-dar]] is the 13th day of the year, it is considered a day when evil's power might cause difficulties for people. Therefore, people leave  urban areas for one day and camp in the countryside. Even in the current post-[[1979 Revolution]] era, and despite the wishes of Islamic government, this tradition continues to be practiced by the majority of the population throughout Iran.

===Other===
* The [[Thirteen Classics]] is considered to be a part of the [[Chinese classics]].

== Lucky and unlucky ==

===Unlucky 13===
{{see|Triskaidekaphobia}}
{{Multiple image
| direction = vertical
| width = 250
| image1 = Many buttons (4187599550).jpg
| image2 = Aviadilo sen 13-a vico.jpg
| footer = This elevator's building and this airline both skip the number 13 and go directly from floor/row 12 to 14
}}
The number 13 is considered an unlucky number in some countries.&lt;ref name="about1"&gt;{{cite web|url=http://urbanlegends.about.com/cs/historical/a/friday_the_13th.htm|title=Why Is Friday the 13th Unlucky? - History and Folklore|first=David|last=Emery|work=About.com Entertainment}}&lt;/ref&gt; The end of the Mayan calendar's 13th Baktun was superstitiously feared as a harbinger of the apocalyptic [[2012 phenomenon]].&lt;ref name="USA Today"&gt;{{cite news| url=https://www.usatoday.com/tech/science/discoveries/story/2011-11-24/mexico-apocalypse-2012-mayans/51387348/1 | work=USA Today | title=Most Popular E-mail Newsletter | date=November 24, 2011}}&lt;/ref&gt; Fear of the number 13 has a specifically recognized [[phobia]], Triskaidekaphobia, a word coined in 1911. The superstitious sufferers of triskaidekaphobia try to avoid bad luck by keeping away from anything numbered or labelled thirteen. As a result, companies and manufacturers use another way of numbering or labelling to avoid the number, with hotels and tall buildings being conspicuous examples ([[thirteenth floor]]).&lt;ref name="Fleischman"&gt;{{cite news |last=Fleischman |first =Sid |title=The 13th Floor: A Ghost Story |url=https://www.washingtonpost.com/wp-dyn/content/article/2007/08/18/AR2007081800890.html |publisher=The Washington Post Company |accessdate=July 26, 2008 |date=August 19, 2007}}&lt;/ref&gt; It is also considered unlucky to have thirteen guests at a table. [[Friday the 13th]] has been considered an unlucky day.&lt;ref name="about1"/&gt;

There are a number of theories as to why the number thirteen became associated with bad luck, but none of them have been accepted as likely.&lt;ref name="about1"/&gt;
*'''The Last Supper:''' At Jesus Christ's [[last supper]], there were thirteen people around the table, counting Christ and the twelve apostles. Some believe this is unlucky because one of those thirteen, [[Judas Iscariot]], was the betrayer of Jesus Christ. From the 1890s, a number of English language sources relate the "unlucky" thirteen to an idea that at the [[Last Supper]], [[Judas Iscariot|Judas]], the [[Disciple (Christianity)|disciple]] who betrayed [[Jesus]], was the 13th to sit at the table.&lt;ref&gt;Cecil Adams (1992-11-06). [http://www.straightdope.com/columns/read/670/why-is-the-number-13-considered-unlucky "Why is the number 13 considered unlucky?"]. The Straight Dope. Retrieved 2011-05-13.&lt;/ref&gt;
*'''Knights Templar:''' On Friday 13 October 1307, King [[Philip IV of France]] ordered the arrest of the [[Knights Templar]],&lt;ref name="about1"/&gt; and most of the knights were tortured and killed.
*'''Full Moons:''' A year with 13 full moons instead of 12 posed problems for the monks in charge of the calendars. "This was considered a very unfortunate circumstance, especially by the monks who had charge of the calendar of thirteen months for that year, and it upset the regular arrangement of church festivals. For this reason thirteen came to be considered an unlucky number."&lt;ref&gt;{{cite web|url=http://www.space.com/9566-strange-story-sunday-blue-moon.html|title=The Really Strange Story Behind Sunday's Blue Moon|work=Space.com}}&lt;/ref&gt; However, a typical century has about 37 years that have 13 full moons, compared to 63 years with 12 full moons, and typically every third or fourth year has 13 full moons.&lt;ref&gt;{{cite web |last=Cooley |first=Keith |url=http://home.hiwaay.net/~krcool/Astro/moon/fullmoonU.htm|title=Full Moons 1900-2100 |date=2008 |publisher=Johns Hopkins University Applied Physics Laboratory}}&lt;/ref&gt;
*'''A Repressed Lunar Cult:''' In ancient cultures, the number 13 represented femininity, because it corresponded to the number of lunar (menstrual) cycles in a year (13 x 28 = 364 days). The theory is that, as the solar calendar triumphed over the lunar, the number thirteen became anathema.&lt;ref name="about1"/&gt;&lt;ref&gt;Stan Gooch, Guardians of the Ancient Wisdom (1980)&lt;/ref&gt;
*'''Hammurabi's Code:''' There is a myth that the earliest reference to thirteen being unlucky or evil is in the Babylonian [[Code of Hammurabi]] (circa 1780 BC), where the thirteenth law is said to be omitted. In fact, the original Code of Hammurabi has no numeration. The translation by L.W. King (1910), edited by Richard Hooker, omitted one article: If the seller have gone to (his) fate (i. e., have died), the purchaser shall recover damages in said case fivefold from the estate of the seller. Other translations of the Code of Hammurabi, for example the translation by Robert Francis Harper, include the 13th article.&lt;ref&gt;[http://oll.libertyfund.org/index.php?option=com_staticxt&amp;staticfile=show.php%3Ftitle=1276&amp;Itemid=27 English translation of the Code of Hammurabi] Online Library of Liberty.&lt;/ref&gt;

===Lucky 13===
{{see also|Lucky Thirteen (disambiguation)}}

In some countries, such as [[Italy]], 13 is considered a lucky number.&lt;ref&gt;{{cite web|title = Top 13 Italian Superstions|url = http://www.italymagazine.com/featured-story/top-13-italian-superstitions|accessdate = 2015-08-13}}&lt;/ref&gt; The expression ''fare tredici'' ("to do 13") means hit the jackpot. 17 is considered an unlucky number instead.&lt;ref&gt;{{cite web|title = Superstitious Numbers Around the World |first=Jaclyn|last=Skurie|url = http://news.nationalgeographic.com/news/2013/09/130913-friday-luck-lucky-superstition-13/|accessdate = 2017-07-16}}&lt;/ref&gt;

===Other===
[[Colgate University]] also considers 13 a lucky number. They were founded in 1819 by 13 men with 13 dollars, 13 prayers and 13 articles.&lt;ref name="history-traditions"&gt;{{cite web|url=http://www.colgate.edu/DesktopDefault1.aspx?tabid=497&amp;pgID=1200|title=Colgate: History &amp; Traditions|publisher=Colgate University|accessdate=September 1, 2007| archiveurl= https://web.archive.org/web/20070814204636/http://www.colgate.edu/DesktopDefault1.aspx?tabid=497&amp;pgID=1200| archivedate= August 14, 2007 &lt;!--Added by DASHBot--&gt;}}&lt;/ref&gt; (To this day, members of the Colgate community consider the number 13 a good omen.) In fact, the campus address is 13 Oak Drive in [[Hamilton, New York]], and the male ''a cappella'' group is called the Colgate 13.

In the Mayan [[Tzolk'in]] calendar, trecenas mark cycles of 13-day periods. The pyramids are also set up in 9 steps divided into 7 days and 6 nights, 13 days total.

In the [[standard 52-card deck]] of playing cards there are four suits, each of 13 ranks.

In a tarot card deck, XIII is the card of Death, usually picturing the Pale horse with its rider.

A [[baker's dozen]], devil's dozen, long dozen, or long measure is 13, one more than a standard dozen.

==Age 13==
*In Judaism, thirteen signifies the age at which a boy matures and becomes a [[Bar and Bat Mitzvah|Bar Mitzvah]], ''i.e.'', a full member of the Jewish faith (is qualified to be counted as a member of Minyan).
*This is the age whereby a preteen becomes an [[adolescent]] in Germanic languages, due to the suffix form beginning at this point (11 &amp; 12 are nonstandard).
*This is also the age in the US when a person can watch, rent, or buy a PG-13 film without parental guidance.
*Thirteen is the minimum [[age of consent]] in [[Argentina]], [[Burkina Faso]], [[Japan]], [[Niger]], and two [[Mexico|Mexican]] states.
*On many [[social media]] sites, thirteen is the standard minimum age to be allowed to create an account.

== History ==
*On January 1, [[49 BC]], the [[Roman senate|Roman Senate]] issued a final order for [[Julius Caesar]] to disband his army and return to [[Rome]] because his term as [[Roman governor|governor]] had finished. In response, Caesar led a single [[Roman legion|legion]], the [[Legio XIII Gemina|Thirteenth Legion]], [[Crossing the Rubicon|over the Rubicon river]] (the frontier boundary of his [[Gallic Wars#Political background|Gaulish provinces]] to centrally administered [[Roman Republic|Roman]] [[Italian Peninsula|Italy]]). This action, in igniting [[Caesar's civil war]], was a significant event in the eventual creation of the [[Roman Empire]]. 
*On October 26, [[1597]] (September 13th in the [[Korean calendar|Korean lunisolar calendar]]), [[Joseon|Korean]] [[Yi Sun-sin|Admiral Yi Sun-Sin]] defeated a 133 warship strong Japanese naval invasion force with the last 13 ships of the [[Joseon Navy|Joseon navy]], at the [[Battle of Myeongnyang]]. Being a decisive [[Joseon]] victory in the [[Myeongnyang Strait]], there were no losses of any Korean ships. Later dying in the [[Battle of Noryang|final battle]] of the [[Japanese invasions of Korea (1592–98)|Imjin War]], Admiral Yi Sun-Sin completed his 23 battle career undefeated in combat. The surprise halt of the Japanese invasion led to a lengthy stalemate and withdrawal of the [[Council of Five Elders|Japanese Armies]] from [[Korean Peninsula|Korea]], and serves as a historic foundation for [[Korean independence movement#History|Korean nationalism]]. 
*The United States of America was created from [[Thirteen Colonies|thirteen British colonies]] and as such, the number thirteen is a commonly recurring motif in [[United States heraldry|American heraldry]]. For example, there are thirteen stars on the [[Great Seal of the United States]] and there are thirteen stripes on the [[Flag of the United States|American flag]].
**The first flag of the United States bore thirteen stripes, alternating red and white, and thirteen white stars in the blue union. The thirteen stripes represented the [[Thirteen Colonies]] from which the United States was created, and the thirteen stars represented the number of states in the new nation.  When two new states were added to the Union in 1795, the flag bore fifteen stars and fifteen stripes.  With the addition of five new states in 1818, the number of stripes was re-set and permanently fixed at thirteen.
**The [[Great Seal of the United States]] bears many images of the number thirteen, representing the [[Thirteen Colonies]] from which the United States was created.  On the Seal's observe, the overhead glory bears thirteen stars.  The chest shield in front of the spread eagle bears thirteen stripes (seven white and six red).  In the eagle's right talon, it holds the Olive Branch of Peace, bearing thirteen olives and thirteen olive leaves.  In the eagle's left talon, it holds the Weapons of War, consisting of thirteen arrows.  In the eagle's mouth, it holds a scroll bearing the national motto "E Pluribus Unum" (which, by coincidence, consists of thirteen letters).  On the Seal's reverse, the unfinished pyramid consists of thirteen levels.
*[[Apollo 13]] was a NASA Moon mission famous for being a "successful failure" in 1970.

==In sports==
* The number 13 was not used in the [[Indianapolis 500]] from 1915 to 2002. It was not permitted for use between 1926-2002. In 2009, [[E.J. Viso]], driving for [[HVM Racing]] in the [[2009 IndyCar Series]] season, drove a green number 13 car full-time, despite terrible [[superstitions]] about it in motorsports.
* The number 13 was not used in [[Formula One]] from 1977 to 2013.
* In [[rugby league]]:
** Each side has 13 players on the field at any given time.
** The jersey number 13 is worn by the starting loose forward or lock forward in most competitions. An exception is in the European [[Super League]], which uses static squad numbering.
* In [[rugby union]], the jersey number 13 is worn by the [[Rugby union positions|outside centre]].
* In [[triathlon]], the number 13 is not used. As such, the numbering goes 11, 12, ''14'', 15 under the current numbering system.

==In TV, films and literature==
*[[13th (film)|13TH]], a 2016 documentary
*[[13 (musical)|''13'' (musical)]], a 2007 musical
*[[13 (2010 film)|''13'' (film)]], an English-language remake of the 2005 French film 13 Tzameti.
*[[Thirteen (2003 film)|''Thirteen'' (film)]], a 2003 American film
*[[Thirteen (TV series)|''Thirteen'' (TV series)]], a 2016 British five-part police drama
*[[Number 13 (film)|''Number 13'' (film)]], an uncompleted Hitchcock 1922 film
*''[[13 Tzameti]]'', a 2005 French film ("Tzameti" means "13" in Georgian)
*''[[13 Ghosts]]'' is a 1960 horror film.
**''[[Thirteen Ghosts]]'' a 2001 remake.
*[[Thirteen (House)|Thirteen]] is the nickname of Dr. Remy Hadley on the American medical drama ''[[House (TV series)|House]]'' played by [[Olivia Wilde]].
*''[[13 Assassins (2010 film)|13 Assassins]]'' is a 2010 film by Japanese director [[Takashi Miike]]
*''[[The Thirteen]]'' is a 1936 Soviet war film by [[Mikhail Romm]]
*''[[The 13th Warrior]]'' is a 1999 historical fiction action film starring [[Antonio Banderas]]
*''[[District 13]]'' is a 2004 French film (with [[David Belle]])
*''[[Apollo 13 (film)|Apollo 13]]'' is a 1995 American film.
*''[[Warehouse 13]]'' is a television show about the 13th warehouse in the line of warehouses that store supernatural artifacts.
*''[[Friday the 13th (franchise)|Friday the 13th]]'' is a horror film series involving a mass murderer named [[Jason Voorhees]].
*''[[Friday the 13th: The Series]]'' is a syndicated American-Canadian horror television series, that originally ran from 1987 to 1990. 
*''[[The 13 Ghosts of Scooby-Doo]]'':  Seventh incarnation of the Hanna-Barbera Scooby-Doo cartoon franchise, first run 1985-1986.
*''[[The Thirteenth Floor]]'' is a 1999 sci-fi film.
*''[[Yavarum Nalam|13B/Yaavarum Nalam]]'' is a 2009 Hindi/Tamil Horror movie starring R Madhavan
*''[[Thirteen Reasons Why]]'' is a novel containing 13 tapes received by a student learning of his classmate's suicide and death.

==See also==
* [[List of highways numbered 13]]

==References==
{{Commons category|13 (number)}}
{{Reflist|30em}}

{{Integers|zero}}
{{Superstitions}}

[[Category:Integers]]
[[Category:Numerology]]
[[Category:Triskaidekaphobia]]
[[Category:Superstitions about numbers]]</text>
      <sha1>faiuzypd8fogzx2wheh08zq4fb9q22a</sha1>
    </revision>
  </page>
  <page>
    <title>Andrew Jackson Libby</title>
    <ns>0</ns>
    <id>9196273</id>
    <revision>
      <id>734244890</id>
      <parentid>721859332</parentid>
      <timestamp>2016-08-13T00:49:14Z</timestamp>
      <contributor>
        <username>TAnthony</username>
        <id>1808194</id>
      </contributor>
      <minor/>
      <comment>The intent of a genre link in this context is to direct the reader to more information on the genre, not a list of other works. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1219">'''Andrew Jackson "[[Slide rule|Slipstick]]" Libby''' is a [[fictional character]] featured in the "[[Future History (Heinlein)|Future History]]" series of [[science fiction]] novels by [[Robert A. Heinlein]].  He is an enormously talented and intuitive mathematician, but received little formal education.  His talent was first appreciated in the short story [[Misfit (short story)|Misfit]], where he helps guide an asteroid into the correct orbit after the guidance computer has failed.&lt;ref&gt;{{cite book
  |title=The classic years of Robert A. Heinlein
  |author =Slusser, George Edgar
  |volume=11
  |year=1977
  |publisher=Wildside Press LLC
  }}
&lt;/ref&gt;&lt;ref&gt;{{cite book
  |title=The Heritage of Heinlein: A Critical Reading of the Fiction
  |author1=Clareson, Thomas D  |author2=Sanders, Joe
  |volume=42
  |year=2014
  |publisher=McFarland
  }} p. 25.&lt;/ref&gt;

In later stories he changes sex to become Elizabeth Andrew Jackson Libby.

==References==
{{reflist}}

{{DEFAULTSORT:Libby, Andrew Jackson}}
[[Category:Characters in written science fiction]]
[[Category:Fictional mathematicians]]
[[Category:Fictional transgender and transsexual characters]]
[[Category:Robert A. Heinlein characters]]


{{novel-char-stub}}</text>
      <sha1>at4xny0m1y3kxk05nutxphteqvv4acn</sha1>
    </revision>
  </page>
  <page>
    <title>Apeirogonal tiling</title>
    <ns>0</ns>
    <id>38764584</id>
    <revision>
      <id>708392960</id>
      <parentid>708085636</parentid>
      <timestamp>2016-03-05T09:25:25Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="788">In [[geometry]], an '''apeirogonal tiling''' is a [[tessellation]] of the [[Euclidean plane]], [[hyperbolic plane]], or some other two-dimensional space by [[apeirogon]]s. Tilings of this type include:
*[[Order-2 apeirogonal tiling]], Euclidean tiling of two half-spaces
*[[Order-3 apeirogonal tiling]], hyperbolic tiling with 3 apeirogons around a vertex
*[[Order-4 apeirogonal tiling]], hyperbolic tiling with 4 apeirogons around a vertex
*[[Order-5 apeirogonal tiling]], hyperbolic tiling with 5 apeirogons around a vertex
*[[Infinite-order apeirogonal tiling]], hyperbolic tiling with an infinite number of apeirogons around a vertex

==See also==
*[[Apeirogonal antiprism]]
*[[Apeirogonal prism]]
*[[Apeirohedron]]

{{set index article|mathematics}}

[[Category:Apeirogonal tilings]]</text>
      <sha1>r07l4bt9y0kqi9snd03zv6r356t3wph</sha1>
    </revision>
  </page>
  <page>
    <title>Art gallery problem</title>
    <ns>0</ns>
    <id>1448859</id>
    <revision>
      <id>868517373</id>
      <parentid>853236025</parentid>
      <timestamp>2018-11-12T18:32:11Z</timestamp>
      <contributor>
        <ip>89.221.170.50</ip>
      </contributor>
      <comment>/* Computational complexity */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19016">The '''art gallery problem''' or '''museum problem''' is a well-studied [[visibility problem]] in [[computational geometry]].  It originates from a real-world problem of guarding an [[art gallery]] with the minimum number of guards who together can observe the whole gallery.  In the geometric version of the problem, the layout of the art gallery is represented by a [[simple polygon]] and each guard is represented by a [[point (geometry)|point]] in the polygon.  A set &lt;math&gt;S&lt;/math&gt; of points is said to guard a polygon if, for every point &lt;math&gt;p&lt;/math&gt; in the polygon, there is some &lt;math&gt;q\in S&lt;/math&gt; such that the [[line segment]] between &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; does not leave the polygon.

==Two dimensions==
[[File:Art gallery problem.svg|thumb|Four cameras cover this gallery.]]
There are numerous variations of the original problem that are also referred to as the art gallery problem.  In some versions guards are restricted to the perimeter, or even to the vertices of the polygon.  Some versions require only the perimeter or a subset of the perimeter to be guarded.

Solving the version in which guards must be placed on vertices and only vertices need to be guarded is equivalent to solving the [[dominating set problem]] on the [[visibility graph]] of the polygon.

===Chvátal's art gallery theorem===
Chvátal's art gallery theorem, named after [[Václav Chvátal]], gives an [[upper bound]] on the minimal number of guards. It states that &lt;math&gt;\left\lfloor n/3 \right\rfloor&lt;/math&gt; guards are always sufficient and sometimes necessary to guard a simple polygon with &lt;math&gt;n&lt;/math&gt; vertices.

The question about how many vertices/watchmen/guards were needed was posed to Chvátal by [[Victor Klee]] in 1973.&lt;ref&gt;{{harvtxt|O'Rourke|1987}}, p.&amp;nbsp;1.&lt;/ref&gt; Chvátal proved it shortly thereafter.&lt;ref&gt;{{harvtxt|Chvátal|1975}}.&lt;/ref&gt; Chvátal's proof was later simplified by Steve Fisk,&lt;ref&gt;{{cite web|url=http://bowdoinorient.com/article/4980|title=Mathematics professor dies of leukemia at 63|last=Leghorn|first=Gemma|publisher=The Bowdoin Orient|year=2010}}&lt;/ref&gt; via a [[graph coloring|3-coloring]] argument.&lt;ref&gt;{{harvtxt|Fisk|1978}}.&lt;/ref&gt;

=== Fisk's short proof ===
[[File:Triangulation 3-coloring.svg|thumb|A 3-coloring of the vertices of a triangulated polygon. The blue vertices form a set of three guards, as few as is guaranteed by the art gallery theorem. However, this set is not optimal: the same polygon can be guarded by only two guards.]]
Steve Fisk's proof {{sfn|Fisk|1978}} is so short and elegant that it was chosen for inclusion in ''[[Proofs from THE BOOK]]''.
The proof goes as follows:

First, the polygon is [[Polygon triangulation|triangulated]] (without adding extra vertices). It is known that the vertices of the resulting triangulation graph may be [[Graph coloring|3-colored]].&lt;ref&gt; To prove 3-colorability of polygon triangulations, we observe that the weak [[dual graph]] to the triangulation (the [[undirected graph]] having one vertex per triangle and one edge per pair of adjacent triangles) is a [[Tree (graph theory)|tree]], since any cycle in the dual graph would form the boundary of a hole in the polygon, contrary to the assumption that it has no holes. Whenever there is more than one triangle, the dual graph (like any tree) must have a vertex with only one neighbor, corresponding to a triangle that is adjacent to other triangles along only one of its sides. The smaller polygon formed by removing this triangle has a 3-coloring by [[mathematical induction]], and this coloring is easily extended to the one additional vertex of the removed triangle.{{cn|date=May 2017}}&lt;/ref&gt; Clearly, under a 3-coloring, every triangle must have all three colors. The vertices with any one color form a valid guard set, because every triangle of the polygon is guarded by its vertex with that color. Since the three colors partition the ''n'' vertices of the polygon, the color with the fewest vertices defines a valid guard set with at most &lt;math&gt;\lfloor n/3\rfloor&lt;/math&gt; guards.

===Generalizations===
Chvátal's upper bound remains valid if the restriction to guards at corners is loosened to guards at any point not exterior to the polygon.

There are a number of other generalizations and specializations of the original art-gallery theorem.&lt;ref&gt;{{harvtxt|Shermer|1992}}.&lt;/ref&gt;  For instance, for [[orthogonal polygons]], those whose edges/walls meet at right angles, only &lt;math&gt;\lfloor n/4 \rfloor&lt;/math&gt; guards are needed. There are at least three distinct proofs of this result, none of them simple: by Kahn, [[Maria Klawe|Klawe]], and [[Daniel Kleitman|Kleitman]]; by [[Anna Lubiw|Lubiw]]; and by [[Jörg-Rüdiger Sack|Sack]] and [[Godfried Toussaint|Toussaint]].&lt;ref&gt;{{harvtxt|O'Rourke|1987}}, pp.&amp;nbsp; 31–80; {{harvtxt|Kahn|Klawe|Kleitman|1983}}; {{harvtxt|Lubiw|1985}}; {{harvtxt|Sack|Toussaint|1988}}.&lt;/ref&gt;

A related problem asks for the number of guards to cover the exterior of an arbitrary polygon (the "Fortress Problem"): &lt;math&gt;\lceil n/2 \rceil&lt;/math&gt; are sometimes necessary and always sufficient.  In other words, the infinite exterior is more challenging to cover than the finite interior.&lt;ref&gt;{{harvtxt|O'Rourke|1987}}, pp.&amp;nbsp;146–154.&lt;/ref&gt;

===Computational complexity===
In [[decision problem]] versions of the art gallery problem, one is given as input both a polygon and a number ''k'', and must determine whether the polygon can be guarded with ''k'' or fewer guards. This problem is [[Existential theory of the reals|&lt;math&gt;\exists\mathbb{R}&lt;/math&gt;-complete]], as is the version where the guards are restricted to the edges of the polygon. &lt;ref&gt;{{citation
 | last1 = Abrahamsen | first1 = Mikkel | last2 = Adamaszek | first2 = Anna | last3 = Miltzow | first3 = Tillmann
 | arxiv = 1704.06969 | title = The Art Gallery Problem is &lt;math&gt;\exists\mathbb{R}&lt;/math&gt;-complete | year = 2017| bibcode = 2017arXiv170406969A}}&lt;/ref&gt; Furthermore, most of the other standard variations (such as restricting the guard locations to vertices) are [[NP-hard]]. &lt;ref&gt;{{cite journal |last1=Lee |first1=D.T. |last2=Lin |first2=A. |title=Computational complexity of art gallery problems |journal=IEEE Transactions on Information Theory |year=1986 |volume=32 |issue=2 |pages=276–282 |doi=10.1109/TIT.1986.1057165}}&lt;/ref&gt; 
&lt;ref&gt;{{cite journal |last1=O'Rourke |first1=J. |last2=Supowit |first2=K. |title=Some NP-hard polygon decomposition problems |journal=IEEE Transactions on Information Theory |year=1983 |volume=29 |issue=2 |pages=181–190 |doi=10.1109/TIT.1983.1056648}}&lt;/ref&gt;
 
Regarding [[approximation algorithm]]s for the minimum number of guards, {{harvtxt|Eidenbenz|Stamm|Widmayer|2001}} proved the problem to be APX-hard, implying that it is unlikely that any [[approximation ratio]] better than some fixed constant can be achieved by a [[polynomial time]] [[approximation algorithm]]. However, an algorithm achieving a constant approximation ratio was not known until very recently. {{harvtxt|Ghosh|1987}} showed that a [[logarithm]]ic approximation may be achieved for the minimum number of vertex guards by discretizing the input polygon into convex subregions and then reducing the problem to a [[set cover]] problem. &lt;ref&gt;{{cite journal |last1=Ghosh |first1=Subir Kumar |title=Approximation algorithms for art gallery problems in polygons |journal=Discrete Applied Mathematics |year=2010 |volume=158 |issue=6 |pages=718–722 |doi=10.1016/j.dam.2009.12.004}}&lt;/ref&gt;
As {{harvtxt|Valtr|1998}} showed, the set system derived from an art gallery problem has bounded [[VC dimension]], &lt;ref&gt;{{citation | last = Valtr | first = Pavl | doi = 10.1007/BF02897056 | issue = 1 | journal = Israel J. Math.
 | pages = 1–16 | title = Guarding galleries where no point sees a small area | volume = 104 | year = 1998}} &lt;/ref&gt; allowing the application of set cover algorithms based on [[ε-net (computational geometry)|ε-nets]] whose approximation ratio is the logarithm of the optimal number of guards rather than of the number of polygon vertices. &lt;ref&gt;{{cite journal |last1=Brönnimann |first1=H. |last2=Goodrich |first2=M. T. |title=Almost optimal set covers in finite VC-dimension |journal=Discrete &amp; Computational Geometry |year=1995 |volume=14 |issue=4 |pages=463–479 |doi=10.1007/BF02570718}}&lt;/ref&gt;
For unrestricted guards, the infinite number of potential guard positions makes the problem even more difficult. 
However by restricting the guards to lie on a fine grid, a more complicated [[logarithm]]ic approximation algorithm can be derived under some mild extra assumptions, as shown by {{harvtxt|Bonnet|Miltzow|2016}}. &lt;ref&gt;{{citation
 | last1 = Bonnet | first1 = Edouard | last2 = Miltzow | first2 = Tillmann | arxiv = 1607.05527 | title = An Approximation Algorithm for the Art Gallery Problem | year  = 2016| bibcode = 2016arXiv160705527B}}.&lt;/ref&gt;
However, efficient algorithms are known for finding a set of  at most &lt;math&gt;\left\lfloor n/3 \right\rfloor&lt;/math&gt; vertex guards, matching Chvátal's upper bound.
{{harvs|first1=David|last1=Avis|author1-link=David Avis|first2=Godfried|last2=Toussaint|author2-link=Godfried Toussaint|year=1981|txt}} proved that a placement for these guards may be computed in O(n ''log'' n) time in the worst case, via a [[divide and conquer algorithm]].
{{harvtxt|Kooshesh|Moret|1992}} gave a [[linear time]] algorithm by using Fisk's short proof and [[Bernard Chazelle]]'s linear time plane triangulation algorithm.

For simple polygons that do not contain holes, the existence of a constant factor approximation algorithm for vertex and edge guards was conjectured by Ghosh. Ghosh's conjecture was initially shown to be true for vertex guards in two special sub-classes of simple polygons, viz. monotone polygons and polygons weakly visible from an edge. {{harvtxt|Krohn|Nilsson|2012}} presented an approximation algorithm that computes in polynomial time a vertex guard set for a monotone polygon such that the size of the guard set is at most 30 times the optimal number of vertex guards. &lt;ref&gt;{{cite journal |last1=Krohn |first1=Erik A. |last2=Nilsson |first2=Bengt J. |title=Approximate Guarding of Monotone and Rectilinear Polygons |journal=Algorithmica |year=2013 |volume=66 |issue=3 |pages=564–594 |doi=10.1007/s00453-012-9653-3}}&lt;/ref&gt;  
{{harvtxt|Bhattacharya|Ghosh|Roy|2015}} presented an approximation algorithm that computes in O(n&lt;sup&gt;2&lt;/sup&gt;) time a vertex guard set for a simple polygon that is weakly visible from an edge such that the size of the guard set is at most 6 times the optimal number of vertex guards. &lt;ref&gt;{{cite journal |last1=Bhattacharya |first1=Pritam |last2=Ghosh |first2=Subir Kumar |last3=Roy |first3=Bodhayan |title=Approximability of guarding weak visibility polygons |journal=Discrete Applied Mathematics |year=2017 |volume=228 |pages=109–129 |doi=10.1016/j.dam.2016.12.015}}&lt;/ref&gt;
Subsequently, {{harvtxt|Bhattacharya|Ghosh|Pal|2017}} claimed to have settled the conjecture completely by presenting constant factor approximation algorithms for guarding general simple polygons using vertex guards and edge guards. 
&lt;ref&gt;{{citation |last1=Bhattacharya |first1=Pritam |last2=Ghosh |first2=Subir Kumar |last3=Pal |first3=Sudebkumar |title=Constant Approximation Algorithms for Guarding Simple Polygons using Vertex Guards |arxiv=1712.05492 |year=2017 |url=https://arxiv.org/abs/1712.05492}}&lt;/ref&gt;
For vertex guarding the subclass of simple polygons that are weakly visible from an edge, a [[polynomial-time approximation scheme]] (PTAS) was recently  proposed by {{harvtxt|Katz|2018}}. &lt;ref&gt;{{citation |last1=Katz |first1=Matthew J. |title=A PTAS for vertex guarding weakly-visible polygons - An extended abstract |arxiv = 1803.02160 |year=2018 |url=http://arxiv.org/abs/1803.02160}}&lt;/ref&gt; 

An  exact  algorithm  was  proposed by  {{harvtxt|Couto|de  Rezende|de Souza|2011}}  for  vertex  guards.   The authors  conducted  extensive computational  experiments with  several classes  of  polygons showing that optimal  solutions can be  found in relatively  small computation times even  for instances associated  to thousands of  vertices. The input data and the optimal solutions for these instances are available for download.&lt;ref&gt;{{harvtxt|Couto|de Rezende|de Souza|2011}}.&lt;/ref&gt;

==Three dimensions==
[[File:Polyhedron with no vertex visible from center.png|thumb|An example of a polyhedron with interior points not visible from any vertex.]]
If a museum is represented in three dimensions as a [[polyhedron]], then putting a guard at each vertex will not ensure that all of the museum is under observation. Although all of the surface of the polyhedron would be surveyed, for some polyhedra there are points in the interior which might not be under surveillance.&lt;ref&gt;{{harvtxt|O'Rourke|1987}}, p.&amp;nbsp;255.&lt;/ref&gt;

==See also==
* [[Polygon covering#Covering a rectilinear polygon with star polygons]]

==Notes==
{{reflist|2}}

==References==
*{{citation
 | last = Aggarwal | first = A.
 | publisher = Ph.D. thesis, Johns Hopkins University
 | title = The art gallery theorem: Its variations, applications, and algorithmic aspects
 | year = 1984}}.
*{{citation
 | last1 = Avis | first1 = D. | author1-link = David Avis
 | last2 = Toussaint | first2 = G. T. | author2-link = Godfried Toussaint
 | doi = 10.1016/0031-3203(81)90002-9
 | issue = 6
 | journal = Pattern Recognition
 | pages = 395–398
 | title = An efficient algorithm for decomposing a polygon into star-shaped polygons
 | url = http://cgm.cs.mcgill.ca/~godfried/publications/star.pdf
 | volume = 13
 | year = 1981}}.
*{{citation
 | last1 = Brönnimann | first1 = H.
 | last2 = Goodrich | first2 = M. T. | author2-link = Michael T. Goodrich
 | doi = 10.1007/BF02570718
 | issue = 1
 | journal = Discrete and Computational Geometry
 | pages = 463–479
 | title = Almost optimal set covers in finite VC-dimension
 | volume = 14
 | year = 1995}}.
*{{citation
 | last = Chvátal | first = V. | author-link = Václav Chvátal
 | doi = 10.1016/0095-8956(75)90061-1
 | journal = Journal of Combinatorial Theory, Series B
 | pages = 39–41
 | title = A combinatorial theorem in plane geometry
 | volume = 18
 | year = 1975}}.
*{{citation
 | last1 = Couto | first1 = M. 
 | last2 = de Rezende | first2 = P. 
 | last3 = de Souza | first3 = C.
 | doi = 10.1111/j.1475-3995.2011.00804.x
 | journal = International Transactions in Operational Research
 | title = An exact algorithm for minimizing vertex guards on art galleries
 | year = 2011
 | pages = no–no}}.
*{{citation
 | last1 = Couto | first1 = M. 
 | last2 = de Rezende | first2 = P. 
 | last3 = de Souza | first3 = C.
 | title = Benchmark instances for the art gallery problem with vertex guards
 | url = http://www.ic.unicamp.br/~cid/Problem-instances/Art-Gallery/
 | year = 2011}}.
*{{citation
 | last1 = Deshpande | first1 = Ajay
 | last2 = Kim | first2 = Taejung
 | last3 = Demaine | first3 = Erik D. | author3-link = Erik Demaine
 | last4 = Sarma | first4 = Sanjay E.
 | doi = 10.1007/978-3-540-73951-7_15
 | pages = 163–174
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = [[SWAT and WADS conferences|Proc. Worksh. Algorithms and Data Structures]]
 | volume = 4619
 | year = 2007
 | chapter = A Pseudopolynomial Time O(logn)-Approximation Algorithm for Art Gallery Problems
 | isbn = 978-3-540-73948-7}}.
*{{citation
 |last1=Eidenbenz 
 |first1=S. 
 |last2=Stamm 
 |first2=C. 
 |last3=Widmayer 
 |first3=P. 
 |doi=10.1007/s00453-001-0040-8 
 |issue=1 
 |journal=Algorithmica 
 |pages=79–113 
 |title=Inapproximability results for guarding polygons and terrains 
 |url=http://www.inf.ethz.ch/personal/eidenben/publications/eidenbenz_algorithmica2001.pdf 
 |volume=31 
 |year=2001 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20030624032504/http://www.inf.ethz.ch/personal/eidenben/publications/eidenbenz_algorithmica2001.pdf 
 |archivedate=2003-06-24 
}}.
*{{citation
 | last = Fisk | first = S.
 | doi = 10.1016/0095-8956(78)90059-X
 | issue = 3
 | journal = Journal of Combinatorial Theory, Series B
 | page = 374
 | title = A short proof of Chvátal's watchman theorem
 | volume = 24
 | year = 1978}}.
*{{citation
 | last = Ghosh | first = S. K.
 | contribution = Approximation algorithms for art gallery problems
 | pages = 429–434
 | title = Proc. Canadian Information Processing Society Congress
 | year = 1987}}.
*{{citation
 | last1 = Kahn | first1 = J.
 | last2 = Klawe | first2 = M. | author2-link = Maria Klawe
 | last3 = Kleitman | first3 = D. | author3-link = Daniel Kleitman
 | doi = 10.1137/0604020
 | issue = 2
 | journal = SIAM J. Alg. Disc. Meth.
 | pages = 194–206
 | title = Traditional galleries require fewer watchmen
 | volume = 4
 | year = 1983}}.
*{{citation
 | last1 = Kooshesh | first1 = A. A.
 | last2 = Moret | first2 = B. M. E.
 | doi = 10.1016/0031-3203(92)90093-X
 | issue = 4
 | journal = Pattern Recognition
 | page = 443
 | title = Three-coloring the vertices of a triangulated simple polygon
 | volume = 25
 | year = 1992}}.
*{{citation
 | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee
 | last2 = Lin | first2 = A. K.
 | doi = 10.1109/TIT.1986.1057165
 | issue = 2
 | journal = IEEE Transactions on Information Theory
 | pages = 276–282
 | title = Computational complexity of art gallery problems
 | volume = 32
 | year = 1986}}.
*{{citation
 | last = Lubiw | first = A. | authorlink = Anna Lubiw
 | doi = 10.1145/323233.323247
 | pages = 97–106
 | title = Proc. 1st ACM Symposium on Computational Geometry
 | year = 1985
 | chapter = Decomposing polygonal regions into convex quadrilaterals
 | isbn = 0-89791-163-6}}.
*{{citation
 | last = O'Rourke | first = Joseph | author-link = Joseph O'Rourke (professor)
 | isbn = 0-19-503965-3
 | publisher = Oxford University Press
 | title = Art Gallery Theorems and Algorithms
 | url = http://cs.smith.edu/~orourke/books/ArtGalleryTheorems/art.html
 | year = 1987}}.
*{{citation
 | last1 = Sack | first1 = J. R. | author1-link = Jörg-Rüdiger Sack
 | last2 = Toussaint | first2 = G. T. | author2-link = Godfried Toussaint
 | contribution = Guard placement in rectilinear polygons
 | editor-last = Toussaint | editor-first = G. T. | editor-link = Godfried Toussaint
 | pages = 153–176
 | publisher = North-Holland
 | title = Computational Morphology
 | year = 1988}}.
*{{citation
 | last = Shermer | first = Thomas
 | doi = 10.1109/5.163407
 | issue = 9
 | journal = Proceedings of the IEEE
 | pages = 1384–1399
 | title = Recent Results in Art Galleries
 | url = http://www.cs.ubc.ca/nest/theory/thread/papers/shermer2002.pdf
 | volume = 80
 | year = 1992}}.
*{{citation
 | last = Valtr | first = P.
 | doi = 10.1007/BF02897056
 | issue = 1
 | journal = Israel J. Math.
 | pages = 1–16
 | title = Guarding galleries where no point sees a small area
 | volume = 104
 | year = 1998}}.

{{DEFAULTSORT:Art Gallery Problem}}
[[Category:Computational geometry]]
[[Category:Articles containing proofs]]
[[Category:Computational problems]]
[[Category:Polygons]]</text>
      <sha1>pccev8iqdgh7ixig0i2l2rysbt64i79</sha1>
    </revision>
  </page>
  <page>
    <title>Band model</title>
    <ns>0</ns>
    <id>58129622</id>
    <revision>
      <id>868812493</id>
      <parentid>861855531</parentid>
      <timestamp>2018-11-14T16:12:44Z</timestamp>
      <contributor>
        <username>TheKing44</username>
        <id>17262741</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2269">[[File:Order 7-3 rhombic tiling in the Band Model.png|thumb|The [[order-7-3 rhombille tiling|order 7-3 rhombic tiling]] shown in a portion of the '''band model'''.]]
In [[geometry]], the '''band model''' is a [[Conformal geometry|conformal]] [[Hyperbolic geometry#Models of the hyperbolic plane|model]] of the [[hyperbolic plane]]. The band model employs a portion of the Euclidean plane between two parallel lines&lt;ref&gt;{{cite book|url=http://matrixeditions.com/TeichmullerVol1.html|title=Teichmüller Theory and Applications to Geometry, Topology, and Dynamics|date=|publisher=Matrix Editions|last=Hubbard|first=John H.|authorlink=John H. Hubbard|isbn=9780971576629|location=Ithaca, NY|oclc=57965863|chapter=2|chapter-url=http://matrixeditions.com/TVol1.Chap2.pdf|page=25}}&lt;/ref&gt;. Distance is preserved along one line through the middle of the band. Assuming the band is given by &lt;math&gt;\{z \in \mathbb C: \left|\operatorname {Im} z\right| &lt; \pi / 2\}&lt;/math&gt;, the metric is given by &lt;math&gt;|dz| \sec (\operatorname{Im} z)&lt;/math&gt;.
[[File:Geodesics in the Band Model.png|thumb|[[Geodesic|Geodesics]] shown in a portion of the '''band model'''.]]
Geodesics include the line along the middle of the band, and any open line segment perpendicular to boundaries of the band connecting the sides of the band. All geodesics have ends with either are orthogonal to the boundaries of the band or which approach &lt;math&gt;\plusmn \infty&lt;/math&gt;.&lt;ref&gt;{{Cite web|url=http://pi.math.cornell.edu/~bowman/metrics.pdf|title=612 CLASS LECTURE: HYPERBOLIC GEOMETRY|last=Bowman|first=Joshua|date=|website=|archive-url=|archive-date=|dead-url=|access-date=August 12, 2018}}&lt;/ref&gt; Lines parallel to the boundaries of the band within the band are [[hypercycle (geometry)|hypercycles]] whose centers are the line through the middle of the band.

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

== External Links ==
* [http://www.roguetemple.com/z/hyper/models.php Models of hyperbolic geometry]
* [http://bulatov.org/math/1001/ Conformal Models of the Hyperbolic Geometry]

[[Category:Conformal geometry]]
[[Category:Hyperbolic geometry]]


{{Math-stub}}</text>
      <sha1>p76nq68u93h7xmdsikfcyi73w7feaoj</sha1>
    </revision>
  </page>
  <page>
    <title>Barnes G-function</title>
    <ns>0</ns>
    <id>2060183</id>
    <revision>
      <id>840660096</id>
      <parentid>822478812</parentid>
      <timestamp>2018-05-11T09:10:49Z</timestamp>
      <contributor>
        <ip>80.115.185.191</ip>
      </contributor>
      <comment>/* Reflection formula 1.0 */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10480">In [[mathematics]], the '''Barnes G-function''' ''G''(''z'') is a [[function (mathematics)|function]] that is an extension of [[superfactorial]]s to the [[complex number]]s. It is related to the [[Gamma function]], the [[K-function]] and the [[Glaisher–Kinkelin constant]], and was named after [[mathematician]] [[Ernest William Barnes]].&lt;ref&gt;E. W. Barnes, "The theory of the G-function", ''Quarterly Journ. Pure and Appl. Math.'' '''31''' (1900), 264–314.&lt;/ref&gt; Up to elementary factors, it is a special case of the [[double gamma function]].

Formally, the Barnes ''G''-function is defined in the following [[Weierstrass product]] form:

:&lt;math&gt; G(1+z)=(2\pi)^{z/2} \text{exp}\left(- \frac{z+z^2(1+\gamma)}{2} \right) \, \prod_{k=1}^{\infty} \left\{ \left(1+\frac{z}{k}\right)^k \text{exp}\left(\frac{z^2}{2k}-z\right) \right\}&lt;/math&gt;

where &lt;math&gt;\, \gamma &lt;/math&gt; is the [[Euler–Mascheroni constant]], [[exponential function|exp]](''x'') = ''e''&lt;sup&gt;''x''&lt;/sup&gt;, and ∏ is [[capital pi notation]].

==Functional equation and integer arguments==

The Barnes ''G''-function satisfies the [[functional equation]]

:&lt;math&gt; G(z+1)=\Gamma(z)\, G(z) &lt;/math&gt;

with normalisation ''G''(1)&amp;nbsp;=&amp;nbsp;1. Note the similarity between the functional equation of the Barnes G-function and that of the Euler [[Gamma function]]:

:&lt;math&gt; \Gamma(z+1)=z \, \Gamma(z) .&lt;/math&gt;

The functional equation implies that ''G'' takes the following values at [[integer]] arguments:

:&lt;math&gt;G(n)=\begin{cases} 0&amp;\text{if }n=0,-1,-2,\dots\\ \prod_{i=0}^{n-2} i!&amp;\text{if }n=1,2,\dots\end{cases}&lt;/math&gt;

(in particular,  &lt;math&gt;\,G(0)=0, G(1)=1&lt;/math&gt;)
and thus

:&lt;math&gt;G(n)=\frac{(\Gamma(n))^{n-1}}{K(n)}&lt;/math&gt;

where &lt;math&gt;\,\Gamma(x)&lt;/math&gt; denotes the [[Gamma function]] and ''K'' denotes the [[K-function]]. The functional equation uniquely defines the G function if the convexity condition: &lt;math&gt;\, \frac{d^3}{dx^3}G(x)\geq 0&lt;/math&gt; is added.&lt;ref&gt;M. F. Vignéras, ''L'équation fonctionelle de la fonction zêta de Selberg du groupe mudulaire SL&lt;math&gt;(2,\mathbb{Z})&lt;/math&gt;'', Astérisque '''61''', 235–249 (1979).&lt;/ref&gt;

==Reflection formula 1.0==

The [[difference equation]] for the G function, in conjunction with the [[functional equation]] for the [[Gamma function]], can be used to obtain the following [[reflection formula]] for the Barnes G function (originally proved by [[Hermann Kinkelin]]):

:&lt;math&gt; \log G(1-z) = \log G(1+z)-z\log 2\pi+ \int_0^z \pi x \cot \pi x \, dx.&lt;/math&gt;

The logtangent integral on the right-hand side can be evaluated in terms of the [[Clausen function]] (of order 2), as is shown below:

:&lt;math&gt;2\pi \log\left( \frac{G(1-z)}{G(1+z)} \right)= 2\pi z\log\left(\frac{\sin\pi z}{\pi} \right)+\text{Cl}_2(2\pi z)&lt;/math&gt;

The proof of this result hinges on the following evaluation of the cotangent integral: introducing the notation &lt;math&gt;\, Lc(z)&lt;/math&gt; for the logtangent integral, and using the fact that &lt;math&gt;\,(d/dx) \log(\sin\pi x)=\pi\cot\pi x&lt;/math&gt;, an integration by parts gives

:&lt;math&gt;\begin{align}
Lc(z) &amp;= \int_0^z\pi x\cot \pi x\,dx \\
        &amp;= z\log(\sin \pi z)-\int_0^z\log(\sin \pi x)\,dx \\
        &amp;= z\log(\sin \pi z)-\int_0^z\Bigg[\log(2\sin \pi x)-\log 2\Bigg]\,dx \\
        &amp;= z\log(2\sin \pi z)-\int_0^z\log(2\sin \pi x)\,dx .
\end{align}&lt;/math&gt;

Performing the integral substitution &lt;math&gt;\, y=2\pi x \Rightarrow dx=dy/(2\pi)&lt;/math&gt; gives

:&lt;math&gt;z\log(2\sin \pi z)-\frac{1}{2\pi}\int_0^{2\pi z}\log\left(2\sin \frac{y}{2} \right)\,dy.&lt;/math&gt;

The [[Clausen function]] – of second order – has the integral representation

:&lt;math&gt;\text{Cl}_2(\theta) = -\int_0^{\theta}\log\Bigg|2\sin \frac{x}{2} \Bigg|\,dx.&lt;/math&gt;

However, within the interval &lt;math&gt;\, 0 &lt; \theta &lt; 2\pi &lt;/math&gt;, the [[absolute value]] sign within the [[integrand]] can be omitted, since within the range the 'half-sine' function in the integral is strictly positive, and strictly non-zero. Comparing this definition with the result above for the logtangent integral, the following relation clearly holds:

:&lt;math&gt;Lc(z)=z\log(2\sin \pi z)+\frac{1}{2\pi}\, \text{Cl}_2(2\pi z).&lt;/math&gt;

Thus, after a slight rearrangement of terms, the proof is complete:

:&lt;math&gt;2\pi \log\left( \frac{G(1-z)}{G(1+z)} \right)= 2\pi z\log\left(\frac{\sin\pi z}{\pi} \right)+\text{Cl}_2(2\pi z)\, . \, \Box &lt;/math&gt;

Using the relation &lt;math&gt;\, G(1+z)=\Gamma(z)\, G(z) &lt;/math&gt; and dividing the reflection formula by a factor of &lt;math&gt;\, 2\pi &lt;/math&gt; gives the equivalent form:

:&lt;math&gt; \log\left( \frac{G(1-z)}{G(z)} \right)= z\log\left(\frac{\sin\pi z}{\pi}
\right)+\log\Gamma(z)+\frac{1}{2\pi}\text{Cl}_2(2\pi z) &lt;/math&gt;


Ref: see '''Adamchik''' below for an equivalent form of the [[reflection formula]], but with a different proof.

==Reflection formula 2.0==


Replacing '''''z''''' with '''(1/2)&amp;nbsp;−&amp;nbsp;''z''''''' in the previous reflection formula gives,  after some simplification, the equivalent formula shown below (involving [[Bernoulli polynomials]]):

:&lt;math&gt;\log\left( \frac{ G\left(\frac{1}{2}+z\right) }{ G\left(\frac{1}{2}-z\right) } \right) =&lt;/math&gt;

:&lt;math&gt;
 \log \Gamma \left(\frac{1}{2}-z \right) + B_1(z) \log 2\pi+\frac{1}{2}\log 2+\pi \int_0^z B_1(x) \tan \pi x \,dx&lt;/math&gt;

==Taylor series expansion==

By [[Taylor's theorem]], and considering the logarithmic [[derivative]]s of the Barnes function, the following series expansion can be obtained:

:&lt;math&gt;\log G(1+z) = \frac{z}{2}\log 2\pi -\left( \frac{z+(1+\gamma)z^2}{2} \right) + \sum_{k=2}^{\infty}(-1)^k\frac{\zeta(k)}{k+1}z^{k+1}.&lt;/math&gt;

It is valid for &lt;math&gt;\, 0 &lt; z &lt; 1 &lt;/math&gt;. Here, &lt;math&gt;\, \zeta(x) &lt;/math&gt; is the [[Riemann Zeta function]]:

:&lt;math&gt; \zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}. &lt;/math&gt;

Exponentiating both sides of the Taylor expansion gives:

:&lt;math&gt;\begin{align} G(1+z) &amp;= \exp \left[ \frac{z}{2}\log 2\pi -\left( \frac{z+(1+\gamma)z^2}{2} \right) + \sum_{k=2}^{\infty}(-1)^k\frac{\zeta(k)}{k+1}z^{k+1} \right] \\
&amp;=(2\pi)^{z/2}\exp\left[ -\frac{z+(1+\gamma)z^2}{2} \right] \exp \left[\sum_{k=2}^{\infty}(-1)^k\frac{\zeta(k)}{k+1}z^{k+1} \right].\end{align}&lt;/math&gt;

Comparing this with the [[Weierstrass product]] form of the Barnes function gives the following relation:

:&lt;math&gt;\exp \left[\sum_{k=2}^{\infty}(-1)^k\frac{\zeta(k)}{k+1}z^{k+1} \right] = \prod_{k=1}^{\infty} \left\{ \left(1+\frac{z}{k}\right)^k\text{exp}\left(\frac{z^2}{2k}-z\right) \right\}&lt;/math&gt;

==Multiplication formula==

Like the Gamma function, the G-function also has a multiplication formula:&lt;ref&gt;I. Vardi, ''Determinants of Laplacians and multiple gamma functions'', SIAM J. Math. Anal. '''19''', 493–507 (1988).&lt;/ref&gt;

:&lt;math&gt;
G(nz)= K(n) n^{n^{2}z^{2}/2-nz} (2\pi)^{-\frac{n^2-n}{2}z}\prod_{i=0}^{n-1}\prod_{j=0}^{n-1}G\left(z+\frac{i+j}{n}\right)
&lt;/math&gt;

where &lt;math&gt;K(n)&lt;/math&gt; is a constant given by:

:&lt;math&gt; K(n)= e^{-(n^2-1)\zeta^\prime(-1)} \cdot
n^{\frac{5}{12}}\cdot(2\pi)^{(n-1)/2}\,=\,
(Ae^{-\frac{1}{12}})^{n^2-1}\cdot n^{\frac{5}{12}}\cdot (2\pi)^{(n-1)/2}.&lt;/math&gt;

Here &lt;math&gt;\zeta^\prime&lt;/math&gt; is the derivative of the [[Riemann zeta function]] and &lt;math&gt;A&lt;/math&gt; is the [[Glaisher–Kinkelin constant]].

==Asymptotic expansion==

The [[logarithm]] of ''G''(''z'' + 1) has the following asymptotic expansion, as established by Barnes:

:&lt;math&gt;\begin{align} \log G(z+1) &amp;= \frac{1}{12}-\log A+\frac{z}{2}\log 2\pi+\left(\frac{z^2}{2} -\frac{1}{12}\right)\log z\\
&amp;\quad-\frac{3z^2}{4}+\sum_{k=1}^{N}\frac{B_{2k + 2}}{4k\left(k + 1\right)z^{2k}}~+~O\left(\frac{1}{z^{2N + 2}}\right).\end{align}&lt;/math&gt;

Here the &lt;math&gt;B_{k}&lt;/math&gt; are the [[Bernoulli numbers]] and &lt;math&gt;A&lt;/math&gt; is the [[Glaisher–Kinkelin constant]]. (Note that somewhat confusingly at the time of Barnes &lt;ref&gt;[[E. T. Whittaker]] and G.N.Watson, "A course of modern analysis", CUP.&lt;/ref&gt; the [[Bernoulli number]] &lt;math&gt;B_{2k}&lt;/math&gt; would have been written as &lt;math&gt;(-1)^{k+1} B_k &lt;/math&gt;, but this convention is no longer current.) This expansion is valid for &lt;math&gt;z &lt;/math&gt; in any sector not containing the negative real axis with &lt;math&gt;|z|&lt;/math&gt; large.

==Relation to the Loggamma integral==

The parametric Loggamma can be evaluated in terms of the Barnes G-function (Ref: this result is found in '''Adamchik''' below, but stated without proof):

:&lt;math&gt; \int_0^z \log \Gamma(x)\,dx=\frac{z(1-z)}{2}+\frac{z}{2}\log 2\pi +z\log\Gamma(z) -\log G(1+z) &lt;/math&gt;

The proof is somewhat indirect, and involves first considering the logarithmic difference of the [[Gamma function]] and Barnes G-function:

:&lt;math&gt;z\log \Gamma(z)-\log G(1+z)&lt;/math&gt;

where

:&lt;math&gt;\frac{1}{\Gamma(z)}= z e^{\gamma z} \prod_{k=1}^{\infty} \left\{ \left(1+\frac{z}{k}\right)e^{-z/k} \right\}&lt;/math&gt;

and &lt;math&gt;\,\gamma&lt;/math&gt; is the [[Euler–Mascheroni constant]].

Taking the logarithm of the [[Weierstrass product]] forms of the Barnes function and Gamma function gives:

:&lt;math&gt;z\log \Gamma(z)-\log G(1+z)=-z \log\left(\frac{1}{\Gamma (z)}\right)-\log G(1+z)=&lt;/math&gt;

:&lt;math&gt;-z \left[ \log z+\gamma z +\sum_{k=1}^{\infty} \Bigg\{ \log\left(1+\frac{z}{k} \right) -\frac{z}{k} \Bigg\} \right]&lt;/math&gt;

:&lt;math&gt;-\left[ \frac{z}{2}\log 2\pi -\frac{z}{2}-\frac{z^2}{2} -\frac{z^2 \gamma}{2} + \sum_{k=1}^{\infty} \Bigg\{k\log\left(1+\frac{z}{k}\right) +\frac{z^2}{2k} -z \Bigg\} \right]&lt;/math&gt;

A little simplification and re-ordering of terms gives the series expansion:

:&lt;math&gt; \sum_{k=1}^{\infty} \Bigg\{ (k+z)\log \left(1+\frac{z}{k}\right)-\frac{z^2}{2k}-z \Bigg\}=&lt;/math&gt;

:&lt;math&gt;-z\log z-\frac{z}{2}\log 2\pi +\frac{z}{2} +\frac{z^2}{2}- \frac{z^2 \gamma}{2}- z\log\Gamma(z) +\log G(1+z)&lt;/math&gt;

Finally, take the logarithm of the [[Weierstrass product]] form of the [[Gamma function]], and integrate over the interval &lt;math&gt;\, [0,\,z]&lt;/math&gt; to obtain:

:&lt;math&gt;\int_0^z\log\Gamma(x)\,dx=-\int_0^z \log\left(\frac{1}{\Gamma(x)}\right)\,dx=&lt;/math&gt;

:&lt;math&gt;-(z\log z-z)-\frac{z^2 \gamma}{2}- \sum_{k=1}^{\infty} \Bigg\{ (k+z)\log \left(1+\frac{z}{k}\right)-\frac{z^2}{2k}-z \Bigg\}&lt;/math&gt;

Equating the two evaluations completes the proof:

:&lt;math&gt; \int_0^z \log \Gamma(x)\,dx=\frac{z(1-z)}{2}+\frac{z}{2}\log 2\pi +z\log\Gamma(z) -\log G(1+z)\, . \, \Box&lt;/math&gt;

==References==
&lt;references/&gt;

*{{dlmf|first=R.A. |last=Askey|first2=R.|last2=Roy|id=5.17}}
{{DEFAULTSORT:Barnes G-Function}}
[[Category:Number theory]]
[[Category:Special functions]]

*{{cite web|last=Adamchik|first=Viktor S.|title=Contributions to the Theory of the Barnes function|url=https://arxiv.org/pdf/math/0308086v1.pdf|accessdate=2003}}</text>
      <sha1>kowlcacfbgncatvoud8qcmm52mz1ghf</sha1>
    </revision>
  </page>
  <page>
    <title>C-symmetry</title>
    <ns>0</ns>
    <id>151001</id>
    <revision>
      <id>814796400</id>
      <parentid>783047097</parentid>
      <timestamp>2017-12-11T00:07:58Z</timestamp>
      <contributor>
        <username>John Baez</username>
        <id>233394</id>
      </contributor>
      <comment>Added explanation of charge conjugation, which was missing.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3591">{{Refimprove|date=December 2008}}

'''Charge conjugation''' is a transformation that switches all particles with their corresponding antiparticles, and thus changes the sign of all [[charge (physics)|charges]]: not only [[electric charge]] but also the charges relevant to other forces.   In [[physics]], '''C-symmetry''' means the symmetry of physical laws under a charge-conjugation [[transformation (mathematics)|transformation]]. Electromagnetism, gravity and the strong interaction all obey C-symmetry, but [[weak interaction]]s violate C-symmetry.

==Charge reversal in electroweak theory==
The laws of [[electromagnetism]] (both [[classical physics|classical]] and [[quantum]]) are [[Invariant (physics)|invariant]] under this transformation: if each charge ''q'' were to be replaced with a charge &amp;minus;''q'', and thus the directions of the [[electric field|electric]] and [[magnetic field]]s were reversed, the dynamics would preserve the same form. In the language of [[quantum field theory]], charge conjugation transforms:&lt;ref name="PS"&gt;{{cite book|author1=Peskin, M.E.  |author2=Schroeder, D.V.|title=An Introduction to Quantum Field Theory|publisher=Addison Wesley|year=1997|isbn=0-201-50397-2}}&lt;/ref&gt;

# &lt;math&gt;\psi \rightarrow -i(\bar\psi \gamma^0 \gamma^2)^T&lt;/math&gt;
# &lt;math&gt;\bar\psi \rightarrow -i(\gamma^0 \gamma^2 \psi)^T&lt;/math&gt;
# &lt;math&gt;A^\mu \rightarrow -A^\mu&lt;/math&gt;

Notice that these transformations do not alter the [[Chirality (physics)|chirality]] of particles. A left-handed [[neutrino]] would be taken by charge conjugation into a left-handed [[antineutrino]], which does not interact in the Standard Model. This property is what is meant by the "maximal violation" of C-symmetry in the weak interaction.

(Some postulated extensions of the [[Standard Model]], like [[left-right model]]s, restore this C-symmetry.)

==Combination of charge and parity reversal==
It was believed for some time that C-symmetry could be combined with the [[parity (physics)|parity]]-inversion transformation (see [[P-symmetry]]) to preserve a combined [[CP-symmetry]]. However, violations of this symmetry have been identified in the weak interactions (particularly in the [[kaon]]s and B [[meson]]s). In the Standard Model, this [[CP violation]] is due to a single phase in the [[CKM matrix]]. If CP is combined with time reversal ([[T-symmetry]]), the resulting [[CPT-symmetry]] can be shown using only the [[Wightman axioms]] to be universally obeyed.

==Charge definition==
{{main|C parity}}

To give an example, take two real scalar fields, ''φ'' and ''χ''. Suppose both fields have even C-parity (even C-parity refers to even symmetry under charge conjugation e.g., &lt;math&gt;C\psi(q) = C\psi(-q)&lt;/math&gt;, as opposed to odd C-parity which refers to antisymmetry under charge conjugation, e.g., &lt;math&gt;C\psi(q)=-C\psi(-q)&lt;/math&gt;). 

Define &lt;math&gt;\psi\ \stackrel{\mathrm{def}}{=}\  {\phi + i \chi\over \sqrt{2}}&lt;/math&gt;. Now, {{mvar|φ}} and {{mvar|χ}} have even ''C''-parities, and  the imaginary number ''i'' has an odd ''C''-parity (''C'' is anti-unitary). Under ''C'', ''ψ'' goes to ''ψ&lt;sup&gt;*&lt;/sup&gt;''.

In other models, it is also possible for both ''φ'' and ''χ'' to have odd C-parities.

==See also==
* [[C parity]]
* [[Anti-particle]]
* [[Antimatter]]
* [[Truly neutral particle]]

==References==
{{reflist}}
* {{cite book|author=Sozzi, M.S.|title=Discrete symmetries and CP violation|publisher=Oxford University Press|year=2008|isbn=978-0-19-929666-8}}

&lt;!-- footer templates --&gt;
{{C, P and T}}

&lt;!-- categories --&gt;
[[Category:Quantum field theory]]
[[Category:Symmetry]]</text>
      <sha1>ontjvxgw1wrvqze0vnwjjwv8quoiohl</sha1>
    </revision>
  </page>
  <page>
    <title>Centered tree</title>
    <ns>0</ns>
    <id>4557120</id>
    <revision>
      <id>796840168</id>
      <parentid>664273259</parentid>
      <timestamp>2017-08-23T10:38:04Z</timestamp>
      <contributor>
        <ip>213.152.15.84</ip>
      </contributor>
      <comment>The center of a tree is different from the centroid of a tree.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1798">[[Image:Centered tree.gif|right|frame|On the left a centered tree, on the right a bicentered one.
The numbers show each node's eccentricity. ]]

In discrete mathematics, a '''centered tree''' is a [[tree (graph theory)|tree]] with only one [[graph center|center]], and a '''bicentered tree''' is a tree with two centers.

Given a graph, the eccentricity of a vertex ''v'' is defined as the greatest [[distance (graph theory)|distance]] from ''v'' to any other vertex. A ''center'' of a graph is a vertex with minimal eccentricity. A graph can have an arbitrary number of centers. However, {{harvtxt|Jordan|1869}} has proved that for trees, there are only two possibilities:
# The tree has precisely one center (centered trees).
# The tree has precisely two centers (bicentered trees). In this case, the two centers are adjacent.
A proof of this fact is given, for example, by Knuth.&lt;ref&gt;{{harv|Knuth|1997}}, p. 387 and p. 589&lt;/ref&gt;

==Notes==
&lt;references /&gt;

==References==

*{{cite journal
| last        = Jordan
| first       = Camille
| authorlink  = Camille Jordan
| year        = 1869
| title       = Sur les assemblages de lignes
| journal     = [[Journal für die reine und angewandte Mathematik]]
| volume      = 70
| issue       = 2
| pages       = 185–190
| url         = http://resolver.sub.uni-goettingen.de/purl?GDZPPN002153998
| language    = French
}}
*{{cite book
|title=[[The Art of Computer Programming]], Volume 1: Fundamental Algorithms 
|edition=3rd 
|last=Knuth 
|first= Donald E. |authorlink=Donald Knuth 
|year=1997 
|publisher=Addison-Wesley Professional 
|isbn=0-201-89683-4
}}

==External links==
* {{MathWorld|title=Bicentered Tree|urlname=BicenteredTree}}
* {{MathWorld|title=Centered Tree|urlname=CenteredTree}}

[[Category:Trees (graph theory)]]


{{topology-stub}}</text>
      <sha1>o11k94mcepv2ry7qe0rjdtaeg8bxzco</sha1>
    </revision>
  </page>
  <page>
    <title>Concurrent lines</title>
    <ns>0</ns>
    <id>2206157</id>
    <revision>
      <id>846339186</id>
      <parentid>846338861</parentid>
      <timestamp>2018-06-18T03:16:30Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/117.224.160.175|117.224.160.175]] ([[User talk:117.224.160.175|talk]]) ([[WP:HG|HG]]) (3.4.3)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10559">{{Refimprove|date=March 2011}}
[[Image:Brianchon's Theorem.svg|450px|right|Concurrent [[diagonal]]s of a [[hexagon]] with an inscribed [[conic]] ]]

In [[geometry]], three or more [[line (mathematics)|lines]] in a plane or higher-dimensional space are said to be '''concurrent''' if they [[Line-line intersection|intersect]] at a single [[point (geometry)|point]].

==Examples==

===Triangles===

In a [[triangle]], four basic types of sets of concurrent lines are [[Altitude (triangle)|altitudes]], [[Bisection#Angle bisector|angle bisectors]], [[Median (geometry)|medians]], and [[Bisection#Perpendicular bisectors|perpendicular bisectors]]:

* A triangle's altitudes run from each [[Vertex (geometry)|vertex]] and meet the opposite side at a [[right angle]]. The point where the three altitudes meet is the [[orthocenter]].
* Angle bisectors are rays running from each vertex of the triangle and bisecting the associated [[angle]]. They all meet at the [[incenter]].
* Medians connect each vertex of a triangle to the midpoint of the opposite side. The three medians meet at the [[centroid]].
* Perpendicular bisectors are lines running out of the midpoints of each side of a triangle at 90 degree angles. The three perpendicular bisectors meet at the [[circumcenter]].

Other sets of lines associated with a triangle are concurrent as well. For example:

* Any median (which is necessarily a [[Bisection#Area bisectors and perimeter bisectors|bisector of the triangle's area]]) is concurrent with two other area bisectors each of which is parallel to a side.&lt;ref&gt;Dunn, J. A., and Pretty, J. E., "Halving a triangle," ''[[Mathematical Gazette]]'' 56, May 1972, 105-108.&lt;/ref&gt;
* A [[Cleaver (geometry)|cleaver]] of a triangle is a line segment that [[Bisection#Area bisectors and perimeter bisectors|bisects the perimeter]] of the triangle and has one endpoint at the midpoint of one of the three sides. The three cleavers concur at the center of the [[Spieker circle]], which is the [[incircle]] of the [[medial triangle]].
* A [[Splitter (geometry)|splitter]] of a triangle is a line segment having one endpoint at one of the three vertices of the triangle and bisecting the perimeter. The three splitters concur at the [[Nagel point]] of the triangle.
* Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's [[incenter]], and each triangle has one, two, or three of these lines.&lt;ref&gt;Kodokostas, Dimitrios, "Triangle Equalizers," ''[[Mathematics Magazine]]'' 83, April 2010, pp. 141-146.&lt;/ref&gt; Thus if there are three of them, they concur at the incenter.
* The [[Tarry point]] of a triangle is the point of concurrency of the lines through the vertices of the triangle perpendicular to the corresponding sides of the triangle's first [[Brocard triangle]].
* The [[Schiffler point]] of a triangle is the point of concurrence of the [[Euler line]]s of four triangles: the triangle in question, and the three triangles that each share two vertices with it and have its [[incenter]] as the other vertex.
* The [[Napoleon points]] and generalizations of them are points of concurrency. For example, the first Napoleon point is the point of concurrency of the three lines each from a vertex to the centroid of the equilateral triangle drawn on the exterior of the opposite side from the vertex. A generalization of this notion is the [[Jacobi point]].
* The [[de Longchamps point]] is the point of concurrence of several lines with the [[Euler line]].
* Three lines, each formed by drawing an external equilateral triangle on one of the sides of a given triangle and connecting the new vertex to the original triangle's opposite vertex, are concurrent at a point called the [[Triangle center#1st isogonic center|first isogonal center]]. In the case in which the original triangle has no angle greater than 120°, this point is also the [[Fermat point]].
* The [[Apollonius point]] is the point of concurrence of three lines, each of which connects a point of tangency of the circle to which the triangle's [[excircle]]s are internally tangent, to the opposite vertex of the triangle.

===Quadrilaterals===

*The two [[Quadrilateral#Special line segments|bimedians]] of a [[quadrilateral]] (segments joining midpoints of opposite sides) and the line segment joining the midpoints of the diagonals are concurrent and are all bisected by their point of intersection.&lt;ref name=Altshiller-Court/&gt;{{rp|p.125}}
*In a [[tangential quadrilateral]], the four [[angle bisector]]s concur at the center of the [[incircle]].&lt;ref&gt;Andreescu, Titu and Enescu, Bogdan, ''Mathematical Olympiad Treasures'', Birkhäuser, 2006, pp. 64–68.&lt;/ref&gt;
*Other concurrencies of a tangential quadrilateral are given [[Tangential quadrilateral#Concurrent and perpendicular lines|here]].
*In a [[cyclic quadrilateral]], four line segments, each [[perpendicular]] to one side and passing through the opposite side's [[midpoint]], are concurrent.&lt;ref name=Altshiller-Court&gt;{{citation |first=Nathan |last=Altshiller-Court |title=College Geometry: An Introduction to the Modern Geometry of the Triangle and the Circle |year=2007 |publisher=Courier Dover |isbn=978-0-486-45805-2 |edition=2nd |origyear=1952 |oclc=78063045 |pages=131, 137–8}}&lt;/ref&gt;{{rp|p.131;}}&lt;ref&gt;{{citation |first=Ross |last=Honsberger |title=Episodes in Nineteenth and Twentieth Century Euclidean Geometry |chapterurl=https://books.google.com/books?id=6oduPgvOAhwC&amp;pg=PA35 |year=1995 |publisher=Cambridge University Press |isbn=978-0-88385-639-0 |pages=35–39 |chapter=4.2 Cyclic quadrilaterals |series=New Mathematical Library |volume=37}}&lt;/ref&gt; These line segments are called the ''maltitudes'',&lt;ref&gt;{{mathworld|title=Maltitude|urlname=Maltitude}}&lt;/ref&gt; which is an abbreviation for midpoint altitude. Their common point is called the ''anticenter''.
*A convex quadrilateral is [[Ex-tangential quadrilateral|ex-tangential]] if and only if there are six concurrent angles bisectors: the internal [[Bisection#Angle bisector|angle bisector]]s at two opposite vertex angles, the external angle bisectors at the other two vertex angles, and the external angle bisectors at the angles formed where the extensions of opposite sides intersect.

===Hexagons===

*If the successive sides of a [[Cyclic polygon|cyclic]] [[hexagon]] are ''a'', ''b'', ''c'', ''d'', ''e'', ''f'', then the three main diagonals concur at a single point if and only if {{nowrap|''ace'' {{=}} ''bdf''}}.&lt;ref&gt;Cartensen, Jens, "About hexagons", ''Mathematical Spectrum'' 33(2) (2000-2001), 37-40.&lt;/ref&gt;
*If a hexagon has an [[inscribed figure|inscribed]] [[conic]], then by [[Brianchon's theorem]] its principal [[diagonal]]s are concurrent (as in the above image).
*Concurrent lines arise in the dual of [[Pappus's hexagon theorem]].
*For each side of a cyclic hexagon, extend the adjacent sides to their intersection, forming a triangle exterior to the given side. Then the segments connecting the circumcenters of opposite triangles are concurrent.&lt;ref&gt;Nikolaos Dergiades, "Dao's theorem on six circumcenters associated with a cyclic hexagon", ''Forum Geometricorum'' 14, 2014, 243--246.  http://forumgeom.fau.edu/FG2014volume14/FG201424index.html&lt;/ref&gt;

===Regular polygons===

*If a regular polygon has an even number of sides, the [[diagonal]]s connecting opposite vertices are concurrent at the center of the polygon.

===Circles===

*The [[Bisection#Line segment bisector|perpendicular bisectors]] of all [[Circle#Chord|chords]] of a [[circle]] are concurrent at the [[Center (geometry)|center]] of the circle.
*The lines perpendicular to the tangents to a circle at the points of tangency are concurrent at the center.
*All [[area]] [[Bisection|bisectors]] and [[perimeter]] bisectors of a circle are [[diameter]]s, and they are concurrent at the circle's center.

===Ellipses===

*All area bisectors and perimeter bisectors of an [[ellipse]] are concurrent at the center of the ellipse.

===Hyperbolas===

*In a [[hyperbola]] the following are concurrent: (1) a circle passing through the hyperbola's foci and centered at the hyperbola's center; (2) either of the lines that are tangent to the hyperbola at the vertices; and (3) either of the asymptotes of the hyperbola.
*The following are also concurrent: (1) the circle that is centered at the hyperbola's center and that passes through the hyperbola's vertices; (2) either directrix; and (3) either of the asymptotes.

===Tetrahedrons===

*In a [[tetrahedron]], the four medians and three bimedians are all concurrent at a point called the ''centroid'' of the tetrahedron.&lt;ref&gt;Leung, Kam-tim; and Suen, Suk-nam; "Vectors, matrices and geometry", Hong Kong University Press, 1994, pp. 53-54&lt;/ref&gt;
*An [[Tetrahedron#Other special cases|isodynamic tetrahedron]] is one in which the [[cevian]]s that join the vertices to the [[Incircle and excircles of a triangle|incenter]]s of the opposite faces are concurrent, and an [[Tetrahedron#Other special cases|isogonic tetrahedron]] has concurrent cevians that join the vertices to the points of contact of the opposite faces with the [[inscribed sphere]] of the tetrahedron.
*In an [[orthocentric tetrahedron]] the four altitudes are concurrent.

==Algebra==
{{See also|Incidence (geometry)#Concurrence}}

According to the [[Rouché–Capelli theorem]], a system of equations is [[Consistent equations|consistent]] if and only if the [[rank (linear algebra)|rank]] of the [[coefficient matrix]] is equal to the rank of the [[augmented matrix]] (the coefficient matrix augmented with a column of intercept terms), and the system has a ''unique'' solution if and only if that common rank equals the number of variables. Thus with two variables the ''k'' lines in the plane, associated with a set of ''k'' equations, are concurrent if and only if the rank of the ''k'' × 2  coefficient matrix and the rank of the ''k'' × 3 augmented matrix are both 2. In that case only two of the ''k'' equations are [[independent equation|independent]], and the point of concurrency can be found by solving any two mutually independent equations simultaneously for the two variables.

==Projective geometry==

In [[projective geometry]], in two dimensions concurrency is the [[Duality (projective geometry)|dual]] of [[collinearity]]; in three dimensions, concurrency is the  dual of [[coplanarity]].

==References==

{{reflist}}

==External links==
* [http://mathworld.wolfram.com/Concurrent.html Wolfram MathWorld Concurrent], 2010.

{{DEFAULTSORT:Concurrent Lines}}
[[Category:Elementary geometry]]</text>
      <sha1>dccclz6oqbqdh9rj9ncc3t86okf39li</sha1>
    </revision>
  </page>
  <page>
    <title>Congruent number</title>
    <ns>0</ns>
    <id>2334769</id>
    <revision>
      <id>853373663</id>
      <parentid>853372687</parentid>
      <timestamp>2018-08-04T09:08:53Z</timestamp>
      <contributor>
        <username>Fruits Monster</username>
        <id>2432305</id>
      </contributor>
      <comment>added image.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14679">[[File:Rtriangle-mathsinegypt.svg|thumb|Triangle with the area 6, a congruent number.]]
In [[mathematics]], a '''congruent number''' is a positive [[integer]] that is the area of a [[right triangle]] with three [[rational number]] sides.&lt;ref&gt;{{MathWorld |urlname=CongruentNumber |title=Congruent Number}}&lt;/ref&gt;  A more general definition includes all positive rational numbers with this property.&lt;ref name=Koblitz&gt;{{citation |first = Neal |last = Koblitz |authorlink = Neal Koblitz |title = Introduction to Elliptic Curves and Modular Forms |isbn = 0-387-97966-2 |publisher = [[Springer-Verlag]] |year = 1993| page = 3 |location = New York}}&lt;/ref&gt;

The sequence of integer congruent numbers starts with
: 5, 6, 7, 13, 14, 15, 20, 21, 22, 23, 24, 28, 29, 30, 31, 34, 37, 38, 39, 41, 45, 46, 47, … {{OEIS|A003273}}
{{hidden begin |title = Congruent number table: {{mvar|n}} &amp;le; 120 {{OEIS|A003273}} |titlestyle=text-align:center}}
{| class="wikitable floatright" style="text-align:center"
|+ Congruent number table: {{mvar|n}} &amp;le; 120&lt;br /&gt;&amp;mdash;: non-Congruent number&lt;br /&gt;&lt;span style="background-color:#FFC0CB"&gt;C: square-free Congruent number&lt;/span&gt;&lt;br /&gt;&lt;span style="background-color:#98FB98"&gt;S: Congruent number with square factor&lt;/span&gt;
|-
! {{mvar|n}}
! 1 !! 2 !! 3 !! 4 !! 5 !! 6 !! 7 !! 8
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 9 !! 10 !! 11 !! 12 !! 13 !! 14 !! 15 !! 16
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 17 !! 18 !! 19 !! 20 !! 21 !! 22 !! 23 !! 24
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 25 !! 26 !! 27 !! 28 !! 29 !! 30 !! 31 !! 32
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 33 !! 34 !! 35 !! 36 !! 37 !! 38 !! 39 !! 40
|-
| 
| &amp;mdash; || style="background-color:#FFC0CB" | C || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 41 !! 42 !! 43 !! 44 !! 45 !! 46 !! 47 !! 48
|-
| 
| style="background-color:#FFC0CB" | C || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 49 !! 50 !! 51 !! 52 !! 53 !! 54 !! 55 !! 56
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 57 !! 58 !! 59 !! 60 !! 61 !! 62 !! 63 !! 64
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S || &amp;mdash;
|-
! {{mvar|n}}
! 65 !! 66 !! 67 !! 68 !! 69 !! 70 !! 71 !! 72
|-
| 
| style="background-color:#FFC0CB" | C || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 73 !! 74 !! 75 !! 76 !! 77 !! 78 !! 79 !! 80
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 81 !! 82 !! 83 !! 84 !! 85 !! 86 !! 87 !! 88
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 89 !! 90 !! 91 !! 92 !! 93 !! 94 !! 95 !! 96
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 97 !! 98 !! 99 !! 100 !! 101 !! 102 !! 103 !! 104
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || &amp;mdash;
|-
! {{mvar|n}}
! 105 !! 106 !! 107 !! 108 !! 109 !! 110 !! 111 !! 112
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|-
! {{mvar|n}}
! 113 !! 114 !! 115 !! 116 !! 117 !! 118 !! 119 !! 120
|-
| 
| &amp;mdash; || &amp;mdash; || &amp;mdash; || style="background-color:#98FB98" | S || style="background-color:#98FB98" | S || style="background-color:#FFC0CB" | C || style="background-color:#FFC0CB" | C || style="background-color:#98FB98" | S
|}
{{hidden end}}

For example, 5 is a congruent number because it is the area of a (20/3, 3/2, 41/6) triangle. Similarly, 6 is a congruent number because it is the area of a (3,4,5) triangle. 3 is not a congruent number.

If {{mvar|q}} is a congruent number then {{math|''s''&lt;sup&gt;2&lt;/sup&gt;''q''}} is also a congruent number for any natural number {{mvar|s}} (just by multiplying each side of the triangle by {{mvar|s}}), and vice versa.  This leads to the observation that whether a nonzero rational number {{mvar|q}} is a congruent number depends only on its residue in the [[group (mathematics)|group]]

:&lt;math&gt;\mathbb{Q}^{*}/\mathbb{Q}^{*2}&lt;/math&gt;.

Every residue class in this group contains exactly one [[square-free integer]], and it is common, therefore, only to consider square-free positive integers, when speaking about congruent numbers.

==Congruent number problem==
The question of determining whether a given rational number is a congruent number is called the '''congruent number problem'''.  This problem has not (as of 2016) been brought to a successful resolution. [[Tunnell's theorem]] provides an easily testable criterion for determining whether a number is congruent; but his result relies on the [[Birch and Swinnerton-Dyer conjecture]], which is still unproven.

[[Fermat's right triangle theorem]], named after [[Pierre de Fermat]], states that no [[square number]] can be a congruent number. However, in the form that every [[congruum]] (the difference between consecutive elements in an arithmetic progression of three squares) is non-square, it was already known (without proof) to [[Fibonacci]].&lt;ref&gt;{{citation|title=Number Theory and Its History|first=Øystein|last=Ore|authorlink=Øystein Ore|publisher=Courier Dover Corporation|year=2012|isbn=978-0-486-13643-1|pages=202–203|url=https://books.google.com/books?id=beC7AQAAQBAJ&amp;pg=PA202}}.&lt;/ref&gt; Every congruum is a congruent number, and every congruent number is a product of a congruum and the square of a rational number.&lt;ref&gt;{{citation|first=Keith|last=Conrad|title=The congruent number problem|journal=Harvard College Mathematical Review|url=http://www.thehcmr.org/issue2_2/congruent_number.pdf|volume=2|issue=2|date=Fall 2008|pages=58–73|deadurl=yes|archiveurl=https://web.archive.org/web/20130120090003/http://www.thehcmr.org/issue2_2/congruent_number.pdf|archivedate=2013-01-20|df=}}.&lt;/ref&gt; However, determining whether a number is a congruum is much easier than determining whether it is congruent, because there is a parameterized formula for congrua for which only finitely many parameter values need to be tested.&lt;ref name="ubm"&gt;{{citation|title=The Universal Book of Mathematics: From Abracadabra to Zeno's Paradoxes|first=David|last=Darling|publisher=John Wiley &amp; Sons|year=2004|isbn=978-0-471-66700-1|page=77|url=https://books.google.com/books?id=HrOxRdtYYaMC&amp;pg=PA77}}.&lt;/ref&gt;

==Relation to elliptic curves==
The question of whether a given number is congruent turns out to be equivalent to the condition that a certain [[elliptic curve]] has positive [[rank of an abelian group|rank]].&lt;ref name=Koblitz /&gt;  An alternative approach to the idea is presented below (as can essentially also be found in the introduction to Tunnell's paper).

Suppose {{mvar|a}}, {{mvar|b}}, {{mvar|c}} are numbers (not necessarily positive or rational) which satisfy the following two equations:

:&lt;math&gt;
	\begin{matrix}
		a^2 + b^2 &amp;=&amp; c^2, \\
		\tfrac{1}{2}ab &amp;=&amp; n.
	\end{matrix}
&lt;/math&gt;

Then set {{math|''x'' {{=}} ''n''(''a''+''c'')/''b''}} and
{{math|''y'' {{=}} 2''n''&lt;sup&gt;2&lt;/sup&gt;(''a''+''c'')/''b''&lt;sup&gt;2&lt;/sup&gt;}}.
A calculation shows
:&lt;math&gt;
	y^2 = x^3 -n^2x
	&lt;/math&gt;
and {{mvar|y}} is not 0 (if {{math|''y'' {{=}} 0}} then {{math|''a'' {{=}} -''c''}}, so {{math|''b'' {{=}} 0}}, but {{math|({{frac|1|2}})''ab'' {{=}} ''n''}} is nonzero, a contradiction).

Conversely, if {{mvar|x}} and {{mvar|y}} are numbers which satisfy the above equation and {{mvar|y}} is not 0, set
{{math|''a'' {{=}} (''x''&lt;sup&gt;2&lt;/sup&gt; - ''n''&lt;sup&gt;2&lt;/sup&gt;)/''y''}},
{{math|''b'' {{=}} 2''nx''/''y''}}, and {{math|''c'' {{=}} (''x''&lt;sup&gt;2&lt;/sup&gt; + ''n''&lt;sup&gt;2&lt;/sup&gt;)/''y''}}.  A calculation shows these three numbers
satisfy the two equations for {{mvar|a}}, {{mvar|b}}, and {{mvar|c}} above.

These two correspondences between ({{mvar|a}},{{mvar|b}},{{mvar|c}}) and ({{mvar|x}},{{mvar|y}}) are inverses of each other, so
we have a one-to-one correspondence between any solution of the two equations in
{{mvar|a}}, {{mvar|b}}, and {{mvar|c}} and any solution of the equation in {{mvar|x}} and {{mvar|y}} with {{mvar|y}} nonzero.   In particular,
from the formulas in the two correspondences, for rational {{mvar|n}} we see that {{mvar|a}}, {{mvar|b}}, and {{mvar|c}} are
rational if and only if the corresponding {{mvar|x}} and {{mvar|y}} are rational, and vice versa.
(We also have that {{mvar|a}}, {{mvar|b}}, and {{mvar|c}} are all positive if and only if {{mvar|x}} and {{mvar|y}} are all positive;
notice from the equation {{math|''y''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; - ''xn''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''x''(''x''&lt;sup&gt;2&lt;/sup&gt; - ''n''&lt;sup&gt;2&lt;/sup&gt;)}}
that if {{mvar|x}} and {{mvar|y}} are positive then {{math|''x''&lt;sup&gt;2&lt;/sup&gt; - ''n''&lt;sup&gt;2&lt;/sup&gt;}} must be positive, so the formula for
{{mvar|a}} above is positive.)

Thus a positive rational number {{mvar|n}} is congruent if and only if the equation
{{math|''y''&lt;sup&gt;2&lt;/sup&gt; {{=}} ''x''&lt;sup&gt;3&lt;/sup&gt; - ''n''&lt;sup&gt;2&lt;/sup&gt;''x''}} has a [[rational point]] with {{mvar|y}} not equal to 0.
It can be shown (as a nice application of [[Dirichlet's theorem on arithmetic progressions|Dirichlet's theorem]] on primes in arithmetic progression)
that the only torsion points on this elliptic curve are those with {{mvar|y}} equal to 0, hence the
existence of a rational point with {{mvar|y}} nonzero is equivalent to saying the elliptic curve has positive rank.

==Current progress==
Much work has been done classifying congruent numbers.

For example, it is known&lt;ref&gt;{{citation |author=[[Paul Monsky]] |title=Mock Heegner Points and Congruent Numbers |journal=Mathematische Zeitschrift |volume=204 |issue=1 |year=1990 |pages=45–67 |doi=10.1007/BF02570859}}&lt;/ref&gt; that for  a prime number {{mvar|p}}, the following holds:
*if {{math|''p'' ≡ 3 ([[modular arithmetic|mod]] 8)}}, then {{mvar|p}} is not a congruent number, but 2{{mvar|p}} is a congruent number.
*if {{math|''p'' ≡ 5 (mod 8)}}, then {{mvar|p}} is a congruent number.
*if {{math|''p'' ≡ 7 (mod 8)}}, then {{mvar|p}} and 2{{mvar|p}} are congruent numbers.

It is also known&lt;ref&gt;{{citation
 | last = Tian | first = Ye | authorlink = Tian Ye (mathematician)
 | arxiv = 1210.8231
 | doi = 10.4310/CJM.2014.v2.n1.a4
 | issue = 1
 | journal = Cambridge Journal of Mathematics
 | mr = 3272014
 | pages = 117–161
 | title = Congruent numbers and Heegner points
 | volume = 2
 | year = 2014}}.&lt;/ref&gt; that in each of the congruence classes {{math|5, 6, 7 (mod 8)}}, for any given {{mvar|k}} there are infinitely many square-free congruent numbers with {{mvar|k}} prime factors.

==Notes==
{{reflist|2}}

==References==
*{{citation |last=Alter |first=Ronald |authorlink=Ronald Alter |title=The Congruent Number Problem |journal=American Mathematical Monthly |volume=87 |issue=1 |year=1980 |pages=43–45 |doi=10.2307/2320381 |publisher=Mathematical Association of America |jstor=2320381}}
*{{citation |doi=10.1007/BF02837344 |last=Chandrasekar |first=V. |title=The Congruent Number Problem |journal=Resonance |volume=3 |issue=8 |year=1998 |pages=33–45 |url=http://www.math.rug.nl/~top/Chandrasekar.pdf}}
*{{citation |last=Dickson |first=Leonard Eugene |authorlink=Leonard Eugene Dickson |title=[[History of the Theory of Numbers]] |volume=Volume II: Diophantine Analysis |date=2005 |series=Dover Books on Mathematics |publisher=Dover Publications |isbn=978-0-486-44233-4 |chapter=Chapter XVI}} - see, for a history of the problem.
*{{citation |last=Guy |first=Richard |authorlink=Richard K. Guy |title=Unsolved Problems in Number Theory |series=Problem Books in Mathematics (Book 1) |edition=3rd |date=2004 |publisher=Springer |isbn=978-0-387-20860-2 | zbl=1058.11001}} - Many references are given it in.
* {{citation
  | last = Tunnell
  | first = Jerrold B.
  | authorlink= Jerrold B. Tunnell
  | title = A classical Diophantine problem and modular forms of weight 3/2
  | journal = [[Inventiones Mathematicae]]
  | volume = 72
  | issue = 2
  | pages = 323–334
  | year = 1983
  | doi = 10.1007/BF01389327
  | bibcode = 1983InMat..72..323T
  | url = http://www.digizeitschriften.de/dms/img/?PID=GDZPPN002099403
  }}

==External links==
*{{MathWorld |urlname=CongruentNumber |title=Congruent Number}}
*A short discussion of the current state of the problem with many references can be found in [[Alice Silverberg]]'s [http://www.math.uci.edu/~asilverb/bibliography/pcmibook.ps Open Questions in Arithmetic Algebraic Geometry] (Postscript).
*[http://www.aimath.org/news/congruentnumbers/ A Trillion Triangles] - mathematicians have resolved the first one trillion cases (conditional on the [[Birch and Swinnerton-Dyer conjecture]]).

[[Category:Arithmetic problems of plane geometry]]
[[Category:Elliptic curves]]
[[Category:Number theory]]
[[Category:Triangle geometry]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>r34e7w76zqc1o8qrcyppgg36utlcrmb</sha1>
    </revision>
  </page>
  <page>
    <title>Cylindrical algebraic decomposition</title>
    <ns>0</ns>
    <id>12218154</id>
    <revision>
      <id>808038278</id>
      <parentid>807569144</parentid>
      <timestamp>2017-10-31T14:20:46Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>/* top */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2836">In [[mathematics]], '''cylindrical algebraic decomposition''' ('''CAD''') is a notion, and an [[algorithm]] to compute it, which are fundamental for [[computer algebra]] and [[real algebraic geometry]]. Given a set ''S'' of polynomials in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, a cylindrical algebraic decomposition is a decomposition of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; into connected [[semialgebraic set]]s called ''cells'', on which each polynomial has constant sign, either +, − or 0. To be ''cylindrical'', this decomposition must satisfy the following condition: If 1&amp;nbsp;≤&amp;nbsp;''k''&amp;nbsp;&lt;&amp;nbsp;''n'' and π is the projection from '''R'''&lt;sup&gt;''n''&lt;/sup&gt; onto '''R'''&lt;sup&gt;''n''−''k''&lt;/sup&gt; consisting in removing the ''k'' last coordinates, then for every pair of cells ''c'' and ''d'', one has either π(''c'')&amp;nbsp;=&amp;nbsp;π(''d'') or π(''c'')&amp;nbsp;∩&amp;nbsp;π(''d'')&amp;nbsp;=&amp;nbsp;∅. This implies that the images by π of the cells define a cylindrical decomposition of&amp;nbsp;'''R'''&lt;sup&gt;''n''−''k''&lt;/sup&gt;.

The notion was introduced by [[George E. Collins]] in 1975, together with an [[algorithm]] for computing it.

Collins' algorithm has a [[Analysis of algorithms|computational complexity]] that is [[double exponential function|double exponential]] in ''n''. This is an upper bound, which is reached on most entries. There are also examples for which the minimal number of cells is doubly exponential, showing that every general algorithm for cylindrical algebraic decomposition has a double exponential complexity.

'''CAD''' provides an effective version of [[quantifier elimination]] over the reals, which has a much better computational complexity than that which results from the original proof of [[Tarski–Seidenberg theorem]]. It is efficient enough to be implemented on a computer. It is one of the most important algorithms of computational [[real algebraic geometry]]. Searching to improve Collins algorithm, or to provide algorithms that have a better complexity for subproblems of general interest, is an active field of research.

==Implementations==
* [[Mathematica]]: [https://reference.wolfram.com/mathematica/ref/CylindricalDecomposition.html CylindricalDecomposition]
==References==
*Basu, Saugata; Pollack, Richard; Roy, Marie-Françoise Algorithms in real algebraic geometry. Second edition. Algorithms and Computation in Mathematics, 10. Springer-Verlag, Berlin, 2006. x+662 pp. {{ISBN|978-3-540-33098-1}}; 3-540-33098-4
*Strzebonski, Adam. ''[http://mathworld.wolfram.com/CylindricalAlgebraicDecomposition.html Cylindrical Algebraic Decomposition]''  from [[MathWorld]].
*[http://planning.cs.uiuc.edu/node292.html Cylindrical Algebraic Decomposition] in ''Planning algorithms'' by Steven M. LaValle. Accessed 13 July 2007

[[Category:Algebra]]
[[Category:Real algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>s0itbf6l2hr7x2pxq20hcs1vuej649p</sha1>
    </revision>
  </page>
  <page>
    <title>DeWitt notation</title>
    <ns>0</ns>
    <id>1300778</id>
    <revision>
      <id>603012268</id>
      <parentid>590992373</parentid>
      <timestamp>2014-04-06T15:01:36Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>/* References */Fix [[Help:CS1_errors#format_missing_url|CS1 format parameter errors]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1760">Physics often deals with classical models where the dynamical variables are a collection of functions 
{''φ''&lt;sup&gt;''α''&lt;/sup&gt;}&lt;sub&gt;''α''&lt;/sub&gt; over a d-dimensional space/spacetime [[manifold]] ''M'' where ''α'' is the "[[flavor (particle physics)|flavor]]" index. This involves [[functional (mathematics)|functional]]s over the ''φ'''s, [[functional derivative]]s, [[functional integral]]s, etc. From a functional point of view this is equivalent to working with an infinite-dimensional [[smooth manifold]] where its points are an assignment of a function for each ''α'', and the procedure is in analogy with [[differential geometry]] where the coordinates for a point ''x'' of the manifold ''M'' are ''φ''&lt;sup&gt;''α''&lt;/sup&gt;(''x'').

In the '''DeWitt notation''' (named after [[theoretical physicist]] [[Bryce DeWitt]]), φ&lt;sup&gt;''α''&lt;/sup&gt;(''x'') is written as φ&lt;sup&gt;''i''&lt;/sup&gt; where ''i'' is now understood as an index covering both ''α'' and ''x''.

So, given a smooth functional ''A'', ''A''&lt;sub&gt;,''i''&lt;/sub&gt; stands for the [[functional derivative]]

:&lt;math&gt;A_{,i}[\phi] \ \stackrel{\mathrm{def}}{=}\ \frac{\delta}{\delta \phi^\alpha(x)}A[\phi]&lt;/math&gt;

as a functional of ''φ''. In other words, a "[[1-form]]" field over the infinite dimensional "functional manifold".

In integrals, the [[Einstein summation convention]] is used. Alternatively,

:&lt;math&gt;A^i B_i \ \stackrel{\mathrm{def}}{=}\ \int_M  \sum_\alpha A^\alpha(x) B_\alpha(x) d^dx&lt;/math&gt;

==References==
* {{cite book | first = Claus | last = Kiefer| authorlink = Claus Kiefer |date=April 2007 | title = Quantum gravity |type= hardcover | edition = 2nd | pages = 361 | publisher = Oxford University Press | isbn=978-0-19-921252-1 }}


[[Category:Mathematical notation]]
{{physics-stub}}</text>
      <sha1>qljf9t2o6wd1q85473bv6ec5c9j33wf</sha1>
    </revision>
  </page>
  <page>
    <title>Decoherence-free subspaces</title>
    <ns>0</ns>
    <id>20145865</id>
    <revision>
      <id>843330223</id>
      <parentid>843319369</parentid>
      <timestamp>2018-05-28T12:32:40Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28068">A '''decoherence-free subspace''' ('''DFS''') is a [[Linear subspace|subspace]] of a system's [[Hilbert space]] that is [[Invariant (mathematics)|invariant]] to non-[[Unitarity (physics)|unitary]] dynamics. Alternatively stated, they are a small section of the system Hilbert space where the system is [[Coupling (physics)|decoupled]] from the environment and thus its evolution is completely unitary. DFSs can also be characterized as a special class of [[Decoherence-free subspaces#Quantum error-correcting codes(QECCs)|quantum error correcting codes]]. In this representation they are ''passive'' error-preventing codes since these subspaces are encoded with information that (possibly) won't require any ''active'' stabilization methods. These subspaces prevent destructive environmental interactions by isolating [[quantum information]]. As such, they are an important subject in [[quantum computing]], where ([[Coherence (physics)|coherent]]) control of quantum systems is the desired goal. [[Quantum decoherence|Decoherence]] creates problems in this regard by causing loss of coherence between the [[quantum states]] of a system and therefore the decay of their [[Electromagnetic interference|interference]] terms, thus leading to loss of information from the (open) quantum system to the surrounding environment. Since quantum computers cannot be isolated from their environment (i.e. we cannot have a truly isolated quantum system in the real world) and information can be lost, the study of DFSs is important for the implementation of quantum computers into the real world.

== Background ==

=== Origins ===
The study of DFSs began with a search for structured methods to avoid decoherence in the subject of [[Quantum computing|quantum information processing]] (QIP). The methods involved attempts to identify particular states which have the potential of being unchanged by certain decohering processes (i.e. certain interactions with the environment). These studies started with observations made by G.M. Palma, K-A Suominen, and [[Artur Ekert|A.K. Ekert]], who studied the consequences of pure dephasing on two [[qubits]] that have the same interaction with the environment. They found that two such qubits do not decohere.&lt;ref name="Lidar and Whaley"&gt;[https://arxiv.org/abs/quant-ph/0301032 Decoherence-free subspaces and subsystems] from [[arXiv]]&lt;/ref&gt; Originally the term "sub-decoherence" was used by Palma to describe this situation. Noteworthy is also independent work by [[Martin Bodo Plenio|Martin Plenio]], [[Vlatko Vedral]] and [[Peter Knight (scientist)|Peter Knight]] who constructed an error correcting code with codewords that are invariant under a particular unitary time evolution in spontaneous emission.&lt;ref name="Plenio, Vedral and Knight"&gt;[https://arxiv.org/abs/quant-ph/9603022 Quantum error correction in the presence of spontaneous emission] from [[arXiv]]&lt;/ref&gt;

=== Further development ===
Shortly afterwards, L-M Duan and G-C Guo also studied this phenomenon and reached the same conclusions as Palma, Suominen, and Ekert. However, Duan and Guo applied their own terminology, using "coherence preserving states" to describe states that do not decohere with dephasing. Duan and Guo furthered this idea of combining two qubits to preserve coherence against dephasing, to both collective dephasing and dissipation showing that decoherence is prevented in such a situation. This was shown by assuming knowledge of the system-environment [[coupling constant|coupling strength]]. However, such models were limited since they dealt with the decoherence processes of dephasing and dissipation solely. To deal with other types of decoherences, the previous models presented by Palma, Suominen, and Ekert, and Duan and Guo were cast into a more general  setting by P. Zanardi and M. Rasetti. They expanded the existing mathematical framework to include more general system-environment interactions, such as collective decoherence-the same decoherence process acting on all the states of a quantum system and general [[Hamiltonian (quantum mechanics)|Hamiltonian]]s. Their analysis gave the first formal and general circumstances for the existence of decoherence-free (DF) states, which did not rely upon knowing the system-environment coupling strength. Zanardi and Rasetti called these DF states "error avoiding codes". Subsequently, [[Daniel Lidar|Daniel A. Lidar]] proposed the title "decoherence-free subspace" for the space in which these DF states exist. Lidar studied the strength of DF states against [[Perturbation theory (quantum mechanics)|perturbation]]s and discovered that the coherence prevalent in DF states can be upset by evolution of the system Hamiltonian. This observation discerned another prerequisite for the possible use of DF states for quantum computation. A thoroughly general requirement for the existence of DF states was obtained by Lidar, D. Bacon, and K.B. Whaley expressed in terms of the [[Quantum decoherence#Operator-sum representation|Kraus operator-sum representation]] (OSR). Later, A. Shabani and Lidar generalized the DFS framework relaxing the requirement that the initial state needs to be a DF-state and modified some known conditions for DFS.&lt;ref name="Shabani and Lidar"&gt;[https://arxiv.org/abs/quant-ph/0505051 Theory of Initialization-Free Decoherence-Free Subspaces and Subsystems] from [[arXiv]]&lt;/ref&gt;

=== Recent research ===
A subsequent development was made in generalizing the DFS picture when E. Knill, [[Raymond Laflamme|R. Laflamme]], and L. Viola introduced the concept of a "noiseless subsystem".&lt;ref name="Lidar and Whaley"/&gt; Knill extended to higher-dimensional [[irreducible representation]]s of the [[algebra]] generating the dynamical symmetry in the system-environment interaction. Earlier work on DFSs described DF states as [[Singlet state|singlets]], which are one-dimensional irreducible representations. This work proved to be successful, as a result of this analysis was the lowering of the number of qubits required to build a DFS under collective decoherence from four to three.&lt;ref name="Lidar and Whaley"/&gt; The generalization from subspaces to subsystems formed a foundation for combining most known decoherence prevention and nulling strategies.

==Conditions for the existence of decoherence-free subspaces==

===Hamiltonian formulation===

Consider an ''N''-dimensional quantum system ''S'' coupled to a bath ''B'' and described by the combined system-bath Hamiltonian as follows:

:&lt;math&gt;\hat{H} = \hat{H}_{S}\otimes\hat{I}_{B} + \hat{I}_{S}\otimes\hat{H}_{B} + \hat{H}_{I}&lt;/math&gt; ,

where the interaction Hamiltonian &lt;span style="vertical-align:25%;"&gt;&lt;math&gt;\hat{H}_{I}&lt;/math&gt;&lt;/span&gt; is given in the usual way as

:&lt;math&gt;\hat{H}_{I} = \sum_{i}\hat{S}_{i}\otimes\hat{B}_{i},&lt;/math&gt;

and where &lt;math&gt;\hat{S}_{i}\big(\hat{B}_{i}\big)&lt;/math&gt; act upon the system(bath) only, and &lt;math&gt;\hat{H}_{S} \big(\hat{H}_{B}\big)&lt;/math&gt; is the system(bath) Hamiltonian, and &lt;math&gt;\hat{I}_{S}\big(\hat{I}_{B}\big)&lt;/math&gt; is the identity operator acting on the system (bath).
Under these conditions, the dynamical evolution within &lt;span style="vertical-align:25%;"&gt;&lt;math&gt;\tilde{\mathcal{H}}_{S}\subset\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt;, where &lt;math&gt;\mathcal{H}_{S}&lt;/math&gt; is the system Hilbert space, is completely unitary &lt;math&gt;\forall|\phi\rangle&lt;/math&gt; (all possible bath states) if and only if:

(i)  &lt;math&gt;\hat{S}_{i}|\phi\rangle = s_{i}|\phi\rangle,  s_{i}\in\mathbb{C}&lt;/math&gt;

&lt;math&gt;\forall|\phi\rangle&lt;/math&gt;  that [[Linear span|span]] &lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;  and  &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\forall\hat{S}_{i}\in\mathcal{O}_{SB}(\mathcal{H}_{SB})&lt;/math&gt;&lt;/span&gt;,  the space of bounded system-bath operators on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{SB}&lt;/math&gt;&lt;/span&gt;,

(ii) the system and bath are not coupled at first (i.e. they can be represented as a product state),

(iii) there is no "leakage" of states out of  &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;; that is, the system Hamiltonian &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\hat{H}_{S}&lt;/math&gt;&lt;/span&gt; does not map the states &lt;math&gt;|\phi\rangle&lt;/math&gt; out of &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;.

In other words, if the system begins in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;(i.e. the system and bath are initially decoupled) and the system Hamiltonian &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\hat{H}_{S}&lt;/math&gt;&lt;/span&gt; leaves &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S} = span\big[\big\{|\phi_{k}\rangle\big\}_{k=1}^{N}\big]&lt;/math&gt;&lt;/span&gt; invariant, then &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt; is a DFS if and only if it satisfies (i).

These states are [[Degenerate energy levels|degenerate]] [[Eigenvector|eigenket]]s of  &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\hat{S}_{i}\in\mathcal{O}_{SB}(\mathcal{H}_{SB})&lt;/math&gt;&lt;/span&gt; and thus are distinguishable, hence preserving information in certain decohering processes. Any subspace of the system Hilbert space that satisfies the above conditions is a decoherence-free subspace. However, information can still "leak" out of this subspace if condition (iii) is not satisfied. Therefore, even if a DFS exists under the Hamiltonian conditions, there are still non-unitary actions that can act upon these subspaces and take states out of them into another subspace, which may or may not be a DFS, of the system Hilbert space.

====Operator-sum representation formulation====
Let &lt;span style="vertical-align:20%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}\subset\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt; be an N-dimensional DFS, where &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt; is the system's (the quantum system alone) Hilbert space. The [[Quantum decoherence#Operator-sum representation|Kraus operators]] when written in terms of the N basis states that [[Linear algebra|span]] &lt;span style="vertical-align:5%;"&gt;&lt;math&gt;\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt; are given as:

{{Clarify|date=May 2018}}
:&lt;math&gt;\mathbf{A}_{l} =
\begin{pmatrix}
g_{l}\mathbf{\tilde{U}} &amp; \mathbf{0} \\
\mathbf{0} &amp; \mathbf{\bar{A}}_{l}
\end{pmatrix},\quad g_{l} = \sqrt{a_{j}}\langle k|\mathbf{U}_{C}|j\rangle&lt;/math&gt;

where &lt;span style="vertical-align:20%;"&gt;&lt;math&gt;\mathbf{U}_{C} = \mathit{exp}\big(\frac{-i\mathbf{H}_{C}t}{\hbar}\big)&lt;/math&gt;&lt;/span&gt;  (&lt;span style="vertical-align:5%;"&gt;&lt;math&gt;\mathbf{H}_{C}&lt;/math&gt;&lt;/span&gt; is the combined system-bath Hamiltonian), &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\tilde{U}}&lt;/math&gt;&lt;/span&gt; acts on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}\subset\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt;, and &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\bar{A}}_{l}&lt;/math&gt;&lt;/span&gt; is an arbitrary matrix that acts on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}^{\bot}}_{S}&lt;/math&gt;&lt;/span&gt; (the [[orthogonal complement]] to &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;). Since &lt;span style="vertical-align:-5%;"&gt;&lt;math&gt;\mathbf{\bar{A}}_{l}&lt;/math&gt;&lt;/span&gt; operates on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}^{\bot}}_{S}&lt;/math&gt;&lt;/span&gt;, then it will not create decoherence in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;; however, it can (possibly) create decohering effects in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}^{\bot}}_{S}&lt;/math&gt;&lt;/span&gt;. Consider the basis kets &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|j\rangle\big\}_{j=1}^{N}&lt;/math&gt;&lt;/span&gt; which span &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt; and, furthermore, they fulfill:

:&lt;math&gt;\mathbf{\bar{A}}_{l}|j\rangle = g_{l}\mathbf{\tilde{U}}|j\rangle,\quad \forall{l}.&lt;/math&gt;

&lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\tilde{U}}&lt;/math&gt;&lt;/span&gt; is an arbitrary [[unitary operator]] and may or may not be time-dependent, but it is independent of the indexing variable &lt;math&gt;\mathbf{\mathit{l}}&lt;/math&gt;. The &lt;math&gt;\mathbf{\mathit{g}}_{l}&lt;/math&gt;'s are [[Complex number|complex]] constants. Since &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|j\rangle\big\}_{j=1}^{N}&lt;/math&gt;&lt;/span&gt; spans &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;, then any [[Quantum states#Pure states as rays in a Hilbert space|pure state]] &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;|\psi\rangle\in\mathcal{\tilde{H}}_{S}&lt;/math&gt; can be written as a [[linear combination]] of these basis kets:

:&lt;math&gt;|\psi\rangle = \sum_{j=1}^{N}b_{j}|j\rangle,\quad b_{j}\in\mathbb{C}.&lt;/math&gt;

This state will be decoherence-free; this can be seen by considering the action of &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\bar{A}}_{l}&lt;/math&gt;&lt;/span&gt; on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;|\psi\rangle&lt;/math&gt;&lt;/span&gt;:

:&lt;math&gt;
\begin{align}
\mathbf{\bar{A}}_{l}|\psi\rangle &amp;= \sum_{j=1}^{N}b_{j}(\mathbf{\bar{A}}_{l}|j\rangle)\\
                                 &amp;= \sum_{j=1}^{N}b_{j}(g_{l}\mathbf{\tilde{U}}|j\rangle)\\
\mathbf{\bar{A}}_{l}|\psi\rangle &amp;= g_{l}\mathbf{\tilde{U}}|\psi\rangle.
\end{align}&lt;/math&gt;

Therefore, in terms of the [[density operator]] representation of &lt;math&gt;|\psi\rangle&lt;/math&gt;,  &lt;math&gt;\rho_{initial} = |\psi\rangle\langle\psi|&lt;/math&gt;, the evolution of this state is:

:&lt;math&gt;
\begin{align}\rho_{final} &amp;= \sum_{l}\mathbf{A}_{l}\rho_{initial}\mathbf{A}^{\dagger}_{l}\\
                          &amp;= \sum_{l}g_{l}\mathbf{\tilde{U}}|\psi\rangle\langle\psi|h_{l}\mathbf{\tilde{U}}^{\dagger} \\
                          &amp;= \mathbf{\tilde{U}}|\psi\rangle\langle\psi|\mathbf{\tilde{U}}^{\dagger}.
\end{align}&lt;/math&gt;

The above expression says that &lt;math&gt;\mathbf{\mathit{\rho}}_{final}&lt;/math&gt; is a pure state and that its evolution is unitary, since &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\tilde{U}}&lt;/math&gt;&lt;/span&gt; is unitary. Therefore, ''any'' state in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt; will not decohere since its evolution is governed by a unitary operator and so its dynamical evolution will be completely unitary. Thus &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt; is a decoherence-free subspace.
The above argument can be generalized to an initial arbitrary [[Quantum states#Mixed states|mixed state]] as well.&lt;ref name="Lidar and Whaley"/&gt;

====Semigroup formulation====
This formulation makes use of the [[Quantum decoherence#Semigroup approach|semigroup approach]]. The [[Quantum decoherence#Semigroup approach|Lindblad decohering term]] determines when the dynamics of a quantum system will be unitary; in particular, when &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{L}}_{D}[\rho] = 0&lt;/math&gt;&lt;/span&gt;, where &lt;math&gt;\mathbf{\mathit{\rho}}&lt;/math&gt; is the density operator representation of the state of the system, the dynamics will be decoherence-free.
Let &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|j\rangle\big\}_{j=1}^{N}&lt;/math&gt;&lt;/span&gt; span &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}\subset\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt;, where &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{S}&lt;/math&gt;&lt;/span&gt; is the system's Hilbert space. Under the assumptions that:

*(i) the [[Quantum decoherence#Semigroup approach|noise parameters]] of the coefficient matrix of the Lindblad decohering term are not fine-tuned (i.e. no special assumptions are made about them)
*(ii) there is no dependence on the initial conditions of the initial state of the system

a necessary and sufficient condition for  &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt; to be a DFS is &lt;math&gt;\forall{|j\rangle}&lt;/math&gt;:

:&lt;math&gt;\mathbf{F}_{\alpha}|j\rangle = \lambda_{\alpha}|j\rangle,\quad\forall\alpha.&lt;/math&gt;

The above expression states that ''all'' basis states &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;|j\rangle&lt;/math&gt;&lt;/span&gt; are degenerate eigenstates of the [[Quantum decoherence#Semigroup approach|error generators]] &lt;span style="vertical-align:10;"&gt;&lt;math&gt;\big\{\mathbf{F}_{\alpha}\big\}_{\alpha=1}^{M=N\times{N}}.&lt;/math&gt;&lt;/span&gt; As such, their respective [[Quantum decoherence#Collective dephasing|coherence terms]] do not decohere. Thus states within &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt; will remain mutually distinguishable after a decohering process since their respective [[eigenvalues]] are degenerate and hence identifiable after action under the error generators.

==DFSs as a special class of information-preserving structures (IPS) and quantum error-correcting codes (QECCs)==

===Information-preserving structures (IPS)===
DFSs can be thought of as "encoding" information through its set of states. To see this, consider a ''d''-dimensional open quantum system that is prepared in the state &lt;math&gt;\mathbf{\rho}&lt;/math&gt;-a non-negative (i.e. its eigenvalues are positive), trace-preserving &lt;math&gt;\big(\mathbf{\mathit{Tr}}[\rho]=1\big)&lt;/math&gt;, &lt;math&gt;d\times d&lt;/math&gt; density operator that belongs to the system's [[Hilbert–Schmidt operator|Hilbert–Schmidt]] space, the space of [[bounded operator]]s on &lt;math&gt;\mathcal{H}&lt;/math&gt; &lt;math&gt;\big(\mathcal{B(\mathcal{H})}\big)&lt;/math&gt;. Suppose that this density operator(state) is selected from a set of states &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;S = \big\{\rho_{i}\big\}_{i=1}^{n}\in\mathcal{\tilde{H}}_{S}&lt;/math&gt;&lt;/span&gt;, a DFS of &lt;math&gt;\mathcal{H}_{S}&lt;/math&gt; (the system's Hilbert space) and where &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{n}}&lt;\mathbf{\mathit{d}}&lt;/math&gt;&lt;/span&gt;.
This set of states is called a ''code'', because the states within this set ''encode'' particular kind of information;&lt;ref name="Blume-Kohout, Khoon Ng, Poulin, and Viola"&gt;[https://arxiv.org/abs/0705.4282 The structure of preserved information in quantum processes] from [[arXiv]]&lt;/ref&gt; that is, the set ''S'' encodes information through its states. This information that is contained within &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{S}}&lt;/math&gt;&lt;/span&gt; must be able to be accessed; since the information is encoded in the states in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{S}}&lt;/math&gt;&lt;/span&gt;, these states must be distinguishable to some process, &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; say, that attempts to acquire the information. Therefore, for two states &lt;math&gt;\mathbf{\rho}_{i},\mathbf{\rho}_{j}\in\mathit{S} \big(i\ne j\big)&lt;/math&gt;, the process &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; is ''information preserving'' for these states if the states &lt;math&gt;\mathbf{\rho}_{i},\mathbf{\rho}_{j}&lt;/math&gt; remain ''as'' distinguishable after the process as they were before it. Stated in a more general manner, a code &lt;math&gt;\mathbf{\mathit{S}}&lt;/math&gt; (or DFS) is preserved by a process &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; iff each pair of states  &lt;math&gt;\mathbf{\rho}_{i},\mathbf{\rho}_{j}\in\mathit{S}&lt;/math&gt; is as distinguishable after &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; is applied as they were before it was applied.&lt;ref name="Blume-Kohout, Khoon Ng, Poulin, and Viola"/&gt; A more practical description would be: &lt;math&gt;\mathbf{\mathit{S}}&lt;/math&gt; is preserved by a process &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; if and only if &lt;math&gt;\forall\mathbf{\rho,\rho'}\in\mathit{S}&lt;/math&gt; and &lt;math&gt;\mathit{x}\in\mathbb{R}^{+}&lt;/math&gt;

:&lt;math&gt;\big\|\mathbf{\zeta}\big(\mathbf{\rho}-\mathit{x}\mathbf{\rho'}\big)\big\|_{1} = \big\|\mathbf{\rho}-\mathit{x}\mathbf{\rho'}\big\|_{1}.&lt;/math&gt;

This just says that &lt;math&gt;\mathbf{\zeta}&lt;/math&gt; is a 1:1 trace-distance-preserving map on &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{S}}&lt;/math&gt;&lt;/span&gt;.&lt;ref name="Blume-Kohout, Khoon Ng, Poulin, and Viola"/&gt; In this picture DFSs are sets of states (codes rather) whose ''mutual distinguishability'' is unaffected by a process &lt;math&gt;\mathbf{\zeta}&lt;/math&gt;.

===Quantum error-correcting codes (QECCs)===
Since DFSs can encode information through their sets of states, then they are secure against errors (decohering processes). In this way DFSs can be looked at as a special class of QECCs, where information is encoded into states which can be disturbed by an interaction with the environment but retrieved by some reversal process.&lt;ref name="Lidar and Whaley"/&gt;

Consider a code &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;C = \operatorname{span}\big[\big\{|j_{k}\rangle\big\}\big]&lt;/math&gt;&lt;/span&gt;, which is a subspace of the system Hilbert space, with encoded information given by &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|j_{k}\rangle\big\}&lt;/math&gt;&lt;/span&gt; (i.e. the "codewords"). This code can be implemented to protect against decoherence and thus prevent loss of information in a small section of the system's Hilbert space. The errors are caused by interaction of the system with the environment (bath) and are represented by the Kraus operators.&lt;ref name="Lidar and Whaley"/&gt; After the system has interacted with the bath, the information contained within &lt;math&gt;\mathbf{\mathit{C}}&lt;/math&gt; must be able to be "decoded"; therefore, to retrieve this information a '''recovery operator''' &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{R}&lt;/math&gt;&lt;/span&gt; is introduced. So a QECC is a subspace &lt;math&gt;\mathbf{\mathit{C}}&lt;/math&gt; along with a set of recovery operators &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{\mathbf{R}_{r}\big\}.&lt;/math&gt;&lt;/span&gt;

Let &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{C}}&lt;/math&gt;&lt;/span&gt; be a QECC for the error operators represented by the Kraus operators &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{\mathbf{A}_{l}\big\}&lt;/math&gt;&lt;/span&gt;, with recovery operators &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{\mathbf{R}_{r}\big\}.&lt;/math&gt;&lt;/span&gt; Then &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{C}}&lt;/math&gt;&lt;/span&gt; is a DFS if and only if upon restriction to &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\mathit{C}}&lt;/math&gt;&lt;/span&gt;, then &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{R}_{r}\propto\mathbf{\tilde{U}}_{S}^{\dagger}, \forall{r}&lt;/math&gt;&lt;/span&gt;,&lt;ref name="Lidar and Whaley"/&gt; where &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathbf{\tilde{U}}_{S}^{\dagger}&lt;/math&gt;&lt;/span&gt; is the inverse of the system evolution operator.

In this picture of reversal of quantum operations, DFSs are a special instance of the more general QECCs whereupon restriction to a given a code, the recovery operators become proportional to the inverse of the system evolution operator, hence allowing for unitary evolution of the system.

Notice that the subtle difference between these two formulations exists in the two words ''preserving'' and ''correcting''; in the former case, error-''prevention'' is the method used whereas in the latter case it is error-''correction''. Thus the two formulations differ in that one is a ''passive'' method and the other is an ''active'' method.

==Example of a decoherence-free subspace==

===Collective dephasing===
Consider a two-qubit Hilbert space, spanned by the basis qubits &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|0\rangle_{1}\otimes|0\rangle_{2}, |0\rangle_{1}\otimes|1\rangle_{2}, |1\rangle_{1}\otimes|0\rangle_{2}, |1\rangle_{1}\otimes|1\rangle_{2}\big\}&lt;/math&gt;&lt;/span&gt; which undergo [[Quantum decoherence#Collective dephasing|collective dephasing]]. A random phase &lt;math&gt;\mathbf{\mathit{\phi}}&lt;/math&gt; will be created between these basis qubits; therefore, the qubits will transform in the following way:

:&lt;math&gt;
\begin{align}|0\rangle_{1}\otimes|0\rangle_{2} &amp; \longrightarrow |0\rangle_{1}\otimes|0\rangle_{2} \\
             |0\rangle_{1}\otimes|1\rangle_{2} &amp; \longrightarrow e^{i\phi}|0\rangle_{1}\otimes|1\rangle_{2} \\
             |1\rangle_{1}\otimes|0\rangle_{2} &amp; \longrightarrow e^{i\phi}|1\rangle_{1}\otimes|0\rangle_{2} \\
             |1\rangle_{1}\otimes|1\rangle_{2} &amp; \longrightarrow e^{2i\phi}|1\rangle_{1}\otimes|1\rangle_{2}.
\end{align}&lt;/math&gt;

Under this transformation the basis states &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;|0\rangle_{1}\otimes|1\rangle_{2}, |1\rangle_{1}\otimes|0\rangle_{2}&lt;/math&gt;&lt;/span&gt; obtain the same phase factor &lt;span style="vertical-align:20%;"&gt;&lt;math&gt;\mathbf{\mathit{e}}^{i\phi}&lt;/math&gt;&lt;/span&gt;. Thus in consideration of this, a state &lt;math&gt;|\psi\rangle&lt;/math&gt; can be encoded with this information (i.e. the phase factor) and thus evolve unitarily under this dephasing process, by defining the following encoded qubits:

:&lt;math&gt;
\begin{align} |0_{E}\rangle &amp;= |0\rangle_{1}\otimes|1\rangle_{2} \\
              |1_{E}\rangle &amp;= |1\rangle_{1}\otimes|0\rangle_{2}
\end{align}&lt;/math&gt;.

Since these are basis qubits, then any state can be written as a linear combination of these states; therefore,

:&lt;math&gt;|\psi_{E}\rangle = l|0_{E}\rangle + m|1_{E}\rangle,\quad l,m\in\mathbb{C}.&lt;/math&gt;

This state will evolve under the dephasing process as:

:&lt;math&gt;|\psi_{E}\rangle\longrightarrow l|0\rangle_{1}\otimes e^{i\phi}|1\rangle_{2} + e^{i\phi}m|1\rangle_{1}\otimes|0\rangle_{2} = e^{i\phi}|\psi_{E}\rangle.&lt;/math&gt;

However, the ''overall'' phase for a quantum state is unobservable and, as such, is irrelevant in the description of the state. Therefore, &lt;math&gt;|\psi_{E}\rangle&lt;/math&gt; remains invariant under this dephasing process and hence the basis set &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|0\rangle_{1}\otimes|1\rangle_{2}, |1\rangle_{1}\otimes|0\rangle_{2}\big\}&lt;/math&gt;&lt;/span&gt; is a ''decoherence-free subspace'' of the 4-dimensional Hilbert space. Similarly, the subspaces &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\big\{|0\rangle_{1}\otimes|0\rangle_{2}\big\}, \big\{|1\rangle_{1}\otimes|1\rangle_{2}\big\}&lt;/math&gt;&lt;/span&gt; are also DFSs.

==Alternative: decoherence-free subsystems==
Consider a quantum system with an N-dimensional system Hilbert space &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{C}&lt;/math&gt;&lt;/span&gt; that has a general subsystem decomposition &lt;span style="vertical-align:10%:"&gt;&lt;math&gt;\mathcal{H}_{C} = \oplus_{j=1}^{N}(\otimes_{i=1}^{l_{N}}\mathcal{H}_{ji}).&lt;/math&gt;&lt;/span&gt; The subsystem &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{ji}&lt;/math&gt;&lt;/span&gt; is a '''decoherence-free subsystem''' with respect to a system-environment coupling if every pure state in &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\mathcal{H}_{ji}&lt;/math&gt;&lt;/span&gt; remains unchanged with respect to this subsystem under the OSR evolution. This is true for any possible initial condition of the environment.&lt;ref name="Bacon"&gt;[https://arxiv.org/abs/quant-ph/0305025 Decoherence, Control, and Symmetry in Quantum Computers] from [[arXiv]]&lt;/ref&gt; To understand the difference between a decoherence-free ''subspace'' and a decoherence-free ''subsystem'', consider encoding a single qubit of information into a two-qubit system. This two-qubit system has a 4-dimensional Hilbert space; one method of encoding a single qubit into this space is by encoding information into a subspace that is spanned by two [[orthogonal]] qubits of the 4-dimensional Hilbert space. Suppose information is encoded in the orthogonal state &lt;span style="vertical-align:10%;"&gt;&lt;math&gt;\alpha|0\rangle + \beta|1\rangle&lt;/math&gt;&lt;/span&gt; in the following way:

:&lt;math&gt;\alpha|0\rangle_{1} + \beta|1\rangle_{2}\longrightarrow \alpha|0\rangle_{1}\otimes|1\rangle_{2} + \beta|1\rangle_{1}\otimes|0\rangle_{2}.&lt;/math&gt;

This shows that information has been encoded into a ''subspace'' of the two-qubit Hilbert space. Another way of encoding the same information is to encode ''only'' one of the qubits of the two qubits. Suppose the first qubit is encoded, then the state of the second qubit is completely arbitrary since:

:&lt;math&gt;\alpha|0\rangle_{1} + \beta|1\rangle_{2}\longrightarrow \big(\alpha|0\rangle_{1} + \beta|1\rangle_{2}\big)\otimes|\psi\rangle.&lt;/math&gt;

This mapping is a ''one-to-many'' mapping from the one qubit encoding information to a two-qubit Hilbert space.&lt;ref name="Bacon"/&gt; Instead, if the mapping is to &lt;math&gt;|\psi\rangle&lt;/math&gt;, then it is identical to a mapping from a qubit to a subspace of the two-qubit Hilbert space.

==See also==

* [[Quantum decoherence]]
* [[Quantum measurement]]

==References==

{{reflist}}

{{DEFAULTSORT:Decoherence-Free Subspaces}}
[[Category:Quantum measurement]]
[[Category:Quantum information science]]</text>
      <sha1>1xqe4jholyni82z3173mjyrrv4jmhac</sha1>
    </revision>
  </page>
  <page>
    <title>Diffusion process</title>
    <ns>0</ns>
    <id>1667059</id>
    <revision>
      <id>850311309</id>
      <parentid>819949673</parentid>
      <timestamp>2018-07-15T02:11:43Z</timestamp>
      <contributor>
        <ip>74.85.255.74</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1444">{{for|the marketing term|Diffusion of innovations}}
In [[probability theory]] and [[statistics]], a '''diffusion process''' is a solution to a [[stochastic differential equation]]. It is a continuous-time [[Markov process]] with [[almost surely]] [[continuous function|continuous]] sample paths. [[Brownian motion]], [[reflected Brownian motion]] and [[Ornstein–Uhlenbeck processes]] are examples of diffusion processes.

A sample path of a diffusion process models the trajectory of a particle embedded in a flowing fluid and subjected to random displacements due to collisions with other particles, which is called [[Brownian motion]].  The position of the particle is then random; its [[probability density function]] as a [[function of space and time]] is  governed by an [[advection equation|advection]]-[[diffusion equation]].

== Mathematical definition ==
A ''diffusion process'' is a [[Markov process]] with [[Sample-continuous_process|continuous sample paths]] for which the [[Kolmogorov_equations|Kolmogorov forward equation]] is the [[Fokker-Planck equation]].&lt;ref&gt;{{cite web|title=9. Diffusion processes|url=http://math.nyu.edu/faculty/varadhan/stochastic.fall08/sec10.pdf|format=pdf|accessdate=October 10, 2011}}&lt;/ref&gt;

== See also ==
*[[Diffusion]]
*[[Itô diffusion]]
*[[Jump diffusion]]
*[[Sample-continuous process]]

== References ==
{{Reflist}}

{{Stochastic processes}}
{{probability-stub}}

[[Category:Markov processes]]</text>
      <sha1>g7imrwsgfdtx4dal84p6b5cgf9t9pk0</sha1>
    </revision>
  </page>
  <page>
    <title>Fractal analysis</title>
    <ns>0</ns>
    <id>18745015</id>
    <revision>
      <id>858405377</id>
      <parentid>849741965</parentid>
      <timestamp>2018-09-06T23:20:41Z</timestamp>
      <contributor>
        <username>GoingBatty</username>
        <id>11555324</id>
      </contributor>
      <minor/>
      <comment>/* top */-</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16269">{{for|Modelling graphics using fractals|Fractal modeling}}
'''Fractal analysis''' is assessing [[fractal]] characteristics of [[data]]. It consists of several methods to assign a [[fractal dimension]] and other fractal characteristics to a dataset which may be a theoretical dataset or a pattern or signal extracted from phenomena including natural geometric objects, sound, market fluctuations,&lt;ref name="time series"&gt;
{{cite book 
| last = Peters 
| first = Edgar 
| title = Chaos and order in the capital markets : a new view of cycles, prices, and market volatility 
| publisher = Wiley 
| location = New York  
| year = 1996 
| isbn = 0-471-13938-6 }}&lt;/ref&gt;&lt;ref name=mul2004&gt;{{cite journal | last = Mulligan | first = R. | title = Fractal analysis of highly volatile markets: an application to technology equities| journal = The Quarterly Review of Economics and Finance | year = 2004 | doi=10.1016/S1062-9769(03)00028-0 | volume=44 | pages=155–179}}&lt;/ref&gt;&lt;ref name=kam2014&gt;{{cite journal | last = Kamenshchikov | first = S. | title = Transport Catastrophe Analysis as an Alternative to a Monofractal Description: Theory and Application to Financial Crisis Time Series| journal = Journal of Chaos | year = 2014 | doi=10.1155/2014/346743 | volume=2014 | pages=1–8}}&lt;/ref&gt; heart rates,&lt;ref name="heart"&gt;{{Cite journal | last1 = Tan | first1 = Can Ozan | last2 = Cohen | first2 = Michael A. | last3 = Eckberg | first3 = Dwain L. | last4 = Taylor | first4 = J. Andrew | title = Fractal properties of human heart period variability: Physiological and methodological implications | doi = 10.1113/jphysiol.2009.169219 | journal = The Journal of Physiology | volume = 587 | issue = 15 | pages = 3929–3941 | year = 2009 | pmid =  19528254| pmc = 2746620}}&lt;/ref&gt; frequency domain in [[Electroencephalography]] signals,&lt;ref name="brain1"&gt;{{Cite journal | last1 = Zappasodi | first1 = Filippo | last2 =  Olejarczyk | first2 = Elzbieta | last3 = Marzetti | first3 = Laura | last4 = Assenza | first4 = Giovanni | title = Fractal Dimension of EEG Activity Senses Neuronal Impairment in Acute Stroke | doi = 10.1371/journal.pone.0100199 | journal = PLOS ONE | volume = 9 | issue = 6 | pages = 3929–3941 | year = 2014 | pmid =  24967904| pmc = 4072666| bibcode = 2014PLoSO...9j0199Z }}&lt;/ref&gt;&lt;ref name="brain2"&gt;{{Cite journal | last1 = Hisonothai | first1 = M. | last2 =  Nakagawa | first2 = M. | title = EEG signal classification method based on fractal features and neural network | doi = 10.1109/IEMBS.2008.4650057 | journal = MEDLINE-Annual International Conference of the IEEE Engineering in Medicine and Biology Society | year = 2008 | pmid =  19163560 | volume=2008 | pages=3880–3}}&lt;/ref&gt;    digital images,&lt;ref&gt;Fractal Analysis of Digital Images http://rsbweb.nih.gov/ij/plugins/fraclac/FLHelp/Fractals.htm&lt;/ref&gt; molecular motion, networks,  etc.
Fractal analysis is now widely used in all areas of [[science]].&lt;ref&gt;{{cite journal|title=Fractals: Complex Geometry, Patterns, and Scaling in Nature and Society | url=http://www.worldscinet.com/fractals/fractals.shtml|issn=1793-6543}}&lt;/ref&gt; An important limitation of fractal analysis is that arriving at an empirically determined fractal dimension does not necessarily prove that a pattern is fractal; rather, other [[fractal#characteristics|essential characteristics]] have to be considered.&lt;ref name="Mandelbrot1983"&gt;
{{cite book
|author=Benoît B. Mandelbrot
|title=The fractal geometry of nature
|url=https://books.google.com/books?id=0R2LkE3N7-oC
|accessdate=1 February 2012
|year=1983
|publisher=Macmillan
|isbn=978-0-7167-1186-5}}&lt;/ref&gt;

== Types of fractal analysis ==
Several types of fractal analysis are done, including [[box counting]], [[lacunarity|lacunarity analysis]], [[mass fractal dimension|mass methods]], and [[multifractal analysis]].&lt;ref name="time series"/&gt;&lt;ref name="Mandelbrot1983"/&gt; A common feature of all types of fractal analysis is the need for benchmark patterns against which to assess outputs.&lt;ref name="benchmark"&gt;{{Cite document|title=Digital Images in FracLac |publisher=ImageJ |accessdate=2012-02-08 |url=http://rsbweb.nih.gov/ij/plugins/fraclac/FLHelp/Images.htm |postscript={{inconsistent citations}} |deadurl=bot: unknown |archiveurl=https://www.webcitation.org/65J0FscOz?url=http://rsbweb.nih.gov/ij/plugins/fraclac/FLHelp/Images.htm |archivedate=2012-02-08 |df= }}&lt;/ref&gt; These can be acquired with various types of [[fractal generating software]] capable of generating benchmark patterns suitable for this purpose, which generally differ from software designed to render [[fractal art]].

==Applications==
Applications of fractal analysis include:&lt;ref&gt;{{cite web|url=http://library.thinkquest.org/26242/full/ap/ap.html|title=Applications|accessdate=2007-10-21|deadurl=yes|archiveurl=https://web.archive.org/web/20071012223212/http://library.thinkquest.org/26242/full/ap/ap.html|archivedate=2007-10-12|df=}}&lt;/ref&gt;
{{col-start}}{{col-break}}
* Heart rate analysis&lt;ref name="heart"/&gt;
* Human gait, balance, and activity&lt;ref&gt;{{Cite journal|last=Costa|first=Isis da Silva|last2=Gamundí|first2=Antoni|last3=Miranda|first3=José G. Vivas|last4=França|first4=Lucas G. Souza|last5=Santana|first5=De|last6=Novaes|first6=Charles|last7=Montoya|first7=Pedro|date=2017|title=Altered Functional Performance in Patients with Fibromyalgia|url=http://journal.frontiersin.org/article/10.3389/fnhum.2017.00014/full|journal=Frontiers in Human Neuroscience|language=English|volume=11|doi=10.3389/fnhum.2017.00014|issn=1662-5161}}&lt;/ref&gt;&lt;ref&gt;
{{cite arXiv |last1=França |first1=L. G. S. |last2=Montoya |first2=Pedro |last3=Miranda |first3=J. G. V.|date=2017 |title=On multifractals: a non-linear study of actigraphy data |eprint=1702.03912}}&lt;/ref&gt;
* Diagnostic imaging &lt;ref name="diagnostic imaging" /&gt;
* Cancer research &lt;ref&gt;{{Cite journal | last1 = Kam | first1 = Y. | last2 = Karperien | first2 = A. | last3 = Weidow | first3 = B. | last4 = Estrada | first4 = L. | last5 = Anderson | first5 = A. R. | last6 = Quaranta | first6 = V. | doi = 10.1186/1756-0500-2-130 | title = Nest expansion assay: A cancer systems biology approach to in vitro invasion measurements | journal = BMC Research Notes | volume = 2 | pages = 130 | year = 2009 | pmid =  19594934| pmc =2716356 }}&lt;/ref&gt;
* [[Categorisation|Classification]] of [[histopathology]] slides in [[medicine]]&lt;ref name="medicine"&gt;
{{cite book
|editor1-last = Losa
|editor1-first= Gabriele A.
|editor2-last= Nonnenmacher
|editor2-first= Theo F.
|title=Fractals in biology and medicine
|url=https://books.google.com/books?id=t9l9GdAt95gC
|accessdate=1 February 2012
|year=2005
|publisher=Springer
|isbn=978-3-7643-7172-2}}&lt;/ref&gt;
* [[Fractal landscape]] or [[Coast]]line complexity&lt;ref name="Mandelbrot1983"/&gt;&lt;ref name="coastline"&gt;{{Cite journal | last1 = Mandelbrot | first1 = B. | title = How Long is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension | doi = 10.1126/science.156.3775.636 | journal = Science | volume = 156 | issue = 3775 | pages = 636–638 | year = 1967 | pmid =  17837158| pmc = |bibcode = 1967Sci...156..636M }}&lt;/ref&gt;
* [[Electrical Engineering]]&lt;ref name="electrical engineering"&gt;
{{Cite journal | last1 = Li | first1 = H. | title = Fractal analysis of side channels for breakdown structures in XLPE cable insulation | doi = 10.1007/s10854-012-0988-y | journal = J Mater Sci: Mater Electron | volume = 24 | pages = 1640–1643 | year = 2013 | publisher = Springer Science | url=http://download.springer.com/static/pdf/909/art%253A10.1007%252Fs10854-012-0988-y.pdf }}&lt;/ref&gt;
* Enzyme/enzymology ([[Michaelis-Menten kinetics]])&lt;ref name="ReuveniGranek2008"&gt;{{cite journal|last1=Reuveni|first1=Shlomi|last2=Granek|first2=Rony|last3=Klafter|first3=Joseph|title=Proteins: Coexistence of Stability and Flexibility|journal=Physical Review Letters|volume=100|issue=20|year=2008|issn=0031-9007|doi=10.1103/PhysRevLett.100.208101|bibcode=2008PhRvL.100t8101R}}&lt;/ref&gt;
* [[Algorithmic composition|Generation of new music]]
* [[Fractal art|Generation of various art forms]]
* [http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=9012687&amp;fileId=S1473550413000177 Detecting ‘life as we don't know it’ by fractal analysis]
*[[Search and rescue]]&lt;ref name="search and rescue"&gt;{{cite journal| title=An Algorithmic Approach to Generate After-disaster Test Fields for Search and Rescue Agents| author=Panteha Saeedi, and Soren A. Sorensen | journal=Proceedings of the World Congress on Engineering 2009 |pages=93–98 | isbn=978-988-17-0125-1|url=http://www.iaeng.org/publication/WCE2009/WCE2009_pp93-98.pdf}}&lt;/ref&gt;
* [[Signal (information theory)|Signal]] and [[Fractal compression|image compression]]
{{Col-break}}{{col-break}}
* Urban growth&lt;ref name="Chen2011"&gt;{{Cite journal | last1 = Chen | first1 = Yanguang &lt;!-- editor is irrelevant here| editor1-last = Hernández Montoya | editor1-first = Alejandro Raúl --&gt;| title = Modeling Fractal Structure of City-Size Distributions Using Correlation Functions | doi = 10.1371/journal.pone.0024791 | journal = PLoS ONE | volume = 6 | issue = 9 | pages = e24791 | year = 2011 | pmid = 21949753 | pmc = 3176775|arxiv = 1104.4682 |bibcode = 2011PLoSO...624791C }}&lt;/ref&gt;
*[[Neuroscience]]&lt;ref name="neuroscience"&gt;{{Cite journal | last1 = Karperien | first1 = Audrey L. | last2 = Jelinek | first2 = Herbert F. | last3 = Buchan | first3 = Alastair M. | doi = 10.1142/S0218348X08003880 | title = Box-Counting Analysis of Microglia Form in Schizophrenia, Alzheimer's Disease and Affective Disorder | journal = Fractals | volume = 16 | issue = 2 | pages = 103–107 | year = 2008 | pmid =  | pmc = }}&lt;/ref&gt;&lt;ref&gt;
{{cite arXiv |last1=França |first1=L. G. S. |last2=Miranda |first2=J. G. V. |last3=Leite |first3=M. | last4=Sharma |first4=N. K. |last5=Walker |first5=M. C. |last6=Lemieux |first6=L. |last7=Wang |first7=Y.|date=2018 |title=Fractal and multifractal properties of electrographic recordings of human brain activity |eprint=1806.03889}}&lt;/ref&gt;&lt;ref name="cerebellum"&gt;{{Cite journal | last1 = Liu | first1 = Jing Z. | last2 = Zhang | first2 = Lu D. | last3 = Yue | first3 = Guang H. | doi = 10.1016/S0006-3495(03)74817-6 | title = Fractal Dimension in Human Cerebellum Measured by Magnetic Resonance Imaging | journal = Biophysical Journal | volume = 85 | issue = 6 | pages = 4041–4046 | year = 2003 | pmid = 14645092 | pmc = 1303704|bibcode = 2003BpJ....85.4041L }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Nikolić | first1 = D. | last2 = Moca | first2 = V.V. | last3 = Singer | first3 = W. | last4 = Mureşan | first4 = R.C. | year = 2008 | title = Properties of multivariate data investigated by fractal dimensionality | url = | journal = Journal of Neuroscience Methods | volume = 172 | issue = 1| pages = 27–33 | doi=10.1016/j.jneumeth.2008.04.007}}&lt;/ref&gt;
*[[Diagnostic imaging]]&lt;ref name="diagnostic imaging"&gt;{{Cite journal 
| last1 = Karperien | first1 = Audrey 
| last2 = Jelinek | first2 = Herbert F. 
| last3 = Leandro | first3 = Jorge de Jesus Gomes
| last4 = Soares | first4 = João V. B. 
| last5 = Cesar Jr | first5 = Roberto M. 
| last6 = Luckie | first6 = Alan 
| title = Automated detection of proliferative retinopathy in clinical practice 
| journal = Clinical ophthalmology (Auckland, N.Z.) 
| volume = 2 
| issue = 1 
| pages = 109–122 
| year = 2008 
| pmid = 19668394 
| pmc = 2698675
| doi = 10.2147/OPTH.S1579
}}&lt;/ref&gt;
*[[Pathology]]&lt;ref name="pathology"&gt;{{Cite journal 
| last1 = Smith | first1 = Robert F. 
| last2 = Mohr | first2 = David N. 
| last3 = Torres | first3 = Vicente E. 
| last4 = Offord | first4 = Kenneth P. 
| last5 = Melton III | first5 = L. Joseph 
| title = Renal insufficiency in community patients with mild asymptomatic microhematuria 
| journal = Mayo Clinic Proceedings 
| volume = 64 
| issue = 4 
| pages = 409–414 
| year = 1989 
| pmid = 2716356 | doi=10.1016/s0025-6196(12)65730-9
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Al-Kadi O.S, Watson D.|title=Texture Analysis of Aggressive and non-Aggressive Lung Tumor CE CT Images|url=http://sro.sussex.ac.uk/1919/1/tbme.pdf| journal=IEEE Transactions on Biomedical Engineering|volume=55 |issue=7|pages=1822–1830 |year=2008|doi=10.1109/tbme.2008.919735|pmid=18595800}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Landini | first1 = Gabriel | title = Fractals in microscopy | doi = 10.1111/j.1365-2818.2010.03454.x | journal = Journal of Microscopy | volume = 241 | issue = 1 | pages = 1–8 | year = 2011 | pmid =  21118245| pmc = }}&lt;/ref&gt;
*[[Geology]]&lt;ref&gt;{{Cite journal | last1 = Cheng | first1 = Qiuming | authorlink = Qiuming Cheng| title = Multifractal Modeling and Lacunarity Analysis | journal = Mathematical Geology | volume = 29 | issue = 7 | pages = 919–932 | doi = 10.1023/A:1022355723781 | year = 1997 | pmid =  | pmc = }}&lt;/ref&gt;
*[[Geography]]&lt;ref name="Chen2011" /&gt;
*[[Archaeology]]&lt;ref name = "archaeology"&gt;{{Cite journal 
| last1 = Burkle-Elizondo | first1 = Gerardo 
| last2 = Valdéz-Cepeda | first2 = Ricardo David 
| title = Fractal analysis of Mesoamerican pyramids 
| journal = Nonlinear dynamics, psychology, and life sciences 
| volume = 10 
| issue = 1 
| pages = 105–122 
| year = 2006 
| pmid = 16393505
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Brown | first1 = Clifford T. | last2 = Witschey | first2 = Walter R. T. | last3 = Liebovitch | first3 = Larry S. | title = The Broken Past: Fractals in Archaeology | doi = 10.1007/s10816-005-2396-6 | journal = Journal of Archaeological Method and Theory | volume = 12 | pages = 37–78 | year = 2005 }}&lt;/ref&gt;
* [[Seismology]]&lt;ref name="seismology"&gt;{{Cite journal | last1 = Vannucchi | first1 = Paola | last2 = Leoni | first2 = Lorenzo | doi = 10.1016/j.epsl.2007.07.056 | title = Structural characterization of the Costa Rica décollement: Evidence for seismically-induced fluid pulsing | journal = Earth and Planetary Science Letters | volume = 262 | issue = 3–4 | pages = 413–428 | year = 2007 | pmid =  | pmc = |bibcode = 2007E&amp;PSL.262..413V }}&lt;/ref&gt;&lt;ref&gt;
{{cite book
|pages=128–140
|title=Critical phenomena in natural sciences: chaos, fractals, self-organization, and disorder : concepts and tools
|author=Didier Sornette
|year=2004
|publisher=Springer
|isbn=978-3-540-40754-6}}&lt;!--|accessdate=2011-02-05--&gt;&lt;/ref&gt;
* [http://fr.arxiv.org/abs/0904.0780 Wave propagation in self-similar (fractal) media]
* [[Fractal in soil mechanics|Soil studies]]&lt;ref name="soil"&gt;{{Cite journal | last1 = Hu | first1 = Shougeng | last2 = Cheng | first2 = Qiuming | last3 = Wang | first3 = Le | last4 = Xie | first4 = Shuyun | title = Multifractal characterization of urban residential land price in space and time | doi = 10.1016/j.apgeog.2011.10.016 | journal = Applied Geography | volume = 34 | pages = 161–170 | year = 2012 | pmid =  | pmc = }}&lt;/ref&gt;
{{col-break}}
* [[Game design|Computer and video game design]], especially [[computer graphics]] for [[life|organic]] environments and as part of [[procedural generation]]
* Fractography and [[fracture mechanics]]
* [[Fractal antenna]]s &amp;mdash; Small size antennas using fractal shapes
* [[SAXS|Small angle scattering theory of fractally rough systems]]
* [[T-shirt]]s and other [[fashion]]
* Generation of patterns for camouflage, such as [[MARPAT]]
* [[Digital sundial]]
* [[Technical analysis]] of price series (see [[Elliott wave principle]])
* [http://www.brotherstechnology.com/math/fractal-music.html Fractal analysis in music]&lt;ref name="music"&gt;{{Cite journal | last1 = Brothers | first1 = Harlan J. | doi = 10.1142/S0218348X0700337X | title = Structural Scaling in [[Cello Suites (Bach)|Bach's Cello Suite No. 3]] | journal = Fractals | volume = 15 | pages = 89–95 | year = 2007 | pmid =  | pmc = }}&lt;/ref&gt;

{{col-end}}

==See also==
*[[Multifractal]]
*[[Rescaled range]]

==References==
&lt;references /&gt;

==Further reading==
*[http://rsb.info.nih.gov/ij/plugins/fraclac/FLHelp/Fractals.htm Fractals and Fractal Analysis]
*[http://www.fch.vutbr.cz/lectures/imagesci/download_ejournal/01_O.Zmeskal.pdf Fractal analysis]
*[http://www.trusoft.netmegs.com/ Benoit - Fractal Analysis Software]
*[http://www.physionet.org/tutorials/fmnc/index.shtml Fractal Analysis Methods for Human Heartbeat and Gait Dynamics]

{{Fractals}}

[[Category:Chaos theory]]
[[Category:Dynamical systems]]
[[Category:Dimension theory]]
[[Category:Fractals]]</text>
      <sha1>ozz1ehjp5lvwdwjfh78r0ss6j7k6mpd</sha1>
    </revision>
  </page>
  <page>
    <title>Fraction (mathematics)</title>
    <ns>0</ns>
    <id>1704824</id>
    <revision>
      <id>871403787</id>
      <parentid>871403763</parentid>
      <timestamp>2018-11-30T20:47:03Z</timestamp>
      <contributor>
        <username>Philipnelson99</username>
        <id>22045319</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/81.107.83.121|81.107.83.121]] ([[User talk:81.107.83.121|talk]]) ([[WP:HG|HG]]) (3.4.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58855">[[File:Cake quarters.svg|thumb|A cake with one quarter (one fourth) removed. The remaining three fourths are shown. Dotted lines indicate where the cake may be cut in order to divide it into equal parts. Each fourth of the cake is denoted by the fraction {{sfrac|1|4}}.]]

A '''fraction''' (from [[Latin]] ''{{lang|la|fractus}}'', "broken") represents a part of a whole or, more generally, any number of equal parts. When spoken in everyday English, a fraction describes how many parts of a certain size there are, for example, one-half, eight-fifths, three-quarters. A ''common'', ''vulgar'', or ''simple'' fraction (examples: &lt;math&gt;\tfrac{1}{2}&lt;/math&gt; and 17/3) consists of an [[integer]] numerator displayed above a line (or before a slash), and a non-zero integer denominator, displayed below (or after) that line.
Numerators and denominators are also used in fractions that are not ''common'', including compound fractions, complex fractions, and mixed numerals.

We begin with positive common fractions, where the numerator and denominator are [[natural number]]s. The numerator represents a number of equal parts, and the denominator indicates how many of those parts make up a unit or a whole. The denominator cannot be zero because zero parts can never make up a whole. For example, in the fraction 3/4, the numerator, 3, tells us that the fraction represents 3 equal parts, and the denominator, 4, tells us that 4 parts make up a whole. The picture to the right illustrates &lt;math&gt;\tfrac{3}{4}&lt;/math&gt; or {{frac|3|4}} of a cake.

A common fraction is a numeral which represents a [[rational number]]. That same number can also be represented as a decimal, a percent, or with a negative exponent. For example, 0.01, 1%, and 10&lt;sup&gt;−2&lt;/sup&gt; all equal the fraction 1/100. An integer such as the number 7 can be thought of as having an implicit denominator of one: 7 equals 7/1.

Other uses for fractions are to represent [[ratio]]s and [[division (mathematics)|division]].&lt;ref&gt;H. Wu, "The Mis-Education of Mathematics Teachers", ''Notices of the American Mathematical Society'', Volume 58, Issue 03 (March 2011), [http://www.ams.org/notices/201103/rtx110300372p.pdf#page374 page 374]
&lt;/ref&gt;
Thus the fraction {{sfrac|3|4}} is also used to represent the ratio 3:4 (the ratio of the part to the whole) and the division 3 ÷ 4 (three divided by four). The non-zero denominator in the case using a fraction to represent division is an example of the rule that [[division by zero]] is undefined.

We can also write negative fractions, which represent the opposite of a positive fraction. For example if {{sfrac|1|2}} represents a half dollar profit, then −{{sfrac|1|2}} represents a half dollar loss. Because of the rules of division of signed numbers, which require that, for example, negative divided by positive is negative, −{{sfrac|1|2}}, {{sfrac|-1|2}}, {{sfrac|1|-2}}, and −{{sfrac|-1|-2}} all represent the same fraction, negative one-half. Because negative divided by negative is positive, {{sfrac|-1|-2}} represents positive one-half.

In mathematics the set of all numbers that can be expressed in the form a/b, where a and b are [[integer]]s and b is not zero, is called the set of rational numbers and is represented by the symbol '''Q''', which stands for [[quotient]]. The test for a number being a rational number is that it can be written in that form (i.e., as a common fraction). However, the word ''fraction'' is also used to describe mathematical expressions that are not rational numbers, for example [[algebraic fraction]]s (quotients of algebraic expressions), and expressions that contain [[irrational number]]s, such as {{sqrt|2}}/2 (see [[square root of 2]]) and π/4 (see [[proof that π is irrational]]).

==Vocabulary&lt;!--'Fraction bar' redirects here--&gt;==
{{See also|List of numbers#Fractional numbers|English numerals#Fractions and decimals}}
In a fraction, the number of equal parts being described is the '''numerator''' (from [[Latin]] ''{{lang|la|numerātor}}'', "counter" or "numberer"), and the type or variety of the parts is the '''denominator''' (from [[Latin]] ''{{lang|la|dēnōminātor}}'', "thing that names or designates").&lt;!--both boldface per WP:R#PLA--&gt;&lt;ref name=schwartzman&gt;{{cite book |last=Schwartzman|first=Steven |title=The Words of Mathematics: An Etymological Dictionary of Mathematical Terms Used in English, |publisher=Mathematical Association of America |date=1994|isbn=978-0883855119 }}&lt;/ref&gt; As an example, the fraction {{frac|8|5}} amounts to eight parts, each of which is of the type named "fifth." In terms of [[division (math)|division]], the numerator corresponds to the [[division (math)|dividend]], and the denominator corresponds to the [[division (math)|divisor]].

Informally, the numerator and denominator may be distinguished by placement alone but in formal contexts they are always separated by a '''fraction bar'''&lt;!--boldface per WP:R#PLA--&gt;. The fraction bar may be horizontal (as in {{sfrac|1|3}}), oblique (as in 1/5), or diagonal (as in {{frac|1|9}}).&lt;ref name=ambrose/&gt; These marks are respectively known as the horizontal bar, the [[slash mark|slash]] ([[American English|US]]) or [[oblique stroke|stroke]] ([[British English|UK]]), the [[division slash]], and the [[fraction slash]].{{refn|group=n|Some typographers such as [[Robert Bringhurst|Bringhurst]] mistakenly distinguish the slash {{angle brackets|[[/]]}} as the ''[[wikt:virgule|virgule]]'' and the fraction slash {{angle brackets|[[⁄]]}} as the ''[[solidus mark|solidus]]'',&lt;ref name="bringhurst"&gt;{{cite book |last=Bringhurst |first=Robert |year=2002 |title=The Elements of Typographic Style |edition=3rd |publisher=Hartley &amp; Marks |isbn=978-0-88179-206-5 |pages=81–82 |contribution=5.2.5: Use the Virgule with Words and Dates, the Solidus with Split-level Fractions |location=[[Point Roberts, Washington|Point Roberts]]}}&lt;/ref&gt; although in fact both are synonyms for the standard slash.&lt;ref name=verg&gt;{{cite encyclopedia |encyclopedia=Oxford English Dictionary |edition=1st |title=virgule, ''n.'' |date=1917 |location=Oxford |publisher=Oxford University Press }}&lt;/ref&gt;&lt;ref name=oedsolid&gt;{{cite encyclopedia |encyclopedia=Oxford English Dictionary |edition=1st |title=solidus, ''n.&lt;sup&gt;1&lt;/sup&gt;'' |date=1913 |location=Oxford |publisher=Oxford University Press }}&lt;/ref&gt;}} In [[typography]], horizontal fractions are also known as "[[en (typography)|en]]" or "[[en dash|nut]] fractions" and diagonal fractions as "[[em (typography)|em]] fractions", based on the width of a line they take up.&lt;ref name=ambrose&gt;{{cite book |last=Ambrose |first=Gavin |author2=Paul Harris |display-authors=1 |ref={{harvid|Ambrose &amp; al.}} |p=[https://books.google.co.jp/books?id=IW9MAQAAQBAJ&amp;pg=PA74 74] |url=https://books.google.co.jp/books?id=IW9MAQAAQBAJ&amp;printsec=frontcover |title=The Fundamentals of Typography, |edition=2nd |publisher=AVA Publishing |location=Lausanne |date=2006 |isbn=978-2-940411-76-4 }}.&lt;/ref&gt;

The denominators of English fractions are generally expressed as [[Ordinal number (linguistics)#Variations|ordinal number]]s, in the plural if the numerator is not one. (For example, {{frac|2|5}} and {{frac|3|5}} are both read as a number of "fifths".) Exceptions include the denominator 2, which is always read "half" or "halves", the denominator 4, which may be alternatively expressed as "quarter"/"quarters" or as "fourth"/"fourths", and the denominator 100, which may be alternatively expressed as "hundredth"/"hundredths" or "[[percent]]". When the denominator is 1, it may be expressed in terms of "wholes" but is more commonly ignored, with the numerator read out as a whole number. (For example, {{sfrac|3|1}} may be described as "three wholes" or as simply "three".) When the numerator is one, it may be omitted. (For example, "a tenth" or "each quarter".)

The entire fraction may be expressed as a single composition, in which case it is hyphenated, or as a number of fractions with a numerator of one, in which case they are not. (For example, "two-fifths" is the fraction {{sfrac|2|5}} and "two fifths" is the same fraction understood as 2 instances of {{fract|1|5}}.) Fractions should always be hyphenated when used as adjectives. Alternatively, a fraction may be described by reading it out as the numerator "over" the denominator, with the denominator expressed as a [[cardinal number]]. (For example, {{sfrac|3|1}} may also be expressed as "three over one".) The term "over" is used even in the case of solidus fractions, where the numbers are placed left and right of a [[slash mark]]. (For example, ½ may be read "one-half", "one half", or "one over two".) Fractions with large denominators that are ''not'' powers of ten are often rendered in this fashion (e.g., {{sfrac|1|117}} as "one over one hundred seventeen") while those with denominators divisible by ten are typically read in the normal ordinal fashion (e.g., {{sfrac|6|1000000}} as "six-millionths", "six millionths", or "six one-millionths").

==Forms of fractions==
===Simple, common, or vulgar fractions===
A '''simple fraction''' (also known as a '''common fraction''' or '''vulgar fraction''') is a [[rational number]] written as ''a''/''b'' or &lt;math&gt;\tfrac{a}{b}&lt;/math&gt;, where ''a'' and ''b'' are both [[integers]].&lt;ref&gt;{{MathWorld |title=Common Fraction |id=CommonFraction}}&lt;/ref&gt;
As with other fractions, the denominator (''b'') cannot be zero. Examples include &lt;math&gt;\tfrac{1}{2}&lt;/math&gt;, &lt;math&gt;-\tfrac{8}{5}&lt;/math&gt;, &lt;math&gt;\tfrac{-8}{5}&lt;/math&gt;, &lt;math&gt;\tfrac{8}{-5}&lt;/math&gt;, and 3/17.
''Simple fractions'' can be positive or negative, proper, or improper (see below). Compound fractions, complex fractions, mixed numerals, and decimals (see below) are not ''simple fractions'', though, unless irrational, they can be evaluated to a simple fraction.
*A [[unit fraction]] is a common fraction with a numerator of 1, e.g. &lt;math&gt;\tfrac{1}{7}&lt;/math&gt;. Unit fractions can also be expressed using negative exponents, as in 2&lt;sup&gt;−1&lt;/sup&gt;, which represents 1/2, and 2&lt;sup&gt;−2&lt;/sup&gt;, which represents 1/(2&lt;sup&gt;2&lt;/sup&gt;) or 1/4.
*A [[Dyadic rational|dyadic fraction]] is a common fraction in which the denominator is a [[power of two]], e.g. &lt;math&gt;\tfrac{1}{8}=\tfrac{1}{2^3}&lt;/math&gt;.

===Proper and improper fractions===
Common fractions can be classified as either proper or improper. When the numerator and the denominator are both positive, the fraction is called proper if the numerator is less than the denominator, and improper otherwise.&lt;ref&gt;{{cite web|url=http://www.worldwidewords.org/qa/qa-vul1.htm|title=World Wide Words: Vulgar fractions|work=World Wide Words|accessdate=2014-10-30}}&lt;/ref&gt;&lt;ref&gt;{{MathWorld |title=Improper Fraction |id=ImproperFraction}}&lt;/ref&gt; In general, a common fraction is said to be a '''proper fraction''' if the [[absolute value]] of the fraction is strictly less than one—that is, if the fraction is greater than −1 and less than 1.&lt;ref&gt;{{cite web|url=http://mathforum.org/library/drmath/view/65128.html|title=Math Forum – Ask Dr. Math:Can Negative Fractions Also Be Proper or Improper?|author=Laurel|date=31 March 2004|publisher=|accessdate=2014-10-30}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.necompact.org/ea/gle_support/Math/resources_number/prop_fraction.htm|title=New England Compact Math Resources|publisher=}}&lt;/ref&gt;
It is said to be an '''improper fraction''', or sometimes '''top-heavy fraction''',&lt;ref&gt;{{cite book|last1=Greer|first1=A.|title=New comprehensive mathematics for 'O' level|date=1986|publisher=Thornes|location=Cheltenham|isbn=9780859501590|page=5|edition=2nd ed., reprinted.|url=https://books.google.com/books?id=wX2dxeDahAwC&amp;pg=PA5|accessdate=2014-07-29}}&lt;/ref&gt; if the absolute value of the fraction is greater than or equal to 1. Examples of proper fractions are 2/3, –3/4, and 4/9; examples of improper fractions are 9/4, –4/3, and 3/3.

===Reciprocals and the "invisible denominator"===
The '''reciprocal''' of a fraction is another fraction with the numerator and denominator exchanged. The reciprocal of &lt;math&gt;\tfrac{3}{7}&lt;/math&gt;, for instance, is &lt;math&gt;\tfrac{7}{3}&lt;/math&gt;. The product of a fraction and its reciprocal is 1, hence the reciprocal is the [[multiplicative inverse]] of a fraction. The reciprocal of a proper fraction is improper, and the reciprocal of an improper fraction not equal to 1, that is, numerator and denominator are not equal, is a proper fraction.

When the numerator and denominator of a fraction are equal (&lt;math&gt;\tfrac{7}{7}&lt;/math&gt;, for example), its value is 1, and the fraction therefore is improper. Its reciprocal also has the value 1, and is improper, too.

Any integer can be written as a fraction with the number one as denominator. For example, 17 can be written as &lt;math&gt;\tfrac{17}{1}&lt;/math&gt;, where 1 is sometimes referred to as the ''invisible denominator''. Therefore, every fraction or integer, except for zero, has a reciprocal. The reciprocal of 17 is &lt;math&gt;\tfrac{1}{17}&lt;/math&gt;.

===Ratios===
A [[ratio]] is a relationship between two or more numbers that can be sometimes expressed as a fraction. Typically, a number of items are grouped and compared in a ratio, specifying numerically the relationship between each group. Ratios are expressed as "group 1 to group 2 ... to group ''n''". For example, if a car lot had 12 vehicles, of which

* 2 are white,
* 6 are red, and
* 4 are yellow,

then the ratio of red to white to yellow cars is 6 to 2 to 4. The ratio of yellow cars to white cars is 4 to 2 and may be expressed as 4:2 or 2:1.

A ratio is often converted to a fraction when it is expressed as a ratio to the whole. In the above example, the ratio of yellow cars to all the cars on the lot is 4:12 or 1:3. We can convert these ratios to a fraction and say that 4/12 of the cars or ⅓ of the cars in the lot are yellow. Therefore, if a person randomly chose one car on the lot, then there is a one in three chance or [[probability]] that it would be yellow.

===Decimal fractions and percentages===
A '''[[decimal fraction]]''' is a fraction whose denominator is not given explicitly, but is understood to be an integer power of ten. Decimal fractions are commonly expressed using decimal notation in which the implied denominator is determined by the number of [[Numerical digit|digit]]s to the right of a [[decimal separator]], the appearance of which (e.g., a period, a raised period (•), a comma) depends on the locale (for examples, see [[Decimal separator#Hindu–Arabic numeral system|decimal separator]]). Thus for 0.75 the numerator is 75 and the implied denominator is 10 to the second power, ''viz.'' 100, because there are two digits to the right of the decimal separator. In decimal numbers greater than 1 (such as 3.75), the [[fractional part]] of the number is expressed by the digits to the right of the decimal (with a value of 0.75 in this case). 3.75 can be written either as an improper fraction, 375/100, or as a mixed number, &lt;math&gt;3\tfrac{75}{100}&lt;/math&gt;.

Decimal fractions can also be expressed using [[scientific notation]] with negative exponents, such as {{val|6.023|e=-7}}, which represents 0.0000006023. The {{val|e=-7}} represents a denominator of {{val|e=7}}. Dividing by {{val|e=7}} moves the decimal point 7 places to the left.

Decimal fractions with infinitely many digits to the right of the decimal separator represent an [[infinite series]]. For example, {{sfrac|1|3}} = 0.333... represents the infinite series 3/10 + 3/100 + 3/1000 + ... .

Another kind of fraction is the [[percentage]] (Latin ''per centum'' meaning "per hundred", represented by the symbol %), in which the implied denominator is always 100. Thus, 51% means 51/100. Percentages greater than 100 or less than zero are treated in the same way, e.g. 311% equals 311/100, and −27% equals −27/100.

The related concept of ''[[permille]]'' or ''parts per thousand'' (ppt) has an implied denominator of 1000, while the more general [[parts-per notation]], as in 75 ''parts per million'' (ppm), means that the proportion is 75/1,000,000.

Whether common fractions or decimal fractions are used is often a matter of taste and context. Common fractions are used most often when the denominator is relatively small. By [[mental calculation]], it is easier to multiply 16 by 3/16 than to do the same calculation using the fraction's decimal equivalent (0.1875). And it is more [[accurate]] to multiply 15 by 1/3, for example, than it is to multiply 15 by any decimal approximation of one third. Monetary values are commonly expressed as decimal fractions with denominator 100, i.e., with two decimals, for example $3.75. However, as noted above, in pre-decimal British currency, shillings and pence were often given the form (but not the meaning) of a fraction, as, for example 3/6 (read "three and six") meaning 3 shillings and 6 pence, and having no relationship to the fraction 3/6.

==={{anchor|Mixed numbers}}Mixed numbers===
A '''mixed numeral''' (also called a ''mixed fraction'' or ''mixed number'') is a traditional denotation of the sum of a non-zero integer and a proper fraction (having the same sign). It is used primarily in measurement: &lt;math&gt;2\tfrac{3}{16}&lt;/math&gt; inches, for example. Scientific measurements almost invariably use decimal notation rather than mixed numbers. The sum is implied without the use of a visible operator such as the appropriate "+". For example, in referring to two entire cakes and three quarters of another cake, the numerals denoting the integer part and the fractional part of the cakes are written next to each other as &lt;math&gt;2\tfrac{3}{4}&lt;/math&gt; instead of the unambiguous notation &lt;math&gt;2+\tfrac{3}{4}.&lt;/math&gt; Negative mixed numerals, as in &lt;math&gt;-2\tfrac{3}{4}&lt;/math&gt;, are treated like &lt;math&gt; -(2+\tfrac{3}{4}).&lt;/math&gt; Any such sum of a ''whole'' plus a ''part'' can be converted to an [[Improper fraction|improper fraction]] by applying the rules of [[Fraction (mathematics)#Adding unlike quantities|adding unlike quantities]].

This tradition is, formally, in conflict with the notation in algebra where adjacent factors denote a product, without an explicit [[infix operator]]. When two algebraic expressions are written next to each other, the operation of multiplication is implied by this general rule: &lt;math&gt;2x&lt;/math&gt; always means the product of &lt;math&gt;2&lt;/math&gt; and &lt;math&gt;x&lt;/math&gt;, even if the value of &lt;math&gt;x&lt;/math&gt; is a fraction. The expression &lt;math&gt; 2 \tfrac{b}{c} &lt;/math&gt; for example is not a mixed number, instead, multiplication is expressly required, where &lt;math&gt; 2 \tfrac{b}{c} = 2 \cdot \tfrac{b}{c}.&lt;/math&gt;

For better readability, the multiplication is sometimes made explicit or parentheses are added. So, &lt;math&gt; 2 \tfrac{b}{c}&lt;/math&gt; may be written as

: &lt;math&gt; 2 \cdot \tfrac{b}{c},\quad&lt;/math&gt; or &lt;math&gt;\quad 2 \times \tfrac{b}{c},\quad&lt;/math&gt; or &lt;math&gt; \quad 2 \left(\tfrac{b}{c}\right),\;\ldots&lt;/math&gt;

An improper fraction can be converted to a mixed number as follows:

#Divide the numerator by the denominator. In the example, &lt;math&gt;\tfrac{11}{4}&lt;/math&gt;, divide 11 by 4. 11 ÷ 4 = 2 with remainder 3.
#The [[quotient]] (without the remainder) becomes the whole number part of the mixed number. The remainder becomes the numerator of the fractional part. In the example, 2 is the whole number part and 3 is the numerator of the fractional part.
#The new denominator is the same as the denominator of the improper fraction. In the example, they are both 4. Thus &lt;math&gt;\tfrac{11}{4} =2\tfrac{3}{4}&lt;/math&gt;.

===Historical notions===
====Egyptian fraction====
An [[Egyptian fraction]] is the sum of distinct positive unit fractions, for example &lt;math&gt;\tfrac{1}{2}+\tfrac{1}{3}&lt;/math&gt;. This definition derives from the fact that the [[ancient Egypt]]ians expressed all fractions except &lt;math&gt;\tfrac{1}{2}&lt;/math&gt;, &lt;math&gt;\tfrac{2}{3}&lt;/math&gt; and &lt;math&gt;\tfrac{3}{4}&lt;/math&gt; in this manner. Every positive rational number can be expanded as an Egyptian fraction. For example, &lt;math&gt;\tfrac{5}{7}&lt;/math&gt; can be written as &lt;math&gt;\tfrac{1}{2} + \tfrac{1}{6} + \tfrac{1}{21}.&lt;/math&gt; Any positive rational number can be written as a sum of unit fractions in infinitely many ways. Two ways to write &lt;math&gt;\tfrac{13}{17}&lt;/math&gt; are &lt;math&gt;\tfrac{1}{2}+\tfrac{1}{4}+\tfrac{1}{68}&lt;/math&gt; and &lt;math&gt;\tfrac{1}{3}+\tfrac{1}{4}+\tfrac{1}{6}+\tfrac{1}{68}&lt;/math&gt;.

===='Complex' and 'Compound' fractions====
Both notions are outdated&lt;ref&gt;https://www.collinsdictionary.com/dictionary/english/complex-fraction et al.&lt;/ref&gt; and nowadays used in no well defined manner, partly even taken synonymously for each other&lt;ref&gt;{{cite web|url=https://www.collinsdictionary.com/dictionary/english/complex-fraction |title=Complex fraction definition and meaning |publisher=Collins English Dictionary |date=2018-03-09 |accessdate=2018-03-13}}&lt;/ref&gt; or for mixed numerals.&lt;ref&gt;{{cite web|url=http://www.sosmath.com/algebra/fraction/frac5/frac5.html |title=Compound Fractions |publisher=Sosmath.com |date=1996-02-05 |accessdate=2018-03-13}}&lt;/ref&gt; They lost their meaning as technical terms and the attributes "complex" and "compound" tend to be used in their every day meaning of "consisting of parts".
*Complex fractions
::''Not to be confused with [[Division of complex numbers|fractions involving complex numbers]]
In a '''complex fraction''', either the numerator, or the denominator, or both, is a fraction or a mixed number,&lt;ref name="Trotter"&gt;{{cite book|last=Trotter|first=James|title=A complete system of arithmetic|page=65|year=1853|url=https://books.google.com/books?id=a0sDAAAAQAAJ&amp;pg=PA65&amp;dq=%2B%22complex+fraction%22+%2B%22compound+fraction%22&amp;hl=sv&amp;ei=kN-6TuKZIITc0QHStb3eCQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4&amp;ved=0CD4Q6AEwAw#v=onepage&amp;q=%22complex%20fraction%22&amp;f=false}}&lt;/ref&gt;&lt;ref name="Barlow"&gt;{{cite book|last=Barlow|first=Peter|title=A new mathematical and philosophical dictionary|year=1814|url=https://books.google.com/books?id=BBowAAAAYAAJ&amp;pg=PT329&amp;dq=%2B%22complex+fraction%22+%2B%22compound+fraction%22&amp;hl=sv&amp;ei=kN-6TuKZIITc0QHStb3eCQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=10&amp;ved=0CFwQ6AEwCQ#v=onepage&amp;q=%2B%22complex%20fraction%22%20%2B%22compound%20fraction%22&amp;f=false}}&lt;/ref&gt; corresponding to division of fractions. For example, &lt;math&gt;\frac{\tfrac{1}{2}}{\tfrac{1}{3}}&lt;/math&gt; and &lt;math&gt;\frac{12\tfrac{3}{4}}{26}&lt;/math&gt; are complex fractions. To reduce a complex fraction to a simple fraction, treat the longest fraction line as representing division. For example:

:&lt;math&gt;\frac{\tfrac{1}{2}}{\tfrac{1}{3}}=\tfrac{1}{2}\times\tfrac{3}{1}=\tfrac{3}{2}=1\tfrac{1}{2}&lt;/math&gt;

:&lt;math&gt;\frac{12\tfrac{3}{4}}{26} = 12\tfrac{3}{4} \cdot \tfrac{1}{26} = \tfrac{12 \cdot 4 + 3}{4} \cdot \tfrac{1}{26} = \tfrac{51}{4} \cdot \tfrac{1}{26} = \tfrac{51}{104}&lt;/math&gt;

:&lt;math&gt;\frac{\tfrac{3}{2}}5=\tfrac{3}{2}\times\tfrac{1}{5}=\tfrac{3}{10}&lt;/math&gt;

:&lt;math&gt;\frac{8}{\tfrac{1}{3}}=8\times\tfrac{3}{1}=24.&lt;/math&gt;

If, in a complex fraction, there is no unique way to tell which fraction lines takes precedence, then this expression is improperly formed, because of ambiguity. So 5/10/20/40 is not a valid mathematical expression, because of multiple possible interpretations, e.g. as
:&lt;math&gt;5/(10/(20/40)) = \frac{5}{10/\tfrac{20}{40}} = \frac{1}{4}\quad&lt;/math&gt; or as &lt;math&gt;\quad (5/10)/(20/40) = \frac{\tfrac{5}{10}}{\tfrac{20}{40}} = 1&lt;/math&gt;
*Compound fractions&lt;br&gt;
A '''compound fraction''' is a fraction of a fraction, or any number of fractions connected with the word ''of'',&lt;ref name="Trotter" /&gt;&lt;ref name="Barlow" /&gt; corresponding to multiplication of fractions. To reduce a compound fraction to a simple fraction, just carry out the multiplication (see the section on [[#Multiplication|multiplication]]). For example, &lt;math&gt;\tfrac{3}{4}&lt;/math&gt; of &lt;math&gt;\tfrac{5}{7}&lt;/math&gt; is a compound fraction, corresponding to &lt;math&gt;\tfrac{3}{4} \times \tfrac{5}{7} = \tfrac{15}{28}&lt;/math&gt;. The terms compound fraction and complex fraction are closely related and sometimes one is used as a synonym for the other. (For example, the compound fraction &lt;math&gt;\tfrac{3}{4} \times \tfrac{5}{7}&lt;/math&gt; is equivalent to the complex fraction &lt;math&gt;\tfrac{3/4}{7/5}&lt;/math&gt;.)

==Arithmetic with fractions==
Like whole numbers, fractions obey the [[commutative]], [[associative]], and [[distributive property|distributive]] laws, and the rule against [[division by zero]].

===Equivalent fractions===
Multiplying the numerator and denominator of a fraction by the same (non-zero) number results in a fraction that is equivalent to the original fraction. This is true because for any non-zero number &lt;math&gt;n&lt;/math&gt;, the fraction &lt;math&gt;\tfrac{n}{n} = 1&lt;/math&gt;. Therefore, multiplying by &lt;math&gt;\tfrac{n}{n}&lt;/math&gt; is equivalent to multiplying by one, and any number multiplied by one has the same value as the original number. By way of an example, start with the fraction &lt;math&gt;\tfrac{1}{2}&lt;/math&gt;. When the numerator and denominator are both multiplied by 2, the result is &lt;math&gt;\tfrac{2}{4}&lt;/math&gt;, which has the same value (0.5) as &lt;math&gt;\tfrac{1}{2}&lt;/math&gt;. To picture this visually, imagine cutting a cake into four pieces; two of the pieces together (&lt;math&gt;\tfrac{2}{4}&lt;/math&gt;) make up half the cake (&lt;math&gt;\tfrac{1}{2}&lt;/math&gt;).

Dividing the numerator and denominator of a fraction by the same non-zero number will also yield an equivalent fraction. This is called reducing or simplifying the fraction. A simple fraction in which the numerator and denominator are [[coprime]] (that is, the only positive integer that goes into both the numerator and denominator evenly is 1) is said to be [[Irreducible fraction|irreducible]], in lowest terms, or in simplest terms. For example, &lt;math&gt;\tfrac{3}{9}&lt;/math&gt; is not in lowest terms because both 3 and 9 can be exactly divided by 3. In contrast, &lt;math&gt;\tfrac{3}{8}&lt;/math&gt; ''is'' in lowest terms—the only positive integer that goes into both 3 and 8 evenly is 1.

Using these rules, we can show that &lt;math&gt;\tfrac{5}{10}&lt;/math&gt; = &lt;math&gt;\tfrac{1}{2}&lt;/math&gt; = &lt;math&gt;\tfrac{10}{20}&lt;/math&gt; = &lt;math&gt;\tfrac{50}{100}&lt;/math&gt;.

A common fraction can be reduced to lowest terms by dividing both the numerator and denominator by their [[greatest common divisor]]. For example, as the greatest common divisor of 63 and 462 is 21, the fraction &lt;math&gt;\tfrac{63}{462}&lt;/math&gt; can be reduced to lowest terms by dividing the numerator and denominator by 21:
:&lt;math&gt;\tfrac{63}{462} = \tfrac{63 \div 21}{462 \div 21}= \tfrac{3}{22}&lt;/math&gt;

The [[Euclidean algorithm]] gives a method for finding the greatest common divisor of any two positive integers.

===Comparing fractions===
Comparing fractions with the same positive denominator yields the same result as comparing the numerators:

:&lt;math&gt;\tfrac{3}{4}&gt;\tfrac{2}{4}&lt;/math&gt; because {{nowrap|3 &amp;gt; 2}}, and the equal denominators &lt;math&gt;4&lt;/math&gt; are positive.

If the equal denominators are negative, then the opposite result of comparing the numerators holds for the fractions:

:&lt;math&gt;\tfrac{3}{-4}&lt;\tfrac{2}{-4}&lt;/math&gt; because &lt;math&gt;\tfrac{a}{-b}= \tfrac{-a}{b}&lt;/math&gt; and &lt;math&gt;-3 &lt; -2&lt;/math&gt;.

If two positive fractions have the same numerator, then the fraction with the smaller denominator is the larger number. When a whole is divided into equal pieces, if fewer equal pieces are needed to make up the whole, then each piece must be larger. When two positive fractions have the same numerator, they represent the same number of parts, but in the fraction with the smaller denominator, the parts are larger.

One way to compare fractions with different numerators and denominators is to find a common denominator. To compare &lt;math&gt;\tfrac{a}{b}&lt;/math&gt; and &lt;math&gt;\tfrac{c}{d}&lt;/math&gt;, these are converted to &lt;math&gt;\tfrac{a\cdot d}{b\cdot d}&lt;/math&gt; and &lt;math&gt;\tfrac{b\cdot c}{b\cdot d}&lt;/math&gt;. Then ''bd'' is a common denominator and the numerators ''ad'' and ''bc'' can be compared. This modification of the two fractions is known as "cross multiplying"{{cn|date=November 2017}}, and it is not necessary to determine the value of the common denominator to compare fractions – one can just compare ''ad'' and ''bc'', without evaluating ''bd'', e.g., comparing &lt;math&gt;\tfrac{2}{3}&lt;/math&gt; ? &lt;math&gt;\tfrac{1}{2}&lt;/math&gt; gives &lt;math&gt;\tfrac{4}{6}&gt;\tfrac{3}{6}&lt;/math&gt;.

For the more laborious question &lt;math&gt;\tfrac{5}{18}&lt;/math&gt; ? &lt;math&gt;\tfrac{4}{17},&lt;/math&gt; multiply top and bottom of each fraction by the denominator of the other fraction, to get a common denominator, yielding &lt;math&gt;\tfrac{5 \times 17}{18 \times 17}&lt;/math&gt; ? &lt;math&gt;\tfrac{18 \times 4}{18 \times 17}&lt;/math&gt;. It is not necessary to calculate &lt;math&gt;18 \times 17&lt;/math&gt; – only the numerators need to be compared. Since 5×17 (=&amp;nbsp;85) is greater than 4×18 (=&amp;nbsp;72), the result of comparing is &lt;math&gt;\tfrac{5}{18}&gt;\tfrac{4}{17}&lt;/math&gt;.

Because every negative number, including negative fractions, is less than zero, and every positive number, including positive fractions, is greater than zero, it follows that any negative fraction is less than any positive fraction. This allows, together with the above rules, to compare all possible fractions.

===Addition===
The first rule of addition is that only like quantities can be added; for example, various quantities of quarters. Unlike quantities, such as adding thirds to quarters, must first be converted to like quantities as described below:
Imagine a pocket containing two quarters, and another pocket containing three quarters; in total, there are five quarters. Since four quarters is equivalent to one (dollar), this can be represented as follows:
:&lt;math&gt;\tfrac24+\tfrac34=\tfrac54=1\tfrac14&lt;/math&gt;.

[[File:Cake fractions.svg|thumb|right|270px|If &lt;math&gt;\tfrac12&lt;/math&gt; of a cake is to be added to &lt;math&gt;\tfrac14&lt;/math&gt; of a cake, the pieces need to be converted into comparable quantities, such as cake-eighths or cake-quarters.]]

====Adding unlike quantities====
To add fractions containing unlike quantities (e.g. quarters and thirds), it is necessary to convert all amounts to like quantities. It is easy to work out the chosen type of fraction to convert to; simply multiply together the two denominators (bottom number) of each fraction. In case of an integer number apply the [[Fraction (mathematics)#Reciprocals and the "invisible denominator"|invisible denominator]] &lt;math&gt;1.&lt;/math&gt;

For adding quarters to thirds, both types of fraction are converted to twelfths, thus:

: &lt;math&gt;\frac14\ + \frac13=\frac{1\times3}{4\times3}\ + \frac{1\times4}{3\times4}=\frac3{12}\ + \frac4{12}=\frac7{12}.&lt;/math&gt;

Consider adding the following two quantities:
:&lt;math&gt;\frac35+\frac23&lt;/math&gt;
First, convert &lt;math&gt;\tfrac35&lt;/math&gt; into fifteenths by multiplying both the numerator and denominator by three: &lt;math&gt;\tfrac35\times\tfrac33=\tfrac9{15}&lt;/math&gt;. Since &lt;math&gt;\tfrac33&lt;/math&gt; equals 1, multiplication by &lt;math&gt;\tfrac33&lt;/math&gt; does not change the value of the fraction.

Second, convert &lt;math&gt;\tfrac23&lt;/math&gt; into fifteenths by multiplying both the numerator and denominator by five: &lt;math&gt;\tfrac23\times\tfrac55=\tfrac{10}{15}&lt;/math&gt;.

Now it can be seen that:

:&lt;math&gt;\frac35+\frac23&lt;/math&gt;

is equivalent to:

:&lt;math&gt;\frac9{15}+\frac{10}{15}=\frac{19}{15}=1\frac4{15}&lt;/math&gt;

This method can be expressed algebraically:
:&lt;math&gt;\frac{a}{b} + \frac {c}{d} = \frac{ad+cb}{bd}&lt;/math&gt;

This algebraic method always works, thereby guaranteeing that the sum of simple fractions is always again a simple fraction. However, if the single denominators contain a common factor, a smaller denominator than the product of these can be used. For example, when adding &lt;math&gt;\tfrac{3}{4}&lt;/math&gt; and &lt;math&gt;\tfrac{5}{6}&lt;/math&gt; the single denominators have a common factor &lt;math&gt;2,&lt;/math&gt; and therefore, instead of the denominator 24 (4&amp;thinsp;&amp;times;&amp;thinsp;6), the halved denominator 12 may be used, not only reducing the denominator in the result, but also the factors in the numerator.

:&lt;math&gt;\begin{align}
\frac34+\frac56 &amp;= \frac{3\cdot 6}{4\cdot 6}+\frac{4 \cdot 5}{4\cdot 6}=\frac{18}{24} + \frac{20}{24}&amp;=\frac{19}{12}\\
&amp;=\frac{3\cdot 3}{4\cdot 3}+\frac{2\cdot 5}{2\cdot 6} =\frac{9}{12} + \frac{10}{12}&amp;=\frac{19}{12}
\end{align}&lt;/math&gt;

The smallest possible denominator is given by the [[least common multiple]] of the single denominators, which results from dividing the rote multiple by all common factors of the single denominators. This is called the least common denominator.

===Subtraction===
The process for subtracting fractions is, in essence, the same as that of adding them: find a common denominator, and change each fraction to an equivalent fraction with the chosen common denominator. The resulting fraction will have that denominator, and its numerator will be the result of subtracting the numerators of the original fractions. For instance,

:&lt;math&gt;\tfrac23-\tfrac12=\tfrac46-\tfrac36=\tfrac16&lt;/math&gt;

===Multiplication===
====Multiplying a fraction by another fraction====
To multiply fractions, multiply the numerators and multiply the denominators. Thus:

:&lt;math&gt;\tfrac{2}{3} \times \tfrac{3}{4} = \tfrac{6}{12}&lt;/math&gt;

To explain the process, consider one third of one quarter. Using the example of a cake, if three small slices of equal size make up a quarter, and four quarters make up a whole, twelve of these small, equal slices make up a whole. Therefore, a third of a quarter is a twelfth. Now consider the numerators. The first fraction, two thirds, is twice as large as one third. Since one third of a quarter is one twelfth, two thirds of a quarter is two twelfth. The second fraction, three quarters, is three times as large as one quarter, so two thirds of three quarters is three times as large as two thirds of one quarter. Thus two thirds times three quarters is six twelfths.

A short cut for multiplying fractions is called "cancellation". Effectively the answer is reduced to lowest terms during multiplication. For example:

:&lt;math&gt;\tfrac{2}{3} \times \tfrac{3}{4} = \tfrac{\cancel{2} ^{~1}}{\cancel{3} ^{~1}} \times \tfrac{\cancel{3} ^{~1}}{\cancel{4} ^{~2}} = \tfrac{1}{1} \times \tfrac{1}{2} = \tfrac{1}{2}&lt;/math&gt;

A two is a common [[Divisor|factor]] in both the numerator of the left fraction and the denominator of the right and is divided out of both. Three is a common factor of the left denominator and right numerator and is divided out of both.

====Multiplying a fraction by a whole number====
Since a whole number can be rewritten as itself divided by 1, normal fraction multiplication rules can still apply.

:&lt;math&gt;6 \times \tfrac{3}{4} = \tfrac{6}{1} \times \tfrac{3}{4} = \tfrac{18}{4}&lt;/math&gt; This method works because the fraction 6/1 means six equal parts, each one of which is a whole.

====Multiplying mixed numbers====
When multiplying mixed numbers, it is considered preferable {{Citation needed|date=February 2015}} to convert the mixed number into an improper fraction. For example:

:&lt;math&gt;3 \times 2\tfrac{3}{4} = 3 \times \left (\tfrac{8}{4} + \tfrac{3}{4} \right ) = 3 \times \tfrac{11}{4} = \tfrac{33}{4} = 8\tfrac{1}{4}&lt;/math&gt;

In other words, &lt;math&gt;2\tfrac{3}{4}&lt;/math&gt; is the same as &lt;math&gt;\tfrac{8}{4} + \tfrac{3}{4}&lt;/math&gt;, making 11 quarters in total (because 2 cakes, each split into quarters makes 8 quarters total) and 33 quarters is &lt;math&gt;8\tfrac{1}{4}&lt;/math&gt;, since 8 cakes, each made of quarters, is 32 quarters in total.

===Division===
To divide a fraction by a whole number, you may either divide the numerator by the number, if it goes evenly into the numerator, or multiply the denominator by the number. For example, &lt;math&gt;\tfrac{10}{3} \div 5&lt;/math&gt; equals &lt;math&gt;\tfrac{2}{3}&lt;/math&gt; and also equals &lt;math&gt;\tfrac{10}{3 \cdot 5} = \tfrac{10}{15}&lt;/math&gt;, which reduces to &lt;math&gt;\tfrac{2}{3}&lt;/math&gt;. To divide a number by a fraction, multiply that number by the reciprocal of that fraction. Thus, &lt;math&gt;\tfrac{1}{2} \div \tfrac{3}{4} = \tfrac{1}{2} \times \tfrac{4}{3} = \tfrac{1 \cdot 4}{2 \cdot 3} = \tfrac{2}{3}&lt;/math&gt;.

===Converting between decimals and fractions===
To change a common fraction to a decimal, do a long division of the decimal representations of the numerator by the denominator (this is idiomatically also phrased as "divide the denominator into the numerator"), and round the answer to the desired accuracy. For example, to change ¼ to a decimal, divide &lt;math&gt;1.00&lt;/math&gt; by &lt;math&gt;4&lt;/math&gt; ("&lt;math&gt;4&lt;/math&gt; into &lt;math&gt;1.00&lt;/math&gt;"), to obtain &lt;math&gt;0.25&lt;/math&gt;. To change ⅓ to a decimal, divide &lt;math&gt;1.000...&lt;/math&gt; by &lt;math&gt;3&lt;/math&gt; ("&lt;math&gt;3&lt;/math&gt; into &lt;math&gt;1.0000...&lt;/math&gt;"), and stop when the desired accuracy is obtained, e.g., at &lt;math&gt;4&lt;/math&gt; decimals with &lt;math&gt;0.3333&lt;/math&gt;. Note that ¼ can be written exactly with two decimal digits, while the fraction ⅓ cannot be written exactly as a decimal with a finite number of digits.
To change a decimal to a fraction, write in the denominator a &lt;math&gt;1&lt;/math&gt; followed by as many zeroes as there are digits to the right of the decimal point, and write in the numerator all the digits of the original decimal, just omitting the decimal point. Thus &lt;math&gt;12.3456 = \tfrac{123456}{10000}.&lt;/math&gt;

====Converting repeating decimals to fractions====
{{See also| Repeating decimal }}
Decimal numbers, while arguably more useful to work with when performing calculations, sometimes lack the precision that common fractions have. Sometimes an infinite [[repeating decimal]] is required to reach the same precision. Thus, it is often useful to convert repeating decimals into fractions.

The preferred way to indicate a repeating decimal is to place a bar over the digits that repeat, for example 0.{{overline|789}} = 0.789789789… For repeating patterns where the repeating pattern begins immediately after the decimal point, a simple division of the pattern by the same number of nines as numbers it has will suffice. For example:
:0.{{overline|5}} = 5/9
:0.{{overline|62}} = 62/99
:0.{{overline|264}} = 264/999
:0.{{overline|6291}} = 6291/9999
In case [[leading zero]]s precede the pattern, the nines are suffixed by the same number of [[trailing zero]]s:
:0.0{{overline|5}} = 5/90
:0.000{{overline|392}} = 392/999000
:0.00{{overline|12}} = 12/9900
In case a non-repeating set of decimals precede the pattern (such as 0.1523{{overline|987}}), we can write it as the sum of the non-repeating and repeating parts, respectively:
:0.1523 + 0.0000{{overline|987}}
Then, convert both parts to fractions, and add them using the methods described above:
:1523&amp;thinsp;/&amp;thinsp;10000 + 987&amp;thinsp;/&amp;thinsp;9990000 = 1522464&amp;thinsp;/&amp;thinsp;9990000

Alternatively, algebra can be used, such as below:

# Let ''x'' = the repeating decimal:
#:''x'' = 0.1523{{overline|987}}
#Multiply both sides by the power of 10 just great enough (in this case 10&lt;sup&gt;4&lt;/sup&gt;) to move the decimal point just before the repeating part of the decimal number:
#:10,000''x'' = 1,523.{{overline|987}}
#Multiply both sides by the power of 10 (in this case 10&lt;sup&gt;3&lt;/sup&gt;) that is the same as the number of places that repeat:
#:10,000,000''x'' = 1,523,987.{{overline|987}}
#Subtract the two equations from each other (if ''a'' = ''b'' and ''c'' = ''d'', then ''a'' − ''c'' = ''b'' − ''d''):
#:10,000,000''x'' − 10,000''x'' = 1,523,987.{{overline|987}} − 1,523.{{overline|987}}
#Continue the subtraction operation to clear the repeating decimal:
#:9,990,000''x'' = 1,523,987 − 1,523
#:&lt;span style="visibility:hidden"&gt;9,990,000''x''&lt;/span&gt; = 1,522,464
#Divide both sides by 9,990,000 to represent ''x'' as a fraction
#:''x'' = 1522464&amp;thinsp;/&amp;thinsp;9990000

==Fractions in abstract mathematics==
In addition to being of great practical importance, fractions are also studied by mathematicians, who check that the rules for fractions given above are [[well defined|consistent and reliable]]. Mathematicians define a fraction as an ordered pair &lt;math&gt;(a,b)&lt;/math&gt; of [[integer]]s &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b \ne 0,&lt;/math&gt; for which the operations [[addition]], [[subtraction]], [[multiplication]], and [[division (mathematics)|division]] are defined as follows:&lt;ref&gt;{{cite web|url=http://www.encyclopediaofmath.org/index.php/Fraction |title=Fraction |publisher=Encyclopedia of Mathematics |date=2012-04-06 |accessdate=2012-08-15}}&lt;/ref&gt;

:&lt;math&gt;(a,b) + (c,d) = (ad+bc,bd) \,&lt;/math&gt;

:&lt;math&gt;(a,b) - (c,d) = (ad-bc,bd) \,&lt;/math&gt;

:&lt;math&gt;(a,b) \cdot (c,d) = (ac,bd)&lt;/math&gt;

:&lt;math&gt;(a,b) \div (c,d) = (ad,bc) \quad(\text{with, additionally, } c \ne 0) &lt;/math&gt;

These definitions agree in every case with the definitions given above; only the notation is different. Alternatively, instead of defining subtraction and division as operations, the "inverse" fractions with respect to addition and multiplication might be defined as:

:&lt;math&gt;\begin{array}{llrrl}
     &amp;-(a,b) &amp;= &amp;(-a, b) &amp;\quad \text{additive inverse fractions,} \\
      &amp;&amp;&amp;&amp;\quad\text{with } (0,b) \text{ as additive unities, and}\\
     &amp;\;\;\ (a,b)^{-1} &amp;= &amp;(b,a) &amp;\quad \text{multiplicative inverse fractions, for } a \ne 0, \\
      &amp;&amp;&amp;&amp;\quad\text{with } (b,b) \text{ as multiplicative unities}.
   \end{array}&lt;/math&gt;

Furthermore, the [[Relation (mathematics)|relation]], specified as 
:&lt;math&gt;(a, b) \sim (c, d)\quad \iff \quad ad=bc,&lt;/math&gt;

is an [[equivalence relation]] of fractions. Each fraction from one equivalence class may be considered as a representative for the whole class, and each whole class may be considered as one abstract fraction. This equivalence is preserved by the above defined operations, i.e., the results of operating on fractions are independent of the selection of representatives from their equivalence class. Formally, for addition of fractions
:&lt;math&gt;(a,b) \sim (a',b')\quad&lt;/math&gt; and &lt;math&gt;\quad (c,d) \sim (c',d') \quad&lt;/math&gt; imply
::&lt;math&gt;((a,b) + (c,d)) \sim ((a',b') + (c',d'))&lt;/math&gt;

and similarly for the other operations.

In case of fractions of integers the fractions with &lt;math&gt;(a,b)&lt;/math&gt; coprime are often taken as uniquely determined representatives for their ''equivalent'' fractions, which are considered to be the ''same'' rational number. This way the fractions of integers make up the field of the rational numbers.

More generally, ''a'' and ''b'' may be elements of any [[integral domain]] ''R'', in which case a fraction is an element of the [[field of fractions]] of ''R''. For example, [[polynomial]]s in one indeterminate, with coefficients from some integral domain ''D'', are themselves an integral domain, call it ''P''. So for ''a'' and ''b'' elements of ''P'', the generated ''field of fractions'' is the field of [[rational fraction]]s (also known as the field of [[rational function]]s).

==Algebraic fractions==
{{Main|Algebraic fraction}}
An algebraic fraction is the indicated [[quotient]] of two [[algebraic expression]]s. As with fractions of integers, the denominator of an algebraic fraction cannot be zero. Two examples of algebraic fractions are &lt;math&gt;\frac{3x}{x^2+2x-3}&lt;/math&gt; and &lt;math&gt;\frac{\sqrt{x+2}}{x^2-3}&lt;/math&gt;. Algebraic fractions are subject to the same [[field (mathematics)|field properties]] as arithmetic fractions.

If the numerator and the denominator are [[polynomial]]s, as in &lt;math&gt;\frac{3x}{x^2+2x-3}&lt;/math&gt;, the algebraic fraction is called a '''rational fraction''' (or '''rational expression'''). An '''irrational fraction''' is one that is not rational, as, for example, one that contains the variable under a fractional exponent or root, as in &lt;math&gt;\frac{\sqrt{x+2}}{x^2-3}&lt;/math&gt;.

The terminology used to describe algebraic fractions is similar to that used for ordinary fractions. For example, an algebraic fraction is in lowest terms if the only factors common to the numerator and the denominator are 1 and −1. An algebraic fraction whose numerator or denominator, or both, contain a fraction, such as &lt;math&gt;\frac{1 + \tfrac{1}{x}}{1 - \tfrac{1}{x}}&lt;/math&gt;, is called a '''complex fraction'''.

The field of rational numbers is the [[field of fractions]] of the integers, while the integers themselves are not a field but rather an [[integral domain]]. Similarly, the [[Rational fraction|rational expressions]] are the field of fractions of [[polynomial]]s. There are different integral domains of polynomials, depending on the integral domain the [[coefficient]]s of the polynomials are from (e.g. from integers, [[real numbers]], [[complex numbers]], ...). Considering the field of fractions generated by polynomials with real coefficients, [[radical expression]]s such as &lt;math&gt;\textstyle \sqrt{2}/2&lt;/math&gt; are also rational fractions, as is the transcendental expression &lt;math&gt;\pi/2&lt;/math&gt;, since all of &lt;math&gt;\sqrt{2},\pi,&lt;/math&gt; and &lt;math&gt;2&lt;/math&gt; are (constant) polynomials over the ''reals''. These same expressions, however, would not be considered elements of the field of fractions generated by polynomials with ''integer'' coefficients. This specific field would contain just the &lt;math&gt;2&lt;/math&gt; of the three polynomials above, or &lt;math&gt;1/2&lt;/math&gt; as fraction, but no radical or transcendental expressions. 

The term [[partial fraction]] is used when decomposing rational expressions into sums. The goal is to write the rational expression as the sum of other rational expressions with denominators of lesser degree. For example, the rational expression &lt;math&gt;\frac{2x}{x^2-1}&lt;/math&gt; can be rewritten as the sum of two fractions: &lt;math&gt;\frac{1}{x+1} + \frac{1}{x-1}&lt;/math&gt;. This is useful in many areas such as integral calculus and differential equations.

==Radical expressions==
{{Main|Nth root|Rationalization (mathematics)}}
A fraction may also contain [[Nth root|radicals]] in the numerator and/or the denominator. If the denominator contains radicals, it can be helpful to [[Rationalisation (mathematics)|rationalize]] it (compare [[Nth root#Simplified form of a radical expression|Simplified form of a radical expression]]), especially if further operations, such as adding or comparing that fraction to another, are to be carried out. It is also more convenient if division is to be done manually. When the denominator is a [[monomial]] square root, it can be rationalized by multiplying both the top and the bottom of the fraction by the denominator:

: &lt;math&gt;\frac{3}{\sqrt{7}} = \frac{3}{\sqrt{7}} \cdot \frac{\sqrt{7}}{\sqrt{7}} = \frac{3\sqrt{7}}{7}&lt;/math&gt;

The process of rationalization of [[binomial (polynomial)|binomial]] denominators involves multiplying the top and the bottom of a fraction by the [[Conjugate (algebra)|conjugate]] of the denominator so that the denominator becomes a rational number. For example:

:&lt;math&gt;\frac{3}{3-2\sqrt{5}} = \frac{3}{3-2\sqrt{5}} \cdot \frac{3+2\sqrt{5}}{3+2\sqrt{5}} = \frac{3(3+2\sqrt{5})}{{3}^2 - (2\sqrt{5})^2} = \frac{ 3 (3 + 2\sqrt{5} ) }{ 9 - 20 } = - \frac{ 9+6 \sqrt{5} }{11}&lt;/math&gt;
:&lt;math&gt;\frac{3}{3+2\sqrt{5}} = \frac{3}{3+2\sqrt{5}} \cdot \frac{3-2\sqrt{5}}{3-2\sqrt{5}} = \frac{3(3-2\sqrt{5})}{{3}^2 - (2\sqrt{5})^2} = \frac{ 3 (3 - 2\sqrt{5} ) }{ 9 - 20 } = - \frac{ 9-6 \sqrt{5} }{11}&lt;/math&gt;

Even if this process results in the numerator being irrational, like in the examples above, the process may still facilitate subsequent manipulations by reducing the number of irrationals one has to work with in the denominator.

==Typographical variations==
In computer displays and [[typography]], simple fractions are sometimes printed as a single character, e.g. ½ ([[one half]]). See the article on [[Number Forms]] for information on doing this in [[Unicode]].

Scientific publishing distinguishes four ways to set fractions, together with guidelines on use:&lt;ref name="galen"&gt;{{Cite journal | title = Putting Fractions in Their Place | first = Leslie Blackwell | last = Galen | journal = [[American Mathematical Monthly]] |date=March 2004 | volume = 111 | number = 3 | doi = 10.2307/4145131 | url = http://www.integretechpub.com/research/papers/monthly238-242.pdf }}&lt;/ref&gt;
* '''special fractions:''' fractions that are presented as a single character with a slanted bar, with roughly the same height and width as other characters in the text. Generally used for simple fractions, such as: ½, ⅓, ⅔, ¼, and ¾. Since the numerals are smaller, legibility can be an issue, especially for small-sized fonts. These are not used in modern mathematical notation, but in other contexts.
* '''case fractions:''' similar to special fractions, these are rendered as a single typographical character, but with a horizontal bar, thus making them ''upright''. An example would be &lt;math&gt;\tfrac{1}{2}&lt;/math&gt;, but rendered with the same height as other characters. Some sources include all rendering of fractions as ''case fractions'' if they take only one typographical space, regardless of the direction of the bar.&lt;ref&gt;{{cite web | url=http://www.allbusiness.com/glossaries/built-fraction/4955205-1.html| title=built fraction | publisher=allbusiness.com glossary | accessdate=2013-06-18}}&lt;/ref&gt;
* '''shilling''' or '''solidus fractions:''' 1/2, so called because this notation was used for pre-decimal British currency ([[£sd]]), as in 2/6 for a [[Half crown (British coin)|half crown]], meaning two shillings and six pence. While the notation "two shillings and six pence" did not represent a fraction, the forward slash is now used in fractions, especially for fractions inline with prose (rather than displayed), to avoid uneven lines. It is also used for fractions within fractions ([[#Complex fractions|complex fractions]]) or within exponents to increase legibility. Fractions written this way, also known as ''piece fractions'',&lt;ref&gt;{{cite web | url=http://www.allbusiness.com/glossaries/piece-fraction/4949142-1.html | title=piece fraction | publisher=allbusiness.com glossary | accessdate=2013-06-18}}
&lt;/ref&gt; are written all on one typographical line, but take 3 or more typographical spaces.
* '''built-up fractions:''' &lt;math&gt;\frac{1}{2}&lt;/math&gt;. This notation uses two or more lines of ordinary text, and results in a variation in spacing between lines when included within other text. While large and legible, these can be disruptive, particularly for simple fractions or within complex fractions.

==History==
The earliest fractions were [[multiplicative inverse|reciprocals]] of [[integer]]s: ancient symbols representing one part of two, one part of three, one part of four, and so on.&lt;ref name="eves"&gt;{{cite book |last=Eves |first=Howard |title=An introduction to the history of mathematics |year=1990 |publisher=Saunders College Pub. |location=Philadelphia |isbn=0-03-029558-0 |edition=6th}}&lt;/ref&gt; The [[History of Egypt|Egyptians]] used [[Egyptian fraction]]s {{circa|lk=no|1000}}&amp;nbsp;{{sc|bc}}. About 4000 years ago, Egyptians divided with fractions using slightly different methods. They used least common multiples with [[unit fraction]]s. Their methods gave the same answer as modern methods.&lt;ref&gt;{{cite web|url=http://egyptianmath.blogspot.com|title=Math History|author=Milo Gardner|date=December 19, 2005|accessdate=2006-01-18}} See for examples and an explanation.&lt;/ref&gt; The Egyptians also had a different notation for [[dyadic fraction]]s in the [[Akhmim Wooden Tablet]] and several [[Rhind Mathematical Papyrus]] problems.

The [[Ancient Greece|Greeks]] used unit fractions and (later) continued fractions. [[Pythagoreans|Followers]] of the [[Ancient Greece|Greek]] [[Greek philosophy|philosopher]] [[Pythagoras]] ({{circa|lk=no|530}}&amp;nbsp;{{sc|bc}}) discovered that the [[square root of two]] [[irrational numbers|cannot be expressed as a fraction of integers]]. (This is commonly though probably erroneously ascribed to [[Hippasus]] of [[Metapontum]], who is said to have been executed for revealing this fact.) In {{nowrap|150 {{sc|bc}}}} [[Jain]] mathematicians in [[History of India|India]] wrote the "[[Sthananga Sutra]]", which contains work on the theory of numbers, arithmetical operations, and operations with fractions.

A modern expression of fractions known as '''bhinnarasi''' seems to have originated in India in the work of [[Aryabhatta]] ({{circa|lk=no|{{sc|ad}} 500}}),{{citation needed|date=February 2016}} [[Brahmagupta]] ({{circa|lk=no|628}}), and [[Bhāskara II|Bhaskara]] ({{circa|lk=no|1150}}).&lt;ref name=jeff&gt;{{cite web |last=Miller |first=Jeff |url=http://jeff560.tripod.com/mathsym.html |title=Earliest Uses of Various Mathematical Symbols |date=22 December 2014 |accessdate=15 February 2016 }}&lt;/ref&gt; Their works form fractions by placing the numerators ({{lang-sa|amsa}}) over the denominators ({{lang|sa|cheda}}), but without a bar between them.&lt;ref name=jeff/&gt; In [[Sanskrit literature]], fractions were always expressed as an addition to or subtraction from an integer.{{citation needed|date=February 2016}} The integer was written on one line and the fraction in its two parts on the next line. If the fraction was marked by a small circle {{angle brackets|०}} or cross {{angle brackets|+}}, it is subtracted from the integer; if no such sign appears, it is understood to be added. For example, [[Bhaskara I]] writes&lt;ref name="filliozat-p152"&gt;{{Harvp|Filliozat|2004|p=152}}&lt;/ref&gt;
: ६ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  १ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  २
: १ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  १ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  १&lt;sub&gt;०&lt;/sub&gt;
: ४ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  ५ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  ९
which is the equivalent of 
: 6 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  2
: 1 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 1 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  −1
: 4 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 5 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  9
and would be written in modern notation as 6{{sfrac|1|4}}, 1{{sfrac|1|5}}, and 2−{{sfrac|1|9}} (i.e., 1{{sfrac|8|9}}).

The horizontal [[fraction bar]] is first attested in the work of [[Al-Hassār]] ({{floruit|1200}}),&lt;ref name=jeff/&gt; a [[Mathematics in medieval Islam|Muslim mathematician]] from [[Fes|Fez]], [[Morocco]], who specialized in [[Islamic inheritance jurisprudence]]. In his discussion he writes, "... for example, if you are told to write three-fifths and a third of a fifth, write thus, &lt;math&gt;\frac{3 \quad 1}{5 \quad 3}&lt;/math&gt;."&lt;ref&gt;{{cite book |last=Cajori|first=Florian|title=A History of Mathematical Notations |volume=1 |publisher=Open Court Publishing Company|year=1928|place=La Salle, Illinois|page=269 |url=https://archive.org/details/historyofmathema031756mbp}}&lt;/ref&gt; The same fractional notation—with the fraction given before the integer&lt;ref name=jeff/&gt;—appears soon after in the work of [[Leonardo Fibonacci]] in the 13th century.&lt;ref&gt;{{harvp|Cajori|1928|loc=pg.89}}&lt;/ref&gt;

In discussing the origins of [[decimal fractions]], [[Dirk Jan Struik]] states:&lt;ref&gt;{{cite book|title=A Source Book in Mathematics 1200–1800|year=1986|publisher=Princeton University Press|location=New Jersey|isbn=0-691-02397-2}}&lt;/ref&gt;
&lt;blockquote&gt;"The introduction of decimal fractions as a common computational practice can be dated back to the [[Flemish Region|Flemish]] pamphlet ''De Thiende'', published at [[Leiden|Leyden]] in 1585, together with a French translation, ''La Disme'', by the Flemish mathematician [[Simon Stevin]] (1548–1620), then settled in the Northern [[Netherlands]]. It is true that decimal fractions were used by the [[Chinese mathematics|Chinese]] many centuries before Stevin and that the Persian astronomer [[Al-Kāshī]] used both decimal and [[sexagesimal]] fractions with great ease in his ''Key to arithmetic'' ([[Samarkand]], early fifteenth century)."&lt;ref&gt;{{cite book|title=Die Rechenkunst bei Ğamšīd b. Mas'ūd al-Kāšī|year=1951|publisher=Steiner|location=Wiesbaden}}&lt;/ref&gt;
&lt;/blockquote&gt;

While the [[Persian people|Persian]] mathematician [[Jamshīd al-Kāshī]] claimed to have discovered decimal fractions himself in the 15th century, J. Lennart Berggren notes that he was mistaken, as decimal fractions were first used five centuries before him by the [[Baghdad]]i mathematician [[Abu'l-Hasan al-Uqlidisi]] as early as the 10th century.&lt;ref&gt;{{Cite book| first=J. Lennart | last=Berggren | title=The Mathematics of Egypt, Mesopotamia, China, India, and Islam: A Sourcebook | chapter=Mathematics in Medieval Islam | publisher=Princeton University Press | year=2007 | isbn=978-0-691-11485-9 | page=518 }}&lt;/ref&gt;{{refn|group=n|While there is some disagreement among history of mathematics scholars as to the primacy of al-Uqlidisi's contribution, there is no question as to his major contribution to the concept of decimal fractions.&lt;ref&gt;[http://www-history.mcs.st-andrews.ac.uk/Biographies/Al-Uqlidisi.html "MacTutor's al-Uqlidisi biography"]. Retrieved 2011-11-22.&lt;/ref&gt;}}

==In formal education==
===Pedagogical tools===
In [[primary school]]s, fractions have been demonstrated through [[Cuisenaire rods]], [[Fraction Bars]], fraction strips, fraction circles, paper (for folding or cutting), [[pattern block]]s, pie-shaped pieces, plastic rectangles, grid paper, [[dot paper]], [[geoboard]]s, counters and computer software.

===Documents for teachers===
Several states in the United States have adopted learning trajectories from the [[Common Core State Standards Initiative]]'s guidelines for mathematics education. Aside from sequencing the learning of fractions and operations with fractions, the document provides the following definition of a fraction: "A number expressible in the form &lt;math&gt;\tfrac{a}{b}&lt;/math&gt; where &lt;math&gt;a&lt;/math&gt; is a whole number and &lt;math&gt;b&lt;/math&gt; is a positive whole number. (The word ''fraction'' in the standards always refers to a non-negative number.)"&lt;ref&gt;{{cite web|url=http://www.corestandards.org/assets/CCSSI_Math%20Standards.pdf |title=Common Core State Standards for Mathematics |publisher=Common Core State Standards Initiative|page=85|year=2010 |accessdate=2013-10-10}}
&lt;/ref&gt;
The document itself also refers to negative fractions.

==See also==
*[[Continued fraction]]
*[[0.999...]]
*[[Multiple (mathematics)|Multiple]]

==Notes==
{{reflist|group=n}}

==References==
{{Reflist|30em}}

==External links==
{{commons category|Fractions}}
{{Wiktionary|denominator}}
{{Wiktionary|numerator}}
*{{cite encyclopedia |encyclopedia=The Online Encyclopaedia of Mathematics |title=Fraction, arithmetical |url=http://www.encyclopediaofmath.org/index.php/Fraction}}
*{{MathWorld|Fraction|Fraction}}
*{{cite encyclopedia |encyclopedia=Encyclopædia Britannica |title=Fraction |url=http://www.britannica.com/EBchecked/topic/215508/fraction}}
*{{cite encyclopedia |encyclopedia=Citizendium |title=Fraction (mathematics) |url=http://en.citizendium.org/wiki/Fraction_(mathematics)}}
*{{cite encyclopedia|encyclopedia=PlanetMath |title=Fraction |url=http://planetmath.org/encyclopedia/Fraction.html |deadurl=yes |archiveurl=https://web.archive.org/web/20111011215017/http://planetmath.org/encyclopedia/Fraction.html |archivedate=2011-10-11 |df= }}

{{Fractions and ratios}}

{{Authority control}}

{{DEFAULTSORT:Fraction (Mathematics)}}
[[Category:Fractions (mathematics)| ]]
[[Category:Elementary arithmetic]]
[[Category:Numbers]]
[[Category:Division (mathematics)]]</text>
      <sha1>1ozafsfnf2skmci3fh094l894o85yk1</sha1>
    </revision>
  </page>
  <page>
    <title>Frey curve</title>
    <ns>0</ns>
    <id>5249765</id>
    <revision>
      <id>839637276</id>
      <parentid>832366705</parentid>
      <timestamp>2018-05-04T18:09:34Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: J.reine u.angew.Math → J. reine angew. Math. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3423">In mathematics, a '''Frey curve''' or '''Frey–Hellegouarch''' curve is the [[elliptic curve]] 
::&lt;math&gt;y^2 = x(x - a^\ell)(x + b^\ell)&lt;/math&gt;
associated with a (hypothetical) solution of [[Fermat's Last Theorem|Fermat's equation]]
:&lt;math&gt;a^\ell + b^\ell = c^\ell.&lt;/math&gt;
The curve is named after [[Gerhard Frey]].

==History==
{{harvs|first=Yves|last=Hellegouarch|year=1975|txt}} came up with the idea of associating solutions &lt;math&gt;(a,b,c)&lt;/math&gt; of Fermat's equation with a completely different mathematical object: an elliptic curve.
If &amp;#8467; is an odd prime and ''a'', ''b'', and ''c'' are positive integers such that

:&lt;math&gt;a^\ell + b^\ell = c^\ell,&lt;/math&gt;

then a corresponding Frey curve is an algebraic curve given by the equation

:&lt;math&gt;y^2 = x(x - a^\ell)(x + b^\ell)&lt;/math&gt;

or, equivalently

:&lt;math&gt;y^2 = x(x - a^\ell)(x - c^\ell).&lt;/math&gt;

This is a nonsingular algebraic curve of genus one defined over '''Q''', and its [[Projectivization|projective completion]] is an elliptic curve over '''Q'''.

{{harvs|first=Gerhard|last=Frey|authorlink=Gerhard Frey|year=1982}} called attention to the unusual properties of the same curve as Hellegouarch, which became called a Frey curve. This provided a bridge between Fermat and Taniyama by showing that a counterexample to [[Fermat's Last Theorem]] would create such a curve that would not be modular. The conjecture attracted considerable interest when {{harvtxt|Frey|1986}} suggested that the [[Taniyama–Shimura–Weil conjecture]] implies Fermat's Last Theorem.  However, his argument was not complete. In 1985, [[Jean-Pierre Serre]] proposed that a Frey curve could not be modular and provided a partial proof of this. This showed that a proof of the semistable case of the Taniyama-Shimura conjecture would imply Fermat's Last Theorem. Serre did not provide a complete proof and what was missing became known as the [[epsilon conjecture]] or ε-conjecture. In the summer of 1986, Ribet (1990) proved the epsilon conjecture, thereby proving that the Taniyama–Shimura–Weil conjecture implies Fermat's Last Theorem.

==References==

*{{Citation | last1=Frey | first1=Gerhard | title=Links between stable elliptic curves and certain Diophantine equations | mr=853387 | year=1986 | journal=Annales Universitatis Saraviensis. Series Mathematicae | issn=0933-8268 | volume=1 | issue=1 | pages=iv+40}}
*{{Citation | last1=Frey | first1=Gerhard | title=Rationale Punkte auf Fermatkurven und getwisteten Modulkurven| year=1982 | journal=J. reine angew. Math. | volume=331 | pages=185–191}}
*{{Citation | last1=Hellegouarch | first1=Yves | title=Rectificatif à l'article de H. Darmon intitulé : "La Conjecture de Shimura-Taniyama-Weil est enfin démontré" | url=http://www.math.unicaen.fr/~nitaj/hellegouarch.html | year=2000 | journal=Gazette des Mathématiciens | issn=0224-8999 | volume=83}}
*{{Citation | last1=Hellegouarch | first1=Yves | title=Points d'ordre 2p&lt;sup&gt;h&lt;/sup&gt; sur les courbes elliptiques | url=http://matwbn.icm.edu.pl/ksiazki/aa/aa26/aa2636.pdf| mr=0379507  | year=1974 | journal=Polska Akademia Nauk. Instytut Matematyczny. Acta Arithmetica | issn=0065-1036 | volume=26 | issue=3 | pages=253–263}}
*{{Citation | last1=Hellegouarch | first1=Yves | title=Invitation to the mathematics of Fermat-Wiles | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-339251-0 | mr=1475927  | year=2002}}

[[Category:Number theory]]</text>
      <sha1>3hiwia10bvf6xwqjouyyazo0ctgii7l</sha1>
    </revision>
  </page>
  <page>
    <title>Fundamental theorem of curves</title>
    <ns>0</ns>
    <id>1056003</id>
    <revision>
      <id>853938735</id>
      <parentid>791879576</parentid>
      <timestamp>2018-08-07T22:37:13Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2089">In [[differential geometry]], the '''fundamental theorem of space curves''' states that every regular [[curve]] in three-dimensional space, with non-zero curvature, has its shape (and size) completely determined by its [[curvature]] and [[Torsion of curves|torsion]].&lt;ref&gt;{{citation|title=Differential Geometry of Curves and Surfaces|first1=Thomas F.|last1=Banchoff|first2=Stephen T.|last2=Lovett|publisher=CRC Press|year=2010|isbn=9781568814568|page=84|url=https://books.google.com/books?id=EkfyHkB2ltMC&amp;pg=PA84}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Global Analysis: Differential Forms in Analysis, Geometry, and Physics|volume=52|series=[[Graduate Studies in Mathematics]]|first1=Ilka|last1=Agricola|author1-link= Ilka Agricola |first2=Thomas|last2=Friedrich|publisher=American Mathematical Society|year=2002|isbn=9780821829516|page=133|url=https://books.google.com/books?id=4pA2P1HyTPoC&amp;pg=PA133}}.&lt;/ref&gt;

==Use==
A curve can be described, and thereby defined, by a pair of [[scalar field]]s: curvature &lt;math&gt;\kappa&lt;/math&gt; and torsion &lt;math&gt;\tau&lt;/math&gt;, both of which depend on some parameter which [[parametric equation|parametrizes]] the curve but which can ideally be the [[arc length]] of the curve.  From just the curvature and torsion, the [[vector field]]s for the tangent, normal, and binormal vectors can be derived using the [[Frenet–Serret formulas]].  Then, [[Integral|integration]] of the tangent field (done numerically, if not analytically) yields the curve.

==Congruence==
If a pair of curves are in different positions but have the same curvature and torsion, then they are [[congruence (geometry)|congruent]] to each other.

==See also==
*[[Gaussian curvature]]

==References==
{{Reflist}}
*{{cite book |title = Differential Geometry of Curves and Surfaces|first = Manfredo|last = do Carmo|authorlink=Manfredo do Carmo | isbn = 0-13-212589-7 | year = 1976}}

{{Fundamental theorems}}

{{DEFAULTSORT:Fundamental Theorem Of Curves}}
[[Category:Differential geometry]]
[[Category:Curves]]
[[Category:Theorems in differential geometry]]
[[Category:Fundamental theorems|Curves]]</text>
      <sha1>rsfwjitfpe162bwy69giyt8w14qlw9r</sha1>
    </revision>
  </page>
  <page>
    <title>Graph factorization</title>
    <ns>0</ns>
    <id>3298854</id>
    <revision>
      <id>865803519</id>
      <parentid>841847329</parentid>
      <timestamp>2018-10-26T07:45:54Z</timestamp>
      <contributor>
        <username>Hjthoma</username>
        <id>16918609</id>
      </contributor>
      <comment>Changed false statement. Not all 1-factorable graphs are regular, for example, P3, the path of length 3.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10912">{{Distinguish|Factor graph}}

[[Image:Desargues graph 3color edge.svg|thumb|200px|1-factorization of [[Desargues graph]]: each color class is a 1-factor.]]
[[Image:Petersen-graph-factors.svg|right|thumb|200px|[[Petersen graph]] can be partitioned into a 1-factor (red) and a 2-factor (blue). However, the graph is not 1-factorable.]]
In [[graph theory]], a '''factor''' of a graph ''G'' is a [[spanning subgraph]], i.e., a subgraph that has the same vertex set as ''G''. A '''''k''-factor''' of a graph is a spanning ''k''-[[Regular graph|regular]] subgraph, and a '''''k''-factorization''' partitions the edges of the graph into disjoint ''k''-factors. A graph ''G'' is said to be '''''k''-factorable''' if it admits a ''k''-factorization. In particular, a '''1-factor''' is a [[perfect matching]], and a 1-factorization of a ''k''-[[regular graph]] is an [[edge coloring]] with ''k'' colors. A '''2-factor''' is a collection of [[Cycle (graph theory)|cycles]] that spans all vertices of the graph.

==1-factorization==

Not every 1-factorable graph (ie, a graph which has a 1-factorization), has to be a [[regular graph]]. Additionally, not all regular graphs are 1-factorable. A ''k''-regular graph is 1-factorable if it has [[chromatic index]] ''k''; examples of such graphs include:
* Any regular [[bipartite graph]].&lt;ref&gt;{{harvtxt|Harary|1969}}, Theorem 9.2, p. 85. {{harvtxt|Diestel|2005}}, Corollary 2.1.3, p. 37.&lt;/ref&gt; [[Hall's marriage theorem]] can be used to show that a ''k''-regular bipartite graph contains a perfect matching. One can then remove the perfect matching to obtain a (''k''&amp;nbsp;&amp;minus;&amp;nbsp;1)-regular bipartite graph, and apply the same reasoning repeatedly.
* Any [[complete graph]] with an even number of nodes (see [[#Complete graphs|below]]).&lt;ref&gt;{{harvtxt|Harary|1969}}, Theorem 9.1, p. 85.&lt;/ref&gt;
However, there are also ''k''-regular graphs that have chromatic index ''k''&amp;nbsp;+&amp;nbsp;1, and these graphs are not 1-factorable; examples of such graphs include:
* Any regular graph with an odd number of nodes.
* The [[Petersen graph]].

===Complete graphs===
[[File:Complete-edge-coloring.svg|thumb|200px|1-factorization of ''K''&lt;sub&gt;8&lt;/sub&gt; in which each 1-factor consists of an edge from the center to a vertex of a [[heptagon]] together with all possible perpendicular edges]]
A 1-factorization of a [[complete graph]] corresponds to pairings in a [[round-robin tournament]]. The 1-factorization of complete graphs is a special case of [[Baranyai's theorem]] concerning the 1-factorization of complete [[hypergraph]]s.

One method for constructing a 1-factorization of a complete graph on an even number of vertices involves placing all but one of the vertices on a circle, forming a [[regular polygon]], with the remaining vertex at the center of the circle. With this arrangement of vertices, one way of constructing a 1-factor of the graph is to choose an edge ''e'' from the center to a single polygon vertex together with all possible edges that lie on lines perpendicular to ''e''. The 1-factors that can be constructed in this way form a 1-factorization of the graph.

The number of distinct 1-factorizations of ''K''&lt;sub&gt;2&lt;/sub&gt;, ''K''&lt;sub&gt;4&lt;/sub&gt;, ''K''&lt;sub&gt;6&lt;/sub&gt;, ''K''&lt;sub&gt;8&lt;/sub&gt;, ... is 1, 1, 6, 6240, 1225566720, 252282619805368320, 98758655816833727741338583040, ... {{oeis|A000438}}.

===1-factorization conjecture===
Let ''G'' be a ''k''-regular graph with 2''n'' nodes. If ''k'' is sufficiently large, it is known that ''G'' has to be 1-factorable:
* If ''k''&amp;nbsp;=&amp;nbsp;2''n''&amp;nbsp;&amp;minus;&amp;nbsp;1, then ''G'' is the complete graph ''K''&lt;sub&gt;2''n''&lt;/sub&gt;, and hence 1-factorable (see [[#Complete graphs|above]]).
* If ''k''&amp;nbsp;=&amp;nbsp;2''n''&amp;nbsp;&amp;minus;&amp;nbsp;2, then ''G'' can be constructed by removing a perfect matching from ''K''&lt;sub&gt;2''n''&lt;/sub&gt;. Again, ''G'' is 1-factorable.
* {{harvtxt|Chetwynd|Hilton|1985}} show that if ''k''&amp;nbsp;≥&amp;nbsp;12n/7, then ''G'' is 1-factorable.
The '''1-factorization conjecture'''&lt;ref&gt;{{harvtxt|Chetwynd|Hilton|1985}}. {{harvtxt|Niessen|1994}}. {{harvtxt|Perkovic|Reed|1997}}. [[#West1FC|West]].&lt;/ref&gt; is a long-standing [[conjecture]] that states that ''k''&amp;nbsp;≈&amp;nbsp;''n'' is sufficient. In precise terms, the conjecture is:
* If ''n'' is odd and ''k''&amp;nbsp;≥&amp;nbsp;''n'', then ''G'' is 1-factorable. If ''n'' is even and ''k''&amp;nbsp;≥&amp;nbsp;''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 then ''G'' is 1-factorable.
The [[overfull conjecture]] implies the 1-factorization conjecture.

===Perfect 1-factorization===
A '''perfect pair''' from a 1-factorization is a pair of 1-factors whose union [[Glossary_of_graph_theory#Subgraphs|induces]] a [[Hamiltonian cycle]].

A '''perfect 1-factorization''' (P1F) of a graph is a 1-factorization having the property that every pair of 1-factors is a perfect pair. A perfect 1-factorization should not be confused with a perfect matching (also called a 1-factor).

In 1964, [[Anton Kotzig]] conjectured that every [[complete graph]] ''K''&lt;sub&gt;2''n''&lt;/sub&gt; where ''n'' ≥ 2 has a perfect 1-factorization. So far, it is known that the following graphs have a perfect 1-factorization:&lt;ref name="wallis"&gt;
{{Citation
 | first = W. D. | last = Wallis
 | title = One-factorizations
 | publisher = [[Springer US]]
 | series = Mathematics and Its Applications
 | volume = 390
 | edition = 1
 | year = 1997
 | chapter = 16. Perfect Factorizations
 | page = 125
 | doi = 10.1007/978-1-4757-2564-3_16
 | isbn = 978-0-7923-4323-3
}}
&lt;/ref&gt;

* the infinite family of complete graphs ''K''&lt;sub&gt;2''p''&lt;/sub&gt; where ''p'' is an odd prime (by Anderson and also Nakamura, independently),
* the infinite family of complete graphs ''K''&lt;sub&gt;''p'' + 1&lt;/sub&gt; where ''p'' is an odd prime,
* and sporadic additional results, including ''K''&lt;sub&gt;2''n''&lt;/sub&gt; where 2''n'' ∈ {16, 28, 36, 40, 50, 126, 170, 244, 344, 730, 1332, 1370, 1850, 2198, 3126, 6860, 12168, 16808, 29792}. Some newer results are collected [http://users.monash.edu.au/~iwanless/data/P1F/newP1F.html here].
&lt;!-- Related OEIS sequences: A005702 A120488 A120489 --&gt;

If the complete graph ''K''&lt;sub&gt;''n'' + 1&lt;/sub&gt; has a perfect 1-factorization, then the [[complete bipartite graph]] ''K''&lt;sub&gt;''n'',''n''&lt;/sub&gt; also has a perfect 1-factorization.&lt;ref name="wanless"&gt;
{{Citation
| last1  = Bryant
| first1 = Darryn
| last2  = Maenhaut
| first2 = Barbara M.
| last3  = Wanless
| first3 = Ian M.

| title   = A Family of Perfect Factorisations of Complete Bipartite Graphs
| journal = Journal of Combinatorial Theory
| series  = A
| volume  = 98
| issue   = 2
| pages   = 328–342
| date    = May 2002
| issn    = 0097-3165
| doi     = 10.1006/jcta.2001.3240
}}
&lt;/ref&gt;

==2-factorization==

If a graph is 2-factorable, then it has to be 2''k''-regular for some integer ''k''. [[Julius Petersen]] showed in 1891 that this necessary condition is also sufficient: any 2''k''-regular graph is 2-factorable.&lt;ref&gt;{{harvtxt|Petersen|1891}}, §9, p. 200. {{harvtxt|Harary|1969}}, Theorem 9.9, p. 90. See {{harvtxt|Diestel|2005}}, Corollary 2.1.5, p. 39 for a proof.&lt;/ref&gt;

If a connected graph is 2''k''-regular and has an even number of edges it may also be ''k''-factored, by choosing each of the two factors to be an alternating subset of the edges of an [[Euler tour]].&lt;ref&gt;{{harvtxt|Petersen|1891}}, §6, p. 198.&lt;/ref&gt;  This applies only to connected graphs; disconnected counterexamples include disjoint unions of odd cycles, or of copies of ''K''&lt;sub&gt;2''k''+1&lt;/sub&gt;.

The [[Oberwolfach problem]] concerns the existence of 2-factorizations of [[complete graph]]s into isomorphic subgraphs. It asks for which subgraphs this is possible. This is known when the subgraph is connected (in which case it is a [[Hamiltonian cycle]] and this special case is the problem of [[Hamiltonian decomposition]]) but the general case remains unsolved.

==Notes==
{{reflist}}

==References==
{{refbegin}}
*{{citation
 |last1       = Bondy
 |first1      = John Adrian
 |authorlink1 = John Adrian Bondy
 |last2       = Murty
 |first2      = U. S. R.
 |authorlink2 = U. S. R. Murty
 |title       = Graph Theory with Applications
 |year        = 1976
 |publisher   = North-Holland
 |isbn        = 0-444-19451-7
 |url         = http://www.math.jussieu.fr/~jabondy/books/gtwa/gtwa.html
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20120616164929/http://www.math.jussieu.fr/~jabondy/books/gtwa/gtwa.html
 |archivedate = 2012-06-16
 |df          = 
}}, Section 5.1: "Matchings".
*{{citation
 | last1=Chetwynd | first1=A. G.
 | last2=Hilton | first2=A. J. W.
 | title=Regular graphs of high degree are 1-factorizable
 | journal=Proceedings of the London Mathematical Society
 | year=1985
 | volume=50
 | number=2
 | pages=193–206
 | doi=10.1112/plms/s3-50.2.193 
}}.
*{{citation
 | last=Diestel | first=Reinhard
 | title=Graph Theory
 | publisher=[[Springer Science+Business Media|Springer]]
 | year=2005
 | edition=3rd
 | isbn=3-540-26182-6
}}, Chapter 2: "Matching, covering and packing". [http://www.math.uni-hamburg.de/home/diestel/books/graph.theory/ Electronic edition].
*{{citation
 | last=Harary | first=Frank | authorlink=Frank Harary
 | title=Graph Theory
 | publisher=Addison-Wesley
 | year=1969
 | isbn=0-201-02787-9
}}, Chapter 9: "Factorization".
* {{springer|title=One-factorization|id=p/o110070}}
*{{citation
 | last=Niessen | first=Thomas
 | title=How to find overfull subgraphs in graphs with large maximum degree
 | journal=Discrete Applied Mathematics
 | volume=51
 | number=1–2
 | year=1994
 | pages=117–125 
 | doi=10.1016/0166-218X(94)90101-5
}}.
*{{citation
 | last1=Perkovic | first1=L.
 | last2=Reed | first2=B. | author2-link=Bruce Reed (mathematician)
 | title=Edge coloring regular graphs of high degree
 | journal=[[Discrete Mathematics (journal)|Discrete Mathematics]]
 | volume=165–166
 | year=1997
 | pages=567–578
 | doi=10.1016/S0012-365X(96)00202-6
}}.
*{{citation
 | last=Petersen | first=Julius | authorlink=Julius Petersen
 | title=Die Theorie der regulären graphs
 | journal=[[Acta Mathematica]]
 | volume=15
 | year=1891
 | pages = 193–220
 | doi = 10.1007/BF02392606}}.
*{{cite web
 | last=West | first=Douglas B.
 | url=http://www.math.uiuc.edu/~west/openp/1fact.html
 | title=1-Factorization Conjecture (1985?)
 | work=Open Problems – Graph Theory and Combinatorics
 | accessdate=2010-01-09
 | ref=West1FC
}}
*{{MathWorld | urlname=GraphFactor | title=Graph Factor}}
*{{MathWorld | urlname=k-Factor | title=k-Factor}}
*{{MathWorld | urlname=k-FactorableGraph | title=k-Factorable Graph}}
{{refend}}

==Further reading==
{{refbegin}}
*{{citation
 | last=Plummer | first=Michael D. | authorlink = Michael D. Plummer
 | title=Graph factors and factorization: 1985–2003: A survey
 | journal=[[Discrete Mathematics (journal)|Discrete Mathematics]]
 | volume=307
 | number=7–8
 | year=2007
 | pages=791–821
 | doi=10.1016/j.disc.2005.11.059
}}.
{{refend}}

[[Category:Graph theory objects]]</text>
      <sha1>fs9uyzyjaqzsdc7okxrfj6qfp5k4p0b</sha1>
    </revision>
  </page>
  <page>
    <title>Implied binomial tree</title>
    <ns>0</ns>
    <id>43721341</id>
    <redirect title="Lattice model (finance)" />
    <revision>
      <id>701076312</id>
      <parentid>632250910</parentid>
      <timestamp>2016-01-22T10:34:51Z</timestamp>
      <contributor>
        <ip>169.202.5.162</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="135">#REDIRECT [[Lattice_model_(finance)#Equity_and_commodity_derivatives]]
[[Category:Mathematical finance]]
[[Category:Options (finance)]]</text>
      <sha1>td9p6bcq83u2acvp36x7wp48tq9ii2y</sha1>
    </revision>
  </page>
  <page>
    <title>Infinity symbol</title>
    <ns>0</ns>
    <id>1605389</id>
    <revision>
      <id>869604588</id>
      <parentid>869604574</parentid>
      <timestamp>2018-11-19T17:46:14Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/80.216.78.44|80.216.78.44]] to version by Shellwood. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3543174) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8190">[[File:Infinity symbol.svg|thumb|The ∞ symbol in several typefaces]]
The '''infinity symbol''' {{math|∞|size=150%}} (sometimes called the [[lemniscate]]) is a [[List of mathematical symbols|mathematical symbol]] representing the concept of [[infinity]].

==History==
[[File:John Wallis by Sir Godfrey Kneller, Bt.jpg|thumb|left|[[John Wallis]] introduced the infinity symbol to mathematical literature.]]

The shape of a sideways figure eight has a long pedigree; for instance, it appears in the cross of [[Saint Boniface]], wrapped around the bars of a [[Latin cross]].&lt;ref name="barrow"&gt;{{citation|title=Cosmic Imagery: Key Images in the History of Science|first=John D.|last=Barrow|authorlink=John D. Barrow|publisher=W. W. Norton &amp; Company|year=2008|isbn=9780393061772|contribution=Infinity: Where God Divides by Zero|pages=339–340|url=https://books.google.com/books?id=uRg6iN10JCIC&amp;pg=PA339}}&lt;/ref&gt; However, [[John Wallis]] is credited with introducing the infinity symbol with its mathematical meaning in 1655, in his ''De sectionibus conicis''.&lt;ref name="barrow"/&gt;&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=03M_AAAAcAAJ&amp;pg=PP5 |title=De sectionibus conicis nova methodo expositis tractatus - John Wallis - Google Boeken |publisher=Books.google.com |date= |accessdate=2013-12-01}} See e.g. Prop.&amp;nbsp;1, p.&amp;nbsp;4.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Scott | first = Joseph Frederick
 | edition = 2
 | isbn = 0-8284-0314-7
 | page = 24
 | publisher = [[American Mathematical Society]]
 | title = The mathematical work of John Wallis, D.D., F.R.S., (1616-1703)
 | url = https://books.google.com/books?id=XX9PKytw8g8C&amp;pg=PA24
 | year = 1981}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Martin-Löf | first = Per | author-link = Per Martin-Löf
 | contribution = Mathematics of infinity
 | doi = 10.1007/3-540-52335-9_54
 | location = Berlin
 | mr = 1064143
 | pages = 146–197
 | publisher = Springer
 | series = [[Lecture Notes in Computer Science]]
 | title = COLOG-88 (Tallinn, 1988)
 | volume = 417
 | year = 1990}}&lt;/ref&gt;
Wallis did not explain his choice of this symbol, but it has been conjectured to be a variant form of a [[Roman numeral#Large numbers|Roman numeral]] for 1,000 (originally CIƆ, also CƆ), which was sometimes used to mean "many", or of the Greek letter&amp;nbsp;ω ([[omega]]), the last letter in the [[Greek alphabet]].&lt;ref&gt;{{citation|title=A brief history of infinity: the quest to think the unthinkable|first=Brian|last=Clegg|publisher=Robinson|year=2003|isbn=9781841196503}}&lt;/ref&gt;

[[File:Euler's infinity sign.svg|thumb|Symbol used by Euler to denote infinity]]
[[Leonhard Euler]] used an open variant of the symbol&lt;ref&gt;See for instance Cor. 1 p. 174 in:  Leonhard Euler.  Variae observationes circa series infinitas. Commentarii academiae scientiarum Petropolitanae 9, 1744, pp. 160-188. [http://eulerarchive.maa.org/docs/originals/E072.pdf]&lt;/ref&gt; in order to denote "absolutus infinitus". Euler freely performed various operations on infinity, such as taking its logarithm. This symbol is not used anymore, and is not encoded as a separate character in Unicode.

==Usage==
In mathematics, the infinity symbol is used more often to represent a [[potential infinity]],&lt;ref name="barrow"/&gt; rather than to represent an actually infinite quantity such as the [[ordinal number]]s and [[cardinal number]]s (which use other notations). For instance, in the mathematical notation for [[summation]]s and [[Limit (mathematics)|limit]]s such as
:&lt;math&gt; \sum_{n=0}^{\infty} \frac{1}{2^n} = \lim_{x\to\infty}\frac{2^x-1}{2^{x-1}} = 2,&lt;/math&gt;
the infinity sign is conventionally interpreted as meaning that the variable grows arbitrarily large (towards infinity) rather than actually taking an infinite value.

The infinity symbol may also be used to represent a [[point at infinity]], especially when there is only one such point under consideration. This usage includes, for instance,
the infinite point of a [[projective line]],&lt;ref&gt;{{citation|title=Algebraic Geometry: An Introduction|first=Daniel|last=Perrin|publisher=Springer|year=2007|isbn=9781848000568|page=28|url=https://books.google.com/books?id=Vn1yR9qPvlMC&amp;pg=PA28}}&lt;/ref&gt;
and the point added to a [[topological space]] &lt;math&gt;T&lt;/math&gt; to form its [[Alexandroff extension|one-point compactification]] &lt;math&gt;T_{\infty}&lt;/math&gt;.&lt;ref&gt;{{citation|title= Infinite Dimensional Analysis: A Hitchhiker's Guide|first1=Charalambos D.|last1=Aliprantis|first2=Kim C.|last2=Border|edition=3rd|publisher=Springer|year=2006|isbn=9783540295877|pages=56–57|url=https://books.google.com/books?id=4vyXtR3vUhoC&amp;pg=PA56}}&lt;/ref&gt;

In areas other than mathematics, the infinity symbol may take on other related meanings; for instance, it has been used in [[bookbinding]] to indicate that a book is printed on [[acid-free paper]] and will therefore be long-lasting.&lt;ref&gt;{{citation|title=A handbook for the study of book history in the United States|first1=Ronald J.|last1=Zboray|first2=Mary Saracino|last2=Zboray|publisher=Center for the Book, Library of Congress|year=2000|isbn=9780844410159|page=49}}&lt;/ref&gt;

==Modern symbolism==
[[File:RWS Tarot 08 Strength.jpg|thumb|The infinity symbol appears on several cards of the [[Rider-Waite tarot deck|Rider–Waite]] [[tarot]] deck]]

In modern mysticism, the infinity symbol has become identified with a variation of the [[ouroboros]], an ancient image of a snake eating its own tail that has also come to symbolize the infinite, and the ouroboros is sometimes drawn in figure-eight form to reflect this identification, rather than in its more traditional circular form.&lt;ref&gt;{{citation|title=Dreams, Illusion, and Other Realities|first=Wendy Doniger|last=O'Flaherty|publisher=University of Chicago Press|year=1986|isbn=9780226618555|page=243|url=https://books.google.com/books?id=vhNNrX3bmo4C&amp;pg=PA243}}. The book also features this image on its cover.&lt;/ref&gt;

In the works of [[Vladimir Nabokov]], including ''[[The Gift (Nabokov novel)|The Gift]]'' and ''[[Pale Fire]]'', the figure-eight shape is used symbolically to refer to the [[Möbius strip]] and the infinite, for instance in these books' descriptions of the shapes of bicycle tire tracks and of the outlines of half-remembered people. The poem after which ''Pale Fire'' is entitled explicitly refers to "the miracle of the lemniscate".&lt;ref&gt;{{citation|title=Nabokov: The Mystery of Literary Structures|first=Leona|last=Toker|publisher=Cornell University Press|year=1989|isbn=9780801422119|page=159|url=https://books.google.com/books?id=Jud1q_NrqpcC&amp;pg=PA159}}&lt;/ref&gt;

==Graphic design==
The well known shape and meaning of the infinity symbol have made it a common [[typography|typographic]] element of [[graphic design]]. For instance, the [[Métis flag]], used by the Canadian [[Métis people (Canada)|Métis people]] in the early 19th century, is based around this symbol.&lt;ref&gt;{{citation|title=Native American Flags|first1=Donald T.|last1=Healy|first2=Peter J.|last2=Orenski|publisher=University of Oklahoma Press|year=2003|isbn=9780806135564|page=284}}&lt;/ref&gt; In modern commerce, corporate logos featuring this symbol have been used by, among others, [[Room for PlayStation Portable]], [[Microsoft Visual Studio]], [[Fujitsu]], and [[CoorsTek]].

==Encoding==
The symbol is encoded in [[Unicode]] at {{unichar|221E|infinity}} and in [[LaTeX]] as &lt;code&gt;\infty&lt;/code&gt;: &lt;math&gt;\infty&lt;/math&gt;.

The Unicode set of symbols also includes several variant forms of the infinity symbol, that are less frequently available in fonts: {{unichar|29DC|INCOMPLETE INFINITY|html=|size=100%|note=ISOtech entity &lt;code&gt;⧜&lt;/code&gt;}}, {{unichar|29DD|TIE OVER INFINITY|html=|size=100%}} and {{unichar|29DE|INFINITY NEGATED WITH VERTICAL BAR|html=|size=100%}} in block Miscellaneous Mathematical Symbols-B.&lt;ref&gt;{{cite web|url=https://www.unicode.org/charts/PDF/U2980.pdf |title=Unicode chart (pdf) |format=PDF |date= |accessdate=2013-12-01}}&lt;/ref&gt; The acid-free paper symbol mentioned above is encoded separately as {{unichar|267E|PERMANENT PAPER SIGN|html=}}.

== See also ==
{{commons category|Infinity}}
* [[History of mathematical notation]]

==References==
{{reflist|35em}}

{{Infinity}}

[[Category:Mathematical symbols]]
[[Category:Infinity]]</text>
      <sha1>42ypjfol8m7ftu5ay8kqzkkp35sywy6</sha1>
    </revision>
  </page>
  <page>
    <title>Jeffrey Brock</title>
    <ns>0</ns>
    <id>56884970</id>
    <revision>
      <id>867767572</id>
      <parentid>858611790</parentid>
      <timestamp>2018-11-07T21:45:04Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Category:Fellows of the American Mathematical Society]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7139">[[File:JFB-Profile4.jpg|thumb|A recent picture of Jeffrey Brock]]
'''Jeffrey Farlowe Brock''' (born June 14, 1970, in [[Bronxville, New York]]) is an American mathematician, working in low-dimensional [[geometry]] and [[Topology|topology.]] He is known for his contributions to the understanding of [[Hyperbolic 3-manifold|hyperbolic 3-manifolds]] and the geometry of [[Teichmüller space|Teichmüller spaces]].   

Since July 2018, Brock is a Professor of Mathematics at [[Yale University]],&lt;ref name=":1"&gt;{{Cite news|url=https://news.yale.edu/2018/03/28/yale-appoints-mathematician-jeff-brock-first-fas-dean-science|title=Yale appoints mathematician Jeff Brock as first FAS dean of science|date=2018-03-28|work=YaleNews|access-date=2018-03-28|language=en}}&lt;/ref&gt; and from January 2019 he will become the first FAS (Faculty of Arts and Sciences) dean of science at [[Yale University]].&lt;ref name=":1" /&gt;

Before joining [[Yale University|Yale]], he was a professor at [[Brown University]],&lt;ref name=":0"&gt;{{Cite web|url=https://www.math.brown.edu/~brock/|title=Jeffrey F. Brock - Home|website=www.math.brown.edu|access-date=2018-03-19}}&lt;/ref&gt; and also founding director of the Data Science Iniative&lt;ref&gt;{{Cite web|url=https://www.brown.edu/initiatives/data-science/about/people/people-executive-committee|title=People: Executive Committee {{!}} Data Science Initiative|website=www.brown.edu|language=en|access-date=2018-03-22}}&lt;/ref&gt; at Brown University. 

== Biography ==
Brock obtained a BA (with distinction in [[Mathematics]]) from [[Yale University]] in 1992. He completed a Ph.D. in Mathematics from the [[University of California, Berkeley]] in 1997, under the supervision of [[Curtis T. McMullen]].&lt;ref&gt;{{Cite web|url=https://www.genealogy.math.ndsu.nodak.edu/id.php?id=32226|title=Jeffrey Brock – The Mathematics Genealogy Project|website=www.genealogy.math.ndsu.nodak.edu|access-date=2018-03-19}}&lt;/ref&gt;

Brock then held positions as (NSF-funded) Szego Assistant Professor &lt;ref name=":0" /&gt; at [[Stanford University]] (1997–2000), assistant professor &lt;ref name=":0" /&gt; at the [[University of Chicago]] (2000–2003), and Donald D. Harrington Faculty Fellow &lt;ref name=":0" /&gt; at the [[University of Texas at Austin]] (2003–2004). He became associate professor (with tenure) at [[Brown University]] in 2004, where he has been full professor since 2007.&lt;ref&gt;{{Cite web|url=https://www.math.brown.edu/people.html|title=People of the Math Department|last=department|first=PAUR Web|website=www.math.brown.edu|language=en|access-date=2018-03-19}}&lt;/ref&gt; He was chair of the Mathematics Department from 2013 to 2017.

Brock has been Associate Director of [[ICERM]] since 2013. Previously, he had been Deputy Director between 2010 and 2013.&lt;ref&gt;{{Cite web|url=https://icerm.brown.edu/people/|title=ICERM|website=icerm.brown.edu|access-date=2018-03-19}}&lt;/ref&gt;

Starting in July 2018 he will take up a position as Professor of Mathematics at [[Yale University]],&lt;ref name=":1" /&gt; and from January 2019 he will become the first FAS (Faculty of Arts and Sciences) dean of science at [[Yale University]].&lt;ref name=":1" /&gt;

Brock is also an accomplished [[jazz]] musician. He was the founding bassist of the Vijay Iyer Trio, lead by the acclaimed jazz pianist [[Vijay Iyer]].

He is married and has three children.

== Research ==
Jeffrey Brock's research focuses on [[low-dimensional topology]] and geometry, particularly on spaces with [[hyperbolic geometry]] or negative curvature. His joint work with [[Richard Canary]] and [[Yair Minsky]] resulted in a solution &lt;ref&gt;{{Cite journal|last=Brock|first=Jeffrey F.|last2=Canary|first2=Richard D.|last3=Minsky|first3=Yair N.|date=2012|title=The classification of Kleinian surface groups, II: The Ending Lamination Conjecture|jstor=23234164|journal=Annals of Mathematics|volume=176|issue=1|pages=1–149}}&lt;/ref&gt; to the "Ending Lamination Conjecture" of [[William Thurston]], culminating in the geometric classification theorem for (topologically-finite) hyperbolic 3-manifolds in terms of their fundamental group and the structure of their ends.

More recently, he has worked to understand applications of [[geometry]] and [[topology]] to the structure of massive and complex data sets and the risks and implications of the increasing use of 'black box' algorithms in science and society.

== Honors and awards &lt;ref name=":0" /&gt; ==
* Fellow of the [[American Mathematical Society]], 2017.
* Simons Fellowship (declined), 2016.
* [[John Simon Guggenheim Fellowship|John Simon Guggenheim]] Fellow, 2008.
* Donald D. Harrington Faculty Fellow, [[University of Texas at Austin]], 2003–2004.
* [[National Science Foundation]] Postdoctoral Fellow, [[Stanford University]], 1997–2000.
* [[Alfred P. Sloan]] Doctoral Dissertation Fellow, [[U.C. Berkeley]], 1996–1997.
* Outstanding Graduate Student Instructor Award, [[U.C. Berkeley]], 1996.
* [[National Science Foundation]] Graduate Fellow, [[U.C. Berkeley]], 1993–1996.
* Stanley and DeForest Mathematics Prizes, [[Yale University]], 1991 and 1992.

== Selected invited talks &lt;ref name=":0" /&gt; ==
* Geometric Topology in Low Dimensions ([[University of Warwick]]), 2017.
* Geometry, Topology and Dynamics of Moduli Spaces ([[National University of Singapore]]), 2016.
* Classical and quantum hyperbolic geometry and topology ([[Orsay]]), 2015.
* Hyperbolic Geometry and Minimal Surfaces (IMPA), 2015.
* Hyperbolic Geometry and Geometric Group Theory ([[Tokyo]]), 2014.

== Selected publications &lt;ref&gt;{{Cite web|url=https://mathscinet.ams.org/mathscinet/|title=MR: Search Publications database|website=mathscinet.ams.org|language=en|access-date=2018-03-19}}&lt;/ref&gt; ==
* (with Nathan Dunfield) "Norms on the cohomology of hyperbolic 3-manifolds", ''Invent. Math.'' 210 (2017), no. 2, 531–558.
* (with [[Yair Minsky]], Hossein Namazi and Juan Souto), "Bounded combinatorics and uniform models for hyperbolic 3-manifolds." ''J. Topol.'' 9 (2016), no. 2, 451–501.
* (with [[Richard Canary]] and [[Yair Minsky]]) "The classification of Kleinian surface groups, II: The ending lamination conjecture." ''Ann. of Math. (2)'' 176 (2012), no. 1, 1–149.
* (with [[Benson Farb]]) "Curvature and rank of Teichmüller space." ''Amer. J. Math.'' 128 (2006), no. 1, 1–22.
* (with Kenneth Bromberg) "On the density of geometrically finite Kleinian groups." ''Acta Math.'' 192 (2004), no. 1, 33–93.
* "The Weil–Petersson metric and volumes of 3-dimensional hyperbolic convex cores." ''J. Amer. Math. Soc.'' 16 (2003), no. 3, 495–535.
* "Iteration of mapping classes and limits of hyperbolic 3-manifolds." ''Invent. Math.'' 143 (2001), no. 3, 523–570.
* "Boundaries of Teichmüller spaces and end-invariants for hyperbolic 3-manifolds." ''Duke Math. J.'' 106 (2001), no. 3, 527–552.

== References ==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Brock, Jeffrey}}
[[Category:1970 births]]
[[Category:Living people]]
[[Category:American mathematicians]]
[[Category:Brown University faculty]]
[[Category:Yale University alumni]]
[[Category:University of California, Berkeley alumni]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>4ws16r2hbge36qu6cd67m2z59a7jvzg</sha1>
    </revision>
  </page>
  <page>
    <title>Kinetic smallest enclosing disk</title>
    <ns>0</ns>
    <id>35872975</id>
    <revision>
      <id>686405380</id>
      <parentid>675138668</parentid>
      <timestamp>2015-10-18T23:29:32Z</timestamp>
      <contributor>
        <username>Spinningspark</username>
        <id>3727527</id>
      </contributor>
      <minor/>
      <comment>/* 2D */ dab</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3313">A '''kinetic smallest enclosing disk''' data structure is a [[kinetic data structure]] that maintains the [[Smallest circle problem|smallest enclosing disk]] of a set of moving points.

== 2D ==
In 2 dimensions, the best known kinetic smallest enclosing disk data structure uses the farthest point delaunay triangulation of the point set to maintain the smallest enclosing disk.&lt;ref name="DEGS10" /&gt; The farthest-point [[Delaunay triangulation]] is the [[Duality (projective geometry)|dual]] of the [[Voronoi diagram#Higher-order Voronoi diagrams|farthest-point Voronoi diagram]]. It is known that if the farthest-point delaunay triangulation of a point set contains an acute triangle, the [[circumcircle]] of this triangle is the smallest enclosing disk. Otherwise, the smallest enclosing disk has the diameter of the point set as its diameter. Thus, by maintaining the [[Kinetic diameter (data)|kinetic diameter]] of the point set, the farthest-point delaunay triangulation, and whether or not the farthest-point delaunay triangulation has an acute triangle, the smallest enclosing disk can be maintained.
This data structure is responsive and compact, but not local or efficient:&lt;ref name="DEGS10" /&gt;
* '''[[Kinetic data structure#Performance|Responsiveness]]:''' This data structure requires &lt;math&gt;O(\log^2 n)&lt;/math&gt; time to process each certificate failure, and thus is responsive.
* '''[[Kinetic data structure#Performance|Locality]]:''' A point can be involved in &lt;math&gt;\Theta(n)&lt;/math&gt; certificates. Therefore, this data structure is not local.
* '''[[Kinetic data structure#Performance|Compactness]]:''' This data structure requires O(n) certificates total, and thus is compact.
* '''[[Kinetic data structure#Performance|Efficiency]]:''' This data structure has &lt;math&gt;O(n^{3+\epsilon})&lt;/math&gt; events total.(for all &lt;math&gt;\epsilon&gt;0&lt;/math&gt; The best known lower bound on the number of changes to the smallest enclosing disk is &lt;math&gt;\Omega(n^2)&lt;/math&gt;. Thus the efficiency of this data structure, the ratio of total events to external events, is &lt;math&gt;O(n^{1+\epsilon})&lt;/math&gt;.
The existence of kinetic data structure that has &lt;math&gt;o(n^{3+\epsilon})&lt;/math&gt; events is an open problem.&lt;ref name="DEGS10" /&gt;

== Approximate 2D ==
The smallest enclosing disk of a set of n moving points can be [[Approximation_algorithm#Epsilon_terms|ε-approximated]] by a kinetic data structure that processes &lt;math&gt;O(1/\epsilon^{5/2})&lt;/math&gt; events and requires &lt;math&gt;O((n/\sqrt{\epsilon})\log n)&lt;/math&gt; time total.&lt;ref name="AH01" /&gt;

== Higher dimensions ==
In dimensions higher than 2, efficiently maintaining the smallest enclosing sphere of a set of moving points is an open problem.&lt;ref name="DEGS10" /&gt;

== References ==
{{Reflist| refs=
&lt;ref name ="DEGS10"&gt;
Erik D. Demaine, Sarah Eisenstat, [[Leonidas J. Guibas]], André Schulz, Kinetic Minimum Spanning Circle, 2010. [http://www.ams.sunysb.edu/~jsbm/fwcg10/papers/25.pdf]
&lt;/ref&gt;
&lt;ref name="AH01"&gt;
Pankaj K. Agarwal and Sariel Hal-Peled. Maintaining approximate extent measures of moving points. In SODA '01: Proceedings of the twelfth annual ACM-SIAM symposium on Discrete algorithms, pages 148–157, Philadelphia, PA, USA, 2001. Society for Industrial and Applied Mathematics.
&lt;/ref&gt;
}}

[[Category:Kinetic data structures]]
[[Category:Computational geometry]]</text>
      <sha1>ljzrhprrfktauby8cw9z5k3khk37n24</sha1>
    </revision>
  </page>
  <page>
    <title>Knowledge Interchange Format</title>
    <ns>0</ns>
    <id>5558061</id>
    <revision>
      <id>730450786</id>
      <parentid>701077025</parentid>
      <timestamp>2016-07-19T02:49:53Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2871">'''Knowledge Interchange Format''' ('''KIF''') is a computer language designed to enable systems to share and re-use information from [[knowledge-based systems]]. KIF is similar to [[frame language]]s such as [[KL-ONE|KL-One]] and [[LOOM (ontology)|LOOM]] but unlike such language its primary role is not intended as a framework for the expression or use of knowledge but rather for the interchange of knowledge between systems. The designers of KIF likened it to [[PostScript]]. PostScript was not designed primarily as a language to store and manipulate documents but rather as an interchange format for systems and devices to share documents. In the same way KIF is meant to facilitate sharing of knowledge across different systems that use different languages, formalisms, platforms, etc.

KIF has a [[Declarative knowledge|declarative semantics]]. It is meant to describe facts about the world rather than processes or procedures. Knowledge can be described as objects, functions, relations, and rules. It is a formal language, i.e., it can express arbitrary statements in [[first order logic]] and can support [[Reasoning system|reasoners]] that can prove the consistency of a set of KIF statements. KIF also supports [[non-monotonic reasoning]]. KIF was  created by Michael Genesereth, [[Richard Fikes]] and others participating in the DARPA knowledge Sharing Effort.&lt;ref&gt;{{cite journal|last1=Genesereth|first1=Michael|last2=Fikes|first2=Richard|title=Knowledge Interchange Format Version 3.0 Reference Manual|journal=Stanford Logic Group Report|date=June 1992|volume=Logic-92-1|url=https://www.cs.auckland.ac.nz/courses/compsci367s2c/resources/kif.pdf|accessdate=7 August 2014|publisher=Stanford University}}&lt;/ref&gt;

Although the original KIF group intended to submit to a formal standards body, that did not occur.  A later version called [[Common Logic]] has since been developed for submission to [[International Organization for Standardization|ISO]] and has been approved and published. A variant called SUO-KIF&lt;ref&gt;{{cite web|last1=Pease|first1=Adam|title=Standard Upper Ontology Knowledge Interchange Format|url=http://sigmakee.cvs.sourceforge.net/viewvc/sigmakee/sigma/suo-kif.pdf|website=http://sigmakee.cvs.sourceforge.net|accessdate=7 August 2014|date=2009-06-18}}&lt;/ref&gt; is the language in which the [[Suggested Upper Merged Ontology]]&lt;ref&gt;[http://www.ontologyportal.org/ Suggested Upper Merged Ontology].&lt;/ref&gt; is written.

== See also ==
* [[Knowledge Query and Manipulation Language]]

== References ==
{{reflist}}

== External links ==
* [http://www.ksl.stanford.edu/knowledge-sharing/kif/ Knowledge Interchange Format] page at the [[Stanford AI Lab]]
* [http://iso-commonlogic.org/ Common Logic]

[[Category:Knowledge representation languages]]
[[Category:Ontology (information science)]]
[[Category:Logic in computer science]]


{{compu-sci-stub}}</text>
      <sha1>itsqmxcxigks4i1ur54z00x2lq85sij</sha1>
    </revision>
  </page>
  <page>
    <title>Koenigs function</title>
    <ns>0</ns>
    <id>33973912</id>
    <revision>
      <id>713379796</id>
      <parentid>673505746</parentid>
      <timestamp>2016-04-03T18:07:17Z</timestamp>
      <contributor>
        <username>Adam majewski</username>
        <id>441224</id>
      </contributor>
      <comment>/* Existence and uniqueness of Koenigs function */ links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7094">In [[mathematics]], the '''Koenigs function''' is a function arising in [[complex analysis]] and [[dynamical systems]]. Introduced in 1884 by the French mathematician [[Gabriel Koenigs]], it gives a canonical representation as dilations of a [[univalent function|univalent holomorphic mapping]], or a [[semigroup]] of mappings, of the [[unit disk]] in the [[complex numbers]] into itself.

==Existence and uniqueness of Koenigs function==
Let ''D'' be the [[unit disk]] in the complex numbers. Let {{mvar|f}} be a [[holomorphic function]] mapping ''D'' into itself, fixing the point 0, with {{mvar|f}} not identically 0 and {{mvar|f}}  not an automorphism of ''D'', i.e. a [[Möbius transformation]] defined by a matrix in SU(1,1).

By the [[Denjoy-Wolff theorem]], {{mvar|f}}  leaves invariant each disk |''z'' | &lt; ''r'' and the iterates of {{mvar|f}} converge uniformly on compacta to 0: in fact for 0 &lt; {{mvar|r}}  &lt; 1, 
:&lt;math&gt; |f(z)|\le M(r) |z|&lt;/math&gt;
for |''z'' | ≤ ''r'' with ''M''(''r'' ) &lt; 1. Moreover {{mvar|f}} '(0) = {{mvar|λ}} with 0 &lt; |{{mvar|λ}}| &lt; 1.

{{harvtxt|Koenigs|1884}} proved that there is a unique holomorphic function ''h'' defined on ''D'', called the '''Koenigs function''',  
such that {{mvar|h}}(0) = 0, {{mvar|h}} '(0) = 1 and [[Schröder's equation]] is satisfied,
:&lt;math&gt; h(f(z))= f^\prime(0) h(z) ~.&lt;/math&gt;

The function ''h'' is ''the [[uniform limit]] on [[Compact space|compacta]] of the normalized iterates'',  &lt;math&gt;g_n(z)=  \lambda^{-n} f^n(z)&lt;/math&gt;. 

Moreover, if {{mvar|f}} is univalent, so is {{mvar|h}}.&lt;ref&gt;{{harvnb|Carleson|Gamelin|1993|pp=28–32}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Shapiro|1993|pp=90–93}}&lt;/ref&gt;

As a consequence, when {{mvar|f}} (and hence {{mvar|h}}) are univalent, {{mvar|D}} can be identified with the open domain {{math|''U'' {{=}} ''h''(''D'')}}. Under this conformal identification, the mapping &amp;nbsp;  {{mvar|f}}  becomes multiplication by {{mvar|λ}}, a dilation on {{mvar|U}}.

===Proof===
*''Uniqueness''. If {{mvar|k}} is another solution then, by analyticity, it suffices to show that ''k'' = ''h'' near 0. Let 
::&lt;math&gt; H=k\circ h^{-1} (z) &lt;/math&gt; 
:near 0. Thus ''H''(0) =0, ''H'''(0)=1 and, for |''z'' | small,
::&lt;math&gt;\lambda H(z)=\lambda h(k^{-1} (z)) = h(f(k^{-1}(z))=h(k^{-1}(\lambda z)= H(\lambda z)~.&lt;/math&gt;

:Substituting into the power series for {{mvar|H}}, it follows that {{math|''H''(''z'') {{=}} ''z''}} near 0. Hence {{math|''h'' {{=}} ''k''}} near 0.

*''Existence''. If &lt;math&gt; F(z)=f(z)/\lambda z,&lt;/math&gt; then by the [[Schwarz lemma]]

::&lt;math&gt;|F(z) - 1|\le (1+|\lambda|^{-1})|z|~.&lt;/math&gt;

:On the other hand,
::&lt;math&gt; g_n(z) = z\prod_{j=0}^{n-1} F(f^j(z))~.&lt;/math&gt;

:Hence ''g''&lt;sub&gt;''n''&lt;/sub&gt; converges uniformly for |''z''| ≤ ''r'' by the [[Weierstrass M-test]] since

::&lt;math&gt; \sum \sup_{|z|\le r} |1 -F\circ f^j(z)| \le (1+|\lambda|^{-1}) \sum M(r)^j &lt;\infty.&lt;/math&gt;

*''Univalence''. By [[Hurwitz's theorem (complex analysis)|Hurwitz's theorem]], since each ''g''&lt;sup&gt;''n''&lt;/sup&gt; is univalent and normalized, i.e. fixes 0 and has derivative 1 there , their limit {{mvar|h}} is also univalent.

==Koenigs function of a semigroup==
Let {{math|''f''&lt;sub&gt;''t''&lt;/sub&gt; (''z'')}} be a semigroup of holomorphic univalent mappings of {{mvar|D}} into itself fixing 0 defined 
for {{math| ''t'' ∈ [0, ∞)}} such that

*&lt;math&gt;f_s&lt;/math&gt; is not an automorphism for {{mvar|s}} &gt; 0
*&lt;math&gt; f_s(f_t(z))=f_{t+s}(z)&lt;/math&gt;
*&lt;math&gt; f_0(z)=z&lt;/math&gt;
*&lt;math&gt; f_t(z)&lt;/math&gt; is jointly continuous in {{mvar|t}} and {{mvar|z}}

Each {{math|''f''&lt;sub&gt;''s''&lt;/sub&gt;}} with {{mvar|s}} &gt; 0 has the same Koenigs function, cf. [[iterated function]]. In fact, if ''h'' is the Koenigs function of 
{{math|''f'' {{=}} ''f''&lt;sub&gt;1&lt;/sub&gt;}}, then  {{math|''h''(''f''&lt;sub&gt;''s''&lt;/sub&gt;(''z''))}} satisfies Schroeder's equation and hence is proportion to ''h''.

Taking derivatives gives
:&lt;math&gt;h(f_s(z)) =f_s^\prime(0) h(z).&lt;/math&gt;
Hence {{mvar|h}} is the Koenigs function of {{math|''f''&lt;sub&gt;''s''&lt;/sub&gt;}}.

==Structure of univalent semigroups==
On the domain {{math|''U'' {{=}} ''h''(''D'')}}, the maps {{math|''f''&lt;sub&gt;''s''&lt;/sub&gt;}} become multiplication by &lt;math&gt;\lambda(s)=f_s^\prime(0)&lt;/math&gt;, a continuous semigroup.
So &lt;math&gt;\lambda(s)= e^{\mu s}&lt;/math&gt; where {{mvar|μ}} is a uniquely determined solution of {{math|''e &lt;sup&gt;μ&lt;/sup&gt; {{=}} λ''}}  with Re{{mvar|μ}} &lt; 0.  It follows that the semigroup is differentiable at 0. Let
:&lt;math&gt; v(z)=\partial_t f_t(z)|_{t=0},&lt;/math&gt;
a holomorphic function on {{mvar|D}} with ''v''(0) = 0 and {{math|''v'''(0)}} = {{mvar|μ}}. 

Then
:&lt;math&gt;\partial_t (f_t(z)) h^\prime(f_t(z))= \mu e^{\mu t} h(z)=\mu h(f_t(z)),&lt;/math&gt;
so that
:&lt;math&gt; v=v^\prime(0) {h\over h^\prime}&lt;/math&gt;
and
:&lt;math&gt;\partial_t f_t(z) = v(f_t(z)),\,\,\, f_t(z)=0  ~,&lt;/math&gt;
the flow equation for a vector field.

Restricting to the case with 0 &lt; λ &lt; 1, the ''h''(''D'') must be [[star domain|starlike]] so that
:&lt;math&gt;\Re {zh^\prime(z)\over h(z)} \ge 0  ~.&lt;/math&gt;

Since the same result holds for the reciprocal,
:&lt;math&gt; \Re {v(z)\over z}\le 0 ~,&lt;/math&gt;
so that {{math|''v''(''z'')}} satisfies the conditions of {{harvtxt|Berkson|Porta|1978}}
:&lt;math&gt; v(z)= z p(z),\,\,\, \Re p(z) \le 0, \,\,\, p^\prime(0) &lt; 0.&lt;/math&gt;

Conversely, reversing the above steps, any holomorphic vector field {{math|''v''(''z'')}}  satisfying these conditions is associated to a semigroup  {{math|''f''&lt;sub&gt;''t''&lt;/sub&gt;}}, with
:&lt;math&gt; h(z)= z \exp \int_0^z {v^\prime(0) \over v(w)} -{1\over w} \, dw.&lt;/math&gt;

==Notes==
{{reflist}}

==References==
*{{citation|last=Berkson|first=E.|last2= Porta|first2= H.|title=Semigroups of analytic functions and composition operators|journal=
Michigan Math. J.|volume= 25|year= 1978|pages= 101–115|doi=10.1307/mmj/1029002009}}
*{{citation|last=Carleson|first=L.|last2= Gamelin|first2= T. D. W.|title=Complex dynamics|series=
Universitext: Tracts in Mathematics|publisher= Springer-Verlag|year=1993|isbn=0-387-97942-5}}
*{{citation|last2=Shoikhet|first2=D.|title=Linearization Models for Complex Dynamical Systems: Topics in Univalent Functions, Functional Equations and Semigroup Theory|volume=208|series= Operator Theory: Advances and Applications|first=M.|last= Elin|publisher=Springer|year= 2010|isbn=    978-3034605083}}
*{{citation|first=G.P.X.|last=Koenigs|title=Recherches sur les intégrales de certaines équations fonctionnelles|journal=Ann. Sci. Ecole Norm. Sup.|volume= 1|year=1884|pages= 2–41}}
*{{cite book |title=Functional equations in a single variable |last=Kuczma |first=Marek|authorlink=Marek Kuczma|series=Monografie Matematyczne |year=1968 |publisher=PWN – Polish Scientific Publishers |location=Warszawa}}  ASIN: B0006BTAC2
*{{citation|last=Shapiro|first=J. H.|title=Composition operators and classical function theory|series=Universitext: Tracts in Mathematics|publisher= Springer-Verlag|year= 1993|isbn=0-387-94067-7}}
*{{citation|last=Shoikhet|first=D.|title=Semigroups in geometrical function theory|publisher= Kluwer Academic Publishers|year= 2001|isbn=
0-7923-7111-9 }}

[[Category:Complex analysis]]
[[Category:Dynamical systems]]
[[Category:Types of functions]]</text>
      <sha1>0cnys794ed5xuvhxa94kfizwthvfmdy</sha1>
    </revision>
  </page>
  <page>
    <title>Lemniscate</title>
    <ns>0</ns>
    <id>5210590</id>
    <revision>
      <id>866205636</id>
      <parentid>866205544</parentid>
      <timestamp>2018-10-28T23:28:53Z</timestamp>
      <contributor>
        <username>RHcosm</username>
        <id>34625434</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/72.80.137.214|72.80.137.214]] ([[User talk:72.80.137.214|talk]]) to last revision by Plandu. ([[WP:TW|Twinkle]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8215">{{about|figure-eight shaped curves in algebraic geometry|other uses|Lemniscate (disambiguation)}}
[[Image:Lemniscate of Bernoulli.svg|thumb|400px|right|The lemniscate of Bernoulli and its two foci]]

In [[algebraic geometry]], a '''lemniscate''' is any of several figure-eight or {{math|[[∞]]}}-shaped [[curve]]s.&lt;ref name="lemniscatomy"/&gt;&lt;ref name="erickson"/&gt; The word comes from the [[Latin language|Latin]] "lēmniscātus" meaning "decorated with ribbons", from the Greek λημνίσκος meaning ribbons,&lt;ref name="erickson"&gt;{{citation|title=Beautiful Mathematics|series=MAA Spectrum|publisher=[[Mathematical Association of America]]|first=Martin J.|last=Erickson|year=2011|isbn=9780883855768|contribution=1.1 Lemniscate|pages=1–3|url=https://books.google.com/books?id=LgeP62-ZxikC&amp;pg=PA1}}.&lt;/ref&gt; or alternatively may refer to the [[wool]] from which the [[ribbons]] were made.&lt;ref name="lemniscatomy"/&gt;

Curves that have been called a lemniscate include three [[quartic plane curve]]s: the [[hippopede]] or lemniscate of Booth, the [[lemniscate of Bernoulli]], and the [[lemniscate of Gerono]]. The study of lemniscates (and in particular the hippopede) dates to [[ancient Greek mathematics]], but the term "lemniscate" for curves of this type comes from the work of [[Jacob Bernoulli]] in the late 17th century.

==History and examples==

===Lemniscate of Booth===
[[File:Lemniscate of Booth.png|thumb|Lemniscate of Booth]]
{{main|Hippopede}}
The consideration of curves with a figure-eight shape can be traced back to [[Proclus]], a Greek [[Neoplatonist]] philosopher and mathematician who lived in the 5th century AD. Proclus considered the [[Toric section|cross-sections]] of a [[torus]] by a plane parallel to the axis of the torus. As he observed, for most such sections the cross section consists of either one or two ovals; however, when the plane is [[tangent]] to the inner surface of the torus, the cross-section takes on a figure-eight shape, which Proclus called a [[Hobble (device)|horse fetter]] (a device for holding two feet of a horse together), or "hippopede" in Greek. The name "lemniscate of Booth" for this curve dates to its study by the 19th-century mathematician [[James Booth (mathematician)|James Booth]].&lt;ref name="lemniscatomy"&gt;{{citation
 | last = Schappacher | first = Norbert
 | contribution = Some milestones of lemniscatomy
 | location = New York
 | mr = 1483331
 | pages = 257–290
 | publisher = Dekker
 | series = Lecture Notes in Pure and Applied Mathematics
 | title = Algebraic Geometry (Ankara, 1995)
 | volume = 193
 | year = 1997}}.&lt;/ref&gt;

The lemniscate may be defined as an [[algebraic curve]], the zero set of the [[quartic polynomial]] &lt;math&gt;(x^2 + y^2)^2 - cx^2 - dy^2&lt;/math&gt; when the parameter ''d'' is negative. For positive values of ''d'' one instead obtains the [[oval of Booth]].

===Lemniscate of Bernoulli===
[[File:Lemniskate bernoulli2.svg|thumb|Lemniscate of Bernoulli]]
{{main|Lemniscate of Bernoulli}}
In 1680, [[Giovanni Domenico Cassini|Cassini]] studied a family of curves, now called the [[Cassini oval]], defined as follows: the [[locus (mathematics)|locus]] of all points, the product of whose distances from two fixed points, the curves' [[focus (geometry)|foci]], is a constant. Under very particular circumstances (when the half-distance between the points is equal to the square root of the constant) this gives rise to a lemniscate.

In 1694, [[Johann Bernoulli]] studied the lemniscate case of the Cassini oval, now known as the [[lemniscate of Bernoulli]] (shown above), in connection with a problem of "[[Isochrone curve|isochrones]]" that had been posed earlier by [[Leibniz]]. Like the hippopede, it is an algebraic curve, the zero set of the polynomial &lt;math&gt;(x^2 + y^2)^2 - 2a^2 (x^2 - y^2)&lt;/math&gt;. Bernoulli's brother [[Jacob Bernoulli]] also studied the same curve in the same year, and gave it its name, the lemniscate.&lt;ref name="bos"&gt;{{citation
 | last = Bos | first = H. J. M.
 | contribution = The lemniscate of Bernoulli
 | location = Dordrecht
 | mr = 774250
 | pages = 3–14
 | publisher = Reidel
 | series = Boston Stud. Philos. Sci., XV
 | title = For Dirk Struik
 | url = https://books.google.com/books?id=OvK9orJNezwC&amp;pg=PA3
 | year = 1974| isbn = 9789027703934
 }}.&lt;/ref&gt; It may also be defined geometrically as the locus of points whose product of distances from two foci equals the square of half the interfocal distance.&lt;ref&gt;{{citation
 | last1 = Langer | first1 = Joel C.
 | last2 = Singer | first2 = David A.
 | doi = 10.1007/s00032-010-0124-5
 | issue = 2
 | journal = Milan Journal of Mathematics
 | mr = 2781856
 | pages = 643–682
 | title = Reflections on the lemniscate of Bernoulli: the forty-eight faces of a mathematical gem
 | volume = 78
 | year = 2010}}.&lt;/ref&gt; It is a special case of the hippopede (lemniscate of Booth), with &lt;math&gt;d=-c&lt;/math&gt;, and may be formed as a cross-section of a torus whose inner hole and circular cross-sections have the same diameter as each other.&lt;ref name="lemniscatomy"/&gt;  The [[lemniscatic elliptic function]]s are analogues of trigonometric functions for the lemniscate of Bernoulli, and the [[Gauss's constant|lemniscate constants]] arise in evaluating the [[arc length]] of this lemniscate.

===Lemniscate of Gerono===
[[File:Lemniscate-of-Gerono2.svg|thumb|280px|Lemniscate of Gerono: solution set of x&lt;sup&gt;4&lt;/sup&gt;&amp;minus;x&lt;sup&gt;2&lt;/sup&gt;+y&lt;sup&gt;2&lt;/sup&gt;=0&lt;ref&gt;{{Cite web|url=http://www.mathematische-basteleien.de/acht.htm|title=Acht-Kurve|last=Köller|first=Jürgen|website=www.mathematische-basteleien.de|access-date=2017-11-26}}&lt;/ref&gt;]]
{{main|Lemniscate of Gerono}}
Another lemniscate, the [[lemniscate of Gerono]] or lemniscate of Huygens, is the zero set of the quartic polynomial &lt;math&gt;y^2-x^2(a^2-x^2)&lt;/math&gt;.&lt;ref&gt;{{citation|title=An elementary treatise on cubic and quartic curves|first=Alfred Barnard|last=Basset|publisher=Deighton, Bell|year=1901|pages=171–172|url=https://books.google.com/books?id=T40LAAAAYAAJ&amp;pg=PA171|contribution=The Lemniscate of Gerono}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Newton's Principia for the common reader|first=S|last=Chandrasekhar|publisher=Oxford University Press|year=2003|isbn=9780198526759|page=133|url=https://books.google.com/books?id=qomP58txKQwC&amp;pg=PA133}}.&lt;/ref&gt; [[Viviani's curve]], a three-dimensional curve formed by intersecting a sphere with a cylinder, also has a figure eight shape, and has the lemniscate of Gerono as its planar projection.&lt;ref&gt;{{citation|first1=Luisa Rossi|last1=Costa|first2=Elena|last2=Marchetti|contribution=Mathematical and Historical Investigation on Domes and Vaults|pages=73–80|title=Aesthetics and architectural composition : proceedings of the Dresden International Symposium of Architecture 2004|year=2005|location=Mammendorf|publisher=Pro Literatur|editor1-last=Weber|editor1-first=Ralf|editor2-last=Amann|editor2-first=Matthias Albrecht}}.&lt;/ref&gt;

===Others===

Other figure-eight shaped algebraic curves include
* The [[Devil's curve]], a curve defined by the quartic equation &lt;math&gt;y^2 (y^2 - a^2) = x^2 (x^2 - b^2)&lt;/math&gt; in which one connected component has a figure-eight shape,&lt;ref&gt;{{citation|title=The Universal Book of Mathematics: From Abracadabra to Zeno's Paradoxes|first=David|last=Darling|publisher=John Wiley &amp; Sons|year=2004|isbn=9780471667001|contribution=devil's curve|pages=91–92|url=https://books.google.com/books?id=HrOxRdtYYaMC&amp;pg=PA91}}.&lt;/ref&gt;
* [[Watt's curve]], a figure-eight shaped curve formed by a mechanical linkage. Watt's curve is the zero set of the degree-six polynomial equation &lt;math&gt;(x^2+y^2)(x^2+y^2-d^2)^2+4a^2y^2(x^2+y^2-b^2)=0&lt;/math&gt; and has the lemniscate of Bernoulli as a special case.

==See also==
* [[Analemma]], the figure-eight shaped curve traced by the noontime positions of the sun in the sky over the course of a year
* [[Lorenz attractor]], a three-dimensional dynamic system exhibiting a lemniscate shape
* [[Polynomial lemniscate]], a level set of the absolute value of a complex polynomial
* Lemniscates as [[Generalized conic]]s

==References==
{{Reflist|30em}}

==External links==
{{commonscat|Lemniscate}}
* {{springer|title=Lemniscates|id=p/l058130}}

[[Category:Mathematical terminology]]
[[Category:Curves]]</text>
      <sha1>fyi30wh1slt4pnvtxxfhg6bmp2ney8i</sha1>
    </revision>
  </page>
  <page>
    <title>List of differential geometry topics</title>
    <ns>0</ns>
    <id>345396</id>
    <revision>
      <id>775855342</id>
      <parentid>766174883</parentid>
      <timestamp>2017-04-17T14:10:27Z</timestamp>
      <contributor>
        <username>Hyperbolick</username>
        <id>30089549</id>
      </contributor>
      <minor/>
      <comment>Disambiguated: [[Symplectic space]] → [[Symplectic vector space]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8546">This is a list of [[differential geometry]] topics. See also [[glossary of differential and metric geometry]] and [[list of Lie group topics]].

==Differential geometry of curves and surfaces==
===[[Differential geometry of curves]]===

*[[List of curves topics]]
*[[Frenet–Serret formulas]]
*[[Curves in differential geometry]]
*[[Line element]]
*[[Curvature]]
*[[Radius of curvature (mathematics)|Radius of curvature]]
*[[Osculating circle]]
*[[Curve]]
*[[Fenchel's theorem]]

===[[Differential geometry of surfaces]]===

*[[Theorema egregium]]
*[[Gauss–Bonnet theorem]]
*[[First fundamental form]]
*[[Second fundamental form]]
*[[Gauss–Codazzi–Mainardi equations]]
*[[Dupin indicatrix]]
*[[Asymptotic curve]]
*[[Curvature]]
**[[Principal curvatures]]
**[[Mean curvature]]
**[[Gauss curvature]]
**[[Elliptic point]]
*Types of [[surface (mathematics)|surface]]s
**[[Minimal surface]]
**[[Ruled surface]]
**[[Conical surface]]
**[[Developable surface]]

==Foundations==
===Calculus on manifolds===
''See also [[multivariable calculus]], [[list of multivariable calculus topics]]''

*[[Manifold]]
**[[Differentiable manifold]]
**[[Smooth manifold]]
**[[Banach manifold]]
**[[Fréchet manifold]]
*[[Tensor analysis]]
**[[Tangent vector]]
**[[Tangent space]]
**[[Tangent bundle]]
**[[Cotangent space]]
**[[Cotangent bundle]]
**[[Tensor]]
**[[Tensor bundle]]
**[[Vector field]]
**[[Tensor field]]
**[[Differential form]]
**[[Exterior derivative]]
**[[Lie derivative]]
**[[pullback (differential geometry)]]
**[[pushforward (differential)]]
*[[jet (mathematics)]]
**[[Contact (mathematics)]]
**[[jet bundle]]
*[[Frobenius theorem (differential topology)]]
*[[Integral curve]]

===[[Differential topology]]===

*[[Diffeomorphism]]
**[[Large diffeomorphism]]
*[[Orientability]]
*[[characteristic class]]
**[[Chern class]]
**[[Pontrjagin class]]
**[[spin structure]]
*[[differentiable map]]
**[[Submersion (mathematics)|submersion]]
**[[Immersion (mathematics)|immersion]]
**[[Embedding]]
***[[Whitney embedding theorem]]
*[[Critical value]]
**[[Sard's theorem]]
**[[Saddle point]]
**[[Morse theory]]
*[[Lie derivative]]
*[[Hairy ball theorem]]
*[[Poincaré–Hopf theorem]]
*[[Stokes' theorem]]
*[[De Rham cohomology]]
*[[Sphere eversion]]
*[[Frobenius theorem (differential topology)]]
**[[Distribution (differential geometry)]]
**[[integral curve]]
**[[foliation]]
**[[integrability conditions for differential systems]]

===Fiber bundles===
*[[Fiber bundle]]
*[[Principal bundle]]
**[[Frame bundle]]
**[[Hopf bundle]]
*[[Associated bundle]]
*[[Vector bundle]]
**[[Tangent bundle]]
**[[Cotangent bundle]]
**[[Line bundle]]
*[[Jet bundle]]

===Fundamental structures===
*[[Sheaf (mathematics)]]
*[[Pseudogroup]]
*[[G-structure]]
*[[synthetic differential geometry]]

==[[Riemannian geometry]]==

===Fundamental notions===
*[[Metric tensor]]
*[[Riemannian manifold]]
**[[Pseudo-Riemannian manifold]]
*[[Levi-Civita connection]]

===Non-Euclidean geometry===
*[[Non-Euclidean geometry]]
*[[Elliptic geometry]]
**[[Spherical geometry]]
**[[Sphere-world]]
**[[Angle excess]]
*[[hyperbolic geometry]]
** [[hyperbolic space]]
** [[hyperboloid model]]
** [[Poincaré disc model]]
** [[Poincaré half-plane model]]
** [[Poincaré metric]]
** [[Angle of parallelism]]

===[[Geodesic]]===
*[[Prime geodesic]]
*[[Geodesic flow]]
*[[Exponential map (Lie theory)]]
*[[Exponential map (Riemannian geometry)]]
*[[Injectivity radius]]
*[[Geodesic deviation equation]]
**[[Jacobi field]]

===Symmetric spaces (and related topics)===
*[[Riemannian symmetric space]]
**[[Margulis lemma]]
*[[Space form]]
**[[Constant curvature]]
**[[taut submanifold]]
*[[Uniformization theorem]]
**[[Myers theorem]]
**[[Gromov's compactness theorem (geometry)|Gromov's compactness theorem]]

===[[Riemannian submanifold]]s===
*[[Gauss–Codazzi equations]]
*[[Darboux frame]]
*[[Hypersurface]]
*[[Induced metric]]
*[[Nash embedding theorem]]
*[[minimal surface]]
**[[Helicoid]]
**[[Catenoid]]
**[[Costa's minimal surface]]
*[[Hsiang–Lawson's conjecture]]

===[[Curvature of Riemannian manifolds]]===
*[[Theorema Egregium]]
*[[Gauss–Bonnet theorem]]
**[[Chern–Gauss–Bonnet theorem]]
**[[Chern–Weil homomorphism]]
*[[Gauss map]]
*[[Second fundamental form]]
*[[Curvature form]]
*[[Riemann curvature tensor]]
*[[Geodesic curvature]]
*[[Scalar curvature]]
*[[Sectional curvature]]
*[[Ricci curvature]], [[Ricci flat]]
*[[Ricci decomposition]]
**[[Schouten tensor]]
**[[Weyl curvature]]
*[[Ricci flow]]
*[[Einstein manifold]]
*[[Holonomy]]

===Theorems in Riemannian geometry===
*[[Gauss–Bonnet theorem]]
*[[Hopf–Rinow theorem]]
*[[Cartan–Hadamard theorem]]
*[[Myers theorem]]
*[[Rauch comparison theorem]]
*[[Morse index theorem]]
*[[Synge theorem]]
*[[Weinstein theorem]]
*[[Toponogov theorem]]
*[[Sphere theorem]]
*[[Hodge theory]]
*[[Uniformization theorem]]
*[[Yamabe problem]]

===[[Isometry]]===
*[[Killing vector field]]

===[[Laplace–Beltrami operator]]===
*[[Hodge star operator]]
*[[Weitzenböck identity]]
*[[Laplacian operators in differential geometry]]

===Formulas and other tools===
*[[List of coordinate charts]]
*[[List of formulas in Riemannian geometry]]
*[[Christoffel symbols]]

===Related structures===
*[[Intrinsic metric]]
*[[Pseudo-Riemannian manifold]]
*[[Sub-Riemannian manifold]]
*[[Finsler geometry]]
*[[General relativity]]
*[[G2 manifold]]
*[[Information geometry]]
**[[Fisher information metric]]

==Lie groups==
{{main|List of Lie group topics}}

==Connections==
{{main article|Connection (mathematics)}}

*[[covariant derivative]]
** [[exterior covariant derivative]]
*[[Levi-Civita connection]]
*[[parallel transport]]
**[[Development (differential geometry)]]
*[[connection form]]
*[[Cartan connection]]
**[[affine connection]]
**[[conformal connection]]
**[[projective connection]]
**[[method of moving frames]]
**[[Cartan's equivalence method]]
**[[Vierbein]], [[Tetrad (general relativity)|tetrad]]
**[[Cartan connection applications]]
**[[Einstein–Cartan theory]]
*[[connection (vector bundle)]]
*[[connection (principal bundle)]]
*[[Ehresmann connection]]
*[[curvature]]
**[[curvature form]]
**[[holonomy]], [[local holonomy]]
**[[Chern–Weil homomorphism]]
**[[Curvature vector]]
**[[Curvature form]]
**[[Riemann curvature tensor|Curvature tensor]]
**[[Cocurvature]]
*[[torsion (differential geometry)]]

==[[Complex manifolds]]==
*[[Riemann surface]]
*[[Complex projective space]]
*[[Kähler manifold]]
*[[Dolbeault operator]]
*[[CR manifold]]
*[[Stein manifold]]
*[[Almost complex structure]]
*[[Hermitian manifold]]
*[[Newlander–Nirenberg theorem]]
*[[Generalized complex manifold]]
*[[Calabi–Yau manifold]]
*[[Hyperkähler manifold]]
*[[K3 surface]]
*[[hypercomplex manifold]]
*[[Quaternion-Kähler manifold]]

==[[Symplectic geometry]]==
*[[Symplectic topology]]
*[[Symplectic vector space|Symplectic space]]
*[[Symplectic manifold]]
*[[Symplectic structure]]
*[[Symplectomorphism]]
*[[Contact structure]]
*[[Contact geometry]]
*[[Hamiltonian system]]
*[[Sasakian manifold]]
*[[Poisson manifold]]

==[[Conformal geometry]]==
*[[Möbius transformation]]
*[[Conformal map]]
*[[conformal connection]]
*[[tractor bundle]]
*[[Weyl curvature]]
*[[Weyl–Schouten theorem]]
&lt;!--*[[obstruction tensor]]
*[[Paneitz operator]]
*[[GJMS operator]]--&gt;
*[[ambient construction]]
*[[Willmore energy]]
*[[Willmore flow]]

==[[Index theory]]==
*[[Atiyah–Singer index theorem]]
*[[de Rham cohomology]]
*[[Dolbeault cohomology]]
*[[elliptic complex]]
*[[Hodge theory]]
*[[pseudodifferential operator]]

==[[Homogeneous spaces]]==
*[[Klein geometry]], [[Erlangen programme]]
*[[symmetric space]]
*[[space form]]
*[[Maurer–Cartan form]]
*Examples
**[[hyperbolic space]]
**[[Gauss–Bolyai–Lobachevsky space]]
**[[Grassmannian]]
**[[Complex projective space]]
**[[Real projective space]]
**[[Euclidean space]]
**[[Stiefel manifold]]
**[[Upper half-plane]]
**[[Sphere]]

==[[Systolic geometry]]==
*[[Loewner's torus inequality]]
*[[Pu's inequality]]
*[[Gromov's inequality for complex projective space]]
*[[Wirtinger inequality (2-forms)]]
*[[Gromov's systolic inequality for essential manifolds]]
*[[Essential manifold]]
*[[Filling radius]]
*[[Filling area conjecture]]
*[[Bolza surface]]
*[[First Hurwitz triplet]]
*[[Hermite constant]]
*[[Systoles of surfaces]]
*[[Systolic freedom]]
*[[Systolic category]]

==Other==

*[[Envelope (mathematics)]]
*[[Bäcklund transform]]

[[Category:Mathematics-related lists|Differential geometry]]
[[Category:Differential geometry| ]]
[[Category:Wikipedia outlines|Differential geometry]]</text>
      <sha1>0tyhzyd5mtkz5h72qnbsdj705od72n3</sha1>
    </revision>
  </page>
  <page>
    <title>List of price index formulas</title>
    <ns>0</ns>
    <id>13186787</id>
    <revision>
      <id>868448067</id>
      <parentid>868447498</parentid>
      <timestamp>2018-11-12T07:49:19Z</timestamp>
      <contributor>
        <ip>78.83.53.221</ip>
      </contributor>
      <comment>/* Geometric means */ - text edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9535">{{Use dmy dates|date=December 2013}}
A number of different formulae, more than hundred, have been proposed as means of calculating [[price index]]es.  While price index formulae all use price and possibly quantity data, they aggregate these in different ways.  A price index aggregates various combinations of base period prices (&lt;math&gt;p_0&lt;/math&gt;), later period prices (&lt;math&gt;p_t&lt;/math&gt;), base period quantities (&lt;math&gt;q_0&lt;/math&gt;), and later period quantities (&lt;math&gt;q_t&lt;/math&gt;). Price index numbers are usually defined either in terms of (actual or hypothetical) expenditures (expenditure = price * quantity) or as different weighted averages of price relatives (&lt;math&gt;p_t/p_0&lt;/math&gt;). These tell the relative change of the price in question. Two of the most commonly used price index formulae were defined by German economists and statisticians [[Étienne Laspeyres]] and [[Hermann Paasche]], both around 1875 when investigating price changes in Germany.

==Laspeyres==
Developed in 1871 by [[Étienne Laspeyres|Laspeyres]], the formula:
:&lt;math&gt; P_{L}=\frac{\sum\left(p_{t}\cdot q_{0}\right)}{\sum\left(p_{0}\cdot q_{0}\right)}&lt;/math&gt;

compares the total cost of the same basket of goods &lt;math&gt;q_0&lt;/math&gt; at the old and new prices.

==Paasche==
Developed in 1874&lt;ref&gt;{{Cite web|url=http://www.stat.go.jp/english/data/cpi/1587.htm|title=Q&amp;A about the Consumer Price Index|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; by [[Hermann Paasche|Paasche]], the formula:
:&lt;math&gt;P_{P}=\frac{\sum\left(p_{t}\cdot q_{t}\right)}{\sum\left(p_{0}\cdot q_{t}\right)}&lt;/math&gt;

compares the total cost of a new basket of goods &lt;math&gt;q_t&lt;/math&gt; at the old and new prices.

==Geometric means==
The geometric means index:

:&lt;math&gt;P_{GM}=\prod_{i=1}^{n}\left(\frac{p_{i,t}}{p_{i,0}}\right)^\frac{p_{i,0}\cdot q_{i,0}}{\sum\left(p_{0}\cdot q_{0}\right)}&lt;/math&gt;

incorporates quantity information through the share of expenditure in the base period.

==Unweighted indices==
Unweighted, or "elementary", price indices only compare prices of a single type of good between two periods. They do not make any use of quantities or expenditure weights. They are called "elementary" because they are often used at the lower levels of aggregation for more comprehensive price indices.&lt;ref&gt;PPI manual, 598.&lt;/ref&gt; In such a case, they are not indices but merely an intermediate stage in the calculation of an index. At these lower levels, it is argued that weighting is not necessary since only one type of good is being aggregated. However this implicitly assumes that only one type of the good is available (e.g. only one brand and one package size of frozen peas) and that it has not changed in quality etc between time periods.

===Carli===
Developed in 1764 by [[Giovanni Rinaldo|Carli]], an Italian economist, this formula is the [[arithmetic mean]] of the price relative between a period ''t'' and a base period ''0''.{{Fix|text=The formula does not make clear over what the summation is done.}}
:&lt;math&gt;P_{C}=\frac{1}{n}\cdot\sum\frac{p_{t}}{p_{0}}&lt;/math&gt;

On 17 August 2012 the BBC Radio 4 program "More or Less" noted that the Carli index, used in part in the British Retail Price Index measure, has a built-in bias towards recording inflation even when over successive periods there is no increase in prices overall.{{clarifyme|date=November 2017}}{{Fix|text=Explain why}}

===Dutot===
In 1738 French economist Dutot&lt;ref&gt;{{Cite web|url=https://www.chicagofed.org/~/media/publications/working-papers/2009/wp2009-10-pdf|title=The Life and Times of Nicolas Dutot|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; proposed using an index calculated by dividing the average price in period ''t'' by the average price in period ''0''.
:&lt;math&gt;P_{D}=\frac{\frac{1}{n}\cdot\sum p_{t}}{\frac{1}{n}\cdot\sum p_{0}}=\frac{\sum p_{t}}{\sum p_{0}} &lt;/math&gt;

===Jevons===
In 1863, English economist [[William Stanley Jevons|Jevons]] proposed taking the [[geometric average]] of the price relative of period ''t'' and base period ''0''.&lt;ref&gt;PPI manual, 602.&lt;/ref&gt; When used as an elementary aggregate, the Jevons index is considered a constant elasticity of substitution index since it allows for product substitution between time periods.&lt;ref&gt;PPI manual, 596.&lt;/ref&gt;
:&lt;math&gt;P_{J}=\left(\prod\frac{p_{t}}{p_{0}}\right)^{1/n}&lt;/math&gt;

This is the formula that was used for the old Financial Times stock market index (the predecessor of the [[FTSE 100 Index]]). It was inadequate for that purpose. In particular, if the price of any of the constituents were to fall to zero, the whole index would fall to zero. That is an extreme case; in general the formula will understate the total cost of a basket of goods (or of any subset of that basket) unless their prices all change at the same rate. Also, as the index is unweighted, large price changes in selected constituents can transmit to the index to an extent not representing their importance in the average portfolio.

===Harmonic mean of price relatives===
The harmonic average counterpart to the Carli index.&lt;ref name="PPI manual, 600"&gt;PPI manual, 600.&lt;/ref&gt;  The index was proposed by Jevons in 1865 and by Coggeshall in 1887.&lt;ref&gt;Export and Import manual, Chapter 20 p. 8&lt;/ref&gt;
:&lt;math&gt;P_{HR}=\frac{1}{\frac{1}{n}\cdot\sum\frac{p_{0}}{p_{t}}}&lt;/math&gt;

===Carruthers, Sellwood, Ward, Dalén index===
Is the geometric mean of the Carli and the harmonic price indexes.&lt;ref&gt;PPI manual, 597.&lt;/ref&gt;  In 1922 Fisher wrote that this and the Jevons were the two best unweighted indexes based on Fisher's test approach to index number theory.&lt;ref&gt;Export and Import manual, Chapter 20, p. 8&lt;/ref&gt;
:&lt;math&gt;P_{CSWD}=\sqrt{P_{C}\cdot P_{HR}}&lt;/math&gt;

===Ratio of harmonic means===
The ratio of harmonic means or "Harmonic means" price index is the harmonic average counterpart to the Dutot index.&lt;ref name="PPI manual, 600"/&gt;
:&lt;math&gt;P_{RH}=\frac{\sum\frac{n}{p_{0}}}{\sum\frac{n}{p_{t}}}&lt;/math&gt;

==Bilateral formulae==

=== Marshall-Edgeworth ===
The Marshall-Edgeworth index, credited to [[Alfred Marshall|Marshall]] (1887) and [[Francis Ysidro Edgeworth|Edgeworth]] (1925),&lt;ref&gt;PPI manual, Chapter 15, p. 378.&lt;/ref&gt; is a weighted relative of current period to base period sets of prices. This index uses the arithmetic average of the current and based period quantities for weighting. It is considered a pseudo-superlative formula and is symmetric.&lt;ref&gt;PPI manual, 620.&lt;/ref&gt; The use of the Marshall-Edgeworth index can be problematic in cases such as a comparison of the price level of a large country to a small one.  In such instances, the set of quantities of the large country will overwhelm those of the small one.&lt;ref&gt;PPI manual, Chapter 15, p. 378&lt;/ref&gt;
:&lt;math&gt;P_{ME}=\frac{\sum\left[p_{t}\cdot \frac{1}{2}\left(q_{0}+q_{t}\right)\right]}{\sum\left[p_{0}\cdot \frac{1}{2}(q_{0}+q_{t})\right]}=\frac{\sum\left[p_{t}\cdot\left(q_{0}+q_{t}\right)\right]}{\sum\left[p_{0}\cdot\left(q_{0}+q_{t}\right)\right]}&lt;/math&gt;

=== Superlative indices ===
Superlative indices treat prices and quantities equally across periods. They are symmetrical and provide close approximations of [[cost of living index|cost of living indices]] and other theoretical indices used to provide guidelines for constructing price indices.  All superlative indices produce similar results and are generally the favored formulas for calculating price indices.&lt;ref&gt;ILO CPI manual, Chapter 1, p. 2.&lt;/ref&gt;  A superlative index is defined technically as "an index that is exact for a flexible functional form that can provide a [[order of approximation|second-order approximation]] to other twice-differentiable functions around the same point."&lt;ref&gt;Export and Import manual, Chapter 18, p. 23.&lt;/ref&gt;

==== Fisher ====
The change in a Fisher index from one period to the next is the [[geometric mean]] of the changes in Laspeyres's and Paasche's indexes between those periods, and these are chained together to make comparisons over many periods:

:&lt;math&gt;P_{F}=\sqrt{P_{L}\cdot P_{P}}&lt;/math&gt;

This is also called Fisher's "ideal" price index.

==== Törnqvist ====
{{further|Törnqvist index}}
The Törnqvist or Törnqvist-Theil index is the geometric average of the n price relatives of the current to base period prices (for n goods) weighted by the arithmetic average of the value shares for the two periods.&lt;ref&gt;PPI manual, p. 610&lt;/ref&gt;&lt;ref&gt;[http://www2.stats.govt.nz/domino/external/omni/omni.nsf/wwwglsry/tornqvist+index+and+other+log-change+index+numbers "Tornqvist Index and other Log-change Index Numbers"], Statistics New Zealand Glossary of Common Terms.&lt;/ref&gt;

:&lt;math&gt;P_{T}=\prod_{i=1}^{n}\left(\frac{p_{i,t}}{p_{i,0}}\right)^{\frac{1}{2}\left[\frac{p_{i,0}\cdot q_{i,0}}{\sum\left(p_{0}\cdot q_{0}\right)}+\frac{p_{i,t}\cdot q_{i,t}}{\sum\left(p_{t}\cdot q_{t}\right)}\right]}&lt;/math&gt;

==== Walsh ====
The Walsh price index is the weighted sum of the current period prices divided by the weighted sum of the base period prices with the geometric average of both period quantities serving as the weighting mechanism:

:&lt;math&gt;P_{W}=\frac{\sum\left(p_{t}\cdot\sqrt{q_{0}\cdot q_{t}}\right)}{\sum\left(p_{0}\cdot\sqrt{q_{0}\cdot q_{t}}\right)}&lt;/math&gt;

==Notes==
{{reflist}}

==References==
* [https://www.imf.org/external/np/sta/xipim/pdf/xipim.pdf ''Export and Import Price Index Manual'']
* [http://www.imf.org/external/np/sta/tegppi/index.htm ''PPI Manual'']

[[Category:Price indices]]
[[Category:Monetary lists|Price indices]]
[[Category:Mathematics-related lists|Price indices]]</text>
      <sha1>ndhmkbctetndgyrrlh07ner3n5wp3xa</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Stanislaw Ulam</title>
    <ns>0</ns>
    <id>49800971</id>
    <revision>
      <id>869132804</id>
      <parentid>866156519</parentid>
      <timestamp>2018-11-16T16:47:46Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="933">This is a (partial) list of things named after [[Stanislaw Ulam]], a 20th-century Polish-American mathematician who also worked in physics and biological sciences:
==Computer science==
*[[Stan (software)|Stan]], [[probabilistic programming]] language

==Mathematics==
*[[Borsuk–Ulam theorem]]
*[[Erdős–Ulam problem]]
*[[Hyers–Ulam–Rassias stability]]
* [[Kuratowski–Ulam theorem]]
*[[Mazur–Ulam theorem]]
*[[Ulam's conjecture (disambiguation)|Ulam's conjecture]]
**[[Collatz conjecture]]
** Kelly–Ulam conjecture, see [[reconstruction conjecture]]
**[[Ulam's packing conjecture]]
*[[Ulam matrix]]
*[[Ulam numbers]]
*[[Ulam spiral]]
*[[Ulam's game]]
*[[Ulam–Warburton automaton|Ulam–Warburton cellular automaton]]

==Physics==
* [[Fermi–Pasta–Ulam–Tsingou problem]]
* [[Fermi–Ulam model]]
*[[Teller–Ulam design]]

==See also==
*{{intitle|Ulam}}
[[Category:Lists of things named after mathematicians|Ulam]]</text>
      <sha1>nc3ru7yci8bekuz8lsmz3frq7a3j1k2</sha1>
    </revision>
  </page>
  <page>
    <title>Margherita Piazzola Beloch</title>
    <ns>0</ns>
    <id>41887951</id>
    <revision>
      <id>867356064</id>
      <parentid>816770952</parentid>
      <timestamp>2018-11-05T05:00:19Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>source the unsourced section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4242">'''Margherita Piazzolla Beloch''' (12 July 1879 in [[Frascati]] &amp;ndash; 28 September 1976 in [[Rome]])&lt;ref name=edd&gt;{{citation|url=http://www.enciclopediadelledonne.it/biografie/margherita-beloch-piazzolla/|work=Enciclopedia Delle Donne|title=Margherita Beloch Piazzolla|first=Massimo|last=Kofler}}&lt;/ref&gt; was an Italian mathematician who worked in algebraic geometry, algebraic topology and photogrammetry.

== Biography ==
Beloch was the daughter of the German historian [[Karl Julius Beloch]], who taught ancient history for 50 years at  [[Sapienza University of Rome]],  and American Bella Bailey.&lt;ref name=edd/&gt;

Beloch studied mathematics at the  [[Sapienza University of Rome]] and wrote her undergraduate thesis under the supervision of [[Guido Castelnuovo]]. She received her degree in 1908&lt;ref name=edd/&gt; with Lauude and "dignita' di stampa" which means that her work was worthy of publication and in fact her thesis "Sulle trasformazioni birazionali dello spazio" (On Birational Transformations In Space)   was published in the Annali di Matematica Pura ed Applicata. 

[[Guido Castelnuovo]] was very impressed with her talent and offer her the position of assistant which Margherita took and held until 1919, when she moved to Pavia and the successive year to Palermo to work under [[Michele De Franchis]], an important figure of the Italian school of algebraic geometry at the time.&lt;ref name=edd/&gt; 

In 1924, Beloch completed her "libera docenza" (a degree that at that time had to be obtained before one could become a professor) and three years later she became a full professor at the [[University of Ferrara]]
where she taught until her retirement (1955).&lt;ref name=edd/&gt;

== Scientific Work ==
Her main scientific interest were
[[algebraic geometry]], 
[[algebraic topology]] 
and 
[[photogrammetry]].
After her thesis she worked on classification of algebraic surfaces studying the configurations of lines that could lie on surfaces. The next step was to study rational curves lying on surfaces and in this framework Beloch obtained the following important result:&lt;ref&gt;E. Strickland, ''Scienziate d'Italia: diciannove vite per la ricerca''.&lt;/ref&gt; "Hyperelleptic surfaces of rank 2 are characterised by having 16 rational curves."

Beloch also made some contributions to the theory of skew algebraic curves.&lt;ref&gt;M. Beloch Piazzolla, "Sur le nombre des plurisecantes et sur la classification des courbes gauches algebriques", ''Comptes Rendus de l'Ac. des Sciences'', 1940&lt;/ref&gt;  She continued working on topological properties of algebraic curves either planar or lying on ruled or cubic surfaces for most of her life, writing about a dozen papers on these subjects.&lt;ref&gt;[http://math.unipa.it/~brig/sds/prima%20pagina/tirocinio/Beloch%20Margherita%20biblio.htm "Beloch Margherita"], at Dept. of Mathematics and Information Science, University of Palermo.&lt;/ref&gt;

Around 1940 Beloch become more and more interested in [[photogrammetry]] and the application of mathematics, and in particular algebraic geometry, to it. She is also known for her contribution to the mathematics of paper folding:&lt;ref&gt;Thomas C. Hull, Thomas C., "Solving cubics with creases: the work of Beloch and Lill", ''Amer. Math. Monthly'' 118 (2011), no. 4, 307–15.&lt;/ref&gt; In particular she seems to have been the first to formalise an origami move which allows, when possible, to construct by paper folding the common tangents to two parabolas. As a consequence she showed how to extract cubic roots by paper folding,&lt;ref&gt;M. Beloch Piazzolla, "Sul metodo del ripiegamento della carta per la risoluzione dei problemi geometrici", ''Periodico di Mathematiche'' Ser. 4, 16 (1936) 104–108.&lt;/ref&gt; something that is impossible to do by rule and compass. The move she used has been called the [[Beloch fold]].&lt;ref&gt;Ken Liu, [http://www.tor.com/2017/06/29/the-magic-and-mathematics-of-paper-folding/ "The Magic and Mathematics of Paper-Folding"], ''Tor.com'', June 29, 2017.&lt;/ref&gt;

== References ==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Beloch, Margherita Piazzola}}
[[Category:1879 births]]
[[Category:1976 deaths]]
[[Category:People from Frascati]]
[[Category:Italian mathematicians]]
[[Category:Women mathematicians]]


{{Italy-mathematician-stub}}</text>
      <sha1>rvo5bek8szqf8jyz3ovpy22qiezhhxj</sha1>
    </revision>
  </page>
  <page>
    <title>Mermin–Wagner theorem</title>
    <ns>0</ns>
    <id>4186556</id>
    <revision>
      <id>805442562</id>
      <parentid>773495751</parentid>
      <timestamp>2017-10-15T12:37:55Z</timestamp>
      <contributor>
        <ip>84.74.15.74</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15069">In [[quantum field theory]] and [[statistical mechanics]], the '''Mermin–Wagner theorem''' (also known as '''Mermin–Wagner–Hohenberg theorem''', '''Mermin–Wagner–Berezinskii theorem''',  or '''Coleman theorem''') states that continuous symmetries cannot be [[spontaneously broken]] at finite temperature in systems with sufficiently short-range interactions in dimensions {{math|''d'' ≤ 2}}. Intuitively, this means that long-range fluctuations can be created with little energy cost and since they increase the entropy they are favored.

This is because if such a [[spontaneous symmetry breaking]] occurred, then the corresponding [[Goldstone bosons]], being massless, would have an infrared divergent [[correlation function]].

The absence of spontaneous symmetry breaking in {{math|''d'' ≤ 2}} dimensional systems was rigorously proved by {{harvs|txt|first=Sidney|last=Coleman|author1-link=Sidney Coleman|year=1973}} in quantum field theory and by [[David Mermin]], [[Herbert Wagner (physicist)|Herbert Wagner]] and [[Pierre Hohenberg]] in statistical physics. That the theorem does not apply to discrete symmetries can be seen in the two-dimensional [[Ising model]].

== Introduction ==
Consider the [[free field|free scalar field]] {{mvar|φ}} of mass {{mvar|m}} in two Euclidean dimensions. Its [[propagator]] is:

:&lt;math&gt;G(x) = \left\langle \varphi (x)\varphi (0) \right\rangle  = \int \frac{d^2 k}{(2\pi)^2} \frac{e^{ik \cdot x}}{k^2  + m^2}.&lt;/math&gt;

For small {{math|''m'', ''G''}} is a solution to Laplace's equation with a point source:

:&lt;math&gt;\nabla^2 G = \delta(x).&lt;/math&gt;

This is because the propagator is the reciprocal of {{math|∇&lt;sup&gt;2&lt;/sup&gt;}} in {{mvar|k}} space.  To use [[Gauss's law]], define the electric field analog to be {{math|''E'' {{=}} ∇''G''}}. The divergence of the electric field is zero. In two dimensions, using a large Gaussian ring:

:&lt;math&gt;E = {1\over 2\pi r}.&lt;/math&gt;

So that the function ''G'' has a logarithmic divergence both at small and large ''r''.

:&lt;math&gt;G(r) = {1\over 2\pi} \log(r)&lt;/math&gt;

The interpretation of the divergence is that the field fluctuations cannot stay centered around a mean. If you start at a point where the field has the value 1, the divergence tells you that as you travel far away, the field is arbitrarily far from the starting value. This makes a two dimensional massless scalar field slightly tricky to define mathematically. If you define the field by a Monte-Carlo simulation, it doesn't stay put, it slides to infinitely large values with time.

This happens in one dimension too, when the field is a one dimensional scalar field, a random walk in time. A random walk also moves arbitrarily far from its starting point, so that a one-dimensional or two-dimensional scalar does not have a well defined average value.

If the field is an angle, {{mvar|θ}}, as it is in the [[Goldstone boson|Mexican hat model]] where the complex field {{math|''A'' {{=}} ''Re&lt;sup&gt;iθ&lt;/sup&gt;''}} has an expectation value but is free to slide in the {{mvar|θ}} direction, the angle {{mvar|θ}} will be random at large distances. This is the Mermin–Wagner theorem: there is no spontaneous breaking of a continuous symmetry in two dimensions.

==Kosterlitz–Thouless transition==
{{main|Kosterlitz–Thouless transition}}

Another example is the [[XY model]]. The Mermin–Wagner theorem prevents any spontaneous symmetry breaking of the model's continuous (internal) {{math|''O''(2)}} symmetry on a spatial lattice of dimension {{math|''d'' ≤ 2}}, i.e. the (spin-)field's expectation value remains zero for any ''finite'' temperature ([[quantum phase transition]]s remain unaffected). However, the theorem does not prevent the existence of a phase transition in the sense of a diverging [[correlation length]] {{mvar|ξ}}. To this end, the model has two phases: a conventional disordered phase at high temperature with dominating exponential decay of the [[correlation length|correlation function]] &lt;math&gt;G(r)\sim\exp(-r/\xi)&lt;/math&gt; for &lt;math&gt;r/\xi\gg1&lt;/math&gt;, and a low-temperature phase with [[Long-range order|quasi-long-range order]] where {{math|''G''(''r'')}} decays according to some [[power law]] for "sufficiently large", but finite distance {{mvar|r}} ({{math|''a'' ≪ ''r'' ≪ ''ξ''}} with {{mvar|a}} the [[lattice spacing]]).

== Heisenberg model ==
We will present an intuitive way&lt;ref&gt;see {{harvtxt|Cardy|2002}}&lt;/ref&gt; to understand the mechanism that prevents symmetry breaking in low dimensions, through an application to the [[Heisenberg model (quantum)|Heisenberg model]], that is a system of {{mvar|n}}-component spins {{math|'''S'''&lt;sub&gt;''i''&lt;/sub&gt;}} of unit length {{math|{{!}}'''S'''&lt;sub&gt;''i''&lt;/sub&gt;{{!}} {{=}} 1}}, located at the sites of a {{mvar|d}}-dimensional square lattice, with nearest neighbor coupling {{mvar|J}}. Its Hamiltonian is 

:&lt;math&gt;H =  - J\sum_{\left\langle {i,j} \right\rangle } \mathbf{S}_i  \cdot \mathbf{S}_j.&lt;/math&gt;

The name of this model comes from its rotational symmetry. Let us consider the [[low temperature]] behavior of this system and assume that there exists a spontaneously broken, that is a phase where all spins point in the same direction, e.g. along the {{mvar|x}}-axis. Then the {{math|''O''(''n'')}} rotational symmetry of the system is spontaneously broken, or rather reduced to the {{math|''O''(''n'' − 1)}} symmetry under rotations around this direction. We can parametrize the field in terms of independent fluctuations {{math|''σ&lt;sub&gt;α&lt;/sub&gt;''}} around this direction as follows:

:&lt;math&gt;\mathbf{S} = \left(\sqrt{1 - \sum_\alpha \sigma_\alpha^2}, \left \{\sigma_\alpha \right\} \right), \qquad \alpha  = 1, \cdots, n - 1.&lt;/math&gt;

with {{math|{{!}}''σ&lt;sub&gt;α&lt;/sub&gt;''{{!}} ≪ 1}}, and Taylor expand the resulting Hamiltonian. We have

:&lt;math&gt;\begin{align}
\mathbf{S}_i \cdot \mathbf{S}_j &amp;= \sqrt{\left(1 - \sum_\alpha \sigma^2_{i\alpha} \right)\left(1 - \sum_\alpha \sigma^2_{j\alpha } \right)} + \sum_\alpha \sigma_{i\alpha} \sigma_{j\alpha}\\ 
&amp;= 1 - \tfrac{1}{2} \sum_\alpha \left(\sigma^2_{i\alpha} + \sigma^2_{j\alpha}\right) + \sum_\alpha \sigma _{i\alpha} \sigma _{j\alpha} + \mathcal{O}\left (\sigma ^4 \right )\\
&amp;= 1 - \tfrac{1}{2} \sum_\alpha \left (\sigma _{i\alpha} - \sigma _{j\alpha } \right )^2 + \ldots 
\end{align}&lt;/math&gt;

whence

:&lt;math&gt;H = H_0 + \tfrac{1}{2} J\sum_{\left\langle i,j \right\rangle} \sum_\alpha \left (\sigma_{i\alpha}- \sigma_{j\alpha} \right )^2 + \cdots&lt;/math&gt;

Ignoring the irrelevant constant term {{math|''H''&lt;sub&gt;0&lt;/sub&gt; {{=}} −''JNd''}} and passing to the continuum limit, given that we are interested in the low temperature phase where long-wavelength fluctuations dominate, we get

:&lt;math&gt;H = \tfrac{1}{2}J \int {\mathrm{d}^d x\sum_\alpha  {(\nabla \sigma _\alpha  )^2 } }  + \ldots.&lt;/math&gt;

The field fluctuations {{math|''σ&lt;sub&gt;α&lt;/sub&gt;''}} are called [[spin wave]]s and can be recognized as Goldstone bosons. Indeed, they are ''n''-1 in number and they have zero mass since there is no mass term in the Hamiltonian.

To find if this hypothetical phase really exists we have to check if our assumption is self-consistent, that is if the expectation value of the [[magnetization]], calculated in this framework, is finite as assumed. To this end we need to calculate the first order correction to the magnetization due to the fluctuations. This is the procedure followed in the derivation of the well-known [[Ginzburg criterion]].

The model is Gaussian to first order and so the momentum space correlation function is proportional to {{math|''k''&lt;sup&gt;−2&lt;/sup&gt;}}. Thus the real space two-point correlation function for each of these modes is

:&lt;math&gt;\left\langle \sigma_\alpha (r)\sigma_\alpha (0) \right\rangle = \frac{1}{\beta J} \int^{\frac{1}{a}} \frac{\mathrm{d}^d k}{(2\pi)^d} \frac{e^{i\mathbf{k} \cdot \mathbf{r}}}{k^2}&lt;/math&gt;

where ''a'' is the lattice spacing. The average magnetization is

:&lt;math&gt;\left\langle S_1 \right\rangle =1-\tfrac{1}{2}\sum_\alpha\left\langle \sigma_\alpha^2 \right\rangle + \ldots&lt;/math&gt;

and the first order correction can now easily be calculated:

:&lt;math&gt;\sum_\alpha \left\langle \sigma_\alpha ^2 (0) \right\rangle = (n-1)\frac{1}{\beta J} \int^{\frac{1}{a}}\frac{\mathrm{d}^d k}{(2\pi)^d} \frac{1}{k^2}.&lt;/math&gt;

The integral above is proportional to

:&lt;math&gt;\int^{\frac{1}{a}} k^{d-3} \mathrm{d}k&lt;/math&gt;

and so it is finite for {{math|''d'' &gt; 2}}, but appears to be logarithmically divergent for {{math|''d'' ≤ 2}}. However, this is really an artifact of the linear approximation. In a more careful treatment, the average magnetization is zero.

We thus conclude that for {{math|''d'' ≤ 2}} our assumption that there exists a phase of spontaneous magnetization is incorrect for all {{math|''T'' &gt; 0}}, because the fluctuations are strong enough to destroy the spontaneous symmetry breaking. This is a general result:

:'''Mermin–Wagner–Hohenberg Theorem.''' There is no phase with spontaneous breaking of a continuous symmetry for {{math|''T'' &gt; 0}}, in {{math|''d'' ≤ 2}} dimensions.

The result can also be extended to other geometries, such as Heisenberg films with an arbitrary number of layers, as well as to other lattice systems (Hubbard model, s-f model).&lt;ref&gt;See {{harvtxt|Gelfert|Nolting|2001}}.&lt;/ref&gt;

== Generalizations ==
Much stronger results than absence of magnetization can actually be proved, and the setting can be substantially more general. In particular:

#The Hamiltonian can be invariant under the action of an arbitrary compact, connected Lie group {{mvar|G}}.
#Long-range interactions can be allowed (provided that they decay fast enough; necessary and sufficient conditions are known).

In this general setting, Mermin–Wagner theorem admits the following strong form (stated here in an informal way): 

:All (infinite-volume) Gibbs states associated to this Hamiltonian are invariant under the action of {{mvar|G}}.

When the assumption that the Lie group be compact is dropped, a similar result holds, but with the conclusion that infinite-volume Gibbs states do not exist.

Finally, there are other important applications of these ideas and methods, most notably to the proof that there cannot be non-translation invariant Gibbs states in 2-dimensional systems. A typical such example would be the absence of crystalline states in a system of hard disks (with possibly additional attractive interactions).

It has been proved however that interactions of hard-core type can lead in general to violations of Mermin–Wagner theorem.

==Notes==
{{Reflist}}

== References ==
* {{citation|first=P.C.|last=Hohenberg|title=Existence of Long-Range Order in One and Two Dimensions|url=http://link.aps.org/abstract/PR/v158/p383|journal=Phys. Rev.|volume=158|page=383|year=1967|bibcode = 1967PhRv..158..383H |doi = 10.1103/PhysRev.158.383 }}
* {{citation|first1=N.D.|last1=Mermin|first2=H.|last2=Wagner|title=Absence of Ferromagnetism or Antiferromagnetism in One- or Two-Dimensional Isotropic Heisenberg Models|url=http://link.aps.org/abstract/PRL/v17/p1133|journal= Phys. Rev. Lett.|volume=17|pages=1133–1136|year=1966|bibcode = 1966PhRvL..17.1133M |doi = 10.1103/PhysRevLett.17.1133 }}
* {{citation|first=Sidney|last=Coleman|title=There are no Goldstone bosons in two dimensions|url=http://projecteuclid.org/Dienst/UI/1.0/Summarize/euclid.cmp/1103859034|journal=Commun. Math. Phys.|volume=31|pages=259|year=1973|bibcode = 1973CMaPh..31..259C |doi = 10.1007/BF01646487 }}
* {{citation|first1=Axel|last1=Gelfert|first2=Wolfgang|last2=Nolting|title=The absence of finite-temperature phase transitions in low-dimensional many-body models: a survey and new results|url=http://www.iop.org/EJ/abstract/0953-8984/13/27/201/|journal= J. Phys.: Condens. Matter|volume=13|pages=R505-R524|year=2001|doi=10.1088/0953-8984/13/27/201|arxiv = cond-mat/0106090 |bibcode = 2001JPCM...13R.505G }}
* {{citation|first1=R.L.|last1=Dobrushin|first2=S.B.|last2=Shlosman|title=Absence of breakdown of continuous symmetry in two-dimensional models of statistical physics|url=http://projecteuclid.org/euclid.cmp/1103898965|journal= Comm. Math. Phys.|volume=42|page=31|year=1975|doi=10.1007/bf01609432|bibcode = 1975CMaPh..42...31D }}
* {{citation|first=C.-E.|last=Pfister|title=On the symmetry of the Gibbs states in two-dimensional lattice systems|url=http://projecteuclid.org/euclid.cmp/1103908962|journal=Comm. Math. Phys.|volume=79|page=181|year=1981|doi=10.1007/bf01942060|bibcode = 1981CMaPh..79..181P }}
* {{citation|first=J.|last=Fröhlich|first2=C.E.|last2=Pfister|title=On the absence of spontaneous symmetry breaking and of crystalline ordering in two-dimensional systems|url=http://projecteuclid.org/euclid.cmp/1103920246|journal=Comm. Math. Phys.|volume=81|page=277|year=1981|doi=10.1007/bf01208901|bibcode = 1981CMaPh..81..277F }}
* {{citation | first1=A.|last1=Klein|first2=L.J.|last2=Landau|first3=D.S.|last3=Shucker|title=On the absence of spontaneous breakdown of continuous symmetry for equilibrium states in two dimensions|url=http://www.springerlink.com/content/x33244059r620747|journal= J. Statist. Phys.|volume= 26|page=505|year=1981|doi=10.1007/bf01011431|bibcode = 1981JSP....26..505K }}
* {{citation|first1=C.A.|last1=Bonato|first2=J.F.|last2=Perez|first3=A.|last3=Klein|title=The Mermin-Wagner phenomenon and cluster properties of one- and two-dimensional systems|url=http://www.springerlink.com/content/p7876364465r7823|journal= J. Statist. Phys.|volume= 29|page=159|year=1982|doi=10.1007/bf01020779|bibcode = 1982JSP....29..159B }}
* {{citation|first1=D.|last1=Ioffe|first2=S.B.|last2=Shlosman|first3=Y.|last3=Velenik|title=2D models of statistical physics with continuous symmetry: the case of singular interactions|url=http://www.springerlink.com/content/mttf9c2t0yn0pucw|journal= Comm. Math. Phys.|volume= 226|page=433|year=2002|doi=10.1007/s002200200627|arxiv = math/0110127 |bibcode = 2002CMaPh.226..433I }}
* {{citation|last=Cardy|first=John|title=Scaling and renormalization in statistical physics|year=2002|publisher=Cambridge University Press|location=[Cambridge]|isbn=978-0-521-49959-0|edition=Reprinted (with corr.)}}
* {{citation|first=T.|last=Richthammer|title=Translation-invariance of two-dimensional Gibbsian point processes|url=http://www.springerlink.com/content/346pp7j7422p2180|journal= Commun. Math. Phys.|volume= 274|page=81|year=2007|bibcode = 2007CMaPh.274...81R |doi = 10.1007/s00220-007-0274-7 |arxiv = 0706.3637 }}
* {{scholarpedia|title=Mermin-Wagner Theorem|urlname=Mermin-Wagner_Theorem|curator=Herbert Wagner}}
*{{cite book |last1=Friedli |first=S. |last2=Velenik |first2=Y. |title=Statistical Mechanics of Lattice Systems: a Concrete Mathematical Introduction |publisher=Cambridge University Press |location=Cambridge |year=2017 |isbn=9781107184824 |url=http://www.unige.ch/math/folks/velenik/smbook/index.html}} 

{{DEFAULTSORT:Mermin-Wagner Theorem}}
[[Category:Quantum field theory]]
[[Category:Physics theorems]]
[[Category:Theorems in quantum physics]]
[[Category:Statistical mechanics theorems]]
[[Category:Theorems in mathematical physics]]</text>
      <sha1>bdb5v0co1587qr9yvp3xor01uxkie03</sha1>
    </revision>
  </page>
  <page>
    <title>Mikhail Leonidovich Gromov</title>
    <ns>0</ns>
    <id>771562</id>
    <revision>
      <id>870223643</id>
      <parentid>870220079</parentid>
      <timestamp>2018-11-23T09:02:21Z</timestamp>
      <contributor>
        <username>Bisbis</username>
        <id>6296186</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Dafna34|Dafna34]] ([[User talk:Dafna34|talk]]): Apparently doesn't have an article. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16122">{{other people||Gromov}}
{{Infobox scientist
| name = Mikhail Leonidovich Gromov
| image = Gromov Mikhail Leonidovich.jpg
| image_size = 
| caption = Mikhail Gromov in 2009
| birth_date = {{birth date and age|1943|12|23|df=y}}
| birth_place = [[Boksitogorsk]], [[Russian SFSR]], [[Soviet Union]]
| death_date = 
| death_place = 
| residence = France
| nationality = Russian and French and American
| alma_mater = [[Saint Petersburg State University|Leningrad State University]] (PhD)
| doctoral_advisor = [[Vladimir Rokhlin (Soviet mathematician)|Vladimir Rokhlin]]
| doctoral_students = [[François Labourie]]&lt;br /&gt;[[Pierre Pansu]]&lt;br /&gt;[[Mikhail Katz]]
| known_for = [[Geometry]]
| field = Mathematics
| work_institutions = [[Institut des Hautes Études Scientifiques]]&lt;br /&gt;[[New York University]]
| prizes = {{no wrap|[[Oswald Veblen Prize in Geometry]] (1981)&lt;br /&gt;[[Wolf Prize]] (1993)&lt;br /&gt; [[Kyoto Prize]] (2002)&lt;br /&gt;[[Nemmers Prize in Mathematics]] (2004)&lt;br /&gt;[[Bolyai Prize]] (2005)&lt;br /&gt;[[Abel Prize]] (2009)}}
}}
'''Mikhail Leonidovich Gromov''' (also '''Mikhael Gromov''', '''Michael Gromov''' or '''Mischa Gromov'''; {{lang-ru|link=no|Михаи́л Леони́дович Гро́мов}}; born 23 December 1943), is an American-French-Russian mathematician known for work in [[geometry]], [[Mathematical analysis|analysis]] and [[group theory]]. He is a permanent member of [[IHÉS]] in France and a Professor of Mathematics at [[New York University]].

Gromov has won several prizes, including the [[Abel Prize]] in 2009 "for his revolutionary contributions to geometry".

==Biography==
Mikhail Gromov was born on 23 December 1943 in [[Boksitogorsk]], [[Soviet Union]]. His father Leonid Gromov and his Jewish&lt;ref&gt;{{cite book |author=Masha Gessen|title=Perfect Rigour: A Genius and the Mathematical Breakthrough of a Lifetime|publisher=Icon Books Ltd |year=2011 |pages= |isbn=}}&lt;/ref&gt; mother Lea Rabinovitz&lt;ref&gt;{{cite book|title=The International Who's Who, 1997–98|url=https://books.google.com/books?id=4XNtwLEbl7wC|year=1997|publisher=Europa Publications|isbn=978-1-85743-022-6|pages=591}}&lt;/ref&gt;&lt;ref name=mactutor&gt;{{MacTutor Biography|id=Gromov}}&lt;/ref&gt; were pathologists.&lt;ref&gt;Gromov, Mikhail. "A Few Recollections", in {{cite book|author1=Helge Holden|author2=Ragni Piene|title=The Abel Prize 2008–2012|url=https://books.google.com/books?id=tEprnQEACAAJ|date=3 February 2014|publisher=Springer Berlin Heidelberg|isbn=978-3-642-39448-5|pages=129–137}} (also available on Gromov's homepage: [http://www.ihes.fr/~gromov/PDF/autobiography-dec20-2010.pdf link])&lt;/ref&gt; Gromov was born during [[World War II]], and his mother, who worked as a medical doctor in the Soviet Army, had to leave the front line in order to give birth to him.&lt;ref name="EMS"&gt;[http://www.ems-ph.org/journals/newsletter/pdf/2009-09-73.pdf Newsletter of the European Mathematical Society, No. 73, September 2009, p. 19]&lt;/ref&gt; When Gromov was nine years old,&lt;ref name="lemonde" /&gt; his mother gave him the book ''The Enjoyment of Mathematics'' by [[Hans Rademacher]] and [[Otto Toeplitz]], a book that piqued his curiosity and had a great influence on him.&lt;ref name="EMS" /&gt;

Gromov studied mathematics at [[Leningrad State University]] where he obtained a master's degree in 1965, a Doctorate in 1969 and defended his Postdoctoral Thesis in 1973. His thesis advisor was [[Vladimir Rokhlin (Soviet mathematician)|Vladimir Rokhlin]].&lt;ref&gt;http://cims.nyu.edu/newsletters/Spring2009.pdf&lt;/ref&gt;

Gromov married in 1967. In 1970, invited to give a presentation at the [[International Congress of Mathematicians]] in France, he was not allowed to leave the USSR. Still, his lecture was published in the conference proceedings.&lt;ref name=simons/&gt;

Disagreeing with the Soviet system, he had been thinking of emigrating since the age of 14. In the early 1970s he ceased publication, hoping that this would help his application to [[Aliyah|move to Israel]].&lt;ref name=lemonde&gt;{{Cite news|url=http://www.lemonde.fr/planete/article/2009/03/26/mikhail-gromov-le-genie-qui-venait-du-froid_1172835_3244.html|title=Mikhaïl Gromov, le génie qui venait du froid|last=Foucart|first=Stéphane|date=2009-03-26|work=|newspaper=Le Monde.fr|language=fr|issn=1950-6244|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=BoUFAQAAIAAJ&amp;q=Vivre+savant+sous+le+communisme&amp;dq=Vivre+savant+sous+le+communisme&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjU3Yue6K3PAhWr6oMKHbZQAlMQ6AEIHjAA|title=Vivre savant sous le communisme|last=Ripka|first=Georges|date=2002-01-01|publisher=Belin|isbn=9782701130538|language=fr}}&lt;/ref&gt; He changed his last name to that of his mother.&lt;ref name=lemonde/&gt; When the request was granted in 1974, he moved directly to New York where a position had been arranged for him at [[Stony Brook University|Stony Brook]].&lt;ref name="simons"&gt;{{cite web|url=https://www.simonsfoundation.org/science_lives_video/science-lives-mikhail-gromov/|title=Science Lives: Mikhail Gromov|last=Roberts|first=Siobhan|authorlink=Siobhan Roberts|date=December 22, 2014|website=|publisher=Simons Foundation|access-date=|work=}}&lt;/ref&gt;

In 1981 he left Stony Brook to join the faculty of [[Pierre and Marie Curie University|University of Paris VI]] and in 1982 he became a permanent professor at the [[Institut des Hautes Études Scientifiques]] (IHES) where he remains today. At the same time, he has held professorships at the [[University of Maryland, College Park]] from 1991 to 1996, and at the [[Courant Institute of Mathematical Sciences]] since 1996.&lt;ref name=mactutor/&gt; He adopted French citizenship in 1992.&lt;ref&gt;{{cite web|title=Mikhail Leonidovich Gromov|work=abelprize.no|date=|url=http://www.abelprize.no/c53859/binfil/download.php?tid=53784
}}&lt;/ref&gt;

==Work==
Gromov's style of geometry often features a "coarse" or "soft" viewpoint, analyzing asymptotic or large-scale properties.

Motivated by [[Nash embedding theorem|Nash and Kuiper's C&lt;sup&gt;1&lt;/sup&gt; embedding theorem]] and Stephen Smale's early results,&lt;ref name=":0" /&gt; Gromov introduced in 1973 the notion of [https://www.encyclopediaofmath.org/index.php/Convex_integration convex integration] and the [[h-principle]], a very general way to solve [[Underdetermined system|underdetermined]] [[partial differential equation]]s and the basis for a geometric theory of these equations.

In the 1980s, Gromov introduced the [[Gromov–Hausdorff metric]], a measure of the difference between two [[compact metric space]]s. In this context he proved [[Gromov's compactness theorem (geometry)|Gromov's compactness theorem]], stating that the set of compact [[Riemannian manifold]]s with [[Ricci curvature]] ≥ ''c'' and [[diameter]] ≤ ''D'' is [[relatively compact]] in the Gromov–Hausdorff metric. The possible limit points of sequences of such manifolds are [[Alexandrov space]]s of curvature ≥ ''c'', a class of [[metric space]]s studied in detail by [[Yuri Burago|Burago]], Gromov and [[Grigori Perelman|Perelman]] in 1992.  Gromov was also the first to study the space of all possible Riemannian structures on a given manifold.

Gromov introduced [[geometric group theory]], the study of [[infinite group]]s via the geometry of their [[Cayley graph]]s and their [[word metric]]. In 1981 he proved [[Gromov's theorem on groups of polynomial growth]]: a [[finitely generated group]] has [[Growth rate (group theory)|polynomial growth]] (a geometric property) if and only if it is [[virtually nilpotent]] (an algebraic property). The proof uses the Gromov–Hausdorff metric mentioned above. Along with [[Eliyahu Rips]] he introduced the notion of [[hyperbolic group]]s.

Gromov founded the field of [[symplectic topology]] by introducing the theory of [[pseudoholomorphic curves]]. This led to [[Gromov–Witten invariant]]s which are used in [[string theory]] and to his [[non-squeezing theorem]].

Gromov is also interested in [[mathematical biology]],&lt;ref name=":0"&gt;{{citation|url=http://www.ams.org/notices/201003/rtx100300391p.pdf|title=Interview with Mikhail Gromov|journal=[[Notices of the AMS]]|date=March 2010|volume=57|issue=3|pages=391–403}}.&lt;/ref&gt; the structure of the brain and the thinking process, and the way scientific ideas evolve.&lt;ref name="simons" /&gt;

==Prizes and honors==

===Prizes===
*[[Prize of the Mathematical Society of Moscow]] (1971)
*[[Oswald Veblen Prize in Geometry]] ([[American Mathematical Society|AMS]]) (1981)
*[[Elie Cartan Prize|Prix Elie Cartan]] de l'Academie des Sciences de Paris (1984)
*[[Prix de l'Union des Assurances de Paris]] (1989)
*[[Wolf Prize in Mathematics]] (1993)
*[[Leroy P. Steele Prize]] for Seminal Contribution to Research ([[American Mathematical Society|AMS]]) (1997)
*[[Lobachevsky Medal]] (1997)
*[[Balzan Prize]] for Mathematics (1999)
*[[Kyoto Prize]] in Mathematical Sciences (2002)
*[[Nemmers Prize in Mathematics]] (2004)&lt;ref&gt;[http://www.ams.org/notices/200407/comm-nemmers.pdf Gromov Receives Nemmers Prize]
&lt;/ref&gt;
*[[Bolyai Prize]] in 2005
*[[Abel Prize]] in 2009 “for his revolutionary contributions to geometry”&lt;ref&gt;[http://www.abelprisen.no/en/prisvinnere/2009/ Abel Prize for 2009], Laureates 2009&lt;/ref&gt;

===Honors===
*Invited speaker to [[International Congress of Mathematicians]]: 1970 (Nice), 1978 (Helsinki), 1982 (Warsaw), 1986 (Berkeley)
*Foreign member of the [[United States National Academy of Sciences|National Academy of Sciences]], the [[American Academy of Arts and Sciences]], the [[Norwegian Academy of Science and Letters]], and the [[Royal Society]] (2011).&lt;ref&gt;[http://royalsociety.org/people/mikhail-gromov/ Professor Mikhail Gromov ForMemRS | Royal Society]&lt;/ref&gt;
*Member of the [[French Academy of Sciences]]

==See also==
{{div col|colwidth=25em}}
*[[Gromov's theorem on groups of polynomial growth]]
*[[Almost flat manifold|Gromov's theorem on almost flat manifolds]]
*[[Gromov's compactness theorem (geometry)]]
*[[Gromov's compactness theorem (topology)]]
*[[Gromov's inequality for complex projective space]]
*[[Gromov's systolic inequality for essential manifolds]]
*[[Gromov–Hausdorff convergence]]
*[[Bishop–Gromov inequality]]
*[[Lévy–Gromov inequality]]
*[[Gromov–Witten invariant]]s
*[[Taubes's Gromov invariant]]
*[[Minimal volume]]
*[[Localisation on the sphere]]
*[[Gromov norm]]
*[[Hyperbolic group]]
*[[Random group]]
*[[Ramsey–Dvoretzky–Milman phenomenon]]
*[[Systolic geometry]]
*[[Filling radius]]
*[[Gromov product]]
*[[δ-hyperbolic space|Gromov δ-hyperbolic space]]
*[[Filling area conjecture]]
*[[Metric Structures for Riemannian and Non-Riemannian Spaces]]
*[[Mean dimension]]
{{div col end}}

==Books and other publications==
*Gromov, M. Hyperbolic manifolds, groups and actions. Riemann surfaces and related topics: Proceedings of the 1978 Stony Brook Conference (State Univ. New York, Stony Brook, N.Y., 1978), pp.&amp;nbsp;183–213, Ann. of Math. Stud., 97, Princeton Univ. Press, Princeton, N.J., 1981.
*Gromov, M. Hyperbolic groups. Essays in group theory, 75–263, Math. Sci. Res. Inst. Publ., 8, Springer, New York, 1987.
*Gromov, M. Asymptotic invariants of infinite groups. Geometric group theory, Vol. 2 (Sussex, 1991), 1–295, London Math. Soc. Lecture Note Ser., 182, Cambridge Univ. Press, Cambridge, 1993.&lt;ref&gt;{{cite journal|author=Toledo, Domingo|title=Review: ''Geometric group theory, Vol. 2: Asymptotic invariants of infinite groups'', by M. Gromov|journal=Bull. Amer. Math. Soc. (N.S.)|year=1996|volume=33|issue=3|pages=395–398|doi=10.1090/s0273-0979-96-00669-6|url=http://www.ams.org/journals/bull/1996-33-03/S0273-0979-96-00669-6/S0273-0979-96-00669-6.pdf}}&lt;/ref&gt;
*Gromov, Misha: Metric structures for Riemannian and non-Riemannian spaces. Based on the 1981 French original. With appendices by M. Katz, P. Pansu and S. Semmes. Translated from the French by Sean Michael Bates. Progress in Mathematics, 152. Birkhäuser Boston, Inc., Boston, MA, 1999. xx+585 pp. {{ISBN|0-8176-3898-9}}&lt;ref&gt;{{cite journal|author=Grove, Karsten|title=Review: ''Metric structures for Riemannian and non-Riemannian spaces'', by M. Gromov|journal=Bull. Amer. Math. Soc. (N.S.)|year=2001|volume=38|issue=3|pages=353–363|url=http://www.ams.org/journals/bull/2001-38-03/S0273-0979-01-00904-1/S0273-0979-01-00904-1.pdf|doi=10.1090/s0273-0979-01-00904-1}}&lt;/ref&gt;
*Gromov, M. Pseudoholomorphic curves in symplectic manifolds. Invent. Math. 82 (1985), no. 2, 307–347.
*Gromov, Mikhael Groups of polynomial growth and expanding maps. Inst. Hautes Études Sci. Publ. Math. No. 53 (1981), 53–73.
*Gromov, Mikhael Structures métriques pour les variétés riemanniennes. (French) [Metric structures for Riemann manifolds] Edited by J. Lafontaine and P. Pansu. Textes Mathématiques [Mathematical Texts], 1. CEDIC, Paris, 1981. iv+152 pp. {{ISBN|2-7124-0714-8}}
*Gromov, Mikhael: [https://books.google.com/books/about/Partial_Differential_Relations.html?id=_uFqWbgChtYC Partial differential relations]. Ergebnisse der Mathematik und ihrer Grenzgebiete (3) [Results in Mathematics and Related Areas (3)], 9. Springer-Verlag, Berlin, 1986. x+363 pp. {{ISBN|0-387-12177-3}}&lt;ref&gt;{{cite journal|author=McDuff, Dusa|authorlink=Dusa McDuff|title=Review: ''Partial differential relations'', by Mikhael Gromov|journal=Bull. Amer. Math. Soc. (N.S.)|year=1988|volume=18|issue=2|pages=214–220|url=http://www.ams.org/journals/bull/1988-18-02/S0273-0979-1988-15654-6/S0273-0979-1988-15654-6.pdf|doi=10.1090/s0273-0979-1988-15654-6}}&lt;/ref&gt;
*[[Hans Werner Ballmann|Ballmann, Werner]]; Gromov, Mikhael; Schroeder, Viktor: Manifolds of nonpositive curvature. Progress in Mathematics, 61. Birkhäuser Boston, Inc., Boston, MA, 1985. vi+263 pp. {{ISBN|0-8176-3181-X}}&lt;ref&gt;{{cite journal|author=Heintze, Ernst|title=Review: ''Manifolds of nonpositive curvature'', by W. Ballmann, M. Gromov &amp; V. Schroeder|journal=Bull. Amer. Math. Soc. (N.S.)|year=1987|volume=17|issue=2|pages=376–380|doi=10.1090/s0273-0979-1987-15603-5|url=http://www.ams.org/journals/bull/1987-17-02/S0273-0979-1987-15603-5/S0273-0979-1987-15603-5.pdf}}&lt;/ref&gt;
*Gromov, Mikhael: Carnot–Carathéodory spaces seen from within. Sub-Riemannian geometry, 79–323, Progr. Math., 144, Birkhäuser, Basel, 1996.
*Gromov, Michael: Volume and bounded cohomology. Inst. Hautes Études Sci. Publ. Math. No. 56 (1982), 5–99 (1983).

==Notes==
{{Reflist}}

==References==
{{refbegin}}
*[[Marcel Berger]], ''[http://www.ams.org/notices/200002/fea-berger.pdf Encounter with a Geometer, Part I]'', [[AMS Notices]], Volume 47, Number 2
*Marcel Berger, ''[http://www.ams.org/notices/200003/fea-berger.pdf Encounter with a Geometer, Part II]'', [[AMS Notices]], Volume 47, Number 3
{{refend}}

==External links==
{{commons category}}
*[http://www.ihes.fr/~gromov/ Personal page at IHÉS]
*[https://web.archive.org/web/20090408203911/http://as.nyu.edu/object/IO_3199.html Personal page at NYU]
*{{MathGenealogy|id=14999|name=Mikhail Gromov}}
*[http://www.pdmi.ras.ru/~vershik/gromov-vershik.pdf Anatoly Vershik, "Gromov's Geometry"]

{{Wolf Prize in Mathematics}}
{{Abel Prize laureates}}
{{Veblen Prize recipients}}
{{FRS 2011}}

{{Use dmy dates|date=May 2013}}
{{Authority control}}

{{DEFAULTSORT:Gromov, Mikhail}}
[[Category:1943 births]]
[[Category:Living people]]
[[Category:People from Boksitogorsk]]
[[Category:Russian people of Jewish descent]]
[[Category:Russian emigrants to France]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Foreign Members of the Russian Academy of Sciences]]
[[Category:Kyoto laureates in Basic Sciences]]
[[Category:Differential geometers]]
[[Category:Russian mathematicians]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century French mathematicians]]
[[Category:French people of Russian-Jewish descent]]
[[Category:Group theorists]]
[[Category:New York University faculty]]
[[Category:Wolf Prize in Mathematics laureates]]
[[Category:Geometers]]
[[Category:Members of the French Academy of Sciences]]
[[Category:Members of the Norwegian Academy of Science and Letters]]
[[Category:Abel Prize laureates]]
[[Category:Foreign Members of the Royal Society]]
[[Category:ISI highly cited researchers]]
[[Category:Soviet mathematicians]]</text>
      <sha1>quwt7j4rwucxj9kkci161xqytatde8i</sha1>
    </revision>
  </page>
  <page>
    <title>Monge array</title>
    <ns>0</ns>
    <id>229649</id>
    <revision>
      <id>824696616</id>
      <parentid>696359161</parentid>
      <timestamp>2018-02-08T22:50:01Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Operations research]] using [[WP:HC|HotCat]] not mentioned in article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4543">{{refimprove|date=September 2012}}
In mathematics applied to [[computer science]], '''Monge arrays''', or '''Monge matrices''', are mathematical objects named for their discoverer, the French mathematician [[Gaspard Monge]].

An ''m''-by-''n'' [[matrix (mathematics)|matrix]] is said to be a ''Monge array'' if, for all &lt;math&gt;\scriptstyle i,\, j,\, k,\, \ell&lt;/math&gt; such that

:&lt;math&gt;1\le i &lt; k\le m\text{ and }1\le j &lt; \ell\le n&lt;/math&gt;

one obtains&lt;ref&gt;{{cite journal
| journal= Discrete Applied Mathematics
| first1 = Rainer E. | last1 = Burkard
| first2 = Bettina | last2 = Klinz
| first3 = Rüdiger | last3 = Rudolf
| title = Perspectives of Monge properties in optimization
| publisher = ELSEVIER 
| volume = 70 
| year = 1996
| issue = 2 
| pages = 95–96
 | doi=10.1016/0166-218x(95)00103-x
}}&lt;/ref&gt;

:&lt;math&gt;A[i,j] + A[k,\ell] \le A[i,\ell] + A[k,j].\,&lt;/math&gt;

So for any two rows and two columns of a Monge array (a 2&amp;nbsp;&amp;times;&amp;nbsp;2 sub-matrix) the four elements at the intersection points have the property that the sum of the upper-left and lower right elements (across the [[main diagonal]]) is less than or equal to the sum of the lower-left and upper-right elements (across the [[antidiagonal]]).

This matrix is a Monge array:
:&lt;math&gt;
\begin{bmatrix}
10 &amp; 17 &amp; 13 &amp; 28 &amp; 23 \\
17 &amp; 22 &amp; 16 &amp; 29 &amp; 23 \\
24 &amp; 28 &amp; 22 &amp; 34 &amp; 24 \\
11 &amp; 13 &amp; 6 &amp; 17 &amp; 7 \\
45 &amp; 44 &amp; 32 &amp; 37 &amp; 23 \\
36 &amp; 33 &amp; 19 &amp; 21 &amp; 6 \\
75 &amp; 66 &amp; 51 &amp; 53 &amp; 34 \end{bmatrix}&lt;/math&gt;

For example, take the intersection of rows 2 and 4 with columns 1 and 5.
The four elements are:
:&lt;math&gt;
\begin{bmatrix}
17 &amp; 23\\
11 &amp; 7 \end{bmatrix}&lt;/math&gt;

: 17 + 7 = 24
: 23 + 11 = 34

The sum of the upper-left and lower right elements is less than or equal to the sum of the lower-left and upper-right elements.

==Properties==
*The above definition is equivalent to the statement
:A matrix is a Monge array [[if and only if]] &lt;math&gt;A[i,j] + A[i+1,j+1]\le A[i,j+1] + A[i+1,j]&lt;/math&gt; for all &lt;math&gt;1\le i &lt; m&lt;/math&gt; and &lt;math&gt;1\le j &lt; n&lt;/math&gt;.

*Any subarray produced by selecting certain rows and columns from an original Monge array will itself be a Monge array.
*Any [[linear combination]] with non-negative coefficients of Monge arrays is itself a Monge array.
*One interesting property of Monge arrays is that if you mark with a circle the leftmost minimum of each row, you will discover that your circles march downward to the right; that is to say, if &lt;math&gt;f(x) = \arg\min_{i\in \{1,\ldots,m\}} A[x,i]&lt;/math&gt;, then &lt;math&gt;f(j)\le f(j+1)&lt;/math&gt; for all &lt;math&gt;1\le j &lt; n&lt;/math&gt;. Symmetrically, if you mark the uppermost minimum of each column, your circles will march rightwards and downwards. The row and column ''maxima'' march in the opposite direction: upwards to the right and downwards to the left.
*The notion of ''weak Monge arrays'' has been proposed; a weak Monge array is a square ''n''-by-''n'' matrix which satisfies the Monge property &lt;math&gt;A[i,i] + A[r,s]\le A[i,s] + A[r,i]&lt;/math&gt; only for all &lt;math&gt;1\le i &lt; r,s\le n&lt;/math&gt;.
*Every Monge array is totally monotone, meaning that its row minima occur in a nondecreasing sequence of columns, and that the same property is true for every subarray. This property allows the row minima to be found quickly by using the [[SMAWK algorithm]].
*Monge matrix is just another name for [[supermodular function|submodular function]] of two discrete variables. Precisely, ''A'' is a Monge matrix if and only if ''A''[''i'',''j''] is a submodular function of variables&amp;nbsp;''i'',''j''.

==Applications==
*A square Monge matrix which is also symmetric about its [[main diagonal]] is called a ''[[Supnick matrix]]'' (after [[Fred Supnick]]); this kind of matrix has applications to the [[traveling salesman problem]] (namely, that the problem admits of easy solutions when the [[distance matrix]] can be written as a Supnick matrix). Note that any linear combination of Supnick matrices is itself a Supnick matrix.

== References ==
{{Reflist}}
* {{cite journal | title = Some problems around travelling salesmen, dart boards, and euro-coins | first1 = Vladimir G. | last1 = Deineko | first2 =  Gerhard J. | last2 = Woeginger | author2-link = Gerhard J. Woeginger | journal = Bulletin of the European Association for Theoretical Computer Science | publisher = [[European Association for Theoretical Computer Science|EATCS]] | volume = 90 |date=October 2006 | issn = 0252-9742 | pages = 43–52 | url = http://alexandria.tue.nl/openaccess/Metis211810.pdf | format = PDF }}

[[Category:Theoretical computer science]]</text>
      <sha1>gih334qrv5523hzbbk16df8wnfesgwb</sha1>
    </revision>
  </page>
  <page>
    <title>Nova fractal</title>
    <ns>0</ns>
    <id>17468979</id>
    <redirect title="Newton fractal" />
    <revision>
      <id>682684329</id>
      <parentid>662273125</parentid>
      <timestamp>2015-09-25T09:13:01Z</timestamp>
      <contributor>
        <username>Afree10</username>
        <id>15588671</id>
      </contributor>
      <comment>Moved to Fractals category to get required attention.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50">#REDIRECT [[Newton fractal]]
[[Category:Fractals]]</text>
      <sha1>6j2cdunjovw8h8mfpozdcxll63lq814</sha1>
    </revision>
  </page>
  <page>
    <title>Parallel parking problem</title>
    <ns>0</ns>
    <id>32366841</id>
    <revision>
      <id>830021705</id>
      <parentid>727707794</parentid>
      <timestamp>2018-03-12T07:24:27Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1578">The '''parallel parking problem''' is a [[motion planning]] problem in [[control theory]] and [[mechanics]] to determine the path a car must take in order to [[parallel parking|parallel park]] into a parking space.  The front wheels of a car are permitted to turn, but the rear wheels must stay aligned.  When a car is initially adjacent to a parking space, to move into the space it would need to move in a direction perpendicular to the allowed path of motion of the rear wheels.  The admissible motions of the car in its configuration space are an example of a [[nonholonomic system]].

==See also==
* [[Automatic parking]]
* [[Bicycle and motorcycle dynamics]]
* [[Falling cat problem]]

==References==
* {{citation|url=http://philsci-archive.pitt.edu/794/1/falling-cats.pdf|title=Falling cats, parallel parking, and polarized light|last=Batterman|first=R|journal=Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics|volume=34|issue=4|year=2003|pages=527&amp;ndash;557|doi=10.1016/s1355-2198(03)00062-5}}.
* {{citation|url=http://www-stat.wharton.upenn.edu/~shepp/publications/99.pdf|title=Optimal paths for a car that goes both forwards and backwards|first1=J.A.|last1=Reeds|first2=L.A.|last2=Shepp|journal=Pacific Journal of Mathematics|year=1990|volume=145|issue=2|pages=367&amp;ndash;393|doi=10.2140/pjm.1990.145.367|deadurl=yes|archiveurl=https://web.archive.org/web/20110927061449/http://www-stat.wharton.upenn.edu/~shepp/publications/99.pdf|archivedate=2011-09-27|df=}}.

[[Category:Control theory]]


{{applied-math-stub}}</text>
      <sha1>s5jxevxr0pidkci0qy2fn5on4r82084</sha1>
    </revision>
  </page>
  <page>
    <title>Percentage point</title>
    <ns>0</ns>
    <id>1969007</id>
    <revision>
      <id>868832889</id>
      <parentid>868801892</parentid>
      <timestamp>2018-11-14T18:58:13Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/128.220.159.33|128.220.159.33]] ([[User talk:128.220.159.33|talk]]): No. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3810">{{distinguish-redirect|Percent point|Percent point function}}

A '''percentage point''' or '''percent point''' is the [[unit (measurement)|unit]] for the [[Difference (mathematics)|arithmetic difference]] of two [[percentage]]s. For example, moving up from 40% to 44% is a 4 ''percentage point'' increase, but is an actual 10 percent increase in what is being measured.&lt;ref&gt;{{cite book |last=Brechner |first=Robert |date=2008 |title=Contemporary Mathematics for Business and Consumers, Brief Edition |url=https://books.google.com/?id=jSsHAAAAQBAJ&amp;lpg=PA190&amp;dq=percentage%20points&amp;pg=PA190#v=onepage&amp;q=percentage%20points&amp;f=false |location= |publisher=Cengage Learning |page=190 |access-date=7 May 2015 |deadurl=no |archiveurl=https://web.archive.org/web/20150518123546/https://books.google.co.uk/books?id=jSsHAAAAQBAJ&amp;lpg=PA190&amp;dq=percentage%20points&amp;hl=no&amp;pg=PA190#v=onepage&amp;q=percentage%20points&amp;f=false |archivedate=18 May 2015 |df= |isbn=9781111805500 }}&lt;/ref&gt; In the literature, the percentage point unit is usually either written out,&lt;ref&gt;{{cite book |last=Wickham |first=Kathleen |date=2003 |title=Math Tools for Journalists |url=https://books.google.com/?id=RYtYmMD2ReAC&amp;lpg=PP1&amp;dq=textbook%20mathematics%20%22percentage%20points%22&amp;pg=PA30#v=onepage&amp;q=points&amp;f=false |location= |publisher=Cengage Learning |page=30 |access-date=7 May 2015 |deadurl=no |archiveurl=https://web.archive.org/web/20150518123538/https://books.google.co.uk/books?id=RYtYmMD2ReAC&amp;lpg=PP1&amp;dq=textbook%20mathematics%20%22percentage%20points%22&amp;hl=no&amp;pg=PA30#v=onepage&amp;q=points&amp;f=false |archivedate=18 May 2015 |df= |isbn=9780972993746 }}&lt;/ref&gt; or abbreviated as ''pp'' or ''p.p.'' to avoid ambiguity. After the first occurrence, some writers abbreviate by using just "point" or "points".

Consider the following hypothetical example: In 1980, 50 percent of the population smoked, and in 1990 only 40 percent smoked. One can thus say that from 1980 to 1990, the prevalence of smoking decreased by 10 ''percentage points'' although smoking did not decrease by 10 percent (it decreased by ''20 percent'') – percentages indicate ratios, not differences.

Percentage-point differences are one way to express a risk or [[probabilities|probability]]. Consider a drug that cures a given disease in 70 percent of all cases, while without the drug, the disease heals spontaneously in only 50 percent of cases. The drug reduces absolute risk by 20 percentage points. Alternatives may be more meaningful to consumers of statistics, such as the  [[Multiplicative inverse|reciprocal]], also known as the [[number needed to treat]] (NNT). In this case, the reciprocal transform of the percentage-point difference would be 1/(20pp) = 1/0.20 = 5. Thus if 5 patients are treated with the drug, one could expect to heal one more case of the disease than would have occurred in the absence of the drug.

For measurements involving percentages as a unit, such as, growth, [[yield (finance)|yield]], or [[ejection fraction]], [[statistical deviation]]s and related [[descriptive statistics]], including the [[standard deviation]] and [[root-mean-square error]], the result should be expressed in units of percentage points instead of percentage. Mistakenly using percentage as the unit for the standard deviation is confusing, since percentage is also used as a unit for the [[relative standard deviation]], i.e. standard deviation divided by average value ([[coefficient of variation]]).

== Related units ==
* [[Percentage]] (%) 1 part in 100
* [[permille|Per mille]] (‰) 1 part in 1,000
* [[Basis point]] (‱) 1 part in 10,000
* [[Parts-per notation]]
* [[Baker percentage]]
* [[Percent point function]]

== References ==
{{Reflist}}

[[Category:Mathematical terminology]]
[[Category:Probability assessment]]
[[Category:Units of measurement]]</text>
      <sha1>49sb2qfho7b6nx13swdiht08f16uwmo</sha1>
    </revision>
  </page>
  <page>
    <title>Product σ-algebra</title>
    <ns>0</ns>
    <id>42487023</id>
    <redirect title="Sigma-algebra" />
    <revision>
      <id>861258152</id>
      <parentid>604129578</parentid>
      <timestamp>2018-09-26T05:21:12Z</timestamp>
      <contributor>
        <username>NikelsenH</username>
        <id>18120325</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="73">#REDIRECT [[Sigma-algebra#Product σ-algebra]]

[[Category:Set families]]</text>
      <sha1>hq7ufm6caxh8jahnsult1lqc16g6ltq</sha1>
    </revision>
  </page>
  <page>
    <title>Projective Set (game)</title>
    <ns>0</ns>
    <id>45646754</id>
    <revision>
      <id>835931033</id>
      <parentid>833737844</parentid>
      <timestamp>2018-04-11T16:59:16Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <minor/>
      <comment>Removed 1 archive link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5165">[[Image:Projective-set-deck.jpg|thumb|A Projective Set deck.]]
'''Projective Set''' (sometimes shortened to '''ProSet''') is a [[Turns, rounds and time-keeping systems in games#Real-time|real-time]] [[card game]] derived from the older game ''[[Set (game)|Set]]''.
The deck contains cards consisting of colored dots; some cards are laid out on the table and players attempt to find "Sets" among them.
The word ''projective'' comes from the game's relation to [[Projective space#Finite projective spaces and planes|Projective spaces]] over the [[finite field]] with two elements.&lt;ref name=Davis-Maclagan/&gt;

Projective Set has been studied [[mathematics|mathematically]] as well as played recreationally.
It has been a popular game at [[Canada/USA Mathcamp]].&lt;ref&gt;https://www.mathcamp.org/2014/academics/Week4Blurbs.pdf&lt;/ref&gt;

== Rules ==

A Projective Set card has six binary attributes, or [[bit]]s, generally represented by colored dots. For each color of dot,
each card either has that dot or does not.
There is one card for each possible combination of dots except the combination of no dots at all,
making &lt;math&gt;2^6 - 1 = 63&lt;/math&gt; cards total.

Three cards are said to form a "set" if the total number of dots of each color is either 0 or 2.
Similarly, four or more cards form a "set" if the number of dots of each color is an even number.

A card and itself could be said to form a two-card set, but as the cards in the deck are all distinct, this
does not arise in actual gameplay.

=== Original Version ===

In the original version, as in ''Set'', 12 cards are laid out on the table.
The first player to find three cards which form a set and call out "set" takes the three cards.
Three new cards are then dealt and the play continues until the deck is depleted.

If at any time the players agree there is no set among the cards, three new cards can be dealt, bringing
the total number of cards on the table to 15. Other than this, new cards are not dealt out unless the
number of cards on the table goes below 12.

The game ends when the deck is depleted and no more sets can be found among the cards on the
table. The player who captured the most sets is the winner.

=== 7-card Version ===

A variation of the game, more popular than the original, allows sets of any size, rather than just sets of size three.
7 cards are put out on the table at a time, and when a set is found (with anywhere from 3-7 cards),
all the cards from the set are taken and then replaced.
Points are generally given at the end according to how many cards each player captured rather than how many sets.

It turns out that among any 7 cards there is a set, under these rules, so there is no extra rule necessary for the case that no
set can be found.

== Mathematics ==

The cards of a Projective Set deck can be thought of as nonzero [[Vector (mathematics and physics)|vectors]] in the [[Examples of vector spaces#Finite vector spaces|finite vector space]]
&lt;math&gt;\mathbb{F}^6&lt;/math&gt;.
The collection of all such vectors is the finite [[projective space]] with order 2 and dimension 5.
Three cards form a set if and only if the corresponding points are collinear in that space.
More generally, in the variant, &lt;math&gt;n&lt;/math&gt; cards form a set if and only if the corresponding vectors
add to the zero vector.

In ''Set'', there can exist 20 cards out of the 81 without a set, but no more.
In Projective Set, there can exist up to 32 out of the 63 cards with no (3-card) set.&lt;ref name=Davis-Maclagan/&gt;&lt;ref name=Bose/&gt;

== References ==
{{reflist|refs=
&lt;ref name=Davis-Maclagan&gt;
{{Cite web|url=http://www.math.rutgers.edu/~maclagan/papers/set.pdf|title=The Card Game Set|author=Benjamin Lent Davis and Diane MacLagan}}
&lt;/ref&gt;
&lt;ref name=Bose&gt;
{{cite journal
| last        = Bose
| first       = R. C.
| date        = March 1947
| title       = Mathematical theory of the symmetrical factorial design
| url         = 
| journal     = Sankhyā: The Indian Journal of Statistics
| location    = 
| publisher   = Springer on behalf of the Indian Statistical Institute
| volume      = 8
| issue       = 2
| pages       = 107–166
| access-date = 
}}
&lt;/ref&gt;
}}

== External links ==

* Projective Set (the variant in which sets of size larger than 3 are allowed) can be played online at
various sites, including: [http://projectiveset.jonemo.de/]
* [https://www.ocf.berkeley.edu/~dadams/proset/]
* [http://www.settinger.net/projects/proset/]
* [http://mathcamp.org/2015/proset/]
* [https://web.archive.org/web/20150402094518/http://pro-zero-sumz.murfel.name/].
* The game was [http://www.zerosumz.com/ marketed online] in April 2012 under the name ''Zero sumZ''.
* The game was [http://socksgame.com/ marketed online] since 2011 under the name ''Socks''.
* [https://itunes.apple.com/us/app/projective-set/id953530895?mt=8] A version of the game is available for [[iOS]].
* [http://stacky.net/wiki/index.php?title=Projective_Set An article written in 2011 about Projective Set].

&lt;!--
http://www.mathcamp.org/prospectiveapplicants/quiz/index.php
https://www.mathcamp.org/2011/hunt/parttwo/cantsee_solution.pdf
--&gt;

[[Category:Dedicated deck card games]]
[[Category:Recreational mathematics]]</text>
      <sha1>dhvjvfnjajols6ryx720wjnvrw3qefa</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum t-design</title>
    <ns>0</ns>
    <id>20210883</id>
    <revision>
      <id>822422278</id>
      <parentid>696559708</parentid>
      <timestamp>2018-01-26T08:21:10Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10076">A '''Quantum t-design''' is a probability distribution over pure [[quantum states]] which can duplicate properties of the probability distribution over the [[Haar measure]] for polynomials of degree t or less. Specifically, the average of any polynomial function of degree t over the design is exactly the same as the average over Haar measure. Here the Haar measure is a uniform probability distribution over all quantum states. Quantum t-designs are so called because they are analogous to [[Block_design#Generalization:_t-designs|t-designs]] in classical statistics, which arose historically in connection with the problem of [[design of experiments]].  Quantum t-designs are usually unique, and thus almost always calculable. Two particularly important types of t-designs in quantum mechanics are spherical and unitary t-designs.

Spherical t-designs are designs where points of the design (i.e. the points being used for the averaging process) are points on a [[unit sphere]]. Spherical t-designs and variations thereof have been considered lately and found useful in [[quantum information theory]],&lt;ref&gt;A. Hayashi, T. Hashimoto, M. Horibe. Reexamination of optimal quantum state estimation of pure states. Phys. Rev. A, 72: 032325, 2006. Also quant-ph/0410207.&lt;/ref&gt; [[quantum cryptography]] and other related fields.

Unitary designs are analogous to spherical designs in that they approximate the entire [[unitary group]] via a finite collection of [[unitary matrices]]. Unitary designs have been found useful in information theory&lt;ref&gt;C. Dankert, R. Cleve, J. Emerson, and E. Livine, Exact and approximate unitary 2-designs: constructions and applications, (2006).&lt;/ref&gt; and [[quantum computing]]. Unitary designs are especially useful in quantum computing since most operations are represented by unitary operators.

== Motivation ==
In a d-dimensional Hilbert space when averaging over all quantum pure states the natural [[Group (mathematics)|group]] is SU(d), the [[special unitary group]] of dimension d. The Haar measure is, by definition, the unique group-invariant measure, so it is used to average properties that are not unitarily invariant over all states, or over all unitaries.

A particularly widely used example of this is the spin &lt;math&gt;\tfrac{1}{2}&lt;/math&gt; system. For this system the relevant group is SU(2) which is the group of all 2x2 unitary operators. Since every 2x2 unitary operator is a rotation of the [[Bloch sphere]], the Haar measure for spin-1/2 particles is invariant under all rotations of the Bloch sphere. This implies that the Haar measure is ''the'' rotationally invariant measure on the Bloch sphere, which can be thought of as a constant density distribution over the surface of the sphere.

Another recent application is the fact that a symmetric informationally complete [[POVM]] is also a spherical 2-design. Also, since a 2-design must have more than &lt;math&gt;d^2&lt;/math&gt; elements, a [[SIC-POVM]] is a '''minimal''' 2-design.

== Spherical Designs ==
Complex projective (t,t)-designs have been studied in [[quantum information theory]] as quantum 2-designs, and in t-designs of vectors in the unit sphere in &lt;math&gt;\mathbb{R}^N&lt;/math&gt; which, when transformed to vectors in &lt;math&gt;\mathbb{C}^{N/2}&lt;/math&gt; become complex projective (t/2,t/2)-designs.

Formally, we define&lt;ref name=autogenerated1&gt;[https://arxiv.org/abs/quant-ph/0701126 [quant-ph/0701126&amp;#93; Quantum t-designs: t-wise independence in the quantum world]&lt;/ref&gt; a complex projective (t,t)-design as a probability distribution over quantum states &lt;math&gt;(p_i,|\phi_i\rangle)&lt;/math&gt; if

&lt;math&gt;\sum_i p_i (|\phi_i\rangle \langle \phi_i|)^{\otimes t} = \int_{\psi}(|\psi\rangle \langle \psi|)^{\otimes t}d\psi&lt;/math&gt;

Here, the integral over states is taken over the Haar measure on the unit sphere in &lt;math&gt;\mathbb{C}^N&lt;/math&gt;

Exact t-designs over quantum states cannot be distinguished from the uniform probability distribution over all states when using t copies of a state from the probability distribution. However in practice even t-designs may be difficult to compute. For this reason approximate t-designs are useful.

Approximate (t,t)-designs are most useful due to their ability to be efficiently implemented. i.e. it is possible to generate a quantum state &lt;math&gt;|\phi\rangle&lt;/math&gt; distributed according to the probability distribution &lt;math&gt;p_i |\phi_i\rangle&lt;/math&gt; in &lt;math&gt;O(\log^c N)&lt;/math&gt; time.
This efficient construction also implies that the [[POVM]] of the operators &lt;math&gt;Np_i |\phi_i\rangle\langle\phi_i|&lt;/math&gt; can be implemented in &lt;math&gt;O(\log^c N)&lt;/math&gt; time.

The technical definition of an approximate (t,t)-design is:

If &lt;math&gt;\sum_i p_i |\phi_i\rangle \langle \phi_i| = \int_{\psi}|\psi\rangle \langle \psi|d\psi&lt;/math&gt;

and &lt;math&gt;(1-\epsilon)\int_{\psi}(|\psi\rangle \langle \psi|)^{\otimes t}d\psi \leq \sum_i p_i (|\phi_i\rangle \langle \phi_i|)^{\otimes t} \leq (1+\epsilon)\int_{\psi}(|\psi\rangle \langle \psi|)^{\otimes t}d\psi&lt;/math&gt;

then &lt;math&gt;(p_i,|\phi_i\rangle)&lt;/math&gt; is an &lt;math&gt;\epsilon&lt;/math&gt;-approximate (t,t)-design.

It is possible, though perhaps inefficient, to find an &lt;math&gt;\epsilon&lt;/math&gt;-approximate (t,t) design consisting of quantum pure states for a fixed t.

===Construction===
For convenience N is assumed to be a power of 2.

Using the fact that for any N there exists a set of &lt;math&gt;N^d&lt;/math&gt; functions {0,...,N-1} &lt;math&gt;\rightarrow&lt;/math&gt; {0,...,N-1} such that for any distinct &lt;math&gt;k_1, ..., k_d \in&lt;/math&gt; {0,...,N-1} the image under f, where f is chosen at random from S, is exactly the uniform distribution over tuples of d elements of {0,...,N-1}.

Let &lt;math&gt;|\psi\rangle = \sum_{i=1}^N \alpha |i\rangle&lt;/math&gt; be drawn from the Haar measure. Let &lt;math&gt;P_n&lt;/math&gt; be the probability distribution of &lt;math&gt;\alpha_n&lt;/math&gt; and let &lt;math&gt;P= \lim_{N\rightarrow \infty} \sqrt{N} P_N&lt;/math&gt;. Finally let &lt;math&gt;\alpha&lt;/math&gt; be drawn from P. If we define &lt;math&gt;X = |\alpha|&lt;/math&gt; with probability &lt;math&gt;\tfrac12&lt;/math&gt; and &lt;math&gt;X = -|\alpha|&lt;/math&gt; with probability &lt;math&gt;\tfrac{1}{2}&lt;/math&gt; then:
&lt;math&gt;E[X^j] = 0&lt;/math&gt; for odd j and &lt;math&gt;E[X^j] = (\tfrac{j}{2})!&lt;/math&gt; for even j.

Using this and [[Gaussian quadrature]] we can construct &lt;math&gt;p_{f,g} = \frac{\sum_{i=1}^N a_{f,i}^2}{|S_1| |S_2|}&lt;/math&gt; so that &lt;math&gt;p_{f,g}|\psi_{f,g}\rangle&lt;/math&gt; is an approximate (t,t)-design.

== Unitary Designs ==
Elements of the unitary design are elements of the unitary group, U(d), the group of &lt;math&gt;d \times d&lt;/math&gt; unitary matrices. A t-design of unitary operators will generate a t-design of states.

Suppose &lt;math&gt;{U_k}&lt;/math&gt; is your unitary design (i.e. a set of unitary operators).  Then for ''any'' pure state &lt;math&gt;|\psi\rangle&lt;/math&gt; let &lt;math&gt;|\psi_k\rangle = U_k|\psi\rangle&lt;/math&gt;.  Then &lt;math&gt;{|\psi_k\rangle}&lt;/math&gt; will always be a t-design for states.

Formally define&lt;ref&gt;[https://arxiv.org/abs/0809.3813 [0809.3813&amp;#93; Unitary designs and codes]&lt;/ref&gt; a ''unitary t-design'', X, if

&lt;math&gt;\frac{1}{|X|}\sum_{U \in X} U^{\otimes t}\otimes (U^{*})^{\otimes t} = \int_{U(d)} U^{\otimes t}\otimes (U^{*})^{\otimes t}dU&lt;/math&gt;

Observe that the space linearly spanned by the matrices &lt;math&gt;U^{\otimes r}\otimes (U^{*})^{\otimes s}dU&lt;/math&gt; over all choices of U is identical to the restriction &lt;math&gt;U \in X&lt;/math&gt; and &lt;math&gt;r + s = t&lt;/math&gt; This observation leads to a conclusion about the duality between unitary designs and unitary codes.

Using the permutation maps it is possible&lt;ref name=autogenerated1 /&gt; to verify directly that a set of unitary matrices forms a t-design.&lt;ref&gt;B. Collins and P. ´ Sniady, Integration with respect to the Haar measure on unitary, orthogonal and symplectic group, Comm. Math. Phys.,264 (2006), 773–795.&lt;/ref&gt;

One direct result of this is that for any finite &lt;math&gt;X \subseteq U(d)&lt;/math&gt;

&lt;math&gt;\frac{1}{|X|^2} \sum_{U,V \in X}|tr(U*V)|^{2t} \geq \int_{U(d)}|tr(U*V)|^{2t}dU&lt;/math&gt;

With equality if and only if X is a t-design.

1 and 2-designs have been examined in some detail and absolute bounds for the dimension of X, |X|, have been derived.&lt;ref&gt;D. Gross, K. Audenaert, and J. Eisert, Evenly distributed unitaries: on the structure of unitary designs, J. Math. Phys., 48 (2007),052104, 22.&lt;/ref&gt;

===Bounds for unitary designs===
Define &lt;math&gt;Hom(U(d),t,t)&lt;/math&gt; as the set of functions homogeneous of degree t in &lt;math&gt;U&lt;/math&gt; and homogeneous of degree t in &lt;math&gt;U^{*}&lt;/math&gt;, then if for every &lt;math&gt;f \in Hom(U(d),t,t)&lt;/math&gt;:

&lt;math&gt;\frac{1}{|X|} \sum_{U \in X} f(U) = \int_{U(d)}f(U) dU&lt;/math&gt;

then X is a unitary t-design.

We further define the inner product for functions &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; on &lt;math&gt;U(d)&lt;/math&gt; as the average value of &lt;math&gt;\bar{f}g&lt;/math&gt; as:

&lt;math&gt;\langle f,g\rangle := \int_{U(d)}\bar{f(U)}g(U) dX&lt;/math&gt;

and &lt;math&gt;\langle f,g\rangle_X&lt;/math&gt; as the average value of &lt;math&gt;\bar{f}g&lt;/math&gt; over any finite subset &lt;math&gt;X \subset U(d)&lt;/math&gt;.

it follows that X is a unitary t-design iff &lt;math&gt;\langle 1,f\rangle_X = \langle 1,f\rangle \quad\forall f&lt;/math&gt;.

From the above it is demonstrable that if X is a t-design then &lt;math&gt;|X| \geq dim(Hom(U(d),\left\lceil\tfrac{t}2\right\rceil,\left\lfloor\tfrac{t}2\right\rfloor))&lt;/math&gt; is an '''absolute bound''' for the design.  This imposes an upper bound on the size of a unitary design. This bound is '''absolute''' meaning it depends only on the strength of the design or the degree of the code, and not the distances in the subset, X.

----

A unitary code is a finite subset of the unitary group in which a few inner product values occur between elements. Specifically, a unitary code is defined as a finite subset &lt;math&gt;X \subset U(d)&lt;/math&gt; if for all &lt;math&gt;U \neq M&lt;/math&gt; in X &lt;math&gt;|tr(U^*M)|^2&lt;/math&gt; takes only distinct values.

It follows that &lt;math&gt;|X| \leq dim(Hom(U(d),s,s))&lt;/math&gt; and if U and M are orthogonal: &lt;math&gt;|X| \leq dim(Hom(U(d),s,s-1))&lt;/math&gt;

==Notes==
{{reflist|2}}

[[Category:Quantum mechanics]]
[[Category:Quantum information science]]
[[Category:Information theory]]
[[Category:Quantum information theory]]</text>
      <sha1>qo3ys32fqyd4dxukqp4gzlhs9d4rjxv</sha1>
    </revision>
  </page>
  <page>
    <title>Rellich–Kondrachov theorem</title>
    <ns>0</ns>
    <id>7907151</id>
    <revision>
      <id>825007781</id>
      <parentid>823139660</parentid>
      <timestamp>2018-02-10T22:52:56Z</timestamp>
      <contributor>
        <username>Kusma</username>
        <id>145855</id>
      </contributor>
      <comment>while his birthplace is now in Italy, he lived in Austria and Germany all his life.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3981">In [[mathematics]], the '''Rellich–Kondrachov theorem''' is a [[compactly embedded|compact embedding]] [[theorem]] concerning [[Sobolev space]]s. It is named after the Austrian-German mathematician [[Franz Rellich]] and the Russian mathematician [[Vladimir Iosifovich Kondrashov]].  Rellich proved the ''L''&lt;sup&gt;2&lt;/sup&gt; theorem and Kondrashov the ''L''&lt;sup&gt;''p''&lt;/sup&gt; theorem.

==Statement of the theorem==

Let Ω&amp;nbsp;⊆&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; be an [[open set|open]], [[bounded set|bounded]] [[Lipschitz domain]], and let 1&amp;nbsp;≤&amp;nbsp;''p''&amp;nbsp;&amp;lt;&amp;nbsp;''n''. Set

:&lt;math&gt;p^{*} := \frac{n p}{n - p}.&lt;/math&gt;

Then the Sobolev space ''W''&lt;sup&gt;1,''p''&lt;/sup&gt;(Ω;&amp;nbsp;'''R''') is [[continuously embedded]] in the [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; space]] ''L''&lt;sup&gt;''p''&lt;sup&gt;∗&lt;/sup&gt;&lt;/sup&gt;(Ω;&amp;nbsp;'''R''') and is [[compactly embedded]] in ''L''&lt;sup&gt;''q''&lt;/sup&gt;(Ω;&amp;nbsp;'''R''') for every 1&amp;nbsp;≤&amp;nbsp;''q''&amp;nbsp;&amp;lt;&amp;nbsp;''p''&lt;sup&gt;∗&lt;/sup&gt;. In symbols,

:&lt;math&gt;W^{1, p} (\Omega) \hookrightarrow L^{p^{*}} (\Omega)&lt;/math&gt;

and

:&lt;math&gt;W^{1, p} (\Omega) \subset \subset L^{q} (\Omega) \text{ for } 1 \leq q &lt; p^{*}.&lt;/math&gt;

===Kondrachov embedding theorem===

On a compact manifold with {{math|''C''&lt;sup&gt;1&lt;/sup&gt;}} boundary, the '''Kondrachov embedding theorem''' states that if {{math|''k'' &gt; ''ℓ''}} and {{math|''k'' − ''n''/''p'' &gt; ''ℓ'' − ''n''/''q''}} then the Sobolev embedding

:&lt;math&gt;W^{k,p}(M)\subset W^{\ell,q}(M)&lt;/math&gt;

is [[completely continuous]] (compact).

==Consequences==

Since an embedding is compact [[if and only if]] the inclusion (identity) operator is a [[compact operator]], the Rellich–Kondrachov theorem implies that any uniformly bounded sequence in ''W''&lt;sup&gt;1,''p''&lt;/sup&gt;(Ω;&amp;nbsp;'''R''') has a subsequence that converges in ''L''&lt;sup&gt;''q''&lt;/sup&gt;(Ω;&amp;nbsp;'''R'''). Stated in this form,  in the past the result was sometimes referred to as the '''Rellich–Kondrachov selection theorem''', since one "selects" a convergent subsequence. (However, today the customary name is "compactness theorem", whereas "selection theorem" has a precise and quite different meaning, referring to [[Multivalued function|multifunctions]]).

The Rellich–Kondrachov theorem may be used to prove the [[Poincaré inequality]],&lt;ref name="Evans"&gt;{{cite book | author=Evans, Lawrence C. | title=Partial Differential Equations | year=2010 | edition=2nd | isbn=0-8218-4974-3 | chapter=§5.8.1 | page=290}}&lt;/ref&gt; which states that for ''u''&amp;nbsp;∈&amp;nbsp;''W''&lt;sup&gt;1,''p''&lt;/sup&gt;(Ω;&amp;nbsp;'''R''') (where Ω satisfies the same hypotheses as above),

:&lt;math&gt;\| u - u_\Omega \|_{L^p (\Omega)} \leq C \| \nabla u \|_{L^p (\Omega)}&lt;/math&gt;

for some constant ''C'' depending only on ''p'' and the geometry of the domain Ω, where

:&lt;math&gt;u_\Omega := \frac{1}{\operatorname{meas} (\Omega)} \int_\Omega u(x) \, \mathrm{d} x &lt;/math&gt;

denotes the mean value of ''u'' over Ω.

==References==
&lt;references /&gt;

== Literature ==
* {{cite book | author=Evans, Lawrence C. | title=Partial Differential Equations | year=2010 | edition=2nd | publisher=American Mathematical Society | isbn=0-8218-4974-3}}
* Leoni, Giovanni (2009). ''A First Course in Sobolev Spaces''. [[Graduate Studies in Mathematics]]. '''105'''. American Mathematical Society. pp. xvi+607. {{ISBN|978-0-8218-4768-8}}. [[Mathematical Reviews|MR]] [https://www.ams.org/mathscinet-getitem?mr=2527916 2527916]. [[Zentralblatt MATH|Zbl]] [https://zbmath.org/?format=complete&amp;q=an:1180.46001 1180.46001]
* {{cite journal
 | last = Rellich
 | first = Franz
 | authorlink = Franz Rellich
 | title = Ein Satz über mittlere Konvergenz 
 | journal = Nachrichten von der Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse
 | volume = 1930
 | pages = 30–35 
 | date = 24 January 1930
 
 | language = German
 | url = https://eudml.org/doc/59297
 | jfm = 56.0224.02}}

{{DEFAULTSORT:Rellich-Kondrachov theorem}}
[[Category:Theorems in analysis]]
[[Category:Sobolev spaces]]</text>
      <sha1>tdgnclnksobft3bzpufr07kzmxop6ep</sha1>
    </revision>
  </page>
  <page>
    <title>Rotational symmetry</title>
    <ns>0</ns>
    <id>701096</id>
    <revision>
      <id>864821460</id>
      <parentid>864821356</parentid>
      <timestamp>2018-10-19T17:59:00Z</timestamp>
      <contributor>
        <username>Kirbanzo</username>
        <id>32890202</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/207.163.34.240|207.163.34.240]] ([[User talk:207.163.34.240|talk]]) to last revision by Polytope4d. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13802">{{refimprove|date=June 2018}} [[File:The armoured triskelion on the flag of the Isle of Man.svg|thumb|The [[triskelion]] appearing on the [[Flag of the Isle of Man|Isle of Man flag]] has rotational symmetry because it appears the same when rotated by one third of a full turn about its center.  Because its appearance is identical in three distinct orientations, its rotational symmetry is three-fold.]]
'''Rotational symmetry''', also known as '''radial symmetry''' in biology, is the property, a shape has when it looks the same after some rotation by a partial turn. An object's degree of rotational symmetry is the number of distinct orientations in which it looks the same.

== Formal treatment ==
{{See also|Rotational invariance}} 
Formally the  rotational symmetry is [[symmetry]] with respect to some or all [[rotation]]s in ''m''-dimensional [[Euclidean space]]. Rotations are [[Euclidean group#Direct and indirect isometries|direct isometries]], i.e., [[Isometry|isometries]] preserving [[Orientation (mathematics)|orientation]]. Therefore a [[symmetry group]] of rotational symmetry is a subgroup of ''E''&lt;sup&gt;+&lt;/sup&gt;(''m'') (see [[Euclidean group]]).

Symmetry with respect to all rotations about all points implies [[translational symmetry]] with respect to all translations, so space is homogeneous, and the symmetry group is the whole ''E''(''m''). With the [[Symmetry#Mathematical model for symmetry|modified notion of symmetry for vector fields]] the symmetry group can also be ''E''&lt;sup&gt;+&lt;/sup&gt;(''m'').

For symmetry with respect to rotations about a point we can take that point as origin. These rotations form the special [[orthogonal group]] SO(''m''), the group of ''m''×''m'' [[orthogonal matrices]] with determinant 1. For {{math|1=''m'' = 3}} this is the [[rotation group SO(3)]].

In another meaning of the word, the rotation group ''of an object'' is the symmetry group within ''E''&lt;sup&gt;+&lt;/sup&gt;(''n''), the [[Euclidean group|group of direct isometries]]; in other words, the intersection of the full symmetry group and the group of direct isometries. For [[chirality (mathematics)|chiral]] objects it is the same as the full symmetry group.

Laws of physics [[isotropy|are SO(3)-invariant]] if they do not distinguish different directions in space. Because of [[Noether's theorem]], rotational symmetry of a physical system is equivalent to the [[angular momentum]] conservation law.

===Discrete rotational symmetry===
'''Rotational symmetry of order&amp;nbsp;''n''''', also called '''''n''-fold rotational symmetry''', or '''discrete rotational symmetry of the ''n''th order''', with respect to a particular point (in 2D) or axis (in 3D) means that rotation by an angle of 360°/n (180°, 120°, 90°, 72°, 60°, 51&amp;nbsp;{{frac|3|7}}°, etc.) does not change the object.  Note that "1-fold" symmetry is no symmetry (all objects look alike after a rotation of 360°).

The [[Crystal system#Overview of point groups by crystal system|notation]] for ''n''-fold symmetry is '''''C&lt;sub&gt;n&lt;/sub&gt;''''' or simply "''n''". The actual [[symmetry group]] is specified by the point or axis of symmetry, together with the ''n''. For each point or axis of symmetry, the abstract group type is [[cyclic group]] of order&amp;nbsp;''n'', Z&lt;sub&gt;''n''&lt;/sub&gt;. Although for the latter also the notation ''C''&lt;sub&gt;''n''&lt;/sub&gt; is used, the geometric and abstract ''C''&lt;sub&gt;''n''&lt;/sub&gt; should be distinguished: there are other symmetry groups of the same abstract group type which are geometrically different, see [[Point groups in three dimensions#Cyclic symmetry groups in 3D cyclic symmetry groups|cyclic symmetry groups in 3D]].

The [[fundamental domain]] is a sector of 360°/n.

Examples without additional [[reflection symmetry]]:
*''n'' = 2, 180°: the ''dyad''; among the [[quadrilateral]]s, the [[parallelogram]]s, which have this as a fully identifying (necessary and sufficient) feature; letters Z, N, S; the outlines, albeit not the colors, of the [[yin and yang]] symbol; the [[Union Flag]] (as divided along the flag's diagonal and rotated about the flag's center point)
*''n'' = 3, 120°: ''triad'', [[triskelion]], [[Borromean rings]], [[Mitsubishi]] logo; sometimes the term ''trilateral symmetry'' is used;
*''n'' = 4, 90°: ''tetrad'', [[swastika]]
*''n'' = 6, 60°: ''hexad'', [[Star of David]]
*''n'' = 8, 45°: ''octad'', Octagonal [[muqarnas]], computer-generated (CG), ceiling

''C''&lt;sub&gt;''n''&lt;/sub&gt; is the rotation group of a regular ''n''-sided [[polygon]] in 2D and of a regular ''n''-sided [[pyramid]] in 3D.

If there is e.g. rotational symmetry with respect to an angle of 100°, then also with respect to one of 20°, the [[greatest common divisor]] of 100° and 360°.

A typical 3D object with rotational symmetry (possibly also with perpendicular axes) but no mirror symmetry is a [[propeller]].

===Examples===
{| class="wikitable" width=600
|- 
! C2 ([[commons:Category:2-fold rotational symmetry|more]])
! C3 ([[commons:Category:3-fold rotational symmetry|more]])
! C4 ([[commons:Category:4-fold rotational symmetry|more]])
! C5 ([[commons:Category:5-fold rotational symmetry|more]])
! C6 ([[commons:Category:6-fold rotational symmetry|more]])
|- valign=top
|[[File:Double_pendulum_flips_graph.png|120px]]&lt;BR&gt;[[Double Pendulum#Chaotic motion|Double Pendulum fractal]]
|[[File:Finland_road_sign_166.svg|120px]]&lt;BR&gt;[[Roundabout]] [[traffic sign]]
|[[File:HinduSwastika.svg|120px]]&lt;BR&gt;Decorative [[Hindu]] form 
|[[File:United States Bicentennial star 1976 (geometry).svg|120px]]&lt;BR&gt;[[United States Bicentennial|US Bicentennial]] Star
|&lt;BR&gt;[[Crop circle]] in perspective
|- valign=top
|[[File:En-300px-Shogi.png|120px]]&lt;BR&gt;The starting position in [[shogi]]
|[[File:Snoldelev-three-interlaced-horns.svg|120px]]&lt;BR&gt;[[Snoldelev Stone]]'s interlocked [[drinking horn]]s design
|[[File:Op-art-4-sided-spiral-tunnel-7.svg|120px]]
|[[File:15crossings-decorative-knot.svg|120px]]
|[[File:Olavsrose.svg|120px]]
|}

===Multiple symmetry axes through the same point===
For [[discrete symmetry]] with multiple symmetry axes through the same point, there are the following possibilities:
*In addition to an ''n''-fold axis, ''n'' perpendicular 2-fold axes: the [[dihedral group]]s ''D''&lt;sub&gt;n&lt;/sub&gt; of order&amp;nbsp;2''n'' ({{math|''n'' ≥ 2}}). This is the rotation group of a regular [[prism (geometry)|prism]], or regular [[bipyramid]]. Although the same notation is used, the geometric and abstract ''D''&lt;sub&gt;n&lt;/sub&gt; should be distinguished: there are other symmetry groups of the same abstract group type which are geometrically different, see [[Dihedral group#Dihedral symmetry groups in 3D|dihedral symmetry groups in 3D]].
*4×3-fold and 3×2-fold axes: the rotation group ''T'' of order&amp;nbsp;12 of a regular [[tetrahedron]]. The group is [[isomorphic]] to [[alternating group]] ''A''&lt;sub&gt;4&lt;/sub&gt;. 
*3×4-fold, 4×3-fold, and 6×2-fold axes: the rotation group&amp;nbsp;''O'' of order&amp;nbsp;24 of a [[cube]] and a regular [[octahedron]]. The group is isomorphic to [[symmetric group]] ''S''&lt;sub&gt;4&lt;/sub&gt;. 
*6×5-fold, 10×3-fold, and 15×2-fold axes: the rotation group&amp;nbsp;''I'' of order&amp;nbsp;60 of a [[dodecahedron]] and an [[icosahedron]]. The group is isomorphic to alternating group&amp;nbsp;''A''&lt;sub&gt;5&lt;/sub&gt;. The group contains 10 versions of ''D&lt;sub&gt;3&lt;/sub&gt;'' and 6 versions of ''D&lt;sub&gt;5&lt;/sub&gt;'' (rotational symmetries like prisms and antiprisms).

In the case of the [[Platonic solid]]s, the 2-fold axes are through the midpoints of opposite edges, and the number of them is half the number of edges. The other axes are through opposite vertices and through centers of opposite faces, except in the case of the tetrahedron, where the 3-fold axes are each through one vertex and the center of one face.

===Rotational symmetry with respect to any angle===&lt;!-- [[axisymmetric]], [[axisymmetrical]] and [[axisymmetry]] redirect to here --&gt;
Rotational symmetry with respect to any angle is, in two dimensions, [[circular symmetry]]. The fundamental domain is a [[Line (mathematics)#Ray|half-line]].

In three dimensions we can distinguish '''cylindrical symmetry''' and '''spherical symmetry''' (no change when rotating about one axis, or for any rotation). That is, no dependence on the angle using [[Coordinates (elementary mathematics)#Cylindrical coordinates|cylindrical coordinates]] and no dependence on either angle using [[Coordinates (elementary mathematics)#Spherical coordinates|spherical coordinates]]. The fundamental domain is a [[half-plane]] through the axis, and a radial half-line, respectively. '''Axisymmetric''' or '''axisymmetrical''' are [[adjective]]s which refer to an object having cylindrical symmetry, or '''axisymmetry''' (i.e. rotational symmetry with respect to a central axis) like a [[doughnut]] ([[torus]]). An example of approximate spherical symmetry is the Earth (with respect to density and other physical and chemical properties).

In 4D, continuous or discrete rotational symmetry about a plane corresponds to corresponding 2D rotational symmetry in every perpendicular plane, about the point of intersection. An object can also have  rotational symmetry about two perpendicular planes, e.g. if it is the [[Cartesian product]] of two rotationally symmetry 2D figures, as in the case of e.g. the [[duocylinder]] and various regular [[duoprism]]s.

===Rotational symmetry with translational symmetry===
{| class=wikitable align=right width=400
|[[File:Wallpaper group diagram p4.png|160px]]&lt;BR&gt;Arrangement within a [[primitive cell]] of 2- and 4-fold rotocenters. A [[fundamental domain]] is indicated in yellow.
|[[File:Wallpaper group diagram p6.png|240px]]&lt;BR&gt;Arrangement within a primitive cell of 2-, 3-, and 6-fold rotocenters, alone or in combination (consider the 6-fold symbol as a combination of a 2- and a 3-fold symbol); in the case of 2-fold symmetry only, the shape of the [[parallelogram]] can be different. For the case p6, a fundamental domain is indicated in yellow.
|}
2-fold rotational symmetry together with single [[translational symmetry]] is one of the [[Frieze group]]s. There are two rotocenters per [[primitive cell]].

Together with double translational symmetry the rotation groups are the  following [[wallpaper group]]s, with axes per primitive cell:
*p2 (2222): 4×2-fold; rotation group of a [[parallelogram]]mic, [[rectangle|rectangular]], and [[rhombus|rhombic]] [[Lattice (group)|lattice]].
*p3 (333): 3×3-fold; ''not'' the rotation group of any lattice (every lattice is upside-down the same, but that does not apply for this symmetry); it is e.g. the rotation group of the [[Tilings of regular polygons#Regular tilings|regular triangular tiling]] with the  equilateral triangles alternatingly colored. 
*p4 (442): 2×4-fold, 2×2-fold; rotation group of a [[Square (geometry)|square]] lattice.
*p6 (632): 1×6-fold, 2×3-fold, 3×2-fold; rotation group of a [[hexagonal]] lattice.
*2-fold rotocenters (including possible 4-fold and 6-fold), if present at all, form the translate of a lattice equal to the translational lattice, scaled by a factor 1/2. In the case translational symmetry in one dimension, a similar property applies, though the term "lattice" does not apply.
*3-fold rotocenters (including possible 6-fold), if present at all, form a regular hexagonal lattice equal to the translational lattice, rotated by 30° (or equivalently 90°), and scaled by a factor &lt;math&gt;\frac{1}{3} \sqrt {3}&lt;/math&gt;
*4-fold rotocenters, if present at all, form a regular square lattice equal to the translational lattice, rotated by 45°, and scaled by a factor &lt;math&gt;\frac{1}{2} \sqrt {2}&lt;/math&gt;
*6-fold rotocenters, if present at all, form a regular hexagonal lattice which is the translate of the translational lattice.

Scaling of a lattice divides the number of points per unit area by the square of the scale factor. Therefore the number of 2-, 3-, 4-, and 6-fold rotocenters per primitive cell is 4, 3, 2, and 1, respectively, again including 4-fold as a special case of 2-fold, etc.

3-fold rotational symmetry at one point and 2-fold at another one (or ditto in 3D with respect to parallel axes) implies rotation group p6, i.e. double translational symmetry and 6-fold rotational symmetry at some point (or, in 3D, parallel axis). The translation distance for the symmetry generated by one such pair of rotocenters is 2{{radic|3}} times their distance.

{| class=wikitable width=480
!Euclidean plane
!Hyperbolic plane
|- valign=top
|[[File:Tile V46b.svg|240px]]&lt;BR&gt;[[Hexakis triangular tiling]], an example of p6, [6,3]&lt;sup&gt;+&lt;/sup&gt;, (632) (with colors) and p6m, [6,3], (*632) (without colors); the lines  are reflection axes if colors are ignored, and a special kind of symmetry axis if colors are not ignored: reflection reverts the colors. Rectangular line grids in three orientations can be distinguished.
|[[File:Order-3 heptakis heptagonal tiling.png|240px]]&lt;BR&gt;[[Order 3-7 kisrhombille]], an example of [7,3]&lt;sup&gt;+&lt;/sup&gt; (732) symmetry and [7,3], (*732) (without colors)
|}

== See also ==
{{Div col|colwidth=22em}}
* [[Ambigram]]
* [[Axial symmetry]]
* [[Crystallographic restriction theorem]]
* [[Lorentz symmetry]]
* [[Point groups in three dimensions]]
* [[Screw axis]]
* [[Space group]]
* [[Translational symmetry]]
{{div col end}}

== References ==
{{reflist}}
*{{cite book |title=Symmetry |last=Weyl |first=Hermann |authorlink=Hermann Weyl |coauthors= |year=1982 |origyear=1952 |publisher=Princeton University Press |location=Princeton |isbn=0-691-02374-3 |pages= |url= |ref=Weyl 1982}}

== External links ==
* {{Commons category-inline|Rotational symmetry by order}}
*[http://www.mathsisfun.com/geometry/symmetry-rotational.html Rotational Symmetry Examples] from [[Math Is Fun]]

&lt;!--Categories--&gt;
[[Category:Rotational symmetry| ]]
[[Category:Symmetry]]
[[Category:Vision rivalry]]</text>
      <sha1>a9uu0pl0g2noe2g9rqs4c8anyoxvgpt</sha1>
    </revision>
  </page>
  <page>
    <title>Shapiro polynomials</title>
    <ns>0</ns>
    <id>10338711</id>
    <revision>
      <id>833450967</id>
      <parentid>741087968</parentid>
      <timestamp>2018-03-31T16:48:48Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <minor/>
      <comment>/* Construction */ wikify</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6246">In mathematics, the '''Shapiro polynomials''' are a [[polynomial sequence|sequence of polynomials]] which were first studied by [[Harold S. Shapiro]] in 1951 when considering the magnitude of specific [[trigonometric sum]]s.&lt;ref&gt;{{Cite journal|title=Note on the Shapiro polynomials|author=John Brillhart and L. Carlitz|journal= Proceedings of the American Mathematical Society|volume=25|date=May 1970|pages=114–118|doi=10.2307/2036537|issue= 1|publisher=Proceedings of the American Mathematical Society, Vol. 25, No. 1|postscript=&lt;!--None--&gt;|jstor=2036537}}&lt;/ref&gt; In [[signal processing]], the Shapiro polynomials have good [[autocorrelation]] properties&lt;ref&gt;{{Cite journal|url=http://ieeexplore.ieee.org/Xplore/login.jsp?url=/iel5/2220/4236720/04236729.pdf?arnumber=4236729|title=Binary sequences with good correlation properties|author=Somaini, U.|journal=Electronics Letters|volume=11|issue=13|date=June 26, 1975|pages=278–279|doi=10.1049/el:19750211|postscript=&lt;!--None--&gt;}}&lt;/ref&gt; and their values on the [[unit circle]] are small.  The first few members of the sequence are:

:&lt;math&gt;
\begin{align}
P_1(x) &amp; {} =1 + x \\
P_2(x) &amp; {} =1 + x + x^2 - x^3 \\
P_3(x) &amp; {} =1 + x + x^2 - x^3 + x^4 + x^5 - x^6 + x^7 \\
... \\
Q_1(x) &amp; {} =1 - x \\
Q_2(x) &amp; {} =1 + x - x^2 + x^3 \\
Q_3(x) &amp; {} =1 + x + x^2 - x^3 - x^4 - x^5 + x^6 - x^7 \\
... \\
\end{align}
&lt;/math&gt;

where the second sequence, indicated by ''Q'', is said to be ''complementary'' to the first sequence, indicated by ''P''.

==Construction==
The Shapiro polynomials ''P''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') may be constructed from the [[Rudin–Shapiro sequence|Golay–Rudin–Shapiro sequence]] ''a''&lt;sub&gt;''n''&lt;/sub&gt;, which  equals 1 if the number of pairs of consecutive ones in the binary expansion of ''n'' is even, and &amp;minus;1 otherwise. Thus ''a''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1,  ''a''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1, ''a''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1, ''a''&lt;sub&gt;3&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;&amp;minus;1, etc.

The first Shapiro ''P''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') is the partial sum of order 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1  (where ''n''&amp;nbsp;=&amp;nbsp;0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...) of the power series

:''f''(''z'') := ''a''&lt;sub&gt;0&lt;/sub&gt;  +  ''a''&lt;sub&gt;1&lt;/sub&gt;&amp;thinsp;''z''  +  a&lt;sub&gt;2&lt;/sub&gt;&amp;thinsp;''z''&lt;sup&gt;2&lt;/sup&gt;  +  ...

The Golay–Rudin–Shapiro sequence {''a''&lt;sub&gt;''n''&lt;/sub&gt;} has a fractal-like structure &amp;ndash; for example, ''a''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''a''&lt;sub&gt;2''n''&lt;/sub&gt; &amp;ndash;  which implies that the subsequence (''a''&lt;sub&gt;0&lt;/sub&gt;,&amp;nbsp;''a''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;''a''&lt;sub&gt;4&lt;/sub&gt;,&amp;nbsp;...) replicates the original sequence {''a''&lt;sub&gt;''n''&lt;/sub&gt;}. This in turn leads to remarkable
functional equations satisfied by ''f''(''z'').

The second or complementary Shapiro polynomials ''Q''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') may be defined in terms of this sequence, or by the relation ''Q''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') = (1-)&lt;sup&gt;''n''&lt;/sup&gt;''z''&lt;sup&gt;2&lt;sup&gt;''n''&lt;/sup&gt;-1&lt;/sup&gt;''P''&lt;sub&gt;''n''&lt;/sub&gt;(-1/''z''), or by the recursions

:&lt;math&gt;P_0(z)=1; ~~ Q_0(z) = 1 ; &lt;/math&gt;
:&lt;math&gt;P_{n+1}(z) = P_n(z) + z^{2^n} Q_n(z) ; &lt;/math&gt;
:&lt;math&gt;Q_{n+1}(z) = P_n(z) - z^{2^n} Q_n(z) . &lt;/math&gt;

==Properties==
[[File:Rudin shapiro 8 zeros.svg|thumbnail|right|Zeroes of the polynomial of degree 255]]
The sequence of complementary polynomials ''Q''&lt;sub&gt;''n''&lt;/sub&gt; corresponding to the ''P''&lt;sub&gt;''n''&lt;/sub&gt; is uniquely characterized by the following properties:
* (i) ''Q''&lt;sub&gt;''n''&lt;/sub&gt; is of degree 2&lt;sup&gt;''n''&lt;/sup&gt; &amp;minus; 1;
* (ii) the coefficients of ''Q''&lt;sub&gt;''n''&lt;/sub&gt; are all 1 or &amp;minus;1, and its constant term equals 1; and
* (iii) the identity  |''P''&lt;sub&gt;''n''&lt;/sub&gt;(''z'')|&lt;sup&gt;2&lt;/sup&gt;  +  |''Q''&lt;sub&gt;''n''&lt;/sub&gt;(''z'')|&lt;sup&gt;2&lt;/sup&gt;  =  2&lt;sup&gt;(''n''&amp;thinsp;+&amp;thinsp;1)&lt;/sup&gt; holds on the unit circle, where the complex variable ''z'' has absolute value one.

The most interesting property of the {''P''&lt;sub&gt;''n''&lt;/sub&gt;} is that the absolute value of ''P''&lt;sub&gt;''n''&lt;/sub&gt;(''z'') is bounded on the unit circle by the [[square root of 2]]&lt;sup&gt;(''n''&amp;thinsp;+&amp;thinsp;1)&lt;/sup&gt;, which is on the order
of the [[L2 norm|L&lt;sup&gt;2&lt;/sup&gt; norm]] of ''P''&lt;sub&gt;''n''&lt;/sub&gt;. Polynomials with coefficients from the set {&amp;minus;1,&amp;nbsp;1} whose maximum modulus on the unit circle is close to their mean modulus are useful for various applications in communication theory (e.g., antenna design and [[data compression]]).  Property (iii) shows that (''P'',&amp;nbsp;''Q'') form a [[Golay pair]].

These polynomials have further properties:&lt;ref&gt;{{cite journal | author=J. Brillhart |author2=J.S. Lomont |author3=P. Morton | title=Cyclotomic properties of the Rudin–Shapiro polynomials | journal=[[J. Reine Angew. Math.]] | volume=288 | year=1976 | pages=37–65 }}&lt;/ref&gt;
:&lt;math&gt; P_{n+1}(z) = P_n(z^2) + z P_n(-z^2) ; \, &lt;/math&gt;
:&lt;math&gt; Q_{n+1}(z) = Q_n(z^2) + z Q_n(-z^2) ; \, &lt;/math&gt;
:&lt;math&gt;P_n(z) P_n(1/z) + Q_n(z) Q_n(1/z) = 2^{n+1} ; \, &lt;/math&gt;
:&lt;math&gt;P_{n+k+1}(z) = P_n(z)P_k(z^{2^{n+1}}) + z^{2^n}Q_n(z)P_k(-z^{2^{n+1}}) ; \, &lt;/math&gt;
:&lt;math&gt;P_n(1) = 2^{\lfloor (n+1)/2 \rfloor}; {~}{~} P_n(-1) = (1+(-1)^n)2^{\lfloor n/2 \rfloor - 1} . \, &lt;/math&gt;

==See also==
* [[Littlewood polynomial]]s

==Notes==
{{reflist}}

==References==
*{{cite book|last = Borwein|first = Peter B|authorlink=Peter Borwein|title = Computational Excursions in Analysis and Number Theory|publisher = Springer|year = 2002|isbn = 0-387-95444-9|url = https://books.google.com/books?id=A_ITwN13J6YC|accessdate = 2007-03-30}} Chapter 4.
* {{cite book | zbl=0724.11010 | last=Mendès France | first=Michel | chapter=The Rudin-Shapiro sequence, Ising chain, and paperfolding | pages=367–390 | editor1-last=Berndt | editor1-first=Bruce C. | editor1-link=Bruce C. Berndt | editor2-last=Diamond | editor2-first=Harold G. | editor3-last=Halberstam | editor3-first=Heini | editor3-link=Heini Halberstam |display-editors = 3 | editor4-last=Hildebrand | editor4-first=Adolf | title=Analytic number theory. Proceedings of a conference in honor of Paul T. Bateman, held on April 25-27, 1989, at the University of Illinois, Urbana, IL (USA) | series=Progress in Mathematics | volume=85 | location=Boston | publisher=Birkhäuser | year=1990 | isbn=0-8176-3481-9 }}

[[Category:Fourier analysis]]
[[Category:Digital signal processing]]
[[Category:Polynomials]]</text>
      <sha1>k30s3jl7kc9unvklqm89k5bgzum2vud</sha1>
    </revision>
  </page>
  <page>
    <title>Simplex category</title>
    <ns>0</ns>
    <id>1028841</id>
    <revision>
      <id>856310124</id>
      <parentid>810061350</parentid>
      <timestamp>2018-08-24T09:44:46Z</timestamp>
      <contributor>
        <ip>2601:2C1:200:1BE0:9405:BE10:1828:2F1B</ip>
      </contributor>
      <comment>/* Augmented simplex category */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4057">In mathematics, the '''simplex category''' (or '''simplicial category''' or '''nonempty finite ordinal category''') is the [[category theory|category]] of non-empty finite [[ordinal number|ordinals]] and [[Monotonic function|order preserving maps]]. It is used to define [[simplicial set|simplicial]] and cosimplicial objects.

==Formal definition==

The '''simplex category''' is usually denoted by &lt;math&gt;\Delta&lt;/math&gt;. There are several equivalent descriptions of this category. &lt;math&gt;\Delta&lt;/math&gt; can be described as the category of ''non-empty finite ordinals'' as objects, thought of as totally ordered sets, and ''order-preserving functions'' as [[morphisms]]. The objects are commonly denoted &lt;math&gt; [n] = \{0, 1, \dots, n\} &lt;/math&gt; (so that &lt;math&gt; [n] &lt;/math&gt; is the ordinal &lt;math&gt; n+1 &lt;/math&gt;). The category is generated by coface and codegeneracy  maps, which amount to inserting or deleting elements of the orderings. (See [[simplicial set]] for relations of these maps.)

A [[simplicial object]] is a [[Presheaf (category theory)|presheaf]] on &lt;math&gt;\Delta&lt;/math&gt;, that is a contravariant functor from &lt;math&gt;\Delta&lt;/math&gt; to another category. For instance, [[simplicial set]]s are contravariant with the codomain category being the category of sets. A '''cosimplicial object''' is defined similarly as a covariant functor originating from &lt;math&gt;\Delta&lt;/math&gt;.

==Augmented simplex category==
The '''augmented simplex category''', denoted by &lt;math&gt;\Delta_+&lt;/math&gt; is the category of ''all finite ordinals and order-preserving maps'', thus &lt;math&gt;\Delta_+=\Delta\cup [-1]&lt;/math&gt;, where &lt;math&gt;[-1]=\emptyset&lt;/math&gt;. Accordingly, this category might also be denoted '''FinOrd'''. The augmented simplex category is occasionally referred to as algebraists' simplex category and the above version is called topologists' simplex category.

A contravariant functor defined on &lt;math&gt;\Delta_+&lt;/math&gt; is called an '''augmented simplicial object''' and a covariant functor out of &lt;math&gt;\Delta_+&lt;/math&gt; is called an '''augmented cosimplicial object'''; when the codomain category is the category of sets, for example, these are called augmented simplicial sets and augmented cosimplicial sets respectively.

The augmented simplex category, unlike the simplex category, admits a natural [[monoidal category|monoidal structure]]. The monoidal product is given by concatenation of linear orders, and the unit is the empty ordinal &lt;math&gt;[-1]&lt;/math&gt; (the lack of a unit prevents this from qualifying as a monoidal structure on &lt;math&gt;\Delta&lt;/math&gt;). In fact, &lt;math&gt;\Delta_+&lt;/math&gt; is the [[monoidal category]] freely generated by a single [[monoid object]], given by &lt;math&gt;[0]&lt;/math&gt; with the unique possible unit and multiplication. This description is useful for understanding how any [[comonoid]] object in a monoidal category gives rise to a simplicial object since it can then be viewed as the image of a functor from &lt;math&gt;\Delta_+^\text{op}&lt;/math&gt; to the monoidal category containing the comonoid; by forgetting the augmentation we obtain a simplicial object. Similarly, this also illuminates the construction of simplicial sets from [[Monad (category theory)|monads]] (and hence [[adjoint functors]]) since monads can be viewed as monoid objects in [[functor category|endofunctor categories]].

The augmented simplex category provides a simple example of a [[compact closed category]].

== See also ==

* [[Simplicial category (disambiguation)|Simplicial category]]
* [[PRO (category theory)]]
* [[Abstract simplicial complex]]

==References==

*P. G. Goerss and J. F. Jardine, ''Simplicial Homotopy Theory'', Progress in Mathematics Vol. 174, Birkhäuser Basel-Boston-Berlin (1999) {{isbn|3-7643-6064-X}}

==External links==
*{{nlab|id=simplex+category|title=Simplex category}}
*http://mathoverflow.net/questions/171920/whats-special-about-the-simplex-category

{{Category theory}}

[[Category:Algebraic topology]]
[[Category:Homotopy theory]]
[[Category:Simplicial sets| ]]
[[Category:Categories in category theory]]
[[Category:Free algebraic structures]]</text>
      <sha1>gme6igoidlfdyqo9n5upxbou6rr0jlw</sha1>
    </revision>
  </page>
  <page>
    <title>Symbols for zero</title>
    <ns>0</ns>
    <id>27875390</id>
    <revision>
      <id>847936540</id>
      <parentid>824608284</parentid>
      <timestamp>2018-06-28T19:52:18Z</timestamp>
      <contributor>
        <username>Ardub23</username>
        <id>13906297</id>
      </contributor>
      <minor/>
      <comment>/* See also */ Revised to use [[Template:Slink]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5807">The modern numerical digit [[0 (number)|0]] is usually written as a circle, an ellipse, or a rounded rectangle.

==Glyphs==
[[File:Text figures 036.svg|71px|left]]

In most modern [[typeface]]s, the height of the 0 character is the same as the other digits. However, in typefaces with [[text figures]], the character is often shorter ([[x-height]]).

[[File:Zero o comparison.svg|A comparison of the letter O and the number 0|right]]

Traditionally, many print typefaces made the capital letter [[O]] more rounded than the narrower, elliptical digit 0.&lt;ref name="bemer"/&gt; [[Typewriter]]s originally made no distinction in shape between O and 0; some models did not even have a separate key for the digit 0. The distinction came into prominence on modern character [[Visual display unit|displays]].&lt;ref name="bemer"/&gt;

The digit 0 with a dot in the centre seems to have originated as an option on [[IBM 3270]] displays. Its appearance has continued with [[Taligent]]'s command line typeface [[Andalé Mono]]. One variation used a short vertical bar instead of the dot. This could be confused with the [[Greek alphabet|Greek letter]] [[Theta]] on a badly focused display, but in practice there was no confusion because theta was not (then) a displayable character and very little used anyway.

An alternative, the [[slashed zero]] (looking similar to the letter O except for the slash), was primarily used in hand-written coding sheets before transcription to punched cards or tape, and is also used in old-style [[ASCII]] graphic sets descended from the default typewheel on the [[Teletype Model 33]] ASR. This form is similar to the symbol &lt;math&gt;\emptyset&lt;/math&gt;, or "∅" ([[Unicode]] character U+2205), representing the [[empty set]], as well as to the letter [[Ø]] used in several [[North Germanic languages|Scandinavian languages]]. Some [[Burroughs Corporation|Burroughs]]/[[Unisys]] equipment displays a digit 0 with a ''reversed'' slash.

The opposing convention that has the letter O ''with'' a slash and the digit 0 ''without'' was advocated by [[SHARE (computing)|SHARE]], a prominent [[IBM]] user group,&lt;ref name="bemer"/&gt; and recommended by IBM for writing [[Fortran|FORTRAN]] programs,&lt;ref name="einarsson"/&gt; and by a few other early mainframe makers; this is even more problematic for Scandinavians because it means two of their letters collide. Others advocated the opposite convention,&lt;ref name="bemer"/&gt; including IBM for writing [[Algol]] programs.&lt;ref name="einarsson"/&gt; Another convention used on some early [[line printer]]s left digit 0 unornamented but added a tail or hook to the capital O so that it resembled an inverted [[Q]] (like U+213A [[℺]]) or cursive capital letter-O (&lt;math&gt;\mathcal O&lt;/math&gt;).&lt;ref name="bemer"/&gt;

Some fonts designed for use with computers made one of the capital-O–digit-0 pair more rounded and the other more angular (closer to a rectangle). The [[Texas Instruments TI-99/4A]] computer featured a more angular capital O and a more rounded digit 0, whereas others made the choice the other way around.
[[File:Deutsches Kfz-Kennzeichen für Behördenfahrzeuge (Nummernbereich 3).jpg|thumb|German license plate with slit zeros]]

The typeface used on most European [[vehicle registration plate]]s distinguishes the two symbols partially in this manner (having a more rectangular or wider shape for the capital O than the digit 0), but in several countries a further distinction is made by slitting open the digit 0 on the upper right side (as in [[Vehicle registration plates of Germany|German plates]] using the ''[[FE-Schrift|fälschungserschwerende Schrift]]'', "forgery-impeding typeface").

Sometimes the digit 0 is used either exclusively, or not at all, to avoid confusion altogether. For example, confirmation numbers&lt;ref name="SW"/&gt; used by [[Southwest Airlines]] use only the capital letters O and I instead of the digits 0 and 1, while [[Canadian postal code]]s use only the digits 1 and 0 and never the capital letters O and I, although letters and numbers always alternate.

==Other==
{| align="right"
| [[File:7-segment cdeg.svg|80px|Unusual smaller appearance of zero on seven-segment displays]]
| [[File:7-segment abcdef.svg|80px|Usual appearance of zero on seven-segment displays]]
|}
On the [[seven-segment display]]s of calculators, watches, and household appliances, 0 is usually written with six line segments, though on some historical calculator models it was written with four line segments.

In [[Braille]], the numeral 0 has the same dot configuration as the letter [[J]].

[[File:ICS Zero.svg|thumb|[[International maritime signal flags|International maritime signal flag]] for 0]]

==See also==
*{{slink|Arabic numeral variations#Slashed zero}}
*{{slink|Regional handwriting variation#Arabic numerals}}

==References==
{{reflist|refs=
&lt;ref name="bemer"&gt;{{cite journal |author-first=Robert William |author-last=Bemer |author-link=Robert William Bemer |title=Towards standards for handwritten zero and oh: much ado about nothing (and a letter), or a partial dossier on distinguishing between handwritten zero and oh |journal=Communications of the ACM |volume=10 |issue=8 |date=August 1967 |pages=513–518 |doi=10.1145/363534.363563}}&lt;/ref&gt;
&lt;ref name="einarsson"&gt;{{cite web |author-first1=Bo |author-last1=Einarsson |author-first2=Yurij |author-last2=Shokin |title=Fortran 90 for the Fortran 77 Programmer |url=http://www.nsc.liu.se/~boein/f77to90/a7.html |at=Appendix 7: "The historical development of Fortran |date=2007-05-24 |dead-url=no |archive-url=https://web.archive.org/web/20170228230542/https://www.nsc.liu.se/~boein/f77to90/a7.html |archive-date=2017-02-28}}&lt;/ref&gt;
&lt;ref name="SW"&gt;http://southwest.com/content/travel_center/retrieveCheckinDoc.html&lt;/ref&gt; 
}}

[[Category:0 (number)]]
[[Category:Mathematical symbols]]</text>
      <sha1>escyzusw8ld27t4qx16akbj8cm827m8</sha1>
    </revision>
  </page>
  <page>
    <title>Triangular bipyramid</title>
    <ns>0</ns>
    <id>646933</id>
    <revision>
      <id>843317683</id>
      <parentid>843285714</parentid>
      <timestamp>2018-05-28T10:12:49Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <comment>Undid revision 843285714 by [[Special:Contributions/43.245.44.173|43.245.44.173]] ([[User talk:43.245.44.173|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4538">{{for|the related molecular geometrical structure|Trigonal bipyramid molecular geometry}}
{{Infobox face-uniform polyhedron
| Image_File      = Triangular bipyramid.png
| Polyhedron_Type = [[Bipyramid]]&lt;BR&gt;and&lt;BR&gt;[[Johnson solid|Johnson]]&lt;br&gt;[[gyroelongated pentagonal pyramid|J&lt;sub&gt;11&lt;/sub&gt;]] -''' J&lt;sub&gt;12&lt;/sub&gt;''' - [[Pentagonal bipyramid|J&lt;sub&gt;13&lt;/sub&gt;]]
| Coxeter={{CDD|node_f1|2x|node_f1|3|node}}
| Schläfli = { } + {3}
| Face_List       = 6 [[triangle]]s
| Edge_Count      = 9
| Vertex_Count    = 5
| Symmetry_Group  = ''D''&lt;sub&gt;''3h''&lt;/sub&gt;, [3,2], (*223) order 12
| Rotation_Group  = ''D''&lt;sub&gt;''3''&lt;/sub&gt;, [3,2]&lt;sup&gt;+&lt;/sup&gt;, (223), order 6
| Face_Type       = V3.4.4
| Dual            = [[Triangular prism]]
| Property_List   = [[convex set|Convex]], [[face-transitive]]
}}
[[File:Johnson solid 12 net.png|thumb|Net]]
In [[geometry]], the '''triangular [[bipyramid]]''' (or '''dipyramid''') is a type of [[hexahedron]], being the first in the infinite set of [[face-transitive]] bipyramids. It is the [[Dual polyhedron|dual]] of the [[triangular prism]] with 6 isosceles triangle faces.

As the name suggests, it can be constructed by joining two [[tetrahedron|tetrahedra]] along one face. Although all its faces are [[congruence (geometry)|congruent]] and the solid is [[face-transitive]], it is not a [[Platonic solid]] because some [[vertex (geometry)|vertices]] adjoin three faces and others adjoin four.

The bipyramid whose six faces are all [[equilateral triangle]]s is one of the [[Johnson solid]]s, (''J''&lt;sub&gt;12&lt;/sub&gt;). {{Johnson solid}}  As a Johnson solid with all faces equilateral triangles, it is also a [[deltahedron]].

[[Image:Triangular dipyramid.png|250px]]

== Dual polyhedron ==
The dual polyhedron of the triangular bipyramid is the [[triangular prism]], with five faces: two parallel equilateral triangles linked by a chain of three rectangles.
Although the triangular prism has a form that is a uniform polyhedron (with square faces), the dual of the Johnson solid form of the bipyramid has rectangular rather than square faces, and is not uniform.
{| class=wikitable width=320
|- valign=top
!Dual triangular bipyramid 
!Net of dual
|- valign=top
|[[File:Dual triangular dipyramid.png|160px]]
|[[File:Dual triangular dipyramid net.png|160px]]
|}

== Related polyhedra and honeycombs==
The ''triangular bipyramid'', dt{2,3}, can be in sequence [[rectification (geometry)|rectified]], rdt{2,3}, [[truncation (geometry)|truncated]], trdt{2,3} and alternated ([[Snub (geometry)|snubbed]]), srdt{2,3}:
:[[File:Snub rectified triangular bipyramid sequence.png|480px]]

The ''triangular bipyramid'' can be constructed by [[Augmentation (geometry)|augmentation]] of smaller ones, specifically two stacked regular [[octahedra]] with 3 triangular bipyramids added around the sides, and 1 tetrahedron above and below. This polyhedron has 24 [[equilateral triangle]] faces, but it is not a [[Johnson solid]] because it has coplanar faces. It is a coplanar 24-triangle [[Deltahedron#Non-strictly convex cases|deltahedron]]. This polyhedron exists as the augmentation of cells in a [[gyrated alternated cubic honeycomb]]. Larger triangular polyhedra can be generated similarly, like 9, 16 or 25 triangles per larger triangle face, seen as a section of a [[triangular tiling]].
:[[File:Triangulated bipyramid.png|120px]]

The triangular bipyramid can form a [[tessellation of space]] with [[Octahedron|octahedra]] or with [[Truncated tetrahedron|truncated tetrahedra]].&lt;ref&gt;http://woodenpolyhedra.web.fc2.com/J12.html&lt;/ref&gt;

{| class=wikitable width=480
|[[File:Tetrahedral-truncated tetrahedral honeycomb slab.png|240px]]&lt;BR&gt;Layers of the uniform [[quarter cubic honeycomb]] can be shifted to pair up regular tetrahedral cells which combined into triangular bipyramids.
|[[File:Tetroctahedric semicheck.png|240px]]&lt;BR&gt;The [[Tetrahedral-octahedral honeycomb#Construction by alternation|gyrated tetrahedral-octahedral honeycomb]] has pairs of adjacent regular tetrahedra that can be seen as triangular bipyramids.
|}

== See also==
* [[Trigonal bipyramidal molecular geometry]]

{{Bipyramids}}

==References==
{{Reflist}}

==External links==
* {{mathworld2 |urlname2=JohnsonSolid |title2=Johnson solid|urlname=TriangularDipyramid |title=Triangular dipyramid}}
*[http://www.georgehart.com/virtual-polyhedra/conway_notation.html Conway Notation for Polyhedra] Try: dP3

{{Johnson solids navigator}}

[[Category:Johnson solids]]
[[Category:Deltahedra]]
[[Category:Pyramids and bipyramids]]
[[Category:Molecular geometry]]</text>
      <sha1>azwosr6risjwdeu7f6bnsjnwp71vvko</sha1>
    </revision>
  </page>
  <page>
    <title>USC-Lockheed Martin Quantum Computation Center</title>
    <ns>0</ns>
    <id>46411525</id>
    <revision>
      <id>861409280</id>
      <parentid>850149502</parentid>
      <timestamp>2018-09-27T06:03:31Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>clean up, replaced: European Physics Journal → European Physical Journal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9754">The '''USC-Lockheed Martin Quantum Computation Center''' (QCC) is a joint scientific research effort between [[Lockheed Martin]] Corporation and the University of Southern California (USC). The QCC is housed at the Information Sciences Institute (ISI), a computer science and engineering research unit of the USC Viterbi School of Engineering, and is jointly operated by ISI and Lockheed Martin.

USC faculty, ISI researchers and students are performing basic and applied research into quantum computing, and are collaborating with researchers around the world. The QCC uses a D-Wave Two quantum annealing system, manufactured by [[D-Wave Systems]], Inc.&lt;ref&gt;{{cite web|url=https://www.forbes.com/sites/alexknapp/2015/01/29/quantum-computing-company-d-wave-raises-29-million/|title=Quantum Computing Company D-Wave Raises $29 Million CAD|author=Alex Knapp|date=29 January 2015|work=Forbes}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.inc.com/will-bourne/d-waves-dream-machine.html|title=D-Wave's Dream Machine|work=Inc.com}}&lt;/ref&gt; The QCC is the first organization outside of D-Wave to operate the system.&lt;ref&gt;{{cite web|url=https://www.washingtonpost.com/business/on-it/can-quantum-computing-change-the-world-this-start-up-is-betting-on-it/2015/05/03/e4681b48-ecfe-11e4-a55f-38924fca94f9_story.html|title=Can quantum computing change the world? This start-up is betting on it.|work=Washington Post}}&lt;/ref&gt; The second system is installed at [[NASA]] [[Ames Research Center]],&lt;ref&gt;{{cite web|url=http://www.nas.nasa.gov/quantum/|title=QuAIL|work=nasa.gov|deadurl=yes|archiveurl=https://web.archive.org/web/20150310044853/http://www.nas.nasa.gov/quantum/|archivedate=2015-03-10|df=}}&lt;/ref&gt; and is operated jointly by NASA and Google.&lt;ref&gt;{{cite web|url=https://www.wired.com/2014/05/quantum-computing|title=The Revolutionary Quantum Computer That May Not Be Quantum at All|date=20 May 2014|work=WIRED}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.nature.com/news/google-and-nasa-snap-up-quantum-computer-1.12999|title=Google and NASA snap up quantum computer|work=Nature News &amp; Comment}}&lt;/ref&gt; The systems must be kept extremely cold and electromagnetically well-shielded to operate with the longest possible coherence time.

==Purpose==

Quantum information processing, also called [[quantum computing]], theoretically is known to offer dramatic speed-ups and more complete answers for some combinatorial computing problems. [[Quantum annealing]] is a branch of quantum computing whose advantages over classical computing are actively being investigated.&lt;ref&gt;{{cite web|url=http://www.isgtw.org/spotlight/world%E2%80%99s-first-quantum-computer-indeed|title=World’s first quantum computer indeed|work=isgtw.org}}&lt;/ref&gt; In quantum annealing, problems are encoded into the lowest energy state of a physical quantum system. Applications currently under study at the QCC include big data analysis, verification and validation of cyber-physical systems, pattern identification and classification, and optimization and machine learning, any of which may support breakthroughs in multiple industries and government.&lt;ref&gt;{{cite web|url=https://www.washingtonpost.com/world/national-security/nsa-seeks-to-build-quantum-computer-that-could-crack-most-types-of-encryption/2014/01/02/8fff297e-7195-11e3-8def-a33011492df2_story.html|title=NSA seeks to build quantum computer that could crack most types of encryption|work=Washington Post}}&lt;/ref&gt;

USC and ISI researchers, as well as Lockheed Martin engineers, seek to develop methods to benchmark quantum annealers,&lt;ref&gt;"Experimental quantum annealing: case study involving the graph isomorphism problem", arXiv:1503.06453, by K.M. Zick, O. Shehab, and M. French.&lt;/ref&gt; and perform tests of quantumness.&lt;ref name=reexamining&gt;"Reexamining classical and quantum models for the D-Wave One processor", The European Physical Journal, Special Topics 224, 111 (special issue on quantum annealing) (2015), by T. Albash, T. Ronnow, M. Troyer, D.A. Lidar.&lt;/ref&gt; These include the study of quantum entanglement&lt;ref&gt;"Entanglement in a quantum annealing processor", Phys. Rev. X 4, 021041, by T. Lanting, A.J. Przybysz, A. Yu. Smirnov, F.M. Spedalieri, M.H. Amin, A.J. Berkley, R. Harris, F. Altomare, S. Boixo, P. Bunyk, N. Dickson, C. Enderud, J.P. Hilton, E. Hoskinson, M.W. Johnson, E. Ladizinsky, N. Ladizinsky, R. Neufeld, T. Oh, I. Perminov, C. Rich, M.C. Thom, E. Tolkacheva, S. Uchaikin, A.B. Wilson and G. Rose.&lt;/ref&gt; and, more generally, the performance of quantum annealing experiments.&lt;ref&gt;{{cite web|url=http://www.popsci.com/article/newest-strictest-test-quantum-computer-yet?dom=PSC&amp;loc=topstories&amp;con=the-newest-strictest-test-of-a-quantum-computer-yet|title=The Newest, Strictest Test Of A Quantum Computer Yet|work=Popular Science}}&lt;/ref&gt;

Researchers also are working to manage [[quantum decoherence]], the phenomenon that degrades the performance of quantum information processors when quantum states are forced out of [[quantum superposition]]. Decoherence can reduce quantum functionality to that of a classical computer, and can be counteracted using [[quantum error correction]].&lt;ref&gt;"Quantum Error Correction", by D.A. Lidar and T.A. Brun (editors), Cambridge University Press (2013).&lt;/ref&gt; QCC researchers and their collaborators have developed methods to counteract decoherence in quantum annealers by combining quantum error correction with energy penalties that suppress decoherence into a single quantum annealing correction method.&lt;ref name=error&gt;"Error-Corrected Quantum Annealing with Hundreds of Qubits", Nature Communications 5, 3243 (2014), by K. Pudenz, T. Albash, and D. Lidar.&lt;/ref&gt;&lt;ref name=adiabatic&gt;"Adiabatic Quantum Optimization with the Wrong Hamiltonian", Phys. Rev. A 88, 062314 (2013), by K.C. Young, R. Blume-Kohout, D.A. Lidar.&lt;/ref&gt;&lt;ref name=annealing&gt;"Quantum Annealing Correction for Random Ising Problems", Phys. Rev. A 91, 042302 (2015), by K. Pudenz, T. Albash, and D. Lidar.&lt;/ref&gt;

==History==

The QCC was launched in November, 2011 under the leadership of Scientific and Technical Director [[Daniel Lidar]], a USC professor of electrical engineering, chemistry and physics; Operational Director  Robert F. Lucas,&lt;ref&gt;{{cite web|url=http://www.isi.edu/about/bio/robert_f_lucas/|title=Information Sciences Institute – Robert F. Lucas, Ph.D.|work=isi.edu}}&lt;/ref&gt; director of ISI’s Computational Systems and Technology division; and Ned Allen and Greg Tallant of Lockheed Martin. The QCC began with a 128-qubit D-Wave One,&lt;ref&gt;{{cite web|url=https://www.forbes.com/sites/alexknapp/2011/10/31/lockheed-martin-installs-quantum-computer/|title=Lockheed Martin Installs Quantum Computer|author=Alex Knapp|date=31 October 2011|work=Forbes}}&lt;/ref&gt; which was replaced in March 2013 with the 512-qubit D-Wave Two.&lt;ref&gt;{{cite web|url=http://www.dwavesys.com/our-company/customers/|title=Customers|work=dwavesys.com}}&lt;/ref&gt;

==Research==

Research initially focused on testing whether the D-Wave is in fact a quantum system,&lt;ref&gt;http://bits.blogs.nytimes.com/2014/03/24/quantum-computing-research-may-back-controversial-company/?_php=true&amp;_type=blogs&amp;_r=2&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://spectrum.ieee.org/tech-talk/computing/hardware/scientists-confirm-dwave-computer-chips-compute-using-quantum-mechanics|title=Scientists Confirm D-Wave|author=Jeremy Hsu|work=ieee.org}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.wired.com/2013/06/d-wave-quantum-computer-usc/|title=Google's Quantum Computer Proven To Be Real Thing (Almost) – WIRED|date=28 June 2013|work=WIRED}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.eurekalert.org/pub_releases/2014-03/uosc-sqd030514.php|title=Seeking quantum-ness: D-Wave chip passes rigorous tests|date=5 March 2014|work=EurekAlert!}}&lt;/ref&gt; and has expanded to benchmarking the D-Wave against classical algorithms,&lt;ref&gt;{{cite web|url=https://www.sciencenews.org/article/commercial-quantum-computer-fails-impress-new-test&gt;|title=Search Content|work=Science News}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.lemonde.fr/sciences/article/2014/06/23/l-ordinateur-quantique-au-banc-d-essai_4443793_1650684.html|title=L’ordinateur quantique au banc d’essai|author=Denis Delbecq|work=Le Monde.fr}}&lt;/ref&gt; and various applications, including [[quantum machine learning]].&lt;ref&gt;{{cite web|url=http://www.truthdig.com/report/item/quantum_computers_are_coming_20141023|title=Thor Benson: Quantum Computers Are Coming, and Here’s How to Process That Information – Truthdig|work=Truthdig}}&lt;/ref&gt; Lockheed Martin researchers have focused on the application of adiabatic quantum computing to the problem of verification and validation of control systems and other tasks with similar mathematical structure, such as the design of special wave forms for RF applications with minimal side-lobes.

==People==
The team includes more than a dozen USC faculty members, ISI researchers, postdoctoral and graduate students, and more than 100 Lockheed Martin users.

==Location==
USC is located in downtown [[Los Angeles]]. ISI is located in [[Marina del Rey, California]]. Lockheed Martin headquarters is located in [[Bethesda, Maryland]]. D-Wave is located in Burnaby, [[British Columbia]], [[Canada]].

==References==
{{reflist|30em}}

==External links==
*{{URL|isi.edu}}
*{{URL|usc.edu}}
*{{URL|dwavesys.com}}

{{coord|33.980295|-118.440003|type:edu_globe:earth_region:US-CA|display=title}}

[[Category:Centers of the University of Southern California]]
[[Category:Computer science institutes in the United States]]
[[Category:Lockheed Martin]]
[[Category:Quantum information science]]
[[Category:Research institutes in California]]
[[Category:Research institutes established in 2011]]
[[Category:2011 establishments in California]]
[[Category:Science and technology in the Greater Los Angeles Area]]</text>
      <sha1>6jybxx6ji8plvt5elnafm6dv2drthcq</sha1>
    </revision>
  </page>
  <page>
    <title>Unary language</title>
    <ns>0</ns>
    <id>12769341</id>
    <revision>
      <id>768992437</id>
      <parentid>768992367</parentid>
      <timestamp>2017-03-06T23:03:55Z</timestamp>
      <contributor>
        <ip>24.85.232.10</ip>
      </contributor>
      <comment>/* Relationships to other complexity classes */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4150">In [[computational complexity theory]], a '''unary language''' or '''tally language''' is a [[formal language]] (a set of [[string (computer science)|strings]]) where all strings have the form 1&lt;sup&gt;''k''&lt;/sup&gt;, where "1" can be any fixed symbol. For example, the language {1, 111, 1111} is unary, as is the language {1&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;|&amp;nbsp;''k'' is [[prime number|prime]]}. The [[complexity class]] of all such languages is sometimes called '''TALLY'''.

The name "unary" comes from the fact that a unary language is the encoding of a set of [[natural number]]s in the [[unary numeral system]]. Since the universe of strings over any finite alphabet is a [[countable set]], every language can be mapped to a unique set A of natural numbers; thus, every language has a ''unary version'' {1&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;|&amp;nbsp;''k'' in A}. Conversely, every unary language has a more compact binary version, the set of binary encodings of natural numbers ''k'' such that 1&lt;sup&gt;''k''&lt;/sup&gt; is in the language.

Since complexity is usually measured in terms of the length of the input string, the unary version of a language can be "easier" than the original language. For example, if a language can be recognized in O(2&lt;sup&gt;''n''&lt;/sup&gt;) time, its unary version can be recognized in O(''n'') time, because ''n'' has become exponentially larger. More generally, if a language can be recognized in O(f(''n'')) time and O(g(''n'')) space, its unary version can be recognized in O(''n'' + f(log ''n'')) time and O(g(log ''n'')) space (we require O(''n'') time just to read the input string). However, if membership in a language is [[Recursive language|undecidable]], then membership in its unary version is also undecidable.

== Relationships to other complexity classes ==

'''TALLY''' is contained in '''[[P/poly]]'''—the class of languages that can be recognized in polynomial time given an advice function that depends only on the input length. In this case, the required advice function is very simple—it returns a single bit for each input length ''k'' specifying whether 1&lt;sup&gt;''k''&lt;/sup&gt; is in the language or not.

A unary language is necessarily a [[sparse language]], since for each ''n'' it contains at most one value of length ''n'' and at most ''n'' values of length at most ''n'', but not all sparse languages are unary; thus '''TALLY''' is contained in '''SPARSE'''.

If there exists a unary language that is [[NP-complete]], then [[P = NP problem|P = NP]].&lt;ref&gt;Piotr Berman. Relationship between density and deterministic complexity of NP-complete languages. In ''Proceedings of the 5th Conference on Automata, Languages and Programming'', pp.63&amp;ndash;71. Springer-Verlag. ''Lecture Notes in Computer Science #62''. 1978.&lt;/ref&gt;

This result can be extended to sparse languages.&lt;ref&gt;S. R. Mahaney. Sparse complete sets for NP: Solution of a conjecture by Berman and Hartmanis. ''Journal of Computer and System Sciences'' 25:130-143. 1982.&lt;/ref&gt;

If ''L'' is a unary language, then ''L*'' (the [[Kleene star]] of ''L'') is a [[regular language]].&lt;ref&gt;{{cite web|first1=Patrick|last1=-|title=Kleene star of an infinite unary language always yields a regular language|url=http://cs.stackexchange.com/a/21775/1342|website=Computer Science Stack Exchange|accessdate=19 October 2014}}&lt;/ref&gt;

== Tally classes ==

The complexity class P&lt;sub&gt;1&lt;/sub&gt; is the class of the unary languages that can be recognized by a polynomial time Turing machine (given its input written in unary); it is the analogue of the class [[P (class)|P]]. The analogue of [[NP (class)|NP]] in the unary setting is NP&lt;sub&gt;1&lt;/sub&gt;. A [[counting class]] #P&lt;sub&gt;1&lt;/sub&gt;, the analogue of [[Sharp-P|#P]], is also known.&lt;ref&gt;[[Leslie Valiant]], ''The Complexity of Enumeration and Reliability Problems'', [http://epubs.siam.org/doi/abs/10.1137/0208032] {{Closed access}}&lt;/ref&gt;

== References ==

===Notes===
{{reflist}}

===General references===
* Lance Fortnow. Favorite Theorems: Small Sets. April 18, 2006. http://weblog.fortnow.com/2006/04/favorite-theorems-small-sets.html
* {{CZoo|TALLY|T#tally}}

[[Category:Formal languages]]
[[Category:Computational complexity theory]]</text>
      <sha1>d4fetzezm49dxq0k70crnxgntbk7n6r</sha1>
    </revision>
  </page>
  <page>
    <title>Variance</title>
    <ns>0</ns>
    <id>32344</id>
    <revision>
      <id>869152748</id>
      <parentid>869152392</parentid>
      <timestamp>2018-11-16T19:05:16Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* Distribution of the sample variance */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51396">{{About|the mathematical concept|other uses|Variance (disambiguation)}}
[[File:Comparison standard deviations.svg|thumb|400px|right|Example of samples from two populations with the same mean but different variances. The red population has mean 100 and variance 100 (SD=10) while the blue population has mean 100 and variance 2500 (SD=50).]]{{Inline citations|date=November 2018}}
In [[probability theory]] and [[statistics]], '''variance''' is the [[expected value|expectation]] of the squared [[Deviation (statistics)|deviation]] of a [[random variable]] from its [[Expected value|mean]].  Informally, it measures how far a set of (random) numbers are spread out from their average value. Variance has a central role in statistics, where some ideas that use it include [[descriptive statistics]], [[statistical inference]], [[hypothesis testing]], [[goodness of fit]], and [[Monte Carlo method|Monte Carlo sampling]]. Variance is an important tool in the sciences, where statistical analysis of data is common. The variance is the square of the [[standard deviation]], the second [[central moment]] of a distribution, and the [[covariance]] of the random variable with itself, and it is often represented by &lt;math&gt;\sigma^2&lt;/math&gt;, &lt;math&gt;s^2&lt;/math&gt;, or &lt;math&gt;\operatorname{Var}(X)&lt;/math&gt;.

{{TOC limit}}

==Definition==
The variance of a random variable &lt;math&gt;X&lt;/math&gt; is the [[expected value]] of the squared deviation from the [[Expected value|mean]] of &lt;math&gt;X&lt;/math&gt;, &lt;math&gt;\mu = \operatorname{E}[X]&lt;/math&gt;:
: &lt;math&gt; \operatorname{Var}(X) = \operatorname{E}\left[(X - \mu)^2 \right]. &lt;/math&gt;
This definition encompasses random variables that are generated by processes that are [[discrete random variable|discrete]], [[continuous random variable|continuous]], [[Cantor distribution|neither]], or mixed. The variance can also be thought of as the [[covariance]] of a random variable with itself:
: &lt;math&gt;\operatorname{Var}(X) = \operatorname{Cov}(X, X).&lt;/math&gt; 
The variance is also equivalent to the second [[cumulant]] of a probability distribution that generates &lt;math&gt;X&lt;/math&gt;. The variance is typically designated as &lt;math&gt;\operatorname{Var}(X)&lt;/math&gt;, &lt;math&gt;\sigma^2_X&lt;/math&gt;, or simply &lt;math&gt;\sigma^2&lt;/math&gt; (pronounced "[[sigma]] squared"). The expression for the variance can be expanded:
:&lt;math&gt;\begin{align}
\operatorname{Var}(X) &amp;= \operatorname{E}\left[(X - \operatorname{E}[X])^2\right] \\[4pt]
&amp;= \operatorname{E}\left[X^2 - 2X\operatorname{E}[X] + \operatorname{E}[X]^2\right] \\[4pt]
&amp;= \operatorname{E}\left[X^2\right] - 2\operatorname{E}[X]\operatorname{E}[X] + \operatorname{E}[X]^2 \\[4pt]
&amp;= \operatorname{E}\left[X^2 \right] - \operatorname{E}[X]^2
\end{align}&lt;/math&gt;

In other words, the variance of {{mvar|X}} is equal to the mean of the square of {{mvar|X}} minus the square of the mean of {{mvar|X}}.  This equation should not be used for computations using [[floating point arithmetic]] because it suffers from [[catastrophic cancellation]] if the two components of the equation are similar in magnitude. There exist [[Algorithms for calculating variance|numerically stable alternatives]].

===Discrete random variable===

If the generator of random variable &lt;math&gt;X&lt;/math&gt; is [[Discrete probability distribution|discrete]] with [[probability mass function]] &lt;math&gt;x_1 \mapsto p_1, x_2 \mapsto p_2, \ldots, x_n \mapsto p_n&lt;/math&gt; then

:&lt;math&gt;\operatorname{Var}(X) = \sum_{i=1}^n p_i\cdot(x_i - \mu)^2,&lt;/math&gt;

or equivalently

:&lt;math&gt;\operatorname{Var}(X) = \left(\sum_{i=1}^n p_i x_i ^2\right) - \mu^2,&lt;/math&gt;

where &lt;math&gt;\mu&lt;/math&gt; is the average value, i.e.

:&lt;math&gt;\mu = \sum_{i=1}^n p_i x_i. &lt;/math&gt;

(When such a discrete [[weighted variance]] is specified by weights whose sum is not&amp;nbsp;1, then one divides by the sum of the weights.)

The variance of a set of &lt;math&gt;n&lt;/math&gt; equally likely values can be written as 

:&lt;math&gt; \operatorname{Var}(X) = \frac{1}{n} \sum_{i=1}^n (x_i - \mu)^2, &lt;/math&gt;

where &lt;math&gt;\mu&lt;/math&gt; is the expected value, i.e.,

:&lt;math&gt;\mu = \frac{1}{n}\sum_{i=1}^n x_i .&lt;/math&gt;

The variance of a set of &lt;math&gt;n&lt;/math&gt; equally likely values can be equivalently expressed, without directly referring to the mean, in terms of squared deviations of all points from each other:&lt;ref&gt;{{cite conference|authors=Yuli Zhang, Huaiyu Wu, Lei Cheng|date=June 2012|title=Some new deformation formulas about variance and covariance|conference=Proceedings of 4th International Conference on Modelling, Identification and Control(ICMIC2012)|pages=987–992}}&lt;/ref&gt; 

:&lt;math&gt; \operatorname{Var}(X) = \frac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n \frac{1}{2}(x_i - x_j)^2 = \frac{1}{n^2}\sum_i \sum_{j&gt;i} (x_i-x_j)^2. &lt;/math&gt;

===Continuous random variable===

If the random variable &lt;math&gt;X&lt;/math&gt; represents samples generated by a [[continuous distribution]] with [[probability density function]] &lt;math&gt;f(x)&lt;/math&gt;, and &lt;math&gt;F(x)&lt;/math&gt; is the corresponding [[cumulative distribution function]], then the population variance is given by

:&lt;math&gt;\begin{align}
   \operatorname{Var}(X) = \sigma^2 &amp;= \int (x-\mu)^2 f(x) \, dx \\[4pt]
     &amp;= \int x^2f(x)\,dx -2\mu\int xf(x)\,dx + \int \mu^2 f(x)\,dx \\[4pt]
     &amp;= \int x^2 \,dF(x) - 2 \mu \int x \,dF(x) + \mu^2 \int \,dF(x) \\[4pt]
     &amp;= \int x^2 \,dF(x) - 2 \mu \cdot \mu + \mu^2 \cdot 1 \\[4pt]
     &amp;= \int x^2 \,dF(x) - \mu^2,
 \end{align}&lt;/math&gt;

or equivalently and conventionally, 

:&lt;math&gt;\operatorname{Var}(X) = \int x^2 f(x) \,dx - \mu^2 ,&lt;/math&gt;

where &lt;math&gt;\mu&lt;/math&gt; is the expected value of &lt;math&gt;X&lt;/math&gt; given by

:&lt;math&gt;\mu = \int x f(x) \, dx = \int x \, d F(x), &lt;/math&gt;

with the integrals being [[definite integral]]s taken for &lt;math&gt;x&lt;/math&gt; ranging over the range of &lt;math&gt;X.&lt;/math&gt;

If a continuous distribution does not have a finite expected value, as is the case for the [[Cauchy distribution]], it does not have a variance either. Many other distributions for which the expected value does exist also do not have a finite variance because the integral in the variance definition diverges. An example is a [[Pareto distribution]] whose [[Pareto index|index]] &lt;math&gt;k&lt;/math&gt; satisfies &lt;math&gt;1 &lt; k \leq 2.&lt;/math&gt;

==Examples==

===Normal distribution===
The [[normal distribution]] with parameters &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\sigma&lt;/math&gt; is a continuous distribution whose [[probability density function]] is given by
:&lt;math&gt;
f(x) = \frac{1}{\sqrt{2\pi \sigma^2}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} }.
&lt;/math&gt;
In this distribution, &lt;math&gt;\operatorname{E}[X] = \mu &lt;/math&gt; and the variance &lt;math&gt;\operatorname{Var}(X)&lt;/math&gt; is related with &lt;math&gt;\sigma&lt;/math&gt; via
:&lt;math&gt;
\operatorname{Var}(X) = \int_{-\infty}^\infty \frac{x^2}{\sqrt{2\pi \sigma^2}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} } \, dx - \mu^2 = \sigma^2.
&lt;/math&gt;
The role of the normal distribution in the [[central limit theorem]] is in part responsible for the prevalence of the variance in probability and statistics.

===Exponential distribution===
The [[exponential distribution]] with parameter &lt;math&gt;\lambda&lt;/math&gt; is a continuous distribution whose support is the semi-infinite interval &lt;math&gt;[0, \infty)&lt;/math&gt;. Its [[probability density function]] is given by

:&lt;math&gt;f(x) = \lambda e^{-\lambda x}&lt;/math&gt;

and it has expected value &lt;math&gt;\mu = \lambda^{-1}&lt;/math&gt;. The variance is equal to

:&lt;math&gt;\operatorname{Var}(X) = \int_0^\infty x^2 \lambda e^{-\lambda x} \, dx - \mu^2 = \lambda^{-2}.&lt;/math&gt;

So for an exponentially distributed random variable, &lt;math&gt;\sigma^2 = \mu^2.&lt;/math&gt;

===Poisson distribution===
The [[Poisson distribution]] with parameter &lt;math&gt;\lambda&lt;/math&gt; is a discrete distribution for &lt;math&gt;k = 0, 1, 2, \ldots&lt;/math&gt;. Its [[probability mass function]] is given by

:&lt;math&gt;p(k) = \frac{\lambda^k}{k!} e^{-\lambda},&lt;/math&gt;

and it has expected value &lt;math&gt;\mu = \lambda&lt;/math&gt;. The variance is equal to

:&lt;math&gt; \operatorname{Var}(X) = \left(\sum_{k=0}^\infty k^2 \frac{\lambda^k}{k!} e^{-\lambda}\right) - \mu^2 = \lambda,&lt;/math&gt;

So for a Poisson-distributed random variable, &lt;math&gt;\sigma^2 = \mu&lt;/math&gt;.

===Binomial distribution===
The [[binomial distribution]] with parameters &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; is a discrete distribution for &lt;math&gt;k = 0, 1, 2, \ldots, n&lt;/math&gt;. Its [[probability mass function]] is given by
:&lt;math&gt;p(k) = {n\choose k}p^k(1-p)^{n-k},&lt;/math&gt;
and it has expected value &lt;math&gt;\mu = np&lt;/math&gt;. The variance is equal to
:&lt;math&gt; \operatorname{Var}(X) = \left(\sum_{k=0}^n k^2 {n\choose k}p^k(1-p)^{n-k}\right) - \mu^2 = np(1-p).&lt;/math&gt;

As a simple example, the binomial distribution with &lt;math&gt;p=1/2&lt;/math&gt; describes the probability of getting &lt;math&gt;k&lt;/math&gt; heads in &lt;math&gt;n&lt;/math&gt; tosses of a fair coin.  Thus the expected value of the number of heads is &lt;math alt="n/2"&gt;n/2,&lt;/math&gt; and the variance is &lt;math alt="n/4"&gt;n/4.&lt;/math&gt;

===Fair die&lt;!--Singular: die; plural: dice. Don't change--&gt;===
A fair [[dice|six-sided die]] can be modeled as a discrete random variable, {{mvar|X}}, with outcomes 1 through 6, each with equal probability 1/6.  The expected value of {{mvar|X}} is &lt;math&gt;(1 + 2 + 3 + 4 + 5 + 6)/6 = 7/2.&lt;/math&gt; Therefore, the variance of {{mvar|X}} is
:&lt;math&gt;\begin{align}
   \operatorname{Var}(X) &amp;= \sum_{i=1}^6 \frac{1}{6}\left(i - \frac{7}{2}\right)^2 \\[5pt]
   &amp;= \frac{1}{6}\left((-5/2)^2 + (-3/2)^2 + (-1/2)^2 + (1/2)^2 + (3/2)^2 + (5/2)^2\right) \\[5pt]
   &amp;= \frac{35}{12} \approx 2.92.
 \end{align}&lt;/math&gt;

The general formula for the variance of the outcome, {{mvar|X}}, of an {{nowrap|{{mvar|n}}-sided}} die is
:&lt;math&gt;\begin{align}
   \operatorname{Var}(X) &amp;= \operatorname{E}(X^2)-(\operatorname{E}(X))^2 \\[5pt]
   &amp;= \frac{1}{n}\sum_{i=1}^n i^2 - \left(\frac{1}{n}\sum_{i=1}^n i\right)^2 \\[5pt]
   &amp;= \frac{(n + 1)(2n + 1)}{6} - \left(\frac{n + 1}{2}\right)^2 \\[4pt]
   &amp;= \frac{n^2 - 1}{12}.
 \end{align}&lt;/math&gt;

==Properties==

===Basic properties===
Variance is non-negative because the squares are positive or zero:
:&lt;math&gt;\operatorname{Var}(X)\ge 0.&lt;/math&gt;

The variance of a constant random variable is zero, and if the variance of a variable in a [[data set]] is 0, then all the entries have the same value:

:&lt;math&gt;P(X=a) = 1 \iff \operatorname{Var}(X)= 0.&lt;/math&gt;

Variance is [[Invariant (mathematics)|invariant]] with respect to changes in a [[location parameter]].  That is, if a constant is added to all values of the variable, the variance is unchanged:
:&lt;math&gt;\operatorname{Var}(X+a)=\operatorname{Var}(X).&lt;/math&gt;

If all values are scaled by a constant, the variance is scaled by the square of that constant:
:&lt;math&gt;\operatorname{Var}(aX)=a^2\operatorname{Var}(X).&lt;/math&gt;

The variance of a sum of two random variables is given by
:&lt;math&gt;\operatorname{Var}(aX+bY)=a^2\operatorname{Var}(X)+b^2\operatorname{Var}(Y)+2ab\, \operatorname{Cov}(X,Y),&lt;/math&gt;

:&lt;math&gt;\operatorname{Var}(aX-bY)=a^2\operatorname{Var}(X)+b^2\operatorname{Var}(Y)-2ab\, \operatorname{Cov}(X,Y),&lt;/math&gt;

where {{math|Cov(⋅, ⋅)}} is the [[covariance]].
In general we have for the sum of &lt;math&gt;N&lt;/math&gt; random variables &lt;math&gt;\{X_1,\dots,X_N\}&lt;/math&gt;:
:&lt;math&gt;\operatorname{Var}\left(\sum_{i=1}^N X_i\right)=\sum_{i,j=1}^N\operatorname{Cov}(X_i,X_j)=\sum_{i=1}^N\operatorname{Var}(X_i)+\sum_{i\ne j}\operatorname{Cov}(X_i,X_j).&lt;/math&gt;

These results lead to the variance of a [[linear combination]] as:

:&lt;math&gt;
\begin{align}
\operatorname{Var}\left( \sum_{i=1}^N a_iX_i\right) &amp;=\sum_{i,j=1}^{N} a_ia_j\operatorname{Cov}(X_i,X_j) \\
&amp;=\sum_{i=1}^N a_i^2\operatorname{Var}(X_i)+\sum_{i\not=j}a_ia_j\operatorname{Cov}(X_i,X_j)\\
&amp; =\sum_{i=1}^N a_i^2\operatorname{Var}(X_i)+2\sum_{1\le i&lt;j\le N}a_ia_j\operatorname{Cov}(X_i,X_j).
\end{align}
&lt;/math&gt;

If the random variables &lt;math&gt;X_1,\dots,X_N&lt;/math&gt; are such that
:&lt;math&gt;\operatorname{Cov}(X_i,X_j)=0\ ,\ \forall\ (i\ne j) ,&lt;/math&gt;
they are said to be [[Covariance#Definition|uncorrelated]].  It follows immediately from the expression given earlier that if the random variables &lt;math&gt;X_1,\dots,X_N&lt;/math&gt; are uncorrelated, then the variance of their sum is equal to the sum of their variances, or, expressed symbolically:

:&lt;math&gt;\operatorname{Var}\left(\sum_{i=1}^N X_i\right)=\sum_{i=1}^N\operatorname{Var}(X_i).&lt;/math&gt;

Since [[Covariance#Uncorrelatedness and independence|independent random variables are always uncorrelated]], the equation above holds in particular when the random variables &lt;math&gt;X_1,\dots,X_n&lt;/math&gt; are independent.  Thus independence is sufficient but not necessary for the variance of the sum to equal the sum of the variances.

===Sum of uncorrelated variables (Bienaymé formula)===
{{see also|Sum of normally distributed random variables}}
One reason for the use of the variance in preference to other measures of dispersion is that the variance of the sum (or the difference) of [[uncorrelated]] random variables is the sum of their variances:

:&lt;math&gt;\operatorname{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \operatorname{Var}(X_i).&lt;/math&gt;

This statement is called the [[Irénée-Jules Bienaymé|Bienaymé]] formula&lt;ref&gt;[[Michel Loève|Loève, M.]] (1977) "Probability Theory", ''Graduate Texts in Mathematics'', Volume 45, 4th edition, Springer-Verlag, p.&amp;nbsp;12.&lt;/ref&gt; and was discovered in 1853.&lt;ref&gt;[[Irénée-Jules Bienaymé|Bienaymé, I.-J.]] (1853) "Considérations à l'appui de la découverte de Laplace sur la loi de probabilité dans la méthode des moindres carrés", ''Comptes rendus de l'Académie des sciences Paris'', 37, p.&amp;nbsp;309–317; digital copy available [http://visualiseur.bnf.fr/CadresFenetre?O=NUMM-2994&amp;I=313]&lt;/ref&gt;&lt;ref&gt;[[Irénée-Jules Bienaymé|Bienaymé, I.-J.]] (1867) "Considérations à l'appui de la découverte de Laplace sur la loi de probabilité dans la méthode des moindres carrés", ''Journal de Mathématiques Pures et Appliquées, Série 2'', Tome 12, p.&amp;nbsp;158–167; digital copy available [http://gallica.bnf.fr/ark:/12148/bpt6k16411c/f166.image.n19][http://sites.mathdoc.fr/JMPA/PDF/JMPA_1867_2_12_A10_0.pdf]&lt;/ref&gt; It is often made with the stronger condition that the variables are [[statistical independence|independent]], but being uncorrelated suffices. So if all the variables have the same variance σ&lt;sup&gt;2&lt;/sup&gt;, then, since division by ''n'' is a linear transformation, this formula immediately implies that the variance of their mean is

:&lt;math&gt;\operatorname{Var}\left(\overline{X}\right) = \operatorname{Var}\left(\frac {1} {n} \sum_{i=1}^n X_i\right) = \frac {1} {n^2}\sum_{i=1}^n \operatorname{Var}\left(X_i\right) = \frac {1} {n^2}n\sigma^2= \frac {\sigma^2} {n}.&lt;/math&gt;

That is, the variance of the mean decreases when ''n'' increases. This formula for the variance of the mean is used in the definition of the [[standard error (statistics)|standard error]] of the sample mean, which is used in the [[central limit theorem]].

To prove the initial statement, it suffices to show that

:&lt;math&gt;\operatorname{Var}(X+Y) = \operatorname{Var}(X)+\operatorname{Var}(Y).&lt;/math&gt;

The general result then follows by induction.  Starting with the definition,

:&lt;math&gt;\begin{align}
   \operatorname{Var}(X+Y) &amp;= \operatorname{E}[(X+Y)^2] - (\operatorname{E}[X+Y])^2 \\[5pt]
    &amp;= \operatorname{E}[X^2+2XY+Y^2] - (\operatorname{E}[X]+\operatorname{E}[Y])^2.
 \end{align}&lt;/math&gt;

Using the linearity of the expectation operator and the assumption of independence (or uncorrelatedness) of ''X'' and ''Y'', this further simplifies as follows:

:&lt;math&gt;\begin{align}
   \operatorname{Var}(X + Y) &amp;= \operatorname{E}[X^2]+2\operatorname{E}[XY]+\operatorname{E}[Y^2] - (\operatorname{E}[X]^2+2\operatorname{E}[X]\operatorname{E}[Y]+\operatorname{E}[Y]^2) \\[5pt]
   &amp;= \operatorname{E}[X^2] + \operatorname{E}[Y^2] - \operatorname{E}[X]^2 - \operatorname{E}[Y]^2 \\[5pt]
   &amp;= \operatorname{Var}(X) + \operatorname{Var}(Y).
 \end{align}&lt;/math&gt;

===Sum of correlated variables===

In general, if the variables are [[correlated]], then the variance of their sum is the sum of their [[covariance]]s:

:&lt;math&gt;\operatorname{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \sum_{j=1}^n \operatorname{Cov}(X_i, X_j) = \sum_{i=1}^n \operatorname{Var}(X_i) + 2\sum_{1\le i&lt;j\le n}\operatorname{Cov}(X_i,X_j).&lt;/math&gt;

(Note: The second equality comes from the fact that {{math|Cov(''X''&lt;sub&gt;''i''&lt;/sub&gt;,''X''&lt;sub&gt;''i''&lt;/sub&gt;) {{=}} Var(''X''&lt;sub&gt;''i''&lt;/sub&gt;)}}.)

Here {{math|Cov(⋅, ⋅)}} is the [[covariance]], which is zero for independent random variables (if it exists). The formula states that the variance of a sum is equal to the sum of all elements in the covariance matrix of the components. The next expression states equivalently that the variance of the sum is the sum of the diagonal of covariance matrix plus two times the sum of its upper triangular elements (or its lower triangular elements); this emphasizes that the covariance matrix is symmetric. This formula is used in the theory of [[Cronbach's alpha]] in [[classical test theory]].

So if the variables have equal variance ''σ''&lt;sup&gt;2&lt;/sup&gt; and the average correlation of distinct variables is ''ρ'', then the variance of their mean is

:&lt;math&gt;\operatorname{Var}(\overline{X}) = \frac {\sigma^2} {n} + \frac {n-1} {n} \rho \sigma^2.&lt;/math&gt;

This implies that the variance of the mean increases with the average of the correlations. In other words, additional correlated observations are not as effective as additional independent observations at reducing the [[standard error|uncertainty of the mean]]. Moreover, if the variables have unit variance, for example if they are standardized, then this simplifies to

:&lt;math&gt;\operatorname{Var}(\overline{X}) = \frac {1} {n} + \frac {n-1} {n} \rho.&lt;/math&gt;

This formula is used in the [[Spearman–Brown prediction formula]] of classical test theory. This converges to ''ρ'' if ''n'' goes to infinity, provided that the average correlation remains constant or converges too. So for the variance of the mean of standardized variables with equal correlations or converging average correlation we have

:&lt;math&gt; \lim_{n \to \infty} \operatorname{Var}(\overline{X}) = \rho.&lt;/math&gt;

Therefore, the variance of the mean of a large number of standardized variables is approximately equal to their average correlation. This makes clear that the sample mean of correlated variables does not generally converge to the population mean, even though the [[law of large numbers]] states that the sample mean will converge for independent variables.

===Matrix notation for the variance of a linear combination===

Define &lt;math&gt;X&lt;/math&gt; as a column vector of &lt;math&gt;n&lt;/math&gt; random variables &lt;math&gt;X_1, \ldots,X_n&lt;/math&gt;, and &lt;math&gt;c&lt;/math&gt; as a column vector of &lt;math&gt;n&lt;/math&gt; scalars &lt;math&gt;c_1, \ldots,c_n&lt;/math&gt;. Therefore, &lt;math&gt;c^T X&lt;/math&gt; is a [[linear combination]] of these random variables, where &lt;math&gt;c^T&lt;/math&gt; denotes the [[transpose]] of &lt;math&gt;c&lt;/math&gt;. Also let &lt;math&gt;\Sigma&lt;/math&gt; be the [[covariance matrix]] of  &lt;math&gt;X&lt;/math&gt;. The variance of &lt;math&gt;c^TX&lt;/math&gt; is then given by:&lt;ref&gt;{{Cite book | last1=Johnson | first1=Richard | last2=Wichern | first2=Dean | year=2001 | title=Applied Multivariate Statistical Analysis | publisher=Prentice Hall | page=76 | isbn=0-13-187715-1 | postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}} }}&lt;/ref&gt;

:&lt;math&gt;\operatorname{Var}(c^T X) = c^T \Sigma c .&lt;/math&gt;

===Weighted sum of variables===
{{distinguish|Weighted variance}}

The scaling property and the Bienaymé formula, along with the property of the [[covariance]] {{math|Cov(''aX'',&amp;nbsp;''bY'') {{=}} ''ab'' Cov(''X'',&amp;nbsp;''Y'')}}  jointly imply that

:&lt;math&gt;\operatorname{Var}(aX \pm bY) =a^2 \operatorname{Var}(X) + b^2 \operatorname{Var}(Y) \pm 2ab\, \operatorname{Cov}(X, Y).&lt;/math&gt;

This implies that in a weighted sum of variables, the variable with the largest weight will have a disproportionally large weight in the variance of the total. For example, if ''X'' and ''Y'' are uncorrelated and the weight of ''X'' is two times the weight of ''Y'', then the weight of the variance of ''X'' will be four times the weight of the variance of ''Y''.

The expression above can be extended to a weighted sum of multiple variables:

:&lt;math&gt;\operatorname{Var}\left(\sum_{i}^n a_iX_i\right) = \sum_{i=1}^na_i^2 \operatorname{Var}(X_i) + 2\sum_{1\le i}\sum_{&lt;j\le n}a_ia_j\operatorname{Cov}(X_i,X_j)&lt;/math&gt;

===Product of independent variables===

If two variables X and Y are [[Independence (probability theory)|independent]], the variance of their product is given by&lt;ref&gt;{{Cite journal |last=Goodman |first=Leo A. |author-link=Leo Goodman |date=December 1960 |title=On the Exact Variance of Products |journal=Journal of the American Statistical Association |volume=55 |issue=292 |pages=708 |doi=10.2307/2281592 |jstor=2281592}}&lt;/ref&gt;
:&lt;math&gt;
\begin{align}
\operatorname{Var}(XY) &amp;= [\operatorname{E}(X)]^2 \operatorname{Var}(Y) + [\operatorname{E}(Y)]^2 \operatorname{Var}(X) + \operatorname{Var}(X)\operatorname{Var}(Y).
\end{align}
&lt;/math&gt;

Equivalently, using the basic properties of expectation, it is given by

:&lt;math&gt;
\operatorname{Var}(XY) = \operatorname{E}(X^2) \operatorname{E}(Y^2) - [\operatorname{E}(X)]^2 [\operatorname{E}(Y)]^2.
&lt;/math&gt;

===Product of statistically dependent variables===

In general, if two variables are statistically dependent, the variance of their product is given by:
:&lt;math&gt;
\begin{align}
\operatorname{Var}(XY) = {} &amp; \operatorname{E}[X^2 Y^2 ]-[\operatorname{E}(XY)]^2 \\[5pt]
= {} &amp; \operatorname{Cov}(X^2,Y^2 )+\operatorname{E}(X^2)\operatorname{E}(Y^2) - [\operatorname{E}(XY)]^2 \\[5pt]
= {} &amp; \operatorname{Cov}(X^2, Y^2) +(\operatorname{Var}(X)+[\operatorname{E}(X)]^2 )(\operatorname{Var}(Y)+[\operatorname{E}(Y)]^2 ) \\[5pt]
&amp; {}-[\operatorname{Cov}(X,Y)+\operatorname{E}(X)\operatorname{E}(Y)]^2
\end{align}&lt;/math&gt;

===Decomposition===

The general formula for variance decomposition or the [[law of total variance]] is: If &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are two random variables, and the variance of &lt;math&gt;X&lt;/math&gt; exists, then

:&lt;math&gt;\operatorname{Var}[X]=\operatorname{E}(\operatorname{Var}[X\mid Y])+\operatorname{Var}(\operatorname{E}[X\mid Y]).&lt;/math&gt;

The [[conditional expectation]] &lt;math&gt;\operatorname E(X\mid Y)&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt; given &lt;math&gt;Y&lt;/math&gt;, and the [[conditional variance]] &lt;math&gt;\operatorname{Var}(X\mid Y)&lt;/math&gt; may be understood as follows. Given any particular value ''y'' of&amp;nbsp;the random variable&amp;nbsp;''Y'', there is a conditional expectation &lt;math&gt;\operatorname E(X\mid Y=y)&lt;/math&gt;  given the event&amp;nbsp;''Y''&amp;nbsp;=&amp;nbsp;''y''. This quantity depends on the particular value&amp;nbsp;''y''; it is a function &lt;math&gt; g(y) = \operatorname E(X\mid Y=y)&lt;/math&gt;. That same function evaluated at the random variable ''Y'' is the conditional expectation &lt;math&gt;\operatorname E(X\mid Y) = g(Y).&lt;/math&gt;

In particular, if &lt;math&gt;Y&lt;/math&gt; is a discrete random variable assuming possible values &lt;math&gt;y_1, y_2, y_3 \ldots&lt;/math&gt; with corresponding probabilities &lt;math&gt;p_1, p_2, p_3 \ldots, &lt;/math&gt;, then in the formula for total variance, the first term on the right-hand side becomes

:&lt;math&gt;\operatorname{E}(\operatorname{Var}[X \mid Y]) = \sum_i p_i \sigma^2_i,&lt;/math&gt;

where &lt;math&gt;\sigma^2_i = \operatorname{Var}[X \mid Y = y_i]&lt;/math&gt;. Similarly, the second term on the right-hand side becomes

:&lt;math&gt;\operatorname{Var}(\operatorname{E}[X \mid Y]) = \sum_i p_i \mu_i^2 - \left(\sum_i p_i \mu_i\right)^2 = \sum_i p_i \mu_i^2 - \mu^2,&lt;/math&gt;

where &lt;math&gt;\mu_i = \operatorname{E}[X \mid Y = y_i]&lt;/math&gt; and &lt;math&gt;\mu = \sum_i p_i \mu_i&lt;/math&gt;. Thus the total variance is given by

:&lt;math&gt;\operatorname{Var}[X] = \sum_i p_i \sigma^2_i + \left( \sum_i p_i \mu_i^2 - \mu^2 \right).&lt;/math&gt;

A similar formula is applied in [[analysis of variance]], where the corresponding formula is

:&lt;math&gt;\mathit{MS}_\text{total} = \mathit{MS}_\text{between} + \mathit{MS}_\text{within};&lt;/math&gt;
 
here &lt;math&gt;\mathit{MS}&lt;/math&gt; refers to the Mean of the Squares. In [[linear regression]] analysis the corresponding formula is

:&lt;math&gt;\mathit{MS}_\text{total} = \mathit{MS}_\text{regression} + \mathit{MS}_\text{residual}.&lt;/math&gt;

This can also be derived from the additivity of variances, since the total (observed) score is the sum of the predicted score and the error score, where the latter two are uncorrelated.

Similar decompositions are possible for the sum of squared deviations (sum of squares, &lt;math&gt;\mathit{SS}&lt;/math&gt;):
:&lt;math&gt;\mathit{SS}_\text{total} = \mathit{SS}_\text{between} + \mathit{SS}_\text{within},&lt;/math&gt;
:&lt;math&gt;\mathit{SS}_\text{total} = \mathit{SS}_\text{regression} + \mathit{SS}_\text{residual}.&lt;/math&gt;

===Formulae for the variance===
{{Main article|Algebraic formula for the variance|Algorithms for calculating variance}}
A formula often used for deriving the variance of a theoretical distribution is as follows:

:&lt;math&gt; \operatorname{Var}(X)  =\operatorname{E}(X^2) - (\operatorname{E}(X))^2. &lt;/math&gt;

This will be useful when it is possible to derive formulae for the expected value and for the expected value of the square.

This formula is also sometimes used in connection with the sample variance. While useful for hand calculations, it is not advised for computer calculations as it suffers from [[catastrophic cancellation]] if the two components of the equation are similar in magnitude and floating point arithmetic is used. This is discussed in the article [[Algorithms for calculating variance]].

===Calculation from the CDF===

The population variance for a non-negative random variable can be expressed in terms of the [[cumulative distribution function]] ''F'' using

:&lt;math&gt;
2\int_0^\infty u( 1-F(u))\,du - \Big(\int_0^\infty (1-F(u))\,du\Big)^2.
&lt;/math&gt;

This expression can be used to calculate the variance in situations where the CDF, but not the [[probability density function|density]], can be conveniently expressed.

===Characteristic property===
The second [[moment (mathematics)|moment]] of a random variable attains the minimum value when taken around the first moment (i.e., mean) of the random variable, i.e. &lt;math&gt;\mathrm{argmin}_m\,\mathrm{E}\left(\left(X - m\right)^2\right) = \mathrm{E}(X)&lt;/math&gt;. Conversely, if a continuous function &lt;math&gt;\varphi&lt;/math&gt; satisfies &lt;math&gt;\mathrm{argmin}_m\,\mathrm{E}(\varphi(X - m)) = \mathrm{E}(X)&lt;/math&gt; for all random variables ''X'', then it is necessarily of the form &lt;math&gt;\varphi(x) = a x^2 + b&lt;/math&gt;, where {{nowrap|''a'' &gt; 0}}. This also holds in the multidimensional case.&lt;ref&gt;{{Cite journal | last1 = Kagan | first1 = A. | last2 = Shepp | first2 = L. A. | doi = 10.1016/S0167-7152(98)00041-8 | title = Why the variance? | journal = Statistics &amp; Probability Letters | volume = 38 | issue = 4 | pages = 329–333 | year = 1998 | pmid =  | pmc = }}&lt;/ref&gt;

===Units of measurement===

Unlike expected  absolute deviation, the variance of a variable has units that are the square of the units of the variable itself.  For example, a variable measured in meters will have a variance measured in meters squared.  For this reason, describing data sets via their [[standard deviation]] or [[root mean square deviation]] is often preferred over using the variance.  In the dice example the standard deviation is √2.9&amp;nbsp;≈&amp;nbsp;1.7, slightly larger than the expected absolute deviation of&amp;nbsp;1.5.

The standard deviation and the expected absolute deviation can both be used as an indicator of the "spread" of a distribution.  The standard deviation is more amenable to algebraic manipulation than the expected absolute deviation, and, together with variance and its generalization [[covariance]], is used frequently in theoretical statistics; however the expected absolute deviation tends to be more [[Robust statistics|robust]] as it is less sensitive to [[outlier]]s arising from [[measurement error|measurement anomalies]] or an unduly [[heavy-tailed distribution]].

==Approximating the variance of a function==
The [[delta method]] uses second-order [[Taylor expansion]]s to approximate the variance of a function of one or more random variables: see [[Taylor expansions for the moments of functions of random variables]]. For example, the approximate variance of a function of one variable is given by

::&lt;math&gt;\operatorname{Var}\left[f(X)\right]\approx \left(f'(\operatorname{E}\left[X\right])\right)^2\operatorname{Var}\left[X\right]&lt;/math&gt;

provided that ''f'' is twice differentiable and that the mean and variance of ''X'' are finite.

==Population variance and sample variance==
{{anchor|Estimation}}
{{see also|Unbiased estimation of standard deviation}}
Real-world observations such as the measurements of yesterday's rain throughout the day typically cannot be complete sets of all possible observations that could be made. As such, the variance calculated from the finite set will in general not match the variance that would have been calculated from the full population of possible observations.  This means that one [[Estimation theory|estimates]] the mean and variance that would have been calculated from an omniscient set of observations by using an [[estimator]] equation.  The estimator is a function of the [[Sample (statistics)|sample]] of ''n'' [[observations]] drawn without observational bias from the whole [[Statistical population|population]] of potential observations. In this example that sample would be the set of actual measurements of yesterday's rainfall from available rain gauges within the geography of interest.

The simplest estimators for population mean and population variance are simply the mean and variance of the sample, the '''sample mean''' and '''(uncorrected) sample variance''' – these are [[consistent estimator]]s (they converge to the correct value as the number of samples increases), but can be improved. Estimating the population variance by taking the sample's variance is close to optimal in general, but can be improved in two  ways. Most simply, the sample variance is computed as an average of [[squared deviations]] about the (sample) mean, by dividing by ''n.'' However, using values other than ''n'' improves the estimator in various ways. Four common values for the denominator are ''n,'' ''n''&amp;nbsp;−&amp;nbsp;1, ''n''&amp;nbsp;+&amp;nbsp;1, and ''n''&amp;nbsp;−&amp;nbsp;1.5: ''n'' is the simplest (population variance of the sample), ''n''&amp;nbsp;−&amp;nbsp;1 eliminates bias, ''n''&amp;nbsp;+&amp;nbsp;1 minimizes [[mean squared error]] for the normal distribution, and ''n''&amp;nbsp;−&amp;nbsp;1.5 mostly eliminates bias in [[unbiased estimation of standard deviation]] for the normal distribution.

Firstly, if the omniscient mean is unknown (and is computed as the sample mean), then the sample variance is a [[biased estimator]]: it underestimates the variance by a factor of (''n''&amp;nbsp;−&amp;nbsp;1) / ''n''; correcting by this factor (dividing by ''n''&amp;nbsp;−&amp;nbsp;1 instead of ''n'') is called [[Bessel's correction]]. The resulting estimator is unbiased, and is called the '''(corrected) sample variance''' or '''unbiased sample variance'''. For example, when ''n''&amp;nbsp;=&amp;nbsp;1 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.

Secondly, the sample variance does not generally minimize [[mean squared error]] between sample variance and population variance. Correcting for bias often makes this worse: one can always choose a scale factor that performs better than the corrected sample variance, though the optimal scale factor depends on the [[excess kurtosis]] of the population (see [[Mean squared error#Variance|mean squared error: variance]]), and introduces bias. This always consists of scaling down the unbiased estimator (dividing by a number larger than ''n''&amp;nbsp;−&amp;nbsp;1), and is a simple example of a [[shrinkage estimator]]: one "shrinks" the unbiased estimator towards zero. For the normal distribution, dividing by ''n''&amp;nbsp;+&amp;nbsp;1 (instead of ''n''&amp;nbsp;−&amp;nbsp;1 or ''n'') minimizes mean squared error. The resulting estimator is biased, however, and is known as the '''biased sample variation'''.

===Population variance===
In general, the '''''population variance''''' of a ''finite'' [[statistical population|population]] of size ''N'' with values ''x''&lt;sub&gt;''i''&lt;/sub&gt; is given by

:&lt;math display="block"&gt; \begin{align}
 \sigma^2 &amp;= \frac 1N \sum_{i=1}^N  \left(x_i - \mu \right)^2 = \frac 1N \sum_{i=1}^N  \left(x_i^2 - 2\mu x_i + \mu^2 \right) \\[5pt]
 &amp;= \left(\frac 1N \sum_{i=1}^N x_i^2\right) - 2\mu \left(\frac 1N \sum_{i=1}^N x_i\right) + \mu^2 \\[5pt]
 &amp;= \left(\frac 1N \sum_{i=1}^N x_i^2\right) - \mu^2
\end{align}&lt;/math&gt;

where the population mean is

: &lt;math&gt; \mu = \frac 1N \sum_{i=1}^N x_i. &lt;/math&gt;

The population variance can also be computed using

:&lt;math&gt; \sigma^2 = \frac {1} {N^2}\sum_{i&lt;j}\left( x_i-x_j \right)^2 = \frac{1}{2N^2} \sum_{i, j=1}^N\left( x_i-x_j \right)^2.&lt;/math&gt;

This is true because

:&lt;math display="block"&gt; 
\begin{align}
\frac{1}{2N^2} \sum_{i, j=1}^N\left( x_i-x_j \right)^2 &amp; = 
 \frac{1}{2N^2} \sum_{i, j=1}^N\left( x_i^2 - 2x_ix_j  + x_j^2 \right) \\[5pt]
 &amp;= \frac{1}{2N} \sum_{j=1}^N\left(\frac 1N \sum_{i=1}^N x_i^2\right) - \left(\frac 1N \sum_{i=1}^N x_i\right)\left(\frac 1N \sum_{j=1}^N x_j\right) \\[5pt]
&amp;\quad + \frac{1}{2N} \sum_{i=1}^N\left(\frac 1N \sum_{j=1}^N x_j^2\right) \\[5pt]
 &amp;= \frac{1}{2} \left( \sigma^2 + \mu^2 \right) - \mu^2 + \frac{1}{2} \left( \sigma^2 + \mu^2 \right) \\[5pt]
 &amp;= \sigma^2
\end{align}
&lt;/math&gt;

The population variance matches the variance of the generating probability distribution. In this sense, the concept of population can be extended to continuous random variables with infinite populations.

===Sample variance===
In many practical situations, the true variance of a population is not known ''a priori'' and must be computed somehow.  When dealing with extremely large populations, it is not possible to count every object in the population, so the computation must be performed on a [[sample (statistics)|sample]] of the population.&lt;ref&gt;Navidi, William (2006) ''Statistics for Engineers and Scientists'', McGraw-Hill, pg 14.&lt;/ref&gt; Sample variance can also be applied to the estimation of the variance of a continuous distribution from a sample of that distribution.

We take a  [[statistical sample|sample with replacement]] of ''n'' values ''Y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''Y''&lt;sub&gt;''n''&lt;/sub&gt; from the population, where ''n''&amp;nbsp;&lt;&amp;nbsp;''N'', and estimate the variance on the basis of this sample.&lt;ref&gt;Montgomery, D. C. and Runger, G. C. (1994) ''Applied statistics and probability for engineers'', page 201. John Wiley &amp; Sons New York&lt;/ref&gt; Directly taking the variance of the sample data gives the average of the [[squared deviations]]:

:&lt;math&gt;\sigma_y^2 = \frac 1n \sum_{i=1}^n \left(Y_i - \overline{Y} \right)^2 =\left(\frac 1n \sum_{i=1}^n Y_i^2\right) - \overline{Y}^2 = \frac {1} {n^2} \sum_{i,j\,:\,i&lt;j}\left( Y_i-Y_j \right)^2.&lt;/math&gt;

Here, &lt;math&gt;\overline{Y}&lt;/math&gt; denotes the [[sample mean]]: 
:&lt;math&gt;\overline{Y}=\frac 1n \sum_{i=1}^n Y_i .&lt;/math&gt;

Since the ''Y''&lt;sub&gt;''i''&lt;/sub&gt; are selected randomly, both &lt;math&gt;\overline{Y}&lt;/math&gt; and &lt;math&gt;\sigma_Y^2&lt;/math&gt; are random variables. Their expected values can be evaluated by averaging over the ensemble of all possible samples {''Y''&lt;sub&gt;''i''&lt;/sub&gt;} of size ''n'' from the population. For &lt;math&gt;\sigma_Y^2&lt;/math&gt; this gives:
:&lt;math&gt;
\begin{align}
\operatorname{E}[\sigma_Y^2]
&amp; = \operatorname{E}\left[ \frac 1n \sum_{i=1}^n \left(Y_i - \frac 1n \sum_{j=1}^n Y_j \right)^2 \right] \\[5pt]
&amp; = \frac 1n \sum_{i=1}^n \operatorname{E}\left[ Y_i^2 - \frac 2n Y_i \sum_{j=1}^n Y_j + \frac{1}{n^2} \sum_{j=1}^n Y_j \sum_{k=1}^n Y_k \right] \\[5pt]
&amp; = \frac 1n \sum_{i=1}^n \left[ \frac{n-2}{n} \operatorname{E}[Y_i^2] - \frac 2n \sum_{j \neq i} \operatorname{E}[Y_i Y_j] + \frac{1}{n^2} \sum_{j=1}^n \sum_{k \neq j}^n \operatorname{E}[Y_j Y_k] +\frac{1}{n^2} \sum_{j=1}^n \operatorname{E}[Y_j^2] \right] \\[5pt]
&amp; = \frac 1n \sum_{i=1}^n \left[ \frac{n-2}{n} (\sigma^2+\mu^2) - \frac 2n (n-1) \mu^2 + \frac{1}{n^2} n (n-1) \mu^2 + \frac 1n (\sigma^2+\mu^2) \right] \\[5pt]
&amp; = \frac{n-1}{n} \sigma^2.
\end{align}
&lt;/math&gt;

Hence &lt;math&gt;\sigma_Y^2&lt;/math&gt; gives an estimate of the population variance that is biased by a factor of &lt;math&gt;\frac{n-1}{n}&lt;/math&gt;. For this reason, &lt;math&gt;\sigma_Y^2&lt;/math&gt; is referred to as the ''biased sample variance''. Correcting for this bias yields the ''unbiased sample variance'':

:&lt;math&gt;s^2 = \frac{n}{n-1} \sigma_Y^2 = \frac{n}{n-1} \left( \frac{1}{n} \sum_{i=1}^n \left(Y_i - \overline{Y} \right)^2 \right) = \frac{1}{n-1} \sum_{i=1}^n \left(Y_i - \overline{Y} \right)^2 &lt;/math&gt;

Either estimator may be simply referred to as the ''sample variance'' when the version can be determined by context. The same proof is also applicable for samples taken from a continuous probability distribution.

The use of the term ''n''&amp;nbsp;−&amp;nbsp;1 is called [[Bessel's correction]], and it is also used in [[sample covariance]] and the [[sample standard deviation]] (the square root of variance). The square root is a [[concave function]] and thus introduces negative bias (by [[Jensen's inequality]]), which depends on the distribution, and thus the corrected sample standard deviation (using Bessel's correction) is biased. The [[unbiased estimation of standard deviation]] is a technically involved problem, though for the normal distribution using the term ''n''&amp;nbsp;−&amp;nbsp;1.5 yields an almost unbiased estimator.

The unbiased sample variance is a [[U-statistic]] for the function ''ƒ''(''y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''y''&lt;sub&gt;2&lt;/sub&gt;) =&amp;nbsp;(''y''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;−&amp;nbsp;''y''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;/2, meaning that it is obtained by averaging a 2-sample statistic over 2-element subsets of the population.

===Distribution of the sample variance===
{{multiple image
&lt;!-- Essential parameters --&gt;
| align     = right &lt;!-- left/right/center/none --&gt; 
| direction = vertical &lt;!-- horizontal/vertical --&gt;
| width     = 250 &lt;!-- Digits only; no "px" suffix, please --&gt;

&lt;!-- Image 1 --&gt;
| image1   = Scaled chi squared.svg &lt;!-- Filename only; no "File:" or "Image:" prefix, please --&gt;
| width1   =
| alt1     =
| caption1 =

&lt;!-- Image 2 --&gt;
| image2   = Scaled chi squared cdf.svg &lt;!-- Filename only; no "File:" or "Image:" prefix, please --&gt;
| width2   =
| alt2     =
| caption2 = Distribution and cumulative distribution of ''S''&lt;sup&gt;2&lt;/sup&gt;/&amp;sigma;&lt;sup&gt;2&lt;/sup&gt;, for various values of ''&amp;nu;'' = ''n'' − 1, when the ''y&lt;sub&gt;i&lt;/sub&gt;'' are independent normally distributed.
}}
Being a function of [[random variable]]s, the sample variance is itself a random variable, and it is natural to study its distribution. In the case that ''Y''&lt;sub&gt;''i''&lt;/sub&gt; are independent observations from a [[normal distribution]], [[Cochran's theorem]] shows that ''S''&lt;sup&gt;2&lt;/sup&gt; follows a scaled [[chi-squared distribution]]:&lt;ref&gt;Knight K. (2000), ''Mathematical Statistics'', Chapman and Hall, New York.  (proposition 2.11)&lt;/ref&gt;
:&lt;math&gt;
(n-1)\frac{S^2}{\sigma^2}\sim\chi^2_{n-1}.
&lt;/math&gt;

As a direct consequence, it follows that 
:&lt;math&gt;
\operatorname{E}(S^2)=\operatorname{E}\left(\frac{\sigma^2}{n-1} \chi^2_{n-1}\right)=\sigma^2 ,
&lt;/math&gt;

and&lt;ref&gt;Casella and Berger (2002) ''Statistical Inference'', Example 7.3.3, p. 331 {{full citation needed|date=March 2013}}&lt;/ref&gt;

:&lt;math display="block"&gt;
 \operatorname{Var}[s^2] =\operatorname{Var}\left(\frac{\sigma^2}{n-1} \chi^2_{n-1}\right)=\frac{\sigma^4}{(n-1)^2}\operatorname{Var}\left( \chi^2_{n-1}\right)=\frac{2\sigma^4 }{n-1}.
  &lt;/math&gt;

If the ''Y''&lt;sub&gt;''i''&lt;/sub&gt; are independent and identically distributed, but not necessarily normally distributed, then&lt;ref&gt;Cho, Eungchun; Cho, Moon Jung; Eltinge, John (2005) The Variance of Sample Variance From a Finite Population. International Journal of Pure and Applied Mathematics 21 (3): 387-394. http://www.ijpam.eu/contents/2005-21-3/10/10.pdf&lt;/ref&gt;&lt;ref&gt;Cho, Eungchun; Cho, Moon Jung (2009) Variance of Sample Variance With Replacement. International Journal of Pure and Applied Mathematics 52 (1): 43–47. http://www.ijpam.eu/contents/2009-52-1/5/5.pdf&lt;/ref&gt;

:&lt;math display="block"&gt;
    \operatorname{E}[S^2] = \sigma^2, \quad
    \operatorname{Var}[S^2] = \frac{\sigma^4}{n} \left ((\kappa-1)+\frac{2}{n-1} \right) = \frac{1}{n} \left(\mu_4 - \frac{n-3}{n-1}\sigma^4\right),
  &lt;/math&gt;
where ''κ'' is the [[kurtosis]] of the distribution and ''μ&lt;sub&gt;4&lt;/sub&gt;'' is the fourth [[central moment]].

If the conditions of the [[law of large numbers]] hold for the squared observations, ''s''&lt;sup&gt;2&lt;/sup&gt; is a [[consistent estimator]] of&amp;nbsp;''σ''&lt;sup&gt;2&lt;/sup&gt;. One can see indeed that the variance of the estimator tends asymptotically to zero.  An asymptotically equivalent formula was given in Kenney and Keeping (1951:164), Rose and Smith (2002:264), and Weisstein (n.d.).&lt;ref&gt;Kenney, John F.; Keeping, E.S. (1951) Mathematics of Statistics. Part Two. 2nd ed. D. Van Nostrand Company, Inc. Princeton: New Jersey. http://krishikosh.egranth.ac.in/bitstream/1/2025521/1/G2257.pdf&lt;/ref&gt;&lt;ref&gt;Rose, Colin; Smith, Murray D. (2002) Mathematical Statistics with Mathematica. Springer-Verlag, New York. http://www.mathstatica.com/book/Mathematical_Statistics_with_Mathematica.pdf&lt;/ref&gt;&lt;ref&gt;Weisstein, Eric W. (n.d.) Sample Variance Distribution. MathWorld—A Wolfram Web Resource. http://mathworld.wolfram.com/SampleVarianceDistribution.html&lt;/ref&gt;

===Samuelson's inequality===

[[Samuelson's inequality]] is a result that states bounds on the values that individual observations in a sample can take, given that the sample mean and (biased) variance have been calculated.&lt;ref&gt;{{cite journal |last=Samuelson |first=Paul |title=How Deviant Can You Be? |journal=[[Journal of the American Statistical Association]] |volume=63 |issue=324 |year=1968 |pages=1522–1525 |jstor=2285901 |doi=10.1080/01621459.1968.10480944}}&lt;/ref&gt; Values must lie within the limits &lt;math&gt;\bar y \pm \sigma_Y (n-1)^{1/2}.&lt;/math&gt;

===Relations with the harmonic and arithmetic means===

It has been shown&lt;ref&gt;{{cite journal |first=A. McD. |last=Mercer |title=Bounds for A–G, A–H, G–H, and a family of inequalities of Ky Fan’s type, using a general method |journal=J. Math. Anal. Appl. |volume=243 |issue=1 |pages=163–173 |year=2000 |doi=10.1006/jmaa.1999.6688 }}&lt;/ref&gt; that for a sample {''y''&lt;sub&gt;''i''&lt;/sub&gt;} of real numbers,

: &lt;math&gt;  \sigma_y^2 \le 2y_{\max} (A - H), &lt;/math&gt;

where ''y''&lt;sub&gt;max&lt;/sub&gt; is the maximum of the sample, ''A'' is the arithmetic mean, ''H'' is the [[harmonic mean]] of the sample and &lt;math&gt;\sigma_y^2&lt;/math&gt; is the (biased) variance of the sample.

This bound has been improved, and it is known that variance is bounded by

: &lt;math&gt; \sigma_y^2 \le \frac{y_{\max} (A - H)(y_\max - A)}{y_\max - H}, &lt;/math&gt;

: &lt;math&gt; \sigma_y^2 \ge \frac{y_{\min} (A - H)(A - y_\min)}{H - y_\min}, &lt;/math&gt;

where ''y''&lt;sub&gt;min&lt;/sub&gt; is the minimum of the sample.&lt;ref name=Sharma2008&gt;{{cite journal |first=R. |last=Sharma |title=Some more inequalities for arithmetic mean, harmonic mean and variance |journal=J. Math. Inequalities |volume=2 |issue=1 |pages=109–114 |year=2008 |doi=10.7153/jmi-02-11|citeseerx=10.1.1.551.9397 }}&lt;/ref&gt;

==Tests of equality of variances==

Testing for the equality of two or more variances is difficult. The [[F test]] and [[chi square test]]s are both adversely affected by non-normality and are not recommended for this purpose.

Several non parametric tests have been proposed: these include the Barton–David–Ansari–Freund–Siegel–Tukey test, the [[Capon test]], [[Mood test]], the [[Klotz test]] and the [[Sukhatme test]]. The Sukhatme test applies to two variances and requires that both [[median]]s be known and equal to zero. The Mood, Klotz, Capon and Barton–David–Ansari–Freund–Siegel–Tukey tests also apply to two variances. They allow the median to be unknown but do require that the two medians are equal.

The [[Lehmann test]] is a parametric test of two variances. Of this test there are several variants known. Other tests of the equality of variances include the [[Box test]], the [[Box–Anderson test]] and the [[Moses test]].

Resampling methods, which include the [[Bootstrapping (statistics)|bootstrap]] and the [[Resampling (statistics)|jackknife]], may be used to test the equality of variances.

==History==
The term ''variance'' was first introduced by [[Ronald Fisher]] in his 1918 paper ''[[The Correlation Between Relatives on the Supposition of Mendelian Inheritance]]'':&lt;ref&gt;[[Ronald Fisher]] (1918) [http://digital.library.adelaide.edu.au/dspace/bitstream/2440/15097/1/9.pdf The correlation between relatives on the supposition of Mendelian Inheritance]&lt;/ref&gt;

&lt;blockquote&gt;The great body of available statistics show us that the deviations of a [[biometry|human measurement]] from its mean follow very closely the [[Normal distribution|Normal Law of Errors]], and, therefore, that the variability may be uniformly measured by the [[standard deviation]] corresponding to the [[square root]] of the [[mean square error]]. When there are two independent causes of variability capable of producing in an otherwise uniform population distributions with standard deviations &lt;math&gt;\sigma_1&lt;/math&gt; and &lt;math&gt;\sigma_2&lt;/math&gt;, it is found that the distribution, when both causes act together, has a standard deviation &lt;math&gt;\sqrt{\sigma_1^2 + \sigma_2^2}&lt;/math&gt;.  It is therefore desirable in analysing the causes of variability to deal with the square of the standard deviation as the measure of variability.  We shall term this quantity the Variance...&lt;/blockquote&gt;

[[File:variance_visualisation.svg|thumb|Geometric visualisation of the variance of an arbitrary distribution (2, 4, 4, 4, 5, 5, 7, 9): {{ordered list
    |A frequency distribution is constructed.
    |The centroid of the distribution gives its mean.
    |A square with sides equal to the difference of each value from the mean is formed for each value.
    |Arranging the squares into a rectangle with one side equal to the number of values, ''n'', results in the other side being the distribution's variance, ''&amp;#963;''&amp;#178;.
}}]]

==Moment of inertia==
{{see also|Moment (physics)#Examples}}
The variance of a probability distribution is analogous to the  [[moment of inertia]] in [[classical mechanics]] of a corresponding mass distribution along a line, with respect to rotation about its center of mass.{{Citation needed|date=February 2012}}  It is because of this analogy that such things as the variance are called ''[[moment (mathematics)|moment]]s'' of [[probability distribution]]s.{{Citation needed|date=February 2012}} The covariance matrix is related to the [[moment of inertia tensor]] for multivariate distributions. The moment of inertia of a cloud of ''n'' points with a covariance matrix of &lt;math&gt;\Sigma&lt;/math&gt; is given by{{Citation needed|date=February 2012}}
:&lt;math&gt;I=n (\mathbf{1}_{3\times 3} \operatorname{tr}(\Sigma) - \Sigma).&lt;/math&gt;
This difference between moment of inertia in physics and in statistics is clear for points that are gathered along a line. Suppose many points are close to the ''x'' axis and distributed along it. The covariance matrix might look like
:&lt;math&gt;\Sigma=\begin{bmatrix}10 &amp; 0 &amp; 0\\0 &amp; 0.1 &amp; 0 \\ 0 &amp; 0 &amp; 0.1\end{bmatrix}.&lt;/math&gt;
That is, there is the most variance in the ''x'' direction.  Physicists would consider this to have a low moment ''about'' the ''x'' axis so the moment-of-inertia tensor is
:&lt;math&gt;I=n\begin{bmatrix}0.2 &amp; 0 &amp; 0\\0 &amp; 10.1 &amp; 0 \\ 0 &amp; 0 &amp; 10.1\end{bmatrix}.&lt;/math&gt;

==Semivariance==

The ''semivariance'' is calculated in the same manner as the variance but only those observations that fall below the mean are included in the calculation. It is sometimes described as a measure of [[downside risk]] in an [[investment#In finance|investments]] context. For skewed distributions, the semivariance can provide additional information that a variance does not.{{Citation needed|date=June 2015}}

For inequalities associated with the semivariance, see {{Section link|Chebyshev's inequality|Semivariances}}.

==Generalizations==

===For complex variables===
If &lt;math&gt;x&lt;/math&gt; is a scalar [[complex number|complex]]-valued random variable, with values in &lt;math&gt;\mathbb{C},&lt;/math&gt; then its variance is &lt;math&gt;\operatorname{E}\left[(x - \mu)(x - \mu)^*\right],&lt;/math&gt; where &lt;math&gt;x^*&lt;/math&gt; is the [[complex conjugate]] of &lt;math&gt;x.&lt;/math&gt;  This variance is a real scalar.

===For vector-valued random variables===

====As a matrix====
If &lt;math&gt;X&lt;/math&gt; is a [[vector space|vector]]-valued random variable, with values in &lt;math&gt;\mathbb{R}^n,&lt;/math&gt; and thought of as a column vector, then a natural generalization of variance is &lt;math&gt;\operatorname{E}\left[(X - \mu)(X - \mu)^{\operatorname{T}}\right],&lt;/math&gt; where &lt;math&gt;\mu = \operatorname{E}(X)&lt;/math&gt; and &lt;math&gt;X^{\operatorname{T}}&lt;/math&gt; is the transpose of &lt;math&gt;X,&lt;/math&gt; and so is a row vector.  The result is a [[positive definite matrix|positive semi-definite square matrix]], commonly referred to as the [[variance-covariance matrix]] (or simply as the ''covariance matrix'').

If &lt;math&gt;X&lt;/math&gt; is a vector- and complex-valued random variable, with values in &lt;math&gt;\mathbb{C}^n,&lt;/math&gt; then the [[Covariance matrix#Complex random vectors|covariance matrix is]] &lt;math&gt;\operatorname{E}\left[(X - \mu)(X - \mu)^\dagger\right],&lt;/math&gt; where &lt;math&gt;X^\dagger&lt;/math&gt; is the [[conjugate transpose]] of &lt;math&gt;X.&lt;/math&gt;{{Citation needed|date=September 2016}}  This matrix is also positive semi-definite and square.

====As a scalar====
Another natural generalization of variance for such vector-valued random variables &lt;math&gt;X,&lt;/math&gt; which results in a scalar value rather than in a matrix, is obtained by interpreting the deviation between the random variable and its mean as the [[Euclidean distance]]. This results in &lt;math&gt;\operatorname{E}\left[(X - \mu)^{\operatorname{T}}(X - \mu)\right] = \operatorname{tr}(C),&lt;/math&gt; which is the [[Trace (linear algebra)|trace]] of the covariance matrix.

==See also==
{{Too many see alsos|date=May 2017}}
{{Portal|Statistics}}
{{Wiktionary|variance}}
{{colbegin|colwidth=20em}}
* [[Average absolute deviation]]
* [[Bhatia–Davis inequality]]
* [[Common-method variance]]
* [[Correlation]]
* [[Chebyshev's inequality]]
* [[Distance variance]]
* [[Estimation of covariance matrices]]
* [[Explained variance]]
* [[Homoscedasticity]]
* [[Mean absolute error]]
* [[Mean absolute difference]]
* [[Mean preserving spread]]
* [[Pooled variance]] (also known as combined, composite, or overall variance)
* [[Popoviciu's inequality on variances]]
* [[Qualitative variation]]
* [[Quasi-variance]], used in linear regression when the explanatory variable is categorical
* [[Reduced chi-squared]]
* [[Sample mean and covariance]]
* [[Semivariance]]
* [[Skewness]]
* [[Taylor's law]]
* [[Weighted mean#Weighted sample variance|Weighted sample variance]]
{{colend}}

==Notes==
{{Reflist|30em}}

{{Theory of probability distributions}}
{{Statistics|descriptive|state=collapsed}}

{{Authority control}}

[[Category:Moment (mathematics)]]
[[Category:Statistical deviation and dispersion]]
[[Category:Articles containing proofs]]</text>
      <sha1>quhhh2p2mai4286v59dlltjjzcn7x8v</sha1>
    </revision>
  </page>
  <page>
    <title>Windward and leeward</title>
    <ns>0</ns>
    <id>276852</id>
    <revision>
      <id>864542505</id>
      <parentid>847806381</parentid>
      <timestamp>2018-10-17T22:04:29Z</timestamp>
      <contributor>
        <username>Ringbang</username>
        <id>147617</id>
      </contributor>
      <minor/>
      <comment>revised link per [[WP:DONOTFIXIT]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5986">{{redirect|Downwind|the album by Pierre Moerlen's Gong|Downwind (album)}}
[[Image:Upwind downwind example.png|thumb|right|400px|Example image showing definitions of windward (upwind) and leeward (downwind)]]
'''Windward''' ({{IPAc-en|ˈ|w|ɪ|n|d|w|ər|d|,_|ˈ|w|ɪ|n|ər|d}}) is the direction upwind from the point of reference, alternatively the direction from which the wind is coming. '''Leeward''' ({{IPAc-en|ˈ|l|iː|w|ər|d|,_|ˈ|lj|uː|ər|d}}) is the direction downwind (or downward) from the point of reference. The leeward region of mountains generally remains dry as compared to the windward. The side of a ship that is towards the leeward is its '''lee side'''. If the vessel is [[Heeling (sailing)|heeling]] under the pressure of the wind, this will be the "lower side". During the age of sail, the term ''weather'' was used as a synonym for ''windward'' in some contexts, as in the ''[[weather gage]]''.

==Nautical and naval==
{{main|Sailing}}
Windward and leeward directions are important factors ([[points of sail]]) to consider when [[sailing]] a [[sailing ship]]. Other terms with broadly the same meaning are widely used, particularly ''upwind'' and ''downwind''.&lt;ref name="Royce1993"&gt;{{cite book|author=Patrick M. Royce|title=Royce's Sailing Illustrated Course: Provides Lectures That Can Be Read Word for Word|url=https://books.google.com/books?id=Mt4OtDd_YP0C&amp;pg=PA11|date=1 April 1993|publisher=ProStar Publications|isbn=978-0-911284-01-0|pages=11–}}&lt;/ref&gt;

The windward vessel is normally the more maneuverable vessel. For this reason, rule 12 of the [[International Regulations for Preventing Collisions at Sea]] stipulates that the windward vessel gives way to the leeward vessel.&lt;ref&gt;{{cite book|title=Navigators International Rules of the Road' 1998 Ed.|url=https://books.google.com/books?id=qzAU4JnK8e8C&amp;pg=PA73|publisher=Rex Bookstore, Inc.|isbn=978-971-23-2239-6|pages=73–}}&lt;/ref&gt; 

===Naval warfare===
In warfare, a [[square rig]]ged warship would often try to enter battle from the windward direction (or "hold the [[weather gauge]]"), thus gaining an important tactical advantage over the opposing warship&amp;nbsp;&amp;ndash; the warship to windward could choose when to engage and when to withdraw. The opposing warship to leeward could often do little but comply without exposing itself unduly.&lt;ref name="Childs2014"&gt;{{cite book|author=David Childs|title=The Warship Mary Rose: The Life and Times of King Henry VII's Flagship|url=https://books.google.com/books?id=e-yZBgAAQBAJ&amp;pg=PT127|date=30 April 2014|publisher=Seaforth Publishing|isbn=978-1-4738-5285-3|pages=127–}}&lt;/ref&gt;

This was particularly important once [[artillery]] was introduced to naval warfare. The ships heeled away from the wind so that the leeward vessel was exposing part of her bottom to shot.&lt;ref name="Willis2008"&gt;{{cite book|author=Sam Willis|title=Fighting at Sea in the Eighteenth Century: The Art of Sailing Warfare|url=https://books.google.com/books?id=UW9kOqCgsIgC&amp;pg=PA152|year=2008|publisher=Boydell Press|isbn=978-1-84383-367-3|pages=152–}}&lt;/ref&gt;

==Meteorological significance==
''Leeward'' and ''windward'' refer respectively to what a [[game stalker]] would call downwind and upwind.&lt;ref name="Michell2015"&gt;{{cite book|author=E. B. Michell|title=The Art and Practice of Hawking|url=https://books.google.com/books?id=JAZACwAAQBAJ&amp;pg=PT250|date=22 December 2015|publisher=Read Books Limited|isbn=978-1-4733-6546-9|pages=250–}}&lt;/ref&gt; The terms are used by seamen in relation to their ships but also in reference to islands in an [[archipelago]] and to the different sides of a single island. In the latter case, the windward side is that side of an island subject to the [[prevailing wind]], and is thus the wetter side (see [[Precipitation (meteorology)|orographic precipitation]]). The leeward side is the side protected by the elevation of the island from the prevailing wind, and is typically the drier side of an island. Thus, leeward or windward siting is an important [[weather]] and [[climate]] factor on oceanic islands.&lt;ref name="Pidwirny2016"&gt;{{cite book|author=Michael Pidwirny|title=Glossary of Terms for Physical Geography|url=https://books.google.com/books?id=jQoIBAAAQBAJ&amp;pg=PA286|date=5 September 2016|publisher=Our Planet Earth Publishing|isbn=978-0-9877029-0-6|pages=286–}}&lt;/ref&gt;

In the case of an [[archipelago]], ''windward islands'' are upwind and ''leeward islands'' are the downwind ones.

==The terms upwind and downwind==
In these contexts the terms ''windward'' and ''layward'' are not used.
* [[Hunting]]: In hunting, the animal that is downwind has an advantage. S/he can smell the upwind animal, but the reverse is not true. The downwind animal has the advantage of surprise when hunting the upwind animal.
* [[Architecture]] and [[urban planning]]: Part of a house, or a community, is located upwind of something downwind that is malodorous — an [[outhouse]], a [[garbage dump]], a [[feedlot]], a [[factory]] or [[meatpacker]]. It is sometimes the case that part of a house or a community, or sometimes the entire house or community, will be downwind of some pleasant odor. These odors are either plant-based — flowers, fruit or flowering trees, forests —, or moving water — rivers, waves, rain.

==See also==
&lt;!-- New links in alphabetical order please --&gt;
*[[Barlavento Islands|Barlavento]] (Windward) and [[Sotavento Islands|Sotavento]] (Leeward) in [[Cape Verde Islands]]
*Downstream and [[Source (river or stream)|upstream]]
*[[Foehn wind]]
*[[Lee shore]]
*[[Northwestern Hawaiian Islands]], also known as Leeward Islands
*[[Windward Islands]], [[Leeward Islands]] and [[Leeward Antilles]] (in the [[Lesser Antilles]])
*[[Windward Islands (Society Islands)|Windward Islands]] and [[Leeward Islands (Society Islands)|Leeward Islands]] (in the [[Society Islands]])

==References==
{{reflist}}

{{DEFAULTSORT:Windward And Leeward}}
[[Category:Nautical terminology]]
[[Category:Orientation (geometry)]]
[[Category:Wind]]</text>
      <sha1>q5qnp90ncu6vll28qe266htac2oy4ge</sha1>
    </revision>
  </page>
  <page>
    <title>Yamabe problem</title>
    <ns>0</ns>
    <id>11757994</id>
    <revision>
      <id>859498175</id>
      <parentid>859494984</parentid>
      <timestamp>2018-09-14T12:18:29Z</timestamp>
      <contributor>
        <username>Derek R Bullamore</username>
        <id>698799</id>
      </contributor>
      <comment>Removed clean-up tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3582">{{More footnotes|date=September 2018}}
The '''Yamabe problem''' in [[differential geometry]] concerns the existence of [[Riemannian metric]]s with constant [[scalar curvature]], and takes its name from the mathematician [[Hidehiko Yamabe]]. {{harvtxt|Yamabe|1960}} claimed to have a solution, but {{harvtxt|Trudinger|1968}} discovered a critical error in his proof. The combined work of [[Neil Trudinger]], [[Thierry Aubin]], and [[Richard Schoen]] later provided a complete solution to the problem in 1984.&lt;ref&gt;{{cite web|url=http://www.math.mcgill.ca/gantumur/math580f12/Yamabe.pdf|format=PDF|title=The Yamabe Problem|author=Selim Tawfik|website=Math.mcgill.ca|accessdate=14 September 2018}}&lt;/ref&gt;

The Yamabe problem is the following: Given a smooth, [[compact space|compact]] [[manifold]] {{math|''M''}} of dimension {{math|''n'' ≥ 3}} with a [[Riemannian metric]] {{math|''g''}}, does there exist a metric {{math|''g''&lt;nowiki/&gt;'}} [[conformal map|conformal]] to {{math|''g''}} for which the [[scalar curvature]] of {{math|''g''&lt;nowiki/&gt;'}} is constant?  In other words, does a smooth function {{math|''f''}} exist on {{math|''M''}} for which the metric {{math|1=''g''&lt;nowiki/&gt;' = ''e''&lt;sup&gt;2''f''&lt;/sup&gt;''g''}} has constant scalar curvature?  The answer is now known to be yes, and was proved using techniques from [[differential geometry]], [[functional analysis]] and [[partial differential equations]].

==The non-compact case==
A closely related question is the so-called "non-compact Yamabe problem", which asks: Is it true that on every smooth complete [[Riemannian manifold]] {{math|(''M'',''g'')}} which is not compact, there exists a metric that is conformal to ''g'', has constant scalar curvature and is also complete? The answer is no, due to counterexamples given by {{harvtxt|Jin|1988}}.

==See also==
* [[Yamabe flow]]
* [[Yamabe invariant]]

==Notes==
{{Reflist}}

==References==
*{{citation|first1=John Marshall|last1=Lee|first2=Thomas H.|last2=Parker|url=http://www.ams.org/bull/1987-17-01/S0273-0979-1987-15514-5/|title=The Yamabe problem|journal=Bulletin of the American Mathematical Society|volume=17|pages=37–81|year=1987|doi=10.1090/s0273-0979-1987-15514-5}}.
*{{Citation | last1=Trudinger | first1=Neil S. | author1-link=Neil Trudinger | title=Remarks concerning the conformal deformation of Riemannian structures on compact manifolds | url=http://www.numdam.org/item?id=ASNSP_1968_3_22_2_265_0 | mr=0240748 | year=1968 | journal=Ann. Scuola Norm. Sup. Pisa (3) | volume=22 | pages=265–274}}
*{{Citation | last1=Yamabe | first1=Hidehiko | title=On a deformation of Riemannian structures on compact manifolds | url=http://projecteuclid.org/euclid.ojm/1200689814 | mr=0125546 | year=1960 | journal=Osaka Journal of Mathematics | issn=0030-6126 | volume=12 | pages=21–37}}
*{{Citation | last1=Schoen  | first1=Richard  | title=Conformal deformation of a Riemannian metric to constant scalar curvature |year=1984| journal=J. Differential Geom. |volume= 20 | pages= 479–495.}}
*{{Citation | last1=Aubin | first1=Thierry | title= Équations différentielles non linéaires et problème de Yamabe concernant la courbure scalaire | year=1976| journal=J. Math. Pures Appl.|volume= (9) 55 |pages=269–296.}} 
*{{Citation | last1=Jin | first1=Zhiren | title= A counterexample to the Yamabe problem for complete noncompact manifolds| url=https://link.springer.com/chapter/10.1007/BFb0082927 | year=1988| journal=Lect. Notes Math.|volume= 1306 |pages=93–101. | doi=10.1007/BFb0082927}}

[[Category:Riemannian geometry]]
[[Category:Mathematical problems]]</text>
      <sha1>su1s66p2qjp029wxa3um8zyi4zkdop0</sha1>
    </revision>
  </page>
</mediawiki>
