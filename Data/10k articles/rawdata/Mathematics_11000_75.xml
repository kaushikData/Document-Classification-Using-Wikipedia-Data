<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>171 (number)</title>
    <ns>0</ns>
    <id>4347699</id>
    <revision>
      <id>867948070</id>
      <parentid>867890771</parentid>
      <timestamp>2018-11-09T00:43:01Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/Piledhigheranddeeper|Piledhigheranddeeper]] ([[User talk:Piledhigheranddeeper|talk]]): Both "clarifications" are confusing. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4846">{{example farm|date=January 2012}}
{{Infobox number
| number = 171
| divisor=1, 3, 9, 19, 57, 171
}}
'''171''' ('''one hundred [and] seventy-one''') is the [[natural number]] following [[170 (number)|170]] and preceding [[172 (number)|172]].

==In mathematics==
171 is an [[odd number]], a [[composite number]], and a [[deficient number]].
It is also a [[triangular number]], a [[tridecagonal number]]&lt;ref&gt;{{Cite web|url=https://oeis.org/A051865|title=Sloane's A051865 : 13-gonal (or tridecagonal) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt; and a [[polygonal number|58-gonal number]].

171 is a [[Harshad number]], a [[palindromic number]], and an [[undulating number]]. 171 is a [[repdigit]] in [[base 7]] (333), and also in bases 18, 56, and 170.

==In astronomy==
* [[171P/Spahr]] is a periodic [[comet]] in our [[solar system]]
* [[171 Ophelia]] is a [[Asteroid belt|main belt]] [[asteroid]], a member of the [[Themis family]] of [[asteroid]]s

==In geography==
* [[Fox Valley No. 171, Saskatchewan]], [[Canada]]

==In the military==
* [[171st Air Refueling Squadron]] unit of the [[Michigan Air National Guard]] flies the [[KC-135T Stratotanker]]
* [[United States Air Force|US Air Force]] [[171st Air Refueling Wing]] [[Air Mobility Command]] unit of the [[Pennsylvania Air National Guard]]
* [[171st Battalion (Quebec Rifles), CEF|171st Battalion]] was a unit based in [[Quebec City, Quebec]] in the [[Canadian Expeditionary Force]] during World War I
* [[United States Army|US Army]] [[171st Infantry Brigade (United States)|171st Infantry Brigade]] based at [[Fort Jackson (South Carolina)|Fort Jackson]], [[South Carolina]]
* {{USS|Burns|DD-171}} was a [[United States Navy]] {{sclass-|Wickes|destroyer}} following World War I
* {{USS|Carroll|DE-171}} was a United States Navy {{sclass-|Cannon|destroyer escort}} during World War II
* {{USS|Claiborne|AK-171}} was a United States Navy {{sclass-|Alamosa|cargo ship}} during World War II
* {{USS|Cuttlefish|SS-171}} was a United States Navy {{sclass-|Cachalot|submarine}} during World War II
* {{USS|Granville|APA-171}} was a United States Navy {{sclass-|Haskell|attack transport}} during World War II
* {{USS|Quest|SP-171}} was a United States Navy [[patrol boat]] during World War I
* {{USS|Storm King|AP-171}} was a United States Navy ''Storm King''-class auxiliary transport during World War II
* [[Australian Army]] [[171st Aviation Squadron (Australia)|171st Aviation Squadron]] [[helicopter]] squadron at [[Holsworthy Barracks]] near Sydney

==In the penal code==
* [[Section 171 of the Criminal Code of Cyprus|Section 171]] of the [[Cyprus]] [[Penal code]]
* Article 171 of the [[Penal code of Brazil]], defines the crime of ''estelionato'' (defrauding the unwary, i.e. a "scam" or "confidence trick"). Because of it, in [[Brazilian Portuguese]], ''um-sete-um'' (literally, one-seven-one) became a synonym for "scam", and also "swindler" or "compulsive liar".
* Article 171 of the [[Philippines]] [[Revised Penal Code of the Philippines|Penal Code]] (falsification of public documents)


==In sports==
* [[Johnny Bright]] rushed for a record 171 yards in the [[Canadian Football League]] [[44th Grey Cup|44th]] [[Grey Cup]] game on November 24, 1956

==In transportation==
* [[British Rail Class 171]]
* [[London Buses route 171]]
* [[SMRT Bus Service 171]]

==In other fields==
'''171''' is also:
* The year AD [[171]] or 171 BC
* [[E171]] (Titanium dioxide)
* In binary form (10101011), the preamble in a [[Specific Area Message Encoding]] header in the [[Emergency Alert System]]
* The [[Compaq 171FS computer monitor]]
* [[JWH-171]], an [[analgesic]] drug that acts as a [[cannabinoid]] receptor agonist
* [[Minuscule 171]], a [[Greek language|Greek]] [[Lower case|minuscule]] [[manuscript]] of the [[New Testament]], on parchment
* [[SJK 171]], one of the earliest New York City [[graffiti artist]]s of the late 1960s and 1970s
* 171, the [[Venezuela]]n [[emergency telephone number]]

==See also==
* [[Mike 171]]
* [[List of highways numbered 171]]
* [[List of United States Supreme Court cases, volume 171|United States Supreme Court cases, Volume 171]]
* [[United Nations Security Council Resolution 171]]

==External links==
{{Commons category|171 (number)}}
* [http://athensohio.net/reference/number/171/ Number Facts and Trivia: 171]
* [http://www.numbergossip.com/171 Number Gossip: 171]
* [http://www.numdic.com/171 The Number 171]
* [http://www.positiveintegers.org/171 The Positive Integer 171]
* [http://www.virtuescience.com/171.html VirtueScience: 171]
* [https://web.archive.org/web/20090730023811/http://www.wfprr.com/171/index.html Locomotive 171 Restoration Project]

== References ==
{{Reflist}}
{{Integers|1}}

{{DEFAULTSORT:171 (Number)}}
[[Category:Integers]]</text>
      <sha1>cc831a5t9cm4gm9y0y3dkxkdymnf981</sha1>
    </revision>
  </page>
  <page>
    <title>Arborescence (graph theory)</title>
    <ns>0</ns>
    <id>13251077</id>
    <revision>
      <id>843601326</id>
      <parentid>781162473</parentid>
      <timestamp>2018-05-30T06:18:03Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Ping Zhang (graph theorist)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6549">In [[graph theory]], an '''arborescence''' is a [[directed graph]] in which, for a vertex ''u'' called the root and any other vertex ''v'', there is exactly one directed path from ''u'' to ''v''. An arborescence is thus the directed-graph form of a [[rooted tree]], understood here as an [[undirected graph]].&lt;ref name="poly"/&gt;&lt;ref name="Williamson1985"/&gt;

Equivalently, an arborescence is a directed, rooted [[Tree (graph theory)|tree]] in which all edges point away from the root; a number of other equivalent characterizations exist.&lt;ref name="Fournier2013"&gt;{{cite book|author=Jean-Claude Fournier|title=Graphs Theory and Applications: With Exercises and Problems|year=2013|publisher=John Wiley &amp; Sons|isbn=978-1-84821-070-7|pages=94–95}}&lt;/ref&gt;&lt;ref name="Gallier2011"&gt;{{cite book|author=Jean Gallier|authorlink= Jean Gallier |title=Discrete Mathematics|year=2011|publisher=Springer Science &amp; Business Media|isbn=978-1-4419-8046-5|pages=193–194}}&lt;/ref&gt; Every arborescence is a [[directed acyclic graph]] (DAG), but not every DAG is an arborescence.

An arborescence can equivalently be defined as a [[rooted digraph]]&lt;!--doesn't matter if the broader or narrower def for that is used--&gt; in which the path from the root to any other vertex is unique.&lt;ref name="poly"&gt;{{cite journal | doi = 10.1090/S0002-9939-1989-0967486-0 | title=A greedoid polynomial which distinguishes rooted arborescences | journal=Proceedings of the American Mathematical Society | date=1989 | volume=107 | issue=2 | pages=287 | first=Gary | last=Gordon}}&lt;/ref&gt;

The term ''arborescence'' comes from French.&lt;ref name="Hage1996"&gt;{{cite book|author=Per Hage and [[Frank Harary]]|title=Island Networks: Communication, Kinship, and Classification Structures in Oceania|year=1996|publisher=Cambridge University Press|isbn=978-0-521-55232-5|page=43}}&lt;/ref&gt; Some authors object to it on grounds that it is cumbersome to spell.&lt;ref name="multi"/&gt; There is a large number of synonyms for arborescence in graph theory, including '''directed rooted tree'''&lt;ref name="Williamson1985"&gt;{{cite book|author=Stanley Gill Williamson|title=Combinatorics for Computer Science|year=1985|publisher=Courier Dover Publications|isbn=978-0-486-42076-9|page=288}}&lt;/ref&gt;&lt;ref name="multi"&gt;{{cite book|author1=Mehran Mesbahi|author2=Magnus Egerstedt|title=Graph Theoretic Methods in Multiagent Networks|year=2010|publisher=Princeton University Press|isbn=1-4008-3535-6|page=38}}&lt;/ref&gt; '''out-arborescence''',&lt;ref name="DuKo2011"&gt;{{cite book|author1=Ding-Zhu Du|author2=Ker-I Ko|author3=Xiaodong Hu|title=Design and Analysis of Approximation Algorithms|year=2011|publisher=Springer Science &amp; Business Media|isbn=978-1-4614-1701-9|page=108}}&lt;/ref&gt; '''out-tree''',&lt;ref name="GrossYellen2013"/&gt; and even '''branching''' being used to denote the same concept.&lt;ref name="GrossYellen2013"&gt;{{cite book|author1=Jonathan L. Gross|author2=Jay Yellen|author3=Ping Zhang|author3-link=Ping Zhang (graph theorist)|title=Handbook of Graph Theory, Second Edition|year=2013|publisher=CRC Press|isbn=978-1-4398-8018-0|page=116}}&lt;/ref&gt; ''Rooted tree'' itself has been defined by some authors as a directed graph.&lt;ref name="Makinson2012"&gt;{{cite book|author=[[David Makinson]]|title=Sets, Logic and Maths for Computing|year=2012|publisher=Springer Science &amp; Business Media|isbn=978-1-4471-2499-3|pages=167–168}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Kenneth Rosen|title=Discrete Mathematics and Its Applications, 7th edition|year=2011|publisher=McGraw-Hill Science|page=747|isbn=978-0-07-338309-5}}&lt;/ref&gt;&lt;ref name="Schrijver2003"/&gt;

Furthermore, some authors define an arborescence to be a spanning directed tree of a given digraph.&lt;ref name="Schrijver2003"&gt;{{cite book|author=Alexander Schrijver|title=Combinatorial Optimization: Polyhedra and Efficiency|year=2003|publisher=Springer|isbn=3-540-44389-4|page=34}}&lt;/ref&gt;&lt;ref name="Bang-JensenGutin2008"&gt;{{cite book|author1=Jørgen Bang-Jensen|author2=Gregory Z. Gutin|title=Digraphs: Theory, Algorithms and Applications|year=2008|publisher=Springer|isbn=978-1-84800-998-1|page=339}}&lt;/ref&gt; The same can be said about some its synonyms, especially ''branching''.&lt;ref name="Bang-JensenGutin2008"/&gt; Other authors use ''branching'' to denote a forest of arborescences, with the latter notion defined in broader sense given at beginning of this article,&lt;ref name="Evans1992"&gt;{{cite book|author=James Evans|title=Optimization Algorithms for Networks and Graphs, Second Edition|year=1992|publisher=CRC Press|isbn=978-0-8247-8602-1|page=59}}&lt;/ref&gt;&lt;ref name="KorteVygen2012"&gt;{{cite book|author1=Bernhard Korte|author2=Jens Vygen|title=Combinatorial Optimization: Theory and Algorithms|year=2012|publisher=Springer Science &amp; Business Media|isbn=978-3-642-24488-9|page=18|edition=5th}}&lt;/ref&gt; but a variation with both notions of the spanning flavor is also encountered.&lt;ref name="Schrijver2003"/&gt;

It's also possible to define a useful notion by reversing all the arcs of an arborescence, i.e. making them all point to the root rather than away from it. Such digraphs are also designated by a variety of terms such as '''in-tree'''&lt;ref name="MehlhornSanders2008"&gt;{{cite book|author1=[[Kurt Mehlhorn]]|author2=[[Peter Sanders (computer scientist)|Peter Sanders]]|title=Algorithms and Data Structures: The Basic Toolbox|date=2008|publisher=Springer Science &amp; Business Media|isbn=978-3-540-77978-0|pages=52 |url=http://people.mpi-inf.mpg.de/~mehlhorn/ftp/Toolbox/Introduction.pdf}}&lt;/ref&gt; or '''anti-arborescence'''&lt;ref name="KorteVygen2012b"&gt;{{cite book|author1=Bernhard Korte|author2=Jens Vygen|title=Combinatorial Optimization: Theory and Algorithms|year=2012|publisher=Springer Science &amp; Business Media|isbn=978-3-642-24488-9|page=28|edition=5th}}&lt;/ref&gt; etc. [[W. T. Tutte]] distinguishes between the two cases by using the phrases ''arborescence diverging from'' [some root] and ''arborescence converging to'' [some root].&lt;ref&gt;{{citation|last1=Tutte|first1=W.T.|title=Graph Theory|publisher=Cambridge University Press|year=2001|isbn=978-0-521-79489-3|pages=126–127}}&lt;/ref&gt;

The number of rooted trees (or arborescences) with ''n'' nodes is given by the sequence:
: 0, 1, 1, 2, 4, 9, 20, 48, 115, 286, 719, 1842, 4766, 12486, ... {{OEIS|A000081}}.

==See also==
* [[Edmonds' algorithm]]
* [[Multitree]]

==References==
{{reflist|30em}}

== External links ==
*{{mathworld|title=Arborescence|urlname=Arborescence}}
*{{mathworld|title=Rooted Tree|urlname=RootedTree}}

{{DEFAULTSORT:Arborescence (Graph Theory)}}
[[Category:Trees (graph theory)]]
[[Category:Directed graphs]]


{{combin-stub}}</text>
      <sha1>plpjs9qfzdbu7zi4v9ta4ylo7iapgea</sha1>
    </revision>
  </page>
  <page>
    <title>Artur Avila</title>
    <ns>0</ns>
    <id>23579022</id>
    <revision>
      <id>871033108</id>
      <parentid>869747057</parentid>
      <timestamp>2018-11-28T14:18:13Z</timestamp>
      <contributor>
        <username>Brunolima17</username>
        <id>27863861</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10489">{{Use dmy dates|date=August 2014}}
{{Portuguese name|Cordeiro|de Melo}}
{{Infobox scientist
| name              = Artur Avila
| image             = Artur Ávila (cropped).jpg
| image_size        = 220px
| caption           = Avila at the [[Mathematical Research Institute of Oberwolfach]] in 2012.
| birth_name        = Artur Avila Cordeiro de Melo 
| birth_date        = {{Birth date and age|df=yes|1979|06|29}}
| birth_place       = [[Rio de Janeiro]], [[Brazil]]
| death_date        = 
| death_place       = 
| residence         = [[Rio de Janeiro]], [[Brazil]]&lt;br /&gt;[[Paris]], [[France]]
| citizenship       = {{hlist|Brazil|France}}&lt;ref&gt;http://www.math.jussieu.fr/~artur/cur.pdf&lt;/ref&gt;
| fields            = Mathematics
| workplaces        = [[Instituto Nacional de Matemática Pura e Aplicada|IMPA]], [[CNRS]]&lt;br&gt;[[Paris Diderot University|Paris Diderot University (Paris 7)]]&lt;br&gt;[[Instituto Nacional de Matemática Pura e Aplicada]]
| education         = [[Instituto Nacional de Matemática Pura e Aplicada]] (PhD and MS) &lt;br /&gt; [[Federal University of Rio de Janeiro]] (BS)
| thesis_title      = Bifurcações de tranformações unimodais sob os pontos de vistas topológico e métrico
| thesis_year       = 2001
| doctoral_advisor  = [[Welington de Melo]]
| known_for         = [[Dynamical system]]s&lt;br /&gt;[[Spectral theory]]&lt;br /&gt;Zorich–Kontsevich conjecture&lt;br /&gt;[[Ten martini problem]]
| awards            = [[Fields Medal]] (2014)&lt;br /&gt;[[Michael Brin Prize in Dynamical Systems]] (2011)&lt;br /&gt;[[EMS Prize]] (2008)&lt;br /&gt;[[Salem Prize]] (2006)&lt;br /&gt;Gold medal at the [[International Mathematical Olympiad]] (1995)
| doctoral_students = 
}}

'''Artur Avila Cordeiro de Melo''' (born 29 June 1979) is a French-Brazilian mathematician working primarily on [[dynamical system]]s and [[spectral theory]]. He is one of the winners of the 2014 [[Fields Medal]],&lt;ref&gt;[https://www.theguardian.com/science/alexs-adventures-in-numberland/2014/aug/13/fields-medals-2014-maths-avila-bhargava-hairer-mirzakhani The Guardian]&lt;/ref&gt; being the first Latin American to win such award. He is a researcher at both the [[Instituto Nacional de Matemática Pura e Aplicada|IMPA]] and the [[Centre national de la recherche scientifique|CNRS]] (working a half-year in each one).

== Biography ==
At the age of 16, Avila won a gold medal at the 1995 [[International Mathematical Olympiad]]&lt;ref&gt;[http://www.imo-official.org/team_r.aspx?code=BRA&amp;year=1995 Web-site of the International Mathematical Olympiad: Brazil at the 36th IMO (1995)]&lt;/ref&gt; and received a scholarship for the [[Instituto Nacional de Matemática Pura e Aplicada]] (IMPA) to M.S. while still attending high school in [[Colégio de São Bento]] and Colégio Santo Agostinho in Rio de Janeiro.&lt;ref&gt;{{Citation|last=Talarico |first=Bruna |title=Gênio da matemática carioca |date=16 January 2010 |work=O Dia Online |url=http://odia.terra.com.br/portal/rio/html/2010/1/genio_da_matematica_carioca_59005.html |language=Portuguese |deadurl=yes |archiveurl=https://web.archive.org/web/20100122050606/http://odia.terra.com.br/portal/rio/html/2010/1/genio_da_matematica_carioca_59005.html |archivedate=22 January 2010 }}&lt;/ref&gt; Later he enrolled in the [[Federal University of Rio de Janeiro]] (UFRJ), earning his B.S in mathematics.&lt;ref&gt;{{Citation|last=Moreira Salles |first=João |authorlink=João Moreira Salles |title=Artur tem um problema |date=January 2010 |work=Piauí |url=http://revistapiaui.estadao.com.br/edicao-40/vultos-das-ciencias/artur-tem-um-problema |language=Portuguese |deadurl=yes |archiveurl=https://web.archive.org/web/20150630063531/http://revistapiaui.estadao.com.br/edicao-40/vultos-das-ciencias/artur-tem-um-problema |archivedate=30 June 2015 |df=dmy }}&lt;/ref&gt;

At the age of 19, Avila began making his doctoral thesis on the theory of [[dynamical systems]]. In 2001 he finished it and received his [[Doctor of Philosophy|PhD]] from IMPA. That same year he moved abroad to France to do postdoctoral research.&lt;ref&gt;{{cite web|url = http://g1.globo.com/educacao/noticia/2014/08/pesquisador-brasileiro-ganha-premio-equivalente-nobel-de-matematica.html|title= Pesquisador brasileiro ganha prêmio equivalente a 'Nobel' de matemática|date= 12 August 2014|author= Vanessa Fajardo|publisher= G1}}&lt;/ref&gt; He works with one-dimensional dynamics and holomorphic functions.&lt;ref&gt;{{cite web|url=http://www.claymath.org/fas/research_fellows/Avila/|title=Artur Avila|publisher=Clay Mathematics Institute}}&lt;/ref&gt; Since 2003 he has worked as a researcher for the [[Centre National de la Recherche Scientifique]] (CNRS) in France, later becoming a research director in 2008. His post-doctoral supervisor was [[Jean-Christophe Yoccoz]].&lt;ref&gt;{{Interlanguage link multi|http://www.simonsfoundation.org/quanta/20140812-a-brazilian-wunderkind-who-calms-chaos/|en|3=A Brazilian Wunderkind Who Calms Chaos}}&lt;/ref&gt;

In 2005, at age 26, Avila became known amongst mathematicians for proving the "Conjecture of the ten martinis", a problem proposed in 1980 by the American [[mathematical physics#Mathematically rigorous physics|mathematical physicist]] [[Barry Simon]]. Simon promised to pay ten martini doses to whoever explained his theory about the behavior of "Schrödinger operators", mathematical tools related to [[quantum physics]]. Artur solved the problem along with mathematician [[Svetlana Jitomirskaya]]&lt;ref&gt;{{cite web|url=http://w3.impa.br/~avila/qmath.pdf|title= Solving the Ten Martini Problem|language=Portuguese}}&lt;/ref&gt;&lt;ref name="arxiv1"&gt;{{Cite book |arxiv = math/0503363|last1 = Avila|first1 = Artur|title = The Ten Martini Problem|volume = 690|pages = 5–16|last2 = Jitomirskaya|first2 = Svetlana|year = 2005|doi = 10.1007/3-540-34273-7_2|chapter = Solving the Ten Martini Problem|series = Lecture Notes in Physics|isbn = 978-3-540-31026-6}}&lt;/ref&gt; and was rewarded with a few rounds of martini.

== Prizes ==
[[File:Four_Fields_medallists_plus_epsilon.jpg|thumb|Four Fields medallists left to right (Artur Avila, [[:en:Martin Hairer|Martin Hairer]] (at back), [[:en:Maryam Mirzakhani|Maryam Mirzakhani]], with Maryam's daughter Anahita) and [[Manjul Bhargava]] at the ICM 2014 in Seoul]]
Later, as a research mathematician, he received in 2006 a [[CNRS Bronze Medal]] as well as the [[Salem Prize]], and was a [[Clay Research Fellow]]. He became the youngest professorial fellow (''directeur de recherches'') at the [[Centre national de la recherche scientifique|CNRS]] in 2008. The same year, he was awarded one of the ten prestigious [[European Mathematical Society]] prizes, and in 2009 he won the {{ill|Grand Prix Jacques Herbrand|fr}} from the [[French Academy of Sciences#Medals, awards and prizes|French Academy of Sciences]].{{citation needed|date=April 2016}} In 2017 he gave the [[Łojasiewicz Lecture]] (on the "One-frequency Schrödinger operators and the almost reducibility conjecture") at the [[Jagiellonian University|Jagiellonian University in Kraków]].&lt;ref&gt;{{Cite web|url=http://www.im.uj.edu.pl/en_GB/lojasiewicz/2017|title=2017 Lecture - Institute of Mathematics of the Jagiellonian University|website=www.im.uj.edu.pl|language=en|access-date=2017-06-25}}&lt;/ref&gt;

He was a [[List of International Congresses of Mathematicians Plenary and Invited Speakers|plenary speaker at the International Congress of Mathematicians]] in 2010.&lt;ref&gt;{{cite web|title=ICM Plenary and Invited Speakers since 1897|url=http://www.mathunion.org/db/ICM/Speakers/SortedByCongress.php|publisher=[[International Congress of Mathematicians]]}}&lt;/ref&gt;
In 2011, he was awarded the [[Michael Brin Prize in Dynamical Systems]].  He received the Early Career Award from the [[International Association of Mathematical Physics]] in 2012,&lt;ref&gt;{{Citation| title= The IAMP Early Career Award | url=http://www.iamp.org/page.php?page=page_award}}&lt;/ref&gt; [[TWAS Prize]] in 2013&lt;ref name="Prizes and Awards"&gt;{{Cite web |url=http://twas.org/article/twas-announces-2013-prize-winners |title=Prizes and Awards |date=2016 |publisher=The World Academy of Sciences}}&lt;/ref&gt; and the [[Fields Medal]] in 2014.&lt;ref&gt;{{Citation | title= 2014 IMU Prize Winners|url=http://www.mathunion.org/general/prizes/2014/prize-citations/}}&lt;/ref&gt;

== Mathematical work ==
In 2005, together with [[Svetlana Jitomirskaya]], he solved the [[ten martini problem]],&lt;ref name="arxiv1"/&gt; and together with [[Marcelo Viana]], he proved the Zorich–Kontsevich conjecture.&lt;ref&gt;{{Cite arxiv |eprint = math/0508508|last1 = Avila|first1 = Artur|title = Simplicity of Lyapunov spectra: Proof of the Zorich-Kontsevich conjecture|last2 = Jitomirskaya|first2 = Svetlana|year = 2005}}&lt;/ref&gt;

== Notes and references ==
{{Reflist|2}}

== Further reading ==
* {{cite journal |first=Thomas |last=Lin |first2=Erica |last2=Klarreich |authorlink2=Erica Klarreich |url=http://www.simonsfoundation.org/quanta/20140812-a-brazilian-wunderkind-who-calms-chaos/ |title=A Brazilian Wunderkind Who Calms Chaos |journal=Quanta Magazine |date=12 August 2014 }}
* [[João Moreira Salles|Moreira Salles, João]]. "[https://piaui.folha.uol.com.br/materia/artur-has-a-problem/ Artur has a problem]" (translated from the Portuguese by F. Thomson-Deveaux). ''Piauí Magazine''.

== External links ==
* [http://w3.impa.br/~avila/ Artur Avila's home page]
* [http://www.math.jussieu.fr/~artur/ Artur Avila's home page]
* [http://lattes.cnpq.br/8907835195811403 Artur Avila's Lattes Platform]
* {{MathGenealogy|id=53746}}
* [http://www.claymath.org/people/artur-avila-0 Claymath fellow page]
* {{IMO results |id=3801}}
* [http://chalkdustmagazine.com/interviews/in-conversation-with-artur-avila/ Interview with Artur Avila] ''Chalkdust Magazine''

{{Fields medalists}}
{{Portal bar|Mathematics|Biography}}

{{Authority control}}

{{DEFAULTSORT:Avila, Artur}}
[[Category:1979 births]]
[[Category:Living people]]
[[Category:21st-century mathematicians]]
[[Category:Fields Medalists]]
[[Category:International Mathematical Olympiad participants]]
[[Category:Mathematical analysts]]
[[Category:People from Rio de Janeiro (city)]]
[[Category:Members of the Brazilian Academy of Sciences]]
[[Category:Légion d'honneur recipients]]
[[Category:French mathematicians]]
[[Category:Dynamical systems theorists]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada alumni]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada researchers]]
[[Category:Brazilian expatriate academics]]
[[Category:French people of Brazilian descent]]
[[Category:21st-century Brazilian mathematicians]]
[[Category:TWAS laureates]]</text>
      <sha1>b80faneswrgtxqc1fu4f711qby8akjj</sha1>
    </revision>
  </page>
  <page>
    <title>Co-Hopfian group</title>
    <ns>0</ns>
    <id>55228538</id>
    <revision>
      <id>806518672</id>
      <parentid>801113543</parentid>
      <timestamp>2017-10-22T15:20:22Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Link to DAB page repaired</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10675">In the mathematical subject of [[group theory]], a '''co-Hopfian group''' is a [[Group (mathematics)|group]] that is not [[Isomorphism|isomorphic]] to any of its proper [[subgroup]]s. The notion is dual to that of a [[Hopfian group]], named after [[Heinz Hopf]]. &lt;ref&gt;[[Wilhelm Magnus]], Abraham Karrass, Donald Solitar, ''Combinatorial group theory. Presentations of groups in terms of generators and relations'', Reprint of the 1976 second edition, Dover Publications, Inc., Mineola, NY, 2004. {{ISBN|0-486-43830-9}}&lt;/ref&gt;

==Formal definition ==

A group ''G'' is called '''co-Hopfian''' if whenever &lt;math&gt;\varphi:G\to G&lt;/math&gt; is an [[Injective function|injective]] [[group homomorphism]] then  &lt;math&gt;\varphi&lt;/math&gt; is [[bijective function|bijective]], that is &lt;math&gt;\varphi(G)=G&lt;/math&gt;.&lt;ref name=DLH&gt;P. de la Harpe, [https://books.google.com/books?id=OEsJhiE_C00C&amp;pg=PA58&amp;dq=co-hopfian+group&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjy69bwksHVAhWS0YMKHdy-Dq4Q6AEIKDAA#v=onepage&amp;q=co-hopfian%20group&amp;f=false ''Topics in geometric group theory''.] Chicago Lectures in Mathematics. University of Chicago Press, Chicago, IL, 2000. {{ISBN|0-226-31719-6}}; p. 58&lt;/ref&gt;

==Examples and non-examples==

*Every finite group ''G'' is co-Hopfian.
*The infinite cyclic group &lt;math&gt;\mathbb Z&lt;/math&gt; is not co-Hopfian since &lt;math&gt;f:\mathbb Z\to \mathbb Z, f(n)=2n&lt;/math&gt; is an injective but non-surjective homomorphism.
*The additive group of real numbers &lt;math&gt;\mathbb R&lt;/math&gt; is not co-Hopfian, since  &lt;math&gt;\mathbb R&lt;/math&gt; is an infinite-dimensional vector space over &lt;math&gt;\mathbb Q&lt;/math&gt; and therefore, as a group &lt;math&gt;\mathbb R\cong \mathbb R\times \mathbb R&lt;/math&gt;.&lt;ref name=DLH/&gt; 
*The additive group of rational numbers &lt;math&gt;\mathbb Q&lt;/math&gt; and the quotient group &lt;math&gt;\mathbb Q/\mathbb Z&lt;/math&gt; are co-Hopfian.&lt;ref name=DLH/&gt;
*The multiplicative group &lt;math&gt;\mathbb Q^\ast&lt;/math&gt; of nonzero rational numbers is not co-Hopfian, since the map &lt;math&gt;\mathbb Q^\ast\to\mathbb Q^\ast, q\mapsto \operatorname{sign}(q)\,q^2&lt;/math&gt; is an injective but non-surjective homomorphism.&lt;ref name=DLH/&gt; In the same way, the group &lt;math&gt;\mathbb Q^{\ast}_+&lt;/math&gt; of positive rational numbers is not co-Hopfian.
*The multiplicative group &lt;math&gt;\mathbb C^\ast&lt;/math&gt; of nonzero complex numbers is not co-Hopfian.&lt;ref name=DLH/&gt;
*For every &lt;math&gt;n\ge 1&lt;/math&gt; the [[free abelian group]] &lt;math&gt;\mathbb Z^n&lt;/math&gt; is not co-Hopfian.&lt;ref name=DLH/&gt;
*For every &lt;math&gt;n\ge 1&lt;/math&gt; the [[free group]] &lt;math&gt;F_n&lt;/math&gt; is not co-Hopfian.&lt;ref name=DLH/&gt;
*There exists a finitely generated non-elementary (that is, not virtually cyclic)  [[virtually free group]] which is co-Hopfian. Thus a subgroup of finite index in a finitely generated co-Hopfian group need not be co-Hopfian, and being co-Hopfian is not a [[quasi-isometry]] invariant for finitely generated groups.&lt;ref name=COR/&gt;
*[[Baumslag–Solitar group]]s &lt;math&gt;BS(1,m)&lt;/math&gt;, where &lt;math&gt;m\ge 1&lt;/math&gt;, are not co-Hopfian.&lt;ref name=NP/&gt;
*If ''G'' is the [[fundamental group]] of a closed aspherical manifold with nonzero [[Euler characteristic]] (or with nonzero [[simplicial volume]] or nonzero [[L2-Betti number|L&lt;sup&gt;2&lt;/sup&gt;-Betti number]]), then ''G'' is co-Hopfian.&lt;ref name=B/&gt;
*If ''G'' is the fundamental group of a closed connected oriented irreducible 3-manifold ''M'' then ''G'' is co-Hopfian if and only if no finite cover of ''M'' is a torus bundle over the circle or the product of a circle and a closed surface.&lt;ref&gt;Shi Cheng Wang, and Ying Qing Wu, ''Covering invariants and co-Hopficity of 3-manifold groups.''
[[Proceedings of the London Mathematical Society]] '''68''' (1994), no. 1, pp. 203–224 &lt;/ref&gt;
*If ''G'' is an irreducible lattice in a real [[semi-simple Lie group]] and ''G'' is not a [[virtually free group]] then ''G'' is co-Hopfian.&lt;ref&gt;[[Gopal Prasad]]
''Discrete subgroups isomorphic to lattices in semisimple Lie groups''.  [[American Journal of Mathematics]] '''98''' (1976), no. 1, 241–261&lt;/ref&gt; E.g. this fact applies to the group &lt;math&gt;SL(n,\mathbb Z)&lt;/math&gt; for &lt;math&gt;n\ge 3&lt;/math&gt;.
*If ''G'' is a one-ended torsion-free [[word-hyperbolic group]] then ''G'' is co-Hopfian, by a result of [[Zlil Sela|Sela]].&lt;ref&gt;[[Zlil Sela]], 
''Structure and rigidity in (Gromov) hyperbolic groups and discrete groups in rank 1 Lie groups. II.''
[[Geometric and Functional Analysis]] '''7''' (1997), no. 3, pp. 561–593 &lt;/ref&gt;
*If ''G'' is the fundamental group of a complete finite volume smooth Riemannian ''n''-manifold (where ''n'' &gt; 2) of pinched negative curvature then ''G'' is co-Hopfian. &lt;ref&gt;I. Belegradek, 
''On Mostow rigidity for variable negative curvature''. [[Topology (journal)|Topology]] '''41''' (2002), no. 2, pp. 341–361 &lt;/ref&gt;
*The [[mapping class group]] of a closed hyperbolic surface is co-Hopfian.&lt;ref&gt;Nikolai Ivanov and John McCarthy, ''On injective homomorphisms between Teichmüller modular groups. I.'' [[Inventiones Mathematicae]] '''135''' (1999), no. 2, pp. 425–486 &lt;/ref&gt;
*The group [[Out(Fn)|Out(''F&lt;sub&gt;n&lt;/sub&gt;'')]] (where ''n''&gt;2) is co-Hopfian.&lt;ref&gt;[[Benson Farb]] and Michael Handel,
''Commensurations of Out(''F&lt;sub&gt;n&lt;/sub&gt;'')'', [[Publications Mathématiques de l'IHÉS]] '''105''' (2007), pp. 1–48&lt;/ref&gt;
*Delzant and Polyagailo gave a characterization of co-Hopficity for geometrically finite [[Kleinian group]]s of isometries of &lt;math&gt;\mathbb H^n&lt;/math&gt; without 2-torsion.&lt;ref&gt;Thomas Delzant and Leonid Potyagailo, ''Endomorphisms of Kleinian groups''. [[Geometric and Functional Analysis]] '''13''' (2003), no. 2, pp. 396–436 &lt;/ref&gt;
*A [[right-angled Artin group]] &lt;math&gt;A(\Gamma)&lt;/math&gt; (where &lt;math&gt;\Gamma&lt;/math&gt; is a finite nonempty graph) is not co-Hopfian; sending every standard generator of &lt;math&gt;A(\Gamma)&lt;/math&gt; to a power &lt;math&gt;&gt;1&lt;/math&gt; defines and endomorphism  of &lt;math&gt;A(\Gamma)&lt;/math&gt;  which is injective but not surjective.&lt;ref&gt;Montserrat Casals-Ruiz, ''Embeddability and quasi-isometric classification of partially commutative groups''.  [[Algebraic and Geometric Topology]] '''16''' (2016), no. 1, 597–620&lt;/ref&gt;
*A finitely generated torsion-free [[nilpotent group]] ''G'' may be either co-Hopfian or not co-Hopfian, depending on the properties of its associated rational [[Lie algebra]].&lt;ref name=B&gt; Igor Belegradek, ''On co-Hopfian nilpotent groups''. [[Bulletin of the London Mathematical Society]] '''35''' (2003), no. 6, pp. 805–811&lt;/ref&gt;&lt;ref name=COR&gt; Yves Cornulier, ''Gradings on Lie algebras, systolic growth, and cohopfian properties of nilpotent groups''. [[Bulletin de la Société Mathématique de France]] '''144''' (2016), no. 4, pp. 693–744  &lt;/ref&gt;
*If ''G'' is a [[relatively hyperbolic group]] and &lt;math&gt;\varphi:G\to G&lt;/math&gt; is an injective but non-surjective endomorphism of ''G'' then either &lt;math&gt;\varphi^k(G)&lt;/math&gt; is parabolic for some ''k'' &gt;1 or ''G'' splits over a virtually cyclic or a parabolic subgroup.&lt;ref&gt;[[Cornelia Druţu]] and [[Mark Sapir]], ''Groups acting on tree-graded spaces and splittings of relatively hyperbolic groups''.  [[Advances in Mathematics]] '''217''' (2008), no. 3, pp. 1313–1367 &lt;/ref&gt;  
*[[Grigorchuk group]] ''G'' of intermediate growth is not co-Hopfian.&lt;ref&gt;Igor Lysënok, ''A set of defining relations for the Grigorchuk group.'' {{icon ru}}
[[Matematicheskie Zametki]] '''38''' (1985), no. 4, 503–516 &lt;/ref&gt;
*[[Thompson groups|Thomposon group]] ''F'' is not co-Hopfian.&lt;ref&gt;Bronlyn Wassink, ''Subgroups of R. Thompson's group F that are isomorphic to F.'' Groups, Complexity, Cryptology '''3''' (2011), no. 2, 239–256 &lt;/ref&gt;
*There exists a [[finitely generated group]] ''G'' which is not co-Hopfian but has [[Kazhdan's property (T)]].&lt;ref&gt;Yann Ollivier, and [[Daniel Wise (mathematician)|Daniel Wise]], ''Kazhdan groups with infinite outer automorphism group''. [[Transactions of the American Mathematical Society]] '''359''' (2007), no. 5, pp. 1959–1976 &lt;/ref&gt;
*If ''G'' is Higman's [[Higman's embedding theorem|universal finitely presented group]] then ''G'' is not co-Hopfian, and ''G'' cannot be embedded in a finitely generated recursively presented co-Hopfian group.&lt;ref&gt;Charles F. Miller, and [[Paul Schupp]], ''Embeddings into Hopfian groups''.  [[Journal of Algebra]] '''17''' (1971), pp. 171–176 &lt;/ref&gt;

==Generalizations and related notions==

*A group ''G'' is called '''finitely co-Hopfian'''&lt;ref&gt;[[Martin Bridson]], Daniel Groves, Jonathan Hillman, [[Gaven Martin]], ''Cofinitely Hopfian groups, open mappings and kno complements.'' [[Groups, Geometry, and Dynamics]] '''4''' (2010), no. 4, pp. 693–707&lt;/ref&gt; if whenever &lt;math&gt;\varphi:G\to G&lt;/math&gt; is an injective endomorphism whose image has finite index in ''G'' then &lt;math&gt;\varphi(G)=G&lt;/math&gt;. For example, for &lt;math&gt;n\ge 2&lt;/math&gt; the [[free group]] &lt;math&gt;F_n&lt;/math&gt; is not co-Hopfian but it is finitely co-Hopfian.
*A finitely generated group ''G'' is called '''scale-invariant''' if there exists a nested sequence of subgroups of finite index of ''G'', each isomorphic to ''G'', and whose intersection is a finite group.&lt;ref name=NP&gt; Volodymyr Nekrashevych, and Gábor Pete, ''Scale-invariant groups''. [[Groups, Geometry, and Dynamics]] '''5''' (2011), no. 1, pp. 139–167&lt;/ref&gt; 
*A group ''G'' is called '''dis-cohopfian'''&lt;ref name=COR/&gt; if there exists an injective endomorphism &lt;math&gt;\varphi:G\to G&lt;/math&gt; such that &lt;math&gt;\bigcap_{n=1}^\infty \varphi^n(G)=\{1\}&lt;/math&gt;. 
*In [[coarse geometry]], a metric space ''X'' is called '''quasi-isometrically co-Hopf''' if every [[quasi-isometry|quasi-isometric embedding]] &lt;math&gt;f:X\to X&lt;/math&gt; is coarsely surjective (that is, is a quasi-isometry). Similarly, ''X'' is called '''coarsely co-Hopf''' if every [[coarse embedding]] &lt;math&gt;f:X\to X&lt;/math&gt; is coarsely surjective. &lt;ref&gt;Ilya Kapovich, and Anton Lukyanenko, [http://www.ams.org/journals/ecgd/2012-16-14/S1088-4173-2012-00246-9/S1088-4173-2012-00246-9.pdf ''Quasi-isometric co-Hopficity of non-uniform lattices in rank-one semi-simple Lie groups.'']  Conformal Geometry and Dynamics '''16''' (2012), pp. 269–282 &lt;/ref&gt;
*In [[metric geometry]], a metric space ''K'' is called '''quasisymmetrically co-Hopf''' if every [[quasisymmetric map|quasisymmetric embedding]] &lt;math&gt;K\to K&lt;/math&gt; is onto. &lt;ref&gt; Sergei Merenkov, ''A Sierpiński carpet with the co-Hopfian property''. [[Inventiones Mathematicae]] '''180''' (2010), no. 2, pp. 361–388&lt;/ref&gt;

==See also==
*[[Hopfian object]]

==References==
{{Reflist}}

==Further reading==
* K. Varadarajan,  [http://mat.uab.cat/pubmat/fitxers/download/FileType:pdf/FolderName:v36(1)/FileName:36192_21.pdf Hopfian and co-Hopfian Objects], Publicacions Matemàtiques  '''36''' (1992), no. 1, pp. 293–317

[[Category:Group theory]] [[Category:Algebra]]</text>
      <sha1>1k0sbnh839rx3li8c7snei2mw3z8pl4</sha1>
    </revision>
  </page>
  <page>
    <title>Comma-free code</title>
    <ns>0</ns>
    <id>40901</id>
    <revision>
      <id>866583941</id>
      <parentid>859988137</parentid>
      <timestamp>2018-10-31T07:10:12Z</timestamp>
      <contributor>
        <username>Veryproicelandic</username>
        <id>23790359</id>
      </contributor>
      <comment>added some links, removed that flag, re-stubbed it...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1133">{{Orphan|date=September 2018}}

A '''comma-free code''' is [[block code]] in which no [[concatenation]] of two [[code word]]s contains a valid code word that overlaps both.&lt;ref name="Society1958"&gt;{{cite journal |author1=S. W. Golomb |last2=Gordon |first2=Basil |author3=L. R. Welch |title=Comma-free Codes |journal=Canadian Journal of Mathematics |url=https://books.google.com/books?id=oRgtS14oa-sC&amp;pg=PA202 |year=1958 |publisher=Canadian Mathematical Society |pages=202–209 |doi=10.4153/CJM-1958-023-9}}&lt;/ref&gt;

Comma-free codes are also known as ''self-synchronizing block codes''&lt;ref name="KnuthChristmasLecture"&gt;{{cite AV media |people=Donald Knuth |date=11 December 2015 |title=Universal Commafree Codes |language=en |url=https://www.youtube.com/watch?v=48iJx8FVuis |access-date=6 February 2016 |publisher=Stanford University}}&lt;/ref&gt; because no [[synchronization]] is required to find the beginning of a code word.

== References ==
&lt;references/&gt;

== External links ==
* {{YouTube|id=48iJx8FVuis|title=Donald Knuth's 21st Annual Christmas Lecture: Universal Commafree Codes}}

[[Category:Coding theory]]


{{applied-math-stub}}</text>
      <sha1>q1i0td5872z9ibekf1oaqh6m5yw4do3</sha1>
    </revision>
  </page>
  <page>
    <title>Cubic form</title>
    <ns>0</ns>
    <id>6680683</id>
    <revision>
      <id>841057901</id>
      <parentid>765491283</parentid>
      <timestamp>2018-05-13T20:15:30Z</timestamp>
      <contributor>
        <ip>206.248.163.153</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3328">In [[mathematics]], a '''cubic form''' is a [[homogeneous polynomial]] of degree 3, and a '''cubic hypersurface''' is the [[zero set]] of a cubic form.  In the case of a cubic form in three variables, the zero set is a [[cubic plane curve]].

In {{harv|Delone|Faddeev|1964}}, [[Boris Delone]] and [[Dmitry Faddeev]] showed that binary cubic forms with integer coefficients can be used to parametrize [[order (ring theory)|orders]] in [[cubic field]]s. Their work was generalized in {{harv|Gan|Gross|Savin|2002|loc=§4}} to include all cubic rings,&lt;ref&gt;A '''cubic ring''' is a [[ring (mathematics)|ring]] that is isomorphic to '''Z'''&lt;sup&gt;3&lt;/sup&gt; as a [[Module (mathematics)|'''Z'''-module]].&lt;/ref&gt;&lt;ref&gt;In fact, [[Pierre Deligne]] pointed out that the correspondence works over an arbitrary [[Scheme (mathematics)|scheme]].&lt;/ref&gt; giving a [[discriminant]]-preserving [[bijection]] between [[Orbit (group theory)|orbits]] of a GL(2,&amp;nbsp;'''Z''')-[[Group action|action]] on the space of integral binary cubic forms and cubic rings up to [[isomorphism]].

The classification of real cubic forms &lt;math&gt;a x^3 + 3 b x^2 y + 3 c x y^2 + d y^3&lt;/math&gt; is linked to the classification of [[umbilical point]]s of surfaces. The [[equivalence class]]es of such cubics form a three-dimensional [[real projective space]] and the subset of [[parabolic form]]s define a surface – the [[umbilic torus]] or [[umbilic bracelet]].&lt;ref name=port&gt;{{Citation|first=Ian R.|last=Porteous|title=Geometric Differentiation, For the Intelligence of Curves and Surfaces|ISBN=978-0-521-00264-6|pp=350
|date=2001|publisher=Cambridge University Press| edition=2nd}}&lt;/ref&gt;

==Examples==
*[[Cubic plane curve]]
*[[Elliptic curve]]
*[[Fermat cubic]]
*[[Cubic 3-fold]]
*[[Koras–Russell cubic threefold]]
*[[Klein cubic threefold]]
*[[Segre cubic]]

==Notes==
{{reflist}}

==References==
*{{Citation
| last=Delone
| first=Boris
| author-link=Boris Delone
| last2=Faddeev
| first2=Dmitriĭ
| title=The theory of irrationalities of the third degree
| publisher=American Mathematical Society
| series=Translations of Mathematical Monographs
| volume=10
| year=1964
| origyear=1940, Translated from the Russian by Emma Lehmer and Sue Ann Walker
| mr=0160744
}}
*{{Citation
| last1=Gan
| first1=Wee-Teck
| last2=Gross
| first2=Benedict
| author2-link=Benedict Gross
| last3=Savin
| first3=Gordan
| title=Fourier coefficients of modular forms on ''G''&lt;sub&gt;2&lt;/sub&gt;
| year=2002
| journal=Duke Mathematical Journal
| volume=115
| number=1
| pages=105–169
| doi=10.1215/S0012-7094-02-11514-2
| mr=1932327
}}
*{{eom|id=c/c027260|first=V.A.|last= Iskovskikh|first2=V.L.|last2= Popov|author2-link=Vladimir L. Popov|title=Cubic form}}
*{{eom|id=c/c027270|first=V.A.|last= Iskovskikh|first2=V.L.|last2= Popov|author2-link=Vladimir L. Popov|title=Cubic hypersurface}}
*{{Citation | last1=Manin | first1=Yuri Ivanovich | author1-link=Yuri Ivanovich Manin | title=Cubic forms | origyear=1972 | url=https://books.google.com/books?id=W03vAAAAMAAJ | publisher=North-Holland | location=Amsterdam | edition=2nd | series=North-Holland Mathematical Library | isbn=978-0-444-87823-6 | mr=833513 | year=1986 | volume=4}}

[[Category:Homogeneous polynomials| ]]
[[Category:Multilinear algebra]]
[[Category:Algebraic geometry]]
[[Category:Algebraic varieties]]


{{algebraic-geometry-stub}}</text>
      <sha1>0vy20m5zwbvuebmz2j4shexnlrsyt3l</sha1>
    </revision>
  </page>
  <page>
    <title>De Donder–Weyl theory</title>
    <ns>0</ns>
    <id>33872518</id>
    <revision>
      <id>822455864</id>
      <parentid>798071830</parentid>
      <timestamp>2018-01-26T13:43:12Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8100">In [[mathematical physics]], the '''De Donder–Weyl theory''' is a generalization of the [[Hamiltonian formalism]] in the [[calculus of variations]] and [[classical field theory]] over [[spacetime]] which treats the space and time coordinates on equal footing. In this framework, the [[Hamiltonian formalism]] in [[mechanics]] is generalized to field theory in the way that a [[Field (physics)|field]] is represented as a system that varies both in space and in time. This generalization is different from the [[Canonical form|canonical]] [[Hamiltonian formalism]] in field theory which treats space and time variables differently and describes classical fields as infinite-dimensional systems evolving in time. 

{| style="margin:0 1em 1em; text-align:center; border:1px solid black; padding:10px; float:right;"
|-
|&lt;u&gt;De Donder–Weyl equations:&lt;/u&gt;
|-
|&lt;math&gt;\partial p^{i}_a / \partial x^{i} = -\partial H / \partial y^{a}&lt;/math&gt;
|-
|&lt;math&gt;\partial y^{a} / \partial x^{i} = \partial H / \partial p^{i}_a&lt;/math&gt;
|-
|}

== De Donder–Weyl formulation of field theory ==
The De Donder–Weyl theory is based on a change of variables known as [[Legendre transformation]]. Let ''x&lt;sup&gt;i&lt;/sup&gt;'' be [[spacetime]] coordinates, for ''i'' = 1 to ''n'' (with ''n'' = 4 representing 3 + 1 dimensions of space and time), and ''y&lt;sup&gt;a&lt;/sup&gt;'' field variables, for ''a'' = 1 to ''m'', and ''L'' the [[Lagrangian density]] 
:&lt;math&gt;L = L(y^{a},\partial_i y^{a},x^{i})&lt;/math&gt;
With the '''polymomenta''' ''p&lt;sup&gt;i&lt;/sup&gt;&lt;sub&gt;a&lt;/sub&gt;'' defined as
:&lt;math&gt;p^{i}_a = \partial L / \partial (\partial_i y^{a})&lt;/math&gt;
and  the '''De Donder–Weyl Hamiltonian function''' ''H'' defined as
:&lt;math&gt;H = p^{i}_a \partial_i y^{a} - L&lt;/math&gt;
the '''De Donder–Weyl equations''' are:&lt;ref&gt;Hanno Rund, 
"Hamilton-Jacobi Theory in the Calculus of Variations: Its Role in Mathematics and Physics", Van Nostrand, Reinhold, 1966.&lt;/ref&gt;
:&lt;math&gt;\partial p^{i}_a / \partial x^{i} = -\partial H / \partial y^{a} \, , \, \partial y^{a} / \partial x^{i} = \partial H / \partial p^{i}_a&lt;/math&gt;

This De Donder-Weyl Hamiltonian form of field equations is [[Covariance and contravariance of vectors|covariant]] and it is equivalent to the [[Euler-Lagrange equations]] when the Legendre transformation to the variables ''p&lt;sup&gt;i&lt;/sup&gt;&lt;sub&gt;a&lt;/sub&gt;'' and  ''H'' is not singular. The theory is a formulation of a [[covariant Hamiltonian field theory]] which is different from the [[Canonical form|canonical]] [[Hamiltonian formalism]] and for ''n'' = 1 it reduces to [[Hamiltonian mechanics]] (see also [[Calculus of variations#Action principle|action principle in the calculus of variations]]). 

[[Hermann Weyl]] in 1935 has developed the [[Hamilton-Jacobi theory]] for the De Donder–Weyl theory.&lt;ref&gt;Hermann Weyl, "Geodesic Fields in the Calculus of Variation for Multiple Integrals", Ann. Math. 36, 607 (1935). https://www.jstor.org/stable/1968645&lt;/ref&gt;

Similarly to the [[Hamiltonian formalism]] in mechanics formulated using the [[symplectic geometry]] of [[phase space]] 
the De Donder-Weyl theory can be formulated using the [[multisymplectic geometry]] or [[polysymplectic geometry]] and the geometry 
of [[jet bundle]]s. 

A generalization of the [[Poisson brackets]] to the De Donder–Weyl theory 
and the representation of De Donder–Weyl equations in terms of generalized [[Poisson brackets]] satisfying the [[Gerstenhaber algebra]] 
was found by Kanatchikov in 1993.&lt;ref&gt;Igor V. Kanatchikov: [https://arxiv.org/abs/hep-th/9312162v1 ''On the Canonical Structure of the De Donder–Weyl Covariant Hamiltonian Formulation of Field Theory I. Graded Poisson brackets and equations of motion''], arXiv:hep-th/9312162v1 (submitted on 20 Dec 1993).&lt;/ref&gt;

== History ==
The formalism, now known as De Donder–Weyl (DW) theory, was developed by [[Théophile De Donder]]&lt;ref&gt;Théophile De Donder, "Théorie invariantive du calcul des variations," Gauthier-Villars, 1930. [https://books.google.com/books?id=3kI7AQAAIAAJ&amp;dq=editions:LCCN39009801]&lt;/ref&gt;&lt;ref&gt;Frédéric Hélein: ''Hamiltonian formalisms for multidimensional calculus of variations and perturbation theory'' 
 In Haïm Brézis, Felix E. Browder, Abbas Bahri, Sergiu Klainerman, Michael Vogelius (ads.): ''Noncompact problems at the intersection of geometry, analysis, and topology'', American Mathematical Society, 2004, pp.&amp;nbsp;127–148, [https://books.google.com/books?id=eL0_cDTqloEC&amp;pg=PA131 p. 131], {{ISBN|0-8218-3635-8}},&lt;/ref&gt; and [[Hermann Weyl]]. Hermann Weyl made his proposal in 1934 being inspired by the work of [[Constantin Carathéodory]], which in turn was founded on the work of [[Vito Volterra]]. The work of De Donder on the other hand started from the theory of integral [[Invariant theory|invariants]] of [[Élie Cartan]].&lt;ref&gt;Roger Bielawski, [[Kevin Houston (mathematician)|Kevin Houston]], Martin Speight: ''Variational Problems in Differential Geometry'', London Mathematical Society Lecture Notes Series, no.&amp;nbsp;394, University of Leeds, 2009, {{ISBN|978-0-521-28274-1}}, [https://books.google.com/books?id=v4F7Ud8RYZoC&amp;pg=PA104 p. 104 f.]&lt;/ref&gt; The De Donder–Weyl theory has been a part of the calculus of variations since the 1930s and initially it found very few applications in physics. Recently it was applied in theoretical physics in the context of [[quantum field theory]]&lt;ref&gt;Igor V. Kanatchikov: [https://arxiv.org/abs/hep-th/9810/9810165v1 ''De Donder–Weyl theory and a hypercomplex extension of quantum mechanics to field theory''], arXiv:hep-th/9810165v1 (submitted on 21 October 1998)&lt;/ref&gt; and [[quantum gravity]].&lt;ref&gt; I.V. Kanatchikov: [https://arxiv.org/abs/gr-qc/0012/0012074v2 ''Precanonical Quantum Gravity: quantization without the space-time decomposition''], arXiv:gr-qc/0012074 (submitted on 20 December 2000)&lt;/ref&gt;

In 1970, Jedrzej Śniatycki, the author of ''Geometric quantization and quantum mechanics'', developed an invariant geometrical formulation of [[jet bundle]]s, building on the work of De Donder and Weyl.&lt;ref&gt;Jedrzej Śniatycki, 1970. Cited after: [[Yvette Kosmann-Schwarzbach]]: ''The Noether Theorems: Invariance and Conservation Laws in the 20th Century'', Springer, 2011, {{ISBN|978-0-387-87867-6}}, [https://books.google.com/books?id=e8F38Pu0YgEC&amp;pg=PA111 p. 111]&lt;/ref&gt; In 1999 Igor Kanatchikov has shown that the De Donder–Weyl covariant Hamiltonian field equations can be formulated in terms of [[Duffin–Kemmer–Petiau algebra|Duffin–Kemmer–Petiau matrices]].&lt;ref&gt;Igor V. Kanatchikov: [https://arxiv.org/abs/hep-th/9911/9911175v1 ''On the Duffin–Kemmer–Petiau formulation of the covariant Hamiltonian dynamics in field theory''], arXiv:hep-th/9911/9911175v1 (submitted on 23 November 1999)&lt;/ref&gt;

==See also==

*[[Hamiltonian field theory]]
*[[Covariant Hamiltonian field theory]]

== Further reading ==
* Selected papers on GEODESIC FIELDS, Translated and edited by D. H. Delphenich. Part 1 [http://mayaloop.gie.im/doc/geodesic_fields_-_pt._1.pdf], Part 2 [http://mayaloop.gie.im/doc/geodesic_fields_-_pt._2.pdf] 
* H.A. Kastrup, Canonical theories of Lagrangian dynamical systems in physics, Physics Reports, Volume 101, Issues 1–2, Pages 1-167 (1983). 
* Mark J. Gotay, James Isenberg, Jerrold E. Marsden, Richard Montgomery: "Momentum Maps and Classical Relativistic Fields. Part I: Covariant Field Theory" [https://arxiv.org/pdf/physics/9801019v2.pdf]
* Cornelius Paufler, Hartmann Römer: [http://wwwthep.physik.uni-mainz.de/~paufler/publications/DWeqMultSympGeom.pdf ''De Donder–Weyl equations and multisymplectic geometry''], Reports on Mathematical Physics, vol.&amp;nbsp;49 (2002), no.&amp;nbsp;2–3, pp.&amp;nbsp;325–334
* Krzysztof Maurin: ''The Riemann legacy: Riemannian ideas in mathematics and physics'', Part II, Chapter 7.16 ''Field theories for calculus of variation for multiple integrals'', Kluwer Academic Publishers, {{ISBN|0-7923-4636-X}}, 1997, [https://books.google.com/books?id=jlll448aDLEC&amp;pg=PA482 p.&amp;nbsp;482 ff.]

== References ==
{{reflist}}

{{DEFAULTSORT:De Donder-Weyl theory}}
[[Category:Calculus of variations]]
[[Category:Mathematical physics]]</text>
      <sha1>a01o1uewtbfil4937o8alwschumyadi</sha1>
    </revision>
  </page>
  <page>
    <title>Dehn–Sommerville equations</title>
    <ns>0</ns>
    <id>8276156</id>
    <revision>
      <id>808324037</id>
      <parentid>784071787</parentid>
      <timestamp>2017-11-02T05:06:27Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4508">In mathematics, the '''Dehn–Sommerville equations''' are a complete set of linear relations between the numbers of faces of different dimension of a [[simplicial polytope]]. For polytopes of dimension 4 and 5, they were found by [[Max Dehn]] in 1905.  Their general form was established by [[Duncan MacLaren Young Sommerville|Duncan Sommerville]] in 1927. The Dehn–Sommerville equations can be restated as a symmetry condition for the [[h-vector|''h''-vector'']] of the simplicial polytope and this has become the standard formulation in recent combinatorics literature. By duality, analogous equations hold for [[simple polytope]]s.

== Statement ==

Let ''P'' be a ''d''-dimensional [[simplicial polytope]]. For ''i'' = 0, 1, ..., ''d''&amp;minus;1, let ''f''&lt;sub&gt;''i''&lt;/sub&gt; denote the number of ''i''-dimensional [[face (geometry)|faces]] of ''P''. The sequence

: &lt;math&gt; f(P)=(f_0,f_1,\ldots,f_{d-1}) &lt;/math&gt;

is called the '''''f''-vector''' of the polytope ''P''. Additionally, set

: &lt;math&gt; f_{-1}=1, f_d=1. &lt;/math&gt;

Then for any ''k'' = &amp;minus;1, 0, &amp;hellip;, ''d''&amp;minus;2, the following '''Dehn–Sommerville equation''' holds:

:&lt;math&gt;\sum_{j=k}^{d-1} (-1)^{j} \binom{j+1}{k+1}  f_j = (-1)^{d-1}f_k. &lt;/math&gt;

When ''k'' = &amp;minus;1, it expresses the fact that [[Euler characteristic]] of a (''d''&amp;nbsp;&amp;minus;&amp;nbsp;1)-dimensional [[simplicial sphere]] is equal to 1 + (&amp;minus;1)&lt;sup&gt;''d''&amp;minus;1&lt;/sup&gt;.

Dehn–Sommerville equations with different ''k'' are not independent. There are several ways to choose a maximal independent subset consisting of &lt;math&gt;\left[\frac{d+1}{2}\right]&lt;/math&gt; equations. If ''d'' is even then the equations with ''k'' = 0, 2, 4, &amp;hellip;, ''d''&amp;minus;2 are independent. Another independent set consists of the equations with ''k'' = &amp;minus;1, 1, 3, &amp;hellip;, ''d''&amp;minus;3. If ''d'' is odd then the equations with ''k'' = &amp;minus;1, 1, 3, &amp;hellip;, ''d''&amp;minus;2 form one independent set and the equations with ''k'' = &amp;minus;1, 0, 2, 4, &amp;hellip;, ''d''&amp;minus;3 form another.

== Equivalent formulations ==
{{main|h-vector}}

Sommerville found a different way to state these equations:

&lt;math&gt; \sum_{i=-1}^{k-1}(-1)^{d+i}\binom{d-i-1}{d-k} f_i = 
\sum_{i=-1}^{d-k-1}(-1)^{i}\binom{d-i-1}{k} f_i, &lt;/math&gt;

where 0 &amp;le; k &amp;le; &amp;frac12;(d&amp;minus;1). This can be further facilitated introducing the notion of ''h''-vector of ''P''. For ''k'' = 0, 1, &amp;hellip;, ''d'', let

: &lt;math&gt; h_k = \sum_{i=0}^k (-1)^{k-i}\binom{d-i}{k-i}f_{i-1}. &lt;/math&gt;

The sequence

: &lt;math&gt;h(P)=(h_0,h_1,\ldots,h_d)&lt;/math&gt;

is called the [[h-vector|''h''-vector]] of ''P''. The ''f''-vector and the ''h''-vector uniquely determine each other through the relation

: &lt;math&gt; \sum_{i=0}^{d}f_{i-1}(t-1)^{d-i}=\sum_{k=0}^{d}h_{k}t^{d-k}. &lt;/math&gt;

Then the Dehn–Sommerville equations can be restated simply as

: &lt;math&gt; h_k = h_{d-k} \quad\textrm{for}\quad 0\leq k\leq d. &lt;/math&gt;

The equations with 0 &amp;le; k &amp;le; &amp;frac12;(d&amp;minus;1) are independent, and the others are manifestly equivalent to them.

[[Richard P. Stanley|Richard Stanley]] gave an interpretation of the components of the ''h''-vector of a simplicial convex polytope ''P'' in terms of the [[projective variety|projective]] [[toric variety]] ''X'' associated with (the dual of) ''P''. Namely, they are the dimensions of the even [[intersection cohomology]] groups of ''X'':

: &lt;math&gt; h_k=\operatorname{dim}_{\mathbb{Q}}\operatorname{IH}^{2k}(X,\mathbb{Q}) &lt;/math&gt;

(the odd [[intersection cohomology]] groups of ''X'' are all zero). In this language, the last form of the Dehn–Sommerville equations, the symmetry of the ''h''-vector, is a manifestation of the [[Poincaré duality]] in the intersection cohomology of ''X''.

==References==

* [[Branko Grünbaum]], ''Convex polytopes''. Second edition. Graduate Texts in Mathematics, 221, Springer, 2003 {{ISBN|0-387-00424-6}}
* [[Richard P. Stanley|Richard Stanley]], ''Combinatorics and commutative algebra''. Second edition. Progress in Mathematics, 41. Birkhäuser Boston, Inc., Boston, MA, 1996. x+164 pp. {{ISBN|0-8176-3836-9}}
* [[Duncan Sommerville]] (1927) [https://www.jstor.org/stable/94871 The relations connecting the angle sums and volume of a polytope in space of n dimensions] [[Proceedings of the Royal Society]] Series A 115:103–19, weblink from [[JSTOR]].
* [[Günter M. Ziegler|G. Ziegler]], ''Lectures on Polytopes'', [[Springer-Verlag|Springer]], 1998. {{ISBN|0-387-94365-X}}

{{DEFAULTSORT:Dehn-Sommerville equations}}
[[Category:Polyhedral combinatorics]]</text>
      <sha1>a2lbj1by06s24lmbsukkog3olp7velb</sha1>
    </revision>
  </page>
  <page>
    <title>Discriminative model</title>
    <ns>0</ns>
    <id>12155912</id>
    <revision>
      <id>871155564</id>
      <parentid>869147753</parentid>
      <timestamp>2018-11-29T08:36:11Z</timestamp>
      <contributor>
        <ip>193.175.154.19</ip>
      </contributor>
      <comment>Removed redundant information</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14567">{{Machine learning bar}}

'''Discriminative models''', also refer to '''conditional models''', are a class of models used in statistics [[statistical classification]], especially in [[Supervised learning|supervised]] [[machine learning]]. The approaches used in [[supervised learning]] can be categorized into discriminative models or [[Generative model|generative models]]. The typical discriminative learning approaches include [[Logistic regression|Logistic Regression]](LR), [[Support vector machine|Support Vector Machine]](SVM), conditional random fields(CRFs)(specified over an undirected graph), and etc. The typical generative model approaches contain [[Naive Bayes]], [[Gaussian mixture model|Gaussian Mixture Model]], and etc. 

== Definition ==
Unlike the generative modelling, which studies from the [[Joint probability distribution|joint probability]] &lt;math&gt;P(x,y)&lt;/math&gt;, the discriminative modeling studies the &lt;math&gt;P(y|x)&lt;/math&gt;or the direct maps the given unobserved variable (target) &lt;math&gt;x&lt;/math&gt; a class label &lt;math&gt;y&lt;/math&gt; depended on the observed variables (training samples). In practical field of object recognition, &lt;math&gt;x&lt;/math&gt;is likely to be a vector (i.e. raw pixels, features extracted from image or so). Within a probabilistic framework, this is done by modeling the [[conditional probability distribution]] &lt;math&gt;P(y|x)&lt;/math&gt;, which can be used for predicting &lt;math&gt;y&lt;/math&gt; from &lt;math&gt;x&lt;/math&gt;. Notice that there is still distinction between the conditional model and discriminative model, though most of the time, they are just categorised as discriminative model.

==== Pure Discriminative Model vs. Conditional Model ====
Conditional Model models the conditional probability distribution while the traditional discriminative model tries to optimize on mapping the input around the most similar trained samples.&lt;ref name=":0"&gt;{{Cite web|url=http://demo.clab.cs.cmu.edu/fa2015-11711/images/e/e5/DiscriminativeModels.pdf|title=Discriminative Models|last=Ballesteros|first=Miguel|date=|website=|archive-url=|archive-date=|dead-url=|access-date=October 28, 2018}}&lt;/ref&gt;

== Typical Discriminative Modelling Approaches&lt;ref name=":1"&gt;{{Cite web|url=http://www.cs.toronto.edu/~rfm/pubs/sdl.ps|title=An introduction to structured discriminative learning|last=Memisevic|first=Roland|date=December 21, 2006|website=|archive-url=|archive-date=|dead-url=|access-date=October 29, 2018}}&lt;/ref&gt; ==
The following approach is based on the assumption that given the training data-set &lt;math&gt;D=\{(x_i;y_i)|i\leq N\in \mathbb{Z}\}&lt;/math&gt;, where &lt;math&gt;y_i&lt;/math&gt;is the corresponding output for the input &lt;math&gt;x_i&lt;/math&gt;.

=== Linear Classifier ===
Using the [[Linear classifier|Linear Classifier]] method, we wish to use the function &lt;math&gt;f(x)&lt;/math&gt;to simulate the behavior of what we observed from the training data-set. Using the joint feature vector &lt;math&gt;\phi(x,y)&lt;/math&gt;, the decision function is defined as:&lt;blockquote&gt;&lt;math&gt;f(x,w)=\arg max_y w^T \phi(x,y)&lt;/math&gt;&lt;/blockquote&gt;According to Memisevic's interpretation&lt;ref name=":1" /&gt;, &lt;math&gt;w^T \phi(x,y)&lt;/math&gt;, which is also &lt;math&gt;c(x,y;w)&lt;/math&gt;computes a score which measures the computability of the input &lt;math&gt;x&lt;/math&gt;with the potential output &lt;math&gt;y&lt;/math&gt;. Then the &lt;math&gt;\arg max&lt;/math&gt;determines the class with the highest score.

=== Logistic Regression (LR) ===
Since the [[0-1 loss function]] is a commonly used one in the decision theory, the conditional probability distribution &lt;math&gt;P(y|x;w)&lt;/math&gt;, where &lt;math&gt;w&lt;/math&gt;is a parameter vector for optimizing the training data, could be reconsidered as following for the logistics regression model:&lt;blockquote&gt;&lt;math&gt;P(y|x;w)= \frac{1}{Z(x;w)} \exp(w^T\phi(x,y))
&lt;/math&gt;, with&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;Z(x;w)= \textstyle \sum_{y}  \displaystyle\exp(x^T\phi(x,y))&lt;/math&gt;&lt;/blockquote&gt;The equation above is the [[Logistic regression|Logistic Regression]]. Notice that a major distinction between models is their way of introducing posterior probability. Posterior probability is inferred from the parametric model. We then can maximize the parameter by following equation:&lt;blockquote&gt;&lt;math&gt;L(w)=\textstyle \sum_{i} \displaystyle \log p(y^i|x^i;w)&lt;/math&gt;&lt;/blockquote&gt;It could also be replaced by the [[Log loss|log-loss]] equation below:&lt;blockquote&gt;&lt;math&gt;l^\log (x^i, y^i,c(x^i;w)) = -\log p(y^i|x^i;w) = \log Z(x^i;w)-w^T\phi(x^i,y^i)&lt;/math&gt;&lt;/blockquote&gt;Since the [[Log loss|log-loss]] is differentiable, gradient-based method is a possible way to optimize the model. Global optimum is guaranteed because the objective function is convex. Gradient of log likelihood is presented by:  &lt;blockquote&gt;&lt;math&gt;\frac{\partial L(w)}{\partial w} = \textstyle \sum_{i} \displaystyle \phi(x^i,y^i) - E_{p(y|x^i;w)} \phi(x^i,y)&lt;/math&gt;&lt;/blockquote&gt;where &lt;math&gt;E_{p(y|x^i;w)}&lt;/math&gt;is the expectation of &lt;math&gt;p(y|x^i;w)&lt;/math&gt;.

The above method will provide efficient computation for the relative small number of classification.

== Contrast with Generative Model ==

=== Contrast in Approaches ===
Let's say we are given the &lt;math&gt;m&lt;/math&gt; class labels(classification) and &lt;math&gt;n&lt;/math&gt; feature variables, &lt;math&gt;Y:\{y_1, y_2,\ldots,y_m\}, X:\{x_1,x_2,\ldots,x_n \}&lt;/math&gt;, as the training samples. 

Generative model takes the joint probability &lt;math&gt;P(x,y)&lt;/math&gt;, where &lt;math&gt;x&lt;/math&gt; is the input and &lt;math&gt;y&lt;/math&gt; the label, and predicts the most possible known label &lt;math&gt;\widetilde{y}\in Y&lt;/math&gt; for the unknown variable &lt;math&gt;\widetilde{x}&lt;/math&gt; using [[Bayes' theorem|Bayes Rules]].&lt;ref name=":2"&gt;{{Cite book|url=http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.9829|title=On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes|last=Ng|first=Andrew Y.|last2=Jordan|first2=Michael I.|date=2001}}&lt;/ref&gt;

Discriminative models, as opposed to [[generative model]]s, do not allow one to generate samples from the [[joint distribution]] of observed and target variables.  However, for tasks such as [[classification (machine learning)|classification]] and [[regression analysis|regression]] that do not require the joint distribution, discriminative models can yield superior performance (in part because they have fewer variables to compute).&lt;ref&gt;{{Cite journal|last=Singla|first=Parag|last2=Domingos|first2=Pedro|date=2005|title=Discriminative Training of Markov Logic Networks|url=http://dl.acm.org/citation.cfm?id=1619410.1619472|journal=Proceedings of the 20th National Conference on Artificial Intelligence - Volume 2|series=AAAI'05|location=Pittsburgh, Pennsylvania|publisher=AAAI Press|pages=868–873|isbn=157735236X}}&lt;/ref&gt;&lt;ref&gt;J. Lafferty, A. McCallum, and F. Pereira. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In ''ICML'', 2001.&lt;/ref&gt;&lt;ref name=":2" /&gt;  On the other hand, generative models are typically more flexible than discriminative models in expressing dependencies in complex learning tasks.  In addition, most discriminative models are inherently [[supervised learning|supervised]] and cannot easily support [[unsupervised learning]]. Application-specific details ultimately dictate the suitability of selecting a discriminative versus generative model.

Discriminative models and generative models also differ in introducing the [[Posterior probability|posterior possibility]]. &lt;ref name=":3"&gt;{{Cite web|url=https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/Bishop-Sicily-05.pdf|title=Comparison of Generative and Discriminative Techniques for Object Detection and Classification|last=Ulusoy|first=Ilkay|date=May 2016|website=|archive-url=|archive-date=|dead-url=|access-date=October 30, 2018}}&lt;/ref&gt; To maintain the least expected loss, the minimization of result's misclassification should be acquired. In the discriminative model, the posterior probabilities, &lt;math&gt;P(y|x) &lt;/math&gt;, is inferred from a parametric model, where the parameters come from the training data. Points of estimation of the parameters are obtained from the maximization of likelihood or distribution computation over the parameters. On the other hand, considering the generative models focuses on the joint probability, the class posterior possibility &lt;math&gt;P(k)&lt;/math&gt; is considered in [[Bayes' theorem|Bayes' Theorem]], which is &lt;math&gt;P(y|x) = \frac{p(x|y)p(y)}{\textstyle \sum_{i}p(x|i)p(i) \displaystyle}=\frac{p(x|y)p(y)}{p(x)}&lt;/math&gt;.&lt;ref name=":3" /&gt;

=== Advantages vs. Disadvantages in Application ===
In the repeated experiments, Logistics Regression and Naive Bayes are applied here for different models on binary classification task, discriminative learning results lower asymptotic errors, while generative one results in higher asymptotic errors faster.&lt;ref name=":2" /&gt;  However, Ulusoy and Bishop's joint work, ''Comparison of Generative and Discriminative Techniques for Object Detection and Classification'', they state that the above statement is true only when the model is the appropriate one for data(i.e.the data distribution is correctly modeled by the generative model).

==== Advantages ====
Significant advantages of using discriminative modeling are:

* Higher accuracy, which mostly leads to better learning result.
* The approach allows simplification of the input and provides a direct approach to &lt;math&gt;P(y|x)&lt;/math&gt;
* Saves calculation resource
* Lower asymptotic errors

Compared with the advantages of using generative modeling:

* Take all data into consideration, which could results in slower processing as a disadvantage
* Requires less training sample
* A flexible framework that could easily cooperate with other needs of the application

==== Disadvantages ====

* Training method usually requires multiple numerical optimization techniques&lt;ref name=":0" /&gt;
* Similarly, by the definition, the discriminative model will need the combination of multiple subtasks for a solving complex real-world problem&lt;ref name=":1" /&gt;

== Optimizations in Applications ==
Since both advantages and disadvantages present on the two way of modeling, combining both approaches will be a good modeling in practice. For example, in Marras' article ''A Joint Discriminative Generative Model for Deformable Model Construction and Classification''&lt;ref&gt;{{Cite web|url=https://ibug.doc.ic.ac.uk/media/uploads/documents/pid4666647.pdf|title=A Joint Discriminative Generative Model for Deformable Model Construction and Classification|last=Marras|first=Ioannis|date=2017|website=|archive-url=|archive-date=|dead-url=|access-date=5 November 2018}}&lt;/ref&gt;, they applied the combination of two modeling on face classification of the models, and receive a higher accuracy than the traditional approach.  

Similarly, Kelm&lt;ref&gt;{{Cite web|url=http://www.professeurs.polymtl.ca/christopher.pal/icpr06/icpr06_combining.pdf|title=Combining Generative and Discriminative Methods for Pixel Classification with Multi-Conditional Learning|last=Kelm|first=B. Michael|date=|website=|archive-url=|archive-date=|dead-url=|access-date=5 November 2018}}&lt;/ref&gt; also proposed the combination of two modeling for pixel classification in his article ''Combining Generative and Discriminative Methods for Pixel Classification with Multi-Conditional Learning''.    

During the process of extracting the discriminative features prior to the clustering, [[Principal component analysis|Principal Component Analysis]](PCA), though commonly used, is not a necessarily discriminative approach. In contrast, LDA is a discriminative one&lt;ref&gt;{{Cite web|url=https://www.ijcai.org/Proceedings/15/Papers/552.pdf|title=A Joint Optimization Framework of Sparse Coding and Discriminative Clustering|last=Wang|first=Zhangyang|date=2015|website=|archive-url=|archive-date=|dead-url=|access-date=5 November 2018}}&lt;/ref&gt;. [[Linear discriminant analysis]](LDA), provides an efficient way of eliminating the disadvantage we list above. As we know, the discriminative model needs a combination of multiple subtasks before classification, and LDA  provides appropriate solution towards this problem by reducing dimension.   

In ''Beyerlein''&lt;nowiki/&gt;'s paper, ''DISCRIMINATIVE MODEL COMBINATION''&lt;ref&gt;{{Cite web|url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.454.9567&amp;rep=rep1&amp;type=pdf|title=DISCRIMINATIVE MODEL COMBINATION|last=Beyerlein|first=Peter|date=|website=|archive-url=|archive-date=|dead-url=|access-date=5 November 2018}}&lt;/ref&gt;, the discriminative model combination provides a new approach in auto speech recognition. It not only helps to optimize the integration of all kinds of models into one log-linear posterior probability distribution. The combination also aims at minimizing the empirical word error rate of training samples.  



In the article, A Unified and Discriminative Model for Query Refinement&lt;ref&gt;{{Cite web|url=https://s3.amazonaws.com/academia.edu.documents/29504968/a_unified_and_discriminative_model_for_query_refinement.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&amp;Expires=1541483095&amp;Signature=9fL4Sk8%2BwdN164bngW%2BAHaIomh0%3D&amp;response-content-disposition=inline%3B%20filename%3DA_unified_and_discriminative_model_for_q.pdf|title=A Unified and Discriminative Model for Query Refinement|last=Guo|first=Jiafeng|date=|website=|archive-url=|archive-date=|dead-url=|access-date=5 November 2018}}&lt;/ref&gt;, Guo and his partners used a unified discriminative model in query refinement using linear classifier successfully obtained a much higher accuracy rate. The experiment they designed also consider generative model as a comparison with the unified model. Just as expected in the real-world application, the generative model performed the poorest in among of the models, including the models without their improvement.  

==Types==
{{prose|date=February 2012}}
Examples of discriminative models used in machine learning include:
*[[Logistic regression]], a type of [[generalized linear model|generalized linear regression]] used for predicting [[Bernoulli distribution|binary]] or [[categorical distribution|categorical]] outputs (also known as [[maximum entropy classifier]]s)
*[[Support vector machines]]
*[[Boosting (meta-algorithm)]]
*[[Conditional random field]]s
*[[Linear regression]]
*[[Neural network]]s
*[[Linear discriminant analysis|Linear Discriminant Analysis]] (The result could be used as a linear classifier.)
*[[Random Forest|Random forest]]s
*[[Perceptron]]s

== See also ==
* [[Generative model]]

==References==
{{reflist|30em}}

[[Category:Regression models]]
[[Category:Machine learning]]

{{Portal|Statistics}}
{{Statistics|state=expanded}}

{{statistics-stub}}
{{comp-sci-stub}}</text>
      <sha1>qzvi9860g51upc93zz3orderflvlw9y</sha1>
    </revision>
  </page>
  <page>
    <title>Erdős–Nagy theorem</title>
    <ns>0</ns>
    <id>20852937</id>
    <revision>
      <id>569825137</id>
      <parentid>479208383</parentid>
      <timestamp>2013-08-23T06:30:03Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fixes / special characters in sortkey fixed using [[Project:AWB|AWB]] (9440)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1907">The '''Erdős–Nagy theorem''' is a result in [[discrete geometry]] stating that a non-convex [[simple polygon]] can be made into a [[convex polygon]] by a finite sequence of flips.  The ''flips'' are defined by taking a convex hull of a polygon and [[Reflection (mathematics)|reflecting]] a pocket with respect to the boundary edge.  The theorem is named after [[mathematician]]s [[Paul Erdős]] and [[Béla Szőkefalvi-Nagy]].

== History ==
[[Paul Erdős]] conjectured the result in 1935 as a problem in the ''[[American Mathematical Monthly]]'', and Szőkefalvi-Nagy published a proof in 1939.  The problem has a curious history and had been repeatedly rediscovered, until [[Branko Grünbaum]] surveyed the results in 1995.  As it turns out, the original proof had a delicate mistake, which has been since corrected.

== References ==
* [[Branko Grünbaum]], How to convexify a polygon, ''[[Geombinatorics]]'', 5 (1995), 24–30.
* [[Godfried Toussaint]], [http://www.cccg.ca/proceedings/1999/fp19.pdf The Erdős–Nagy Theorem and its Ramifications], ''Proc. 11th Canadian Conference on Computational Geometry'' (1999), 219–236.
* Branko Grünbaum and Joseph Zaks, [http://www.math.washington.edu/~grunbaum/Convexification2.pdf Convexification of polygons by flips and by flipturns], ''Discrete Math.'' 241 (2001), 333–342.
* [[Erik Demaine|E.D. Demaine]], B. Gassend, [[Joseph O'Rourke (professor)|J. O'Rourke]], G.T. Toussaint, [http://erikdemaine.org/papers/Flips_DCG20/paper.ps All polygons flip finitely right?] ''Surveys on discrete and computational geometry'', 231–255, in ''Contemp. Math.'', 453, Amer. Math. Soc., Providence, RI, 2008.

== External links ==
* [http://www.cs.mcgill.ca/~cs507/projects/1998/mas/main2.html The convexification of a simple polygon]

{{DEFAULTSORT:Erdos-Nagy Theorem}}
[[Category:Theorems in discrete geometry]]
[[Category:Paul Erdős]]


{{geometry-stub}}</text>
      <sha1>0mhinlkhc1t4zq7sucj8hft7bmn01q6</sha1>
    </revision>
  </page>
  <page>
    <title>Erdős–Rado theorem</title>
    <ns>0</ns>
    <id>22844355</id>
    <revision>
      <id>676218786</id>
      <parentid>676218760</parentid>
      <timestamp>2015-08-15T14:36:18Z</timestamp>
      <contributor>
        <username>Denisarona</username>
        <id>4770293</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/77.103.109.5|77.103.109.5]] ([[User talk:77.103.109.5|talk]]) to last version by EmilJ</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1878">In [[partition calculus]], part of [[combinatorial set theory]], which is a branch of mathematics, the '''Erdős–Rado theorem'''  is a basic result, extending [[Ramsey's theorem]] to uncountable sets.

==Statement of the theorem==
If ''r'' ≥ 0  is finite, ''κ'' is an infinite cardinal, then
:&lt;math&gt;
\exp_r(\kappa)^+\longrightarrow(\kappa^+)^{r+1}_\kappa
&lt;/math&gt;
where exp&lt;sub&gt;0&lt;/sub&gt;(κ) = ''κ'' and inductively exp&lt;sub&gt;''r''+1&lt;/sub&gt;(κ)=2&lt;sup&gt;exp&lt;sub&gt;''r''&lt;/sub&gt;(κ)&lt;/sup&gt;. This is sharp in the sense that exp&lt;sub&gt;''r''&lt;/sub&gt;(κ)&lt;sup&gt;+&lt;/sup&gt; cannot be replaced by exp&lt;sub&gt;''r''&lt;/sub&gt;(κ) on the left hand side.

The above partition symbol describes the following statement. If ''f'' is a coloring of the ''r+1''-element subsets of a set of cardinality exp&lt;sub&gt;''r''&lt;/sub&gt;(κ)&lt;sup&gt;+&lt;/sup&gt;,  in ''κ'' many colors, then there is a homogeneous set of cardinality ''κ&lt;sup&gt;+&lt;/sup&gt;'' (a set, all whose ''r+1''-element subsets get the same ''f''-value).

==References==
*{{citation|mr=0795592
|last=Erdős|first= Paul|author1-link=Paul Erdős|last2= Hajnal|first2= András|author2-link=András Hajnal|last3= Máté|first3= Attila|last4= Rado|first4= Richard|author4-link=Richard Rado
|title=Combinatorial set theory: partition relations for cardinals
|series=Studies in Logic and the Foundations of Mathematics|volume= 106|publisher= North-Holland Publishing Co., |place=Amsterdam|year= 1984| isbn= 0-444-86157-2 }}
*{{citation|mr=0081864
|last=Erdős|first= P.|author1-link=Paul Erdős|last2= Rado|first2= R.|author2-link=Richard Rado
|title=A partition calculus in set theory.
|journal=Bull. Amer. Math. Soc. |volume=62 |year=1956|pages= 427–489
|url=http://www.ams.org/bull/1956-62-05/S0002-9904-1956-10036-0/|doi=10.1090/S0002-9904-1956-10036-0}}

{{DEFAULTSORT:Erdos-Rado theorem}}
[[Category:Set theory]]
[[Category:Theorems in combinatorics]]
[[Category:Paul Erdős]]</text>
      <sha1>6sc4jns8x8vkoiiax4u3r366rmg29p0</sha1>
    </revision>
  </page>
  <page>
    <title>Esscher principle</title>
    <ns>0</ns>
    <id>16204398</id>
    <revision>
      <id>758178173</id>
      <parentid>748791651</parentid>
      <timestamp>2017-01-03T22:46:36Z</timestamp>
      <contributor>
        <username>Klbrain</username>
        <id>11677590</id>
      </contributor>
      <comment>Removing stale merge proposal from January 2014; no case made, no discussion over 3 years</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="641">The '''Esscher principle''' is an [[insurance premium principle]]. It is given by &lt;math&gt;\pi[X,h]=E[Xe^{hX}]/E[e^{hX}]&lt;/math&gt;, where &lt;math&gt;h&lt;/math&gt; is a strictly positive parameter. This premium is the [[net premium]] for a risk &lt;math&gt;Y=Xe^{hX}/m_X(h)&lt;/math&gt;, where &lt;math&gt;m_X(h)&lt;/math&gt; denotes the [[moment generating function]].

The Esscher principle is a [[risk measure]] used in actuarial sciences that derives from the [[Esscher transform]]. This risk measure does not respect the  positive homogeneity property of [[coherent risk measure]] for &lt;math&gt;h&gt;0&lt;/math&gt;.

==References==
{{Reflist}}

{{bank-stub}}

[[Category:Actuarial science]]</text>
      <sha1>ren1tmfognd2duvbxa0gdb2k81jxl92</sha1>
    </revision>
  </page>
  <page>
    <title>Euler measure</title>
    <ns>0</ns>
    <id>57857677</id>
    <revision>
      <id>862708932</id>
      <parentid>858628645</parentid>
      <timestamp>2018-10-06T05:17:03Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1038">In [[measure theory]], the '''Euler measure''' of a [[polyhedral set]] equals the [http://mathworld.wolfram.com/EulerIntegral.html Euler integral] of its [[indicator function]].

==The magnitude of an Euler measure==

By induction, it is easy to show that independent of [[dimension]], the Euler measure of a [[Closed set|closed]] [[Bounded set|bounded]] [[Convex polytope|convex polyhedron]] always equals 1, while the Euler measure of a ''d''-D [[Subspace topology|relative]]-[[Open set|open]] [[bounded convex polyhedron]] is &lt;math&gt;(-1)^d&lt;/math&gt;.&lt;ref name="Euler Measure"&gt;{{cite web | url=http://mathworld.wolfram.com/EulerMeasure.html | title=Euler Measure | publisher=Wolfram MathWorld | work=Euler Measure | accessdate=7 July 2018 | author=Weisstein, Eric W.}}&lt;/ref&gt;

==See also==

* [[Measure (mathematics)|Measure theory]]

==Notes==
{{Reflist}}

==External links==

* [https://arxiv.org/abs/math/0204009 ''Exponentiation and Euler measure'']

[[Category:Measures (measure theory)]]
[[Category:Measure theory]]


{{analysis-stub}}</text>
      <sha1>trd1nhb8ivbw7qv0b4z6mbj2m9vfuhk</sha1>
    </revision>
  </page>
  <page>
    <title>Frank Morgan (mathematician)</title>
    <ns>0</ns>
    <id>20185599</id>
    <revision>
      <id>837870042</id>
      <parentid>806571932</parentid>
      <timestamp>2018-04-23T14:54:40Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4905">{{For|the actor "Frank Morgan"|Frank Morgan}}
{{Infobox scientist
|name              = Frank Morgan
|image             =
|caption           = Frank Morgan
|residence         = [[United States]]
|nationality       = [[United States of America|American]]
|field             = [[Mathematics]]
|work_institutions = [[Williams College]]
|alma_mater        = [[Massachusetts Institute of Technology|MIT]]&lt;br&gt;[[Princeton University]]
|doctoral_advisor  = [[Frederick J. Almgren Jr.|Frederick Almgren Jr.]]
|doctoral_students =
|known_for         = Proving [[Double Bubble conjecture]]
|prizes            = [[National Science Foundation research grant]], (1977-2006, 2008-) &lt;br&gt; First [[National Distinguished Teaching Award]] (1992) &lt;br&gt; [[Princeton University]], 250-Anniversary Visiting Professorship for Distinguished Teaching (1997–98)
|Erdős number      = 3
|religion          =
|footnotes         =
}}

'''Frank Morgan''' is an [[United States of America|American]] [[mathematician]] and the Webster Atwell '21 Professor of Mathematics at [[Williams College]], specialising in [[geometric measure theory]] and [[minimal surface]]s. [[Image:Double bubble.png|left|thumb|Double bubble]] He is most famous for proving the [[Double Bubble conjecture]], that the minimum-surface-area enclosure of two given volumes is formed by three spherical patches meeting at 120-degree angles at a common circle.  Morgan was a vice-president-elect of the [[American Mathematical Society]].&lt;ref&gt;{{cite web|url=http://www.ams.org/secretary/election-results.html|title=Election Results|work=American Mathematical Society home page|date=2008-11-27|accessdate=2008-11-27}}&lt;/ref&gt;

Morgan studied at the [[Massachusetts Institute of Technology]] and  [[Princeton University]], and received his Ph.D. from Princeton in 1977, under the supervision of [[Frederick J. Almgren Jr.]]. He taught at MIT for ten years before joining the Williams faculty.&lt;ref&gt;{{mathgenealogy|id=17378|name=Frank Morgan}}.&lt;/ref&gt;&lt;ref&gt;[http://math.williams.edu/morgan/bio/ Bio from Morgan's web site].&lt;/ref&gt;

==Current work==
Frank Morgan is the founder of SMALL, one of the largest and best known summer undergraduate Mathematics research programs. The [[National Science Foundation]] has recently announced the award of a three-year $145,445 grant to him. Morgan and his students will research manifolds with density, a generalization of [[Riemannian manifold]]s, long prominent in probability and of rapidly growing interest in geometry. [[Manifold]]s, or topological spaces that are locally Euclidean, can be understood intuitively as surfaces. This work will build on research conducted by Morgan and his students over the summer.

Specifically, Morgan intends to approach this area by studying the [[isoperimetric inequality|isoperimetric problem]] for manifolds with density such as [[Gauss space]], the premier example of a manifold with density. Isoperimetric problems, which involve finding a closed curve of fixed length, which encloses the greatest area in the plane, have applications in probability theory, in Riemannian geometry, and in [[Grigori Perelman]]’s proof of the [[Poincaré conjecture]].&lt;ref name="NSF"&gt;{{cite web|url=http://math.williams.edu/morgan-gets-nsf-grant/|archive-url=https://archive.is/20110717040244/http://math.williams.edu/morgan-gets-nsf-grant/|dead-url=yes|archive-date=2011-07-17|title=Morgan gets NSF grant|work=Williams College Mathematics and Statistics Department home page|date=2008-11-10|accessdate=2008-11-21}}&lt;/ref&gt;

Frank Morgan is also an avid dancer. He gained temporary fame for his work "Dancing the Parkway".&lt;ref name="Dance on Morgan Blog"&gt;{{cite web|url=http://www.williams.edu/Mathematics/fmorgan/Dancing%20the%20Parkway%20VII.mov |title=Dancing the Parkway|publisher=Frank Morgan's Blog|accessdate=2009-02-25}}&lt;/ref&gt;

==Awards and honors==
In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-02-10.&lt;/ref&gt;

==Books==
*''Calculus Lite'' (1995)
*''Real Analysis and Applications''
*''Geometric Measure Theory''
*''The Math Chat Book''
*''Riemannian Geometry: A Beginners Guide'' (1998)

==Notes==
{{Reflist}}

==External links==
* {{MathGenealogy|id=17378}}
* [http://math.williams.edu/morgan/ Williams College home page]

{{Authority control}}

{{DEFAULTSORT:Morgan, Frank}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Princeton University alumni]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:Williams College faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Textbook writers]]
[[Category:Geometers]]</text>
      <sha1>f8n53abti21wisyfzb1otgjt8xjvhqi</sha1>
    </revision>
  </page>
  <page>
    <title>Gabriel Andrew Dirac</title>
    <ns>0</ns>
    <id>1643806</id>
    <revision>
      <id>867801970</id>
      <parentid>867801604</parentid>
      <timestamp>2018-11-08T02:55:07Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:Hungarian mathematicians]] parent category using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3834">{{more citations needed|date=October 2013}}

{{Infobox scientist
| honorific_prefix  =
| name              = Gabriel Andrew Dirac
| honorific_suffix  =
| native_name       = 
| native_name_lang  = 
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size        = 
| alt               = 
| caption           = 
| birth_date        = {{birth date |1925|03|13}}
| birth_place       = [[Budapest]]
| death_date        = {{death date and age |1984|07|20|1925|03|13}}
| death_place       = [[Arlesheim]]
| death_cause       = 
| resting_place     = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names       = 
| residence         = 
| citizenship       = 
| nationality       = 
| fields            = Mathematics
| workplaces        = University of Aarhus, Trinity College Dublin
| patrons           = 
| education         = Ph.D.
| alma_mater        = University of London
| thesis_title      = &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor  = Richard Rado
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| known_for         = Graph theory
| influences        = 
| influenced        = 
| awards            = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse            = &lt;!--(or | spouses = )--&gt;
| partner           = &lt;!--(or | partners = )--&gt;
| children          = 
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| website           = &lt;!--{{URL|www.example.com}}--&gt;
| footnotes         = 
}}

'''Gabriel Andrew Dirac''' (13 March 1925 – 20 July 1984) was a [[mathematician]] who mainly worked in [[graph theory]]. He stated a sufficient condition for a graph to contain a [[Hamiltonian path|Hamiltonian circuit]]. In 1951 he conjectured that n points in the plane, not all [[collinearity|collinear]], must span at least [n/2] two-point lines, where [x] is the largest integer not exceeding x. This conjecture was proven true when n is sufficiently large by Green and Tao in 2012.&lt;ref&gt;{{cite arxiv|last=Green|first=Ben|last2=Tao|first2=Terence|date=2012-08-23|title=On sets defining few ordinary lines|eprint=1208.4714|class=math.CO}}&lt;/ref&gt;

==Education==
Dirac received his [[Ph.D.]] in 1952 from the [[University of London]] under [[Richard Rado]].&lt;ref&gt;{{MathGenealogy|id=42235}}&lt;/ref&gt;

==Career==
Dirac was professor of mathematics in the [[University of Aarhus]] in [[Denmark]], and was also Erasmus Smith's Professor of Mathematics (1962) at [[Trinity College Dublin]] in the mid-1960s.

==Family==
He was the stepson of [[Paul Dirac]], who adopted him after marrying his mother Manci, and the nephew of [[Eugene Wigner]]. His biological father is Richard Balazs, and he had an older sister, and two younger half-sisters.

==See also==
*[[Dirac's theorem on Hamiltonian cycles]]
*[[Dirac's theorem on chordal graphs]]
*[[Dirac's theorem on cycles in k-connected graphs|Dirac's theorem on cycles in {{mvar|k}}-connected graphs]]

==Notes==
{{reflist}}

==References==
* L. Døvling Andersen, I. Tafteberg Jakobsen, C. Thomassen, B. Toft, and  P. Vestergaard (eds.), [http://www.elsevier.com/wps/find/bookdescription.librarians/501830/description ''Graph Theory in Memory of G.A. Dirac''], North-Holland, 1989.  {{ISBN|0-444-87129-2}}.

{{Authority control}}

{{DEFAULTSORT:Dirac, Gabriel Andrew}}
[[Category:20th-century Hungarian mathematicians]]
[[Category:Graph theorists]]
[[Category:Alumni of the University of London]]
[[Category:1925 births]]
[[Category:1984 deaths]]
[[Category:Hungarian Jews]]
[[Category:Paul Dirac]]
[[Category:Aarhus University faculty]]
[[Category:Academics of Trinity College, Dublin]]</text>
      <sha1>hl51by4o8cz9sw391as4guv9wykp0py</sha1>
    </revision>
  </page>
  <page>
    <title>Giant component</title>
    <ns>0</ns>
    <id>2379792</id>
    <revision>
      <id>856870414</id>
      <parentid>853938228</parentid>
      <timestamp>2018-08-28T02:03:18Z</timestamp>
      <contributor>
        <username>TAnthony</username>
        <id>1808194</id>
      </contributor>
      <comment>/* Giant component in Erdős–Rényi model */ CS1 citation fix (extra text)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7404">In [[network theory]], a '''giant component''' is a [[Connected component (graph theory)|connected component]] of a given [[random graph]] that contains a finite fraction of the entire graph's [[vertex (graph theory)|vertices]].

==Giant component in Erdős–Rényi model==
Giant components are a prominent feature of the [[Erdős–Rényi model]] (ER) of random graphs, in which each possible edge connecting pairs of a given set of {{mvar|n}} vertices is present, independently of the other edges, with probability {{mvar|p}}. In this model, if &lt;math&gt;p \le \frac{1-\epsilon}{n}&lt;/math&gt; for any constant &lt;math&gt;\epsilon&gt;0&lt;/math&gt;, then [[with high probability]] all connected components of the graph have size {{math|O(log ''n'')}}, and there is no giant component. However, for &lt;math&gt;p \ge \frac{1 + \epsilon}{n}&lt;/math&gt; there is with high probability a single giant component, with all other components having size {{math|O(log ''n'')}}. For &lt;math&gt;p=p_c = \frac{1}{n}&lt;/math&gt;, intermediate between these two possibilities, the number of vertices in the largest component of the graph is with high probability proportional to &lt;math&gt;n^{2/3}&lt;/math&gt;.&lt;ref name="b"&gt;{{citation|contribution=6. The Evolution of Random Graphs—The Giant Component|pages=130–159|title=Random Graphs|volume=73|series=Cambridge studies in advanced mathematics|first=Béla|last=Bollobás|edition=2nd|publisher=Cambridge University Press|year=2001|isbn=978-0-521-79722-1}}.&lt;/ref&gt;

Giant component is also important in percolation theory.&lt;ref name="b" /&gt;&lt;ref name=":0"&gt;{{Cite book|url=https://www.worldcat.org/oclc/851388749|title=Fractals and Disordered Systems|last=Armin.|first=Bunde,|date=1996|publisher=Springer Berlin Heidelberg|others=Havlin, Shlomo.|isbn=9783642848681|edition=Second rev. and enlarged|location=Berlin, Heidelberg|oclc=851388749}}&lt;/ref&gt;&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt; When a fraction of nodes, &lt;math&gt;q=1-p&lt;/math&gt;, is removed randomly from an ER network of degree &lt;math&gt;\langle k \rangle&lt;/math&gt;, there exists a critical threshold, &lt;math&gt;p_c= \frac{1}{\langle k \rangle}&lt;/math&gt;. Above &lt;math&gt;p_c&lt;/math&gt; there exists a giant component (largest cluster) of size, &lt;math&gt;P_{inf}&lt;/math&gt;. &lt;math&gt;P_{inf}&lt;/math&gt; fulfills, &lt;math&gt;P_{inf}=p(1-\exp(-\langle k \rangle P_{inf})&lt;/math&gt;.  For &lt;math&gt;p&lt;p_c&lt;/math&gt; the solution of this equation is &lt;math&gt;P_{inf}=0&lt;/math&gt;, i.e., there is no giant component.

At &lt;math&gt;p_c&lt;/math&gt;, the distribution of cluster sizes behaves as a power law, &lt;math&gt;n(s)~s^{-5/2}&lt;/math&gt; which is a feature of phase transition. Giant component appears also in percolation of lattice networks.&lt;ref name=":0" /&gt;

Alternatively, if one adds randomly selected edges one at a time, starting with an [[empty graph]], then it is not until approximately &lt;math&gt;n/2&lt;/math&gt; edges have been added that the graph contains a large component, and soon after that the component becomes giant. More precisely, when &lt;math&gt;t&lt;/math&gt; edges have been added, for values of &lt;math&gt;t&lt;/math&gt; close to but larger than &lt;math&gt;n/2&lt;/math&gt;, the size of the giant component is approximately &lt;math&gt;4t-2n&lt;/math&gt;.&lt;ref name="b"/&gt; However, according to the [[coupon collector's problem]], &lt;math&gt;\Theta(n\log n)&lt;/math&gt; edges are needed in order to have high probability that the whole random graph is connected.

==Graphs with arbitrary degree distribution==
A similar sharp threshold between parameters that lead to graphs with all components small and parameters that lead to a giant component also occurs in random graphs with non-uniform [[degree distribution]]s.
The degree distribution does not define a graph uniquely. 
However under assumption that in all respects other than their degree distribution,
the graphs are treated as entirely random, many results on finite/infinite-component sizes are known.  
In this model, the existence of the giant component depends only on the first two (mixed) [[Moment (mathematics)|moments]] of the degree distribution. Let a randomly chosen vertex has degree &lt;math&gt;k &lt;/math&gt;, then the giant component exists&lt;ref name="Molloy&amp;Reed1995"&gt;M. Molloy and B. Reed (1995). "A critical point for random graphs with a given degree sequence". "Random Struct. Algorithms" 6, 161&lt;/ref&gt; if and only if&lt;math display="block"&gt;\mathbb E [k^2] - 2 \mathbb E [k]&gt;0.&lt;/math&gt;Similar expressions are also valid for [[directed graph]]s, in which case the [[degree distribution]] is two-dimensional. There are three types of connected components in [[directed graph]]s. For a randomly chosen vertex:

a. out-component is a set of vertices that can be reached by recursively following all out-edges forward;

b. in-component is a set of vertices that can be reached by recursively following all in-edges backward;

c. weak component is a set of vertices that can be reached by recursively following all edges regardless of their direction.

Let a randomly chosen vertex has &lt;math&gt;k_\text{in} &lt;/math&gt; in-edges and &lt;math&gt;k_\text{in} &lt;/math&gt; out edges. By definition, the average number of in- and out-edges coincides so that  &lt;math&gt;\mathbb E [k_\text{in}] =\mathbb E [k_\text{out}] &lt;/math&gt;.  The criteria for giant component existence in directed and undirected random graphs are given in the table below. 
{|
! align="center" | Type
! align="center" | Criteria
|-
| align="left" | undirected: giant component
| align="center" | &lt;math&gt;\mathbb E [k^2] - 2 \mathbb E [k]&gt;0&lt;/math&gt;&lt;ref name="Molloy&amp;Reed1995" /&gt;
|-
| align="left" | directed: ''giant in/out-component''
| align="center" | &lt;math&gt;\mathbb E [k_\text{in}k_{out}] - \mathbb E [k_\text{in}]&gt;0&lt;/math&gt;&lt;ref name="NewmanStrogatzWatts2001"&gt;M. E. J. Newman, S. H. Strogatz, and D. J. Watts (2001). "Random graphs with arbitrary degree distributions and their applications". Phys. Rev. E 64, 026118&lt;/ref&gt;
|-
| align="left" | directed: ''giant weak component''
| align="center" | &lt;math&gt;2\mathbb{E}[k_\text{in}] 
\mathbb{E}[k_\text{in}k_\text{out}]
- \mathbb{E}[k_\text{in}] 
\mathbb{E}[k_\text{out}^2]  
- \mathbb{E}[k_\text{in}] 
\mathbb{E}[k_\text{in}^2] 
+[k_\text{in}^2] k_\text{out}^2] 
 - \mathbb{E}[k_\text{in} k_\text{out}]^2 &gt;0
 &lt;/math&gt;&lt;ref name="Kryven2016"&gt;I. Kryven (2016). "Emergence of the giant weak component in directed random graphs with arbitrary degree distributions" Phys. Rev. E 94, 012315&lt;/ref&gt;
|-
|+ Criteria for giant component existence in directed and undirected configuration graphs, &lt;math&gt;\mathbb E [k_\text{in}] =\mathbb E [k_\text{out}] &lt;/math&gt;
|}
For other properties of the giant component and its relation to percolation theory and critical phenomena,  see references.&lt;ref name=":1"&gt;{{Cite book|url=https://doi.org/10.1017/CBO9780511780356|title=Complex Networks: Structure, Robustness and Function|last=Cohen|first=Reuven|last2=Havlin|first2=Shlomo|date=2010|publisher=Cambridge University Press|year=|isbn=9780521841566|location=Cambridge|pages=|language=en|doi=10.1017/cbo9780511780356}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite book|title=Networks : an introduction|last=Newman|first=M. E. J.|date=2010|publisher=Oxford University Press|year=|isbn=|location=New York|pages=|oclc=456837194}}&lt;/ref&gt;&lt;ref name=":0" /&gt;

==See also==

* [[Fractals]]
* [[Graph theory]]
* [[Interdependent networks]]
* [[Percolation theory]]
* [[Phase transitions]]
* [[Complex network|Complex Networks]]
* [[Network science|Network Science]]
* [[Scale-free network|Scale free networks]]

==References==
{{reflist}}

[[Category:Graph connectivity]]
[[Category:Random graphs]]</text>
      <sha1>nie8o96dl8x2tz9d7v3xtkegwxz2rgn</sha1>
    </revision>
  </page>
  <page>
    <title>Grossberg network</title>
    <ns>0</ns>
    <id>35323360</id>
    <revision>
      <id>833185999</id>
      <parentid>833185817</parentid>
      <timestamp>2018-03-30T03:41:54Z</timestamp>
      <contributor>
        <ip>73.196.100.213</ip>
      </contributor>
      <comment>clarify wording</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1360">'''Grossberg network''' is a [[artificial neural network]] introduced by [[Stephen Grossberg]]. It is a [[self organizing]], competitive network based on continuous time.&lt;ref name="Hagan"&gt;{{cite book |author=Martin T. Hagan |author2=Howard B. Demuth |author3=Mark H. Beale  |title=Neural Network Design |edition=1st |date=January 2002 |origyear=1996 |publisher=PWS Publishing Co.|isbn=978-0971732100 |page=15-1 |chapter=Chapter 15: Grossberg Network}}&lt;/ref&gt; Grossberg, a neuroscientist and a biomedical engineer, designed this network based on the [[Human visual system model|human visual system]].

== Shunting model ==
The shunting model is one of Grossberg's neural network models, based on a [[Leaky integrator]], described by the differential equation
:&lt;math&gt;{dn\over dt} \; = \; -An \; + (B - n)E \; - (C + n)I&lt;/math&gt;,
where &lt;math&gt;n=n(t)&lt;/math&gt; represents the activation level of a neuron, &lt;math&gt;E=E(t)&lt;/math&gt; and &lt;math&gt;I=I(t)&lt;/math&gt; represent the excitatory and inhibitory inputs to the neuron, and &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;B&lt;/math&gt;, and &lt;math&gt;C&lt;/math&gt; are constants representing the leaky decay rate and the maximum and minimum activation levels.

At equilibrium (where &lt;math&gt;dn/dt=0&lt;/math&gt;), the activation &lt;math&gt;n&lt;/math&gt; reaches the value
:&lt;math&gt;n \; = \; {BE-CI\over A+E+I}&lt;/math&gt;.

== References ==
{{Reflist}}

[[Category:Artificial neural networks]]</text>
      <sha1>84cfwwv6140ae6vhl5v8rf23b76xbnw</sha1>
    </revision>
  </page>
  <page>
    <title>Hann function</title>
    <ns>0</ns>
    <id>4326149</id>
    <revision>
      <id>857126471</id>
      <parentid>852550666</parentid>
      <timestamp>2018-08-29T18:48:49Z</timestamp>
      <contributor>
        <username>MichaelE</username>
        <id>25392924</id>
      </contributor>
      <comment>Error in equation corrected.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3161">[[File:Window function and frequency response - Hann.svg|thumb|500px|right|Hann function (left), and its frequency response (right)]]

The '''Hann function''', named after the Austrian meteorologist [[Julius von Hann]], is a [[discrete_signal|discrete]] [[window function]] given by

:&lt;math&gt;w(n)= \frac{1}{2}\; \left(1 - \cos \left ( \frac{2 \pi n}{N-1} \right) \right)&lt;/math&gt;

or

:&lt;math&gt;w(n)=  \sin^2 \left ( \frac{ \pi n}{N-1} \right) &lt;/math&gt;

or, in terms of the [[haversine]] function, 

:&lt;math&gt;w(n)=\operatorname{hav}\left(\frac {2 \pi n} {N-1} \right).&lt;/math&gt;

== Spectrum ==

The Hann window is a linear combination of modulated [[Rectangular_function|rectangular windows]] &lt;math&gt;w_r = \mathbf{1}_{[0,N-1]}&lt;/math&gt;. From [[Euler's formula]] 
:&lt;math&gt;w(n)= \frac{1}{2} \,w_r(n) -\frac{1}{4} e^{\mathrm{i}2\pi \frac{n}{N-1}} w_r(n) - \frac{1}{4}e^{-\mathrm{i}2\pi \frac{n}{N-1}} w_r(n)&lt;/math&gt;
Due to the basic properties of the [[Fourier transform]], its spectrum is
:&lt;math&gt;\hat{w} (\omega) = \frac{1}{2} \hat{w}_r (\omega) - \frac{1}{4} \hat{w}_r \left(\omega + \frac{2\pi}{N-1}\right) - \frac{1}{4} \hat{w}_r \left(\omega - \frac{2\pi}{N-1}\right) &lt;/math&gt;
with the spectrum of the rectangular window
:&lt;math&gt;\hat{w}_r (\omega) = e^{-\mathrm{i} \omega \frac{N-1}{2}} \frac{\sin((N-1)\omega/2)}{(N-1)\omega/2}&lt;/math&gt;
If windows are time-shifted around 0 the modulation factor vanishes and the signs in front of the 1/4 terms change to +.

== Name ==

Hann function is the original name, in honour of von Hann; however, the erroneous "Hanning" function is also heard of on occasion, derived from the paper in which it was named, where the term "hanning a signal" was used to mean applying the Hann window to it.{{Citation needed|date=May 2016}}   The confusion arose from the similar [[Hamming function]], named after [[Richard Hamming]].

== Use ==

The Hann function is typically used as a [[window function]] in [[digital signal processing]] to select a subset of a series of samples in order to perform a [[Fourier transform]] or other calculations. 

i.e. (using continuous version to illustrate)
:&lt;math&gt;S(\tau)= \int w(t+\tau)f(t) \, dt &lt;/math&gt;

The advantage of the Hann window is very low [[aliasing]], and the tradeoff slightly is a decreased resolution (widening of the [[Spectral leakage|main lobe]]).

==See also==
* [[Apodization]]
* [[Raised cosine distribution]]
* [[Window function]]

==References==
*{{Cite journal | last1 = Harris | first1 = F. J. | doi = 10.1109/PROC.1978.10837 | title = On the use of windows for harmonic analysis with the discrete Fourier transform | journal = Proceedings of the IEEE | volume = 66 | pages = 51 | year = 1978 | pmid =  | pmc = }}
*{{Cite journal | doi = 10.1002/j.1538-7305.1958.tb03874.x| title = The Measurement of Power Spectra from the Point of View of Communications Engineering - Part I| journal = Bell System Technical Journal| volume = 37| pages = 185| year = 1958| last1 = Blackman | first1 = R. B.| last2 = Tukey | first2 = J. W.}}

== External links ==
* [http://mathworld.wolfram.com/HanningFunction.html Hann function] at [[MathWorld]]

[[Category:Signal processing]]


{{mathapplied-stub}}</text>
      <sha1>ccxslk2npuimk9e0su6cio9689zirkt</sha1>
    </revision>
  </page>
  <page>
    <title>Harmonic progression (mathematics)</title>
    <ns>0</ns>
    <id>24307466</id>
    <revision>
      <id>844210174</id>
      <parentid>844210165</parentid>
      <timestamp>2018-06-03T11:32:01Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/2405:204:A515:6A8B:E5D5:40C7:3F0:8161|2405:204:A515:6A8B:E5D5:40C7:3F0:8161]] to version by Dolphin51. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3399354) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3340">{{For|the musical term|Chord progression}}
[[File:First members of harmonic sequence.svg|thumb|The first ten members of the harmonic sequence &lt;math&gt;a_n=\tfrac 1n&lt;/math&gt;.]]
In [[mathematics]], a '''harmonic progression''' (or '''harmonic sequence''') is a progression formed by taking the reciprocals of an [[arithmetic progression]]. It is a [[sequence]] of the form

:&lt;math&gt; \frac{1}{a} ,\ \frac{1}{a+d}\ , \frac{1}{a+2d}\ , \frac{1}{a+3d}\ , \cdots, \frac{1}{a+kd},&lt;/math&gt;

where &amp;minus;a/''d'' is not a [[natural number]] and ''k'' '''is''' a natural number.

Equivalently, a sequence is a harmonic progression when each term is the [[harmonic mean]] of the neighboring terms.

It is not possible for a harmonic progression (other than the trivial case where ''a'' = 1 and ''k'' = 0)  to sum to an [[integer]]. The reason is that, necessarily, at least one denominator of the progression will be divisible by a [[prime number]] that does not divide any other denominator.&lt;ref&gt;{{citation|first=P.|last= Erdős |authorlink=Paul Erdős |title=Egy Kürschák-féle elemi számelméleti tétel általánosítása|trans-title=Generalization of an elementary number-theoretic theorem of Kürschák|language=Hungarian|journal=Mat. Fiz. Lapok|volume=39|year=1932|pages=17–24|url=https://www.renyi.hu/~p_erdos/1932-02.pdf}}. As cited by {{citation
 | last = Graham | first = Ronald L. | authorlink = Ronald Graham
 | contribution = Paul Erdős and Egyptian fractions
 | doi = 10.1007/978-3-642-39286-3_9
 | mr = 3203600
 | pages = 289–309
 | publisher = János Bolyai Math. Soc., Budapest
 | series = Bolyai Soc. Math. Stud.
 | title = Erdős centennial
 | volume = 25
 | year = 2013}}.&lt;/ref&gt;

==Examples==
* 12,                                                                                 6, 4, 3, &lt;math&gt;\tfrac{12}{5}&lt;/math&gt;, 2, … , &lt;math&gt;\tfrac{12}{1+n}&lt;/math&gt;
* 10, 30, &amp;minus;30, &amp;minus;10, &amp;minus;6, &amp;minus; &lt;math&gt;\tfrac{30}{7}&lt;/math&gt;, … , &lt;math&gt;\tfrac{10}{1-\tfrac{2n}{3}}&lt;/math&gt;

==Use in geometry==
If [[collinear points]] A, B, C, and D are such that D is the [[Projective harmonic conjugates|harmonic conjugate]] of C with respect to A and B, then the distances from any one of these points to the three remaining points form harmonic progression.&lt;ref&gt;''Chapters on the modern geometry of the point, line, and circle, Vol. II'' by Richard Townsend (1865) p. 24&lt;/ref&gt;&lt;ref&gt;''Modern geometry of the point, straight line, and circle: an elementary treatise'' by John Alexander Third (1898) p. 44&lt;/ref&gt; Specifically, each of the sequences
AC,&amp;nbsp;AB,&amp;nbsp;AD; BC,&amp;nbsp;BA,&amp;nbsp;BD; CA,&amp;nbsp;CD,&amp;nbsp;CB; and DA,&amp;nbsp;DC,&amp;nbsp;DB are harmonic progressions, where each of the distances is signed according to a fixed orientation of the line.

In a triangle, if the altitudes are in [[arithmetic progression]], then the sides are in harmonic progression

==See also==
*[[Geometric progression]]
*[[Harmonic series (mathematics)|Harmonic series]]

==References==
{{reflist}}

*''Mastering Technical Mathematics'' by Stan Gibilisco, Norman H. Crowhurst, (2007) p.&amp;nbsp;221
*''Standard mathematical tables'' by Chemical Rubber Company (1974) p.&amp;nbsp;102
*''Essentials of algebra for secondary schools'' by [[Webster Wells]] (1897) p.&amp;nbsp;307

{{Series (mathematics)}}

[[Category:Mathematical series]]
[[Category:Sequences and series]]</text>
      <sha1>iahgigp2x778rjc5u4o17va3l4rb1bp</sha1>
    </revision>
  </page>
  <page>
    <title>Information exchange</title>
    <ns>0</ns>
    <id>10677746</id>
    <revision>
      <id>867205115</id>
      <parentid>867205036</parentid>
      <timestamp>2018-11-04T09:50:33Z</timestamp>
      <contributor>
        <username>Jojoyee</username>
        <id>8108497</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/106.79.226.37|106.79.226.37]] ([[User talk:106.79.226.37|talk]]) to last revision by Ira Leviton. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4928">{{distinguish|knowledge sharing|data sharing|data exchange|knowledge exchange|}}
{{more citations needed|date=October 2015}}
'''Information exchange''' or '''information sharing''' are informal terms that can either refer to bidirectional ''[[information transfer]]'' in [[telecommunication]]s and [[computer science]] or ''[[communication]]'' seen from a [[system theory|system-theoretic]] or [[information-theoretic]] point of view. As "information" in this context invariably refers to ([[Digital data|electronic]]) [[data]] that [[encoder|encodes]] and represents&lt;ref&gt;http://www.csi.ucd.ie/staff/jcarthy/home/Information.html&lt;/ref&gt; the information at hand, a broader treatment can be found under '''[[data exchange]]'''.

The term '''information sharing''' has a long history in [[information technology]]. Traditional information sharing referred to one-to-one exchanges of data between a sender and receiver. These '''information exchange'''s are implemented via dozens of open and proprietary [[network protocol|protocols]], message and file formats. Electronic data interchange ([[Electronic data interchange|EDI]]) is a successful implementation of commercial data exchanges that began in the late 1970s and remains in use today.

Initiatives to standardize information sharing protocols include extensible markup language ([[XML]]), simple object access protocol ([[SOAP]]), and web services description language ([[Web Services Description Language|WSDL]]).

From the point of view of a computer scientist, the four primary information sharing [[design pattern]]s are sharing information [[One-to-one (communication)|one-to-one]], [[Point-to-multipoint communication|one-to-many]], [[many-to-many]], and [[many-to-one]]. Technologies to meet all four of these design patterns are evolving and include [[blog]]s, [[wiki]]s, [[RSS|really simple syndication]], [[Tag (metadata)|tagging]], and [[Online chat|chat]].

One example of United States government's attempt to implement one of these design patterns (one to one) is the [[National Information Exchange Model]] (NIEM).&lt;ref&gt;[http://www.niem.gov/ NIEM]&lt;/ref&gt; One-to-one exchange models fall short of supporting all of the required design patterns needed to fully implement data exploitation technology.

Advanced information sharing platforms provide [[controlled vocabularies]], [[data integration|data harmonization]], [[data steward]]ship policies and guidelines, standards for uniform data as they relate to [[privacy]], [[data security|security]], and [[data quality]].

==Information sharing and the Intelligence Reform and Terrorism Prevention Act==
The term '''information sharing''' gained popularity as a result of the [[9/11 Commission]] Hearings and its [[9/11 Commission Report|report]] of the [[United States government]]'s lack of response to information known about the planned [[terrorist]] attack on the [[New York City]] [[World Trade Center (1973–2001)|World Trade Center]] prior to the event. The resulting commission report led to the enactment of several executive orders by [[George W. Bush|President Bush]] that mandated agencies implement policies to "share information" across organizational boundaries. In addition, an Information Sharing Environment Program Manager&lt;ref&gt;[http://www.ise.gov/ Program Manager for the Information Sharing Environment]&lt;/ref&gt; (PM-ISE) was appointed, tasked to implement the provisions of the [[Intelligence Reform and Terrorism Prevention Act]] of 2004.&lt;ref&gt;http://www.ise.gov/intelligence-reform-and-terrorism-prevention-act-2004-sec-1016-information-sharing&lt;/ref&gt; In making recommendation toward the creation of an "Information Sharing Environment" the 9/11 Commission based itself on the findings and recommendations made by the [[Markle Foundation|Markle]] Task Force on National Security in the Information Age.&lt;ref&gt;[http://www.markle.org/national-security/markle-task-force-national-security Markle Task Force on National Security in the Information Age]&lt;/ref&gt;

==Education==
Information exchange is also used to describe the process of [[learning]] and the efficiency of the learning.

==See also==
*[[Channel (communications)]]
*[[Communications protocol]]
*[[Sexual recombination]] enables cross-pollination in bio&lt;ref&gt;{{Cite thesis|type=Ph.D. |chapter=6 |title=Enzyme Genetic Programming |url= http://www.macs.hw.ac.uk/~ml355/common/thesis/c6.html|last=Lones |first=Michael |year=2003 |publisher= University of York, Heslington|accessdate=7 Aug 2015| quote = After all, recombination enables co-operative evolution by allowing information exchange within a population.}}&lt;/ref&gt;
*[[Data mapping]]
*[[Electronic Data Interchange]]
*[[Fusion center]]
*[[Information Exchange Gateway]]
*[[Knowledge Sharing]]
*[[Semi-structured data]]
*[[:Category:Data interchange standards|Data interchange standards]]

==References==
{{reflist}}

{{wiktionary}}

[[Category:Information theory]]
[[Category:Sharing]]</text>
      <sha1>cnoccjy5wve9o5icnj0twb63kji4sdb</sha1>
    </revision>
  </page>
  <page>
    <title>Isaac ibn al-Ahdab</title>
    <ns>0</ns>
    <id>57915320</id>
    <revision>
      <id>856937137</id>
      <parentid>856886495</parentid>
      <timestamp>2018-08-28T14:02:41Z</timestamp>
      <contributor>
        <username>Kyuko</username>
        <id>7178757</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3320">'''Itzḥak ben Shlomo ibn al-Aḥdab''' (or '''ibn al-Ḥadib''')  '''ben Tzaddiq ha-Sefardi''' ({{he|יצחק בן שלמה בן צדיק אלאחדב הספרדי}}, c. 1350-c. 1426) was a [[Jew]]ish mathematician, astronomer, and poet.&lt;ref&gt;{{cite book|editor-first=Ora|editor-last=Raanan|language=Hebrew|location=Lod|year=1988|title=The Poems of Iṣḥak ben Shlomo Al-Aḥdab|publisher=Mekhon Haberman le-meḥḳere sifrut}}&lt;/ref&gt;

Ibn al-Aḥdab was born in [[Castile (historical region)|Castile]] to a prominent Jewish family. He was a student of Judah ben Asher II, the great-grandson of [[Asher ben Jehiel|Asher ben Yeḥiel]] of Cologne, who was killed in the [[History of the Jews in Spain#1300–1391|anti-Jewish massacres]] of 1391. By 1396 Ibn al-Aḥdab had fled Spain and was in [[Sicily]], where he lived (in [[Syracuse, Sicily|Syracuse]] and [[Palermo]]) until his death around 1426.&lt;ref&gt;{{cite book|first=M.|last=Steinschneider|title=Mathematik bei den Juden|edition=2|publisher=Hildensheim|year=1964|page=168|language=German}}&lt;/ref&gt;

== Work ==
He studied the algebra of Maghrebi mathematician [[Ibn al-Banna' al-Marrakushi|Ibn al-Bannā]] and published ''The Epistle of the Number'', a translation and detailed commentary on Ibn al-Bannā's 13th century treatise ''Talḵīṣ ʿAmal al-Ḥisāb'' (''A summary of the operations of calculation'').&lt;ref name=katz&gt;{{cite journal|first=Victor|last=Katz|author-link=Victor J. Katz|title=The Mathematical Cultures of Medieval Europe|journal=History and Pedagogy of Mathematics|year=2016|location=Montpellier|url=https://hal.archives-ouvertes.fr/hal-01349229/document}}&lt;/ref&gt; The work is notable in being the first known Hebrew-language treatise to include extensive algebraic theories and operations.&lt;ref&gt;{{cite book|last=Wartenberg|first=Ilana|title=The epistle of the number, by Ibn al-Ahdab|series=Perspectives on Society and Culture|location=Piscataway|publisher=Gorgias Press|year=2015|isbn=978-1-4632-0417-4}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Reif|first=Stefan C.|title=Hebrew manuscripts at Cambridge University Library: a description and introduction|journal=University of Cambridge oriental publications|volume=52|publisher=Cambridge University Press|year=1997|isbn=052158339X}}&lt;/ref&gt;

His main astronomical work was ''Oraḥ selulah'', a set of tables in Hebrew for conjunctions and oppositions of the Sun and the Moon.&lt;ref&gt;{{cite article|title=Isaac ibn al-Ḥadib and Flavius Mithridates: The Diffusion of an Iberian Astronomical Tradition in the Late Middle Ages|last1=Goldstein|first1=Bernard R.|last2=Chabás|first2=José|journal=Journal for the History of Astronomy|issn=0021-8286|volume=37|number=127|pages=147-172|year=2006|url=http://adsabs.harvard.edu/full/2006JHA....37..147G|bibcode=2006JHA....37..147G}}&lt;/ref&gt;

==References==
{{reflist}}

{{mathematician-stub}}
{{authority control}}

[[Category:1350s births]]
[[Category:1420s deaths]]
[[Category:14th-century astronomers]]
[[Category:14th-century mathematicians]]
[[Category:14th-century Spanish people]]
[[Category:14th-century Sephardi Jews]]
[[Category:15th-century astronomers]]
[[Category:15th-century mathematicians]]
[[Category:15th-century Spanish people]]
[[Category:15th-century Sephardi Jews]]
[[Category:Medieval Spanish Jews]]
[[Category:Medieval Jewish astronomers]]</text>
      <sha1>p4v3c0rgjq7o7zb2y41wy78zlhocy8n</sha1>
    </revision>
  </page>
  <page>
    <title>Isoperimetric dimension</title>
    <ns>0</ns>
    <id>945225</id>
    <revision>
      <id>810797814</id>
      <parentid>790711799</parentid>
      <timestamp>2017-11-17T14:24:27Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7481">In [[mathematics]], the '''isoperimetric dimension''' of a [[manifold]] is a notion of dimension that tries to capture how the ''large-scale behavior'' of the manifold resembles that of a [[Euclidean space]] (unlike the [[topological dimension]] or the [[Hausdorff dimension]] which compare different ''local behaviors'' against those of the Euclidean space).

In the [[Euclidean space]], the [[isoperimetry|isoperimetric inequality]] says that of all bodies with the same volume, the ball has the smallest surface area. In other manifolds it is usually very difficult to find the precise body minimizing the surface area, and this is not what the isoperimetric dimension is about. The question we will ask is, what is ''approximately'' the minimal surface area, whatever the body realizing it might be.

==Formal definition==

We say about a [[differentiable manifold]] ''M'' that it satisfies a ''d''-dimensional '''isoperimetric inequality''' if for any open set ''D'' in ''M'' with a smooth boundary one has

:&lt;math&gt;\mathrm{area}\,(\partial D)\geq C\,\mathrm{vol}\,(D)^{(d-1)/d}.&lt;/math&gt;

The notations vol and area refer to the regular notions of volume and surface area on the manifold, or more precisely, if the manifold has ''n'' topological dimensions then vol refers to ''n''-dimensional volume and area refers to (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)-dimensional volume. ''C'' here refers to some constant, which does not depend on ''D'' (it may depend on the manifold and on ''d'').

The '''isoperimetric dimension''' of ''M'' is the supremum of all values of ''d'' such that ''M'' satisfies a ''d''-dimensional isoperimetric inequality.

==Examples==

A ''d''-dimensional Euclidean space has isoperimetric dimension ''d''. This is the well known [[isoperimetry|isoperimetric problem]] &amp;mdash; as discussed above, for the Euclidean space the constant ''C'' is known precisely since the minimum is achieved for the ball. 

An infinite cylinder (i.e. a [[cartesian product|product]] of the [[unit circle|circle]] and the [[real line|line]]) has topological dimension 2 but isoperimetric dimension 1. Indeed, multiplying any manifold with a compact manifold does not change the isoperimetric dimension (it only changes the value of the constant ''C''). Any compact manifold has isoperimetric dimension&amp;nbsp;0.

It is also possible for the isoperimetric dimension to be larger than the topological dimension. The simplest example is the infinite [[jungle gym]], which has topological dimension 2 and isoperimetric dimension 3. See [https://web.archive.org/web/20040817075143/http://www.math.ucla.edu/~bon/jungle.html] for pictures and Mathematica code.

The [[hyperbolic geometry|hyperbolic plane]] has topological dimension 2 and isoperimetric dimension infinity. In fact the hyperbolic plane has positive [[Cheeger constant]]. This means that it satisfies the inequality

:&lt;math&gt;\mathrm{area}\,(\partial D)\geq C\,\mathrm{vol}\,(D),&lt;/math&gt;

which obviously implies infinite isoperimetric dimension.

==Of graphs==
{{main|Expander graph}}
The isoperimetric dimension of [[Graph (discrete mathematics)|graphs]] can be defined in a similar fashion.
A precise definition is given in Chung's survey.&lt;ref&gt;{{cite journal|last=Chung|first=Fan|title=Discrete Isoperimetric Inequalities|url=http://math.ucsd.edu/~fan/wp/iso.pdf}}&lt;/ref&gt; 
Area and volume are measured by set sizes. For every subset ''A'' of the graph ''G'' one defines &lt;math&gt;\partial A&lt;/math&gt; as the set of vertices in &lt;math&gt;G\setminus A&lt;/math&gt; with a neighbor in&amp;nbsp;''A''. A ''d''-dimensional isoperimetric inequality is now defined by

:&lt;math&gt;|\partial A|\geq C\left(\min \left( |A| , |G\setminus A| \right)\right)^{(d-1)/d}. &lt;/math&gt;

(This [http://mathoverflow.net/questions/85334/ MathOverflow question] provides more details.) The graph analogs of all the examples above hold but the definition is slightly different in order to avoid that the isoperimetric dimension of any finite graph is&amp;nbsp;0: In the above formula the volume of &lt;math&gt;A&lt;/math&gt; is replaced by &lt;math&gt;\min (|A|,|G\setminus A|)&lt;/math&gt; (see Chung's survey, section 7).

The isoperimetric dimension of a ''d''-dimensional grid is ''d''. In general, the isoperimetric dimension is preserved by [[Glossary of Riemannian and metric geometry#Q|quasi isometries]], both by quasi-isometries between manifolds, between graphs, and even by quasi isometries carrying manifolds to graphs, with the respective definitions. In rough terms, this means that a graph "mimicking" a given manifold (as the grid mimics the Euclidean space) would have the same isoperimetric dimension as the manifold. An infinite complete [[binary tree]] has isoperimetric dimension&amp;nbsp;∞.{{Citation needed|date=January 2011}}

==Consequences of isoperimetry==&lt;!-- This section is linked from [[Random walk]] --&gt;

A simple integration over ''r'' (or sum in the case of graphs) shows that a ''d''-dimensional isoperimetric inequality implies a ''d''-dimensional [[Growth rate (group theory)|volume growth]], namely

:&lt;math&gt;\mathrm{vol}\,B(x,r)\geq Cr^d&lt;/math&gt;

where ''B''(''x'',''r'') denotes the ball of radius ''r'' around the point ''x'' in the [[Riemannian manifold|Riemannian distance]] or in the [[Glossary of graph theory#Distance|graph distance]]. In general, the opposite is not true, i.e. even uniformly exponential volume growth does not imply any kind of isoperimetric inequality. A simple example can be had by taking the graph '''Z''' (i.e. all the integers with edges between ''n'' and ''n''&amp;nbsp;+&amp;nbsp;1) and connecting to the vertex ''n'' a complete binary tree of height |''n''|. Both properties (exponential growth and 0 isoperimetric dimension) are easy to verify.

An interesting exception is the case of [[Group (mathematics)|groups]]. It turns out that a group with polynomial growth of order ''d'' has isoperimetric dimension ''d''. This holds both for the case of [[Lie group]]s and for the [[Cayley graph]] of a [[finitely generated group]].

A theorem of [[Nicholas Varopoulos|Varopoulos]] connects the isoperimetric dimension of a graph to the rate of escape of [[random walk]] on the graph. The result states

''Varopoulos' theorem: If G is a graph satisfying a d-dimensional isoperimetric inequality then''

:&lt;math&gt;p_n(x,y)\leq Cn^{-d/2} &lt;/math&gt;

''where'' &lt;math&gt;\scriptstyle p_n(x,y)&lt;/math&gt; ''is the probability that a random walk on G starting from x will be in y after n steps, and C is some constant.''

==References==
&lt;references /&gt;
&lt;hr /&gt;
* Isaac Chavel, ''Isoperimetric Inequalities: Differential geometric and analytic persepectives'', Cambridge university press, Cambridge, UK (2001), {{ISBN|0-521-80267-9}}
:Discusses the topic in the context of manifolds, no mention of graphs.
* N. Th. Varopoulos, ''Isoperimetric inequalities and Markov chains'', J. Funct. Anal. '''63:2''' (1985), 215–239.
* Thierry Coulhon and Laurent Saloff-Coste, ''Isopérimétrie pour les groupes et les variétés'', Rev. Mat. Iberoamericana '''9:2''' (1993), 293–314.
:This paper contains the result that on groups of polynomial growth, volume growth and isoperimetric inequalities are equivalent. In French.
* Fan Chung, ''Discrete Isoperimetric Inequalities''. ''Surveys in Differential Geometry IX'', International Press, (2004), 53–82. http://math.ucsd.edu/~fan/wp/iso.pdf.
:This paper contains a precise definition of the isoperimetric dimension of a graph, and establishes many of its properties.

[[Category:Mathematical analysis]]
[[Category:Dimension]]</text>
      <sha1>euijpzb9d05e4z59otm19eah1kz09un</sha1>
    </revision>
  </page>
  <page>
    <title>J. J. Thomson</title>
    <ns>0</ns>
    <id>70085</id>
    <revision>
      <id>870974182</id>
      <parentid>870788816</parentid>
      <timestamp>2018-11-28T03:55:43Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove size in {{[[Template:Post-nominals|Post-nominals]]}}. The 100% size is needed only for infoboxes; in the lede, just use the default</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38310">{{About|the Nobel laureate and physicist|the moral philosopher|Judith Jarvis Thomson}}
{{EngvarB|date=October 2013}}
{{Use dmy dates|date=October 2013}}
{{Infobox scientist
|image = J.J Thomson.jpg
| name = Sir J. J. Thomson
|birth_name = Joseph John Thomson
|honorific_suffix = {{post-nominals|country=GBR|OM|PRS|size=100%}}
|image_size = 200px
|birth_date = {{birth date|1856|12|18|df=yes}}
|birth_place = [[Cheetham Hill]], [[Manchester]], England
|death_date = {{Death date and age|1940|8|30|1856|12|18|df=yes}}
|death_place = [[Cambridge]], England
|nationality = [[English people|English]]
|citizenship = British
|fields = [[Physics]]
|workplaces = [[Trinity College, Cambridge]]
|alma_mater = [[Owens College]] (now the [[University of Manchester]])&lt;br /&gt;[[Trinity College, Cambridge]] (BA)
|doctoral_advisor = &lt;!--there was no PhD at Cambridge until 1919--&gt;
|academic_advisors = [[John Strutt, 3rd Baron Rayleigh|John Strutt (Rayleigh)]]&lt;br /&gt;[[Edward John Routh]]
|doctoral_students = &lt;!--So far, all the students below appear to be pre-1919 and so were not doctoral--&gt;
|notable_students = [[Charles Glover Barkla]]&lt;br /&gt;[[Charles T. R. Wilson]]&lt;br /&gt;[[Ernest Rutherford]]&lt;br /&gt;[[Francis William Aston]]&lt;br /&gt; [[John Sealy Edward Townsend|John Townsend]]&lt;br /&gt;[[J. Robert Oppenheimer]]&lt;br /&gt;[[Owen Willans Richardson|Owen Richardson]]&lt;br /&gt;[[William Henry Bragg]]&lt;br /&gt;[[H. Stanley Allen]]&lt;br /&gt;[[John Zeleny]]&lt;br /&gt;[[Daniel Frost Comstock]]&lt;br /&gt;[[Max Born]]&lt;br /&gt;[[T. H. Laby]]&lt;br /&gt;[[Paul Langevin]]&lt;br /&gt;[[Balthasar van der Pol]]&lt;br /&gt;[[Geoffrey Ingram Taylor]]&lt;br /&gt;[[Niels Bohr]]&lt;br /&gt;[[George Paget Thomson]]
|known_for = [[Plum pudding model]]&lt;br /&gt;[[electron|Discovery of electron]]&lt;br /&gt;[[isotopes|Discovery of isotopes]]&lt;br /&gt;[[mass spectrometer|Mass spectrometer invention]]&lt;br /&gt;[[Mass-to-charge ratio|First m/e measurement]]&lt;br /&gt;[[Waveguide (electromagnetism)|Proposed first waveguide]]&lt;br /&gt;[[Thomson scattering]]&lt;br /&gt;[[Thomson problem]]&lt;br /&gt;[[Delta ray|Coining term 'delta ray']]&lt;br /&gt;[[Epsilon radiation|Coining term 'epsilon radiation']]&lt;br /&gt;[[Thomson (unit)]]
|influences =
|influenced =
|awards = {{no wrap|[[Smith's Prize]] &lt;small&gt;(1880)&lt;/small&gt;&lt;br&gt;[[Royal Medal]] {{small|(1894)}}&lt;br&gt;[[Hughes Medal]] {{small|(1902)}}&lt;br&gt;[[Nobel Prize in Physics]] {{small|(1906)}}&lt;br&gt;[[Elliott Cresson Medal]] {{small|(1910)}}&lt;br&gt;[[Copley Medal]] {{small|(1914)}}&lt;br&gt;[[Albert Medal (Royal Society of Arts)|Albert Medal]] {{small|(1915)}}&lt;br&gt;[[Franklin Medal]] {{small|(1922)}}&lt;br&gt;[[Faraday Medal]]  {{small|(1925)}}}}
|signature = Jjthomson sig.svg
| children = [[George Paget Thomson]].
}}

{{external media | width = 180px | align = right | headerimage= [[File:Title page On the Chemical Combination of Gases by Joseph John Thomson 1856-1940.jpg|180px]] | video1 = [https://www.youtube.com/watch?v=WH-U_qCEzT0 ''The Early Life of J.J. Thomson: Computational Chemistry and Gas Discharge Experiments''] }}

'''Sir Joseph John Thomson''' {{post-nominals|country=GBR|OM|PRS}}&lt;ref name="frs"&gt;{{Cite journal | last1 = Rayleigh | doi = 10.1098/rsbm.1941.0024 |title = Joseph John Thomson. 1856-1940 | journal = [[Obituary Notices of Fellows of the Royal Society]] | volume = 3 | issue = 10 | pages = 586–609 | year = 1941 | pmid =  | pmc = }}&lt;/ref&gt; (18 December 1856 – 30 August 1940) was an English [[physicist]] and [[Nobel Prize in Physics|Nobel Laureate in Physics]], credited with the discovery and identification of the [[electron]]; and with the discovery of the first [[subatomic particle]].

In 1897, Thomson showed that [[cathode ray]]s were composed of previously unknown negatively charged particles (now called electrons), which he calculated must have bodies much smaller than atoms and a very large [[charge-to-mass ratio]].&lt;ref name="Profile"/&gt; Thomson is also credited with finding the first evidence for [[isotope]]s of a stable (non-radioactive) element in 1913, as part of his exploration into the composition of [[canal ray]]s (positive ions). His experiments to determine the nature of positively charged particles, with [[Francis William Aston]], were the first use of [[mass spectrometry]] and led to the development of the mass spectrograph.&lt;ref name="Profile"/&gt;

Thomson was awarded the 1906 [[Nobel Prize in Physics]] for his work on the conduction of electricity in gases.&lt;ref name=Nobel1906&gt;{{cite web|title=J.J. Thomson - Biographical|url=https://www.nobelprize.org/nobel_prizes/physics/laureates/1906/thomson-bio.html|website=The Nobel Prize in Physics 1906|publisher=The Nobel Foundation|accessdate=11 February 2015}}&lt;/ref&gt;

==Education and personal life==
Joseph John Thomson was born 18 December 1856 in [[Cheetham Hill]], [[Manchester]], [[Lancashire]], England. His mother, Emma Swindells, came from a local textile family. His father, Joseph James Thomson, ran an antiquarian bookshop founded by a great-grandfather. He had a brother, Frederick Vernon Thomson, who was two years younger than he was.&lt;ref name="ReferenceA"&gt;Davis &amp; Falconer, ''J.J. Thomson and the Discovery of the Electron''&lt;/ref&gt; J. J. Thomson was a reserved yet devout [[Anglican]].&lt;ref&gt;Peter J. Bowler, Reconciling Science and Religion: The Debate in Early-Twentieth-Century Britain (2014). University of Chicago Press. p. 35. {{ISBN|9780226068596}}. "Both Lord Rayleigh and J. J. Thomson were Anglicans."&lt;/ref&gt;&lt;ref&gt;Seeger, Raymond. 1986. "J. J. Thomson, Anglican," in Perspectives on Science and Christian Faith, 38 (June 1986): 131-132. The Journal of the American Scientific Affiliation. ""As a Professor, J.J. Thomson did attend the Sunday evening college chapel service, and as Master, the morning service. He was a regular communicant in the Anglican Church. In addition, he showed an active interest in the Trinity Mission at Camberwell. With respect to his private devotional life, J.J. Thomson would invariably practice kneeling for daily prayer, and read his Bible before retiring each night. He truly was a practicing Christian!" ([[Raymond Seeger]] 1986, 132)."&lt;/ref&gt;&lt;ref&gt;Richardson, Owen. 1970. "Joseph J. Thomson," in The Dictionary of National Biography, 1931-1940. L. G. Wickham Legg - editor. [[Oxford University Press]].&lt;/ref&gt;

His early education was in small private schools where he demonstrated outstanding talent and interest in science. In 1870, he was admitted to [[Owens College]] in Manchester (now [[University of Manchester]]) at the unusually young age of 14. His parents planned to enroll him as an apprentice engineer to [[Sharp Stewart|Sharp-Stewart &amp; Co]], a locomotive manufacturer, but these plans were cut short when his father died in 1873.&lt;ref name="ReferenceA"/&gt;

He moved on to [[Trinity College, Cambridge]], in 1876. In 1880, he obtained his [[Bachelor of Arts]] degree in mathematics ([[Second Wrangler]] in the [[Tripos]]&lt;ref name=ThomsonProfile&gt;{{cite web|last=Grayson|first=Mike|title=The Early Life of J.J. Thomson: Computational Chemistry and Gas Discharge Experiments|url=https://www.youtube.com/watch?v=WH-U_qCEzT0|website=Profiles in Chemistry|publisher=[[Chemical Heritage Foundation]]|accessdate=11 February 2015|date=May 22, 2013}}&lt;/ref&gt; and 2nd [[Smith's Prize]]).&lt;ref name="ACAD"/&gt;  He applied for and became a Fellow of Trinity College in 1881.&lt;ref name=Victoria&gt;{{cite book|title=The Victoria University Calendar for the Session  1881-2|date=1882|page=184|url=https://books.google.com/books?id=3d8NAAAAQAAJ&amp;pg=PA184|accessdate=11 February 2015}} {{ISBN missing}}&lt;/ref&gt;  Thomson received his [[Master of Arts]] degree (with [[Adams Prize]]) in 1883.&lt;ref name="ACAD"&gt;{{acad|id=THN876JJ|name=Thomson, Joseph John}}&lt;/ref&gt;

In 1890, Thomson married Rose Elisabeth Paget, one of his former students,&lt;ref&gt;[https://books.google.ca/books?id=LTSYePZvSXYC&amp;pg=PA972&amp;dq=Paget,+Rose&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjX6e6r9uDWAhWP14MKHcJ0BxcQ6AEIKDAA#v=onepage&amp;q=Paget%2C%20Rose&amp;f=false The Biographical Dictionary of Women in Science: L-Z] by By Marilyn Bailey Ogilvie and Joy Dorothy Harvey, Taylor &amp; Francis, p.972&lt;/ref&gt; daughter of [[Sir George Edward Paget]], KCB, a physician and then [[Regius Professor of Physic (Cambridge)|Regius Professor of Physic at Cambridge]] at the church of [[Little_St_Mary's,_Cambridge|St. Mary the Less]]. They had one son, [[George Paget Thomson]], and one daughter, Joan Paget Thomson.

==Career and research==
===Overview===
On 22 December 1884, Thomson was appointed [[Cavendish Professor of Physics]] at the [[University of Cambridge]].&lt;ref name="Profile"&gt;{{cite web|title=Joseph John "J. J." Thomson|url=https://www.sciencehistory.org/historical-profile/joseph-john-j-j-thomson|publisher=[[Science History Institute]]|accessdate=20 March 2018|date=June 2016}}&lt;/ref&gt; The appointment caused considerable surprise, given that candidates such as [[Osborne Reynolds]] or [[Richard Glazebrook]] were older and more experienced in laboratory work.  Thomson was known for his work as a mathematician, where he was recognized as an exceptional talent.&lt;ref name=Leadership&gt;{{cite book|last1=Kim|first1=Dong-Won|title=Leadership and creativity : a history of the Cavendish Laboratory, 1871 - 1919|date=2002|publisher=Kluwer Acad. Publ.|location=Dordrecht|isbn=9781402004759|url=https://books.google.com/books?id=iN13QvH8vnwC&amp;pg=PA51|accessdate=11 February 2015}}&lt;/ref&gt;

He was awarded a Nobel Prize in 1906, "in recognition of the great merits of his theoretical and experimental investigations on the conduction of electricity by gases." He was [[knighthood|knighted]] in 1908 and appointed to the [[Order of Merit (Commonwealth)|Order of Merit]] in 1912. In 1914, he gave the [[Romanes Lecture]] in [[University of Oxford|Oxford]] on "The atomic theory". In 1918, he became Master of [[Trinity College, Cambridge|Trinity College]], [[University of Cambridge|Cambridge]], where he remained until his death. Joseph John Thomson died on 30 August 1940; his ashes rest in [[Westminster Abbey]], near the graves of [[Isaac Newton|Sir Isaac Newton]] and his former student, [[Ernest Rutherford]].&lt;ref name=sirJJrestingplace&gt;{{cite web|last=Westminster Abbey| title= Sir Joseph John Thomson| url=http://www.westminster-abbey.org/our-history/people/sir-joseph-john-thomson}}&lt;/ref&gt;

One of Thomson's greatest contributions to modern science was in his role as a highly gifted teacher. One of his students was [[Ernest Rutherford]], who later succeeded him as [[Cavendish Professor of Physics]]. In addition to Thomson himself, six of his research assistants ([[Charles Glover Barkla]], [[Niels Bohr]], [[Max Born]], [[William Henry Bragg]], [[Owen Willans Richardson]] and [[Charles Thomson Rees Wilson]]) won Nobel Prizes in physics, and two ([[Francis William Aston]] and [[Ernest Rutherford]]) won Nobel prizes in chemistry. In addition, Thomson's son ([[George Paget Thomson]]) won the 1937 Nobel Prize in physics for proving the wave-like properties of electrons.

===Early work===
Thomson's prize-winning master's work, ''Treatise on the motion of vortex rings'', shows his early interest in atomic structure.&lt;ref name="Nobel1906"/&gt; In it, Thomson mathematically described the motions of [[William Thomson, 1st Baron Kelvin|William Thomson]]'s vortex theory of atoms.&lt;ref name=Leadership/&gt;
 
Thomson published a number of papers addressing both mathematical and experimental issues of electromagnetism.  He examined the [[electromagnetic theory of light]] of [[James Clerk Maxwell]], introduced the concept of [[Electromagnetic mass|electromagnetic mass of a charged particle]], and demonstrated that a moving charged body would apparently increase in mass.&lt;ref name=Leadership/&gt;

Much of his work in mathematical modelling of chemical processes can be thought of as early [[computational chemistry]].&lt;ref name="Profile"/&gt; In further work, published in book form as ''Applications of dynamics to physics and chemistry'' (1888), Thomson addressed the transformation of energy in mathematical and theoretical terms, suggesting that all energy might be kinetic.&lt;ref name=Leadership/&gt; His next book, ''Notes on recent researches in electricity and magnetism'' (1893), built upon Maxwell's ''Treatise upon electricity and magnetism'', and was sometimes referred to as "the third volume of Maxwell".&lt;ref name="Nobel1906"/&gt; In it, Thomson emphasized physical methods and experimentation and included extensive figures and diagrams of apparatus, including a number for the passage of electricity through gases.&lt;ref name=Leadership/&gt; His third book, [http://catalog.hathitrust.org/Record/001985977 ''Elements of the mathematical theory of electricity and magnetism''] (1895)&lt;ref&gt;{{cite journal|author=Mackenzie, A. Stanley|authorlink=Arthur Stanley Mackenzie|title=Review: ''Elements of the Mathematical Theory of Electricity and Magnetism'' by J. J. Thomson|journal=Bull. Amer. Math. Soc.|year=1896|volume=2|issue=10|pages=329–333|url=http://www.ams.org/journals/bull/1896-02-10/S0002-9904-1896-00357-8/S0002-9904-1896-00357-8.pdf|doi=10.1090/s0002-9904-1896-00357-8}}&lt;/ref&gt; was a readable introduction to a wide variety of subjects, and achieved considerable popularity as a textbook.&lt;ref name=Leadership/&gt;

A series of four lectures, given by Thomson on a visit to [[Princeton University]] in 1896, were subsequently published as ''Discharge of electricity through gases'' (1897).  Thomson also presented a series of six lectures at [[Yale University]] in 1904.&lt;ref name="Nobel1906"/&gt;

===Discovery of the electron===
Several scientists, such as [[William Prout]] and [[Norman Lockyer]], had suggested that atoms were built up from a more fundamental unit, but they envisioned this unit to be the size of the smallest atom, hydrogen. Thomson in 1897 was the first to suggest that one of the fundamental units was more than 1,000 times smaller than an atom, suggesting the subatomic particle now known as the electron. Thomson discovered this through his explorations on the properties of cathode rays. Thomson made his suggestion on 30 April 1897 following his discovery that cathode rays (at the time known as [[Philipp Lenard|Lenard rays]]) could travel much further through air than expected for an atom-sized particle.&lt;ref name="referenceB"&gt;{{cite journal |last=Thomson |first=J.J. |year=1897 |url=https://books.google.com/books?id=vBZbAAAAYAAJ&amp;pg=PA104#v=onepage&amp;q&amp;f=false |title=Cathode Rays |journal=The Electrician |volume=39 |page=104}}&lt;/ref&gt; He estimated the mass of cathode rays by measuring the heat generated when the rays hit a thermal junction and comparing this with the magnetic deflection of the rays. His experiments suggested not only that cathode rays were over 1,000 times lighter than the hydrogen atom, but also that their mass was the same in whichever type of atom they came from. He concluded that the rays were composed of very light, negatively charged particles which were a universal building block of atoms. He called the particles "corpuscles", but later scientists preferred the name [[electron]] which had been suggested by [[George Johnstone Stoney]] in 1891, prior to Thomson's actual discovery.&lt;ref&gt;{{cite book |last=Falconer |first=Isobel  |year=2001 |chapter=Corpuscles to electrons |chapter-url=https://isobelf.files.wordpress.com/2013/08/falconer_corpusclestoelectrons_preprint.pdf |editor1-last=Buchwald |editor1-first=J. Z.|editor2-last=Warwick |editor2-first=A. |title=Histories of the Electron |publisher=MIT Press |page=77–100 |isbn=9780262024945}}&lt;/ref&gt;

In April 1897, Thomson had only early indications that the cathode rays could be deflected electrically (previous investigators such as [[Heinrich Hertz]] had thought they could not be). A month after Thomson's announcement of the corpuscle, he found that he could reliably deflect the rays by an electric field if he evacuated the discharge tube to a very low pressure. By comparing the deflection of a beam of cathode rays by electric and magnetic fields he obtained more robust measurements of the mass-to-charge ratio that confirmed his previous estimates.&lt;ref name="PhilMag"&gt;{{cite journal|last1=Thomson|first1=J. J.|title=Cathode Rays|journal=Philosophical Magazine|date=7 August 1897|volume=44|issue=269|page=293|url=http://web.lemoyne.edu/~giunta/Thomson1897.html|accessdate=4 August 2014|series=5|doi=10.1080/14786449708621070}}&lt;/ref&gt; This became the classic means of measuring the charge and mass of the electron.

Thomson believed that the corpuscles emerged from the atoms of the trace gas inside his [[cathode ray tube]]s. He thus concluded that atoms were divisible, and that the corpuscles were their building blocks. In 1904, Thomson suggested a model of the atom, hypothesizing that it was a sphere of positive matter within which electrostatic forces determined the positioning of the corpuscles.&lt;ref name="Profile"/&gt;  To explain the overall neutral charge of the atom, he proposed that the corpuscles were distributed in a uniform sea of positive charge.  In this "plum pudding" model, the electrons were seen as embedded in the positive charge like plums in a plum pudding (although in Thomson's model they were not stationary, but orbiting rapidly).&lt;ref&gt;{{citation|title=Modern Inorganic Chemistry|first=Joseph William|last=Mellor|publisher=Longmans, Green and Company|year=1917|page=868|url=https://books.google.com/books?id=1iQ7AQAAMAAJ&amp;pg=PA868|quote=According to J. J. Thomson's hypothesis, atoms are built of systems of rotating rings of electrons.}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Dahl|1997}}, p. 324: "[https://books.google.com/books?id=xUzaWGocMdMC&amp;pg=PA324 Thomson's model, then, consisted of a uniformly charged sphere of positive electricity (the pudding), with discrete corpuscles (the plums) rotating about the center in circular orbits, whose total charge was equal and opposite to the positive charge.]"&lt;/ref&gt;

===Isotopes and mass spectrometry===
[[File:Discovery of neon isotopes.JPG|thumb|In the bottom right corner of this photographic plate are markings for the two isotopes of neon: neon-20 and neon-22.]]
In 1912, as part of his exploration into the composition of the streams of positively charged particles then known as [[canal rays]], Thomson and his research assistant [[Francis William Aston|F. W. Aston]] channelled a stream of neon ions through a magnetic and an electric field and measured its deflection by placing a photographic plate in its path.&lt;ref name="ReferenceA"/&gt; They observed two patches of light on the photographic plate (see image on right), which suggested two different parabolas of deflection, and concluded that neon is composed of atoms of two different atomic masses (neon-20 and neon-22), that is to say of two [[isotope]]s.&lt;ref&gt;J.J. Thomson (1912) "Further experiments on positive rays," ''Philosophical Magazine'', series 6, '''24''' (140):  209–253.&lt;/ref&gt;&lt;ref&gt;J.J. Thomson (1913) "Rays of positive electricity," ''Proceedings of the Royal Society'' A, '''89''': 1–20.&lt;/ref&gt; This was the first evidence for isotopes of a stable element; [[Frederick Soddy]] had previously proposed the existence of isotopes to explain the decay of certain [[radioactive]] elements.

J.J. Thomson's separation of neon isotopes by their mass was the first example of [[mass spectrometry]], which was subsequently improved and developed into a general method by [[Francis William Aston|F. W. Aston]] and by [[A. J. Dempster]].&lt;ref name="Profile"/&gt;

===Experiments with cathode rays===
Earlier, physicists debated whether cathode rays were immaterial like light ("some process in the [[luminiferous aether|aether]]") or were "in fact wholly material, and ... mark the paths of particles of matter charged with negative electricity", quoting Thomson.&lt;ref name="PhilMag" /&gt; The aetherial hypothesis was vague,&lt;ref name="PhilMag" /&gt; but the particle hypothesis was definite enough for Thomson to test.

====Magnetic deflection====
Thomson first investigated the [[magnetic deflection]] of cathode rays. Cathode rays were produced in the side tube on the left of the apparatus and passed through the anode into the main [[bell jar]], where they were deflected by a magnet. Thomson detected their path by the [[fluorescence]] on a squared screen in the jar. He found that whatever the material of the anode and the gas in the jar, the deflection of the rays was the same, suggesting that the rays were of the same form whatever their origin.&lt;ref&gt;{{cite journal |last=Thomson |first=J. J. |date=8 February 1897 |title=On the cathode rays |journal=Proceedings of the Cambridge Philosophical Society |volume=9 |issue= |page=243}}&lt;/ref&gt;

====Electrical charge ====
[[File:JJ Thomson Cathode Ray Tube 1.png|right|thumb|The cathode ray tube by which J.J. Thomson demonstrated that cathode rays could be deflected by a magnetic field, and that their negative charge was not a separate phenomenon.]]
While supporters of the aetherial theory accepted the possibility that negatively charged particles are produced in [[Crookes tube]]s,{{Citation needed|date=June 2012}} they believed that they are a mere by-product and that the cathode rays themselves are immaterial.{{Citation needed|date=June 2012}} Thomson set out to investigate whether or not he could actually separate the charge from the rays.

Thomson constructed a Crookes tube with an [[electrometer]] set to one side, out of the direct path of the cathode rays. Thomson could trace the path of the ray by observing the phosphorescent patch it created where it hit the surface of the tube. Thomson observed that the electrometer registered a charge only when he deflected the cathode ray to it with a magnet. He concluded that the negative charge and the rays were one and the same.&lt;ref name="referenceB"/&gt;
{{Clear}}

====Electrical deflection====
{{refimprove|section|date=August 2017}}&lt;!--only first paragraph has a citation--&gt;
{{multiple image
 | align = right 
 | direction = vertical
 | width = 452
 | footer =
 | image1 = JJ Thomson Cathode Ray 2.png
 | alt1 =
 | caption1 = Thomson's illustration of the Crookes tube by which he observed the deflection of cathode rays by an electric field (and later measured their mass-to-charge ratio). Cathode rays were emitted from the cathode C, passed through slits A (the anode) and B ([[Ground (electricity)|grounded]]), then through the electric field generated between plates D and E, finally impacting the surface at the far end.
 | image2 = Thomson cathode ray exp.gif
 | alt2 =
 | caption2 = The cathode ray (blue line) was deflected by the electric field (yellow).
}}


In May–June 1897, Thomson investigated whether or not the rays could be deflected by an electric field.&lt;ref name="ReferenceA"/&gt; Previous experimenters had failed to observe this, but Thomson believed their experiments were flawed because their tubes contained too much gas.

Thomson constructed a [[Crookes tube]] with a better vacuum. At the start of the tube was the cathode from which the rays projected. The rays were sharpened to a beam by two metal slits – the first of these slits doubled as the anode, the second was connected to the earth. The beam then passed between two parallel aluminium plates, which produced an electric field between them when they were connected to a battery. The end of the tube was a large sphere where the beam would impact on the glass, created a glowing patch. Thomson pasted a scale to the surface of this sphere to measure the deflection of the beam. Note that any electron beam would collide with some residual gas atoms within the Crookes tube, thereby ionizing them and producing electrons and ions in the tube ([[space charge]]); in previous experiments this space charge electrically screened the externally applied electric field. However, in Thomson's Crookes tube the density of residual atoms was so low that the space charge from the electrons and ions was insufficient to electrically screen the externally applied electric field, which permitted Thomson to successfully observe electrical deflection.

When the upper plate was connected to the negative pole of the battery and the lower plate to the positive pole, the glowing patch moved downwards, and when the polarity was reversed, the patch moved upwards.
{{Clear}}

====Measurement of mass-to-charge ratio====



[[File:JJ Thomson exp3.gif|thumb]]

In his classic experiment, Thomson measured the [[mass-to-charge ratio]] of the cathode rays by measuring how much they were deflected by a magnetic field and comparing this with the electric deflection. He used the same apparatus as in his previous experiment, but placed the discharge tube between the poles of a large electromagnet. He found that the mass-to-charge ratio was over a thousand times ''lower'' than that of a hydrogen ion (H&lt;sup&gt;+&lt;/sup&gt;), suggesting either that the particles were very light and/or very highly charged.&lt;ref name="PhilMag"/&gt;  Significantly, the rays from every cathode yielded the same mass-to-charge ratio. This is in contrast to [[anode rays]] (now known to arise from positive ions emitted by the anode), where the mass-to-charge ratio varies from anode-to-anode.  Thomson himself remained critical of what his work established, in his Nobel Prize acceptance speech referring to "corpuscles" rather than "electrons".

Thomson's calculations can be summarised as follows (notice that we reproduce here Thomson's original notations, using F instead of E for the electric field and H instead of B for the magnetic field):

The electric deflection is given by Θ = Fel/mv&lt;sup&gt;2&lt;/sup&gt; where Θ is the angular electric deflection, F is applied electric intensity, e is the charge of the cathode ray particles, l is the length of the electric plates, m is the mass of the cathode ray particles and v is the velocity of the cathode ray particles.

The magnetic deflection is given by φ = Hel/mv where φ is the angular magnetic deflection and H is the applied magnetic field intensity.

The magnetic field was varied until the magnetic and electric deflections were the same, when Θ = φ and Fel/mv&lt;sup&gt;2&lt;/sup&gt;= Hel/mv. This can be simplified to give m/e = H&lt;sup&gt;2&lt;/sup&gt;l/FΘ. The electric deflection was measured separately to give Θ and H, F and l were known, so m/e could be calculated.
{{Clear}}

====Conclusions====
{{quote|As the cathode rays carry a charge of negative electricity, are deflected by an electrostatic force as if they were negatively electrified, and are acted on by a magnetic force in just the way in which this force would act on a negatively electrified body moving along the path of these rays, I can see no escape from the conclusion that they are charges of negative electricity carried by particles of matter.|J. J. Thomson&lt;ref name="PhilMag" /&gt;}}

As to the source of these particles, Thomson believed they emerged from the molecules of gas in the vicinity of the cathode.

{{quote|If, in the very intense electric field in the neighbourhood of the cathode, the molecules of the gas are dissociated and are split up, not into the ordinary chemical atoms, but into these primordial atoms, which we shall for brevity call corpuscles; and if these corpuscles are charged with electricity and projected from the cathode by the electric field, they would behave exactly like the cathode rays.|J. J. Thomson&lt;ref name="Philosophical Magazine 1897"&gt;{{cite journal |last=Thomson |first=J. J.|url=http://web.lemoyne.edu/~GIUNTA/thomson1897.html |title=Cathode rays |journal=Philosophical Magazine |volume=44 |page=293 |year=1897}}&lt;/ref&gt;}}

Thomson imagined the atom as being made up of these corpuscles orbiting in a sea of positive charge; this was his [[plum pudding model]]. This model was later proved incorrect when his student [[Ernest Rutherford]] showed that the positive charge is concentrated in the nucleus of the atom.

===Other work===
In 1905, Thomson discovered the natural [[radioactivity]] of [[potassium]].&lt;ref name='Phil Mag 1905'&gt;{{cite journal|doi=10.1080/14786440509463405|title=On the emission of negative corpuscles by the alkali metals|journal=Philosophical Magazine |series=Series 6|year=1905|first=J. J. |last=Thomson|volume=10|issue=59|pages=584–590}}&lt;/ref&gt;

In 1906, Thomson demonstrated that [[hydrogen]] had only a single [[electron]] per atom. Previous theories allowed various numbers of electrons.&lt;ref&gt;{{The Timetables of Science|pages=411}}&lt;/ref&gt;&lt;ref name='Phil Mag 1906'&gt;{{cite journal|title=On the Number of Corpuscles in an Atom |journal=Philosophical Magazine |date=June 1906 |first=J. J. |last=Thomson |volume=11 |issue= 66|pages=769–781 |url=http://dbhs.wvusd.k12.ca.us/webdocs/Chem-History/Thomson-1906/Thomson-1906.html |accessdate=4 October 2008 |doi=10.1080/14786440609463496 |deadurl=yes |archiveurl=https://web.archive.org/web/20071219132619/http://dbhs.wvusd.k12.ca.us/webdocs/Chem-History/Thomson-1906/Thomson-1906.html |archivedate=19 December 2007 }}&lt;/ref&gt;

===Awards and honours===
[[File:J.J. Thomson Plaque outside the Old Cavendish Laboratory.jpg|thumb|Plaque commemorating J. J. Thomson's discovery of the electron outside the old Cavendish Laboratory in Cambridge]]
Thomson was elected a [[Fellow of the Royal Society]] (FRS)&lt;ref name="frs"/&gt;&lt;ref name=EBThomson&gt;{{cite book|last1=Thomson|first1=Sir George Paget|chapter=Sir J.J. Thomson, British Physicist|title=Encyclopædia Brittanica|url=http://www.britannica.com/EBchecked/topic/593074/Sir-JJ-Thomson|accessdate=11 February 2015}}&lt;/ref&gt; and appointed to the Cavendish Professorship of [[Experimental Physics]] at the [[Cavendish Laboratory]], [[University of Cambridge]] in 1884.&lt;ref name="Profile"/&gt; Thomson won numerous awards and honours during his career including:
* [[Adams Prize]] (1882)
* [[Royal Medal]] (1894)
* [[Hughes Medal]] (1902)
* [[Hodgkins Medal]] (1902)
* [[Nobel Prize for Physics]] (1906)
* [[Elliott Cresson Medal]] (1910)
* [[Copley Medal]] (1914)
* [[Franklin Medal]] (1922)

Thomson was elected a Fellow of the [[Royal Society]]&lt;ref name="frs"/&gt; on 12 June 1884 and served as President of the Royal Society from 1915 to 1920.
====Posthumous honours====
In 1991, the [[Thomson (unit)|thomson]] (symbol: Th) was proposed as a unit to measure mass-to-charge ratio in [[mass spectrometry]] in his honour.&lt;ref&gt;{{cite journal|title=The 'Thomson'. A suggested unit for mass spectroscopists|journal=[[Rapid Communications in Mass Spectrometry]]|year=1991|first=R. G.|last=Cooks|author2=A. L. Rockwood|volume=5|issue=2|page=93}}&lt;/ref&gt;

J J Thomson Avenue, on the [[University of Cambridge]] campus, is named after Thomson.&lt;ref&gt;{{cite web|url=http://www.cambridgenetwork.co.uk/news/cambridge-physicist-is-streets-ahead/|title=Cambridge Physicist is streets ahead|accessdate=2014-07-31|date=2002-07-18}}&lt;/ref&gt;

In November 1927, J.J. Thomson opened the Thomson building, named in his honour, in the [[The Leys School|Leys School]], Cambridge.&lt;ref&gt;{{cite web|url=https://www.theleys.net/about-us/history/thomson-building|archive-url=https://web.archive.org/web/20150111042826/https://www.theleys.net/about-us/history/thomson-building|dead-url=yes|archive-date=2015-01-11|title=Opening of the New Science Building: Thomson|accessdate=2015-01-10|date=2005-12-01}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

==Bibliography==
* 1883. ''A Treatise on the Motion of Vortex Rings: An essay to which the Adams Prize was adjudged in 1882, in the University of Cambridge''. London: Macmillan and Co., pp.&amp;nbsp;146. Recent reprint: {{ISBN|0-543-95696-2}}.
* 1888. ''Applications of Dynamics to Physics and Chemistry''. London: Macmillan and Co., pp.&amp;nbsp;326. Recent reprint: {{ISBN|1-4021-8397-6}}.
* 1893. ''Notes on recent researches in electricity and magnetism: intended as a sequel to Professor Clerk-Maxwell's 'Treatise on Electricity and Magnetism{{'}}''. Oxford University Press, pp.xvi and 578. 1991, Cornell University Monograph: {{ISBN|1-4297-4053-1}}.
* 1921 (1895). ''Elements Of The Mathematical Theory Of Electricity And Magnetism''. London: Macmillan and Co. [https://books.google.com/books?id=w9kEAAAAYAAJ&amp;dq=elements+of+the+mathematical+theory+of+electricity+and+magnetism&amp;printsec=frontcover#PPP7,M1 Scan of 1895 edition.]
* ''A Text book of Physics in Five Volumes'', co-authored with [[J.H. Poynting]]: (1) [https://archive.org/details/textbookofphysic01poynuoft Properties of Matter], (2) [https://archive.org/details/atextbookphysic02thomgoog Sound], (3) [https://archive.org/details/textbookofphysic00poynuoft Heat], (4) Light, and (5) [https://archive.org/details/textbookofphysi00poynuoft Electricity and Magnetism]. Dated 1901 and later, and with revised later editions.
* Dahl, Per F., "''Flash of the Cathode Rays: A History of J.J. Thomson's Electron''". Institute of Physics Publishing. June 1997. {{ISBN|0-7503-0453-7}}
* J.J. Thomson (1897) "Cathode Rays", ''The Electrician'' 39, 104, also published in ''Proceedings of the Royal Institution'' 30 April 1897, 1–14—first announcement of the "corpuscle" (before the classic mass and charge experiment)
* J.J. Thomson (1897), [http://web.lemoyne.edu/~GIUNTA/thomson1897.html ''Cathode rays''], ''Philosophical Magazine'', 44, 293—The classic measurement of the electron mass and charge
* J.J. Thomson (1912), "Further experiments on positive rays" ''Philosophical Magazine'', 24, 209–253—first announcement of the two neon parabolae
* J.J. Thomson (1913), [http://web.lemoyne.edu/~giunta/canal.html ''Rays of positive electricity''], ''Proceedings of the Royal Society'', A 89, 1–20—Discovery of neon isotopes
* J.J. Thomson (1904), [https://web.archive.org/web/20131213172104/http://www.cond-mat.physik.uni-mainz.de/~oettel/ws10/thomson_PhilMag_7_237_1904.pdf "On the Structure of the Atom]: an Investigation of the Stability and Periods of Oscillation of a number of Corpuscles arranged at equal intervals around the Circumference of a Circle; with Application of the Results to the Theory of Atomic Structure," ''Philosophical Magazine'' Series 6, Volume 7, Number 39, pp. 237–265. This paper presents the classical "[[plum pudding model]]" from which the [[Thomson Problem]] is posed.
* J.J. Thomson (1923), ''The Electron in Chemistry: Being Five Lectures Delivered at the Franklin Institute,'' Philadelphia.
* Thomson, Sir J. J. (1936), ''Recollections and Reflections'', London: G. Bell &amp; Sons, Ltd. Republished as [https://books.google.com.au/books?id=K8mn6N7oPzwC&amp;printsec=frontcover&amp;dq=Recollections+and+Reflections+thomson&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiB5q_b2PnaAhVKybwKHf7oD5QQ6AEIJzAA#v=onepage&amp;q=Recollections%20and%20Reflections%20thomson&amp;f=false digital edition], Cambridge: University Press, 2011 (Cambridge Library Collection series).
* Thomson, George Paget. (1964) ''J.J. Thomson: Discoverer of the Electron''. Great Britain: Thomas Nelson &amp; Sons, Ltd.
* Davis, Eward Arthur &amp; Falconer, Isobel (1997), ''J.J. Thomson and the Discovery of the Electron''. {{ISBN|978-0-7484-0696-8}}
* Falconer, Isobel (1988) "J.J. Thomson's Work on Positive Rays, 1906–1914" ''Historical Studies in the Physical and Biological Sciences'' 18(2) 265–310
* Falconer, Isobel (2001) "Corpuscles to Electrons" in J Buchwald and A Warwick (eds) ''Histories of the Electron'', Cambridge, Mass: MIT Press, pp.&amp;nbsp;77–100.
* {{cite journal |last1=Navarro |first1=Jaume |title=J. J. Thomson on the Nature of Matter: Corpuscles and the Continuum |journal=Centaurus |date=2005 |volume=47 |issue=4 |pages=259–282 |doi=10.1111/j.1600-0498.2005.00028.x}}
* {{cite journal|doi=10.1016/j.jasms.2009.07.008|pmid=19734055|title=J. J. Thomson goes to America|journal=Journal of the American Society for Mass Spectrometry|volume=20|issue=11|pages=1964–1973|year=2009|last1=Downard|first1=Kevin M.}}

==External links==
{{Library resources box|by=yes|onlinebooksby=yes|viaf=7472229}}
* {{commonsinline|Joseph John Thomson}}
* {{wikisource author-inline}}
* {{wikiquote-inline}}
* [http://www.aip.org/history/electron/ The Discovery of the Electron]
* [http://nobelprize.org/nobel_prizes/physics/laureates/1906/ The Nobel Prize in Physics 1906]
* [http://alsos.wlu.edu/qsearch.aspx?browse=people/Thomson,+Joseph+J. Annotated bibliography for Joseph J. Thomson from the Alsos Digital Library for Nuclear Issues]
* [https://web.archive.org/web/20151201005910/http://www.asa3.org/ASA/PSCF/1986/JASA6-86Seeger.html Essay on Thomson life and religious views]
* [http://www.crtsite.com/page3.html The Cathode Ray Tube site]
* [http://nobelprize.org/nobel_prizes/physics/laureates/1906/thomson-lecture.html Nobel Prize acceptance lecture (1906)]
* [https://books.google.com/books?id=DyUDAAAAMBAJ&amp;lpg=PA521&amp;pg=PA521#v=onepage&amp;q=&amp;f=false Thomson's discovery of the isotopes of Neon]
* [https://web.archive.org/web/20110719091132/http://www-outreach.phy.cam.ac.uk/camphy/museum/area2/cabinet3.htm Photos of some of Thomson's remaining apparatus at the Cavendish Laboratory Museum]
* {{Gutenberg author | id=Thomson,+J.+J.}}
* {{Internet Archive author |sname=Joseph John Thomson |sopt=tight}}

{{s-start}}
{{s-aca}}
{{s-bef|before=[[Henry Montagu Butler]]}}
{{s-ttl|title=[[Trinity College, Cambridge|Master of Trinity College, Cambridge]]|years=1918–1940}}
{{s-aft|after=[[George Macaulay Trevelyan]]}}
{{s-end}}
{{Copley Medallists 1901-1950}}
{{Nobel Prize in Physics Laureates 1901-1925}}
{{Royal Society presidents 1900s}}
{{Scientists whose names are used as non SI units}}
{{Scientists whose names are used in physical constants}}
{{Masters of Trinity College, Cambridge}}

{{Authority control}}

{{DEFAULTSORT:Thomson, J. J.}}
[[Category:1856 births]]
[[Category:1940 deaths]]
[[Category:20th-century physicists]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Burials at Westminster Abbey]]
[[Category:English Anglicans]]
[[Category:English mathematicians]]
[[Category:English physicists]]
[[Category:Experimental physicists]]
[[Category:Fellows of the Royal Society]]
[[Category:Masters of Trinity College, Cambridge]]
[[Category:Members of the Order of Merit]]
[[Category:Nobel laureates in Physics]]
[[Category:People from Cheetham Hill]]
[[Category:Presidents of the Royal Society]]
[[Category:Recipients of the Copley Medal]]
[[Category:Royal Medal winners]]
[[Category:Knights Bachelor]]
[[Category:Second Wranglers]]
[[Category:Alumni of the Victoria University of Manchester]]
[[Category:Presidents of the British Science Association]]
[[Category:Presidents of the Institute of Physics]]
[[Category:Presidents of the Physical Society]]
[[Category:Mass spectrometrists]]</text>
      <sha1>7x00vzfm5eshsfrvtsbmlr86l0iphx9</sha1>
    </revision>
  </page>
  <page>
    <title>Jean Taylor</title>
    <ns>0</ns>
    <id>36328633</id>
    <revision>
      <id>814472979</id>
      <parentid>809115742</parentid>
      <timestamp>2017-12-09T01:02:54Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: journal = Annals of Mathematics. Second Series → journal = Annals of Mathematics |series=Second Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6957">{{other people}}
'''Jean Ellen Taylor''' (born September 17, 1944) is an [[United States|American]] mathematician who is currently a professor emerita at [[Rutgers University]]&lt;ref&gt;[http://www.math.rutgers.edu/people/?type=emeritus Emeritus faculty listing], Rutgers University Mathematics Department, retrieved 2012-07-04.&lt;/ref&gt; and visiting faculty at [[Courant Institute of Mathematical Sciences]] of [[New York University]].&lt;ref&gt;[http://math.nyu.edu/people/visitors.html Visiting members and research fellows], Courant Institute, retrieved 2012-07-04.&lt;/ref&gt;

==Biography==
Taylor was born on September 17, 1944 in [[San Mateo, California]]; her father was a lawyer, her mother a schoolteacher, and she had two siblings. She did her undergraduate studies at [[Mount Holyoke College]], graduating summa cum laude with an A.B. in 1966. She began her graduate studies in chemistry at the [[University of California, Berkeley]], but after receiving an M.Sc. she switched to mathematics under the mentorship of [[Shiing-Shen Chern|S. S. Chern]] and then transferred to the [[University of Warwick]] and received a second M.Sc. in mathematics there. She completed a doctorate in 1972 from [[Princeton University]] under the supervision of [[Frederick J. Almgren, Jr.]]&lt;ref name="pwm"&gt;{{citation|contribution=Jean E. Taylor: Five Little Crystals and How They Grew|title=Profiles of Women in Mathematics: The Emmy Noether Lectures|publisher=[[Association for Women in Mathematics]]|year=2003|url=http://www.awm-math.org/noetherbrochure/Taylor03.html|accessdate=2012-07-04}}.&lt;/ref&gt;&lt;ref&gt;{{mathgenealogy|name=Jean Ellen Taylor|id=6182}}.&lt;/ref&gt;

Taylor joined the Rutgers faculty in 1973, and retired in 2002.&lt;ref name="pwm"/&gt; She was president of the [[Association for Women in Mathematics]] from 1999 to 2001.&lt;ref name="pwm"/&gt;&lt;ref&gt;[https://sites.google.com/site/awmmath/awm/history AWM history], [[Association for Women in Mathematics]], retrieved 2012-07-04.&lt;/ref&gt;

She has been married three times, to mathematician [[John Guckenheimer]] (her fellow student at Berkeley), to her advisor Fred Almgren (with whom she had a daughter and two step-children), and to financier and science advocate [[William T. Golden]].&lt;ref name="pwm"/&gt;&lt;ref&gt;{{citation|title=William T. Golden, Financier and Key Science Adviser, Is Dead at 97|journal=[[New York Times]]|date=October 9, 2007|first=Dennis|last=Overbye|url=https://www.nytimes.com/2007/10/09/us/09golden.html}}.&lt;/ref&gt;

==Research==
Taylor is known for her work on the mathematics of [[soap bubble]]s and of the growth of [[crystal]]s. In 1976 she published the first proof of [[Plateau's laws]], a description of the shapes formed by soap bubble clusters that had been formulated without proof in the 19th century by [[Joseph Plateau]].{{sfnp|Taylor|1976}}

==Awards and honors==
Taylor is a fellow of the [[American Academy of Arts and Sciences]], the [[American Association for the Advancement of Science]], the [[Association for Women in Mathematics]], the [[American Mathematical Society]]&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-08-25.&lt;/ref&gt; and the [[Society for Industrial and Applied Mathematics]].&lt;ref&gt;{{cite web|title=SIAM Fellows: Class of 2017|url=http://fellows.siam.org/index.php?sort=year&amp;value=2017|website=Society for Industrial and Applied Mathematics|accessdate=24 April 2017}}&lt;/ref&gt; In 2001, she received an honorary doctorate from Mount Holyoke.&lt;ref name="pwm"/&gt; In 2017, she was selected as a fellow of the [[Association for Women in Mathematics]] in the inaugural class.&lt;ref&gt;{{cite web|title=Launch of the AWM Fellows Program|url=https://sites.google.com/site/awmmath/awm-fellows|website=sites.google.com/site/awmmath/|publisher=Association for Women in Mathematics|accessdate=7 November 2017}}&lt;/ref&gt;

==Selected publications==
*{{citation
 | last = Taylor | first = Jean E.
 | issue = 3
 | journal = Annals of Mathematics |series=Second Series
 | mr = 0428181
 | pages = 489–539
 | title = The structure of singularities in soap-bubble-like and soap-film-like minimal surfaces
 | volume = 103
 | year = 1976
 | doi=10.2307/1970949}}.
*{{citation
 | last1 = Taylor | first1 = J. E.
 | last2 = Cahn | first2 = J. W.
 | last3 = Handwerker | first3 = C. A.
 | doi = 10.1016/0956-7151(92)90090-2
 | issue = 7
 | journal = Acta Metallurgica et Materialia
 | pages = 1443–1474
 | title = Overview No. 98. I. Geometric models of crystal growth
 | volume = 40
 | year = 1992}}.
*{{citation
 | last = Taylor | first = J. E.
 | doi = 10.1016/0956-7151(92)90091-R
 | issue = 7
 | journal = Acta Metallurgica et Materialia
 | pages = 1475–1485
 | title = Overview No. 98. II. Mean curvature and weighted mean curvature
 | volume = 40
 | year = 1992}}.
*{{citation
 | last1 = Almgren | first1 = Fred
 | last2 = Taylor | first2 = Jean E.
 | last3 = Wang | first3 = Lihe
 | doi = 10.1137/0331020
 | issue = 2
 | journal = SIAM Journal on Control and Optimization
 | mr = 1205983
 | pages = 387–438
 | title = Curvature-driven flows: a variational approach
 | volume = 31
 | year = 1993}}.
*{{citation
 | last1 = Cahn | first1 = J. W.
 | last2 = Taylor | first2 = J. E.
 | doi = 10.1016/0956-7151(94)90123-6
 | issue = 4
 | journal = Acta Metallurgica et Materialia
 | pages = 1045–1053
 | title = Overview No. 113. Surface motion by surface diffusion
 | volume = 42
 | year = 1994}}.
*{{citation
 | last = Taylor | first = Jean E.
 | mr = 1943134
 | issue = 1
 | journal = Bulletin of the American Mathematical Society
 | pages = 69–87
 | title = Some mathematical challenges in materials science
 | volume = 40
 | year = 2003
 | doi=10.1090/s0273-0979-02-00967-9}}.
*{{citation
 | last = Taylor | first = Jean E.
 | doi = 10.1007/BF02838879
 | issue = 6
 | journal = Resonance
 | pages = 26–30
 | title = Soap bubbles and crystals
 | volume = 11
 | year = 2006}}.

==References==
{{reflist}}

==External links==
* [http://www.math.rutgers.edu/~taylor/ Home page at Rutgers]
* [http://www.agnesscott.edu/lriddle/women/jtaylor.htm "Jean Taylor", Biographies of Women Mathematicians], [[Agnes Scott College]]

{{Authority control}}

{{DEFAULTSORT:Taylor, Jean E.}}
[[Category:1944 births]]
[[Category:Living people]]
[[Category:American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Mount Holyoke College alumni]]
[[Category:University of California, Berkeley alumni]]
[[Category:Alumni of the University of Warwick]]
[[Category:Princeton University alumni]]
[[Category:Rutgers University faculty]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the American Association for the Advancement of Science]]
[[Category:Courant Institute of Mathematical Sciences faculty]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Fellows of the Association for Women in Mathematics]]</text>
      <sha1>3qpic7gyoj2gieks05qm2krv9letg88</sha1>
    </revision>
  </page>
  <page>
    <title>John of Tynemouth (geometer)</title>
    <ns>0</ns>
    <id>30370276</id>
    <revision>
      <id>848814950</id>
      <parentid>848814783</parentid>
      <timestamp>2018-07-04T14:20:46Z</timestamp>
      <contributor>
        <username>Ealdgyth</username>
        <id>4497767</id>
      </contributor>
      <comment>links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4137">{{Other uses|John of Tynemouth (disambiguation){{!}}John of Tynemouth}}

'''John of Tynemouth''' was a 13th-century [[mathematician]] and [[List_of_geometers|geometer]].

Little is known of John's background, but he authored ''De curvis superficiebus'' or ''Liber de curvis superficiebus Archimenidis'', a tract about [[Archimedes]]' measurements of spheres. This is an important work in the history of medieval geometry, as it helped transmit Archimedes' ideas to other medieval scholars. The work itself follows closely Archimedes' own reasoning, but with enough differences to lead modern historians to believe that John's work was dependent on a Greek text from late antiquity.&lt;ref name=DNB&gt;Knorr "Tynemouth, John of (fl. early 13th cent.) also including John of Tynemouth (d. 1221)" ''Oxford Dictionary of National Biography''&lt;/ref&gt;

''De curvis'' survives in over 12 manuscripts, and was used by a number of other medieval scholars, including [[Robert Grosseteste]], [[Jordanus de Nemore]], [[Gerard of Brussels]], and [[Roger Bacon]].&lt;ref name=DNB/&gt;

Certain stylistic choices in ''De curvis'' suggest that John was also responsible for a number of other works:&lt;ref&gt;Edited in {{cite book|last1=Clagett|first1=Marshall|title=Archimedes in the middle ages, quasi-archimedean geometry in the thirteenth century|date=1984|publisher=American Philosophical Society|location=Philadelphia|isbn=0871691574}}&lt;/ref&gt;

* ''De circulo quadrando'', a revision of another of Archimedes' works, the ''De quadratura circuli'', which is now in [[Florence]] at the [[National Central Library (Florence)|Biblioteca Nazionale]];
* ''De quadratura circuli'';
* ''De figuris isoperimetris'', now in [[Oxford University]]'s [[Bodleian Library]] as manuscript Digby 174;&lt;ref&gt;{{cite journal|last1=Busard|first1=H. L. L.|title=Der Traktat ''De isoperimetris'', der unmittelbar aus dem Griechischen ins Lateinische versetzt worden ist|journal=Mediaeval Studies|date=1980|volume=42|pages=61–88|doi=10.1484/J.MS.2.306255}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Knorr|first1=Wilbur R.|title=Paraphrase Editions of Latin Mathematical Texts: De figuris ysoperimetris|journal=Mediaeval Studies|date=1990|volume=52|pages=132–189|doi=10.1484/J.MS.2.306377}}&lt;/ref&gt;
* a paraphrase of [[Euclid]]'s ''Elementa'' from the translation of [[Adelard of Bath]], later cited by [[Roger Bacon]];
* ''Quaelibet media proportionalia''.

==Citations==
{{reflist}}

==References==
{{refbegin}}
* {{cite encyclopedia |author= Knorr, Wilbur R. |title=Tynemouth, John of (fl. early 13th cent.) also including John of Tynemouth (d. 1221)|encyclopedia= Oxford Dictionary of National Biography |publisher= Oxford University Press|year= 2004 |url=http://www.oxforddnb.com/view/article/52685|format=fee required| accessdate=8 January 2011}} {{ODNBsub}}
{{refend}}

==Further reading==
{{refbegin}}
* {{cite journal |author=Clagett, M. |title=The Medieval Latin Translations from the Arabic of the ''Elements'' of Euclid, with Special Emphasis on the Versions of Adelard of Bath|journal=Isis |volume=44 |year=1953 |pages=16–42 |doi=10.1086/348186}}
* {{cite journal |author=Knorr, W. R. |title=John of Tynemouth, alis John of London: Emerging Portrait of a Singular Medieval Mathematician|journal=British Journal for the History of Science |volume=23 |year=1990 |pages=293–330 |doi=10.1017/s0007087400044009}}
* {{cite journal |author=Knorr, W. R. |title=On a Medieval Circle Quadrature: ''De Circulo Quadrando'' |journal=Historia Mathematica |volume=18 |year=1991 |pages=107–128 |doi=10.1016/0315-0860(91)90495-j}}
* {{cite journal |author=Knorr, W. R. |title=Paraphrase Editions of Latin Mathematical Texts: ''De Figuris Ysopherimetris'' |journal = Mediaeval Studies |volume=52 |year=1990 |pages=132–189}}
* {{cite book |author=Knorr, W. R. |title=Textual Studies in Ancient and Medieval Geometry |year=1989 }}
{{refend}}

{{authority control}}

{{Use British English|date=August 2017}}
{{Use dmy dates|date=August 2017}}

{{short description|13th-century English mathematician}}

[[Category:13th-century Latin writers]]
[[Category:13th-century mathematicians]]
[[Category:Geometers]]</text>
      <sha1>o51ntkdlu9rb9iqjiqk84h8a7fijidv</sha1>
    </revision>
  </page>
  <page>
    <title>K-regular sequence</title>
    <ns>0</ns>
    <id>49645022</id>
    <revision>
      <id>858853083</id>
      <parentid>858852713</parentid>
      <timestamp>2018-09-10T01:56:27Z</timestamp>
      <contributor>
        <username>Eric Rowland</username>
        <id>7918938</id>
      </contributor>
      <comment>/* Properties */ growth rate</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10216">{{DISPLAYTITLE:''k''-regular sequence}}
In [[mathematics]] and [[theoretical computer science]], a '''''k''-regular sequence''' is an infinite [[sequence]] of terms characterized by a [[Finite-state machine|finite automaton]] with auxiliary storage.&lt;ref name=AS44&gt;Allouche &amp; Shallit (1992), Theorem 4.4&lt;/ref&gt; They are a generalization of [[automatic sequence|''k''-automatic sequences]] to alphabets of infinite size.

==Definition==
There exist several characterizations of ''k''-regular sequences, all of which are equivalent. Some common characterizations are as follows. For each, we take ''R''′ to be a [[commutative]] [[Noetherian ring]] and we take ''R'' to be a [[ring (mathematics)|ring]] containing ''R''′.

===''k''-kernel===
Let ''k''&amp;nbsp;≥&amp;nbsp;2. The ''k-kernel'' of the sequence &lt;math&gt;s(n)_{n \geq 0}&lt;/math&gt; is the set of subsequences
:&lt;math&gt;K_{k}(s) = \{s(k^e n + r)_{n \geq 0} : e \geq 0 \text{ and } 0 \leq r \leq k^e - 1\}.&lt;/math&gt;
The sequence &lt;math&gt;s(n)_{n \geq 0}&lt;/math&gt; is (''R''′, ''k'')-regular (often shortened to just "''k''-regular") if the &lt;math&gt;R'&lt;/math&gt;-module generated by ''K''&lt;sub&gt;''k''&lt;/sub&gt;(''s'') is a [[Finitely generated module|finitely-generated]] ''R''′-[[module (mathematics)|module]].&lt;ref name=AS21&gt;Allouche &amp; Shallit (1992), Definition 2.1&lt;/ref&gt;

In the special case when &lt;math&gt;R' = R = \mathbb{Q}&lt;/math&gt;, the sequence &lt;math&gt;s(n)_{n \geq 0}&lt;/math&gt; is &lt;math&gt;k&lt;/math&gt;-regular if &lt;math&gt;K_k(s)&lt;/math&gt; is contained in a finite-dimensional vector space over &lt;math&gt;\mathbb{Q}&lt;/math&gt;.

===Linear combinations===
A sequence ''s''(''n'') is ''k''-regular if there exists an integer ''E'' such that, for all ''e''&lt;sub&gt;''j''&lt;/sub&gt; &gt; ''E'' and 0 ≤ ''r''&lt;sub&gt;''j''&lt;/sub&gt; ≤ ''k''&lt;sup&gt;''e''&lt;sub&gt;''j''&lt;/sub&gt;&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1, every subsequence of ''s'' of the form ''s''(''k''&lt;sup&gt;''e''&lt;sub&gt;''j''&lt;/sub&gt;&lt;/sup&gt;''n''&amp;nbsp;+&amp;nbsp;''r''&lt;sub&gt;''j''&lt;/sub&gt;) is expressible as an ''R''′-[[linear combination]] &lt;math&gt;\sum_{i} c_{ij} s(k^{f_{ij}}n + b_{ij})&lt;/math&gt;, where ''c''&lt;sub&gt;''ij''&lt;/sub&gt; is an integer, ''f''&lt;sub&gt;''ij''&lt;/sub&gt; ≤ ''E'', and 0 ≤ ''b''&lt;sub&gt;''ij''&lt;/sub&gt; ≤ ''k''&lt;sup&gt;''f''&lt;sub&gt;''ij''&lt;/sub&gt;&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1.&lt;ref name=AS22&gt;Allouche &amp; Shallit (1992), Theorem 2.2&lt;/ref&gt;

Alternatively, a sequence ''s''(''n'') is ''k''-regular if there exist an integer ''r'' and subsequences ''s''&lt;sub&gt;1&lt;/sub&gt;(''n''), ..., ''s''&lt;sub&gt;''r''&lt;/sub&gt;(''n'') such that, for all 1 ≤ ''i'' ≤ ''r'' and 0 ≤ ''a'' ≤ ''k''&amp;nbsp;−&amp;nbsp;1, every sequence ''s''&lt;sub&gt;''i''&lt;/sub&gt;(''kn''&amp;nbsp;+&amp;nbsp;''a'') in the ''k''-kernel ''K''&lt;sub&gt;''k''&lt;/sub&gt;(''s'') is an ''R''′-linear combination of the subsequences ''s''&lt;sub&gt;''i''&lt;/sub&gt;(''n'').&lt;ref name=AS22 /&gt;

===Formal series===
Let ''x''&lt;sub&gt;0&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''k''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt; be a set of ''k'' non-commuting variables and let τ be a map sending some natural number ''n'' to the string ''x''&lt;sub&gt;''a''&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; ... ''x''&lt;sub&gt;''a''&lt;sub&gt;''e''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;&lt;/sub&gt;, where the base-''k'' representation of ''x'' is the string ''a''&lt;sub&gt;''e''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;...''a''&lt;sub&gt;0&lt;/sub&gt;. Then a sequence ''s''(''n'') is ''k''-regular if and only if the [[Formal power series|formal series]] &lt;math&gt;\sum_{n \geq 0} s(n) \tau (n)&lt;/math&gt; is &lt;math&gt;\mathbb{Z}&lt;/math&gt;-[[Rational series|rational]].&lt;ref name=AS43&gt;Allouche &amp; Shallit (1992), Theorem 4.3&lt;/ref&gt;

===Automata-theoretic===
The formal series definition of a ''k''-regular sequence leads to an automaton characterization similar to [[Marcel-Paul Schützenberger|Schützenberger]]'s matrix machine.&lt;ref name=AS44 /&gt;&lt;ref&gt;{{citation | last = Schützenberger | first = M.-P. | title = On the definition of a family of automata | journal = Information and Control | volume = 4 | year = 1961 | pages = 245–270 | doi=10.1016/S0019-9958(61)80020-X }}.&lt;/ref&gt;

==History==
The notion of ''k''-regular sequences was first investigated in a pair of papers by Allouche and Shallit.&lt;ref name=AS&gt;Allouche &amp; Shallit (1992, 2003)&lt;/ref&gt; Prior to this, Berstel and Reutenauer studied the theory of [[rational series]], which is closely related to ''k''-regular sequences.&lt;ref&gt;{{cite book | last1 = Berstel | first1 = Jean | last2 = Reutenauer | first2 = Christophe | title = Rational Series and Their Languages | volume = 12 | series = EATCS Monographs on Theoretical Computer Science | year = 1988 | isbn = 978-3-642-73237-9 | publisher = [[Springer Science+Business Media|Springer-Verlag]] }}&lt;/ref&gt;

==Examples==

===Ruler sequence===
Let &lt;math&gt;s(n) = \nu_2(n+1)&lt;/math&gt; be the [[p-adic valuation | &lt;math&gt;2&lt;/math&gt;-adic valuation]] of &lt;math&gt;n+1&lt;/math&gt;. The ruler sequence &lt;math&gt;s(n)_{n \geq 0} = 0, 1, 0, 2, 0, 1, 0, 3, \dots&lt;/math&gt; ({{OEIS2C|id=A007814}}) is &lt;math&gt;2&lt;/math&gt;-regular, and the &lt;math&gt;2&lt;/math&gt;-kernel
:&lt;math&gt;\{s(2^e n + r)_{n \geq 0} : e \geq 0 \text{ and } 0 \leq r \leq 2^e - 1\}&lt;/math&gt;
is contained in the two-dimensional vector space generated by &lt;math&gt;s(n)_{n \geq 0}&lt;/math&gt; and the constant sequence &lt;math&gt;1, 1, 1, \dots&lt;/math&gt;. These basis elements lead to the recurrence relations
:&lt;math&gt;
\begin{align}
s(2 n) &amp;= 0, \\
s(4 n + 1) &amp;= s(2 n + 1) - s(n), \\
s(4 n + 3) &amp;= 2 s(2 n + 1) - s(n),
\end{align}
&lt;/math&gt;
which, along with the initial conditions &lt;math&gt;s(0) = 0&lt;/math&gt; and &lt;math&gt;s(1) = 1&lt;/math&gt;, uniquely determine the sequence.&lt;ref name=ASe8&gt;Allouche &amp; Shallit (1992), Example 8&lt;/ref&gt;

===Thue–Morse sequence===
The [[Thue–Morse sequence]] ''t''(''n'') ({{OEIS2C|id=A010060}}) is the [[fixed point (mathematics)|fixed point]] of the morphism 0 → 01, 1 → 10. It is known that the Thue–Morse sequence is 2-automatic. Thus, it is also 2-regular, and its 2-kernel
:&lt;math&gt;\{t(2^e n + r)_{n \geq 0} : e \geq 0 \text{ and } 0 \leq r \leq 2^e - 1\}&lt;/math&gt;
consists of the subsequences &lt;math&gt;t(n)_{n \geq 0}&lt;/math&gt; and &lt;math&gt;t(2 n + 1)_{n \geq 0}&lt;/math&gt;.

===Cantor numbers===
The sequence of [[Cantor set|Cantor numbers]] ''c''(''n'') ({{OEIS2C|id=A005823}}) consists of numbers whose [[Ternary numeral system|ternary]] expansions contain no 1s. It is straightforward to show that 
:&lt;math&gt;
\begin{align}
c(2n) &amp;= 3c(n), \\
c(2n+1) &amp;= 3c(n) + 2,
\end{align}
&lt;/math&gt;
and therefore the sequence of Cantor numbers is 2-regular.&lt;ref name=ASe3&gt;Allouche &amp; Shallit (1992), Example 3&lt;/ref&gt;

===Sorting numbers===
A somewhat interesting application of the notion of ''k''-regularity to the broader study of algorithms is found in the analysis of the [[merge sort]] algorithm. Given a list of ''n'' values, the number of comparisons made by the merge sort algorithm are the [[sorting number]]s, governed by the recurrence relation
:&lt;math&gt;
\begin{align}
T(1) &amp;= 0, \\
T(n) &amp;= T(\lfloor n / 2 \rfloor) + T(\lceil n / 2 \rceil)  + n - 1, \ n \geq 2.
\end{align}
&lt;/math&gt;
As a result, the sequence defined by the recurrence relation for merge sort, ''T''(''n''), constitutes a 2-regular sequence.&lt;ref name=ASe28&gt;Allouche &amp; Shallit (1992), Example 28&lt;/ref&gt;

===Other sequences===
If &lt;math&gt;f(x)&lt;/math&gt; is an [[integer-valued polynomial]], then &lt;math&gt;f(n)_{n \geq 0}&lt;/math&gt; is ''k''-regular for every &lt;math&gt;k \geq 2&lt;/math&gt;.

Allouche and Shallit give a number of additional examples of ''k''-regular sequences in their papers.&lt;ref name=AS /&gt;

==Properties==
''k''-regular sequences exhibit a number of interesting properties.
*Every [[automatic sequence|''k''-automatic sequence]] is ''k''-regular.&lt;ref&gt;Allouche &amp; Shallit (1992), Theorem 2.3&lt;/ref&gt;
*Every [[k-synchronized sequence|''k''-synchronized sequence]] is ''k''-regular.
*A ''k''-regular sequence takes on finitely many values if and only if it is ''k''-automatic.&lt;ref name=AS441&gt;Allouche &amp; Shallit (2003) p. 441&lt;/ref&gt; This is an immediate consequence of the class of ''k''-regular sequences being a generalization of the class of ''k''-automatic sequences.
*The class of ''k''-regular sequences is closed under termwise addition, termwise multiplication, and [[convolution]]. The class of ''k''-regular sequences is also closed under scaling each term of the sequence by an integer λ.&lt;ref name=AS441 /&gt;&lt;ref&gt;Allouche &amp; Shallit (1992), Theorem 2.5&lt;/ref&gt;&lt;ref&gt;Allouche &amp; Shallit (1992), Theorem 3.1&lt;/ref&gt;&lt;ref name=AS445&gt;Allouche &amp; Shallit (2003) p. 445&lt;/ref&gt;
*For multiplicatively independent ''k'',&amp;nbsp;''l''&amp;nbsp;≥&amp;nbsp;2, if a sequence is both ''k''-regular and ''l''-regular, then the sequence satisfies a linear recurrence.&lt;ref&gt;{{cite journal | first=J. | last=Bell | title=A generalization of Cobham’s theorem for regular sequences| journal=Séminaire Lotharingien de Combinatoire | volume=54A | year=2006 }}&lt;/ref&gt; This is a generalization of a result due to Cobham regarding sequences that are both ''k''-automatic and ''l''-automatic.&lt;ref&gt;{{cite journal | first=A. | last=Cobham | title=On the base-dependence of sets of numbers recognizable by finite automata | journal=Math. Systems Theory | volume=3 | issue=2 | year=1969 | pages=186–192 | doi=10.1007/BF01746527 }}&lt;/ref&gt;
*The ''n''th term of a ''k''-regular sequence of integers grows at most polynomially in ''n''.&lt;ref&gt;Allouche &amp; Shallit (1992) Theorem 2.10&lt;/ref&gt;

== Notes ==
{{reflist}}

==References==
*{{citation | last1 = Allouche | first1 = Jean-Paul | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit | title = The ring of ''k''-regular sequences | journal = Theoret. Comput. Sci. | volume = 98 | year = 1992 | pages = 163–197 | url = https://dx.doi.org/10.1016/0304-3975(92)90001-V | doi=10.1016/0304-3975(92)90001-v}}.
*{{citation | last1 = Allouche | first1 = Jean-Paul | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit | title = The ring of ''k''-regular sequences, II | journal = Theoret. Comput. Sci. | volume = 307 | year = 2003 | pages = 3–29 | url = https://dx.doi.org/10.1016/S0304-3975(03)00090-2 | doi=10.1016/s0304-3975(03)00090-2}}.
*{{cite book | last1 = Allouche | first1 = Jean-Paul | last2 = Shallit | first2 = Jeffrey | author2-link = Jeffrey Shallit | isbn = 978-0-521-82332-6 | publisher = [[Cambridge University Press]] | title = Automatic Sequences: Theory, Applications, Generalizations | year = 2003 | zbl=1086.11015 }}

[[Category:Combinatorics on words]]
[[Category:Automata (computation)]]
[[Category:Integer sequences]]
[[Category:Recurrence relations]]</text>
      <sha1>9j6x8wpy58uhemddfeupt8vioyota8j</sha1>
    </revision>
  </page>
  <page>
    <title>Laplacian smoothing</title>
    <ns>0</ns>
    <id>8722051</id>
    <revision>
      <id>759566124</id>
      <parentid>711437216</parentid>
      <timestamp>2017-01-11T23:09:50Z</timestamp>
      <contributor>
        <ip>128.100.3.109</ip>
      </contributor>
      <comment>add geometry processing category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2107">{{about|the mesh smoothing algorithm|the multinomial shrinkage estimator, also called ''Laplace smoothing'' or ''add-one smoothing''|additive smoothing}}

'''Laplacian smoothing''' is an algorithm to [[smoothing|smooth]] a [[Polygon mesh|polygonal mesh]].&lt;ref&gt;{{citation
 | last = Herrmann | first = Leonard R.
 | issue = 5
 | journal = Journal of the Engineering Mechanics Division
 | pages = 749–756
 | title = Laplacian-isoparametric grid generation scheme
 | volume = 102
 | year = 1976}}.&lt;/ref&gt;&lt;ref&gt;
{{cite book| author=Sorkine, O., Cohen-Or, D., Lipman, Y., Alexa, M., R\"{o}ssl, C., Seidel, H.-P.| chapter=Laplacian Surface Editing| title=Proceedings of the 2004 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing| year=2004| pages=175–184| publisher=ACM| location=Nice, France| series=SGP '04| doi=10.1145/1057432.1057456| isbn=3-905673-13-4| url=http://doi.acm.org/10.1145/1057432.1057456| accessdate=1 December 2013}}
&lt;/ref&gt; For each vertex in a mesh, a new position is chosen based on local information (such as the position of neighbors) and the vertex is moved there. In the case that a mesh is topologically a rectangular grid (that is, each internal vertex is connected to four neighbors) then this operation produces the [[Laplacian]] of the mesh.

More formally, the smoothing operation may be described per-vertex as:

:&lt;math&gt;\bar{x}_{i}= \frac{1}{N} \sum_{j=1}^{N}\bar{x}_j &lt;/math&gt;

Where &lt;math&gt;N&lt;/math&gt; is the number of adjacent vertices to node &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;\bar{x}_{j}&lt;/math&gt; is the position of the &lt;math&gt;j&lt;/math&gt;-th adjacent vertex and &lt;math&gt;\bar{x}_{i}&lt;/math&gt; is the new position for node &lt;math&gt;i&lt;/math&gt;.&lt;ref&gt;{{cite book |title=Mesh enhancement |last=Hansen |first=Glen A. |last2=Douglass |first2=R. W |first3=Andrew |last3=Zardecki |year=2005 |publisher=Imperial College Press |page=404 |ref=Glen05}}&lt;/ref&gt;

==See also==
*[[Tutte embedding]], an embedding of a planar mesh in which each vertex is already at the average of its neighbors' positions

==References==
&lt;references /&gt;

[[Category:Mesh generation]]
[[Category:Geometry processing]]


{{geometry-stub}}</text>
      <sha1>616217b4p4cq26lkjxf7annx7srxzle</sha1>
    </revision>
  </page>
  <page>
    <title>Margulis lemma</title>
    <ns>0</ns>
    <id>5180277</id>
    <revision>
      <id>835926205</id>
      <parentid>822511567</parentid>
      <timestamp>2018-04-11T16:29:09Z</timestamp>
      <contributor>
        <username>Havranwiki</username>
        <id>29923944</id>
      </contributor>
      <minor/>
      <comment>/* Other applications */ Typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7644">In differential geometry, a subfield of [[mathematics]], the '''Margulis lemma''' (named after [[Grigory Margulis]]) is a result about [[discrete subgroup]]s of isometries of a [[Sectional curvature#Manifolds with non-positive sectional curvature|non-positively curved]] [[Riemannian manifold]]s (e.g. the [[hyperbolic space|hyperbolic n-space]]). Roughly, it states that within a fixed radius, usually called the '''Margulis constant''', the structure of the orbits of such a group cannot be too complicated. More precisely, within this radius around a point all points in its orbit are in fact in the orbit of a [[Nilpotent group|nilpotent]] subgroup (in fact a bounded finite number of such).

== The Margulis lemma for manifolds of non-positive curvature ==

=== Formal statement ===

The Margulis lemma can be formulated as follows.{{sfn|Ballmann|Gromov|Schroeder|loc=Theorem 9.5}}

Let &lt;math&gt;X&lt;/math&gt; be a [[Simply connected space|simply-connected]] manifold of non-positive bounded curvature. There exist constants &lt;math&gt;C, \varepsilon&gt;0&lt;/math&gt; with the following property. For any discrete subgroup &lt;math&gt;\Gamma&lt;/math&gt; of the group of isometries of &lt;math&gt;X&lt;/math&gt; and any &lt;math&gt;x \in X&lt;/math&gt;, if &lt;math&gt;F_x&lt;/math&gt; is the set:
:&lt;math&gt; F_x = \{ g \in \Gamma: d(x, gx) &lt; \varepsilon \} &lt;/math&gt;
then the subgroup generated by &lt;math&gt;F_x&lt;/math&gt; contains a nilpotent subgroup of index less than &lt;math&gt;C&lt;/math&gt;. Here &lt;math&gt;d&lt;/math&gt; is the [[Metric (mathematics)|distance]] induced by the Riemannian metric.

An immediately equivalent statement can be given as follows: for any subset &lt;math&gt;F&lt;/math&gt; of the isometry group, if it satisfies that: 
* there exists a &lt;math&gt;x \in X&lt;/math&gt; such that &lt;math&gt;\forall g \in F : d(x, gx) &lt; \varepsilon&lt;/math&gt;; 
* the group &lt;math&gt;\langle F \rangle &lt;/math&gt; generated by &lt;math&gt;F&lt;/math&gt; is discrete
then &lt;math&gt;\langle F \rangle &lt;/math&gt; contains a nilpotent subgroup of index &lt;math&gt;\le C&lt;/math&gt;.

=== Margulis constants ===

The optimal constant &lt;math&gt;\varepsilon&lt;/math&gt; in the statement can be made to depend only on the dimension and the lower bound on the curvature; usually it is normalised so that the curvature is between -1 and 0. It is usually called the Margulis constant of the dimension.

One can also consider margulis constants for specific spaces. For example there has been an important effort to determine the Margulis constant of the hyperbolic spaces (of constant curvature -1). For example:
*the optimal constant for the [[hyperbolic plane]] is equal to &lt;math&gt;2 \mathrm{arcsinh} \left( \sqrt{\frac {2\cos(2\pi/7) - 1} {8\cos(\pi/7) + 7}} \right) \simeq 0.2629 &lt;/math&gt;;&lt;ref&gt;{{cite journal | ref=harv | last=Yamada | first=A. | title=On Marden’s universal constant of Fuchsian groups | journal=Kodai Math. J. | volume=4 | date=1981 | pages=266–277}}&lt;/ref&gt;
*In general the Margulis constant &lt;math&gt;\varepsilon_n&lt;/math&gt; for the hyperbolic &lt;math&gt;n&lt;/math&gt;-space is known to satisfy the bounds: 
::&lt;math&gt; c^{-n^2} &lt; \varepsilon_n &lt; K/\sqrt n &lt;/math&gt; 
:for some &lt;math&gt;0&lt;c&lt;1, K&gt;0&lt;/math&gt;.&lt;ref&gt;{{cite book | last=Belolipetsky | first=Mikhail | chapter=Hyperbolic orbifolds of small volume | title=Proceedings of ICM 2014 | publisher=Kyung Moon SA | url=https://arxiv.org/pdf/1402.5394}}&lt;/ref&gt;

=== Zassenhaus neighbourhoods ===

A particularly studied family of examples of negatively curved manifolds are given by the [[symmetric space]]s associated to [[semisimple Lie group]]s. In this case the Margulis lemma can be given the following, more algebraic formulation which dates back to [[Hans Zassenhaus]]. {{sfn|Raghunatan|1972|Definition 8.22}}

:''If &lt;math&gt;G&lt;/math&gt; is a semisimple Lie group there exists a neighbourhood &lt;math&gt;\Omega&lt;/math&gt; of the identity in &lt;math&gt;G&lt;/math&gt; and a &lt;math&gt;C &gt; 0&lt;/math&gt; such that any discrete subgroup &lt;math&gt;\Gamma&lt;/math&gt; which is generated by &lt;math&gt;\Gamma \cap \Omega&lt;/math&gt; contains a nilpotent subgroup of index &lt;math&gt;\le C&lt;/math&gt;. ''

Such a neighbourhood is called a '''Zassenhaus neighbourhood'''.

== Thick-thin decomposition ==

Let &lt;math&gt;M&lt;/math&gt; be a Riemannian manifold and &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt;. The ''thin part'' of &lt;math&gt;M&lt;/math&gt; is the subset of points &lt;math&gt;x \in M&lt;/math&gt; where the [[injectivity radius]] of &lt;math&gt;M&lt;/math&gt; at &lt;math&gt;x&lt;/math&gt; is less than &lt;math&gt;\varepsilon&lt;/math&gt;, usually denoted &lt;math&gt;M_{&lt; \varepsilon}&lt;/math&gt;, and the ''thick part'' its complement, usually denoted &lt;math&gt;M_{\ge \varepsilon}&lt;/math&gt;. There is a tautological decomposition into a disjoint union &lt;math&gt;M = M_{&lt; \varepsilon} \cup M_{\ge \varepsilon}&lt;/math&gt;.

When &lt;math&gt;M&lt;/math&gt; is of negative curvature and &lt;math&gt;\varepsilon&lt;/math&gt; is smaller than the Margulis constant for &lt;math&gt;\widetilde M&lt;/Math&gt; the structure of the components of the thin part is very simple. Let us restrict to the case of hyperbolic manifolds of finite volume. Suppose that &lt;math&gt;\varepsilon&lt;/math&gt; is smaller than the Margulis constant for &lt;math&gt;\mathbb H^n&lt;/math&gt; and let &lt;math&gt;M&lt;/math&gt; be a [[Hyperbolic manifold|hyperbolic &lt;math&gt;n&lt;/math&gt;-manifold]] of finite volume. Then its thin part has two sorts of components:{{sfn|Thurston|1998|loc=Chapter 4.5}}

*[[Cusp neighbourhood|Cusps]]: these are the unbounded components, they are diffeomorphic to a [[Flat manifold|flat &lt;math&gt;(n-1)&lt;/math&gt;-manifold]] times a line;
*Margulis tubes: these are neighbourhoods of [[closed geodesic]]s of length &lt;math&gt;&lt; \varepsilon&lt;/math&gt; on &lt;math&gt;M&lt;/math&gt;. They are bounded and diffeomorphic to a circle times a &lt;math&gt;(n-1)&lt;/math&gt;-disc.

In particular, a complete finite-volume hyperbolic manifold is always diffeomorphic to the interior of a compact manifold with (possibly empty boundary).

== Other applications ==

The Margulis lemma is an important tool in the study of manifolds of negative curvature. Besides the thick-thin decomposition some other applications are:

*The ''collar lemma'': this is a more precise version of the description of the compact components of the thin parts. It states that any closed geodesic of length &lt;math&gt;\ell &lt; \varepsilon&lt;/math&gt; on an hyperbolic surface is contained in an embedded cylinder of diameter of order &lt;math&gt;\ell^{-1}&lt;/math&gt;.
*The Margulis lemma gives an immediate qualitative solution to the problem of minimal covolume among hyperbolic manifolds: since the volume of a Margulis tube can be seen to be bounded below by a constant depending only on the dimension, it follows that there exists a positive infimum to the volumes of hyperbolic ''n''-manifolds for any ''n''.{{sfn|Ratcliffe|2006|p=666}}
*The existence of Zassenhaus neighbourhoods is a key ingredient in the proof of the [[Kazhdan-Margulis theorem]].
*One can recover the [[Jordan–Schur theorem]] as a corollary to the existence of Zassenhaus neighbourhoods.

== Notes ==

{{reflist}}

== References ==

*{{cite book | ref=harv | last1=Ballmann | first1=Werner | last2=Gromov | first2=Mikhail | last3=Schroeder | first3=Viktor | title=Manifolds of Nonpositive Curvature | publisher=Birkhâuser | year=1985}}
*{{cite book | ref=harv | last=Raghunathan | first=M. S. | title=Discrete subgroups of Lie groups | publisher=[[Springer-Verlag]] | series=Ergebnisse de Mathematik und ihrer Grenzgebiete | year=1972 | MR=0507234}}
*{{cite book | ref=harv | last=Ratcliffe | first=John | title=Foundations of hyperbolic manifolds, Second edition | publisher=Springer | year=2006 | pages=xii+779 | ISBN= 978-0387-33197-3}}
*{{cite book | ref=harv |last=Thurston | first=William | title=Three-dimensional geometry and topology. Vol. 1 | publisher=Princeton University Press | year=1997}}

[[Category:Lie groups]]
[[Category:Hyperbolic geometry]]
[[Category:Differential geometry]]
[[Category:Lemmas]]</text>
      <sha1>lna07eqzytgzuyihzyhy1rgk8t5vs01</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical Neuroscience Prize</title>
    <ns>0</ns>
    <id>53876896</id>
    <revision>
      <id>789650155</id>
      <parentid>777307413</parentid>
      <timestamp>2017-07-08T17:26:28Z</timestamp>
      <contributor>
        <username>Tassedethe</username>
        <id>7098284</id>
      </contributor>
      <comment>/* Laureates */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1158">The '''Mathematical Neuroscience Prize''' is a prize awarded biennially since 2013 by the [[nonprofit organization]] [[Israel Brain Technologies]] (IBT). It is endowed with $100,000 for each laureate and honors researchers who have significantly advanced the understanding of the neural mechanisms of [[perception]], [[behavior]] and [[thought]] through the application of mathematical analysis and modeling.

== Laureates ==
* 2013 [[Larry Abbott]] (Columbia University) und [[Haim Sompolinsky]] (Hebrew University Jerusalem)
* 2015 [[Nancy Kopell]] (Boston University) und [[Bard Ermentrout]] (University of Pittsburgh)
* 2017 [[Fred Wolf (neuroscientist)|Fred Wolf]] ([[Max Planck Institute for Dynamics and Self-Organization]]) and [[Misha Tsodyks]] ([[Weizmann Institute of Science]])

== See also ==
* The [[Grete Lundbeck European Brain Research Prize|Brain Prize]]
* The [[Kavli Prize]]
* The [[Mind &amp; Brain Prize]]

== Weblinks ==
* [http://israelbrain.org/prize-programs/ ''Prize Programs''] at ''Israel Brain Technologies'' (israelbrain.org)

[[Category:Awards established in 2013]]
[[Category:Neuroscience awards]]
[[Category:Mathematics awards]]</text>
      <sha1>rk04gtcusmtsf7njctzt11m30jjvl4h</sha1>
    </revision>
  </page>
  <page>
    <title>Mean operation</title>
    <ns>0</ns>
    <id>47609709</id>
    <revision>
      <id>696362537</id>
      <parentid>689042948</parentid>
      <timestamp>2015-12-22T17:09:13Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* Further reading */Journal cites, Added 1 doi to a journal cite using [[Project:AWB|AWB]] (11757)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1772">In [[algebraic topology]], a '''mean''' or '''mean operation''' on a [[topological space]] ''X'' is a [[continuous function|continuous]], [[commutative property|commutative]], [[idempotence|idempotent]] [[binary operation]] on ''X''. If the operation is also [[associative property|associative]], it defines a [[semilattice]]. A classic problem is to determine which spaces admit a mean. For example, [[Euclidean space]]s admit a mean -- the usual [[arithmetic mean |average]] of two vectors -- but [[n-sphere|spheres of positive dimension]] do not, including the [[circle]].

==Further reading==
*{{citation
 | last = Aumann | first = G.
 | journal = Mathematische Annalen
 | pages = 210–215
 | title = Über Räume mit Mittelbildungen.
 | url = http://eudml.org/doc/160126
 | volume = 119
 | year = 1943
 | doi=10.1007/bf01563741}}.
*{{citation
 | last = Sobolewski | first = Mirosław
 | doi = 10.1090/s0002-9939-08-09414-8
 | issue = 10
 | journal = Proceedings of the American Mathematical Society
 | pages = 3701–3707
 | title = Means on chainable continua
 | volume = 136
 | year = 2008}}.
*{{citation
 | last = T. Banakh | first = W. Kubis, R. Bonnet
 | issue = 1
 | journal = Topological Algebra and its Applications
 | title = Means on scattered compacta
 | url = http://eudml.org/doc/266591
 | volume = 2
 | year = 2014}}.
*{{citation
 | last = Charatonik | first = Janusz J.
 | title = Selected problems in continuum theory
 | url = http://topology.auburn.edu/tp/reprints/v27/tp27107.pdf
 | issue = 1
 | journal = Topology Proceedings
 | mr = 2048922
 | pages = 51–78
 | department = Proceedings of the Spring Topology and Dynamical Systems Conference
 | volume = 27
 | year = 2003}}.

[[Category:Binary operations]]
[[Category:Means]]

{{topology-stub}}</text>
      <sha1>dni3awo5k2jo3xfc8tdve9fc244uyqa</sha1>
    </revision>
  </page>
  <page>
    <title>Metric derivative</title>
    <ns>0</ns>
    <id>6840149</id>
    <revision>
      <id>545547369</id>
      <parentid>545384632</parentid>
      <timestamp>2013-03-19T23:43:00Z</timestamp>
      <contributor>
        <username>FallingGravity</username>
        <id>17911012</id>
      </contributor>
      <comment>/* References */ +page #; Note: the chapter did not "kill the book title", I had accidentally added the Title parameter twice.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2148">In [[mathematics]], the '''metric derivative''' is a notion of [[derivative]] appropriate to [[Parametric equation|parametrized]] [[path (topology)|paths]] in [[metric space]]s. It generalizes the notion of "speed" or "absolute velocity" to spaces which have a notion of distance (i.e. metric spaces) but not direction (such as [[vector space]]s).

==Definition==

Let &lt;math&gt;(M, d)&lt;/math&gt; be a metric space. Let &lt;math&gt;E \subseteq \mathbb{R}&lt;/math&gt; have a [[limit point]] at &lt;math&gt;t \in \mathbb{R}&lt;/math&gt;. Let &lt;math&gt;\gamma : E \to M&lt;/math&gt; be a path. Then the '''metric derivative''' of &lt;math&gt;\gamma&lt;/math&gt; at &lt;math&gt;t&lt;/math&gt;, denoted &lt;math&gt;| \gamma' | (t)&lt;/math&gt;, is defined by

:&lt;math&gt;| \gamma' | (t) := \lim_{s \to 0} \frac{d (\gamma(t + s), \gamma (t))}{| s |},&lt;/math&gt;

if this [[Limit (mathematics)|limit]] exists.

==Properties==

Recall that [[absolute continuity|AC&lt;sup&gt;''p''&lt;/sup&gt;(''I''; ''X'')]] is the space of curves ''γ'' : ''I'' → ''X'' such that

:&lt;math&gt;d \left( \gamma(s), \gamma(t) \right) \leq \int_{s}^{t} m(\tau) \, \mathrm{d} \tau \mbox{ for all } [s, t] \subseteq I&lt;/math&gt;

for some ''m'' in the [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; space]] ''L''&lt;sup&gt;''p''&lt;/sup&gt;(''I''; '''R'''). For ''γ'' ∈ AC&lt;sup&gt;''p''&lt;/sup&gt;(''I''; ''X''), the metric derivative of ''γ'' exists for [[Lebesgue measure|Lebesgue]]-[[almost all]] times in ''I'', and the metric derivative is the smallest ''m'' ∈ ''L''&lt;sup&gt;''p''&lt;/sup&gt;(''I''; '''R''') such that the above inequality holds.

If [[Euclidean space]] &lt;math&gt;\mathbb{R}^{n}&lt;/math&gt; is equipped with its usual Euclidean norm &lt;math&gt;\| - \|&lt;/math&gt;, and &lt;math&gt;\dot{\gamma} : E \to V^{*}&lt;/math&gt; is the usual [[Fréchet derivative]] with respect to time, then

:&lt;math&gt;| \gamma' | (t) = \| \dot{\gamma} (t) \|,&lt;/math&gt;

where &lt;math&gt;d(x, y) := \| x - y \|&lt;/math&gt; is the Euclidean metric.

==References==

* {{cite book | author=Ambrosio, L., Gigli, N. &amp; Savaré, G. | title=Gradient Flows in Metric Spaces and in the Space of Probability Measures | publisher=ETH Zürich, Birkhäuser Verlag, Basel | year=2005 | isbn=3-7643-2428-7 | page=24}}

[[Category:Differential calculus]]
[[Category:Metric geometry]]</text>
      <sha1>9t4qyxpd3tnzs3ssuejchfphgozt8br</sha1>
    </revision>
  </page>
  <page>
    <title>Neal Amundson</title>
    <ns>0</ns>
    <id>19049577</id>
    <revision>
      <id>860224174</id>
      <parentid>860224006</parentid>
      <timestamp>2018-09-19T05:45:46Z</timestamp>
      <contributor>
        <username>YBUE</username>
        <id>32474760</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14107">{{Infobox scientist
| name = '''Neal Amundson'''
| image = Neal Amundson.jpg
| caption = Neal Amundson
| birth_date = {{birth date|1916|1|10}}
| birth_place = [[Saint Paul, Minnesota|Saint Paul]], [[Minnesota]]
| death_date = {{death date and age|2011|2|16|1916|1|10}}
| death_place = 
| residence = 
| citizenship = 
| nationality = [[United States|American]]
| ethnicity = 
| field = [[Mathematical modeling]], [[Chemical reaction engineering]], [[Transport phenomena]]
| work_institutions = [[University of Minnesota]]&lt;br/&gt; [[University of Houston]]
| alma_mater = [[University of Minnesota]]
| doctoral_advisor = [[Hugh Turrittin]]
| doctoral_students = Over 50 students
| known_for = 
| awards = [[E. V. Murphree Award in Industrial and Engineering Chemistry|E. V. Murphree Award]] &lt;small&gt;(1960)&lt;/small&gt;&lt;br&gt;[[Albert Einstein Award]] &lt;small&gt;(1989)&lt;/small&gt;&lt;br&gt;[[Chemical_reaction_engineering#Neal_R._Amundson_Award_for_Excellence_in_Chemical_Reaction_Engineering|Amundson Award]]&lt;small&gt; (1996)&lt;/small&gt;
| influences = 
| influenced = 
| prizes = 
| religion = 
| footnotes = 
| signature = 
}}

'''Neal R. Amundson''' (January 10, 1916{{spaced ndash}}February 16, 2011)&lt;ref name="che.uh.edu_2011-02-17"&gt;[http://www.che.uh.edu/news/0211/amundson "Father of Chemical Engineering" Neal Amundson Passes Away], University of Houston Cullen College of Engineering, February 17, 2011: "passed away yesterday".&lt;/ref&gt; was an [[Americans|American]] [[chemical engineer]] and [[Applied mathematics|applied mathematician]]. He was the Chair of the Department of Chemical Engineering at the [[University of Minnesota]] for over 25 years. Later, he was the Cullen Professor of Chemical &amp; Biomolecular Engineering and Mathematics at the [[University of Houston]]. Amundson was considered one of the most prominent chemical engineering educators and researchers in the United States.&lt;ref&gt;http://www.pnas.org/content/108/18/7285.short&lt;/ref&gt;. The Chemical Engineering and Materials Science building at the University of Minnesota-Twin Cities bears his name.&lt;ref&gt;https://www.egr.uh.edu/news/amundson&lt;/ref&gt;

== Early life and education ==
Neal Amundson was born and raised in Saint Paul, Minnesota, as the only child of a pipefitter and a housewife who struggled to survive the [[Great Depression]]&lt;ref&gt;https://cse.umn.edu/news-feature/in-memoriam-neal-r-amundson/&lt;/ref&gt;. As a young child of 9, Neal became a scratch golfer with golf clubs provided by his father, Oscar Amundson.  Neal graduated from St. Paul Central High School in 1933 and was sixth in his class of 658 students.  Neal was awarded a bachelor's degree in chemical engineering in 1937 and was first in his class of 52 students that year from the University of Minnesota.  He was employed as a process engineer with Standard Oil of New Jersey at a plant in Louisiana.  He then returned to Minnesota where he met his wife, Shirley Dimond in 1941, and had three children.  He entered graduate school and earned an MS in chemical engineering in 1941 and a Ph.D. in mathematics in 1945 from the University of Minnesota.

== Career ==
He taught in the mathematics department until 1947 and joined the University of Minnesota's Chemical Engineering Department, where he served as Chair from 1949 until 1977.  During his 25 years as department chair, Amundson helped the department to achieve a high national ranking among chemical engineering departments, which it still retains.&lt;ref&gt;[http://purl.umn.edu/104342 Oral history interview with Neal R. Amundson] [[Charles Babbage Institute]], University of Minnesota&lt;/ref&gt;

Amundson joined the University of Houston (UH) in 1977 as a Cullen Professor and a faculty member of the Chemical Engineering &amp; Mathematics departments. He served as UH Provost from 1987 to 1989.   Amundson is known internationally for his pioneering work applying mathematical modeling and analysis to the solution of chemical engineering problems.  His technical contributions are in the areas of mathematical modeling and analysis of chemical reactors, separation systems, polymerization units, and coal gasification units.&lt;ref&gt;http://tkvw.com/researchuh/re1.htm&lt;/ref&gt; Amundson was one of the main architects of the analytical methodology practiced by chemical engineers today.&lt;ref&gt;http://www.legacy.com/obituaries/houstonchronicle/obituary.aspx?pid=148775651&lt;/ref&gt;

Amundson wrote more than 200 technical articles as well as several books.  He chaired the U.S. National Research Council committee that wrote the influential "Frontiers in Chemical Engineering" report. He was the U.S. editor of ''Chemical Engineering Science'' from 1955 to 1972. Amundson was elected a member of [[National Academy of Engineering]] in 1970&lt;ref name=NAE&gt;{{cite web|title=Dr. Neal R. Amundson|url=http://www.nae.edu/MembersSection/Directory20412/29776.aspx|work=National Academy of Engineering|accessdate=17 April 2011}}&lt;/ref&gt; and the [[United States National Academy of Sciences|National Academy of Sciences]] in 1992.&lt;ref name=NAS&gt;{{cite web|title=Amundson, Neal R.|url=http://www.nasonline.org/site/Dir/1647108920?pg=vprof&amp;mbr=1001513|work=National Academy of Sciences|accessdate=17 April 2011}}&lt;/ref&gt; He was elected a Fellow of the [[American Academy of Arts and Sciences]] in 1992.&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780-2010: Chapter A|url=http://www.amacad.org/publications/BookofMembers/ChapterA.pdf|publisher=American Academy of Arts and Sciences|accessdate=17 April 2011}}&lt;/ref&gt;  The National Academy of Engineering (NAE) bestowed on Amundson the prestigious NAE Founders' Award in 1990.&lt;ref name="Amundson bio"&gt;[http://www.chee.uh.edu/faculty/amundson/ Amundson bio], University of Houston. Retrieved 2011-01-04.&lt;/ref&gt;

In 1996, Amundson was the first recipient of the International Symposia on Chemical Reaction Engineering (ISCRE) award for excellence,&lt;ref&gt;[http://www.iscre.org/amundsonaward.html ISCRE website]&lt;/ref&gt; an award that is also named for him. The chemical engineering building at his alma mater [[University of Minnesota]] is named in his honor.&lt;ref&gt;[http://www.eurekalert.org/pub_releases/2005-12/uoh-oc120805.php 'Father of chemical engineering' turns 90, still teaching at UH]&lt;/ref&gt; He received numerous professional awards from the [[American Institute of Chemical Engineers]] (AIChE), [[American Chemical Society]] (ACS), International Symposium on [[Chemical Reaction Engineering]] (ISCRE), and [[American Society for Engineering Education]] (ASEE).

He received honorary doctorates from the Universities of Minnesota, Notre Dame, Pennsylvania, Guadalajara, and Northwestern University.&lt;ref name="Amundson bio"/&gt; He received the highest faculty honors given by the Universities of Minnesota and Houston.&lt;ref name="Amundson bio"/&gt;

== Key publications ==
Neal Amundson has authored numerous journal articles describing significant advances in [[chemical reaction engineering]] and [[chemical engineering]] which includes but is not limited to:

*A. Acrivos, Neal Amundson, '''"Applications of Matrix Mathematics to Chemical Engineering Problems"''', Industrial &amp; Engineering Chemistry 47, 1533 (1955).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/ie50548a027|title=Applications of Matrix Mathematics to Chemical Engineering Problems|accessdate=5 February 2018 | doi=10.1021/ie50548a027|volume=47|journal=Industrial &amp; Engineering Chemistry|pages=1533}}&lt;/ref&gt;

*L. Lapidus, Neal Amundson, '''"Mathematics of Adsorption in Beds. VI. The Effect of Longitudinal Diffusion in Ion Exchange and Chromatographic Columns"''', Journal of Physical Chemistry 56, 984 (1952).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/j150500a014|title=Mathematics of Adsorption in Beds. VI. The Effect of Longitudinal Diffusion in Ion Exchange and Chromatographic Columns|accessdate=5 February 2018 | doi=10.1021/j150500a014|volume=56|journal=Journal of Physical Chemistry|pages=984}}&lt;/ref&gt;

*L. Lapidus, Neal Amundson, '''"Chemical Reactor Stability and Sensitivity"''', AIChE Journal 1, 513 (1955).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/j150500a014|title=Chemical Reactor Stability and Sensitivity|accessdate=5 February 2018 | doi=10.1002/aic.690010422|volume=1|journal=AIChE Journal|pages=513}}&lt;/ref&gt;

*O. Bilous, Neal Amundson, '''"Chemical reactor stability and sensitivity: II. Effect of parameters on sensitivity of empty tubular reactors"''', AIChE Journal 2, 117-126 (1956).&lt;ref&gt;{{cite journal|url=http://onlinelibrary.wiley.com/doi/10.1002/aic.690020124/full|title=Chemical reactor stability and sensitivity: II. Effect of parameters on sensitivity of empty tubular reactors|accessdate=5 February 2018 | doi=10.1002/aic.690020124|volume=2|journal=AIChE Journal|pages=117-126}}&lt;/ref&gt;

*R. Aris, Neal Amundson, '''"An analysis of chemical reactor stability and control—I: The possibility of local control, with perfect or imperfect control mechanisms"''', Chemical Engineering Science 7, 121 (1958).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/j150500a014|title=An analysis of chemical reactor stability and control—I: The possibility of local control, with perfect or imperfect control mechanisms|accessdate=5 February 2018 | doi=10.1016/0009-2509(58)80019-6|volume=7|journal=Chemical Engineering Science|pages=121}}&lt;/ref&gt;

*K.Valentas, O. Bilous, Neal Amundson, '''"Analysis of Breakage in Dispersed Phase Systems"''', Industrial and Engineering Chemistry Fundamentals 5, 271 (1966).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/i160018a019|title=Analysis of Breakage in Dispersed Phase Systems|accessdate=5 February 2018 | doi=10.1021/i160018a019|volume=5|journal=Industrial and Engineering Chemistry Fundamentals|pages=271-279}}&lt;/ref&gt;

*Dan Luss, Neal Amundson, '''"Uniqueness of the steady state solutions for chemical reaction occurring in a catalyst particle or in a tubular reactor with axial diffusion"''', Chemical Engineering Science 22, 253-266 (1967).&lt;ref&gt;{{cite journal|url=https://www.sciencedirect.com/science/article/pii/0009250967801131|title=Uniqueness of the steady state solutions for chemical reaction occurring in a catalyst particle or in a tubular reactor with axial diffusion|accessdate=5 February 2018 | doi=10.1016/0009-2509(67)80113-1|volume=22|journal=Chemical Engineering Science|pages=253-266}}&lt;/ref&gt;

*F.R. Newbold, Neal R. Amundson, '''"A model for evaporation of a multicomponent droplet"''', AIChE Journal 19, 22-30 (1973).&lt;ref&gt;{{cite journal|url=http://onlinelibrary.wiley.com/doi/10.1002/aic.690190105/full|title=A model for evaporation of a multicomponent droplet|accessdate=5 February 2018 | doi=10.1002/aic.690190105|volume=19|journal=AIChE Journal|pages=22-30}}&lt;/ref&gt;

*Hugo S. Caram, Neal R. Amundson, '''"Diffusion and Reaction in a Stagnant Boundary Layer about a Carbon Particle"''', Industrial and Engineering Chemistry Fundamentals 16, 171-181 (1977).&lt;ref&gt;{{cite journal|url=https://pubs.acs.org/doi/abs/10.1021/i160062a001|title=Diffusion and Reaction in a Stagnant Boundary Layer about a Carbon Particle|accessdate=5 February 2018 | doi=10.1021/i160062a001|volume=16|journal=Industrial and Engineering Chemistry Fundamentals|pages=171-181}}&lt;/ref&gt;

== Legacy and Impact on Chemical Engineering ==
Neal's vision was to combine modern advances in science together with elegant yet practical mathematical methods.&lt;ref&gt;http://www.chee.uh.edu/amundsonchair&lt;/ref&gt;  In his first two decades as department head of chemical engineering at the University of Minnesota, Amundson hired several chemists, mathematicians, and chemical engineers. He encouraged young faculty to explore new topics in chemical engineering such as biological systems and focused on broadening the discipline to include materials science and engineering. Neal acknowledged the importance of emerging fields and had a goal of attracting young faculty in topics such as microbiology and polymers.  In two decades, he hired several faculty that would become leaders of chemical engineering and materials science; these diverse individuals were then combined into a coherent program bound by his philosophy for team teaching and collaborative research.  Neal was famous for stating, "I never hired anybody if I thought I was smarter than they are."&lt;ref&gt;http://www.msthalloffame.org/neal_amundson.htm&lt;/ref&gt;  Amundson promoted the idea of teaching courses in groups, with young faculty teaching and lecturing alongside senior professors; his legacy continues at the University of Minnesota.

Neal Amundson has been called the "father of modern chemical engineering" to recognize his invigoration of chemical engineering with mathematics and emerging research fields.  His work has impacted multiple generations of students, including his mentoring of 52 PhD students throughout his career.  As of 2006, Neal Amundson's academic family tree contains more than 3,000 individuals.  His work on reaction engineering, transport phenomena, and complex reacting systems remains the foundation of modern reaction engineering and chemical engineering.  As stated by Profssors Andreas Acrivos and Dan Luss, "Seldom has an individual exerted such a major influence in the development of an important field as was done by Neal Amundson to chemical engineering." &lt;ref&gt;http://www.msthalloffame.org/neal_amundson.htm&lt;/ref&gt;

==Death==
Amundson died on February 16, 2011, at the age of 95.&lt;ref&gt;http://www.legacy.com/obituaries/houstonchronicle/obituary.aspx?pid=148775651&lt;/ref&gt;

==Notes==
{{reflist|30em}}

{{Authority control}}
{{DEFAULTSORT:Amundson, Neal}}
[[Category:1916 births]]
[[Category:2011 deaths]]
[[Category:Engineering academics]]
[[Category:American chemical engineers]]
[[Category:Chemical engineers]]
[[Category:Applied mathematicians]]
[[Category:University of Houston faculty]]
[[Category:University of Minnesota faculty]]
[[Category:University of Minnesota alumni]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Guggenheim Fellows]]
[[Category:Minnesota CEMS]]</text>
      <sha1>cq6w5sxn6mryuiba15sje3zap0oazzh</sha1>
    </revision>
  </page>
  <page>
    <title>Neumann–Poincaré operator</title>
    <ns>0</ns>
    <id>36728510</id>
    <revision>
      <id>863518420</id>
      <parentid>829402773</parentid>
      <timestamp>2018-10-11T08:27:49Z</timestamp>
      <contributor>
        <ip>2001:67C:10EC:52C6:8000:0:0:15B1</ip>
      </contributor>
      <comment>/* Fredholm eigenvalues */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="59892">In [[mathematics]], the '''Neumann–Poincaré operator''' or '''Poincaré–Neumann operator''', named after [[Carl Neumann]] and [[Henri Poincaré]], is a non-self-adjoint [[compact operator]] introduced by Poincaré to solve [[boundary value problem]]s for the Laplacian on bounded domains in Euclidean space. Within the language of [[potential theory]] it reduces the [[partial differential equation]] to an [[integral equation]] on the boundary to which the theory of [[Fredholm operator]]s can be applied. The theory is particularly simple in two dimensions—the case treated in detail in this article—where it is related to [[complex function theory]], the conjugate [[Beurling transform]] or complex [[Hilbert transform]] and the Fredholm eigenvalues of bounded planar domains.

==Dirichlet and Neumann problems==
{{See also|Dirichlet boundary condition|Neumann boundary condition}}
[[Green's theorem]] for a bounded region Ω in the plane with smooth boundary ∂Ω states that

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} A\, dx + B\, dy =\iint_\Omega (B_x-A_y)\, dx\, dy.}&lt;/math&gt;

One direct way to prove this is as follows. By subtraction, it is sufficient to prove the theorem for a region bounded by a simple smooth curve. Any such is diffeomorphic to the closed [[unit disk]]. By change of variables it is enough to prove the result there. Separating the ''A'' and ''B'' terms, the right hand side can be written as a double integral starting in the ''x'' or ''y'' direction, to which the [[fundamental theorem of calculus]] can be applied. This converts the integral over the disk into the integral over its boundary.&lt;ref&gt;{{harvnb|Folland|1995|p=9}}&lt;/ref&gt;

Let Ω be a region bounded by a simple closed curve. Given a smooth function ''f'' on the closure of Ω its normal derivative ∂&lt;sub&gt;''n''&lt;/sub&gt;''f'' at a boundary point is the directional derivative in the direction of the outward pointing normal vector.
Applying Green's theorem with ''A'' = ''v''&lt;sub&gt;''x''&lt;/sub&gt; ''u'' and ''B'' = ''v''&lt;sub&gt;''y''&lt;/sub&gt; ''u'' gives the first of [[Green's identities]]:&lt;ref&gt;{{harvnb|Folland|1995|p=69}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} u \, \partial_nv = \iint_\Omega u_x v_x + u_y v_y - u \, \Delta v,}&lt;/math&gt;

where the Laplacian Δ is given by

:&lt;math&gt;\displaystyle \Delta  = -\partial^2_x -\partial_y^2. &lt;/math&gt;

Swapping ''u'' and ''v'' and subtracting gives the second of Green's identities:

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} u \,   \partial_nv - \partial_nu \, v=\iint_\Omega \, \Delta u \, v - u \, \Delta v.}&lt;/math&gt;

If now ''u'' is harmonic in Ω  and ''v'' = 1, then this identity implies that

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} \partial_n u = 0,}&lt;/math&gt;

so the integral of the normal derivative of a harmonic function on the boundary of a region always vanishes.

A similar argument shows that the average of a harmonic function on the boundary of a disk equals its value at the centre. Translating the disk can be taken to be centred at 0. Green's identity can be applied to an annulus formed of the boundary of the disk and a small circle centred on 0 with ''v'' = ''z''&lt;sup&gt;2&lt;/sup&gt;: it follows that the average is independent of the circle. It tends to the value at its value at 0 as the radius of the smaller circle decreases. This result also follows easily using Fourier series and the [[Poisson integral]].

For continuous functions ''f'' on the whole plane which are smooth in Ω and the complementary region Ω&lt;sup&gt;''c''&lt;/sup&gt;, the first derivative can have a jump across the boundary of Ω. The value of the normal derivative at a boundary point can be computed from inside or outside Ω. The '''interior normal derivative''' will be denoted by ∂&lt;sub&gt;''n''−&lt;/sub&gt; and the '''exterior normal derivative''' by ∂&lt;sub&gt;''n''+&lt;/sub&gt;. With this terminology the four basic problems of classical potential theory are as follows:&lt;ref&gt;{{harvnb|Folland|1995|pp=114–120}}&lt;/ref&gt;

*'''Interior Dirichlet problem:''' ∆''u'' = 0 in Ω, ''u'' = ''f'' on ∂Ω
*'''Interior Neumann problem:''' ∆''u'' = 0 in Ω, ∂&lt;sub&gt;''n''−&lt;/sub&gt; ''u'' = ''f'' on ∂Ω
*'''Exterior Dirichlet problem:''' ∆''u'' = 0 in Ω&lt;sup&gt;''c''&lt;/sup&gt;, ''u'' = ''f'' on ∂Ω, ''u'' continuous at ∞
*'''Exterior Neumann problem:''' ∆''u'' = 0 in Ω&lt;sup&gt;''c''&lt;/sup&gt;, ∂&lt;sub&gt;''n''+&lt;/sub&gt; ''u'' = ''f'' on ∂Ω, ''u'' continuous at ∞

For the exterior problems the inversion map ''z''&lt;sup&gt;−1&lt;/sup&gt; takes harmonic functions on Ω&lt;sup&gt;''c''&lt;/sup&gt; into harmonic functions on the image of Ω&lt;sup&gt;''c''&lt;/sup&gt; under the inversion map.&lt;ref&gt;{{harvnb|Folland|1995|pp=113–114}} Up to composition with complex conjugation, this is the special case of the [[Kelvin transform]] in two dimensions. In this case, since a function is harmonic if and only if it is the real part of a holomorphic function, the statement follows from the fact that the composition of holomorphic functions is holomorphic.&lt;/ref&gt; The transform ''v'' of ''u'' is continuous in a small disc |''z''| ≤ ''r'' and harmonic everywhere in the interior except possibly 0. Let ''w'' be the harmonic function given by the [[Poisson integral]] on
|''z''| ≤ ''r'' with the same boundary value ''g'' as ''v''  on |''z''| = ''r''. Applying the [[maximum principle]] to 
''v'' − ''w'' + ε log |''z''| on δ ≤ |''z''| ≤ ''r'', it must be negative for δ  small. Hence ''v''(''z'') ≤ ''u''(''z'') for ''z'' ≠ 0.  The same argument applies with ''v'' and ''w'' swapped, so ''v'' = ''w'' is harmonic in the disk.&lt;ref&gt;{{harvnb|Folland|1995|p=111}}&lt;/ref&gt; Thus the singularity at ∞ is removable.

By the maximum principle the interior and exterior Dirichlet problems have unique solutions. For the interior Neumann problem, if a solution ''u'' is harmonic in 0 and its interior normal derivative vanishes, then Green's first identity implies implies the ''u''&lt;sub&gt;''x''&lt;/sub&gt; = 0 = ''u''&lt;sub&gt;''y''&lt;/sub&gt;, so that ''u'' is constant. This shows the interior Neumann problem has a unique solution up to adding constants. Applying inversion, the same holds for the external Neumann problem.

For both Neumann problems, a necessary condition for a solution to exist is

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} f\,\,=\,\,0.}&lt;/math&gt;

For the interior Neumann problem, this follows by setting ''v'' = 1 in Green's second identity. For the exterior Neumann problem, the same can be done for the intersection of  Ω&lt;sup&gt;''c''&lt;/sup&gt; and a large disk |''z''| &lt; ''R'', giving

:&lt;math&gt;\displaystyle{\int_{\partial\Omega} f\,\,=\,\,\int_{|z|=R}\partial_n u.}&lt;/math&gt;

At ∞ ''u'' is the real part of a holomorphic function ''F'' with

:&lt;math&gt;\displaystyle{F(z)=a_0 + a_1z^{-1} + a_2 z^{-2} + \cdots}&lt;/math&gt;

The interior normal derivative on |''z''| = ''R'' is just the radial derivative ∂&lt;sub&gt;''r''&lt;/sub&gt;, so that for |''z''| = ''R''

:&lt;math&gt;\displaystyle{|\partial_r F(z)| = |F^\prime(z)|\le C R^{-2}.}&lt;/math&gt;

Hence

:&lt;math&gt;\displaystyle{\left|\int_{|z|=R}\partial_n u\right|\le 2\pi CR^{-1},}&lt;/math&gt;

so the integral over ∂Ω must vanish.

The [[fundamental solution]] of the Laplacian is given by

:&lt;math&gt;\displaystyle{E(z) =-{1\over 2\pi} \log |z|.}&lt;/math&gt;

''N''(''z'') = − ''E''(''z'') is called the [[Newtonian potential]] in the plane. Using polar coordinates, it is easy to see that 
''E'' is in L&lt;sup&gt;''p''&lt;/sup&gt; on any closed disk for any finite ''p'' ≥ 1. To say that ''E'' is a fundamental solution of the Laplacian means that for any smooth function φ of compact support

:&lt;math&gt;\displaystyle{\iint E \cdot\Delta\varphi = \varphi(0).}&lt;/math&gt;

The standard proof uses Green's second identity on the annulus ''r'' ≤ |''z''| ≤ ''R'' where the support of φ is contained in |''z''| &lt; ''R''. In fact, since ''E'' is harmonic away from 0,

:&lt;math&gt;\displaystyle{\iint_{|z|\ge r} E \cdot \Delta \varphi  ={1\over 2\pi}\int_0^{2\pi} \varphi(r e^{i\theta})  - r \cdot \log r\cdot\partial_n\varphi(re^{i\theta})  \, d\theta.}&lt;/math&gt;

As ''r'' tends to zero, the first term on the right hand side tends to φ(0) and the second to 0, since ''r'' log ''r'' tends to 0 and the normal derivatives of φ are uniformly bounded. (That both sides are equal even before taking limits follows from the fact that the average of a harmonic function on the boundary of a disk equals it value at the centre, while the integral of its normal derivative vanishes.)

==Neumann–Poincaré kernel==
The properties of the fundamental solution lead to the following formula for recovering a harmonic function ''u'' in Ω from its boundary values:&lt;ref&gt;{{harvnb|Folland|1995|p=77}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{u(z)=\int_{\partial \Omega} K(z,w)u(w) - N(z-w)\partial_n u(w) \,|dw|,}&lt;/math&gt;

where ''K'' is the '''Neumann−Poincaré kernel'''

:&lt;math&gt;\displaystyle{K(z,w)=\partial_{n,w} N(z-w).}&lt;/math&gt;

To prove this identity, Green's second identity can be applied to Ω with a small disk centred on ''z'' removed. This reduces  to showing that the identity holds in the limit for a small disk centred on ''z'' shrinking in size. Translating, it can be assumed that ''z'' = 0 and the identity becomes

:&lt;math&gt;\displaystyle{u(0)=\lim_{r\rightarrow 0} {1\over 2\pi}\int_{0}^{2\pi} u(re^{i\theta}) - r\cdot \log r \cdot \partial_r u(re^{i\theta})\,d\theta,}&lt;/math&gt;

which was proved above. A similar formula holds for functions harmonic in Ω&lt;sup&gt;''c''&lt;/sup&gt;:&lt;ref&gt;{{harvnb|Schiffer|1957}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{u(z)=\int_{\partial \Omega} -K(z,w)u(w) + N(z-w)\partial_n u(w) \,|dw|.}&lt;/math&gt;

The signs are reversed because of the direction of the normal derivative.

In two dimensions the Neumann–Poincaré kernel ''K''(''z'',''w'') has the remarkable property that it restricts to a smooth function on ∂Ω&amp;nbsp;&amp;times;&amp;nbsp;∂Ω. It is ''a priori'' only defined as a smooth function off the diagonal but it admit a (unique) smooth extension to the diagonal.&lt;ref&gt;{{harvnb|Hsiao|Wendland|2008|pp=553–554}}&lt;/ref&gt; Using vector notation  '''v'''(''t'') = (''x''(''t''), ''y''(''t'')) to parametrize the boundary curve by arc length, the following classical formulas hold:

:&lt;math&gt;\displaystyle{\dot{\mathbf{v}}\cdot \dot{\mathbf{v}} =1,\,\,\, \ddot{\mathbf{v}}\cdot \dot{\mathbf{v}} = 0.}&lt;/math&gt;

Thus the unit tangent vector '''t'''(''t'') at ''t'' is the velocity vector

:&lt;math&gt;\displaystyle{\mathbf{t} =\dot{\mathbf{v}},}&lt;/math&gt;

so the oriented unit normal '''n'''(''t'') is

:&lt;math&gt;\displaystyle{\mathbf{n}=(-\dot{y},\dot{x}).}&lt;/math&gt;

The constant relating the acceleration vector to the normal vector is the [[Curvature#Curvature of plane curves|curvature]] of the curve:

:&lt;math&gt;\displaystyle{\ddot{\mathbf{v}}=\kappa(t)\,\mathbf{n}(t).}&lt;/math&gt;

Thus the curvature is given by

:&lt;math&gt;\displaystyle{\kappa=\ddot{\mathbf{v}}\cdot \mathbf{n}=\ddot{y}\dot {x} - \ddot{x}\dot{y}.}&lt;/math&gt;

There are two further formulas of [[Jean Frédéric Frenet|Frenet]]:

:&lt;math&gt;\displaystyle{\dot{\mathbf{n}}=-\kappa \mathbf{t},\,\,\, \ddot{\mathbf{n}}= \dot{\kappa}\mathbf{n} -\kappa^2 \mathbf{t}.}&lt;/math&gt;

The Neumann–Poincaré kernel is given by the formula

:&lt;math&gt;\displaystyle{K(\mathbf{u},\mathbf{v}(t))=-{1\over 2\pi} {(\mathbf{u}-\mathbf{v}(t))\cdot\mathbf{n}(t)\over |\mathbf{u}-\mathbf{v}|^2}.}&lt;/math&gt;

For ''s'' ≠ ''t'', set

:&lt;math&gt;\displaystyle{k(s,t)=K(v(s),v(t)).}&lt;/math&gt;

The function

:&lt;math&gt;\displaystyle{a(s,t)={|v(s)-v(t)|^2\over |e^{is/L} -e^{it/L}|^2}}&lt;/math&gt;

is smooth and nowhere vanishing with ''a''(''s'',''s'')  = ''L''&lt;sup&gt;2&lt;/sup&gt; if the length of the curve is 2{{pi}}''L''.

Similarly the function

:&lt;math&gt;\displaystyle{b(s,t)=  {(\mathbf{v}(s)-\mathbf{v}(t))\cdot\mathbf{n}(t)\over |e^{is/L} -e^{it/L}|^2}}&lt;/math&gt;

is smooth. In fact writing ''s'' = ''t'' + ''h'',

:&lt;math&gt;\displaystyle{\mathbf{v}(t+h)-\mathbf{v}(t)=h \mathbf{t}(t) + {h^2\over 2} \kappa(t) \mathbf{n}(t) -{h^3\over 6} \kappa(t)\mathbf{t}(t) + {h^4 \over 24}(\dot{\kappa}\mathbf{n} -\kappa^2 \mathbf{t}) + \cdots , }&lt;/math&gt;

so that

:&lt;math&gt;\displaystyle{h^{-2}(\mathbf{v}(t+h)-\mathbf{v}(t))\cdot\mathbf{n}(t)=\kappa(t)/2  +h^2 \dot{\kappa}(t)/24 +\cdots}&lt;/math&gt;

On the diagonal ''b''(''t'',''t'') = κ ''L''&lt;sup&gt;2&lt;/sup&gt; / 2. Since ''k'' is proportional to ''b'' / ''a'', it is also smooth. Its diagonal values are given by the formula

:&lt;math&gt;\displaystyle{k(t,t)=-{\kappa(t)\over 4\pi}.}&lt;/math&gt;

Another expression for ''k''(''s'',''t'') is as follows:&lt;ref&gt;{{harvnb|Khavinson|Putinar|Shapiro|2007|p=149}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{k(s,t)={1\over 2\pi}\partial_t \arg (z(s) - z(t)),}&lt;/math&gt;

where ''z''(''t'') = ''x''(''t'') + i ''y''(''t'') is the boundary curve parametrized by arc length. This follows from the identity

:&lt;math&gt;\displaystyle{\log z = \log |z| + i\arg z}&lt;/math&gt;

and the [[Cauchy–Riemann equations]] which can be used to express the normal derivative in terms of the tangential derivative.

Note that

:&lt;math&gt;\displaystyle{K(\mathbf{v}(t)+ \lambda \mathbf{n}(t),\mathbf{v}(t))=-{1\over 2\pi \lambda},}&lt;/math&gt;

so in the direction normal to the boundary curve ''K'' is discontinuous at the boundary.

==Double layer potentials==
The '''[[double layer potential]]''' with moment φ in C(∂Ω) is defined on the complement of ∂Ω as

:&lt;math&gt;\displaystyle{D(\varphi)(z)= \int_{\partial\Omega} K(z,w)\varphi(w)\, |dw|.}&lt;/math&gt;

It is a continuous function on the complement. Since the restriction of ''K'' extends to a smooth function on ∂Ω × ∂Ω, ''D''(φ) can also be defined on ∂Ω. However like the Neumann–Poincaré kernel it will have discontinuities at the boundary. These are jump discontinuities. If φ is real, then the double layer potential is just the real part of a Cauchy integral:&lt;ref&gt;{{harvnb|Hackbusch|1995|p=254}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{D(\varphi)(z)= \Re {1\over 2\pi i} \int_{\partial\Omega} {\varphi(w)\over w-z}\,dw .}&lt;/math&gt;

The simplest case is when φ is identically 1 on ∂Ω. In this case ''D''(1) equals

*1 on Ω, by the vanishing of the integral of the normal derivative on the boundary region bounded by ∂Ω and a small disk centred on ''z''; so the integral over the ∂Ω equals the average of the function 1 on the boundary of small disk and hence equals 1. (This integral and the one for  Ω&lt;sup&gt;''c''&lt;/sup&gt; can also be calculated using [[Cauchy's integral theorem]].)
*0 on Ω&lt;sup&gt;''c''&lt;/sup&gt;, because it is the integral of a normal derivative of a harmonic function.
*1/2 on ∂Ω, since

::&lt;math&gt;\displaystyle{\int_{\partial\Omega} K(z,w) |dw| ={1\over 2\pi}\int_{s-\pi L}^{s+\pi L} \partial_t \arg (z(s) - z(t))\, dt =1/2.}&lt;/math&gt;

By definition the '''Neumann–Poincaré operator''' ''T''&lt;sub&gt;''K''&lt;/sub&gt; is the operator on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω) given by the kernel ''K''(''z'',''w''). It is a [[Hilbert–Schmidt operator]] since the kernel is continuous. It takes values in C&lt;sup&gt;∞&lt;/sup&gt;(∂Ω) since the kernel is smooth. The third computation above is equivalent to the statement that the constant function 1 is an eigenfunction of ''T''&lt;sub&gt;''K''&lt;/sub&gt; with eigenvalue 1/2.

To establish jump formulas for more general functions, it is necessary to check that the integrals for ''D''(1) are uniformly absolutely convergent, i.e. that there is a uniform finite bound ''C'' such that

:&lt;math&gt;\displaystyle{\int_{\partial \Omega} |K(z,w)|\, |dw| \le C}&lt;/math&gt;

for all ''z'' not in the boundary. It is enough to check this for points in a tubular neighbourhood of the boundary. Any such point '''u''' lies on a normal through a unique point, '''v'''(0) say, on the curve and it is enough to look at the contribution to the integral from points '''v'''(''t'') with ''t'' in a small interval around 0. Writing

:&lt;math&gt;\displaystyle{\mathbf{u}=\mathbf{v}(0) + \lambda \mathbf{n}(0),}&lt;/math&gt;

it follows that

:&lt;math&gt;\displaystyle{\mathbf{v}(t)-\mathbf{u}= -\lambda\mathbf{n}(0) + t\mathbf{t}(0) + {t^2 \over 2}\kappa(0)\mathbf{n}(0) + O(t^3).}&lt;/math&gt;

So for ''t'' sufficiently small

:&lt;math&gt;\displaystyle{|\mathbf{v}(t)-\mathbf{u}|^2 = \lambda^2 + t^2(1-\lambda\kappa(0)) + O(t^3)\ge (\lambda^2 + t^2)/2,\,\,\, \,\,\,|(\mathbf{v}(t)-\mathbf{u})\cdot \mathbf{n}(0)| =|-\lambda + {t^2 \over 2}\kappa(0) +  O(t^3)|\le |\lambda| + C_1t^2}&lt;/math&gt;

for some constant ''C''&lt;sub&gt;1&lt;/sub&gt;. (The first inequality gives an approximate version of [[Pythagorean theorem|Pythagoras' theorem]] in the tubular neighbourhood.) Hence

:&lt;math&gt;\displaystyle{2\pi\cdot |K(\mathbf{u},\mathbf{v}(t))|={|(\mathbf{v}(t)-\mathbf{u})\cdot \mathbf{n}(0)|\over |\mathbf{v}(t)-\mathbf{u}|^2} \le {2|\lambda| + C_1t^2\over \lambda^2 + t^2}\le {2|\lambda|\over \lambda^2 + t^2} +C_1.}&lt;/math&gt;

Uniform boundedness follows because the first term has a finite integral independent of λ:

:&lt;math&gt;\displaystyle{\int_{-\infty}^\infty {|\lambda|\, dt\over t^2 + \lambda^2} = \int_{-\infty}^\infty {dt\over t^2 + 1}=\pi&lt;\infty.}&lt;/math&gt;

The bound above can be used to prove that if the moment φ vanishes at a boundary point ''z'' then its double layer potential ''D''(φ) is continuous at ''z''. More generally if φ&lt;sub&gt;''n''&lt;/sub&gt; tends uniformly to φ, then ''D''(φ&lt;sub&gt;''n''&lt;/sub&gt;)(''z''&lt;sub&gt;''n''&lt;/sub&gt;) converges to ''D''(φ)(''z''). In fact suppose that |φ(''w'')| ≤ ε if |''w'' - ''z''| ≤ δ. Taking ''z''&lt;sub&gt;''n''&lt;/sub&gt; tending to ''z''

:&lt;math&gt;|D(\varphi_n)(z_n) - D(\varphi)(z)| \le \int_{|w-z|\ge\delta} |K(z_n,w)-K(z,w)||\varphi(w)|\,|dw|
+\int_{|w-z|\le\delta} (|K(z_n,w)|+|K(z,w)|)\cdot|\varphi(w)|  \, |dw|&lt;/math&gt;
:::::::::::::&lt;math&gt; + \int_{\partial \Omega} |K(z_n,w)|\cdot |\varphi_n(w) -\varphi(w)|\, |dw|.&lt;/math&gt;

The first integrand tends uniformly to 0 so the integral tends to 0. The second integral is bounded above by 2ε''C''. The third integral is bounded by C times the supremum norm of φ&lt;sub&gt;''n''&lt;/sub&gt; − φ. Hence ''D''(φ)(''z''&lt;sub&gt;''n''&lt;/sub&gt;) tends to ''D''(φ)(''z'').

'''JUMP FORMULAS.''' If φ is a continuous function on ∂Ω, the restrictions of its double layer potential ''u'' = ''D''φ to Ω and  Ω&lt;sup&gt;''c''&lt;/sup&gt; extend uniquely to continuous functions on their closures. Let ''u''&lt;sub&gt;−&lt;/sub&gt; and ''u''&lt;sub&gt;+&lt;/sub&gt; be the resulting continuous functions on ∂Ω. Then

:&lt;math&gt;\displaystyle{u_-(z) = {1\over 2}\varphi(z) + T_K\varphi(z),\,\,\,\,\,  u_+(z) = -{1\over 2}\varphi(z) + T_K\varphi(z).}&lt;/math&gt;

In particular

:&lt;math&gt;\displaystyle{\varphi=u_- - u_+.}&lt;/math&gt;

In fact the expressions for ''u''&lt;sub&gt;±&lt;/sub&gt; are continuous, so it is enough to show that the if ''z''&lt;sub&gt;''n''&lt;/sub&gt; tends to a boundary point ''z'' with ''z''&lt;sub&gt;''n''&lt;/sub&gt; in Ω or  Ω&lt;sup&gt;''c''&lt;/sup&gt; then ''u''(''z''&lt;sub&gt;''n''&lt;/sub&gt;) tends to the expression for ''u''&lt;sub&gt;±&lt;/sub&gt;(''z''). If ''z''&lt;sub&gt;''n''&lt;/sub&gt; lie in Ω or Ω&lt;sup&gt;''c''&lt;/sup&gt; then

:&lt;math&gt;\displaystyle{u(z_n) \mp {1\over 2}\varphi(z) - T_K\varphi(z)=\int_{\partial \Omega} (K(z_n,w) -K(z,w))(\varphi(w)-\varphi(z))\,|dw| = D(\psi)(z_n) - D(\psi)(z),}&lt;/math&gt;

where ψ(''w'') = φ(''w'') − φ(''z''). The right hand side tends to zero since ψ vanishes at ''z''.

==Single layer potentials==
The '''[[single layer potential]]''' with moment φ in C(∂Ω) is defined on '''C''' as

:&lt;math&gt;\displaystyle{S(\varphi)(z)=\int_{\partial\Omega} N(z-w)\varphi(w)\,|dw|,}&lt;/math&gt;

where ''N'' is the [[Newtonian potential]]

:&lt;math&gt;\displaystyle{N(z)={1\over 2 \pi} \log |z|.}&lt;/math&gt;

The single layer potential is harmonic off ∂Ω. Since

:&lt;math&gt;\displaystyle{S(\varphi)(z)={1\over 2\pi}\int_{\partial} (\log |z-w| - \log |z|) \varphi(w)\,|dw| + {\log |z| \over 2\pi} \int \varphi(w) \, |dw|,}&lt;/math&gt;

and the first integrand tends uniformly to 0 as |''z''| tends to infinity, the single layer potential is harmonic at infinity if and only if ∫ φ = 0.

The single layer potential is continuous on '''C'''. In fact continuity off ∂Ω is clear. If ''z''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''z'' with ''z'' in ∂Ω, then

:&lt;math&gt;|S(\varphi)(z)-S(\varphi)(z_n)| \le{1\over 2\pi}\int_{|w-z|\ge \varepsilon} |\log |z-w| -\log |z_n-w||\,|\varphi(w)|\, |dw| + \|\varphi\|_\infty \int_{|w-z|\le \varepsilon} (|\log|z-w|| + |\log|z_n-w||)\, |dw|.&lt;/math&gt;

The first integrand tends uniformly to 0 on |''w'' - ''z''| ≥ ε. For ''n'' sufficiently large the last integral is bounded by

:&lt;math&gt;\displaystyle{2\int_{|w-z|\le 2\varepsilon} |\log|z-w|| \,\, |dw|,}&lt;/math&gt;

which tends to 0 as ε tends to 0, by the [[Cauchy–Schwarz inequality]] since the integrand is square integrable.

The same argument shows that ''S'' = ''T''&lt;sub&gt;''N''&lt;/sub&gt; defines a bounded operator on C(∂Ω):

:&lt;math&gt;\displaystyle{\|S\varphi\|_\infty \le C^\prime \|\varphi\|_\infty,}&lt;/math&gt;

for φ in C(∂Ω).

Although the single layer potentials are continuous, their first derivatives have a jump discontinuity across ∂Ω. On the tubular neighbourhood of ∂Ω, the '''normal derivative''' is defined by

:&lt;math&gt;\displaystyle{\partial_n u(z + a\mathbf{n}_z)={d\over dt} a(z+t\mathbf{n}_z)|_{t=a}.}&lt;/math&gt;

It follows that

:&lt;math&gt;\displaystyle{\partial_n S(\varphi)(z)=\int_{\partial\Omega} K(w,z) \varphi(w)\,|dw|,}&lt;/math&gt;

so it is given by the adjoint kernel of ''K'':

:&lt;math&gt;\displaystyle{K^*(z,w)=K(w,z).}&lt;/math&gt;

The kernel ''K''* extends naturally to a smooth function on  ∂Ω × ∂Ω and the operator ''T''&lt;sub&gt;''K''*&lt;/sub&gt; is the adjoint of ''T''&lt;sub&gt;''K''&lt;/sub&gt; on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω).

'''JUMP FORMULAS.''' If φ is a continuous function on ∂Ω, the normal derivatives of the single layer potential ''u'' = ''S''(φ) on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt; near ∂Ω extend continuously to the closure of both regions, defining continuous functions ∂&lt;sub&gt;''n''-&lt;/sub&gt; ''u'' and ∂&lt;sub&gt;''n''+&lt;/sub&gt; ''u'' on ∂Ω. Then

:&lt;math&gt;\displaystyle{\partial_{n-}u(z) = -{1\over 2}\varphi(z) + T_K^*\varphi(z),\,\,\,\,\,  \partial_{n+}u(z) = {1\over 2}\varphi(z) + T_K^*\varphi(z).}&lt;/math&gt;

In particular

:&lt;math&gt;\displaystyle{\varphi=\partial_{n+}u - \partial_{n-}u.}&lt;/math&gt;

In fact let ''v'' = ''D''(φ) be the double layer potential with moment φ. On ∂Ω set

:&lt;math&gt;\displaystyle{f=T_K\varphi + T_K^*\varphi}&lt;/math&gt;

and on the complement of ∂Ω in a tubular neighbourhood set

:&lt;math&gt;\displaystyle{f=v +\partial_n u.}&lt;/math&gt;

Then ''f'' is continuous on the tubular neighbourhood. In fact, by definition is continuous on ∂Ω and its complement, so it  suffices to that ''f''(''z''&lt;sub&gt;''n''&lt;/sub&gt;) tends to ''f''(''z'') whenever ''z''&lt;sub&gt;''n''&lt;/sub&gt; is a sequence of points in the complement tending to a boundary point ''z''. In this case

:&lt;math&gt;\displaystyle{f(z_n)-f(z)=\int_{\partial\Omega} (K(w,z_n) + K(z_n,w) - K(w,z) - K(z,w))\varphi(w) \, |dw| =\int_{|w-z|\ge \delta} + \int_{|w-z|\le \delta}.}&lt;/math&gt;

The integrand tends uniformly to 0 for |''w'' − ''z''| ≥ δ, so the first integral tends to 0. To show the second integral is small for δ small, it suffices to show that the integrand is uniformly bounded. This follows because, if ζ&lt;sub&gt;''n''&lt;/sub&gt; is the point on ∂Ω with normal containing ''z''&lt;sub&gt;''n''&lt;/sub&gt;, then

:&lt;math&gt;\displaystyle{2\pi|K(z_n,w)+K(w,z_n)| ={|(z_n-w)\cdot (\mathbf{n}_{\zeta_n} -\mathbf{n}_w)|\over  |z_n-w|^2}\le {|\mathbf{n}_{\zeta_n} -\mathbf{n}_w|\over |z_n-w|}={|\mathbf{n}_{\zeta_n} -\mathbf{n}_w|\over |\zeta_n-w|}\cdot {|\zeta_n -w|\over |z_n-w|}.}&lt;/math&gt;

The first term the last product uniformly bounded because of the smoothness of the Gauss map '''n'''(''t''). The second is uniformly bounded because of the approximate version of Pythagoras' theorem:

:&lt;math&gt;\displaystyle{|z_n -w|^2 \ge (|z_n-\zeta_n|^2 + |\zeta_n -w|^2)/2.}&lt;/math&gt;

Continuity of ''f'' implies that on ∂Ω

:&lt;math&gt;\displaystyle{T_K\varphi + T^*_K\varphi= v_\pm +\partial_{n\pm}u=\mp\varphi/2 +T_K\varphi +\partial_{n\pm}u,}&lt;/math&gt;

which gives the jump formulas.

==Derivatives of layer potentials==
If the moment φ is smooth, the derivatives of the single and double layer potentials on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt; extend continuously to their closures.&lt;ref&gt;{{harvnb|Saranen|Vainniko|2001}}&lt;/ref&gt;

As usual the [[gradient]] of a function ''f'' defined on an open set in '''R'''&lt;sup&gt;2&lt;/sup&gt; is defined by

:&lt;math&gt;\displaystyle{\nabla f=(\partial_xf,\partial_yf).}&lt;/math&gt;

Set

:&lt;math&gt;\displaystyle{\widetilde{\nabla} f=(\partial_yf, -\partial_xf).}&lt;/math&gt;

If the moment φ is smooth, then

:&lt;math&gt;\displaystyle{\nabla S(\varphi) = -D(\varphi \mathbf{n}) + S(\partial_t (\varphi \mathbf{t})),\,\,\, 
\nabla D(\varphi)=\widetilde{\nabla} S(\dot{\varphi}).}&lt;/math&gt;

In fact

:&lt;math&gt;\displaystyle{\nabla_z N(z-w)=-\nabla_wN(z-w) =-\partial_{n,w}N(z-w)\mathbf{n}_w -\partial_tN(z-w)\mathbf{t}_w,}&lt;/math&gt;

so that

:&lt;math&gt;\displaystyle{\nabla S(\varphi)= -D(\varphi \mathbf{n})-\int_{\partial\Omega} (\partial_{t}N(z-\mathbf{v}(t))) \varphi(t)\mathbf{t}(t)\, dt= -D(\varphi \mathbf{n})+ S(\partial_t (\varphi \mathbf{t})).}&lt;/math&gt;

Moreover

:&lt;math&gt;\displaystyle{\nabla D(\varphi) = \int_{\partial\Omega} \Delta_z N(z-w)\mathbf{n}\varphi -\widetilde{\nabla}\int_{\partial\Omega} \partial_{t}N(z-\mathbf{v}(t))\,\varphi \, dt=\widetilde{\nabla} S(\dot{\varphi}).}&lt;/math&gt;

The second relation can be rewritten by substituting in from the first relation:

:&lt;math&gt;\displaystyle{\nabla D(\varphi)=D(\dot{\varphi}\mathbf{t}) + S(\partial_t(\dot{\varphi}\mathbf{n})),}&lt;/math&gt;

'''Regularity of layer potentials.''' As a consequence of these relations, successive derivatives can all be expressed in terms of single and double layer potentials of smooth moments on the boundary. Since the layer potentials on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt; have continuous limits on the boundary it follows that they define smooth functions on the closures of  Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt;.

'''Continuity of normal derivatives of double layer potentials.''' Just as the single layer potentials are continuous at the boundary with a jump in the normal derivative, so the double layer potentials have a jump across the boundary while their normal derivatives are continuous. In fact from the formula above

:&lt;math&gt;\displaystyle{\partial_n D(\varphi)(\mathbf{v}(s) +\lambda \mathbf{n}(s))= D(\dot{\varphi}\mathbf{t}\cdot \mathbf{n}(s))+ S(\partial_t(\dot{\varphi}\mathbf{n})\cdot\mathbf{n}(s)).} &lt;/math&gt;

If ''s''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''s'' and λ&lt;sub&gt;''n''&lt;/sub&gt; tends to 0, the first term tends to ''T''&lt;sub&gt;''K''&lt;/sub&gt;(''v''(s)) since the moments tend uniformly to a moment vanishing at ''t'' = ''s''; the second term is continuous because it is a single layer potential.

==Solution of Dirichlet and Neumann problems==
The following properties of ''T'' = ''T''&lt;sub&gt;''K''&lt;/sub&gt; are required to solve the boundary value problem:

* 1/2 is not a generalized eigenvalue of ''T''&lt;sub&gt;''K''&lt;/sub&gt; or ''T''&lt;sub&gt;''K''&lt;/sub&gt;*; it has multiplicity one.
* −1/2 is not an eigenvalue of ''T''&lt;sub&gt;''K''&lt;/sub&gt; or ''T''&lt;sub&gt;''K''&lt;/sub&gt;*.

In fact since ''a'' I + ''T'' is a Fredholm operator of index 0, it and its adjoint have kernels of equal dimension. The same applies to any power of this operator. So it suffices to verify each of the statements for either ''T'' or ''T''*. To check that ''T'' has no generalized eigenvectors with eigenvalue 1/2 it suffices to show that

:&lt;math&gt;\displaystyle{T_K\varphi -{1\over 2}\varphi = 1}&lt;/math&gt;

has no solutions. The definition of the double layer potential shows that it vanishes at ∞, so that it is harmonic at ∞. The equation above shows that if ''u'' = ''D''(φ) then ''u''&lt;sub&gt;+&lt;/sub&gt; = 1. On the other hand, applying the inversion map gives a contradiction; for it would produce a harmonic map in bounded region vanishing at an interior point with boundary value 1, which contradicts the fact that 1 is the only harmonic map with boundary value 1. If the eigenvalue 1/2 has multiplicity greater than 1, there is a moment φ such that ''T''*φ = φ/2 and ∫ φ = 0. It follows that if ''u'' = ''S''(φ) then ∂&lt;sub&gt;''n''−&lt;/sub&gt; ''u'' = 0. By uniqueness ''u'' is constant on Ω. Since ''u'' is continuous on '''R'''&lt;sup&gt;2&lt;/sup&gt; ∪ ∞ and is harmonic at ∞ (since ∫ φ = 0) and constant on ∂Ω, it must be zero. Hence φ = ∂&lt;sub&gt;''n''+&lt;/sub&gt; ''u'' − ∂&lt;sub&gt;''n''−&lt;/sub&gt; ''u'' = 0. Thus the eigenspace is one-dimensional and the eigenfunction ψ can be normalized so that ''S''(ψ) = 1 on ∂Ω.

In general if

:&lt;math&gt;\displaystyle{T_K^*\varphi +{1\over 2}\varphi = f,}&lt;/math&gt;

then

:&lt;math&gt;\displaystyle{\int \varphi =\int f,}&lt;/math&gt;

since

:&lt;math&gt;\int f=(f,1)=((T_K^* +{1\over 2})\varphi,1)=(\varphi,(T_K + {1\over 2})1)=(\varphi,1)=\int \varphi.&lt;/math&gt;

If φ satisfies

:&lt;math&gt;\displaystyle{T_K^*\varphi +{1\over 2}\varphi = 0,}&lt;/math&gt;

it follows that ∫ φ = 0 and so ''u'' = ''S''(φ) is harmonic at infinity. By the jump formulas, ∂&lt;sub&gt;''n''-&lt;/sub&gt;''u'' = 0. By uniqueness ''u'' is constant on Ω. By continuity it is constant on ∂Ω. Since it is harmonic on Ω&lt;sup&gt;''c''&lt;/sup&gt; and vanishes at infinity, it must vanish identically. As above this forces φ = 0.

These results on the eigenvalues of ''T''&lt;sub&gt;''K''&lt;/sub&gt; lead to the following conclusions about the four boundary value problems:

*there is always a unique solution to the interior and exterior Dirichlet problems;
*there is a solution to the interior and exterior Neumann problems if and only if ∫ ''f'' = 0; the solution is unique up to a constant for the interior Neumann problem and unique for the exterior problem;
*the solution is smooth on the closure of the domain if the boundary data is smooth.

The solution is obtained as follows:

*'''Interior Dirichlet problem.''' Let φ be the unique solution of ''T''&lt;sub&gt;''K''&lt;/sub&gt;φ + φ/2 = ''f''. Then ''u'' = ''D''(φ) gives the solution of the Dirichlet problem in Ω by the jump formula.
*'''Exterior Dirichlet problem.''' Since 1 is not in the range of ''T''&lt;sub&gt;''K''&lt;/sub&gt; − ½''I'', ''f'' can be written uniquely as ''f'' = ''T''&lt;sub&gt;''K''&lt;/sub&gt;φ − φ/2 + λ where φ is unique up to a constant. Then ''u'' = ''D''(φ) + λ''S''(ψ) gives the solution of the Dirichlet problem in Ω&lt;sup&gt;''c''&lt;/sup&gt; by the jump formula.
*'''Interior Neumann problem.''' The condition (''f'',1) = 0 implies that ''f'' = ''T''&lt;sub&gt;''K''&lt;/sub&gt;*φ − φ/2 can be solved. Then ''u'' = ''S''(φ) gives the solution of the Neumann problem in Ω by the jump formula.
*'''Exterior Neumann problem.''' Let φ be the unique solution of ''T''&lt;sub&gt;''K''&lt;/sub&gt;*φ + φ/2 = ''f''. Then ''u'' = ''S''(φ) gives the solution of the Neumann problem in Ω by the jump formula.

The smoothness of the solution follows from the regularity of single and double layer potentials.

==Calderón projector==
{{main article|Calderón projector}}
There is another consequence of the laws giverning the derivatives, which completes the symmetry of the jump relations, is that normal derivative of the double layer potential has no jump across the boundary, i.e. it has a continuous extension to a tubular neighbourhood of the boundary given by&lt;ref&gt;{{harvnb|Saranen|Vainniko|2001}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{H(\varphi)=-\partial_n D(\varphi)|_{\partial\Omega} =-\partial_t(S(\partial_t\varphi)|_{\partial\Omega}).}&lt;/math&gt;

''H'' is called a '''hypersingular operator'''. Although it takes smooth functions to smooth functions, it is not a bounded operator on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω). In fact it is a [[pseudodifferential operator]] of order 1, so does define a bounded operator between Sobolev spaces on ∂Ω, decreasing the order by 1. It allows a 2 × 2 matrix of operators to be defined by

:&lt;math&gt;\displaystyle{C=\begin{pmatrix} {1\over 2}I + T_K &amp; S\\ H &amp; {1\over 2}I - T_K^*\end{pmatrix}.}&lt;/math&gt;

The matrix satisfies ''C''&lt;sup&gt;2&lt;/sup&gt; = ''C'', so is an [[idempotent]], called the '''Calderón projector.'''  This identity is equivalent the following classical relations, the first of which is the symmetrization relation of Plemelj:

:&lt;math&gt;\displaystyle{ST^*=TS,\,\,\,SH={1\over 4}I - T^2,\,\,\, HS={1\over 4}I - (T^*)^2, \,\,\, HT=T^*H.}&lt;/math&gt;

The operators ''T'' and ''S'' are pseudodifferential operators of order −1. The relations above follow by considering ''u'' = ''S''(φ). It has boundary value ''S''φ) and normal derivative ''T''* φ − φ/2. Hence in Ω

:&lt;math&gt;\displaystyle{u=D(S\varphi) - S(T^*\varphi) + S(\varphi)/2.}&lt;/math&gt;

Taking the boundary values of both sides and their normal derivative yields 2 equations. Two more result by considering ''D''(Ψ); these imply the relations for the Calderón projector.

==Fredholm eigenvalues==
{{see also|Symmetrizable compact operator}}
The non-zero [[eigenvalue]]s of the Neumann–Poincaré operator ''T''&lt;sub&gt;''K''&lt;/sub&gt; are called the '''Fredholm eigenvalues''' of the region Ω. Since ''T''&lt;sub&gt;''K''&lt;/sub&gt; is a [[compact operator]], indeed a [[Hilbert–Schmidt operator]], all non-zero elements in its spectrum are eigenvalues of finite multiplicity by the general theory of [[Fredholm operator]]s. The solution of the boundary value requires knowledge of the spectrum at ± 1/2, namely that the constant function gives an eigenfunction with eigenvalue 1/2 and multiplicity one; that there are no corresponding generalized eigenfunctions with eigenvalue 1/2; and that -1/2 is not an eigenvalue. {{harvtxt|Plemelj|1911}} proved that all non-zero eigenvalues are real and contained in the interval (-1/2,1/2]. {{harvtxt|Blumenfeld|Mayer|1914}} proved that the other non-zero eigenvalues have an important symmetry property, namely that if λ is an eigenvalue with 0 &lt; |λ| &lt; 1/2, then so is –λ, with the same multiplicity. Plemelj also showed that ''T'' = ''T''&lt;sub&gt;''K''&lt;/sub&gt; is a [[symmetrizable compact operator]], so that, even though it is not self-adjoint, it shares many of the properties of self-adjoint operators. In particular there are no generalized eigenfunctions for non-zero eigenvalues and there is a [[variational principle]] similar to the [[minimax principle]] for determining the non-zero eigenvalues.

If λ ≠ 1/2 is an eigenvalue of ''T''&lt;sub&gt;''K''&lt;/sub&gt;* then λ is real, with  λ ≠ ± 1/2. Let φ be a corresponding eigenfunction and, following Plemelj, set ''u'' = ''S''(φ).&lt;ref&gt;{{harvnb|Kress|1999|pp=174–175}}&lt;/ref&gt;  Then the jump formulas imply that

:&lt;math&gt;\displaystyle{\partial_{n\pm} u =(\lambda \mp{1\over 2})\varphi,}&lt;/math&gt;

and hence that

:&lt;math&gt;\displaystyle{(\lambda +{1\over 2}) \int_{\partial\Omega} \partial_{n+}u \, \overline{u} =(\lambda -{1\over 2}) \int_{\partial\Omega} \partial_{n-}u \, \overline{u}.}&lt;/math&gt;
 
Since ∫ φ = 0, ''u'' is harmonic at ∞. So by Green's theorem

:&lt;math&gt;\displaystyle{(\lambda +{1\over 2}) \iint_{\Omega} |u_x|^2 + |u_y|^2  = (\lambda -{1\over 2}) \iint_{\Omega^c} |u_x|^2 + |u_y|^2.}&lt;/math&gt;

If both the integrals vanish then ''u'' is constant on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt;. Since it is continuous and vanishes at ∞, it must therefore be identically 0, contradicting φ = ∂&lt;sub&gt;''n''+&lt;/sub&gt; - ∂&lt;sub&gt;''n''−&lt;/sub&gt;. So both integrals are strictly positive and hence λ must lie in (−½,½).

Let  φ be an eigenfunction of ''T''&lt;sub&gt;''K''&lt;/sub&gt;* with real eigenvalue λ satisfying 0 &lt; |λ| &lt; 1/2. If ''u'' = ''S''(φ), then on
∂Ω

:&lt;math&gt;\displaystyle{u_+ = u_-,\,\,\, {\partial_{n+}u\over \lambda+{1\over 2}}={\partial_{n_-}u\over \lambda -{1\over 2}}=\varphi.}&lt;/math&gt;

This process can be reversed. Let ''u'' be a continuous function on '''R'''&lt;sup&gt;2&lt;/sup&gt; ∪ ∞ which is harmonic on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt; ∪ ∞ and such that the derivatives of ''u'' on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt; extend continuously to their closures. Suppose that

:&lt;math&gt;\displaystyle{{\partial_{n+}u\over \lambda + {1\over 2}}={\partial_{n_-}u\over\lambda - {1\over 2}}=\varphi.}&lt;/math&gt;

Let ψ be the restriction of ''u'' to  ∂Ω. Then

:&lt;math&gt;\displaystyle{u|_\Omega = D(\psi) - (\lambda - {1\over 2})S(\varphi), \,\,\, u|_{\Omega^c} = -D(\psi) +(\lambda+{1\over 2})S(\varphi).}&lt;/math&gt;

The jump formulas for the boundary values and normal derivatives give

:&lt;math&gt;\displaystyle{\psi=T\psi +{1\over 2}\psi -(\lambda- {1\over 2})S\varphi=-(T\psi -{1\over 2}\psi) +(\lambda+{1\over 2})S\varphi}&lt;/math&gt;

and

:&lt;math&gt;\displaystyle{(\lambda-{1\over 2})\varphi=\partial_n D(\psi)|_{\partial \Omega} -(\lambda - {1\over 2})(T^*\varphi-{1\over 2}\varphi),\,\,\,\, (\lambda +{1\over 2})\varphi=-\partial_n D(\psi)|_{\partial\Omega} +(\lambda + {1\over 2})(T^*\varphi+{1\over 2}\varphi).}&lt;/math&gt;

It follows that

:&lt;math&gt;\displaystyle{T\psi=\lambda\psi, \,\,\, T^*\varphi =\lambda\varphi, \,\,\, S\varphi=\psi, \,\,\, \partial_n D(\psi)|_{\partial\Omega}=(\lambda^2 -{1\over 4})\varphi,}&lt;/math&gt;

so that ψ and φ are eigenfunctions of ''T'' and ''T''* with eigenvalue λ.

Let ''u'' be a real harmonic function on Ω extending to a smooth function on its closure. The [[harmonic conjugate]] ''v'' of ''u'' is the unique real function on Ω such that ''u'' + ''i'' ''v'' is holomorphic. As such it must satisfy the [[Cauchy–Riemann equations]]:

:&lt;math&gt;\displaystyle{u_x=-v_y,\,\, u_y=v_x.}&lt;/math&gt;

If ''a'' is a point in Ω, a solution is given by

:&lt;math&gt;\displaystyle{v(z)=\int_a^z -u_y dx + u_x dy,}&lt;/math&gt;

where the integral is taken over any path in the closure of Ω. It is easily verified that ''v''&lt;sub&gt;''x''&lt;/sub&gt; and ''v''&lt;sub&gt;''y''&lt;/sub&gt; exist and are given by the corresponding derivatives of ''u''. Thus ''v'' is a smooth function on the closure of Ω, vanishing at 0. By the Cauchy-Riemann equations, ''f'' = ''u'' + ''i'' ''v'' is smooth on the closure of Ω, holomorphic on
Ω and ''f''(a) = 0. Using the inversion map, the same result holds for a harmonic function in  Ω&lt;sup&gt;''c''&lt;/sup&gt; harmonic at ∞. It has a harmonic conjugate ''v'' such that  ''f'' = ''u'' + ''i'' ''v'' extends smoothly to the boundary and ''f'' is holomorphic on Ω ∪ ∞. Adjusting ''v'' by a constant it can be assumed that ''f''(∞) = 0.

Following {{harvtxt|Schiffer|2011}}, let  φ be an eigenfunction of ''T''&lt;sub&gt;''K''&lt;/sub&gt;* with real eigenvalue λ satisfying 0 &lt; |λ| &lt; 1/2. Let ''u'' = ''S''(φ) and let ''v''&lt;sub&gt;±&lt;/sub&gt; be the harmonic conjugates of ''u''&lt;sub&gt;±&lt;/sub&gt; in  Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt;.
Since on ∂Ω

:&lt;math&gt;\displaystyle{u_+ = u_-,\,\,\, {\partial_{n+}u\over \lambda-{1\over 2}}={\partial_{n_-}u\over \lambda+{1\over 2}}=\varphi,}&lt;/math&gt;

the Cauchy-Riemann equations give on ∂Ω

:&lt;math&gt;\displaystyle{\partial_{n+}v=\partial_{n_-}v,\,\,\,\,v_+={\lambda+{1\over 2}\over \lambda - {1\over 2}}\cdot v_-.}&lt;/math&gt;

Now define

:&lt;math&gt;\displaystyle{U_-=v_-, \,\,\,\,U_+={\lambda+{1\over 2}\over \lambda - {1\over 2}}\cdot v_+.}&lt;/math&gt;

Thus ''U'' is continuous on '''R'''&lt;sup&gt;2&lt;/sup&gt; and

:&lt;math&gt;\displaystyle{\partial_{n+}U={\lambda-{1\over 2}\over \lambda + {1\over 2}}\cdot \partial_{n_-}U.}&lt;/math&gt;

It follows that −λ is an eigenvalue of ''T''. Since −''u'' is the harmonic conjugate of ''v'', the process of taking harmonic conjugates is one-one, so the multiplicity of −λ as an eigenvalue is the same as that of λ.

By Green's theorem

:&lt;math&gt;\displaystyle{\iint_\Omega S(\varphi_1)_x S(\varphi_2)_x + S(\varphi_1)_yS(\varphi_2)_y =\int_{\partial\Omega}S(\varphi_1)\partial_{n-} S(\varphi_2),\,\,\,\iint_{\Omega^c} S(\varphi_1)_x S(\varphi_2)_x + S(\varphi_1)_yS(\varphi_2)_y =\int_{\partial\Omega}S(\varphi_1)\partial_{n-} S(\varphi_2).}&lt;/math&gt;

Adding the two integrals and using the jump relations for the single layer potential, it follows that

:&lt;math&gt;\displaystyle{\iint S(\varphi_1)_x S(\varphi_2)_x + S(\varphi_1)_yS(\varphi_2)_y = \int_{\partial\Omega} S(\varphi_1)\varphi_2.}&lt;/math&gt;

Thus

:&lt;math&gt;\displaystyle{(S\varphi,\varphi)=\int \|\nabla S(\phi)\|^2, \,\,\, (S\varphi_1,\varphi_2) = \int \nabla S(\varphi_1) \cdot \overline{\nabla S(\varphi_2)}.}&lt;/math&gt;

This shows that the operator ''S'' is self-adjoint and non-negative on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω).

The image of ''S'' is dense (or equivalently it has zero kernel). In fact the relation ''SH'' = ¼ ''I'' - ''T''&lt;sup&gt;2&lt;/sup&gt; =(½ ''I'' – ''T'') (½ ''I'' + ''T'') shows that the closure of the image of ''S'' contains the image of ½ ''I'' – ''T'', which has codimension 1. Its orthogonal complement is given by the kernel of ''T'' – ½ ''I'', i.e. the eigenfunction ψ such that ''T''*ψ = ½ ψ. On the other hand ''ST''=''T''* ''S''. If the closure of the image is not the whole of L&lt;sup&gt;2&lt;/sup&gt;(∂Ω) then necessarily ''S''ψ = 0. Hence ''S''{ψ) is constant. But then ψ = ∂&lt;sub&gt;''n''+&lt;/sub&gt;''S''(ψ) – ∂&lt;sub&gt;''n''−&lt;/sub&gt;''S''(ψ) = 0, a contradiction.

Since ''S'' is strictly positive and ''T'' satisfies the Plemelj symmetrization relation ''ST''* = ''TS'', the operator ''T''* is a [[symmetrizable compact operator]]. The operator ''S'' defines a new inner product on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω):

:&lt;math&gt;\displaystyle{(f,g)_S=(Sf,g).}&lt;/math&gt;

The operator ''T''* is formally self-adjoint with respect to this inner product and by general theory its restriction is bounded and it defines a self-adjoint Hilbert–Schmidt operator on the Hilbert space completion. Since ''T''* is formally self-adjoint on this inner product space, it follows immediately that any generalized eigenfunction of ''T''* must already be an eigenfunction. By Fredholm theory, the same is true for ''T''. By general theory the kernel of ''T'' and its non-zero eigenspaces span a dense subspace of L&lt;sup&gt;2&lt;/sup&gt;(∂Ω). The [[Fredholm determinant]] is defined by

:&lt;math&gt;\displaystyle{\Delta(z)=\det (I -zT^2).}&lt;/math&gt;

It can be expressed in terms of the Fredholm eigenvalues λ&lt;sub&gt;''n''&lt;/sub&gt; with modulus less than 1/2, counted with multiplicity, as

:&lt;math&gt;\displaystyle{\Delta(z)=(1-z/4)\cdot \prod_{n\ge 1} (1-z\lambda_n^2).}&lt;/math&gt;

==Complex Hilbert transform==
{{See also|Beurling transform|Grunsky matrix}}
Now define the '''complex Hilbert transform''' or '''conjugate Beurling transform''' ''T''&lt;sub&gt;''c''&lt;/sub&gt; on L&lt;sup&gt;2&lt;/sup&gt;('''C''') by

:&lt;math&gt;\displaystyle{T_c f(w)=\lim_{\varepsilon\rightarrow 0} {1\over \pi i} \iint_{|z-w|\ge \varepsilon} {\overline{f(z)} \over (z-w)^2}\, dx\,dy.}&lt;/math&gt;

This is a conjugate-linear isometric involution.&lt;ref&gt;{{harvnb|Schiffer|1981}}&lt;/ref&gt;

It commutes with ∂&lt;sub&gt;{{overline|''z''}}&lt;/sub&gt; so carries A&lt;sup&gt;2&lt;/sup&gt;(Ω) ⊕ A&lt;sup&gt;2&lt;/sup&gt;(Ω&lt;sup&gt;''c''&lt;/sup&gt;) onto itself. The compression of ''T''&lt;sub&gt;''c''&lt;/sub&gt; to A&lt;sup&gt;2&lt;/sup&gt;(Ω) is denoted ''T''&lt;sub&gt;Ω&lt;/sub&gt;.

If ''F'' is a holomorphic univalent map from the unit disk ''D'' onto Ω then the Bergman space of Ω and its conjugate can be identified with that of ''D'' and  ''T''&lt;sub&gt;Ω &lt;/sub&gt; becomes the conjugate-linear singular integral operator with kernel

:&lt;math&gt; K_F(z,w)={F^\prime(z)F^\prime(w)\over (F(z)-F(w))^2}.&lt;/math&gt;

It defines a [[contraction (operator theory)|contraction]]. On the other hand it can be checked that ''T''&lt;sub&gt;''D''&lt;/sub&gt; = 0 by computing directly on powers {{overline|''z''}}&lt;sup&gt;''n''&lt;/sup&gt; using Stokes theorem to transfer the integral to the boundary.

It follows that the conjugate-linear operator with kernel

:&lt;math&gt;\displaystyle{  {F^\prime(z)F^\prime(w)\over (F(z)-F(w))^2} \,-\,{1\over (z-w)^2}}&lt;/math&gt;

acts as a contraction on the Bergman space of ''D''.  It is thus a [[Hilbert–Schmidt operator]].

The conjugate-linear operator ''T'' = ''T''&lt;sub&gt;Ω&lt;/sub&gt; satisfies the self-adjointness relation

:&lt;math&gt;\displaystyle{(Tu,v)=(Tv,u)}&lt;/math&gt;

for ''u'', ''v'' in A&lt;sup&gt;2&lt;/sup&gt;(Ω).

Thus ''A'' = ''T''&lt;sup&gt;2&lt;/sup&gt; is a compact self-adjoint linear operator on ''H'' with

:&lt;math&gt;\displaystyle{(Au,u)=(Tu,Tu)=\|Tu\|^2\ge 0,}&lt;/math&gt;

so that ''A'' is a positive operator. By the spectral theorem for compact self-adjoint operators, there is an orthonormal basis ''u''&lt;sub&gt;''n''&lt;/sub&gt; of ''H'' consisting of eigenvectors of ''A'':

:&lt;math&gt; \displaystyle{Au_n=\mu_n u_n,}&lt;/math&gt;

where μ&lt;sub&gt;''n''&lt;/sub&gt; is non-negative by the positivity of ''A''. Hence

:&lt;math&gt; \displaystyle{\mu_n=\lambda_n^2}&lt;/math&gt;

with λ&lt;sub&gt;''n''&lt;/sub&gt; ≥ 0. Since ''T'' commutes with ''A'', it leaves its eigenspaces invariant. The positivity relation shows that it acts trivially on the zero eigenspace. The other non-zero eigenspaces are all finite-dimensional and mutually orthogonal. Thus an orthonormal basis can be chosen on each eigenspace so that:

:&lt;math&gt; \displaystyle{Tu_n=\lambda_n u_n.}&lt;/math&gt;

Note also that

:&lt;math&gt;\displaystyle{ T(iu_n)=-\lambda_n iu_n}&lt;/math&gt;

by conjugate-linearity of ''T''.

==Connection with Hilbert transform on a closed curve==
{{See also|Singular integral operators on closed curves}}
The Neumann–Poincaré operator is defined on real functions ''f'' as

:&lt;math&gt;\displaystyle{Tf(w)={1\over 2\pi}\int_{\partial\Omega}\partial_n (\log|z-w|) f(z)={1\over 2}\Re (Hf)(w),}&lt;/math&gt;

where ''H'' is the [[singular integral operators on closed curves|Hilbert transform]] on ∂Ω. Let ''J'' denote complex conjugation. Writing ''h'' = ''f'' + ''ig'',&lt;ref&gt;{{harvnb|Shapiro|1992|pp=66–67}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{2Th =\Re(Hf) + i\Re(Hg)={1\over 2} (Hf +JHf +iHg +iJHg)={1\over 2}(H+JHJ)h}&lt;/math&gt;

so that

:&lt;math&gt;\displaystyle{T={1\over 4} (H +JHJ),}&lt;/math&gt;

The imaginary part of the Hilbert transform can be used to establish the symmetry properties of the eigenvalues of ''T''&lt;sub&gt;''K''&lt;/sub&gt;. Let

:&lt;math&gt;\displaystyle{A={1\over 2} (H+JHJ),\,\,\,\, B={1\over 2i} (H-JHJ),}&lt;/math&gt;

so that

:&lt;math&gt;\displaystyle{H=A+iB.}&lt;/math&gt;

Then

:&lt;math&gt;\displaystyle{AB=-BA,\,\,\,\,A^2-B^2 =I.}&lt;/math&gt;

The Cauchy idempotent ''E'' satisfies ''E''1 = 1 = ''E''*1. Since ''J''1 = 1, it follows that ''E'' and ''E''* leave invariant 
L&lt;sup&gt;2&lt;/sup&gt;&lt;sub&gt;0&lt;/sub&gt;(∂Ω), the functions orthogonal to constant functions. The same is also true of ''A'' = 2 ''T''&lt;sub&gt;''K''&lt;/sub&gt; and ''B''. Let ''A''&lt;sub&gt;1&lt;/sub&gt; and ''B''&lt;sub&gt;1&lt;/sub&gt; be their restrictions. Since 1 is an eigenvector of ''T''&lt;sub&gt;''K''&lt;/sub&gt; with eigenvalue 1/2 and multiplicity one and ''T''&lt;sub&gt;''K''&lt;/sub&gt; + ½ ''I'' is invertible,

:&lt;math&gt;\displaystyle{A_1^2 -I =B_1^2}&lt;/math&gt;

is invertible, so that ''B''&lt;sub&gt;1&lt;/sub&gt; is invertible. The equation ''A''&lt;sub&gt;1&lt;/sub&gt;''B''&lt;sub&gt;1&lt;/sub&gt; = − ''B''&lt;sub&gt;1&lt;/sub&gt; ''A''&lt;sub&gt;1&lt;/sub&gt; implies that if λ is an eigenvalue of ''A''&lt;sub&gt;1&lt;/sub&gt; then so is −λ and they have the same multiplicity.

==Eigenfunctions of complex Hilbert transform==
The links between the Neumann–Poincaré operator and [[geometric function theory]] appeared first in {{harvtxt|Bergman|Schiffer|1951}}. The precise relationship between single and double layer potentials, Fredholm eigenvalues and the complex Hilbert transform is explained in detail in {{harvtxt|Schiffer|1981}}. Briefly given a smooth Jordan curve, the complex derivatives of its single and double layer potentials are −1 and +1 eigenfunctions of the complex Hilbert transform.&lt;ref&gt;See also:
*{{harvnb|Schiffer|1957}}
*{{harvnb|Schiffer|2011}}
*{{harvnb|Ahlfors|1962}}
*{{harvnb|Khavinson|Putinar|Shapiro|2007}}
*{{harvnb|Burbea|1986}}
*{{harvnb|Partyka|1997}}
*{{harvnb|Krzyż|Partyka|1993}}
&lt;/ref&gt;

Let 𝕳 be the direct sum&lt;ref&gt;{{harvnb|Khavinson|Putinar|Shapiro|2007}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{\mathfrak{H}=\mathfrak{H}(\overline{\Omega})\oplus \mathfrak{H}(\overline{\Omega^c}),}&lt;/math&gt;

where the first space consists of functions smooth on the closure of Ω  and harmonic on Ω; and the second consists of functions smooth on the closure of Ω&lt;sup&gt;''c''&lt;/sup&gt;, harmonic on Ω&lt;sup&gt;''c''&lt;/sup&gt; and at ≈. The space 𝕳 is naturally an inner product space with corresponding norm given by

:&lt;math&gt;\displaystyle{\|f_-\oplus f_+\|_{\mathfrak{H}}^2=\iint_\Omega |\nabla f_-|^2 + \iint_{\Omega^c} |\nabla f_+|^2.}&lt;/math&gt;

Each element of 𝕳 can be written uniquely as the restriction of the sum of a double layer and single layer potential, provided that the moments are normalized to have 0 integral on ∂Ω. Thus for ''f''&lt;sub&gt;−&lt;/sub&gt; ⊕ ''f''&lt;sub&gt;+&lt;/sub&gt; in 𝕳, there are unique φ, ψ in C&lt;sup&gt;∞&lt;/sup&gt;(∂Ω) with integral 0 such that

:&lt;math&gt;\displaystyle{f_-=D(\varphi)|_{\Omega} + S(\psi)|_\Omega,\,\,\,\,\, f_+=D(\varphi)|_{\Omega^c} + S(\psi)|_{\Omega^c}.}&lt;/math&gt;

Under this correspondence

:&lt;math&gt;\displaystyle{\varphi=f_-|_{\partial \Omega} - f_+|_{\partial\Omega},\,\,\,\, \psi=\partial_{n}f_-|_{\partial\Omega} -\partial_{n} f_+|_{\partial\Omega}.}&lt;/math&gt;

The layer potentials can be identified with their images in 𝕳:

:&lt;math&gt;\displaystyle{D(\varphi)=D(\varphi)|_\Omega \oplus D(\varphi)|_{\Omega^c},\,\,\,\, S(\psi)=S(\psi)|_\Omega \oplus S(\psi)_{\Omega^c}.}&lt;/math&gt;

The space of double layer potentials is orthogonal to the space of single layer potentials for the inner product. In fact by Green's theorem&lt;ref&gt;{{harvnb|Schiffer|1981|p=150}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{(S,D)=\iint_{\Omega \cup \Omega^c}\nabla S\cdot \nabla D= -\int_{\partial\Omega} S\partial_n D + \int_{\partial\Omega} S\partial_n D=0.}&lt;/math&gt;

Define an isometric embedding of 𝕳&lt;sub&gt;'''R'''&lt;/sub&gt; in L&lt;sup&gt;2&lt;/sup&gt;('''C''') by

:&lt;math&gt;\displaystyle{U(f_- \oplus f_+) =(\partial_{z} f_-)\chi_\Omega + (\partial_{z} f_-)\chi_{\Omega^c}.}&lt;/math&gt;

The image lies in A&lt;sup&gt;2&lt;/sup&gt;(Ω) ⊕ A&lt;sup&gt;2&lt;/sup&gt;(Ω&lt;sup&gt;''c''&lt;/sup&gt;), the direct sum of the [[Bergman space]]s of square integrable holomorphic functions on Ω and Ω&lt;sup&gt;''c''&lt;/sup&gt;. Since polynomials in ''z'' are dense in  A&lt;sup&gt;2&lt;/sup&gt;(Ω) and polynomials in ''z''&lt;sup&gt;−1&lt;/sup&gt; without constant term are dense in A&lt;sup&gt;2&lt;/sup&gt;(Ω&lt;sup&gt;''c''&lt;/sup&gt;), the image of ''U'' is dense in A&lt;sup&gt;2&lt;/sup&gt;(Ω) ⊕ A&lt;sup&gt;2&lt;/sup&gt;(Ω&lt;sup&gt;''c''&lt;/sup&gt;).

It can be verified directly that for φ, ψ real&lt;ref&gt;See:
*{{harvnb|Schiffer|1981|pp=151–153}}
*{{harvnb|Khavinson|Putinar|Shapiro|2007|pp=167–168}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{T_c(U(D(\varphi) + S(\psi)))=U(D(\varphi)-S(\psi)).}&lt;/math&gt;

In fact for single layer potentials, applying Green's theorem on the domain  Ω ∪ Ω&lt;sup&gt;''c''&lt;/sup&gt; with a small closed disk of radius ε removed around a point ''w'' of the domain, it follows that

:&lt;math&gt;\displaystyle{\iint_{\Omega\cup\Omega^c, \,\, |z-w| &gt;\varepsilon} \nabla N(w-z) \cdot \nabla  S(\psi)(z)  \,dx\, dy=-\int_{|z-w| =\varepsilon} \partial_n N(z-w)\,S(\psi)(z)=-S(\psi)(z),}&lt;/math&gt;

since the mean of a harmonic function over a circle is its value at the centre. Using the fact that {{overline|π''z''}}&lt;sup&gt;−1&lt;/sup&gt; is the fundamental solution for ∂&lt;sub&gt;''w''&lt;/sub&gt;, this can be rewritten as

:&lt;math&gt;\displaystyle{{1\over \pi} \,\iint_{\Omega\cup\Omega^c}{\overline{\partial_z S(\psi)(z)}\over z-w}\,dx\,dy= -S(\psi)(w).}&lt;/math&gt;

Applying ∂&lt;sub&gt;''w''&lt;/sub&gt; to both sides gives

:&lt;math&gt;\displaystyle{T_c(\partial_z S(\psi)) = -\partial_z S(\psi).}&lt;/math&gt;

Similarly for a double layer potential

:&lt;math&gt; \displaystyle{\iint_{\Omega\cup\Omega^c, \,\, |z-w| &gt;\varepsilon} \nabla N(w-z) \cdot \nabla  D(\varphi)(z) \,dx\, dy=\int_{|z-w| =\varepsilon} N(z-w)\,\partial_n D(\varphi)(z)=0,}&lt;/math&gt;

since the mean of the normal derivative of a harmonic function over a circle is zero. As above, using the fact {{overline|π''z''}}&lt;sup&gt;−1&lt;/sup&gt; is the fundamental solution for ∂&lt;sub&gt;''w''&lt;/sub&gt;, this can be rewritten in terms of complex derivatives as

:&lt;math&gt;\displaystyle{{1\over \pi} \,\iint_{\Omega\cup\Omega^c}{\overline{\partial_z D(\varphi)(z)}\over z-w}\,dx\,dy= D(\varphi)(w).}&lt;/math&gt;

Applying ∂&lt;sub&gt;''w''&lt;/sub&gt; to both sides,

:&lt;math&gt;\displaystyle{T_c(\partial_z D(\varphi)) = \partial_z D(\varphi).}&lt;/math&gt;

==Connection with Hilbert transform on a domain==
Let L&lt;sup&gt;2&lt;/sup&gt;(∂Ω)&lt;sub&gt;0&lt;/sub&gt; be the closed subspace of L&lt;sup&gt;2&lt;/sup&gt;(∂Ω) orthogonal to the constant functions. Let ''P''&lt;sub&gt;0&lt;/sub&gt; the orthogonal projection onto L&lt;sup&gt;2&lt;/sup&gt;(∂Ω)&lt;sub&gt;0&lt;/sub&gt; and set

:&lt;math&gt;\displaystyle{T_{K,0}=P_0 T_K P_0.}&lt;/math&gt;

With respect to the new inner product on L&lt;sup&gt;2&lt;/sup&gt;(∂Ω)&lt;sub&gt;0&lt;/sub&gt;

:&lt;math&gt;\displaystyle{(f,g)_0=((1/2-T_K)^{-1}Sf,g)}&lt;/math&gt;

the operator ''T''&lt;sub&gt;''K'',0&lt;/sub&gt; is formally self-adjoint.

Let ''H''&lt;sub&gt;0&lt;/sub&gt; be the Hilbert space completion.

Define a unitary operator ''V'' from ''H''&lt;sub&gt;0&lt;/sub&gt; onto A&lt;sup&gt;2&lt;/sup&gt;(Ω) by

:&lt;math&gt;\displaystyle{V(\psi)=U(D(\varphi)+S(\psi))|_{\Omega},}&lt;/math&gt;

where

:&lt;math&gt;\displaystyle{({1\over 2} I-T_K)\varphi= -S\psi.}&lt;/math&gt;

Then

:&lt;math&gt;\displaystyle{VT_{K,0}V^*=T_\Omega.}&lt;/math&gt;

==Fredholm eigenfunctions==
If φ is an eigenfunction of ''T''&lt;sub&gt;''K''&lt;/sub&gt; on ∂Ω corresponding to an eigenvalue λ with |λ| &lt; 1/2, then φ is orthogonal to the constants and can be taken real-valued.&lt;ref&gt;See:
*{{harvnb|Schiffer|1957}}
*{{harvnb|Schiffer|1981}}
*{{harvnb|Khavinson|Putinar|Shapiro|2007}}&lt;/ref&gt; Let

:&lt;math&gt;\displaystyle{\Phi_-=\partial_z D(\varphi)|_\Omega \in A^2(\Omega),\,\,\, \Phi_+=\partial_z D(\varphi)|_{\Omega^c}\in A^2(\Omega^c).}&lt;/math&gt;

Since double potentials are harmonic, given as the real part of a holomorphic function,

:&lt;math&gt;\displaystyle{\Phi_{\pm}(w)={1\over 2\pi i}\int_{\partial \Omega} {\varphi(z)\over (z-w)^2} \,dz.}&lt;/math&gt;

Then

:&lt;math&gt;\displaystyle{T_\Omega \Phi_-=\lambda \Phi_-,\,\,\, T_{\Omega^c} \Phi_+=\lambda \Phi_+.}&lt;/math&gt;

Moreover

:&lt;math&gt;\displaystyle{(T_c \Phi_-)|_{\Omega^c}= (\lambda + {1\over 2})\Phi_+,\,\,\,(T_c \Phi_+)|_{\Omega}=(\lambda-{1\over 2})\Phi_-.}&lt;/math&gt;

If two eigenfunctions φ and ψ are orthogonal for the inner product defined by ''S'', then their transforms Φ&lt;sub&gt;±&lt;/sub&gt; and Ψ&lt;sub&gt;±&lt;/sub&gt; are orthogonal in A&lt;sup&gt;2&lt;/sup&gt;(Ω) and A&lt;sup&gt;2&lt;/sup&gt;(Ω&lt;sup&gt;''c''&lt;/sup&gt;).

==Eigenfunctions in Hardy space==
{{See also|Singular integral operators on closed curves}}
The Hardy space H&lt;sup&gt;2&lt;/sup&gt;(∂Ω) can be defined as the closure of the complex polynomials in ''z'' in L&lt;sup&gt;2&lt;/sup&gt;(∂Ω). The Cauchy transform of ''f'' in  H&lt;sup&gt;2&lt;/sup&gt;(∂Ω)

:&lt;math&gt;\displaystyle{F(w)={1\over 2\pi i}\int_{\partial\Omega} {f(z)\over z-w}\, dz}&lt;/math&gt;

defines a holomorphic function ''F'' in Ω such that its restrictions to the level curves ∂Ω&lt;sup&gt;''s''&lt;/sup&gt; in a tubular neighbourhood of ∂Ω have uniformly bounded L&lt;sup&gt;2&lt;/sup&gt; norms. The classical definition of Hardy space is of holomorphic functions on Ω with this property. Identifying the level curves with ∂Ω, it follows that the restrictions of ''F'' tend to ''f'' in L&lt;sup&gt;2&lt;/sup&gt; norm. Writing H&lt;sup&gt;2&lt;/sup&gt;(Ω) for the classical Hardy space, identified with H&lt;sup&gt;2&lt;/sup&gt;(∂Ω) by taking L&lt;sup&gt;2&lt;/sup&gt; boundary values, it follows that Hardy space H&lt;sup&gt;2&lt;/sup&gt;(Ω) is a dense subspace of Bergman space  A&lt;sup&gt;2&lt;/sup&gt;(Ω).

Define the conjugate Cauchy transform of ''f'' by&lt;ref&gt;{{harvnb|Krzyż|Partyka|1993}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{Cf(w)={1\over 2\pi i}\int_{\partial\Omega} {\overline{f(z)}\over z-w}\, d\overline{z}.}&lt;/math&gt;

It lies in H&lt;sup&gt;2&lt;/sup&gt;(Ω). Moreover for ''w'' in Ω

:&lt;math&gt;\displaystyle{Cf(w)=T_\Omega F(w),}&lt;/math&gt;

since by Green's theorem

:&lt;math&gt;\displaystyle{{1\over \pi}\iint_{\Omega,\,\,\,|z-w|&gt;\varepsilon} {\overline{F(z)}\over (z-w)^2} \,dx\,dy = Cf(w) -{1\over 2\pi i} \int_{|z-w|=\varepsilon} {\overline{F(z)}\over z-w}\, d\overline{z}=Cf(w).}&lt;/math&gt;

For a smooth Jordan curve ∂Ω, the Fredholm eigenfunctions of ''T''&lt;sub&gt;Ω&lt;/sub&gt; all lie in H&lt;sup&gt;2&lt;/sup&gt;(Ω).

==See also==
*[[Grunsky matrix]]

==Notes==
{{reflist|2}}

==References==
*{{citation|last=Ahlfors|first= Lars V.|authorlink=Lars Ahlfors|title=Remarks on the Neumann–Poincaré integral equation|journal=Pacific J. Math.|volume= 2|year=1952|pages =271–280|doi=10.2140/pjm.1952.2.271}}
*{{citation|last=Bergman|first= S.|authorlink=Stefan Bergman|last2=Schiffer|first2= M.|title=Kernel functions and conformal mapping|journal=[[Compositio Mathematica]]|volume= 8|year=1951| pages=205–249}}
*{{citation|first=J. |last=Blumenfeld|first2=W.|last2= Mayer|title= Über Poincaresche fundamentalfunktionen|journal= Sitz. Wien. Akad. Wiss., Math.-Nat. Klasse |volume=122|year=1914|pages= 2011–2047}}
*{{citation|last=Burbea|first= Jacob|title=Fredholm spectrum and Grunsky inequalities in general domains|journal=Studia Math.|volume= 83|year=1986|pages= 167–200}}
*{{citation|last=Folland|first= Gerald B.|authorlink=Gerald Folland|title= Introduction to partial differential equations|edition=2nd|publisher=Princeton University Press|year=1995|isbn= 0-691-04361-2}}
*{{citation|title=Integral Equations: Theory and Numerical Treatment|volume= 120|series= International Series of Numerical Mathematics|first=Wolfgang|last= Hackbusch|publisher=Springer|year= 1995|isbn=3764328711}}
*{{citation|last=Hsiao|first=George C.|last2= Wendland|first2= Wolfgang L.|title=Boundary integral equations|
series=Applied Mathematical Sciences|volume= 164|publisher= Springer-Verlag|year= 2008|isbn=978-3-540-15284-2}}
*{{citation|last=Kellogg|first= Oliver Dimon|authorlink=Oliver Dimon Kellogg|title=Foundations of potential theory|series= Die Grundlehren der Mathematischen Wissenschaften|volume=31|publisher= Springer-Verlag|year=1929}}
*{{citation|last=Khavinson|first= D.|last2= Putinar|first2= M.|last3= Shapiro|first3= H. S.|authorlink3=Harold S. Shapiro|title=Poincaré's variational problem in potential theory| journal=Arch. Ration. Mech. Anal.|volume= 185 |year=2007|pages=143–184|doi=10.1007/s00205-006-0045-1}}
*{{citation|title=Linear Integral Equations|volume= 82|series=Applied Mathematical Sciences|first=Rainer|last=Kress|
edition=2nd|publisher=Springer|year=1999|isbn=0387987002}}
*{{citation|last=Krzyż|first= Jan G.|last2= Partyka|first2= Dariusz|title= Generalized Neumann–Poincaré operator, chord-arc curves and Fredholm eigenvalues|journal= Complex Variables Theory Appl.|volume= 21|year=1993|pages= 253–263|doi=10.1080/17476939308814634}}
*{{citation|last=Landkof|first=N. S.|title= Foundations of modern potential theory|series=Die Grundlehren der mathematischen Wissenschaften|volume= 180|publisher= Springer-Verlag|year= 1972}}
*{{citation|title=Mathematical physics: an advanced course|first=S. G.|last= Mikhlin|publisher=North Holland|year= 1971}}
*{{citation|last=Partyka|first= Dariusz|title=The generalized Neumann–Poincaré operator and its spectrum|series=
Dissertationes Math|volume= 366|year=1997}}
*{{citation|last=Plemelj|first= J.|title= Potentialtheoretische Untersuchungen|publisher=Teubner|year= 1911}}
*{{citation|last=Poincaré|first= H.|authorlink=Henri Poincaré|title=La méthode de Neumann et le problème de Dirichlet|journal=Acta Math.|volume= 20|pages=59–152|year=1897|url=http://www.springerlink.com/content/k1353553t4r82u74/|doi=10.1007/bf02418028}}
*{{citation|title=Periodic Integral and Pseudodifferential Equations with Numerical Approximation|first=Jukka|last= Saranen|first2= Gennadi|last2= Vainikko|publisher=Springer|year= 2001|isbn=3540418784}}
*{{citation|last=Schiffer|first=M.|title=The Fredholm eigenvalues of plane domains|journal=Pacific J. Math.|volume= 7|year= 1957|pages= 1187–1225|doi=10.2140/pjm.1957.7.1187}}
*{{citation|last=Schiffer|first= M.|title=Fredholm eigenvalues of multiply connected domains|journal=Pacific J. Math.|volume= 9|year= 1959|pages= 211–269|doi=10.2140/pjm.1959.9.211}}
*{{citation|last=Schiffer|first= M.|last2= Hawley|first2= N. S.|title=Connections and conformal mapping|journal=Acta Math.|volume= 107 |year=1962|pages= 175–274|doi=10.1007/bf02545790}}
*{{citation|last=Schiffer|first= M.|title=Fredholm eigenvalues and Grunsky matrices|journal=Ann. Polon. Math.|volume= 39|year= 1981|pages= 149–164}}
*{{citation|series=Autovalori e autosoluzioni, C.I.M.E. Summer Schools|year=2011|volume= 27| pages=203–234|title=
Fredholm Eigenvalues and Conformal Mapping|publisher=Springer|last=Schiffer|first=Menahem}}
*{{citation|last=Shapiro|first=H. S.|authorlink=Harold S. Shapiro|title=The Schwarz function and its generalization to higher dimensions|series=
University of Arkansas Lecture Notes in the Mathematical Sciences|volume= 9|publisher= Wiley-Interscience|year= 1992|isbn=0-471-57127-X}} 
*{{citation|last=Taylor|first= Michael E.|authorlink=Michael E. Taylor|title= Partial differential equations II: Qualitative studies of linear equations|edition=2nd|series=Applied Mathematical Sciences|volume= 116|publisher=Springer|year=2011|isbn= 978-1-4419-7051-0}}

{{DEFAULTSORT:Neumann-Poincare operator}}
[[Category:Potential theory]]
[[Category:Partial differential equations]]
[[Category:Complex analysis]]
[[Category:Operator theory]]</text>
      <sha1>8eb7w7krum7fii5p4u6o9ipnswrzb28</sha1>
    </revision>
  </page>
  <page>
    <title>Neuroinformatics</title>
    <ns>0</ns>
    <id>3062721</id>
    <revision>
      <id>870960323</id>
      <parentid>864920859</parentid>
      <timestamp>2018-11-28T01:49:04Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: pages. Add: title. Converted bare reference to cite template. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Bioinformatics]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37140">{{for|the scientific journal|Neuroinformatics (journal)}}
{{multiple issues|
{{cleanup list|article|date=April 2009}}
{{more footnotes|date=April 2009}}
}}
'''Neuroinformatics''' is a research field concerned with the organization of [[neuroscience]] data by the application of computational models and analytical tools. These areas of research are important for the integration and analysis of increasingly large-volume, high-dimensional, and fine-grain experimental data.  Neuroinformaticians provide computational tools, mathematical models, and create interoperable databases for clinicians and research scientists. Neuroscience is a heterogeneous field, consisting of many and various sub-disciplines (e.g., [[cognitive psychology]], [[behavioral neuroscience]], and [[behavioral genetics]]). In order for our understanding of the brain to continue to deepen, it is necessary that these sub-disciplines are able to share data and findings in a meaningful way; Neuroinformaticians facilitate this.&lt;ref&gt;{{Cite journal 
| last1 = Adee | first1 = Sally
| title = Reverse engineering the brain
| doi = 10.1109/MSPEC.2008.4531462
| journal = [[IEEE Spectrum]]
| volume = 45
| issue = 6
| pages = 51–55
| date=June 2008
| url = http://spectrum.ieee.org/biomedical/ethics/reverse-engineering-the-brain/0
}}&lt;/ref&gt;

Neuroinformatics stands at the intersection of [[neuroscience]] and [[information science]]. Other fields, like [[genomics]], have demonstrated the effectiveness of freely distributed databases and the  application of theoretical and computational models for solving complex problems. In Neuroinformatics, such facilities allow researchers to more easily quantitatively confirm their working theories by computational modeling.  Additionally, neuroinformatics fosters collaborative research—an important fact that facilitates the field's interest in studying the multi-level complexity of the brain.

There are three main directions where neuroinformatics has to be applied:&lt;ref&gt;{{cite web|title=INCF Strategy Overview|url=http://www.incf.org/documents/incf-core-documents/INCFStrategyOverview}}&lt;/ref&gt;

# the development of tools and databases for management and sharing of neuroscience data at all levels of analysis,
# the development of tools for analyzing and modeling neuroscience data,
# the development of computational models of the [[nervous system]] and neural processes.

In the recent decade, as vast amounts of diverse data about the brain were gathered by many research groups, the problem was raised of how to integrate the data from thousands of publications in order to enable efficient tools for further research. The biological and neuroscience data are highly interconnected and complex, and by itself, integration represents a great challenge for scientists.

Combining [[Informatics (academic field)|informatics]] research and [[brain]] research provides benefits for both fields of science. On one hand, informatics facilitates brain [[data processing]] and data handling, by providing new electronic and software technologies for arranging [[database]]s, modeling and communication in brain research. On the other hand, enhanced discoveries in the field of neuroscience will invoke the development of new methods in [[information technologies]] (IT).

==History==
Starting in 1989, the United States [[National Institute of Mental Health]] (NIMH), the [[National Institute of Drug Abuse]] (NIDA) and the [[National Science Foundation]] (NSF) provided the  National Academy of Sciences [[Institute of Medicine]] with funds to undertake a careful analysis and study of the need to create databases, share neuroscientific data and to examine how the field of information technology could create the tools needed for the increasing volume and modalities of neuroscientific data. {{Citation needed|date=May 2009}} The positive recommendations were reported in 1991.&lt;ref&gt;{{cite report |date=1991 |title=Mapping the Brain and Its Functions: Integrating Enabling Technologies into Neuroscience Research |type=Consensus study report |publisher=[[National Academy Press]] |location=Washington, DC |editor1-last=Pechura |editor1-first=Constance M. |editor2-last=Martin |editor2-first=Joseph B. |isbn=978-0-309-04497-4 |doi=10.17226/1816 |doi-access=free |url=https://www.nap.edu/catalog/1816/mapping-the-brain-and-its-functions-integrating-enabling-technologies-into }}&lt;/ref&gt; This positive report enabled NIMH, now directed by Allan Leshner, to create the "Human Brain Project" (HBP), with the first grants awarded in 1993. The HBP was led by Koslow along with cooperative efforts of other [[NIH]] Institutes, the NSF, the [[National Aeronautics and Space Administration]] and the [[United States Department of Energy|Department of Energy]]. The HPG{{Expand acronym|date=September 2017}} and grant-funding initiative in this area slightly preceded the explosive expansion of the World Wide Web. From 1993 through 2004 this program grew to over 100 million dollars in funded grants.

Next, Koslow pursued the globalization of the HPG and neuroinformatics through the [[European Union]] and the [[Office for Economic Co-operation and Development]] (OECD), Paris, France. Two particular opportunities occurred in 1996.

* The first was the existence of the US/European Commission Biotechnology Task force co-chaired by Mary Clutter from NSF. Within the mandate of this committee, of which Koslow was a member the United States European Commission Committee on Neuroinformatics was established and co-chaired by Koslow from the United States. This committee resulted in the European Commission initiating support for neuroinformatics in Framework 5 and it has continued to support activities in neuroinformatics research and training.
* A second opportunity for globalization of neuroinformatics occurred when the participating governments of the Mega Science Forum (MSF) of the OECD were asked if they had any new scientific initiatives to bring forward for scientific cooperation around the globe. The [[White House Office of Science and Technology Policy]] requested that agencies in the federal government meet at NIH to decide if cooperation were needed that would be of global benefit. The NIH held a series of meetings in which proposals from different agencies were discussed. The proposal recommendation from the U.S. for the MSF was a combination of the NSF and NIH proposals. Jim Edwards of NSF supported databases and data-sharing in the area of biodiversity; Koslow proposed the HPG as a model for sharing neuroscientific data, with the new moniker of ''neuroinformatics''.

The two related initiates were combined to form the United States proposal on "Biological Informatics". This initiative was supported by the [[White House Office of Science and Technology Policy]] and presented at the OECD MSF by Edwards and Koslow. An MSF committee was established on Biological Informatics with two subcommittees: 1. Biodiversity (Chair, James Edwards, NSF), and 2. Neuroinformatics (Chair, Stephen Koslow, NIH). At the end of two years the Neuroinformatics subcommittee of the Biological Working Group issued a report supporting a global neuroinformatics effort. Koslow, working with the NIH and the White House Office of Science and Technology Policy to establishing a new Neuroinformatics working group to develop specific recommendation to support the more general recommendations of the first report. The Global Science Forum (GSF; renamed from MSF) of the OECD supported this recommendation.

===The International Neuroinformatics Coordinating Facility===
{{Main|International Neuroinformatics Coordinating Facility}}
{{Unreferenced section|date=September 2017}}
This committee presented 3 recommendations to the member governments of GSF. These recommendations were:

# National neuroinformatics programs should be continued or initiated in each country should have a national node to both provide research resources nationally and to serve as the contact for national and international coordination.
# An [[International Neuroinformatics Coordinating Facility]] (INCF) should be established. The INCF will coordinate the implementation of a global neuroinformatics network through integration of national neuroinformatics nodes.
# A new international funding scheme should be established. This scheme should eliminate national and disciplinary barriers and provide a most efficient approach to global collaborative research and data sharing. In this new scheme, each country will be expected to fund the participating researchers from their country.

The GSF neuroinformatics committee then developed a business plan for the operation, support and establishment of the INCF which was supported and approved by the GSF Science Ministers at its 2004 meeting. In 2006 the INCF was created and its central office established and set into operation at the Karolinska Institute, Stockholm, Sweden under the leadership of [[Sten Grillner]]. Sixteen countries (Australia, Canada, China, the Czech Republic, Denmark, Finland, France, Germany, India, Italy, Japan, the Netherlands, Norway, Sweden, Switzerland, the United Kingdom and the United States), and the EU Commission established the legal basis for the INCF and Programme in International Neuroinformatics (PIN). To date, eighteen countries (Australia, Belgium, Czech Republic, Finland, France, Germany, India, Italy, Japan, Malaysia, Netherlands, Norway, Poland, Republic of Korea, Sweden, Switzerland, the United Kingdom and the United States) are members of the INCF. Membership is pending for several other countries.

The goal of the INCF is to coordinate and promote international activities in neuroinformatics. The INCF contributes to the development and maintenance of database and computational infrastructure and support mechanisms for neuroscience applications. The system is expected to provide access to all freely accessible human brain data and resources to the international research community. The more general task of INCF is to provide conditions for developing convenient and flexible applications for neuroscience laboratories in order to improve our knowledge about the human brain and its disorders.

===Society for Neuroscience Brain Information Group===
On the foundation of all of these activities, Huda Akil, the 2003 President of the [[Society for Neuroscience]] (SfN) established the Brain Information Group (BIG) to evaluate the importance of neuroinformatics to neuroscience and specifically to the SfN. Following the report from BIG, SfN also established a neuroinformatics committee.

In 2004, SfN announced the Neuroscience Database Gateway (NDG) as a universal resource for neuroscientists through which almost any neuroscience databases and tools may be reached. The NDG was established with funding from NIDA, NINDS and NIMH. The Neuroscience Database Gateway has transitioned to a new enhanced platform, the [[Neuroscience Information Framework]].&lt;ref&gt;http://www.neuinfo.org{{dead link|date=February 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; Funded by the NIH Neuroscience BLueprint, the NIF is a dynamic portal providing access to neuroscience-relevant resources (data, tools, materials) from a single search interface. The NIF builds upon the foundation of the NDG, but provides a unique set of tools tailored especially for neuroscientists: a more expansive catalog, the ability to search multiple databases directly from the NIF home page, a custom web index of neuroscience resources, and a neuroscience-focused literature search function.

==Collaboration with other disciplines==
{{Unreferenced section|date=September 2017}}
Neuroinformatics is formed at the intersections of the following fields:
{{columns-list|colwidth=22em|
* [[neuroscience]]
* [[computer science]]
* [[biology]]
* [[experimental psychology]]
* [[medicine]]
* [[engineering]]
* [[physical sciences]]
* [[mathematics]]
* [[chemistry]]
}}
Biology is concerned with molecular data (from genes to cell specific expression); medicine and anatomy with the structure of synapses and systems level anatomy; engineering – [[electrophysiology]] (from single channels to scalp surface EEG), brain imaging; computer science – databases, software tools, mathematical sciences – models, chemistry – [[neurotransmitter]]s, etc.  Neuroscience uses all aforementioned experimental and theoretical studies to learn about the brain through its various levels. Medical and biological specialists help to identify the unique cell types, and their elements and anatomical connections. Functions of complex organic molecules and structures, including a myriad of biochemical, molecular, and genetic mechanisms which regulate and control brain function, are determined by specialists in chemistry and cell biology. Brain imaging determines structural and functional information during mental and behavioral activity. Specialists in [[biophysics]] and physiology study physical processes within neural cells neuronal networks. The data from these fields of research is analyzed and arranged in databases and neural models in order to integrate various elements into a sophisticated system; this is the point where neuroinformatics meets other disciplines.

Neuroscience provides the following types of data and information on which neuroinformatics operates: 
* Molecular and cellular data ([[ion channel]], [[action potential]], genetics, cytology of neurons, [[protein pathway]]s),
* Data from organs and systems ([[visual cortex]], [[perception]], audition, [[sensory system]], pain, taste, [[motor system]], [[spinal cord]]),
* [[Cognitive]] data (language, emotion, [[motor learning]], [[sexual behavior]], [[decision making]], [[social neuroscience]]),
* Developmental information ([[neuronal differentiation]], cell survival, [[synaptic formation]], motor differentiation, injury and regeneration, axon guidance, [[growth factor]]s),
* Information about diseases and aging (autonomic nervous system, depression, anxiety, Parkinson's disease, addiction, [[memory loss]]),
* Neural engineering data ([[brain-computer interface]]), and
* Computational neuroscience data (computational models of various neuronal systems, from membrane currents, proteins to learning and memory).

Neuroinformatics uses databases, the Internet, and visualization in the storage and analysis of the mentioned neuroscience data.

==Research programs and groups==

=== Australia ===
; Neuroimaging &amp; Neuroinformatics, Howard Florey Institute, University of Melbourne
: Institute scientists utilize brain imaging techniques, such as magnetic resonance imaging, to reveal the organization of brain networks involved in human thought. Led by Gary Egan.

=== Canada ===
; [http://mcin-cnim.ca/ McGill Centre for Integrative Neuroscience (MCIN)], Montreal Neurological Institute, McGill University
: Led by Alan Evans, MCIN conducts computationally-intensive brain research using innovative mathematical and statistical approaches to integrate clinical, psychological and brain imaging data with genetics.  MCIN researchers and staff also develop infrastructure and software tools in the areas of image processing, databasing, and high performance computing.  The MCIN community, together with the [http://ludmercentre.ca Ludmer Centre for Neuroinformatics and Mental Health], collaborates with a broad range of researchers and increasingly focuses on open data sharing and open science, including for the Montreal Neurological Institute.

=== Denmark ===
; The THOR Center for Neuroinformatics
: Established April 1998 at the Department of Mathematical Modelling, Technical University of Denmark. Besides pursuing independent research goals, the THOR Center hosts a number of related projects concerning neural networks, functional neuroimaging, multimedia signal processing, and biomedical signal processing.

=== Germany ===
; The Neuroinformatics Portal Pilot
: The project is part of a larger effort to enhance the exchange of neuroscience data, data-analysis tools, and modeling software. The portal is supported from many members of the OECD Working Group on Neuroinformatics. The Portal Pilot is promoted by the German Ministry for Science and Education.
; Computational Neuroscience, ITB, Humboldt-University Berlin
: This group focuses on computational neurobiology, in particular on the dynamics and signal processing capabilities of systems with [[spiking neuron]]s. Led by Andreas VM Herz.
; The Neuroinformatics Group in Bielefeld
: Active in the field of Artificial Neural Networks since 1989. Current research programmes within the group are focused on the improvement of man-machine-interfaces, robot-force-control, eye-tracking experiments, machine vision, virtual reality and distributed systems.

=== Italy ===
; Laboratory of Computational Embodied Neuroscience (LOCEN)&lt;ref&gt;{{cite web|url=http://www.istc.cnr.it/group/locen|title=Laboratory of Computational Embodied Neuroscience - Institute of Cognitive Sciences and Technologies|author=|date=|website=www.istc.cnr.it|accessdate=2 April 2018}}&lt;/ref&gt;
: This group, part of the Institute of Cognitive Sciences and Technologies, Italian National Research Council (ISTC-CNR) in Rome and founded in 2006 is currently led by Gianluca Baldassarre. It has two objectives: (a) understanding the brain mechanisms underlying learning and expression of sensorimotor behaviour, and related motivations and higher-level cognition grounded on it, on the basis of embodied computational models; (b) transferring the acquired knowledge to building innovative controllers for autonomous humanoid robots capable of learning in an open-ended fashion on the basis of intrinsic and extrinsic motivations.

=== Japan ===
; Japan national neuroinformatics resource
: The Visiome Platform is the Neuroinformatics Search Service that provides access to mathematical models, experimental data, analysis libraries and related resources. An online portal for neurophysiological data sharing is also available at [http://brainliner.jp BrainLiner.jp] as part of the [[Ministry of Education, Culture, Sports, Science and Technology|MEXT]] Strategic Research Program for Brain Sciences (SRPBS).
; Laboratory for Mathematical Neuroscience, [[RIKEN Brain Science Institute]] (Wako, Saitama)
: The target of Laboratory for Mathematical Neuroscience is to establish mathematical foundations of brain-style computations toward construction of a new type of information science. Led by Shun-ichi Amari.

=== The Netherlands ===
; Netherlands state program in neuroinformatics
: Started in the light of the international OECD Global Science Forum which aim is to create a worldwide program in Neuroinformatics.

=== Pakistan ===
; NUST-SEECS Neuroinformatics Research Lab&lt;ref&gt;{{cite web|url=http://neuro.seecs.nust.edu.pk/|title=Neuro-Informatics Lab @ SEECS, NUST - School of Electrical Engineering &amp; Computer Sciences, National University of Sciences &amp; Technology|author=|date=|website=neuro.seecs.nust.edu.pk|accessdate=2 April 2018}}&lt;/ref&gt;
: Establishment of the Neuro-Informatics Lab at SEECS-NUST has enabled Pakistani researchers and members of the faculty to actively participate in such efforts, thereby becoming an active part of the above-mentioned experimentation, simulation, and visualization processes. The lab collaborates with the leading international institutions to develop highly skilled human resource in the related field. This lab facilitates neuroscientists and computer scientists in Pakistan to conduct their experiments and analysis on the data collected using state of the art research methodologies without investing in establishing the experimental neuroscience facilities. The key goal of this lab is to provide state of the art experimental and simulation facilities, to all beneficiaries including higher education institutes, medical researchers/practitioners, and technology industry.

=== Switzerland ===
; The Blue Brain Project
: The [[Blue Brain]] Project was founded in May 2005, and uses an 8000 processor [[Blue Gene]]/L supercomputer developed by IBM.  At the time, this was one of the fastest supercomputers in the world.
:The project involves:
:* '''Databases''': 3D reconstructed model neurons, synapses, synaptic pathways, microcircuit statistics, computer model neurons, virtual neurons.
:* '''Visualization''': microcircuit builder and simulation results visualizator, 2D, 3D and immersive visualization systems are being developed.
:* '''Simulation''': a simulation environment for large-scale simulations of morphologically complex neurons on 8000 processors of IBM's Blue Gene supercomputer.
:* '''Simulations and experiments''': iterations between large-scale simulations of neocortical microcircuits and experiments in order to verify the computational model and explore predictions.
: The mission of the Blue Brain Project is to understand mammalian brain function and dysfunction through detailed simulations. The Blue Brain Project will invite researchers to build their own models of different brain regions in different species and at different levels of detail using Blue Brain Software for simulation on Blue Gene. These models will be deposited in an internet database from which Blue Brain software can extract and connect models together to build brain regions and begin the first whole brain simulations.
; The Institute of Neuroinformatics (INI)
: Established at the University of Zurich at the end of 1995, the mission of the Institute is to discover the key principles by which brains work and to implement these in artificial systems that interact intelligently with the real world.

=== United Kingdom ===
; [[Genes to Cognition Project]]
: A neuroscience research programme that studies genes, the brain and behaviour in an integrated manner. It is engaged in a large-scale investigation of the function of molecules found at the synapse. This is mainly focused on proteins that interact with the NMDA receptor, a receptor for the neurotransmitter, glutamate, which is required for processes of synaptic plasticity such as long-term potentiation (LTP). Many of the techniques used are high-throughout in nature, and integrating the various data sources, along with guiding the experiments has raised numerous informatics questions. The program is primarily run by Professor [[Seth Grant]] at the [[Wellcome Trust]] [[Sanger Institute]], but there are many other teams of collaborators across the world.
; The CARMEN project&lt;ref&gt;{{cite web|url=http://www.carmen.org.uk/|title=Welcome to CARMEN|author=|date=|website=Welcome to CARMEN|accessdate=2 April 2018}}&lt;/ref&gt;
: The CARMEN project is a multi-site (11 universities in the United Kingdom) research project aimed at using [[GRID computing]] to enable experimental neuroscientists  to archive their datasets in a structured database, making them widely accessible for further research, and for modellers and algorithm developers to exploit.
; EBI Computational Neurobiology, EMBL-EBI (Hinxton)
: The main goal of the group is to build realistic models of neuronal function at various levels, from the synapse to the micro-circuit, based on the precise knowledge of molecule functions and interactions (Systems Biology). Led by Nicolas Le Novère.

=== United States ===
; Neuroscience Information Framework
: The [[Neuroscience Information Framework]] (NIF) is an initiative of the [[NIH Blueprint for Neuroscience Research]], which was established in 2004 by the [[National Institutes of Health]]. Unlike general [[search engine]]s, NIF provides deeper access to a more focused set of resources that are relevant to neuroscience, search strategies tailored to neuroscience, and access to content that is traditionally "hidden" from [[web search engine]]s.  The NIF is a dynamic inventory of neuroscience databases, annotated and integrated with a unified system of biomedical terminology (i.e. [[NeuroLex]]). NIF supports concept-based queries across multiple scales of biological structure and multiple levels of biological function, making it easier to search for and understand the results. NIF will  also provide a registry through which resources providers can disclose availability of resources relevant to neuroscience research. NIF is not intended to be a warehouse or repository itself, but a means for disclosing and locating resources elsewhere available via the [[World Wide Web|web]].
; Neurogenetics GeneNetwork
: [[Genenetwork]] started as component of the NIH Human Brain Project in 1999 with a focus on the genetic analysis of brain structure and function. This international program consists of tightly integrated genome and phenome data sets for human, mouse, and rat that are designed specifically for large-scale systems and network studies relating gene variants to differences in mRNA and protein expression and to differences in CNS structure and behavior. The great majority of data are open access. GeneNetwork has a companion neuroimaging web site—the Mouse Brain Library—that contains high resolution images for thousands of genetically defined strains of mice.
; The Neuronal Time Series Analysis (NTSA)&lt;ref&gt;{{cite web |title=NTSA Workbench |url=http://soma.npa.uiuc.edu/ntsa/ |publisher=University of Illinois Urbana-Champaign |archive-date=21 July 2006 |archive-url=https://web.archive.org/web/20060721115355/http://soma.npa.uiuc.edu/ntsa/ }}&lt;/ref&gt;
: NTSA Workbench is a set of tools, techniques and standards designed to meet the needs of neuroscientists who work with neuronal time series data. The goal of this project is to develop information system that will make the storage, organization, retrieval, analysis and sharing of experimental and simulated neuronal data easier. The ultimate aim is to develop a set of tools, techniques and standards in order to satisfy the needs of neuroscientists who work with neuronal data.
; The Cognitive Atlas&lt;ref&gt;{{cite web|url=http://www.cognitiveatlas.org/|title=Cognitive Atlas|author=|date=|website=www.cognitiveatlas.org|accessdate=2 April 2018}}&lt;/ref&gt;
: The Cognitive Atlas is a project developing a shared knowledge base in cognitive science and neuroscience. This comprises two basic kinds of knowledge: tasks and concepts, providing definitions and properties thereof, and also relationships between them. An important feature of the site is ability to cite literature for assertions (e.g. "The Stroop task measures executive control") and to discuss their validity. It contributes to [[NeuroLex]] and the [[Neuroscience Information Framework]], allows programmatic access to the database, and is built around [[semantic web]] technologies.
; Brain Big Data research group at the Allen Institute for Brain Science (Seattle, WA)
: Led by Hanchuan Peng,&lt;ref&gt;{{cite web|url=http://home.penglab.com|title=Hanchuan Peng's Homepage|author=|date=|website=home.penglab.com|accessdate=2 April 2018}}&lt;/ref&gt; this group has focused on using large-scale imaging computing and data analysis techniques to reconstruct single neuron models and mapping them in brains of different animals.

==Technologies and developments==
The main technological tendencies in neuroinformatics are:

# Application of computer science for building databases, tools, and networks in neuroscience;
# Analysis and modeling of neuronal systems.
In order to organize and operate with neural data scientists need to use the standard terminology and atlases that precisely describe the brain structures and their relationships.

* [[Neuron tracing|Neuron Tracing and Reconstruction]] is an essential technique to establish digital models of the morphology of neurons. Such morphology is useful for neuron classification and simulation. 
* '''BrainML'''&lt;ref&gt;{{Cite web | url=http://www.brainml.org | title=BrainML Model Repository}}&lt;/ref&gt; is a system that provides a standard XML metaformat for exchanging neuroscience data. 
* The '''[[Biomedical Informatics Research Network]]''' (BIRN)&lt;ref&gt;{{cite web |url=http://www.birncommunity.org/ |title=Archived copy |accessdate=2010-05-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20100529202813/http://www.birncommunity.org/ |archivedate=2010-05-29 |df= }}&lt;/ref&gt; is an example of a [[grid computing|grid system]] for neuroscience. BIRN is a geographically distributed virtual community of shared resources offering vast scope of services to advance the diagnosis and treatment of disease. BIRN allows combining databases, interfaces and tools into a single environment.
* '''[[Budapest Reference Connectome]]''' is a web-based 3D visualization tool to browse connections in the human brain. Nodes, and connections are calculated from the [[MRI]] datasets of the [[Human Connectome Project]].
* '''GeneWays'''&lt;ref&gt;http://anya.igsb.anl.gov/Geneways/GeneWays.html{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; is concerned with cellular morphology and circuits. GeneWays is a system for automatically extracting, analyzing, visualizing and integrating molecular pathway data from the research literature. The system focuses on interactions between molecular substances and actions, providing a graphical view on the collected information and allows researchers to review and correct the integrated information.
* '''Neocortical Microcircuit Database''' (NMDB).&lt;ref&gt;[[Henry Markram]], X. Luo, G. Silberberg, M. Toledo-Rodriguez and A. Gupta. The Neocortical Microcircuit Database (NMDB), in ''Databasing the Brain: From Data to Knowledge (Neuroinformatics)'', p. 327-342, 2005.&lt;/ref&gt; A database of versatile brain's data from cells to complex structures. Researchers are able not only to add data to the database but also to acquire and edit one.
* '''SenseLab'''.&lt;ref&gt;{{cite web|url=http://senselab.med.yale.edu/|title=SenseLab: Home|author=|date=|website=senselab.med.yale.edu|accessdate=2 April 2018}}&lt;/ref&gt; SenseLab is a long-term effort to build integrated, multidisciplinary models of neurons and neural systems. It was founded in 1993 as part of the original [[Human Brain Project]].  A collection of multilevel neuronal databases and tools. SenseLab contains six related databases that support experimental and theoretical research on the membrane properties that mediate information processing in nerve cells, using the olfactory pathway as a model system.
* '''BrainMaps.org'''&lt;ref&gt;{{cite web|url=http://brainmaps.org/|title=BRAINMAPS.ORG - BRAIN ATLAS, BRAIN MAPS, BRAIN STRUCTURE,         NEUROINFORMATICS, BRAIN, STEREOTAXIC ATLAS, NEUROSCIENCE|first=UC|last=Davis|date=|website=brainmaps.org|accessdate=2 April 2018}}&lt;/ref&gt; is an interactive high-resolution digital [[brain atlas]] using a high-speed database and virtual microscope that is based on over 12 million megapixels of scanned images of several species, including human.
Another approach in the area of the [[brain map]]pings is the probabilistic atlases obtained from the real data from different group of people, formed by specific factors, like age, gender, diseased etc. Provides more flexible tools for brain research and allow obtaining more reliable and precise results, which cannot be achieved with the help of traditional brain atlases.

==See also==
{{columns-list|colwidth=22em|
* [[Outline of the human brain]]
* [[Outline of brain mapping]]
* [[List of neuroscience databases]]
* [[Brain simulation]]
* [[Computational neuroscience]]
* [[Computational anatomy]]
* [[Systems neuroscience]]
* [[Vision science]]
* [[Brain-reading]]
* [[Human Brain Project]]
* [[Connectogram]]
* [[Neuroethology]]
}}

==Notes and references==
{{Reflist|30em}}

==Bibliography==
{{refbegin}}
* {{Cite journal |last=Adee |first=Sally |date=June 2008 |title=Reverse Engineering the Brain |journal=IEEE Spectrum |volume=45 |issue=6 |pages=51–53 |doi=10.1109/MSPEC.2008.4531462 |subscription=yes }}
* {{cite web |date=2006 |website=Society for neuroscience |title=Annual Report FY2006: Navigating a changing landscape |url=http://www.sfn.org/~/media/SfN/Documents/Annual%20Reports/2006_annual_report.ashx |format=PDF }}
* {{cite book |editor1-last=Arbib |editor1-first=Michael A. |editor2-last=Grethe |editor2-first=Jeffrey S. |date=2001 |title=Computing the Brain, A Guide to Neuroinformatics |publisher=Academic Press |location=San Diego, CA |isbn=978-0-12-059781-9 |oclc=162129478 }}
* {{cite journal |last1=Ascoli |first1=Giorgio A. |last2=De Schutter |first2=Erik |last3=Kennedy |first3=David N. |title=An information science infrastructure for neuroscience |journal=Neuroinformatics |volume=1 |issue=1 |pages=001–002 |date=March 2003 |pmid=15055390 |doi=10.1385/NI:1:1:001 |subscription=yes }}
* {{cite journal |last1=Beltrame |first1=F. |last2=Koslow |first2=S.H. |title=Neuroinformatics as a megascience issue |journal=IEEE Transactions on Information Technology in Biomedicine |volume=3 |issue=3 |pages=239–40 |date=September 1999 |pmid=10719488 |doi=10.1109/4233.788587 |subscription=yes }}
* {{Cite journal |last1=Gardner |first1=Daniel |last2=Shepherd |first2=Gordon M. |author2-link=Gordon M Shepherd (neuroscientist) |date=September 2004 |title=A gateway to the future of Neuroinformatics |journal=[[Neuroinformatics (journal)|Neuroinformatics]] |volume=2 |issue=3 |pages=271–274 |doi=10.1385/NI:2:3:271 |pmid=15365191 |subscription=yes }}
* {{cite book |editor1-last=Koslow |editor1-first=Stephen H. |editor2-last=Huerta |editor2-first=Michael F. |date=1997 |title=Neuroinformatics: An overview of the Human Brain Project |series=Progress in neuroinformatics research |publisher=L. Erlbaum |location=Mahwah, NJ |isbn=978-0-8058-2099-7 |oclc=34958678 }}
* {{Cite book |editor1-last=Koslow |editor1-first=Steven H. |editor2-last=Subramaniam |editor2-first=Shankar |date=2005 | title=Databasing the Brain: From Data to Knowledge |series=Neuroinformatics |publisher=Wiley-Liss |location=Hoboken, NJ |isbn=978-0-471-30921-5 |oclc=60194822 }}
* {{Cite web |title=Strategy Overview 2008–2010 |date=8 July 2008 |website=INCF |publisher=International Neuroinformatics Coordinating Facility |url=https://files.incf.org/dl/y7FLrWCmVh }}
{{refend}}

==Further reading==
===Books===
{{refbegin}}
* {{cite book |editor-last=Ascoli |editor-first=Giorgio |date=2002 |title=Computational Neuroanatomy: Principles and Methods |publisher=Humana |location=Totowa, NJ |isbn=978-1-58829-000-7 |oclc=48399178 }}
* {{cite book |editor-last=Crasto |editor-first=Chiquito Joaquim |date=2007 |title=Neuroinformatics |series=Methods in Molecular Biology |volume=401 |publisher=Humana |location=Totowa, NJ |isbn=978-1-58829-720-4 |oclc=123798711 }}
* {{cite book |editor1-last=Koslow |editor1-first=Stephen H. |editor2-last=Huerta |editor2-first=Michael F. |date=2000 |title=Electronic Collaboration in Science |series=Progress in Neuroinformatics Research |volume=2 |isbn=978-1-138-00318-7 |oclc=47009543 }}
* {{cite book |last=Kötter |first=Rolf |date=2003 |title=Neuroscience Databases: A Practical Guide |publisher=Springer |location=Boston, MA |isbn=978-1-4615-1079-6 |oclc=840283587 }}
* {{cite book |last1=Mitra |first1=Partha P. |last2=Bokil |first2=Hemant |date=2008 |title=Observed Brain Dynamics |publisher=Oxford University Press |location=Oxford |isbn=978-0-19-517808-1 |oclc=213446303 }}
* {{cite book |editor1-last=Shortliffe |editor1-first=Edward H. |editor1-link=Edward H. Shortliffe |editor2-last=Cimino |editor2-first=James J. |editor2-link=James J. Cimino |date=2013 |title=Biomedical Informatics: Computer Applications in Health Care and Biomedicine |edition=4th |series=Health Informatics |publisher=Springer |location=New York |isbn=978-1-4471-4474-8 |oclc=937648601 }}
* {{cite book |last1=Sterratt |first1=David |last2=Graham |first2=Bruce |last3=Gillies |first3=Andrew |last4=Willshaw |first4=David |date=2011 |title=Principles of Computational Modeling in Neuroscience |publisher=Cambridge University Press |location=Cambridge |isbn=978-1-139-04255-0 |oclc=739098279 }}
{{refend}}

===Journals===
{{columns-list|colwidth=30em|
* ''[http://www.springerlink.com/content/100465/ Biological Cybernetics]''
* ''[https://www.springer.com/computer/ai/journal/40708 Brain Informatics]''
* ''[http://frontiersin.org/neuroinformatics Frontiers in Neuroinformatics]''
* ''[[Interdisciplinary Description of Complex Systems]]''
* ''[http://www.springerlink.com/content/100282/ Journal of Computational Neuroscience]''
* ''[[Journal of Integrative Neuroscience]]''
* ''[[The Journal of Neuroscience|Journal of Neuroscience]]''
* ''[[Journal of Web Semantics]]''
* ''[[Neural Computation (journal)|Neural Computation]]''
* ''Neural Information Processing'' (In [[Springer Science+Business Media|Springer]]'s ''[[Lecture Notes in Computer Science]]'')
* ''[[Neuroinformatics (journal)|Neuroinformatics]]''
* ''[[Neuron (journal)|Neuron]]''
* ''[[PLOS Computational Biology|PLoS Computational Biology]]''
* ''[[Science (journal)|Science]]''
}}

{{Neuroscience}}
{{Emerging technologies}}
{{Portal bar|Neuroscience}}

[[Category:Neuroinformatics| ]]
[[Category:Computational neuroscience]]
[[Category:Emerging technologies]]
[[Category:Bioinformatics]]
[[Category:Computational fields of study]]</text>
      <sha1>s2k6ogxddy9sucfenu89enmjcnoqok8</sha1>
    </revision>
  </page>
  <page>
    <title>Nørlund–Rice integral</title>
    <ns>0</ns>
    <id>3856935</id>
    <revision>
      <id>847048321</id>
      <parentid>827955252</parentid>
      <timestamp>2018-06-22T15:22:56Z</timestamp>
      <contributor>
        <username>Casaleggg</username>
        <id>32965622</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4574">In [[mathematics]], the '''Nørlund–Rice integral''', sometimes called '''Rice's method''', relates the ''n''th [[forward difference]] of a function to a [[line integral]] on the [[complex plane]].  As such, it commonly appears in the theory of [[finite differences]], and also has been applied in [[computer science]] and [[graph theory]] to estimate [[binary tree]] lengths. It is named in honour of [[Niels Erik Nørlund]] and [[Stephen O. Rice]]. Nørlund's contribution was to define the integral; Rice's contribution was to demonstrate its utility by applying [[Method of steepest descent|saddle-point technique]]s to its evaluation.

==Definition==
The ''n''th [[forward difference]] of a function ''f''(''x'') is given by

:&lt;math&gt;\Delta^n[f](x)= \sum_{k=0}^n {n \choose k} (-1)^{n-k} f(x+k)&lt;/math&gt;

where &lt;math&gt;{n \choose k}&lt;/math&gt; is the [[binomial coefficient]].

The Nörlund–Rice integral is given by

:&lt;math&gt;\sum_{k=\alpha}^n {n \choose k} (-1)^{n-k} f(k) = 
\frac{n!}{2\pi i}
\oint_\gamma \frac{f(z)}{z(z-1)(z-2)\cdots(z-n)}\, dz&lt;/math&gt;

where ''f'' is understood to be [[meromorphic]], α is an integer, &lt;math&gt;0\leq \alpha \leq n&lt;/math&gt;, and the contour of integration is understood to circle the [[pole (complex analysis)|poles]] located at the integers α, ..., ''n'', but encircles neither integers 0, ..., &lt;math&gt;\alpha-1&lt;/math&gt; nor any of the poles of ''f''.  The integral may also be written as

:&lt;math&gt;\sum_{k=\alpha}^n {n \choose k} (-1)^{k} f(k) = 
-\frac{1}{2\pi i}
\oint_\gamma B(n+1, -z) f(z)\, dz&lt;/math&gt;

where ''B''(''a'',''b'') is the Euler [[beta function]].  If the function &lt;math&gt;f(z)&lt;/math&gt; is [[polynomially bounded]] on the right hand side of the complex plane, then the contour may be extended to infinity on the right hand side, allowing the transform to be written as

:&lt;math&gt;\sum_{k=\alpha}^n {n \choose k} (-1)^{n-k} f(k) = 
\frac{-n!}{2\pi i}
\int_{c-i\infty}^{c+i\infty} \frac{f(z)}{z(z-1)(z-2)\cdots(z-n)}\, dz&lt;/math&gt;

where the constant ''c'' is to the left of α.

==Poisson–Mellin–Newton cycle==
The Poisson–Mellin–Newton cycle, noted by Flajolet et al. in 1985, is the observation that the resemblance of the Nørlund–Rice integral to the [[Mellin transform]] is not accidental, but is related by means of the [[binomial transform]] and the [[Newton series]].  In this cycle, let &lt;math&gt;\{f_n\}&lt;/math&gt; be a [[sequence]], and let ''g''(''t'') be the corresponding [[Poisson generating function]], that is, let

:&lt;math&gt;g(t) = e^{-t} \sum_{n=0}^\infty f_n t^n.&lt;/math&gt;

Taking its Mellin transform

:&lt;math&gt;\phi(s)=\int_0^\infty g(t) t^{s-1}\, dt,&lt;/math&gt;

one can then regain the original sequence by means of the Nörlund–Rice integral:

:&lt;math&gt;f_n = \frac{(-1)^n }{2\pi i}
\int_\gamma
\frac {\phi(s)}{\Gamma(-s)} \frac{n!}{s(s-1)\cdots (s-n)}\, ds&lt;/math&gt;

where Γ is the [[gamma function]].

==Riesz mean==
A closely related integral frequently occurs in the discussion of [[Riesz mean]]s. Very roughly, it can be said to be related to the Nörlund–Rice integral in the same way that [[Perron's formula]] is related to the Mellin transform: rather than dealing with infinite series, it deals with finite series.

==Utility==
The integral representation for these types of series is interesting because the integral can often be evaluated using [[asymptotic expansion]] or [[Method of steepest descent|saddle-point]] techniques; by contrast, the forward difference series can be extremely hard to evaluate numerically, because the binomial coefficients grow rapidly for large ''n''.

==See also==
* [[Table of Newtonian series]]
* [[List of factorial and binomial topics]]

==References==
* Niels Erik Nørlund, ''Vorlesungen uber Differenzenrechnung'', (1954) Chelsea Publishing Company, New York.
* Donald E. Knuth, ''[[The Art of Computer Programming]]'', (1973), Vol. 3 Addison-Wesley.
* Philippe Flajolet and Robert Sedgewick, "[https://www.sciencedirect.com/science/article/pii/030439759400281M Mellin transforms and asymptotics: Finite differences and Rice's integrals]{{dead link|date=February 2018 |bot=InternetArchiveBot |fix-attempted=yes }}",  ''Theoretical Computer Science'' '''144''' (1995) pp 101–124.
* Peter Kirschenhofer, "[http://www.combinatorics.org/ojs/index.php/eljc/article/view/v3i2r7/pdf]", ''[http://www.combinatorics.org The Electronic Journal of Combinatorics]'', Volume '''3''' (1996) Issue 2 Article 7.

{{DEFAULTSORT:Norlund-Rice integral}}
[[Category:Factorial and binomial topics]]
[[Category:Complex analysis]]
[[Category:Integral transforms]]
[[Category:Finite differences]]</text>
      <sha1>cfdyysjb1tonqg146nb44fcqapfxxx4</sha1>
    </revision>
  </page>
  <page>
    <title>One-class classification</title>
    <ns>0</ns>
    <id>20420396</id>
    <revision>
      <id>866033381</id>
      <parentid>846599506</parentid>
      <timestamp>2018-10-27T20:52:26Z</timestamp>
      <contributor>
        <ip>139.179.242.21</ip>
      </contributor>
      <comment>there exists one-class methods which utilise both positive and negative samples for training</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5408">In [[machine learning]], '''one-class classification''', also known as '''unary classification''' or '''class-modelling''', tries to ''identify'' objects of a specific class amongst all objects, by primarily learning from a [[training set]] containing only the objects of that class&lt;ref&gt;{{Cite journal|last=Oliveri|first=Paolo|title=Class-modelling in food analytical chemistry: Development, sampling, optimisation and validation issues – A tutorial|url=http://linkinghub.elsevier.com/retrieve/pii/S0003267017306050|journal=Analytica Chimica Acta|volume=982|pages=9–19|doi=10.1016/j.aca.2017.05.013}}&lt;/ref&gt;, although there exist variants of one-class classifiers where counter-examples are used to further refine the classification boundary. This is different from and more difficult than the traditional [[classification (machine learning)|classification]] problem, which tries to ''distinguish between'' two or more classes with the training set containing objects from all the classes. An example is the classification of the operational status of a nuclear plant as 'normal':&lt;ref&gt;[http://homepage.tudelft.nl/n9d04/thesis.pdf Tax, D. (2001) One-class classification: Concept-learning in the absence of counter-examples. Doctoral Dissertation, University of Delft, The Netherlands.]&lt;/ref&gt; In this scenario, there are few, if any, examples of catastrophic system states; only the statistics of normal operation are known. The term '''one-class classification''' was coined by Moya &amp; Hush (1996)&lt;ref&gt;Moya, M. and Hush, D. (1996). "Network constraints and multi- objective optimization for one-class classification". ''Neural Networks'', 9(3):463–474. {{doi|10.1016/0893-6080(95)00120-4}}&lt;/ref&gt; and many applications can be found in scientific literature, for example [[outlier detection]], [[anomaly detection]], [[novelty detection]]. A feature of one-class classification is that it uses only sample points from the assigned class, so that a representative sampling is not strictly required for non-target classes.&lt;ref&gt;{{Cite journal|last=Rodionova|first=Oxana Ye|last2=Oliveri|first2=Paolo|last3=Pomerantsev|first3=Alexey L.|date=2016-12-15|title=Rigorous and compliant approaches to one-class classification|url=http://www.sciencedirect.com/science/article/pii/S0169743916302799|journal=Chemometrics and Intelligent Laboratory Systems|volume=159|pages=89–96|doi=10.1016/j.chemolab.2016.10.002}}&lt;/ref&gt; 

While many of the above approaches focus on the case of removing a small number of outliers or anomalies, one can also learn the other extreme, where the single class covers a small coherent subset of the data, using an [[Information bottleneck method|information bottleneck]] approach.&lt;ref&gt;{{Cite journal|last=Crammer|first=Koby|date=2004|title=A needle in a haystack: local one-class optimization|url=https://dl.acm.org/citation.cfm?id=1015399|journal=ICML Proceedings of the twenty-first international conference on Machine learning|volume=|pages=26|via=}}&lt;/ref&gt;

==PU learning==
A similar problem is '''PU learning''', in which a [[binary classification|binary classifier]] is learned in a [[semi-supervised learning|semi-supervised]] way from only ''positive'' and ''unlabeled'' sample points.&lt;ref&gt;{{cite book|title=Web Data Mining|last=Liu|first=Bing|publisher=Springer|year=2007|pages=165−178}}&lt;/ref&gt;

In PU learning, two sets of examples are assumed to be available for training: the positive set &lt;math&gt;P&lt;/math&gt; and a ''mixed set'' &lt;math&gt;U&lt;/math&gt;, which is assumed to contain both positive and negative samples, but without these being labeled as such. This contrasts with other forms of semisupervised learning, where it is assumed that a labeled set containing examples of both classes is available in addition to unlabeled samples. A variety of techniques exist to adapt [[supervised learning|supervised]] classifiers to the PU learning setting, including variants of the [[Expectation-maximization|EM algorithm]]. PU learning has been successfully applied to [[text classification|text]],&lt;ref&gt;{{cite conference |author=Bing Liu |author2=Wee Sun Lee |author3=Philip S. Yu |author3-link=Philip S. Yu |author4=Xiao-Li Li |last-author-amp=yes |year=2002 |title=Partially supervised classification of text documents |conference=ICML |pages=8–12}}&lt;/ref&gt;&lt;ref&gt;{{cite conference |author=Hwanjo Yu |author2=Jiawei Han |author3=Kevin Chen-Chuan Chang |title=PEBL: positive example based learning for web page classification using SVM |conference=ACM SIGKDD |year=2002}}&lt;/ref&gt;&lt;ref&gt;{{cite conference |author=Xiao-Li Li |author2=Bing Liu |last-author-amp=yes |title=Learning to classify text using positive and unlabeled data |conference=IJCAI |year=2003}}&lt;/ref&gt; time series,&lt;ref&gt;{{cite conference |author=Minh Nhut Nguyen |author2=Xiao-Li Li |author3=See-Kiong Ng |last-author-amp=yes |title=Positive Unlabeled Learning for Time Series Classification |conference=IJCAI |year=2011}}&lt;/ref&gt; and [[bioinformatics]] tasks.&lt;ref&gt;{{cite conference |author=Peng Yang |author2=Xiao-Li Li |author3=Jian-Ping Mei |author4=Chee-Keong Kwoh |author5=See-Kiong Ng |last-author-amp=yes |title=Positive-Unlabeled Learning for Disease Gene Identification |conference=Bioinformatics, Vol 28(20)|year=2012}}&lt;/ref&gt;

==See also==
*[[Multiclass classification]]

==References==
{{reflist|30em}}

[[Category:Statistical classification]]
[[Category:Classification algorithms]]


{{compu-AI-stub}}
{{statistics-stub}}</text>
      <sha1>30gosmlt67paebdhfbkrvx9t9gv5nx4</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial Wigner–Ville distribution</title>
    <ns>0</ns>
    <id>45116986</id>
    <revision>
      <id>868945590</id>
      <parentid>866177587</parentid>
      <timestamp>2018-11-15T12:09:05Z</timestamp>
      <contributor>
        <username>R06942045</username>
        <id>35117292</id>
      </contributor>
      <comment>Add Design of a Practical Polynomial Kernel</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6449">{{More citations needed|date=August 2015}}
In signal processing, the '''polynomial Wigner–Ville distribution''' is a [[quasiprobability distribution]] that generalizes the [[Wigner distribution function]]. It was proposed by Boualem Boashash and Peter O'Shea in 1994.

== Introduction ==

Many signals in nature and in engineering applications can be modeled as &lt;math&gt;z(t)=e^{j2\pi\phi(t)}&lt;/math&gt;, where &lt;math&gt;\phi(t)&lt;/math&gt; is a polynomial phase and &lt;math&gt;j=\sqrt{-1}&lt;/math&gt;.

For example, it is important to detect signals of an arbitrary high-order polynomial phase. However, the conventional Wigner–Ville distribution have the limitation being based on the second-order statistics. Hence, the polynomial Wigner–Ville distribution was proposed as a generalized form of the conventional Wigner–Ville distribution, which is able to deal with signals with nonlinear phase.

== Definition ==

The polynomial Wigner–Ville distribution &lt;math&gt;W^g_z(t, f)&lt;/math&gt; is defined as

:&lt;math&gt; W^g_z(t, f)=\mathcal{F}_{\tau\to f}\left[K^g_z(t, \tau)\right] &lt;/math&gt;

where &lt;math&gt;\mathcal{F}_{\tau\to f}&lt;/math&gt; denotes the [[Fourier transform]] with respect to &lt;math&gt;\tau&lt;/math&gt;, and &lt;math&gt;K^g_z(t, \tau)&lt;/math&gt; is the polynomial kernel given by

:&lt;math&gt; K^g_z(t, \tau)=\prod_{k=-\frac{q}{2}}^{\frac{q}{2}} \left[z\left(t+c_k\tau\right)\right]^{b_k} &lt;/math&gt;

where &lt;math&gt;z(t)&lt;/math&gt; is the input signal and &lt;math&gt;q&lt;/math&gt; is an even number.
The above expression for the kernel may be rewritten in symmetric form as

:&lt;math&gt; K^g_z(t, \tau)=\prod_{k=0}^{\frac{q}{2}} \left[z\left(t+c_k\tau\right)\right]^{b_k}\left[z^*\left(t+c_{-k}\tau\right)\right]^{-b_{-k}} &lt;/math&gt;

The discrete-time version of the polynomial Wigner–Ville distribution is given by the [[discrete Fourier transform]] of

:&lt;math&gt; K^g_z(n, m)=\prod_{k=0}^{\frac{q}{2}} \left[z\left(n+c_{k}m\right)\right]^{b_k}\left[z^*\left(n+c_{-k}m\right)\right]^{-b_{-k}} &lt;/math&gt;

where &lt;math&gt;n=t{f}_s, m={\tau}{f}_{s},&lt;/math&gt; and &lt;math&gt;f_s&lt;/math&gt; is the sampling frequency.
The conventional [[Wigner distribution function|Wigner–Ville distribution]] is a special case of the polynomial Wigner–Ville distribution with &lt;math&gt;q=2, b_{-1}=-1, b_1=1, b_0=0, c_{-1}=-\frac{1}{2}, c_0=0, c_1=\frac{1}{2} &lt;/math&gt;

== Example ==

One of the simplest generalizations of the usual Wigner–Ville distribution kernel can be achieved by taking &lt;math&gt;q=4&lt;/math&gt;. The set of coefficients &lt;math&gt;b_k&lt;/math&gt; and &lt;math&gt;c_k&lt;/math&gt; must be found to completely specify the new kernel. For example, we set

:&lt;math&gt; b_1=-b_{-1}=2, b_2=b_{-2}=1, b_0=0 &lt;/math&gt;
:&lt;math&gt; c_1=-c_{-1}=0.675, c_2=-c_{-2}=-0.85&lt;/math&gt;

The resulting discrete-time kernel is then given by

:&lt;math&gt; K^g_z(n, m)=\left[z\left(n+0.675m\right)z^*\left(n-0.675m\right)\right]^2z^*\left(n+0.85m\right)z\left(n-0.85m\right) &lt;/math&gt;

=== Design of a Practical Polynomial Kernel ===
Given a signal &lt;math&gt;z(t)=e^{j2\pi\phi(t)}&lt;/math&gt;, where &lt;math&gt;\phi(t)=\sum_{i=0}^p a_i t^i&lt;/math&gt;is a polynomial function, its instantaneous frequency (IF) is &lt;math&gt;\phi'(t) = \sum_{i=1}^p ia_it^{i-1}&lt;/math&gt;.

For a practical polynomial kernel &lt;math&gt;K^g_z(t, \tau)&lt;/math&gt;, the set of coefficients &lt;math&gt;q, b_k&lt;/math&gt;and &lt;math&gt;c_k&lt;/math&gt;should be chosen properly such that&lt;blockquote&gt;&lt;math&gt;\begin{align}
K^g_z(t, \tau) &amp;=\prod_{k=0}^{\frac{q}{2}} \left[z\left(t+c_k\tau\right)\right]^{b_k}\left[z^*\left(t+c_{-k}\tau\right)\right]^{-b_{-k}}\\
&amp;= \exp(j2\pi \sum_{i=1}^pia_it^{i-1}\tau)
\end{align}&lt;/math&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;\begin{align}
W_z^g(t,f) &amp;= \int_{-\infin}^{\infin} \exp(-j2\pi(f - \sum_{i=1}^p i a_i t^{i-1}) \tau)d\tau\\
&amp;\cong \delta (f - \sum_{i=1}^p i a_i t^{i-1})
\end{align}&lt;/math&gt;&lt;/blockquote&gt;

* When &lt;math&gt;q=2, b_{-1}=-1, b_0=0, b_1=1, p=2&lt;/math&gt;,

&lt;blockquote&gt;&lt;math&gt;z\left(t+c_1\tau\right)z^*\left(t+c_{-1}\tau\right)=\exp(j2\pi \sum_{i=1}^2 i a_i t^{i-1}\tau)&lt;/math&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;a_2(t+c_1)^2 + a_1(t+c_1) - a_2(t + c_{-1})^2 - a_1(t + c_{-1}) = 2a_2t\tau + a_1\tau&lt;/math&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;\Rightarrow c_1 - c_{-1} = 1, c_1 + c_{-1} = 0&lt;/math&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;\Rightarrow c_1=\frac{1}{2}, c_{-1}=-\frac{1}{2}&lt;/math&gt;&lt;/blockquote&gt;

* When &lt;math&gt;q=4, b_{-2}=b_{-1}=-1, b_0=0, b_2=b_1=1, p=3&lt;/math&gt;

&lt;blockquote&gt;&lt;math&gt;\begin{align}
&amp;a_3(t + c_1)^3 + a_2(t+c_1)^2 + a_1(t+c_1) \\
&amp;a_3(t + c_2)^3 + a_2(t+c_2)^2 + a_1(t+c_2) \\
&amp;- a_3(t + c_{-1})^3 - a_2(t + c_{-1})^2 - a_1(t + c_{-1}) \\
&amp;- a_3(t + c_{-2})^3 - a_2(t + c_{-2})^2 - a_1(t + c_{-2}) \\
&amp;= 3a_3t^2\tau + 2a_2t\tau + a_1\tau
\end{align}&lt;/math&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;math&gt;\Rightarrow 
\begin{cases} 
c_1 + c_2 - c_{-1} - c_{-2} = 1 \\ 
c_1^2 + c_2^2 - c_{-1}^2 - c_{-2}^2 = 0 \\ 
c_1^3 + c_2^3 - c_{-1}^3 - c_{-2}^3 = 0 
\end{cases}&lt;/math&gt;&lt;/blockquote&gt;

== Applications ==

Nonlinear FM signals are common both in nature and in engineering applications. For example, the sonar system of some bats use hyperbolic FM and quadratic FM signals for echo location. In radar, certain pulse-compression schemes employ linear FM and quadratic signals. The [[Wigner distribution function|Wigner–Ville distribution]] has optimal concentration in the time-frequency plane for linear [[Frequency modulation|frequency modulated]] signals. However, for nonlinear frequency modulated signals, optimal concentration is not obtained, and smeared spectral representations result. The polynomial Wigner–Ville distribution can be designed to cope with such problem.

== References ==

1. B. Boashash and P. O’Shea, “Polynomial Wigner–Ville distributions and their relationship to time varying high order spectra,”IEEE Trans. Signal Process., vol. 42, pp. 216–220, Jan. 1994.&lt;br /&gt;
2. M. Benidir and B. Boashash, “On the polynomial Wigner–Ville dis-tribution,” in Proc. SPIE, June 1995, San Diego, CA, vol. 2563, pp.&amp;nbsp;69–79.&lt;br /&gt;
3. “Polynomial Wigner–Ville distributions and time-varying higher spectra,” in Proc. Time-Freq. Time-Scale Anal., Victoria, B.C., Canada, Oct. 1992, pp.&amp;nbsp;31–34.

4. Jian-Jiun Ding, Time frequency analysis and wavelet transform class notes, the Department of Electrical Engineering, National Taiwan University (NTU), Taipei, Taiwan, 2018.

{{DEFAULTSORT:Polynomial Wigner-Ville distribution}}
[[Category:Quantum mechanics]]
[[Category:Continuous distributions]]
[[Category:Concepts in physics]]
[[Category:Mathematical physics]]
[[Category:Exotic probabilities]]
[[Category:Polynomials]]</text>
      <sha1>tjvnkn8peq2nuww3w14h7dmbyu73o6t</sha1>
    </revision>
  </page>
  <page>
    <title>Pythagorean means</title>
    <ns>0</ns>
    <id>3314539</id>
    <revision>
      <id>871347388</id>
      <parentid>871346984</parentid>
      <timestamp>2018-11-30T13:11:23Z</timestamp>
      <contributor>
        <username>Dominic3203</username>
        <id>27983238</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4033">[[Image:MathematicalMeans.svg|thumb|right|A geometric construction of the quadratic mean and the Pythagorean means (of two numbers ''a'' and ''b''). Harmonic mean denoted by {{colorbox|purple}}{{nbsp}}''H'', geometric by {{colorbox|blue}}{{nbsp}}''G'', arithmetic by {{colorbox|red}}{{nbsp}}''A'' and quadratic mean (also known as [[root mean square]]) denoted by {{colorbox|green}}{{nbsp}}''Q''.]]
[[Image:Comparison_Pythagorean_means.svg|thumb|right|Comparison of the arithmetic, geometric and harmonic means of a pair of numbers. The vertical dashed lines are [[asymptote]]s for the harmonic means.]]
In mathematics, the three classical '''[[Pythagoreanism|Pythagorean]] [[Mean|means]]''' are the [[arithmetic mean]] (''AM''), the [[geometric mean]] (''GM''), and the [[harmonic mean]] (''HM''). These means were studied with proportions by [[Pythagoreans]] and later generations of Greek mathematicians&lt;ref&gt;{{cite book|first=Thomas|last=Heath|title=History of Ancient Greek Mathematics}}&lt;/ref&gt; because of their importance in geometry and music.

==Definition==
They are defined by:

:&lt;math&gt;\begin{align}
  \operatorname{AM} \left( x_1,\; \ldots,\; x_n \right) &amp;= \frac{1}{n} \left(x_1 + \;\cdots\; + x_n\right) \\[9pt]
  \operatorname{GM} \left( x_1,\; \ldots,\; x_n \right) &amp;= \sqrt[n]{\left\vert x_1 \times \,\cdots\, \times x_n \right\vert} \\[9pt]
  \operatorname{HM} \left( x_1,\; \ldots,\; x_n \right) &amp;= \frac{n}{\displaystyle \frac{1}{x_1} + \;\cdots\; + \frac{1}{x_n}} 
\end{align}&lt;/math&gt;

==Properties==
Each mean, &lt;math display="inline"&gt;\operatorname{M}&lt;/math&gt;, has the following properties:
; Value preservation: &lt;math&gt;\operatorname{M}(x, x,\, \ldots,\, x) = x&lt;/math&gt;
; First order [[homogeneous function|homogeneity]]: &lt;math&gt;\operatorname{M}(bx_1,\, \ldots,\, bx_n) = b \operatorname{M}(x_1,\, \ldots,\, x_n)&lt;/math&gt;
; Invariance under exchange: &lt;math&gt;\operatorname{M}(\ldots,\, x_i,\, \ldots,\, x_j,\, \ldots) = \operatorname{M}(\ldots,\, x_j,\, \ldots,\, x_i,\, \ldots)&lt;/math&gt;
: for any &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;.
; Averaging: &lt;math&gt;\min(x_1,\, \ldots,\, x_n) \leq \operatorname{M}(x_1,\, \ldots,\, x_n) \leq \max(x_1,\, \ldots,\, x_n)&lt;/math&gt;

The harmonic and arithmetic means are reciprocal duals of each other for positive arguments:
: &lt;math&gt;\operatorname{HM}\left(\frac{1}{x_1},\, \ldots,\, \frac{1}{x_n}\right) = \frac{1}{\operatorname{AM}\left(x_1,\, \ldots,\, x_n\right)}&lt;/math&gt;

while the geometric mean is its own reciprocal dual:
: &lt;math&gt;\operatorname{GM}\left(\frac{1}{x_1},\, \ldots,\, \frac{1}{x_n}\right) = \frac{1}{\operatorname{GM}\left(x_1,\, \ldots,\, x_n\right)}&lt;/math&gt;

== Inequalities among means ==
There is an ordering to these means (if all of the &lt;math&gt; x_i &lt;/math&gt; are positive)
: &lt;math&gt;\min \leq \operatorname{HM} \leq \operatorname{GM} \leq \operatorname{AM} \leq \max&lt;/math&gt;
with equality holding if and only if the &lt;math&gt;x_i&lt;/math&gt; are all equal. 

This is a generalization of the [[inequality of arithmetic and geometric means]] and a special case of an inequality for [[generalized mean]]s.  The proof follows from the [[inequality of arithmetic and geometric means|arithmetic-geometric mean inequality]], &lt;math&gt;\operatorname{AM} \leq \max&lt;/math&gt;, and reciprocal duality (&lt;math&gt;\min&lt;/math&gt; and &lt;math&gt;\max&lt;/math&gt; are also reciprocal dual to each other).

The study of the Pythagorean means is closely related to the study of [[majorization]] and [[Schur-convex function|Schur-convex functions]]. The harmonic and geometric means are concave symmetric functions of their arguments, and hence Schur-concave, while the arithmetic mean is a linear function of its arguments, so both concave and convex.

==See also==
* [[Arithmetic-geometric mean]]
* [[Average]]
* [[Generalized mean]]

==References==

{{reflist}}

==External links==
*{{MathWorld|urlname=PythagoreanMeans|title=Pythagorean Means|author=Cantrell, David W.}}
* Nice comparison of Pythagorean means with emphasis on the [http://www.cse.unsw.edu.au/~teachadmin/info/harmonic3.html harmonic mean].

[[Category:Means]]</text>
      <sha1>hb24zq2nw5gsaudq62ckyva0xiln9w2</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum spacetime</title>
    <ns>0</ns>
    <id>24593105</id>
    <revision>
      <id>866319822</id>
      <parentid>864286844</parentid>
      <timestamp>2018-10-29T17:09:13Z</timestamp>
      <contributor>
        <ip>144.212.3.4</ip>
      </contributor>
      <comment>/* Heisenberg model spacetimes */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21290">{{longintro|date=October 2018}}
{{morefootnotes|date=October 2018}}
In [[mathematical physics]], the concept of '''quantum spacetime''' is a generalization of the usual concept of [[spacetime]] in which some variables that ordinarily [[Commutative property|commute]] are assumed not to commute and form a different [[Lie algebra]].  The choice of that algebra still varies from theory to theory.
As a result of this change some variables that are usually continuous may become discrete.
Often only such discrete variables are called "quantized"; usage varies.
The idea of quantum spacetime was proposed in the early days of quantum theory by [[Werner Heisenberg|Heisenberg]] and [[Ivanenko]]
as a way to eliminate infinities from quantum field theory.
The germ of the idea passed from Heisenberg to [[Rudolf Peierls]], who noted that electrons in a magnetic field
can be regarded as moving in a quantum space-time, and to [[Robert Oppenheimer]], who carried it
to [[Hartland Snyder]],
who published the first concrete example.&lt;ref&gt;{{citation| first=H. |last=Snyder| title=Quantized space-time| journal=Physical Review|volume= 67 |year=1947| pages= 38–41|doi=10.1103/PhysRev.71.38|bibcode=1947PhRv...71...38S}}&lt;/ref&gt;
Snyder's [[Lie algebra]] was made simple by [[C. N. Yang]] in the same year.

Physical reasons have been given to believe that physical spacetime is a quantum spacetime.
In [[quantum mechanics]] position and momentum variables &lt;math&gt;x,p&lt;/math&gt; are already [[noncommutative]], obey the [[Heisenberg uncertainty principle]], and are continuous.
Because of the Heisenberg uncertainty relations, greater energy is needed to probe smaller distances.
Ultimately, according to gravity theory, the probing particles form [[black holes]] that destroy what was to be measured. The process cannot be repeated, so it cannot be counted as a measurement.
This limited measurability led many to expect that our usual picture of continuous commutative spacetime breaks down at [[Planck scale]] distances, if not sooner.

Again, physical spacetime is expected to be quantum because physical coordinates are already slightly noncommutative.
The astronomical coordinates of a star are modified by gravitational fields between us and the star, as in the deflection of light by the sun, one of the classic tests of [[general relativity]].
Therefore, the coordinates actually depend on gravitational field variables.
According to quantum theories of gravity these field variables do not commute;
therefore coordinates that depend on them likely do not commute.

Both arguments are based on pure gravity and quantum theory, and they limit the measurement of time
by the only time constant in pure [[quantum gravity]], the [[Planck time]].
Our instruments, however, are not purely gravitational but are made of particles. They may set a more severe, larger, limit than the Planck time.

Quantum spacetimes are often described mathematically using the [[noncommutative geometry]] of Connes,
[[quantum geometry]], or [[quantum groups]].

Any noncommutative algebra with at least four generators could be interpreted as a quantum spacetime, but
the following desiderata have been suggested:
* Local [[Lorentz group]] and [[Poincaré group]] symmetries should be retained, possibly in a generalised form. Their generalisation often takes the form of a [[quantum group]] acting on the quantum spacetime algebra.
* The  algebra might plausibly arise in an effective description of quantum gravity effects in some regime of that theory. For example, a physical parameter &lt;math&gt;\lambda&lt;/math&gt;, perhaps the [[Planck length]], might control the deviation from commutative classical spacetime, so that ordinary Lorentzian spacetime arises as &lt;math&gt;\lambda\to 0&lt;/math&gt;.
* There might be a notion of [[quantum differential calculus]] on the quantum spacetime algebra, compatible with the (quantum) symmetry and preferably reducing to the usual differential calculus as &lt;math&gt;\lambda\to 0&lt;/math&gt;.
This would permit wave equations for particles and fields and facilitate predictions for experimental deviations from classical spacetime physics that can then be tested experimentally.
* The Lie algebra should be [[semisimple]].&lt;ref&gt;Yang, I. E. Segal 1947&lt;/ref&gt; This makes it easier to formulate a finite theory.

Several models were found in the 1990s more or less meeting most of the above criteria.

== Bicrossproduct model spacetime ==
The bicrossproduct model spacetime was introduced by Shahn Majid and Henri Ruegg&lt;ref&gt;{{citation| doi=10.1016/0370-2693(94)90699-8| first1=S. | last1=Majid| first2= H. |last2=Ruegg|title= Bicrossproduct structure of the &lt;math&gt;\kappa&lt;/math&gt;-Poincaré group and noncommutative geometry| journal=Physics Letters B| volume=334| issue=3–4| pages=348–354|year=1994|arxiv = hep-th/9405107 |bibcode = 1994PhLB..334..348M }}&lt;/ref&gt; and has Lie algebra relations

: &lt;math&gt; [x_i,x_j]=0,\quad [x_i, t]=i \lambda x_i &lt;/math&gt;

for the spatial variables &lt;math&gt;x_i&lt;/math&gt; and the time variable &lt;math&gt;t&lt;/math&gt;. Here &lt;math&gt;\lambda&lt;/math&gt; has dimensions of time and is therefore expected to be something like the Planck time. The Poincaré group here is  correspondingly deformed, now to a certain bicrossproduct quantum group  with the following characteristic features.

[[File:2dhyp.png|right|framed|Orbits for the action of the Lorentz group on momentum space in the construction of the bicrossproduct model in units of &lt;math&gt;\lambda^{-1}&lt;/math&gt;. Mass-shell hyperboloids are `squashed' into a cylinder.]]

The momentum generators &lt;math&gt;p_i&lt;/math&gt; commute among themselves but addition of momenta, reflected in the quantum group structure, is deformed (momentum space becomes a [[non-abelian group]]). Meanwhile, the Lorentz group generators enjoy their usual relations among themselves but act non-linearly on the momentum space. The orbits for this action are depicted in the figure as a cross-section of &lt;math&gt;p_0&lt;/math&gt; against one of the &lt;math&gt;p_i&lt;/math&gt;. The  on-shell region describing particles in the upper center of the image would normally be hyperboloids but these are now `squashed' into the cylinder

: &lt;math&gt;\sqrt{p_1^2+p_2^2+p_3^2}&lt; \lambda^{-1} \, &lt;/math&gt;

in simplified units.  The upshot is that Lorentz-boosting a momentum will never increase it above the Planck momentum. The existence of a highest momentum scale or lowest distance scale fits the physical picture. This squashing comes from the non-linearity of the Lorentz boost and is an endemic feature of bicrossproduct quantum groups known since their introduction in 1988.&lt;ref&gt;{{citation|doi=10.1088/0264-9381/5/12/010|first=Shahn|last=Majid|title=Hopf algebras for physics at the Planck scale|year=1988|journal=Classical and Quantum Gravity|volume= 5|issue=12|pages=1587–1607|bibcode = 1988CQGra...5.1587M }}&lt;/ref&gt; Some physicists dub the bicrossproduct model [[doubly special relativity]], since it sets an upper limit to both speed and momentum.

Another consequence of the squashing is that the propagation of particles is deformed, even of light, leading to a [[variable speed of light]]. This prediction requires the particular &lt;math&gt;p_0,p_i&lt;/math&gt; to be the physical energy and spatial momentum (as opposed to some other function of them). Arguments for this identification were provided in 1999 by [[Giovanni Amelino-Camelia]] and Majid&lt;ref&gt;{{citation| first1=G.|last1= Amelino-Camelia|first2=S.| last2=Majid|title=Waves on noncommutative spacetime and gamma-ray bursts| journal=International Journal of Modern Physics A| volume=15 |issue= 27|year=2000|pages=4301–4323| doi=10.1142/s0217751x00002779|arxiv=hep-th/9907110|bibcode=2000IJMPA..15.4301A}}&lt;/ref&gt; through a study of plane waves for a quantum differential calculus in the model. They take the form

: &lt;math&gt;e^{i \sum_ip_ix_i} e^{i p_0 t} \, &lt;/math&gt;

in other words a form which is sufficiently close to classical that one might plausibly believe the interpretation. At the moment such wave analysis represents the best hope to obtain physically testable predictions from the model.

Prior to this work there were a number of unsupported claims to make predictions from the model based solely on the form of the Poincaré quantum group. There were also claims based on an earlier &lt;math&gt;\kappa&lt;/math&gt;-Poincaré quantum group introduced by Jurek  Lukierski and co-workers&lt;ref&gt;{{citation|first1=J|last1=Lukierski|first2=A|last2=Nowicki |first3=H|last3=Ruegg|first4=V.N.|last4=Tolstoy|title=&lt;math&gt;q&lt;/math&gt;-Deformation of Poincaré algebras|year=1991|journal=Physics Letters B| volume=264|issue=3–4| pages=331–338|doi=10.1016/0370-2693(91)90358-w |bibcode=1991PhLB..264..331L}}&lt;/ref&gt; which should be viewed as an important precursor to the bicrossproduct one, albeit without the actual quantum spacetime and with different proposed generators for which the above picture does not apply. The bicrossproduct model spacetime has also been called &lt;math&gt;\kappa&lt;/math&gt;-deformed spacetime with &lt;math&gt;\kappa=\lambda^{-1}&lt;/math&gt;.

== ''q''-Deformed spacetime ==
This model was introduced independently by a team&lt;ref&gt;{{citation|doi=10.1007/BF01565619|first1=U.|last1=Carow-Watamura|first2=M.|last2=Schlieker|first3=M.|last3=Scholl| first4=S.|last4=Watamura|title=Tensor representation of the quantum group &lt;math&gt;SL_q(2,\Bbb C)&lt;/math&gt; and quantum Minkowski space|journal=Zeitschrift für Physik C|volume=48|issue=1|pages=159|year=1990}}&lt;/ref&gt; working under [[Julius Wess]] in 1990 and by Majid{{who|date=September 2017}} and coworkers in a series of papers on braided matrices starting a year later.&lt;ref&gt;{{citation|doi=10.1063/1.529485|first=S.|last= Majid|title=Examples of braided groups and braided matrices|journal= Journal of Mathematical Physics|volume= 32|issue=12|year=1991|pages=3246–3253|bibcode = 1991JMP....32.3246M }}&lt;/ref&gt; The  point of view in the second approach is that usual Minkowski spacetime has a nice description via [[Pauli matrices]] as the space of 2 x 2 hermitian matrices. In quantum group theory and using [[braided monoidal category]] methods one has a natural q-version of this defined here for real values of &lt;math&gt;q&lt;/math&gt; as a `braided hermitian matrix' of generators and relations

: &lt;math&gt; \begin{pmatrix}\alpha &amp; \beta\\ \gamma &amp;\delta\end{pmatrix}=\begin{pmatrix}\alpha &amp; \beta\\ \gamma &amp;\delta\end{pmatrix}^\dagger,\quad \beta\alpha=q^2\alpha\beta,\  [\alpha,\delta]=0,\ [\beta,\gamma]=(1-q^{-2})\alpha(\delta-\alpha),\ [\delta,\beta]=(1-q^{-2})\alpha\beta&lt;/math&gt;

These relations say that the generators commute as &lt;math&gt;q\to 1&lt;/math&gt; thereby recovering usual Minkowski space. One can work with more familiar variables &lt;math&gt;x,y,z,t&lt;/math&gt; as linear combinations of these. In particular, time

: &lt;math&gt; t = \text{Trace}_q \begin{pmatrix} \alpha &amp; \beta\\ \gamma &amp;\delta\end{pmatrix} = q\delta+q^{-1}\alpha&lt;/math&gt;

is given by a natural braided trace of the matrix and commutes with the other generators (so this model has a very different flavour from the bicrossproduct one).  The braided-matrix picture also leads naturally to a quantity

: &lt;math&gt; {\det}_q\begin{pmatrix}\alpha &amp; \beta\\ \gamma &amp;\delta\end{pmatrix}=\alpha\delta-q^2\gamma\beta&lt;/math&gt;

which as &lt;math&gt;q\to 1&lt;/math&gt; returns us the usual Minkowski distance (this translates to a metric in the quantum differential geometry). The parameter &lt;math&gt;q=e^{\lambda}&lt;/math&gt; or &lt;math&gt;q=e^{i \lambda}&lt;/math&gt;  is dimensionless and &lt;math&gt;\lambda&lt;/math&gt; is thought to be a ratio of the Planck scale and the cosmological length. That is, there are indications that this model relates to quantum gravity '''with''' non-zero [[cosmological constant]], the choice of &lt;math&gt;q&lt;/math&gt; depending on whether this is positive or negative. We have described the mathematically better understood but perhaps less physically justified positive case here.

A full understanding of this model requires (and was concurrent with the development of) a full theory of `braided linear algebra' for such spaces. The momentum space for the theory is another copy of the same algebra and there is a certain `braided addition' of momentum on it expressed as the structure of a  [[braided Hopf algebra]] or quantum group ''in'' a certain braided monoidal category). This theory by 1993 had provided the corresponding  &lt;math&gt;q&lt;/math&gt;-deformed Poincaré group as generated by such translations and &lt;math&gt;q&lt;/math&gt;-Lorentz transformations, completing the interpretation as a quantum spacetime.&lt;ref&gt;{{citation|doi=10.1063/1.530154|first=S. |last=Majid |title=Braided momentum in the q-Poincaré group| journal= Journal of Mathematical Physics| volume=34|issue=5 |year=1993| pages=2045–2058|arxiv = hep-th/9210141 |bibcode = 1993JMP....34.2045M }}&lt;/ref&gt;

In the process it was discovered that the Poincaré group not only had to be deformed but had to be extended to include dilations of the quantum spacetime. For such a theory to be exact we would need all particles in the theory to be massless, which is consistent with experiment as masses of elementary particles are indeed vanishingly small compared to the [[Planck mass]].  If current thinking in cosmology is correct then this model is more appropriate, but it is significantly  more complicated and for this reason its physical predictions have yet to be worked out{{how|date=September 2017}}

== Fuzzy or spin model spacetime ==
This refers in modern usage to the [[angular momentum]] algebra

: &lt;math&gt; [x_1,x_2]= 2 i \lambda x_3,\ [x_2,x_3]= 2 i \lambda x_1,\ [x_3,x_1]= 2 i \lambda x_2&lt;/math&gt;

familiar from [[quantum mechanics]] but interpreted in this context as coordinates of a quantum space or spacetime. These relations were proposed by [[Roger Penrose]] in his earliest [[spin network]] theory of space. It is a toy model of quantum gravity in 3 spacetime dimensions (not the physical 4) with a Euclidean (not the physical Minkowskian) signature. It was again proposed&lt;ref&gt;{{citation| doi=10.1088/0264-9381/13/5/018| first=G.|last='t Hooft|year=1996|title=Quantization of point particles in (2&amp;nbsp;+&amp;nbsp;1)-dimensional gravity and spacetime discreteness|journal=Classical and Quantum Gravity|volume=13| issue=5|pages=1023–1039|arxiv = gr-qc/9601014 |bibcode = 1996CQGra..13.1023T }}&lt;/ref&gt; in this context by [[Gerardus 't Hooft]]. A further development including a quantum differential calculus and an action of a certain `quantum double' quantum group as deformed Euclidean group of motions was given by Majid and E. Batista&lt;ref&gt;{{citation|doi=10.1063/1.1517395|first1=E. | last1=Batista | first2=S.| last2= Majid | title=Noncommutative geometry of angular momentum space U(su_2)| journal=Journal of Mathematical Physics| volume= 44|issue=1| year=2003| pages=107–137|arxiv = hep-th/0205128 |bibcode = 2003JMP....44..107B }}&lt;/ref&gt;

A striking feature of the noncommutative geometry here is that the smallest covariant quantum differential calculus has one dimension higher than expected, namely 4, suggesting that  the above can also be viewed as the spatial part of a 4-dimensional quantum spacetime. The model should not be confused with [[fuzzy sphere]]s which are finite-dimensional matrix algebras which one can think of as spheres in the spin model spacetime of fixed radius.

== Heisenberg model spacetimes ==
The quantum spacetime of [[Hartland Snyder]] proposes that

: &lt;math&gt; [x_\mu,x_\nu]= i M_{\mu\nu} &lt;/math&gt;

where the &lt;math&gt;M_{\mu\nu}&lt;/math&gt; generate the Lorentz group. This quantum spacetime and that of [[C. N. Yang]] entail a radical unification of spacetime, energy-momentum, and angular momentum.

The idea was revived in a modern context by [[Sergio Doplicher]], Klaus Fredenhagen and John Roberts in 1995
&lt;ref&gt;{{citation|doi=10.1007/BF02104515|first1=S.|last1= Doplicher|first2=K. |last2=Fredenhagen |first3=J.E. |last3=Roberts| title=The quantum structure of spacetime at the Planck scale and quantum fields| journal=Communications in Mathematical Physics|volume= 172|issue=1|pages=187–220 | year=1995|arxiv = hep-th/0303037 |bibcode = 1995CMaPh.172..187D }}&lt;/ref&gt; by letting &lt;math&gt;M_{\mu\nu}&lt;/math&gt; simply be viewed as some function of &lt;math&gt;x_\mu&lt;/math&gt; as defined by the above relation, and any relations involving it viewed as higher order relations among the  &lt;math&gt;x_\mu&lt;/math&gt;. The Lorentz symmetry is arranged so as to transform the indices as usual and without being deformed.

An even simpler variant of this model is to let &lt;math&gt;M&lt;/math&gt; here be a numerical antisymmetric tensor, in which context it is usually denoted &lt;math&gt;\theta&lt;/math&gt;, so the relations are &lt;math&gt;[x_\mu,x_\nu]= i \theta_{\mu\nu}&lt;/math&gt;. In even dimensions &lt;math&gt;D&lt;/math&gt;, any nondegenerate such theta can be transformed to a normal form in which this really is just the [[Heisenberg algebra]] but the difference that the variables are being proposed as those of spacetime. This proposal was for a time quite popular because of its familiar form of relations and because it has been argued&lt;ref&gt;{{citation|first1=N.|last1=Seiberg| first2= E.|last2= Witten|title= String theory and noncommutative geometry|journal= Journal of High Energy Physics|pages=9909;032|year=1999|doi=10.1088/1126-6708/1999/09/032|bibcode=1999JHEP...09..032S|volume=1999|issue=9|arxiv=hep-th/9908142}}&lt;/ref&gt;  that it emerges from the theory of open strings landing on D-branes, see [[noncommutative quantum field theory]] and [[Moyal plane]]. However, it should be realised that this D-brane lives in some of the higher spacetime dimensions in the theory and hence it is not our physical spacetime that string theory suggests to be effectively quantum in this way. You also have to subscribe to D-branes as an approach to quantum gravity in the first place. Even when posited as quantum spacetime it is hard to obtain physical predictions and one reason for this is that if &lt;math&gt;\theta&lt;/math&gt; is a tensor then by dimensional analysis it should have dimensions of length&lt;math&gt;{}^2&lt;/math&gt;, and if this length is speculated to be the Planck length then the effects would be even harder to ever detect than for other models.

== Noncommutative extensions to spacetime ==
Although not quantum spacetime in the sense above, another use of noncommutative geometry is to tack on `noncommutative extra dimensions' at each point of ordinary  spacetime. Instead of invisible curled up extra dimensions as in string theory, [[Alain Connes]] and coworkers have argued that the coordinate algebra of this extra part should be replaced by a finite-dimensional noncommutative algebra.  For a certain reasonable choice of this algebra, its representation and extended Dirac operator, one is able to recover the [[Standard Model]] of elementary particles. In this point of view the different kinds of matter particles are manifestations of geometry in these extra noncommutative directions. Connes's first works here date from 1989&lt;ref&gt;{{citation|doi=10.1016/0920-5632(91)90120-4|first1=A.|last1=Connes|first2=J.|last2=Lott|title=Particle models and noncommutative geometry|journal=Nuclear Physics B: Proceedings Supplements|volume=18|issue=2 |year=1989|pages= 29|bibcode = 1991NuPhS..18...29C }}&lt;/ref&gt; but has been developed considerably since then. Such an approach can theoretically be combined with quantum spacetime as above.

== See also ==
* [[Quantum group]]
* [[Quantum geometry]]
* [[Noncommutative geometry]]
* [[Quantum gravity]]
* [[Anabelian geometry|Anabelian topology]]

== References ==
{{Reflist|30em}}

== Further reading ==
* {{citation|first=S.|last=Majid|title=Foundations of Quantum Group Theory|publisher=Cambridge University Press|year=1995}}
* {{citation|editor=D. Oriti|title=Approaches to Quantum Gravity|publisher=Cambridge University Press|year=2009}}
* {{citation | first1 = A. | last1=Connes | author1-link = Alain Connes
            | first2 = M. | last2=Marcolli | author2-link = Matilde Marcolli
            | title=Noncommutative Geometry, Quantum Fields and Motives|year=2007|publisher=Colloquium Publications}}
* {{citation | title=&lt;math&gt;q&lt;/math&gt;-Deformation and semidualization in 3D quantum gravity
            | first1 = S. | last1 = Majid
            | first2 = B.J. |last2 = Schroers
            | year= 2009
            | journal=  Journal of Physics A: Mathematical and Theoretical| volume = 42| issue = 42 | pages = 425402 (40pp)
            | doi = 10.1088/1751-8113/42/42/425402 | bibcode = 2009JPhA...42P5402M }}
* R. P. Grimaldi, Discrete and Combinatorial Mathematics: An Applied Introduction, 4th Ed. Addison-Wesley 1999.
* J. Matousek, J. Nesetril, Invitation to Discrete Mathematics. Oxford University Press 1998.
* Taylor E. F., John A. Wheeler, Spacetime Physics, publisher W. H. Freeman, 1963.
* {{cite journal | last1 = Khoshbin-e-Khoshnazar | first1 = M.R. | year = 2013 | title = Binding Energy of the Very Early Universe: Abandoning Einstein for a Discretized Three–Torus Poset.A Proposal on the Origin of Dark Energy | journal = Gravitation and Cosmology | volume = 19 | issue = 2| pages = 106–113 | doi=10.1134/s0202289313020059| bibcode = 2013GrCo...19..106K }}

== External links ==
* [http://plus.maths.org/issue43/features/noncom/index-gifd.html Plus Magazine article on quantum geometry] by Marianne Freiberger
* {{citation|title=On Space and Time | editor=S. Majid| publisher=Cambridge University Press| year=2008|isbn=978-1-107-64168-6}}

[[Category:Mathematical physics]]</text>
      <sha1>fokth026uium5lw0o1457b1egkwqp05</sha1>
    </revision>
  </page>
  <page>
    <title>Range accrual</title>
    <ns>0</ns>
    <id>20179556</id>
    <revision>
      <id>630936255</id>
      <parentid>618286954</parentid>
      <timestamp>2014-10-24T14:24:13Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>number fmt using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4451">In [[finance]], a '''range accrual''' is a type of derivative product very popular among structured-note investors. It is estimated that more than US$160 billion of Range Accrual indexed on interest rates only have been sold to investors between 2004 and 2007.&lt;ref&gt;[http://www.globalmtn-i.com Mtn-I Publication 2007]&lt;/ref&gt; It is one of the most popular non-vanilla financial derivatives.  In essence the investor in a range accrual is betting that the reference "index" - usually interest rates or currency exchange rates - will stay within a predefined range.

== Payoff description ==

A general expression for the payoff of a range accrual is:

: &lt;math&gt;P \times \sum_{i=1}^{N} 1_{\text{index}(i) \in \text{Range}} \times \frac{1}{N}&lt;/math&gt;

* index(''i'') is the value of the index at the ''i''th observation date
* ''N'' is the total number of observations within a period
* ''P'' is the payout when the index is in the range

If the observation frequency is daily, the payoff could be more easily written as

: &lt;math&gt;P \times \frac{n}{N}&lt;/math&gt;

where

* ''n'' is the number of days a specified index is within a given range
* ''N'' is the total number of days of the observation period
* ''P'' is the payout for any given day where the index is in the range

The index could be an interest rate (e.g. USD 3 months Libor), or a FX rate (e.g. EUR/USD) or a commodity (e.g. oil price) or any other observable financial index.&lt;br /&gt;
The observation period can be different from daily (e.g. weekly, monthly,etc.), though a daily observation is the most encountered.

The receiver of the range accrual coupons is selling [[Digital option|binary options]]. The value of these options is used to enhance the coupon paid.

=== Example ===

Let's take an example of a 5 years range accrual note linked to USD 3 months Libor, with range set as [1.00%;&amp;nbsp;6.00%] and a conditional coupon of 5.00%. Let's assume the note to start on January 1, 2009 and the first coupon payment to happen on July 1, 2009.

An investor who buys USD 100m of this note will have the following cash flows:

* '''First coupon''' &amp;mdash; Between January 1 and July 1, 2009, if USD 3m Libor fixes between

1.00% and 6.00% for 130 days, then the rate applied for the first semester will be:

:5.00% &amp;times; 130/181 = 3.5912% ''(there are 181 days in total between January 1, 2009 and July 1, 2009)''.
:The coupon paid on July 1, 2009 would be: US$100m&amp;nbsp;&amp;times;&amp;nbsp;3.5912%&amp;nbsp;&amp;times;&amp;nbsp;0.5 = $1,795,600 ''(assuming 0.5 for the day-count fraction between January 1, 2009 and July 1, 2009)''

* '''Second coupon''' - Between July 1, 2009 and January 1, 2010, if USD 3m Libor fixes between 1.00% and 6.00% for 155 days, then the rate applied for the second semester will be:
:5.00% &amp;times; 155/184= 4.2120%.
:The coupon paid on January 1, 2010 would be: US$100m&amp;nbsp;&amp;times;&amp;nbsp;4.2120%&amp;nbsp;&amp;times;&amp;nbsp;0.5 = $2,106,000 ''(assuming 0.5 for the day-count fraction between July 1, 2009 and January 1, 2010)''.

* For the 8 following coupons, the same methodology applies. The highest rate investor will get is 5.00% and the lowest 0.00%.

=== Different types of range accruals ===

The payout (''P'' in our notation), for each day the index is in the range, could be either a fix or variable rate.

== Valuation and risks ==

A range accrual can be seen as a strip of [[Digital option|binary options]], with a decreasing lag between fixing date and payment date. For this reason, it is important the valuation model is well calibrated to the volatility term structure of the underlying, at least at the strikes implied by the range.

If furthermore the range accrual is [[Callable bond|callable]], then the valuation model also needs to take into account the dynamic between the [[swaption]] and the underlying.

Accrual swaps that monitor permanence of interest rates into a range and pay a related interest rate times the permanence factor also depend on correlation across different adjacent forward rates. For the details see for example Brigo and Mercurio (2001).

== Market ==
''(To be completed)''

==References==
{{reflist}}
*{{cite book | title = Interest Rate Models &amp;mdash; Theory and Practice with Smile, Inflation and Credit| author = [[Damiano Brigo]], [[Fabio Mercurio]] | publisher = Springer Verlag | year = 2001 | edition = 2nd ed. 2006 | isbn = 978-3-540-22149-4}}

[[Category:Investment]]
[[Category:Mathematical finance]]
[[Category:Options (finance)]]</text>
      <sha1>4yfgypmlfzvm8hk3p1o6dqop3ansfby</sha1>
    </revision>
  </page>
  <page>
    <title>Romanian Master of Mathematics and Sciences</title>
    <ns>0</ns>
    <id>28088480</id>
    <revision>
      <id>768755151</id>
      <parentid>768754743</parentid>
      <timestamp>2017-03-05T16:24:06Z</timestamp>
      <contributor>
        <ip>138.38.106.24</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3357">{{Infobox football tournament
| name                 = Romanian Master of Mathematics and Sciences
| logo                 = 
| caption              =
| founded              = 2008
| this year            = 4th edition – 23rd – 28th of February
| abolished            =
| region               = [[World]]
| number of teams      = 
| current champions    = {{Flag icon|Korea}} South Korea – mathematics
| most titles          =
| broadcasters         =
| motto                =
| website              = [http://rmm.lbi.ro/index.php?id=home RMMS website]
| current              =
}}

The '''Romanian Master of Mathematics and Sciences''' (formerly known as the '''Romanian Masters in Mathematics''') is an annual competition for students in the preuniversitary level, held in [[Bucharest]], [[Romania]]. The contestants compete individually, in four different sections: ''mathematics'', ''physics'', ''chemistry'' and ''computer science''. The participating teams (national and local teams) can have up to six students for each section (plus two teachers: a leader and a deputy leader). The contest follows the same structure as [[International Mathematical Olympiad|IMO]] and [[IPhO]] and is usually held at the end of February.

==History==
The first Romanian Master in Mathematics was held in 2008 and has been initiated by prof. Severius Moldoveanu and prof. Radu Gologan .&lt;ref&gt;[http://rmms.lbi.ro/rmm/ Romanian Master of Mathematics 2008 website]&lt;/ref&gt; In 2010 &lt;ref&gt;[http://rmms.lbi.ro/rms/ Romanian Master of Mathematics and Sciences 2010 website]&lt;/ref&gt; Physics was also added as a section, therefore the name changed to RMMS. At the beginning, the competition structure had been 4 problems in 5 hours, but also in 2010, it was changed to 3 problems in 4 hours, two days format. The first country that won the competition was the United Kingdom. The 4th edition was held between 23–28 of February 2011 and included also Chemistry and Computer Science. The 5th edition, held in 2012 was only for Physics and Mathematics. 
The current champions in Mathematics is South Korea.

===Teams reaching the top three in mathematics===
{| class="wikitable sortable"
|-
! Team !! Titles !! Runners-up !! Third place !! Total finishes in top 3 !!
|-
|Russia
|2 (2010, 2015)
|3 (2008, 2012, 2013)
|1 (2011)
|6
|-
|United Kingdom
|1 (2008)
|3 (2011[[#1|*]], 2016, 2017)
|1 (2013)
|5
|-
|China
|2 (2009, 2012[[#1|*]]) 
|1 (2010)
|2 (2015, 2017)
|5
|-
|United States
|3 (2011, 2013, 2016)
|1 (2015)
|3 (2009, 2010, 2012)
|7
|-
|Romania
|1 (2012[[#1|*]]) 
|0
|0
|1
|-
|Serbia
|0
|1 (2009)
|1 (2008)
|2
|-
|Hungary
|0
|1 (2011[[#1|*]])
|0
|1
|-
|Poland
|0
|0
|1 (2016)
|1
|-
|South Korea
|1 (2017)
|0
|0
|1
|-
|}
:&lt;div id="1"&gt;''&lt;nowiki&gt;*&lt;/nowiki&gt; = teams finished equal points''

==Organizers==
The contest is organised by the [[Tudor Vianu National College of Computer Science]] in collaboration with the [[Sector 1]] town council. As a host, the college has the right to have its own team entering the contest in each section, thus participating against countries.

==References==
{{reflist}}

[[Category:Mathematics competitions]]
[[Category:Physics events]]
[[Category:Science competitions]]
[[Category:Science events in Romania]]
[[Category:Annual events in Romania]]
[[Category:2008 establishments in Romania]]
[[Category:Recurring events established in 2008]]</text>
      <sha1>5c9vjv4avtw0jbllxa8i3ecsewxiktz</sha1>
    </revision>
  </page>
  <page>
    <title>Schilder's theorem</title>
    <ns>0</ns>
    <id>13345478</id>
    <revision>
      <id>857108613</id>
      <parentid>829805963</parentid>
      <timestamp>2018-08-29T16:36:58Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>[[MOS:FRAC]] style fix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4789">In [[mathematics]], '''Schilder's theorem''' is a result in the [[large deviations theory]] of [[stochastic process]]es.  Roughly speaking, Schilder's theorem gives an estimate for the probability that a (scaled-down) sample path of [[Brownian motion]] will stray far from the mean path (which is constant with value 0).  This statement is made precise using [[rate function]]s.  Schilder's theorem is generalized by the [[Freidlin–Wentzell theorem]] for [[Itō diffusion]]s.

==Statement of the theorem==
Let ''B'' be a standard Brownian motion in ''d''-[[dimension]]al [[Euclidean space]] '''R'''&lt;sup&gt;''d''&lt;/sup&gt; starting at the origin, 0&amp;nbsp;&amp;isin;&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt;; let '''W''' denote the [[law (stochastic processes)|law]] of ''B'', i.e. classical [[Wiener measure]].  For ''&amp;epsilon;''&amp;nbsp;&amp;gt;&amp;nbsp;0, let '''W'''&lt;sub&gt;''&amp;epsilon;''&lt;/sub&gt; denote the law of the rescaled process {{radic|''&amp;epsilon;''}}''B''.  Then, on the [[Banach space]] ''C''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''C''&lt;sub&gt;0&lt;/sub&gt;([0,&amp;nbsp;''T''];&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt;) of continuous functions  &lt;math&gt; f : [0,T] \longrightarrow \mathbf{R}^d&lt;/math&gt; such that &lt;math&gt;f(0)=0&lt;/math&gt;, equipped with the [[supremum norm]] ||&amp;middot;||&lt;sub&gt;&amp;infin;&lt;/sub&gt;, the [[probability measure]]s '''W'''&lt;sub&gt;''&amp;epsilon;''&lt;/sub&gt; satisfy the large deviations principle with good rate function ''I''&amp;nbsp;:&amp;nbsp;''C''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;&amp;rarr;&amp;nbsp;'''R'''&amp;nbsp;&amp;cup;&amp;nbsp;{+&amp;infin;} given by

:&lt;math&gt;I(\omega) = \frac{1}{2} \int_{0}^{T} | \dot{\omega}(t) |^{2} \, \mathrm{d} t&lt;/math&gt;

if ''&amp;omega;'' is [[absolutely continuous]], and ''I''(''&amp;omega;'')&amp;nbsp;=&amp;nbsp;+&amp;infin; otherwise.  In other words, for every [[open set]] ''G''&amp;nbsp;&amp;sube;&amp;nbsp;''C''&lt;sub&gt;0&lt;/sub&gt; and every [[closed set]] ''F''&amp;nbsp;&amp;sube;&amp;nbsp;''C''&lt;sub&gt;0&lt;/sub&gt;,

:&lt;math&gt;\limsup_{\varepsilon \downarrow 0} \varepsilon \log \mathbf{W}_{\varepsilon} (F) \leq - \inf_{\omega \in F} I(\omega)&lt;/math&gt;

and

:&lt;math&gt;\liminf_{\varepsilon \downarrow 0} \varepsilon \log \mathbf{W}_{\varepsilon} (G) \geq - \inf_{\omega \in G} I(\omega).&lt;/math&gt;

==Example==
Taking ''&amp;epsilon;''={{sfrac|1|''c''&lt;sup&gt;2&lt;/sup&gt;}}, one can use Schilder's theorem to obtain estimates for the probability that a standard Brownian motion ''B'' strays further than ''c'' from its starting point over the time interval [0,&amp;nbsp;''T''], i.e. the probability

:&lt;math&gt;\mathbf{W} (C_{0} \setminus \mathbf{B}_{c} (0; \| \cdot \|_{\infty})) \equiv \mathbf{P} \big[ \| B \|_{\infty} &gt; c \big],&lt;/math&gt;

as ''c'' tends to infinity.  Here '''B'''&lt;sub&gt;''c''&lt;/sub&gt;(0;&amp;nbsp;||&amp;middot;||&lt;sub&gt;&amp;infin;&lt;/sub&gt;) denotes the [[open ball]] of radius ''c'' about the zero function in ''C''&lt;sub&gt;0&lt;/sub&gt;, taken with respect to the [[supremum norm]].  First note that

:&lt;math&gt;\| B \|_{\infty} &gt; c \iff \sqrt{\varepsilon} B \in A := \left \{ \omega \in C_{0} \big| | \omega(t) | &gt; 1 \mbox{ for some } t \in [0, T] \right\}.&lt;/math&gt;

Since the rate function is continuous on ''A'', Schilder's theorem yields

:&lt;math&gt;\begin{align}
\lim_{c \to \infty} \frac{\log \left (\mathbf{P} \left [ \| B \|_{\infty} &gt; c \right] \right )}{c^{2}}  &amp;= \lim_{\varepsilon \to 0} \varepsilon \log \left (\mathbf{P} \left[ \sqrt{\varepsilon} B \in A \right] \right ) \\
&amp;= - \inf \left\{ \left. \frac{1}{2} \int_{0}^{T} | \dot{\omega}(t) |^{2} \, \mathrm{d} t \right| \omega \in A \right\} \\
&amp;= - \frac{1}{2} \int_{0}^{T} \frac{1}{T^{2}} \, \mathrm{d} t \\
&amp;= - \frac{1}{2 T},
\end{align}&lt;/math&gt;

making use of the fact that the [[infimum]] over paths in the collection ''A'' is attained for ''&amp;omega;''(''t'')&amp;nbsp;=&amp;nbsp;''t''&amp;nbsp;&amp;frasl;&amp;nbsp;''T''.  This result can be heuristically interpreted as saying that, for large ''c'' and/or large ''T''

:&lt;math&gt;\frac{\log \left (\mathbf{P} \left [ \| B \|_{\infty} &gt; c \right] \right )}{c^{2}} \approx - \frac{1}{2T} \qquad \text{or} \qquad \mathbf{P} \left[ \| B \|_{\infty} &gt; c \right ] \approx \exp \left( - \frac{c^{2}}{2 T} \right).&lt;/math&gt;

In fact, the above probability can be estimated more precisely:  for ''B'' a standard Brownian motion in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, and any ''T'', ''c'' and ''&amp;epsilon;''&amp;nbsp;&amp;gt;&amp;nbsp;0, we have:

:&lt;math&gt;\mathbf{P} \left[ \sup_{0 \leq t \leq T} \left| \sqrt{\varepsilon} B_{t} \right | \geq c \right] \leq 4 n \exp \left( - \frac{c^{2}}{2 n T \varepsilon} \right).&lt;/math&gt;

==References==
* {{cite book
| last= Dembo
| first = Amir
|author2=Zeitouni, Ofer
 | title = Large deviations techniques and applications
| series = Applications of Mathematics (New York) 38
| edition = Second
| publisher = Springer-Verlag
| location = New York
| year = 1998
| pages = xvi+396
| isbn = 0-387-98406-2
| mr=1619036}} (See theorem 5.2)

[[Category:Asymptotic analysis]]
[[Category:Theorems regarding stochastic processes]]
[[Category:Large deviations theory]]</text>
      <sha1>r06877j4uvaknviquclt7c4ydlwthe5</sha1>
    </revision>
  </page>
  <page>
    <title>Scotland Yard (board game)</title>
    <ns>0</ns>
    <id>54727</id>
    <revision>
      <id>859087872</id>
      <parentid>859087558</parentid>
      <timestamp>2018-09-11T16:44:11Z</timestamp>
      <contributor>
        <username>Tronvillain</username>
        <id>21335179</id>
      </contributor>
      <comment>/* Adaptations */ cr</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8762">{{One source|date=January 2018}}
{{Italic title}}
{{Infobox game
| subject_name = ''Scotland Yard''
| image_link = [[Image:Scotlandyard2.jpg|none|250px]]
| image_caption = The ''Scotland Yard'' board
| players = 3–6
| ages = 10+
| setup_time = 5–15 minutes
| playing_time = 1 hour (player dependent)
| complexity = medium
| strategy = medium
| random_chance = initial set-up
| skills = [[tactic (method)|Tactics]], [[Strategy]], and [[Deception|Bluffing]]
}}
[[Image:ScotlandYardPlan.JPG|thumb|Taxi, bus and underground 'tickets']]
'''''Scotland Yard''''' is a [[board game]] in which a team of players, as police, cooperate to track down a player controlling a criminal around a board representing the streets of [[London]]. It is named after [[Scotland Yard]],  the headquarters of London's [[Metropolitan Police Service]].  ''Scotland Yard'' is an [[symmetric game|asymmetric]] board game, with the detective players cooperatively solving a variant of the [[pursuit-evasion]] problem. The game is published by [[Ravensburger]] in most of Europe and Canada and by [[Milton Bradley]] in the United States. It received the ''[[Spiel des Jahres]]'' (Game of the Year) award in 1983. 

==Gameplay==
One player controls "Mr. X", a criminal whose location is only revealed periodically, and the other players each control a detective, which is always present on the board.

All players start with a number of tokens allowing them to use the following methods of transport:
* [[Taxicab|Taxi]]s allow the player to move only one space for each token used.  They can be used to reach any point in London, most of which are not accessible in this game by other means.
* [[Bus]]es are available throughout most of the map, allowing longer-distance travel more quickly if the player is located at a bus-stop.
* The [[London Underground]] allows quick travel between distant points of London. Because the stations are far apart, the use of an underground ticket can narrow down the possibilities of Mr. X's location.
* Water routes are available, which only Mr. X can use, following the water buses' routes along the [[Thames]] between [[Greenwich]] and [[Whitehall]].

Each player (Mr. X and the detectives) draws one of 18 possible cards which show where a player has to start, with Mr. X always drawing first. The locations on these cards are spaced far enough apart to ensure that Mr. X cannot be caught in the first round of play. There are a total of 199 locations on the board.&lt;ref&gt;{{cite web|url=http://boardgamegeek.com/thread/1059554/why-there-no-space-108|title=Why is there no space 108 - Scotland Yard - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt;

Each detective begins with a total of 22 tokens. Once each transport token is used by a detective, it is turned over to Mr. X, effectively giving him unlimited transport. As he makes each move, he writes down his destination (either in the log book provided with the game, or on a sheet of paper) and covers it with the token he has used, so that the detectives have clues as to his whereabouts. Mr. X also has a supply of black tokens that can be used for any mode of transport (one per detective in play; in the Milton Bradley version this is always five), and two cards that allow him to make two moves in a single turn. The water routes require a black token; when one of these is played, the detectives must consider whether or not it is being used to hide a river trip.  Mr. X moves first on every turn, after which the detectives must move in the same order.

At five specific times during the game, Mr. X has to reveal his current position.  Detectives will take this opportunity to refine their search and, if possible, plan ways to encircle him.  From each known position, the types of transport used by Mr. X limit the number of possible locations he can reach on his next move, which provides useful information to detectives (as well as preventing some types of cheating by the fugitive player).

The game is won by the detectives if any of them lands on Mr. X's current location or vice versa. Mr. X wins by avoiding capture until all detectives can no longer move, due to either exhausting their token supplies or reaching a space for which they have no more usable tokens.

Although the game says it is for 3-6 players many play this game with only 2 players. The police, when controlled by 1 person, are far more coordinated and have a better chance of catching Mr. X. When 3-5 people are playing as the police they have to work as a team and coordinate their moves which can be difficult, especially when one player wants to play a hunch.

The contents of the game contain:
*1 gameboard map of Central London
*6 pawns
*125 fare tickets
*1 label sheet
*18 start cards
*2 double move cards
*1 logbook and pad
*1 storage tray to be used to store tickets, start cards and pawns

There are two main board editions, one typically associated with [[Milton Bradley]], and another typically associated with [[Ravensburger]]. The primary difference between these is in the numbering of the stations: five stations are numbered differently, with 108 missing from the [[Milton Bradley]] boards, and 200 missing from the [[Ravensburger]] boards.&lt;ref&gt;{{cite web|url=http://boardgamegeek.com/thread/77052/starting-places|title=Starting Places - Scotland Yard - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt; There are also minor differences in the routes, such as a bus line between stations 198 and 199 that is changed to a taxi line in later editions, and the removal of a taxi line between stations 13 and 14 sometime after the renumbering.

==Alternative versions==
The game has been adapted to take place on maps of different cities. ''Scotland Yard Tokyo'', also distributed by [[Ravensburger]], takes place on the streets of Tokyo, with the major difference being game aesthetics. ''Scotland Yard: Swiss Edition'' uses the same gameplay and is set in Switzerland, with the addition of more boat routes and ski areas available only to Mr. X.&lt;ref&gt;{{cite web|url=https://boardgamegeek.com/boardgame/100881/scotland-yard-swiss-edition|title=Scotland Yard Swiss Edition - Board Game - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt;

''NY Chase'' is a version based on [[New York City]]. In this version, detectives do not hand their used tokens over, and they have access to roadblocks and a helicopter, tilting the game more in favour of those playing as detectives.&lt;ref&gt;{{cite web|url=https://boardgamegeek.com/boardgame/534/ny-chase|title=N.Y. Chase - Board Game - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt;

A faster travel version called ''Die Jagd Nach Mister X'' exists that functions quite differently. In this version, Mr. X's location is only hidden when a black travel token is used, and the game is essentially an open chase around London. Evasion is accomplished with black tokens and using the fastest travel to distant locations. In this version, each player takes turns as Mr. X, and points collected (in the form of the detectives' used travel tokens) determine the overall winner.&lt;ref&gt;{{cite web|url=https://boardgamegeek.com/boardgame/94837/scotland-yard-die-jagd-nach-mister-x|title=Scotland Yard: Die Jagd nach Mister X - Board Game - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt;

== Alternative rules ==
Three years after the game's publication, Alain Munoz and Serge Laget posted an article in the French magazine ''[[Jeux &amp; Stratégie]]'' suggesting alternative rules to balance and expand the game.&lt;ref&gt;pages 76-78, unknown magazine number, dated "three years after the game's first European publication"&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://boardgamegeek.com/filepage/26406/variantspdf|title=variants.pdf - Scotland Yard - BoardGameGeek|work=boardgamegeek.com}}&lt;/ref&gt;

==Adaptations==
The game was first adapted for the [[Nintendo Game Boy]] in 1990, and then as ''Scotland Yard Interactive'' for the [[Philips CD-I]] in 1993. It was subsequently adapted for Windows by [[Cryo Interactive]] in 1998, for the [[Nintendo DS]] by [[Sproing Interactive]] in 2008, and for iPhone (2012)&lt;ref&gt;{{cite web |url=http://www.appspy.com/review/4956/scotland-yard |date=23 May 2012 |title=Scotland Yard Review |last=Nesvadva |first=Andrew |website=AppSpy |publisher=Steel Media}}&lt;/ref&gt; and Android (2015) by Ravensburger Digital.

==References==
{{Reflist}}

==External links==
* {{bgg|55763|''Mister X''}}
* {{bgg|438|''Scotland Yard''}}
* {{bgg|534|''New York Chase''}}

{{Spiel des Jahres}}

[[Category:Board games introduced in 1983]]
[[Category:Murder and mystery board games]]
[[Category:Spiel des Jahres winners]]
[[Category:Cooperative board games]]
[[Category:Deduction board games]]
[[Category:Milton Bradley Company games]]
[[Category:Ravensburger games]]
[[Category:Pursuit-evasion]]</text>
      <sha1>lfttt9b6mjehtlc96kv7wbrh8s73vr5</sha1>
    </revision>
  </page>
  <page>
    <title>Spin structure</title>
    <ns>0</ns>
    <id>2844303</id>
    <revision>
      <id>855748479</id>
      <parentid>851193945</parentid>
      <timestamp>2018-08-20T15:24:53Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* Spin&lt;sup&gt;C&lt;/sup&gt; structures */Various citation &amp; identifier cleanup, plus AWB genfixes (arxiv version pointless when published)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24849">In [[differential geometry]], a '''spin structure''' on an [[orientable]] [[Riemannian manifold]] {{nowrap|(''M'', ''g'')}} allows one to define associated [[spinor bundle]]s, giving rise to the notion of a [[spinor]] in differential geometry.

Spin structures have wide applications to [[mathematical physics]], in particular to [[quantum field theory]] where they are an essential ingredient in the definition of any theory with uncharged [[fermion]]s.  They are also of purely mathematical interest in [[differential geometry]], [[algebraic topology]], and [[K theory]]. They form the foundation for [[spin geometry]].

==Overview&lt;!--'Spin frame' and 'Spin frames' redirect here--&gt;==
In [[geometry]] and in [[Field theory (physics)#Field theory|field theory]], mathematicians ask whether or not a given oriented Riemannian manifold (''M'',''g'') admits [[spinor]]s. One method for dealing with this problem is to require that ''M'' has a spin structure.&lt;ref name="autogenerated558"&gt;{{cite journal|title=Sur l’extension du groupe structural d’un espace fibré|author=A. Haefliger|journal=C. R. Acad. Sci. Paris|volume=243|year=1956|pages=558–560}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Spin structures on manifolds|author=J. Milnor|journal=L'Enseignement Mathématique|volume=9|year=1963|pages=198–203}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Champs spinoriels et propagateurs en rélativité générale|author=A. Lichnerowicz|author-link=André Lichnerowicz|journal=Bull. Soc. Math. Fr.|volume=92|year=1964|pages=11–100}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Algèbres de Clifford et K-théorie|author=M. Karoubi|journal=Ann. Sci. Éc. Norm. Sup.|volume=1|year=1968|pages=161–270|issue=2}}&lt;/ref&gt; This is not always possible since there is potentially a topological obstruction to the existence of spin structures. Spin structures will exist if and only if the second [[Stiefel–Whitney class]] ''w''&lt;sub&gt;2&lt;/sub&gt;(''M'') ∈ H&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) of ''M'' vanishes. Furthermore, if ''w''&lt;sub&gt;2&lt;/sub&gt;(''M'') = 0, then the set of the isomorphism classes of spin structures on ''M'' is acted upon freely and transitively by H&lt;sup&gt;1&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) . As the manifold ''M'' is assumed to be oriented, the first Stiefel–Whitney class ''w''&lt;sub&gt;1&lt;/sub&gt;(''M'') ∈ H&lt;sup&gt;1&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) of ''M'' vanishes too. (The Stiefel–Whitney classes ''w&lt;sub&gt;i&lt;/sub&gt;''(''M'') ∈ H&lt;sup&gt;''i''&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) of a manifold ''M'' are defined to be the Stiefel–Whitney classes of its [[tangent bundle]] ''TM''.)

The bundle of spinors π&lt;sub&gt;''S''&lt;/sub&gt;: ''S'' → ''M'' over ''M'' is then the [[complex vector bundle]] associated with the corresponding [[principal bundle]] π&lt;sub&gt;'''P'''&lt;/sub&gt;: '''P''' → ''M'' of '''spin frames'''&lt;!--boldface per WP:R#PLA--&gt; over ''M'' and the spin representation of its structure group Spin(''n'') on the space of spinors Δ&lt;sub&gt;''n''&lt;/sub&gt;. The bundle ''S'' is called the spinor bundle for a given spin structure on ''M''.

A precise definition of spin structure on manifold was possible only after the notion of [[fiber bundle]] had been introduced; [[André Haefliger]] (1956) found the topological obstruction to the existence of a spin structure on an orientable Riemannian manifold and [[Max Karoubi]] (1968) extended this result to the non-orientable pseudo-Riemannian case.&lt;ref&gt;
{{Citation
| last = Alagia
| first = H. R. 
| last2 = Sánchez
| first2 = C. U. 
| title = Spin structures on pseudo-Riemannian manifolds
| language = 
| journal = Revista de la Unión Matemática Argentina
| volume = 32
| issue = 
| pages = 64–78
| year = 1985
| url = http://inmabb.criba.edu.ar/revuma/pdf/v32n1/p064-078.pdf
| mr = 
| zbl =
| doi= 
}}
&lt;/ref&gt;

==Spin structures on Riemannian manifolds==

===Definition===
A spin structure on an [[orientable]] [[Riemannian manifold]] ''(M,g)'' is an [[equivariant]] lift of the oriented orthonormal frame bundle ''F''&lt;sub&gt;SO&lt;/sub&gt;(''M'') → ''M'' with respect to the double covering ρ: Spin(''n'') → SO(''n''). In other words, a pair ('''P''',''F''&lt;sub&gt;'''P'''&lt;/sub&gt;) is a spin structure on the principal bundle π: ''F''&lt;sub&gt;SO&lt;/sub&gt;(''M'') → ''M'' when
:a) π&lt;sub&gt;'''P'''&lt;/sub&gt;: '''P''' → ''M'' is a principal Spin(''n'')-bundle over ''M'',
:b) ''F''&lt;sub&gt;'''P'''&lt;/sub&gt;: '''P''' → ''F''&lt;sub&gt;SO&lt;/sub&gt;(''M'') is an [[equivariant]] 2-fold [[covering map]] such that

::&lt;math&gt;\pi\circ F_{\mathbf P}=\pi_{\mathbf P}&lt;/math&gt; and ''F''&lt;sub&gt;'''P'''&lt;/sub&gt;('''p''' ''q'') = ''F''&lt;sub&gt;'''P'''&lt;/sub&gt;('''p''')ρ(''q'') for all '''p''' ∈ '''P''' and ''q'' ∈ Spin(''n'').

The principal bundle π&lt;sub&gt;'''P'''&lt;/sub&gt;: '''P''' → ''M'' is also called the bundle of spin frames over ''M''.

Two spin structures ('''P'''&lt;sub&gt;1&lt;/sub&gt;, ''F''&lt;sub&gt;'''P'''&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;) and ('''P'''&lt;sub&gt;2&lt;/sub&gt;, ''F''&lt;sub&gt;'''P'''&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;) on the same oriented [[Riemannian manifold]] ''(M,g)'' are called "equivalent" if there exists a Spin(''n'')-equivariant map ''f'': '''P'''&lt;sub&gt;1&lt;/sub&gt; → '''P'''&lt;sub&gt;2&lt;/sub&gt; such that

:&lt;math&gt;F_{\mathbf P_2}\circ f=F_{\mathbf P_1}&lt;/math&gt; and ''f''('''p''' ''q'') = ''f''('''p''')''q'' for all &lt;math&gt;{\mathbf p}\in {\mathbf P_1}&lt;/math&gt; and ''q'' ∈ Spin(''n'').

Of course, in this case &lt;math&gt;F_{\mathbf P_1}&lt;/math&gt; and &lt;math&gt;F_{\mathbf P_2}&lt;/math&gt; are two equivalent double coverings of the oriented orthonormal frame SO(''n'')-bundle ''F''&lt;sub&gt;SO&lt;/sub&gt;(''M'') → ''M'' of the given Riemannian manifold ''(M,g)''.

This definition of spin structure on (''M'',''g'') as a spin structure on the principal bundle ''F''&lt;sub&gt;SO&lt;/sub&gt;(''M'') → ''M'' is due to [[André Haefliger]] (1956).

===Obstruction===
[[André Haefliger]] &lt;ref name="autogenerated558"/&gt; found necessary and sufficient conditions for the existence of a spin structure on an oriented Riemannian manifold (''M'',''g''). The obstruction to having a spin structure is a certain element [''k''] of H&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) . For a spin structure the class [''k''] is the second [[Stiefel–Whitney class]] ''w''&lt;sub&gt;2&lt;/sub&gt;(''M'') ∈ H&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) of ''M''. Hence, a spin structure exists if and only if the second Stiefel–Whitney class ''w''&lt;sub&gt;2&lt;/sub&gt;(''M'') ∈ H&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z'''&lt;sub&gt;2&lt;/sub&gt;) of ''M'' vanishes.

==Spin structures on vector bundles&lt;!--'Spin manifold' redirects here--&gt;==
Let ''M'' be a [[paracompact]] [[topological manifold]] and ''E'' an [[Oriented#Orientation of vector bundles|oriented]] vector bundle on ''M'' of dimension ''n'' equipped with a [[fibre metric]].  This means that at each point of ''M'', the fibre of ''E'' is an [[inner product space]].  A spinor bundle of ''E'' is a prescription for consistently associating a [[spin representation]] to every point of ''M''.  There are topological obstructions to being able to do it, and consequently, a given bundle ''E'' may not admit any spinor bundle.  In case it does, one says that the bundle ''E'' is ''spin''.

This may be made rigorous through the language of [[principal bundle]]s.  The collection of oriented [[orthonormal frame]]s of a vector bundle form a [[frame bundle]] ''P''&lt;sub&gt;SO&lt;/sub&gt;(''E''), which is a principal bundle under the action of the [[special orthogonal group]] SO(''n'').  A spin structure for ''P''&lt;sub&gt;SO&lt;/sub&gt;(''E'') is a ''lift'' of ''P''&lt;sub&gt;SO&lt;/sub&gt;(''E'') to a principal bundle ''P''&lt;sub&gt;Spin&lt;/sub&gt;(''E'') under the action of the [[spin group]] Spin(''n''), by which we mean that there exists a bundle map φ : ''P''&lt;sub&gt;Spin&lt;/sub&gt;(''E'') → ''P''&lt;sub&gt;SO&lt;/sub&gt;(''E'') such that
:&lt;math&gt;\phi(pg) = \phi(p)\rho(g)&lt;/math&gt;, for all {{nowrap|''p'' &amp;isin; ''P''&lt;sub&gt;Spin&lt;/sub&gt;(''E'')}} and {{nowrap|''g'' &amp;isin; Spin(''n'')}},
where {{nowrap|''ρ'' : Spin(''n'') → SO(''n'')}} is the mapping of groups presenting the spin group as a double-cover of SO(''n'').

In the special case in which ''E'' is the [[tangent bundle]] ''TM'' over the base manifold ''M'', if a spin structure exists then one says that ''M'' is a '''spin manifold'''&lt;!--boldface per WP:R#PLA--&gt;. Equivalently ''M'' is ''spin'' if the SO(''n'') principal bundle of [[orthonormal basis|orthonormal bases]] of the tangent fibers of ''M'' is a '''Z'''&lt;sub&gt;2&lt;/sub&gt; quotient of a principal spin bundle.

If the manifold has a [[CW complex|cell decomposition]] or a [[Triangulation (topology)|triangulation]], a spin structure can equivalently be thought of as a homotopy-class of trivialization of the [[tangent bundle]] over the 1-[[skeleton]] that extends over the 2-skeleton.  If the dimension is lower than 3, one first takes a Whitney sum with a trivial line bundle.

===Obstruction===
A spin structure on a vector bundle ''E'' exists if and only if the second [[Stiefel–Whitney class]] ''w''&lt;sub&gt;2&lt;/sub&gt; of ''E'' vanishes. This is a result of [[Armand Borel]] and [[Friedrich Hirzebruch]].&lt;ref&gt;{{cite journal|author=A. Borel|author2=F. Hirzebruch |title=Characteristic classes and homogeneous spaces I|journal=[[American Journal of Mathematics]]|volume=80|year=1958|pages=97–136|doi=10.2307/2372795|jstor=2372795|issue=2}}&lt;/ref&gt; Note, we have assumed π&lt;sub&gt;''E''&lt;/sub&gt;: ''E'' → ''M'' is an [[orientable]] [[vector bundle]].

===Classification===
When spin structures exist, the inequivalent spin structures on a manifold have a one-to-one correspondence (not canonical) with the elements of H&lt;sup&gt;1&lt;/sup&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;), which by the [[universal coefficient theorem]] is isomorphic to H&lt;sub&gt;1&lt;/sub&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;). More precisely, the space of the isomorphism classes of spin structures is an [[affine space]] over H&lt;sup&gt;1&lt;/sup&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;).

Intuitively, for each nontrivial cycle on ''M'' a spin structure corresponds to a binary choice of whether a section of the SO(''N'') bundle switches sheets when one encircles the loop.  If ''w''&lt;sub&gt;2&lt;/sub&gt;&lt;ref&gt;{{cite web|title=Spin manifold and the second Stiefel-Whitney class|url=https://math.stackexchange.com/a/808396/251222|website=Math.Stachexchange}}&lt;/ref&gt; vanishes then these choices may be extended over the two-[[skeleton (topology)|skeleton]], then (by [[obstruction theory]]) they may automatically be extended over all of ''M''.  In [[particle physics]] this corresponds to a choice of periodic or antiperiodic [[boundary condition]]s for [[fermions]] going around each loop. Note that on a complex manifold &lt;math&gt;X&lt;/math&gt; the second Steifel-Whitney class can be computed as the first [[chern class]] &lt;math&gt;\text{mod } 2&lt;/math&gt;.

===Examples===
# A [[genus (mathematics)|genus]] ''g'' [[Riemann surface]] admits 2&lt;sup&gt;2''g''&lt;/sup&gt; inequivalent spin structures; see [[theta characteristic]].
# If ''H''&lt;sup&gt;2&lt;/sup&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;) vanishes, ''M'' is ''spin''. For example, ''S''&lt;sup&gt;''n''&lt;/sup&gt; is ''spin'' for all &lt;math&gt; n\neq 2 &lt;/math&gt;. (Note that ''S''&lt;sup&gt;2&lt;/sup&gt; is also ''spin'', but for different reasons; see below.)
# The complex [[projective plane]] '''CP'''&lt;sup&gt;2&lt;/sup&gt; is not ''spin''.
# More generally, all even-dimensional [[complex projective space]]s '''CP'''&lt;sup&gt;2''n''&lt;/sup&gt; are not ''spin''.
# All odd-dimensional [[complex projective space]]s '''CP'''&lt;sup&gt;2n+1&lt;/sup&gt; are ''spin''.
# All compact, [[orientable manifold]]s of dimension 3 or less are ''spin''.
# All [[Calabi–Yau manifold]]s are ''spin''.

=== Properties ===
* The [[Â genus]] of a spin manifold is an integer, and is an even integer if in addition the dimension is 4 mod 8.
*:In general the [[Â genus]] is a rational invariant, defined for any manifold, but it is not in general an integer.
*:This was originally proven by [[Friedrich Hirzebruch|Hirzebruch]] and [[Armand Borel|Borel]], and can be proven by the [[Atiyah–Singer index theorem]], by realizing the [[Â genus]] as the index of a [[Dirac operator]] – a Dirac operator is a square root of a second order operator, and exists due to the spin structure being a "square root". This was a motivating example for the index theorem.

==Spin&lt;sup&gt;C&lt;/sup&gt; structures==
A spin&lt;sup&gt;'''C'''&lt;/sup&gt; structure is analogous to a spin structure on an oriented [[Riemannian manifold]],&lt;ref&gt;{{Cite book | last1=Lawson | first1=H. Blaine | last2=Michelsohn | first2=Marie-Louise|author2-link=Marie-Louise Michelsohn | title=Spin Geometry | publisher=[[Princeton University Press]] | isbn=978-0-691-08542-5 | year=1989 | postscript=&lt;!--None--&gt;}} page 391
&lt;/ref&gt; but uses the Spin&lt;sup&gt;'''C'''&lt;/sup&gt; group, which is defined instead by the [[exact sequence]] 
:&lt;math&gt;1 \to \mathbf{Z}_2 \to \operatorname{Spin}^{\mathbf{C}}(n) \to \operatorname{SO}(n)\times \operatorname{U}(1) \to 1.&lt;/math&gt;
To motivate this, suppose that {{nowrap|''κ'' : Spin(''n'') → U(''N'')}} is a complex spinor representation.  The center of U(''N'') consists of the diagonal elements coming from the inclusion {{nowrap|''i'' : U(1) → U(''N'')}}, i.e., the scalar multiples of the identity. Thus there is a [[homomorphism]]
:&lt;math&gt;\kappa\times i\colon {\mathrm {Spin}}(n)\times {\mathrm U}(1)\to {\mathrm U}(N).&lt;/math&gt;
This will always have the element (−1,−1) in the kernel. Taking the quotient modulo this element gives the group Spin&lt;sup&gt;'''C'''&lt;/sup&gt;(''n''). This is the twisted product

:&lt;math&gt;{\mathrm {Spin}}^{\mathbb C}(n) = {\mathrm {Spin}}(n)\times_{\Bbb Z_2} {\mathrm U}(1)\, ,&lt;/math&gt;

where U(1) = SO(2) = '''S'''&lt;sup&gt;1&lt;/sup&gt;. In other words, the group Spin&lt;sup&gt;'''C'''&lt;/sup&gt;(''n'') is a [[central extension (mathematics)|central extension]] of SO(''n'') by '''S'''&lt;sup&gt;1&lt;/sup&gt;.

Viewed another way, Spin&lt;sup&gt;'''C'''&lt;/sup&gt;(''n'') is the quotient group obtained from {{nowrap|Spin(''n'') × Spin(2)}} with respect to the normal '''Z'''&lt;sub&gt;2&lt;/sub&gt; which is generated by the pair of covering transformations for the bundles {{nowrap|Spin(''n'') → SO(''n'')}} and {{nowrap|Spin(2) → SO(2)}} respectively. This makes the Spin&lt;sup&gt;C&lt;/sup&gt; group both a bundle over the circle with fibre Spin(''n''), and a bundle over SO(''n'') with fibre a circle.&lt;ref&gt;{{cite journal|title=''Spin&lt;sup&gt;c&lt;/sup&gt;–structures and homotopy equivalences''|author=R. Gompf|doi=10.2140/gt.1997.1.41|journal=[[Geometry &amp; Topology]]|volume=1|year=1997|pages=41–50|arxiv=math/9705218}}&lt;/ref&gt;&lt;ref&gt;{{Cite book | last1=Friedrich|first1=Thomas| title = Dirac Operators in Riemannian Geometry| publisher=[[American Mathematical Society]] | year=2000|isbn=978-0-8218-2055-1 | postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}
page 26&lt;/ref&gt;

The fundamental group π&lt;sub&gt;1&lt;/sub&gt;(Spin&lt;sup&gt;'''C'''&lt;/sup&gt;(''n'')) is isomorphic to '''Z'''.

If the manifold has a [[CW complex|cell decomposition]] or a [[Triangulation (topology)|triangulation]], a spin&lt;sup&gt;C&lt;/sup&gt; structure can be equivalently thought of as a homotopy class of [[Complex manifold|complex structure]] over the 2-[[skeleton]] that extends over the 3-skeleton.  Similarly to the case of spin structures, one takes a Whitney sum with a trivial line bundle if the manifold is odd-dimensional.

Yet another definition is that a spin&lt;sup&gt;C&lt;/sup&gt; structure on a manifold ''N'' is a complex line bundle ''L'' over ''N'' together with a spin structure on {{nowrap|T''N'' ⊕ ''L''}}.

===Obstruction===
A spin&lt;sup&gt;'''C'''&lt;/sup&gt; structure exists when the bundle is orientable and the second [[Stiefel–Whitney class]] of the bundle ''E'' is in the image of the map {{nowrap|''H''&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z''') → ''H''&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z'''/2'''Z''')}} (in other words, the third integral Stiefel–Whitney class vanishes).  In this case one says that ''E'' is spin&lt;sup&gt;'''C'''&lt;/sup&gt;.  Intuitively, the lift gives the [[Chern class]] of the square of the U(1) part of any obtained spin&lt;sup&gt;'''C'''&lt;/sup&gt; bundle.
By a theorem of Hopf and Hirzebruch, closed orientable 4-manifolds always admit a spin&lt;sup&gt;'''C'''&lt;/sup&gt; structure.

===Classification===
When a manifold carries a spin&lt;sup&gt;'''C'''&lt;/sup&gt; structure at all, the set of spin&lt;sup&gt;'''C'''&lt;/sup&gt; structures forms an affine space.  Moreover, the set of spin&lt;sup&gt;'''C'''&lt;/sup&gt; structures has a free transitive action of {{nowrap|''H''&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z''')}}.  Thus, spin&lt;sup&gt;'''C'''&lt;/sup&gt;-structures correspond to elements of {{nowrap|''H''&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z''')}} although not in a natural way.

====Geometric picture====
This has the following geometric interpretation, which is due to [[Edward Witten]].  When the spin&lt;sup&gt;'''C'''&lt;/sup&gt; structure is nonzero this square root bundle has a non-integral Chern class, which means that it fails the [[triple overlap condition]].  In particular, the product of transition functions on a three-way intersection is not always equal to one, as is required for a [[principal bundle]].  Instead it is sometimes &amp;minus;1.

This failure occurs at precisely the same intersections as an identical failure in the triple products of transition functions of the obstructed [[spinor bundle|spin bundle]].  Therefore, the triple products of transition functions of the full ''spin''&lt;sup&gt;''c''&lt;/sup&gt; bundle, which are the products of the triple product of the ''spin'' and U(1) component bundles, are either {{nowrap|1=1&lt;sup&gt;2&lt;/sup&gt; = 1}} or {{nowrap|1=(−1)&lt;sup&gt;2&lt;/sup&gt; = 1}} and so the spin&lt;sup&gt;'''C'''&lt;/sup&gt; bundle satisfies the triple overlap condition and is therefore a legitimate bundle.

====The details====
The above intuitive geometric picture may be made concrete as follows.  Consider the [[short exact sequence]] {{nowrap|0 → '''Z''' → '''Z''' → '''Z'''&lt;sub&gt;2&lt;/sub&gt; → 0}}, where the second [[arrow]] is [[multiplication]] by 2 and the third is reduction modulo 2.  This  induces a [[long exact sequence]] on cohomology, which contains

::&lt;math&gt;\dots \longrightarrow \textrm H^2(M;\mathbf Z) \stackrel {2} {\longrightarrow} \textrm H^2(M;\mathbf Z) \longrightarrow \textrm H^2(M;\mathbf Z_2) \stackrel {\beta}\longrightarrow \textrm H^3(M;\mathbf Z) \longrightarrow \dots ,&lt;/math&gt;

where the second [[arrow]] is induced by multiplication by 2, the third is induced by restriction modulo 2 and the fourth is the associated [[Bockstein homomorphism]] ''β''.

The obstruction to the existence of a ''spin'' bundle is an element ''w''&lt;sub&gt;2&lt;/sub&gt; of {{nowrap|H&lt;sup&gt;2&lt;/sup&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;)}}.  It reflects the fact that one may always locally lift an SO(N) bundle to a ''spin'' bundle, but one needs to choose a '''Z'''&lt;sub&gt;2&lt;/sub&gt; lift of each transition function, which is a choice of sign.  The lift does not exist when the product of these three signs on a triple overlap is −1, which yields the [[Čech cohomology]] picture of ''w''&lt;sub&gt;2&lt;/sub&gt;.

To cancel this obstruction, one tensors this ''spin'' bundle with a U(1) bundle with the same obstruction ''w''&lt;sub&gt;2&lt;/sub&gt;.  Notice that this is an abuse of the word ''bundle'', as neither the ''spin'' bundle nor the U(1) bundle satisfies the triple overlap condition and so neither is actually a bundle.

A legitimate U(1) bundle is classified by its [[Chern class]], which is an element of H&lt;sup&gt;2&lt;/sup&gt;(''M'','''Z'''). Identify this class with the first element in the above exact sequence.  The next arrow doubles this Chern class, and so legitimate bundles will correspond to even elements in the second {{nowrap|H&lt;sup&gt;2&lt;/sup&gt;(''M'', '''Z''')}}, while odd elements will correspond to bundles that fail the triple overlap condition.  The obstruction then is classified by the failure of an element in the second H&lt;sup&gt;2&lt;/sup&gt;(''M'','''Z''') to be in the image of the arrow, which, by exactness, is classified by its image in H&lt;sup&gt;2&lt;/sup&gt;(''M'','''Z'''&lt;sub&gt;2&lt;/sub&gt;) under the next arrow.

To cancel the corresponding obstruction in the ''spin'' bundle, this image needs to be ''w''&lt;sub&gt;2&lt;/sub&gt;.  In particular, if ''w''&lt;sub&gt;2&lt;/sub&gt; is not in the image of the arrow, then there does not exist any U(1) bundle with obstruction equal to ''w''&lt;sub&gt;2&lt;/sub&gt; and so the obstruction cannot be cancelled.  By exactness, ''w''&lt;sub&gt;2&lt;/sub&gt; is in the image of the preceding arrow only if it is in the kernel of the next arrow, which we recall is the [[Bockstein homomorphism]] β.  That is, the condition for the cancellation of the obstruction is

:::&lt;math&gt;W_3=\beta w_2=0&lt;/math&gt;

where we have used the fact that the third '''integral''' Stiefel–Whitney class ''W''&lt;sub&gt;3&lt;/sub&gt; is the Bockstein of the second Stiefel–Whitney class ''w''&lt;sub&gt;2&lt;/sub&gt; (this can be taken as a definition of ''W''&lt;sub&gt;3&lt;/sub&gt;).

====Integral lifts of Stiefel–Whitney classes====
This argument also demonstrates that second Stiefel–Whitney class defines elements not only of '''Z'''&lt;sub&gt;2&lt;/sub&gt; cohomology but also of integral cohomology in one higher degree.  In fact this is the case for all even Stiefel–Whitney classes.  It is traditional to use an uppercase ''W'' for the resulting classes in odd degree, which are called the integral Stiefel–Whitney classes, and are labeled by their degree (which is always odd).

===Examples===
# All [[oriented]] [[smooth manifold]]s of dimension 4 or less are spin&lt;sup&gt;'''C'''&lt;/sup&gt;.&lt;ref&gt;{{Cite book | last1=Gompf | first1=Robert E. | last2=Stipsicz | first2=Andras I. | title=4-Manifolds and Kirby Calculus | publisher=[[American Mathematical Society]] | isbn=0-8218-0994-6 | year=1999 | pages=55–58, 186–187}}&lt;/ref&gt;
# All [[almost complex manifold]]s are spin&lt;sup&gt;'''C'''&lt;/sup&gt;.
# All ''spin'' manifolds are spin&lt;sup&gt;'''C'''&lt;/sup&gt;.

==Application to particle physics==

In [[particle physics]] the [[spin–statistics theorem]] implies that the [[wavefunction]] of an uncharged [[fermion]] is a section of the [[associated vector bundle]] to the ''spin'' lift of an SO(''N'') bundle ''E''.  Therefore, the choice of spin structure is part of the data needed to define the wavefunction, and one often needs to sum over these choices in the [[partition function (quantum field theory)|partition function]].  In many physical theories ''E'' is the [[tangent bundle]], but for the fermions on the worldvolumes of [[D-branes]] in [[string theory]] it is a [[normal bundle]].

In [[quantum field theory]] charged spinors are sections of associated ''spin''&lt;sup&gt;''c''&lt;/sup&gt; bundles, and in particular no charged spinors can exist on a space that is not ''spin''&lt;sup&gt;''c''&lt;/sup&gt;.  An exception arises in some [[supergravity]] theories where additional interactions imply that other fields may cancel the third Stiefel–Whitney class. The mathematical description of spinors in supergravity and string theory is a particularly subtle open problem, which was recently addressed in references.&lt;ref name=LazaroiuShahbaziI&gt;C. Lazaroiu and C. S. Shahbazi [https://arxiv.org/abs/1606.07894 "Real pinor bundles and real Lipschitz structures"].&lt;/ref&gt;&lt;ref&gt;C. Lazaroiu and C. S. Shahbazi [https://arxiv.org/abs/1607.02103 "On the spin geometry of supergravity and string theory"].&lt;/ref&gt; It turns out that the standard notion of spin structure is too restrictive for applications to supergravity and string theory, and that the correct notion of spinorial structure for the mathematical formulation of these theories is a "Lipschitz structure".&lt;ref name=LazaroiuShahbaziI /&gt;&lt;ref&gt;Thomas Friedrich, Andrzej Trautman. [https://arxiv.org/abs/math/9901137 "Spin spaces, Lipschitz groups, and spinor bundles"], ''[[Annals of Global Analysis and Geometry]]'', 2000, Volume 18, Issue 3, pp. 221–240.&lt;/ref&gt;

==See also==
* [[Orthonormal frame bundle]]
* [[Spinor]]

==References==
&lt;references/&gt;

==Further reading==
* {{Cite book | last1=Lawson | first1=H. Blaine | last2=Michelsohn | first2=Marie-Louise | title=Spin Geometry | publisher=[[Princeton University Press]] | isbn=978-0-691-08542-5 | year=1989 | postscript=&lt;!--None--&gt;}}
* {{Cite book | last1=Friedrich|first1=Thomas| title = Dirac Operators in Riemannian Geometry| publisher=[[American Mathematical Society]] | year=2000|isbn=978-0-8218-2055-1 | postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}
* {{Cite book | last1=Karoubi | first1=Max|title=K-Theory | publisher=Springer | isbn=978-3-540-79889-7 | year=2008 |pages=212–214| postscript=&lt;!--None--&gt;}}
* {{Cite book | last1=Greub | first1=Werner | last2=Petry | first2=Herbert-Rainer. |title=On the lifting of structure groups | publisher=in Lecture Notes in Mathematics, Springer-Verlag | isbn= |volume=676| year=1978 |pages=217–246| postscript=&lt;!--None--&gt;}}

==External links==
*[http://earthlingsoft.net/ssp/studium/2001spring/Spin.pdf Something on Spin Structures] by Sven-S. Porst is a short introduction to [[orientability|orientation]] and spin structures for mathematics students.

[[Category:Riemannian manifolds|Structures on Riemannian manifolds]]
[[Category:Structures on manifolds]]
[[Category:Algebraic topology]]
[[Category:K-theory]]
[[Category:Mathematical physics]]</text>
      <sha1>iqmjs0esbjzybx08st7h51hihjykb4y</sha1>
    </revision>
  </page>
  <page>
    <title>Stochastic homogenization</title>
    <ns>0</ns>
    <id>57653446</id>
    <revision>
      <id>845556861</id>
      <parentid>845514666</parentid>
      <timestamp>2018-06-12T15:14:10Z</timestamp>
      <contributor>
        <username>CapitalSasha</username>
        <id>483374</id>
      </contributor>
      <comment>+[[Category:Stochastic processes]]; +[[Category:Stochastic models]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="636">{{technical|date=June 2018}}
In [[homogenization (mathematics)|homogenization theory]], a branch of [[mathematics]], '''stochastic homogenization''' is a technique for understanding solutions to [[partial differential equations]] with [[oscillatory]] [[random variable|random]] coefficients.&lt;ref&gt;{{cite web |title=Stochastic Homogenization |url=https://www.mis.mpg.de/applan/research/homogenization.html |website=www.mis.mpg.de |accessdate=11 June 2018 |language=en}}&lt;/ref&gt;

==References==
&lt;references /&gt;

{{mathematics-stub}}

[[Category:Partial differential equations]]
[[Category:Stochastic processes]]
[[Category:Stochastic models]]</text>
      <sha1>jdy0fs4fe6algtov01efuj9ayhaba6g</sha1>
    </revision>
  </page>
  <page>
    <title>Subgame</title>
    <ns>0</ns>
    <id>1286452</id>
    <revision>
      <id>776623142</id>
      <parentid>603425898</parentid>
      <timestamp>2017-04-22T05:49:47Z</timestamp>
      <contributor>
        <username>Cherkash</username>
        <id>10363</id>
      </contributor>
      <minor/>
      <comment>clean up, [[WP:AWB/T|typo(s) fixed]]: Furthermore → Furthermore, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4254">{{about|subgames in game theory|subgame as a short video game contained in another| minigame}}

In [[game theory]], a '''subgame''' is any part (a subset) of a game that meets the following criteria (the following terms allude to a game described in [[extensive form game|extensive form]]):&lt;ref&gt;
{{cite web
|url=http://press.princeton.edu/TOCs/c5590.html
|title=Table of Contents for Morrow, J.D.: Game Theory for Political Scientists.
|publisher=press.princeton.edu
|accessdate=2008-03-26
|last=
|first=
}}
&lt;/ref&gt;

#It has a single initial node that is the only member of that node's [[information set (game theory)|information set]] (i.e. the initial node is in a [[singleton (mathematics)|singleton]] information set).
#If a node is contained in the subgame then so are all of its successors.
#If a node in a particular [[information set (game theory)|information set]] is in the subgame then all members of that information set belong to the subgame.

It is a notion used in the [[solution concept]] of [[subgame perfect equilibrium|subgame perfect Nash equilibrium]], a refinement of the [[Nash equilibrium]] that eliminates [[non-credible threat]]s.

The key feature of a subgame is that it, when seen in isolation, constitutes a game in its own right. When the initial node of a subgame is reached in a larger game, players can concentrate only on that subgame; they can ignore the history of the rest of the game (provided they know [[bayesian game|what subgame they are playing]]). This is the intuition behind the definition given above of a subgame. It must contain an initial node that is a singleton information set since this is a requirement of a game. Otherwise, it would be unclear where the player with first move should start at the beginning of a game (but see [[Bayesian game|nature's choice]]). Even if it is clear in the context of the larger game which node of a non-singleton information set has been reached, players could not ignore the history of the larger game once they reached the initial node of a subgame if subgames cut across information sets. Furthermore, a subgame can be treated as a game in its own right, but it must reflect the strategies available to players in the larger game of which it is a subset. This is the reasoning behind 2 and 3 of the definition. All the strategies (or subsets of strategies) available to a player at a node in a game must be available to that player in the subgame the initial node of which is that node.

==Subgame perfection==

One of the principal uses of the notion of a subgame is in the [[solution concept]] subgame perfection, which stipulates that an equilibrium strategy profile be a [[Nash equilibrium]] in ''every subgame''.

In a Nash equilibrium, there is some sense in which the outcome is optimal - every player is playing a best response to the other players. However, in some dynamic games this can yield implausible equilibria. Consider a two-player game in which player 1 has a strategy S to which player 2 can play B as a best response. Suppose also that S is a best response to B. Hence, {S,B} is a Nash equilibrium. Let there be another Nash equilibrium {S',B'}, the outcome of which player 1 prefers and B' is the only best response to S'. In a dynamic game, the first Nash equilibrium is implausible (if player 1 moves first) because player 1 will play S', forcing the response (say) B' from player 2 and thereby attaining the second equilibrium (regardless of the preferences of player 2 over the equilibria). The first equilibrium is subgame imperfect because B does not constitute a best response to S' once S' has been played, i.e. in the subgame reached by player 1 playing S', B is not optimal for player 2.

If not all strategies at a particular node were available in a subgame containing that node, it would be unhelpful in subgame perfection. One could trivially call an equilibrium subgame perfect by ignoring playable strategies to which a strategy was not a best response. Furthermore, if subgames cut across information sets, then a Nash equilibrium in a subgame might suppose a player had information in that subgame, he did not have in the larger game.

==References==
{{reflist}}

{{Game theory}}

[[Category:Game theory]]

[[de:Teilspiel]]</text>
      <sha1>jvex3kd68d0rssuzl48flu3zk83k3hv</sha1>
    </revision>
  </page>
  <page>
    <title>Table of costs of operations in elliptic curves</title>
    <ns>0</ns>
    <id>25944272</id>
    <revision>
      <id>740292713</id>
      <parentid>740136439</parentid>
      <timestamp>2016-09-20T05:01:01Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fix for #03.  Missing Reflist.  Do [[Wikipedia:GENFIXES|general fixes]] if a problem exists. -</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6264">{{Multiple issues|
{{Technical|date=February 2010}}
{{refimprove|date=May 2014}}
}}

[[Elliptic curve cryptography]] is a popular form of [[public key]] encryption that is based on the mathematical theory of [[elliptic curve]]s. Points on an elliptic curve can be added and form a [[group (mathematics)|group]] under this addition operation. This article describes the computational costs for this group addition and certain related operations that are used in elliptic curve cryptography algorithms.

==Abbreviations for the operations==

The next section presents a table of all the time-costs of some of the possible operations in elliptic curves. The columns of the table are labelled by various computational operations. The rows of the table are for different models of elliptic curves. These are the operations considered :
&lt;poem&gt;
DBL - Doubling
ADD - Addition
mADD - Mixed addition: addition of an input that has been scaled to have ''Z''-coordinate 1.
mDBL - Mixed doubling: doubling of an input that has been scaled to have ''Z'' coordinate 1.
TPL - Tripling.
DBL+ADD - Combined double and add step
&lt;/poem&gt;

To see how adding (ADD) and doubling (DBL) points on elliptic curves are defined, see  [[elliptic curve#The group law|The group law]]. The importance of doubling to speed scaler multiplication is discussed after the table. For information about other possible operations on elliptic curves see http://hyperelliptic.org/EFD/g1p/index.html.

==Tabulation==

Under different assumptions on the multiplication, addition, inversion for the elements in some fixed [[field (mathematics)|field]], the time-cost of these operations varies.
In this table it is assumed that:

: I = 100M, S = 1M, *param = 0M, add = 0M, *const = 0M

This means that 100 multiplications (M) are required to invert (I) an element; one multiplication is required to compute the square (S) of an element; no multiplication is needed to multiply an element by a parameter (*param), by a constant (*const), or to add two elements.

For more information about other results obtained with different assumptions, see http://hyperelliptic.org/EFD/g1p/index.html

{| class="wikitable"
|-
! Curve shape, representation
! DBL
! ADD
!mADD
!mDBL
!TPL
!DBL+ADD
|-
|align=center|[[Elliptic curve|Short Weierstrass projective]]
|11
|14
|11
|8
|
|
|-
|align=center|[[Elliptic curve|Short Weierstrass projective with a4=-1]]
|11
|14
|11
|8
|
|
|-
|align=center|[[Elliptic curve|Short Weierstrass projective with a4=-3]]
|10
|14
|11
|8
|
|
|-
|align=center|Short Weierstrass Relative Jacobian&lt;ref&gt;{{Cite journal|last=Fay|first=Björn|date=2014-12-20|title=Double-and-Add with Relative Jacobian Coordinates|url=http://eprint.iacr.org/2014/1014|journal=Cryptology ePrint Archive|volume=|issue=|doi=|pmid=|access-date=|via=}}&lt;/ref&gt;
|10
|11
|(7)
|(7)
|
|18
|-
| align="center" |[[Tripling-oriented Doche–Icart–Kohel curve]]
|9
|17
|11
|6
|12
|
|-
| align="center" |[[Hessian curve#Extended coordinates|Hessian curve extended]]
|9
|12
|11
|9
|
|
|-
| align="center" |[[Hessian curves|Hessian curve projective]]
|8
|12
|10
|6
|14
|
|-
| align="center" |[[Jacobian curve#Alternative coordinates for the Jacobi quartic|Jacobi quartic XYZ]]
|8
|13
|11
|5
|
|
|-
| align="center" |[[Jacobian curve#Alternative coordinates for the Jacobi quartic|Jacobi quartic doubling-oriented XYZ]]
|8
|13
|11
|5
|
|
|-
| align="center" |[[Twisted Hessian curves|Twisted Hessian curve projective]]
|8
|12
|12
|8
|14
|
|-
| align="center" |[[Doubling-oriented Doche–Icart–Kohel curve]]
|7
|17
|12
|6
|
|
|-
| align="center" |[[Jacobian curve|Jacobi intersection projective]]
|7
|14
|12
|6
|14
|
|-
| align="center" |[[Jacobian curve#Extended coordinates|Jacobi intersection extended]]
|7
|12
|11
|7
|16
|
|-
| align="center" |[[Twisted Edward Curves|Twisted Edwards projective]]
|7
|11
|10
|6
|
|
|-
| align="center" |[[Twisted Edward Curves|Twisted Edwards Inverted]]
|7
|10
|9
|6
|
|
|-
| align="center" |[[Twisted Edward Curves|Twisted Edwards Extended]]
|8
|9
|8
|7
|
|
|-
| align="center" |[[Edwards curves|Edwards projective]]
|7
|11
|9
|6
|13
|
|-
| align="center" |[[Jacobian curve#Alternative coordinates for the Jacobi quartic|Jacobi quartic doubling-oriented XXYZZ]]
|7
|11
|9
|6
|14
|
|-
| align="center" |[[Jacobian curve#Alternative coordinates for the Jacobi quartic|Jacobi quartic XXYZZ]]
|7
|11
|9
|6
|14
|
|-
| align="center" |[[Jacobian curve#Alternative coordinates for the Jacobi quartic|Jacobi quartic XXYZZR]]
|7
|10
|9
|7
|15
|
|-
| align="center" |[[Edwards curve#Inverted Edwards coordinates|Edwards curve inverted]]
|7
|10
|9
|6
|
|
|-
| align="center" |[[Montgomery curve]]
|4
|
|
|3
|
|
|}

==Importance of doubling==
In some applications of [[elliptic curve cryptography]] and the elliptic curve method of factorization ([[Lenstra elliptic curve factorization|ECM]]) it is necessary to consider the scalar multiplication [''n'']''P''. One way to do this is to compute successively:

: &lt;math&gt; P,\quad [2]P=P+P,\quad [3]P=[2]P+P,  \dots  , [n]P=[n-1]P+P &lt;/math&gt;

But it is faster to use [[Exponentiation by squaring|double-and-add method]], e.g. [5]''P'' = [2]([2]P) + ''P''.
In general to compute [''k'']''P'', write

&lt;math&gt; k=\sum_{i\le l}k_i2^i &lt;/math&gt;

with ''k''&lt;sub&gt;''i''&lt;/sub&gt; in {0,1} and &lt;math&gt;l=[log_2 k]&lt;/math&gt;, ''k''&lt;sub&gt;''l''&lt;/sub&gt; = 1, then:

&lt;math&gt; [2](....([2]([2]([2]([2]([2]P+[k_{(l-1)}]P)+[k_{(l-2)}]P)+[k_{(l-3)}]P)+ \dots ) \dots +[k_1]P)+[k_0]P= 
 [2^l]P+[k_{(l-1)}2^{l-1}]P+ \dots  +[k_12]P+[k_0]P &lt;/math&gt;.

Note that, this simple algorithm takes at most ''2l'' steps and each step consists of a doubling and (if ''k''&lt;sub&gt;''i''&lt;/sub&gt; &amp;ne; 0) adding two points. So, this is one of the reasons why addition and doubling formulas are defined.
Furthermore, this method is applicable to any group and if the group law is written multiplicatively, the double-and-add algorithm is instead called [[Exponentiation by squaring|square-and-multiply algorithm]].

==References==
{{Reflist}}
*http://hyperelliptic.org/EFD/g1p/index.html

{{DEFAULTSORT:Table Of Costs Of Operations In Elliptic Curves}}
[[Category:Elliptic curve cryptography]]
[[Category:Finite fields]]
[[Category:Computational number theory]]
[[Category:Cryptographic attacks]]
[[Category:Elliptic curves]]</text>
      <sha1>gevz17qeoaz134jx2ov74k3sn50b5dk</sha1>
    </revision>
  </page>
  <page>
    <title>Term (logic)</title>
    <ns>0</ns>
    <id>24885593</id>
    <revision>
      <id>870519631</id>
      <parentid>870519628</parentid>
      <timestamp>2018-11-25T10:05:20Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/2600:1:F420:186E:C4E9:1C1E:83BB:5015|2600:1:F420:186E:C4E9:1C1E:83BB:5015]] to version by 2A00:23C6:7F80:C000:BF:6FEE:E14:5B27. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3546980) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21064">{{redirect|Term (mathematics)|the concept in quantum mechanics|Term symbol}}
In analogy to natural language, where a [[noun phrase]] refers to an object and a whole [[Sentence (linguistics)|sentence]] refers to a fact, in [[mathematical logic]], a '''term''' denotes a mathematical object and a [[Formula (mathematical logic)|formula]] denotes a mathematical fact. In particular, terms appear as components of a formula.

A [[first-order logic|first-order]] term is [[recursive definition|recursively constructed]] from constant symbols, [[Variable (mathematics)|variables]] and [[function symbol (logic)|function symbols]].
An expression formed by applying a [[predicate (logic)|predicate symbol]] to an appropriate number of terms is called an [[atomic formula]], which evaluates to [[Truth#Truth in mathematics|true]] or [[False (logic)|false]] in [[Principle of bivalence|bivalent logics]], given an [[interpretation (logic)|interpretation]].
For example, {{tmath|(x+1)*(x+1)}} is a term built from the constant 1, the variable {{mvar|x}}, and the binary function symbols {{tmath|+}} and {{tmath|*}}; it is part of the atomic formula {{tmath|(x+1)*(x+1) \ge 0}} which evaluates to true for each [[real number|real-numbered]] value of {{mvar|x}}.

Besides in [[logic]], terms play important roles in [[universal algebra]], and [[rewriting system]]s.

==Elementary mathematics==
In the context of [[polynomial]]s, sometimes ''term'' is used for a [[monomial]] with a [[coefficient]]: to 'collect [[Like and unlike terms|like terms]]' in a polynomial is the [[Operation (mathematics)|operation]] of making it a [[linear combination]] of [[distinct (mathematics)|distinct]] monomials.  Terms, in this sense, are things that are added or subtracted.
A [[Series (mathematics)|series]] is often represented as the sum of a [[sequence]] of terms. 
Individual factors in an expression representing a product are [[Multiplication#Notation and terminology|multiplicative term]]s. 
For example, in {{math|6&amp;nbsp;+&amp;nbsp;3''x''&amp;nbsp;&amp;minus;&amp;nbsp;2}}, we have that {{math|6, 3''x''}}, and {{math|&amp;minus;2}} are all terms.

In elementary mathematics,&lt;ref&gt;{{cite book | first=Steven | last=Schwartzman | title=The words of mathematics: An etymological dictionary of mathematical terms used in English | pages=219 | publisher=The Mathematical Association of America | year=1994 | isbn=0-88385-511-9}}&lt;/ref&gt; 
* each argument term of the addition operator + is called an ''[[addend]]'',
* the first and second argument term of the subtraction operator - is called a ''[[minuend]]'' and ''[[subtrahend]]'', respectively,
* each argument term of the multiplication operator ⋅ is called a ''factor'', the first and second argument term is also called ''multiplicand'' and ''multiplier'', respectively,
* the first and second argument term of the division operator / is called ''dividend'' and ''[[divisor]]'', respectively,
* if the division operator is written as [[Fraction (mathematics)#Common.2C vulgar.2C or simple fractions|fraction bar]], the top and bottom terms are called ''numerator'' and ''denominator'', respectively.

==Formal definition==
[[File:Tree structure of mathematical first-order terms svg.svg|thumb|Tree structure of terms (''n''⋅(''n''+1))/2 and ''n''⋅((''n''+1)/2)]]

Given a set ''V'' of variable symbols, a set ''C'' of constant symbols and sets ''F''&lt;sub&gt;''n''&lt;/sub&gt; of ''n''-ary function symbols, also called operator symbols, for each natural number ''n'' ≥ 1, the set of (unsorted first-order) terms ''T'' is [[recursive definition|recursively defined]] to be the smallest set with the following properties:&lt;ref&gt;{{cite book| author1=C.C. Chang| author2= H. Jerome Keisler|author1link=Chen Chung Chang |author2link=H. Jerome Keisler | title=Model Theory| year=1977| volume=73| publisher=North Holland| series=Studies in Logic and the Foundation of Mathematics}}; here: Sect.1.3&lt;/ref&gt;
* every variable symbol is a term: ''V'' ⊆ ''T'',
* every constant symbol is a term: ''C'' ⊆ ''T'',
* from every ''n'' terms ''t''&lt;sub&gt;1&lt;/sub&gt;,...,''t''&lt;sub&gt;''n''&lt;/sub&gt;, and every ''n''-ary function symbol ''f'' ∈ ''F''&lt;sub&gt;''n''&lt;/sub&gt;, a larger term ''f''(''t''&lt;sub&gt;1&lt;/sub&gt;, ..., ''t''&lt;sub&gt;''n''&lt;/sub&gt;) can be built.
Using an intuitive, pseudo-[[Grammar formalism#Formal definition|grammatical]] notation, this is sometimes written as:
''t'' ::= ''x'' | ''c'' | ''f''(''t''&lt;sub&gt;1&lt;/sub&gt;, ..., ''t''&lt;sub&gt;''n''&lt;/sub&gt;).
Usually, only the first few function symbol sets ''F''&lt;sub&gt;''n''&lt;/sub&gt; are inhabited. Well-known examples are the unary function symbols ''sin'', ''cos'' ∈ ''F''&lt;sub&gt;1&lt;/sub&gt;, and the binary function symbols +, −, ⋅, / ∈ ''F''&lt;sub&gt;2&lt;/sub&gt;, while [[ternary operation]]s are less known, let alone higher-arity functions. Many authors consider constant symbols as 0-ary function symbols ''F''&lt;sub&gt;0&lt;/sub&gt;, thus needing no special syntactic class for them.

A term denotes a mathematical object from the [[domain of discourse]]. A constant ''c'' denotes a named object from that domain, a variable ''x'' ranges over the objects in that domain, and an ''n''-ary function ''f'' maps ''n''-[[tuple]]s of objects to objects. For example, if ''n'' ∈ ''V'' is a variable symbol, 1 ∈ ''C'' is a constant symbol, and ''add'' ∈ ''F''&lt;sub&gt;2&lt;/sub&gt; is a binary function symbol, then ''n'' ∈ ''T'', 1 ∈ ''T'', and (hence) ''add''(''n'', 1) ∈ ''T'' by the first, second, and third term building rule, respectively. The latter term is usually written as ''n''+1, using [[infix notation]] and the more common operator symbol + for convenience.

===Term structure vs. representation===
Originally, logicians defined a term to be a ''character string'' adhering to certain building rules.&lt;ref&gt;{{cite book|first1=Hans|last1=Hermes|authorlink=Hans Hermes| title=Introduction to Mathematical Logic|publisher=Springer London|issn=1431-4657|isbn=3540058192|year=1973}}; here: Sect.II.1.3&lt;/ref&gt; However, since the concept of [[Tree (data structure)|tree]] became popular in computer science, it turned out to be more convenient to think of a term as a tree. For example, several distinct character strings, like "{{math|(''n''⋅(''n''+1))/2}}",  "{{math|((''n''⋅(''n''+1)))/2}}", and "&lt;math&gt;\frac{n(n+1)}{2}&lt;/math&gt;", denote the same term and correspond to the same tree, viz. the left tree in the above picture.
Separating the tree structure of a term from its graphical representation on paper, it is also easy to account for parentheses (being only representation, not structure) and invisible multiplication operators (existing only in structure, not in representation).

===Structural equality===
Two terms are said to be '''structurally''', '''literally''', or '''syntactically''' equal if they correspond to the same tree. For example, the left and the right tree in the above picture are structurally '''un'''equal terms, although they might be considered "'''semantically equal'''" as they always evaluate to the same value in [[Rational number#Arithmetic|rational arithmetic]]. While structural equality can be checked without any knowledge about the meaning of the symbols, semantic equality cannot. If the function / is e.g. interpreted not as rational but as  [[integer division#Of integers|truncating integer]] division, then at ''n''=2 the left and right term evaluates to 3 and 2, respectively.
Structural equal terms need to agree in their variable names.

In contrast, a term ''t'' is called a '''renaming''', or a '''variant''', of a term ''u'' if the latter resulted from consistently renaming all variables of the former, i.e. if ''u'' = ''tσ'' for some [[Substitution (logic)#First-order logic|renaming substitution]] σ. In that case, ''u'' is a renaming of ''t'', too, since a renaming substitution σ has an inverse σ&lt;sup&gt;−1&lt;/sup&gt;, and ''t'' = uσ&lt;sup&gt;−1&lt;/sup&gt;. Both terms are then also said to be '''equal modulo renaming'''. In many contexts, the particular variable names in a term don't matter, e.g. the commutativity axiom for addition can be stated as ''x''+''y''=''y''+''x'' or as ''a''+''b''=''b''+''a''; in such cases the whole formula may be renamed, while an arbitrary subterm usually may not, e.g. ''x''+''y''=''b''+''a'' is not a valid version of the commutativity axiom.&lt;ref group=note&gt;Since atomic formulas can be viewed as trees, too, and renaming is essentially a concept on trees, atomic (and, more generally, [[Quantifier-free formula#Predicate logic|quantifier-free]]) formulas can be renamed in a similar way as terms. In fact, some authors consider a quantifier-free formula as a term (of type ''bool'' rather than e.g. ''int'', cf. [[#Sorted terms]] below).&lt;/ref&gt;
&lt;ref group=note&gt;Renaming of the commutativity axiom can be viewed as [[Lambda calculus#.CE.B1-conversion|alpha-conversion]] on the [[Universal quantification#Universal closure|universal closure]] of the axiom: "''x''+''y''=''y''+''x''" actually means "∀''x'',''y'': ''x''+''y''=''y''+''x''", which is synonymous to "∀''a'',''b'': ''a''+''b''=''b''+''a''"; see also [[#Lambda terms]] below.&lt;/ref&gt;

===Ground and linear terms===
The set of variables of a term ''t'' is denoted by ''vars''(''t'').
A term that doesn't contain any variables is called a '''[[ground term]]'''; a term that doesn't contain multiple occurrences of a variable is called a '''linear term'''.
For example, 2+2 is a ground term and hence also a linear term, ''x''⋅(''n''+1) is a linear term, ''n''⋅(''n''+1) is a non-linear term. These properties are important in, for example, [[term rewriting]].

Given a [[signature (logic)|signature]] for the function symbols, the set of all &lt;!---redundant: possible---&gt; terms &lt;!---redundant: that can be freely generated from the constants, variables and functions---&gt; forms the '''[[Free object|free]] [[term algebra]]'''. The set of all ground terms forms the '''[[initial algebra|initial]] term algebra'''.

Abbreviating the number of constants as ''f''&lt;sub&gt;0&lt;/sub&gt;, and the number of ''i''-ary function symbols as ''f''&lt;sub&gt;''i''&lt;/sub&gt;, the '''number θ&lt;sub&gt;''h''&lt;/sub&gt; of distinct ground terms'''  of a height up to ''h'' can be computed by the following recursion formula:
* θ&lt;sub&gt;0&lt;/sub&gt; = ''f''&lt;sub&gt;0&lt;/sub&gt;, since a ground term of height 0 can only be a constant,
* &lt;math&gt;\theta_{h+1} = \sum_{i=0}^\infty f_i \cdot \theta_h^i&lt;/math&gt;, since a ground term of height up to ''h''+1 can be obtained by composing any ''i'' ground terms of height up to ''h'', using an ''i''-ary root function symbol. The sum has a finite value if there is only a finite number of constants and function symbols, which is usually the case.

===Building formulas from terms===

Given a set ''R''&lt;sub&gt;''n''&lt;/sub&gt; of ''n''-ary relation symbols for each natural number ''n'' ≥ 1, an (unsorted first-order) atomic formula is obtained by applying an ''n''-ary relation symbol to ''n'' terms. As for function symbols, a relation symbol set ''R''&lt;sub&gt;''n''&lt;/sub&gt; is usually non-empty only for small ''n''. In mathematical logic, more complex [[First-order logic#Formulas|formulas]] are built from atomic formulas using [[logical connective]]s and [[Quantifier (logic)|quantifiers]]. For example, letting ℝ denote the set of [[real number]]s, ∀''x'': ''x'' ∈ ℝ ⇒ (''x''+1)⋅(''x''+1) ≥ 0 is a mathematical formula evaluating to true in the algebra of [[complex number]]s.
An atomic formula is called ground if it is built entirely from ground terms; all ground atomic formulas composable from a given set of function and predicate symbols make up the [[Herbrand universe#Herbrand base|Herbrand base]] for these symbol sets.

==Operations with terms==
[[File:Example term for position, path, depth, match svg.svg|thumb|Tree structure of black example term &lt;math&gt;\frac{a*((a+1)*(a+2))}{1*(2*3)}&lt;/math&gt;, with blue redex {{tmath|x*(y*z)}}]]
 
* Since a term has the structure of a tree hierarchy, to each of its nodes a '''position''', or '''path''', can be assigned, that is, a string of natural numbers indicating the node's place in the hierarchy. The empty string, commonly denoted by ε, is assigned to the root node. Position strings within the black term are indicated in red in the picture.
* At each position ''p'' of a term ''t'', a unique '''subterm''' starts, which is commonly denoted by {{math|''t''{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}}. For example, at position 122 of the black term in the picture, the subterm ''a''+2 has its root. The relation ''"is a subterm of"'' is a [[partial order]] on the set of terms; it is [[reflexive relation|reflexive]] since each term is trivially a subterm of itself. 
* The term obtained by '''replacing''' in a term ''t'' the subterm at a position ''p'' by a new term ''u'' is commonly denoted by {{math|''t''[''u'']&lt;sub&gt;''p''&lt;/sub&gt;}}. The term {{math|''t''[''u'']&lt;sub&gt;''p''&lt;/sub&gt;}} can also be viewed as resulting from a generalized concatenation of the term ''u'' with a term-like object {{math|''t''[.]}}; the latter is called a '''context''', or a '''term with a hole''' (indicated by "."; its position being ''p''), in which ''u'' is said to be '''embedded'''. For example, if ''t'' is the black term in the picture, then {{math|''t''[''b''+1]&lt;sub&gt;12&lt;/sub&gt;}} results in the term &lt;math&gt;\frac{a*(b+1)}{1*(2*3)}&lt;/math&gt;.  The latter term also results from embedding the term {{math|''b''+1}} into the context &lt;math&gt;\frac{a*(\; . \;)}{1*(2*3)}&lt;/math&gt;. In an informal sense, the operations of [[substitution (logic)#First-order logic|instantiating]] and embedding are converse to each other: while the former appends function symbols at the bottom of the term, the latter appends them at the top. The [[encompassment ordering]] relates a term and any result of appends on both sides.
* To each node of a term, its '''depth''' (called '''height''' by some authors) can be assigned, i.e. its distance (number of edges) from the root. In this setting, the depth of a node always equals the length of its position string. In the picture, depth levels in the black term are indicated in green.
* The '''size''' of a term commonly refers to the number of its nodes, or, equivalently, to the length of the term's written representation, counting symbols without parentheses. The black and the blue term in the picture has the size 15 and 5, respectively.
* A term ''u'' '''matches''' a term ''t'', if a substitution instance of ''u'' structurally equals a subterm of ''t'', or formally, if {{math|1=''u''σ = ''t''{{!}}&lt;sub&gt;''p''&lt;/sub&gt;}} for some position ''p'' in ''t'' and some substitution σ. In this case, ''u'', ''t'', and σ are called the '''pattern term''', the '''subject term''', and the '''matching substitution''', respectively. In the picture, the blue pattern term {{tmath|x*(y*z)}} matches the black subject term at position 1, with the matching substitution {{math| { ''x'' ↦ ''a'', ''y'' ↦ ''a''+1, z ↦ ''a''+2 } }} indicated by blue variables immediately left to their black substitutes. Intuitively, the pattern, except for its variables, must be contained in the subject; if a variable occurs multiply in the pattern, equal subterms are required at the respective positions of the subject.
* [[Unification (computer science)#Syntactic unification of first-order terms|unifying terms]]
* [[Term rewriting#Term rewriting systems|term rewriting]]

==Related concepts==

===Sorted terms===
{{main|Many-sorted logic}}
When the domain of discourse contains elements of basically different kinds, it is useful to split the set of all terms accordingly. To this end, a '''sort''' (sometimes also called '''type''') is assigned to each variable and each constant symbol, and a declaration &lt;ref group=note&gt;I.e., "symbol type" in the [[Signature (logic)#Many-sorted signatures|Many-sorted signatures]] section of the Signature (logic) article.&lt;/ref&gt; of domain sorts and range sort to each function symbol. A '''sorted term''' ''f''(''t''&lt;sub&gt;1&lt;/sub&gt;,...,''t''&lt;sub&gt;''n''&lt;/sub&gt;) may be composed from sorted subterms ''t''&lt;sub&gt;1&lt;/sub&gt;,...,''t''&lt;sub&gt;''n''&lt;/sub&gt; only if the {{mvar|i}}th subterm's sort matches the declared {{mvar|i}}th domain sort of ''f''. Such a term is also called '''well-sorted'''; any other term (i.e. obeying the [[#formal definition|unsorted rules]] only) is called '''ill-sorted'''.

For example, a [[vector space#Definition|vector space]] comes with an associated [[field (mathematics)|field]] of scalar numbers. Let ''W'' and ''N'' denote the sort of vectors and numbers, respectively, let ''V''&lt;sub&gt;''W''&lt;/sub&gt; and ''V''&lt;sub&gt;''N''&lt;/sub&gt; be the set of vector and number variables, respectively, and ''C''&lt;sub&gt;''W''&lt;/sub&gt; and ''C''&lt;sub&gt;''N''&lt;/sub&gt; the set of vector and number constants, respectively. Then e.g. &lt;math&gt;\vec{0} \in C_W&lt;/math&gt; and {{math|0 ∈ ''C''&lt;sub&gt;''N''&lt;/sub&gt;}}, and the vector addition, the scalar multiplication, and the inner product is declared as {{tmath|+:W \times W \to W, *:W \times N \to W}}, and {{tmath|\langle .,. \rangle: W \times W \to N}}, respectively. Assuming variable symbols &lt;math&gt;\vec{v},\vec{w} \in V_W&lt;/math&gt; and {{math|''a'',''b'' ∈ ''V''&lt;sub&gt;''N''&lt;/sub&gt;}}, the term &lt;math&gt;\langle (\vec{v}+\vec{0})*a,\vec{w}*b \rangle&lt;/math&gt; is well-sorted, while &lt;math&gt;\vec{v}+a&lt;/math&gt; is not (since + doesn't accept a term of sort ''N'' as 2nd argument). In order to make &lt;math&gt;a*\vec{v}&lt;/math&gt; a well-sorted term, an additional declaration {{tmath|*:N \times W \to W}} is required. Function symbols having several declarations are called '''overloaded'''.

See [[many-sorted logic]] for more information, including extensions of the '''many-sorted framework''' described here.

===Lambda terms===

{| class="wikitable" style="float: right;"
|+ Terms with bound variables
|- 
! Notation &lt;br/&gt; example  !! Bound &lt;br/&gt; variables !! Free &lt;br/&gt; variables !! Written as &lt;br/&gt; lambda-term
|-
| {{math|{{underset|''n''→∞|lim}} ''x''/''n''}} || ''n'' || ''x'' || ''limit''(λ''n''. ''div''(''x'',''n''))
|-
| &lt;math&gt;\sum_{i=1}^n i^2 &lt;/math&gt;|| ''i'' || ''n'' || ''sum''(1,''n'',λ''i''. ''power''(''i'',2))
|-
| &lt;math&gt;\int_a^b \sin(k \cdot t) dt&lt;/math&gt; || ''t'' || ''a'', ''b'', ''k'' || ''integral''(''a'',''b'',λ''t''. ''sin''(''k''⋅''t''))
|}
{{main|Lambda term}}

====Motivation====
Mathematical notations as shown in the table do not fit into the scheme of a first-order term as defined [[#Formal definition|above]], as they all introduce an own '''local''', or '''bound''', variable that may not appear outside the notation's scope, e.g. &lt;math&gt;t \cdot \int_a^b \sin(k \cdot t) \; dt&lt;/math&gt; doesn't make sense. 
In contrast, the other variables, referred to as '''free''', behave like ordinary first-order term variables, e.g. &lt;math&gt;k \cdot \int_a^b \sin(k \cdot t) \; dt&lt;/math&gt; does make sense.

All these operators can be viewed as taking a function rather than a value term as one of their arguments. For example, the ''lim'' operator is applied to a sequence, i.e. to a mapping from positive integer to e.g. real numbers. As another example, a [[C (programming language)|C]] function to implement the second example from the table, ∑, would have a function pointer argument (see box below).

'''[[Lambda term]]s''' can be used to denote '''[[anonymous function]]s''' to be supplied as arguments to ''lim'', ∑, ∫, etc.

For example, the function ''square'' from the C program below can be written anonymously as a lambda term λ''i''. ''i''&lt;sup&gt;2&lt;/sup&gt;. The general sum operator ∑ can then be considered as a ternary function symbol taking a lower bound value, an upper bound value and a function to be summed-up. Due to its latter argument, the ∑ operator is called a '''second-order function symbol'''.
As another example, the lambda term λ''n''. ''x''/''n'' denotes a function that maps 1, 2, 3, ... to ''x''/1, ''x''/2, ''x''/3, ..., respectively, that is, it denotes the [[Sequence#Definition|sequence]] (''x''/1, ''x''/2, ''x''/3, ...). The ''lim'' operator takes such a sequence and returns its limit (if defined).

The rightmost column of the table indicates how each mathematical notation example can be represented by a lambda term, also converting common [[Infix notation|infix]] operators into [[Polish notation|prefix]] form.

&lt;source lang="C"&gt;
int sum(int lwb, int upb, int fct(int)) {    // implements general sum operator
    int res = 0;
    for (int i=lwb; i&lt;=upb; ++i)
        res += fct(i);
    return res;
}

int square(int i) { return i*i; }            // implements anonymous function (lambda i. i*i); however, C requires a name for it

#include &lt;stdio.h&gt;
int main(void) {
    int n;
    scanf(" %d",&amp;n);
    printf("%d\n", sum(1,n,square) );        // applies sum operator to sum up squares
    return 0;
}
&lt;/source&gt;

==See also==
* [[Equation]]
* [[Expression (mathematics)]]

== Notes==
{{Reflist|group=note}}

== References ==
* {{cite book|author1=Franz Baader|author2=Tobias Nipkow|authorlink1=Franz Baader|authorlink2=Tobias Nipkow|title=Term Rewriting and All That|year=1999|publisher=Cambridge University Press|isbn=978-0-521-77920-3|pages=1–2 and 34–35}}
{{Reflist}}

[[Category:Mathematical logic]]
[[Category:Rewriting systems]]
[[Category:Elementary mathematics]]</text>
      <sha1>cewlzv5xsb890vglx7rsgeet5um21vj</sha1>
    </revision>
  </page>
  <page>
    <title>Traced monoidal category</title>
    <ns>0</ns>
    <id>7984007</id>
    <revision>
      <id>711460091</id>
      <parentid>673633165</parentid>
      <timestamp>2016-03-23T00:41:02Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>/* Properties */Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2822">In [[category theory]], a '''traced monoidal category''' is a category with some extra structure which gives a reasonable notion of feedback.

A '''traced symmetric monoidal category''' is a [[symmetric monoidal category]] '''C''' together with a family of functions
:&lt;math&gt;\mathrm{Tr}^U_{X,Y}:\mathbf{C}(X\otimes U,Y\otimes U)\to\mathbf{C}(X,Y)&lt;/math&gt;
called a ''trace'', satisfying the following conditions (where we sometimes denote an identity morphism by the corresponding object, e.g., using  ''U'' to denote &lt;math&gt;\text{id}_U&lt;/math&gt;):
* naturality in ''X'': for every &lt;math&gt;f:X\otimes U\to Y\otimes U&lt;/math&gt; and &lt;math&gt;g:X'\to X&lt;/math&gt;,
::&lt;math&gt;\mathrm{Tr}^U_{X,Y}(f)g=\mathrm{Tr}^U_{X',Y}(f(g\otimes U))&lt;/math&gt;

[[Image:Trace diagram naturality 1.svg|thumb|center|400px|Naturality in X]]

* naturality in ''Y'': for every &lt;math&gt;f:X\otimes U\to Y\otimes U&lt;/math&gt; and &lt;math&gt;g:Y\to Y'&lt;/math&gt;,
::&lt;math&gt;g\mathrm{Tr}^U_{X,Y}(f)=\mathrm{Tr}^U_{X,Y'}((g\otimes U)f)&lt;/math&gt;

[[Image:Trace diagram naturality 2.svg|thumb|center|400px|Naturality in Y]]

* dinaturality in ''U'': for every &lt;math&gt;f:X\otimes U\to Y\otimes U'&lt;/math&gt; and &lt;math&gt;g:U'\to U&lt;/math&gt;
::&lt;math&gt;\mathrm{Tr}^U_{X,Y}((Y\otimes g)f)=\mathrm{Tr}^{U'}_{X,Y}(f(X\otimes g))&lt;/math&gt;

[[Image:Trace diagram dinaturality.svg|thumb|center|400px|Dinaturality in U]]

* vanishing I: for every &lt;math&gt;f:X\otimes I\to Y\otimes I&lt;/math&gt;,
::&lt;math&gt;\mathrm{Tr}^I_{X,Y}(f)=f&lt;/math&gt;

[[Image:Trace diagram vanishing.svg|thumb|center|400px|Vanishing I]]

* vanishing II: for every &lt;math&gt;f:X\otimes U\otimes V\to Y\otimes U\otimes V&lt;/math&gt;
::&lt;math&gt;\mathrm{Tr}^{U\otimes V}_{X,Y}(f)=\mathrm{Tr}^U_{X,Y}(\mathrm{Tr}^V_{X\otimes U,Y\otimes U}(f))&lt;/math&gt;

[[Image:Trace diagram associativity.svg|thumb|center|400px|Vanishing II]]

* superposing: for every &lt;math&gt;f:X\otimes U\to Y\otimes U&lt;/math&gt; and &lt;math&gt;g:W\to Z&lt;/math&gt;,
::&lt;math&gt;g\otimes \mathrm{Tr}^U_{X,Y}(f)=\mathrm{Tr}^U_{W\otimes X,Z\otimes Y}(g\otimes f)&lt;/math&gt;

[[Image:Trace diagram superposition.svg|thumb|center|400px|Superposing]]

* yanking:
::&lt;math&gt;\mathrm{Tr}^X_{X,X}(\gamma_{X,X})=X&lt;/math&gt;
(where &lt;math&gt;\gamma&lt;/math&gt; is the symmetry of the monoidal category).

[[Image:Trace diagram yanking.svg|thumb|center|400px|Yanking]]

== Properties ==
* Every [[compact closed category]] admits a trace.
* Given a traced monoidal category '''C''', the ''Int construction'' generates the free (in some bicategorical sense) compact closure Int('''C''') of '''C'''.

== References ==
* {{cite journal
 | author = [[André Joyal]], [[Ross Street]], [[Dominic Verity]]
 | year = 1996
 | title = Traced monoidal categories
 | journal = Mathematical Proceedings of the Cambridge Philosophical Society
 | volume = 3
 | pages = 447–468
 | doi = 10.1017/S0305004100074338
 }}

[[Category:Monoidal categories]]


{{categorytheory-stub}}</text>
      <sha1>l8a1wqpsnlnrl5ihh2cetxm3vs3ejgx</sha1>
    </revision>
  </page>
  <page>
    <title>Ute Finckh-Krämer</title>
    <ns>0</ns>
    <id>59008046</id>
    <revision>
      <id>869271087</id>
      <parentid>868778943</parentid>
      <timestamp>2018-11-17T15:08:44Z</timestamp>
      <contributor>
        <username>EmausBot</username>
        <id>11292982</id>
      </contributor>
      <minor/>
      <comment>Bot: Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:Q15449253]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5525">{{refimprove BLP|date=November 2018}}
{{Infobox writer &lt;!-- for more information see [[:Template:Infobox writer/doc]] --&gt;
| name         = Finckh-Krämer, Ute
| image = Finckh-Krämer, Ute-8960.jpg
| imagesize = 200px
| caption      = Ute Finckh-Krämer (2014)
| birth_date   = December 16, 1956
| birth_place  = Weisbaden
| death_date   = 
| occupation   = [[Mathematician]]
| citizenship  = German
| notableworks = 
| awards       = 
| influenced   =
| spouse       = 
| children     = 2
}}

'''Ute Elisabeth Finckh-Krämer''' (born December 16, 1956 in [[Wiesbaden]]) is a German [[politician]] in ([[SPD]]) and [[pacifism|pacifist]]. She was a board member of the Federal Social Defense League and served as one of its chairpersons from March 2005 to March 201. In September 2013, she moved to the [[Berlin]] Landesliste in the [[German Bundestag]], which she served until October 2017.

== Education and Profession ==
Finckh-Krämer graduated from the Altes Gymnasium (Bremen) in May 1974 and studied [[mathematics]] with a minor in [[physics]] at the University of Erlangen-Nuremberg. In the summer semester of 1977, she moved to the University of Tübingen, where she graduated in April 1981 with a degree in mathematics. In the year 1986, she obtained her [[doctorate|doctoral degree]] in Tübingen with the dissertation
'' Beiträge zur Wahrscheinlichkeitstheorie auf einer Kingman-Struktur '' under Herbert Heyer.&lt;ref name="nodak"&gt;{{cite web|url=https://www.genealogy.math.ndsu.nodak.edu/id.php?id=26634|title=Ute Finckh-Krämer - The Mathematics Genealogy Project|website=genealogy.math.ndsu.nodak.edu|accessdate=2018-11-09}}&lt;/ref&gt; She first worked as a lecturer in adult and further education in 1987 then worked in the German Central Register for Child Hearing Disorders from 1994 to 2000. She has been a consultant in the Press and Information Office of the Federal Government since September 2001.

== Peace Movement ==
Finckh-Krämer has been active since her student days, having participated in, among other things, the blockade in [[Großengstingen]] in the summer of 1982 and participated in a blockade in [[Mutlangen]] in the summer of 1984. In 1989, she co-founded [[Minden]] / Westphalia with the Bund für Soziale Defense (BSV). She is active for the BSV in the Civil Conflict Transformation Platform.

== SPD Membership ==
Finckh-Krämer joined the [[SPD]] at the age of 16. From 1996 to 2002 she was a departmental cashier, then from 2002 to 2008 she was district cashier in the SPD district of Steglitz-Zehlendorf (Berlin) and from 2000 to 2002 a member of the board of directors of this circle as well as in the year 2009 campaign officer of the same circle.&lt;ref name="finckh-kraemer"&gt;{{cite web|url=http://www.finckh-kraemer.de/ueber_mich/lebenslauf/index.html|title=Ute Finckh-Kr&amp;auml;mer, MdB - Lebenslauf|website=finckh-kraemer.de|accessdate=2018-11-09}}&lt;/ref&gt;

In the 2013 [[Bundestag]] elections, Finckh-Krämer joined the SPD as a direct candidate in the Constituency Steglitz-Zehlendorf.&lt;ref&gt;[http://archiv.spd-berlin.de/archiv/news/news-2013/januar-2013/ute-finckh-kraemer-spitzenkandidatin-der-spd-steglitz-zehlendorf/ ]{{dead link|date=November 2018}}&lt;/ref&gt; 

Finckh-Krämer was the head of the SPD in the Subcommittee on Civilian Crisis Prevention, Conflict Transformation and Network Action and Deputy Chair of the Subcommittee on Disarmament, Arms Control and Non-Proliferation. In addition, she was a full member of the {{ill|Foreign Affairs Committee (Germany)|lt=Foreign Affairs Committee|de|Auswärtiger Ausschuss}} and the {{ill|Human Rights and Humanitarian Aid Committee|de|Ausschuss für Menschenrechte und humanitäre Hilfe}}. She served as [[secretary]] in the Bundestag presidency and was a member of the [Parliamentary Assembly of the Council of Europe | Parliamentary Assembly of the Council of Europe] in January 2018 until the German delegation was replaced.

In the federal election 2017, she was again unable to prevail in her constituency with 24.6% of the first votes and was defeated by the CDU candidate Thomas Heilmann (35.4%).&lt;ref name="bundeswahlleiter"&gt;{{cite web|url=https://www.bundeswahlleiter.de/bundestagswahlen/2017/ergebnisse/bund-99/land-11/wahlkreis-79.html|author=Der Bundeswahlleiter|title=Ergebnisse Berlin-Steglitz-Zehlendorf - Der Bundeswahlleiter|website=bundeswahlleiter.de|accessdate=2018-11-09}}&lt;/ref&gt; so she left the Bundestag.

== Personal life ==
Finckh-Krämer is married and has two adult sons. She has lived in the Berlin district [[Steglitz-Zehlendorf]] (until 2001 [[Steglitz]]) since 1992. She is the eldest daughter of Ulrich Finckh. Finckh-Krämer is [[Protestant]] and is a member of the Lukas parish Steglitz.&lt;ref name="finckh-kraemer2"&gt;{{cite web|url=http://www.finckh-kraemer.de/ueber_mich/memberships/index.html|title=Ute Finckh-Kr&amp;auml;mer, MdB - Mein politisches Engagement|website=finckh-kraemer.de|accessdate=2018-11-09}}&lt;/ref&gt;

== External links ==
* [http://www.finckh-kraemer.de/ Website of Ute Finckh-Krämer]
* [https://www.spdfraktion.de/abgeordneten/finckh-kraemer?wp=18 '' Dr. Ute Finckh-Krämer ''] on the website of the SPD parliamentary group

==References==
{{reflist}}

===Sources===
*Content in this edit is translated from the existing German Wikipedia article at ; see its history for attribution.

{{DEFAULTSORT:Finckh-Krämer, Ute}}
[[Category:1956 births]]
[[Category:Mathematician politicians]]
[[Category:Living people]]
[[Category:German women in politics]]
[[Category:German women mathematicians]]</text>
      <sha1>1u5t8vmpekj2wdghvniyd42d2mnt9ie</sha1>
    </revision>
  </page>
</mediawiki>
