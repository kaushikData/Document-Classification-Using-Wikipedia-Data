<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>228 (number)</title>
    <ns>0</ns>
    <id>37631784</id>
    <revision>
      <id>832584220</id>
      <parentid>789172878</parentid>
      <timestamp>2018-03-26T21:16:18Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>save text from invisible. replace SloanesRef: use {{Cite OEIS}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1103">'''228''' ('''two hundred [and] twenty-eight''') is the [[natural number]] following [[227 (number)|227]] and preceding [[229 (number)|229]].
{{Infobox number
| number = 228
| prime = no
}}

228 is a [[refactorable number]],&lt;ref&gt;{{Cite OEIS|A033950|name=Refactorable numbers}}&lt;/ref&gt;
and a [[practical number]].&lt;ref&gt;{{Cite OEIS|A005153|name=Practical numbers}}&lt;/ref&gt;
There are 228 [[matching (graph theory)|matchings]] in a [[ladder graph]] with five rungs.&lt;ref&gt;{{Cite OEIS|A030186|name=a(n) = 3a(n-1) + a(n-2) - a(n-3)}}&lt;/ref&gt;
228 is the smallest even number ''n'' such that the numerator of the ''n''th [[Bernoulli number]] is divisible by a nontrivial [[square number]] that is [[relatively prime]] to&amp;nbsp;''n''.&lt;ref&gt;{{Cite OEIS|A090943|name=Even numbers n such that N(n) is divisible by a nontrivial square, m^2, say and GCD(n,m)=1, where N(n) is the numerator of the Bernoulli number B(n)}}&lt;/ref&gt;

The binary form of 228 contains all the two digit binary numbers in sequence from highest to lowest (11 10 01 00).

==References==
{{reflist|30em}}

{{Integers|2}}

[[Category:Integers]]

{{Num-stub}}</text>
      <sha1>r0pko5sxo8s19vou33eaun70waxbtjn</sha1>
    </revision>
  </page>
  <page>
    <title>Antiprism graph</title>
    <ns>0</ns>
    <id>45012210</id>
    <revision>
      <id>702615144</id>
      <parentid>702589333</parentid>
      <timestamp>2016-01-31T17:52:52Z</timestamp>
      <contributor>
        <username>Dr Greg</username>
        <id>847224</id>
      </contributor>
      <comment>/* top */ dab graph</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2394">In the [[mathematics|mathematical]] field of [[graph theory]], an '''antiprism graph''' is a [[Graph (discrete mathematics)|graph]] that has one of the [[antiprism]]s as its skeleton. An ''n''-sided antiprism has 2''n'' vertices and 4''n'' edges. They are [[regular graph|regular]], [[polyhedral graph|polyhedral]] (and therefore by necessity also [[K-vertex-connected graph|3-vertex-connected]], [[Vertex-transitive_graph|vertex-transitive]], and [[planar graph]]s), and also [[Hamiltonian graph]]s.&lt;ref&gt;Read, R. C. and Wilson, R. J. ''An Atlas of Graphs'', Oxford, England: Oxford University Press, 2004 reprint, Chapter 6 ''special graphs'' pp. 261, 270.&lt;/ref&gt;

==Examples==
The first graph in the sequence, the [[octahedral graph]], has 6 vertices and 12 edges. Later graphs in the sequence may be named after the type of antiprism they correspond to:

* [[Octahedral graph]] – 6 vertices, 12 edges
* [[square antiprism]]atic graph – 8 vertices, 16 edges
* [[Pentagonal antiprism]]atic graph – 10 vertices, 20 edges
* [[Hexagonal antiprism]]atic graph – 12 vertices, 24 edges
* [[Heptagonal antiprism]]atic graph – 14 vertices, 28 edges
* [[Octagonal antiprism]]atic graph– 16 vertices, 32 edges
* ...

{| class=wikitable
|- align=center
|[[File:3-cube t2.svg|100px]]&lt;BR&gt;3
|[[File:Square antiprismatic graph.png|100px]]&lt;BR&gt;4
|[[File:Pentagonal antiprismatic graph.png|100px]]&lt;BR&gt;5
|[[File:Hexagonal antiprismatic graph.png|100px]]&lt;BR&gt;6
|[[File:Heptagonal antiprism graph.png|100px]]&lt;BR&gt;7
|[[File:Octagonal antiprismatic graph.png|100px]]&lt;BR&gt;8
|}

Although geometrically the [[star polygon]]s also form the faces of a different sequence of (self-intersecting) antiprisms, the star antiprisms, they do not form a different sequence of graphs.

==Related graphs==
An antiprism graph is a special case of a [[circulant graph]], Ci&lt;sub&gt;2''n''&lt;/sub&gt;(2,1). 

Other infinite sequences of polyhedral graph formed in a similar way from polyhedra with regular-polygon bases include the [[prism graph]]s (graphs of [[Prism (geometry)|prisms]]) and [[wheel graph]]s (graphs of [[Pyramid (geometry)|pyramids]]). Other vertex-transitive polyhedral graphs include the [[Archimedean graph]]s.

== References==
{{reflist}}

==External links==
* {{mathworld | urlname = AntiprismGraph | title = Antiprism graph }}

[[Category:Graph families]]
[[Category:Regular graphs]]
[[Category:Planar graphs]]</text>
      <sha1>btrtdkcf34rpt9xdtxj7wu1jasb9m6d</sha1>
    </revision>
  </page>
  <page>
    <title>Balinski's theorem</title>
    <ns>0</ns>
    <id>24732291</id>
    <revision>
      <id>680300334</id>
      <parentid>680296224</parentid>
      <timestamp>2015-09-10T00:19:06Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>illo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3641">[[File:Balinski.svg|thumb|upright=1.35|Removing any two vertices (yellow) cannot disconnect a three-dimensional polyhedron: one can choose a third vertex (green), and a nontrivial linear function whose zero set (blue) passes through these three vertices, allowing connections from the chosen vertex to the minimum and maximum of the function, and from any other vertex to the minimum or maximum.]]
In [[polyhedral combinatorics]], a branch of mathematics, '''Balinski's theorem''' is a statement about the [[graph theory|graph-theoretic]] structure of three-dimensional [[polyhedron|polyhedra]] and higher-dimensional [[polytope]]s. It states that, if one forms an [[undirected graph]] from the vertices and edges of a convex ''d''-dimensional polyhedron or polytope (its [[skeleton (topology)|skeleton]]), then the resulting graph is at least [[connectivity (graph theory)|''d''-vertex-connected]]: the removal of any ''d''&amp;nbsp;&amp;minus;&amp;nbsp;1 vertices leaves a connected subgraph. For instance, for a three-dimensional polyhedron, even if two of its vertices (together with their incident edges) are removed, for any pair of vertices there will still exist a path of vertices and edges connecting the pair.&lt;ref&gt;{{citation|first=Günter M.|last=Ziegler|authorlink=Günter M. Ziegler|title=Lectures on Polytopes|publisher=Springer-Verlag|year=1995|series=[[Graduate Texts in Mathematics]]|volume=152|contribution=Section 3.5: Balinski's Theorem: The Graph is ''d''-Connected}}.&lt;/ref&gt;

Balinski's theorem is named after mathematician [[Michel Balinski]], who published its proof in 1961,&lt;ref&gt;{{citation|title=On the graph structure of convex polyhedra in ''n''-space|first=M. L.|last=Balinski|authorlink=Michel Balinski|journal=[[Pacific Journal of Mathematics]]|volume=11|issue=2|year=1961|pages=431–434|mr=0126765|url=http://projecteuclid.org/euclid.pjm/1103037323|doi=10.2140/pjm.1961.11.431}}.&lt;/ref&gt; although the three-dimensional case dates back to the earlier part of the 20th century and the discovery of [[Steinitz's theorem]] that the graphs of three-dimensional polyhedra are exactly the three-connected planar graphs.&lt;ref&gt;{{citation|first=E.|last=Steinitz|authorlink=Ernst Steinitz|contribution=Polyeder und Raumeinteilungen|title=[[Klein's encyclopedia|Encyclopädie der mathematischen Wissenschaften]], Band 3 (Geometries)|year=1922|pages=1–139}}.&lt;/ref&gt;

==Balinski's proof==
Balinski proves the result based on the correctness of the [[simplex method]] for finding the minimum or maximum of a linear function on a convex polytope (the [[linear programming]] problem). The simplex method starts at an arbitrary vertex of the polytope and repeatedly moves towards an adjacent vertex that improves the function value; when no improvement can be made, the optimal function value has been reached.

If ''S'' is a set of fewer than ''d'' vertices to be removed from the graph of the polytope, Balinski adds one more vertex ''v''&lt;sub&gt;0&lt;/sub&gt; to ''S'' and finds a linear function ƒ that has the value zero on the augmented set but is not identically zero on the whole space. Then, any remaining vertex at which ƒ is non-negative (including ''v''&lt;sub&gt;0&lt;/sub&gt;) can be connected by simplex steps to the vertex with the maximum value of ƒ, while any remaining vertex at which ƒ is non-positive (again including ''v''&lt;sub&gt;0&lt;/sub&gt;) can be similarly connected to the vertex with the minimum value of ƒ. Therefore, the entire remaining graph is connected.

==References==
{{reflist}}

[[Category:Polyhedral combinatorics]]
[[Category:Graph connectivity]]
[[Category:Theorems in discrete geometry]]
[[Category:Theorems in graph theory]]</text>
      <sha1>l2tr84nneyh7v4v18wur7b76vi62ktd</sha1>
    </revision>
  </page>
  <page>
    <title>Binary multiplier</title>
    <ns>0</ns>
    <id>4533924</id>
    <revision>
      <id>865428733</id>
      <parentid>865428718</parentid>
      <timestamp>2018-10-23T21:56:53Z</timestamp>
      <contributor>
        <username>Plandu</username>
        <id>34084</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/108.51.190.87|108.51.190.87]] ([[User talk:108.51.190.87|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15345">A '''binary multiplier''' is an [[electronic circuit]] used in [[digital electronics]], such as a [[computer]], to [[Multiplication|multiply]] two [[binary number]]s. It is built using [[binary adder]]s.

A variety of [[:Category:computer arithmetic|computer arithmetic]] techniques can be used to implement a digital multiplier.  Most techniques involve computing a set of ''partial products'', and then summing the partial products together.  This process is similar to the method taught to primary schoolchildren for conducting long multiplication on base-10 integers, but has been modified here for application to a base-2 ([[binary numeral system|binary]]) [[numeral system]].

==History==
Between 1947-1949 Arthur Alec Robinson worked for English Electric Ltd, as a student apprentice, and then as a development engineer. Crucially during this period he studied for a PhD degree at the University of Manchester, where he worked on the design of the hardware multiplier for the early Mark 1 computer.
[https://issuu.com/clarealumni/docs/mu16632_clare_annual_-_web]
However, until the late 1970s, most [[minicomputers]] did not have a multiply instruction, and so programmers used a "multiply routine"&lt;ref&gt;"The Evolution of Forth" by Elizabeth D. Rather et al.
[http://www.forth.com/resources/evolution/evolve_2.html]
[http://www.forth.com/resources/evolution/evolve_1.html]
&lt;/ref&gt;&lt;ref&gt;[https://dx.doi.org/10.1016/0308-5953(77)90004-6 "Interfacing a hardware multiplier to a general-purpose microprocessor"]&lt;/ref&gt;
which repeatedly [[multiplication algorithm#Shift and add|shifts and accumulates]] partial results,
often written using [[loop unwinding]].  [[Mainframe computer]]s had multiply instructions, but they did the same sorts of shifts and adds as a "multiply routine".

Early [[microprocessor]]s also had no multiply instruction.  Though the multiply instruction is usually associated with the 16-bit microprocessor generation,&lt;ref&gt;{{cite book 
 | title = Fundamentals of Digital Logic and Microcomputer Design
 | author = M. Rafiquzzaman
 | publisher = [[John Wiley &amp; Sons]]
 | page = 251
 | year = 2005
 | isbn = 978-0-47173349-2
 | url = https://books.google.com/books?id=1QZEawDm9uAC&amp;pg=PA251&amp;dq=6809+multiply+instruction&amp;hl=en&amp;sa=X&amp;ei=WhIrVc3wG8nvoATz2YGABw&amp;ved=0CDgQ6AEwBQ#v=onepage&amp;q=6809%20multiply%20instruction&amp;f=false}}&lt;/ref&gt; 
at least two "enhanced" 8-bit micro have a multiply instruction:   the [[Motorola 6809]], introduced in 1978,&lt;ref&gt;{{cite book 
 | title = Microprocessors and Microcontrollers: Architecture, Programming and System Design 8085, 8086, 8051, 8096
 | author = Krishna Kant
 | publisher = PHI Learning Pvt. Ltd.
 | page = 57
 | year = 2007
 | isbn = 9788120331914
 | url = https://books.google.com/books?id=P-n3kelycHQC&amp;pg=PA57&amp;dq=6809+multiply+instruction&amp;hl=en&amp;sa=X&amp;ei=WhIrVc3wG8nvoATz2YGABw&amp;ved=0CCgQ6AEwAg#v=onepage&amp;q=6809%20multiply%20instruction&amp;f=false
}}&lt;/ref&gt;&lt;ref&gt;{{cite book 
 | title = Microprocessor-Based Agri Instrumentation
 | author = Krishna Kant
 | publisher = PHI Learning Pvt. Ltd.
 | page = 139
 | year = 2010
 | isbn = 9788120340862
 | url = https://books.google.com/books?id=k56RJCu07ZQC&amp;pg=PA139&amp;dq=6809+multiply+instruction&amp;hl=en&amp;sa=X&amp;ei=WhIrVc3wG8nvoATz2YGABw&amp;ved=0CFAQ6AEwCQ#v=onepage&amp;q=6809%20multiply%20instruction&amp;f=false
}}&lt;/ref&gt; and [[Intel MCS-51]] family, developed in 1980, and later the modern [[Atmel AVR]] 8-bit microprocessors present in the ATMega, ATTiny and ATXMega microcontrollers.

As more [[transistor count|transistors per chip]] became available due to larger-scale integration, it became possible to put enough adders on a single chip to sum all the partial products at once, rather than reuse a single adder to handle each partial product one at a time.

Because some common [[digital signal processing]] algorithms spend most of their time multiplying, [[digital signal processor]] designers sacrifice a lot of chip area in order to make the multiply as fast as possible; a single-cycle [[multiply–accumulate]] unit often used up most of the chip area of early DSPs.

==Multiplication basics==
The method taught in school for multiplying decimal numbers is based on calculating partial products, shifting them to the left and then adding them together. The most difficult part is to obtain the partial products, as that involves multiplying a long number by one digit (from 0 to 9):

  &lt;nowiki&gt;    123
   x 456
   =====
     738  (this is 123 x 6)
    615   (this is 123 x 5, shifted one position to the left)
 + 492    (this is 123 x 4, shifted two positions to the left)
   =====
   56088&lt;/nowiki&gt;

A binary computer does exactly the same, but with binary numbers. In binary encoding each long number is multiplied by one digit (either 0 or 1), and that is much easier than in decimal, as the product by 0 or 1 is just 0 or the same number. Therefore, the multiplication of two binary numbers comes down to calculating partial products (which are 0 or the first number), [[Logical shift|shifting]] them left, and then adding them together (a binary addition, of course):

 &lt;nowiki&gt;
       1011   (this is 11 in binary)
     x 1110   (this is 14 in binary)
     ======
       0000   (this is 1011 x 0)
      1011    (this is 1011 x 1, shifted one position to the left)
     1011     (this is 1011 x 1, shifted two positions to the left)
  + 1011      (this is 1011 x 1, shifted three positions to the left)
  =========
   10011010   (this is 154 in binary)&lt;/nowiki&gt;

This is much simpler than in the decimal system, as there is no table of multiplication to remember: just shifts and adds.

This method is mathematically correct and has the advantage that a small CPU may perform the multiplication by using the shift and add features of its arithmetic logic unit rather than a specialized circuit. The method is slow, however, as it involves many intermediate additions. These additions take a lot of time. Faster multipliers may be engineered in order to do fewer additions; a modern processor can multiply two 64-bit numbers with 6 additions (rather than 64), and can do several steps in parallel. {{fact|date=August 2017}}

The second problem is that the basic school method handles the sign with a separate rule ("+ with + yields +", "+ with − yields −", etc.). Modern computers embed the sign of the number in the number itself, usually in the [[two's complement]] representation. That forces the multiplication process to be adapted to handle two's complement numbers, and that complicates the process a bit more. Similarly, processors that use [[ones' complement]], [[sign-and-magnitude]], [[IEEE-754]] or other binary representations require specific adjustments to the multiplication process.

==A more advanced approach: an unsigned example==
For example, suppose we want to multiply two [[signedness|unsigned]] eight bit integers together: ''a''[7:0] and ''b''[7:0].  We can produce eight partial products by performing eight one-bit multiplications, one for each bit in multiplicand ''a'':
  &lt;nowiki&gt;p0[7:0] = a[0] &amp;times; b[7:0] = {8{a[0]}} &amp; b[7:0]
 p1[7:0] = a[1] &amp;times; b[7:0] = {8{a[1]}} &amp; b[7:0]
 p2[7:0] = a[2] &amp;times; b[7:0] = {8{a[2]}} &amp; b[7:0]
 p3[7:0] = a[3] &amp;times; b[7:0] = {8{a[3]}} &amp; b[7:0]
 p4[7:0] = a[4] &amp;times; b[7:0] = {8{a[4]}} &amp; b[7:0] 
 p5[7:0] = a[5] &amp;times; b[7:0] = {8{a[5]}} &amp; b[7:0]
 p6[7:0] = a[6] &amp;times; b[7:0] = {8{a[6]}} &amp; b[7:0]
 p7[7:0] = a[7] &amp;times; b[7:0] = {8{a[7]}} &amp; b[7:0]&lt;/nowiki&gt;

where &lt;nowiki&gt;{8{a[0]}}&lt;/nowiki&gt; means repeating a[0] (the 0th bit of a) 8 times ([[Verilog]] notation).

To produce our product, we then need to add up all eight of our partial products, as shown here:
                                                 p0[7] p0[6] p0[5] p0[4] p0[3] p0[2] p0[1] p0[0]
                                         + p1[7] p1[6] p1[5] p1[4] p1[3] p1[2] p1[1] p1[0] 0
                                   + p2[7] p2[6] p2[5] p2[4] p2[3] p2[2] p2[1] p2[0] 0     0
                             + p3[7] p3[6] p3[5] p3[4] p3[3] p3[2] p3[1] p3[0] 0     0     0
                       + p4[7] p4[6] p4[5] p4[4] p4[3] p4[2] p4[1] p4[0] 0     0     0     0
                 + p5[7] p5[6] p5[5] p5[4] p5[3] p5[2] p5[1] p5[0] 0     0     0     0     0
           + p6[7] p6[6] p6[5] p6[4] p6[3] p6[2] p6[1] p6[0] 0     0     0     0     0     0
     + p7[7] p7[6] p7[5] p7[4] p7[3] p7[2] p7[1] p7[0] 0     0     0     0     0     0     0
 -------------------------------------------------------------------------------------------
 P[15] P[14] P[13] P[12] P[11] P[10]  P[9]  P[8]  P[7]  P[6]  P[5]  P[4]  P[3]  P[2]  P[1]  P[0]

In other words, ''P''[15:0] is produced by summing ''p''0, ''p''1 &lt;&lt; 1, ''p''2 &lt;&lt; 2, and so forth, to produce our final unsigned 16-bit product.

==More advanced approach: signed integers==
If ''b'' had been a [[signedness|signed]] integer instead of an [[signedness|unsigned]] integer, then the partial products would need to have been sign-extended up to the width of the product before summing.  If ''a'' had been a signed integer, then partial product ''p7'' would need to be subtracted from the final sum, rather than added to it.

The above array multiplier can be modified to support [[two's complement notation]] signed numbers by inverting several of the product terms and inserting a one to the left of the first partial product term:

                                                     1  ~p0[7]  p0[6]  p0[5]  p0[4]  p0[3]  p0[2]  p0[1]  p0[0]
                                                 ~p1[7] +p1[6] +p1[5] +p1[4] +p1[3] +p1[2] +p1[1] +p1[0]   0
                                          ~p2[7] +p2[6] +p2[5] +p2[4] +p2[3] +p2[2] +p2[1] +p2[0]   0      0
                                   ~p3[7] +p3[6] +p3[5] +p3[4] +p3[3] +p3[2] +p3[1] +p3[0]   0      0      0
                            ~p4[7] +p4[6] +p4[5] +p4[4] +p4[3] +p4[2] +p4[1] +p4[0]   0      0      0      0
                     ~p5[7] +p5[6] +p5[5] +p5[4] +p5[3] +p5[2] +p5[1] +p5[0]   0      0      0      0      0
              ~p6[7] +p6[6] +p6[5] +p6[4] +p6[3] +p6[2] +p6[1] +p6[0]   0      0      0      0      0      0
    1  +p7[7] ~p7[6] ~p7[5] ~p7[4] ~p7[3] ~p7[2] ~p7[1] ~p7[0]   0      0      0      0      0      0      0
  ------------------------------------------------------------------------------------------------------------
 P[15]  P[14]  P[13]  P[12]  P[11]  P[10]   P[9]   P[8]   P[7]   P[6]   P[5]   P[4]   P[3]   P[2]   P[1]  P[0]

Where ~p represents the complement (opposite value) of p.

There are a lot of simplifications in the bit array above that are not shown and are not obvious.  The sequences of one complemented bit followed by noncomplemented bits are implementing a two's complement trick to avoid sign extension.  The sequence of p7 (noncomplemented bit followed by all complemented bits) is because we're subtracting this term so they were all negated to start out with (and a 1 was added in the least significant position).  For both types of sequences, the last bit is flipped and an implicit -1 should be added directly below the MSB.  When the +1 from the two's complement negation for p7 in bit position 0 (LSB) and all the -1's in bit columns 7 through 14 (where each of the MSBs are located) are added together, they can be simplified to the single 1 that "magically" is floating out to the left.  For an explanation and proof of why flipping the MSB saves us the sign extension, see a computer arithmetic book.&lt;ref&gt;Parhami, Behrooz, Computer Arithmetic: Algorithms and Hardware Designs, [[Oxford University Press]], New York, 2000 ({{ISBN|0-19-512583-5}},  490 + xx pp.)&lt;/ref&gt;

==Implementations==
Older multiplier architectures employed a shifter and accumulator to sum each partial product, often one partial product per cycle, trading off speed for die area.  Modern multiplier architectures use the (Modified) [[Baugh&amp;ndash;Wooley algorithm]],&lt;ref name="Baugh-Wooley_1973"/&gt;&lt;ref name="Hatamian-Cash_1986"/&gt;&lt;ref name="Gebali_2003"/&gt;&lt;ref name="ULVD_2015"/&gt; [[Wallace tree]]s, or [[Dadda multiplier]]s to add the partial products together in a single cycle.  The performance of the [[Wallace tree]] implementation is sometimes improved by ''modified'' [[Booth encoding]] one of the two multiplicands, which reduces the number of partial products that must be summed.

==Example==
[[Image:binary multi1.jpg|center|thumb|500px|2-bit by 2-bit binary multiplier]]
&lt;!-- Deleted image removed: [[Image:eightbitmult.jpg|center|thumb|500px|4 Bit by 4 Bit Binary Multiplier&lt;br&gt; '''Using 4 Bit + 4 Bit Adders''']] --&gt;

==See also==
* [[Booth's multiplication algorithm]]
* [[Fused multiply–add]]
* [[Wallace tree]]
* [[BKM algorithm]] for complex logarithms and exponentials
* [[Kochanski multiplication]] for [[modular arithmetic|modular]] multiplication
* [[Logical shift left]]

==References==
{{Reflist|refs=
&lt;ref name="Baugh-Wooley_1973"&gt;{{cite journal |url=http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1672241&amp;sortType%3Dasc_p_Sequence%26filter%3DAND%28p_IS_Number%3A35072%29 |author-first1=Charles Richmond |author-last1=Baugh |author-first2=Bruce A. |author-last2=Wooley |title=A Two's Complement Parallel Array Multiplication Algorithm |journal=[[IEEE Transactions on Computers]] |volume=C-22 |pages=1045–1047 |date=December 1973}}&lt;/ref&gt;
&lt;ref name="Gebali_2003"&gt;{{cite web |url=http://www.ece.uvic.ca/~fayez/courses/ceng465/lab_465/project2/multiplier.pdf |author-first=Fayez |author-last=Gebali |title=Baugh–Wooley Multiplier |publisher=[[University of Victoria]], CENG 465 Lab 2 |date=2003 |access-date=2018-04-14 |dead-url=no |archive-url=https://web.archive.org/web/20180414230734/http://www.ece.uvic.ca/~fayez/courses/ceng465/lab_465/project2/multiplier.pdf |archive-date=2018-04-14}}&lt;/ref&gt;
&lt;ref name="Hatamian-Cash_1986"&gt;{{cite journal |author-last1=Hatamian |author-first1=
Mehdi |author-last2=Cash |author-first2=Glenn |date=1986 |title=A 70-MHz 8-bit×8-bit parallel pipelined multiplier in 2.5-µm CMOS |journal=[[IEEE Journal of Solid State Circuits]] |volume=21 |issue=4 |pages=505-513 |doi=10.1109/ISSC.1986.1052564 |url=https://www.researchgate.net/publication/2981745_A_70-MHz_8-bit8-bit_parallel_pipelined_multiplier_in_25-mm_CMOS}}&lt;/ref&gt;
&lt;ref name="ULVD_2015"&gt;{{cite book |title=Ultra-Low-Voltage Design of Energy-Efficient Digital Circuits |author-first1=Nele |author-last1=Reynders |author-first2=Wim |author-last2=Dehaene |series=Analog Circuits And Signal Processing (ACSP) |date=2015 |edition=1 |location=Heverlee, Belgium |publisher=[[Springer International Publishing AG Switzerland]] |publication-place=Cham, Switzerland |isbn=978-3-319-16135-8 |issn=1872-082X |doi=10.1007/978-3-319-16136-5 |lccn=2015935431}}&lt;/ref&gt;
}}
* {{cite book |title=Computer Architecture: A quantitative Approach |author-first1=John L. |author-last1=Hennessy |author-first2=David A. |author-last2=Patterson |isbn=978-0-12383872-8 |date=1990 |publisher=[[Morgan Kaufmann Publishers, Inc.]] |chapter=Section A.2, section A.9 |pages=A-3..A-6, A-39..A-49}}

==External links==
* [http://www.andraka.com/multipli.php Multiplier Designs] targeted at [[FPGA]]s
* [http://www.fullchipdesign.com/binary_multiplier_digital.htm Binary Multiplier circuit using Half -Adders and digital gates.]

{{DEFAULTSORT:Binary Multiplier}}
[[Category:Digital circuits]]
[[Category:Binary arithmetic]]
[[Category:Multiplication]]</text>
      <sha1>q2z9d663sk0qw9l54dfljbyn26ojien</sha1>
    </revision>
  </page>
  <page>
    <title>Bruno Courcelle</title>
    <ns>0</ns>
    <id>43140009</id>
    <revision>
      <id>765529113</id>
      <parentid>750318166</parentid>
      <timestamp>2017-02-14T22:48:05Z</timestamp>
      <contributor>
        <ip>50.53.1.33</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3421">{{Infobox scientist
| name        = Bruno Courcelle
| native_name = 
| native_name_lang = 
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  =         &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| birth_place = 
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = French
| nationality = 
| fields      = [[Graph theory]], [[Computer science]]
| workplaces  = [[University of Bordeaux 1]]
| patrons     = 
| education   = 
| alma_mater  = [[French Institute for Research in Computer Science and Automation]]
| thesis_title =        &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year =        1976
| doctoral_advisor =    &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = [[Courcelle's theorem]]
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         &lt;!--{{URL|www.example.com}}--&gt;
| footnotes   = 
}}
'''Bruno Courcelle''' is a French [[mathematician]] and [[computer scientist]], best known for [[Courcelle's theorem]] in [[graph theory]].

==Life==
Courcelle earned his Ph.D. in 1976 from the [[French Institute for Research in Computer Science and Automation]], then called IRIA, under the supervision of [[Maurice Nivat]]. He then joined the Laboratoire Bordelais de Recherche en Informatique (LaBRI) at the [[University of Bordeaux 1]], where he remained for the rest of his career.&lt;ref name="nivat"/&gt; He has been a senior member of the [[Institut Universitaire de France]] since 2007.&lt;ref&gt;[http://iuf.amue.fr/author/bcourcelle/ Bruno Courcelle] {{webarchive |url=https://web.archive.org/web/20140315055625/http://iuf.amue.fr/author/bcourcelle/ |date=March 15, 2014 }}, [[Institut Universitaire de France]], retrieved 2014-06-24.&lt;/ref&gt;

A workshop in honor of  Courcelle's retirement was held in Bordeaux in 2012.&lt;ref name="nivat"&gt;[http://bc12.labri.fr/nivat-courcelle.pdf Bruno Courcelle], text of remarks presented by [[Maurice Nivat]] at Courcelle workshop, retrieved 2014-06-24.&lt;/ref&gt;&lt;ref&gt;[http://bc12.labri.fr/ Bruno's workshop, June 18-20, 2012, LaBRI, Bordeaux], retrieved 2014-06-24.&lt;/ref&gt;

==Work==
He is known for [[Courcelle's theorem]], which combines [[second order logic]], the theory of [[formal language]]s, and [[tree decomposition|tree decompositions of graphs]] to show that a wide class of algorithmic problems in [[graph theory]] have efficient solutions.

==References==
{{reflist}}

==External links==
*{{Official website}}
*{{MathGenealogy|name=Bruno Courcelle}}
*{{Google Scholar id|name=Bruno Courcelle}}

{{Authority control}}

{{DEFAULTSORT:Courcelle, Bruno}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:French mathematicians]]
[[Category:French computer scientists]]
[[Category:Graph theorists]]</text>
      <sha1>t1f0r9t3aes0ichrpmfx7cagm1zccjj</sha1>
    </revision>
  </page>
  <page>
    <title>Coaxial</title>
    <ns>0</ns>
    <id>542587</id>
    <revision>
      <id>682803931</id>
      <parentid>645326030</parentid>
      <timestamp>2015-09-26T04:36:23Z</timestamp>
      <contributor>
        <username>Mild Bill Hiccup</username>
        <id>5202324</id>
      </contributor>
      <minor/>
      <comment>/* top */ Cleaned up using [[WP:AutoEd|AutoEd]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1395">{{Unreferenced|date=December 2009}}
{{other uses}}
[[Image:RG-59.jpg|thumb|right|[[coaxial cable]]]]
In [[geometry]], '''coaxial''' means that two or more three-[[dimension]]al linear forms share a common [[Coordinate axis|axis]]. Thus, it is [[concentric]] in three-dimensional, linear forms.

A [[coaxial cable]], as a common example, is a three-dimensional linear structure. It has a wire [[Conductor (material)|conductor]] in the centre (D), a circumferential outer conductor (B), and an insulating medium called the dielectric (C) separating these two conductors. The outer conductor is usually sheathed in a protective PVC outer jacket (A). All these have a common axis.

The dimension and material of the conductors and insulation determine the cable's characteristic impedance and [[attenuation]] at various frequencies.

In [[loudspeaker]] design, [[coaxial speakers]] are a loudspeaker system in which the individual driver units radiate sound from the same point or axis.

A [[Weapon mount#Coaxial|coaxial weapon mount]] places two weapons on [roughly] the same axis – as the weapons are usually side-by-side or one on top of the other, they are technically par-axial rather than coaxial, however the distances involved mean that they are effectively coaxial as far as the operator is concerned.

== External links ==
{{wiktionary|coaxial}}

{{RF connectors}}

[[Category:Geometry]]</text>
      <sha1>o1z341nadftklp88sf89fcjisc6mmzm</sha1>
    </revision>
  </page>
  <page>
    <title>Color model</title>
    <ns>0</ns>
    <id>1979078</id>
    <revision>
      <id>867368990</id>
      <parentid>859015607</parentid>
      <timestamp>2018-11-05T07:48:08Z</timestamp>
      <contributor>
        <ip>94.65.216.254</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29419">{{refimprove|date=September 2007}}

A '''color model''' is an abstract mathematical model describing the way [[color]]s can be represented as [[tuple]]s of numbers, typically as three or four values or color components. When this model is associated with a precise description of how the components are to be interpreted (viewing conditions, etc.), the resulting set of colors is called "[[color space]]." This section describes ways in which human [[color vision]] can be modeled.

== Tristimulus color space ==

[[File:gamut full.png|thumb|right|3D representation of the human color space.]]

One can picture this space as a region in three-dimensional [[Euclidean space]] if one identifies the ''x'', ''y'', and ''z'' axes with the stimuli for the long-wavelength (''L''), medium-wavelength (''M''), and short-wavelength (''S'') [[Cone cell|light receptors]]. The origin, (''S'',''M'',''L'') = (0,0,0), corresponds to black.  White has no definite position in this diagram; rather it is defined according to the [[color temperature]] or white balance as desired or as available from ambient lighting. The human color space is a horse-shoe-shaped cone such as shown here (see also [[Color_models#CIE_XYZ_color_space|CIE chromaticity diagram]] below), extending from the origin to, in principle, infinity. In practice, the human color receptors will be saturated or even be damaged at extremely high light intensities, but such behavior is not part of the [[International Commission on Illumination|CIE]] color space and neither is the changing color perception at low light levels (see: [[Kruithof curve]]). 
The most saturated colors are located at the outer rim of the region, with brighter colors farther removed from the origin. As far as the responses of the receptors in the eye are concerned, there is no such thing as "brown" or "gray" light. The latter color names refer to orange and white light respectively, with an intensity that is lower than the light from surrounding areas. One can observe this by watching the screen of an [[overhead projector]] during a meeting: one sees black lettering on a white background, even though the "black" has in fact not become darker than the white screen on which it is projected before the projector was turned on.  The "black" areas have not actually become darker but appear "black" relative to the higher intensity "white" projected onto the screen around it. See also [[color constancy]].

The human tristimulus space has the property that additive mixing of colors corresponds to the adding of vectors in this space. This makes it easy to, for example, describe the possible colors ([[gamut]]) that can be constructed from the red, green, and blue primaries in a computer display.

== CIE XYZ color space ==
{{main article|CIE 1931 color space}}
[[Image:CIE 1931 XYZ Color Matching Functions.svg|thumb|325px|right|[http://www.cie.co.at/framepublications.html CIE] 1931 Standard Colorimetric Observer functions between 380 nm and 780 nm (at 5 nm intervals).]]

One of the first mathematically defined color spaces is the CIE XYZ color space (also known as CIE 1931 color space), created by the [[International Commission on Illumination]] in 1931. These data were measured for human observers and a 2-degree field of view. In 1964, supplemental data for a 10-degree field of view were published.

Note that the tabulated sensitivity curves have a certain amount of arbitrariness in them. The shapes of the individual X, Y and Z sensitivity curves can be measured with a reasonable accuracy. However, the overall [[luminosity function]] (which in fact is a weighted sum of these three curves) is subjective, since it involves asking a test person whether two light sources have the same brightness, even if they are in completely different colors. Along the same lines, the relative magnitudes of the X, Y, and Z curves are arbitrarily chosen to produce equal areas under the curves. One could as well define a valid color space with an X sensitivity curve that has twice the amplitude. This new color space would have a different shape. The sensitivity curves in the CIE 1931 and 1964 xyz color space are scaled to have equal areas under the curves.

Sometimes XYZ colors are represented by the luminance, Y, and chromaticity coordinates ''x'' and ''y'', defined by:

:&lt;math&gt;x = \frac{X}{X + Y + Z}&lt;/math&gt; and &lt;math&gt;y = \frac{Y}{X + Y + Z}&lt;/math&gt;

Mathematically, ''x'' and ''y'' are projective coordinates and the colors of the chromaticity diagram occupy a region of the [[projective plane|real projective plane]]. Because the CIE sensitivity curves have equal areas under the curves, light with a flat energy spectrum corresponds to the point (''x'',''y'') = (0.333,0.333).

The values for ''X'', ''Y'', and ''Z'' are obtained by integrating the product of the spectrum of a light beam and the published color-matching functions.

==Additive and subtractive color models==

=== RGB color model ===

{{main|RGB color model}}
[[File:RGBCube a.svg|179px|thumb]]

Media that transmit light (such as television) use [[additive color]] mixing with [[primary color]]s of [[red]], [[green]], and [[blue]], each of which stimulates one of the three types of the eye's color receptors with as little stimulation as possible of the other two. This is called "[[RGB]]" color space. Mixtures of light of these primary colors cover a large part of the human color space and thus produce a large part of human color experiences. This is why [[color television]] sets or color computer monitors need only produce mixtures of red, green and blue light. See [[Additive color]].

Other primary colors could in principle be used, but with red, green and blue the largest portion of the [[human color space]] can be captured. Unfortunately there is no exact consensus as to what loci in the [[chromaticity diagram]] the red, green, and blue colors should have, so the same RGB values can give rise to slightly different colors on different screens.

=== CMYK color model ===

{{main|CMYK color model}}

It is possible to achieve a large range of colors seen by humans by combining [[cyan]], [[magenta]], and [[yellow]] transparent dyes/inks on a white substrate. These are the ''[[subtractive color|subtractive]]'' [[primary color]]s. Often a fourth ink, [[black]], is added to improve reproduction of some dark colors. This is called the "CMY" or "CMYK" color space.

The cyan ink absorbs red light but transmits green and blue, the magenta ink absorbs green light but transmits red and blue, and the yellow ink absorbs blue light but transmits red and green. The white substrate reflects the transmitted light back to the viewer. Because in practice the CMY inks suitable for printing also reflect a little bit of color, making a deep and neutral black impossible, the K (black ink) component, usually printed last, is needed to compensate for their deficiencies. Use of a separate black ink is also economically driven when a lot of black content is expected, e.g. in text media, to reduce simultaneous use of the three colored inks. The dyes used in traditional color photographic prints and [[reversal film|slides]] are much more perfectly transparent, so a K component is normally not needed or used in those media.
{{-}}

==Cylindrical-coordinate color models==
A number of color models exist in which colors are fit into [[conic]], [[cylindrical]] or [[spherical]] shapes, with neutrals running from black to white in a central axis, and hues corresponding to angles around that axis. Arrangements of this type date back to the 18th century, and continue to be developed in the most modern and scientific models.

===Background===
{{multiple image
 | align             = right
 | direction         = horizontal
 | total_width       = 440
 | image1            = Runge Farbenkugel.jpg
 | caption1          = [[Philipp Otto Runge]]’s ''Farbenkugel'' (color sphere), 1810, showing the surface of the sphere (top two images), and horizontal and vertical cross sections (bottom two images).
 | image2            = Tape Ball Color Space, Itten, 1919-20.jpg
 | caption2          = Color sphere of [[Johannes Itten]], 1919-20
}}
{{see also|Color solid}}
Different color theorists have each designed unique [[color solid]]s.  Many are in the shape of a [[sphere]], whereas others are warped three-dimensional ellipsoid figures&amp;mdash;these variations being designed to express some aspect of the relationship of the colors more clearly.  The color spheres conceived by [[Phillip Otto Runge]] and [[Johannes Itten]] are typical examples and prototypes for many other color solid schematics.&lt;ref&gt;Johannes Itten, "The Art of Color", 1961. Trans. Ernst Van Haagen. New York: Reinhold Publishing Corporation, 1966. {{ISBN|0-442-24038-4}}.&lt;/ref&gt; The models of Runge and Itten are basically identical, and form the basis for the description below.

Pure, saturated hues of equal brightness are located around the equator at the periphery of the color sphere.  As in the color wheel, [[Complementary color |contrasting (or complementary) hues]] are located opposite each other.  Moving toward the center of the color sphere on the equatorial plane, colors become less and less saturated, until all colors meet at the central [[Coordinate axis|axis]] as a neutral [[gray]].  Moving vertically in the color sphere, colors become lighter (toward the top) and darker (toward the bottom). At the upper pole, all hues meet in white; at the bottom pole, all hues meet in black.  

The vertical axis of the color sphere, then, is gray all along its length, varying from [[black]] at the bottom to [[white]] at the top.  All pure (saturated) hues are located on the surface of the sphere, varying from light to dark down the color sphere.  All impure (unsaturated hues, created by mixing contrasting colors) comprise the sphere's interior, likewise varying in brightness from top to bottom.

===HSL and HSV===
{{main|HSL and HSV}}
{{multiple image
 | align   = right
 | total_width = 440
 | image1  = tint-tone-shade.svg
 | caption1 = Painters long mixed colors by combining relatively bright pigments with black and white. Mixtures with white are called ''tints'', mixtures with black are called ''shades'', and mixtures with both are called ''tones''. See [[Tints and shades]].&lt;ref name=Levkowitz&gt;[[#Levkowitz|Levkowitz and Herman (1993)]]&lt;/ref&gt;
 | alt1   =
 | image2  = RGB Cube Show lowgamma cutout b.png
 | caption2 = The RGB gamut can be arranged in a cube. The RGB model is not very intuitive to artists used to using traditional models based on tints, shades and tones. The HSL and HSV color models were designed to fix this.
}}
{{multiple image
 | align   = right
 | total_width = 440
 | image1  = HSL color solid cylinder saturation gray.png
 | caption1 = HSL cylinder
 | alt1   =
 | image2  = HSV color solid cylinder saturation gray.png
 | caption2 = HSV cylinder
}}

HSL and HSV are both cylindrical geometries, with hue, their angular dimension, starting at the [[red]] [[primary color|primary]] at 0°, passing through the [[green]] primary at 120° and the [[blue]] primary at 240°, and then wrapping back to red at 360°. In each geometry, the central vertical axis comprises the ''neutral'', ''achromatic'', or ''gray'' colors, ranging from black at lightness 0 or value 0, the bottom, to white at lightness 1 or value 1, the top.

Most televisions, computer displays, and projectors produce colors by combining red, green, and blue light in varying intensities—the so-called [[RGB color model|RGB]] [[additive color|additive]] [[primary color]]s. However, the relationship between the constituent amounts of red, green, and blue light and the resulting color is unintuitive, especially for inexperienced users, and for users familiar with [[subtractive color]] mixing of paints or traditional artists’ models based on tints and shades.

In an attempt to accommodate more traditional and intuitive color mixing models, computer graphics pioneers at [[PARC (company)|PARC]] and [[New York Institute of Technology|NYIT]] developed{{explain|date=June 2018}} the HSV model in the mid-1970s, formally described by [[Alvy Ray Smith]]&lt;ref name=Smith&gt;[[#Smith|Smith (1978)]]&lt;/ref&gt; in the August 1978 issue of [[Computer Graphics (publication)|''Computer Graphics'']]. In the same issue, Joblove and Greenberg&lt;ref name=Joblove&gt;[[#Joblove|Joblove and Greenberg (1978)]]&lt;/ref&gt; described the HSL model—whose dimensions they labeled ''hue'', ''relative chroma'', and ''intensity''—and compared it to HSV. Their model was based more upon how colors are organized and conceptualized in [[color vision|human vision]] in terms of other color-making attributes, such as hue, lightness, and chroma; as well as upon traditional color mixing methods—e.g., in painting—that involve mixing brightly colored pigments with black or white to achieve lighter, darker, or less colorful colors.

The following year, 1979, at [[SIGGRAPH]], [[Tektronix]] introduced graphics terminals using HSL for color designation, and the Computer Graphics Standards Committee recommended it in their annual status report. These models were useful not only because they were more intuitive than raw RGB values, but also because the conversions to and from RGB were extremely fast to compute: they could run in real time on the hardware of the 1970s. Consequently, these models and similar ones have become ubiquitous throughout image editing and graphics software since then.

===Munsell color system===
{{multiple image
| total_width     = 440
| image1    = Munsell color sphere.png
| width1    = 581
| height1   = 660
| caption1  = Munsell’s color sphere, 1900. Later, Munsell discovered that if hue, value, and chroma were to be kept perceptually uniform, achievable surface colors could not be forced into a regular shape.
| image2    = Munsell 1943 color solid cylindrical coordinates.png
| width2    = 2400
| height2   = 1800
| caption2  = Three-dimensional representation of the 1943 Munsell renotations. Notice the irregularity of the shape when compared to Munsell's earlier color sphere, at left.
}}
{{main|Munsell color system}}
Another influential older cylindrical color model is the early-20th-century [[Munsell color system]]. [[Albert Henry Munsell|Albert Munsell]] began with a spherical arrangement in his 1905 book ''A Color Notation'', but he wished to properly separate color-making attributes into separate dimensions, which he called ''hue'', ''value'', and ''chroma'', and after taking careful measurements of perceptual responses, he realized that no symmetrical shape would do, so he reorganized his system into a lumpy blob.&lt;ref&gt;{{cite book |last1=Runge |first1=Phillipp Otto |author-link=Philipp Otto Runge |date=1810 |title=Die Farben-Kugel, oder Construction des Verhaeltnisses aller Farben zueinander |location=Hamburg, Germany |publisher=Perthes |language=German |trans-title=The Color Sphere, or Construction of the Relationship of All Colors to Each Other}}&lt;/ref&gt;&lt;ref&gt;[[Albert Henry Munsell]] (1905). ''A Color Notation''. Boston, MA: [[Munsell Color Company]].&lt;/ref&gt;{{refn|group=upper-alpha |See also [[#Fairchild|Fairchild (2005)]], and [[Munsell Color System]] and its references.}}

Munsell’s system became extremely popular, the de facto reference for American color standards—used not only for specifying the color of paints and crayons, but also, e.g., electrical wire, beer, and soil color—because it was organized based on perceptual measurements, specified colors via an easily learned and systematic triple of numbers, because the color chips sold in the ''Munsell Book of Color'' covered a wide [[gamut]] and remained stable over time (rather than fading), and because it was effectively marketed by [[Munsell Color Company|Munsell’s Company]]. In the 1940s, the [[Optical Society of America]] made extensive measurements, and adjusted the arrangement of Munsell colors, issuing a set of "renotations". The trouble with the Munsell system for computer graphics applications is that its colors are not specified via any set of simple equations, but only via its foundational measurements: effectively a [[lookup table]]. Converting from {{nobr|RGB ↔ Munsell}} requires interpolating between that table’s entries, and is extremely computationally expensive in comparison with converting from {{nobr|RGB ↔ HSL}} or {{nobr|RGB ↔ HSV}} which only requires a few simple arithmetic operations.&lt;ref name=Fairchild&gt;[[#Fairchild|Fairchild (2005)]]&lt;/ref&gt;&lt;ref&gt;{{cite journal |first1=Edward |last1=Landa |first2=Mark |last2=Fairchild |date=September–October 2005 |url=http://www.americanscientist.org/issues/feature/charting-color-from-the-eye-of-the-beholder/5 |title=Charting Color from the Eye of the Beholder |journal=American Scientist |volume=93 |issue=5 |page=436}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Dorothy Nickerson |year=1976|title=History of the Munsell Color System|journal=Color Research and Application|volume=1|pages=121–130}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=Sidney Newhall |author2=Dorothy Nickerson |author3=Deane Judd |doi=10.1364/JOSA.33.000385|title=Final Report of the OSA Subcommittee on the Spacing of the Munsell Colors|year=1943|journal=Journal of the Optical Society of America|volume=33|issue=7|pages=385}}&lt;/ref&gt;

===Preucil hue circle===
In [[densitometry]], a model quite similar to the hue defined above is used for describing colors of [[CMYK color model|CMYK process]] inks. In 1953, Frank Preucil developed two geometric arrangements of hue, the "Preucil hue circle" and the "Preucil hue hexagon", analogous to our ''H'' and ''H''&lt;sub&gt;2&lt;/sub&gt;, respectively, but defined relative to idealized cyan, yellow, and magenta ink colors. The "Preucil ''hue error''" of an ink indicates the difference in the "hue circle" between its color and the hue of the corresponding idealized ink color. The ''grayness'' of an ink is {{nobr|''m''/''M''}}, where ''m'' and ''M'' are the minimum and maximum among the amounts of idealized cyan, magenta, and yellow in a density measurement.&lt;ref&gt;Frank Preucil (1953). "Color Hue and Ink Transfer—Their Relation to Perfect Reproduction". ''Proceedings of the 5th Annual Technical Meeting of TAGA''. {{nobr|pp. 102–110}}.&lt;/ref&gt;

===Natural Color System===
The Swedish [[Natural Color System]] (NCS), widely used in Europe, takes a similar approach to the Ostwald bicone at right. Because it attempts to fit color into a familiarly shaped solid based on "[[phenomenology (psychology)|phenomenological]]" instead of photometric or psychological characteristics, it suffers from some of the same disadvantages as HSL and HSV: in particular, its lightness dimension differs from perceived lightness, because it forces colorful yellow, red, green, and blue into a plane.&lt;ref name=MacEvoy&gt;[[#MacEvoy|MacEvoy (2010)]]&lt;/ref&gt;

===CIELCH&lt;sub&gt;uv&lt;/sub&gt; and CIELCH&lt;sub&gt;ab&lt;/sub&gt;===
{{multiple image
 | total_width       = 440
 | image1 = Visible gamut within CIELCHuv color space D65 whitepoint mesh.webm
 | alt1 = Visible gamut in CIELCHuv space
 | thumbtime1 = 0
 | image2 = Visible gamut within CIELCHab color space D65 whitepoint mesh.webm
 | alt2 = Visible gamut within CIELCHab color space
 | thumbtime2 = 0
 | footer = The visible gamut under [[Illuminant D65]] plotted within the CIELCHuv (''left'') and CIELCHab (''right'') color spaces. ''L'' is the vertical axis; ''C'' is the cylinder radius; ''H'' is the angle around the circumference.
}}

The [[International Commission on Illumination]] (CIE) developed the [[CIE 1931 color space|XYZ model]] for describing the colors of light spectra in 1931, but its goal was to match human visual [[metamerism (color)|metamerism]], rather than to be perceptually uniform, geometrically. In the 1960s and 70s, attempts were made to transform XYZ colors into a more relevant geometry, influenced by the Munsell system. These efforts culminated in the 1976 [[CIELUV]] and [[CIELAB]] models. The dimensions of these models—{{nobr|(''L''*, ''u''*, ''v''*)}} and {{nobr|(''L''*, ''a''*, ''b''*)}}, respectively—are cartesian, based on the [[opponent process]] theory of color, but both are also often described using polar coordinates—{{nobr|(''L''*, ''C''*&lt;sub&gt;''uv''&lt;/sub&gt;, ''h''*&lt;sub&gt;''uv''&lt;/sub&gt;)}} and {{nobr|(''L''*, ''C''*&lt;sub&gt;''ab''&lt;/sub&gt;, ''h''*&lt;sub&gt;''ab''&lt;/sub&gt;)}}, respectively—where ''L''* is lightness, ''C''* is chroma, and ''h''* is hue angle. Officially, both CIELAB and CIELUV were created for their [[color difference]] metrics ∆''E''*&lt;sub&gt;''ab''&lt;/sub&gt; and ∆''E''*&lt;sub&gt;''uv''&lt;/sub&gt;, particularly for use defining color tolerances, but both have become widely used as color order systems and color appearance models, including in computer graphics and computer vision. For example, [[gamut mapping]] in [[International Color Consortium|ICC]] [[color management]] is usually performed in CIELAB space, and Adobe Photoshop includes a CIELAB mode for editing images. CIELAB and CIELUV geometries are much more perceptually relevant than many others such as RGB, HSL, HSV, YUV/YIQ/YCbCr or XYZ, but are not perceptually perfect, and in particular have trouble adapting to unusual lighting conditions.&lt;ref name=Fairchild/&gt;&lt;ref name=Kuehni&gt;[[#Kuehni|Kuehni (2003)]]&lt;/ref&gt;&lt;ref&gt;Robert Hunt (2004). ''The Reproduction of Colour''. 6th ed. MN: Voyageur Press. {{ISBN|0-86343-368-5}}.&lt;/ref&gt;&lt;ref name=MacEvoy/&gt;&lt;ref&gt;{{cite web |website=Adobe Systems |date=January 2007 |archive-url=https://web.archive.org/web/20081207061220/http://kb.adobe.com/selfservice/viewContent.do?externalId=310838 |url=http://kb.adobe.com/selfservice/viewContent.do?externalId=310838 |title=The Lab Color Mode in Photoshop |archive-date=2008-12-07 |deadurl=yes |df= }}&lt;/ref&gt;&lt;ref&gt;Steven K. Shevell (2003) ''The Science of Color''. 2nd ed. Elsevier Science &amp; Technology. {{ISBN|0-444-51251-9}}. https://books.google.com/books?id=G1TC1uXb7awC&amp;pg=PA201 {{nobr|pp. 202–206}}&lt;/ref&gt;{{refn|group=upper-alpha|See also [[CIELAB]], [[CIELUV]], [[Color difference]], [[Color management]], and their references.}}

The [[HCL color space]] seems to be synonymous with CIELCH.

===CIECAM02===
The CIE’s most recent model, [[CIECAM02]] (CAM stands for "color appearance model"), is more theoretically sophisticated and computationally complex than earlier models. Its aims are to fix several of the problems with models such as CIELAB and CIELUV, and to explain not only responses in carefully controlled experimental environments, but also to model the color appearance of real-world scenes. Its dimensions ''J'' (lightness), ''C'' (chroma), and ''h'' (hue) define a polar-coordinate geometry.&lt;ref name=Fairchild/&gt;&lt;ref name=MacEvoy/&gt;
&lt;!-- TODO: add some pictures after the top pair? --&gt;

== Color systems ==

There are various types of color systems that classify color and analyse their effects. The American [[Munsell color system]] devised by [[Albert Henry Munsell|Albert H. Munsell]] is a famous classification that organises various colors into a color solid based on hue, saturation and value. Other important color systems include the Swedish [[Natural Color System]] (NCS), the [[Optical Society of America]]'s [[Uniform Color Space]] (OSA-UCS), and the Hungarian [[Coloroid]] system developed by [[Antal Nemcsics]] from the [[Budapest University of Technology and Economics]]. Of those, the NCS is based on the [[opponent process|opponent-process]] color model, while the Munsell, the OSA-UCS and the Coloroid attempt to model color uniformity. The American [[Pantone]] and the German [[RAL (color space system)|RAL]] commercial color-matching systems differ from the previous ones in that their color spaces are not based on an underlying color model.

== Other uses of "color model" ==
=== Models of mechanism of color vision ===

We also use "color model" to indicate a model or mechanism of color vision for explaining how color signals are processed from visual cones to ganglion cells.  For simplicity, we call these models color mechanism models. The classical color mechanism models are [[Thomas Young (scientist)|Young]]–[[Hermann von Helmholtz|Helmholtz]]'s [[Young–Helmholtz theory|trichromatic model]] and [[Ewald Hering|Hering]]'s [[opponent process|opponent-process model]]. Though these two theories were initially thought to be at odds, it later came to be understood that the mechanisms responsible for color opponency receive signals from the three types of cones and process them at a more complex level.&lt;ref name="Kandel"&gt;Kandel ER, Schwartz JH and Jessell TM, 2000. ''Principles of Neural Science'', 4th ed., McGraw-Hill, New York. pp.&amp;nbsp;577–80.&lt;/ref&gt;

=== Vertebrate evolution of color vision ===

{{main|Evolution of color vision}}

Vertebrate animals were primitively [[tetrachromatic]]. They possessed four types of cones—long, mid, short wavelength cones, and ultraviolet sensitive cones.  Today, fish, amphibians, reptiles and birds are all tetrachromatic. Placental mammals lost both the mid and short wavelength cones. Thus, most mammals do not have complex color vision—they are [[dichromacy|dichromatic]] but they are sensitive to ultraviolet light, though they cannot see its colors. Human trichromatic color vision is a recent evolutionary novelty that first evolved in the common ancestor of the Old World Primates. Our trichromatic color vision evolved by duplication of the long wavelength sensitive [[opsin]], found on the X chromosome. One of these copies evolved to be sensitive to green light and constitutes our mid wavelength opsin. At the same time, our short wavelength opsin evolved from the ultraviolet opsin of our vertebrate and mammalian ancestors.

Human [[red-green color blindness]] occurs because the two copies of the red and green opsin genes remain in close proximity on the X chromosome. Because of frequent recombination during meiosis, these gene pairs can get easily rearranged, creating versions of the genes that do not have distinct spectral sensitivities.

== See also ==

*[[Color appearance model]]
*[[Comparison of color models in computer graphics]]

==Notes==
{{reflist|group=upper-alpha |45em}}

== References ==
{{reflist}}

==Bibliography==
* {{cite book|ref= Fairchild|author=Fairchild, Mark D. |year=2005|url=http://www.cis.rit.edu/fairchild/CAM.html |title=Color Appearance Models|edition= 2nd|publisher= Addison-Wesley}} This book doesn’t discuss HSL or HSV specifically, but is one of the most readable and precise resources about current color science.
* {{cite journal|ref=Joblove|author1=Joblove, George H. |author2=Greenberg, Donald |date=August 1978|url=http://portal.acm.org/citation.cfm?id=807362 |title=Color spaces for computer graphics|journal= [[Computer Graphics (publication)|Computer Graphics]]|volume=12|issue=3|pages= 20–25|doi=10.1145/965139.807362}} Joblove and Greenberg’s paper was the first describing the HSL model, which it compares to HSV.
* {{cite book|ref=Kuehni|author= Kuehni, Rolf G. |year=2003|title=Color Space and Its Divisions: Color Order from Antiquity to the present|place=New York|publisher= Wiley|isbn=978-0-471-32670-0}} This book only briefly mentions HSL and HSV, but is a comprehensive description of color order systems through history.
* {{cite journal|ref=Levkowitz|author1=Levkowitz, Haim |author2=Herman, Gabor T. |year=1993 |title=GLHS: A Generalized Lightness, Hue and Saturation Color Model|journal=CVGIP: Graphical Models and Image Processing |volume=55 |issue=4 |pages=271–285 |doi=10.1006/cgip.1993.1019}} This paper explains how both HSL and HSV, as well as other similar models, can be thought of as specific variants of a more general "GLHS" model. Levkowitz and Herman provide pseudocode for converting from RGB to GLHS and back.
* {{cite web|ref=MacEvoy|author=MacEvoy, Bruce |date=January 2010|url=http://www.handprint.com/LS/CVS/color.html |title=Color Vision|work=handprint.com}}. Especially the sections about [http://www.handprint.com/HP/WCL/color7.html "Modern Color Models"] and [http://www.handprint.com/HP/WCL/color18a.html "Modern Color Theory"]. MacEvoy’s extensive site about color science and paint mixing is one of the best resources on the web. On this page, he explains the color-making attributes, and the general goals and history of color order systems—including HSL and HSV—and their practical relevance to painters.
* {{cite journal|ref=Smith|author=Smith, Alvy Ray |authorlink=Alvy Ray Smith|date=August 1978|url=http://portal.acm.org/citation.cfm?id=807361 |title=Color gamut transform pairs|journal=Computer Graphics|volume=12|issue=3|pages=12–19|doi=10.1145/965139.807361}} This is the original paper describing the "hexcone" model, HSV. Smith was a researcher at [[New York Institute of Technology|NYIT]]’s Computer Graphics Lab. He describes HSV’s use in an early [[raster graphics|digital painting]] program.

== External links ==
* [http://learn.colorotate.org/color-models/ Illustrations and summaries of RGB, CMYK,  LAB, HSV, HSL, and NCS]
* [http://www.cs.rit.edu/~ncs/color/a_spaces.html Demonstrative color conversion applet]
* [http://demonstrations.wolfram.com/HSVColors/ HSV Colors] by Hector Zenil, [[The Wolfram Demonstrations Project]].
* [https://codebeautify.org/hsv-to-rgb-converter HSV to RGB] by CodeBeautify.

{{Color space}}
{{Color topics}}
[[Category:Color|Model]]
[[Category:Mathematical modeling]]
[[Category:Color models|*]]
[[Category:Color vision]]</text>
      <sha1>lqs1q3mf5kx7rj48rwsy1kjx9ypgsy7</sha1>
    </revision>
  </page>
  <page>
    <title>Contraction morphism</title>
    <ns>0</ns>
    <id>52622473</id>
    <revision>
      <id>849278963</id>
      <parentid>848875472</parentid>
      <timestamp>2018-07-07T21:33:10Z</timestamp>
      <contributor>
        <username>Katharineamy</username>
        <id>2590656</id>
      </contributor>
      <comment>added [[Category:Algebraic geometry]]; removed {{uncategorized}} using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2054">In [[algebraic geometry]], a '''contraction morphism''' is a surjective [[projective morphism]] &lt;math&gt;f: X \to Y&lt;/math&gt; between normal projective varieties (or projective schemes) such that &lt;math&gt;f_* \mathcal{O}_X = \mathcal{O}_Y&lt;/math&gt; or, equivalently, the geometric fibers are all connected ([[Zariski's connectedness theorem]]). It is also commonly called an '''algebraic fiber space''', as it is an analog of a [[fiber space]] in algebraic topology.

By the [[Stein factorization]], any surjective projective morphism is a contraction morphism followed by a finite morphism.

Examples include [[ruled surface]]s and [[Mori fiber space]]s.

== Birational perspective ==
The following perspective is crucial in [[birational geometry]] (in particular in [[Mori's minimal model program]]).

Let ''X'' be a projective variety and &lt;math&gt;\overline{NS}(X)&lt;/math&gt; the closure of the span of irreducible curves on ''X'' in &lt;math&gt;N_1(X)&lt;/math&gt; = the real vector space of numerical equivalence classes of real 1-cycles on ''X''. Given a face ''F'' of &lt;math&gt;\overline{NS}(X)&lt;/math&gt;, the '''contraction morphism associated to ''F''''', if it exists, is a contraction morphism &lt;math&gt;f: X \to Y&lt;/math&gt; to some projective variety ''Y'' such that for each irreducible curve &lt;math&gt;C \subset X&lt;/math&gt;, &lt;math&gt;f(C)&lt;/math&gt; is a point if and only if &lt;math&gt;[C] \in F&lt;/math&gt;.&lt;ref&gt;{{harvnb|Kollár–Mori|loc=Definition 1.25.}}&lt;/ref&gt; The basic question is which face ''F'' gives rise to such a contraction morphism (cf. [[cone theorem]]).

== See also ==
*[[Castelnuovo's contraction theorem]]
*[[Flip (mathematics)]]

== References ==
{{reflist}}
*{{Citation | last1=Kollár | first1=János | last2=Mori | first2=Shigefumi | title=Birational geometry of algebraic varieties | publisher=[[Cambridge University Press]] | series=Cambridge Tracts in Mathematics | isbn=978-0-521-63277-5 |mr=1658959 | year=1998 | volume=134}}
*[[Robert Lazarsfeld]], ''Positivity in Algebraic Geometry I: Classical Setting'' (2004)


{{algebraic-geometry-stub}}



[[Category:Algebraic geometry]]</text>
      <sha1>0o5ibglti3fvsdb72p92fvjjpospbs9</sha1>
    </revision>
  </page>
  <page>
    <title>Control variable (programming)</title>
    <ns>0</ns>
    <id>47790980</id>
    <revision>
      <id>868177931</id>
      <parentid>868166016</parentid>
      <timestamp>2018-11-10T14:18:31Z</timestamp>
      <contributor>
        <username>BernardoSulzbach</username>
        <id>33434303</id>
      </contributor>
      <comment>Disambiguated: Ada → Ada (programming language)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1169">{{confuse|Control variable}}
A '''control variable''' in [[computer programming]] is a [[program variable]] that is used to regulate the [[flow of control]] of the program.

In definite iteration, control variables are variables which are successively assigned (or bound to) values from a predetermined sequence of values.&lt;ref name="Watt"&gt;{{cite book |last1=Watt |first1=David A. |title=Programming Language Design Concepts |date=2004 |publisher=Wiley |pages=84-85}}&lt;/ref&gt;

== Special rules ==

In some programming languages control variables are just ordinary variables used for manipulating the program flow. This is the case of [[C (programming language)|C]], [[Fortran]], and [[Pascal (programming language)|Pascal]], which allow for control variables to have their values changed within the loop body.&lt;ref name="Watt"/&gt; However, some languages have special rules for control variables. In [[Ada (programming language)|Ada]], for instance, the control variable of the for loop must remain constant within the loop body.

== References ==

{{reflist}}

{{Computer science}}

[[Category:Mathematical terminology]]
[[Category:Computing terminology]]

{{comp-sci-stub}}</text>
      <sha1>f0r3hkyg9op3p9dskqfzphlyonc2pfo</sha1>
    </revision>
  </page>
  <page>
    <title>Definitions of mathematics</title>
    <ns>0</ns>
    <id>21653957</id>
    <revision>
      <id>867540330</id>
      <parentid>867523001</parentid>
      <timestamp>2018-11-06T11:06:17Z</timestamp>
      <contributor>
        <username>DVdm</username>
        <id>262666</id>
      </contributor>
      <comment>Reverted to revision 854302537 by [[Special:Contributions/Jim1138|Jim1138]] ([[User talk:Jim1138|talk]]): Undo junk. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12246">[[Mathematics]] has no generally accepted definition.  Different schools of thought, particularly in [[philosophy]], have put forth radically different definitions. All are controversial.&lt;ref name=Mura/&gt;&lt;ref name=Runge/&gt;

==Survey of leading definitions==
=== Early definitions ===

[[Aristotle]] defined mathematics as:&lt;ref name=Cajori/&gt;

&lt;blockquote&gt;The science of [[quantity]].&lt;/blockquote&gt;

In Aristotle's classification of the [[sciences]], discrete quantities were studied by [[arithmetic]], continuous quantities by [[geometry]].&lt;ref name=Franklin&gt;James Franklin, "Aristotelian Realism" in ''Philosophy of Mathematics", ed. A.D. Irvine, [https://books.google.com/books?id=mbn35b2ghgkC&amp;pg=PA104#v=onepage&amp;q&amp;f=false p. 104]. Elsevier (2009).&lt;/ref&gt;

[[Auguste Comte]]'s definition tried to explain the role of mathematics in coordinating phenomena in all other [[fields of study|fields]]:&lt;ref&gt;Arline Reilein Standley, ''Auguste Comte,'' p. 61. Twayne Publishers (1981).&lt;/ref&gt;

&lt;blockquote&gt;The science of indirect measurement.&lt;ref name=Cajori&gt;Florian Cajori ''et al.,'' ''A History of Mathematics,'' 5th ed., [https://books.google.com/books?id=mGJRjIC9fZgC&amp;lpg=PA285&amp;pg=PA285#v=onepage&amp;q&amp;f=false p. 285–6]. American Mathematical Society (1991).&lt;/ref&gt; &lt;small&gt;[[Auguste Comte]] 1851&lt;/small&gt;&lt;/blockquote&gt;

The "indirectness" in Comte's definition refers to determining quantities that cannot be measured directly, such as the distance to planets or the size of atoms, by means of their relations to quantities that can be measured directly.&lt;ref&gt;Auguste Comte, ''The Philosophy of Mathematics,'' tr. W.M. Gillespie, [https://books.google.com/books?id=EXutRb2evHoC&amp;pg=PA25#v=onepage&amp;q&amp;f=false pp. 17–25]. Harper &amp; Brothers, New York (1851).&lt;/ref&gt;

=== Greater abstraction and competing philosophical schools ===
The preceding kinds of definitions, which had prevailed since Aristotle's time,&lt;ref name=Franklin/&gt; were abandoned in the 19th century as new branches of mathematics were developed, which bore no obvious relation to measurement or the physical world, such as [[group theory]], [[projective geometry]],&lt;ref name=Cajori/&gt; and [[non-Euclidean geometry]].&lt;ref name=Russell/&gt; As mathematicians pursued greater [[Rigor#Mathematical rigour|rigor]] and more-abstract [[foundations of mathematics|foundations]], some proposed definitions purely in terms of [[logic]]:

&lt;blockquote&gt;Mathematics is the science that draws necessary conclusions.&lt;ref name=eves&gt;[https://books.google.com/books?id=-UzKwHWzdesC Foundations and fundamental concepts of mathematics By Howard Eves] page 150&lt;/ref&gt; &lt;small&gt;[[Benjamin Peirce]] 1870&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;All Mathematics is Symbolic Logic.&lt;ref name=Russell&gt;Bertrand Russell, ''The Principles of Mathematics,'' [https://books.google.com/books?id=kj0a_aV2mxIC&amp;pg=PA5#v=onepage&amp;q&amp;f=false p. 5]. University Press, Cambridge (1903)&lt;/ref&gt; &lt;small&gt;[[Bertrand Russell]] 1903&lt;/small&gt;&lt;/blockquote&gt;

Peirce did not think that mathematics is the same as logic, since he thought mathematics makes only hypothetical assertions, not [[categorical proposition|categorical]] ones.&lt;ref&gt;Carl Boyer, [[Uta Merzbach]], ''A History of Mathematics,'' [https://books.google.com/books?id=BokVHiuIk9UC&amp;pg=PT426#v=onepage&amp;q&amp;f=false p. 426]. John Wiley &amp; Sons (2011).&lt;/ref&gt; Russell's definition, on the other hand, expresses the [[logicist]] [[philosophy of mathematics]]&lt;ref name='three-crises'&gt;{{Citation |last=Snapper |first=Ernst |date=September 1979 |title=The Three Crises in Mathematics: Logicism, Intuitionism, and Formalism |journal=Mathematics Magazine |doi=10.2307/2689412 |jstor=2689412 |volume=52 |issue=4 |pages=207–16}}&lt;/ref&gt; without reservation. Competing philosophies of mathematics put forth different definitions.

Opposing the completely deductive character of logicism, [[intuitionism]] emphasizes the construction of ideas in the mind. Here is an intuitionist definition:&lt;ref name=three-crises/&gt;

&lt;blockquote&gt;Mathematics is mental activity which consists in carrying out, one after the other, those mental constructions which are inductive and effective.&lt;/blockquote&gt;

meaning that by combining fundamental ideas, one reaches a definite result.

[[formalism (mathematics)|Formalism]] denies both physical and mental meaning to mathematics, making the symbols and rules themselves the object of study.&lt;ref name='three-crises'/&gt; A formalist definition:

&lt;blockquote&gt;Mathematics is the manipulation of the meaningless symbols of a first-order language according to explicit, syntactical rules.&lt;/blockquote&gt;

Still other approaches emphasize pattern, order, or structure. For example:

&lt;blockquote&gt;Mathematics is the classification and study of all possible patterns.&lt;ref name="Sawyer"&gt;{{cite book | url=https://books.google.com/books?id=6wF4SklxcnkC&amp;pg=PA12 | title=Prelude to Mathematics | publisher=Penguin Books | author=Sawyer, W.W. | authorlink=Walter Warwick Sawyer | year=1955 | pages=12 | isbn=0486244016}}&lt;/ref&gt; &lt;small&gt;[[Walter Warwick Sawyer]], 1955&lt;/small&gt;&lt;/blockquote&gt;

Yet another approach makes abstraction the defining criterion:

&lt;blockquote&gt;Mathematics is a broad-ranging field of study in which the properties and interactions of idealized objects are examined. &lt;small&gt;[http://mathworld.wolfram.com/Mathematics.html Wolfram MathWorld]&lt;/small&gt;&lt;/blockquote&gt;

=== Definitions in general reference works ===
Most contemporary reference works define mathematics by summarizing its main topics and methods:

&lt;blockquote&gt;The abstract science which investigates deductively the conclusions implicit in the elementary conceptions of spatial and numerical relations, and which includes as its main divisions geometry, arithmetic, and algebra. &lt;small&gt;[[Oxford English Dictionary]], 1933&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;The study of the measurement, properties, and relationships of quantities and sets, using numbers and symbols. &lt;small&gt;[[American Heritage Dictionary]], 2000&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;The science of structure, order, and relation that has evolved from elemental practices of counting, measuring, and describing the shapes of objects.&lt;ref&gt;"Mathematics. ''Encyclopædia Britannica'' from [[Encyclopædia Britannica 2006 Ultimate reference Suite DVD]].&lt;/ref&gt; &lt;small&gt;[[Encyclopædia Britannica]], 2006&lt;/small&gt;&lt;/blockquote&gt;

== Playful, metaphorical, and poetic definitions ==
Bertrand Russell wrote this famous tongue-in-cheek definition, describing the way all terms in mathematics are ultimately defined by reference to undefined terms:

&lt;blockquote&gt;The subject in which we never know what we are talking about, nor whether what we are saying is true.&lt;ref&gt;{{Citation |last=Russell |first=Bertrand |date=1901 |title=Recent Work on the Principles of Mathematics |journal=International Monthly |volume=4}}&lt;/ref&gt; &lt;small&gt;[[Bertrand Russell]] 1901&lt;/small&gt;&lt;/blockquote&gt;

Many other attempts to characterize mathematics have led to humor or poetic prose:

&lt;blockquote&gt;A mathematician is a blind man in a dark room looking for a black cat which isn't there.&lt;ref&gt;"Pi in the Sky", John Barrow&lt;/ref&gt; &lt;small&gt;[[Charles Darwin]]&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;A mathematician, like a painter or poet, is a maker of patterns. If his patterns are more permanent than theirs, it is because they are made with ideas. &lt;small&gt;[[G. H. Hardy]], 1940&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;Mathematics is the art of giving the same name to different things.&lt;ref name=eves/&gt; &lt;small&gt;[[Henri Poincaré]]&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;Mathematics is the science of skillful operations with concepts and rules invented just for this purpose. [this purpose being the skillful operation ....]&lt;ref&gt;Wigner, Eugene P. (1960). "[[The Unreasonable Effectiveness of Mathematics in the Natural Sciences]]," ''Communications in Pure and Applied Sciences'', 13(1960):1–14. Reprinted in ''Mathematics: People, Problems, Results,'' vol. 3, ed. Douglas M. Campbell and John C. Higgins, [https://books.google.com/books?id=FcgB818WAQgC&amp;lpg=PA116&amp;pg=PA116 p. 116]&lt;/ref&gt; &lt;small&gt;[[Eugene Wigner]]&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;Mathematics is not a book confined within a cover and bound between brazen clasps, whose contents it needs only patience to ransack; it is not a mine, whose treasures may take long to reduce into possession, but which fill only a limited number of veins and lodes; it is not a soil, whose fertility can be exhausted by the yield of successive harvests; it is not a continent or an ocean, whose area can be mapped out and its contour defined: it is limitless as that space which it finds too narrow for its aspirations; its possibilities are as infinite as the worlds which are forever crowding in and multiplying upon the astronomer's gaze; it is as incapable of being restricted  within assigned boundaries or being reduced to definitions of permanent validity, as the consciousness of life, which seems to slumber in each monad, in every atom of matter, in each leaf and bud cell, and is forever ready to burst forth into new forms of vegetable and animal existence.&lt;ref name=StewartFrom&gt;"From Here to Infinity", Ian Stewart&lt;/ref&gt; &lt;small&gt;[[James Joseph Sylvester]]&lt;/small&gt;&lt;/blockquote&gt;

&lt;blockquote&gt;What is mathematics? What is it for? What are mathematicians doing nowadays? Wasn't it all finished long ago? How many new numbers can you invent anyway? Is today's mathematics just a matter of huge calculations, with the mathematician as a kind of zookeeper, making sure the precious computers are fed and watered? If it's not, what is it other than the incomprehensible outpourings of superpowered brainboxes with their heads in the clouds and their feet dangling from the lofty balconies of their ivory towers? Mathematics is all of these, and none. Mostly, it's just different. It's not what you expect it to be, you turn your back for a moment and it's changed. It's certainly not just a fixed body of knowledge, its growth is not confined to inventing new numbers, and its hidden tendrils pervade every aspect of modern life.&lt;ref name=StewartFrom/&gt; &lt;small&gt;[[Ian Stewart (mathematician)|Ian Stewart]]&lt;/small&gt;&lt;/blockquote&gt;

== See also ==
* [[Philosophy of mathematics]]

== References ==
{{Reflist|refs=
&lt;ref name="Mura"&gt;{{citation |last=Mura |first=Robert |date=December 1993 |title=Images of Mathematics Held by University Teachers of Mathematical Sciences |journal=Educational Studies in Mathematics |volume=25 |issue=4 |pages=375–385 |jstor=10.2307/3482762 |ref=harv}}&lt;/ref&gt;
&lt;ref name="Runge"&gt;{{citation |last1=Tobies |first1=Renate |last2=Neunzert |first2=Helmut |date=2012 |title=Iris Runge: A Life at the Crossroads of Mathematics, Science, and Industry |publisher=Springer |page=9 |isbn=3-0348-0229-3 |quote=It is first necessary to ask what is meant by ''mathematics'' in general. Illustrious scholars have debated this matter until they were blue in the face, and yet no consensus has been reached about whether mathematics is a natural science, a branch of the humanities, or an art form. |url=https://books.google.com/books?id=EDm0eQqFUQ4C&amp;pg=PA9}}&lt;/ref&gt;
}}

== Further reading ==
*{{citation |last1=Courant |first1=Richard |author1-link=Richard Courant |last2=Robbins |first2=Herbert |author2-link=Herbert Robbins |date=1996 |title=[[What is Mathematics?]] |edition=2nd |publisher=Oxford University Press |isbn=978-0-19-510519-3}}
*{{citation |editor1-last=Gowers |editor1-first=Timothy |editor1-link=Timothy Gowers |editor2-last=Barrow-Green |editor2-first=June |editor3-last=Leader |editor3-first=Imre |editor3-link=Imre Leader |date=2008 |title=[[The Princeton Companion to Mathematics]] |publisher=Princeton University Press |isbn=978-0-691-11880-2}}
*{{citation |last=Hersh |first=Reuben |authorlink=Reuben Hersh |date=1999 |title=What is Mathematics, Really? |publisher=Oxford University Press |isbn=978-0-19-513087-4}}
*{{citation |last=Paulos |first=John Allen |authorlink=John Allen Paulos |date=1991 |title=Beyond Numeracy |publisher=Viking |isbn=978-0-670-83654-3}}
*{{citation |last=Stewart |first=Ian |authorlink=Ian Stewart (mathematician) |date=1996 |title=[[From Here to Infinity (book)|From Here to Infinity]] |publisher=Oxford University Press |isbn=0-19-283202-6}}

[[Category:Philosophy of mathematics]]
[[Category:Definitions|Mathematics]]</text>
      <sha1>4gfq7w4q5gg9m2t56jpmne2w9esdcub</sha1>
    </revision>
  </page>
  <page>
    <title>Del</title>
    <ns>0</ns>
    <id>151925</id>
    <revision>
      <id>870136608</id>
      <parentid>860569408</parentid>
      <timestamp>2018-11-22T17:14:37Z</timestamp>
      <contributor>
        <ip>24.188.19.18</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16982">{{Other uses}}
{{hatnote | This article is about the usage of del for mathematics, for information on the symbol itself see [[nabla symbol]]}}
{{No footnotes|date=March 2010}}

[[File:Del.svg|right|100px|thumb|Del operator,&lt;br /&gt;represented by&lt;br /&gt;the [[nabla symbol]]]]
'''Del''', or '''nabla''', is an [[Operator (mathematics)|operator]] used in mathematics, in particular in [[vector calculus]], as a [[vector (geometry)|vector]] [[differential operator]], usually represented by the [[nabla symbol]] '''&amp;nabla;'''.  When applied to a [[function (mathematics)|function]] defined on a [[dimension (mathematics)|one-dimensional]] domain, it denotes its standard [[derivative]] as defined in [[calculus]]. When applied to a field (a function defined on a multi-dimensional domain), it may denote the [[gradient]] (locally steepest slope) of a [[scalar field]] (or sometimes of a [[vector field]], as in the [[Navier–Stokes equations#Interpretation as v·(&amp;nabla;v)|Navier–Stokes equations]]), the [[divergence]] of a vector field, or the [[curl (mathematics)|curl]] (rotation) of a vector field, depending on the way it is applied.

Strictly speaking, del is not a specific operator, but rather a convenient [[mathematical notation]] for those three operators, that makes many [[equations]] easier to write and remember.  The del symbol can be interpreted as a vector of [[partial derivative]] operators, and its three possible meanings—gradient, divergence, and curl—can be formally viewed as the [[Product (mathematics)|product]] with a scalar, a [[dot product]], and a [[cross product]], respectively, of the del "operator" with the field. These formal products do not necessarily [[commutative operation|commute]] with other operators or products.  These three uses, detailed below, are summarized as:
* Gradient: &lt;math&gt;\operatorname{grad}f = \nabla f&lt;/math&gt;
* Divergence: &lt;math&gt;\operatorname{div}\vec v =  \nabla \cdot \vec v &lt;/math&gt;
* Curl: &lt;math&gt;\operatorname{curl}\vec v =  \nabla \times \vec v&lt;/math&gt;

==Definition==
In the [[Cartesian coordinate system]] '''R'''&lt;sup&gt;{{mvar|n}}&lt;/sup&gt; with coordinates &lt;math&gt;(x_1, \dots, x_n)&lt;/math&gt; and [[standard basis]] &lt;math&gt;\{\vec e_1, \dots, \vec e_n \}&lt;/math&gt;, del is defined in terms of [[partial derivative]] operators as
:&lt;math&gt; \nabla = \sum_{i=1}^n \vec e_i {\partial \over \partial x_i} = \left( {\partial \over \partial x_1}, \ldots, {\partial \over \partial x_n} \right)&lt;/math&gt;

In [[three-dimensional]] Cartesian coordinate system '''R'''&lt;sup&gt;3&lt;/sup&gt; with coordinates &lt;math&gt;(x, y, z)&lt;/math&gt; and standard basis or unit vectors of axes &lt;math&gt;\{\vec e_x, \vec e_y, \vec e_z \}&lt;/math&gt;, del is written as
:&lt;math&gt;\nabla = \vec e_x {\partial \over \partial x} + \vec e_y {\partial \over \partial y} + \vec e_z {\partial \over \partial z}= \left( {\partial \over \partial x}, {\partial \over \partial y}, {\partial \over \partial z} \right) &lt;/math&gt;

Del can also be expressed in other coordinate systems, see for example [[del in cylindrical and spherical coordinates]].

==Notational uses==
Del is used as a shorthand form to simplify many long mathematical expressions. It is most commonly used to simplify expressions for the [[gradient]], [[divergence]], [[Curl (mathematics)|curl]], [[directional derivative]], and [[Laplacian]].

===Gradient===
The vector derivative of a [[scalar field]] &lt;math&gt;f&lt;/math&gt; is called the [[gradient]], and it can be represented as:
: &lt;math&gt;\operatorname{grad}f = {\partial f \over \partial x} \vec e_x + {\partial f \over \partial y} \vec e_y + {\partial f \over \partial z} \vec e_z=\nabla f&lt;/math&gt;

It always points in the [[Direction_(geometry)|direction]] of greatest increase of &lt;math&gt;f&lt;/math&gt;, and it has a [[magnitude (mathematics)|magnitude]] equal to the maximum rate of increase at the point&amp;mdash;just like a standard derivative. In particular, if a hill is defined as a height function over a plane &lt;math&gt;h(x,y)&lt;/math&gt;, the gradient at a given location will be a vector in the xy-plane (visualizable as an arrow on a map) pointing along the steepest direction. The magnitude of the gradient is the value of this steepest slope.

In particular, this notation is powerful because the gradient product rule looks very similar to the 1d-derivative case:
: &lt;math&gt;\nabla(f g) = f \nabla g + g \nabla f&lt;/math&gt;

However, the rules for [[dot product]]s do not turn out to be simple, as illustrated by:
: &lt;math&gt;\nabla (\vec u \cdot \vec v) = (\vec u \cdot \nabla) \vec v + (\vec v \cdot \nabla) \vec u + \vec u \times (\nabla \times \vec v) + \vec v \times (\nabla \times \vec u)&lt;/math&gt;

===Divergence===
The [[divergence]] of a [[vector field]]
&lt;math&gt; \vec v(x, y, z) = v_x \vec e_x  + v_y \vec e_y + v_z \vec e_z &lt;/math&gt; is a [[scalar field|scalar]] function that can be represented as:
:&lt;math&gt;\operatorname{div}\vec v = {\partial v_x \over \partial x} + {\partial v_y \over \partial y} + {\partial v_z \over \partial z} = \nabla \cdot \vec v &lt;/math&gt;

The divergence is roughly a measure of a vector field's increase in the direction it points; but more accurately, it is a measure of that field's tendency to converge toward or repel from a point.

The power of the del notation is shown by the following product rule:
:&lt;math&gt;\nabla \cdot (f \vec v) = f (\nabla \cdot \vec v) + \vec v \cdot (\nabla f)&lt;/math&gt;

The formula for the [[vector product]] is slightly less intuitive, because this product is not commutative:
:&lt;math&gt;\nabla \cdot (\vec u \times \vec v) = \vec v \cdot (\nabla \times \vec u) - \vec u \cdot (\nabla \times \vec v)&lt;/math&gt;

===Curl===
The [[Curl (mathematics)|curl]] of a vector field &lt;math&gt;\vec v(x, y, z) = v_x\vec e_x  + v_y\vec e_y + v_z\vec e_z&lt;/math&gt; is a [[vector field|vector]] function that can be represented as:
:&lt;math&gt;\operatorname{curl}\vec v = \left( {\partial v_z \over \partial y} - {\partial v_y \over \partial z} \right) \vec e_x + \left( {\partial v_x \over \partial z} - {\partial v_z \over \partial x} \right) \vec e_y + \left( {\partial v_y \over \partial x} - {\partial v_x \over \partial y} \right) \vec e_z = \nabla \times \vec v&lt;/math&gt;

The curl at a point is proportional to the on-axis torque that a tiny pinwheel would be subjected to if it were centred at that point.

The vector product operation can be visualized as a pseudo-[[determinant]]:
:&lt;math&gt;\nabla \times \vec v = \left|\begin{matrix} \vec e_x &amp; \vec e_y &amp; \vec e_z \\[2pt] {\frac{\partial}{\partial x}} &amp; {\frac{\partial}{\partial y}} &amp; {\frac{\partial}{\partial z}} \\[2pt] v_x &amp; v_y &amp; v_z \end{matrix}\right|&lt;/math&gt;

Again the power of the notation is shown by the product rule:
:&lt;math&gt;\nabla \times (f \vec v) = (\nabla f) \times \vec v + f (\nabla \times \vec v)&lt;/math&gt;

Unfortunately the rule for the vector product does not turn out to be simple:
:&lt;math&gt;\nabla \times (\vec u \times \vec v) = \vec u \, (\nabla \cdot \vec v) - \vec v \, (\nabla \cdot \vec u) + (\vec v \cdot \nabla) \, \vec u - (\vec u \cdot \nabla) \, \vec v&lt;/math&gt;

===Directional derivative===
The [[directional derivative]] of a scalar field &lt;math&gt;f(x,y,z)&lt;/math&gt; in the direction
&lt;math&gt;\vec a(x,y,z) = a_x \vec e_x + a_y \vec e_y + a_z \vec e_z &lt;/math&gt; is defined as:
:&lt;math&gt;\vec a\cdot\operatorname{grad}f = a_x {\partial f \over \partial x} + a_y {\partial f \over \partial y} + a_z {\partial f \over \partial z} = \vec a \cdot (\nabla f) &lt;/math&gt;

This gives the rate of change of a field &lt;math&gt;f&lt;/math&gt; in the direction of &lt;math&gt;\vec a&lt;/math&gt;. In operator notation, the element in parentheses can be considered a single coherent unit; [[fluid dynamics]] uses this convention extensively, terming it the [[convective derivative]]&amp;mdash;the "moving" derivative of the fluid.

Note that &lt;math&gt; (\vec a \cdot \nabla) &lt;/math&gt; is an operator that takes scalar to a scalar. It can be extended to operate on a vector, by separately operate on each of its components.

===Laplacian===
The [[Laplace operator]] is a scalar operator that can be applied to either vector or scalar fields; for cartesian coordinate systems it is defined as:
: &lt;math&gt;\Delta = {\partial^2 \over \partial x^2} + {\partial^2 \over \partial y^2} + {\partial^2 \over \partial z^2} = \nabla \cdot \nabla = \nabla^2&lt;/math&gt;
and the definition for more general coordinate systems is given in [[vector Laplacian]].

The Laplacian is ubiquitous throughout modern [[mathematical physics]], appearing for example in [[Laplace's equation]], [[Poisson's equation]], the [[heat equation]], the [[wave equation]], and the [[Schrödinger equation]].

===Tensor derivative===
Del can also be applied to a vector field with the result being a [[tensor]]. The [[tensor derivative]] of a vector field &lt;math&gt;\vec{v}&lt;/math&gt; (in three dimensions) is a 9-term second-rank tensor – that is, a 3×3 matrix – but can be denoted simply as &lt;math&gt;\nabla \otimes \vec{v}&lt;/math&gt;, where &lt;math&gt;\otimes&lt;/math&gt; represents the [[dyadic product]]. This quantity is equivalent to the transpose of the [[Jacobian matrix]] of the vector field with respect to space. The divergence of the vector field can then be expressed as the [[Trace (linear algebra)|trace]] of this matrix.

For a small displacement &lt;math&gt;\delta \vec{r}&lt;/math&gt;, the change in the vector field is given by:
: &lt;math&gt; \delta \vec{v} = (\nabla \otimes \vec{v}) \sdot \delta \vec{r} &lt;/math&gt;

== Product rules ==

For [[vector calculus]]:

:&lt;math&gt;\begin{align}
                           \nabla (fg) &amp;= f\nabla g + g\nabla f \\
           \nabla(\vec u \cdot \vec v) &amp;= \vec u \times (\nabla \times \vec v) + \vec v \times (\nabla \times \vec u) + ( \vec u \cdot \nabla) \vec v + (\vec v \cdot \nabla )\vec u \\
               \nabla \cdot (f \vec v) &amp;= f (\nabla \cdot \vec v) + \vec v \cdot (\nabla f) \\
   \nabla \cdot (\vec u \times \vec v) &amp;= \vec v \cdot (\nabla \times \vec u) - \vec u \cdot (\nabla \times \vec v ) \\
              \nabla \times (f \vec v) &amp;= (\nabla f) \times \vec v + f (\nabla \times \vec v) \\
  \nabla \times (\vec u \times \vec v) &amp;= \vec u \, (\nabla \cdot \vec v) - \vec v \, (\nabla \cdot \vec u) + (\vec v \cdot \nabla) \, \vec u - (\vec u \cdot \nabla) \, \vec v
\end{align}&lt;/math&gt;

For [[matrix calculus]] (for which &lt;math&gt;\vec u \cdot \vec v&lt;/math&gt; can be written &lt;math&gt;\vec u^\text{T} \vec v&lt;/math&gt;):

:&lt;math&gt;\begin{align}
  (\mathbf{A}\nabla)^\text{T} \vec u &amp;= \nabla^\text{T} (\mathbf{A}^\text{T}\vec u) - (\nabla^\text{T} \mathbf{A}^\text{T}) \vec u
\end{align}&lt;/math&gt;

Another relation of interest (see e.g. ''[[Euler equations]]'') is the following, where &lt;math&gt;\vec u \otimes \vec v&lt;/math&gt; is the [[outer product]] tensor:
:&lt;math&gt;\begin{align}
    \nabla(\vec u \otimes \vec v) = (\nabla \cdot \vec u) \vec v + (\vec u \cdot \nabla) \vec v
\end{align}&lt;/math&gt;

==Second derivatives==
[[File:DCG chart.svg|thumb|DCG chart:

A simple chart depicting all rules pertaining to second derivatives.
D, C, G, L and CC stand for divergence, curl, gradient, Laplacian and curl of curl, respectively.

Arrows indicate existence of second derivatives. Blue circle in the middle represents curl of curl, whereas the other two red circles (dashed) mean that DD and GG do not exist. 
]]
When del operates on a scalar or vector, either a scalar or vector is returned. Because of the diversity of vector products (scalar, dot, cross) one application of del already gives rise to three major derivatives: the gradient (scalar product), divergence (dot product), and curl (cross product). Applying these three sorts of derivatives again to each other gives five possible second derivatives, for a scalar field ''f'' or a vector field '''''v'''''; the use of the scalar [[Laplacian]] and [[vector Laplacian]] gives two more:
: &lt;math&gt;\begin{align}
        \operatorname{div}(\operatorname{grad}f ) &amp;= \nabla \cdot (\nabla f) \\
       \operatorname{curl}(\operatorname{grad}f ) &amp;= \nabla \times (\nabla f) \\
                                         \Delta f &amp;= \nabla^2 f \\
   \operatorname{grad}(\operatorname{div}\vec v ) &amp;= \nabla (\nabla \cdot \vec v) \\
   \operatorname{div}(\operatorname{curl}\vec v ) &amp;= \nabla \cdot (\nabla \times \vec v) \\
  \operatorname{curl}(\operatorname{curl}\vec v ) &amp;= \nabla \times (\nabla \times \vec v) \\
                                    \Delta \vec v &amp;= \nabla^2 \vec v
\end{align}&lt;/math&gt;

These are of interest principally because they are not always unique or independent of each other.  As long as the functions are [[well-behaved]], two of them are always zero:
: &lt;math&gt;\begin{align}
      \operatorname{curl}(\operatorname{grad}f ) &amp;= \nabla \times (\nabla f) = 0 \\
  \operatorname{div}(\operatorname{curl}\vec v ) &amp;= \nabla \cdot \nabla \times \vec v = 0
\end{align}&lt;/math&gt;

Two of them are always equal:
: &lt;math&gt; \operatorname{div}(\operatorname{grad}f ) = \nabla \cdot (\nabla f) = \nabla^2 f = \Delta f &lt;/math&gt;

The 3 remaining vector derivatives are related by the equation:
:&lt;math&gt;\nabla \times \left(\nabla \times \vec v\right) = \nabla (\nabla \cdot \vec v) - \nabla^2 \vec{v}&lt;/math&gt;

And one of them can even be expressed with the tensor product, if the functions are well-behaved:
: &lt;math&gt;\nabla ( \nabla \cdot \vec v) = \nabla \cdot (\nabla \otimes \vec v)&lt;/math&gt;

==Precautions==

Most of the above vector properties (except for those that rely explicitly on del's differential properties&amp;mdash;for example, the product rule) rely only on symbol rearrangement, and must necessarily hold if the del symbol is replaced by any other vector. This is part of the value to be gained in notationally representing this operator as a vector.

Though one can often replace del with a vector and obtain a vector identity, making those identities mnemonic, the reverse is ''not'' necessarily reliable, because del does not commute in general.

A counterexample that relies on del's failure to commute:
:&lt;math&gt;\begin{align}
              (\vec u \cdot \vec v) f &amp;\equiv (\vec v \cdot \vec u) f \\
              (\nabla \cdot \vec v) f &amp;= \left (\frac{\partial v_x}{\partial x} + \frac{\partial v_y}{\partial y} + \frac{\partial v_z}{\partial z} \right )f
                                        = \frac{\partial v_x}{\partial x}f + \frac{\partial v_y}{\partial y}f + \frac{\partial v_z}{\partial z}f \\
              (\vec v \cdot \nabla) f &amp;= \left (v_x \frac{\partial}{\partial x} + v_y \frac{\partial}{\partial y} + v_z \frac{\partial}{\partial z} \right )f
                                        = v_x \frac{\partial f}{\partial x} + v_y \frac{\partial f}{\partial y} + v_z \frac{\partial f}{\partial z} \\
  \Rightarrow (\nabla \cdot \vec v) f &amp;\ne (\vec v \cdot \nabla) f \\
\end{align}&lt;/math&gt;

A counterexample that relies on del's differential properties:
: &lt;math&gt;\begin{align}
  (\nabla x) \times (\nabla y) &amp;= \left (\vec e_x \frac{\partial x}{\partial x}+\vec e_y \frac{\partial x}{\partial y}+\vec e_z \frac{\partial x}{\partial z} \right ) \times \left (\vec e_x \frac{\partial y}{\partial x}+\vec e_y \frac{\partial y}{\partial y}+\vec e_z \frac{\partial y}{\partial z} \right ) \\
                               &amp;= (\vec e_x \cdot 1 +\vec e_y \cdot 0+\vec e_z \cdot 0) \times (\vec e_x \cdot 0+\vec e_y \cdot 1+\vec e_z \cdot 0) \\
                               &amp;= \vec e_x  \times \vec e_y \\
                               &amp;= \vec e_z \\
  (\vec u x )\times (\vec u y) &amp;= x y (\vec u \times \vec u) \\
                               &amp;= x y \vec 0 \\
                               &amp;= \vec 0
\end{align}&lt;/math&gt;

Central to these distinctions is the fact that del is not simply a vector; it is a [[vector operator]]. Whereas a vector is an object with both a magnitude and direction, del has neither a magnitude nor a direction until it operates on a function.

For that reason, identities involving del must be derived with care, using both vector identities and ''differentiation'' identities such as the product rule.

==See also==
* [[Del in cylindrical and spherical coordinates]]
* [[Notation for differentiation]]
* [[Vector calculus identities]]
* [[Maxwell's equations]]
* [[Navier–Stokes equations]]
* [[Table of mathematical symbols]]
* [[Quabla operator]]

==References==
* [[Willard Gibbs]] &amp; [[Edwin Bidwell Wilson]] (1901) [[Vector Analysis]], [[Yale University Press]], 1960: [[Dover Publications]].
*{{cite book |title=Div, Grad, Curl, and All That: An Informal Text on Vector Calculus |first=H. M. |last=Schey |year=1997 |location=New York |publisher=Norton |isbn=0-393-96997-5 }}
*{{cite web |first=Jeff |last=Miller |url=http://jeff560.tripod.com/calculus.html |title=Earliest Uses of Symbols of Calculus |year= |work= }}
* {{cite web |author=Arnold Neumaier |editor=Cleve Moler |url=http://www.netlib.org/na-digest-html/98/v98n03.html#2 |title=History of Nabla |series=NA Digest, Volume 98, Issue 03 |publisher=netlib.org |date=January 26, 1998}}

==External links==
*[http://hdl.handle.net/2027.42/7869 A survey of the improper use of ∇ in vector analysis] (1994) Tai, Chen

[[Category:Vector calculus]]
[[Category:Mathematical notation]]
[[Category:Differential operators]]</text>
      <sha1>dk1z1jc0u24b9cv9vwv6e370hs7wmcy</sha1>
    </revision>
  </page>
  <page>
    <title>Distribution (differential geometry)</title>
    <ns>0</ns>
    <id>2976052</id>
    <revision>
      <id>761725059</id>
      <parentid>761724993</parentid>
      <timestamp>2017-01-24T13:45:06Z</timestamp>
      <contributor>
        <ip>2001:638:904:FFC7:5C9B:30EC:D9A6:1D82</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4496">In [[differential geometry]], a discipline within [[mathematics]], a '''distribution''' is a subset of the [[tangent bundle]] of a [[differentiable manifold|manifold]] satisfying certain properties. Distributions are used to build up notions of [[Integrable system|integrability]], and specifically of a [[foliation]] of a manifold.

Even though they share the same name, distributions we discuss in this article have nothing to do with [[distribution (mathematics)|distribution]]s in the sense of analysis.

==Definition==
Let &lt;math&gt;M&lt;/math&gt; be a &lt;math&gt;C^\infty&lt;/math&gt; manifold of dimension &lt;math&gt;m&lt;/math&gt;, and let &lt;math&gt;n \leq m&lt;/math&gt;. Suppose that for each &lt;math&gt;x \in M&lt;/math&gt;, we assign an &lt;math&gt;n&lt;/math&gt;-dimensional [[linear subspace|subspace]]  &lt;math&gt;\Delta_x \subset T_x(M)&lt;/math&gt; of the [[tangent space]] in such a way that for a [[neighbourhood (mathematics)|neighbourhood]]  &lt;math&gt;N_x \subset M&lt;/math&gt; of &lt;math&gt;x&lt;/math&gt; there exist &lt;math&gt;n&lt;/math&gt; [[linear independence|linearly independent]] smooth [[vector field]]s &lt;math&gt;X_1,\ldots,X_n&lt;/math&gt; such that for any point &lt;math&gt;y \in N_x&lt;/math&gt;, [[linear span|span]] &lt;math&gt;\{ X_1(y),\ldots,X_n(y) \} = \Delta_y.&lt;/math&gt; We let &lt;math&gt;\Delta&lt;/math&gt; refer to the [[set (mathematics)|collection]] of all the &lt;math&gt;\Delta_x&lt;/math&gt; for all &lt;math&gt;x \in M&lt;/math&gt; and we then call &lt;math&gt;\Delta&lt;/math&gt; a ''distribution'' of dimension &lt;math&gt;n&lt;/math&gt; on &lt;math&gt;M&lt;/math&gt;, or sometimes a ''&lt;math&gt;C^\infty&lt;/math&gt; &lt;math&gt;n&lt;/math&gt;-plane distribution'' on &lt;math&gt;M.&lt;/math&gt; The set of smooth vector fields  &lt;math&gt;\{ X_1,\ldots,X_n \}&lt;/math&gt; is called a ''local basis'' of &lt;math&gt;\Delta.&lt;/math&gt;

==Involutive distributions==
We say that a distribution &lt;math&gt;\Delta&lt;/math&gt; on &lt;math&gt;M&lt;/math&gt; is ''involutive'' if for every point &lt;math&gt;x \in M&lt;/math&gt; there exists a local basis  &lt;math&gt;\{ X_1,\ldots,X_n \}&lt;/math&gt; of the distribution in a neighbourhood of &lt;math&gt;x&lt;/math&gt; such that for all  &lt;math&gt;1 \leq i, j \leq n&lt;/math&gt;, &lt;math&gt;[X_i,X_j]&lt;/math&gt; (the [[Lie bracket of vector fields|Lie bracket]] of two vector fields) is in the span of  &lt;math&gt;\{ X_1,\ldots,X_n \}.&lt;/math&gt; That is, if &lt;math&gt;[X_i,X_j]&lt;/math&gt; is a [[linear combination]] of  &lt;math&gt;\{ X_1,\ldots,X_n \}.&lt;/math&gt; Normally this is written as  &lt;math&gt;[ \Delta , \Delta ] \subset \Delta.&lt;/math&gt;

Involutive distributions are the tangent spaces to [[foliation]]s. Involutive distributions are important in that they satisfy the conditions of the [[Frobenius theorem (differential topology)|Frobenius theorem]], and thus lead to [[integrable system]]s.

A related idea occurs in [[Hamiltonian mechanics]]: two functions ''f'' and ''g'' on a [[symplectic manifold]] are said to be in '''mutual involution''' if their [[Poisson bracket]] vanishes.

==Generalized distributions==
A '''generalized distribution''', or '''Stefan-Sussmann distribution''', is similar to a distribution, but the subspaces &lt;math&gt;\Delta_x \subset T_xM&lt;/math&gt; are not required to all be of the same dimension.  The definition requires that the &lt;math&gt;\Delta_x&lt;/math&gt; are determined locally by a set of vector fields, but these will no longer be linearly independent everywhere. It is not hard to see that the dimension of &lt;math&gt;\Delta_x&lt;/math&gt; is [[lower semicontinuous]], so that at special points the dimension is lower than at nearby points.

One class of examples is furnished by a non-free action of a [[Lie group]] on a manifold, the vector fields in question being the infinitesimal generators of the [[group action]] (a free action gives rise to a genuine distribution).  Another arises in [[dynamical systems]], where the set of vector fields in the definition is the set of vector fields that commute with a given one.  There are also examples and applications in [[Control theory]], where the generalized distribution represents infinitesimal constraints of the system.

== References ==
* William M. Boothby. Section IV. 8. Frobenius's Theorem in ''An Introduction to Differentiable Manifolds and Riemannian Geometry'', Academic Press, San Diego, California, 2003.
* P. Stefan, Accessible sets, orbits and foliations with singularities. ''Proc. London Math. Soc.'' '''29''' (1974), 699-713.
* H.J. Sussmann, Orbits of families of vector fields and integrability of distributions. ''Trans. Amer. Math. Soc.'' '''180''' (1973), 171-188.

==External links==
* {{springer|title=Involutive distribution|id=p/i052550}}

{{PlanetMath attribution|id=6541|title=Distribution}}

[[Category:Differential geometry]]
[[Category:Foliations]]</text>
      <sha1>pwkm92471k5y2oitqx0m9b729znl8km</sha1>
    </revision>
  </page>
  <page>
    <title>Dose-fractionation theorem</title>
    <ns>0</ns>
    <id>47197348</id>
    <revision>
      <id>858259489</id>
      <parentid>854839121</parentid>
      <timestamp>2018-09-06T00:02:23Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: format, url. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:AquaDTRS|AquaDTRS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1621">{{multiple issues|
{{Orphan|date=November 2015}}
{{technical|date=August 2018}}
{{underlinked|date=August 2018}}
}}

Hegerl and Hoppe.&lt;ref name=Hegerl&gt;{{cite journal|title=Influence of Electron Noise on Three-dimensional Image Reconstruction|year=1976|author1=R. Hegerl |author2=W. Hoppe |journal=Zeitschrift für Naturforschung A|volume=31|issue=12|pages=1717–1721|doi=10.1515/zna-1976-1241|bibcode=1976ZNatA..31.1717H}}&lt;/ref&gt; have pointed out that the total dose required to achieve statistical significance for each [[voxel]] of a computed 3D reconstruction is the same as that required to obtain a single 2D image of that isolated voxel, at the same level of statistical significance. Thus a statistically significant 3D image can be computed from statistically insignificant projections, as long as the total dose that is distributed among these projections is high enough that it would have resulted in a statistically significant projection, if applied to only one image.&lt;ref name=McEwen&gt;{{cite journal|title=The relevance of dose-fractionation in tomography of radiation-sensitive specimens|year=1995|vauthors=McEwen BF, Downing KH, Glaeser RM |journal=Ultramicroscopy|volume=60|issue=3|doi=10.1016/0304-3991(95)00082-8|pages=357–373|url=https://zenodo.org/record/1258471|format=Submitted manuscript}}&lt;/ref&gt;

==References==
{{Reflist}}

{{DEFAULTSORT:Computed Tomography}}
[[Category:Condensed matter physics]]
[[Category:Electron microscopy]]
[[Category:Medical imaging]]
[[Category:Geometric measurement]]
[[Category:X-ray computed tomography]]
[[Category:Multidimensional signal processing]]


{{CMP-stub}}</text>
      <sha1>luatx10bym0v41gp7djxcdnhooj00wq</sha1>
    </revision>
  </page>
  <page>
    <title>Edward G. Coffman Jr.</title>
    <ns>0</ns>
    <id>1303196</id>
    <revision>
      <id>807540036</id>
      <parentid>805600117</parentid>
      <timestamp>2017-10-28T16:44:24Z</timestamp>
      <contributor>
        <username>JJMC89 bot</username>
        <id>27446209</id>
      </contributor>
      <minor/>
      <comment>JJMC89 bot moved page [[Edward G. Coffman, Jr.]] to [[Edward G. Coffman Jr.]]: [[WP:Bots/Requests for approval/JJMC89 bot 14|Task 14]]: [[WP:JR/SR|No comma preferred before Jr/Sr]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6593">{{Use dmy dates|date=July 2013}}
{{Infobox scientist
| name                    = Edward G. Coffman Jr.
| image                   = 
| image_size        = 150px
| caption                 = 
| birth_date              = {{birth date and age|df=yes|1934|8|16}}
| birth_place             = [[Los Angeles]], USA
| death_date              =
| death_place             =
| residence               = New York City, New York
| citizenship             = USA
| nationality             = American
| ethnicity               =
| field                   = [[Electrical Engineering]], [[Computer Science]], [[Operations Research]]
| work_institution        = [[Princeton University]]&lt;br&gt;[[Pennsylvania State University]]&lt;br&gt;[[University of California, Santa Barbara]]&lt;br&gt;[[Bell Laboratories]]&lt;br&gt;[[New Jersey Institute of Technology]]&lt;br&gt;[[Columbia University]]
| alma_mater              = [[University of California, Los Angeles]]
| doctoral_advisor        = 
| thesis_title = Stochastic Models of Multiple and Time-shared Computer Operations
| thesis_year = 1966
| doctoral_students       = 
| known_for               = Mathematical modeling and analysis in [[computer engineering]] and [[operations research]] 
| author_abbreviation_bot =
| author_abbreviation_zoo =
| prizes                  = [[Association for Computing Machinery|ACM]] [http://awards.acm.org/citation.cfm?id=1016856&amp;srt=all&amp;aw=143&amp;ao=OSTCONTR&amp;yr=1987 Outstanding Contribution Award]&lt;br&gt;[[Association for Computing Machinery|ACM]] [http://awards.acm.org/citation.cfm?id=1016856&amp;srt=all&amp;aw=144&amp;ao=DISTGSVC&amp;yr=2004 Distinguished Service Award]&lt;br&gt;[[Association for Computing Machinery|ACM]] [http://www.sigmetrics.org/achievementaward-2003.shtml Sigmetrics Achievement Award]&lt;br&gt;[[Canadian Operational Research Society|CORS]] Larnder Prize&lt;br&gt;&lt;br&gt;Fellow [[Association for Computing Machinery|ACM]], [[Institute of Electrical and Electronics Engineers|IEEE]] 
| religion                =
| footnotes               =
}}

'''Edward Grady "Ed" Coffman Jr.''' is a [[computer scientist]]. He began his career as a systems programmer at the [[System Development Corporation]] (SDC) during the period 1958–65. His PhD in Engineering at [[UCLA]] in 1966 was followed by a series of positions at [[Princeton University]] (1966–69), The [[Pennsylvania State University]] (1970–76), [[Columbia University]] (1976–77), and the [[University of California, Santa Barbara]] (1977–79).  In 1979, he joined the Mathematics Center at [[Bell Laboratories]] where he stayed until his retirement as a Distinguished Member of Technical Staff 20 years later. After a one-year stint at the [[New Jersey Institute of Technology]], he returned to [[Columbia University]] in 2000 with appointments in [[Computer Science]], [[Electrical Engineering]], and [[Industrial Engineering and Operations Research]].  He retired from teaching in 2008 and is now a Professor Emeritus still fully engaged in research and in professional activities.

==Research==
Coffman is best known for his seminal research together with his international collaborations, measured in part by some 150 co-authors in his collection of publications.  His work can be found in over 180 articles in technical journals devoted to original research contributions. He published 4 graduate-level text books, and papers in the proceedings of some 250 conferences and workshops, most of these being preliminary versions of journal articles.  In his research, Coffman has been a generalist following many parallel paths in engineering and applied mathematics. The directions he has taken have drawn on the tools of combinatorial optimization and the theory of algorithms, along with those of applied probability and stochastic processes. The processes studied include those in the theories of [[Scheduling (computing)|scheduling]], [[bin packing]], sequential selection, [[graph algorithms|graphs]], and [[dynamic allocation]], along with those in [[queueing theory|queueing]], polling, reservation, [[K-server problem|moving-server]], [[computer network|networking]], and distributed [[local-rule systems]] (e.g. [[cellular automaton|cellular automata]]). His contributions have been divided between mathematical foundations and the design and analysis of [[approximation algorithms]] providing the basis for engineering solutions to [[NP-hard]] problems. Computer and network engineering applications have been broad in scope; a partial list includes research addressing problems in the scheduling and storage allocation functions of computer [[operating systems]], [[computer storage|storage architectures]], [[data structures]], computer timing problems such as [[deadlocks]] and [[synchronization (computer science)|synchronization]], Internet congestion, [[peer-to-peer file sharing]] networks, stream merging, [[self-assembly]] processes of [[dna computing|molecular computing]], minimalist algorithms in [[sensor networks]], [[optical burst switching]], and [[Dynamic Spectrum Management|dynamic spectrum management]] in [[cognitive networks]].  The list expands greatly when including the myriad applications in [[industrial engineering and operations research]] of Coffman's research in scheduling and bin-packing theory in one and two dimensions. As of November 11, 2015, his works have been cited 13,597 times, and he has an [[h-index]] of 49.&lt;ref&gt;{{Cite web|title = e g coffman - Google Scholar Citations|url = https://scholar.google.com/citations?user=Fj5sn6QAAAAJ&amp;hl=en|website = scholar.google.com|accessdate = 2015-11-11}}&lt;/ref&gt;

Coffman has been active professionally serving on several editorial boards, dozens of technical program committees, setting research agendas in workshops of the [[United States National Research Council|National Research Council]], co-founding the [[Symposium on Operating Systems Principles]], and the special interest groups on performance evaluation of both [[ACM SIGMETRICS|ACM]] and [[IFIPS]].

== Selected publications ==
* 1964, with [[Jules Schwartz]] and Clark Weissman.  "A General Purpose Time-Sharing System".  Spartan Books.&lt;ref&gt;http://www.ee.columbia.edu/~egc/e.coffman1.pdf&lt;/ref&gt;
* 1973, with Peter Denning.  ''Operating Systems Theory''.  Prentice-Hall.

==See also==
*[[Coffman–Graham algorithm]]
*[[Deadlock]]

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Coffman, Edward G.}}
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Theoretical computer scientists]]
[[Category:Columbia School of Engineering and Applied Science faculty]]
[[Category:1934 births]]
[[Category:Living people]]</text>
      <sha1>806v3zv225ff1shqwo59vgy4tsu4ofq</sha1>
    </revision>
  </page>
  <page>
    <title>Evidence lower bound</title>
    <ns>0</ns>
    <id>56891926</id>
    <revision>
      <id>853533473</id>
      <parentid>847037789</parentid>
      <timestamp>2018-08-05T12:22:22Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Statistics]]; added [[Category:Theory of probability distributions]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="742">{{one source|date=May 2018}}

In statistics, the '''evidence lower bound''' ('''ELBO''', also '''variational lower bound''') is the difference between the [[probability distribution|distribution]] of a [[latent variable]] and the distribution of the respective observed variable&lt;ref&gt;{{cite web|last1=Yang|first1=Xitong|title=Understanding the Variational Lower Bound|url=http://legacydirs.umiacs.umd.edu/~xyang35/files/understanding-variational-lower.pdf|website=Institute for Advanced Computer Studies|publisher=University of Maryland|accessdate=20 March 2018}}&lt;/ref&gt; (See [[Kullback–Leibler_divergence|Kullback–Leibler divergence]])

==References==
&lt;references /&gt;

{{statistics-stub}}



[[Category:Theory of probability distributions]]</text>
      <sha1>7ylil3al106a9qdc2yx1ehdngfh8wlx</sha1>
    </revision>
  </page>
  <page>
    <title>Exceptional isomorphism</title>
    <ns>0</ns>
    <id>25262819</id>
    <revision>
      <id>868563814</id>
      <parentid>868563511</parentid>
      <timestamp>2018-11-13T00:24:37Z</timestamp>
      <contributor>
        <ip>2600:1700:E1C0:F340:1913:1136:8EEE:A852</ip>
      </contributor>
      <comment>/* Lie theory */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7805">In [[mathematics]], an '''exceptional isomorphism''', also called an '''accidental isomorphism''', is an [[isomorphism]] between members ''a''&lt;sub&gt;''i''&lt;/sub&gt; and ''b''&lt;sub&gt;''j''&lt;/sub&gt; of two families, usually infinite, of mathematical objects, that is not an example of a pattern of such isomorphisms.&lt;ref group="note"&gt;Because these series of objects are presented differently, they are not identical objects (do not have identical descriptions), but turn out to describe the same object, hence one refers to this as an isomorphism, not an equality (identity).&lt;/ref&gt; These coincidences are at times considered a matter of trivia,&lt;ref name="raw"/&gt; but in other respects they can give rise to other phenomena, notably [[exceptional object]]s.&lt;ref name="raw"/&gt; In the following, coincidences are listed wherever they occur.

== Groups ==

=== Finite simple groups ===
The exceptional isomorphisms between the series of [[finite simple group]]s mostly involve [[projective special linear group]]s and [[alternating group]]s, and are:&lt;ref name="raw"&gt;{{Citation | last1=Wilson | first1=Robert A. | authorlink = Robert Arnott Wilson | title=The finite simple groups | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=[[Graduate Texts in Mathematics]] 251 | isbn=978-1-84800-987-5 | doi=10.1007/978-1-84800-988-2 | year=2009 |chapter = Chapter 1: Introduction |chapterurl=http://www.maths.qmul.ac.uk/~raw/fsgs_files/intro.ps | postscript =, [http://www.maths.qmul.ac.uk/~raw/fsgs.html 2007 preprint]; Chapter {{doi|10.1007/978-1-84800-988-2_1}}. | zbl=1203.20012 | volume=251}}&lt;/ref&gt;
*&lt;math&gt;\operatorname{PSL}_2(4) \cong \operatorname{PSL}_2(5) \cong \mathfrak{A}_5,&lt;/math&gt; the smallest non-abelian simple group (order 60);
*&lt;math&gt;\operatorname{PSL}_2(7) \cong \operatorname{PSL}_3(2),&lt;/math&gt; the second-smallest non-abelian simple group (order 168) – [[PSL(2,7)]];
*&lt;math&gt;\operatorname{PSL}_2(9) \cong \mathfrak{A}_6,&lt;/math&gt;
*&lt;math&gt;\operatorname{PSL}_4(2) \cong \mathfrak{A}_8,&lt;/math&gt;
*&lt;math&gt;\operatorname{PSU}_4(2) \cong \operatorname{PSp}_4(3),&lt;/math&gt; between a [[projective special orthogonal group]] and a [[projective symplectic group]].

=== Groups of Lie type ===
In addition to the aforementioned, there are some isomorphisms involving SL, PSL, GL, PGL, and the natural maps between these. For example, the groups over &lt;math&gt;\mathbf{F}_5&lt;/math&gt; have a number of exceptional isomorphisms:
*&lt;math&gt;\operatorname{PSL}(2,5) \cong \mathfrak{A}_5 \cong \mathbb{I},&lt;/math&gt; the alternating group on five elements, or equivalently the [[icosahedral group]];
*&lt;math&gt;\operatorname{PGL}(2,5) \cong \mathfrak{S}_5,&lt;/math&gt; the [[symmetric group]] on five elements;
*&lt;math&gt;\operatorname{SL}(2,5) \cong 2\mathfrak{A}_5 \cong 2\mathbb{I},&lt;/math&gt; the [[covering groups of the alternating and symmetric groups|double cover of the alternating group A&lt;sub&gt;5&lt;/sub&gt;]], or equivalently the [[binary icosahedral group]].

=== Alternating groups and symmetric groups ===
[[File:Compound of five tetrahedra.png|thumb|The [[compound of five tetrahedra]] expresses the exceptional isomorphism between the icosahedral group and the alternating group on five letters.]]
There are coincidences between alternating groups and small groups of Lie type:
*&lt;math&gt;\operatorname{PSL}_2(4) \cong \operatorname{PSL}_2(5) \cong \mathfrak{A}_5,&lt;/math&gt;
*&lt;math&gt;\operatorname{PSL}_2(9) \cong \operatorname{Sp}_4(2)' \cong \mathfrak{A}_6,&lt;/math&gt;
*&lt;math&gt;\operatorname{Sp}_4(2) \cong \mathfrak{S}_6,&lt;/math&gt;
*&lt;math&gt;\operatorname{PSL}_4(2) \cong \operatorname{O}_6^+(2)' \cong \mathfrak{A}_8,&lt;/math&gt;
*&lt;math&gt;\operatorname{O}_6^+(2) \cong \mathfrak{S}_8.&lt;/math&gt;
These can all be explained in a systematic way by using linear algebra (and the action of &lt;math&gt;S_n&lt;/math&gt; on affine &lt;math&gt;n&lt;/math&gt;-space)
to define the isomorphism going from the right side to the left side. (The above isomorphisms for &lt;math&gt;A_8&lt;/math&gt; and &lt;math&gt;S_8&lt;/math&gt; are linked via the exceptional isomorphism &lt;math&gt;\operatorname{SL}_4/\mu_2 \cong \operatorname{SO}_6&lt;/math&gt;.)
There are also some coincidences with symmetries of [[regular polyhedra]]: the alternating group A&lt;sub&gt;5&lt;/sub&gt; agrees with the [[icosahedral group]] (itself an exceptional object), and the [[covering groups of the alternating and symmetric groups|double cover]] of the alternating group A&lt;sub&gt;5&lt;/sub&gt; is the [[binary icosahedral group]].

=== Cyclic groups ===
Cyclic groups of small order especially arise in various ways, for instance:
* &lt;math&gt; \operatorname{C}_2 \cong \{\pm1\} \cong \operatorname{O}(1) \cong \operatorname{Spin}(1) \cong \mathbb Z^\times&lt;/math&gt;, the last being the group of units of the integers.

=== Spheres ===
The spheres ''S''&lt;sup&gt;0&lt;/sup&gt;, ''S''&lt;sup&gt;1&lt;/sup&gt;, and ''S''&lt;sup&gt;3&lt;/sup&gt; admit group structures, which can be described in many ways:
* &lt;math&gt; S^0\cong\operatorname{O}(1)\cong\mathbb{Z}/2\mathbb{Z} &lt;/math&gt; ,
* &lt;math&gt; S^1\cong\operatorname{SO}(2)\cong\operatorname{U}(1)\cong\operatorname{Spin}(2)\cong \mathbb R/\mathbb Z \cong &lt;/math&gt; [[circle group]]
* &lt;math&gt; S^3\cong\operatorname{Spin}(3)\cong\operatorname{SU}(2)\cong\operatorname{Sp}(1)\cong&lt;/math&gt; [[versors|unit quaternions]].

=== Coxeter groups ===
[[File:Dynkin Diagram Isomorphisms.svg|thumb|upright|The exceptional isomorphisms of connected [[Dynkin diagram]]s.]]
There are some exceptional isomorphisms of [[Coxeter diagram]]s, yielding isomorphisms of the corresponding Coxeter groups and of polytopes realizing the symmetries. These are:
* A&lt;sub&gt;2&lt;/sub&gt; = I&lt;sub&gt;2&lt;/sub&gt;(2) (2-simplex is regular 3-gon/triangle);
* BC2 = I&lt;sub&gt;2&lt;/sub&gt;(4) (2-cube (square) = 2-cross-polytope (diamond) = regular 4-gon)
* A&lt;sub&gt;3&lt;/sub&gt; = D&lt;sub&gt;3&lt;/sub&gt; (3-simplex (tetrahedron) is 3-demihypercube (demicube), as per diagram)
* A&lt;sub&gt;1&lt;/sub&gt; = C&lt;sub&gt;1&lt;/sub&gt; ≈ B&lt;sub&gt;1&lt;/sub&gt; (= D&lt;sub&gt;1&lt;/sub&gt;?)
* D&lt;sub&gt;2&lt;/sub&gt; ≈ A&lt;sub&gt;1&lt;/sub&gt; × A&lt;sub&gt;1&lt;/sub&gt;
* A&lt;sub&gt;4&lt;/sub&gt; = E&lt;sub&gt;4&lt;/sub&gt;
* D&lt;sub&gt;5&lt;/sub&gt; = E&lt;sub&gt;5&lt;/sub&gt;

Closely related ones occur in Lie theory for [[Dynkin diagram#Isomorphisms|Dynkin diagrams]].

== Lie theory ==

In low dimensions, there are isomorphisms among the classical Lie algebras and among the classical Lie groups called ''accidental isomorphisms''. For instance, there are isomorphisms between low-dimensional [[spin group]]s and certain classical Lie groups, due to low-dimensional isomorphisms between the [[root systems]] of the different families of [[simple Lie algebra]]s, visible as isomorphisms of the corresponding Dynkin diagrams:
* Trivially, ''A''&lt;sub&gt;0&lt;/sub&gt; = ''B''&lt;sub&gt;0&lt;/sub&gt; = ''C''&lt;sub&gt;0&lt;/sub&gt; = ''D''&lt;sub&gt;0&lt;/sub&gt;
* ''A''&lt;sub&gt;1&lt;/sub&gt; = ''C''&lt;sub&gt;1&lt;/sub&gt; ≈ ''B''&lt;sub&gt;1&lt;/sub&gt;, or &lt;math&gt;\mathfrak{sl}_2 = \mathfrak{sp}_1 \cong \mathfrak{so}_3&lt;/math&gt;
* ''B''&lt;sub&gt;2&lt;/sub&gt; ≈ ''C''&lt;sub&gt;2&lt;/sub&gt;, or &lt;math&gt;\mathfrak{so}_5 \cong \mathfrak{sp}_2 &lt;/math&gt;
* ''D''&lt;sub&gt;2&lt;/sub&gt; ≈ ''A''&lt;sub&gt;1&lt;/sub&gt; × ''A''&lt;sub&gt;1&lt;/sub&gt;, or &lt;math&gt;\mathfrak{so}_{4} \cong \mathfrak{sl}_2 \oplus \mathfrak{sl}_2 &lt;/math&gt;; note that these are disconnected, but part of the ''D''-series
* ''A''&lt;sub&gt;3&lt;/sub&gt; = ''D''&lt;sub&gt;3&lt;/sub&gt; &lt;math&gt;\mathfrak{sl}_4 \cong \mathfrak{so}_6&lt;/math&gt;
* ''A''&lt;sub&gt;4&lt;/sub&gt; = ''E''&lt;sub&gt;4&lt;/sub&gt;; the ''E''-series usually starts at 6, but can be started at 4, yielding isomorphisms
* ''D''&lt;sub&gt;5&lt;/sub&gt; = ''E''&lt;sub&gt;5&lt;/sub&gt;

:Spin(1) = [[Orthogonal group|O(1)]]
:Spin(2) = [[Unitary group|U(1)]] = [[Special orthogonal group|SO(2)]]
:Spin(3) = [[Symplectic group|Sp(1)]] = [[Special unitary group|SU(2)]]
:Spin(4) = [[Symplectic group|Sp(1)]] &amp;times; [[Symplectic group|Sp(1)]]
:Spin(5) = [[Symplectic group|Sp(2)]]
:Spin(6) = [[Special unitary group|SU(4)]]

== See also ==
* [[Exceptional object]]
* [[Mathematical coincidence]], for numerical coincidences

== Notes ==
{{reflist|group=note}}

== References ==
{{reflist}}
{{refbegin}}
{{refend}}

[[Category:Mathematical relations]]</text>
      <sha1>fa93657mbsyu9q936uqiof2mjdll9nl</sha1>
    </revision>
  </page>
  <page>
    <title>Excess-256</title>
    <ns>0</ns>
    <id>57914834</id>
    <redirect title="Offset binary" />
    <revision>
      <id>850519224</id>
      <timestamp>2018-07-16T11:35:13Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[Offset binary#Excess-256]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="180">#REDIRECT [[Offset binary#Excess-256]]

{{Redirect category shell|1=
{{R to related topic}}
{{R with possibilities}}
}}

[[Category:Binary arithmetic]]
[[Category:Numeral systems]]</text>
      <sha1>2lszq2yg3lue1avcq5hd8fyeifkppkx</sha1>
    </revision>
  </page>
  <page>
    <title>Extensionality</title>
    <ns>0</ns>
    <id>294056</id>
    <revision>
      <id>845210930</id>
      <parentid>845122340</parentid>
      <timestamp>2018-06-10T06:26:42Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <minor/>
      <comment>/* See also */ alpha</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3242">In [[logic]], '''extensionality''', or '''extensional equality''', refers to principles that judge objects to be [[equality (mathematics)|equal]] if they have the same external properties. It stands in contrast to the concept of [[intensionality]], which is concerned with whether the internal definitions of objects are the same.

==Example==

Consider the two functions ''f'' and ''g'' mapping from and to [[natural number]]s, defined as follows:
* To find ''f''(''n''), first add 5 to ''n'', then multiply by 2.
* To find ''g''(''n''), first multiply ''n'' by  2, then add 10. 

These functions are extensionally equal; given the same input, both functions always produce the same value. But the definitions of the functions are not equal, and in that intensional sense the functions are not the same. 

Similarly, in natural language there are many predicates (relations) that are intensionally different but are extensionally identical. For example, suppose that a town has one person named Joe, who is also the oldest person in the town. Then, the two argument predicates "has one person named", "is the oldest person in" are intensionally distinct, but extensionally equal for "Joe" in that "town" now.

==In mathematics==
The extensional definition of function equality, discussed above, is commonly used in mathematics. Sometimes additional information is attached to a function, such as an explicit [[codomain]], in which case two functions must not only agree on all values, but must also have the same codomain, in order to be equal. 

A similar extensional definition is usually employed for relations: two relations are said to be equal if they have the same [[Extension (predicate logic)|extensions]].

In set theory, the [[axiom of extensionality]] states that two sets are equal if and only if they contain the same elements.  In mathematics formalized in set theory, it is common to identify relations&amp;mdash;and, most importantly, [[function (mathematics)|functions]]&amp;mdash;with their extension as stated above, so that it is impossible for two relations or functions with the same extension to be distinguished.

Other mathematical objects are also constructed in such a way that the intuitive notion of "equality" agrees with set-level extensional equality; thus, equal [[ordered pair]]s have equal elements, and elements of a set which are related by an [[equivalence relation]] belong to the same [[equivalence class]].

[[Type theory|Type-theoretical]] foundations of mathematics are generally ''not'' extensional in this sense, and [[setoid]]s are commonly used to maintain a difference between intensional equality and a more general equivalence relation (which generally has poor [[constructivism (mathematics)|constructibility]] or [[Decidability (logic)|decidability]] properties).

==See also==
*[[Duck typing]]
*[[Identity of indiscernibles]]
*[[Structural typing]]
*[[Univalence axiom]]

==References==
{{reflist}}
* [https://plato.stanford.edu/entries/logic-intensional/ Intensional Logic (Stanford Encyclopedia of Philosophy)]
* [https://ncatlab.org/nlab/show/equality equality] in [[nLab]]

{{Mathematical logic}}

[[Category:Set theory]]
[[Category:Concepts in logic]]
[[Category:Equivalence (mathematics)]]</text>
      <sha1>d7bj3es2k9u0skm7h7r0h9m7q8zc7vx</sha1>
    </revision>
  </page>
  <page>
    <title>Eyeborg</title>
    <ns>0</ns>
    <id>24778033</id>
    <redirect title="Cyborg antenna" />
    <revision>
      <id>816100115</id>
      <parentid>811591692</parentid>
      <timestamp>2017-12-19T07:49:54Z</timestamp>
      <contributor>
        <username>Tramesa332</username>
        <id>32655398</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[Cyborg antenna]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6901">#REDIRECT [[Cyborg antenna]]
{{about|the prosthetic color apparatus|2009 science fiction film|Eyeborgs}}
[[File:Harbisson's Sonochromatic Scales.png|550px|thumb|right| The Harbisson's Sonochromatic Music Scale]]
An '''eyeborg''' or '''eye-borg''' is a [[body modification]] apparatus which fits on the wearer's head, and is designed to allow people to perceive color through sound waves. It works with a head-mounted antenna that senses the colors directly in front of a person, and converts them in real-time into sound waves [[osseointegration|through bone conduction]].&lt;ref&gt;Alfredo M. Ronchi: ''Eculture: Cultural Content in the Digital Age.'' Springer (New York, 2009). p.319  {{ISBN|978-3-540-75273-8}}&lt;/ref&gt;

==History==
The first eyeborg was created in England in 2003 by Adam Montandon in collaboration with colourblind artist [[Neil Harbisson]].&lt;ref name=BBCOutlook /&gt; The invention, under the heading ''Bridging the Island of the Colourblind Project'', won a British award in Innovation (Submerge 2004)&lt;ref&gt;[http://www.plymouth.ac.uk/pages/view.asp?page=10944] Submerge Innovation Award (Bristol, 2004){{dead link|date=February 2017|bot=medic}}{{cbignore|bot=medic}}&lt;/ref&gt; and a European award in Content Tools and Interface Design ([[Europrix]] 2004).&lt;ref&gt;[[Europrix]] Europrix Awards&lt;/ref&gt; In 2007, Peter Kese, a software developer from [[Kranj]], [[Slovenia]], made further developments to the eyeborg by increasing the number of color [[hue]]s to 360 and adding [[color saturation]] through different volume levels.&lt;ref&gt;Harbisson, Neil. [http://www.artinfo.com/news/enlarged_image/27743/96442/ "Painting by ear"] {{webarchive|url=https://web.archive.org/web/20080803074843/http://www.artinfo.com/news/enlarged_image/27743/96442/ |date=2008-08-03 }} ''Modern Painters, The International Contemporary Art Magazine'' pp.70-73. New York, June 2008.&lt;/ref&gt; In 2009, Matias Lizana, a student from [[Universitat Politècnica de Catalunya]] developed the eyeborg into a chip as part of his final year project.&lt;ref name="lavanguardia.es"&gt;Sanchis, Ima. [http://www.lavanguardia.es/free/edicionimpresa/20100710/53961073929.html "La veo en blanco y negro pero la oigo en colores"], La Contra de ''[[La Vanguardia]]'', 10 July 2010.&lt;/ref&gt; The chip allows users to have the device implanted and to hear colors beyond the limits of human perception such as infrared and ultraviolet.&lt;ref&gt;Millás, Juan José. [http://www.elpais.com/articulo/portada/ciborg/tercer/ojo/elpepusoceps/20120115elpepspor_9/Tes. “El Cyborg del Tercer Ojo”]{{dead link|date=September 2017 |bot=InternetArchiveBot |fix-attempted=yes }}, ''[[El Pais]]'', 15 Jan 2012.&lt;/ref&gt;

==Color to sound scales==
Harbisson's Sonochromatic Music Scale (2003) is a microtonal and [[logarithmic scale]] with 360 notes in an octave. Each note corresponds to a specific degree of the [[color wheel]]. The scale was introduced to the first eyeborg in 2004.&lt;ref&gt;[http://www.artinfo.com/news/story/27743/june-2008-table-of-contents/] ''Modern Painters, The International Contemporary Art Magazine'' pp 70-73 (New York, June 2008)&lt;/ref&gt;

Harbisson's Pure Sonochromatic Scale (2005) is a non-logarithmic scale based on the [[:wikt:transpose|transposition]] of light frequencies to sound frequencies. The scale discards color as being part of a color wheel and ignores musical/logarithmic perception so it can overstep the limits of human perception. The introduction of the new scale to the eyeborg in 2010, allows users to decide whether they want to perceive colors logarithmically or not.&lt;ref name="lavanguardia.es"/&gt;

==The blind==
[[File:Eyeborgs for the blind.jpg|thumb|right|Blind Ecuadorians using eyeborgs]]
Since 2005, eyeborgs have been donated to blind communities in Europe, Asia and America with the aim of helping the blind develop the sense of color.&lt;ref&gt;EFE [http://www.prensa.com/impreso/tecnologia-%C2%B4cyborg%C2%B4-para-la-vision/35482 "Tecnologia cyborg para la vision"], [[EFE]], 27 October 2011&lt;/ref&gt; The first blind person to try out an eyeborg was [[Sabriye Tenberken]] followed by blind students from [[Braille Without Borders]] in Tibet and members of the Sociedad de Ciegos de Pichincha in Ecuador.&lt;ref&gt;Redacción [http://elcomercio.pe/tecnologia/721054/noticia-fundacion-se-dedica-convertir-humanos-ciborgs "Una fundación se dedica a convertir humanos en ciborgs"] ''[[El Comercio (Peru)]]'', 1 Mar 2011.&lt;/ref&gt;

In 2011, vice-president of Ecuador [[Lenin Moreno]] announced that his government would collaborate with the [[Cyborg Foundation]] to create eyeborgs and new sensory extensions.&lt;ref&gt;Redaccion [http://www.eltiempo.com.ec/noticias-cuenca/81856-gobierno-impulsara-plan-para-no-videntes/ "Gobierno impulsara plan para no videntes"], [[El Tiempo (Ecuador)]], 30 October 2011.&lt;/ref&gt; In 2012, after lecturing at Escola Politécnica de Pernambuco in Recife,&lt;ref&gt;Redação [http://www.diariodepernambuco.com.br/nota.asp?materia=20120430114940 "Primeiro ciborgue do mundo estará nesta quarta na UPE"] {{webarchive|url=https://web.archive.org/web/20120512032546/http://diariodepernambuco.com.br/nota.asp?materia=20120430114940 |date=2012-05-12 }}, ''[[Diário de Pernambuco]]'', 30 April 2012&lt;/ref&gt; the [[Cyborg Foundation]] signed a partnership to create eyeborgs and other new human extensions in collaboration with [[Universidade de Pernambuco]] in Brazil.&lt;ref&gt;Lins, Letícia [http://oglobo.globo.com/tecnologia/homem-ciborgue-desenvolve-projeto-no-brasil-4794658 "Homem-ciborgue desenvolve projeto no Brasil"], ''[[O Globo]]'', 2 May 2012&lt;/ref&gt;

Eyeborgs are currently being treated as body parts rather than as devices, and therefore are donated rather than sold.&lt;ref&gt;Maia, Rafael [http://tecnologia.terra.com.br/campus-party/2012/noticias/0,,OI5602708-EI19138,00-Nao+quero+vender+olhos+diz+ciborgue+que+ouve+as+cores.html "Nao quero vender olhos"], [[Terra Networks]], 9 February 2012.&lt;/ref&gt;

==See also==
* [[Synesthesia]]
* [[Neuroprosthetics]]

==References==
{{Reflist|refs=
&lt;ref name=BBCOutlook&gt;{{cite web|last1=Bannister|first1=Matthew|title=Outlook|website=http://www.bbc.co.uk/programmes/p00my2ry|publisher=BBC World Service|accessdate=4 June 2014|page=16m41s|date=2012-01-23}}&lt;/ref&gt;
}}

==External links==
*[http://www.ted.com/talks/neil_harbisson_i_listen_to_color.html Video: How the eyeborg works]
*[http://www.eyeb.org Eyeborg Website (Eyeborg chip development site)]
*[https://www.wired.com/underwire/2008/02/cyborg-enables-color-blind-artist-to-hear-his-palette/ Article about an eyeborg user on Wired (USA 2008)]
*[http://entertainment.timesonline.co.uk/tol/arts_and_entertainment/visual_arts/article3423446.ece Eyeborg user example on The Sunday Times (UK, 2008)]
*[http://www.bbc.co.uk/devon/news_features/2005/eyeborg.shtml Information from BBC (UK, 2005)]
*[http://www.harbisson.com Neil Harbisson's personal website]

[[Category:Cybernetics]]
[[Category:Visual disturbances and blindness]]</text>
      <sha1>8i8kws8ud5aoim884e0rwcje6ycwy3f</sha1>
    </revision>
  </page>
  <page>
    <title>Fano plane</title>
    <ns>0</ns>
    <id>390404</id>
    <revision>
      <id>859572483</id>
      <parentid>851487487</parentid>
      <timestamp>2018-09-14T22:01:08Z</timestamp>
      <contributor>
        <username>Watchduck</username>
        <id>5530646</id>
      </contributor>
      <minor/>
      <comment>/* Structure of the automorphism group */ same orientation as in the permutation images</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20137">[[File:Fano plane.svg|thumb|The Fano plane]]

In [[finite geometry]], the '''Fano plane''' (after [[Gino Fano]]) is the [[Projective plane#Finite projective planes|finite projective plane]] of order 2. It is the finite projective plane with the smallest possible number of points and lines: 7 points and 7 lines, with 3 points on every line and 3 lines through every point. The standard notation for this plane, as a member of a family of [[projective space]]s, is {{math|PG(2,2)}} where {{math|PG}} stands for "[[Projective Geometry]]", the first parameter is the geometric dimension and the second parameter is the order.

The Fano plane is an example of a finite [[incidence structure]], so many of its properties can be established using [[Combinatorics|combinatorical techniques]] and other tools used in the study of [[incidence geometry|incidence geometries]]. Since it is a projective space, algebraic techniques can also be effective tools in its study.

==Homogeneous coordinates==
The Fano plane can be constructed via [[linear algebra]] as the [[projective plane]] over the [[finite field]] with two elements. One can similarly construct projective planes over any other finite field, with the Fano plane being the smallest.

Using the standard construction of projective spaces via [[homogeneous coordinates]], the seven points of the Fano plane may be labeled with the seven non-zero ordered triples of binary digits 001, 010, 011, 100, 101, 110, and 111. This can be done in such a way that for every two points ''p'' and ''q'', the third point on line ''pq'' has the label formed by adding the labels of ''p'' and ''q'' modulo 2. In other words, the points of the Fano plane correspond to the non-zero points of the finite [[vector space]] of dimension 3 over the finite field of order 2.

Due to this construction, the Fano plane is considered to be a [[Desarguesian plane]], even though the plane is too small to contain a non-degenerate [[Desargues configuration]] (which requires 10 points and 10 lines).

The lines of the Fano plane may also be given homogeneous coordinates, again using non-zero triples of binary digits. With this system of coordinates, a point is incident to a line if the coordinate for the point and the coordinate for the line have an even number of positions at which they both have nonzero bits: for instance, the point 101 belongs to the line 111, because they have nonzero bits at two common positions. In terms of the underlying linear algebra, a point belongs to a line if the [[inner product]] of the vectors representing the point and line is zero.

The lines can be classified into three types.
*On three of the lines the binary triples for the points have the 0 in a constant position: the line 100 (containing the points 001, 010, and 011) has 0 in the first position, and the lines 010 and 001 are formed in the same way.
*On three of the lines, two of the positions in the binary triples of each point have the same value: in the line 110 (containing the points 001, 110, and 111) the first and second positions are always equal, and the lines 101 and 011 are formed in the same way.
*In the remaining line 111 (containing the points 011, 101, and 110), each binary triple has exactly two nonzero bits.

==Group-theoretic construction==
Alternatively, the 7 points of the plane correspond to the 7 non-identity elements of the [[group (mathematics)|group]] (''Z''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;3&lt;/sup&gt; = ''Z''&lt;sub&gt;2&lt;/sub&gt; &amp;times; ''Z''&lt;sub&gt;2&lt;/sub&gt; &amp;times; ''Z''&lt;sub&gt;2&lt;/sub&gt;. The lines of the plane correspond to the subgroups of order 4, isomorphic to ''Z''&lt;sub&gt;2&lt;/sub&gt; &amp;times; ''Z''&lt;sub&gt;2&lt;/sub&gt;.  The [[automorphism]] group [[GL(3,2)]] of the group (''Z''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;3&lt;/sup&gt; is that of the Fano plane, and has order 168.

==Levi graph==
[[File:Heawood graph 2COL.svg|thumb|Bipartite Heawood graph. Points are represented by vertices of one color and lines by vertices of the other color.]]
As with any incidence structure, the [[Levi graph]] of the Fano plane is a [[bipartite graph]], the vertices of one part representing the points and the other representing the lines, with two vertices joined if the corresponding point and line are [[Incidence (geometry)|incident]]. This particular graph is a connected [[cubic graph]] (regular of degree 3), has [[Girth (graph theory)|girth 6]] and each part contains 7 vertices. It is the [[Heawood graph]], the unique [[Cage (graph theory)|6-cage]].&lt;ref&gt;{{harvnb|Pisanski|Servatius|2013|loc=p. 171}}&lt;/ref&gt;

==Collineations==
[[File:Fanoperm364.svg|180px|thumb|left|A collineation of the Fano plane corresponding to the 3-bit [[Gray code]] permutation]]
A permutation of the seven points of the Fano plane that carries [[incidence (geometry)|collinear]] points (points on the same line) to collinear points (in other words, it "preserves collinearity") is called a "[[collineation]]", "[[automorphism]]", or "[[symmetry]]" of the plane. The full [[collineation|collineation group]] (or [[automorphism group]], or [[symmetry group]]) is the [[projective linear group]] PGL(3,2)&lt;ref&gt;Actually it is PΓL(3,2), but since the finite field of order 2 has no non-identity automorphisms, this becomes PGL(3,2).&lt;/ref&gt; which in this case is isomorphic to the [[projective special linear group]] [[PSL(3,2)]], and the [[general linear group]] GL(3,2) (which is equal to PGL(3,2), because the field has only one nonzero element) and is also isomorphic to PSL(2,7).&lt;ref&gt;{{harvnb|Hirschfeld|1979|loc=p. 131}}&lt;/ref&gt; It consists of 168 different permutations.

As a [[permutation group]] [[Group action|acting]] on the points of the plane, the collineation group is [[doubly transitive]] meaning that any [[ordered pair]] of points can be mapped by at least one collineation to any other ordered pair of points.&lt;ref&gt;{{citation|first=Robert D.|last=Carmichael|title=Introduction to the theory of groups of finite order|year=1956|origyear=1937|publisher=Dover|isbn=0-486-60300-8|page=363}}&lt;/ref&gt;

Collineations may also be viewed as the color preserving automorphisms of the Heawood graph.

[[File:Fano plane Hasse diagram.svg|thumb|Duality in the Fano plane: Each point corresponds to a line and vice versa.]]
===Dualities===

{{main|Duality (projective geometry)}}
A [[bijection]] between the point set and the line set that preserves incidence is called a ''duality'' and a duality of order two is called a ''polarity''.&lt;ref&gt;{{harvnb|Polster|1998|loc=p. 11}}&lt;/ref&gt;

Dualities can be viewed in the context of the Heawood graph as color reversing automorphisms. An example of a polarity is given by reflection through a vertical line that bisects the Heawood graph representation given on the right.&lt;ref&gt;{{harvnb|Polster|1998|loc=p. 15}}&lt;/ref&gt; The existence of this polarity shows that the Fano plane is ''self-dual''. This is also an immediate consequence of the symmetry between points and lines in the definition of the incidence relation in terms of homogeneous coordinates, as detailed in an earlier section.
{{clear}}

==Structure of the automorphism group==
[[File:Fano plane nimbers.svg|thumb|180px|A [[nimber]] labeling of the Fano plane]]
With the nimber labels of the accompanying figure, the collineation group of the Fano plane, presented as a [[permutation group]] can be generated by the [[permutation]]s given in cyclic notation by:&lt;ref&gt;{{harvnb|Pisanski|Servatius|2013|loc=p. 173}} given with a different labeling&lt;/ref&gt;
:⟨(1432657), (162)(374), (14)(27), (17)(24), (17)(24)(36)⟩.

The collineation group is made up of 6 [[conjugacy classes]].&lt;br&gt;
All [[Cycles and fixed points|cycle structures]] except the 7-cycle uniquely define a conjugacy class:
*[[File:Fanoperm124.svg|40px]] The identity permutation
*[[File:Fanoperm421.svg|40px]] 21 permutations with two [[Transposition (mathematics)|2-cycles]]
*[[File:Fanoperm621.svg|40px]] 42 permutations with a 4-cycle and a 2-cycle
*[[File:Fanoperm521.svg|40px]] 56 permutations with two 3-cycles
The 48 permutations with a complete 7-cycle form two distinct conjugacy classes with 24 elements:
*[[File:Fanoperm713.svg|40px]] ''A'' maps to ''B'', ''B'' to ''C'', ''C'' to ''D''. Then ''D'' is on the same line as ''A'' and ''B''.
*[[File:Fanoperm265.svg|40px]] ''A'' maps to ''B'', ''B'' to ''C'', ''C'' to ''D''. Then ''D'' is on the same line as ''A'' and ''C''.

See [[v:3-bit Walsh permutation#Fano plane collineations|Fano plane collineations]] for a complete list.

Hence, by the [[Pólya enumeration theorem]], the number of inequivalent colorings of the Fano plane with ''n'' colors is:
:&lt;math&gt;{1 \over 168}\left(n^7 + 21 n^5 + 98 n^3 + 48 n\right).&lt;/math&gt;

==Complete quadrangles and Fano subplanes==
{{main|Complete quadrangle}}
In any projective plane a set of four points, no three of which are collinear, and the six lines joining pairs of these points is a [[Projective configuration|configuration]] known as a [[complete quadrangle]]. The lines are called ''sides'' and pairs of sides that do not meet at one of the four points are called ''opposite sides''. The points at which opposite sides meet are called ''diagonal points'' and there are three of them.&lt;ref&gt;{{citation|first=Frederick W.|last=Stevenson|title=Projective Planes|year=1972|publisher= W.H. Freeman and Co.|isbn=0-7167-0443-9|page= 21}}&lt;/ref&gt;

If this configuration lies in a projective plane and the three diagonal points are collinear, then the seven points and seven lines of the expanded configuration form a subplane of the projective plane that is isomorphic to the Fano plane and is called a ''Fano subplane''. 

A famous result, due to [[Andrew M. Gleason]] states that if every complete quadrangle in a finite projective plane extends to a Fano subplane (that is, has collinear diagonal points) then the plane is Desarguesian.&lt;ref&gt;{{citation|first=Andrew M.|last=Gleason|author-link=Andrew M. Gleason|title=Finite Fano planes|journal=American Journal of Mathematics|year=1956|volume=78|pages=797-807}}&lt;/ref&gt; Gleason called any projective plane satisfying this condition a ''Fano plane'' thus creating some confusion with modern terminology. To compound the confusion, ''Fano's axiom'' states that the diagonal points of a complete quadrangle are ''never'' collinear, a condition that holds in the Euclidean and real projective planes. Thus, what Gleason called Fano planes do not satisfy Fano's axiom.&lt;ref&gt;{{harvnb|Dembowski|1968|loc=p. 168}}&lt;/ref&gt;
 
==Configurations==

The Fano plane contains the following numbers of configurations of points and lines of different types. For each type of configuration, the number of copies of configuration multiplied by the number of symmetries of the plane that keep the configuration unchanged is equal to 168, the size of the entire collineation group, provided each copy can be mapped to any other copy (see [[Orbit-Stabiliser theorem]]). Since the Fano plane is self-dual, these configurations come in dual pairs and it can be shown that the number of collineations fixing a configuration equals the number of collineations that fix its dual configuraton.
* There are 7 points with 24 symmetries fixing any point and dually, there are 7 lines with 24 symmetries fixing any line. The number of symmetries follows from the 2-transitivity of the collineation group, which implies the group acts transitively on the points.
*There are 42 [[ordered pair]]s of points, and each may be mapped by a symmetry onto any other ordered pair. For any ordered pair there are 4 symmetries fixing it. Correspondingly, there are 21 [[unordered pair]]s of points, each of which may be mapped by a symmetry onto any other unordered pair. For any unordered pair there are 8 symmetries fixing it.
*There are 21 [[flag (geometry)|flags]] consisting of a line and a point on that line. Each flag corresponds to the unordered pair of the other two points on the same line. For each flag, 8 different symmetries keep it fixed.
* There are 7 ways of selecting a [[Quadrilateral|quadrangle]] of four (unordered) points no three of which are collinear.  These four points form the complement of a line, which is the ''diagonal line'' of the quadrangle and a collineation fixes the quadrangle if and only if it fixes the diagonal line. Thus, there are 24 symmetries that fix any such quadrangle. The dual configuration is a quadrilateral consisting of four lines no three of which meet at a point and their six points of intersection, it is the complement of a point in the Fano plane.
* There are &lt;math&gt;\tbinom{7}{3} = 35&lt;/math&gt; triples of points, seven of which are collinear triples, leaving 28 non-collinear triples or ''[[triangles]]''. The configuration consisting of the three points of a triangle and the three lines joining pairs of these points is represented by a 6-cycle in the Heawood graph. A color-preserving automorphism of the Heawood graph that fixes each vertex of a 6-cycle must be the identity automorphism.&lt;ref&gt;{{harvnb|Pisanski|Servatius|2013|loc=p. 171}}&lt;/ref&gt; This means that there are 168 labeled triangles fixed only by the identity collineation and only six collineations that stabilize an unlabeled triangle, one for each permutation of the points. These 28 triangles may be viewed as corresponding to the 28 [[bitangents of a quartic]].&lt;ref&gt; {{harvnb|Manivel|2006}}&lt;/ref&gt; There are 84 ways of specifying a triangle together with one distinguished point on that triangle and two symmetries fixing this configuration. The dual of the triangle configuration is also a triangle.
*There are 28 ways of selecting a point and a line that are not incident to each other (an ''anti-flag''), and six ways of permuting the Fano plane while keeping an anti-flag fixed. For every non-incident point-line pair (''p'',''l''), the three points that are unequal to ''p'' and that do not belong to ''l'' form a triangle, and for every triangle there is a unique way of grouping the remaining four points into an anti-flag.
*There are 28 ways of specifying a [[hexagon]] in which no three consecutive vertices lie on a line, and six symmetries fixing any such hexagon.
*There are 84 ways of specifying a [[pentagon]] in which no three consecutive vertices lie on a line, and two symmetries fixing any pentagon.

The Fano plane is an example of an {{math|(''n''&lt;sub&gt;3&lt;/sub&gt;)}}-configuration, that is, a set of {{mvar|n}} points and {{mvar|n}} lines with three points on each line and three lines through each point. The Fano plane, a (7&lt;sub&gt;3&lt;/sub&gt;)-configuration, is unique and is the smallest such configuration.&lt;ref&gt;{{harvnb|Pisanski|Servatius|2013|loc=p. 165}}&lt;/ref&gt; According to a theorem by Steinitz,&lt;ref&gt;{{citation|first=E.|last=Steinitz|title=Über die construction der configurationen {{math|''n''&lt;sub&gt;3&lt;/sub&gt;}}|year=1894|type=Ph. D. thesis|publisher=Kgl. Universität, Breslau}}&lt;/ref&gt; configurations of this type can be realized in the Euclidean plane having at most one curved line (all other lines lying on Euclidean lines).&lt;ref&gt;{{harvnb|Pisanski|Servatius|2013|loc=p. 221}}&lt;/ref&gt;

==Block design theory==

The Fano plane is a small [[Block design#Symmetric BIBDs|symmetric block design]], specifically a 2-(7,3,1)-design.  The points of the design are the points of the plane, and the blocks of the design are the lines of the plane.&lt;ref name=vanLint196&gt;{{harvnb|van Lint|Wilson|1992|loc= pp. 196−197}}&lt;/ref&gt;  As such it is a valuable example in (block) design theory.

With the points labelled 0, 1, 2, ..., 6 the lines (as point sets) are the translates of the (7, 3, 1) planar [[difference set]] given by {0, 1, 3} in the group &lt;math&gt;\mathbb{Z} / 7\mathbb{Z}.&lt;/math&gt;&lt;ref name=vanLint196 /&gt; With the lines labeled ''ℓ''&lt;sub&gt;0&lt;/sub&gt;, ...,''ℓ''&lt;sub&gt;6&lt;/sub&gt; the [[incidence matrix]] (table) is given by:

:{| align=left class=wikitable
|-
! ||0||1||2||3||4||5||6
|-
!''ℓ''&lt;sub&gt;0&lt;/sub&gt;
|1||1||0||1||0||0||0
|-
!''ℓ''&lt;sub&gt;1&lt;/sub&gt;
|0||1||1||0||1||0||0 
|-
!''ℓ''&lt;sub&gt;2&lt;/sub&gt;
|0||0||1||1||0||1||0 
|-
!''ℓ''&lt;sub&gt;3&lt;/sub&gt;
|0||0||0||1||1||0||1
|-
!''ℓ''&lt;sub&gt;4&lt;/sub&gt;
|1||0||0||0||1||1||0
|-
!''ℓ''&lt;sub&gt;5&lt;/sub&gt;
|0||1||0||0||0||1||1
|-
!''ℓ''&lt;sub&gt;6&lt;/sub&gt;
|1||0||1||0||0||0||1
|}
{{clr}}
===Steiner system===
{{main|Steiner system}}

The Fano plane, as a block design, is a [[Steiner system#Steiner triple systems|Steiner triple system]].&lt;ref&gt;{{harvnb|Polster|1998|loc=p. 23}}&lt;/ref&gt;  As such, it can be given the structure of a [[quasigroup]].  This quasigroup coincides with the multiplicative structure defined by the unit [[octonion]]s ''e''&lt;sub&gt;1&lt;/sub&gt;, ''e''&lt;sub&gt;2&lt;/sub&gt;, ..., ''e''&lt;sub&gt;7&lt;/sub&gt; (omitting 1) if the signs of the octonion products are ignored {{harv|Baez|2002}}.

==Matroid theory==
{{main|Matroid theory}}

The Fano plane is one of the important examples in the structure theory of [[matroid]]s.  Excluding the Fano plane as a [[matroid minor]] is necessary to characterize several important classes of matroids, such as [[regular matroid|regular]], [[graphic matroid|graphic]], and cographic ones.

If you break one line apart into three 2-point lines you obtain the "non-Fano configuration", which can be embedded in the real plane. It is another important example in matroid theory, as it must be excluded for many theorems to hold.

== Fano three-space==
[[File:fano3space.png|thumb|PG(3,2) but not all the lines are drawn]]

The Fano plane can be extended in a third dimension to form a three-dimensional projective space, denoted by PG(3,2).
It has 15 points, 35 lines, and 15 planes and is the smallest three-dimensional projective space.&lt;ref&gt;{{citation|first=Bruce E.|last=Meserve|title=Fundamental Concepts of Geometry|year=1983|origyear=1955|publisher=Dover|isbn=0-486-63415-9|page=29}}&lt;/ref&gt;  It also has the following properties:&lt;ref&gt;{{harvnb|Polster|1998|loc=p. 69}}&lt;/ref&gt;

* Each point is contained in 7 lines and 7 planes
* Each line is contained in 3 planes and contains 3 points 
* Each plane contains 7 points and 7 lines
* Each plane is [[Isomorphism|isomorphic]] to the Fano plane
* Every pair of distinct planes intersect in a line
* A line and a plane not containing the line intersect in exactly one point

==See also==
{{commons category}}

*[[Projective configuration]]
*[[Transylvania lottery]]

==Notes==
{{reflist}}

==References==
*{{citation |last=Baez |first=John |authorlink=John Baez |title=The Octonions |url=http://www.ams.org/bull/2002-39-02/S0273-0979-01-00934-X/home.html |journal=Bull. Amer. Math. Soc. |volume=39 |year=2002 |pages=145–205 |doi=10.1090/S0273-0979-01-00934-X |issue=2|arxiv=math/0105155 }} ([http://math.ucr.edu/home/baez/octonions/ Online HTML version])
*{{Citation | last1=Dembowski | first1=Peter | title=Finite geometries | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=[[Ergebnisse der Mathematik und ihrer Grenzgebiete]], Band 44 | mr=0233275  | year=1968 | isbn=3-540-61786-8}}
* {{Citation
|title=Projective Geometries Over Finite Fields
|first1=J. W. P.
|last1=Hirschfeld
|publisher=[[Oxford University Press]]
|year=1979
|isbn=978-0-19-850295-1}}
*{{citation |last=Manivel |first=L. |doi=10.1016/j.jalgebra.2006.04.029 |issue=1 |journal=Journal of Algebra |issn=0021-8693 |pages=457–486 |title=Configurations of lines and models of Lie algebras |volume=304 |year=2006}}
* {{citation|first1=Tomaž|last1=Pisanski|first2=Brigitte|last2=Servatius|author1-link=Tomaž Pisanski|author2-link=Brigitte Servatius|title=Configurations from a Graphical Viewpoint|year=2013|publisher=Birkhäuser|isbn=978-0-8176-8363-4}}
* {{citation|first=Burkard|last=Polster|author-link=Burkard Polster|year=1998|title=A Geometrical Picture Book|publisher=Springer|isbn=978-0-387-98437-7}}
&lt;!-- Chapter 1: "Introduction via the Fano Plane", also pp 21, 23, 27, 29, 71, 73, 77, 112, 115, 116, 132, 174 --&gt;
* {{citation |last1=van Lint |first1=J. H. |last2=Wilson |first2=R. M. |year=1992 |title=A Course in Combinatorics |publisher=Cambridge University Press|isbn=978-0-521-42260-4}}

==External links==
*{{MathWorld|title=Fano Plane|urlname=FanoPlane}}
*{{planetmath reference|id=3510|title=Finite plane and Fano plane}}

[[Category:Projective geometry]]
[[Category:Finite geometry]]
[[Category:Incidence geometry]]
[[Category:Configurations]]
[[Category:Matroid theory]]</text>
      <sha1>nciibyt1anf1fi2i1isejm4r5sy9mfk</sha1>
    </revision>
  </page>
  <page>
    <title>Fano variety</title>
    <ns>0</ns>
    <id>3095929</id>
    <revision>
      <id>854307044</id>
      <parentid>848081875</parentid>
      <timestamp>2018-08-10T11:11:00Z</timestamp>
      <contributor>
        <username>FrescoBot</username>
        <id>9021902</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:FrescoBot/Links|link syntax]] and minor changes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8557">In [[algebraic geometry]],  a '''Fano variety''', introduced in {{harvs|authorlink=Gino Fano|last=Fano|year1=1934|year2=1942}}, is a [[Complete algebraic variety|complete variety]] ''X'' whose [[anticanonical bundle]] ''K''&lt;sub&gt;X&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; is [[ample line bundle|ample]]. In this definition, one could assume that ''X'' is [[Smooth scheme|smooth]] over a field, but the [[minimal model program]] has also led to the study of Fano varieties with various types of singularities, such as [[canonical singularity|terminal]] or [[canonical singularity|klt]] singularities.

==Examples==

*The fundamental example of Fano varieties are the [[algebraic geometry of projective spaces|projective spaces]]: the [[canonical bundle|anticanonical line bundle]] of '''P'''&lt;sup&gt;''n''&lt;/sup&gt; over a field ''k'' is ''O''(''n''+1), which is [[very ample]] (over the complex numbers, its [[curvature]] is ''n+1'' times the [[Fubini–Study]] symplectic form).
*Let ''D'' be a smooth codimension-1 subvariety in '''P'''&lt;sup&gt;n&lt;/sup&gt;. The [[adjunction formula]] implies that ''K''&lt;sub&gt;''D''&lt;/sub&gt; = (''K''&lt;sub&gt;''X''&lt;/sub&gt; + ''D'')|&lt;sub&gt;''D''&lt;/sub&gt; = (−(''n''+1)''H'' + deg(''D'')H)|&lt;sub&gt;''D''&lt;/sub&gt;, where ''H'' is the class of a hyperplane. The [[hypersurface]] ''D'' is therefore Fano if and only if deg(''D'') &lt; ''n''+1.
*More generally, a smooth [[complete intersection]] of hypersurfaces in ''n''-dimensional projective space is Fano if and only if the sum of their degrees is at most ''n''.
*[[Weighted projective space]] '''P'''(''a''&lt;sub&gt;0&lt;/sub&gt;,...,''a''&lt;sub&gt;''n''&lt;/sub&gt;) is a singular ([[canonical singularity|klt]]) Fano variety. This is the projective scheme associated to a graded polynomial ring whose generators have degrees ''a''&lt;sub&gt;0&lt;/sub&gt;,...,''a''&lt;sub&gt;''n''&lt;/sub&gt;. If this is well formed, in the sense that no ''n'' of the numbers ''a'' have a common factor greater than 1, then any complete intersection of hypersurfaces such that the sum of their degrees is less than ''a''&lt;sub&gt;0&lt;/sub&gt;+...+''a''&lt;sub&gt;''n''&lt;/sub&gt; is a Fano variety.
*Every projective variety in characteristic zero that is homogeneous under a linear algebraic group is Fano.

==Some properties==

The existence of some ample line bundle on ''X'' is equivalent to ''X'' being a [[projective variety]], so a Fano variety is always projective. For a Fano variety ''X'' over the complex numbers, the [[Kodaira vanishing theorem]] implies that the [[sheaf cohomology]] groups &lt;math&gt;H^j(X , \mathcal{O}_X)&lt;/math&gt; of the [[structure sheaf]] vanish for &lt;math&gt;j&gt; 0&lt;/math&gt;. In particular, the Todd genus &lt;math&gt;\chi (X, \mathcal{O})= \sum (-1)^j h^j(X , \mathcal{O}_X)&lt;/math&gt; automatically equals 1. The &lt;math&gt;j=1,2&lt;/math&gt; cases of this vanishing statement also tell us that the [[first Chern class]] induces an isomorphism &lt;math&gt;c_1: Pic(X)\to H^2(X, \mathbb{Z})&lt;/math&gt;. 

By Yau's solution of the [[Calabi conjecture]], a smooth complex variety admits Kähler metrics of positive
Ricci curvature if and only if it is Fano. [[Myers' theorem]]  therefore tells us that the [[universal cover]]  of a Fano manifold is compact, and so can only be a finite covering. However,  we have just seen that the Todd genus of a Fano manifold must equal 1. Since this would also apply to the manifold's universal cover, and since the Todd genus is multiplicative under finite covers, it follows that &lt;b&gt;any Fano manifold is [[Simply connected space|simply connected]]&lt;/b&gt;. 

A much easier fact is that every Fano variety has [[Kodaira dimension]] &amp;minus;∞.

Campana and [[János Kollár|Kollár]]–[[Yoichi Miyaoka|Miyaoka]]–[[Shigefumi Mori|Mori]] showed that a smooth Fano variety over an algebraically closed field is [[Rational variety#Rationally connected variety|rationally chain connected]]; that is, any two closed points can be connected by a chain of [[Algebraic curve#Rational curves|rational curves]].&lt;ref&gt;J. Kollár. Rational Curves on Algebraic Varieties. Theorem V.2.13.&lt;/ref&gt; 
Kollár–Miyaoka–Mori also showed that the smooth Fano varieties of a given dimension over an algebraically closed field of characteristic zero form a bounded family, meaning that they are classified by the points of finitely many algebraic varieties.&lt;ref&gt;J. Kollár. Rational Curves on Algebraic Varieties. Corollary V.2.15.&lt;/ref&gt; In particular, there are only finitely many deformation classes of Fano varieties of each dimension. In this sense, Fano varieties are much more special than other classes of varieties such as varieties of [[Variety of general type#General type|general type]].

==Classification in small dimensions==

The following discussion concerns smooth Fano varieties over the complex numbers.

A Fano curve is [[isomorphism|isomorphic]] to the [[projective line]].

A Fano surface is also called a [[del Pezzo surface]]. Every del Pezzo surface is isomorphic to either '''P'''&lt;sup&gt;1&lt;/sup&gt; × '''P'''&lt;sup&gt;1&lt;/sup&gt; or to the projective plane blown up in at most 8 points, which must be in general position. As a result, they are all [[Rational variety|rational]].

In dimension 3, there are smooth complex Fano varieties which are not rational, for example cubic 3-folds in '''P'''&lt;sup&gt;4&lt;/sup&gt; (by [[Herbert Clemens|Clemens]] - [[Phillip Griffiths|Griffiths]]) and quartic 3-folds in '''P'''&lt;sup&gt;4&lt;/sup&gt; (by [[Vasily Iskovskikh|Iskovskikh]] - [[Yuri Manin|Manin]]). {{harvs|txt|last=Iskovskih|year1=1977|year2=1978|year3=1979}} classified the smooth Fano 3-folds with second [[Betti number]] 1 into 17 classes, and  {{harvtxt|Mori|Mukai|1981}} classified the smooth ones with second Betti number at least 2, finding 88 deformation classes. A detailed summary of the classification of smooth Fano 3-folds is given in {{harvtxt|Iskovskikh|Prokhorov|1999}}.

==Notes==
{{reflist}}

==References==
*{{citation|first=Gino |last=Fano| author-link=Gino Fano | chapter=Sulle varietà algebriche a tre dimensioni aventi tutti i generi nulli|title= Proc. Internat. Congress Mathematicians (Bologna) , 4 , Zanichelli  |year=1934|pages= 115–119}}
*{{Citation | doi=10.1007/BF02565618 | last1=Fano | first1=Gino | author-link=Gino Fano | title=Su alcune varietà algebriche a tre dimensioni razionali, e aventi curve-sezioni canoniche | url=http://gdz.sub.uni-goettingen.de/no_cache/dms/load/img/?IDDOC=209966 | mr=0006445 | year=1942 | journal=Commentarii Mathematici Helvetici | issn=0010-2571 | volume=14 | pages=202–211}}
*{{Citation | last1=Iskovskih | first1=V. A. | title=Fano threefolds. I  | doi=10.1070/IM1977v011n03ABEH001733 | mr=463151 | year=1977 | journal=Math. USSR Izv.  | issn=0373-2436 | volume=11 | issue=3 | pages=485–527}}
*{{Citation | last1=Iskovskih | first1=V. A. | title=Fano 3-folds II | doi=10.1070/IM1978v012n03ABEH001994Fano+3-folds+II | mr=0463151  | year=1978 | journal=Math USSR Izv. | volume=12 | issue=3 | pages=469–506}}
*{{Citation | last1=Iskovskih | first1=V. A. | title=Current problems in mathematics, Vol. 12 (Russian) | publisher=VINITI, Moscow | mr=537685 | year=1979 | chapter=Anticanonical models of three-dimensional algebraic varieties | pages=59–157}}
*{{Citation | last1=Iskovskikh | first1=V. A. | last2=Prokhorov | first2=Yu. G. | chapter=Fano varieties | pages=1–247 | title=Algebraic Geometry, V. Encyclopedia Math. Sci., 47 | editor1=A. N. Parshin | editor2=I. R. Shafarevich | year=1999 | publisher=[[Springer-Verlag]] | isbn=3-540-61468-0 | mr=1668579}}
*{{Citation | last1=Kollár | first1=János | author1-link=Janos Kollar | title=Rational Curves on Algebraic Varieties | publisher=[[Springer-Verlag]] | location=Berlin, Heidelberg | isbn=978-3-642-08219-1 | doi=10.1007/978-3-662-03276-3 | mr=1440180 | year=1996 }}
*{{eom|id=F/f038220|first=Vik.S.|last= Kulikov}}
*{{Citation | last1=Mori | first1=Shigefumi | last2=Mukai | first2=Shigeru | authorlink=Shigefumi Mori | author2-link=Shigeru Mukai | title=Classification of Fano 3-folds with B&lt;sub&gt;2&lt;/sub&gt;≥2 | doi=10.1007/BF01170131 | mr=641971 | year=1981 | journal=Manuscripta Mathematica | issn=0025-2611 | volume=36 | issue=2 | pages=147–162}}
*{{Citation | last1=Mori | first1=Shigefumi | last2=Mukai | first2=Shigeru | authorlink=Shigefumi Mori | author2-link=Shigeru Mukai | title=Erratum: "Classification of Fano 3-folds with B&lt;sub&gt;2&lt;/sub&gt;≥2" | doi=10.1007/s00229-002-0336-2 | mr=1969009 | year=2003 | journal=Manuscripta Mathematica | issn=0025-2611 | volume=110 | issue=3 | pages=407}}

==See also==
*[[Periodic table of shapes]] a project to classify all Fano varieties in three, four and five dimensions.

[[Category:Algebraic geometry]]
[[Category:3-folds]]</text>
      <sha1>84ndbeorbcpammilv94f24auolxhkg4</sha1>
    </revision>
  </page>
  <page>
    <title>Flow-sensitive typing</title>
    <ns>0</ns>
    <id>49728689</id>
    <revision>
      <id>863211973</id>
      <parentid>842381867</parentid>
      <timestamp>2018-10-09T11:52:29Z</timestamp>
      <contributor>
        <username>Voddan</username>
        <id>18372678</id>
      </contributor>
      <comment>Corrected the definition, add Kotlin example</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5872">{{Type systems}}

In [[programming language theory]], '''flow-sensitive typing''' (or '''flow typing''') is a [[type system]] where the type of an [[Expression (computer science)|expression]] depends on its position in the [[control flow]].

In [[Static typing|statically typed languages]], a type of an expression is determined by the types of the sub-expressions that compose it. However, in flow-sensitive typing, an expression's type may be updated to a more specific type if it follows a statement that validates its type. The type is determined by using [[type inference]] and type information is carried using [[algebraic data type]]s.

== Example ==

=== Ceylon ===

See the following example in [[Ceylon (programming language)|Ceylon]] which illustrates the concept:

&lt;syntaxhighlight lang="ceylon" line=1&gt;
// Object? means the variable "name" is of type Object or else null
void hello(Object? name) {
    if (is String name) {
        // "name" now has type String in this block
        print("Hello, ``name``!");
        // and it is possible to call String methods on the variable
        print(" String.size is ``name.size``");
    }
    else if (exists name) {
        // "name" now has type Object in this block
        print("Hello, object ``name``!");
    }
    else {
        print("Hello, world!");
    }
}

          
hello(null);
hello(1);
hello("John Doe");
&lt;/syntaxhighlight&gt;

Which outputs:

 &lt;nowiki&gt;Hello, world!
Hello, object 1!
Hello, John Doe!
 String.size is 8&lt;/nowiki&gt;

=== Kotlin ===

[[Kotlin (programming language)|Kotlin]] uses very flexible flow typing:

&lt;syntaxhighlight lang="kotlin" line=1&gt;
fun hello(obj: Any) {
    // A type cast fails if `obj` is not a String
    obj as String

    // Since the type cast did not fail, `obj` must be a String!
    val l = obj.length

    println("'$obj' is a string of length $l")
}
          
hello("Mooooo")
&lt;/syntaxhighlight&gt;

== Benefits ==

This technique coupled with type inference reduces the need for writing [[Type signature|type annotations]] for all variables or to do [[Type conversion|type casting]], like is seen with [[Dynamic typing|dynamic languages]] that use [[duck typing]]. It reduces [[verbosity]] and makes up for terser code, easier to read and modify.

It can also help language implementers to provide faster implementations for dynamic languages by statically predicting the type of objects.&lt;ref&gt;{{cite web | url=http://blog.jooq.org/2014/12/11/the-inconvenient-truth-about-dynamic-vs-static-typing | title=The Inconvenient Truth About Dynamic vs. Static Typing | publisher=blog.jooq.org | date=11 December 2014 | accessdate=11 March 2016 | author=Lukas Eder}}&lt;/ref&gt;

Finally, it increases [[type safety]] and can prevent problems due to [[null pointer]]s, labeled by [[C.A.R. Hoare]]—the null reference inventor—as "the billion dollar mistake"&lt;ref&gt;{{cite web
|url=http://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare
|title=Null References: The Billion Dollar Mistake
|publisher=InfoQ.com
|date=2009-08-25
|author=[[Tony Hoare]]
|quote=I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language ([[ALGOL W]]). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.}}&lt;/ref&gt;

==Implementations==

[[Whiley (programming language)|Whiley]], created by David J. Pearce, was the first language to make use of flow-sensitive typing in 2009.&lt;ref&gt;{{cite web | url=http://whiley.org/2010/09/22/on-flow-sensitive-types-in-whiley/ | title=On Flow-Sensitive Types in Whiley | publisher=whiley.org | date=22 September 2010 | accessdate=11 March 2016 | author=David J. Pearce}}&lt;/ref&gt;&lt;ref&gt;{{cite web | url=http://whiley.org/guide/typing/flow-typing/ | title=Whiley - Flow Typing | publisher=whiley.org | date=8 April 2012 | accessdate=11 March 2016 | author=David J. Pearce}}&lt;/ref&gt;

Since this introduction, other languages have made use of it, namely [[Ceylon (programming language)|Ceylon]],&lt;ref&gt;{{cite web | url=http://ceylon-lang.org/documentation/1.2/introduction/#typesafe_null_and_flow_sensitive_typing | title=Ceylon - Quick introduction - Typesafe null and flow-sensitive typing | publisher=ceylon-lang.org | accessdate=11 March 2016}}&lt;/ref&gt; [[Kotlin (programming language)|Kotlin]],&lt;ref&gt;{{cite web | url=https://kotlinlang.org/docs/reference/null-safety.html | title=Null Safety | publisher=kotlinlang.org | accessdate=11 March 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite web | url=https://kotlinlang.org/docs/reference/typecasts.html | title=Type Checks and Casts | publisher=kotlinlang.org | accessdate=11 March 2016}}&lt;/ref&gt; [[TypeScript]]&lt;ref&gt;{{cite web | url=https://blogs.msdn.microsoft.com/typescript/2014/11/18/typescript-1-4-sneak-peek-union-types-type-guards-and-more | title=TypeScript 1.4 sneak peek: union types, type guards, and more | publisher=blogs.msdn.microsoft.com | date=18 November 2014 | accessdate=11 March 2016 | author=Ryan Cavanaugh}}&lt;/ref&gt; and [[Facebook]] Flow.&lt;ref&gt;{{cite web | url=https://code.facebook.com/posts/1505962329687926/flow-a-new-static-type-checker-for-javascript | title=Flow, a new static type checker for JavaScript | publisher=code.facebook.com | date=18 November 2014 | accessdate=11 March 2016 | authors=Avik Chaudhuri, Basil Hosmer, Gabriel Levi}}&lt;/ref&gt;

==External references==
&lt;references /&gt;

{{Data types}}

[[Category:Type systems]]
[[Category:Data types]]
[[Category:Program analysis]]
[[Category:Type theory]]</text>
      <sha1>5od3yredbos5fhq9phttca0f52wkwck</sha1>
    </revision>
  </page>
  <page>
    <title>Frink ideal</title>
    <ns>0</ns>
    <id>21687353</id>
    <revision>
      <id>628760629</id>
      <parentid>606998889</parentid>
      <timestamp>2014-10-08T07:58:06Z</timestamp>
      <contributor>
        <ip>129.125.51.184</ip>
      </contributor>
      <comment>Clarified that the upper and lower bounds are common upper/lower bounds.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1439">In mathematics, a '''Frink ideal''', introduced by [[Orrin Frink]], is a certain kind of subset of a [[partially ordered set]].

== Basic definitions ==
LU(''A'') is the set of all common [[lower bound]]s of the set of all common [[upper bound]]s of the subset ''A'' of a [[partially ordered set]].

A  subset ''I'' of a partially ordered set (''P'',&amp;nbsp;≤) is a '''Frink ideal''', if the following condition holds:

For every finite subset ''S'' of ''P'', ''S''&amp;nbsp;&lt;math&gt;\subseteq&lt;/math&gt;&amp;nbsp;''I''  implies that LU(''S'')&amp;nbsp;&lt;math&gt;\subseteq&lt;/math&gt;&amp;nbsp;''I''.

A  subset ''I'' of a partially ordered set (''P'',≤) is a '''normal ideal''' or a '''cut''' if LU(''I'')&amp;nbsp;&lt;math&gt;\subseteq&lt;/math&gt;&amp;nbsp;''I''.

== Remarks==
#Every Frink ideal ''I'' is a [[lower set]].
#A subset ''I'' of a lattice (''P'',&amp;nbsp;≤) is a  Frink ideal [[if and only if]] it is a lower set that is closed under finite joins ([[suprema]]).
# Every normal ideal is a Frink ideal.

==Related notions==
*[[pseudoideal]]
*[[Doyle pseudoideal]]

==References==
*{{cite journal|author=Frink, Orrin|title=Ideals in Partially Ordered Sets|journal=[[American Mathematical Monthly]]|volume=61|year=1954|pages=223–234|mr=61575|doi=10.2307/2306387}}
*{{cite journal|author=Niederle, Josef|title=Ideals in ordered sets|journal=[[Rendiconti del Circolo Matematico di Palermo]]|volume=55|year=2006|pages=287–295|doi=10.1007/bf02874708}}

[[Category:Order theory]]</text>
      <sha1>2zui5aucex8j6pmqnt7usfczeebvdug</sha1>
    </revision>
  </page>
  <page>
    <title>Graph reduction</title>
    <ns>0</ns>
    <id>564004</id>
    <revision>
      <id>871548079</id>
      <parentid>824489835</parentid>
      <timestamp>2018-12-01T21:09:07Z</timestamp>
      <contributor>
        <username>Jschievink</username>
        <id>34480924</id>
      </contributor>
      <comment>/* Notes */ Remove incorrect and unsourced statements from notes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4503">{{About|the computer science term|for the graph theory use|transitive reduction}}
In [[computer science]], '''graph reduction''' implements an efficient version of non-strict evaluation, an [[evaluation strategy]] where the arguments to a function are not immediately evaluated. This form of non-strict evaluation is also known as [[lazy evaluation]] and used in [[functional programming|functional programming languages]]. The technique was first developed by [[Chris Wadsworth]] in 1971.

== Motivation ==
A simple example of evaluating an arithmetic expression follows:

:&lt;math&gt;
\begin{align}
&amp; {} &amp; &amp;((2+2)+(2+2))+(3+3) \\
&amp; {} &amp;=&amp;((2+2)+(2+2))+ 6 \\
&amp; {} &amp;=&amp;((2+2)+ 4)+6 \\
&amp; {} &amp;=&amp;(4+4)+6 \\
&amp; {} &amp;=&amp;8+6 \\
&amp; {} &amp;=&amp;14
\end{align}
&lt;/math&gt;

The above reduction sequence employs a strategy known as [[outermost tree reduction]]. The same expression can be evaluated using [[innermost tree reduction]], yielding the reduction sequence:

:&lt;math&gt;
\begin{align}
&amp; {} &amp;  &amp;((2+2)+(2+2))+(3+3) \\
&amp; {} &amp;= &amp;((2+2)+4)+(3+3) \\
&amp; {} &amp;= &amp;(4+4)+(3+3) \\
&amp; {} &amp;= &amp;(4+4)+6 \\
&amp; {} &amp;= &amp;8+6 \\
&amp; {} &amp;= &amp;14
\end{align}
&lt;/math&gt;

Notice that the reduction order is made explicit by the addition of parentheses. This expression could also have been simply evaluated right to left, because addition is an [[associative]] operation.

Represented as a [[Tree data structure|tree]], the expression above looks like this:

[[Image:Expression Tree.svg|300px]]

This is where the term tree reduction comes from.  When represented as a tree, we can think of innermost reduction as working from the bottom up, while outermost works from the top down.

The expression can also be represented as a [[directed acyclic graph]], allowing sub-expressions to be shared:

[[Image:Expression Graph.svg|300px]]

As for trees, outermost and innermost reduction also applies to graphs.  Hence we have '''graph reduction'''.

Now evaluation with outermost graph reduction can proceed as follows:

[[Image:Expression Graph Reduction.svg|200px]]

Notice that evaluation now only requires four steps. Outermost graph reduction is referred to as [[lazy evaluation]] and innermost graph reduction is referred to as [[eager evaluation]].

== Combinator graph reduction ==
'''Combinator graph reduction''' is a fundamental implementation technique for [[functional programming]] languages, in which a program is converted into a [[combinator]] representation which is mapped to a [[directed graph]] [[data structure]] in computer memory, and program execution then consists of rewriting parts of this graph ("reducing" it) so as to move towards useful results.

== History ==
The concept of a graph reduction that allows evaluated values to be shared was first developed by [[Chris Wadsworth]] in his 1971 Ph.D. dissertation.&lt;ref&gt;{{cite journal | last = Hudak | first = Paul | title = Conception, evolution, and application of functional programming languages | journal = [[Association for Computing Machinery|ACM]] Computing Surveys | volume = 21 | issue = 3 | pages = 359–411 |date=September 1989 | citeseerx = 10.1.1.83.6505 | doi =10.1145/72551.72554 }}&lt;/ref&gt; This dissertation was cited by Peter Henderson and James H. Morris Jr. in 1976 paper, “A lazy evaluator” &lt;ref&gt;[http://portal.acm.org/citation.cfm?id=811543 A lazy evaluator]&lt;/ref&gt; that introduced the notion of lazy evaluation. In 1976 [[David Turner (computer scientist)|David Turner]] incorporated lazy evaluation into [[SASL programming language|SASL]] using combinators.&lt;ref&gt;{{cite conference |last1=Hudak |first1=Paul |last2=Hughes|first2=John|last3=Peyton Jones|first3=Simon|last4=Wadler|first4=Philip |title=A History of Haskell: Being Lazy with Class|url =http://haskell.org/haskellwiki/History_of_Haskell |booktitle=History of Programming Languages Conference 2007 }}&lt;/ref&gt;
SASL was an early functional programming language first developed by Turner in 1972.

==See also==
*[[Graph reduction machine]]
*[[SECD machine]]

==Notes==

&lt;references/&gt;

==References==
*{{cite book
 |title=Introduction to Functional Programming using Haskell
 |last=Bird|first=Richard
 |publisher=Prentice Hall
 |year=1998
 |isbn=0-13-484346-0
 }}

==Further reading==
*[[Simon Peyton Jones]], ''The Implementation of Functional Programming Languages'', Prentice Hall, 1987.  Full text online.[http://research.microsoft.com/users/simonpj/papers/slpj-book-1987/index.htm]

[[Category:Implementation of functional programming languages]]
[[Category:Graph algorithms]]
[[Category:Graph rewriting]]</text>
      <sha1>m195aunf4b6oy76i4lxtthd2t59x0sw</sha1>
    </revision>
  </page>
  <page>
    <title>Grundy's game</title>
    <ns>0</ns>
    <id>10966810</id>
    <revision>
      <id>824599940</id>
      <parentid>824376618</parentid>
      <timestamp>2018-02-08T09:52:31Z</timestamp>
      <contributor>
        <ip>193.55.176.111</ip>
      </contributor>
      <comment>/* Mathematical theory */ fixed Elwyn Berlekamp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2784">'''Grundy's game''' is a two-player mathematical game of strategy. The starting configuration is a single heap of objects, and the two players take turn splitting a single heap into two heaps of different sizes. The game ends when only heaps of size two and smaller remain, none of which can be split unequally. The game is usually played as a ''[[misère game|normal play]]'' game, which means that the last person who can make an allowed move wins.

== Illustration ==

A normal play game starting with a single heap of 8 is a win for the first player provided he does start by splitting the heap into heaps of 7 and 1:
 player 1: 8 → 7+1
Player 2 now has three choices: splitting the 7-heap into 6 + 1, 5 + 2, or 4 + 3. In each of these cases, player 1 can ensure that on the next move he hands back to his opponent a heap of size 4 plus heaps of size 2 and smaller:
 player 2: 7+1   → 6+1+1        player 2: 7+1   → 5+2+1        player 2: 7+1   → 4+3+1
 player 1: 6+1+1 → 4+2+1+1      player 1: 5+2+1 → 4+1+2+1      player 1: 4+3+1 → 4+2+1+1
Now player 2 has to split the 4-heap into 3 + 1, and player 1 subsequently splits the 3-heap into 2 + 1:
 player 2: 4+2+1+1   → 3+1+2+1+1
 player 1: 3+1+2+1+1 → 2+1+1+2+1+1
 player 2 has no moves left and loses

== Mathematical theory ==

The game can be analysed using the [[Sprague–Grundy theorem]]. This requires the heap sizes in the game to be mapped onto equivalent [[Nim|nim heap sizes]]. This mapping is captured in the [[On-Line Encyclopedia of Integer Sequences]] as {{OEIS2C|id=A002188}}:

 Heap size           : 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 ...
 Equivalent Nim heap : 0  0  0  1  0  2  1  0  2  1  0  2  1  3  2  1  3  2  4  3  0 ...

Using this mapping, the strategy for playing the game [[Nim]] can also be used for Grundy's game. Whether the sequence of nim-values of Grundy's game ever becomes periodic is an unsolved problem. [[Elwyn Berlekamp]], [[John Horton Conway]] and [[Richard K. Guy|Richard Guy]] have conjectured&lt;ref&gt;E. Berlekamp, J. H. Conway, R. Guy. ''Winning Ways for your Mathematical Plays.'' Academic Press, 1982.&lt;/ref&gt; that the sequence does become periodic eventually, but despite the calculation of the first 2&lt;sup&gt;35&lt;/sup&gt; values by [[Achim Flammenkamp]], the question has not been resolved.

== See also ==

* [[Nim]]
* [[Sprague–Grundy theorem]]
* [[Wythoff's game]]
* [[Subtract a square]]

== References ==
&lt;references/&gt;

== External links ==
* [http://mathworld.wolfram.com/GrundysGame.html Grundy's game on MathWorld]
* [http://wwwhomes.uni-bielefeld.de/achim/grundy.html Sprague-Grundy values for Grundy's Game by A. Flammenkamp]

[[Category:Mathematical games]]
[[Category:Combinatorial game theory]]
[[Category:Recreational mathematics]]</text>
      <sha1>dyuk5lcl349c4d44o7rcd2hwxl3lq92</sha1>
    </revision>
  </page>
  <page>
    <title>Horner's method</title>
    <ns>0</ns>
    <id>14263</id>
    <revision>
      <id>870627453</id>
      <parentid>870159381</parentid>
      <timestamp>2018-11-26T01:29:18Z</timestamp>
      <contributor>
        <ip>2601:341:280:1400:5530:ADE5:6254:155F</ip>
      </contributor>
      <comment>Make the the subscript an exponent</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="38619">{{cleanup|reason = See [[Talk:Horner's method#This Article is about Two Different Algorithms]]|date=November 2018}}
In [[mathematics]], '''Horner's rule''' (also known as '''Horner scheme''' or '''Horner's method''')&lt;ref name="Cormen et al."&gt;{{harvnb|Cormen|Leiserson|Rivest|Stein|2009|pages=41, 900, 990}}.&lt;/ref&gt;&lt;ref name="HornerRule"&gt;{{MathWorld|urlname=HornersRule|title=Horner's Rule}}&lt;/ref&gt; is a way of expressing and evaluating [[polynomial]]s, which optimizes the needed number of arithmetic operations. 

More precisely Horner's rule consists of expressing the polynomial
:&lt;math&gt;p(x)=a_0+a_1x+a_2x^2 +\cdots + a_nx^n&lt;/math&gt;
as
:&lt;math&gt;p(x)=a_0+x(a_1 +x(a_2 +x(\cdots +x(a_{n-1} +xa_n)\cdots))).&lt;/math&gt;
This allows evaluating a polynomial of degree {{mvar|n}} with only {{math|''n'' – 1}} multiplications and {{math|''n'' – 1}} additions. This is optimal, since there are polynomials of degree {{mvar|n}} that cannot be evaluated with fewer arithmetic operations.{{cn|date=November 2018}}

'''Horner's method''' may also refer to the use of Horner's rule in the process of solving a [[polynomial equation]] with [[Newton's method]].&lt;ref name="HornerMethod"&gt;{{MathWorld|urlname=HornersMethod|title=Horner's Method}}&lt;/ref&gt; 

These methods are named after the British mathematician [[William George Horner]], although they were known before him by [[Paolo Ruffini]]&lt;ref name="Cajori"&gt;{{harvnb|Cajori|1911}}.&lt;/ref&gt; , six hundred years earlier, by the Chinese mathematician [[Qin Jiushao]]&lt;ref&gt;''It is obvious that this procedure is a Chinese invention'', in {{harvnb|Libbrecht|2005|p=178}}.&lt;/ref&gt; and seven hundred years earlier, by the Persian mathematician [[Sharaf al-Dīn al-Ṭūsī]].&lt;ref&gt;{{Cite web|url=http://www-groups.dcs.st-and.ac.uk/history/Biographies/Al-Tusi_Sharaf.html|title=Al-Tusi_Sharaf biography|website=www-groups.dcs.st-and.ac.uk|access-date=2018-03-17}}&lt;/ref&gt;

== Description of the algorithm ==

Given the polynomial

:&lt;math&gt;p(x) = \sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots + a_n x^n,&lt;/math&gt;

where &lt;math&gt;a_0, \ldots, a_n&lt;/math&gt; are real numbers, we wish to evaluate the polynomial at a specific value of &lt;math&gt;x&lt;/math&gt;, say &lt;math&gt;x_0&lt;/math&gt;.

To accomplish this, we define a new sequence of constants as follows:

:&lt;math&gt;\begin{align}
b_n &amp; := a_n \\
b_{n-1} &amp; := a_{n-1} + b_n x_0 \\
 &amp; ~~~ \vdots \\
b_0 &amp; := a_0 + b_1 x_0.
\end{align}&lt;/math&gt;

Then &lt;math&gt;b_0&lt;/math&gt; is the value of &lt;math&gt;p(x_0)&lt;/math&gt;.

To see why this works, note that the polynomial can be written in the form

:&lt;math&gt;p(x) = a_0 + x(a_1 + x(a_2 + \cdots + x(a_{n-1} + a_n x))). &lt;/math&gt;

Thus, by iteratively substituting the &lt;math&gt;b_i&lt;/math&gt; into the expression,
: &lt;math&gt;
\begin{align}
p(x_0) &amp; = a_0 + x_0(a_1 + x_0(a_2 + \cdots + x_0(a_{n-1} + b_n x_0))) \\
&amp; = a_0 + x_0(a_1 + x_0(a_2 + \cdots + x_0 b_{n-1})) \\
&amp; ~~ \vdots \\
&amp; = a_0 + x_0 b_1 \\
&amp; = b_0.
\end{align}
&lt;/math&gt;

== Examples ==

Evaluate &lt;math&gt;f(x)=2x^3-6x^2+2x-1&lt;/math&gt; for &lt;math&gt;x=3.&lt;/math&gt;

We use [[synthetic division]] as follows:

  ''x&lt;sub&gt;0&lt;/sub&gt;''│   ''x&lt;sup&gt;3&lt;/sup&gt;''    ''x&lt;sup&gt;2&lt;/sup&gt;''    ''x&lt;sup&gt;1&lt;/sup&gt;''    ''x&lt;sup&gt;0&lt;/sup&gt;''
  3 │   2    −6     2    −1
    │         6     0     6
    └────────────────────────
        2     0     2     5

The entries in the third row are the sum of those in the first two. Each entry in the second row is the product of the ''x''-value (3 in this example) with the third-row entry immediately to the left. The entries in the first row are the coefficients of the polynomial to be evaluated. Then the remainder of &lt;math&gt;f(x)&lt;/math&gt; on division by &lt;math&gt;x-3&lt;/math&gt; is 5.

But by the [[polynomial remainder theorem]], we know that the remainder is &lt;math&gt;f(3) &lt;/math&gt;. Thus &lt;math&gt;f(3) = 5&lt;/math&gt;

In this example, if &lt;math&gt;a_3 = 2, a_2 = -6, a_1 = 2, a_0 = -1&lt;/math&gt; we can see that &lt;math&gt;b_3 = 2, b_2 = 0, b_1 = 2, b_0 = 5 &lt;/math&gt;, the entries in the third row. So, synthetic division is based on Horner's method.

As a consequence of the polynomial remainder theorem, the entries in the third row are the coefficients of the second-degree polynomial, the quotient of &lt;math&gt;f(x)&lt;/math&gt; on division by &lt;math&gt; x-3 &lt;/math&gt;. 
The remainder is 5. This makes Horner's method useful for [[polynomial long division]].

Divide &lt;math&gt;x^3-6x^2+11x-6&lt;/math&gt; by &lt;math&gt;x-2&lt;/math&gt;:

  2 │   1    −6    11    −6
    │         2    −8     6
    └────────────────────────
        1    −4     3     0

The quotient is &lt;math&gt;x^2-4x+3&lt;/math&gt;.

Let &lt;math&gt;f_1(x)=4x^4-6x^3+3x-5&lt;/math&gt; and &lt;math&gt;f_2(x)=2x-1&lt;/math&gt;. Divide &lt;math&gt;f_1(x)&lt;/math&gt; by &lt;math&gt;f_2\,(x)&lt;/math&gt; using Horner's method.

   2 │  4    −6    0    3   │   −5
 ────┼──────────────────────┼───────
   1 │        2   −2   −1   │    1
     └──────────────────────┼───────
        2    −2   −1    1   │   −4

The third row is the sum of the first two rows, divided by 2. Each entry in the second row is the product of 1 with the third-row entry to the left. The answer is

:&lt;math&gt;\frac{f_1(x)}{f_2(x)}=2x^3-2x^2-x+1-\frac{4}{2x-1}.&lt;/math&gt;

===Floating-point multiplication and division===
{{main|multiplication algorithm#Shift and add}}

Horner's method is a fast, code-efficient method for multiplication and division of binary numbers on a [[microcontroller]] with no [[binary multiplier|hardware multiplier]].  One of the binary numbers to be multiplied is represented as a trivial polynomial, where (using the above notation) ''a''&lt;sub&gt;''i''&lt;/sub&gt; = 1, and ''x'' = 2.  Then, ''x'' (or ''x'' to some power) is repeatedly factored out.  In this [[binary numeral system]] (base 2), ''x'' = 2, so powers of 2 are repeatedly factored out.

====Example====
For example, to find the product of two numbers (0.15625) and ''m'':

:&lt;math&gt;
\begin{align}
(0.15625) m &amp; = (0.00101_b) m = ( 2^{-3} + 2^{-5}) m = (2^{-3})m + (2^{-5})m \\
 &amp; = 2^{-3} (m + (2^{-2})m) = 2^{-3} (m + 2^{-2} (m)).
\end{align}
&lt;/math&gt;

====Method====
To find the product of two binary numbers ''d'' and ''m'':
:1. A register holding the intermediate result is initialized to ''d''.
:2. Begin with the least significant (rightmost) non-zero bit in ''m''.
::2b. Count (to the left) the number of bit positions to the next most significant non-zero bit.  If there are no more-significant bits, then take the value of the current bit position.
::2c. Using that value, perform a left-shift operation by that number of bits on the register holding the intermediate result
:3. If all the non-zero bits were counted, then the intermediate result register now holds the final result.  Otherwise, add d to the intermediate result, and continue in step 2 with the next most significant bit in ''m''.

====Derivation====
In general, for a binary number with bit values (&lt;math&gt; d_3 d_2 d_1 d_0 &lt;/math&gt;) the product is
:&lt;math&gt; (d_3 2^3 + d_2 2^2 + d_1 2^1 + d_0 2^0)m = d_3 2^3 m + d_2 2^2 m + d_1 2^1 m + d_0 2^0 m. &lt;/math&gt;
At this stage in the algorithm, it is required that terms with zero-valued coefficients are dropped, so that only binary coefficients equal to one are counted, thus the problem of multiplication or [[division by zero]] is not an issue, despite this implication in the factored equation:

:&lt;math&gt; = d_0\left(m + 2 \frac{d_1}{d_0} \left(m + 2 \frac{d_2}{d_1} \left(m + 2 \frac{d_3}{d_2} (m)\right)\right)\right). &lt;/math&gt;

The denominators all equal one (or the term is absent), so this reduces to
:&lt;math&gt; = d_0(m + 2 {d_1} (m + 2 {d_2} (m + 2 {d_3} (m)))),&lt;/math&gt;
or equivalently (as consistent with the "method" described above)
:&lt;math&gt; = d_3(m + 2^{-1} {d_2} (m + 2^{-1}{d_1} (m + {d_0} (m)))). &lt;/math&gt;

In binary (base-2) math, multiplication by a power of 2 is merely a [[arithmetic shift|register shift]] operation.  Thus, multiplying by 2 is calculated in base-2 by an [[arithmetic shift]].  The factor (2&lt;sup&gt;−1&lt;/sup&gt;) is a right [[arithmetic shift]], a (0) results in no operation (since 2&lt;sup&gt;0&lt;/sup&gt; = 1 is the multiplicative [[identity element]]), and a (2&lt;sup&gt;1&lt;/sup&gt;) results in a left arithmetic shift.
The multiplication product can now be quickly calculated using only arithmetic shift operations, addition and subtraction.

The method is particularly fast on processors supporting a single-instruction shift-and-addition-accumulate.  Compared to a C floating-point library, Horner's method sacrifices some accuracy, however it is nominally 13 times faster (16 times faster when the "[[canonical signed digit]]" (CSD) form is used) and uses only 20% of the code space.&lt;ref&gt;{{harvnb|Kripasagar|2008|p=62}}.&lt;/ref&gt;

=== Polynomial root finding ===
Using Horner's method in combination with [[Newton's method]], it is possible to approximate the real roots of a polynomial. The algorithm works as follows. Given a polynomial &lt;math&gt;p_n(x)&lt;/math&gt; of degree &lt;math&gt;n&lt;/math&gt; with zeros &lt;math&gt; z_n &lt; z_{n-1} &lt; \cdots &lt; z_1,&lt;/math&gt; make some initial guess &lt;math&gt; x_0 &lt;/math&gt; such that &lt;math&gt; x_0 &gt; z_1 &lt;/math&gt;. Now iterate the following two steps:

1. Using [[Newton's method]], find the largest zero &lt;math&gt;z_1&lt;/math&gt; of &lt;math&gt;p_n(x)&lt;/math&gt; using the guess &lt;math&gt;x_0&lt;/math&gt;.

2. Using Horner's method, divide out &lt;math&gt;(x-z_1)&lt;/math&gt; to obtain &lt;math&gt;p_{n-1}&lt;/math&gt;. Return to step 1 but use the polynomial &lt;math&gt;p_{n-1}&lt;/math&gt; and the initial guess &lt;math&gt;z_1&lt;/math&gt;.

These two steps are repeated until all real zeros are found for the polynomial. If the approximated zeros are not precise enough, the obtained values can be used as initial guesses for Newton's method but using the full polynomial rather than the reduced polynomials.&lt;ref&gt;{{harvnb|Kress|1991|p=112}}.&lt;/ref&gt;

==== Example ====

[[File:HornerandNewton.gif|thumb|right|500px|Polynomial root finding using Horner's method]]

Consider the polynomial

: &lt;math&gt;
p_6(x) = (x-3)(x+3)(x+5)(x+8)(x-2)(x-7)
&lt;/math&gt;

which can be expanded to

: &lt;math&gt;
p_6(x) = x^6 + 4x^5 - 72x^4 -214x^3 + 1127x^2 + 1602x -5040.
&lt;/math&gt;

From the above we know that the largest root of this polynomial is 7 so we are able to make an initial guess of 8. Using Newton's method the first zero of 7 is found as shown in black in the figure to the right. Next &lt;math&gt;p(x)&lt;/math&gt; is divided by &lt;math&gt;(x-7)&lt;/math&gt; to obtain

: &lt;math&gt;
p_5(x) = x^5 + 11x^4 + 5x^3 - 179x^2 - 126x + 720
&lt;/math&gt;

which is drawn in red in the figure to the right. Newton's method is used to find the largest zero of this polynomial with an initial guess of 7. The largest zero of this polynomial which corresponds to the second largest zero of the original polynomial is found at 3 and is circled in red. The degree 5 polynomial is now divided by &lt;math&gt;(x-3)&lt;/math&gt; to obtain

: &lt;math&gt;
p_4(x) = x^4 + 14x^3 + 47x^2 - 38x - 240
&lt;/math&gt;

which is shown in yellow. The zero for this polynomial is found at 2 again using Newton's method and is circled in yellow. Horner's method is now used to obtain

: &lt;math&gt;
p_3(x) = x^3 + 16x^2 + 79x + 120
&lt;/math&gt;

which is shown in green and found to have a zero at&amp;nbsp;&amp;minus;3. This polynomial is further reduced to

: &lt;math&gt;
p_2(x) = x^2 + 13x + 40
&lt;/math&gt;

which is shown in blue and yields a zero of&amp;nbsp;&amp;minus;5. The final root of the original polynomial may be found by either using the final zero as an initial guess for Newton's method, or by reducing &lt;math&gt;p_2(x)&lt;/math&gt; and solving the linear equation. As can be seen, the expected roots of &amp;minus;8, &amp;minus;5, &amp;minus;3, 2, 3, and 7 were found.

==== Octave implementation ====
The following [[GNU Octave|Octave]] code was used in the example above to implement Horner's method.

&lt;source lang="octave"&gt;
function [y b] = horner(a,x)
  % Input a is the polynomial coefficient vector, x the value to be evaluated at.
  % The output y is the evaluated polynomial and b the divided coefficient vector.
  b(1) = a(1);
  for i = 2:length(a)
    b(i) = a(i)+x*b(i-1);
  end
  y = b(length(a));
  b = b(1:length(b)-1);
end
&lt;/source&gt;

==== Python implementation ====

The following [[Python (programming language)|Python]] code implements Horner's method.

&lt;source lang="python"&gt;
def horner(x, *polynomial):
    """Implement the Horner Scheme for evaluating a
    polynomial of coefficients *polynomial in x."""
    result = 0
    for coefficient in reversed(polynomial):
        result = result * x + coefficient
    return result
&lt;/source&gt;

==== C implementation ====

The following [[C (programming language)|C]] code implements Horner's method.
&lt;source lang="c"&gt;
double HornerEvaluate (double x, double * CoefficientsOfPolynomial, unsigned int DegreeOfPolynomial)
{
    /*
        We want to evaluate the polynomial in x, of coefficients CoefficientsOfPolynomial, using Horner's method.
        The result is stored in dbResult.
    */
    double dbResult = 0.0;
    int i;
    for(i = DegreeOfPolynomial; i &gt;= 0; i--)
    {
        dbResult = dbResult * x + CoefficientsOfPolynomial[i];
    }
    return dbResult;
}
&lt;/source&gt;

Here is a slightly optimized version using explicit fused [[Multiply–accumulate operation]], often execute faster than the above when running on a computer built with a processor supporting FMA instruction:

&lt;source lang="c"&gt;
// gcc -std=c11 -lm horner.c -o horner
#include &lt;math.h&gt;

double horner_fma(double x, const double *coeffs, size_t count)
{
    double result = 0.0;
    for (int idx = count-1; idx &gt;= 0; idx--)
        result = fma(result, x, coeffs[idx]);
    return result;
}
&lt;/source&gt;

====  C# implementation ====

The following C# code implements Horner's method.

&lt;source lang="c#"&gt;
public double HornerEvaluate(int[] numbers, double x)
{
	double result = 0;
	
	for(int i = numbers.Length - 1; i &gt;= 0; i--)
	{
		result = result * x + numbers[i];
	}
	
	return result;
}
&lt;/source&gt;

== Application ==

Horner's method can be used to convert between different positional [[numeral system]]s – in which case ''x'' is the base of the number system, and the ''a''&lt;sub&gt;''i''&lt;/sub&gt; coefficients are the digits of the base-''x'' representation of a given number – and can also be used if ''x'' is a [[matrix (math)|matrix]], in which case the gain in computational efficiency is even greater. In fact, when ''x'' is a matrix, further acceleration is possible which exploits the structure of [[matrix multiplication]], and only &lt;math&gt;\sqrt{n}&lt;/math&gt; instead of ''n'' multiplies are needed (at the expense of requiring more storage) using the 1973 method of Paterson and Stockmeyer.&lt;ref&gt;{{harvnb|Higham|2002|loc=Section 5.4}}.&lt;/ref&gt;

== Efficiency ==

Evaluation using the monomial form of a degree-''n'' polynomial requires at most ''n'' additions and (''n''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''n'')/2 multiplications, if powers are calculated by repeated multiplication and each monomial is evaluated individually.  (This can be reduced to ''n'' additions and 2''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 multiplications by evaluating the powers of ''x'' iteratively.)  If numerical data are represented in terms of digits (or bits), then the naive algorithm also entails storing approximately 2''n'' times the number of bits of ''x'' (the evaluated polynomial has approximate magnitude ''x&lt;sup&gt;n&lt;/sup&gt;'', and one must also store ''x&lt;sup&gt;n&lt;/sup&gt;'' itself).  By contrast, Horner's method requires only ''n'' additions and ''n'' multiplications, and its storage requirements are only ''n'' times the number of bits of ''x''. Alternatively, Horner's method can be computed with ''n'' [[fused multiply–add]]s.  Horner's method can also be extended to evaluate the first ''k'' derivatives of the polynomial with ''kn'' additions and multiplications.&lt;ref&gt;{{harvnb|Pankiewicz|1968}}.&lt;/ref&gt;

Horner's method is optimal, in the sense that any algorithm to evaluate an arbitrary polynomial must use at least as many operations. [[Alexander Ostrowski]] proved in 1954 that the number of additions required is minimal.&lt;ref&gt;{{harvnb|Ostrowski|1954}}.&lt;/ref&gt; [[Victor Pan]] proved in 1966 that the number of multiplications is minimal.&lt;ref&gt;{{harvnb|Pan|1966}}.&lt;/ref&gt; However, when ''x'' is a matrix, Horner's method is not optimal.{{Citation needed|date=September 2017}}

This assumes that the polynomial is evaluated in monomial form and no [[preconditioning]] of the representation is allowed, which makes sense if the polynomial is evaluated only once. However, if preconditioning is allowed and the polynomial is to be evaluated many times, then faster algorithms are possible. They involve a transformation of the representation of the polynomial. In general, a degree-''n'' polynomial can be evaluated using only {{floor|''n''/2}}+2 multiplications and ''n'' additions.&lt;ref&gt;{{harvnb|Knuth|1997}}.&lt;/ref&gt;

===Parallel evaluation===
{{also|Estrin's scheme}}
A disadvantage of Horner's rule is that all of the operations are [[data dependency|sequentially dependent]], so it is not possible to take advantage of [[instruction level parallelism]] on modern computers.  In most applications where the efficiency of polynomial evaluation matters, many low-order polynomials are evaluated simultaneously (for each pixel or polygon in computer graphics, or for each grid square in a numerical simulation), so it is not necessary to find parallelism within a single polynomial evaluation.

If, however, one is evaluating a single polynomial of very high order, it may be useful to break it up as follows:
:&lt;math&gt;\begin{align}
p(x) &amp; = \sum_{i=0}^n a_i x^i \\
     &amp; = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots + a_n x^n \\
     &amp; = \left( a_0 + a_2 x^2 + a_4 x^4 + \cdots\right) + \left(a_1 x + a_3 x^3 + a_5 x^5 + \cdots \right) \\
     &amp; = \left( a_0 + a_2 x^2 + a_4 x^4 + \cdots\right) + x \left(a_1 + a_3 x^2 + a_5 x^4 + \cdots \right) \\
     &amp; = \sum_{i=0}^{\lfloor n/2 \rfloor} a_{2i} x^{2i} + x \sum_{i=0}^{\lfloor n/2 \rfloor} a_{2i+1} x^{2i} \\
     &amp; = p_0(x^2) + x p_1(x^2). \\
\end{align}&lt;/math&gt;

More generally, the summation can be broken into ''k'' parts:
:&lt;math&gt;\begin{align}
p(x) &amp; = \sum_{i=0}^n a_i x^i \\
     &amp; = \sum_{j=0}^{k-1} x^j \sum_{i=0}^{\lfloor n/k \rfloor} a_{ki+j} x^{ki} \\
     &amp; = \sum_{j=0}^{k-1} x^j p_j(x^k) \\
\end{align}&lt;/math&gt;
where the inner summations may be evaluated using separate parallel instances of Horner's method.  This requires slightly more operations than the basic Horner's method, but allows ''k''-way [[SIMD]] execution of most of them.

== Divided difference of a polynomial ==

Horner's method can be modified to compute the divided difference &lt;math&gt;(p(y) - p(x))/(y - x).&lt;/math&gt; Given the polynomial (as before)

:&lt;math&gt;p(x) = \sum_{i=0}^n a_i x^i = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots + a_n x^n,&lt;/math&gt;

proceed as follows&lt;ref name="Fateman &amp; Kahan"&gt;{{harvnb|Fateman|Kahan|2000}}&lt;/ref&gt;

:&lt;math&gt;\begin{align}
b_n &amp; = a_n,                 &amp;\quad d_n &amp;= b_n, \\
b_{n-1} &amp; = a_{n-1} + b_n x, &amp;\quad d_{n-1} &amp;= b_{n-1} + d_n y, \\
&amp; {}\  \  \vdots             &amp;\quad &amp;  {}\ \ \vdots\\
b_1 &amp; = a_1 + b_2 x,         &amp;\quad d_1 &amp;= b_1 + d_2 y,\\
b_0 &amp; = a_0 + b_1 x.
\end{align}&lt;/math&gt;

At completion, we have
:&lt;math&gt;\begin{align}
p(x) &amp;= b_0, \\
\frac{p(y) - p(x)}{y - x} &amp;= d_1, \\
p(y) &amp;= b_0 + (y - x) d_1.
\end{align}&lt;/math&gt;
This computation of the divided difference is subject to less
round-off error than evaluating &lt;math&gt;p(x)&lt;/math&gt; and &lt;math&gt;p(y)&lt;/math&gt; separately, particularly when
&lt;math&gt; x \approx y&lt;/math&gt;.  Substituting
&lt;math&gt;y = x&lt;/math&gt; in this method gives &lt;math&gt;d_1 = p'(x)&lt;/math&gt;, the derivative of &lt;math&gt;p(x)&lt;/math&gt;.

== History ==

[[File:Qingjiushaoquad1.GIF|thumb|right|200px|Qin Jiushao's algorithm for solving the quadratic polynomial equation&lt;math&gt;-x^4+763200x^2-40642560000=0&lt;/math&gt;&lt;br&gt;result: x=840&lt;ref&gt;{{harvnb|Libbrecht|2005|pages=181&amp;ndash;191}}.&lt;/ref&gt;]]
Horner's paper entitled "A new method of solving numerical equations of all orders, by continuous approximation"&lt;ref name="Horner"&gt;{{harvnb|Horner|1819}}.&lt;/ref&gt; was read before the Royal Society of London, at its meeting on July 1, 1819, with [[Davies Gilbert]], Vice-President and Treasurer, in the chair; this was the final [http://hdl.handle.net/2027/mdp.39015014105277?urlappend=%3Bseq=158 meeting] of the session before the Society adjorned for its Summer recess. When a sequel was read before the Society in 1823, it was again at the final meeting of the session. On both occasions, papers by [[James Ivory (mathematician)|James Ivory]], FRS, were also read. In 1819, it was Horner's paper that got through to publication in the "Philosophical Transactions".&lt;ref name="Horner" /&gt; later in the year, Ivory's paper falling by the way, despite Ivory being a Fellow; in 1823, when a total of ten papers were read, fortunes as regards publication, were reversed. But Gilbert, who had strong connections with the West of England and may have had social contact with Horner, resident as Horner was in Bristol and Bath, published his own [http://turing.une.edu.au/~ernie/Horner/Gilbert1823QJSLA.pdf survey] of Horner-type methods earlier in 1823.

Horner's paper in Part II of ''Philosophical Transactions of the Royal Society of London'' for 1819 was warmly and expansively welcomed by a [http://turing.une.edu.au/~ernie/Horner/Horner1820MonthlyRev91-4.pdf reviewer] in the issue of ''The Monthly Review: or, Literary Journal'' for April, 1820; in comparison, a technical paper by [[Charles Babbage]] is dismissed curtly in this review. However, the reviewer noted that another, similar method had also recently been published by the architect and mathematical expositor, Peter Nicholson. This theme is developed in a further [http://turing.une.edu.au/~ernie/Horner/Horner1820MonthlyRev93-12.pdf review] of some of Nicholson's books in the issue of ''The Monthly Review'' for December, 1820, which in turn ends with notice of the appearance of a booklet by Theophilus Holdred, from whom Nicholson acknowledges he obtained the gist of his approach in the first place, although claiming to have improved upon it. The sequence of reviews is concluded in the issue of ''The Monthly Review'' for September, 1821, with the [http://turing.une.edu.au/~ernie/Horner/Horner1821MonthlyRev96-9.pdf reviewer] concluding that whereas Holdred was the first person to discover a direct and general practical solution of numerical equations, he had not reduced it to its simplest form by the time of Horner's publication, and saying that had Holdred published forty years earlier when he first discovered his method, his contribution could be more easily recognized. The reviewer is exceptionally well-informed, even having sighted Horner's preparatory correspondence with [[Peter Barlow (mathematician)|Peter Barlow]] in 1818, seeking work of [[François Budan de Boislaurent|Budan]]. The Bodlean Library, Oxford has the Editor's annotated copy of ''The Monthly Review'' from which it is clear that the most active reviewer in mathematics in 1814 and 1815 (the last years for which this information has been published) was none other than Peter Barlow,one of the foremost specialists on approximation theory of the period, suggesting that it was Barlow, who wrote this sequence of reviews. As it also happened, Henry Atkinson, of Newcastle, devised a similar approximation scheme in 1809; he had consulted his fellow [[Geordie]], [[Charles Hutton]], another specialist and a senior colleague of Barlow at the Royal Military Academy, Woolwich, only to be advised that, while his work was publishable, it was unlikely to have much impact. J. R. Young, writing in the mid-1830s, concluded that Holdred's first method replicated Atkinson's while his improved method was only added to Holdred's booklet some months after its first appearance in 1820, when Horner's paper was already in circulation.

The feature of Horner's writing that most distinguishes it from his English contemporaries is the way he draws on the Continental literature, notably the work of [[Louis François Antoine Arbogast|Arbogast]]. The advocacy, as well as the detraction, of Horner's Method has this as an unspoken subtext. Quite how he gained that familiarity has not been determined. Horner is known to have made a close reading of John Bonneycastle's book on algebra. Bonneycastle recognizes that Arbogast has the general, combinatorial expression for the reversion of series, a project going back at least to Newton. But Bonneycastle's main purpose in mentioning Arbogast is not to praise him, but to observe that Arbogast's notation is incompatible with the approach he adopts. The gap in Horner's reading was the work of [[Paolo Ruffini]], except that, as far as awareness of Ruffini goes, citations of Ruffini's work by authors, including medical authors, in ''Philosophical Transactions'' speak volumes: there are none - Ruffini's [http://hdl.handle.net/2027/njp.32101013501372?urlappend=%3Bseq=695 name] only appears in 1814, recording a work he donated to the Royal Society. Ruffini might have done better if his work had appeared in French, as had [[Malfatti's problem|Malfatti's Problem]] in the reformulation of [[Gergonne|Joseph Diaz Gergonne]], or had he written in French, as had [[:it:Antonio Cagnoli|Antonio Cagnoli]], a source quoted by Bonneycastle on series reversion (today, Cagnoli is in the Italian Wikipedia, as shown, but has yet to make it into either French or English).

Fuller&lt;ref&gt;{{harvnb|Fuller|1999|pages=29–51}}.&lt;/ref&gt; showed that the method in Horner's 1819 paper differs from what afterwards became known as 'Horner's method' and that in consequence the priority for this method should go to Holdred (1920). This view may be compared with the remarks concerning the works of Horner and Holdred in the previous paragraph. Fuller also takes aim at [[Augustus De Morgan]]. Precocious though Augustus de Morgan was, he was not the reviewer for ''The Monthly Review'', while several others - [[Thomas Stephens Davies]], J. R. Young, Stephen Fenwick, T. T. Wilkinson - wrote Horner firmly into their records, not least Horner himself, as he published extensively up until the year of his death in 1837. His paper in 1819 was one that would have been difficult to miss. In contrast, the only other mathematical sighting of Holdred is a single named contribution to ''The Gentleman's Mathematical Companion'', an answer to a problem.

It is questionable to what extent it was De Morgan's advocacy of Horner's priority in discovery&lt;ref name="Cajori" /&gt;&lt;ref name="St Andrews" /&gt; that led to "Horner's method" being so called in textbooks, but it is true that those suggesting this tend themselves to know of Horner largely through intermediaries, of whom De Morgan made himself a prime example. However, this method ''qua'' method was known long before Horner. In reverse chronological order, Horner's method was already known to:

* [[Paolo Ruffini]] in 1809 (see [[Ruffini's rule]])&lt;ref name="Cajori" /&gt;&lt;ref name="St Andrews"&gt;{{MacTutor Biography|id=Horner}}&lt;/ref&gt;
* [[Isaac Newton]] in 1669 (but precise reference needed)
* the [[Chinese mathematics|Chinese mathematician]] [[Zhu Shijie]] in the 14th century&lt;ref name="St Andrews" /&gt;
* the [[Chinese mathematics|Chinese mathematician]] [[Qin Jiushao]] in his ''[[Mathematical Treatise in Nine Sections]]'' in the 13th century
* the [[Persian people|Persian]] [[Islamic mathematics|mathematician]] [[Sharaf al-Dīn al-Tūsī]] in the 12th century (the first to use that method in a general case of cubic equation)&lt;ref&gt;{{harvnb|Berggren|1990|pages = 304–309}}.&lt;/ref&gt;
* the Chinese mathematician [[Jia Xian]] in the 11th century ([[Song dynasty]])
* ''[[The Nine Chapters on the Mathematical Art]]'', a Chinese work of the [[Han Dynasty]] (202 BC &amp;ndash; 220 AD) edited by [[Liu Hui]] (fl. 3rd century).&lt;ref&gt;{{harvnb|Temple|1986|p=142}}.&lt;/ref&gt;

However, this observation on its own masks significant differences in conception and also, as noted with Ruffini's work, issues of accessibility.

[[Qin Jiushao]], in his ''Shu Shu Jiu Zhang'' (''[[Mathematical Treatise in Nine Sections]]''; 1247), presents a portfolio of methods of Horner-type for solving polynomial equations, which was based on earlier works of the 11th century Song dynasty mathematician [[Jia Xian]]; for example, one method is specifically suited to bi-quintics, of which Qin gives an instance, in keeping with the then Chinese custom of case studies. The first person writing in English to note the connection with Horner's method was [[Alexander Wylie (missionary)|Alexander Wylie]], writing in ''The North China Herald'' in 1852; perhaps conflating and misconstruing different Chinese phrases, Wylie calls the method ''Harmoniously Alternating Evolution'' (which does not agree with his Chinese, ''linglong kaifang'', not that at that date he uses [[pinyin]]), working the case of one of Qin's quartics and giving, for comparison, the working with Horner's method. [[Yoshio Mikami]] in ''Development of Mathematics in China and Japan'' published in Leipzig in 1913, gave a detailed description of Qin's method, using the quartic illustrated to the above right in a worked example; he wrote: "who can deny the fact of Horner's illustrious process being used in China at least nearly six long centuries earlier than in Europe ... We of course don't intend in any way to ascribe Horner's invention to a Chinese origin, but the lapse of time sufficiently makes it not altogether impossible that the Europeans could have known of the Chinese method in a direct or indirect way.".&lt;ref&gt;{{harvnb|Mikami|1913|p=77}}.&lt;/ref&gt; However, as Mikami is also aware, it was ''not altogether impossible'' that a related work, ''Si Yuan Yu Jian'' (''Jade Mirror of the Four Unknowns; 1303)'' by [[Zhu Shijie]] might make the shorter journey across to Japan, but seemingly it never did, although another work of Zhu, ''Suan Xue Qi Meng'', had a seminal influence on the development of traditional mathematics in the Edo period, starting in the mid-1600s. [[Ulrich Libbrecht]] (at the time teaching in school, but subsequently a professor of comparative philosophy) gave a detailed description in his doctoral thesis of Qin's method, he concluded: ''It is obvious that this procedure is a Chinese invention....the method was not known in India''. He said, Fibonacci probably learned of it from Arabs, who perhaps borrowed from the Chinese.&lt;ref&gt;{{harvnb|Libbrecht|2005|p=208}}.&lt;/ref&gt; Here, the problems is that there is no more evidence for this speculation than there is of the method being known in India. Of course, the extraction of square and cube roots along similar lines is already discussed by [[Liu Hui]] in connection with Problems IV.16 and 22 in ''Jiu Zhang Suan Shu'', while [[Wang Xiaotong]] in the 7th century supposes his readers can solve cubics by an approximation method described in his book [[Jigu Suanjing]].

== See also ==

*[[Clenshaw algorithm]] to evaluate polynomials in [[Chebyshev form]]
*[[De Boor's algorithm]] to evaluate [[spline curve|splines]] in [[B-spline]] form
*[[De Casteljau's algorithm]] to evaluate polynomials in [[Bézier form]]
*[[Estrin's scheme]] to facilitate parallelization on modern computer architectures
*[[Lill's method]] to approximate roots graphically
*[[Ruffini's rule]] to divide a polynomial by a binomial of the form x − r

== Notes ==
{{Reflist}}

== References ==

*{{cite journal
 | last = Berggren
 | first = J. L.
 | year = 1990
 | title = Innovation and Tradition in Sharaf al-Din al-Tusi's Muadalat
 | journal = Journal of the American Oriental Society
 | volume = 110
 | issue = 2
 | doi = 10.2307/604533
 | ref = harv
 | page=304
}}
*{{cite journal
 | last = Cajori
 | first = Florian
 | author-link = Florian Cajori
 | title = Horner's method of approximation anticipated by Ruffini
 | journal = Bulletin of the American Mathematical Society
 | volume = 17
 | number = 8
 | pages = 409&amp;ndash;414
 | year = 1911
 | url = http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.bams/1183421253
 | ref = harv
 | doi = 10.1090/s0002-9904-1911-02072-9
}} Read before the Southwestern Section of the American Mathematical Society on November 26, 1910.
*{{cite book
 | last1 = Cormen
 | first1 = Thomas H.
 | author1-link = Thomas H. Cormen
 | last2 = Leiserson
 | first2 = Charles E.
 | author2-link = Charles E. Leiserson
 | last3 = Rivest
 | first3 = Ronald L.
 | author3-link = Ron Rivest
 | last4 = Stein10.1016/0315-0860(81)90069-0
 | first4 = Clifford
 | author4-link = Clifford Stein
 | title = Introduction to Algorithms
 | edition = 3rd
 | year = 2009
 | publisher = MIT Press
 | ref = harv
}}
*{{cite report
 | last1 = Fateman
 | first1 = R. J.
 | authorlink1 = Richard Fateman
 | last2 = Kahan
 | first2 = W.
 | authorlink2 = William Kahan
 | title = Improving exact integrals from symbolic algebra systems
 | series = PAM
 | number = 386
 | year = 2000
 | institution = Center for Pure and Applied Mathematics
 | location = University of California, Berkeley
 | url = https://people.eecs.berkeley.edu/~fateman/papers/nform.pdf
 | ref = harv
}}
*{{cite journal
 | last = Fuller
 | first = A. T.
 | title = Horner versus Holdred: An Episode in the History of Root Computation
 | journal = Historia Mathematica
 | volume = 26
 | year = 1999
 | ref = harv
 | doi = 10.1006/hmat.1998.2214
 | pages=29–51
}}
*{{cite book
 | last = Higham
 | first = Nicholas
 | year = 2002
 | title = Accuracy and Stability of Numerical Algorithms
 | publisher = SIAM
 | isbn = 0-89871-521-0
 | ref = harv
}}
*{{cite book
 | last = Holdred
 | first = T.
 | year = 1820
 | url = http://turing.une.edu.au/~ernie/Horner/Holdred1820.pdf
 | title = A New Method of Solving Equations with Ease and Expedition; by which the True Value of the Unknown Quantity is Found Without Previous Reduction. With a Supplement, Containing Two Other Methods of Solving Equations, Derived from the Same Principle
 | publisher = Richard Watts
 | ref = harv
}}
*: Holdred's method is in the supplement following page numbered 45 (which is the 52nd page of the pdf version).
*{{cite journal|last = Horner|first = William George|author-link = William George Horner|date = July 1819|year=|title = A new method of solving numerical equations of all orders, by continuous approximation|url=https://www.ece.cmu.edu/~ece447/s15/lib/exe/fetch.php?media=horner-1819.pdf|journal = Philosophical Transactions|publisher = Royal Society of London|volume=|pages = pp.&amp;nbsp;308&amp;ndash;335|jstor=107508|ref = harv|via=}}
*: Directly available online via the link, but also reprinted with appraisal in D.E. Smith: ''A Source Book in Mathematics'', McGraw-Hill, 1929; Dover reprint, 2 vols, 1959.
*{{cite book
 | last = Knuth
 | first = Donald
 | author-link = Donald Knuth
 | title = The Art of Computer Programming
 | volume = Vol. 2: Seminumerical Algorithms
 | edition = 3rd
 | year = 1997
 | publisher = Addison-Wesley
 | isbn = 0-201-89684-2
 | pages = 486&amp;ndash;488 in section 4.6.4
 | ref = harv
}}
*{{cite book
 | last = Kress
 | first = Rainer
 | title = Numerical Analysis
 | publisher = Springer
 | year = 1991
 | ref = harv
}}
*{{cite journal
 | last = Kripasagar 
 | first =  Venkat
 | title = Efficient Micro Mathematics &amp;ndash; Multiplication and Division Techniques for MCUs
 | journal = Circuit Cellar magazine
 | issue = 212
 | date = March 2008
 | ref = harv
}}
*{{cite book
 | last = Libbrecht
 | first = Ulrich
 | title = Chinese Mathematics in the Thirteenth Century
 | chapter = Chapter 13
 | edition = 2nd
 | year = 2005
 | publisher = Dover
 | isbn = 0-486-44619-0
 | ref = harv
 | url = http://store.doverpublications.com/0486446190.html
}}
*{{cite book
 | last = Mikami
 | first = Yoshio
 | title = The Development of Mathematics in China and Japan
 | chapter = Chapter 11. Ch'in Chiu-Shao
 | edition = 1st
 | year = 1913
 | publisher = Chelsea Publishing Co reprint
 | pages = 74–77
 | url = https://archive.org/stream/treatiseindynami033561mbp#page/n89/mode/2up
 | ref = harv
}} &lt;!-- Yes, really! It looks as though the link is taking you to a completely different work, but you end up at Mikami's book, as you find on checking the specified pages. --&gt;
*{{cite book
 | last = Ostrowski
 | first = Alexander M.
 | year = 1954
 | chapter = On two problems in abstract algebra connected with Horner's rule
 | title = Studies in Mathematics and Mechanics presented to Richard von Mises
 | pages = 40–48
 | publisher = Academic Press
 | isbn = 978-1-4832-3272-0
 | url = http://www.sciencedirect.com/science/book/9781483232720
 | ref = harv
}}
*{{cite journal
 | last = Pan
 | first = Y. Ja
 | year = 1966
 | title = On means of calculating values of polynomials
 | journal = Russian Math. Surveys
 | volume = 21
 | pages = 105–136
 | doi = 10.1070/rm1966v021n01abeh004147
 | ref = harv
}}
*{{cite journal
 | last = Pankiewicz
 | first = W.
 | url = http://portal.acm.org/citation.cfm?doid=364063.364089
 | title = Algorithm 337: calculation of a polynomial and its derivative values by Horner scheme
 | journal = [[Communications of the ACM]]
 | volume = 11
 | issue = 9
 | year = 1968
 | page = 633
 | publisher = ACM
 | ref = harv
 | doi=10.1145/364063.364089
}}
*{{cite book
 | last = Spiegel
 | first = Murray R.
 | title = Schaum's Outline of Theory and Problems of College Algebra
 | year = 1956
 | publisher = McGraw-Hill
 | ref = harv
}}
*{{cite book
 | last = Temple
 | first = Robert
 | year = 1986
 | title = The Genius of China: 3,000 Years of Science, Discovery, and Invention
 | publisher = Simon and Schuster
 | isbn = 0-671-62028-2
 | ref = harv
}}
* {{cite book
 | last1 = Whittaker
 | first1 = E.T.
 | author1-link = E._T._Whittaker
 | last2 = Robinson
 | first2 = G.
 | title = The Calculus of Observations
 | location = London
 | year = 1924
 | publisher = Blackie
 | url = https://archive.org/stream/calculusofobserv031400mbp#page/n119/mode/2up/search/100
 | ref = harv
}}
* {{cite book
 | last = Wylie
 | first = Alexander
 | title = Chinese Researches
 | chapter = Jottings on the Science of Chinese Arithmetic
 | year = 1897
 | pages = 159–194
 | location = Shanghai
 | url = https://archive.org/details/chineseresearche00wyliuoft
 | ref = harv
}}
*: Reprinted from issues of ''The North China Herald'' (1852).

== External links ==
* {{springer|title=Horner scheme|id=p/h048030}}
* Qiu Jin-Shao, [http://turing.une.edu.au/~ernie/Chinese/SSJZ.pdf Shu Shu Jiu Zhang] (Cong Shu Ji Cheng ed.)

{{DEFAULTSORT:Horner Scheme}}
[[Category:Algebra]]
[[Category:Polynomials]]
[[Category:Numerical analysis]]
[[Category:Articles with example Python code]]
[[Category:Articles with example MATLAB/Octave code]]
[[Category:Articles with example C code]]</text>
      <sha1>prl78e26sovcsgp64dzl1rpovaltqs8</sha1>
    </revision>
  </page>
  <page>
    <title>Igusa variety</title>
    <ns>0</ns>
    <id>37466657</id>
    <revision>
      <id>752821577</id>
      <parentid>747526832</parentid>
      <timestamp>2016-12-03T15:17:03Z</timestamp>
      <contributor>
        <ip>2.24.120.146</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1296">In [[mathematics]], an '''Igusa curve''' is (roughly) a coarse [[moduli space]] of [[elliptic curve]]s in characteristic ''p'' with a level ''p'' Igusa structure, where an '''Igusa structure''' on an elliptic curve ''E'' is roughly a point of order ''p'' of ''E''&lt;sup&gt;(''p'')&lt;/sup&gt; generating the kernel of ''V'':''E''&lt;sup&gt;(''p'')&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;''E''.  An '''Igusa variety''' is a higher-dimensional analogue of an Igusa curve. Igusa curves were studied by {{harvs|txt|last=Igusa|authorlink=Jun-Ichi Igusa|year=1968}} and Igusa varieties were introduced by {{harvtxt|Harris|Taylor|2001}}.

==References==

*{{Citation | last1=Harris | first1=Michael | last2=Taylor | first2=Richard | title=The geometry and cohomology of some simple Shimura varieties | url=https://books.google.com/books?id=sigBbO69hvMC | publisher=[[Princeton University Press]] | series=Annals of Mathematics Studies | isbn=978-0-691-09090-0 |mr=1876802 | year=2001 | volume=151}}
*{{Citation | last1=Igusa | first1=Jun-ichi | title=On the algebraic theory of elliptic modular functions | doi=10.4099/jmath.20.96 |mr=0240103 | year=1968 | journal=Journal of the Mathematical Society of Japan | issn=0025-5645 | volume=20 | pages=96–106}}

[[Category:Algebraic geometry]]
[[Category:Elliptic curves]]

{{numtheory-stub}}</text>
      <sha1>0v3vw6h2c83eoxrebvugxdmoyswi73l</sha1>
    </revision>
  </page>
  <page>
    <title>Initial algebra</title>
    <ns>0</ns>
    <id>4116488</id>
    <revision>
      <id>868762164</id>
      <parentid>840936969</parentid>
      <timestamp>2018-11-14T08:05:37Z</timestamp>
      <contributor>
        <username>DesolateReality</username>
        <id>4591330</id>
      </contributor>
      <comment>/* Final coalgebra */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8582">{{Refimprove|date=December 2017}}

In [[mathematics]], an '''initial algebra''' is an [[initial object]] in the [[F-algebra|category of &lt;math&gt;F&lt;/math&gt;-algebras]] for a given [[endofunctor]] &lt;math&gt;F&lt;/math&gt;. This initiality provides a general framework for [[mathematical induction|induction]] and [[recursion]]. 

For instance, consider the endofunctor &lt;math&gt;1+(-)&lt;/math&gt; on the category of sets, where &lt;math&gt;1&lt;/math&gt; is the one-point (singleton) set, the terminal object in the category. An algebra for this endofunctor is a set &lt;math&gt;X&lt;/math&gt; (called the ''carrier'' of the algebra) together with a point &lt;math&gt;x\in X&lt;/math&gt; and a function &lt;math&gt;X\to X&lt;/math&gt;. The set of [[natural number]]s is the carrier of the initial such algebra: the point is zero and the function is the successor map. 

For a second example, consider the endofunctor &lt;math&gt;1+\mathbf{N}\times(-)&lt;/math&gt; on the category of sets, where &lt;math&gt;\mathbf{N}&lt;/math&gt; is the set of natural numbers. An algebra for this endofunctor is a set &lt;math&gt;X&lt;/Math&gt; together with a point &lt;math&gt;x\in X&lt;/math&gt; and a function &lt;math&gt;\mathbf{N}\times X\to X&lt;/math&gt;. The set of finite [[List (computing)|list]]s of natural numbers is the initial such algebra. The point is the empty list, and the function is [[cons]], taking a number and a finite list, and returning a new finite list with the number at the head.

In categories with binary coproducts, the definitions just given are equivalent to the usual definitions of a [[natural number object]] and a [[list object]], respectively.

==Final coalgebra==
Dually, a '''final coalgebra''' is a [[terminal object]] in the [[F-coalgebra|category of &lt;math&gt;F&lt;/math&gt;-coalgebras]]. The finality provides a general framework for [[coinduction]] and [[corecursion]].

For example, using the same functor &lt;math&gt;1+(-)&lt;/math&gt; as before, a coalgebra is a set &lt;math&gt;X&lt;/math&gt; together with a [[truth-value]]d test function &lt;math&gt;p\colon X \to 2&lt;/math&gt; and a [[partial function]] &lt;math&gt;f\colon X \to X&lt;/math&gt; whose [[Domain of a function|domain]] is formed by those &lt;math&gt;x \in X&lt;/math&gt; for which &lt;math&gt;p(x) = 0&lt;/math&gt;. The set &lt;math&gt;\mathbf{N} \cup \{\omega\}&lt;/math&gt; consisting of the natural numbers extended with a new element &lt;math&gt;\omega&lt;/math&gt; is the carrier of the final coalgebra in the category, where &lt;math&gt;p&lt;/math&gt; is the test for zero: &lt;math&gt;p(0)=1&lt;/math&gt; and &lt;math&gt;p(n+1) = p(\omega) = 0&lt;/math&gt;, and &lt;math&gt;f&lt;/math&gt; is the predecessor function (the [[Inverse function|inverse]] of the successor function) on the positive naturals, but acts like the [[Identity function|identity]] on the new element &lt;math&gt;\omega&lt;/math&gt;: &lt;math&gt;f(n+1) = n&lt;/math&gt;, &lt;math&gt;f(\omega) = \omega&lt;/math&gt;. This set &lt;math&gt;\mathbf{N} \cup \{\omega\}&lt;/math&gt; that is the carrier of the final coalgebra of &lt;math&gt;1+(-)&lt;/math&gt; is known as the set of [[conatural numbers]].

For a second example, consider the same functor &lt;math&gt;1 + \mathbf{N}\times(\mathord{-})&lt;/math&gt; as before. In this case the carrier of the final coalgebra consists of all lists of natural numbers, finite as well as [[Infinite list|infinite]]. The operations are a test function testing whether a list is empty, and a deconstruction function defined on nonempty lists returning a pair consisting of the head and the tail of the input list.

== Theorems ==
* Initial algebras are minimal (i.e., have no proper subalgebra).
* Final coalgebras are [[Simple algebra|simple]] (i.e., have no proper quotients).

== Example ==

Consider the endofunctor &lt;math&gt;F: \mathbf{Set} \to \mathbf{Set}&lt;/math&gt; sending &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;1+X&lt;/math&gt;. Define
:&lt;math displaystyle="block"&gt;
\begin{align}
  \operatorname{zero} \colon 1 &amp;\longrightarrow\mathbf{N} \\
  * &amp;\longmapsto 0
\end{align}
&lt;/math&gt; 
and
:&lt;math displaystyle="block"&gt;
\begin{align}
  \operatorname{succ}\colon \mathbf{N}&amp;\longrightarrow\mathbf{N} \\
  n &amp;\longmapsto n + 1.
\end{align}
&lt;/math&gt;
Then the set &lt;math&gt;\mathbf{N}&lt;/math&gt; of [[natural number]]s together with the function &lt;math&gt;[\operatorname{zero},\operatorname{succ}]\colon 1+\mathbf{N} \to \mathbf{N}&lt;/math&gt; is an initial &lt;math&gt;F&lt;/math&gt;-algebra. The initiality (the [[universal property]] for this case) is not hard to establish; the unique [[homomorphism]] to an arbitrary &lt;math&gt;F&lt;/math&gt;-algebra &lt;math&gt;(A, [e,f])&lt;/math&gt;, for &lt;math&gt;e\colon 1 \to A&lt;/math&gt; an element of &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;f\colon A \to A&lt;/math&gt; a [[function (mathematics)|function]] on &lt;math&gt;A&lt;/math&gt;, is the function sending the natural number &lt;math&gt;n&lt;/math&gt; to &lt;math&gt;f^n(e)&lt;/math&gt;, that is, &lt;math&gt;f(f(\dots(f(e))\dots))&lt;/math&gt;, the &lt;math&gt;n&lt;/math&gt;-fold application of &lt;math&gt;f&lt;/math&gt; to &lt;math&gt;e&lt;/math&gt;.

== Use in computer science ==

Various finite [[data structures]] used in [[Mathematical programming|programming]], such as [[List (computing)|list]]s and [[tree]]s, can be obtained as initial algebras of specific endofunctors.
While there may be several initial algebras for a given endofunctor, they are [[unique (mathematics)|unique]] [[up to]] [[isomorphism]], which informally means that the "observable" properties of a data structure can be adequately captured by defining it as an initial algebra.

To obtain the [[datatype|type]] &lt;math&gt;\mathrm{List}(A)&lt;/math&gt; of lists whose elements are members of set &lt;math&gt;A&lt;/math&gt;, consider that the list-forming operations are:

*&lt;math&gt;\mathrm{nil}\colon 1 \to \mathrm{List}(A)&lt;/math&gt;
*&lt;math&gt;\mathrm{cons}\colon A \times \mathrm{List}(A) \to \mathrm{List}(A)&lt;/math&gt;

Combined into one function, they give:

*&lt;math&gt;[\mathrm{nil},\mathrm{cons}]\colon (1 + A \times \mathrm{List}(A))\to \mathrm{List}(A)&lt;/math&gt;,

which makes this an &lt;math&gt;F&lt;/math&gt;-algebra for the endofunctor &lt;math&gt;F&lt;/math&gt; sending &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;1+(A\times X)&lt;/math&gt;. It is, in fact, ''the'' initial &lt;math&gt;F&lt;/math&gt;-algebra. Initiality is established by the function known as ''[[Fold (higher-order function)|foldr]]'' in [[functional programming|functional]] [[programming language]]s such as [[Haskell (programming language)|Haskell]] and [[ML programming language|ML]].

Likewise, [[binary tree]]s with elements at the leaves can be obtained as the initial algebra

*&lt;math&gt;[\mathrm{tip},\mathrm{join}]\colon A + (\mathrm{Tree}(A) \times \mathrm{Tree}(A)) \to \mathrm{Tree}(A)&lt;/math&gt;.

Types obtained this way are known as [[algebraic data type]]s.

Types defined by using [[least fixed point]] construct with functor &lt;math&gt;F&lt;/math&gt; can be regarded as an initial [[F-algebra|&lt;math&gt;F&lt;/math&gt;-algebra]], provided that [[parametricity]] holds for the type.&lt;ref name=free-rectypes&gt;Philip Wadler: [http://homepages.inf.ed.ac.uk/wadler/papers/free-rectypes/free-rectypes.txt Recursive types for free!] University of Glasgow, July 1998. Draft.&lt;/ref&gt;

In a [[Duality (mathematics)|dual]] way, similar relationship exists between notions of [[greatest fixed point]] and terminal [[F-coalgebra]], with applications to [[coinductive]] types.  These can be used for allowing [[Actual infinity|potentially infinite]] objects while maintaining [[Normalization property (lambda-calculus)|strong normalization property]].&lt;ref name=free-rectypes/&gt; In the strongly normalizing [[Charity (programming language)|Charity]] programming language (i.e. each program terminates), coinductive data types can be used achieving surprising results, e.g. defining [[Lookup table|lookup]] constructs to implement such [[Computability theory (computer science)|“strong”]] functions like the [[Ackermann function]].&lt;ref&gt;Robin Cockett: Charitable Thoughts ([ftp://ftp.cpsc.ucalgary.ca/pub/projects/charity/literature/papers_and_reports/charitable.ps ps]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }} and [ftp://ftp.cpsc.ucalgary.ca/pub/projects/charity/literature/papers_and_reports/charitable.ps.gz ps.gz]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes}})&lt;/ref&gt;

== See also ==
* [[Algebraic data type]]
* [[Catamorphism]]
* [[Anamorphism]]

== Notes ==

&lt;references/&gt;

== External links ==
* [http://www.cs.ut.ee/~varmo/papers/thesis.pdf Categorical programming with inductive and coinductive types] by Varmo Vene 
* Philip Wadler: [http://homepages.inf.ed.ac.uk/wadler/papers/free-rectypes/free-rectypes.txt Recursive types for free!] University of Glasgow, July 1998. Draft.
* [http://citeseer.ist.psu.edu/rutten94initial.html Initial Algebra and Final Coalgebra Semantics for Concurrency] by  J.J.M.M. Rutten and D. Turi
* [http://tunes.org/wiki/initiality_20and_20finality.html Initiality and finality] from CLiki

[[Category:Category theory]]
[[Category:Functional programming]]
[[Category:Type theory]]</text>
      <sha1>e7yy3vt3uppxn9paoj69a3k994ptcfu</sha1>
    </revision>
  </page>
  <page>
    <title>Jason Behrstock</title>
    <ns>0</ns>
    <id>45323078</id>
    <revision>
      <id>837871981</id>
      <parentid>831153054</parentid>
      <timestamp>2018-04-23T15:09:07Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4969">{{Infobox scientist
| name        = Jason Behrstock
| native_name = 
| native_name_lang = 
| image       =  JasonBehrstock.jpg
| image_size  = 
| alt         = 
| caption     =  Jason Behrstock in 2010
| birth_date  =         &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| birth_place = 
| death_date  =         &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = United States
| nationality = 
| fields      = [[Mathematics]]
| workplaces  = [[City University of New York]]
| patrons     = 
| education   = 
| alma_mater  = [[State University of New York at Stony Brook]]
| thesis_title = Asymptotic Geometry of the Mapping Class Group and Teichmüller Space
| thesis_url  =         
| thesis_year =  2004
| doctoral_advisor = [[Yair Minsky]]
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = [[Geometric group theory]]
| influences  = 
| influenced  = 
| awards      = {{ublist 
| [[Simons Foundation|Simons Fellow]]
| [[Alfred P. Sloan Fellowship|Alfred P. Sloan Fellow]]
| Fellow of the [[American Mathematical Society]]
}}
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         &lt;!--{{URL|www.example.com}}--&gt;
| footnotes   = 
}}

'''Jason Behrstock''' is a mathematician at [[City University of New York]] known for his work in [[geometric group theory]] and [[low-dimensional topology]].&lt;ref name=homepage&gt;{{cite web|title=Jason Behrstock|url=http://comet.lehman.cuny.edu/behrstock/|accessdate=Feb 6, 2015}}&lt;/ref&gt;

==Life and career==
Behrstock was born in California and was educated in California's public school system.&lt;ref name=meridian&gt;{{cite news|newspaper=The Meridian|url=http://www.lcmeridian.com/2010/04/01/professor-jason-behrstock-wins-alfred-p-sloan-research-fellowship/|title=PROFESSOR JASON BEHRSTOCK WINS ALFRED P. SLOAN RESEARCH FELLOWSHIP|date=Apr 1, 2010|accessdate=Feb 6, 2015}}&lt;/ref&gt; He received his Ph.D. from [[State University of New York at Stony Brook]] in 2004.&lt;ref&gt;{{MathGenealogy|id=86328|title=Jason Alan Behrstock}}&lt;/ref&gt; He went to work at [[Columbia University]] and the [[University of Utah]] before his time at [[Lehman College]], [[City University of New York]].&lt;ref name=today/&gt;

==Awards and honors==
*In 2009, Behrstock was award the Feliks Gross Endowment Award by the CUNY Graduate Center, a research award for young faculty.&lt;ref&gt;{{cite web|url=http://wp.lehman.edu/lehman-today/2012/05/lehman-economics-professor-wins-feliks-gross-award/|date=May 3, 2012|location=[[Lehman College]], [[City University of New York]]|title=Lehman Economics Professor Wins Feliks Gross Award|newspaper=Lehman Today|accessdate=Feb 6, 2015}} The article is about another recipient, but mentions Behrstock.&lt;/ref&gt;
*In 2010, Behrstock was awarded the [[Alfred P. Sloan Fellowship]].&lt;ref name=today&gt;{{cite news|title=Prestigious Alfred P. Sloan Research Fellowship Awarded to Lehman Mathematics Professor Jason Behrstock|newspaper=Lehman Today|location=[[Lehman College]], [[City University of New York]]|date= Mar 1, 2010|accessdate=Feb 6, 2015|url=http://www.lehman.cuny.edu/lehmantoday/2010_03/t_behrstock.html}}&lt;/ref&gt;
*In 2012, Behrstock became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society]&lt;/ref&gt;
*Behrstock became a [[Simons Foundation|Simons Fellow]] in 2014.&lt;ref&gt;{{cite web|url=https://www.simonsfoundation.org/funding/funding-opportunities/mathematics-physical-sciences/simons-fellow-program/simons-fellows-awardees-mathematics/|title=Simons Fellows Awardees: Mathematics|accessdate=Feb 6, 2015}}&lt;/ref&gt;

==Selected publications==
*Behrstock, Jason A. "Asymptotic geometry of the mapping class group and Teichmüller space". ''Geom. Topol.'' 10 (2006), 1523–1578.
*Behrstock, Jason; Druţu, Cornelia; Mosher, Lee. "Thick metric spaces, relative hyperbolicity, and quasi-isometric rigidity". ''Math. Ann.'' 344 (2009), no. 3, 543–595.
*Behrstock, Jason A.; Minsky, Yair N. "Dimension and rank for mapping class groups". ''Ann. of Math.'' (2) 167 (2008), no. 3, 1055–1077.

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Behrstock, Jason}}
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Stony Brook University alumni]]
[[Category:Columbia University faculty]]
[[Category:University of Utah faculty]]
[[Category:Lehman College faculty]]
[[Category:Sloan Research Fellows]]
[[Category:Mathematicians from California]]</text>
      <sha1>r5dle4iuiwyd229qtma9ht0yp9x1xa6</sha1>
    </revision>
  </page>
  <page>
    <title>Kaplan–Yorke conjecture</title>
    <ns>0</ns>
    <id>44357173</id>
    <revision>
      <id>832503301</id>
      <parentid>795638650</parentid>
      <timestamp>2018-03-26T12:04:01Z</timestamp>
      <contributor>
        <username>Laksh773</username>
        <id>33391830</id>
      </contributor>
      <comment>I changed one of the inequalities</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2748">In applied mathematics, the '''Kaplan–Yorke conjecture''' concerns the [[dimension]] of an [[attractor]], using [[Lyapunov exponent]]s.&lt;ref&gt;{{cite book |first=J. |last=Kaplan |first2=J. |last2=Yorke |authorlink2=James A. Yorke |chapter=Chaotic behavior of multidimensional difference equations |title=Functional Differential Equations and the Approximation of Fixed Points |series=Lecture Notes in Mathematics |volume=730 |editor-first=H. O. |editor-last=Peitgen |editor2-first=H. O. |editor2-last=Walther |publisher=Springer |location=Berlin |year=1979 |page=204–227 |isbn=0-387-09518-7 |chapterurl=http://yorke.umd.edu/Yorke_papers_most_cited_and_post2000/1979_C11_Kaplan_multidimensional.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |first=P. |last=Frederickson |first2=J. |last2=Kaplan |first3=E. |last3=Yorke |first4=J. |last4=Yorke |title=The Lyapunov Dimension of Strange Attractors |journal=[[Journal of Differential Equations|J. Diff. Eqs.]] |volume=49 |year=1983 |issue=2 |pages=185–207 |doi=10.1016/0022-0396(83)90011-6 }}&lt;/ref&gt; By arranging the Lyapunov exponents in order from largest to smallest &lt;math&gt;\lambda_1\geq\lambda_2\geq\dots\geq\lambda_n&lt;/math&gt;, let ''j'' be the index for which

:&lt;math&gt; \sum_{i=1}^j \lambda_i \geqslant 0 &lt;/math&gt;

and

:&lt;math&gt; \sum_{i=1}^{j+1} \lambda_i &lt; 0. &lt;/math&gt;

Then the conjecture is that the dimension of the attractor is

:&lt;math&gt; D=j+\frac{\sum_{i=1}^j\lambda_i}{|\lambda_{j+1}|}. &lt;/math&gt;

== Examples ==
Especially for chaotic systems, the Kaplan–Yorke conjecture is a useful tool in order to determine the [[fractal dimension]] of the corresponding attractor.&lt;ref&gt;{{cite journal |first=A. |last=Wolf |first2=A. |last2=Swift |first3=B. |last3=Jack |first4=H. L. |last4=Swinney |first5=J. A. |last5=Vastano |title=Determining Lyapunov Exponents from a Time Series |journal=[[Physica (journal)|Physica D]] |year=1985 |volume=16 |issue=3 |pages=285–317 |doi=10.1016/0167-2789(85)90011-9 }}&lt;/ref&gt;

* The [[Hénon map]] with parameters ''a''&amp;nbsp;=&amp;nbsp;1.4 and ''b''&amp;nbsp;=&amp;nbsp;0.3 has the ordered Lyapunov exponents &lt;math&gt;\lambda_1=0.603&lt;/math&gt; and &lt;math&gt;\lambda_2=-2.34&lt;/math&gt;. In this case, we find ''j''&amp;nbsp;=&amp;nbsp;1 and the dimension formula reduces to

:: &lt;math&gt;D=j+\frac{\lambda_1}{|\lambda_2|}=1+\frac{0.603}{|-2.34|}=1.26.&lt;/math&gt;

* The [[Lorenz system]] shows chaotic behavior at the parameter values &lt;math&gt;\sigma=16&lt;/math&gt;, &lt;math&gt;\rho=45.92&lt;/math&gt; and &lt;math&gt;\beta=4.0&lt;/math&gt;. The resulting Lyapunov exponents are {2.16,&amp;nbsp;0.00,&amp;nbsp;-32.4}. Noting that&amp;nbsp;''j''&amp;nbsp;=&amp;nbsp;2, we find

:: &lt;math&gt;D=2+\frac{2.16 + 0.00}{|-32.4|}=2.07.&lt;/math&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Kaplan-Yorke conjecture}}
[[Category:Dimension]]
[[Category:Dynamical systems]]
[[Category:Limit sets]]</text>
      <sha1>7mdavkx45p8hf29ry9jw4iqyzpahpqu</sha1>
    </revision>
  </page>
  <page>
    <title>Koopman–von Neumann classical mechanics</title>
    <ns>0</ns>
    <id>37704906</id>
    <revision>
      <id>866779922</id>
      <parentid>856043180</parentid>
      <timestamp>2018-11-01T14:18:48Z</timestamp>
      <contributor>
        <username>Gehenna1510</username>
        <id>34982813</id>
      </contributor>
      <minor/>
      <comment>CS1 error fixed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34473">{{Classical mechanics|cTopic=Formulations}}
The '''Koopman–von Neumann mechanics''' is a description of classical mechanics in terms of [[Hilbert space]], introduced by [[Bernard Koopman]] and [[John von Neumann]] in 1931 and 1932.&lt;ref name=Koopman1931&gt;{{Cite journal | last1 = Koopman | first1 = B. O. | title = Hamiltonian Systems and Transformations in Hilbert Space | doi = 10.1073/pnas.17.5.315 | journal = Proceedings of the National Academy of Sciences | volume = 17 | issue = 5 | pages = 315–318 | year = 1931 | pmid =  16577368| pmc = 1076052| bibcode = 1931PNAS...17..315K }}&lt;/ref&gt;&lt;ref name=Neumann1932&gt;{{cite journal | doi = 10.2307/1968537 | last1 = von Neumann | first1 = J.  | year = 1932 | title = Zur Operatorenmethode In Der Klassischen Mechanik | journal = Annals of Mathematics | volume = 33 | issue = 3 | pages = 587–642 | jstor = 1968537}}&lt;/ref&gt;&lt;ref name=Neumann1932a&gt;{{cite journal | doi = 10.2307/1968225 | last1 = von Neumann | first1 = J.  | year = 1932 | title = Zusatze Zur Arbeit "Zur Operatorenmethode..." | journal = Annals of Mathematics | volume = 33 | issue = 4 | pages = 789–791 | jstor = 1968225}}&lt;/ref&gt;

As Koopman and von Neumann demonstrated, a [[Hilbert space]] of [[Complex number|complex]], [[Square-integrable function|square integrable]] wavefunctions can be defined in which classical mechanics can be formulated as an operatorial theory similar to [[quantum mechanics]].

==History==
[[Statistical mechanics]] describes macroscopic systems in terms of [[Statistical ensemble (mathematical physics)|statistical ensembles]], such as the macroscopic properties of an [[ideal gas]].  Ergodic theory is a branch of mathematics arising from the study of statistical mechanics.

===Ergodic theory===
The origins of Koopman–von Neumann (KvN) theory are tightly connected with the rise{{when|date=October 2016}} of [[ergodic theory]] as an independent branch of mathematics, in particular with [[Ludwig Boltzmann|Boltzmann's]] [[ergodic hypothesis]].

In 1931 Koopman and [[André Weil]] independently observed that the phase space of the classical system can be converted into a Hilbert space by postulating a natural integration rule over the points of the phase space as the definition of the scalar product, and that this transformation allows drawing of interesting conclusions about the evolution of physical observables from [[Stone's theorem on one-parameter unitary groups|Stone's theorem]], which had been proved shortly before. This finding inspired von Neumann to apply the novel formalism to the ergodic problem. Already in 1932 he completed the operator reformulation of quantum mechanics currently known as Koopman–von Neumann theory. Subsequently, he published several seminal results in modern ergodic theory including the proof of his [[Ergodic theory#Mean ergodic theorem|mean ergodic theorem]]''.

==Definition and dynamics==

===Derivation starting from the Liouville equation===
In the approach of Koopman and von Neumann ('''KvN'''), dynamics in [[phase space]] is described by a (classical) probability density, recovered from an underlying wavefunction – the Koopman–von Neumann wavefunction – as the square of its absolute value (more precisely, as the amplitude multiplied with its own [[complex conjugate]]). This stands in analogy to the [[Born rule]] in quantum mechanics. In the KvN framework, observables are represented by commuting self-adjoint operators acting on the [[Hilbert space]] of KvN wavefunctions. The commutativity physically implies that all observables are simultaneously measurable. Contrast this with quantum mechanics, where observables need not commute, which underlines the [[uncertainty principle]], [[Kochen–Specker theorem]], and [[Bell inequalities]].&lt;ref name=Landau1987&gt;{{Cite journal | last1 = Landau | first1 = L. J. | title = On the violation of Bell's inequality in quantum theory | doi = 10.1016/0375-9601(87)90075-2 | journal = Physics Letters A | volume = 120 | issue = 2 | pages = 54–56| year = 1987 | pmid =  | pmc = |bibcode = 1987PhLA..120...54L }}&lt;/ref&gt;

The KvN wavefunction is postulated to evolve according to exactly the same [[Liouville's theorem (Hamiltonian)|Liouville equation]] as the classical probability density. From this postulate it can be shown that indeed probability density dynamics is recovered.

&lt;div style="clear:both;width:75%;" class="NavFrame expanded"&gt;
&lt;div class="NavHead" style="background-color:#CCCCFF; text-align:left; font-size:larger;"&gt;Dynamics of the probability density (proof)&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;"&gt;

In classical statistical mechanics, the probability density obeys the Liouville equation&lt;ref name=DaniloMauro2002/&gt;&lt;ref name=Mauro2002/&gt;
:&lt;math&gt;i\frac{\partial}{\partial t} \rho (x, p, t) = \hat{L} \rho(x, p, t)&lt;/math&gt;
with the self-adjoint Liouvillian
:&lt;math&gt;\hat{L} = - i\frac{\partial H(x, p)}{\partial p}  \frac{\partial}{\partial x} + i\frac{\partial H(x, p)}{\partial x} \frac{\partial}{\partial p},&lt;/math&gt;
where &lt;math&gt; H(x,p) &lt;/math&gt; denotes the [[Hamiltonian mechanics|classical Hamiltonian]].
The same dynamical equation is postulated for the KvN wavefunction
:&lt;math&gt;i\frac{\partial}{\partial t} \psi (x, p, t) = \hat{L} \psi (x, p, t),&lt;/math&gt;
thus
:&lt;math&gt;\frac{\partial}{\partial t} \psi(x, p, t) = \left[- \frac{\partial H(x, p)}{\partial p}  \frac{\partial}{\partial x} + \frac{\partial H(x, p)}{\partial x} \frac{\partial}{\partial p} \right] \psi(x, p, t),&lt;/math&gt;
and for its complex conjugate
:&lt;math&gt;\frac{\partial}{\partial t} \psi^*(x, p, t) = \left[- \frac{\partial H(x, p)}{\partial p}  \frac{\partial}{\partial x} + \frac{\partial H(x, p)}{\partial x} \frac{\partial}{\partial p} \right] \psi^*(x, p, t).&lt;/math&gt;
From
:&lt;math&gt;\rho(x, p, t) = \psi^*(x, p, t) \psi(x, p, t)&lt;/math&gt;
follows using the [[Product rule#Higher partial derivatives|product rule]] that
:&lt;math&gt;\frac{\partial}{\partial t} \rho(x, p, t) = \left[- \frac{\partial H(x, p)}{\partial p}  \frac{\partial}{\partial x} + \frac{\partial H(x, p)}{\partial x} \frac{\partial}{\partial p} \right] \rho(x, p, t)&lt;/math&gt;
which proves that probability density dynamics can be recovered from the KvN wavefunction.

;Remark:
The last step of this derivation relies on the classical Liouville operator containing only first-order derivatives in the coordinate and momentum; this is not the case in quantum mechanics where the [[Schrödinger equation]] contains second-order derivatives.
&lt;ref name=DaniloMauro2002&gt;
{{Cite arXiv | last=Mauro | first=D. | title=Topics in Koopman–von Neumann Theory | year=2002 | eprint=quant-ph/0301172 }} PhD thesis, Università degli Studi di Trieste.
&lt;/ref&gt;
&lt;ref name=Mauro2002&gt;{{Cite journal | last1 = Mauro | first1 = D. | title = On Koopman–Von Neumann Waves | doi = 10.1142/S0217751X02009680 | journal = International Journal of Modern Physics A | volume = 17 | issue = 9 | pages = 1301–1325 | year = 2002 | pmid =  | pmc = |arxiv = quant-ph/0105112 |bibcode = 2002IJMPA..17.1301M | citeseerx = 10.1.1.252.9355 }}&lt;/ref&gt;
&lt;/div&gt;
&lt;/div&gt;

===Derivation starting from operator axioms===
Conversely, it is possible to start from operator postulates, similar to the [[Operator (physics)#Operators in quantum mechanics|Hilbert space axioms of quantum mechanics]], and derive the equation of motion by specifying how expectation values evolve.&lt;ref name=Bondar2012&gt;{{Cite journal | last1 = Bondar | first1 = D. | last2 = Cabrera | first2 = R. | last3 = Lompay | first3 = R. | last4 = Ivanov | first4 = M. | last5 = Rabitz | first5 = H. | title = Operational Dynamic Modeling Transcending Quantum and Classical Mechanics | doi = 10.1103/PhysRevLett.109.190403 | journal = Physical Review Letters | volume = 109 | issue = 19 | year = 2012 | pmid =  23215365| pmc = |arxiv = 1105.4014 |bibcode = 2012PhRvL.109s0403B | pages=190403}}&lt;/ref&gt;

The relevant axioms are that as in quantum mechanics (i) the states of a system are represented by normalized vectors of a complex Hilbert space, and the observables are given by [[self-adjoint operator]]s acting on that space, (ii) the expectation value of an observable is obtained in the manner as the [[Expectation value (quantum mechanics)#Formalism in quantum mechanics|expectation value in quantum mechanics]], (iii) the probabilities of measuring certain values of some observables are calculated by the [[Born rule]], and (iv) the state space of a composite system is the [[tensor product]] of the subsystem's spaces.

&lt;div class="NavContent" style="text-align:left;"&gt;
&lt;div style="clear:both;width:75%;" class="NavFrame expanded"&gt;
&lt;div class="NavHead" style="background-color:#CCCCFF; text-align:left; font-size:larger;"&gt;{{anchor|sec_formulation}}Mathematical form of the operator axioms&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;"&gt;
The above axioms (i) to (iv), with the [[inner product]] written in the [[bra–ket notation]], are
:(i) &lt;math&gt; \langle \psi(t) | \psi(t) \rangle = 1&lt;/math&gt;,
:(ii) The expectation value of an observable &lt;math&gt;\hat{A}&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt; is &lt;math&gt;\langle A (t)\rangle =  \langle \Psi (t)| \hat{A} | \Psi(t) \rangle.&lt;/math&gt;
:(iii)  The probability that a measurement of an observable &lt;math&gt;\hat{A}&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt; yields &lt;math&gt;A&lt;/math&gt; is &lt;math&gt; \left|\langle A | \Psi(t)\rangle \right|^2 &lt;/math&gt;, where &lt;math&gt; \hat{A} |A\rangle = A |A \rangle &lt;/math&gt;. (This axiom is an analogue of the [[Born rule]] in quantum mechanics.&lt;ref name=Brumer2006&gt;{{Cite journal | last1 = Brumer | first1 = P. | last2 = Gong | first2 = J. | doi = 10.1103/PhysRevA.73.052109 | title = Born rule in quantum and classical mechanics | journal = Physical Review A | volume = 73 | issue = 5 | pages = 052109 | year = 2006 | pmid =  | pmc = |arxiv = quant-ph/0604178 |bibcode = 2006PhRvA..73e2109B | hdl = 1807/16870 }}&lt;/ref&gt;)
:(iv) (see [[Tensor product of Hilbert spaces#Definition|Tensor product of Hilbert spaces]]).
&lt;/div&gt;
&lt;/div&gt;

These axioms allow us to recover the formalism of both classical and quantum mechanics.&lt;ref name=Bondar2012/&gt; Specifically, under the assumption that the classical position and momentum operators [[Commutative property|commute]], the Liouville equation for the KvN wavefunction is recovered from averaged [[Newton's laws of motion]]. However, if the coordinate and momentum obey the [[canonical commutation relation]], the [[Schrödinger equation]] of quantum mechanics is obtained.

&lt;div style="clear:both;width:75%;" class="NavFrame expanded"&gt;
&lt;div class="NavHead" style="background-color:#CCCCFF; text-align:left; font-size:larger;"&gt;{{anchor|sec_KvN_from_Newton}}Classical mechanics from the [[#sec_formulation|operator axioms]] (derivation)&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;"&gt;
We begin from the following equations for expectation values of the coordinate ''x'' and momentum ''p''
:&lt;math&gt;
m\frac{d}{dt} \langle x \rangle = \langle p \rangle, \qquad \frac{d}{dt} \langle p \rangle =\langle -U'(x) \rangle,
&lt;/math&gt;
aka, [[Newton's laws of motion]] averaged over ensemble. With the help of the [[#sec_formulation|operator axioms]], they can be rewritten as
:&lt;math&gt;
\begin{align}
m\frac{d}{dt} \langle \Psi(t) | \hat{x} | \Psi(t) \rangle &amp;= \langle \Psi(t) | \hat{p} | \Psi(t) \rangle, \\
\frac{d}{dt} \langle \Psi(t) | \hat{p} | \Psi(t) \rangle &amp;= \langle \Psi(t) | -U'(\hat{x}) | \Psi(t) \rangle.
\end{align}
&lt;/math&gt;
Notice a close resemblance with [[Ehrenfest theorem]]s in quantum mechanics. Applications of the [[product rule]] leads to
:&lt;math&gt;
\begin{align}
\langle d\Psi/dt | \hat{x} | \Psi \rangle + \langle \Psi | \hat{x} | d\Psi/dt \rangle &amp;= \langle \Psi | \hat{p}/m | \Psi \rangle, \\
	\langle d\Psi/dt | \hat{p} | \Psi \rangle  + \langle \Psi | \hat{p} | d\Psi/dt \rangle &amp; = \langle \Psi | -U'(\hat{x}) | \Psi \rangle,
\end{align}
&lt;/math&gt;
into which we substitute a consequence of [[Stone's theorem on one-parameter unitary groups|Stone's theorem]] &lt;math&gt; i | d\Psi(t)/dt \rangle = \hat{L} | \Psi(t) \rangle &lt;/math&gt; and obtain
:&lt;math&gt;
\begin{align}
im \langle \Psi(t) | [\hat{L}, \hat{x} ] | \Psi(t) \rangle &amp;= \langle \Psi(t)| \hat{p} |\Psi(t)\rangle,  \\
i \langle \Psi(t) | [\hat{L}, \hat{p}] | \Psi(t)\rangle &amp;= - \langle \Psi(t)| U'(\hat{x}) |\Psi(t)\rangle.
\end{align}
&lt;/math&gt;
Since these identities must be valid for any initial state, the averaging can be dropped and the  system of commutator equations for the unknown &lt;math&gt;\hat{L}&lt;/math&gt; is derived
{{NumBlk|:|&lt;math&gt;
	im  [\hat{L}, \hat{x}] =  \hat{p} , \qquad i [\hat{L}, \hat{p}] = -U'(\hat{x}).
&lt;/math&gt;|{{EquationRef|commutator eqs for L}}}}
'''Assume that the coordinate and momentum commute &lt;math&gt;[ \hat{x}, \hat{p} ] = 0&lt;/math&gt;.''' This assumption physically means that the classical particle's coordinate and momentum can be measured simultaneously, implying absence of the [[uncertainty principle]].

The solution &lt;math&gt;\hat{L}&lt;/math&gt; cannot be simply of the form &lt;math&gt;\hat{L} = L(\hat{x}, \hat{p})&lt;/math&gt; because it would imply the contractions &lt;math&gt; im  [L(\hat{x}, \hat{p}), \hat{x}] =  0 = \hat{p} &lt;/math&gt; and &lt;math&gt; i [L(\hat{x}, \hat{p}), \hat{p}] = 0 = -U'(\hat{x}) &lt;/math&gt;. Therefore, we must utilize additional operators &lt;math&gt;\hat{\lambda}_x&lt;/math&gt; and &lt;math&gt;\hat{\lambda}_p&lt;/math&gt; obeying
{{NumBlk|:|&lt;math&gt;
	[ \hat{x}, \hat{\lambda}_x ] = [ \hat{p}, \hat{\lambda}_p ] = i, \quad [\hat{x}, \hat{p}] = [ \hat{x}, \hat{\lambda}_p ] =  [ \hat{p}, \hat{\lambda}_x ] = [ \hat{\lambda}_x, \hat{\lambda}_p ] = 0.
&lt;/math&gt;|{{EquationRef|KvN algebra}}}}
The need to employ these auxiliary operators arises because all classical observables commute. Now we seek &lt;math&gt;\hat{L}&lt;/math&gt; in the form &lt;math&gt;\hat{L} = L(\hat{x}, \hat{\lambda}_x, \hat{p}, \hat{\lambda}_p)&lt;/math&gt;. Utilizing {{EquationNote|KvN algebra}}, the {{EquationNote|commutator eqs for L}} can be converted into the following differential equations
:&lt;ref name=Bondar2012/&gt;&lt;ref name=Transtrum2005&gt;{{Cite journal | last1 = Transtrum | first1 = M. K. | last2 = Van Huele | first2 = J. F. O. S. | doi = 10.1063/1.1924703 | title = Commutation relations for functions of operators | journal = Journal of Mathematical Physics | volume = 46 | issue = 6 | pages = 063510 | year = 2005 | pmid =  | pmc = |bibcode = 2005JMP....46f3510T }}&lt;/ref&gt;
:&lt;math&gt;
m L'_{\lambda_x} (x, \lambda_x, p, \lambda_p) = p, \qquad L'_{\lambda_p} (x, \lambda_x, p, \lambda_p) = -U'(x).
&lt;/math&gt;
Whence, we conclude that the classical KvN wave function &lt;math&gt;|\Psi(t)\rangle&lt;/math&gt; evolves according to the  [[Schrödinger equation|Schrödinger-like]] equation of motion
{{NumBlk|:|&lt;math&gt;
	i\frac{d}{dt} |\Psi(t)\rangle = \hat{L} |\Psi(t)\rangle,
\qquad \hat{L} = \frac{\hat{p}}{m} \hat{\lambda}_x  - U'(\hat{x}) \hat{\lambda}_p.
&lt;/math&gt;|{{EquationRef|KvN dynamical eq}}}}

Let us explicitly show that {{EquationNote|KvN dynamical eq}} is equivalent to the [[Liouville's theorem (Hamiltonian)#Liouville equations|classical Liouville mechanics]].

Since &lt;math&gt;\hat{x}&lt;/math&gt; and &lt;math&gt;\hat{p}&lt;/math&gt; commute, they share the common [[eigenvectors]]
{{NumBlk|:|&lt;math&gt;
\hat{x} |x,p\rangle = x |x,p\rangle, \quad \hat{p} |x,p\rangle = p |x,p\rangle , \quad
A(\hat{x}, \hat{p}) |x,p\rangle = A(x,p) |x,p\rangle,
&lt;/math&gt;|{{EquationRef|xp eigenvec}}}}
with the [[Self-adjoint operator#Resolution of the identity|resolution of the identity]]
&lt;math&gt;
1 = \int dx dp \, |x,p\rangle \langle x,p|.
&lt;/math&gt;
Then, one obtains from equation ({{EquationNote|KvN algebra}})
:&lt;math&gt;
\langle x,p| \hat{\lambda}_x | \Psi \rangle =  -i \frac{\partial}{\partial x} \langle x,p | \Psi \rangle, \qquad
\langle x,p| \hat{\lambda}_p | \Psi \rangle =  -i \frac{\partial}{\partial p} \langle x,p | \Psi \rangle.
&lt;/math&gt;
Projecting equation ({{EquationNote|KvN dynamical eq}}) onto &lt;math&gt;\langle x,p|&lt;/math&gt;, we get the equation of motion for the KvN wave function in the xp-representation
{{NumBlk|:|&lt;math&gt;
\left[ \frac{\partial }{\partial t} + \frac{p}{m} \frac{\partial}{\partial x} -  U'(x) \frac{\partial}{\partial p} \right]  \langle x,p | \Psi(t) \rangle = 0.
&lt;/math&gt;|{{EquationRef|KvN dynamical eq in xp}}}}
The quantity &lt;math&gt;\langle x,\, p |\Psi(t) \rangle&lt;/math&gt; is the probability amplitude for a classical particle to be at point &lt;math&gt;x&lt;/math&gt; with momentum &lt;math&gt;p&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt;. According to the [[#sec_formulation|axioms above]], the probability density is given by
&lt;math&gt;\rho(x,p;t) = \left| \langle x, p |\Psi(t) \rangle \right|^2&lt;/math&gt;. Utilizing the identity
:&lt;math&gt;
\frac{\partial }{\partial t} \rho(x,p;t) = \langle \Psi(t) | x, p \rangle \frac{\partial }{\partial t} \langle x, p |\Psi(t) \rangle
+ \langle x, p |\Psi(t) \rangle \left( \frac{\partial }{\partial t}  \langle x, p |\Psi(t) \rangle \right)^*
&lt;/math&gt;
as well as ({{EquationNote|KvN dynamical eq in xp}}), we recover the classical Liouville equation
{{NumBlk|:|&lt;math&gt;
\left[ \frac{\partial }{\partial t} + \frac{p}{m} \frac{\partial}{\partial x} -  U'(x) \frac{\partial}{\partial p}  \right]  \rho(x,p;t) = 0.
&lt;/math&gt;|{{EquationRef|Liouville eq}}}}

Moreover, according to the [[#sec_formulation|operator axioms]] and ({{EquationNote|xp eigenvec}}),
:&lt;math&gt;
\begin{align}
\langle A \rangle  &amp;=  \langle \Psi (t)| A(\hat{x}, \hat{p}) | \Psi(t) \rangle
= \int dxdp \, \langle \Psi (t)| x,p\rangle A(x, p) \langle x,p | \Psi(t) \rangle \\
&amp; = \int dxdp \,  A(x, p) \langle \Psi (t)| x,p\rangle \langle x,p | \Psi(t) \rangle
= \int dxdp \,  A(x, p) \rho(x,p;t).
\end{align}
&lt;/math&gt;
Therefore, the rule for calculating averages of observable &lt;math&gt; A(x,p) &lt;/math&gt; in classical statistical mechanics has been recovered from the [[#sec_formulation|operator axioms]] with the additional assumption &lt;math&gt;[ \hat{x}, \hat{p} ] = 0&lt;/math&gt;. As a result, the phase of a classical wave function does not contribute to observable averages. Contrary to quantum mechanics, the phase of a KvN wave function is physically irrelevant. Hence, nonexistence of the [[double-slit experiment]]&lt;ref name=Mauro2002/&gt;&lt;ref name=Gozzi2003&gt;{{Cite journal | last1 = Gozzi | first1 = E. | last2 = Mauro | first2 = D. | doi = 10.1142/S0217751X04017872 | title = On Koopman–Von Neumann Waves Ii | journal = International Journal of Modern Physics A | volume = 19 | issue = 9 | pages = 1475 | year = 2004 | pmid =  | pmc = |arxiv = quant-ph/0306029 |bibcode = 2004IJMPA..19.1475G | citeseerx = 10.1.1.252.1596 }}&lt;/ref&gt;&lt;ref name=Gozzi2010&gt;{{Cite journal | last1 = Gozzi | first1 = E. | last2 = Pagani | first2 = C. | doi = 10.1103/PhysRevLett.105.150604 | title = Universal Local Symmetries and Nonsuperposition in Classical Mechanics | journal = Physical Review Letters | volume = 105 | issue = 15 | year = 2010 | pmid =  21230883| pmc = |arxiv = 1006.3029 |bibcode = 2010PhRvL.105o0604G | page=150604}}&lt;/ref&gt; as well as [[Aharonov–Bohm effect]]&lt;ref name=Gozzi2002&gt;{{Cite journal | last1 = Gozzi | first1 = E. | last2 = Mauro | first2 = D. | doi = 10.1006/aphy.2001.6206 | title = Minimal Coupling in Koopman–von Neumann Theory | journal = Annals of Physics | volume = 296 | issue = 2 | pages = 152 | year = 2002 | pmid =  | pmc = |arxiv = quant-ph/0105113 |bibcode = 2002AnPhy.296..152G | citeseerx = 10.1.1.252.9506 }}&lt;/ref&gt; is established in the KvN mechanics.

Projecting {{EquationNote|KvN dynamical eq}} onto the common eigenvector of the operators &lt;math&gt;\hat{x}&lt;/math&gt; and &lt;math&gt;\hat{\lambda}_p&lt;/math&gt; (i.e., &lt;math&gt;x\lambda_p&lt;/math&gt;-representation), one obtains classical mechanics in the doubled configuration space,&lt;ref name=Blokhintsev1977&gt;{{Cite journal | last1 = Blokhintsev | first1 = D. I. | title = Classical statistical physics and quantum mechanics | doi = 10.1070/PU1977v020n08ABEH005457 | journal = Soviet Physics Uspekhi | volume = 20 | issue = 8 | pages = 683–690 | year = 1977 | pmid =  | pmc = | bibcode = 1977SvPhU..20..683B }}&lt;/ref&gt; whose generalization leads
&lt;ref name=Blokhintsev1977/&gt;
&lt;ref name=Blokhintsev1940a&gt;{{Cite journal|last=[[Blokhintsev]] | first=D.I. | journal = J. Phys. U.S.S.R. |issue=1 |pages = 71–74 | title = The Gibbs Quantum Ensemble and its Connection with the Classical Ensemble | volume = 2 |year = 1940 }}
&lt;/ref&gt;
&lt;ref name=Blokhintsev1940&gt;{{Cite journal| last1= [[Blokhintsev]] | first1= D.I. | last2=Nemirovsky | first2= P | journal = J. Phys. U.S.S.R. | issue=3 | pages = 191–194 | title = Connection of the Quantum Ensemble with the Gibbs Classical Ensemble. II | volume = 3 | year = 1940 }}
&lt;/ref&gt;
&lt;ref name=Blokhintsev1941&gt;{{Cite journal| last1=[[Blokhintsev]] | first1= D.I. | last2=Dadyshevsky | first2=Ya. B. | journal = Zh. Eksp. Teor. Fiz. | issue=2–3 | pages = 222–225 | title = On Separation of a System into Quantum and Classical Parts | volume = 11 |year = 1941 }}
&lt;/ref&gt;
&lt;ref name=blokhintsev2010philosophy&gt;{{Cite book|last=[[Blokhintsev]] | first=D.I.|publisher = Springer|isbn=9789048183357|title = The Philosophy of Quantum Mechanics |year = 2010}}
&lt;/ref&gt;
to the [[Phase space formulation|phase space formulation of quantum mechanics]].
&lt;/div&gt;
&lt;/div&gt;

&lt;div style="clear:both;width:75%;" class="NavFrame expanded"&gt;
&lt;div class="NavHead" style="background-color:#CCCCFF; text-align:left; font-size:larger;"&gt;{{anchor|sec_quantum_mech}}Quantum mechanics from the [[#sec_formulation|operator axioms]] (derivation)&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;"&gt;
As in the [[#sec_KvN_from_Newton|derivation of classical mechanics]], we begin from the following equations for averages of coordinate ''x'' and momentum ''p''
:&lt;math&gt;
m\frac{d}{dt} \langle x \rangle = \langle p \rangle, \qquad \frac{d}{dt} \langle p \rangle =\langle -U'(x) \rangle.
&lt;/math&gt;
With the help of the [[#sec_formulation|operator axioms]], they can be rewritten as
:&lt;math&gt;
\begin{align}
m\frac{d}{dt} \langle \Psi(t) | \hat{x} | \Psi(t) \rangle &amp;= \langle \Psi(t) | \hat{p} | \Psi(t) \rangle, \\
\frac{d}{dt} \langle \Psi(t) | \hat{p} | \Psi(t) \rangle &amp;= \langle \Psi(t) | -U'(\hat{x}) | \Psi(t) \rangle.
\end{align}
&lt;/math&gt;
These are the [[Ehrenfest theorem]]s in quantum mechanics. Applications of the [[product rule]] leads to
:&lt;math&gt;
\begin{align}
\langle d\Psi/dt | \hat{x} | \Psi \rangle + \langle \Psi | \hat{x} | d\Psi/dt \rangle &amp;= \langle \Psi | \hat{p}/m | \Psi \rangle, \\
	\langle d\Psi/dt | \hat{p} | \Psi \rangle  + \langle \Psi | \hat{p} | d\Psi/dt \rangle &amp; = \langle \Psi | -U'(\hat{x}) | \Psi \rangle,
\end{align}
&lt;/math&gt;
into which we substitute a consequence of [[Stone's theorem on one-parameter unitary groups|Stone's theorem]]
:&lt;math&gt;
i\hbar | d \Psi(t)/dt \rangle = \hat{H} | \Psi(t) \rangle,
&lt;/math&gt;
where &lt;math&gt;\hbar&lt;/math&gt; was introduced as a normalization constant to balance dimensionality. Since these identities must be valid for any initial state, the averaging can be dropped and the system of commutator equations for the unknown quantum generator of motion &lt;math&gt;\hat{H}&lt;/math&gt; are derived
:&lt;math&gt;
im [\hat{H}, \hat{x}] = \hbar \hat{p}, \qquad i [\hat{H}, \hat{p}] = -\hbar U'(\hat{x}).
&lt;/math&gt;
Contrary to the case of [[#sec_KvN_from_Newton|classical mechanics]], we '''assume that observables of the coordinate and momentum obey the [[canonical commutation relation]]''' &lt;math&gt;[ \hat{x}, \hat{p} ] = i\hbar&lt;/math&gt;. Setting &lt;math&gt;\hat{H} = H(\hat{x}, \hat{p})&lt;/math&gt;, the commutator equations can be converted into the differential equations
&lt;ref name=Bondar2012/&gt;&lt;ref name=Transtrum2005/&gt;
:&lt;math&gt;
m H'_p (x,p) = p, \qquad H'_x (x,p) = U'(x),
&lt;/math&gt;
whose solution is the familiar [[Hamiltonian (quantum mechanics)|quantum Hamiltonian]]
:&lt;math&gt;
\hat{H} = \frac{\hat{p}^2}{2m} + U(\hat{x}).
&lt;/math&gt;
Whence, the [[Schrödinger equation]] was derived from the Ehrenfest theorems by assuming the canonical commutation relation between the coordinate and momentum. This derivation as well as the [[#sec_KvN_from_Newton|derivation of classical KvN mechanics]] shows that the difference between quantum and classical mechanics essentially boils down to the value of the commutator &lt;math&gt;[ \hat{x}, \hat{p} ]&lt;/math&gt;.
&lt;/div&gt;
&lt;/div&gt;

===Measurements===
In the Hilbert space and operator formulation of classical mechanics, the Koopman von Neumann–wavefunction takes the form of a superposition of eigenstates, and measurement collapses the KvN wavefunction to the eigenstate which is associated the measurement result, in analogy to the [[wave function collapse]] of quantum mechanics.

However, it can be shown that for Koopman–von Neumann classical mechanics ''non-selective measurements'' leave the KvN wavefunction unchanged.&lt;ref name=DaniloMauro2002/&gt;

==KvN vs Liouville mechanics==

The KvN dynamical equation ({{EquationNote|KvN dynamical eq in xp}}) and [[Liouville's theorem (Hamiltonian)#Liouville equations|Liouville equation]] ({{EquationNote|Liouville eq}}) are [[first-order partial differential equation|first-order linear partial differential equations]]. One recovers [[Newton's laws of motion]] by applying the [[method of characteristics]] to either of these equations. Hence, the key difference between KvN and Liouville mechanics lies in weighting individual trajectories: Arbitrary weights, underlying the classical wave function, can be utilized in the KvN mechanics, while only positive weights, representing the probability density, are permitted in the Liouville mechanics (see [[#fig_KvN_vs_Liouville|this scheme]]).

[[File:KvN vs Liouville mechanics.pdf|thumb|350px|center|{{anchor|fig_KvN_vs_Liouville}}The essential distinction between KvN and Liouville mechanics lies in weighting (coloring) individual trajectories: Any weights can be utilized in KvN mechanics, while only positive weights are allowed in Liouville mechanics. Particles move along Newtonian trajectories in both cases. ([[#animation_KvN_for_Morse|Regarding a dynamical example, see below.]])]]

==Quantum analogy==

Being explicitly based on the Hilbert space language, the KvN classical mechanics adopts many techniques from quantum mechanics, for example, [[Perturbation theory (quantum mechanics)|perturbation]] and [[Feynman diagrams|diagram techniques]]&lt;ref name=Liboff2003&gt;{{Cite book| last=Liboff | first=R. L. | title=Kinetic theory: classical, quantum, and relativistic descriptions | publisher=Springer | year=2003 |isbn=9780387955513}}&lt;/ref&gt; as well as [[Functional integration|functional integral methods]]&lt;ref name=Gozzi1988&gt;{{Cite journal | last1 = Gozzi | first1 = E. | title = Hidden BRS invariance in classical mechanics | doi = 10.1016/0370-2693(88)90611-9 | journal = Physics Letters B | volume = 201 | issue = 4 | pages = 525–528 | year = 1988 | pmid =  | pmc = |bibcode = 1988PhLB..201..525G | url = http://cds.cern.ch/record/199310 | format = Submitted manuscript }}&lt;/ref&gt;&lt;ref name=Gozzi1989&gt;{{Cite journal | last1 = Gozzi | first1 = E. | last2 = Reuter | first2 = M. | last3 = Thacker | first3 = W. | doi = 10.1103/PhysRevD.40.3363 | title = Hidden BRS invariance in classical mechanics. II | journal = Physical Review D | volume = 40 | issue = 10 | pages = 3363 | year = 1989 | pmid =  | pmc = |bibcode = 1989PhRvD..40.3363G }}&lt;/ref&gt;&lt;ref name=Blasone2005&gt;{{Cite journal | last1 = Blasone | first1 = M. | last2 = Jizba | first2 = P. | last3 = Kleinert | first3 = H. | title = Path-integral approach to 't Hooft's derivation of quantum physics from classical physics | doi = 10.1103/PhysRevA.71.052507 | journal = Physical Review A | volume = 71 | issue = 5 | pages = 052507 | year = 2005 | pmid =  | pmc = |arxiv = quant-ph/0409021 |bibcode = 2005PhRvA..71e2507B }}&lt;/ref&gt;. The KvN approach is very general, and it has been extended to [[dissipative systems]],&lt;ref name=Chruscinski2006&gt;{{Cite journal | last1 = Chruściński | first1 = D. | title = Koopman's approach to dissipation | doi = 10.1016/S0034-4877(06)80023-6 | journal = Reports on Mathematical Physics | volume = 57 | issue = 3 | pages = 319–332 | year = 2006 | pmid =  | pmc = | bibcode=2006RpMP...57..319C}}&lt;/ref&gt; [[relativistic mechanics]],&lt;ref name=Cabrera2012/&gt; and [[classical field theories]]&lt;ref name=Bondar2012/&gt;&lt;ref name=Carta2006&gt;{{Cite journal | last1 = Carta | first1 = P. | last2 = Gozzi | first2 = E. | last3 = Mauro | first3 = D. | doi = 10.1002/andp.200510177 | title = Koopman–von Neumann formulation of classical Yang–Mills theories: I | journal = Annalen der Physik | volume = 15 | issue = 3 | pages = 177 | year = 2006 | pmid =  | pmc = |arxiv = hep-th/0508244 |bibcode = 2006AnP...518..177C }}&lt;/ref&gt;&lt;ref name=Gozzi2011&gt;{{Cite journal | last1 = Gozzi | first1 = E. | last2 = Penco | first2 = R. | doi = 10.1016/j.aop.2010.11.018 | title = Three approaches to classical thermal field theory | journal = Annals of Physics | volume = 326 | issue = 4 | pages = 876 | year = 2011 | pmid =  | pmc = |arxiv = 1008.5135 |bibcode = 2011AnPhy.326..876G }}&lt;/ref&gt;&lt;ref name=Cattaruzza2011&gt;{{Cite journal | last1 = Cattaruzza | first1 = E. | last2 = Gozzi | first2 = E. | last3 = Francisco Neto | first3 = A. | doi = 10.1016/j.aop.2011.05.009 | title = Diagrammar in classical scalar field theory | journal = Annals of Physics | volume = 326 | issue = 9 | pages = 2377 | year = 2011 | pmid =  | pmc = |arxiv = 1010.0818 |bibcode = 2011AnPhy.326.2377C | citeseerx = 10.1.1.750.8350 }}&lt;/ref&gt;.

The KvN approach is fruitful in studies on the [[Classical limit|quantum-classical correspondence]]&lt;ref name=Bondar2012/&gt;&lt;ref name=Brumer2006/&gt;&lt;ref name=Wilkie1997&gt;{{Cite journal | last1 = Wilkie | first1 = J. | last2 = Brumer | first2 = P. | doi = 10.1103/PhysRevA.55.27 | title = Quantum-classical correspondence via Liouville dynamics. I. Integrable systems and the chaotic spectral decomposition | journal = Physical Review A | volume = 55 | issue = 1 | pages = 27–42 | year = 1997 | pmid =  | pmc = |bibcode = 1997PhRvA..55...27W | arxiv = chao-dyn/9608013 | hdl = 1807/16867 }}&lt;/ref&gt;&lt;ref name=Wilkie1997a&gt;{{Cite journal | last1 = Wilkie | first1 = J. | last2 = Brumer | first2 = P. | doi = 10.1103/PhysRevA.55.43 | title = Quantum-classical correspondence via Liouville dynamics. II. Correspondence for chaotic Hamiltonian systems | journal = Physical Review A | volume = 55 | issue = 1 | pages = 43–61 | year = 1997 | pmid =  | pmc = |bibcode = 1997PhRvA..55...43W | arxiv = chao-dyn/9608014 | hdl = 1807/16874 }}&lt;/ref&gt;&lt;ref name=Abrikosovjr2005&gt;{{Cite journal | last1 = Abrikosov | first1 = A. A. | last2 = Gozzi | first2 = E. | last3 = Mauro | first3 = D. | title = Geometric dequantization | doi = 10.1016/j.aop.2004.12.001 | journal = Annals of Physics | volume = 317 | issue = 1 | pages = 24–71 | year = 2005 | pmid =  | pmc = |arxiv = quant-ph/0406028 |bibcode = 2005AnPhy.317...24A }}&lt;/ref&gt; as it reveals that the Hilbert space formulation is not exclusively quantum mechanical.&lt;ref&gt;Bracken, A. J. (2003). "Quantum mechanics as an approximation to classical mechanics in Hilbert space", ''Journal of Physics A: Mathematical and General'', '''36'''(23), L329.&lt;/ref&gt; Even [[Dirac spinor]]s are not exceptionally quantum as they are utilized in the relativistic generalization of the KvN mechanics.&lt;ref name=Cabrera2012/&gt; Similarly as the more well-known [[phase space formulation]] of quantum mechanics, the KvN approach can be understood as an attempt to bring classical and quantum mechanics into a common mathematical framework. In fact, the time evolution of the [[Wigner quasiprobability distribution|Wigner function]] approaches, in the classical limit, the time evolution of the KvN wavefunction of a classical particle.&lt;ref name=Cabrera2012&gt;{{cite arXiv|eprint=1107.5139|author1=Renan Cabrera|author2=Bondar|author3=Rabitz|title=Relativistic Wigner function and consistent classical limit for spin 1/2   particles|class=quant-ph|year=2011}}&lt;/ref&gt;&lt;ref name=Bondar2013&gt;{{Cite journal|arxiv=1202.3628|author1=Bondar|author2=Renan Cabrera|author3=Zhdanov|author4=Rabitz|title=Wigner Function's Negativity Demystified|year=2012|doi=10.1103/PhysRevA.88.052108|volume=88|issue=5|pages=263|journal=Physical Review A|bibcode=2013PhRvA..88e2108B}}&lt;/ref&gt; However, a mathematical resemblance to quantum mechanics does not imply the presence of hallmark quantum effects. In particular, impossibility of [[double-slit experiment]]&lt;ref name=Mauro2002/&gt;&lt;ref name=Gozzi2003/&gt;&lt;ref name=Gozzi2010/&gt; and [[Aharonov–Bohm effect]]&lt;ref name=Gozzi2002/&gt; are explicitly demonstrated in the KvN framework.

{{Gallery
|title=KvN propagation vs Wigner propagation
|align=center
|lines=10
|width=320
|height=320
|File:KvN evolution for Morse potential.ogv|{{anchor|animation_KvN_for_Morse}}The time evolution of the classical KvN wave function for the [[Morse potential]]: &lt;math&gt;U (x) = 20 ( 1 - e^{-0.16x} )^2 &lt;/math&gt;. Black dots are classical particles following [[Newton's law of motion]]. The solid lines represent the [[level set]] of the [[Hamiltonian mechanics|Hamiltonian]] &lt;math&gt;H(x,p) = p^2 / 2 + U(x) &lt;/math&gt;. This video illustrates [[#fig_KvN_vs_Liouville|the fundamental difference between KvN and Liouville mechanics]].
|File:Wigner function propagation for morse potential.ogv|Quantum counterpart of the classical KvN propagation on the left: The [[Wigner quasiprobability distribution|Wigner function]] time evolution of the [[Morse potential]] in [[atomic units]] (a.u.). The solid lines represent the [[level set]] of the underlying [[Hamiltonian mechanics|Hamiltonian]]. Note that the same initial condition used for this quantum propagation as well as for the KvN propagation on the left.
}}

==See also==

* [[Classical mechanics]]
* [[Statistical mechanics]]
* [[Liouville's theorem (Hamiltonian)|Liouville's theorem]]
* [[Quantum mechanics]]
* [[Phase space formulation|Phase space formulation of quantum mechanics]]
* [[Wigner quasiprobability distribution]]
* [[Dynamical systems]]
* [[Ergodic theory]]

==References==
{{reflist|30em}}

==Further reading==
* {{Cite arXiv | last=Mauro | first=D. | title=Topics in Koopman–von Neumann Theory | year=2002 | eprint=quant-ph/0301172 }} PhD thesis, Università degli Studi di Trieste.
* H.R. Jauslin, D. Sugny, [http://icb.u-bourgogne.fr/omr/dqnl/sugny/files/MHQP-LN-Jauslin.pdf Dynamics of mixed classical-quantum systems, geometric quantization and coherent states], Lecture Note Series, IMS, NUS, Review Vol., August 13, 2009
* The Legacy of John von Neumann (Proceedings of Symposia in Pure Mathematics, vol 50), ''edited by James Glimm, John Impagliazzo, Isadore Singer''. — Amata Graphics, 2006. — {{ISBN|0821842196}}

{{DEFAULTSORT:Koopman von-Neumann wavefunction}}
[[Category:Classical mechanics]]
[[Category:Concepts in physics]]
[[Category:Mathematical physics]]
[[Category:Articles containing video clips]]</text>
      <sha1>lt9ylzpwqzksu2h115queiwo8wpzar1</sha1>
    </revision>
  </page>
  <page>
    <title>Középiskolai Matematikai és Fizikai Lapok</title>
    <ns>0</ns>
    <id>19287170</id>
    <revision>
      <id>822470251</id>
      <parentid>804261725</parentid>
      <timestamp>2018-01-26T15:26:29Z</timestamp>
      <contributor>
        <username>NewYorkActuary</username>
        <id>26033934</id>
      </contributor>
      <comment>no need for a template here</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1269">{{italic title}}
'''''Középiskolai Matematikai és Fizikai Lapok''''' [''Mathematical and Physical Journal for Secondary Schools''] ('''''KöMaL''''') is a Hungarian [[mathematics]] and [[physics]] journal for [[high school]] students. It was founded by Dániel Arany, a high school teacher from [[Győr]], Hungary and has been continually published since 1893.

KöMaL has been organizing various renowned correspondence competitions for high school students, making a major contribution to Hungarian high school education. Since the early 1970s, all of the problems in the ''KöMaL'' journal have been translated into English; published solutions, however, are not typically translated.  A 100-year archive of issues is provided online.

The journal has been a source of inspiration for the [[United States of America Mathematical Talent Search]].&lt;ref name="website1"&gt;{{cite web|url=http://www.usamts.org/About/U_AbHist.php|title=History|publisher=USAMTS}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* [http://www.komal.hu/info/bemutatkozas.e.shtml ''KöMaL'' homepage]
* [http://www.komal.hu/info/miazakomal.e.shtml What is ''KöMaL''?]

{{DEFAULTSORT:Kozepiskolai Matematikai Es Fizikai Lapok}}
[[Category:Mathematics journals]]


{{math-journal-stub}}</text>
      <sha1>0su6dodqmgllos7d0bibnr8uelhhs4l</sha1>
    </revision>
  </page>
  <page>
    <title>Language equation</title>
    <ns>0</ns>
    <id>8031241</id>
    <revision>
      <id>799381780</id>
      <parentid>772281416</parentid>
      <timestamp>2017-09-07T11:14:27Z</timestamp>
      <contributor>
        <ip>141.76.60.251</ip>
      </contributor>
      <comment>/* Language equations and finite automata */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8542">'''Language equations''' are mathematical statements that resemble [[equation|numerical equations]], but the variables assume values of [[formal languages]] rather than numbers. Instead of arithmetic operations in numerical equations, the variables are joined by language operations. Among the most common operations on two languages ''A'' and ''B'' are the [[set union]] ''A'' ∪ ''B'', the [[set intersection]] ''A'' ∩ ''B'', and the [[Concatenation#Concatenation_of_sets_of_strings|concatenation]] ''A''⋅''B''. Finally, as an operation taking a single [[operand]], the set ''A''&lt;sup&gt;*&lt;/sup&gt; denotes the [[Kleene star]] of the language ''A''. Therefore language equations can be used to represent [[formal grammar]]s, since the languages generated by the grammar must be the solution of a system of language equations.

==Language equations and context-free grammars==

[[Seymour Ginsburg|Ginsburg]] and [[Henry Gordon Rice|Rice]]&lt;ref name="GinsburgRice1962"&gt;{{cite journal|last1=Ginsburg|first1=Seymour|last2=Rice|first2=H. Gordon|title=Two Families of Languages Related to ALGOL|journal=Journal of the ACM|volume=9|issue=3|year=1962|pages=350–371|issn=00045411|doi=10.1145/321127.321132}}&lt;/ref&gt;
gave an alternative definition of [[context-free grammar]]s by language equations. To every context-free grammar &lt;math&gt;G = (V, \Sigma, R, S)&lt;/math&gt;, is associated a system of equations in variables &lt;math&gt;V&lt;/math&gt;. Each variable &lt;math&gt;X \in V&lt;/math&gt; is an unknown language over &lt;math&gt;\Sigma&lt;/math&gt; and is defined by equation &lt;math&gt;X=\alpha_1 \cup \ldots \cup \alpha_m&lt;/math&gt; where &lt;math&gt;X \to \alpha_1&lt;/math&gt;, ..., &lt;math&gt;X \to \alpha_m&lt;/math&gt; are all productions for &lt;math&gt;X&lt;/math&gt;. Ginsburg and Rice used a [[fixed-point iteration]] argument to show that a solution always exists, and proved that the assignment &lt;math&gt;X=L_G(X)&lt;/math&gt; is the ''least solution'' to this system, i.e. any other solution must be a componentwise subset of this one.

Language equations with added intersection analogously correspond to [[conjunctive grammars]].

==Language equations and finite automata==

[[Janusz Brzozowski (computer scientist)|Brzozowski]] and Leiss&lt;ref name="BrzozowskiLeiss1980"&gt;{{cite journal|last1=Brzozowski|first1=J.A.|last2=Leiss|first2=E.|title=On equations for regular languages, finite automata, and sequential networks|journal=Theoretical Computer Science|volume=10|issue=1|year=1980|pages=19–35|issn=03043975|doi=10.1016/0304-3975(80)90069-9}}&lt;/ref&gt; studied ''left language equations'' where every concatenation is with a singleton constant language on the left, e.g. &lt;math&gt;\{a\} \cdot X&lt;/math&gt; with variable &lt;math&gt;X&lt;/math&gt;, but not &lt;math&gt;X \cdot Y&lt;/math&gt; nor &lt;math&gt;X \cdot \{a\}&lt;/math&gt;. Each equation is of the form &lt;math&gt;X_i=F(X_1, ..., X_k)&lt;/math&gt; with one variable on the right-hand side. Every [[nondeterministic finite automaton]] has such corresponding equation using left-concatenation and union, see Fig. 1. If intersection operation is allowed, equations correspond to [[alternating finite automaton|alternating finite automata]].

[[File:DFAexample.svg|thumb|Fig. 1: A [[finite automaton]] with associated system of equations &lt;math&gt;S_1 = 1 S_1 \cup 0 S_2&lt;/math&gt;, &lt;math&gt;S_2 = 1 S_2 \cup 0 S_1 \cup \{\epsilon\}&lt;/math&gt; where &lt;math&gt;\epsilon&lt;/math&gt; is the empty word.]]

[[Franz Baader|Baader]] and Narendran&lt;ref name="BaaderNarendran2001"&gt;{{cite journal|last1=Baader|first1=Franz|last2=Narendran|first2=Paliath|title=Unification of Concept Terms in Description Logics|journal=Journal of Symbolic Computation|volume=31|issue=3|year=2001|pages=277–305|issn=07477171|doi=10.1006/jsco.2000.0426}}&lt;/ref&gt; studied equations &lt;math&gt;F(X_1, \ldots, X_k)=G(X_1, \ldots, X_k)&lt;/math&gt; using left-concatenation and union and proved that their satisfiability problem is [[EXPTIME-complete]].

==Conway's problem==

[[John Horton Conway|Conway]]&lt;ref&gt;{{cite book | last1=Conway | first1=John Horton | title=Regular Algebra and Finite Machines | publisher=Chapman and Hall | isbn=978-0-486-48583-6 | year=1971}}&lt;/ref&gt; proposed the following problem: given a constant finite language &lt;math&gt;L&lt;/math&gt;, is the greatest solution of equation &lt;math&gt;LX=XL&lt;/math&gt; always regular? This problem was studied by [[Juhani Karhumäki|Karhumäki]] and Petre&lt;ref name="KarhumäkiPetre2002a"&gt;{{cite journal|last1=Karhumäki|first1=Juhani|last2=Petre|first2=Ion|title=Conway's problem for three-word sets|journal=Theoretical Computer Science|volume=289|issue=1|year=2002|pages=705–725|issn=03043975|doi=10.1016/S0304-3975(01)00389-9}}&lt;/ref&gt;&lt;ref name="KarhumäkiPetre2002b"&gt;{{cite journal|last1=Karhumäki|first1=Juhani|last2=Petre|first2=Ion|title=The Branching Point Approach to Conway’s Problem|volume=2300|year=2002|pages=69–76|issn=0302-9743|doi=10.1007/3-540-45711-9_5}}&lt;/ref&gt; who gave an affirmative answer in a special case. A strongly negative answer to Conway's problem was given by [[Michal Kunc|Kunc]]&lt;ref name="Kunc2007"&gt;{{cite journal|last1=Kunc|first1=Michal|title=The Power of Commuting with Finite Sets of Words|journal=Theory of Computing Systems|volume=40|issue=4|year=2007|pages=521–551|issn=1432-4350|doi=10.1007/s00224-006-1321-z}}&lt;/ref&gt; who constructed a finite language &lt;math&gt;L&lt;/math&gt; such that the greatest solution of this equation is not recursively enumerable.

Kunc&lt;ref name="Kunc2005"&gt;{{cite journal|last1=Kunc|first1=Michal|title=Regular solutions of language inequalities and well quasi-orders|journal=Theoretical Computer Science|volume=348|issue=2-3|year=2005|pages=277–293|issn=0304-3975|doi=10.1016/j.tcs.2005.09.018}}&lt;/ref&gt; also proved that the greatest solution of inequality &lt;math&gt;LX \subseteq XL&lt;/math&gt; is always regular.

==Language equations with Boolean operations==

Language equations with concatenation and Boolean operations were first studied by [[Rohit Parikh|Parikh]], [[Ashok K. Chandra|Chandra]], [[Joseph Halpern|Halpern]] and [[Albert R. Meyer|Meyer]]
&lt;ref name="ParikhChandra1985"&gt;{{cite journal|last1=Parikh|first1=Rohit|last2=Chandra|first2=Ashok|last3=Halpern|first3=Joe|last4=Meyer|first4=Albert|title=Equations between Regular Terms and an Application to Process Logic|journal=SIAM Journal on Computing|volume=14|issue=4|year=1985|pages=935–942|issn=0097-5397|doi=10.1137/0214066}}&lt;/ref&gt; who proved that the satisfiability problem for a given equation is undecidable, and that if a system of language equations has a unique solution, then that solution is recursive. Later, [[Alexander Okhotin|Okhotin]]&lt;ref name="Okhotin2010"&gt;{{cite journal|last1=Okhotin|first1=Alexander|title=Decision problems for language equations|journal=Journal of Computer and System Sciences|volume=76|issue=3-4|year=2010|pages=251–266|issn=00220000|doi=10.1016/j.jcss.2009.08.002}}&lt;/ref&gt; proved that the unsatisfiability problem is [[RE-complete]] and that every recursive language is a unique solution of some equation.

==Language equations over a unary alphabet==

For a one-letter alphabet, Leiss&lt;ref name="Leiss1994"&gt;{{cite journal|last1=Leiss|first1=E.L.|title=Unrestricted complementation in language equations over a one-letter alphabet|journal=Theoretical Computer Science|volume=132|issue=1-2|year=1994|pages=71–84|issn=0304-3975|doi=10.1016/0304-3975(94)90227-5}}&lt;/ref&gt; discovered the first language equation with a nonregular solution, using complementation and concatenation operations. Later, Jeż&lt;ref name="Jeż2008"&gt;{{cite journal|last1=Jeż|first1=Artur|title=Conjunctive grammars generate non-regular unary languages|journal=International Journal of Foundations of Computer Science|volume=19|issue=03|year=2008|pages=597–615|issn=0129-0541|doi=10.1142/S012905410800584X}}&lt;/ref&gt; showed that non-regular unary languages can be defined by language equations with union, intersection and concatenation, equivalent to [[conjunctive grammar]]s. By this method Jeż and Okhotin&lt;ref name="JeżOkhotin2014"&gt;{{cite journal|last1=Jeż|first1=Artur|last2=Okhotin|first2=Alexander|title=Computational completeness of equations over sets of natural numbers|journal=Information and Computation|volume=237|year=2014|pages=56–94|issn=08905401|doi=10.1016/j.ic.2014.05.001}}&lt;/ref&gt; proved that every recursive unary language is a unique solution of some equation.

==See also==
* [[Boolean grammar]]
* [[Arden's Rule]]
* [[Set constraint]]

==References==
{{Reflist}}

==External links==
* [http://www.math.utu.fi/dlt2007/tale/ Workshop on Theory and Applications of Language Equations (TALE 2007)]

[[Category:Formal languages]]
[[Category:Equations]]

{{settheory-stub}}
{{comp-sci-theory-stub}}</text>
      <sha1>px2es0cacgyv201ww33r49ncve2t08t</sha1>
    </revision>
  </page>
  <page>
    <title>Lie algebra extension</title>
    <ns>0</ns>
    <id>45603435</id>
    <revision>
      <id>871162031</id>
      <parentid>865818403</parentid>
      <timestamp>2018-11-29T09:52:50Z</timestamp>
      <contributor>
        <ip>128.243.59.44</ip>
      </contributor>
      <comment>/* Semidirect product (groups) */ Minor corrections.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="99681">{{Lie groups}}
In the theory of [[Lie groups]], [[Lie algebra]]s and their [[Lie algebra representation|representation theory]], a '''Lie algebra extension''' {{math|'''e'''}} is an enlargement of a given Lie algebra {{math|'''g'''}} by another Lie algebra {{math|'''h'''}}. Extensions arise in several ways. There is the '''trivial extension''' obtained by taking a direct sum of two Lie algebras. Other types are the '''split extension''' and the '''central extension'''. Extensions may arise naturally, for instance, when forming a Lie algebra from [[Projective representation|projective group representations]]. Such a Lie algebra will contain [[central charge]]s.

Starting with a [[Loop algebra|polynomial loop algebra]] over finite-dimensional [[Simple Lie group|simple]] Lie algebra and performing two extensions, a central extension and an extension by a derivation, one obtains a Lie algebra which is isomorphic with an untwisted affine [[Kac–Moody algebra]]. Using the centrally extended loop algebra one may construct a [[current algebra]] in two spacetime dimensions. The [[Virasoro algebra]] is the universal central extension of the [[Witt algebra]].&lt;ref name="Bauerle_de_Kerf_1997"/&gt;

Central extensions are needed in physics, because the symmetry group of a quantized system usually is a central extension of the classical symmetry group, and in the same way the corresponding symmetry Lie algebra of the quantum system is, in general, a central extension of the classical symmetry algebra.&lt;ref&gt;{{harvnb|Schottenloher|2008|loc=Introduction}}&lt;/ref&gt; Kac–Moody algebras have been conjectured to be symmetry groups of a unified superstring theory.&lt;ref&gt;{{harvnb|Dolan|1995}} [http://www.ams.org/notices/199512/index.html The Beacon of Kac–Moody Symmetry for Physics. (free access)]&lt;/ref&gt; The centrally extended Lie algebras play a dominant role in [[quantum field theory]], particularly in [[conformal field theory]], [[string theory]] and in [[M-theory]].&lt;ref&gt;{{harvnb|Green|Schwarts|Witten|1987}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Schottenloher|2008}}&lt;/ref&gt;

A large portion towards the end is devoted to background material for applications of Lie algebra extensions, both in mathematics and in physics, in areas where they are actually useful. A parenthetical link, ([[#Background material|background material]]), is provided where it might be beneficial.

==History==
Due to the [[Lie correspondence]], the theory, and consequently the history of Lie algebra extensions, is tightly linked to the theory and history of group extensions. A systematic study of group extensions was performed by the Austrian mathematician [[Otto Schreier]] in 1923 in his PhD. thesis and later published.&lt;ref group=nb&gt;
[[Otto Schreier]] (1901 - 1929) was a pioneer in the theory of [[group extension|extension of groups]]. Along with his rich research papers, his lecture notes were posthumously published (edited by [[Emanuel Sperner]]) under the name ''Einführung in die analytische Geometrie und Algebra'' (Vol I 1931, Vol II 1935), later in 1951 translated to English in [https://www.amazon.com/Introduction-Modern-Algebra-Matrix-Theory/dp/0486482200 Introduction to Modern Algebra and Matrix Theory]. See {{harvnb|MacTutor|2015}} for further reference.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Schrier|1926}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Schrier|1925}}&lt;/ref&gt; The problem posed for his thesis  by [[Otto Hölder]] was "given two groups {{mvar|G}} and {{mvar|H}}, find all groups {{mvar|E}} having a normal subgroup {{mvar|N}} isomorphic to {{mvar|G}} such that the factor group {{math|''E''/''N''}} is isomorphic to {{mvar|H}}".

Lie algebra extensions are most interesting and useful for infinite-dimensional Lie algebras. In 1967, [[Victor Kac]] and [[Robert Moody]] independently generalized the notion of classical Lie algebras, resulting in a new theory of infinite-dimensional Lie algebras, now called [[Kac–Moody algebra]]s.&lt;ref&gt;{{harvnb|Kac|1967E}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Moody|1967}}&lt;/ref&gt; They generalize the finite-dimensional simple Lie algebras and can often concretely be constructed as extensions.&lt;ref name=Baurle_de_Kerf_19&gt;{{harvnb|Bäuerle|de Kerf|1997|loc=Chapter 19}}&lt;/ref&gt;

==Notation and proofs==
Notational abuse to be found below includes {{math|''e''&lt;sup&gt;''X''&lt;/sup&gt;}} for the [[exponential map (Lie theory)|exponential map]] {{math|exp}} given an argument, writing {{mvar|g}} for the element {{math|(''g'', ''e''&lt;sub&gt;''H''&lt;/sub&gt;)}} in a direct product {{math|''G'' × ''H''}} ({{math|''e''&lt;sub&gt;''H''&lt;/sub&gt;}} is the identity in {{mvar|H}}), and analogously for Lie algebra direct sums (where also {{math|''g'' + ''h''}} and {{math|(''g'', ''h'')}} are used interchangeably). Likewise for semidirect products and semidirect sums. Canonical injections (both for groups and Lie algebras) are used for implicit identifications. Furthermore, if {{math|''G''}}, {{math|''H''}}, ..., are groups, then the default names for elements of {{math|''G''}}, {{math|''H''}}, ..., are {{math|''g''}}, {{math|''h''}}, ..., and their Lie algebras are {{math|'''g'''}}, {{math|'''h'''}}, ... . The default names for elements of {{math|'''g'''}}, {{math|'''h'''}}, ..., are {{math|''G''}}, {{math|''H''}}, ... (just like for the groups!), partly to save scarce alphabetical resources but mostly to have a uniform notation.

Lie algebras that are ingredients in an extension will, without comment, be taken to be over the same [[field (mathematics)|field]].

The [[summation convention]] applies, including sometimes when the indices involved are both upstairs or both downstairs.

'''Caveat:''' Not all proofs and proof outlines below have universal validity. The main reason is that the Lie algebras are often infinite-dimensional, and then there may or may not be a Lie group corresponding to the Lie algebra. Moreover, even if such a group exists, it may not have the "usual" properties, e.g. the [[exponential map (Lie theory)|exponential map]] might not exist, and if it does, it might not have all the "usual" properties. In such cases, it is questionable whether the group should be endowed with the "Lie" qualifier. The literature is not uniform. For the explicit examples, the relevant structures are supposedly in place.

==Definition==
Lie algebra extensions are formalized in terms of short [[exact sequence]]s.&lt;ref name=Bauerle_de_Kerf_1997&gt;{{harvnb|Bäuerle|de Kerf|1997}}&lt;/ref&gt; A short exact sequence is an exact sequence of length three,
{{NumBlk|
:|&lt;math&gt;
 \mathfrak h \; \overset i \hookrightarrow \; \mathfrak e \; \overset s \twoheadrightarrow \; \mathfrak g,
&lt;/math&gt;|{{EquationRef|1}}}}
such that {{mvar|i}} is a [[monomorphism]], {{mvar|s}} is an [[epimorphism]], and {{math|ker ''s'' {{=}} im ''i''}}. From these properties of exact sequences, it follows that (the image of) {{math|'''h'''}} is an [[ideal (ring theory)|ideal]] in {{math|'''e'''}}. Moreover, 
:&lt;math&gt;
\mathfrak g \cong \mathfrak e/\operatorname{Im} i = \mathfrak e/ \operatorname{Ker} s,
&lt;/math&gt;
but it is not necessarily the case that {{math|'''g'''}} is isomorphic to a subalgebra of {{math|'''e'''}}. This construction mirrors the analogous constructions in the closely related concept of [[group extension]]s.

If the situation in {{EquationNote|(1)}} prevails, non-trivially and for Lie algebras over the same [[field (mathematics)|field]], then one says that {{math|'''e'''}} is an extension of {{math|'''g'''}} by {{math|'''h'''}}.

==Properties==
The defining property may be reformulated. The Lie algebra {{math|'''e'''}} is an extension of {{math|'''g'''}} by {{math|'''h'''}} if
{{NumBlk|
:|&lt;math&gt;
 0 \; \overset \iota \hookrightarrow \mathfrak h \; \overset i \hookrightarrow \; \mathfrak e \; \overset s \twoheadrightarrow \; \mathfrak g \; \overset \sigma \twoheadrightarrow \; 0
&lt;/math&gt;|{{EquationRef|2}}}}
is exact. Here the zeros on the ends represent the zero Lie algebra (containing the [[null vector]] {{math|∅}} only) and the maps are the obvious ones; {{math|''ί''}} maps {{math|∅}} to {{math|∅}} and {{math|''σ''}} maps all elements of {{math|'''g'''}} to {{math|∅}}. With this definition, it follows automatically that {{math|''i''}} is a monomorphism and {{math|''s''}} is an epimorphism.

An extension of {{math|'''g'''}} by {{math|'''h'''}} is not necessarily unique. Let {{math|'''e''', '''e&lt;nowiki&gt;'&lt;/nowiki&gt;'''}} denote two extensions and let the primes below have the obvious interpretation. Then, if there exists a Lie algebra isomorphism {{math|''f'':'''e''' → '''e'''&lt;nowiki&gt;'&lt;/nowiki&gt;}} such that
:&lt;math&gt;f \circ i = i', \quad s' \circ f = s,&lt;/math&gt;
[[File:Lie algebra extension figure 1.svg|center|200px]]
then the extensions {{math|'''e'''}} and {{math|'''e&lt;nowiki&gt;'&lt;/nowiki&gt;'''}} are said to be '''equivalent extensions'''. Equivalence of extensions is an [[equivalence relation]].

==Extension types==

===Trivial===
A Lie algebra extension
:&lt;math&gt;
 \mathfrak h \; \overset i \hookrightarrow \; \mathfrak t \; \overset s \twoheadrightarrow \; \mathfrak g,
&lt;/math&gt;
is '''trivial''' if there is a subspace {{math|'''i'''}} such that {{math|'''t''' {{=}} '''i''' ⊕ ker ''s''}} and {{math|'''i'''}} is an [[ideal (ring theory)|ideal]] in {{math|'''t'''}}.&lt;ref name=Bauerle_de_Kerf_1997/&gt;

===Split===
A Lie algebra extension
:&lt;math&gt;
 \mathfrak h \; \overset i \hookrightarrow \; \mathfrak s \; \overset s \twoheadrightarrow \; \mathfrak g,
&lt;/math&gt;
is '''split''' if there is a subspace {{math|'''u'''}} such that {{math|'''s''' {{=}} '''u''' ⊕ ker ''s''}} as a vector space and {{math|'''u'''}} is a subalgebra in {{math|'''s'''}}.

An ideal is a subalgebra, but a subalgebra is not necessarily and ideal. A trivial extension is thus a split extension.

===Central===
Central extensions of a Lie algebra {{math|'''g'''}} by an abelian Lie algebra {{math|'''a'''}} can be obtained with the help of a so-called (nontrivial) [[Wigner's theorem#Representations and projective representations|2-cocycle]] ([[#Cohomology|background]]) on {{math|'''g'''}}. Non-trivial 2-cocycles occur in the context of [[projective representation]]s ([[#Projective representation|background]]) of Lie groups. This is alluded to further down.

A Lie algebra extension
:&lt;math&gt;
 \mathfrak h \; \overset i \hookrightarrow \; \mathfrak c \; \overset s \twoheadrightarrow \; \mathfrak g,
&lt;/math&gt;
is a '''central extension''' if {{math|ker ''s''}} is contained in the [[center (algebra)|center]] {{math|''Z''('''c''')}} of {{math|'''c'''}}.

'''Properties'''
*Since the center commutes with everything, {{math|'''h''' ≅ im ''i'' {{=}} ker ''s''}} in this case is [[Lie algebra#Abelian.2C nilpotent.2C and solvable|abelian]].
*Given a central extension {{math|'''e'''}} of {{math|'''g'''}}, one may construct a 2-cocycle on {{math|'''g'''}}. Suppose {{math|'''e'''}} is a central extension of {{math|'''g'''}} by {{math|'''h'''}}. Let {{math|''l''}} be a linear map from {{math|'''g'''}} to {{math|'''e'''}} with the property that {{math|''s'' ∘ ''l'' {{=}} Id&lt;sub&gt;'''g'''&lt;/sub&gt;}}, i.e. {{math|''l''}} is a '''section''' of {{math|''s''}}. Use this section to define {{math|''ε'': '''g''' × '''g''' → '''e'''}} by
:&lt;math&gt;
\epsilon(G_1, G_2) = l([G_1, G_2]) - [l(G_1), l(G_2)], \quad G_1, G_2 \in \mathfrak g.
&lt;/math&gt;
[[File:Lie algebra extension figure 2.svg|center|200px]]
The map {{math|''ε''}} satisfies
:&lt;math&gt;
\epsilon(G_1, [G_2, G_3]) + \epsilon(G_2, [G_3, G_1]) + \epsilon(G_3, [G_1, G_2]) = 0 \in \mathfrak e.
&lt;/math&gt;
To see this, use the definition of {{math|''ε''}} on the left hand side, then use the linearity of {{math|''l''}}. Use Jacobi identity on {{math|'''g'''}} to get rid of half of the six terms. Use the definition of {{math|''ε''}} again on terms {{math|''l''[''G''&lt;sub&gt;''i''&lt;/sub&gt;,''G''&lt;sub&gt;''j''&lt;/sub&gt;]}} sitting inside three Lie brackets, bilinearity of Lie brackets, and the Jacobi identity on {{math|'''e'''}}, and then finally use on the three remaining terms that {{math|Im ''ε'' ⊂ ker ''s''}} and that {{math|ker ''s'' ⊂ ''Z''('''e''')}} so that {{math|''ε''(''G''&lt;sub&gt;''i''&lt;/sub&gt;, ''G''&lt;sub&gt;''j''&lt;/sub&gt;)}} brackets to zero with everything.
It then follows that {{math|''φ'' {{=}} ''i''&lt;sup&gt;−1&lt;/sup&gt; ∘ ε}} satisfies the corresponding relation, and if {{math|'''h'''}} in addition is one-dimensional, then {{math|''φ''}} is a 2-cocycle on {{math|'''g'''}} (via a trivial correspondence of {{math|'''h'''}} with the underlying field).

A central extension
:&lt;math&gt;
 0 \; \overset \iota \hookrightarrow \mathfrak h \; \overset i \hookrightarrow \; \mathfrak e \; \overset s \twoheadrightarrow \; \mathfrak g \; \overset \sigma \twoheadrightarrow \; 0
&lt;/math&gt;
is '''universal''' if for every other central extension
:&lt;math&gt;
 0 \; \overset \iota \hookrightarrow \mathfrak h' \; \overset {i'} \hookrightarrow \; \mathfrak e' \; \overset {s'} \twoheadrightarrow \; \mathfrak g \; \overset \sigma \twoheadrightarrow \; 0
&lt;/math&gt;
there exist ''unique'' homomorphisms &lt;math&gt; \Phi : \mathfrak e  \to  \mathfrak e'&lt;/math&gt; and &lt;math&gt; \Psi : \mathfrak h  \to  \mathfrak h'&lt;/math&gt; such that the diagram
[[File:Lie algebra extension figure 3.svg|center|400px]]
commutes, i.e. {{math|''i''&lt;nowiki&gt;'&lt;/nowiki&gt; ∘ Ψ {{=}} Φ ∘ ''i''}} and {{math|''s''&lt;nowiki&gt;'&lt;/nowiki&gt; ∘ Φ {{=}} ''s''}}. By universality, it is easy to conclude that such universal central extensions are unique up to isomorphism.

==Construction==

===By direct sum===
Let {{math|'''g''', '''h'''}} be Lie algebras over the same field {{math|''K''}}. Define
:&lt;math&gt;\mathfrak e = \mathfrak h \times \mathfrak g,&lt;/math&gt;
and define addition pointwise on {{math|'''e'''}}. Scalar multiplication is defined by
:&lt;math&gt;\alpha(H, G) = (\alpha H, \alpha G), \alpha \in F, H \in \mathfrak h, G \in \mathfrak g.&lt;/math&gt;
With these definitions, {{math|'''h''' × '''g''' ≡ '''h''' ⊕ '''g'''}} is a vector space over {{mvar|F}}. With the Lie bracket
{{NumBlk|:|:&lt;math&gt;[(H_1, G_1),(H_2, G_2)] = ([H_1, H_2],[G_1, G_2]),&lt;/math&gt;|{{EquationRef|3}}}}
{{math|'''e'''}} is a Lie algebra. Define further
:&lt;math&gt;i:\mathfrak h \hookrightarrow \mathfrak e; H \mapsto (H, 0), \quad s:\mathfrak e \twoheadrightarrow \mathfrak g; (H, G) \mapsto G.&lt;/math&gt;
It is clear that {{EquationNote|(1)}} holds as an exact sequence. This extension of {{math|'''g'''}} by {{math|'''h'''}} is called a '''trivial extension'''. It is, of course, nothing else than the Lie algebra direct sum. By symmetry of definitions, {{math|'''e'''}} is an extension of {{math|'''h'''}} by {{math|'''g'''}} as well, but {{math|'''h''' ⊕ '''g''' ≠ '''g''' ⊕ '''h'''}}. It is clear from {{EquationNote|(3)}} that the subalgebra {{math|0 ⊕ '''g'''}} is an [[ideal (Lie algebra)]]. This property of the direct sum of Lie algebras is promoted to the definition of a trivial extension.

===By semidirect sum===
Inspired by the construction of a semidirect product ([[#Semidirect product (groups)|background]]) of groups using a homomorphism {{math|''G'' → Aut(''H'')}}, one can make the corresponding construct for Lie algebras.

If {{math|''ψ'':'''g''' → der '''h'''}} is a Lie algebra homomorphism, then define a Lie bracket on {{math|'''e''' {{=}} '''h''' ⊕ '''g'''}} by
{{NumBlk|:|&lt;math&gt;[(H , G), (H' , G')] = ([H , H']  + \psi_G(H') - \psi_{G'}(H), [G , G']),\quad H,H' \in \mathfrak h, G, G' \in \mathfrak g.&lt;/math&gt;|{{EquationRef|7}}}}
With this Lie bracket, the Lie algebra so obtained is denoted {{math|'''e'''{{=}} '''h''' ⊕&lt;sub&gt;S&lt;/sub&gt; '''g'''}} and is called the '''semidirect sum''' of {{math|'''h'''}} and {{math|'''g'''}}.

By inspection of {{EquationNote|(7)}} one sees that {{math|0 ⊕ '''g'''}} is a subalgebra of {{math|'''e'''}} and {{math|'''h''' ⊕ 0}} is an ideal in {{math|'''e'''}}. Define {{math|''i'':'''h''' → '''e'''}} by {{math|''H'' ↦ ''H'' ⊕ 0}} and {{math|''s'':'''e''' → '''g'''}} by {{math|''H'' ⊕ ''G'' ↦ ''G'', ''H'' ∈ '''h''', ''G'' ∈ '''g'''}}. It is clear that {{math|ker ''s'' {{=}} im ''i''}}. Thus {{math|'''e'''}} is a Lie algebra extension of {{math|'''g'''}} by {{math|'''h'''}}.

As with the trivial extension, this property generalizes to the definition of a split extension.

'''Example'''&lt;br /&gt;
Let {{mvar|G}} be the [[Lorentz group]] {{math|O(3, 1)}} and let {{math|T}} denote the [[translation group]] in 4 dimensions, isomorphic to {{math|(ℝ&lt;sup&gt;4&lt;/sup&gt;, +)}}, and consider the multiplication rule of the [[Poincaré group]] {{math|P}}
:&lt;math&gt;(a_2, \Lambda_2)(a_1, \Lambda_1) = (a_2 + \Lambda_2a_1, \Lambda_2\Lambda_1), \quad a_1, a_2 \in \mathrm T \subset P, \Lambda_1, \Lambda_2 \in \mathrm O(3,1) \subset \mathrm P,&lt;/math&gt;
(where {{math|T}} and {{math|SO(3, 1)}} are identified with their images in {{math|P}}). From it follows immediately that, in the Poincaré group, {{math|(0, Λ)(''a'', ''I'')(0, Λ&lt;sup&gt;−1&lt;/sup&gt;) {{=}} (Λ ''a'', ''I'') ∈ T ⊂ P}}. Thus every Lorentz transformation {{math|Λ}} corresponds to an automorphism {{math|Φ&lt;sub&gt;Λ&lt;/sub&gt;}} of {{math|T}} with inverse {{math|Φ&lt;sub&gt;Λ&lt;sup&gt;−1&lt;/sup&gt;&lt;/sub&gt;}} and {{math|Φ}} is clearly a homomorphism. Now define
:&lt;math&gt;\overline \mathrm P = \mathrm T \otimes_S \mathrm O(3, 1),&lt;/math&gt;
endowed with multiplication given by {{EquationNote|(4)}}. Unwinding the definitions one finds that the multiplication is the same as the multiplication one started with and it follows that {{math|{{overline|P}} {{=}} P}}. From {{EquationNote|(5')}} follows that {{math|Ψ&lt;sub&gt;Λ&lt;/sub&gt; {{=}} Ad&lt;sub&gt;Λ&lt;/sub&gt;}} and then from {{EquationNote|(6')}} it follows that {{math|''ψ''&lt;sub&gt;''λ''&lt;/sub&gt; {{=}} ad&lt;sub&gt;''λ''&lt;/sub&gt;. ''λ'' ∈ '''o'''(3, 1)}}.

===By derivation===
Let {{math|''δ''}} be a derivation ([[#Derivations|background]]) of {{math|'''h'''}} and denote by {{math|'''g'''}} the one-dimensional Lie algebra spanned by {{math|''δ''}}. Define the Lie bracket on {{math|'''e''' {{=}} '''g''' ⊕ '''h'''}} by&lt;ref group=nb&gt;To show that the [[Jacobi identity]] holds, one writes everything out, uses the fact that the underlying Lie algebras have a Lie product satisfying the Jacobi identity, and that {{math|''δ''[''X'', ''Y''] {{=}} [''δ''(''X''), ''Y''] + [''X'', ''δ''(''Y'')]}}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Bäuerle|de Kerf|ten Kroode|1997|loc=Example 18.1.9}}&lt;/ref&gt;

:&lt;math&gt;[G_1 + H_1, G_2 + H_2] = [\lambda\delta + H_1, \mu\delta + H_2] = [H_1, H_2] + \lambda \delta(H_1) - \mu \delta(H_2).&lt;/math&gt;

It is obvious from the definition of the bracket that {{math|'''h'''}} is and ideal in {{math|'''e'''}} in and that {{math|'''g'''}} is a subalgebra of {{math|'''e'''}}. Furthermore, {{math|'''g'''}} is complementary to {{math|'''h'''}} in {{math|'''e'''}}. Let {{math|''i'':'''h''' → '''e'''}} be given by {{math|''H'' ↦ (0, ''H'')}} and {{math|''s'':'''e''' → '''g'''}} by {{math|(''G'', ''H'') ↦ ''G''}}. It is clear that {{math|im ''i'' {{=}} ker ''s''}}. Thus {{math|'''e'''}} is a split extension of {{math|'''g'''}} by {{math|'''h'''}}. Such an extension is called '''extension by a derivation'''.

If {{math|''ψ'': '''g''' → der '''h'''}} is defined by {{math|''ψ''(''μδ'')(''H'') {{=}} ''μδ''(''H'')}}, then {{mvar|ψ}} is a Lie algebra homomorphism into {{math|der '''h'''}}. Hence this construction is a special case of a semidirect sum, for when starting from {{mvar|ψ}} and using the construction in the preceding section, the same Lie brackets result.

===By 2-cocycle===
If {{math|''ε''}} is a 2-cocycle ([[#Cohomology|background]]) on a Lie algebra {{math|'''g'''}} and {{math|'''h'''}} is any one-dimensional vector space, let {{math|'''e''' {{=}} '''h''' ⊕  '''g'''}} (vector space direct sum) and define a Lie bracket on {{math|'''e'''}} by
:&lt;math&gt;
[\mu H + G_1, \nu H + G_2] = [G_1, G_2] + \epsilon(G1, G2)H, \quad \mu, \nu \in F.
&lt;/math&gt;

Here {{mvar|H}} is an arbitrary but fixed element of {{math|'''h'''}}. Antisymmetry follows from antisymmetry of the Lie bracket on {{math|'''g'''}} and antisymmetry of the 2-cocycle. The Jacobi identity follows from the corresponding properties of {{math|'''g'''}} and of {{math|''ε''}}. Thus {{math|'''e'''}} is a Lie algebra. Put {{math|''G''&lt;sub&gt;1&lt;/sub&gt; {{=}} 0}} and it follows that {{math|''μH'' ∈ ''Z''('''e''')}}. Also, it follows with {{math|''i'': ''μH'' ↦ (''μH'', 0)}} and {{math|''s'': (''μH'', ''G'') ↦ ''G''}} that {{math|Im ''i'' {{=}} ker ''s'' {{=}} &lt;nowiki&gt;{&lt;/nowiki&gt;(''μH'', 0):''μ'' ∈ ''F''&lt;nowiki&gt;}&lt;/nowiki&gt; ⊂ Z('''e''')}}. Hence {{math|'''e'''}} is a central extension of {{math|'''g'''}} by {{math|''h''}}. It is called '''extension by a 2-cocycle'''.

==Theorems==
Below follows some results regarding central extensions and 2-cocycles.&lt;ref&gt;{{harvnb|Bäurle|de Kerf|1990|loc=Chapter 18}}&lt;/ref&gt;

'''Theorem'''&lt;ref name=Bauerle_de_Kerf_1997/&gt;&lt;br /&gt;
Let {{math|''φ''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''φ''&lt;sub&gt;2&lt;/sub&gt;}} be cohomologous 2-cocycles on a Lie algebra {{math|'''g'''}} and let {{math|'''e'''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|'''e'''&lt;sub&gt;2&lt;/sub&gt;}} be respectively the central extensions constructed with these 2-cocycles. Then the central extensions {{math|'''e'''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|'''e'''&lt;sub&gt;2&lt;/sub&gt;}} are equivalent extensions.&lt;br /&gt;
'''Proof'''&lt;br /&gt;
By definition, {{math|''φ''&lt;sub&gt;2&lt;/sub&gt; {{=}} ''φ''&lt;sub&gt;1&lt;/sub&gt; + ''δf''}}. Define
:&lt;math&gt;
\psi: G + \mu c \in \mathfrak{e}_1 \mapsto G + \mu c + f(G)c \in \mathfrak{e}_2.&lt;/math&gt;
It follows from the definitions that {{mvar|ψ}} is a Lie algebra isomorphism and {{EquationNote|(2)}} holds.

'''Corollary'''&lt;br /&gt;
A cohomology class {{math|[''Φ''] ∈ ''H''&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}} defines a central extension of {{math|'''g'''}} which is unique up to isomorphism.

The trivial 2-cocycle gives the trivial extension, and since a 2-coboundary is cohomologous with the trivial 2-cocycle, one has &lt;br /&gt;
'''Corollary'''&lt;br /&gt;
A central extension defined by a coboundary is equivalent with a trivial central extension.

'''Theorem'''&lt;br&gt;
A finite-dimensional simple Lie algebra has only trivial central extensions.&lt;br&gt;
'''Proof'''&lt;br&gt;
Since every central extension comes from a 2-cocycle {{math|''φ''}}, it suffices to show that every 2-cocycle is a coboundary. Suppose {{math|''φ''}} is a 2-cocycle on {{math|'''g'''}}. The task is to use this 2-cocycle to manufacture a 1-cochain {{mvar|f}} such that {{math|''φ'' {{=}} ''δf''}}.

The first step is to for each {{math|''G''&lt;sub&gt;''G''&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; ∈ '''g'''}} use {{mvar|φ}} to define a linear map {{math|''ρ''&lt;sub&gt;''G''&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;:'''g''' → ''F''}}. But the linear maps are elements of {{math|'''g'''&lt;sup&gt;∗&lt;/sup&gt;}}. This suffices to express {{mvar|φ}} in terms of {{math|''K''}}, using the isomorphism {{mvar|ν}}. Next, a linear map {{math|''d'':'''g''' → '''g'''}} is defined that turns out to be a derivation. Since all derivations are inner, one has {{math|''d'' {{=}} ad&lt;sub&gt;''G''&lt;sub&gt;''d''&lt;/sub&gt;&lt;/sub&gt;}} for some {{math|''G''&lt;sub&gt;''d''&lt;/sub&gt; ∈ '''g'''}}. An expression for {{mvar|φ}} in terms of {{math|''K''}} and {{math|''d''}} is obtained. Thus set, trusting that {{mvar|d}} is a derivation,
:&lt;math&gt;\varphi(G_1, G_2) \equiv \rho_{G_1}(G_2) = K(\nu^{-1}(\rho_{G_1}), G_2) \equiv K(d(G_1), G_2) = K(\mathrm{ad}_{G_d}(G_1), G_2) = K([G_d, G_1], G_2) = K(G_d, [G_1, G_2]).&lt;/math&gt;

Let {{mvar|f}} be the 1-cochain defined by
:&lt;math&gt;f(G) = K(G_d,G).&lt;/math&gt;
Then
:&lt;math&gt;\delta f(G_1, G_2) = f([G_1, G_2]) = K(G_d,[G_1, G_2]) = \varphi(G_1, G_2),&lt;/math&gt;
showing that {{math|''φ''}} is a coboundary. By the previous results, any central extension is trivial.
{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=Proof of {{mvar|d}} being a derivation}}
To verify that {{mvar|d}} actually is a derivation, first note that it is linear since {{mvar|ν}} is, then compute
:&lt;math&gt;\begin{align}K(d([G_1, G_2]), G_3)) &amp;= \varphi([G_1, G_2]), G_3)) = \varphi(G_1,[G_2, G_3]) + \varphi(G_2, [G_3, G_1])\\
                                           &amp;= K(d(G_1),[G_2, G_3]) + K(d(G_1), (G_3, G_1)) = K([d(G_1),G_2], G_3) + K([G_1, d(G_2)], G_3))\\
                                           &amp;= K([d(G_1), G_2] + [G_1, d(G_2)], G_3).\end{align}&lt;/math&gt;
By appeal to the non-degeneracy of {{mvar|K}}, the left arguments of {{mvar|K}} are equal on the far left and far right.
{{Hidden end}}
The observation that one can define a derivation {{math|''d''}}, given a symmetric non-degenerate associative form {{mvar|K}} and a 2-cocycle {{mvar|φ}}, by
:&lt;math&gt;K(\nu^{-1}(\rho_{G_1}), G_2) \equiv K(d(G_1), G_2),&lt;/math&gt;
or using the symmetry of {{math|''K}} and the antisymmetry of {{mvar|φ}},
:&lt;math&gt;K(d(G_1), G_2) = -K(G_1, d(G_2)),&lt;/math&gt;
leads to a corollary.

'''Corollary'''&lt;br&gt;
Let {{mvar|L:'''g''' × '''g'': → ''F''}} be a non-degenerate symmetric associative bilinear form and let {{mvar|d}} be a derivation satisfying
:&lt;math&gt;L(d(G_1), G_2) = -L(G_1, d(G_2)),&lt;/math&gt;
then {{mvar|φ}} defined by
:&lt;math&gt;\varphi(G_1, G_2) = L(d(G_1), G_2)&lt;/math&gt;
is a 2-cocycle.

'''Proof'''
The condition on {{mvar|d}} ensures the antisymmetry of {{mvar|φ}}. The Jacobi identity for 2-cocycles follows starting with
:&lt;math&gt;\varphi([G1, G_2], G_3) = L(d[G1, G_2], G_3) = L([d(G1), G_2], G_3) + L([G1, d(G_2)], G_3),&lt;/math&gt;
using symmetry of the form, the antisymmetry of the bracket, and once again the definition of {{mvar|φ}} in terms of {{mvar|L}}.

If {{math|'''g'''}} is the Lie algebra of a Lie group {{math|''G''}} and {{math|'''e'''}} is a central extension of {{math|'''g'''}}, one may ask whether there is a Lie group {{math|''E''}} with Lie algebra {{math|'''e'''}}. The answer is, by [[Lie's third theorem]] affirmative. But is there a ''central extension'' {{math|''E''}} of {{math|''G''}} with Lie algebra {{math|'''e'''}}? The answer to this question requires some machinery, and can be found in {{harvtxt|Tuynman|Wiegerinck|1987|loc=Theorem 5.4}}.

==Applications==
The "negative" result of the preceding theorem indicates that one must, at least for semisimple Lie algebras, go to infinite-dimensional Lie algebras to find useful applications of central extensions. There are indeed such. Here will be presented affine Kac–Moody algebras and Virasoro algebras. These are extensions of polynomial loop-algebras and the Witt algebra respectively.

===Polynomial loop-algebra===
Let {{math|'''g'''}} be a polynomial loop algebra ([[#Loop algebra|background]]),
:&lt;math&gt;\mathfrak g = C[\lambda, \lambda^{-1}] \otimes \mathfrak g_0,&lt;/math&gt;
where {{math|'''g'''&lt;sub&gt;0&lt;/sub&gt;}} is a complex finite-dimensional simple Lie algebra. The goal is to find a central extension of this algebra. Two of the theorems apply. On the one hand, if there is a 2-cocycle on {{math|'''g'''}}, then a central extension may be defined. On the other hand, if this 2-cocycle is acting on the {{math|'''g'''&lt;sub&gt;0&lt;/sub&gt;}} part (only), then the resulting extension is trivial. Moreover, derivations acting on {{math|'''g'''&lt;sub&gt;0&lt;/sub&gt;}} (only) cannot be used for definition of a 2-cocycle either because these derivations are all inner and the same problem results. One therefore looks for derivations on {{math|''C''[''λ'', ''λ''&lt;sup&gt;−1&lt;/sup&gt;]}}. One such set of derivations is 
:&lt;math&gt;d_k \equiv \lambda^{k+1}\frac{d}{dk}, \quad k \in \mathbb Z.&lt;/math&gt;

In order to manufacture a non-degenerate bilinear associative antisymmetric form {{math|''L''}} on {{math|'''g'''}}, attention is focused first on restrictions on the arguments, with {{math|''m'', ''n''}} fixed. It is a theorem that ''every'' form satisfying the requirements is a multiple of the Killing form {{mvar|K}} on {{math|'''g'''&lt;sub&gt;0&lt;/sub&gt;}}.&lt;ref&gt;{{harvnb|Bäurle|de Kerf|1997}} Corollary 22.2.9.&lt;/ref&gt; This requires
:&lt;math&gt;L(\lambda^l \otimes G_1, \lambda^m \otimes G_2) = \gamma_{lm}K(G_1, G_2).&lt;/math&gt;
Symmetry of {{mvar|K}} implies
:&lt;math&gt;\gamma_{mn}=\gamma_{nm},&lt;/math&gt;
and associativity yields
:&lt;math&gt;\gamma_{k+l,m}=\gamma_{k,l+m}.&lt;/math&gt;
With {{math|''l'' {{=}} 0}} one sees that {{math|''γ''&lt;sub&gt;''lm''&lt;/sub&gt; {{=}} ''γ''&lt;sub&gt;0,''l''+''m''&lt;/sub&gt;}}. This last condition implies the former. Using this fact, define {{math|''f''(''n'') {{=}} ''γ''&lt;sub&gt;0,''n''&lt;/sub&gt;}}. The defining equation then becomes
:&lt;math&gt;L(\lambda^m \otimes G_1, \lambda^m \otimes G_2) = f(l+m)K(G_1, G_2).&lt;/math&gt;
For every {{math|''i'' ∈ ℤ}} the definition
:&lt;math&gt;f(n) = \delta_{ni} \Leftrightarrow \gamma_{lm}=\delta_{l+m, i}&lt;/math&gt;
does define a symmetric associative bilinear form
:&lt;math&gt;L_i(\lambda^l \otimes G_1, \lambda^m \otimes G_2) = \delta_{l+m,i}K(G_1, G_2).&lt;/math&gt;
But these forms the basis of a vector space in which every form has the right properties.

Returning to the derivations at hand and the condition
:&lt;math&gt;L_i(d_k(\lambda^l \otimes G_1), \lambda^m \otimes G_2) = -L_i(\lambda^l \otimes G_1, d_k(\lambda^m \otimes G_2)),&lt;/math&gt;
one sees, using the definitions, that
:&lt;math&gt;l\delta_{k+l+m,i} = -m\delta_{k+l+m,i},&lt;/math&gt;
or, with {{math|''n'' {{=}} ''l'' + ''m''}},
:&lt;math&gt;n\delta_{k+n,i} = 0.&lt;/math&gt;
This (and the antisymmetry condition) holds if {{math|''k'' {{=}} ''i''}}, in particular it holds when {{math|''k'' {{=}} ''i'' {{=}} 0}}.

Thus chose {{math|''L'' {{=}} ''L''&lt;sub&gt;0&lt;/sub&gt;}} and {{math|''d'' {{=}} ''d''&lt;sub&gt;0&lt;/sub&gt;}}. With these choices, the premises in the corollary are satisfied. The 2-cocycle {{mvar|φ}} defined by
:&lt;math&gt;\varphi(P(\lambda) \otimes G_1), Q(\lambda) \otimes G_2)) = L(\lambda\frac{dP}{d\lambda} \otimes G_1, Q(\lambda) \otimes G_2)&lt;/math&gt;
is finally employed to define a central extension of {{math|'''g'''}},
:&lt;math&gt;\mathfrak e = \mathfrak g \oplus \mathbb CC,&lt;/math&gt;
with Lie bracket
:&lt;math&gt;[P(\lambda) \otimes G_1 + \mu C, Q(\lambda) \otimes G_2 + \nu C] = P(\lambda)Q(\lambda)\otimes[G_1, G_2] + \varphi(P(\lambda) \otimes G_1,Q(\lambda) \otimes G_2)C.&lt;/math&gt;
For basis elements, suitably normalized and with antisymmetric structure constants, one has
:&lt;math&gt;\begin{align}{}[\lambda^l \otimes G_i + \mu C, \lambda^m \otimes G_j + \nu C] &amp;= \lambda^{l+m}\otimes[G_i, G_j] + \varphi(\lambda^l \otimes G_i,\lambda^m \otimes G_j)C\\
&amp;= \lambda^{l+m}\otimes {C_{ij}}^kG_k + L(\lambda \frac{d\lambda^l}{d\lambda} \otimes G_i, \lambda^m \otimes G_j)C\\
&amp;=\lambda^{l+m}\otimes {C_{ij}}^kG_k + lL(\lambda^l \otimes G_i, \lambda^m \otimes G_j)C\\
&amp;=\lambda^{l+m}\otimes {C_{ij}}^kG_k + l\delta_{l+m, 0}K(G_i,  G_j)C\\
&amp;=\lambda^{l+m}\otimes {C_{ij}}^kG_k + l\delta_{l+m, 0}{C_{ik}}^m{C_{jm}}^kC = \lambda^{l+m}\otimes {C_{ij}}^kG_k + l\delta_{l+m, 0}\delta^{ij}C.
\end{align}
&lt;/math&gt;
This is a universal central extension of the polynomial loop algebra.&lt;ref&gt;{{harvnb|Kac|1990}} Exercise 7.8.&lt;/ref&gt;

'''A note on terminology'''
In physics terminology, the algebra of above might pass for a Kac–Moody algebra, whilst it will probably not in mathematics terminology. An additional dimension, an extension by a derivation is required for this. Nonetheless, if, in a physical application, the eigenvalues of {{math|'''g'''&lt;sub&gt;0&lt;/sub&gt;}} or its representative are interpreted as (ordinary) [[quantum number]]s, the additional superscript on the generators is referred to as the '''level'''. It is an additional quantum number. An additional operator whose eigenvalues are precisely the levels is introduced further below.

===Current algebra===
[[File:Murray Gell-Mann - World Economic Forum Annual Meeting 2012.jpg|180px|thumb|right|[[Murray Gell-Mann]], 1969 [[Nobel Laureate]] in physics, initiated the field of current algebra in the 1960s. It exploits known local symmetries even without knowledge of the underlying dynamics to extract predictions, e.g. the '''Adler–Weisberger sum rule'''.]]
{{main|Current algebra}}
As an application of a central extension of polynomial loop algebra, a [[current algebra]] of a quantum field theory is considered ([[#Current algebra (physics)|background]]). Suppose one has a current algebra, with the interesting commutator being
{{NumBlk|:|&lt;math&gt;[J_a^0(t, \mathbf x), J_b^i(t, \mathbf y)] = i{C_{ab}}^cJ_c^i(t, \mathbf x)\delta(\mathbf x - \mathbf y) + S_{ab}^{ij}\partial_j\delta(\mathbf x - \mathbf y) + ... ,&lt;/math&gt;|{{EquationRef|CA10}}}}
with a Schwinger term. To construct this algebra mathematically, let {{math|'''g'''}} be the centrally extended polynomial loop algebra of the previous section with
:&lt;math&gt;[\lambda^l \otimes G_i + \mu C, \lambda^m \otimes G_j + \nu C] = \lambda^{l+m}\otimes {C_{ij}}^kG_k + l\delta_{l+m, 0}\delta_{ij}C&lt;/math&gt;
as one of the commutation relations, or, with a switch of notation ({{math|''l''→''m'', ''m''→''n'', ''i''→''a'', ''j''→''b'', ''λ''&lt;sup&gt;''m''&lt;/sup&gt;⊗''G''&lt;sub&gt;''a''&lt;/sub&gt;→''T''&lt;sup&gt;''m''&lt;/sup&gt;&lt;sub&gt;''a''&lt;/sub&gt;}}) with a factor of {{math|''i''}} under the physics convention,&lt;ref group=nb name=physics_convention/&gt;
:&lt;math&gt;[T^m_a, T^n_b] = i{C_{ab}}^cT^{m+n}_c + m\delta_{m+n, 0}\delta_{ab}C.&lt;/math&gt;

Define using elements of {{math|'''g'''}},
:&lt;math&gt;J_a(x) = \frac{\hbar}{L}\sum_{n=-\infty}^{\infty}e^{\frac{2\pi inx}{L}}T_a^{-n}, x \in \mathbb R.&lt;/math&gt;
One notes that
:&lt;math&gt;J_a(x+L) = J_a(x)&lt;/math&gt;
so that it is defined on a circle. Now compute the commutator,
:&lt;math&gt;\begin{align}[] [J_a(x),J_b(y)]&amp;= \left(\frac{\hbar}{L}\right)^2\left[\sum_{n=-\infty}^{\infty}e^{\frac{2\pi inx}{L}}T_a^{-n}, \sum_{m=-\infty}^{\infty}e^{\frac{2\pi imy}{L}}T_b^{-m}\right]\\
&amp;=\left(\frac{\hbar}{L}\right)^2 \sum_{m,n=-\infty}^{\infty} e^{\frac{2\pi inx}{L}} e^{\frac{2\pi imy}{L}} [T_a^{-n},T_b^{-m}].\end{align}&lt;/math&gt;

For simplicity, switch coordinates so that {{math|''y'' → 0, ''x'' → ''x'' − ''y'' ≡ ''z''}} and use the commutation relations,
:&lt;math&gt;\begin{align}[] [J_a(z),J_b(0)] &amp;= \left(\frac{\hbar}{L}\right)^2\sum_{m,n=-\infty}^{\infty} e^{\frac{2\pi inz}{L}}[i{C_{ab}}^cT^{-m-n}_c + m\delta_{m+n, 0}\delta_{ab}C]\\
&amp;=\left(\frac{\hbar}{L}\right)^2\sum_{m=-\infty}^{\infty} e^{\frac{2\pi i(-m)z}{L}}\sum_{l=-\infty}^\infty ie^{\frac{2\pi i(l)z}{L}}{C_{ab}}^cT^{-l}_c + \left(\frac{\hbar}{L}\right)^2\sum_{m,n=-\infty}^{\infty}e^{\frac{2\pi inz}{L}}m\delta_{m+n, 0}\delta_{ab}C\\

&amp;=\left(\frac{\hbar}{L}\right)\sum_{m=-\infty}^{\infty} e^{\frac{2\pi imz}{L}}i{C_{ab}}^cJ_c(z) - \left(\frac{\hbar}{L}\right)^2\sum_{n=-\infty}^{\infty}e^{\frac{2\pi inz}{L}}n\delta_{ab}C\end{align}&lt;/math&gt;

Now employ the [[Poisson summation formula]],
:&lt;math&gt;\frac{1}{L}\sum_{n=-\infty}^\infty e^{\frac{-2\pi inz}{L}} = \frac{1}{L}\sum_{n=-\infty}^\infty \delta(z + nL) = \delta(z)&lt;/math&gt;
for {{mvar|z}} in the interval {{math|(0, L)}} and differentiate it to yield
:&lt;math&gt;-\frac{2\pi i}{L^2}\sum_{n=-\infty}^\infty ne^{\frac{-2\pi inz}{L}} = \delta'(z),&lt;/math&gt;
and finally
:&lt;math&gt;[J_a(x-y),J_b(0)] = i\hbar {C_{ab}}^cJ_c(x-y)\delta(x-y) + \frac{i\hbar^2}{2\pi}\delta_{ab}C\delta'(x-y),&lt;/math&gt;
or
:&lt;math&gt;[J_a(x),J_b(y)] = i\hbar {C_{ab}}^cJ_c(x)\delta(x-y) + \frac{i\hbar^2}{2\pi}\delta_{ab}C\delta'(x-y),&lt;/math&gt;
since the delta functions arguments only ensure that the arguments of the left and right arguments of the commutator are equal (formally {{math|''δ''(''z'') {{=}} ''δ''(''z'' − 0) ↦  ''δ''((''x'' −''y'') − 0) {{=}} ''δ''(''x'' −''y'')}}).

By comparison with {{EquationNote|CA10}}, this is a current algebra in two spacetime dimensions, ''including a Schwinger term'', with the space dimension curled up into a circle. In the classical setting of quantum field theory, this is perhaps of little use, but with the advent of string theory where fields live on world sheets of strings, and spatial dimensions are curled up, there may be relevant applications.

===Kac–Moody algebra===
[[File:Moody Baake.jpg|right|200px|thumb|[[Robert Moody]] (left), Fellow of the [[Royal Society of Canada]], is a Canadian mathematician at [[University of Alberta]]. He is co-discoverer of the Kac–Moody algebra together with [[Victor Kac]], Fellow of the [[American Mathematical Society]], a Russian mathematician working at [[MIT]].]]
The derivation {{math|''d''&lt;sub&gt;0&lt;/sub&gt;}} used in the construction of the 2-cocycle {{mvar|φ}} in the previous section can be extended to a derivation {{mvar|D}} on the centrally extended polynomial loop algebra, here denoted by {{math|'''g'''}} in order to realize a Kac–Moody algebra&lt;ref&gt;{{harvnb|Kac|1990}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Bäuerle|de Kerf|1990}}&lt;/ref&gt; ([[#Affine Kac–Moody algebra|background]]). Simply set
:&lt;math&gt;D(P(\lambda) \otimes G + \mu C) = \lambda \frac{dP(\lambda)}{d\lambda} \otimes G.&lt;/math&gt;
Next, define as a vector space
:&lt;math&gt;\mathfrak e = \mathbb Cd + \mathfrak g.&lt;/math&gt;
The Lie bracket on {{math|'''e'''}} is, according to the standard construction with a derivation, given on a basis by
:&lt;math&gt;\begin{align}{}[\lambda^m \otimes G_1 + \mu C + \nu D, \lambda^n \otimes G_2 + \mu' C + \nu' D] &amp;= \lambda^{m+n} \otimes [G_1, G_2] + m\delta_{m+n,0}K(G_1, G_2)C + \nu D(\lambda^n \otimes G_1) - \nu'D(\lambda^m \otimes G_2)\\
&amp;= \lambda^{m+n} \otimes [G_1, G_2] + m\delta_{m+n,0}K(G_1, G_2)C + \nu n\lambda^n \otimes G_1 - \nu'm \lambda^m \otimes G_2.\end{align}&lt;/math&gt;

For convenience, define
:&lt;math&gt;G_i^m \leftrightarrow \lambda^m \otimes G_i.&lt;/math&gt;
In addition, assume the basis on the underlying finite-dimensional simple Lie algebra has been chosen so that the structure coefficients are antisymmetric in all indices and that the basis is appropriately normalized. Then one immediately through the definitions verifies the following commutation relations.

:&lt;math&gt;\begin{align}{}[G_i^m,G_j^n] &amp;= {C_{ij}}^kG_k^{m+n} + m\delta_{ij}\delta^{m+n,0}C,\\
                    {}[C,G_i^m] &amp;= 0, \quad 1 \le i, j, N,\quad m,n \in \mathbb Z\\
                    {}[D, G_i^m] &amp;= mG_i^m\\
                    {}[D,C] &amp;= 0.\end{align}&lt;/math&gt;
These are precisely the short-hand description of an untwisted affine Kac–Moody algebra. To recapitulate, begin with a finite-dimensional simple Lie algebra. Define a space of formal Laurent polynomials with coefficients in the finite-dimensional simple Lie algebra. With the support of a symmetric non-degenerate alternating bilinear form and a derivation, a 2-cocycle is defined, subsequently used in the standard prescription for a central extension by a 2-cocycle. Extend the derivation to this new space, use the standard prescription for a split extension by a derivation and an untwisted affine Kac–Moody algebra obtains.

===Virasoro algebra===
{{main|Virasoro algebra}}
The purpose is to construct the [[Virasoro algebra]], due to [[Miguel Ángel Virasoro (physicist)|Miguel Angel Virasoro]],&lt;ref group=nb&gt;[[Miguel Ángel Virasoro (physicist)|Miguel Angel Virasoro]], born 1940 is an Argentine physicist. The Virasoro algebra, named after him, was first published in {{harvtxt|Virasoro|1970}}&lt;/ref&gt; as a central extension by a 2-cocycle {{mvar|φ}} of the Witt algebra {{math|''W''}} ([[#Witt algebra|background]]). The Jacobi identity for 2-cocycles yields
{{NumBlk|:|&lt;math&gt;(l-m)\eta_{n+m,p} + (m-n)\eta_{m+n,l} + (n-l)\eta_{l+n,m} = 0, \quad \eta_{ij} = \varphi(d_i, d_j).&lt;/math&gt;|{{EquationRef|V10}}}}
Letting {{math|l {{=}} 0}} and using antisymmetry of {{mvar|η}} one obtains
:&lt;math&gt;(m+p)\eta_{mp}=(m-p)\eta_{m+p,0}.&lt;/math&gt;

In the extension, the commutation relations for the element {{math|''d''&lt;sub&gt;0&lt;/sub&gt;}} are
:&lt;math&gt;[d_0 + \mu C, d_m + \nu C]_\varphi = -md_m + \eta_{0m}C = -m(d_m - \frac{\eta_{0m}}{m}C).&lt;/math&gt;
It is desirable to get rid of the [[central charge]] on the right hand side. To do this define
:&lt;math&gt;f:W \to \mathbb C; d_m \to \frac{\varphi(d_0,d_m)}{m} = \frac{\eta_{0m}}{m}.&lt;/math&gt;
Then, using {{math|''f''}} as a 1-cochain, 
:&lt;math&gt;\eta'_{0n} = \varphi'(d_0, d_n) = \varphi(d_0, d_n) + \delta f([d_0, d_n]) = \varphi(d_0, d_n) -n \frac{\eta^{0n}}{n}= 0,&lt;/math&gt;
so with this 2-cocycle, equivalent to the previous one, one has&lt;ref group=nb&gt;The same effect can be obtained by a change of basis in {{math|''W''}}.&lt;/ref&gt;
:&lt;math&gt;[d_0 + \mu C, d_m + \nu C]_{\varphi'} = -md_m.&lt;/math&gt;
With this new 2-cocycle (skip the prime) the condition becomes
:&lt;math&gt;(n+p)\eta_{mp} = (n-p)\eta_{m+p,0}=0,&lt;/math&gt;
and thus
:&lt;math&gt;\eta_{mp}=a(m)\delta_{m. -p}, \quad a(-m) = -a(m),&lt;/math&gt;
where the last condition is due to the antisymmetry of the Lie bracket. With this, and with {{math|''l'' + ''m'' + ''p'' {{=}} 0}} (cutting out a "plane" in {{math|ℤ&lt;sup&gt;3&lt;/sup&gt;}}), {{EquationNote|(V10)}} yields
:&lt;math&gt;(2m+p)a(p) + (m-p)a(m+p) + (m+2p)a(m) = 0,&lt;/math&gt;

that with {{math|''p'' {{=}} 1}} (cutting out a "line" in {{math|ℤ&lt;sup&gt;2&lt;/sup&gt;}}) becomes
:&lt;math&gt;(m-1)a(m+1) - (m+2)a(m) + (2m+1)a(1) = 0.&lt;/math&gt;
This is a [[difference equation]] generally solved by
:&lt;math&gt;a(m) = \alpha m + \beta m^3.&lt;/math&gt;
The commutator in the extension on elements of {{math|''W''}} is then
:&lt;math&gt;[d_l, d_m] = (l-m)d_{l+m} + (\alpha m + \beta m^3)\delta_{l,-m}C.&lt;/math&gt;
With {{mvar|β {{=}} 0}} it is possible to change basis (or modify the 2-cocycle by a 2-coboundary) so that
:&lt;math&gt;[d'_l, d'_m] = (l-m)d_{l+m},&lt;/math&gt;
with the central charge absent altogether, and the extension is hence trivial. (This was not (generally) the case with the previous modification, where only {{math|''d''&lt;sub&gt;0&lt;/sub&gt;}} obtained the original relations.) With {{mvar|β ≠ 0}} the following change of basis,
:&lt;math&gt;d'_l = d_l + \delta_{0l}\frac{\alpha+\gamma}{2}C,&lt;/math&gt;
the commutation relations take the form
:&lt;math&gt;[d'_l, d'_m] = (l-m)d'_{l+m} + (\gamma m + \beta m^3)\delta_{l,-m}C,&lt;/math&gt;
showing that the part linear in {{mvar|''m''}} is trivial. It also shows that {{math|''H''&lt;sup&gt;2&lt;/sup&gt;(''W'', ℂ)}} is one-dimensional (corresponding to the choice of {{mvar|β}}). The conventional choice is to take {{math|''α'' {{=}} −''β'' {{=}} {{frac|1|12}}}} and still retaining freedom by absorbing an arbitrary factor in the arbitrary object {{math|''C''}}. The '''Virasoro algebra''' {{math|''V''}} is then
:&lt;math&gt;\mathcal V = \mathcal W + \mathbb C C,&lt;/math&gt;
with commutation relations
{{Equation box 1
|indent =:
|title= 
|equation = &lt;math&gt;[d_l + \mu C, d_m + \nu C] = (l-m)d_{l+m} + \frac{(m - m^3)}{12}\delta_{l,-m}C.&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}

====Bosonic open strings====
{{main|Bosonic string theory}}
The relativistic classical open string ([[#Relativistic classical string theory|background]]) is subject to [[quantization (physics)|quantization]]. This roughly amounts to taking the position and the momentum of the string and promoting them to operators on the space of states of open strings. Since strings are extended objects, this results in a continuum of operators depending on the parameter {{mvar|σ}}. The following commutation relations are postulated in the [[Heisenberg picture]].&lt;ref&gt;{{harvnb|Zwiebach|2004|loc=Chapter 12}}&lt;/ref&gt;
:&lt;math&gt;\begin{align}{}[X^I(\tau, \sigma), \mathcal P^{\tau J}(\tau, \sigma)] &amp;= i\eta^{IJ}\delta(\sigma-\sigma'),\\
{}[x_0^-(\tau),p^+(\tau)] &amp;= -i.\end{align}&lt;/math&gt;
All other commutators vanish.

Because of the continuum of operators, and because of the delta functions, it is desirable to express these relations instead in terms of the quantized versions of the Virasoro modes, the '''Virasoro operators'''. These are calculated to satisfy
:&lt;math&gt;[\alpha_m^I, \alpha_n^J] = m\eta^{IJ}\delta_{m+n,0}&lt;/math&gt;
They are interpreted as [[creation and annihilation operators]] acting on Hilbert space, increasing or decreasing the quantum of their respective modes. If the index is negative, the operator is a creation operator, otherwise it is an annihilation operator. (If it is zero, it is proportional to the total momentum operator.) In view of the fact that the light cone plus and minus modes were expressed in terms of the transverse Virasoro modes, one must consider the commutation relations between the Virasoro operators. These were classically defined (then modes) as
:&lt;math&gt;L_n = \frac{1}{2}\sum_{p \in \mathbb Z}\alpha_{n-p}^I\alpha_p^I.&lt;/math&gt;

Since, in the quantized theory, the alphas are operators, the ordering of the factors matter. In view of the commutation relation between the mode operators, it will only matter for the operator {{math|''L''&lt;sub&gt;0&lt;/sub&gt;}} (for which {{math|''m'' + ''n'' {{=}} 0}}). {{math|''L''&lt;sub&gt;0&lt;/sub&gt;}} is chosen [[normal order]]ed,
:&lt;math&gt;L_0 = \frac{1}{2}\alpha_0^I\alpha_0^I + \sum_{p=1}^\infty \alpha_{-p}^I\alpha_p^I,
 = \alpha' p^Ip^I + \sum_{p=1}^\infty p \alpha_{p}^{I\dagger}\alpha_p^I + c&lt;/math&gt;
where {{mvar|c}} is a possible ordering constant. One obtains after a somewhat lengthy calculation&lt;ref&gt;{{harvnb|Zwiebach|2002|pp=219–228}}&lt;/ref&gt; the relations
:&lt;math&gt;[L_m, L_n] = (m-n)L_{m+n}, \quad m+n\ne 0.&lt;/math&gt;
If one would allow for {{math|''m'' + ''n'' {{=}} 0}} above, then one has precisely the commutation relations of the Witt algebra. Instead one has
:&lt;math&gt;[L_m, L_n] = (m-n)L_{m+n} + \frac{D-2}{12}(m^3-m)\delta_{m+n,0},\quad \forall m,n \in \mathbb Z.&lt;/math&gt;
upon identification of the generic central term as {{math|(''D'' − 2)}} times the identity operator, this is the Virasoro algebra, the universal central extension of the Witt algebra.

The operator {{math|''L''&lt;sub&gt;0&lt;/sub&gt;}} enters the theory as the [[Hamiltonian (quantum mechanics)|Hamiltonian]], modulo an additive constant. Moreover, the Virasoro operators enter into the definition of the Lorentz generators of the theory. It is perhaps the most important algebra in string theory.&lt;ref&gt;{{harvnb|Zwiebach|2004|p=227}}&lt;/ref&gt; The consistency of the Lorentz generators, by the way, fixes the spacetime dimensionality to 26. While this theory presented here (for relative simplicity of exposition) is unphysical, or at the very least incomplete (it has, for instance, no fermions) the Virasoro algebra arises in the same way in the more viable [[superstring theory]] and [[M-theory]].

===Group extension===
{{main|Group extension}}
A projective representation {{math|Π(''G'')}} of a Lie group {{mvar|''G''}} ([[#Projective representation|background]]) can be used to define a so-called [[group extension]] {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}}.

In quantum mechanics, [[Wigner's theorem]] asserts that if {{math|''G''}} is a symmetry group, then it will be represented projectively on Hilbert space by unitary or antiunitary operators. This is often dealt with by passing to the [[universal covering group]] of {{math|''G''}} and take it as the symmetry group. This works nicely for the [[rotation group]] {{math|SO(3)}} and the [[Lorentz group]] {{math|O(3, 1)}}, but it does not work when the symmetry group is the [[Galilean group]]. In this case one has to pass to its central extension, the '''Bargmann group''',&lt;ref&gt;{{harvnb|Bargmann|1954}}&lt;/ref&gt; which is the symmetry group of the [[Schrödinger equation]]. Likewise, if {{math|''G'' {{=}} ℝ&lt;sup&gt;2''n''&lt;/sup&gt;}}, the group of translations in position and momentum space, one has to pass to its central extension, the [[Heisenberg group]].&lt;ref name=Tuynman_Wiegerinck&gt;{{harvnb|Tuynman|Wiegerinck|1987}}&lt;/ref&gt;

Let {{mvar|ω}} be the 2-cocycle on {{math|''G''}} induced by {{math|Π}}. Define&lt;ref group=nb&gt;If the 2-cocycle takes its values in the abelian group {{math|U(1)}}, i. e. it is a phase factor, which will always be the case in the contezt of [[Wigner's theorem]], then {{math|ℂ&lt;sup&gt;*&lt;/sup&gt;}} may be replaced with {{math|U(1)}} in the construction.&lt;/ref&gt;
:&lt;math&gt;G_{\mathrm {ex}} = \mathbb C^* \times G = \{(\lambda,g)|\lambda \in \mathbb C, g \in G\}&lt;/math&gt;
as a set and let the multiplication be defined by
:&lt;math&gt;(\lambda_1,g_1)(\lambda_2,g_2) = (\lambda_1\lambda_2\omega(g_1,g_2),g_1g_2).&lt;/math&gt;
Associativity holds since {{mvar|ω}} is a 2-cocycle on {{math|''G''}}. One has for the unit element
:&lt;math&gt;(1,e)(\lambda,g) = (\lambda\omega(e,g),g) = (\lambda,g) = (\lambda,g)(1,e),&lt;/math&gt;
and for the inverse
:&lt;math&gt;(\lambda,g)^{-1} = \left(\frac{1}{\lambda \omega(g, g^{-1})}, g^{-1}\right).&lt;/math&gt;

The set {{math|(ℂ&lt;sup&gt;*&lt;/sup&gt;, ''e'')}} is an abelian subgroup of {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}}. This means that {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}} is not semisimple. The [[Center (group theory)|center]] of {{mvar|G}}, {{math|''Z''(''G'') {{=}} &lt;nowiki&gt;{&lt;/nowiki&gt;''z'' ∈ ''G''{{!}}''zg'' {{=}} ''gz'' ∀''g'' ∈ ''G''&lt;nowiki&gt;}&lt;/nowiki&gt;}} includes this subgroup. The center may be larger.

At the level of Lie algebras it can be shown that the Lie algebra {{math|'''g'''&lt;sub&gt;ex&lt;/sub&gt;}} of {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}} is given by
:&lt;math&gt;\mathfrak{g}_{\mathrm{ex}} = \mathbb CC \oplus \mathfrak g,&lt;/math&gt;
as a vector space and endowed with the Lie bracket
:&lt;math&gt;[\mu C + G_1,\nu C + G_2] = [G_1, G_2] + \eta(G_1, G_2)C.&lt;/math&gt;
Here {{mvar|η}} is a 2-cocycle on {{math|'''g'''}}. This 2-cocycle can be obtained from {{mvar|ω}} albeit in a highly nontrivial way.&lt;ref group=nb&gt;{{harvnb|Bäuerle|de Kerf|1997|loc=Chapter 18.}} The reference states the fact and that it is difficult to show. No further references are given. Expressions on a slightly different form can be found though in {{harvtxt|Tuynman|Wiegerinck|1987}} and {{harvtxt|Bargmann|1954}}.&lt;/ref&gt;

Now by using the projective representation {{math|Π}} one may define a map {{math|Π&lt;sub&gt;ex&lt;/sub&gt;}} by
:&lt;math&gt;\Pi_{\mathrm{ex}}((\lambda,g)) = \lambda\Pi(g).&lt;/math&gt;
It has the properties
:&lt;math&gt;\Pi_{\mathrm{ex}}((\lambda_1,g_1))\Pi_{\mathrm{ex}}((\lambda_2,g_2))=\lambda_1\lambda_2\Pi(g_1)\Pi(g_2)=\lambda_1\lambda_2\omega(g_1,g_2)\Pi(g_1g_2)=\Pi_{\mathrm{ex}}(\lambda_1\lambda_2\omega(g_1,g_2),g_1g_2) = \Pi_{\mathrm{ex}}((\lambda_1, g_1)(\lambda_2,g_2)),&lt;/math&gt;
so {{math|Π&lt;sub&gt;ex&lt;/sub&gt;(''G''&lt;sub&gt;ex&lt;/sub&gt;)}} is a bona fide representation of {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}}.

In the context of Wigner's theorem, the situation may be depicted as such (replace {{math|ℂ&lt;sup&gt;*&lt;/sup&gt;}} by {{math|U(1)}}); let {{math|''SH''}} denote the unit sphere in Hilbert space {{mvar|H}}, and let {{math|(·,·)}} be its inner product. Let {{math|''PH''}} denote [[Wigner's theorem#Rays and ray space|ray space]] and {{math|[·,·]}} the [[Wigner's theorem#Symmetry transformations|ray product]]. Let moreover a wiggly arrow denote a [[group action]]. Then the diagram
[[File:Lie algebra extension figure 4.svg|200px|center]]
commutes, i.e.
:&lt;math&gt;\pi_2 \circ \Pi_{\mathrm{ex}}((\lambda, g))(\psi) = \Pi \circ \pi(g)(\pi_1(\psi)), \quad \psi \in S\mathcal H.&lt;/math&gt;
Moreover, in the same way that {{math|''G''}} is a symmetry of {{math|''PH''}} preserving {{math|[·,·]}}, {{math|''G''&lt;sub&gt;ex&lt;/sub&gt;}} is a symmetry of {{math|''SH''}} preserving {{math|(·,·)}}. The [[fiber (mathematics)|fibers]] of {{math|''π''&lt;sub&gt;2&lt;/sub&gt;}} are all circles. These circles are left invariant under the action of {{math|U(1)}}. The action of {{math|U(1)}} on these fibers is transitive with no fixed point. The conclusion is that {{math|''SH''}} is a [[principal fiber bundle]] over {{math|''PH''}} with structure group {{math|U(1)}}.&lt;ref name=Tuynman_Wiegerinck/&gt;
&lt;!--
Actually, since 
:&lt;math&gt;\begin{align}\frac{d}{ds}\frac{d}{dt}e^{\mathrm{Ad}_{e^{sX}}tX}|_{t=0}|_{s=0}
&amp;=\frac{d}{ds}\frac{d}{dt}e^{e^{sX}tYe^{-sX}}|_{t=0}|_{s=0}
=\frac{d}{ds}\frac{d}{dt}e^{sX}e^{tY}e^{-sX}|_{t=0}|_{s=0}
=\frac{d}{ds}e^{sX}Ye^{tY}e^{-sX}|_{t=0}|_{s=0}
=\frac{d}{ds}e^{sX}Ye^{-sX}|_{s=0}\\
&amp;=\frac{d}{ds}\mathrm{Ad}_{e^{sX}}Y|_{s=0}
=\frac{d}{ds}e^{\mathrm{ad}_{sX}}Y|_{s=0}
=\frac{d}{ds}e^{s\mathrm{ad}_{X}}Y|_{s=0}
=\mathrm{ad}_Xe^{s\mathrm{ad}_{X}}Y|_{s=0}
=\mathrm{ad}_XY|_{t=0}
=[X,Y],\end{align}&lt;/math&gt;
one has
:&lt;math&gt;e^{\mathrm{Ad}_{(1,e^{tG})}(1,sH}=(1,e^{tG})(1,e^{sH})(1,e^{-tG})=(\omega(e^{tG},e^{sH}),e^{tG}e^{sH})\left(\frac{1}{\omega(e^{tG},e^{-tG})},e^{-tG}\right) = \left(\frac{\omega(e^{tG},e^{sH})}{\omega(e^{tG},e^{-tG})}\omega(e^{tG}e^{sH},e^{-tG}),e^{tG}e^{sH}e^{-tG}\right),&lt;/math&gt;
so that
:&lt;math&gt;[\mu C + G_1,\nu C + G_2] = [G_1, G_2] + \eta(G_1, G_2)C,\qquad \eta(G_1, G_2) = \frac{d}{ds}\left .\left[\frac{d}{dt}\left.\frac{\omega(e^{tG},e^{sH})}{\omega(e^{tG},e^{-tG})}\omega(e^{tG}e^{sH},e^{-tG})\right|_{t=0}\right]\right|_{s=0}&lt;/math&gt;
--&gt;

==Background material==
In order to adequately discuss extensions, structure that goes beyond the defining properties of a Lie algebra is needed. Rudimentary facts about these are collected here for quick reference.

===Derivations===
A '''derivation''' {{mvar|δ}} on a Lie algebra {{math|'''g'''}} is a map
:&lt;math&gt;\delta: \mathfrak g \rightarrow \mathfrak g&lt;/math&gt;
such that the [[Product rule|Leibniz rule]]
:&lt;math&gt;\delta[G_1, G_2] = [\delta G_1, G_2] + [G_1, \delta G_2]&lt;/math&gt;
holds. The set of derivations on a Lie algebra {{math|'''g'''}} is denoted {{math|der '''g'''}}. It is itself a Lie algebra under the Lie bracket
:&lt;math&gt;[\delta_1, \delta_2] = \delta_1 \circ \delta_2 - \delta_2 \circ \delta_1.&lt;/math&gt;
It is the Lie algebra of the group {{math|Aut '''g'''}} of automorphisms of {{math|'''g'''}}.&lt;ref&gt;{{harvnb|Rossmann|2002|loc=Section 2.2}}&lt;/ref&gt; One has to show
:&lt;math&gt;\delta[G_1, G_1] = [\delta G_1, G_2] + [G_1, \delta G_2] \Leftrightarrow e^{t\delta}[G_1,G_2] = [e^{t\delta}G_1, e^{t\delta}G_2], \quad \forall t \in \mathbb R.&lt;/math&gt;
If the rhs holds, differentiate and set {{math|''t'' {{=}} 0}} implying that the lhs holds. If the lhs holds {{math|('''A''')}}, write the rhs as
:&lt;math&gt;[G_1,G_2]\; \overset{?}{=}\; e^{-t\delta}[e^{t\delta}G_1, e^{t\delta}G_2],&lt;/math&gt;
and differentiate the rhs of this expression. It is, using {{math|('''A''')}}, identically zero. Hence the rhs of this expression is independent of {{mvar|t}} and equals its value for {{math|''t'' {{=}} 0}}, which is the lhs of this expression.

If {{math|''G'' ∈ '''g'''}}, then {{math|ad&lt;sub&gt;''G''&lt;/sub&gt;}}, acting by {{math|ad&lt;sub&gt;''G''&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;(''G''&lt;sub&gt;2&lt;/sub&gt;) {{=}} [''G''&lt;sub&gt;1&lt;/sub&gt;, ''G''&lt;sub&gt;2&lt;/sub&gt;]}}, is a derivation. The set {{math|ad&lt;sub&gt;''G''&lt;/sub&gt;: ''G'' ∈ '''g'''}} is the set of '''inner derivations''' on {{math|'''g'''}}. For finite-dimensional simple Lie algebras all derivations are inner derivations.&lt;ref&gt;{{harvnb|Humphreys|1972}}&lt;/ref&gt;

===Semidirect product (groups)===
{{main|Semidirect product}}
Consider two Lie groups {{mvar|G}} and {{mvar|H}} and {{math|Aut ''H''}}, the [[automorphism group]] of {{mvar|H}}. The latter is the group of isomorphisms of {{mvar|H}}. If there is a Lie group homomorphism {{math|Φ:''G'' → Aut ''H''}}, then for each {{math|''g'' ∈ ''G''}} there is a {{math|Φ(''g'') ≡ Φ&lt;sub&gt;''g''&lt;/sub&gt; ∈ Aut ''H''}} with the property {{math|Φ&lt;sub&gt;''gg''&lt;nowiki&gt;'&lt;/nowiki&gt;&lt;/sub&gt; {{=}} Φ&lt;sub&gt;''g''&lt;/sub&gt;Φ&lt;sub&gt;''g''&lt;nowiki&gt;'&lt;/nowiki&gt;&lt;/sub&gt;, ''g'',''g''&lt;nowiki&gt;'&lt;/nowiki&gt; ∈ ''G''}}. Denote with {{mvar|''E''}} the ''set'' {{math|''H'' × ''G''}} and define multiplication by 
{{NumBlk|:|&lt;math&gt;(h, g)(h', g') = (h\phi_g(h'), gg'), \quad g, g' \in G, h, h' \in H.&lt;/math&gt;|{{EquationRef|4}}}}
Then {{math|''E''}} is a group with identity {{math|(''e''&lt;sub&gt;''H''&lt;/sub&gt;, ''e''&lt;sub&gt;''G''&lt;/sub&gt;)}} and the inverse is given by {{math|(''h'', ''g'')&lt;sup&gt;−1&lt;/sup&gt; {{=}} (''Φ''&lt;sub&gt;''g''&lt;sup&gt;−1&lt;/sup&gt;&lt;/sub&gt;(''h''&lt;sup&gt;−1&lt;/sup&gt;), ''g''&lt;sup&gt;−1&lt;/sup&gt;)}}. Using the expression for the inverse and equation {{EquationNote|(4)}} it is seen that {{mvar|H}} is normal in {{mvar|E}}. Denote the group with this [[semidirect product]] as {{math|''E'' {{=}} ''H'' ⊗&lt;sub&gt;''S''&lt;/sub&gt; ''G''}}.

Conversely, if {{math|''E'' {{=}} ''H'' ⊗&lt;sub&gt;''S''&lt;/sub&gt; ''G''}} is a given semidirect product expression of the group {{math|''E''}}, then by definition {{math|''H''}} is normal in {{math|''E''}} and {{math|''C''&lt;sub&gt;''g''&lt;/sub&gt; ∈ Aut ''H''}} for each {{math|''g'' ∈ ''G''}} where {{math|''C''&lt;sub&gt;''g''&lt;/sub&gt; (''h'') ≡ ''ghg''&lt;sup&gt;−1&lt;/sup&gt;}} and the map {{math|''Φ'':''g'' ↦ ''C''&lt;sub&gt;''g''&lt;/sub&gt;}} is a homomorphism.

Now make use of the Lie correspondence. The maps {{math|Φ&lt;sub&gt;''g''&lt;/sub&gt;:''H'' → ''H'', ''g'' ∈ ''G''}} each induce, at the level of Lie algebras, a map {{math|Ψ&lt;sub&gt;''g''&lt;/sub&gt;:'''h''' → '''h'''}}. This map is computed by
{{NumBlk|:|&lt;math&gt;\Psi_g(G) = \left .\frac{d}{dt}\phi_g(e^{tG})\right|_{t = 0}, \quad G \in \mathfrak g, g \in G.&lt;/math&gt;|{{EquationRef|5}}}}
For instance, if {{math|''G''}} and  {{math|''H''}} are both subgroups of a larger group {{mvar|E}} and {{math|Φ&lt;sub&gt;''g''&lt;/sub&gt; {{=}} ''ghg''&lt;sup&gt;−1&lt;/sup&gt;}}, then 
{{NumBlk|:|&lt;math&gt;\Psi_g(G) = \left .\frac{d}{dt}ge^{tG}g^{-1}\right|_{t = 0} = gGg^{-1} = \mathrm{Ad}_g(G),&lt;/math&gt;|{{EquationRef|5&lt;nowiki&gt;'&lt;/nowiki&gt;}}}}
and one recognizes {{math|Ψ}} as the [[adjoint representation|adjoint action]] {{math|Ad}} of {{mvar|E}} on {{math|'''h'''}} restricted to {{mvar|G}}. Now {{math|Ψ:''G'' → Aut '''h'''}} &lt;nowiki&gt;[&lt;/nowiki&gt; {{math|⊂ GL('''h''')}} if {{math|'''h'''}} is finite-dimensional&lt;nowiki&gt;]&lt;/nowiki&gt; is a homomorphism,&lt;ref group=nb&gt;To see this, apply formula {{EquationNote|(4)}} to {{math|Ψ&lt;sub&gt;''gg&lt;nowiki&gt;'&lt;/nowiki&gt;''&lt;/sub&gt;}}, recall that {{math|Φ}} is a homomorphism, and use {{math|Φ&lt;sub&gt;''g''&lt;/sub&gt;(''e''&lt;sup&gt;''G''&lt;/sup&gt;) {{=}} ''e''&lt;sup&gt;Ψ&lt;sub&gt;''g''&lt;/sub&gt;(''G'')&lt;/sup&gt;}} a couple of times.&lt;/ref&gt; and appealing once more to the Lie correspondence, there is a unique Lie algebra homomorphism {{math|''ψ'':'''g''' → Lie(Aut '''h''') {{=}} Der '''h''' ⊂ gl('''h''')}}.&lt;ref group=nb&gt;The fact that the Lie algebra of {{math|Aut '''h''')}} is {{math|Der '''h'''}}, the set of all derivations of {{math|'''h'''}} (itself being a Lie algebra under the obvious bracket), can be found in {{harvnb|Rossmann|2002|p=51}}&lt;/ref&gt; This map is (formally) given by
{{NumBlk|:|&lt;math&gt;\psi_G = \left .\frac{d}{dt}\Psi_{e^{tG}}\right|_{t=0},\quad G \in \mathfrak g&lt;/math&gt;|{{EquationRef|6}}}}
for example, if {{math|Ψ {{=}} Ad}}, then (formally)
{{NumBlk|:|&lt;math&gt;\psi_G = \left .\frac{d}{dt}\mathrm{Ad}_{e^{tG}}\right|_{t=0} = \left .\frac{d}{dt}e^{\mathrm{ad}_{tG}}\right|_{t=0} = \mathrm{ad}_G,&lt;/math&gt;|{{EquationRef|6&lt;nowiki&gt;'&lt;/nowiki&gt;}}}}
where a relationship between {{math|Ad}} and the [[adjoint representation of a Lie algebra|adjoint action]] {{math|ad}} rigorously proved in [[Baker–Campbell–Hausdorff formula#An important lemma|here]] is used.

'''Lie algebra'''&lt;br&gt;
The Lie algebra is, as a vector space, {{math|'''e''' {{=}} '''h''' ⊕ '''g'''}}. This is clear since {{math|''GH''}} generates {{math|''E''}} and {{math|''G'' ∩ ''H'' {{=}} (''e''&lt;sub&gt;''H''&lt;/sub&gt;, ''e''&lt;sub&gt;''G''&lt;/sub&gt;)}}. The Lie bracket is given by&lt;ref&gt;{{harvnb|Knapp|2002}}&lt;/ref&gt;
:&lt;math&gt;[H_1 + G_1,H_2 + G_2]_\mathfrak e = [H_1, H_2]_\mathfrak h + \psi_{G_1}(H_2) -\psi_{G_2}(H_1) + [G_1, G_2]_\mathfrak g.&lt;/math&gt;
{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=Computation of Lie bracket}}
To compute the Lie bracket, begin with a surface in {{math|''E''}} parametrized by {{math|''s''}} and {{math|''t''}}. Elements of {{math|'''h'''}} in {{math|'''e''' {{=}} '''h''' ⊕ '''g'''}} are decorated with a bar, and likewise for {{math|'''g'''}}.
:&lt;math&gt;
\begin{align}
e^{e^{t\overline{G}}s\overline{H}e^{-t\overline{G}}} &amp;= e^{t\overline{G}}e^{s\overline{H}}e^{-t\overline{G}}=(1,e^{tG})(e^{sH},1)(1,e^{-tG})\\
&amp;=(\phi_{e^{tG}}(e^{sH}), e^{tG})(1,e^{-tG}) = (\phi_{e^{tG}}(e^{sH})\phi_{e^{tG}}(1),1)\\
&amp;= (\phi_{e^{tG}}(e^{sH}),1)
\end{align}
&lt;/math&gt;

One has 
:&lt;math&gt;
\frac{d}{ds} \left. e^{Ad_{e^{t\overline{G}}}s\overline{H}}\right|_{s=0} = Ad_{e^{t\overline{G}}}\overline{H}
&lt;/math&gt;
and
:&lt;math&gt;
\frac{d}{ds} \left. (\phi_{e^{tG}}(e^{sH}),1)\right|_{s = 0} = (\Psi_{e^{tG}}(H), 0)
&lt;/math&gt;
by {{EquationNote|5}} and thus
:&lt;math&gt;
Ad_{e^{t\overline{G}}}\overline{H} = (\Psi_{e^{tG}}(H), 0).
&lt;/math&gt;

Now differentiate this relationship with respect to {{mvar|t}} and evaluate at {{math|''t'' {{=}} 0}}$:
:&lt;math&gt;
\frac{d}{dt} \left .e^{t\overline{G}}\overline{H}e^{-t\overline{G}}\right|_{t=0} = [\overline{G}, \overline{H}]
&lt;/math&gt;
and
:&lt;math&gt;
\frac{d}{dt} \left .(\Psi_{e^{tG}}(H), 0)\right|_{t=0} = (\psi_G(H), 0)
&lt;/math&gt;
by {{EquationNote|6}} and thus
:&lt;math&gt;[H_1 + G_1,H_2 + G_2]_\mathfrak e = [H_1, H_2]_\mathfrak h + [G_1, H_2] + [H_1, G_2] + [G_1, G_2]_\mathfrak g = [H_1, H_2]_\mathfrak h + \psi_{G_1}(H_2) -\psi_{G_2}(H_1) + [G_1, G_2]_\mathfrak g.&lt;/math&gt;
{{Hidden end}}

===Cohomology===
{{main|Algebraic topology|Cohomology|Lie algebra cohomology}}
For the present purposes, consideration of a limited portion of the theory Lie algebra cohomology suffices. The definitions are not the most general possible, or even the most common ones, but the objects they refer to are authentic instances of more the general definitions.

'''2-cocycles'''&lt;br&gt;
The objects of primary interest are the 2-cocycles on {{math|'''g'''}}, defined as [[bilinear map|bilinear]] [[alternating map|alternating]] functions, 
:&lt;math&gt;
\phi:\mathfrak g \times \mathfrak g \rightarrow F,
&lt;/math&gt;
that are alternating,
:&lt;math&gt;
\phi(G_1, G_2) = -\phi(G_2, G_1),
&lt;/math&gt;
and having a property resembling the Jacobi identity called the '''Jacobi identity for 2-cycles''',
:&lt;math&gt;
\phi(G_1, [G_2, G_3]) + \phi(G_2, [G_3, G_1]) + \phi(G_3, [G_1, G_2]) = 0.
&lt;/math&gt;

The set of all 2-cocycles on {{math|'''g'''}} is denoted {{math|''Z''&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}}.

'''2-cocycles from 1-cochains'''&lt;br&gt;
Some 2-cocycles can be obtained from 1-cochains. A '''1-cochain''' on {{math|'''g'''}} is simply a linear map,
:&lt;math&gt;
f:\mathfrak g \rightarrow F
&lt;/math&gt;
The set of all such maps is denoted {{math|''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'')}} and, of course (in at least the finite-dimensional case) {{math|''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'') ≅ '''g'''*}}. Using a 1-cochain {{mvar|f}}, a 2-cocycle {{math|''δf''}} may be defined by
:&lt;math&gt;
\delta f(G_1, G_2) = f([G_1, G_2]).
&lt;/math&gt;
The alternating property is immediate and the Jacobi identity for 2-cocycles is (as usual) shown by writing it out and using the definition and properties of the ingredients (here the Jacobi identity on {{math|'''g'''}} and the linearity of {{mvar|f}}). The linear map {{math|''δ'':''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'') → ''Z''&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}} is called the '''coboundary operator''' (here restricted to {{math|''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'')}}).

'''The second cohomology group'''&lt;br&gt;
Denote the image of {{math|''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'')}} of {{mvar|δ}} by {{math|''B''&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}}. The quotient
:&lt;math&gt;
H^2(\mathfrak g, \mathbb F) = Z^2(\mathfrak g, \mathbb F)/B^2(\mathfrak g, \mathbb F)
&lt;/math&gt;
is called the '''second cohomology group''' of {{math|'''g'''}}. Elements of {{math|H&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}} are equivalence classes of 2-cocycles and two
2-cocycles {{math|''φ''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''φ''&lt;sub&gt;2&lt;/sub&gt;}} are called '''equivalent cocycles''' if they differ by a 2-coboundary, i.e. if {{math|''φ''&lt;sub&gt;1&lt;/sub&gt; {{=}} ''φ''&lt;sub&gt;2&lt;/sub&gt; + ''δf''}} for some {{math|''f'' ∈ ''C''&lt;sup&gt;1&lt;/sup&gt;('''g''', ''F'')}}. Equivalent
2-cocycles are called '''cohomologous'''. The equivalence class of {{math|''φ'' ∈ ''Z''&lt;sup&gt;2&lt;/sup&gt;('''g''', ''F'')}} is denoted {{math|[''φ''] ∈ ''H''&lt;sup&gt;2&lt;/sup&gt;}}.

These notions generalize in several directions. For this, see the main articles.

===Structure constants===
{{main|Structure constants}}
Let {{math|''B''}} be a [[Hamel basis]] for {{math|'''g'''}}. Then each {{math|''G'' ∈ '''g'''}} has a unique expression as
:&lt;math&gt;G = \sum_{\alpha \in A}c_\alpha G_\alpha, \quad c_\alpha \in F, G_\alpha \in B&lt;/math&gt;
for some indexing set {{mvar|A}} of suitable size. In this expansion, only finitely many {{math|''c''&lt;sub&gt;''α''&lt;/sub&gt;}} are nonzero. In the sequel it is (for simplicity) assumed that the basis is countable, and Latin letters are used for the indices and the indexing set can be taken to be {{math|ℕ&lt;sup&gt;∗&lt;/sup&gt; {{=}} 1, 2, ...}}. One immediately has
:&lt;math&gt;[G_i, G_j] = {C_{ij}}^k G_k&lt;/math&gt;
for the basis elements, where the summation symbol has been rationalized away, the summation convention applies. The placement of the indices in the structure constants (up or down) is immaterial. The following theorem is useful:

'''Theorem''':There is a basis such that the structure constants are antisymmetric in all indices if and only if the Lie algebra is a direct sum of simple compact Lie algebras and {{math|'''u'''(1)}} Lie algebras. This is the case if and only if there is a real positive definite metric {{mvar|''g''}} on {{math|'''g'''}} satisfying the invariance condition
:&lt;math&gt;g_{\alpha\beta}{C^\beta}_{\gamma\delta}=-g_{\gamma\beta}{C^\beta}_{\alpha\delta}.&lt;/math&gt;
in any basis. This last condition is necessary on physical grounds for non-Abelian [[Gauge theory|gauge theories]] in [[quantum field theory]]. Thus one can produce an infinite list of possible gauge theories using the Cartan catalog of simple Lie algebras on their compact form (i.e., {{math|'''sl'''(''n'', ℂ) → '''su'''(''n'')}}, etc. One such gauge theory is the {{math|U(1) × SU(2) × SU(3)}} gauge theory of the [[standard model]] with Lie algebra {{math|'''u'''(1) ⊕ '''su'''(2) ⊕ '''su'''(3)}}.&lt;ref&gt;{{harvnb|Weinberg|1996|loc=Appendix A, Ch 15.}}&lt;/ref&gt;

===Killing form===
{{main|Killing form}}
The '''Killing form''' is a symmetric bilinear form on {{math|'''g'''}} defined by
:&lt;math&gt;K(G_1, G_2) = \mathrm{trace} (\mathrm{ad}_{G_1}\mathrm{ad}_{G_2}).&lt;/math&gt;
Here {{math|ad&lt;sub&gt;''G''&lt;/sub&gt;}} is viewed as a matrix operating on the vector space {{math|'''g'''}}. The key fact needed is that if {{math|'''g'''}} is [[semisimple Lie algebra|semisimple]], then, by [[Cartan's criterion]], {{mvar|K}} is non-degenerate. In such a case {{mvar|K}} may be used to identify {{math|'''g'''}} and {{math|'''g'''&lt;sup&gt;∗&lt;/sup&gt;}}. If {{math|''λ'' ∈ '''g'''&lt;sup&gt;∗&lt;/sup&gt;}}, then there is a {{math|''ν''(''λ'') {{=}} ''G''&lt;sub&gt;''λ''&lt;/sub&gt; ∈ '''g'''}} such that
:&lt;math&gt;\langle \lambda, G \rangle = K(G_\lambda, G) \quad \forall G \in \mathfrak g.&lt;/math&gt;
This is resembling [[Riesz representation theorem]] and the proof is virtually the same. The Killing form has the property
:&lt;math&gt;K([G_1, G_2], G_3) = K(G_1, [G_2, G_3]), &lt;/math&gt;
which is referred to as associativity. By defining {{math|''g''&lt;sub&gt;''αβ''&lt;/sub&gt; {{=}} ''K''[''G''&lt;sub&gt;''α''&lt;/sub&gt;,''G''&lt;sub&gt;''β''&lt;/sub&gt;]}} and expanding the inner brackets in terms of structure constants, one finds that the Killing form satisfies the invariance condition of above.

===Loop algebra===
{{main|Loop algebra|Loop group}}
A [[loop group]] is taken as a group of smooth maps from the unit circle {{math|''S''&lt;sup&gt;1&lt;/sup&gt;}} into a Lie group {{math|''G''}} with the group structure defined by the group structure on {{math|''G''}}. The Lie algebra of a loop group is then a vector space of mappings from {{math|''S''&lt;sup&gt;1&lt;/sup&gt;}} into the Lie algebra {{math|'''g'''}} of {{math|''G''}}. Any subalgebra of such a Lie algebra is referred to as a '''loop algebra'''. Attention here is focused on '''polynomial loop algebras''' of the form
:&lt;math&gt;\{h: S^1 \to \mathfrak g|h(\lambda) = \sum \lambda^n G_n, n \in \mathbb Z, \lambda = e^{i\theta} \in S^1, G_n \in \mathfrak g\}.&lt;/math&gt;

{{Hidden begin| titlestyle = color:green;background:lightgrey;|title='''Derivation of the Lie algebra'''}}
To see this, consider elements {{math|''H''(''λ'')}} near the identity in {{math|''G''}} for {{math|''H''}} in the loop group, expressed in a basis {{math|{G_k&lt;nowiki&gt;}&lt;/nowiki&gt;}} for {{math|'''g'''}}
:&lt;math&gt;
H(\lambda) = e^{h^k(\lambda)G_k} = e_G + h^k(\lambda)G_k + \ldots ,
&lt;/math&gt;
where the {{math|''h''&lt;sup&gt;''k''&lt;/sup&gt;(''λ'')}} are real and small and the implicit sum is over the dimension {{math|''K''}} of {{math|'''g'''}}.
Now write
:&lt;math&gt;
h^k(\lambda) = \sum_{n=-\infty}^\infty \theta^k_{-n}\lambda^n
&lt;/math&gt;
to obtain
:&lt;math&gt;
e^{h^k(\lambda)G_k} = 1_G + \sum_{n=-\infty}^\infty \theta^k_{-n}\lambda^nG_k + \ldots .
&lt;/math&gt;
Thus the functions
:&lt;math&gt;
h:S^1 \to \mathfrak g; h(\lambda) = \sum_{n=-\infty}^\infty \sum_{k=1}^K\theta^k_{-n}\lambda^nG_k \equiv \sum_{n=-\infty}^\infty \lambda^nG_n
&lt;/math&gt;
constitute the Lie algebra.
{{Hidden end}}

A little thought confirms that these are loops in {{math|'''g'''}} as {{mvar|θ}} goes from {{math|0}} to {{math|2''π''}}. The operations are the ones defined pointwise by the operations in {{math|'''g'''}}. This algebra is isomorphic with the algebra
:&lt;math&gt;C[\lambda, \lambda^{-1}] \otimes \mathfrak g,&lt;/math&gt;
where {{math|C[''λ'', ''λ''&lt;sup&gt;−1&lt;/sup&gt;]}} is the algebra of [[Laurent polynomial]]s,
:&lt;math&gt;\sum \lambda^k G_k \leftrightarrow \sum \lambda^k \otimes G_k.&lt;/math&gt;
The Lie bracket is
:&lt;math&gt;[P(\lambda) \otimes G_1, Q(\lambda) \otimes G_2] = P(\lambda)Q(\lambda) \otimes [G_1, G_2].&lt;/math&gt;
In this latter view the elements can be considered as polynomials with (constant!) coefficients in {{math|'''g'''}}. In terms of a basis and structure constants,
:&lt;math&gt;[\lambda^m \otimes G_i, \lambda^n \otimes G_j] = {C_{ij}}^k\lambda^{m+n} \otimes G_k.&lt;/math&gt;

It is also common to have a different notation,
:&lt;math&gt;\lambda^m \otimes G_i \cong \lambda^mG_i \leftrightarrow T^m_i(\lambda) \equiv T^m_i,&lt;/math&gt;
where the omission of {{mvar|λ}} should be kept in mind to avoid confusion; the elements really are functions {{math|''S''&lt;sup&gt;1&lt;/sup&gt; → '''g'''}}. The Lie bracket is then
{{Equation box 1
|indent = 
|title= 
|equation = :&lt;math&gt;[T^m_i, T^n_j] = {C_{ij}}^kT^{m+n}_k,&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}
which is recognizable as one of the commutation relations in an untwisted affine Kac–Moody algebra, to be introduced later, ''without'' the central term. With {{math|''m'' {{=}} ''n'' {{=}} 0}}, a subalgebra isomorphic to {{math|'''g'''}} is obtained. It generates (as seen by tracing backwards in the definitions) the set of constant maps from {{math|''S''&lt;sup&gt;1&lt;/sup&gt;}} into {{mvar|G}}, which is obviously isomorphic with {{math|''G''}} when {{math|exp}} is onto (which is the case when {{mvar|G}} is compact. If {{math|''G''}} is compact, then a basis {{math|(''G''&lt;sub&gt;''k''&lt;/sub&gt;)}} for {{math|'''g'''}} may be chosen such that the {{math|''G''&lt;sub&gt;''k''&lt;/sub&gt;}} are skew-Hermitian. As a consequence, 
:&lt;math&gt;T_i^{n\dagger} = (\lambda^nG_i)^{\dagger} = -\lambda^{-n}G_i = -T_i^{-n}.&lt;/math&gt;
Such a representation is called unitary because the representatives
:&lt;math&gt;H(\lambda) = e^{\theta_{n}^k T_k^{-n}} \in G&lt;/math&gt;
are unitary. Here, the minus on the lower index of {{mvar|T}} is conventional, the summation convention applies, and the {{mvar|λ}} is (by the definition) buried in the {{math|''T''}}s in the right hand side.

===Current algebra (physics)===
Current algebras arise in quantum field theories as a consequence of global [[gauge symmetry]]. [[Conserved current]]s occur in [[classical field theory|classical field theories]] whenever the [[Lagrangian (field theory)|Lagrangian]] respects a [[continuous symmetry]]. This is the content of [[Noether's theorem]]. Most (perhaps all) modern quantum field theories can be formulated in terns of classical Lagrangians (prior to quantization), so Noether's theorem applies in the quantum case as well. Upon quantization, the conserved currents are promoted to position dependent operators on Hilbert space. These operators are subject to commutation relations, generally forming an infinite-dimensional Lie algebra. A model illustrating this is presented below.

To enhance the flavor of physics, factors of {{math|''i''}} will appear here and there as opposed to in the mathematical conventions.&lt;ref group=nb name=physics_convention&gt;Roughly, the whole Lie algebra is multiplied by {{mvar|i}}, there is an {{mvar|i}} occurring in the definition of the structure constants and the exponent in the [[exponential map (Lie theory)]] acquires a factor of (minus) {{mvar|i}}. the main reason for this convention is that physicists like their Lie algebra elements to be [[Hermitian]] (as opposed to [[skew-Hermitian]]) in order for them to have real eigenvalues and hence be candidates for [[observable]]s.&lt;/ref&gt;

Consider a column vector {{math|Φ}} of [[scalar field]]s {{math|(Φ&lt;sub&gt;1&lt;/sub&gt;, Φ&lt;sub&gt;2&lt;/sub&gt;, ..., Φ&lt;sub&gt;N&lt;/sub&gt;)}}. Let the Lagrangian density be
:&lt;math&gt;\mathcal L = \partial_\mu \phi^\dagger\partial^\mu\phi - m^2\phi^\dagger\phi.&lt;/math&gt;

This Lagrangian is invariant under the transformation&lt;ref group=nb&gt;Since {{math|''U'' {{=}} −''i''∑''α''&lt;sup&gt;''a''&lt;/sup&gt;''T''&lt;sub&gt;''a''&lt;/sub&gt;}} and {{math|''U''&lt;sup&gt;†&lt;/sup&gt;}} are constant, they may be pulled out of partial derivatives. The {{math|''U''}} and {{math|''U''&lt;sup&gt;†&lt;/sup&gt;}} then combine in {{math|''U''&lt;sup&gt;†&lt;/sup&gt;''U'' {{=}} ''I''}} by unitarity.&lt;/ref&gt;
:&lt;math&gt;\phi \mapsto e^{-i\sum_{a=1}^r\alpha^aF_a}\phi,&lt;/math&gt;

where {{math|&lt;nowiki&gt;{&lt;/nowiki&gt;''F''&lt;sub&gt;1&lt;/sub&gt;, ''F''&lt;sub&gt;1&lt;/sub&gt;, ..., ''F''&lt;sub&gt;r&lt;/sub&gt;&lt;nowiki&gt;}&lt;/nowiki&gt;}} are generators of either {{math|U(''N'')}} or a closed subgroup thereof, satisfying
:&lt;math&gt;[F_a, F_b] = i{C_{ab}}^cF_c.&lt;/math&gt;

Noether's theorem asserts the existence of {{math|r}} conserved currents,
:&lt;math&gt;J_a^\mu = -\pi^\mu iF_a\phi, \quad \pi^{k\mu} = \frac{\partial \mathcal L}{\partial (\partial_\mu \phi_k)},&lt;/math&gt;

where {{math|''π''&lt;sup&gt;''k''0&lt;/sup&gt; ≡ ''π''&lt;sup&gt;''k''&lt;/sup&gt;}} is the momentum canonically conjugate to {{math|Φ&lt;sub&gt;''k''&lt;/sub&gt;}}.
The reason these currents are said to be ''conserved'' is because
:&lt;math&gt;\partial_\mu J^\mu_a = 0,&lt;/math&gt;
and consequently
:&lt;math&gt;Q_a(t) = \int J^0_a d^3x = \mathrm{const} \equiv Q_a,&lt;/math&gt;

the '''charge''' associated to the '''charge density''' {{math|''J''&lt;sub&gt;''a''&lt;/sub&gt;&lt;sup&gt;0&lt;/sup&gt;}} is constant in time.&lt;ref group=nb&gt;This follows from [[Gauss law]] is based on the assumption of a sufficiently rapid fall-off of the fields at infinity.&lt;/ref&gt; This (so far classical) theory is quantized promoting the fields and their conjugates to operators on Hilbert space and by postulating (bosonic quantization) the commutation relations&lt;ref&gt;{{harvnb|Greiner|Reinhardt|1996}}&lt;/ref&gt;&lt;ref group=nb&gt;There are alternative routes to quantization, e.g. one postulates the existence of [[creation and annihilation operators]] for all particle types with certain exchange symmetries based on which statistics, [[Bose–Einstein statistics|Bose–Einstein]] or [[Fermi–Dirac statistics|Fermi–Dirac]], the particles obey, in which case the above are derived for scalar bosonic fields using mostly Lorentz invariance and the demand for the unitarity of the [[S-matrix]]. In fact, ''all'' operators on Hilbert space can be built out of creation and annihilation operators. See e.g. {{harvtxt|Weinberg|2002}}, chapters 2–5.&lt;/ref&gt;
:&lt;math&gt;\begin{align}{}[\phi_k(t, x), \pi^l(t, x)] &amp;= i\delta(x-y)\delta_k^l,\\
                    {}[\phi_k(t, x), \phi_l(t, x)]&amp;= [\pi^k(t, x), \pi^l(t, x)] = 0.\end{align}&lt;/math&gt;
The currents accordingly become operators&lt;ref group=nb&gt;This step is ambiguous, since the classical fields commute whereas the operators don't. Here it is pretended that this problem doesn't exist. In reality, it is never serious as long as one is consistent.&lt;/ref&gt; They satisfy, using the above postulated relations, the definitions and integration over space, the commutation relations
:&lt;math&gt;\begin{align}{}[J_a^0(t, \mathbf x),J_b^0(t, \mathbf y)] &amp;=  i\delta(\mathbf x - \mathbf y){C_{ab}}^cJ_c^0(ct, \mathbf x)\\
                    {}[Q_a, Q_b] &amp;= i{Q_{ab}}^cQ_c\\
                    {}[Q_a, J_b^\mu(t, \mathbf x)] &amp;= i{C_{ab}}^cJ_c^\mu(t, \mathbf x),\end{align}&lt;/math&gt;
where the speed of light and the reduced [[Planck's constant]] have been set to unity. The last commutation relation does ''not'' follow from the postulated commutation relations (these are fixed only for {{math|''π''&lt;sup&gt;''k''0&lt;/sup&gt;}}, not for {{math|''π''&lt;sup&gt;''k''1&lt;/sup&gt;, ''π''&lt;sup&gt;''k''2&lt;/sup&gt;, ''π''&lt;sup&gt;''k''3&lt;/sup&gt;}}), except for {{math|''μ'' {{=}} 0}} For {{math|''μ'' {{=}} 1, 2, 3}} the Lorentz transformation behavior is used to deduce the conclusion. The next commutator to consider is
:&lt;math&gt;[J_a^0(t, \mathbf x), J_b^i(t, \mathbf y)] = i{C_{ab}}^cJ_c^i(t, \mathbf x)\delta(\mathbf x - \mathbf y) + S_{ab}^{ij}\partial_j\delta(\mathbf x - \mathbf y) + ... .&lt;/math&gt;
The presence of the delta functions and their derivatives is explained by the requirement of '''microcausality''' that implies that the commutator vanishes when {{math|'''x''' ≠ '''y'''}}. Thus the commutator must be a distribution supported at {{math|'''x''' {{=}} '''y'''}}.&lt;ref&gt;{{harvnb|Bauerle|de Kerf|1997}} Section 17.5.&lt;/ref&gt; The first term is fixed due to the requirement that the equation should, when integrated over {{math|'''X'''}}, reduce to the last equation before it. The following terms are the '''Schwinger terms'''. They integrate to zero, but it can be shown quite generally&lt;ref&gt;{{harvnb|Bauerle|de Kerf|1997|pp=383–386}}&lt;/ref&gt; that they must be nonzero.

{{Hidden begin| titlestyle = color:green;background:lightgrey;|title='''Existence of Schwinger terms'''}}
Consider a conserved current
{{NumBlk|:|&lt;math&gt;\partial_0J^0 + \partial_i J^i=0, \quad \langle 0|J^i|0\rangle=0, \quad J^{0\dagger} J^0 = J^0J^{0\dagger} = I.&lt;/math&gt;|{{EquationRef|S10}}}}
with a generic Schwinger term
:&lt;math&gt;[J^0(t,\mathbf x),J^i(t,\mathbf y)] = i\delta(\mathbf x - \mathbf y)J^i(t,\mathbf x) + C^i(\mathbf x, \mathbf y).&lt;/math&gt;
By taking the [[vacuum expectation value]] (VEV),
:&lt;math&gt;\langle 0|C^i(\mathbf x, \mathbf y)|0\rangle = \langle 0|[J^0(t,\mathbf x),J^i(t,\mathbf y)]|0\rangle,&lt;/math&gt;
one finds
:&lt;math&gt;\begin{align}\langle 0|\frac{\partial C^i(\mathbf x, \mathbf y)}{\partial_{y^i}}|0\rangle &amp;= \langle 0|[J^0(t,\mathbf x),\frac{\partial J^i(t,\mathbf y)}{\partial_{y^i}}]|0\rangle\\ &amp;= -\langle 0|[J^0(t,\mathbf x),\frac{\partial J^0(t,\mathbf y)}{\partial_{t}}]|0\rangle = i\langle 0|[J^0(t,\mathbf x),[J^0(t,\mathbf y),H]]|0\rangle\\ &amp;= -i\langle 0|J^0(t,\mathbf x)HJ^0(t,\mathbf y)+J^0(t,\mathbf x)HJ^0(t,\mathbf x)|0\rangle,\end{align}&lt;/math&gt;
where {{EquationNote|S10}} and [[Heisenberg's equation]] of motion have been used as well as {{math|''H''{{!}}0⟩ {{=}} 0}} and its conjugate.

Multiply this equation by {{math|''f''('''x''')''f''('''y''')}} and integrate with respect to {{math|'''x'''}} and {{math|'''y'''}} over all space, using [[integration by parts]], and one finds
:&lt;math&gt;-i\int\int d\mathbf x d\mathbf y\langle 0|C^i(\mathbf x, \mathbf y)|0\rangle f(\mathbf x)\frac{\partial f}{\partial y^i}f(\mathbf x) = 2\langle 0|FHF|\rangle, \quad F = \int J^0(\mathbf x)f(\mathbf x).&lt;/math&gt;
Now insert a complete set of states, {{math|{{!}}''n⟩}}
:&lt;math&gt;\langle 0|FHF|\rangle = \sum_{mn}\langle 0|F|m\rangle\langle m|H|n\rangle\langle n|F|0\rangle=\sum_{mn}\langle 0|F|m\rangle E_n\delta_{mn}\langle n|F|0\rangle ) \sum_{n \ne 0}|\langle 0|F|n\rangle|^2E_n &gt; 0 \Rightarrow C^i(\mathbf x, \mathbf y) \ne 0.&lt;/math&gt;
Here hermiticity of {{mvar|F}} and the fact that not all matrix elements of {{mvar|F}} between the vacuum state and the states from a complete set can be zero.
{{Hidden end}}

===Affine Kac–Moody algebra===
{{main|Kac–Moody algebra}}
Let {{math|'''g'''}} be an {{math|''N''}}-dimensional complex simple Lie algebra with a dedicated suitable normalized basis such that the structure constants are antisymmetric in all indices with commutation relations
:&lt;math&gt;[G_i,G_j] = {C_{ij}}^kG_k, \quad 1 \le i, j, N.&lt;/math&gt;
An '''untwisted affine Kac–Moody algebra''' {{math|{{overline|'''g'''}}}} is obtained by copying the basis for each {{math|''n'' ∈ ℤ}} (regarding the copies as distinct), setting
:&lt;math&gt;\overline{\mathfrak g} = FC \oplus FD \oplus \bigoplus_{1 \le i \le \N,m \in \mathbb Z} FG^i_m&lt;/math&gt;
as a vector space and assigning the commutation relations

:&lt;math&gt;\begin{align}{}[G_i^m,G_j^n] &amp;= {C_{ij}}^kG_k^{m+n} + m\delta_{ij}\delta^{m+n,0}C,\\
                    {}[C,G_i^m] &amp;= 0, \quad 1 \le i, j, N,\quad m,n \in \mathbb Z\\
                    {}[D, G_i^m] &amp;= mG_i^m\\
                    {}[D,C] &amp;= 0.\end{align}&lt;/math&gt;

If {{math|''C'' {{=}} ''D'' {{=}} 0}}, then the subalgebra spanned by the {{math|''G''&lt;sup&gt;''m''&lt;/sup&gt;&lt;sub&gt;''i''&lt;/sub&gt;}} is obviously identical to the polynomial loop algebra of above.

===Witt algebra===
[[File:Ernst Witt.jpeg|180px|right|thumb|[[Ernst Witt]] (1911–1991), German mathematician. The Witt algebras, studied by him over finite fields in the 1930s, were first examined in the complex case by [[Elie Cartan|Cartan]] in 1909.]]
{{main|Witt algebra}}
The [[Witt algebra]], named after [[Ernst Witt]], is the complexification of the Lie algebra {{math|Vect''S''&lt;sup&gt;1&lt;/sup&gt;}} of smooth [[vector fields]] on the circle {{math|''S''&lt;sup&gt;1&lt;/sup&gt;}}. In coordinates, such vector fields may be written
:&lt;math&gt;X = f(\varphi)\frac{d}{d\varphi},&lt;/math&gt;
and the Lie bracket is the Lie bracket of vector fields, on {{math|''S''&lt;sup&gt;1&lt;/sup&gt;}} simply given by
:&lt;math&gt;[X, Y] = \left[f\frac{d}{d\varphi}, g\frac{d}{d\varphi}\right] = \left(f\frac{dg}{d\varphi} - g\frac{df}{d\varphi}\right)\frac{d}{d\varphi}.&lt;/math&gt;
The algebra is denoted {{math|''W'' {{=}} Vect''S''&lt;sup&gt;1&lt;/sup&gt; + ''i''Vect''S''&lt;sup&gt;1&lt;/sup&gt;}}.
A basis for {{mvar|W}} is given by the set
:&lt;math&gt;\{d_n, n \in \mathbb Z\} = \left\{\left .ie^{in\varphi}\frac{d}{d\varphi} = -z^{n+1}\frac{d}{dz}\right|n \in \mathbb Z \right\}.&lt;/math&gt;
This basis satisfies
{{Equation box 1
|indent = 
|title= 
|equation = :&lt;math&gt;[d_l, d_m] = (l-m)d_{l+m} \equiv {C_{lm}}^nd_n = (l-m)\delta_{l+m}^nd_n,\quad l,m,n \in \mathbb Z.&lt;/math&gt;
|cellpadding= 6
|border
|border colour = #0073CF
|bgcolor=#F9FFF7}}

This Lie algebra has a useful central extension, the Virasoro algebra. It has {{math|3-}}dimensional subalgebras isomorphic with {{math|'''su'''(1, 1)}} and {{math|'''sl'''(2, ℝ)}}. For each {{math|''n'' ≠ 0}}, the set {{math|{''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;''−n''&lt;/sub&gt;, ''d''&lt;sub&gt;''n''&lt;/sub&gt;&lt;nowiki&gt;}&lt;/nowiki&gt;}} spans a subalgebra isomorphic to {{math|'''su'''(1, 1) ≅ '''sl'''(2, ℝ)}}.

{{Hidden begin| titlestyle = color:green;background:lightgrey;|title=Relationship to {{math|'''sl'''(2, ℝ)}} and {{math|'''su'''(1, 1)}}}}
For {{math|''m'', ''n'' ∈ {−1, 0, 1&lt;nowiki&gt;}&lt;/nowiki&gt;}} one has
:&lt;math&gt;[d_0, d_{-1}] = d_{-1}, \quad [d_0, d_{1}] = -d_{1},\quad [d_1, d_{-1}] = 2d_0.&lt;/math&gt;
These are the commutation relations of {{math|'''sl'''(2, ℝ)}} with
:&lt;math&gt;d_0 \leftrightarrow H = \left(\begin{smallmatrix} 1 &amp; 0\\ 0 &amp; -1\end{smallmatrix}\right), 
 \quad d_{-1} \leftrightarrow X = \left(\begin{smallmatrix} 0 &amp; 1\\ 0 &amp; 0\end{smallmatrix}\right),
 \quad d_1 \leftrightarrow Y = \left(\begin{smallmatrix} 0 &amp; 0\\ 1 &amp; 0\end{smallmatrix}\right), \quad H, X, Y \in \mathfrak{sl}(2, \mathbb R).&lt;/math&gt;
The groups {{math|SU(1, 1)}} and {{math|SL(2, ℝ)}} are isomorphic under the map&lt;ref&gt;{{harvnb|Rossmann|2002|loc=Section 4.2}}&lt;/ref&gt;
:&lt;math&gt;SU(1,1) = \left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)SL(2, \mathbb R)\left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)^{-1},&lt;/math&gt; 
and the same map holds at the level of Lie algebras due to the properties of the [[exponential map (Lie theory)|exponential map]].
A basis for {{math|'''su'''(1, 1)}} is given, see [[classical group]], by
:&lt;math&gt;U_0 = \left(\begin{smallmatrix} 0 &amp; 1\\ 1 &amp; 0\end{smallmatrix}\right), 
 \quad U_1 = \left(\begin{smallmatrix} 0 &amp; -i\\ i &amp; 0\end{smallmatrix}\right),
 \quad U_2 = \left(\begin{smallmatrix} i &amp; 0\\ 0 &amp; -i\end{smallmatrix}\right)&lt;/math&gt;
Now compute
:&lt;math&gt;\begin{align}H_{\mathfrak{su}(1,1)} &amp;= \left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)H\left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)^{-1}
=\left(\begin{smallmatrix} 0 &amp; 1\\ 1 &amp; 0\end{smallmatrix}\right) = U_0,\\
X_{\mathfrak{su}(1,1)} &amp;= \left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)X\left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)^{-1}
=\frac{1}{2}\left(\begin{smallmatrix} i &amp; -i\\ i &amp; -i\end{smallmatrix}\right) = \frac{1}{2}(U_1+U_2),\\
Y_{\mathfrak{su}(1,1)} &amp;= \left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)Y\left(\begin{smallmatrix} 1 &amp; -i\\ 1 &amp; i\end{smallmatrix}\right)^{-1}
=\frac{1}{2}\left(\begin{smallmatrix} -i &amp; -i\\ i &amp; i\end{smallmatrix}\right) = \frac{1}{2}(U_1-U_2).
\end{align}&lt;/math&gt;
The map preserves brackets and there are thus Lie algebra isomorphisms between the subalgebra of {{mvar|W}} spanned by {{math|{''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;−1&lt;/sub&gt;, ''d''&lt;sub&gt;1&lt;/sub&gt;&lt;nowiki&gt;}&lt;/nowiki&gt;}} with ''real'' coefficients, {{math|'''sl'''(2, ℝ)}} and {{math|'''su'''(1, 1)}}. The same holds for ''any'' subalgebra spanned by {{math|{''d''&lt;sub&gt;0&lt;/sub&gt;, ''d''&lt;sub&gt;−''n''&lt;/sub&gt;, ''d''&lt;sub&gt;''n''&lt;/sub&gt;&lt;nowiki&gt;}&lt;/nowiki&gt;, ''n'' ≠ 0}}, this follows from a simple rescaling of the elements (on either side of the isomorphisms).
{{Hidden end}}

===Projective representation===
{{main|Wigner's theorem|Projective representation|Group cohomology}}
If {{mvar|''G''}} is a [[matrix Lie group]], then elements {{mvar|''G''}} of the Lie algebra can be given by
:&lt;math&gt;G = \frac{d}{dt}\left .(g(t))\right|_{t=0},&lt;/math&gt;
where {{mvar|α}} is a differentiable path in {{mvar|G}} that goes through the identity element at {{math|''t'' {{=}} 0}}. Commutators of elements of the Lie algebra can be computed using two paths, {{math|''g''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt;}} and the group commutator,
:&lt;math&gt;[G_1, G_2] = \frac{d}{dt} \left .g_1(t)g_2(t)g_1(t)^{-1}g_2(t)^{-1}\right|_{t = 0}, \quad G_1 = g_1'(0), G_2 = g_2'(0).&lt;/math&gt;

Likewise, given a group representation {{math|''U''(''G'')}}, its Lie algebra {{math|'''u'''('''g''')}} is computed by
:&lt;math&gt;\begin{align}[] [U_1, U_2] &amp;= \frac{d}{dt} \left .U(g_1(t))U(g_2(t))U(g_1(t))^{-1}U(g_2(t))^{-1}\right|_{t = 0}\\
&amp;= \frac{d}{dt} \left .U(g_1(t)g_2(t)g_1(t)^{-1}g_2(t)^{-1})\right|_{t = 0}, \quad G_1 = g_1'(0), G_2 = g_2'(0).\end{align}&lt;/math&gt;
Then there is a Lie algebra between {{math|'''g'''}} and {{math|'''u'''('''g''')}} isomorphism sending bases to bases, so that {{math|'''u'''}} is a faithful representation of {{math|'''g'''}}.

If however {{math|''U''(''G'')}} is a [[projective representation]], i.e. a representation up to a phase factor,then the Lie algebra, as computed from the group representation, is ''not'' isomorphic to {{math|'''g'''}}. In a projective representation the multiplication rule reads
:&lt;math&gt;U(g_1)U(g_2) = \omega(g_1, g_2)U(g_1g_2) = e^{i\xi(g_1, g_2)}U(g_1g_2).&lt;/math&gt;
The function {{mvar|ω}},often required to be smooth, satisfies
:&lt;math&gt;\begin{align}\omega(g,e)&amp;=\omega(e,g) = 1,\\
\omega(g_1, g_2g_3)\omega(g_2,g_3) &amp;= \omega(g_1,g_2)\omega(g_1g_2,g_3)\\
\omega(g,g^{-1})&amp;=\omega(g^{-1},g).\end{align}&lt;/math&gt;
It is called a '''2-cocycle''' on {{mvar|''G''}}.

One has
:&lt;math&gt;\begin{align}[] [U_1, U_2] &amp;= \frac{d}{dt} \left .U(g_1(t))U(g_2(t))U(g_1(t))^{-1}U(g_2(t))^{-1}\right|_{t = 0}\\
&amp;= \frac{d}{dt} \left .e^{i\xi(g_1,g_2)\xi(g_1^{-1}, g_2^{-1})\xi(g_1g_2, g_1^{-1}g_2^{-1})}U(g_1(t)g_2(t)g_1(t)^{-1}g_2(t)^{-1})\right|_{t = 0}\\
&amp;\equiv \frac{d}{dt} \left .\Omega(g_1,g_2)U(g_1(t)g_2(t)g_1(t)^{-1}g_2(t)^{-1})\right|_{t = 0}\\
&amp;= \left .\frac{dU(g_1(t)g_2(t)g_1(t)^{-1}g_2(t)^{-1})}{dt}\right|_{t = 0} + \left .\frac{d\Omega(g_1,g_2)}{dt}\right|_{t=0}I, \quad G_1 = g_1'(0), G_2 = g_2'(0),\end{align}&lt;/math&gt;
because both {{math|Ω}} and {{mvar|U}} evaluate to the identity at {{math|''t'' {{=}} 0}}. For an explanation of the phase factors {{mvar|ξ}}, see [[Wigner's theorem]]. The commutation relations in {{math|'''g'''}} for a basis,
:&lt;math&gt;[G_i,G_j] = {C_{ij}^k}G_k&lt;/math&gt;
become in {{math|'''u'''}}
:&lt;math&gt;[U_i,U_j] = {C_{ij}^k}U_k + D_{ij}I,&lt;/math&gt;
so in order for {{math|'''u'''}} to be closed under the bracket (and hence have a chance of actually being a Lie algebra) a [[central charge]] {{math|''I''}} must be included.

===Relativistic classical string theory===
{{main|Bosonic string theory}}
A classical relativistic string traces out a [[Worldsheet|world sheet]] in spacetime, just like a point particle traces out a [[world line]]. This world sheet can locally be [[Parametrization|parametrized]] using two parameters {{mvar|σ}} and {{mvar|τ}}. Points {{math|''x''&lt;sup&gt;''μ''&lt;/sup&gt;}} in spacetime can, in the range of the parametrization, be written {{math|''x''&lt;sup&gt;''μ''&lt;/sup&gt; {{=}} ''x''&lt;sup&gt;''μ''&lt;/sup&gt;(''σ'', ''τ'')}}. One uses a capital {{mvar|X}} to denote points in spacetime actually being on the world sheet of the string. Thus the string parametrization is given by {{math|(''σ'', ''τ'') ↦(''X''&lt;sup&gt;0&lt;/sup&gt;(''σ'', ''τ''), ''X''&lt;sup&gt;1&lt;/sup&gt;(''σ'', ''τ''), ''X''&lt;sup&gt;2&lt;/sup&gt;(''σ'', ''τ''), ''X''&lt;sup&gt;3&lt;/sup&gt;(''σ'', ''τ''))}}. The inverse of the parametrization provides a [[coordinate chart|local coordinate system]] on the world sheet in the sense of [[manifold]]s.

The equations of motion of a classical relativistic string derived in the [[Lagrangian mechanics|Lagrangian formalism]] from the [[Nambu–Goto action]] are&lt;ref&gt;{{harvnb|Zwiebach|2004}} Equation 6.53 (supported by 6.49, 6.50).&lt;/ref&gt;
:&lt;math&gt;\frac{\partial \mathcal P_\mu^\tau}{\partial \tau} + \frac{\partial \mathcal P_\mu^\sigma}{\partial \sigma} = 0, \quad
\mathcal P_\mu^\tau = -\frac{T_0}{c}\frac{(\dot X \cdot X')X'_\mu - (X')^2\dot X_\mu}{\sqrt{(\dot X \cdot X')^2 - (\dot X)^2(X')^2}},\quad
\mathcal P_\mu^\sigma = -\frac{T_0}{c}\frac{(\dot X \cdot X')X'_\mu - (\dot X)^2 X'_\mu}{\sqrt{(\dot X \cdot X')^2 - (\dot X)^2(X')^2}}.&lt;/math&gt;
A dot ''over'' a quantity denotes differentiation with respect to {{mvar|τ}} and a prime differentiation with respect to {{mvar|σ}}. A dot ''between'' quantities denotes the relativistic inner product.

These rather formidable equations simplify considerably with a clever choice of parametrization called the [[light cone gauge]]. In this gauge, the equations of motion become
:&lt;math&gt;\ddot X^\mu - {X^\mu}'' = 0,&lt;/math&gt;
the ordinary [[wave equation]]. The price to be paid is that the light cone gauge imposes constraints,
:&lt;math&gt;\dot X^\mu \cdot {X^\mu}' = 0, \quad (\dot X)^2 + (X')^2 = 0,&lt;/math&gt;
so that one cannot simply take arbitrary solutions of the wave equation to represent the strings. The strings considered here are open strings, i.e. they don't close up on themselves. This means that the [[Neumann boundary condition]]s have to be imposed on the endpoints. With this, the general solution of the wave equation (excluding constraints) is given by 
:&lt;math&gt; X^\mu(\sigma, \tau) = x_0^\mu + 2\alpha'p_0^\mu\tau - i\sqrt{2\alpha'}\sum_{n=1}\left( a_n^{\mu*}e^{in\tau} - a_n^{\mu}e^{-in\tau}\right)\frac{\cos n\sigma}{\sqrt n},&lt;/math&gt;
where {{math|''α''&lt;nowiki&gt;'&lt;/nowiki&gt;}} is the '''slope parameter''' of the string (related to the '''string tension'''). The quantities {{math|''x''&lt;sub&gt;0&lt;/sub&gt;}} and {{math|''p''&lt;sub&gt;0&lt;/sub&gt;}} are (roughly) string position from the initial condition and string momentum. If all the {{math|''α''{{supsub|''μ''|''n''}}}} are zero, the solution represents the motion of a classical point particle.

This is rewritten, first defining
:&lt;math&gt;\alpha_0^\mu = \sqrt{2\alpha'}a_ \mu,\quad \alpha_n^\mu = a_n^\mu\sqrt{n}, \quad \alpha_{-n}^\mu = a_n^{\mu*}\sqrt{n},&lt;/math&gt;
and then writing
:&lt;math&gt; X^\mu(\sigma, \tau) = x_0^\mu + \sqrt{2\alpha'}\alpha_0^\mu \tau + i\sqrt{2\alpha'}\sum_{n\ne 0}\frac{1}{n}\alpha_n^{\mu}e^{-in\tau}\cos n\sigma.&lt;/math&gt;

In order to satisfy the constraints, one passes to [[light cone coordinates]]. For {{math|''I'' {{=}} 2, 3, ...''d''}}, where {{math|''d''}} is the number of ''space'' dimensions, set 
:&lt;math&gt;\begin{align}
X^I(\sigma, \tau) &amp;= x_0^I + \sqrt{2\alpha'}\alpha_0^I \tau + i\sqrt{2\alpha'}\sum_{n \ne 0}\frac{1}{n}\alpha_n^{I}e^{-in\tau}\cos n\sigma,\\
X^+(\sigma, \tau) &amp;= \sqrt{2\alpha'}\alpha_0^+ \tau,\\
X^-(\sigma, \tau) &amp;= x_0^- + \sqrt{2\alpha'}\alpha_0^- \tau + i\sqrt{2\alpha'}\sum_{n \ne 0}\frac{1}{n}\alpha_n^{-}e^{-in\tau}\cos n\sigma. \end{align}&lt;/math&gt;

Not all {{math|''α''&lt;sub&gt;''n''&lt;/sub&gt;&lt;sup&gt;''μ''&lt;/sup&gt;, ''n'' ∈ ℤ, ''μ'' ∈ &lt;nowiki&gt;{&lt;/nowiki&gt;+, −, 2, 3, ..., ''d''&lt;nowiki&gt;}&lt;/nowiki&gt;}} are independent. Some are zero (hence missing in the equations above), and the "minus coefficients" satisfy
:&lt;math&gt;\sqrt{2\alpha'}\alpha_n^- = \frac{1}{2p^+}\sum_{p \in \mathbb Z}\alpha_{n-p}^I\alpha_p^I.&lt;/math&gt;
The quantity on the left is given a name, 
:&lt;math&gt;\sqrt{2\alpha'}\alpha_n^- \equiv \frac{1}{p^+}L_n,\quad L_n = \frac{1}{2}\sum_{p \in \mathbb Z}\alpha_{n-p}^I\alpha_p^I,&lt;/math&gt;
the '''transverse Virasoro mode'''.

When the theory is quantized, the alphas, and hence the {{math|''L''&lt;sub&gt;''n''&lt;/sub&gt;}} become operators.

==See also==
*[[Group cohomology]]
*[[Group contraction]] ('''Inönu–Wigner contraction''')
*[[Group extension]]
*[[Lie algebra cohomology]]
*[[Ring extension]]

==Remarks==
{{reflist|group=nb}}

==Notes==
{{reflist}}

==References==

===Books===
*{{cite book|ref=harv|last1=Bäuerle|first1=G.G.A|last2=de Kerf|first2=E.A.|title=Finite and infinite dimensional Lie algebras and their application in physics|year=1990|series=Studies in mathematical physics|volume=1|editor1=A. van Groesen|editor2=E.M. de Jager|publisher=North-Holland|isbn=978-0-444-88776-4}}
*{{cite book|ref=harv|last1=Bäuerle|first1=G.G.A|last2=de Kerf|first2=E.A.|last3=ten Kroode|first3=A. P. E.|title=Finite and infinite dimensional Lie algebras and their application in physics|year=1997|series=Studies in mathematical physics|volume=7|editor1=A. van Groesen|editor2=E.M. de Jager|publisher=North-Holland|isbn=978-0-444-82836-1|url=http://www.sciencedirect.com/science/bookseries/09258582|via=[[ScienceDirect]]|subscription=yes}}
*{{cite book|ref=harv|editor-first1=P.|editor-last1=Goddard|editor-link1=Peter Goddard (physicist)|editor-first2=D.|editor-last2=Olive|editor-link2=David Olive|title=Kac–Moody and Virasoro algebras, A reprint Volume for Physicists|series=Advanced Series in Mathematical Physics|volume=3|publisher=World Scientific Publishing|location=Singapore|year=1988|isbn=978-9971-50-419-9|url=https://books.google.com/?id=Wpk6Q-gFTmwC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false}}
*{{cite book|last=Goldin|first=G.A.|editor-first1=J-P.|editor-last1=Françoise|editor-first2=G. L.|editor-last2=Naber|editor-first3=T. S.|editor-last3=Tsun|ref=harv|title=Encyclopedia of Mathematical Physics|at=Current Algebra|isbn=978-0-12-512666-3|year=2006}}
*{{cite book|first1=M.B.|last1=Green|authorlink1=Michael Green (physicist)|first2=J.H.|last2=Schwarz|authorlink2=John Henry Schwarz|first3=E.|last3=Witten|authorlink3=Edward Witten|title=Superstring theory|volume=l|publisher=[[Cambridge University Press]]|year=1987|isbn=9781107029118}}
*{{cite book|ref=harv|last=Greiner|first=W.|authorlink=Walter Greiner|last2=Reinhardt|first2=J.|year=1996|title=Field Quantization|publisher=[[Springer Publishing]]|isbn=978-3-540-59179-5}}
*{{cite book|ref=harv|last=Humphreys|first=J. E.|authorlink=James E. Humphreys|title=Introduction to Lie Algebras and Representation Theory|edition=3rd|isbn=978-3-540-90053-5|publisher=[[Springer-Verlag]]|location=Berlin·Heidelberg·New York|year=1972}}
*{{cite book|ref=harv|first=V.G.|last=Kac|title=Infinite-dimensional Lie algebras|edition=3rd|publisher=[[Cambridge University Press]]|year=1990|authorlink=Victor Kac|isbn=978-0-521-37215-2}}
*{{cite book|ref=harv|first=A.|last=Knapp|authorlink=Anthony Knapp|title=Lie groups beyond an introduction|edition=2nd|year=2002|publisher=[[Birkhäuser]]|location=Boston·Basel·Berlin|editor-last1=bass|editor-first1=H.|editor-last2=Oesterlé|editor-first2=J.|editor-last3=Weinstein|editor-first3=A.|series=Progress in mathematics|volume=140|isbn=978-0-8176-4259-4}}
*{{cite book|ref=harv|last=Rossmann|first= Wulf|title=Lie Groups - An Introduction Through Linear Groups|publisher=Oxford Science Publications|year=2002|series=Oxford Graduate Texts in Mathematics|isbn=0 19 859683 9|postscript=&lt;!--none--&gt;}}
*{{cite book|first=M.|last=Schottenloher|title=A Mathematical Introduction to Conformal Field Theory|publisher=[[Springer-Verlag]]|location=Berlin, Heidelberg|year=2008|orig-year=1997|edition=2nd|isbn=978-3-540-68625-5}}
*{{cite book|ref=harv|last=Weinberg|first=S.|year=2002|title=The Quantum Theory of Fields|volume=I|isbn=978-0-521-55001-7|authorlink=Steven Weinberg|publisher=[[Cambridge University Press]]}}
*{{cite book|ref=harv|last=Weinberg|first=S.|year=1996|title=The Quantum Theory of Fields|volume=II|isbn=978-0-521-55002-4|publisher=Cambridge University Press}}
*{{cite book|ref=harv|last=Zwiebach|first=B.|authorlink=Barton Zwiebach|title=A First Course in String Theory|year=2004|publisher=[[Cambridge University Press]]|isbn=0 521 83143 1}}

===Journals===
*{{cite journal|ref=harv|first=V.|last=Bargmann|authorlink=Valentine Bargmann|title=On unitary ray representations of continuous groups|journal=Ann. of Math.|volume=59|issue=1|year=1954|pages=1–46|doi=10.2307/1969831|jstor=1969831}}
*{{cite journal|ref=harv|last=Dolan|first=L.|title=The Beacon of Kac–Moody Symmetry for Physics|journal=Notices of the AMS|volume=42|issue=12|year=1995|pages=1489–1495|issn=0002-9920|url=http://www.ams.org/notices/199512/index.html|bibcode=1996hep.th....1117D|arxiv=hep-th/9601117}}
*{{cite journal|ref=harv|last=Kac|first=V. G.|authorlink=Victor Kac|year=1967R|title=[Simple graded Lie algebras of finite growth]|journal=Funkt. Analis I Ego Prilozh|volume=1|issue=4|pages=82–83|language=Russian}}
*{{cite journal|ref=harv|last=Kac|first=V. G.|year=1967E|title=Simple graded Lie algebras of finite growth|journal=Funct. Anal. Appl.|volume=1|pages=328–329}} (English translation)
*&lt;!--{{cite journal|ref=harv|last=Kac|first=V. G.|year=1968|title=Simple irreducible graded Lie algebras of finite growth|journal=Mathematics of the USSR - 
Izvestiya|year=1968|volume=2|issue=6|pages=1271–1311|url=http://iopscience.iop.org/0025-5726/2/6/A06|subscription=yes|publisher=IOP Science|authorlink=Victor Kac}}--&gt;
*
*{{cite journal|ref=harv|last1=Goddard|first1=P.|authorlink1=Peter Goddard (physicist)|last2=Olive|first2=D.|authorlink2=David Olive|volume=1|issue=2|year=1986|title=Kac–Moody and Virasoro algebras in relation to quantum physics|journal= Int. J. Mod. Phys. A|pages=303–414|doi=10.1142/S0217751X86000149|bibcode = 1986IJMPA...1..303G }} This can be found in [https://books.google.com/books?id=Wpk6Q-gFTmwC&amp;printsec=frontcover&amp;hl=sv#v=onepage&amp;q&amp;f=false Kac–Moody and Virasoro algebras, A reprint Volume for Physicists]
*{{cite journal|ref=harv|last=Moody|first=R. V.|authorlink=Robert Moody|title=Lie algebras associated with generalized Cartan matrices|journal=Bull. Amer. Math. Soc.|volume=73|issue=2|year=1967|pages=217–221|url=http://www.ams.org/journals/bull/1967-73-02/S0002-9904-1967-11688-4/home.html|mr=0207783|zbl=0154.27303|doi=10.1090/S0002-9904-1967-11688-4}} (open access)
*{{cite journal|ref=harv|last=Schreier|first=O.|authorlink=Otto Schreier|journal=Monatshefte für Mathematik|volume=34|issue=1|pages=165–180|year=1926|doi=10.1007/BF01694897|title=Uber die Erweiterung von Gruppen I|trans-title=On the theory of group extensions I|language=German}}
*{{cite journal|ref=harv|last=Schreier|first=O.|journal=Abhandlungen aus dem Mathematischen Seminar der Universität Hamburg|volume=4|issue=1|pages=321–346|year=1925|doi=10.1007/BF02950735|title=Uber die Erweiterung von Gruppen II|language=German|trans-title=On the theory of group extensions II}}
*{{cite journal|first=M. A.|last=Virasoro|authorlink=Miguel Ángel Virasoro (physicist)|url=http://prola.aps.org/abstract/PRD/v1/i10/p2933_1|title=Subsidiary conditions and ghosts in dual-resonance models|journal=Phys. Rev. D|volume=1|issue=10|year=1970|pages=2933–2936|doi=10.1103/PhysRevD.1.2933|bibcode = 1970PhRvD...1.2933V }}
*{{cite journal|ref=harv|first1=G.M.|last1=Tuynman|first2=W.A.J.J.|last2=Wiegerinck|title=Central extensions and physics|journal=J. Geometry and Physics|volume=4|year=1987|pages=207–258|via=[[ScienceDirect]]|subscription=yes|doi=10.1016/0393-0440(87)90027-1|issue=2|url=http://www.sciencedirect.com/science/article/pii/0393044087900271|bibcode = 1987JGP.....4..207T }}

===Web===
*{{cite web|ref=harv|last=MacTutor|year=2015|website=MacTutor History of Mathematics|access-date=2015-03-08|url=http://www-history.mcs.st-and.ac.uk/history/Biographies/Schreier.html|title=Schreier biography}}

[[Category:Lie groups]]
[[Category:Quantum field theory]]
[[Category:Lie algebras]]
[[Category:Mathematical physics]]
[[Category:Conformal field theory]]
[[Category:String theory]]</text>
      <sha1>diax6zeck90onjzyfc45ny6pwvorm5r</sha1>
    </revision>
  </page>
  <page>
    <title>Lindsey–Fox algorithm</title>
    <ns>0</ns>
    <id>36266522</id>
    <revision>
      <id>862709739</id>
      <parentid>852437406</parentid>
      <timestamp>2018-10-06T05:23:21Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15556">{{orphan|date=September 2012}}

The '''Lindsey–Fox algorithm''', named after Pat Lindsey and Jim Fox, is a numerical [[algorithm]] for finding the roots or zeros of a high-degree [[polynomial]] with real coefficients over the [[complex field]].  It is particularly designed for random coefficients but also works well on polynomials with coefficients from samples of speech, seismic signals, and other measured phenomena. A [[Matlab]] implementation of this has factored polynomials of degree over a million on a desk top computer.

== The Lindsey–Fox algorithm==
The Lindsey–Fox algorithm uses the [[Fast Fourier transform|FFT]] (fast Fourier transform) to very efficiently conduct a grid search in the complex plane to find accurate approximations to the ''N'' roots (zeros) of an ''N''th-degree polynomial. The power of this grid search allows a new [[Factorization of polynomials|polynomial factoring]] strategy that has proven to be very effective for a certain class of polynomials. This algorithm was conceived of by Pat Lindsey and implemented by Jim Fox in a package of computer programs created to factor high-degree polynomials. It was originally designed and has been further developed to be particularly suited to polynomials with real, random coefficients. In that form, it has proven to be very successful by factoring thousands of polynomials of degrees from one thousand to hundreds of thousand as well as several of degree one million and one each of degree two million and four million. In addition to handling very high degree polynomials, it is accurate, fast, uses minimum memory, and is programmed in the widely available language, Matlab. There are practical applications, often cases where the coefficients are samples of some natural signal such as speech or seismic signals, where the algorithm is appropriate and useful. However, it is certainly possible to create special, ill-conditioned polynomials that it cannot factor, even low degree ones. The basic ideas of the algorithm were first published by Lindsey and Fox in 1992&lt;ref&gt;J. P. Lindsey and James W. Fox. “A method of factoring long z-transform polynomials”, Computational Methods in Geosciences, SIAM, pp. 78–90, 1992.&lt;/ref&gt; and reprinted in 1996.&lt;ref&gt;Osman Osman (editor), Seismic Source Signature Estimation and Measurement, Geophysics Reprint Series #18, Society of Exploration Geophysicists (SEG), 1996, pp. 712–724.&lt;/ref&gt;&amp;nbsp; After further development, other papers were published in 2003&lt;ref&gt;Gary A. Sitton, C. Sidney Burrus, James W. Fox, and Sven Treitel. “Factoring very high degree polynomials”. IEEE Signal Processing Magazine, 20(6):27–42, November 2003.&lt;/ref&gt;&lt;ref&gt;C. S. Burrus, J. W. Fox, G. A. Sitton, and S. Treitel, “Factoring High Degree Polynomials in Signal Processing”, Proceedings of the IEEE DSP Workshop, Taos, NM, Aug. 3, 2004, pp. 156–157.&lt;/ref&gt; and an on-line booklet.&lt;ref&gt;{{cite web|url=http://cnx.org/content/col10494/latest/|author=C. Sidney Burrus|title=Factoring Polynomials of High Degree|work=Connexions|date=Apr 1, 2012|publisher=Rice University|quote=Accepted by the IEEE Signal Processing Society Lens|accessdate=23 July 2012}}&lt;/ref&gt;&amp;nbsp; The program was made available to the public in March 2004 on the Rice University web site.&lt;ref&gt;{{cite web|url=http://www-dsp.rice.edu/software/fvhdp.shtml|title=Factoring Very High Degree Polynomials|date=March 10, 2006|author1=C. S. Burrus |author2=J. W. Fox |author3=G. A. Sitton |author4=and S. Treitel |publisher=Rice University|accessdate = 23 July 2012}}{{failed verification|date=July 2012}}&lt;/ref&gt;&amp;nbsp; A more robust version-2 was released in March 2006 and updated later in the year.

==The three stages of the Lindsey–Fox program==
The strategy implemented in the Lindsey–Fox algorithm to factor polynomials is organized in three stages. The first evaluates the polynomial over a grid on the complex plane and conducts a direct search for potential zeros. The second stage takes these potential zeros and “polishes” them by applying [[Laguerre's method]] to bring them close to the actual zeros of the polynomial. The third stage multiplies these zeros together or “unfactors” them to create a polynomial that is verified against the original. If some of the zeros were not found, the original polynomial is “deflated” by dividing it by the polynomial created from the found zeros. This quotient polynomial will generally be of low order and can be factored by conventional methods with the additional, new zeros added to the set of those first found. If there are still missing zeros, the deflation is carried out until all are found or the whole program needs to be restarted with a finer grid. This system has proven to be fast, accurate, and robust on the class of polynomials with real, random coefficients and other similar, well-conditioned polynomials.

=== Stage one: the grid search for prospective zeros ===
# Construct a [[polar coordinate]] grid on the complex plane with spacing derived from the degree of the polynomial being factored
# Use the FFT to evaluate the polynomial at each node along the concentric circles of the grid.
# Search over each 3x3 set of values for relative minima. If the center value is less than the edge values, it is a prospective zero by the [[Maximum modulus principle|Minimum Modulus Theorem]] of complex analysis.

=== Stage two: polish the prospective zeros ===
# Apply Laguerre’s algorithm to each prospective zero, correcting it to a better approximation of the “true” zero of the polynomial
# Test the set of polished zeros for uniqueness and discard any duplicates to give a set of candidate zeros

=== Stage three: unfactor, perhaps deflate, and verify ===
# Unfactor the polished zeros i.e., reconstruct a candidate polynomial in coefficient form from the polished candidate zeros
# If the degree of the reconstructed polynomial is the same as that of the original polynomial and differences in their coefficients are small, the factoring is successful and finished
# If some zeros were missed, deflate and factor the quotient polynomial. If that does not find all of the missed zeros, deflate and factor again until all are found or until no new ones are found
# If deflation finds all the zeros that it can, and it still has not found them all, design a new grid with a finer spacing and return to stage one. If four restarts do not find them all and/or the reconstruction error is not small, declare failure.

== Description of the three stages ==
'''Stage one''' is the reason this algorithm is so efficient and is what sets it apart from most other [[Factorization|factoring]] algorithms. Because the FFT (fast Fourier transform) is used to evaluate the polynomial, a fast evaluation over a dense grid in the complex plane is possible. In order to use the FFT, the grid is structured in polar coordinates. In the first phase of this stage, a grid is designed with concentric circles of a particular radius intersected by a set of radial lines. The positions and spacing of the radial lines and the circles are chosen to give a grid that will hopefully separate the expected roots. Because the zeros of a polynomial with random coefficients have a fairly uniform angular distribution and are clustered close to the unit circle, it is possible to design an evaluation grid that fits the expected root density very well. In the second phase of this stage, the polynomial is evaluated at the nodes of the grid using the fast Fourier transform (FFT). It is because of the extraordinary efficiency and accuracy of the FFT that a direct evaluation is possible. In the third phase of this first stage, a search is conducted over all of the 3 by 3 node cells formed in the grid. For each 3 by 3 cell (see Figure below), if the value of the polynomial at the center node of the cell (the "x") is less than the values at all 8 of the nodes on the edges of the cell (the "o's"), the center is designated a candidate zero. This rule is based on the “Minimum Modulus Theorem” which states that if a relative minimum of the absolute value of an analytic function over an open region exists, the minimum must be a zero of the function. Finally, this set of prospective zeros is passed to the second stage. The number is usually slightly larger than the degree because some were found twice or mistakes were made. The number could be less if some zeros were missed. 
[[File:FFT Cell.png|thumb|Figure 1: Section of the polar coordinate grid showing a 3-node by 3-node cell]]

'''Stage two''' is more traditional than the other two. It “polishes” each of the prospective zeros found by the grid search. The first phase consists of applying an iterative algorithm to improve the accuracy of the location found by the grid search. In earlier versions of the program, Newton’s method was used but analysis and experiment showed that Laguerre's method was both more robust and more accurate. Even though it required more calculation than Newton’s method for each iteration, it converged in fewer iterations. The second phase of the second stage checks for duplications. A “fuzzy” uniqueness test is applied to each zero to eliminate any cases where on two or more prospective zeros, iterations converged to the same zero. If the number of unique, polished zeros is less than the degree of the polynomial, deflation later will be necessary. If the number is greater, some error has occurred. This stage consumes the largest part of the execution time of the total factorization, but it is crucial to the final accuracy of the roots. One of the two criteria for success in factoring a polynomial is that each root must have been successfully polished against the original polynomial.

'''Stage three''' has several phases and possible iterations or even restarting. The first phase of the third stage takes all of the unique, polished zeros that were found in the first two stages and multiplies them together into the coefficient form of a candidate polynomial (“unfactors” the zeros). If the degree of this reconstructed polynomial is the same as that of the original polynomial and if the difference in their coefficients is small, the factorization is considered successful. Often, however, several zeros were missed by the grid search and polish processes of stage one and two, or the uniqueness test discarded a legitimate zero (perhaps it is multiple), so the original polynomial is “deflated” (divided) by the reconstructed polynomial and the resulting (low degree) quotient is factored for the missing zeros. If that doesn’t find them all, the deflation process is repeated until they are all found. This allows the finding of multiple roots (or very tightly clustered roots), even if some of them were discarded earlier. If, in the unusual case, these further iterations of deflation do not find all of the missing zeros, a new, finer grid is constructed and the whole process started again at stage one.  More details on the third stage are in another module.

'''Multiple order''' and clustered roots are unusual in random coefficient polynomials. But, if they happen or if factoring an ill-conditioned polynomial is attempted, the roots will be found with the Lindsey–Fox program in most cases but with reduced accuracy. If there are multiple order zeros (Mth order with M not too high), the grid search will find them, but with multiplicity one. The polishing will converge to the multiple order root but not as fast as to a distinct root. In the case of a cluster with ''Q'' zeros that fall within a single cell, they are erroneously identified as a single zero and the polishing will converge to only one of them. In some cases, two zeros can be close to each other in adjacent cells and polish to the same point. In all of these cases, after the uniqueness test and deflation, the quotient polynomial will contain a ''M''&amp;nbsp;&amp;minus;&amp;nbsp;1 order zero and/or ''Q''&amp;nbsp;&amp;minus;&amp;nbsp;1 zeros clustered together. Each of these zeros will be found after ''M''&amp;nbsp;&amp;minus;&amp;nbsp;1 or ''Q''&amp;nbsp;&amp;minus;&amp;nbsp;1 deflations. There can be problems here because Laguerre’s polishing algorithm is not as accurate and does not converge as fast for a multiple zero and it may even diverge when applied to tightly clustered zeros. Also, the condition of the quotient polynomial will be poorer when multiple and clustered zeros are involved. If multiple order zeros are extremely far from the unit circle, the special methods for handling multiple roots developed by Zhonggang Zeng  are used. Zeng’s method is powerful but slow, and hence only used in special cases [6].  References

'''Successful completion''' of the factoring of a polynomial requires matching zeros on the complex plane measured by the convergence of Laguerre’s algorithm on each of the zeros. It also requires matching the polynomial reconstructed from the found zeros with the original polynomial by measuring the maximum difference in each coefficient.

== Characteristics of the Lindsey–Fox algorithm ==

Because the FFT is such an efficient means of evaluating the polynomial, a very fine grid can be used which will separate all or almost all of the zeros in a reasonable time. And because of the fineness of the grid, the starting point is close to the actual zero and the polishing almost always converges in a small number of steps (convergence is often a serious problem in traditional approaches). And because the searching and polishing is done on the original polynomial, they can be done on each root simultaneously on a parallel architecture computer. Because the searching is done on a 3 by 3 cell of the grid, no more that three concentric circles of the grid need be kept in memory at a time, i.e., it is not necessary to have the entire grid in memory. And, some parallelization of the FFT calculations can be done.

Deflation is often a major source of error or failure in a traditional iterative algorithm. Here, because of the good starting points and the powerful polisher, very few stages of deflation are generally needed and they produce a low order quotient polynomial that is generally well-conditioned. Moreover, to control error, the unfactoring (multiplying the found roots together) is done in the FFT domain (for degree larger than 500) and the deflation is done partly in the FFT domain and partly in the coefficient domain, depending on a combination of stability, error accumulation, and speed factors.

For random coefficient polynomials, the number of zeros missed by the grid search and polish stages ranges from 0 to 10 or occasionally more. In factoring one 2 million degree polynomial, the search and polish stages found all 2 million zeros in one grid search and required no deflation which shows the power of the grid search on this class of polynomial. When deflation is needed, one pass is almost always sufficient. However, if you have a multiple zero or two (or more) very, very closely spaced zeros, the uniqueness test will discard a legitimate zero but it will be found by later deflation. Stage three has enough tests and alternatives to handle almost all possible conditions. But, by the very definition of random coefficients, it is hard to absolutely guarantee success.

The timings of the Lindsey–Fox program and examples of root distributions of polynomials with random coefficients are [http://cnx.org/content/col10494/latest/ here].

== References ==
{{reflist}}

{{DEFAULTSORT:Lindsey-Fox algorithm}}
[[Category:Polynomials]]</text>
      <sha1>jsjtfs471oh687pjdvc57l86izlur6d</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Ernst Witt</title>
    <ns>0</ns>
    <id>39482629</id>
    <revision>
      <id>824952363</id>
      <parentid>557003928</parentid>
      <timestamp>2018-02-10T15:59:24Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>rearrange, change link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="610">These are '''things named after [[Ernst Witt]]''', a German mathematician.
* [[Bourbaki–Witt theorem]]
* [[Three subgroups lemma|Hall–Witt identity]]
* [[Hasse–Witt matrix]]
* [[Poincaré–Birkhoff–Witt theorem]], usually known as the PBW theorem
* [[Shirshov–Witt theorem]]
* [[Witt algebra]]
* [[Witt's theorem#Witt's decomposition theorem|Witt decomposition]]
* [[Witt design]] (Witt geometry)
* [[Witt group]]
* [[Witt index]]
* [[Witt polynomial]]
* [[Witt vector|Witt ring]]
* [[Witt scheme]]
* [[Witt's theorem]]
* [[Witt vector]]

[[Category:Lists of things named after mathematicians|Witt]]</text>
      <sha1>hctcgc9xhziynzbbdt4h7zvh0d7cblh</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical folklore</title>
    <ns>0</ns>
    <id>168905</id>
    <revision>
      <id>809967335</id>
      <parentid>808370424</parentid>
      <timestamp>2017-11-12T17:02:34Z</timestamp>
      <contributor>
        <username>Syp</username>
        <id>91052</id>
      </contributor>
      <minor/>
      <comment>removing non existing German interwiki</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3190">{{other uses of|folk theorem|Folk theorem (disambiguation)}}

As the term is understood by [[mathematician]]s, '''folk mathematics''' or '''mathematical folklore''' is the body of theorems, definitions, proofs, or mathematical facts or techniques that circulate among mathematicians by word of mouth but have not appeared in print, either in books or in scholarly journals. Knowledge of folklore is the coin of the realm of academic mathematics.{{OR|date=July 2016}}

Quite important at times for researchers are '''folk theorems''', which are results known, at least to experts in a field, and considered to have established status, but not published in complete form. Sometimes these are only alluded to in the public literature. 
An example is a book of exercises, described on the back cover:
{{quote|This book contains almost 350 exercises in the basics of [[ring theory]]. The problems form the "folklore" of ring theory, and the solutions are given in as much detail as possible.&lt;ref&gt;Grigore Calugareau &amp; Peter Hamburg (1998) ''Exercises in Basic Ring Theory'', Kluwer,[{{isbn|0792349180}}]&lt;/ref&gt;}}

Another distinct category is '''wellknowable''' mathematics, a term introduced by [[John Horton Conway|John Conway]]. This consists of matters that are known and factual, but not in active circulation in relation with current research. Both of these concepts are attempts to describe the actual context in which research work is done.

Some people, principally non-mathematicians, use the term ''folk mathematics'' to refer to the [[informal mathematics]] studied in many ethno-cultural studies of mathematics.

==Stories, sayings and jokes==
{{See also|Mathematical joke}}
{{Wikiquote|Mathematics}}
{{Wikiquote|Mathematicians}}
Mathematical folklore may also refer to unusual (and possibly apocryphal) stories or jokes involving mathematicians or mathematics that are told verbally in mathematics departments. Compilations include tales collected in [[G. H. Hardy]]'s ''[[A Mathematician's Apology]]'' and {{Harv|Krantz|2002}}; examples include:
*[[Galileo]] dropping weights from the [[Leaning Tower of Pisa]].
*An apple falling on [[Isaac Newton]]'s head to inspire his theory of gravitation.
*The drinking, duel and early death of [[Galois]].
*[[Richard Feynman]] cracking safes in the Manhattan Project.
*[[Alfréd Rényi]]'s definition of a mathematician: "a device for turning coffee into theorems".
*The "[[turtles all the way down]]" story told by [[Stephen Hawking]].
*[[Fermat]]'s [[Fermat's Last Theorem#Fermat's conjecture|lost simple proof]].
*The unwieldy proof and associated controversies of the [[Four Color Theorem]].

== See also ==
{{Portal|Mathematics}}

==Notes==
{{Reflist}}

==References==
{{Refbegin}}
* {{ Citation | title = Mathematical Apocrypha: Stories &amp; Anecdotes of Mathematicians &amp; the Mathematical | first = Steven G. | last = Krantz | authorlink=Steven G. Krantz | year = 2002 }}
* David Harel, "On Folk Theorems", ''[[Communications of the ACM]]'' '''23''':7:379-389 (July 1980)
{{Refend}}

[[Category:Philosophy of mathematics]]
[[Category:Mathematics and culture]]
[[Category:Scientific folklore]]
[[Category:Sociology of scientific knowledge]]</text>
      <sha1>h95t8xwzximz8i3rli9pmhot9lxvq6s</sha1>
    </revision>
  </page>
  <page>
    <title>Maze generation algorithm</title>
    <ns>0</ns>
    <id>200877</id>
    <revision>
      <id>870617703</id>
      <parentid>870608813</parentid>
      <timestamp>2018-11-26T00:05:41Z</timestamp>
      <contributor>
        <username>Anders Kaseorg</username>
        <id>122703</id>
      </contributor>
      <comment>Citation for Wilson's algorithm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21889">{{refimprove|date=March 2018}}
'''Maze generation [[algorithm]]s''' are automated methods for the creation of [[maze]]s.

[[Image:Prim Maze.svg|right|frame|This maze generated by modified version of [[Prim's algorithm]], below.]]

== Graph theory based methods ==

[[File:Graph based maze animation.gif|thumb|Animation of Graph theory based method]]

A maze can be generated by starting with a predetermined arrangement of cells (most commonly a rectangular grid but other arrangements are possible) with wall sites between them. This predetermined arrangement can be considered as a [[connected graph]] with the edges representing possible wall sites and the nodes representing cells. The purpose of the maze generation algorithm can then be considered to be making a subgraph in which it is challenging to find a route between two particular nodes.

If the subgraph is not [[connected graph|connected]], then there are regions of the graph that are wasted because they do not contribute to the search space.  If the graph contains loops, then there may be multiple paths between the chosen nodes.  Because of this, maze generation is often approached as generating a random [[spanning tree (mathematics)|spanning tree]].  Loops, which can confound naive maze solvers, may be introduced by adding random edges to the result during the course of the algorithm.

The animation shows the maze generation steps for a 
graph that is not on a rectangular grid.
First, the computer creates a random [[planar graph]] G
shown in blue, and its [[Dual graph|dual]] F
shown in yellow. Second, computer traverses F using a chosen
algorithm, such as a depth-first search, coloring the path red.
During the traversal, whenever a red edge crosses over a blue edge,
the blue edge is removed.
Finally, when all vertices of F have been visited, F is erased
and two edges from G, one for the entrance and one for the exit, are removed.

=== Depth-first search ===
[[File:Depth-First Search Animation.ogv|thumb|right|Animation of generator's thinking process using Depth-First Search]]

This algorithm is a randomized version of the [[depth-first search]] algorithm. Frequently implemented with a stack, this approach is one of the simplest ways to generate a maze using a computer. Consider the space for a maze being a large grid of cells (like a large chess board), each cell starting with four walls. Starting from a random cell, the computer then selects a random neighbouring cell that has not yet been visited. The computer removes the wall between the two cells and marks the new cell as visited, and adds it to the stack to facilitate backtracking. The computer continues this process, with a cell that has no unvisited neighbours being considered a dead-end. When at a dead-end it backtracks through the path until it reaches a cell with an unvisited neighbour, continuing the path generation by visiting this new, unvisited cell (creating a new junction). This process continues until every cell has been visited, causing the computer to backtrack all the way back to the beginning cell. We can be sure every cell is visited.

As given above this algorithm involves deep recursion which may cause stack overflow issues on some computer architectures. The algorithm can be rearranged into a loop by storing backtracking information in the maze itself. This also provides a quick way to display a solution, by starting at any given point and backtracking to the beginning.

[[File:Horizontally Influenced Depth-First Search Generated Maze.png|thumb|right|Horizontal Passage Bias]]

Mazes generated with a depth-first search have a low branching factor and contain many long corridors, because the algorithm explores as far as possible along each branch before backtracking.

=== Recursive backtracker ===
[[File:Hexamaze.webm|thumb|Recursive backtracker on a hexagonal grid]]
The depth-first search algorithm of maze generation is frequently implemented using [[backtracking]]:

# Make the initial cell the current cell and mark it as visited
# While there are unvisited cells
##  If the current cell has any neighbours which have not been visited
###  Choose randomly one of the unvisited neighbours
###  Push the current cell to the stack
###  Remove the wall between the current cell and the chosen cell
###  Make the chosen cell the current cell and mark it as visited
## Else if stack is not empty
###  Pop a cell from the stack
###  Make it the current cell

=== Randomized Kruskal's algorithm ===
[[File:KruskalGeneratedMaze.webm|thumb|An animation of generating a 30 by 20 maze using Kruskal's algorithm.]]
This algorithm is a randomized version of [[Kruskal's algorithm]].

# Create a list of all walls, and create a set for each cell, each containing just that one cell.
# For each wall, in some random order:
## If the cells divided by this wall belong to distinct sets:
### Remove the current wall.
### Join the sets of the formerly divided cells.

There are several data structures that can be used to model the sets of cells.  An efficient implementation using a [[disjoint-set data structure]] can perform each union and find operation on two sets in nearly constant [[amortized time]] (specifically, &lt;math&gt;O(\alpha(V))&lt;/math&gt; time; &lt;math&gt;\alpha(x) &lt; 5&lt;/math&gt; for any plausible value of &lt;math&gt;x&lt;/math&gt;), so the running time of this algorithm is essentially proportional to the number of walls available to the maze.

It matters little whether the list of walls is initially randomized or if a wall is randomly chosen from a nonrandom list, either way is just as easy to code.

Because the effect of this algorithm is to produce a minimal spanning tree from a graph with equally weighted edges, it tends to produce regular patterns which are fairly easy to solve.

=== Randomized Prim's algorithm ===
[[File:MAZE 30x20 Prim.ogv|thumb|upright=1.6|An animation of generating a 30 by 20 maze using Prim's algorithm.]]
This algorithm is a randomized version of [[Prim's algorithm]].

# Start with a grid full of walls.
# Pick a cell, mark it as part of the maze. Add the walls of the cell to the wall list.
# While there are walls in the list:
## Pick a random wall from the list. If only one of the two cells that the wall divides is visited, then:
### Make the wall a passage and mark the unvisited cell as part of the maze.
### Add the neighboring walls of the cell to the wall list.
## Remove the wall from the list.

It will usually be relatively easy to find the way to the starting cell, but hard to find the way anywhere else.

Note that simply running classical Prim's on a graph with random edge weights would create mazes stylistically identical to Kruskal's, because they are both minimal spanning tree algorithms.  Instead, this algorithm introduces stylistic variation because the edges closer to the starting point have a lower effective weight.

==== Modified version ====
Although the classical Prim's algorithm keeps a list of edges, for maze generation we could instead maintain a list of adjacent cells.  If the randomly chosen cell has multiple edges that connect it to the existing maze, select one of these edges at random.  This will tend to branch slightly more than the edge-based version above.

=== Wilson's algorithm ===
{{Main|Loop-erased random walk}}

All the above algorithms have biases of various sorts: depth-first search is biased toward long corridors, while Kruskal's/Prim's algorithms are biased toward many short dead ends. Wilson's algorithm,&lt;ref&gt;{{cite conference
| url = http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.8598&amp;rep=rep1&amp;type=pdf
| format = PDF
| title = Generating random spanning trees more quickly than the cover time
| first = David Bruce
| last = Wilson
| date = May 22–24, 1996
| conference = Symposium on Theory of Computing
| book-title = Proceedings of the Twenty-eighth Annual ACM Symposium on Theory of Computing
| publisher = ACM
| location = Philadelphia
| pages = 296–303
| isbn = 0-89791-785-5
| doi = 10.1145/237814.237880
}}&lt;/ref&gt; on the other hand, generates an ''unbiased'' sample from the [[discrete uniform distribution|uniform distribution]] over all mazes, using [[loop-erased random walk]]s.

We begin the algorithm by initializing the maze with one cell chosen arbitrarily. Then we start at a new cell chosen arbitrarily, and perform a random walk until we reach a cell already in the maze—however, if at any point the random walk reaches its own path, forming a loop, we erase the loop from the path before proceeding. When the path reaches the maze, we add it to the maze. Then we perform another loop-erased random walk from another arbitrary starting cell, repeating until all cells have been filled.

This procedure remains unbiased no matter which method we use to arbitrarily choose starting cells. So we could always choose the first unfilled cell in (say) left-to-right, top-to-bottom order for simplicity.

==Recursive division method==
{| class="wikitable" align="right"
|+ '''Illustration of Recursive Division'''
|-
! width="110px" | ''original chamber''
! width="110px" | ''division by two walls''
! width="110px" | ''holes in walls''
! width="110px" | ''continue subdividing...''
! width="110px" | ''completed''
|-
| align="center" | [[File:Chamber.svg|thumb|step 1|101px]]
| align="center" | [[File:Chamber-division.svg|thumb|step 2|101px]]
| align="center" | [[File:Chamber-divided.svg|thumb|step 3|101px]]
| align="center" | [[File:Chamber-subdivision.svg|thumb|step 4|101px]]
| align="center" | [[File:Chamber-finished.svg|thumb|step 5|101px]]
|}

Mazes can be created with ''recursive division'', an algorithm which works as follows: Begin with the maze's space with no walls. Call this a chamber. Divide the chamber with a randomly positioned wall (or multiple walls) where each wall contains a randomly positioned passage opening within it. Then recursively repeat the process on the subchambers until all chambers are minimum sized. This method results in mazes with long straight walls crossing their space, making it easier to see which areas to avoid.

[[File:Recursive maze.gif|thumb|right|Recursive Maze generation]]

For example, in a rectangular maze, build at random points two walls that are perpendicular to each other. These two walls divide the large chamber into four smaller chambers separated by four walls. Choose three of the four walls at random, and open a one cell-wide hole at a random point in each of the three. Continue in this manner recursively, until every chamber has a width of one cell in either of the two directions.

{{clear}}

== Simple algorithms ==
[[File:Prim Maze 3D.svg|right|thumb|300px|3D version of Prim's algorithm. Vertical layers are labeled 1 through 4 from bottom to top. Stairs up are indicated with "/"; stairs down with "\", and stairs up-and-down with "x". Source code is included with the image description.]]
Other algorithms exist that require only enough memory to store one line of a 2D maze or one plane of a 3D maze. They prevent loops by storing which cells in the current line are connected through cells in the previous lines, and never remove walls between any two cells already connected.

Most maze generation algorithms require maintaining relationships between cells within it, to ensure the end result will be solvable. Valid simply connected mazes can however be generated by focusing on each cell independently. A binary tree maze is a standard orthogonal maze where each cell always has a passage leading up or leading left, but never both. To create a binary tree maze, for each cell flip a coin to decide whether to add a passage leading up or left. Always pick the same direction for cells on the boundary, and the end result will be a valid simply connected maze that looks like a [[binary tree]], with the upper left corner its root.

A related form of flipping a coin for each cell is to create an image using a random mix of forward slash and backslash characters. This doesn't generate a valid simply connected maze, but rather a selection of closed loops and unicursal passages.  (The manual for the [[Commodore 64]] presents a BASIC program using this algorithm, but using [[PETSCII]] diagonal line graphic characters instead for a smoother graphic appearance.)

== Cellular automaton algorithms ==
Certain types of [[cellular automata]] can be used to generate mazes.&lt;ref name=ca&gt;{{cite web|url=http://www.conwaylife.com/wiki/index.php?title=Maze|title=Maze - LifeWiki |author=[http://www.conwaylife.com/wiki/index.php?title=User:Nathaniel Nathaniel Johnston]|date=21 August 2010 |publisher=LifeWiki |accessdate=1 March 2011|display-authors=etal}}&lt;/ref&gt; Two well-known such cellular automata, Maze and Mazectric, have rulestrings B3/S12345 and B3/S1234.&lt;ref name=ca /&gt; In the former, this means that cells survive from one generation to the next if they have at least one and at most five [[Moore neighbourhood|neighbours]]. In the latter, this means that cells survive if they have one to four neighbours. If a cell has exactly three neighbours, it is born. It is similar to [[Conway's Game of Life]] in that patterns that do not have a living cell adjacent to 1, 4, or 5 other living cells in any generation will behave identically to it.&lt;ref name=ca /&gt; However, for large patterns, it behaves very differently from Life.&lt;ref name=ca /&gt;

For a random starting pattern, these maze-generating cellular automata will evolve into complex mazes with well-defined walls outlining corridors. Mazecetric, which has the rule B3/S1234 has a tendency to generate longer and straighter corridors compared with Maze, with the rule B3/S12345.&lt;ref name=ca /&gt; Since these cellular automaton rules are [[deterministic]], each maze generated is uniquely determined by its random starting pattern. This is a significant drawback since the mazes tend to be relatively predictable.

Like some of the graph-theory based methods described above, these cellular automata typically generate mazes from a single starting pattern; hence it will usually be relatively easy to find the way to the starting cell, but harder to find the way anywhere else.

==Python code example==
Example implementation of a variant of Prim's algorithm in [[Python (programming language)|Python]]/[[NumPy]]. Prim's algorithm above starts with a grid full of walls and grows a single component of pathable tiles. In this example, we start with an open grid and grow multiple components of walls.

This algorithm works by creating n (density) islands of length p (complexity). An island is created by choosing a random starting point with odd coordinates, then a random direction is chosen. If the cell two steps in the direction is free, then a wall is added at both one step and two steps in this direction. The process is iterated for n steps for this island. p islands are created. n and p are expressed as float to adapt them to the size of the maze. With a low complexity, islands are very small and the maze is easy to solve. With low density, the maze has more "big empty rooms".

&lt;source lang="numpy"&gt;
import numpy
from numpy.random import random_integers as rand
import matplotlib.pyplot as pyplot

def maze(width=81, height=51, complexity=.75, density=.75):
    # Only odd shapes
    shape = ((height // 2) * 2 + 1, (width // 2) * 2 + 1)
    # Adjust complexity and density relative to maze size
    complexity = int(complexity * (5 * (shape[0] + shape[1]))) # number of components
    density    = int(density * ((shape[0] // 2) * (shape[1] // 2))) # size of components
    # Build actual maze
    Z = numpy.zeros(shape, dtype=bool)
    # Fill borders
    Z[0, :] = Z[-1, :] = 1
    Z[:, 0] = Z[:, -1] = 1
    # Make aisles
    for i in range(density):
        x, y = rand(0, shape[1] // 2) * 2, rand(0, shape[0] // 2) * 2 # pick a random position
        Z[y, x] = 1
        for j in range(complexity):
            neighbours = []
            if x &gt; 1:             neighbours.append((y, x - 2))
            if x &lt; shape[1] - 2:  neighbours.append((y, x + 2))
            if y &gt; 1:             neighbours.append((y - 2, x))
            if y &lt; shape[0] - 2:  neighbours.append((y + 2, x))
            if len(neighbours):
                y_,x_ = neighbours[rand(0, len(neighbours) - 1)]
                if Z[y_, x_] == 0:
                    Z[y_, x_] = 1
                    Z[y_ + (y - y_) // 2, x_ + (x - x_) // 2] = 1
                    x, y = x_, y_
    return Z

pyplot.figure(figsize=(10, 5))
pyplot.imshow(maze(80, 40), cmap=pyplot.cm.binary, interpolation='nearest')
pyplot.xticks([]), pyplot.yticks([])
pyplot.show()
&lt;/source&gt;

==C code example==
The code below is an example of depth-first search maze generator in C. 
&lt;source lang="c"&gt;
//Code by Jacek Wieczorek

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
#include &lt;string.h&gt;

typedef struct
{
	int x, y; //Node position - little waste of memory, but it allows faster generation
	void *parent; //Pointer to parent node
	char c; //Character to be displayed
	char dirs; //Directions that still haven't been explored
} Node;

Node *nodes; //Nodes array
int width, height; //Maze dimensions


int init( )
{
	int i, j;
	Node *n;
	
	//Allocate memory for maze
	nodes = calloc( width * height, sizeof( Node ) );
	if ( nodes == NULL ) return 1;
		
	//Setup crucial nodes
	for ( i = 0; i &lt; width; i++ )
	{
		for ( j = 0; j &lt; height; j++ )
		{
			n = nodes + i + j * width;
			if ( i * j % 2 ) 
			{
				n-&gt;x = i;
				n-&gt;y = j;
				n-&gt;dirs = 15; //Assume that all directions can be explored (4 youngest bits set)
				n-&gt;c = ' '; 
			}
			else n-&gt;c = '#'; //Add walls between nodes
		}
	}
	return 0;
}

Node *link( Node *n )
{
	//Connects node to random neighbor (if possible) and returns
	//address of next node that should be visited

	int x, y;
	char dir;
	Node *dest;
	
	//Nothing can be done if null pointer is given - return
	if ( n == NULL ) return NULL;
	
	//While there are directions still unexplored
	while ( n-&gt;dirs )
	{
		//Randomly pick one direction
		dir = ( 1 &lt;&lt; ( rand( ) % 4 ) );
		
		//If it has already been explored - try again
		if ( ~n-&gt;dirs &amp; dir ) continue;
		
		//Mark direction as explored
		n-&gt;dirs &amp;= ~dir;
		
		//Depending on chosen direction
		switch ( dir )
		{
			//Check if it's possible to go right
			case 1:
				if ( n-&gt;x + 2 &lt; width )
				{
					x = n-&gt;x + 2;
					y = n-&gt;y;
				}
				else continue;
				break;
			
			//Check if it's possible to go down
			case 2:
				if ( n-&gt;y + 2 &lt; height )
				{
					x = n-&gt;x;
					y = n-&gt;y + 2;
				}
				else continue;
				break;
			
			//Check if it's possible to go left	
			case 4:
				if ( n-&gt;x - 2 &gt;= 0 )
				{
					x = n-&gt;x - 2;
					y = n-&gt;y;
				}
				else continue;
				break;
			
			//Check if it's possible to go up
			case 8:
				if ( n-&gt;y - 2 &gt;= 0 )
				{
					x = n-&gt;x;
					y = n-&gt;y - 2;
				}
				else continue;
				break;
		}
		
		//Get destination node into pointer (makes things a tiny bit faster)
		dest = nodes + x + y * width;
		
		//Make sure that destination node is not a wall
		if ( dest-&gt;c == ' ' )
		{
			//If destination is a linked node already - abort
			if ( dest-&gt;parent != NULL ) continue;
			
			//Otherwise, adopt node
			dest-&gt;parent = n;
			
			//Remove wall between nodes
			nodes[n-&gt;x + ( x - n-&gt;x ) / 2 + ( n-&gt;y + ( y - n-&gt;y ) / 2 ) * width].c = ' ';
			
			//Return address of the child node
			return dest;
		}
	}
	
	//If nothing more can be done here - return parent's address
	return n-&gt;parent;
}

void draw( )
{
	int i, j;

	//Outputs maze to terminal - nothing special
	for ( i = 0; i &lt; height; i++ )
	{
		for ( j = 0; j &lt; width; j++ )
		{
			printf( "%c", nodes[j + i * width].c );
		}
		printf( "\n" );
	}
}

int main( int argc, char **argv )
{
	Node *start, *last;

	//Check argument count
	if ( argc &lt; 3 )
	{
		fprintf( stderr, "%s: please specify maze dimensions!\n", argv[0] );
		exit( 1 );
	}
	
	//Read maze dimensions from command line arguments
	if ( sscanf( argv[1], "%d", &amp;width ) + sscanf( argv[2], "%d", &amp;height ) &lt; 2 )
	{
		fprintf( stderr, "%s: invalid maze size value!\n", argv[0] );
		exit( 1 );
	}

	//Allow only odd dimensions
	if ( !( width % 2 ) || !( height % 2 ) )
	{
		fprintf( stderr, "%s: dimensions must be odd!\n", argv[0] );
		exit( 1 );
	}
	
	//Do not allow negative dimensions
	if ( width &lt;= 0 || height &lt;= 0 )
	{
		fprintf( stderr, "%s: dimensions must be greater than 0!\n", argv[0] );
		exit( 1 );
	}

	//Seed random generator
	srand( time( NULL ) );
	
	//Initialize maze
	if ( init( ) )
	{
		fprintf( stderr, "%s: out of memory!\n", argv[0] );
		exit( 1 );
	}
	
	//Setup start node
	start = nodes + 1 + width;
	start-&gt;parent = start;
	last = start;
	
	//Connect nodes until start node is reached and can't be left
	while ( ( last = link( last ) ) != start );
	draw( );
}
&lt;/source&gt;

==See also==
* [[Maze solving algorithm]]
* [[Self-avoiding walk]]

==References==
{{reflist}}

==External links==
* [http://www.astrolog.org/labyrnth/algrithm.htm#perfect Think Labyrinth: Maze algorithms] (details on these and other maze generation algorithms)
* [http://www.jamisbuck.org/presentations/rubyconf2011/index.html Jamis Buck: HTML 5 Presentation with Demos of Maze generation Algorithms]
* [https://franciscouzo.github.io/maze/ Maze generation visualization]
* [http://jonathanzong.com/blog/2012/11/06/maze-generation-with-prims-algorithm Java implementation of Prim's algorithm]
* [http://rosettacode.org/wiki/Maze Implementations of DFS maze creation algorithm] in multiple languages at Rosetta Code
* [https://github.com/armin-reichert/mazes Armin Reichert: 34 maze algorithms in Java 8, with demo application]
* [http://www.cadforum.cz/cadforum_en/maze-generator-for-autocad-tip11914 CADforum: Maze generation algorithm in VisualLISP]

[[Category:Mazes]]
[[Category:Algorithms]]
[[Category:Random graphs]]
[[Category:Articles with example Python code]]
[[Category:Articles containing video clips]]</text>
      <sha1>3hqea6v0qe3utlf37mrm1hybbpm8rel</sha1>
    </revision>
  </page>
  <page>
    <title>Measure algebra</title>
    <ns>0</ns>
    <id>25626903</id>
    <revision>
      <id>761714739</id>
      <parentid>549616591</parentid>
      <timestamp>2017-01-24T11:48:59Z</timestamp>
      <contributor>
        <username>Dasistmiregal</username>
        <id>7474842</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1079">In mathematics, a '''measure algebra''' is a [[Boolean algebra (structure)|Boolean algebra]] with a countably additive positive measure. A [[probability measure]] on a [[measure space]] gives a measure algebra on the Boolean algebra of measurable sets modulo [[null set]]s.

==Definition==
A measure algebra is a Boolean algebra ''B'' with a measure ''m'', which is a real-valued function on ''B'' such that:
*''m''(0)=0, ''m''(1)=1
*''m''(''x'') &gt;0 if ''x''≠0
*''m'' is countably additive: ''m''(Σ''x''&lt;sub&gt;''i''&lt;/sub&gt;) = Σ''m''(''x''&lt;sub&gt;''i''&lt;/sub&gt;) if the ''x''&lt;sub&gt;''i''&lt;/sub&gt; are a countable set of elements that are disjoint (''x''&lt;sub&gt;''i''&lt;/sub&gt; ∧ ''x''&lt;sub&gt;''j''&lt;/sub&gt;=0 whenever ''i''≠''j'').

==References==
*{{Citation | last1=Jech | first1=Thomas | author1-link=Thomas Jech | title=Set Theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=third millennium | series=Springer Monographs in Mathematics | isbn=978-3-540-44085-7 | doi=10.1007/3-540-44761-X_22 | year=2003| chapter=Saturated ideals|page=415}}

[[Category:Measure theory]]</text>
      <sha1>hx1ralhkrkg7en2hmp3p06kiyhhz7s3</sha1>
    </revision>
  </page>
  <page>
    <title>Michael G. Crandall</title>
    <ns>0</ns>
    <id>35265777</id>
    <revision>
      <id>869412930</id>
      <parentid>843082999</parentid>
      <timestamp>2018-11-18T12:52:29Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4669">{{Use mdy dates|date=August 2014}}
{{Infobox person
| name        = Michael G. Crandall
| image       = Michael Crandall.jpg
| alt         = 
| caption     =
| birth_name  = 
| birth_date  = {{birth-date and age|November 29, 1940}}
| birth_place = [[Baton Rouge, Louisiana]], U.S.
| death_date  = &lt;!-- {{Death date and age|YYYY|MM|DD|YYYY|MM|DD}} or {{Death-date and age|Month DD, YYYY|Month DD, YYYY}} (death date then birth date) --&gt;
| death_place =
| nationality = American
| occupation  = Mathematics Professor (Emeritus) 
| known_for   =
|module=    {{infobox scientist
     |embed=yes
     |alma_mater=[[UC Berkeley]]
     |workplaces=[[University of California, Santa Barbara]]
     |doctoral_students=[[Lawrence Evans]]
     |awards=[[Leroy P. Steele Prize]] (1999)
     }}
}}

'''Michael Grain Crandall''' (born November 29, 1940, in [[Baton Rouge, Louisiana]]) is an American mathematician, specializing in differential equations.

== Mathematical career ==
In 1962 Crandall earned a baccalaureate in engineering physics from [[University of California, Berkeley]], changed to mathematics, earning a master's in 1964 and a PhD in 1965 under Heinz Cordes at Berkeley, with a thesis that solved a problem in celestial mechanics posed by  [[Carl Ludwig Siegel]]; the thesis title is ''Two families of plane solutions of the four body problem''. In 1965 he was an instructor at Berkeley, in 1966 an assistant professor at [[Stanford University]] and from 1969 at the [[University of California, Los Angeles]] (UCLA), where he was a professor from 1973 to 1976. From 1974 to 1984 he was a professor at the Mathematics Research Center at the [[University of Wisconsin–Madison]], from 1984 to 1990 as Hille-Professor of Mathematics. From 1988 until his retirement he was a professor at the [[University of California, Santa Barbara]]. Crandall was several times a visiting professor at the [[University of Paris]], where he received an honorary doctorate in 1999. His legacy of contributions contains all but not limited to: Banach solutions in Euclidean spaces, Fourier transforms of planar variables, PDE concepts and iterations for sequence analysis, semigroup transform solutions, differential harmonic study of divergent hyperbole, physical transformations of finite Jacobian entities, unique harmonic populations in convergent contexts, application of abstract existence principles on non-linear contexts, normalized vector sequencing in multi-dimensional parallax geometries, and the mathematical equivalence study of topographical dissimilar nodes using traditional non-linear surfacing theories to produce distinct solutions in the realm of differential multi-variable applications.

Crandall works primarily on partial differential equations, e.g., with [[bifurcation theory]], evolution equations, generation of semigroups of transformations on [[Banach space]]s&lt;ref&gt;Crandall, Thomas Liggett: ''Generation of semigroups of nonlinear transformations on general Banach spaces.'' In: ''American Journal of Mathematics.'' vol. 93, 1971, pp. 265-298. This paper is cited in the award presentation of the Steele Prize.&lt;/ref&gt; and the theory of [[Hamilton–Jacobi equation]]s. With [[Pierre-Louis Lions]] he did research on the viscosity solutions of partial differential equations.&lt;ref&gt;Crandall, Lions: ''Viscosity of solutions of Hamilton-Jacobi equations.'' In: ''Transactions AMS.'' vol. 277, 1983, pp. 1-42. This paper is part of the research that won the Steele Prize.&lt;/ref&gt;

In 2000 he was elected a member of the [[American Academy of Arts and Sciences]]. In 1999 he received the [[Leroy P. Steele Prize]]. In 1974 he was an Invited Lecturer (on "Semigroups of nonlinear equations and evolution equations") at the [[International Congress of Mathematicians]] in Vancouver. In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved November 10, 2012.&lt;/ref&gt;

Among his doctoral students is [[Lawrence C. Evans]].&lt;ref&gt;{{mathgenealogy|id=9655}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* [http://www.math.ucsb.edu/~crandall/ home page Crandall - UCSB Math. Dept.]
* [http://www.ams.org/notices/199904/comm-steele-prz.pdf Steele Prize to Crandall, pdf-file, Notices AMS] (76&amp;nbsp;kB)

{{Authority control}}

{{DEFAULTSORT:Crandall, Michael G.}}
[[Category:1940 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Mathematical analysts]]
[[Category:PDE theorists]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>lbsgx9rn87f38qocmddrcf0dfrvr88a</sha1>
    </revision>
  </page>
  <page>
    <title>Nassif Ghoussoub</title>
    <ns>0</ns>
    <id>18739787</id>
    <revision>
      <id>866166503</id>
      <parentid>863211288</parentid>
      <timestamp>2018-10-28T18:26:01Z</timestamp>
      <contributor>
        <username>Nooorooo</username>
        <id>34699307</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9184">{{BLP sources|date=January 2013}}
{{Infobox scientist
| name              = Nassif Ghoussoub
| image             = Nassif Ghoussoub.jpg
| image_size        = 
| caption           = 
| birth_date        = {{b-da|9 November 1953}}
| birth_place       = [[Segou]]
| death_date        = 
| death_place       = 
| nationality       = [[Canada|Canadian]]
| fields            = [[Mathematics]]
| workplaces        = [[University of British Columbia]]
| alma_mater        = [[Paris VI University]]
| doctoral_advisor  = [[Gustave Choquet]]&lt;br&gt;[[Antoine Brunel]]
| doctoral_students = 
| known_for         = 
| awards            = 
}}
'''Nassif  A. Ghoussoub''', {{Post-nominals|country=CAN|OC|FRSC}}, is a [[Canada|Canadian]] [[mathematician]] working in the fields of non-linear [[analysis (mathematics)|analysis]] and [[partial differential equations]]. He is a Professor of Mathematics and a Distinguished University Scholar at the [[University of British Columbia]].&lt;ref name=":1"&gt;{{Cite news|url=https://www.timescolonist.com/news/b-c/film-director-egoyan-photographer-grant-receive-order-of-canada-honours-1.2142555|title=Film director Egoyan, photographer Grant receive Order of Canada honours|work=Times Colonist|access-date=2018-09-23}}&lt;/ref&gt;

== Early life and education ==
Ghoussoub was born to Lebanese parents in Western Africa (now [[Mali]]).&lt;ref name=":1" /&gt;&lt;ref name=":2"&gt;{{Cite web|url=http://ulcm.org/wlcu-lebanese-heritage/news/interviews/2016/03/26/order-of-canada-honours-for-nassif-ghoussoub-a-lebanese-canadian-from-vancouver|title=Order of Canada honours for Nassif Ghoussoub, a Lebanese Canadian from vancouver|website=ulcm.org|access-date=2018-09-28}}&lt;/ref&gt; 

He completed his doctorat 3ème cycle (PhD) in 1975, and a Doctorat d'Etat in 1979 at the [[Pierre and Marie Curie University]], where his advisors were [[Gustave Choquet]] and Antoine Brunel. 

== Career ==
Ghoussoub completed his post-doctoral fellowship at the [[Ohio State University]] during 1976-77. He then joined the University of British Columbia, where he currently holds a position of Professor of Mathematics and a Distinguished University Scholar.&lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;&lt;ref&gt;{{Cite news|url=https://www.macleans.ca/education/university/the-acrimony-and-enigma-of-arvind-guptas-exit-from-ubc/|title=The acrimony and enigma of Arvind Gupta's exit from UBC|date=2015-08-18|work=Macleans.ca|access-date=2018-09-28|language=en-US}}&lt;/ref&gt;&lt;ref name=":3"&gt;{{Cite news|url=https://studylib.net/doc/11098010/mathematics-newsletter-message-from-the-head--mike-bennett|title=Interview with UBC Math Professor Nassif Ghoussoub|last=|first=|date=|work=studylib.net|access-date=2018-09-28|language=en}}&lt;/ref&gt; Ghoussoub is known for his work in functional analysis, non-linear analysis and partial differential equations.&lt;ref name=":3" /&gt;

He was vice-president of the [[Canadian Mathematical Society]] from 1994 to 1996, the founding director of the [[Pacific Institute for the Mathematical Sciences]] (PIMS) for the period 1996&amp;ndash;2003, the co-editor-in-chief of the Canadian Journal of Mathematics during 1993-2002, a co-founder of the MITACS Network of Centres of Excellence, and is the founder and current scientific director of the [[Banff International Research Station]] (BIRS).&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt; In 1994, Ghoussoub became a fellow of the Royal Society of Canada, and in 2012, a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-01-19.&lt;/ref&gt; 

Ghoussoub has been awarded multiple awards and distinctions, including the Coxeter-James prize in 1990, and the Jeffrey-Williams prize in 2007. He holds honorary doctorates from the Université Paris-Dauphine (France), and the University of Victoria (Canada). He was awarded the Queen Elizabeth II Diamond Jubilee Medal in 2012, and appointed to the [[Order of Canada]] in 2015, with the grade of officer for contributions to mathematics, research and education.&lt;ref name=":2" /&gt;&lt;ref&gt;{{cite web|url=http://www.gg.ca/document.aspx?id=16283&amp;lan=eng|title=Order of Canada Appointments|website=The Governor General of Canada His Excellency the Right Honourable David Johnston|publisher=[[Governor General of Canada]]|accessdate=31 December 2015}}&lt;/ref&gt; 

In 2018, Ghoussoub was elected a faculty representative on the University of British Columbia's Board of Governors.&lt;ref name=":0"&gt;{{Cite news|url=https://www.ubyssey.ca/news/nassif-ghoussoub-wins-bog-faculty-seat/|title=Faculty elects math professor to UBC Board of Governors|last=Vescera&lt;/a&gt;|first=Written by &lt;a href="/authors/alex-nguyen/"&gt;Alex Nguyen&lt;/a&gt; and &lt;a href="/authors/zak-vescera/"&gt;Zak|work=The Ubyssey|access-date=2018-09-23}}&lt;/ref&gt; He will serve until February 29, 2020.&lt;ref name=":0" /&gt; Ghoussoub has previously served two consecutive terms in this role from 2008 to 2014.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite news|url=https://www.ubyssey.ca/news/bog-faculty-rep-candidates-profile/|title=Two newcomers and two familiar faces run for Board of Governors faculty seat|last=Vescera&lt;/a&gt;|first=Written by &lt;a href="/authors/alex-nguyen/"&gt;Alex Nguyen&lt;/a&gt; and &lt;a href="/authors/zak-vescera/"&gt;Zak|work=The Ubyssey|access-date=2018-09-23}}&lt;/ref&gt;&lt;ref name=":3" /&gt;

Ghoussoub's scholarly work has been cited over 5,000 times, and has an h-index of 37.&lt;ref&gt;{{Cite web|url=https://scholar.google.com/citations?user=g_-M8x0AAAAJ&amp;hl=en|title=N. Ghoussoub - Google Scholar Citations|website=scholar.google.com|access-date=2018-09-23}}&lt;/ref&gt;

== Awards ==
* [[Coxeter-James Prize]], [[Canadian Mathematical Society]] (1990)
* [[The Killam Trusts|Killam Senior Research Fellowship]], [[University of British Columbia|UBC]] (1992)
* Fellow of the [[Royal Society of Canada]] (1994)
* Distinguished University Scholar, [[University of British Columbia|UBC]] (2003)
* Doctorat [[Honoris Causa]], [[Paris Dauphine University]]&lt;ref&gt;[https://mail.cms.math.ca/pipermail/cmath/2004/000044.html Announcement]&lt;/ref&gt;  
* [[Jeffery&amp;ndash;Williams Prize]], Canadian mathematical Society (2007) &lt;ref&gt;[http://www.cms.math.ca/Prizes/recip?id=JW]&lt;/ref&gt;
* Faculty of Science Achievement Award for outstanding service and leadership, [[University of British Columbia|UBC]] (2007)
* David Borwein Distinguished Career Award, Canadian Mathematical Society (2010)
* Fellow of the American Mathematical Society (2012)
* Queen Elizabeth II Diamond Jubilee Medal (2012)
* Honorary Doctor of Science-University of Victoria (June 2015)
* Officer of the Order of Canada (December 2015)

== Bibliography ==

=== Selected Academic Publications ===

* N Ghoussoub and D Preiss. A general mountain pass principle for locating and classifying critical points. Ann. Inst. H. Poincaré Anal. Non Linéaire. 1989.
* N Ghoussoub and C Gui. On a conjecture of De Giorgi and some related problems. [[Mathematische Annalen]]. 1998.
* N Ghoussoub and C Yuan. Multiple solutions for quasi-linear PDEs involving the critical Sobolev and Hardy exponents. [[Transactions of the American Mathematical Society]]. 2000.
* I Ekeland and N Ghoussoub. Selected new aspects of the calculus of variations in the large. [[Bulletin of the American Mathematical Society]]. 2002.
* N Ghoussoub and Y Guo. On the partial differential equations of electrostatic MEMS devices: stationary case. SIAM Journal of Mathematical Analysis. 2007.

=== Books ===

*# N. Ghoussoub, A. Moradifam: ''Functional Inequalities: New Perspectives and New Applications'', Mathematical Survey and Monographs series, AMS (2013) 310 pp
*# P. Esposito, N. Ghoussoub, Y. Guo: ''Mathematical Analysis of Partial Differential Equations Modeling Electrostatic MEMS'', Courant Lecture Notes, Volume 20 (2010) 318 pp, 
*# N. Ghoussoub: ''Self-dual Partial Differential Systems and Their Variational Principles'', Springer Monographs in Mathematics, Springer New York (2008) 354 pp
*# N Ghoussoub. Duality and perturbation methods in critical point theory. Cambridge Tracts, Cambridge University Press 107, (1993) p.1-268. [https://books.google.ca/books?hl=en&amp;lr=&amp;id=tYrzf9LC6yEC&amp;oi=fnd&amp;pg=PR11&amp;dq=info:gzhUPZm3d2kJ:scholar.google.com&amp;ots=823bLtXkN9&amp;sig=jPD93uyzPjgCYWOzcoxsGG57Y_c&amp;redir_esc=y#v=onepage&amp;q&amp;f=false]

==See also==
* [[Banff International Research Station]]

==References==
{{Reflist}}

==External links==
* [http://www.birs.ca/~nassif/ Nassif Ghoussoub's homepage]
* [http://nghoussoub.com/ Piece of Mind], Nassif's personal blog
* [http://www.mathunion.org/o/Organization/GA/GA-Santiago/candidatesCV/EC/ECGhoussoub.pdf A biography]

{{Authority control}}

{{DEFAULTSORT:Ghoussoub, Nassif}}
[[Category:Living people]]
[[Category:20th-century Canadian mathematicians]]
[[Category:21st-century Canadian mathematicians]]
[[Category:Canadian people of Lebanese descent]]
[[Category:Mathematical analysts]]
[[Category:University of British Columbia faculty]]
[[Category:Pierre and Marie Curie University alumni]]
[[Category:Fellows of the Royal Society of Canada]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Functional analysts]]
[[Category:PDE theorists]]
[[Category:Officers of the Order of Canada]]
[[Category:1953 births]]</text>
      <sha1>palm9689v68k4dyhj60diectm3ku2cr</sha1>
    </revision>
  </page>
  <page>
    <title>Nth root</title>
    <ns>0</ns>
    <id>235029</id>
    <revision>
      <id>867755526</id>
      <parentid>866002005</parentid>
      <timestamp>2018-11-07T20:14:28Z</timestamp>
      <contributor>
        <ip>24.57.106.253</ip>
      </contributor>
      <comment>/* nth root algorithm */ wikifying 'recurrence relation'</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="31450">{{about|nth-roots of real and complex numbers|other uses|Root (disambiguation)}}
{{DISPLAYTITLE:''n''th root}}
In [[mathematics]], an '''''n''th root''' of a [[number]] ''x'', where ''n'' is usually assumed to be a positive integer, is a number ''r'' which, when raised to the power ''n'' yields&amp;nbsp;''x'':
:&lt;math&gt;r^n = x,&lt;/math&gt;
where ''n'' is the ''degree'' of the root. A root of degree 2 is called a ''[[square root]]'' and a root of degree 3, a ''[[cube root]]''. Roots of higher degree are referred by using ordinal numbers, as in ''fourth root'', ''twentieth root'', etc.

For example:
* 3 is a square root of 9, since 3&lt;sup&gt;2&lt;/sup&gt; = 9.
* −3 is also a square root of 9, since (−3)&lt;sup&gt;2&lt;/sup&gt; = 9.

Any non-zero number, considered as complex number, has ''n'' different "complex roots of degree ''n''" (''n''th roots), including those with zero imaginary part, i.e. any real roots. The root of ''0'' is zero for all degrees ''n'', since {{nobr|0&lt;sup&gt;''n''&lt;/sup&gt; {{=}} 0}}. In particular, if ''n'' is even and ''x'' is a positive real number, one of its ''n''th roots is positive, one is negative, and the rest (when ''n'' &gt; 2) are complex but not real; if ''n'' is even and ''x'' is a negative real, none of the ''n''th roots is real. If ''n'' is odd and ''x'' is real, one ''n''th root is real and has the same sign as ''x'', while the other (''n'' − 1) roots are not real. Finally, if ''x'' is not real, then none of its ''n''th roots is real.

Roots are usually written using the [[radical symbol]] or ''radix'' with &lt;math&gt;\sqrt{x}&lt;/math&gt; denoting the principal square root of &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;\sqrt[3]{x}&lt;/math&gt; denoting the principal cube root, &lt;math&gt;\sqrt[4]{x}&lt;/math&gt; denoting the principal fourth root, and so on. In the expression &lt;math&gt;\sqrt[n]{x}&lt;/math&gt;, ''n'' is called the ''index'', &lt;math&gt;\sqrt{\;}&lt;/math&gt; is the ''radical sign'' or ''radix'', and &lt;math&gt;x&lt;/math&gt; is called the ''radicand''. Since the radical symbol denotes a [[function (mathematics)|function]], it is defined to return only one result for a given argument &lt;math&gt;x&lt;/math&gt;, which is called the principal ''n''th root of &lt;math&gt;x&lt;/math&gt;. Conventionally, a real root, preferably non-negative, if there is one, is designated as the principal ''n''th root.

A complementary definition of ''principal root'' (though not formally defined or universally accepted) is to say that it is always the complex root that has the least value of the argument among all roots; here “argument” is bound to &lt;math&gt;[0, 2\pi)&lt;/math&gt; and means the counterclockwise [[polar coordinate system|angle in radian]] between the positive real axis and the line joining the complex number to the origin.

For example:
* &lt;math&gt;-8&lt;/math&gt; has three cube roots: &lt;math&gt;-2&lt;/math&gt;, &lt;math&gt;1 + i\sqrt{3}&lt;/math&gt; and &lt;math&gt;1 - i\sqrt{3}&lt;/math&gt; with arguments &lt;math&gt;\pi,\;\tfrac{1}{3}\pi, \;\tfrac{5}{3}\pi,&lt;/math&gt; respectively. Of these, &lt;math&gt;1 + i\sqrt{3}&lt;/math&gt; has the least argument and hence in some contexts is considered the principal cube root, while in other contexts &lt;math&gt;-2&lt;/math&gt; is said to be the principal cube root because it is the only real one.
* &lt;math&gt;16&lt;/math&gt; has four fourth roots: &lt;math&gt;2,\;2i,\;-2,&lt;/math&gt; and &lt;math&gt;-2i&lt;/math&gt;, having arguments &lt;math&gt;0,\;\tfrac{1}{2}\pi,\;\pi&lt;/math&gt; and &lt;math&gt;\tfrac{3}{2}\pi&lt;/math&gt; respectively. So &lt;math&gt;2&lt;/math&gt; is always considered the unique principal fourth root, because it is a positive real, which necessarily has the least argument possible:&amp;nbsp;&lt;math&gt;0&lt;/math&gt;.

An unresolved root, especially one using the radical symbol, is sometimes referred to as a ''surd''&lt;ref&gt;{{cite book |title=New Approach to CBSE Mathematics IX |first=R. K. |last=Bansal |page=25 |year=2006 |isbn=978-81-318-0013-3 |publisher=Laxmi Publications |url=https://books.google.com/books?id=1C4iQNUWLBwC&amp;pg=PA25#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt; or a ''radical''.&lt;ref name=silver&gt;{{cite book|last=Silver|first=Howard A.|title=Algebra and trigonometry|year=1986|publisher=Prentice-Hall|location=Englewood Cliffs, N.J.|isbn=0-13-021270-9}}&lt;/ref&gt; Any expression containing a radical, whether it is a square root, a cube root, or a higher root, is called a ''radical expression'', and if it contains no [[transcendental functions]] or [[transcendental numbers]] it is called an [[algebraic expression]].

In [[calculus]], '''roots''' are treated as special cases of [[exponentiation]], where the [[exponent]] is a [[Fraction (mathematics)|fraction]]:
:&lt;math&gt;\sqrt[n]{x} = x^\frac{1}{n}.&lt;/math&gt;
Roots are particularly important in the theory of infinite [[Series (mathematics)|series]]; the [[root test]] determines the [[radius of convergence]] of a [[power series]]. Roots can also be defined for [[complex number]]s, and the complex roots of&amp;nbsp;1 (the [[Root of unity|roots of unity]]) play an important role in higher mathematics.  [[Galois theory]] can be used to determine which [[algebraic number]]s can be expressed using roots and to prove the [[Abel–Ruffini theorem]], which states that a general [[polynomial]] equation of degree five or higher cannot be solved using roots alone; this result is also known as "the insolubility of the quintic".

==History==

{{Main article|Square root#History|Cube root#History}}
An archaic term for the operation of taking ''n''th roots is ''radication''.&lt;ref&gt;{{cite web|url=https://www.merriam-webster.com/dictionary/radication|title=Definition of RADICATION|website=www.merriam-webster.com}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://en.oxforddictionaries.com/definition/radication|title=radication - Definition of radication in English by Oxford Dictionaries|website=Oxford Dictionaries - English}}&lt;/ref&gt; 

==Definition and notation==

[[File:NegativeOne4Root.svg|thumb|The four 4th roots of −1,&lt;br /&gt; none of which is real]]
[[File:NegativeOne3Root.svg|thumb|The three 3rd roots of −1,&lt;br /&gt; one of which is a negative real]]
An  '''''n''th root''' of a number ''x'', where ''n'' is a positive integer, is any of the ''n'' real or complex numbers ''r'' whose ''n''th power is ''x'':
:&lt;math&gt;r^n = x.&lt;/math&gt;
Every positive [[real number]] ''x'' has a single positive ''n''th root, called the [[principal value|principal ''n''th root]], which is written &lt;math&gt;\sqrt[n]{x}&lt;/math&gt;. For ''n'' equal to 2 this is called the principal square root and the  ''n'' is omitted. The ''n''th root can also be represented using [[exponentiation]] as ''x''&lt;sup&gt;1/n&lt;/sup&gt;.

For even values of ''n'', positive numbers also have a negative ''n''th root, while negative numbers do not have a real ''n''th root.  For odd values of ''n'', every negative number ''x'' has a real negative ''n''th root.  For example, −2 has a real 5th root, &lt;math&gt;\sqrt[5]{-2} = -1.148698354\ldots&lt;/math&gt; but −2 does not have any real 6th roots.

Every non-zero number ''x'', real or [[Complex number|complex]], has ''n'' different complex number ''n''th roots.  (In the case ''x'' is real, this count includes any real ''n''th roots.) The only complex root of 0 is 0.

The ''n''th roots of almost all numbers (all integers except the ''n''th powers, and all rationals except the quotients of two ''n''th powers) are [[irrational number|irrational]].  For example,
:&lt;math&gt;\sqrt{2} = 1.414213562\ldots&lt;/math&gt;

All ''n''th roots of integers are [[algebraic number]]s.

The term ''surd'' traces back to [[Khwārizmī|al-Khwārizmī]] (c. 825), who referred to rational and irrational numbers as ''audible'' and ''inaudible'', respectively. This later led to the Arabic word "{{rtl-lang|tg-Arab|أصم}}" (''asamm'', meaning "deaf" or "dumb") for ''irrational number'' being translated into Latin as "surdus" (meaning "deaf" or "mute"). [[Gerard of Cremona]] (c. 1150), [[Fibonacci]] (1202), and then [[Robert Recorde]] (1551) all used the term to refer to ''unresolved irrational roots''.&lt;ref&gt;{{cite web |url=http://jeff560.tripod.com/s.html |title=Earliest Known Uses of Some of the Words of Mathematics|publisher=Mathematics Pages by Jeff Miller|accessdate=2008-11-30}}&lt;/ref&gt;

===Square roots===
[[Image:Square-root function.svg|thumb|right|The graph &lt;math&gt;y=\pm \sqrt{x}&lt;/math&gt;.]]
{{Main article|Square root}}
A '''square root''' of a number ''x'' is a number ''r'' which, when [[square (algebra)|squared]], becomes ''x'':
:&lt;math&gt;r^2 = x.&lt;/math&gt;
Every positive real number has two square roots, one positive and one negative.  For example, the two square roots of 25 are 5 and −5.  The positive square root is also known as the '''principal square root''', and is denoted with a radical sign:
:&lt;math&gt;\sqrt{25} = 5.&lt;/math&gt;

Since the square of every real number is a positive real number, negative numbers do not have real square roots.  However, for every negative real number there are two [[imaginary number|imaginary]] square roots.  For example, the square roots of −25 are 5''i'' and −5''i'', where ''[[imaginary unit|i]]'' represents a number whose square is {{math|−1}}.

===Cube roots===
[[Image:cube-root function.svg|thumb|right|The graph &lt;math&gt;y=\sqrt[3]{x}&lt;/math&gt;.]]
{{Main article|Cube root}}
A '''cube root''' of a number ''x'' is a number ''r'' whose [[cube (algebra)|cube]] is ''x'':
:&lt;math&gt;r^3 = x.&lt;/math&gt;
Every real number ''x'' has exactly one real cube root, written &lt;math&gt;\sqrt[3]{x}&lt;/math&gt;.  For example,
:&lt;math&gt;\sqrt[3]{8} = 2&lt;/math&gt; and &lt;math&gt;\sqrt[3]{-8} = -2.&lt;/math&gt;
Every real number has two additional [[complex number|complex]] cube roots.

==Identities and properties==
Expressing the degree of an ''n''th root in its exponent form, as in &lt;math&gt;x^\frac{1}{n}&lt;/math&gt;, makes it easier to manipulate powers and roots.

:&lt;math&gt;\sqrt[n]{a^m} \equiv \left(a^m\right)^{\frac{1}{n}} \equiv a^{\frac{m}{n}}.&lt;/math&gt;

Every [[positive number|positive real number]] has exactly one positive real ''n''th root, and so the rules for operations with surds involving positive radicands &lt;math&gt;a,\; b&lt;/math&gt; are straightforward within the real numbers:

:&lt;math&gt;\begin{align}
           \sqrt[n]{ab} &amp;\equiv \sqrt[n]{a} \sqrt[n]{b} \\
  \sqrt[n]{\frac{a}{b}} &amp;\equiv \frac{\sqrt[n]{a}}{\sqrt[n]{b}}
\end{align}&lt;/math&gt;

Subtleties can occur when taking the ''n''th roots of negative or [[complex number]]s. For instance:

:&lt;math&gt;\sqrt{-1}\times\sqrt{-1} \neq \sqrt{-1 \times -1} = 1,\quad&lt;/math&gt; but rather &lt;math&gt;\quad\sqrt{-1}\times\sqrt{-1} = i \times i = i^2 = -1.&lt;/math&gt;

Since the rule &lt;math&gt;\sqrt[n]{a} \times \sqrt[n]{b} =  \sqrt[n]{ab} &lt;/math&gt; strictly holds for non-negative real radicands only, its application leads to the inequality in the first step above.

==Simplified form of a radical expression==
A non-nested radical expression is said to be in '''simplified form''' if&lt;ref&gt;{{cite book|last=McKeague|first=Charles P.|title=Elementary algebra|page=470|year=2011|url=https://books.google.com/books?id=etTbP0rItQ4C&amp;printsec=frontcover&amp;dq=editions:q0hGn6PkOxsC&amp;hl=sv&amp;ei=52CsTqv9Go7sOZ_tldAP&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=2&amp;ved=0CDEQ6AEwAQ#v=onepage&amp;q&amp;f=false}}&lt;/ref&gt;
# There is no factor of the radicand that can be written as a power greater than or equal to the index.
# There are no fractions under the radical sign.
# There are no radicals in the denominator.

For example, to write the radical expression &lt;math&gt;\sqrt{\tfrac{32}{5}}&lt;/math&gt; in simplified form, we can proceed as follows. First, look for a perfect square under the square root sign and remove it:
:&lt;math&gt;\sqrt{\tfrac{32}{5}} = \sqrt{\tfrac{16 \cdot 2}{5}} = 4 \sqrt{\tfrac{2}{5}}&lt;/math&gt;
Next, there is a fraction under the radical sign, which we change as follows:
:&lt;math&gt;4 \sqrt{\tfrac{2}{5}} = \frac{4 \sqrt{2}}{\sqrt{5}}&lt;/math&gt;
Finally, we remove the radical from the denominator as follows:
:&lt;math&gt;\frac{4 \sqrt{2}}{\sqrt{5}} = \frac{4 \sqrt{2}}{\sqrt{5}} \cdot \frac{\sqrt{5}}{\sqrt{5}} = \frac{4 \sqrt{10}}{5} = \frac{4}{5}\sqrt{10}&lt;/math&gt;

When there is a denominator involving surds it is always possible to find a factor to multiply both numerator and denominator by to simplify the expression.&lt;ref&gt;B. F. Caviness, R. J. Fateman, [http://www.eecs.berkeley.edu/~fateman/papers/radcan.pdf "Simplification of Radical Expressions"], ''Proceedings of the 1976 ACM Symposium on Symbolic and Algebraic Computation'', p.&amp;nbsp;329.&lt;/ref&gt;&lt;ref&gt;Richard Zippel, "Simplification of Expressions Involving Radicals", ''Journal of Symbolic Computation'' '''1''':189–210 (1985) {{doi|10.1016/S0747-7171(85)80014-6}}.&lt;/ref&gt; For instance using the [[Factorization#Sum/difference of two cubes|factorization of the sum of two cubes]]:

:&lt;math&gt;
  \frac{1}{\sqrt[3]{a} + \sqrt[3]{b}} =
  \frac{\sqrt[3]{a^2} - \sqrt[3]{ab} + \sqrt[3]{b^2}}{\left(\sqrt[3]{a} + \sqrt[3]{b}\right)\left(\sqrt[3]{a^2} - \sqrt[3]{ab} + \sqrt[3]{b^2}\right)} =
  \frac{\sqrt[3]{a^2} - \sqrt[3]{ab} + \sqrt[3]{b^2}}{a + b} \,.
&lt;/math&gt;

Simplifying radical expressions involving [[nested radical]]s can be quite difficult. It is not obvious for instance that:

:&lt;math&gt;\sqrt{3 + 2\sqrt{2}} = 1 + \sqrt{2}&lt;/math&gt;

The above can be derived through:
:&lt;math&gt;\sqrt{3 + 2\sqrt{2}} = \sqrt{1 + 2\sqrt{2} + 2} = \sqrt{1^2 + 2\sqrt{2} + \sqrt{2}^2} = \sqrt{\left(1 + \sqrt{2}\right)^2} = 1 + \sqrt{2}&lt;/math&gt;

==Infinite series==
The radical or root may be represented by the [[infinite series]]:

:&lt;math&gt;(1+x)^\frac{s}{t} = \sum_{n=0}^\infty \frac{\prod_{k=0}^{n-1} (s-kt)}{n!t^n}x^n&lt;/math&gt;

with &lt;math&gt;|x|&lt;1&lt;/math&gt;. This expression can be derived from the [[binomial series]].

==Computing principal roots==
The ''n''th root of an [[integer]] ''k'' is only an integer if ''k'' is the product of ''n''th powers of integers. In all other cases the ''n''th root of an integer is an [[irrational number]]. For instance, the fifth root of
:&lt;math&gt;\sqrt[5]{248 832} = \sqrt[5]{3^5\cdot 2^5\cdot 2^5} = 12&lt;/math&gt;

and the fifth root of 34 is
:&lt;math&gt; \sqrt[5]{34} = \sqrt[5]{2\cdot 17} = 2.024397458 \ldots , &lt;/math&gt;

where here the dots signify not only that the decimal expression does not end after a finite number of digits, but also that the digits never enter a repeating pattern, because the number is irrational.

Since for positive real numbers {{mvar|a}} and {{mvar|b}} the equality &lt;math&gt;\;\sqrt[n]{a/b} = \sqrt[n]{a}/\sqrt[n]{b}\;&lt;/math&gt; holds, the above property can be extended to positive rational numbers. Let &lt;math&gt;r=p/q&lt;/math&gt;, with {{mvar|p}} and {{mvar|q}} coprime and positive integers, be a rational number, {{nowrap|then {{mvar|r}}}} has a rational ''n''th root, if both positive {{nowrap|integers {{mvar|p}}}} {{nowrap|and {{mvar|q}}}} have an integer ''n''th root, i.e., &lt;math&gt;\;r= p\cdot\tfrac{1}{q}\;&lt;/math&gt; is the product of ''n''th powers of rational numbers. If one or both ''n''th roots of {{mvar|p}} or {{mvar|q}} are irrational, the quotient is irrational, too.

===''n''th root algorithm===

The ''n''th root of a number ''A'' can be computed by the [[nth root algorithm|''n''th root algorithm]], a special case of [[Newton's method]]. Start with an initial guess ''x''&lt;sub&gt;0&lt;/sub&gt; and then iterate using the [[recurrence relation]]
:&lt;math&gt;x_{k+1} = \frac{1}{n} \left({(n-1)x_k +\frac{A}{x_k^{n-1}}}\right) &lt;/math&gt;
until the desired precision is reached.

Depending on the application, it may be enough to use only the first Newton approximant:
:&lt;math&gt; \sqrt[n]{x^n+y} \approx x + \frac{y}{n x^{n-1}}. &lt;/math&gt;
For example, to find the fifth root of 34, note that 2&lt;sup&gt;5&lt;/sup&gt; = 32 and thus take ''x'' = 2, ''n'' = 5 and ''y'' = 2 in the above formula. This yields
:&lt;math&gt; \sqrt[5]{34} = \sqrt[5]{32 + 2} \approx 2 + \frac{2}{5 \cdot 16} = 2.025. &lt;/math&gt;
The error in the approximation is only about 0.03%.

Newton's method can be modified to produce a [[generalized continued fraction#Roots of positive numbers|generalized continued fraction]] for the ''n''th root which can be modified in various ways as described in that article. For example:
:&lt;math&gt;
  \sqrt[n]{z} = \sqrt[n]{x^n+y} = x+\cfrac{y} {nx^{n-1}+\cfrac{(n-1)y} {2x+\cfrac{(n+1)y} {3nx^{n-1}+\cfrac{(2n-1)y} {2x+\cfrac{(2n+1)y} {5nx^{n-1}+\cfrac{(3n-1)y} {2x+\ddots}}}}}};
&lt;/math&gt;
:&lt;math&gt;
  \sqrt[n]{z} = x+\cfrac{2x\cdot y}{n(2z - y)-y-\cfrac{(1^2n^2-1)y^2}{3n(2z - y)-\cfrac{(2^2n^2-1)y^2}{5n(2z - y)-\cfrac{(3^2n^2-1)y^2}{7n(2z - y)-\ddots}}}}.
&lt;/math&gt;

In the case of the fifth root of 34 above (after dividing out selected common factors):
:&lt;math&gt;
  \sqrt[5]{34} = 2+\cfrac{1} {40+\cfrac{4} {4+\cfrac{6} {120+\cfrac{9} {4+\cfrac{11} {200+\cfrac{14} {4+\ddots}}}}}}
               = 2+\cfrac{4\cdot 1}{165-1-\cfrac{4\cdot 6}{495-\cfrac{9\cdot 11}{825-\cfrac{14\cdot 16}{1155-\ddots}}}}.
&lt;/math&gt;

=== Digit-by-digit calculation of principal roots of decimal (base 10) numbers ===
[[Image:PascalForDecimalRoots.png|right|thumb|[[Pascal's triangle|Pascal's Triangle]] showing &lt;math&gt;P(4,1) = 4&lt;/math&gt;.]]
Building on the [[Methods of computing square roots#Decimal (base 10)|digit-by-digit calculation of a square root]], it can be seen that the formula used there, &lt;math&gt;x(20p + x) \le c&lt;/math&gt;, or &lt;math&gt;x^2 + 20xp \le c&lt;/math&gt;, follows a pattern involving Pascal's triangle.  For the ''n''th root of a number &lt;math&gt;P(n,i)&lt;/math&gt; is defined as the value of element &lt;math&gt;i&lt;/math&gt; in row &lt;math&gt;n&lt;/math&gt; of Pascal's Triangle such that &lt;math&gt;P(4,1) = 4&lt;/math&gt;, we can rewrite the expression as &lt;math&gt;\sum_{i=0}^{n-1}10^i P(n,i)p^i x^{n-i}&lt;/math&gt;.  For convenience, call the result of this expression &lt;math&gt;y&lt;/math&gt;.  Using this more general expression, any positive principal root can be computed, digit-by-digit, as follows.

Write the original number in decimal form. The numbers are written similar to the [[long division]] algorithm, and, as in long division, the root will be written on the line above. Now separate the digits into groups of digits equating to the root being taken, starting from the decimal point and going both left and right. The decimal point of the root will be above the decimal point of the square. One digit of the root will appear above each group of digits of the original number.

Beginning with the left-most group of digits, do the following procedure for each group:

# Starting on the left, bring down the most significant (leftmost) group of digits not yet used (if all the digits have been used, write "0" the number of times required to make a group) and write them to the right of the remainder from the previous step (on the first step, there will be no remainder). In other words, multiply the remainder by &lt;math&gt;10^n&lt;/math&gt; and add the digits from the next group. This will be the '''current value ''c'''''.
# Find ''p'' and ''x'', as follows:
#* Let &lt;math&gt;p&lt;/math&gt; be the '''part of the root found so far''', ignoring any decimal point. (For the first step, &lt;math&gt;p = 0&lt;/math&gt;).
#* Determine the greatest digit &lt;math&gt;x&lt;/math&gt; such that &lt;math&gt;y \le c&lt;/math&gt;.
#* Place the digit &lt;math&gt;x&lt;/math&gt; as the next digit of the root, i.e., above the group of digits you just brought down. Thus the next ''p'' will be the old ''p'' times 10 plus ''x''.
# Subtract &lt;math&gt;y&lt;/math&gt; from &lt;math&gt;c&lt;/math&gt; to form a new remainder.
# If the remainder is zero and there are no more digits to bring down, then the algorithm has terminated. Otherwise go back to step 1 for another iteration.

====Examples====
'''Find the square root of 152.2756.'''

         &lt;u&gt;  1  2. 3  4 &lt;/u&gt;
     &lt;u&gt; &lt;/u&gt;  /
      \/  01 52.27 56

          01                   10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·0&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;1&lt;/sup&gt;     ≤      1   &lt;   10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·2·0&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;         x = 1
         &lt;u&gt; 01 &lt;/u&gt;                     y = 10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·2·0&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;   =  1 +    0   =     1
          00 52                10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·1&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;     ≤     52   &lt;   10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·3&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·2·1&lt;sup&gt;1&lt;/sup&gt;·3&lt;sup&gt;1&lt;/sup&gt;         x = 2
         &lt;u&gt; 00 44 &lt;/u&gt;                  y = 10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·2·1&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;   =  4 +   40   =    44
             08 27             10&lt;sup&gt;0&lt;/sup&gt;·1·12&lt;sup&gt;0&lt;/sup&gt;·3&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·12&lt;sup&gt;1&lt;/sup&gt;·3&lt;sup&gt;1&lt;/sup&gt;   ≤    827   &lt;   10&lt;sup&gt;0&lt;/sup&gt;·1·12&lt;sup&gt;0&lt;/sup&gt;·4&lt;sup&gt;2&lt;/sup&gt;  + 10&lt;sup&gt;1&lt;/sup&gt;·2·12&lt;sup&gt;1&lt;/sup&gt;·4&lt;sup&gt;1&lt;/sup&gt;        x = 3
            &lt;u&gt; 07 29 &lt;/u&gt;               y = 10&lt;sup&gt;0&lt;/sup&gt;·1·12&lt;sup&gt;0&lt;/sup&gt;·3&lt;sup&gt;2&lt;/sup&gt;  + 10&lt;sup&gt;1&lt;/sup&gt;·2·12&lt;sup&gt;1&lt;/sup&gt;·3&lt;sup&gt;1&lt;/sup&gt;  =  9 +  720   =   729
                98 56          10&lt;sup&gt;0&lt;/sup&gt;·1·123&lt;sup&gt;0&lt;/sup&gt;·4&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·123&lt;sup&gt;1&lt;/sup&gt;·4&lt;sup&gt;1&lt;/sup&gt; ≤   9856   &lt;   10&lt;sup&gt;0&lt;/sup&gt;·1·123&lt;sup&gt;0&lt;/sup&gt;·5&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·123&lt;sup&gt;1&lt;/sup&gt;·5&lt;sup&gt;1&lt;/sup&gt;       x = 4
               &lt;u&gt; 98 56 &lt;/u&gt;            y = 10&lt;sup&gt;0&lt;/sup&gt;·1·123&lt;sup&gt;0&lt;/sup&gt;·4&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·2·123&lt;sup&gt;1&lt;/sup&gt;·4&lt;sup&gt;1&lt;/sup&gt; = 16 + 9840   =  9856
                00 00          Algorithm terminates: Answer is 12.34

'''Find the cube root of 4192 to the nearest hundredth.'''

      &lt;u&gt;   1   6.  1   2   4&lt;/u&gt;
  &lt;u&gt;3&lt;/u&gt;  /
   \/  004 192.000 000 000

       004                      10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;3&lt;/sup&gt;    +  10&lt;sup&gt;1&lt;/sup&gt;·3·0&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·0&lt;sup&gt;2&lt;/sup&gt;·1&lt;sup&gt;1&lt;/sup&gt;    ≤          4  &lt;  10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;3&lt;/sup&gt;     + 10&lt;sup&gt;1&lt;/sup&gt;·3·0&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt;    + 10&lt;sup&gt;2&lt;/sup&gt;·3·0&lt;sup&gt;2&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;     x = 1
      &lt;u&gt; 001 &lt;/u&gt;                        y = 10&lt;sup&gt;0&lt;/sup&gt;·1·0&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;3&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·3·0&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·0&lt;sup&gt;2&lt;/sup&gt;·1&lt;sup&gt;1&lt;/sup&gt;   =   1 +      0 +          0   =          1
       003 192                  10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·6&lt;sup&gt;3&lt;/sup&gt;    +  10&lt;sup&gt;1&lt;/sup&gt;·3·1&lt;sup&gt;1&lt;/sup&gt;·6&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·1&lt;sup&gt;2&lt;/sup&gt;·6&lt;sup&gt;1&lt;/sup&gt;    ≤       3192  &lt;  10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·7&lt;sup&gt;3&lt;/sup&gt;     + 10&lt;sup&gt;1&lt;/sup&gt;·3·1&lt;sup&gt;1&lt;/sup&gt;·7&lt;sup&gt;2&lt;/sup&gt;    + 10&lt;sup&gt;2&lt;/sup&gt;·3·1&lt;sup&gt;2&lt;/sup&gt;·7&lt;sup&gt;1&lt;/sup&gt;     x = 6
      &lt;u&gt; 003 096 &lt;/u&gt;                    y = 10&lt;sup&gt;0&lt;/sup&gt;·1·1&lt;sup&gt;0&lt;/sup&gt;·6&lt;sup&gt;3&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·3·1&lt;sup&gt;1&lt;/sup&gt;·6&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·1&lt;sup&gt;2&lt;/sup&gt;·6&lt;sup&gt;1&lt;/sup&gt;   = 216 +  1,080 +      1,800   =      3,096
           096 000              10&lt;sup&gt;0&lt;/sup&gt;·1·16&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;3&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·3·16&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·16&lt;sup&gt;2&lt;/sup&gt;·1&lt;sup&gt;1&lt;/sup&gt;   ≤      96000  &lt;  10&lt;sup&gt;0&lt;/sup&gt;·1·16&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;3&lt;/sup&gt;   + 10&lt;sup&gt;1&lt;/sup&gt;·3·16&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt;   + 10&lt;sup&gt;2&lt;/sup&gt;·3·16&lt;sup&gt;2&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;    x = 1
          &lt;u&gt; 077 281 &lt;/u&gt;                y = 10&lt;sup&gt;0&lt;/sup&gt;·1·16&lt;sup&gt;0&lt;/sup&gt;·1&lt;sup&gt;3&lt;/sup&gt;  + 10&lt;sup&gt;1&lt;/sup&gt;·3·16&lt;sup&gt;1&lt;/sup&gt;·1&lt;sup&gt;2&lt;/sup&gt;  + 10&lt;sup&gt;2&lt;/sup&gt;·3·16&lt;sup&gt;2&lt;/sup&gt;·1&lt;sup&gt;1&lt;/sup&gt;  =   1 +    480 +     76,800   =     77,281
           018 719 000          10&lt;sup&gt;0&lt;/sup&gt;·1·161&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;3&lt;/sup&gt;  + 10&lt;sup&gt;1&lt;/sup&gt;·3·161&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt;  + 10&lt;sup&gt;2&lt;/sup&gt;·3·161&lt;sup&gt;2&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt;  ≤   18719000  &lt;  10&lt;sup&gt;0&lt;/sup&gt;·1·161&lt;sup&gt;0&lt;/sup&gt;·3&lt;sup&gt;3&lt;/sup&gt;  + 10&lt;sup&gt;1&lt;/sup&gt;·3·161&lt;sup&gt;1&lt;/sup&gt;·3&lt;sup&gt;2&lt;/sup&gt;  + 10&lt;sup&gt;2&lt;/sup&gt;·3·161&lt;sup&gt;2&lt;/sup&gt;·3&lt;sup&gt;1&lt;/sup&gt;   x = 2
              &lt;u&gt; 015 571 928 &lt;/u&gt;        y = 10&lt;sup&gt;0&lt;/sup&gt;·1·161&lt;sup&gt;0&lt;/sup&gt;·2&lt;sup&gt;3&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·3·161&lt;sup&gt;1&lt;/sup&gt;·2&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt;·3·161&lt;sup&gt;2&lt;/sup&gt;·2&lt;sup&gt;1&lt;/sup&gt; =   8 + 19,320 + 15,552,600   = 15,571,928
               003 147 072 000  10&lt;sup&gt;0&lt;/sup&gt;·1·1612&lt;sup&gt;0&lt;/sup&gt;·4&lt;sup&gt;3&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·3·1612&lt;sup&gt;1&lt;/sup&gt;·4&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt;·3·1612&lt;sup&gt;2&lt;/sup&gt;·4&lt;sup&gt;1&lt;/sup&gt; ≤ 3147072000  &lt;  10&lt;sup&gt;0&lt;/sup&gt;·1·1612&lt;sup&gt;0&lt;/sup&gt;·5&lt;sup&gt;3&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt;·3·1612&lt;sup&gt;1&lt;/sup&gt;·5&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt;·3·1612&lt;sup&gt;2&lt;/sup&gt;·5&lt;sup&gt;1&lt;/sup&gt;  x = 4
                                The desired precision is achieved:
                                The cube root of 4192 is about 16.12

===Logarithmic calculation===

The principal ''n''th root of a positive number can be computed using [[logarithm]]s. Starting from the equation that defines ''r'' as an ''n''th root of ''x'', namely &lt;math&gt;r^n=x,&lt;/math&gt; with ''x'' positive and therefore its principal root ''r'' also positive, one takes logarithms of both sides (any [[logarithm#Particular bases|base of the logarithm]] will do) to obtain

:&lt;math&gt;n \log_b r = \log_b x \quad \quad \text{hence} \quad \quad \log_b r = \frac{\log_b x}{n}.&lt;/math&gt;

The root ''r'' is recovered from this by taking the [[antilog]]:

:&lt;math&gt;r = b^{\frac{1}{n}\log_b x}.&lt;/math&gt;

(Note: That formula shows ''b'' raised to the power of the result of the division, not ''b'' multiplied by the result of the division.)

For the case in which ''x'' is negative and ''n'' is odd, there is one real root ''r'' which is also negative. This can be found by first multiplying both sides of the defining equation by −1 to obtain &lt;math&gt;|r|^n = |x|,&lt;/math&gt; then proceeding as before to find |''r''|, and using {{nowrap|''r'' {{=}} −{{!}}''r''{{!}}}}.

==Geometric constructibility==

The [[ancient Greek mathematicians]] knew how to [[compass-and-straightedge construction|use compass and straightedge]] to construct a length equal to the square root of a given length. In 1837 [[Pierre Wantzel]] proved that an ''n''th root of a given length cannot be constructed if ''n'' is not a power of 2.&lt;ref&gt;{{Citation|first = [[Monsieur|M.]] L.|last = Wantzel|title = Recherches sur les moyens de reconnaître si un Problème de Géométrie peut se résoudre avec la règle et le compas |journal = Journal de Mathématiques Pures et Appliquées|year = 1837|volume = 1|issue = 2|pages = 366–372|url = http://visualiseur.bnf.fr/ConsulterElementNum?O=NUMM-16381&amp;Deb=374&amp;Fin=380&amp;E=PDF}}.&lt;/ref&gt;

==Complex roots==
Every [[complex number]] other than 0 has ''n'' different ''n''th roots.

===Square roots===
[[Image:Imaginary2Root.svg|thumb|right|The square roots of '''''i''''']]
The two square roots of a complex number are always negatives of each other. For example, the square roots of {{math|−4}} are {{math|2''i''}} and {{math|−2''i''}}, and the square roots of {{math|''i''}} are
:&lt;math&gt;\tfrac{1}{\sqrt{2}}(1 + i) \quad\text{and}\quad -\tfrac{1}{\sqrt{2}}(1 + i).&lt;/math&gt;
If we express a complex number in polar form, then the square root can be obtained by taking the square root of the radius and halving the angle:
:&lt;math&gt;\sqrt{re^{i\theta}} = \pm\sqrt{r} \cdot e^\frac{i\theta}{2}.&lt;/math&gt;
A ''principal'' root of a complex number may be chosen in various ways, for example
:&lt;math&gt;\sqrt{re^{i\theta}} = \sqrt{r} \cdot e^\frac{i\theta}{2}&lt;/math&gt;
which introduces a [[branch cut]] in the [[complex plane]] along the [[positive real axis]] with the condition {{math|0&amp;nbsp;≤&amp;nbsp;''θ''&amp;nbsp;&lt;&amp;nbsp;2π}}, or along the negative real axis with {{math|−π&amp;nbsp;&lt;&amp;nbsp;''θ''&amp;nbsp;≤&amp;nbsp;π}}.

Using the first(last) branch cut the principal square root &lt;math&gt;\scriptstyle \sqrt z&lt;/math&gt; maps &lt;math&gt;\scriptstyle z&lt;/math&gt; to the half plane with non-negative imaginary(real) part. The last branch cut is presupposed in mathematical software like [[Matlab]] or [[Scilab]].

===Roots of unity===
[[File:3rd roots of unity.svg|thumb|right|The three 3rd roots of 1]]
{{Main article|Root of unity}}

The number 1 has ''n'' different ''n''th roots in the complex plane, namely
:&lt;math&gt;1,\;\omega,\;\omega^2,\;\ldots,\;\omega^{n-1},&lt;/math&gt;
where
:&lt;math&gt;\omega = e^\frac{2\pi i}{n} = \cos\left(\frac{2\pi}{n}\right) + i\sin\left(\frac{2\pi}{n}\right)&lt;/math&gt;
These roots are evenly spaced around the [[unit circle]] in the complex plane, at angles which are multiples of &lt;math&gt;2\pi/n&lt;/math&gt;.  For example, the square roots of unity are 1 and −1, and the fourth roots of unity are 1, &lt;math&gt;i&lt;/math&gt;, −1, and &lt;math&gt;-i&lt;/math&gt;.

===''n''th roots===
{{visualisation_complex_number_roots.svg}}
Every complex number has ''n'' different ''n''th roots in the complex plane.  These are

:&lt;math&gt;\eta,\;\eta\omega,\;\eta\omega^2,\;\ldots,\;\eta\omega^{n-1},&lt;/math&gt;

where ''η'' is a single ''n''th root, and 1,&amp;nbsp;''ω'',&amp;nbsp;''ω''&lt;sup&gt;2&lt;/sup&gt;,&amp;nbsp;...&amp;nbsp;''ω''&lt;sup&gt;''n''−1&lt;/sup&gt; are the ''n''th roots of unity.  For example, the four different fourth roots of 2 are

:&lt;math&gt;\sqrt[4]{2},\quad i\sqrt[4]{2},\quad -\sqrt[4]{2},\quad\text{and}\quad -i\sqrt[4]{2}.&lt;/math&gt;

In polar form, a single ''n''th root may be found by the formula

:&lt;math&gt;\sqrt[n]{re^{i\theta}} = \sqrt[n]{r} \cdot e^{i\theta/n}.&lt;/math&gt;

Here ''r'' is the magnitude (the modulus, also called the [[absolute value]]) of the number whose root is to be taken; if the number can be written as ''a+bi'' then &lt;math&gt;r=\sqrt{a^2+b^2}&lt;/math&gt;. Also, &lt;math&gt;\theta&lt;/math&gt; is the angle formed as one pivots on the origin counterclockwise from the positive horizontal axis to a ray going from the origin to the number; it has the properties that &lt;math&gt;\cos \theta = a/r,&lt;/math&gt;  &lt;math&gt; \sin \theta = b/r,&lt;/math&gt; and &lt;math&gt; \tan \theta = b/a.&lt;/math&gt;

Thus finding ''n''th roots in the complex plane can be segmented into two steps. First, the magnitude of all the ''n''th roots is the ''n''th root of the magnitude of the original number. Second, the angle between the positive horizontal axis and a ray from the origin to one of the ''n''th roots is &lt;math&gt;\theta / n&lt;/math&gt;, where &lt;math&gt;\theta&lt;/math&gt; is the angle defined in the same way for the number whose root is being taken. Furthermore, all ''n'' of the ''n''th roots are at equally spaced angles from each other.

If ''n'' is even, a complex number's ''n''th roots, of which there are an even number, come in [[additive inverse]] pairs, so that if a number ''r''&lt;sub&gt;1&lt;/sub&gt; is one of the ''n''th roots then ''r''&lt;sub&gt;2&lt;/sub&gt; =  –''r''&lt;sub&gt;1&lt;/sub&gt; is another. This is because raising the latter's coefficient –1 to the ''n''th power for even ''n'' yields 1: that is, (–''r''&lt;sub&gt;1&lt;/sub&gt;)&lt;sup&gt;''n''&lt;/sup&gt; = (–1)&lt;sup&gt;''n''&lt;/sup&gt; × ''r''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt; = ''r''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;.

As with square roots, the formula above does not define a [[continuous function]] over the entire complex plane, but instead has a [[branch cut]] at points where ''θ''&amp;nbsp;/&amp;nbsp;''n'' is discontinuous.

==Solving polynomials==
{{see also|Root-finding algorithm}}

It was once [[conjecture]]d that all [[polynomial equation]]s could be [[Algebraic solution|solved algebraically]] (that is, that all roots of a [[polynomial]] could be expressed in terms of a finite number of radicals and [[elementary arithmetic|elementary operations]]). However, while this is true for third degree polynomials ([[cubic function|cubics]]) and fourth degree polynomials ([[quartic function|quartics]]), the [[Abel–Ruffini theorem]] (1824) shows that this is not true in general when the degree is 5 or greater. For example, the solutions of the equation

:&lt;math&gt;x^5 = x + 1&lt;/math&gt;

cannot be expressed in terms of radicals. (''cf.'' [[quintic equation]])

==See also==
* [[Nth root algorithm]]
* [[Shifting nth root algorithm]]
* [[Irrational number]]
* [[Radical symbol]]
* [[Algebraic number]]
* [[Nested radical]]
* [[Twelfth root of two]]
* [[Super-root]]

==References==

{{Reflist}}

== External links ==
{{Wiktionary|surd}}
{{Wiktionary|radical}}

{{Hyperoperations}}
[[Category:Elementary algebra]]</text>
      <sha1>kpmog3dhw8u4o5tjjw5xlt42akmz5iu</sha1>
    </revision>
  </page>
  <page>
    <title>Otfrid Mittmann</title>
    <ns>0</ns>
    <id>46179348</id>
    <revision>
      <id>796896054</id>
      <parentid>768346167</parentid>
      <timestamp>2017-08-23T18:06:29Z</timestamp>
      <contributor>
        <username>Amidewiki</username>
        <id>30879242</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7429">{{Infobox scientist
| honorific_prefix =
| name        = Otfrid Mittmann
| honorific_suffix =
| native_name = 
| native_name_lang = 
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{birth date|1908|12|27|df=y}}
| birth_place = [[Ruda Śląska]]
| death_date  = &lt;!---no source for death date---{{dda|1998|8|10|1908|12|27|df=y}}---&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates =  &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| residence   = 
| citizenship = 
| nationality = 
| fields      = 
| workplaces  = 
| patrons     = 
| education   = 
| alma_mater  = [[Georg-August-Universität Göttingen]] 
| thesis_title = Mathematisch-statistische Untersuchungen zur Erforschung fließender Merkmale.
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year = 1935
| doctoral_advisor = Münzner, Kühn&lt;ref name="DMV"/&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| website     =         &lt;!--{{URL|www.example.com}}--&gt;
| footnotes   = 
}}
'''Otfrid Mittmann''' (27 December 1908 in [[Ruda Śląska]]&lt;ref&gt;[https://portal.dnb.de/opac.htm?method=simpleSearch&amp;cqlMode=true&amp;query=idn%3D1016744528 Record] and [[German National Library]]&lt;/ref&gt;&lt;ref name="Weiss.1982"&gt;{{cite journal | author=Volkmar Weiss | title=Klassischer und probabilistischer Mendelismus: Ein wissenschaftsgeschichtlicher Beitrag zur Latenz wissenschaftlicher Ideen | journal=Biologisches Zentralblatt | volume=101 | number= | pages=597&amp;mdash;607 | url=http://www.v-weiss.de/latenz.html | year=1982 }}&lt;/ref&gt; &amp;mdash; 10 August 1998 in [[Rheinbach]]){{cn|reason=Weiss (1982) even supposes the Mittmann died in WWII. Although this is probably wrong, no publications of some 'Otfrid Mittmann' could be found after 1968.|date=June 2016}} was a German [[mathematician]].
Starting in 1927, he studied mathematics and natural sciences in [[G&amp;ouml;ttingen]] and [[Leipzig]], and got his [[Ph.D.]] in Apr 1935.&lt;ref name="Weiss.1982"/&gt; He joined the [[Nazi movement]] in Oct 1929.&lt;ref name="DMV"&gt;[https://web.archive.org/web/20150402103008/https://dmv.mathematik.de/index.php/dmv/geschichte/kurzbiographien/518-dmv-kurzbiographie-m/file Vita] (p.10) at [[German Mathematical Society]]&lt;/ref&gt; and published on statistical aspects of [[Nazi eugenics]]. After the war, he published in G&amp;ouml;ttingen&lt;ref&gt;{{cite journal | url=http://booksc.org/dl/1732959/20abfb | author=Otfrid M.J. Mittmann | title=Ausgleichsrechnung mit einem Operator | journal=Math. Nachr. | volume=3 | number=2 | pages=102&amp;mdash;106 | year=1949 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | url=http://booksc.org/dl/6801260/15afbe | author=O.M.J. Mittmann | title=Varianz-Untersuchungen bei stationären Variablen | journal=Archiv für Meteorologie, Geophysik und Bioklimatologie,  Serie A | publisher=Springer | volume=9 | number=4 | pages=519&amp;mdash;523 | date=Dec 1956 }}&lt;/ref&gt; and [[Bonn]].&lt;ref&gt;{{cite journal | url=http://booksc.org/dl/6256086/360f85 | author=O. Mittmann | title=Rückschlüsse von Selektionskollektiven &amp;mdash; Bemerkungen zu der Arbeit von H. Grosse ``Über Berksons Fallacy und die Selektion durch den Tod'', Virchows Archiv 337, 573&amp;mdash;578 (1964) | journal=Virchows Arch. path. Anat. | volume=337 | number= | pages=579&amp;mdash;582 | year=1964 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | url=http://booksc.org/dl/5994221/31fce3 | author=O. Hornstein and H. Eifel and O. Mittmann | title=Untersuchungen über die Reinkeschen Kristalloide  der Leydigzellen bei Hodenparenchymschäden | journal=Archiv für klinische und experimentelle Dermatologie | volume=225 | pages=1&amp;mdash;3 | year=1966 }}&lt;/ref&gt;

==Publications==

* {{cite thesis | type=Ph.D. thesis | author=Mittmann, O. | title=Mathematisch-statistische Untersuchungen zur Erforschung  fließender Merkmale | institution=Univ. Göttingen | month= | year=1935 }}
*{{cite book | author=Mittmann, Otfrid | title=Über die Schnelligkeit der relativen Vermehrung vorteilhafter Mutationen | location=Göttingen | publisher=[[Vandenhoeck &amp; Ruprecht]] | year=1936 }}
*{{cite journal | author=Otfrid Mittmann | title=Zur Austilgung einer vererbbaren Eigenschaft bei Merkmalen mit übergreifenden Erscheinungformen (Fall des einpaarigen Erbgangs) | journal=[[Deutsche Mathematik]] | volume=1 | number=2 | pages=149&amp;mdash;155 | date=May 1936 }}
*{{cite journal | author=Otfrid Mittmann | title=Die Erfolgsaussichten von Auslesemaßnahmen  im Kampf gegen die Erbkrankheiten | journal=Deutsche Mathematik | volume=2 | number=1 | pages=32&amp;mdash;55 | date=Apr 1937 | url=https://commons.wikimedia.org/wiki/File:Mittmann.1937.pdf  | quote=Man pflegt leider mit einem derartig unsauberen Verfahren zu arbeiten, wenn es sich darum handelt, ein Urteil &amp;uuml;ber den Wert des deutschen Gesetzes zur Verhütung erbkranken Nachwuchses in die Welt zu setzen. Es soll im folgenden kurz gezeigt werden, wie die Dinge liegen und welche Extremf&amp;auml;lle man sich auszusuchen pflegt, um ein m&amp;ouml;glichst ung&amp;uuml;nstiges Urteil &amp;uuml;ber den Wert der deutschen Auslesema&amp;szlig;nahmen zu gewinnen. ''(Unfortunately, one uses to work with such an unsound approach when a judgement about the German [[Law for the Prevention of Hereditarily Diseased Offspring]] is to be created. In the following, it shall be shown how things are and which extremal cases one uses to pick out to obtain an as unfavorable judgement as possible about the value of the German selection measures.)''}}
*{{cite journal | author=Otfrid Mittmann | title=Über die Schnelligkeit der Ausmerze von Erbkrankheiten durch Sterilisation | journal=Deutsche Mathematik | volume=2 | number=6 | pages=709&amp;mdash;721 | date=Jan 1938 | url=https://commons.wikimedia.org/wiki/File:Mittmann.1938.pdf }}
*{{cite book | author=Mittmann, Otfrid | title=Erbbiologische Fragen in mathematischer Behandlung | location=Berlin | publisher=[[de Gruyter]] | year=1940 }}
*{{cite journal | author=Otfrid Mittmann | title=Theoretische Erbprognose und Gattenwahl | journal=Deutsche Mathematik | volume=5 | number=4 | pages=328&amp;mdash;337 | date=Dec 1940 }}
*{{cite journal | author=Otfrid Mittmann | title=Funktionale Zusammenhänge  zwischen Zygotenwahrscheinlichkeiten | journal=Deutsche Mathematik | volume=5 | number=6 | pages=563&amp;mdash;570 | date=May 1941 }}
* {{cite journal | author=O. Mittmann | title=Zur statistischen Zwillingsmethode | journal=[[Corrado Gini#Career|Metron]] | volume=27 | pages=1&amp;mdash;7 | year=1968 }}&lt;!---citation found on p.267 of {{cite book | isbn=978-3-642-65974-4 | author=Wilhelm-Wolfgang Höpker | title=Spätfolgen extremer Lebensverhältnisse | location=Heidelberg | publisher=Springer | year=1974 }}---&gt;

==References==
{{reflist}}

==External links==
{{commons category|Otfrid Mittmann (mathematician)}}
* {{MathGenealogy|65547}}

{{Authority control}}

{{DEFAULTSORT:Mittmann, Otfrid}}
[[Category:German mathematicians]]
[[Category:1908 births]]
[[Category:Nazi Party members]]
[[Category:German eugenicists]]
[[Category:Year of death missing]]


{{nazi-stub}}
{{mathematician-stub}}</text>
      <sha1>9hcbwv1qymq2p4179v9k9igizkwg61z</sha1>
    </revision>
  </page>
  <page>
    <title>Plateau principle</title>
    <ns>0</ns>
    <id>24608545</id>
    <revision>
      <id>802398034</id>
      <parentid>802397955</parentid>
      <timestamp>2017-09-25T22:38:34Z</timestamp>
      <contributor>
        <ip>134.84.18.27</ip>
      </contributor>
      <comment>/* Equations for the approach to steady state */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22889">The '''plateau principle''' is a [[mathematical model]] or [[scientific law]] originally developed to explain the time course of drug action.&lt;ref name="Goldstein A 1968"&gt;Goldstein A, Aronow L, and Kalman SM. Principles of Drug Action. The Basis of Pharmacology. Harper and Row, New York, 1968.&lt;/ref&gt;  The principle has wide applicability in pharmacology, physiology, nutrition, biochemistry and system dynamics.  It applies whenever a drug or nutrient is infused or ingested at a relatively constant rate and when a constant fraction is eliminated during each time interval.  Under these conditions, any change in the rate of infusion leads to an exponential increase or decrease until a new level is achieved.  This behavior is also called an '''approach to [[steady state]]''' because rather than causing an indefinite increase or decrease, a natural balance is achieved when the rate of infusion or production is balanced by the rate of loss.

An especially important use of the plateau principle is to study the renewal of tissue constituents in the human and animal body.   In adults, daily synthesis of tissue constituents is nearly constant, and most constituents are removed with a first order [[reaction rate]].  Applicability of the plateau principle was recognized during [[radiotracer]] studies of protein turnover in the 1940s by [[Rudolph Schoenheimer]]&lt;ref&gt;Schoenheimer R. The Dynamic State of Body Constituents. Harvard University Press, Cambridge, MA, 1942.&lt;/ref&gt; and [[David Rittenberg]].&lt;ref&gt;San Pietro A, Rittenberg D. A study of the rate of protein synthesis in humans. II. Measurement of the metabolic pool and the rate of protein synthesis. J Biol Chem. 201:457, 1953.&lt;/ref&gt;  Unlike the case with drugs, the initial amount of tissue or tissue protein is not zero because daily synthesis offsets daily elimination.  In this case, the model is also said to approach a [[steady state]] with [[Exponential function|exponential]] or [[logarithmic growth|logarithmic]] kinetics.  Constituents that change in this manner are said to have a [[biological half-life]].

A practical application of the plateau principle is that most people have experienced "plateauing" during regimens for weight management or training for sports.  After a few weeks of progress, one seems unable to continue gaining in ability or losing weight.  This outcome results from the same underlying quantitative model.  This entry will describe the popular concepts as well as development of the plateau principle as a scientific, mathematical model.

In the sciences, the broadest application of the plateau principle is creating realistic time signatures for change in kinetic models (see [[Mathematical model]]). One example of this principle is the long time required to effectively change human body composition.  Theoretical studies have shown that many months of consistent physical training and food restriction are needed to bring about permanent weight stability in people who were previously [[overweight]].&lt;ref&gt;Chow CC, Hall KD. The dynamics of human body weight change. PLoS Comput. Biol. 4(3):e1000045, 2008.&lt;/ref&gt;

==The plateau principle in pharmacokinetics==
Most drugs are eliminated from the [[blood plasma]] with first order kinetics.  For this reason, when a drug is introduced into the body at a constant rate by [[intravenous therapy]], it approaches a new steady concentration in the blood at a rate defined by its [[half-life]].  Similarly, when the intravenous infusion is ended, the drug concentration decreases exponentially and reaches an undetectable level after 5–6 half-lives have passed.&lt;ref&gt;Pratt, WB and Taylor P, Principles of Drug Action: The Basis of Pharmacology. Churchill-Livingstone, New York, 1990&lt;/ref&gt;&lt;ref&gt;Okpako, D.T. Principles of Pharmacology : A Topical Approach. Cambridge University Press. 1991.&lt;/ref&gt;  If the same drug is administered as a [[bolus (medicine)]] with a single injection, peak concentration is achieved almost immediately and then the concentration declines exponentially.

Most drugs are taken by mouth.  In this case, the assumption of constant infusion is only approximated as doses are repeated over the course of several days.  The plateau principle still applies but more complex models are required to account for the [[route of administration]].

==Equations for the approach to steady state==
Derivation of equations that describe the time course of change for a system with [[Order of approximation#Zeroth-order|zero-order]] input and first-order elimination are presented in [[exponential decay]] and [[biological half-life]] and in scientific literature.,&lt;ref name="Goldstein A 1968"/&gt;&lt;ref name="Berlin CM 1965"&gt;Berlin CM, Schimke RT. Influence of turnover rates on the responses of enzymes to cortisone. Mol Pharmacol. 1:149, 1965.&lt;/ref&gt;

:&lt;math&gt;C_t = C_0 e^{-k_e t} \,&lt;/math&gt;

*''C&lt;sub&gt;t&lt;/sub&gt;'' is concentration after time ''t''
*''C''&lt;sub&gt;0&lt;/sub&gt; is the initial concentration (''t'' = 0)
*''k&lt;sub&gt;e&lt;/sub&gt;'' is the elimination rate constant

The relationship between the elimination rate constant and half-life is given by the following equation:

:&lt;math&gt;k_e = \frac{\ln 2}{t_{1/2}}\,&lt;/math&gt;

Because ln 2 equals 0.693, the half-life is readily calculated from the elimination rate constant.  Half-life has units of time, and the elimination rate constant has units of 1/time, e.g., per hour or per day.

An equation can be used to forecast the concentration of a compound at any future time when the fractional degration rate and steady state concentration are known:

:&lt;math&gt;C_t = C_0 + (C_{ss} - C_0)(1 - e^{-k_e t})\,&lt;/math&gt;

*''C&lt;sub&gt;ss&lt;/sub&gt;'' is concentration after the steady state has been achieved.

The exponential function in parentheses corresponds to the fraction of total change that has been achieved as time passes and the difference between ''C&lt;sub&gt;ss&lt;/sub&gt;'' and ''C&lt;sub&gt;0&lt;/sub&gt;'' equals the total amount of change.  Finally, at steady state, the concentration is expected to equal the rate of synthesis, production or infusion divided by the first order elimination constant.

:&lt;math&gt;C_{ss}= \frac{k_s}{k_e} \,&lt;/math&gt;

*''k&lt;sub&gt;s&lt;/sub&gt;'' is the rate of synthesis or infusion

Although these equations were derived to assist with predicting the time course of drug action,&lt;ref name="Goldstein A 1968"/&gt; the same equation can be used for any substance or quantity that is being produced at a measurable rate and degraded with first-order kinetics.  Because the equation applies in many instances of [[mass balance]], it has very broad applicability in addition to [[pharmacokinetics]].  The most important inference derived from the steady state equation and the equation for fractional change over time is that the elimination rate constant (''k&lt;sub&gt;e&lt;/sub&gt;'') or the sum of rate constants that apply in a model determine the time course for change in mass when a system is perturbed (either by changing the rate of inflow or production, or by changing the elimination rate(s)).

===Estimating values for kinetic rate parameters===
When experimental data are available, the normal procedure for estimating rate parameters such as ''k&lt;sub&gt;e&lt;/sub&gt;'' and ''C&lt;sub&gt;ss&lt;/sub&gt;'' is to minimize the [[Mean squared error|sum of squares]] of differences between observed data and values predicted based on initial estimates of the rate constant and steady state value.  This can be done using any software package that contains a [[curve fitting]] routine.  An example of this methodology implemented with spreadsheet software has been reported.&lt;ref&gt;Hargrove JL, Heinz G, Heinz O. Modeling transitions in body composition: the approach to steady state for anthropometric measures and physiological functions in the Minnesota human starvation study. Dyn Med. 2008 Oct 7;7:16.&lt;/ref&gt;  The same article reports a method that requires only 3 equally spaced data points to obtain estimates for kinetic parameters. Spreadsheets that compare these methods are available. [http://www.pubmedcentral.nih.gov/articlerender.fcgi?tool=pubmed&amp;pubmedid=18840293 Three point method explained]

==The plateau principle in nutrition==
Dr. [[Wilbur O. Atwater]], who developed the first database of food composition in the United States, recognized that the response to excessive or insufficient nutrient intake included an adjustment in efficiency that would result in a plateau.  He observed: "It has been found by numerous experiments that when the nutrients are fed in large excess, the body may continue for a time to store away part of the extra material, but after it has accumulated a certain amount, it refuses to take on more, and the daily consumption equals the supply even when this involves great waste."&lt;ref&gt;Atwater, W.O. The Potential Energy of Food. The Chemistry and Economy of Food. III. Century 1887; 34:397–405.&lt;/ref&gt;

In general, no [[essential nutrient]] is produced in the body.  Nutrient kinetics therefore follow the plateau principle with the distinction that most are ingested by mouth and the body must contain an amount adequate for health.  The plateau principle is important in determining how much time is needed to produce a deficiency when intake is insufficient.  Because of this, pharmacokinetic considerations should be part of the information needed to set a [[dietary reference intake]] for essential nutrients.

===Vitamin C===
The blood plasma concentration of [[vitamin C]] or [[ascorbic acid]] as a function of dose attains a plateau with a half-life of about 2 weeks.&lt;ref&gt;Levine M, Conry-Cantilena C, Wang Y, Welch RW, et al. Vitamin C pharmacokinetics in healthy volunteers: evidence for a recommended
dietary allowance. Proc Natl Acad Sci U S A. 93(8):3704–9, 1996.&lt;/ref&gt; [[Bioavailability]] of vitamin C is highest at dosages below 200&amp;nbsp;mg per day. Above 500&amp;nbsp;mg, nearly all of excess vitamin C is excreted through urine.

===Vitamin D===
Vitamin D metabolism is complex because the [[provitamin]] can be formed in the skin by ultraviolet irradiation or obtained from the diet. Once hydroxylated, the vitamin has a half-life of about 2 months.&lt;ref&gt;Jones G. Pharmacokinetics of vitamin D toxicity. Am J Clin Nutr. 88:582S, 2008.&lt;/ref&gt;
Various studies have suggested that current intakes are inadequate for optimum bone health and much current research is aimed at determining recommendations for obtaining adequate circulating vitamin D&lt;sub&gt;3&lt;/sub&gt; and calcium while also minimizing potential toxicity.&lt;ref&gt;Heaney RP, Armas LA, Shary JR, Bell NH, Binkley N, Hollis BW. 25-Hydroxylation of vitamin D3: relation to circulating vitamin D3 under various input conditions. Am J Clin Nutr. 87:1738, 2008.&lt;/ref&gt;

===Phytochemicals in foods and beverages===
Many healthful qualities of foods and beverages may be related to the content of phytochemicals (see [[List of phytochemicals in food]]).  Prime examples are [[flavonoids]] found in green tea, berries, [[Cocoa solids|cocoa]] and [[spice]] as well as in the skins and seeds of apples, onions and grapes.

Investigations into healthful benefits of phytochemicals follow exactly the same principles of pharmacokinetics that are required to study drug therapy. The initial concentration of any non-nutritive phytochemical in the blood plasma is zero unless a person has recently ingested a food or beverage. For example, as increasing amounts of green tea extract are consumed, a graded increase in plasma [[tea catechins|catechin]] can be measured, and the major compound is eliminated with a half-life of about 5 hours.&lt;ref&gt;Yang CS, Chen L, Lee MJ, et al. Blood and urine levels of tea catechins after ingestion of different amounts of green tea by human volunteers. Cancer Epidemiol Biomarkers Prev.7:351, 1998.&lt;/ref&gt;  Other considerations that must be evaluated include whether the ingested compound interacts favorably or unfavorably with other nutrients or drugs, and whether there is evidence for a threshold or [[toxicity]] at higher levels of intake.

==Transitions in body composition==

=== Plateaus during dieting and weight loss ===

It is especially common for people who are trying to lose weight to experience plateaus after several weeks of successful weight reduction.  The plateau principle suggests that this leveling off is a sign of success.  Basically, as one loses weight, less [[food energy]] is required to maintain the resting metabolic rate, which makes the initial regimen less effective.&lt;ref&gt;Freytag, C. Let's bust that plateau.  Prevention magazine, May 2007&lt;/ref&gt;  The idea of weight plateaus has been discussed for subjects who are participating in a [https://www.nytimes.com/2009/10/11/magazine/11Calories-t.html?pagewanted=2 calorie restriction experiment] &lt;ref&gt;Das SK, Gilhooly CH, Golden JK et al. Long-term effects of 2 energy-restricted diets differing in glycemic load on dietary adherence, body composition, and metabolism in CALERIE: a 1–y randomized controlled trial. Am J Clin Nutr. 85:1023, 2007.&lt;/ref&gt;  Food energy is expended largely through work done against gravity (see [[Joule]]), so weight reduction lessens the effectiveness of a given workout.  In addition, a trained person has greater skill and therefore greater efficiency during a workout.  Remedies include increasing the workout intensity or length and reducing portion sizes of meals more than may have been done initially.

The fact that weight loss and dieting reduce the metabolic rate is supported by research. In one study, heat production was reduced 30% in obese men after a weight loss program, and this led to resistance to further lose body weight.&lt;ref&gt;Chaput JP and Tremblay A. Adaptive Reduction in Thermogenesis and Resistance to Lose Fat in Obese Men. The British Journal of Nutrition. 102:488, 2009.&lt;/ref&gt;  Whether body mass increases or decreases, adjustments in the [[thermic effect of food]], resting energy expenditure, and non-resting energy expenditure all oppose further change.&lt;ref&gt;Leibel RL, Rosenbaum M, Hirsch J. Changes in energy expenditure resulting from altered body weight. N Engl J Med. 332:621, 1995.&lt;/ref&gt;

===Plateaus during strength training===

Any athlete who has trained for a sport has probably experienced plateaus, and this has given rise to various strategies to continue improving.&lt;ref&gt;Ganley, T. Dodging the Dreaded Plateau: Confusing Your Muscles to Make Fitness Gains. Tampa Bay Wellness. Tampa, Florida. June, 2008.&lt;/ref&gt; Voluntary [[Skeletal muscle]] is in balance between the amount of muscle synthesized or renewed each day and the amount that is degraded.  Muscle fibers respond to repetition and load, and increased training causes the quantity of exercised muscle fiber to increase exponentially (simply meaning that the greatest gains are seen during the first weeks of training).  Successful training produces [[hypertrophy]] of muscle fibers as an adaptation to the training regimen.  In order to make further gains, greater workout intensity is required with heavier loads and more repetitions, although improvement in skill can contribute to gains in ability.

When a bodily constituent adjusts exponentially over time, it usually attains a new stable level as a result of the plateau principle.  The new level may be higher than the initial level ([[hypertrophy]]) in the case of strength training or lower in the case of dieting or disuse [[atrophy]].  This adjustment contributes to [[homeostasis]] but does not require [[feedback]] regulation.  Gradual, asymptotic approach to a new balance between synthesis and degradation produces a stable level.  Because of this, the plateau principle is sometimes called the '''stability principle.'''  Mathematically, the result is [[linear]] dynamics despite the fact that most biological processes are non-linear (see [[Nonlinear system]]) if considered over a very broad range of inputs.

===Changes in body composition when food is restricted===
Data from the [[Minnesota Starvation Experiment]] by [[Ancel Keys]] and others&lt;ref&gt;Keys A, Brozek J, Henschel A, Mickelsen O, Taylor HL. The biology of human starvation. Minneapolis,: University of Minnesota Press; 1950.&lt;/ref&gt; demonstrate that during food restriction, total body mass, fat mass and lean body mass follow an exponential approach to a new steady state.&lt;ref&gt;Alpert SS. A two-reservoir energy model of the human body.Am J Clin Nutr. 32:1710, 1979.&lt;/ref&gt; The observation that body mass changes exponentially during partial or complete starvation seems to be a general feature of adaptation to energy restriction.&lt;ref&gt;Kleiber M. The Fire of Life, An Introduction to Animal Energetics. New York: Huntington: Robert Kreiger; 1975&lt;/ref&gt;

==The plateau principle in biochemistry==
Each cell produces thousands of different kinds of [[protein]] and [[enzyme]]s.  One of the key methods of cellular regulation is to change the rate of [[Transcription (genetics)|transcription]] of [[messenger RNA]], which gives rise to a change in the rate of synthesis for the protein that the messenger RNA encodes.  The plateau principle explains why the concentration of different enzymes increases at unique rates in response to a single [[hormone]].  Because each enzyme is degraded with at a unique rate (each has a different [[half-life]]), the rate of change differs even when the same stimulus is applied.  This principle has been demonstrated for the response of liver enzymes that degrade amino acids to [[cortisone]], which is a [[catabolic]] hormone.&lt;ref name="Berlin CM 1965"/&gt;

The method of approach to steady state has also been used to analyze the change in messenger RNA levels when synthesis or degradation changes, and a model has also been reported in which the plateau principle is used to connect the change in messenger RNA synthesis to the expected change in protein synthesis and concentration as a function of time.&lt;ref&gt;Hargrove JL, Schmidt FH. The role of mRNA and protein stability in gene expression.FASEB J. 3:2360, 1989.&lt;/ref&gt;

==The plateau principle in physiology==
Excessive gain in body weight contributes to the [[metabolic syndrome]], which may include elevated fasting [[blood sugar]] (or [[glucose]]), resistance to the action of [[insulin]], elevated [[low-density lipoprotein]] (LDL cholesterol) or decreased [[high-density lipoprotein]] (HDL cholesterol), and elevated [[blood pressure]]. Although [[obesity]] by itself is not considered a disease, it increases the risk for [[Diabetes mellitus type II]].  Because body mass, fat mass and fat free mass all change exponentially during weight reduction, it is a reasonable hypothesis to expect that symptoms of metabolic syndrome will also adjust exponentially towards normal values.

==The plateau principle in compartmental modeling==
Scientists have evaluated turnover of bodily constituents using [[radiotracer]] methods and [[stable isotopes]].&lt;ref&gt;Berman M, Weiss MF, Shawn E. Some formal approaches to the analysis of kinetic data in terms of linear compartmental systems. Biophys J. 2:289, 1962.&lt;/ref&gt;  If given orally, the tracers are absorbed and move into the [[blood plasma]], and are then distributed throughout the bodily tissues.  In such studies, a [[multi-compartment model]] is required to analyze turnover by [[Isotopic labeling]].  The isotopic marker is called a '''tracer''' and the material being analyzed is the '''tracee'''.

In studies with humans, blood plasma is the only tissue that can be easily sampled.  A common procedure is to analyze the dynamics by assuming that changes can be attributed to a sum of exponentials.  A single mathematical '''compartment''' is usually assumed to follow first-order kinetics in accord with the plateau principle.  There are many examples of this kind of analysis in nutrition, for example, in the study of metabolism of zinc,&lt;ref&gt;Wastney ME, House WA, et al. Kinetics of zinc metabolism: Variation with diet, genetics and disease. J. Nutr. 130:1355S, 2000.&lt;/ref&gt; and carotenoids.&lt;ref&gt;Diwadkar-Navsariwala V, Novotny JA, Gustin DM, et al. A physiological pharmacokinetic model describing the disposition of lycopene in healthy men. J. Lipid Res. 44: 1927, 2003.&lt;/ref&gt;

The commonest assumption in compartmental modeling is that material in a homogeneous compartment behaves exponentially.  However, this assumption is sometimes modified to include a saturable response that follows [[Michaelis-Menten kinetics]] or a related model called a Hill equation.  When the material in question is present at a concentration near the ''K''&lt;sub&gt;''M''&lt;/sub&gt;, it often behaves with pseudo first-order kinetics (see [[Rate equation]]) and the plateau principle applies despite the fact that the model is non-linear.

==The plateau principle in system dynamics==
Compartmental modeling in biomedical sciences primarily originated from the need to study metabolism by using tracers.  In contrast, [[System dynamics]] originated as a simple method of developing mathematical models by [[Jay Wright Forrester]] and colleagues.  System dynamics represents a compartment or pool as a '''stock''' and movement among compartments as '''flows'''.  In general, the rate of flow depends on the amount of material in the stock to which it is connected.  It is common to represent this dependence as a constant proportion (or first order) using a '''connector''' element in the model.

System dynamics is one application of the field of [[Control theory]].  In the biomedical field, one of the strongest advocates for computer-based analysis of physiological problems was Dr. [[Arthur Guyton]]. For example, system dynamics has been used to analyze the problem of body weight regulation.&lt;ref&gt;Flatt JP. Carbohydrate-fat interactions and obesity examined by a two-compartment computer model.Obes Res. 12:2013, 2004.&lt;/ref&gt; Similar methods have been used to study the spread of epidemics (see [[Compartmental models in epidemiology]]).

Software that solves systems of equations required for compartmental modeling and system dynamics makes use of [[Finite difference]] methods to represent a set of [[Ordinary differential equation]]s.  An expert appraisal of the different types of dynamic behavior that can be developed by application of the plateau principle to the field of system dynamics has been published.&lt;ref&gt;Gallaher EJ. Biological System Dynamics: From Personal Discovery to Universal Application. Simulation. 66:243, 1996&lt;/ref&gt;

==References==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

==External links==
* [https://www.amazon.com/The-Plateau-Principle-Diet-Exercise/dp/1492727911/ref=sr_1_1?ie=UTF8&amp;qid=1379945327&amp;sr=8-1&amp;keywords=plateau+principle/ Plateau Principle book with Excel tutorials]
* [https://sites.google.com/site/plateauprinciple/ Background on the Plateau Principle with free Excel tutorials]

{{DEFAULTSORT:Plateau Principle}}
[[Category:Pharmacokinetics]]
[[Category:Mathematical and theoretical biology]]</text>
      <sha1>15akz7v0rgz5mvlmxxvt010ripenqro</sha1>
    </revision>
  </page>
  <page>
    <title>Pontryagin class</title>
    <ns>0</ns>
    <id>385944</id>
    <revision>
      <id>831543271</id>
      <parentid>828407834</parentid>
      <timestamp>2018-03-21T03:25:23Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>/* Pontryagin numbers */ tex</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6857">In [[mathematics]], the '''Pontryagin classes''', named for [[Lev Pontryagin]],  are certain [[characteristic class]]es. The Pontryagin class lies in [[cohomology group]]s with degree a multiple of four. It applies to real [[vector bundle]]s.

== Definition ==
Given a real vector bundle ''E'' over ''M'', its ''k''-th Pontryagin class ''p&lt;sub&gt;k&lt;/sub&gt;''(''E'') is defined as 
:''p&lt;sub&gt;k&lt;/sub&gt;''(''E'') = ''p&lt;sub&gt;k&lt;/sub&gt;''(''E'', '''Z''') = (−1)&lt;sup&gt;''k''&lt;/sup&gt; ''c''&lt;sub&gt;2''k''&lt;/sub&gt;(''E'' ⊗ '''C''') ∈ ''H''&lt;sup&gt;4''k''&lt;/sup&gt;(''M'', '''Z'''),
where:
*''c''&lt;sub&gt;2''k''&lt;/sub&gt;(''E'' ⊗ '''C''') denotes the 2''k''-th [[Chern class]] of the [[complexification]] ''E'' ⊗ '''C''' = ''E'' ⊕ ''iE'' of ''E'', 
*''H''&lt;sup&gt;4''k''&lt;/sup&gt;(''M'', '''Z''') is the 4''k''-[[cohomology]] group of ''M'' with [[integer]] coefficients.

The rational Pontryagin class ''p&lt;sub&gt;k&lt;/sub&gt;''(''E'', '''Q''') is defined to be the image of ''p&lt;sub&gt;k&lt;/sub&gt;''(''E'') in ''H''&lt;sup&gt;4''k''&lt;/sup&gt;(''M'', '''Q'''), the 4''k''-cohomology group of ''M'' with [[Rational number|rational]] coefficients.

== Properties ==
The '''total Pontryagin class''' 
:&lt;math&gt;p(E)=1+p_1(E)+p_2(E)+\cdots\in H^*(M,\mathbf{Z}),&lt;/math&gt;
is (modulo 2-torsion) multiplicative with respect to 
[[Glossary of differential geometry and topology#W|Whitney sum]] of vector bundles, i.e., 
:&lt;math&gt;2p(E\oplus F)=2p(E)\smile p(F)&lt;/math&gt;
for two vector bundles ''E'' and ''F'' over ''M''.  In terms of the individual Pontryagin classes ''p&lt;sub&gt;k&lt;/sub&gt;'', 
:&lt;math&gt;2p_1(E\oplus F)=2p_1(E)+2p_1(F),&lt;/math&gt;
:&lt;math&gt;2p_2(E\oplus F)=2p_2(E)+2p_1(E)\smile p_1(F)+2p_2(F)&lt;/math&gt;
and so on.

The vanishing of the Pontryagin classes and [[Stiefel–Whitney class]]es of a vector bundle does not guarantee that the vector bundle is trivial.  For example, up to [[Vector bundle#Vector bundle morphisms|vector bundle isomorphism]], there is a unique nontrivial rank 10 vector bundle ''E''&lt;sub&gt;10&lt;/sub&gt; over the [[N-sphere|9-sphere]].  (The [[Clutching construction|clutching function]] for ''E''&lt;sub&gt;10&lt;/sub&gt; arises from the [[Orthogonal group#Homotopy groups|homotopy group]] π&lt;sub&gt;8&lt;/sub&gt;(O(10)) = '''Z'''/2'''Z'''.)  The Pontryagin classes and Stiefel-Whitney classes all vanish: the Pontryagin classes don't exist in degree 9, and the Stiefel–Whitney class ''w''&lt;sub&gt;9&lt;/sub&gt; of ''E''&lt;sub&gt;10&lt;/sub&gt; vanishes by the [[Stiefel-Whitney class#Relations over the Steenrod algebra|Wu formula]] ''w''&lt;sub&gt;9&lt;/sub&gt; = ''w''&lt;sub&gt;1&lt;/sub&gt;''w''&lt;sub&gt;8&lt;/sub&gt; + Sq&lt;sup&gt;1&lt;/sup&gt;(''w''&lt;sub&gt;8&lt;/sub&gt;).  Moreover, this vector bundle is stably nontrivial, i.e. the [[Glossary of differential geometry and topology#W|Whitney sum]] of ''E''&lt;sub&gt;10&lt;/sub&gt; with any trivial bundle remains nontrivial. {{Harv|Hatcher|2009|p=76}}

Given a 2''k''-dimensional vector bundle ''E'' we have 
:&lt;math&gt;p_k(E)=e(E)\smile e(E),&lt;/math&gt;
where ''e''(''E'') denotes the [[Euler class]] of ''E'', and &lt;math&gt;\smile&lt;/math&gt; denotes the [[cup product]] of cohomology classes. 

=== Pontryagin classes and curvature ===
As was shown by [[Shiing-Shen Chern]] and [[André Weil]] around 1948, the rational Pontryagin classes 
:&lt;math&gt;p_k(E,\mathbf{Q})\in H^{4k}(M,\mathbf{Q})&lt;/math&gt;
can be presented as differential forms which depend polynomially on the [[curvature form]] of a vector bundle. This [[Chern–Weil theory]] revealed a major connection between algebraic topology and global differential geometry.

For a [[vector bundle]] ''E'' over a ''n''-dimensional [[differentiable manifold]] ''M'' equipped with a [[connection form|connection]], the total Pontryagin class is expressed as 
:&lt;math&gt;p=\left[1-\frac{{\rm Tr}(\Omega ^2)}{8 \pi ^2}+\frac{{\rm Tr}(\Omega ^2)^2-2 {\rm Tr}(\Omega ^4)}{128 \pi ^4}-\frac{{\rm Tr}(\Omega ^2)^3-6 {\rm Tr}(\Omega ^2) {\rm Tr}(\Omega ^4)+8 {\rm Tr}(\Omega ^6)}{3072 \pi ^6}+\cdots\right]\in H^*_{dR}(M),&lt;/math&gt;

where Ω denotes the [[curvature form]], and ''H*''&lt;sub&gt;dR&lt;/sub&gt;(''M'') denotes the [[de Rham cohomology]] groups.{{Citation needed|date=July 2009}}

=== Pontryagin classes of a manifold ===
The '''Pontryagin classes of a smooth manifold''' are defined to be the Pontryagin classes of its [[tangent bundle]].

[[Sergei Novikov (mathematician)|Novikov]] proved in 1966 that if manifolds are [[homeomorphism|homeomorphic]] then their rational Pontryagin classes ''p&lt;sub&gt;k&lt;/sub&gt;''(''M'', '''Q''') in ''H''&lt;sup&gt;4''k''&lt;/sup&gt;(''M'', '''Q''') are the same.

If the dimension is at least five, there are at most finitely many different smooth manifolds with given [[Homotopy#Homotopy equivalence of spaces|homotopy type]] and Pontryagin classes.

== Pontryagin numbers ==
'''Pontryagin numbers''' are certain [[topological invariant]]s of a smooth [[manifold]]. The Pontryagin number vanishes if the dimension of manifold is not divisible by 4. It is defined in terms of the Pontryagin classes of a [[manifold]] as follows:

Given a smooth &lt;math&gt;4 n&lt;/math&gt;-dimensional manifold ''M'' and a collection of natural numbers 
:&lt;math&gt;k_1, k_2, \ldots , k_m&lt;/math&gt; such that &lt;math&gt;k_1+k_2+\cdots +k_m =n&lt;/math&gt;,
the Pontryagin number &lt;math&gt;P_{k_1,k_2,\dots,k_m}&lt;/math&gt; is defined by
:&lt;math&gt;P_{k_1,k_2,\dots, k_m}=p_{k_1}\smile p_{k_2}\smile \cdots\smile p_{k_m}([M])&lt;/math&gt;
where &lt;math&gt;p_k&lt;/math&gt; denotes the ''k''-th Pontryagin class and [''M''] the [[fundamental class]] of ''M''.

=== Properties ===
#Pontryagin numbers are oriented [[cobordism]] invariant; and together with [[Stiefel-Whitney number]]s they determine an oriented manifold's oriented cobordism class.
#Pontryagin numbers of closed Riemannian manifolds (as well as Pontryagin classes) can be calculated as integrals of certain polynomials from the curvature tensor of a Riemannian manifold.
#Invariants such as [[Signature (topology)|signature]] and [[Â genus|&lt;math&gt;\hat A&lt;/math&gt;-genus]] can be expressed through Pontryagin numbers. For the theorem describing the linear combination of Pontryagin numbers giving the signature see [[Hirzebruch signature theorem]].

== Generalizations ==
There is also a ''quaternionic'' Pontryagin class, for vector bundles with [[quaternion]] structure.

== See also ==
*[[Chern–Simons form]]

== References ==
*{{cite book
  |author= [[John Milnor|Milnor John W.]]
  |author2=Stasheff, James D. |authorlink2=Jim Stasheff 
  |title= Characteristic classes
  |work= Annals of Mathematics Studies
  |issue=76
  |publisher=Princeton University Press / University of Tokyo Press
  |location=Princeton, New Jersey; Tokyo
  |year= 1974
  |isbn= 0-691-08122-0}}
* {{Cite journal | last=Hatcher | first=Allen | author-link=Allen Hatcher  | title=Vector Bundles &amp; K-Theory | edition=2.1 | year=2009 | ref=harv | postscript=&lt;!--None--&gt; | url=http://www.math.cornell.edu/~hatcher/VBKT/VBpage.html}}

==External links==
* {{springer|title=Pontryagin class|id=p/p073750}}

[[Category:Characteristic classes]]
[[Category:Differential topology]]</text>
      <sha1>ex8ta5yia0ed981cvzkromxtbx6ccff</sha1>
    </revision>
  </page>
  <page>
    <title>Product metric</title>
    <ns>0</ns>
    <id>6812823</id>
    <revision>
      <id>869000577</id>
      <parentid>868999832</parentid>
      <timestamp>2018-11-15T19:44:11Z</timestamp>
      <contributor>
        <username>Irina Gelbukh</username>
        <id>11768660</id>
      </contributor>
      <comment>/* The case of Riemannian manifolds */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2042">In [[mathematics]], a '''product metric''' is a [[metric (mathematics)|metric]] on the [[Cartesian product]] of finitely many [[metric spaces]] &lt;math&gt;(X_1,d_{X_1}),\ldots,(X_n,d_{X_n})&lt;/math&gt; which metrizes the product topology. The most prominent product metrics are the ''p'' '''product metrics''' for a fixed &lt;math&gt;p\in[1,\infty]&lt;/math&gt; :
It is defined as the [[Lp space|''p'' norm]] of the ''n''-vector of the distances measured in ''n'' subspaces:
:&lt;math&gt;d_p((x_1,\ldots,x_n),(y_1,\ldots,y_n)) = \|\left(d_{X_1}(x_1,y_1), \ldots, d_{X_n}(x_n,y_n)\right)\|_p&lt;/math&gt;

For &lt;math&gt;p=\infty&lt;/math&gt; this metric is also called the sup metric:
:&lt;math&gt;d_{\infty} ((x_1,\ldots,x_n),(y_1,\ldots,y_n)) := \max \left\{ d_{X_1}(x_1,y_1), \ldots, d_{X_n}(x_n,y_n) \right\}.&lt;/math&gt;

==Choice of norm==
For [[Euclidean space]]s, using the L&lt;sub&gt;2&lt;/sub&gt; norm gives rise to the Euclidean metric in the product space; however, any other choice of ''p'' will lead to a topologically equivalent metric space. In the [[category of metric spaces]] (with Lipschitz maps having Lipschitz constant 1), the product (in the category theory sense) uses the sup metric.

==The case of Riemannian manifolds==

For [[Riemannian manifold]]s &lt;math&gt;(M_1,g_1)&lt;/math&gt; and &lt;math&gt;(M_2,g_2)&lt;/math&gt;, the '''product metric''' &lt;math&gt;g=g_1\oplus g_2&lt;/math&gt; on &lt;math&gt;M_1\times M_2&lt;/math&gt; is defined by 

:&lt;math&gt;g(X_1+X_2,Y_1+Y_2)=g_1(X_1,Y_1)+g_2(X_2,Y_2)&lt;/math&gt; 

for &lt;math&gt;X_i,Y_i\in T_{p_i}M_i&lt;/math&gt; under the natural identification &lt;math&gt;T_{(p_1,p_2)}(M_1\times M_2)=T_{p_1}M_1\oplus T_{p_2}M_2&lt;/math&gt;.

==References==
*{{citation
 | last1 = Deza | first1 = Michel Marie | author1-link = Michel Deza
 | last2 = Deza | first2 = Elena
 | page = 83
 | publisher = Springer-Verlag
 | title = Encyclopedia of Distances
 | url = https://books.google.com/books?id=LXEezzccwcoC&amp;pg=PA83
 | year = 2009}}.
* {{citation|first=John|last=Lee|title=Riemannian manifolds|publisher=Springer Verlag|year=1997|isbn=978-0-387-98322-6}}.


{{DEFAULTSORT:Product Metric}}
[[Category:Metric geometry]]</text>
      <sha1>r20ts1iesk6bbnrs9mcidyw86ultx7v</sha1>
    </revision>
  </page>
  <page>
    <title>Quasitoric manifold</title>
    <ns>0</ns>
    <id>30495939</id>
    <revision>
      <id>841543228</id>
      <parentid>790774229</parentid>
      <timestamp>2018-05-16T13:46:38Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14908">{{Orphan|date=May 2013}}

In [[mathematics]], a '''quasitoric manifold''' is a topological analogue of the [[Toric variety#Resolution of Singularities|nonsingular]] projective [[toric variety]] of [[algebraic geometry]]. A [[Smooth manifold|smooth]] &lt;math&gt;2n&lt;/math&gt;-dimensional [[manifold]] is a quasitoric manifold if it admits a smooth, locally standard action of an [[Torus#n-dimensional torus|&lt;math&gt;n&lt;/math&gt;-dimensional torus]], with [[orbit space]] an &lt;math&gt;n&lt;/math&gt;-dimensional [[Simple polytope|simple]] [[Convex polytope|convex]] [[polytope]].

Quasitoric manifolds were introduced in 1991 by M. Davis and T. Januszkiewicz,&lt;ref name=autogenerated1&gt;M. Davis and T. Januskiewicz, 1991.&lt;/ref&gt; who called them "toric manifolds". However, the term "quasitoric manifold" was eventually adopted to avoid confusion with the class of compact smooth [[toric variety|toric varieties]], which are known to algebraic geometers as [[toric manifold]]s.&lt;ref&gt;V. Buchstaber and T. Panov, 2002.&lt;/ref&gt;

Quasitoric manifolds are studied in a variety of contexts in [[algebraic topology]], such as [[Complex cobordism|complex cobordism theory]], and the other oriented [[Cohomology theory|cohomology theories]].&lt;ref&gt;V. Buchstaber and N. Ray, 2008.&lt;/ref&gt;

==Definitions==
Denote the &lt;math&gt;i&lt;/math&gt;-th subcircle of the &lt;math&gt;n&lt;/math&gt;-torus &lt;math&gt;T^n&lt;/math&gt; by &lt;math&gt;T_i&lt;/math&gt; so that &lt;math&gt;T_1 \times \ldots \times T_n = T^n&lt;/math&gt;. Then coordinate-wise multiplication of &lt;math&gt;T^n&lt;/math&gt; on &lt;math&gt;\mathbb{C}^n&lt;/math&gt; is called the '''standard representation'''.

Given open sets &lt;math&gt;X&lt;/math&gt; in &lt;math&gt;M^{2n}&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; in &lt;math&gt;\mathbb{C}^n&lt;/math&gt;, that are closed under the [[Group action|action]] of &lt;math&gt;T^n&lt;/math&gt;, a &lt;math&gt;T^{n}&lt;/math&gt;-action on &lt;math&gt;M^{2n}&lt;/math&gt; is defined to be '''locally isomorphic''' to the standard representation if &lt;math&gt;h(tx) = \alpha(t)h(x)&lt;/math&gt;, for all &lt;math&gt;t&lt;/math&gt; in &lt;math&gt;T^n&lt;/math&gt;, &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;X&lt;/math&gt;, where &lt;math&gt;h&lt;/math&gt; is a [[homeomorphism]] &lt;math&gt;X \rightarrow Y&lt;/math&gt;, and &lt;math&gt;\alpha&lt;/math&gt; is an [[automorphism]] of &lt;math&gt;T^n&lt;/math&gt;.

Given a simple convex polytope &lt;math&gt;P^n&lt;/math&gt; with &lt;math&gt;m&lt;/math&gt; [[Facet (mathematics)|facets]], a &lt;math&gt;T^n&lt;/math&gt;-manifold &lt;math&gt;M^{2n}&lt;/math&gt; is a '''quasitoric manifold over''' &lt;math&gt;P^n&lt;/math&gt; if,

# the &lt;math&gt;T^n&lt;/math&gt;-action is locally isomorphic to the standard representation,
# there is a [[projection map|projection]] &lt;math&gt;\pi : M^{2n} \rightarrow P^n&lt;/math&gt; that maps each &lt;math&gt;l&lt;/math&gt;-dimensional orbit to a point in the interior of an &lt;math&gt;l&lt;/math&gt;-dimensional [[Face (geometry)|face]] of &lt;math&gt;P^n&lt;/math&gt;, for &lt;math&gt;l = 0,&lt;/math&gt; &lt;math&gt;...,&lt;/math&gt;  &lt;math&gt;n&lt;/math&gt;.

The definition implies that the fixed points of &lt;math&gt;M^{2n}&lt;/math&gt; under the &lt;math&gt;T^n&lt;/math&gt;-action are mapped to the vertices of &lt;math&gt;P^n&lt;/math&gt; by &lt;math&gt;\pi&lt;/math&gt;, while points where the action is free project to the interior of the polytope.

==The dicharacteristic function==
A quasitoric manifold can be described in terms of a '''dicharacteristic function''' and an associated '''dicharacteristic matrix'''. In this setting it is useful to assume that the facets &lt;math&gt;F_1,\dots,F_m&lt;/math&gt; of &lt;math&gt;P^n&lt;/math&gt; are ordered so that the intersection &lt;math&gt;F_{1} \cap  \dots  \cap F_{n}&lt;/math&gt; is a vertex &lt;math&gt;v&lt;/math&gt; of &lt;math&gt;P^{n}&lt;/math&gt;, called the '''initial vertex'''.

A '''dicharacteristic function''' is a [[homomorphism]] &lt;math&gt;\lambda : T^m \rightarrow T^n&lt;/math&gt;, such that if &lt;math&gt;F_{i_1} \cap  \dots  \cap F_{i_k}&lt;/math&gt; is a [[codimension]]-&lt;math&gt;k&lt;/math&gt; face of &lt;math&gt;P^n&lt;/math&gt;, then &lt;math&gt;\lambda&lt;/math&gt; is a [[monomorphism]] on restriction to the subtorus &lt;math&gt;T_{i_1} \times  \dots  \times T_{i_k}&lt;/math&gt; in &lt;math&gt;T^m&lt;/math&gt;.

The restriction of &amp;lambda; to the subtorus &lt;math&gt;T_1 \times \ldots \times T_n&lt;/math&gt; corresponding to the initial vertex &lt;math&gt;v&lt;/math&gt; is an isomorphism, and so &lt;math&gt;\lambda(T_1), \ldots, \lambda(T_n)&lt;/math&gt; can be taken to be a basis for the [[Lie algebra]] of &lt;math&gt;T^n&lt;/math&gt;. The [[epimorphism]] of Lie algebras associated to &amp;lambda; may be described as a linear transformation &lt;math&gt;\mathbb{Z}^m \rightarrow \mathbb{Z}^n&lt;/math&gt;, represented by the &lt;math&gt; n \times m&lt;/math&gt; '''dicharacteristic matrix''' &lt;math&gt;\Lambda&lt;/math&gt; given by

::&lt;math&gt;
\begin{bmatrix}
1 &amp; 0 &amp; \dots &amp; 0 &amp; \lambda_{1, n+1} &amp; \dots &amp; \lambda_{1, m}\\
0 &amp; 1 &amp; \dots &amp; 0 &amp; \lambda_{2, n+1} &amp; \dots &amp; \lambda_{2, m}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; 1 &amp; \lambda_{n, n+1} &amp; \dots &amp; \lambda_{n, m}
\end{bmatrix}.
&lt;/math&gt;

The &lt;math&gt;i&lt;/math&gt;th column of &lt;math&gt;\Lambda&lt;/math&gt; is a primitive vector &lt;math&gt;\lambda_i = (\lambda_{1, i}, \dots, \lambda_{n, i})&lt;/math&gt; in &lt;math&gt;\mathbb{Z}^n&lt;/math&gt;, called the '''facet vector'''.  As each facet vector is primitive, whenever the facets &lt;math&gt;F_{i_1} \cap  \dots  \cap F_{i_n}&lt;/math&gt; meet in a vertex, the corresponding columns &lt;math&gt;\lambda_{i_1}, \dots \lambda_{i_n}&lt;/math&gt; form a basis of &lt;math&gt;\mathbb{Z}^n&lt;/math&gt;, with determinant equal to &lt;math&gt;\pm 1&lt;/math&gt;.  The [[Isotropy group#Orbits and stabilizers|isotropy subgroup]] associated to each facet &lt;math&gt;F_i&lt;/math&gt; is described by

::&lt;math&gt; \{(e^{2\pi i \theta\lambda_{1,i}}, \ldots, e^{2\pi i \theta\lambda_{n,i}}) \in T^n \},  &lt;/math&gt;

for some &lt;math&gt;\theta&lt;/math&gt; in &lt;math&gt;\mathbb{R}&lt;/math&gt;.

In their original treatment of quasitoric manifolds, Davis and Januskiewicz&lt;ref name=autogenerated1 /&gt; introduced the notion of a '''characteristic function''' that mapped each facet of the polytope to a vector determining the isotropy subgroup of the facet, but this is only defined up to sign.  In more recent studies of quasitoric manifolds, this ambiguity has been removed by the introduction of the dicharacteristic function and its insistence that each circle &lt;math&gt;\lambda(T_i)&lt;/math&gt; be oriented, forcing a choice of sign for each vector &lt;math&gt;\lambda_i&lt;/math&gt;. The notion of the dicharacteristic function was originally introduced V. Buchstaber and N. Ray&lt;ref&gt;V. Buchstaber and N. Ray, 2001.&lt;/ref&gt; to enable the study of quasitoric manifolds in complex cobordism theory.  This was further refined by introducing the ordering of the facets of the polytope to define the initial vertex, which eventually leads to the above neat representation of the dicharacteristic matrix &lt;math&gt;\Lambda&lt;/math&gt; as &lt;math&gt;(I_n \mid S)&lt;/math&gt;, where &lt;math&gt;I_n&lt;/math&gt; is the [[identity matrix]] and &lt;math&gt;S&lt;/math&gt; is an &lt;math&gt;n \times (m-n)&lt;/math&gt; submatrix.&lt;ref&gt;V. Buchstaber, T. Panov and N. Ray, 2007.&lt;/ref&gt;

==Relation to the moment-angle complex==
The kernel &lt;math&gt;K(\lambda)&lt;/math&gt; of the dicharacteristic function acts freely on the [[moment angle complex]] &lt;math&gt;Z_{P^n}&lt;/math&gt;, and so defines a [[Principle fiber bundle|principal]] &lt;math&gt;K(\lambda)&lt;/math&gt;-bundle &lt;math&gt;Z_{P^n} \rightarrow M^{2n}&lt;/math&gt; over the resulting [[Quotient space (topology)|quotient space]] &lt;math&gt;M^{2n}&lt;/math&gt;.  This quotient space can be viewed as

:: &lt;math&gt;T^n \times P^n / \sim, &lt;/math&gt;

where pairs &lt;math&gt;(t_1, p_1)&lt;/math&gt;, &lt;math&gt;(t_2, p_2)&lt;/math&gt; of &lt;math&gt;T^n \times P^n&lt;/math&gt; are identified if and only if &lt;math&gt;p_1 = p_2&lt;/math&gt; and &lt;math&gt;t_1^{-1}t_2&lt;/math&gt; is in the image of &lt;math&gt;\lambda&lt;/math&gt; on restriction to the subtorus &lt;math&gt;T_{i_1} \times \dots \times T_{i_k}&lt;/math&gt; that corresponds to the unique face &lt;math&gt;F_{i_1} \cap \dots \cap F_{i_k}&lt;/math&gt; of &lt;math&gt;P^n&lt;/math&gt; containing the point &lt;math&gt;p_1&lt;/math&gt;, for some &lt;math&gt;1 \leq k \leq n&lt;/math&gt;.

It can be shown that any quasitoric manifold &lt;math&gt;M^{2n}&lt;/math&gt; over &lt;math&gt;P^n&lt;/math&gt; is [[Equivariant map|equivariently]] [[Diffeomorphism|diffeomorphic]] to a quasitoric manifold of the form of the quotient space above.&lt;ref&gt;M. Davis and T. Januskiewicz, 1991, Proposition 1.8.&lt;/ref&gt;

==Examples==
* The &lt;math&gt;n&lt;/math&gt;-dimensional [[complex projective space]] &lt;math&gt;\mathbb{C}P^n&lt;/math&gt; is a quasitoric manifold over the &lt;math&gt;n&lt;/math&gt;-[[simplex]] &lt;math&gt;\Delta^n&lt;/math&gt;. If &lt;math&gt;\Delta^n&lt;/math&gt; is embedded in &lt;math&gt;\mathbb{R}^{n+1}&lt;/math&gt; so that the origin is the initial vertex, a dicharacteristic function can be chosen so that the associated dicharacteristic matrix is

::&lt;math&gt;
\begin{bmatrix}
1 &amp; 0 &amp; \dots &amp; 0 &amp; -1\\
0 &amp; 1 &amp; \dots &amp; 0 &amp; -1\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; 1 &amp; -1
\end{bmatrix}.
&lt;/math&gt;

The moment angle complex &lt;math&gt;Z_{\Delta^n}&lt;/math&gt; is the &lt;math&gt;(2n+1)&lt;/math&gt;-sphere &lt;math&gt;S^{2n+1}&lt;/math&gt;, the kernel &lt;math&gt;K(\lambda)&lt;/math&gt; is the diagonal subgroup &lt;math&gt;\{(t, \dots, t)\} &lt; T^{n+1}&lt;/math&gt;, so the quotient of &lt;math&gt;Z_{\Delta^n}&lt;/math&gt; under the action of &lt;math&gt;K(\lambda)&lt;/math&gt; is &lt;math&gt;\mathbb{C}P^n&lt;/math&gt;.&lt;ref&gt;V. Buchstaber, T. Panov and N. Ray, 2007, Example 3.11.&lt;/ref&gt;

* The [[Bott manifold]]s that form the stages in a [[Bott tower]] are quasitoric manifolds over [[Hypercube|&lt;math&gt;n&lt;/math&gt;-cubes]]. The &lt;math&gt;n&lt;/math&gt;-cube &lt;math&gt;I^n&lt;/math&gt; is embedded in &lt;math&gt;\mathbb{R}^{2n}&lt;/math&gt; so that the origin is the initial vertex, and a dicharacteristic function is chosen so that the associated dicharacteristic matrix &lt;math&gt;(I_n \mid S)&lt;/math&gt; has &lt;math&gt;S&lt;/math&gt; given by

::&lt;math&gt;
\begin{bmatrix}
1       &amp;0          &amp;\cdots &amp;0      &amp;0      &amp;\cdots &amp;0  &amp;0  \\
-a(1,2)   &amp;1          &amp;\cdots &amp;0      &amp;0      &amp;\cdots &amp;0  &amp;0  \\
\vdots      &amp;\vdots         &amp;   &amp;\vdots     &amp;\vdots     &amp;   &amp;\vdots &amp;\vdots \\
-a(1,i)   &amp;-a(2,i)      &amp;\cdots &amp;-a(i-1,i)    &amp;1      &amp;\cdots &amp;0  &amp;0  \\
\vdots      &amp;\vdots         &amp;   &amp;\vdots     &amp;\vdots     &amp;   &amp;\vdots &amp;\vdots \\
-a(1,n) &amp;-a(2,n)        &amp;\cdots &amp;-a(i-1,n)  &amp;-a(i,n)    &amp;\cdots &amp;-a(n-1,n)  &amp;1  
\end{bmatrix},
&lt;/math&gt;

for integers &lt;math&gt;a(i,j)&lt;/math&gt;.

The moment angle complex &lt;math&gt;Z_{I^n}&lt;/math&gt; is a product of &lt;math&gt;n&lt;/math&gt; copies of 3-sphere embedded in &lt;math&gt;\mathbb{C}^{2n}&lt;/math&gt;, the kernel &lt;math&gt;K(\lambda)&lt;/math&gt; is given by

::&lt;math&gt;\{(t_1,t_1^{-a(1,2)}t_2,\dots,t_1^{-a(1,i)}\dots t_{i-1}^{-a(i-1,i)}t_i,\dots, t_1^{-a(1,n)}\dots t_{n-1}^{-a(n-1,n)}t_n, t_1^{-1}, \dots, t_n^{-1}) : t_i \in T,  1\leq i\leq n \} &lt; T^{2n}&lt;/math&gt;,

so that the quotient of &lt;math&gt;Z_{I^n}&lt;/math&gt; under the action of &lt;math&gt;K(\lambda)&lt;/math&gt; is the &lt;math&gt;n&lt;/math&gt;-th stage of a Bott tower.&lt;ref&gt;V. Buchstaber, T. Panov and N. Ray, 2007, Example 3.12.&lt;/ref&gt; The integer values &lt;math&gt;a(i,j)&lt;/math&gt; are the tensor powers of the line bundles whose product is used in the iterated sphere-bundle construction of the Bott tower.&lt;ref&gt;Y. Civan and N. Ray, 2005.&lt;/ref&gt;

==The cohomology ring of a quasitoric manifold==
Canonical [[complex line bundle]]s &lt;math&gt;\rho_i&lt;/math&gt; over &lt;math&gt;M^{2n}&lt;/math&gt; given by

:: &lt;math&gt;Z_{P^n} \times_{K(l)} \mathbb{C}_i \longrightarrow M^{2n}&lt;/math&gt;,

can be associated with each facet &lt;math&gt;F_i&lt;/math&gt; of &lt;math&gt;P^n&lt;/math&gt;, for &lt;math&gt;1 \leq i \leq m&lt;/math&gt;, where &lt;math&gt;K(\lambda)&lt;/math&gt; acts on &lt;math&gt;\mathbb{C}_i&lt;/math&gt;, by the restriction of &lt;math&gt;K(\lambda)&lt;/math&gt; to the &lt;math&gt;i&lt;/math&gt;-th subcircle of &lt;math&gt;T^m&lt;/math&gt; embedded in &lt;math&gt;\mathbb{C}&lt;/math&gt;.  These bundles are known as the '''facial bundles''' associated to the quasitoric manifold.  By the definition of &lt;math&gt;M^{2n}&lt;/math&gt;, the preimage of a facet &lt;math&gt;\pi^{-1}(F_i)&lt;/math&gt; is a &lt;math&gt;2(n-1)&lt;/math&gt;-dimensional quasitoric '''facial submanifold''' &lt;math&gt;M_i&lt;/math&gt; over &lt;math&gt;F_i&lt;/math&gt;, whose isotropy subgroup is the restriction of &lt;math&gt;\lambda&lt;/math&gt; on the subcircle &lt;math&gt;T_i&lt;/math&gt; of &lt;math&gt;T^m&lt;/math&gt;.  Restriction of &lt;math&gt;\rho_i&lt;/math&gt; to &lt;math&gt;M_i&lt;/math&gt; gives the [[Normal bundle|normal]] 2-plane bundle of the embedding of &lt;math&gt;M_i&lt;/math&gt; in &lt;math&gt;M^{2n}&lt;/math&gt;.

Let &lt;math&gt;x_i&lt;/math&gt; in &lt;math&gt;H^2(M^{2n}; \mathbb{Z})&lt;/math&gt; denote the first [[Chern class]] of &lt;math&gt;\rho_i&lt;/math&gt;. The integral [[cohomology ring]] &lt;math&gt;H^*(M^{2n}; \mathbb{Z})&lt;/math&gt; is generated by &lt;math&gt;x_i&lt;/math&gt;, for &lt;math&gt;1 \leq i \leq m&lt;/math&gt;, subject to two sets of relations. The first are the relations generated by the [[Stanley–Reisner ring|Stanley–Reisner ideal]] of &lt;math&gt;P^n&lt;/math&gt;; linear relations determined by the dicharacterstic function comprise the second set:

:: &lt;math&gt;x_i = -\lambda_{i, n+1}x_{n+1} - \cdots - \lambda_{i, m}x_m,  \mbox{ for } 1\leq i \leq n&lt;/math&gt;.

Therefore only &lt;math&gt;x_{n+1}, \dots, x_m&lt;/math&gt; are required to generate &lt;math&gt;H^*(M^{2n}; \mathbb{Z})&lt;/math&gt; multiplicatively.&lt;ref name=autogenerated1 /&gt;

==Comparison with toric manifolds==
* Any projective toric manifold is a quasitoric manifold, and in some cases non-projective toric manifolds are also quasitoric manifolds.
* Not all quasitoric manifolds are toric manifolds. For example, the [[connected sum]] &lt;math&gt;\mathbb{C}P^2 \sharp \mathbb{C}P^2&lt;/math&gt; can be constructed as a quasitoric manifold, but it is not a toric manifold.&lt;ref&gt;M. Masuda and D. Y. Suh 2007.&lt;/ref&gt;

== Notes ==
{{Reflist}}

==References==
*{{Citation | last1=Buchstaber | first1=V. | last2=Panov | first2=T. | title=Torus Actions and their Applications in Topology and Combinatorics|year=2002 | publisher=American Mathematical Society | series=University Lecture Series | volume=24}}
*{{Citation | last1=Buchstaber | first1=V. | last2=Panov | first2=T. | last3=Ray | first3=N. | title=Spaces of polytopes and cobordism of quasitoric manifolds |year=2007 | journal=Moscow Mathematical Journal| volume=7 | issue=2 |pages=219–242}}
*{{Citation | last1=Buchstaber | first1=V. | last2=Ray | first2=N. | title=Tangential structures on toric manifolds and connected sums of polytopes |year=2001 | journal=International Mathematics Research Notices | volume=4 | pages=193–219}}
*{{Citation | last1=Buchstaber | first1=V. | last2=Ray | first2=N. | title=Proceedings of the International Conference in Toric Topology; Osaka City University 2006 | year=2008 | publisher=American Mathematical Society| series=Contemporary Mathematics | volume=460 | chapter=An Invitation to Toric Topology: Vertex Four of a Remarkable Tetrahedron | pages=1–27}}
*{{Citation | last1=Civan| first1=Y. | last2=Ray | first2=N. | title=Homotopy decompositions and ''K''-theory of Bott towers|year=2005 | journal=K-Theory | volume=34 | pages=1–33 | doi=10.1007/s10977-005-1551-x| arxiv=math/0408261}}
*{{Citation | last1=Davis | first1=M. | last2=Januskiewicz | first2=T. | title=Convex polytopes, Coxeter orbifolds and torus actions |year=1991 | journal=Duke Mathematical Journal | volume=62 | issue=2 | pages=417–451 | doi=10.1215/s0012-7094-91-06217-4}}
*{{Citation | last1=Masuda | first1=M. | last2=Suh | first2=D. Y. | title=Proceedings of the International Conference in Toric Topology; Osaka City University 2006 | year=2008 | publisher=American Mathematical Society| series=Contemporary Mathematics | volume=460 | chapter=Classification problems of toric manifolds via topology | pages=273–286}}

{{Areas of mathematics |collapsed}}

{{DEFAULTSORT:Quasitoric Manifold}}
[[Category:Algebraic topology]]
[[Category:Topology]]
[[Category:Manifolds]]</text>
      <sha1>t2m9kl4taq2tibs4f19x6uyr5xfw7sl</sha1>
    </revision>
  </page>
  <page>
    <title>The Theoretical Minimum</title>
    <ns>0</ns>
    <id>43821526</id>
    <revision>
      <id>835400747</id>
      <parentid>811334620</parentid>
      <timestamp>2018-04-08T13:50:47Z</timestamp>
      <contributor>
        <username>Gehrab</username>
        <id>49203</id>
      </contributor>
      <comment>I modified some words and added an external link to an official webpage for the first book.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4654">{{Infobox book  
| name          = The Theoretical Minimum
| image         = The Theoretical Minimum - book cover.jpg
| caption       = Hardcover edition
| border        = yes
| author        = [[Leonard Susskind]], George Hrabovsky
| country       = United States
| language      = English
| genre         = [[Popular science]]
| publisher     = [[Basic Books]]
| release_date  = January 29, 2013
| media_type    = Print, e-book, audiobook
| pages         = 256 pp.
| isbn          = 978-0465028115
| dewey         =  
| congress      =  
| oclc          =  
| preceded_by   = 
| followed_by   = 
}}

'''''The Theoretical Minimum: What You Need to Know to Start Doing Physics''''' ({{ISBN|0-465-02811-X}})  is a [[popular science]] book by [[Leonard Susskind]] and George Hrabovsky. The book was initially published on January 29, 2013 by [[Basic Books]].&lt;ref&gt;{{citation|url=https://www.wsj.com/articles/SB10001424127887323968304578250253842601938|title=Physics Made (Almost) Easy|first1=John|last1=Gribbin|date=2013-02-01|accessdate=2014-12-13|newspaper=[[The Wall Street Journal]]}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=''The Theoretical Minimum: What You Need to Know to Start Doing Physics''|first=Robert G.|last=Brown|journal=Physics Today|volume=66|issue=6|department=Books|date=June 2013|publisher=American Institute of Physics|doi=10.1063/PT.3.2015}}.&lt;/ref&gt;&lt;ref name="dubson"&gt;{{citation|title=''The Theoretical Minimum: What You Need to Know to Start Doing Physics''|department=Book Reviews|journal=American Journal of Physics|volume=82|issue=2|page=174|doi=10.1119/1.4816681|first=Michael|last=Dubson}}.&lt;/ref&gt;

==Overview==
The book is a mathematical introduction to various [[theoretical physics]] concepts, such as [[principle of least action]], [[Lagrangian mechanics]], [[Hamiltonian mechanics]], [[Poisson brackets]], and [[electromagnetism]].&lt;ref name="dubson"/&gt; It is the first book in a series called ''The Theoretical Minimum'', based on Stanford Continuing Studies courses taught by world renowned physicist [[Leonard Susskind]]. The courses collectively teach everything required to gain a basic understanding of each area of modern physics, including much of the fundamental mathematics.

== Core Course 1: Classical Mechanics ==
The book, also published in 2014 by Penguin Books under the title '''''Classical Mechanics: The Theoretical Minimum''''' ({{ISBN|978-0141976228}}), is complemented by video recordings of the complete lectures which are available [http://theoreticalminimum.com/courses/classical-mechanics/2011/fall on-line]. There is also a supplemental [http://www.madscitech.org/tm/index.html website] for the book.

== Core Course 2: Quantum Mechanics ==
The second book in the series, by [[Leonard Susskind]] and Art Friedman, was published in 2014 by Basic Books under the title '''''Quantum Mechanics: The Theoretical Minimum''''' ({{ISBN|978-0465062904}}).Video recordings of the complete lectures are available [http://theoreticalminimum.com/courses/quantum-mechanics/2012/winter on-line].
== Core Course 3: Special Relativity and Classical Field Theory ==
The third book in the series, by [[Leonard Susskind]] and Art Friedman, was published in 2017. This covers Special Relativity and Classical Field Theory

== Core Courses 4-6 ==
Lectures in the remaining three courses, on
* General Relativity
* Cosmology
* Statistical Mechanics
are available [http://theoreticalminimum.com/courses on-line] as video recordings.

== Supplemental Courses ==
Further lecture courses in the Theoretical Minimum series have been delivered by Prof. Susskind, on
* Advanced Quantum Mechanics
* Higgs Boson
* Quantum Entanglement
* Relativity
* Particle Physics 1: Basic Concepts
* Particle Physics 2: Standard Model
* Particle Physics 3: Supersymmetry and Grand Unification
* String Theory
* Cosmology and Black Holes
and these are also available [http://theoreticalminimum.com/courses/supplemental on-line] as video recordings.

==References==
{{reflist}}

==External links==
{{wikiquote}}
* [http://theoreticalminimum.com/home The Theoretical Minimum] website at the [[Stanford Institute for Theoretical Physics]].
* [https://1drv.ms/b/s!AqWTa8Ggj9Ahgdw9H6ILGS7FLgr83Q Solutions to The Theoretical Minimum, Classical Mechanics] by Filip Van Lijsebetten.
* [https://onedrive.live.com/redir?resid=21D08FA0C16B93A5!28241&amp;authkey=!AAM3H-TDeYaAbaI&amp;ithint=file%2cpdf Solutions to The Theoretical Minimum, Quantum Mechanics] by Filip Van Lijsebetten.

{{DEFAULTSORT:Theoretical Minimum, The}}
[[Category:Popular science books]]
[[Category:2013 non-fiction books]]
[[Category:Basic Books books]]

{{physics-book-stub}}
{{mathematics-lit-stub}}</text>
      <sha1>kndp4kutnei7fljinxnfzgspb38f3qm</sha1>
    </revision>
  </page>
  <page>
    <title>Transportation theory (mathematics)</title>
    <ns>0</ns>
    <id>6631661</id>
    <revision>
      <id>871618113</id>
      <parentid>867406908</parentid>
      <timestamp>2018-12-02T09:13:25Z</timestamp>
      <contributor>
        <username>Slaymaker1907</username>
        <id>35199423</id>
      </contributor>
      <comment>As described in talk page, removed incorrect and opinionated material.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15674">{{Use dmy dates|date=April 2012}}
{{Missing information|commonly used linear programming formulations|date=February 2015}}
In [[mathematics]] and economics, '''transportation theory''' or '''transport theory''' is a name given to the study of optimal [[transport]]ation and [[allocation of resources]]. The problem was formalized by the French [[mathematician]] [[Gaspard Monge]] in 1781.&lt;ref name=Monge&gt;G. Monge. ''Mémoire sur la théorie des déblais et des remblais. Histoire de l’Académie Royale des Sciences de Paris, avec les Mémoires de Mathématique et de Physique pour la même année'', pages 666–704, 1781.&lt;/ref&gt;

In the 1920s A.N. Tolstoi was one of the first to study the transportation problem [[mathematical model|mathematically]]. In 1930, in the collection ''Transportation Planning Volume I'' for the National Commissariat of Transportation of the Soviet Union, he published a paper "Methods of Finding the Minimal Kilometrage in Cargo-transportation in space".&lt;ref&gt;[[Alexander Schrijver|Schrijver, Alexander]], [https://books.google.com/books?id=mqGeSQ6dJycC&amp;printsec=frontcover ''Combinatorial Optimization''], Berlin ; New York : Springer, 2003. {{isbn|3540443894}}. Cf. [https://books.google.com/books?id=mqGeSQ6dJycC&amp;pg=PA362&amp;lpg=PA362&amp;dq=a.n.+tolstoi+transportation+networks&amp;source=bl&amp;ots=xONQNWerQa&amp;sig=LJl_9KbyS1FDp_wYuXNJ9ruEKes&amp;hl=en&amp;ei=bMujTLP6O4OClAfjoomQCw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CBsQ6AEwAA#v=onepage&amp;q=a.n.%20tolstoi%20transportation%20networks&amp;f=false p.362]&lt;/ref&gt;&lt;ref&gt;Ivor Grattan-Guinness, Ivor,  [https://books.google.com/books?id=2hDvzITtfdAC&amp;printsec=frontcover ''Companion encyclopedia of the history and philosophy of the mathematical sciences''], Volume 1, JHU Press, 2003. Cf. [https://books.google.com/books?id=2hDvzITtfdAC&amp;pg=PA831&amp;lpg=PA831&amp;dq=%22a.n.+tolstoy%22+mathematics&amp;source=bl&amp;ots=pCwrnZWBwI&amp;sig=QQz_1ng7mR6dmZWCmZ4L1Twar3U&amp;hl=en&amp;ei=w8SjTJeUDoT7lwe3nYT8Cw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4&amp;ved=0CCAQ6AEwAw#v=onepage&amp;q=%22a.n.%20tolstoy%22%20mathematics&amp;f=false p.831]&lt;/ref&gt;

Major advances were made in the field during World War II by the [[Soviet Union|Soviet]] mathematician and economist [[Leonid Kantorovich]].&lt;ref name=Kantorovich&gt;L. Kantorovich. ''On the translocation of masses.'' C.R. (Doklady) Acad. Sci. URSS (N.S.), 37:199–201, 1942.&lt;/ref&gt; Consequently, the problem as it is stated is sometimes known as the '''Monge–Kantorovich transportation problem'''.&lt;ref name="Villani2003"&gt;{{cite book|author=Cédric Villani|title=Topics in Optimal Transportation|year=2003|publisher=American Mathematical Soc.|isbn=978-0-8218-3312-4|page=66}}&lt;/ref&gt; The [[linear programming]] formulation of the transportation problem is also known as the [[Frank Lauren Hitchcock|Hitchcock]]–[[Tjalling Koopmans|Koopmans]] transportation problem.&lt;ref name="RaoRao2009"&gt;{{cite book|author1=Singiresu S. Rao|title=Engineering Optimization: Theory and Practice|year=2009|publisher=John Wiley &amp; Sons|isbn=978-0-470-18352-6|pages=221|edition=4th}}&lt;/ref&gt; A similar problem was solved in 1917 by the Japanese mathematician [[Soichi Kakeya]].&lt;ref&gt;{{cite web|url = http://repo.lib.hosei.ac.jp/bitstream/10114/3101/1/kogakubu%2022%20tanaka.pdf|author=George Tanaka|title=The Transportation Problem by Prof. Kakeya}}&lt;/ref&gt;

==Motivation==

===Mines and factories===
Suppose that we have a collection of ''n'' mines mining iron ore, and a collection of ''n'' factories which use the iron ore that the mines produce. Suppose for the sake of argument that these mines and factories form two [[Disjoint sets|disjoint]] [[subset]]s ''M'' and ''F'' of the [[Euclidean plane]] '''R'''&lt;sup&gt;2&lt;/sup&gt;. Suppose also that we have a ''cost function'' ''c''&amp;nbsp;:&amp;nbsp;'''R'''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;×&amp;nbsp;'''R'''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;[0,&amp;nbsp;∞), so that ''c''(''x'',&amp;nbsp;''y'') is the cost of transporting one shipment of iron from ''x'' to ''y''. For simplicity, we ignore the time taken to do the transporting. We also assume that each mine can supply only one factory (no splitting of shipments) and that each factory requires precisely one shipment to be in operation (factories cannot work at half- or double-capacity). Having made the above assumptions, a ''transport plan'' is a [[bijection]] ''T'' : ''M'' → ''F''.
In other words, each mine ''m'' ∈ ''M'' supplies precisely one factory ''T''(''m'') ∈ ''F'' and each factory is supplied by precisely one mine. 
We wish to find the ''optimal transport plan'', the plan ''T'' whose ''total cost''

:&lt;math&gt;c(T) := \sum_{m \in M} c(m, T(m))&lt;/math&gt;

is the least of all possible transport plans from ''M'' to ''F''. This motivating special case of the transportation problem is an instance of the [[assignment problem]].
More specifically, it is equivalent to finding a minimum weight matching in a bipartite graph.

===Moving books: the importance of the cost function===
The following simple example illustrates the importance of the [[Cost curve|cost function]] in determining the optimal transport plan. Suppose that we have ''n'' books of equal width on a shelf (the [[real line]]), arranged in a single contiguous block. We wish to rearrange them into another contiguous block, but shifted one book-width to the right. Two obvious candidates for the optimal transport plan present themselves:
# move all ''n'' books one book-width to the right ("many small moves");
# move the left-most book ''n'' book-widths to the right and leave all other books fixed ("one big move").
If the cost function is proportional to Euclidean distance (''c''(''x'',&amp;nbsp;''y'')&amp;nbsp;=&amp;nbsp;α|''x''&amp;nbsp;−&amp;nbsp;''y''|) then these two candidates are ''both'' optimal. If, on the other hand, we choose the [[Convex function|strictly convex]] cost function proportional to the square of Euclidean distance (''c''(''x'',&amp;nbsp;''y'')&amp;nbsp;=&amp;nbsp;α|''x''&amp;nbsp;−&amp;nbsp;''y''|&lt;sup&gt;2&lt;/sup&gt;), then the "many small moves" option becomes the unique minimizer.

==Abstract formulation of the problem==

===Monge and Kantorovich formulations===

The transportation problem as it is stated in modern or more technical literature looks somewhat different because of the development of [[Riemannian geometry]] and [[measure theory]]. The mines-factories example, simple as it is, is a useful reference point when thinking of the abstract case. In this setting, we allow the possibility that we may not wish to keep all mines and factories open for business, and allow mines to supply more than one factory, and factories to accept iron from more than one mine.

Let ''X'' and ''Y'' be two [[separable space|separable]] [[metric space]]s such that any [[probability measure]] on ''X'' (or ''Y'') is a [[Radon measure]] (i.e. they are [[Radon space]]s). Let ''c'' : ''X'' × ''Y'' → [0, ∞] be a Borel-[[measurable function]]. Given probability measures μ on ''X'' and ν on ''Y'', Monge's formulation of the optimal transportation problem is to find a transport map ''T'' : ''X'' → ''Y'' that realizes the [[infimum]]

:&lt;math&gt;\inf \left\{ \left. \int_{X} c(x, T(x)) \, \mathrm{d} \mu (x) \;\right| \; T_* (\mu) = \nu \right\},&lt;/math&gt;

where ''T''&lt;sub&gt;∗&lt;/sub&gt;(μ) denotes the [[pushforward measure|push forward]] of μ by ''T''. A map ''T'' that attains this infimum (''i.e.'' makes it a [[minimum]] instead of an infimum) is called an "optimal transport map".

Monge's formulation of the optimal transportation problem can be ill-posed, because sometimes there is no ''T'' satisfying ''T''&lt;sub&gt;∗&lt;/sub&gt;(μ) = ν: this happens, for example, when μ is a [[Dirac measure]] but ν is not.

We can improve on this by adopting Kantorovich's formulation of the optimal transportation problem, which is to find a probability measure γ on ''X'' × ''Y'' that attains the infimum

:&lt;math&gt;\inf \left\{ \left. \int_{X \times Y} c(x, y) \, \mathrm{d} \gamma (x, y) \right| \gamma \in \Gamma (\mu, \nu) \right\},&lt;/math&gt;

where Γ(μ, ν) denotes the collection of all probability measures on ''X'' × ''Y'' with [[Conditional probability|marginals]] μ on ''X'' and ν on ''Y''. It can be shown&lt;ref name=AGS&gt;L. Ambrosio, N. Gigli &amp; G. Savaré. ''Gradient Flows in Metric Spaces and in the Space of Probability Measures.'' Lectures in Mathematics ETH Zürich, Birkhäuser Verlag, Basel. (2005)&lt;/ref&gt; that a minimizer for this problem always exists when the cost function ''X'' is lower semi-continuous and Γ(μ, ν) is a [[Tightness of measures|tight]] collection of measures (which is guaranteed for Radon spaces ''X'' and ''Y''). (Compare this formulation with the definition of the [[Wasserstein metric]] ''W''&lt;sub&gt;1&lt;/sub&gt; on the space of probability measures.) A gradient descent formulation for the solution of the Monge-Kantorovich problem was given by [[Sigurd Angenent]], Steven Haker, and [[Allen Tannenbaum]].&lt;ref name=AHT&gt;{{cite journal |first=S. |last=Angenent |first2=S. |last2=Haker |first3=A. |last3=Tannenbaum |title=Minimizing flows for the Monge–Kantorovich problem |journal=SIAM J. Math. Analysis |volume=35 |issue=1 |pages=61–97 |year=2003 |doi=10.1137/S0036141002410927 }}&lt;/ref&gt;

===Duality formula===
The minimum of the Kantorovich problem is equal to

:&lt;math&gt;\sup \left( \int_{X} \varphi (x) \, \mathrm{d} \mu (x) + \int_{Y} \psi (y) \, \mathrm{d} \nu (y) \right),&lt;/math&gt;

where the [[supremum]] runs over all pairs of [[bounded function|bounded]] and [[continuous function]]s &lt;math&gt;\phi : X \rightarrow \mathbf{R}&lt;/math&gt; and &lt;math&gt;\psi : Y \rightarrow \mathbf{R}&lt;/math&gt; such that

:&lt;math&gt;\varphi (x) + \psi (y) \leq c(x, y).&lt;/math&gt;

==Solution of the problem==

===Optimal transportation on the real line===
{{multiple image
&lt;!-- Layout parameters --&gt;
 | align             = right
 | direction         = vertical
 | width             = 200
&lt;!--image 1--&gt;
 | image1            = Optimal transport matrix.png
 | alt1              = Optimal transportation matrix
 | link1             = 
 | caption1          =  Optimal transportation matrix
&lt;!--image 2--&gt;
 | image2            = Continuous optimal transport.png
 | alt2              = Continuous optimal transport 
 | link2             = 
 | caption2          = Continuous optimal transport
}}
For &lt;math&gt;1 \leq p &lt; \infty&lt;/math&gt;, let &lt;math&gt;\mathcal{P}_p(\mathbf{R})&lt;/math&gt; denote the collection of [[probability measure]]s on '''&lt;math&gt;\mathbf{R}&lt;/math&gt;''' that have finite ''&lt;math&gt;p&lt;/math&gt;''-th [[moment (mathematics)|moment]]. Let &lt;math&gt;\mu, \nu \in \mathcal{P}_p(\mathbf{R})&lt;/math&gt; and let &lt;math&gt;c(x, y) = h(x-y)&lt;/math&gt;, where &lt;math&gt;h:\mathbf{R} \rightarrow [0,\infty)&lt;/math&gt; is a [[convex function]].
# If &lt;math&gt;\mu&lt;/math&gt; has no [[atom (measure theory)|atom]], i.e., if the [[cumulative distribution function]] &lt;math&gt;F_\mu = \mathbf{R}\rightarrow[0,1]&lt;/math&gt; of &lt;math&gt;\mu&lt;/math&gt; is a [[continuous function]], then &lt;math&gt;F_{\nu}^{-1} \circ F_{\mu} : \mathbf{R} \to \mathbf{R}&lt;/math&gt; is an optimal transport map. It is the unique optimal transport map if &lt;math&gt;h&lt;/math&gt; is strictly convex.
# We have
::&lt;math&gt;\min_{\gamma \in \Gamma(\mu, \nu)} \int_{\mathbf{R}^2} c(x, y) \, \mathrm{d} \gamma (x, y) = \int_0^1 c \left( F_{\mu}^{-1} (s), F_{\nu}^{-1} (s) \right) \, \mathrm{d} s.&lt;/math&gt;

The proof of this solution appears in.&lt;ref name=RL_MTP&gt;Rachev, Svetlozar T., and Ludger Rüschendorf. ''Mass Transportation Problems: Volume I: Theory''. Vol. 1. Springer, 1998.&lt;/ref&gt;

===Separable Hilbert spaces===
Let ''&lt;math&gt;X&lt;/math&gt;'' be a [[separable space|separable]] [[Hilbert space]]. Let &lt;math&gt;\mathcal{P}_p(X)&lt;/math&gt; denote the collection of probability measures on ''&lt;math&gt;X&lt;/math&gt;'' such that have finite &lt;math&gt;p&lt;/math&gt;-th moment; let &lt;math&gt;\mathcal{P}_p^r(X)&lt;/math&gt; denote those elements &lt;math&gt;\mu \in \mathcal{P}_p(X)&lt;/math&gt; that are '''Gaussian regular''': if &lt;math&gt;g&lt;/math&gt; is any [[strictly positive measure|strictly positive]] [[Gaussian measure]] on &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;g(N) = 0&lt;/math&gt;, then &lt;math&gt;\mu(N) = 0&lt;/math&gt; also.

Let &lt;math&gt;\mu \in \mathcal{P}_p^r (X)&lt;/math&gt;, &lt;math&gt;\nu \in \mathcal{P}_p(X)&lt;/math&gt;, &lt;math&gt;c (x, y) = | x - y |^p/p&lt;/math&gt; for &lt;math&gt;p\in(1,\infty), p^{-1} + q^{-1} = 1&lt;/math&gt;. Then the Kantorovich problem has a unique solution &lt;math&gt;\kappa&lt;/math&gt;, and this solution is induced by an optimal transport map: i.e., there exists a Borel map &lt;math&gt;r\in L^p(X, \mu; X)&lt;/math&gt; such that

:&lt;math&gt;\kappa = (\mathrm{id}_{X} \times r)_{*} (\mu) \in \Gamma (\mu, \nu).&lt;/math&gt;

Moreover, if &lt;math&gt;\nu&lt;/math&gt; has [[bounded set|bounded]] [[support (measure theory)|support]], then

:&lt;math&gt;r(x) = x -  | \nabla \phi (x) |^{q - 2} \nabla \phi (x)&lt;/math&gt;

for &lt;math&gt;\mu&lt;/math&gt;-almost all ''&lt;math&gt;x\in X&lt;/math&gt;'' for some [[Lipschitz continuous|locally Lipschitz]], ''c''-concave and maximal Kantorovich potential &lt;math&gt;\phi&lt;/math&gt;. (Here &lt;math&gt;\nabla \phi&lt;/math&gt; denotes the [[Gâteaux derivative]] of &lt;math&gt;\phi&lt;/math&gt;.)

== Applications ==
The Monge-Kantorovich optimal transport has found applications in wide range in different fields. Among them are:
* [[Image registration]] and warping &lt;ref&gt;{{Cite journal|last=Haker|first=Steven|last2=Zhu|first2=Lei|last3=Tannenbaum|first3=Allen|last4=Angenent|first4=Sigurd|date=2004-12-01|title=Optimal Mass Transport for Registration and Warping|url=https://link.springer.com/article/10.1023/B:VISI.0000036836.66311.97|journal=International Journal of Computer Vision|language=en|volume=60|issue=3|pages=225–240|doi=10.1023/B:VISI.0000036836.66311.97|issn=0920-5691}}&lt;/ref&gt;
* Reflector design &lt;ref&gt;{{Cite journal|last=Glimm|first=T.|last2=Oliker|first2=V.|date=2003-09-01|title=Optical Design of Single Reflector Systems and the Monge–Kantorovich Mass Transfer Problem|url=https://link.springer.com/article/10.1023/A:1024856201493|journal=Journal of Mathematical Sciences|language=en|volume=117|issue=3|pages=4096–4108|doi=10.1023/A:1024856201493|issn=1072-3374}}&lt;/ref&gt;
* Retrieving information from [[Shadowgraph|shadowgraphy]] and proton radiography &lt;ref&gt;{{Cite journal|last=Kasim|first=Muhammad Firmansyah|last2=Ceurvorst|first2=Luke|last3=Ratan|first3=Naren|last4=Sadler|first4=James|last5=Chen|first5=Nicholas|last6=Sävert|first6=Alexander|last7=Trines|first7=Raoul|last8=Bingham|first8=Robert|last9=Burrows|first9=Philip N.|date=2017-02-16|title=Quantitative shadowgraphy and proton radiography for large intensity modulations|url=https://link.aps.org/doi/10.1103/PhysRevE.95.023306|journal=Physical Review E|volume=95|issue=2|pages=023306|doi=10.1103/PhysRevE.95.023306|arxiv=1607.04179|bibcode=2017PhRvE..95b3306K}}&lt;/ref&gt;
* [[Seismic tomography]] and [[Reflection seismology]] &lt;ref&gt;{{cite journal |last1=Metivier |first1=Ludovic |title=Measuring the misfit between seismograms using an optimal transport distance: application to full waveform inversion |journal=Geophysical Journal International |date=24 February 2016 |volume=205 |issue=1 |page=345–377 |doi=10.1093/gji/ggw014 |url=https://academic.oup.com/gji/article-abstract/205/1/345/2594839}}&lt;/ref&gt;

==See also==
{{Commons category|Transportation theory}}
* [[Wasserstein metric]]
* [[Transport function]]
* [[Hungarian algorithm]]
* [[Transportation planning]]

==References==
{{Reflist|30em}}

==Further reading==
* {{cite book | last=Brualdi | first=Richard A. | title=Combinatorial matrix classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86565-4 | zbl=1106.05001 }}

{{DEFAULTSORT:Transportation Theory}}
[[Category:Calculus of variations]]
[[Category:Matching]]
[[Category:Mathematical economics]]
[[Category:Measure theory]]
[[Category:Transport economics]]
[[Category:Optimization in vector spaces]]
[[Category:Mathematical optimization in business]]</text>
      <sha1>ijelpeejxlc1hhp4pcvlzu9j5miv98m</sha1>
    </revision>
  </page>
  <page>
    <title>Valery Glivenko</title>
    <ns>0</ns>
    <id>21711296</id>
    <revision>
      <id>849292788</id>
      <parentid>837714523</parentid>
      <timestamp>2018-07-07T23:52:57Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>Various citation &amp; identifier cleanup (JSTOR mostly), plus AWB genfixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3592">{{Infobox scientist
| alma_mater = {{Moscow University|1925}}
}}
'''Valery Ivanovich Glivenko''' ({{lang-ua|Вале́рій Іва́нович Гливе́нко}}, {{lang-ru|Вале́рий Ива́нович Гливе́нко}}; 2 January 1897 ([[Gregorian calendar]]) / 21 December 1896 ([[Julian calendar]]) in [[Kiev]] &amp;ndash; 15 February 1940 in [[Moscow]]) was a [[Ukrainians|Ukrainian]] [[Soviet Union|Soviet]] [[mathematician]]. He worked in [[foundations of mathematics]], [[real analysis]], [[probability theory]], and [[mathematical statistics]].  He taught at Moscow Industrial Pedagogical Institute&lt;ref&gt;which was later merged with the Moscow Pedagogical Institute, now [[Moscow State Pedagogical University]]&lt;/ref&gt; until his death at age 43.&lt;ref&gt;Eckart Menzler-Trott, Logic's lost genius: the life of Gerhard Gentzen, tr. Craig A. Smoryński and Edward R Griffor, p. 95.&lt;/ref&gt;&lt;ref&gt;{{cite journal|mr=0004017|last=Kolmogoroff|first=A.|authorlink=Andrey Kolmogorov|title=Obituary: Valerii Ivanovich Glivenko. (1897–1940)|language=Russian|journal= Uspekhi Mat. Nauk|volume=8|year=1941|pages=379&amp;ndash;383|url=http://mi.mathnet.ru/umn8831}}&lt;/ref&gt; Most of Glivenko's work was published in [[French language|French]].

==See also==
*[[Double-negation translation#Propositional logic|Glivenko's double-negation translation]]
*[[Glivenko's theorem (probability theory)]]
*[[Glivenko–Cantelli theorem]]
*[[Glivenko–Stone theorem]]

==Notes==
&lt;references/&gt;

==Works==
* {{cite journal
|author=Glivenko V.
|title=Sur quelques points de la logique de M. Brouwer
|journal=Bulletins de la classe des sciences
|year=1929
|volume=15
|number=5
|pages=183–188
}} {{ref-fr}}
* {{cite journal
|author=Glivenko V.
|title=Sur la logique de M. Brouwer
|journal=Académie Royale de Belgique, Bulletin
|year=1928
|volume=14
|pages=225–228
}} {{ref-fr}}
* {{cite journal
|author=Glivenko V.
|title=Sur les valeurs probables de fonctions
|journal=Rendiconti Accad. d. L. Roma
|year=1928
|volume=8
|number= 6
|pages=480–483
}} {{ref-fr}}
* {{cite journal
|author=Glivenko V.
|title=Sur les fonctions représentables implicitement par fonctions continues
|journal=Fundamenta Mathematicae
|year=1929
|volume=14
|number= 1
|pages=252–265
|doi=10.4064/fm-14-1-252-265
}} {{ref-fr}}
* {{cite journal
|author=Glivenko V.
|title=Sur les fonctions implicites
|journal= Mat. Sb.
|year=1929
|volume=36
|number= 2
|pages=138–142
}} {{ref-fr}}
* {{cite journal
|author=Glivenko V.
|title=Sulla determinazione empirica delle leggi di probabilita
|journal= Giorn. Ist. Ital. Attuari 
|year=1933
|volume=4
|pages=92–99
}} {{It icon}}
* {{cite journal
|author=Glivenko V.
|title=Contribution a l'étude des systémes de choses normées
|journal= American Journal of Mathematics
|year=1937
|volume=59
|number=3
|pages=941–956
|jstor= 2371360
|doi=10.2307/2371360
}} {{ref-fr}}
*{{cite book |last=Glivenko |first=V. |date=1938 |title=Théorie générale des Structures |volume=652 |publisher=Hermann et Cie}} {{ref-fr}}

==External links==
* {{MathGenealogy|108323}}
* [http://www.kazan.mathnet.ru/php/getFT.phtml?jrnid=rm&amp;paperid=8832&amp;volume=&amp;year=1941&amp;issue=8&amp;fpage=378&amp;what=fullt&amp;option_lang=eng Photograph]

{{Authority control}}

{{DEFAULTSORT:Glivenko, Valery Ivanovich}}
[[Category:20th-century mathematicians]]
[[Category:Soviet mathematicians]]
[[Category:Soviet logicians]]
[[Category:1896 births]]
[[Category:1940 deaths]]
[[Category:Probability theorists]]
[[Category:Mathematical analysts]]
[[Category:Mathematical logicians]]


{{Ukraine-mathematician-stub}}
{{Russia-mathematician-stub}}</text>
      <sha1>jiilhba9kuwl1p9wptb4nnf2nsix55b</sha1>
    </revision>
  </page>
</mediawiki>
